question_id,title,body,tags
778870,Does this series converge ? $\sum_{n=1}^{\infty}\frac{\ln2\ln3\dots\ln(n+1)}{\ln(2+a)\ln(3+a)\dots \ln(n+1+a)}$,"I want to evaluate $$\sum_{n=1}^{\infty}\frac{\ln2\ln3\dots\ln(n+1)}{\ln(2+a)\ln(3+a)\dots \ln(n+1+a)}$$ where $a>0$. I tried to see if it converges or not with Raabe Duhamel , but it gets really nasty and I'm not sure of the outcome.Any help is welcomed.","['convergence-divergence', 'calculus', 'limits']"
778876,"Characterization of lim sup, lim inf","If $(a_n)$ is a real sequence, in lecture we had: $$\begin{align}\limsup_{n\to\infty} a_n=a \iff &(i)\forall \epsilon >0 \,\exists n_0\in \mathbb{N} :a_n<a+\epsilon  \forall n\ge n_0\\\text{ and }&(ii) \forall \epsilon >0 \, \forall m\in \mathbb{N} \, \exists n\ge m :a_n>a-\epsilon\end{align}$$ and such a analogue characterization for lim inf. I know the definition of $ \limsup\limits_{n\to\infty} a_n=\sup H(a_n)$ with $H(a_n)$ set of all the limitpoints of $(a_n)$. I don't understand the epsilon-characterization of lim sup an, maybe you can draw a picture,  explain it in words why it is equivalent (or prove it directly, but I only want to understand it). Later I want to do an example if I have understand this. Maybe you want to help? Regards","['limsup-and-liminf', 'real-analysis', 'definition']"
778881,Differential vs difference equations in mathematical modeling,"I'm reading a little about mathematical modeling and I've seen some population models based on differential equations. I've also seen some (not many) that can support both difference  and differential equations. My question is: in the case where a problem (not necessarily about population growth) can be modeled both ways, what advantages / disadvantages of using each method? The answer to the first question always depends on the problem? I've read books like ""Mathematical biology"" by JD Murray and ""Mathematical Models"" by Haberman, but these authors do not mention advantages / disadvantages of using one method or another. If you can recommend me literature on the subject would be great. Thank you very much.","['applications', 'ordinary-differential-equations', 'mathematical-modeling']"
778903,need to construct a function satisfying wave equation.,"I need an example of a function  that satisfies wave equation and that vanishes beyond certain range. I mean if $f(x,t)$ is a function of space and time, then $f(x, t) = 0, $ for $x < a(t) $ and $x>b(t)$ where $a(t)$ and $b(t)$ be any function of time such that $b(t)<a(t)$ for all time $t$. How to construct such function?","['physics', 'partial-differential-equations', 'functions']"
778910,Solving a differential equation using Laplace transform,"The problem has two parts: 1.
Solve the initial value problem:
$$
y''+y=\sum_{j=0}^\infty \delta_{2j\pi}(t)
$$
with the initial conditions: $y(0)=y'(0)=0$ 2.Show that if $2n\pi<t<2(n+1)\pi$ for some integer n, then $y(t)=(n+1)sin(t)$. I only managed to partially solve the first part. I got: $$\mathcal{L} \{y(t)\}=\frac{e^{2\pi s}}{(e^{2\pi s}-1)(s^{2}+1)}$$ I could really use some help finding the inverse Laplace transform of this and solving the second part. Thank you in advance!","['laplace-transform', 'ordinary-differential-equations', 'calculus']"
778912,"How does one prove or disprove this integral inequality for a $C^1([0,1])$ function with zero average?","By zero average, I mean $\int_0^1 f(x) dx = 0$. The inequality is 
$$ 2 \int_0^1 [f(x)]^2 dx \le \left(\int_0^1 |f(x)|dx\right)\left(\int_0^1 |f'(x)|dx\right).
$$
Cauchy-Schwarz hasn't led me anywhere, and Poincare's Inequality doesn't apply in an obvious fashion.","['functional-analysis', 'real-analysis', 'integral-inequality']"
778946,"Prove that if $A$ is normal, then eigenvectors corresponding to distinct eigenvalues are necessarily orthogonal (alternative proof)","The problem statement is as follows: Prove that for a normal matrix $A$, eigenvectors corresponding to different eigenvalues are necessarily orthogonal. I can certainly prove that this is the case, using the spectral theorem.  The gist of my proof is presented below. If possible, I would like to find a simpler proof.  I was hoping that there might be some sort of manipulation along these lines , noting that
$$
\langle Av_1,A v_2\rangle 
= \langle v_1,A^*Av_2\rangle 
= \langle v_1,AA^*v_2\rangle 
= \langle A^* v_1,A^* v_2 \rangle
$$ Any ideas here would be appreciated. My proof: Let $\{v_{\lambda,i}\}$ be an orthonormal basis of eigenvectors (as guaranteed by the spectral theorem) such that
$$
A v_{\lambda,i} = \lambda v_{\lambda,i}
$$
Let $v_1,\lambda_1$ and $v_2,\lambda_2$ be eigenpairs with $\lambda_1 \neq \lambda_2$.  We may write
$
v_1 = \sum_{i,\lambda}a_{i,\lambda}v_{i,\lambda}
.$
We then have
$$
0 = Av_1 - \lambda_1 v_1 = \sum_{i,\lambda}(\lambda - \lambda_1)a_{i,\lambda}v_{i,\lambda}
$$
So that $a_{i,\lambda} = 0$ when $\lambda \neq \lambda_1$.  Similarly, we may write $v_2 = \sum_{i,\lambda}b_{i,\lambda}v_{i,\lambda}$, and note that $b_{i,\lambda} = 0$ when $\lambda \neq \lambda_2$.  From there, we have
$$
\langle v_1,v_2 \rangle = \sum_{i,\lambda}a_{i,\lambda}b_{i,\lambda}
$$
the above must be zero since for each pair $i,\lambda$, either $a_{i,\lambda}=0$ or $b_{i,\lambda} = 0$.","['matrices', 'linear-algebra', 'alternative-proof']"
778951,Notions of stability for differential equations,"Consider a system of differential equations $$\dot{x} = f(x,u)$$ $$y = h(x,u)$$
where $x(t), u(t)$ are vectors in some $\mathbb{R}^n$. We define the infinity norm of a function in more-or-less in the usual way $$||z(t)||_{\infty} = \sup_{t \geq 0} ||z(t)||_{\infty}$$ where the infinity norm of a vector is the absolute value of its largest entry. This system of differential equations is called BIBO (bounded-input, bounded-output) stable if every $u$ with bounded infinity norm results in $y$ with bounded infinity norm, regardless of the initial condition $x(0)$. It is called ${\mathcal L}_{\infty}$ stable if we have $$||y||_{\infty} \leq g(||u||_{\infty}) + q(x(0))$$ where $g: \mathbb{R} \rightarrow \mathbb{R}, q: \mathbb{R}^n \rightarrow \mathbb{R}$ are some (finite valued) functions. My question: is it true that a BIBO stable system is ${\mathcal L}_{\infty}$ stable? This is really a question about compactness, taking a converging subsequence carefully - I'm having some trouble doing that. If it were true that BIBO stable systems are $L_{\infty}$ stable, we would need  to rule out the possibility that while every $u$ with bounded infinity norm results in $y$ with bounded infinity norm, there is no uniform bound on how large these norms get. Motivation: Khalil's textbook Nonlinear Systems has a confusing sentence about these two notions: on page 198 of the third edition, The definition of $L_{\infty}$ stability is the familiar notion of bounded-input-bounded-output stability; namely, if the system is ${\mathcal L}_{\infty}$ stable, then for every bounded input $u(t)$, the output...is bounded. The part before the semicolon seems to suggest the two notions are equivalent, while the part afterwards suggests that the implication was meant only in one direction. Furthermore: does the answer depend on assumptions on $f$ and $h$? For example, the $f,h$ I'd like to apply this to are differentiable, but not Lipschitz over all of $\mathbb{R}^n$. Does it make a difference if we assume these functions are differentiable infinitely many times as well as Lipschitz over $\mathbb{R}^n$?","['dynamical-systems', 'ordinary-differential-equations', 'analysis']"
778990,How can I find a curve based on its tangent lines?,Let's say for some curve its tangent lines at every point have a property that the length of a segment within the first quarter $[0;+\infty)^2$ is exactly $C>0$. How can such a curve be defined analytically? Maybe even in terms of $y=f(x)$. Now about the tangent lines themselves. Noticeably for all $k<0$ the tangent line $y = kx - \frac{Ck}{\sqrt{k^2 + 1}}$ seems to fit the description precisely because the length of its segment within the first quarter is equal to $C$. But what to do next?,"['plane-curves', 'derivatives']"
779013,Need to check if a t- test should be used instead of a z -test here! [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 10 years ago . Improve this question For this question shouldn't they be using a t test and the test statistic should be t and not z as the sample is small? Is this a mistake in the mark scheme?",['statistics']
779022,The 'sine and cosine theorem' - formulas for the sum and difference,"I've read somewhere that the sine and cosine functions can be fully described by this theorem: $\sin(0) = 0, \cos(0) = 1$ $\sin(a-b) = \sin(a)\cos(b) - \sin(b)\cos(a)$ $\cos(a-b) = \cos(a)\cos(b) + \sin(a)\sin(b)$ There is na $r>0$ such that:
$$0<\sin(x)<x<\tan(x), x \in(0, r), \tan(x) = \frac{\sin(x)}{\cos(x)} $$ With this theorem, we can prove things like: $\sin^2(x) + \cos^2(x) = 1$ by doing $\cos(a-a) = \cos(a)\cos(a) + \sin(a)\sin(a)$ $\sin(-x) = -\sin(x)$ by doing $\sin(0-x) = \sin(0)\cos(x) - \sin(x)\cos(0)$ $\cos(a+b) = \cos(a)\cos(b) - \sin(a)\sin(b)$ by doing $\cos(a-(-b)) = \cos(a)\cos(-b) + \sin(a)\sin(-b)$ $\sin(a+b) = \sin(a)\cos(b)+\sin(b)\cos(a)$ by doing $\sin(a-(-b)) = \sin(a)\cos(-b) - \sin(-b)\cos(a)$ And other trigonometric identities that also follows from what I've already done. The problem is that there are many definitions for the sine and cosine function. Let's begin by the classical definition: Classical Definition The sine function is defined as the ratio between the opposite side of the angle, and the hipotenuse of this right triangle. The cosine function is defined as the ratio between the adjacent side of the angle, and the hipotenuse of this right triangle. The tangent function is defined as the ratio between the sine function and the cosine function (with $\cos (x) \neq 0)$ The other trigonometric identities can be proven geometrically for an angle less than or equal $\frac{\pi}{2}rad$ because it's a right triangle. So, we can't prove $\sin(a-b)$ geometrically and then prove $\sin(a+b)$ analytically like I did, because we assumed a negative $b$, something that's not defined geometrically in the right triangle. The identity $\sin^2(x) + \cos^2(x) = 1$ can be proven with a simple pythagorean theorem in a triangle with hypotenuse 1. The formulas for the sum and difference of sines and cosines can be proven geometrically like in this images I found in this answer : Unit circle definition Imagine a circle centered at the origin of the cartesian plane, then: The sine function for an $x \in R, x>0$ can be defined as the $y$ position of point of the circle where the angle stops if we travel anti-clockwise inside the circle's line. The cosine for an $x \in R, x>0$ function can be defined as the $x$ position of point of the circle where the angle stops if we travel anti-clockwise inside the circle's line. We can make the same definition for negative angles, so for an $x \in R, x<0$ the same holds, but we're know travelling clockwise. The tangent function is defined as the ratio between the sine function and the cosine function (with $\cos (x) \neq 0)$ Then, we can define these functions for all real numbers, since when we travel $2\pi$ we get back to the initial point. So we defined sine and cosine as periodic functions. Open question : How do I prove, with the unit circle periodic definition and without being circular , the $\sin(a-b)$ and $\cos(a-b)$ formulas? (same for $\sin(a+b)$ and $\cos(a+b)$. Taylor Series definition $$\sin x = \sum^{\infty}_{n=0} \frac{(-1)^n}{(2n+1)!} x^{2n+1}$$
$$\cos x = \sum^{\infty}_{n=0} \frac{(-1)^n}{(2n)!} x^{2n}$$
$$\tan x = \sum^{\infty}_{n=1} \frac{B_{2n} (-4)^n (1-4^n)}{(2n)!} x^{2n-1}$$ Here , in the same question, there's an analytic proof of the trigonometric identites, for these sums. What's the best definition for calculus? Well, in calculus we use trigonometric functions a LOT: in integral substitutions, in series, taylor series (like the ones I showed now), derivatives, convergence tests (like the Euler onde in the basel problem) and other things... All the definitions I see, are kinda circular or not rigorous enough to make me feel good taking some derivatives or integral substitution, because I always care about the domain of these things. So I want to define it very nicely and be able to use all the trigonometric identities. I've seen many geometrical proofs of $\sin(a-b)$, $\sin(a+b)$, $\cos(a-b)$, $\cos(a+b)$ using a right triangle and then suddenly the person starts using this formula for all real numbers. I need a complete definition of the trigonometric functions that works periodically and for all reals. The taylor series definition seems good but they're generated using trigonometric identities that are not yet proven (assuming this definition). ps: I know that I used some primitive words in some definitions, like ' travel ' so I let them in emphasis , but I hope you guys understand. And sorry by the long post, but I needed to do it, because I've never seen a complete definition in any book. Thanks.","['geometry', 'calculus', 'algebra-precalculus']"
779034,Abelian group generators and relations,"(a) Define what it means for an abelian group to be finitely generated .  Explain the terms elementary divisors and rank of $G$ and describe the structure theorem for finitely generated abelian groups. (b) Consider the integral matrix $R:=\left[\begin{array}{cccc}2&2&2&2\\4&4&8&5\\6&12&12&8\\4&10&8&6\end{array}\right]$ . Determine the structure of the abelian group given by generators and relations $$A_r:=\left\langle a_1,a_2,a_3,a_4\mid R\circ a = 0\right\rangle.$$ I know this is a long question, But I am really struggling to find a method online that is clear and can be applied again to another example. I put part a in to give some context of the question but I am pretty happy with the definitions, part b is the problem. A method and answer for part b would be amazing, thanks.","['matrices', 'finite-groups', 'group-theory', 'abelian-groups']"
779042,How would you evaluate $I:=\int_ {0}^{\infty} \frac {\cos(ax)} {(x^2 + b^2)^n} \ \mathrm{d}x$?,Any pointers on how should I start? $$I:=\int_ {0}^{\infty} \frac {\cos(ax)} {(x^2 + b^2)^n} \ \mathrm{d}x$$,['integration']
779057,Conditional probability with Poisson processes,"I'm reading a section on conditional logistic models in which a heterogeneous Poisson process is used to make inferences in disease mapping. Basically, the likelihood of a Poisson process is used to describe the events $\{s\}$ within a spatial region $T$ $$L(\{s\}|\Psi) = \frac{1}{m!}\prod_{i=1}^{m}\lambda(s_{i}|\Psi)\exp\{\Lambda_{T}\} $$ where $\Lambda_{T} = \int_{T}\lambda(u|\Psi)du$. $\lambda(s)$ is called the intensity. This quantity determines the rate of case events (detected cases of disease, for example) and $\Lambda_{T}$ is the intensity over the region $T$. Usually for case events, $\lambda(s|\Psi)$ is given by $\lambda_{0}(s|\Psi_{0})\lambda_{1}(s|\Psi_{1})$ in which $\lambda_{0}(s|\Psi_{0})$ is a ""spatially-varying function of the population at risk of the disease in question"" and $\lambda_{1}(s|\Psi_{1})$  includes appropriate predictors. However, in the case of modeling cases and controls, I don't understand what calculation is performed. I quote the relevant paragraph: When a bivariate realization of cases and controls are available it is
  possible to make conditional inference on this joint realization.
  Define the case events as $s_{i} : i = 1, ..., m$ and the control
  events as $s_i : i = m + 1, ...., N$ where $N = m + n$ the total
  number of events. Associated with each location is a binary variable
  ($y_i$) which labels the event either as a case ($y_i = 1$) or a
  control ($y_i = 0$). Assume also that the point process models
  governing each event type (case or control) is a heterogeneous Poisson
  process with intensity $\lambda(s|ψ)$ for cases and $\lambda_0 (s|ψ_{0})$ for controls. The superposition of the two processes is
  also a heterogeneous Poisson process with intensity $λ_0(s|ψ_0) + λ(s|ψ) = λ_0 (s|ψ_0 )[1+λ_1 (s|ψ_1 )]$. Conditioning on the joint
  realization of these processes, then it is straightforward to derive
  the conditional probability of a case at any location as $$Pr(y_{i}=1) = \frac{λ_0(s_i |ψ_0 )λ_1(s_i |ψ_1 )}{λ_0 (s_i |ψ_0 )[1 + λ_1 (s_i |ψ_1 )]} = p_{i}$$ $$Pr(y_{i}=0) = \frac{1}{1 + λ_1 (s_i |ψ_1)} = 1-p_{i}$$ What is the author calculating in these equations? It seems to be the probability of a case and a control respectively. However, if a Poisson process is modeling each event type, I don't see traces of a Poisson process there. Furthermore, using the previous equations, the likelihood is: $$L(\Psi_{1}|s) = \prod_{i\in \text{cases}}p_{i}\prod_{i\in \text{controls}}(1-p_{i})$$ which seems very reasonable except for the conditioning on $s$ instead of conditioning on the parameters $\Psi$. I would appreciate any help. UPDATE : You can find this section available in Google Books using this link .","['stochastic-processes', 'probability', 'conditional-probability']"
779064,Derived functor vs. spectral sequence,"I heard many times that because of introducing derived category, we can avoid cumbersome spectral sequence. However, I don't quite understand its meaning. Here is a precise example people talking about: Let $f: X \to Y, g: Y \to Z$ be morphism of smooth varieties, and Let $D(X), D(Y), D(Z)$ be derived category of bounded complexes of quasi-coherent sheaves. Then it is said that because of the associativity of derived functor, i.e. $${\rm{R}}f_* \circ {\rm{R}}g_* = {\rm{R}}{(f \circ g)}_*\quad,$$ we can avoid the write the spectral sequence. I don't know which spectral sequence people refer to, and why the associativity of derived functor equivalent to that spectral sequence?","['spectral-sequences', 'homological-algebra', 'algebraic-geometry']"
779067,Is there an upper bound on the number of distinct integer outputs a trig function can have?,"""Usually"" when you plug integers into trig functions you don't get integers as output. I'm interested in trig functions that pass through integer lattice points. Let $f$ be a linear combination of sine and cosine functions. We want to plug integers into $f$ and get integers in return. Here are some examples: $5\cos \left(\frac{2\pi x}{3}\right)+\frac{9}{\sqrt{3}}\sin \left(\frac{2\pi x}{3}\right)$ cycles through the outputs 5, 2, and -7. $5\cos \left(\frac{\pi x}{2}\right)+2\sin \left(\frac{\pi x}{2}\right)$ cycles through the outputs 5, 2, -5, and -2. $5\cos \left(\frac{\pi x}{3}\right)-\frac{1}{\sqrt{3}}\sin \left(\frac{\pi x}{3}\right)$ cycles through the outputs 5, 2, -3, -5, -2, and 3. These examples demonstrate that we can get three, four, and six distinct integer outputs. I'm wondering if we can achieve more than that, particularly if we can produce arbitrarily many distinct integer outputs. Here the sine and cosine functions have the same period, but that does not have to be the case. These integer outputs also came from consecutive integer inputs, but that also does not have to be so. Thank you.","['trigonometry', 'number-theory']"
779082,All finite abelian groups of order 1024,"List all finite abelian groups of order 1024. Attempt: The prime decomposition of 1024 is 1024 = 2^10.
So Z_1024 = Z_2 x Z_512 = Z_2 x Z_2 x Z_256

   = Z_2 x Z_2 x Z_2 x Z_128

   = Z_2 x Z_2 x Z_2 x Z_2 x Z_64

   = Z_2 x Z_2 x Z_2 x Z_2 x Z_2 x Z_32

   = Z_2 x Z_2 x Z_2 x Z_2 x Z_2 x Z_2 x Z_16

   = Z_2 x Z_2 x Z_2 x Z_2 x Z_2 x Z_2 x Z_2 x Z_8

   = Z_2 x Z_2 x Z_2 x Z_2 x Z_2 x Z_2 x Z_2 x Z_2 x Z_4

   = Z_2 x Z_2 x Z_2 x Z_2 x Z_2 x Z_2 x Z_2 x Z_2 x Z_2 x Z_2 Can anyone please help me verify this are all the finite abelian groups of order 1024.
Thank you for the help.","['group-theory', 'abstract-algebra']"
779202,"$G$ an abelian group, $n>1$ a fixed integer, and $\phi :G\to G$ defined by $\phi(a)=a^n$ for $a\in G$. Determine wheter $\phi$ is onto.","$G$ an abelian group, $n>1$ a fixed integer, and $\phi :G\to G$ defined by $\phi(a)=a^n$ for $a\in G$. Determine wheter $\phi$ is onto. I think it totally depends on different situations. $\forall x\in G$,we want to determine whether $x=a^n$ has solutions. But I don't know how to discuss it onto-ness under different circumstances.","['functions', 'group-theory', 'abstract-algebra']"
779211,Is it always possible to get from a set to another inside the universe?,"With an example: We have $C\cap (A\cup B)$. And we want to get to any other ""state"" (I don't know the actual term) by using set theory operations. Say we want to get to the blue area of $(A\cap B - C) \cup (B \cap C - A)$. Is this possible to do, regardless of the combination we might want? Please do tell me if this is too vague or unclear. In few words, is there a finite number of operations that take a state in the universe and take it to any other state?",['elementary-set-theory']
779243,Selection from identical objects - distinction between number of ways and number of outcomes,"The number of ways in which $2$ oranges can be selected from $5$ identical oranges is given by $5 \choose 2$ . In another interpretation, since the oranges are identical , the number of ways is $1$. Is the following explanation correct ? When we say the number of ways in which $2$ oranges can be selected from $5$ identical oranges is $5 \choose 2$, we are referring to number of ways in which the oranges can be taken in groups of $2$. The oranges look identical, but they themselves are distinct. Let's say we assign each orange a number. Then the problem becomes one of choosing two numbers from the set $\{1,2,3,4,5\}$. The answer is $5 \choose 2$. In another interpretation, the answer is $1$. No matter which two oranges we pick, they look identical. But the answer $1$ refers to number of distinct outcomes . In the first situation(# of ways is $5 \choose 2$), we were more concerned with all possible variations in $2$-groupings but the order within the grouping did not matter. Here, we are more concerned with all possible variations in appearance . If those oranges were distinct , then both the answers (# of ways and # of outcomes) would be $5 \choose 2$",['combinatorics']
779248,"Integral $\int_0^\infty \ln x\,\exp\left(-\frac{1+x^4}{2\alpha x^2}\right) \frac{x^4+3\alpha x^2- 1}{x^6}dx$","$$I:=\int_0^\infty \ln x\,\exp\left(-\frac{1+x^4}{2\alpha x^2}\right) \frac{x^4+3\alpha x^2- 1}{x^6}dx=\frac{(1+\alpha)\sqrt{2\alpha^3 \pi}}{2\sqrt[\alpha]e},\qquad \alpha>0.$$ This one looks very nice.  It has stumped me. Differentiation with respect to parameter does not seem to work either if I try $I(\alpha)$ and $I'(\alpha)$. at x=0 there seems to be a problem with the integrand also however I am not sure how to go about using this. Perhaps we could try and use a series expansion for $e^x=\sum_{n=0}^\infty  x^n /n!$, however the function $e^{-1/x^2}$ is well known that its taylor series is zero despite the function not being.","['calculus', 'integration', 'definite-integrals', 'real-analysis', 'complex-analysis']"
779262,Integral$\int_0^{\pi/4} \log \tan \left(\frac{\pi}{4}\pm x\right)\frac{dx}{\tan 2x}=\pm\frac{\pi^2}{16}$,"Hi I am trying to prove $$
\int_0^{\pi/4} \log \tan \left(\frac{\pi}{4}\pm x\right)\frac{dx}{\tan 2x}=\pm\frac{\pi^2}{16}.
$$
What an amazing result and a clever one this is.    I tried writing
$$
\int_0^{\pi/4} \log \sin \left(\frac{\pi}{4}\pm x\right)\frac{dx}{\tan 2x}-\int_0^{\pi/4} \log \cos \left(\frac{\pi}{4}\pm x\right)\frac{dx}{\tan 2x}.
$$
Changing variables $y=2x$ I obtained
$$
\frac{1}{2}\int_0^{\pi/2} \log \sin \left(\frac{\pi}{4}\pm \frac{y}{2}\right)\frac{dy}{\tan y}-\frac{1}{2}\int_0^{\pi/2} \log \cos \left(\frac{\pi}{4}\pm \frac{y}{2}\right)\frac{dy}{\tan y}.
$$
I would rather work with the log sine/cosines for $y\in [0,\pi/2]$ since we can use $\int_0^{\pi/2} \log \sin x dx=-\frac{\pi}{2} \ln 2.$  But I am stuck here.  Thanks","['calculus', 'integration', 'definite-integrals', 'real-analysis', 'complex-analysis']"
779275,Finding singularities of a projective curve,"For $w \in \mathbb{C}$ we define the projective curve
$$p(x,y,z):= x^3+y^3+z^3+wxyz.$$ Now I have to find all $w \in \mathbb{C}$ for which the projective curve $p(x,y,z)$ is singular and show that for this $w$ the curve $p(x,y,z)$ is reducible (and finding the prime factorization).","['projective-space', 'plane-curves', 'complex-analysis', 'projective-geometry']"
779279,"If $f(x)=2x-5$, when $f(x)=13$","If $ \ f(x) = 2x - 5 \ $ , find $ \ x \ $ when $ \ f(x) = 13 \ $. I substituted 13 and got 21, but the answer was 9? Can someone please show me working out for this type of question I'm bad at math!","['algebra-precalculus', 'functions']"
779328,Computing the Fourier transform of the surface measure on $S^2$,"I am almost a beginner in the topics of Fourier transform. So, I am asking this question here. Let $n=3$ and let $\mu_t$ denote surface measure on the sphere $|x|=t$ . Then how do we show that $$
\frac{\text{sin} 2\pi t|\xi|}{2\pi|\xi|}=\frac{1}{4\pi t}\hat{\mu_{t}}(\xi)
$$ where $\hat{\mu_{t}}$ is the Fourier transform of $\mu_t$ .","['fourier-transform', 'measure-theory', 'fourier-analysis', 'real-analysis']"
779351,Prove that the number of subgroups in $D_n = \tau (n) + \sigma (n)$,"Prove that the number of subgroups in $D_n = \tau (n) + \sigma (n)$ where $\tau (n)$ represents number of divisors of $n$ and $\sigma (n)$ represnts the sum of divisors of $n$. Attempt: $D_n = \{e,r,r^2, \cdot \cdot \cdot, r^{n-1},s,rs,r^2s, \cdot \cdot \cdot, r^{n-1}s \}$ Then, $\{e,r,r^2, \cdot \cdot \cdot, r^{n-1}\}$ is a cyclic subgroup of $G$. There are $\tau(n)$ such cyclic subgroups. Total number of subgroups of order $2=n+1$ if $n$ is even and $=n$ if $n$ is odd. Hence, the sum is $\tau(n)+n$ or $\tau(n)+n+1$ Now, let $H$ denote the set of reflections, then if $a=r^is,b=r^js ~\in~H$, then $r^is~ (r^js)^{-1} = (r^is)^{-1}r^js=sr^{-i}r^js=sr^{j-i}s=s^2r^{i-j}=r^{i-j} \notin H$ Hence, the set of reflections cannot form a subgroup in themselves in any case. Now, we must consider sets involving both rotations and reflections and find conditions for them to form subgroups. By Lagrange's theorem, order of such a subgroup $H$ must divide $n$ as we have already found out the total number of subgroups of order $2$ So : (a) A reflection is it's self inverse (b) A reflection times a reflection is always a rotation (c) Inverse of a rotation $r^i = r^{n-i}$ (d) A rotation times a rotation is always a rotation. How do I choose such rotation and reflective elements such that they form a group. Suppose, $|H|=4$, In that case, $H$ should look something like this: $H = \{f_1,f_2,r^i,r^{n-i}\}$ where $f_1,f_2$ are reflections and $f_1f_2=r^i$ How can I extend this to $n$ variables? A hint to move ahead would be really appreciated. Thanks","['dihedral-groups', 'group-theory', 'abstract-algebra']"
779376,Limit of $\frac1n\left(1+\frac1{\sqrt[n]{2}}+\frac1{\sqrt[n]{3}}+\dotsb+\frac1{\sqrt[n]{n}}\right)$ when $n\to\infty$,"Calculate this limit
  $$\lim\limits_{n \to \infty} \frac{1}{n}\left(1+\frac{1}{\sqrt[n]{2}}+\frac{1}{\sqrt[n]{3}}+\dotsb+\frac{1}{\sqrt[n]{n}}\right).$$ I think inside the parentheses, each limit is $1$, and there are $n$ of them, so their sum is limited to $n$. Also, $$\lim\limits_{n \to \infty}\frac{1}{n}=0.$$ Therefore I think,
$$\lim\limits_{n \to \infty} \frac{1}{n}\left(1+\frac{1}{\sqrt[n]{2}}+\frac{1}{\sqrt[n]{3}}+\dotsb+\frac{1}{\sqrt[n]{n}}\right) = 0.$$ Is this solution correct? If so, how to prove it?","['radicals', 'limits', 'analysis']"
779403,Definite integral $\int_{R_0}^{R}\frac{dr}{r^2\sqrt{\frac{R_0-R_S}{R_0^3}-\frac{1}{r^2}\left(1-\frac{R_{s}}{r}\right)}}$,"In general relativity, null geodesics (in the unbounded case) can be written under the following form :
$$\frac{d\varphi}{dr}=\frac{1}{r^2\sqrt{\frac{R_0-R_S}{R_0^3}-\frac{1}{r^2}\left(1-\frac{R_{s}}{r}\right)}}$$
with: $\left(r, \varphi\right)$ the polar coordinates of the photon $R_S$ the Schwarschild radius of the central object ($R_S\in\mathbb{R^{+}_{*}}$) $R_0$ the distance of closest approach ($R_0 > \frac{3\sqrt{3}}{2}R_S$) Consequently, to compute the exact trajectory up to a radius $R$ (with $R > R_0$), one can evaluate:
$$\varphi\left(R\right)=\int_{R_0}^{R}\frac{dr}{r^2\sqrt{\frac{R_0-R_S}{R_0^3}-\frac{1}{r^2}\left(1-\frac{R_{s}}{r}\right)}}$$ And now comes my question : is there an analytical formula (in terms of special functions for example) corresponding to this integral ? (I would like to compute this integral numerically and an expression in terms of special functions would help a lot).","['improper-integrals', 'special-functions', 'integration', 'indefinite-integrals', 'general-relativity']"
779480,Integral inequality $\int_0^{+\infty}|\frac{\sin x}x|^p dx\leq\frac\pi{\sqrt{2p}}$,"$p\geq2$ , then we have $$\int_0^{+\infty}\Bigg|\frac{\sin x}x\Bigg|^p\,\mathrm dx\leq\frac\pi{\sqrt{2p}}$$ I  try to use $\Bigg|\frac{\sin x}x\Bigg|\leq1$ , and $\frac{\sin x}x\geq\frac2\pi(x\in(0,\frac\pi2])$ , but without any progress. Thank you very much for your help","['calculus', 'integration', 'integral-inequality', 'real-analysis', 'analysis']"
779492,Find a continuous function on the reals where $f(x) >0$ and $f'(x) < 0$ and $f''(x) < 0$,"We need to find a function $f(x)$ where $f(x) >0 $and $f'(x) < 0$ and $f''(x) < 0$ where $f$ is continuous for all real numbers. We have tried $ f(x) = \sqrt{-x}$ however this is not defined for $x>0$ and therefore is only continuous where $x<0$. Is there even such a function? Because $f$ is positive but decreasing (...increasingly) Any help is appreciated. 
Thanks.","['continuity', 'calculus', 'derivatives', 'functions']"
779507,Can you give me some concrete examples of magmas?,"I've seen the following (e.g. here ): I've learned a bit about groups and I could give examples of groups, but when reading the given table, I couldn't imagine of what a magma would be. It has no associativity, no identity, no divisibility and no commutativity. I can't imagine what such a thing would be. Can you give a concrete example of a magma?","['examples-counterexamples', 'abstract-algebra', 'magma']"
779541,"To find relatively prime ordered pairs of positive integers $(a,b)$ such that $ \dfrac ab +\dfrac {14b}{9a}$ is an integer","How many ordered pairs $(a,b)$ of positive integers are there such that g.c.d.$(a,b)=1$ , and $ \dfrac ab +\dfrac {14b}{9a}$ is an integer ?","['elementary-number-theory', 'algebra-precalculus', 'divisibility', 'number-theory']"
779546,Can RUBIK's cube be solved using group theory?,"Can RUBIK's cube be solved using group theory? If yes, how can we use it to solve a $2\times2$ Rubiks Cube?","['rubiks-cube', 'group-theory']"
779585,Expected number of spins,"A spinner has 4 sectors of area 10%, 20%, 30% and 40%. What is the expected # of spins for the spinner to stop on each sector at least once ? edit If areas were equal, it'd be 4/4 +4/3 +4/2 +4/1 = 8.33 and with the unequal probabilities above, it'd be > 10 as pointed out by @Hagen, but how do we get the exact value ? edit2 I have already provided some context in the first edit. I am not a mathematician, just a puzzle aficionado, so the simpler the explanation, the better for me.",['probability']
779589,Sample Covariance: divide by n or n-1,"To obtain the sample covariance, does one divide by $n$ or by $n-1$? I have seen both being used. What is the advantage of using $n-1$? Does it make the covariance unbiased? Or is it so that in the formula for the sample correlation the $n-1$ cancels with the $n-1$ used in the formula for the unbiased variance?",['statistics']
779590,Any non-trivial finitely-generated group admits maximal subgroups,"I want to solve the following problem from Dummit & Foote's Abstract Algebra: This is exercise involving Zorn's Lemma (see Appendix I) to prove that every nontrivial finitely generated group possesses maximal subgroups. Let $G$ be a finitely generated group, say $G=\langle g_1,g_2,\dots,g_n \rangle$ , and let $\mathcal{S}$ be the set of all proper subgroups $G$ . Then $\mathcal{S}$ is partially ordered by inclusion. Let $\mathcal{C}$ be a chain in $\mathcal{S}$ . (a) Prove that the union, $H$ , of all the subgroups in $\mathcal{C}$ is a subgroup of $G$ . (b) Prove that $H$ is a proper subgroup. [If not, each $g_i$ must lie in $H$ and so must lie in some element of the chain $\mathcal{C}$ . Use the definition of a chain to arrive at a contradiction.] (c) Use Zorn's Lemma to show that $\mathcal{S}$ has a maximal element (which is, by definition, a maximal subgroup). Here is my attempt at a solution: REMARK: The goal of this exercise is to prove that any chain has an upper bound in $\mathcal{S}$ . It seems that the case of an empty chain needs to be handled separately: The empty chain $\mathcal{C}=\emptyset$ , has any element of $\mathcal{S}$ as an upper bound. From now on, we assume all chains are nonempty. (a) Let $\mathcal{C}$ be a nonempty chain in $\mathcal{S}$ , and let $H=\cup_{K \in \mathcal{C}} K$ . Since $\mathcal{C}$ is nonempty, it contains some subgroup $K_0$ , which has the identity element. Thus $1 \in H$ , so $H \neq \emptyset$ . Suppose $x,y \in H$ then there are subgroups $K_1,K_2 < G$ in $\mathcal{C}$ , such that $x \in K_1,y \in K_2$ . Since $\mathcal{C}$ is a chain we must have either $K_1 \subseteq K_2$ or $K_2 \subseteq K_1$ . Suppose WLOG that $K_1 \subseteq K_2$ . Then both $x,y$ are elements of $K_2$ , and since it's a subgroup we have $xy^{-1} \in K_2 \subseteq H$ . Thus $H$ is a subgroup of $G$ . (b) Suppose, by way of contradiction that $H$ is not a proper subgroup. Then there exist subgroups $K_1,\dots,K_n \in \mathcal{C}$ such that $g_i \in K_i$ for $1 \leq i \leq n$ . As before, it follows from the definition of the chain that one of the subgroups $K_1,K_2$ contains both of $g_1$ and $g_2$ . Similarly one of the subgroups $K_1, \dots, K_n$ must contain all generators $g_1,\dots,g_n$ of $G$ . Suppose WLOG that $K_n$ is that subgroup, we arrive at a contradiction since any element of $G$ may be constructed from the generators, so $K_n=G$ (This is a contradiction, because the elements in the chain are proper subgroups). (c) Combining the previous two parts, we have shown that any (nonempty) chain in $\mathcal{S}$ has an upper bound in $\mathcal{S}$ (the empty case was taken care of in the remark). Thus Zorn's lemma furnishes the existence of a maximal element in $\mathcal{S}$ . By definition this is a proper subgroup $M <G $ , such that if $M \subseteq K$ for any other proper subgroup $K \in \mathcal{S}$ , then $M=K$ . Thus there cannot be any subgroup $K<G$ which is a proper supergroup of $M$ . In other words, $M$ is a maximal subgroup of $G$ . Is my proof correct? Must the case of an empty chain be handled separately? Thank you!","['solution-verification', 'abstract-algebra', 'finitely-generated', 'maximal-subgroup', 'group-theory']"
779593,About Cantor Set And Measure,"Prove that the Cantor ternary set has Jordan content 0. Additionally, prove that the Cantor ternary set has uncountably many points.",['analysis']
779609,Prove the following expansion.,Prove that $${e^{-1} =2(\frac{1}{3!} + \frac{2}{5!} + \frac{3}{7!}  + \frac{4}{9!} ....)}$$. I am unable to solve it. I know I have to solve it using expansion of ${e^x}$.But I am unable to understand the algebraic manipulation that I have to perform to solve it. Please help me. Thank you! :)),['sequences-and-series']
779618,A question about linear subspace and subfield,"If we see the complex numbers $\mathbb{C}$ as a linear space on field $\mathbb{Q}$, then $\mathbb{C}$ is infinite dimensional over $\mathbb{Q}$, $2$-dimensional over $\mathbb{R}$, $1$-dimensional over $\mathbb{C}$ itself. My question: Is there a field $F\subset\mathbb{R}$, $\mathbb{R}$ is $2$-dimensional linear space over $F$?","['linear-algebra', 'extension-field']"
779658,parallel curvature imply constant Ricci and scalar curvature,"$\text{Suppose we have} \nabla R = 0 $, where R represents curvature tensor, Prove that Ricci  curvature and scalar curvature are constant.",['differential-geometry']
779719,Can I flip the integral and sum here?,"I have the convergent integral-sum: $$\int_0^\infty \sum_{n\mathop=0}^\infty \frac {x^{4n+1}} {e^x - 1} \frac {(-1)^n} {(2n)!(4\pi)^{2n}}\mathrm d x$$ But is it the same as this?: $$\sum_{n\mathop=0}^\infty \int_0^\infty \frac {x^{4n+1}} {e^x - 1} \frac {(-1)^n} {(2n)!(4\pi)^{2n}}\mathrm d x$$ We don't look at Fubini or Tonelli's theorems at high school so I'm not confident with it, but I don't believe Tonelli applies here as we have the $(-1)^n$ and I don't think Fubini works either because the absolute value wouldn't converge. Does this mean the integral and sum cannot be interchanged in the above case?","['sequences-and-series', 'integration', 'indefinite-integrals']"
779735,What does $\frac{d^2}{dx^2}$ stands for,I would like to know what is $\frac{d^n}{dx^n}$. I think it stands for dervation of $n-$th order but I am not sure.,"['notation', 'derivatives']"
779757,Roots of irreducible polynomial over finite field,"I have this, and a couple other problems of this kind: For $\mathbb{F}_9=\mathbb{Z}_3[x]/(x^2+1)$, what are the roots of $z^2+1\in\mathbb{F}_9[z]$? I can't figure out, how to start with the solution. Can somebody please guide me through the solution of this problem and/or provide some explanation?","['discrete-mathematics', 'polynomials']"
779759,Integer values of polynomial $a^2+ab-b^2$,"Playing with the polynomial $f(a,b)=a^2+ab-b^2=d$ for a given $d \in \mathbb{Z}$ I found that it has integer solutions $(a,b) \in \mathbb{Z}$ for the following values of $d$: $$D'=\{1,5,11,19,29,31,41,55,59,61,71,79,89,95,\ldots, 209, \ldots\}$$
and also for every $d = k^2\cdot e$, $e \in D'$ and $k \in \mathbb{Z}$. So let $$D := \{d \in \mathbb{N} : f(a,b)=d \text{ has a solution}\}$$ I noticed that $D'$ contains many primes, but $55, 95$ and $209$ are not prime, but they are product of numbers in $D'$. So this lead to my Conjecture : $D$ is multiplicatively closed. I couldn't proove it so far, but this conjecture seemed so clean and simple to me that I thought someone must have discovered it before. So is there any theorem in this direction?","['polynomials', 'number-theory']"
779792,Prove that $|f(z)|\leq |z|^2$ where $f$ is analytic on the unit disc and has a zero of order 2 at zero.,"$f(z)$ is analytic on the unit disk $|z|<1$. If $f(z)$ has a zero of order $2$ at the origin and $|f(z)|\leq 1$ on the disk. Prove that $|f(z)|\leq |z|^2$ when $|z|<1$. What I did: Since $f(z)$ is analytic on the unit disk, so $f(z)$ has the Taylor series representation $\sum a_nz^n$. And since $f(z)$ has a zero of order $2$, $a_0=a_1=0$, so $f(z)=a_2z^2+a_3z^3+......$ Since $|f(z)|\leq1$, so $|f(z)|=|a_2z^2+a_3z^3+......|\leq1$, then I stuck... Please help!
Thanks!",['complex-analysis']
779796,What differential equation might model this almost-harmonic oscillator?,"I need to precisely control the motion of a damped, driven (nearly) harmonic oscillator: $$
\ddot x(t) + \alpha\dot x(t) + \omega_0^2 x(t) \approx V(t)
$$ I use the $\approx$ symbol because this is a real-world system, and I'm convinced this equation of motion is not sufficiently accurate for my needs. Help me determine a more accurate mathematical model! The damping term $\alpha$ is positive, and small compared to the resonant frequency $\omega_0$ (approximately ten oscillations per decay half-time).  I can choose the driving term $V(t)$ arbitrarily, and I can measure $x(t)$ fairly precisely. In order to characterize my oscillator, I measured the impulse response $x(t)$ by setting $V(t)$ to (approximately) a delta function $\delta(t)$. The resulting behavior $x(t)$ fits fairly well to an exponentially decaying sinusoid, as expected : $$
V(t) \approx\propto \delta(t)
$$
$$
x(t) \approx\propto e^{- k t} \sin\,(\omega t )
$$ I use the $\approx\propto$ symbols to express that my input $V(t)$ isn't perfectly proportional to a delta function (it's a square pulse much shorter than the resonant period of the oscillator), and my output $x(t)$ isn't perfectly proportional to a damped sinusoid (but it looks a lot like one over a few tens of oscillations). However, when I checked the impulse response for different impulse strengths, I got a surprise: my oscillator is nonlinear! The plot below shows impulse responses for several different impulse strengths, normalized by the impulse strength: The first cycle of oscillations match fairly closely, but the decay time of my oscillator depends strongly on the impulse strength! For example, changing the impulse strength from $1$ unit to $7$ units increased the decay time by a factor of $\sim 2$. Interestingly, the larger impulses seem to decay into the smaller impulses . The following plot shows the same data as the previous plot, except that the responses are not normalized. Instead, each response is shifted in time until it (approximately) lines up with the other responses: So, my system looks a lot like a damped harmonic oscillator, but the decay rate of the oscillation seems to increase as oscillation amplitude decreases. How should I modify my equation of motion to account for this behavior? What other measurements would be helpful to guide my choice? For example, it seems to me that my measurements are consistent with a damping that increases as velocity decreases:
$$
\ddot x(t) + \alpha\dot x(t) + \beta\dot x(t)|\dot x(t)| + \omega_0^2 x(t) \approx V(t)
$$ but my measurements might also be consistent with a damping that depends on position: $$
\ddot x(t) + \alpha\dot x(t) F(x)+ \omega_0^2 x(t) \approx V(t)
$$ What measurements might help distinguish between these models? I can't change the system resonant frequency or the damping, but I can set $V(t)$ to whatever I want, as long as it doesn't break my oscillator by making $x(t)$ go too large. EDIT: vonbrand asked an excellent question in the comments: What does it matter what the ""right"" model is? I should be more clear about how accurate I need my model to be. I'm trying to achieve a particular output signal $x(t)$ from my oscillator. I wanted to use my measured impulse response to calculate what input signal $V(t)$ would give this output, as illustrated here: I'd like my actual output to match my desired output within a few percent for a few tens of resonant periods. In the small-signal limit, this seemed to be working: (ignore the banding artifact; that's what happens when someone opens the door during the measurement) This is the right shape for $x(t)$, but the wrong amplitude; I want to operate at larger amplitude. When I scale $V(t)$ up to higher values, though, this is what happens: This was actually the first hint that my oscillator was nonlinear, and lead to measuring impulse responses for different impulse strengths.","['ordinary-differential-equations', 'integration', 'partial-differential-equations', 'numerical-methods', 'mathematical-modeling']"
779798,$G\times G\cong H\times H\Longrightarrow G\cong H$ for $G$ ACC and DCC,"I want to prove that, if $G$ satisfies ACC and DCC on normal subgroups, then $G\times G\cong H\times H$ implies $G\cong H$. I observed that if we can prove that $G\times G$ satisfies ACC and DCC the conclusion will follow by Krull-Schmidt. So I tried to see if it's true Let $\pi_1:G\times G\to G$ and $\pi_2:G\times G\to G$ be projection on the first and second summand. Then any $\{e\}\le N_1\le N_2\le\cdots$. Then $\pi_1(N_k)$ and $\pi_2(N_k)$ both stabilize, but I'm not sure if I can conclude that $N_k$ also stabilizes. Is what I am trying to prove in the second paragraph even correct? If not, how do I prove the theorem in the first paragraph?","['group-theory', 'abstract-algebra']"
779805,Show that AB is singular if A is singular,"Actually I need to show that $\det(AB) = \det(A)\det(B)$ if $A$ is a singular matrix. The determinant of $A$ is $0$ if $A$ is singular, so $\det(AB)$ has to be $0$ as well, but I have problems showing that $AB$ is singular if $A$ is singular. How can I show that?","['matrices', 'linear-algebra']"
779813,sequence and series (complex analysis),"Let $N_0\in \mathbb{N}.$ If a sequence of complex numbers $\{F_N\}_{N \in \mathbb{N}}$ has the following properties:
$$\lim_{N \rightarrow \infty} |F_N|^{1/N}=0$$ and for all $N \geq N_0$,
$$|F_N|\leq \sum_{k=N+1}^{\infty} |F_k|,\quad \quad \quad  $$
then there exists $N_1\in \mathbb{N}$ such that $F_N=0$ for all $N \geq N_1.$ I found this argument on a paper but I cannot prove it. Could you please help me or give me an idea? Thank you. Masik",['complex-analysis']
779822,Find bases of Jordan Form for a $3\times 3$ matrix,"Here is my matrix: $A=\begin{bmatrix}
2 &2  &3 \\ 
1 &3  &3 \\ 
-1 &-2  &-2 
\end{bmatrix}.$ And I know that the Jordan form is $J=\begin{bmatrix}
1 &0  &0 \\ 
0 &1  &1 \\ 
0 &0  &1 
\end{bmatrix}.$ I have problems when I try to find the invertible matrix $P$ such that $P^{-1}AP=J.$ Here is my trial: Consider $AP=PJ$: $A\begin{bmatrix}
p_1 &p_2  &p_3 
\end{bmatrix}=\begin{bmatrix}
p_1 &p_2  &p_3 
\end{bmatrix}\begin{bmatrix}
1 &0  &0 \\ 
0 &1  &1 \\ 
0 &0  &1 
\end{bmatrix}=\begin{bmatrix}
p_1 &p_2  &p_2+p_3 
\end{bmatrix}.$ Then, we have $(A-I)p_1=0, (A-I)p_2=0$ and $(A-I)p_2=p_3$. Then, I try to consider $$A-I=\begin{bmatrix}
1 &2  &3  \\ 
0 & 0& 0  \\ 
 0& 0 &0   
\end{bmatrix}.$$ I know that $(-2,1,0)^T$ and $(-3,0,1)^T$ are two linearly independent vectors corresponding to the eigenvalue 1. (I do now know I should do this step or not...) I have stuck for the whole days to compute different bases for different Jordan canonical form of matrices but I do not get a standard way to finish them. I am frustrated and could anyone give me a hand to do a step by step calculation for this example? Thank you so much.",['matrices']
779874,A problem related to Schwarz reflection principle,"Let $\Omega$ be a bounded domain in $\mathbb{C}$. Suppose there is a function $f$ which is analytic in $\Omega$ except a simple pole at $a\in\Omega$, such that $(z-a)f(z)$ is continuous on $\bar{\Omega}$ with $f(z)=\bar{z}$ on $\partial\Omega$. Prove that the function $g(z)=(z-a)f(z)-(z-a)\bar{a}$ is constant. What is $\Omega$? It should be consistent with the problem if we assume $\Omega$ to be the unit disc $\mathbb{D}$, then we may use the reflection principle with respect to $\mathbb{D}$ to extend $g$ to an entire function and then conclude using the Liouville theorem that $g$ is a constant. But how can we see that this is the most general case that can happen?",['complex-analysis']
779879,"systematic way of finding the bounds for change of variables (multivariable case), Jacobian","Let's say that $X,Y$ are independent standard normal random variables. I am interested in the distribution $P(X+Y\le 2t)$. Clearly, the domain of integration in this case is $-\infty<x<\infty$ and $-\infty<y\le 2t-x.$ If I were to introduce a change of variables $u=\frac{1}{2}(x+y)$ and $v=\frac{1}{2}(x-y)$, how can I systematically determine the domain of integration for $u,v$? From the looks of it, clearly $u\le t$. And judging from the values of $x,y$, $-\infty < u \le t$ and $-\infty <v<\infty.$ But this was merely obtained by looking at the values of $x$ and $y$. How would I know that the region of integration on the $uv$-plane would have, for instance, the bounds on $v$ being a function of $u$?","['multivariable-calculus', 'probability-distributions', 'calculus', 'probability']"
779899,Recurrence Relation all general solutions [duplicate],"This question already has answers here : How to show all solutions for a particular recurrence solution (2 answers) Closed last year . I need some help solving the following recurrence relation: $a_n = 4a_{n-1} - 4a_{n-2} + (n+1)*2^n$ What I've tried: a) Find the general solution of the associated linear homogenous recurrence relation. I got this general solution : $a^{(H)}_n = \alpha_1*2^n + \alpha_2*n*2^n $ b) Guess the particular solution. This is the step I'm confused in. Seeing some other examples, I believe a correct guess would be $n^2*(p_1*n + p_0)*2^n$. To get all the solutions I would have to put this particular solution equation into the original recurrence relation. This way I get a very complex equation. I think either I'm doing this incorrectly or I'm making it too complicated. Is there a better and more intuitive way to solve such recurrence relations?","['recurrence-relations', 'discrete-mathematics']"
779911,"Assuming that A and B are non-empty, if there is an injective function F : A -> B then there must exist a surjective function g : B -> A","Either give a counter-example, or a proof. A question in my proofs review. From what I understand we must assume each element of A is carried to a unique element of B (i.e. every value of A is associated with a unique value of B when punched into F). We now must prove (or disprove by use of counter-example) that there always exists a surjective function G that carries B -> A.  Surjectivity (from what I understand) means that EVERY element of A (in this case) has AT LEAST one associated B value in terms of the function G. Will anybody be kind enough to correct any misunderstandings that I may have?
Also, I can't really figure out where to begin with this question, help needed!","['elementary-set-theory', 'functions']"
779918,solving a non-linear (trigonometric) system of equations with two equations and two variables,"I'm trying to solve the following system of equations: $$l_1 \sin(\alpha) = l_2 \cos(\gamma) + l_3 \sin(\beta)$$ $$l_2 \sin(\gamma) + l_1 \cos(\alpha)=l_3 \cos(\beta) + l_4$$ with the unknowns $\beta, \gamma \in \Bbb R⁺$, the constants $l_1$, ..., $l_4$ $\in$ $\Bbb R⁺$ and the(known) variable $\alpha \in [0,\pi]$. What I need is a function $\beta(\alpha)$. $\gamma$ is not of any importance to me. I tried solving this system of equations with Maxima (software), but I don't get any results: declare(l_1,real);
assume(l_1>=0);
declare(l_2,real);
assume(l_2>=0);
declare(l_3,real);
assume(l_3>=0);
declare(l_4,real);
assume(l_4>=0);
declare(A,real);
assume(A>=0, A<=%pi);
declare(B,real);
assume(B>=0);
declare(G,real);
assume(G>=0);

eq1: l_1*sin(A)=l_2*cos(G)+l_3*sin(B);
eq2: l_2*sin(G)+l_1*cos(A)=l_3*cos(B)+l_4;

solve([eq1, eq2], [B, G]);
[] Does anybody know how to solve this, so that I end up with a function $\beta(\alpha)$?
Thanks for your help!","['trigonometry', 'maxima-software', 'systems-of-equations', 'nonlinear-system']"
779946,Sine and cosine expression,"Find the greatest possible value of $5\cos x + 6\sin x$. I attempted to solve this using graphing, however, the answer appears to be an ugly irrational. Is there a better method of solving this problem? Thank you.",['algebra-precalculus']
779987,Gradient and Swiftest Ascent,"I want to understand intuitively why it is that the gradient gives the direction of steepest ascent. (I will consider the case of $f:\mathbb{R}^2\to\mathbb{R}$) The standard proof is to note that the directional derivative is $$D_vf=v\cdot \nabla f=|\nabla f|\,\cos\theta$$ which is maximized at $\theta=0$. This is a good verification, but it doesn't really help me understand the result.","['optimization', 'multivariable-calculus', 'intuition']"
779988,Matrix multiplication makes zero to specific elements,"I have this matrix $A = \pmatrix{3&2&5\\ 1&2&3\\ 2&3&5\\ 1&3&4}$.
I want to multiply this matrix by another one, say $M$, which must have its diagonal elements = 1 , and the result must be: $MA = \pmatrix{3&2&5\\ 1&0&3\\ 2&0&5\\ 1&0&4}$. Should I multiply the inv(A)x(result_matrix) to get the matrix $M$ or is there any other procedure? Thanks in advance.","['matrices', 'linear-algebra']"
780006,Why is $\Bbb Z_2 \times \Bbb Z_4$ not isomorphic to $\Bbb Z_8$?,$\Bbb Z_2 \times \Bbb Z_4$ has 8 elements and obviously so does $\Bbb Z_8$. How do you conclude they are not isomorphic then? They essentially have a $1-1$ relationship.,"['group-isomorphism', 'group-theory', 'abstract-algebra']"
780013,"If $f$ differs from a uniformly continuous function by less than $\epsilon$ for any $\epsilon$, then $f$ is uniformly continuous","For any $\epsilon>0$ there exists a function $g$, such that $g$ is uniformly continuous and $|f(x)-g(x)|<\epsilon$. Show that $f$ is uniformly continuous. I know that I will have to use the definition of a function being uniformly continuous for the function $g$. 
$|x-x_0| < \delta$ implying $|g(x)-g(x_0)|<\epsilon$.","['functions', 'real-analysis', 'uniform-continuity']"
780043,Prove that the union of two disjoint countable sets is countable,"This is a question from my proofs course review list that I have had trouble understanding. I understand the concept of disjoint sets.  I'm not sure what they mean by countable. How would one prove a set is countable and furthermore, that the union of two countable sets is countable. Please help me get started with the question by understanding this concept.",['elementary-set-theory']
780097,The meaning of $\lambda$ in Lagrange Multipliers,"This is related to two previous questions which I asked about the history of Lagrange Multipliers and intuition behind the gradient giving the direction of steepest ascent. I am wondering if the constant $\lambda$ in the Lagrange equation $$\nabla f=\lambda \nabla g$$ has any significance. For instance, can the sign of $\lambda$ tell us anything about the nature of the critical point? Does its magnitude have any significance?","['optimization', 'multivariable-calculus', 'lagrange-multiplier']"
780103,Double integral definition,"I don't understand the definition of double integral. For instance in the functions with single variable the definite integral was defined as Riemannian sum as: $$\lim_{n\to\infty}\sum_{k=1}^{n} f(c_k)\delta x_k$$ In which I could assume $f(c_k)$ as the height and $\delta x_k$ as the width of the rectangles we're going to calculate the sum of but for the double integration in the region $R$ we've got the definition:
$$\lim_{\delta A\to\infty}\sum_{k=1}^{n}f(x_k,y_k)\delta A_k $$
Now I can assume the $\delta A$ to be the surface of small rectangles which cover the region $R$.Then what $f(x_k,y_k)$ supposed to be?
I'm trying to learn by analogy that $f(c_k)$ was assumed to be the height but now what is the $f(x_k,y_k)$ supposed to be in the double integral definition? Thanks in advance P.S: Notice that I'm trying to find out what $f(x_k,y_k)$ tries to represent when we're trying to find the surface of region $R$ not the volume !","['definite-integrals', 'multivariable-calculus', 'integration']"
780128,Calculating the residues of $\frac{\zeta^{\prime}{(s) x^{s}}}{\zeta(s)\cdot s}$,"Calculating the poles of $\frac{\zeta^{\prime}{(s) x^{s}}}{\zeta(s)\cdot s}$, where x is a fixed real number. I am trying to calculate the poles of this function at the trivial zeros of $\zeta$, namely the even negative integers. To do so I image one looks at $\lim_{s \to \ -2k} \frac{(s+2k)\zeta^{\prime}{(s) x^{s}}}{\zeta(s)\cdot s}$ but I have trouble when evaluating the $\zeta^{\prime}$ at $-2k$. Is my strategy bad or am I able to calculate $\zeta^{\prime}(-2k)$ for every k? I suspect the value to be 1. This is almost exactly the same question, but no satisfying answer has been given.","['residue-calculus', 'riemann-zeta', 'complex-analysis']"
780158,Derivation 9.97 in Jaynes' Probability Theory,"In page 298 of Jaynes' Probability Theory: the Logic of Science, equation (9.97), Jaynes says: We expect that, if hypothesis $H$ is true, then $n_k$ will be close to $np_k$ , in the sense that the difference $|n_k-np_k|$ will grow with $n$ only as $\sqrt n$ . Call this 'condition A'. Then using the expansion $\log(x) = (x-1)-(x-1)^2/2+...$ , we find that $$\sum_{k=1}^mn_k\log\left[\frac{n_k}{np_k}\right] = \frac 1 2\sum_k\frac{(n_k-np_k)^2}{np_k} + O\left(\frac 1 {\sqrt n}\right)$$ In the above, $\sum_kp_k = 1$ and $\sum_kn_k=n$ , where $n$ is the total number of trials in a series of Bernoulli trials and $n_k$ is the number of trials that had outcome $k$ . I'd like to know how he got from that expansion to the quoted equation, especially given that the squared term in the expansion has negative sign. --EDIT to add info-- Jaynes' nomenclature confused me a bit. He calls hypotheses of the type ""there are $m$ possible outcomes of an experiment, each being observed with probability $p_k$ independent of previous or future repetitions of that experiment"" the ""Bernoulli class."" $n_k$ is the number of performed experiments that had outcome $k$ , $n$ is the total number of experiments performed. But that is all that's defined by Jaynes, and all that's known about the hypotheses. (A thought occurs: what if Jaynes meant that condition A is that $|n_k -np_k| \approx O(1/\sqrt n)$ ? I haven't explored this possibility to know whether it makes sense.)","['probability-theory', 'calculus', 'probability', 'taylor-expansion']"
780160,Inverse of this $3\times 3$ matrix using the Cayley–Hamilton theorem,"Find the inverse of the matrix $$\begin{pmatrix} -1 & 2& 0
\\ 1& 1 &0 \\ 2 & -1& 2 \end{pmatrix}$$ using the Cayley–Hamilton theorem. Thanks!","['matrices', 'linear-algebra', 'inverse']"
780170,How can a function have an antiderivative that can't be written?,"If a function's integral can't be written, then how can we find exact values for it over areas? Can we only ever estimate it? Why can't we make new functions to define these strange unwritable anti-derivatives?","['calculus', 'integration', 'indefinite-integrals']"
780198,How do you estimate the mean of a Poisson distribution from data?,"I have thought of three different approaches for estimating the mean for a Poisson, but I am not sure which one is the correct method to estimate it (the third one is documented separately at the end of the question). For the sake of a concrete example, say that we want to find the Poisson distribution for the number of cars passing by in an hour (in front of our house or whatever). Say that we want to estimate this by standing outside of hours house for $t$ hours and counting the number $n$ of cars we saw. Then we could approximate the mean $\lambda$ as: $$\lambda \approx \frac{n}{t}$$ where $\lambda$ is the mean number of cars that we see per hour. That is first approach (which is the one I believe is the correct one). (note: that I know the first one is easier to do in real life for the specific example, but I am not concerned with that, I am concerned with the mathematical correctness) The second approach is the following approach. Instead imagine that for some reason we are only allowed to record how long it takes us to see 1 single specific car. We record how long it took to see car i as $\tau_i$ (hours). Now we could estimate how many cars we see expect to see in 1 hour by doing: $$ \lambda_i \approx \frac{1}{\tau_i}$$ [note that if $\tau_i < 1$, then we can have an mean value of seeing a car for an hour to be > 1] So now, say that instead we choose to do this on independent days and we took k of these time periods $\tau_i$ and instead we estimated the ""global"" mean by doing a average of the means: $$\lambda = \frac{1}{k}\sum^{k}_{i=1} \lambda_i = \frac{1}{k}\sum^{k}_{i=1} \frac{1}{\tau_i}$$ The second method might seem a little strange, but I was wondering if the two method where actually equivalent somehow, or if the second one was completely wrong and I why. The first one seems to be the correct one but I can't seem to ""prove"" to myself why my intuition says that. [notice that the second method has an interesting property where we can instead of weighting all of them equally, we can do a weighted average to maybe insert the intuitive concept of which $\tau_i$ we trust more for our certain application. A little tangential to my original question, but an interesting thought...] Bounty Section I forgot to add this the first time I asked the question and thought it was important to add it now (since this was the reason my question came up in the first place!). I have a different method for estimating the mean and was wondering if it was correct. Instead of waiting outside for t minutes, what if you did the following. You waited outside and recored how much time it took to see 1 car. Let $\tau_i$ be amount of time you waited to see the ith car. However, notice that after you see a car, you stop your stop-watch and later (maybe on another day), you restart your watch waiting to see the next occurrence of a single car (otherwise, if you you just stop your stop-watch and re-start it immediately, its just the same as the original MLE estimator I was asking about), and you obviously repeat this a but of times. In fact, assume you do this $n$ times (i.e. you see n cars and record how long it took to see each one). Then instead of doing my previous method of $\frac{1}{\tau_i}$, you instead try to do something similar to the first maximum likelihood method by doing the following: $$\lambda \approx \frac{n}{t} = \frac{n}{\sum^{n}_{i=1} \tau_i}$$ where t is the total time it took you to see n cars. But this time these cars were seen by n independent ""samples"". It feels that this method might not be correct but I was not sure. Is there something about necessarily having the total time interval t happen in one consecutive time interval?","['statistics', 'probability-distributions', 'probability']"
780207,Cartier divisors and global sections,"I have a brief question - I seem to have a vague recollection that if we have a Cartier divisor $D$ on a scheme $X$ , then we can determine whether $D$ is effective by saying whether $\mathcal{O}_X(D)$ has a global section or not. I have tried to prove this fact, but can't seem to do it (is it true?) . If anyone could confirm / deny this I would be very happy, and I would also be glad if someone could give me a reference or a proof of the fact! Sincerely Tedar",['algebraic-geometry']
780226,"Exercise, measure theory","I need help with this exercise: This exercise is in a chapter where I learn the monotone convergence theorem and Fatous lemma, so I assume I shall use them. Since $\textbf{1}_Ef_n\rightarrow \textbf{1}_Ef$, this exercise would have been very easy if the sequences were increasing, sadly they are not. Using Fatou's lemma I get: $\liminf_{n \rightarrow \infty} \int_Ef_nd\mu \ge \int\liminf_{n \rightarrow \infty}\textbf{1}_Ef_n d\mu=\int_Ef d\mu$. If I could get another with lim sup, I would maybe be able to be done. Another problem is that since the $f_n$'s may not be increasing, I do not really know that: $lim_{n \rightarrow \infty}\int_Ef_nd\mu$ even exist?, because this sequence may not even be monotone? I guess I should use the part where the entire integral is less than infinity. But I do not really see how to use it. I guess this tells me that the function is finite a.e., but how does that help?",['measure-theory']
780247,In probability notation: what does a tilde over a letter mean?,I am reading this paper. In section 1.1 he says: What do the tildes above the letters mean? How can I translate these two sentences into ordinary English?,"['notation', 'probability']"
780254,A tricky integral,"I'm trying to find the exact value of $$\int_{\frac{1}{\sqrt{3}}}^{\sqrt{3}} \frac{\arctan{(x^2)} }{1+x^2} \, dx$$ Ostensibly, I'd want to use this: $$\frac{d}{dx}\arctan{(x)}=\frac{1}{1+x^2}$$ But either I'm missing something, or this doesn't work out nicely ...","['definite-integrals', 'trigonometry', 'calculus', 'integration']"
780255,Tricky Integral equation - where to start?,"How would you go about solving this?
$$p(x,t)=C\exp\left[-x+\int_0^t\int_0^\infty y\,p(y,\tau)\,\mathrm{d}y\,\mathrm{d}\tau\right]$$ Here $p(x,t)$ is the time-dependent probability distribution of a variable $x$, so it should be normalized to 1, and positive everywhere. Also, we have the initial condition:
$$p(x,0) = \exp\left[-x\right]$$ I hit across this equation in some work I'm doing, and I'm stuck. Don't know enough about integral equations to know where to begin. Is there any hope at all to solve this?
Where would you start?","['improper-integrals', 'ordinary-differential-equations', 'integral-equations', 'problem-solving']"
780276,Primitive Pythagorean triples,"Prove that if $x = 2uv$ and $y = u^2 - v^2$, show that $(x, y, z)$ is a primitive Pythagorean triple if and only if $\gcd(u, v) = 1$. The direction $\gcd(u, v) \neq 1$ implies $(x, y, z)$ is a non-primitive Pythagorean triple – this is straightforward. But I need the converse too, for which I'm completely stumped.","['pythagorean-triples', 'number-theory']"
780299,Proving derivative of $e^x$ and $\ln x$,"If we define the number $e$ as $$e:=\lim_{n\to\infty}\left(1+{1\over n}\right)^n$$ then the only way I know to prove the derivatives of $e^x$ and it's inverse is to write $$\frac{\ln(x+h)-\ln x}{h}={1\over h}\ln\frac{x+h}{x}=\ln\left[\left(1+{h\over x}\right)^{1/h}\right]$$ and with some limit manipulations this can be shown to converge as $h\to 0$ to $$\ln(e^{1/x})={1\over x}$$ Now using the formula for the derivative of the inverse, $$\frac{d}{dx}e^x=\frac{1}{1/e^x}=e^x$$ Is there a way to get the derivative of $e^x$ directly from the definition of $e$ given above?","['calculus', 'derivatives']"
780320,Endomorphisms of direct sum and division ring,"How to prove that 
  $$\operatorname{End}_R(V^{ \oplus n }) \cong M_n(D),$$ where $V$ is a simple left $R$-module and $D=\operatorname{End}_R(V)$. This is part of the proof finally leads to prove that ring is simple and left semi-simple if and only if it is isomorphic to $M_n(D)$ for some division ring $D$, and what's already been proved is that $End_R(V \oplus W) \cong End_R(V) \oplus End_R(W)$ and its corollary.","['noncommutative-algebra', 'division-algebras', 'ring-theory', 'abstract-algebra', 'modules']"
780329,Finding rational points on a non-trivial algebraic curve,"The curve in question is defined as the set of all points $(x,y)$ where both $x$ and $y$ are in $(0,1)$, and that satisfy the following: $$ \left( x^4 - 6 x^2 + 1 \right)  \left( y^4-6y^2+1
 \right) -64 x^2 y^2 = 0$$ I do not know how I could identify even a single rational point on this curve, let alone others. Any assistance would be appreciated.","['elementary-number-theory', 'number-theory']"
780332,Integration by parts of $\varphi \cdot \operatorname{curl}(u)$,"Does anybody happen to know the integration by parts formula for $\iint(\varphi\cdot \operatorname{curl}(u) dV)$, where both $\varphi$ and $u$ are 3D vectors? Is there a good reference for similar formulae? The ""intuitive"" solution would be $$\iint\varphi\cdot \operatorname{curl}(u) dV = \oint (\varphi \times u) \cdot dS - \iint \operatorname{curl}(\varphi) \cdot u dV$$ but this doesn't seem to quite work.","['multivariable-calculus', 'calculus', 'integration']"
780375,Are these 2 functions equivalent?,"Say, $f(x) = \dfrac{x-1}{x^2-1}$ and $g(x) = \dfrac{1}{x+1}$. Does $f = g$? I can reduce $f(x)$ to $g(x)$ but my textbook says they are not equal, can someone please explain to me why?","['algebra-precalculus', 'functions']"
780394,Probability of rolling the first 6 on an even throw?,"I came across this question and I wasn't sure how to approach it. The question says basically roll a die, what's the probability you get the first 6 on an even throw? I.e., the 2nd, 4th, 6, 8th, etc. die throw. Part of my issue is that obviously you never know when it may come. Here's my guess: The probability of you getting a 6 on your $n$th  throw is: $$\left(\frac{5}{6}\right)^{n-1}\cdot\frac{1}{6}$$ Now we want to solve when $n=2k$ where $k$ is a natural number which gives us: $$\left(\frac{5}{6}\right)^{2k-1}\cdot\frac{1}{6}=\left(\frac{5}{6}\right)^{2k}\cdot\left(\frac{5}{6}\right)^{-1}\cdot\frac{1}{6}$$ The obvious guess is $\frac12$, since it seems it would be equally likely to fall on an even vs. odd, though odd should have an edge since the number of odd rolls are always greater than or equal to the even throws, but unsure. $$=\left(\frac{5}{6}\right)^{2k}\cdot\frac{1}{5}=\left(\frac{25}{36}\right)^{k}\cdot\frac{1}{5}$$ This point I have no idea how to proceed, have I been doing this right so far? What's the next step?","['probability-theory', 'probability']"
780399,Geometric intuition behind subspaces in $\mathbb C^n$,"While learning elementary linear algebra one develops a great deal of geometric intuition in $\mathbb R^n$. It helps to see the forest for the trees and leads through proofs. After meeting complexification , I've realized that my old intuition doesn't seem to work in $\mathbb C^n$. For example, if $U$ is a subspace of $\mathbb C^n$, what is $\bar U$? In what relation is it to $U$? Etc. Is there a handy way you think about $\mathbb C^n$?","['vector-spaces', 'linear-algebra', 'visualization', 'complex-numbers', 'intuition']"
780417,GCD function and relation between Hurwitz and Riemann zeta function,"Does anyone know how to show the following: $\sum_{k=1}^n\gcd(n,k)\zeta(s,\frac{k}{n})=\left(\sum_{k=1}^n\gcd(n,k)\right)\zeta(s)$","['zeta-functions', 'number-theory']"
780423,$\left\{x\in H: 2\leq \|x\|\leq 5\right\}$ is compact?,"In a Hilbert space $H$ of dimention infinite, $A=\left\{x\in H:2\leq \|x\|\leq 5\right\}$ is compact? (totally bounded and complete)
Thanks in advance.","['normed-spaces', 'hilbert-spaces', 'compactness', 'analysis']"
780427,How find this integral $\int\frac{\sin{x}}{\sqrt{2}+\sin{x}+\cos{x}}dx$,"Find the  integral 
$$\int\dfrac{\sin x}{\sqrt{2}+\sin x+\cos x} \, dx$$ My idea: since
$$\sin x+\cos x=\sqrt{2}\sin(x+\dfrac{\pi}{4})$$
so $$\int\dfrac{\sin x}{\sqrt{2}+\sin x +\cos x} \, dx=\int\dfrac{\sin x}{\sqrt{2}(1+\sin (x+\dfrac{\pi}{4})} \, dx$$
But then I don't know how to continue. Thank you",['integration']
780486,How prove $\left(\sum\cos{\frac{2k-1}{p}\pi}\right)\cdot\left(\sum\cos{\frac{2k-1}{p}\pi}\right)$,"Question:let $p$ be an odd prime number,let $A$ be the set of the (postive and less than $p$) quadratic residues modulo $p$,and $B$ be the set of the (positive and less than $p$ quadraric non-residues modulo $p$, if we let $$p=4t+1$$
  prove or disprove 
  $$\left(\sum_{1\le k\le 2t,(2k-1)\in A}\cos{\dfrac{2k-1}{p}\pi}\right)\cdot\left(\sum_{1\le k\le 2t,(2k-1)\in B}\cos{\dfrac{2k-1}{p}\pi}\right)=-\dfrac{t}{4}$$ This problem is my found,because I know prove this follow (1):$p=5,t=1,$
$$\left(\cos{\dfrac{\pi}{5}}\right)\cdot\left(\cos{\dfrac{3\pi}{5}}\right)=-\dfrac{1}{2}$$ (2):$p=13,t=3$
$$\left(\cos{\dfrac{3\pi}{13}}+\cos{\dfrac{9\pi}{13}}+\cos{\dfrac{\pi}{13}}\right)
\cdot\left(\cos{\dfrac{7\pi}{13}}+\cos{\dfrac{11\pi}{13}}+\cos{\dfrac{5\pi}{13}}\right)=
-\dfrac{3}{4}$$
and so on,and I use computer  to have this: maybe this is true,and How prove it? Thank you","['trigonometry', 'summation', 'triangulation']"
780487,Evaluation of finite sum,How can one prove the following equality (for fixed positive integer $a$): $$12\sum_{k=1}^{an^2-1}k\left\{\frac{k(an-1)}{an^2}\right\}=3a^2n^4-a^2n^2-2$$ where $\{x\}=x-\lfloor x\rfloor$ denotes the fractional part operator.,"['summation', 'number-theory']"
780491,Does adding two linear equations will result in a line which will pass through an intersection of the linear equations?,I was wondering why it is almost impossible to find a geometrical explanation of why adding two linear equations helps us to find a solution of a system of linear equations? Am I right that adding two linear equations will result in an equation of a line which will pass through a point where two linear equations intersect? If it is right then I completely don't understand why such a crucial point in understanding how to solve systems of equations is never properly taught even at a university level.,"['linear-algebra', 'systems-of-equations']"
780504,What's wrong with the classical Cauchy construction of the reals?,"I am reading Bishop's ""Constructive Analysis"" and he says that defining a real number to just be an equivalence class of Cauchy sequences of rationals would be wrong.  Why is that?","['cauchy-sequences', 'constructive-mathematics', 'real-analysis', 'analysis']"
780535,Probability of rolling 3 sixes in 6 rolls [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question I roll a die six times. What is the probability of rolling at least 3 sixes? Please share the formula as well, so I can figure it out myself in future.","['dice', 'probability']"
780539,Minimum Modulus Principle for a constant fuction in a simple closed curve,"Suppose that $f$ is analytic on a domain $D$, which contains a simple closed curve $\gamma$ and the inside of $\gamma$. If $|f|$ is constant on $\gamma$, then I want to prove that either $f$ is constant or $f$ has a zero inside $\gamma$ Here is my take:
if $f$ is constant, i dont see a reason why $|f|$ wouldnt be constant :) if $f$ is not constant, then the max/min modulus principle applies ...
meaning $|f|$ can not have any local max/min on D
now i am lost at this point ...","['maximum-principle', 'roots', 'proof-writing', 'complex-analysis']"
780554,Subgroups of order $p^2$ present in a abelian group,How many subgroups of order $p^2$ does the abelian group $\mathbb{Z_{p^3}} \times \mathbb{Z_{p^2}}$have ?,"['group-theory', 'abelian-groups', 'direct-product']"
780591,How to make a smart guess for this ODE,"I am dealing with a strange problem currently, we have a differential equation 
$$y(x)^2 = \pm \sqrt{-A \cos(x) - B \cos^2(x)+y'(x)-C},$$ where $C, A$ and $B $ are parameters.
(The case that either $A$ or $B$ is zero is not interesting to me as these solutions are well-studied in the literature). So the idea of $C$ is to be some kind of adjustment variable, which means that I don't care about its value and it's only purpose is to make it easier to find solutions. Now my question is: Is there a smart way to do this so that I get a wide range of solutions and is there even a solution for all different kinds of $A $ and $B$, because I am particularly interested in having a free choice in these two paramters?
But even if you are able to suggest a better guess to me that gives me more solutions, this would be tremendously helpful! Somehow I don't have much experience with differential equation and making this guess the way I did it, is probably not very sophisticated so I would be highly interested in hearing about better methods to do this. (Probably, if anybody here would tell me that he is able to solve this would remedy all my troubles, but I doubt that it is possible ;-))","['dynamical-systems', 'ordinary-differential-equations', 'calculus', 'real-analysis', 'analysis']"
780655,How to prove the inequalities $\int_{0}^{1}\sin{(x^n)}dx\ge\int_{0}^{1}(\sin x)^ndx\ge 0$,"Show that:
  $$\int_{0}^{1}\sin{(x^n)}dx\ge\int_{0}^{1}(\sin x)^ndx\ge 0$$ My idea:maybe $\sin{(x^n)}\ge (\sin{x})^n？$","['integration', 'integral-inequality']"
780670,Continuous functions mapping subgroups of R to subgroups of R,"My question is simple to state: Suppose that $f:\mathbb{R}\rightarrow\mathbb{R}$ is continuous and has the property that $f[G]$ (the image of $G$ under $f$) is a subgroup of $\mathbb{R}$ for every subgroup $G$ of $\mathbb{R}$. Must $f$ be an endomorphism of $(\mathbb{R},+)$? In other words, is it true that $f(x)=ax$ for some real number $a$ (recall that $f$ is assumed continuous)?","['group-theory', 'real-analysis']"
780693,"Convex , then also Measurable","I was reading about Jensen's inequality and noticed that don't require $\phi$ to be measurable here: Wikipedia link . Therefore, I guess that being convex implies being measurable somehow, but I have never actually seen this and this is why I wanted to ask here if this is true?","['calculus', 'measure-theory', 'real-analysis', 'lebesgue-integral', 'lebesgue-measure']"
780715,Do line integrals along non-piecewise-smooth curves exist?,"This article at Wolfram Mathworld has the following theorem on conservative vector fields: Theorem. The following conditions are equivalent for a conservative vector field $ \mathbf{F} $ defined on an open subset $ U $ of $ \mathbb{R}^{n} $ : For any oriented, simple and closed curve $ C $ whose image lies in $ U $ , the contour integral of $ \mathbf{F} $ along $ C $ equals $ 0 $ , i.e., $ \displaystyle \oint_{C} \mathbf{F} \cdot \mathrm{d}{\mathbf{s}} = 0 $ . For any two oriented and simple curves $ C_{1} $ and $ C_{2} $ with the same endpoints whose images lie in $ U $ , we have $ \displaystyle \int_{C_{1}} \mathbf{F} \cdot \mathrm{d}{\mathbf{s}} = \int_{C_{2}} \mathbf{F} \cdot \mathrm{d}{\mathbf{s}} $ . There exists a differentiable function $ f: U \to \mathbb{R} $ , called the scalar potential function of $ \mathbf{F} $ , such that $ \mathbf{F} = \nabla f $ . However, I have read in other places that the curves $ C $ , $ C_{1} $ and $ C_{2} $ must be piecewise smooth . It seems like a necessary restriction on otherwise arbitrary curves. Hence, my question is: Question. Is the theorem valid for non-piecewise-smooth curves? What about non-piecewise-differentiable curves? I think that the line integral might not be defined then.","['curves', 'vector-fields', 'differential-geometry', 'plane-curves', 'vector-analysis']"
780729,Applications of Stein spaces in Algebraic Geometry,"I want to know where are essential applications of the theory of Stein spaces in algebraic geometry. I heard Cartan's theorem A & B were used in Serre's GAGA, but are there any other applications?","['analytic-geometry', 'algebraic-geometry', 'complex-analysis']"
780747,Approximating the erf function,"I was trying to find an approximate solution to the following: $\DeclareMathOperator\erf{erf}$ $$\frac12 \sqrt{\pi}  \erf\left (\frac{x-2}{\sqrt{10}}\right) + \frac12 \sqrt{\pi} \erf \left(\frac{x+2}{\sqrt{10}}\right) = \frac25 \sqrt{\pi}$$ This naturally equals $$\int_0^{\frac{x-2}{\sqrt{10}}} e^{-t^2} dt+ \int_0^{\frac{x+2}{\sqrt{10}}} e^{-t^2} dt = \frac25 \sqrt\pi$$ What I tried then was to use the taylor approximation and then solve the polynomial equations.. but the results I obtained were not consistently getting close to the correct solution ( $x \sim 1.71$ ), obtained with wolfram alpha In fact, using $\displaystyle \int_0^x e^{-t^2}dt = x - \frac{x^3}{3} + \frac{x^5}{10} - \frac{x^7}{42} + \dots$ I obtained the following approximations ( $x_i$ indicates the result obtained considering the terms until $x^i$ ) $$x_1 \sim 1.12\ \ \ \ x_3 = -4.975 \ \ \ x_5 = 1.59 \ \ \ x_7 = -4.718 | 3.729 | 1.755 \ \ \ \ x_9 = 1.70$$ Questions 1) If I take into account the whole series, what assures me that only one solution will be found (with $x_7$ , for example, I find $3$ real solutions) 2) I understand that as long as I am near $0$ , the solution will be good approximation. But a priori I don't know what values $x$ is going to take, so the error can be large as large as $x$ and the Taylor approximation is useless. 3) Why is (eventually) the error going to $0$ if one takes the whole series? I don't think I have a clear understanding of the passage between Taylor polynomial (valid only near a point $x_0$ ) and series (why exactly they are convergent everywhere (well, at least in the case of $e^x$ ) if we consider an an infinite amount of terms)","['sequences-and-series', 'calculus', 'statistics', 'error-function', 'taylor-expansion']"
780753,Connection between degree of dominant morphism and cardinality of fibres,"My exercise: Let $f:X\rightarrow Y$ be a dominant morphism of curves.
For any dominant morphism, the degree of it is defined to be $[K(X):K(Y)]$ with $K(Y)$ identified with $f^*(K(Y))$. Prove that the fibres of $f$ have at most $deg(f)$ points if $Y$ is non-singular. The notes we are working out skim over the whole degree/ramification story.  Other sources(i.e. Shafarevich Book 1) treat more material, but only for $f$ finite. Could anyone elaborate(e.g. give some concrete examples) on what the connection is between the algebraic definition of degree and the behaviour of $f$ on the varieties and/or give a hint for the exercise so I can figure this connection out for myself?",['algebraic-geometry']
780761,Proving $\dfrac{dN}{ds}=-\kappa T+\tau B$,"Currently revising for a differential geometry exam. The question I am working on is one of those types where the next part of the question follows from the last. I've gotten to the point where I have proven $T\cdot \dfrac{dN}{ds}=-\kappa$, and the next part is where I got stuck, which is to prove $\dfrac{dN}{ds}=-\kappa T+\tau B$. I looked at the mark scheme and it said ""Follows from previous item, and $B=T\times N$"". I simply don't see how it follows, though.","['plane-curves', 'differential-geometry']"
