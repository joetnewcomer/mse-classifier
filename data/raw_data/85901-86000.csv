question_id,title,body,tags
1135683,minimum number of steps for knight in chess,"Given two squares on an 8×8 chess board, how can we determine the minimum number of moves required by a knight to reach one square starting from the other?",['combinatorics']
1135697,Computations with canonical sheaf on $\mathbb{P}^1\times\mathbb{P}^1$,"Consider $X=\mathbb{P}^1\times\mathbb{P}^1$ and two projections $p,q:X\to\mathbb{P}^1$. It is known that $\omega_X\cong p^*\omega_{\mathbb{P}^1}\otimes q^*\omega_{\mathbb{P}^1}$. How can I compute cohomologies $H^i(\mathbb{P}^1, (p_*\omega_X)(1))$? Is it possible to compute $p_*\omega_X$ explicitly (i.e., to split it into the direct sum of line bundles over $\mathbb{P}^1$)?",['algebraic-geometry']
1135705,"Fresnel Integrals: $\lim_{R\to\infty}\int_0^{\pi/4} \mathrm{e}^{-(Re^{i\theta})^{2}}{iRe^{i\theta}}\,\mathrm{d}\theta=?$","I'm having trouble proving that the arc from $R$ to $Re^{i\pi/4}$ in the Fresnel contour goes to zero. Currently I have $$\int_0^{\pi/4} \mathrm{e}^{-(Re^{i\theta})^{2}}{iRe^{i\theta}}\,\mathrm{d}\theta$$ and I've tried a couple of things but I can't seem to find an inequality that works.","['complex-integration', 'complex-analysis']"
1135735,Do sequences fully specify the topology of $\mathcal{D}(\Omega)$ and $\mathcal{D}'(\Omega)$?,"It is well known that $\mathcal{D}(\Omega)$ and $\mathcal{D}'(\Omega)$ are not metrizable, and that a topological vector space is metrizable if and only if it is first-countable (Rudin, Thm. 1.24). This doesn't necessarily mean that sequences will not specify the topology of the space, but it isn't good news at all on that front. Nonetheless, very often I've seen ""sequence arguments,"" which attempt (always successfully) to explore the topology of the space using sequences (for example, in ""Introduction to the Theory of Distributions"" by Friedlander and Joshi, sequences are used to show that, when considered as distributions, the space of smooth, compactly supported functions is dense in $\mathcal{D}'(\Omega)$). I am wondering if some such arguments are inevitably doomed to fail because sequences don't always fully specify the topology. I think there are two entwined questions here: Given any set $A$ in one of these spaces, and any limit point $a$ of it, is there a sequence $\{a_n\}$ of elements of $A$ which converges to $a$? Given any set $A$ in one of these spaces such that all sequences converging to points in $A$ are eventually contained in $A$, must $A$ be open? I am not sure if affirmative answers to either one of these questions implies an affirmative answer to the other. A follow-up question (if the answer is affirmative) I have is that if a topological vector space $E$ is the strict locally convex inductive limit of a countable collection of Frechet spaces $E_{n}$ such that $E_n$ is always a closed subspace of $E_{n+1}$, then can the topology of the space be fully specified by sequences? Any help would be greatly appreciated!","['topological-vector-spaces', 'distribution-theory', 'functional-analysis']"
1135750,Prove that $AB = 0 \iff \mathrm{im}(B) \subseteq \ker(A)$,"Problem 1. Prove that for any $\ell \times m$-matrix $A$ and any $m \times n$-matrix $B$, $$
AB = 0 \quad\text{ if and only if }\quad \mathrm{im}(B) \subseteq \ker(A)
$$ I have no idea on how to start this... 
I'm new to proofs and this is my first proof.","['matrices', 'linear-algebra']"
1135753,Help with a cumulative distribution function question.,"This is a question I want to solve: The random variable $X$ has cdf:
$$
F_X(x) = \begin{cases}
\begin{align}
&0 &&x <0\\
&0.5 + c\sin^2\left(\frac{\pi x}{2}\right) &0 \leq\; &x \leq 1\\
&1 &&x>1
\end{align}
\end{cases}
$$ (a) What values can $c$ assume? (b) Plot the cdf. (c) Find $P[X > 0]$. I assume that $x$ is between $0$ and $1$ so
$$
0.5 + c \sin^2(\pi\times x/2) = 0
$$ then $x=1$ and
$$
c \sin^2(\pi\times 1/2) = -0.5
$$ since $c = -0.5$ Is that correct and I need help with the nother parts please.","['statistics', 'probability']"
1135765,Poisson Distribution: P(exceeds certain number),"A professor plans to schedule an open lab in order to provide answers and additional
help to students in the hour before homework is due. The number of students who will
come to open lab will vary from week to week, and the professor assumes the count in
a particular week will follow a Poisson(15) distribution. The professor is offered a room for the open lab, but is concerned that the room
capacity of 23 won’t be sufficient. Compute the probability that the number of
students who come to open lab in a particular week will exceed the room capacity. I get that λ=15, but how do you find P(X > 23)? Would it be 1-P(0 < X ≤ 23)? That would take ages to calculate...","['statistics', 'probability-distributions', 'probability']"
1135783,Proof for de Moivre's Formula,"I have a book that has a brief history of the complex numbers and it covers de Moivre's formula: $(\cos(x) + i\sin(x))^n = \cos(nx) + i\sin(nx)$. I am very curious as to how this result was originally found, or derived, BEFORE Euler's formula was around. Also, what was the original proof of this?","['math-history', 'complex-analysis']"
1135811,"For a function which is everywhere right-differentiable, what can be said about the existence of points where it is differentiable?","We know that a function which is right-differentiable everywhere is also continuous almost-everywhere, but what about differentiability? For example, is there a function which is everywhere right-differentiable but nowhere-differentiable? Also, what happens if we weaken the assumption and say that a function is right-differentiable everywhere except on a countable set. How small can the set of points where it is non-differentiable be?","['derivatives', 'real-analysis']"
1135852,Does a bounded holomorphic function on the unit disc have summable Taylor coefficients?,"Given a bounded holomorphic function $\phi (z)=\sum_{n=0}^\infty a_nz^n$ on the open unit disc, is it true that $\sum_{n=0}^\infty |a_n|<\infty$? I was thinking that this question could possibly be answered using some theory on analytic continuation, but unfortunately I do not know this theory very well. Any hint or counterexample would be most appreciated. Thank you.","['sequences-and-series', 'complex-analysis']"
1135877,Why can some asymptotes be crossed?,I was taught that an asymptote cannot be crossed. My teacher then went and made my life a lot harder by countering what I've learned. Why can some asymptotes be crossed?,['algebra-precalculus']
1135884,Proving two measures of Borel sigma-algebra are equal,"I am working on this problem on measure theory like this: Let $X$ be set of $\mathbb R$, and let $\mathcal B$ be its Borel $\sigma$-algebra, and finally let $\mu_1$ and $\mu_2$ be the two measures on $(X,\mathcal B)$ such that $\mu_1((a,b))= \mu_2((a,b)) < \infty$ whenever $−\infty < a < b < \infty$. Show that $\mu_1(A) = \mu_2(A)$ whenever $A \in \mathcal B$.​ Here is what I was at first thinking: Since $a,b \in \mathbb R$ and since $A$ is an arbitrary subset of $\mathcal B$, so if only I can prove that $(a,b) \in \mathcal B$, then I am done. But I was told by a responder to my posting at Physics Forum here that this reasoning is wrong, since not all sets in $\mathcal B$ are open. I am hitting a deadend again. Therefore I am posting this question here looking for help, thanks for your time and effort. POST SCRIPT - 1: I should have mentioned this: This problem comes from the 3rd. chapter of an introductory text by Richard F. Bass here , therefore any solution shouldn't involve any advanced theorems such as Dynkin's, etc. Sorry for this belated info, thanks though to all who have taken time to help. POST SCRIPT - 2 : I finally came up with solution without any advanced theorems, adapted from a solution by @JoshKeneda, who used Dynkin's Theorem. I have submitted this work to my professor, he ok'd it except for (5) because it is true only when the $A_i$'s are pairwise disjoint. Feel free to drop me a message if you have ideas to improve (5). Thanks to all and especially to @JoshKeneda. DISCLOSURE: This question is very similar to an old MSE posting here , which was put on hold due to being incomplete. My posting has all the correction to the first posting. Always conscientious of community rule and guideline, I have tried avoiding duplication by posting this question elsewhere here and here , but I did not receive any meaningful helps $-$ understandably, as those two outside forums are not specialized in math. Thank you for your understanding.","['measure-theory', 'real-analysis', 'analysis']"
1135907,Showing that $y''+xy'+y=0$ is exact and then finding the general solution,We can use the condition $P''(x)-Q'(x)+R(x)=0$ to show that $y''+xy'+y=0$ is exact. I was told that I will need to integrate the equation once then apply the appropriate first order method. I have tried to integrate but got lost with all the variables.,['ordinary-differential-equations']
1135914,Prove that $\sin^7 x + \cos^7 x < 1$ if $0 < x < \frac{\pi}{2}. $,I am not sure how to attack this. Using the Pythagorean identity seems just to make things messier.,['trigonometry']
1135959,What does it mean to represent a number in term of a $2\times2$ matrix?,"Today my friend showed me that the imaginary number can be represented in term of a matrix $$i = \pmatrix{0&-1\\1&0}$$ This was very very confusing for me because I have never thought of it as a matrix. But it is apparent that the properties of imaginary number holds even in this representation, namely $i\cdot i = -1$ Even more confusing is that a bunch of quantities can be represented by matrices $$e^{i\theta} = \pmatrix{\cos\theta&-\sin\theta\\
\sin\theta&\cos\theta}$$ Naturally I wonder if we can perform this for any number. What is the big picture here? What is this operation called turning a number into a matrix. What is the deeper implication - how does knowing this help? 100 points to anyone who can answer this in a comprehensive way.","['abstract-algebra', 'rotations', 'matrices', 'linear-algebra', 'complex-numbers']"
1135993,$\mathbb{R}$ with the lower limit topology is not second-countable,"I am trying to prove that $\mathbb{R}$ with the lower limit topology is not second-countable. To do this, I'm trying to form an uncountable union $A$ of disjoint, half-open intervals of the form $[a, b)$, $a < b$. Is this possible? I think this would imply the $A$ is open but no countable union of basis elements could coincide with $A$ therefore making the real numbers with the lower limit topology not second-countable. I think there must exist something like $A$ described above but I am having trouble visualizing it and coming up with a formula to represent it. Maybe there is some other way to show it is not second-countable.","['general-topology', 'sorgenfrey-line']"
1136017,"Let $a,b,c$ be the lenghts of the sides of a triangle. Suppose that $ab+bc+ca=1$. Show that $(a+1)(b+1)(c+1)<4$ [duplicate]","This question already has answers here : An inequality for sides of a triangle (3 answers) Closed 5 years ago . Let $a,b,c$ be the lenghts of the sides of a triangle. Suppose that $ab+bc+ca=1$. Show that $(a+1)(b+1)(c+1)<4$. My attempt: I tried multiplying the whole thing but that didn't help at all. So, I tried to manipulate the triangle inequality and bring out the given form but that didn't help too. I am out of ideas now. Please help. Thank you.","['geometry', 'triangles', 'inequality']"
1136039,$f(x)$ is onto?,"A function $f:R-{a_1,a_2}$ to $R$ is defined by $$f(x)=\frac{ Ax^2+6x-8}{A+6x-8x^2}$$
How many integral values of $A$  exist for which $f(x)$ is onto.
I tried finding the range of this function, but I did not find things working out. Please see- This is a problem from brilliant.org(I am not cheating, I have used all my chances).",['functions']
1136049,Uniqueness in Doob's Decomposition Theorem,"I'm a little uneasy about one step in the uniqueness proof for Doob's Decomposition Theorem. Let $(X_n)_{n \geq 0}$ be a submartingale, $(M_n)_{n \geq 0}$ a martingale, and $(A_n)_{n \geq 0}$ be an increasing process such that $A_{n+1}$ is $\mathcal{F}_n$-measurable. If we have 2 decompositions
\begin{align*}
X_n &= X_0 + M_n + A_n\\
X_n &= X_0 + L_n + C_n,
\end{align*}
Then $M_n - L_n = A_n - C_n$ (a.s.?). Here is the part I don't get: My book argues that since $A_n - C_n$ is $\mathcal{F}_{n-1}$-measurable, $M_n - L_n$ is also $\mathcal{F}_{n-1}$-measurable. Why is this true? I feel like in general, $X=Y$ a.s. and $Y$ is $\mathcal{F}$-measurable does not imply that $X$ is $\mathcal{F}$-measurable, like the example here: Almost sure convergence for measurability","['probability-theory', 'martingales']"
1136056,"If C and D are club sets, why is the intersection of C and D closed?","Almost every proof I've seen on club (closed and unbounded) sets begins with If C and D are club sets then it is easy to see why C intersect D are closed. Intuitively it makes sense, but I haven't been able to construct a proper argument explaining why. If you had to explain to somebody why C intersect D are closed, how might you do it?",['elementary-set-theory']
1136057,Find a bijective function between two sets [duplicate],"This question already has answers here : How to define a bijection between $(0,1)$ and $(0,1]$? (9 answers) Specify a bijection from [0,1] to (0,1]. [duplicate] (2 answers) Closed 9 years ago . I want to find a bijective function from $(\frac{1}{2},1]$ into $[0,1]$. So, What is a bijective function $f:(\frac{1}{2},1]\to[0,1]$?",['functions']
1136112,Lower Bound on Expectation of Operator Norm,"I've been working through Terence Tao's text on random matrices, and there's a step in a proof that I am having trouble with.  We want to show Proposition 2.3.19.  The assumptions are $M$ symmetric with entries which are variance 1, mean 0, and $O(1)$ in magnitude.  The eventual goal is to conclude that $E{||M||}_{op}$ is bounded below by $(2-o(1)) \sqrt{n}$. Let's say we've shown that $E{||M||}^k_{op} \geq (C_{k/2} +o_{k}(1))n^{k/2}$.  We want to conclude something about $E{||M||}_{op}$ from this, but the k inside of the expectation is bothersome.  The proof says to combine the previous result with a corollary of Talagrand's theorem for the Gaussian decay of the operator norm in such a case; namely $Pr[\big|{||M||}_{op}-E{||M||}_{op}\big| > t] \leq a e^{-bt^2}$.  The formula also holds for the median in place of the mean, if this is helpful. Using the above two facts, we are supposed to deduce that $E{||M||}_{op} \geq (C_{k/2}^{1/k}+o_k(1))\sqrt{n}$ Conceptually for me, I am having trouble connecting concentration of measure about the mean with knowledge of the value of the mean, at least in the lower bound direction. Much appreciated","['random-matrices', 'probability']"
1136131,Schwartz functions & differentiation under the integral sign.,"Let $\mathscr{S}(\mathbb{R}^n)$ denote the space of Schwartz functions. That is
$$
\mathscr{S}(\mathbb{R}^n) = \left\{ f \in C^\infty(\mathbb{R}^n, \mathbb{R}) ~\colon \sup_{x\in\mathbb{R}^n} \left|x^\alpha \partial_\beta f(x) \right| < \infty \quad \forall \alpha, \beta \right\}
$$
where $\alpha$ and $\beta$ are multi-indices. Take $f(t, x) \in \mathscr{S}(\mathbb{R}^{n+1})$ and define $F ~\colon \mathbb{R} \to \mathbb{R}$ by
$$
F(t) = \int_{\mathbb{R}^n} f(t, x) ~\mathrm{d}t
$$
I would like to know when it is valid to compute $F'(t)$ by ""differentiation under the integral sign"". In other words, when is it justifiable to say
$$
F'(t) 
= \partial_t \int_{\mathbb{R}^n} f(t, x) ~ \mathrm{d}t
=  \int_{\mathbb{R}^n} \partial_t f(t, x) ~ \mathrm{d}t
$$
I'm think I am able to show this when I have a few extra conditions, say if I know that $\partial_t f(t, x)$ is a decreasing function of $t$ for all fixed $x$. However, I feel that it should be true in general and perhaps I'm just missing something important. Any help will be appreciated.","['functional-analysis', 'partial-differential-equations', 'integration', 'real-analysis']"
1136140,Normalization or integral closure of ring over $\mathbb Z_p$,"Let $p$ be a prime larger than four. And denote the $p$ adic integers by $\mathbb Z_p$. Consider the ring $A=\mathbb Z_p[x]$ and its field of fractions $K=\mathbb Q_p(x)$. Now let's extend $K$ to a field $L$, which is a function field of a curve, like $L=\mathbb Q_p(x)[y]/(y^2-(x^5-2)(x-p)(x+p))$. Now what is the normalization or integral closure of $A$ in $L$? And (as an algebraic question) why do I also have to look at the situation over $\mathbb F_p$ as well?
The geometric answer is: This normalization describes an affine model $\mathcal Y$ of a curve $Y$ with special fiber $\bar Y=\mathcal Y\otimes\mathbb F_p$, which has a singularity at $(0,0)$. My ideas so far: The curve is nonsingular over $\mathbb Z_p$, so nothing to do there. Over $\mathbb F_p$ we have a double point at $(0,0)$. Normally one gets rid of such a point by introducing somethin like $t:=y/x$. But how do I do this here? I also know the easy examples $y^2=x^3$ and $y^2=x^2(x+1)$. Kind regards","['geometry', 'ring-theory', 'algebraic-geometry', 'abstract-algebra', 'commutative-algebra']"
1136144,"Expand $(a−b)^2 +(b−c)^2 +(a−c)^2$ , and hence prove that $a ^2 +b^2 +c^2 ≥ ab+bc+ac$.","I would like some advice on how I can prove that  $$a^2 +b^2 +c^2 ≥ ab+bc+ac.$$ I have completed the first part of the question that asks for an expansion: $$ (a−b)^2 +(b−c)^2 +(a−c)^2$$
$$(a^2-2ab+b^2)+(b^2-2bc+c^2)+(a^2-2ac+c^2)$$
$$ 2a^2+2b^2+2c^2-2ab-2bc-2ac $$
$$ 2(a^2+b^2+c^2-ab-bc-ac)$$ If I have done the expansion incorrectly, corrections in this aspect would also be helpful.",['algebra-precalculus']
1136163,Minimal presentations and (co)homology groups,"I wonder whether there exists a link between the number of generators and relations of a presentation for a given group $G$ and the ranks of its (co)homology groups $H_1(G,\mathbb{Z})$ and $H_2(G, \mathbb{Z})$. For example, if $\langle X \mid R \rangle$ is a presentation of a group $G$ such that $R$ has as less relations as possible provided that $|X|= \mathrm{rank}(G)$, can we say that $\mathrm{rank}~H_2(G,\mathbb{Z}) = |R|$? It seems to be true at least for some groups. I am not really familiar with (co)homology of groups, so I don't know what would be a pertinent formulation. Instead, I conclude with a pretty vague question: Is it possible to link minimal presentations and (co)homology groups?","['group-cohomology', 'group-theory', 'group-presentation']"
1136200,Maybe Stuck Pedal Triangle with geometry problem,"Suppose $P$ is any point within an acute-angled triangle,Let $X,Y,Z$ be the feet of the perpendiculars from $P$ onto the sides $BC,CA,AB$ respectively. and $U,V,W$ be where $AP,BP,CP$ meet the sides $BC,AC,AB$ respectively. show that：
$$|UV|+|UW|+|VW|\ge |XY|+|XZ|+|YZ|$$ This problem is from  New Zealand 2015 TST exam ,It is said no one solved it in the olympiad. Everyone got 0 point.Background Pedal Triangle http://mathworld.wolfram.com/PedalTriangle.html",['geometry']
1136201,The normaliser of the left regular image [D&F],"I want to solve the following problem from Dummit & Foote's Abstract Algebra text (p. 186): Let $H$ be a group of order $n$, let $K=\text{Aut}(H)$ and form $G=\text{Hol}(H)=H \rtimes K$ (where $\varphi$ is the identity homomorphism). Let $G$ act by left multiplication on the left cosets of $K$ in $G$ and let $\pi$ be the associated permutation representation $\pi:G \to S_n$. (a) prove that the elements of $H$ are coset representatives for the left cosets of $K$ in $G$ and with this choice of coset representatives $\pi$ restricted to $H$ is the left regular representation of $H$. (b) Prove $\pi(G)$ is the normalizer in $S_n$ of $\pi(H)$. Deduce that under the regular representation of any finite group $H$ of order $n$, the normalizer in $S_n$ of the image of $H$ is isomorphic to $\text{Hol}(H)$. [Show $|G|=|N_{S_n}(\pi(H))|$ using Exercises 1 and 2 above.] (c) Deduce that the normalizer of the group generated by an $n$-cycle in $S_n$ is isomorphic to $\text{Hol}(Z_n)$ and has order $n \varphi(n)$. My attempt: (a) We know that there are $|G|/|K|=|H|=n$ left cosets of $K$ in $G$. If $h_1K=h_2K$ are the same coset, where $h_1,h_2 \in H$ then $h_1^{-1}h_2 \in K$. Since $h_1^{-1}h_2 \in H$ as well we find $h_1^{-1}h_2=1$ or $h_1=h_2$. Thus the $n$ distinct elements of $H$ give rise to $n$ distinct left cosets of $K$ in $G$, which are all such cosets. Moreover, $\pi \big|_H(h)(h'K)=hh'K$, so that working with the representatives from $H$, $\pi \big|_H$ coincides with the left regular representation of $H$. (b) I could prove one inclusion: Let $\pi(g) \in \pi(G)$. We have $$\pi(g) \pi(H) \pi(g)^{-1}=\pi(gHg^{-1})=\pi(H),$$
hence $\pi(G) \leq N_{S_n}(\pi(H))$. I can't see how to use Exercises 1 and 2 (which I will quote below) to follow the hint. (c) Once I have part $(b)$ right, this is easy. My questions: Is my partial solution correct so far? If not, please help me fix it. How can I prove part (b) by following the hint in the brackets. For reference, Exercises 1 and 2 state that for a semi-direct product $G=H \rtimes_\varphi K$ we have $C_K(H)=\ker  \varphi$ and $C_H(K)=N_H(K)$. Thank you!","['semidirect-product', 'permutations', 'group-theory', 'abstract-algebra']"
1136207,How to determine the curve?,"In the figure above, segment $PQ$ is determined by two points: $P: (t,0)$ and $Q: (1,t)$, where $t\in [0,1]$ continuously increases and decreases between $0$ and $1$. Then this gives a close region swept by $PQ$, the upper edge of which is a curve. How to determine the equation of the curve (maybe implicit form)? My own method Suppose the curve is $y=y(x)$, then for any fixed $x_0\in (0,1)$, there is a vertical line $x=x_0$, which intersects a bundle of such $PQ(t)$ segments: $$y=\frac{t(x-t)}{1-t}$$ Easy to conclude that, the desired $y_0$ on the curve corresponding to $x_0\left(\in(0,1)\right)$ is the maximum of: $$y_0= \max\limits_{t\in (0,1)}\frac{t(x_0-t)}{1-t}=2-2\sqrt{1-x_0}-x_0$$ How to use the envelope concept? Is there any elementary method since the area is $\frac{1}{6}$?","['geometry', 'calculus']"
1136219,Convergence in distribution to derive the expectation convergence,"If $X_n\longrightarrow X$ in distribution, $\mathbb{E}(X)\lt\infty$, Do we have the following conclusion: $\mathbb{E}(X_n)\longrightarrow\mathbb{E}(X)$?","['weak-convergence', 'expectation', 'probability-theory', 'probability-distributions', 'probability']"
1136236,"How to calculate derivative of a multi-variable function, if variables are dependent of each other?","For a multiple variable function, such as $f(x, y)$, if $y$ is actually dependent on $x$, then I think there are two ways to calculate $df$: replace $y$ by $x$ in $f(x,y)$ and then treat the result function as a single variable function $g(x)$, then calculate $dg$ calculate $df(x,y)$ using partial derivatives and then substitute. However, I have a problem with the second method, and cannot reconcile the two. As an example, suppose we have a function $$f(x, y) = x + 2y + 3xy$$ but $x$ and $y$ are related via $$y = 1 - x$$ Then the first method will give me the following $$g(x) = f(x, 1-x) = x + 2(1-x) + 3x(1-x) = -3x^2 + 2x + 2$$
so
$$dg(x) = (-6x + 2)dx$$ Using the second method, I have the following. calculate $df(x,y)$ as partial derivatives of $x$ and $y$
$$df(x, y) = f_x(x, y)dx + f_y(x,y)dy + f_{x,y}(x,y) dx dy $$
$$df(x, y) = (1+3y)dx + (2+3x)dy + 3 dx dy $$ replace $y$ by $1-x$ and $dy$ by $(dy/dx)dx = -dx$ throughout
$$df(x) = (1+3(1-x))dx + (2+3x)(-dx) + 3 dx(-dx) $$
$$df(x) = (-6x + 2)dx - 3 (dx)^2 $$ As you can see, there is an extra $-3(dx)^2$ term using the partial derivative method. What went wrong? I also have two questions is it legitimate to replace $dy$ by $(dy/dx)dx$ in step 2? Shouldn't term $f_ydy$ mean keeping $x$ unchanged? Then how can we replace $dy$ by $(dy/dx)dx$ as it means $x$ changes? when I substitute $y$ by $1-x$ and $dy$ by $(dy/dx)dx$, what does $df(x,y)$ become? do we write it as another function $dg(x)$ or $df(x, 1-x)$? I'm really confused. Thank you!","['partial-derivative', 'derivatives']"
1136247,Minimal polynomial of a matrix satisfying $A^t=A^2$,"Let $A\in M_n(\mathbb R)$ be a non-zero non-identity matrix such that $A^t=A^2$. Then is it possible to find the minimal polynomial of $A$? My  try is: the given condition implies that $A^4=A$, hence the minimal polynomial $p(t)$ of $A$ divides $t^4-t=t(t-1)(t^2+t+1)$. So $p(t)$ can be some factor of $t(t-1)(t^2+t+1)$. Also if $\lambda$ is an eigenvalue of $A$ and $x$ is the corresponding eigenvector (considered as a column vector), then $Ax=\lambda x \implies \lambda x^t=x^t A^t\implies \lambda x^t=x^tA^2\implies \lambda(x^t x)=x^t(A^2x)\implies \lambda(x^t x)=\lambda^2(x^tx)\implies (\lambda^2-\lambda)(x^tx)=0\implies\lambda^2-\lambda=0,\text{ as } x^tx \text{ is non-zero}.$ Hence $0$ and $1$ are the only eigenvalues of $A$. So the minimal polynomial is of the form $p(t)=t(t-1).$ Is this correct or did I misunderstood something? P.S. $A^t$ denotes the transpose of the matrix $A$.","['linear-algebra', 'eigenvalues-eigenvectors', 'minimal-polynomials']"
1136259,Show that $y_1$ and $y_2$ are not Linearly Independent,"Suppose that $y_1(x)$ and $y_2(x)$ are solutions of the differential equation $y''+py'+qy=0$ on $I$. How can I show that if $y_1$ and $y_2$ vanish at the same point then they are not linearly independent? Here is my attempt to prove the problem. Since $y_1(x)$ and $y_2(x)$ are solutions of the differential equation $y''+py'+qy=0$ on $I$, it is enough for me to show that the Wronskian of $y_1$ and $y_2$ denoted by $W(y_1,y_2)$ is zero. Now since $y_1$ and $y_2$ vanish at the same point say $p$ we have $y_1(p)=0$ and also $y_2(p)=0$. Solving for $W(y_1,y_2)(p)$ we have: $y_1(p)y_2'(p)-y_2(p)y_1'(p)=0$ since $y_1(p)=0$ and also $y_2(p)=0$. Am I correct?
Thanks","['linear-algebra', 'ordinary-differential-equations']"
1136275,Why is $\mathbb Q $ (rational numbers) countable? [duplicate],"This question already has answers here : How to prove that $\mathbb{Q}$ ( the rationals) is a countable set (7 answers) Closed 9 years ago . By definition, a set $S$ is called countable if there exists an bijective function $f$ from $S$ to the natural numbers $N$. If we take a function $g\colon\mathbb{Z\times N\to Q}$  given by $g(m, n) = \frac{m}{ n} $ to ""construct"" rational numbers, $g$ would only be a surjection from the countable set $\mathbb{Z\times N}$ to $\mathbb Q$. It's not injective, or is it?","['elementary-set-theory', 'rational-numbers']"
1136281,Showing minimal graded free resolutions are isomorphic,"I'm currently reading Rogalski's notes on noncommutative projective algebraic geometry (which can be found here ) and I'm currently trying to fill out the details of Lemma 1.24 (2). The step which I don't understand is why the map $h$ is an isomorphism. I understand that there is an isomorphism $P/PA_{\ge 1} \rightarrow Q/QA_{\ge 1}$, and how we can lift this to a map $h: P \rightarrow Q$, but I can't see either injectivity or surjectivity of $h$. I feel like graded Nakayama should be relevant, but can't see why.","['homological-algebra', 'noncommutative-algebra', 'algebraic-geometry']"
1136287,"Why ""cylinder sets""?","If $I$ is any set of indexes, we define $E^I=\{(x_i)_{i\in I}:x_i\in E\,\,\forall i\in I\}$, $E$ being any set. Subsets of $E^I$ of the form $C_J=\{x_i\in B_i\,\,\forall i\in J\}$, where $B_i\in\mathcal{A}\,\,\forall i\in J$, $\mathcal{A}$ is a $\sigma$-algebra on $E$ and $J\subseteq I$ is finite, are called ""cylinder sets"", and form a basis of the product $\sigma$-algebra $\mathcal{A}^{\otimes I}$. Why are these sets called ""cylinder sets""? What is the origin of this name?","['measure-theory', 'terminology']"
1136310,How to evaluate $\lim\limits_{p \rightarrow \infty} \left(\sum_\limits{i=1}^n \left|x_i-y_i\right|^p\right)^{\frac{1}{p}}$,"I'd like to know why $\lim\limits_{p \rightarrow \infty} \left(\sum_\limits{i=1}^n \left|x_i-y_i\right|^p\right)^{\frac{1}{p}} = \max\limits_{1\le i \le n} \left| x_i-y_i\right|$ for $\mathbf{x},\mathbf{y}\in \mathbb{R}^n$. So I started by checking a simpler expression: $\lim\limits_{x\rightarrow \infty} ((6-3)^x+(5-1)^x)^{\frac{1}{x}}=4$ I don't know how to get 4. The expression inside the parenthesis is indeterminate $(\infty + \infty)$ and I don't know of any way to rewrite it so that I can remove the exponents.",['limits']
1136326,How can I quickly find the determinant of this matrix,"$$
        \begin{vmatrix}
        14 & 2 & 1 & 3\\
        31 & 4 & 5 & 6\\
        26 & 3 & 7 & 4\\
        10 & 1 & 3 & 2\\
        \end{vmatrix}
       =
        \begin{vmatrix}
        5\cdot2+1+3 & 2 & 1 & 3\\
        5\cdot4+5+6 & 4 & 5 & 6\\
        5\cdot3+7+4 & 3 & 7 & 4\\
        5\cdot1+3+2 & 1 & 3 & 2\\
        \end{vmatrix}$$$$
       =
        \begin{vmatrix}
        5\cdot2 & 2 & 1 & 3\\
        5\cdot4 & 4 & 5 & 6\\
        5\cdot3 & 3 & 7 & 4\\
        5\cdot1 & 1 & 3 & 2\\
        \end{vmatrix}
        +
        \begin{vmatrix}
        1 & 2 & 1 & 3\\
        5 & 4 & 5 & 6\\
        7 & 3 & 7 & 4\\
        3 & 1 & 3 & 2\\
        \end{vmatrix}
        +
        \begin{vmatrix}
        3 & 2 & 1 & 3\\
        6 & 4 & 5 & 6\\
        4 & 3 & 7 & 4\\
        2 & 1 & 3 & 2\\
        \end{vmatrix}
$$ However I am not able to proceed beyond. The answer given is zero. Is there any simple determinant property that I am not able to guess?","['matrices', 'linear-algebra', 'determinant']"
1136327,Finding $\int_{0}^{\pi/2} x \log(\sec{x}) \mathrm{d}x$,How do I evaluate $I=\displaystyle\int_{0}^{\pi/2} x \log(\sec{x}) \mathrm{d}x$? We could write $I$ as $\dfrac{1}{2}\displaystyle\int_{0}^{\pi/2} x \log(1+\tan^2{x})$ and then taylor expand to get $$\begin{align}I&=\int_{0}^{\pi/2} \sum_{n=1}^{\infty} (-1)^{n+1}\dfrac{x \tan^{2n}{x}}{n} \mathrm{d}x \\ &= \sum_{n=1}^{\infty}\dfrac{(-1)^{n+1}}{n}\int_{0}^{\pi/2}x \tan^{2n}{x} \mathrm{d}x\end{align}$$ But I don't know what to do from here on. Please help me out. Thank you.,"['definite-integrals', 'integration']"
1136350,How do distribute exams within three weeks?,"In our program of study we have $N$ students and $M$ courses. I guess $M \approx 50$ and $N \approx 1000$. Each student takes at most $3$ courses in our department. At our university we struggle with the question how one should assign the exam dates of each course within 3 weeks (15 days), such that most student have some days between their exams. I wonder now if there is some mathematical way to find an optimal solution for this difficult problem. Edit: I do not know the size $N$ and $M$ at the moment. Of course it would be possible to get this data from the online registration platform of the courses. It would be possbile to get a database where it is shown which student took which course.","['optimization', 'discrete-mathematics', 'probability']"
1136389,Analog of an open map for uniform structures,"In topology, a function is continuous if the inverse image of an open set is open.
A function is open if the image of an open set is open. Uniformity continuity can be defined in a similar way as continuity.
A map $f$ between two uniform spaces is uniformly continuous if the inverse image (under $f \times f$) of an entourage is an entourage. Now consider the following ""uniform analog"" of openness: the image (under $f \times f$) of an entourage is an entourage. Question . Was this property studied? And if yes, is there a well-established name for it? Motivation. I need this property in a very special case and I am looking for references.","['general-topology', 'reference-request', 'uniform-spaces']"
1136459,Left and right derivative,Find the left and right derivative of $f(x) = (2+|x|)e^x$ in x = 0. This is how I started (with the derivative from the right): $$\lim _{h\to 0^+}\frac{f(0+h) - f(0)}{h} =$$ $$\lim _{h\to 0^+}\frac{(2+|0+h|)e^{0+h} - (2+|0|)e^{0}}{h} = \lim _{h\to 0^+}\frac{(2+h)e^h - 2}{h}$$ This is as far as I have gotten. Am I approaching it the right way? How do I continue from here? I can't see how to get rid of $h$ in the denominator.,"['derivatives', 'limits']"
1136472,Weak convergence of order statistics,"I've encountered the following problem:
Let $U_1,...,U_n$ be iid uniformly distributed on $[0,1]$ and let $U_{n(k_n)}$ denote the $k_n$-th order statistic where $k_n$ is chosen, s.t. $\frac{k_n}{n}=p+\frac{c}{\sqrt{n}}+o\left(\frac{1}{\sqrt{n}}\right)$ where $c$ is some constant and $p\in(0,1)$. Then it should hold (and this is my question): 
$$\left(U_{n(k_n)}-p\right)_{n\in\mathbb{N}}$$
converges weakly to some random variable. Does someone know why this is true and how to identify the limit?
Thanks a lot!","['statistics', 'probability-distributions', 'probability-theory']"
1136490,Chess Set Latin Square,"Here is a very interesting question that my professor and I came up with today. We came up with it while discussing another problem, and I'm very curious to see how this pans out! Question: Suppose that you have 32 chess sets and a 32 x 32 board. The chess sets are standard, consisting of 16 white pieces (8 pawns, 2 castles, 2 knights, 2 bishops, 1 queen and 1 king), and 16 black pieces (same as white) each. How many ways can you arrange the pieces on the board so that all of the rows and columns form chess sets? Thoughts: Clearly, the number of ways that you can arrange the pieces in the first row is $$\frac{32!}{(8!(2!)^3)^2}$$ The second row is also relatively easy, as the only restriction is that you cannot have two kings or queens of the same colour in the same column. After that it gets a bit tricky, because there is no guarantee that there are already two castles, knights or bishops in the same column. Obviously, as you work down the columns it becomes more probable that there are already the sufficient number of any given piece in the columns. However, the complexity that immediately arises from this method begs the question of whether or not multiplying out the number of arrangements for each row is the most efficient way of approaching this problem. I'm quite a beginner at combinatorics, and simply thought that it would be an interesting problem to give to this community, as well an opportunity to open my eyes to an area unfamiliar to me.",['combinatorics']
1136495,Multiplication of inverse and non-inverse matrices,"I have thought about the combination of multiplication product of invertible and non-invertible matrices: invertible $\cdot$ invertible = invertible non-invertible $\cdot$non-invertible = non-invertible non-invertible $\cdot$invertible = non-invertible invertible $\cdot$non-invertible = non-invertible Is it right? I have thought about from the point of view that non-invertible matrix is row equivalent to a matrix with a zero row there for multiple it from both right and left will produce a matrix with a zero row and a zero column respectfully, and opposite goes for invertible matrices",['linear-algebra']
1136508,Integrate $\int_0^{\infty}\cos(x-x^3)\mathrm dx$?,"Is there any way of integrating
$$\int_0^{\infty}\cos(x-x^3)\mathrm dx$$
in closed form?","['definite-integrals', 'trigonometry', 'integration']"
1136520,Choosing the definition of $\frac{\partial^2}{\partial x\partial y}$,"Today, I answered this question and discovered that the definition of $\dfrac{\partial^2}{\partial x\partial y}$ is a matter of convention. For example this .edu link and this other .edu link use the convention
$$\frac{\partial^2}{\partial x\partial y}:=\frac{\partial}{\partial y}\left(\frac{\partial}{\partial x}\right) \qquad \qquad (1)$$ However, this wikipedia article , this .edu link and this other .edu link use the convention $$\frac{\partial^2}{\partial x\partial y}:=\frac{\partial}{\partial x}\left(\frac{\partial}{\partial y}\right) \qquad \qquad (2)$$ Since apparently the definition has not been fixed yet, I can imagine that both definitions has advantages/disadvantages depending on the context they are used. However, I can't find any of these situation. Question: What are the pros and cons of each definition? EDIT: At the time I write this edit, it seems that even in the wikipedia article about partial derivatives, there is a ""contradiction"", here definition $(1)$ is used but here they use definition $(2)$...","['multivariable-calculus', 'convention', 'definition', 'notation', 'derivatives']"
1136535,If the scalar product are equal then the operators are equal.,"I want to show the following: Let H be a $\mathbb C$ -hilbert space and $S,T\in L(X)$ If $\langle Sx,x \rangle = \langle Tx,x \rangle$ for all $x\in H$, then $S=T$ Any hints for me?","['operator-theory', 'hilbert-spaces', 'functional-analysis']"
1136589,What is wrong with this proof on ring of integers being finitely generated,"I have seen some proofs about the theorem that the ring of integers is a finitely-generated $\mathbb{Z}$-module, but I thought I came up with a more straightforward proof. However, I believe there is some loophole in the argument because I don't see this argument being presented anywhere. Let $K$ by a number field (i.e. finite extension of $\mathbb{Q}$), with $[K:\mathbb{Q} ] = n$. The ring of integers $O_K$ is the integral closure of $\mathbb{Z}$ in $K$. We can define a map $O_K \otimes_\mathbb{Z} \mathbb{Q} \to K$ where we define $\alpha \otimes q \mapsto \alpha q$ (and extend linearly). In my class, I saw that this is an isomorphism of $\mathbb{Q}$-vector spaces, so I don't think there is anything wrong with that claim. Anyway my class left this point to prove the theorem with some use of trace etc, but I thought the following reasoning should work. In search of contradiction, suppose $O_K$ is not finitely generated over $\mathbb{Z}$. Then I may find $\alpha_1,...,\alpha_{n+1} \in O_K$ such that they are $\mathbb{Z}$-independent. Let $M = \mathbb{Z} \alpha_1 + ... + \mathbb{Z}\alpha_{n+1}$. Then $M \subset O_K$ and so $M \otimes_\mathbb{Z} \mathbb{Q} \hookrightarrow K$. But $M \simeq \mathbb{Z}^{n+1}$ so $M \otimes_\mathbb{Z} \mathbb{Q} \simeq \mathbb{Q} ^ {n+1}$. Thus the injectivity is a contradiction. Is there anything wrong with the above proof?","['modules', 'algebraic-number-theory', 'abstract-algebra']"
1136592,how to calculate a vector in a left invariant vector field?,"I would like to understand the left invariant vector field by using a numerical example. Now we consider a Lie group $G=SE(3)$, and the associated Lie algebra is $\mathfrak{g}=se(3)$. We suppose:
$$g=\pmatrix{1 & 0 & 0 & 1\\
0 & 1 & 0 & 2\\0 & 0 & 1 & 3\\0 & 0 & 0 & 1}\in G$$
and
$$v=\pmatrix{0 & 0 & 0 & 1\\
0 & 0 & 0 & 2\\0 & 0 & 0 & 0\\0 & 0 & 0 &0}\in\mathfrak{g}$$
$v$ is a vector at the identity element $I$ in a left invariant vector field $X$ of the Lie Group $G$.
Then my questions: 1) how to calculate the vector $v_g$ at the point $g$ in the vector field $X$? 2) Now we consider a map: $\phi:G\rightarrow G,x\rightarrow gx$, where $g$ is defined as above. Then $\quad$ i) how to calculate the vector at the identity element $I$ in the new Lie Group $\phi(G)$? (Is this equal to $v$?) $\quad$ ii) how to calculate the vector at the point $g=\phi(I)$ in the Lie Group $\phi(G)$? $\quad$ iii) how to calculate the vector at the point $\phi(g)$ in the Lie Group $\phi(G)$?","['lie-algebras', 'lie-groups', 'differential-geometry']"
1136639,$E|X-m|$ is minimised at $m$=median,"For a continuous random variable $X$, I want to show that $E|X-m|$ is minimum implies $m$ is the median of the distribution. Assume that the distribution function is $F$ and the density function is $f$. In this case, we basically need to minimize $$\int_x |x-m|f(x)\,dx=\int_{x>m}(x-m)f(x)\,dx+\int_{x<m}(m-x)f(x)\,dx.$$ I am finally being left with $2mF(m)-m+E(X)-2\int_{x<m}xf(x)\,dx$. What does it mean to minimise this expression? Is there some way out? Well, my intuition says that since I have to prove that $F(m)=0.5$, I somehow will need to show that $E|X-m|$ is minimised if $2mF(m)-m=0$ (as then I will get $F(m)=0.5$","['probability-theory', 'probability-distributions', 'probability', 'median']"
1136640,Studying when $P_n=(p_1\cdot p_2\cdots p_n)+1$ is a square number [duplicate],"This question already has answers here : Is my proof correct? $p_1p_2p_3\cdots p_n+1)$ cannot be the square of an integer [duplicate] (2 answers) Closed 9 years ago . Let $p_n$ be the $n$th prime number. I need to find under which conditions the number $$P_n=(p_1\cdot p_2\cdots p_n)+1$$ is a square number. So far I have seen that $$P_1 = 2+1 =3$$ $$P_2 = 2\cdot3+1 =7$$ $$P_3 = 2\cdot3\cdot5+1 =31$$ give all prime numbers, this is that $P_n$ is always a prime number, and so it can never be a square number. But I can not find the exact way to prove it. I though of trying something like the prove for the Euclidean Theorem  that states that there are infinite prime numbers but I can not figure it out. Thank you.","['prime-numbers', 'prime-factorization', 'elementary-number-theory', 'number-theory']"
1136681,Writing Corollaries into Proofs,"I'm taking Discrete Math and one of my homework problems from Epp's Discrete Mathematics with Applications asks me to prove the following: If $r$ and $s$ are any two rational numbers, then $\frac{r+s}{2}$ is rational. It's pretty basic, and here is my proof: We will use the direct method. Let $r$ and $s$ be rational numbers such that \begin{align}r=\frac{a}{b},\:s=\frac{c}{d},\:\:\:\text{s. th.}\:\:a,b,c,d\in\mathbb{Z}\tag{1}.\end{align} Therefore we have \begin{align}\frac{r+s}{2}=\frac{\left(\frac{a}{b}\right)+\left(\frac{c}{d}\right)}{2}=\frac{ad+cb}{2bd}\tag{2},\end{align}and since the product of two integers is an integer and the sum of two integers is also an integer, $(2)$ is therefore the quotient of two integers, which is by definition a rational number.$\:\:\blacksquare$ Okay, so no problem there. But the next question now asks me to write a corollary to the proof above: For any rational numbers $r$ and $s$, $2r+3s$ is rational. I know it is easily proved, but how do I write a corollary to a proof? Do I simply write ""corollary:"" and then continue? What should be re-stated and what should I assume to be a given from the previous proof? Epp only briefly talks about corollaries on page 168. Thank you for your time, and please know that I recognize it is not your job to do my homework and nor would I ever ask it of you.","['discrete-mathematics', 'proof-writing']"
1136682,On the stochastic definition of $e$,"I've read on Wikipedia that one can give a stochastic representation of $e$: In addition to exact analytical expressions for representation of $e$, there are stochastic techniques for estimating $e$. One such approach begins with an infinite sequence of independent random variables $X_1, X_2,\dots$, drawn from the uniform distribution on $[0, 1]$. Let $V$ be the least number $n$ such that the sum of the first $n$ samples exceeds $1$:
  $$V = \min \left \{ n \mid X_1+X_2+\cdots+X_n > 1 \right \}.$$
  Then the expected value of $V$ is $e$: $\mathbb{E}(V) = e$. I was wondering how to show (analytically) that $\mathbb{E}(V) = e$. I looked at the references but they seems to deal just with numerical aspects.","['probability', 'real-analysis']"
1136693,How many are exposed to two of the three? (venn diagram problem),"Q: A survey has shown that of 100 people chosen at random, 80 watch TV commercials, 70 read newspaper ads, 40 read magazines. Only 10 do none of these things, and 20 do all three. How many of these people are exposed to exactly two of the three forms of advertising? Here is my reasoning. I gave up on using the union/intersection terminology because I got nowhere. We are only considering 90 people (100-10). The sum 80 + 70 + 40 = 190 represents all people in T + N + M including double counting. 190 - 20 = 170 is all people, including doubles, less those who do all 3 (because we only want the sum of the ""petals"" not the center) There are only really 90 people meaning that the difference of 170-90 = 80 must represent the sum of the overlapped sections (""petals""). If this is wrong or you know a more elegant way to solve it please share.",['discrete-mathematics']
1136704,"If $y_1(x)$ and $y_2(x)$ are two solutions of equation $y'' +P(x)y' +Q(x)y = 0$ on an interval $[a,b]$ and have a common zero , show linear dependence","If $y_1(x)$ and $y_2(x)$ are two solutions of equation $y'' +P(x)y' +Q(x)y = 0$ on an interval $[a,b]$ and have a common zero in this interval, show that one is a constant multiple of the 1other. Suppose the initial values of the solutions $y_1$ and $y_2$ are defined as follows : $y_1(t_o)=0,y_1'(t_o)=c_1$ and $y_2(t_o)=0, y_2'(t_o)=c_2,$ then, $y_1-y_2$ is also a solution to the given differential equation which satisfies : $(y_1 -y_2 )(t_o)=0 , (y_1~ -y_2)~'(t_o) = c_1-c_2$. Since, all of  $y_1~,y_2,~y_1-y_2$ are solutions to he given differential equation, as per the uniqueness theorem, there exist unique curves which satisfy the above initial conditions. Hence, I do not completely understand  why $y_1$, $y_2$ must be a constant multiple of the other . I found an answer to this problem here . However, I do not understand the answer quite much. Could someone please give an explanation to my confusion above. Thank you for the help!",['ordinary-differential-equations']
1136748,Evaluate the general infinite square root [duplicate],"This question already has answers here : $\sqrt{7\sqrt{7\sqrt{7\sqrt{7\sqrt{7\cdots}}}}}$ approximation [closed] (7 answers) Closed 9 years ago . $$x = \sqrt{n\sqrt{n\sqrt{n}} \cdots}$$ I see that: $$x = \sqrt{nx}$$ $$x^2 -nx = 0$$ Them: $$x(x - n) = 0 \implies x \in \{0, n\}$$ How should I reject the $x = 0$ solution?  (any level proof is fine, analysis, calculus etc...)","['calculus', 'real-analysis', 'analysis', 'proof-writing', 'derivatives']"
1136766,Proving a subset of R is countable,"I have a subset $V$ of $\mathbb{R}$. I know that given any sequence $(u_n)$ of elements of $V$, $(u_n)$ doesn't converge in $\mathbb{R}$. It seems ""obvious"" that it implies that $V$ is countable. However I am not familiar with this kind of proofs, and I am not able to write explicitly why the properties of the sequence imply that $V$ is at most countable. Do someone knows which classical theorem we should apply? Or can someone write explicitly the proof ? Thank you.","['general-topology', 'real-analysis', 'analysis']"
1136773,"If $x \in\mathbb{Z}$ has the property that for all $m \in\mathbb Z$, $mx = m$, then $x = 1$","I am learning proofs, and I am stuck with this proposition: Let $x \in\mathbb{Z}$. If $x$ has the property that for all $m \in\mathbb Z$, $mx = m$, then $x = 1$. I want to use the additive identity to get $mx = m \cdot 1$ to introduce the 1. I am tempted to simply cancel the $m$, but I am supposed to use axioms. Any idea? If $m$ would be any integer except 0, I could use the cancellation axiom. However, $m$ accounts for all integers.","['elementary-number-theory', 'abstract-algebra', 'discrete-mathematics']"
1136789,Cuspidal curve realized from $\mathbb{P}^1$ adding a fat point,"let me ask you a question which will show my poor understanding of stalks and ringed spaces.. I hope that this example will help me clarifying the subject. So here we go: I've read (in particular from Michel Brion's ""Local properties of algebraic group actions"", example 1.12) that ""a cuspidal curve $X$ can be obtained from $\mathbb{P}^1$ by sending the fat point $Spec(\mathcal{O}_{\mathbb{P}^1,\infty}/\mathfrak{M}^2$) to the cusp $x$"". I have a hard time understanding the meaning of this sentence. In particular: 1) Does it mean that $\mathcal{O}_{\mathbb{P}^1,\infty}/\mathfrak{M}^2$ is isomorphic to $\mathcal{O}_{X,x}$, with $X$ the cuspidal curve? I can't really see it, because, given $ZX^2=Y^3$ the homogeneous equation of $X$ in $\mathbb{P}^2$, with cusp in $x=[0,0,1]$, then  $\mathcal{O}_{X,x}=\{\frac{F}{G}|F,G\in \mathbb{C}[X,Y,Z]/(ZX^2=Y^3),G([0,0,1])\neq 0\}$ 2) Is it true that, away from the cusp $x$, the stalks $\mathcal{O}_{\mathbb{P}^1,t}$ and $\mathcal{O}_{X,y}$ are isomorphic?","['algebraic-geometry', 'schemes']"
1136801,"Generalising the cross product to infinite dimensions, does $v \times v = 0$ hold also in infinite dimensional spaces","Consider I have a vector space $V$ with inner product and a bilinear map $b : V \times V \to V$ i)  such that if $z = b(u,v)$ for two $u,v \in V$, then
$$
 z \perp u \quad \mbox{ and } \quad z \perp v.
$$
ii) if $u, v \in V$ are perpendicular, i.e. $u \perp v$, then
$$
 ||b(u,v)|| = ||u||||v||.
$$
These definitions are motivated by an axiomatic introduction of the cross product, see here . Now I want to show that for every $v \in V$ we have $b(v,v) = 0$. If $V$ is finite-dimensional, then this follows by the fact that in an $n$-dimensional space, if $\{v_1, \ldots, v_m\}$ are orthogonal and non-zero, then $m \le n$ (because orthogonality of non-zero vectors implies linear independence). For if $v \in V, v \ne 0$ then the vectors
$$
 M = \{ v, b(v,v), b(v,b(v,v)), \ldots, b(v, b(v, \ldots, b(v,v))) \}
$$
are all orthgonal, to simplify notation suppose we have a $n = 4$ dimensional space. Then 
$$
 b(v, b(v, b(v, b(v, v))) = 0
$$
which implies by ii)
\begin{align*}
 0 & = ||b(v, b(v, b(v, b(v,v)))|| \\
   & = ||v|| ||b(v, b(v, b(v,v)))|| \\
   & = ||v|| ||v|| ||b(v, b(v,v))|| \\
   & = ||v|| ||v|| ||v|| ||b(v,v)||
\end{align*}
which implies $||b(v,v)|| = 0$, because $v \ne 0$, which implies that $b(v,v)$ is the zero vector. But does this also hold if $V$ is infinite-dimensional, if not can you give an example were it fails?","['cross-product', 'linear-algebra', 'orthogonality', 'functional-analysis']"
1136807,"Dividing the interval into $\rm\,n\,$ equal pieces. [Spivak - Calculus, Exercise 20]","I was doing exercise 20 of Spivak Calculus, it says (a) Find a function $\rm\,f\,$, other than a constant function such that $$\rm\,|f(x)-f(y)|\le|y-x|\,$$
  (b) Suppose that $\rm\,f(y)-f(x)\le(y-x)^2\,$ for all $\rm\,x\,$ and $\rm\,y\,$. (Why does this imply that $\rm\,|f(y)-f(x)|\le(y-x)^2\,$?) Prove that $f$ is a constant function. Hint: Divide the interval from $\rm\,x\,$ to $\rm\,y\,$ into $\rm\,n\,$ equal pieces. I could do (a) without much problem. But for (b) I couldn't do it after hours thinking. so i look up in the solution book I can't understand how he goes to the green. (what's the intuition?) For the first inequality it's easy to see because $$\rm|\sum_i a_i|\le\sum_i|a_i|$$ but then how does he go to the orange part? And how he goes to the yellow part? (riemann sums aren't introduced in that part). Also how can he concludes that $\rm\,f\,$ must then be constant? Limits aren't covered in that part, so you can't let $\rm\,n\to\infty\,$ Is this just a bad exercise to put in that section because i would never come up with that solution? thanks! $$\bbox[8pt,border:3px white solid]{\color{black}{\large}}$$","['inequality', 'calculus', 'algebra-precalculus']"
1136848,Unknown Taylor expansion,"I have come across a few apparently related Taylor expansions, as detailed below: \begin{align}
&\dots\frac{a^7}{140}-\frac{a^6}{80}-\frac{3 a^5}{40}-\frac{a^4}{8}+\frac{a^2}{2}+a+1&&=\exp \left(a-\frac{a^3}{6}\right)&\tag{1}\\
\\
&\dots\frac{11 a^7 b}{1120}+\frac{a^6 b}{32}+\frac{a^5 b}{40}-\frac{a^4 b}{16}-\frac{a^3 b}{4}-\frac{a^2 b}{4}+\frac{b}{2}&&=?&\tag{2}\\
\end{align} The first was fairly easy to guess the closed form on the RHS, but the bottom one I am stuck on. The extra $b$ is obviously doing something to the coefficients, but I don't know what. Are there any good strategies for finding a closed form for $(2$)? Unfortunately, I don't have any background information on them, so much is pure guesswork. Update All known coefficients  for $(2)$: $$\frac{1}{2},0,-\frac{1}{4},-\frac{1}{4},-\frac{1}{16},\frac{1}{40},\frac{1}{32},\frac{11}{1120},-\frac{1}{1280},-\frac{43}{20160}$$","['power-series', 'sequences-and-series', 'taylor-expansion']"
1136851,Why is it useful to know when a linear operator on a vector space is diagonalizable?,"I'm currently taking a conceptual course in linear algebra, and I'm trying to understand why it would be theoretically useful or illuminating to know when a linear operator (or its matrix representation) is diagonalizable. Why is this? How does it help us to more deeply understand vector spaces, linear operators, their applications, etc.?","['linear-transformations', 'matrices', 'linear-algebra', 'diagonalization']"
1136859,Curve from curvature,It is possible to obtain the parameters of a curve in 2d simply by having only its curvature k(s)? I need to obtain its parametric equations in order to reconstruct the curve but i don't have any idea how or even if its possible? I try to search on internet but i couldn't find anything related to the problem.I even look into different differential geometry books but i couldn't found anything related to the problem,['differential-geometry']
1136885,Solve $x^2f''(x)+f(x)=0$ check my answer,"I'd just like someone else to review my answer, I'm  preparing for an exam and I saw this question but a solution was not included with it, and the result is...somewhat unpleasant, It's not feasible to derive it twice and check that it is indeed a solution. Ok, so the question is to solve the ODE $x^2f''(x)+f(x)=0$, it's not with constant coefficients so there is no set method, but we do have a hint: define $t=\ln{x}$ Ok, so $e^{2t}f''(e^t)+f(e^t)=0$ is what we want to solve. Let's look at the function $g(t)=f(e^t)$: $g'(t)=e^tf'(e^t)$, and $g''(t)=e^tf'(e^t)+e^{2t}f''(e^t)$ We can see that $g''(t)-g'(t)+g(t)=e^{2t}f''(t)+f(e^t)$. So solving $g''(t)-g'(t)+g(t)=0$ is equivalent to solving our original question. Using the method of finding the roots of the characteristic polynomial, the solutions are $g_1(t)=e^{\frac{1}{2}t}\cos(\frac{\sqrt{3}}{2}t)$ and $g_2(t)=e^{\frac{1}{2}t}\sin({\frac{\sqrt{3}}{2}t})$ And the most general solution is $g(t)=f(e^t)=c_1e^{\frac{1}{2}t}\cos(\frac{\sqrt{3}}{2}t)+c_2e^{\frac{1}{2}t}\sin({\frac{\sqrt{3}}{2}t}) $ But since our original question was in the sense of $x$, not $t$, our final answer should be $f(x)=c_1e^{\frac{1}{2}\ln x}\cos(\frac{\sqrt{3}}{2}\ln x)+c_2e^{\frac{1}{2}\ln x}\sin({\frac{\sqrt{3}}{2}\ln x})$ Is this result correct?","['ordinary-differential-equations', 'calculus', 'proof-verification', 'derivatives']"
1136891,Discrete Math - Finding the integer solutions of an inequality,"For couple of hours I'm contemplating on this question: How many non-negative integer solutions of the inequality $x_1 + x_2 + x_3 + \ldots + x_6 < 10$? I've come up with a solution with the aid of my notes: By adding x$_7$ which is greater than 0 we can rewrite as, $x_1 + x_2 + x_3 + \ldots + x_6 +x_7= 10$ where $0 \leq x_i, \space 1 \leq i \leq 6$ and  $0 < x_7$ so we can supply $y_i=x_i$ and $y_7=x_7 - 1$ 
Then the equation becomes, $$y_1+y_2+y_3 + \dots +y_6+y_7 = 9$$ This is $C(15, 9)$ Although it is all fine, the point that I couldn't understand is: Why are we supplying a new variable and subtracting $1$ from the one that we initially added in?","['inequality', 'discrete-mathematics', 'combinatorics']"
1136914,How are ∈ and ⊂ defined to be relations?,"I understand a relation to mean, for elements $x\in X$, $y\in Y$ and for subset $R\subset X\times Y$, if $(x,y)\in R$ then $x$ is in the relation $R$ to $y$. But how are $\in$ and $\subset$ defined as relations if they're assumed in the definition of a relation?","['relations', 'elementary-set-theory']"
1136951,Is this understanding of indexed collections correct?,"I am currently trying to study set theory. A professor at my school was kind enough to lend me a book (The Joy of Sets) and I just want to make sure I understand this correctly, before moving on. The book defined indexed collections and intersections of set, and I think I understand the definition. Looking at the definition, I understand it to be something like this: $X_1 \cup X_2 \cup X_3 \cup X_i$ where I is the set of numbers {1,2,3... i} and a similar concept for intersection. But, I'm not sure if I'm understanding it when its applied to another case. For example, theres an exercise in the book that says ""Prove that $\cup_{i \in I}(x_i  \cup y_i) = (\cup_{i \in I}x_i) \cup (\cup_{i \in I}y_i)$ If I were to write the first part out, would it be something along the lines of: $(x_1 \cup y_1) \cup (x_2 \cup y_2) \cup (x_3 \cup y_3) \cup ...(x_i \cup y_i)$ ? Or if the statement was, $\cup(z - x_i)$, is that equivalent to $(z - x_1) \cup (z - x_2) \cup (z - x_3)... (z - x_i)$? Is that correct or is my understanding wrong?",['elementary-set-theory']
1136973,How to prove the function $\sin(x)$ is not onto,"\begin{align}
f:\mathbb{R}\rightarrow\mathbb{R},\:f\left(x\right)=\sin\left(x\right)\tag{1}
\end{align}
I know that it is not onto because for all values of $y$ past $[-1,1]$ there is no $x$. Graphically it makes sense but I'm finding it hard to do an actual proof for this function.","['algebra-precalculus', 'elementary-set-theory', 'functions']"
1136987,Projection of fiber bundle is a submersion,"I'm just wondering about my proof for the following fact. I get the feeling it is almost trivial but I am still getting a feel for geometry and so it doesn't seem 'obvious' to me just yet. The projection $\pi$ of the fiber bundle $(E,\pi,M,F)$ is a submersion. Is the below argument a correct proof of this fact? Would it be considered 'the obvious' proof? To show $\pi$ is a submersion, we must show that for each $p\in E$, the differential $d\pi_p:T_pE\rightarrow T_{\pi(p)}M$ is surjective. Since, $(E,\pi,M,F)$ is a fiber bundle, there exists a neighbourhood $U\subseteq M$ containing $\pi(p)$ and diffeomorphism $\phi:\pi^{-1}(U)\rightarrow U\times F$ , such that $\pi|_{\pi^{-1}(U)}=\pi_1\circ \phi:\pi^{-1}(U)\rightarrow U$. Thus, showing $d\pi_p$ is surjective is equivalent to showing $d(\pi_1\circ \phi)_p={d\pi_1}_{\phi(p)}\circ d\phi_p$ is surjective. Since $\phi$ is a diffeomorphism, $d\phi_{p}$ is an isomorphism, so it is surjective. Furthermore, ${d\pi_1}_{\phi(p)}$ is surjective since projection onto the first factor is a submersion. Since the composition of two surjections is a surjection itself, it follows that ${d\pi_1}_{\phi(p)}\circ d\phi_p=d\pi_p$ is surjective. Thus, $\pi$ is a submersion.","['geometry', 'vector-bundles', 'differential-geometry', 'fiber-bundles', 'riemannian-geometry']"
1137009,Proof that all rational maps $\mathbb{P}^1\to\mathbb{P}^N$ are regular without using codimension?,"There is a theorem in Shafarevich's Basic Algebraic Geometry (Theorem 3, pg. 109) which states that if $X$ is a nonsingular variety, and $\varphi\colon X\to\mathbb{P}^N$ a rational map to projective space, then the set of points at which $\varphi$ is not regular as codimension $\geq 2$. So if $X=\mathbb{P}^1$, this immediately implies that every rational map $\mathbb{P}^1\to\mathbb{P}^N$ is also regular. Is there a way to see this in a more ""down-to-earth"" way, I feel like this theorem is a bit overkill for the result. Thanks.",['algebraic-geometry']
1137040,"Integrating $ \int \frac{1}{\sqrt{x^2+4}}\,dx $ using Trigonometric Substitution","I'm reviewing integration by trigonometric substitution in anticipation of covering it in class next week.  I seem to be a bit rusty and keep catching myself making various mistakes.  On this particular problem I keep getting the same answer which is very close to being correct.  However, I somehow end up dividing by two where I should not.  I'm hoping another set of eyes can quickly set me right so I can stop frustrating myself reworking the problem to the same apparently wrong answer repeatedly!  Thanks in advance! The problem asks to solve: $$
\int \frac{1}{\sqrt{x^2+4}}\,dx
$$ The answer is given as: $$
ln\lvert x + \sqrt{x^2+4} \rvert + C
$$ Somehow I keep getting: $$
ln\Bigg|\frac{\sqrt{x^2+4}}{2} + \frac{x}{2}\Bigg| + C
$$ Here's my work: $$
\int \frac{1}{\sqrt{x^2+4}}\,dx = \int \frac{1}{\sqrt{4(\frac{1}{4}x^2+1)}}\,dx = \frac{1}{2}\int\frac{1}{\sqrt{\frac{1}{4}x^2+1}}\,dx = \frac{1}{2}\int\frac{1}{\sqrt{(\frac{1}{2}x)^2+1}}\,dx
$$ At this point I substitute as follows: $$
\frac{1}{2}x = \tan\theta
$$
$$
x = 2\tan\theta
$$
$$
dx = 2\sec^2\theta
$$ So I continue on with: $$
\frac{1}{2}\int\frac{2\sec^2\theta}{\sqrt{\tan^2\theta+1}}\,d\theta = \int\frac{\sec^2\theta}{\sqrt{\sec^2\theta}}\,d\theta = \int\frac{\sec^2\theta}{\sec\theta}\,d\theta = \int\sec\theta\,d\theta = ln\lvert\sec\theta + \tan\theta\rvert + C
$$ Finally, to get the answer in terms of x I essentially draw a right triangle and use the fact that $\tan\theta = \frac{x}{2}$.  The side opposite $\theta$ I take to be x, the side adjacent $\theta$ is 2, and the hypotenuse is $\sqrt{x^2+4}$.  So $\sec\theta = \frac{\sqrt{x^2+4}}{2}$ and $\tan\theta = \frac{x}{2}$. So, substituting these values back in, as mentioned, I end up with: $$
ln\Bigg|\frac{\sqrt{x^2+4}}{2} + \frac{x}{2}\Bigg| + C
$$ Can anyone help me see where I'm going wrong or failing to understand something?","['trigonometry', 'calculus', 'integration', 'indefinite-integrals']"
1137060,stable marriage algorithm problem,"Better of the two Suppose that in the stable marriage problem with $n$ men and $n$ women, we have found two (possibly different) stable matchings $S$ and $T$. We will show how to combine $S$ and $T$ into two new stable matchings $W$ and $M$, which are the best of both worlds for the women and men respectively. Each woman is given the name of the man she is matched with in $S$ and the one she is matched with in $T$ (note that they might be the same man). Of the two names each woman receives, she picks the one she prefers the most.
Prove that no two women would end up picking the same man. Conclude that if women are matched with the men they pick, the result is a matching. Call this matching $W$. Prove that $W$ is a stable matching. Another way of combining the matchings $S$ and $T$, is to give each man the names of the women he is matched with in $S$ and $T$ and force each man to pick the woman he prefers the least amongst the two. Prove that this results in the same stable matching $W$ as before. How would you combine the matchings $S$ and $T$ to create stable matching $M$, which is the best of both worlds for the men? Just think about how $M$ related to $W$. I have studied stable marriage algorithm but i do not have a clue on this one.","['game-theory', 'discrete-mathematics', 'combinatorial-game-theory']"
1137063,Cantor's Theorem Paradox? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. This question is not about mathematics, within the scope defined in the help center . Closed 9 years ago . Improve this question Cantor's Theorem states that the cardinality of the power-set of any set is strictly greater than the cardinality of the set. That is to say, that you cannot establish a bijection between a set and its power-set. I seem to have found two counter-examples, and I would like to know what is my error. Let's consider the set of natural numbers plus zero, $N=\{0,1,2, ...\}$ and the set of powers of two, $B=\{2^0,2^1,2^2, ...\}$. It is trivial that $|N|=|B|$. You can easily establish a bijection $f$ between $N$ and $\mathcal{P}(B)$ by corresponding every natural number with its binary representation. $$f(0)\rightarrow \emptyset$$
$$f(1)\rightarrow \{{2^0\}}$$
$$f(2)\rightarrow \{{2^1\}}$$
$$f(3)\rightarrow \{{2^0,2^1\}}$$
$$f(4)\rightarrow \{{2^2\}}$$
$$f(5)\rightarrow \{{2^0,2^2\}}$$ ... and so on. This is a bijection because each natural number has a unique binary representation and any sum of powers of two equals a unique natural number. But this is not possible according to the Cantor's Theorem. (Note: In fact, in my exposition the bijection is between the set and the power-set of a subset, but it is trivially equivalent.) The other example is even worse and it is based on prime factorization. In this case I use the set of prime numbers, and I proceed in a similar way, but I establish a surjection between the power-set of the primes onto the naturals plus zero. Each natural number is corresponded with its prime factorization. In this case, each natural number has a unique prime factorization, but every subset of the prime number set is corresponded with infinite natural numbers as seen in the following examples: $$g(1)\rightarrow \emptyset$$
$$g(2)\rightarrow \{2\}$$
$$g(3)\rightarrow \{3\}$$
$$g(4=2^2)\rightarrow \{2\}$$
$$g(6=2\cdot3)\rightarrow \{2,3\}$$ Implying that $|\mathcal{P}(N)|<|N|$! Where is the problem?",['elementary-set-theory']
1137064,Existence of a Pythagorean Triple with one side given.,I am curious about the answer to the question: Does there exists a pythagorean triple with $n$ as one of the sides for all $n\geq 3$ ?. Your answers and comments will mean a lot.,"['pythagorean-triples', 'number-theory']"
1137095,Give $\ker(\phi)$ for $\phi: \mathbb{Z} \to \mathbb{Z_7}$ such that $\phi(1)=4$,"Give $\ker(\phi)$  for $\phi: \mathbb{Z} \to \mathbb{Z_7}$ such that $\phi(1) = 4$ So the generator of $\mathbb{Z}$ maps to $4$ and $\langle 4 \rangle = \{0,1,2,3,4,5,6\}$ so it has order seven. so $\ker(\phi) = 7\mathbb{Z}$ because every seventh element will map to the identity under the given map. Is that the correct reasoning?","['group-theory', 'abstract-algebra']"
1137102,Dot product for 3 vectors,The dot product can be used to write the sum: $$\sum_{i=1}^n a_i b_i$$ as $$a^T b$$ Is there an equivalent notation for the following sum: $$\sum_{i=1}^n a_i b_i c_i$$,"['notation', 'linear-algebra']"
1137122,Approximation of the binomial distribution,"Let $S_n=\dfrac{B_n - np}{\sqrt{n\cdot p\cdot (1-p)}}$ be a random variable which has the standardized binomial distribution. From Chebyshev's inequality I know that $$P(|S_n| \ge x) \le \frac{1}{x^2}$$ Is there also a good approximation of the form $P(|S_n| \ge x) \ge \ldots\,{}$?","['probability-theory', 'probability-distributions', 'inequality', 'reference-request']"
1137129,"If $L,K$ fields, and $L(\alpha)=K(\alpha)$ then $L=K$","The question appeared in my mind when I was studying Field Extension(preparation for Galois Theory). It is trivial that if $L=K$, and $\alpha$ algebraic over $L$ and $K$, then $L(\alpha)$=$K(\alpha)$ Is it always true that If $L,K$ fields, $L(\alpha)=K(\alpha)$, and $[K(\alpha):K]=[L(\alpha):L]$  then $L=K$? I think it is true and I try to prove it via the following statements: It is clear that the smallest field containing $L$ and $\alpha$ is equal to the the smallest field containing $K$ and $\alpha$. Then the smallest field $F$ containing $L,K,\alpha$ is equal to both $L(\alpha)=K(\alpha)$. Thus $F\subset L(\alpha)$ implies $K\subset L(\alpha)$. Then we can conclude that $K\subset L$ Similarly, $L\subset K$ Finally, $L=K$ ============================ Thank you all guys for providing trivial or non-trivial examples, the statement is clearly false.","['abstract-algebra', 'field-theory']"
1137134,Derivative of an integral with respect to a function,"Can some one help me out this derivative:
$$
\frac{\partial\int_{-\infty}^\infty f(x)g(x)\,dx}{\partial g}
$$ Appreciate any explanation! Many thanks to those who answered or commented on my question! Maybe I am not very clear about my question or I might have misunderstood what I need. I was reading a Quantum Field Theory textbook and trying to verify the following equation:
$$
\langle 0\mid 0\rangle_{f, h} = \int Dp\,Dq \exp \left[i\int_{-\infty}^\infty dt(p\dot q-H_0(p, q)-H_1(p, q)+fq+hp)\right]
$$
$$
=\exp \left[ -i\int_{-\infty}^\infty dt \, H_1 \left( \frac 1 i \frac \delta {\delta h(t)}, \frac 1 i \frac{\delta}{\delta f(t)} \right) \right]\times \int Dp\,Dq\, \exp \left[ i\int_{-\infty}^\infty dt\,(p\dot q-H_0(p, q)+fq+hp) \right]
$$ I expanded the first exponential of the second line to a Taylor series. Thus every term is a derivative with respect to either $h(t)$ or $g(t)$. And then I got lost. I guess this is related to functional derivatives and I tried to search some examples but I failed. Or maybe it's just I didn't realize I have seen the same thing because of my poor math.","['calculus', 'functional-analysis', 'derivatives']"
1137156,Improper integrals with singularities on the REAL AXIS (Complex Variable),"I'm having some troubles when I try to solve improper integrals exercises that have singularities on the real axis. I have made a lot of exercises where singularities are inside a semicircle in the upper half side, but I don't know how to solve them when the singularities are on the real axis.
I read some books but I think they are not very good explained (at least, I can't understood them). This is the exercise:
$$\int_{-\infty}^{\infty} \frac{\cos(2\pi x)}{x^2-1} dx$$ Using complex variable, I have: $$f(z) =\frac{e^{i2\pi z}}{z^2-1}$$
so there are 2 singularities:
$z_1 = -1$ and $z_2 = 1$ I use a curve $C$ that is holomorphic inside it, because both singularities are out of it. Of course, I can divide $C$ in 6 curves: $C_R$ that is the ""roof"" of the curve and, using Jordan's Lemma, I can prove that $$\int_{C_R}^{ } \frac{e^{i2\pi z}}{z^2-1} dx = 0$$ but I don't know what do I have to do now. I saw in some places they said that the Residue Theorem over the semicircle around the singularities was something like: $$-i\pi\sum{}{}Res[f(z), z_k]$$ but I didn't understand why. I hope you can help me, because I don't know what can I do.
Thanks!!","['improper-integrals', 'integration', 'complex-integration', 'complex-analysis', 'contour-integration']"
1137168,Question about complete orthonormal basis,"Let $V$ be an inner product space. Let $W$ be the Hilbert space obtained as the completion of $V$. Is there a complete orthonormal basis of $V$ which is still complete in $W$? This is true if we assume that $V$ is separable (Schumidt's method), but I don't know if this is true or not in general.",['linear-algebra']
1137175,Is $C(\mathbb R)$ Complete?,"I'm trying to prove an exercise from Carthers' book chapter10 of Real Analysis, problem claimed as, where $C(\mathbb R)$ denote the infinity norm space of all continuous functions on real line. I tried to use the hint. However, I got an counterexample that probably works for incomplete $C([-n,n])$. That is: $f_n(x) = x^{2n}$ does not converge to a continuous function in $C([-1,1])$.
Where is my fault?","['metric-spaces', 'functional-analysis', 'real-analysis']"
1137213,Evaluating solutions for a given trigonometric equation over a specified interval,"This question is similar in form to this one: Finding all Trigonometric Solutions of an Equation within a Given Interval However, I want to verify my method of solving, as it would appear I have made some logical error in my processes. My method goes as follows: Solve for $\theta$ over the interval $[0, 2\pi)$ $\sqrt{2}\sin{\theta} = \sqrt{\sin{\theta}+1}$ $(\sqrt{2}\sin{\theta})^2 = (\sqrt{\sin{\theta}+1})^2$ $2\sin^2{\theta} = \sin{\theta} + 1$ $\sin^2{\theta} = \dfrac{\sin{\theta} + 1}{2}$ $\dfrac{1-\cos{2\theta}}{2} = \dfrac{\sin{\theta} + 1}{2}$ $1-\cos{2\theta} = \sin{\theta} + 1$ $-\cos{2\theta} = \sin{\theta}$ $0 = \sin{\theta} + \cos{2\theta}$ Then solve for $\theta$. $\sin{\dfrac{1\pi}{2}} = 1$ $\cos{\dfrac{2\pi}{2}} = \cos{\pi} = -1$ Therefore $\theta = \dfrac{\pi}{2}$ I was told my method was incorrect. I don't see where.",['trigonometry']
1137217,Application of Cauchy-Schwarz with Sobolev norms,"I'm working through the problems in the initial value formulation chapter in Wald's General Relativity . A short summary of the problem. I have to show that $$\sup_{x\in A}|f(x)|\le C||f||_{A,k}$$ where $A\subset \mathbb{R}^n$ satisfies the uniform interior cone condition, $C$ is a constant, $k>n/2$ is an integer and $||.||_{A,k}$ is the Sobolev norm. Let $Q$ denote the solid closed cone in $\mathbb{R}^n$ of height $H$ and solid angle $\Omega$, with vertex at the origin. Let $\psi:\mathbb{R}\longrightarrow\mathbb{R}$ be a $C^\infty$ function with $\psi(r)=1$ for $r<H/3$ and $\psi(r)=0$ for $r >2H/3$. I have shown that
$$\tag{1}f(0)=C_1\int_{Q\subset\mathbb{R}^n} r^{k-n}\frac{d^k}{dr^k}(\psi f)\,dx$$
The hint says to show
$$\tag{2}|f(0)|\le C||f||_{Q,k}$$
using Cauchy-Schwarz. From this I can obtain the final result using the uniform interior cone condition. Any help would be greatly appreciated. EDIT: I should be using Cauchy-Schwarz with the $L^2$ inner product, not the Sobolev one. I can write
$$f(0)=C_1\langle r^{k-n},\partial_r^k(\psi f)\rangle_{L^2}$$
and thus
$$\tag{3}|f(0)|\le C_1 ||r^{k-n}||_{L^2}\cdot ||\partial^k_r(\psi f)||_{L^2}$$
For the first factor I get
$$||r^{k-n}||_{L^2}=\int_Q |r^{k-n}|^2\,dx=\int_Q r^{2k-2n}\,dx=\int_Q r^{2k-2n}r^{n-1}\,drd\Omega=C_2$$
a constant, iff $k>n/2$. Putting this into (3), I get
$$\tag{4}|f(0)|\le C_3||\partial^k_r(\psi f)||_{L^2}$$
I can obtain (2) by showing that
$$||\partial^k_r(\psi f)||_{L^2}\le C_4 ||f||_{Q,k}$$
Intuitively, this is clear, because $||f||_{Q,k}$ contains ""more terms"" which are all positive. But my problem then lies with the equals in $\le$. I don't see how it could be anything other than strictly larger, but since I'm using my gut here, I could very well be wrong. EDIT 2: I guess the equality could hold based on the precise form of $\psi$ perhaps, but I'm still not sure.","['multivariable-calculus', 'inner-products', 'inequality', 'partial-differential-equations', 'real-analysis']"
1137219,Applying geometric calculus to a matrix expression,"Let $f(\mathbf x) = \mathbf x^T A \mathbf x + \mathbf b^T\mathbf x + c$, where $A$ is a square matrix, $\mathbf x, \mathbf b$ are column matrices and $c$ is a constant.  Then the gradient of this expression is $\nabla f(\mathbf x) = (A+A^T)\mathbf x + \mathbf b$.  I see how to derive this by interpretting the gradient as the matrix operator $D$.  I'm wondering if we could get the same answer if we used the geometric gradient defined by $\nabla = \sum_i \mathbf e^i \partial_i$.  So I'd like to know how to use geometric calculus on this matrix expression.  Is there a way to do this?  Thanks.","['multivariable-calculus', 'geometric-algebras']"
1137220,construct a counterexample in measure theory,"Problem:
Construct a $\sigma$-algebra $\mathscr{F}$ of subsets of $R$ such that no open interval is measurable with respect to $\mathscr{F}$, although any singleton $\{x\}$ is ($x\in R$). I tried to construct an example like the complement of any open interval is not in $\mathscr{F}$, but I did not make it. Can someone give a hint?","['probability-theory', 'measure-theory', 'lebesgue-measure', 'real-analysis']"
1137225,"Use the maximum likelihood to estimate the parameter $\theta$ in the uniform pdf $f_Y(y;\theta) = \frac{1}{\theta}$ , $0 \leq y \leq \theta$","(a) Based on the random sample $Y_1 = 6.3$ , $Y_2 = 1.8$, $Y_3 = 14.2$, and $Y_4 = 7.6$, use the method of maximum likelihood to estimate the parameter $\theta$ in the uniform pdf $f_Y(y;\theta) = \frac{1}{\theta}$ ,   $0 \leq y \leq \theta$ (b) Suppose the random sample in part (a) represents the two-parameter uniform pdf $f_Y(y;\theta_1, \theta_2) = \frac{1}{\theta_2 - \theta_1}$ ,   $\theta_1 \leq y \leq \theta_2$ Find the maximum likelihood estimates for $\theta_1$ and $\theta_2$. My attempt (a) The likelihood function is given by 
$L(\theta)= \Pi_{i = 0}^{n}\frac{1}{\theta} = \theta^{-n} $ Take natural log both sides, so ln$L(\theta) = - n$ ln($\theta)$
Take derivative and set it equal to zero.
Thus, $\frac{d}{d\theta}$ln$L(\theta)$ = -$\frac{n}{\theta}$ if we try to solve for theta equal to zero it wont work. So we have to reduce the the 
value for $y$ as much as possible. So choose the value of $\theta_e = y_{min} = 1.8$ (b) since the range is dependent on $
\theta$, finding the derivative equal to zero won't work. So the maximun likelihood for $\theta_1e = 14.2$ and the maximun likelihood for $\theta_2e = 1.8$ Can anyone please verify this? If this does not work, can someone please help? Any feedback/hint would help.
Thank you in advance.","['statistics', 'probability', 'parameter-estimation']"
1137250,Evaluating $ \int_{-\pi /2014}^{\pi /2014}\frac{1}{2014^{x}+1}\left( \frac{\sin ^{2014}x}{\sin ^{2014}x+\cos ^{2014}x}\right) dx $,The following integration problem appears in our calculus assignment: $$ \int \limits_{-\pi /2014}^{\pi /2014}\dfrac{1}{2014^{x}+1}\left(\dfrac{\sin ^{2014}x}{\sin ^{2014}x+\cos ^{2014}x}\right) dx .$$ But the problem is I have no idea how to begin this problem. Could anyone give me some help ? Any hints/ideas are much appreciated.,"['calculus', 'integration', 'definite-integrals', 'real-analysis', 'analysis']"
1137263,Maximum of *Absolute Value* of a Random Walk,"Suppose that $S_{n}$ is a simple random walk started from $S_{0}=0$.
Denote $M_{n}^{*}$ to be the maximum absolute value of the
walk in the first $n$ steps, i.e., $M_{n}^{*}=\max_{k\leq n}\left|S_{k}\right|$. What is the expected value of $M_{n}^{*}$? Or perhaps a bit easier,
asymptotically, what is $\lim_{n\to\infty}M_{n}^{*}/\sqrt{n}$? This question relates to https://mathoverflow.net/questions/150740/expected-maximum-distance-of-a-random-walk , but I need to obtain the value of the multiplicative constant. Thanks!","['probability-theory', 'stochastic-processes', 'random-walk']"
1137297,Can someone verify this direct modulus proof?,"This is from Discrete Mathematics and its applications To do this proof, I used this mod property Here is my work What I did was basically expand both sides of (a-c) mod m and (b - d) mod m with that property. Then I saw that with what I was given, the two sides looked the same.
I am not sure if you're allowed to use that property to do this though.","['modular-arithmetic', 'proof-writing', 'discrete-mathematics', 'proof-verification']"
1137336,What am I doing wrong when multiplying binary numbers together?,"This is from Discrete Mathematics and its applications I was able to get sum pretty easy. I am trying to follow this example in the book to get the product of the two binary numbers Here's my work so far I got the expected output from my calculator windows application. Does anyone see what the issue is? The problem starts when I don't get 7 zeros separating the first two ones. What would you do with the end result, 8? I am still not sure about that.","['binary-operations', 'computer-science', 'discrete-mathematics', 'binary']"
1137364,Having trouble solving part two of an equation:,"Part one consisted of proving that 
$$\frac{x-1}{x-3} = 1+ \frac{2}{x-3}$$
I completed this and here is my working:
$$let \frac{x-1}{x-3}= LHS$$
$$RHS=\frac{x-3}{x-3} + \frac{2}{x-3}$$
$$\frac{2+(x-3)}{(x-3)}$$
$$\frac {x-3+2}{x-3}$$
$$\frac {x-1}{x-3} = LHS$$ Part two then asks me to hence solve: $$\frac{x-1}{x-3}-\frac{x-3}{x-5} = \frac{x-5}{x-7}−\frac{x-7}{x-9}$$ I have attempted to sub in part one into part two but my answers always turn out to be incorrect. 
Any tips in the matter would be much appreciated. I'd like to thank anyone who comments and answers in advance, your help is much appreciated.",['algebra-precalculus']
1137374,Taylor's theorem on manifold,"Taylor's theorem for real-valued functions on manifolds is straightforward, and doesn't even require anything beyond differential structure. How does Taylor's theorem work for manifold-valued functions? Suppose you have a function $f:\mathbb{R}\to M$, where $M$ is a manifold (i.e., $f$ is a curve on $M$). Is there some notion of a Taylor's theorem on $M$, i.e., a way to write $f(t)$ only in terms of $f$ and its derivatives at $t=0$? I assume at minimum $M$ needs a connection, since otherwise I'm not sure how to even define the second and higher-order derivatives of $f$. With a metric one can define a ""first-order approximation"" of $f$ by $$f(t) \approx \exp_{f(0)} \left[t f'(0)\right]$$ but what would the higher-order approximations look like?","['differential-geometry', 'taylor-expansion']"
1137385,Evaluating $\lim_{h \to 0}\frac{(x+h)^{\frac15}-x^{\frac15}}{h}$,"The limit is:
$$
  \lim_{h \to 0}\frac{(x+h)^{\frac15}-x^{\frac15}}{h}
$$ When I use calculator and substitute $h$ with $0.000001$ and $-0.000001$, the result is: $$
  \frac{1}{5x^{\frac45}}
$$ My question is: How to do it without calculator. Show me the steps on how it's being done.",['limits']
1137386,The Boolean algebra of regularly open sets in a topological space is complete,"To prove that regular open (Boolean) algebra is complete, I tried to show following claim, but I couldn't. I saw this statement in Kunen's 'Set Theory' p.64 but in other books what I checked, describing regular open algebra, there is no mention of the infimum of an arbitrary family of regular open sets. Is the claim really true? or an errata? Context . $X$ is a topological space. Definition . $b\subset X$ is a regular open set iff $b=\rm{int}(\rm{cl}(b))$ and $b$ is open. $\rm{ro}(X)$ is the set of all regular open sets in $X$. Context . $\{{b_i}\}_{i\in I}$ is a family of regular open sets Claim . $\rm{int}(\underset{i\in I}{\bigcap}b_i)$ is a regular open set. (so that any subset of $\rm{ro}(X)$ has infimum)","['general-topology', 'set-theory', 'boolean-algebra']"
1137395,Can you have a gradient of time?,"Okay this maybe a very stupid question but in my calculus III class we introduced the gradient but I am curious why don't we also include the derivative of time in the gradient. Thanks, math noob",['multivariable-calculus']
1137420,Verification of product rule for covariant derivatives. Stuck on one step involving simplifying terms to yield zero.,"I am trying to learn more about covariant differentiation. I'm specifically interested in physics applications, but I found this nice exercise in Misner, Thorne, and Wheeler's book Gravitation that I thought would help me get more familiar with the concept. It's purely math. Specifically, the task is to prove the product rule for covariant differentiation. Let $\text{S}^{\alpha\beta}_{\gamma}$ be a $(2,1)$ tensor field, and let $\text{M}^{\gamma}_{\beta}$ be a $(1,1)$ tensor field. By contracting these tensor fields, one obtains the vector field $\text{S}^{\alpha\beta}_{\gamma}\text{M}_{\beta}^\gamma$. The divergence of this vector field reads
  \begin{equation}
(\text{S}^{\alpha\beta}_{\gamma}\text{M}_{\beta}^\gamma)_{;\alpha}=\text{S}^{\alpha\beta}_{\gamma;\alpha}\text{M}_{\beta}^\gamma+\text{S}^{\alpha\beta}_{\gamma}\text{M}_{\beta;\alpha}^\gamma
\end{equation}
  Verify the validity of this product rule by expressing both sides of the equation in terms of directional derivatives plus connection-coefficient corrections. Here's what I did, I started with the left hand side of the equation. Note, I use the Einstein summation convention. LHS: 
  \begin{align*}
(\text{S}^{\alpha\beta}_{\gamma}\text{M}_{\beta}^\gamma)_{;\alpha}&=\partial_{\alpha}(\text{S}^{\alpha\beta}_{\gamma}\text{M}_{\beta}^\gamma)+\Gamma^{\alpha}_{\lambda\alpha}\text{S}^{\lambda\beta}_{\gamma}\text{M}_{\beta}^{\gamma}\\&=(\partial_{\alpha}\text{S}^{\alpha\beta}_{\gamma})\text{M}_{\beta}^\gamma + \text{S}^{\alpha\beta}_{\gamma}(\partial_{\alpha}\text{M}_{\beta}^\gamma) + \Gamma^{\alpha}_{\lambda\alpha}\text{S}^{\lambda\beta}_{\gamma}\text{M}_{\beta}^{\gamma}
\end{align*}
  I then decided to do some work on the right-hand side. RHS:
  \begin{align*}
\text{S}^{\alpha\beta}_{\gamma;\alpha}\text{M}_{\beta}^\gamma+\text{S}^{\alpha\beta}_{\gamma}\text{M}_{\beta;\alpha}^\gamma&=\left((\partial_{\alpha}\text{S}^{\alpha\beta}_{\gamma})\text{M}_{\beta}^\gamma+\Gamma_{\alpha\lambda}^{\alpha}\text{S}^{\lambda\beta}_{\gamma}\text{M}_{\beta}^{\gamma}+\Gamma^{\beta}_{\alpha\lambda}\text{S}^{\alpha\lambda}_{\gamma}\text{M}_{\beta}^{\gamma}-\Gamma^{\lambda}_{\alpha\gamma}\text{S}^{\alpha\beta}_{\lambda}\text{M}_{\beta}^{\gamma}\right)\\&\phantom{x}+\left(\text{S}^{\alpha\beta}_{\gamma}(\partial_{\alpha}\text{M}_{\beta}^\gamma)+\Gamma^{\gamma}_{\alpha\lambda}\text{S}^{\alpha\beta}_{\gamma}\text{M}_{\beta}^{\lambda}-\Gamma^{\lambda}_{\alpha\beta}\text{S}^{\alpha\beta}_{\gamma}\text{M}_{\lambda}^{\gamma}\right)\\&=\left((\partial_{\alpha}\text{S}^{\alpha\beta}_{\gamma})\text{M}_{\beta}^\gamma + \text{S}^{\alpha\beta}_{\gamma}(\partial_{\alpha}\text{M}_{\beta}^\gamma) + \Gamma^{\alpha}_{\lambda\alpha}
\text{S}^{\lambda\beta}_{\gamma}\text{M}_{\beta}^{\gamma}\right)\\&\phantom{x}+ \left(\Gamma^{\beta}_{\alpha\lambda}\text{S}^{\alpha\lambda}_{\gamma}\text{M}_{\beta}^{\gamma}-\Gamma^{\lambda}_{\alpha\gamma}\text{S}^{\alpha\beta}_{\lambda}\text{M}_{\beta}^{\gamma}+\Gamma^{\gamma}_{\alpha\lambda}\text{S}^{\alpha\beta}_{\gamma}\text{M}_{\beta}^{\lambda}-\Gamma^{\lambda}_{\alpha\beta}\text{S}^{\alpha\beta}_{\gamma}\text{M}_{\lambda}^{\gamma}\right)\\&=\left((\partial_{\alpha}\text{S}^{\alpha\beta}_{\gamma})\text{M}_{\beta}^\gamma + \text{S}^{\alpha\beta}_{\gamma}(\partial_{\alpha}\text{M}_{\beta}^\gamma) + \Gamma^{\alpha}_{\lambda\alpha}
\text{S}^{\lambda\beta}_{\gamma}\text{M}_{\beta}^{\gamma}\right)+(0)
\end{align*} It's with the right hand side I got stuck. I should be able to somehow simplify \begin{equation}
\left(\Gamma^{\beta}_{\alpha\lambda}\text{S}^{\alpha\lambda}_{\gamma}\text{M}_{\beta}^{\gamma}-\Gamma^{\lambda}_{\alpha\gamma}\text{S}^{\alpha\beta}_{\lambda}\text{M}_{\beta}^{\gamma}+\Gamma^{\gamma}_{\alpha\lambda}\text{S}^{\alpha\beta}_{\gamma}\text{M}_{\beta}^{\lambda}-\Gamma^{\lambda}_{\alpha\beta}\text{S}^{\alpha\beta}_{\gamma}\text{M}_{\lambda}^{\gamma}\right)
\end{equation} to yield $0$, but I can't figure out how to do it. This would leave my right-hand and left-hand sides equal and thus completing the proof. But I am stuck on this one step. Any ideas? My Thoughts: I'm not sure what kind of manipulation I need to do. Do I need to manipulate indices? That seemed like a possibility. I have seen sometimes you can relabel dummy indices in a way that allows you to rearrange terms. But I can't tell if I can do that here. Another possibility is maybe I need to do some kind of factoring by multiplying by identity and then rearranging to somehow simplify so things cancel. I'm not sure if that's the right idea or even how I would do that, but that seemed like another possibility. Apart from that, I am stumped.","['riemannian-geometry', 'derivatives', 'differential-geometry']"
1137438,"How to humanly verify $ba^5ba=b^2a^4$ in the group with presentation $\langle a,b : a^7=1, b^3=1, ba^2=ab \rangle$?","The group with presentation $\langle a,b : a^7=1, b^3=1, ba^2=ab \rangle$ is isomorphic to $\mathbb{Z}_7 \rtimes \mathbb{Z}_3$ ( ref. ). Q : How can I (as a human) verify that $ba^5ba=b^2a^4$ in this group? Attempting to do this by hand became tedious quickly, although it's more than possible I didn't look in the right direction. (Perhaps there software that automatically generates a human-readable proof?) I can verify this identity on the computer:  If I understand correctly, this presentation is used for this group for $\mathbb{Z}_7 \rtimes \mathbb{Z}_3$ in GAP .  To check this: gap> G:=SmallGroup(21,1);;        
gap> StructureDescription(G);
""C7 : C3""
gap> P:=PresentationViaCosetTable(G);;
gap> TzPrintRelators(P);   
#I  1. f1^3
#I  2. f1*f2^2*f1^-1*f2^-1 Here we have $a$ given by f2 and $b$ given by f1 .  (I add in the relation $a^7=1$; it makes no difference.)  After setting the variables gap> a:=GeneratorsOfGroup(G)[2];
f2
gap> b:=GeneratorsOfGroup(G)[1];
f1 we can then check b*a^5*b*a=b^2*a^4; is true .  But it doesn't show me how it works, so it's not too helpful.","['gap', 'finite-groups', 'group-theory']"
