question_id,title,body,tags
535656,Constructing a differential equation for hyperbolic crochet,"There is plenty of information about hyperbolic geometry and its melding with crochet, however I have yet to find an exact equation for determining the number of stitches in each row. I will try to ask my question without including crochet terms. Let's say you have a row with a certain number of stitches, fox example 6. For every 2 stitches, you add 3 stitches on top. So the second row will have 9 stitches, and the third row will have 13.5 (ignore the decimals; in crochet you can't have half a stitch), then 20.25, 30.375, etc. Each row will be 1.5 longer than the previous. The circumference grows exponentially. Heuristically (plotting and adding a trendline in Excel) I know the equation to be s(r) = 4*Exp(0.405*r). 4 comes from 6/1.5, or initial stitches divided by rate. 0.405 is a constant of integration, solved using s(2) = 9. So I know I have to construct a differential equation, but the only form I can think of is s'(r) = 6*1.5*s(r). The change of stitches equals the number of initial stitches times the rate of increase times the current number of stitches of the previous row. How does the constant of integration find itself in the exponent when most solutions have the form s(r) = A*Exp(r)? Thanks for your help! edit: Changed 4 = 6*1.5 to 4 = 6/1.5","['hyperbolic-geometry', 'ordinary-differential-equations', 'exponential-function']"
535696,Learning roadmap for Non-commutative Geometry [closed],Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 10 years ago . Improve this question I am interested in learning Non-commutative geometry and K-theory of operator algebras. Please suggest a learning roadmap for this subject. My present knowledge of Measure theory & Functional Analysis is very little.Please advise which topics in Functional Analysis and Operator Theory should I learn before starting Alain Connes' book 'Non Commutative Geometry' and references for the same. What are other prerequisites for reading this book ?,"['noncommutative-geometry', 'operator-theory', 'operator-algebras', 'reference-request', 'functional-analysis']"
535697,Prove that this is a topology,"I have to prove that the following family defined in $\mathbb{R}^2$ is a topology. $\tau= \{U\subseteq \mathbb{R}^2:$ for any $(a,b) \in U$ exists  $\epsilon >0 $ where $[a,a+\epsilon] \times [b-\epsilon, b+\epsilon]\subseteq U\}$ I have started in the following way:
(i) 
$\emptyset, X \in\tau?$
any $(a,b)\in \mathbb{R}^2 $, exists $\epsilon >0$ where $[a,a+\epsilon]\times[b-\epsilon, b+\epsilon]\subseteq \mathbb{R}^2$ so $ X=\mathbb{R}^2 \subseteq \tau$ But I don't know how to prove that the empty set is in the topology. (ii) In the second, I have argued that taking $U_1, U_2\in \tau$, the intersection is going to be either the empty set or a set of this type: $[a,a+\epsilon] \times [b-\epsilon, b+\epsilon]$ Is it correct? (iii) To prove that for any $i\in I$ where $ U_i \in \tau, $ then the union of these sets is also in $\tau$ I got lost. Could you help me please? Thank you for your time and apologies for my poor writing.",['general-topology']
535720,What are the properties of the roots of the incomplete/finite exponential series?,"Playing around with the incomplete/finite exponential series $$f_N(x) := \sum_{k=0}^N \frac{z^k}{k!} \stackrel{N\to\infty}\longrightarrow e^z$$ for some values on alpha (e.g. solve sum_(k=0)^19 z^k/(k!) = 0  for  z ), I made a few observations: The sum of the roots of $f_N$ are $-N$ The product of the roots of $f_N$ are $(-1)^N\cdot N!$ Their imaginary part seems to lie between $\pm10$ The zeros seem to form an interesting shape: Patterns for $N=17, 18, 19$ Now the sum and product part are clear, since $$\begin{align}
  f_N(x) &= \frac1{N!}\left(z^N + N z^{N-1} + N(N-1)z^{N-2} + ... + N!\right)
\\ &= \frac1{N!}(z-z_{N0})(z-z_{N1})\cdots(z-z_{NN})
\\ &= \frac1{N!}\left(z^N - \left(\sum_{k=0}^Nz_{Nk}\right) z^{N-1} + ... + (-1)^N\prod_{k=0}^N z_{NK}\right)
\end{align}$$ and since $e^z=0 \Leftarrow \Re z\to-\infty$ it is clear that the roots tend towards real parts with negative infinity, but I'm still intrigued by the questions what ($N$-dependent) curve do the zeros of $f_N(z)$ lie on, does that curve maintain its shape for varying $N$ and merely translate or also deform; and what other properties of the zeros (e.g. absolute value) can be derived?","['sequences-and-series', 'roots', 'exponential-function', 'complex-analysis', 'taylor-expansion']"
535725,Is $GL(n;R)$ closed as a subset of $M_n(R)$?,"Let $M_n(R)$ denote the space of all $n×n$ matrices with real entries. The general linear group over real numbers,denoted $GL(n,R)$, is given by $GL(n,R)=${$A∈M_n(R)|det(A)\neq0$}.           Is $GL(n,R)$ closed as a subset of $M_n(R)$? Some thought of mine:Obviously,there exists a sequence $A_n$ in $GL(n,R)$ such that $A_n$ tends to $A$ as $n$ to infinity where $A$ is not invertible.For instance,considering $n=2$,let $A_n=\begin{pmatrix} 1 && 0\\ 0 && \frac{1}{n}\end{pmatrix}$.Then $limA_n=A=\begin{pmatrix} 1 && 0\\ 0 && 0\end{pmatrix} ,n\to{+\infty}$,where $det(A)=0$.The example tells us that $GL(n,R)$ is not closed in $M_n(R)$. How can we prove $GL(n,R)$ is open in $M_n(R)$ directly and strictly?And how do you define the topology in $M_n(R)$?","['general-topology', 'lie-groups']"
535726,How find the integral $I=\int_{-R}^{R}\frac{\sqrt{R^2-x^2}}{(a-x)\sqrt{R^2+a^2-2ax}}dx$,"Find the integral: $$I=\int_{-R}^{R}\dfrac{\sqrt{R^2-x^2}}{(a-x)\sqrt{R^2+a^2-2ax}}\;\mathrm dx$$ My try: Let $x=R\sin{t},\;t\in\left[-\dfrac{\pi}{2},\dfrac{\pi}{2}\right]$
  then,
  $$I=\int_{-\pi/2}^{\pi/2}\dfrac{R\cos{t}}{(a-R\sin{t})\sqrt{R^2+a^2-2aR\sin{t}}}\cdot R\cos{t}\;\mathrm dt$$
  so,
  $$I=R^2\int_{-\pi/2}^{\pi/2}\dfrac{\cos^2{t}}{(a-R\sin{t})\sqrt{R^2+a^2-2aR\sin{t}}}\;\mathrm dt$$ Maybe following can use Gamma function? But I can't find it. Thank you someone can help me.","['definite-integrals', 'calculus', 'integration']"
535765,Selecting k numbers out of N sorted numbers to a minimize a condition/Formula,"A sorted list of $\mathbf N$ numbers is given. $X_1$ $\le$ $X_2$ $\le$ $X_3$ $\le$ ....  $\le$ $X_N$ Select $\mathbf K$ Numbers -  $Y_1$ , $Y_2$ , $Y_3$ , ..... , $Y_K$  -  Such that the following value is minimised. $$\sum_{1 \le i \lt j \le k} |(Y_i-Y_j)| $$ 
Let's call it FORMULA. My Approach I Select them such that $Y_1$ $\le$ $Y_2$ $\le$ $Y_3$ $\le$ ..... $\le$ $Y_K$  . Now we need to minimize $$\sum_{1 \le i \lt j \le k} (Y_i-Y_j) $$ REAL DOUBT I m only considering $\mathbf K\,consecutive$ elements(could start from any position). So, is it possible  that the left out cases(i.e K non-consecutive elements ) give a lower value (for the formula above) than the cases i consider ? Bonus Question To calculate the FORMULA for a particular case  $\;Y_1$ $\le$ $Y_2$ $\le$ $Y_3$ $\le$ ..... $\le$ $Y_K$ I create another list with 
   $Z_j$= $(Y_{j+1} - Y_j) $   ---> Equation1 FORMULA = $\sum_{i=1}^{(n-1)}i(k-i)Z_i$ ---> Equation2 Is this Correct? EDIT 1 In my opinion , If there are such instances, they would  consist of equal elements in the       original list with N numbers.","['permutations', 'sequences-and-series', 'combinatorics']"
535768,Show $f''+vf' +\alpha^2 f(1-f)=0$ has solutions satisfying $\lim_{x \to - \infty}f=0$ and $\lim_{x \to \infty}f=1$ given $v\leq -2\alpha < 0$,"I posted this question before but I took a completely different approach here, that's why I reposted as my previous question was already very long and took a different approach from here. I am given the Fisher equation $$u_t=u_{xx}+\alpha ^2u(1-u)$$ where $\alpha >0$ is a constant. Now assuming that $u(x,t) = f(x-vt)$ I need to show there exists a solution $f$ such that $\lim\limits_{x \to - \infty}f=0$ and $\lim\limits_{x \to  \infty}f=1$ provided that $v \leq -2\alpha$. Now substituting $f$ into the differential equation we get:
$$f''+vf' +\alpha^2 f(1-f)=0$$
Where $f$ is a funtion of a single variable $\eta = x-vt$. From here onwards I will go into my attempt to solve using linearization about the stationary points. If someone finds another method to show the asked results I will still award the bounty! It is easy to see that the two stationary points are $(f_0,f'_0)=(0,0)$ and $(f_1,f'_1)=(1,0)$. Now I will linearize the system in these stationary points, first in $(f_0,f'_0)$ via $f=f_0 +\epsilon w_0$ around the first stationary points. Leaving out terms of order $\epsilon^2$ we obtain the following differential equation via substituting this $f$:
$$w_0''+vw'_0+\alpha^2 w_0=0        $$
The solution to this DE is $w_0=Ae^{r_1 \eta}+Be^{r_2 \eta}$ where $r_1 = \frac{-v + \sqrt{v^2-4\alpha^2}}{2}$ and $r_2 = \frac{-v - \sqrt{v^2-4\alpha^2}}{2}$. Now using $v \leq -2\alpha < 0$ we see that $0 \leq \sqrt{v^2-4\alpha^2}< -v$ such that $-v + \sqrt{v^2-4\alpha^2}$ and $-v-\sqrt{v^2-4\alpha^2 }$ are both larger than zero. Thus around the stationary point $(f,f')=(0,0)$ we can approximate the solution of $f$ by:
$$f = f_0 + w_0 = Ae^{r_1 \eta}+Be^{r_2 \eta}$$
Where both $r_1$ and $r_2$ are positive, thus $f$ is increasing at the stationary point $(f,f')=(0,0)$. This is the first result. Now for the second stationary point we use the linearization $f=f_1+\epsilon w_1 = 1 + \epsilon w_1$. This turns the DE into:
$$w_0''+vw'_0-\alpha^2 w_0=0        $$
with solution $w_1=Ce^{s_1\eta}+De^{s_2\eta}$
where $s_1 = \frac{-v + \sqrt{v^2+4\alpha^2}}{2} > 0$ and $s_2=\frac{-v - \sqrt{v^2+4\alpha^2}}{2}<0$
So the approximation around $(f,f')=(1,0)$ is given by $$f=f_1+ Ce^{s_1\eta}+De^{s_2\eta}=1+Ce^{s_1\eta}+De^{s_2\eta}$$
which can be either increasing or decreasing, I cant tell unless we determine the constants. My question is, how do I proceed from here. I think I am going in the right direction as I heard from some of my classmates they solved the problem using linearization... I realize that even the conclusion that the first approximation is increasing is shaky because then I am making the assumption that $A$ and $B$ are not both negative... If anyone could help me out that would be amazing. This question is homework but the deadline is already passes, I handed in what I had and did good on the other questions. I am just frustrated by my inability to get anywhere with this question no matter how much time I spend on it... Thanks in advance! P.S. if anyone has a better way of solving that would of course be very welcome too! Thanks",['ordinary-differential-equations']
535776,estimation of a sample size for a pilot study,I am currently involved in a research project whilst being involved in a statistics programme and I can't quite understand what I have to do...so if anyone could help I would be so very grateful. OK so < need to look at diurnal variation in cortisol levels and I need to estimate my sample size for a pilot study. I have looked at several studies and currently have 6 standard deviation values. How do I then convert this into a formula that can give me a sample size? Probably a stupid question but can anyone help? Many thanks.,['statistics']
535790,"What does it mean to ""determine"" an equivalence relation?","I don't understand the following problem: What does it mean exactly that a number of pairs can ""determine"" an equivalence relation? Say if I have the following set: {1, 2, 3}, and a relation R that's true for (a, b) if a=b. Then would the pairs {1, 1}, {2, 2}, and {3, 3} ""determine"" this relation? How then, does the author arrive at n/2 for this solution? This problem is from this problem set .",['discrete-mathematics']
535805,Balls and boxes probability problem,"Here is another question from the book of V. Rohatgi and A. Saleh. I would like to ask help again. Here it goes: Let A, B, and C be three boxes with three, four, and five cells, respectively. There are three yellow balls numbered 1 to 3, four green balls numbered 1 to 4, and five red balls numbered 1 to 5. The yellow balls are placed at random in box A, the green in B, and the red in C, with no cell receiving more than one ball. Find the probability that only one of the boxes will show no matches. My question is more on how to interpret the problem. I actually cannot understand what is being asked and how was the experiment performed. Can anyone help me please? Also, if you have an answer, please explain the solution as well. Thanks","['statistics', 'probability']"
535809,Discrete valuation ring associated to a principal divisor,"Suppose that $V$ is a normal variety, and $Z$ is a principal divisor so a closed subvariety of $V$ with codimension $1$.Then I don't understand the following construction of the valuation ring $\mathcal O_Z$: In particular my problem is the following: since $V$ is normal, $R=\mathcal O_X(U)=\Gamma( U,\mathcal O)$ is integrally closed but I don't understand why $R_{\mathfrak p}$ is a discrete valuation ring. Moreover why is it important the fact that $\mathfrak p$ is a minimal ideal?","['commutative-algebra', 'algebraic-geometry']"
535814,"Prove that $[0,1]$ is not a compact subset of $\mathbb{R}$ with the lower limit topology, i.e. open sets are of the form $[a,b)$.","Prove that $[0,1]$ is not a compact subset of $\mathbb{R}$ with the lower limit topology, i.e. open sets are of the form $[a,b)$. My question is will different topology affect compactness of a set? If this is so, why? 
At first, when I see this question, I thought something is wrong with this question because I know that $[0,1]$ is compact by using Heine-Borel theorem.",['general-topology']
535824,Find asymptotic for $s(n)=\min\{m\in{\mathbb N}\mid C_n^m\cdot e^{-m^3/(\ln m)^{10}}<1\}$,"I have some strange function: $s(n)=\min\{m\in {\mathbb N} \mid C_n^m\cdot e^{-m^3/(\ln m)^{10}}<1\}$ and I need to find asymptotics for it. I have a solution for this except one last step, I believe. So any help would be appreciated. Solution is as follows: first we observe that $m = o(\sqrt n)$, in other cases ($m \ge \sqrt n$) exponent decreases much faster compared to growth of binomial coefficient. So, for the case of $m = o(\sqrt n)$ we could write following chain of (asymptotical) equalities: \begin{align}
C_n^m\cdot e^{-m^3/(\ln m)^{10}} & \sim \frac{n^m}{m!} \cdot e^{-m^3/(\ln m)^{10}} \\                                 
    &= e^{m \ln n - \ln m! - m^3/(\ln m)^{10}} \\                                        
    &\sim e^{m \ln n - m \ln m \cdot (1 + o(1)) - m^3/(\ln m)^{10}} \\
\end{align} For last equation to be less than $1$, exponent argument should be less than/asymptotically equal to $0$: \begin{align}
& m \ln n - m \ln m \cdot (1 + o(1)) - \frac{m^3}{(\ln m)^{10}} \sim 0 \\                                             
& \ln n - \ln m \cdot (1 + o(1)) - \frac{m^2}{(\ln m)^{10}} \sim 0 \\                                                 
& \ln n - \frac{m^2}{(\ln m)^{10}} \cdot (1 + o(1)) \sim 0 \\
\end{align} And in the last equation I should find $m$ in terms of $n$. And I don't know how can I do that. May be I missed something on the previous steps and $(\ln m)^{10}$ could be removed somehow. But I cannot see a way to do that. Thanks in advance for any ideas.","['asymptotics', 'binomial-coefficients', 'combinatorics']"
535825,"Show that $f(x)=||x||^p, p\ge 1$ is convex function on $\mathbb{R}^n$","Show that $f(x)=||x||^p, p\ge 1$  is convex function on $\mathbb{R}^n$. I have tried to use Holder's inequality, but I still cannot solve this problem. Could you help me with this problem? Thank you so much.","['normed-spaces', 'convex-analysis', 'real-analysis']"
535850,Continuous images of Cauchy sequences are not necessarily Cauchy,"Could you please provide an example for two metric spaces $X,Y$, a continuous function $f$ that maps $X$ to $Y$ and a Cauchy sequence in $X$, which is not mapped to a Cauchy sequence in $Y$ by $f$? Does $f(x) = \frac{1}{x}$ work if $X$ is any metric space and $Y$ is the set of real numbers?","['general-topology', 'metric-spaces']"
535854,"Explanation on a ""different"" proof that $C_c(\Omega)$ is dense in $L^p(\Omega)$.","Theorem: Let $\Omega\subset \mathbb{R}^n$ be an open set and $1\leq p < \infty$. The space $C_c(\Omega)$ is dense in $L^p(\Omega)$. Haim Brezis has a French book called "" Analyse fonctionnelle: theorie et applications "" (my version, Análysis Functional: Teoría y aplicaciones, is Spanish) that says: We know that $C_c(\Omega)$ is dense in $L^1(\Omega)$. So, we can suppose $1<p< \infty$. To prove that $C_c(\Omega)$ is dense in $L^p(\Omega)$ it's enough to show that if $h\in L^{p'}(\Omega)$ satisfies $$\int_\Omega hu=0\,\textit{ for all }\,u\in C_c(\Omega),$$ then $h=0$. Here $p'$ is a number such that $1/p+1/p'=1$. Could someone explain me why is it enough to prove it? Note: The rest of the proof is to show that $h$ is locally integrable to conclude that $$\int_\Omega hu=0\text{ for all }u\in C_c(\Omega)\Rightarrow h=0.$$ This proof seems ""different"" of other proofs ( like this one ) that uses, for example, approximation by simple functions. Thanks.","['sobolev-spaces', 'measure-theory', 'functional-analysis', 'lp-spaces']"
535860,What is the simplest formula for activation / smooth step function?,"I want smooth step function, which is changing from a to b while x changes from 0 to 1 , and I want to control both slope and step location. Which is the simplest formula for this?",['functions']
535868,Probability of Multiple Collisions in the Birthday Problem,"I need help with an approximation concerning the birthday problem.  In a recent MAA Monthly (August-September 2013) article  ""Simple Approximation Formulas for the Birthday Problem"" by Matthias Arnold and Werner Glass, the authors claim the probability $p$ that out of $n$ people at least $k$ birthdays occur on a single day in a year with $c$ days  is approximately
    $$p\approx1-\exp\,\left(\!n^k{\textrm{e}}^{-n/c}\left(\!\frac n{c(k+1)} -1\!\right)^{\!-1}c^{1-k}(k!)^{-1}\!\right).$$ The authors cite this formula from a 1989 paper  ""Methods for Studying Coincidences"" by Persi Diaconis and Frederick Mosteller.  Unfortunately, this reference only claims the formula comes from unpublished work and provides no further references. Can anyone provide  insight about how to obtain such a formula?","['birthday', 'probability']"
535894,"If $f: [0,1]\rightarrow \mathbb{R}$ is continuous function positive","If $f: [0,1]\rightarrow \mathbb{R}$ is continuous function positive, so $$\int_{0}^{1} \frac{f(x)}{f(x)+f(1-x)}dx=\frac{1}{2}$$??? all examples that I tested have worked.","['multivariable-calculus', 'calculus', 'real-analysis']"
535909,Definition: finite type vs finitely generated,"The mathematical term ""finite type"" appears more and more in the modern articles nowadays. But it is still hard to be found in the standard textbooks. I learned the definition of it from Stacks Project http://stacks.math.columbia.edu/tag/00F2 , it is defining on the ring maps. What is the right point of view when we say ""ring of finite type"", ""group of finite type"", ""module of finite type""? Would the definition in each case be exactly equivalent to the definition of ""finitely generated""?","['math-history', 'terminology', 'abstract-algebra', 'definition']"
535922,how to find center/radius of a sphere,"Say you have an irregular tetrahedron, but you know the (x,y,z) coordinates of the four vertices; is there a simple formula for finding a sphere whose center exists within the tetrahedron formed by the four points and on whose surface the four points lie?",['geometry']
535928,Picard's Theorem (Lipschitz) Problem.,"I have the following question: Determine if the function $F(x,y) = xy^{1/3}$ satisfy a Lipschitz condition on the rectangle $\{ (x,y) : |x| \leq h, |y| \leq k \}$ where $h > 0$ and $k > 0$? If $b>0$ determine the region $|x| < h, |y|<k$ which has the largest value of $h$ in which Picard's theorem can be used to show that the initial-value problem $y' = xy^{1/3}$, $y(0) = b$ has a unique solution (you may assume Picard's theorem, but should prove that the assumptions are satisfied) and find the solution explicitly. If $b=0$ show that for any $c > 0$ there is a solution $y$ which is identically zero on $[-c,c]$ and positive when $|x| > c$. Find these solutions explicitly and show that the resulting solutions satisfy the ODE for all values of $x$. In trying to determine whether or not this satisfies the Lipschitz condition or not I've done the following: $|F(x,u) - F(x,v)| = |xu^{1/3} - xv^{1/3}| = |x||u^{1/3} - v^{1/3}| \leq h|u^{1/3} - v^{1/3}|$ But get stuck at this point as $h|u^{1/3} - v^{1/3}| \leq h|u-v|$ if and only if $u,v \geq 1$ - so I'm thinking this doesn't satisfy the Lipschitz condition but can't really formulate it. For the two conditions of Picard's theorem to be satisfied, we must have: $F(x,y)$ is continuous in $R$, where $R$ is the rectangle: $|x|<h$, $|y-b|<k$ and that $F$ is bounded by $M$ so $|F(x,y)| \leq M$ and $Mh \leq k$ The second condition being that $F$ satisfies a Lipschitz condition in $R$. Beyond this I'm unsure what to do, thanks. EDIT: Sorry, to include the version of Picard's theorem I'm using: The ODE $y' = f(x,y)$ with $y(a) = b$ has a solution in the rectangle $R: |x-a| \leq h, |y-b| \leq k$ provided: (i) $f$ is continuous in $R$, bounded by $M$ (so $|f(x,y)| \leq M$) and $Mh \leq k$ (ii) $f$ satisfies a Lipschitz condition in $R$. Furthermore, this solution is unique.",['ordinary-differential-equations']
535948,How do I prove that $(1+\frac{1}{2})^{n} \ge 1 + \frac{n}{2}$ for every $n \ge 1$?,How do I prove that $(1+\frac{1}{2})^{n} \ge 1 + \frac{n}{2}$ for every $n \ge 1$ My base case is $n=1$ Inductive step is $n=k$ Assume $n=k+1$ $(\frac{3}{2})^{k} \times \frac{3}{2} \ge (1 + \frac{k+1}{2})$ I'm not sure how to proceed.,"['induction', 'discrete-mathematics', 'proof-writing']"
535963,Find $\int_0^{2\pi}\frac{1-\frac{1}{4}\cos\theta}{1+\frac{1}{16}\cos^2\theta}d\theta$,"How to evaluate the following integral?
$$\int_0^{2\pi}\frac{1-\frac{1}{4}\cos\theta}{1+\frac{1}{16}\cos^2\theta}d\theta$$
This is an exercise in complex analysis . It looks like a holomorphic function $f(z)$ that we integrate along a circle and take the real part, but I can't see which function could produce that. More precisely, by Cauchy Integral formula,
$$f(z)=\frac{1}{2\pi i}\int_0^{2\pi}\frac{f(e^{i\theta})}{e^{i\theta}-z}ie^{i\theta}d\theta$$
so I tried to find a holomorphic function and a $z\in\mathbb{C}$ such that $$\Re\left(\frac{f(e^{i\theta})}{e^{i\theta}-z}ie^{i\theta}\right)=\frac{1-\frac{1}{4}\cos\theta}{1+\frac{1}{16}\cos^2\theta}$$
but this attempt failed.","['calculus', 'integration', 'complex-analysis']"
535978,Expressing Powers in Terms of Falling Powers,"The falling power $n^\underline{k}$ (read $n$ to the falling $k$) is defined as follows: $$n^\underline{k}=n(n-1)(n-2)\cdots(n-k+1)$$
These are important in discrete calculus because their finite differences and sums are analogous to those of normal powers in differential calculus: $$\Delta n^\underline{k} = k n^\underline{k-1}$$
It is easy to see that $n^1=n^\underline{1}$ and $n^2=n^\underline{2} + n^\underline{1}$. With these base cases, one can recursively express any normal power $n^k$ as a sum of falling powers of order $k$ and less by the following method: expand $n^\underline{k}$, yielding a $k$th order polynomial. Then, substitute falling-power-expansions for all terms of order less than $k$, expressing $n^\underline{k}$ as $n^k$ plus some lower-order falling powers. Rearrange to put $n^k$ on the LHS and all falling powers on the RHS. For example, one can find that $n^3 = n^\underline{3} + 3n^\underline{2} + n^\underline{1}$. This is rather tedious to do by hand for large values of $k$. Is there a more direct method to expand $n^k$ into a sum of falling powers?",['discrete-mathematics']
535981,"If $\displaystyle \lim _{x\to +\infty}y(x)\in \mathbb R$, then $\lim _{x\to +\infty}y'(x)=0$ [duplicate]","This question already has answers here : If a function has a finite limit at infinity, does that imply its derivative goes to zero? (6 answers) Closed 10 years ago . Not homework. I need this (or something similar) to solve 4. in this question . Let $y:(a ,+\infty)\to \mathbb R$ be $C^1$. Prove that $$\lim_{x\to +\infty}y(x)=\eta\text{ for some }\eta\in \mathbb R\implies\text{the following limit exists and } \lim_{x\to +\infty}y'(x)=0$$ Intuitively this is true because $\displaystyle \lim_{x\to +\infty}y(x)=\eta$ means that $y$ almost stops increasing or decreasing, so $\displaystyle \lim_{x\to +\infty}y'(x)=0$. But how to prove it? I tried $$\lim_{x\to +\infty}y'(x)=0=\lim_{x\to +\infty} \lim_{h\to 0}\dfrac{y(x+h)-y(x)}h= \lim_{h\to 0}\lim_{x\to +\infty}\dfrac{y(x+h)-y(x)}h= \lim_{h\to 0}\dfrac{a-a}h=0,$$ but why I can change the order of the limits? If I can't even do that, how can I prove this? After reading the threads Tyler provided, I now just need to prove that $\displaystyle \lim_{x\to +\infty}y'(x)$ exists? Please consider a suitable adaption to the  linked question.","['calculus', 'derivatives', 'real-analysis', 'limits']"
535983,Lebesgue integral of absolute value as difference goes to zero,"Suppose $f\in L^1(\mathbb{R},\mu)$. Prove that $$\lim_{t\rightarrow 0}\int_\mathbb{R}|f(x)-f(x+t)|d\mu=0$$ When I see a limit like this, I want to move the limit inside the integral sign. Usually this can be done by the monotone convergence theorem or the dominated convergence theorem. But here the limit is $t\rightarrow 0$ instead of a sequence of functions with $n\rightarrow\infty$. What can we do?","['lebesgue-integral', 'measure-theory', 'real-analysis']"
536001,Prove that $A\cap (B\setminus C)=(A \cap B)\setminus(A \cap C)$.,"Problem: Prove that $A\cap (B\setminus C)=(A \cap B)\setminus(A \cap C)$. I've tried it on my own:
\begin{align}
x&\in A\cap (B\setminus C) \\
&\Leftrightarrow (x\in A) \wedge (x\in B\setminus C) \\
&\Leftrightarrow (x\in A) \wedge (x\in B \wedge x\notin C) \\
&\Leftrightarrow (x\in A \wedge x\in B) \wedge (x\notin C) \\
&\Leftrightarrow x\in (A\cap B)\setminus C\\
&\Leftrightarrow \dots
\end{align}
What would the next step be? I've no idea how to get from $x\in (A\cap B)\setminus C$ to $x\in(A \cap B)\setminus(A \cap C)$. If I'm trying to do the right side, we get
\begin{align}
x&\in(A \cap B)\setminus(A \cap C)\\
&\Leftrightarrow (x\in A \wedge x\in B)\wedge x\notin (A \cap C)\\
&\Leftrightarrow (x\in A \wedge x\in B)\wedge  (x\notin A \wedge x\notin C)\\
&\Leftrightarrow \dots
\end{align}
How do I make it simpler?",['elementary-set-theory']
536015,What is the purpose of sets? Why do we use them?,All is in the title. Why sets? Why do we need them and where are they important?,"['elementary-set-theory', 'soft-question']"
536017,"Does $d(x_{n+1},x_n)<d(x_n,x_{n-1})$ imply anything?","Let $(X,d)$ be a complete metric space, $(x_n)_{n\in\mathbb{N}}\subset X$ such that $d(x_{n+1},x_n)<d(x_n,x_{n-1})$ for all $n\in\mathbb{N}$. Since I cannot construct such sequence which is not convergent, I wonder if every such sequence is convergent? I first thought of defining a sequence $y_n:=d(x_{n+1},x_n)\in[0,\infty)$ and checking if it converges to zero, but it does not seem fruitful. (Of course, I am aware of the definition of convergence, which is much stronger than this.)","['convergence-divergence', 'sequences-and-series', 'metric-spaces']"
536052,What's the integral of a constant?,If the derivative of a constant is $0$ then what is the integral of a constant? What is the integral of $0$ ?,"['calculus', 'integration']"
536057,Closed-form expression for an iterated integral,"Does the following iterated integral have a simple closed-form expression in terms of $z$? $$ I = \int_0^\infty \int_0^\infty \sqrt{\frac{1 + x^2 y^2 + x^2 z^2 + y^2 z^2}{(x^2 + y^2 + z^2 + x^2 y^2 z^2)^3}} \, dy \, dx $$ where $x \in \mathbb{R^+}$ and $y \in \mathbb{R^+}$. Assume $z \in \mathbb{R^+}$ is a constant. I tried substituting: $$ u = \frac{1}{2} \left[ 1 + \frac{y^2(1 + x^2 z^2)-(x^2+z^2)}{y^2(1 + x^2 z^2)+(x^2+z^2)} \right] $$ which simplifies the integral to this: \begin{align}
I &= \int_0^\infty \frac{\pi}{2} \frac{1}{x^2+z^2} \operatorname{_2F_1} \left( -\tfrac{1}{2}, \tfrac{1}{2}; 1; 1{-}\left[ \frac{x^2+z^2}{1+x^2 z^2} \right]^2 \right) \, dx \\
&= \int_0^\infty \frac{1}{x^2+z^2} \operatorname{E} \left( \sqrt{1{-}\left[ \frac{x^2+z^2}{1+x^2 z^2} \right]^2} \right) \, dx
\end{align} $\operatorname{E}(k)$ here is the complete elliptic integral of the second kind (using elliptic modulus $k$, not the parameter $m=k^2$). I can't seem to simplify this any further. Is there a way to proceed with this integral over $\operatorname{E}(k)$? (I have looked through tables of integrals of elliptic integrals, but nothing seems to match.) Or is there another way to simplify the iterated integral, e.g. via a substitution for both $x$ and $y$? For the record, this integral arises when deriving a certain kind of prior distribution for the parameters of a particular probabilistic model. Berger & Bernardo, 1992, ""Ordered Group Reference Priors with Application to the Multinomial Problem"" describe a sort of generalized Jeffreys prior which assumes a specific parameter ordering and grouping. Essentially, the ""conditional Jeffreys prior"" is derived for each group based on a conditional Fisher information matrix (with the parameters earlier in the ordering held constant), which is based on a marginal likelihood function (with parameters later in the ordering integrated out). The integral above appears when deriving such a prior for a bivariate Bernoulli model with a specific parameterization and ordered grouping of parameters. For two binary variables $X$ and $Y$ with joint probability denoted e.g. $p_{11}$, consider the saturated model with three ""odds ratio"" parameters: $$O_X=\left(\frac{p_{10} p_{11}}{p_{00} p_{01}}\right)^{1/4}, 
O_Y=\left(\frac{p_{01} p_{11}}{p_{00} p_{10}}\right)^{1/4}, 
O_{XY}=\left(\frac{p_{00} p_{11}}{p_{10} p_{01}}\right)^{1/4}$$ (These are similar to the classic log-linear parameters defined e.g. in Bishop, Fienberg, & Holland, 1975, Discrete Multivariate Analysis, but without the logs. I assume the integral here would also appear for the case with log-linear parameters.) Assuming the ordered grouping: $(\{O_{XY}\},\{O_X,O_Y\})$, the integral above appears as part of the normalizing constant for the conditional prior $p(O_X,O_Y|O_{XY})$. Finding the joint prior $p(O_X,O_Y,O_{XY})$ then involves deriving $p(O_{XY})$ from a marginal likelihood.","['multivariable-calculus', 'integration', 'definite-integrals', 'elliptic-integrals', 'hypergeometric-function']"
536060,Show that quotient ring of a $\Bbb C$-algebra by a maximal ideal is isomorphic to $\mathbb{C}$.,"Let $R = \mathbb{C}[x_1,...,x_n]/I$ be a quotient of a polynomial ring over $\mathbb{C}$, and let $M$ be a maximal ideal of $R$. How do I show that quotient ring $R/M$ is isomorphic to $\mathbb{C}$? So I use the fact that $M$ is a maximal ideal of $R$ if and only if $R/M$ is a field. Obviously $\mathbb{C}$ is a field. How would I use this theorem? Hilbert's Nullstellensatz: the maximal ideals of the polynomial ring $\mathbb{C}[x_1,...x_n]$ are in bijective correspondence with points of complex n-dimensional plane. A point a in $\mathbb{C^n}$ corresponds to the kernel of a substitution map which sends f(x) in $\mathbb{C}[x_1,...x_n]$ to f(a). the kernel of this map is the ideal generated by linear polynomials with roots consisting of the components of a","['commutative-algebra', 'ring-theory', 'ideals', 'abstract-algebra']"
536079,Evaluating $\int_{-\infty}^\infty \frac{dx}{\cosh(x-a)\cos(2x)}$,"I have been asked to evaluate $$\int_{-\infty}^\infty \frac{dx}{\cosh(x-a)\cos(2x)}$$. I'm deliberating on whether this indefinite integral exists or not. The integrand diverges when $x=\frac{1}{2}(n+\frac{1}{2})\pi$ but the $\cosh(x-a)$ term relaxes these singularities exponentially as $x$ goes to infinity. If it does exist, then I'm left with the problem of computing it. This is for a complex variables class, so I was using residue methods. However, there are countably many simple poles along the real axis as well as for each $z=i(n+\frac{1}{2})\pi +a$ in the complex plane, so I don't even know what contour to use. It looks like rectangles and semicircles are out. Any suggestions?","['residue-calculus', 'improper-integrals', 'integration', 'complex-analysis']"
536089,Are these bases for a topology?,"I have the following topology :
$$\tau= \Bigl\{U\subseteq \mathbb{R}^2: (\forall(a,b) \in U) (\exists  \epsilon >0) \bigl([a,a+\epsilon] \times [b-\epsilon, b+\epsilon]\subseteq U\bigr)\Bigr\}$$ Are these a basis for the previous topology: $\beta_1= \{[a,a+\epsilon] \times [b-\epsilon, b+\epsilon]\subseteq \Bbb R^2: (a,b)\in \Bbb R^2, \epsilon>0 \}$ $\beta_2= \{[a,a+\epsilon) \times [b-\epsilon, b+\epsilon)\subseteq \Bbb R^2: (a,b)\in \Bbb R^2, \epsilon>0 \}$ The first one is obviously a basis for $\tau$ because of the definition of $\tau$
and I would say that the second is also a basis, because $[a,a+\epsilon) \times [b-\epsilon, b+\epsilon) \subseteq [a,a+\epsilon] \times [b-\epsilon, b+\epsilon] 
$ Is it correct? what do you think?",['general-topology']
536101,"Weak convergence, together with convergence of norms, implies strong convergence in a Hilbert space.","Let $(x_n)$ be a weakly convergent sequence in a Hilbert space $H$ . If $\| x_n \| \to \| x \|$ , show that $x_n$ converges strongly to $x$ . Context This problem comes from a question in my exam paper; the original problem was incorrect.","['hilbert-spaces', 'convergence-divergence', 'functional-analysis', 'weak-convergence']"
536117,Does there exist an open interval $U$ such that $\mu(A\cap U)>0$ and $\mu(A^c\cap U)=0$,"Let $(X,\mathcal{M},\mu)$ be a measure space where $X=\mathbb{R}$ and $ \mu$ is the Lebesgue measure.  Take and open interval $O\supset A$, $\mu(A)>0$ and $B=O\setminus A$. Does there exist an open interval $U$ such that $\mu(A\cap U)>0$ and $\mu(B\cap U)=0$? As you may have guessed, I am very much a beginner at this. I know that in general (e.g. A is a Cantor set with positive measure) there will not exist a $U, \mu(U)>0$ such that $(B\cap U)$ is an empty set but it seems like we should be able to satisfy $\mu(B\cap U)=0$ by expressing $O$ as a countable union of pair-wise disjoint open intervals $O_i$ such that
$$ O=\bigcup_{i=1}^\infty O_i$$
Then
$$\mu(O)=\sum_{i=1}^\infty \mu(O_i) = \sum_{i=1}^\infty \mu(A\cap O_i) + \sum_{i=1}^\infty \mu(B\cap O_i)$$ So the crux seems to be, for at least one of the summands, can the following be proved to hold?
$$\mu(O_i) =\mu(A\cap O_i) \Rightarrow \mu(B\cap O_i)=0$$",['measure-theory']
536121,Laurent series of $z^{-3}$ at $z_0 = i$. Is there a way to do this by hand or is the question just evil?,"I have to find the two Laurent series expansions of $\frac{1}{z^3}$ about $i$. The only approach I can think of is to do: $$\frac{1}{z^3} = \frac{1}{(z-i)^3} \left( \frac{z-i}{z} \right) ^3 = \frac{1}{(z-i)^3} \left( 1 - \frac{i}{i+(z-i)} \right) ^3 = \frac{1}{(z-i)^3} \left( 1 - \frac{1}{1-i(z-i)} \right) ^3 $$ This expansion will work in the disk $|z-i|<1:$ $$=\frac{1}{(z-i)^3} \left( 1 - \sum_{n=0}^{\infty}i^n(z-i)^n \right) ^3  =i \left(  \sum_{n=0}^{\infty}i^{n}(z-i)^{n} \right) ^3 .$$ But this is nasty, because I don't know how to cube the series! And I don't think anything nice would come out of it, anyway. The second expansion is in the annulus $|z-i|>1:$ $$\frac{1}{z^3} = ... =  \frac{1}{(z-i)^3} \left( 1 - \frac{1}{z-i}\frac{1}{ \frac{1}{z-i}-i} \right) ^3 = \frac{1}{(z-i)^3} \left( 1 - \frac{1}{z-i}\frac{i}{ 1-\frac{-i}{z-i}} \right) ^3 =$$ $$=  \left( \frac{1}{z-i} - i \sum_{n=0}^{\infty} \frac{(-i)^n}{(z-i)^{n-2}} \right) ^3$$
Same problem, except now it's even worse... How do I deal with this?","['laurent-series', 'power-series', 'complex-analysis']"
536144,Why does the google calculator give $\tan 90^{\circ} = 1.6331779e^{+16}$?,I typed in $\tan 90^{\circ}$ in Google and it gave $1.6331779\mathrm{E}16$ . How did it come to this answer? Limits? Some magic?,"['floating-point', 'trigonometry']"
536157,Reconstructing an Affine Variety from its Coordinate Ring,"I'm trying to understand the construction often written as $V=\operatorname{Spec}(R)$, where $R$ is a finitely generated $\mathbb C$-algebra with no nonzero nilpotents. At first glance, the notation $\operatorname{Spec}(R)$ is introduced just as the set of maximal ideals. If $R=\mathbb C[V]$ is the coordinate ring of an affine variety $V\subseteq\mathbb C^n$, we know that points of $V$ correspond to maximal ideals of $\mathbb C[V]$, so $V=\operatorname{Spec}(\mathbb C[V])$ is a legitimate equation on the level of sets. But to make $\operatorname{Spec}(R)$ a proper affine variety if we don't already know the variety that has $R$ as its coordinate ring, we need some way to equip the set of maximal ideals with the structure of an affine variety. From what I read, the ""proper"" way to look at this, is learning about schemes. Since I'm only beginning algebraic geometry (to study toric varieties), I don't know anything about the theory of schemes for now. The way I managed to equip $\operatorname{Spec}(R)$ with the structure of an affine variety is the following: Let $R$ be a finitely generated $\mathbb C$-algebra with no nonzero nilpotents. Pick generators $f_1,\dots,f_r$ and consider the surjective $\mathbb C$-algebra homomorphism $\varphi:\mathbb C[x_1,\dots,x_r]\to R$ with $x_i\mapsto f_i$. By the homomorphism theorem we have an isomorphism $R\cong\mathbb C[x_1,\dots,x_r]/I$, where $I$ is the kernel of $\varphi$. Since $R$ has no nonzero nilpotents, the ideal $I$ is radical. Let $V=\mathbf V(I)\subseteq\mathbb C^r$ be the affine variety given by the ideal $I$, then $\mathbf I(V)=\sqrt{I}=I$ by Hilbert's Nullstellensatz and therefore $\mathbb C[V] = \mathbb C[x_1,\dots,x_r]/I\cong R$. Since $V=\operatorname{Spec}(R)$ as sets, this construction equips $\operatorname{Spec}(R)$ with the structure of an affine variety. Is this the right way to think about this, when I come across varieties defined as the $\operatorname{Spec}$ of some $\mathbb C$-algebra?",['algebraic-geometry']
536165,"Proof that $\int_0^{2\pi}\sin nx\,dx=\int_0^{2\pi}\cos nx\,dx=0$","Prove that $\int_0^{2\pi}\sin nx\,dx=\int_0^{2\pi}\cos nx\,dx=0$ for all integers $n \neq 0$. I think I'm encouraged to prove this by induction (but a simpler method would probably work, too). Here's what I've attempted: $$\text{1.}\int_0^{2\pi}\sin x\,dx=\int_0^{2\pi}\cos x\,dx=0.\;\checkmark\\\text{2. Assume}\int_0^{2\pi}\sin nx\,dx=\int_0^{2\pi}\cos nx\,dx=0.\;\checkmark\\\text{3. Prove}\int_0^{2\pi}\sin (nx+x)\,dx=\int_0^{2\pi}\cos (nx+x)\,dx=0.\\\text{[From here, I'm lost. I've tried applying a trig identity, but I'm not sure how to proceed.]}\\\text{For the}\sin\text{integral},\int_0^{2\pi}\sin (nx+x)\,dx=\int_0^{2\pi}\sin nx\cos x\,dx+\int_0^{2\pi}\cos nx\sin x\,dx.$$ I hope I'm on the right track. In the last step, I have $\sin nx$ and $\cos nx$ in the integrals, but I'm not sure if that helps me. I would appreciate any help with this. Thanks :) As I indicated above, it'd be great to find a way to complete this induction proof—probably by, as Arkamis said, ""working it like the transcontinental railroad"" with trig identities (if that's possible). I think my instructor discouraged a simple $u$-substitution, because we've recently been focused on manipulating trig identities.","['definite-integrals', 'trigonometry', 'induction', 'integration']"
536202,Please check if my proof is correct of Monotone Convergent theorem,"I was required to prove Monotone Convergent Theorem as a corollary of Fatou lemma,i.e using Fatou lemma to prove the MCT. The hint I was given is let $f_n$ be a sequence of increasing function, $lim f_n =  f$ . let $b_n=f-f_n$ to prove. Due to my knowledge of limsup and liminf is rusty and superficial. I tried to prove as follows, however I am not sure the way I do is right or not, so please point out the mistake. Apply Fatou Lemma for $f_n$ : $ \int \liminf f_n\le\liminf\int f_n \\$ since $\lim f_n =  f$ , then $\liminf f_n = f$ $\int f\le\liminf\int f_n \\$ (1) Apply Fatou Lemma for $b_n$ : $\int (\liminf (f-f_n))\le\liminf\int(f-f_n)\\$ $\int(f+\liminf (-f_n))\le\liminf(\int f-\int f_n)\\$ $\int f+ \int \liminf (-f_n)\le\int f+\liminf(-\int f_n) \\$ $-\int\limsup(f_n)\le-\limsup(\int f_n)$ since $\lim f_n =  f$ , then $\limsup f_n = f$ $\int f \ge\limsup(\int f_n)\ge\liminf\int f_n $ (2) (1),(2) : $\int f = \liminf\int f_n = \lim \int f_n$, due to $f_n\to f$.","['measure-theory', 'limsup-and-liminf', 'proof-verification', 'real-analysis', 'lebesgue-integral']"
536220,Do the algebraic properties of the exponential and log functions specify them uniquely in probability theory?,"I come from a physics background and in classical mechanics, we construct a Hamiltonian function whose partial derivatives generates a vector field, two independent systems are assigned a total Hamiltonian which is the algebraic sum of the Hamiltonians for the isolated systems. In statistical mechanics, Liouville's theorem requires that in equilibrium, the probability that a system's dynamical variables have specific values is a function of the value Hamiltonian for those specific values. So the standard probability theory argument that the probability to measure state a in system A and state b in system B for independent systems A and B is the product of the individual probabilities: $Pr(a \text{ & } b) = Pr(a)*Pr(b)$. This is essentially a quick derivation of the maxwell-boltzmann distribution. I've seen this argument about probability theory in several places, and can easily see that the exponential satisfies the requirement. So I think my question is essentially this, does
$$
f(a+b) = f(a)*f(b) \\
f(x) > 0 \text{ for all real x} \\
$$ uniquely specify that $f(x)=Ae^{cx}$? Or is there some other consideration that I must be overlooking?","['statistics', 'probability-distributions', 'probability', 'statistical-mechanics']"
536232,Value of tan(pi/2) [duplicate],"This question already has answers here : Is $\tan(\pi/2)$ undefined or infinity? (3 answers) Closed 7 years ago . I understand that this is a very stupid question but I'm not getting the answer. At $x=\pi/2$, what is the value of $tan(x)$? Should it be $-\infty$ or $+\infty$? Text  tells it to be $+\infty$. But why? Geometrically thinking, it comes out to be $+\infty$. But how to explain the graph which has both the values at $\pi/2$?","['trigonometry', 'analysis']"
536239,A Better Way to Solve this Factorial Problem?,"I had a problem that asked me to find which of the following is larger: ${2013 \choose 500}$ or ${2013 \choose 1500}$ Beneath is my proof. I think it is correct (though your verification and suggestions would nonetheless be appreciated). I haven't worked with factorials all that much, and am curious to see if it could be done any more swiftly. Are there easier ways to prove this proposition? ${\bf Proof:}$
$${n \choose k} = \frac{n!}{k!(n-k)!}$$
$${2013 \choose 1500} = \frac{2013!}{1500!(2013-1500)!} = \frac{2013!}{1500!\cdot 513!}$$
$${2013 \choose 500} = \frac{2013!}{500!(2013-500)!} = \frac{2013!}{500!\cdot 1513!}$$
Obviously, if $500!1513! > 1500!513!$, then ${2013 \choose 1500} > {2013 \choose 500}$ and vice-versa. Note that $\frac{500!1513!}{500!} = 1513!$, and $\frac{513!1500!}{500!} = 1500!\cdot(501\cdot 502 \cdot ... \cdot 513)$. We can rewrite $1513!$ as $1500 \cdot (1501 \cdot 1502 \cdot ... \cdot 1513)$. As both expansions $A = (501 \cdot ... \cdot 513), B = (1501 \cdot ... \cdot 1513)$ have 13 terms each, and $\forall a \in A, a < b$ for any $b \in B$, it must be that $\prod\limits_{a\in A} a < \prod\limits_{b \in B} b$. So $1513! > 1500!(501\cdot ... \cdot 513)$, so $500!1513! > 1500!513!$, so $\frac{2013!}{500!1513!}<\frac{2013!}{1500!513!}$, so ${2013 \choose 1500} > {2013 \choose 500}$. $\square$","['factorial', 'discrete-mathematics', 'proof-verification']"
536253,Proof of Aristarchus' Inequality,Does anyone know how to prove that if $0<\alpha<\beta<\frac{\pi}{2}$ then $\frac{\sin\alpha}{\alpha}>\frac{\sin\beta}{\beta}$. Any methods/techniques may be used.,"['analytic-geometry', 'trigonometry', 'calculus']"
536261,What is the underlying structure that makes this analogy so good?,"In ""Linear Algebra Done Right"", the author draws (in my opinion) a fantastic parallel between $\mathbb{C}$ and $\mathcal{L}(V)$ (where $V$ is an $\mathbb{F}$-inner product space).  In this analogy, he establishes: A complex number $z$ corresponds to an operator $T$, The conjugate $\overline{z}$ corresponds to the adjoint $T^*$, The complex number $z$ is real corresponds to $T$ being self-adjoint, The complex number $z$ is non-negative corresponds to $T$ being positive-semidefinite, The complex number $z$ satisfies $|z| = 1$ corresponds to $T$ being an isometry ($TT^* = I$), among others.  I'm curious though if there is some underlying structure linking $\mathbb{C}$ and $\mathcal{L}(V)$ that makes the parallel so great (I know they are both vector spaces), or is this just a coincidental observation by the author?","['linear-algebra', 'soft-question']"
536281,Triangle inside a square,"Suppose that we have a square with side $L$. Given 3 non collinear points inside this square, can we affirm that the area of the triangle formed linking these points is less than (or equals) $\frac{L^2}{2} $?",['geometry']
536320,mean curvature is trace of second fundamental form?,"My understanding was that, from the Weingarten equations, mean curvature $H$ of a surface in $\mathbb{R}^3$ satisfied $$2H = \operatorname{tr}(g^{-1} b),$$ where $g$ is the first fundamental form (metric of the surface) and $b$ is the second fundamental form. However, on Wikipedia at the article on Mean Curvature , I find the following sentence: More abstractly, the mean curvature is the trace of the second fundamental form divided by n (or equivalently, the shape operator). Which asserts that
$$2H = \operatorname{tr}(b).$$
Which is it? Are the two expressions somehow equal?",['differential-geometry']
536321,Showing a sequence $x_{n+1} = Tx_n$ forms a contraction mapping,"I want to show that the sequence given by 
$$x_{n+1} = Tx_n = x_n-\frac{(x_n^2-2)}{x_n+x_{n-1}}$$ forms a contraction mapping. That is 
$$|Tx_1-Tx_2|\leq c|x_1-x_2|.$$ Where $c$ is to be determined. I am also unsure of what the conditions for convergence are. 
So far I have $$\begin{align*}|Tx_1-Tx_2| &= \bigg|(x_1-\frac{(x_1^2-2)}{x_1+x_0})-(x_2-\frac{(x_2^2-2)}{x_2+x_1})\bigg| \\
&= \bigg|\frac{(x_1^2-2)(x_0-x_2)}{(x_1+x_0)(x_1+x_2)}\bigg| \end{align*}$$
and I am not really sure where to go from here. I have also thought about 
$$|Tx_1-Tx_2| = \bigg|(x_1-x_2)-\frac{(x_1^2-2)}{x_1+x_0}+\frac{(x_2^2-2)}{x_2+x_1}\bigg|$$
and factoring out the $(x_1-x_2)$ term but I am also unsure of where to go from there. I should note that this sequence comes from the secant method with $f(x)=x^2-2$. Would it be better to show that the secant method forms a contraction mapping? If so how would one do that? Any help and comments would be appreciated. Thank you.","['fixed-point-theorems', 'sequences-and-series', 'functional-analysis', 'analysis']"
536362,Countably generated $\sigma$-algebra implies separability of $L^p$ spaces,"Let $\Sigma = \sigma(\mathcal C)$ be the $\sigma$-algebra generated by the countable collection of sets $\mathcal C \subset \mathcal{P}(X)$. How can I prove that if $\mu$ is a $\sigma$-finite measure on $(X,\Sigma)$ then $L^p(X)$ is separable for $1 \le p < \infty$? I know that simple functions are dense in $L^p(X)$, so I would like to find a countable subset of the set of simple functions that is dense in them. Could you help me please?","['general-topology', 'measure-theory', 'lp-spaces']"
536381,"Autocorrelation function, cumulants and probability distribution","I have a doubt. Is it possible to get the cumulants of a probability distribution from the autocorrelation function? or the probability distribution?. For example, the variance (the second cumulant) corresponds to the autocorrelation function at $\tau =0$. Thank you so much","['statistics', 'probability-distributions', 'probability']"
536386,Conditional expectation: Is $X/E[X \mid \mathcal{G}] \in L^p$?,"Let $(\Omega, \mathcal{F}, P)$ be a probability space, and let $X$ be a strictly positive random variable with finite moments of all orders (i.e. $E[X^q] < \infty$ for all $1 \le q < \infty$).  Let $\mathcal{G} \subset \mathcal{F}$ be a sub-$\sigma$-field.  For $p > 1$, I would like to know whether it holds that
$$E \left[ \left( \frac{X}{E[X \mid \mathcal{G}]} \right)^p \right] < \infty.$$
It clearly holds when $p=1$, when $X$ is $\mathcal{G}$-measurable, and when $X$ is independent of $\mathcal{G}$.  But I cannot find a proof or counterexample in general; the inequalities I tried seem to go the wrong direction. Note that we do not assume $E[X^{-1}] < \infty$.","['probability-theory', 'lp-spaces', 'conditional-probability']"
536391,Integrating exponential of exponential function,"I would like to find the integral of $\int_0^\infty\exp(-u-\exp(-ku))\,du$ for $k>0$. This is related to the gumbel distribution( http://en.wikipedia.org/wiki/Gumbel_distribution ), which shows that this integral is one if k=1. However, I would like to know how to integrate this without using the fact that this is a distribution, just so that I can see the method of integration. Side question: Any suggestions on integrating $\int_{-\infty}^\infty\exp(-\theta^2-\exp(-k\theta^2))\,d\theta$ update: See my comment below on Roberts answer for a solution.","['definite-integrals', 'probability-distributions', 'integration']"
536401,Sample size from population?,"This is probably very rudimentary maths, but given a strict population size ($N = 20$ for example), is the sample size any number $<N$? For use in calculation of confidence intervals using a population size, all of the formulas use $n$ and not $N$, meaning I need a sample size rather than population size. $$N = 20;\qquad n = 1, 2, 3, \dots , 19$$ 
$$N = 10;\qquad n = 1, 2, 3, \dots , 9$$ Is this right? This isn't really a maths question, but moreso a semantics question; is a sample size just taken from a population? A sample size of $n = 5$ can come from a population size of $N = 10$? Basically: for determining confidence intervals of a population, is the sample size used in calculations an arbitrary number as long as it fits within the amount of the population? edit; according to the textbook (and online sources), a sample should be an approximation of a population, so $n = N - 1$? Math is my weakest area, so I apologize if this is silly.","['statistics', 'sampling', 'definition']"
536425,What is the relationship between Fourier transformation and Fourier series?,Is there any connection between Fourier transformation of a function and its Fourier series of the function? I only know the formula to find Fourier transformation and to find Fourier coefficients to find the corresponding Fourier series.,"['fourier-analysis', 'analysis']"
536442,"Intuitive explanation for $\mathbb{E}X= \int_0^\infty 1-F(x) \, dx$","I can see by manipulating the expression why $\mathbb{E}X$ works out to be $\int_0^\infty 1-F(x)\,dx$, where $F$ is the distribution function of $X$, but what is an intuitive explanation for why that is true? If at each point we sum the probability $\mathbb{P}(X>x)$, why should we end up with the expectation? Thanks","['probability', 'soft-question']"
536443,"Use mathematical induction to prove that for any $k \in\mathbb N , \lim (1+k/n)^n = e^k$.","Use mathematical induction to prove that for any $k \in \mathbb N, \lim (1+k/n)^n = e^k$. I already used monotone Convergence Theorem to prove $k=1$ case. Do I just need to go through the same process to show $k$? If not, could you please help? Thanks","['sequences-and-series', 'real-analysis', 'analysis']"
536466,For each given subspace W there is one and only one row-reduced echelon matrix that has W as its row space.,Let m and n be positive integers and let F be a field. Suppose W is a subspace of $ {F ^{n}}$ and $ dim W \le m$. Prove that there is precisely one m x n row-reduced echelon matrix over F which has W as its row space.,['linear-algebra']
536468,Bound on graph edges,"I need some help with the following problem. Suppose I have a graph $G$ of $n$ elements such that each edge $e$ missing from it, is contained in a copy of $K_s$ (complete graph os $s$ vertices) in $G$ with $e$ added. I need to show that
$$ \left| E(G) \right| \geq {n \choose 2} - {n-s+2 \choose 2} $$
$\left| E(G) \right|$ is the number of edges of $G$ I appreciate any helps or thoughts on it, thanks.","['graph-theory', 'combinatorics']"
536484,Can we say anything about the structure of the semigroup of non-coprime pairs after this?,"Let $S = \{(a,b) :  \ a, b \in \Bbb{Z} \wedge \gcd(a,b) \neq 1 \}$.  Then it forms a semigroup under componentwise multiplication and if we add an exception, that even though $\gcd(1,1) = 1$, we include $(1,1)$ in set, then we have a semigroup with identity. The operation $(a,b)\cdot(c,d) \mapsto (ac, bd), \ \ S \times S \to S$.  Can be generalized.  What if you let the operation be given by a pair of polynomials as $(p(a,b,c,d), q(a,b,c,d))$.  For instance the polynomials $p = ac - bd, \ q = ad + bc$ work, i.e. $S$ is closed under $x \cdot y \mapsto (p(x,y), q(x,y))$. In the following, let $(a,b) = x$ and $(c,d) = y$ and $p(x,y)$ stand for $p(a,b,c,d)$. Lets see.  The polynomials we speak of are in $\Bbb{Z}[x_1, \dots, x_4]$ which we'll just call $R$.  Consider the ideal $I = x_1 x_3 R + x_1 x_4 R + x_2 x_3 R + x_2 x_4 R$. Conjecture :  the set of all integer polynomial pairs $p,q$ such that $S$ is closed under $x\cdot y \mapsto (p(x,y), q(x,y))$ is $I \times I$. Claim $(1)$ : For any $p, q \in I$, the pair $p,q$ is such that $S$ is closed under $x \cdot y \mapsto (p(x, y), q(x,y))$ Proof . $\gcd(a,b)\cdot\gcd(c,d) = r$ divides each of $ac, ad, bc, bd$, so when we evaluate each of $p$, $q$, if they're in that ideal then clearly each results in an integer that is divisible by $r$. QED Claim $(2)$ : The set $T$ of all non-constant polynomials $p$ such that $p, q$ is such a pair for some polynomial $q$ forms an ideal of $R$ that contains $I$. Proof .  We've shown that $I$ satisfies the required properties so any such ideal contains $I$.  We need to show that for all $p,q \in T, p - q \in T$ and $\forall r \in R, \ rT \subset T$. Let $r\in R, p \in T$.  Then $\exists q \in R$ such that $p, q$ is such a pair.  Then $rp, q$ is automatically such a pair as anything dividing $p$ also divides $rp$.  Thus $T$ absorbs $R$. It's tougher to show that $p - q \in T$.   We know that $\gcd(p(x,y), q'(x,y)) \neq 1, \forall x, y \in S$ for some non-constant $q' \in R$.","['polynomials', 'semigroups', 'abstract-algebra', 'number-theory']"
536550,"Prove that for each $n$, there are $n$ consecutive integers, each of which is divisible by a perfect square larger than $1$ [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 10 years ago . Improve this question Prove that for each positive integer $n$ , there are $n$ consecutive integers, each of which is divisible by a
perfect square larger than $1$ .","['modular-arithmetic', 'number-theory']"
536553,How can it be meaningful to add a discrete random variable to a continuous random variable while they are functions over different sample spaces?,"It seems that one usually use the set of all possible values of $X$ as the sample space of random variable $X$. (Therefore discrete random variables have countable sample space, continuous random variables have uncountable sample space.) However, I don't think this is right. Since random variables are defined as measurable functions over sample space, the above assumption would make sum/product of a discrete random variable and a continuous  random variable meaningless (because they are function over different spaces.) Well, this post says that Every uncountable standard Borel space is isomorphic to [0,1] with the Borel σ-algebra. Moreover, every non-atomic probability measure on a standard Borel space is equivalent to Lebesgue-measure on [0,1]. However, this doesn't solve all the problems. First, that claim is true only for uncountable sample space, so the problem of adding of a discrete RV and a continuous RV is still unsolved. Second, even with two continuous RV, there are still problems if we consider expectation (integration). Although the quoted claim says that ""every non-atomic probability measure on a standard Borel space is equivalent to Lebesgue-measure on [0,1]."" , however, two different measures cannot be transformed to Lebesgue measure on [0,1] with same isomorphism. Therefore two RVs $X$ and $Y$ may have different measures on [0,1], which will make $\mathbb{E}XY$ meaningless. This really confused me.... Can people really base all different random variables onto one same sample space with one same measure?","['probability-theory', 'probability']"
536556,Creating one Set from another using Set Builder Notation,"I'm a little confused about set builder notation. If I have one set, how do I construct another set from the first set, supposing that I want to alter all the elements? For example, Let there be a set $A = \{1,2,3,4,5\}$ and I want to construct, from $A$, a set $B = \{\sqrt{1},\sqrt{2},\sqrt{3},\sqrt{4},\sqrt{5}\}$. What is the correct notation to do this? Surely it isn't $B = \{a \in A | \sqrt{a}\}$?",['elementary-set-theory']
536563,Trouble computing the shape operator.,"Where have I gone wrong in the following computation of the shape operator of surface? Suppose we have a surface $M = \{(x,y,f(x,y)) \: | \: (x,y) \in \mathbb{R}^2 \}$ for some nice $f:\mathbb{R}^2 \to \mathbb{R}$. Let $\phi: \mathbb{R}^2 \to M$ be the obvious parametrisation. The tangent space at a point are given by the span of $\phi_x = (1,0,f_x)$ and $\phi_y = (0,1, f_y)$ (evaluated at that point). The unit normal vector is $N = \frac{\phi_x \times \phi_y}{\|\phi_x \times \phi_y \|} = \gamma (-f_x, -f_y,1)$, where $\gamma = (1+f_x^2+f_y^2)^{-1/2}$. The coefficients of the first fundamental form are 
$E = \phi_x \cdot \phi_x = 1 + f_x^2$, $F = \phi_x \cdot \phi_y = f_x f_y$, and $G = \phi_y \cdot \phi_y = 1 + f_y^2$. Note that $EG - F^2 = 1 + f_x^2 + f_y^2 = \gamma^{-2}$. The coefficients of the second fundamental form are
$e = N \cdot \phi_{xx} = \gamma f_{xx}$, $f = N \cdot \phi_{xy} = \gamma f_{xy}$, and $g = N \cdot \phi_{xx} = \gamma f_{yy}$. By the Weingarten equations, we have the shape operator given as $\frac{1}{EG -F^2} \begin{bmatrix} e & f \\ f & g\end{bmatrix} 
\begin{bmatrix} G & -F \\ -F & E\end{bmatrix} = 
\gamma^3 \begin{bmatrix} f_{xx} & f_{xy} \\ f_{xy} & f_{yy} \end{bmatrix} 
\begin{bmatrix} 1 + f_y^2 & -f_x f_y \\ -f_x f_y & 1 + f_x^2\end{bmatrix}
$ This matrix is supposed to be symmetric ([sic] SEE BELOW). However, even choosing a simple $f$, like $f = x^2 - y^2$ yields something not symmetric: $\gamma^3 \begin{bmatrix} 2 & 0 \\ 0 & -2 \end{bmatrix} 
\begin{bmatrix} 1 + 4y^2 & -4xy \\ -4xy & 1 + 4x^2\end{bmatrix}
= 2\gamma^3 \begin{bmatrix} 1 + 4y^2 & -4xy \\ 4xy & -(1 + 4x^2)\end{bmatrix}
$ Please set me straight. ADDENDUM: I have conflated a few things and tripped over some basic linear algebra. The matrix above need not by symmetric in general. Rather, it is self-adjoint, and the corresponding bilinear form is what is symmetric.","['surfaces', 'riemannian-geometry', 'differential-geometry']"
536591,How to prove $\sum_{k=1}^n \frac{2^k}{k}< 3\frac{2^n}{n}$?,"How to prove $$\sum_{k=1}^n \frac{2^k}{k}< 3\frac{2^n}{n}$$ and further $$\lim_{n\rightarrow \infty}\frac{n}{2^n}\sum_{k=1}^n 
\frac{2^{k}}{k} = 2$$? These results are verified by computer, yet I can't figure out a neat proof.","['limits', 'inequality', 'analysis']"
536595,Can anyone explain to me this square root? step by step?,"$$\begin{align}
v(p_1, p_2, w) 
& = \sqrt{\frac w{p_1^2\left(\frac1{p_1}+\frac1{p_2}\right)}} 
  +  \sqrt{\frac w{p_2^2\left(\frac1{p_1}+\frac1{p_2}\right)}}
\\
& =  \sqrt{\frac w{\left(\frac1{p_1}+\frac1{p_2}\right)}}
\left(\sqrt{\frac1{p_1^2}}+\sqrt{\frac1{p_2^2}}\right)
\\
& = \sqrt{\frac w{p_1}+\frac w{p_2}}
\end{align}$$ So as the title says, can anyone explain to me this square root? ( Original scan )",['algebra-precalculus']
536624,Is the quotient ring of a PID a PID?,"Let $A$ be a commutative ring and $S$ a multiplicative closed subset of $A$. If $A$ is a PID, show that $S^{-1}A$ is a PID. I've taken an ideal $I$ of $S^{-1}A$ and I've tried to see that is generated by one element; the ideal $I$ has the form $S^{-1}J$ with $J$ an ideal of $A$. $J$ is generated by one element but I can't see why $I$ has to be generated by one element, maybe I'm wrong.","['principal-ideal-domains', 'commutative-algebra', 'localization', 'abstract-algebra']"
536625,Clarification of Hölder norm in terms of oscillation,"Let $\Omega\subset\mathbb{R}^2$ be an open bounded set, $B(x_0, \rho)=\{x\in\mathbb{R}^2\ |\ |x-x_0|\leq \rho\}$, $\Omega(x_0, \rho)\equiv B(x_0, \rho)\cap \Omega$, $u\in L^{\infty}\big(\Omega(x, \rho);\mathbb{R}^N\big)$ and $O(u, x, \rho)=\max_{1\leq k\leq N} \text{osc}_{\Omega(x, \rho)}u^k$, where $\text{osc}_{S} v\equiv\text{ess max}_{S}v-\text{ess min}_{S}v$. In Wiegner's 1981 paper, ""On Two-Dimensional Elliptic Systems with a One-sided Condition"", he defines the following norm for the Hölder space $C^{0, \alpha}(\overline{\Omega};\mathbb{R}^N)$:
\begin{equation}
\|u\|_{C^{0, \alpha}(\Omega;\mathbb{R}^N)}\equiv \sup_{\Omega}|u(x)|+\sup_{\substack{x\in \Omega\\ \rho\leq\rho_0}}\{\rho^{-\alpha}\cdot O(u, x, \rho)\}
\end{equation} Does anyone understand what $\rho_0$ is? He certainly doesn't define it before that line in his paper. I am assuming that if $u\in C^{0, \alpha}(\overline{\Omega}, \mathbb{R}^N)$ then 
\begin{equation}
\|u\|_{C^{0, \alpha}(\overline{\Omega}, \mathbb{R}^N)}\equiv \sum_{k=1}^N\|u^k\|_{L^{\infty}(\Omega)}+[u^k]_{C^{0, \alpha}(\Omega)}
\end{equation}
would be the typical Holder norm we would assign to the space $C^{0, \alpha}(\overline{\Omega}, \mathbb{R}^N)$. Wiegner's norm is as in the question but I will denote it as $\|\cdot\|_W$ to distinguish it from the one above. If Ray Yang's interpretation (see comments) is true then I should be able to show an equivalence between the two norms. To show $\|\cdot\|_{C^{0, \alpha}(\overline{\Omega}, \mathbb{R}^N)}\leq K\|\cdot\|_W$ I argued as follows: Firstly, we see that:
\begin{equation}
\sup_{\Omega} |u|\geq \|u^k\|_{L^{\infty}(\Omega)}\quad\forall \ k
\end{equation}which implies
\begin{equation}\tag{1}
N\sup_{\Omega} |u|\geq \sum_{i=1}^N\|u^k\|_{L^{\infty}(\Omega)}.
\end{equation} Now if we let $x\in\Omega$ and $\rho_o=\text{dist}(x, \partial\Omega)$ then for all $0<\rho\leq\rho_0$ and $y: |x-y|=\rho$ we deduce:
\begin{align}
\frac{|u^k(x)-u^k(y)|}{|x-y|^{\alpha}}&\leq\frac{\max_{B(x, \rho)}u^k(z)-\min_{B(x, \rho)}u^k(z)}{\rho^{\alpha}}\\
&\leq \rho^{-\alpha}O(u, x, \rho)\quad\ \forall\ k.
\end{align}
In this way as we vary $x$, we vary $\rho_0$ and $y$ , so for each $k$ we have
\begin{equation}
[u^k]_{C^{0, \alpha}(\Omega)}\leq \sup_{\substack{x\in\Omega\\ \rho\leq\rho_0}}\{\rho^{-\alpha}O(u, x, \rho)\}
\end{equation} and therefore
\begin{equation}\tag{2}
\sum_{k=1}^{N}[u^k]_{C^{0, \alpha}(\Omega)}\leq N\sup_{\substack{x\in\Omega\\ \rho\leq\rho_0}}\{\rho^{-\alpha}O(u, x, \rho)\}.
\end{equation}
Putting (1) and (2) together we have
\begin{equation}
\|u\|_{C^{0, \alpha}(\overline{\Omega}, \mathbb{R}^N)}\leq N\|u\|_W
\end{equation}
I don't know how to get 
\begin{equation}
\|\cdot\|_W\leq K\|\cdot\|_{C^{0, \alpha}(\overline{\Omega}, \mathbb{R}^N)}.
\end{equation}","['definition', 'holder-spaces', 'partial-differential-equations', 'analysis']"
536664,Orthogonal projection and two subspaces,"Let $\mathcal{S}$ and $\mathcal{T}$ be two subspaces of $\mathbb{R}^n$, let $P$ be the orthogonal projection of $\mathbb{R}^n$ on $\mathcal{S}$ and let $Q$ be the orthogonal projection of $\mathbb{R}^n$ onto $\mathcal{T}$. Show that if $P$ and $Q$ commute, then $PQ$ is a projection and $PQ$ is the projection onto $\mathcal{S}\cap \mathcal{T}$. Is the converse assertion true? Suppose $PQ$ is the orthogonal projection of $\mathbb{R}^n$ onto the intersection $\mathcal{S}\cap \mathcal{T}$. Must $P$ commute with $Q$. Anybody has advice on how i should start proving this assertion?",['linear-algebra']
536676,Does every open affine subscheme of an affine scheme have form $A_f$,"Let Spec${A}$ be an affine scheme, can every open affine subscheme be written as 
Spec$A_f$ for some $f$ in $A$?",['algebraic-geometry']
536682,A simple question about *-homomorphism in C*-algebra,"Let $A$ and $B$ be C*-algebra, $h\colon A\rightarrow B$ is *-homomorphism. If $a\in A_{\operatorname{sa}}$, then $\operatorname{sp}(h(a))\backslash \{0\}\subset \operatorname{sp}(a)\backslash\{0\}$. Here, $A_{\operatorname{sa}}$ denotes all the self adjoint elements in $A$ How to prove this inclusion?","['c-star-algebras', 'operator-algebras', 'spectral-theory', 'functional-analysis']"
536693,Linear algebra and matrix.,"prove or disprove : If A and B are 2 by 2 orthogonal matrices over R then A+B cannot be orthogonal. OR If S,T:R^2--->R^2 are orthogonal transformation then S+T is not an orthogonal transformation.","['matrices', 'linear-algebra', 'transformation']"
536712,How solve this equation,"Solve the equation $$\cos \left(x+30^{\circ}\right)+\cos \left(x+10^{\circ}\right)=\cos \left(2x+10^{\circ}\right)+\cos 10^{\circ}$$ , where $x\in (0,\pi )$ My try: 
$$\cos{(x+30)}+\cos{(x+10)}=2\cos{(x+20)}\cos{10}$$ and
$$\cos{(2x+10)}+\cos{10}=2\cos{(x+10)}\cos{x}$$
then
$$\cos{(x+20)}\cos{10}=\cos{(x+10)}\cos{x}$$ then I can't work,Thank you",['trigonometry']
536767,Solve the following Diffrential Equation $(x+y+1)dx+(2x+2y-1)dy=0$,"I want to seperate variables in the following equation and need some advice:
$$(x+y+1)dx+(2x+2y-1)dy=0$$
what I tried to do so far is:
$$ydx+(x+1)dx+(2y-1)dy+2xdy=0$$
now how I should I continue? thanks.",['ordinary-differential-equations']
536779,Can we simplify $\sqrt{a}*\sqrt{a}$ to $a$ when $a \in \mathbb{R}$ and we do not know whether a is positive or negative?,Can we simplify $\sqrt{a}*\sqrt{a}$ to $a$ when $a \in \mathbb{R}$ and we do not know whether a is positive or negative? (Since $\sqrt{a}$ by itself is undefined in $\mathbb{R}$ when $a$ is negative) I was wondering about how we can handle the above problem in $\mathbb{R}$ when I had to do some exercise that involved squaring the squareroot in $\mathbb{C}$,"['complex-numbers', 'algebra-precalculus']"
536787,Why do the Wirtinger derivatives behave like actual partial derivative operators?,"Despite the fact that they're not partial derivative operators, the Wirtinger derivatives obey things like the chain rule.  Of course I can prove such things by manipulating formulas, but this gives no intuition for what's really happening.  Is there a deep reason that everything just seems to work out with these things?","['several-complex-variables', 'complex-analysis']"
536800,Irrationality/Transcendentality of values of $e^{e^x}$,"1) Is $e^{e^x}$ irrational for all rational $x$? It is known that $e^x$ is transcendental for every nonzero algebraic $x$.
But this dos not help here because for transcedental $x$, $e^x$ can be
rational. 2) Is $e^{e^x}$ transcendental for all algebraic $x$? This would imply 1).","['transcendental-numbers', 'number-theory']"
536837,Hilbert Spaces are Reflexive,"I want to show that all Hilbert spaces are reflexive.  I have found the following proof on StackExchange: Hilbert Space is reflexive However, I do not understand it.  Essentially, we want to show that for all $g \in X^{**}$ , (X is some Hilbert space) there exists a unique $x \in X$ such that $g(h) = h(x)$ for all $h \in X^*$ .  Following the OP's logic, we should apply the Riesz-Fréchet Representation Theorem (RRT) twice: Pick any $g \in X^{**}$ .  Then, since $g$ is bounded on $X^*$ , by RRT there exists a unique $f \in X^*$ such that $||g|| = ||f||$ , and $g(h) = \langle h,f \rangle$ for all $h \in X^*$ .  Now apply RRT to $f$ to get a unique $x \in X$ such that $||f|| = ||x||$ and $f(y) = \langle y,x \rangle$ for all $y \in X$ .  It follows that: $f(x) = \langle x,x\rangle = ||x||^2 = ||f||^2 = \langle f,f \rangle = g(f)$ . We have shown that for any $g \in X^{**}$ that there exist unique $x \in X$ , $f \in X^*$ such that $f(x) = g(f)$ .  This is not quite what we want.  We want this to hold for a general $h \in X^*$ . According to icurays1, we have basically defined a bijective mapping $T:X^{**} \to X$ .  Why is T bijective, and why does this give us that $X$ is reflexive?","['hilbert-spaces', 'functional-analysis']"
536844,Solve the following Diffrential Equation $(3y-7x+7)dx-(3x-7y-3)dy=0$,"I want to solve the following equation:
$$(3y-7x+7)dx-(3x-7y-3)dy=0$$
I will need  two new variables? or I can solve it with 1, for example set expression as $z$? What you are suggesting? thanks.",['ordinary-differential-equations']
536852,Banach space with cardinality bigger than $\mathfrak{c}$.,"By using the information contained in this post , we have that the cardinality of every Banach space is equal to its dimension, which in turn, is bigger or equal to $\mathfrak{c}$. In my area of study, I have always beem studying spaces like $W^{1,p}$ for $p\in (1,\infty)$ which are separable. Moreover, the space that I know which are not separable is $L^\infty$, but I don't know how to calculate its cardinality. My question is: Is there a example of a Banach space with cardinality bigger than $\mathfrak{c}$? Remark: I'm not used to study those things, hence, if I have posted something stupid here, please neglect it.","['cardinals', 'functional-analysis', 'banach-spaces']"
536881,"Is the function $f(x,y)=\begin {cases} ( x^3(i+1)-y^3(1-i))/(x^2+y^2) & x^2+y^2>0\\0 & x=y=0 \end{cases}$ continuous?","Is the function $f(x,y)=\begin {cases} \frac{ x^3(i+1)-y^3(1-i)}{x^2+y^2} & x^2+y^2>0\\ 0 & x=y=0 \end{cases}$ continuous? I would like to prove that thos function isn't continuous with help from two series and show that the limz doesn't equals the limf(z), z=(x,y)...sory for my English and my writting...I hope someone gets this (:","['general-topology', 'functions']"
536893,Derivations of the algebra of differential forms,"It is well known that the interior product, the Lie derivative, and the De Rham differential are derivations of the algebra of differential forms. Does there exist other derivations of this algebra but with degree $\pm k$ for $k\notin\{0,1\}$? Thanks.","['differential-geometry', 'differential-forms', 'abstract-algebra']"
536894,"What ""standard estimates for the laplacian"" do the authors of this paper mean?","I am trying to follow the proof of lemma 2.1 in this paper. The setup. Consider a solution $v$ to the nonlinear equation $$ -\Delta v = ic \partial_1 v + v(1-\vert v\vert^2) ~\mbox{on}~ \mathbb{R}^N$$ with finite energy, i.e., $$\Vert Dv \Vert_{L^2(\mathbb{R}^N)}+ \Vert 1-\vert v \vert^2 \Vert_{L^2(\mathbb{R}^N)} < \infty. $$ Here, $c$ is a real constant and $i$ the imaginary unit. The question. The authors want to prove the following statement. There is a constant $K(c,k,N)>0$ such that $\Vert v \Vert_{C^k(\mathbb{R}^N)} \leq K(c,k,N), \forall k \in \mathbb{R}.$ All they say is: ""One invokes standard estimates for the laplacian"". What standard estimates do they mean? What, precisely, is the argument here? More information. I don't know if this helps, but from the first part of the lemma in the paper, we already know the following: $\Vert 1 - \vert v \vert \Vert_{L^\infty(\mathbb{R}^N)} \leq \max \lbrace 1, \frac{c}{2} \rbrace$ $\Vert \nabla v \Vert_{L^\infty(\mathbb{R}^N)} \leq K(N) \left( 1+ \frac{c^2}{4} \right)^{\frac{3}{2}}$ v is smooth and bounded. Any help is much appreciated!","['functional-analysis', 'partial-differential-equations']"
536898,Complete ordered field is an Archimedean field that cannot be extended to an Archimedean field,"As a bonus problem, our professor of real analysis asked us to prove that the real numbers (a complete ordered field) cannot be extended into an Archimedean field, with no definition of what he meant by extending. I have tried using proof by contradiction to show that if we have some set, $\mathbb{R}^{*}$ such that $\mathbb{R}$ is a proper subset of $\mathbb{R}^{*}$, and that $\mathbb{R}^{*}$ forms an Archimedean field, then because for there to be new elements in $\mathbb{R}^{*}$ as opposed to $\mathbb{R}$, they would have to be larger (or smaller) than all the elements of R. But then we would have reached a contradiction with the Archimedean property. Professor returned this solution and said it's not the right solution (without any further comment). Can anyone offer some enlightenment on what I have done wrong or what I could try now? All I have found on Google are mentions in textbooks that go along the lines of ""every Archimedean field is isomorphic to a subfield of real numbers"". That would imply that we cannot extend reals into an Archimedean field, but how can one go about proving that? I can only use basic definition of an ordered (Archimedean) field and other ""basics"", we have not yet covered sequences, etc.","['field-theory', 'analysis']"
536907,Roots of a Quadratic Problem,I'm struggling with this problem and was hoping I could get some advice. Here is the problem: Let a and b be the roots of the quadratic equation $x^2−x−1/27=0$. Without calculating the a and b show that $a^{1/3}+b^{1/3}$ is a root of the equation $x^3+x−1=0$. Any help would be much appreciated! Thanks,['algebra-precalculus']
536936,Probabilities with three events,"I have a probability problem where I have to calculate the total probability and a Bayes probability from two events. The chances as given are: $P(A) = 0.1, P(A^c) = 0.9$ $P(B|A) = 0.9, P(B|A^c) = 0.05$ Using these probabilities, I was able to work out the total probability: $P(B) = P(A)P(B|A) + P(A^c)P(B|A^c) = (0.1*0.9) + (0.9*0.05) = 0.135$ And the chance of A given B using Bayes: $P(A|B) = \frac{P(B|A)P(A)}{P(B)} = \frac{0.9*0.1}{0.135} = \frac{2}{3}$ Pretty standard stuff so far. However, the last part of the question adds an event C. The chance of C given A and B is 0.1. Knowing this, I have to calculate the chance of an outcome having A, B, and C. Is this really as easy as $P(A \cap B \cap C) = P(A)*P(B)*P(C) = 0.1*0.9*0.1 = 0.009?$","['statistics', 'bayes-theorem', 'probability']"
536962,Laurent series for $\frac{e^z}{1 - z}$ for $|z| > 1$,"I do this like $\dfrac{e^z}{1-z}$ = $-e \dfrac{e^{z-1}}{z-1}$ = $-e \sum_{k=0}^{\infty} \dfrac{(z-1)^k}{k!(z-1)}$ = $-e \sum_{k=0}^{\infty} \dfrac{(z-1)^{k-1}}{k!}$ However doesn't this give me the Laurent series around $|z-1| > 0$? Should I do a taylor expansion of the first term $\dfrac{-e}{z-1}$ to a geometric series to get the expansion for $|z|>1$? Maybe I have just messed up some definitions, sorry if that's the case.","['laurent-series', 'power-series', 'complex-analysis']"
537012,Showing a quotient $\mathbb{Z}$ module is free,"In Fulton's ""Introduction to Toric Varieties"" he repeatedly uses the following fact. Let $\sigma$ be a strongly convex rational polyhedral cone in a lattice $N$ and let $N_{\sigma}$ be the subgroup generated by the elements in $\sigma\cap N,$ so $N_{\sigma} = (\sigma \cap N) + (-\sigma \cap N).$ Then $N/N_{\sigma}$ is a lattice (finite rank free $\mathbb{Z}$-module). I suspect one shows that $N_{\sigma}$ is a saturated subgroup of $N,$ which means the following: If $u\in N$ and $m\in \mathbb{Z}$ are such that $mu\in N_{\sigma},$ then $u\in N_{\sigma}.$ Showing this implies $N/N_{\sigma}$ is torsion free and hence free. But I still can't prove the result. Here's a failed attempt: If $np\in N_{\sigma}$ then $np=s_1 - s_2$ for some $s_i\in \sigma\cap N,$ and hence $p = m^{-1}s_1 - m^{-1} s_2.$ Sure, $p$ is in $\sigma$ and $N,$  $m^{-1}s_i$ are in $\sigma$ and $s_i\in N,$ but we also need to ensure $m^{-1}s_i$ are in $N$ if we want to deduce the required result this way. In fact it does not even appear to be true unless the $s_i$ are primitive (the components have gcd 1). I'm not seeing a solution to this. Please help me.","['convex-analysis', 'algebraic-geometry', 'toric-geometry']"
537033,condition for curve on a sphere,"Let $\alpha (t)$ be a curve such that $|\alpha'(t)|=1$ for all $t\in\mathbb R$. Assume $k(t)\neq 0$, $k'(t)\neq 0$ (whereas $k=|\alpha''(t)|$ is the curvature) and $\tau(s)\neq 0$, whereas $\tau$ is the torsion. Prove: The trace of $\alpha$ lies on a sphere $\Leftrightarrow$ $\frac{1}{k^2} +\frac{1}{(k'\cdot\tau)^2}=$const.$>0$. I know this somehow works by using the Frenet-Serret-equations, but I don't really know how to do this proof. Can anyone help me out? Thanks!",['differential-geometry']
537037,Solve $f(x)\mid g^2(x)+1$ in $\mathbb Z[x]$,"We know that if $p\in \mathbb P$ and $p\equiv 1\bmod 4$ then we can find $t\in\mathbb Z$ such that $p\mid t^2+1.$ For what polynomial $f(x)\in \mathbb Z[x]$, we can find $g(x)\in \mathbb Z[x]$ such that $f(x)\mid g^2(x)+1$? Let $g^2(x)+1=f(x)h(x),h(x)\in \mathbb Z[x]$, we get that $f(x)g(x)=0$ has no real roots. Hence $$f(x)=\prod_{i=1}^n(a_ix^2+b_ix+c_i),(b_i^2-4a_ic_i<0,a_i,b_i,c_i\in\mathbb R).$$ My idea is factor $g^2(x)+1$ in $C[x]:$ $$g^2(x)+1=(g(x)+I)(g(x)-I)=f(x)h(x).$$
But how to go on now ?","['polynomials', 'algebraic-number-theory', 'number-theory']"
537052,Groups with 3 conjugacy classes and finite exponent,"I have seen the question on groups with two conjugacy classes, and I proved to myself that such a group must be torsion-free (if it isn't the cyclic group of order 2), but what about a group with three conjugacy classes? If it is finite, it must be C3 or S3, but what if it is infinite? I also proved that there is no infinite group with three conjugacy classes and exponent 3 (first prove that two conjugate elements commute, then prove that the third class is the inverses of the elements in the first class, and from those two facts it follows that the group is abelian). No other prime exponent works, so we have to move on to the case of exponents with two factors. Is there an infinite group with only three conjugacy classes and finite exponent?","['infinite-groups', 'group-theory']"
537054,Are most numbers of the form $a\cdot b^n+c$ composite?,"It seems evident that for $a,b,c$ with $a>0$ and $b>1$ that there are only $o(x)$ primes of the form $a\cdot b^n+c$ with $n\le x.$ Has this been proven? Hooley (Applications of Sieves to the Theory of Numbers) proves this for Cullen numbers, and apparently this proof generalizes to forms $n\cdot2^{n+a}+b$. A reference would be great, if one can be found. Otherwise, I'll take what I can get!","['prime-numbers', 'reference-request', 'sieve-theory', 'number-theory']"
537089,Orthonormal bases for Hilbert spaces,"In Reed and Simon (Functional Analysis) Theorem II.6 states that, given an orthonormal basis $\{ x_\alpha \}_{\alpha \in A}$ (not necessarily countable)for a Hilbert space $H$, every $y \in H$ can be written as a sum
$$
\sum_{\alpha \in A} (x_{\alpha}, y) x_\alpha 
$$ 
where $(\cdot,\cdot)$ denotes the inner product). The proof uses a conclusion that I cannot quite follow: By Bessel's inequality we know that for any finite subset $A' \subset A$, $\sum_{\alpha \in A'} |(x_\alpha ,y )|^2 \le \|y\|^2$. Thus $(x_\alpha,y) \ne 0$ for at most a countable number of $\alpha's$ in $A$. Why can we deduce the last statement ?","['operator-theory', 'hilbert-spaces', 'functional-analysis']"
537095,Matrix Equation $A^3-3A=\begin{pmatrix}-7 & -9\\ 3 & 2\end{pmatrix}$,How can I solve in $\mathcal{M}_{2}(\mathbb{Z})$ the equation $$A^3-3A=\begin{pmatrix}-7 & -9\\ 3 & 2\end{pmatrix}?$$ I try to use $$A^2-Tr(A)A+detA\cdot I_2=O_2$$ but I don't still obtain anything. thanks.,"['matrix-equations', 'matrices']"
537111,Prove that $g^{-1}(0)$ is a $n$-dimensional manifold.,"Let $A\subset \mathbb R ^n$ be open and let $g:A\to \mathbb R ^p$ be a differentiable function such that $g'(x)$ has rank $p$ whenever $g(x)=0$. Then $g^{-1}(0)$ is an $(n-p)$-dimensional manifold. This is Theorem 5-1 in Spivak's ""Calculus on Manifolds"" and the proof is: ""It follows immediately from Theorem 2-13.[]"" Theorem 2-13 says practically that (under the same hypothesis) if $x\in A$, then there is an open set $U$ containing $x$, an open set $V\subset \mathbb R ^n$ and a diffeomorphism $h:U\to V$ such that $$g(h(x))=(x_1,...,x_p).$$ My bad, I can't see how does the theorem follow immediately from this. To prove that $g^{-1}(0)$ is a $(n-p)$ manifold, I should find open sets $U'$ with $x\in U'$, $V'$ and a diffeomorphism $h':U'\to V'$ such that $$h'(g^{-1}(0)\cap U')=V'\cap [\mathbb R ^{(n-p)}\times \{0\}],$$
where $0$ is the $\mathbb R ^p$'s zero. How do I construct $U'$, $V'$, $h'$ starting from the given $U,V,h$? The only ideas that come to my mind are silly things like $$f(x)=I(x)-(0,g\circ h(x)),$$
where $I$ is the identity and $0$ is the $n-p$ one. I'm very unfamiliar with this stuff, so I'm probably missing some pedantic application of the definition, can you give me some hint?","['manifolds', 'differential-geometry']"
537115,What are definitions of ellipticity?,"Ellipticity seems to have many definitions.  So far, I'm aware of three.  Are there other definitions of ellipticity that you know of, and if so, where did you encounter them? The three definitions that I'm listing all have that $a \geq b$. Definition 1:
$$
\varepsilon = \frac{a-b}{a} = 1 - \frac{b}{a}.
$$
This definition comes from my ""Dictionary of Physics and Mathematics"" from McGraw-Hill. Definition 2:
$$
\varepsilon = \sqrt{\frac{a^2-b^2}{a^2}} = \sqrt{1 - \frac{b^2}{a^2}}.
$$
This definition comes from http://mathworld.wolfram.com/Ellipticity.html .  As a side note, the Wolfram page on ellipticity also defines something called flattening that is equivalent to my definition 1. Definition 3:
$$
\varepsilon = \frac{a^2-b^2}{a^2+b^2}.
$$ I've done a light search for information on definition three, but I have not turned up anything in the literature.","['geometry', 'conic-sections', 'definition']"
537119,map colinear triple of points to another triple of points in $\mathbb{R}^2$,"Given two triples of pw different colinear points in $\mathbb{R}^2$ so $(x_1,x_2,x_3),(y_1,y_2,y_3) \in (\mathbb{R}^2)^3$. There is a map of the form $T:\mathbb{R}^2\to\mathbb{R}^2,x\mapsto Ax+b$, where $A \in Gl(\mathbb{R},2), b\in \mathbb{R}^2$ with $T(x_k)=y_k,k=1,2,3$. $$\iff$$ $$\frac{||x_1-x_2||}{||x_2-x_3||} = \frac{||y_1-y_2||}{||y_2-y_3||}$$ Intuitively it is somewhat clear, but how to pin that down?","['vector-spaces', 'geometry', 'linear-algebra']"
537125,Dense curve on torus not an embedded submanifold,"In reference to Showing a subset of the torus is dense , the responders helped show the poster that the image set $f(\mathbb{R})$ is dense in the torus. But, it's not immediately clear to me why the image set is not an embedded submanifold. If $f(\mathbb{R})$ is an embedded submanifold, we must have that it's a smooth manifold in the subspace topology and that the inclusion map from $f(\mathbb{R})$ to $T^2$ is a smooth embedding. It's visually clear to me that under the subspace topology, $f(\mathbb{R})$ is not locally Euclidean (as it's not locally path connected). But, I can't seem to formalize this or any argument, using that $f(\mathbb{R})$ is dense in $T^2$, which says that $f(\mathbb{R})$ fails 1) or 2). Thanks for any help!",['differential-geometry']
