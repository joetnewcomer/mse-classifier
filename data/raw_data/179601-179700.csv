question_id,title,body,tags
3262051,"Calculate $\iiint_V\frac{xyz}{x^2+y^2}\,dx\,dy\,dz$","Problem : Calculate $$\iiint_V\frac{xyz}{x^2+y^2}\,dx\,dy\,dz,$$ where $V$ is the domain bounded by the surface $(x^2+y^2+z^2)^2=a^2xy$ and the plane $z=0$ . My solution : We make the following substitution: $$
\begin{cases}
x = r\sin\theta\cos\varphi,\\
y = r\sin\theta\sin\varphi,\\
z = r\cos\theta
\end{cases}
$$ The given surface is symmetrical by $O$ , so we just need to take the integration by the object in the first quadrant. Hence, we have $0\le \theta\le\dfrac\pi2$ and $0\le \varphi\le\dfrac\pi2$ . For $r$ , we have $$r^4 = a^2r^2\sin^2\theta\sin\varphi\cos\varphi \iff r^2 = a^2\sin^2\theta\frac{\sin2\varphi}{2},$$ so $0\le r\le a\sin\theta\cdot\sqrt{\dfrac{\sin2\varphi}{2}}$ . Now we can calculate the integral in spherical coordinate. First, the given function become $$\frac{xyz}{x^2+y^2}=\frac{r^2\sin^2\theta\sin\varphi\cos\varphi\cdot r\cos\theta}{r^2\sin^2\theta}=\frac{r\cos\theta\sin2\varphi}{2},$$ so the integration is equal to $$I=\int^{\pi/2}_0d\varphi\int^{\pi/2}_0d\theta\int_0^{a\sin\theta\cdot\sqrt{\frac{\sin2\varphi}{2}}}\frac{r\cos\theta\sin2\varphi}{2}\cdot r^2\sin\theta\,dr.$$ The calculation: $$
\begin{aligned}
I&=2\int^{\pi/2}_0d\varphi\int^{\pi/2}_0d\theta\int_0^{a\sin\theta\cdot\sqrt{\frac{\sin2\varphi}{2}}}\frac{r\cos\theta\sin2\varphi}{2}\cdot r^2\sin\theta\,dr.\\
&=2\int^{\pi/2}_0d\varphi\int^{\pi/2}_0\frac{\sin\theta\cos\theta\sin2\varphi}{2}\cdot\frac{a^4\sin^4\theta\sin^22\varphi}{4}\,d\theta\\
&=2\cdot \frac{a^4}{8}\int^{\pi/2}_0\sin^32\varphi\,d\varphi\int^{\pi/2}_0\sin^5\theta\cos\theta\,d\theta\\
&=\frac{a^4}{4}\cdot\frac 23\cdot\frac 16 = \frac{a^4}{36}.
\end{aligned}
$$ Question : The correct answer is $\dfrac{a^4}{180}$ . But I can't seem to find any mistake in my argument and calculation. Can someone have a look at this and specify where did I do wrong? Thank you very much.","['integration', 'multivariable-calculus']"
3262069,Furstenberg's topological proof of infinitude of primes,"There's fairly well-known proof of infinitude of prime numbers by using topology by Furstenberg. ( Here is K.Conrad's note about the proof). As we can see in the last section, Furstenberg's topological proof is actually not topological, but only uses the terminology. In fact, it is almost same as Euclid's famous argument. So I have some questions about this proof, especially some possible generalizations. 1) How far can we generalize this to an arbitrary (infinite) ring? I think we can prove that there are infinitely many irreducible elements in $\mathcal{O}_{K}$ , a ring of integer of some number field $K$ , by using the same argument with suitable modification. Also, it seems possible to prove that any $\mathcal{O}_{K}$ has infinitely many prime ideals, at least if it has finitely many units (like totally imaginary fields). 2) Can we really prove something related to topology by using a similar argument? For example, by defining a suitable topology on some set $X$ , can we prove that there are infinitely many irreducible subsets, or elements in $X$ , where irreducible may depend on context? For example, can we prove that there are infinitely many prime geodesics on a hyperbolic surface by defining some suitable topology on it? (I think this is not a good example) Thanks in advance.","['number-theory', 'general-topology', 'prime-numbers']"
3262087,Examples of proper group actions,"Lately I encountered the definition of proper group: A $G$ -action on $X$ is called proper if the function $f:(g,x)\mapsto (g\cdot x, x)$ is proper, i.e. for any compact set $U\subset X\times X$ , the preimage $f^{-1}(U)$ is compact. But I have no clue how to check this on concrete examples. For example consider $\mathbb Z \times \mathbb R \to \mathbb R$ , $(n,x)\mapsto x+n$ . Its clear that for any $n\in \mathbb Z$ , $n^{-1}\cdot[0,1]=[-1,1]$ and so $$f^{-1}([0,1]) = \bigcup_{n\in \mathbb Z} \{n\}\times [-n,-n+1],$$ but this is still an infinite union of compact sets. Also, even if I show this, it does not really help me. It's not like in the case of continuity that it suffices to consider balls. Another example which should be easy to check is the action of $GL(V)$ on the vector space $V$ , (for symplicity $V = \mathbb R^2$ ). So here is my question: Could you provide me with some examples of proper discontinuous group actions and most importantly how to check this property ? Edit: The first answer is based on the Poincare Polyhedron Theorem which looks very useful. However, i would also like to see a more direct approach worling with the definitions.","['differential-geometry', 'analysis', 'group-theory', 'group-actions', 'compactness']"
3262088,Integrals involving powers and beta (or hypergeometric) function,"I have the three following integrals, very similar the one to the others, $$I_1^{(p)}(N)\equiv\frac{1}{2^{N+p}}\int_0^1(1+t)^{N-1}(1-t)^pB\left(\frac{1}{t+1};N+p+1,N\right)\text{d}t$$ $$I_2^{(p)}(N)\equiv 2^{2N-1}\int_0^1 t^{N-1}(1-t)^p\left(1-\frac{N+p+1}{N-1}t\right)B\left(\frac{1}{t+1};N+p+1,N\right)\text{d}t$$ $$I_3^{(p)}(N)\equiv\frac{2^{2N-1}}{N-1}\int_0^1 t^{N-1}(1-t)^pB\left(\frac{1}{t+1};N+p+1,N\right)\text{d}t$$ where $N\in\mathbb{N}$ , $p>0$ and $B(x;a,b)$ is the incomplete beta function $$B(x;a,b)=\int_0^x u^{a-1}(1-u)^{b-1}\text{d}u.$$ What I am trying to find is a closed form for the quantity $$I^{(p)}(N)\equiv I_1^{(p)}(N)-I_2^{(p)}(N)+I_3^{(p)}(N).$$ I obtained the above expressions by starting from double integrals of the form given here and proceeding in the way described in the answer. Once I arrived to these single integrals, I was not able to proceed any further, nor to do relevant simplifications by putting all together in $I^{(p)}(N)$ , which results in \begin{equation}\begin{split}
I^{(p)}(N)&=\int_0^1t^{N-1}(1-t)^pB\left(\frac{1}{t+1};N+p+1,N\right)\\[8pt]
&\quad\cdot\left\{\frac{1}{2^{N+p}}\left(1+\frac{1}{t}\right)^{N-1}+\frac{2^{2N-1}}{N-1}\left[(N+p+1)t-(N-2)\right]\right\}\text{d}t.
\end{split}\end{equation} I cannot think of a proper useful substitution, and I obtained nothing by trying some, e.g. to transform the first argument of the beta function as $1/(t+1)\to t$ . Edit1: I managed to reduce the starting expression to \begin{equation}\begin{split}
&I^{(p)}(N)\equiv R(N,p)+J(N,p)\\[7pt]
&=R(N,p)+\int_{\frac{1}{2}}^1t^{N+p}(1-t)^{N-1}\left[B\left(\frac{1}{2t};N,p+1\right)+\frac{2^{2N}}{N-1}B\left(\frac{1-t}{t};N,p+1\right)\right]\text{d}t
\end{split}\end{equation} where $R(N,p)$ is given by (I will provide the steps as soon as I can) \begin{equation}\begin{split}
R(N,p)&=B\left(\frac{1}{2};N+p+1,N\right)\left\{\frac{1}{2^{N+p}(p+1)}{}_2F_1(1,1-N;p+2;-1)+\right.\\[7pt]
&\left.\quad+\frac{2^{2N-1}}{N-1}\left[(N+p+1)B(N+1,p+1)-(N-2)B(N,p+1)\right]\right.\\[7pt]
&\left.\quad+B\left(\frac{1}{2};N,p+1\right)\right\}-B\left(\frac{1}{2};N,p+1\right)B(N,N+p+1)\\[7pt]
&\quad-\frac{1}{N-1}B(p+2,2N){}_2F_1(1,p+2;2N+p+2;-1).\end{split}
\end{equation} Now the remaining integral appears to me simpler than the starting one, and I noted that by using the relation \begin{equation}\tag{1}\label{eq1}
B(z;a,b)=B(a,b)-B(1-z;b,a),
\end{equation} in the square brakets one obtains something of the form $$B\left(\frac{u}{2};p+1,N\right)+\frac{2^{2N}}{N-1}B\left(u;p+1,N\right),$$ i.e. the two beta functions differ only by a factor $2$ in their first argument. Integrating by parts the integral in $J(N,p)$ I get \begin{equation}\begin{split}
J(N,p)&=B\left(\frac{1}{2};N,p+1\right)B(N,N+p+1)\\[7pt]
&\quad-\frac{2^{2N}+N-1}{N-1}B\left(\frac{1}{2};N+p+1,N\right)B(N,p+1)\\[7pt]
&\quad+\int_{\frac{1}{2}}^1\frac{(2t-1)^p}{t^{N+p+1}}\left[\frac{1}{2^{N+p}}+\frac{2^{2N}}{N-1}(1-t)^{N-1}\right]B(t;N+p+1,N)\,\text{d}t.
\end{split}\end{equation} with the final integral containing a single beta function, with a simple first argument. Edit2: I found something that could be useful here , and the formula cited there here . By first using Eq. (\ref{eq1}) in $I^{(p)}(N)$ and then the relation $$B(z;a,b)=\frac{z^a(1-z)^{b-1}}{a}{}_2F_1\left(1,1-b;a+1;\frac{z}{z-1}\right),$$ the starting integral can be rewritten with the hypergeometric function ${}_2F_1$ in the following form (here I neglect the terms that can be easily integrated) \begin{equation}\begin{split}
I^{(p)}(N)&=\, ...\,-\frac{1}{N}\int_0^1\frac{t^{2N-1}(1-t)^p}{(1+t)^{2N+p}}\left\{\frac{1}{2^{N+p}}\left(\frac{1+t}{t}\right)^{N-1}\right.\\[7pt]
&\left.\quad+\frac{2^{2N-1}}{N-1}\left[(N+p+1)t-(N-2)\right]\right\}{}_2F_1(1,-N-p;N+1;-t)\,\text{d}t.
\end{split}\end{equation} Now it is easy to see that the three terms are all of the form given in the link above. In particular, the first one can be expressed with the Appell series $F_3$ according to the cited reference (I checked this result numerically with Mathematica) \begin{equation}\begin{split}
&\int_0^1\frac{t^N(1-t)^p}{(1+t)^{N+p+1}}{}_2F_1(1,-N-p;N+1;-t)\,\text{d}t\\[7pt]
&\quad=\frac{B(N+1,p+1)}{2^{N+p+1}}F_3\left(N+p+1,1,p+1,-N-p,N+p+2;\frac{1}{2};-1\right).
\end{split}\end{equation} The problem is that this result does not hold for the second and third terms, due to the fact that the third argument of ${}_2F_1$ (i.e. $N+1$ ) differs from the exponent of $t$ plus one ( $2N+1$ and $2N$ respectively). Furthermore, I am not sure if further simplifications are possible.","['integration', 'definite-integrals', 'special-functions', 'calculus', 'closed-form']"
3262105,Matrix complicated equation,"Let $$A = \begin{bmatrix}
    1 & 3 & 4\\
    3 & 6 & 9\\
    1 & 6 & 4
  \end{bmatrix},$$ $B$ be a $3\times 3$ matrix and $$A \cdot A^{T} \cdot A +3B^{-1} =0$$ What would be the value of $ \det( \operatorname{adj} (A^{-1}(B^{-1}){2B^{T}}))$ ?","['matrices', 'linear-algebra']"
3262116,Is there a limit for this complex sequence?,"Interested by this question , I tried to work the more general problem of $$I_n=\int_0^\infty e^{-x}\log\big(1+\sin^{2n}(x)\big)\, dx$$ for which were found expressions of the type $$I_n=A_n  \,
   _{2n+1}F_{2n}\left(1,1,\color{red}{\textbf{#}};\color{green}{\textbf{@}};-1\right)$$ in which $\color{red}{\textbf{ #}}$ and $\color{green}{\textbf{@}}$ show nice and simple patterns. The front coefficient is $$A_n=\int_0^\infty e^{-x} \sin^{2n}(x)\,dx=(-1)^n\,\frac{i \,  n\, \Gamma \left(\frac{i}{2}-n\right)\, \Gamma (2
   n)}{4^n\,\Gamma \left(n+1+\frac{i}{2}\right)}$$ What I wonder is if $$L=\lim_{n\to \infty } \, \frac{I_n}{A_n}=\lim_{n\to \infty } \, \,
   _{2n+1}F_{2n}\left(1,1,\color{red}{\textbf{#}};\color{green}{\textbf{@}};-1\right)$$ does exist or not. Could we somehow use the fact that, for $k \pi \leq x \leq (k+1)\pi$ , $\log\big(1+\sin^{2n}(x)\big)$ looks like a gaussian ? In the table below, I tabulated some of the numerical values I obtained $$\left(
\begin{array}{cc}
 n & \frac{I_n}{A_n} \\
 1 & 0.76498434 \\
 2 & 0.76742187 \\
 3 & 0.76742296 \\
 4 & 0.76718009 \\
 5 & 0.76694124 \\
 6 & 0.76673938 \\
 7 & 0.76657308 \\
 8 & 0.76643577 \\
 9 & 0.76632132 \\
 10 & 0.76622482 \\
 20 & 0.76573433 \\
 30 & 0.76554963 \\
 40 & 0.76545318 \\
 50 & 0.76539397 \\
 60 & 0.76535394 \\
 70 & 0.76532508 \\
 80 & 0.76530328 \\
 90 & 0.76528623 \\
 100 & 0.76527254 \\
200 & 0.76521029 \\
 300 & 0.76518932 \\
 400 & 0.76517879 \\
 500 & 0.76517246 \\
 600 & 0.76516823 \\
 700 & 0.76516521 \\
 800 & 0.76516294 \\
 900 & 0.76516117 \\
 1000 & 0.76515976
\end{array}
\right)$$","['limits', 'definite-integrals']"
3262154,Proving that a certain space of compact sets is a complete metric space,"Let $(X,d)$ be a metric space, and let $K(X)$ denote the collection of all non-empty compact subsets of $X$ . Define a function, $d_h\colon K(x)\times K(x)\to\mathbb R$ by letting $$d_h(A,B)=\inf\{\varepsilon\colon A\subseteq U_\varepsilon(B) \text{ and } B\subseteq U_\varepsilon(A)\},$$ where $ U_\varepsilon(S)=\{x\in X\colon d(x, S)<\varepsilon\} $ , and the distance $d(x, S)$ from a point $x\in X$ to a non-empty subset $S$ of $X$ is defined by $d(x,S)=\inf\{d(x,s)\colon s\in S\}$ . Prove that $(K(X), d_h)$ is a complete metric space. My attempt: First, we need to show that $d_h$ is a metric. It is trivial to show that $d_h\ge 0$ and $d_h=0$ if and only if $d_h=0$ . Also, it is clear that $d_h(A,B)=d_h(B,A)$ . To see that for every $A, B, C\in K(X)$ , we have $d_h(A,C)\le d_h(A,B)+d_h(B,C)$ , we consider $\gamma_{A}:=\{x\colon d(x,A)=d_h(A,B)\}$ and $\gamma_{B}:=\{x\colon d(x,B)=d_h(B,C)\}$ . If $d_h(A,C)\le d_h(A,B)$ or $d_h(A,C)\le d_h(B,C)$ then we are through, otherwise we claim that $$d_h(B,C)\ge d_h(A,C)-d_h(A,B).$$ Suppose the converse, $\gamma_B$ would be completely lying in the interior of $\gamma_A$ . By the definition of $d_h(B,C)$ , $C$ would be lying in $ U_{d_{h}(B,C)}$ and in the interior of $$\gamma:=\{x\colon d(x,A)=d_h(B,C)+d_h(A,B)<d_h(A,C)\}.$$ Interchanging the roles played by $A$ and $C$ , we will have a contradiction with the definition of $d_h(A,C)$ . Hence $d_h$ is a metric. However, I got stuck in proving completeness. Suppose we have a sequence $\{C_n\}_{n=1}^\infty$ with $C_n\in  K(X)$ and $d_h(C_n,C_m)\to 0$ as $n,m\to\infty$ , I failed to find out the limit set. I think it should be $$\bigcap_{n=1}^\infty\bigcup_{k=n}^\infty C_k$$ but I am not even sure whether it is compact or not. Any help here? Thank you! Edit : As user10354138 pointed out, we should assume $X$ is a complete metric space.","['general-topology', 'metric-spaces', 'compactness']"
3262168,Closed operator with trivial resolvent set,"For a separable Hilbert space $H$ , and $$
D:{\frak dom}(D) \subseteq H \to H
$$ a closed operator, it is possible that $D$ has trivial resolvent. In the other words, is it possible that $T - \lambda$ id $_H$ does not admit a bounded inverse, for all $\lambda \in \mathbb{C}$ . Moreover, we know that if $T$ is self-adjoint, then it has non-empty resolvent since, for example, $i$ cannot be in the spectrum. However, if $T$ is merely closed and symmetric, or just symmetric, will the resolvent still be empty?","['hilbert-spaces', 'functional-analysis', 'unbounded-operators', 'operator-algebras']"
3262217,"Show, that $\frac {E[Xg(X)]}{E[g(X)]} \ge E[X]$ when $g$ strictly monotonic increasing","Let $g:\mathbb R \to (0,\infty), X$ real valued random variable and $g(X) \in \mathcal L^2$ and $g$ strictly monotonic increasing. Show, that $\frac {E[Xg(X)]}{E[g(X)]} \ge E[X]$ I tried something with expected values and their correlation with covariance, but I don't get the final result.","['expected-value', 'covariance', 'probability']"
3262219,Statistical distance induced by Fisher information metric on statistical manifold of categorical distribution (simplex),"I am trying to compute the information length or distance induced by the Fisher information metric on the statistical manifold of the categorical distribution (the interior of the n-dimensional simplex). I have checked each part of my computation several times. However, the result I obtain is dependent on my original choice of chart. How is this possible? Changing how the computation is done, I obtain a result consistent with another method, which I discuss at the end. However, inspection reveals that there are problems associated with that as well. How can I adapt the derivation to get the correct expression for the information distance? Here, I summarise my computation of the information distance: Suppose there are n+1 possible outcomes. Let $\mathring \Delta^n =
 \{x=(x_0, ..., x_n) \in \mathbb R^{n+1}\:|\: x_i > 0, \sum_i x_i
 =1\}$ , be the statistical manifold of the categorical distribution in this case. We choose the chart $ \psi: \mathring \Delta^n \to Im(\psi) =:U
\subset \mathbb R^n : (x_0, ..., x_n) \mapsto (x_1, ..., x_n)$ ; $\psi^{-1}(y_1, ..., y_n)= (1-\sum_{i=1}^ny_i,y_1, ..., y_n)$ . So now
  we can work on local (in fact global) coordinates on $U$ . The computation of the Fisher information metric is fairly
  straightforward
  (see https://www.ii.pwr.edu.pl/~tomczak/PDF/%5BJMT%5DFisher_inf.pdf for details). It
  is given by: $$g(y)=\sum_{\substack{i=1}}^n \frac 1{y_i} dy_i \otimes dy_i$$ Let $y^0, y^1 \in U$ be two points, we would like to find the distance $d(y^0, y^1)$ induced by the Fisher information metric. This is the
  length of the geodesic $\gamma :[0,1]\to \mathring \Delta^n$ between
  the two. The length of a curve is given by: $$L(\gamma)=\int_0^1 \sqrt{\dot \gamma(t)^Tg(\gamma(t)) \dot \gamma(t) }\:
 dt = \int_0^1 \sqrt{\sum_{i=1}^n \frac {\dot
 \gamma_i(t)^2}{\gamma_i(t)}} \: dt$$ We can obtain the geodesic via the geodesic equation $\ddot \gamma_k +
 \sum_{ij}\Gamma^k_{ij} \dot \gamma_i \dot \gamma_j =0$ , where $\Gamma^k_{ij}$ are the Christoffel symbols of the Levi-Civita
  connection. In our case the only non-zero Christoffel symbols are: $$\Gamma^i_{ii}(y)=-\frac 1{2y_i}$$ The geodesic equation then becomes: $$2\gamma_i\ddot \gamma_i - ( \dot \gamma_i)^2  =0, \forall i
 =1,...,n$$ where $\gamma_i$ is the $i$ -th component of the geodesic. It is clear from this equation that it admits a polynomial solution of
  degree two. Solving with the boundary conditions $\gamma_i(0)=y^0_i,
 \gamma_i(1)=y^1_i$ and constraint $0<\gamma_i(t)<1, \forall t$ , we obtain the geodesic: $$\gamma_i(t)=(\sqrt{y_i^0}-\sqrt
 {y_i^1})^2t^2+2(\sqrt{y_i^0y_i^1}-y^0_i)t+y^0_i, t \in [0,1]$$ Recalling the definition of length, it is possible to show that $\frac {\dot
 \gamma_i(t)^2}{\gamma_i(t)}\equiv constant, \forall i$ . One way to do this is
  to take the derivative of this expression of notice that it is zero.
  With some rearrangement this implies $$L(\gamma)= \sqrt{\sum_{i=1}^n \frac {\dot
 \gamma_i(0)^2}{\gamma_i(0)}}= 2 ||\sqrt {y^1}- \sqrt {y^0}||=d(y^0,
 y^1)$$ where $||\cdot||$ denotes the Euclidean metric and $\sqrt{\cdot}$ is
  performed componentwise. Summarising, for points $x^0, x^1 \in \mathring \Delta^n$ , $$d(x^0, x^1) = 2|| \sqrt{\psi(x^0)}-\sqrt{ \psi(x^1) }||$$ where $||\cdot||$ denotes the Euclidean metric and $\sqrt{\cdot}$ is
  performed componentwise. The resulting formula is nice because it relates the information distance to the Euclidean distance. The problem is: it depends on the choice of chart. If one chooses a different chart, e.g. $ \psi': \mathring \Delta^n \to Im(\psi') =:U'
\subset \mathbb R^n : (x_0, ..., x_n) \mapsto (x_0, ..., x_{n-1})$ , one obtains different values for the distance. Seeing this problem, I was tempted not to work in a chart at all since the statistical manifold is a subset of $\mathbb R^{n+1}$ . That is to say, doing the exact same calculations using $x$ instead of $y$ and forgetting about charts. This gives the expression: $d(x^0, x^1) = 2|| \sqrt{x^0}-\sqrt{x^1 }||$ . This formula is much nicer than the first. It coincides (although rearranged) with the result obtained in p4 of http://www.pieter-kok.staff.shef.ac.uk/docs/geometrical_Cramer-Rao.pdf , using the Euclidean distance on the n-sphere. However, inspection shows that there are a number of problems with this. To obtain it I used an n+1 dimensional Fisher information matrix, while the statistical manifold is n-dimensional. The ensuing geodesic does not lie on the simplex, i.e. the sum of its n+1 components is mostly $\neq 1$ . This second approach corresponds to extending the statistical manifold of interest to an open neighbourhood of $\mathring \Delta^n$ , and indeed, the geodesics are geodesics in this space, as I could verify numerically that they were extrema of the energy functional of paths ( https://en.wikipedia.org/wiki/Geodesic#Riemannian_geometry ). Lastly, the case $n=1$ is sketched in http://www.boris-belousov.net/2017/07/11/distance-between-probabilities/#geodesic-distance-between-distributions but doesn't coincide with any of these approaches. What did I miss? How can I adapt the derivation to get the right expression for the informational distance? Thank you for your help!","['information-geometry', 'smooth-manifolds', 'riemannian-geometry', 'differential-geometry']"
3262238,Does knowing the surface area of all faces uniquely determine a tetrahedron?,"I was wondering if the four areas of a tetrahedron faces were sufficient information to uniquely determine its shape. For example, is it true to say that if the surface areas are equal then the solid must be a regular tetrahedron? If the answer is negative, then what else we need to fully determine the shape of the tetrahedron in space?","['polyhedra', 'geometry']"
3262295,Minimal Rook Difference Grids,"In the below grid all 18 orthogonal differences are distinct, with a difference of 18 missing. Could the highest number be 18?  The resulting graph would have valence 4, making it an Eulerian Graceful graph with edges(mod 4)=2.  Rosa (1967) proved Eulerian Graceful graphs must have edges(mod 4)=0 or 3, so 18 is impossible. Thus the minimal $3\times3$ rook difference grid has $rdg(3,3)=19$ . For $rdg(1,n)$ see Golomb Ruler . $rdg(2,3)=9$ and $rdg(2,4)=16$ , as shown below. What are values for larger grids?","['graph-theory', 'recreational-mathematics', 'combinatorics']"
3262297,"Decide whether $\sum_{n=1}^{\infty}(-1)^n\frac{nx}{1+n^4x^2}$ uniformly converges on $[0,\infty)$ or not","$\newcommand{\FUNC}[1]{#1 \frac{nx}{1+n^4x^2}}$ The following problem has bothered me for a very long time. I've been trying to solve this problem for 3 days long - and it feels I tried everything. To conclude - I absolutely need the help of the professionals; And that's why I came here. I am given with the following function series: $$S(x)\equiv\sum_{n=1}^{\infty}(-1)^nf_n(x)\equiv\sum_{n=1}^{\infty}\FUNC{(-1)^n}$$ My task is to decide whether the series $S(x)$ uniformly converges on $[0,\infty)$ , or not. Things I tried: (1) I tried to use Leibniz's Alternating Series Test. I proved that $f_n(x)$ uniformly converges to $0$ , but the problem is that $f_n(x)$ is not a decreasing sequence - for every $n\in\mathbb{N}$ , there exists $0<x_0\in\mathbb{R}$ , such that $f_n(x)$ is increasing on $[0,x_0]$ , and decreasing on $[x_0,\infty)$ . I've noticed that $\lim_{n\to\infty}x_0=0$ , but that doesn't help - since it would never actually reach $0$ (that would only help to prove that the series uniformly converges on $[c,\infty)$ when $c>0$ ). (2) I tried to use Weierstrass's M Test. I found that $f_n(x)\leq\frac{1}{2n}$ for every $n\in\mathbb{N}$ , but that of course won't help (since $\sum_{n=1}^{\infty}\frac{1}{2n}$ diverges). The huge problem using the M test is that $\frac{1}{2n}$ is actually a tight bound. (3) I proved that $\displaystyle \sum_{n=1}^{\infty}\FUNC{}$ uniformly converges on $[c,\infty)$ when $c>0$ , but does not uniformly converges on $[0,\infty)$ . That wasn't very helpful, since $S(x)$ might converges conditionally. (4) Defining: $$S_m(x)\equiv\sum_{n=1}^{m}\FUNC{(-1)^n}$$ It is sufficient to show that: $$(*) \lim_{m\to\infty}\left(\sup_{[0,\infty)}\left|S_m(x)-S(x)\right|\right)\equiv\lim_{m\to\infty}\left(\sup_{[0,\infty)}\left|\sum_{n=m+1}^{\infty}\FUNC{(-1)^n}\right|\right)=0$$ in order to prove the series uniformly converges on $[0,\infty).$ Looks impossible and complicated - yet I was eager to try that too. But to no avail. I will say that my intuition is that the series does uniformly converge on $[0,\infty)$ , and that is because I used graphic calculators, and found that for every $n\in\mathbb{N}$ : $$\sup_{[0,\infty)}\left|\sum_{n=m+1}^{\infty}\FUNC{(-1)^n}\right|\leq\sum_{n=m+1}^{\infty}\frac{1}{n^2}$$ And since $\displaystyle \sum_{n=m+1}^{\infty}\frac{1}{n^2}$ converges, we can say that its limit when $m\to\infty$ is $0$ , thus proving $(*)$ . However - I couldn't prove this inequality. I tried using the triangle inequality, to distinguish between odd and even indices - nothing worked. As you might see - I really need help. Thank you very much!","['calculus', 'sequences-and-series']"
3262354,"Showing that $f(u,v) = (u,v,u^2-v^2)$ is a parametrization.","Exercise : Let $f(u,v) = (u,v,u^2-v^2), \; (u,v) \in U$ where $U$ is a coherent and open subset of $\mathbb R^2$ . Show that $f$ is a parametrization of a $C^\infty$ patch (local surface) of a surface $\Phi$ . Attempt/Question : I know that in order to show that $f$ is a regular parametrization (I don't know and cannot find the cases just for ""parametrization""), one needs to show that the function $f: U \to \Phi$ is injective and onto, while also $f_u \times f_v \neq 0 $ everywhere in $U$ . It is $f_u \times f_v = (-2u,2v,1) \neq \mathbf{0} \; \forall (u,v) \in U$ . I am having trouble showing that $f$ is injective and onto though, any guidance will be appreciated. Though, the following question arises : Question : When is $f$ just simply called a parametrization ? I assume, that when $f$ is injective and onto, while also smooth. That takes the $f_u \times f_v \neq \mathbf{0}$ out. As a starter in Differential Geometry I would really appreciate any thorough explanations. P.S. : I apologise if any term is mistakenly stated, as I am trying to properly translate the terms and the exercise from Greek.","['multivariable-calculus', 'differential-topology', 'parametrization', 'differential-geometry']"
3262408,If $f$ is invertible is $f\left(f^{-1}(x)\right)=x$ and $f^{-1}(f(x))=x$ always True?,"If $f$ is invertible, is $f\left(f^{-1}(x)\right)=x$ and $f^{-1}(f(x))=x$ always True? I have doubt in the second one since $$\sin^{-1}(\sin x)=x$$ is not always true. Any comments on this?","['algebra-precalculus', 'functions', 'trigonometry', 'inverse-function']"
3262434,Disease spread through checkerboard,"Suppose we have an infinite checkerboard (square grid) with a single “infected” square at time $t=0$ . After each discrete time step, each square that is adjacent (sharing an edge) to one or more infected squares becomes infected with probability $p$ . Infected squares stay infected forever. Let $X_t$ be the number of squares infected at time $t$ . It is probably far too complicated and difficult to explicitly calculate $\mathbb E[X_t]$ . However, we can anticipate that $X_t\sim c\cdot t^2$ for some constant $c$ that depends on $p$ . Does anyone know how to make this asymptotic estimate sharper by calculating the explicit value of $c$ in terms of $p$ ? In other words, can we find $$\lim_{t\to\infty}\frac{\mathbb E[X_t]}{t^2}=c=\space ?$$ I do know that $c=2$ when $p=1$ and $c=0$ when $p=0$ , so I would expect something like $c=2p$ or $c=2p^2$ . However, I have no idea how to go about finding $c$ . Can somebody please help?","['markov-chains', 'asymptotics', 'markov-process', 'limits', 'probability']"
3262450,Why are universal families useful?,"I recently started to read about moduli spaces. The best one can probably hope for, seems to be a fine moduli space and that is a moduli space that carries a universal family. In other words, the corresponding moduli functor is represented by a scheme. These are quite abstract notions but I think, I'm fine with the definitions. One point that I didn't really get is what these families are really good for. For example, take the Grassmannian. It is a fine moduli space and carries the universal family $$U=\{(V,p)\in Gr(k,n)\times \mathbb P^n\mid p\in V\}$$ and we have natural projections $p: U\to Gr(k,n)$ and $q:U\to \mathbb P^n$ . $p$ gives $U$ the structure of an algebraic bundle over the Grassmannian and this bundle is the tautological one (i.e. the fibre over a point is the subscheme parameterised by this point). In 3264 and all that by Eisenbud and Harris, they compute the tangent sheaf of the Grassmannian from this which is fair enough an application of the existence of an universal family but still seems to involve other things that are special to Grassmannians. In general, it is not clear to me, why such a family is useful. Where does it make our lifes simpler? Are there standard arguments using the existence of universal families?","['universal-property', 'algebraic-geometry', 'moduli-space']"
3262464,"Find $\frac{\partial^2 f}{\partial x \partial y}(0, 0)$ given that $\lim_{(x, y) \to (0,0)} \frac{f(x, y) - \tan{(x)}\sin{(y)}}{x^2 + y^2} = 0$.","$f \in C^2(\mathbb{R^2})$ satisfies $$\lim_{(x, y) \to (0, 0)} \frac{f(x, y) - \tan{(x)}\sin{(y)}}{x^2 + y^2} = 0.$$ Find $\frac{\partial^2 f}{\partial x \partial y}(0, 0).$ I've tried to deduce something from the limit and definition of partial derivatives but with no effect.","['partial-derivative', 'limits', 'multivariable-calculus', 'real-analysis']"
3262481,"Why should the equality of mixed partials be ""intuitively obvious""?","I am reading Ted Shifrin's excellent book Multivariable Mathematics . It claims that the equality of mixed partials is ""an intuitively obvious result, but the proof is quite subtle"". However, I guess I must be thinking in the wrong way, because I do not see the intuition behind this result. This is how I think about it: Let $f:\mathbb{R}^2 \to \mathbb{R}$ . I think of $f_x$ as a ""field of slopes"" in the $x$ -direction. If we analyze the movement in the $y$ direction in this field of slopes, we get $f_{xy}$ . Now $f_y$ is a ""field of slopes"" in the $y$ -direction. If we analyze movement in the $x$ direction here, we get $f_{yx}$ . It's unclear to me why movement in the $x$ -direction in the ""field of $y$ -slopes"" should be the same as movement in the $y$ -direction in the ""field of $x$ -slopes"".","['multivariable-calculus', 'analysis', 'real-analysis']"
3262513,Calculating the probability of $ (Z-1)^2 \leq XY$,"We randomly choose three numbers $X, Y, Z$ $\in [0,1]$ . Calculate the probability that $ (Z-1)^2 \leq XY$ . I have tried to observe just the ""edge"" i.e. $ (Z-1)^2  = XY$ but I am pretty much stuck on calculating the boundaries for double integral. Any hint helps!",['probability']
3262522,Different functions having the same derivative [duplicate],"This question already has answers here : How come $\frac{1}{1-x}$ and $\frac{x}{1-x}$ have the same derivative? (2 answers) Closed 5 years ago . Let $g(x) = \frac{1}{1-x}$ and $h(x) = \frac{x}{1-x}$ : Their derivatives are: $$\frac{d}{dx}g(x)=\frac{1}{\left(1-x\right)^2}$$ $$\frac{d}{dx}h(x)=\frac{1}{\left(1-x\right)^2}$$ Integrating the RHS I should get back the initial function(s): $$\int \frac{1}{\left(1-x\right)^2}\;\mathrm dx=\frac{1}{1-x} + C$$ But I obviously get only one of the expressions, namely $g(x)$ .
So my question is how can both functions have the same derivative even though when integrating the derivative, I get back only one of the expressions? What am I missing? Does it have something to do with the $C$ constant?","['integration', 'calculus', 'derivatives']"
3262588,Can a non-invertible function be inverted by returning a set of all possible solutions?,"Is there a concept of inverting a non-invertible function by returning a set of the possible solutions? For example: $g(x) = x^2$ Would it be possible to create an inverse function $f(y)$ where, for example: $f(4) = \{-2,2\}$ (I'm pretty sure I'm going about this wrong, but I'm still learning so I don't know *how* I'm wrong)","['functions', 'inverse-function']"
3262600,"Probability that $AX^2+BX+C=0$ has only real roots for $A,B,C \sim Unif(0,1)$ [duplicate]","This question already has answers here : Probability that a quadratic polynomial with random coefficients has real roots (6 answers) Closed 5 years ago . From chapter 6, practice exercise 26 (b) from ""A First Course in Probability"" by Sheldon Ross (working it for my own recreation): Given R.V.s $A,B,C\sim_{iid}Unif(0,1)$ and asked to find the probability that $AX^2+BX+C=0$ has real roots (ie $B^2>4AC$ ). Can someone help me understand how to set up the integral to compute the desired probability: $$
Pr(B^2>4AC)=Pr(B>2\sqrt{AC})
$$ * $\{B<-2\sqrt{AC}\}$ has probability zero since $B\sim Unif(0,1)$ and, therefore, cannot be negative. I understand that, in order for $B$ to be between 0 and 1, we need $0<\sqrt{AC}<\frac{1}{2} \rightarrow 0<AC <\frac{1}{4}$ , but I am having trouble coming up with an integral that makes sense. Thanks!","['probability-distributions', 'probability']"
3262648,Reduce number of arguments by linear combinations,"Given a nonlinear function $f : \mathbb{R}^n \rightarrow \mathbb{R}$ . My goal is to reduce the number of arguments that this function takes using only linear combinations of its original arguments. Let $x \in \mathbb{R}^n$ be the original arguments and $$
\tilde{x} = A x
$$ the ""reduced"" arguments $\tilde{x} \in \mathbb{R}^m$ with $A \in \mathbb{R}^{m \times n}$ and $m \leq n$ . So the task is then to find $A$ and $g : \mathbb{R}^m \rightarrow \mathbb{R}$ such that $g(\tilde{x}) = f(x) \, \forall x \in \mathbb{R}^n$ and that $m$ is as small as possible. Example 1 : Take $f : \mathbb{R}^4 \rightarrow \mathbb{R}$ with $$
f(x) = (x_1 + x_2)^2 + (x_3 - x_4)^2
$$ It is now easy to choose a linear combination to reduce the number of arguments of $f$ by $$
\tilde{x} = \begin{bmatrix}
\tilde{x}_1 \newline
\tilde{x}_2
\end{bmatrix} = A x =  \begin{bmatrix}
1 & 1 & 0 & 0 \newline
0 & 0 & 1 & -1
\end{bmatrix} \begin{bmatrix}
x_1 \newline
x_2 \newline
x_3 \newline
x_4
\end{bmatrix} = \begin{bmatrix}
x_1 + x_2 \newline
x_3 - x_4
\end{bmatrix}
$$ So we can rewrite $f$ as the function $g : \mathbb{R}^2 \rightarrow \mathbb{R}$ in terms of the new arguments as $$
g(\tilde{x}) = \tilde{x}_1^2 + \tilde{x}_2^2
$$ Now $g$ is a function of only 2 arguments, so $m < n$ because $2 < 4$ . I  assume that this is also the smallest $m$ possible here. Example 2 : Take $f : \mathbb{R}^4 \rightarrow \mathbb{R}$ with $$
f(x) = x_1 x_2 x_3 x_4
$$ Here, I see no possiblity to reduce the number of arguments somehow using the described technique. So I would assume that here, the smallest possible $m = n = 4$ . Questions : Three questions basically. Is there a way to always find the smallest $m$ , the related $A$ matrix and $g$ function? If not, a way to find some $m < n$ , if it exists, the related $A$ matrix and $g$ function? Is this a known (or related to a known) problem? If yes, references are appreciated. Note : The two examples are multivariate  polynomials, but I would be also interested in a solution for non-polynomial $f$ .","['functions', 'linear-algebra', 'linear-transformations', 'real-analysis']"
3262655,Perfect powers of the form $2^n\pm n$?,"In the range $$1\le n\le 10^5$$ the only perfect powers of the form $$2^n\pm n$$ are $$2^5-5=3^3$$ and $$2^7-7=11^2$$ How can I prove that there are no more perfect powers of this form ? The case of even $n$ allows at least to find the possible perfect squares, but I do not have an idea for a complete solution.","['number-theory', 'elementary-number-theory', 'perfect-powers']"
3262656,Show that $z^5 - z +16$ has two roots in the right half plane,"Show that the polynomial $$z^5 - z +16$$ has all of its roots in the region $$\{z\in \mathbb{C} \; | \; 1< |z| < 2\},$$ and show that two of its roots have positive real part. I have used Rouché's theorem to prove that all of its roots are in the above region. But I don't have any clue on how to show the second part, that two of the roots are in the right half plane.","['complex-analysis', 'rouches-theorem', 'polynomials', 'complex-integration', 'complex-numbers']"
3262663,Evaluate $\sum_{n=1}^\infty\frac{(-1)^{n-1}H_n}{(2n+1)^3}$,How to prove that $$\sum_{n=1}^\infty\frac{(-1)^{n-1}H_n}{(2n+1)^3}=\frac{7\pi}{16}\zeta(3)+\frac{\pi^3}{16}\ln2+\frac{\pi^4}{32}-\frac1{256}\psi^{(3)}\left(\frac14\right)$$ where $H_n=1+\frac1{2}+\frac1{3}+...+\frac1{n}$ is the $n$ th harmonic number. This sum was proposed by Cornel and I solved it using integration but can we solve it using series manipulation? The integral representation of the sum is $\ \displaystyle\frac12\int_0^1\frac{\ln^2x\ln(1+x^2)}{1+x^2}\ dx$ in case it is needed.,"['integration', 'polygamma', 'real-analysis', 'harmonic-numbers', 'calculus']"
3262680,Question about convergence of nets in $X^*$,"Let $X$ be a Banach space with dual $X^*.$ Let ${a_i}$ and ${b_i}$ be two nets in $X^*$ such that $a_i$ is norm-bounded in $X^*$ and $a_i \to a$ and $a_i + b_i \to 0$ ,  where in both the convergence is understood in terms of weak-star Topology. My question is that from above can we conclude that the $(b_i)$ is norm-bounded or at least admits a bounded subnet ? 
What if $X$ be reflexive ?","['general-topology', 'functional-analysis', 'real-analysis']"
3262727,"$ \mathbb{A}^{1}_{k}\backslash \lbrace a_{1},\dots,a_{l} \rbrace \cong \mathbb{A}^{1}_{k}\backslash \lbrace b_{1},\dots,b_{m} \rbrace. $ Is $ l = m?$","By assumption, the points $ a_{1},\dots,a_{l} $ are distinct from $ b_{1},\dots,b_{m}. $ We know that for an affine variety $ V $ and for $ f \in k[V], $ we have the quasi-affine variety $$ V_{f} = V \backslash V(f) = \lbrace P \in V\;|\;f(P) \neq 0 \rbrace, $$ and furthermore $ V_{f} $ is isomorphic to $ \operatorname{Spec}k[V]_{f}. $ I'm not sure about the following: So if $$ f:\mathbb{A}^{1}_{k}\backslash \lbrace a_{1},\dots,a_{l} \rbrace \longrightarrow  \mathbb{A}^{1}_{k}\backslash \lbrace b_{1},\dots,b_{m} \rbrace, $$ is an isomorphism, then we have some resulting isomorphism $$ f^{*}: k[x]_{\prod_{i=1}^{l}(x-a_{i})} \longrightarrow k[x]_{\prod_{i=1}^{m}(x-b_{i})}.    $$ Am I on the right track?",['algebraic-geometry']
3262735,Fibonacci sequence and other metallic sequences emerged in the form of fractions,"The Fibonacci sequence $P_n = P_{n-1}+P_{n-2}$ is $$1,1,2,3,5,8,13,21,34,55,89,144,233,377, 610, \cdots $$ I learnt that the fraction $1/89$ contains all the numbers in the sequence. $$\begin{align}
\frac{1}{89}&= 0.\overline{01123595505617977528089887640449438202247191~}\\
&=0.01+0.001+0.0002+0.00003+0.000005+0.0000008+~\\
&~~~~~0.00000013+0.000000021+0.0000000034+0.00000000055+ ~\\
&~~~~~0.000000000089+0.0000000000144+0.00000000000233+~\\
&~~~~~0.000000000000377+0.0000000000000610+\cdots
\end{align}$$ where the over line represents repeated cycle. Rule of the number of zeros (not sure if this is right or not): Don't add zero for the next number if it is ""smaller"" than the previous number. To compare numbers, we only keep the first digit and make the rest of the digits after the decimals point. For example, $13$ in this case is ""smaller"" than $8$ because $1.3<8$ , so we don't add any zero for $13$ -- the same $7$ zeros in front of both $13$ and $8$ . On the other hand, if the number in the sequence is greater than or equal to the previous one, we would add a zero before the greater number. For example, $3>2$ , so we add a zero in front of $3$ , making $5$ zeros in front of $3$ and $4$ zeros in front of $2$ . I think that the rule of the number of zeros applies to all the metallic sequences. If not, let's assume it is for now and keep on reading. I then decided to further explore other metallic sequences. Lets define the $n^{th}$ metallic sequence $$\sigma_n: P_n = nP_{n-1}+P_{n-2}$$ In this post, the Fibonacci sequence is $\sigma_1$ . 
The next metallic sequence $\sigma_2$ , or the silver sequence, is $$\sigma_2: P_n = 2P_{n-1}+P_{n-2}$$ $$1,2,5,12,29,70,169,408,985,2378,5741,13860,33461,80782,\cdots$$ I took a guess that $1/79$ would contain all the numbers in $\sigma_2$ , and it seems like I am correct for the numerical value although I am not sure how to prove the relationship. $$\begin{align}
\frac{1}{79}&=0.\overline{0126582278481}\\
&= 0.01+0.002+0.005+0.00012+0.000029+0.0000070+~\\
&~~~~~0.00000169+0.000000408+0.0000000985+~\\
&~~~~~0.00000002378+0.000000005741+0.000000001386+~\\
&~~~~~0.00000000033461+0.000000000080782+\cdots
\end{align}$$ I will present two more cases so that you will get the idea of the pattern. Here is $\sigma_3$ , or copper sequence: $$\sigma_3: P_n = 3P_{n-1}+P_{n-2}$$ $$1,3,10,33,109,360,1189,3927,12970,42837,141481,467280$$ $$\begin{align}
\frac{1}{69}&=0.\overline{01449275362}\\
&= 0.01+0.003+0.0010+0.00033+0.000109+0.0000360+~\\
&~~~~~0.00001189+0.000003927+0.0000012970+~\\
&~~~~~0.00000042837+0.000000141481+0.000000046728+~\cdots
\end{align}$$ Lastly, I will present the case for $\sigma_{9}$ : $$\sigma_9: P_n = 9P_{n-1}+P_{n-2}$$ $$1,9,82,747,6805,61992,564733,5144589,46866034,426938895,3889316089,\cdots$$ $$\begin{align}
\frac{1}{9}&=0.\overline{1}\\
&=0.01+0.009+0.0082+0.00747+0.006805+0.0061992+~\\
&~~~~~0.00564733+0.005144589+0.0046866034+0.00426938895+~\\
&~~~~~0.003889316089+\cdots
\end{align}$$ For $\sigma_9$ , I know that if you only type these numbers into the calculator, the value is by no way close to $1/9$ because the series approaches $1/9$ very slowly, so we have to type in a lot of numbers to get the value close to $1/9$ . Now, I have two questions on hand: $1)$ How to prove that a fraction, such as $1/89,~1/79,~1/69,\cdots,~1/9$ ,  is the sum of all the numbers in the corresponding metallic sequence? $2)$ I am trying to find a fraction that contains all the numbers in $\sigma_{10}$ , but with no avail. Are there any other fractions that contain all the numbers in the metallic sequence $\sigma_{10}$ ? Maybe also fractions for $\sigma_{11},~ \sigma_{12}$ , and so on?","['golden-ratio', 'fractions', 'sequences-and-series']"
3262751,The closure of the interior of the boundary is a subset of the closure of the intersection between a set and the interior of the boundary,"The statement is the following: Let X be a topological space and let A be a subset of X. Then $ cl(int(\partial A)) \subseteq cl(A \cap int (\partial A) ) $ Notation: $cl$ means closure, $\partial $ means boundary of a set, and $int $ means interior of a set. These are the posts I have read so far: A set which the interior of its boundary is not empty When is the closure of an intersection equal to the intersection of closures? If the interior of the boundary of a set is nonempty, then the interior of that set is empty However I have not been able to prove it yet. How can I prove that statement?","['elementary-set-theory', 'general-topology', 'convex-analysis', 'real-analysis']"
3262785,Integral $\ 4\int_0^1\frac{\chi_2(x)\operatorname{Li}_2(x)}{x}\ dx+\int_0^1\frac{\log(1-x)\log^2(x)\log(1+x)}{x}\ dx$,How to prove that $$4\int_0^1\frac{\chi_2(x)\operatorname{Li}_2(x)}{x}\ dx+\int_0^1\frac{\log(1-x)\log^2(x)\log(1+x)}{x}\ dx=\frac{29}4\zeta(2)\zeta(3)-\frac{91}8\zeta(5)$$ Where $\chi_2(x)=\sum_{n=1}^\infty\frac{x^{2n-1}}{(2n-1)^2}$ is the Legendre Chi function and $ \operatorname{Li}_2(x)=\sum_{n=1}^\infty\frac{x^n}{n^2}$ is the Dilogarithm function. This integral was proposed by Cornel.,"['integration', 'definite-integrals', 'harmonic-numbers', 'calculus', 'polylogarithm']"
3262821,Question about evaluating a Definite Integral w/ U-Substitution,"My textbook asked me to evaluate the integral $\int_1^5\left(\frac{x}{\sqrt{2x-1}}\right)$ using u-substitution. I rewrote the integrand as $x*(2x-1)^{-\frac{1}{2}}$ , but I soon became stuck because I couldn't settle on what was $g'(x), g(x),$ or $F(x)$ (I didn't know how to define u or du). I checked the book (this was an example problem) and it said to set u = $\sqrt{2x-1}$ . How did it come to this conclusion? Thanks for your help.","['integration', 'calculus']"
3262822,Is a regular tetrahedron the most optimal equilateral triangle based pyramid and if so how would you prove it?,"If one is to find the minimum surface area to enclose a given volume for this type of pyramid, would they arrive at a tetrahedron?","['optimization', 'calculus', 'geometry']"
3262907,Is this true $(A – B)\cap(C–B)=A–(B\cup C)$?,"The Problem in my textbook was : For all sets $A,B$ and $C$ show that $(A–B)\cap(C–B)=A–(B\cup C)$ I tried the problem for about half an hour. Then I finally tried drawing a Venn diagram and I found out that the L.H.S was not equal to the R.H.S. I even tried using an example Consider the sets $A=\{1,2,3,4\},B=\{3,4,5,6\},C=\{4,8,9,1\}$ (I've taken the sets randomly as there was no constraints or conditions specified in the problem.) On the L.H.S you will get: $\{1,2\}\cap\{8,9,1\}=\{1\}$ And on the R.H.S you will get : $\{1,2,3,4\}-\{3,4,5,6,8,9,1\}=\{2\}$ Therefore, as you can see L.H.S is clearly not equal to R.H.S. Can someone verify this and if the problem is indeed incorrect, can someone modify it?",['elementary-set-theory']
3262920,What does it mean for a transition kernel to be a density with respect to a sigma-finite measure?,"My background in math (never took a course on measure theory) is weak, but I have been studying it for probability theory here and there as needed. I like to think I understand what a measure, probability measure, and $\sigma$ -finite measure is (as a user), but I am reading a paper on Markov chain Monte Carlo, and in its excerpt on convergence theory, it states the following: Let $X = (X^0, \dots, X^t, \dots)$ , $X^t \in E \subseteq \mathbb{R}^n$ be a Markov chain with transition kernel $K:E\times E \rightarrow \mathbb{R}^n$ such that, with respect to a $\sigma$ -finite measure $\nu$ on $\mathbb{R}^n$ , $$P(X^t \in A \mid X^{t-1} = x) = \int_A K(x,x') d\nu(x') + r(x) I[x\in A]$$ If we define $K^{(t)}(x,x') = \int K^{(t-1)}(x,y)K(y,x')d\nu(y)+K^{(t-1)}(x,x')r(x') + \{1-r(x)\}^{t-1}K(x,x')$ then $K^{(t)}(x_0, \cdot)$ is the density (with respect to $\nu$ ) of $X^t$ given $X^0 = x_0$ This really threw me off. I understood measures as functions that map $\sigma$ -algebra (sets) to the non-negative real numbers. My question is, what does ""with respect to a $\sigma$ -finite measure $\nu$ on $\mathbb{R}^n$ "" mean? From the definitions I have studied about measures on $\sigma$ -algebra, I do not how a density is defined ""with respect to"" one.","['measure-theory', 'monte-carlo', 'markov-chains', 'probability-theory', 'probability']"
3262922,Can a group be recovered from its order and automorphism? [duplicate],This question already has an answer here : If $G$ and $H$ are nonisomorphic group with same order then can we say that $\operatorname{Aut}(G)$ is not isomorphic to $\operatorname{Aut}(H)$? (1 answer) Closed 5 years ago . Does there exists two non-isomorphic finite groups $G$ and $H$ of same cardinality with $Aut(G) \cong Aut(H)$ ? I know that the non-cyclic group of order $4$ i.e. $\mathbb{Z}_{2} \oplus \mathbb{Z}_{2}$ and the non-abelian group of order $6$ i.e $S_{3}$ have isomorphic automorphism group. But I am interested in groups with same order? I don't know whether  such example exists or not?,"['group-theory', 'abstract-algebra', 'finite-groups']"
3262944,Hadamard Product Matrix Norm Inequality,"Let $A \odot B$ denote the Hadamard or entry-wise product of two matrices with equivalent dimensions.  In this post ( Hadamard product: Optimal bound on operator norm ) it is claimed without proof that if $A$ is positive-definite, then $$\|A \odot B\|_2 \leq \max_{i, j}|A_{i,j}| \|B\|_2$$ where $\| \cdot \|_2$ is the matrix operator norm induced from the Euclidean norm.  Does anyone know how to prove this or have a reference?  To me it does not seem so simple.",['matrices']
3262947,"Topics in Algebra - N. Herstein Exercise from Section 2.12, Question 16 (Page 103)","Please help me with this Herstein exercise (Page 103,Sec 2.12, Ques 16). \begin{array} { l } { \text { If } G \text { is a finite group and its } p \text { -Sylow subgroup } P \text { lies in the center of } } \\ { G , \text { prove that there exists a normal subgroup } N \text { of } G \text { with } P \cap N = (e)} \\ {  \text {and } P N = G . }  \end{array} I got to know about more general theorems like Schur-Zassenhaus Theorem or Burnside's normal p-complement theorem from which this can be deduced as corollary. But, I want a solution which just uses theory built in Herstein's book. The question just before this is \begin{array} { l } { \text { Let } G \text { be a finite group in which } ( a b ) ^ { p } = a ^ { p } b ^ { p } \text { for every } a , b \in G , } \\ { \text { where } p \text { is a prime dividing } o ( G ) \text { . Prove } } \\ { \text { (a) The } p \text { -Sylow subgroup of } G \text { is normal in } G \text { . } } \\ { \text { (b) If } P \text { is the } p \text { -Sylow subgroup of } G , \text { then there exists a normal } } \\ { \text { subgroup } N \text { of } G \text { with } P \cap N = ( e ) \text { and } P N = G \text { . } } \\ { \text { (c) } G \text { has a nontrivial center. } } \end{array} I have solved it by first proving, for $p^n|o(G)$ and $p^{n+1} \not| o(G)$ , $$P=\{x\in G : x^{p^n}=e\}$$ is unique $p-Sylow$ sugroup of G and then taking a homomorphism $\phi:G\to G$ defined by $\phi(g)=g^{p^n}$ , where $p^n$ is order of $p-Sylow$ subgroup of G. Then $\phi(G)= N$","['finite-groups', 'normal-subgroups', 'abstract-algebra', 'sylow-theory', 'group-theory']"
3263027,"Prove $\forall m\in\mathbb{N},m\neq1:\quad\sum_{n=1}^{m}\frac{1}{n^2}\leq\int_1^m\frac{\sqrt{x^6+4}}{x^3}\ dx$","So I have stumbled upon this question and was very intrigued on how to solve it. I have an intuitive solution, but I guess that's not enough. I would be glad if you could shed some light on how to make it more rigorous. Prove the following inequality: $$\forall m\in\mathbb{N},m\neq1:\quad\sum_{n=1}^{m}\frac{1}{n^2}\leq\int_1^m\frac{\sqrt{x^6+4}}{x^3}\ dx$$ My intuitive solution : Define $f(x)=\frac{1}{x^2}$ on the interval $[1,m]$ . Intuitively , the summation of the values of $f$ along its graph on the interval $[1,m]$ would be greater than the discrete summation of the series, since every element of the series is already being summed in the integral; alongside with other positive (real) values. Thus, defining: $$\gamma(t)=\left(t,\frac{1}{t^2}\right) \implies \gamma'(t)=\left(1,-\frac{2}{t^3}\right) \\ t\in[1,m]$$ We can say that: $$L(\gamma)\equiv\int_\gamma ds\geq\sum_{n=1}^m\frac{1}{n^2}$$ Evaluating $\displaystyle \int_{\gamma}ds$ , we will get the desired inequality: $$\fbox{$\int_1^m \frac{\sqrt{t^4+6}}{t^3}\ dt \geq \sum_{n=1}^{m}\frac{1}{n^2}$}$$ I would be glad to hear your thoughts. Thanks! P.S.: Since the integrand is greater than $1$ , we can say that when $m\to\infty$ , the integral diverges. Thus, since the series converges, the inequality becomes trivial for large enough values of $m$ . The interesting values of the inequality would be as low as possible, specifically $m=2$ .","['calculus', 'definite-integrals', 'sequences-and-series']"
3263051,Probability Dilemma,"The teacher gave us a question: We flip a coin. If it was Heads, we roll a die and if it was Tails, we flip three other coins. What's the probability of exactly having one coin as Heads? I first calculated $n(S)= 1 
\cdot 6 + 1 \cdot 2 \cdot 2 \cdot 2$ , then $n(a) = 1 \cdot 6 + 1 \cdot 1 \cdot 1 \cdot 3$ . $P(a)=n(a)/n(S) = 9/14$ . For calculating $n(S)$ I first considered the case of the (first) coin being Heads and multiplied by $6$ (for the die), then calculated the case of the (first) coin being Tails and a $2 \cdot 2 \cdot 2$ for the coins. You'll get a sense of what I did for calculating $n(a)$ . The teacher told that my answer was incorrect and then wrote the answer as $6 \cdot (1/12) + 3 \cdot (1/16)=11/16$ and told me to find the problem of my answer for the next session. I don't think there's anything wrong with my answer and my teacher's wrong.",['probability']
3263059,Why must the coordinates of a point on a circle be sinusoidal as a function of the angle? [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 5 years ago . Improve this question A defining feature of radians as a unit of measurement is that if an angle $\theta$ is expressed in radians, the height of a point on the unit circle at this angle is $\sin(\theta)$ . Is it possible to choose a different unit of measurement for the angle so that we get something other than a sinusoid? Why doesn't the height of a point on the unit circle as a function of the angle give us a well-shaped half-circle on each half-period rather than a sinusoid? Wouldn't such a circle shape be more fundamental than a sinusoid? If not, why must the coordinates of a point on the unit circle be sinusoidal as a function of the angle? I may have a very basic error in my thought, maybe sines were not taught properly to me, but when I learned them they were something that suddenly came out of nowhere. I know it's like the movement of a wriggling snake or the time diagram of a spring that is bouncing , but I still have this question in my head. I would be thankful if I hear your input on it.","['trigonometry', 'angle']"
3263064,Showing that $f:S_1 \to S_2$ is a conformal mapping.,"Exercise : Given the surfaces $S_1 = \{ x \in \mathbb R^3 : \|x\| = 1\}$ and $S_2 = \{x \in \mathbb R^3 : \|x\| = r\}$ where $r >0$ , check if the mapping $f:S_1 \to S_2$ with the formula $f(x,y,z) = (rx,ry,-rz)$ is conformal. Thoughts : According to my Differential Geometry notes, I have the following equivalent definitions : 1 : The topical diffeomorphism $f : S_1 \to S_2$ is conformal, if and only if $f_p^* = \lambda(p)\langle \cdot, \cdot\rangle_p, \; \forall p$ where $\lambda : S_1 \to \mathbb R$ is a function. 2 : The topical diffeomorphism $f:S_1 \to S_2$ is conformal, if and only if $\forall r$ patches around $p$ , $f \circ r$ is also a patch around $f(p)$ with : $$E_p = \lambda(p)E_{f(p)}, \; F_p = \lambda(p)E_{f(p)}, \; G_p = \lambda(p)G_{f(p)}$$ I assume that the second equivalent definition is or more use, as we have an explicit formula for $f$ that can help finding the fundamental form. But, I am kind of stuck in decoding it. What is $E_p$ and what $E_{f(p)}$ in that case ? Also, I first need to show that $f$ is a Diffeomorphism, which I found to have many equivalent remarks here . Any explanation or thorough elaboration will be much appreciated as I am still a beginner in differential geometry regarding my experience on the subject.","['conformal-geometry', 'multivariable-calculus', 'diffeomorphism', 'differential-geometry']"
3263067,Renewal for Levy Processes,"Suppose $X(t)$ is a Levy process with almost surely positive increments (for all $t_1 < t_2$ $P(X(t_1) < X(t_2)) = 1$ ) Define $$\nu X(t) := \sup \{\tau \in \mathbb{R_+}| X(\tau) < t\}$$ It is not hard to see, that $\nu X$ is also a stochastic process with almost surely positive increments. My question is: Is it a Levy process too? It is not hard to see, that $\nu X (0) = 0$ and for all $t_1 < t_2$ $\nu X(t_1) - \nu X(t_2) = \mu\{\tau \in \mathbb{R}| X(\tau) \in (t_1; t_2]\}$ , which means, that the conditions (1), (3) and (4) are satisfied. However, I do not know, whether the increments of $\nu X(t)$ are independent or not. They are indeed uncorrelated, but uncorrelatedness $\neq$ independence. One can also notice, that $\nu \nu X(t) = X(t)$ almost surely. However, it does not seem to be very helpful.","['levy-processes', 'renewal-processes', 'stochastic-processes', 'probability-theory', 'probability']"
3263074,Matrix optimization problem,"I am having some difficulty understanding an argument in a book. The authors claim that the following Theorem is a direct consequence of the preceding lemma, but fail to give details. Either it is completely trivial and I am not seeing it, or there are some details missing. Lemma : Let $A$ be a $n\times n$ symmetric positive definite matrix over $\mathbb{R}$ with eigenvalues $\lambda_1>\lambda_2>\ldots>\lambda_n$ and associated eigenvectors $v_1,v_2,\ldots v_n$ . Then we have $$
 \max\{x^TAx: ||x||=1, \langle x,v_j\rangle=0 \,\,\text{for}\,\, 1\leq
j\leq i-1\}=\lambda_i, $$ where the maximum is attained precisely at the points $v_i$ and $-v_i$ . Theorem :
  Let $p\leq n$ . Consider the following optimization problem \begin{align} \max\sum_{k=1}^p &\langle Au_k,u_k\rangle\\
 s.t:\,\,(u_1,\ldots u_p)&\,\,\,\text{is an orthonormal system}
 \end{align} The claim is that the optimal value is $\sum_{k=1}^p \lambda_k$ with
  optimal solution $(v_1,v_2,\ldots,v_p)$ , and that the solution is unique up to sign and permutation. It seems to me that the optimization is carried out by successively maximizing each summand. I fail to understand why this is legitimate. What am I missing here? Thanks","['nonlinear-optimization', 'matrices', 'linear-algebra', 'optimization', 'matrix-decomposition']"
3263099,confused about a matrix problem,"question: $$A=\begin{bmatrix} 1&2 \\3&4\end{bmatrix} ,
B=\begin{bmatrix} k&2 \\3&9\end{bmatrix},
(AB)^5=A^5B^5$$ what's the value of k? I know I can let $AB=BA$ , which is $$\begin{bmatrix}\ k+6&20\\3k+12&42\end{bmatrix}=\begin{bmatrix}\ k+6&2k+8\\30&42\end{bmatrix},$$ and I can get $k=6$ . But I am not pretty sure that it's the only answer.  I want to know if there is any other answer or solution to this question.","['matrices', 'linear-algebra']"
3263166,showing the pdf of n-th order statistics,"I am working on a mathematical stats assignment and I got stuck here. Letting $X_1, X_2, ... ,X_n$ a random sample from uniform(0, $\theta$ ), and Y is n-th order statistic, I need to show that the pdf of Y is: $p(y|\theta) = \frac{ny^{n-1}}{\theta^{n}}, 0<y<\theta$ I know that n-th order is $g_n(y_n) = nf(y_n)[\int_{-\infty}^{y_n}f(x)dx]^{n-1}.$ I plugged in the uniform distribution $f(x)=\frac{1}{\theta}$ and tried to solve the integral, and it didn't show the result I wanted. How should I approach this? Should I assign something else for $f(x)$ ? Also, If I want to find the joint pdf f(y,θ) of Y and θ, which the prior pdf $\lambda(\theta)$ is given, I just multiply $p(y|\theta)$ to get the f(y, $\theta$ ), right? Thanks in advance.","['statistics', 'uniform-distribution', 'bayesian', 'order-statistics']"
3263225,Existence of a specific function,"I am supposed to construct a function, which is defined on interval $[a,b]$ and differentiable on $(a,b)$ , as well as $f(a)=f(b)$ and $$f{}'(x)\neq 0$$ for each $x$ , which belongs to $(a,b)$ . I was thinking about Rolle's theorem and thought, that this is not possible, but, Rolle's theorem does not satisfy it.
Can anyone help me?","['functions', 'real-analysis']"
3263254,"Checking if $f: \Phi_1 \to \Phi_2 \; ; f_1(\theta, v) \mapsto f_2(\theta, \sinh v)$ is an isometry.","Exercise : Consider the surfaces : $$\Phi_1 : f_1(\theta, v) = \left( \cos \theta \cosh v, \sin \theta \cosh v, v\right), \; (\theta, v) \in (0,2 \pi) \times \mathbb R$$ $$\Phi_2 : f_2(\phi, u) = \left( u\cos \phi , u\sin \phi, \phi\right), \; (\theta, v) \in (0,2 \pi) \times \mathbb R$$ Check if the following mapping is an isometry between them : $$f: \Phi_1 \to \Phi_2 \;; f_1(\theta, v) \mapsto f_2(\theta, \sinh v)$$ Thoughts-Question : To start off, this is a Differential Geometry related question which I am not that experienced, thus if it feels trivial, excuse me. From my continuous experience, interest and studying of a whole differnt subject (Functional Analysis - Operator Theory), I know very well that a Linear Isometry is essentialy achieved if $\|Av\|_Y = \|v\|_X$ where $A:X \to Y$ is a linear operator. This means that they are distance preserving. It is a global isometry if it also is surjective. Now, a similar correspondance can be found in Differential Geometry. Specifically, if we have $2$ surfaces, $\Phi_1$ and $\Phi_2$ , then the function $f: \Phi_1 \to \Phi_2$ is an isometry if and only if $f:\Phi_1 \to \Phi_2$ is a differentiable mapping which is an inective and surjective local isometry. Now, I am having a hard time proving the following statements. First of all, I start by constructing my function as stated by the exercise body : $$f(f_1(\theta,v)) = f_2(\theta, \sinh v)$$ $$\implies$$ $$f(\cos\theta\cosh v, \sin \theta\cosh v, v) = (\sinh v \cos \theta, \sinh v\sin \theta, \theta)$$ So, checking the statements needed, first of all, that $f$ is differentiable. Now, how does one show that this $f$ is injective and surjective ? Also, what about the local isometry ? I know that we can check if it is a local isometry or not, since the fundamental quantities of the fundamental form must oblige the following relations : $$E_p = E_{f(p)}, \; F_p = F_{f(p)}, \; G_p = G_{f(p)}$$ I am kind of confused on the calculations of the fundamental quantities though. In a solved (but poorly elaborated) example I've seen, one must first calculate the inverse of $f$ and then correlate the argument of $f$ with what it's mapped to. I would really appreciate any thorough elaboration which can help me how to handle showing the injectivity, surjectivity but most importantly on how to find the fundamental quantities stated.","['surfaces', 'multivariable-calculus', 'conformal-geometry', 'isometry', 'differential-geometry']"
3263271,Find maximum and minimum of $\sin x + \sin y$,"I am working on my scholarship exam practice but I am stuck on finding the minimum. Pre-university maths background is assumed. When $x + y = \frac{2\pi}{3}, x\geq0, y\geq0$ , the maximum of $\sin x+\sin y$ is ....., and the minimum of that is ..... Let me walk you through what I have got. $\sin x+\sin y = 2\sin (\frac{x+y}{2})\cos (\frac{x-y}{2})$ By substituting $x + y = \frac{2\pi}{3}$ into the sine function, we have $\sin x+\sin y = 2\sin (\frac{2\pi}{3\cdot2})\cos (\frac{x-y}{2})$ $\sin x+\sin y = \sqrt{3}\cos (\frac{x-y}{2})$ To find the maximum and minimum, we know that $-1 \leq\cos (\frac{x-y}{2})\leq1$ $-\sqrt{3} \leq\sqrt{3}\cos (\frac{x-y}{2})\leq\sqrt{3}$ Hence, the maximum is $\sqrt{3}$ which is correct and in accordance with the answer key. However, it seems that the minimum equals to $-\sqrt{3}$ is incorrect. The answer key provided is $\frac {\sqrt{3}}{2}$ . Could you please elucidate how I can get to this answer? My guess is something to do with the condition $x\geq0$ and $y\geq0$ given by the question.","['jensen-inequality', 'maxima-minima', 'optimization', 'trigonometry', 'karamata-inequality']"
3263328,"Calculate $\lim_{x\to 0} \frac{1}{x^2}\int^{1-\cos x}_{\sqrt[3]{ x^7}} \ln (2+\tan^2 t)\,dt$","Calculate $$\lim _{x\rightarrow 0}\frac{1}{x^2} \int\limits^{1-\cos x}_{\sqrt[3]{ x^7}} \ln (2+\tan^2 t)\,dt$$ My solution: Let: $$f(x)=\int^{1-\cos x} _{\sqrt[3]{ x^7}} \ln (2+\tan^2 t)\,dt$$ $$g(x)=x^2$$ For $x\rightarrow 0$ we have $f,g \rightarrow 0$ . So from L'Hôpital's rule: $$\lim_{x\rightarrow 0} \frac{f(x)}{g(x)}=\lim_{x\rightarrow 0} \frac{f'(x)}{g'(x)}=\lim_{x\rightarrow 0} \frac{\ln (2+ \tan ^{2} (1-\cos x)) \cdot \sin x -\ln (2+\tan^{2} (x^{\frac{7}{3}})) \cdot \frac{7}{3} \cdot x^{\frac{4}{3}})}{2x}=\ln 2$$ And then I have a question: how do I prove that I can use L'Hôpital's rule? I think that I should say that for $x\rightarrow 0$ for $f$ I have an integral from $0$ to $0$ so $f(x)=0$ . But I need a professional explanation so I am asking for a detailed justification of why I can use this rule.","['limits', 'real-analysis']"
3263361,An example computation with a form that is closed but not exact,"I'm working on the following question in munkres: Let $A = \mathbb{R}^2-0$ ; let $$\omega = (-y\,dx + x\, dy)/(x^2+y^2)$$ in $A$ . Show $\omega$ is closed but not exact in $A$ . This is a multi-part question, so I've posted an image of all the parts (I wrote the question so it could be searched). My questions correspond to the parts of problem: b. This clearly ""smells"" like polar coordinates. Indeed, if $\phi(x,y) = \tan^{-1}(y/x)$ the formulas are verified ""almost everywhere"" on B. However, the fact that the formula above doesn't work everywhere (namely $x=0$ ) gives me pause. The way he asks the question makes me think there's a way of showing uniqueness without producing an explicit formula for $\phi$ , but I cannot see the argument. Thoughts? c. My original thought was to consider $f_1(x,y,t) = (x^2+y^2)^{1/2}\cos t - x$ and $f_2(x,y,t) = (x^2+y^2)^{1/2}\cos t - y$ . Then use implicit fxn theorem to conclude there exists $g(x,y) = t$ -- this gets me regularity of $g$ too. But there are some periodic problems. For $f_1$ : $\frac{\partial f_1}{\partial t} = 0$ when $t = k\pi$ so this $g(x,y)$ isn't defined everywhere. How would one proceed showing this then? How is the hint used? d. Do b/c provide an explicit formula then? How is the hint used? e. So in d, we showed $\omega$ is exact. The given formula shows $\omega$ is a one form. Then by this part, we conclude $\phi$ is constant on $B$ ? f. I don't understand what the hint is suggesting I do. Generically:
I think the point of the problem is to show that the domain of the form matters -- is this correct?","['manifolds', 'differential-topology', 'differential-geometry']"
3263363,"Compute $\lim \limits_{n\to \infty} \frac{1}{n}\sum_{i,j=1}^n\frac{1}{\sqrt{i^2+j^2}}$","Compute $\lim \limits_{n\to \infty} \frac{1}{n}\sum_{i,j=1}^n\frac{1}{\sqrt{i^2+j^2}}$ . I am not looking for a solution using double integrals. I tried to turn this into a Riemann sum, but I couldn't make any progress. I thought about using the squeeze theorem, but I can't find any useful inequalities, I just tried to use AM-GM on the denominator, but it didn't help. Edit: This is definitely solveable without double integrals, it comes from a high school book and here multivariate calculus isn't covered.","['integration', 'limits']"
3263393,What is the large-n limit of a distribution of the following sample statistic:,"What is the large-n limit of a distribution of the following sample statistic: $$\displaystyle\frac{\sum^{n}X_{i}}{\,\sqrt{\,\sum^{n}X_{i}^{2}\,}\,}$$ when sampling the Cauchy(0,1) distribution? Monte Carlo simulation indicates that convergence to this limit is quite fast, and that the resulting (symmetric) PDF has very sharp cusps at -1 and +1, but of course does not yield an analytic expression for this PDF - would anyone be able to find it? The following graph indicates how the positive half of the PDF looks like:","['probability-limit-theorems', 'statistics', 'probability-distributions', 'probability']"
3263506,derivation of order 3 method for differential equations,"I am stuck with a big problem. Trying to understand the proof that the numerical method of solving differential equation $x_{i+1} = x_i + \tau_iF(t_i+\frac{\tau_i}{2}, x_{i+\frac{1}{2}})$ $x_{i+\frac{1}{2}} = x_i + \frac{\tau}{2}F(t_i,x_i)$ which seems to be the Cauchy-Euler's method. I am stuck with the Taylor approximation of $x(t+\tau) = x(t)+\tau x'(t) + \frac{1}{2} x''(t) + O(\tau^3)$ . Here it is OK for me. I also understand, why $x'(t)=F(t,x(t))$ . But why $x''(t) = \frac{d}{dt}F(t,x(t)) = \partial_tF(t,x(t)) + D_xF(t,x(t))F(t,x(t))$ ??? I am a little frustrated about this.
Normally I am more into computer science and some mathematical concepts can be missing, so sorry for possible trivial or illposed question, thanks for patience :)","['numerical-methods', 'ordinary-differential-equations']"
3263513,Solve differential equation $u_t = i u_{xx} - x^2 u$,"Consider $u_t = i u_{xx} - x^2 u$ with $u_{t = 0} = 1$ . We want to find a solution. My attempt : let's say $u = X(x)T(t)$ , hence we have $\frac{T'(t)}{T(t)} = i \frac{X""(x)}{X(x)} - x^2$ . We may say that $\frac{T'(t)}{T(t)} = \lambda$ and $i \frac{X""(x)}{X(x)} - x^2 = \lambda$ , so $ \frac{X""(x)}{X(x)} =  -i(x^2 + \lambda)$ . But the second equation is give some problem. Maybe there is a better way to solve it? UPD : I actually think that this idea is bad, because if $u = X(x)T(t)$ , when $u(x,0) = X(x) = 1$","['ordinary-differential-equations', 'proof-verification', 'partial-differential-equations', 'partial-derivative', 'derivatives']"
3263530,"How to find the growth rates of $n$ bacteria, knowing the sizes of bacteria from $m$ observations?","Each bacterium grows at a some constant rate, i.e. every minute the size of the bacteria increases by some constant value. Different bacteria can grow at different rate (they can also grow at same rate). Scientists observe $n$ bacteria under the microscope. Bacteria differ only in size and growth rate (in all other they are indistinguishable). Every minute, scientists identify the sizes of all $n$ bacteria and write down $n$ numbers - the sizes of bacteria (Scientists do not know which particular bacterium is of this or that size, because the bacteria move all the time). Prove that there is a number $m$ such that after $m$ minutes of observations, scientists will be able to unequivocally find a set of the growth rates of $n$ bacteria (The number $m$ should not depend on the sizes of the bacteria and their growth rates. The number $m$ may depend on the number $n$ .). My work . Scientists have numbers of $n$ arithmetic progressions. They need to find a set of common difference of arithmetic progressions. I proved that: a) if $n=1$ then $m=2$ ; b) if $n=2$ then $m=3$ ; c) if $n \ge 3$ then $m \ne 3$ (I do not know how to prove of the problem in the case when $n \ge 3$ ).","['contest-math', 'combinatorics', 'sequences-and-series']"
3263582,"Can long numbers be ""3-palindromic""?","Question Let $n$ be a number with $d\ge9$ digits when written in number base $b\ge2$ . Can $n$ be $3$ -palindromic? That is, does there exist $b$ , such that $n$ is simultaneously a palindrome in number bases $b,b+1,b+2$ ? Below I will present solutions for $d=3,5,7$ (Each case has infinitely many solutions). I'm not sure whether the smallest solution for $d=9$ is very large, or does not exist for some unexpected reason. I have confirmed my families of solutions for $d=3,5$ with an OEIS entry (link below). I have later, discovered seven more solution families, now for $d=7$ , but I can't find a single solution example for $d\ge9$ (details below), still (For $d=9$ , smallest example is $\gt10^{17}$ , if it exists). If all $3$ -palindromes are found/characterized, then it would be easy to see whether any of them can exist as a part of a $4$ -palindrome , whose existence is a open problem. $3$ -palindromic A number $n$ is palindromic (a palindrome) in number base $b\gt1$ if it is the same when its digits are reversed in that number base. For example: $121$ is a a palindrome in number base $10$ since $121=\color{}1\cdot10^2+2\cdot10^1+1\cdot10^0=121_{10}$ $5$ is a palindrome in number base $2$ (binary) since $5=\color{}1\cdot2^2+0\cdot2^1+1\cdot2^0=101_2$ I say that a number $n$ is $3$ -palindromic if it is simultaneously palindromic in three consecutive number bases $b,b+1,b+2$ , and has at least two digits in all of those number bases (Since one digit numbers are trivially palindromic). For example: $178$ is $3$ -palindromic since $178=454_6 = 343_7 = 262_8$ is palindromic in bases $6,7,8$ . $3360633$ is $3$ -palindromic since $6281826_9=3360633_{10}=1995991_{11}$ . There are infinitely many ""short enough"" $3$ -palindromes Let $d$ be the number of digits a number $n$ has when written in base $b$ . If $d$ is small enough (numbers are ""short enough""), and odd, we can find many examples: There are no $3$ -palindromes among $d$ digit numbers when $d$ is even. This is because when a number is a palindrome in base $b$ , and also has an even number of digits in that base, then it is divisible by $b+1$ and thus ends with $0$ in base $b+1$ . Thus, lets assume $d$ is odd, and also $d\gt1$ since one digit numbers are trivially palindromic. There are infinitely many numbers that are $3$ -palindromic and have $d=3,5,7$ digits: $178, 300, 373, 676, 1111, 1702, \dots$ are $d=3$ digit $3$ -palindromes. $154593982, 234531337, 344570692,\dots$ are $d=5$ digit $3$ -palindromes. $3360633, 19987816, 43443858,\dots$ are $d=7$ digit $3$ -palindromes. Characterization of all ""short enough"" $3$ -palindromes $(d\lt 9)$ Formulas for above sequences are shown in comments of A279093 , and here in more detail: All numbers $n$ palindromic in number bases $b,b+1,b+2$ with $d=3$ digits are given by: $F_3=\{n\in\mathbb N : n=\frac12(b^3 + 3b^2+5b+2),b=6+2k,k\in\mathbb N_0\}\cup\{300\}$ It can be proven $^{[1]}$ that $n$ is a $d=3$ digit $3$ -palindrome if and only if $n\in F_3$ . All numbers $n$ palindromic in number bases $b,b+1,b+2$ with $d=5$ digits are in: $F_5=\{n\in\mathbb N : n=\frac14(3 b^5 + 15 b^4 + 35 b^3 + 45 b^2 + 37 b + 13),b=45+4k,k\in\mathbb N_0\}$ I strongly conjecture that $n$ is a $d=5$ digit $3$ -palindrome if and only if $n\in F_5$ . I conjecture that all $3$ -palindormes with $d=7$ digits are given by: $F_7=F^{(0)}_7\bigcup F^{(1)}_7\bigcup F^{(2)}_7\bigcup \dots \bigcup F^{(m)}_7\bigcup \dots$ Where sets $F^{(m)}_7,m\in\mathbb N$ are mutually disjoint and given by: $\{n\in\mathbb N : n=n_{m}(b)\}$ , where $n_m(b)$ is a polynomial of degree $7$ , that goes over $b=c+tk,c,t\in\mathbb N$ , and where set $F^{(0)}_7$ is finite and already fully found (exact elements for $m=0$ can be found at the linked question or at the linked OEIS sequence, among ""known terms that do not belong to any families""). I have found $F^{(m)}_7$ for $m=1,2,3,4,5,6,7$ , and I think there could be more of these. The latest one has the smallest element of size $\approx 10^{17}$ , and I haven't searched beyond $10^{18}$ . $F^{(m)}_7=\{n\in\mathbb N : n=n_{m}(b), b=c+tk, k\in\mathbb N_0\}$ then $[m, n_m(b), (c,t)]$ are given by: (Where + sign should stand between the coefficients - but table is too wide then.) $$
\begin{matrix}
1, & \frac12 ( 6 & 25 b & 55 b^2 & 73 b^3 & 55 b^4 & 25 b^5 & 7 b^6 & b^7 ), & (74,2)\\
2, & \frac{1}{6} (4 & 25 b & 55 b^2 & 73 b^3 & 55 b^4 & 25 b^5 & 7 b^6 & b^7), & (56, 6) \\
3, & \frac16(28 & 94 b & 175 b^2 & 217 b^3 & 175 b^4 & 91 b^5 & 28 b^6 & 4 b^7), & (173,6) \\
4, & \frac{1}{6} (32 & 125 b & 275 b^2 & 365 b^3 & 275 b^4 & 125 b^5 & 35 b^6 & 5 b^7), & (278, 6) \\
5, & \frac{1}{12} (10 & 68 b & 193 b^2 & 269 b^3 & 187 b^4 & 71 b^5 & 16 b^6 & 2 b^7), &(37,12) \\
6, & \frac{1}{12} (66 & 256 b & 543 b^2 & 703 b^3 & 537 b^4 & 253 b^5 & 72 b^6 & 10 b^7), &(117,12) \\
7, & \frac{1}{12} (10 & 80 b & 283 b^2 & 419 b^3 & 277 b^4 & 89 b^5 & 16 b^6 & 2 b^7), &(289,12)
\end{matrix}
$$ Notice that $c\equiv 2,5,2\pmod 6$ for $t=6$ and that $c\equiv 1,9,1\pmod {12}$ for $t=12$ . Also notice the unexpected coincidental similarity between $m=1,2$ . If you want to sort them by smallest element $\min\{F^{(m)}_7\}$ , ascending, they would be in order: $m=5,2,1,6,3,7,4$ , with those minimal elements being: $$\begin{matrix}
m & \min\{F^{(m)}_7\} & (b,b+1,b+2) \\
5 & 19683596522 & (37,38,39) \\
2 & 326217315210 & (56,57,58) \\
1 & 6678940007962 & (74,75,76) \\ 
6 & 265965216105640 & (117,118,119) \\
3 & 3219426999580862 & (173,174,185) \\
7 & 28854914566144178 & (289,290,291) \\ 
4 & 109665618707825827 & (278,279,280)
\end{matrix}$$ The next set, $F^{(8)}_7$ has smallest element $\gt 10^{18}$ . I'm not sure how to find the next set, without the brute force search. There are probably more sets with both $t=6$ and $t=12$ , and I'm not sure about $t=2$ . Q: Can we find a general characterization for sets $F^{(m)}_7$ (how many more are there)? Update: Number bases $\le412$ and from $600$ to $612$ do not have a new solution (family). This indicates a new family of solutions, if it exists, would appear in bases $\gt 612$ . Given first $7$ families appear in first $300$ bases, and in next $300$ bases no new families appear, it could be that the $8$ th family does not exits. Here you can see the seven known familis in more detail. (Exact digits in each base). ""Long numbers"" as $3$ -palindromes Let $d\ge9$ be the number of digits of number $n$ when written in number base $b$ , and let $n$ satisfy being a $3$ -palindrome: Being palindromic in bases $b,b+1,b+2$ . I have no examples in this case. They are either very large, or do not exist for some unexpected reason. I have searched for the smallest example for $F_9$ , and it has to be $\gt 10^{17}$ , so far. Haven't searched significantly in cases $F_d,d\ge 11$ . Q: Can we provide arguments why they would (not) exist? I'm not sure how can one attempt to search for these solutions other than filtering out generated palindromes - there should be a better way, since the solutions for $d=3,5,7$ are very nicely characterized by $F_3,F_5,F_7$ , and $d\ge9$ should follow similarly? Q: How efficiently can we search/solve for elements in $F_d,d\ge9$ ? $[1]:$ Proof for $F_3$ , the $d=3$ digit $3$ -palindromes I believe I was able to show that $F_3$ contains all solutions for $d=3$ . But I haven't been able to fully analyze $d=5,7,9$ in a similar way. The idea is in short simple and natural: All palindromes with three digits are given with $Ab^2+Bb+A$ where $A,B<b$ . We can rewrite that as: $A(b+1)^2+(B-2A)(b+1)+(2A-B)$ , Now we can search for $2$ -palindromes first, numbers palindromic in bases $b,b+1$ : We need now to satisfy (looking at digits of the rewritten expression): $$1\le A-\alpha_1\le b$$ $$0\le B-2A +\alpha_1 (b+1) -\alpha_2 \le b$$ $$1\le 2A-B +\alpha_2 (b+1) \le b$$ To have a valid number, and to have a valid palindrome in base $b+1$ : $$A-\alpha_1=2A-B+\alpha_2 (b+1)$$ Where $\alpha_1,\alpha_2\in\mathbb Z$ are freely used to ""borrow"" from and to neighbouring digits, to satisfy the first three conditions depending on $b,A,B$ . We can parametrize then all the $3$ -digit numbers in base $b+1$ with some $t\in\mathbb N$ : (After preforming the trivial borrowing, we are observing bases $b+t,b+t+1$ ) (Omitted the new $\alpha_1,\alpha_2$ gotten after trivial borrowing, from expressions, for readability) And after this, we can show that the numbers on and below yellow line can't give base $b+1$ palindromes, and after further analysis and playing with conditions, one can show that $3$ -palindromes must be numbers of forms located on green and blue lines. Now we do the same thing, but for $b+1,b+2$ and considering only the blue and green forms, and after final analysis, one can finally prove and show that $F_3$ contains all $d=3$ digit $3$ -palindromes, and that $d=3$ digit $4$ -palindromes do not exist. More specifically, the blue forms yield solution $300$ (see $F_3$ ), and the green forms yield the solutions generated by $b_3(b)$ that makes up the rest of $F_3$ . Q: Can we apply similar analysis to $d=5,7,9,\dots$ and solve/prove $F_d$ ? A: I asked this question some time ago here . - not answered . Here you can also see this proof in more detail. My poof for $d=3$ relied on guessing the right cases to split the parameterized forms into, and then solving each of those cases, splitting into subcases if necessary, until the proof contained all parameterized forms. I wasn't able to guess $d=5$ cases that would allow the parameterized forms to be analyzed and $F_5$ found. Notice that if we were to use a similar image as above for form visualization, to help us guess the cases to analyze, we would now have for $d=5$ , a 3-dimensional matrix of parameterized forms with $t$ , and $\alpha_1,\alpha_2,\alpha_3,\alpha_4$ parameters. I'm not sure how to transform this into a rigorous method to allow me to attack $d=5,7,9,\dots$ Clarification: If you can provide insight into $d\le 9$ , then refer to the linked question . If you can provide insight into $d\ge 9$ and $d=7$ regarding $F_7^{(m)}$ for $m\gt7$ , refer to this question.","['number-theory', 'palindrome', 'modular-arithmetic', 'diophantine-equations']"
3263629,Permutations preserving a filtration property,"Suppose $\mathcal{A}$ is a non-empty family of sets of natural numbers size $n$ with the property that if $\{k_1<k_2< \dots <k_n\}\in \mathcal{A}$ and $j_i\leq k_i$ for all $1\leq i\leq n$ , then $\{j_1,j_2,\dots, j_n\}\in \mathcal{A}$ as well. If $A=\{k_1, k_2, \dots,k_n\}\in\mathcal{A}$ , and $f$ is a permutation of $\mathbb{N}$ ,  denote by $f(A)=\{f(k_1), f(k_2), \cdots, f(k_n)\}$ , and by $f(\mathcal{A})=\{f(A): A\in\mathcal{A}\}$ . If $f(\mathcal{A})$ has the same filtration property as above, does it follow that $\mathcal{A}=f(\mathcal{A})$ ? This is trivial when $n=1$ , but for me not so clear otherwise.","['combinatorics', 'discrete-mathematics']"
3263659,Eigenfunctions of Laplace-Beltrami operator,"Let $M$ be a compact Riemannian manifold and $$Lf:=-\operatorname{div} \nabla(f)$$ be the Laplace-Beltrami operator. Let $f$ be a smooth function on $M$ . Consider the optimization problem of minimizing $$\int_ML(f)f$$ under the constraint $\int_M |f|^2=1$ . I wonder how to prove that if $f$ minimize the integral $\int_ML(f)f$ , then it must be an eigenfunction of $L$ , i.e. $L(f)=\lambda f$ for some $\lambda$ . I know it can be shown that $\int_M\|\nabla f\|^2= \int_ML(f)f$ but this may not be helpful.","['riemannian-geometry', 'differential-geometry']"
3263674,"Definition of closed, compact manifold and topological spaces","This is a very basic question but I seem not to get a ""simple"" definition anywhere that is at the same time rigorous and clear. I probably understand basic definitions of topology, topological spaces, open and closed sets, manifolds etc. However, I fail to see what compact or closed topological spaces and manifolds are. I realise that there is a difference between these concepts as applied to topological spaces and manifolds. Also, how do we define the boundary of a topological space and a manifold? I frequently have to encounter these concepts while studying gravity and a clear intuitive picture would help a lot.","['definition', 'differential-geometry']"
3263689,Is this spectrum-shifting operator well-defined?,"Consider a separable Hilbert space (over $\mathbb{C}$ ), and let $U(t)$ be a one-parameter group of unitary operators so that $$
	U(t)=e^{iHt}
\tag{1}
$$ for some densely-defined operator $H$ as in Stone's theorem. Let $A$ be any bounded (everywhere-defined) operator on the Hilbert space, and define $$
	A(t) = U(t)A U(-t).
\tag{2}
$$ For real numbers $\omega$ and $\epsilon$ with $\epsilon>0$ , I want to define $$
	B := 
		\int_{-\infty}^\infty dt\ 
			 \exp(-i\omega t-\epsilon t^2) A(t).
\tag{3}
$$ Question: Is $B$ a well-defined operator on the Hilbert space? If not, is it at least densely defined? If the answer is ""it depends,"" then is there a simple necessary-and-sufficient condition on $A$ and $H$ such that $B$ is at least densely defined for all $\omega$ and all $\epsilon>0$ ? For whatever it's worth, here's the reason for the words ""spectrum-shifting"" in the title of the question: At least naively, equation (3) implies $HB=B(H+\omega)+O(\epsilon)$ . In physics jargon, if $H$ is the energy operator, then applying $B$ to an ""eigenstate"" of $H$ shifts its energy by $\omega$ , up to an arbitrarily small term of order $\epsilon$ . That's the motive, but I don't know when (3) is actually well-defined.","['hilbert-spaces', 'functional-analysis', 'operator-algebras']"
3263742,Proving a linear transformation is unique,"In Axler's Linear Algebra Done Right, there is this theorem. (3.5) Suppose $v_1. . .  v_n $ is a basis of $V$ and $w_ , . . . w_n \in W$ . Then there exists
  a unique linear map $T: V \rightarrow  W$ such that $$T (v_j) = w_j$$ for each $j\in   1, . . . , n $ . I understood the first part of the proof proving existence of such a transformation, but didn't understand the uniqueness part of the proof. To prove uniqueness, now suppose that $T \in \cal L $$(L,V)$ ;and that $T( v_j)=  w_j$ for each $j\in   1, . . . , n $ . Let $c_1,. . . ,c_n \in F$ . The homogeneity of $T$ implies that $T(c_j v_j) =  c_jw_j$ for each $j\in   1, . . . , n $ . The additivity of T now implies that $T(c_1v_1 + . . . + c_nv_n) = c_1w_1 + . . . + c_nw_n$ . Thus $T$ is uniquely determined on span( $v_1, . . . ,v_n$ ) by the equation above.
  Because $v_1,  . . . v_n$ is a basis of $V$ , this implies that $T$ is uniquely determined
  on $V$ . How does ""equation above"" show that $T$ is uniquely determined on span( $v_1, . . . ,v_n$ )? Is it because there is one way to get each of the basis vectors using the equation? How do we know  there isn't another transformation that will work?","['proof-explanation', 'linear-algebra', 'linear-transformations']"
3263751,"For which smooth maps $f:X\to Y$ is the restriction $C^\infty_{Y,fx}\to C^\infty_{X,x}$ surjective?","In this answer , the notion of $R$ -immersion of ringed spaces was suggested. It means a topological embedding $f:X\to Y$ such that germ restriction on the structure sheaves is surjective. $$\mathcal O_{Y,fx}\twoheadrightarrow \mathcal O_{X,x}$$ I am trying to understand what this condition might mean for smooth manifolds. In this case the structure sheaves are the sheaves of smooth real functions. Let $f:X\to Y$ a smooth map. Precomposing with it induces a restriction map on germs $$C^\infty_{Y,fx}\to C^\infty_{X,x}.$$ Question 1. Surjectivity means a smooth germ on $X$ extends along $f$ to a smooth germ on $Y$ ? 
When does this hold? I don't see why it should hold for smooth immersions, for instance. (Or for smooth embeddings.) Question 2. Suppose that instead of the sheaves $C^\infty$ we consider the tangent sheaves, i.e the sheaves of sections of the tangent bundles. When do we have surjectivity of germ restriction $$T_{Y,fx}\to T_{X,x}?$$ (This seems closer to smooth immersions.)","['smooth-manifolds', 'differential-geometry']"
3263767,Universal cover of homogeneous space $G/H$.,"Let $G$ be a compact connected Lie group with finite fundamental group and $H \leq G$ be a closed subgroup. Consider the homogeneous space $G/H$ . Let $H'=\pi^{-1}(H)$ and $\bar{H}=(H')_0$ be the identity component of the closed subgroup $H'$ . I am trying to prove that $\widetilde{G}/\bar{H}$ is the universal cover of $G/H$ where $\pi:\widetilde{G} \rightarrow G$ is the universal cover of $G$ . I have already proved that $G/H$ is simply connected. Therefore I need only show that $\widetilde{G}/H$ is a covering space for $G/H$ . Let $K=H'/\bar{H}$ be the group of components of $H'$ . I have shown that $K$ is finite and therefore it suffices to construct a free action of $K$ on $\widetilde{G}/\bar{H}$ such that the corresponding orbit space is $G/H$ . This is where I am stuck. I am having trouble constructing any action of $K$ on $G/H$ , let alone one that is free and gives the proper orbit space.","['algebraic-topology', 'riemannian-geometry', 'homogeneous-spaces', 'lie-groups', 'differential-geometry']"
3263804,why is the population standard deviation approximated as the sample standard deviation [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question does not appear to be about math within the scope defined in the help center . Closed 5 years ago . Improve this question This question addresses calculating a p value from the mean and standard deviation statistics of a sample.  I understand that the -general- philosophy is to divide the sample standard deviation by the root of the population size to get the standard deviation of the sampling distribution, using the assumption that the standard deviation of the sample is roughly equal to the standard deviation of the hypothetical larger population.  Then one calculates a z-score from the number of standard deviations of the sampling distribution to calculate what percent of the time the observed result would have occurred by random chance.  I understand that the particular formula for the sampling distribution standard deviation depends on the particular statistic, say difference of means is a different formula. The texts and videos that I've looked at use language like ""the sample standard deviation is the best number we have available to estimate the population standard deviation.""  I just don't find that explanation satisfying. This approach hinges on the validity of estimating the standard deviation of the entire population as being approximately equal to the standard deviation of the representative sample.  However, we don't make the same assumption that the mean of the population is the approximately equal to the mean of the sample.  At some level, it feels like the final result of significance or non-significance is only self-validating or checking for self-consistency of an assumption that is baked into the methodology. So to restate, why is the sample standard deviation a good approximation of the populatoin standard deviation, but the sample mean is not a good approximation of the population mean?  I found online an equation for standard deviation of the sampling distribution of standard deviations: standard error of standard deviation = .71 sample standard deviation / root N. Does the relative narrowness of the standard error compared to standard deviation play a role in justifying the approximation? Thank you","['statistics', 'probability']"
3263854,"Conditional expectation with Radon Nikodym derivative is in $L^1(\Omega, \mathbb F, \mathbb Q)$","Let $\mathbb {P, Q}$ be equivalent probability measures on $(\Omega, \mathbb F)$ , $X \in L^1(\Omega, \mathbb F, \mathbb Q)$ , ${d\mathbb Q}\over {d \mathbb P}$ be the Radon Nikodym derivative and $ \mathbb G \subset \mathbb F$ a subsigma-algebra. I know that ${{d\mathbb Q}\over {d \mathbb P}} \in L^1(\Omega, \mathbb F, \mathbb P)$ by de Radon Nikodym theorem, hence $\mathbb E_{\mathbb P}[{{d\mathbb Q}\over {d \mathbb P}}| \mathbb G]\in L^1(\Omega, \mathbb F, \mathbb P)$ and is positive with probability $1$ I was able to prove that given the hypothesis, the product $X{{d\mathbb Q}\over {d \mathbb P}}\in L^1(\Omega, \mathbb F, \mathbb P)$ and hence $\mathbb E_{\mathbb P}[X{{d\mathbb Q}\over {d \mathbb P}}| \mathbb G]\in L^1(\Omega, \mathbb F, \mathbb P)$ My question: given that $X \in L^1(\Omega, \mathbb F, \mathbb Q)$ how can I show that $${1 \over \mathbb E_{\mathbb P}[{{d\mathbb Q}\over {d \mathbb P}}| \mathbb G]}\mathbb E_{\mathbb P}[X{{d\mathbb Q}\over {d \mathbb P}}| \mathbb G] \in L^1(\Omega, \mathbb F, \mathbb Q)$$ and $$ \mathbb E_{\mathbb Q}[X| \mathbb G]={1 \over \mathbb E_{\mathbb P}[{{d\mathbb Q}\over {d \mathbb P}}| \mathbb G]}\mathbb E_{\mathbb P}[X{{d\mathbb Q}\over {d \mathbb P}}| \mathbb G]$$ My issue is regarding the first question since the last one is just working out with the properties of conditional expectation. I would really appreciate any hints or suggestions.","['measure-theory', 'conditional-expectation', 'probability-theory', 'probability', 'radon-nikodym']"
3263899,Unable to solve $ \int \frac{x + \sqrt{2}}{x^2 + \sqrt{2} x + 1} dx $? [duplicate],"This question already has answers here : How to integrate $\int \frac{ev+f}{av^2 + bv +c} dv$? [duplicate] (3 answers) Integration of elementary rational fractions (1 answer) Closed 5 years ago . This comes from a bigger problem :- $$ \text{Evaluate } \int\frac{dx}{1+x^4} $$ After making $ \int \frac {dx}{1+x^4} = \frac{dx}{(1+x^2)^2 - (\sqrt{2}x)^2} $ and then applying partial fraction method, I got :- $$ \int \frac{dx}{1 + x^4} =\frac{1}{2 \sqrt{2}} \int \frac{x + \sqrt{2}}{x^2 + \sqrt{2}x + 1} dx - \frac{1}{2 \sqrt{2}} \int \frac{x - \sqrt{2}}{x^2 - \sqrt{2}x + 1} dx $$ Now, to the first integral, I tried making a u-substitution:- $$ \text{Let }x^2 + \sqrt{2}x + 1 = u \\
\frac{du}{dx} = 2x + \sqrt{2} \\
\implies du = (2x + \sqrt{2}) dx \\ $$ As you can see, it is not the same as the numerator, which is $$ (x + \sqrt{2}) dx $$ Any hints on how to proceed ?","['integration', 'indefinite-integrals', 'analysis']"
3263956,Proof about monotonicity of functions,"Let $f:[a,b]\rightarrow\mathbf{R}$ Suppose $f'(x)>0$ for all x $\in (a,b)$ $\ \ \ \ \ \ \ $ and $f$ is differentiable on $(a,b)$ $\ \ \ \ \ \ \ $ and $f$ is continuous on $[a,b]$ Show $f$ is strictly increasing on $[a,b]$ . What i tried so far: Let $x_1,x_2 \in (a,b)$ , Assume $x_1<x_2$ By MVT exist $c$ in $(a,b)$ s.t. $f'(c) = \dfrac{f(x_2) - f(x_1)}{x_2 - x_1}$ With $f'(c)>0$ implies $f(x_1)<f(x_2)$ That $f$ is strictly in creasing on $(a,b)$ Also WTS for all x in (a,b), $f(a)<x<f(b)$ That is $f(a)<x$ and $x<f(b)$ Assume its negation is true Have $f(a)\geq x$ or $x \geq f(b)$ Now need to find some contradiction ... Any help would be appreciated. Please tell me if there is an easier proof.","['functions', 'derivatives']"
3263975,An equivalence relation on the isomorphism classes of finite groups,"Let all groups be finite. I am interested in the equivalence relation on finite groups given by $G \sim H$ , if and only if, there exist $W_1,W_2,Z$ with $W_1 \cong W_2 \unlhd Z$ so that $G \oplus Z/W_1 \cong H\oplus Z/W_2$ . The most obvious question to ask is when are two groups equivalent. A necessary condition is that they have the same order. In the case, if the two groups are abelian this is sufficient. This can be worked out from the classification of finite abelian groups and the fact $\mathbb{Z}_{p^n} \sim \mathbb{Z}_{p^n-1} \oplus \mathbb{Z}_p$ . This means abelian groups under this relation are isomorphic to the positive integers under multiplication. Can anyone provide two groups of the same order that are not equivalent? I was not able to do it for the case $S_3,\mathbb{Z}_6$ . The reason I am interested in the question is because I recently saw the definition of topological K-theory. I was interested if there was some interesting way to mimic it for the case of groups. For various reasons, I decided that before forming the Grothendieck group, I wanted the elements to be of the form $G-H$ (with addition component wise direct sum) where $H \leq G$ . It should also have the property that $G+H-H=G$ . The idea behind this is that for any subgroup $H$ we are formally introducing another subgroup to act as a complementary summand to $H$ . However, if the subgroup already is a direct summand these should coincide. But if we are treating subgroups like direct summands, it only makes sense to also require that if $H \unlhd G$ , then $G-H \sim G/H$ , from which you get things like $\mathbb{Z}_{p^n} \sim \mathbb{Z}_{p^n-1} \oplus \mathbb{Z}_p$ . It was a hassle to find the equivalence relation generated by this, but it ended up being: $G_1 - H_1 \sim G_2 - H_2$ , if and only if, there exists $H_1,H_2 \unlhd F$ and $W\cong\bar{W} \unlhd Z$ so that $F/H_1 \oplus G_1 \oplus Z/W \cong F/H_2 \oplus G_2 \oplus Z/\bar{W}$ . So the monoid I am interested in is the set of formal differences $G-H$ with $H \leq G$ , quotiented out by this equivalence relation. The question in the first paragraphs is what you get when you ask when $G \sim H$ in this monoid. It's worth noting that nontrivial inverses don't exist, and the operation remains cancellative even after quotienting. I think this means the Grothendieck group will contain pretty much the same information as this monoid. So to reiterate, $\textbf{Can anyone provide two groups of the same order that are not equivalent?}$ . I think a good pair to check might be a perfect group and an abelain group. If this question ends up being too easy, feel free to talk about the structure of the monoid.","['group-theory', 'abstract-algebra']"
3264034,"Existence of open sets $U, V$ of matrices such that for every $A \in U$ there exists $B \in V$ such that $B^4 = A$","Prove there exist non-empty open sets U and V of $n \times n$ matrices over $\mathbb{R}$ such that for every matrix $A \in U$ there exists exactly one matrix $B \in V$ such that $B^4 = A$ . I've tried to approach this problem in several ways, using characteristic polynomials, Jordan Canonical Form and facts from calculus but failed to get anything useful.","['matrices', 'linear-algebra', 'real-analysis']"
3264059,Why is the Grassmannian functor representable by a scheme?,"I am having some trouble following a proof that the Grassmannian functor is representable by a scheme. I am following the proof in EGA 9.7.4. It is only a small step that I am stuck on. For reference, let $\mathcal{E}$ be a quasicoherent sheaf on a scheme $S$ and we define the functor $F: Sch/S \rightarrow \text{Set}$ by (just thinking about the n=1 case since that should clarify all I need): $$
F(T \stackrel{g}{\rightarrow}S) = \{  \text{invertible sheaves } \mathcal{L} : (g^{*}\mathcal{E} \rightarrow \mathcal{L} \rightarrow 0  )/\sim \}
$$ where the equivalence $\sim$ is just isomorphisms commuting with the quotient in the obvious way. It is easy enough to see that $F$ is a Zariski sheaf. So consider when $S = \text{Spec} A$ is affine. All I need to do is cover $F$ by representable open subfunctors, which is where I run into a problem. From what I understand, Grothendieck's argument is as follows: Let $\mathcal{E} = \tilde{M}$ be generated by sections $\{ m_{i} \}_{i \in I}$ . Then the sections $\{ g^{*}m_{i} \}_{i \in I}$ generated $g^{*} \mathcal{E}$ on $T$ and so correspond to a surjection, $$
\bigoplus_{i \in I} \mathcal{O}_{T}^{(i)} \longrightarrow g^{*} \mathcal{E} \longrightarrow 0.
$$ He then seems to appeal to the fact that for the $n=1$ case, such a surjection must factor through precisely one of the summands. This is where I get lost. It looks like some kind of compact object argument, but any argument I can see would rely on strong finiteness assumptions on the scheme $T$ , such as $T$ being at least quasicompact (and probably quasiseparated). Can anyone explain how the subfunctors are defined, and how they go on to cover $F$ ? For reference, I found this note which seems to suggest quasicompactness is necessary also.","['representable-functor', 'proof-explanation', 'algebraic-geometry', 'sheaf-theory', 'schemes']"
3264081,Calculate $\lim\limits_{x\rightarrow 0^+} \int\limits_0^1 \ln(1+\sin(tx))dt$,"Calculate $$\lim_{x\rightarrow 0^+}\int_0^1\ln(1+\sin(tx))dt$$ My try: $$\lim_{x\rightarrow 0^+} \int_0^1 \ln (1+ \sin (tx)) dt=\lim_{x\rightarrow 0^+} ([t \ln (1+\sin (tx))]^1_0 - \int_0^1 \frac{t \cos (tx) x}{1+ \sin (tx)} dt)$$ Then I want to use: $$u=1+\sin (tx), du=\cos (tx) x$$ But then I have: $$\lim_{x\rightarrow 0^+}([t \ln (1+\sin (tx))]^1_0 - \int_1^{1+\sin x} \frac{\arcsin(u-1)}{ux} du)$$ So I think my idea about $u$ is not helpfull and I need other idea. Can you help me?","['integration', 'limits', 'definite-integrals', 'real-analysis']"
3264137,Local Inversion theorem (first sentence of the proof),"In this local inversion theorem I want to prove that a map f between two Banach spaces E and F is a local diffeomorphism. In the proof it says : Without loss of generality we can consider the case where E= F. Sorry for this simple question, but why is that? How does this imply the general case where f goes from an open set U in E to F? In finite dimensions we could probably have an embedding of E in F or something similar...but I'm not sure how to justify this for general Banach spaces...","['multivariable-calculus', 'differential-topology', 'differential-geometry']"
3264177,Convergence in p-adics and reals,"I have been trying to solve three closely related problems about convergence of sequences in the p-adic numbers. I managed to solve two, but got stuck on the last one. Apart from trying to find a solution for this last one, I'd also like to doublecheck my answers for the first two, just to make sure I'm not misunderstanding the theory. Sidenote: I've been seeing different notations for the p-adic valuation, I am used to $\text{ord}_p(x)$ . Problem 1: Can you construct a sequence converging to $0$ in $\mathbb{Q}_2$ , but to $1$ in $\mathbb{R}$ ? The answer I came up with was $a_n = \frac{2^n}{2^n-1}$ , convergence in the reals is easy to verify, while in $\mathbb{Q}_2$ you can note that $\text{ord}_2(a_n) = \text{ord}_2(2^n) - \text{ord}_2(2^n - 1) = n \to \infty$ . Problem 2: Can you construct a sequence converging to $0$ in $\mathbb{Q}_2$ , but to $1$ in $\mathbb{Q}_3$ ? The answer I came up with was $a_n = \frac{2^n}{2^n-3^n}$ , where you can note that $a_n - 1 = \frac{3^n}{2^n-3^n}$ . Consequently $\text{ord}_2(a_n) = n \to \infty$ and $\text{ord}_3(a_n - 1) = n \to \infty$ . Problem 3: Can you construct a sequence converging to $0$ in $\mathbb{Q}_2$ , but to $1$ in both $\mathbb{Q}_3$ and $\mathbb{R}$ ? First I thought simply trying to take the product of my above two sequences, until I realized that my second sequence actually converges to zero over the reals. I'm not entirely convinced it is even possible to find such a sequence, but I wouldn't know where to start on proving that.","['p-adic-number-theory', 'sequences-and-series']"
3264205,How independent are the minors of a matrix?,"Let $M$ be a $p\times q$ matrix (say, $p\leq q$ ) with formal coefficients $m_{i,j}$ . It has $pq$ entries, and ${q\choose p}$ minors of maximal size $p\times p$ , which gives us a map $$\varphi_{p,q}: \Bbb Z^{pq}\to \Bbb Z^{q\choose p}$$ I'm interested in the surjectivity of this map. It is easy to see that $\varphi_{3,4}$ , for instance, is surjective, meaning that we can adjust the coefficients of a $3\times 4$ matrix to give each of the $3\times 3$ minors a prescribed value. In most cases, ${q\choose p}$ is much bigger than $pq$ , so it feels unlikely that $\varphi$ will be surjective. But what if we keep only a relatively small amount of minors? Question 1: For what values of $p,q,r\in\Bbb N$ is there a map $f:\Bbb Z^{q\choose p}\to \Bbb Z^r$ defined by keeping only some $r$ coordinates, such that $f\circ \varphi_{p,q}$ is surjective? Question 2 (less general but the one I'm really interested in) : Take $p=3, q=6$ and forget about the three minors corresponding to columns $(1, 4, 5), (2, 4, 6), (3, 5, 6)$ . Is the resulting map $\Bbb Z^{18}\to \Bbb Z^{17}$ surjective?","['determinant', 'linear-algebra']"
3264235,Vector field on an odd sphere. $X = \sum_{i=1}^n -y^i \frac{\partial}{\partial x^i} + x^i \frac{\partial}{\partial y^i}$ is smooth.,"This is problem 14.2 from Loring Tu's Introduction to Manifolds. Vector field on an odd sphere. Let $x^1,y^1,\dots,x^n,y^n$ be the standard coordinates on $R^{2n}$ . The unit sphere $S^{2n-1}$ in $R^{2n}$ is defined by the equation $\sum (x^i)^2 + (y^i)^2=1$ . Show that $$X = \sum_{i=1}^n -y^i \frac{\partial}{\partial x^i} + x^i \frac{\partial}{\partial y^i}$$ is a nowhere-vanishing smooth vector field on $S^{2n-1}$ . I have shown that it is nowhere-vanishing, but I do not know how to show that this is smooth. From Proposition 14.2 of the text, it is equivalent to showing that there is an atlas on the unit sphere such that on any chart $(U,\phi) = (U,z^1,\dots z^n)$ of the atlas, the coefficients $a^i$ of $X=\sum a^i \partial/\partial z^i$ relative to the frame $\partial/\partial z^i$ are all smooth. I know of two charts for the unit sphere : the projection charts onto each hemisphere and the stereographic projection. However, for each atlas has only $2n-1$ coordinates, so there are $2n-1$ basis vectors $\partial / \partial z^i$ , whereas the standard coordinates give us $2n$ bases. How can we make a transition between two coordinates of different number of basis here? This is a solution I found for this problem. However, I can't figure out how we can formally justify $$\frac{\partial}{\partial t^i} = \sum \frac{\partial z_k}{\partial t^i}\frac{\partial}{\partial z_k}.$$ Here we are expressing the standard tangent vectors on $R^{2n}$ , i.e. $\partial / \partial t^i$ in terms of the tangent vectors $\partial / \partial z_k$ on the unit sphere $S^{2n-1}$ given by the stereographic projection. However, these two coordinate maps belong to spaces of different dimensions. So we cannot use, say the following proposition from the text. As we can see from the proof, the transition relationship depends on the fact that the two frames are with respect to the same tangent space, hence one is a linear combination of the others. However, here they belong to different spaces, so how can we come up with such a linear combination?","['manifolds', 'vector-fields', 'smooth-manifolds', 'differential-geometry']"
3264274,"$\sqrt{2} x^2 - \sqrt{3} x +k=0$ with solutions $\sin\theta$ and $\cos\theta$, find k","If the equation $\sqrt{2} x^2 - \sqrt{3} x +k=0$ with $k$ a constant has two solutions $\sin\theta$ and $\cos\theta$ $(0\leq\theta\leq\frac{\pi}{2})$ , then $k=$ …… My approach is suggested below but I am not sure how to continue. Since $\sin\theta$ and $\cos\theta$ are two solutions of the equation, Then we have, $\sqrt{2} \sin^2\theta - \sqrt{3} \sin\theta +k=0$ .....Equation (1) $\sqrt{2} \cos^2\theta - \sqrt{3} \cos\theta +k=0$ .....Equation (2) Add (2) to (1), $\sqrt{2} (\sin^2\theta + \cos^2\theta) - \sqrt{3} (\sin\theta + \cos\theta) +2k=0$ $\sqrt{2} - \sqrt{3} (\sin\theta + \cos\theta) +2k=0$ The answer key provided is $\frac{\sqrt{2}}{4}$ . I think I am probably on the right track here but not sure how I should proceed with $\sin\theta$ and $\cos\theta$ next. Please help.","['algebra-precalculus', 'quadratics', 'roots', 'trigonometry']"
3264279,Does there exist a non-trivial group that is both perfect and complete?,"A group $G$ is called perfect iff $G’ = G$ . A group $G$ is called complete iff $Z(G) = \{e\}$ and $Aut(G) \cong G$ . Does there exist a non-trivial group $G$ , that is both perfect and complete at the same time? Motivation behind this question: Both «perfect groups» and «complete groups» are translated to Russian as «совершенные группы» despite those properties being completely different and not implying one another. It would however be interesting to know (despite this interest being purely recreational) whether or not these two properties defined by the same word are completely disjoint, or are there such groups, for which such an ambiguous translation does not cause problems.","['complete-groups', 'recreational-mathematics', 'derived-subgroup', 'abstract-algebra', 'group-theory']"
3264331,Is this series for Pi correct?,"The idea was to use an infinite series of triangles. The red then green then the... to get the area of this sector then the area of the circle is 16 times this. If it is a unit circle than area should equal Pi. Here is the series I got using Pythagorean’s theorem , is it correct? $$\begin{align}
A&=3r^{2} + 12\sum_{ n=0}^{\infty}2^{n-1}x_{n}\left(1-\sqrt{r^{2}-\frac{x{_{n}}^{2}}{4}}\right),\\ x_{0}&=r\sqrt{2-\sqrt{3}}
,\\x_{n+1}&=\sqrt{2r^{2}-2r\sqrt{r^{2}-\frac{x{_{n}}^{2}}{4}}}
\end{align}$$ So-for-a-unit-circle $$\begin{align}
\pi&=3 + 12\sum_{ n=0}^{\infty}2^{n-1}x_{n}\left(1-\sqrt{1-\frac{x{_{n}}^{2}}{4}}\right),\\ x_{0}&=\sqrt{2-\sqrt{3}}
,\\x_{n+1}&=\sqrt{2-2\sqrt{1-\frac{x{_{n}}^{2}}{4}}}
\end{align}$$","['solution-verification', 'geometry', 'sequences-and-series']"
3264480,Name for a function whose effect is canceled by another function?,"I've been saying function $f$ "" eclipses "" $g$ if $f(g(x)) = f(x)$ for all $x$ .  For example, if $f(x) = \lvert x \rvert$ and $g(x) = -x$ , then $f$ eclipses $g$ . Is there an established word for this property?","['functions', 'terminology']"
3264527,"""go / goes to"" $(x \to y)$ vs. ""maps to"" $(x \mapsto y)$","Is there a convention for determining when to use $\to$ vs when to use $\mapsto$ ? Or is there some flexibility between the two? I have only ever seen $\to$ used within the notation for limits (ie I have never seen anything like $\lim_{x {\color{red}\mapsto} a^+}\limits f(x)$ ) - which makes sense to me. However, I have seen both symbols used for reassignment of a variable -- eg if a question is posed in terms of variables that may shroud the (otherwise familiar) structure of an equation to new initiates: Ex 1: to help a student familiar with spherical coordinates recognize that $\vec{r} = \left< 5\sin u \cos t, 5 \sin u \sin t, 5\cos u \right>$ for $u \in [0,\pi]$ , $t \in [0, 2\pi]$ is the equation of a sphere in polar coordinates by re-writing the expression in terms of the more familiar spherical coordinates $\phi$ and $\theta$ , I've seen both ""let $u \to \phi$ and $t \to \theta$ "" as well as ""let $u \mapsto \phi$ and $t \mapsto \theta$ ."" Ex 2: when making a substitution (e.g. during integration) I've seen ""let $u = x^2$ ,"" as well as ""let $u \mapsto x^2$ ,"" as well as "" $x \mapsto x^2$ ."" I realize that there are hardly any universal conventions; so am equally interested in the reasoning for any specific one (i.e. if you really think they should never be interchanged, I'd love to know why ). Context / Motivation: Most of my (post-secondary) math education has been informal -- a haphazard dipping into many different textbooks; course notes from different universities; online course etc. to complement the basic education I received in applied math during my physics undergraduate degree -- and so I've encountered many different uses of notation. It hasn't been a stumbling block for my understanding (at least, not that I'm aware of), but it feels like high time for me to look into these details. Thanks in advance for your time and help.","['notation', 'convention', 'multivariable-calculus']"
3264603,Evaluate the definite integral $\int_0^{2\pi}\arctan\left((a\cos x + b\sin x)^2\right)dx$,"Writing: Integrate[ArcTan[(a Cos[x] + b Sin[x])^2], {x, 0, 2 Pi}, Assumptions -> a^2 + b^2 > 0] $$\int_0^{2\pi}\arctan\left((a\cos x + b\sin x)^2\right)dx,$$ where $a $ and $b $ are real numbers. I get: 2 Pi ArcTan[Sqrt[1/2 (-1 + Sqrt[1 + (a^2 + b^2)^2])]] $$2\pi\arctan\sqrt{\frac{\sqrt{1 + (a^2 + b^2)^2}-1}2} $$ How to derive this result on paper?","['integration', 'calculus', 'definite-integrals']"
3264618,"Prove that the set $A = \{k^\frac{1}{k}| k \neq 0, k \in \mathbb{Z}\}$ is countably infinite","In a practice test for my algorithms class I was asked to prove that the set $A = \{k^\frac{1}{k}| k \neq 0, k \in \mathbb{Z}\}$ is countably infinite. My professor provided me with the answer that we can create an image like the following $$ 1 \rightarrow 1^\frac{1}{1}, 2 \rightarrow (-1)^{-\frac{1}{1}}, 3 \rightarrow 2^\frac{1}{2}, 4 \rightarrow (-2)^{-\frac{1}{2}} ..., k \rightarrow ((-1)^{k+1}\lfloor\frac{k-1}{2} + 1\rfloor)^{(-1)^{k+1}\cdot\frac{1}{\lfloor\frac{k-1}{2} + 1\rfloor}}$$ which shows that for every $k$ there is an unique value of $((-1)^{k+1}\lfloor\frac{k-1}{2} + 1\rfloor)^{(-1)^{k+1}\cdot \frac{1}{\lfloor\frac{k-1}{2} + 1\rfloor}}$ , and thus the image is a bijection and the set is countable infinite. I am familiar with the concept of how there has to be a bijection with the natural numbers for a set to be countably infinite, but I have no idea how my professor got to the expression after ' $k \rightarrow$ '. Can someone enlighten me on this? Or, perhaps, show a different way to proof that the set is countably infinite?","['infinity', 'discrete-mathematics']"
3264633,When is $C_c^\infty(\mathbb R^d \setminus \{ 0 \})$ dense in $C_c^\infty(\mathbb R^d)$?,Let $d\in \mathbb N$ . Under what constraints for $d$ and $p$ is $C_c^\infty(\mathbb R^d \setminus \{ 0 \})$ dense in $C_c^\infty(\mathbb R^d)$ with respect to the $L^p(\mathbb R^d)$ -norm?,"['functional-analysis', 'analysis', 'real-analysis']"
3264634,Does setting records in a sport become less likely (under certain assumptions)?,"Problem Let $X_{j}$ be the number of seconds $j$ -th swimmer takes from one end of the pool to the other, where $X_{1}, X_{2}, ...$ are i.i.d. with a continuous distribution. We will say that the $j$ -th swimmer sets a records if $X_{j}$ is greater than all of $X_{j-1}, ..., X_{1}.$ Is the event that ""the 110th swimmer sets a record"" independent of the event that ""the 111th swimmer sets a record""? Approach : Prove $P(I_{111}=1, I_{110}=1) = P(I_{111}=1)P(I_{110}=1)$ where $I_{j}$ is an indicator random variable for the $j$ -th person setting a record. $P(I_{j} = 1) = \frac{1}{j}$ , since by i.i.d. properties, all of the first $j$ swimmers are equally likely to set the record. $P(I_{111}=1, I_{110}=1) = \frac{109!}{111!}$ , since we fix the 111-th and 110-th swimmers in record setting positions. Then, $$P(I_{111}=1, I_{110}=1) = \frac{109!}{111!} = \frac{1}{111 * 110} = P(I_{111} = 1) * P(I_{110} = 1).$$ Thus, the events in question are independent . Intuition Suppose a million swimmers participate in the competition. If the $999999$ -th swimmer sets a record, the swimmer probably completed the task in an incredible short period of time, since $999998$ swimmers before him had chances to set records. This means that for the $1000000$ -th swimmer to set a new record, they will probably need to complete the task in an extremely unlikely amount of time. So, the events in question are dependent . Question I am having trouble reconciling my intuition with the result obtained after doing the computation. I have a suspicion the key is in the fact that $X_{j}$ are i.i.d., Any pointers? Note The question comes from strategic practice and homework 4 of Stat110 .","['statistics', 'probability-theory', 'probability']"
3264666,Prove that there is $n\in\mathbb{N}$ such that $n!$ starts with 1996,"Basically the statement says that there is some number $n$ such that: $$1996\cdot 10^k<n!<1997 \cdot 10^k$$ $$k + \log 1996<\sum_{i=1}^n \log i<k+\log 1997$$ A nice idea how to solve a similar problem can be found here , but I could not utilize it in this problem. Origin of this problem is a mystery - I have found it on a page where people listed their favorite math problems but this one had no solution.","['elementary-number-theory', 'algebra-precalculus']"
3264677,Explain why a line can never intersect a plane in exactly two points.,"Why can a line never intersect a plane in exactly two points? I know this seems like a really simple question, but I'm having a hard time figuring out how to answer it. I also tried googling the question but I couldn't find an answer for exactly what I'm looking for.",['geometry']
3264735,Two holes in the graph when dividing polynomials?,"Sorry if this seems like a dumb question, or if it has been answered already. I did a quick search and didn't turn up anything, so here goes. I'm teaching a high school algebra class, and the book I'm doing says the students need to note restrictions on both the numerator and denominator when dividing two polynomials. For example: $$\frac{ \left(\frac{x^2-121}{x^2-4} \right)}{ \left(\frac{x+2}{x-11} \right)}$$ There is obviously going to be an asymptote at $x = -2$ , but the book also suggests there should be a hole in the graph at $x = 11$ . However, graphing the function on a graphing calculator (desmos, in this case), shows the function to be equal to $0$ when $x = 11$ . Changing the numerator of the dividend to something like $(x² - 133)$ doesn't alter the equation equaling zero at $x = 11$ either. Wouldn't $x = 11$ imply that $(x² - 133)/(x² - 4) ÷ (x+2)/(x-11)$ is actually $(x² - 133)/(x² - 4) ÷ 1/0$ , or $(x² - 133)/(x² - 4) ÷ ∞$ ? Note: the TI-83 also gives me an ERROR message for this function at $x = 11$ , so perhaps it is just desmos? Edit: Sorry! I forgot to include another division sign when discussing this problem.","['calculus', 'graphing-functions', 'polynomials']"
3264738,"Maximum value of $x\cos(x)$ on $[0, \pi/2]$","I would like to find the maximum value of : $f(x) = x\cos(x)$ on $[0, \pi/2]$ . The huge problem I have is that $x$ is increasing on this domain and $\cos(x)$ is decreasing. I tried to find the derivative which is : $-\sin(x)x + \cos(x)$ yet finding its sign is as difficult as the original problem. So is there a shortcut  I am missing here ? Thank you !","['maxima-minima', 'trigonometry', 'functions', 'real-analysis']"
3264760,There exists a continuous function $f$ such that $f(\Bbb Q) \subseteq \Bbb R\setminus\Bbb Q$ and $f(\Bbb R\setminus\Bbb Q)\subseteq\Bbb Q$ [duplicate],"This question already has answers here : No continuous function switches $\mathbb{Q}$ and the irrationals (4 answers) Closed 5 years ago . True or false: There exists a continuous function $f: \Bbb R \to \Bbb R$ such that $f(\Bbb Q) \subseteq {\Bbb R}\setminus {\Bbb Q}$ and $f({\Bbb R}\setminus {\Bbb Q}) \subseteq {\Bbb Q}$ . My attempt: I was trying to use the sequential definition of continuity. Consider $a \in \Bbb R$ then we have a seqn ${x_n}$ of rational numbers converging to $a$ and we have a seqn ${y_n}$ of irrational numbers converging to $a$ . Then what will be $f(a)$ ? 
I was thinking that in one way $f(a) \in \Bbb Q$ and on the other way $ f(a) \in {\Bbb R}\setminus {\Bbb Q}$ . But I am wrong $\{f(x_n)\} \subseteq {\Bbb R}\setminus {\Bbb Q}$ and $\{f(y_n)\} \subseteq {\Bbb Q}$ still $f(a)$ can be anywhere. Is there any way to fix my attempt or any other possible idea?","['analysis', 'real-analysis', 'continuity', 'functions', 'sequences-and-series']"
3264779,"Vector fields - Chapter 0, Do Carmo's Riemannian Geometry","There's the following observation with a very short proof: Observe that if $\varphi : M \to M$ is a diffeomorphism, $v \in T_p M$ and $f$ is a differentiable function in a neighborhood of $\varphi(p)$ , we have $$
(d\varphi(p) f) \varphi (p) = v(f \circ \varphi)(p)
$$ Indeed, let $\alpha : (-\epsilon, \epsilon) \to M$ be a differentiable curve with $\alpha'(0) = v$ and $\alpha(0) = p$ . Then $$
(d \varphi (v) f) \varphi (p) = \left. \frac{d}{dt} (f \circ \varphi \circ \alpha) \right|_{t=0} = v(f \circ \varphi)(p)
$$ I don't get the very last line, I suppose it follows from the definition given of tangent vector, but I really can't work out the details. Could you explain more in detail that line? Thank you (P.S. here $M$ is a differentiable manifold). Update : In the statement of this theorem $\beta$ is defined as $\beta = \varphi \circ \alpha$ . Given a curve $\alpha : (-\epsilon,\epsilon) \to M$ (differentiable manifold) a tangent vector is defined as $$
\alpha'(0) f = \frac{d}{dt} (f \circ \alpha).
$$ Using $\beta$ instead of $\alpha$ we have $$
\beta'(0)f = \frac{d}{dt}(f \circ \beta) = \frac{d}{dt}(f \circ \varphi \circ \alpha)
$$ but $\beta'(0) = d \varphi_p(v)$ therefore $\beta'(0) f = d \varphi_p(v) f$ and therefore we have $$
d \varphi_p(v) f = \frac{d}{dt}(f \circ \varphi \circ \alpha)
$$ Therefore what I think I'm actually missing is the meaning of the notation $ \left( d \varphi_p(v) f \right) \varphi(p)$ More details Just to clarify, my previous update is my interpretation of the notation used, I've noticed there's some inconsistencies (I think) in the notation used throughout the book (at least for chapter 0). 1) In definition 2.6. The author defines a tangent vector to a differentiable manifold $M$ as an operator $\alpha'(0) : \cal{D} \to \mathbb{R}$ , where $\cal{D}$ is the set of differentiable functions defined on $M$ . Such description makes very clear to me the meaning of the notation $\alpha'(0)f$ , If I view it as an operator. Moreover we have the expression given $$
\alpha'(0) f = \frac{d}{dt}(f \circ \alpha)
$$ The right handside of the expression in terms of computation is clear to me, because of the parameterization. 2) In proposition 2.7, given a differentiable map $\varphi$ between two differentiable manifolds $M_1^n, M_2^m$ and the differential $d \varphi_p(v)$ is defined. To define this differential we need a $p \in M_1^n$ and a tangent vector $v \in T_p M_1^n$ . The differential is a map from $T_p M_1^n$ to $T_{\varphi(p)} M_2^m$ , and therefore it acts as an operator from the set of differentiable functions on $M_2^m$ to $\mathbb{R}$ . Thefore the meaning of the notation $ d \varphi_p(v) f $ is still clear to me. 3) My original question concern page 26 of the book, where the notation $(d \varphi(v) f)\varphi(p)$ is introduced. The reason I get confused is in the first place I think there's a mistake in the notation used because if you compare $d \varphi_p(v) f$ against $(d \varphi (v) f) \varphi(p)$ there's some difference. I don't know for example what $d \varphi(v)$ means, but I do know what $d \varphi_p(v)$ means. Also $d \varphi_p(v) f$ returns a real value by definition and this doesn't not seem evident to me from $(d \varphi(v) f) \varphi(p)$ . I hope I clarified what my issue is.","['proof-explanation', 'differential-geometry']"
3264807,"Prove $\det \left[\begin{smallmatrix} A&B\\\\C&D\\ \end{smallmatrix}\right] =\det(AD-BC)$ for $A,B,C,D$ upper triangular complex matrices","Let $A,B,C$ and $D$ be upper-triangular $n \times n$ complex matrices. Let $$E=\begin{bmatrix} A&B\\C&D\\ \end{bmatrix}$$ Prove $\det(E)=\det(AD-BC)$ . I did this problem in the case that the matrices commute but I cannot figure out this case.","['matrices', 'determinant', 'linear-algebra', 'block-matrices']"
3264812,Proving this trigonometry proves difficult,"At first the question appear cheap to me, so I hesitated in solving it but when I finally tried to solve it. I did not arrive at the supposed answer Given that $\tan A/2 = \csc A - \sin A $ Show that $\tan (A/2)^2 = -2 ± \sqrt{5}$ Using the $t$ -formula to solve it, I got hooked at $3{t^4} - 4{t^2} +1 = 0$ instead of $t^4 + 4t^2 - 1 = 0$ I need help on this. How do I unravel the mystery behind this? The solution in the handout here begin with changing to t formula
Where $\tan (A/2) = t$ and $\sin A = 2t/(1 + t^2)$ . 
We have $t = (1 + t^2)/2t - 2t/(1+t^2)$ $t = ((1 + t^2)^2 - 4t^2)/2t(1 + t^2)$ From there the handout jumped to $t^4 + 4t^2 - 1 = 0$ My problem is how to arrive at this equation above?",['trigonometry']
3264847,Why do we find the homogeneous solution of inhomogeneous Differential Equations?,"We all know that if we have inhomogeneous differential equation, we must solve for homogeneous solution and the inhomogeneous solution. And, in the end, we add them together for the complete solution. Suppose i have simple ODE : $y''+2y'+y=x$ And i got : $y_h=\left(C_1+xC_2\right)e^{-x}\\
y_p=x-2\\$ $
 \begin{aligned} \therefore y &= y_h+y_p\\
&=\left(C_1+xC_2\right)e^{-x}+x-2
\end{aligned}$ But i know that the inhomogeneous solution ( $y_p$ ) is satisfied enough for that ODE, so why don't we use the $y_p$ only? Lately, This question appear in my mind and sometimes it's annoying cz i still can't answer it.","['differential', 'ordinary-differential-equations']"
3264866,Probability Notation: What does $\{\omega\in \Omega : X(\omega) \in A\}$ mean?,"In the book Stats with Julia on p. 79 is reads ... ""The probability distribution of a random variable fully describes the
  probabilities of the events such as $\{\omega\in \Omega : X(\omega) \in A\}$ for all sensible $A \subset R$ "" How would you say "" $\{\omega\in \Omega : X(\omega) \in A\}$ "" in plain English? Is it .... for every possible outcome $(\omega)$ in the $(\in)$ event space $(\Omega)$ such that $(:)$ there is some specific outcome $(X(\omega))$ in the set $A$ where set $A$ contains real numbers .. is that close??","['notation', 'probability', 'random-variables']"
3264878,Why is dim(ρW)=dimW for ρ being a linear representation?,"first time asking on here so sorry if it's a bit clumsy. I will have to hold a seminar tomorrow and my professor helped me with one of my proofs. The proof is about showing that for any group $G$ and any abelian Subgroup $A$ the following statement is true: The degree of any irreducible representation of $G$ is less or equal to $\frac{g}{a}$ with $g$ being the order of $G$ and $a$ being the order of $A$ . I've already shown that any irreducible subrepresentation of an abelian group has degree $1$ . Later in my proof my professor wrote something along those lines: $ \dim(\rho*W) = \dim(W) $ for $\rho$ being a linear representation of $G$ in $V$ and $W$ being a subspace of $V$ and $W$ being the representation space of $A$ (abelian subgroup of $G$ ).
He wrote something about $\rho$ being an isomorphism but as far as I know, linear representations usually are only (Group-)Homomorphisms but not necessarily Isomorphisms. So can anybody please explain to me why this statement is true in this general case, if it's even true at all? I would be very thankful if anybody could explain this to me. My main problem is that $\rho$ (referring to any element of $G$ ) is more or less a Matrix. Multiplying this matrix with $W$ (so every element in $W$ ) must not necessarily produce a vector space with the same dimension as the space $W$ . For example let's look at the matrix with $0$ in each entry. Multiplying this matrix with any vector in $W$ would give me only the vector space containing $0$ which is most certainly not $W$ . I'm sorry to bother you and I hope my problem isn't something completely obvious, I've been missing for hours now...","['finite-groups', 'group-theory', 'linear-algebra', 'representation-theory']"
3264903,Integral $\int_{-\infty}^{\infty} \arctan(e^x) \arctan(e^{-x})dx=\frac{7}{4}\zeta(3)$,"How to prove that $$\int_{-\infty}^{\infty} \arctan(e^x) \arctan(e^{-x})\rm dx=\frac{7}{4}\zeta(3)?$$ This integral appeared while attempting to solve an unanswered question, namely: Closed form of :$ \int_{-\infty}^{\infty}\arctan\left(e^{-x^2 \text{erf}(x)}\right)\,\arctan\left(e^{x^2\text{erf(x)}}\right)\,dx $ I happened to find that $$\int_{-\infty}^{\infty} \arctan(e^x) ~\arctan(e^{-x})~dx=\frac{7}{4}\zeta(3).$$ How can you work out the answer on the right by hand? I guess that there could be multiple approaches to solve this one.","['integration', 'improper-integrals', 'definite-integrals', 'trigonometric-integrals', 'riemann-zeta']"
3264908,Let $f(x)=\int_1^\infty \frac{\cos t}{x^2+t^2}dt$. Then which of the following are correct?,"Let $f(x)=\int_1^\infty \frac{\cos t}{x^2+t^2}dt$ . Then which of the following are correct? $f$ is bounded on $\mathbb R$ $f$ is continuous on $\mathbb R$ $f$ is not defined everywhere on $\mathbb R$ $f$ is not continuous on $\mathbb R$ My try: $|f(x)|=|\int_1^\infty \frac{\cos t}{x^2+t^2}dt|\leq \int_1^\infty |\frac{\cos t}{x^2+t^2}|dt\leq \int_1^\infty \frac{1}{x^2+t^2}dt=\frac{1}{x}\tan^{-1}(\frac{t}{x})|_1^\infty $ . Let $g(x)= \frac{1}{x}\tan^{-1}(\frac{t}{x})|_1^\infty$ is not continuous at $0$ . That doesn't mean that $f$ is not bounded. For continuity, $|f(x)-f(y)|=|\int_1^\infty \frac{\cos t}{x^2+t^2}dt-\int_1^\infty \frac{\cos t}{y^2+t^2}dt|\leq \int_1^\infty |\frac{1}{x^2+t^2}-\frac{1}{y^2+t^2}|dt=\int_1^\infty |\frac{y^2-x^2}{(x^2+t^2)(y^2+t^2)}|dt $ . I am not conclude from here.","['integration', 'improper-integrals', 'real-analysis']"
3264914,Showing that the real projective space is Hausdorff using matrices and linear algebra,"I am trying to follow the proof in Loring Tu's book (An introduction to smooth manifolds, 2nd edition, p.79) to show that the real projective space is Hausdorff. A snippet of the proof is shown below. I am confused about the part where we show that $R$ is a closed subset. I understand that the rank of $x$ and $y$ concatinated being at most 1 is equivalent to the vanishing of all $2\times 2$ minors of $[x \hspace{0.5em} y]$ . My 2 questions are: 1) How is $R$ the zero set of finitely many polynomials? Showing the rank is at most 1 only involves $2 \times 2$ minors, i.e. only 2 rows of $R$ are utilized. 2) If it is the zero set, why is it closed? Does the ""finitely"" (in ""finitely many polynomials) play a role here? Hoping someone can help clarify things. Thanks!","['smooth-manifolds', 'linear-algebra', 'manifolds', 'general-topology', 'differential-geometry']"
