question_id,title,body,tags
3359946,Find the point on the graph of $z= x^{2} +y^{2} +10$ nearest to the plane $x+2y-z=0$.,"Find the point on the graph of $z= x^{2} +y^{2} +10$ nearest to the plane $x+2y-z=0$ . So, any point on the given surface will be $(x,y,x^{2} +y^{2} +10)$ .
I need to minimize the function $(x +2y-x^{2}-y^{2}-10)/(\sqrt{6})$ The only critical point is $(1/2,1)$ . But this point gives maximum of the function.
How would I find the nearest point. What I think is that, I should change the sign of the function, to keep the distance positive, then I'll get the same critical point, but the value will be minimum. So I'll get the nearest point. In this case if I am asked to find the maximum distance, what it should be then $?$","['multivariable-calculus', 'calculus']"
3359982,"1-Torus as finite dimensional $\mathbb{R}$-vector space is one dimensional, yet not isomorphic to $\mathbb{R}$","I know that the 1-torus, given by its presentation as rotation matrixes: $\mathbb{T}=\{R_{\theta}=\begin{pmatrix} cos(\theta) & -sin(\theta) \\ sin(\theta) & cos(\theta) \end{pmatrix}: \theta \in \mathbb{R}\}$ , forms a vector space over $\mathbb{R}$ , with the following addition and scalar multiplication. $R_{\theta}  \oplus R_{\alpha} = R_{\theta}R_{\alpha}=R_{\theta + \alpha}$ , this works because of sine and cosine sum of angles formulae. And scalar multiplication given by $r\odot R_{\theta} = R_{r\theta}$ . My doubt is the following, I'm quite sure given a finite dimensional vector space $V$ over a field $\mathbb{K}$ , we can say that: $$(1)\text{    }\text{    }\text{    }\text{    }\text{    }\text{    }V\cong \bigoplus_{j=1}^{dim(V)}\mathbb{K}$$ Where the isomorphism is given by mapping the scalar multiplying each basis element to it's own coordinate on the direct sum. The thing here, is that we have an epimorphism given by: $$\psi:\mathbb{R}\to \mathbb{T}$$ $${\theta}\mapsto R_{\theta}$$ This epimorphism has clearly a nontrivial kernel, given the periodicity of sine and cosine functions, and the space defined as $\mathbb{T}$ is clearly one dimensional. Also, no linear mapping between these spaces can be ever an isomorphism, given that $\mathbb{T}$ is compact, and every linear function is continuous on $\mathbb{R}$ . How come this isn't a contradiction, am i missing something and $\mathbb{T}$ isn't really a vector space? What I'm sure has to be true is, given a vector space $V$ , with an ordered basis $\mathcal{B}=\{b_{i}\}_{i=1}^{n}$ , and the mapping: $$\phi: \bigoplus_{j=1}^{n}\mathbb{K} \to V$$ $$(\lambda_{i})_{i=1}^{n} \mapsto  \sum\limits_{i=1}^{n} \lambda_{i}b_{i}$$ Is an epimorphism, so because of the first isomorphism theorem for modules, we can conclude: $$V\cong \bigoplus_{j=1}^{n} (\mathbb{K}/Ker(\phi_{i}))$$ Where $\phi_{i}:\mathbb{K}\to V$ , given by $\phi_{i}(\lambda)=\lambda b_{i}$ . Is this what I should think about when talking about finite dimensional vector spaces, or is indeed (1) true, and I'm missing something fundamental about the structure of $\mathbb{T}$ , making it NOT a vector space of finite dimension over $\mathbb{R}$ ?","['linear-algebra', 'vector-spaces', 'vector-space-isomorphism']"
3360048,Measure theory; proving an infinite partition exists from a sigma-algebra.,I'm really new to measure theory and have trouble with interpreting a question. We have a space $A$ with $\mathbb{A}$ a $\sigma$ -algebra with infinitely many elements. Now I need to show an infinite partition exists. Of course we first need to define what an infinite partition is. It is a countable infinite sequence of non-empty and disjoint sets which union is $A.$ So we know there are infinite elements in the $\sigma$ -algebra. I would argue we need to rearrange the elements of $\mathbb{A}$ to make them countable and then introduce a 'left-overs' subset that contains all elements that are outside of our countable division. I know this is probably very wrong but I would appreciate any steering in the right direction...,"['measure-theory', 'set-partition', 'real-analysis']"
3360064,How would I find the Jacobian matrix for this set of differential equations?,"I am working on a nonlinear dynamics problem set and I am uncertain of how to go about finding the Jacobian matrix for this set of equations. I know that you can use taylor expansion and I should end up with a matrix of partial derivatives... I think I have an answer, I just want to double check! Thank you so much! Here are the equations: $\dot{x} = y - x^3 - 3x^2 + I$ $\dot{y} = 1 - 5x^2 - y$ NB: I think that the jacobian is $\begin{bmatrix}3x^2 - 6x & 1\\ -10x & -1\end{bmatrix}$ and it will be evaluated at some point (x*, y*).","['systems-of-equations', 'jacobian', 'multivariable-calculus', 'calculus', 'linear-algebra']"
3360204,Help prove that the set $\mathbb{Q^3}$ is countable,"Help is this close, right? Need very elementary explanation $\mathbb{Q}^3=\{(x,y,z)|(x,y,z) \in \mathbb{Q}\}$ A remark in the text states that the sets $\mathbb{Z}$ and $\mathbb{Q}$ are countable but the set of irrationals is not. There is another theorem (1.42) which states Let $A_1, A_2...$ be at most countable sets then: $A_1$ $\times$ $A_2$ is at most countable. Proof: Let $$A_1 = \{x | x \in \mathbb{Q}\}$$ $$A_2= \{y | y \in \mathbb{Q}\}$$ $$A_3 = \{z | z \in \mathbb{Q}\}$$ Since $A_1$ , $A_2$ , $A_3$ are at most countable: $$A_1 \times A_2 \times A_3 = \mathbb{Q} \times \mathbb{Q} \times \mathbb{Q} = \mathbb{Q}^3$$","['elementary-set-theory', 'proof-verification']"
3360213,English Sentence to Predicate Logic,"I have 2 English sentences that I am having trouble translating them to predicate logic. 1. All people who live together drive the same car. 2. There is no number that is larger than all other numbers. I do know that for sentence 1 it has to have a universal quantifier. The key word that gave it was All. Would this be correct or close to the answer .. ∀x(Person(x) ∧ Home(x) ->  ∃y Car(y,x)) For the second one Same thing... Instead of a universal i use existential for the first part because it only refers to 1 number.
Can anyone help out with these? I'm just confused on how to tackle these. I'm looking for the answer but as well as the thoughts on how i can figure these out.","['predicate-logic', 'logic', 'discrete-mathematics']"
3360228,Some extended question on bounds of Rational map,"I saw this question here : I am stuck on the same kind of question but my problem is a bit more general which thrives me to post a new one. I am copying a bit definition from that post to save some typing time. Let $\phi: \Bbb P^1 \to \Bbb P^1$ be a rational map then we define $Aut(\phi)=\{f \in PGL_2(\Bbb C): \phi^f=f^{-1}\phi f(z)=\phi(z)\}$ Here, in general, the definition of a rational map is: Let $\mathbb{P}^n$ and $\mathbb{P}^m$ be projective spaces. If $m$ homogeneous polynomials in $n+1$ variables of the same degree ""d"" give a partially defined map from $\mathbb{P}^n$ to $\mathbb{P}^m$ then this map is called a rational map. We can exactly define this on a projective variety as well. Let $\phi: \Bbb P^1 \to \Bbb P^1$ be a rational map of degree $d \geq 2$ . Then $Aut(\phi)$ is a finite subgroup of $ PGL_2(\Bbb C)$ and its order is bounded by a function of $d$ . Proof: Let $f \in Aut(\phi)$ . Then for any point $P \in \Bbb P (\Bbb C)$ and any $n\geq 1$ we have $$\phi^n(P) = (\phi^f)^n(P ) = (f^{-1}\phi^nf) (P )$$ ,
and hence $$f (\phi^n(P )) = \phi^n(f( P))$$ . In particular, if P is a periodic point of (primitive) period n, then f (P) is also a
periodic point of (primitive) period n. Thus each $f \in Aut(\phi)$ induces a permutation of each of the sets $Per_n (\phi)$ and $Per_n^{**} (\phi )$ , where $Per_n (\phi)$ and $Per_n^{**} (\phi )$ are the collection of periodic point and premitive peiodic points of period $n$ . [so $P\in  Per_n (\phi)$ means $\phi^n(P)=P$ and $P\in  Per_n^{**} (\phi)$ means n is the smallest natural no such that $\phi^n(P)=P$ holds. Choose three distinct integers $n_l, n_2, n_3$ such that $\phi$ contains primitive n periodic points for each value of n. Now we have a result that says that we can find such values, and further
that their magnitude can be bounded solely in terms of d. More precisely, they may
be chosen from among the first d+ 5 primes. Letting $$N_i =|Per_{n_i}(\phi)|\geq 1$$ for $$i=1,2,3$$ ,
the action of $\phi$ on the sets of primitive periodic points yields a homomorphism $$Aut(\phi) \to S_{N_1} \times S_{N_2} \times S_{N_3}...................(1)$$ from $Aut(\phi)$ into a product of three symmetric groups.
We claim that the homomorphism (1) is injective. To see this, we observe that
any f in the kernel of (1) fixes each $Per_{n_i}^{**} (\phi )$ ; hence f fixes at least three points
in $\Bbb P^1(\Bbb C)$ ; hence f is the identity map. Thus the homomorphism (1) is injective,
which implies that $Aut (\phi)$ is finite. This ends the proof. Now I have some questions: Can we extend this result for $n=2$ . I have some idea here that we don't have finite periodic points in $\Bbb P^2$ but finite indeterminacy locus. Can we exploit that? Can anyone please give me a written answer or some steps to do that? I feel that in $\Bbb P^3$ is infinite, if not, how to prove that? If yes then can anyone give me one example of the rational map $\phi:\Bbb P^3 \to \Bbb P^3$ where $Aut(\phi)$ is infinite. Remember we defined $Aut(\phi)=\{f \in PGL_2(\Bbb C): \phi^f=f^{-1}\phi f(z)=\phi(z)\}$ . Now we are going to define $BiRat(\phi)=\{f$ a birational map $: \phi^f=f^{-1}\phi f(z)=\phi(z)\}$ . For the sake of simplicity, you can take a birational map to be a rational map with the rational inverse. Then clearly $Aut(\phi) \subseteq BiRat(\phi)$ . Now the question is for $n=2$ . Is $|BiRat(\phi)|=\infty$ ? Otherwise give me an example of rational or biration map $\phi$ for which $|BiRat(\phi)|<\infty$ ? This one is for those who are familiar with the Cremona group . Can we find a finite subgroup of the Cremona group $Cr(2)$ or $Cr(n), n\geq 3$ ? Give me one specific example. Thanks in advance. Please help me in at least one of these questions.","['algebraic-number-theory', 'dynamical-systems', 'arithmetic-dynamics', 'algebraic-geometry', 'projective-space']"
3360273,Differentiability of homogeneous functions in n variables,"Suppose $f=f(x_1,x_2,...,x_n)$ is a homogeneous function $$f(Cx_1,Cx_2,...,Cx_n)=C^\lambda f(x_1,x_2,...,x_n)$$ 1) Is $f$ differentiable w/respect to all its arguments? 2) Is $f$ differentiable w/respect to all its arguments at the origin? 3) Is $f$ differentiable w/respect to all its arguments at a point, where some of the $x_i$ are negative or zero? 4) Are all partial derivatives of $f$ also differentiable, to what order and where? Perhaps Euler's theorem for homogeneous functions is related to the question... When is a homogeneous function also differentiable?","['real-analysis', 'multivariable-calculus', 'calculus', 'partial-derivative', 'derivatives']"
3360322,Asymptotic of sum with binomial coefficients.,"Let $\displaystyle f(n,k) = \sum_{m \le k} \binom{n}{m}$ . We need to show $\displaystyle f(n,k) \sim \frac{2^{nH(k/n)}}{\sqrt{2\pi k(n-k)/n}}(1 + o(1))$ , where $k = o(n)$ and $k \to \infty$ Actually I've thought about three ideas : 1) Consider $\displaystyle \xi _{i}$ be Bernoulli random variables, and use CLT for estimating this sum. 2) Use Stirling approximation. 3) Use Abel summation. The former idea give the worst asymptotic. The second one isn't usable , because $m$ is just a constant for finitely many times. The last idea gives me : (1) = $\displaystyle \sum_{m \le k} \binom{n}{m} = \sum \frac{n!}{m!} \cdot \frac{1}{(n-m)!}$ , let $\displaystyle g(x) = \frac{1}{\Gamma(n-x)}$ and $a_m = n! / m!$ . Hence we have $\displaystyle A(x) = \sum_{m \le x} \frac{n!}{m!} \sim n! e$ , so we would have something like (1) $\displaystyle \sim$ $\displaystyle \frac{en!}{\Gamma(n-k)} + \int_{1}^{k} \frac{en! \Gamma'(n-x)}{\Gamma^2(n-x)} dx$ . Major part of integral gives us $\displaystyle \frac{en!}{\Gamma(n-k)}$ , so we obtain $\displaystyle \frac{2e n!}{\Gamma(n-k)} = \frac{2en!}{(n-k)!}$ even Stirling approximation doesn't give us the mentioned result. Any hint? Attempt (using CLT). Let $S_n = \sum X_i$ , where $X_i$ i.r.v with Bernoulli distribution and $p = 1/2$ . Hence we have $2^n \mathbb{P}( S_n \le k) = \sum ^{k} \binom{n}{m}$ . So we should estimate this probability. Using CLT we have : $ \mathbb{P}\left( \frac{S_n - \mathbb{E}(S_n) }{\sqrt{\mathbb{Var}(S_n)}} \le \frac{k - \mathbb{E}(S_n)}{ \sqrt{\mathbb{Var}(S_n)}}\right)$ . Thus for $n \to \infty$ we have that probability estimates as $F_{Z} \left( \frac{k - n/2}{ \sqrt{n/4}}\right)$ which doesnt give us a given estimation. Maybe this approach can be obtained and upgraded?","['proof-verification', 'binomial-coefficients', 'discrete-mathematics', 'sequences-and-series']"
3360383,Compute $\sum_{n=1}^\infty\frac{H_nH_{2n}}{(2n+1)^3}$,"How to prove that $$\small{\sum_{n=1}^\infty\frac{H_nH_{2n}}{(2n+1)^3}=\frac1{12}\ln^52+\frac{13}{128}\zeta(5)-\frac12\ln^32\zeta(2)+\frac74\ln^22\zeta(3)-\frac{17}{8}\ln2\zeta(4)+2\ln2\operatorname{Li}_4\left(\frac12\right)}$$ whre $H_n$ is the harmonic number, $\zeta$ is the Riemann zeta function and $\operatorname{Li}_a(x)$ is the polylogarithm function. This problem is proposed by Cornel ( can be found here ) and no solution has been submitted yet. I tried all the tools I used in solving the other tough series but did not work, so I consider this series very hard to crack. Any idea ? I am tagging "" integration"" as logarithmic integrals are very related to harmonic series.","['integration', 'harmonic-numbers', 'polylogarithm', 'sequences-and-series', 'riemann-zeta']"
3360409,Dual of a polyhedral cone,"A general polyhedral cone $\mathcal{P} \subseteq \mathbb{R}^n$ can be represented as either $\mathcal{P} = \{x \in \mathbb{R}^n : Ax \geq 0 \}$ or $\mathcal{P} = \{V x : x \in \mathbb{R}_+^k , V \in \mathbb{R}^{n \times k} \}$ . I am trying to do show the dual of $\mathcal{P}$ , $\mathcal{P}^*$ , is a polyhedral set. I start by writing $\mathcal{P}^* = \{ y \in \mathbb{R}^n : y^T V x \geq 0$ $\forall x \in \mathbb{R}_+^k \}$ . (1) A polyhedral set is a set of the form $\{x \in \mathbb{R}^n : Ax \leq b \}$ (2). Any ideas how to go from (1) to (2). I also know that an image of a polyhedral set under a linear map is also polyhedral. PS: Similar questions like these have very advanced solution methods; I am looking for a much simpler way.","['polyhedra', 'dual-cone', 'convex-geometry', 'geometry', 'convex-analysis']"
3360442,How do I prove that there is a distance shorter than the length of 24in?,"I have been given this following math problem: In a room 10 feet high, with a ceiling 16 feet long and 8 feet wide, there sits a fly, exactly on the center line of the narrow wall, 0.8 feet from the ceiling. On the opposite wall, also on the center line, sits a spider, 2.4 feet above the ground. The fly notices that the spider has just awakened, and addresses it, ""Honorable spider, would you care to come over here and catch me?"" ""No, you would not give me enough time to reach you, but would fly away just in time."" ""Well, how fast do you intend crawling over here?” the fly asks. ""When I was young, I used to be able to run pretty fast. But now, I am old. I cannot crawl more than 8 feet per minute."" Upon hearing this, the fly replies sorrowfully, ""Too bad, I cannot wait longer than three minutes. I shall sleep for that length of time, and then I must get into the sunshine."" Now this problem has stumped me because the solution tells me that it is possible, but does not tell me why. I simply thought the answer was not possible because the shortest distance from the spider to the fly was the distance on the remaining wall from the spider (10 - 2.4), the length of the prism (16) and the remaining distance to the fly (0.8) which is equal to 24.4. $d = (10-2.4) + 16 + 0.8 = 24.4$ $t = \frac{d}{v} = \frac{24.4}{8} = 3.05$ min This would mean that the spider would miss the fly by 3 seconds. What am I overlooking here?","['algebra-precalculus', 'geometry']"
3360460,Calculating the curvature of product manifold $\mathbb{S}^2 \times \mathbb{R}$,"I've read that $\mathbb{S}^2 \times \mathbb{R}$ is one of the model geometries of Thurston which has non constant curvature. I took it to mean that the manifold $(\mathbb{S}^2 \times \mathbb{R}, g)$ has non constant sectional curvature (where $g$ is the standard product metric) and tried to compute its sectional curvature. Here's what I used: Let $(M, g_1)$ and $(N, g_2)$ be two Riemannian manifolds with curvature tensors $R_1$ and $R_2$ . Using that for each $(p, q) \in M \times N$ , $T_pM \oplus T_q N \cong T_{(p, q)}(M \times N)$ , for each $X, Y, Z \in \Gamma(T(M \times N))$ , we have: $R(X, Y)Z = R_1(X_1, Y_1)Z_1 + R_2(X_2, Y_2)Z_2$ $\text{Rm}(X, Y, Z, W) = \langle R(X,Y)Z, W \rangle$ where $X = (X_1, X_2)$ , with $X_1 \in \Gamma(TM)$ , $X_2 \in \Gamma(TN)$ and analogously for $Y$ and $Z$ , and the metric on $M \times N$ is given by: $$g^{M \times N}_{(p, q)}(X, Y) = g^{M}_{p}(X_1, Y_1) + g^{N}_{q}(X_2, Y_2)$$ Denoting by $R_1$ the curvature tensor for the sphere $\mathbb{S}^2$ and by $R_2$ the one for the real line, it's obvious that $R_2 \equiv 0$ . Now, let $X, Y$ be an orthonormal basis for a $2$ plane contained in some tangent space of $\mathbb{S}^2 \times \mathbb{R}$ . We have: $$\begin{align}R(X,Y)Y  &= R(X_1 + X_2, Y_1 + Y_2)( X_1 + X_2)\\ &= R(X_1, Y_1)X_1 + R(X_2, Y_1)X_1 + R(X_1, Y_2)X_1 + R(X_2, Y_2)X_1& \\ &+R(X_1, Y_1)X_2 + R(X_2, Y_1)X_2 + R(X_1, Y_2)X_2 + R(X_2, Y_2)X_2 \\ &= R_{1}(X_1, Y_1)X_1  \end{align}$$ since all the other terms disappear, where we're using that $R_2 \equiv 0$ . Then: $$\begin{align}K(X, Y) &= \langle R(X, Y)Y, X \rangle \\
&= \langle R_1(X_1, Y_1)Y_1, X_1 \rangle + \langle R_1(X_1, Y_1)Y_1, X_2 \rangle \\ &= \langle R_1(X_1, Y_1)Y_1, X_1 \rangle = 1 
\end{align}$$ because $\mathbb{S}^2$ has constant sectional curvature equal to $1$ . So we have that $\mathbb{S}^2 \times \mathbb{R}$ has constant sectional curvature as well. Where did I make a mistake here? Or does $\mathbb{S}^2 \times \mathbb{R}$ actually have constant curvature? (I also realized that if my computations are correct, it would imply that $\mathbb{S}^n \times \mathbb{R}$ has constant curvature for all $n \geq 1$ ...)","['riemannian-geometry', 'geometry', 'curvature', 'manifolds', 'differential-geometry']"
3360545,Consequence of Lagrange's Theorem,"This is from Abstract Algebra , Dummit and Foote, pg 93. For reference, this is how we know $|HK| = 4$ : My question is, how do we know $S_3 = \langle \: (12) , (23) \: \rangle $ ? What is it a consequence of? I know it's not a subgroup because 4 doesn't divide $|S_3| = 6$ . But couldn't { $(12) , (23)$ } just be a set that is not a subgroup or group?","['group-theory', 'abstract-algebra']"
3360577,Generalized Uniform Boundedness Theorem,"The following question is from the book ""General Topology"" written by John Kelly, Exercise 6.U in page 215. Def: A meager set is a union of countably many nowhere dense sets. Let $X$ be a real linear topological space which is not meager in itself and let $K$ be a closed convex subset of X such that $K$ = - $K$ and $K$ contains a line segment in each direction (i.e. for each $x \in X$ there is a positive real number $t$ such that for any $s \in$ [ $0, t$ ], $sx \in K$ . Show that $K$ is a neighborhood of $0$ (the identity element of $X$ . Used fact: 1): (From Exercise 6.P in page 211) A subset $A \subseteq X$ almost in $X$ (or satisfy the condition of Baire iff there is a meager set $B$ such that ( $A$ \ $B) \cup (B$ \ $A$ ) (denoted as $A \Delta B$ ) is open. 2): (From Exercise 6.P.a) in page 211) A subset $A$ is almost open in $X$ iff there are meager sets $B$ and $C$ such that ( $A$ \ $B$ ) $\cup$ $C$ is open. 3): (From Exercise 6.P.b) in page 211) For any subsets $A$ in a topological group ( $X, \tau$ ), if $A$ contains a non-meager almost open subset, then $AA^{-1}$ is a neighborhood of the identity element. Also 3) is known as the *Banach-Kuratowski-Pettis Theorem*. According to the hint, I need to prove that $K$ is non-meager and almost open. The only way I came up with is to apply contradiction, assuming $K$ is meager. I mainly had difficulty using the condition ""contains a line segment"". I added some random thoughts below .... Assume $K$ is meager and hence $K = \cup_{n \in \omega}U_n$ . Fix $a \in X$ and assume $sx \in K$ $\forall s \in [0, t_x]$ . Since the interior of each $U_n$ is empty and there are only countably many of them, I believe this will imply one of $U_n$ will contain $sx$ $\forall s \in [t_n, t_n^{'}]$ where $0 \le t_n^{'} < t_n < t$ . To make it more clear, WLOG say $K = \cup_{q \in \mathbb{Q_t}}U_q$ where $\mathbb{Q_t}$ is the set of rationals in [ $0, t$ ]. Fix $U_k$ and assume $sx \in U_k$ $\forall s \in [(t^{'})_{x, k}, t_{x, k}]$ . Once I have the set $\{t_{x, k}\}_{x \in X}$ , if its inf is $0$ , then I can not find a neighborhood inside $U_k$ Any hints will be appreciated.","['general-topology', 'topological-vector-spaces', 'functional-analysis']"
3360608,I don't understand the explanation of Proof by Contradiction,"I was given this explanation in my notes to understand Proof by Contradiction: Proof by Contradiction We want to prove that $\ P(n) \to Q(n) $ is true. In
a proof by contradiction, we assume by contradiction that $\ P(n) \to Q(n) $ is false, that is, that: $\ \neg (P(n) \to Q(n)) $ is true. The only way this might happen, is if $\ P(n) $ is true and $\ Q(n)$ is false. Thus we start with $\ P(n)$ true and $\ Q(n)$ false. If from there we deduce a contradiction,
that is a statement of the form $\ C \wedge \neg C $ , which is always false, what we
have proven is : $\ \neg (P(n) \to Q(n)) \to C \wedge \neg C$ , is true. This is equivalent to $\ P(n) \to Q(n) $ . To see that, set $\ S(n) = ""P(n) \to Q(n)""$ , and look at the truth table: What I don't understand is this line:
"" $\ \neg (P(n) \to Q(n)) \to C \wedge \neg C$ , is true."" How is it true if previously stated that $\ \neg (P(n) \to Q(n))$ is True $\ C \wedge \neg C$ is False (a contradiction) But we know that... $\ P \to Q $ is always False? How am I interpreting this explanation wrongly? I am really confused right now... any help/explanation is very much appreciated, thanks!!! Original screenshot (in case I formatted the equations wrongly... I'm new to mathjax/latex thing):","['proof-writing', 'proof-verification', 'logic', 'discrete-mathematics']"
3360609,"If $ABA = B$ and $BAB = A$ and $A$ is invertible, then $A^4 = I$","Let $A$ and $B$ be square matrices of the same order so that $ABA = B$ and $BAB = A$ . If $A$ is invertible, prove that $A^4 = I$ . I already proved that $A^2=B^2$ . How can I prove $A^4=I$ ?","['matrices', 'matrix-equations', 'projection-matrices']"
3360618,Time until next bus,"You arrive at a bus stop where buses come at a rate of $3$ per hour. What's the probability distribution of the waiting time for the next bus and its mean if the interarrival times between buses are (a) constant, (b) exponential, (c) either 0 or 60 minutes (groups of 3 buses go by in an hour). I can guess that the mean waiting time for constant is just $c/2$ where $c$ is the constant. In exponential distribution it will be just $\lambda$ . Not so sure about the third one. But getting these means doesn't help me find the distribution. Can anyone suggest me how to do it? I think you need to use the equilibrium distribution, but where do we use the fact that buses come at $3$ per hour? Do I even need this for the constant case?","['statistics', 'probability-distributions', 'probability-theory', 'probability']"
3360651,Explicit formula for product rule for Ito processes,"We know that we have the following formula $d(XY)=XdY+YdX+d[X,Y]$ , but how does this look when we have two actual processes? Should it look something like this? $d(XY)=XdY+YdX+d[X,Y]=X(\mu_{Y}dt+\sigma_{Y}dW)+Y(\mu_{X}dt+\sigma_{X}dW)+\sigma_{X}\sigma_{Y}dt=X \mu_{Y}+Y \mu_{X}+\sigma_{X}\sigma_{Y}dt +(\sigma_{Y}+\sigma_{X})dW=(\mu_{X}dt+\sigma_{X}dW )\mu_{Y}+(\mu_{Y}dt+\sigma_{Y}dW) \mu_{X}+\sigma_{X}\sigma_{Y}dt +(\sigma_{Y}+\sigma_{X})dW=$ $(\mu_{X}+\mu_{Y}+\sigma_{X}\sigma_{Y})dt+(\sigma_{X}\mu_{Y}+\sigma_{Y}\mu_{X}+\sigma_{Y}+\sigma_{X})dW$ where I used the definition of integration with respect to a semimartingale and the formula for the crossvariation of two Ito processes. Is the above equalites true for some hypothesis on the processes?","['stochastic-processes', 'probability-theory', 'stochastic-calculus']"
3360661,Derivative of $\sqrt{AA^T}$ with respect to $A$,"How to find the derivative of the function $f: M_n(\mathbb{R})\to M_n(\mathbb{R}), A\mapsto \sqrt{AA^T},$ where $A^T$ is the transpose of the matrix $A$ ? \begin{align}
    Df_V(A) & = \lim_{h\to 0}\dfrac{f(A+hV)-f(A)}{h}\\
            & = \lim_{h\to 0}\dfrac{\sqrt{(A+hV)(A+hV)^T}-\sqrt{AA^T}}{h}\\
            & = \lim_{h\to 0} \dfrac{\sqrt{AA^T+hAV^T+hVA^T+h^2VV^T}-\sqrt{AA^T}}{h}
  \end{align} Now, what should I do?","['matrices', 'matrix-calculus', 'derivatives']"
3360694,Order of an element 250 in U(641),"$U(n)$ is the collection of positive integers which are coprime to n forms a group under multiplication modulo n. What is the order of the element 250 in $U(641)$ ? My attempt:
Here 641 is a prime number.
So $U(641)$ is a cyclic group. So this group is Isomorphic to $Z/640 Z$ under addition modulo 640. I need to find the smallest positive integer n such that $250^n$ congruent to 1 (mod 641).
Any easy way to find this n? Also I found that inverse of 250 in U(641) is 100. Kindly provide some hints to find the required n. Thanks in advance.",['group-theory']
3360696,Interior points of a convex set,"If it is known that point I is an interior point of convex set C, would I be right in claiming that any point of the form K = pI + (1-p)X, where X is any other point in the convex set, p>0 and p<=1, is also an interior point? Alternatively: a boundary point cannot be expressed as a convex combination of points where there is a non-trivial contribution from interior points. Intuitively this seems to be the case, but I'm unable to prove it.","['general-topology', 'convex-analysis']"
3360707,"If $\lim\limits_{(x,y)\to (0,0)}(f(x)+g(y))$ exists, do $\lim\limits_{x\to 0}f(x)$ and $\lim\limits_{y\to 0}g(y)$ exist?","If the limit $\lim\limits_{(x,y)\to (0,0)}(f(x)+g(y))$ exists.Is it true that the limits $\lim\limits_{x\to 0}f(x)$ and $\lim\limits_{y\to 0}g(y)$ both exist?",['multivariable-calculus']
3360794,Beyond the complex plane - solving $\sqrt{x}=-1$,"Let $f: \mathbb R \longrightarrow [0,\infty[$ be some positive-valued function and consider the equation $$f(x) = -1.\tag{1}$$ Looks weird, but for $f(x)=x^2$ one has $x^2=-1$ which leads to the set of complex numbers by defining $\mathbb i$ to be the solution.
Now consider other simple algebraic functions like $f(x)=\sqrt{x}$ or $f(x)=|x|$ , such that (1) cannot be solved by real or complex $x$ . By defining $\mathbb j$ such that $$f(\mathbb j)=-1$$ we get a new set $\mathbb J$ of numbers $a + \mathbb j b, \ a,b \in \mathbb C$ . Complex numbers led to a new era of mathematics. I like thinking outside of the box. Let us collect some ideas about this approach. Is it known? Is it nonsense, inconsistent, non-valuable? If not, what properties do these numbers have? Edit: When $f$ is a polynomial (1) leads to $\mathbb C$ . Let $f$ be arbitrary and $\mathbb J =\{a + \mathbb j b \ |\ a,b \in \mathbb C\}$ . To make it a field we need $x\cdot y \in \mathbb J$ for all $x,y \in \mathbb J$ . This requires either $\mathbb j^2 =0$ , $\mathbb j^2 \approx \mathbb j$ or $\mathbb j^2 \in \mathbb C$ . For the latter let wlog $|\mathbb j^2|_{\mathbb C}=1$ such that $\mathbb j^2 = \exp(\mathbb i \theta)$ , for some $\theta \in [0,2\pi]$ . By the series expansion we get $$\exp(\mathbb j z)= \cosh(z \exp(\mathbb i \theta/2)) + \mathbb j \sinh(z \exp(\mathbb i \theta/2)), \ z\in \mathbb C.$$ For the second let wlog $\mathbb j^2 =\mathbb j$ . If $f$ has a series expansion around $\mathbb j$ then $$f(\mathbb j)= f(0)+ \mathbb j (f(1) -1),$$ which requires $f(0)=-1$ and $f(1)=1$ .","['complex-analysis', 'arithmetic', 'abstract-algebra', 'recreational-mathematics']"
3360805,3 as a sum of three integer cubes,"Until now, the only known integer solutions to the equation $x^{3}+y^{3}+z^{3}=3$ were $(x, y, z)=(1,1,1)$ and $(4, 4, -5)$ (up to their permuations). I have just seen on Facebook someone posting that $$569936821221962380720^3
+ (-569936821113563493509)^3
+ (-472715493453327032)^3 = 3,$$ but didn't reveal the discoverer of the result. Also, i couldn't find any news of this on Google. Has anyone else heard of this yet ?","['number-theory', 'diophantine-equations']"
3360876,What did I wrong in this question?(Group homomorphism and primitive roots),"This is the question that don't  have any idea Which point I was wrong Q) Let group homomorphism $f : Z_{50}^* \to  Z_{50}^*  $ $by$ $f(3) = 31$ (Here, the $Z_{50}^* = \{a \in Z_{50} \vert gcd(a,50)=1\}$ ) $3$ is a primitive root for $mod$ $50$ Find all the element of the $A =  \{ x \in Z_{50}^* \vert f(x)=9\}$ My attempt) $31 = 81 = 3^4$ $(mod50)$ So, $f(3) = 3^4$ Plus Owing to the $3$ is a primitive roots of the $Z_{50}^*$ , $3$ is a generator of the group $Z_{50}^*$ Then All we have to do is just find the $3^a s.t.$ $f(3^a) = 3^{4a} =3^2(mod50)$ Hence Find the $a$ satisfying $4a = 2(mod \phi(50))$ (Here the $a \in \{x \vert 1 \leq x <50, gcd(x,50)=1\}$ ) But $\phi(50)$ = $20$ , There aren't exist the "" $a$ "". (I.E. $A = \phi$ ) p.s.) But the someone who gave me this question said the answer is $A = \{9,13,37,41\}$ I totally couldn't understand Which point I was wrong . Please help me. Thanks. Additional post) 
Here is that person's solution who claiming the $A = \{9,13,37,41\}$ He might be the suggesting the incorrect answer, Surely there are two possibility that Should be incorrect either mine or his. For the integer set $Z$ , since $3^4 = 31$ , $imf=\{f(3^a) \vert a \in Z\} = \{(3^4)^a \vert a \in Z\}= <3^4>$ Then $\vert imf \vert  =5$ and $\vert Z_{50}^* / kerf \vert = \vert imf \vert = 5$ Hence $\vert kerf \vert =4$ Also, $f(-7) = f(3^5) = f(3)^5 = 3^{20} =1$ Plus, $f(-1) = f(3^{10} ) = f(3)^{10} = 3^{40} =1$ Therefore $\{-1, -7\} \in kerf$ So, $kerf = \{1,-1,7,-7\} $ We can conclude the $A = f^{-1}({9}) = 9kerf = \{9,-9,63,-63\} = \{9,13,37,41\}$","['group-homomorphism', 'number-theory', 'group-theory', 'abstract-algebra']"
3360908,Divergence of sum over lattice.,"This is  follow up to my last question on summing over countably infinite sets. I understand the idea conceptually now but I am still stuck when dealing with a concrete example. Specifically, consider $$\sum_{\omega \in \Lambda^*}\frac{1}{\omega^2}$$ where $\Lambda^*$ is a lattice in the complex plane without the origin. This sum has come up in several books when the author is defining the $\wp$ elliptic function. Apparently, it diverges but I haven't been able to find the details of why it does. Intuitively, I would think it would converge since for large $|\omega|$ one would expect $|1/\omega^2|$ to decay very rapidly. How would I even begin to analyze such a sum? I think the issue is my intuition from the sum $\sum \frac{1}{n^2}$ which does converge is corrupting my understanding. Thanks.","['complex-analysis', 'elliptic-functions']"
3360914,Concavity inequality for the matrix square root,"Let $A$ , $B$ and $C$ be symmetric, positive semi-definite matrices. Is it true that $$ \|(A + C)^{1/2} - (B + C)^{1/2}\| \leq \|A^{1/2} - B^{1/2}\|,$$ in either the 2 or Frobenius norm? It is clearly true when $A, B$ and $C$ commute, but the general case is less clear to me. In fact, even the particular case $B = 0$ does not seem obvious. Without loss of generality, it is clear that we can assume that $C$ is diagonal.
We show that it is sufficient to prove to prove the inequality for the matrix with zeros everywhere except on any position $k$ on the diagonal, $$
(C_k)_{ij} = \begin{cases} 1 & \text{if } i=j=k\\ 0 & \text{otherwise} \end{cases}
$$ Clearly,  if the inequality is true for one $C_k$ , it is true for any $C_k$ , by flipping the axes, and also for $C = \alpha C_k$ , for any $\alpha \geq 0$ , because \begin{align}
\|(A + \alpha \, C_k)^{1/2} - (B + \alpha C_k)^{1/2}\| 
&= \sqrt{\alpha} \|(A/\alpha +  C_k)^{1/2} - (B/\alpha + C_k)^{1/2}\|  \\
&\leq \sqrt{\alpha} \|(A/\alpha)^{1/2} - (B/\alpha)^{1/2}\|
= \sqrt{\alpha} \|A^{1/2} - B^{1/2}\|
\end{align} Now, a general diagonal $C$ can be decomposed as $C = \sum_{k=1}^{n} \alpha_k C_k$ .
Applying the previous inequality (specialized for a matrix $C$ with only one nonzero diagonal element) repeatedly,
we can remove the diagonal elements one by one \begin{align}
&\|(A + \sum_{k=1}^{n}\alpha_k \, C_k)^{1/2} - (B + \sum_{k=1}^{n}\alpha_k \, C_k)^{1/2}\| \\
&\qquad = \|((A + \sum_{k=1}^{n-1}\alpha_k \, C_k) + \alpha_n C_n)^{1/2} - ((B + \sum_{k=1}^{n-1}\alpha_k \, C_k) + \alpha_n C_n)^{1/2}\| \\
&\qquad \leq \|(A + \sum_{k=1}^{n-1}\alpha_k \, C_k)^{1/2} - (B + \sum_{k=1}^{n-1}\alpha_k \, C_k)^{1/2}\| \\
&\qquad \leq \|(A + \sum_{k=1}^{n-2}\alpha_k \, C_k)^{1/2} - (B + \sum_{k=1}^{n-2}\alpha_k \, C_k)^{1/2}\| \\
&\qquad \leq \dots \leq \sqrt{\alpha} \|A^{1/2} - B^{1/2}\|.
\end{align} Here are three ways of proving the inequality in 1 dimension,
which I tried to generalize to the multidimensional case without success.
Let us write $a$ , $b$ , $c$ instead of $A$ , $B$ , $C$ ,
to emphasize that we are working in one dimension,
and let us assume without loss of generality that $a \leq b$ . Let us write: $$ f(c) = \sqrt{b + c} - \sqrt{a + c} $$ We calculate that the derivative of $f$ is given by $$
f'(c) = \frac{1}{2} \left( \frac{1}{\sqrt{b + c}} - \frac{1}{\sqrt{a + c}} \right) \leq 0,
$$ and so $f(c) = f(0) + \int_{0}^{c} f'(x) \, d x  \leq f(0)$ . We have, by the fundamental theorem of calculus and a change of variable \begin{align}
    \sqrt{b + c} - \sqrt{a + c} &= \int_{a + c}^{b + c} \frac{1}{2 \sqrt{x}} \, d x = \int_{a}^{b} \frac{1}{2 \sqrt{x + c}} \, d x  \\
    &\leq \int_{a}^{b} \frac{1}{2 \sqrt{x}} \, d x = \sqrt{b} - \sqrt{a}.
\end{align} Squaring the two sides of the inequality, we obtain $$
a + c - 2 \sqrt{a+ c} \, \sqrt{b + c} + b + c \leq a + b - 2 \sqrt{a} \sqrt{b}.
$$ Simplifying and rearranging, $$
c + \sqrt{a} \sqrt{b} \leq \sqrt{a+ c} \, \sqrt{b + c} .
$$ Squaring again $$
\require{cancel} \cancel{c^2 + a b} + 2 c \sqrt{a b} \leq \cancel{c^2 + ab} + ac + bc,
$$ leading to $$ a  + b - 2 \sqrt{ab} = (\sqrt{b} - \sqrt{a})^2 \geq 0$$ . Numerical experiments suggest that the inequality is true in both the 2 and the Frobenius norm. 
(One realization of) the following code prints 0.9998775. import numpy as np
import scipy.linalg as la

n, d, ratios = 100000, 3, []
for i in range(n):
    A = np.random.randn(d, d)
    B = np.random.randn(d, d)
    C = .1*np.random.randn(d, d)
    A, B, C = A.dot(A.T), B.dot(B.T), C.dot(C.T)
    lhs = la.norm(la.sqrtm(A + C) - la.sqrtm(B + C), ord='fro')
    rhs = la.norm(la.sqrtm(A) - la.sqrtm(B), ord='fro')
    ratios.append(lhs/rhs)

print(np.max(ratios))","['matrices', 'inequality']"
3360970,how can I find the Side length Two squares inside an equilateral Triangle?,"Question: Figure shows an equilateral triangle with side length equal to $1$ . Two squares of side length  a  and $2a$ placed side by side just fit inside the triangle as shown. Find the exact value of $a$ . Its an Assessment question from edX course ""A-Level Mathematics Course 1""  and I am supposed to use skills that I learnt in Indices and surds,Inequalities and The Factor Theorem . I have tried finding the height of triangle and then use similar triangles to find the right triangle length still No luck. I am just looking for food for thought or very small hints thats all.","['triangles', 'geometry']"
3360985,Solving an integral equation with Laplace transform and convolution,"So I solved the integral equation $\int_{-\infty}^\infty f(t)f(x-t)\,dt = f(x)$ using the Fourier transform and convolution. With $F$ as $f$ 's Fourier transform, I found that $F²=F,$ then by using $F$ 's continuity and integrability I concluded that $F$ was the null function on $\Bbb R$ and so was $f$ . Now I've got a very similar equation to solve : $$\int_{0}^x f(t)f(x-t)\,dt = f(x).$$ Now it still looks like a convolution product but from Laplace's transform point of view, which use is strongly recommended in order to solve this. I fail to see why the conclusion would be any different, though; can someone push me in the right direction? Thanks a lot!","['fourier-transform', 'convolution', 'laplace-transform', 'analysis']"
3360994,Find rational $\frac{p}{q}$ such that $\frac{1}{3000}<|\sqrt{2}-\frac{p}{q}|<\frac{1}{2000}$,"Find rational $\frac{p}{q}$ such that $\frac{1}{3000}<|\sqrt{2}-\frac{p}{q}|<\frac{1}{2000}$ My Attempt take a sequence which converges to $\sqrt{2}$ : $p_1=1+\frac{1}{2}, p_{n+1}=1+\frac{1}{1+p_n}$ I find how to calculate the sequence : $p_n=\frac{x_n}{y_n}, \Delta y_n=x_n$ and $(\Delta^2-2)y_n=0 $ but there is no way how to find the rational which matches the given term.","['algebra-precalculus', 'sequences-and-series']"
3360997,Is the following way differentiating $x^TAx$ correct,"I know that there are a lot of question where the differential is found. Before i checked out those answered i tried myself, and i can't quite figure out if the results are the same. Here is what i tried. We have the following $$
\begin{array}{c}{f(x)=x^{T} A x} \\ {x=\left(\begin{array}{c}{x_{1}} \\ {\vdots} \\ {x_{n}}\end{array}\right) \quad \text { , } A=\left[\begin{array}{ccc}{a_{11}} & {\dots} & {a_{1 n}} \\ {\vdots} & {\ddots} & {\vdots} \\ {a_{n 1}} & {\dots} & {a_{n n}}\end{array}\right]}\end{array}
$$ Find $$\frac{\partial f(x)}{\partial x_i}$$ This can be rewritten in the following way $$
f(x)=\sum_{k=1}^{n} \sum_{r=1}^{n} a_{r k} \cdot x_{r} \cdot x_{k}
$$ We can divide this into the following cases $$
\left\{\begin{array}{ll}{x_{k} \cdot \sum_{r=1}^{n}\left(x_{k} \cdot a_{r k}\right)=\sum_{r=1}^{n} a_{r k} \cdot x_{k}^{2}} & {\text { for } k=i} \\ {x_{k} \cdot \sum_{r=1}^{n}\left(x_{k} \cdot a_{r k}\right)=c_{k}} & {\text { for } k \neq i}\end{array}\right.
$$ Since we have to find the partial with respect to $x_i$ and constants will disapear we have to find the parital derivative of the following, $$
\begin{array}{c}{f(x)=\sum_{r=1}^{n} a_{r i} \cdot x_{i}^{2}} \\ {f_{x_{i}}^{\prime}(x)=2 \cdot \sum_{r=1}^{n} a_{r i} \cdot x_{i}}\end{array}
$$ Is this method correct, or am i making an error somewhere? I understand the way other answers on here solves it, but i dont see why this is wrong - if it is.","['partial-derivative', 'calculus', 'derivatives', 'analysis']"
3361046,How to prove that Christoffel symbols are not components of a tensor,"I know how to prove it by the fact they don't respect the usual change of coordinates, but I want to prove it using that a tensor must be $\mathcal{C}^\infty$ -multilinear in all its components. 
Here is my wrong proof, someone can help me finding the mistake? Call $\Gamma:=\Gamma_{ij}^kdx^idx^j\frac{\partial}{\partial x^k}$ , then I want to prove that $\Gamma$ is not $\mathcal{C}^\infty$ -multilinear, i.e. if $X,Y\in\mathcal{T}(M)$ , $w\in\mathcal{T}^*(M)$ and $f,g,h\in\mathcal{C}^\infty(M)$ , then it doesn't hold that $\Gamma(fX,gY,hw)=fgh\Gamma(X,Y,w)$ . But we have: $\Gamma(fX,gY,hw)=\Gamma_{ij}^kdx^i(fX^s\frac{\partial}{\partial x^s})dx^j(gY^m\frac{\partial}{\partial x^m})\frac{\partial}{\partial x^k}(hw_tdx^t)=fgh\Gamma_{ij}^kdx^i(X^s\frac{\partial}{\partial x^s})dx^j(Y^m\frac{\partial}{\partial x^m})\frac{\partial}{\partial x^k}(w_tdx^t)=fgh\Gamma(X,Y,X)$ So where's the mistake? Thank you all.","['differential', 'differential-geometry']"
3361051,"What is the point solving hard integrals, trigonometric proofs and determinant proofs [closed]","Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 4 years ago . Improve this question There is this culture among highschool boards where they would rather spend time teaching you how to integrate $\sqrt{\tan(x)}$ instead of helping you develop intuition on how integration by parts or product rule works. While I totally understand that you must be proficient in things such integral solving, they rather teach you 'types' of integrals. These are so hard to the point where people learn what substitution must be made. Shouldn't time be spent on developing intuition and application rather than learning methods to solve trig identities or integrals. Especially cause the really hard ones are things one would never tackle in real life.","['calculus', 'soft-question', 'trigonometry']"
3361084,Surjectivity on stalks implies surjectivity on sheaves,"Let $\phi : F \rightarrow G$ be a map of sheaves.
Let $\phi _p  : F_p \rightarrow G_p$ be the induced maps of stalks at a point p $\in$ X (where F and G are sheaves over some topological space X) Show that if $\phi_p$ is surjective for every p in X, then $\phi$ is surjective. i.e show that if Im( $\phi_p$ ) $= G_p$ for every p then Im( $\phi$ ) $ = G$ . This is in reference to Hartshorne Chapter 2, exercise 1.2b. I have shown that (Im $\phi$ ) $_p = $ Im( $\phi_p$ ) and so if the map on stalks is surjective then we have that  (Im $\phi$ ) $_p =G_p$ But I'm not sure how to proceed from there. Most of the proofs I have found  just assert that this implies that Im( $\phi$ ) $ = G$ (which I don't see how it follows, because from what I understand, equality on stalks does not imply equality of sheaves). Some others involve a manipulation of direct limits and co-kernels but I don't quite understand how the proof for this works(I am not very fluent with category theory). Is there a way to prove this without (too much) category theory? If not, I'd appreciate any help with the category theoretic proof. Edit: here Im $\phi$ is the sheafification of the image presheaf","['algebraic-geometry', 'sheaf-theory']"
3361096,Simple recursion or closed form for $\lfloor 2^n \sqrt{2}\rfloor$,"Is it possible to find an expression of the form $$\lfloor 2^n \sqrt{2}\rfloor = \sum_{k=1}^r (\alpha_k + \beta_ki)\cdot\Big(a_k+b_k i\Big)^n, $$ where $i^2 = -1$ and $\alpha_k, \beta_k, a_k, b_k$ real numbers? Maybe with $r< 5$ if possible. I am trying to compute the mean value (average) of $\{ 2^n \sqrt{2}\}= 2^n \sqrt{2} - \lfloor 2^n \sqrt{2}\rfloor$ over $n=0, 1,2, \cdots$ . Let us denote as $p$ this mean value: $p$ is the proportion of binary digits of $\sqrt{2}$ equal to one, and $p$ is widely believed to be equal to $\frac{1}{2}$ . Note that $$p=\lim_{n\rightarrow\infty} p_n, \mbox{ with } p_n = \frac{1}{n}\sum_{k=1}^n \Big( 2^k \sqrt{2} - \lfloor 2^k \sqrt{2}\rfloor\Big).$$ Assuming we have a simple closed form for $\lfloor 2^k \sqrt{2}\rfloor$ as suggested in the first formula, then we can have a closed form for $p_n$ , involving a finite number of terms. I don't expect this to be true if you replace $\sqrt{2}$ by (say) $\pi$ or $\log 2$ , but I would expect this to work with any quadratic irrational. Of course you can always use the Fourrier series to represent the fractional part function, but I don't think it would be easy to handle: it involves an infinite number of terms ( $r=\infty$ .)","['number-theory', 'recurrence-relations', 'combinatorics', 'discrete-mathematics', 'sequences-and-series']"
3361106,Isomorphism of quotient of ideals,"Let $k$ be a field of characteristic zero.  Suppose that $A$ and $B$ are finitely generated $k$ -algebras, $I$ is an ideal of $A$ and $J$ an ideal of $B$ . Consider the ideal of $A\otimes_kB$ given by $$ L=I\otimes_k B+A\otimes_k J $$ For each $i\in\mathbb{Z}_{\geq0}$ we have a natural map $$ \bigoplus\limits_{0\leq j\leq i}\left(I^j/I^{j+1}\otimes_k B/J\right)\otimes_{(A\otimes B)/L}\left(A/I\otimes_kJ^{i-j}/J^{j-i+1}\right)\to L^i/L^{i+1}$$ given by multiplication on each summand.  I am quite sure this should be an isomorphism, and I believe it is surjective, but I haven't been able to prove it is injective.  Any ideas? In the case I am considering $I$ and $J$ are nilpotent ideals, so if that helps then you may assume that.  In fact in my case, $I$ and $J$ are the nilradicals of $A$ and $B$ respectively, and $A/I$ and $B/J$ are integral domains.  You can use that if it's helpful.","['ring-theory', 'algebraic-geometry', 'commutative-algebra']"
3361125,Direct construction of the real numbers using only the integers (c.f. Eudoxus reals),"Let the natural numbers $\Bbb N = \{0,1,2,3,\dots\}$ and the integers $\Bbb Z$ be given. We define a function $\gamma: \Bbb Z \to \Bbb Z$ by $$   
    \gamma(n) = \left\{\begin{array}{lr}
        \frac{n}{2} , & \text{when }\; n \text{ is even}\\
        \frac{n-1}{2}, & \text{when }\;  n \text{ is odd}\\
        \end{array}\right\} 
$$ A binary relation $R$ on $\Bbb N$ and $\Bbb Z$ is said to be a r-locator if it satisfies the following four properties: $$\tag 1 \text{The domain of } R \text{ is equal to } \Bbb N$$ $$\tag 2 \text{For every integer } n \ge 0, \text{ if } nRm \text{ then } (n+1)R2m$$ $$\tag 3 \text{For every integer } n \gt 0, \text{ if } nRm \text{ then } (n-1)R\gamma(m)$$ $$\tag 4 \text{For every integer } n \ge 0, \text{ the image } R(n) \text{ is bounded above}$$ We can associate to any r-locator a function $\; \mathtt M(R): \Bbb N \to \Bbb Z$ by writing $$\tag 5 \mathtt M(R): n \mapsto \text{Max}\big(R(n)\big)$$ A function $\alpha: \Bbb N \to \Bbb Z$ is said to be a binary tick specification if it satisfies the following two properties, $\tag 6 \text{For every } n \in \Bbb N, \; \big [ \, \alpha(n+1) = 2\alpha(n) \text{ or } \alpha(n+1) = 2\alpha(n) + 1 \,\big ]$ $\tag 7 \text{For every } N \in \Bbb N \text{ there exists a } n  \ge N \text{ such that } \alpha(n+1) = 2\alpha(n)$ Lemma 1: If $R$ is a r-locator then the function $\alpha = \mathtt M(R)$ satisfies $\text{(6)}$ . In general, when a function $\rho$ satisfies only $\text{(6)}$ , there is a fix : Find the smallest $K$ such that for all $k \ge K$ , $\rho(k)$ is odd. Then redefine the function by writing $\rho^{'}(k) = \rho(k) + 1$ for $k \ge K$ . Also, if $K$ has a predecessor, define $\rho^{'}(K-1) = \rho(K-1) + 1$ and retain the remaining $\rho$ definitions (if any) for $\rho^{'}$ . The new function $\rho^{'}$ satisfies both $\text{(6)}$ and $\text{(7)}$ . Example: $\rho = (-1,-1,-1,\dots)$ satisfies $\text{(6)}$ but not $\text{(7)}$ . Applying the fix, $\rho^{'} = (0,0,0,\dots)$ . Lemma 2: Let $\alpha$ and $\beta$ be two binary tick specifications. The smallest subset $[R(\alpha,\beta)]$ of $\Bbb N \times \Bbb Z$ containing the graph of $\alpha + \beta$ (pointwise addition) and satisfying $\text{(1)}$ thru $\text{(3)}$ also satisfies $\text{(4)}$ . If necessary we apply the fix to $\mathtt M([R(\alpha,\beta)])$ and define the addition of the two specifications, $$\tag 8  \alpha + \beta = \mathtt M([R(\alpha,\beta)])$$ giving another binary tick specification. Let $\Bbb B$ denote the set of all binary tick specifications with this binary operation $+$ . Theorem 3: The structure $(\Bbb B, +)$ is a commutative group. Moreover, it is isomorphic to $(\Bbb R, +)$ . Example: Pointwise addition of $\quad +\frac{1}{4} = (0,0,1,2,4,\dots)$ $\quad -\frac{1}{4} = (-1,-1,-1,-2,-4,\dots)$ gives $\quad \quad \;\, = (-1,-1,0,0,0,\dots)$ If this sum generates the r-locator $R$ , then $\mathtt M(R)$ returns $(0,0,0,0,0,\dots)$ , as expected. My Work I've been working through some of the theory details, but felt it would be beneficial to present these rough ideas now rather than attempting to supply complete proofs. Does this theory hold together? The motivation for this work came from the desire to find a model for Tarski's axiomatic formulation of the real numbers; see this . The exposition of the above theory is a direct route to the real numbers that does not require the construction of the rational numbers. Nor the definition of a limit or floor function. However, the following relations hold true: Every $\alpha$ specifies a real number $a$ as follows, $\quad a = {\displaystyle \lim _{n \to +\infty} \frac{\alpha(n)}{2^n}}$ The inverse mapping is given by $\quad \alpha(n) = \lfloor a 2^n \rfloor$","['real-numbers', 'binary', 'examples-counterexamples', 'real-analysis', 'group-theory']"
3361134,$GL_3(\mathbb{F}_2)$ is a simple group,"I'm trying to prove that $G := GL_3(\mathbb{F}_2)$ , the group of $3 \times 3$ matrices with entries in $\mathbb{F}_2$ is a simple group. The steps outlined for me look like: 1) Construct a list of representatives for the conjugacy classes of $G$ . 2) Compute the size of each of these conjugacy classes. 3) Show that $G$ is simple. I was able to solve step (1) using the fact that every matrix in $G$ is conjugate to a unique block matrix, where each of the blocks are companion matrices of a list of invariant factors. That is, for each matrix $A \in G$ there exists unique (up to associates) $\delta_1 \mid \cdots \mid \delta_n$ , $\delta_i \in \mathbb{F}_2[x]$ such that $A \sim $ diag(Com( $\delta_1$ ), $\ldots$ , Com( $\delta_n$ )). Using this fact I was able to construct the following list of representatives for conjugacy classes of matrices: $$
\begin{bmatrix} 
0 & 0 & 1\\
1 & 0 & 0 \\
0 & 1 & 0 
\end{bmatrix} , \begin{bmatrix} 
0 & 0 & 1\\
1 & 0 & 1 \\
0 & 1 & 0 
\end{bmatrix}, \begin{bmatrix} 
0 & 0 & 1\\
1 & 0 & 1 \\
0 & 1 & 1 
\end{bmatrix}, \begin{bmatrix} 
0 & 0 & 1\\
1 & 0 & 0 \\
0 & 1 & 1 
\end{bmatrix} , \begin{bmatrix} 
1 & 0 & 0\\
0 & 0 & 1 \\
0 & 1 & 0 
\end{bmatrix}, 
\begin{bmatrix} 
1 & 0 & 0\\
0 & 1 & 0 \\
0 & 0 & 1 
\end{bmatrix}
$$ I get a little stuck on part (2). I know the size of the conjugacy class of each of the above matrices is equal to the index of the centralizer. I could compute the centralizer of each of the above matrices directly and that would give me the answer but I'm a little hesitant to just multiply matrices for 10-15 minutes. This problem was on a practice qualifying exam so I suspect that there is a faster/more clever way to compute the sizes of these conjugacy classes. This is really what I want. One idea I have: Two matrices are conjugate if and only if they have the same list of invariant factors. For many of the matrices the list of invariant factors is a single degree 3 polynomial. In this case I know both the minimal polynomial and characteristic polynomial of any matrix conjugate to my representative. These observations do not seem to make the computation much faster though. I suspect that once I can do (2), (3) will follow relatively quickly.","['matrices', 'group-theory', 'abstract-algebra']"
3361169,Dual space of quotient of C$^*$-algebras,I'm interested in understanding what the dual space of a quotient of a $C^*$ -algebra $A$ looks like. Let $A$ denote a $C^*$ -algebra and $I$ a closed ideal therein. Denote the dual space of $A$ by $B$ . I think one can say something like: The dual space $B_I$ of the quotient $A/I$ is canonically isometrically isomorphic to a weak $^*$ closed subset of B. Is this true? Thank you very much!,"['c-star-algebras', 'banach-algebras', 'functional-analysis', 'operator-algebras']"
3361185,Finding the Eigenvectors,"Consider the matrix given below: $\begin{pmatrix}
1 & 1 \\
1 & 0
\end{pmatrix}.$ The eigenvalues for this matrix are $\dfrac{1+\sqrt 5}{2},\dfrac{1-\sqrt 5}{2}.$ I am facing trouble finding the eigenvectors. Please help.","['matrices', 'eigenvalues-eigenvectors']"
3361221,Estimating population size from capture recapture metho,"Given a population of unknown size, with k tagged individuals, we sample n of them and find m to be tagged. We would like an estimate for the size of the population N
If we assume equal likelyhood of capture throughout and constant population size, we can apply the Lincoln-Petersen method and estimate N using the ratio: $kn/m$ , I would like to formally derive this ratio by maximizing the discrete probability function of tagged indvidualsin the sample. i.e. find N such that the probability of having m tagged individuals in our sample of size n is maximized. We know that P(m out of n individuals are tagged)= ${k\choose m}{N-k\choose n-n}/{N\choose n}$ .
I would like to show that the ratio 𝑘𝑛/𝑚 is the value of N that maximizes this function but I/m getting stuck in the computation.","['statistics', 'probability', 'sampling']"
3361224,Showing that a dense subspace $Y$ of a first countable separable topological space is separable,"Show that a dense subspace $Y$ of a first countable separable topological space $X$ is separable. Proof: $X$ is separable.
Let $S=\{x_n \in X | n \in \mathbb{N}\}$ be a countable dense subset of $X$ . $Y$ is also dense in $X$ . Because $X$ is first-countable, thus for each $x_n$ where $n \in \mathbb{N}$ there exists a countable local-basis around $x_n$ .
Let the countable local-basis around $x_n$ be $S_n=\{\text{ }B_n^k \text{ } | \text{ }k \in \mathbb{N} \}$ Because $Y$ is dense in $X$ thus for each $x_n$ where $ n=1,2,3 \dots $ and for each $B_n^k$ where $k=1,2,3,4 \dots$ , we have $Y \cap B_n^k \neq \phi$ . Say $y_n^k \in Y \cap B_n^k \neq \phi$ Denote $Z=\{ y_n^k \in Y \text{ } | \text{ } n,k \in \mathbb{N} \}$ Claim: $Z$ is a countable dense set of $Y$ . Choose $y \in Y$ and any open set $V$ in $Y$ containing y. $V$ is open in $Y$ implies that $V=U \cap Y$ where $U$ is an open set in $X$ . Thus $y \in U \in \tau$ and $y \in Y$ $y \in U$ and $U$ is open in X. Because $S$ is dense in X, we have that $U \cap S \neq \phi $ . Let $x_n \in U \cap S$ , Thus $x_n \in U$ and $U$ is open in $X$ . Considering that $S_n$ is a countable local-basis around $x_n$ we have an element $B_n^{k_0}$ such that $x_n \in B_n^{k_0} \subset U$ . choose the corresponding $y_n^{k_0}$ as done in the construction above. Then we have $y_n^{k_0} \in B_n^{k_0} \subset U$ . Thus $y_n^{k_0} \in U \cap Y = V$ and hence $V \cap Z \neq \phi$ as it contains $y_n^{k_0}$ . Hence $Y$ has a countable dense subset. $Y$ is separable. Hence proved! Please check my solution. I need to correct my mistakes and learn.
Thank You.","['general-topology', 'proof-verification']"
3361248,Proving a stochastic process is almost surely continuous.,"Let $f:[0,\infty) \times\mathbb{R}$ be  bounded and continuous. If we let $(X_t)$ be an adapted process such that $X_0=0$ and $X_t = \int_0^tf(s,X_s)ds \forall t \geq 0$ Show that $X_t$ is almost surely continuous. We know that almost surely continuous means $ P(X_n \to X)=1 $ iff $$ \lim_{n \to \infty}P(\sup_{m \ge n} |X_m -X|>\epsilon) \to 0  $$ I feel like this would not be true. Counter example: Take f to be the constant function f = 1. Then $X_t = \int_0^t1ds = t$ and the limit X= $\infty$ So $$ \lim_{n \to \infty}P(\sup_{t \ge n} |X_t -X|>\epsilon)  $$ $$ =\lim_{n \to \infty}P(\sup_{t \ge n} |t -\infty|>\epsilon) $$ $$ =\lim_{n \to \infty}P(\infty>\epsilon) =1$$ So why is $X_t$ almost surely continuous and what is wrong with my counter example?","['statistics', 'stochastic-processes', 'limits', 'probability-theory', 'probability']"
3361326,Prove the irreducibility of a polynomial,"Let $p(x) = x^2 + ax + b$ a polynomial with $a,b\in\Bbb Z$ odd integers. Prove that $p$ is irreducible at $\Bbb Z[X]$ , and at $\Bbb Q[X]$ . I know the Eisenstein's criterion but I'm not sure about how to apply it.",['abstract-algebra']
3361329,A sort of AM-GM inequality for matrices,"Let $A, B$ be symmetric, positive definite matrices. Is it true that $$
tr \left( (A B^2 A)^{1/2}\right) \leq \frac{1}{4} \| A + B\|_F^2?
$$ In the diagonal case, the left-hand side is $tr(AB)$ and,
denoting by $\lambda_i$ and $\mu_i$ the diagonal elements of $A$ and $B$ , the inequality follows from the usual AM-GM inequality: $$
tr(AB) =\sum_i \mu_i \lambda_i \leq \frac{1}{4} \sum_i (\mu_i + \lambda_i)^2 = \frac 14 \| A + B\|_F^2.
$$ To convince ourselves that the inequality is true,
we can run the following python code, which prints 0.99999375. import numpy as np
import scipy.linalg as la

n, d, ratios = 100000, 3, []
for i in range(n):
    A = np.random.randn(d, d)
    B = np.random.randn(d, d)
    A, B = A.dot(A.T), B.dot(B.T)
    lhs = np.matrix.trace(la.sqrtm(A.dot(B).dot(B).dot(A)))
    rhs = (1/4)*la.norm(A + B, ord='fro')**2
    ratios.append(lhs/rhs)

print(np.max(ratios)) After a little literature search,
it seems that a slightly modified version of the inequality,
with a factor $1/2$ instead of $1/4$ in the right-hand side,
is a consequence of Theorem IX.4.2 in the textbook Matrix Analysis by Rajendra Bhatia. Statement of Theorem IX.4.2: for any two matrices, $$s_j(A^*B) \leq \frac{1}{2} \, s_j(AA^* + BB^*),$$ where $s_j$ , $j = 1, \dots, n$ , denotes the $j$ -th singular value. Proof that this partially answers the question: we can rewrite the left-hand side as $$
GM(A, B) := tr \left( (A B^2 A)^{1/2}\right) = tr \left(\left((BA)^*BA\right)^{1/2} \right) = \sum_j s_j(BA).
$$ Using the quoted result, we therefore obtain \begin{align}
GM(A, B) &\leq \frac{1}{2} \sum_j s_j(A^2 + B^2) = \frac{1}{2} tr(A^2 + B^2) \\
&= \frac 14 tr((A + B)^2 + (A - B)^2) \\
&= \frac 14 tr(A + B)^2 + \frac{1}{4} tr(A - B)^2 \\
&= \frac 14 \|A + B\|_F^2 + \frac 14 \|A - B\|_F^2 \\
&\leq \frac 12 \|A + B\|_F^2 =: 2 \, AM(A, B).
\end{align} Let us note that numerical experiments show that
the inequality $$
\frac{1}{2} \sum_j s_j(A^2 + B^2) \leq 2 \, AM(A, B),
$$ is sharp.","['matrices', 'a.m.-g.m.-inequality']"
3361382,Bertini's theorem for singular varieties over an algebraically closed field,"Let $k$ be an algebraically closed field (of arbitrary characteristic), $X$ a projective $k$ -variety (= integral projective $k$ -scheme) and $f: X \to P := \mathbb{P}_k^n$ a closed immersion.
  (And identify the set of hyperplanes of $P$ with $P' := \mathbb{P}_k^n(k)$ ) Then for almost all hyperplanes $H$ in $P$ , $X \not\subseteq H$ and $H \cap X$ is irreducible. (""almost all"" means ""there exists an open subset $U$ of $P'$ and for all $H \in U(k)$ "".) I know this is theorem 6.3 of Jouanolou's ""Theoremes de Bertini et applications"". But its proof is very difficult for me because it is too long, too general and written in French... The author shows it under the hypothesis that $k$ is arbitrary infinite field, $X$ is just a geometrically irreducible $k$ -shceme and $f$ is just a $k$ -morphism. So I'm glad if there are some short proofs of Bertini in my situation. If it becomes easier, I'm willing to restrict the hypothesis to normal $X$ . This statement is very common (e.g., is used in Mumford's Abelian varieies), but I don't know any good scheme-theoritic proofs. I have tried it by mimicking the proof of Hartshorne.
However its proof hevily relies on the regularity of $X$ , and so I couldn't. So my question is: Would you show Bertini under the highlighted hypothesis?
Or would you give some references which include a short proof of Bertini? Thank you very much!",['algebraic-geometry']
3361451,"$\forall x\in \mathbb{R} \exists b\in (x, x+a) \frac{f'(x) } {f(x) }=e^{a{f'(b) }/{f(b) } }$","Let $a\ge 0$ and $f:\mathbb{R}\rightarrow  \mathbb{R}$ be a differentiable positive function such that $f'(x) =f(x+a) \forall x\in \mathbb{R}$ . How can I prove that $\forall x\in \mathbb{R} \exists b\in (x, a+x) \frac{f'(x) } {f(x) }=e^{a\frac{f'(b) }{f(b) } }$ . I tried the intermediate value Theorem but couldn't prove it. Thank you in advance for your help.","['continuity', 'derivatives', 'real-analysis']"
3361458,How to determine if these sets involving rationals are countable?,"I am wondering whether the set of polynomial functions from $\mathbb{Q} \to \mathbb{Q}$ is countable, whether the set of maps from $\mathbb{Q} \to \mathbb{Q}$ with finite image is countable, and whether the set of finite subsets of $\mathbb{Q}$ is countable. For the first question, I tried to approach the problem by considering that there are only finitely many orders of polynomials (the integers), but got tripped up once I had to consider coefficients. In general, I feel like there is an easier way to determine this than I am envisioning at the moment and would appreciate any help.",['elementary-set-theory']
3361483,Computing $\underset{x\rightarrow0}{\lim}\big(a^{x}+b^{x}-c^{x}\big)^\frac{1}{x}$,"A friend asked me to help him with calculating a certain hideous limit: $$\underset{x\rightarrow0}{\lim}\big(a^{x}+b^{x}-c^{x}\big)^\frac{1}{x},\space\space0<a,b,c\in\mathbb{R}$$ I came up with a solution (and wolfram alpha confirmed), but unfortunately it involves a lot of steps and a couple of theorems and identities so we're actually reaching out hoping someone can come up with a better solution. Hopefully a more intuitive one! Here's what I had in mind: $$\underset{x\rightarrow0}{\lim}\big(a^{x}+b^{x}-c^{x}\big)^\frac{1}{x}=\underset{x\rightarrow0}{\lim}e^{\ln{\big((a^{x}+b^{x}-c^{x})^\frac{1}{x}\big)}}=\underset{x\rightarrow0}{\lim}e^\frac{\ln{\big(a^{x}+b^{x}-c^{x}\big)}}{x}$$ Since $e^x$ is continuous and therefore we have: $$\underset{x\rightarrow{x_0}}{\lim}e^{f(x)}=e^{\underset{x\rightarrow{x_0}}{\lim}f(x)}$$ So we focus on finding: $$\underset{x\rightarrow0}{\lim}\frac{\ln{\big(a^{x}+b^{x}-c^{x}\big)}}{x}$$ Suppose it is equal to some $L$ , then our original limit will be equal to $e^L$ . We now note that: $$\underset{x\rightarrow0}{\lim}x=0\space,\space \underset{x\rightarrow0}{\lim}\ln{\big(a^{x}+b^{x}-c^{x}\big)}=\ln{(a^0+b^0-c^0)}=\ln{(1+1-1)}=\ln(1)=0$$ So our limit takes the indeterminate form $""\frac{0}{0}""$ . After checking all the conditions are satisfied we proceed with L'Hospital setting $g(x)=x$ and $f(x)=\ln{\big(a^{x}+b^{x}-c^{x}\big)}$ , and get the following: (oh boy this is going to be an ugly) $$\underset{x\rightarrow0}{\lim}\frac{f(x)}{g(x)}=\underset{x\rightarrow0}{\lim}\frac{f'(x)}{g'(x)}=\underset{x\rightarrow0}{\lim}\frac{\frac{a^{x}\ln{(a)}+b^{x}\ln{(b)}-c^{x}\ln{(c)}}{a^{x}+b^{x}-c^{x}}}{1}=\ln{(a)}+\ln{(b)}-\ln{(c )}=\ln{\big(\frac{ab}{c}\big)}$$ (Again, the computation was straightforward because $\ln$ is continuous and the limit of composition of functions). So we finally get: $$\underset{x\rightarrow0}{\lim}\big(a^{x}+b^{x}-c^{x}\big)^\frac{1}{x}=\underset{x\rightarrow0}{\lim}e^\frac{\ln{\big(a^{x}+b^{x}-c^{x}\big)}}{x}=e^{\ln{(\frac{ab}{c})}}=\frac{ab}{c}$$ And that's  it! As you can see it's not that intuitive, and it involves a lot of computation and some theorems and identities and as a result- many steps. 
I would appreciate in other insight regrading formality and other perspectives on calculating this limit. Thank you","['limits', 'calculus']"
3361492,Is the composite of two simple radical extensions another simple radical extension?,"I encountered this (fact? Maybe I misunderstood) in a proof of a lemma in Dummit and Foote where the authors state something which (I think) implies this without proof, namely that the composition of two root extensions is another one. If what they state doesn't require that the composition of two simple radical extensions be another one, please explain why. I tried doing this in various ways, but (as the answer below suggests) this may not even be true. If so, there must be something wrong with my understanding or a way to avoid running into this supposed requirement. They also didn't prove the statement that the composite of all fields $\sigma{K}$ for $\sigma\in Aut(L/F)$ is precisely $L$ (the Galois closure) and here's my attempt to prove it with $K$ an arbitrary extension of $F$ . Denote the composite of all such fields by $E$ and consider the action of any $\tau\in Aut(L/F)$ on it. We see that any such $\tau$ sends $E$ into itself (see the edit below). And so, any $\sigma\in Aut(L/F)$ is an automorphism of the field $E$ fixing $F$ , But the number of embeddings $N$ of $E$ into an algebraic closure which contains $L$ that fix $F$ is the order of the set of cosets $\left|Aut\left(L/F\right)\right|/\left|Aut\left(L/E\right)\right|$ by the fundamental theorem.
Combining these results we get, $$\frac{\left|Aut\left(L/F\right)\right|}{\left|Aut\left(L/E\right)\right|}\ge\left|Aut\left(E/F\right)\right|\ge\left|Aut\left(L/F\right)\right|$$ which (since $L/E$ is galois) leads to $$\left|Aut\left(L/E\right)\right|=\left[L:E\right]=1$$ Is this correct? Edit: Let $B_i=\left\{b_{i,1},b_{i,2},...b_{i,m}\right\}$ denote any set of elements that span $\sigma_iK$ over $F$ . Define $P=\left\{p_1,p_2,...p_s\right\}$ to be the set of all possible products of elements $b_{i,r}$ in the union $B_1 \cup B_2 \cup ...B_q$ . The set $P$ spans $E$ over $F$ . So, for arbitrary $\alpha \in E$ we have $$\alpha=\sum_{j=0}^sa_jp_j                          $$ $a_j \in F$ applying some $\tau \in Aut(L/F)$ and noting that $\tau$ fixes the $a_j$ 's, we get $$\tau\left(\alpha\right)=\sum_{j=0}^sa_j\tau\left(p_j\right)$$ Each $p_j$ is a product of $b$ 's in the union above and each $b_{i,r}$ is in some $\sigma_{i}K$ so $\tau$ sends it to an element of $\tau\sigma_{i}K$ which is an element of $E$ by definition. So, the image of a product of any number of $b$ 's will still be in $E$ since all the images are in $E$ . So, the image of $p_j$ is some $\beta$ again in $E$ which may or may not be in $P$ , but this doesn't matter since $\tau\left(\alpha\right)$ is in $E$ anyway and we started with an arbitrary $\alpha$ . Noting that $\tau$ can't send two elements to the same element since it's an automorphism of the larger field $L$ , I conclude that any such $\tau$ is an automorphism of $E$ fixing $F$ .","['proof-verification', 'field-theory', 'galois-theory', 'abstract-algebra', 'extension-field']"
3361524,How do I find all complex numbers that are solutions of $z^3 +8i=0$?,"My workbook has answers in the standard form $a+bi$ . I would assume that to solve this, I would expand the complex number $z$ into trigonometric form to deal with that exponent. This is what I have so far using De Moivre's Theorem: $(r^3(\cos(3\theta)+i\sin(3\theta)) +8i=0$ . However, I do not know where to go from here. Thank you!","['algebra-precalculus', 'complex-numbers']"
3361526,What's the sum of the reciprocals of the numbers that can be written as the sum of two positive cubes?,"A very specific question: What's the sum of the reciprocals of the numbers that can be written as the sum of two positive cubes ( Oeis: A003325 )? $$\begin{align}
&\sum_{n=1}^\infty \frac{1}{A003325(n)} \\
& =\frac{1}{1^3+1^2}+\frac{1}{1^3+2^3}+\frac{1}{2^3+2^3}+\frac{1}{1^3+3^3}+\frac{1}{2^3+3^3}+\frac{1}{3^3+3^3}+\frac{1}{1^3+4^3}+\dots \\
& = \frac{1}{2}+\frac{1}{9}+\frac{1}{16}+\frac{1}{28}+\frac{1}{35}+\frac{1}{54}+\frac{1}{65}+\frac{1}{72}+\frac{1}{91}+\dots
\end{align} $$ Some notation to organize my thinking: Let $S\subset \mathbb{N}$ and let $1_{S}(x)=\cases{1 \mbox{ when }{x\in S }\\0 \mbox{ when } x\notin S}$ And define $m(S)=\sum_{n=1}^\infty \frac{1_S(n)}{n}$ . This would be the sum of the reciprocals of $S$ . $S_{a,b}=\{n\in \mathbb{N}: \exists \vec{x} \in\mathbb{N^{a}}, \sum_{i=1}^a |x_i|^b=n \}$ .  This is the set of numbers that can be written as sum of $a$ positive numbers raised to the fixed power $b$ . Some immediate results of this notation. And some examples. $m(S_{1,k})=\zeta(k)$ and $m(S_{4,2})$ is a divergent sum because $S_{4,2}=\mathbb{N}$ . My question above is asking for $m(S_{2,3})$ . And somewhat more broadly I am asking: Can we get a handle on the density of this set? Why should we have any chances of answering this? As we can read here , here , here and here . The first two links are MSE questions and the latter two are publications by Kevin A. Broughan. $$n\in S_{2,3} \iff \exists m \mid n ,\quad n^{1/3} \leq m \leq 4^{1/3} n^{1/3} \mbox{ s.t. }\\ ( m^{2} - \frac{n}{m})=3l \mbox{ and }(m^{2} - 4l) \mbox{ is a perfect square. }$$ So because we have this nice characterization I was curious if this number could possibly be expressed in relationship to other well-known constants like value of the zeta function. Note that the related question:
  What's the sum of the reciprocals of the numbers that can be written as the sum of two non-negative cubes? But we can see that this question is just $\zeta(3)$ away from the title question. That is, $$m(\{n:(x,y)\in \mathbb{N_0^2}: n=x^3+y^3 \})=m(S_{2,3})+\zeta(3)$$ Here is what I know so far $m(S_{2,3}) \approx 	0.9777693455 =\sum_{n=1}^{20000} \frac{1}{A003325(n)}$ . Can anyone provide any more insight into what this number is? Apologies Note that in the original version of this I made a typo and wrote $S_{a,b}=\{n\in \mathbb{N}: \exists \vec{x} \in\mathbb{Z^{a}}, \sum_{i=1}^a |x_i|^b=n \}$ this isn't quite what I wanted to type here.","['number-theory', 'real-analysis', 'combinatorics', 'sequences-and-series', 'zeta-functions']"
3361553,Hoeffding's lemma: hard to prove,"This is a continuation of another post . Let $F$ be the joint distribution function and $F_X,F_Y$ the marginal distribution function of the random variables $X,Y$ respectively. Let $(X,Y), (X_2,Y_2)$ be independent and distributed according to $F$ . Assume $E\mid XY\mid, E\mid X \mid, E\mid Y \mid$ finite. Then \begin{align}
&E\bigg\{\int\int\Big[I(X\leq x)-I(X_2\leq x)\Big]\Big[I(Y\leq y)-I(Y_2\leq y)\Big]dxdy\bigg\}\\
&=2\int\int F_{X,Y}(x,y)-F_X(x)F_Y(y)dxdy
\end{align} where $I$ is the indicator function. My attempt There are two challenging steps for me. Firstly, I think I have to show that I can put the expectation inside the integrals using Fubini-Tonelli's theorem. Unfortunately I'm struggling to deal with it. Well, I know that the integrand is a (measurable) function of the random variables $X,Y,X_2$ and $Y_2$ . So I saw the $L.H.S.$ of the above equality as $$\int_{\mathbb{R}^4}\int\int\Big[I(x_1\leq x)-I(x_2\leq x)\Big]\Big[I(y_1\leq y)-I(y_2\leq y)\Big]dxdy P_{X,Y,X_2,Y_2}(dx_1dy_1dx_2dy_2)$$ I don't know if this allows me to interchange the integrals to obtain \begin{align}
&\int\int\ E\bigg\{\Big[I(X\leq x)-I(X_2\leq x)\Big]\Big[I(Y\leq y)-I(Y_2\leq y)\Big]\bigg\}dxdy\\
\end{align} If everything is alright so far, then I need to show that $E\bigg\{\Big[I(X\leq x)-I(X_2\leq x)\Big]\Big[I(Y\leq y)-I(Y_2\leq y)\Big]\bigg\}=2Cov(I(X\leq x),I(Y\leq y))$ , and the rest becomes straighforward to me. Thus I need to show (i) the independence of $I(X_2\leq x)\perp I(Y\leq y)$ and $I(X\leq x)\perp I(Y_2\leq y)$ given $X_2\perp Y$ and $X\perp Y_2$ ; and (ii) $E(I(Y\leq y))=E(I(Y_2\leq y))$ which is easy, and that $Cov(I(X\leq x),I(Y\leq y))=Cov(I(X_2\leq x),I(Y_2\leq y))$ . I wonder if you can help me with it. UPDATE Since $X$ is independent of $Y_2$ , by definition, $\sigma(X)=\{X^{-1}(B):B\in \mathcal{B}_\mathbb{R}\}$ and $\sigma(Y_2)$ are independent, meaning that $P(A\cap B)=P(A)P(B), \ \forall A\in \sigma(Y_2), B\in \sigma(X)$ . Since $f=I_{(-\infty,x]}$ and $g=I_{(-\infty,y]}$ are $(\mathbb{R},\mathcal{B}_\mathbb{R})-(\mathbb{R},\mathcal{B}_\mathbb{R})$ measurable functions, then $(f\circ X)^{-1}=X^{-1}(f^{-1}(A))\in \sigma(X), \forall A\in \mathcal{B}_\mathbb{R}$ . The same holds for $g\circ Y_2$ . It implies $\sigma(f\circ X)\subseteq \sigma(X)$ and $\sigma(g\circ Y_2)\subseteq \sigma(Y_2)$ . Hence $\sigma(f\circ X)$ and $\sigma(g\circ Y_2)$ are also independent. That is the indicator functions (measurable) preserve the independence of the random variables. Exploring one of the answers below, let $f,b:\mathbb{R}\rightarrow\mathbb{R}$ measurable functions (like the indicator functions I am interested in). Then $F_{f\circ X, g\circ Y}(x_1,y_1)=P\{f(X)\leq x_1, g(Y)\leq y_1\}=P(X\in f^{-1}(-\infty,x_1], Y\in g^{-1}(-\infty,y_1])=P_{XY}(f^{-1}(-\infty,x_1]\times g^{-1}(-\infty,y_1])=P_{X_2Y_2}(f^{-1}(-\infty,x_1]\times g^{-1}(-\infty,y_1])=F_{f\circ X_2, g\circ Y_2}(x_1,y_1)$ . This immediately implies $Cov(f\circ X_2, g\circ Y_2)=Cov(f\circ X, g\circ Y)$ . Just put $f=I_{(-\infty,x]}$ and $g=I_{(-\infty,y]}$ . Finally, it is clear that the marginal probability distributions must be the same ( $P_X=P_{X_2}$ ), by assumption. Therefore, $E(f\circ X)=\int_{\Omega} (f\circ X)(z) P(dz)=\int_{\mathbb{R}} f(w) P_X(dw)=\int_{\mathbb{R}} f(w) P_{X_2}(dw)=E(f\circ X_2)$ , since $f$ is nonnegative measurable function (the indicator function)[see the Corollary 5.5.1, Resnick, A probability path, p. 138].","['self-learning', 'measure-theory']"
3361568,Generalized Inverse Distribution Function is right continuous,"I am given the problem, For a distribution function $F$ , we define $F^{-1}: [0,1] \to \mathbb{R}$ , where $F^{-1}(x)=\inf \{y \in \mathbb{R}: F(y) \geq x\}$ . Show $F^{-1}$ is right-continuous. I know $F: \mathbb{R} \to [0,1]$ is a right-continuous, non-decreasing function s.t. $\lim_{x \to \infty}F(x)=1$ and $\lim_{x \to -\infty}F(x)=0$ . To show right-continuous, I want that $\lim_{y \downarrow x}F^{-1}(y)=F^{-1}(x).$","['probability-distributions', 'probability-theory']"
3361579,Integrate $\int{\frac{x^2-1}{x^4+3x^3+5x^2+3x+1}}dx$,"The answer of this integral $$\int{\frac{x^2-1}{x^4+3x^3+5x^2+3x+1}}dx$$ is $$\frac{2}{\sqrt{3}}\arctan\left[\frac{2}{\sqrt{3}}(x+\frac{1}{x})+\sqrt{3}\right]+C$$ But, I couldn’t figure out how I would solve it. I tried to use partial fraction, but the denominator $$x^4+3x^3+5x^2+3x+1$$ can't be easily factored. I also tried to use WolframAlpha to solve it, but it can't give a useful answer for this integral.","['integration', 'indefinite-integrals']"
3361589,Proof that $\sum\limits_{n=1}^{\infty}{(-1)^{n+1}\sin(n)\over{n}}={1\over2}$,"While messing around with WolframAlpha, I came across this identity that ${\sin{1}\over{1}}-{\sin{2}\over{2}}+{\sin{3}\over{3}}-{\sin{4}\over{4}}+{\sin{5}\over{5}}\cdots={1\over{2}}$ . One would perhaps expect such a seemingly simple identity to have a clean / intuitive proof, however after I have had trouble finding one while looking around online. What is the simplest/ most intuitive way to prove this?","['trigonometry', 'sequences-and-series']"
3361614,How many permutations of the letters A to H if the three letters ABC must appear together but not necessarily consecutively?,"How many permutations of the letters A to H exist if the three letters ABC must appear together but not necessarily consecutively? Pretty confused on how to start... 
Can I group ABC as one letter? Then there will be 6 ""letters"", making it 6!, and then multiplied by 3! because there are 3! ways in which ABC can be assigned.","['permutations', 'proof-verification', 'combinatorics']"
3361615,Good typesetting software for linear algebra?,"I have broken my dominant hand, leaving me unable to write. Thus far, I have been using LaTeX, but have been disappointed by how long it takes to display matrices, format, etc. Does anyone know of a linear algebra specific typesetting software?","['linear-algebra', 'math-software']"
3361618,Sequences where $\sum\limits_{n=k}^{\infty}{a_n}=\sum\limits_{n=k}^{\infty}{a_n^2}$,"I was recently looking at the series $\sum_{n=1}^{\infty}{\sin{n}\over{n}}$ , for which the value quite cleanly comes out to be ${1\over2}(\pi-1)$ , which is a rather cool closed form. I then wondered what would happen to the value of the series if all the terms in the series were squared. Turns out... nothing happens! $\displaystyle\sum_{n=1}^{\infty}{\left({\sin{n}\over{n}}\right)}^2=\sum_{n=1}^{\infty}{\sin{n}\over{n}}={1\over2}(\pi-1)$ . This is a rather cool result, and I was wondering if there are any other simple series that share this property? Or, more generalized, series for which raising the terms to the power $m$ yields the same result as raising them to the power $p$ .","['sums-of-squares', 'trigonometry', 'square-numbers', 'sequences-and-series']"
3361631,Bound on operator norm of block matrices,"Let $A\in\mathbb{R}^{m\times n}$ be a block matrix which is partitioned into submatrices $A_{ij} \in \mathbb{R}^{m_i\times n_j}$ .  Let $\|\cdot\|_{p\times q}$ denote the spectral (operator) norm on $p\times q$ matrices. Is it true that $$\|A\|_{m\times n} \leq \sum_{i,j}\|A_{ij}\|_{m_i \times n_i}\:?$$","['spectral-norm', 'matrices', 'linear-algebra', 'inequality', 'block-matrices']"
3361638,Prove that $\exists c>0$ s.t $\sum_{n\geq x}\frac{1}{n^2}\leq \frac{c}{x}$ [duplicate],"This question already has answers here : Prove that there exists a constant $c>0$ such that the following happens (2 answers) Closed 4 years ago . $\mathbf{Question:}$ Prove that there exists a constant $c>0$ such that for all $x \in [1, \infty)$ , $\displaystyle\sum_{n \geq x}\frac{1}{n^2} \leq \frac{c}{x}$ $\mathbf{Attempt:}$ Evidently, $\displaystyle\bigg[\displaystyle\sum_{n =1}^\infty\frac{1}{n^2}-\sum_{j=1}^{\lfloor x \rfloor} \frac{1}{j^2}\bigg]{\lfloor x \rfloor}\leq x\displaystyle\sum_{n \geq x}\frac{1}{n^2} \leq \displaystyle\bigg[\sum_{n =1}^\infty\frac{1}{n^2}-\sum_{j=1}^{\lfloor x \rfloor} \frac{1}{j^2}\bigg]{\lceil x \rceil} $ . This inequality arises since, $\displaystyle\bigg[\sum_{n =1}^\infty\frac{1}{n^2}-\sum_{j=1}^{\lfloor x \rfloor} \frac{1}{j^2}\bigg]=\displaystyle\sum_{n \geq x}\frac{1}{n^2}$ . Now, let $\lfloor x\rfloor=m$ $\displaystyle\lim_{m \to \infty}\bigg[\sum_{n =1}^\infty\frac{1}{n^2}-\sum_{j=1}^m \frac{1}{j^2}\bigg]m$ $=\lim_{{m \to \infty},{r\to \infty}}\bigg[\frac{m}{(m+1)^2}+\frac{m}{(m+2)^2}+\frac{m}{(m+3)^2}+...+\frac{m}{(m+r)^2}+...\bigg]=$ $\lim_{{h \to 0},{r\to \infty}}h\bigg[\frac{1}{(1+h)^2}+\frac{1}{(1+2h)^2}+\frac{1}{(1+3h)^2}+...+\frac{1}{(1+rh)^2}+...\bigg]=\displaystyle\int_{x=0}^\infty\frac{1}{(1+x)^2}dx=1$ We have, $\lceil x\rceil=m+1$ and $\displaystyle\lim_{m \to \infty}\bigg[\sum_{n =1}^\infty\frac{1}{n^2}-\sum_{j=1}^m \frac{1}{j^2}\bigg](m+1)=\lim_{m \to \infty}\bigg[\sum_{n =1}^\infty\frac{1}{n^2}-\sum_{j=1}^m \frac{1}{j^2}\bigg]m$ Thereby, we conclude, $\displaystyle \lim_{x\to \infty}x\sum_{n \geq x}\frac{1}{n^2}=1 $ . Therefore, from the definition of limit, $\forall \varepsilon>0$ , $\exists G>0$ such that $\bigg|x\displaystyle\sum_{n \geq x}\frac{1}{n^2}-1\bigg|<\varepsilon$ $\forall x>G$ . Choosing $\varepsilon =1$ , we get $G=G_0$ such that $x\displaystyle\sum_{n \geq x}\frac{1}{n^2}<2$ , for any $x> G_0$ . We set $\displaystyle c=\max\bigg\{2, \sup_{x\in [1,G_0]}x\sum_{n \geq x}\frac{1}{n^2} \bigg\}$ Is this procedure valid? Kindly verify.","['ceiling-and-floor-functions', 'improper-integrals', 'proof-verification', 'real-analysis', 'sequences-and-series']"
3361681,Equality of subsheaves on stalks implies equality of subsheaves,"My question is in context of Sheaves with the same stalks are not necessarily isomorphic another question posted earlier. Why is it true that given two subsheaves F and F’ of a sheaf G on a topological space X, $F_p = F’_p$ for any p in X implies $F = F’$ . I want to understand this rigorously using the definitions as I’m still trying to get used to the language of stalks and sheaves. I tried proving this as follows: Assume $F_p = F’_p$ . We will show F(U) $\subseteq$ F’(U) for any U $\subseteq$ X open. Let s $\in$ F(U)
Then given any p in X, consider the germ  of s in $F_p$ . Now since $F_p = F’_p$ , we have that $\in F’_p$ and so by definition of $F’_p$ we get that s is in F’(U) (where F’ $_p = \{<U,s_u> \textrm{s.t } p \in U \subseteq X \textrm{open and } s \in F’(U)\}$ modulo the standard equivalence relation) Thus F(U) $\subseteq$ F’(U) and the other inclusion follows similarly. This seems incorrect to me because as far as I understand, I haven’t used the condition that F and F’ are subsheaves of the same sheaf. The statement clearly doesn’t hold for any arbitrary sheaves F and F’. So my first question is about what is wrong with this argument and what would be a correct proof for this? Additionally, my second question/concern is that I don’t fully understand in what sense the stalks are ‘equal’, since viewing  in F $_p$ versus  in F’ $_p$ should technically be different objects since the restriction maps in F don’t need to be compatible with the restriction maps in F’.","['algebraic-geometry', 'sheaf-theory']"
3361768,How to find the probability that we need to weigh at least 20 eggs before we find the 12th medium-sized egg,"The mass of eggs in a farm is normally distributed with a mean of $575~\text{g}$ and standard deviation of $80~\text{g}$ . (a) An egg can be classified as having a “medium size” if its mass is between $500$ and $600$ grams. What is the probability that a randomly selected egg from the farm is a medium-sized egg? Use R to find the answer. (b) Let $M$ be the count of medium-sized eggs in a random sample of $100$ . What is the distribution of $M$ ? Using R, find the probability that at least half of the $100$ eggs are medium-sized. (c) Eggs from this farm are sold by the dozen (12 eggs). Let $D$ be the number of randomly selected eggs we must weigh until we find the 12th medium-sized egg. What is the distribution of $D$ ? Using R, find the probability that we need to weigh at least 20 eggs before we find the 12th medium-sized egg My attempt using Rstudio for a and b p <- pnorm(600,575,80)-pnorm(500,575,80) p [1] 0.448419 sum(dbinom(50:100, 50, p)) [1] 3.838845e-18 Now for part c do you use the part b and change 50 to 12 to find the distribution and then somehow find the probability using that to find the second part of part c? $$EDIT$$ Possible answer to part C, by $$P(X=10) = {20-1 \choose 12-1}0.0448419^{12}(1-0.044819)^{20-12}$$ Thoughts?","['statistics', 'probability']"
3361783,Prove Process is Markov Chain Using Markov Property,"Let $A_n$ be a Markov chain $(\lambda,P)$ on a state space $I$ , with stationary distribution $\pi$ . Let $B_n$ be a Markov $(\pi,P)$ chain, and independent of $A_n$ on the same state space $I$ . Prove $C_{n}=(A_{n},B_{n})$ is a Markov chain on $I \times I$ . Proof:
Here's my attempt anyway:
Proof: First note that if $c_{n} \in C_{n}$ , then $c_{n}=(a_{n},b_{n})$ , where $a_n \in A_{n}$ and $b_{n} \in B_{n}$ . $$
P(C_{n+1}=c_{n+1} \mid C_{0}=c_{0},..C_{n}=c_{n})
$$ Rewriting: \begin{align*}
&P((A_{n+1},B_{n+1})=(a_{n+1}, b_{n+1})\mid (A_0, B_0)=(a_0,b_0),..(A_{n},B_{n})=(a_n,b_n))\\
&=P(A_{n+1}=a_{n+1}, B_{n+1}=b_{n+1} \mid A_{0}=a_{0},..A_{n}=a_n, B_{0}=b_{0},..B_{n}=b_{n})\\
&=P(A_{n+1}=a_{n+1} \mid A_{0}=a_{0},...A_{n}=a_n) \cdot P(B_{n+1}=b_{n+1} | B_{0}=b_{0},...B_{n}=b_n)\\
&=P(A_{n+1}=a_{n+1} \mid A_{n}=a_{n}) \cdot P(B_{n+1}=b_{n+1} \mid B_{n}=b_{n})\\
&=P(A_{n+1}=a_{n+1}, B_{n+1}=b_{n+1} \mid A_{n}=a_{n}, B_{n}=b_{n})\\
&=P((A_{n+1},B_{n+1})=(a_{n+1},b_{n+1}) \mid (A_{n}, B_{n})=(a_{n},b_{n}))\\
&=P(C_{n+1}=c_{n+1} \mid C_{n}=c_{n})
\end{align*} Hence is a Markov chain. I'm not sure if $\textbf{second equals sign}$ and the $\textbf{fourth equals sign}$ is correct? i.e.: Can I say $P(A \cap B \mid C \cap D)=P(A \mid C) \cdot P(B \mid D)$ ? by independence?","['statistics', 'markov-chains', 'stochastic-processes', 'probability-theory', 'probability']"
3361835,Are linear transformations precisely those that keep lines straight and the origin fixed?,"It's easy to show that given a linear transformation $T:\mathbb{R}^n \rightarrow \mathbb{R}^m$ lines are mapped to lines and the origin stays fixed (as long as its rank $=n$ ). Yet is the converse true? More precisely, if $T:\mathbb{R}^n \rightarrow \mathbb{R}^m$ is a function that maps lines to lines in the sense that for any pair of vectors $a, b$ there exists vectors $c, d$ such that $T(a+tb)=c+td$ & $T(0)=0$ can we deduce that $T(x+y)=T(x)+T(y)$ for all vectors $x, y$ ? Would appreciate any help.","['proof-writing', 'linear-algebra', 'linear-transformations']"
3361886,"Does $\mathsf{Top}$ have interesting Grothendieck topologies, and do they have applications?","In algebraic geometry, the importance of non-trivial Grothendieck topologies is very well-known. One starts out with the Zariski topology on $\mathsf{Sch}$ , but concludes that it is 'too coarse' for cohomological techniques to work, and so one develops the more refined étale topology as a remedy. The validity of étale descent is central to why the topology works in the first place. Ever since then, one often finds algebraic geometers playing with the various topologies, sometimes even developing new ones that get as close as possible to their needs. Contrast this to 'ordinary' topology, where one has the archetypical Grothendieck topology on $\mathsf{Top}$ in which coverings are simply declared to be the open coverings in the classical sense. I do not recall having ever seen any other Grothendieck topology, and certainly no interesting ones. One could declare coverings to be jointly surjective, but that topology would fail to be subcanonical. What about covering spaces? Perhaps we may declare coverings to be one-element sets $\{Y \to X\}$ in which the map $Y \to X$ is a covering space. Do you know of any interesting Grothendieck topologies on $\mathsf{Top}$ ? Are they as varied as they are on $\mathsf{Sch}$ , and are there any applications to their existence?","['grothendieck-topologies', 'algebraic-geometry', 'sheaf-theory', 'general-topology', 'algebraic-topology']"
3362015,Singular covariance matrix identity,"Let $Z=(Z_1,...,Z_n)^T$ be a random vector with mean 0, and define its covariance $\Sigma=\mathbb{E}[ZZ^T]$ . Assume that $\Sigma$ is singular. Then I need to show something (non-related to the question), but I was told to start with the identity, that $\alpha^T \Sigma \alpha=0$ (I guess its supposed to be that there exists an $\alpha$ such that it is true), but I fail to understand how that is true, any help is appreciated.","['stochastic-processes', 'linear-algebra']"
3362030,Evaluate the limit $\lim\limits_{n\to0}\frac{(x)+(2x)+\cdots (nx)}{n^2}$,"Find the limit of $\lim_{n\rightarrow ~0}\frac{(x)+(2x)+\cdots (nx)}{n^2}$ , where, $(x)=x-[x]$ and $[x] $ is the greatest integer function(the fractional part function). I feel, as $n \rightarrow 0$ this limit  goes to infinity, but the options given are $x~,~x/2,~x/3,~x/4$ . How this is happening, I double checked the question paper, in question $n$ . is tending to 0 only not to $\infty$ . I found a similar question here","['sequence-of-function', 'real-analysis', 'fractional-part', 'functions', 'limits']"
3362045,"Critical point of $f(x,y) = x^{3} -3xy^{2}, x,y \in \Bbb{ R}$","Consider the function $f(x,y) = x^{3} -3xy^{2}, x,y \in \Bbb{R}$ . Then what can you conclude about its critical point $(0,0) ?$ For this function $f_{xx} f_{yy} - f_{xy}^{2} = 0$ at $(0,0)$ So the test gives no result. The function can be written as $x(x^{2} - 3y^{2}) = x(x- √3 y)(x+√3 y)$ Now how do we know the nature of function near $(0,0) $ ?","['multivariable-calculus', 'calculus']"
3362097,"Trying to find $c_{1}$ , $c_{2}$ for Big theta notation.","Need to find $c_{1},$ $c_{2}$ and $n_{0}$ . \begin{equation}
c_{1}n^3 \leq \frac{n^3}{100} - 100n^2 - 100n + 3\leq c_{2}n^3
\end{equation} \begin{equation}
c_{1} \leq \frac{1}{100} - \frac{100}{n} - \frac{100}{n^2} + \frac{3}{n^3} \leq c_{2}
\end{equation} \begin{equation}
\frac{1}{100} - \frac{100}{n} - \frac{100}{n^2} + \frac{3}{n^3} \leq c_{2}
\end{equation} This is what I have done so far, but I am currently stuck do I need to chose c2 which is positive and greater than $\frac{100}{n} + \frac{3}{n^3}$ ? And for c1 , I need a c1, which is >0. How do I find these constants?","['asymptotics', 'discrete-mathematics']"
3362115,Coordinate Geometry of maximum slope on tangent,"Find the maximum value of $y/x$ if it satisfies $(x-5)^2+(y-4)^2=6$ . Geometrically, this is finding the slope of the tangent from the origin to the circle. Other than solving this equation with $x^2+y^2=35$ , I cannot see any synthetic geometry solution. Thanks!","['tangent-line', 'circles', 'geometry']"
3362117,Real eigensolutions to the diffusion equation.,"How can I find the real eigensolutions to the diﬀusion equation $u_t$ = $\left(x^2 u_x\right)_x,$ modeling diffusion in an inhomogeneous medium on the half-line $x>0?$ And which solutions satisfy the Dirichlet boundary conditions $u(t,1)=u(t,2)=0?$","['boundary-value-problem', 'ordinary-differential-equations']"
3362187,How might one formulate integration over an ordered probability simplex?,"Given a probability simplex ( $x_i \geq 0$ , $i=1,\ldots,n$ ) \begin{equation}
\sum_{i=1}^n x_i=1,
\end{equation} I want to attempt integrations of various (""operator-monotone""-based https://pdfs.semanticscholar.org/d393/21f142432eddd2af0d3bd07235a63aca2019.pdf ) functions over that subsection for which \begin{equation}
x_i \geq x_{i-1}.
\end{equation} Further, I'm particularly interested in such integrations ( $n=4$ ) with the additional (""absolute separability"") constraint (eq. (3) in https://arxiv.org/pdf/quant-ph/0502170.pdf ) \begin{equation}
x_1 \leq x_3+2 \sqrt{x_2 x_4}.
\end{equation} What are my options for setting up the integrations (coordinate transformations might be of interest)? The particular integrations I have in mind are seemingly very challenging, and I may (probably) have to resort to numerical methods.","['integration', 'multivariable-calculus', 'simplex', 'probability']"
3362192,Noetherian $R$-algebra corresponds to a coherent sheaf of rings on $\operatorname{Spec}(R)$,"Let $R$ be a ring and $A$ a Noetherian $R$ -Algebra. Let $\newcommand{\m}{\mathcal} \m{A} = \tilde{A}$ be the corresponding $\m{O}_X$ -Module, where $(X, \m{O}_X) = \operatorname{Spec}(R)$ . I would like to show that $\m{A}$ then is a coherent $\m{A}$ -Module on X. Is the following attempt at a proof correct? We first need that $\m{A}$ is of finite type, which is trivial. The nontrivial part is to prove that for every short exact sequence of $\m{A}$ -Modules $$
0 \to \m{K} \to \m{A}^n \to \m{A} \to 0
$$ the kernel $\m{K}$ is an $\m{A}$ -Module of finite type. Since $\m{A}$ and $\m{A}^n$ are quasi-coherent $\m{O}_X$ -Modules, $\m{K} = \tilde{K}$ is quasi-coherent, with $K = \Gamma(X, \m{K})$ . $K$ is an $\Gamma(X, \m{A})$ -Module and by the equivalence of categories between $\mathsf{qCoh}(X)$ and $R$ - $\mathsf{Mod}$ , $$
0 \to K \to A^n \to A \to 0
$$ is an exact sequence (in $R$ - $\mathsf{Mod}$ , and hence also in $A$ - $\mathsf{Mod}$ ). Since $A$ is Noetherian, it follows that $K$ is a $A$ -Module of finite type, i.e. there is a surjection $A^m \to K \to 0$ . Applying $\tilde{}$ gives an exact sequence $$
\m{A}^m \to \m{K} \to 0
$$ (again, at first this is only exact in $\m{O}_X$ - $\mathsf{Mod}$ ). $\square$ Background: Proposition 16.1.8 in EGA IV (part 4), which (I think) uses this fact. (Grothendieck writes that this follows from the exactness of inverse images and $X = Y \times_{Y \times_S Y} (X \times_S Y)$ , however I don't see how this is helpful at all. Alternatively - my french is not very good - these facts could be explaining why $\operatorname{gr}_I^\bullet A$ is Noetherian for $A$ Noetherian. If you can make sense of any of this please drop me a comment.)","['proof-verification', 'coherent-sheaves', 'category-theory', 'algebraic-geometry', 'sheaf-theory']"
3362203,Blow up and relationship between tangents sheaves,"Let $X = \mathbb{P}^{n}$ and $Y \subset X$ a smooth subvariety of $X$ . Let us consider the blowup morphism of $X$ along of $Y$ , denoted by $\pi : \widetilde{X} \longrightarrow X$ with exceptional divisor $E = \pi^{-1}(Y)$ . 1) Is there any relationship between $T_{\widetilde{X}}$ and $T_{X}$ ? If $c \in \mathbb{Z}$ and $\mathcal{F}$ is a coherent sheaf in $X$ , then : 2) Is it possible to write $T_{\widetilde{X}} \simeq \pi^{*}(T_{X}) \otimes \pi^{*}(\mathcal{F}) \otimes  \mathcal{O}_{\widetilde{X}}(cE)$ ? 3) Is there any relationship between $c$ and $\text{deg}(Y)$ ? References on the subject and any help are welcome. Thanks a lot.","['algebraic-geometry', 'coherent-sheaves', 'sheaf-theory']"
3362207,The closure of graph of dense open sets,"$U$ is a quasi-projective variety in $\mathbb{P}^n$ , and V is an open dense set in $U$ . There is a morphism $\phi:U\to Y\subset\mathbb{P^n}$ . $U, Y$ are irreducible. Then how can we get $$ \overline{\{(x,\phi(x))|x\in U\}}=\overline{(x,\phi(x))|x\in V\}}?$$ P.S. (1) $\{(x,\phi(x))\}$ is defined on $U \times Y$ , but the topo on $U\times Y$ is not the product topo of $U$ and $Y$ . (2) I already know $\phi(V)$ is dense in $\phi(U)$ .",['algebraic-geometry']
3362270,Computing $ \int_C z \frac{f'(z)}{f(z)} dz $,"I want to compute $$ I =  \int_C z \frac{f'(z)}{f(z)} dz $$ , where $ C = \{z : z = e^{i\theta}, 0 \leq \theta \leq 2\pi \}$ and $f$ is analytic, with a simple unique root at $z_0$ inside the circle $C$ . So I say $f$ can be written in the form of $f(z) = (z-z_0) g(z)$ , where $g(z)$ is analytic and $g(z) \neq 0$ for all $z \in \mathbb{C}$ . Thus $f'(z) = (z- z_0)g'(z) + g(z)$ so $$
\begin{align}
I &= \int_C z\frac{(z- z_0)g'(z) + g(z)}{(z-z_0)g(z)} dz  \\
 &= \int_C z \frac{g'(z)}{g(z)}dz + \int_C \frac{z}{z-z_0}dz \\
 &= I_1 + I_2
\end{align}
$$ Now $z \frac{g'(z)}{g(z)}$ is analytic everywhere so $I_1 = 0$ and $I_2 = 2\pi i z_0$ so $$
I = 2\pi i z_0.
$$ Is my thought correct or am I missing something? Any comment would be appreciated.","['complex-analysis', 'complex-integration']"
3362271,A $C^1$ fucntion $f$ on $\Bbb R^2$ that has no mixed second derivative,"Is there a $C^1$ function $f$ on $\Bbb R^2$ that have no mixed second derivatives? (Here, mixed second derivative means $f_{xy}$ or $f_{yx}$ .)","['multivariable-calculus', 'calculus', 'analysis']"
3362305,How we can find the symmetric group with least $n$ whose subgroup of it is isomorphic to $G$?,By Cayley's Theorem any group $G$ is isomorphic to a subgroup of $S_n$ for $n = |G|$ (since we can think of group actions as permutations of the group elements). And I am asking if there is a general way of calculating the least $n \le |G|$ with such property. Let me illustrate what I mean by an example: We know that $D_3$ is isomorphic to $S_3$ . But by Cayley's Theorem we also know that $D_3$ is isomorphic to a subgroup of $S_6$ (since every group action is a permutation of $3\cdot2 = 6$ elements). In this case least such $n \le |G|$ is $3$ . I am asking for a general way of calculating the $n$ for an arbitrary group $G$ .,"['symmetric-groups', 'group-theory', 'group-isomorphism']"
3362348,If $a_{k}=2^{2^k}+2^{-2^k}$ then evaluate $\prod_{k=1}^\infty\left(1-\frac{1}{a_{k}}\right)$,If $$a_{k}=2^{2^k}+2^{-2^k}$$ then evaluate $$\prod_{k=1}^\infty\left(1-\frac{1}{a_{k}}\right)$$ I tried using Sophie-Germaine Identity about factorisation for $x^4+4$ but it did not work,"['algebra-precalculus', 'sequences-and-series']"
3362391,What did I get wrong when solving $\int\frac{\sqrt{x^2-1}}{x^4}dx$?,"I'm not sure that this is the problem, but I think I may not know how to find the $\theta$ value when solving an integral problem with trigonometric substitution. I got $\frac{\sin^3(\sec^{-1}(x))}{3}+C$ for the answer, but the answer should be, $\frac{1}{3}\frac{(x^2-1)^{3/2}}{x^3}+C$ $$\int\frac{\sqrt{x^2-1}}{x^4}dx$$ Let $x=\sec\theta$ Then $dx=\sec\theta\tan\theta d\theta$ $$\int\frac{\sqrt{\sec^2\theta-1}}{\sec^4\theta}\sec\theta\tan\theta d\theta$$ $$=\int\frac{\sec\theta}{\sec^4\theta}\sqrt{\tan^2\theta}\tan\theta d\theta$$ $$=\int\frac{1}{\sec^3\theta} \tan^2\theta d\theta$$ $$=\int\frac{1}{\sec^3\theta}\frac{\sec^2\theta}{\csc^2\theta}d\theta$$ $$=\int\frac{1}{\sec\theta}\frac{1}{\csc^2\theta}d\theta$$ $$=\int \cos\theta\sin^2\theta d \theta$$ Using $u$ -substition, let $u=\sin\theta$ Then $du=\cos\theta d\theta$ and $dx = \frac{1}{\cos\theta}du$ $$\int\cos\theta u^2 \frac{1}{\cos\theta}du$$ $$=\int u^2 du$$ $$=\frac{u^3}{3}+C$$ $$=\frac{\sin^3\theta}{3}+C$$ Since $x=\sec\theta$ , $\sec^{-1}(x)=\theta$ $$=\frac{\sin^3(\sec^{-1}(x))}{3}+C$$ What am I doing wrong?","['integration', 'calculus', 'trigonometric-integrals', 'indefinite-integrals', 'trigonometry']"
3362397,Does $\sigma(T) = \{1\}$ and $\|T\| = 1$ imply that $T$ is the identity?,"Suppose that $T$ is a bounded linear operator on a complex Banach space X and that we know that $\sigma(T) = \{1\}$ and $\|T\| = 1$ (i.e. the spectrum of the contraction $T$ consists only of a single point, 1). Does it follow that $T$ is the identity operator? This is true in finite dimensions. In finite dimensions, the operator $N := T - \mathbb{1}$ is nilpotent. If $N\neq 0$ , then there exists a strictly positive interger $D$ , such that $N^D \neq 0$ and $N^{D+1} = 0$ . For $K \geq D$ , we have $$1 = \|T\| = \|\mathbb{1} +N\| = \|(\mathbb{1} + N)^K\| = \|\mathbb{1} + \sum_{i = 1}^K {K\choose i} N^i\| = \|\mathbb{1} + \sum_{i = 1}^D {K\choose i} N^i\|.$$ Choose a vector $x \in X$ such that $N^Dx \neq 0$ , then the vectors $x, Nx, N^2x, \dots N^Dx$ are linearly independent. The coordinate function of $Nx$ is ${K\choose 1} = K$ , which is unbounded as $K \rightarrow \infty$ . This contradicts that $\|T\| = 1$ . In infinite dimensions, the difficulty is that $N$ is not nilpotent but merely quasinilpotent and that the coordinate functions may not be continuous. At the moment I can neither prove this nor construct a counter example.","['semigroup-of-operators', 'operator-theory', 'spectral-theory', 'functional-analysis']"
3362447,Is variable substitution the same as function composition?,"Is the process of variable substitution the same as function composition ? And if yes how do you write it in the case of multivariable functions ? For example a typical variable substitution is $$
x=r\cos(\theta), \  y=r\sin(\theta).$$ Given is $$f(x,y)=x^2 + y$$ Which is no turned into $$f(x(r,\theta),y(r,\theta))=g(r,\theta)=r^2\cos^2(\theta)+r\sin(\theta)$$ This looks to me like a composition of the function $$
f:\mathbb R^2 \rightarrow \mathbb R
$$ and the function $$
p:\mathbb R^2 \rightarrow \mathbb R^2
$$ but i am unable to properly define $$p$$ which takes care of turning $(x,y)$ to $(r\cos(\theta), r\sin(\theta))$ . I seem to have a misconception some where but iam not able to make sense of it. Are changes of coordinate systems more than simple substitutions/function compositions or not ?",['functions']
3362460,How to find this ODE solution $f''(x)+x^2f(x)=0$?,"My idea: For $f(x)\neq 0$ , we have $$ \dfrac{f''(x)}{f(x)}=-x^2. $$ Note that $$ \dfrac{d}{dx}\left( \dfrac{f'(x)}{f(x)} \right)=\dfrac{f''(x)f(x)-[f'(x)]^2}{[f(x)]^2}=\dfrac{f''(x)}{f(x)} - \left( \dfrac{f'(x)}{f(x)} \right)^2. $$ Now let $u(x)=\dfrac{f'(x)}{f(x)}$ . It follows that, $$\dfrac{du}{dx}+u^2=-x^2.$$ But this way all I can do is getting this Ricatti equation.",['ordinary-differential-equations']
3362463,Projective modules over local rings are free (Matsumura's proof),"I have a question about an argument from a proof in Hideyuki Matsumura's ""Commutative Ring Theory"" on page 9, Theorem 2.5: Let $(A,\mathfrak{m})$ be a local ring; then a projective module $M$ over $A$ is free. The understanding problem arises in the verification of the case when $M$ is finite (as $A$ -module). The proof works as follows: Choose a minimal $A$ -basis $\omega_1,...,\omega_n$ of $M$ . Take into account that ""minimal"" means that there cannot exist another system of generators $b_1,..., b_m \in M$ with $m < n$ and $M = \sum_{i=1} ^m A b_i$ . Define a surjective map $\varphi:F \to M$ from the free module $F = Ae_1 \oplus \cdots \oplus Ae_n$ to $M$ by $\varphi(\sum a_i e_i) = \sum a_i\omega_i$ . If we set $K = \operatorname{Ker}(\varphi)$ then, from the minimal basis property $$\sum a_i \omega_i =0 \Rightarrow a_i \in \mathfrak{m} \text{ for all } i. $$ Thus $K \subset \mathfrak{m}F$ .  Because $M$ is projective, there exists $\psi: M \to F$ such that $F = \psi(M)\oplus K$ , and it follows that $K = \mathfrak{m}K$ . (???) On the other hand, $K$ is a quotient of $F$ , therefore finite over $A$ , so that $K = 0$ by Nakayama and $F = M$ . Question: why the fact that $F = \psi(M)\oplus K$ implies that $K = \mathfrak{m}K$ , more precisely why $K \subset \mathfrak{m}K$ ? (The other inclusion is trivial.) Considerations: $F = \psi(M)\oplus K$ is a decomposition as $A$ -modules and since $\mathfrak{m} \subset A$ we obtain $\mathfrak{m} F = \mathfrak{m} \psi(M)\oplus \mathfrak{m} K$ . since $K \subset \mathfrak{m}F$ it suffices to show that $\mathfrak{m} \psi(M)=0$ . Why is it true? I would like additionally to remark that I found already some other proofs but the intention of this question bases only on the understanding of the explained step in the presented proof.","['projective-module', 'proof-explanation', 'modules', 'abstract-algebra', 'commutative-algebra']"
3362482,Discrete math -- equivalence relations,"I've been learning about equivalence relations in my discrete math class. I understand that equivalence relations are relations that are symmetric, reflexive, and transitive. I also learned about the equivalent class and the quotient set. 
However, this example that we did in class was very confusing. Example: Let A = {a,b,c} and let R be the binary relation on A defined by R = {(a,a),(b,a),(c,c)}. Find A/R Answer: A/R = {[a],[b],[c]} = {{a,b},empty set, {c}} I thought to be able to find the quotient set, you needed to first find the equivalence class. But how do you find an equivalence class if R is not an equivalence relation? Thanks! Edit: I asked my prof this question and this is what he said. Question: If a relation is binary, but, it is NOT an equivalence relation, does it still have a quotient set? Nice question. You could use the same definition for any binary relation on a set A; however, only if the relation is an equivalence relation we can ensure the following properties: (a) the set A is the union of the equivalence classes (b) two different classes are disjoint, i.e., if the classes are different, then they do not share elements. If we think of the classes as if they were teams, the failure of the conditions above mean that either there are elements in A that do not belong to any team or there are elements that belong to more than one team.",['discrete-mathematics']
3362516,"In Lebesgue world, is there $f=g$?","As we develop the theory of Lebesgue integration, it seems every function being equal is no longer the equality in the Riemann world. The notion of ""almost everywhere"" seems to basically replace the notion of equalit between two real-valued functions. Is this correct? In other words, when you compare two real-valued functions defined on $E\subset\mathbb{R}^d$ , you always compare their equality including all negligible set. Hence the birth of the notion of equal almost everywhere. Is this a correct interpretation? So, there is no true equality in the Lebesgue world then?","['measure-theory', 'real-analysis']"
3362558,Under what conditions two cyclic modules are isomorphic?,"Let $R$ be a ring with identity and let $I$ and $J$ be right ideals of $R$ . I know that if $R$ is commutative , then the $R$ -modules $R/I$ and $R/J$ are isomorphic if and only if $I=J$ . What happens if $R$ is not commutative? Is there any necessary and sufficient condition (in terms of $I$ and $J$ ) to force that $R/I$ and $R/J$ are isomorphic right $R$ -modules?","['ring-theory', 'abstract-algebra', 'modules']"
3362584,"How many integral solutions does $2x + 3y + 5z = 900$ have when $ x, y, z \ge 0$?","Solution: Let $2x + 3y = u.$ Then we must solve $\begin{align} u + 5z = 900 \tag 1 \\ 2x + 3y = u \tag 2 \end{align}$ For $(1),$ a particular solution is $(u_0, z_0) = (0, 180).$ Hence, all the integral solutions of $(1)$ are $\begin{cases} u = 5t \\ z = 180 - t \end{cases} (t \in \mathbb Z)$ Substituting $u = 5t$ into $(2)$ gives $2x + 3y = 5t$ whose particular solution is $(x_0, y_0) = (t, t).$ Hence all the integral solutions of $(2)$ are $\begin{cases} x = t - 3s \\ y = t + 2s \end{cases} (t \in \mathbb Z)$ Thus all the integral solutions of $2x + 3y + 5z = 900$ are given by $$\begin{cases} x = t - 3s \\ y = t + 2s \\ z = 180 - t \end{cases} (s,t \in \mathbb Z)$$ Now suppose $x, y, z \ge 0.$ Note, $180 - t \ge 0 \implies t \le 180$ and so $t + 2s \ge 0 \implies s \ge -90$ and $t - 3s \ge 0 \implies s \le 60.$ Thus we have $-90 \le s \le 60.$ Consider $0 \le s \le 60.$ Now $t \le 180, \ t \ge 3s \implies 3s \le t \le 180$ . Thus in this range of $s$ , there are $180 - 3s + 1 = 181 - 3s$ of $t$ 's. Consider $-90 \le s < 0.$ Now $t \le 180, \ t \ge -2s \implies -2s \le t \le 180$ . Thus in this range of $s$ , there are $180 + 2s + 1 = 181 + 2s$ of $t$ 's. Range $0 \le s \le 60$ has the following points: $(0, 181 - 3(0)), \ (1, 181 - 3(1)), (2, 181 - 3(2), \ldots (60, 181 - 3(60))$ of which there are $61.$ The range $-90 \le s < 0$ must have $91$ points. In sum, we have $61 + 91 = 152$ points for $x, y, z \ge 0.$ My question: According to the book the answer is $\displaystyle{\sum_{s = 0}^{60}(181 - 3s) + \sum_{s = -90}^{-1}(181 + 2s) = 13651.}$ I don't understand why they took the sum of all $t$ 's in the range of $s$ . That means some of my denotations and labels above must be incorrect. Where's the mistake? Thanks. edit : I think I see my mistake. The number $181 - 3s$ is the number of $t$ 's, not necessarily the form of $t$ . Given that, the number of ordered pairs (in the given range) must be $(181 - 3s)*61$ by the product rule.","['elementary-number-theory', 'proof-verification', 'combinatorics', 'integer-programming', 'linear-diophantine-equations']"
3362683,Free normal subgroup of an HNN-extension,"Suppose $F$ is a finitely generated free group and $a,b$ are not in $F'$ but $b^{-1}a \in F'$ . By taking the HNN extension $G=\langle F,t | t^{-1}atb^{-1}\rangle$ , is there a way to find a normal free subgroup of $G$ so that their quotient is cyclic? I'm trying to define a homomorphism from $G$ to $\Bbb Z$ so that the kernel acts freely on the vertices of the HNN tree, which have the conjugates of $F$ as stabilizers but with no success. Moreover by defining $f_1:F \to \Bbb Z$ in general and let $f_2:\langle t\rangle \to \Bbb Z$ be trivial I have a map from $G\to \Bbb Z$ but this map can't be injective on the conjugates of $F$ because $f_1$ can never be injective due to $f_1(a)=f_1(b)$ . Is there something I'm missing?","['cyclic-groups', 'combinatorial-group-theory', 'group-extensions', 'normal-subgroups', 'group-theory']"
3362751,"Two trains move towards each other, a bird moves between them. How many trips can the bird make? [duplicate]","This question already has answers here : 'Bee flying between two trains' problem (9 answers) Closed 4 years ago . The problem statement: Two trains move towards each other at a speed of $34\ km/h$ in the same rectilinear road. A certain bird can fly at a speed of $58\ km/h$ and starts flying from the front of one of the trains to the other, when they're $102\ km$ apart. When the bird reaches the front of the other train, it starts flying back to the first train, and so on. How many of these trips can the bird make before the two trains meet? What is the total distance the bird travels? Commentary: The second question of the problem seems relatively simple, since one only has to notice that the trains will take 1.5 hours to meet, therefore, the bird travels $58\cdot1.5=87 km$ . However, the first question baffles me. How can one calculate how many trips the bird makes? If I'm correct, in order to obtain the time the bird will take to make its first trip, we have to add the bird's speed and the speed at which the distance of the trains is being reduced ( $68\ km/h$ ). This means the bird will take $\frac{102}{126}\approx0.809$ hours to finish the first trip, and the trains will be $\frac{986}{21}\approx 46.95\ km$ apart. If I continue this way (now finding how long will the bird take to travel those 46.95 km), it seems that I'll never stop or that at least it will take a huge amount of trips that cannot be computed by hand. Is there a way to find a 'quick' answer to this problem? Am I making it more complicated than it actually is? Thanks in advance!","['limits', 'arithmetic', 'puzzle']"
3362797,Tensor product commutes with associated graded,"Let $V,W$ be vector spaces over a field $k$ , not necessarily finite-dimensional, and $V_{\bullet}=(V=V_0\supseteq V_1\supseteq\cdots\supseteq V_n=0)$ and $W_{\bullet}=(W=W_0\supseteq W_1\supseteq\cdots\supseteq W_m=0)$ be finite filtrations of each. Then $V\otimes_k W$ admits a natural finite filtration $(V\otimes W)_\bullet$ given by $$ (V\otimes W)_k=\sum\limits_{i+j=k}V_i\otimes W_j.$$ I want to know whether $\operatorname{gr}(V\otimes W)_\bullet\cong\operatorname{gr}V_\bullet\otimes\operatorname{gr}W_\bullet$ as graded vector spaces, where $\operatorname{gr}$ is the functor which takes a filtered vector space to its associated graded. More specifically, for each $k$ we have a natural map $$\phi_k:\bigoplus\limits_{i+j=k}(V_i/V_{i+1})\otimes(W_j/W_{j+1})\to(V\otimes W)_k/(V\otimes W)_{k+1}$$ coming from the natural surjective map $$\bigoplus\limits_{i+j=k}V_i\otimes W_j\to(V\otimes W)_k/(V\otimes W)_{k+1}$$ coming from the inclusions $V_i\otimes W_j\subseteq(V\otimes W)_k$ when $i+j=k$ .  Thus $\phi_k$ is surjective for all $k$ .  I would like to know whether $\phi_k$ is always an isomorphism.  I've tried writing out a basis of some splitting of this filtration to show it, and I can't quite complete the argument that way. If you have a proof, know a counterexample, or have a reference for this I would really appreciate it!!","['linear-algebra', 'vector-spaces', 'filtrations', 'graded-modules']"
3362814,Does the Cramer-Wold theorem hold for random elements?,"Recall the Cramer-Wold theorem; If $(X_n)$ and $X$ are $d$ dimensional random variables, then $X_n\to_d X$ iff $c\cdot X_n\to_d c\cdot X$ for all $c\in R^d$ . Does there exist a version of this for random elements? To be concrete, let us consider Donsker's invariance principle. https://en.wikipedia.org/wiki/Donsker%27s_theorem In the notation of the Wikipedia article, $W^{(n)}$ is a random element of $D[0,1]$ and converges to $W$ =standard Brownian motion, in distribution. Now, if we suppose our underlying random variables are $d$ dimensional and let $W$ be a $d$ -dimensional standard Brownian motion, then to prove $W^{(n)}\implies W$ ,  would it be sufficient to show $c\cdot W^{(n)}\implies c\cdot W$ for all $c\in R^d$ ? Or, would one have to go via the standard route of using Cramer-Wold to prove the finite dimensional distributions converge, and then verify tightness? PS: I know that a higher dimensional DIP holds, this is just an illustrative example.","['probability-distributions', 'brownian-motion', 'probability-theory']"
3362833,Examples of presheaves which are not sheaves,1) Consideremos $\mathbb{C}$ con la topología usual. Definimos el prehaz de las $\textbf{funciones acotadas}$ $\mathcal{F}:\textbf{Top}(X)\to \textbf{Ab}$ de la siguiente manera: $$\mathcal{F}(U)=\{f:U\to \mathbb{C} \mid f\text{ acotada}\}.$$ Este prehaz no es un haz. 2)  Consideremos $\mathbb{C}$ con la topología usual. Definimos el prehaz de las $\textbf{funciones acotadas}$ $\mathcal{F}:\textbf{Top}(X)\to \textbf{Ab}$ de la siguiente manera: $$\mathcal{F}(U)=\{f:U\to \mathbb{C} \mid f\text{ holomorfa y acotada}\}.$$ Este prehaz no es un haz. Más ejemplos de prehaces que no sean haces? Muchas gracias Translation: 1): Consider $\mathbb{C}$ with the usual topology. Define the presheaf of bounded functions $\mathcal{F}:\textbf{Top}(X)\to \textbf{Ab}$ as follows: $\mathcal{F}(U)= \lbrace f:U\to \mathbb{C} \mid f \text{ is bounded} \rbrace$ This presheaf is not a sheaf. 2): Consider $\mathbb{C}$ with the usual topology. Define the presheaf of bounded functions $\mathcal{F}:\textbf{Top}(X)\to \textbf{Ab}$ as follows: $\mathcal{F}(U)= \lbrace f:U\to \mathbb{C} \mid f \text{ is bounded and holomorphic} \rbrace$ This presheaf is not a sheaf. More examples of presheaves which are not sheaves? Thanks a lot.,"['algebraic-geometry', 'sheaf-theory']"
3362851,Is there such thing as a continuous set?,"I've been working with sets recently and have often thought about the idea of set continuity. However, I don't remember ever being taught about set continuity or anyone else mentioning it (I've even received push-back). After investigating for a little, I the only reference to ""continuous set"" I've found is from the Encyclopedia of Mathematics . Which has a definition for a continuous set and then says: "" The phrase ""continuous set"" is not used in the Western literature "". So my question is: is there such a thing as a continuous set? If so, where can I find a definition for it (other than EoM)? If not, then why is the study of this property unimportant/inconsequential? Here is my proposed definition of what a continuous should be: Set $A$ is said to be continuous $\Leftrightarrow$ $$\forall B\neq\emptyset, B\subset A,  \exists \ C \ such \ that\ C \cap B\neq\emptyset, B \nsupseteq C\subset A $$ where $C$ is a convex set not contained in $B$ . Put simply, a set is continuous if it is possible to travel from any point in the set to any other point in the set without leaving the set. One Particular example: I've been studying preference continuity in microeconomics, and it seems obvious to me that preferences must be defined in a continuous set in order to be continuous themselves. But I think this is often left to one side as preferences are commonly thought in $ \mathbb{R}_+^L $ , which is a continuous set (However I am more concerned on the mathematical use of a continuous set than it's use in this particular example).","['elementary-set-theory', 'continuity', 'economics']"
3362902,Finding Primes in Pi [duplicate],"This question already has an answer here : Digits of $\pi$ forming primes? (1 answer) Closed 4 years ago . Consider the numbers of the form $$
a_n=\lfloor\pi\times 10^{n-1}  \rfloor,
$$ for $n\in\mathbb{N}$ . In other words, $\{a_n\}_{n\in\mathbb{N}}$ is the sequence composed of integers built from the first $n$ digits of $\pi$ , so that $$
a_1=3,\,\,\,a_2=31,\,\,\,a_3=314,\,\,\,a_4=3141,\,\,\,a_5=31415,\,\,\,...
$$ My question is: for which values of $n$ is $a_n$ a prime number? I wrote a small code to find primes for $1\leq n\leq 10^4$ , and I've only found primes for $n\in\{1,2,6,38\}$ , which are, respectively, \begin{align}
a_1&=3\\
a_2&=31\\
a_6&=314159\\
a_{38}&=31415926535897932384626433832795028841
\end{align} I found this result rather intriguing, since I'd expect to find more primes up to numbers with $10^4$ digits. Are there any more primes in this sequence? Is there an explanation for the lack of primes between $a_{38}$ and $a_{10^4}$ ?","['number-theory', 'pi', 'prime-numbers', 'sequences-and-series']"
3362926,Coproduct in an alternative category of groups,"I've been thinking about the following category $\mathbb{G}$ . Objects of $\mathbb{G}$ are groups and a morphism from $G$ to $H$ is a set $X$ equipped with commuting left, right actions of $G, H$ ; equivalently, a left action of $G \oplus H^{op}$ on $X$ . The identity morphism on $G$ is $G$ itself, with the actions just given by left and right multiplication. If $X \in \mathbb{G}(G,H)$ and $Y \in \mathbb{G}(H,K)$ , the composition $X\circ Y$ is the cartesian product $X \times Y$ , modulo the relation $(x\cdot h, y) \sim (x,h\cdot y)$ . This admits a well-defined $G \oplus K^{op}$ action. Is this a standard category to consider? It is similar to the category of rings, with bimodules as morphisms. I am interested in whether this category has a coproduct, and if it is different from the coproduct in the standard category of groups (free product).","['group-theory', 'group-actions', 'limits-colimits', 'category-theory']"
3363002,Proving whether or not a limit is correct.,"I am new to calculus. In class, we are learning how to formally prove a limit is correct. Say f(x)=x+2
         Say someone claims the limit as x approaches 2 is 3. We were asked to check (formally) whether this is correct or not. I started by asking what values of x would keep the absolute value of ""f(x)-3"" less than some number, epsilon. I got that for this to hold true, the absolute value of ""x-1"" has to be less than epsilon. Then I said, well lets suppose that the limit is 3. Now lets suppose epsilon is 0.1. For the limit to be correct, there must be some range around 2 such that all f(x) lie within 0.1 of 3. But from previous work, I know that this will only happen as long as x is between 0.9 and 1.1. Since I have shown that there exists some epsilon for which there is no range around 2 which works, the limit can not be 3. Is this approach correct?","['limits', 'calculus']"
3363014,Second derivative test with non zero result,"Suppose function f(x,y) is of $C^2$ , and we know that $f_{xx}f_{yy}-f_{xy}^2$ does not equal to 0. Furthermore, $f_{xx}+f_{yy} \ge 0$ . Show that f does not have a strict local max. So the second derivative test tells us that it is either a saddle point, min, or max since it does not equal to 0. And we know that $f_{xy}^2 \ge 0$ . If $f_{xx}f_{yy} > f_{xy}^2 $ , then we know $f_{xx}f_{yy}-f_{xy}^2 > 0$ , then if $f_{xx}>0$ , local min. But it can be a local max if $f_{xx}<0$ . If $f_{xx}f_{yy} < f_{xy}^2 $ , then we know $f_{xx}f_{yy}-f_{xy}^2 < 0$ , then saddle point. How can I show $f_{xx}<0$ is not possible through $f_{xx}+f_{yy} \ge 0$ ?","['real-analysis', 'maxima-minima', 'multivariable-calculus', 'calculus', 'derivatives']"
