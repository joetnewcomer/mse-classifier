question_id,title,body,tags
1191477,Show that $-\frac{2yx^3}{(x^2+y^2)^2}$ is bounded.,"Show that $-\frac{2yx^3}{(x^2+y^2)^2}$ is bounded. I'm approaching this starting with
$$ \left| \frac{2yx^3}{(x^2+y^2)^2} \right| = \left| \frac{2yx^3}{x^4+2x^2y^2+y^4} \right| \leq \left| \frac{2yx^3}{2x^2y^2} \right| = \left| \frac{x}{y}\right|.$$ However, this doesn't get me anywhere. What am I missing?","['multivariable-calculus', 'inequality']"
1191479,"How to prove that there are no integers a,b such that $b^2=4a+2$","How to prove that there are no integers a,b such that $b^2=4a+2$ This seems like a very simple prof but when i tried to work through it i keep on hitting walls.
 I tried to prove this by contradiction saying that suppose there exists an $a,b\in\mathbb{Z}:b^2=4a+2$ then i worked through the proof as different cases, when a and b is odd, a,b is even and a is odd and b is even but i cant seem to get the answer.","['discrete-mathematics', 'contest-math', 'recreational-mathematics']"
1191497,Show $\frac{\partial^2}{\partial ^2 x}+ \frac{\partial^2}{\partial ^2 y}= 4 \frac{\partial^2}{\partial z \partial{ \overline{z}}} $,"I want to solve the following exercise: Show that: $$\frac{\partial^{2}}{\partial ^{2}x}+ \frac{\partial^{2}}{\partial ^{2}y}= 4 \frac{\partial^{2}}{\partial z \partial{ \overline{z}}}.$$ My attempt: We know that: $$\frac{\partial}{ \partial{ \overline{z}}} = \frac{1}{2}\left(\frac{\partial}{\partial x} + i \frac{\partial}{\partial y} \right),$$ and $$\frac{\partial}{ \partial z} = \frac{1}{2}\left(\frac{\partial}{\partial x} - i \frac{\partial}{\partial y} \right),$$ hence $$\frac{\partial^{2}}{\partial z \partial{ \overline{z}}}= \frac{1}{2} \frac{\partial}{\partial z}\left[ \frac{1}{2}\left(\frac{\partial}{\partial x} + i \frac{\partial}{\partial y}\right)\right]= \frac{1}{4}\left[\frac{\partial}{ \partial z}\left(\frac{\partial}{ \partial x}\right)+ i\frac{\partial}{ \partial z}\left(\frac{\partial}{ \partial y}\right) \right] = \frac{1}{4}\left[\frac{\partial^{2}}{ \partial x^{2}}- i \frac{\partial^{2}}{ \partial y \partial x} + i \frac{\partial^{2}}{ \partial x \partial y} + \frac{\partial^{2}}{ \partial y^{2}}\right]= \frac{1}{4}\left[\frac{\partial^{2}}{ \partial x^{2}}+\frac{\partial^{2}}{ \partial y^{2}}\right].$$ Am I right? If not, can you help me fix the mistake please?","['proof-verification', 'complex-analysis']"
1191503,Conditioning of Triangular Matrices:,"Let $U \in \mathbb{R}^{N\times N}$ be upper triangular. $U$ is well conditioned if  the magnitude of the diagonal elements is sufficiently large compared to that of the corresponding off-diagonal elements. I'm trying to show that if $|u_{ii}| -2\,\displaystyle\sum_{j\neq i}{|u_{ij}|}>0$, for all  $1\leq i\leq N,$ then $\kappa_{\infty}(U)\leq 2\>\dfrac{\|U\|_{\infty}}{\min_{1\leq j\leq N}{|u_{jj}|}}.$ I am struggling to show $\|U^{-1}\|_{\infty} \le \dfrac{2}{\min_{1\leq j\leq N}{|u_{jj}|}}$. Does anyone have any ideas?","['numerical-linear-algebra', 'matrices', 'linear-algebra']"
1191536,Prove: There exists an even integer $n$ that can be written in two different ways as a sum of two distinct primes.,"I am working on this problem, Prove: There exists an even integer $n$ that can be written in two different ways
as a sum of two distinct primes. I know: $3+13=11+5=16$ $11+13=7+17=24$ $23+7=11+19=30$ I don't see any information to help me do the question from my examples, can anyone give me a hint or suggestion? Thanks in advance!","['elementary-number-theory', 'discrete-mathematics']"
1191542,Subgroups of free products of cyclic groups,"Consider the free product $\mathbb{Z}_{3} \star \mathbb{Z}_{3}$. How would one determine the number of subgroups of this product up to isomorphism? It is routine for the case of the product $\mathbb{Z}_{2} \star \mathbb{Z}_{2}$ either by considering the combinations of elements from each group separately or the number of covering spaces of the wedge product of projective spaces. I feel that the easiest way would be to consider the subgroups from the group directly without resorting to topology, but how would one do this?","['algebraic-topology', 'finite-groups', 'group-theory', 'abstract-algebra']"
1191553,Probability and elementary set theory proofs,"(i) suppose P(A) = $0 $ or $ 1$, prove that A and any subset B of Ω are independent. I did:  $P(A)+P(B)+P(C)=1 $ since $ P(Ω)=1.$ If $P(A)=0, $ then $P(B)=1-P(C)=P(B|A)$ Similarly, if $P(A)=1, $ then $P(B)=P(C)=P(B|A)$ Therefore, A and any subset B of Ω are independent. Is this correct and/or sufficient?","['elementary-set-theory', 'probability']"
1191562,Why is this not a poset after adding zero?,"The problem Consider the following set for divisibility. {1, 2, 3, 4, 6, 8, 12, 16, 24, 32, 96}. If 0 is added, the divisibility relation set will no longer be  a poset. Please explain why My Work From what I've been reading, Division by Zero , I 've come to the conclusion that the divisibility relation on this set is not a poset because it is not reflexive because (0, 0) is not in the relation for divisibility for this relation. Would the correct justification be that nothing can be divided by zero? This is confusing to me because the definition for a divides b is, is there an integer k such that b = ak? For something like 0 divides 6, this obviously wouldn't be true, because there is no integer k to make 6 = 0(k) true. However for 0 divides 0, any integer k would make 0 = 0(k) true. Can anyone clarify this?","['discrete-mathematics', 'divisibility', 'elementary-set-theory', 'relations', 'computer-science']"
1191566,Leibniz rule for improper integral,"We know that the Leibniz integral formula $$\frac{d}{dt}\int_{\phi(t)}^{\psi(t)} f(t,s) ds = \int_{\phi(t)}^{\psi(t)} \frac{d}{dt}f(t,s) ds+f(t,\psi(t))\frac{d}{dt}\psi(t) -f(t,\phi(t))\frac{d}{dt}\phi(t).$$ Can we apply this rule for $$\frac{d}{dt}\int_{\phi(t)}^{\infty} f(t,s) ds ?$$","['improper-integrals', 'ordinary-differential-equations', 'calculus', 'integration', 'leibniz-integral-rule']"
1191599,Discrete Mathematics: Relations,"Confused about this question: Describe two binary relations $R$ and $S$ on $\{1, 2, 3\}$ that are not equivalence relations, but whose composition $R\circ S$ is an equivalence relation.","['relations', 'computer-science', 'discrete-mathematics']"
1191606,What is the optimal strategy for this made-up casino game?,"Part 1: Let's say I walk into a casino with 100 dollars in my wallet. I sit down to play a game where my payoff or loss each round is a X dollars, where X is a continuous random variable uniformly distributed between [-2, 2]. However, because I'm friends with the manager, he gives me a special deal. If X < -1, I only lose a dollars instead of losing anywhere between a and 2a dollars, as I rightfully would. (Note that the random variable is deliberately [-2, 2] instead of [-1, 2], in order that the initial determination of the random variable will have an EV of 0.) The random variable X is redetermined every round. The one choice I get to make is the value of the constant a , which is fixed forever once I choose it. If I want to maximize the amount of cash in my wallet at the end of 50 rounds (and implicit in this question is the need to avoid going bust), what value should I pick for a ? Part 2: Everything is the same, but instead of the payout or loss each round being a X dollars, it is now a (X+ b ). Let's say b = 0.1, so my payout or loss every round will be a * [-1.9, 2.1]. The special deal with my buddy the manager is still on for any X < -1, so I only lose a dollars instead of anywhere between a and 1.9a dollars. How does my selection of a change?","['statistics', 'optimization']"
1191626,Uniform Integrability: domination implies UI,"I need to show that if $|f_n|\leq g$, and $g$ is integrable, then $\{f_n\}$ is uniformly integrable, i.e., $\underset{a\rightarrow\infty}\lim\sup_n\int_{[|f_n|\geq a]} |f_n| d\mu=0$. Here is how I thought about it: Since $|f_n|\leq g$, and $g$ is integrable, then each $f_n$ is integrable. Thus, for each $n$, $|f_n| I_{[|f_n|\geq a]}\leq |f_n|$ and $|f_n| I_{[|f_n|\geq a]}\rightarrow 0$ almost everywhere, thus, by Lebesgue dominated convergence theorem, we have 
$\underset{a\rightarrow\infty}\lim\int_{[|f_n|\geq a]} |f_n|d\mu=0$ for each $n$, and hence, 
$$0=\sup_n \lim_{a\rightarrow\infty}\int_{[|f_n|\geq a]}|f_n|d\mu=\lim_{a\rightarrow\infty}\sup_n\int_{[|f_n|\geq a]}|f_n|d\mu.$$ However, I am not so sure about the last step of interchanging the limit and supremum? Any thoughts?","['probability-theory', 'uniform-integrability', 'measure-theory', 'real-analysis']"
1191631,"True or False: If sets $A$ and $B$ have a maxima, and $A \cap B \neq \emptyset$, then $A \cap B$ has a maxima","I am almost certain that the statement in the title is True, but am not 100% sure how to prove it, or if my conclusion is valid. My reasoning is that since $A$ and $B$ both have a maxima, then they have an upperbound which belongs to their respective sets. As such, we can think of $A$ and $B$ as closed intervals, and their instersection should then also at least be bounded above, and closed from the right side. Is my line of thinking correct, is there anything I have missed?",['real-analysis']
1191650,Continuity of a rational function,"I have to evaluate the continuity of a two functions at a couple of different points and I am a bit stuck. Here are the two functions: $f(x,y) = 0$ if $(x,y)=(0,0)$, $f(x,y) = \frac{x^3y^2}{3x^4+2y^2}$ if $(x,y) \neq (0,0)$. I want to evaluate the continuity of this one at $(0,0)$ and $(1,0)$. I also have $f(x,y) = 0$ if $(x,y)=(0,0)$, $f(x,y) = \frac{y^3x}{x^2+y^6}$ if $(x,y) \neq (0,0)$. I want to evaluate the continuity of this one at $(0,0)$ and $(0,1)$. Okay, so for both of these functions at $(0,0)$ the denominator is zero along $3x^4+2y^2$ and $x^2+y^6$, respectively, so I cannot simply evaluate the limit of a sequence approaching points along this line to determine the limit. Everywhere else however, including $(1,0)$ the limit exists and is hence continuous. In my class, we did two similar examples, but both denominators were of the form $x^2+y^2$. It was easy to show that for one example, you get a different limit for various sequences approaching the origin, hence the limit DNE. For the other example, we proved a limit existed by using the squeeze theorem. But both ways seemed more to be like tricks to me. How am I supposed to know what to do here without any experience?","['multivariable-calculus', 'continuity', 'limits']"
1191651,Solving Systems of Linear Differential Equations by Elimination,"For a homework problem, we are provided: $\frac{dx}{dt}=-y + t$ $\frac{dy}{dt}=x-t$ Putting these into differential operator notation and separating the dependent variables from the independent: $Dx-y=t$ $Dy-x=-t$ My first inclination is to apply the D operator to the second equation to eliminate Dx and get: $D^2y+y=t-1$ I solve the homogenous part and end up with $y_c=C_1\cos(t) + C_2\sin(t).$ Using annihilator approach and method of undetermined coefficients, I determine that $y_p=t-1$. General solution for $y(t) = C_1\cos(t)+C_2\sin(t)+t-1$. After plugging $y$ into the second equation, I get $x(t)=-C_1\sin(t)+C_2\cos(t)+1+t$ Checking my answer against the back of the book, they show:
$x(t) = C_1\cos(t)+C_2\sin(t)+t+1$ and $y(t)=C_1\sin(t)-C_2\cos(t)+t-1$ I can't seem to find what I did wrong.  Chegg solutions shows to eliminate y instead of x, and got the book's solution.  Does the variable chosen for elimination matter?  Halp!","['ordinary-differential-equations', 'systems-of-equations']"
1191652,Equilateral triangle in a circle,"Suppose you have a circle and consider three disjoint $60$ degree arcs $A,B,C$ in the circle. (i.e the arcs $A,B,C$ are separated by three arcs $x,y,z$ (with $x+y+z=180$ degrees and $x,y,z>0$)). Now take the chords on $x,y,z$. Call them $X,Y,Z$ respectively. Prove that the triangle that has its vertices at the midpoints of $X,Y,Z$ is an equilateral triangle.",['geometry']
1191668,probability set theory proof,"Denote by A, B and C subsets of the sample space Ω, Please advice me on my solutions below as I am unsure and help me answer the part iii. (ii) if P(A) > 0,P(B) > 0, and A,B are mutually exclusive, then are A and B independent? I did: If A and B are mutually exclusive then $P(A\cap B)=0$ as $(A\cap B)=\phi$ Since, $P(A\cap B)=0\ne P(A)P(B)> 0$  as $ P(A),P(B) > 0.$ It implies A and B are dependent. (iii) if A, B, C are (mutually) independent, prove that $A^c, B^c $ and $ C^c$ are (mutually) independent. I did: $P(A\cap B\cap C)=P(A)P(B)P(C).$ $((A∩B)∩C)^c=(A\cap B)^c\cup C^c=A^c\cup B^c\cup C^c - $ DeMorgan's Laws $P((A∩B)∩C)^c=1-P(A)P(B)P(C)=P(A^c\cup B^c\cup C^c)=P(A^c)+P(B^c)+P(C^c)$ I don't know what to do from now on. Please help. Also advice on the above solution.","['elementary-set-theory', 'probability']"
1191691,Solve a PDE with Feynman-Kac Formula,"So there is the following PDE given: $\frac{\partial}{\partial t}f(t,x) + rx\frac{\partial}{\partial x}f(t,x)+\frac{\sigma^2 x^2}{2}\frac{{\partial}^2}{\partial x^2}f(t,x) = rf(t,x)$ With boundary condition $f(T,x) = x^{\frac{2r}{\sigma^2}}$ Here $r$ and $\sigma$ are positive constants. From what I have learned, I the solution is from the boundary condition $f(t,x) =e^{-r(T-t)}E[x^{\frac{2r}{\sigma^2}}]$ So first I look fro the stochastic representation which I find as: $dX(t) = rdt + \sigma dW(t)$ with X(t) = x The solution is: $X(T) = x + r(T-t) + \sigma(W(T)-W(t))$ This is normally distributed with mean $x + r(T-t)$ and variance $\sigma \sqrt{T-t}$ Now from boundary condition I have $f(t,x) =e^{-r(T-t)}E[(x + r(T-t) + \sigma(W(T)-W(t)))^{\frac{2r}{\sigma^2}}]$ However I don't know if this method is correct. If it is correct, how should I calculate this expectation? By the way, I take this expectation under $Q$ martingale measure. Thanks","['stochastic-calculus', 'ordinary-differential-equations', 'partial-differential-equations']"
1191702,Prove that $A \subseteq B$ if and only if $A \cap \overline{B}=\emptyset.$,"Prove that $A \subseteq B$ if and only if $A \cap \overline{B}=\emptyset.$ Proof: Since $A \cap \overline{B}$ implies that $x \in A$ but $x \notin B$, whilst $A \subseteq B$ implies that $x \in A$ and $x \in B$, we have a contradiction, since $x \in B$ and $x \notin B$. Thus, $A \cap \overline{B}=\emptyset.$ Is this sufficient? How else can this be proved?",['elementary-set-theory']
1191714,What are criteria to tell when the point spectrum is discrete?,"Are there some criteria to tell when the point spectrum of a linear operator is discrete? In general it is not the same (take the spectrum of the ""annihilation"" operator). More specifically, what are the conditions that should be satisfied by a symmetric (or even self-adjoint) operator to have ""point spectrum"" = ""discrete spectrum""?","['spectral-theory', 'functional-analysis']"
1191715,Is there any difference between $\subset$ and $\subseteq$ [duplicate],"This question already has answers here : $\subset$ vs $\subseteq$ when *not* referring to strict inclusion (4 answers) Closed 2 days ago . If we write $A \subset B$ and $B \subset A$ then we can assert that $A = B$ and the same goes for $A \subseteq B$ , $B \subseteq A$ ... So then what is the essential difference between these two notations?",['elementary-set-theory']
1191727,Do any of these sequences have infinitely-many distinct iterates under run-length substitution?,"Let 
$$S = \{x \in \{1,2\}^\mathbb{N}: \ \text{every run in }x\text{ has finite length}\}$$
and define
$$T: S\to \mathbb{N}^\mathbb{N}
$$
such that for any $x\in S$, ${T}x$ is the sequence of run-lengths in $x$; that is, $Tx$ is the result of replacing each (maximal) run by its length. The $T$-iterates of $x$ (when they exist) are then $x, Tx, T^2x, T^3x,...$ Terminology :  Given an infinite sequence $x$, a run in $x$ is any subsequence of $x$ comprising one or more contiguous equal elements. A run is called maximal if it is not adjacent to an element equal to those in the run. If a run has finitely many elements, then their number is called the length of the run; otherwise, the length of the run is said to be infinite. Question : Is there any $x \in S$ having infinitely-many distinct $T$-iterates? If ""no"", how to prove? If ""yes"", how to construct an example? I suspect that no $x\in S$ has infinitely-many distinct iterates, and that every $T$-trajectory either terminates at some iterate not in $S$, or eventually enters a cycle (as in the following examples). Each point in $S$ has exactly two immediate $T$-predecessors, and these are mutual ""complements""; i.e., for any $x\in S$, there exist exactly two points in $S$, say $w$ and $\overline{w}$, such that $Tw = T \ \overline{w} = x$, where $\overline{w}$ is the result of replacing (in  $w$) each $1$ by $2$ and vice versa. (Consequently, in the above picture, it must be the case that $y=\overline{z}$ and $q=\overline{t}$. This applies to the numerical examples given below in $1b$.) The question can be formally restated by partitioning $S$ as follows: $$S = (A_{1a} \cup A_{1b}) \cup A_2$$
where (with $i,j,k$ restricted to nonnegative integers)
$$\begin{align}
A_{1a} & = \{x \in S : \exists i (T^i x \notin S)  \}\\
A_{1b} & = \{x \in S : \forall i (T^i x \in S) \ \mathrm{and} \  \exists\ j\ne k \ (T^jx = T^kx)  \}\\
A_2 & = \{x \in S : \forall i (T^i x \in S) \ \mathrm{and} \  \forall\ j\ne k \ (T^jx \ne T^kx)  \}.
\end{align}
$$ In other words, for any infinite sequence $x\in S$, iterating $T$ repeatedly must result in exactly one of the following cases: $x$ has only finitely-many distinct iterates in $S$. 1a. The iterations terminate due to an iterate that's not in $S$ (i.e., it has some element that's neither $1$ nor $2$, and/or it has a run of infinite length). E.g., $1112...\to 3...$, or $121212...\to 1^\infty$. 1b. All iterates remain in $S$, but there are only finitely many of them (i.e., they eventually enter a finite cycle). E.g., the two Kolakoski sequences are the only 1-cycles (fixed points) of $T$: 
$$12211212212211211221211212211... \to 12211212212211211221211212211...\\
 2211212212211211221211212211... \to 2211212212211211221211212211... 
$$
Using the first of these two, here's an example corresponding to the above picture: 
$$\begin{align}
     &.\\
     &.\\
\to\ v =\ &22122112112212112112212212112...\\
\to\ w =\ &21221221121221211211221221211...\\
\to\ x =\ &11212211211212212112212211212...\\
\to\ y =\ &21122121121122122112122121122... \ (= \overline{z}) \\
\to\ z =\ &\mathbf{12211212212211211221211212211}...\\
\to\ z \to\ &z\ \to \ ...
\end{align}
$$ 
By starting with the first element of each sequence of a cycle, then working ""backwards"", it's straightforward to construct cycles of arbitrary finite size; e.g., here's a 3-cycle construction (with labels corresponding to the above picture): 
$$\begin{align}
     &.\\
     &.\\
\to\ p =\ &211221221211211221211212211211212212112212211...\\
\to\ q =\ &122121121221121122121121122122121121221121121...\ (= \overline{t})\\
\to\ r =\ &\mathbf{121121122122112122121121122121121221121121221...}\\
\to\ s =\ &\mathbf{112122122112112122112112212112...}\\
\to\ t =\ &\mathbf{2112122121122122112\dots}\\
\to\ r =\ &\underline{121121122122}112122121121122121121221121121221...\\
\to\ s\ \to &\ t\ \to\ r\ \to\ s\ \to t\ \to\ r\ \to\ ...
\end{align}$$ $x$ has infinitely-many distinct iterates in $S$. Question : How to prove whether $A_2$ is empty? If $A_2$ is not empty, how to construct an example element? Since, for any $x \in \{1,2\}^\mathbb{N}$, an infinite run can occur only as a suffix, $S$ seems to have the same cardinality as the set of irrationals in the real interval $[0,1]$ (i.e. uncountably infinite); cf. all the reals in that interval except those with ""terminating"" binary expansions. On the other hand, although it seems that $A_{1b}$ is countable, I'm unsure of the cardinality of $A_{1a}$ (uncountable?). So I'm unable to deduce even the cardinality of $A_2$.","['dynamical-systems', 'sequences-and-series', 'recreational-mathematics', 'discrete-mathematics']"
1191728,Why don't we write $\nabla_{X}(fY) = f\nabla_{X}Y$ instead of $\nabla_{X}(fY) = f\nabla_{X}Y+ X(f)Y$ for affine connections?,"According to do Carmo, in Riemannian Geometry pages 49-50, he says let $\mathcal{X}(M)$ denote the set of all vector fields of class $C^{\infty}$ on $M$. Let $\mathcal{D}(M)$ denote the ring of all real-valued functions of class $C^{\infty}$ defined on $M$. An affine connection $\nabla$ on differential manifold $M$ is a mapping $\nabla : \mathcal{X}(M) \times \mathcal{X}(M) \rightarrow \mathcal{X}(M)$ which is denoted by $(X,Y) \xrightarrow{\nabla} \nabla_{X}Y$ and which satisfies the following properties: $\nabla_{fX+gY}Z = f\nabla_{X} Z+ g\nabla_{Y}Z$ $\nabla_{X}(Y+Z) = \nabla_{X}Y + \nabla_{X}Z$ $\nabla_{X}(fY) = f\nabla_{X}Y+ X(f)Y$ in which $X,Y,Z \in \mathcal{X}(M)$ and $f,g \in \mathcal{D}(M)$. The first property simply is linear in the first argument $X$ right? In that case, $X$ happened to be defined as $fX + gY$ So why is the second argument different? By argument, I mean if I write the covariant derivative like $\nabla (X,Y)$, I can clearly see the linearity stated in property 1. Then property 2 looks like property 1 in this regard in that it satisfies the addition property. But the multiplication part is different. Instead of yielding just $\nabla_{X}(fY) = f\nabla_{X}Y$ it yields $\nabla_{X}(fY) = f\nabla_{X}Y+ X(f)Y$. My Question: Why don't we write  $\nabla_{X}(fY) = f\nabla_{X}Y$? Why do we specify the product rule? Why is this important for affine connections? Remark: Consider the first property. We have $\nabla_{fX}Z=f\nabla_X Z$. That doesn't involve the product rule, does it? So why do we need it when we are applying it $\nabla_{X}(fZ)$?","['riemannian-geometry', 'differential-geometry']"
1191730,How to solve $\int\sqrt{1+x\sqrt{x^2+2}}dx$,"I need to solve $$\int\sqrt{1+x\sqrt{x^2+2}}dx$$ I've chosen the substitution variables $$u=\sqrt{x^2+2}$$
$$du=\frac{x}{\sqrt{x^2+2}}$$ However, I am completly stuck at $$\int\sqrt{1+xu} dx$$ Which let me believe I've chosen wrong substitution variables. I've then tried letting $u=x^2+2$ or simply $u=x$, but it does not help me at all solving it. Would someone please give me an hint on this ? Thanks.","['improper-integrals', 'integration']"
1191741,How can I find $\lim_{x \to 0}\left(\frac{e^{2\sin x}-1}{x}\right)$ without l'Hopital's Rule?,"How do I evaluate
$$\lim_{x \to 0}\left(\frac{e^{2\sin x}-1}{x}\right)$$ I know it's the indeterminate form since the numerator and denominator both approach 0, but I can't use l'Hopital's rule so I'm not sure how to go about finding the limit.","['limits-without-lhopital', 'calculus', 'limits']"
1191753,"Is there an isometry between $L^2([0,1])$ and $L^2(\mathbb{R})$?","I was wondering whether there can exist an isometric operator from a bounded $L^2([0,1])$ space to one with an unbounded interval, let's say $L^2(\mathbb{R})$? Both shall be equipped with the standard Lebesgue measure and the Borel sigma algebra.","['measure-theory', 'functional-analysis', 'real-analysis']"
1191759,Finding the roots of $(1 + i)^{\frac{1}{4}}$,"The professor says that the $n = 4$ roots of this are in the form: $\cos(\frac{\theta + 2k\pi}{n}) + i\sin(\frac{\theta + 2k\pi}{n})$, where $k = 0, 1, 2, 3$. So to find $\theta$, we find the $r = \sqrt{(1)^2 + (1)^2} = \sqrt{2}$ since $Re(1+i) = 1$ and $Im(1+i) = 1$. So $\sqrt{2}\cos\theta = 1$ and $\sqrt{2}\sin\theta = 1$, so the angle $\theta$ is $\frac{\pi}{4}$. However, if we do $k=0$, then we get that one of the roots is $1$, which is obviously not true since $1^4 \neq 1 + i$. The professor says that the solutions are: $k=1: \cos(\frac{9\pi}{16}) + i\sin(\frac{9\pi}{16})$, $k=2: \cos(\frac{17\pi}{16}) + i\sin(\frac{17\pi}{16})$, and $k=3: \cos(\frac{25\pi}{16}) + i\sin(\frac{25\pi}{16})$. I plugged these into WolfRamAlpha and rose them to the $4$th power, but none of them return the form $1+i$. What is incorrect about these steps?","['complex-numbers', 'complex-analysis']"
1191768,"If $f$ maps sets of measure zero to sets of measure zero, then so does $g(x)=x+f(x)$.","I want to prove the following. Let $f:[a,b]\to\mathbb{R}$ be continuous and non-decreasing, and suppose that $f$ maps sets of (Lebesgue) measure zero to sets of measure zero. Then, so does
  $$g(x)=x+f(x).$$ This is used in a proof in Rudin Real and Complex Analysis, but I can't understand the argument. He simply say that this ""follows easily"" from the fact that: ""If the $f$-image of some segment of length $\eta$ has length $\eta'$, then the $g$-image of that same segment has length $\eta+\eta'$."" I am able to prove that this statement is true, but how does that imply that $g$ maps null sets to null sets?","['measure-theory', 'real-analysis']"
1191776,Give an argument for $\int_{0}^{n} x^p dx \leq 1 +2^{p} + 3^{p} + \cdots+ n^{p}\leq \int_{0}^{n+1} x^p dx$,"For any $n$ and $p\geq 0$ give an argument that the following is true: $$\int_{0}^{n} x^p dx \leq 1 +2^{p} + 3^{p} + \cdots+ n^{p}\leq \int_{0}^{n+1} x^p dx$$ I'm having trouble even beginning this question. My first thought it to somehow meld this with the squeeze theorem, but, again, am not sure how to begin and show any real work. Any insight is very much appreciated.",['multivariable-calculus']
1191798,What is the proof that the rank of a matroid is sub-modular?,"Recall the definition of the rank of a matroid $(V, \mathcal{I})$: $$ r(A) = \operatorname{rank}(A) = \max_{I \in \mathcal{I}}\{ | A \cap I | \} = \max\{ |I| : I \subseteq A, I \in \mathcal{I} \}$$ I was trying to prove that the rank of a matroid is a sub-modular function, i.e. that the following inequality holds for all subsets of the ground set (i.e. $\forall A, B \subseteq V$): $$ r(A) + r(B) \geq r(A \cup B) + r(A \cap B)$$ I tried a ""picture proof"" by drawing a couple of sets and seeing how their intersection with independent elements behaved and I can only conclude that its in fact an equality. I am sure there is something wrong with that method and its not a real proof but wasn't sure how else to approach it. Does someone have a proof or a suggestion on good direction I might try to actually prove this result? Also, is this suppose to be ""intuitively obvious""? Because its not completely obvious for me.","['matroids', 'functions']"
1191800,"Principal bundles, connection forms and fundamental vector fields","Suppose $\pi:P\rightarrow M$ is a principal bundle, $\omega\in \Omega^1(P;\mathfrak{g})$ is the connection one form and $\sigma(\cdot)$ is the fundamental vector field associated to some vector field in $\mathfrak{g}$. That is, for $X\in \mathfrak{g}$, the value of $\sigma(X)$ at $p\in P$ is given by $
\begin{align*}
\sigma(X)_p=\frac{d}{dt}\bigg|_{t=0}p\exp(tX).
\end{align*}$ I am reading through some lecture notes at the moment and the author decomposes a vector field $u\in \mathfrak{X}(P)$ in to its horizontal and vertical components. So $u=u_v + u_h$. The author then takes the derivative $u_v f$ of some function $f$ defined on $P$. They make the argument that since this derivative at a point $p\in P$ depends only on the vector $u_v$ at $p$, they may assume $u_v = \sigma(\omega(u))$. I understand the idea of the derivative only depending on the vector at $p$. However, I am stuck on how they can assume that $u_v=\sigma(\omega(u))$. I don't understand how $u_v$ at $p$ is equal to $\sigma(\omega(u))$ at $p$. If anyone could help that would be greatly appreciated. Thanks! EDIT: Thanks very much for your detailed response. I have a few questions 1) Why have you written that map as $\rho_p$ instead of $L_p$? Isn't it just left multiplication? On that note, is it kosher to define left multiplication on $P$? 2)Is the reason $\sigma(X)_p=(\rho_p)_{*,e}X$ because $X=\frac{d}{dt}\big|_{t=0}\exp(tX)$, so $(\rho_p)_{*,e}X=(\rho_p)_{*,e}\frac{d}{dt}\big|_{t=0}\exp(tX)=\frac{d}{dt}\big|_{t=0}p\exp(tX)=\sigma(X)_p$?? 3) Why does $R_g$ and $\delta_g$ being diffeomorphisms imply  $\rho_p$ has constant rank? Why did you go to the effort of adding $g$ and $g^{-1}$? 4) Why does dim$V_p$=dim$\mathfrak{g}$ imply the map is surjective? I'm thinking that's just something from linear algebra I'm forgetting? Thank you again!","['principal-bundles', 'lie-algebras', 'differential-geometry', 'manifolds', 'lie-groups']"
1191809,A nonempty class of isomorphic groups defines a group,"The context of this question is from the definition of the sporadic Mathieu group $M_{23}$, which (in one possible definition) is the stabilizer of a point in $M_{24}$, which is a certain subgroup of $S_{24}$ (a permutation group on $24$ points). When I read this I was a bit surprised since they haven't specified which point is to be stabilized, but I assume that the content here is that it doesn't matter, since different stabilizers yield isomorphic subgroups. Which brings me to the question: is it possible to define a single group given a set of isomorphic groups? Of course in this case we could define $M_{23}$ as the stabilizer of the first point, assuming that the $24$ original points are distinguishable to begin with, for example if they were the numbers $1,\dots,24$ and I could pick out $1$ specifically. But in more general contexts this can be problematic, especially for sets which have no distinguished members, such as the set of all free ultrafilters of $\Bbb N$. If I have a family $(G_i)_{i\in I}$ of groups for some nonempty index set $I$ such that $G_i\cong G_j$ for all $i,j\in I$, is it possible to define a group $G$ such that $G\cong G_i$ for all $i$? By the observation above, if there is some term $x$ for which $x\in I$ is provable, then it would suffice to take $G=G_x$, but what if there is no such $x$?","['elementary-set-theory', 'foundations', 'logic', 'group-theory']"
1191818,why does e raised to the power of negative infinity equal 0?,"Why is it that e raised to the power of negative infinity would equal 0 instead of negative infinity? I am working on problems with regards to limits of integration, specifically improper integrals and a little confused as to what things approach infinity our negative infinity versus approaching zero","['exponentiation', 'calculus', 'infinity', 'limits']"
1191826,Can anyone tell me if this is correct?,"Suppose that the temperature of a metal plate is given by $T(x; y) = x^2 +2x+y^2$, for points $(x, y)$ on the elliptical plate defined by $x^2 + 4y^2 <= 24$.
Find the maximum and minimum temperatures on the plate. This is what i have done so far. Finding critical point:
$T(x)=2x+2$, $T(y)=2y$. Equating to $0$, $x=-1$, $y=0$.
Critical point is $(-1,0)$ and is a minimum. On the boundary,   $  x^2 + 4y^2 = 24$ $g(x,y)=x^2 + 4y^2$ $g(x)=2x, g(y)=8y$ $2x+2=A2x$---------(1) $2y  =A8y$---------(2) $x^2+4y^2=24$------(3) When solving from equation 1 and 3 im getting $ x=-1,y=|(23/4)^{0.5}|,$ and $x=|24^{0.5}|, y=0$ and when from eqn 2 and 3 im getting $x=|24^{0.5}|,y=0, A= 0.25 , x=-4/3, y=|(50/9)^{0.5}|$. Is this correct? am getting different values when using equation $1$ and $2$.","['multivariable-calculus', 'lagrange-multiplier']"
1191847,Tangent space of tangent vector,"Let $M$ be a smooth manifold. There's a (split) short exact sequence $$0\to T_aM\to T_v(TM)\stackrel {D_v}{\to} T_aM \to 0,$$
where $v\in TM$ and $a=\pi(v)\in M$. I'm trying to understand what this exact sequence means, but I don't even have an intuition about $T_v(TM)$. Can someone explain an example of tangent space of tangent vector (e.g. tangent vector of $S^1$)? How to take a tangent vector of a tangent vector geometrically?","['differential-topology', 'manifolds', 'differential-geometry']"
1191886,Why are the countable ordinals a set?,"The countable ordinals are themselves either countable or uncountable.  They cannot be countable since that would involve a set with itself as an element, so they are uncountable. If they are uncountable, then either they form a consistent totality or they are a proper class.  If they form a consistent totality, then a least uncountable ordinal exists, otherwise not. So how is it determined that the sequence of countable ordinals is or is not a consistent totality?  My problem is that it cannot be said they form a consistent totality because there is an uncountable limit ordinal since that would be circular.  Therefore, how exactly is this resolved? Edit, as requested: My question is not equivalent to the question, ""What axioms are you using?  ZFC?""  Nor is it answered by (I haven't figured out how to format the symbols on this site so I'll just spell it out): ""The set of all countable ordinals is the set of those elements x of the cardinal number two to the aleph-null such that x is a countable ordinal"", which seems to be a way of saying x is a countable ordinal if it is a member of the set of countable ordinals, except two to the aleph-null is a number: it is not a set but the cardinality of a set, so it doesn't actually have elements.  I suppose the intention of that answer could be taken as that all countable sets are elements of the power set of N, except the assertion isn't true.  Nor is my question addressed by comments to that answer.  So far as I can tell, the answerer did not define omega plus one, nor have I ever seen two to the aleph-null described as an ordinal.  Besides which, the relation of the cardinal number two to the aleph-one to the limit ordinal omega-one is outside ZFC.  So I honestly don't see what any of this has to do with my question or why I was asked to edit it accordingly.","['ordinals', 'elementary-set-theory']"
1191889,Residue of two functions,"Let be $f,g$ functions analytic in $z_0$, with $z_0$ a zero of order one of $g$ and $f(z_{0})\neq 0$. Show that 
$$
\operatorname{Res}\Bigl(\frac{f}{g},z_0\Bigr)=\frac{f(z_{0})}{g'(z_{0})}
$$
My attemp... If $z_{0}$ is a zero of order one of $g$, then $g(z)=(z-z_{0})h(z)$, with $h(z)$ analytic and $h(z_{0})\neq 0$, then by analyticity of $g$ and $h$: $g'(z)=h(z)+(z-z_{0})h'(z)$. So, 
$$
\frac{f(z_{0})}{g'(z_{0})}=\frac{f(z_{0})}{h(z_{0})+0}=\lim_{z\to z_{0}}{(z-z_{0})\frac{f(z)}{g(z)}}
$$ 
But in the ultimate point I'm not sure",['complex-analysis']
1191899,Homotopy equivalence between O-O and $\theta$,"Show that the dumbbell O-O (where there's no space between the ""O"" and ""-"") and the letter $\theta$ are homotopy equivalent, using the definition. So, let $X$ be the set of points in the dumbbell, and $Y$ the set of points in $\theta$. We should give continuous maps $f:X\rightarrow Y$ and $g:Y\rightarrow X$ such that $f\circ g$ is homotopic to $\text{id}_Y$ and $g\circ f$ is homotopic to $\text{id}_X$. I'm thinking about mapping the ""-"" in the dumbbell to the $-$ in $\theta$, and the two ""O""s in the dumbbell to the two halves of $\theta$. But each end of the ""-"" in the dumbbell is connected to only one half, while each end of the $-$ in theta is connected to both halves. So I'm not sure what to do.","['general-topology', 'homotopy-theory']"
1191901,Floor function of a factorial,"Compute $$\left\lfloor \frac{1000!}{1!+2!+\cdots+999!} \right\rfloor.$$ How can I start with the problem? I thought of dividing by some number, but then I thought that some small numbers when added could also give an integer. Thanks.","['factorial', 'algebra-precalculus', 'ceiling-and-floor-functions']"
1191923,"Second Countable, First Countable, and Separable Spaces","Upon further studying Topological Spaces, I understand: If a space $X$ has a countable dense subset, then $X$ is a separable space. A space $X$ is first countable provided that there is a countable local basis at each point of $X$. A space $X$ is second countable if and only if its topology of $X$ has a countable basis. My question is: Why would a space $X$ that is second countable also be first countable and separable? Why would a space $X$ that is first countable not necessarily be considered a separable space and vice versa? I do have a rough idea as to why a second countable space is also a first countable space. A second countable space has a countable basis $\mathcal{B}$ $-$ which consist of a countable family of open sets $-$ then the members of $\mathcal{B}$ which contain a particular point $a$ form a countable local basis at $a$. Thus each second countable space is first countable. Now if the space $X$ is second-countable, to also be separable, there needs to exists a countable dense subset of $X$. It has been established that if $X$ is a second countable space, it has a countable basis $B$. This is where I get stuck. I am not sure as to why spaces that are first countable do not imply they are separable and vice verse. Does it have to do with the fact first countable spaces deal with countable local basis that may or may not be dense? Am I on the right track? Sorry for the rather long question. If is it rather confusing, let me know so I can clarify. I want to thank you in advance for taking the time to read this question. I greatly appreciate any assistance you provide.","['general-topology', 'separable-spaces', 'first-countable', 'second-countable']"
1191924,Is it true that every element of $V \otimes W$ is a simple tensor $v \otimes w$?,"I know that every vector in a tensor product $V \otimes W$ is a sum of simple tensors $v \otimes w$ with $v \in V$ and $w \in W$. In other words, any $u \in V \otimes W$ can be expressed in the form$$u = \sum_{i=1}^r v_i \otimes w_i$$for some vectors $v_i \in V$ and $w_i \in W$. This follows from the proof of the existence of $V \otimes W$, where one shows that $V \otimes W$ is spanned by the simple tensors $v \otimes w$; the assertion now follows from the fact that, in forming linear combinations, the scales can be absorbed in the vectors: $c(v \otimes w) = (cv) \otimes w = v\otimes (cw)$. My question is, is it true in general that every element of $V \otimes W$ is a simple tensor $v \otimes w$?","['abstract-algebra', 'tensor-products', 'linear-algebra', 'exterior-algebra', 'multilinear-algebra']"
1191931,Length from tangent circles,"A circle $Γ_1$ of radius $25$ is externally tangent to a circle $Γ_2$ of radius $16$ at $C$. Let $AB$ be a common direct tangent, so that $A$ lies on $Γ_1$ and $B$ lies on $Γ_2$. Draw the tangent to $Γ_1$ that is parallel to $AB$; let this tangent intersect $Γ_1$ at $T$, and the common transverse tangent through C at $U$. Then find the  length of $TU $. From where do I start the problem. I tried drawing some perpendiculars, but I don't think it helps.","['geometry', 'circles', 'contest-math']"
1191941,Exterior derivatives involving representations,"I have two questions regarding the exterior derivative of vector valued forms when representations are involved: Suppose $V$ is a vector space, $M$ a smooth manifold and $\omega$ is a $V$ valued $k$-form on $M$. Ie, $\omega \in \Omega^k(M;V)$. Suppose furthermore that $\rho_1:G\rightarrow GL(V)$ is a representation for some Lie Group $G$ and $\rho_2:\mathfrak{g}\rightarrow GL(V)$ is the induced Lie algebra representation. The function $\rho_1(g)\circ \omega$ could be considered as a $V$ valued $k$-form on $M$. If $d:\Omega^k(M;V)\rightarrow \Omega^{k+1}(M;V)$ is the exterior derivative for $V$ valued $k$-forms, then $d(\rho(g)\circ \omega)=\rho(g)\circ d\omega$. I am just wondering why this is true? Furthermore, in some lecture notes I'm reading the author also writes for $\eta\in \Omega^1(M;\mathfrak{g})$ that $d(\rho_2(\eta)\circ \omega)=\rho_2(d\eta)\circ \omega-\rho_2(\eta)\wedge d\omega$ I am completely in the dark as to how this equation makes sense. I don't understand how the RHS is a 2-form or where the RHS even comes from. How would you make sense of this equation?","['lie-algebras', 'differential-geometry', 'differential-forms', 'manifolds', 'lie-groups']"
1191945,Problem with definite integral $\int_{0}^{\frac{\pi}{6}}\cos x\sqrt{1-2\sin x} dx$,$$\int_{0}^{\frac{\pi}{6}}\cos x\sqrt{1-2\sin x} dx$$ The question says 'evaluate the integral using the suggested substitution. It gives $u=\cos x$. But I think Let $u=1-2\sin x$ is better. $$\int_{0}^{\frac{\pi}{6}}\cos x\sqrt{1-2\sin x} dx$$ $$u=1-2\sin x$$ $$du=-2\cos x dx$$ $$=-\frac{1}{2}\int_{1}^{0}\sqrt{u}du$$ $$=\frac{1}{2}\int_{0}^{1}\sqrt{u}du$$ $$=\left | \frac{u^{\frac{3}{2}}}{3} \right |_{0}^{1}$$ $$=\frac{1}{3}$$ My question is how to solve it by using $u=\cos x$. Can anyone show the solution for it? Thanks a lot!,"['definite-integrals', 'trigonometry', 'calculus', 'integration']"
1191982,Limit for sequence $a_{m+n}\leq a_m+a_n$,"Let $a_1,a_2,\ldots$ be a sequence of positive real numbers. Suppose that $a_{m+n}\leq a_m+a_n$ for all $n\geq 1$. Does $\lim_{n\rightarrow\infty}\dfrac{a_n}{n}$ always exist? From $a_{m+n}\leq a_m+a_n$ we know that $a_n\leq na_1$, so that $\dfrac{a_n}{n}\leq a_1$, which means the sequence $\dfrac{a_n}{n}$ is bounded both from above and below. But this is not enough to conclude that the limit exists.","['real-analysis', 'limits']"
1192008,Evan's Proof to Converse of Mean Value Property.,"The theorem state: If $u \in C^2(U)$ satisfies $$ u(x) = \frac{1}{|\partial B(x,r)|}\int_{\partial B(x,r)} u(y) dS(y)$$ for each ball $B(x,r) \in U$, then u is harmonic. The issue that I have is with the proof of the theorem. He asserts to show it by contradiction, to assume that $\Delta u > 0$. Then for $$\phi(r) =  \frac{1}{|\partial B(x,r)|}\int_{\partial B(x,r)} u(y) dS(y)$$ $$ 0 = \phi ' (r) = \frac{r}{n}\frac{1}{|B(x,r)|} \int_{B(x,r)} \Delta u(y) dy >0$$ a contradiction. My issue is that I'm pretty sure that we show $\phi ' (r) = 0$ in the opposite direction by using the fact that $u$ is harmonic in the first place, so I don't see how we can use that fact here, especially when we're assuming the opposite. I feel like there is something very sly going on here. Can someone explain the proof?","['partial-differential-equations', 'real-analysis']"
1192013,$\sum_{i=1}^{89} \sin^{2n} (\frac{\pi}{180}i)$ is a dyadic rational,"Last year's Euclid contest had a problem asking for the rational value of $\sum_{i=1}^{89} \sin^{6} (\frac{\pi}{180}i)$.  I tested this sum for different even powers, and the result was always a dyadic rational (meaning it is of the form $\frac{n}{2^m}$ for positive integers $n$ and $m$).  Can someone prove that $\sum_{i=1}^{89} \sin^{2n} (\frac{\pi}{180}i)$ is a dyadic rational for all positive integers $n$, or find a counterexample? More generally, is $\sum_{i=1}^{k} \sin^{2n} (\frac{\pi}{k}i)$ always a dyadic rational for positive integers $n,k$?","['trigonometry', 'sequences-and-series']"
1192045,Bisecting the area and perimeter,"In triangle $ABC$, $AB=16$, $AC=15$, and $BC=13$. Point $D$ is on $AB$, and point $E$ is on $AC$ so that $DE$ bisects both the area and perimeter of triangle $ABC$. (In other words, both $DA+AE$ and $DB+BC+CE$ are equal to half the perimeter.) Find $DE^2$.","['geometry', 'triangles']"
1192088,Rationalizing the fraction $\frac{1}{1-\sqrt2 -\sqrt3}$,"I'm having problem in rationalizing the following root with the fraction $$\frac{1}{1-\sqrt2 -\sqrt3}$$
Eventually after many tries, I found the solution which was : $$\frac{-\sqrt2 (1-\sqrt2 +\sqrt3 )}{4}$$
But I want to know if there's a specific method to use in a case like this.
Thanks","['rationalising-denominator', 'radicals', 'algebra-precalculus']"
1192121,Is a square of a prime ideal in a UFD always primary?,"More concretely, Let $R$ be a UFD and $\mathfrak{p}$ a prime ideal ideal of $R$. Does it always hold that $\mathfrak{p}^2$ is a primary ideal? I know that it always holds if $\mathfrak{p}$ is a principal ideal or a maximal ideal, so one needs only consider rings of Krull dimension $\geqslant 3$. I proposed this question mainly because I'd like to know how well-behaved a prime ideal of UFD could be.","['commutative-algebra', 'ideals', 'unique-factorization-domains', 'abstract-algebra']"
1192134,Locus of a midpoint,"Let $Γ_1$ be a circle of radius $4$, and let $Γ_2$ be a circle of radius $14$. The distance between the centers of $Γ_1$ and $Γ_2$ is $25$. Let $A$ be a variable point on $Γ_1$, let $B$ be a variable point on $Γ_2$, and let $M$ be the midpoint of $AB$. Let $S$ be the set of all possible locations of $M$. Then find the area of $S$. I am getting $81\pi$. See the figure With one of my friends, I got this.Let C1 be centered at $(0,0)$ and let C2 be $(25, 0)$. The points that will lie on the boundary of S are
1. Midpoint of (-4, 0) and (11, 0) i.e. (3.5, 0)
2. Midpoint of (4, 0) and (39, 0) i.e. (21.5, 0)
3. Midpoint of the tangents joining C1 and C2 Let the angle that the point of intersection of the tanget to circle C1 and C2 makes with the x axis be $\theta $ then
The point of intersection on C1 and C2 are
  $$(x_1, y_1) = (4\cos{\theta}, 4\sin{\theta})$$
  $$(x_2, y_2) = (25+14\cos{\theta}, 14\sin{\theta})$$ The equation of the tangent is
$$ y = -\frac{x}{\tan{\theta}} + c$$ Putting the above two points in the line equation and eliminating c gives
  $$ 10\sin{\theta} = -\frac{25 + 10\cos{\theta}}{\tan{\theta}}$$
  $$ 10\sin{\theta}\tan{\theta} = -25 - 10\cos{\theta}
   \frac{2}{\cos{\theta}} = -5
   \cos{\theta} = -\frac{2}{5}$$ This gives
  $$ \sin{\theta} = \pm \frac{\sqrt{21}}{5}$$ The two pairs of points of intersection in C1 and C2 are
  $$ (x_1, y_1) = (-\frac{8}{5}, \frac{4\sqrt{21}}{5})$$
  $$ (x_2, y_2) = (\frac{97}{5}, \frac{14\sqrt{21}}{5})$$
and
   $$(x_1, y_1) = (-\frac{8}{5}, -\frac{4\sqrt{21}}{5})$$
  $$ (x_2, y_2) = (\frac{97}{5}, -\frac{14\sqrt{21}}{5})$$ This gives the other two mid points as $(\frac{89}{10}, \frac{9\sqrt{21}}{5})$, $(\frac{89}{10}, -\frac{9\sqrt{21}}{5})$ Using all the mid points obtained and putting them into the ellipse equation
  $$ \frac{(x - x_1)^2}{a^2} + \frac{(y - y_1)^2}{b^2}$$
following are obtained
  $$ x_1 = \frac{25}{2}$$ and $$ y_1 = 0$$
 $ a = 9$ and $b=9$.
 Where is it wrong.($81\pi$ is wrong!) Please help, thanks.","['geometry', 'circles', 'locus']"
1192151,Prove complements of independent events are independent.,"Given a finite set of events $\{A_i\}$ which are mutually independent, i.e., for every subset $\{A_n\}$, 
$$\mathrm{P}\left(\bigcap_{i=1}^n A_i\right)=\prod_{i=1}^n \mathrm{P}(A_i).$$ show that the set $\{A_i^c\}$, that is the set of complements of the original events, is also mutually independent. I can prove this, but my proof relies on the Inclusion-Exclusion principle (as does the proof given in this question ). I'm hoping there is a more concise proof. Can this statement be proved without the use of the Inclusion-Exclusion principle?",['probability']
1192173,Probability - marbles without replacement,"Math is my weakest subject and I'm having a hard time trying to figure out what equation to use in this problem: A jar contains 5 purple balls, 10 pink balls, and 7 blue balls. If 3 balls are to be drawn successively without replacement. What is the probability of getting 2 purple balls and 1 pink ball? Ans: I tried doing (5/22)(4/21) & (10/22). But I don't think it's right... Any help is appreciated.","['statistics', 'probability']"
1192178,Curve in a product of tori,"Consider the curve $\gamma:\mathbb R\to (\mathbb R/\mathbb Z)^n$ given by $$\gamma(t)=(a_1t,\ldots,a_nt)$$ for generic real numbers $a_1,\ldots,a_n$. Is the image of $\gamma$ dense in $(\mathbb R/\mathbb Z)^n$?","['calculus', 'differential-geometry', 'general-topology', 'real-analysis', 'analysis']"
1192189,Maximum value of the absolute value of a holomorphic function,"Consider the holomorphic function $f(z) := \frac{1}{z}(e^z - 1) = \sum_{k=0}^\infty \frac{z^k}{(k+1)!}$ with $\text{Re}(z) \leq 0$ and let $g(z) := |f(z)|$. Show that the maximum of $g$ is attained at $z = 0$. I have solved this by the bruteforce method by setting $z = a + b i$, $a \leq 0$, $b \in \mathbb{R}$ and considering $g$ as a real-valued function $g(a,b)$.
By the maximum modulus principle I only considered the case $a = 0$ which drastically simplifies the task. However, this principle is only applicable for bounded domains. 
Can I also apply this here? Or is there another ""simple"" method that directly gives the answer?",['complex-analysis']
1192199,What is wrong with ${13 \choose 1}{4 \choose 2} \cdot {12 \choose 1}{4 \choose 2}$ as combinations for two pair in poker?,Let's consider two pairs in a 52 cards deck of poker where every person gets five cards. My idea to approach this problem is to take following steps: First pair There are ${4 \choose 2}$ combinations getting two cards of the same rank There are ${13 \choose 1}$ combinations of having a specific rank out of a suit Second pair There are still ${4 \choose 2}$ combinations to get two cards of the same rank However as one card per suit is gone we only have ${12 \choose 1}$ for each combination out of a suit Any card There are ${4 \choose 1}$ combinations getting one card out of the same rank There are ${11 \choose 1}$ combinations to getting one card out of a suit This would yield in: $$P(TP) = \frac{{4 \choose 2}{13 \choose 1} \cdot {4 \choose 2}{12 \choose 1} \cdot {4 \choose 1}{11 \choose 1}}{{52 \choose 5}}$$ According to wikipedia the correct probability would be calculated as: $$P(TP) = \frac{{13 \choose 2}{4 \choose 2}{4 \choose 2} \cdot {4 \choose 1}{11 \choose 1}}{{52 \choose 5}}$$ What is the mistake in my model and how could I think of the one provided in wikipedia?,"['binomial-coefficients', 'probability', 'combinations']"
1192241,How to row reduce a matrix with complex entries?,"I have been doing some practice questions for university, and one of them is regarding row reducing a complex matrix.
From what I can work out, I think (i could very well be wrong) that the first unknown (row 1) should be (1/32)(41i - 82)
And as such, the second unknown should be (-3-2i) - (2 + 2i)((1/32)(41i - 82)) However this looks messy, and is making me think i may have done it wrong. If someone could please let me know if i am correct or not, and if not, where i went wrong, i would be hugely grateful. Thanks heaps in advance
Corey","['matrices', 'complex-numbers', 'linear-algebra', 'gaussian-elimination']"
1192281,"Show that if $U \subseteq C$ and $V \subseteq C$ are both open and convex sets, then the set $U \cap V \subseteq C$ is open and convex as well.",I think you have to prove that as it is the intersection then both are in open and convex sets seeing as they are on their own. Don't really know how to put this down in notation though.,['analysis']
1192306,Define the Riemann integral via trapezoids instead of rectangles,"Let $I$ be an interval and $f\colon I \to \mathbb{R}$. Recall that $f$ is called Riemann-integrable with integral $s$ if the following is true: For all $\epsilon > 0$, there exists $\delta > 0$ such that for any tagged partition $x_0,\ldots,x_n$ of $I$ and $t_0,\ldots,t_{n-1}$ whose mesh is less than $\delta$, we have $$\left|\sum_{i=0}^{n-1} f(t_i) (x_{i+1}-x_i) - s\right| < \epsilon$$ The intuitive idea which leads to the Riemann integral is that you approximate the ""area under the curve"" by rectangles. However one could also start with the idea to approximate it via trapezoids. So one could try to define the ""trapezoid integral"" via: For all $\epsilon > 0$, there exists $\delta > 0$ such that for any  partition $x_0,\ldots,x_n$ of $I$ whose mesh is less than $\delta$, we have $$\left |\frac{1}{2} \sum_{k=0}^{n-1} \left( x_{k+1} - x_{k} \right) \left( f(x_{k+1}) + f(x_{k})\right) -s \right | < \epsilon$$ Would this ""trapezoid integral"" be equivalent to the Riemann integral in the sense that a function is trapezoid integrable iff it is Riemann integrable and the integral s are equal in this case? If not, is one more general than the other? If not: Is it possible to make a slightly different definition of the integral starting from the trapezoid idea such that one can state such a theorem? Is it also possible to generalize the idea to a Newton-Cotes approach and also get a clear connection to the Riemann integral Is this type of ""trapezoid"" integral (or a generalization) known in the literature? If so, do you have a reference which states and proves theorems about the relation to the Riemann integral? Note that I know the trapezoid Rule for approximating the Riemann integral but this is only for numerical approximations.","['integration', 'riemann-sum', 'reference-request', 'real-analysis', 'analysis']"
1192308,Putnam 2006 B1 Problem,"Show that the curve $x^{3}+3xy+y^{3}=1$ contains only one set of three distinct points, $A,B,$ and $C,$ which are the vertices of an equilateral triangle, and find its area. Yikes. Without knowing that this is the Folium of Descartes, it says the equation is reducible somehow... $$x^3 + 3xy + y^3 - 1 = 0$$ Is factorable somehow. I tried the cubic way, but it is still insane... $$(x - 1)(x^2 + x + 1) + y(y^2 + 3x) = 0$$ But that doesnt help any bit, I could change $3xy$ I suppose: $$\implies x^3 + xy + xy + xy + y^3 - 1 = 0$$ But that doesnt help either!","['calculus', 'algebra-precalculus', 'contest-math', 'elementary-number-theory', 'real-analysis']"
1192320,"If $A_i$ is a compact subset of a metric space $(X_i,d)$ where $i = 1,2$ to show that $A_1 \times A_2$ is compact in $X_1 \times X_2$.","If $A_i$ is a compact subset of a metric space $(X_i,d)$ where $i = 1,2$ to show that $A_1 \times A_2$ is compact in $X_1 \times X_2$. Proof: Let $\{(a_n ,b_n)\}$ be any sequence in $A_1 \times A_2$ . Then $a_n $ in $A_1$ has a convergent subsequence $a_{n_i} \to a$ and taking the sequence $b_{n_i}$ in $A_2$ we have a convergent subsequence $b_{n_{i_{j}}} \to b$ and also $a_{n_{i_{j}}} \to a$. Thus the sequence $\{(a_n ,b_n)\}$ have a convergent subsequence $(a_{n_{i_{j}}},b_{n_{i_{j}}} ) \to (a,b)$. Thus  $A_1 \times A_2$ is compact in $X_1 \times X_2$. Is my working correct??","['general-topology', 'metric-spaces']"
1192322,Strong Markov property of Bessel processes,"I am thinking about the following: If $(B_t)_{t \geq 0}$ is a  Brownian motion in $\mathbb{R}^3$, how can we show that the Bessel process (of order $3$) $(|B_t|)_{t \geq 0}$ has the strong Markov property? Any hints?","['probability-theory', 'stochastic-processes', 'markov-process', 'brownian-motion']"
1192339,How to prove whether the equation set has a unique solution?,"\begin{eqnarray}
\begin{cases}
\sin A \sin C-(\sin B)^2=0
\cr AC-B^2=0
\cr A+B+C-\pi=0
\cr A>0,B>0,C>0
\end{cases} \end{eqnarray} How to prove whether the equation set has a unique solution or not ?","['geometry', 'education', 'systems-of-equations', 'contest-math']"
1192347,Mapping vector spaces over two different fields?,"I was having linear algebra class and we have been discussing about a possible group homomorphism that might allow mapping between two vector spaces over two different fields This is also an extension of this question Suppose we have vector spaces $V$ and $W$ over some general field $\mathbb{F}_1$ and $\mathbb{F}_2$ and $T$ is a (linear) map from $V$ to $W$ In order to get around the issue of this vector space axiom becoming undefined because of c being in different fields $$T(c\mathbf{x})=cT(\mathbf{x})$$ What's the issue in doing this (adapting the definition of group homomorphism, where there are two groups $(G,@)$ and $(H,*)$ )? $$\phi (a @b)=\phi(a)*\phi(b)$$ to the context of vector space (where the fields are defined as $(\mathbb{F}_1,+,*)$ and $(\mathbb{F}_2,"",@)$ ) $$T(c_\mathbb{F_1}*\mathbf{x})=T(c_\mathbb{F_1})@T(\mathbf{x})=c_\mathbb{F_2}@T(\mathbf{x})$$ (The two cs are different because they are elements of different fields) It seems valid as long every element in $\mathbb{F}_2$ can be mapped from at least one in $\mathbb{F}_1$ . What subtleties have we overlooked? If this is valid is this still a linear algebra?","['vector-spaces', 'linear-algebra', 'group-theory']"
1192399,"Let $(X,\mathcal M, \mu)$ be a measure space, and $\mu_0$ the semifinite part of $\mu$. Show that there is a measure $\nu$ such that $\mu=\mu_0+\nu$.","This is Exercise 15c Chapter 1 from Folland. I know that if there is an $F\subseteq E$ with $0<\mu(F)<\infty$, then $\mu_0(E)=\mu(E)$. If $\mu(E)=\infty$, and $F\subseteq E$,$\mu(F)<\infty$ imply $\mu(F)=0$, then $\mu_0(E)=0$. I tried
$$\nu(E)=
\begin{cases}
0, & \text{if }\mu(E)=\mu_0(E)\\
\infty, & \text{otherwise}.
\end{cases}$$ This satisfies $\mu=\mu_0+\nu$, but it is not a measure.  If $\{E_n\}\subseteq\mathcal M$ is a collection of disjoint sets, and $\nu(E_n)=\infty$ for some $n$, and $\nu(E_m)=0$ for $m\ne n$ then
$$\sum_{n=1}^\infty \nu(E)=\infty,$$ but there are $F\subset\bigcup E_n$ such that $0<\mu(F)<\infty$, since such sets are contained in any $E_m$ distinct from $E_n$; so,
$$\nu\left(\bigcup_{n=1}^\infty E_n\right)=0.$$ Letting $\nu(E)=\infty$ if and only if $\mu(E)=\infty$ doesn't work either.  We only need a countable collection of sets of finite measure, such that the union has infinite measure to see that $\nu$ is not a measure in this case. So, I'm stuck.","['measure-theory', 'real-analysis']"
1192433,Infinite sequence series. Limit,"If $0<x<1$ and
$$A_n=\frac{x}{1-x^2}+\frac{x^2}{1-x^4}+\ldots+\frac{x^{2^n}}{1-x^{2^{n+1}}},$$
then $\lim_{n\to\infty} A_n$ is $$\text{a) }\ \dfrac{x}{1-x} \qquad\qquad \text{b) }\ \frac{1}{1-x} \qquad\qquad \text{c) }\ \frac{1}{1+x} \qquad\qquad \text{d) }\ \frac{x}{1+x}$$ How to do this? Not able to convert in any standard form.","['sequences-and-series', 'calculus', 'limits']"
1192438,$(1-\zeta_m)$ is a unit in $\mathbb{Z}[\zeta_m]$ if m contains at least two prime factors,"We know that for $m=p^r, 1-\zeta_m$ is a prime.Now suppose that m has at least 2 distinct primes appearing in its prime factorization,we need to show that $1-\zeta_m$ is a unit in its ring of integers $\mathcal{O}_{\mathbb{Q}(\zeta_m)}=\mathbb{Z}[\zeta_m]$. 
I tried proving that $N_{\mathbb{Q}}^{\mathbb{Q}(\zeta_m)} (1-\zeta_m)=\pm 1$ but got stuck in finding norm of $\zeta_m$. Some hint would be nice.","['commutative-algebra', 'algebraic-number-theory', 'number-theory']"
1192458,"Prove that if $a^p-b^p$ is divisible by $p$, then it is also divisible by $p^2$","$a$ and $b$ are natural numbers and $p$ is a prime number. Prove that if $a^{p}-b^{p}$ is divisible by $p$, then it is also divisible by $p^{2}$. My attempt: Based on Fermat's theorem $(a^{p}-a)$ and $(b^{p}-b)$ are divisible by p, therefore their difference is divisible by $p$. I.e.
$(a^{p}-a)-(b^{p}-b)=(a^{p}-b^{p})-(a-b)$ is divisible by $p$. Since the left hand side of this equation is divisible by $p$, the right hand side also should be divisible by $p$. Based on the problem's assumption $(a^{p}-b^{p})$ is divisible by $p$ therefore we conclude $(a-b)$ must be divisible by $p$. Now We can factorize $(a^{p}-b^{p})$
$$(a^{p}-b^{p})=(a-b)(a^{p-1}+a^{p-2}b+....+b^{p-1})$$
we have to prove $(a^{p}-b^{p})$ is multiple of $p^2$ which means we have to show the right hand side should be multiple of $p^{2}$. But $(a-b)$ is multiple of p therefore we have to show 
$(a^{p-1}+a^{p-2}b+\cdots+b^{p-1})$ is multiple of $p$ and I am stuck here. Any help would be appreciated.","['elementary-number-theory', 'lifting-the-exponent', 'algebra-precalculus']"
1192459,Help with the Basis Step of a strong induction proof,"I have to determine whether the following definition is valid and, if so, find a formula for $f(n)$. $f(0)=1$, $f(1)=0$, $f(2)=2$, $f(n)=2f(n-3)$ for $n \geq 3$ I know it is valid because I successfully get a result for $f(3)$, $f(4)$, $f(5)$ and so on from such a definition. I have also devised a formula which includes $2$ cases: $f(n) = 0$ when $(n \bmod 3) = 1$ and $f(n) = 2^{\lceil n/3 \rceil}$ otherwise. Now, the exercise asks to prove the formula and I see that I have to do it considering the $2$ separate cases and I guess that I can use strong induction. In fact, I am trying to use strong induction to prove the  first case but I am not sure about how to do it. So, the proposition $P(n)$ can be: $f(n) = 0$ when $(n \bmod 3) = 1$ for $n = 1, 4, 7, 10,...$ The Basis Step can be $f(1) = 0$, $f(4) = 0$, $f(7) = 0$ and then would come the Inductive Step. My question is about the Basis Step, I am not sure if it is defined correctly or if I should use a kind of recursive expression which is the subject in the book. I will very much appreciate your advice.",['discrete-mathematics']
1192493,Understanding the proof of Jordan-Hölder Theorem.,"I need some help to understand the proof of this theorem which can be found in the book Introduction to Representation Theory by Pavel Etingof, Oleg Golberg, Sebastian Hensel, Tiankai Liu, Alex Schwendner, Dmitry Vaintrob, and Elena Yudovina. Let $V$ be a finite dimensional representation of $A$, and $0=V_0\subset V_1 \subset  ...\subset V_n=V$, $0=V_0'\subset V_1' \subset  ...\subset V_m'=V$ be filtrations of $V$, such that the representations $W_i:=V_i/V_{i-1}$ and $W_i':=V_i'/V_{i-1}'$ are irreducible for all i. Then $n=m $, and there exists a permutation $\sigma$ of 1, ..., n such that $W_{\sigma (i)}$ is isomorphic to $W_i'$. First proof: (for k of characteristic zero). The character of V obviously equals the sum of characters of $W_i$, and also the sum of characters of $W_i'$ But by Theorem 2.17, the characters of irreducible representations are linearly independent, so the multiplicity of every irreducible representation $W$ of $A$ among $W_i$ and among $W_i'$ are the same. This implies the theorem. Second proof: (general) The proof is by induction on $\text{dim}V$ . The base of induction is clear, so let us prove the induction step. If $W_1=W_1'$ (as subspaces), we are done, since by the induction assumption the theorem holds for $V/W_1$. So asume $W_1\neq W_1'$. In this case $W_1 \cap W_1' = 0$ (as $W_1, W_1'$ are irreducible), so we have an embedding $f: W_1 \oplus W_1' \rightarrow V$. Let $U=V/(W_1 \oplus W_1')$ and $0=U_0 \subset U_1 \subset ... \subset U_p=U$ be a filtration of $U$ with simple quotients $Z_i=U_1/U_{i-1}$ (it exists by Lemma 2.8 in the book). Then we see that: 1) $W/W_1$ has a filtration with successive quotients $W_1', Z_1, ...,Z_p$ and another filtration with successive quotients $W_2. ..., W_n$. 2) $W/W_1'$ has a filtration with successive quotients $W_1, Z_1, ...,Z_p$ and another filtration with successive quotients $W_2'. ..., W_n'$. By the induction assumption, this means that the collection of irreducible representations with multiplicities $W_1. W_1', Z_1, ..., Z_p$ coincides on one hand with $W_1, ..., W_n$, and on the other hand, with $W_1', ..., W_n'$. We are done. I'm trying to complete some details and understand the proof. With respect to the proof 1. In this proof they claim that the character of $V$ is equals to the sum of the characters of $W_i$, and also the characters of $W_i'$. This means that each $W_i$ is not isomorphic to $W_j$ with $i \neq j $ as representation of $V$. The same happen with the $W_i'$ representations. Now, in the book we have the following definition: Let $A$ be an algebra and $V$ a finite-dimensional representation of $A$ with action $\rho$. Then the character of $V$ is the linear function $\chi_{V}: A \rightarrow k$ given by $$\chi_{V}(a)=tr|_{V}(\rho(a))$$ On this point I understand that the characters of irreducible representations are linearly independent, but I have a problem with the conclusion. Why this is possible? There is a note that says the following This proof does not work in characteristic $p$ because it only implies that the multiplicities of $W_i$ and $W_i'$ are the same modulo $p$, which is not sufficient. In fact, the character of the representation $pV$, where $V$ is any representation, is zero. With respect to the second proof. The base induction. If $\text{dim}V=1$, then we have $V$ has the filtration $0=V_0 \subset V_1=V$ (the reason is $V=\langle v\rangle$ where $v \in V$) then obviously any representation has the same length because any element $v \in V$ generates $V$ and $V/0$ is the same $V$. Right? Finally, I want to understand how works the embedding $f$ in the case when $W_1\neq W_1'$ Thanks.","['ring-theory', 'representation-theory', 'abstract-algebra', 'linear-algebra', 'group-theory']"
1192512,Upper bound on the distance of orthogonal matrices,"Dear math stackexchange users, I have a question on orthogonal matrices: suppose I have a matrix $X\in\mathbb{R}^{n\times n}$ and I consider the orbit of the orthogonal group $O(n)$ acting from the left on $X$: 
$$Orb= \{Y\in\mathbb{R}^{n\times n}\ |\ Y=OX, O\in O(n)\}.$$
Now let $\epsilon>0$ and suppose I have $OX\in Orb$ satisfying $\|X-OX\|_F\leq \epsilon$. If $I$ is the identity matrix, is there any way to give an upper bound on the distance $\|I-O\|_F$ in terms of $\|X\|_F$ and $\epsilon$? Of course, if I have an upper bound on $\|I-O\|_F$, then by submultiplicativity of the Frobenius norm this gives an upper bound on $\|X-OX\|$. However, is there anything for the other direction? The orthogonal group is a compact set and this gives a trivial upper bound. This one however, is not applicable in my problem. Thank you very much!","['differential-geometry', 'analytic-geometry', 'matrices', 'matrix-calculus', 'riemannian-geometry']"
1192515,Bijection on Preordered Sets Implies Homeomorphism,"Prove that if $X$ and $Y$ are finite, then the ""converse"" of one of my other questions Homeomorphism on a Preordered Set is true: if $h: X \to Y$ is bijective and satisfies  $\forall a,b \in X, \quad  (a \trianglelefteq_{\mathscr{S}}b \iff h(a) \trianglelefteq_{\mathscr{T}}h(b))$, then $h$ is a homeomorphism. We are assuming that $h$ is bijective, i.e., both one-to-one and onto. Our goal is to arrive at the conclusion that $h$ is continuous and has a continuous inverse in order to label it as a homeomorphism. I read somewhere that because $X$ and $Y$ are finite, then one-to-one and onto are equivalent, but I do not want to claim this and call it a day. Instead, I would like a more detail-oriented approach: Since $h$ satisfies $a \trianglelefteq_{\mathscr{S}} b \iff h(a) \trianglelefteq_{\mathscr{T}} h(b)$, then if $a \in \overline{\{b\}}$ in $\mathscr{S}$, then $h(a) \in \overline{h(b)}$ in $\mathscr{T}$. So a closed set in one topology gets mapped to another closed set in a separate topology. Wouldn't this show that $h$ is continuous? As for the pre-image, could I apply $h^{-1}$ to the condition that is satisfied to get $h^{-1}(a) \trianglelefteq_{\mathscr{S}} h^{-1}(b) \iff a \trianglelefteq_{\mathscr{T}} b$ since $h$ is bijective, i.e., it has an inverse? Thank you in advance for reading this post and for any assistance provided, it is greatly appreciated.","['general-topology', 'proof-writing', 'functions', 'order-theory']"
1192524,Does free bimodule exist?,"Let $R,S$ be rings and $A$ be a set. Does there exist a free $(R,S)$-bimodule $F(A)$ on $A$? How do I construct it? Is it just $\oplus_{i\in A} (R\times S)$?","['modules', 'abstract-algebra']"
1192583,Why we cannot simplify $\partial x$?,"First consider the formula: $$\frac{df}{dt}=\frac{df}{dx}\frac{dx}{dt}$$ As we can see, $dx$ can be simplified from the RHS to get the LHS. This can be explained like this: define $y=x'(c)(t-c)+x(c)$ the tangent of $x(t)$ at $c$. Then $dx$ in $df/dx$ is simply $\Delta x$, while $dx$ in $\frac{dx}{dt}$ is $\Delta y$. And since $\Delta x\approx \Delta y$ when $\Delta t$ is very small, we can simplify $dx$ in the above formula. Now consider the formula: $$\frac{\partial f}{\partial u}=\frac{\partial f}{\partial x}\frac{\partial x}{\partial u}+\frac{\partial f}{\partial y}\frac{\partial y}{\partial u}$$ where $x,y$ are functions with variables $u,v$ and $f$ is function with variables $x,y$. Of course we cannot simplify $\partial x$. I tried to use the same argument for $dx$, but it is more difficult to imagine. Maybe I need some exact definition of $\partial f$ and $\partial x$ (just a guess, maybe the definition is related to a tangent plane?) Thanks so much.","['multivariable-calculus', 'partial-derivative', 'calculus', 'derivatives']"
1192587,"Counterexamples for the Converse of ""Topological Conjugacy Implies Equal Topological Entropy""","Question: I would like to find two topological dynamical systems that are not topologically conjugate but nevertheless have the same topological entropy. Two topological dynamical systems $f:X\to X,g:Y\to Y$ are topologically conjugate if there is a homeomorphism $H:X\to Y$ such that $f\circ H=H\circ g$. If $X$ is a compact metric space and $f:X\to X$ is continuous, then $d_n(x,y):=\max\{d(f^k(x),f^k(y))|0\leq k\leq n-1\}$; $\forall \varepsilon>0, N(n,\varepsilon):=\max\{|\{p_1,...,p_m\}|=m|i\neq j \implies d_n(p_i,p_j)\geq\varepsilon\}$ (i.e., $N(n,\varepsilon)$ is the largest number of points $p_1,...,p_m\in X$ such that $i\neq j\implies d_n(p_i,p_j)\geq\varepsilon$); and $h(f):=\lim_{\varepsilon\to0}\limsup_{n\to\infty}\dfrac{1}{n}N(n,\varepsilon)$ is the topological entropy of $f$ (This is the definition of Bowen and Dinaburg, and it requires a metric. For a definition that works for the general setting see wikipedia ). Motivation: We know that topological conjugacy preserves topological entropy. But the converse is not true: first example that comes to mind is that $h(\sigma^+_k)=\log k=h(\sigma_k)$ but $\sigma^+_k\not\sim \sigma_k$, where $\sigma^+_k:\Sigma^+_k\to \Sigma^+_k$ is the topological Bernoulli shift and $\sigma_k:\Sigma_k\to \Sigma_k$ is the full shift. But it is immediate that these two systems are not conjugate (full shift is bijective, the other is not). So I am more interested in finding a counterexample where both of the systems are invertible, though any other counterexamples, either that use metric spaces or topological spaces, are welcomed.","['general-topology', 'dynamical-systems', 'metric-spaces']"
1192660,Riemann-Roch theorem without heavy tools,"I have read two proofs of Riemann-Roch : one very quick in Forster, Lecture on Riemann Surfaces which use cohomology of sheaf, and results from functional analysis. Another one is in the book of Miranda about Riemann surfaces, which is more elementary, but use lot of intermediate results and especially snake lemma. Each time I'm reading one of these proofs, I just can't convince myself that is true because I have to believe these results in functionnal analysis, or the snake lemma. To me it looks really like powerful and a bit mysterious results (even it's probably a basic result for most of mathematician). So my question is Can we find a reasonably short proof of Riemann-Roch which not use homological algebra or functional analysis and which is ""almost"" elementary ? I'm aware that this theorem is quite powerful so we probably need a bit of work or powerful theorem. But, what is the most ""effective"" proof which use not too much big results ?",['algebraic-geometry']
1192662,How can I prove the following set theory question? (Intersection left distributes over difference),"I have $$(A-B)∩C = (A∩C)-(B∩C)$$ and $A-B = \{x ∈ A ∧ x ∉ B\}$                    definition of difference, $(A-B)∩C = \{x ∈ A ∧ x ∉ B ∧ x ∈ C\}$      definition of intersection And now I'm stuck on trying to make it equal to the left side or vice versa? Could someone lead me into the right direction using the $""\{x ∈ \ldots \text{and }x∉ \ldots\}""$ notation? Thank you very much.",['elementary-set-theory']
1192684,Sum of factorial fractions,Find the sum $$\sum\limits_{a=0}^{\infty}\sum\limits_{b=0}^{\infty}\sum\limits_{c=0}^{\infty}\frac{1}{(a+b+c)!}$$ I tried making something like a geometric series but couldn't. Then I couldn't think of anything.,"['factorial', 'summation', 'calculus']"
1192688,Reducing eigenvalues of symmetric PSD matrix towards 0: effect on ratios of original matrix elements?,"Let $\boldsymbol{S}$ be $k \times k$ positive semi-definite real symmetric matrix with eigen decomposition $\boldsymbol{S} = \boldsymbol{X} \boldsymbol{\Lambda} \boldsymbol{X}'$ ($\boldsymbol{\Lambda}$ diagonal, $\boldsymbol{X}$ orthonormal matrix of eigenvectors). Assume that we reduce each eigenvalue $\lambda_i$ by $\psi_i \in [0, \lambda_i]$, for $i = 1, \ldots, k$ with $\lambda_i$ sorted so that $\lambda_i \ge \lambda_{i+1}$. Define our ratio of interest $r_{ij}^\psi$ in terms of elements of the new matrix $\boldsymbol{S}^{\psi}$: $$ r_{ij}^\psi = \frac{s_{ij}^\psi}{\sqrt{s_{ii}^\psi}\sqrt{s_{jj}^\psi}} = \frac{\sum_{l=1}^k x_{il} x_{jl} (\lambda_l - \psi_l)}{\sqrt{\sum_{l=1}^k x_{il}^2 (\lambda_l - \psi_l)} \sqrt{\sum_{l=1}^k x_{jl}^2 (\lambda_l - \psi_l)}}. $$ How does $r_{ij}^\psi$ change as $\psi_i$ grows? In particular, I am interested in the case when $\psi_i \ge \psi_{i+1}$ for $i = 1, \ldots, k$. Initially my numerical experiments delivered an increase in absolute value, but now I have found the cases that yield a decrease instead. I can formulate a counterexample for some subset of parameter values using the fact that columns of $\boldsymbol{X}$ are length one and orthogonal to each other (e.g., when $\lambda_k \approx 0$), so strictly speaking I'm done; but I wonder if it can be shown more generally and elegantly. (If $r_{ij}^\psi$ is thought as a correlation coefficient, then this problem has direct relation to statistics.)","['statistics', 'linear-algebra', 'eigenvalues-eigenvectors']"
1192701,Is it true that $(f\cdot g)\circ \phi=(f\circ \phi)\cdot(g\circ \phi)$?,"Let be $f,g,\phi: \mathbb{R} \longrightarrow \mathbb{R}$ Is it true that $(f\cdot g)\circ \phi=(f\circ \phi)\cdot(g\circ \phi)$? ($\cdot$ is the product of functions) Thanks!",['functions']
1192729,Express $\sqrt{3}\sin\theta - \cos\theta$ as: $a\cos (\theta + \alpha) $,Express $\sqrt{3}\sin\theta - \cos\theta$ as: $a\cos (\theta + \alpha) $ Can someone please explain to me how to go about doing this?,['trigonometry']
1192771,Galois representations and isogenies of elliptic curves,"Let $E$ be an elliptic curve over $\mathbb{Q}$. For each prime $\ell$, the action of $\mathrm{Gal}(\bar{\mathbb{Q}}/\mathbb{Q})$ on $E[\ell]$ (the group of $\ell$-division points of $E$) defines a representation
$$\rho=\rho_\ell:\mathrm{Gal}(\bar{\mathbb{Q}}/\mathbb{Q}) \longrightarrow \mathrm{GL}(2,\mathbb{F}_\ell). $$ Then how to prove that $\rho$ is reducible if and only if $E$ admits an isogeny of degree $\ell$?","['algebraic-geometry', 'elliptic-curves', 'galois-representations', 'number-theory']"
1192775,Crossing of strings,There are two strings of color red and blue. They are made to cross each other odd number of times (greater than one) without any self crossing. Is it always possible that there will be pair of crossings which are adjacent on both the strings ?,"['geometry', 'graph-theory', 'planar-graphs', 'curves']"
1192798,Large numbers and CLT: confusion over the behavior of the sum of iid random variable,"In a nutshell I am confused about the fact that the fluctuations of the sum behave as $ \sqrt n $ but the empirical mean converges (fluctuations here behave as $  \frac {1}{\sqrt n} $). Below my reasons for the confusion and a few examples that puzzle me. In the simplest version of the law of large numbers the empirical mean of n independent and identical (iid) random variables converges in probability to the mean u of the underlying true distribution as n tends to infinity. Now, I am tempted to say that as the sampling mean converges we can also say that the sum of n iid random variables converges to $n \cdot u$ or if we don't want to use the word 'converge' because there is still n in the limit we can say that the sum behaves as $n \cdot u$ . Is this right? Does this mean, for 1-D RV, that for $ n \rightarrow \infty $ only the sequences $ \{x_1, x_2, .., x_n\} $ whose terms sum to $n \cdot u$  survive? In fact, using the central limit theorem, say that the RV X has finite variance, the probability distribution of the sum approximates a normal distribution with mean $ n \cdot u $ and variance $ \sigma^2 \cdot n$, which really means that fluctuations keep growing with n. This means that for example if I toss n times a fair coin it's not actually true that for n going to infinity I'll surely get n/2 times tails and n/2 time heads (because that would mean that the value of the sum was fixed). Is this right? This feels slighty strange to me, because the empirical mean will almost surely (almost surely in an informal sense here) be u and yet the sum won't be $n \cdot u$ . In the same spirit, I can express the law of large numbers saying that the empirical probability $ \sum \delta(x - x_i)/n $ converges to $ P(x_i)$. Then consider a 1-d random walk of a particle on the x axis with step either -1 and 1 with equal probability starting from the origin. The mean squared distance will behave as n in the limit. If I say,  though, that in the limit $ N \rightarrow  \infty \Rightarrow n_-1 \rightarrow n/2 $ and $ n_+1 \rightarrow n/2 $, respectively the number of occurrences of step -1 and step +1, it seems obvious that for $ n \rightarrow \infty\ $ the particle will be in the origin and it's hard to understand how the mean distance could possible behave as $ \sqrt n $. This is wrong, isn't? In general, given X RV and P(X) with X well-behaved enough for some version of the the law of large numbers and CLT, can I say that the number of occurrences $ N_x = P(x)\cdot N $ as $ N \rightarrow  \infty $? I notice that people say this in many situations, I myself have done so without really thinking about it in a fair amount of occasions, and yet I have doubts now because the fluctuations in the number of occurrences grow with N. I study physics and I'm studying a bit of serious statistics and probability as part of a statistical mechanics course (just so you know my background). In many situations in statistical mechanics the energy of the system is a sum of many independent terms and it would be a disaster if the fluctuations grew with the numbers of terms. This adds to my confusion. Thanks in advance for any responses.","['probability-theory', 'law-of-large-numbers', 'probability-limit-theorems', 'central-limit-theorem']"
1192808,"Confusion with a function being ""onto"" and 1-1 correspondence.","If we are given an onto function $f : A \to B$, then this ensures that every element of $B$ corresponds to something in $A$. But does this necessarily mean that the number of elements in set $B$ equates to that of the number of elements in set $A$? My understanding is the answer to this is ""no"". If my understanding is correct, then given a 1-1 correspondence between two sets $A$ and $B$ (i.e 1-1 and onto) does THIS then imply that the number of elements in sets $A$ and $B$ are equal? Also, assume that $A$ and $B$ are finite sets. I do not want to necessarily talk about cardinality of infinite domains.","['elementary-set-theory', 'functions']"
1192815,Functions in $L^p$ spaces,"If I have a function $f:\mathbb{R} \rightarrow \mathbb{R}$ that belongs to $L^p(\mathbb{R})$ for all $p\geq 2$ including $p=\infty$, that is
$$f \in \bigcap_{p\in [2,\infty]} L^p(\mathbb{R})$$
and all the norms have the same bound, let us say that for all $p\geq 2$
$$\|f\|_p \leq C$$
and
$$\|f\|_\infty \leq C$$ Can we conclude that $f$ is also in $L^p(\mathbb{R})$ for $1< p <2$ and that 
$$\|f\|_p \leq C?$$","['inequality', 'calculus', 'integration', 'real-analysis', 'functional-analysis']"
1192839,Find the fraction that creates a repeating decimal that repeats certain digits,"Is there any way to find the fraction $x/y$ that, when converted to a decimal, repeats a series of digits $z$? For example: ${x}/{y} = z.zzzzzzzz...$ or with actual numbers, $x/y = 234.234234234...$ (z is 234) If this is impossible, is there a way that does the same but the value to the left of the decimal is not $z$?","['fractions', 'arithmetic', 'decimal-expansion', 'algebra-precalculus']"
1192853,Combinatorics and Probability- where am I wrong?,"Let there be a cube with $n$ sides denoted $1,...,n$ each. The cube is tossed $n+1$ times. For $1\le k\le n$, what is the probability that exactly $k$ first tosses give different number (i.e, the $(k+1)$-st toss give a number that was already gotten.) I really need to know why I got a slightly different answer from the official one. My attempt: Let us build a uniform sample space. $\Omega=\{a_i=(i_1,...,i_k)|1\le i_j\le n\}$. $|\Omega|=(n+1)^n$, $\forall \omega\in \Omega, P(\omega)={1\over |\Omega|}$.
We seek for the event $A=\{(i_1,...,i_k,i_{k+1},...,i_{n+1})|i_t\ne i_s, \forall 1\le t\ne s\le k, k\in \{i_1,...,i_k\}\}$. This is the problematic part: $|A|={n\choose k}\cdot k!\cdot k \cdot n^{n-k-1} $. (Then I and the answer use the formula for probability of an even it a uniform sample space.) The point is, the answer says: $|A|={n\choose k}\cdot k!\cdot k \cdot n^{n-k} $. I don't understand why; First I pick $k$ numbers, count all their permutations, then pick one of them for the $(k+1)$-th toss, and then I have $n-k-1$ tosses left, each of which has $n$ possibilities. I would appreciate your help.","['probability', 'combinatorics']"
1192876,"Is there an algebraic non-rational extension of the integers, whose set of prime elements contains the prime integers?",Let the ring $\mathbb{Z}[\alpha]$ with $\alpha$ an algebraic number. Let $P(\mathbb{Z}[\alpha])$ be the set of all the prime elements of $\mathbb{Z}[\alpha]$. Question : Is there $\alpha$ algebraic and non-rational such that $P(\mathbb{Z}) \subset P(\mathbb{Z}[\alpha])$?,"['prime-numbers', 'commutative-algebra', 'ring-theory', 'abstract-algebra']"
1192892,Evaluating $\int\frac{1}{5\cos x+\sin x+7}~dx$,Evaluating  $$\int\frac{1}{5\cos x+\sin x+7}~dx.$$ This can be done by substituting $$\sin x = \frac{2t}{1 + t^2}$$ and $$\cos x = \frac{1 - t^2}{1 + t^2}.$$ However after I substitute it I cannot simplify it to get anything easier to integrate. After substituting I got: integral $$\frac{1 + t^2}{2(t + 2)(t + 3)}$$ or $$\frac{1 + t^2}{12 + 2t^2 + 10t}.$$ Could someone give me a hint? Many thanks.,['integration']
1192922,$S_{n+1}$ not isomorphic to subgroup of $S_n \times S_n$,"I've been asked to prove that there is no injective homomorphism from $S_{n+1}$ to $S_n \times S_n$ for $n\ge4$. This seems to me to follow from the fact that $S_{n+1}$ cannot be recognized as a direct product of two of its subgroups, essentially because it has only one normal subgroup.  Are there any ways to do this via order considerations, as this was my first impulse upon seeing the problem.","['finite-groups', 'group-theory', 'abstract-algebra']"
1192924,Calculating the intersection of two spaces of polynomials,"This problem is driving me nuts. I feel like there should be an elementary argument, yet I have failed to find one. Consider the vector space $V_n=\mathbb Q[x]/{x^{2n+1}}=\mathbb Q\{1,x,x^2,\ldots, x^{2n}\}$. Define polynomials $p_m=x^m+(-1-x)^m+(-1-x)^{2n-m}$. Consider the subspaces of $V_n$ given by $$I=\mathbb Q\{p_m\,:\, 0\leq m\leq 2n\},$$ $$J=\mathbb Q\{x^{2i}\,:\,0\leq i\leq n\}$$ and $$K=\mathbb Q\{x^{2i}-x^{2n-2i}\,:\,0\leq i\leq n\}.$$ I want to prove that $$I\cap J= K.$$ Inclusion in the reverse direction is clear: $p_m-p_{2n-m}=x^m-x^{2n-m}$. The hard part is showing the inclusion $I\cap J\subset K$. Computer calculations show this is true for all $n$ I have checked. Update: I have asked this question at mathoverflow. Update 2: This question now has an answer at mathoverflow.","['vector-spaces', 'linear-algebra', 'abstract-algebra', 'polynomials']"
1192932,What do we know if we know the determinant and trace of a matrix?,"Can we reconstruct an $n\times n$ matrix if all we know is the determinant and trace of that matrix (and its size: i.e. what $n$ is)?  I would think not, because two scalars wouldn't be enough to tell us about all $n^2$ entries.  But then this brings up three questions for me. What else do we need to specify a matrix exactly?  Obviously, I'm not talking about something for which we can immediately get back the matrix, like for instance, the transpose.  But what if we knew all of the eigenvectors and eigenvalues?  Or what if we know its Jordan form? If all we know is the trace and the determinant, what else can we figure out about the matrix?  Obviously we know whether it is invertible or not, but what about say the eigenvalues -- can we figure them out in the $n\ge 3$ case?  Can we figure something else out about the matrix? Are the trace and the determinant the only invariants of a matrix under change of basis? Basically, I'm just trying to find out exactly what information is encoded in the trace and determinant of a matrix. I know that the trace is the sum of the eigenvalues, the determinant is the product of the eigenvalues, and that the determinant of a matrix is the factor by which areas change under the linear transformation $x \mapsto Ax$, where $A$ is the matrix.  Is there anything thing else that knowing both of these invariants tell us?","['matrices', 'linear-algebra']"
1192949,What does this notation mean: $\mathbb{Z}_2$,"$\mathbb Z$ (Our usual notation for the integers) with a little subscript at the bottom. This is the question being asked: what are the subgroups of order $4$ of $\mathbb Z_2 \times\mathbb Z_4$ ($\mathbb Z_2$ cross $\mathbb Z_4$) Give them as sets and
identity the group of order 4 that each of the subgroup is isomorphic to I was thinking that it meant the set of integers modulo $4$ and modulo $2$, but I'm not too sure Give them as sets and
identity the group of order $4$ that each of the subgroup is isomorphic to What is the definition of ""order"". I couldn't really find that anywhere either.","['notation', 'abstract-algebra']"
1192984,Proving that every set in the ring generated by all rectangles can be covered by a finite disjoint union of rectangles,"Let $\mathcal{J}^n$ by the collection of all ""rectangles"" in $\mathbb{R}^n$, that is: $[[a,b))\in\mathcal{J}^n\iff [[a,b))=[a_1,b_1)\times[a_2,b_2)\times\cdots\times[a_n,b_n)$ where $a,b\in\mathbb{R}^n$ and $a_i\le b_i\ \forall i$ I will call such $[[a,b))$ ""rectangles"". $R(\mathcal{J}^n)$ denotes the ring generated by the collection of n dimensional rectangles. A ring is http://www.maths.kisogo.com/index.php?title=Ring_of_sets - simply put, a class of sets closed under set-subtraction and union. Ring generated by can be found at http://www.maths.kisogo.com/index.php?title=Ring_generated_by along with the proof that given $S\in R(\mathcal{J}^n)$ that there is a finite covering using sets in $\mathcal{J}^n$, that is: $$S=\bigcup^n_{i=1}[[a_i,b_i))$$ Question: I need to show that given a finite covering, there is a finite DISJOINT covering. this is obvious, but is difficult to prove. You can ignore everything below this line, it is just my proof of work Example Take the rectangle $[[0,5))\subset\mathbb{R}^2$ that is the ""square"" $\{(x,y)|0\le x< 5,\ 0\le y< 5\}$ It is easy to see $[[0,5))-[[1,6))=[[0,1))\cup [0,1)\times[1,5)\cup [1,5)\times [0,1)$ for example. Yet $[[0,5))-[[1,2))$ has yet more cases (8 infact), a cube less something inside of it has 26 chunks. What I think I must do I think I need to do something by induction, and consider $\mathcal{J}^n=\mathcal{J}^n\times\mathcal{J}^1$. What I have done I have shown this to be true for $\mathcal{J}^1$ (and could do it for any any specific n). How? Given a covering $\cup^m_{i=1}B_i$ where $B_i\in\mathcal{J}^1$ we may generate a disjoint covering as follows: Define $A_1=B_1$ and $A_n=B_n-\cup^{n-1}_{i=1}A_i$ (notice $\cup^n_{i=1}A_i=\cup^n_{i=1}B_i$) Let us proceed by induction: $A_1$ can be expressed directly as an interval in $\mathcal{J}^1$ Assume $A_n$ can be expressed as the union of disjoint members of $\mathcal{J}^1$, then $A_{n+1}=S_{n+1}-\bigcup^n_{i=1}A_i=S_{n+1}\cap[\cup_{i=1}^nA_i]^c$ Then WLOG you can order the (disjoint) intervals present in $\cup_{i=1}^nA_i$, then the complement takes the form $(-\infty,a_1)\cup[b_1,a_2)\cup\cdots\cup[b_{n-1},a_n)\cup[b_n,\infty)$ and as $S_{n+1}=[x,y)$ You don't include all the intervals whos endpoints are below $x$ you cut the one whos lower bound is $\le x$, you keep including while the upper bound is $< y$ then you cut the one which contains $y$, then you ignore the remainder. A subset of a finite set is finite, so we have (by induction) shown we can cover a finite covering by a finite collection of disjoint members from $\mathcal{J}^1$","['measure-theory', 'lebesgue-measure', 'real-analysis']"
1192992,How do you find the sine of the angle between two vectors?,I do not know what the sine of the angle between two vectors is. I think it may be the vector created by connecting the tips of the two vectors but I am not sure. How do you find the sine of the angle between two vectors?,"['trigonometry', 'angle', 'vectors']"
1193000,Transfer function for double cart system,"System: Define X2 = Y2; I've described the system with the following diff equation: 
$$f_{tot} = m_1\ddot{x_1} + k(x_2-x_1)+m_2\ddot{x_2}+B(\dot{x_2}-\dot{x_1})$$
where m1, m2, k and B are Cart mass 1, Cart mass 2, Spring constant and dampner constant respectively. All derivatives are in respect to time, $t$. I get the following after Laplace: 
$$F(s) = m_1s^2X_1(s)+k(X_2(s)-X_1(s)) + m2s^2X_2(s)+B(sX_2(s)+sX_1(s))$$ $$G(s) = \frac{Output}{Input} = \frac{X_2(s)}{F(s)} = ???$$ But the problem is that I can't define $X_1(s)$. Should $X_1(s)$ be interpreted as $1$? Is the above formula correct?","['control-theory', 'ordinary-differential-equations', 'laplace-transform']"
1193008,On diagonizability of commutating matrices,Let $A$ and $B$ be $n\times n$ matrices over the Galois Field of order $p$ ($p$ is a prime). Suppose that $A$ and $B$ are diagonizable matrices and that they commutate. Is it possible to make them simultaneously diagonizable in $GF(p)$? I know that when we have an algebraically closed field the things go fine. What in this case? I find somethings that lead me to think that this is true.,"['matrices', 'finite-fields', 'abstract-algebra', 'field-theory']"
1193018,How can I understand cohomology theories in the context of basic homology theory?,"Please pardon the ignorance in advance -- I'm doing research, trying to solve a specific problem, so naturally I'm led down paths in mathematics I never had the opportunity to study in depth. I understand the basic ideas of topology, and algebraic topology. For example, I understand the intuitive interpretation of $\pi_0(X)$ as the free group on $k$ letters, where $X$ has $k$ ""holes"" in it... and so on in higher dimensions to get all the homotopy groups. I then think of homology as the abelianization of those homotopy groups. This all makes sense intuitively. The reason I think I need to understand cohomology is because it sounds like it provides a means of assigning a notion of ""quantity"" or ""value"" to the elements of a given space. In particular, I'm going to be looking at the clique complex of a weighted graph, so there are many interesting ""quantities"" to look at. What I don't get is how this cohomology business actually works to get me there, and what I need to learn to finish off this problem. Now, it's my understanding that cohomology is the ""algebraic dualization"" of the concept of homology. And I sorta get that, and I've read how one can literally turn a chain complex into a cochain complex trivially. I also have noticed that, while there are an abundance of ""cohomology theories,"" there is only one notion of ""homology"" I've come across. If someone could help me put all this together in my head I would be super appreciative! And given knowledge of my use case, any hints on whether I'm off on the wrong tangent would be really helpful as well. TIA!!","['homology-cohomology', 'algebraic-topology', 'abstract-algebra']"
1193021,A function that is both open and closed but not continuous,"This does not have to be a very extravagant example just something that I can wrap my head around to have a concrete idea. I was thinking that this could be satisfied by the function $f: [0, 2\pi) \rightarrow B_1 = \{(x,y): x^2 + y^2 = 1\}$ $$
f(x) = (\cos(x),\sin(x))
$$ The point of discontinuity is obviously at $(1,0)$. I was hoping to get a little help convincing myself that this is both an open and closed mapping. (Still getting use to the definition). So, my definition as stated follows. Let $f:X \rightarrow Y$ be a function on the indicated spaces. Then $f$ is an $\bf{open}$ $\bf{function}$ or $\bf{open}$ $\bf{mapping}$ if for each open set $O$ in $X$, $f(O)$ is open in $Y$. The function $f$ is a $\bf{closed}$ $\bf{function}$ or $\bf{closed}$ $\bf{mapping}$ if for each closed set $C$ in $X$, $f(C)$ is closed in $Y$. My idea was along the lines of the following. Let $O$ be an open set in the interval $[0, 2\pi)$. Then $O = (a,b)$, $a>0, b<2\pi$.  Suppose $U = (0, 2\pi) = \cup O$. Where $U$ is the collection of all open sets $O$. Then $f(U)$ is the unit circle excluding the point $(1,0)$ Therefore an open set. Let $C$ be a closed set in the interval $[0, 2\pi)$. Let $\epsilon > 0$ be given. Then $C = [a, b]$ such that $a \geq 0$, $b \leq 2\pi- \epsilon$. Suppose $H = [0, 2\pi- \epsilon]= \cup C$. $H$ is the collection of all closed sets $C$. Then $f(H)$ is the approximately the unit circle radius 1 starting at the point $(1,0)$ ending and including a point before the point $(\cos(2\pi- \epsilon), \sin(2\pi- \epsilon))$. Therefore a closed set. Thus we have found a discontinuous, closed and open map.","['general-topology', 'functional-analysis']"
