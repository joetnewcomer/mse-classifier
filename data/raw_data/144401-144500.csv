question_id,title,body,tags
2352635,Question about changing variables in $\iiint_W x+3yz^2dV$,"I've had a multivariable calculus exam with this problem, I needed to calculate following integral: $$\iiint_W x+3yz^2dV$$
  $W = \{ (x,y,z) \in \Bbb R^3 : z^2 \geq 9x^2 + 9y^2, 0 \leq z \leq 3, x \geq 0\}$ My question is, would it make sense to make this variable change?: $x = r \sin \theta$ $y = r \cos \theta$ $z = z$ Boundaries for integrating would be: $0 \leq z \leq 3$ $0 \leq r \leq 1$ $0 \leq \theta \leq \pi$ I've tried it like this, but when I try substituting in the integral and multiplying it by the Jacobian's determinant it doesn't seem right. What would a best change of variables be? Any suggestions or ideas? Thanks!","['multivariable-calculus', 'integration', 'definite-integrals', 'change-of-variable', 'analysis']"
2352644,Calculate the probability of getting a total of 6 in three throws of a die,"I am working on the following problem: In three throws of a die, what is the probability of a total score of $6$? My solution: We can get $6$ by the combination $(4,1,1)$ which has $3$ permutations and $(3,2,1)$ which has $6$ permutations. Therefore the probability is 
$$\frac{3 + 6}{6^3} = \frac{9}{216} = \frac{1}{24}$$ 
But the solution that is mentioned as correct in my notes is: $$\frac{5}{108}$$ What am I doing wrong here?","['combinatorics', 'probability-theory', 'probability', 'dice']"
2352672,Product of two elements not in a subgroup is in a subgroup?,"So I have seen this post, but my question is a bit different. Suppose $b_1,b_2\in G$ and $b_1\neq b_2^{-1}$. And suppose you have a subgroup $H\leq G$ and neither $b_1$ nor $b_2$ belong to $H$. Can $b_1b_2\in H$? So far I have just gone round in s circle and been rearranging without getting anywhere. I have tried proof by contradiction but again I get nowhere. It seems like either the above is true  or I am missing some obvious step.",['group-theory']
2352683,"Analyze the existence of the infimum, minimum, supreme and maximum of the following sequence","Analyze the existence of the infimum, minimum, supreme and maximum of the following set: $A=\{{a_n}:n \in\mathbb{N}\}$ where $a_n=P(n).b_n$ and $P(x)=1/3x^3-x^2-3x+10$ and $(b_n)_{n\in\mathbb{N}}$ is a sequence of positive terms that verifies: $b_1=b_2=b_3$ $b_n<b_{n+1}$ If we observe the behavior of $P(n)$ we can obviously appreciate that it grows infinitely, then diverges, and even if it grows monotonously, we know that it won't have supreme and maximum. But, what happens with $(b_n)_{n\in\mathbb{N}}$ (apart from its monotonically increasing)? Should we consider the cases where is bounded then is convergent so it will have a supreme, and the cases where is not? And then, what we can say about $a_n$ ?","['algebra-precalculus', 'exact-sequence', 'sequences-and-series', 'calculus']"
2352684,When is a symmetric matrix invertible?,"My professor always writes on the board: $A$ is $m \times n$, assuming that the vectors of $A$ form a basis, then $A^TA$ is always invertible. one thing I know is that $A^TA$ is always symmetric, but I'm not sure about the conditions on a symmetric matrix needed to ensure that it is invertible?","['matrices', 'symmetric-matrices', 'linear-algebra', 'inverse']"
2352688,Approximation of a Riemann sum (not really) by a Laplacian integral,"I have a sum of the form: $$S_n = \frac{1}{n} \sum_{i=0}^n \mathrm{e}^{n f(i/n)} g(i/n)$$ where $f(x)$ and $g(x)$ are smooth functions defined for $0\le x \le 1$. I am interested in the Asymptotic behaviour of $S_n$ as $n\rightarrow +\infty$. What I have tried is to replace the sum by an integral: $$S_n \approx\int_0^1 \mathrm{e}^{n f(x)} g(x) \mathrm{d}x$$ and then I was thinking of doing a saddle-point approximation ( Laplace's method ), but I am not sure of the validity of replacing the sum by the integral. It looks like a Riemann sum, except for the $n$ multiplying $f$ in the exponent. Any suggestions appreciated. If it makes your life easier assume that $f(x)$ has a single maximum inside the interval $x\in(0,1)$. I'd be happy if someone could at least point out some reference to the literature where sums like this have popped out before. I have the feeling that this has been treated before. Edit, TLTR. The summarized version of the question is: Prove or disprove that $S_n / I_n \rightarrow c$ for some constant $c$ as $n\rightarrow \infty$, where $$S_n = \frac{1}{n} \sum_{i=0}^n \mathrm{e}^{n f(i/n)} g(i/n), \quad I_n = \int_0^1 \mathrm{e}^{n f(x)} g(x) \mathrm{d}x$$ Moreover, is the difference between $I_n$ and $S_n$ exponentially decreasing in $n$? That is, $|I_nc - S_n| / S_n = \mathcal{O}(n^p e^{-qn})$ for some numbers $p,q$?","['laplace-method', 'reference-request', 'integration', 'riemann-sum', 'sequences-and-series']"
2352704,Can this integral be calculated in closed form?,"I'm trying to calculate the following integral: $$
\int_{0}^{1}x\,\mathrm{J}_{2}\!\left(\,bx\,\right)
\sin\left(\,a\,\sqrt{\,1 - x^{2}\,}\,\right)\,\mathrm{d}x
$$where $a$ and $b$ are parameters ( independent of $x$ ). Things I have tried so far, without success (but possibly not driven through far enough): look up in tables: no joy. The ''closest'' match I have found is eq. (6.738.1) in Gradshteyn and Ryzhik, but that result is for the
first factor being $x^3$ instead of $x$; use WolframAlpha (Standard): does not give values for general $a$
and $b$; only for assigned selected $a$ and $b$. Since I need results for a wide range of values for both $a$ and $b$, this (or any numerical quadrature for arbitrary $a$ and $b$) is not practical; use an integral representation for Bessel functions: \begin{align}
J_2(bx) = \frac{1}{\pi} \int^\pi_0 \cos(2\theta - bx \sin\theta)
d\theta \end{align} then swap the order of integration. However, the outer integration (i.e., with respect to $\theta$) then becomes problematic; use a recurrence relation for Bessel functions: \begin{align} J_2(bx) =
(2/(bx)) J_1(bx) - J_0(bx) \end{align} This does not seem to simplify matters, because the square root in sin() remains a difficulty. attempt partial integration: since the integrand contains three
factors, the choice is not obvious. I tried grouping the first two
factors and use the partial integral result \begin{align} \int x^m J_n(x)
dx = -x^m J_{n-1}(x) + (m+n-1) \int x^{m-1} J_{n-1}(x) dx
\end{align} for $m=1$ , $n=2$, i.e., \begin{align} \int x J_2(x) dx
= -x J_{1}(x) - 2 J_{0}(x) + C\end{align} but the derivative of $\sin(a\sqrt{1-x^2})$ with respect to $x$ complicates the remaining
integration; use a series representation of the Bessel function: this leads to a
double summation of integrals (one sum is semi-infinite) of the
form \begin{align} \int^1_0 u^{2m+1} \sin(a u) du \end{align}  but
this integral is a itself a difference of hypergeometric functions (or
alternatively an additional series representation). Such a double or triple summation is again
impractical for calculating for parametrized $a$ and $b$; converting the original integral to \begin{align}
\int^1_0 y J_2 (b \sqrt{1-y^2}) \sin(a y) dx \end{align} where $y=\sqrt{1-x^2}$ and repeating the previous approaches; attempt
    a trigonometric substitution such as $x = \sin \alpha$ and repeat the
    previous approaches. Can you find a solution or give further suggestions what could be attempted?","['integration', 'calculus']"
2352721,What is the probability of the sum of four dice being 22?,"Question Four fair six-sided dice are rolled. The probability that the sum of the results being $22$ is $$\frac{X}{1296}.$$ What is the value of $X$ ? My Approach I simplified it to the equation of the form: $x_{1}+x_{2}+x_{3}+x_{4}=22, 1\,\,\leq x_{i} \,\,\leq 6,\,\,1\,\,\leq i \,\,\leq 4 $ Solving this equation results in: $x_{1}+x_{2}+x_{3}+x_{4}=22$ I removed restriction of $x_{i} \geq 1$ first as follows-: $\Rightarrow x_{1}^{'}+1+x_{2}^{'}+1+x_{3}^{'}+1+x_{4}^{'}+1=22$ $\Rightarrow x_{1}^{'}+x_{2}^{'}+x_{3}^{'}+x_{4}^{'}=18$ $\Rightarrow \binom{18+4-1}{18}=1330$ Now i removed restriction for $x_{i} \leq 6$ , by calculating the number of bad cases and then subtracting it from $1330$ : calculating bad combination i.e $x_{i} \geq 7$ $\Rightarrow x_{1}^{'}+x_{2}^{'}+x_{3}^{'}+x_{4}^{'}=18$ We can distribute $7$ to $2$ of $x_{1}^{'},x_{2}^{'},x_{3}^{'},x_{4}^{'}$ i.e $\binom{4}{2}$ We can distribute $7$ to $1$ of $x_{1}^{'},x_{2}^{'},x_{3}^{'},x_{4}^{'}$ i.e $\binom{4}{1}$ and then among all others . i.e $$\binom{4}{1} \binom{14}{11}$$ Therefore, the number of bad combinations equals $$\binom{4}{1} \binom{14}{11}  - \binom{4}{2}$$ Therefore, the solution should be: $$1330-\left( \binom{4}{1} \binom{14}{11} - \binom{4}{2}\right)$$ However, I am getting a negative value. What am I doing wrong? EDIT I am asking for my approach, because if the question is for a larger number of dice and if the sum is higher, then predicting the value of dice will not work.","['combinatorics', 'probability', 'dice']"
2352729,$T$ is bounded iff $S\circ T$ is bounded.,"Let $X , Y, Z$ are Banach spaces. $T:X\to Y$ be a linear map and $S:Y\to Z$ be a one-one linear map which is bounded. Show that $T$ is bounded iff $S\circ T$ is bounded. One side is trivial that I know. But how to prove that if $S\circ T$ is bounded then $T$ is bounded too.","['functional-analysis', 'banach-spaces']"
2352821,How to get the sum of the series $\sum _{n=1}^{\infty } \frac{1}{\left(4 n^2-1\right)^2}$?,"So, in order to obtain the required answer, I tried to apply some Taylor expansions, which led me to nowhere actually. 
After a while I tried to use the summation theorem $\sum_{n=-\infty}^{+\infty}{f\left(n\right)}=-\sum_{i=1}^{m}{Res_{z=z_i}{\pi\cot\left(\pi z\right)f\left(z\right)}}$ at $f\left(z\right)$'s poles. Residue at $z=-\frac{1}{2}$ equals to residue at $z=\frac{1}{2}$, both of them are $-\frac{\pi ^2}{16}$. 
What I got seems to be not the correct answer after all: $-\sum_{i=1}^{m}{Res_{z=z_i}{\pi\cot\left(\pi z\right)f\left(z\right)}} = -\frac{\pi ^2}{8}$, so that $\sum_{n=-\infty}^{+\infty}{f\left(n\right)}=\frac{\pi ^2}{8}$
Since the $f\left(z\right)$ is even, I get $\sum_{n=0}^{+\infty}{f\left(n\right)}=\frac{\pi ^2}{16}$ However, the initial task was to find the sum of $\sum_{n=1}^{+\infty}{f\left(n\right)}$. I supposed that $\sum_{n=1}^{+\infty}{f\left(n\right)}=\sum_{n=0}^{+\infty}{f\left(n\right)}-f\left(0\right)=\frac{\pi ^2}{16}-1$, which is incorrect, as according to Mathematica, I should get $\frac{\pi ^2}{16}-\frac{1}{2}$. I don't know where is my mistake at this point. Perhaps, the whole approach is not well executed.","['residue-calculus', 'sequences-and-series']"
2352827,Is T2 modulo permutation by S2 a familiar surface? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question If I have a 2d Torus $S_1 \times S_1$ but I identify $(x,y)\equiv(y,x)$, is that a familiar surface? context: I am an engineering graduate student with a vanilla background in undergraduate topology pursuing a research question. I tried the usual gluing of edges but had difficulty embedding in 3 dimensions (which is my best chance at recognizing it). I felt the answer should be widely known on the internet but couldn't find it.","['permutations', 'general-topology']"
2352828,Injective holomorphic/smooth map into a topological vector space vs immersion.,"In the finitely dimensional case it follows from the constant rank theorem that a smooth map between smooth manifolds, which is not an immersion on an open set, cannot be injective. I need a ""semi-infinite"" dimensional analogue of this fact. Namely, let $U$ be a domain in $\mathbf{C}^{d}$, let $E$ be a topological vector space and let $\varphi:U\to E$ be holomorphic, such that the rank of $D\varphi_{x}$ is less than $d$ for every $x\in U$. Does it follow that $\varphi$ is not injective? I understand that the constant rank theorem does exist for infinite dimensions, but it has a lot of technical conditions, which I suspect to be redundant if the domain is finitely dimensional. In particular, I am curious if we need $E$ to be good, e.g. isomorphic to a Banach space. In fact, I can prove my claim; however I hope for a reference to a constant rank theorem or something else, that would just make my life simple =)","['complex-geometry', 'functional-analysis', 'complex-analysis', 'differential-geometry', 'topological-vector-spaces']"
2352839,Space of bounded sequences in Banach space is complete,"Let $(X, |\cdot|)$ be a Banach Space and 
$$X_b := \{ (x_n)_{n\in \mathbb{N}} \subset X: \| (x_n)_{n\in\mathbb N} \|_{X_b}< \infty \}$$
 with 
$$\|(x_n)_{n\in\mathbb N}\|_{X_b}:= \sup\limits_{n \in \mathbb{N}} |x_n|.$$
Why is $(X_b,\|\cdot\|_{X_b})$ complete?","['functional-analysis', 'banach-spaces']"
2352840,Why is the accepted definition of random variable what it is? [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 6 years ago . Improve this question I'm wondering, why are random variables defined in terms of measurable functions from a probability space $\Omega$ to any measurable space $M$. Why not instead have an axiomatic approach defining the properties of correlation and expected value. I get that the accepted definition works, but to me it seems like it may be an overkill definition, especially when generally no one cares about the underlying probability space $\Omega$. I'm thinking of something similar to http://www.randomservices.org/random/expect/Spaces.html https://golem.ph.utexas.edu/category/2016/06/how_the_simplex_is_a_vector_sp.html",['probability-theory']
2352856,Independence of $z$ and $\bar{z}$,"I am teaching complex analysis to physics students next semester and I would like to discuss the fact that $z$ and $\bar{z}$ are functionally(?)/algebraically(?) (what is the correct terminology, anyway?) independent as early as possible in a course. Ideally, after I introduce complex numbers $z$ as a pair of real numbers and develop the basic complex algebra, I would like to define the complex conjugate $\bar{z}$ and then prove that $\bar{z}$ cannot be obtained from $z$ using algebra, i.e. using $+,-,\times,\div$. Now, my question is, what is the strongest statement of independence of $z$ and $\bar{z}$ that I can prove using basic complex algebra? Rephrasing the question: how can I prove that $z$ and $\bar{z}$ are algebraically independent in the ordinary sense of the word? I want to prove there exists no nontrivial polynomial $P_n(z,\bar{z})$ with complex constants so that $P_n(z,\bar{z}) = 0$ for any $n \in \mathbb{N}$ (including $n \to \infty$).","['complex-analysis', 'complex-numbers']"
2352900,Indicator function for divisibility,"Is there well known or common notation for an indicator-like function that tells if $a$ divides $b$? Something like the Kronecker delta, but for divisibility? A function like: $\begin{align}
\mathcal{I}:\mathbb{Z}^2 \mapsto \{0,1\} \text{, where }
\mathcal{I}(a,b)=\begin{cases}
1, & \text{if } a\mid b\\
0, & \text{if } a \nmid b
\end{cases}
\end{align}$ Or is there a better way to think about this function?","['special-functions', 'divisibility', 'functions', 'elementary-number-theory']"
2352922,Method to estimate variance of sample mean for correlated data,"I have $m$ weakly stationary observations $X_1,X_2,\cdots,X_m$. I don't know anything else about the observations. I want to estimate the variance of the sample mean. At first, my idea was to use nonparametric bootstrapping to do this. But I learnt that this method doesn't work for correlated data. What are the most easy, standard ways of doing this to get reliable estimates?","['statistics', 'estimation', 'parameter-estimation']"
2352929,If $T$ is a positive operator then $I+T$ is invertible,"Let $T$ be a positive operator on a Hilbert space $H$, prove that $I+T:H\to H$ is invertible and $(I+T)^{-1} \in B(H)$. Now, If I prove $I+T$ is invertible, the bounded inverse theorem implies the second part. Now while proving that $I+T$ is invertible, I have proved that $I+T$ is one-one. But now I have to prove that $I+T$ is onto. In doing so my idea is to prove that $I+T$ is bounded below, so that $Range(I+T)$ becomes closed and then show that $Range(I+T)^{\perp}=\{\ 0 \}\ $, then by projection theorem we will have $Range(I+T)=H$. But I couldn't execute this idea. Other ideas will also be appreciated Thanks in advance!!","['functional-analysis', 'operator-theory', 'hilbert-spaces']"
2352957,What is the Householder matrix for complex vector space?,"For $\Bbb R^n$, Householder matrix $Q=I-2vv^T$ is an operator that maps a vector to its reflection across a hyperplane of normal $v$. The following is an illustration for Householder operator of a general inner product space. For $\Bbb R^n$, use standard inner product, then we have $x-2<x,v>v=x-2vv^Tx=(I-2vv^T)x$, where $I-2vv^T$ is the Householder matrix. It satisfies the following However, I am wondering what would be the Householder matrix for complex vector space $\Bbb C^n$? It looks like $I-2vv^H$ is not right ($H$ denotes conjugate transpose), because by my calculation it does not satisfy above problem 5.7.3. Wikipedia suggests I tried, and I might be wrong, but it does not seem to satisfy problem 5.7.3 either. $Q(x+y)=(x + y) - \frac{{x - y}}{{{{\left\| {x - y} \right\|}^2}}}({(x - y)^H}(x + y) + \frac{{{x^H}(x - y)}}{{{{(x - y)}^H}x}}{(x - y)^H}(x + y))$ It looks impossible for $Q(x+y)=x+y$ unless $x^Hy=y^Hx$.","['matrices', 'matrix-decomposition', 'linear-algebra']"
2352985,A cute two variable inequality involving logarithms,"A cute inequality of my invention: Let $z>0$ and $z>x,y>0$. Then $x\ln (\frac{z}{z-y})>y\ln (\frac{z}{z-x})$ implies $x<y$.","['algebra-precalculus', 'inequality']"
2353024,$x^4 + y^4 \mod p$,"The primes $p = 5, 13, 17, 29$ have the property that there exist fewer than $p$ values for $x^4 + y^4 \mod p$.  For example, $x^4 \equiv 0$ or $1 \mod 5$ so $x^4 + y^4 \equiv 0, 1$ or $2$, but never $3$ or $4$, $\mod 5$.  Are there any other primes with this property? The question arose in connection with OEIS sequence A289559","['number-theory', 'elementary-number-theory']"
2353071,Why does the empty set matter? [closed],"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 6 years ago . Improve this question I'm trying to understand why the empty set is a useful tool for mathematicians. Are there any nontrivial theorems that could only be achieved by the existence of the empty set, or is the recognition of the empty set just a conventional standard that mathematicians have adopted?",['elementary-set-theory']
2353104,Finding determinant using row operations,"I'm currently learning about finding determinant using row operations. This method requires the values below the main diagonal to all be zero. I'm looking at this example and I don't understand the last matrix. They have done r4 = 1/2r3 + r4. However, what if I had done r4 = 2r4 + r3 ? I would still get my desired zeros below the diagonals but my last value on my diagonal becomes -13 instead of -13/2. This changes my determinant result. Why is this happening? Can I not do r4 = 2r4 + r3?","['linear-algebra', 'determinant']"
2353141,what is the possible number of commutative binary operations that can be defined on a set of n elements?,"Please guide the approach , If we have to find commutative operations , then what will the cardinality of the set which would be mapped to a set with $n$ elements ,since for calculating total no of binary operations we have a mapping defined from set of $n^2$ elements to $n$ elements so possible no of binary operations $=n^{n^2}$ ,but how to approach for commutative binary operation ?",['discrete-mathematics']
2353148,Why is my way of solving $5^{4x+1} = 7^{x+2}$ invalid?,"I know I could just express $$5^{4x+1} = 7^{x+2}$$ as $(4x+1)\log 5 = (x+2)\log 7$ but I wanted to try something off the cuff. Here's what my thought process was. $$7^\alpha = 5$$ $$\alpha = \frac{\log 5}{\log 7}$$ Since both bases can be expressed as $5$, we can equate their exponents. $$\alpha x + 2\alpha = 4x+1$$ $$x\ (4 - \alpha) = 1 - 2\alpha$$ $$x = \frac {1-2\alpha}{4-\alpha}$$ $$x = \frac{1 - 2\frac{\log 5}{\log 7}}{4 - \frac{\log 5}{\log 7}}$$ Approximating $\frac{\log 5}{\log 7}$ as about $0.827$, $x$ is roughly: $$x = 0.478$$ However, this is not true. What did I do wrong, if my logic is sound?","['algebra-precalculus', 'logarithms']"
2353174,Can there be a symbol for continuous product? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question We know that continuous version of $\sum$ is $\int$, but, can there be a continuous version of $\Pi$?","['terminology', 'soft-question', 'calculus', 'analysis']"
2353177,Understanding the notations of the expectation of a random variable,"We know that if $P$ is a probability in the measurable space $(\mathbb{R}, \mathcal{B})$ , then we can define a distribuition function $F$ as following: $$F(x):= P((-\infty,x])), \quad \forall x \in \mathbb{R}$$ By the Carathéodory's extension theorem we can prove that the converse is also valid, that is:
if $F$ is a distibuition function, then there is a unique $P_{\small{F}}$ in $(\mathbb{R}, \mathcal{B})$ that $$F(x)= P_{\small{F}}((-\infty,x])),\quad \forall x \in \mathbb{R}$$ In other words, there is a one-to-one correspondence between the set of probabilities in $(\mathbb{R}, \mathcal{B})$ and the set of all distribuition functions. $Remake:$ :: If $X:(\Omega,\mathcal{F}, \mu) \to \mathbb{R}$ is a random variable, we can define a probability in $(\mathbb{R}, \mathcal{B})$ and a distribuition function, respectively, as following: $$P_{\small{X}}(B) := \mu(X \in B),\quad B \in \mathcal{B}$$ $$F_{\small{X}}(x) := P_{\small{X}}((-\infty, x]))= \mu(X \leq x), \quad x \in \mathbb{R}$$ A random variable is continue (absolutly?) if there is a density (non negative) function $f$ such that $$F_{\small{X}}(x) = \int_{-\infty}^{x}f(y)dy$$ I dont will write the Lebesgue integral definition, but it is supossed that the classical definition is well known. I would like to remember its notations $$E(X) = \int_{\Omega}Xd\mu = \int_{\Omega}X^{+}d\mu - \int_{\Omega}X^{-}d\mu$$ Although I consider the one-to-one correspondence between $F_{X}$ and $P_X$ , I can not find, besides the notations justificatives, good arguments for the following equivalences (for each iquality) $$\int_{\Omega}Xd\mu = \int_{\mathbb{R}} xdF_{\small{X}}(x) = \int_{\mathbb{R}} xdP_{\small{X}}(x) = \int_{\mathbb{R}} x f(x)dx$$ Some justificatives?","['probability', 'notation', 'expected-value']"
2353178,Proof the following!,"$$a_0(x)\frac{d^2y}{dx^2}+a_1(x)\frac{dy}{dx}+a_2(x)y=0$$ A) Let $f_1$ & $f_2$ are two solutions to the above differential equation. Show that $f_1$ & $f_2$ are linearly independent on $a \leq x \leq b$ and $A_1$,$A_2$,$B_1$&$B_2$  are constants such that $A_1B_2-A_2B_1\neq 0$ then the solution $A_1f_1+A_2f_2$ & $B_1f_1+B_2f_2$ are also linearly independent on $a \leq x \leq b$ My work is down! I assume that the solution of the differential equation are linearly independent then we can write them as follows $$A_1f_1+A_2f_2=0$$ $$\frac{f_1}{f_2}=-\frac{A_1}{A_2}$$ $$B_1f_1+B_2f_2=0$$ $$B_1 f'_1+B_2 f'_2=0$$ $$\frac{f'_1}{f'_2}=-\frac{B_1}{B_2}$$ Since the two solutions are linearly independent their Wronskian are not zero! $$W[f_1(x),f_2(x)]=f_1f_2'-f_2f_1'\neq 0$$ $W(x)\neq 0$ therefore $ W'(x)\neq 0$ $$W(x)[f_1,f_2]=(-A_1)(-B_2)-(A_2)(B_1)$$ $$(-A_1)(-B_2)-(A_2)(B_1)\neq 0$$ What I do is very foolish. Can someone propose a proper way of doing things! B) Let set ${f_1,f_2}$ be two solutions to the above differential equation and ${g_1,g_2}$ be another set then show that the wronskian is $W[f_1(x),f_2(x)]=cW[g_1(x),g_2(x)]$ such that $c\neq 0$ Since $f_1$ & $f_2$ are solutions, then $$a_0f_1''+a_1f_1'+a_2f_1+a_0f_2''+a_1f_2'+a_2f_2=0=0$$ $$a_0(f_1f_2''-f_2f_1'')+a_1(f_1f_2'-f_2f_1')+a_2(f_2f_1-f_1f_2)=0$$ $$a_0W'[f_1(x),f_2(x)]+a_1W[f_1(x),f_2(x)]=0$$ $$W'[f_1(x),f_2(x)]=-\frac{a_1}{a_0}W[f_1(x),f_2(x)]$$ $$W'[g_1(x),g_2(x)]=-\frac{a_1}{a_0}W[g_1(x),g_2(x)]$$ $$\int\frac{dW[g_1(x),g_2(x)]}{W[g_1(x),g_2(x)]}=\int \frac{dW[f_1(x),f_2(x)]}{W[f_1(x),f_2(x)]}$$ $$W[f_1(x),f_2(x)]=cW[g_1(x),g_2(x)]$$ Totally stuck! This is bad. I can't even proceed from the question! Hope someone help me in this question","['ordinary-differential-equations', 'proof-verification']"
2353189,How is complex analysis relevant to other areas of mathematics?,"I'm going to do a math PhD next year. My main interests in mathematics are composition algebra, algebraic topology, and group theory. Now I have the opportunity to take a one-semester course in complex analysis, but I am not sure if it is relevant to my research interests. My understanding of complex analysis is that it is mostly about Laurent series, Cauchy's integral theorem, residue theorem, and evaluating weird-looking real integrals using these techniques. But I fail to see its connection to algebra. I am sure that it is a beautiful theory and that it is also an important set of tools for applied mathematicians and engineers, but is there anything useful I can take from complex analysis as an algebraist?","['complex-analysis', 'soft-question']"
2353190,MCQ The nth derivative of $f(x)=\frac{1+x}{1-x}$,Let $f(x)=\dfrac{1+x}{1-x}$ The nth derivative of f is equal to: $\dfrac{2n}{(1-x)^{n+1}} $ $\dfrac{2(n!)}{(1-x)^{2n}} $ $\dfrac{2(n!)}{(1-x)^{n+1}} $ by Leibniz formula $$ {\displaystyle \left( \dfrac{1+x}{1-x}\right)^{(n)}=\sum _{k=0}^{n}{\binom {n}{k}}\ (1+x)^{(k)}\ \left(\dfrac{1}{1-x}\right)^{(n-k)}}$$ using the hint $\dfrac{1+x}{1-x}=\dfrac{2-(1-x)}{1-x}=\dfrac2{1-x}-1$ and $\left(\dfrac{1}{x}\right)^{n}=\dfrac{(-1)^{n}n!}{x^{n+1}}$ so $${\displaystyle \left( \dfrac{1+x}{1-x} \right)^{(n)} = \left( \dfrac{2}{1-x}-1 \right)^{(n)}=2\dfrac{ (-1)^{n}n! }{ (1-x)^{n+1} }   }  $$ but this result isn't apear in any proposed answers what about the method of Lord Shark the Unknown tell me please this way holds for any mqc question contain find the n th derivative so it's suffice to check each answer in y case i will start with first let $f_n(x)=\dfrac{2n}{(1-x)^{n+1}}$ then $f_{n+1}(x)=\dfrac{2(n+1)}{(1-x)^{n+2}}$ do i have $f'_{n}=f_{n+1}$  let calculate $$ f'_n=\dfrac{-2n(n+1)}{(1-x)^{n+2}}\neq f_{n+1}$$ let $f_n(x)=\dfrac{2(n!)}{(1-x)^{2n}}$ then $f_{n+1}(x)=\dfrac{2((n+1)!)}{(1-x)^{2(n+1)}}$ do i have $f'_{n}=f_{n+1}$  let calculate $$ f'_n=\dfrac{-2(n!)(2n)}{(1-x)^{4n}}\neq f_{n+1}$$ let $f_n(x)=\dfrac{2(n!)}{(1-x)^{n+1}}$ then $f_{n+1}(x)=\dfrac{2((n+1)!)}{(1-x)^{n+2}}$ do i have $f'_{n}=f_{n+1}$  let calculate $$ f'_n=\dfrac{2(n!)(n+1)}{((1-x)^{n+1})^{2}}=\dfrac{2((n+1)!)}{(1-x)^{2n+2}}\neq f_{n+1}$$,['derivatives']
2353197,Question 4.K of Bartle's Element of Integration,"I've have lots of trouble proving the next question of Bartle's book: If $(X,\mathcal{X},\mu)$ is a finite measure space, and if $(f_{n})$ is a real-valued sequence in $M^{+}(X,\mathcal{X})$ which converges uniformly to a function $f,$ then $f$ belongs to $M^{+}(X,\mathcal{X}),$ and 
$$\int f d\mu=\lim\int f_{n} d\mu.$$ I don't understand correctly the proposition. First: why does it ask the condition of a finite measure space? Second: I guess that the hipotesis of uniform convergence is to create an increasing monotone sequence,to guarantee the pointwise convergence and then using Monotone Theorem Convergence, but I'm not sure of this. Is there another way to prove this easily? Any kind of help is thanked in advanced.","['real-analysis', 'integration', 'measure-theory']"
2353211,Division in $\Bbb R^n$,"What is the most natural generalization of division from $\Bbb R$ to $\Bbb R^n $? In fact my original question concerns any normed space $X$. How one can divide two vectors in $X$ ? However, question is still non trivial in $ \Bbb R^n $. I want at least this division be continuous w.r.t  the norm of $X$. Motivation : Let $\{x_n\}$ and $\{y_n\}$ be two sequences in $X$, with $y_n$ be nice enough for all $n \in \Bbb N$. I want to find a good notion of division such that if $x_n \to x$ and $y_n \to y$ then we get $$\frac{x_n}{y_n}  \to \frac{x}{y} $$ For example, this is possible in all $\Bbb R^{n^2}$, viewing its members as square matrices then if $\{y_n\} \subseteq \Bbb R^{n^2} $ be the sequence of non singular matrices, we have that conclusion!","['functional-analysis', 'real-analysis', 'linear-algebra']"
2353212,Some combinatorial properties of Fano geometry,"I am starting to learn about finite geometries and in particular am trying to understand some basic (mainly combinatorial) features of the seven point geometry. (I have not yet reached the context of projective geometry, so my questions are truly basic, and I'd appreciate answers that use only elementary methods.) Let's say that a symmetry is a permutation of $\{1, \ldots, 7\}$ that preserves lines. I am not sure how to prove whether or not the following properties hold : (i) Given any two different lines (e.g., $\{1, 3, 2\}$ and $\{3,6,5\}$ ), there is a symmetry that takes one to the other. (ii) Given any two distinct points, there is a symmetry taking one to the other. Moreover, although I am able to see why there are 168 total symmetries, I can't see why there are 24 symmetries fixing a point and 24 fixing a line (as stated on WIkipedia).  I also can't figure out at all how many would fix two lines. I'd really appreciate if someone could help me answer these questions. My intuition with finite geometry is pretty weak right now.","['noneuclidean-geometry', 'symmetry', 'geometry', 'combinatorics', 'discrete-mathematics']"
2353272,Expansion coefficients,"Suppose that we are given the function $f(x)$ in the following product form: 
$$f(x) = \prod_{k = -K}^K (1-a^k x)\,,$$
Where $a$ is some real number. I would like to find the expansion coefficients $c_n$, such that:
$$f(x) = \sum_{n = 0}^{2K+1} c_n x^n\,.$$ A closed form solution for $c_n$, or at least a relation between the coefficients $c_n$ (e.g. between $c_n$ and $c_{n+1}$) would be great!","['products', 'taylor-expansion', 'polynomials', 'functions']"
2353298,Showing a function in two variables is continuous at every point,"I am new to functions in multiple variables, and I'm trying to get a better understanding of the continuity of such functions. Let's take the simplest of cases: $f(x,y)=x+y$. How can I show that this function is continuous?","['continuity', 'calculus', 'functions']"
2353307,Royal way to learn algorithmic / computational / computer algebra,"Background I have some background in abstract commutative algebra and basic scheme theory as covered in Atiyah/Macdonald and the notes by Ravi Vakil. What I have absolutely no background in is computer science and programming. However, I would like to self-learn some algorithmic or computational algebra. I would appreciate to see some book recommendations concerning these topics. Books that I know about What seems to be quite standard but not very deep on the algebra side and not so explicit on the implementation side (which I want to learn as well) is the book Ideals, Varieties and Algorithms by Cox, Little and O'Shea. I also know about the book A SINGULAR Introduction to commutative algebra by Greuel and Pfister. It seems to be much more in depth on the algebra side --- covering for example commutative algebra over arbitrary base rings, not just fields --- and closely connected to the CAS SINGULAR. There is also a three volume book Computational Commutative Algebra by Kreuzer and Robbiano working with the CAS CoCoA. Besides those computer Algebra books there are books on constructive algebra (which I am also interested in) like Commutative Algebra: Constructive Methods by Lombardi and Quitté an A Course in Constructive Algebra by Mines, Richman and Ruitenburg. These work purely constructively but do not make explicit the algorithms that can be extracted from the proofs. My Questions Is it important to have a book focusing on one CAS explicitly? From this there arise two more questions: Which CAS should I decide for? There are so many choices here and I'm not sure if they are basically all the same or if there are major differences and which to prefer. Where does the programming experience come from? Suppose I just learned about Gröbner bases and the Buchberger algorithm. I might implement some version of that algorithm and compute Gröbner bases of two or three more or less complicated ideals. And then? Is this all? Move on to the next topic? Although I want to learn so computational thinking, it is not the case that every day I encounter problems that can only be solved with a computer. So where do the problems to solve and to earn experience from? How to check if I have written good code? This is perhaps more a computer science question. But computer scientists probably have to hand in exercises for university or so where they get feedback. If I write the worst and most inefficient code one can think of, which still somehow works - how should I know?","['polynomials', 'algebraic-geometry', 'computational-mathematics', 'computer-algebra-systems', 'commutative-algebra']"
2353329,Holomorphic and analytic functions.,"I read this today (source: Wikipedia): The fact that all holomorphic functions are complex analytic
  functions, and vice versa, is a major theorem in complex analysis. Is there a similar result in real analysis?","['complex-analysis', 'real-analysis']"
2353342,Set theoretic definition of cartesian product of two sets,"I am trying to study mathematics rigorously.It is mentioned in my book in the chapter of set theory that the symbol ""$:$"" stands for the phrase ""such that"". 
Then in the next chapter of relations, the cartesian product of two sets $A$ and $B$ is defined as follows: If $A$ and $B$ be two sets,
$A\times B =\{(a,b):\forall (a\in A , b\in B) \}$. If this symbolic definition is translated into words, it reads:""The cartesian product of two sets $A$ and $B$ is defined as the set of all ordered pairs $(a,b)$ such that for all $a$ belongs to $A$ and $b$ belongs to to $B$. My concern is about the last part in the symbolic definition, that is, ""$:\forall (a\in A , b\in B)$"". If this is translated into words it reads ""such that for all $a$ belongs to $A$ and all $b$ belongs to to $B$"". This sounds incomplete to me. Is this correct both mathematically and grammatically? Would not it be better to define the cartesian product of $A$ and $B$ as $A\times B =\{(x,y):(x,y)=(a,b)\forall (a\in A , b\in B) \}$ or simply as $A\times B =\{(a,b):a\in A , b\in B) \}$. Among these three which is correct grammatically as well as rigorous mathematically?","['relations', 'elementary-set-theory']"
2353358,Why refer to elements in this weird way?,"Often while reading in Jacobson's Basic Algebra textbook, I find him referring to elements of a set in a particular, weird way. Instead of saying for example ""let $x_1,\ldots,x_n$ be elements of $S$"", he says let $i \mapsto x_i$ be a map of $\{1,\ldots,n\}$ into $S$. Why does he do this? Is it just for rigour purposes? Added: here is a concrete one. For any ring $R$ and any positive integer $r$ there exists a ring $R[x_1,\ldots,x_r]$ with the following ""universal"" property. If $S$ is any ring and $\eta$ is a homomorphism of $R$ into $S$ and $i\mapsto u_i$ is a map of $\{1,\ldots,r\}$ into $S$, then there exists a unique extension of $\eta$ to a homomorphism of $R[x_1,\ldots,x_r]$ into $S$ sending $x_i$ to $u_i$, $1\le i \le r$. Another one is on page $69$ (first volume) when talking about free groups.","['terminology', 'abstract-algebra', 'soft-question']"
2353367,Common complex roots,"If the equations $ax^2+bx+c=0$ and $x^3+3x^2+3x+2=0$ have two common roots then show that $a=b=c$. My attempts: Observing $-2$ is a root of $x^3+3x^2+3x+2=0\implies x^3+3x^2+3x+2=(x+2)(x^2+x+1)=0$ Hence $ax^2+bx+c=0$ can have complex roots in common, comming from $(x^2+x+1)=0$ Both the roots of $(x^2+x+1)=0$ and $ax^2+bx+c=0$ are common should imply $a=b=c$ not only this but $a=b=c=1$. Is this solution correct?","['algebra-precalculus', 'roots', 'common-root', 'quadratics']"
2353436,Existence of one-sided derivatives for a Lipschitz function,"Let $f(x):\mathbb{R}\to[0,1]$ be Lipschitz continuous, differentiable everywhere except for $x=0$ and such that $f(0)=0$.
My question is whether or not
the ""left"" derivative  $\lim_{x\uparrow 0} \frac{f(x)}{x}$ and
the ""right"" derivative  $\lim_{x\downarrow 0} \frac{f(x)}{x}$ always exist.","['derivatives', 'real-analysis', 'lipschitz-functions', 'continuity']"
2353459,Are natural numbers always sets in set theory?,"The case $0 \subseteq \emptyset$: If we define natural numbers as sets then we have $$0=\emptyset$$and  $$\emptyset \subseteq \emptyset$$ and therefore $$0=\emptyset  \subseteq \emptyset.$$ The case $2 \subseteq A$: In same manner, we can see $2$ as a set which is  $$2=\{0,1\}=\{\emptyset, \{\emptyset\}\}.$$ As an example, given $$A=\{0,1\}$$ we have $$A=2$$ and therefore $$2=2\subseteq 2 =A.$$ Question: Do we always need to see a natural number as a set in set theory? Can we say that `$2$ is a number, not a set, therefore it cannot be a subset'?",['elementary-set-theory']
2353501,Problem concerning the real Nullstellensatz,"The real quadratic  Nullstellensatz says: Let $p(x), q(x)\in \mathbb R[x_1,...,x_n]$ be quadratic polynomials such that 
$$(*) \  \{x\in \mathbb R^n: p(x)=0\}=\{x\in \mathbb R^n: q(x)=0\}$$
and $p(x)$ has at least one zero $x_0$ such that $grad \ p(x_0) \neq 0$. 
Then there is a $\alpha \in \mathbb R^*$ such that $p=\alpha q$. Is the same true if the condition (*) is replaced by the following one:
$$
(*) \  \{x\in \mathbb R^n: p(x)=0\} \subset \{x\in \mathbb R^n: q(x)=0\} ?
$$","['abstract-algebra', 'algebraic-geometry']"
2353523,How can the sum of squares be negative?,"If $a,b,c,d$ are the roots of the equation $x^4-Kx^3+Kx^2+Lx+M=0$, where $K,L,M$ are real numbers, then the mininmum value of $a^2+b^2+c^2+d^2$ is? My answer: $\sum a=K,\ \sum ab=K\implies$ $a^2+b^2+c^2+d^2=K^2-2K=(K-1)^2-1$. For $K=1$, $(a^2+b^2+c^2+d^2)_{min}=-1$ This matches with the answer in fact, but how can sum of squares ever result in NEGATIVE . What's the intuition behind this answer is it wrong or I'm going the wrong way.","['algebra-precalculus', 'roots', 'maxima-minima', 'quadratics']"
2353529,Problem on Triangles,"I was solving this question. I solved it. Then I forgot how I solved it. An acute angled triangle $ABC$ has $AD$ as altitude. $E$ is the midpoint of $BC$. $F$ is the midpoint of $AC$. $\angle{EAB}=40°$ and $\angle{EAD}=\angle{EFD}$. Find $\angle{ADF}$. This is the diagram I made. What I cannot understand is how I proved $\angle{AEF}=\angle{ADF}$, or if that is even true, and how to actually get the solution. Can anyone help?","['circles', 'euclidean-geometry', 'triangles', 'geometry', 'contest-math']"
2353542,limit of a sequence,"I know from my intuition that the sequence $$x_n=\left(1-\cfrac{1}{3}\right)^2 \left(1-\cfrac{1}{6}\right)^2 \left(1-\cfrac{1}{10}\right)^2\cdots \cdots\left(1-\cfrac{1}{\cfrac{n\left(n+1\right)}{2}}\right)^2,\quad n\geq2$$ is convergent. 
But i don't know how to prove it.I almost try to apply every theorem I know (for eg ratio  test ,monotone convergence theorem,...). Help me to prove this. Proof or idea is needed.Where does the sequence converge to?","['limits', 'sequences-and-series', 'telescopic-series', 'products', 'fractions']"
2353554,Is the geometrical meaning of cup product still valid for subvarieties?,"It is known that cup product is Poincaré dual to the intersection. I'm referring to  the following fact: if $X$ is a closed, oriented smooth manifold and $A, B$ are transverse-intersecting oriented submanifolds of codimension $i, j$ respectively, then $$[A \cap B]^* = [A]^* \smile [B]^* \in H^{i+j}(X)\space ,$$ where the asterisk denotes Poincaré dual. My question: is the same true if we take $A, B$ to be transverse-intersecting algebraic varieties? (And does that even make sense? I think that an algebraic subvariety defines an homology class given by the pushforward of the inclusion of the top class, and therefore it makes sense; but correct me if I'm wrong). For context: I'm studying Schubert calculus, and I want to use this fact when $A, B$ are Schubert varieties, but I think Schubert varieties aren't smooth manifolds in general, since they contain singular points.","['algebraic-topology', 'schubert-calculus', 'algebraic-geometry']"
2353562,Heat equation with discontinuous sink and zero flux boundary conditions,"I am trying to solve the following problem: $\frac{\partial p}{\partial t}=D\frac{\partial^2 p}{\partial r^2}-\lambda p,$ on the domain $r\in[0,r_w]$ and for times $t\in [0,\infty)$, where $ {\displaystyle \lambda={\begin{cases}\lambda_s,& \text{for } 0<r\leq r_s,
\\ \lambda_w,& \text{for } r_s<r\leq r_w.\end{cases}}}$ The initial condition is a dirac delta function at the right hand end of the domain $p(r,0)=\delta(r-r_w),$ and the boundary conditions are zero flux at either end of the domain: $\frac{\partial p}{\partial r}|_{r=0}=0$ and $\frac{\partial p}{\partial r}|_{r=r_w}=0$. At the intermediate boundary I would like continuity and smoothness of the solution: $p_I(r_s)=p_O(r_s)$, and $\frac{\partial p_I}{\partial r}|_{r=r_s}=\frac{\partial p_O}{\partial r}|_{r=r_s}$, where $p_I$ and $p_O$ are the inner and outer solutions respectively. If there is a reason why these can't be satisfied, I would be interested to hear why. I have tried fourier series solutions for the two distinct parts of the domain but couldn't get the matching correct. Any help would be appreciated.","['ordinary-differential-equations', 'partial-differential-equations']"
2353604,Closed linear operators vs Continuous linear operators,"Suppose we have two real Banach spaces $X, Y$, and a linear operator $A:X \rightarrow Y$. We say that $A$ is closed if whenever $u_k \rightarrow u$ in $X$ and $A u_k \rightarrow v$ in $Y$, then $Au = v$. This definition is very reminiscent of the sequential criterion for continuity of real-valued functions. I assume that there are operators that are closed but not continuous, because otherwise, there'd be no point in having a different word. If my assumption is correct, is this because operators behave differently when we consider more general spaces, or because there is some subtle difference between this definition and the sequential criterion that I'm missing? Also, could someone provide an example of such a function?","['continuity', 'banach-spaces', 'linear-algebra', 'analysis']"
2353620,"If $a + \frac{1}{a} = -1$, then the value of $(1-a+a^2)(1+a-a^2)$ is?","If $a + \frac{1}{a} = -1$ then the value of $(1-a+a^2)(1+a-a^2)$ is? Ans. 4 What I have  tried: \begin{align}
a + \frac{1}{a} &= -1 \\
\implies a^2 + 1 &= -a \tag 1 \\
\end{align} which means \begin{align}
(1-a+a^2)(1+a-a^2) &=(-2a)(-2a^2) \\
&=4a^{3}
\end{align} as $1 + a^{2} = -a$ and $1 + a = -a^{2}$ from $(1)$.","['algebra-precalculus', 'polynomials', 'complex-numbers']"
2353677,How to find missing angles in a quadrilateral,"I have a quadrilateral ABCD , with diagonals AC and BD .
Given are four angles: ∠DAC = 20°, ∠CAB = 60°, ∠ABD = 50°, and ∠DBC = 30°. Those are the red angles in the above image. I need to fill in all the other angles.  Most are trivial – the angles in blue – but how do I find ∠BDC and ∠ACD ?  Their sum is 110, obviously, but I can't figure out how to find the individual angles. Edit: Note that the red angles are examples; I'm looking for a general solution given any values for these angles that form a convex quadrilateral.  (They do if ∠DAC + ∠CAB + ∠ABD < 180° and ∠CAB + ∠ABD + ∠DBC < 180; in that case you can draw triangles ABD and ABC and then quadrilateral ABCD .)","['quadrilateral', 'trigonometry', 'triangles', 'geometry']"
2353679,"If an integrable function has a nonnegative integral over any set of a generating algebra, then it has a nonnegative integral over any measurable set","Let $(\Omega,\mathcal A,\mu)$ be a $\sigma$-finite measure space $f\in\mathcal L^1(\mu)$ and $$\mathcal M:=\left\{A\in\mathcal A:\int_Af\:{\rm d}\mu\ge0\right\}$$ $\mathcal E\subseteq\mathcal M$ be an algebra with $\sigma(\mathcal E)=\mathcal A$ I want to conclude that $$\int_Af\:{\rm d}\mu\ge0\;\;\;\text{for all }A\in\mathcal A\;.\tag1$$ Using the dominated convergence theorem , we should be able to show that $\mathcal M$ is a monotone class and hence $$\mathcal A=\sigma(\mathcal E)\subseteq\mathcal M\subseteq\mathcal A\tag2$$ by the monotone class theorem . Is there any mistake in my argumentation? Moreover, I'm curious whether or not we're able to relax the assumption of being an algebra on $\mathcal E$. In particular, I've found a proof where the author is assuming that $\mathcal E$ is only closed under complement. I've asked another question for that.","['real-analysis', 'monotone-class-theorem', 'proof-verification', 'integration', 'measure-theory']"
2353709,$\|f\|_p\to \|f\|_\infty$ under general assumptions,"I am trying to show that for nonnegative $f$ on $\mathbb{R}$ if $||f||_1<\infty$ , we have $$
\lim_{p\uparrow \infty}\|f\|_p=\|f\|_\infty
$$ I have tried to fiddle around with $$
\left(\int_\mathbb{R}|f|^p|f|^{1-p} \right)^{1/p}<\infty
$$ but haven't found a nice way to get an estimate on $\int_E|f|^p$ from this. Honestly I am pretty uncomfortable with non finite measure spaces. Any hints would be awesome! Any references for problems similar to this would also be awesome. edit: this is not a duplicate of the linked question as 1) my measure space is not finite, 2) my function is in $L^1$ and not necessarily in $L^\infty$","['functional-analysis', 'real-analysis', 'lp-spaces', 'measure-theory']"
2353720,The set of normal numbers is uncountable [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question I'm a grad student tutoring for undergrad math majors and one of them asked this question, I got stuck trying to solve it:
Say a real number in (0,1) is normal if its ternary expansion contains every finite string made up from 0,1,2. Prove the set of normal numbers is uncountable.","['general-topology', 'real-analysis', 'analysis']"
2353781,Guillemin's $\epsilon$-neighbor-theorem: Why does $\pi$ map to the closest point in Y?,"The theorem goes as follows: Let $Y \subseteq \mathbb{R}^n$ smooth, compact manifold. Then for a small enough $ \epsilon>0 $, each $w \in Y^\epsilon := \{ w \in \mathbb{R}^n \big \vert \exists y \in Y: |y-v|< \epsilon\} $ has a unique closest point in Y, denoted $\pi(v)$. Moreover $\pi : Y^\epsilon \rightarrow Y$ is a submersion with $\pi_{|Y}=id$. Parts of the proof are left as an exercise, including the statement that $\pi(w)$ is the unique closest point At this point I have shown that $h: N(Y) \rightarrow \mathbb{R}^n, \; h(y,v)=y+v$, where $N(Y)$ is the normal bundle, $y\in Y$ and $v\in N_yY$, maps a neighborhood of $Y \times 0 \subseteq N(Y)$ onto $Y^\epsilon\subseteq \mathbb{R}^n$, which is a neighborhood of Y. Guillemin defines $\pi =\sigma \circ h^{-1} $, where $\sigma:N(Y) \rightarrow Y$ is the natural projection. I can show that if $\pi(w)$ is indeed a closest point, then for some $\epsilon > 0$ small enough it is unique, but what I haven't been able to show is that $|| \pi(w) -w|| $ really is minimal. I know that a closest point must exist by compactness of $Y$, let's call it $y_{min}$, and I think I have shown that a necessary condition for $y \in Y$ to minimize $||y-w||$ is $(y-w) \perp T_yY $, which would fit my intuition. From the definition one can see that $\pi(w)-w \perp T_{\pi(w)}Y$. But how can I see that $h^{-1}(w)= (y_{min}, w-y_{min})$, such that $\pi(w)=\sigma((y_{min}, w-y_{min}))=y_{min}$ ? I have tried so far to assume that $h^{-1}(w)= (\tilde{y}, w-\tilde{y})$ for some $y_{min}\neq \tilde{y} \in Y$ and either show that $\tilde{y}$ is another closest point, since I show uniqueness only later, or assumed that $\tilde{y}$ is not a closest point and find a contradiction to $h^{-1}$ being a diffeomorphism on $Y^\epsilon$, but neither has been successful so far. Any help would be appreciated.","['geometric-topology', 'general-topology', 'differential-topology']"
2353797,Lie derivative commutes with interior product,"Let $i_X : \Omega^k M \to \Omega^{k-1} M$ be the interior product for a smooth manifold $M$ and a smooth vector field $X$ with flow $\Phi$ and 
$$L_X : \Omega^k \to \Omega^k, \; \omega \mapsto L_X \omega := \frac{\text d}{\text d t} \Big| _{t=0} \Phi^*_t \omega$$
the Lie derivative of a $k$-form. Show that 
$$i_X \circ L_X = L_X \circ i_X.$$ To be honest, I have no clue. What I have proven so far is that the Lie derivative commutes with the exterior derivative ($d \circ L_X = L_X \circ d$), and I have also proven Cartan's magic formula ($L_X = i_X \circ d + d \circ i_X$) by induction. Is there an easy way to use both of these to prove the upper statement?","['lie-derivative', 'differential-geometry']"
2353846,Measure of the image of functions homotopy equivalent to the identity on a Riemann surface,Let $S_g$ be a closed orientable surface of genus $g\ge 2$. Let $f:S_g\rightarrow S_g$ be a continuous function such that $f_*:\pi_1(S_g)\rightarrow \pi_1(S_g)$ is equal to the identity on $\pi_1(S_g)$ (or equivalently $f$ is homotopy equivalent to $Id:S_g\rightarrow S_g$). Is it true that $S_g\setminus f(S_g)$ is a set of measure $0$? Call $V\subset S_g$ a maximal subset such that $f:V\rightarrow S_g$ is injective. Is it true that $S_g\setminus V$ and $S_g\setminus f(V)$ are sets of measure $0$ for every $V$ maximal? Does there exist a maximal $V$ such that $S_g\setminus V$ or $S_g\setminus f(V)$ are sets of measure zero?,"['riemann-surfaces', 'differential-geometry', 'measure-theory', 'homotopy-theory']"
2353850,What is the chance the product of four dice would equal 144?,"Question Four fair six-sided dice are rolled. Out of the 1296 possibilities, what would result in a product of 144? I started out with listing all possible combinations that lead to this product. 6*6*4*1
  $${4\choose2}{2\choose1}{1\choose1} = {4!\over2!1!1!} = 12$$ 6*6*2*2
  $${4\choose2}{2\choose2} = {4!\over2!2!} = 6$$ 6*4*3*2
  $${4\choose1}{3\choose1}{2\choose1}{1\choose1} = {4!\over1!1!1!1!} = 24$$ 4*4*3*3
  $${4\choose2}{2\choose2} = {4!\over2!2!} = 6$$ And then I add all those numbers together. 12+6+24+6 = 48 Obviously this method is inefficient and prone to error. I do not feel confident with my answer (as in, I think it's not even right) and want to know if there's a better way to do this. As a side note I checked out What is the probability of the sum of four dice being 22? but was completely confused on how that worked, so I need some hand-holding here.","['combinatorics', 'probability', 'dice']"
2353873,Normal bundle with Complete intersection,"In general case, consider $X$ be a smooth complex manifold and $S = D_{1} \cap D_{2} \subset X$ be a complete intersection. Is there a relation beetween normal bundle of S, denoted by $N_{S/X}$, and the normal bundle of each hypersurface $D_{i}$ for $i=1,2$?","['algebraic-topology', 'complex-geometry', 'algebraic-geometry']"
2353874,"$A,B \in M(n,\mathbb C)$ with $AB=BA$ , then does there exist $P \in M(n,\mathbb C)$ and $f(X) , g(X) \in \mathbb C[X]$ such that $A=f(P), B=g(P)$? [duplicate]","This question already has answers here : Can commuting matrices $X,Y$ always be written as polynomials of some matrix $A$? (3 answers) Closed 6 years ago . Let $A,B \in M(n,\mathbb C)$ ; if $\exists P \in M(n, \mathbb C)$ and $f(X) , g(X) \in \mathbb C[X]$ such that $A=f(P) , B=g(P)$ then $AB=BA$ . Now suppose $AB=BA$ ; then does there exist $P \in M(n,\mathbb C)$ and $f(X) , g(X) \in \mathbb C[X]$ such that $A=f(P)$ and $ B=g(P)$ ? If this is not true in general , then what if we assume that both $A,B$ are diagonalizable ? Is it true then ?","['polynomials', 'matrices', 'diagonalization', 'linear-transformations', 'linear-algebra']"
2353878,The theorem inverse to Isserlis' theorem,"In probability theory there exists the Isserlis' theorem, which states that if $X=(X_1,X_2,\ldots,X_{2n})$ is a zero mean multivariate normal random vector, then an expectation value of a product $X_1X_2\ldots X_{2n}$ can be calculated as
$$\mathbb{E}\left(X_1X_2\ldots X_{2n}\right)=\sum{\mathbb{E}(X_{i_1}X_{j_1})\mathbb{E}(X_{i_2}X_{j_2})\ldots \mathbb{E}(X_{i_n}X_{j_n})}$$ where sum is for all possible pairings of the set $\left\{1,2,\ldots,2n\right\}$. It's fairly easy to prove this, but in my textbook (non-math) there is a statement I cannot proof: if there is a matrix $D_{mn}$ and all of its eigenvalues are positive and every expectation value for any set of variables from $\left\{X_1,X_2,\ldots,X_{2n}\right\}$ can be calculated by pairing chosen set of variables as $(X_{i_s},X_{i_r})$, taking for each pair corresponding $D_{i_s r_s}$ and multipliing them and then summing productions for all possible pairings, then the vector $X=(X_1,X_2,\ldots,X_{2n})$ is a zero mean multivariate normal random vector with covariance matrix $D$.","['probability-theory', 'probability-distributions']"
2353882,A clarification regarding the Borel $\sigma$-algebra on $\mathbb{R}^{2}$,"Let $B_{2}$ be the Borel-$\sigma$ algebra on $\mathbb{R}^{2}$, that is, the smallest $\sigma-algebra$ that contains all open subsets of $\mathbb{R}^{2}$. Let $B_{1}$ be the usual Borel-$\sigma$ algebra on $\mathbb{R}$. (1) Is $B_{2}$ equal to $B_{1}\times B_{1}$? Prove or Disprove. (2) What about the completion of $B_{2}$ and $B_{1}\times B_{1}$? Are they same? Prove or Disprove. I have been trying this for quiet sometime, but have been unable to do it. I have read this product measure from the book ""Real analysis for Graduate Students-R. Bass"" and this is a problem from the same book. What I know is given two measure space $(X,A,\mu)$ and $(Y,B,\nu)$, the product sigma algebra denoted by $A\times B$ on the space $X\times Y$, is defined to the smallest sigma algebra containing the measurable rectangles, where the measurable rectangles are subsets of $X\times Y$ of the form $a\times b$(where $a\in A, b\in B)$. Now I know that the problem with this product measure is that even if $\mu$ and $\nu$ are complete, the product measure may not be complete. The book has given a very common example taking $\mathbb{R}^{2}$ and the lebesgue measure $m$ on $\mathbb{R}$. So $m\times m$ is the product measure and he shows that this measure is not complete by displaying a null set that is not in the product sigma algebra. And he remarks that the two dimensional lebesgue measure can easily be constructed by taking the completion of this product measure $m\times m$. Also I know that Lebesgue sigma algebra in $\mathbb{R}$ is basically the completion of the Borel $\sigma$-algebra. For the first part I have no idea. But for the second part I think that the completion of $m\times m$ is same as $B_{1}\times B_{1}$ and $B_{2}$. But then I have to prove it which I have no idea about. I hope to get a elaborate explanation so that I can understand this concept clearly. Thanks in advance.","['real-analysis', 'lebesgue-measure', 'measure-theory']"
2353884,Probability of getting at least 1 red or green ball,"I am working on the following problem: We have 2 bags that each contain 3 yellow, 4 blue, 5 red, 6 green and
  2 black balls.   In a simultaneous draw what is the chance of getting
  at least 1 red or 1 green ball? My approach: Find probability of getting at least 1 green ball: $(\frac{14}{20})^2 = (\frac{7}{10})^2= \frac{49}{100}$ is the probability of not getting a green ball in the draw hence $1 - \frac{49}{100} = \frac{51}{100}$ is the probability of getting at least 1 green ball. Find probability of getting at least 1 red ball: $(\frac{15}{20})^2 = (\frac{3}{4})^2 = \frac{9}{16}$ is the probability of not getting a red ball in the draw hence $1 - \frac{9}{16} = \frac{7}{16}$ is the probability of getting at least 1 red ball. Therefore what we are looking for is the sum of these probabilities i.e. $\frac{51}{100} + \frac{7}{16} = \frac{816 + 700}{1600} =\frac{1516}{1600} = \frac{379}{400}$ But my notes say $\frac{319}{400}$ Is this a typo or is my solution wrong?","['probability-theory', 'probability']"
2353895,A four dimensional mapping Torus Parallelizable?,"I want to show that under certain conditions a four dimensional mapping torus is parallelizable.
Let $X$ be a 3 dimensional, compact, orientable Riemann manifold. We know that every such manifold is parallelizable. That means we have three vector fields $X_{1}, X_{2}, X_{3}$ such that they form a basis at any point. Let $f: X \to X $ be a diffeomorphism such that ($f_{p})_{*}X_{i}(p)=X_{i}(f(p))$. Now can I conclude that the mapping torus $M_f$ is parallelizable?","['fiber-bundles', 'differential-topology', 'smooth-manifolds', 'compact-manifolds', 'differential-geometry']"
2353938,How to prove that $C_1e^x$ is the unique solution to $f'=f$?,Is it possible to prove that $C_1e^x$ is the unique solution to $f'(x)=f(x)$? I have tried to suppose there exists $g'=g$ and $g(x)\neq C_1e^x$. But I cannot find any contradiction by myself. Any solutions or hints will be helpful. Thanks.,"['derivatives', 'real-analysis', 'calculus', 'algebra-precalculus', 'ordinary-differential-equations']"
2353946,"Is $\Bbb R$ different from $\Bbb R^ⁿ$ where $n > 1$, in that $\Bbb R$ is not a set of $1$-tuples?","$\Bbb R^n$ where $n\gt1$ seems to be defined as a set of $n$-tuples, while $\Bbb R$ is defined a set of numbers. Some questions: Does $\Bbb R^1$ equal $\Bbb R$, or is it the set $\{(a):a\in\Bbb R\}$? Is e.g. $\Bbb R^2\times\Bbb R^2$ the set $\{((a,b),(c,d)):a,b,c,d\in\Bbb R\}$? Apologies if it's been asked, couldn't find a matching question. Edit: Thanks for the comments and answers so far! There's been a few to the effect that distinctions of this kind don't have any practical consequences. I'm going to attempt to sketch out a scenario where it seems to me they do matter. Suppose I'm presenting some mathematical argument that applies to the Cartesian product $A\times B$ of arbitrary sets $A$ and $B$. Then, it seems natural to think of the resulting entity as a set of ordered pairs, and e.g. ""pick them apart"" by saying e.g. ""let $(a,b)\in A\times B$"", where implicitly $a\in A$ and $b\in B$. Now suppose you look at the special case where $A=B=\Bbb R^2$. It seems like I may still want $a$ and $b$ to still each denote elements of $\Bbb R^2$.","['notation', 'elementary-set-theory']"
2353947,"$G$ be a finite group such that for any subgroup $H,K$ of $G$ , $HK$ is also a subgroup of $G$ , then is every subgroup of $G$ normal?","Let $G$ be a  finite group such that $HK=KH$ for any subgroups $H,K$ of $G$ . Then is every subgroup of $G$ normal ? [Edit]
(to anyone thinking this question is not worth keeping: Here is the response from the OP to a comment from Tobias Kildetoft stating that the condition implies uniqueness of all Sylow subgroups, and hence that $G$ is nilpotent, JL) If for a fixed prime $p$, $H,K$ are two different Sylow-p subgroups then $|H \cap K| < |H|=|K|$ and then the subgroup $HK$ is a $p$-subgroup with order $|H||K|/|H \cap K| > |H|$ , impossible ! Hence for a given prime $p$ , there is a unique Sylow-p subgroup . But I have no idea whether these line of arguments passes to all subgroups or not ... [/Edit]","['finite-groups', 'normal-subgroups', 'group-theory']"
2353955,Radon-Nikodym derivative can depend on the $\sigma$-algebra,"Suppose $X$ is a set and $\mathcal{E} \subset \mathcal{F}$ are two $\sigma$-algebras of subsets of $X$. Let $\mu,\nu$ be two finite positive measures on $(X,\mathcal{F})$ and suppose $\nu \ll \mu$. Let $\bar{\mu}$ be the restriction of $\mu$ to $(X,\mathcal{E})$ and $\bar{\nu}$ the restriction of $\nu$ to $\mathcal{E}$. Find an example of the above framework where $\frac{d\bar{\nu}}{d\bar{\mu}} \ne \frac{d\nu}{d\mu}$, i.e, where the Radon-Nikodym derivative of $\bar{\nu}$ with respect to $\bar{\mu}(\text{in terms of $\mathcal{E}$)} $ is not the same as the Radon-Nikodym derivative of $\nu$ with respect to $\mu$ (in terms of $\mathcal{F}$). For this I took $X=\{0,1,2,3\},\mathcal{E}=\{\{0,1\},X,\phi,\{3,4\}\}, \mathcal{F}=\mathcal{P}(X)$. I chose $\mu$ as counting measure and $\nu(E)=\mu(E \cap\{1\})$. Then $\nu \ll \mu$. Then $\frac{d\nu}{d\mu}=\chi_{\{1\}}$ where as $\frac{d\bar{\nu}}{d\bar{\mu}}=\chi_{\{0,1\}}$. Is this alright? I was wondering if there are examples which look a little more beautiful. Thanks for the help!!","['real-analysis', 'measure-theory', 'analysis']"
2354003,What's special about 323 and squared rectangles?,"The minimal number of squares for rectangles up to longest side 380 is known. The data was calculated for the question "" tiling a rectangle with the smallest number of squares "". I took a look at hard cases for aspect ratios under 2. f(323,319) =18. (shown above) f(323,293) =17. (shown above, along with f(30,293)=17) f(323,317) =16. f(323,283) =16. f(323,281) =16. Those are all of the cases up to 380 that need more than 15 squares.  For 15 squares, add the value 352 as hard. f(323,X)=15, with X in {256, 271, 277, 307, 313} f(352,X)=15, with X in {283, 289, 293, 299, 307, 311, 317, 325, 329, 331, 333, 343, 347, 349, 351} For rectangles needing 14 squares, more than half the values have larger side 323 or 352. If f(a,b) is the minimal number of squares needed for an aXb rectangle, an array plot of those values looks like the following, with gray levels for 1 to 13 squares, cyan for 14 squares, red for 15-18 squares, and yellow for 19+ squares.  The anomalies are at 323 and 352. What is special about 323 (and 352) and squared rectangles? For rectangles with aspect ratios under 2 and relatively prime sides, calculate the average number of squares needed for a given longest edge.  By the oblong conjecture , subtract (edge)^(1/3) +6.  The last two spikes are at 323 and 352.  The middle spike is at 180. Where is the next hard value after 180, 323, 352? UPDATE:  As shown in the answer below, some better solutions exist for f(323,319).  So it turns out there is nothing special about 323, it's just a runtime glitch of some sort on those two rows.  Indeed, it turns out a 13 square solution exists for 323x319.","['graph-theory', 'number-theory', 'tiling', 'integers', 'recreational-mathematics']"
2354004,Sum: $\sum\limits_{n=0}^\infty \frac{n!}{(2n)!}$,"I'm struggling with the following sum: $$\sum_{n=0}^\infty \frac{n!}{(2n)!}$$ I know that the final result will use the error function, but will not use any other non-elementary functions. I'm fairly sure that it doesn't telescope, and I'm not even sure how to get $\operatorname {erf}$ out of that. Can somebody please give me a hint? No full answers, please.","['sequences-and-series', 'error-function']"
2354006,How to avoid ambiguity defining continuity / differentiability of multivariable function,"A function $f(x):\mathbb R^n \rightarrow\mathbb R^1$ is continuous on $\mathbb R^n\setminus \{0\}$ and the limit $\lim_{x\rightarrow0} f(x)$ exists (in a sense is bounded) in any direction to origin. Is this function continuous in the origin, or in order to be continuous there it has to have the same limit value there in all directions? How to differentiate such two cases defining function continuity? Same question arises concerning differentiability. I appreciate any explanations.","['multivariable-calculus', 'continuity']"
2354012,Proof of an integer partitions inequality,"I came across an interesting problem the other day. Let $P_n$ be the number of partitions of a positive integer $n$. For instance $P_4$ = $5$, as there are five ways of partitioning $4$: $4$ $3+1$ $2+2$ $2+1+1$ $1+1+1+1$ Prove that $P_n$ < $\sqrt{P_{n(n+2)}}$. The way I tried to prove this is by bounding $P_n$ from above by some function $F(n)$ and bounding $P_{n(n+2)}$ from below by some function $G(n)$ such that $(F(n))^2$ < $G(n)$. Unfortunately, I wasn't able to find bounds that would satisfy the inequality. How to go about proving this?","['integer-partitions', 'number-theory', 'integers', 'combinatorics', 'discrete-mathematics']"
2354032,How is it justified to apply the chain rule to a function when the inputs themselves are functions?,"Given $u(x,v)$, $v(x,y)$, and $f(u,v)$ ($u$ is a function of $x$ and $v$, and $v$ itself is a function of $x$ and $y$), we want to find ${\partial f}/{\partial x}.$  I've seen this done as: ${\partial f}/{\partial x} = {\partial f}/{\partial u} \cdot {\partial u}/{\partial x} + {\partial f}/{\partial v} \cdot {\partial v}/{\partial x}$. ${\partial u}/{\partial x}$ is then found as if $v$ was a constant (not a function of $x$). However, this seems wrong to me.  The chain rule allows us to separate variables, but how does it allow us to treat functions of the variable we are differentiating against as constants? Nonetheless, this is a common approach in many CS papers, especially concerning machine learning and neural networks.  Backpropogation, a common ML/NN algorithm, seems to rely on it. 
 For a very clear example, see the derivation of ${\partial l}/{\partial x_i}$ in http://costapt.github.io/2016/07/09/batch-norm-alt/ . What is the proof or basis to treat $v$ as a constant when taking the partial derivative with respect to $u$?","['multivariable-calculus', 'computer-science']"
2354047,"Dot product vs Matrix multiplication, is the later a special case of the first?","I seemed to have thoroughly confused myself today... Long story short, the question is simple. Is matrix multiplication just a special case of the dot product of two sets of vectors when the sets of vectors have the same cardinality and all vectors in both sets have the same length? I assume the answer is yes from reviewing the computation of matrix multiplication and the dot product .","['matrices', 'linear-algebra', 'inner-products']"
2354053,Rigid and nef implies numerically trivial [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question If $X$ is a smooth projective variety and $L$ is an effective divisor that is both nef and rigid ($h^0(nD)=1$ for all $n\geq 0$), is $L$ numerically trivial?","['algebraic-geometry', 'birational-geometry']"
2354055,Geometric intuition behind curl of vector field,"If F = P i + Q j + R k is a vector field on $\mathbb{R}^{3}$, then the curl of F is defined by $$\operatorname{Curl}(F) = \nabla \times F$$ where $\nabla$ is the differential operator. Is there a geometric intuition behind the curl of a vector function F ? I would like to see a clear geometric diagram explaining the concept of the curl of F , as my book only gives the definition. Any help is appreciated!",['multivariable-calculus']
2354090,Existence of random variable given first $k$ moments,"A sequence of real numbers $\{m_k\}$ is the list of moments of some real random variable if and only if the infinite Hankel matrix $$\left(\begin{matrix}
m_0 & m_1 & m_2 & \cdots     \\
m_1 & m_2 & m_3 & \cdots  \\
m_2 & m_3 & m_4 & \cdots  \\
\vdots & \vdots & \vdots & \ddots  \\
\end{matrix}\right)$$ is positive definite.  (Source: https://en.wikipedia.org/wiki/Hamburger_moment_problem ) My question is, given only the first $k$ moments, is it sufficient that the top left $k \times k$ minor of the Hankel matrix be positive definite for there to exist a real random variable with those first $k$ moments? In other words, can a $k \times k$ positive definite Hankel matrix always be extended to an infinite positive definite Hankel matrix?","['probability-theory', 'moment-problem']"
2354094,"Find three non-constant, pairwise unequal functions $f,g,h:\mathbb R\to \mathbb R$...","I've been stumped by this problem: Find three non-constant, pairwise unequal functions $f,g,h:\mathbb R\to \mathbb R$ such that
  $$f\circ g=h$$
  $$g\circ h=f$$
  $$h\circ f=g$$
  or prove that no three such functions exist. I highly suspect, by now, that no non-trivial triplet of functions satisfying the stated property exists... but I don't know how to prove it. How do I prove this, or how do I find these functions if they do exist? All help is appreciated! The functions should also be continuous.","['function-and-relation-composition', 'functions']"
2354095,Sufficient condition for open mappings $f:\mathbb{R} \to \mathbb{R}$ to be continuous,"In this problem, we strictly concern ourselves with functions $f:\mathbb{R} \to \mathbb{R}$. Suppose that $(\text{i})$ $\ f$ is open. $(\text{ii})$  $\ f$ is injective. Does it follow that $f$ is continuous? If so, what happens if we change the condition to locally injective (a function is locally injective if for all $x_0 \in \mathbb{R}$ there is a neighbourhood $N_{{x_0}}$ of $x_0$ such that the restriction $f|_{N_{{x_0}}}$ is injective) ? I'm aware that for continuous $f$, $f \ \text{open} \Longrightarrow f \ \text{injective}$ (this is ""sort of"" the converse). I'm also aware that there are discontinuous open mappings, but these are usually very badly behaved, so I'm inclined doubt that there are injective or even locally injective examples.","['general-topology', 'real-analysis', 'continuity', 'functions']"
2354125,Find $\mathbb{P} [ \| Z+a\| \le r \mid \|Z \| \le r ]$ where $Z$ is an i.i.d. Gaussian vector,"How to find \begin{align}
\mathbb{P} [ \| Z+a\| \le r \mid \|Z \| \le r ]
\end{align}
where $Z \in \mathbb{R}^n$ is an i.i.d. Gaussian vector?   Here $\| \cdot\|$ is the Euclidean norm. 
If the close form is difficult to get it would be interesting to see an upper bound that is asymptotically tight as $n\to \infty$. If $\| a\| \ge 2r $ then the probability is zero.  So we have to assume that  $\| a\| \ge 2r $. One can approach this question by using Bayes rule 
\begin{align}
\mathbb{P} [ \| Z+a\| \le r \mid \|Z \| \le r ]= \frac{ \mathbb{P} [ \| Z+a\| \le r , \|Z \| \le r ]}{ P[\|Z \| \le r ]},
\end{align} Note that $P[\|Z \| \le r ]=1-\frac{\Gamma(n/2,r^2/2)}{\Gamma(n/2)}$. So, the question boils down to finding the joint probability $\mathbb{P} [ \| Z+a\| \le r , \|Z \| \le r ]$. As suggested in sketch of a proof by  @kimchi lover   we should define
\begin{align}
(R,S)=(\|Z+a\|, \|Z\|)= \left(\sqrt{ (Z_1+A)^2 +Q}, \sqrt{ Z_1^2 +Q}   \right)
\end{align}
where $Q$ is a chi-square distribution.  In this case
\begin{align}
\mathbb{P} [ \| Z+a\| \le r , \|Z \| \le r ]=\mathbb{P} [R \le r , S \le r ]= \int_0^r \int_0^r f_{R,S}(x,y)dxdy.
\end{align} However, it is not very clear to me how to find the joint distribution  $f_{R,S}(x,y)$.","['probability-theory', 'probability']"
2354127,What are the matrices $ A $ such as $ \exp(A+B) = \exp(A)\exp(B) $ for all $ B $,"In  $ M_n(\mathbb{C})  $ , if two matrices commute, then the exponential of their sum is the product of their exponentials.
This property invited me to reflect on the matrices  $ A $ for which $ \exp(A+B)  =  \exp(A)\exp(B)  $ is true for all complex matrix  $ B $.
I would like to show that such matrices are scalar (proportional to  $ I_n $ ).
What if  $ \mathbb{C} $  is replaced by  $ \mathbb{R} $?","['matrices', 'matrix-exponential', 'linear-algebra', 'lie-algebras', 'lie-groups']"
2354152,Proving that a recursive sequence will eventually reach an even number.,"Take an arbitrary odd natural number $x$, take the recursive sequence given by
$$a_0 = x, a_n= \left \lfloor{ \frac{3 a_{n-1}}{2}} \right \rfloor$$ where $\left \lfloor{ .} \right \rfloor : N \rightarrow N$ is the floor function. I would like to prove that for any $x$ chosen this sequence eventually has an even number in it, I thought this would be doable but I am stuck. How could one prove this?","['real-analysis', 'sequences-and-series']"
2354166,"Solution verification: picking $5$-card hands from standard deck of $52$, with conditions","Problem A 5-card hand is dealt from a perfectly shuffled deck of playing cards. What is the probability of each of the following events? (a) The hand has at least one club. (b) The hand has at least two cards with the same rank. (c) The hand has exactly one club or exactly one spade. (d) The hand has at least one club or at least one spade. My solutions (a) By complement, if there are no clubs, that means we have $13$ ranks but only $3$ suits to choose from, for a total of $39$ cards from which to pick $5$ : $p(E) = 1 - \frac{{39 \choose 5}}{{52 \choose 5}}$ (b) By complement, if at least $2$ cards have the same rank, then the negation of this statement is that no $2$ cards have the same rank, i.e. all $5$ cards are different ranks. This means that we only have $13$ cards to choose from (I think), so I got: $p(E) = 1 - \frac{{13 \choose 5}}{{52 \choose 5}}$ (c) Let $C$ denote the set of outcomes that are exactly $1$ club, and let $S$ denote the set of outcomes that are exactly $1$ spade. These are not mutually exclusive. $p(C \cup S) = p(C) + p(S) - p(C \cap S)$ $p(C)$ : one of the cards is a club, leaving us with $13$ ranks and $3$ suits to choose from (and we choose $4$ cards): ${39 \choose 4}$ $p(S)$ : same logic as above, so we have ${39 \choose 4}$ again $P(C \cap S)$ : one club and one spade, $3$ cards left to choose from $2$ suits of $13$ ranks each, meaning we choose $3$ from $26$ cards: ${26 \choose 3}$ I got: $\frac{2\cdot {39 \choose 4}-{26 \choose 3}}{{52 \choose 5}}$ (d) : at least $1$ club or at least $1$ spade; we can use complement to find the probability of $0$ clubs AND $0$ spades and subtract this from $1$ . If there are no clubs or spades, then we have $13$ cards and $2$ suits to choose from, and we pick $5$ cards, so that's ${26 \choose 5}$ . I got: $p(E) = 1 - \frac{{26 \choose 5}}{{52 \choose 5}}$ Questions/concerns I'd really appreciate if you could verify my work, as the solutions are not available. I'm particularly curious if I did part (b) correctly.","['discrete-mathematics', 'probability', 'card-games', 'combinatorics', 'solution-verification']"
2354183,Beginner in Probability Needs Advice/Guidance,"So, I work for SP+ and make garage signs for them. Most of the math I ever need is Geometry and maybe some trigonometry. My memory of calculus is faint, and I can only recall basic concepts of probability. While was at work, a question about probability and chance occurred to me. We had 20 signs made, but 3 had a missing punctuation. I know that means that 15% of the whole stack has to be fixed and that there is a 3 in 20 chance that whichever random sign I picked would need to be altered. My coworker took half the stack. This is when I thought to myself that I didn't know the chances of getting any of the three signs if half of the randomized stack was taken. My first thought was that half of 15% would be 7.5%. In other words, I would then have a 7.5% chance of getting a sign with a missing piece of vinyl (let's just refer to it as M for simplicity's sake). That seems too simple though. I don't think that would work, and even if it did how would I be able to figure out the chances of getting 1, 2, or all 3 signs in my stack? Adding 7.5 with itself doesn't feel correct. I tried asking my wife (she was a math major a few years back), and she didn't know nor really like probability. I tried googling it, but I'm not even sure what this concept would be called. I stumbled upon something called combining multiple probabilities, but I'm unfamiliar with some of the signs and concepts that are used in the equation. I'm basically leaping from basic probability to this complex problem. I need help in trying to figure this out because the question is continuously nagging at me. Where would I start in trying to figure this out? Is there a special name for this particular type of thing in math? And how would I be able to come to an answer for a similar question in the future?","['probability-theory', 'probability', 'statistics']"
2354225,How many times does $k$ occur in the composition of $n$?,"How many times does the number $k$ occur in the composition of $n$? Composition of Integer In short, the difference between the partition of an integer and composition is the order of numbers. In partition, the order doesn't matter whereas, in composition, it does. That's why Partitions are sometimes called as ordered Compositions. Example: $k$ = $1$ & $n$ = $5$ The composition of 5 are: $5$ $4 + 1$ $3 + 2$ $3 + 1 + 1$ $2 + 3$ $2 + 2 + 1$ $2 + 1 + 2$ $2 + 1 + 1 + 1$ $1 + 4$ $1 + 3 + 1$ $1 + 2 + 2$ $1 + 2 + 1 + 1$ $1 + 1 + 3$ $1 + 1 + 2 + 1$ $1 + 1 + 1 + 2$ $1 + 1 + 1 + 1 + 1$ In all $1$ occurs $28$ times in the composition of $5$ Similarly is there any relation between $k$ and $n$ for all $n \geq 0$ & $k \leq n$","['combinations', 'combinatorics', 'integer-partitions']"
2354232,"Is it possible to evaluate $-\int_0^\infty \log(1-\cosh(x))\frac{x^2}{e^x}\,dx$?","Few minutes ago I was playing with Wolfram Alpha about integrals like this 
$$-\int_0^\infty \log(1-\cosh(x))\frac{x^2}{e^x}\,dx.$$ Previous integral is convergent, and Wolfram Alpha online calculator provide me a closed-form for the indefinite integral int -log(1-cosh(x))x^2e^(-x)dx Notice that my idea was to choose the integration limits from $0$ to $\infty$ with the purpose to get $\zeta(3)$ as a summand in the output. But I don't know how to evaluate all terms, specially those involving the polylogarithm (I know that the other terms are tedious, and one could to calculate those with a CAS). Question. Is it possible to get a closed-form of $$-\int_0^\infty \log(1-\cosh(x))\frac{x^2}{e^x}\,dx.$$
  in terms of particular values of of well-known special functions? Many thanks. If you prefer different calculations of previous explanation (get a closed-form and evaluate the integration limits as did Wolfram Alpha), feel free to tell us your approach.","['integration', 'definite-integrals', 'limits']"
2354240,Let $u \in C^2 (\Omega) \cap C (\bar \Omega) $ be a solution: $\Delta u = f(u)$ in $\Omega$ and $u=0$ on $\partial \Omega$. Show that $u \equiv 0$,"Let $\Omega = \{ (x,y) \in \mathbb R^2: x^2 + y^2<1 \}$ and assume that $f: \mathbb R \rightarrow \mathbb R$ is a strictly increasing function with $f(0) =0$. Let $u \in C^2 (\Omega) \cap C (\bar \Omega) $ be a solution of the following problem: $$\Delta u = f(u)$$ in $\Omega$ and $u=0$ on $\partial \Omega$. Show that $u \equiv 0$.
I have two ideas. The first is to multiply $u$ on the equation first and then integrate, which gives us $\int_{\Omega} |\nabla u|^2 = -\int_{\Omega} uf(u)$,but don't know how to use the condition of $f$. The second one is just integrate the equation which gives us $\int_{\Omega} f(u) = \int_{\partial \Omega} \frac{\partial u}{\partial n}dS$.","['real-analysis', 'analysis', 'partial-differential-equations']"
2354255,Surface element of inverted cone in cylindrical coordinates.,"I have to integrate over the curved surface of a inverted cone, since the surface is of a cone I think all three $s, \phi$ and $z$ are varying under the integral sign. Now this causes the problem, I don't know surface element when all three are varying nor I can find a solution on internet,  I thought I will take $\displaystyle|d\vec a| = s\ ds\ d\phi\ dz$ but that is volume element. What should I do ? Drop $s$ from $\displaystyle |d\vec a| = s\ ds\ d\phi \ dz$ ?","['multivariable-calculus', 'integration', 'calculus']"
2354279,No homomorphism from $Z_{16}\oplus Z_{2}$ onto $Z_{4}\oplus Z_{4}$.,"For some reasons, homomorphism is a very hard area for me to make improvements. I've been hitting the brick wall for almost 2 hours. Prove that no homomorphism exists from $Z_{16}\oplus Z_2$ onto $Z_4\oplus Z_4$. Assume a homomorphism $\phi$ exists from $Z_{16}\oplus Z_2$ onto $Z_4\oplus Z_4$. Then $\phi$ is an isomorphism. Note that the $\left | \ker \phi \right |=2$
The $\ker \phi$ is also a normal subgroup for $Z_{16}\oplus Z_{2}$.
We want possible normal subgroup of order 2. I.e., 2 elements in each normal subgroups. By Lagrange's theorem, the order of each element in a group divides the order of a group so the possible order of the elements are 1 or 2. If the elements has order 1, then the Ker \phi cannot have 2 elements. Hence, $\ker\phi$ = $\left \{ (0,0),(8,0) \right \}$ ,$\left \{ (0,0),(0,8) \right \}$,$\left \{ (0,0),(8,1) \right \}$, possibly. By the First isomorphism theorem: $\phi: Z_{16}\oplus Z_2 \rightarrow Z_2\oplus Z_2$ $\Psi: G/\ker \phi \rightarrow \phi\left ( Z_16\oplus Z_2 \right )=Z_2\oplus Z_2$ $g\ker \phi  \mapsto \phi(g)=\Psi(g\ker \phi)$ Any help is appreciated. Edit: I know that $(2,0)$ has order $8$ in $Z_{16}\oplus Z_{2}$ but any elements in $Z_{4}\oplus Z_{4}$ does not have order $8$ which would have solved the question at the outset. But I would like a different route.","['finite-groups', 'abstract-algebra', 'group-homomorphism', 'group-isomorphism', 'group-theory']"
2354280,Intuitive reason why $\sqrt[n]n\to 1$ as $n\to\infty$?,"We are aware of the limit
$$
\lim_{n\to\infty}\sqrt[n]n = 1;
$$
is there any geometric or otherwise intuitive reason to see why this limit holds? Edit: I am adding some context, since this question was previously put on-hold, and I think one of the main reasons was that it was poorly motivated. From theorem 8.1 of Baby Rudin, suppose the series
$$
\sum_{n=0}^\infty c_nx^n
$$
converges for $|x|<R$, and define
$$
f(x) = \sum_{n=0}^\infty c_nx^n \qquad (|x|<R). \tag{1}
$$
Among other conclusions, the function $f$ is differentiable in $(-R,R)$, and
$$
f'(x) = \sum_{n=0}^\infty nc_n x^{n-1} \qquad (|x|<R). \tag{2}
$$
Rudin uses the fact that $\sqrt[n]n\to 1$ as $n\to\infty$ to justify that the series in $(1)$ and the series in $(2)$ have the same radius of convergence. I recognized the limit, but it is just such a nice combination of $n$ and the $n$th-root, that I thought there ought to be some nice intuitive way to understand it, hence this question.","['intuition', 'real-analysis', 'limits']"
2354334,Proof of fundamental theorem of algebra in Baby Rudin,"I am reading Rudin's proof of FTA. (FTA) Suppose $a_0, \ldots, a_n$ are complex numbers, $n \geq 1$, $a_n \neq 0$, $P(z) = \sum_{k = 0}^n a_k z^k$. Then $P(z) = 0$ for some $z \in \Bbb{C}$. The first part of the proof goes like this: WLOG, suppose $a_n = 1$. Let $\mu = \inf_{z \in \Bbb{C}} |P(z)|$. $\lim_{z \to \infty} |P(z)| = \infty$ (details omitted). Hence there is $R_0 >0$ such that $|z| > R_0 \implies |P(z)| > \color{red}{\mu}$ . Since $|P|$ is continuous on the closed ball $\overline{B_{R_0}(0)}$, the extreme value theorem shows that $|P(z_0)|=\mu$ for some $z_0$. However, I don't think the statement in bold is precisely what he meant. Specifically, ""there is $R_0>0$ such that $|z|> R_0 \implies |P(z)| > \mu$"" does not imply the existence of $z_0 \in \overline{B_{R_0}(0)}$ such that $|P(z_0)|=\mu$: For example, if we consider the exponential function $f(z) = e^z$, then $\mu = 0$ and $f(z) \neq 0$ for all $z \in \Bbb{C}$. In particular, $|z| > 1 \implies |f(z)|>0$. And $|f|$ is continuous on the closed ball $\overline{B_1(0)}$. But it is not true that there is $z_0 \in \Bbb{C}$ such that $f(z_0)=0$. In this example, $\lim_{z \to \infty} |f(z)| \neq \infty$ and $\inf_{|z|\leq 1} |f(z)| = e^{-1}\neq \mu$. So I think the condition $\lim_{z \to \infty} |P(z)| = \infty$ can be better utilized to show that  $\inf_{|z|\leq R_0} |P(z)| = \mu$. Thus, I think he actually meant the following: Hence there is $R_0>0$ such that $|z|>R_0 \implies |P(z)|>\mu+1$. Let $A = \overline{B_{R_0}(0)}$ and $B = \Bbb{C} \backslash A$. Now from the contrapositive, $|P(z)|\leq \color{red}{\mu+1} \implies z \in A$. But $\mu+1>\mu:=\inf_{z \in \Bbb{C}}|P(z)|$. So that there is some $z_1 \in \Bbb{C}$ such that $|P(z_1)|<\mu +1$. Above shows that $z_1 \in A$. Now we claim that $\inf_{z \in \Bbb{C}} |P(z)| = \inf_{z \in A} |P(z)|$. Pick any $z \in \Bbb{C}$. If $z \in A$, then $|P(z)| \geq \inf_{z \in A} |P(z)|$. If $z \in B$, then 
$$|P(z)| > \mu+1 > |P(z_1)| \geq \inf_{z \in A} |P(z)|$$ 
So that $\inf_{z \in A} |P(z)|$ is a lower bound and $\inf_{z \in A} |P(z)|\leq \inf_{z \in \Bbb{C}} |P(z)|$. For $A \subset \Bbb{C}$, $\inf_{z \in \Bbb{C}} |P(z)|\leq \inf_{z \in A} |P(z)|$ and we have  $\inf_{z \in \Bbb{C}} |P(z)|= \inf_{z \in A} |P(z)|= \mu$. Since $|P|$ is continuous on the compact set $A$, the extreme value theorem shows that $|P(z_0)|= \mu$ for some $z_0 \in A$. My questions are, (1) Have I interpreted that first part of the proof correctly? (Done) The complete proof is attached below. I have already gone through the rest of the proof and I understand the logic. Apparently he only uses the fact that $\forall \ z \in \Bbb{C}$, $z = |z|e^{i \theta}$ for some $\theta \in [0,2\pi)$. (2) But does any part of the proof involves is indirectly related to any concept/theorem from complex analysis? I know nothing about complex analysis yet so can anyone provide me some keywords?","['complex-analysis', 'polynomials', 'proof-verification', 'proof-explanation']"
2354337,continuity of function defined by surface integral,"I'm considering this function for positive $r$ $$
\varphi(r) = \int\limits_{\partial B(0,r)} f \, dS.
$$ where $f$ is a $C^1(\mathbb{R}^n)$ function and $\partial B(0,r)$ is the surface of the $n$-sphere. I think this function should be continuous (even if $f$ is only continuous) but I am having a hard time proving it, I should find a small enough $h>0$ so $$
\left| \partial B(0,r+h) - \partial B(0,r) \right| < \varepsilon.
$$ My failed ideas -This would be routine if I had $\partial B(0,r) \subset \partial B(0,r+h)$ but that is false, however if I could somehow transform the integral from the boundary to the interior of the ball that would solve it but I don't know if that's possible. -The other idea was to show that the $\varphi(r) = f(c_r) \operatorname{Measure}(\partial B(0,r))$ for a $c_r$ depending on r and going from there, but then I need assume that $\lim\limits_{h \to 0} c_{r+h} = c_r$ but that's pretty much assuming what I'm trying to prove. I'm probably missing something important here, so any hints would be greatly appreciated.","['multivariable-calculus', 'real-analysis']"
2354356,Positivity result from the strong maximum principle,"In Evans PDE textbook(page 27), it said if $U$ is connected and $u \in C^2(U)\cap C(\bar U)$ satisfies:$\Delta u = 0$ in $U$ and $u=g$ on $\partial U$, where $g \geq 0$. Then, $u$ is positive everywhere in $U$ if $g$ is positive somewhere on $\partial U$. I don't see why. I know the maximum is always achived on the boundary unless it's constant within $U$, but I don't see how they are related here.","['real-analysis', 'analysis', 'partial-differential-equations']"
2354373,Minimize KL-divergence $D(p\|q)$ when $q$ is Gaussian,"Consider $p(x)$ and $q(x)$ are two pdfs of $X$, where $q(x)$ is a Gaussian distribution with the following form $$q(x) = \frac{1}{\sqrt{2\pi\sigma_q^2}} \exp\left(-\frac{x^2}{2\sigma_q^2}\right).$$ Additionally, the variance of $x$ under pdf $p(x)$ is given (constrained), say $\sigma_p^2$, where $\sigma_p \neq \sigma_q$. Note that $p$ can be any pdf which is Lebesgue integrable. Then which distribution $p(x)$ can minimize the KL-divergence $D(p\|q)$? The KL-divergence is defined as follows. $$D(p\|q) = \int_{-\infty}^\infty p(x) \log\frac{p(x)}{q(x)} \, dx.$$ Thanks! Note: If there is no variance constraint of $p(x)$, the answer is simply $p = q$ (a.e.). But this question is based on $\sigma_p \neq \sigma_q$. How to find the minimizer $p(x)$? Thanks a lot!","['probability-theory', 'entropy']"
2354401,Find a cubic polynomial.,"If $f(x)$ is a polynomial of degree three with leading coefficient $1$ such that $f(1)=1$, $f(2)=4$, $f(3)=9$, then $f(4)=?,\ f(6/5)=(6/5)^3?$ I attempt: I managed to solve this by assuming polynomial to be of the form $f(x)=x^3+ax^2+bx+c$, then getting the value of $a,b,c$, back substituting in the equation and so on.... But we can see: $f(x)=q_1(x-1)+1\\f(x)=q_2(x-2)+4\\f(x)=q_3(x-3)+9$ Also when we put $x=1$ we get $f(1)=1^2$, when $x=2$ then $f(2)=2^2$, when $x=3$ then $f(3)=3^2$ but $f(4)\neq4^2$ (from answer). Can this information be used to reproduce $f(x)$ directly without using the step I described in very first line of my solution?","['algebra-precalculus', 'cubics', 'roots', 'polynomials']"
2354417,Why is the matrix in Dirac's bracket formula invertible?,"I am reading the book ""Introduction to mechanics and symmetry"" by J.Marsden and T.Ratiu and am experenced a problem. Let $(P,\Omega)$ be a symplectic manifold, a submanifold $S\subset P$ is called a symplectic submanifold when $\omega:=i^*\Omega$ is a symplectic form on $S, i:S\rightarrow P$ being the inclusion.  Assume that $\dim P=2n,\dim S=2k$. In a neighborhood of a point $z_0\in S$, choose coordinates $z^1,...,z^{2n}$ on $P$ such that $S$ is given by $$z^{2k+1}=0,...,z^{2n}=0,$$
and so $z^1,...,z^{2k}$ provide the local coordinates for $S$. In the formulation of Dirac's bracket formula, it appears the inverse of the matrix defined by $$C^{ij}(z)=\{z^i,z^j\},\ i,j=2k+1,...,2n.$$ The author said that it is easy to see one can choose coordinates such that the matrix $C=\{C^{ij}\}$ is invertible. But I cannot see the reason. Thank you if you can give a short proof or refer me to a good reference. Chengbo","['symplectic-geometry', 'classical-mechanics', 'differential-geometry']"
2354428,Extending homeomorphisms in Cantor set,"Let $C'$ be the ""endpoints"" of the Cantor set $C$. These are the endpoints of the missing intervals, and we know $C'\simeq \mathbb Q$. Does every homeomorphism $h:C'\to C'$ extend to a homeomorphism of $C$? What if I do $\langle b_0,b_1,...,b_n,z,z,z, ...\rangle\leftrightarrow \langle b_0,b_1,...,1-b_n,z,z,z ...\rangle$? In other words, looking at $C'$ as the eventually constant sequences in $2^\omega$, and flipping the value of a sequence at last place before it stays constant? That should produce a homeomorphism, but I wonder if it extends...",['general-topology']
2354443,$\lim_{n\to\infty}\|f-f_n\|_p=0\implies \lim_{n\to\infty}\|f_n\|_p=\|f\|_p$,"Suppose $(X,M,\mu)$ is a measure space, $\mu$ a positive measure $f_n,f\in L^{p}(X)$ and $1\leq p < \infty$ . I want to prove that $\displaystyle\lim_{n\to\infty}\|f-f_n\|_p=0\implies 
\displaystyle\lim_{n\to\infty}\|f_n\|_p=\|f\|_p$ I don't really know how to prove this but I have some ideas. By the Riesz-Fischer theorem, $\{f_n\}\to f$ in $L^p(X)$ implies that there exists a subsequence of $\{f_n\}$ that converges pointwise a.e to $f$ on $X$ . And there is another theorem in Royden's which states that: Theorem 7 Let $E$ be a measurable set and $1\leq p<\infty$ . Suppose $\{f_n\}$ is a sequence in $L^p(E)$ that converges pointwise a.e. on $E$ to the function $f$ which belongs to $L^p(E)$ . Then $$\{f_n\}\to f\ \text{in}\ L^p(E)\ \text{if and only}\ \lim_{n\to\infty}\int_E|f_n|^p=\int_E|f|^p.$$ Does this imply the statement is true? Any help is appreciated. Thank you!","['real-analysis', 'lp-spaces', 'measure-theory']"
2354497,Number of ways to divide a group of N people into 2 groups,"I've seen a bunch of questions about dividing a group of $N$ into groups of a specified size, but I am unsure about how to calculate the total number of ways to divide a group of $N$ people into $2$ distinct groups.. The questions states that one group could be empty, and that a group could have sizes from $0, 1, 2, ..., N$. The question then goes on to ask what is the probability that one of the groups has exactly $3$ people in it. I presume this would be calculated by dividing $N\choose 3$ by the total number of ways calculated above, but any other comments would be greatly appreciated!","['permutations', 'combinatorics', 'probability', 'combinations']"
2354500,Exponential map on product manifolds,"Let $M=M_i \times M_j$. Then if $Exp^i_{\mathbf{p}_i}:T_{\mathbf{p}_i}M_i \to M_i$ and $Exp^j_{\mathbf{p}_j}:T_{\mathbf{p}_j}M_j \to M_j$ are the exponential maps on $M_i$ and $M_j$, respectively, then $\left(Exp^i_{\mathbf{p}_i}, Exp^j_{\mathbf{p}_j}\right)=:Exp_{(\mathbf{p}_i, \mathbf{p}_j)} : T_{(\mathbf{p}_i, \mathbf{p}_j)}M_i \times M_j \to M_i \times M_j$ is the exponential map on $M_i \times M_j$. Is this statement true? The ""feeling"" is that it is and an argument might be that for any $\mathbf{v}\in T_{(\mathbf{p}_i,\mathbf{p}_j)}M_i\times M_j$ the action of the product exponential map is to trace a geodesic having the length of $\mathbf{v}$ and for which $\dot{\gamma}(0)=\mathbf{v}$. Of course, the component exp maps must be defined on the factors of the product tangent space (we can either assume geodesic completeness or amend the definition of the product exp map such that we use a product of neighborhoods in the tangent space domain for which both exp maps are defined).","['proof-writing', 'riemannian-geometry', 'differential-geometry']"
