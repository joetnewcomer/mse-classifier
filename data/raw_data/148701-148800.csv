question_id,title,body,tags
2454332,Homeomorphism and Borel sets,"Suppose that $X,Y,Z$ are metric spaces, equipped with the Borel $\sigma$-algebra. Assume that $f:X\rightarrow Y$ is a homeomorphism, and that $g:Y\rightarrow Z$ is a measureable map (with respect to the Borel $\sigma$-algebra). Is it necessarily true that $g\circ f$ is measureable? Note: this is not as easy as it seems, the obvious proof is not working, let $U$ be open in $Z$, then $(g\circ f)^{-1}(U) = f^{-1}\circ g^{-1}(U)$, $g^{-1}(U)$ is a measureable set, is it necessarily true that a pre-image of a Borel set under a homeomorphism is measureable? Thanks!","['borel-sets', 'general-topology', 'measure-theory']"
2454438,What is the difference between dispersion and mean root square deviation?,"So the question is why do we have mean root square deviation (standard deviation)? 
Isn't it enough just to use only such characteristic as dispersion?
Why is root square deviation (standard deviation) used if we already have dispersion? I'd be very happy to discuss this topic with you, guys!
Thank you in advance!","['probability-theory', 'standard-deviation', 'calculus', 'statistics', 'probability']"
2454440,Negation of the Definition of the Limit of sequence,"I am having trouble understanding this question. What does it mean to negate the limit. Does it mean that n does not have a limit? Also I have done the symbolic negation, is this correct? $\begin{equation}\exists \epsilon > 0, \forall N \in \mathbb Z, \exists n\in \mathbb Z, n > N \wedge \neg L - \epsilon < a_n < L + \epsilon.\end{equation}$. Here is the question: Recall from Calculus the definition of the limit of a sequence $a_n$. We say that the limit of the sequence $a_n$ as $n$ goes to infinity equals $L$ and write: $lim_{n\rightarrow \infty} a_n = L$ We can write this using quantifiers as follows: \begin{equation}\label{limit}\forall \epsilon > 0, \exists N \in \mathbb Z, \forall n\in \mathbb Z, n > N \rightarrow L - \epsilon < a_n < L + \epsilon.\end{equation} Explain in words what the negation of this definition means. Now write the negation of the limit from the given formula.","['predicate-logic', 'logic', 'proof-verification', 'discrete-mathematics']"
2454461,Proving a level set is not an embedded submanifold of $\mathbb R^2$,"I was trying to prove the following: Let $F(x,y)=x^3+xy+y^3$ be defined on $\mathbb R^2$. Show that $F^{-1}[\{0\}]$ is not an embedded submanifold of $\mathbb R^2$. I have verified that $(0,0)$ is not a regular point of $F$ and it is a saddle point. I have read in another question that this implies $F^{-1}[\{0\}]$ is the image of a smooth curve with self-intersections. I would like to solve this problem without using this ""result"", since I don't know a proof of it and haven't found one anywhere, or else I'd like a reference to such a proof.","['smooth-manifolds', 'differential-geometry', 'differential-topology']"
2454476,Fill out a group table with 6 elements,"Let $G=\{0,1,2,3,4,5\}$ be a group whose table is partially shown below: \begin{array}{ c| c | c | c | c |c|c|}
            * & 0& 1 & 2 & 3& 4 & 5\\
            \hline
            0 & 0 & 1  & 2 & 3 & 4 & 5 \\
            \hline
            1 & 1 & 2 & 0 & 4 &    &  \\
            \hline
            2 &  2 &    &    &   &     & \\
            \hline
            3 & 3  & 5  &  &   &  & 1\\
            \hline
            4 & 4  &    &  &   &  &  \\
            \hline
            5 &  5 &   &  &   & & \\
            \hline
        \end{array} Complete the table. Needed to use Inverses, cancellation and No 1 element can repeat per row/col, but got the wrong table. \begin{array}{ c| c | c | c | c |c|c|}
            * & 0& 1 & 2 & 3& 4 & 5\\
            \hline
            0 & 0 & 1  & 2 & 3 & 4 & 5 \\
            \hline
            1 & 1 & 2 & 0 & 4 &  5   & 3 \\
            \hline
            2 &  2 &  0  & 1   & 5  &  3   & 4 \\
            \hline
            3 & 3  & 5  & 4  & 2  & 0 & 1\\
            \hline
            4 & 4  &  3  & 5 & 0  & 1 & 2 \\
            \hline
            5 &  5 & 4  & 3 & 1  & 2& 0\\
            \hline
        \end{array} What is the correct table?","['abstract-algebra', 'group-theory']"
2454610,Probability of $k$ changeovers when a coin is thrown $n$ times with $p=0.6$,"E.g. 2 changeovers from 3 coin flips: H TH . So I have seen the answer to this question with p=0.5 . What would be the answer to $P(k)$ for $k=1, \ldots, n-1$ when $P(Head)=0.6$?","['probability-theory', 'probability']"
2454623,"How can I show $(\pi_1,W_1), (\pi_2,W_2)$ is a smooth atlas for $S^3$","Let $S^3 = \{(x^1,x^2,x^3,x^4) \in \mathbb{R}^4 \mid (x^1)^2+(x^2)^2+(x^3)^2+(x^4)^2 = 1\}$ Let $W_1 = S^3 - (0,0,0,1);$ and $\pi_1: W_1\to \mathbb{R}^3$ by $$\pi_1(x^1,x^2,x^3,x^4) = \left (\frac{x^1}{1-x^4},\frac{x^2}{1-x^4},\frac{x^3}{1-x^4} \right ) $$ Let $W_2 = S^3 - (0,0,0,-1);$ and $\pi_2: W_2\to \mathbb{R}^3$ by $$\pi_2(x^1,x^2,x^3,x^4) = \left (\frac{x^1}{1+x^4},\frac{x^2}{1+x^4},\frac{x^3}{1+x^4} \right ) $$ How can I show that $(\pi_1,W_1), (\pi_2,W_2)$ is a smooth atlas for $S^3$? I know that in order to show this, I need to show that $\pi_1,\pi_2$ are diffeomorphisms, and that $W_1 \cup W_2 \supseteq S^3$ and $\pi_2 \circ \pi_{1}^{-1}$ is $C^\infty$. but I don't know how to show any of these things computationally, how could I do that?","['manifolds', 'smooth-manifolds', 'differential-geometry']"
2454657,"If $x_n$ and $y_n$ are bounded, show that $\lim \inf (x_n + y_n) \leq \lim \inf x_n + \lim \sup y_n$","Suppose you have $x_n$ and $y_n$ that are bounded. Show then that: $$\lim \inf x_n + \lim \inf y_n \leq \lim \inf (x_n + y_n) \leq \lim \inf x_n + \lim \sup y_n  $$ So to show this part: $\lim \inf x_n + \lim \inf y_n \leq \lim \inf (x_n + y_n)$. I defined three sets:
$$X_n = \{ x_k | k \geq n \} $$
$$Y_n = \{y_k | k \geq n \} $$
and $$XY_n = \{x_k + y_k | k \geq n \} $$
Let $n\in \mathbb{N}$. We then have $$XY_n \subset X_n + Y_n$$, thus $$ \inf X_n + \inf Y_n \leq \inf XY_n$$ thus $$ \lim\inf (X_n + Y_n) \leq  \lim \inf XY_n  \iff \lim \inf X_n + \lim \inf Y_n \leq \lim \inf (X_n + Y_n)$$. Now all is left is to show that $$ \lim \inf (x_n + y_n) \leq \lim \inf x_n + \lim \sup y_n .$$ Any ideas how to proceed?","['real-analysis', 'limsup-and-liminf', 'sequences-and-series', 'limits']"
2454684,"We deal 52 cards to 4 players, what is the probability that each player has an ace?","I saw on internet the answer is : $$\frac{13^4}{{52}\choose{4}} $$ but I don't intuitively understand it. So I tried another one that is : $$\frac{{52}\choose{13 \ 13 \ 13 \ 13}}{52!} \cdot 4!$$ Because we will divide 52 cards into 4 groups of 13 cards , there is 52! ways to shuffle the deck and 4! ways to order the 4 aces . But this doesn't give me a correct result..","['combinatorics', 'probability', 'card-games']"
2454725,ln(1+x) maclaurin series,"I found the first four derivatives of 
$ f(x) = ln(1+x) $ Then for all n > 1, $$ f^n(x) = \frac{(-1^{n+1})(n-1)!}{(1+x)^n } $$ So, $$ f^n(0) = (-1^{n+1})(n-1)! $$ By definition Maclaurin Series are defined as: $$\sum_{n=0}^{\infty} \frac{f^n(0)}{n!}x^n$$ *Since the $ f^n(0) $ is only true when n > 1 then, $$\sum_{n=1}^{\infty} \frac{f^{n+1}(0)}{n+1!}x^{n+1}$$ I continue by replacing each term and I get: $$ ln(1+x) = - \sum_{n=1}^{\infty} \frac{(-1)^n}{n*(n+1)}x^{n+1}$$ I know that the answer should be : $$ ln(1+x) = - \sum_{n=1}^{\infty} \frac{(-1)^n}{n}x^{n}$$ Where did I go wrong? ""*"" : Unsure about the step. I'm really bad at taylor series so if you have any good sites for resources, it would be very much appreciated.
Thank you for any help and answers.",['multivariable-calculus']
2454805,How to know when a curve has maximum curvature and why?,"This is a question about understanding the concept of curvature. 
Firstly, what exactly is curvature of a curve (not the formula, what does it actually mean conceptually)?
Secondly, I am confused about how one can figure out when a curve would have the maximum curvature. 
I was told it is when the derivative of the curvature function (k(x)) = 0.
But, I don't understand the concept/reason behind it. In the book I am using there are more than one definitions for curvature. Some of them are: Number One: $$k\left(x\right)=\frac{\left|f''\left(x\right)\right|}{\left[1+\left(f'\left(x\right)\right)^2\right]^{\frac{3}{2}}}$$ Number 2: $$k\left(t\right)=\frac{\left|\vec{r}'\left(t\right)\:\times \:\:\vec{r}''\left(t\right)\right|}{\left|\vec{r}'\left(t\right)\right|^3}$$ Number 3: $$k\left(t\right)=\frac{\left|\vec{T}'\left(t\right)\right|}{\left|\vec{r}'\left(t\right)\right|}$$","['curvature', 'curves', 'calculus', 'geometry']"
2454809,Convergence of a sequence of eigenvectors (nonnegative matrix),"Let $A$ be a $n\times n$ matrix with coefficients in $ [0,1] $ . Let $ B $ be the matrix filled up only with the value $ \frac{1}{2} $ : $$B = \begin{pmatrix}
\frac{1}{2} & \dots  & \frac{1}{2} \\ 
\vdots & \ddots  & \vdots \\ 
\frac{1}{2} & \dots  & \frac{1}{2} 
\end{pmatrix}\,.$$ For all $ t \in ]0,1] $ let $ A(t) = tB + (1-t)A $ . The matrix $ A(t) $ is primitive for any fixed $ t $ . Hence, from the Perron-Frobenius theorem, we have that $ \rho(t) $ (i.e. the spectral radius of the matrix $ A(t) $ ) is a simple eigenvalue, with the relative eigenvector that can be taken positive (i.e. every component is strictly positive). Let me call it $ x(t) $ , choosing it such that $ \|x(t)\|_1 = \rho(t) $ (i.e. the sum of all the components is equal to the spectral radius of the matrix). In this way, I obtain the following properties: \begin{matrix}
A(t)x(t) = \rho(t)x(t) \\
\|x(t)\|_1 = \rho(t)\\ 
x(t) > 0
\end{matrix} My question is: does there exist $ \lim_{t \to 0^+}x(t) $ ? I have read that spectral radius is continuous with respect to any matrix norm, and then I would have: $ \lim_{t \to 0^+}A(t) = A \Rightarrow \lim_{t \to 0^+}\rho(t) = \rho(0) $ . Is it correct? Anyway, passing to the sequences with $ t = \frac{1}{n} $ , I did not succeed in proving that the generated sequence $ x_n = x(\frac{1}{n}) $ is a Cauchy sequence (this fact would imply that $ x_n $ is convergent, because of the sequentially compactness of $ [0,1]^n $ ). I think that the better way in order to prove the existence of the limit above is to prove the monotonicity of the components of $ x_n $ using the monotonicity of the coefficients $ a_{ij}(t) $ of $ A(t) $ . It is only an idea but I do not know if it works. I really thank you in advance.","['matrices', 'eigenvalues-eigenvectors', 'numerical-linear-algebra', 'linear-algebra']"
2454863,Why is the commutator subgroup of the group associated to a finite quandle finitely generated?,"A quandle $Q$ is a set with one binary operation $(x, y) \mapsto  x ∗ y$ which satisfies the following three axioms: i) $\forall x \in Q: x ∗ x=x$ ii) the map $S_{x}: y \mapsto y ∗ x$ is a bijection on $Q$ for all $x \in Q$ iii)$(x∗ y)∗ z=(x∗ z)∗ (y∗ z)$ for all $x,y,z \in Q$ Given a quandle $(Q,∗)$, denote by $G_{Q}$ the group generated by all the elements of $Q$ and the set of relations
$x ∗ y = y^{−1}xy$  for all $x, y \in Q$. I came across a theorem that said: let $(Q, ∗)$ be a finite quandle , then the commutator subgroup $G^{'}_{Q }$ of $G_{Q }$ is finitely generated. But why is that? I mean $G^{'}_{Q }= \langle g^{-1}h^{-1}gh|g,h \in G_Q \rangle$, but you still can generate infinitely many elements of $G_Q$ by using finitely many elements of $Q$. Can someone help me out?","['abstract-algebra', 'group-theory']"
2454867,How are these two definitions of the function $\sin x$ related?,"The high school definition of the sine function can be summarized by the following picture This Wikipedia article says that the sine function can be defined by series. How are these two definitions related? (Since they both define the same thing, I think they should be ""equivalent"". But I don't see why.) My second question might be vague: in practice, are there any concerns about which definition one uses?","['trigonometry', 'soft-question']"
2454926,Relations & Cartesian product explanation,"I'm confused about this notation: $$
R\subseteq A \times B
$$ ( $R$ is a subset of the Cartesian product of $A$ and $B$ ). Cartesian product of $A\times B$ looks like this, right? 1       2        3
x (x,1)   (x,2)    (x,3)
y (y,1)   (y,2)    (y,3)
z (z,1)   (z,2)    (z,3) Where $1$ , $2$ and $3$ index is $B$ , and $x$ , $y$ and $z$ index is $A$ .
And R in the notation means 'Relation' (I guess). But how can a relation be a subset of $A\times B$ ?
Or is it just a way of writing that $R$ is defined in the context of $A\times B$ ? For example: R is defined like this: $$
R = \{(x,y) e Z \times Z | y = x^2 + 2x - 3\}
$$ And that this definition of $R$ occurs for the Cartesian product only? I'm lost here, can someone explain this to me?
I'm also confused about the following notations: If $R\subseteq A\times B$ is a relation, and $(a,b)$ is an element of that relation, we note this: $aRb$ instead of this: $(a,b)\in R$ . And what is the notation $U\subseteq A$ ? And, what exactly is a relation?
Thanks a lot!","['notation', 'discrete-mathematics', 'elementary-set-theory', 'relations', 'definition']"
2454969,Union on the empty set and the set containing the empty set,"I'm trying to get a clearer sense of some of the consequences the axiom of unions has on the empty set. I understand that $\emptyset = \{\} \not= \{\emptyset\}$. But assuming the following identities are correct, I don't understand why $\bigcup\emptyset = \bigcup \{\} = \bigcup \{\emptyset\}$. It's likely that I'm floundering on some minutiae of set theory, but it's making me uncomfortable, and I'd like to know what I'm missing.",['elementary-set-theory']
2454995,What is the best strategy in the game $3 \times 3$?,"2 people play The field of the game is a board of size 3 to 3. The horizontals are numbered-numbers from 1 to 3, and verticals from a to c Each player has an army of 100 tanks Before the battle at night, each side secretly places its tanks in an arbitrary way on 9 squares. On any cell, you can put any number of tanks from 0 to 100. In the morning the battle begins. On each of the 9 cells, the player who has more tanks on this cage wins. For the victory on each of the 9 cells is given 1 point. If there is an equal number of tanks on both sides, then the battle on this cage ends in a draw, and both players receive 0.5 points. Question: What strategy is best for obtaining the maximum number of points?","['game-theory', 'combinatorics']"
2455005,Why is Integral from $a$ to $b$ equal to negative integral from $b$ to $a$ [duplicate],"This question already has answers here : Is integration from $a$ to $b$ same or $b$ to $a$ or is negative? (2 answers) Closed 6 years ago . Why is the integral from $a$ to $b$ equal to negative integral from $b$ to $a$. According to my teacher this is a definition, but definitions still have some logic/reasoning behind it, so what is the logic/reasoning in this case?","['integration', 'calculus', 'definition']"
2455030,Showing that the union of three pairwise intersecting sets is not contractible,"Let $X$ be a ""nice"" Hausdorff space (probably a compact complete metric space).
Suppose that $A_1,A_2$ and $A_3$ are compact, path-connected subsets of $X$ such that: $A_i \cap A_j \ne \varnothing$ is path-connected for all $i,j$; and $A_1 \cap A_2 \cap A_3 = \varnothing$. Is the space $A_1 \cup A_2 \cup A_3$ not contractible, and if so how would you go about showing it? Also, what are the minimum conditions that can be put on ""nice""?","['general-topology', 'homotopy-theory']"
2455062,"Proving by induction that for $m, n\in\omega$ and $m < n$ ,then there exists a $p$ s.t. $n=m+p^+$","I am in a set theory class working with the natural numbers, where $\omega$ represents the natural numbers and $n^+=n\cup\{n\}$ is the successor of $n$ for all $n\in\omega$. The book we use is Enderton. Also, we define addition by recursion:
\begin{align}
+:{}&\omega \times \omega \rightarrow\omega \\
&m+0=m \\
&m+n^+=(m+n)^+.
\end{align} Also, we have that $m ∈ n$ iff $m < n$. Further another theorem states that if $m,n,p\in\omega$ then $m<n$ iff $m+p<n+p$. The question I am asked to solve, by induction, reads: Suppose that $m, n\in\omega$ and that $m < n$. Then there exists $p\in\omega$ such
  that $n = m + p^+$. Now I need help setting up my set and deciding how for the inductive step when we pick $n\in S$ this helps with finding $n^+$ in the set. I want to use induction on $n$. I was thinking: Let $S=\{m,n\in\omega\mid m < n \text{ and there exists }p\in\omega\text{ such that }n=m+p^+\}$. Then $0$ is in the set because nothing is smaller then $0$. The to show that $n^+$ is in the set I am not sure how I would start. What variables would I fix? Or I was thinking of starting by saying let $m, n\in\omega$ and that $m < n$. Then let the set $S=\{p\in\omega\mid n=m+p^+\}$. Then again starting with showing $0$ is in the set.","['proof-writing', 'set-theory', 'proof-verification', 'discrete-mathematics']"
2455068,Lebesgue measurable sets are invariant under translations and dilations?,"From Folland's book, this theorem is proved as following: Actually I am pretty confused about this proof, is there any other way to prove this theorem? More explicitly, can we use the following theorem to prove this? I really appreciate your help","['lebesgue-measure', 'measure-theory']"
2455090,Ways to express a number with a sum of factorials of $n \geq 2$,"I am wondering how I should express a number with a sum of factorials. I know all numbers can be expressed with $1!$ obviously, but how should I go about expressing a number as a sum of factorials $\geq 2$. For example if we take $ 10$, it can be expressed as $3!+2!+2!, 2!+2!+2!+2!+2!$
or $12 = 3!+3!, 3!+2!+2!+2!, 6 \cdot 2!$ I understand that odd numbers can't be expressed in this way at all, however what would be the technique for finding all ways to express even numbers as factorials? Thanks!","['factorial', 'proof-writing', 'discrete-mathematics']"
2455106,"Probability that exactly k bins are empty, given m balls and n bins?","I've searched for an understandable answer to this exact question and have failed to find it. How do you find the probability that exactly $k$ bins are empty, given $m$ balls and $n$ bins? (Each ball drop is independent). The solution to this similar question does not explain how to find the probability that exactly $k$ bins are empty. It mentions the solution in passing in the comments, but does not thoroughly explain how to find the answer.","['balls-in-bins', 'binomial-distribution', 'probability']"
2455117,"Prove the limit of $\cos(1/x)$ does not exist as $x \to 0$, by using Epsilon and Delta.","I was trapped by this question at least for two hours. I negated the definition of limit first, and then try to prove $$\lim_{x \to 0}\cos\left(\frac1x\right)$$ not exist.","['calculus', 'analysis']"
2455118,Using variation of parameters on $2y'' - 3y' +y = (t^2 +1)e^t$,"Suppose $$2y'' - 3y' + y = (t^2 +1)e^t.$$ How do you solve this using variation of parameters? When I try solving this, I get the following answer: 
$$c_1 e^{t/2} + (c_2+\frac{2}{3}t^3 - 4t^2 + 18t)e^t,$$
but the answer in the back of the book (and from WolframAlpha) is 
$$c_1 e^{t/2} + (c_2+\frac{1}{3}t^3 - 2t^2 + 9t)e^t.$$ Here is an outline of my attempt. First, we solve
$$2y'' -3y' +y = 0$$
and find that $y_1(t) = e^{t/2}$ and $y_2(t) = e^t$ are solutions. We next find $u_1(t)$ and $u_2(t)$ so that $y(t) = u_1(t)y_1(t) + u_2(t)y_2(t)$ is a solution to the original differential equation. The Wronskian is $W[y_1,y_2](t) = e^{3t/2}/2$. So, let
 $g(t) = (t^2 + 1)e^t.$ We find that 
$$u_1(t) = \int -\frac{g(t)y_2(t)}{W[y_1,y_2]}dt = -2\int(t^2+1)e^{t/2}dt.$$
Using integration by parts twice yields
$$u_1(t) = -4(t^2+1)e^{t/2} + 16te^{t/2} - 32e^{t/2},$$
which matches with what WolframAlpha says the integral is (after some slight simplifying). Then, 
$$u_2(t) = \int \frac{g(t)y_1(t)}{W[y_1,y_2]} dt = 2\int (t^2 + 1) dt.$$
And hence $u_2(t) = 2(t^3/3 + t)$. My solution is thus $y =(c_1 + u_1)y_1 + (c_2+u_2)y_2$, which after simplifying, gives what I wrote above (after absorbing the constant $-36$ into the constant $c_2$).",['ordinary-differential-equations']
2455121,Distributing gifts so that everybody gets at least one,"So I was in class discussing the following problem: We have $20$ different presents to distribute to $12$ children. It is not required that every child get something; it could even happen that we give all the presents to one child. In how many ways can we distribute the presents? After some discussion we realized that the answer was $12^{20}$ , because the problem could only be solved if we saw this from the perspective of the presents and not from the children. I thought it was very cool. Then I went home and thought of a corollary to the problem: how many ways are there so that each child gets at least one present? I have been thinking for a week and I cannot solve it. I thought it was $12^{12} \times 12^8$ , the first number to represent the presents distribute to at least one child and the other the ones spread out without discrimination. However, that number is bigger than the original number of ways which makes no sense. How would you go about solving this?","['combinatorics', 'discrete-mathematics']"
2455132,How to demonstrate the subset definition?,"I'm having a hard time trying to demonstrate the definition of a subset, which is : $S \subseteq T \Leftrightarrow (S \subset T) \vee (S = T)$ I always end up by expending the definitions of $\subset$ and $=$ in Boolean algebra, resulting into this complicated situation . Any way to solve it by staying in the Set theory? Or in Boolean algebra?","['boolean-algebra', 'elementary-set-theory', 'discrete-mathematics']"
2455169,Are there commutative operations beyond exponentiation?,"Most of us know that multiplication is repeated addition and that exponentiation is repeated multiplication. You will notice if you begin solving certain problems that addition and multiplication are commutative, but suddenly exponentiation is not commutative. For example: $2^3 = 8$ $3^2 = 9$ $8$ is not equal to $9$ My question is, are there operations beyond exponentiation that are commutative (I know tetration is the next operation after exponentiation, but I'm pretty sure it's not commutative)? If there are, what are they? If not, do we know why there aren't any?",['algebra-precalculus']
2455195,Probability of the highest roll in two die pools being the same,"Say we roll n identical, fair dice, each with d sides. (Every side comes up with the same probability.) On each die, the sides are numbered from $1$ to d with no repeating numbers, as you would expect. So it's an ordinary d sided die pool. How would we calculate the odds of the highest rolled die value from a given dice pool equaling the highest rolled die value from a different dice pool?","['probability', 'dice']"
2455199,How many $4$ digit numbers can be made with exactly $3$ digits the same?,Can anyone help to verify if my reasoning is correct? The way I look at it is that if we use: (all possible combinations) - (at most two digits are the same) - (exactly $4$ digits are the same) then we get exactly $3$ digits are the same namely: $$9 \cdot 10 \cdot 10 \cdot 10 - 9 \cdot 10 \cdot 10 \cdot 9 - 9$$ Is that right?,['combinatorics']
2455218,Prove HEP with Yoneda,"If there is given an top. embedding $i:A \subset X$ and there exists a retraction $r: X\times I \to A\times I \cup X\times \{0\}$ I want to show that this induces the cofibration property of $i$, therefore HEP holds: For given $g:X \to Y$ and homotopy $h:A \times I \to Y$ with $g \circ i = h(-,0)|_A$ and $h(-,0) = g$ there exist a homotopy $H: X \times I \to Y$ such that $H|_{i(A) \times I}=h$. The crux of the matter is that I found already some proofs in Hatcher and TvDieck but I heard that there is an elegant way to prove using Yoneda lemma. Unfortunately I don't see how ...","['category-theory', 'general-topology', 'homotopy-theory']"
2455221,Differentiation with respect to matrix,I have matrices $W$ and $X$ of dimensions $h\times d$ and $d\times1$ respectively. I want to calculate the partial derivative of $WX$ with respect to $W$. Will that be $X$?,"['derivatives', 'vectors', 'matrices', 'partial-derivative', 'implicit-differentiation']"
2455226,Why these tensor fields do not depend on the hypersurfaces chosen to define them?,"In the paper Dynamics of Extended Bodies in General Relativity. I. Momentum and Angular Momentum , W.G. Dixon proposes definitions for momentum and angular momentum of a certain distribution of matter in GR described by an energy momentum tensor $T$ and a current one-form $J$ on spacetime $(M,g)$. Essentialy, he defines $W = \operatorname{supp}T\cup \operatorname{supp}J$ as the so-called ""world tube"" of the matter and supposes that: if $\Sigma \subset M$ is one spacelike hypersurface such that $W\cap \Sigma\neq \emptyset$ then there is one open set $N_\Sigma\subset M$ such that $W\cap \Sigma\subset N_\Sigma$ and $N_\Sigma$ is a normal neighborhood of all its points. Under these conditions he defines: $$p^{\kappa}(z,\Sigma)=\int_\Sigma (K^\kappa_\alpha(x,z)\mathfrak{T}^{\alpha\beta}(x)+\Psi^{\kappa}(x,z)\mathfrak{J}^{\beta}(x))n_\beta(x)d^{n-1}x$$ $$S^{\kappa\lambda}(z,\Sigma)=2\int_\Sigma \sigma^{[\lambda}(H^{\kappa]}_\alpha(z,x)\mathfrak{T}^{\alpha\beta}(x)+\Phi^{\kappa]}(x)\mathfrak{J}^\beta(x))n_\beta(x)d^{n-1}x$$ where $\Sigma\subset M$ is a spacelike hypersurface, $n$ is its normal vector, with $z\in \Sigma\cap W \neq \emptyset$. Also $K^{\kappa}_\alpha$, $H^\kappa_\alpha$, $\Psi^\kappa$, $\Phi^\kappa$ are two-point tensors whose definitions don't really seem to matter here. The issue is that he derives that on maximally symmetric spacetimes (those with constant curvature), given a one-paramter family of hypersurfaces $\Sigma(s)$, $s\in (a,b)$ and a path $\gamma : (a,b)\to M$ with $\gamma(s)\in \Sigma(s)$ the tensor fields over $\gamma$ defined by $$p^{\kappa}(s)=p^{\kappa}(\gamma(s),\Sigma(s)),\quad S^{\kappa \lambda}(s)=S^{\kappa\lambda}(\gamma(s),\Sigma(s))$$ satisfy the differential equations (with $k$ the constant curvature) $$\dfrac{D}{ds}p^{\kappa}=k S^{\kappa\lambda}\dot{\gamma}_{\lambda},\quad \dfrac{D}{ds}S^{\kappa\lambda}=2p^{[\kappa}\dot{\gamma}^{\lambda]}.$$ Now the author of the paper says in his words: The pair of equations (5.7) and (5.9) [those above] can now be integrated along $L$ given the values of $p^\kappa$ and $S^{\kappa\lambda}$ at one point of it. This shows that $p^{\kappa}$ and $S^{\kappa\lambda}$ must be independent of the particular choice of $\Sigma$, depending only on the point $z$ at which they are evaluated. They are thus well defined tensor fields on $M$. Now I can't understand. He says that those equations implies that the definitions he gave are actually independent of $\Sigma$, i.e., $p^{\kappa}(z,\Sigma)=p^{\kappa}(z,\Sigma')$ and $S^{\kappa\lambda}(z,\Sigma)=S^{\kappa\lambda}(z,\Sigma')$ for distinct $\Sigma,\Sigma'$ with $z\in \Sigma\cap \Sigma'\cap W$. How to understand what the auhtor says? Why these equations implies independence of $\Sigma$? I thought that it is because if I pick the same curve with two choices of $\Sigma,\Sigma'$, the differential equation is the same, but if I pick another curve connecting two points, why would it be the same, for example? What really is the point here that solving this equation on the curve implies indepdence of $\Sigma$?","['semi-riemannian-geometry', 'general-relativity', 'mathematical-physics', 'ordinary-differential-equations', 'differential-geometry']"
2455280,Existence of Limit for $x_{n+1} = 1+1/x_{n}$,"I'm attempting to prove that if one defines a sequence with $x_{1} = 1$ and 
$$x_{n+1} = 1+\frac{1}{x_{n}}$$
for all $n >1$ then the limit of $\{x_{n}\}_{n \ge 1}$ exists. My Attempt:
Since $\{x_{n}\}_{n \ge 1}$ was defined recursively I immediately thought to try and prove that the sequence is monotone and bounded. The problem is that $\{x_{n}\}_{n \ge 1}$ is an alternating sequence. Its first few values are $1,2,3/2,5/8,\ldots$. I checked boundedness next. Since $x_{1} = 1 \le \frac{1+\sqrt{5}}{2}$ we induct on $n$ and assume $x_{n} \le \frac{1+\sqrt{5}}{2}$. For the $x_{n+1}$ case we find that $x_{n+1} \ge \frac{1+\sqrt{5}}{2}$ which I thought was a little odd... Is there another way I should be attacking this proof or can I fiddle with the sequence a bit to use MCT?","['real-analysis', 'limits']"
2455288,Rock Paper Scissors Team Building with Rule Change,"There is a simple icebreaker game where a group of people compete in a rock-paper-scissors (RPS) tournament. When person A beats person B, they become a team where person A is the leader. And in general, when team A beats team B, they all become one team, and A's leader becomes the leader of the new team. This game always ends quickly with everyone on the same team. As Ross Millikan pointed out in the comments, it always takes exactly $n-1$ games. But I'm wondering what would happen if we changed the rules slightly. Suppose team A beats team B. Then team A acquires B's leader, and the rest of team B dissolves into a bunch of teams of 1. For example, if a team of 4 beats a team of 6, then it will result in a team of 5 and 5 teams of 1. It makes sense that this game would last longer because teams can be dissolved. I am specifically interested in finding out the average number of RPS games played in a tournament of $n$ people (they all start out as teams of 1) before there is only 1 team. To make this number well defined, I assume the following: Only one RPS game is played at a time. Each RPS game is played between a random pair of teams, with equal probabilities. The result of each RPS game is completely random (50/50). (Perhaps rock paper scissors was a bad analogy because it has ties. Just imagine that ties are played out until there is a winner, and that we're not counting ties in our running total of RPS games.) I have constructed Markov Chains for a few values of $n$ where the nodes are the different partitions of teams. Using them, I have found that the average number of RPS games played seems to be $$2^{n-1}-1$$ I have no idea why this would be, or how to prove it, but maybe it is just a coincidence that it works for $1\le n\le6$ (or maybe I calculated them wrong). Can anyone prove a formula for the average number of RPS games? I would also appreciate it if anyone can programmatically verify my formula for larger values of $n$.","['markov-chains', 'probability']"
2455326,First-order set theory : What is the class of all sets in ZFC?,"What do we mean when we let the universal set be the class of all sets? How do I intuitively think about this? Do I just think of it as a collection of all sets? Also, is the Axiom of Regularity a part of ZFC? I have to prove a statement in the class of all sets, but I'm not sure what I'm supposed to assume since I've no idea what a class is (besides the definition 'a collection which is not a set because it causes paradoxes i.e Russel's paradox)","['axioms', 'first-order-logic', 'logic', 'elementary-set-theory']"
2455344,Computing Hessian using matrix notation efficiently,"I answered this question , but I'd like to understand more details about the matrix notation behind it (and that's why I'm making another post). We have $f:\Bbb R^n\to \Bbb R$ given by $$f(\theta) \doteq \alpha e^{-\beta \theta^\top\theta}, $$alright. We want to compute the bilinear map ${\rm Hess} f (\theta)$. Since I recognize $g (\theta)\doteq\theta^\top \theta$ as $\langle \theta,\theta\rangle$ (of course, $\langle \cdot,\cdot\rangle$ denotes the usual scalar product), I see that $$Dg(\theta) = 2\langle \theta, \cdot \rangle = 2\theta^\top, $$and hence $\nabla g (\theta) = 2\theta $. Then chain rule gives $$\nabla f (\theta) = -2\alpha \beta e^{-\beta \theta^\top \theta}\theta $$as the OP of the linked question states, so far so good. I'm having trouble doing something similar to check that $${\rm Hess}f (\theta)=2\alpha \beta e^{-\beta \theta^\top\theta}(2\beta \color{blue}{\theta\theta^\top}-{\rm Id}_n).$$I do not want to use components as I did there. A simple attempt is to use the product rule together with ${\rm d}\theta ={\rm Id}_n $. Differentiating the expression for $\nabla f (\theta) $ we get $$-2\alpha\beta (e^{-\beta\theta^\top\theta}(-2\beta \theta^\top)\theta +e^{-\beta \theta^\top\theta}{\rm Id}_n) = 2\alpha \beta e^{-\beta \theta^\top\theta}(2\beta\color{red}{\theta^\top\theta}-{\rm Id}_n), $$but this doesn't compile, and I can't see why the order comes out wrong. So I'd like to know exactly what identification am I missing here. I also recognize $\theta\theta^\top$ as the matrix of the bilinear map $\theta \otimes \theta$, and I'm comfortable with tensor products, so you can come in with guns blazing, if needed. Thanks.","['multivariable-calculus', 'hessian-matrix', 'matrix-calculus']"
2455355,In how many ways can a student score exactly $100$ points on four $50$ point exams? greater than $100$?,"A student takes up $4$ exams with $50$ points each. In how many ways can he score exactly $100$? Similarly, in how many ways can he score greater than $100$? My try: I cannot seem to fill in the $4$ possibilities. The range depends on the constraint of equating to $100$. Thanks for any help!","['permutations', 'combinatorics']"
2455366,The composition of two involution functions,Is the composition of two involution functions always an involution? I think this is probably not the case but would like if someone could provide me with some counter-examples.,['functions']
2455371,"When solving PDEs by separation of variables, why are we allowed to divide by the dependent variable?","When solving PDEs in physics, one common tool in use is separation of variables. However, to me, there exists a big problem when one divides both sides of a equation by some function that might be $0$. Here in this link ( Laplace's equation 1: Separation of variables , Rudolf Winter, 2008), when we divided by $XY$, should not we assume $XY$ is not $0$? But it seems like $XY$ could be 0 in the general solution. Why is that?","['ordinary-differential-equations', 'calculus', 'partial-differential-equations']"
2455388,Solution of the differential equation $2x^3dy + (1 - y^2)(x^2y^2 + y^2 - 1)dx = 0$.,"Find the solution of the differential equation 
  $$2x^3dy + (1 - y^2)(x^2y^2 + y^2 - 1)dx = 0$$ My attempt: After arranging the above equation as $$\frac{dy}{dx}=\frac{(1-y^2)(x^2y^2+y^2-1)}{-2x^3}$$ I am not getting any standard method to get to the next step. Any suggestion will be helpful.",['ordinary-differential-equations']
2455428,An identity involving binomial coefficients and rational functions,"While going through some exercises in my analysis textbook, I came up with an equation which looks like an identity. I strongly believe that this is the case, but I couldn't prove this. $$\sum_{0\leq k\leq n}(-1)^k\frac{p}{k+p}\binom{n}{k} = \binom{n+p}{p}^{-1}$$ Can someone provide a proof of this identity? Also, it would help a lot if you could explain the general strategy of proving such identities, if there is one, for me. Thank you.","['combinatorics', 'binomial-coefficients', 'combinatorial-proofs']"
2455493,Alernative way of solving summation $5+55+555+\ldots$,"Question Find the summation for the series-: $$5+55+555+5555+...$$ I know it is a duplicate of this , but still, I am posting this because i was thinking of solving another way due to which I got stuck in another series. My Attempt $S=5+55+555+5555....$ $2*S=10+110+1110+11110....$ $=10*(1+11+111+1111+...)$ $=\frac{10}{9}*(9+99+999+9999+...)$ $=\frac{10}{9}*((10-1)+(10^{2}-1)+(10^{3}-1)+(10^{4}-1)+...)$ $=\frac{10}{9}*(10*\frac{10^{n}-1}{10-1}-n)$ $=\frac{10}{9}*(\frac{10^{n+1}-10}{9}-n)$ $$S=\frac{5}{9}*(\frac{10^{n+1}-10}{9}-n)$$ So i think i got my answer.But i have doubt in summation of series-: $S=10+110+1110+11110....$ I got summation (from above ) as-: $=\frac{10}{9}*(\frac{10^{n+1}-10}{9}-n)$ But here , it is different .Which one is correct? I am stuck .
Please help me out !","['geometric-progressions', 'arithmetic-progressions', 'summation', 'sequences-and-series']"
2455648,Extending three vectors to commuting vector fields,"The following claim can be found in page 27 of Petersen's book ""Riemannian Geometry"": ""... any three vectors can be extended to vector fields that commute."" I have been unable to prove the statement, mostly because the equations determining the commutativity of vector fields are a system of nonlinear partial differential equations, although their symmetry might make them easier to treat. I was wondering if someone could help me find an existence theorem for the Cauchy problem of such equations, or figure out a way to prove such a claim.","['cauchy-problem', 'vector-fields', 'differential-geometry', 'partial-differential-equations']"
2455702,Sum of number of vertices in a graph,"Question Let $T$ be a tree on $100$ vertices. Let $n_{i}$ be the number of vertices in $T$ which have exactly $i$ neighbors. Let $$s= \sum_{i=1}^{100}\,\, i . n_i$$ Which of the following is true? $A)s=99$ $B)s=198$ $C)99 \: < \: s \: < \: 198$ $D)$ None of the above My Approach Making it simple, I assumed it as skewed tree.So every vertex other than leaf will have exactly $1$ neighbour and only leaf node( $100^{th}$ vertex) will be having $0$ vertex. $$s=\sum_{i=1}^{100}\,\, i . n_{i}$$ $$s=1*1+2*1+3*1+....99*1+100*0$$ $$s=4950$$ So it should be none of these. Am I right?","['combinatorics', 'graph-theory']"
2455715,Prove that the greatest integer function $\lfloor x\rfloor$ is continuous at all points except at integer points.,"Prove that the greatest integer function $\lfloor x\rfloor$ is continuous at all points except at integer points. I was solving this function , now the question that arises is that I was solving this using an example i.e. A numerical value, but my teacher keeps saying that it's wrong or I have to solve it using constants such as k... Etc. Is this method wrong according to u? i) f(x) = [x], for all x in R
==> By the definition of greatest integer function: If x lies between two successive integers, then f(x) = least integer of them. ii) So, at x = 2, f(x) = [2] = 2 -------- (1) Left side limit (x ---> 2-h): f(x) = [2 - h] = 1 ----- (2)
{Since (2 - h) lies between 1 & 2; and the least being 1} Right side limit (x --> 2+h): f(x) = [2 + h] = 2 -------- (3)
{Since (2+h) lies between 2 & 3; and the least being 2} iii) Thus from the above 3 equations, left side limit is not equal to right side limit.
So limit of the function does not exist.
Hence it is discontinuous at x = 2
So this is not derivable at x = 2
Hence Proved.","['continuity', 'ceiling-and-floor-functions', 'calculus', 'functions']"
2455738,Is $f(x)=\frac{1}{x}$ invertible?,"Let $f(x)=\frac{1}{x}$, then $f^{-1}(x)$ must equal $$y=\frac{1}{x}$$ and after swapping the variables $$x=\frac{1}{y}$$and rearranging to solve for $y$, $$\frac{1}{x}=y$$ that being said, can you conclude that $f^{-1}(x)=\frac{1}{x}$? I know it works since, when you take $f(f^{-1}(x))$ the result is $x$, it's just unheard of to me to have a function whose inverse is itself... Any help is appreciated.","['inverse-function', 'functions', 'inverse']"
2455743,How can you comment this calculation step to avoid points deduction by teacher?,"Solve the initial value problem: $y'+2y=e^{-x}$ with $y(0)=4$ Our teacher gave me a mistake / unclear mark at the part which I will mark red here. But I don't understand why and I no longer have the opportunity to ask him. This is an extract of my solution (it leads to the correct solution): $$e^{2x} \cdot \frac{dy}{dx} + e^{2x} \cdot 2y = e^{2x} \cdot e^{-x} \Leftrightarrow$$ $$\Leftrightarrow \color{red}{\frac{d}{dx} \cdot e^{2x} \cdot y} = e^{x} \Leftrightarrow$$ $$\int{\frac{d}{dx} \cdot e^{2x} \cdot y} \text{ } dx = \int{e^x} \text{ } dx$$ $$...$$ I don't understand, is an explanation here really required? So I took that $y$ from $\frac{dy}{dx}$ and wrote it at the end of the term and now we got $\frac{d}{dx}$ at the front. $\frac{d}{dx}$ means ""the derivative of.."" (whatever comes after). And taking that derivative, we will get what we had before (the line before the red marked line), so they are equal to each other. But how would you explain that (on paper) in a reasonable way? I don't know if my current explanation is fine. Edit: When I handed this in, I used brackets too. The reason I got point deduction is ""how do you get from here to there?"" (first line to red line).","['derivatives', 'calculus', 'integration', 'ordinary-differential-equations', 'analysis']"
2455780,Sum of series $\frac{x}{1-x^2} + \frac{x^2}{1-x^4} + \frac{x^4}{1-x^8} +\ldots$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question The problem is to find the sum of series $$\frac{x}{1-x^2} + \frac{x^2}{1-x^4} + \frac{x^4}{1-x^8} +\ldots$$
  to infinite terms, if $|x|<1$ I tried taking $\frac{x}{1-x^2}$ outside but could not solve it.
How to proceed further?","['geometric-progressions', 'sequences-and-series']"
2455789,"On a Riemannian $3$-manifold, what is the relation between the Levi-Civita connection $\nabla$ and the cross product $\times$?","Let $(M,g)$ be a Riemannian $3$ -manifold and $X\perp Y\in \mathfrak{X}(M)$ . then What is the relation between $\nabla$ and $\times$ ? Is it possible to calculate $\nabla _X(X\times Y)$ and $\nabla _{(X\times Y)}X$ in general in term of $X,Y$ ? where $\nabla$ is Levi-civita connection and $\times$ cross  product.","['riemannian-geometry', 'differential-geometry']"
2455838,Generating iid samples of mixture of distributions,"Let $D_1$ and $D_2$ be distributions. Assume that:
- one can always get finite amount of iid samples from $D_1$
- one can always get finite amount of iid samples from $D_2$
Let also $D=\frac12 D_1 + \frac12 D_2$ and $m$ be an integer.
How can we get at least $m$ i.i.d. samples from $D$? Is it true that we can just pick $m/2$ iid samples from $D_1$ and $m/2$ iid samples from $D_2$?","['probability-theory', 'sampling', 'probability-distributions', 'statistics', 'probability']"
2455972,Conditional probability of multivariate gaussian,"I'm unsure regarding my (partial) solution/approach to the below problem. Any help/guidance regarding approach would be much appreciated. Let $\mathbf{X} = (X_1, X_2)' \in N(\mu, \Lambda ) $ , where $$\begin{align}
    \mu &= \begin{pmatrix}
           1 \\
           1
         \end{pmatrix}
  \end{align}
$$ $$
\begin{align}
    \Lambda &= \begin{pmatrix}
           3 \quad 1\\
           1 \quad 2
         \end{pmatrix}
  \end{align}
$$ We are tasked with computing: $P(X_1 \geq 2 \mid X_2 +3X_1=3)$ I here begin by doing a transformation, $$ \mathbf{Y} = (Y_1, Y_2)', \qquad Y_1 = X_1, \qquad Y_2 = X_2 + 3X_1$$ We now are interested in the probability, $$P(Y_1 \geq 2 \mid Y_2 = 3)$$ Since we can write that $\mathbf{Y = BX}$ , it follows that, $$\mathbf{Y} \in \mathcal{N}(\mathbf{B\mu, B\Lambda B')})$$ where $$\mathbf{B}= \begin{pmatrix}
           1 \quad 0\\
           3 \quad 1
         \end{pmatrix} \rightarrow \quad \mathbf{B \mu} = \begin{pmatrix}
           1 \\
           4
         \end{pmatrix}, \quad \mathbf{B\Lambda B'}= \begin{pmatrix}
           1 \quad 0\\
           3 \quad 1
         \end{pmatrix} \begin{pmatrix}
           3 \quad 1\\
           1 \quad 2
         \end{pmatrix} \begin{pmatrix}
           1 \quad 3\\
           0 \quad 1
         \end{pmatrix} = \begin{pmatrix}
           3 \quad 10\\
           10 \; \; 35
         \end{pmatrix}$$ We thereafter know that we can obtain the conditional density function by, $$
f_{Y_1\mid Y_2 = 3} (y_1) = \frac{f_{Y_1,Y_2}(y_1, 3)}{f_{Y_2}(3)} \tag 1
$$ The p.d.f. of the bivariate normal distribution, $$f_{Y_1, Y_2}(y_1, y_2) = \frac{1}{2\pi \sigma_1 \sigma_2 \sqrt{1-\rho^2}} e^{\frac{1}{2(1-\rho^2)}(\frac{(y_1 - \mu_1)^2}{\sigma_1^2} - \frac{2 \rho (y_1 - \mu_1)(y_2 - \mu_2)}{\sigma_1 \sigma_2} + \frac{(y_1 - \mu_1)^2}{\sigma_2^2})} $$ The marginal probability density of $Y_2$ , $$f_{Y_2}(y_2) = \frac{1}{\sqrt{2\pi} \sigma_2} e^{-(y_2 - \mu_2)^2 / (2\sigma_2^2)}$$ Given that, $$\sigma_1 = \sqrt{3}, \quad \sigma_2 = \sqrt{35}, \quad \rho = \frac{10}{\sigma_1 \sigma_2 } = \frac{10}{\sqrt{105}}  $$ we are ready to determine (1). However, the resulting expression, which I then need to integrate as follows, $$
Pr(Y_1 \geq 2 \mid Y_2 = 3) = \int_2^\infty f_{Y_1\mid Y_2 = 3} (y_1) \, dy_1
$$ becomes quite ugly, making me unsure whether I've approached the problem in the wrong way? Thanks in advance!","['probability-theory', 'probability', 'conditional-probability', 'normal-distribution']"
2456032,Antisymmetric relation - answer key is wrong,"If I define a relation $\rho$ on $\Bbb Z$ by:  $x\rho y$ if and only if $x$ is a multiple of $y$. The solution key tells me that this is not an antisymmetric relation. But say $x$ is a multiple of $y$, then $x=yn$ for some $n\in \Bbb Z$. Then if $y$ is a multiple of $x$, we have $y=xk$ for some $k\in \Bbb Z$. Hence $x=yn=xnk\implies nk=1$ and hence $x=y$. Which makes this antisymmetric? Is the answer key wrong?","['relations', 'elementary-set-theory']"
2456041,The Mean Value Theorem without an equation,"I've done this question a few times but I can't seem to figure out what I'm doing wrong... 
In the question, there is a statement and then a graph. 
The question states: Applying the Mean Value Theorem with $a = 2$, $b = 7$, and $c = 4$. What is 
the equation of the tangent line at 4? Then the figure below the question shows part of circle with the points, $(2, 3)$, $(4, 6)$, $(7, 7)$ and a tangent line passing the point, $(4, 6)$, which, from what I understand, is point $c$. The answer is a fill in the blanks, $y =$ ______ So, first I wrote out the equation for The Mean Value Theorem: $${f'(c) = \frac{f(b) - f(a)}{b - a}}$$ Then I plugged in the values: $${f'(4) = \frac{f(7) - f(2)}{7 - 2}}$$ Using the points on the graph, I plug in the f(x) values $${f'(4) = \frac{7 - 3}{5}}$$ $${f'(4) = \frac{4}{5}}$$ $\frac{4}{5}$, however, is not the answer because I am not looking for $y'$, I'm looking for $y$. What do I do next? How do I find y?","['derivatives', 'calculus']"
2456054,Prove $\det(P+Q+R)=\det(P+Q)+\det(Q+R)+\det(R+P)-\det(P)-\det(Q)-\det(R)$,"If $P,Q,R$ be three $2\times2$ matrices, then prove that 
$$\det(P+Q+R)=\det(P+Q)+\det(Q+R)+\det(R+P)-\det(P)-\det(Q)-\det(R).$$ My Attempt : I have no idea from where to start","['matrices', 'determinant']"
2456085,Why quotient ring $R/R$ is zero ring $\{ 0\}$?,"There is already similar question. Factor rings $R/R$ and $R/0$ Of course, I read it. However I still don't know, how and why the quotient ring $R/R$ is zero ring. So, I ask your help to check my thinking logic. In my opinion, it seems to be $R/R=R$. The definition of the quotient ring is $R/P=\{r+P|r \in R\}$. So, $R/R=\{r+R|r \in R\}$. Does $r+R$ make all of element of $R$? And if $R$ is a commutative ring with identity, is that something different result? I think I have a big problem with that logic, but I'm blind to find it. 
I hope your brighter sight. Thank you in advance.","['abstract-algebra', 'ring-theory']"
2456133,Solve the differential equation $y'=\frac{1+y}{1+x}$,$$\text{Solve the differential equation } y'=\frac{1+y}{1+x}$$ I'm going to write an exam soon and I'm worried about my solution for this task. So far I solved these problems by forming them into their standard form $y'+P(x)y = Q(x)$. But it seems like this won't work here. So I tried it like that: $$\frac{dy}{dx} = \frac{1+y}{1+x}$$ $$\Leftrightarrow dy = \left (\frac{1+y}{1+x} \right )dx$$ $$\Leftrightarrow \left (\frac{1}{1+y}\right) dy = \left(\frac{1}{1+x}\right) dx$$ $$\Leftrightarrow (1+y)^{-1} dy = (1+x)^{-1} dx$$ $$\Leftrightarrow \int{(1+y)^{-1} dy} = \int{(1+x)^{-1} dx}$$ $$\Leftrightarrow \ln(1+y)=\ln(1+x)+c$$ $$\Leftrightarrow e^{\ln(1+y)}= e^{\ln(1+x)}+e^{c}$$ $$\Leftrightarrow 1+y = 1+x+e^{c}$$ $$\Leftrightarrow y = x+e^{c}$$ I have no idea if this is correct though? :p And is there a better way of solving it?,"['ordinary-differential-equations', 'calculus', 'analysis']"
2456217,help with absolute value question $||x-3|-2|\leq 1$,"could anyone help in validating this absolute value question that my son is working on?
$|(|x-3|-2)|\leq 1$ $-1\leq|x-3|-2\leq 1$ $1\leq|x-3|\leq 3$ $1\leq x-3\leq 3$ $4\leq x\leq 6$ or $-3\leq x-3\leq -1$ $0\leq x\leq 2$ thus $x\in [4,6]\cup [0,2]$","['algebra-precalculus', 'inequality', 'absolute-value', 'proof-verification']"
2456255,Binomial theorem relating proof,There is this identity $$1 -\frac{1}{2}\binom{n}{1}+\frac{1}{3} \binom{n}{2}- \frac{1}{4}\binom{n}{3}+....+(-1)^n \frac{1}{n+1}\binom{n}{n}$$ And we are supposed to prove it using these two identities $$k\binom{n}{k} = n\binom{n-1}{k-1}$$ and $$\binom{n}{0} + \binom{n}{1} + \binom{n}{2} +....+ \binom{n}{n} = 2^n$$ I have been working on this problem for a long time.  Can you guys help me?,"['combinatorics', 'discrete-mathematics']"
2456275,Two invertible matrices,"Let $A,B$ be two $n\times n$ invertible matrices with complex entries. Also, let $\alpha, \beta \in \mathbb{C}$ with $|\alpha| \neq |\beta|$ such that $\alpha AB+\beta BA=I_n$. Prove that $\det(AB-BA)=0$. I tried to manipulate the given equation in order two get $(AB-BA)$ as a factor somewhere, but didn't manage to get anything useful. I also thought of using $A^{-1}$ and $B^{-1}$ somewhere, but I only got messier relations.","['matrices', 'matrix-equations', 'linear-algebra', 'determinant']"
2456303,Significance of Riemann Roch theorem,"In Ravi Vakil's book, the Riemann-Roch theorem for an invertible sheave $\mathscr L$ on regular projective curve $C$ is stated as $$ h^0(C, \mathscr L) - h^1(C, \mathscr L) = deg(\mathscr L) - g +1 $$ where $g$ is the genus of the curve. To me, Riemann-Roch theorem gives an upper bound on $h^0(C, \mathscr L)$ given the genus of $C$ and degree of $\mathscr L$. Is there any other reason why this theorem is considered so important? What really makes this theorem so significant?",['algebraic-geometry']
2456334,Lasker-Noether theorem implies structure theorem for f.g. modules over PID's,"According to Wikipedia the Lasker-Noether theorem, i.e. that f.g. modules over a Noetherian ring have a primary decomposition, is a generalization of the structure theorem for f.g. modules over PID's. I have no idea how to see that. For starters Lasker-Noether refers to submodules of a given module not to the module ""as an object"" and the decomposition into a direct sum suggests we should be dealing with suprema (sums), not infima, in Lasker-Noether. Perhaps this is easy, but I don't even know where to start.","['abstract-algebra', 'ring-theory', 'modules', 'commutative-algebra']"
2456355,Continuous function and function relationship,"I have a function relationship and I know that this function is continuous in a specific $x_0$. I know how to prove that this function is continuous at $D_f$. I have the function relationship:
$$f(x+y)=f(x)\cdot f(y)-\sin(x)\cdot \sin(y), \forall x,y\in\mathbb{R}$$ This function is continuous in $x_0=0$ and I want to prove that $f$ is continuous at $\mathbb{R}$. But for $x=y=0$ I get two different values for $f(0)$. So how to prove what I want?","['algebra-precalculus', 'continuity', 'functions', 'functional-equations']"
2456372,Formulate a Linear Program of minimizing maximum distance from a set of points to a line and formulate its dual,"Say we define the distance from a point to a line in the plane as the length of the vertical distance ""you would have to walk"" from the point till you hit the line. Then find a line $L:y=ax+b$ , where $a,b\in \mathbb{R}$ in the plane that minimize the maximum distance from the points $(1,1),(2,2),(2,4),(3,2)$ to $L$. How would you formulate this problem as a linear problem and write down its dual LP?","['linear-algebra', 'linear-programming', 'duality-theorems']"
2456373,Optimal route consisting of rowing then walking,"Problem You're in a boat on point A in the water, and you need to get to point B on land. Your rowing speed is 3km/h, and your walking speed 5km/h. See figure: Find the route that takes the least amount of time. My idea I started by marking an arbitrary route: From here, I figure the total time is going to be $$T = \frac{R}{3\mathrm{km/h}} + \frac{W}{5\mathrm{km/h}}$$ Since this is a function of two variables, I'm stuck. A general idea is to express $W$ in terms of $R$ to make it single-variable, and then apply the usual optimization tactics (with derivatives), but I'm having a hard time finding such an expression. Any help appreciated! EDIT - Alternative solution? Since the distance from A to the right angle (RA) is traveled 3/5 times as fast as the distance between RA and B, could I just scale the former up? That way, I get A-RA being a distance of $6\cdot\frac53 = 10\mathrm{km}$, which makes the hypotenuse $\sqrt{181}$ the shortest distance between A and B. And since we scaled it up, we can consider it traversable with walking speed rather than rowing speed! Thoughts?","['derivatives', 'trigonometry', 'optimization']"
2456416,What is a countably generated $\sigma$-algebra? Can't find a definition online [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question What is a countably generated $\sigma$-algebra? Is Borel $\sigma$-algebra countably generated?","['general-topology', 'probability', 'measure-theory']"
2456475,Show that the fibre $\pi^{-1}(p)$ is a regular submanifold,"Exercise 6.4 of the book Manifolds and Differential Geometry (Jeffrey M. Lee, 2009) states the following: Show that if $(E,M,\pi, F)$ is a (smooth) fiber bundle, then $\pi: E \rightarrow M$ is a submersion and each fiber $\pi^{-1}(p)$ is a regular submanifold
which is diffeomorphic to $F$ . Show that if both $F$ and $M$ are connected,
then E is connected. I think I can proof the first statement: Because $(E,M,\pi,F)$ is a fibre bundle, for each $p\in M$ there exists a neighborhood $U$ which contains $p$ and a diffeomorphism $\Psi:\pi^{-1}(U) \rightarrow U\times F$ such that $\pi|_U=\Psi\circ \mbox{proj}_U$ (composition is by the right). Hence $d\pi|_U = d\Psi\circ d\,\mbox{proj}_U$ ; since $\Psi$ is a diffeomorphism, $d\Psi$ is bijective. Clearly $d\,\mbox{proj}_U$ has constant rank equal to $\mbox{dim }(M)$ and thus it follows that $\pi$ is a submersion. In order to see that $\pi^{-1}(p)$ for $p\in M$ is a regular submanifold of $E$ of dimension $k$ , I have to find a chart $(A,\tau)$ of the smooth manifold $E$ such that $$ \tau\big(A\cap\pi^{-1}(p)\big) = \tau(A)\cap)\big(\mathbb{R}^k \times\{c\}\big), $$ where $c$ is an element of $\mathbb{R}^{d-k}$ (typically $c=0$ ) and $d=\mbox{dim }(E)$ . So, my questions are: 1- Is right my proof? 2.- How I can see the fibre over $p$ is a regular submanifold? How proof that is diffeomorphic to $F$ ? 3.- If $M$ and $F$ are connected, then $U\times F$ is connected for all open set $U\subset M$ and thus the open set $\pi^{-1}(U)$ is connected in $E$ thanks to the diffeomorphism $\Psi$ . So it is clear that $E$ is locally connected. However, the connectedness of $E$ has not proof yet. How is the proof?","['fiber-bundles', 'smooth-manifolds', 'differential-geometry', 'differential-topology']"
2456486,Negative Binomial with $4$ white faces before $3$ black faces,"Suppose that a fair $6$-sided die having $2$ black faces and $4$ white faces will be rolled repeatedly. What is the probability that $4$ rolls resulting in a white face occur before $3$ rolls resulting in a black face? Attemped Solution: I'm trying to make use of the following negative binomial formula: $n$ trials, given $k$ success: ${n-1}\choose{k-1}$$p^k$$(1-p)^{n-k}$ In our case, $n$ can be $4,5$, or $6$ and $k$ is fixed at $4$. $3\choose{3}$$(\frac{2}{3})$$^4$(${1}\over{3}$)$^0$+$4\choose3$(${2}\over{3}$)$^4$(${1}\over{3}$)+$5\choose3$(${2}\over{3}$)$^4$(${1}\over{3}$)$^2$ = $.680$ Is this a valid solution? I would also be interested in alternative solutions.","['combinatorics', 'probability', 'negative-binomial']"
2456516,Using partial fractions in ODE,"I am trying to solve the following ODE via different methods as in this question : $$
\begin{align}
\frac{dr}{dt} &= ar(1-r) + b (1-r)^2
\end{align}
$$ The correct solution is given by: $$
r(t) = \frac{e^{at} -1}{ e^{at} - 1 + (a/b)}
$$ In this part I try to use partial fractions. I have never used this method before and am quite unsure of how to proceed. My first step is to separate the equation. Here is my attempt: $$
\int \frac{1}{ar(1-r) + b(1-r)^2} = \int dt 
$$ $$
= \int \bigg\{ \frac{1}{ar} + \frac{1}{a(1-r)}\bigg\}dr + 2\int \frac{1}{b(1-r)} dr
$$ Then, $$
t = \frac 1 a \ln ( r(r-1)) - \frac 2b \ln (r-1) +c 
$$ Taking the exponential: $$
e^{at} = r(r -1) + (r-1)^{-2a/b}
$$ I am not sure if this is correct, or how to proceed? Any help is much appreciated!","['ordinary-differential-equations', 'proof-verification']"
2456532,Inequality proof by Cauchy-Schwarz inequality,"I've been wrestling with the following inequality for 3 days to prove it by CSI, but I can't choose the right column vectors $u$ and $v$ of CSI. $$
\frac{a^2_1}{b_1}+\frac{a^2_2}{b_2}+\cdots+\frac{a^2_n}{b_n}\ge\frac{\left(a_1+\cdots+a_n\right)^2}{b_1+\cdots+b_n}
$$ How on earth should I fix these vectors?","['inequality', 'linear-algebra']"
2456536,Galois action and Weil restriction,"Let $k'/k$ be a finite Galois extension, and $X$ an affine $k'$-scheme. Consider its Weil restriction $\mathrm{Res}_{k'/k} X$, an affine $k$-scheme. It is well-known (for instance Weil, Adeles and algebraic groups I.3) that \begin{equation} ( \mathrm{Res}_{k'/k} X ) \times_k k' \cong \prod_{\sigma \in \mathrm{Gal} (k'/k)} X^{\sigma} \end{equation}
where $X^{\sigma}$ is the base change of $X$ along the $k$-map $\sigma: k' \longrightarrow k'$. This question Two definitions of the Weil restriction. as well as the source they mention (Weil) explains more or less how the map is defined: it is the product of the maps $p^{\sigma}$ where $p: ( \mathrm{Res}_{k'/k} X ) \times_k k' \longrightarrow X$ corresponds (I am guessing) to the identity map on $\mathrm{Res}_{k'/k} X$ under the adjunction \begin{equation} \mathrm{Hom} \left( ( \mathrm{Res}_{k'/k} X ) \times_k k', X \right) \cong \mathrm{Hom} \left( \mathrm{Res}_{k'/k} X , \mathrm{Res}_{k'/k} X \right) \end{equation}
and $p^{\sigma}$ is obtained by $p$ via base change along $\sigma: k' \longrightarrow k'$ as before. I would like to understand how $\mathrm{Gal} (k'/k)$-action on the right hand side works - on the left hand side it is simply the Galois action on the $k'$-factor. I would guess that on the right hand side the action of $\gamma$ is simply given by `permuting' the factors, via $X^{\sigma} \stackrel{\gamma}{\longrightarrow} X^{\sigma \gamma}$ - is that the case? Of course, I tried to make the Galois action go through the isomorphism mentioned above, but I am a bit confused about whether $p^{\sigma}$ is defined as ""$p$, followed by base change by $\sigma^{-1}$"" or if one really wants to base change under $\sigma$ the map $p: \mathrm{Res}_{k'/k} X \times_k k' \longrightarrow X$, and then there is some canonical isomorphism between the domain and its $\sigma$-base change. I am aware that the Galois action can be used to define the descent datum on the right hand side and ultimately prove the existence of the Weil restriction, but I am not sure how this could help me.","['number-theory', 'affine-schemes', 'algebraic-geometry']"
2456724,Why aren't complex compact Lie groups trivial?,"What's wrong with my understanding of Liouville's theorem? A complex lie group is one where group multiplication and inversion are holomorphic. Supposing $G$ is compact and complex, so is $G \times G$. Then multiplication could be viewed as a holomorphic function on a compact set, so it must be constant valued in $G$ by Liouville's. Then since, in particular, the identity times itself is the identity, so is any element times any other element. But this only makes sense if $G=\{e\}$. I've seen that there is no hesitation in saying that the adjoint representation $\textrm{Ad}: G\to \textrm{Aut}(\mathfrak{g})$ is holomorphic on a compact set and so constant by Liouville in the same context. I assume that the difference must be in that the functions ""multiplication"" and ""inversion"" take values in $G$ instead of some other space, but I don't understand what we lose.","['complex-analysis', 'lie-groups']"
2456728,$f\in L^1(\mathbb{R})$ there exists step functions $\{ g_n\}$ such that $\lim_{n\to \infty}\int_{-\infty}^{\infty}|f(x)-g_n(x)|dx=0$,"Question: If $f\in L^1(\mathbb{R})$ then prove that there exists step functions $\{ g_n\}$ such that $$\displaystyle\lim_{n\to \infty}\int_{-\infty}^{\infty}|f(x)-g_n(x)|dx=0$$ I defined $g_n(x)=\displaystyle\sum_{i=1}^{2n^2}f\Big(-n+\frac{i-1}{2n}\Big) \chi_{[-n+\frac{i-1}{2n},-n+\frac{i}{2n}]}$ which I believe works but I cannot find a way to prove this. Any help is appreicated. Thank you!","['real-analysis', 'measure-theory']"
2456758,Will a Roomba always vacuum the whole room?,"This question, as indicated in the title, is motivated by the Roomba vacuum, but I am going to formulate it in slightly more mathematical terms: Suppose that I am given a union $U$ of finitely many almost disjoint squares of area $A\in \mathbb{N}$. Moreover, a point $p$ were chosen from $U$ randomly (evenly distributed). Finally, assume that I know if any point $q$ is within distance $\frac{\sqrt{A}}{2}$ of the boundary of $U$. Can I come up with an algorithm to find a path that is piece-wise linear and will pass through each square once? My initial thoughts are to think about this like a graph theoretic problem. You can construct a graph out of $U$ by treating it like a graph (corners as nodes) and taking the dual graph, which we will call $U^*$. This graph tells you about the connectedness of the squares. Then you start on a random node $v_1$ of $U^*$ and the probability of moving to an adjacent node $v_2$ is as follows $$ P(v_2|v_1) = \begin{cases} 1/n \quad d(v_1,v_2) > \frac{\sqrt{A}}{2}\\ 0 \quad\quad d(v_1,v_2) \le \frac{\sqrt{A}}{2} \end{cases}$$ where $n$ is the number of adjacent nodes with $d(v_1,v_2) > \frac{\sqrt{A}}{2}$. Then you do the same thing for all the following nodes. The thing you would try to prove is that $\forall 1 \geq \epsilon > 0$, there is a $k \in \mathbb{N}$ such that, after $k$ steps, the probability that you have been to every node is $1 - \epsilon$. But I have no idea how to prove that sort of thing. Any thoughts on how to better approach this problem? (Or on how Roombas actually work?)","['random-walk', 'algorithms', 'probability']"
2456806,Minimum and maximum value related to the sides of the quadrilateral.,"If $a$, $b$, $c$ and $d$ are the sides of the quadrilateral then find the minimum value of 
  $$\frac{a^2+b^2+c^2}{d^2}.$$ I have tied by the inequality $a+b+c>d$, but it doesn't work.","['quadrilateral', 'cauchy-schwarz-inequality', 'geometric-inequalities', 'maxima-minima', 'geometry']"
2456816,Why does Fubini's theorem not hold here?,I have shown that $$\int_0^1\int_0^1 \frac{x^2-y^2}{(x^2+y^2)^2}dx  dy=\frac{\pi}{4}$$ and that $$\int_0^1\int_0^1 \frac{x^2-y^2}{(x^2+y^2)^2}dy   dx =-\frac{\pi}{4}$$ Shouldn't these two Integrals be equal according to fubini's theorem? Why do we get two different results?,"['multivariable-calculus', 'definite-integrals', 'calculus']"
2456824,"Localized center modes with exponential decay tails, solved from non-linear differential equations","Two coupled non-linear differential equations in a radial $r$-direction in the region $r \in [0, \infty)$: $$-a\big(\partial_r^2+\frac{\partial_r}{r}\big) U(r)+ 
B(r) \partial_r V(r)=0,
$$
  $$
-B(r) \partial_r 
U(r)
+
a\big(\partial_r^2+\frac{\partial_r}{r}\big) V(r)
=0,
$$
  We like to solve $U(r)$ and $V(r)$. The B(r) is given such that $B(r)$ is a nice smooth differentiable function, with
$$B(0)=0$$
$$\lim_{r \to 0} B(r)=0$$
$$\lim_{r \to \infty} B(r)=b=constant >0,$$
and $B(r)>0$ is monotonically increasing along $r \in [0, \infty)$,
also
$$a=constant >0.$$ Both $a$ and $b$ are finite values. I have done some analysis myself. My expected analysis find that
$U(r)$ and $V(r)$ have exponential decay tails that look like 
$$\exp[-\int_0^r B(r')^{\#} dr']$$
The ${\#}$ means some tentative power. And both $U(r)$ and $V(r)$ likely contain Bessel functions $J_0(r),J_1(r), ...,etc$. What are the exact solutions of $U(r)$ and $V(r)$? I suppose that they have localized center modes at $r=0$ (namely, $U(0)$ and $V(0)$ are maximum and positive) with exponential decay tails $\lim_{r \to 0} U(r)=\lim_{r \to 0} V(r)=0.$ If exact analytic solutions are NOT possible, please give arguments, and please feel free to take approximations. Personally I believe that it can be solved analytically exactly by some Bessel type functions. (p.s. This is not a homework problem. Just do some trial analysis done by myself.)","['boundary-value-problem', 'real-analysis', 'ordinary-differential-equations', 'partial-differential-equations']"
2456831,Find value of $\frac{\sum_{k=1}^{399} \sqrt{20+\sqrt{k}}}{\sum_{k=1}^{399} \sqrt{20-\sqrt{k}}}$,Find value of $$S=\frac{\sum_{k=1}^{399} \sqrt{20+\sqrt{k}}}{\sum_{k=1}^{399} \sqrt{20-\sqrt{k}}}$$ I started with $$S+\frac{1}{S}=\frac{\sum_{k=1}^{399} \sqrt{20+\sqrt{k}}}{\sum_{k=1}^{399} \sqrt{20-\sqrt{k}}}+\frac{\sum_{k=1}^{399} \sqrt{20-\sqrt{k}}}{\sum_{k=1}^{399} \sqrt{20+\sqrt{k}}}$$ $\implies$ $$S+\frac{1}{S}=\frac{\sum_{i=1}^{399}(20+\sqrt{i})+2S_1+\sum_{i=1}^{399}(20-\sqrt{i})+2S_2}{\left(\sum_{k=1}^{399}\sqrt{20+\sqrt{k}}\right) \times \left(\sum_{k=1}^{399}\sqrt{20-\sqrt{k}}\right)}$$ $\implies$ $$S+\frac{1}{S}=\frac{15960+2S_1+2S_2}{\left(\sum_{k=1}^{399}\sqrt{20+\sqrt{k}}\right) \times \left(\sum_{k=1}^{399}\sqrt{20-\sqrt{k}}\right)}$$ where $$S_1=\sum_{i \ne j=1}^{399}\left(\sqrt{20+\sqrt{i}}\right)\left(\sqrt{20+\sqrt{j}}\right)$$ and like wise $$S_2=\sum_{i \ne j=1}^{399}\left(\sqrt{20-\sqrt{i}}\right)\left(\sqrt{20-\sqrt{j}}\right)$$ Any way to proceed from here?,"['algebra-precalculus', 'summation', 'sequences-and-series', 'irrational-numbers']"
2456924,Proving that $\int_0^\infty\sin(x)dx=1$,"Logically and by method 1 the limit should be undefined, but with some juggling it comes out to be $1$. Method 1. $\displaystyle \lim_{k\to\infty} \int_0^k \sin(x) \, dx = -\lim_{k\to\infty} (\cos(k)-1) = \text{not defined}$. Method 2. Let $I = \int e^{-tx}\sin(x) \, dx$ and $J=\int e^{-tx}\cos(x) \, dx$. Using integration by parts, \begin{align*}
I &= -e^{-tx}\cos x - tJ, \tag{i} \\
J &= e^{-tx}\sin x + tI \tag{ii}
\end{align*} from $\text{(i)}$ and $\text{(ii)}$, $$ I = -e^{-tx} \left[ \frac{\cos x + t\sin x}{1+t^2} \right], \qquad
J = e^{tx}\left[ \frac{\sin x-t\cos x}{1+t^2} \right]. $$ Thus $\int_0^\infty e^{-tx}\sin(x) \, dx = \frac{1}{1+t^2}$. Taking limit $t \to 0$ $$ \lim_{t\to 0}\int_{0}^{\infty} e^{-tx}\sin(x) \, dx
= \int_{0}^{\infty} \sin(x) \, dx
= 1. $$ Is the integral $1$ or undefined?","['limits', 'fake-proofs', 'calculus', 'integration', 'definite-integrals']"
2456925,Question regarding the proof of $\sum_{k=0}^{n} (-1)^k \binom{n}{k}^{2}$,"Let $n$ be a positive integer.  Prove that $$\sum_{k=0}^{n} (-1)^k \binom{n}{k}^{2} = \begin{cases}
0   & \text{if $n$ is odd} \\
(-1)^m \binom{2m}{m}, & \text{if $n$ = 2m}
\end{cases}$$ So I wrote out a first few terms to get a feel of the problem $\binom{n}{k} = \frac{n!}{k!(n-k)!}$ When n is odd (eg n =3): $$\binom{3}{0}^2 -\binom{3}{1}^2 +\binom{3}{2}^2 -\binom{3}{3}^2 = 0$$ When n is even (eg n = 4): $$\binom{4}{0}^2 - \binom{4}{1}^2 + \binom{4}{2}^2 - \binom{4}{3}^2 + \binom{4}{4}^2 = \binom{4}{2}^2 = \binom{2(2)}{2}^2 (-1)^2$$ So there is a hint that the textbook gave me, it is For $n = 2m$, consider the coefficient of $x^n$ in $(1-x^2)^n = (1 +
 x)^n(1-x)^n$ So I tried writing out what $(1+x)^n$ and $(1-x)^n$ are $$(1+x)^n = \sum_{k=0}^{n} \binom {n}{k} x^k$$ $$(1-x)^n = \sum_{k=0}^{n} \binom {n}{k} (-1)^k x^k$$ And this is where I've been lost for the last few hours....","['combinatorics', 'discrete-mathematics']"
2456960,Discrete Metric Space is Not Separable,"Why is it that for the metric space $(X,d)$ where $X=\Bbb R$ and $d$ is the discrete metric, then $(X,d)$ is not separable? Does this have something to do with $\Bbb R$ being uncountable? Can someone prove why this is true?","['examples-counterexamples', 'general-topology', 'metric-spaces']"
2456976,Find all points on which a function is discontinuous.,"$ f(x,y) = \begin{cases} \dfrac{x^3+y^3}{x^2+y^2} &\quad\text{if} [x,y] \neq [0,0]\\[2ex]  0 &\quad\text{if}[x,y] = [0,0]\\ \end{cases} $ The only point it could be discontinuous in is [0,0] . How do I find the limit of the function for $(x,y) \rightarrow (0,0)$? $ \lim_{(x,y) \rightarrow (0,0)} \frac{x^3+y^3}{x^2+y^2} $ seems pretty hard to analyse.","['multivariable-calculus', 'continuity']"
2456999,Do all members of this sequence have $8$ divisors?,"Define the set $A$ as a subset of $\mathbb{N}$ as follows: Take all of the divisor pairs of a natural number $n$ (except $n$ and $1$), divide the larger of each pair by the smaller, and then take the resultant product. If this number $=n,$ it is a member of the set. For example, the divisor pairs of $24$ (excluding $1$ and itself) are $(2,12),(3,8),(4,6).$ Divide the larger by the smaller: $6,8/3,3/2$ and multiply them together $=24.$ Hence $24$ is a member of the set. The sequence starts: $1, 24, 30, 40, 56, 64, 70, 105, 135, 154\dots$ With the exception of $1$ and $p^6$ (where $p$ is prime), all members of $A$ appear to have $8$ divisors. That is, $\sigma_0(n)=8,$ for all $n\in A.$ Is this true? There are other ways to formulate the sequence, eg: the product of the largest of each divisor pair excluding $n$ ifself $=n^2.$ (If $n$ is a square, include $\sqrt{n}$.) eg for $n=24,$ take the larger of each divisor pair: $6,8,12.$ Their product $=24^2.$ I have seached oeis, but the sequence doen't feature.","['number-theory', 'elementary-number-theory']"
2457052,How to identify $\bigwedge^2 TM$ with $\mathfrak{so}(n)$?,"Let $(M,g)$ be a Riemannian manifold and $TM$ its tangent bundle. Does anyone know how to  identify  $\bigwedge^2 TM$ with $\mathfrak{so}(n)$?","['riemannian-geometry', 'differential-geometry', 'lie-algebras', 'lie-groups']"
2457087,How to prove that $x^y - y^x = x + y$ has only one solution in positive integers?,"Prompted by this question , I tried to show that $(2,5)$ is the only solution in positive integers of $x^y - y^x = x+y$ (which would show, a fortiori , that it's the only solution in primes). It's convenient to rewrite the equation as $f(x,y) = x^y - y^x - x - y = 0$. With the aid of some trial calculations, I reasoned informally as follows: If $x=1$ then $f(x,y) = -2y=0$, implying $y=0$. If $x=2$ and $y \leq 5$, then a case-by-case check shows that only $(2,5)$ is a solution. If $(x,y) = (2,6)$ then $f(x,y) = 20$, and as $y$ increases above $6$, $f(x,y)$ increases. If $x \geq 3$ and $y \leq x$ then $f(x,y) < 0$. If $x \geq 3$ and $y=x+1$, then $f(x,y)>0$, and as $y$ increases above $x+1$, $f(x,y)$ increases. How can the above be made into a rigorous proof?  I've included calculus as a tag since it could be useful in showing under what conditions $f(x,y)$ is an increasing function of $y$ (viewing it as a real variable).","['diophantine-equations', 'calculus', 'elementary-number-theory']"
2457103,Lusin’s Theorem and the connection between measurable and continuous functions,"I know questions similar to this have been asked on here, but I have yet to find an answer to my question. I’m trying to prove Lusin’s Theorem: Let $f$ be a measurable real-valued function on $[a,b]$. Given $\delta>0$, there exists a continuous function $\theta$ on$[a,b]$ such that $\mu(\{x;f(x)\neq\theta(x)\})<\delta$. And in the notes that I’m reading through, the first line of the proof goes: Let $f(x)$ be measurable on $[a,b]$ and let $\delta>0$. For each $n$, there exists a continuous function $h_n$ on $[a,b]$ such that
  \begin{equation}\mu(\{x:|h_n(x)-f(x)|\geq\delta/2^{n+2}\}<\delta/2^{n+2}.\end{equation} How is this true? I am not seeing how we are able to make any assumptions about continuous functions just given that we have a measurable function.","['real-analysis', 'measure-theory']"
2457160,"Question: Properties of differential equation (linear, homogeneous, order, constant coefficients..)","Hi maths people I have question for test I write next week.
There are differential equations and you say what property they have.
But my issue is I maybe don't understand all property right. For order I count maximum number of derivative line. By this I mean for example $y''' + y''$ maximum line is $3$ so this is 3th order. Linear you check if exponent of $y$ or $y$ with lines is equal to $1$. Example $(y'')^4$ not linear, $y^2$ not linear, but $y+y''$ is linear. Homogeneous you check if equation is equal with zero and check if function have.. I call it disturbing function. If it have disturbing function you have no homogenetic. I don't can explain good sorry but here is example: $y'''+2y'' = 0$ this is homo because equal to zero and no disturbing function. $y'''-6xy' = 2-3e^x$ this is no homo because there is disturbung function $2$ But I have question, what if this is $y'''-6xy' = 3e^x$ (so without $2$) instead? I think is homogeneous because $x$ and $y$ belong to equation so there is no disturbing function. Is this right? But what is constant coefficient ? I think coefficient is the thing factorized by the variables. When it is number, it is constant coefficient. 
But I don't know.. can you please give example? Here is summary I make examples (can you say if this is right?): $y''' +2y'' -5y'+3y+2=0$, 3th order, linear, constant coefficients, no homo $2xy+x^2y'=0$, 1st order, linear, no constant coefficients because muliply by $x$, homo Can you please say if all is good? My friend also not sure we learn
  together and this is only thing we must understanded then ready for
  test in school! Thank you very much for read all my question!!","['functions', 'ordinary-differential-equations', 'calculus', 'analysis']"
2457192,Eigenvectors for a sum of diagonal and anti-diagonal matrices,"Consider the case of invertible matrix which is the sum of diagonal and anti-diagonal matrices, e.g., $$\begin{bmatrix} \color{red}1 &   0 &  0 &  0 &  \color{red}6 \\ 0 &  \color{red}2 &  0 &  \color{red}7 &  0 \\ 0  & 0 & \color{red}3 &  0 &  0 \\ 0 &  \color{red}8  & 0 & \color{red}4 &  0 \\ \color{red}9 &  0  & 0 & 0 &  \color{red}5\end{bmatrix}$$ Such matrices I name shortly $X$ -matrices (even shorter $X$ - do they have more official name?) and it's easy to check that the sum of two $X$ -matrices is an $X$ -matrix. Also the product of two matrices is   an $X$ -matrix as $$X_1X_2=(D_1+A_1)   (D_2+A_2)=(D_1D_2+A_1A_2)+(D_1A_2+A_1D_2)$$ ( $D,A$ denoted here as diagonal and antidiagonal part of $X$ ) and product of two diagonal or two anti-diagonal is always diagonal and product of diagonal and anti-diagonal is anti-diagonal. Further if $X$ -matrix is invertible also its inverse is an $X$ -matrix because inverse can be presented as a polynomial of $X$ from Cayley-Hamilton theorem. Making calculations I have found one more property of these matrices: i.e. also eigenvectors $v_1, v_2, \dots $ for this type of matrix can be grouped  to make $X$ -matrix. For instance for the matrix listed above we have eigenvectors as colummns of $$V=\begin{bmatrix}
 \color{red}{-0.730}  &  \color{red}{0.529}   &  0.000  &   0.000   &  0.000 \\
  0.000  &  0.000   &  \color{red}{0.730}  &  \color{red}{-0.633}  &   0.000  \\
  0.000 &   0.000   & 0.000  &   0.000  &  \color{red}{1.000}  \\
  0.000  &   0.000  & \color{red}{-0.683}  &  \color{red}{-0.774}  &  0.000  \\
  \color{red}{0.683} &   \color{red}{0.848}   &  0.000  &   0.000  &   0.000  \\
\end{bmatrix}$$ and it's possible to permute columns in order to obtain  from them an $X$ -matrix. How this last property can be proved? How  can we prove that there is a permutation of eigenvectors of $X$ -matrix which is also an $X$ -matrix? Could we use for proof the equation $X=VDV^{-1}$ where however $V$ , if columns are chosen randomly, can be in the form which is not an $X$ -matrix? (but its some permutation supposedly is ...)","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra', 'permutations']"
2457275,"Jacobi field J along geodesic, satisfying additional condition $[J, \frac{\partial}{\partial r}] = 0.$","Following came up reading different articles and books: Let $p$ be a point on a Riemannian manifold. For $x \in M \backslash Cut(p)$ let $\gamma$ be the minimal geodesic joining $p$ and $x$ parametrized by the distance, such that $\gamma(0) = p$, $\gamma(r) = x$. Now let $X$ be a vector in $T_x M$ such that $\langle X, \frac{\partial}{\partial r} \rangle$ (x) = 0. 
Since $x$ is not a conjugate point of $p$, we can extend $X$ to a Jacobi field $\tilde{X}$ along $\gamma$ satisfying $\tilde{X}(\gamma(0)) = 0, \tilde{X}(\gamma(r)) = X$ and $[\tilde{X}, \frac{\partial}{\partial r}] = 0.$ My problem is the last part: Why does such a Jacobi field exist, that it commutes with $\frac{\partial}{\partial r}$? More particular: Don't the first two conditions already determine $\tilde{X}$ uniquely? If yes, how to see that the commutator vanishes? If not, how can one defind such a Jacobi field? Any help is much appreciated. Thanks!","['vector-fields', 'differential-geometry', 'geodesic']"
2457285,Are the linear combinations of iid random variables independent?,"Suppose $X_1, X_2, ... , X_n$ are independently and identically distributed random variables. Let $\bar{X} = \frac{1}{n} \sum_{i=1} ^{n} X_i$. Are $\bar{X} $ and $X_1 - \bar{X}$ independent? I realize that this is true if $X_1, X_2, ... , X_n$ are i.i.d. normal. However, does it work for the general case? I have tried to prove (or disprove) this using moment generating functions. But I always end up with a very messy mgf. Before I conclude that since the joint mgf of $\bar{X} $ and $X_1 - \bar{X}$ cannot be expressed as the product of both mgf, therefore they are both independent, I am worried that I may be missing something. Can someone please help me out?","['independence', 'probability-theory', 'probability-distributions', 'moment-generating-functions', 'random-variables']"
2457301,Numbers in form $\prod\frac{p}{p-1}$,"Let $n>1$ be an integer number. Then we could prove that there exists positive integer $m_1,\ldots,m_k>1$ such that $n=\prod_{j=1}^k \frac{m_j}{m_j-1}$. My proof is based on the induction. For example let $p$ be a prime divisor of $n$. Then we write $n=\frac p{p-1} \cdot (p-1)$. Since $p-1<n$ then applying assumsion induction, we are done. My question is the following: I want to find such presentation of $n$ so that $m_1+\cdots+m_k$ attains the minimum. I compute some examples, and relize that $m_1,\ldots, m_k$ must be prime numbers. Is this true? How to prove or disprove it?","['number-theory', 'contest-math', 'elementary-number-theory']"
2457305,Solve $32x^2 -y^2 = 448$,"I am trying to find all integer solutions to the following equation:
$$32x^2 - y^2 = 448$$ This is what I have tried so far: The equation describes a hyperbola, and so I try the usual trick of intersecting the curve with a line of rational slope to find rational solutions first. Knowing the point (4,8) satisfies the equation, I solve the following system:
$$\left\{ 
\begin{array}{c}
32x^2 - y^2 = 448 \\ 
y = m(x - 4) + 8 \\
\end{array}
\right.$$ After a bunch of algebra, I get:
$$x = \frac{-4m^2+16m-128}{32-m^2}$$
$$y = \frac{8m^2-256m+256}{32-m^2}$$ Finally, substituting $m = \frac{u}{v}$, I get:
$$x = \frac{-4u^2+16uv-128v^2}{32v^2-u^2}$$
$$y = \frac{8u^2-256uv+256v^2}{32v^2-u^2}$$ Cool, with any choice of $u$ and $v$, I get a rational solution. But since cancelling the denominators does not work, I do not know how to continue to get integer solutions only. Is this perhaps not the right way to go?
Any help would be much appreciated.","['diophantine-equations', 'sums-of-squares', 'number-theory', 'pell-type-equations', 'elementary-number-theory']"
2457308,What is the relation between universal covering space and curvature of base manifolds?,"Does anyone know what is the relation between universal covering space and curvature of base manifolds? Edit: For example   If universal covering of a complete $3$-manifold $(M,g)$ 
 isometric to a Riemann product $N^2\times \Bbb R$ where $N^2$ is a complete
$2$-manifold with non-negative sectional curvature then what we can say about $(M,g)$? Thanks","['riemannian-geometry', 'differential-geometry']"
2457374,"Show that $t_n$ of $\textrm{GCD}(a,b)$ is $O(n)$","Can someone help me show that $t_n$ is $O(n)$. I have using Euclids algorithm and $t_n$ is the worst-case steps to solve $\textrm{GCD}(a,b)$ when $n \geq a \geq b > 0$.","['algorithms', 'discrete-mathematics']"
2457415,Extension of equivalent norms (Exercise 2.4 in “Linear Analysis” by Bollobás),"The following is Exercise 4 from Chapter 2 of Linear Analysis, an introductory course by Béla Bollobás. Let $X = (V, \|\cdot\|)$ be a normed space and $W$ a subspace of $V$ . Suppose $|\cdot|$ is a norm on $W$ which is equivalent to the restriction of $\|\cdot\|$ to $W$ .
Show that there is a norm $\|\cdot\|_1$ on $V$ that is equivalent to $\|\cdot\|$ and whose restriction to $W$ is precisely $|\cdot|$ . ( Original scan ) In a solution of this question, must the Hahn–Banach theorem be used used or can we prove it without using Hahn–Banach?","['functional-analysis', 'normed-spaces']"
2457468,"Function with domain all real numbers and range $(0,1)$","Is there a one-to-one function whose domain is all real numbers and range is $(0,1)$? I can't find any so I was thinking about trying to find a piece-wise function that meets the requirements, but I'm having a lot of trouble doing that too. This is a part of the problem I'm trying to solve to show that two sets have the same cardinality. Any help is appreciated!","['functions', 'discrete-mathematics']"
2457481,Limit Evaluation (Conjugate Method)–Further algebraic manipulation?,$$\lim_\limits{x\to 2} \frac{\sqrt{6-x}-2}{\sqrt{3-x}-1}$$ I have tried evaluating the above limit by multiplying either both the conjugate of numerator and the denominator with no avail in exiting the indeterminate form. i.e.   $$\frac{\sqrt{6-x}-2}{\sqrt{3-x}-1}*\frac{\sqrt{6-x}+2}{\sqrt{6-x}+2}$$ and conversely $$\frac{\sqrt{6-x}-2}{\sqrt{3-x}-1}*\frac{\sqrt{3-x}+1}{\sqrt{3-x}+1}$$ To my suspicions of which–either numerator or denominator–conjugate to multiply by I chose $$\frac{\sqrt{3-x}+1}{\sqrt{3-x}+1}$$ This resulted in $$\frac{(\sqrt{6-x}-2)(\sqrt{3-x}-1)}{3-x-1}$$ Is it indeterminate? What is the reason for multiplying by a specific conjugate in a fraction (denominator or numerator) and the reason for the conjugate being either a) denominator b) numerator c) or both? Am I simply practicing incorrect algebra by rationalizing the expression to: $$\frac{(6-x)(3-x)-2\sqrt{3}+2x+2}{x-2}$$ Or am I failing to delve further and manipulate the expression out of the indeterminate form?,"['radicals', 'limits', 'calculus', 'algebra-precalculus', 'limits-without-lhopital']"
2457491,Solve the equation $\log(n)\cdot\log(n+1) = 1$,"Problem: Solve $$\log(n)\cdot\log(n+1) = 1$$ for natural numbers less than $100$ Source: The actual problem was a multiple choice question, and it goes something like this, Find the maximum* value of $n$ such that both $(n+1)^n$ and $n^{(n+1)}$ divide $100!$ Then there were a few options that I don't remember (one was 24, and one 25 as I remember, but they were two digit natural numbers for sure) As I sat down to solve it, I applied the following approach: My attempt: Let, $$100! = K(n+1)^n$$ where $K$ is an arbitrary integer
And let, $$100! = C(n)^{(n+1)}$$ where $C$ is an arbitrary integer To get rid of the 100! and solve for n exclusively, I did
$$\frac{100!}{K} = (n+1)^n$$
Taking natural logarithm (yes, $ln$ or $log_e$ NOT $log_{10}$) on both sides
$$ \log(\frac{100!}{K}) = (n)\log(n+1) $$
Upon differentiating** w.r.t $n$ we get,
$$ 0 = \frac{n}{n+1} + \log(n+1)$$
Upon solving the second equation as above we get
$$\log(n)\cdot\log(n+1) = 1$$
Now, how do I find $n$, I know plug and chug would work but I won't have a calculator on exam. All help appreciated! maximum maybe the maximum number from the given options. I'm utterly sorry for not having the options ** is this approach trivial? Edit: Answer is $15$ and the differentiating approach is faulty","['logarithms', 'functions', 'elementary-number-theory']"
2457551,There's no immersion from $S^n$ to $\mathbb{R}^n$,"I want to show that there's no immersion from $S^n$ to $\mathbb R^n$, that is, there exists no smooth function $f:S^n\rightarrow \mathbb R^n$ such that $df|_p$ is injective $\forall p \in S^n$. By simple calculation, we know that it's equivalent to say that after writing $f = (f_1,f_2,\cdots, f_n)$, the matrix $(\frac{\partial f_i}{\partial x_j}|_p)_{i,j}$ has determinant $\neq 0\, \forall p \in S^n$ where $x_i$ are local coords of $S^n.$ But I don't know what to do next.","['differential-geometry', 'differential-topology']"
2457556,Computing $\lim_{\varepsilon\to 0^{+}}\psi(\varepsilon)/\Gamma(\varepsilon)$ with asymptotic expansions,"I have the following limit of which I want to compute:
\begin{equation}
\lim_{\varepsilon\to 0^{+}} \frac{\psi(\varepsilon)}{\Gamma(\varepsilon)}.
\end{equation} For $\varepsilon\approx 0$ and $\varepsilon\neq 0$ I have the following limiting forms
\begin{equation}
\tag{1}
\psi(\varepsilon)=-\frac{1}{\varepsilon}-\gamma+O(\varepsilon)
\end{equation}
and
\begin{equation}
\tag{2}
\frac{1}{\Gamma(\varepsilon)}=\varepsilon+O(\varepsilon^{2}).
\end{equation} If I multiply $(1)$ and $(2)$ together we get
\begin{align}
\tag{3}
\frac{\psi(\varepsilon)}{\Gamma(\varepsilon)}
&=
-1-\frac{O(\varepsilon^{2})}{\varepsilon}
-\gamma\varepsilon-\gamma O(\varepsilon^{2})
+\varepsilon O(\varepsilon)+O(\varepsilon)O(\varepsilon^{2})\\
&=
-1-O(\varepsilon)
-\gamma\varepsilon-\gamma O(\varepsilon^{2})
+O(\varepsilon^{2})+O(\varepsilon^{3}).
\end{align} In the limit, all of the terms with $\varepsilon$ approach zero such that we arrive at
\begin{equation}
\lim_{\varepsilon\to0^{+}} \frac{\psi(\varepsilon)}{\Gamma(\varepsilon)} =
-1.
\end{equation} I have checked this answer against WolframAlpha which yields the same result. Despite getting the same result, I have doubts as to if this is a sound approach to computing the limit. My question is this: Is the use of asymptotic expansions in this manner proper (i.e. is this a valid method to computing my limit)? Or does it just happen to work out in this example?","['limits', 'asymptotics', 'digamma-function', 'limits-without-lhopital', 'gamma-function']"
