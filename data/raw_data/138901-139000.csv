question_id,title,body,tags
2228394,Prove $\lvert\int_a^bf \cdot g\rvert \le (\int_a^bf^2)^{1/2} \cdot (\int_a^bg^2)^{1/2}$,I'm studying from Spivak's Calculus on Manifolds and I'm trying to prove problem 1-6 which looks like Cauchy-Schwarz applied to continuous functions. Assume $f$ and $g$ are integrable. Prove that $$\lvert\int_a^bf \cdot g\rvert \le (\int_a^bf^2)^{1/2} \cdot (\int_a^bg^2)^{1/2}$$,"['functional-analysis', 'proof-writing']"
2228398,'Trace trick' for expectations of quadratic forms,"I am trying to understand the proof for the Kullback-Leibler divergence between two multivariate normal distributions . On the way, a sort of trace trick is applied for the expectation of the quadratic form $$E[ (x-\mu)^T \Sigma^{-1} (x-\mu) ]= \operatorname{trace}(E[(x-\mu)(x-\mu)^T)] \Sigma^{-1}),$$ where $x$ is MV-normal with mean $\mu$ and covariance matrix $\Sigma$ . The expectation is taken over $x$ . I would like to understand why this identity holds. I think more than one step is taken at once. I believe, $\operatorname{trace}(E[(x-\mu)(x-\mu)^T] \Sigma^{-1})$ = $\operatorname{trace}(E[(x-\mu) \Sigma^{-1} (x-\mu)^T])$ , but where does the trace come from?","['matrices', 'trace', 'statistics', 'expected-value']"
2228415,questions about double centralizer theorem,"An important fact in the theory of central simple algebras is the double centralizer theorem, which says: if $k$ is a field, $A$ is a $k$-algebra, $V$ is a faithful semisimple $A$-algebra, then $C(C(A)) = A$, where $C(A)$ is the centralizer of $A$ in $End_k(V)$. Taking the centralizer is an inclusion-reversing operation. If we consider the algebra $M_n(k)$ of $n\times n$ matrices over a field $k$, identfying $k$ with the scalar matrices and $\Delta$ with the diagonal matrices, we get $C(k)$ = $M_n(k)$, $C(M_n(k)) = k$, and $C(\Delta) = \Delta$. (1) This suggests that the centralizer operation is something like a duality between $k$-subalgebras. Is there any truth to this? (2) Will there always be a subalgebra like $\Delta$ which is its own centralizer? I'm not exactly sure what conditions to put on $k, A$, and $V$, so I'm open to flexibility on that. (3) Does a double centralizer result hold in the context of groups? (i.e. $C_G(C_G(H)) = H$?). If not in general, for what groups does this hold?","['abstract-algebra', 'division-algebras', 'representation-theory']"
2228418,Find the sum of all primitive roots of $n$,"Let $\xi_n$ denote a primitive $n^{th}$ root of unity and let $K=\mathbb{Q}(\xi)$ be the associated cyclotomic field. Let $a$ denote the trace of $\xi_n$ from $K$ to $\mathbb{Q}$. Prove that $a=1$ if $n=1$, $a=0$ if $n$ is divisible by the square of a prime, and $a=(-1)^r$ if $n$ is the product of $r$ distinct primes. It is actually the I know that the trace of $\xi_n$ from $K$ to $\mathbb{Q}$ is the sum of all primitive roots of $n$. If $n=1$, it is very easy. I know the fact that $a$ is a primitive root of $n$, then $-a$ is a primitive of $n$ as well if $n$ is divisible by the square of a prime. How to prove that? This is the key to prove the second case. For the third case, I totally had no idea. How to prove the two cases using theorems about the cyclotomic field or cyclotomic polynomial?","['number-theory', 'abstract-algebra', 'galois-theory', 'field-theory']"
2228441,Finitely presented module + flat implies projective,"Let $M$ be a finitely presented module. Show that $M$ is flat if and only if $M$ is projective. I think I am fine with the part ""projective"" implies flatness but I need help on showing that flatness + finitely presented modules implies projective. Any help on this part will be great.","['abstract-algebra', 'ring-theory', 'modules', 'projective-module']"
2228454,"With the condition $\lim_{x\to \infty}(f(x+a)-f(x))=0$, how to construct $h(x)$?","Assume $f(x)\in C[0,+\infty)$，and for all $a\geqslant 0$, we have
\begin{align*}
\lim_{x\to \infty}(f(x+a)-f(x))=0 \tag{*}.
\end{align*}
Prove that there exists $g(x)\in C[0,+\infty)$ and $h(x)\in C^1[0,+\infty)$ such that $f(x)=g(x)+h(x)$, and such that they satisfy
\begin{align*}
\lim_{x\to \infty}g(x)=0,~~\lim_{x\to \infty}h'(x)=0.
\end{align*} My thought is let $h(x)=\frac1 a\int_x^{x+a}f(t)\,dt$, then it is easy to see $\lim_{x\to \infty}h'(x)=0$, but I can't explain that $\lim_{x\to \infty}g(x)=\lim_{x\to \infty}f(x)-h(x)=0$.  It seems we should try proving  $\lim_{x\to +\infty}f(x)$ exists by using the condition of (*), but I'm not sure whether it's true or false.","['derivatives', 'limits']"
2228457,Standard notation for expressing a certain binary operation between functions,"Given two functions whose outputs coincide at all values in the intersection of their domains, is there some commonly used notation to express the function whose graph is formed by the union of both those function's graphs? Symbolically given any two functions $f:A\to X$ and $g:B\to Y$ with $f(r)=g(r)$ for all $r\in A\cap B$ I'm looking for some standard notation to write the function $h:A\cup B\to X\cup Y$ defined by: $$h(r)=\begin{cases} f(r)& \text{if } r\in A\\ g(r)& \text{if } r\in B\end{cases}$$ So far I've just been writing $h=f\cup g$, as this notation seems pretty natural and also satisfies a lot of nice properties involving the standard usage of the union operator between sets. For example: $$f\cup g=g\cup f$$
 $$(f\cup g)\cup h=f\cup (g\cup h)$$
 $$\text{dom}(f\cup g)=\text{dom}(f)\cup \text{dom}(g)$$
 $$\text{range}(f\cup g)=\text{range}(f)\cup \text{range}(g)$$
 $$(f\cup g)[U]=f[U\cap A]\cup g[U\cap B] \text{ for any subset } U\subseteq A\cup B$$
 $$\text{ If } f \text{ and } g \text{ are bijective then so is } f\cup g \text{ further we have } (f\cup g)^{-1}=f^{-1}\cup g^{-1}$$ In particular a recent example of where this notation would have been useful, was when I was dealing with three functions $f:A\to X$ and $g:B\to Y$ and $h:C\to Z$ as well as two binary operations $*$ on $A\times B$ to $C$ and $\cdot$ on $X\times Y$ to $Z$ which satisfied: $$h(a*b)=f(a)\cdot g(b)$$ Now using the previous notation this is equivalent to the identity: $$(f\cup g\cup h)(a*b)=(f\cup g\cup h)(a)\cdot (f\cup g\cup h)(b)$$ Thus instead of writing all the aforementioned relations I could have just more concisely wrote that $f\cup g\cup h$ is a homomorphism from $(*,A\times B)$ to $(\cdot,X\times Y)$. However for the sake of communicability I'm hesitant to define the ""union"" of functions in the way that I did and so I'm curious if there is some standard notation for expressing this binary operation between arbitrary functions.","['abstract-algebra', 'functions', 'elementary-set-theory', 'binary-operations', 'graphing-functions']"
2228474,Two-variable polynomials over $\mathbb{Q}$ with finitely many roots in $\mathbb{R}^2$,"I found this interesting exercise (not homework assignment) in real algebraic geometry: Describe an algorithm which decides whether a given polynomial in $\mathbb{Q}[X, Y]$ has infinitely or finitely many roots in $\mathbb{R}^2$. There's not much I've found already. It's easy to construct a polynomial with a given number of roots, for example
$$
X^2 + \prod_{k=1}^n (Y - k)^2
$$
has exactly $n$ roots in $\mathbb{R}^2$. The idea used is that any system of polynomials in $\mathbb{Q}[X, Y]$ having finitely many solutions (in this case $\lbrace X = 0, \prod_{k=1}^n (Y - k) = 0 \rbrace$) can be converted into one polynomial in $\mathbb{Q}[X, Y]$ having exactly those solutions as roots using sums of squares. However, not all polynomials in $\mathbb{Q}[X, Y]$ can be written as a sum of squares (or minus a sum of squares), provided that they have finitely many roots. For example, it is well-known that the Motzkin polynomial $F = X^4Y^2 + X^2Y^4 - 3X^2Y^2 + 1$ cannot be written as a sum of squares in $\mathbb{R}[X, Y]$, but on the other hand the polynomial
$$
(1 + X^2)F = (1 - X^2Y^2)^2 + X^2(1 - Y^2)^2 + X^2Y^2(1 - X^2)^2
$$
has exactly the same roots in $\mathbb{R}^2$ as $F$, namely $(1, 1), (1, -1), (-1, 1)$ and $(-1, -1)$. The above equality also shows that $F$ only takes positive values. In fact, using the middle value theorem, one can easily see that if a polynomial in $\mathbb{R}[X, Y]$ can take both strictly negative and strictly positive values, it must have infinitely many zeroes in $\mathbb{R}^2$. Conversely, though, some polynomials in $\mathbb{Q}[X, Y]$ never take negative values and still have infinitely many zeroes. Any thoughts on this? Both hints and full answers are welcome.","['real-algebraic-geometry', 'roots', 'polynomials', 'algebraic-geometry']"
2228479,Proving every rectifiable path (bounded in some sense) is integrable,"Prove that every rectifiable path $f:[a,b]\to\mathbb{R}^n$ is
  integrable Where by rectifiable we mean a path that, for every partion $P = \{t_0,\cdots,t_n\} $ of its domain, we have that $$l(f,P) = |f(t_1)-f(t_0)| + |f(t_2)-f(t_1)| + \cdots + |f(t_n)-f(t_{n-1})|$$ is bounded. By integrable path we mean a path that has its coordinates as integrable functions. It's intuitive to say that since it has a ""finite graph"" then it should be integrable. However, there is no assumption about continuity of the coordinate functions, so how I should prove they are integrable?","['multivariable-calculus', 'real-analysis', 'integration', 'calculus']"
2228505,"Prove that if $(x+y)^2 \equiv 0 \pmod{xy}$, then $x = y$","Let $x,y$ be integers. Prove that if $(x+y)^2 \equiv 0 \pmod{xy}$, then $x = \pm y$. The given condition is equivalent to $x^2+y^2 \equiv 0 \pmod{xy}$. How do we continue from here to prove that $x = \pm y$?",['number-theory']
2228549,Is the following series consisting of $\pm 1$ bounded? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question does not appear to be about math within the scope defined in the help center . Closed 6 years ago . Improve this question (Link to cross-post to MathOverflow) Let $b=\frac{\sqrt{5}-1}2$ and $a_n:=(-1)^{[nb]}$ where $[\cdot]$ denotes the floor function. Are the partial sums $A_N=\sum\limits_{n=0}^N a_n$ bounded? The sequence $nb\bmod 2$ is equidistributed in $[0,2]$, so, as $n$ gets large, there will be about half of indices in $\{1,2,\cdots,n\}$ that correspond to $1$ and the other half to $-1$. This doesn't help much though because what it says is basically $A_N\in o(N)$. By testing on computer softwares, it seems that $A_N\in O(\log N)$. Also, is there anything special about $b$ besides being an irrational real number? What if one replaces it by, say, $\pi$?","['real-analysis', 'dynamical-systems', 'random-walk', 'ergodic-theory', 'sequences-and-series']"
2228555,Different solutions for PDE $u_x+u_y=1$,"I try to solve a very basic PDE problem ""$u_x+u_y=1$""
Here is my approach. I try to use change coordinates method. notice $(u_x, u_y)$ $\cdot$ (1, 1)=1
Let $x_1=x+y, y_1=x-y$, so $x = (x_1+y_2)/2, y = (x_1 - y_2)/2$
Then $""u_x = u_{x_1} + u_{y_1}, u_y= u_{x_1} - u_{y_1}$
Then we get $U_x+u_y=2u_{x_1}=1, i.e. u_{x_1}=1/2.$ 
Then general solution for such ODE is $u=(x_1)/2 + f(y_1)$
So we get solution to the ODE =(x+y)/2 + f(x-y) However, I search online found there are solutions y+ f(x - y) =1 or = x+ f(x - y) which still work. Are all of them(including mine) the correct solutions? Why there are such huge differences?","['ordinary-differential-equations', 'partial-differential-equations']"
2228556,Alternative way to find if an infinite set is countable,"I'm studying about countable and uncountable sets, and I have found that 
an infinite set is countable if and only if its possible to find a bijective relation between that set and the set of natural numbers. I got a bit confused thinking the way of the definition above, so I thought of another way to find if a set
is countable or uncountable. I'm not sure if it's correct so I would like to get some help. An infinite set S is countable if and only if: Given any ordering relation that covers all the elements of S: for each pair (e1, e2) of elements of S,
it is always possible, starting from e1, to reach e2 by counting the elements between e1 and e2 one by one
(the same if starting from e2 and going towards e1). This way I can prove that P(N) is uncountable by establishing an order relation that states all the subsets of N that are elements of P(N) and have cardinality 'c' are located in the left of all of those that have cardinality 'c+1'. So I can start from, for example, {1}, and knowing that {1,2} is in some place to the right of {1}, even if I try to reach {1,2} from {1} counting element by element to the right, I will never, so P(N) is uncountable. I thought this way because it's easier for me to undersand, but I'm not sure if I'm right.","['infinity', 'elementary-set-theory']"
2228578,How to show that $P_1 \wedge P_2 \neq 0$?,"Suppose that $P_1$ and $P_2$ are finitely additive probability measures on $(X, \mathcal{B})$, and suppose that there's some $ B_0 \in \mathcal{B}$ such that $0 < P_1(B_0) < 1$ and $P_2(B_0) = 1$. I'd like to show that $P_1 \wedge P_2 \neq 0$. I know that $P_1 \wedge P_2$ is defined for all $B \in \mathcal{B}$ by 
$$(P_1 \wedge P_2)(B) = \inf\{P_1(A) + P_2(B-A): A \subseteq B, A \in \mathcal{B} \},$$
and from this it is clear that $P_1 \wedge P_2 \geq 0$, since $P_1$ and $P_2$ are probabilities. To finish, I just need to show that there's some $B \in \mathcal{B}$ such that $(P_1 \wedge P_2)(B) > 0$. I have tried to show this for $B_0$ but am unable to conclude. As a follow-up, if $P_1$ and $P_2$ are mutually singular probabilities, then is $P_1 \wedge P_2 = 0$?","['probability-theory', 'measure-theory']"
2228597,Combinatorics problem using inclusion/exclusion on matching pairs,"There are 5 different pairs of shoes. How many ways are there for 5 people to each choose 2 shoes with no one getting a matching pair? So I think this is a inclusion/exclusion problem. I think that the universe $|U|=5!$ Then I'm not sure how to continue. I guess I have to add up the number of ways for 1 person to get a matching pair. Then 2 people and so forth to all 5 people getting matching pairs. $5! - [5C1 * 4! - 5C2 * 3! + 5C3 * 2! - 5C4 * 1! + 5C5 * 0!] = 44$ So I'm pretty sure this is wrong and the $|U|=\frac{10!}{2^5}$. However I have trouble setting up the $P_i,P_i\cap P_j,...$. I tried taking the number of ways that a person gets a matching pair as $\binom{5}{1} * \frac{8!}{2^4}$ but it doesn't work.","['combinations', 'combinatorics', 'inclusion-exclusion', 'discrete-mathematics']"
2228606,Does Serre duality for Hodge numbers follow from Serre duality for coherent sheaves?,"When discussing Hodge numbers, the identity $h^{p,q} = h^{n-p,n-q}$ is called Serre duality . AFAIU, this identification follows from applying the Hodge $*$ isomorphism. In particular, $H^q(X,\Omega^p_X)$ is dual to $H^{n-q}(X,\Omega^{n-p}_X)$. If $X$ is now projective, we know that $H^q(X,\Omega_X^p)$ is dual to $H^{n-q}(X, \Omega_X^n \otimes \wedge^p T_X )$.
I would like to then deduce the identity of Hodge numbers above by saying that $\Omega_X^{n-p}$ is isomorphic to $\Omega_X^n \otimes \wedge^p T_X$ but I don't know why that should be true. It would certainly follow if I knew that the wedging map $\Omega^p_X \otimes \Omega^{n-p}_X \to \Omega^n_X$ were an isomorphism.","['hodge-theory', 'kahler-manifolds', 'complex-geometry', 'algebraic-geometry']"
2228636,Prove $8(1-\cos^2a)(1-\cos^2b)(1-\cos^2c) \geq 27 \cos a\cos b\cos c$,"Let $a$, $b$ and $c$ be angles of an acute triangle. Prove that:
  $$8(1-\cos^2a)(1-\cos^2b)(1-\cos^2c) \geq 27 \cos a\cos b\cos c$$ I tried am-gm, rm-gm rm-am and a couple of other inequalities but I didn't get anywhere.","['inequality', 'a.m.-g.m.-inequality', 'trigonometry', 'geometric-inequalities', 'triangles']"
2228642,How would I find the series generated by $e^x$ + $4x^2$? (exponential generating function),"Can I simply say: $e^x$ generates 1 + x/1! + $x^2$/2! + ....
and add on the $4x^2$ term? so the sequence generated instead of being 1,1,1,1,1,... is 1,1,4,1,1,1...?","['generating-functions', 'exponential-function', 'discrete-mathematics']"
2228657,Necessary and Sufficient Conditions for Convergence to Standard Normal,"I am stuck on the following problem: Let $\{X_n\}$ be a sequence of iid random variable with density:
  $$f(t)=c \frac{1}{|t|^{3+\alpha}}1_{\{|t| \ge 1 \}}\quad; t \in \mathbb{R}, \quad \alpha > 0$$ Choose $\{B_n\}$ to be a sequence of positive reals such that 
  $$\{B_n\} \to \infty \quad \text{as} \quad n \to \infty$$ Provide the necessary and sufficient conditions on the sequence $\{B_n\}$ so that $$\lim_{n \to \infty} \frac{X_1+...+X_n}{B_n}=N(0,1)$$ in distribution. I am not sure how to approach this problem.  Should I be trying to calculate the characteristic function for $\displaystyle \frac{X_1+...+X_n}{B_n}$ and then attempting to deduce conditions based on that?","['characteristic-functions', 'probability-theory', 'probability', 'random-variables']"
2228685,Generalization of Fuchs' Theorem for Differential Equations,"I am familiar with the method of Frobenius for solving second order linear DEs and have found a number of references to it online. To recap, it allows us to solve a DE like $\frac{d^2y}{dx^2} + p(x)\frac{d^2y}{dx^2} + q(x)y = 0$ with power series near a regular singular point assuming that p(x) and q(x) have poles of order at most 1 and 2 respectively. Fuchs' Theorem tells us that this method will always produce at least one answer. And I'm wondering if there is an analog to Fuchs' theorem to higher order linear DEs that anyone knows about and has a proof for. If we consider a higher order DE, $\frac{d^{n}y}{dx^{n}} + p_{n-1}(x)\frac{d^{n-1}y}{dx^{n-1}} + \cdots + p_{1}(x)\frac{dy}{dx} + p_{0}(x)y = 0$, we could begin to generalize the method. I imagine a singular point $x_{0}$ is called regular if $(x-x_0)^k p_{n-k}(x)$ is analytic for all $k = 1, 2, \cdots, n$. For this particular DE we would get an indical equation $r(r-1)\cdots (r-n+1) + r(r-1)\cdots (r-n+2)p_{n-1} + \cdots + p_{0} = 0$ where $p_k = lim_{x\rightarrow x_0}p_{k}(x)$ for each $k = 0, 1, \cdots, n-1$. Using solutions for $r$ we could then consider and work with solutions $y = \sum_{n=0}^{\infty}a_n (x-x_0)^{n+r}$. This seems like it would logically work, but I can't find much literature on this sort of generalization. I have only found one reference to this generalization at http://docsdrive.com/pdfs/sciencepublications/jmssp/2005/3-7.pdf and am curious as to whether there are others, perhaps an actual proof of these results and a characterization of the solutions in terms of the multiplicity of the solutions of the indical equation and their differences.",['ordinary-differential-equations']
2228700,Coordinate free proof for $a\times (b\times c) = b(a\cdot c) - c(a\cdot b)$,"The vector triple product is defined as $\mathbf{a}\times (\mathbf{b}\times \mathbf{c})$. This is often re-written in the following way:
\begin{align*}\mathbf{a}\times (\mathbf{b}\times \mathbf{c}) = \mathbf{b}(\mathbf{a}\cdot\mathbf{c}) - \mathbf{c}(\mathbf{a}\cdot\mathbf{b})\end{align*}
This is a very useful identity for integrating over vector fields and so on (usually in physics). Every proof I have encountered splits the vectors into components first. This is understandable, because the cross product is purely a three dimensional construct. However, I'm curious as to whether or not there is a coordinate free proof of this identity. Although I don't know much differential geometry, I feel that tensors and so on may form a suitable framework for a coordinate free proof.","['differential-topology', 'cross-product', 'differential-geometry', 'linear-algebra', 'vector-spaces']"
2228704,Find all solutions to $x^2+54=y^3$ over the integers,"Find all solutions to $x^2+54=y^3$ over the integers. Hint: the ideal class group order of $\mathcal{O}_{-6}$, $h_{\sqrt{-6}}=2$. $$\\$$
First we note that if $K=\mathbb{Q}(\sqrt{-6})$, then $R=\mathcal{O}_K=\mathbb{Z}[\sqrt{-6}]$, and by some theorem, since $-6\equiv2 \pmod4$, then the ideal $(2)_R$ ramifies into $\mathfrak{p}_2^2$, where $\mathfrak{p}_2=(2,\sqrt{-6})_R$, which cannot be a principal ideal since there is no solution to $a^2+6b^2=2$ over the integers. Hence the class group $Cl(R)=\{e,[\mathfrak{p}_2]\}$, since its order is 2. We can factorise so that if $\alpha =x+3\sqrt{-6}$, then $\alpha\tilde{\alpha}=y^3$. Now, note that $2\nmid x$ (otherwise $2|y\Rightarrow 4|54=2\cdot3^3$, contradiction), so $2\nmid y$. This means that $(y)_R^3\sim e $, since otherwise we would have $\mathfrak{p}_2|(y)_R^3\Rightarrow \mathfrak{p}_2^2|(y)_R^3$ which we cannot have by the above. Hence $(\alpha\tilde\alpha)_R\sim (y)_R^3\sim e$. This in turn implies that in the maximal ideal decomposition of $(\alpha)_R$, we cannot have a factor of $\mathfrak{p}_2$, and so $(\alpha)_R\sim(\tilde\alpha)_R\sim e$. Then we can write $(\alpha)_R=\prod_{i=1}^n\mathfrak{q}_i^{r_i}$ for $\mathfrak{q}_i\nsim\mathfrak{p}_2$ maximal ideals. We can now deduce that $3|r_i\;\; \forall i$, so that we can write $(\beta)_R=\prod_{i=1}^n\mathfrak{q}_i^{r_i/3}$ with $(\beta)^3_R=(\alpha)_R$. As both are principal ideals, we can write $\beta^3=\alpha=x+3\sqrt{-6}$ for some $a+b\sqrt{-6}=\beta\in R$. Solving this equation by comparing coefficients we get that: $\beta^3=a(a^2-18b^2)+3b(a^2-2b^2)\sqrt{-6}=x+3\sqrt{-6}\Rightarrow b(a^2-2b^2)=3$, and we get that the only solution is $b=-1,a=\pm 1\Rightarrow x=\pm17\Rightarrow y=7$. So $(\pm 17,7)$ are all the solutions. Is my reasoning correct?","['number-theory', 'algebraic-number-theory']"
2228769,Last Digit of this expression?,"Came across this Devil while preparing for JEE Advanced. Question : If $$K=\sum_{n=1}^{\infty}\frac{6^n}{(3^n-2^n)(3^{n+1}-2^{n+1})}$$
Then the last digit of $(K+6)^{(K+6)!}$ is? What i tried to do was to separate $6^n$ as $3^n$$2^n$ and tried to proceed further, but to be honest, I'm getting nowhere around the answer which according to my textbook is 8.","['number-theory', 'combinatorics', 'summation']"
2228809,Meaning of Dot Products in Regards to Linear Algebra,"I'm currently taking an intro to linear algebra course. We have reached the section on dot products and I fail to understand the meaning of it. What does it tell me, besides spitting out a scalar? I initially read that the answer is similar to asking what the point of multiplication is, but I understand why multiplication is useful.","['vectors', 'linear-algebra', 'soft-question']"
2228815,Finding the derivative at a particular point,"So I've got this question and I'm not 100% if I've actually answered it correctly, would be appreciated if you can check it and tell me whether its correct if not can you tell me where I went wrong and where I can improve thanks! :) Question Find the derivative of the function $$f(x)=\begin{cases}
x^2\sin(\frac{1}{x}), &x \neq 0 \\
0, & x=0
\end{cases}$$ at $x=0$ Working $\lim_{h\to 0}\frac{f(h)-f(0)}{h}=\lim_{h\to 0} h^2\sin(\frac{1}{h})$ *Apply squeeze theorem. $-1\leq\lim_{h\to 0}h^2\sin(\frac{1}{h})\leq1$ $\therefore \lim_{h\to 0}h^2(\frac{1}{-1})\leq\lim_{h\to 0}h^2\sin(\frac{1}{h})\leq\lim_{h\to 0}h^2(\frac{1}{1})$ $0\leq\lim_{h\to 0}h^2\sin(\frac{1}{h})\leq 0$ $\implies \lim_{h\to 0}h^2\sin(\frac{1}{h})=0$","['derivatives', 'proof-verification', 'calculus', 'limits']"
2228874,D&F Definition of rank on modules - need explanation,"In Dummit & Foote's Abstract Algebra , pg 460, Chap 12, they defined: For any integral domain $R$ the rank of an $R$-module $M$ is the maximum number of $R$-linearly independent elements of $M$. Sorry if these are obvious: (i) If the maximum number is not finite does this mean we define the rank as: the cardinality of a maximal $R$-linearly independent set. (ia) But then we would have to show all maximal $R$-linearly independent set have same cardinality? (ib) How do we know such a maximal $R$-linearly independent set of elements in $M$ exists?","['abstract-algebra', 'ring-theory', 'modules', 'definition']"
2228941,Infinite solution in quadratic equation,In my textbook it says that some quadratic equations can have infinite solutions. For example if $x^2-2x=x^2-3$ then rather than cancelling $x^2$ from both sides the book lets $x=\frac{1}{m}$ and then rearranges to get $1-2m=1-3m^2$ or $m(3m-2)=0$ therefore $m=0$ or $m=\frac{2}{3}$ giving $x=\infty$ or $\frac{3}{2}$. This is the first time I see this so I am just wondering if $\infty$ is actually a valid solution?,"['algebra-precalculus', 'proof-verification', 'quadratics']"
2228942,Ring homomorphism: Prove the image is a subring,"I was given the following question (in my undergraduate Abstract Algebra module): Let $f:R\to S$ be a ring homomorphism. Prove that: the image of $f$ is a subring of $S$ if $R$ is a ring with unity and $f$ is surjective. The following is my attempt: The image of $f=\{s\in S\mid s=f(r)$  for some $r\in R\}$.
Let $x,y\in R$ and  $f(x), f(y)\in f(R)$ $$f(x)-f(y)=f(x-y)$$ 
$x-y\in R$ (since $R$ is a group). Thus the image of $f$ is closed under subtraction. $$f(x)*f(y)=f(xy)        $$
$xy\in R$ (since $R$ is a group).
Thus the image of $f$ is closed under multiplication. Therefore the image of $f$ is a subring of $S$. Is this even correct? I never used the fact that $R$ is a ring with unity and that $f$ is surjective so it is confusing me? Thank you.","['abstract-algebra', 'ring-theory']"
2228958,"Determinant of matrix that is diagonal, but for last row/column","I would like to compute the determinant of a symmetric $(K+1)\times (K+1)$ matrix in which the upper left $K \times K$ matrix is diagonal but the $(K+1)$th row and column are complete. E.g.
$$
X = \begin{bmatrix} 
x_1 & 0 & \dots & 0 & y_1 \\
0 & x_2 & \dots & 0 & y_2 \\
\vdots & \vdots & \ddots & \vdots & \vdots \\
0 & 0 & \dots & x_K & y_K \\
y_1 & y_2 & \dots & y_K & y_{K+1}
\end{bmatrix}
$$ 
Is there a simple way to compute $\det(X)$? Note, a similar question was asked for a matrix with the same form but with more constraints on the entries: Determinant of an almost-diagonal matrix I can't see that the answer to this question helps here though.","['matrices', 'linear-algebra', 'determinant']"
2228975,Showing that roots of a quadratic polynomial are of opposite signs.,"Prove that, for all values of $k$, the roots of the quadratic polynomial $x^2 - (2 + k) x - 3$ are real. Show further that the roots are of opposite signs. For the first part I was able to demonstrate such by using the discriminant of the quadratic, then using the discriminant of the discriminant. For the second part I was not able to demonstrate such.","['algebra-precalculus', 'polynomials', 'quadratics']"
2228994,Examing a limit of sum of square roots,"Calculate the following limit:
  $$\lim\limits_{n \to\infty} \left(\frac{1}{\sqrt{n^2+1}} + \frac{1}{\sqrt{n^2+2}} + ... + \frac{1}{\sqrt{n^2+n}} \right)$$ I think this limit equals $1$. I am not sure. Tried using the squeeze theorem: $$1 \leq  \left(\frac{1}{\sqrt{n^2+1}} + \frac{1}{\sqrt{n^2+2}} + ... + \frac{1}{\sqrt{n^2+n}} \right) \leq n\cdot \frac{1}{\sqrt{n^2}}$$. It's quite clear why the right hand side is bigger than the middle term, but is $1$ really smaller of equals to the middle term? Please note I can't use integrals here nor taylor series. Thanks!","['real-analysis', 'limits']"
2229019,Dedekind domain in which quotient rings are not all finite?,"In rings of integers $O_K$, which are free $Z$-modules of finite rank (say n), we have that if m is an integer in the prime ideal $\mathfrak{p},$ then there is a surjection $$\frac{O_K}{(m)} \rightarrow \frac{O_K}{\mathfrak{p}}.$$The size of the first ring is $m^{n},$ which is finite. Therefore , the surjection of a finite ring into $\frac{O_K}{\mathfrak{p}}$ implies both rings are finite. But $\frac{O_K}{\mathfrak{p}}$ is a finite integral domain, therefore a field, therefore $\mathfrak{p}$ is a maximal ideal. In short, every quotient of $O_K$ by an ideal is finite, so prime ideals must be maximal. Since the only Dedekind domains I am familiar are rings of integers, is there an example of a Dedekind domain where this rule does not apply,i.e. where the quotient rings are not all finite?","['abstract-algebra', 'ring-theory', 'algebraic-number-theory', 'ideals']"
2229056,Derivative of definite integral of function of two variables,"I know that the fundamental theorem of calculus says that if $f(t)$ is differentiable on the interval $(a,x)$ for some constant $a$ and variable $x$ then we have \begin{equation}\frac{d}{dx}\int_a^x f(t)dt = f(x).\end{equation} What I am wondering is, what happens when a function depends on $x$ as well? So, for example, $g: \mathbb{R}^2 \to \mathbb{R}$. For concreteness perhaps say $g(x,t) = f(x-t)$. Then how do I compute \begin{equation}\frac{d}{dx}\int_a^x g(x,t)dt?\end{equation}","['multivariable-calculus', 'integration', 'calculus', 'derivatives']"
2229058,Computing Ray from the Center of the Camera Passing through $X$ for given pixel $x$,"For perspective projection with given camera matrices and rotation and translation we can compute the 2D pixel coordinate of a 3D point. using the projection matrix, $$
P = K [R | t]
$$ where $K$ is intrinsic camera matrix, $R$ is rotation $t$ is translation. The projection is simple matrix multiplication $x = P X $. It is also known we can add an extra row to the matrices above to get a $4 \times 4$ projection matrix. $$
\tilde{P} = \left[\begin{array}{cc} 
K & 0 \\ 0^T & 1
\end{array}\right]
\left[\begin{array}{cc} 
R & t \\  0^T & 1
\end{array}\right]
$$ I am trying to do the reverse. In Computer Vision Alg and Application book , pg. 54, Szeliski says we can  invert $\tilde{P}$ to get the ray from camera center that'll pass through all possible points. I tried this approach for a camera with known calibration, for given pixel (200,200), K = [[ 282.363047,      0.,          166.21515189],
     [   0.,          280.10715905,  108.05494375],
     [   0.,            0.,            1.        ]]
K = np.array(K)
R = np.eye(3)
t = np.array([[0],[1],[0]])
P = K.dot(np.hstack((R,t)))
P = np.vstack((P,[0,0,0,1]))
print P

x = np.array([200,200,10,1])
X = np.dot(lin.inv(P),x)
print X to get a direction, which gives me [-5.17826796 -3.14361632  9.          1.        ] The camera was merely translated one unit in Y direction, but the resulting vector seems to be pointing in the wrong direction. Szeliski talks about a disparity which I am not sure how to encode in the pixel input. Any help on this approach, or alternative approaches to calculate the ray for given pixel, matrix with known orientation and $K$ would be helpful.","['computational-geometry', 'projective-geometry', 'image-processing', 'geometry', 'linear-algebra']"
2229096,Showing that $10!=6!7!$ via Gamma function,"It is well-known that $10! = 6! 7! $, I want to prove it via algebraic manipulations of Gamma function, i.e show that:
 $$ \int_{0}^{+\infty} x^7 e^{-x} \, dx \int_{0}^{+\infty} y^6 e^{-y} \, dy = \int_{0}^{+\infty} z^{10} e^{-z} \, dz \qquad (1) $$
I tried to write the LHS as: $$ \int_{0}^{+\infty} \int_{0}^{+\infty} x (xy)^6 e^{-(x+y)}  \, dx dy \qquad (2)$$ and go for the substitution $u = x + y $, $v=xy$, but that leads to complicated calculations. Is there a reasonable way/substitution to turn the double integral in $(2)$ into the RHS in $(1)$. Thanks in advance for any contribution.","['factorial', 'integration', 'gamma-function']"
2229101,"quick question about the limit of a two-variable function as $x,y\to\infty$","$$\lim_{x,y\to\infty} \frac{x-y}{x^2+y^2}\tag{$\star$}$$ I'm used to do the following substitution when I see $``x^2+y^2""$ and that $x,y\to 0$ $$x^2+y^2 = r^2,\;x=r\cos\theta,\;y=r\sin\theta$$ plug these values in the function and compute the limit as $r\to0$ I know I can do that because the only way for $x$ & $y$ to approach $0$ is $r$ approaching $0.$ I cannot do this substitution everytime because if for example: $(x,y)\to(-1,7)$ there's no value $u$ that guarantee me if $r\to u$ then $(x,y)\to(-1,7).$ but here since $x,y\to\infty$ I think that logically this phenomenon can only happen if $r\to\infty$ as well. So computing $(\star)$ is the same as computing this : $$
\lim_{r\to\infty} \frac{r\cos\theta-r\sin\theta}{r^2} =\lim_{r\to\infty} \frac{\cos\theta-\sin\theta}{r}=0.
$$ I'm 90% sure that what I've done is correct but I still want a confirmation and if possible show me other ways to compute this limit. Sorry if this question sounds kinda dumb but I'm still new to multivariable calculus and today is my first time dealing with MVC limits. Thank you !","['multivariable-calculus', 'limits']"
2229107,Show that $l^2$ is the only $l^p$ space which norm is induced by the inner product,"I want to use the theorem of Jordan and von Neumann which states that norm is induced by inner product if and only if the parallelogram law is true Let $\Vert x \Vert_p$ be the norm in $l^p, 1\le p < \infty$. In parallelogram law we have, $\Vert x+y \Vert_p^2 + \Vert x-y \Vert_p^2 = 2\Vert x \Vert_p^2 + 2\Vert y \Vert_p^2$ which is equivalent $(\sum|x_i+y_i|^p)^{(2/p)} + (\sum|x_i-y_i|^p)^{(2/p)} = 2(\sum|x_i|^p)^{(2/p)} +2(\sum|y_i|^p)^{(2/p)}$. But now how can we get that $p=2$ is the only correct one? Is it possible to construct a sequence for which parallelogram fails for each $p$ different than 2?",['functional-analysis']
2229110,Show $P(z) $ is a polynomial of degree $n-1$ interpolating an Analytic function.,"Let $C$ be a regular curve enclosing the distinct points $ω_1,ω_2,...ω_n$ and let $p(ω) = (ω −ω_1)(ω −ω_2) \cdots (ω −ω_n)$. Suppose that $f (ω)$ is analytic in a region that includes $C$. Show that $$P(z) =  \frac{1}{2 \pi i} \int_C \frac{f(ω)}{p(ω)} . \frac{p(ω) -p(z)}{ω -z} dω$$ is a polynomial of degree $n-1$ and $P(ω_i) = f(ω_i)$.","['interpolation', 'lagrange-interpolation', 'calculus', 'complex-analysis', 'analysis']"
2229117,Why is Normalizer-Centralizer (N/C) Theorem valid only for subgroups?,I have a few queries regarding the normalizer/centralizer theorem and I would prefer a response suitable for a beginner. Suppose that $G$ is a group and $S \subseteq G$ then we know that both $N_{G}(S)$ and $C_{G}(S)$ are subgroups of $G$ and in particular $C_{G}(S)$ is a normal subgroup of $N_{G}(S)$. The N/C theorem only deals with the case when the subset $S$ is actually a subgroup of $G$ and not just any subset of $G$. The quotient $N(S)/G(S)$ makes sense for arbitrary subsets $S$ of $G$. Why does the $N/C$ theorem not deal with such subsets $S$? One obvious reason is that we can't talk about $Aut(S)$ unless $S$ itself is a group. But apart from that is there any other specific reason to choose $S$ as a subgroup of $G$? Or perhaps the quotient $N/C$ is interesting enough (i.e. it provides valuable information about $S$) only when $S$ is a subgroup. Next consider the usual N/C theorem: $$\frac{N_{G}(H)}{C_{G}(H)} \cong K \leq Aut(H)$$ where $H\leq G$. Now the members of $K$ are inner automorphisms of $G$ based on conjugation by members of $N_{G}(H)$ i.e. $K \subseteq Inn(G)$. The only reason this $K$ is also a subset of $Aut(H)$ is because members of $K$ are conjugation via members of $N_{G}(H)$. Is my understanding about $K$ above correct? Also does $K \leq Inn(G)$?,"['abstract-algebra', 'group-theory']"
2229128,Increasing sequence containing only finitely many prime numbers [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Prove the existance of an increasing sequence $(a_n)_{n≥1}$ of positive integers such that
for any $k ≥ 0$, the sequence $k + a_n, n ≥ 1,$ contains only finitely many primes.",['number-theory']
2229130,Dividing a rectangle into a grid of rectangles/squares,"I'm writing a program where I need to divide a large rectangle into small pieces, no constraint on being exactly equally sized or exactly rectangle(they can be a square as well) and even if they protrude out of the larger rectangle a little, it'll be fine. I know how to divide a rectangle into some number of rectangles, but my current situation is making it difficult to visualize how many rectangles should I divide it into. Let me explain the scenario - I've been given a large rectangle with n number of uniformly distributed points inside it and I've to make smaller rectangles so that each rectangle has ~10^3-10^4 points in it. The n can vary easily from 10^5 - 10^8 and even above. My idea is to cluster those points into smaller rectangles so that I don't have to compare all points linearly and just compare their bounding rectangles to the geometric figure. So in earlier case, I would be comparing millions of points for each geometric figure, now I would be comparing much much less number of bounding rectangles. For now I've hardcoded the values eg. 1000 smaller rectangles for 10^6 number of points and like that for 10^7 and 10^8. But it has a disadvantage that instead of calculating for continuous range, I'm hard coding for discrete range which does not work for 5000000 number of points or any such in middle. Also, they are usually made into thin strips which makes them very hard to fall completely within the geometric shape I'm comparing with. I hope I've explained it clearly, but I'll provide a TLDR; Given a rectangle with n number of points uniformly distributed inside it, split that rectangle into smalle rectangles with 10^3-10^4 number of points in each of them. Also, the naive solution like dividing into very slim strips does not work for me because then most strips only intersect with geometric figure rather than falling within it completely, it would be preferable for an algorithm/function to make somewhat both axis uniform boxes. ________                           ________
| | | | |   <-- slim strips         |   |   |   <-- much better
| | | | |                           |---|---|
|_|_|_|_|                           |___|___|","['algorithms', 'geometry']"
2229144,Finding UMVUE of $p^s$ in Bernoulli distribution,"Suppose that $X_1, \ldots, X_n$ follows Bernoulli distribution $B(1,p)$, then what is the UMVUE of $p^s$ and $p^s + (1-p)^{n-s}$? I suppose I should use the Lehmann–Scheffé theorem. Now $\overline{X}$ is a sufficient and complete statistic, I need to find a function of $\overline{X}$ whose expectation is $p^s$ and  $p^s + (1-p)^{n-1}$. But I don't know how to find such a function. Any hint would be welcome!","['statistics', 'probability']"
2229172,Measure of intersection of a set with its translate,"I'm trying to prove that if $A \subset \mathbb{R}^d$ is a Lebesgue mensurable set with $\mu(A) \neq 0$ and $\mu(A) < \infty$, then $$\lim_{\| x \| \to 0} \mu(A \cap (A+x)) = \mu(A).$$
I think I can prove this for parallelepipeds, but I'm unable to make it for other sets. Can anyone help me?","['real-analysis', 'measure-theory']"
2229175,How Hahn-Banach theorem implies that the dual space is non-trivial?,Why does the theorem of Hahn-Banach implies that the dual space is not empty ($X^*\neq\emptyset)$ ? Is there an important corollary which I've missed ?,"['real-analysis', 'dual-spaces', 'normed-spaces', 'functional-analysis', 'linear-algebra']"
2229192,"To what extent $\frac{d}{dx} \int_{-\infty}^{\infty} f(t,x)\, dt = \int_{-\infty}^{\infty}\frac{d}{dx}f(t,x)\, dt$","Assume $\int_{-\infty}^{\infty} f(t,x)\, dt$ exists for every $x \in {\mathbb R}^n$. Then, to what extent, the following equation holds? $$\frac{d}{dx} \int_{-\infty}^{\infty} f(t,x)\, dt = \int_{-\infty}^{\infty}\frac{d}{dx}f(t,x) \,dt.$$","['derivatives', 'integration', 'calculus']"
2229216,Is there a injective compact operator $T$ such that #$sp(T) < \infty$?,"Let $X$ a Banach spaces such that $\dim X = \infty$, and $T: X\to X$ a injective compact operator. Is there $T$ such that #$sp(T) < \infty$  ? Thanks","['functional-analysis', 'spectral-theory']"
2229227,"If a metric on $\Bbb R^n$ is flat, is the space globally isometric to Euclidean space?","Let $g$ be a metric of arbitrary signature on $\Bbb R^n$. If the Riemann tensor of $g$ vanishes identically, is there a diffeomorphism $f:\Bbb R^n\to\Bbb R^n$ with $g=f^*e$, where $e$ is the standard metric with the same signature as $g$? In the Riemannian case, assuming $(\Bbb R^n,g)$ is complete, this is well known from the classification of space forms. I was unable to show that $(\Bbb R^n,g)$ is always complete in the Riemannian case, and I don't know if it's true or not. I also know that this is always true in a local sense, but I am looking for a global isometry.","['riemannian-geometry', 'differential-geometry']"
2229263,Convergence of $\sum \frac{\sin(n^2)}{n}$,Does the numerical series $\sum \frac{\sin(n^2)}{n}$ converges ? For the moment I have tried a discrete integration by parts but it involves the asymptotic behaviour of $\sum \sin(n^2)$ which seems complex. Trying a comparison with an integral does not seem very useful too.,"['asymptotics', 'sequences-and-series', 'trigonometric-series']"
2229280,"What is meant by ""The Levi-Civita Connection is an $\mathfrak{so}(n)$-Valued 1-form""?","this is a statement that I've seen around, and I thought it's time that I understand it. I know that the LCC is locally given by a matrix $ \omega = (\omega_i^j)$ of 1-forms in a preferred frame $e_i$, so that $$ \nabla f_ie_i  =   df_i \otimes e_i + f_i \omega_i^j \otimes e_j   $$ for any local smooth functions $f_i$. Then, $\omega$ is a matrix representing a linear map on each tangent space. Now, ""$\nabla$ is an $\mathfrak{so}(n)$-valued 1-form"" suggests to me that each $(\nabla v)|_p$ is in $\mathfrak{so}(T_pM)$ , but I know that this is only true for $v$ a Killing field. But perhaps I'm getting confused between $\nabla$ as an object and its representation $\omega$ in a particular frame. So, my next guess is that it means that, in some choices of local frame $e_i$, the matrix $\omega_i^j(v)$ is skew-symmetric for any $v$. Orthormal frame is the probable condition. But this would mean, in particular, that each $\nabla e_i$ is skew-symmetric, since if $v = e_i$, there are no nonconstant components of $v$ to worry about, and '$\nabla = \omega$'. Then again, we'd be at the statement that all the $e_i$ are (local) Killing fields, which is just rubbish - on a generic Riemannian manifold, there are no nontrivial local Killing fields, if I remember right. So, what does ""$\omega$ is $\mathfrak{so}$-valued"" mean? Any help would be massively appreciated.","['connections', 'riemannian-geometry', 'differential-geometry']"
2229289,Irreducible algebraic sets of $\mathbb A^2(k)$,"I want to show that the irreducible algebraic sets of $\mathbb A^2(k)$ are exactly the following: $$\mathbb A^2(k),\emptyset,\text{Singleton and algebraic curves}.$$ Of course all of them are irreducible algebraic sets of $\mathbb A^2(k)$, but how can I show that there are exactly those sets?","['abstract-algebra', 'algebraic-geometry']"
2229335,$x$ is smaller than all positive numbers,We have $0\le x \lt h$ for all $h \gt 0$. Prove that $x=0$. I know it is obvious but I can't prove it. My try : I think it has some connections with concept of limit but I can't prove it.,['algebra-precalculus']
2229343,Find uncountable set of functions from countable set agreeing only in finite subsets,"(Sorry for the terrible title, but I couldn't come up with a reasonable description of the problem with words.) The problem: Let $I$ be a countably infinite set and $A$ be an infinite set. Prove that there exist $S \subseteq A^I$ such that $|S|=\aleph_1$ and for $f,g \in S$, if $f \neq g$ then $\{ i \in I : f(i) = g(i) \}$ is finite. Show that, if $U$ is a free ultrafilter over $I$, then $|A^I/U| \geq \aleph_1$. (Here, the quotient is over the equivalence relation $\sim_U$ given by $a \sim_U b$ iff $\{ i \in I : a(i) = b(i) \} \in U$). I am allowed to use the Continuum Hypothesis. Partial resolution: Given the result of the first part, the second one is easy to prove. If $U$ is a free ultrafilter over $I$, then all the cofinite sets of $I$ belong to $U$, and therefore, no finite subset of $I$ belongs to $U$. So, $a/U \neq b/U$ whenever $\{ i \in I : a(i) = b(i)\}$ is finite, and thus, each member of $S$ represents a different class of $\sim_{U}$, that is, a different element of $A^{I}/U$, so that $|A^I/U| \geq |S| = \aleph_1$. Tentative of solving the first part: If $A$ is uncountable, then $|A| \geq \aleph_1$ and so we can take a subset $B$ of $A$ with $|B| = \aleph_1$ and the $S$ to be the constant functions from $I$ to $B$. Suppose $A$ is countable.
In this case, I though I could parametrize a family of functions from $I$ to $A$ more or less like $c_{a,J}$, for $a \in A$ and $J$ a finite subset of $I$, by making
$$c_{a,J}(i) = 
\begin{cases}
a &\text{ if } i \in J,\\
\phi(i) &\text{ if } i \notin J.
\end{cases}$$
where $\phi$ would be a function from $I$ to $A$ that would suit the required conditions. (The reason for which $J$ must be finite is that otherwise we could have $J,J'$ for the same $a \in A$, so that $c_{a,J}$ and $c_{a,J'}$ could agree in an infinite subset of $I$, although being different.) But on a second though I realized that this family is not large enough, because, since there are only as many finite subsets of $I$ as members of $I$, there are only $|I| \cdot |A|$ such functions, that is, we would have $|S| = \aleph_0$.",['elementary-set-theory']
2229357,Problem with Understanding Proof of the Multivariable Mean Value Theorem,"I have some questions concerning a proof of the Mean Value Theorem from Bredon's book that I find rather cryptical. Theorem: Let $f : \mathbb{R}^n \to \mathbb{R}$ be $C^1$. Let $x := (x_1, \dots , x_n)$ and let $x' := (x'_{1}, \dots , x'_n)$. Then there exists a $x^* := (x^*_{1}, \dots , x^*_n)$ on the line segment between $x$ and $x'$ such that $$ f(x) - f(x') = \sum^{n}_{i = 1} \frac{\partial f}{\partial x_i} (x^*) (x - x').$$ Proof: Apply the Mean Value Theorem found in any calculus book to the function $\mathbb{R} \to \mathbb{R}$ defined by $t \mapsto f(tx + (1-t)x')$ and use the Chain Rule:
  $$ \frac{d f(tx + (1-t)x')}{dt} \Bigg|_{t = t^*} = %
\sum^{n}_{i = 1} \frac{\partial f}{\partial x_i} (x^*) \frac{d (tx_i + (1-t)x'_i)}{dt} \Bigg|_{t = t^*} = %
\sum^{n}_{i = 1} \frac{\partial f}{\partial x_i} (x^*) (x_i - x'_i )$$
  with $x^* := t^* x + (1 - t^* )x' $. I have the following problems. Why $t \mapsto f(tx + (1-t)x')$ is defined on $\mathbb{R} \to \mathbb{R}$ ? I think it should rather be defined on $[0,1] \to \mathbb{R}$ (i.e., it should be convex and not affine), since we want to capture that $x^* \in f(t^* x + (1 - t^* )x')$ for some $t^* \in [0,1]$. If $t \mapsto f(tx + (1-t)x')$ is defined on $[0,1]$ then I can almost get what happens in the equation. That is, things should work as follows: start from $t \mapsto f(tx + (1-t)x')$ and apply calculus Mean Value Theorem getting
\begin{align}
\frac{f(x) - f(x')}{?} & = \frac{df}{dt} (t^*) \\
& = \sum^{n}_i \frac{\partial f}{\partial x_i} (x^*).
\end{align}
Notice that at the denominator on the LHS I put a question mark because I don't see how it should work. We should get $(x - x')$, but I don't really see how. Or better, I see it, if the denominator works as
$$ (1x + (1-1)x' - 0x + (1-0)x' ),$$ which is indeed equal to $(x - x')$, but to me this is not clear at all. Indeed it should simply be equal to $1$, because we are acting on the domain of $t \mapsto f(tx + (1-t)x')$, that should be just $[0, 1]$, not on its codomain. [The RHS should be OK, since we have that there is a $t^*$ and then we use it to define $x^*$.] How should this actually work? Any feedback would be greatly appreciated since I am self-taught and I think I never really got how these analysis proofs with differentiation actually work. Thanks a a lot for your time.","['multivariable-calculus', 'real-analysis', 'proof-explanation']"
2229365,Covairant Derivative along the Constant Curve. What is the Mistake?,"Let $(M, g)$ be a Riemannian manifold, equipped with the Riemannian connection. Let $f:I\to M$ be the constant curve, mapping all elements of $I$ to a point $p$ on the manifold. Let $V$ be a vector field along $f$. Thus $V$ can be thought of as a smooth map $V:I\to T_pM$. Question. What is the covariant derivative of $V$ along $f$? By definition, the covariant derivative $\frac{DV}{dt}(t_0)=\nabla_{f'(t_0)}\tilde V$, where $\tilde V$ is any extension of $V$ in a neihborhood of $f'(t_0)$. But $f'(t_0)=0$ since $f$ is constant. Thus $\nabla_{f'(t_0)}\tilde V=0$, and thus the required covariant derivative is also $0$. This is not the right answer, for Problem 6 of Chapter 2 of Do Carmo's Riemannian Geometry asks to prove that the covariant derivative is same as the derivative of the smooth map $V:I\to T_pM$, which might not be $0$. I am unable to locate my mistake.","['riemannian-geometry', 'differential-geometry']"
2229374,"Evaluate $\int_0^{2\pi}\frac{1}{1 + A\sin(\theta) + B\cos(\theta)}\, \mathrm{d}\theta \ \text{ for }\ A,B \ll 1$","I need to evaluate the definite integral $$\int_0^{2\pi}\frac{1}{1 + A\sin(\theta) + B\cos(\theta)}\, \mathrm{d}\theta  \ \text{    for various}\ A,B \text{; with}\ A,B\ll1.$$ Wolfram Alpha provides the following indefinite general solution:- $$\int \frac{1}{1 + A\sin(\theta) + B\cos(\theta)}\, \mathrm{d}\theta =  -(2/K) \tanh^{-1} \left( \frac{A-(B-1)\tan(\theta/2)}{K}\right) $$ where $K = \sqrt{A^2 + B^2 -1}$ . But I am having trouble checking it for the simple case when $A=B=0$ when I would expect the answer to be given by:- $$\int_0^{2\pi}\frac{1}{1 + 0 + 0}\, \mathrm{d}\theta = 2\pi.$$ I have approached the Wolfram Alpha solution thus:- $$ -\frac{2}{K}\tanh^{-1} \left( \frac{\tan(2\pi/2)}{K}\right) +\frac{2}{K} \tanh^{-1} \left( \frac{\tan(0/2)}{K}\right) $$ $$ -\frac{2}{K} \tanh^{-1} \left( \frac{\tan(\pi)}{K}\right) +\frac{2}{K} \tanh^{-1} \left( \frac{\tan(0)}{K}\right) $$ $$ -\frac{2}{K}\tanh^{-1}\left(\frac{0}{K}\right) +\frac{2}{K} \tanh^{-1} \left( \frac{0}{K}\right) $$ which gives the result of zero. I presume this error comes from trying to integrate across the range $0, 2\pi$ where the $\tan$ function has singularities at $\pi/2$ and $3\pi/2$ . However when I try and break the integration into the three continuous ranges $0,\pi/2$ and $\pi/2,3\pi/2$ and $3\pi/2,2\pi$ I am still getting a result of zero thus:- $$ -\frac{2}{K} \tanh^{-1} \left( \frac{\tan(2\pi/2)}{K}\right) +\frac{2}{K} \tanh^{-1} \left( \frac{\tan(3\pi/4)}{K}\right) + $$ $$ -\frac{2}{K} \tanh^{-1} \left( \frac{\tan(3\pi/4)}{K}\right) +\frac{2}{K} \tanh^{-1} \left( \frac{\tan(\pi/4)}{K}\right) +$$ $$ -\frac{2}{K} \tanh^{-1} \left( \frac{\tan(\pi/4)}{K}\right) +\frac{2}{K} \tanh^{-1} \left( \frac{\tan(0)}{K}\right) $$ leading to $$ -\frac{2}{K} \tanh^{-1} \left( \frac{0}{K}\right) +\frac{2}{K} \tanh^{-1}\left( \frac{-1}{K}\right) + $$ $$ -\frac{2}{K} \tanh^{-1} \left( \frac{-1}{K}\right) +\frac{2}{K} \tanh^{-1} \left(\frac{1}{K}\right) +$$ $$ -\frac{2}{K} \tanh^{-1} \left( \frac{1}{K}\right) +\frac{2}{K} \tanh^{-1}\left( \frac{0}{K}\right) $$ which gives the same result of zero. I would be grateful if somebody could tell me where I am going wrong here? EDIT 1: I have accepted the solution provided kindly by Dr. MV.
I have posted a related question which seeks to understand where my original evaluation of the definite integrand goes wrong. EDIT 2: In the related question comments from user mickep pointed out that the wrong partitions had been used in the original evaluation. Using the correct partitions ( $0...\pi$ ) and ( $\pi...2\pi$ ) leads to the correct answer, for $A=B=0$ , of $2\pi$ (as described in my self-answer to that same question). EDIT 3: It was pointed out by user mickep in comments to the related question that the Wolfram Alpha solution $$ -\left(\frac{2}{K_1}\right) \text{arctanh}\left( \frac{A-(B-1)\tan(\theta/2)}{K_1}\right) $$ where $K_1= \sqrt{A^2 + B^2 -1}$ . is not as friendly as an alternative solution (reported by user mickep) which is: $$ +\left(\frac{2}{K_2}\right) \arctan  \left( \frac{A+(1-B)\tan(\theta/2)}{K_2}\right) $$ where $K_2 = \sqrt{1 - A^2 - B^2}$ .","['integration', 'trigonometry']"
2229402,"Evaluate $\int_0^\frac{\pi}{4} \cos^{-1}({\sin x}) \,dx$","I came across this integral in a math competition and couldn't solve it
$$\int_0^\frac{\pi}{4} \cos^{-1}({\sin x})\, dx$$ I tried a $u$-substitution, with $u=\sin x$ and ended up with the integral $$\int_0^\frac{\pi}{4} \cos^{-1}(\text{u}) \cdot \frac{1}{\sqrt{1-u^2}}\,du$$ which is not much simpler and I cannot figure out how to solve this. Any hints/solutions for this problems? I also tried drawing a triangle for the problem but it didn't really help with the solution.","['definite-integrals', 'trigonometry', 'calculus']"
2229423,Möbius transformation sending line and circle to concentric circles,"I want to find some Möbius transformation sending the line $l$ defined by $Re(z) = 5$ and the circle $\vert z\vert = 4$ to concentric circles in the complex plane. I know that Möbius transformations preserve (generalized) circles and that möbius transformations are closed under composition via its group structure. So the simplest inversion Möbius transformation $T_1(z) = \frac{1}{z}$ turns $l$ into the circle with radius $\frac{1}{10}$ situated at  $\frac{1}{10} +0i$. I can then turn it into the unit circle by two composed möbius transformations moving it to the left by $\frac{1}{10}$ and then scale it by $10$. Even if this is correct, how can I make sure that $\vert z\vert = 4$ stays somewhat ""invariant"" so that encloses the image of my line $l$?","['complex-analysis', 'mobius-transformation']"
2229527,Shading a honeycomb board,"The following figure shows a honeycomb  board that is bounded by an equilateral triangle. The $i^{\mathrm{th}}$ row contains $9 - (i - 1)$ cells for each integer $1 \leq i \leq 9$. A game is played on the board. Every time a token is placed on the board,
all the cells on the same row and on the same diagonal as it are shaded. (An instance of the shading from a turn is shown.) Determine the minimal number of turns required to shade the figure. Comments By induction, for every positive integer $n$, the maximum number of turns to shade a similar honeycomb figure with either $2n - 1$ or with $2n$ cells along an edge is $n$. As there are 9 cells along the base of the given figure, and as $9 = 2(5) - 1$, the maximum number of turns required to shade the given figure is 5. Requests What is the minimum number of turns to shade the board? Is there a convenient rule for computing the minimum number of turns needed on a similar board with $n$ cells along the bottom row?",['combinatorics']
2229533,How to derive the cdf of given function,"Let
$$Y = \frac{X_1+X_2+\cdots+X_{100}}{100}$$ I understand that the Central Limit Theorem says you can approximate Y. But by what random variable? And how can I write the cumulative distribution function of this random variable? I am confused on how to derive the CDF. Do I need to find the PDF first?","['statistics', 'central-limit-theorem']"
2229549,Given a solution of a Differential Equation. How to find the another solution in this exercise?,"$y'''-x^2y'+xy=0$, solve the differential equation if $y_1=x$ is a solution. I've tryed using the sustitution $y=u(x)y_1(x)=u(x) \cdot x$. Taking the derivates, the final form is like this:
$$(3u''+xu''')-x^2(u+xu')+x(u \cdot x)=0$$
$$3u''+xu'''-x^2u-x^3u'+ux^2=0$$
$$xu'''+3u''-x^3u'=0$$ But, now i have antoher D.E of degree 3. How i can find the another solution?.",['ordinary-differential-equations']
2229589,Topology on a space starting from topologies on subspaces,"I have a question about constructing a topology on a space $X$ starting from topologies defined on a family of subspaces $(X_i)_{i\in I}$ of $X$. Assume that $X$ is a set and $(X_i)_{i\in I}$ is a collection of subsets of $X$. Assume also that for every $i\in I$, there is a topology $\mathcal{T}_i$ defined on $X_i$. We say that a topology $\mathcal{T}$ on $X$ is consistent with the family $(X_i,\mathcal{T}_i)_{i\in I}$ if the induced topology by $\mathcal{T}$ on $X_i$ is exactly $\mathcal{T}_i$ for every $i\in I$. Consistent topologies may or may not exist. And if they exist, there might be a unique consistent topology, or there might be more than one. It is easy to check the following facts: If consistent topologies exist, then the finest consistent topology is given by $$\mathcal{T}=\{U\subset X:\; U\cap X_i\in\mathcal{T}_i,\;\forall i\in I\}.$$ A necessary condition for the existence of consistent topologies is the pairwise compatibility of the topologies $(\mathcal{T}_i)_{i\in I}$, i.e., it must be the case that for every $i,j\in I$, the topology induced by $\mathcal{T}_i$ on $X_i\cap X_j$ must be the same as the topology induced by $\mathcal{T}_j$ on $X_i\cap X_j$. The above condition becomes sufficient if the spaces $(X_i)_{i\in I}$ are an increasing sequence, i.e., if $I=\mathbb{N}$ and $X_n\subset X_{n+1}$ for every $n\in\mathbb{N}$. Is the above necessary condition also sufficient in general for arbitrary collection of subspaces? if not, is there a known necessary and sufficient condition for the existence of consistent topologies? Is there a necessary and sufficient condition for the uniqueness of the consistent topology (in case such one exists)? Has this problem been studied? If yes, can someone refer me to a good reference?",['general-topology']
2229609,Sum of independent standard normal and chi square with one degree of freedom,"I need to calculate the distribution of the sum of two independent random variable: the first is a standard normal and the second is a chi square with one degree of freedom. I know that the sum has density given by the convolution between the respective densities, but i have trouble figuring out what this calculation leads to.
Can anyone help me?","['statistics', 'probability', 'convolution']"
2229618,"Is a Gaussian ""steepest"" at 1-sigma?","If I take the 2nd derivative of a Gaussian $e^{-\frac{x^2}{2\sigma^2}}$ and set it equal to $0$, the inflection point is $x=\pm \sigma$. Is $1$-$\sigma$ the point at which the Gaussian curve is ""steepest""?","['derivatives', 'calculus']"
2229659,Is every unitary matrix of the form $e^{A}$ where $A$ is skew-adjoint?,"If (and only if) $A$ is a skew-adjoint matrix, then $e^{A}$ is unitary.  Can this be reversed?  In other words, can every unitary matrix be written as a matrix exponential?","['matrices', 'operator-theory']"
2229691,Convergence in measure and bounded $L^p$ norm implies convergence in $L^p$,"Let $1<p<\infty$, and let $\mu$ be a finite measure. Prove that if a sequence $\{f_n\}_{n=1}^{\infty} \subset L^p(\mu)$ satisfies 1. $f_n \rightarrow f$ in measure and 2. $\sup_{n \in \mathbb{N}} \|f_n\|_p < +\infty$ where $\|f_n\|_p = (\int |f_n|^p \,\mathrm{d}\mu)^{\frac{1}{p}}$ is the $L^p$ norm. then $\int f_n \rightarrow \int f$ in $L^p(\mu)$. I know that convergence in measure implies that there exists a subsequence converges a.e.,but how does it relate to convergence in $L^p(\mu)$. Update: Thanks for @carmichael561, the conclusion of the question was incorrect. It should be the convergence of integration.","['real-analysis', 'lp-spaces', 'measure-theory']"
2229707,Contour Integration of $\sin(x)/x^{1/2}$,"Please help me with this contour integration: 
$$\int_0^\infty \frac{\sin(x)}{x^{1/2}}\,dx$$ My teacher says we can use ML bound, but I don't know how to do this. It cannot be a pole of order $1/2$, right?","['complex-analysis', 'contour-integration']"
2229735,Show that $\sum_{n=1}^\infty r^n\cos(n\theta)=\dfrac{r\cos\theta -r^2}{1-2r\cos\theta+r^2}$ whenever $0<r<1$.,"Note I have seen that this question has already been posted but I believe my concerns with the question have yet to be answered. Question: Write $z=re^{i\theta}$, where $0<r<1$, in the summation formula $$\sum_{n=0}^\infty z^n=\dfrac{1}{1-z}$$ whenever $|z|<1$. Then, with the aid of the following theorem, Suppose that $z_n=x_n+iy_n$ ($n=1,2,\dots$) and $S=X+iY$. Then
  $$\sum_{n=1}^\infty z_n=S \text{ if and only if }\sum_{n=1}^\infty x_n=X \text{ and } \sum_{n=1}^\infty y_n=Y$$ show that 
$$\sum_{n=1}^\infty r^n\cos(n\theta)=\dfrac{r\cos\theta -r^2}{1-2r\cos\theta+r^2} \text{ and } \sum_{n=1}^\infty r^n\sin(n\theta)=\dfrac{r\sin\theta}{1-2r\cos\theta+r^2}$$ whenever $0<r<1$. Proof: Let $z=re^{i\theta}$, where $0<r<1$. Recall $$\sum_{n=0}^\infty z^n=\dfrac{1}{1-z}$$ whenever $|z|<1$. Replace $z$ by $re^{i\theta}$ in the summation. $$\sum_{n=0}^\infty \left(re^{i\theta}\right)^n=\sum_{n=0}^\infty r^ne^{i\theta n}=\dfrac{1}{1-re^{i\theta}}$$ whenever $\left|re^{i\theta}\right|<1$. Replace $e^{i\theta}$ by $\cos\theta +i\sin\theta$. \begin{equation*}
\sum_{n=0}^\infty r^ne^{i\theta n} =\dfrac{1}{1-r\cos\theta-ir\sin\theta} =\dfrac{1-r\cos\theta+ir\sin\theta}{((1-r\cos\theta)-ir\sin\theta)((1-r\cos\theta)+ir\sin\theta)}=\dfrac{1-r\cos\theta+ir\sin\theta}{(1-r\cos\theta)^2+(r\sin\theta)^2}=\dfrac{1-r\cos\theta+ir\sin\theta}{1-2r\cos\theta+r^2\cos^2\theta+r^2\sin^2\theta}=\dfrac{1-r\cos\theta+ir\sin\theta}{1-2r\cos\theta+r^2}
\end{equation*} whenever $\left|re^{i\theta} \right|<1$. Replace $e^{i\theta n}$ by $\cos(n\theta)+i\sin(n\theta)$. 
$$\sum_{n=0}^\infty r^n(cos(\theta n)+i\sin(\theta n))=\dfrac{1-r\cos\theta}{1-2r\cos\theta+r^2}+i \cdot \dfrac{r\sin\theta}{1-2r\cos\theta+r^2}$$
whenever $\left|re^{i\theta}\right|<1$. By the theorem, we have the next two sums: $$\sum_{n=1}^\infty r^n\cos(n\theta)=\dfrac{1-r\cos\theta}{1-2r\cos\theta+r^2}$$ and $$\sum_{n=1}^\infty r^n\sin(n\theta)=\dfrac{r\sin\theta}{1-2r\cos\theta+r^2}$$ whenever $\left|re^{i\theta}\right|<1$. So my questions are: How can I get $1-r\cos\theta$ to become $r\cos\theta -r^2$? What do I do with the $n=0$ term of both sums?",['complex-analysis']
2229765,Integer solutions to $y^{2} = 2x^{2} +15x$.,"$x,y \in \mathbb{N}$ and $x,y \neq 0$. This equation popped up in my friend's homework and it's quite a doozy. He's only supposed to find two possible solutions but we had to boot up Mathematica to find any ($x = 60$ and $2160$). I was wondering if there was anything we were missing, because this doesn't seem approachable with any of the Diophantine solving techniques we found online (e.g. Pell's equation, etc.).","['number-theory', 'diophantine-equations']"
2229771,"If partial derivatives of $f$ is bounded, show that $f$ is continuous.","Let a function $f(x,y)$ be defined in an open set $D$ of the plane, and suppose that $f_1$ and $f_2$ are defined and bounded everywhere in $D$. Show that $f$ is continuous in $D$. The answer says ""Using the mean value theorem, show that $|f(p)-f(p_0)|\le M|p-p_0|$"" But in order to use the mean value theroem, shouldn't we assume f is a continuous function, which is the aim? How can we use it? Even if I use it, I couldn't quite get the statement answer is saying. Any help is welcomed. Thanks in advance.","['multivariable-calculus', 'continuity']"
2229786,Gauss prime divides exactly one integer prime in $\mathbb{Z}[i]$,"I am asked to show that a Gauss prime $\pi$ divides exactly one integer prime in $\mathbb{Z}[i]$. To show existence, I have tried to use the fact that the product $\pi \overline{\pi}$ is equal to either an integer prime $p$ or the square of integer prime $p^2$. If $\pi$ satisfies the first case, then the statement is immediate. How about when $\pi \overline{\pi}=p^2$? Also, how do we show that $\pi$ divides no other integer primes (i.e. uniqueness)?","['abstract-algebra', 'algebraic-number-theory']"
2229844,General form of a shear map,"From Wikipedia In plane geometry, a shear mapping is a linear map that displaces each point in fixed direction, by an amount proportional to its signed distance from a line that is parallel to that direction. I'm interested in the matrix representation of a general shear map in the plane.  Every resource I look at either only gives the horizontal and vertical shear matrices $$\begin{bmatrix} 1 & k \\ 0 & 1\end{bmatrix} \quad\text{and}\quad \begin{bmatrix} 1 & 0 \\ k & 1\end{bmatrix}$$ or a couple have said that $$\begin{bmatrix} 1 & a \\ b & 1\end{bmatrix}$$ is also a shear map.  However I don't think that last one is if neither $a$ nor $b$ is zero because, as far as I understand, shear mappings should be area preserving. So then what is the general form of the matrix representing a shear map that displaces all vectors in the direction parallel to an arbitrary vector $(x,y)$?","['matrices', 'linear-algebra', 'linear-transformations', 'geometry']"
2229845,What is the solution to the Dido isoperimetric problem when the length is longer than the half-circle?,"Given $L$-the length of a curve (single-valued function) passing trough the points $x_1$ and $x_2$ on the $x$-axis. What is the curve $y(x)$ maximizing the area between this curve and the $x$-axis? The solution is, of course, well known: one formulates a variational problem with a constraint $
F[y,y']=\int_{x_1}^{x_2}\left(y+\lambda\sqrt{1+y'^2(x)}\right)dx,
$ which yields an equation of circle $(x-x_0)^2+(y-y_0)^2=r^2$ as a solution. On the final step, one finds the unknown constants $x_0$, $y_0$, and $r$ by requesting that the circlular arc goes through the points $(x_1,0)$, $(x_2,0)$, and has the length $L$. The solution is clear to me for $0\le L\le \pi/2(x_2-x_1)$. But what if $L>\pi/2(x_2-x_1)$ ? To my opinion, there is a discrepancy between the length as computed via the integral and the length obtained by imposing the boundary conditions. This is illustrated in the second panel. What is the solution in this case?","['calculus-of-variations', 'geometry']"
2229847,Asymptotic quality of rational approximations to $\pi$,"Dalzell's integral
$$\int_0^1 \frac{x^4(1-x)^4}{1+x^2}dx=\frac{22}{7}-\pi$$ is case $n=2$ of the generalization $$\int_0^1 \frac{x^{n+2}(1-x)^{2n}}{2^{n-2}(1+x^2)}dx = \frac{p_n}{q_n}-\pi$$ Such an integral gives rational approximations to $\pi$ from above: $4$, $\dfrac{19}{6}$, $\dfrac{22}{7}$, $\dfrac{377}{120}$,... The qualities M of the latter three fractions are $2.057, 3.429, 1.98669,$ according to the definition $$\Bigg \|{\pi-\frac{p_n}{q_n}}\Bigg \|=\frac{1}{q^{M_n}}$$ How is the asymptotic quality of this approximation sequence $\displaystyle\lim_{n \to \infty} M_n$  computed?","['asymptotics', 'diophantine-approximation', 'number-theory', 'pi', 'approximation']"
2229944,"Calculate $\int_{-\infty}^{+\infty}\frac{x}{1+x^2}dx$, what is wrong with this?","Evaluate the integral
  $$\int_{-\infty}^{+\infty}\dfrac{x}{1+x^2}dx .$$ Intuitive approach As you see, it's an odd function,and we can say that value of the integral is $0$, because its symetric point is $0$ in opposite sign each other, and I think $0$ is mid point of $(-\infty,\infty)$. Solution (wrong) It's a improper integral and let's change its form: $$\displaystyle\int_{-\infty}^{+\infty}\dfrac{x}{1+x^2}dx=\displaystyle\int_{-a}^{+a}\dfrac{x}{1+x^2}dx=\lim_\limits{a\rightarrow \infty}\left[\dfrac{1}{2}\ln|x^2+1|\right]^{^{a}}_{_{-a}}=\lim\limits_{a\rightarrow \infty}\dfrac{1}{2}[0]=0$$ I've checked in Wolfram, but it says that this integral is not defined. Why can't we just calculate simply? There are no improper points, and it is a very simple function. What is the big deal? What I miss?","['improper-integrals', 'integration', 'calculus']"
2229950,"Closed form solution for the (easy at first glance) IVP $wu' =(2-w) u$, $ww'=u-w$","Consider the nonlinear autonomous 1st order IVP: \begin{align*}
u'(t) & = \frac{(2-w) u}{w}  \\ 
w'(t) & = \frac{u-w}{w}
\end{align*} $t > 0$, with $u(0)=w(0)=0$. We know that $t = 0$ is a singular point of the system and the asymptotic behaviors $u = 3w = 6t$ are valid for $t \ll 1$. Looking at the phase portrait, we see that the critical point $u = w = 2$ is a stable focus of the system. That allows me to say that for $t \to \infty$, $u$ and $w$ converges to the value $2$. I can support this numerically but trying to derive an analytical solution for all $t$ seems impossible. Both Matlab and Mathematica tell me that there does not exist such a solution to the system. I have tried a variety of change of variables, which led me to nowhere, and divide formally the equations to get: $$ \frac{\mathrm{d} u}{\mathrm{d} w}  = \frac{(2-w) u}{u-w}, \quad u(0) = 0$$ I am (and so is Mr. Mathematica) completely unable to solve this equation although it looks easier (at least to the untrained eye). My question is, Should I give up on solving this equation algebraically and embrace numerics? Is there any change of variables that would make my life easier? Any thoughts are deeply appreciated.","['ordinary-differential-equations', 'dynamical-systems', 'closed-form']"
2229955,Problem with calculation this integral: $\int_0^\pi \frac{dx}{1+3\sin^2x}$,"Question Calculate this integral: $$\displaystyle\int_0^\pi \frac{dx}{1+3\sin^2x}$$ Solution $$I=\displaystyle\int \frac{dx}{1+3\sin^2x}=\displaystyle\int \frac{dx}{\cos^2x+4\sin^2x}=\displaystyle\int \frac{\sec^2x\;dx}{1+4\tan^2x}$$ Let's apply substitution $u=2\tan x$, so $du=2\sec^2x\;dx$  $$I=\dfrac12\displaystyle\int \frac{du}{1+u^2}=\frac12\arctan(u)+c=\frac12\arctan(2\tan x)+c$$ In this case; $$\displaystyle\int_0^\pi \frac{dx}{1+3\sin^2x}=\left[\frac12\arctan(2\tan x)\right]_{x=0}^{x=\pi}=0$$. But we know that: $$\frac{1}{1+3\sin^2 x} \ge \frac14$$ Therefore; $$\displaystyle\int_0^\pi \frac{dx}{1+3\sin^2x} \ge \displaystyle\int_0^\pi \frac{dx}{4}=\frac{\pi}4$$ On the other hand; $$0 \ge \frac{\pi}4$$ which is not true. 1) Where is the problem? (Why?)
2) How we can correct this mistake by applying the same substitution?",['integration']
2229960,"Given two fields, constructing a field containing both","In the text by Dummit and Foote, the authors introduce the idea of an algebraic closure, and also prove that one always exists for every field $F$.  They then comment that we can ""...speak sensibly of the composite of any collection of algebraic extensions by viewing them as subfields of an algebraic closure."" But I'm a bit confused by this.  Suppose we have two fields $K_1$ and $K_2$.  Then we have the two algebraic closures $\overline{K_1}$ and $\overline{K_2}$, but it doesn't necessarily follow that either one of these algebraic closures contains both $K_1$ and $K_2$... So I have two questions: How do we construct the big field that contains both $K_1$ and $K_2$? The quoted comment said that $K_1$ and $K_2$ must be algebraic extensions...why is this?","['abstract-algebra', 'field-theory']"
2230000,Size of a convergent series restricted to primes,"Let $(a_n)_{n=1}^\infty$ be a decreasing sequence of positive real numbers such that $\sum_{n=1}^\infty a_n$ converges. I am interested in the sum $\sum_{p}a_p$, where $p$ ranges over the primes. This subsum obviously converges, but I am interested in how quickly it converges. More precisely, I would like to know what I can say about the asymptotic size of $R(x):=\sum_{p\geq x}a_p$. Because $\sum_{n\geq x}a_n=o(1)$, it seems as though we should have $R(x)=o\left(\frac{1}{\log x}\right)$. In fact, I would like to be able to prove that $$\sum_{m=1}^\infty \frac{R(m)}{m}$$ converges. I am not sure if this is true, though. Any help would be greatly appreciated.","['analytic-number-theory', 'prime-numbers', 'sequences-and-series', 'convergence-divergence']"
2230008,Is the integral squared equal to two times the integral from $a$ to $b$ and from $x$ to $b$?,"I have to prove that 
$$2\int_a^b\int_x^bf(x)f(y)\,dx\,dy = \left(\int_a^bf(x)\,dx\right)^2  $$
where $f$ is continuous in $[a,b].$
I tried to separate the integrals in a way that I get that \begin{align*}
\left(\int_a^bf(x)\,dx\right)^2 &= \left(\int_a^bf(x)\,dx\right) \left(\int_a^bf(y)\,dy\right)\\
&= \left(\int_a^bf(x)\,dx\right)\left(\int_a^xf(y)\,dy+\int_x^bf(y)\,dy\right).
\end{align*} But I don't understand how am I supposed to prove that
$$\int_a^xf(y)\,dy=\int_x^bf(y)\,dy$$
becuase that expression depends on the $x$ that I take.  It seems that I need a certain symmetry in the function to accomplish something similar, where I can take another $x_{o}$ in $[a,b]$ and show that
$$\int_a^{x_{o}}f(y)\,dy=\int_{x_{o}}^bf(y)\,dy.$$
There something that I am not seeing, any hint or idea would be helpful.","['multivariable-calculus', 'calculus']"
2230084,polynomial in entire function with polynomial coefficients,"Let $f$ be an entire function. Assume that there are polynomials $p_0, \ldots , p_n(z)$, not all zero, such that $p_n(z)(f(z))^n + p_{n−1}(z)(f(z))^{n−1} + \cdots + p_0(z) = 0$. Prove that f is a polynomial.","['complex-analysis', 'polynomials', 'entire-functions']"
2230151,Characterization of (Lebesgue) measurable sets [duplicate],"This question already has an answer here : Proving Caratheodory measurability if and only if the measure of a set summed with the measure of its complement is the measure of the whole space. (1 answer) Closed 7 years ago . I am stuck trying to show a characterization of (Lebesgue) measurable sets from Caratheodory's definition of measurable. This means we do not have the notion of an inner measure, as it is not required to define measure via Caretheodory's criterion. Show that a bounded subset $E\subset \mathbb{R}$ is (Lebesgue) measurable if there is some bounded interval $I\supset E$ such that
$$\lambda^*(I)=\lambda^*(E)+\lambda^*(I\setminus E)$$ I am trying to prove that $E$ is measurable by showing that if such an $I$ exists, then for any interval $J$ $$\lambda^*(J)=\lambda^*(J\cap E)+\lambda^*(J\setminus E)$$ I am trying to prove this when $J\subset I$ (it is clearly true when $J\cap E=\emptyset$, and then the result will follow). So I require $$\lambda^*(J)\ge\lambda^*(J\cap E)+\lambda^*(J\setminus E)$$ for $J\subset I$. Manipulating the set relations doesn't seem to get me anywhere.","['outer-measure', 'lebesgue-measure', 'measure-theory']"
2230166,Find all continuous functions such that $f(x)f(2x)\dots f(nx) \le an^k$,"Find all continuous functions $f : \mathbb{R} \rightarrow [1,\infty)$ for which there exist $a \in \mathbb{R}$ and $k$ a positive integer such that 
$$f(x)f(2x)\dots f(nx) ≤ an^k,$$ for every real number $x$ and positive integer $n$. EDIT: A trivial solution I could find was the constant function equal to one.","['real-analysis', 'functional-inequalities', 'functional-equations']"
2230214,"$\{a_n\} \subseteq \mathbb C$ discrete set with no limit point . For any sequence $\{z_n\} $ , there is entire $f $ on $\mathbb C$ with $f(a_n)=z_n$?","Let $\{a_n\} \subseteq \mathbb C$ be a discrete set with no limit point . Then for every sequence $\{z_n\}$ of complex numbers , can we find an entire function $f:\mathbb C \to \mathbb C$ such that $f(a_n)=z_n , \forall n \in \mathbb N$ ? I feel I have to use Weierstrass factorization or Mittag-Leffler , but I can't quite crack it . Please help . Thanks in advance","['complex-analysis', 'weierstrass-factorization', 'holomorphic-functions', 'entire-functions']"
2230226,Show that there are infinitely many powers of two starting with the digit 7 [duplicate],This question already has answers here : Starting digits of $2^n$. (1 answer) Is $2^k = 2013...$ for some $k$? [duplicate] (1 answer) Closed 7 years ago . This is a contest math problem which I was not able to solve. A hint toward the solution would be helpful as well. Problem: Show that there are infinitely many powers of 2 starting with the digit 7. Thanks in advance.,"['decimal-expansion', 'abstract-algebra', 'number-theory', 'contest-math', 'elementary-number-theory']"
2230232,Applications of valuation rings,"Some background: I am in the process of writing a research paper for an undergraduate abstract algebra course. I've chosen to write my paper on valuation rings and discrete valuation rings. The goal of the paper is to broaden my own and my classmates' understanding of abstract algebra by independently researching a topic not covered in the course. So far, my paper consists of surveying the properties of valuation rings and giving examples of valuation rings. What I would like to know: I would like to be able to comment on how valuation rings are utilized in various fields of mathematics. Thus far I've had a hard time finding examples that are both explicit and accessible to me, as all of the literature I've found on valuation rings have been graduate texts. It seems like valuation rings are often used in number theory and algebraic geometry, but how are they applied in those fields? What other fields find valuation rings of significant usefulness, and how are they applied? I would also find so-called real world applications useful for my understanding of the topic, but personally I'm more interested in how mathematicians make use of them. Assume I know linear and abstract algebra at an undergraduate level. Do not assume I know very much about geometry, number theory, or analysis. I'm currently taking a differential geometry course, but what I'm learning seems entirely separate from anything I've seen relating valuation rings to geometry. My apologies for the broad question. Please let me know if I can clarify or specify in any way.","['abstract-algebra', 'ring-theory', 'commutative-algebra', 'valuation-theory', 'applications']"
2230247,What is the linear algebra of the Schur complement?,"I am interested in the combinatorics of electrical networks, and this leads naturally into the notion of the Schur complement: Suppose we have a graph (possibly edge-weighted with 'resistances') with ""boundary"" and ""interior"" vertices— the idea is that we get to have control over the voltages on the boundary, but not on the interior. The graph, being a graph, has a Laplacian matrix $L=D-A$ . It turns out that the Schur complement of the Laplacian with respect to the internal vertices (thus, a square matrix of side length the number of boundary vertices) has electrical significance. Namely, this is the so-called ""response matrix"" which takes in a vector of voltages and spits out the corresponding vector of current: how much electricity will flow through the boundary vertices. Regardless of application: I don't like matrices. I like linear maps (and I'm fine with bases). Is there any way for someone like me to think about the Schur complement without going all the way down to matrix-land?","['matrices', 'linear-algebra', 'schur-complement']"
2230255,supremum of expectation $\le$ expectation of supremum?,"Suppose that $X$ is an arbitrary random variable, is the following is true for any function $f$: 
$$\underset{y\in \mathcal Y} \sup \mathbb E\big[f(X,y)\big] \le \mathbb E\big[\underset{y\in \mathcal Y} \sup f(X,y)\big]?$$ If $f$ is convex in $X$, then the inequality clearly holds, since the supremum of a family of convex functions is still convex.  If $f$ is not convex in $X$, I think the inequality still holds for the following reason: For any realization of $X$ and any value of $y$, we have $f(X,y) \le \underset{y\in \mathcal Y} \sup f(X,y)$.  Therefore, for any $y$, $\mathbb E\big[f(X,y)\big] \le \mathbb E\big[\underset{y\in \mathcal Y} \sup f(X,y)\big]$.  In other words, $\mathbb E\big[\underset{y\in \mathcal Y} \sup f(X,y)\big]$ is an upper bound of the set $\left\{\mathbb E\big[f(X,y)\big]: y\in \mathcal Y\right\}$, so it follows that $\underset{y\in \mathcal Y} \sup \mathbb E\big[f(X,y)\big] \le \mathbb E\big[\underset{y\in \mathcal Y} \sup f(X,y)\big]$. So it appears that convexity of $f$is not needed at all for the inequality to hold. Am I mistaken somewhere?  I'd appreciate it if someone would correct me, if I missed something.  Thanks a lot!","['expectation', 'convex-analysis', 'proof-verification', 'supremum-and-infimum', 'probability']"
2230301,Interchanging Derivative and Integral Example,"In class the other day, my professor stated the following theorem: Suppose $\frac{d}{dy}f(x,y)$ is continuous on $[0,1] \times [0,1]$, then $\frac{d}{dy} \int^1_0 f(x,y) \, dx = \int_0^1 \frac{d}{dy}f(x,y) \, dx$. He then quickly corrected this to read: Suppose $\frac{d}{dy}f(x,y)$ and f are continuous on $[0,1] \times [0,1]$, then $$\frac{d}{dy} \int^1_0 f(x,y) \, dx = \int_0^1 \frac{d}{dy}f(x,y) \, dx.$$ I was wondering if anyone could provide an example of $f$ which satisfies the conditions for the first statement written but not the subsequently added continuity condition from the second statement, and therefore fails the overall implication of the first statement.",['multivariable-calculus']
2230311,Are quaternions useful as coordinate systems for two-dimensional manifolds?,"I am learning how quaternions work. For that reason I have prepared a coordinate system based on quaternions applied to two-dimensional topological manifolds of the shape of a Klein bottle (it can be adapted easily to others like a Möbius strip, or a torus for instance). Basically we can represent the Klein bottle by its gluing diagram : And we will add extra information to the points that ""inhabit"" the surface of the manifold. A point of the surface will be represented by a quaternion as follows: $$a+bi+cj+dk$$ Where: $a$ represents the side. Any point of the surface of the bottle has an equivalent point in the internal side, so $a = 0,1$ ( $0$ outer side, $1$ inner side). A point can be in some of the both inner or outer sides. $i$ represents the horizontal position $x$ in the gluing diagram ( $i \in [0,I]$ where $I$ is the length of the Klein bottle diagram) $j$ represents the vertical position $y$ in the gluing diagram ( $i \in [0,J]$ where $J$ is the height of the Klein bottle diagram) Finally, $k$ will be an extra property of the point, in my case I named it the ""spin"", it has $4$ positions, ( $k \in [0,3]$ ). I could be seen as a kind of local orientation associated to the gluing diagram (North,South,East,West). This provides a coordinate system with sum and multiplication. As we are using quaternions, the standard rules of quaternions are applied: $$i^2=j^2=k^2=ijk=-1$$ Addition, scalar multiplication and quaternion multiplication are available and the quaternion multiplication rotation laws hold: $$ij=k, ji=-k, jk=i, kj=-i, ki=j, ik=-j$$ The Hamilton product is defined as the standard one: $$(a_1+b_1i+c_1j+d_1k)\cdot(a_2+b_2i+c_2j+d_2k) = (a1a2-b1b2-c1c2-d1d2)+(a1b2+b1a2+c1d2-d1c2)i+(a1c2-b1d2+c1a2+d1b2)j+(a1d2+b1c2-c1b2+d1a2)k$$ To visualize how the points move along the Klein bottle, let us define a collision game. We put randomly $7000$ points in a Klein Bottle, visualized as seen in the gluing diagram. The yellow points are in the outer side and blue points in the inner side. The points are represented depending on the spin ( $k$ ) as little points, circles, stars and ""plus"" (+) symbols ( $k=0,1,2,3$ respectively). They are moving following random walks. Collision rules: When two points $P_1,P_2$ of located in the same side and with the same spin collide (they have exactly the same values $a,i,j,k$ ), they disappear and generate a new point $P_1+P_2$ (quaternion sum). When two points $P_1,P_2$ of the different side are in the same position and spin collide  (they have exactly the same values $i,j,k$ ), they disappear and generate a new point $P_1 \cdot P_2$ (quaternion Hamilton product). This is how it looks like when the width and height of the diagram is $100$ units and we put $7000$ points on the surface of the manifold: And this is the animation of the evolution of the first $500$ steps of a test: (*) I cannot add a bigger version of the animation due to the weight of the image, a bigger version can be seen here . The Python code is also available, please use it and modify it freely. Due to the properties of the Klein bottle: When a point goes out from the right side, is going to the other side of the Klein bottle, so it will appear from the left side of the diagram with the opposite side color and the $j$ position is inverted. When a point goes out from the left side, is going to the other side of the Klein bottle, so it will appear from the right side of the diagram with the opposite side color and the $j$ position is inverted. When a point goes out from the top or bottom, it keeps in the same current side (inner or outer), so it will appear at the opposite region of the current side (Top $\to$ Bottom, or Bottom $\to$ Top). As time evolves, collisions happen and the number of points decreases. I would like to ask the following questions: Are the properties of quaternions good for this kind of coordinate systems? Are there documented references of this kind of application? (quaternions applied as coordinate systems to topological manifolds). Any insights are very appreciated.","['coordinate-systems', 'reference-request', 'quaternions', 'visualization', 'general-topology']"
2230316,Ellipse tangent to two circles,"We're given two circles with radii $p$ and $q$, one centered at the origin, and one centered at the point $(w,0)$. I want to construct an ellipse of the form
$$
\frac{(x-c)^2}{a^2} + \frac{y^2}{b^2} = 1
$$
that is tangent to the two circles, as shown here: If $b$ is known, can we obtain closed form expressions for $a$ and $c$ as functions of $p$, $q$, $w$ and $b$.","['analytic-geometry', 'conic-sections', 'geometry']"
2230329,bounding the second largest eigenvalue of a regular graph,"I read that the second largest eigenvalue of a graph is always positive except for 
specific classes of graphs, i.e the graphs that have second largest eigenvalue smaller than zero are fully characterized. I was not able to figure out this question completely by browsing the web and looking at papers I found. Any reference or full answer would be of great help.","['reference-request', 'graph-theory', 'spectral-graph-theory', 'linear-algebra']"
2230354,Binomial limit $\left(\binom{3n}{n}\binom{2n}{n}^{-1}\right)^{1/n}$ as $n\to \infty$,"The limit:$$\lim_{n\to \infty}\left(\dfrac{\binom{3n}{n}}{\binom{2n}{n}}\right)^\frac{1}{n}$$ What I did was put limit = $L$. Then, $$\begin{align}\log(L)&={\lim_{n \to \infty}}\dfrac{1}{n}\cdot\sum_{r=0}^{{n-1}} \log\left(\dfrac{3-\frac{r}{n}}{2-\frac{r}{n}}\right)\\
&=\int_0^1 \log\left(\dfrac{3-x}{2-x}\right)dx\\
&=\log\left(\dfrac{27}{16}\right)
\end{align}$$ Is this aproach correct? Is there other method. Edit: I have corrected the expression for the limit.","['binomial-coefficients', 'limits']"
2230356,Alternative method to solve $x''+x=0$,"The question is how to solve the equation $x''+x=0$, using the hint to consider $v=dx/dt$ and then to use the chain rule to get $x'' = v\cdot dv/dx$. My thoughts: This is an equation where the independent variable t does not appear explicitly. Following the hint and substituting in the main equation I got,
$$v^2 = - (x^2) +C$$
Now how do I solve this equation to get $x= c_1 \sin t + c_2 \cos t$, which I already know, from the more widely used method, is the answer?",['ordinary-differential-equations']
2230375,Help to use change of variables to solve the double integral,"I'm trying to evaluate: $$\iint_D \left(\sqrt{a^2-x^2-y^2}-\sqrt{x^2+y^2}~\right)dxdy$$ where $D_{xy}$ is the disk $x^2+y^2\le a^2$. The exercise is to use change of variables to solve this integral. My solution I chose $\varphi (r,\theta)=(ra\cos\theta,ra\sin\theta)$, where $0\le r\le 1$ and $0\le \theta\le 2\pi$ to be the change of variables. The determinant of the Jacobian is $ra^2$ and 
\begin{align*}
&\iint_{D_{xy}}\left(\sqrt{a^2-x^2-y^2}-\sqrt{x^2+y^2}~\right)dxdy \\&=\int_0^{2\pi}\int^1_0\left(\sqrt{a^2-r^2a^2}-ra\right)ra^2 drd\theta\\
&=2\pi a^3\int^1_0 \left(r\sqrt{1-r^2}-r^2 \right)dr\\
&=2\pi a^3\left(\int^1_0r\sqrt{1-r^2}dr-\int^1_0r^2dr\right)\\
&=2\pi a^3\left( \frac{1}{3}-\frac{1}{3} \right)\\
&=0
\end{align*} I would like to know where I'm mistaken. The answer in the end of the book shows $\pi a^3/3$.",['multivariable-calculus']
2230381,Example when equality holds in Bessel Inequality,"Example of $x\in l^2$ such that $\sum_{k=1}^{\infty}|\langle x,e_k\rangle|^2\leq \|x\|^2$ has strict inequality where $(e_k)$ is an orthonormal sequence in $l^2$ . My thinking: I think it's not possible
As $\|x\|\ _{2}=\left(\sum_{k=1}^{\infty}|x_k|^2\right)^{1/2}$ and so by Bessel inequality we have $$
\sum_{k=1}^{\infty}|\langle x,e_k\rangle|^2\leq \left(\left(\sum_{k=1}^{\infty}|x_k|^2\right)^{1/2}\right)^2
$$ $$
\sum_{k=1}^{\infty}|\langle x,e_k\rangle|^2\leq \left(\sum_{k=1}^{\infty}|x_k|^2\right)$$ But aren't both the things same, I mean there should be an equality Kreyzig: Introduction to Functional Analysis, Ch-3, 3.4 Ques 4",['functional-analysis']
2230430,Probability of selecting an even natural number from the set $\Bbb N$.,"I confirmed on this thread that there are as many as even natural numbers as there are natural numbers. Question : Suppose I have selected a number $n \in \mathbb N$ ; what is the probability that $n$ is even? My Thought : $\text{Probability} = \dfrac{\text{n(E)}}{\text{n(S)}}$ Here $\text{n(S)}$ is the set of all natural numbers i.e. $\mathbb N$ , and $\text{n(E)}$ is set of all even natural numbers. Since it is proved that number of elements is the set $\mathbb N$ is exactly the same as the number of elements in the set of natural numbers (it’s very easy to put the set of natural numbers, $\Bbb N=\{0,1,2,3,\dots\}$ , into one-to-one correspondence with the set $\text{E}=\{0,2,4,6,\dots\}$ of even natural numbers; the map $\Bbb N\to \text{E}:n\mapsto 2n$ is clearly a bijection.) ; Thus, Probability $= \boxed 1$ I know this is definitely wrong.Probability must be $0.5$ . But where am I wrong? Can anyone explain ? Thanks!","['infinite-groups', 'probability', 'infinity']"
2230450,How many elements are in $\mathbb{Z}[i]/2\langle a+bi \rangle$?,"Consider the quotient ring $\mathbb{Z}[i]/2\langle a + bi \rangle$. Then this ring is isomorphic to $\mathbb{Z}[x]/\langle x^2 + 1, 2(a + bx) \rangle$. Then $x = i$ and $x = -\frac{a}{b}$, such that $-\frac{a}{b} \in \mathbb{Z}$. Am I getting this right? But how do I proceed from here? I've read some posts on similar problems, but I don't know/see something peculiar, which is omitted in all of those posts I've seen. I'd really appreciate if someone could explain the real mechanics behind this kind of determination.","['abstract-algebra', 'ring-theory', 'algebraic-number-theory']"
2230501,explanation of a triple integral $\iiint _{x^2+y^2+z^2<R^2}\left|xz\right|y^2dxdydz\:$,"I'm trying to figure out how the my book solve this exercise: $$\iiint _{x^2+y^2+z^2<R^2}\left|xz\right|y^2dxdydz\:$$ BOOK SOLUTION: $$\iiint _{x^2+y^2+z^2<R^2}\left|xz\right|y^2dxdydz\: = 8\iiint _Sxzy^2dxdydz\:$$
with:
$$S=\{(x,y,z):x^2+y^2+z^2<R^2, x\ge0, y\ge0, z\ge0\}$$
We transform in spherical coordinates:
$$S=\{(\rho,\phi,\theta): \rho \in [0,R], \phi\in[0,\frac{\pi}{2}], \theta \in [0,\frac{\pi}{2}]\}, dxdydz=\rho^2\sin\phi d\phi d\theta d\rho$$
then, the exercise continues with the triple integral solution after the transformation (which is not difficult). MY DOUBT i will report below, what I am not clear (outlined in red) $$\iiint _{x^2+y^2+z^2<R^2}\left|xz\right|y^2dxdydz\: = \color{red}{8\iiint_Cxzy^2dxdydz\:}$$
I just can not understand how these two integrals can be equal. Then:
$$S=\{(\rho,\phi,\theta): \rho \in [0,R], \color{red}{\phi\in[0,\frac{\pi}{2}]}, \color{red}{\theta \in [0,\frac{\pi}{2}]}\}, dxdydz=\rho^2\sin\phi d\phi d\theta d\rho$$
why in that range?
Thanks","['multivariable-calculus', 'real-analysis', 'integration']"
2230507,Matlab code to compute the smallest nonzero singular value of the matrix without using SVD,"I want to compute the smallest nonzero singular value of the matrix A, which is defined as follows. Let $B =  rand(500, 250)$, $A = B*B^t$, where $t$ denotes the transpose of the matrix. I found the following matlab code to compute singular values of the matrix A which is based on the Singular value decomposition of the matrix. svds = svd(A);                             
s = min(svds);  % smallest singular value I want to know is there any other efficient way to smallest singular value? Thank you in advance","['numerical-linear-algebra', 'matrices', 'matlab', 'singular-values', 'linear-algebra']"
2230508,Decay of Fourier transform of function composition,"Given a function $f$ and an invertible matrix $A$, we have the following relation for the Fourier transforms:
$$
  \widehat{f \circ A}(\xi) = |\det A|^{-1} \widehat f(A^{-T}\xi).
$$
In particular, $\widehat f(\xi) = O(|\xi|^{-\alpha})$ at infinity if and only if $\widehat{f \circ A}(\xi) = O(|\xi|^{-\alpha})$. Now, given a $C^\infty$-diffeomorphism $g$ which differs from identity only on some compact set $K$ we can only write (see this answer )
$$
   \widehat{f \circ g}(\xi) = \int f(y)|\det g'(y)|^{-1}\exp(ig^{-1}(y)\xi) dy.
$$
Is it still possible to say that $\widehat f(\xi) = O(|\xi|^{-\alpha})$ at infinity if and only if $\widehat{f \circ g}(\xi) = O(|\xi|^{-\alpha})$?","['real-analysis', 'asymptotics', 'fourier-analysis', 'calculus']"
