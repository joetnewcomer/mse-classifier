question_id,title,body,tags
3824568,What is the reason that $\int_{-\infty}^{\infty}f(x) \Bbb dx$ may not be the same as $\lim_{b \to \infty} \int_{-b}^{b}f(x) \Bbb dx$?,"Given question: Calculus by Thomas, Chp 8, pg 501, No. 66: $\int_{-\infty}^{\infty}f(x) \Bbb dx$ may not equal $\lim_{b \to \infty} \int_{-b}^{b}f(x) \Bbb dx$ Show that $$\int_{0}^{\infty} \frac{2x\Bbb dx}{x^2 + 1}$$ diverges and hence
that $$\int_{-\infty}^{\infty} \frac{2x\Bbb dx}{x^2 + 1}$$ diverges.
Then show that $$\lim_{b\to \infty} \int_{-b}^{b} \frac{2x\Bbb dx}{x^2
 + 1} = 0$$ My attempt: $$\begin{align} \int_{0}^{\infty} \frac{2x\Bbb dx}{x^2 + 1} &=
 \ln\left(x^2+1\right)\Bigg|_0^{\infty}\\ &= \ln(\infty)-\ln(1)\\ &=
 \infty \quad \text{(Diverges)} \end{align}$$ Since $\int_{0}^{\infty} \frac{2x\Bbb dx}{x^2 + 1}$ diverges, then $\int_{-\infty}^{\infty} \frac{2x\Bbb dx}{x^2 + 1}$ also diverges. Regarding to the second question: $$\begin{align} \lim_{b\to \infty} \int_{-b}^{b} \frac{2x\Bbb dx}{x^2
 + 1} &= \lim_{b\to \infty} \ln\left(x^2+1\right)\Bigg|_{-b}^{b}\\ &=  \lim_{b\to \infty} \ln\left(b^2+1\right) - \lim_{b\to \infty}
 \ln\left(b^2+1\right)\\ &= 0\quad \text{(Converges)} \end{align}$$ Here i feel confused. Does that mean $f(x) = \frac{2x}{x^2
 + 1}$ is a counterexample of $\int_{-\infty}^{\infty}f(x) \Bbb dx = \lim_{b \to \infty} \int_{-b}^{b}f(x) \Bbb dx$ or what? And does it converge? Please explain to me. Thanks!","['integration', 'improper-integrals', 'calculus', 'definite-integrals']"
3824569,Integrability of a periodic function based on $\int_0^1 |f(a+t)-f(b+t)| dt$,"Proposition: Let $f$ be a measurable function with period $1$ on the real line such $\int_0^1 |f(a+t)-f(b+t)| dt$ is bounded uniformly for all $a, b \in \mathbb{R}$ . Show that $f$ is integrable on $[0, 1]$ . [Hint: Use $a = x$ , $b = −x$ , integrate with respect to $x$ , and change variables to $ξ=x+t$ , $η=−x+t$ .] First of all what does it is bounded uniformly for all $a, b \in \mathbb{R}$ ? Does it mean that for all $a, b \in \mathbb{R}$ , $\int_0^1 |f(a+t)-f(b+t)| dt \le M$ for a single $M$ ? And how does it help to solve the exercise? How the hint is useful when nothing cancels out to reach $\int_0^1 |f(t)| dt$ with the use of the hint?","['integration', 'measure-theory', 'real-analysis']"
3824575,Non-trivial zero(s) of Akiyama-Tanigawa triangle,"Introduced in 1997, the Akiyama-Tanigawa triangle is a doubly-indexed recursion that encodes the Bernoulli numbers, among other sequences. It is defined as follows: let $a:\mathbb{N^0}\times\mathbb{N^+}\to \mathbb{R}$ (this indexing is to agree with that of the Bernoulli numbers) be given by: $$
a_{0,j}=\frac{1}{j}\qquad a_{i,j} = j(a_{i-1,j}-a_{i-1,j+1})
$$ Here is a table for $1\le i+1,j\le10$ : $$
\begin{array}{c|cccccccccc}
  & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 \\
\hline 0 & 1 & \frac{1}{2} & \frac{1}{3} & \frac{1}{4} & \frac{1}{5} & \frac{1}{6} & \frac{1}{7} &
   \frac{1}{8} & \frac{1}{9} & \frac{1}{10} \\
 1 & \frac{1}{2} & \frac{1}{3} & \frac{1}{4} & \frac{1}{5} & \frac{1}{6} & \frac{1}{7} &
   \frac{1}{8} & \frac{1}{9} & \frac{1}{10} & \frac{1}{11} \\
 2 & \frac{1}{6} & \frac{1}{6} & \frac{3}{20} & \frac{2}{15} & \frac{5}{42} & \frac{3}{28} &
   \frac{7}{72} & \frac{4}{45} & \frac{9}{110} & \frac{5}{66} \\
 3 & 0 & \frac{1}{30} & \frac{1}{20} & \frac{2}{35} & \frac{5}{84} & \frac{5}{84} &
   \frac{7}{120} & \frac{28}{495} & \frac{3}{55} & \frac{15}{286} \\
 4 & -\frac{1}{30} & -\frac{1}{30} & -\frac{3}{140} & -\frac{1}{105} & \color{red}{0} & \frac{1}{140} &
   \frac{49}{3960} & \frac{8}{495} & \frac{27}{1430} & \frac{125}{6006} \\
 5 & 0 & -\frac{1}{42} & -\frac{1}{28} & -\frac{4}{105} & -\frac{1}{28} & -\frac{29}{924} &
   -\frac{7}{264} & -\frac{28}{1287} & -\frac{87}{5005} & -\frac{27}{2002} \\
 6 & \frac{1}{42} & \frac{1}{42} & \frac{1}{140} & -\frac{1}{105} & -\frac{5}{231} &
   -\frac{9}{308} & -\frac{343}{10296} & -\frac{1576}{45045} & -\frac{27}{770} &
   -\frac{205}{6006} \\
 7 & 0 & \frac{1}{30} & \frac{1}{20} & \frac{8}{165} & \frac{5}{132} & \frac{295}{12012} &
   \frac{67}{5720} & \frac{4}{6435} & -\frac{6}{715} & -\frac{75}{4862} \\
 8 & -\frac{1}{30} & -\frac{1}{30} & \frac{1}{220} & \frac{7}{165} & \frac{200}{3003} &
   \frac{1543}{20020} & \frac{3997}{51480} & \frac{464}{6435} & \frac{1539}{24310} &
   \frac{775}{14586} \\
 9 & 0 & -\frac{5}{66} & -\frac{5}{44} & -\frac{44}{455} & -\frac{629}{12012} &
   -\frac{41}{12012} & \frac{133}{3432} & \frac{140}{1989} & \frac{1113}{12155} &
   \frac{9597}{92378} \\
\end{array}
$$ As claimed (I could provide a proof, if there's interest, but it's not relevant to my question), $a_{i,1}=B_i$ , the $i^{th}$ Bernoulli number, with $B_1=1/2$ . As such, $a_{2i+1,1}=0$ for $i>1$ ; call these trivial zeros. Note $a_{4,5}=0$ as well: my conjecture is that this is the only such non-trivial zero. I have verified this claim for $a_{i,j}$ for $1\le i+1,j\le 100$ . I also believe that for fixed $j$ , $a_{n,j}>0$ for some $n=n(j)$ . Additionally, for several fixed $j$ there is a closed-form by using the recursion. However, I'm not sure which of any of these lines is a feasible plan-of-attack, or if miraculously a closed-form for $a_{i,j}$ exists.","['bernoulli-numbers', 'recurrence-relations', 'discrete-mathematics', 'sequences-and-series']"
3824594,Can we prove that $\operatorname{Tr}(ABC) = \operatorname{Tr}(CBA)$?,"I would like to verify the claim: $$\operatorname{Tr}(ABC) = \operatorname{Tr}(CBA)$$ I tried verifying through an example: Given the following $3$ different matrices: \begin{align}
A & = \begin{pmatrix}
1 & 2 & 3 & 4 \\
5 & 6 & 7 & 8 \\
9 & 10 & 11 & 12 \\
13 & 14 & 15 & 16
\end{pmatrix}\\[2ex]
B & = \begin{pmatrix}
4 & 3 & 2 & 1 \\
3 & 6 & 4 & 2 \\
2 & 4 & 6 & 3 \\
1 & 2 & 3 & 4
\end{pmatrix}\\[2ex]
C & = \begin{pmatrix}
4 & 3 & 2 & 1 \\
5 & 6 & 7 & 8 \\
8 & 7 & 6 & 5 \\
4 & 3 & 2 & 1
\end{pmatrix}
\end{align} I calculated $\operatorname{Tr}(ABC) = 7930$ and $\operatorname{Tr}(CBA) = 7510$ . Is there any thing wrong in my calculation, or does this prove that $\operatorname{Tr}(ABC) \neq \operatorname{Tr}(CBA)$ ? Many thanks!","['matrices', 'trace', 'linear-algebra']"
3824611,How to show that there exist no four circles as in the picture?,These are distinct (their radii might differ or not) semicircles on the $x-axis$ as depicted below. I want to show that there exist no such four Euclidean semicircles such that the intersections occurs at a right angle as in the figure. How can show that algebraically?,"['euclidean-geometry', 'geometry']"
3824695,Number of integers that do not show up,"An integer is repeatedly drawn at random from $1, 2, . . . , 10$ . What are the expected value and the standard deviation of the number of integers from $1, 2, . . . , 10$ that do not show up in $20$ drawings? Let $X_i$ be the random variable that assumes value $1$ if the number $i$ doesn't show up in $20$ drawings and $0$ otherwise. So $\mathbb{P}(X_i=1)=(\frac{9}{10})^{20}$ . Since $\mathbb{E}[X_i]=0\cdot (\frac{1}{10})^{20}+1\cdot (\frac{9}{10})^{20}=(\frac{9}{10})^{20}$ , I know that: $\mathbb{E}[X]=\mathbb{E}[X_1]+...+\mathbb{E}[X_{10}]=(\frac{9}{10})^{20}+...+(\frac{9}{10})^{20}=10\cdot (\frac{9}{10})^{20}=1,216$ $\operatorname{Var}[X]=\mathbb{E}[X^2]-\mathbb{E}[X]^2=\space{?}-(1,216)^2$ How do I find $\mathbb{E}[X^2]$ ? EDIT:",['probability']
3824706,Perform a Natural Deduction with No Logical Equivalencies,"Prove: $$\frac{(a \land b) \rightarrow (b \leftrightarrow c)}{\therefore a \rightarrow(b \rightarrow c)}$$ My conclusion: $1.\space(a \land b) \rightarrow (b \leftrightarrow c) \qquad Premise.$ $\boxed{ 2. \space a \qquad \qquad Assumption. \\ \boxed{3. \space b \qquad \qquad Assumption. \\ 4. \space a \land b \qquad \land-intro\space(2,3)\\ 5. \space b \leftrightarrow c \qquad \rightarrow-elim(1,4) \\ 6. \space c \qquad \qquad \leftrightarrow-elim(3,5)}  \\7. \space b \rightarrow c \qquad \rightarrow -intro (3-6)
}$ $8. \space a \rightarrow (b\rightarrow c) \quad \rightarrow-intro(2-7)$ Here I am asking to see if my steps to the conclusion are right. I am not super clear on the ""correct"" way to go about this problem. I know that I am assuming things to be true and drawing conclusions based on what I have assumed and what comes out with the statements I deduct from. Some insight on this problem and if someone could validate my work would me very helpful.","['propositional-calculus', 'logic', 'solution-verification', 'discrete-mathematics', 'natural-deduction']"
3824754,Regarding a potential generalisation of Krylov-Bogolubov theorem,"Let $(\mathbb{X},d)$ be a Compact Metric Space and $T:(\mathbb{X},d) \longrightarrow (\mathbb{X},d)$ be a Continuous Mapping . Let $B(\mathbb{X})$ be $\sigma$ - Algebra of all Borel subsets of $\mathbb{X}$ . It is well-known in Ergodic Theory that Krylov-Bogolubov theorem guarantees the existence of $T-$ invariant borel probability measure $\mu$ defined on $B(\mathbb{X})$ ( $T-$ invariant means $\mu(B) = \mu(T^{-1}(B))$ for every $B\in B(\mathbb{X})$ ). Via Riesz Representation Theorem we identify the set $M(\mathbb{X})$ (the set of all borel probability measures defined on $B(\mathbb{X})$ ) with a subset of the set of all positive normalised continuous linear functionals on $C(\mathbb{X})$ (the space of all real continuous functions defined on $\mathbb{X}$ ). Since Riesz Representation Theorem has been generalised for a Locally Compact Hausdorff topological space (that is called Riesz-Markov-Kakutani theorem). I would like to enquire whether it is possible to generalise Krylov-Bogolubov theorem for a Locally Compact Hausdorff topological space. To understand the whole image, you can consult An Introduction To Ergodic Theory , Peter Walters , 1982. Chapter 6 .","['general-topology', 'ergodic-theory', 'functional-analysis', 'measure-theory']"
3824780,Minimum n for which $2020^n+1$ is prime,"I wish to find the minimum value of Positive integer $n$ for which $2020^n+1$ is a prime number.
Since $n$ cannot be odd or of the form $2^jK$ , therefore $n$ must be of the form $2^k$ . How to proceed further?","['number-theory', 'elementary-number-theory', 'prime-numbers']"
3824797,Venn Diagram Problem - Set of Athletes,"In a group of athletes, 38 enjoy rugby, 12 enjoy soccer and 24 enjoy tennis. Of these, 8 athletes like all three activities, while 30 like only one of them. How many athletes like only two of the three activities? Could someone explain how to solve this?",['elementary-set-theory']
3824822,"A) How many license plates are possible in Massachusetts, if the format must be 0-9, A-Z, A-Z ,0-9, 0-9, 0-9?","A) How many license plates are possible in Massachusetts, if the format must be 0-9, A-Z, A-Z ,0-9, 0-9, 0-9?
B) How many are possible if the format is the same, but the last three cannot all be the same number? For part A, I have $26^2*10^4= 6,760,000$ because for 0-9 there are 10 options and for A-Z there are 26 options. For part B, since the last three cannot all be the same, I have 0-9, A-Z, A-Z, but I'm not sure how to get the last three. Would it be $\frac{n_i}{10}$ ?","['combinations', 'combinatorics']"
3824875,"Monomorphism that is not left-invertible, epimorphism that is not right-invertible","Exercise 0.3 (b) in Topology: A Categorical Approach by Bradley, Bryson and Terilla asks for an example of an epimorphism that is not right-invertible. Before I get to that, I am trying to understand the example given of a monomorphism that is not left-invertible. Below is a quote from page 14: For example, the map $n \mapsto 2n$ defines a left-cancellative group homomorphism $f \colon \mathbb Z / 2 \mathbb Z \to \mathbb Z / 4 \mathbb Z$ . However, there is no group homomorphism $g \colon \mathbb Z / 4 \mathbb Z \to \mathbb Z / 2 \mathbb Z$ so that $gf = \text{id}_{\mathbb Z / 2 \mathbb Z}$ . I try to explain this to myself as follows. We have a homomorphism $f$ such that $f([0]_2) = [0]_4$ and $f([1]_2) = [2]_4$ . The text says on page 14 that a function is injective $\Leftrightarrow$ function is left-cancellative. Therefore, the morphism (function) $f$ , clearly being injective, must be left-cancellative. Unfortunately I cannot justify the assertion that there is no $g$ such that $gf = \text{id}_{\mathbb Z / 2 \mathbb Z}$ . Perhaps the most succinct reason why I'm struggling with the idea that $f$ is not left-invertible is that group homomorphisms are in fact functions, and the text says that a function is injective $\Leftrightarrow$ it has a left inverse. I figure if I can't understand this example, I have no hope of giving an example of an epimorphism that is not right-invertible. I appreciate any help. Edit: epimorphism that is not right-invertible I would appreciate verification that this example is correct. Consider the group homomorphism $h \colon \mathbb Z \to \mathbb Z / 3 \mathbb Z$ given by $z \mapsto z \mod 3$ . Because this morphism (function) is surjective, it is right-cancellative, i.e. epic. We want to show that there is no group homomorphism $g \colon \mathbb Z / 3 \mathbb Z \to \mathbb Z$ such that $hg = \text{id}_{\mathbb Z / 3 \mathbb Z}$ . I was able to show in a few lines that $g$ must be the trivial homomorphism. Therefore, for example, $h \big( g ( [2]_3 ) \big) = h(0) = [0]_3 \neq [2]_3$ , as desired.","['group-homomorphism', 'category-theory', 'functions', 'abstract-algebra', 'group-theory']"
3824881,Intuitive explanation for $\lim\limits_{n\to\infty}\left(\frac{\left(n!\right)^{2}}{\left(n-x\right)!\left(n+x\right)!}\right)^{n}=e^{-x^2}$,"In this post I noticed (at first numerically) that: $$\lim\limits_{n\to\infty}\left(\frac{\left(n!\right)^{2}}{\left(n-x\right)!\left(n+x\right)!}\right)^{n}=e^{-x^2}$$ This can be proved by looking at the Taylor expansion $$n\ln\left(\frac{\left(n!\right)^{2}}{\left(n-x\right)!\left(n+x\right)!}\right)=-2n\sum_{k=1}^{\infty}\frac{\psi^{(2k-1)}\left(n+1\right)}{\left(2k\right)!}x^{2k}$$ and the asymptotic expansion $$\psi^{(m)}(n+1)=\left(-1\right)^{\left(m+1\right)}\sum_{k=0}^{\infty}\frac{\left(k+m-1\right)!}{k!}\frac{B_k}{n^{k+m}}$$ where we have chosen $B_1=-\frac12$ . However, this limit seems so beautiful and interesting that it produces the Gaussian function. It makes me wonder if there is a more intuitive way to understand this limit, possibly in a context of probabilities.","['limits', 'gaussian', 'probability']"
3825092,How to prove that $S(n) = \sum_{k=1}^{n} (-1)^{n-k} k^n\binom{n+1}{n-k} = 1$?,"I want to show the following: $$S(n) = \sum_{k=1}^{n} (-1)^{n-k} k^n\binom{n+1}{n-k} = 1$$ I spent hours trying to solve this, unsuccessfully. My main attempt so far, has been trying induction. It trivially holds for $n=1$ , and I concluded that $S(n+1) = S(n)$ if the following holds: $$\sum_{k=1}^{n} (-1)^{n-k} k^n\binom{n+1}{k} = (n+1)^n$$ So I tried induction again, but it turned out to be way harder than I expected. I ""know"" both of these are true via software. Any help will be appreciated.","['summation', 'binomial-coefficients', 'combinatorics']"
3825193,Backpropagation calculus,"I'm trying to understand the backpropagation calculus, i made that but i'm not very sure if it ok. Someone can confirm me that?","['matrices', 'machine-learning', 'derivatives']"
3825235,Why does the determinant of the Dirac operator on $S^n$ approach $1$ as $n\to\infty$?,"Bär and Schopka (reference below) present an interesting conjecture regarding the determinant of the Dirac operator on spheres $S^n$ . The conjecture is simple: in the limit $n\to\infty$ , the determinant goes to $1$ . The numerical evidence for this conjecture is impressive, but the authors said they ""have no explanation for this phenomenon."" That was published in 2003. Has any new insight been gained about why this conjecture might be true (or false)? Reference: Bär and Schopka (2003), ""The Dirac Determinant of Spherical Space Forms"", in Geometric Analysis and Nonlinear Partial Differential Equations (link to pdf: https://www.math.uni-potsdam.de/fileadmin/user_upload/Prof-Geometrie/Dokumente/Publikationen/determinante.pdf ). The conjecture is shown on page 16 in the pdf file, after theorem 4.4.","['elliptic-operators', 'spin-geometry', 'partial-differential-equations', 'spectral-theory', 'differential-geometry']"
3825270,The resulting number after a squence of replacing numbers,"Write the sequence $\frac{1}{2012},\frac{2}{2012},...,\frac{2011}{2012}$ on blackboard. For each arbitrary pair of numbers $x, y$ in that sequence, we cancel it out and replace them by $x+y-4xy$ . What is the number after the 2010th step? I feel that we could solve this problem by using invariant principle, but still couldn't solve it.
Please help me. Thanks.","['contest-math', 'combinatorics']"
3825292,"Take a continuous map from a product topology, and fix one of the 2 arguments. Is the resultant map continuous?","Let $A,B$ and $C$ be topological spaces. Suppose we have a continuous map from the product space $$f: A\times B \to C$$ Let $a\in A$ , and consider the function $$g_a : B \to C \\
g_a(b) := f(a,b)$$ (Aside - is there a standard name for $g_a$ , like a 'section' or something? Given $f$ is continuous, is $g_a$ also continuous? Is this true for general topologies on $A$ , or are some separation conditions required?","['continuity', 'general-topology', 'topological-vector-spaces']"
3825344,Prove that there doesn't exist any normal subgroup $H$ such that $S_5/H $ is isomorphic to $S_4$,"My attempt :
Order of the group $S_5$ is $5!$ so by Lagrange's theorem the order of the group $H$ should be $5$ .So it must be a cyclic group generated by a $5$ cycle then let $(a_1 a_2 a_3 a_4 a_5)$ be a generator of the subgroup. Then for any element $g \in S_5$ , $g(a_1..a_5)g^{-1} \in H$ , then $g(a_1)..g(a_5) \in H$ .Now, all the elements of $H$ are $5$ cycles. Now if we choose $g$ in such a manner that $g(a_1)..g(a_5)$ becomes a two cycle then I am done. So I choose $g(a_1)=a_2$ , $g(a_2)=(a_1)$ ..Is this OK?  I don't think it is right where am I going wrong?","['symmetric-groups', 'group-theory', 'abstract-algebra']"
3825367,How many rings are there for a given order?,"Often I have encountered questions like : How many rings of order 4 are there upto isomorphism ? Often the solution involved brute-force treatments as checking the multiplication tables. But it is possible to check all possible multiplication tables if the order of the ring is small.But it becomes very difficult when it comes to any arbitrary number $n$ . So,does there exist any general formulation to find the number of rings of order $n$ upto isomorphism of rings?","['number-theory', 'ring-theory', 'abstract-algebra', 'combinatorics', 'group-theory']"
3825386,Prove that $\det(\overline M)=\overline {\det(M)}$,"For $M \in M_{n×n}(\mathbb C)$ , let $\overline M$ be the matrix such that $(\overline M)_{ij}=\overline {M_{ij}}$ for all $i,j$ , where $\overline {M_{ij}}$ is the complex conjugate of $M_{ij}$ . Prove that $\det(\overline M)=\overline {\det(M)}$ . My attempt: We will use induction on $n$ . Base case $n=1$ : Let $M$ be the one-by-one matrix with entry $a+bi$ \begin{align*}
\det(\overline M) &= \det(a-bi)=a-bi \\
\overline {\det(M)} &=\overline {a+bi}=a-bi
\end{align*} Induction hypothesis: assume holds for $n$ , NTS it holds for $n+1$ : \begin{align*}
\det(\overline M) &= \sum_{j=1}^{n+1} {(-1)^{1+j} \overline M_{1j} \cdot \det(\overline {\tilde M_{1j}}})
\\&=(-1)^{1+n+1} \overline {M_{1,n+1}}\cdot \det(\overline {\tilde M_{1,n+1})} + \sum_{j=1}^{n} {(-1)^{1+j} \overline M_{1j} \cdot \det(\overline {\tilde M_{1j}}})
\\&=(-1)^{2+n}\overline {M_{1,n+1}}\cdot \overline{\det(\tilde M_{1,n+1})}+\overline{\det(M')}
\end{align*} where $M'$ is $n$ -by- $n$ . I feel like the proof is almost complete but am not sure how to proceed. Any help is greatly appreciated.","['matrices', 'determinant', 'linear-algebra']"
3825433,How to find first multiple of number in a range that isn't also a multiple of 2 or 3?,"Given a range of integers $[x, x+1, x+2, ... y]$ one could find the first term that is a multiple of $k$ by doing $floor(\frac{x}{k}) \times k$ . If it's less than $x$ , add $k$ . Assume $k$ is prime. How can one find the first term that is a multiple of $k$ that is not a multiple of 2 nor 3? For example in $[110,111,112,113,118,119,120]$ how do you find the first term that's a multiple of $7$ but not 2 nor 3? $floor(\frac{110}{7}) \times 7=105$ which is less than the starting range so add $7$ to get $112$ . But $112$ is no good because $2|112$ . What we want is $119$ since it meets the criteria a) is divisible by 7  b) not a multiple of 2 c) not a multiple of 3 Another example $[10, 11, 12,...,20]$ we want to find first multiple of 5 that isn't a multiple of 2 or 3. The answer would be 20. Is there a good way of doing this or is a linear search pretty much the only option?","['elementary-number-theory', 'combinatorics', 'discrete-mathematics']"
3825506,"Properties of the iterated exponential sequences, $z_n = e^{z_{n-1}}$","Let $z_0 \in \mathbb{C}$ be a complex number, and define from it the infinite sequence $z_n = e^{z_{n-1}}$ . Question: in general, what can we say about the properties of the sequence $\{z_n\}$ ? I know that if $z_0 \in \mathbb{R}$ , then $\{z_n\}$ goes to $+\infty$ very rapidly. Also, there are infinitely many $z_0$ that are fixed points of $e^z$ - according to Wolfram Alpha, all values of the form $-W_n(-1)$ with $n\in \mathbb{Z}$ work. I would guess that for all $m>1$ , there are also infinitely many $z_0$ for which the sequence has a period of $m$ (though I don't know if that's true). But all results so far were given for special values of $z_0$ (a set of measure 0). What can we say about the sequence for a general $z_0$ ? Does it usually diverge to $\infty$ , or converge to a fixed point, or does it have weirder behavior? I've tried to check it on Python (with $z_0 = i$ for example), and the process seems very numerically unstable, so it's hard to say what the analytic behavior is from the simulation.","['complex-analysis', 'dynamical-systems']"
3825522,Independence and Fubini's Theorem,"I just want to make sure I understand a detail in the proof of the following result in my book: Proposition. Let $X_1,\dots,X_n$ be independent real random variables. Then $$E\Big(\prod_{i=1}^{n} X_i\Big)=\prod_{i=1}^{n}E(X_i)$$ if all $X_i$ are non-negative or if each is integrable. In the second case the product $\prod_{i=1}^{n} X_i$ is also integrable. Proof. Let $Q:=\bigotimes_{i=1}^n P_{X_i}$ denote the joint distribution of $X_1,\dots,X_n$ . Then by the change-of-variable formula and Tonelli's theorem $$E\Big(\Big\lvert \prod_{i=1}^{n} X_i \Big\rvert\Big)=\int | x_1\cdot ...\cdot x_n| Q(dx)
=\int\dots\int |x_1|\cdot ...\cdot|x_n| P_{X_1}(dx_1)...P_{X_n}(dx_n)$$ $$=\prod_{i=1}^{n}\int |x_i|P_{X_i}(dx_i)=\prod_{i=1}^{n}E(|X_i|)$$ Hence the assertion in the case that all $X_i\geq 0$ , as well as the integrability of $\prod_{i=1}^{n} X_i$ in the case that each $X_i$ is integrable. In the latter case by Fubini's theorem the computations above remain valid if we remove all the absolute value signs. Question: Usually when applying Fubini's theorem the iterated integrals are only defined a.e. with respect to the product measure of the coordinates in which integration has not yet occured, which could invalidate the third equality above when absolute values are removed. However I think in this case this does not happen because each $X_i$ is assumed to be integrable, and hence the iterated integrals are can be defined  on the whole product space of the coordinates in which integration has not yet occured, and measurable with respect to the product $\sigma$ -algebra of that space. For example, on the first iteration Fubini's theorem tells us that $$\int x_1\cdot ...\cdot x_n dP_{X_1}= x_2\cdot ...\cdot x_n \int x_1 dP_{X_1}$$ is defined $\otimes_{i=2}^n \mu_i$ a.e. and also $\otimes_{i=2}^n \mu_i$ integrable when extending it (on a null set) to a measurable function on $\times_{i=2}^n \Omega_i$ . Hence we are free to define $$\int x_1\cdot ...\cdot x_n dP_{X_1}dx_1:= x_2\cdot ...\cdot x_n \int x_1 dP_{X_1}$$ on such a null set to integrate. Repeated application of this reasoning with respect to each coordinate then gives us the product of integrals. Is this right way to think about this? Thanks a lot for your help.","['measure-theory', 'independence', 'expected-value', 'fubini-tonelli-theorems', 'probability-theory']"
3825597,Is the empty set compact in $\mathbb R$?,"Here they say that the emptyset is compact. Nevertheless, in $\mathbb R$ , I know that compact sets are closed and bounded. So, indeed $\varnothing $ is closed, but we have that $$\inf_{\mathbb R}\varnothing =+\infty \quad \text{and}\quad \sup_{\mathbb R}\varnothing =-\infty ,$$ in partuclar, it doesn't seem bounded. So, who is correct ?",['general-topology']
3825606,Fundamental group of $\mathbb{C}\mathbb{P}^{n}$,"I'd like to compute the fundamental group of $\mathbb{C}\mathbb{P}^{n}$ possibly using Van Kampen theorem, there is another source on SE which is Is complex projective space simply connected? but it goes beyond my actual knowledge. It seems there is a lot of difference between the computation of the real and the complex projective fundamental group without using homology, since I didn't have found any material on classical books either. What I'd like to do is to proceed by induction since I already know that $\mathbb{C}\mathbb{P}^{1} \sim \mathbb{S}^{2}$ simply connected. For the inductive step I'd like to define $A = \mathbb{C}\mathbb{P}^{n}- H$ , where $H = \left\lbrace [x_{0} : \cdots : x_{n}] : x_{0} = 0\right\rbrace$ and $B = \mathbb{C}\mathbb{P}^{n}-[1 : \cdots : 0]$ I know that $A$ is homeomorphic to $\mathbb{C}^{n}$ so it has trivial fundamental group. I'd like to prove that $H$ is a deformation retract of $B$ to conclude that it's simply connected as well and conclude since the intersection is path connected. I don't really how to properly (i.e formally) costruct the deformation on $H$ . There are simple ways or nicer way to do it ? Any help, hint or solution which doesn't require any theory greter than general topology and using Van Kampen would be appreciated.","['path-connected', 'fundamental-groups', 'homotopy-theory', 'general-topology', 'projective-space']"
3825617,Sum of any two prime numbers except the prime number 2 is even.,"(a) For every odd natural number, there is a different natural number such that their sum is even. $$(\forall x): (\neg \text{Even}(x) \rightarrow (\forall y): (y \neq x \rightarrow \text{Even}(x+y)).$$ Alternate Solution: $\forall x (\neg \text{Even}(x) \rightarrow \exists y (y \neq x \land \text{Even}(x+y))$ (b) The sum of any two prime number except the prime number 2 is even. 1. $(\forall x, y):((x \neq 2 \land y \neq 2) \rightarrow ([\text{Prime}(x) \land \text{Prime}(y)) \rightarrow \text{Even}(x+y))).$ 2. $(\forall x, y):((\text{Prime}(x) \land \text{Prime}(y) \land \text{Even}(x+y)) \rightarrow (x \neq 2 \land y \neq 2)).$ I am not sure which one of the logical statements is correct for (b) , I think it's 2. because the first statement will be vacuously true even if $x$ and $y$ are primes not equal to $2$ . Is my reasoning correct? Please correct me if I am wrong. Thank you!","['propositional-calculus', 'predicate-logic', 'logic', 'discrete-mathematics']"
3825687,What is the asymptotic of finite group Cayley length?,"Let’s for any bijection $f: A \to A$ define its support as $$supp(f) = \{a \in A| f(a) \neq a\}$$ Now, let’s define $S_\infty$ as the group of all bijections $\mathbb{N} \to \mathbb{N}$ with finite support. By Cayley Theorem any finite group is isomorphic to a subgroup of $S_\infty$ . Therefore, for any finite group $G$ we can define its Cayley length as $$len_c (G) = \min \{\sum_{\alpha \in A} |supp(\alpha)| | A \subset S_\infty \langle A \rangle \cong G \}$$ Now, we can define a following function: $$CL(n) = \max \{len_c(G) | |G| \leq n \}$$ What is the asymptotic of $CL$ ? I managed to derive the following two bounds: $$CL(n) = O(n \log(n))$$ This is because any finite group $G$ has a generating set of size $O(\log(n))$ and the size of supports of permutations, corresponding to each of those generators under left multiplicative action is $n$ . $$CL(n) = \Omega(n)$$ Suppose $p$ is prime. Then $len_c(C_p) = p$ . Indeed, all non-trivial elements of $C_p$ have order $p$ , any permutation of order $p$ has size of support dividing $p$ . However, I do not know, whether any of those bounds is tight...","['permutations', 'finite-groups', 'extremal-combinatorics', 'symmetric-groups', 'group-theory']"
3825718,Why is the notation $A\setminus B$ preferred over $A-B$?,"Let $A$ and $B$ be sets, why is the notation $A\setminus B$ preferred over $A-B$ for set differences?","['elementary-set-theory', 'notation']"
3825746,Find the value of the sum $600\sum_{a = 1}^\infty \sum_{b = 1}^\infty \sum_{c = 1}^\infty \frac{ab(3a + c)}{4^{a + b + c} (a + b)(b + c)(c + a)}$,"The value of the sum $$600\sum_{a = 1}^\infty \sum_{b = 1}^\infty \sum_{c = 1}^\infty \frac{ab(3a + c)}{4^{a + b + c} (a + b)(b + c)(c + a)}$$ is ______ My attempt :
This looks very symmetric, except for the numerator. We can resolve it into two sums: $$\begin{align}
S_1(a,b,c) &= 600\sum_{a = 1}^\infty \sum_{b = 1}^\infty \sum_{c = 1}^\infty\frac{abc}{4^{a+b+c}(a+b)(b+c)(c+a)} \\
S_2(a,b,c) &= 1800\sum_{a = 1}^\infty \sum_{b = 1}^\infty \sum_{c = 1}^\infty\frac{a^2b}{4^{a+b+c}(a+b)(b+c)(c+a)}
\end{align}$$ I don't know how to evaluate these two sums. The function does not 'separate' cleanly into different summations. I also read the Symmetric sums article on AoPS but coudn't get how to apply that concept here. Any hints/solutions are appreciated.","['summation-method', 'summation', 'sequences-and-series']"
3825756,"Finding the area under the inequality $\sin^2 \pi x + \sin^2 \pi y \le 1$ for $x,y \in [-1,1]$","Find the area under the inequality $$\sin^2 \pi x + \sin^2 \pi y \le 1 \text{ for } x,y \in [-1,1]$$ I coudn't do this problem without using a graphing calculator: It's easy to see now that in each quadrant, the area is $1/2$ unit, so the total area would be $2$ units. How would one do this without access to a graphing calculator ? Looking at the graph, It looks like there is a pattern I am missing out on. One thought would be to make the implicit inequality explicit, and obtain $$|\sin \pi y \le \cos \pi x|$$ but I still couldn't couldn't graph this manually.","['calculus', 'area', 'trigonometry', 'inequality']"
3825842,Show that $(x+ \sqrt{x})^n$ is arbitrarily close to an integer for $x \leq 3$ as $n$ approaches $\infty$,"So basically I want to show two things, firstly that $$(2+\sqrt{2})^n$$ approaches an integer as $n$ gets large. And secondly that this is only true for $$\lim_{n \to \infty }(x+\sqrt{x})^n, x \leq 3.$$ To show the first one, I tried to expand the expression using the binomial theorem. Arguing that the binomial coefficients are positive integers so it remains to show that a sum of $2$ 's to some power of $n$ is an integer there I'm pretty much stuck...","['limits', 'convergence-divergence', 'sequences-and-series']"
3825916,Spectrum of a positive operator in $B(H)$.,"We know that for $T\in B(H)$ . If $T$ is positive, then $T$ is self-adjoint and $\sigma(T)\subset R^{+}$ .
Do we have the inverse ie: if $T$ is self-adjoint and $\sigma(T)\subset R^{+}$ . $T$ is positive. where $T$ is said to be positive in case $\langle Tx,x\rangle\geq 0$ for all $x\in H$ , $H$ is a Hilbert space. Thank you very much for your help.","['hilbert-spaces', 'von-neumann-algebras', 'operator-theory', 'functional-analysis']"
3825918,A roll-unter-Game with cashback-rate on losses.,"Im scretching my head about the following roll-under-game: Choose a bet-amount $B$ and a number $N$ between $2$ and $96$ .
Then the bank picks a Number $R$ between $1$ and $100$ discretly uniformly distributed.
If $N< R$ you won the game and get $w(N)\cdot B$ back, where ... $$w(N)=\frac{\beta}{P(R<N)}=\frac{\beta}{\frac{N-1}{100}}=\frac{100\cdot\beta}{N-1}$$ ... with $P(R<N)=\frac{N-1}{100}$ and $0\leq\beta\leq1$ . On the other hand, if the result is $N\geq R$ you loose a portion $\gamma\cdot B$ of your bet-amount. In the case considered here the following applies: $\beta=0.985$ and $\gamma\in[0,1]$ (loss-ratio) with $\gamma:=1-\delta$ , where $\delta\in[0,1]$ (cashback-rate). So for $\delta=0$ or else $\gamma=1$ we get the classical roll-under-game with no cashback-bonus. I'll give two quick example to illustrate the game: i) [ $\beta=0.985$ , $\gamma=1$ (no chashback)]: If you pick $N=51$ you will win with a probability of $50\%$ and get $1.97\cdot B$ back. In the event of a loss the entire bet-amount is lost. ii) [ $\beta=0.985$ , $\gamma=0.7$ (30% chashback)]: If you pick $N=51$ you will win with a probability of $50\%$ and get $1.97\cdot B$ back. In the event of a loss you will receive $0.3\cdot B$ back. We choose a fixed number $N\in\{2,3,\ldots,96\}$ , a bet-amount $B>0$ and play the game with a seed-capital of $M_0\in\mathbb{R}_+$ multiple times in a row. Set $\omega:=W(N)-1$ .
Lets define be a sequence of r.v.'s with $X_n\in\{1,0\}$ such that $X_n=1$ describes a win and $X_n=0$ represents a loss of the $n$ -th game played.
Obviously $P(X_n=1)=:p=P(R<N)=\frac{N-1}{100}$ and $P(X_n=0)=:q=1-p$ holds for all $n\in\mathbb{N}$ , therefore $X\sim Ber(p)$ .
Because $X_n$ is bernoulli distributed we know that $E[X_n]=p$ . Now we take a look at the earnings in each round. Obviosly they can be described by the sequence of r.v. $Y_n=X_n\cdot\omega B+(X_n-1)\cdot\gamma B$ .
The expected value is: $$\begin{align}E[Y_n]&=E[X_n\cdot\omega B+(X_n-1)\cdot\gamma B]\\&=E[X_n]\cdot\omega B+(E[X_n]-1)\cdot\gamma B\\&=p\cdot\omega B+(p-1)\cdot\gamma B=B(p\cdot\omega-(1-p)\cdot\gamma)\\&=B(p\cdot\omega-q\cdot\gamma)\end{align}$$ So it is a fair game with $E[Y_n]=0$ if $\omega=1$ , $\gamma=1$ and $p=0.5$ . We continue to simplify the expression from above with $\delta:=1-\gamma$ (Cashbackrate), $\Delta:=\beta-1$ and $\omega=W(N)-1=\frac{\beta}{p}-1$ . Leading to: $$\begin{align}E[Y_n]&=B\cdot(\omega p-\gamma q)=B\cdot((\frac{\beta}{p}-1)p-\gamma q)\\&=B\cdot(\beta-p-\gamma(1-p))=B\cdot(\beta-p-\gamma+\gamma p)\\&=B\cdot(\beta-p(1-\gamma)-\gamma)=B\cdot(\beta-p\delta-(1-\delta))\\&=B\cdot((\beta-1)+\delta(1-p)=B\cdot((\beta-1)+\delta q)\\&=B\cdot(\Delta+\delta q) \end{align}$$ In the case described at the beginning with $\beta=0.985$ and no cashback (meaning $\gamma=1$ ) and $N=51$ (which gives $p=0.5$ ) we get $E[Y_n]=B\cdot(\Delta+\delta q)=B(-0.015+0\cdot 0.5)=-0.015\cdot B$ . So in a roll-under-game without any cashback on losses we expect a loss of 1.5% of the bet-amount each game. Now let's check how the cashback rate has to be changed in order to expect a profit: $$E[Y_n]\geq 0\Leftrightarrow B\cdot(\Delta+\delta q)\geq0 \Rightarrow (\Delta+\delta q)\geq0 \Leftrightarrow q\geq\frac{-\Delta}{\delta} $$ So we expect a profitable game when $\frac{-\Delta}{\delta}<q$ .
For $N=51$ , $\beta=0.985$ and with a cashback-rate of $\delta=5\%,7\%,9\%,11\%,13\%,15\%$ we achieve a expected profit of $1\%,2\%,3\%,4\%,5\%,6\%$ of the bet-amount $B$ each game.
On the other hand if we choose a cashback-rate of $\delta=3\%$ we achieve a fair game. Is this calculation correct so far? For the sake of completeness we look at the capital stocks r.v.'s $M_1,M_2,\ldots$ after each round. $M_0$ describes the overall capital at the beginning of the game.
It is clear that $M_n=M_0+\sum_{k=1}^n X_n$ applies. For the expected value we get: $$\begin{align}E[M_n]&=E[M_0+\sum_{k=1}^n Y_n]=M_0+\sum_{k=1}^n E[X_n]=M_0+B\sum_{k=1}^n(\Delta+\delta q)\\&=M_0+n\cdot B(\Delta+\delta q)\end{align}$$ Now i try to find the probability that i am runied after $n$ games.
For this we define $W_n=\sum_{k=1}X_k$ the number of wins in $n$ trails, which we know is binomial distributed $W_n\sim Bin(n,p)$ .
Further we define $L_n=n-W_n$ the number of lost games in $n$ trails.
So we are bankrupt if: $$\begin{align}M_0+W_n\omega B-L_n\cdot\gamma B\leq 0 
&\Leftrightarrow M_0+W_n\omega B \leq L_n\cdot\gamma B
\\ &\Leftrightarrow M_0+W_n\omega B \leq (n-W_n)\cdot\gamma B 
\\ &\Leftrightarrow M_0+W_n\omega B \leq n\gamma B-W_n\gamma B
\\ &\Leftrightarrow M_0+W_n B(\omega-\gamma) \leq n\gamma B
\\&\Leftrightarrow W_n\leq\frac{n\gamma B-M_0}{B(\omega-\gamma)} \end{align}$$ So the probability to get ruined after $n$ games is given by $P(W_n\leq K)$ with $K:=\frac{n\gamma B-M_0}{B(\omega-\gamma)}$ .
Because $W_n\sim Bin(n,p)$ we know the cumulativ distribution function $F_{W_n}(x)$ . This gives us: $$P(W_n\leq K)=F_{W_n}(K)=\sum_{k=0}^{\lfloor K \rfloor}\binom{n}{k}p^kq^{n-k}$$ Is this correct? Are there any flaws? Especially the last result seems somehow strange to me. How can I determine the probability that I have a higher capital $M_n$ after $n$ games than at the beginning $M_0$ ?
Which means nothing else than, how do I calculate the probability $P(M_n\geq M_0)$ ? Is a approach through random walks better? Basically it is a random walk with different step-sizes. It walks $\gamma B$ to the left side with probability $q=1-p$ and walks $\omega(N) B$ to the right with the probability $p=\frac{N-1}{100}$ .
Is there any literature for this special case of a random-walk? Any assistance, thoughts or comments would be much appreciated.","['random-walk', 'expected-value', 'probability-theory', 'probability', 'random-variables']"
3825946,"Implicit functions of $f(x,y,z)= x \sin z- y \cos z=0$","Let $U=\{(x,y,z) \in \mathbb{R}^{3} : x>0\}$ open and $f:U \rightarrow \mathbb{R}$ defined by $$f(x,y,z)= x \sin z- y \cos z.$$ Show that given $p=(x,y,z) \in \mathbb{R}^3$ if $f(p)=0$ then $\frac{\partial f}{\partial z}(p)\neq 0$ . Let $V=\{(x,y) \in \mathbb{R}^{2}: x>0\}$ show that there are infinitely many continuous functions $g:V \rightarrow \mathbb{R}$ such that $f(x,y, g(x,y))=0$ for all $(x,y) \in V$ , each $g$ is of class $\mathbb{C}^{\infty}$ and any two of them differ by a constant. for the first part, we have $f(x,y,z)=x \sin z- y \cos z =0$ , this is $$\sin z=\frac{y \cos z}{x}.$$ Deriving we have $$\frac{\partial f}{\partial z}=x \cos z+ y \sin z= x \cos z + y \sin z.$$ If we assume that $ \frac{\partial f}{\partial z}=0$ , we have $$x \cos z + y \sin z=x \cos z + y \frac{y \cos z}{x}=\cos z (x^2+y^2)=0$$ as $x>0$ , we have $\cos z=0$ then $z=\frac{(2n+1) \pi}{2}$ , which is a contradiction because $x \sin z- y \cos z =0$ . I don't know how to demonstrate the second, any help please?","['partial-derivative', 'multivariable-calculus']"
3825984,Green's Theorem and Line Integrals,"So I'm supposed to use Green' theorem to calculate the line integral $$
\int_{C_1} \frac{x^2-1}{x^2+4y^2}dx +\frac{x}{x^2+4y^2}dy
$$ Where $C_1$ is the part of the parabola $y=1-x^2$ from point $(1,0)$ to $(-1,0)$ My first problem: I was able to calculate $\partial P/ \partial y$ and $\partial Q/ \partial x$ but it was indeed very tedious. Is there another way to calculate it? I thought about considering the derivatives only evaluated at the parabola, in a way I could write $x^2-1=-y$ but I don't know if I can do this because when we calculate the surface integral at Green's theorem we are considering the whole surface, right? Anyways, I found out $\partial Q/ \partial x - \partial P/ \partial y = 0$ . Then, since the theorem requires me to have a closed path, I chose my ""second path"" as the ellipsis $x^2+4y^2=1$ . So then I can write: $$
\int_{C_1} \frac{x^2-1}{x^2+4y^2}dx +\frac{x}{x^2+4y^2}dy= -\int_{C_2} x^2-1dx +xdy
$$ After this we just need to parametrize the ellipsis as $y=\frac{1}{2} \sin(t); \enspace x=\cos(t)$ . Sadly enough the answer I get is not the correct one (which is $\pi/2$ ). What am I doing wrong/ is there a better way to proceed? I appreciate any tips/corrections.","['greens-theorem', 'multivariable-calculus', 'line-integrals', 'parametrization']"
3826019,"How many values of $x\in\mathbb Z^+,x<99$ are there such that $m,n\in\mathbb Z$ and $m^2-n^2=x$ is possible?","How many values of $x\in\mathbb Z^+,x<99$ are there such that $m,n\in\mathbb Z$ and $m^2-n^2=x$ is possible? So what I'm trying to find here is the number of integers between $1$ and $98$ inclusive such that that integer can be expressed as the difference of two squares. I know that all odd numbers can be expressed as the difference between to consecutive squares, so the answer is at least $98/2=49$ , but I don't really see a way to continue from here. Maybe I can utilize Pythagorean Theorem somehow? Thanks for the help. Also I'm not too sure which topic this question falls under so if someone could edit the tags that would be great.","['elementary-number-theory', 'algebra-precalculus', 'square-numbers']"
3826061,Show that there is a conjugation class that is contained in the subset of triangular matrices,"The question goes like this: Let $p$ be a prime, $G$ a subgroup of $GL(n, \mathbb{F}_p)$ such that $|G| = p^k$ for some $k \ge 1$ . Show that there exists an element $g \in GL(n, \mathbb{F}_p)$ such that $G^g$ is contained in the subgroup of $GL(n, \mathbb{F}_p)$ composed of upper triangular matrices with ones in the diagonal entries. Here $G^g = \{x^{-1} g x \mid x \in G\}$ .
I think this must have something to do with the class equation, since $|G| = p^k$ must imply there is some conjugacy class with just one element. I'm not sure. EDIT: a previous question says that there is a common eigenvector $v$ with eigenvalue 1 for all matrices in $G$ , and there is a hint to use induction over $n$ , applying the induction hypothesis on $\mathbb{F}_p^n / \langle v \rangle$ .","['group-theory', 'linear-algebra']"
3826080,"Prove that if $A$ is a positive definite matrix, then $A$ is non-singular.","First, going through what it means to be positive definite and non-singular: Positive definite implies $\det(A) > 0$ All eigenvalues of $A$ are positive, and so $0$ is not an eigenvalue of $A$ Nonsingular implies $\det(A) \neq 0$ All eigenvalues of A are nonzero The product of eigenvalues of $A$ $= \det(A)$ It seems as though these two characterizations go hand in hand, though I assume negative eigenvalues could form a non-singular matrix but not a positive definite matrix. Can this be proven directly, or do I need to figure out how to prove by contradiction? Thanks!","['matrices', 'proof-writing', 'linear-algebra', 'positive-definite']"
3826164,Is $M\otimes_{S} S(n)$ Isomorphic to $M(n)$?,"$S$ is a graded ring and $M$ is a graded $S$ module, let $S(n)$ denote the graded $S$ module by shifting the grading of $S$ , i.e. $S(n)_i = S_{n+i}$ . Then do we have $M\otimes_{S} S(n)$ Isomorphic to $M(n)$ ? If this is not true, is it true with the additional condition that $S$ is generated by $S_1$ as a $S_0$ algebra? EDIT: The reason that I am interested in this question is that I am trying to understand the proof of Hartshorne Chapter II Proposition 5.12 (b) which states If $S$ is a graded ring, assume $S$ is generated by $S_1$ as a $S_0$ algebra. For any graded $S$ module $M$ , $\tilde{M}(n)\cong \widetilde{M(n)}$ , Where in the proof Hartshorne said use the fact that $\widetilde{M\otimes_{S} N}\cong \tilde{M}\otimes_{O_X} \tilde{N}$ . I am able to show this fact, but I think Hartshorne was trying to let $N$ be $S(n)$ , then by the isomorphism, we have $\tilde{M}(n) \cong \widetilde{M\otimes_{S} S(n)}$ . Then if I can show $M\otimes_{S} S(n)\cong M(n)$ , then it is done.","['modules', 'algebraic-geometry', 'ring-theory', 'abstract-algebra', 'commutative-algebra']"
3826176,Likelihood of random spanning tree given distribution of edge weights?,"Suppose I have a complete graph $G=(V,E)$ with $n$ vertices, whose edge weights $W\in\mathbb R_+^{n\times n}$ are drawn from some distribution $P(W)\in\mathrm{Prob}(\mathbb R_+^{n\times n})$ .  I randomly draw a set of edge weights $W\sim P$ and then compute the resulting minimum spanning tree $T\subseteq E$ of the weighted graph. Is it possible to compute the probability of a given spanning tree $T$ given the distribution $P(\cdot)$ ? A value proportional to this probability would suffice.  If it helps, I'm happy to assume that each weight is chosen independently, i.e. $P(W)=\prod_{ij}P_{ij}(W_{ij})$ , but I do not want to assume that the $W_{ij}$ 's are iid.  Even assuming each $P_{ij}$ is a Bernoulli (or exponential or Gaussian) distribution with a different parameter would be a great start.","['random-graphs', 'trees', 'graph-theory', 'combinatorics', 'probability']"
3826178,Markov Chain Limit Value,"Suppose I have the following Markov chain. $X_0 > 0$ is a fixed constant and for every $1 \leq n \in \mathbb{N}$ we have $$X_n = \begin{cases} 1.5X_{n-1} & \text{with probability } 0.5 \\ rX_{n-1} & \text{with probability } 0.5 \end{cases} $$ I want to find the minimum value of $r$ such that the limiting value of the $X_n$ is greater than or equal to $X_0$ , the original amount.  I figured that making this a martingale would suffice (i.e. setting $r = 0.5$ ) but when I run a simulation the limiting value is zero every time, so obviously this is wrong. I'm looking for a value $r$ such that the limit is exactly $X_0$ since (I'm guessing that) anything larger will lead to an infinite limit almost surely.  This problem makes no sense to me though.  Please help if you can.","['stochastic-processes', 'probability-theory', 'markov-chains']"
3826199,"Trying to solve: $y'' + 2y' = \frac{(y')^2}{y + 1} + \frac{y'}{x} \ln(\frac{y+1}{y'})$, $y(1) = 1$, $y'(1) = 2/e$.","The problem is the following:  Solve $$y'' + 2y' = \frac{(y')^2}{(y + 1)} + \frac{y'}{x} \ln\left(\frac{y+1}{y'}\right),$$ given that $y(1) = 1$ , $y'(1) = \frac{2}{e}$ . My solution: After noting that $$\left(\ln\left(\frac{y+1}{y'}\right)\right)' = \frac{y'}{y + 1} - \frac{y''}{y'}$$ we divide the original equation by $y'$ , rearrange and get $$\frac{y'}{y + 1} - \frac{y''}{y'} + \frac{1}{x}\ln\left(\frac{y + 1}{y'}\right) = 2$$ Then we substitute $t(x) = \ln\left(\frac{y + 1}{y'}\right)$ . Now we have $$t' + \frac{t}{x} = 2$$ Particular solution to this equation is $t = x$ and for $t' + \frac{t}{x} = 0$ we have $t = \frac{C}{x}$ . So finally we have $t = x + \frac{C}{x}$ . Now we note that $t(1) = \ln\left(\frac{e(1 + 1)}{2}\right) = 1$ and conclude that $t = x$ and then solve for $y$ . For $y$ we have $$\frac{y + 1}{y'} = e^x$$ Solution for this equation is $\ln|y + 1| = -e^{-x} + C$ . After some manipulations we get $$y = \frac{C}{e^{e^{-x}}} - 1$$ and following the initial condition $y(1) = 1$ we get $C = 2e^{e^{-1}}$ . So the answer will be $$y = 2e^{e^{-1} - e^{-x}}$$ I have 2 questions: $\qquad 1)$ Is my solution correct? The answer looks terrible, so maybe I had an error somewhere. $\qquad 2)$ Is there any easier solution? I thought about finding $y''(1)$ , multiplying by $x/y'$ , taking derivative to remove $\ln$ -function and solve the resulting equation, but it seemed to be much harder than what I did in the solution above.","['solution-verification', 'ordinary-differential-equations']"
3826239,prove: $2n+1\le 2^n$ by induction,"I'm struggling with verifying inequalities through the use of induction and wanted some guidance on the matter. I asked a question previous to this one that's similar, but this problem is different and aims at clarifying the rest of my confusion. The problem is this: verify the inequality $2n+1 \le 2^n$ for $n = 3,4...$ I have a screenshot of the problem along with my professor's solution, but I am not understanding her solution at all. I understand that induction with inequalities works by this process: let the left side of the inequality you are trying to prove be A. let the left side of the inductive hypothesis be B, and the right side be C. Since you know B<C with your hypothesis, you have to show A<B is true. If it is, you can conclude A<C. How can this be done with this problem?","['proof-explanation', 'induction', 'solution-verification', 'discrete-mathematics']"
3826248,Intuitive explanation for inverse of a permutation matrix,"Today in lecture we learned that the transpose of a permutation matrix is the inverse of the permutation matrix. Meaning, $$P^{T}P = I$$ I can work out the math by matrix multiplication but I'd prefer a deeper, more intuitive understanding. What I have so far in my head is: We know that the matrix $P$ will swap rows when we apply it to a matrix, let's say $A$ . Then $PA$ will swap the $i^{th}$ row of A with the $j^{th}$ of $A$ . This then means that $P^{T}(PA)$ must swap our new $i^{th}$ row with the new $j^{th}$ row so we can have our original $A$ matrix back. Why is this always true? More specifically why does $P^{T}$ swap back out rows...?","['permutation-matrices', 'matrices', 'linear-algebra', 'inverse', 'intuition']"
3826256,Combinatoric problem: Contest winner problem,"I have this problem to solve where:
There is a contest between $m$ competitors.
Each competitor draws a number between $1$ to $N$ separately, and the winner is the one who drew the highest number. The problem I'm having is to find out the probability that the contest fails.
The contest fails when there isn't a single winner - two or more competitors drew the same number and that number was the highest from all the other numbers that were drawn.
Generally, to draw the same number is not a problem as long that there is a competitor who drew higher. I calculated the probability that two or more competitors drew the same number using the complement probability: $$
\begin{multline}
1 - P(\text{all m contestants drew different number})  = 1 - \frac{N!}{(N-m)!} \frac{1}{N^m} 
\end{multline}
$$ Am I right?  I'm missing the part where the number that was drawn was the highest. Appreciate your help, thank you in advance.","['combinatorics', 'probability']"
3826276,"What are the domain and values of binomial coefficients $ n \choose k $ for any integer $n$ and $k$, and why?","This is a question about ""nasty details"" of the binomial coefficients. I would like to understand the definition of binomial coefficients $ n \choose k $ for general integers $n$ and $k$ . One way to define binomial coefficients is as the number of cardinality $k$ subsets of an cardinality $n$ subsets, which is, ${n \choose k} := |\{\; S \subseteq \{ 1, \dots, n \} \;:\; |S| = k \;\}|$ This formula is well-defined for any integer $n$ and $k$ . Note that for $k = 0$ we always get ${n \choose k} = 1$ regardless of $n$ but generally it is zero for negative $n$ . There are many other ways of defining the binomial coefficients. For instance, another definition is: ${n \choose k} := \prod_{i=1}^k \dfrac{ n+1-i }{ i }$ which is equals $1$ for any non-positive $k$ regardless of $n$ . Argueably, the latter definition of the binomial coefficients is not regarded as ""foundational"" for non-negative $n$ and $k$ , but that does not really help in deciding for integers the binomial coefficients are defined and what their values are. Is there a commonly accepted definition of ${n \choose k}$ for any integers $n$ and $k$ , and what are the benefits of that definition for the working mathematician?","['convention', 'binomial-coefficients', 'combinatorics']"
3826291,Why isn't the matrix logarithm defined as the integral of the inverse function?,"I just started to play around with the idea of the matrix logarithm. From my research, the simplest way to compute the value of the matrix logarithm is a generalization of the Taylor series of the natural logarithm — you just replace the $1$ , with $I$ : $$\ln(A + I) = \sum_{n=1}^{\infty} (-1)^{-n + 1} \frac{A^{n}}{n}$$ Why not define the matrix logarithm, as the generalization of the $\ln(x)$ as the integral of the function $\frac{1}{x}$ instead $?$ $$\ln(x) = \int_{1}^{x} \frac{1}{t} dt = \lim_{n\to\infty} \sum_{i=1}^{n-1}\frac{1}{1 + \frac{(x - 1)i}{n}}\frac{x-1}{n}$$ so why not define the matrix logarithm as such $$\ln(A) = \int_{I}^{A} \frac{1}{x} dx = \lim_{n\to\infty} \sum_{i=1}^{n-1}\frac{1}{I + \frac{(A - I)i}{n}}\frac{A-I}{n}?$$ I know it's a bit weird that the limits of integration are matrices, but I don't see anything wrong with that, especially because we can just use the Riemann sum directly. Do we avoid using that definition because not every matrix is invertiable $?$ Because the two matrices in this sum don't always commute? or do we do use this definition and my reseasrch was incomplete?","['logarithms', 'matrix-analysis', 'matrices', 'matrix-calculus', 'limits']"
3826311,Fairness of rolling a die 3 times,"I have a pair of sneakers to give away and 3 friends would like to have it.
I decided to have them each roll a dice and the person with the highest number wins the sneakers.
Does the first person to roll the dice have an advantage over the other two?","['statistics', 'dice', 'probability']"
3826337,Why would $1^{-\infty}$ not be 1?,"It would seem to me that $1^{-∞}=\lim_\limits{x→∞}1^{-x}=\lim_\limits{x→∞}\frac1{1^x}=\frac11=1$ no matter how we approach it. However, Wolfram Alpha answers with a mysteriously unqualified “ $\text{(undefined)}$ ”. Similarly, JavaScript also thinks that the result isn't a number. On the other hand, the very mathematically inclined APL languages NARS2000 and J both have it give $1$ . What reasons are there to reject $1^{-∞}=1$ ?","['power-series', 'limits', 'infinite-product', 'mathematica']"
3826427,Is every bounded operator part of a $C_0$-semigroup?,"Let $X$ be a Banach space and $B \in \mathcal{B}(X)$ be a bounded linear operator on $X$ . Is there necessarily a $C_0$ -semigroup $T$ such that $B = T(t)$ for some $t$ ? There might be something obvious I'm missing, but I'm not sure of a good way to approach this problem. The most obvious idea to me would be using some sort of functional calculus for bounded operators that lets you apply a logarithm, and would hopefully result in a (not necessarily bounded) generator for the desired semigroup. I am not aware of any such functional calculus though. I also can't think of a trivial ""natural exponential progression"" from the identity map to $B$ . As far as counter examples go, I know of few theorems that force specific behaviors of $C_0$ -semigroups. An obvious one to try is the $0$ operator. At least on $X = C_0[0,1)$ , though, the translation semigroup is nilpotent. This is not a homework problem or anything, just something I got curious about.","['banach-spaces', 'operator-theory', 'functional-analysis']"
3826448,How many $3$-letter words are there with no repeated letter if the middle letter is a vowel?,"My first answer was $5 \times 25 \times 24$ , picking the vowel before the first and last letter. To my surprise, my book says this is the right answer! But I thought I was not counting everything and continued considering the following situations: If I pick one vowel, there are $5 \times 21 \times 20$ words since I'm not considering vowels in the remaining choices. For instance, suppose I pick ""abd"". Then, there are $3!$ ways to arrange this word, but I want the middle letter to be the vowel, so only ""b a d"" and ""d a b"" are valid. Then for each of the $5 \times 21 \times 20$ words, there are two valid permutations. Therefore, there are $5 \times 21 \times 20 \times 2$ words. If I pick two vowels, there are $5 \times 4 \times 21$ words. For instance, suppose I pick ""aed"". Again, there are $3!$ ways to arrange this word, but since there are two vowels, we have four valid permutations: ""a e d"", ""d e a"", ""e a d"", and ""d a e"". So for each of the $5 \times 4 \times 21$ words, there are four valid permutations. Therefore, there are $5 \times 4 \times 21 \times 4$ words. If I pick three vowels, there are $5 \times 4 \times 3$ words. Since all are vowels, all $3!$ permutations are valid. Therefore, there are $5 \times 4 \times 3 \times 6$ words. Finally, I summed all three to get $(5 \times 21 \times 20 \times 2) + (5 \times 4 \times 21 \times 4) + (5 \times 4 \times 3 \times 6)$ $3$ -letter words with no repeated letters such that the middle letter is a vowel. If the answer in the book is correct, clearly I overcomplicated a simple problem, but I cannot see why the book is correct. Am I overcounting? Am I considering cases that should not be considered? Thank you for any clarifications! :)","['combinatorics', 'discrete-mathematics']"
3826449,What is the transported metric?,"In this previous question: Transported Metric , I wanted to transport the Euclidean metric $ds^2=dx^2+dy^2$ into the first quadrant of the $(u,v)$ -plane, such that for all curves $\gamma$ in the $(x,y)$ -plane we have $L_{uv}\bigl(f(\gamma)\bigr)=L_{xy}(\gamma)$ . I used a map $f:\Bbb R^2\to\Bbb R^{2}$ with $f(x,y)=(e^x,e^y).$ Then (with the help of @ChristianBlatter) the transported metric is: $$ds^2={1\over u^2}du^2+{1\over v^2}dv^2\ .$$ I noticed that $f$ maps the third quadrant of the $(x,y)$ -plane to $(0,1)^2$ in the $(u,v)$ -plane. So I decided to map all the quadrants of the $(x,y)$ -plane into $(0,1)^2$ of the $(u,v)$ -plane and write down the transported metric. Since all the quadrants of the $(x,y)$ -plane are represented in $(0,1)^2$ of the $(u,v)$ -plane, then I think it is isomorphic to $\Bbb R^2.$ So the four maps I used were, $f_n:\Bbb R^2 \to \Bbb R^2$ for $n=1,2,3,4$ with: $$ f_1(x,y)=(-e^{-x},-e^{-y})$$ $$ f_2(x,y)=(e^x,-e^{-y}) $$ $$ f_3(x,y)=(e^x,e^y) $$ $$ f_4(x,y)=(-e^{-x},e^y) $$ The subscripts represent the quadrant that each map ""acts on."" So $f_3$ for example, maps points from the third quadrant to $(0,1)^2.$ So I'll say that $f_3$ ""acts on"" points in the third quadrant. Then I translated all the image spaces for $f_n$ to $(0,1)^2$ of the $(u,v)$ -plane. Now the quadrants all overlap so I don't know how to define the metric. What is the transported metric in $(0,1)^2$ of the $(u,v)$ -plane?","['euclidean-geometry', 'transformation', 'geometry', 'metric-spaces']"
3826488,Geometric meaning of the degree of the normal bundle $\mathcal{N}_{C/X}$,"Assume all varieties are projective and smooth over $\Bbb{C}$ . Let $X\subset\Bbb{P}^3$ be surface and $C\subset X$ a curve on it. The normal bundle $\mathcal{N}_{C/X}$ is the cokernel of the map $T_C\hookrightarrow T_X\big|_C$ , which intuitively represent the tangent vectors on $X$ which are perpendicular to $C$ . I've read recently that the selfintersection $C^2$ equals the degree of the normal bundle $\mathcal{N}_{C/X}$ , which can be interpreted as how free the curve $C$ is to move inside $X$ (in particular, if $C^2<0$ then $C$ can't move). At first I understood this explanation to be just a way to make us more comfortable with the idea of selfintersection. But this answer made me think twice. The answer deals in particular with the example of (I'll adapt it a little) a curve $C\subset\Bbb{P}_\Bbb{C}^3$ of degree $2$ and genus $0$ . It can be proven that there is a quadric $Q\subset\Bbb{P}^3$ containing $C$ . Furthermore $\mathcal{N}_{C/Q}=\mathcal{O}_C(1)$ , which according to the answer is because ""any such curve is obtained as a hyperplane section of $Q$ , so the line bundle $\mathcal{N}_{C/Q}$ has to have degree $1$ on $C$ "". I want to explore that. Does that mean that the possibilities of $C$ to move in $Q$ amount to the way we move the hyperplane cutting $Q$ ? If, more generally, we had $\mathcal{N}_{C/X}=\mathcal{O}_C(d)$ , would this mean that $C$ is the section of $X$ by a hypersurface of degree $d$ and that $C$ moves in $X$ according to how we move the hypersurface? I'd like to understand this as geometrically as possible. Thank you!","['algebraic-geometry', 'intersection-theory', 'line-bundles']"
3826526,What this “resp.” means?,"I’m not a native English speaker and not a good math reader too.
My question came while I reading this Debreu article about a existence of a real function to represent the preferences and I’m stuck in this passage: If $A$ , $B$ are two $f$ -sets (resp. $i$ -sets) and $A \cap B$ is not empty, then $A \cup B$ is an $f$ -set (resp. $i$ -set). What’s this “resp.” means?","['notation', 'analysis', 'terminology']"
3826527,$\sup_{x \neq y}\frac{||f(x)-f(y)||}{||x-y||}= \sup_{z \in U} ||f'(z)||$,"Let $f:U \to \mathbb{R}^{m}$ differentiable in the open convex $U \subset \mathbb{R}^{m}$ . Prove that $$\sup_{x \neq y}\frac{\|f(x)-f(y)\|}{\|x-y\|}= \sup_{z \in U} \|f'(z)\|$$ by the mean value theorem we have $$\sup_{x \neq y}\frac{\|f(x)-f(y)\|}{\|x-y\|} \leq \sup_{z \in U} \|f'(z)\|$$ the other implication I can't do it, any ideas?","['multivariable-calculus', 'lipschitz-functions', 'real-analysis']"
3826632,$f^{-1}f(\Sigma)$ has measure zero for analytic map from manifolds $M$ to $N$,"Differential Topology Hirsch Chapter 3 Section 1 Problem 4: (a) Let $M$ be a connected manifold and $f: M \rightarrow N$ an analytic map. Let $\Sigma \subset M$ be the set of critical points. If $\Sigma \neq M$ then $f^{-1}f(\Sigma)$ has measure zero. (b) If $f$ is merely $C^{\infty}$ The conclusion (a) can be false. For part (a) A function is analytic iff its Taylor series about $x_0$ converges to the function in some neighborhood for every $x_0$ in the domain. The definition of analytic function is the same as $C^{\infty}$ function except for the notion of convergence in a neighborhood of nonzero radius in the former. Therefore, we can apply the Morse-Sard Theorem and conclude that the set of regular values is dense. A critical point cannot be a regular value so $f^{-1}f(\Sigma)$ , which is the set of critical points must have measure 0. For part (b) I didn't use anything about the function being analytic in part (a) so I'm not sure how I would approach this part. Thank you!","['differential-topology', 'differential-geometry']"
3826641,Proof of ∀𝒙 ∈ 𝑪 ((𝒙 ∈ 𝑨)↔($𝒙^2$ ∈ 𝑩)),"Let 𝐴 = {−2, −1,0,1,2}, 𝐵 = {0,1,4} and 𝐶 = {−4, −3, −2, −1,0,1,2,3,4}. Prove if ∀𝒙 ∈ 𝑪 ((𝒙 ∈ 𝑨)↔( $𝒙^2$ ∈ 𝑩)) is true/false. This is my attempt at the proof, I am not sure if it is correct. Is there a more concise way of proving without using proof by exhaustion? Also, is there a better way to express lines 1.1 and 2.1? Thank you!","['elementary-set-theory', 'proof-writing', 'solution-verification', 'discrete-mathematics']"
3826733,classical occupancy problem in Feller - $r$ balls in $n$ cells - poisson approximation,"I'm reading Feller's Introduction to Probability Vol. 1 page 103, and I'm try to wrap my head around the following. There is a step from the section on classical occupancy problem (section 2 of chapter IV). The classical occupancy problem involves the random distribution of $r$ balls in $n$ cells, where we seek the probability $p_m(r,n)$ of finding exactly $m$ cells empty. In Chapter IV, (2.6) we have (2.6) $\hspace{1in}$ $ \{ne^{-(\nu+r)/(n-\nu)} \}^\nu < \nu! S_{\nu} < \{ne^{-r/n}\}^\nu$ Then $\lambda$ is set $$ne^{-r/n} = \lambda $$ and suppose that $r$ and $n$ increase in such a way that $\lambda$ remains constrained to a finite interval: $0 < a < \lambda < b$ . For each fixed $\nu$ the ratio of extreme members in (2.6) then tend to unity, and so $$ 0 \leq \frac{\lambda^\nu}{\nu!} - S_{\nu} \to 0 $$ How did he arrive at the last step? Appendix: $S_\nu$ is defined as below $$ S_\nu = {n \choose \nu} \left( 1- \frac{\nu}{n} \right)^r$$ for every $ \nu \leq n $ For example, $ S_1 = \Sigma p_i $ ,  where $p_i$ is the probability that the $i$ th bin is empty. $ S_2 = \Sigma p_{ij} $ ,  where $p_{ij}$ is the probability that the $i$ th and $j$ th bins are empty, for all $i$ and $j$ and $i<j$ . $ S_3 = \Sigma p_{ijk} $ , ... and so on.","['poisson-distribution', 'limits', 'probability-theory', 'probability']"
3826743,A lemma in Tensor Categories (Etingof et al),"Lemma 8.10.5 in EGNO's Tensor Categories basically states Let $\mathcal{C}$ be a tensor category over an algebraically closed field $\mathbb{k}$ with braiding $c$ .
For any nonzero simple object $X$ the composition \begin{align}
    t(X) := \operatorname{ev}_X \circ c_{X, X^\vee} \circ \operatorname{coev}_X \in \operatorname{End}_{\mathcal{C}}(\mathbf{1}) 
\end{align} is nonzero. I feel very conflicted.
On the one hand, the one line proof given in the book seems plausible: Since $X$ is simple, the corresponding composition \begin{align}
\operatorname{End}(\mathbf{1}) \to \operatorname{Hom}(\mathbf{1}, X\otimes X^\vee) \to \operatorname{End}(\mathbf{1})
\end{align} consists of nonzero maps between 1-dimensional spaces, and is thus non-zero. On the other hand, suppose that the lemma holds and that $X$ is projective.
Then $P = X \otimes X^\vee$ is projective.
Set $f = t(X)^{-1} \operatorname{coev}_X$ and $g = \operatorname{ev}_X \circ c_{X, X^\vee}  $ .
But then \begin{align}
    \mathbf{1} \xrightarrow{f} P \xrightarrow{g} \mathbf{1} = \operatorname{id}_{\mathbf{1}}
\ ,
\end{align} so that $\mathbf{1}$ , being a direct summand in a projective, is projective.
But then $\mathcal{C}$ is semisimple.
A contradiction to the existence of non-semisimple finite tensor categories with simple projective objects. Note that in fact the general heuristic in this last part implies that in a non-semisimple (finite) tensor category there exists no nonzero endomorphism of the tensor unit factoring through a projective object.
For this heuristic, see also the proof of Theorem 6.6.1 in the book. So, where is the mistake? Edit: Here are two examples for non-semisimple finite tensor categories with simple projective objects: The symplectic fermions .
This category is even factorizable, i.e. ribbon with a certain non-degeneracy condition on the braiding. The category of representations over the restricted quantum group $\overline{U}_q(sl_2)$ . Edit 2: The mistake is in the proof in the book.
Namely, as I prove, the map $\operatorname{Hom}(\mathbf{1}, X \otimes X^\vee) \to \operatorname{End}(\mathbf{1})$ is zero if $X$ is projective.","['projective-module', 'monoidal-categories', 'category-theory', 'abstract-algebra', 'abelian-categories']"
3826764,Why does Maschke's theorem require the characteristic of the field to be coprime to the order of the group?,"I was reading a proof of Maschke's theorem (specifically pages 5-6 of this paper ) and it seemed relatively straightforward... the only problem is the extra condition of coprimeness, which doesn't seem necessary to me. Where does the proof fail if the coprime condition is not satisfied? Also, what happens for fields of characteristic 0, such as the complex numbers? Isn't that not coprime to the order of any group except the trivial group?","['field-theory', 'group-theory', 'representation-theory']"
3826788,Bound on difference of derivatives of convex functions,"Let $f:[0, \infty) \to \mathbb{R}$ be a convex function.
Let us assume further that $f(0) = 0, f'(x) \geq 0$ and that for every $x > 0$ $$|f(x) -x^2| \leq \varepsilon,$$ for some $\varepsilon > 0$ . Can we uniformly bound $$\sup_{x\geq 0}|f'(x)-2x|$$ in terms of $\varepsilon?$ If this is not possible? what can be said about $$\sup_{T\geq x\geq 0}|f'(x)-2x|,$$ for some fixed $T$ . Note that uniformly one cannot deduce uniform bounds on derivatives from uniform bounds on the functions. But I'm hoping that convexity can help here.","['inequality', 'convex-analysis', 'derivatives', 'uniform-convergence']"
3826817,"A way to list $1,\, 2,\, 3,\cdots,\, n$.","In how many ways can list the number $1,\, 2,\, 3,\cdots,\, n$ such that apart from the leading element the number $k$ can be placed only if either $k-1$ or $k+1$ already appears? Example: $324516$ , $435216$ , but not $351246$ . This is a problem in GTM A Course in Enumeration . And inspired by the textbook context, I want to solve the problem by applying ( Rule of Counting in Two Ways ). When two formulas enumerates the same set, then they must be equal. Define $d(i,\,k)$ be the number of permutation of $1,\,2,\cdots,\,n$ satisfies such property with $k$ in $i$ th position.
Then we have $$
d(1,\,1)=1,\quad d(1,\,n)=1
$$ and $$
\sum_{k=1}^{n}d(i,\,k)\quad\text{and}\quad\sum_{i=1}^{n}d(i,\,k)
$$ is the desired result for all $i,\,k=1,\,2,\cdots,\,n$ respectively. But I don't know how to go on.",['combinatorics']
3826825,sum of the series $(1+n)^{1/5} - n^{1/5}$ as $n$ tends to infinity,"The sum of the series ${(1+n)}^{1/5} - n^{1/5}$ when $n$ goes from 0 to infinity is
(A) less than -1
(B) equal to -1
(C) greater than 1 but less than 2
(D) none of the above When I expand the summation, all the terms of the series cancel each other and what we are finally left with is $(1+n)^{1/5} - 1^{1/5}$ . Here I have assumed $1 = 1^{1/5}$ and the series is $S = (1+n)^{1/5} - 1 $ now $n>0$ so $1+n > 1$ that implies $(1+n)^{1/5} > 1 $ so, $(1+n)^{1/5} - 1 > 0 $ If n goes to infinity then this sum is greater than 0 but we cannot be sure that it is less than 2.
so, I think (D) is the correct option.
Am I correct ?
please help me! Thanks.","['limits', 'telescopic-series', 'real-analysis']"
3826884,Describing an action on the Weyl group $W(T)=N_G(T)/T$ for different maximal tori $T$,"While trying to understand more the structure of reductive group, I came upon the situation that I describe below. I can't find a mistake in my dissertation, however I arrive to an absurd conclusion. Would somebody agree to read the following and tell me where I assumed something impossible / concluded something wrong ? Let $G$ be a connected reductive group over an algebraically closed field. Fix $T_0$ a maximal torus, and denote by $W_0:=W(T_0)=N_G(T_0)/T_0$ the associated Weyl group. Assume that there exists an element $w_0\in W_0$ of order $2$ which is not in the center of $W_0$ . Let $n_0\in N_G(T_0)$ be a representative of $w_0$ , and consider $\phi:G\xrightarrow{\sim} G$ the conjugation-by- $n_0$ automorphism. Naturally, the torus $T_0$ is $\phi$ -stable, and $\phi$ induces the conjugation-by- $w_0$ automorphism of $W_0$ . Let me now consider another maximal torus $T=\,^gT_0$ for some $g\in G$ . Associated to it, we have another description of the Weyl group $W:=W(T)=N_G(T)/T \simeq \, ^gW_0$ . Note that we also have $N_G(T) = \, ^gN_G(T_0)$ . We make the assumption that $T$ is also $\phi$ -stable, so that $\phi$ also induces an action on $W$ naturally. It means that $g^{-1}\phi(g)$ lies in $N_G(T_0)$ , I denote this element by $\tilde{n_0}$ . Eventually, I assume that $\tilde{n_0}$ also has image $w_0$ in $W_0$ . It implies that $\tilde{n_0}n_0$ lies in $T_0$ , because $w_0$ has order $2$ . Let me now look at the action of $\phi$ on $W$ . Let me consider $\nu\in N_G(T)$ and write $\nu=g\nu_0g^{-1}$ for some $\nu_0\in N_G(T_0)$ . I have $$\begin{align}
\phi(\nu)=\phi(g)\phi(\nu_0)\phi(g)^{-1} & = g\tilde{n_0}\,\phi(\nu_0)\,\tilde{n_0}^{-1}g^{-1}\\
& = g\tilde{n_0}\,n_0\nu_0n_0^{-1}\,\tilde{n_0}^{-1}g^{-1}\\
& = (g\tilde{n_0}n_0g^{-1})(g\nu_0g^{-1})(gn_0^{-1}\tilde{n_0}^{-1}g^{-1})
\end{align}$$ Because $\tilde{n_0}n_0$ lies in $T_0$ , both the first and last parentheses are in $^gT_0=T$ . Moreover, the middle parenthesis is just $\nu$ . Now, $\nu$ normalizes $T$ so we may rewrite it under the form $\nu\cdot \text{sth in }T$ .
This last observation means that $\phi$ acts like $\mathrm{id}$ on $W$ . But that is absurd : if it did, it would also act as identity on $W_0$ , meaning that $w_0$ would be in the center of $W_0$ , that is a contradiction. So, where has something gone wrong in my arguments ? Edit: An example, as demanded in the comments. I consider $G=\mathrm{GL}_n$ over an algebraically closed field $k$ with $\mathrm{char}(k)\not = 2$ , and I assume that $n=2k+1$ is odd. I consider $T_0$ the usual maximal torus consisting of diagonal matrices, and $W_0$ is identified with $\mathfrak S_n$ . I consider $w_0$ defined by the formula $w_0(i)=n+1-i$ . As a representative in $N_G(T_0)$ , I consider $n_0$ the matrix having antidiagonal filled with $1$ 's. Now, I put $$g = 
\begin{bmatrix}
1 &        &       &        &        &        & 1\\
  & \unicode{x22f1} &       &        &        & \unicode{x22F0} &  \\
  &        & 1     &        & 1      &        &  \\
  &        &       & 1      &        &        &  \\
  &        & 1     &        & -1     &        &  \\
  & \unicode{x22F0} &       &        &        & \unicode{x22f1} &  \\
1 &        &       &        &        &        & -1
\end{bmatrix} 
\quad 
g^{-1} =
\frac{1}{2}
\begin{bmatrix}
1 &        &       &        &        &        & 1\\
  & \unicode{x22f1} &       &        &        & \unicode{x22F0} &  \\
  &        & 1     &        & 1      &        &  \\
  &        &       & 2      &        &        &  \\
  &        & 1     &        & -1     &        &  \\
  & \unicode{x22F0} &       &        &        & \unicode{x22f1} &  \\
1 &        &       &        &        &        & -1
\end{bmatrix} 
$$ This shape is possible because $n$ is odd. The matrix $g$ is invertible because of the assumption on the characteristic. Its inverse is given by the matrix on the right. I may now compute $g^{-1}\phi(g)$ which gives me the antidiagonal matrix having coefficients, from bottom left to top right, $k$ times $-1$ and $k+1$ times $1$ . It is a generalized permutation matrix, so it lies in $N_G(T_0)$ . In means that $T:=\,^gT_0$ is stable by $\phi$ . Moreover, let us note that $\tilde{n_0}:=g^{-1}\phi(g)$ also is a representative of $w_0$ , just as in the situation I considered above. We may further compute $T$ explicitly. It is the subgroup (maximal torus) consisting of all cross-shaped invertible matrices (ie. with coefficients on the diagonals only) which are invariant under 180° rotation. Edit2: Partial answer and thoughts. I think that my mistake lies in ""if $\phi$ acts like $\mathrm{id}$ on $W$ then it must act like $\mathrm{id}$ in $W_0$ as well"". Say, generally speaking, that $\phi:G\rightarrow G$ is an endomorphism of $G$ having $T_0$ and $T:=\,^gT_0$ as two maximal $\phi$ -stable tori, so that $\tilde{n_0}:=g^{-1}\phi(g) \in N_G(T_0)$ . Assume also that $\phi$ acts like $\mathrm{id}$ on $W$ . It means precisely that $\forall \nu \in N_G(T), \;\nu^{-1}\phi(\nu)\in T$ . In terms of $T_0$ , it means that $\forall \nu_0\in N_G(T_0),\; \nu_0^{-1}\tilde{n_0}\phi(\nu_0)\tilde{n_0}^{-1}\in T_0$ . In other words, the composition of the conjugation by $\tilde{n_0}$ with $\phi$ induces the identity on $W_0$ . Thus, $\phi$ acts like conjugation by (the image of) $\tilde{n_0}^{-1}$ on $W_0$ , which may not be the identity. This is consistent with my situation above, where $\phi$ acts like conjugation by $w_0$ . The conclusion is that the action of an endomorphism on a Weyl group actually depends on the choice of the stable maximal torus ; that was unexpected for me.","['algebraic-groups', 'weyl-group', 'reductive-groups', 'algebraic-geometry', 'solution-verification']"
3826893,irreducibility of a certain polynomial,"$\alpha =\sqrt{-1+\sqrt{-2}}$ and $\beta =\sqrt{-1-\sqrt{-2}}$ are roots of irreducible polynomial: $$f(x)=x^{4}+2x^2+3$$ over $\mathbb{Q}$ . Since $\alpha ^{2}+\beta ^{2}=-2$ , I want to prove that $$irr(\beta, \mathbb{Q}(\alpha ))=x^{2}+\alpha ^{2}+2$$ But I can't prove irreducibility of $x^{2}+\alpha ^{2}+2$ over $\mathbb{Q}(\alpha )$ . Help me please. Thank you in advance!","['galois-theory', 'abstract-algebra']"
3826932,Is the $p$-norm of the fourier transform of a function greatest when its phase is constant?,"Suppose $f\in L^2$ and define $g\in L^2$ by $g(x) = \lvert f(x)\rvert$ . Based on numerical experiments I believe that $$ \Big\lVert\hat f\Big\rVert_p\leq\Big\lVert\hat g\Big\rVert_p$$ whenever $p\geq 4$ . How can I prove this? I do have a proof in the case when $p=2n$ for $n\in\mathbb Z$ . Then
we can write: $$\left\lVert \hat f\right\rVert_p = \left\lVert \hat
   f\right\rVert_{2n} = \left\lVert {\hat
   f}^n\right\rVert_{2}^{1/n}=\left\lVert f^{*n}\right\rVert_{2}^{1/n}$$ (using the convolution power ) and likewise $\left\lVert \hat
   g\right\rVert_p =\left\lVert g^{*n}\right\rVert_{2}^{1/n}$ . Then
since we have $$\lvert f^{*n}(x)\rvert=\left\lvert\int_{\sum x_i=x}f(x_0)\dots
   f(x_{n-1})\right\rvert\leq\int_{\sum x_i=x}\lvert f(x_0)\rvert\dots
   \lvert f(x_{n-1})\rvert=\lvert g^{*n}(x)\rvert$$ for all $x$ , we are done. So I'm interested in the more general case where $p$ is an arbitrary real number (greater than or equal to $4$ ). My numerical experiments were based on the discrete fourier transform. The requirement that $p\geq 4$ comes from the example $f = (1,-1,0)$ . Then $$\left\lVert\hat f\right\rVert_p=\left(\frac{\sqrt{3}^p+\sqrt{3}^p+0^p}3\right)^{1/p}$$ and $$\left\lVert\hat g\right\rVert_p=\left(\frac{2^p+1^p+1^p}3\right)^{1/p}.$$ Thus for this $f$ and $g$ , the inequality $ \Big\lVert\hat f\Big\rVert_p\leq\Big\lVert\hat g\Big\rVert_p$ holds only when $p\leq 2$ or $p\geq 4$ . The motivation for this question is to try to tighten the entropic uncertainty principle in quantum mechanics. The theorem would say that for a given position distribution and $n\geq 2$ , the Rényi entropy $H_n$ of the momentum distribution is minimized by the wavefunction with constant phase. (I do know how to prove that this wavefunction minimizes the variance of the momentum distribution, so it already gives a tightening of Heisenberg's uncertainty principle.)","['fourier-transform', 'lp-spaces', 'fourier-analysis', 'functional-analysis']"
3826953,"Are the numbers $\sqrt{n^2 + q^2}$, $n=0,1,\dots$, linearly dependent over $\mathbb{Q}$?","Let $q$ be a non-zero rational number, and consider the set of numbers $\sqrt{n^2 + q^2}$ , with $n=0,1,\dots$ . Are they linearly dependent over $\mathbb{Q}$ ? In other terms, can we find some positive integer $N$ and some rational numbers $a_0,\dots,a_N$ not all equal to zero, such that \begin{equation}
\sum_{n=0}^{N} a_N \sqrt{n^2 + q^2} = 0?
\end{equation} I found this statement in the post Linear Independence of Square Roots over Q , where the author of the post considers it ""evident"". For me, not only it is not evident at all, but I have some serious doubt that it is generally true.
What do you think about it? Thank you very much for your attention in advance. NOTE . Let us recall, in connection with this problem, that we have the following remarkable result. Theorem Let $n_1,\dots,n_k$ be square-free integers. Then the numbers $\sqrt{n_1},\dots,\sqrt{n_k}$ are linearly independent over $\mathbb{Q}$ if and onfly if $n_1,\dots,n_k$ are pairwise distinct. Elementary proofs of this result are given in Linear Independence of Radicals by Iurie Borieco, then a young pluri-medallist at the International Mathematical Olympiads.","['number-theory', 'elementary-number-theory']"
3827006,"Let $f(x)=3+x^2+\tan\frac{\pi x}2$, where $-1<x<1$. Find $(f^{-1})'(3)$","I am tasked with the following problem: Let $f(x)=3+x^2+\tan\frac{\pi x}2$ , where $-1<x<1$ . Find $(f^{-1})'(3)$ . However, when I attempt to find the inverse of the function, it seems that none can be formulated. I worked out that the derivative is $\frac{\pi \sec ^2\left(\frac{\pi x}{2}\right)}{2}+2x$ , but I find that both of these functions seem to head to infinity.","['calculus', 'inverse-function', 'derivatives', 'trigonometry']"
3827032,On the imaginary and real part of the eigenvalues of a real normal matrix.,"Let $A\in\mathbb{R}^{d\times d}$ be a real normal matrix . We can write $A=\frac{1}{2}(A+A^T)+\frac{1}{2}(A-A^T)$ . Can we show that the real part of $A$ 's eigenvalues are the eigenvalues of the symmetric $A+A^T$ and the imaginary part of $A$ 's eigenvalues are the eigenvalues of the skew symmetric $A-A^T$ ? It is claimed in another post that ""the real part of a normal matrix $A$ 's eigenvalues are $A+A^T$ "", however, there is no proof, and there is no claim on what happens with the imaginary part of the eigenvalues. Furthermore, it concerns complex normal matrices, I'm hoping the real case has a simpler proof.","['linear-algebra', 'complex-numbers', 'eigenvalues-eigenvectors']"
3827089,Simple proof for the result:$a$ is a removable singularity of $e^f$ iff $a$ is a removable singularity of $f$.,"Suppose $f$ is analytic in $0<|z-a|<R$ for some $R>0$ . Then $a$ is a removable singularity of $e^f$ $\iff$ $a$ is a removable singularity of $f$ . Proof :
that $a$ is a removable singularity of $f$ implies $a$ is a removable singularity of $e^f$ is clear. For the other direction:
for any $0<r<R$ ,
by the Argument Principle: $$\int_{|z-a|=r}\frac{\left(e^{f(z)}\right)'}{e^{f(z)}}\,dz
=\int_{|z-a|=r}f'(z)\,dz = 0,$$ and this implies that $e^{f(z)}$ has no zero at $a$ . If $e^{f(z)}$ has a removable singularity at $a$ ,
then $e^{f(z)}$ is analytic in the disk $|z-a|<R$ ,
and $$e^{f(a)}=\lim_{z\to a}e^{f(z)},\qquad e^{f(z)}\neq 0,\quad |z-a|<R.$$ Let $F(z)=e^{f(z)}$ , then $f'(z)=F'(z)e^{-f(z)}$ is analytic in $|z-a|<R$ .
So $f(z)$ has a removable singularity at $a$ . The proof above uses the ""Argument Principle"", it is seems to use a ""big"" tool to prove this ""small"" result.
What I want to say is that: is there a ""simple"" method to prove this ""small"" result,
any helps and hints will welcome!",['complex-analysis']
3827091,Looking for a combinatorial solution to a (seemingly) non combinatorial Putnam problem,"Putnam 1980, problem A4: Each of $a, b, c$ are integers and none have an absolute value greater than or equal to one million. Prove that $$
\left| a + b\sqrt2 + c\sqrt3\right| > 10^{-21}
$$ for any choice of $a, b, c$ . I would have never thought this would have anything to do with combinatorics or the pigeonhole principle but in the book 'Problem solving strategies' by Arthur Engel it's been included in the chapter on the pigeonhole principle. I would give an attempt but I have no idea. I thought about looking at the fractional parts of each of the three terms, but that didn't lead to anything.  If you have a solution please give hints and not the whole solution. Thank you","['contest-math', 'pigeonhole-principle', 'combinatorics']"
3827097,Derivative of Integral With Limits,"I have the following problem: Let $f(x) = \int_{3}^{x}\sqrt{1+t^3}\ dt$ . Find $(f^{-1})'(0)$ . I know that if $g' = f^{-1}(x)$ that $g'(f(x))f'(x) = 1$ . Obviously when $x$ is $3$ , $f(x)$ is $0$ . So I worked out that: $\displaystyle\ g’(f(3))f’(3)=1→ g'(0)=\frac{1}{f'(3)}→(f^{-1})'(0)=\frac{1}{\frac{d}{dt}[\int\sqrt{1+3^{3}}dt]}=\frac{1}{\sqrt{1+27}}$ $$=\frac{1}{\sqrt{28}}.$$ My question is: since $f(x)$ was originally an integral evaluated from $3$ to $x$ , shouldn't $x$ be $3$ across the equation, making the attempt to take the derivative of it useless? Would this result in the solution being ""not defined"" since you can't divide $(1)$ by zero? Or, does the derivative effectively nullify the limits?","['integration', 'calculus', 'inverse-function', 'derivatives']"
3827133,Atiyah-Macdonald: Exercise 1.8,"Let $A$ be a ring $\neq0$ . Show that the set of prime ideals of $A$ has minimal elements with respect to inclusion. I am trying to do this exercise from Atiyah-Macdonald. Attempt:
We should assume that there is no such minimal prime ideal. Then we have a chain $P_1 \supset P_2 \supset P_3 \supset ...$ . Then we should set $P= \bigcap_i P_i$ , This would be a minimal element but I can't see why it should be prime?","['abstract-algebra', 'commutative-algebra']"
3827188,How to give the sketch of a set,"I'm asked to give a sketch of this set: $K = \{(x,y)\in\mathbb R^2: 13x^2-10xy+13y^2=72\}$ and then give the points for which the distance from the origin is maximal/ will be maximal.  Please help me. I have no idea how to solve it. Thanks in advance","['analytic-geometry', 'graphing-functions', 'geometry']"
3827196,Actuarial Mathematics for Life Contingent Risks Questions $2.12.$ Part (b),"I am stuck on the following problem: (a) Construct a table of $Px$ for Makeham's law with parameters $A= 0.0001, B = 0.00035$ and $C = 1.075,$ for integer $x$ from age $0$ to age $130,$ using Excel or other appropriate computer software. You should set the parameters so that they can be easily changed, and you should keep the table, as many exercises and examples in future chapters will use Makeham's law. (b) Use the table to determine the age last birthday at which a life currently aged $70$ is most likely to die. I have found the solutions manual that solves part (b) in the most ""descriptive"" way to leave me still completely confused. I can't take anything from this to be able to use this to solve similar problems. Please help! ""The probability that $(70)$ dies at age $70 + k$ last birthday is $Pr[K70 = k]$ where $Kx$ is the curtate future lifetime. The most likely age at death is the value of $k$ that maximizes $Pr[K70 = k] = k\mid q70.$ The maximum value for $k \mid q70$ can be found by constructing a table of values and selecting the largest value; it is $3 \mid q70 = 0.05719,$ so the most likely age at death is $73$ "" I still have no idea how that was deemed as the largest value.","['actuarial-science', 'statistics']"
3827231,Finite State Automata,"it's been a while since I've done FSA's so I'm a little rusty, bear with me. I'm creating an FSA to parse Integer and Decimal tokens for a class. The two tokens have the regex Integer: $0|[1-9][0-9]^*$ \ Decimal: $(0|[1-9][0-9]^*).[0-9][0-9]$ Question Prompt: Draw one finite state automaton (FSA) which will scan INTEGER and DECIMAL tokens and discard all other characters read. Note that the scanner will be called repeatedly from the parser and therefore when a string such as 00 is scanned, the second 0 symbol should not be discarded by the scanner. There are a handful of constraints I have to meet which are: One FSA for both tokens Each type of token must be accepted by it's own single final state The automaton will halt on final states so there are no transitions starting from any final state For each final state, you must indicate next to the state which type of token it accepts and whether or not the last character read to enter the state should be consumed Every state in your FSA should have an ""other"" transition to capture what happens when any other character than the ones for which you already have a transition is read. So far I have been reviewing how FSA's work and have drawn up a pretty rough one that I know isn't correct. Note: The two connections leading to state $q5$ are ""."", it might be hard to see in the screenshot I did my best to combine the two expressions and come up with the above FSA. I'm aware that it probably isn't correct but I can't seem to figure out where to go from here. I appreciate any help I can get, I'd prefer if I wasn't just given the answer as I'd like to learn how to get to it myself :).","['automata', 'finite-state-machine', 'discrete-mathematics']"
3827235,"What Are the $x_i^*,y_j^*$ in the Riemann Sum Definition of the Double Integral?","the double integral $$\iint \limits_{[a,b] \times [c,d]} f(x,y) \, dxdy$$ can be represented with a Riemann Sum as $$\lim_{(\Delta x , \Delta y) \to (0,0)} \sum_{i=1}^n\sum_{j=1}^mf(x_i^*,y_j^*)\Delta x \Delta y$$ What are $x_i^*$ and $y_j^*$ in this case?","['integration', 'notation', 'multivariable-calculus', 'calculus', 'riemann-sum']"
3827270,How to determine if a field is a gradient field?,"What is a gradient field? If I have a scalar function : $$f(x,y)$$ and the derivative of the scalar function   i.e. the gradient of the function is : $$ \nabla f $$ Is it true that if $ \nabla f $ somehow equals the vector field only then can I call it a gradeint vector field?
I'm considerably new to this topic..so forgive me if this seems like a stupid question.
If I have a gradient that looks like $$<xy,y^2>$$ what would the original function look like? How do I know if the field is a gradient field.
Is it necessary that the fundamental theorem of line integral calculus : $$\int_C \overrightarrow {\nabla f}. \overrightarrow {dr} = f(P_1)-f(P_0)$$ where $P_1$ and $P_0$ are the final and initial points on the curve satisfies only if f is a gradient field.",['multivariable-calculus']
3827302,Last step in proof of countable stability of Hausdorff dimension,"In part of Kenneth Falconer's proof of the countable stability of Hausdorff dimension on p. 49, sect 3.2 of Fractal Geometry , I understand him to say that $$\dim_H \bigcup_{i=1}^{\infty}F_i\leq \sup_{1\leq i\leq\infty}\{\dim_H F_i\}\;,$$ because when $s>\dim_H F_i$ for all $i$ , ${\cal H}^s(F_i)=0$ , and thus $${\cal H}^s(\bigcup_{i=1}^{\infty} F_i) \leq \sum_{i=1}^{\infty}{\cal H}^s(F_i) = 0\;.$$ Here $\dim_H$ is Hausdoff dimension, and ${\cal H}^s$ is $s$ -dimensional Hausdorff measure. I understand everything after $s>\dim_H F_i$ above, but I'm confused about why ${\cal H}^s(\bigcup_{i=1}^{\infty} F_i) \leq \sum_{i=1}^{\infty}{\cal H}^s(F_i) = 0$ implies $\dim_H \bigcup_{i=1}^{\infty}F_i\leq \sup_{1\leq i\leq\infty}\{\dim_H F_i\}$ . I understand that Hausdorff dimension of a set $G$ is the Hausdorff measure for which ${\cal H}^s(G)$ is finite, such that for $s>\dim_H G$ , the Hausdorff measure is $0$ , and for $s<\dim_H G$ , the Hausdorff measure is infinite.  I don't see why the fact that ${\cal H}^s(\bigcup_{i=1}^{\infty} F_i) \leq 0$ for an $s$ that is larger than the dimension implies the first inequality above, which concerns a $\sup$ for Hausdorff dimensions that are possibly greater than $0$ .  I'm sure there must be something obvious that I'm not seeing. I've been thinking about it for a week and I'm still confused. This answer gives a detailed proof of the part I already understand, but leaves my question unanswered.","['measure-theory', 'hausdorff-measure', 'dimension-theory-analysis', 'real-analysis', 'fractals']"
3827307,Question about limit of a harmonic function,"I am trying assignments of complex analysis and need help in this particular question. Let $u(z)=\Im\frac{(1+z^2)^2}{(1-z^2)^2}$ . Show that $u$ is harmonic in $U$ , the unit disk centered at the origin. Show that $\lim\limits_{r\to 1} u(r e^{i\theta}) = 0$ for all $\theta$ . Why doesn't this contradict the maximum modulus principle for harmonic functions? For 1. I proved that it is harmonic by the definition that sum of partial derivatives wrt both $x$ and $y$ is $0$ . But is there any other way to prove that it is harmonic as using the definition involves a lot of calculations? For 2. I tried writing $z=r \sin\theta +i \cos\theta$ and putting $r = 1$ but I don't get zero; instead I get $\frac{i\sin\theta}{ 1+\cos\theta}$ . If I use the maximum modulus principle, I get LHS $=0$ and RHS $=\int_{0}^{2\pi} f(r e^{i\theta}$ ). I don't understand what contradiction one should expect if limit given above tends to $0$ and why there must be no contradiction? I request you to kindly shed some light on this.","['complex-analysis', 'limits', 'maximum-principle', 'harmonic-functions']"
3827308,Can the fundamental group and homology of the line with two origins be computed as a direct limit?,"Let $X$ be the line with two origins, the result of identifying two lines except their origins. Let $X_n$ be the result of identifying two lines except their intervals $(-\frac{1}{n},\frac{1}{n})$ . $X_n$ is a Hausdorff space that exists in $\mathbb{R}^2$ and is homotopic to a circle, and $X_{n+1}$ is naturally a quotient space of $X_n$ . I like to imagine that we have two zipper sliders gradually approaching each other without touching, which results in $X$ . Is this intuition correct, i.e., is $X$ is the direct limit of $X_1\rightarrow X_2\rightarrow\cdots$ , where the maps are quotient maps? I think I was able to show that if we have a directed diagram of quotient maps, the natural map from each space $X_i$ to the direct limit $X$ is also quotient map, and in our case this should imply the direct limit is same as line with two origins. If so, can we use this to get the homology and fundemental groups of $X$ ? I know that homology commutes with direct limits for nice spaces, such as increasing union of CW complexes, but I saw an example that this is not true in general; also we are having quotient maps but not inclusion here. I am aware of this question; just curious if the groups can be obtained by some abstract nonsense.","['limits-colimits', 'fundamental-groups', 'quotient-spaces', 'general-topology', 'algebraic-topology']"
3827318,Complex vector bundles associated to principal bundle on Riemann surface,"I'm reading the paper ""Self-Duality Equations on a Riemann Surface"" written by N.J.Hitchin in 1986. He is considering a principal $SO(3)$ bundle $P$ over a compact Riemann surface $X$ of genus $g\ge 2$ and he says we can always associate to $P$ a rank $2$ complex vector bundle $V$ . To be able to do this we have to consider two cases: The second Stiefel-Whitney class $w_2(P)$ is equal to zero $w_2(P)\neq0$ In the first case the condition is equivalent to requiring that the principal $SO(3)$ -bundle is spin and then there exist another principal bundle $\tilde{P}$ over $X$ whose structure group is Spin $(3)\cong SU(2)$ and to which we can associate a rank $2$ complex vector bundle $V$ with deg $(V):=\int_Xc_1(V)=0$ . Here I have my first question: Question 1 In this case the rank $2$ complex vector bundle $V$ associated to $\tilde{P}$ is given by $ad(\tilde{P}):=\tilde{P}\times_{SU(2)}\mathfrak{\mathfrak{su}(2)}$ ? Where $\mathfrak{su}(2)$ is the Lie algebra of $SU(2)$ . Moving on to the second case, Hitchin says that if $w_2(P)\neq0$ then there exist a $U(2)$ -principal bundle $\bar{P}$ to which $P$ is associated via the homomorphism $U(2)/Z(U(2))\simeq SO(3)$ . Associated to $\bar{P}$ is a rank $2$ complex vector bundle $V$ with odd degree. Question 2 How can we associate the bundle $\bar{P}$ to $P$ following Hitchin? I really do not understand the construction in the latter case. Thank you if anyone could help.","['algebraic-topology', 'complex-geometry', 'vector-bundles', 'lie-groups', 'differential-geometry']"
3827386,Annihilator in infinite dimensional vector space,"I am working on the following question: Consider $U$ and $W$ subspaces of a finite-dimensional vector space $V$ . Show that $$(U \cap W)^{0} = U^{0} + W^{0}$$ Is it necessary for the $V$ dimension to be finite? I proved that $(U \cap W)^{0} = U^{0} + W^{0}$ and I know that it is necessary that the dimension of $V$ be finite so that $(U \cap W)^{0} \subset U^{0} + W^{0}$ , but I can't find a counterexample show this inclusion fails if the dimension of $V$ is infinite. Can someone help me? Thank you in advance.","['linear-algebra', 'vector-spaces', 'dual-spaces']"
3827409,$q$-expansion of Klein's absolute invariant using infinite products,"Given that $$j=\frac{1}{13824q^2}\left(2^8q^2\prod_{k\gt 0}(1+q^{2k})^{16}+\prod_{k\gt 0}(1+q^{2k-1})^{16}+\prod_{k\gt 0}(1-q^{2k-1})^{16}\right)^3,$$ how can I show that $$j=\frac{1}{1728q^2}(1+c_1 q^2+c_2 q^4+\cdots)$$ where $c_1,\, c_2,\, \ldots$ are some constants? I'm interested in the first term, i.e. $\frac{1}{1728q^2}$ . I tried expanding the product, which gives $$j=\frac{1}{13824q^2}\left(2^{24}q^6\prod_{k\gt 0}(1+q^{2k})^{48}+3\cdot 2^{16}q^4\prod_{k\gt 0}(1+q^{2k})^{32}(1+q^{2k-1})^{16}+3\cdot 2^{16}q^4\prod_{k\gt 0}(1+q^{2k})^{32}(1-q^{2k-1})^{16}+3\cdot 2^{16}q^4\prod_{k\gt 0}(1+q^{2k})^{16}(1+q^{2k-1})^{32}+6\cdot 2^8q^2\prod_{k\gt 0}(1+q^{2k}-q^{4k-2}-q^{6k-2})^{16}+3\cdot 2^8 q^2\prod_{k\gt 0}(1+q^{2k})^{16}(1-q^{2k-1})^{32}+\prod_{k\gt 0}(1+q^{2k-1})^{48}+3\prod_{k\gt 0}(1+q^{2k-1})^{32}(1-q^{2k-1})^{16}+3\prod_{k\gt 0}(1+q^{2k-1})^{16}(1-q^{2k-1})^{32}+\prod_{k\gt 0}(1-q^{2k-1})^{48}\right).$$ Expanding doesn't seem to help. But I know that the expression above can be written as $$j=\frac{1}{13824}\frac{(\theta _2 ^8(0)+\theta _3 ^8(0)+\theta _4 ^8(0))^3}{q^2\prod_{k\gt 0}(1-q^{2k})^{24}}$$ where $$\begin{align}\theta _2(0)&=2Pq^{\frac{1}{4}}\prod_{k\gt 0}(1+q^{2k})^2\\ \theta _3(0)&=P\prod_{k\gt 0}(1+q^{2k-1})^2\\ \theta _4(0)&=P\prod_{k\gt 0}(1-q^{2k-1})^2\end{align}$$ where $P=\prod_{k\gt 0}(1-q^{2k})$ and $$\theta _2 ^8(0)+\theta _3 ^8(0)+\theta _4 ^8(0)=\frac{3}{\pi ^4}(e_1 ^2+e_2 ^2+e_3 ^2).$$ The symbol $q$ is the nome $e^{\pi i\frac{\omega _1}{\omega _2}}$ and $e_1=\wp \left(\frac{\omega _1}{2}\right)$ , $e_2=\wp \left(\frac{\omega _2}{2}\right)$ and $e_3 =\wp \left(-\frac{\omega _1+\omega _2}{2}\right)$ for the Weierstrass's elliptic function $\wp$ .","['complex-analysis', 'modular-function', 'q-series', 'infinite-product']"
3827422,How do we know that group representations exist?,"Given a finite group $G$ , how do we know that there exists a map $\rho: G \rightarrow GL(V)$ such that $\rho(g_1\circ g_2) = \rho(g_1).\rho(g_2)$ for any $g_1, g_2\in G$ ? Intuitively, why does matrix multiplication always capture the properties of a group?","['representation-theory', 'group-theory', 'linear-algebra']"
3827544,Recurrence relation between two series,"The problem asks to prove that $$\sum_{n=1}^{\infty}\frac{(-1)^{n-1}}{n^2(n+1)^2\ldots(n+p-1)^2} = \frac{5p+2}{4(p+1)}\frac{1}{p!^2}-\frac{p(p+1)^3}{4}\cdot\sum_{n=1}^{\infty}\frac{(-1)^{n-1}}{n^2(n+1)^2\ldots(n+p+1)^2}$$ where $p$ is a natural number.
How can I show that this equation holds? I think that this follows from a Kummer transformation , which I briefly describe here: usually we want to accelerate the convergence of a given series $a_n$ by means of the following obvious transformation: $$\sum a_n = \gamma C + \sum\left(1-\gamma\frac{c_n}{a_n}\right)a_n$$ where $c_n$ is a convergent series of known sum $C$ such that $a_n/c_n \to \gamma \ne 0 $ (a finite number) as $n\to +\infty$ ; usually $c_n$ is chosen as much close to $a_n$ as possible, to make the convergence more rapid. In this particular example, I tried $c_n = (n+y)a_n-(n+2+y)a_{n+2}$ (which is a telescoping series, thus $C$ is easy to compute) with $y$ to determine such that the sum on the right hand side of the kummer transformation is close to the right hand side of my equation. This choice for $c_n$ is tyipical in other scenarios, but it doesn't really work here. What should be a proper choice? Also, can I approach the problem from another point? Finally let me point out that this equation is a recurrence relation if we let $T_p$ be the sum of the first series. An interesting problem would be to determine the relation between $T_1$ and $T_{2k+1}$ for example, which leads to other potential transformations...","['sequences-and-series', 'real-analysis']"
3827581,$4$-manifold with fundamental group $\Bbb Z/4\Bbb Z$,"Before I write my question, I want to write some thoughts. Let $M$ be a connected topological manifold such that $\pi_1(M)=\Bbb Z/3\Bbb Z$ . Then, considering its orientation $2$ -fold cover, which is connected, I can say $M$ is orientable. Now, an example of such a closed $3$ -manifold is $L(3,1)$ . Now, this type of argument can not be given if I consider $\pi_1(M)=\Bbb Z/4\Bbb Z$ to conclude $M$ is orientable. But Euler characteristic of an odd-dimensional closed manifold is always zero, so we cannot say $\Bbb Z/4\Bbb Z$ is the fundamental group of any closed connected non-orientable $3$ -manifold, as $H_1(M,\Bbb Z)$ is infinite when $M$ is closed non-orientable connected $3$ -manifold. Again this logic can not be given for $4$ -dimensional closed connected manifold. So, I am wondering if the following fact. I assume closed means compact without boundary. Does there exist closed connected $4$ -manifolds both orientable and
non-orientable type having fundamental group $\Bbb Z/4\Bbb Z$ ? Any help will be appreciated.","['homotopy-theory', 'differential-topology', 'low-dimensional-topology', 'algebraic-topology', 'differential-geometry']"
3827601,"Give an example of a set with full Lebesgue measure on $[0,1]$ that is also a countable union of nowhere dense sets.","I was asked to prove or give a counterexample of the statement. Assume $P$ is a subset of $[0,1]$ with Lebesgue measure equal to $1$ . Then $P$ is not a countable union of nowhere dense sets. I find that there are nowhere dense sets with positive measure. So I am not able to derive this from subadditivity.","['measure-theory', 'real-analysis']"
3827642,Epsilon Delta proof for rational function containing radicals,"I am having trouble constructing the delta-epsilon proof for this limit. I am currently trying to find the delta in terms of epsilon: $$\lim_{x \to 1} \frac{x^3-1}{\sqrt{x}-1}$$ So far I have gotten to $$6-\epsilon < (x-1)*\frac{x^2+x+1}{\sqrt{x}-1} < 6+\epsilon$$ I am having trouble bounding the fraction $\frac{x^2+x+1}{\sqrt{x}-1}$ so that I can isolate $x-1$ and find the delta. It has a vertical asymptote at x=1, which makes it difficult to find an upper/lower bound. Am I on the right track to this problem? If not, how would I go about finding the delta?","['limits', 'calculus', 'algebra-precalculus', 'epsilon-delta']"
3827668,Finite union of Noetherian topological spaces is Noetherian,"Suppose $X_1,...,X_n\subset X$ , and each $X_i$ is a Noetherian topological space (with the induced topology). Thats is, each of them satisfies the descending chain condition for closed subsets. I'd like to understand why $\bigcup_{i=1}^nX_i$ is also Noetherian (with the induced topology). I saw this result here but without the proof included, and I want to make sure I have the right idea. Is this just because, if we have a chain of sets $Z_i$ closed in $\bigcup_{i=1}^nX_i$ , then each $Z_i$ is closed in each $X_i$ and so we use the descending chain condition for the $X_i$ s?","['algebraic-geometry', 'general-topology', 'abstract-algebra', 'commutative-algebra']"
3827693,Fibonacci-like sequences mod $p$ where $a_{n+1}$ only really depends on $a_n$.,"Consider a prime $p$ and a sequence $(a_n)_{n\ge 0}$ in $\mathbb{F}_p$ satisfying $a_{n+2}=a_{n+1}+a_n$ for all $n\ge 0$ . Now, assume that each element of the sequence only really depends on the previous one. That is, assume there exists a function $f:\mathbb{F}_p\to\mathbb{F}_p$ such that $a_{n+1}=f(a_n)$ for all $n\ge 0$ . If $p\not\in\{2,5\}$ and $5$ is a quadratic residue mod $p$ there are the obvious sequences $$\left(c\left[\frac12+\frac12\sqrt5\right]^n\right)_{n\ge 0}\quad\text{and}\quad\left(c\left[\frac12-\frac12\sqrt5\right]^n\right)_{n\ge 0}$$ for $c\in\mathbb{F}_p$ any constant, but are there any others? Computational results by @Servaes Let's call two Fibonacci-like sequences modulo $p$ equivalent if they can be turned into each other through shifting and multiplication by units, then any sequence where each element is a function of the previous and and which is not equivalent to $$(0)_{n\ge 0},\quad (c^n)_{n\ge 0}$$ where $c^2=c+1$ , is called strange . @Servaes has shown through computation that the first few primes for which strange sequences exist are $$199, 211, 233, 281, 421, 461, 521, 557, 859, 911.$$ Own work For any prime $p$ let $\pi(p)$ be the Pisano period mod $p$ (so this is not the prime counting function) Claim: Let $p$ be a prime, $(a_n)_{n\ge 0}$ a strange sequence. Then it has period $\pi(p)$ . Proof: Let $A=\{a_n:n\ge 0\}$ be the set of attained values and $f:A\to A$ the function which makes this sequence strange, in the sense that $a_{n+1}=f(a_n)$ for all $n\ge 0$ . Clearly, $f$ is a bijection. It is easily proved that, for all $a\in A$ and $n\in\mathbb{Z}$ , $$f^n(a)=F_{n-1}a+F_nf(a).$$ Let $m$ be the period of $(a_n)_{n\ge 0}$ , then clearly $m$ is the smallest positive integer $n$ for which $f^n=\operatorname{id}_A$ . Thus, for all $a\in A$ , $$(1-F_{m-1})a=F_mf(a)$$ If $F_m\neq 0$ it follows that $f(a)=F_m^{-1}(1-F_{m-1})a$ and the sequence is equivalent to $\left(c^n\right)_{n\ge 0}$ where $c=F_m^{-1}(1-F_{m-1})$ satisfies $c^2=c+1$ . This contradicts our assumption that the sequence is strange, so $F_m=0$ . Since the sequence is not the null sequence, we may take $a\in A$ non-zero and conclude that $F_{m-1}=1$ . It follows that $\pi(p)\mid m$ . Since $$f^{\pi(p)}(a)=F_{\pi(p)-1}a+F_{\pi(p)}f(a)=F_{-1}a+F_0F(a)=a,$$ the opposite division relation holds as well and we are done. EDIT: I asked a slightly more general version of this question on Mathoverflow and linked to this question, but forgot to link the Mathoverflow question here.","['fibonacci-numbers', 'number-theory', 'finite-fields', 'elementary-number-theory', 'recurrence-relations']"
3827696,Integral Manifolds of the Symplectic Foliation,"Let $(M,\pi)$ be a Poisson manifold. Denote by $\pi^*:T^*M \rightarrow TM$ , the induced bundle map. In the simple case, where the Poisson bivector is of constant rank, we obtain a smooth regular foliation of M, i.e. $Im\pi^*$ , whose leaves are actually symplectic submanifolds. In the case that $\pi$ is not of constant rank, we obtain a (singular) symplectic foliation of the underlying manifold. I am trying to figure out the details of this foliation. The construction of the leaves for the singular foliation is the following: First one observes that the distribution $Im(\pi^{*})$ has integral manifolds. Let $x\in M$ and $\big(U,(p_i,q^i,x^s)\big)$ be the Darboux-Weinstein coordinates centered at $x$ . Then, the submanifold $S=\{x^s=0\}$ is an integral submanifold containing x. The second step is to show that the integral manifolds of $Im(\pi^*)$ are actually weakly embedded submanifolds and that the connected components of the intersection of two integral manifolds are also integral manifolds. Lastly, for a point $x_0 \in M$ we take the union of all integral manifolds containing it, and use a gluing lemma for weakly embedded submanifolds to show that this union is the maximal integral manifold containing $x_0$ , i.e the symplectic leaf of the foliation that contains $x_0$ . In order to prove the second step, we use the following lemma: Lemma : Let N be an integral manifold, $x\in N$ and $\big(U,(p_i,q^i,x^s)\big)$ the Darboux-Weinstein coordinates at $x$ . Then the following hold: i)The connected components of $N \cap U$ are contained in the slices $\{x^s=constant\}$ . ii) If $N'$ is another integral manifolds containing $x$ then the connected component of $N\cap N'$ containg $x$ is an integral manifold. I am stack at the two arguments that prove the Lemma: For i) it is  claimed that it suffices to show that $N\cap \{x^s=constant\}$ is both open and closed in $N\cap U$ . I do not see why this is sufficient. Then, it is claimed that ii) follows from i) since the slices $\{x^s=const.\}$ and integral manifolds have the same dimension. My intuition on this tells me that we are fine, since the tangent spaces at the intersection overlap nicely but what is the smooth manifold structure on $N \cap N'$ ? Any help to clear things out is deeply appreciated!","['symplectic-geometry', 'poisson-geometry', 'differential-geometry']"
3827704,Weird patterns in order of sums of elements in cyclic groups,"this is my first time posting so if I make mistakes, I'm very sorry. For my homework in abstract algebra I was asked to basically calculate the order of elements $a$ and $b$ , and then the order of $a+b$ in $\mathbb{Z}_{12}$ . After doing the homework, I got curious about patterns in this, and noticed that $$Q\equiv\frac{\operatorname{lcm}(|a|,|b|)}{|a+b|}\in\mathbb{N}$$ Basically, not only is it a whole number, it seems to always divide the order of the group, so if we are in $\mathbb{Z}_n$ , then $Q$ divides $n$ . I'm not sure why this is. I got more curious and decided to make a heat map of all of the values of $Q$ for any combination of elements $a$ and $b$ in the group. I let the order be $144$ , and this is what I got: Q144 In this, black is equivalent to 1, the lowest number. The higher the value, the hotter. White is equal to the order of the group.
It's worth noting that this is very composite, so I wondered what happened when the order was prime, and here's what I got for order 53: Q53 Very strange patterns I'm seeing, any ideas why this is? I don't know much about group theory (since I'm taking a class in it), so any insight would be much appreciated :)","['elementary-number-theory', 'group-theory', 'abstract-algebra', 'cyclic-groups']"
3827742,Prove that $\lim_{x \to 2} 5x^2 = 20$ using $\epsilon - \delta$ definition.,"Working on the book: Richard Hammack. "" Book of Proof "" (p. 259) Example 13.2 Prove that $\lim_{x \to 2} 5x^2 = 20$ . Proof. Suppose $\epsilon$ > 0. Notice that $$
| f(x) - L| = |5x^2 - 20| = |5(x^2 - 4)| = |5(x - 2)(x + 2)| = 5 · |x-2| · |x + 2|.
$$ Now we have a factor of $|x-2|$ in $|f(x)-L|$ , but it is accompanied with $|x+2|$ . But if $|x-2|$ is small, then $x$ is close to 2, so $|x+2|$ should be close to 4. Now, the author assumes $|x-2| \leq 1$ In fact, if $|x-2| \leq 1$ , then | $x+2| = |(x-2)+4| \leq |x-2|+|4| \leq 1+4 = 5$ . (Here we applied the inequality (13.2) from page 245.) In other words, if $|x - 2| \leq 1, \text{then } |x + 2| \leq 5$ , and the above equation yields $$
| f (x) - L| = |5x^2 - 20| = 5 · |x - 2| · |x + 2| < 5 · |x - 2| · 5 = 25|x - 2|.
$$ Take $\delta$ to be smaller than both 1 and $\frac{\epsilon}{25}$ . Then $0<|x-2|<\delta$ implies $|5x^2-20|<25·|x-2|<25\delta<25\frac{\epsilon}{25}=\epsilon$ . By Definition 13.2, $\lim_{x \to 2} 5x^2 = 20$ My questions are: Where does the assumption $|x-2| \leq 1$ come from and how it gets discharged ? I wonder if the author is really proving $\forall \epsilon > 0 ( \exists \delta > 0(|x-c| < \delta \Rightarrow (|x-c| \leq 1 \Rightarrow |f(x) - f(c)| < \epsilon)))$ . Perhaps, I am wrong but it is not possible to add that assumption as a premise, as arbitrary variable $x$ appears after the introduction of $\delta$ .","['epsilon-delta', 'proof-explanation', 'logic', 'real-analysis', 'limits']"
3827758,$f\in L^1$ iff $\sum\limits_{i\in\mathbb{N}}2^n\mu(A_n)<\infty$,"I want to show that the measurable function $f:[0,1]\to\mathbb{R}^+$ is in $L^1([0,1])$ if and only if $$\sum\limits_{i\in\mathbb{N}}2^i\mu(A_i)<\infty$$ for $$A_i:=\{x\in[0,1]\mid 2^i\leq f(x)<2^{i+1}\}.$$ I saw a similar example here but I didn't fully understand what was going on there. If I define the function $$g(x):=\sum_{i\in\mathbb{N}}2^i\chi_{A_i},$$ where $\chi_{A_i}$ is the indicator function, then I basically have to show $$\int_{[0,1]}|f|\,\mathrm{d}\mu<\infty\iff\int_{[0,1]}g\,\mathrm{d}\mu<\infty.$$ I'm not sure how to continue here, but I thought about expressing $f$ in a sum of indicator functions on $A_i$ and then estimating the sum ? Any hints would be appreciated. Thanks :)","['measure-theory', 'lebesgue-measure', 'probability', 'real-analysis']"
3827761,"If $A \times B$ is finite, does it follow that $A$ and $B$ are finite?","Problem : If $A \times  B$ is finite, does it follow that $A$ and $B$ are finite? Note : $A \times  B$ is the cartesian product. If $A \times  B$ is empty, we may not be able to say that If $A$ and $B$ are finite because one may be empty and the other may be infinite. An example of this case would be if $A = \mathbb{R}$ and $B=\emptyset$ . Then, $A \times  B = \mathbb{R} \times \emptyset=\emptyset$ . Note that this $\emptyset$ denotes empty set. However, if $A$ and $B$ are both nonempty and $A \times  B$ is finite, then both $A$ and $B$ are finite. My Try : Now I want to try to apply a Corollary which states Let $B$ be a nonempty set. Then the following are equivalent $B$ is finite There is a surjective function from a section of the positive integers onto $B$ There is an injective function from $B$ into a section of positive integers. Now applying this Corollary from $(3)\Rightarrow (1)$ . Suppose that $A \times  B$ is finite. Then, there is an injective function: $f: A \times B \to S_n$ where $S_n$ , denotes a set of positive integers less than $n$ . Let $B \neq \emptyset $ . Then $f : A \times \{b\} \to S_n$ , is an injective function for a fixed $b \in B$ . Then changing the range of $f$ gives a bijection of $ A \times \{b\}$ with a subset of $S_n$ . It then follows that $A$ is finite. Similarly, if $A\neq \emptyset$ , then $B$ is finite. Am I so far correct?",['elementary-set-theory']
3827831,Mixed partial derivatives of planar functions converging to delta distribution,"Given a sequence $(f_k)_{k\in\mathbb{N}}\subset C^2(\mathbb{R}^2)$ of strictly positive functions $f_k\equiv f_k(x,y)$ with $\|f_k(x,\cdot)\|_{L^1}=1$ for all $x\in\mathbb{R}$ , such that for each $x\in\mathbb{R}$ we have $$\tag{1} \lim_{k\rightarrow\infty} f_k(x,\cdot) = \delta_x \qquad\text{ in the distributional sense},$$ with $\delta_x$ the delta distribution at $x$ . (The 'heat kernel' $f_k:=\frac{k}{4\pi}e^{-k(x-y)^2/4}$ is an example of such a sequence.) Question: Is the above enough, I wonder, to infer that for infinitely many $k\in\mathbb{N}$ , the mixed derivatives $\partial_y\partial_x\log(f_k)$ vanish (almost) nowhere on the diagonal $\Delta:=\{(x,x)\mid x\in\mathbb{R}\}$ ? Intuition : Let $k\in\mathbb{N}$ and $x_0\in\mathbb{R}$ be fixed, and $\delta>0$ be small. Considering the restriction of $f_k$ to the square $\mathcal{R}:= B_\delta(x_0)\times B_\delta(x_0)$ with $y$ -sections $\mathcal{R}_y:= B_\delta(x_0)\times\{y\}$ , we by $(1)$ find the functions $\phi_k^y := \left.f_k\right|_{\mathcal{R}_y}$ to 'bulk' increasingly (with $k$ ) at the point $(y,y)$ and 'flatten sharply' on $\mathcal{R}_y\setminus\{(y,y)\}$ . Consequently, the (monotonic) transformations $\varphi_k^y:=\log(\phi^y_k)$ show a 'rapid decay (as $k\rightarrow\infty$ ) below zero' on $\mathcal{R}_y\setminus\{(y,y)\}$ . This suggests that (for $k$ large enough) we have $\psi_k^y:= \left.\partial_x(\varphi_k^y)\right|_{x=x_0}>0$ for $y>x_0$ , and $\psi_k^y<0$ for $y<x_0$ , so that $\left.\partial_y[\partial_x\log(f_k)]\right|_{(x,y)=(x_0, x_0)} = \partial_y(\left.\psi_k^y)\right|_{y=x_0} > 0$ , provided that $(1)$ guarantees that $\lim_{h\rightarrow 0^+}\frac{\psi_k^{x_0+h} - \psi_k^{x_0-h}}{2h}>0.$ Do you see a way to put this intuition into a rigorous proof? (Or is it wrong altogether and the claim doesn't hold?)","['distribution-theory', 'real-analysis', 'multivariable-calculus', 'partial-differential-equations', 'partial-derivative']"
3827858,Prove that for A $\subseteq$ B int(A) $\subseteq$ int(B) and cl(A) $\subseteq$ cl(B).,"I have to prove that for A $\subseteq$ B, int(A) $\subseteq$ int(B)and cl(A) $\subseteq$ cl(B). I hope someone here can help me out, and I apologize for any obvious mistakes. So here is my approach. By definition, the interior of B int(B) is the largest open set contained in B. It is the union of all open sets in B: $int(A)=_{W\subseteq A:\ W\;is\;closed}W$ . Thus if int(B) $\subseteq$ B and A $\subseteq$ B, then int(A) $\subseteq$ int(B). By definition, cl(B), is the smallest closed set containing B. It is the intersection of all closed sets containing B. Thus it must hold that cl(A) $\subseteq$ cl(B), as A $\subseteq$ cl(A) and B $\subseteq$ cl(B), with A $\subseteq$ B.","['elementary-set-theory', 'general-topology', 'proof-writing', 'solution-verification']"
3827896,"Prove that there is a function $F$ from $[0, 1]$ to circle with radius 1, that $|Area(Im(F))-\pi| < \frac{1}{n}$ and $Im(F)$ is a regular polygon.","I was doing the OMU test ( https://www.olimpiada.ime.unicamp.br/ ), witch is already done (just to be clear), and came across the following question: Consider $C$ the circle with center in $(0, 0)$ and radius r = 1, that
is: $$C = \{(x, y) : x^2 + y^2 \leq 1\}$$ Given any natural number $n> 0$ , show that there is a function $F:[0, 1]\longrightarrow C$ so
that: The image set of $F$ , denoted by $Im(F)$ is a regular polygon with at
least n sides and (I) $|Area(Im(f)) - \pi| < \frac{1}{n}$ is true (II) Here is what I made: If $Im(F)$ describes a poligon with p sides inscribed in $C$ and $p\longrightarrow \infty$ , (II) is true, because the polygon area tends to be equal to circle area. So: \begin{gather}
                |\lim_{p\rightarrow \infty} Area(Im(f))-\pi| < \frac{1}{n} \\
                |(\pi*1)-\pi| < \frac{1}{n}\\
                0 < \frac{1}{n}\quad (true)
            \end{gather} And (I) is true because: $$[0, 1]\sim\mathbb{R}^2$$ and $$\mathbb{R}^2\supseteq C \supseteq Im(f)$$ So there is a injection function from $[0, 1]$ to $Im(F)$ no matter $Im(F)$ . Have I made every thing right? And this was from the high school level so I supose there is another simplier way to solve, am I right? Could anyone help me?","['elementary-set-theory', 'analytic-geometry', 'geometry']"
