question_id,title,body,tags
2882257,Finding Geometric Probability?,Four points are chosen at random from the interior of a circle. What is the probability that the sum of each of their distances from the center is greater than half the circumference of the circle? I don't even know how to begin this problem. Any hints would be greatly appreciated.,"['geometry', 'probability']"
2882265,Optimal strategy for cutting a sausage?,"You are a student, assigned to work in the cafeteria today, and it is your duty to divide the available food between all students. The food today is a sausage of 1m length, and you need to cut it into as many pieces as students come for lunch, including yourself. The problem is, the knife is operated by the rotating door through which the students enter, so every time a student comes in, the knife comes down and you place the cut. There is no way for you to know if more students will come or not, so after each cut, the sausage should be cut into pieces of approximately equal length. So here the question - is it possible to place the cuts in a manner to ensure the ratio of the largest and the smallest piece is always below 2? And if so, what is the smallest possible ratio? Example 1 (unit is cm): 1st cut: 50 : 50     ratio: 1 2nd cut: 50 : 25 : 25   ratio: 2 - bad Example 2 1st cut: 40 : 60              ratio: 1.5 2nd cut: 40 : 30 : 30            ratio: 1.33 3rd cut: 20 : 20 : 30 : 30    ratio: 1.5 4th cut: 20 : 20 : 30 : 15 : 15  ratio: 2 - bad Sorry for the awful analogy, I think this is a math problem but I have no real idea how to formulate this in a proper mathematical way.","['fair-division', 'recreational-mathematics', 'logic', 'combinatorics']"
2882276,Interesting questions (with answers) about concepts in topology for an amateur audience,"I have been asked to hold an introductory math quiz for the Freshmen batch in my college. It entails interesting questions about different areas of mathematics presented in such a way so that it seems it has nothing to do with that area of mathematics. An example of such a problem is the Futurama Theorem. These questions should not be in a language which involves terms from topology (like topological spaces, homeomorphism, etc) considering the amateur audience for whom this is being presented. Personally I haven't been able to find any such questions except a few which involves showing equivalence of different knots.","['education', 'general-topology', 'big-list', 'algebraic-topology']"
2882308,"Help with the notation $(x,t)\in \mathbb R^n \times (0,\infty)$","What is the meaning of $$(x,t)\in \mathbb R^n \times (0,\infty)\quad ?\tag 1\label1$$ I guess $x$ is a $n$-vector and $t$ is just a scalar, i.e. 
\begin{align}
x&=(x_1, x_2, \dots, x_n)\in \mathbb R^n \tag 2\\
t&\in (0,\infty) \tag 3
\end{align} Attempt 1: Does \eqref{1} mean I have , i.e.
\begin{align}
(x_1, t),  (x_2,t), \dots, (x_n,t) \tag 4
\end{align}
I.e. $n$ number of points in $\mathbb R^2$ (I guess?). Attempt 2: Or does \eqref{1} mean 
\begin{align}
(x_1, x_2, \dots, x_n,t) \tag 5
\end{align}
I.e. just one point. But how many dimensions?","['elementary-set-theory', 'multivariable-calculus', 'notation', 'vectors']"
2882365,Are all numbers of the type $\frac{n!}{2}+1$ deficient?,"Are all numbers of the type $\frac{n!}{2}+1$ deficient? Deficient numbers are such numbers $k$, that the divisor sum of $k$ is less than $2k$. I checked all numbers of this type, with $n$ ranging from $1$ to $11$. They really are. However, I do not know, how to prove this statement in general. Probably, it has something to do with $\frac{n!}{2}+1$ being coprime with all numbers that do not exceed $n$, thus making it a number without small prime divisors. But probably, that fact is not that helpful either... Any help will be appreciated.","['number-theory', 'divisor-sum', 'factorial', 'elementary-number-theory']"
2882377,Doubts regarding $\epsilon$-$\delta$ definition of limits,"I am learning $\epsilon$ - $\delta$ definition of limits. I was confused on a few points and read some of the related answers on this and other sites. But I couldn't find discussion on any of these questions anywhere, so I am asking them here. The questions are- Why should $|x-c|<\delta$ imply $|f(x)-L|<\epsilon$ ? Can't it be the other way round? That is, would this be wrong definition: "" Let $f$ be a function defined on an open interval around $c$ (except possibly at $c$ ). Then, if for any $\epsilon>0$ there exists a $\delta > 0$ such that $0< |x-c|<\delta$ whenever $|f(x)-L|<\epsilon$ ; then $$\lim_{x \to c} f(x) = L$$ ""? 2  Why do we choose open intervals around $x$ and $f(x)$ instead of closed ones (i.e. $x \in (x-\delta,x+\delta),f(x) \in (f(x)-\epsilon,f(x)+\epsilon)$ instead of $x \in [x-\delta,x+\delta],f(x) \in [L-\epsilon,L+\epsilon]$ ) ? Why are $\delta$ and $\epsilon$ chosen to be greater than zero? Can't we choose them to be less than zero and specify the bounds of $x$ and $f(x)$ thus: $\delta < x-c< -\delta$ and $\epsilon < f(x) - L < -\epsilon$ ? My guess is that the answer to the points 2 & 3 should be: It is just by convention . But I have no source to back it up. I couldn't find any discussion on this anywhere. Not in my textbook, nor on Wikipedia or other sites. So, what are the answers to these questions? EDIT: If someone says that we can make the choices I suggested in points 2 & 3 too (instead of the ones we do currently), and so the latter are just historical conventions, please cite the source for your statement.","['epsilon-delta', 'real-analysis', 'calculus', 'definition', 'limits']"
2882378,Symmetric random walk passes through 1,"I am working on the following problem (which I couldn't find on the website so far): Show that a symmetric random walk ($1$ dimensional) starting from the origin visits the point $1$ with probability $1$. My attempt so far (an adaptation of the recurrence proof from Probability An Introduction $2^{nd}$ edition by Grimmett and Welsh -p.170). Let $S_n$ be the r.v. which represents where (on the $X$-axis) the random walk is at time $n$. And let $X_n$ be the random variable representing the move that has happened at time $n$. Of course, $X_i=\pm1$ and $$
P(X_i=1) = P(X_i=-1)=\frac{1}{2} \mbox{ as it is symmetric}
$$ Hence, we can write $S_n = X_1 + \dots + X_n$. In order to be at point $1$ we would need to have had an odd number of moves ($m+1$ to the right and $m$ to the left). Hence we cannot be at point $1$ after an even number of moves. Hence, $$
P(S_{2m}=1) = 0, \mbox{  } m\geq0 \tag{1}
$$
and 
$$
P(S_{2m+1} = 1) = \binom{2m+1}{m}\frac{1}{2^{2m+1}}, \mbox{ } m\geq0 \tag{2}
$$
Let, now, $A_n = \left \{ S_n = 1\right \}$ for the event that the walk visits point $1$ at time $n$, and:
$$
B_n = \left\{ S_n = 1, S_k\neq1 \mbox{ for } 1\leq k\leq n-1 \right\}
$$
for the event that the first visit of the walk through point $1$ occurs at time $n$. If $A_n$ occurs, then exactly one of $B_1, \dots , B_n$ occurs, giving that:
$$
P(A_n) = \sum_{k=1}^{n}P(A_n\cap B_k).
$$
Now, $A_n\cap B_k$ is the event that the walk goes through $1$ for the first time at time $k$ and then again in another $n-k$ steps. Hence:
$$
P(A_n\cap B_k) = P(B_k)P(A_{n-k}), \mbox{for } 2\leq k \leq n \tag{3}
$$ I have doubts that in the equation above, the boundaries are correct i.e. not sure if $n\geq 2$ since transitions in disjoint intervals of time are independent of each other. We write $f_n = P(B_n)$ and $u_n = P(A_n)$. Hence, from the above equations we get that:
$$
u_n = \sum_{k=2}^{n} f_{k}u_{n-k}, \mbox{ for } n=1,2,\dots
$$ We know the $u_i$s from $(1)$ and $(2)$ and we want to find the $f_k$. Given that the summation we got above is a convolution, we can use probability generating functions. 
$$
U(s) = \sum_{n=0}^{\infty}u_ns^n
$$
$$
F(s) = \sum_{n=0}^{\infty}f_ns^n
$$
noting that $u_0 = 0$ and $f_0 = 0$, we have, from $(3)$ that:
$$
\sum_{n=2}^{\infty}u_ns^n = F(s)U(s)
$$ 
Hence $U(s) - \frac{1}{2}s = F(s)U(s)$. Hence 
$$F(s) = 1 - \frac{1}{2sU(s)}
$$
And we can find out (not so easily), that:
$$
U(s) = \frac{1-\sqrt{1-s^2}}{s\sqrt{1-s^2}}, |s|<1 
$$
Hence, 
$$
F(s) = 1-\frac{s\sqrt{1-s^2}}{2s-2s\sqrt{1-s^2}}, |s|<1 
$$ We get the probability we are interested in by taking the limit in the above equation as $s\to 1$, which yields $1$. I am not sure if I manipulated the (summation) indexes correctly. I would appreciate comments on this proof as well as an alternative proof if anybody knows one.","['stochastic-processes', 'proof-verification', 'random-walk', 'probability']"
2882381,Examples non experiments in probability,"I'm reading a book on probability theory and they say that an experiment is Any procedure that has not got a pre-determined outcome In the Wikipedia page they, instead, that an experiment should: be infinitely repeatable have well-defined set of possible outcomes Now, I really don't see why it has to be infinitely repeatable. I mean, it makes sense only for frequentist probability right? Surely not for bayesian one. Anyway, my question is: then what is NOT an experiment? what are some examples of procedures that are not experiments? My Solution My idea is that the following are experiments: Tossing a fair coin, and looking at which side is facing upward after landing. Tossing a fair dice, and looking at which side is facing upward after landing. Picking up a numbered ball from within a box (where balls are placed randomly and the picking up mechanism is fair) and looking at the number of the ball. However, I can't quite make up any sensible example of something that is NOT an experiment. For instance, I think that also the following is an experiment: Tossing a non-fair coin that always lands on HEAD and looking at the side facing upwards. because even though the coin is biased, it is infinitely repeatable and has well-defined set of possible outcomes. What are some examples of non-experiments?","['statistics', 'examples-counterexamples', 'probability-theory', 'probability']"
2882386,Can every smooth scalar function $f$ on $M$ be written as $f=\operatorname{div}(X)$?,"Let $(M,g)$ be a Riemannian manifold of dimension $n$ and $X$ a vector field over it. divergence of $X$ is a real value function defined by:
$$\operatorname{div}(X)=g(\nabla_{e_i}X,e_i),$$
where $\{e_1,\cdots, e_n\}$ is a local orthonormal frame on $(M,g)$. it also can be defined (see J. M. Lee, p43, Ex. 3.3)
$$\mathcal{L}_XdVol_g=d(i_XdVol_g)=\operatorname{div}(X)dVol_g.$$ Question: Can every smooth scalar function $f$ on $M$ be written as $f=\operatorname{div}(X)$? I think that this depend on the topology of $M$ by using De-Rham cohomology but I don't know how to apply it.","['differential-topology', 'de-rham-cohomology', 'riemannian-geometry', 'differential-geometry']"
2882393,How few disks are needed to cover a square efficiently?,"A unit square can be covered by a single disk of area $\pi/2$. Let us call the ratio of the square's area to that of the covering disks (i.e. the sum of the areas of the disks) the efficiency of the covering, so that in the base case with one disk the efficiency is $2/\pi\approx63.66\%$. Say that a covering is efficient if its efficiency exceeds this value. If we use a honeycomb (hexagonal) grid of $22$ equal disks in alternating rows of four and five disks, we get a covering efficiency of $24/11\pi\approx69.45\%$; so efficient coverings exist. Allowing disks of different sizes, how few are needed to cover the square efficiently? Can it be done with fewer than $22$ disks?","['discrete-geometry', 'geometry', 'tiling']"
2882400,Proving that a sequence is periodic,"Given the following sequence, $$1,1,2,3,5,8,3,1,4,5,9,4,3,7....$$
  $$a_{n+2}=(a_n+a_{n+1}) \mod{10}\;\;\;\; \forall\;\;{n\geq{1}}$$
  Prove that it is periodic? My Attempt: There can be atmost $10 \times 10=100$ unique pairs of integers $(a,b)$ with $0\leq{a,b}\leq9$. So pairs will certainly start repeating after $100$ pairs. Let the first pair repeating after $100$ is $(x,y)$. The problem I am facing is that how can prove that $(x,y)$ will have unique predecessors and successors, i.e., if $$...a,b,x,y,c,d...\in\text{sequence}$$ also, $$...e,f,x,y,g,h... \in \text{sequence}$$ then , $a=e,b=f,c=g,d=h...$ If I can prove this, I can easily prove that $(x,y)$ will trace back to $(1,1)$ and the sequence is periodic. Any hints on how I can show this. Also let me know if I can make the question more clearer.","['periodic-functions', 'functions', 'sequences-and-series']"
2882430,"For positive number $a,b$, when $a,b$ satisfies $2a^2 +7ab+3b^2=7$, what is maximum value of $a+{\sqrt{3ab}}+2b$","Question is For positive numbers $a,b$ such that $2a^2 +7ab+3b^2 = 7$, what is the maximum value of $a+{\sqrt{3ab}}+2b$? I use AM-GM Inequality to do this $$(2a+b)(a+3b)=7\text{ and }2a+b=\frac{7}{a+3b}.$$ So, maximum value $m$ is $\frac{7}{a+3b}+{\sqrt{3ab}}$ so $m=\frac{7}{2{\sqrt{3ab}}}+{\sqrt{3ab}}$ is $2{\sqrt{\frac{7}{2}}}$ so $2m^2=28$. But it didn't satisfy equal condition so how do I get it?","['inequality', 'maxima-minima', 'optimization', 'substitution', 'algebra-precalculus']"
2882440,Mathematical Explanation of Mathematica Summation ${\sum_{n=1}^{\infty}\frac{(2n-1)!}{(2n+2)!}\zeta(2n)}$,"From a mathematical point of view, what phenomena that most likely Mathematica Wolfram encountered when calculating : $$ \sum_{n=1}^{\infty}\frac{(2n-1)!}{(2n+2)!}\zeta(2n)\,=\,\color{red}{\frac{2\log(2\pi)-3}{8}+\frac{\zeta(3)}{8\pi^2}} $$ which is incorrect. While calculating the sum from this question , I noticed that Wolfram result is containing ${\small\,\frac{\zeta(3)}{8\pi^2}\,}$ , which is incorrect. Although I realized that this could be a bug, I started to wonder if there are any logical explanation behind this miscalculation! Has Wolfram algorithm encountered something similar to Riemann Rearrangement Theorem ? Doing more investigations, it turns-out that Wolfram is incorrectly miscalculating the closed form of an entire class of zeta summation, except the last case which is correct. $$ \small \begin{align} \sum_{n=1}^{\infty}\frac{\zeta(\alpha\,n)}{(n+a)(n+b)\dots} &= \sum_{n=1}^{\infty}\left[A\frac{\zeta(\alpha\,n)}{n+a}+B\frac{\zeta(\alpha\,n)}{n+b}+\dots\right] = \\ C+\,\sum_{n=1}^{\infty}\frac{\zeta(\alpha\,n)-1}{(n+a)(n+b)\dots} &= \color{darkgreen}{\sum_{n=1}^{\infty}\left[A\frac{\zeta(\alpha\,n)-1}{n+a}+B\frac{\zeta(\alpha\,n)-1}{n+b}+\dots\right]\,+C} \end{align} $$ And with the appearance of this case (the last correct closed form), I believe there is a mathematical explanation regarding a correct summation method or algorithm that gives a kind of systematic incorrect closed form if it applied in a certain way. Appreciating if someone can explore this and alert us regardless of any bug that may exist in any math app . Thanks.","['riemann-zeta', 'summation', 'wolfram-alpha', 'sequences-and-series']"
2882445,Number of ways to roll $S$ with $n$ dice.,"I have been working on this problem for the past 3 days and I am not having a lot of luck with it. I posted part of a) here already and I got some very useful advice. I am sitting a test in this tomorrow and any help whatsoever would be greatly appreciated as I can't make heads or tails of it. For 1a) I let the set $A= \binom{S-1}{n-1}$ and thanks  to a kind user yesterday understand how the set $Aj = \binom{S-1-6}{n-1}$. 
Using the IE formula proved trickier than I thought. I set $N_{n,S}= \sum A - \sum Aj$ and I know to use the inclusion exclusion I need to start adding the individual sums to $S$ and subtracting the intersections of $2$ and add $3$ etc but I'm just not sure how to apply that logically here? b) For this part here I don't even know where to start. I used $ S_6 $ inside the bracket and got $\sum_{a=1}^{6} t^{a} = \frac{t(1-t^{6})}{1-t}$ but I have no idea how to use this to prove b. I also tried to differentiate it and that didn't work either. Because of this, I think proving the generalised binomial formula a different way will be very difficult. Any help would be greatly appreciated, I am sitting a repeat college exam in this tomorrow and not dropping out would be nice!","['combinations', 'inclusion-exclusion', 'combinatorics', 'generating-functions']"
2882446,Every finite commutative ring with no zero divisors contains a multiplicative identity?,"There is an easy argument which shows that a finite integral domain (commutative unital ring with no zero divisors) is a field. Here I wonder whether this result still stands if the term ""unital"" is dropped. In other words, can a finite commutative ring with no zero divisors always contain a multiplicative identity? More generally, if this is true, can we even generalize Wedderburn's little theorem: every finite ring with no zero divisors is a field?","['ring-theory', 'abstract-algebra']"
2882451,"Adding the constraint ""at least one entry of $x$ is $100$"" to a convex program","I have the following optimization problem in $x \in \mathbb R^p$ $$\begin{array}{ll} \text{minimize} & a^\top x\\ \text{subject to} & x \geq 0\end{array}$$ where $x \geq 0$ means that $x_1, x_2, \dots, x_p \geq 0$. To add the condition ""at least one entry of $x$ is $100$"", one option is to use the following $$(x_1−100) (x_2−100) \cdots (x_p−100)=0$$ But how do I represent this in matrix form? I used the example from the posted link. But looks like $$(x_1−100)(x_2−100) \cdots (x_p−100)=0$$ is difficult to express in matrix multiplication as it is not linear. The alternate solution, does not guarantee that value of 100 will be achieved.","['matrices', 'optimization']"
2882454,"Is this construction of the ""edge polytope"" known?","Given a convex polytope $P\subseteq\Bbb R^d$ . I am going to construct a new polytope from its edges (I call it the edge polytope ) with the following steps: Take the 1-skeleton of $P$ . Extract the different edge directions $v_1,...,v_n\in\Bbb R^d$ from the skeleton. The edge directions should be normalized, i.e. $\|v_i\|=1$ . Take the convex hull $P_e$ of the points $\pm v_i$ . Then $P_e$ is the edge polytope of $P$ . Question: Is this construction known in the literature? If yes, what is its name and where to read about it? On top of that, I am interested in applying the same construction to embedded graphs . Example. Here are some polytopes together with their edge polytope: Regular polygons give regular polygons again, where a $2n$ -gon gives the same $2n$ -gone again (maybe rotated), and $(2n+1)$ -gons give $(4n+2)$ -gons. The cube (and hypercube of any dimension) gives the octahedron (or cross-polytope of the respective dimension). Tetrahedron, octahedron and cuboctahedron all give the cuboctahedron. Icosahedron, dodecahedron and icosidodecahedron all give the icosidodecahedron. Prisms give bi-pyramids . It seems that the edge polytope will have the same symmetries as the original (or more, if the original was not centrally symmetric with all vertices on a sphere). Further, it seems that iterating this construction ends in fixed points, e.g. $2n$ -gons, the cuboctahedron or icosidodecahedron. I have not found yet any polytope where the construction loops.","['polytopes', 'convex-hulls', 'geometry', 'reference-request', 'terminology']"
2882557,Why do we require that a perfect set is closed?,"Definition of Perfect Set says $E$ is perfect if $E$ is closed and if every point of $E$ is limit point of $E$. Is it possible that every point of $E$ is limit point of $E$ but $E$ is not closed ?
I'am unable to find an example. Because Closed set is defined as if every limit point of $E$ is a point of $E$. If not possible. Then what is need of including in Definition of Perfect set ? ( that If $E$ is closed )
Help would be appreciated !","['general-topology', 'metric-spaces', 'real-analysis']"
2882588,Can a Hamel basis for an infinite-dimensional Hilbert space be orthonormal?,"For a finite-dimensional Hilbert space, any orthonormal basis is trivially a Hamel basis (because there's only one natural notion of ""basis"" in finite dimensions). But for an infinite-dimensional Hilbert space, no orthonormal basis is a Hamel basis, as proven here . But is it possible for a Hamel basis $B$ for an infinite-dimensional Hilbert space to form an orthonormal set , i.e. $\forall x, y \in B, \langle x, y\rangle = \delta_{xy}$ (the Kronecker delta)? (There are some linguistic issues here, because unfortunately ""a basis that is orthonormal"" is not necessarily the same thing as ""an orthonormal basis"". In the title of my question, I'm refering to an orthonormal set that is also a Hamel basis, not to an orthonormal basis.)","['hilbert-spaces', 'orthonormal', 'hamel-basis', 'functional-analysis']"
2882589,"Inequality involving $f,f',f''$","Let $f:\mathbb{R}\to [0,+\infty)$ is strictly convex ($f''(x)\geq 0$) and is $\mathrm{C}^2$ with $\min f(x) = f(0) = 0$. If $f''(0) > 0$ then by Taylor's expansion around $0$, obviously 
$$ \limsup_{x\to 0} \left|\frac{f(x)}{\left[f'(x)\right]^2} \right|<+\infty.$$ My questions are, If $f''(0) = 0$, what assumptions on $f$ do we need to ensure that $$
\limsup_{x\to 0}
\left|\frac{f''(x)f(x)}{\left[f'(x)\right]^2} \right|<+\infty? \qquad(*)$$ Can we prove $(*)$ if $f\in \mathrm{C}^3$? 
  In other words, is it true that if $f\in C^3$ is strictly convex with $\min f = f(0) = 0$ then
  $$ \limsup_{x\to 0} \frac{f''(x)f(x)}{f'(x)^2} < \infty?$$","['calculus', 'functional-analysis', 'analysis', 'real-analysis']"
2882607,inverse Fourier transform of $\frac{x^3y}{(x^2+y^2)^2}$,"Let $f(x,y)=\frac{x^3y}{(x^2+y^2)^2}$. What is the inverse Fourier transform of $f$? Since $f$ is neither a $L^1$-function nor a Schwartz-function I am looking for an inverse Fourier transform in the sense of tempered distributions. I’ve tried several distributions but every single one failed. Does anyone have a hint?","['calculus', 'fourier-transform', 'analysis']"
2882618,When are geometric and harmonic means used?,"From what little statistics I know, the only 'mean' commonly used is the arithmetic mean, and the rest are irrelevant. Any reading I've done has pretty much said something along the lines of ""acceleration or something"". So, under what situations are geometric, harmonic, and the other types of means are genuinely useful, and why are they used for those situations?","['average', 'statistical-inference', 'statistics', 'means']"
2882642,"Prove that, $\left\lfloor{\frac{x}{n}}\right\rfloor=\left\lfloor{\frac{\lfloor{x}\rfloor}{n}}\right\rfloor$ where $n \in{\mathbb{N}}$ [duplicate]","This question already has answers here : How to prove or disprove $\forall x\in\Bbb{R}, \forall n\in\Bbb{N},n\gt 0\implies \lfloor\frac{\lfloor x\rfloor}{n}\rfloor=\lfloor\frac{x}{n}\rfloor$. (5 answers) Closed 5 years ago . Prove that $$\left\lfloor{\frac{x}{n}}\right\rfloor=\left\lfloor{\frac{\lfloor{x}\rfloor}{n}}\right\rfloor,$$ where $n \in{\mathbb{N}}.$ My Attempt: Let $x=nt$. Then, I need to prove, $$\lfloor{t}\rfloor=\left\lfloor{\frac{\lfloor{nt}\rfloor}
{n}}\right\rfloor.$$ Let $t=n\lambda+r+f$, 
where $0\leq{r}\leq{n-1}$ and $0\leq{f}\lt{1}.$ This gives R.H.S as, $$\left\lfloor{\frac{\lfloor{n^2\lambda+nr+nf}\rfloor}
{n}}\right\rfloor.$$ How do I continue? I also know the property, $$\lfloor{x}\rfloor=\left\lfloor{\frac{x}{n}}\bigg\rfloor+\bigg\lfloor{\frac{x+1}{n}}\right\rfloor+\left\lfloor{\frac{x+2}{n}}\right\rfloor \cdots \left\lfloor{\frac{x+(n-1)}{n}}\right\rfloor.$$ Can I use that here?","['ceiling-and-floor-functions', 'functions']"
2882643,Evaluate $\int \frac{dx}{(x^2-x+1)\sqrt{x^2+x+1}}$ [duplicate],"This question already has answers here : Compute the integral $\int\frac{dx}{(x^2-x+1)\sqrt{x^2+x+1}}$ (2 answers) Closed 5 years ago . Evaluate $$I=\int \frac{dx}{(x^2-x+1)\sqrt{x^2+x+1}}$$ My book gave the substitution for $$\int \frac{dx}{P\sqrt{Q}}$$ as $\frac{Q}{P}=t^2$ when $P$ and $Q$ are quadratic expressions So accordingly i used $$\frac{x^2+x+1}{x^2-x+1}=t^2 \tag{1}$$ we get $$\frac{(1-x^2) \, dx}{(x^2-x+1)^2}=t \,dt$$ Then $$I=\int \frac{\sqrt{x^2-x+1}\:dt}{1-x^2}$$ By Componendo Dividendo in $(1)$ we get $$\frac{x^2+1}{x}=\frac{t^2+1}{t^2-1}$$ But how to express integrand purely in terms of $t$?","['indefinite-integrals', 'calculus']"
2882663,"Why do the first Chern classes of these line bundles span the Dolbeault cohomology group $H^{1,1}(X;\mathbb{R})$?","Forgive me for what is probably a simple question, I am new to this field. I am studying the Hirzebruch surfaces and their higher dimensional analogues $M_{n,k}$, defined to be the projective line bundles \begin{equation}
M_{n,k}=\mathbb{P}(\mathcal{O}(-k)\oplus\mathcal{O}(0))
\end{equation}
over $\mathbb{CP}^{n-1}$. Here, $\mathcal{O}(-1)$ is the tautological line bundle, and $\mathcal{O}(0)$ the trivial line bundle, both over $\mathbb{CP}^{n-1}$. We can define two divisors on $M_{n,k}$, namely $D_0$ to be the section with zero $\mathcal{O}(-k)$ component and $D_\infty$ to be the section with zero $\mathcal{O}(0)$ component. These two divisors then determine holomorphic line bundles $[D_0]$ and $[D_\infty]$ in the usual way. But to a line bundle $L$ on a complex manifold $X$, we can associate its first Chern class $c_1(L)$, which I understand to be the cohomology class in $H^{1,1}(X;\mathbb{R})$ determined by the curvature form $R_h$ of any Hermitian metric $h$ on $L$ (this is independent of $h$). I am then told that the cohomology classes $c_1([D_0])$ and $c_1([D_\infty])$ span $H^{1,1}(M_{n,k};\mathbb{R})$, and that for any Kahler class $\alpha\in H^{1,1}(M_{n,k};\mathbb{R})$ (i.e. any class for which a Kahler metric/form can be chosen as a representative), one can find constants $0<a<b$ such that
\begin{equation}
\alpha=\frac{b}{k}[D_\infty]-\frac{a}{k}[D_0].
\end{equation} I'm afraid that I have absolutely no idea as to how one can show this, or why it may be obvious. I'm aware that there are other ways of defining the 1st Chern class of a line bundle, and perhaps one of these may be more useful. Any help would be much appreciated!","['complex-geometry', 'vector-bundles', 'algebraic-geometry', 'characteristic-classes']"
2882678,Why are the morphisms of the category of sets functions?,"Why are the morphisms of the category of sets functions?
Shouldn't the morphisms take an object in a category and turn it into another object of the category, i.e. map Set to Set. I don't understand how e.g.
$f(x)=x^2$
is a map from a set to a set. If the morphism had been the image of a set under a function it would make more sense to me.","['elementary-set-theory', 'category-theory']"
2882685,Integer solutions to $x^3=y^3+2y+1$?,"Find all integral pairs $(x,y)$ satisfying $$ x^3=y^3+2y+1.$$ My approach: I tried to factorize $x^3-y^3$ as $$(x-y)(x^2 + xy + y^2)=2y+1,$$ but I know this is completely helpless. Please help me in solving this problem.","['contest-math', 'cubics', 'elementary-number-theory', 'diophantine-equations', 'algebra-precalculus']"
2882717,Interview Question on Probability: A and B toss a dice with 1 to n faces in an alternative way,"A and B toss a dice with 1 to n faces in an alternative way, the game is over when a face shows up with point less than the previous toss and that person loses. What is the probability of the ﬁrst person losing the game and the expected number of tosses? I can solve this question for 6 face dice:  If the first die is 1, there are 5 greater numbers on the second: 1/6 * 5/6 = 5/36. If the first die is 2, there are 4: 1/6 * 4/6 = 4/36 and so on. T/hus prob of first person losing the game is: 5/36 + 4/ 36 + 3/36 + 2/36 + 1/36 = 15/36 = 5/12 don't know how to generalize it to n faces.","['statistics', 'geometric-probability', 'dice', 'probability-theory', 'probability']"
2882730,Is there a proof that performing an operation on both sides of an equation preserves equality?,"so I was learning some abstract algebra and group theory, when they went over the proof of the cancellation law $$
ab = ac\implies a^{-1}(ab) = a^{-1}(ac)\implies (a^{-1}a)b = (a^{-1}a)c\implies eb=ec \implies b=c
$$ But the first step in which you add the additional term seems jarring to me, especially since I felt we were proving ever trivial thing from the ground up. Obviously I'm familiar with middle school pre-algebra, so I know that it is true that if we perform an operation on both sides it preserves equality, but I didn't know how we know this is the case always. Is it an axiom or is it proven? Here is my attempt at a proof, let me know if I am going in the correct direction. Assume via axiom that $x=x$ and if $a=b$ and $b=c$ then $a=c$, and prove that $a=b\implies ka=kb$ We know that $a=b$, we define $x\mid x=a \implies a=x$. Since $a=b$ and $a=x$, then $b=x$ which we can rewrite as $x=x$. Now we perform the operation on both sides $kx=kx$, which is true via our axiom. Then we re-substitute $x=a$ and $x=b$ to get $ka=kb$. Q.E.D That was my original idea but I don't know if that's watertight. Thank you!","['axioms', 'group-theory', 'abstract-algebra', 'proof-writing']"
2882760,Evaluate $\sum_{n=0}^\infty (-1)^n \ln\frac{2+2n}{1+2n}$,"I'm trying to evaluate: $$\sum_{n=0}^\infty (-1)^n \ln\frac{2+2n}{1+2n}$$ I'm not too sure where to start. I've tried writing it as a telescoping sum, but that doesn't work. I'm thinking it's related to the Wallis Product or some infinite product of Gamma's somehow, but I can't figure anything out. I've rewritten it as: $$\sum_{n=0}^\infty \ln\frac{(2+4n)(3+4n)}{(1+4n)(4+4n)}=\ln\prod_{n=0}^\infty\frac{(2+4n)(3+4n)}{(1+4n)(4+4n)}$$ but to no avail.","['infinite-product', 'summation', 'sequences-and-series']"
2882762,Is there an easy way to compute the jacobian of a normalized vector?,"If $x \in \mathbb{R}^3$ I want to compute the jacobian of the following function $$
f(x) = \frac{x}{\lVert x \rVert }
$$ If I proceed I get a matrix whose elements are $$
a_{ij} = \begin{cases}
\frac{1}{\lVert x \rVert} - \frac{x_i^2}{\lVert x \rVert^3} & i = j \\
-\frac{x_i x_j}{\lVert x \rVert^3} &i \neq j
\end{cases}
$$ Is this the most compact form?
The derivation is based on the product rule componentwise.","['jacobian', 'multivariable-calculus']"
2882771,"Convergence of $\sum\limits_{n=1}^{+\infty}\int_{n^{\alpha}}^{n^{\alpha+1}}\log^2\left(1+\sin1/x\right)\,dx$","Study the convergence of the following series as $\alpha>0$ $$\sum_{n=1}^{+\infty}\int_{n^{\alpha}}^{n^{\alpha+1}}\log^2\left(1+\sin\frac{1}{x}\right)\,dx$$ This is the first time I do an exercise with a series defined by a integral and I hold it is equal to study the convergence of the improper integral (isn't it?): $$\lim_{N \to +\infty}\int_{1^{\alpha}}^{N^{\alpha+1}}\log^2\left(1+\sin\frac{1}{x}\right)\,dx$$ or, do I need to follow a different path?","['convergence-divergence', 'definite-integrals', 'sequences-and-series', 'real-analysis']"
2882779,Surface integral enclosing all of space? Improper surface integral convergence?,"Consider a surface integral over a closed surface $S$ in $\mathbb{R}^3$ $$ \iint_S V\vec{E} \cdot d\vec{S}$$ (I'm writing out $V$ and $\vec{E}$ to make connection with physics textbooks, and to show the motivation behind this question, where $\vec{E}$ is the electric field of a continuous charge distribution and $V$ is the corresponding potential. Let's think of the integrand as a function $V\vec{E} = \vec{F}: \mathbb{R}^3 \to \mathbb{R}^3$) (What follows isn't even my main question, but it would be useful to setup in order to answer my main question on convergence seen further below) How do you mathematically specify that you want to expand the surface so that it encloses all of space? I would like an 'improper surface integral', in the same way that we have improper 1-dimensional integrals $$ \int_a^\infty f(x) dx = \lim_{R\to \infty} \int_a^R f(x) dx$$
Is there any such notation or is $$ \iint _{\text{surface enclosing all space}} \vec{F}\cdot d\vec{S}$$
the best you can do? Technically such a surface doesn't exist? You need some sort of limit to keep expanding the surface further and further? To phrase this initial notation question in another way, consider a parameterization of the closed surface $g(\theta, \phi): \mathcal{D}\subset \mathbb{R}^2 \to \mathbb{R}^3$ In particular, consider a spherical coordinates parameterization of the surface $g(\theta, \phi) = r(\theta, \phi) \hat{r} + 0\hat{\theta} + 0\hat{\phi}$ where $r$ outputs a radial distance from the origin. How do I show that I want to ""push"" the output $r$, for every given $(\theta, \phi)$ pair, out to infinity so that my surface encloses all of space? There is no unique way to push this surface outwards. It seems like I'd have to give a sequence of functions that take me from the initial enclosing radial function $r_1$ to some final radial function $r_2$ which encloses all of space? Question on convergence Given that we have some sort of notation for a surface enclosing all of space, how do we evaluate if the surface integral converges or not over this limiting sequence? In particular, lets consider an integrand which physics textbooks claim make the integral $0$. They argue (in words, which I will try to translate into math) given $$ \lim_{r\to\infty}\vec{F}(r,\theta,\phi) \sim \frac{1}{r^3}\hat{r}$$ i.e. integrand is asymptotically equivalent to the vector field $(1/r^3) \hat{r}$ at large distances, the surface integral over all space is $0$ since $d\vec{S}$ goes as $r^2$ ($d\vec{S} = r^2\sin\theta\; d\theta \;d\phi \;\hat{r}$). Is there mathematical rigor behind this statement? Considering my notation and thoughts above, it seems like the mathematical problem would be phrased as $$ \lim_{\text{sequence of parameterizations} \;g_i} \iint_{g_i} \vec{F}(g(\theta,\phi)) \cdot |g_{\theta} \times g_{\phi}| \; d\theta \; d\phi
$$
where $$ g_{\theta} = \frac{\partial r}{\partial \theta}\hat{r} + r \hat{\theta}$$
$$ g_{\phi} = \frac{\partial r}{\partial \phi}\hat{r} + r \sin\theta\hat{\phi}$$ where I have used that $\partial \hat{r}/ \partial \theta = \hat{\theta}$ and $\partial \hat{r}/\partial \phi = \sin\theta \hat{\phi}$. The cross product yields $$ g_{\theta} \times g_{\phi} = \hat{r}(r^2\sin\theta) + \hat{\theta}(-r\frac{\partial r}{\partial \theta}\sin\theta) + \hat{\phi}(-r\frac{\partial r}{\partial \phi}) $$ Therefore if we could somehow get the limit inside the integral, to turn $\vec{F}$ to $\hat{r}/r^3$, the dot product would result in the integral $$ \lim_{\text{sequence of} g_i}\iint_{g_i} \frac{1}{r^3}r^2\sin\theta d\theta d\phi$$ (Can you make that replacement?) And I guess this now goes to $0$? So in summary, is my notation/thoughts on pushing a surface out to infinity so that it encloses all of $\mathbb{R}^3$ valid/the way to go? What is the mathematical proof behind improper surface integrals converging to $0$? The convergence should be defined so that it is independent of ""path"" right? Meaning, it doesn't matter what sequence of $g_i$'s I choose? I might as well start with a sphere radius $a$ and just let $a$ tend to infinity? Whatever value I get (say it converges), I hope that it's the same value for all other sequences of $g_i$'s.","['surface-integrals', 'real-analysis', 'notation', 'calculus', 'limits']"
2882799,Is every finitely generated group the fundamental group of some finite topological space?,"Can every finitely generated group be realized as the fundamental group of some finite topological space? The motivation for my question is that the topological space on the finite point set $X=\{v_1,v_2,e_1,e_2\}$, with the topology generated by $\{e_1,e_2,\{v_1,e_1,e_2\},\{v_2,e_1,e_2\}\}$, has a fundamental group of $\mathbb Z$. The idea is that $X$ resembles a circle in a loose sense; $v_1$ and $v_2$ are like vertices, and $e_1$ and $e_2$ are disjoint paths connecting $v_1$ to $v_2$. (I think this is called the digital circle? Its universal covering space is the digital line ). Using this same idea, you can make a finite topological space which resembles any finite graph $G=(V,E)$. The points are $V\cup E$, and the topology is the finest topology for which every $e\in E$ is open and every $v\in V$ is closed. This is equivalent to saying that sets of the form $\{e\}$ for $e\in E$ and $v\cup E_v$ for $v\in V$ are open, where $E_v$ are the edges which have $v$ as an endpoint. This means every finitely generated free group is the fundamental group of a finite topological space. In the preceding paragraph, we made a finite topological space corresponding to any $1$ dimensional CW complex. I know that there is a $2$ dimensional cell complex whose fundamental group is any desired group (there is one vertex, the $1$-cells are generators, the $2$-cells are relations). It therefore seems like the goal is to extend this construction to make arbitrary finite $2$-complexes. I could not figure out how to do this.","['general-topology', 'fundamental-groups']"
2882830,Shortest distance between two non-intersecting differentiable curves is along their common normal,"I want to formally prove the following property: The shortest distance between two differentiable non-intersecting curves is along their common normal. I looked at the discussion on this on Quora, (Link: https://www.quora.com/How-can-I-show-that-the-shortest-distance-between-2-non-intersecting-curves-always-lies-along-their-common-normal ), but the proofs were not formal there. My approach :
Let the curves be denoted by f and g respectively. And let AB be a line segment with A lying on f and B lying on g. 
WLOG, take A as the origin of the coordinate axis, and the tangent to f at A to be the x-axis.
Let $B \equiv (b,g(b))$, $A = (0,0)$. Let the angle AB makes with the x-axis be $\theta \in (0,\pi)$.
Let 2 rays from A making an angle of $\theta + \epsilon$ and $\theta - \epsilon$ ($\epsilon > 0$) with the x-axis intersect $y = g(x)$ at $B_1$ and $B_2$ respectively. I wish to show that $\theta \neq \frac{\pi}{2} \Leftrightarrow |AB| > \min\{|AB_1|, |AB_2| \}$. Suppose $\theta \neq \frac{\pi}{2} $. Then let $B_1 \equiv (b_1,g(b_1))$ and $B \equiv (b_2,g(b_2))$.Then 
\begin{align}
g(b) &= b\tan(\theta)\\
g(b_1) &= b_1\tan(\theta + \epsilon)\\
g(b_2) &= b_2\tan(\theta - \epsilon) \\
\Rightarrow |AB| &= |b \sec(\theta) | \\
|AB_1| &= |b_1 \sec(\theta + \epsilon) | \\
|AB_2| &= |b_2 \sec(\theta - \epsilon) | 
\end{align}
I wanted to relate $b_1$ and $b_2$ to $b$ using the continuity of $g$. However I am not able to do so. How do I proceed from here? - or is there an easier formal approach?","['analytic-geometry', 'calculus']"
2882853,"$AB-BA=A^k$, then $A$ is not invertible","Let $k\in\mathbb{N}$ and $A,B\in M_n(\mathbb{R})$ such that $AB-BA=A^k$. Show that $A$ is not invertible. I can show the claim if $k=1$: Assume that $A$ is invertible. We have $AB=(I_n+B)A$, so $B=A^{-1}(I_n+B)A$. Taking the trace gives a contradiction. How can I proceed for the general case?","['matrices', 'determinant', 'linear-algebra', 'inverse']"
2882857,Writing a Fake Proof for Real Analysis,"mathematics community! I'm teaching a course in Real Analysis soon, and one thing I wanted to include were a few ""fake proofs"" for my students to evaluate. The research I've done hasn't turned up any fake-proofs regarding continuity. So I'll put it out to you: do any of you have a favorite ""proof"" involving continuity or a sequential criterion with a flaw in it that could potentially stump some people?","['continuity', 'fake-proofs', 'real-analysis']"
2882859,Group of matrices which share a fixed eigenvector is noncommutative,"Let $n\in\mathbb{N}$, $n>1$, $v\in\mathbb{R}^n$. Let $X=\{A\in GL_n(\mathbb{R})\mid Av=\lambda v\text{ for some }\lambda\in \mathbb{R}\}$. Then $X$ is a noncommutative group. It is easy to show, that $X$ is a group. But how do I show non commutativity? I can definitely construct counterexamples, but I think there should be a general argument that works for an arbitrary $v$.","['matrices', 'abelian-groups', 'linear-algebra', 'eigenvalues-eigenvectors']"
2882901,Answer check: What is the number of integers smaller than one million that contain two consecutive digits which are the same?,"I try to use the Inclusion-Exclusion Principle to do this, with the component sets being $\{T_1, T_2, T_3, T_4, T_5 \}$, where $T_i$ denotes the set of 6-digits integers containing repeated digits at position $i$ and $i+1$. The ""1-fold"" overlapping of the sets has size $5 \times 10^5$. 2-fold overlapping has size $10 \times 10^4$. 3-fold overlapping has size $10 \times 10^3$. 4-fold overlapping has size $5 \times 10^2$. 5-fold overlapping has size $10$. Applying the PIE formula, I obtain $409,510$ as the number of integers smaller than one million that contain two consecutive digits which are the same. Please comment on this answer. Thanks. ================================================================== Edit: How do I get rid of the blanks between the ""2-fold"", ""3-fold"", etc. lines?","['inclusion-exclusion', 'discrete-mathematics']"
2882910,Complex number raised to irrational power,"Why are there infinitely many values if a complex number is raised to an irrational power? I have to prove this, and don't know how. I am thinking Cauchy sequences, but I don't know how to start. Could you you please help? Thanks!","['complex-analysis', 'irrational-numbers', 'complex-numbers']"
2882914,Problem on Determinant.,"Q. $$\text{If } \Delta = \left|\begin{array}{ccc} a & b & c \\ c & a & b \\ b & c & a \end{array}\right|,$$ $$\text{ then the value of }$$ $$ \left|\begin{array}{ccc} a^2 - bc & b^2 - ca & c^2 - ab \\ c^2 - ab & a^2 - bc & b^2 - ca \\ b^2 - ca & c^2 - ab & a^2 - bc \end{array}\right| \text{ is:}$$ Express the Answer in terms of $ \Delta $ . My Attempt - I tried Rearranging the Second determinant (by adding or subtracting particular rows or Columns) such that after this, It'll be easy for me write the second determinant as the product of two or more other Determinants that might be same as $\Delta$ . But I Found that rearranging the Second Det. Wasn't a good choice as it seems to never simplify itself!! So, I tried Expressing the Second Det. directly as the product of two or more Det. ! Still It was no use. I finally concluded that the Second Det. Can't be expressed as a product without Rearrangement ! But Rearranging it makes it more creepier! Could you please Guide me how to Rearrange it so that it could be easily expressed as a product? Or is their Another Way for this type of Problem? Please Let me know! Any help would be Appreciated.","['matrices', 'determinant']"
2882920,Is exterior calculus efficient for simple vector calculus problems?,"Exterior calculus and invariant formulations are important and lead to many breakthroughs and great insights in physics and mathematics.
But for daily vector calculus tasks, I still struggle to apply the theory efficiently . Question: Is it possible to practice exterior calculus hard enough such that it becomes as fast as classical vector calculus?
Or is there just an unavoidable trade-off we need to accept? Example: I want to validate a simple equation like $$\mathbf B = \operatorname{rot} \mathbf A$$ for a potential $\mathbf A$ defined by $\mathbf{A} := \frac 1 2( \mathbf{r} \times \mathbf{B}).$ ($\mathbf B$ is a given constant magnetic field.) Using classical vector calculus (with indices), this computation is easy. But using rules from differential geometry instead, there are always the same difficulties for me: Which kind of tensors do we have: differential forms, vector fields or tensor-fields? (Knowing this is in general interesting, but sometime I just don't have the time to get into these questions...) If the tensors don't match, I need to use general formulas which involve many isomorphisms (musicals, hodge-star ), that's complicated! For this example, I did the computations by applying all isomorphisms one after each other, i.e. $$\mathbf B = [*(\mathrm d ( * (\mathbf r^\flat \wedge \mathbf 
 B^\flat)))]^\sharp .$$ 
It took me more than 10 minutes to figure it out. And additionally, it does not use the idea that $\mathbf B$ is more naturally seen as a $2$-form. Therefore, I really hope that I am just a bit stupid and there is a smarter way to this. But this is not the first example where I could not find an efficient way to calculate. Books: I mainly use John M. Lee's 'Introduction to smooth manifolds' and Marsdens books 'Introduction to Mechanics and Symmetry' and 'Mathematical foundations of elasticity' to learn differential geometry.
(To be honest, I was scared off but the old prints of Spivak's books.)","['physics', 'soft-question', 'vector-analysis', 'differential-geometry']"
2882969,"Show that $\frac{1}{n-1}\sum_{i=1}^n(X_iY_i-\overline{X}\overline{Y})$ is an unbiased estimator of $\text{Cov}[X,Y].$","Assume that $(X_1,Y_1),...,(X_n,Y_n)$ is a sample on a two-dimensional
  random variable $(X,Y)$ and that $E[X^2], \ E[Y^2]$ and $E[XY]$ are
  all finite so that the variances and covariance are well-defined. Show
  that $$S=\frac{1}{n-1}\sum_{i=1}^n(X_iY_i-\overline{X}\overline{Y})$$ is an
  unbiased estimator of $\text{Cov}[X,Y].$ So I'm supposed to show that $E[S]=\text{Cov[X,Y]}.$ Now $$E\left[\sum_{i=1}^n(X_iY_i-\overline{X}\overline{Y})\right]=\sum_{i=1}^nE[X_iY_i]-nE[\overline{X}\overline{Y}]=n(E[XY]-E[\overline{X}\overline{Y}]).\tag1$$ According to the formula for variance the last step in $(1)$ can be rewritten as $$n(\mu_x\mu_y+\text{Cov}[X,Y]-(\mu_x\mu_y+\text{Cov}[\overline{X}\overline{Y}]))=\text{Cov}[X,Y]-\text{Cov}[\overline{X}\overline{Y}])), \tag2$$ where $\mu_x$ and $\mu_y$ are the respective mean. Questions: In $(2)$, I understand that from the covariance formula we get 
$$\mu_x\mu_y=E[X]E[Y]=E[XY]-\text{Cov}[X,Y],$$
but why is it also equal to
$$\mu_x\mu_y=E[X]E[Y]=E[XY]-\text{Cov}[\overline{X}\overline{Y}]?$$
Shouldn't the sample means with overline cause any difference? How do I proceeed from here?","['probability-distributions', 'probability-theory', 'probability']"
2883048,"The functions $f$ and $g$ are not continuous and have directional derivative at $(0,0)$","Let $$f:\Bbb{R}^2\to\Bbb{R}$$
$$(x,y)\mapsto f(x,y)=\begin{cases}y^2\log|x|& ,x\neq 0,\\0 &,x=0.\end{cases}$$
and 
$$g:\Bbb{R}^2\to\Bbb{R}$$
$$(x,y)\mapsto f(x,y)=\begin{cases}\frac{x^2 y}{x^2+y^2}& ,(x,y)\neq (0,0),\\\;0 &,x=y=0.\end{cases}$$
I want to show that $f$ and $g$ are not continuous at $(0,0).$ $f$ and $g$ have directional derivatives at $(0,0).$ PART A: To show that $f$ and $g$ are not continuous, it suffices to use line, i.e. $y=\alpha x,\;\alpha\in \Bbb{R}$. So, I have $$f(x,y)=f(x,\alpha x)=\alpha^2 x^2\log|x|$$ which goes to $0$ as $x\to 0$
Also, $$g(x,y)=g(x,\alpha x)=\frac{\alpha x^3 }{x^2+\alpha^2 x^2}=\frac{\alpha x }{1+\alpha^2 \alpha^2}$$ which also goes to $0$ as $x\to 0.$ So, why I'm I not arriving at the desired result? Could my computation be wrong? PART B: Let $(x_0,y_0)\in \Bbb{R}^2.$ Then, for $x_0\neq 0,$
$$f((x_0,y_0)+(h_1,h_2))-f(x_0,y_0)$$
$$f(x_0+h_1,y_0+h_2)-f(x_0,y_0)$$
$$=(y_0+h_2)^2\log|x_0+h_1|-y^2_0 \log|x_0|.$$ I got stuck here. So, could anyone please, help-out? I would be glad for any help rendered.","['real-analysis', 'continuity', 'multivariable-calculus', 'calculus', 'derivatives']"
2883056,What surfaces(manifolds) can be the boundary of hyperbolic groups?,"Question: What surfaces can be the Gromov boundary of a hyperbolic group ? (You could also ask the same question except for higher dimensional manifolds.) I know that spheres appear as the boundary of some hyperbolic group (fundamental groups of closed hyperbolic three manifolds), but that is about it. Intuitively I feel like surfaces of genus $g>0$ should not appear as boundaries (it ""feels"" like they don't have enough nice symmetries/self similarity, although their homeomorphisms groups are huge...). Bowditch gave topological(dynamical) characterization of hyperbolic groups in terms of uniform convergence actions , which I am not familiar with, but looks like it could help show that some boundaries do or do not exist. The naive idea I was thinking, if surfaces with genus could be boundaries, would be choose some homeomorphisms of the surface with ""north"" and ""south"" poles and hopefully the group generated by those would be nice enough that the group would have that surface as its boundary. Maybe a Poincare-Hopf type theorem could rule this out. At the end of the summary section of Sphere boundaries of hyperbolic groups by Benjamin Beeker and Nir Lazarovich there is a descriptions of a hyperbolic group with an interesting boundary, and when it was explained to me months ago I seem to remember it was surface-ish but I don't remember the details(I don't think it was a surface though).","['gromov-hyperbolic-spaces', 'geometric-group-theory', 'group-theory']"
2883106,sum expression in terms of special functions $\sum_{n=1}^\infty \frac{n^{s-1}}{e^{2\pi n}-1}$,"As the title already says it I have this expression
$$
f(s)=\sum_{n=1}^\infty \frac{n^{s-1}}{e^{2\pi n}-1}
$$
and am wondering if this one can be expressed in terms of any special or analytical functions? Note that for large $n$ the denominator behaves like $e^{2\pi n}$ and thus approximately the main contributions come from the terms around the maximum $$n=\frac{s-1}{2\pi} $$ so that it should behave like $\sim (s-1)^{s-1}$. In fact asymptotically it seems like $$(2\pi)^{s}f(s) \sim \Gamma(s) \, .$$ Thank you Update: In writing $f(-s+1)$ I re-expressed $$n^{-s}= \frac{1}{\Gamma(s)}\int_{0}^\infty t^{s-1} \, e^{-nt} \, {\rm d}t \, ,$$ so that
\begin{align}
f(-s+1) &= \sum_{n=1}^\infty \frac{n^{-s}}{e^{2\pi n} -1} \\
&= \frac{1}{\Gamma(s)} \int_0^\infty {\rm d}t \, t^{s-1} \sum_{n=1}^\infty e^{-nt} \sum_{k=0}^\infty e^{-2\pi n(k+1)} \\
&= \frac{1}{\Gamma(s)} \int_0^\infty {\rm d}t \, t^{s-1} \sum_{k=0}^\infty \frac{1}{e^{t} \, e^{2\pi (k+1)} -1} \\
\end{align}
and maybe $$\sum_{k=1}^\infty \frac{1}{z \, e^{2\pi k}-1}$$ is simpler to evaluate? More than the precise values of $f(s)$ I'm actually interested in the analytic structure. Is it possible to see whether there are any zeros? 2nd Update: Being made aware about the Mellin-Transform Method shown at various sites here on MSE by Marko Riedel I carried out the analysis for certain positive $s$ values. For negative $s$ some more information can be found here: A new formula for Apery's constant and other zeta(s)? We adapt the notation from above at little and write
$$
f_k(x) = \sum_{n=1}^\infty \frac{n^{k-1}}{e^{nx}-1}
$$
with Mellin-Transform
$$
{\cal M}_{f_k}(s) = \Gamma(s)\zeta(s)\zeta(1+s-k)
$$
where the integral converges for $s>k$. The inverse Mellin is given by
$$
f_k(x)=\frac{1}{2\pi i} \int_{k+\frac{1}{2}-i\infty}^{k+\frac{1}{2}+i\infty} \Gamma(s)\zeta(s)\zeta(1+s-k) \, x^{-s} \, {\rm d}s \, .
$$
We now close the contour at ${\rm Re}(s)=-\frac{1}{2}$ and transform this integral. First
$$
\int_{-\frac{1}{2}+i\infty}^{-\frac{1}{2}-i\infty} \Gamma(s)\zeta(s)\zeta(1+s-k) \, x^{-s} \, {\rm d}s \\
\stackrel{u=k-s}{=} -\int_{k+\frac{1}{2}-i\infty}^{k+\frac{1}{2}+i\infty} \Gamma(k-u)\zeta(k-u)\zeta(1-u) \, x^{u-k} \, {\rm d}u
$$
and then using the $\zeta$-functional equation
$$
\zeta(1-s) = \frac{2}{\left(2\pi\right)^s} \, \cos\left(\frac{\pi s}{2}\right) \Gamma(s) \zeta(s)
$$
and continue (renaming $u$ back to $s$)
$$
=(-1)^{\frac{k}{2}+1}\int_{k+\frac{1}{2}-i\infty}^{k+\frac{1}{2}+i\infty} \Gamma(s)\zeta(s)\zeta(1+s-k) \, \left(2\pi\right)^{-s} \, \left(\frac{x}{2\pi}\right)^{s-k} \, {\rm d}s
$$
where we needed to assume $k$ even. Obviously the value $x=2\pi$ is somewhat special and plugging in this becomes
$$
=(-1)^{\frac{k}{2}+1} \, 2\pi i \,  f_k\left(2\pi\right) \, .
$$ The poles we enclosed are at $s=k$, $s=1$ and $s=0$ and the residue theorem yields
$$
\left(1-\left(-1\right)^{\frac{k}{2}}\right) f_k(2\pi) = \frac{1}{2\pi i} \oint_\gamma \Gamma(s)\zeta(s) \zeta(1+s-k) \, (2\pi)^{-s} \, {\rm d}s \\
= \frac{\Gamma(k)\zeta(k)}{(2\pi)^k} + \frac{\Gamma(1)\zeta(2-k)}{2\pi} + \zeta(0)\zeta(1-k) \, .
$$
In this equation not all even $k$ values are allowed, but only those of the form
$$
k=4n+2 \qquad n=0,1,2,3,...
$$
and we obtain the result
$$
f_{4n+2}(2\pi) = \frac{(4n+2)!\zeta(4n+2)}{2(4n+2)(2\pi)^{4n+2}} + \frac{\zeta(-4n)}{4\pi} - \frac{\zeta(-4n-1)}{4} \\
= \frac{{\rm B}_{4n+2}}{2(4n+2)} - \frac{\delta_{n,0}}{8\pi} \, .
$$ In fact the latter result also seems to be very close for the numbers
$$
k=4n+4 \qquad n=0,1,2,3,...
$$
if we correct the negative sign of these Bernoulli numbers
$$
f_{2n}(2\pi) = \frac{(-1)^{n+1} \, {\rm B}_{2n}}{2(2n)} - \frac{\delta_{n,1}}{8\pi} \qquad n=1,2,3,... \, .
$$","['analytic-functions', 'sequences-and-series']"
2883109,Find the geometry of the curves of the contour lines of $f(x) = \frac{1}{2}x^tAx + b^tx + c$,"Find the geometry of the curves of the contour lines of a quadratic
  function $$f(x) = \frac{1}{2}x^tAx + b^tx + c$$ where $A \in \mathbb{R}^{2 \times 2}$, $b\in \mathbb{R}^2$ and $c\in \mathbb{R}$ in the following cases: $A>0$ $A\ge 0$ and there exists $x$ such that $Ax+b = 0$ $A\ge 0$ and there is no $x$ such that $Ax + b = 0$ $A$ is undefined and non-singular. I suppose $^t$ is the transpose. What is $A>0$? I'm trying to develop a technique to see this. If we write $A = \begin{bmatrix} 
     a & b \\
     b & c\\  
     \end{bmatrix}$ then the function becomes $$f((x_1,x_2)) = \frac{1}{2}\begin{bmatrix} 
     x_1  & x_2  
     \end{bmatrix}\begin{bmatrix} 
     a & b \\
     b & c\\  
     \end{bmatrix}\begin{bmatrix} 
     x_1 \\
     x_2\\  
     \end{bmatrix} + \begin{bmatrix} 
     b_1  & b_2  
     \end{bmatrix}\begin{bmatrix} 
     x_1 \\
     x_2\\  
     \end{bmatrix} + d = \\ \frac{1}{2}(ax_1^2 + 2bx_1x_2 + cx_2^2) + b_1x_1 + b_2x_2 + d $$ I don't know if I can simplify $(ax_1^2 + 2bx_1x_2 + cx_2^2)$. I think not. Maybe it's a shape of its own and I should recognize. I thin I can see it as approximate $x^2 + y^2$ everywhere since they grow much faster than $xy$. So the contour here would be circles? Is there a more accurate way of drawing the contour? I cannot suppose they're circles, I need to find what they truly are. Anyways, $A>0$ implies that $\frac{1}{2}(ax_1^2 + 2bx_1x_2 + cx_2^2)>0$ right? And $A\ge 0 \implies \frac{1}{2}(ax_1^2 + 2bx_1x_2 + cx_2^2)\ge 0$, and the condition there exists $x$ such that $Ax+b=0$ means there exists $x$ such that $\begin{bmatrix} 
     ax_1 + bx_2 + b_1 \\
     ax_2 + bx_1 + b_2\\  
     \end{bmatrix} = \begin{bmatrix} 
     0 \\
     0\\  
     \end{bmatrix}\implies ax_1 + bx_2 + b_1 = 0, ax_2 + bx_1 + b_2 = 0$ What this should tell me? $A$ being undefined and non singular means an arbitrary nonsingular matrix, I suppose. So the invertibility or the determinant of $A$ plays a role here.","['matrices', 'systems-of-equations', 'linear-algebra', 'geometry']"
2883154,An estimate involving polynomial of degree 2,"Let $P(z)=(z-a)(z-b)$ where $a,b$ are any complex numbers such that $|a|\geq 1, |b|\geq 1.$ Then may I know, if
$$\max_{|z|=1}|P'(z)|\leq \left(\frac{1}{2}+\frac{1}{1+|ab|}\right)\max_{|z|=1}|P(z)|$$
is true?",['complex-analysis']
2883188,Evaluating an Integral by converting into polar coordinates.,"Question. Evaluate the integral by converting into polar coordinate: $$I=\int_{0}^{\sqrt 3}\int_{0}^{\sqrt {4-y^2}}\frac{dx~dy}{4+x^2+y^2}$$ My Solution. Let $f(x,y)=\frac{1}{4+x^2+y^2}$ . Now the region of the integration is $S_1 \cup S_2$ as depicted in the following figure: $xy$ -plane"" /> Now $I=\iint_{S_1} f(x,y)~dxdy +\iint_{S_2} f(x,y)~dxdy=I_1+I_2.$ Hence if I change the coordinate into polar co ordinate by $x=r \cos \theta;~y=r\sin \theta$ where $0<r; 0\le\theta<2 \pi$ , $I_1=\int_{r=0}^{2}\int_{0}^{\pi/3}f ~rdrd\theta$ And $I_2=\int_{0}^{\sqrt 3}\int_{0}^{y}f(x,y)~dxdy$ .
But I cannot figure out range of $r$ and $\theta$ when $(x,y)$ varies in $S_2$ . How can I find the range of $r$ and $\theta$ in the later case? Please help. Thank you.","['multivariable-calculus', 'calculus', 'multiple-integral']"
2883232,Proving that $\operatorname{Tor}_n^R$ is a bifunctor,"$\newcommand{\Tor}{\operatorname{Tor}}$ Ex10.2 pg 615: For a ring $R$ and fixed $k \ge 0$, prove that $\Tor_n^R(-,-)$ is a bifunctor. I am aware of this post. I am also not satisfied with the answer. I am unfamilar with total complexes, and I still don't see how the argument writes out. Concerns: There must be a choice of projective resolution here. $P,Q$ be resolutions of $A,B$. Suppose $P'$ is another resolution of $A$, then we can show we have $\mathbb{Z}$-isomoprhisms.
  $$\Tor_n^R(A,B) \cong \Tor_n^R(A,B)'$$ In Rotman's homological algebra , we defined $\Tor$ as derived functor of right tensor, whislt $\operatorname{tor}$ as derived functor of left tensor. Hence, $\Tor$ is only a functor in its first argument, and how does make sense of an induced morphism $\Tor_n^R(A,B) \rightarrow \Tor_n^R(A,B')$ from $B\rightarrow B'$ ? I was thinking we may use the isomorphism $\Tor_n(A,B) \cong \operatorname{tor}_n(A,B)$. But isomoprhism is terribly (for me) obscured in the proof: Theorem 6.32, pg 355 . How should one approach? May someone also elaborate on using total complexes? Ok: so I have defined my own ""induced morphisms"". This is the proof I came up with. I wonder if it is right. I don't like it as it requires pointwise element chase - is this inevitable?","['homological-algebra', 'abstract-algebra', 'graded-modules', 'modules']"
2883253,Differential equation: $\dfrac{dy}{dx}= \dfrac{(x+y)^2}{(x+2)(y-2)}$,"The solution of $\dfrac{dy}{dx}= \dfrac{(x+y)^2}{(x+2)(y-2)}$ is given by: a) $(x+2)^4 (1+\frac{2y}{x})= ke^{\frac{2y}{x}}$ b) $(x+2)^4 (1+ 2\frac{(y-2)}{x+2})= ke^{\frac{2(y-2)}{x+2}}$ c) $(x+2)^3 (1+ 2\frac{(y-2)}{x+2})= ke^{\frac{2(y-2)}{x+2}}$ d) None of these Attempt: I have expanded and checked but couldn't spot any exact differentials. Secondly, it's not a homogeneous equation, so couldn't use $y = vx$. How do I go about solving this problem?",['ordinary-differential-equations']
2883337,Prove that there exists irrational numbers p and q such that $p^{q}$ is rational,"I found this on the lecture slides of my Discrete Mathematics module today. I think they quote the theorems mostly from the Susanna S.Epp Discrete Mathematics with Applications 4th edition. Here's the proof: We know from Theorem 4.7.1(Epp) that $\sqrt{2}$ is irrational. Consider $\sqrt{2}^{\sqrt{2}}$ : It is either rational or irrational. Case 1: It is rational: 3.1 Let $p=q=\sqrt{2}$ and we are done. Case 2: It is irrational: 4.1 Then let p=$\sqrt{2}^{\sqrt{2}}$, and $q =\sqrt{2}$ 4.2 p is irrational(by assumption), so is q (by Theorem 4.7.1(Epp)) 4.3 Consider $p^{q} = (\sqrt{2}^{\sqrt{2}})^{\sqrt{2}}$ 4.4 $=(\sqrt{2})^{\sqrt{2} \times\sqrt{2}}$, by the power law 4.5 $=(\sqrt{2})^{2}=2$, by algebra 4.6 Clearly $2$ is rational In either case, we have found the required p and q. From what I understand from the proof, it's a clever construction of a number and splitting up into cases to prove that the given number is a rational number (one by clear observation and the other by some sort of contradiction). While the proof seems valid, though I somehow am forced to be convinced that the contradiction works, I wondered to myself if $\sqrt{2}^{\sqrt{2}}$ is actually rational since they constructed it. My question would be if the example is indeed irrational, how is it possible an untrue constructed example could be used to verify this proof? If it's indeed rational, can someone tell me the $a/b$ representation of this number? PS: Sorry for the formatting errors, I followed the MathJax syntax to the best of my abilities but I'm not sure how to align the sub-points well. Please help me edit the post, thanks.",['discrete-mathematics']
2883345,Continuity of trace and norm,"Let $L|K$ be a finite extension of discrete valuation fields (not necessarily complete). Consider the classical maps: $$\operatorname{Tr}_{L|K}:L\to K$$
$$N_{L|K}:L^\times\to K^\times$$ Are such functions continuous with respect to the valuation topologies?","['field-theory', 'general-topology', 'abstract-algebra', 'valuation-theory']"
2883364,Why isn't this true for $x<0$?,"Prove that $$\lfloor{x}\rfloor=\bigg\lfloor{\frac{x+1}{2}}\bigg\rfloor+\bigg\lfloor{\frac{x+2}{2^2}}\bigg\rfloor+\bigg\lfloor{\frac{x+2^2}{2^3}}\bigg\rfloor+
 \ldots$$
  $x\geq{0}$ I asked this question here yesterday. Although I was able to come up with a proof, the second part was left unanswered. I proved it using, Subtract $\lfloor{x}\rfloor$ from both sides. Then we need to prove that,
  $$-\lfloor{x}\rfloor+\bigg\lfloor{\frac{x+1}{2}}\bigg\rfloor+\bigg\lfloor{\frac{x+2}{2^2}}\bigg\rfloor+\bigg\lfloor{\frac{x+2^2}{2^3}}\bigg\rfloor+
 \ldots=0$$ We know that,
  $\lfloor{x}\rfloor=\bigg\lfloor{\frac{x}{2}}\bigg\rfloor+\bigg\lfloor{\frac{x+1}{2}}\bigg\rfloor$ Therefore,
  $-\lfloor{x}\rfloor+\bigg\lfloor{\frac{x+1}{2}}\bigg\rfloor=-\bigg\lfloor{\frac{x}{2}}\bigg\rfloor$ Subsituting this, $$-\bigg\lfloor{\frac{x}{2}}\bigg\rfloor+\bigg\lfloor{\frac{x+2}{2^2}}\bigg\rfloor+\bigg\lfloor{\frac{x+2^2}{2^3}}\bigg\rfloor+
 \ldots$$ $$-\bigg\lfloor{\frac{x}{2}}\bigg\rfloor+\bigg\lfloor{\frac{\frac{x}{2}+1}{2}}\bigg\rfloor+\bigg\lfloor{\frac{x+2^2}{2^3}}\bigg\rfloor+
 \ldots$$ Similarly, I reach, $$\lim_{n\to\infty}-\bigg\lfloor{\frac{x}{2^n}}\bigg\rfloor+\bigg\lfloor{\frac{\frac{x}{2^n}+1}{2}}\bigg\rfloor$$ i.e. $$=0$$ My question is,as $\lfloor{x}\rfloor=\bigg\lfloor{\frac{x}{2}}\bigg\rfloor+\bigg\lfloor{\frac{x+1}{2}}\bigg\rfloor$ is true $\forall x\in{\mathbb{R}}$. Why isn't
$$\lfloor{x}\rfloor=\bigg\lfloor{\frac{x+1}{2}}\bigg\rfloor+\bigg\lfloor{\frac{x+2}{2^2}}\bigg\rfloor+\bigg\lfloor{\frac{x+2^2}{2^3}}\bigg\rfloor+
 \ldots$$ true $\forall x\in{\mathbb{R}}$. Also how would the expression change for $x\lt{0}$. Thank you.","['ceiling-and-floor-functions', 'functions']"
2883369,characteristic function for independent $X$ and $Y$,"$X$ and $Y$ are independent, identically distributed random variables with mean $0$, variance $1$ and characteristic function $\phi$, If $X+Y$ and $X-Y$ are independent, prove that $$\phi(2t)=\phi(t)^3\phi(-t).$$By making the substitution $\gamma(t)=\phi(t)/\phi(-t)$ or otherwise, show that, for any positive integer $n$,$$\phi(t)={\left\{1-\frac {1}{2}{\left(\frac{t}{2^n}\right)}^2+o\left({\left[\frac t{2^n}\right]}^2\right)\right\}}^{4^n}$$ Hence, find the common distribution of $X$ and $Y$. I know how to do the first part. However for the second part, I have no idea at all. Can anyone teach me? Thanks.","['characteristic-functions', 'probability-theory']"
2883390,Riemannian holonomy of a covering,"Suppose I have a connected Riemannian manifold $X$ and a covering $\pi:Y\to X$ with the pulled back metric on $Y$, making $\pi$ into a local isometry between Riemannian manifolds. Suppose we have a closed loop in $Y$ based at a point $y\in Y$. This will give rise to an element of the holonomy group $\mathrm{Hol}_y(Y)$, which after we fix a basis of $T_yY$ becomes an element of $\mathrm{GL}(n)$ (or $\mathrm O(n)$ really). If we project the path to $X$, we get a closed loop again, hence an element of $\mathrm{Hol}_xX$, where $x = \pi(y)$, and by using $\pi$ to map the basis of $T_yY$ to one of $T_xX$ this becomes an element of $\mathrm{GL}(n)$ as well, and we can talk about equality in a sensible way. Since all along the paths the geometry is identical (around every point there is a neighbourhood on which $\pi$ induces an isometry) it seems clear that they must induce the same element in holonomy. This would mean that the holonomy of $Y$ is a subgroup of the holonomy of $X$. This inclusion can be strict, if $X$ is not orientable for example, its holonomy group might be $\mathrm O(n)$, but if we take $Y$ to be its oriented double cover its holonomy must be contained in $\mathrm{SO}(n)$. Can anything more precise be said about the relation between the holonomy groups of $X$ and of $Y$? I would expect the fundamental group or rather the group of deck transformations to play a role, but I don't know in what form. Thanks!","['covering-spaces', 'holonomy', 'curvature', 'differential-geometry']"
2883396,Initial value theorem for Fourier transform,"Initial value theorem states that for a bounded function $f(t) = O(e^{ct})$ and an existing initial value, one-sided Laplace transform $F(s) = \int\limits^\infty_{0^-}f(\tau)e^{-s\tau}\mathrm{d\tau}$ can give the initial value of this function:
$$
\lim_{t\rightarrow 0}{f(t)} = \lim_{s\rightarrow\infty}sF(s) \tag 1
$$ Is there a similar theorem for the Fourier transform $\mathcal{F}(\omega) = \int\limits^\infty_{-\infty}f(\tau)e^{-j\omega\tau}\mathrm{d\tau}$, something along the lines:
$$
\lim_{t\rightarrow 0}{f(t)} = \lim_{j\omega\rightarrow\infty}j\omega \mathcal{F}(j\omega) \tag 2
$$ I find myself lacking the knowledge of complex analysis. I have a problem with formulation of the above hypothesis. I am not sure whether it's legal to write $j\omega\rightarrow\infty$. Also, one of the potential issues I see that I am trying to formulate the same theorem for the two-sided transform. Could you help me prove or disprove the above statement for the Fourier transform? Any pointers are appreciated.","['complex-analysis', 'fourier-transform', 'laplace-transform']"
2883413,Thoughts about the Lucas Theorem,"We define $f(n) = max \{k \in \mathbb{N} \text{, such that $2^k$ divides n} \}$. As an example, $f(99) = 0$, $f(5) = 0$, $f(12) = 2$, $f(14) = 1$.
Now further let's define $g(n) := f(n!)$. Finding a recurrence, if $n$ is odd then $g(n) = g(n-1)$. How can we write $g(n)$ in terms of a closed formula? How can we describe the even variant in terms of $g(n/2)$?
And if we can describe it, what would be the closed formula for two evens $a,b$ for the equation $g(a) - g(b)$? As an example $g(8.000.000.000.000) - g(4.000.000.000.000) = ?$","['combinatorics', 'discrete-mathematics']"
2883423,Why does integrating Brownian motion transition probability and first hitting time density produce a Cauchy?,"I was reviewing some facts and concepts on Brownian motion and came through this result which is kind of mind blowing, and wanted to ask some insight on why it's the way it is. Given a probability space $(\Omega, \mathcal{F}, P)$ equipped with a filtration $\{\mathcal{F}\}_{t \geq 0}$, suppose we have a standard Brownian motion $B$ adapted to said filtration. For said Brownian motion, it is well known that the random variable first hitting time $T_\beta$ for a level $\beta$ has density function $$f_{T_\beta}(t) = \frac{|\beta|}{\sqrt{2\pi t^3}}\exp\left\{-\frac{\beta^2}{2t}\right\} \quad t>0$$ and that the transition probability for standard Brownian motion from $0$ to $x$ in time $t$ is given by $$p(x,t) = \frac{1}{\sqrt{2\pi t}}\exp\left\{ -\frac{x^2}{2t}\right\} \quad t>0$$ Now the result I was referring to in the introduction is that $$\int_0^\infty f_{T_\beta}(s) p(x,s) ds = \frac{|\beta|}{\pi(\beta^2 + x^2)}$$ The proof is not shown in the book since it's quite trivial. Still, I fail to grasp the underlying intuition behind it. Why does the result of this integral turn out to be Cauchy? And could changing the transition law $p$ (to the one of say some other process) produce other probability distributions when integrated after being multiplied by their first hitting time distributions?","['brownian-motion', 'probability-theory', 'intuition']"
2883448,Differential equation: $x''=\frac{2x}{x^2-1}$,"I want to solve the differential equation$$\begin{cases}x''=\frac{2x}{x^2-1}\\x'(0)=0\\x(0)=x_0\end{cases}$$ This is what I have done so far. I have not studied differential equation much, and introducing the function $s$ below is just a trick that I learned, but I'm not sure why/if it works. Let $s:=x'$. Then 
$$\frac{d^2x}{dt^2}=\frac{ds}{dt}=\frac{ds}{dx}\frac{dx}{dt}=\frac{ds}{dx}s$$
so the above equation becomes $$s\frac{ds}{dx}=\frac{2x}{x^2-1}$$
$$s\,ds=\frac{2x}{x^2-1}\,dx$$$$\int s\,ds=\int\frac{2x}{x^2-1}\,dx+C$$
$$s^2=\log\lvert x^2-1\rvert+C$$$$x'=\omega\sqrt{\log\lvert x^2-1\rvert+C},\,\omega:\mathbb R_+\mapsto\{-1,1\}$$
and with $x'(0)=0$, $x(0)=x_0$ we have
$$x'=\omega\sqrt{\log\bigg\lvert\frac{x^2-1}{x_0^2-1}\bigg\rvert}$$
How can I continue to solve for $x(t)$? And am I justified in introducing $s$ and treat the notation like I did to obtain $x'$?",['ordinary-differential-equations']
2883455,Limit of $n \left(\frac{1}{2}-e^{-n}\left(1+n+\frac{n^2}{2!}+...+\frac{n^n}{n!}\right)\right)$,"It is known around here that $$\lim_{n\to\infty }e^{-n}\left(1+n+\frac{n^2}{2!}+...+\frac{n^n}{n!}\right)=\frac12$$ So what about the following limit:
$$L=\lim_{n \to \infty}n \left(\frac{1}{2}-\frac{1}{e^n}\left(1+n+\frac{n^2}{2!}+...+\frac{n^n}{n!}\right)\right)$$ My thought was to apply Stolz-Cesaro theorem, after rewritting as $$L=\lim_{n \to \infty}\frac{ \left(\frac{1}{2}-\frac{1}{e^n}\left(1+n+\frac{n^2}{2!}+...+\frac{n^n}{n!}\right)\right)}{\frac1n}$$ would produce: $$L=\lim_{n \to \infty}\frac{e^{-(n+1)}\left(1+(n+1)+\frac{(n+1)^2}{2!}+...+\frac{(n+1)^{n+1}}{(n+1)!}\right)-e^{-n}\left(1+n+\frac{n^2}{2!}+...+\frac{n^n}{n!}\right)}{\frac1{n(n+1)}}$$
$$=\lim_{n \to \infty}\frac{e^{-n}\left(\frac{1-e}{e} +\frac1e\frac{(n+1)^{n+1}}{(n+1)!} +n\left(\frac{\left(1+\frac1n\right)}{e}-1\right) +\frac{n^2}{2!}\left(\frac{\left(1+\frac1n\right)^2}{e}-1\right)+\cdots +\frac{n^n}{n!}\left(\frac{\left(1+\frac1n\right)^n}{e}-1\right)\right)}{\frac1{n(n+1)}}$$ But I dont see how can I go further, can you help me evaluate it? Also, are limits of this form already known?","['limits', 'exponential-function']"
2883489,What is the radius of this circle?,"Polygon $ABC$ is an equilateral triangle. Three congruent semicircular arcs are drawn on the three sides and towards the interior of the triangle. The terminal points of the semicircular arcs are the three vertices of the triangle $ABC$.
Semicircle $C_1$ of diameter $AB$
Semicircle $C_2$ of diameter $BC$
Semicircle $C_3$ of diameter $CA$ A small circle $F$ is drawn such that it is tangent internally to $C_1$ and $C_3$ and externally to $C_2$ What is the radius of circle $ F$? Here is the picture","['circles', 'geometry']"
2883509,If $f^{-1}[\cap_{i\in i}B_i]\subseteq f^{-1}[B_i]\Rightarrow f^{-1}[\cap_{i\in i}B_i]\subseteq \cap_{i\in I}f^{-1}[B_i]$,"I may be missing something trivial, I manage to prove that 
for all $i\in I$ we get $$f^{-1}[\cap_{i \in I}B_i]\subseteq f^{-1}[B_i]$$ Now, why can I take the intersection and say that: $$f^{-1}[\cap_{i \in I}B_i]\subseteq \cap_{i\in I}f^{-1}[B_i]$$",['elementary-set-theory']
2883526,"If the order in a set doesn’t matter, can we change order of, say, $\Bbb{N}$?","I’m given to understand that the order of the elements of a set doesn’t matter. So can I change the order of the set of natural numbers or any set of numbers ( $\mathbb{W,Z,Q,R}$ for that matter) as follows?
$$ \mathbb{N} = \{ 1,2,5,4,3,\cdots \} $$
$$ \mathbb{N}= \{3,5,\cdots,78,1,9\} $$ If yes, is this is really problematic? If not, then why not? PS: I know this is a silly question, but this has been in the back of my mind for a really long time.","['elementary-set-theory', 'natural-numbers']"
2883565,Question about compactness of the zero set of an analytic function of several variables,"Hartogs's Theorem Let $f$ be a  holomorphic function on a set $G \setminus K$, where $G$ is an open subset of $\mathbb{C}^n$ ($n \ge
 2$) and $K$ is a compact subset of $G$. If the complement $G\setminus
 K$ is connected, then $f$ can be extended to a unique to a unique
  holomorphic function on $G$. This theorem can be used to show the following result about the zeros of analytic functions of several variables. Suppose that $f$ is an analytic function on some open set $U$ and that
  $f$ is not identically zero on $U \subset \mathbb{C}^n$ with $n \ge 2$.
  Then, the set of zeros of $f$ (i.e. $\Lambda(f)=\{ z: f(z)=0\}$) is not compact. Since  $\Lambda(f)$ is not compact we can have the following three possibilities: $\Lambda(f)$ is closed but is not bound $\Lambda(f)$ is not closed but  bounded $\Lambda(f)$ is not closed and not bounded My question is the following: Can we come up with examples of $f$ for each of the three cases? Here is an example of the function that satisfies the first case.  Let  $f_1(z_1,z_2)=z_1 \cdot z_2$ then
\begin{align}
\Lambda(f_1)= \{  (z_1,z_2) : z_1=0 \} \cup \{  (z_1,z_2) : z_2=0 \}. 
\end{align}
where  $\Lambda(f_1)$ is closed but not bounded.","['complex-analysis', 'multivariable-calculus']"
2883591,"Skew-symmetric multi-derivations of $k[x_1,\ldots,x_n]/I$","Let $I = \langle f_1, \ldots f_r \rangle$ be an ideal in $R=k[x_1,\ldots,x_n]$ where $k$ is a field, and put $A = R/I$ . (If $k$ is algebraically closed and $I$ is radical then $A$ is the coordinate ring of an affine variety.) Let $\mathfrak{X}^p(A) = \operatorname{Der}_k(\wedge^p A, A) $ be skew-symmetric $p$ -derivations (derivation in each argument) of $A$ . Question : Is there an algorithm to calculate $\mathfrak{X}^p(A)$ in terms of $f_1,\ldots,f_r$ ? I am interested in $p=1,2,3$ . What I have tried/observed so far: The condition that $P \in \mathfrak{X}^p(R)$ descends to (is well-defined on) $\mathfrak{X}^p(A)$ is a system of (ideal membership) equations $$P(x_{i_1}, \ldots, x_{i_{p-1}}, f_j) \in I \quad \text{for each } 1\leq i_1<\cdots<i_{p-1}\leq n \text{ and } 1\leq j\leq r.$$ (Note also every element of $\mathfrak{X}^p(A)$ has a lift to $\mathfrak{X}^p(R)$ .) Letting $P_{i_1,\ldots,i_p} = P(x_{i_1},\ldots,x_{i_p}) \in R$ be the (sought for) coefficients of $P$ , the system becomes $$\sum_k P_{i_1,\ldots,i_{p-1},k} \frac{\partial f_j}{\partial x_k} \in I \quad \text{for each } 1\leq i_1<\cdots<i_{p-1}\leq n \text{ and } 1\leq j\leq r.$$ Here one can restrict to the sum over $k \in \{1,\ldots,n\} \setminus \{i_1,\ldots i_{p-1}\}$ . Note the equations are not independent, due to skew-symmetry. The equations above for fixed $j$ suggest to consider the intersection $I \cap \langle \frac{\partial f_j}{\partial x_1}, \ldots \frac{\partial f_j}{\partial x_n} \rangle$ which can be computed using Groebner bases. I am not sure what we can conclude about the coefficients $P_{i_1,\ldots,i_{p-1},k}$ . Furthermore, I do not see how one would combine these results for different $(i_1,\ldots,i_{p-1})$ 's and $j$ 's. $\mathfrak{X}^p(A)$ is an $A$ -module. I think it is finitely generated. (I am interested in the case where it is.) $\mathfrak{X}^p(A) \cong \operatorname{Hom}_A(\Omega^p(A), A)$ where $\Omega^p(A)$ are Kähler $p$ -forms. $\mathfrak{X}^2(A) \neq \wedge^2 \mathfrak{X}^1(A)$ in general: 
if $I = \langle yx, yz, y^2 \rangle$ in $R=\mathbb{C}[x,y,z]$ then $0 \neq y \frac{\partial}{\partial y} \wedge \frac{\partial}{\partial z}$ is in $\mathfrak{X}^2(A)$ and not in $\wedge^2 \mathfrak{X}^1(A)$ . I would also be interested in (classes of) examples where one can calculate $\mathfrak{X}^p(A)$ explicitly for $p=1,2,3$ .","['groebner-basis', 'affine-varieties', 'algebraic-geometry', 'ideals', 'commutative-algebra']"
2883613,Prove that there exists no differentiable real function $g(x)$ such that $g(g(x))=-x^3+x+1$.,"Prove that there exists no differentiable real function $g(x)$ such that $g(g(x))=-x^3+x+1$. I have googled it but find nothing useful. Now I know it's a Iterated function problem. It's an exercise problem after the chapter DERIVATIVE , so I guess maybe it's not too difficult. Could you give me a hint to solve this problem? Could you give me a book list about the  systematic introduction about Iterated function?",['calculus']
2883720,Closed form of a logarithmic sum involving binomial coefficient,"I am trying to simplify an equation and in a term I have the following, 
$$\sum _{k=1}^n\binom{n}{k}k \log _2(k) $$
I was wondering if I can write above in closed form?","['summation', 'binomial-coefficients', 'closed-form', 'discrete-mathematics', 'sequences-and-series']"
2883759,"Solve $ \binom{a}{2} + \binom{b}{2} = \binom{c}{2} $ with $a,b,c \in \mathbb{Z}$","I am trying to solve the Diophantine equation: $$ \binom{a}{2} + \binom{b}{2} = \binom{c}{2} $$ Here's what it looks like if you expand, it's variant of the Pythagorean triples: $$ a \times (a-1) + b \times (b-1) = c \times (c-1) $$ I was able to find solutions by computer search but this could have also been checked using the Hasse principle.
\begin{eqnarray*}
\binom{3}{2}+ \binom{3}{2}&=& \binom{4}{2} \\ \\
\binom{5}{2}+ \binom{10}{2}&=& \binom{11}{2} \\ \\
\binom{15}{2}+ \binom{15}{2}&=& \binom{21}{2} 
\end{eqnarray*} and many others.  Is there a general formula for the $(a,b,c) \in \mathbb{Z}^3$ that satisfy this integer constraint. >>> N = 25
>>> f = lambda a : a*(a-1)/2
>>> X = [(a,b,c,f(a) + f(b) - f(c)) for a in range(N) for b in range(N) for c in range(N)] 

>>> [(x[0],x[1],x[2]) for x in X if x[3] == 0 and x[0] > 1  and x[1] > 1 and x[2] > 1]

[( 3,  3,  4),  ( 4, 6, 7) , ( 5, 10, 11), ( 6,  4,  7), ( 6,  7,  9), 
 ( 6, 15, 16),  ( 7, 6, 9) , ( 7, 10, 12), ( 7, 21, 22), ( 9, 11, 14), 
 (10,  5, 11),  (10, 7, 12), (10, 14, 17), (10, 22, 24), (11,  9, 14), 
 (12, 15, 19), (12, 21, 24), (13, 18, 22), (14, 10, 17), (15,  6, 16), 
 (15, 12, 19), (15, 15, 21), (15, 19, 24), (18, 13, 22), (19, 15, 24), 
 (21,  7, 22), (21, 12, 24), (22, 10, 24)]","['number-theory', 'pythagorean-triples', 'quadratic-forms', 'diophantine-equations']"
2883763,How do I find the line perpendicular to the intersection of two planes and going through a certain point?,"The line $r$ has the following equation: 
$ \begin{cases} 
x-y+2=0 \\
2x-z+1=0
\end{cases} $ What's the equation of the line perpendicular to $r$ and going through $P(0,0,-1)$, written in the same form as $r$? I started solving the system of equations and got $\begin{cases} x=-\dfrac{1}{2} + \dfrac{1}{2} t \\ y = \dfrac{3}{2} + \dfrac{1}{2}t \\
z=t\end{cases}$ but I'm not sure what to do from here. Thanks in advance.","['geometry', '3d']"
2883765,Find the $n$-th derivative of $f(x)=\frac{x}{\sqrt{1-x}}$,"Find the $n$-th derivative of
$$f(x)=\frac{x}{\sqrt{1-x}}$$
First I just calculated the first, second and 3-th, 4-th derivatives and now I want to summarize the general formula. But it seems too complicated. Then I want to use binomial theorem or Taylor expansion... Also got no more clues.","['calculus', 'derivatives']"
2883768,Do we have $(\mathcal L\otimes_{\mathcal O_X}\mathcal L)(X)=\mathcal L(X)\otimes_{\mathcal O_X(X)}\mathcal L(X)$?,"Let $X$ be a scheme and $\mathcal L$ an invertible sheaf on $X$, do we have $(\mathcal L\otimes_{\mathcal O_X}\mathcal L)(X)=\mathcal L(X)\otimes_{\mathcal O_X(X)}\mathcal L(X)$?","['algebraic-geometry', 'schemes', 'sheaf-theory']"
2883779,What is the difference between ∀x(p(x) →q(x)) and ∀x(p(x) ∧q(x))?,"Textbook(Discrete Mathematics with Applications by Susanna S. Epp) says that $\forall x$ in $D$, $p(x)$ can be written as $\forall x$ in $D$$\to p(x)$, $\exists x$ in $D$, $p(x)$ can be written as $\exists x$ in $D$$\land p(x)$. but I am wonder, does it make no sense to say that $\forall x$ in $D$, $p(x)$ can be written as $\forall x$ in $D$$\land p(x)$, $\exists x$ in $D$, $p(x)$ can be written as $\exists x$ in $D$$\to p(x)$? I cannot understand why can $\forall x$ in $D$, $p(x)$ / $\exists x$ in $D$, $p(x)$ be written as $\forall x$ in $D$$\to p(x)$ / $\exists x$ in $D$$\land p(x)$ but $\forall x$ in $D$$\land p(x)$ / $\exists x$ in $D$$\to p(x)$.","['propositional-calculus', 'predicate-logic', 'discrete-mathematics']"
2883791,Coefficients such that linear combination lies in an ideal,"Let $R$ be a ring, $I$ an ideal, and $\langle g_1, \ldots, g_m \rangle$ a finitely generated ideal. Considering the intersection $I \cap \langle g_1, \ldots, g_m \rangle$, I became interested in the set of coefficients $c \in R^m$ such that $\sum_i c_i g_i \in I$. Question : is there an algorithm to calculate $\{ c \in R^m : \sum_i c_i g_i \in I \}$? It seems to be an $R$-module. It is easy to see that $\prod_i (I : (g_i))$ is contained in it (which contains $IR^m$). Does it have a name? Can it be expressed in terms of some other objects which can be computed? I am interested in the case $R = k[x_1,\ldots,x_n]$ where $k$ is a field, and (so) the ideal $I$ is also finitely generated. Maybe a Groebner basis of the intersection could help. Solution attempt : Suppose $I \cap \langle g_1, \ldots, g_m \rangle$ is finitely generated (e.g. $R$ is Noetherian). Say it is equal to $\langle h_1, \ldots, h_t \rangle$, and express $h_s = \sum_i b_{s,i} g_i$ with $b_{s,i} \in R$. Then $b_s = (b_{s,i}) \in R^m$ is contained in the set I'm interested in, for each $s=1,\ldots,t$. So the span $Rb_1+ \ldots+ Rb_t \subset R^m$ is contained in the set I'm interested in. Now the question is whether a different choice of basis for the intersection (or a different choice of coefficients) can give more elements in the span, and whether $Rb_1 + \ldots + Rb_t$ exhausts the set I'm interested in.","['groebner-basis', 'ring-theory', 'abstract-algebra', 'ideals', 'commutative-algebra']"
2883793,Additive non-sequential pdf sampling from a multidimensional distribution,"I've developed a method for sampling from a multidimensional distribution and want to ask the MathExchange community two questions: (a) is it correct, and (b) if so, what is the best way to notate it? For a 1-D probability distribution, drawing a sample is a straightforward inversion of the CDF $F(x)$ : $$X=F^{-1}(U[0,1])$$ where $F(x)=\int_{-\infty}^x f(u)\,du$ and $f(x)\,dx$ is the probability of $X$ being found between $x$ and $x+dx$ . This equation is deployed as follows: pick a random number between 0 and 1 starting at negative infinity, take steps $dx$ in the $+x$ direction, adding increments of probability density $f(x)dx$ as you go. Once this sum reaches the random number drawn in step 1, the value of $x$ at which this occurs is your sample. My question is about the validity of a similar method which can be used in multiple dimensions where the concept of inverting $F(x)$ to produce a sample is not as straight forward. The idea is to approximate a sample by selecting random points $x_j$ and then accumulating the corresponding values of pdf $f(x) \, \Delta x$ increments until a $u_*=U[0,1]$ target value is exceeded.  Just like steps 1 and 2 listed above, but instead of integrating sequentially, you add up pdf increments from randomly chosen points. Key concepts are (a) the starting point for the integration doesn't matter (b) you do not need to perform the integration/summation sequentially. I had previously posted (link/citation below) about performing a sequential integral spiraling outward from origin (one could also spiral inward or scan left to right downward, etc) previous post of mine (since deleted my Cross Validated account due to moderation disputes) on spiral path sampling The point which finally causes the sum to exceed the ""step 1"" $U[0,1]$ draw is the point taken as sample.  My attempt to notate this is as follows (asking for improved notation as part of my question). $$X \approx x_n \text{ where } n= \min n \ni U[0,1]<\sum_{j=1}^{n} f(x_j=U[a,b])\,\Delta x$$ where the hyper-rectangular region framed by $a$ and $b$ contain the meat of the pdf $f(x)$ . Is there a name for this ""non-sequential integral"" alternative/method? It seems to provide a relative convenient (though computationally intensive) way to sample from a multidimensional distribution.
Please let me know if there is an easier/more correct way to express this idea. (my first use of $\ni$ ""such that"" (?) for instance) 1-d sampling spreadsheet example Thanks in advance and comments are welcome. Bonus question: what is the distribution of $x_{n-1}$ ? VBA code example of 3-D sampling Function drawabp(datarange As Range, 
astart As Double, aend As Double, 
bstart As Double, bend As Double, 
pstart As Double, pend As Double, 
dx As Double, mle As Double) As String

    Dim ptest As Double
    Dim atest As Double
    Dim btest As Double
    Dim zsum As Double
    Dim Ftarget As Double


    zsum = 0
    Ftarget = Rnd()

    While zsum < Ftarget
        ptest = (pend - pstart) * Rnd() + pstart
        atest = (aend - astart) * Rnd() + astart
        btest = (bend - bstart) * Rnd() + bstart
        zsum = zsum + Exp(lnlklhd(datarange, ptest, atest, btest) - mle) * dx
    Wend
    drawabp = ptest & "","" & atest & "";"" & btest
    End Function 1-D spreadsheet example Example of 2-D sampling Function drawabp(datarange As Range, 
astart As Double, aend As Double, 
bstart As Double, bend As Double,  
dx As Double, mle As Double) As String

    Dim atest As Double
    Dim btest As Double
    Dim zsum As Double
    Dim Ftarget As Double


    zsum = 0
    Ftarget = Rnd()

    While zsum < Ftarget
        atest = (aend - astart) * Rnd() + astart
        btest = (bend - bstart) * Rnd() + bstart
        zsum = zsum + Exp(lnlklhd(datarange, atest, btest) - mle) * dx
    Wend
    drawabp = atest & "","" & btest
    End Function Some notes on the method: It seems as though the pdf $f(x)$ doesn't necessarily need to be properly normalized, but it does need to be ""small enough"" (which I haven't quantified). The intuitive reason for this is that since the addition of pdf voxels doesn't have a required starting point, or a required path, the only thing that matters is that the number of additions in order to sum to unity is ""large enough"" (again not quantified) I would be interested on co-authoring a paper on this with anyone who can help me flesh out the ideas and solidify the notation, etc. This probably goes without saying, but you can set a limit on the number of pdf samples to add up and if you exceed that limit you can simply abandon the sum and begin again.  So, for example (in my spreadsheet example $n$ =35""), if after adding 35 pdf samples, instead of adding a 36th in an attempt to reach the $U[0,1]$ target value, you can simply discard the sum and begin again.","['statistics', 'probability-distributions', 'probability-theory', 'sampling']"
2883837,How to properly choose a solution to a system of equations of trigonometric functions?,"I worked my way to encounter a system of equations \begin{equation}
\begin{cases} 
      q=k_1\cos\phi_1+k_2\cos\phi_2&  \\
      0=k_1\sin\phi_1+k_2\sin\phi_2&
   \end{cases}
\end{equation} I don't need to solve for specific angles $\phi_1,\phi_2$ because these equations will probably be very rough, but it's enough to know the answer in terms of $\cos\phi_1$ and $\sin\phi_2$ or vice versa. If I am looking to solve this by hand then what I have to do is obviously rewrite one of the trigonometric functions in terms of the other, for example \begin{equation}
\begin{cases} 
      q=k_1\cos\phi_1\pm k_2\sqrt{1-\sin^2\phi_2}&  \\
      0=\pm k_1\sqrt{1-\cos^2\phi_1}+k_2\sin\phi_2&
   \end{cases},
\end{equation}
where now it's just basic algebra to solve the equations. My question concerns the $\pm$ signs that appear there. I can rearrange the equations in such a way, that after squaring them I get a sign independent result again. Hence I get a unique solution to this equation. But to me that seems weird - I would assume I should get solutions that aren't unique. I assume that I must at some point arrive at some expression that differs by (at least) a sign, since I am expressing everything in terms of $\cos\phi_1$ and $\sin\phi_2$, which can swap signs depending on their argument.
Could anyone clear this up for me?","['trigonometry', 'systems-of-equations']"
2883859,"Is $\langle Ax,x \rangle\in \overline{M}$?","In this question $F$ stands for a complex Hilbert space with inner product $\langle\cdot\;,\;\cdot\rangle$ and the norm $\|\cdot\|$. Let $\mathcal{B}(F)$ the algebra of all bounded linear operators on $F$. Let $A\in\mathcal{B}(F)$ and consider
 $$M=\{\langle Ax,x \rangle;\;x\in \text{Im}(A), \|x\|=1\}.$$ Let $c\in M$, then there exists $x\in \text{Im}(A)$ such that $\|x\|=1$ and $c=\langle Ax,x \rangle$. If there exists $(x_n)_n\subset \text{Im}(A)$ such that $\|x_n-x\|\to 0$. Then we have $\langle Ax_n,x_n \rangle\to \langle Ax,x \rangle$. Further, clearly $\|x_n\|\to1$. In this case it is true that $c=\langle Ax,x \rangle\in \overline{M}$? Where $\overline{M}$ is the closure of $M$ with respect to the topology induced by $\mathbb{C}$. My problem is that we have only $\|x_n\|\to1$. However, I think in order to get  $\langle Ax,x \rangle\in \overline{M}$, we should prove that $\|x_n\|=1$ for all $n$.","['hilbert-spaces', 'general-topology', 'functional-analysis']"
2883934,When should I measure the angle of a complex number clockwise or anticlockwise?,In this diagram theta is measured anticlockwise. How would I know from which side to measure the angle? In this diagram theta is measured clockwise.,"['trigonometry', 'functions', 'complex-numbers']"
2883971,Non cyclic group of order $8$ having exactly one element of order $2$,"Let $G$ be a non-cyclic group of order $8$ having exactly one element of order $2$. Prove that $G$ is generated by elements $a$ and $b$ subject to the relations $a^4=1$ and $a^2=b^2$. I can start this by a process of elimination if I know all groups of order $8$: It can not be an abelian group because it is not cyclic and all others have more then one element of order 2. It can not be the dihedral group of order $8$ $D_8=\langle x,y\mid y^4=x^2=1, xyx^{-1}=y^{-1}\rangle$ because it also has more then one element of order $2$ ($y^2$ and $x$). The only remaining group are the quaternions $H=\langle x,y\mid x^4=1, x^2=y^2, yxy^{-1}=x^{-1}$. How do I see that the third relation holds? And is there any chance to solve this without knowing all groups of order $8$?","['group-theory', 'finite-groups', 'dihedral-groups']"
2883982,"$\forall x\in [0,1]$, if $f(t)f(t-x)$ is integrable, then $f(t)$ is integrable?","The original problem (from here problem 8) is: Let $\alpha>\frac{1}{2}$ be a real number. Prove that it is impossible to find a real function $f$ such that
$$f(x)=1+\alpha\int_x^1 f(t)f(t-x) \, dt$$
holds for all $0\leq x\leq1$. My solution: Integrate both sides for $x$ from $0$ to $1$ and suppose $s=\int_0^1f(x) \, dx$. Then the equality becomes $s=1+\frac{1}{2}\alpha s^2$. Apply AM-GM to finish the proof. However, my solution works only when $f(x)$ is integrable (on $[0,1]$). My question is: if the equality in the problem holds, then $\forall x\in [0,1]$, $f(t)f(t-x)$ is integrable, so is it true that $f(x)$ is integrable? If it is not true, is there an explicit counterexample? For all ""integrable"" here, I think I mean ""Riemann integrable"". I have not studied the Lebesgue theory yet.","['integration', 'analysis', 'real-analysis', 'calculus', 'riemann-integration']"
2883987,Proof function mapping from standard normals to standard normal is lipschitz-1,"Let $X_1,...,X_n$ be i.i.d $\mathcal{N}(0,1)$ and let $f: \mathbb{R}^n \rightarrow \mathbb{R}$ be a $L$-Lipschitz function. I'm trying to prove that if $f(X_1,...,X_n) \sim \mathcal{N}(0,1)$ then $f$ is 1-Lipschitz. ( Tsirelson-Ibragimov-Sudakov 1976 ) Let $X_1,...,X_n$ be i.i.d $\mathcal{N}(0,1)$ and let $f: \mathbb{R}^n \rightarrow \mathbb{R}$ be a $L$-Lipschitz function with respect to the Euclidean norm. Then
  \begin{equation}
    \mathbb{P}\left[f(X_1,...,X_n) - \mathbb{E}\left[f(X_1,...,X_n)\right] \geq t\right] \leq e^{\frac{-t^2}{2L^2}}
  \end{equation}
  If $f(X_1,...,X_n) \sim \mathcal{N}(0,1)$ then the expectation of $f=0$ and by the markov inequality we have
  \begin{align}
    \mathbb{P}\left[f(X_1,...,X_n) \geq t\right] &=\\ 
    \inf_{\lambda>0} \mathbb{P}\left[\exp(\lambda f(X_1,...,X_n)) \geq e^{\lambda t}\right] &\leq\\
    \inf_{\lambda>0} e^{-\lambda t}\mathbb{E}\left[\exp(\lambda f(X_1,...,X_n))\right] &=\\
    \inf_{\lambda>0} e^{\frac{\lambda^2}{2} - \lambda t} = e^{\frac{-t^2}{2}}
  \end{align}
  after making the optimal choice $\lambda = t$. We now can rewrite our Lipschitz bound as:
  \begin{equation}
    \mathbb{P}\left[f(X_1,...,X_n) \geq t\right] \leq e^{\frac{-t^2}{2}} \leq e^{\frac{-t^2}{2L^2}}
  \end{equation}
  Therefore 
  \begin{align}
    ||f||_L \geq 1 \\
  \end{align} This is as far as I got. Is there a way to upper bound the $||f||_L$?","['probability-theory', 'functional-analysis', 'lipschitz-functions']"
2884077,Triangular grids on a torus,"Definitions The torus that we consider is the flat representation given by the quotient $\mathbb{C}/\mathbb{Z}[i]$, or equivalently as the set
$$
\tau = \{\, (x, y) \in \mathbb{R}^{2} : 0 \leq x, y \leq 1 \,\}
$$
with the points $(x, y), (x+1, y), (x, y+1)$ identified. The 3D torus is not of interest here. Consider the torus as a subset of $\mathbb{R}^{2}$. Then a line is what we would usually consider a straight line in $\mathbb{R}^{2}$, with the identification of edges possibly splitting the line into many segments bounded by the boundary of the torus. For example, the following (left) image is the line of gradient $4/3$ on the torus that passes through $(0,0)$. The right image is twelve tilings of the flat representation to show where each segment on the left comes from. A partitioning of the torus is an arrangement of lines on the torus. These lines must extend from boundary to boundary, as above. A triangular grid is a partitioning of the torus by three sets of parallel lines such that every vertex has degree $6$ and every face is a triangle. We may assume the lines to be horizontal, vertical, and of a rational slope if necessary. One example of a triangular grid is given below, followed by five partitions that are allowed on the torus. It is important that there are exactly three distinct gradients that the lines can have, and that the lines continue from boundary to boundary . For example, the flat representation of the {""Circulant"", {9, {1, 2, 3}}} graph (taken from Ed Pegg's answer below ) does not fit the requirements of a triangular grid as the lines do not have exactly three different gradients. This is not an allowed partition either as not all lines extend from boundary to boundary. Useful Identities Let every intersection of lines induce a vertex, let each line segment between connected vertices be an edge, and let the closed interior of at least two incident edges be a face. Let $V, E, F$ be the number of vertices, edges, and faces that the torus is partitioned into, respectively. It is well known that the Euler characteristic of the torus is zero, so
$$
V - E + F = 0.\tag{1}
$$
Let $d(v)$ denote the degree of the vertex $v$ (which must be even, by construction). It is also well known that summing the degrees of all vertices gives
$$
2E = \sum d(v).\tag{2}
$$
Let $F_{s}$ denote the number of faces with $s > 1$ edges. When there are no loops in the graph, a simple counting argument shows that
$$
2E = \sum_{s \geq 2} sF_{s}.\tag{3}
$$
It is also trivial that $F = \sum_{s \geq 2} F_{s}$. Lemma -- Question We start with a simple lemma: Lemma. Consider a partitioning of the torus into $V$ vertices, $E$ edges, and $F$ faces that form a triangular grid. Then
  $$
E = 3V \qquad\text{and}\qquad F = 2V.
$$ Proof. Every face has $3$ edges, so $F = F_{3}$. By $(3)$, we have
$$
2E = \sum_{s\geq 2}sF_{s} = 3F_{3} = 3F.
$$
By $(1)$, we have $V - E + F = 0$ so that $3F - 3E = -3V$. We have a system of simultaneous equations, namely
$$
3F - 2E = 0 \qquad\text{and}\qquad 3F - 3E = -3V.
$$
Solving this gives $E = 3V$ and $F = 2V$ as required.$\qquad\square$ My question is the following. Is the converse of the Lemma true? That is, if some partitioning of the torus has $V$ vertices, $E$ edges, and $F$ faces such that $E = 3V$ and $F = 2V$, then is it true that the partition is necessarily a triangular grid? I have not yet been able to find a counter-example. In the proof of the converse, I want to prove that $d(v) = 6$ for all vertices $v$, and that $F_{3} = F$ with $F_{i} = 0$ for all $i \neq 3$. I have noticed that we cannot have any faces with more than $6$ edges so that the $s$ index only runs between $2$ and $6$, but there still seem to be too many variables to do anything (namely, each of the vertex degrees and the five $F_{s}$ for $s \in [2, 6]\cap\mathbb{Z}$).","['graph-theory', 'geometry', 'algebraic-topology']"
2884084,Are functions satisfying a certain inequality monotone,"Let $f: (0, \infty) \rightarrow (0,\infty)$ be a continuous function which satisfies the inequality
$$f(x) + f(y) \geq 2f(x+y).$$
Is $f$ necessarily monotone?","['functional-equations', 'functions', 'monotone-functions']"
2884094,Trace of product of two Hermitian matrices,"Let $A$ and $B$ be two Hermitian complex matrices. (a) Prove that
  $\operatorname{tr}(AB)$ is real. (b) Prove that if $A, B$ are
  positive, then $\operatorname{tr}(AB)>0$. (a) The trace of Hermitian matrix is a real number, since $a_{ii} = \bar{a}_{ii}$, that also means that all eigenvalues are real. I can't proceed to conclusion that $\operatorname{tr}(AB)$ is real, since $\operatorname{tr}(AB) \neq \operatorname{tr}A\cdot\operatorname{tr}B$ and product of two Hermitian matrices is also Hermitian only if these matrices commute, which is not the case for arbitrary Hermitian matrices. (b) Am I missing something or the question is indeed so easy? If all entries $a_{ij}>0$ and $b_{ij}>0$, then all $c_{ij}=\sum_{m}a_{im}\cdot b_{mj}>0$ too, finally $\operatorname{tr}(AB)=\sum_{i}c_{ii}>0$.","['matrices', 'trace', 'linear-algebra']"
2884100,Find all value of integers n for which the expression is a perfect square.,"Find all integers $n$ for which the expression $$n^4+6n^3+11n^2+3n+31$$ is a perfect square. My approach : First I simplified the expression and equated it to some square number  $$(n^2+3n+1)^2 - 3(n-10) = k^2$$  Now if we try to remove the term ""$3(n-10)$"" then the equation will be satisfied. And it is done only be equating $n = 10$ . I don't know how to find other solution. Please help me in solving further.","['contest-math', 'number-theory']"
2884136,$f$ convex $\iff$ $f(y) \ge f(x) + \nabla^Tf(x)(y-x)$ and $f$ is convex $\iff$ $\nabla^2f(x)\ge 0$,"I need to prove $2$ things: 1) Let $f\in C^1$. Then $f$ is convex em a convex $S$ $\iff$ for all
   $x,y\in S$ we have $$f(y) \ge f(x) + \nabla^Tf(x)(y-x)$$ 2) Let $f\in C^2$. Let $S\subset\mathbb{R}^n$ be a convex such that
   $S^0$ (actually an S with a $0$ on top of it, what is it?). Then $f$
  is convex $\iff$ $\nabla^2f(x)\ge 0$ for all $x\in S$ (I've seen Prove this basic inequality $f(y)\geq f(x)+\nabla f(x)^T(y-x)$for differentiable convex functions but since these $2$ propositions are connected I think it has more sense to do a proof a little different) For (1) , I noticed that if we take the Taylor Expansion: $$f(x+p) = f(x) + p^T\nabla^Tf(x) + \frac{1}{2}p^t\nabla^2f(x+tp)p$$ for some $t\in (0,1)$ and do $p = y-x$ we end up with $$f(y) = f(x) + (y-x)^T\nabla^Tf(x) + \frac{1}{2}(y-x)^t\nabla^2f(x+t(y-x))(y-x)$$ If we want to prove that $f(y) \ge f(x) + \nabla^Tf(x)(y-x)$, then using the taylor expansion above, it's just a matter of proving $\frac{1}{2}(y-x)^t\nabla^2f(x+t(y-x))\ge 0$. But there are no assumptions about the second derivative of $f$. For (2) , if we use the convex condition of $1$, then using the second order taylor expansion again: $$f(y) = f(x) + (y-x)^T\nabla^Tf(x) + \frac{1}{2}(y-x)^t\nabla^2f(x+t(y-x))(y-x)$$ Now if we suppose $\nabla^2 f(x)\ge 0$, we get that $f$ is convex because we get the inequality of the first exercise. But how do we know for sure that  $\nabla^2f(x)\ge 0$ for all $x\in S$ $\implies \frac{1}{2}(y-x)^t\nabla^2f(x+t(y-x))(y-x)$? For the converse , if $f$ is convex then $$f(y) \ge f(x) + \nabla^Tf(x)(y-x)$$ If $\nabla^2f(x)$ wereto be $<0$, we'd have the second order term $\frac{1}{2}(y-x)^t\nabla^2f(x+t(y-x))(y-x)$ in a taylor expansion to be negative (how to prove this?), then by the taylor expansion we'd have $f(y) < f(x) + \nabla^Tf(x)(y-x)$ which is a contradiction.","['multivariable-calculus', 'calculus', 'convex-analysis', 'optimization']"
2884154,Are simultaneously diagonalizable matrices dense in $(M_{n\times n})^k$?,"Let $M_{n\times n}$ be the space of $n\times n$ matrices (over algebraically closed field). Then I know that the diagonalizable matrices are dense in $M_{n\times n}$ (because $M_{n\times n}$ is irreducible wrt. Zariski topology and the diagonalizable matrices are the open subset defined by the nonvanishing of the discriminant). If $(M_{n\times n})^k$ consists of $k$-tuples of matrices, do the tuples of simultaneously diagonalizable matrices form a dense subset?","['matrices', 'general-topology']"
2884206,"In 2-by-2 partitions of two rectangles, is there always a pair of non-overlapping parts?","There are two rectangles, red and blue.
Each rectangle is partitioned into 4 sub-rectangles using one cut parallel to its longer side and two cuts parallel to its shorter side, like this: Does there always exits a pair of sub-rectangles, one red and one blue, that do not overlap? NOTE: Initially I thought that the answer should be positive even when partitioning to 3 sub-rectangles. However, I found a negative example. In the partitions below, each blue sub-rectangle overlaps all three red sub-rectangles (and vice versa): EDIT: here is a Geogebra worksheet to play with.","['rectangles', 'geometry']"
2884213,What is the sum of the even (resp. odd) terms only of the Hockey-stick identity?,"The Hockey-stick identity is $$\sum^n_{i=r}{i\choose r}={n+1\choose r+1} \qquad \text{ for } n,r\in\mathbb{N}, \quad n>r$$ I am trying to determine the values of the following $$\sum_{\substack{i=r \\ i\,\text{even}}}^n{i\choose r}\;\text{and}\sum_{\substack{i=r \\ i\,\text{odd}}}^n{i\choose r}$$ EDIT WITH PARTIAL ANSWERS: The cases $r=0,1$ are clear, and I have been able to prove (i.e. beyond computer guesswork) that for $r=2,3,4$ and $n=2(k-1)$ the even sums are
$$\sum_{i=2}^{k}{2(i-1)\choose 2}={k\choose 2}+4{k\choose 3}$$
$$\sum_{i=3}^{k}{2(i-1)\choose 3}=4{k\choose 3}+8{k\choose 4}$$
$$\sum_{i=3}^{k}{2(i-1)\choose 4}={k\choose 3}+12{k\choose 4}+16{k\choose 5}$$
respectively. However, I am still at a loss regarding the general case.","['elementary-number-theory', 'binomial-coefficients', 'combinatorics', 'discrete-mathematics']"
2884220,What is the domain of a division of functions?,"This question is about real functions of real variables. I think that, in general, if the domain of some function $f(x)$ is A, and the domain of another function $g(x)$ is B, then the domain of $(f/g)(x)$ is A$\cap$B and where $g\neq0$. Now, what happens if I have something like $f(x)=2$, $g(x)=1/x$? In this case, $(f/g)(x)=2x$, which seems to be defined for all real numbers. But my statement above (which I think is correct in general) implies that $x=0$ is not allowed. So I'm conflicted. Can somebody tell me what the domain of $(f/g)(x)$ is in this case? Is it all real numbers, or all real numbers except $0$? Thanks.","['real-numbers', 'combinations', 'functions']"
2884231,Show that $\int f\ge 3/2$,"I'm trying to prove a question of my homework, but I'm stuck. The question is Question: let $f:[0,1]\rightarrow \mathbb{R}$, such that $|f'(x)| < 1, \forall x$ and $f(0) = 2$, prove that $\int_0^1f(x)dx \geq \frac{3}{2}$ Ok, so my efforts until now were these: I know that if $|f'(x)| < 1$, can be proved that $f(x)-f(y) < |x-y|$, (I don't prove that inequality is strictly), so I can use the condition on hypothesis $\Rightarrow$ $|f(x)-2| \leq |f(x)| -2 < |x|$ $\Rightarrow$ $\int_0^1f(x)dx < \int_0^1x-2dx$, so I only can conclude that $\int_0^1f(x)dx < 5/2$. My other try is to using the mean value theorem so I can write down $f'(c) = \frac{f(1) - f(0)}{1-0} <1$, for some $c \in (a,b)$, then $f(1) < 3$. I'm not sure about my first effort, but I'm confident about the second one. Thank you in advance!","['integration', 'real-analysis']"
2884232,Find the gradient and hessian of $f(Ax+b)$ for real value $f$ and matrix $A$,"Let $A\in\mathbb{R}^{m\times n}$, $b\in \mathbb{R}^m$. For
  $x\in\mathbb{R}^n$, we define $q(x) = f(Ax+b)$ with
  $f:\mathbb{R}^m\to\mathbb{R}$. Find the gradient and hessian of the
  function $q$. This question is kinda strange. If I were to take the jacobian, I would just compose the jacobian of the outer funciton with the jacobian of the inner function. Now, how do I take the partial derivative of $q$? $$\frac{\partial f(Ax+b)}{\partial x_1} = \lim_{h\to 0}\frac{f(A(x_1+h,x_2,\cdots,x_n) + b) - f(Ax+b)}{h}$$ I don't think it helps in thinking this way. I have no means of finding this limit without using some chain rule or so. Maybe I can apply the chain rule to $q$, but how? UPDATE: By the hint given below, $$q(x_1,\dots, x_n)=f(f_1,\cdots,f_n) = f\left(\sum_{i=1}^n a_{1i}x_i+b_1,\dots,\sum_{i=1}^n a_{mi}x_i+b_m\right)$$ I think the multivariable chain rule can be applied: $$\frac{\partial f}{\partial x_1} = \frac{\partial f}{\partial f_1}\frac{\partial f_1}{\partial x_1} + \cdots + \frac{\partial f}{\partial f_n}\frac{\partial f_n}{\partial x_1}$$ And see that $$\frac{\partial f_1}{\partial x_1} = a_{11}\\\cdots\\\frac{\partial f_n}{\partial x_1} = a_{m1}$$ So we get $$\frac{\partial f}{\partial x_1} = \frac{\partial f}{\partial f_1}a_{11} + \cdots + \frac{\partial f}{\partial f_n}a_{m1}$$ In general: $$\frac{\partial f}{\partial x_j} = \frac{\partial f}{\partial f_1}a_{1j} + \cdots + \frac{\partial f}{\partial f_n}a_{mj}$$ I think there's still a lot of work to do.","['multivariable-calculus', 'calculus', 'derivatives', 'real-analysis']"
2884248,Under what conditions can one glue together local diffeomorphisms?,"I know that, given an open cover $\{U_\alpha\}$ of a manifold $M$ and a family of smooth maps $\,f_\alpha: U_\alpha \to N$ that agree on overlaps, it is possible to construct a smooth $f:M \to N$ that restricts to $f_\alpha$ on each $U_\alpha$. My question is, are there conditions under which you can do the same thing with a family of local diffeomorphisms? I have a family of such maps defined on open subsets of some $M$ that agree on overlaps, and I would like to glue them together on some larger open set and have the extended map remain a local diffeomorphism.  Is such a thing possible? Thanks, EDIT: To be more clear, I suppose I mean conditions on which the extended map is a diffeomorphism on the entire larger open set.  It is obviously still a local diffeomorphism after extension.","['differential-topology', 'smooth-manifolds', 'differential-geometry']"
2884256,Is $\limsup |C_n|^{\frac{1}{n}} = \limsup |C_{n+j}|^{\frac{1}{n}}? $ where $j\geq0 $,$C_n$ is a sequence of complex numbers. I would like to prove that the radius of convergence of a differentiated power series is the same as the original series. i.e. $\limsup |(n+j)(\cdots)(n+1)C_{n+j}|^{\frac{1}{n}} = \limsup |C_n|^{\frac{1}{n}}$ I know that $\limsup |(n+j)(\cdots)(n+1)C_{n+j}|^{\frac{1}{n}} = \limsup|C_{n+j}|^{\frac{1}{n}}$ since $\lim((n+j)(\cdots)(n+1))^{\frac{1}{n}}=1$ But I am stuck at the above question. Any help?,"['power-series', 'limsup-and-liminf', 'derivatives', 'sequences-and-series']"
2884278,Let $f\colon\Bbb{R}^2\to \Bbb{R}$ such that $|f(x)-f(y)|\leq \Vert x-y\Vert^2.$ Prove that $f$ is a constant,"Edit: Several questions of this type have been asked here before but not on the same domain $\Bbb{R}^2.$ Please, how do I deal with a function of this type or could anyone show me a reference or a similar question with the same domain? Let $f\colon\Bbb{R}^2\to \Bbb{R}$ such that $|f(x)-f(y)|\leq \Vert x-y\Vert^2.$  Prove that $f$ is a constant. What if we assume that $f$ is differentiable. Is there another way of showing that $f$ is a constant?","['real-analysis', 'multivariable-calculus', 'calculus', 'holder-spaces', 'holder-inequality']"
2884291,Dummit and Foote problem 11 in section 7.4,"I am trying to solve problem 11 in Dummit and Foote section 7.4. The problem is the following: Assume $R$ is commutative. Let $I$ and $J$ be ideals of $R$ and assume $P$ is a prime ideal of $R$ that contains $IJ$. Prove either $I$ or $J$ is contained in $P$. I came up with the following proof and I just want to check if it is right. It's as follows: We know $IJ \subset P$. Then if we consider $i \in I$ and $j \in J$. Then, we know $ij \in IJ \subset P$. By primality of $P$ and since $ij \in P$, we know that either $i \in P$ or $j \in P$. Thus, we must have that $I \subset P$ or $J \subset P$, as desired. I would appreciate any suggestion or comments on this proof. Thanks!","['proof-verification', 'maximal-and-prime-ideals', 'ring-theory', 'abstract-algebra', 'ideals']"
2884318,"Solve the following problem, $u'(t)+p(t)u(t)=0,\;\;u(0)=0,$ $p(t)=\begin{cases}2& 0\leq t< 1,\\1 &t\geq 1\end{cases}.$","Using Laplace transform, solve the following problem. $$u'(t)+p(t)u(t)=0,\;\;u(0)=0,$$
$$p(t)=\begin{cases}2& 0\leq t< 1,\\1 &t\geq 1\end{cases}.$$ Here's what I've done: Taking the Laplace transform of both sides
$$L(u'(t))+L(p(t)u(t))=0,$$
$$sU(s)-u(0)+L(p(t)u(t))=0,$$
$$sU(s)+L(p(t)u(t))=0.$$ I'm stuck at this point. Please, how do I proceed?","['ordinary-differential-equations', 'laplace-transform', 'calculus', 'algebra-precalculus', 'derivatives']"
2884382,A finite group such that every element is conjugate to its square is trivial,"Suppose $G$ is a finite group such that $g$ is conjugate to $g^2$ for every $g\in G$. Here's a proof that $G$ is trivial.  First, observe that if $\lvert G\rvert$ is even, then $G$ contains an element $h$ of order $2$, in which case, $h$ is conjugate to $h^2=1$.  But this implies that $h=1$, so $h$ does not have order $2$.  By contradiction, $\lvert G\rvert$ is odd.  Then, by the Feit–Thompson theorem, $G$ is solvable.  In particular, this means that the derived series of $G$ terminates.  However, for any $g$ in $G$, there exists $a\in G$ such that $g^2=aga^{-1}$, i.e., $g=aga^{-1}g^{-1}\in G^{(1)}$.  It follows that $G^{(1)}=G$.  In fact, this shows that $G^{(n)}=G$ for all $n\geq 1$.  Since the derived series of $G$ terminates, this implies that $G$ must be trivial. While I'm convinced of the result, this proof is not particularly satisfying to me, since it relies on Feit-Thompson.  Is there an elementary proof that $G$ is trivial?","['group-theory', 'abstract-algebra', 'finite-groups']"
2884449,Sum of fifth roots of roots of cubic.,"$a,b,c$ are the (real) roots of $x^3-16x^2-57x+1=0$. Prove that
$\sqrt[5]{a} + \sqrt[5]{b} +\sqrt[5]{c} = 1 $ ................................................................................ edit : my answer to this question on another forum Let $p=\sqrt[5]{a},q=\sqrt[5]{b}, r=\sqrt[5]{c}, u=p+q+r, v=qr+rp+pq, w=pqr$ From given cubic p⁵+q⁵+r⁵=16, q⁵r⁵+r⁵p⁵+p⁵q⁵=-57, p⁵q⁵r⁵=-1 (so w=-1) Thus results at end gives the following simultaneous equations for u,v p⁵+q⁵+r⁵ = 16 = u⁵-5u³v+5uv²-5u²+5v 
q⁵r⁵+r⁵p⁵+p⁵q⁵ = -57 = v⁵+5uv³+5u²v+5v²+5u I solved these via Mathematica to give u=1, v=-2 (only real solution) so your answer is 1 ==================== p,q,r are roots of z³-uz²+vz-w=0 Multiply by zⁿ and let s(n)=pⁿ+qⁿ+rⁿ Set z=p,q,r in turn and sum for the recurrence s(n+3) = us(n+2)-vs(n+1)+ws(n) Noting that s(0)=3, s(1)=u, s(2)=u²−2v generate s(3), s(4), s(5) as follows … n=0 : s(3) = us(2)-vs(1)+ws(0) = u³-3uv+3w n=1 : s(4) = us(3)-vs(2)+ws(1) = u⁴-4u²v+2v²+4uw n=2 : s(5) = us(4)-vs(3)+ws(2) = u⁵-5u³v+5uv²+5u²w-5vw p⁵+q⁵+r⁵ = u⁵-5u³v+5uv²+5u²w-5vw Replace p by qr, q by rp, r by pq and get q⁵r⁵+r⁵p⁵+p⁵q⁵ = v⁵-5uv³w+5u²vw²+5v²w²-5uw³ ====================",['algebra-precalculus']
2884454,If $A$ is absolutely flat then every primary ideal is maximal,"Given the ring $A$ is commutative with an identity element. If $A$ is absolutely flat (i.e. each $A$-module is flat) then every primary ideal is maximal. This exercise 4.3 comes from the classical text of Atiyah-Macdonald : introduction to the commutative algebra. Attempt: Suppose $\mathfrak{q}$ is a primary ideal in $A$ and fix an $x\in A-\mathfrak{q}.$ Then $\bar{x}\in A/\mathfrak{q}$ is non-zero since $x\not\in\mathfrak{q}$ Recall that $A$ is absolutely flat $\Longleftrightarrow$ every principal ideal is idempotent. Then as $x\in\langle x\rangle=\langle x^{2}\rangle$, we have $x=ax^{2}$ for some $a\in A$ and hence $x(ax-1)=0\in\mathfrak{q}$ and we thus have $(ax-1)^{n}\in\mathfrak{q}$ for some integer $n>0$ since $x\not\in\mathfrak{q}.$ Therefore, we get that $(ax-1)^{n}=\bar{0}$ in $A/\mathfrak{q}$. It follows that $\bar{a}\bar{x}-\bar{1}\in A/\mathfrak{q}$ is nilpotent and thus $\bar{a}\bar{x}=(\bar{a}\bar{x}-\bar{1})+\bar{1}\in A/\mathfrak{q}$ is unit which implies $\bar{x}\in A/\mathfrak{q}$ is unit. Therefore, $A/\mathfrak{q}$ is a field. It follows that $\mathfrak{q}$ must be a maximal ideal in $A$. I am not very sure if my proof is valid. Any suggestion or comment I will be grateful.","['abstract-algebra', 'proof-verification', 'commutative-algebra']"
