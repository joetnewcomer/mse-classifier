question_id,title,body,tags
3224917,Integral with messy integrand,"Let $N\in\mathbb{N}$ , $\theta_{i}>0$ , and $a_{ij}\in\mathbb{R}$ , $\forall i = 1,\ldots, N$ . Is there a somewhat explicit expression for \begin{align}
\int_{0}^{\infty} t \left[\prod_{i=1}^{N} \frac{1}{\sqrt{1+2\theta_{i}t}}\right] 
    \left[\sum_{i,j=1}^{N}\frac{a_{ij}}{(1+2\theta_{i}t)(1+2\theta_{j}t)}\right]dt?
\end{align}","['integration', 'calculus', 'definite-integrals', 'analysis']"
3224941,Understanding Finite element method,"Suppose we have Poisson in 1D: $u'' = f(t)$ where $0<t<1$ and $u(0)=0$ and $u(1)=1$ We approximate the solution by $U(t) \approx \sum_{i=1}^n x_i \phi_i(t) $ where $\phi_i(t)$ are some basis functions. Once we put this into our equation we get some residual $r(x_i,t) = U''(t) - f(t) $ . The idea is to multiply by some ${\bf weight }$ function and solve $$ \int\limits_0^1 r(x_i,t) w(t) d t $$ In the Galerkin method, we take $w(t) = \phi_i(t)$ and use integration by parts to derive a system of equations where we find $x_1,...,x_n$ . The question is Suppose the hat function is used as the shape function (piecewise linear shape function) and the domain is decomposed into subintervals of lenght $h=0.2$ Compute the element stiffness matrix ${\bf K}$ If I understood correctly, we use $$ \phi_i(x) = \begin{cases} \frac{ x - x_{i-1} }{h} & x_{i-1} \leq x \leq x_i \\ \frac{x_{i+1}-x}{h} & x_i \leq x \leq x_{i+1} \end{cases} $$ as our basis functions. We are given that $$ K_{ij} = \sum_{e} K_{ij}^e $$ where $K_{ij}^e$ is the element stiffness matrix for element $\Omega_e$ . In our case, we have $5$ elements as $h=0.2$ . For example, for the first element: $[x_0,x_1]$ we have $$ K_{ij}^1 = \int\limits_{x_0}^{x_1} ( \phi_i' \phi_j' + \phi_i \phi_j) dx $$ Is this how finite element method works?","['boundary-value-problem', 'numerical-methods', 'finite-element-method', 'ordinary-differential-equations']"
3224980,How to take the derivative of minimum of a norm?,"Suppose $f: \mathbb{R}^n \rightarrow \mathbb{R}$ where $f$ is the following: $$
f(z) = 
\begin{cases}
0 \,\,\,\, z \in C \\
\min_{x\in C} \frac{1}{2} \|x-z\|_2^2 \,\,\,\ z\notin C
\end{cases}
$$ where $C$ is a closed convex $C$ in $\mathbb{R}^n$ and $x$ is a point in $C$ . How can we find derivative of $f$ . I know the answer is $$
f'(z) = 
\begin{cases}
0 \,\,\,\, z \in C \\
z-x \,\,\,\ z\notin C
\end{cases}
$$ but how would we find this derivative using the definition? Is there any way to get that using: $$
f'(z;d) = \lim_{d \rightarrow 0^{+}} \frac{\min_{x\in C} \frac{1}{2} \|x-(z+td)\|_2^2 - \min_{x\in C} \frac{1}{2} \|x-z\|_2^2}{t}
$$","['convex-analysis', 'derivatives']"
3224998,"Existence of the $\Omega$ set in ""Guaranteed Minimum-Rank Solutions of Linear Matrix Equations via Nuclear Norm Minimization""","In the proof of Lemma 4.3 in [1], they claim the following: Let $U$ be a subspace of $\mathbb{R}^{m\times n}$ with dim $(U)=d$ and let $\delta>0$ . Then, there exists a set $\Omega\subset\mathbb{R}^{m\times n}$ wiht at most $(12/\delta)^d$ elements such that for every $X\in U$ with $\lVert X\rVert_F\leq 1$ there exists a $Q\in\Omega$ such that $\lVert X-Q\rVert_F \leq \delta/4$ . I don't see the reason why this is true. References [1] Recht, B., Fazel, M., & Parrilo, P. A. (2010). Guaranteed minimum-rank solutions of linear matrix equations via nuclear norm minimization. SIAM review, 52(3), 471-501.","['matrices', 'linear-algebra', 'real-analysis']"
3225060,Existence of convex defining functions for convex domains,"I have a question regarding the construction of a barrier frequently used in PDE. The barrier used is the following: Let $\Omega$ be a uniformly convex domain in $\mathbb{R}^n$ with $C^2$ boundary. Here uniformly convex means there exists some $r>0$ such that every point in $\partial \Omega$ satisfies an interior sphere condition for a sphere with radius $r$ . Then there exists a uniformly convex defining function $h \in C^2(\Omega)$ , that is a function satisfying $$ h < 0 \text{ in } \Omega, \quad h = 0 \text{ on }\partial\Omega$$ and $$ |Dh| = 1 \text{ on }\partial\Omega, \quad D^2h \geq \delta I \text{ in } \Omega,$$ for some $\delta >0$ . My question is the following: Whilst I understand how such a function can be constructed in some neighborhood of the boundary by taking for example $h(x) = -\text{dist}(x,\partial \Omega)+\text{dist}(x,\partial \Omega)^2$ (as outlined in Gilbarg and Trudinger $\S$ 14.6 or the footnote on page 40 of Figalli's Monge–Ampère book), how does one extend this function to the entire domain? That is how does one explicitly construct $h$ ?","['elliptic-operators', 'real-analysis', 'partial-differential-equations', 'convex-analysis', 'differential-geometry']"
3225107,"Complex-analytic argument that $\mathrm{SL}(2,\mathbb R)$ acts isometrically on $\mathbb H^2 \subseteq \mathbb C$","Let $\mathbb H^2 := \left\{ z = x+iy \in \mathbb C : y > 0\right\}$ , equipped with the hyperbolic Riemannian metric $\breve{g} = \frac 1{y^2}\left(dx^2 + dy^2\right)$ . It is a classical result that the group $\mathrm{SL}(2,\mathbb R)$ acts on $\mathbb H^2$ isometrically via $$
\left(\begin{array}{cc}
a & b \\ c & d
\end{array}\right) \cdot z = \frac{az+b}{cz+d}
$$ Denote $\theta_A(z) = A\cdot z$ for $A \in \mathrm{SL}(2,\mathbb R)$ . Then it is straightforward to calculate $$
\frac{d}{dz}\theta_A(z) = \frac 1{(cz+d)^2}. 
$$ Problem: Find a complex-analytic proof using $\frac{d}{dz}\theta_A(z)$ to show $\theta_A : \mathbb H^2 \to \mathbb H^2$ is an isometry. I have the following argument in real Cartesian coordinates: $\theta_A$ becomes $\theta_A(x,y) = \big( u(x,y),\: v(x,y)\big)$ , where $$
u(x,y) = \frac{(ax+b)(cx+d)+acy^2}{(cx+d)^2+c^2y^2},\qquad v(x,y) = \frac y{(cx+d)^2+c^2y^2}
$$ Since $\theta_A : \mathbb H^2 \to \mathbb H^2$ is a holomorphic function, $u$ and $v$ satisfy the Cauchy-Riemann equations, so the differential of the map $\theta_A : \mathbb H^2 \to \mathbb H^2$ (considering $\mathbb H^2 \subset \mathbb R^2$ ) satisfies: \begin{align*}
d(\theta_A)_z &= \left(\begin{array}{cc}
u_x & u_y \\ v_x & v_y
\end{array}\right) = \left(\begin{array}{cc}
v_y & -v_x \\ v_x & v_y
\end{array}\right) \\
&= \frac 1{\left((cx+d)^2+c^2y^2\right)^2}\left(\begin{array}{cc}
(cx+d)^2-c^2y^2 & 2cy(cx+d) \\ -2cy(cx+d) & (cx+d)^2 - c^2 y^2
\end{array}\right) 
\end{align*} Therefore if we let $\left\{ \partial_x, \partial_y\right\}$ denote the standard coordinate frame induced by the identity coordinates $\mathbb H^2 \hookrightarrow \mathbb R^2$ , it's a starightforward calculation to show $$
\theta_A^*\breve g(\partial_x, \partial y) = 0, \qquad \theta_A^* \breve g(\partial_x, \partial_x) = \theta_A^* \breve g(\partial_y, \partial_y) = \frac 1{y^2},
$$ whence it follows that $\theta_A^* \breve{g} = \breve{g}$ , so $\theta_A$ is a Riemannian isometry. However: I'm trying to develop comfort and familiarity with complex one-forms and Riemannian geometry of complex surfaces, so I would like to know what the details would be in order to use $\theta_A'(z) = (cz+d)^{-2}$ to show $\theta_A$ is an isometry, without falling back to Cartesian coordinates. I'd also like to avoid using geodesics if possible, in favor of using complex differential forms and complex coordinate frames (i.e. $\left\{ dz, d\overline z\right\}$ and $\left\{\partial/\partial z, \partial/\partial\overline z\right\}$ respectively). Any insights on what this flavor of argument would look like? EDIT: See comments for a solution.","['riemannian-geometry', 'complex-analysis', 'hyperbolic-geometry', 'lie-groups', 'differential-geometry']"
3225111,A limit of an integral of a quotient related to fractional Sobolev space,"Let $0<\alpha<1$ and $1\leq p<\infty$ . Suppose $f\in L^p(\mathbb{R}^n)$ satisfies \begin{align}
\int_{\mathbb{R}^n}\int_{\mathbb{R}^n}\frac{|f(x)-f(y)|^p}{|x-y|^{n+\alpha p}}dxdy<\infty
\end{align} Is it true that \begin{align}
\int_{B(0,r)}\frac{|f(x+h)-f(x)|^p}{|h|^{n+\alpha p}}dh\to 0\qquad\text{as}\qquad r\to 0
\end{align} for a.e. $x\in\mathbb{R}^n$ ? Since this is an integration over the ball $B(0,r)$ (of radius $r$ ), at first I tried to look at Lebesgue-Besicovitch differentiation theorem, but the theorem actually involves the average (i.e. we need to take care of $|B(0,r)|^{-1}$ too). Now I have no idea where to start. Any hint, comment and answer are greatly appreciated.","['measure-theory', 'lebesgue-measure', 'lebesgue-integral', 'real-analysis']"
3225118,Proving a convex space is connected,"A set $C \subset R^n$ is convex if given any $x_1, x_2 \in C$ , the line segment connecting $x_1$ and $x_2$ is contained in C. Show that any convex set $C \subset R^n$ must be connected. I want to prove this by assuming that C is disconnected and finding a contradiction. I know that since C is disconnected this means it has a pair of nonempty open sets A and B which partition it. So then if I choose $x_1 \in A$ and $x_2 \in B$ , the line segment connecting these two points is contained in C. My idea is to show that if the line segment is contained in C then this contradicts A and B both being open. Will this work? I can't find the right way to finish this proof.",['general-topology']
3225139,$(p \implies q) \wedge (p \implies r) = p \implies (q \wedge r)$ PROOF,"$\def\implies{\to}$ I am trying to prove the following: $$(p \implies q)\wedge (p\implies r) \equiv (p\implies q \wedge r) $$ I did this, although I am second-guessing because of the parenthesis placement and the order of operations: $$ \begin{align}(p \implies q) \wedge (p \implies r) &\equiv (\neg p \vee q)\wedge (\neg p \vee r) \\[1ex] &\equiv \neg p \vee (q \wedge r) \\[1ex] &\equiv p \implies (q\wedge r)\end{align}$$ Any help/insight on this is appreciated!","['logic', 'discrete-mathematics']"
3225164,Points outside a circle mapped inside a circle by $1/z$,"Prove or disprove the following conjecture: Let $C$ be a circle in the complex plane that passes by the points $z_1=-1$ and $z_2=a$ , with $a$ real and greater that one (there are obviously infinitely many circles with that property). Then every point outside $C$ gets mapped by $1/z$ to a point inside $C$ . Note that the converse is not true. There are points inside $C$ that get mapped by $1/z$ to points also inside $C$ . For example, all points in the real axis between $1$ and $a$ are inside $C$ and are mapped to points in the real axis between $0$ and $1$ , which are also inside $C$ , as the whole $(-1,a)$ interval in the real axis is inside the circle $C$ . For the record, I believe the conjecture to be true.",['complex-analysis']
3225192,Solve and find the flaw in this integral equation,"The following integral equation often appears in the books and it has once been
asked in the prestigious examination called IIT JEE (M) dated 10-04-2016. The question is: $\forall x \in R-\{0\}$ , if $y(x)$ is  differentiable function such that $$ x\int_{1}^{x}~ y(t)~dt =(x+1) \int_{1}^{x} t ~y(t)~dt.$$ Find $y(x)$ . Some four interesting expression of $y(x)$ were given as alternatives in this MCQ type question. Solving this you may find a serious flaw in this question. I would like to thank Ninad Sutrave for expressing a doubt about this question.","['integration', 'integral-equations', 'ordinary-differential-equations']"
3225247,"$N\rtimes_{\phi}H\cong N\rtimes_{\phi\circ\psi}H$ for $N,H$ be groups, $\phi \colon H\rightarrow Aut(N)$ be a homomorphism, $\psi \in Aut(H)$","Let $N,H$ be groups, $\phi \colon H\rightarrow Aut(N)$ be a homomorphism, if $\psi \in Aut(H)$ , prove that $$N\rtimes_{\phi}H\cong N\rtimes_{\phi\circ\psi}H.$$ This is mentioned in the original post . I am seeking proof of the statement. Edit : I have changed the order of $\phi$ and $\psi$ and the composition acts from right to left. Sorry about the vagueness. Define $\varphi: N\rtimes_\phi H\to N\rtimes_{\phi\circ\psi}H$ by $$ (n,h)\mapsto (n,\psi^{-1}(h)) .$$ So it suffices to show that $\varphi$ is a group homomorphism. \begin{align}
\varphi((n_1,h_1)\cdot_\phi(n_2,h_2))&=\varphi((n_1\phi(h_1)(n_2),h_1h_2))\\
&=(n_1\phi(h_1)(n_2),\psi^{-1}(h_1)\psi^{-1}(h_2))
\end{align} On the other hand, \begin{align}
\varphi((n_1,h_1))\cdot_{\phi\circ\psi}\varphi((n_2,h_2))&=(n_1,\psi^{-1}(h_1))\cdot_{\phi\circ\psi}(n_2,\psi^{-1}(h_2))\\
&=(n_1\phi\circ\psi\circ\psi^{-1}(h_1)(n_2),\psi^{-1}(h_1)\psi^{-1}(h_2))
\end{align}","['semidirect-product', 'group-theory', 'abstract-algebra']"
3225250,Solve this equation $\cos{\left(\frac{\pi}{3}-\frac{\pi}{3r}\right)}=\sqrt{\frac{11}{r^2}-2}$,"Let $r>0$ , solve this equation $$\cos{\left(\dfrac{\pi}{3}-\dfrac{\pi}{3r}\right)}=\sqrt{\dfrac{11}{r^2}-2}$$ I have found that $r=2$ is a solution, as $$LHS=\cos{\dfrac{\pi}{6}}=\dfrac{\sqrt{3}}{2}$$ and $$RHS=\sqrt{\dfrac{11}{4}-2}=\dfrac{\sqrt{3}}{2},$$ so $r=2$ is a root. How can other solutions be found?","['trigonometry', 'radicals']"
3225258,$\forall x (P(x) \wedge \neg Q(x)) \equiv \forall x P(x) \wedge \neg \exists x Q(x)$,"I'm supposed to determine whether or not these equivalences are valid for all predicates P and Q. I've written my assumptions but I've never done anything like this so it almost seems too simple and I feel as though my logic is incorrect: a) $$ \forall x (P(x) \wedge \neg Q(x)) \equiv \forall xP(x) \wedge \neg \exists xQ(x)$$ This is how I interpreted it: 
For all x, P(x) is true and Q(x) is false. 
    For all x, P(x) is true and there does not exist an x such that Q(x) is true (thus meaning 
    Q(x) must always be false). These equivalences appear to be valid. b) $$\forall x (\neg P(x) \vee Q(x)) \equiv (\neg \exists xP(x)) \vee (\forall x Q(x))$$ This is how I interpreted this one:
For all x, P(x) is false or Q(x) is true.
    There does not exist an x such that P(x) is true (thus P(x) must always be false) or for all 
    x, Q(x) is true. These equivalences appear to be valid. Any help is appreciated :)","['predicate-logic', 'first-order-logic', 'quantifiers', 'logic', 'discrete-mathematics']"
3225313,Non-homeomorphic subsets of the Cantor set,"Are there uncountably many subsets of the Cantor set such that they are not homeomorphic to each other? Motivation: Let $X$ be the space of infinite binary tree. Then $Ends(X):=\varprojlim_{K,\text{compact}}\pi_0(X-K)$ has to topology of Cantor set. Let $\Sigma_X$ be a surface which handles are glued to a $2$ -sphere along the tree $X$ . Then $Ends(X)=Ends(\Sigma_X)$ has the topology of Cantor set. If there are uncountably many subsets of the Cantor set such that they are not homeomorphic to each other, then I can construct an uncountably infinite family of surfaces $\{\Sigma_{X'}\}_{X'\subseteq X}$ such that they are pairwise non-homeomorphic, and each is obtained by gluing countably many handles.","['general-topology', 'measure-theory', 'analysis']"
3225324,Example of non-cocompact lattice in a specific topological group,"An exercise in Dave Witte Morris' Introduction to Arithmetic Groups asks the reader to suppose the following. $\Gamma$ is a non-cocompact lattice in a topological group $H$ $H$ has a compact, open subgroup $K$ The exercise asks the reader to show that $\Gamma$ has a non-trivial element of finite order. While the exercise itself is easy, I'm having difficulty coming with an example of such a group $H$ , and a lattice $\Gamma$ . Since $K$ has to be an open compact subgroup, that means the identity component of $H$ must be compact, and therefore $H$ is the semidirect product of a compact connected group $H^{\circ}$ , and a discrete group $D = H/H^{\circ}$ . Given such a group $H^{\circ} \ltimes D$ , one now needs to find a non-cocompact lattice $\Gamma$ , and
this is where I'm stuck. I can't think of any examples of such lattices. If anyone has any examples, I'd be interested in knowing what they are. Thanks.","['lattices-in-lie-groups', 'topological-groups', 'group-theory', 'lie-groups', 'differential-geometry']"
3225358,$\quad A\subset\mathbb{R}$ is measurable and $m(A)>0$. then $m\left(\mathbb{R}-\bigcup_{q\in\mathbb{Q}}q\cdot A\right)=0$. [duplicate],"This question already has answers here : Minkowski sum of a positive Lebesgue measure set and $\mathbb{Q}$. (2 answers) Closed 5 years ago . $\quad A\subset\mathbb{R}$ is measurable and $m(A)>0$ . then $m\left(\mathbb{R}-\bigcup_{q\in\mathbb{Q}}q\cdot A\right)=0$ . How to prove it ? $ q \cdot A $ is a dilation or contraction of each element in $ A$ for example if $ A=(1 ,3],  2A= 2(1 ,3] = (2,6].$ The proof  is trivial if $ A $ is an interval or countable union of intervals but not so for arbitrary sets. This question is not a duplicate of link because taking logarithm $ log_{10} (qA) =log_{10}A+log_{10}q$ , $ log_{10} q $ is not always a rational number","['measure-theory', 'real-analysis']"
3225413,Probability of X being a trick coin (heads every time) after heads is flipped k amount of times,"A magician has 24 fair coins, and 1 trick coin that flips heads every time. Someone robs the magician of one of his coins, and flips it $k$ times
  to check if it's the trick coin. A) What is the probability that the coin the robber has is the trick
  coin, given that it flips heads all $k$ times? B) What is the smallest number of times they need to flip the coin to
  believe there is at least a 90% chance they have the trick coin, given
  that it flips heads on each of the flips? Here is my approach: Let $T$ be the event that the robber has the trick coin Let $H$ be the event where the robber flips a heads k times in a row $Pr(T) = 1/25$ $Pr(H|T) = 1$ $Pr(T') = 24/25$ $Pr(H|T') = 1/2$ when $k=1$ , $1/4$ when $k=2$ , $1/8$ when $k=3$ ... etc $Pr(T|H) = (1 * 1/2) / (1 * 1/2 + Pr(H|T') * 24/25) = 1/13, 1/7, 1/4,...$ etc So the Pr(T|H) answer changes for every k, do I answer with the formula? How can I answer A? How do I make a probability distribution when k can be infinite? Also is B 8 flips? Since when k = 8, Pr(T|H) = 1/256. Thanks for any help.","['conditional-probability', 'discrete-mathematics', 'probability']"
3225436,Bipartite graphs from permutations,"Given are $n\geq 1$ permutations of $abcd$ . We construct a bipartite graph $G_{a,b}$ as follows: The $n$ vertices on one side are labeled with the sets containing $a$ and the letters after it in each permutation, and the $n$ vertices on the other side are labeled with $b$ and the letters before it in each permutation. There is an edge between two vertices if their sets overlap. Construct $G_{b,c},G_{c,d},G_{d,a}$ similarly. It could be that $G_{a,b},G_{b,c},G_{c,d}$ all have no perfect matchings (for example, if all permutations are $dcba$ , then all three graphs have no edges).  But is it true that among $G_{a,b},G_{b,c},G_{c,d},G_{d,a}$ , at least one must have a perfect matching? Example : if the permutation set is $\{abcd,abcd,dbca\}$ , then $G_{a,b}$ has vertices $v_1 =\{a,b,c,d\},v_2 =\{a,b,c,d\},v_3 =\{a\}$ and $w_1 =\{b,a\},w_2 =\{b,a\},w_3 =\{d,b\}$ with edges $(v_1 ,w_1),(v_1 ,w_2),(v_1 ,w_3),(v_2 ,w_1),(v_2 ,w_2),(v_2 ,w_3),(v_3 ,w_1 ),(v_3 ,w_2)$ .","['permutations', 'graph-theory', 'matching-theory', 'combinatorics', 'bipartite-graphs']"
3225464,Continuity and differentiability of $f(x) = \frac{x}{1+x} + \frac{x}{(x+1)(2x+1)} + \frac{x}{(2x+1)(3x+1)}+...$,"Here's the given function: $$f(x) = \dfrac{x}{1+x} + \dfrac{x}{(x+1)(2x+1)} + \dfrac{x}{(2x+1)(3x+1)}+...$$ My question regarding this function: is this function considered a continuous and a differenciable function? Is it not continuous or differenciable at any specific points? According to a question about this function, $f(x)$ is non-continuous. They haven't mentioned anything about it being differenciable or not. My working: Simplyfing the series on the right hand side of the equation is quite straightforward- $$f(x) = \dfrac{x}{1+x} + \dfrac{x}{(x+1)(2x+1)} + \dfrac{x}{(2x+1)(3x+1)}+...$$ $$\implies f(x) = \dfrac{1+x-1}{1+x} + \dfrac{(2x+1)-(x+1)}{(x+1)(2x+1)} + \dfrac{(3x+1)-(2x+1)}{(2x+1)(3x+1)}+...$$ $$\implies f(x) = 1 -\dfrac{1}{1+x}+\dfrac{1}{1+x} -\dfrac{1}{2x+1} +\dfrac{1}{2x+1}-\dfrac{1}{3x+1}...$$ $$\implies f(x) =1 $$ Since $f(x)$ is a constant function, it appears to be both continuous and differenciable $\forall x \in \mathbb R$ . This is clearly incorrect, what am I doing wrong? EDIT: Is there a way to graph a function like $f(x)$ ?","['limits', 'calculus', 'continuity', 'sequences-and-series']"
3225472,"Find$f(6)$ where $f(4)=\frac{f(8)}{2}=\frac{1}{4}$, $\int_4^8 \frac{[f'(x)]^2}{[f(x)]^4}dx=1$","Suppose $f(x)$ is differentiable function on $\mathbb{R}$ and $\forall x \in \mathbb{R}, f(x)\neq 0$ We only know $f(4)=\frac{1}{4}, f(8)=\frac{1}{2}, \int_4^8 \frac{(f'(x))^2}{(f(x))^4}dx=1$ and find $f(6).$ How should I approach? Substitution doesn't work.","['integration', 'calculus', 'definite-integrals']"
3225553,Show $4x^2+6x+3$ is a unit in $\mathbb{Z}_8[x]$ (inverting unit + nilpotent),"Show that $4x^2+6x+3$ is a unit in $\mathbb{Z}_8[x]$ . Once you have found the inverse like here , the verification is trivial. But how do you come up with such an inverse. Do I just try with general polynomials of all degrees and see what restrictions RHS = $1$ imposes on the coefficients until I get lucky? Also is there a general method to show an element in a ring is a unit?","['ring-theory', 'abstract-algebra', 'inverse', 'polynomials']"
3225619,Does this iterated sequence always end in a finite number of steps to a number which is divisible by a perfect number?,"I posted this question at MathOverflow, but then I realized that maybe it is more appropriate to ask it here: Let $f$ be a multiplicative arithmetic function which maps $\mathbb{N}$ to itself, such as $\sigma=$ sum of divisors, $\phi = $ Euler phi-function or $\tau = $ number of divisors.
Define $\Sigma_f(n) = n \cdot \frac{n_0(f(n))}{\gcd(n_0(n),n_0(f(n)))}$ where $n_0(x)$ is the radical of $x$ = product of primes dividing $x$ .
We start with some number $n_1$ and iterate the sigma process: $n_{i+1} = \Sigma_f(n_i)$ . In this context, it might be helpful to ""visualize"" what happens:
Define for $f,n$ the graph $G=(V,E)$ , where $V= \Pi(n) \cup \Pi(f(n))$ where $\Pi(x) = \{ p | p \text{ prime }, p | x \} = $ set of primes which divide $x$ . Then a directed edge from $p$ to $q$ is written, if and only if, $p|n$ and $q | f(p^{v_p(n)})$ . We might call an arithemtic function ""noetherian"" if for all $n$ the sigma process stopps after finitely many steps.
Questions: a) Are $\sigma, \tau, \phi$ noetherian functions? b) Is $\sigma_2$ not noetherian (Consider $n_1=2$ )? c) If $\Sigma_f(n) = n$ , is then $G$ connected? d) If $\Sigma_{\sigma}(n) = n$ , is then $n$ divisible by a perfect number? In the attachment, you can find some Sage code, which implements this idea. Thanks for your help. If a) and d) are true, then one would have a method for constructing perfect numbers, namely start with any number $n$ , and iterate the function $\Sigma_{\sigma}$ on $n$ and by a) this will stopp after finitely many steps, constructing a number $N$ with $\Sigma_{\sigma}(N) = N$ . By d) this number will be divisible by a perfect number. (I am not saying that those perfect numbers will be distinct or that there are infinitely many of them. Just start with some natural number, and then eventually one will get some perfect number.) Some examples: 1 [1]
2 [2, 6]
3 [3, 6]
4 [4, 28]
5 [5, 30]
6 [6]
7 [7, 14, 42]
8 [8, 120]
9 [9, 117, 1638]
10 [10, 30]
11 [11, 66]
12 [12, 84]
13 [13, 182, 546]
14 [14, 42]
15 [15, 30]
16 [16, 496]
17 [17, 102]
18 [18, 234, 1638]
19 [19, 190, 570]
20 [20, 420] The following graph is the graph for $n=9660$ and $f=\sigma$ . The number $n$ has the following properties: $\Sigma_{\sigma}(n) = n$ and $n$ is divisible by at least two ( $6$ and $28$ ) perfect numbers. The graph has the following properties: ['is_connected',
 'is_circular_planar',
 'is_planar',
 'is_interval',
 'is_directed',
 'is_chordal'] ( For a definition of these terms, see: http://doc.sagemath.org/html/en/reference/graphs/sage/graphs/generic_graph.html ) Attachment : def rad(n):
    return prod(prime_divisors(n))

def nextN(n,f=sigma):
    return n*rad(f(n))/gcd(rad(n),rad(f(n)))

def iterN(n,f=sigma,verbose=False):
    n0 = n
    n1 = -1
    ll = [n0]
    while n0 != nextN(n0,f=f):
        n1 = nextN(n0,f=f)
        if verbose:
            print n1
        ll.append(n1)
        n0 = n1
    return ll

def graphN(n,f=sigma):
    G = DiGraph()
    V = set(prime_divisors(n)).union(set(prime_divisors(f(n))))
    for p in V:
        for q in V:
            if n%p==0 and f(p^valuation(n,p))%q==0:
                G.add_edge(p,q)
    return G

G = graphN(1)
properties = { 'is_chordal': G.is_chordal(),
                   'is_circulant': G.is_circulant(),
      'is_circular_planar':G.is_circular_planar(),
     'is_clique':G.is_clique(),
     'is_connected': G.is_connected(),
    # 'is_cut_edge': G.is_cut_edge(),
    # 'is_cut_vertex': G.is_cut_vertex(),
     'is_directed': G.is_directed(),
     'is_directed_acyclic':G.is_directed_acyclic(),
     'is_drawn_free_of_edge_crossings': G.is_drawn_free_of_edge_crossings(),
    # 'is_equitable': G.is_equitable(),
     'is_eulerian':G.is_eulerian(),
     'is_gallai_tree': G.is_gallai_tree(),
     'is_hamiltonian':G.is_hamiltonian(),
     'is_independent_set':G.is_independent_set(),
     'is_interval':G.is_interval(),
     'is_planar':G.is_interval(),
     'is_regular':G.is_regular(),
     'is_strongly_connected':G.is_strongly_connected(),
     'is_transitive': G.is_transitive(),
     'is_transitively_reduced': G.is_transitively_reduced(),
     'is_vertex_transitive': G.is_vertex_transitive()}
allproperties = set(properties.keys())
for n in range(2,31):
    F = sigma
    it = iterN(n,f=F)
    N = it[-1]
    G = graphN(N,f=F)
    print N, len(G.vertices()),len(prime_divisors(N)),len(G.edges())
    #print 'is_aperiodic',G.is_aperiodic()
    properties = { 'is_chordal': G.is_chordal(),
                   'is_circulant': G.is_circulant(),
      'is_circular_planar':G.is_circular_planar(),
     'is_clique':G.is_clique(),
     'is_connected': G.is_connected(),
    # 'is_cut_edge': G.is_cut_edge(),
    # 'is_cut_vertex': G.is_cut_vertex(),
     'is_directed': G.is_directed(),
     'is_directed_acyclic':G.is_directed_acyclic(),
     'is_drawn_free_of_edge_crossings': G.is_drawn_free_of_edge_crossings(),
    # 'is_equitable': G.is_equitable(),
     'is_eulerian':G.is_eulerian(),
     'is_gallai_tree': G.is_gallai_tree(),
     'is_hamiltonian':G.is_hamiltonian(),
     'is_independent_set':G.is_independent_set(),
     'is_interval':G.is_interval(),
     'is_planar':G.is_interval(),
     'is_regular':G.is_regular(),
     'is_strongly_connected':G.is_strongly_connected(),
     'is_transitive': G.is_transitive(),
     'is_transitively_reduced': G.is_transitively_reduced(),
     'is_vertex_transitive': G.is_vertex_transitive()}
    P = [ p for p in properties.keys() if properties[p]]
    print N,P
    allproperties = allproperties.intersection(set(P))

print allproperties

perfectNumbers = [6,28,496,8128,33550336,8589869056]
for n in range(1,100000):
    F = sigma
    it = iterN(n,f=F)
    N = it[-1]
    if all([ N%p!=0 for p in perfectNumbers]):
        print N","['perfect-numbers', 'number-theory', 'fixed-point-theorems', 'divisor-sum', 'totient-function']"
3225629,What is the range of $ y = (\operatorname{arccot} x) (\operatorname{ arccot} ( - x)) $,"What is the range of $ y =  (\operatorname{ arccot x }) (\operatorname{ arccot{ - x }}) $ . I solved this problem with right answer using AM GM inequality. But I received a lot of  criticism for using AM GM inequality here on this site as it does not give sharp bounds.  So is there a better way? I was thinking about Jensen's inequality but that doesn't work. What is wrong with my solution of maximum value of $ \sin \frac {A}{2} + \sin \frac{B}{2} + \sin \frac{C}{2} $ in a triangle ABC? The side of a triangle inscribed in a given circle subtends angles $a, b, $ and $ y$ at the center. What is wrong with this solution of find the least value of $ \sec^6 x +\csc^6 x + \sec^6 x\csc^6 x$","['maxima-minima', 'trigonometry']"
3225635,How to show the following problem of determinant,"If the matrices $A,B\in M_{3}(\Bbb{Z})$ are singular and $AB=BA$ , show that the number $$\det(A^3+B^3)+\det(A^3-B^3)$$ is the double of a perfect cube. I have considered the polynomial $$\det(A+xB)=\det A+mx+nx^2+x^3\det B$$ From this how I can show","['matrices', 'determinant', 'linear-algebra']"
3225712,"$|f(x,y)| \le K |x-y|$: is there a name for this property?","Here $f:\mathbb{R}^2 \to \mathbb{R}$ and $K>0$ is a constant. It's a bit like being contractive or Lipschitz, but not the same as either of those.","['continuity', 'analysis']"
3225801,How does this Lie derivative axiom follow from my definition of the Lie derivative?,"$\newcommand{\L}{\mathcal{L}}$ $\newcommand{\der}[2][]{\frac{d#1}{d#2}}$ $\newcommand{\pder}[2][]{\frac{\partial#1}{\partial#2}}$ The definition of the Lie derivative which I'm starting with is $$ \L_v(\alpha) := \der{t} (\phi_t^*(\alpha))|_{t=0}$$ where $X$ is a manifold, $\alpha$ is some tensor, $v \in \Gamma(TX)$ is a vector field and $\phi : \mathbb{R} \times X \rightarrow X$ (writing $\phi_t(x) = \phi(t, x)$ ) is the 1-parameter group of diffeomorphisms on $X$ . Wikipedia says that this definition follows from four axioms, the first one being $$ \L_v(f) = v(f)$$ for $f$ a smooth function and the second one being $$ \L_v(S \otimes T) = \L_v(S) \otimes T + S \otimes \L_v(T) $$ (plus two more). I'd like to know how to show the first one I've written. Referring back to the definition I started with, I know that if $\alpha = f$ a smooth function then $\phi_t^*(f) = f \circ \phi_t$ . So using the chain rule $$ \begin{align} \L_v(f) &= \der{t}(f \circ \phi_t)|_{t=0} \\ 
&=  \sum_{k=1}^n\pder[f]{x_k} \der[x_k]{t}|_{t=0} \\
&= \sum_{k=1}^n\pder[f]{x_k} v^k
\end{align} $$ Here $(x_1, \dots, x_n)$ are local coordinates on $X$ and I've written $v^k = \der[x_k]{t}|_{t=0}$ since these are real numbers (coefficients). But then I think that $\sum_{k=1}^n\pder[f]{x_k} v^k$ is what we get if we ""apply $v$ the vector field to $f$ "", i.e. $$ \L_v(f) = \sum_{k=1}^n\pder[f]{x_k} v^k = v(f) $$ Is this the correct way to do it? Thank you.","['vector-fields', 'lie-derivative', 'smooth-manifolds', 'derivatives', 'differential-geometry']"
3225821,Maximum Regions Vees Can Divide a Circle,"The Circle Division by Lines problem ( link ) asks into how many regions, at most, one can divide a circle (or: the plane) with $n$ chords (or: lines). I am wondering about a similar question, but for which the dividing curves are not chords/lines, but rather $\mathsf{V}$ -shaped curves, which can be oriented in any direction. Stated succinctly: What is the maximum number of pieces in which it is possible to divide a circle for a given number of $\mathsf{V}$ -shaped cuts, where the cuts can be oriented in any direction? RE: Initial Comments I am fine with the assumption that the vertex must be inside the circle and the angle should be fixed across all $\mathsf{V}$ -cuts. But, I am open to suggestions as others see fit! RE: Solution In fact, the formula provided works irrespective of the vertex angle. In retrospect, Euler's Formula is a wise way to solve the problem and, with a quick check, one finds that plugging in $n=1$ and $n=2$ , respectively, yields $2(1)^2 - 1 + 1 = \fbox{2}$ and $2(2)^2 - 2 + 1 = \fbox{7}$ , as desired. For example, when there are a total of $2$ $\mathsf{V}$ -cuts, I believe the maximum is $7$ regions: What is the maximum number of regions for $n \in \mathbb{Z}^+$ total $\mathsf{V}$ -cuts?","['graph-theory', 'circles', 'extremal-combinatorics', 'geometry', 'planar-graphs']"
3225845,"If $T:L^p[0,1] \to L^p[0,1]$ bounded for $1 < p < \infty$ with continuous image, then it's compact","Is the following statement true? Let $T:L^p[0,1] \to L^p[0,1]$ be a bounded operator for $1 < p < \infty$ and suppose that $\operatorname{Im}(T) \subset C[0,1]$ consists of continuous functions. Then $T$ is compact. I have tried to prove it by using the reflexivity of $X=L^p[0,1]$ : Given $f_n \in X$ a bounded sequence, $Tf_n$ is also bounded, and thus by weak compactness, there exists $g \in L^p[0,1]$ such that $Tf_n \overset{w}{\to}g$ (denoting the subsequence again by $Tf_n$ ). One can show that actually $g = Tf$ for some $f \in X$ (by the fact that $TB_X$ is closed and convex and thus weakly closed) and thus $T(f_n - f) \overset{w}{\to}0$ . I am stuck here and can't seem to understand how by continuity of $T(f_n - f)$ we can conclude strong convergence. Maybe this approach is not fruitful, or the statement is just false. Any leads are appreciated.","['banach-spaces', 'compact-operators', 'operator-theory', 'lp-spaces', 'functional-analysis']"
3225868,"Showing Proj $R[x,y]/(x^2)$ is not affine scheme","So I started reading the Proj construction. I wanted to get more understanding by consider the graded ring $$\frac{R[x,y]}{(x^2)}$$ where $x,y$ have degree $1$ . Let $X= Proj(R[x,y]/(x^2))$ . 
So I want to know if (i) The scheme is not reduced. (ii) The scheme is not affine. For (i) I believe it is not so, since $$O_X(D_+(y))= (R[x,y]/(x^2))_{(y)} \simeq R[a]/(a^2) $$ is not reduced ring. But how does one show that is not affine?","['projective-schemes', 'affine-schemes', 'algebraic-geometry', 'schemes', 'projective-space']"
3225899,Evaluating $\int_0^1 \frac{3x}{\sqrt{4-3x}} dx$,"So this is the integral I must evaluate: $$\int_0^1 \frac{3x}{\sqrt{4-3x}} dx$$ I have this already evaluated but I don't understand one of the steps in its transformation.
I understand how integrals are evaluated, but I don't understand some of the steps when it is being broken down and integrated.
The steps are as follows: $$ - \left( \frac {-3x} {\sqrt{4-3x}}\right)$$ $$ - \left( \frac {4-3x-4}{\sqrt{4-3x}}\right) $$ $$ - \sqrt {4-3x} + \frac {4}{\sqrt{4-3x}}$$ $\mathbf {Question1} $ In these three steps the first thing I don't understand how it got broken down into two terms in the third step. If I add together the terms of the third step I get back the original one but I don't understnad how the author reached this point in the first place, like how can I know how to break it down into which and which terms? After this it is put back into the original equation: $$ \int_0^1 \frac {3x}{\sqrt{4-3x}} dx = - \int_0^1 (4-3x)^\frac {1}{2} dx + 4 \int_0^1 (4-3x)^\frac{-1}{2} dx $$ $$ =  \frac {1}{3} \int_0^1 (4-3x)^\frac {1}{2} (-3 dx) - \frac{4}{3} \int_0^1 (4-3x)^\frac{-1}{2} (-3dx) $$ After this it is integrated as usual with $-3dx$ term disappearing in both and $(4-3x)^\frac{1}{2}$ and $(4-3x)^\frac{-1}{2}$ get integrated with n+1 formula. $\mathbf{Question 2}$ Why was $-3$ multiplied and divided in second step. The dx doesn't change to du so it clearly isn't substitution. So what exactly is happening here?","['integration', 'calculus', 'definite-integrals', 'substitution']"
3225934,nonzero cohomology class on even dimensional compact manifold,"Let $M$ be a compact manifold of dimension $2n$ . Let $\omega$ be a 2 form on $M$ such that the induced bundle map $\tilde{\omega}: TM \to T^*M$ defined by $\tilde{\omega}(X)(Y) = \omega(X,Y)$ is a bundle isomorphism. Show that if $d \omega = 0$ , then $[\omega^n] \in H_{dR}^{2n}(M)$ is nonzero. I recognize that on oriented compact manifolds top cohomology is nontrivial, but this question doesn't seem to assume that. I tried assuming $\omega^n$ was exact and getting some contradiction but didn't get anywhere. Any advice would be appreciated.","['de-rham-cohomology', 'differential-forms', 'differential-geometry']"
3226028,solve the differential equation $\dot{x} + a\cdot x - b\cdot \sqrt{x} = 0$,Problem I want to know how to solve the differential equation $$ \dot{x} + a\cdot x - b\cdot \sqrt{x} = 0 $$ for $a>0$ and both situations: for $b > 0$ and $b < 0$ . My work One can separate the variables to obtain: $$ \frac{dx}{b\cdot \sqrt{x} - a\cdot x} = dt$$ but I do not know how to proceed ... https://www.wolframalpha.com/input/?i=solve+x%27(t)%2Bax(t)-bsqrt(x(t))+%3D+0 it seems to have an explicit solution ... Context This problem occurs in the following context: $$ \ddot{X} + a \cdot \dot{X} = f(X)$$ then multiplying both sides with $2\dot{X}^T$ one obtains: $$ (\dot{X}^T\dot{X})' + 2a\cdot \dot{X}^T\dot{X} = 2\dot{X}^T f(X)$$ Let $v= \dot{X}^T \dot{X}$ and the above differential equation arises ...,['ordinary-differential-equations']
3226042,Integral: $\int_0^1\frac{\mathrm{Li}_2(x^2)}{\sqrt{1-x^2}}dx$,I am trying to evaluate $$P=\frac\pi2\sum_{n\geq1}\frac{{2n\choose n}}{4^n n^2}$$ I used the beta function to show that $$P=\int_0^1\frac{\mathrm{Li}_2(x^2)}{\sqrt{1-x^2}}dx$$ IBP: $$P=\sin^{-1}(x)\mathrm{Li}_2(x^2)\big|_0^1+2\int_0^1\frac{\ln(1-x^2)}{x}\sin^{-1}(x)dx$$ Which is $$P=\frac{\pi^3}{12}+4\int_0^{\pi/2}x\cot(x)\ln(\cos x)dx$$ Which I'm not sure how to handle. I will continue working on this integral and update on my progress.,"['integration', 'special-functions', 'polylogarithm', 'closed-form', 'sequences-and-series']"
3226067,ABC triangle with $\tan\left(\frac{A}{2}\right)=\frac{a}{b+c}$,"I have a triangle ABC and I know that $\tan\left(\frac{A}{2}\right)=\frac{a}{b+c}$ , where $a,b,c$ are the sides opposite of the angles $A,B,C$ . Then this triangle is: a. Equilateral b. Right triangle with $A=\pi/2$ c. Right triangle with $B=\pi/2$ or $C=\pi/2$ (right answer) d. Acute e. Obtuse I tried to write $\frac{a}{\sin(A)}=2R\implies a=2R\sin(A)$ and to replace in initial equation.Same for $b$ and $c$ but I didn't get too far.","['trigonometry', 'triangles']"
3226088,Why can we let $x = 2\cos t\ $ in the solution for the following system of equations,"Solve in real number the system of equations $\begin{cases}x^2 = y+2
 \\ y^2 = z+2 \\ z^2 = x+2 \end{cases}$ The solution given to me says the following: If we eliminate $y$ and $z$ , we obtain a polynomial, $P$ , of degree $8$ in $x$ . Clearly this not an efficient way to proceed. Let $x =
 2\cos t,\ 0 \leq t \leq \pi$ ... Why are we allowed to make this trignometric substitution? To me, this is saying I can represent any real number $x$ by the trig function $2\cos t$ on the domain $t \in \left [ 0, \pi\right]$ because $x$ is supposed to be any real number. But, $|2\cos t|$ is at most $2$ on that interval. So why are we allowed to do this substitution if I cannot represent every real number with that trig function?","['proof-explanation', 'algebra-precalculus', 'systems-of-equations', 'substitution']"
3226098,"Compute the derivative $\partial_t\int_{\{u(t,\cdot) >0\} } 1\, dx$ in the sense of distributions","Let $u:\Omega\subset \mathbb R^N \to \mathbb R$ be bounded function that solves (in the sense of distributions) an evolution PDE $\partial_t u(t,x)= L(u(t,\cdot))(x)$ , where $L$ is some elliptic operator in divergence form. In a post on MathOverflow , a calculation was made regarding the time derivative $$\partial_t\int_{\{u(t,\cdot) >0\} } 1\,  dx$$ in the following way: $$\partial_t\int_{\{u(t,\cdot) >0\} } 1\,  dx= ∫_\Omega \delta[u(t,x)]\partial_t u(t,x)\,dx=\int_{S(t)}\frac{\partial_t u(t,x)}{|\nabla_x u(t,x)|}d\sigma(x).$$ How can one rewrite this calculation emphasizing the fact that we are doing a derivative in the sense of distributions, i.e. $$\langle \partial_t T, \phi\rangle = -\langle T, \partial_t\phi \rangle $$ where $T$ is the distribution associated with $\int_{\{u(t,\cdot) >0\} } 1\,  dx$ ? And how can we use the fact that $u$ solves the PDE above in the final formula?","['multivariable-calculus', 'distribution-theory', 'functional-analysis', 'real-analysis']"
3226154,Are complex numbers two dimensional or one dimensional?,"Complex numbers are represented as: z = x + yi This gives the impression that complex numbers are a real component plus an imaginary component. However, when doing math with complex numbers, they are represented as 2-D vectors like in this picture: Complex Vector Are complex numbers one or two dimensional? If they are one dimensional, then why do we do math with them and represent them as vectors? If they are two dimensional, then why are they represented as one number: ""x + yi"" instead of a coordinate pair: ""(x, yi)"" I know this has been asked a zillion times, but most of the answers I've found online don't explain the subject well. The best explanation I've found so far was here on Quora: https://www.quora.com/Are-complex-numbers-2-dimensional","['linear-algebra', 'complex-numbers']"
3226169,Dihedral angle of a regular simplex in $n$ dimensions,"For the regular simplex on $(n+1)$ points in $n$ dimensions, what is the dihedral angle i.e. the angle between two of the faces?","['euclidean-geometry', 'geometry', 'simplex']"
3226180,Minimal Least Common Multiplier for $n$ distinct integers,"Let $n\in\mathbb N^+$ be a positive integer. I am trying to find a set of $n$ distinct positive integers with minimal LCM. What is the set of $n$ distinct integers with minimal LCM? What is the asymptotics of this LCM as a function of $n$ ? Observe that we can choose the set to be $\{1,...,n\}$ , which would give a bound of $2^{O(n)}$ . However, I'm not sure that this is tight. For example, if $n=9$ then LCM $(\{1,2,3,4,5,6,7,8,9\})=2520$ , but we have LCM $(\{1,2,3,4,6,8,12,16,24\})=48$ .","['number-theory', 'least-common-multiple', 'elementary-number-theory']"
3226247,If the set on which a Riemann integrable function $f$ is nonzero has empty interior then the integral of $|f|$ is $0$.,"$f:[a,b]\to\mathbb{R}$ is Rieman integrable and $X=\{x\in [a,b] : f(x)\neq 0\}$ has empty interior. show that $\int_a^b|f(x)|dx=0.$ I think that it is an easy exercise of measure theory. But how to solve it without the knowledge of measure theory and just using real analysis. Thanks in advance.","['integration', 'calculus', 'riemann-integration', 'real-analysis']"
3226253,Prove that $T$ is uniquely ergodic,"Let $T:X\rightarrow X$ be a continuous map on a compact metric space $(X,d)$ . Suppose that $\mu$ is ergodic with respect to $T$ and for every $x\in X$ there exists a constant $C=C(x)$ such that for every $f \in C(X), f \geq  0$ , \begin{align*}
\limsup_{N \rightarrow \infty} \frac{1}{N} \sum_{n=0}^{N-1} f (T^nx) \leq C \int f d\mu.
\end{align*} Show that $T$ is uniquely ergodic. I knew the following theorem $\textbf{Theorem}$ the following properties are equivalent. (i) $T$ is uniquely ergodic (ii) For every $f\in C(X)$ , \begin{align*}
A_N^f:=\frac{1}{N} \sum_{n=0}^{N-1} f(T^nx) \rightarrow C_f, 
\end{align*} where $C_f$ is a constant independent of $x$ . I don't know how to induce the convergence of $A_N^f$ from the assumption in the problem. Any help is appreciated... Thank you!!","['ergodic-theory', 'analysis', 'real-analysis']"
3226262,Deriving a multivariate inverse function,"In my math assignment I have to find the inverse of $$ f(x_1, x_2) = \left(\ln \left(\frac{x_2}{x_1}\right), x_1^2 + x_2^2\right) $$ Now I already have looked into this, and came up with the following: I split f into $$ f_1(x_1,x_2) = \ln \left(\frac{x_2}{x_1} \right)\\ \text{and} \\ f_2(x_1,x_2) = x_1^2+x_2^2 $$ solving $f_1$ for $x_2$ resulted in $$e^{f_1} \cdot x_1 = x_2 $$ and after using this $x_2$ in $f_2$ $$ x_1 = \sqrt{\frac{f_2}{1+e^{2f_1}}} $$ which I then used in $x_2$ again and led to: $$ x_2 = e^{f_1} \cdot \sqrt{\frac {f_2}{1+e^{2f_1}}}  $$ So according to what I have done the inverse should be: $$ f^{-1}(f_1, f_2) = \left( \sqrt{\frac{f_2}{1+e^{2f_1}}} \ ,\ e^{f_1} \cdot \sqrt{\frac {f_2}{1+e^{2f_1}}} \right) $$ But after looking at another example on this site, it appears to be wrong. So I'd like to ask whether this is wrong or not, and if it is where I made the mistakes.","['functions', 'inverse', 'logarithms']"
3226318,Coloring of rectangle $3\times 4$,"We are colorings fields of rectangle with $3$ rows and $4$ columns in use of $2$ colors. Two colorings are the same if one is created from second in use any permutation of rows and cyclic shift of columns. Find number of different colorings, in which each color is used $6$ times. A = \begin{bmatrix}
    a & a & a \\
    a & a & a \\
    b & b & b \\
    b & b & b
\end{bmatrix} $A^T$ give me $1$ coloring.
A = \begin{bmatrix}
    a & a & a \\
    a & a & b \\
    a & b & b \\
    b & b & b
\end{bmatrix} $A^T$ give me $1$ coloring.
A = \begin{bmatrix}
    a & a & b \\
    a & a & b \\
    a & a & b \\
    b & b & b
\end{bmatrix} $A^T$ give me $1$ coloring.
A = \begin{bmatrix}
    a & a & b \\
    a & a & b \\
    a & b & b \\
    a & b & b
\end{bmatrix} $A^T$ give me $1$ coloring.
etc... But is there any smarter  way to do this? Writing all combinations is really slow and will cause an mistake so... I would like to see how to solve tasks like this when we are coloring structure with additional conditions.","['matrices', 'coloring', 'graph-theory', 'discrete-mathematics']"
3226329,Does the existence of $\lim f'(x)$ imply the existence of $\lim f(x)$?,"Let $f(x)$ be a differentiable function on an interval $(a,b)$ , where $a<b$ . If $\lim_{x\to a^+}f'(x)$ exists, does it necessarily follow that $\lim_{x\to a^+}f(x)$ also exists? I suspect that it is true, but does anyone know any simple proof?","['limits', 'calculus']"
3226499,"Show that $B(X,Y^*)$ and $B(Y,X^*)$ are isometrically isomorphic.","If $X$ and $Y$ are normed spaces then we define. $$B(X,Y)= \{ f:X\rightarrow Y | f :\text{ f is a linear operator and bounded }\}$$ $X^*= \{f:X \rightarrow \mathbb{R}  | \text{ f is a linear operator and bounded }\}$ I only know Hanh-Banach Theorem. And I don't know how even start. Something that confuse me is how to send functions that send a vector in a linear functional in a function that send a vector in a functional. This seems super hard. How should I think about this?","['linear-algebra', 'functional-analysis', 'dual-spaces']"
3226500,Integral $\int_{-\infty}^{\infty}\ln(2-2\cos(x^2))dx=-\sqrt{2\pi}\zeta(3/2)$,"Prove that $$\int_{-\infty}^{\infty}\ln(2-2\cos(x^2))dx=-\sqrt{2\pi}\zeta(3/2)$$ I was given this integral in my post Request for crazy integrals . I have never seen an integral like this before and I need help evaluating it. Here's what I've tried. Setting $$J=\int_{-\infty}^{\infty}\ln(2-2\cos(x^2))dx$$ We have that $$I=-\frac{J}{2\ln2}=\sum_{n\geq1}\frac1{n}\int_0^\infty \cos^n(x^2)dx$$ from the series $$-\ln(1-x)=\sum_{n\geq1}\frac{x^n}{n}$$ Then set $$p_n=\int_0^{\infty}\cos^n(x^2)dx$$ so that $$I=p_1+\sum_{k\geq1}\frac{p_{2k+1}}{2k+1}+\frac12\sum_{k\geq1}\frac{p_{2k}}{k}$$ We have from Wikipedia that if $n$ is odd then $$\cos^n x=2^{1-n}\sum_{k=0}^{(n-1)/2}{n\choose k}\cos[(n-2k)x]$$ And for even $n$ , $$\cos^n x=\frac1{2^n}{n\choose n/2}+2^{1-n}\sum_{k=0}^{n/2-1}{n\choose k}\cos[(n-2k)x]$$ So $$p_{2k+1}=\frac1{4^k}\sum_{\ell=0}^{k} {2k+1\choose \ell}\int_0^\infty \cos[(2k-2\ell+1)x^2]dx$$ Then wolfram provides $$\int_0^\infty \cos(ax^2)dx=\frac{\sqrt{\pi}}{2\sqrt{2|a|}}$$ Which I know how to prove. Anyway, $$p_{2k+1}=\frac{\sqrt\pi}{2^{2k+3/2}}\sum_{\ell=0}^{k}\frac{{2k+1\choose \ell}}{\sqrt{2k-2\ell+1}}$$ Thus $$I=\frac12\sqrt{\frac\pi2}\left[1+\sum_{k\geq1}\frac1{4^k(2k+1)}\sum_{\ell=0}^{k}\frac{{2k+1\choose \ell}}{\sqrt{2k-2\ell+1}}\right]+\frac12\sum_{k\geq1}\frac{p_{2k}}{k}$$ The evaluation of $p_{2k}$ may be significantly more difficult from potential convergence issues. In any case, this doesn't seem to getting me anywhere close to $\zeta(3/2)$ , so I would like to see how it's done. Thanks :) Edit: Okay, from @ComplexYetTrivial's comment, we have that essentially everything I have done so far (apart from exploiting symmetry) is wrong. So yeah, I'm happy someone caught that.","['integration', 'special-functions', 'real-analysis', 'closed-form', 'riemann-zeta']"
3226508,"Given $f$ is continuous and $f(x)=f(e^{t}x)$ for all $x\in\mathbb{R}$ and $t\ge0$, show that $f$ is constant function","This question was asked in ISI BStat / BMath 2018 entrance exam : Let $f: \mathbb{R} \to \mathbb{R}$ be a continuous function such that
  for all $x\in\mathbb{R}$ and $t\ge 0$ , $$f(x)=f(e^{t}x)$$ Show that $f$ is a constant function. My attempt: Suppose that $f$ is not a constant function. Then $f(0)\ne f(x_0)$ for some $x_0 \in \mathbb{R}$ . We eliminate the possibilities that $x_0>0$ and $x_0<0$ , thus proving that our assumption was wrong. Case 1: ( $x_0>0$ ). Let $k$ be any real number between $f(0)$ and $f(x_0)$ (not inclusive). Then by the intermediate value theorem,  there exists $y_0 \in (0, x_0)$ such that $f(y_0)=k$ . But $f(y_0)=f\left( e^{\ln \left( \frac{x_0}{y_0}\right)  } y_0\right) = f(x_0)$ which contradicts our assumption that $f(y_0)$ was between $f(0)$ and $f(x_0)$ . Case 2: ( $x_0<0$ ). Let $k$ be any real number between $f(0)$ and $f(x_0)$ (not inclusive). Then by the intermediate value theorem,  there exists $y_0 \in (x_0, 0)$ such that $f(y_0)=k$ . But $f(x_0)=f\left( e^{\ln \left( \frac{y_0}{x_0}\right)  } x_0\right) = f(y_0)$ , a contradiction again. Is this proof correct? I was probably looking for a direct proof if there's any. Alternative proofs are welcome.","['alternative-proof', 'continuity', 'proof-verification', 'real-analysis']"
3226519,"$f(x)$ is uniform continuous and $\{f(nh)\}_{n\in\mathbb N}$ converges,prove $\lim_{x\to \infty}f(x)$ exists","Assume $f(x)\in C[0,+\infty)$ and $f(x)$ is uniform continous,if for any $h>0$ ,the sequence $\{f(nh)\}_{n\in\mathbb N}$ converges,please prove that $\lim\limits_{x\to\infty}f(x)$ exists. I have no idea how to answer this question,though it doesn't seem to be diffcult.Please give me some ideas or solutions,thank you.","['calculus', 'analysis']"
3226538,On Hopfian modules over commutative Noetherian rings,"Let $R$ be a commutative Noetherian ring with unity. Let us call an $R$ -module $M$ to be Hopfian if every surjective endomorphism $M \to M $ is injective. 1) If $M_1$ and $M_2$ are Hopfian modules, then is $M_1 \oplus M_2$ necessarily Hopfian ? 2) If we have an exact sequence $0\to M_1 \to M\to M_2\to 0$ with $M$ Hopfian, then are $M_1$ and $M_2$ necessarily Hopfian ? If these are not true in general, are there any additional conditions on $R$ that would make it true ?","['ring-theory', 'abstract-algebra', 'commutative-algebra', 'modules']"
3226539,Definition of the set $\mathbb{Z}_+$,"I'm currently going through the introductory chapters of Munkres' Topology , and in chapter 1 section 4 of the second edition, Munkres attempts to briefly establish some Mathematical foundations for the study of Topology. In particular, he assumes a set of axioms for $\mathbb{R}$ (i.e. the so-called Field axioms), and from them he is able to obtain the set $\mathbb{Z}$ of integers. He does so as follows: A subset $A$ of real numbers is inductive if it contains the number $1$ (whose existence is given by one of the field axioms) and if for every $x \in A$ , $x+1$ is also in $A$ . Then, letting $\mathcal{A}$ be the collection of all inductive subsets of $\mathbb{R}$ , he defines $\mathbb{Z}_+$ as: $$ \mathbb{Z}_+ = \bigcap_{A \in \mathcal{A}} A$$ Intuitively this makes sense since if $A$ is inductive, $1$ is necessarily in $A$ (by definition) and so is $1+1 = 2$ and $2+1 = 3$ and so on. However, for a novice such as myself, this begs the question, why didn't we just define $\mathbb{Z}_+$ as $\{1, 2, 3, \ldots \}$ in the first place (indeed, many texts introducing elementary set theory do just this). What am I missing here?","['elementary-set-theory', 'number-theory', 'foundations']"
3226580,Evaluating $\sum_{n=0}^{\infty}ne^{1-n}$ using calculus,I'm trying to evaluate the following integral which popped up in MIT Integration Bee 2015 which involves the floor function. $$\int_{0}^{\infty}\left(xe^{1-x}-\lfloor x\rfloor e^{1-\lfloor x\rfloor}\right)\mathrm dx$$ My Attempt : $$\begin{aligned}\mathrm I &=\int_{0}^{\infty}xe^{1-x}\mathrm dx-\sum_{n=0}^{\infty}\int_{n}^{n+1}ne^{1-n}\mathrm dx\\ &= e-\sum_{n=0}^{\infty}ne^{1-n}=e\biggl(1+\sum_{n=0}^{\infty}\left(e^{1-n}\right)'\biggr)\end{aligned}$$ I'm getting stuck at this step because I'm not able to figure out how to evaluate this sum. I know one way is to use differentiation to get an expression for the sum but I'm not sure how to proceed. A hint in the right direction would be appreciated. Thanks Note : This is different from How can I evaluate $\sum_{0}^{\infty}(n+1)x^n$ ? . This problem is about bringing the sum into the form from which differentiation would yield the result.,"['integration', 'ceiling-and-floor-functions', 'exponential-sum', 'sequences-and-series']"
3226684,Countability of a subset of sequences,"Let $\mathcal{A} = \{a \in \{1,2,3,4,5\}^\Bbb N : |a_i- a_{i+1}| = 1 \; \forall i\}.$ Is the set $\mathcal{A}$ countable? I tried an argument like Cantor's diagonalization process but without success. This problem arises when solving the hiding cat puzzle ( https://www.youtube.com/watch?time_continue=2&v=yZyx9gHhRXM ). Indeed, if that set is countable and $\{a^1, a^2,...\}$ is an enumeration of $\mathcal{A},$ then we can define $a \in \{1,2,3,4,5\}^\Bbb N$ by $a_i = a^i_i.$ Then, the sequence $a$ solves the puzzle.","['arithmetic', 'cardinals', 'discrete-mathematics', 'sequences-and-series']"
3226707,Functions of Bounded Variation Have Left and Right Limits,"I have a proof of this for a real valued function https://www.encyclopediaofmath.org/index.php/Function_of_bounded_variation#Generalizations based on the Jordan decomposition into monotonic functions. I am looking for a more general proof in the case of a function $f: I = [a, b] \subset \mathbb R \to X$ where $X$ is a complete normed vector space (or even more generally, a complete metric space $(X, d)$ in which case substitute $||f(s) - f(t)||$ by $d(f(s) - f(t))$ in what follows) . My own attempt follows and I would appreciate feedback on this. Definitions: Let $f: I = [a, b] \subset \mathbb R \to X$ where $X$ is a normed vector space and $||.||$ its norm. A partition of a $[a, b]$ is a finite set of points $P = \{p_0 = a < p_1 < p_2 ... < p_n = b\}$ $V(f, P):= \sum_{i=1}^n ||f(p_i) - f(p_{i-1}||$ is a real non-negative number being the variation of $f$ on the partition $P$ (of the interval $I$ ). Note that the variation is defined for any function and any partition. $V(f):= sup\{V(f, P): P $ is a partition of I } is an extended real (i.e. can be $+\infty$ ) being the (total) variation of $f$ on the interval $I$ . If $V(f)$ is finite then $f$ is a function of bounded variation . $f$ has a left limit at $x \in (a, b]$ if given $\epsilon > 0$ there is $w \in [a, x)$ such that for all $y, z \in (w, x)$ then $||f(y) - f(z)|| < \epsilon$ . This is the Cauchy condition for the existence of this limit in a complete space. The right limit is similarly defined for $x \in [a, b)$ . Proof: Assume that $f$ does not have a left limit at some point $x \in (a, b]$ and construct a sequence of partitions of $[a, x]$ of increasing (unbounded) variation. This shows that in such cases $f$ cannot be of bounded variation (on $[a, x]$ and therefore also on $[a, b]$ ). The case for not having a right limit is analogous, so it follows by contra-positive that if $f$ is of bounded variation these limits must exist. Express the absence of a left limit by negation of the Cauchy definition....... If $f$ has no left limit at $x \in (a, b]$ then there is some $\epsilon > 0$ where for all $w \in [a, x)$ there is some $y, z \in (w, x)$ with $||f(y) - f(z)|| \ge \epsilon$ . Wlg assume $y < z$ . Firstly, this applies for $w = a$ and there is $a < y_1 < z_1 < x$ with $||f(y_1) - f(z_1)|| \ge \epsilon$ . Now define the partition $P_1 = \{a, y_1, z_1, x\}$ and it follows that $V(f, P_1) \ge \epsilon$ . As a second iteration, the condition applies for $w = z_1$ so there is $z_1 < y_2 < z_2 < x$ with $||f(y_2) - f(z_2)|| \ge \epsilon$ . Define the partition $P_2$ by adding $y_2, z_2$ to $P_1$ (in sequence) $ = \{a, y_1, z_1, y_2, z_2, x\}$ and  it follows that $V(f, P_2) \ge 2\epsilon$ . Then one can continue and define a sequence of partitions of $[a, x]$ $P_1, P_2, .....$ and for $P_n$ we have $V(f, P_n) \ge n.\epsilon$ so $sup\{V(f, P): P $ is a partition of $[a, x]\} = \infty$ , I.e. $f $ is not of bounded variation on $[a, x]$ .","['limits', 'proof-verification', 'bounded-variation', 'real-analysis']"
3226716,"Is there a norm making $C([0,1])$ into a Hilbert space?","The space $C([0,1])$ of continuous functions on $[0,1]$ is an inner product space under the $L^2$ -norm, but not complete. Equipped instead with the $L^\infty$ -norm, it becomes complete but the norm is no longer induced by an inner product (in particular it does not satisfy the parallelogram law). This got me wondering: can we equip $C([0,1])$ with a norm which makes it into a Hilbert space?","['hilbert-spaces', 'banach-spaces', 'normed-spaces', 'functional-analysis']"
3226717,"I'm looking for a book with solved exercises on differential geometry of surfaces (Christoffel symbols, cutvatures, etc.)","I'm very bad at long and tedious calculations and I need to cruch through at least 10 to be able to do it quickly enough to pass a test, so I'm looking for such calculations heavy exercises with solutions to make sure i do it right. Do you know any books that would fit my description? Thanks in advance!","['book-recommendation', 'differential-geometry']"
3226719,Probability random coins tossing,"You are playing with a friend: You are tossing a (fair) coin. If it is a tail, you win. If not, then you are tossing 2 (fair) coins. If they are both tails, you win. If not, you are tossing 3 (fair) coins, if they are all tails you win. If not, you are tossing 4 (fair) coins and so on... What is the probability for you to win???  Is it a rational number? I came to this formula: $1-\Pi_{n=1}^{\infty}(1-(\frac{1}{2})^n)$",['probability']
3226736,How to find basis of a de Rham Cohomology group?,"For example, we know that $H^1_{dR}(\mathbb{R}^2-\{p,q\})=\mathbb{R}^2$ where $p,q$ are two points, say $(-1,0),(1,0)$ . But how can we find the basis of this cohomology group? I think I need to find two closed but not exact 1-forms that are not homologous, but how should I do that?","['geometry', 'smooth-manifolds', 'general-topology', 'differential-topology', 'differential-geometry']"
3226743,Trying to understand the geometrization conjecture,"The Thurston's geometrization conjecture says: Every closed orientable 3-manifold decomposes canonically into pieces whose interior has a locally homogeneous complete metric. I'm trying to understand what a canonical decomposition means in this context. As far as I understand, that ""canonical pieces"" can be obtained as follows: Let $M$ be a closed orientable 3-manifold. For the Knesser-milnor theorem, it can be decomposed as a conected sum $$M\cong M_1 \sharp \cdots \sharp M_k$$ (unique up to permutation and homeomorphism) and each $M_i$ is prime. If $M_i$ is prime, then is either irreducible or $S^1 \times S^2$ , so the KM decomposition can be rewrited as $$M\cong N_1 \sharp \cdots \sharp N_s \sharp S^1 \times S^2 \sharp \cdots \sharp S^1 \times S^2$$ where the $N_i$ are irreducible. Finally, we aply the Jaco-Shalen decomposition, that says that if $N$ is a closed orientable irreducible 3-manifold, then there exist a family $\mathcal T$ of incompressible tori such that each component of $M\setminus \mathcal{T}$ is either a Seifert manifold or atoroidal. So, I undertstand that these small pieces which admit a geometry are the atoroidal or the Seifert manifolds. Am I right? And what happens whith $S^1 \times S^2$ ?Is a Seifert manifold? Thanks!","['general-topology', 'algebraic-topology']"
3226755,How to factorized this 4th degree polynomial?,I need your help to this polynomial's factorization. Factorize this polynomials which doesn't have roots in Q. $ \ f(x) = x^4 +2x^3-8x^2-6x-1 $ P.S.) Are there any generalized method finding 4 th degree polynomials factor?,"['algebra-precalculus', 'factoring', 'polynomials']"
3226780,Existence of a symmetric subset $B\subseteq A$ such that $2A-A\subseteq 8A$,"Let $A$ be a nonempty open connected subset of a (real) topological vector space $X$ such that $$2A-A \subseteq 8A$$ (for instance one could take $A=(-1,2)$ ). Question. Is it true that there exists a nonempty open connected set $B\subseteq A$ such that $B$ , in addition, is symmetric (i.e., $B=-B$ )?","['general-topology', 'topological-vector-spaces', 'connectedness']"
3226785,contour integration $\int_C \frac{\ln^2 z}{\sqrt{z}(1+z^2)}$(1 Short answer),"I solved this question and had a try as shown ... i got similar form ... but not getting correct answer.
here is the question: Question 3. $\quad$ (a) By considering the integral of $z^{-1/2}\log^2(z)/(1+z^2)$ around a suitably chosen contour in the cut $z$ plane, prove that $$\int_0^{\infty}\frac{\log^2(t) - \pi^2}{t^{1/2}(1+t^2)}dt = -\frac{\pi^3}{4\sqrt{2}}$$ $\quad$ In your solution, include a diagram that clearly specifies the contour you are using and provide a careful discussion of all required estimates of contributions from contours that you will discard when an appropriate limit is taken. $\quad$ (b) Using the same integration contour as in part (a) with the integrand $z^{-1/2}\log^2(z)/(1-z)$ , find a relation between the integrals $$\int_0^{\infty}\frac{\log^2(t)}{t^{1/2}(1+t)}dt \quad\text{ and }\quad \int_0^{\infty}\frac{dt}{t^{1/2}(1+t)}.$$ $\quad$ Use this relation to deduce, without further contour integration, that $$\int_0^{1}\frac{\log^2(t)}{t^{1/2}(1+t)}dt = \frac{\pi^3}{2}.$$ Here is what I have so far: $\quad$ Ans 3. a) $$\int_0^{\infty}\frac{log^2(t) - \pi^2}{\sqrt{t}(1+t^2)}dt$$ $$\begin{multline}
  \shoveleft \text{Consider} \quad f(z) = \frac{log^2(z)}{\sqrt{z}(1+z^2)} \\
  \shoveleft \text{Consider} \quad \int_Cf(z)dz \qquad \text{along the C as shown below}
  \end{multline}$$ $$\begin{multline}
  \shoveleft \text{Poles are at } z = 0 \text{ (not lies[sic] in contour)}, \quad z = \pm i \\ 
  \shoveleft \text{Res }f(z=i) \quad \space \space \space = \quad \lim_{z \rightarrow i}\frac{(z-i)log^2(z)}{\sqrt{z}(z-i)(z+i)} \space = e^{i\pi /4}\frac{\pi^2}{8} \\
  \shoveleft \text{Res }f(z=-i) \quad = \quad \lim_{z \rightarrow -i}\frac{(z+i)log^2(z)}{\sqrt{z}(z-i)(z+i)} = -e^{3i\pi /4}\frac{\pi^2}{8} \\
  \shoveleft \therefore \quad \int_{C}f(z)dz = 2\pi i\left[\frac{\pi^2}{8}(e^{i\pi /4} - e^{3i\pi /4}) \right] = \frac{i\pi^3}{2\sqrt{2}} \\
  \shoveleft \\
  \shoveleft \text{Thus,} \\
  \shoveleft \quad \int_{AB}f(z)dz + \int_{\Gamma}f(z)dz + \int_{FG}f(z)dz + \int_{\gamma}f(z)dz = \frac{i\pi^3}{2\sqrt{2}} \\
  \shoveleft \\
  \shoveleft \text{On AB: } z = x \quad \text{and on FG: } z = xe^{2\pi i} \\
  \shoveleft \therefore \quad \int_{AB}f(z)dz + \int_{FG}f(z)dz = \int_{r}^{R}\frac{log^2x}{\sqrt{x}(1+x^2)}dx + \int_{R}^{r}\frac{\left( log(xe^{2\pi i}) \right)^2e^{2\pi i}}{\sqrt{xe^{2\pi i}}(1+x^2e^{2\pi i})}dx \\
  \shoveleft \\
  \shoveleft = \int_{r}^{R}\frac{log^2x}{\sqrt{x}(1+x^2)}dx + \int_{R}^{r}\frac{log^2x - 4\pi^2 +4\pi log(x)i}{\sqrt{x}e^{\pi i}(1+x^2)}dx \\
  \shoveleft \\
  \shoveleft = \int_{r}^{R}\frac{log^2x}{\sqrt{x}(1+x^2)}dx \ + \space \int_{r}^{R}\frac{log^2x - 4\pi^2 + 4\pi log(x)i}{\sqrt{x}(1+x^2)}dx \quad \because \space e^{\pi i} = -1 \\
  \shoveleft \\
  \shoveleft = \int_{r}^{R}\frac{2log^2x - 4\pi^2 - 4\pi log(x)i}{\sqrt{x}(1+x^2)}dx \\
  \end{multline}$$ $$\begin{multline}
  \shoveleft \\
  \shoveleft \text{For the circle } \gamma : \space z = re^{i \theta} \\
  \shoveleft \text{So, } \int_{\gamma}f(z)dz = \int_{2\pi}^{0} \frac{\left( log(re^{i \theta})\right)^2(rie^{i \theta})}{\sqrt{re^{i \theta}}(1 + r^2 e^{2i \theta})}d\theta = \int_{2\pi}^{0}\frac{\sqrt{r}*ie^{i \theta}*log^2(re^{i \theta})}{e^{i\theta /2}(1 + r^2e^{2i\theta})}d\theta \\
  \shoveleft \text{Clearly, if } r \rightarrow 0, \space \int_{\gamma}f(z)dz \rightarrow 0 \\
  \end{multline}$$ $$\begin{multline}
  \shoveleft \\
  \shoveleft \text{Now, on the circle } \Gamma : \space z = Re^{i\theta} \\
  \shoveleft \text{So, } \int_{\Gamma}f(z)dz = \int_{0}^{2\pi} \frac{\left( log(Re^{i \theta})\right)^2(Rie^{i \theta})}{\sqrt{Re^{i \theta}}(1 + R^2 e^{2i \theta})}d\theta = \int_{0}^{2\pi}\frac{\sqrt{R}*ie^{i \theta /2}*log^2(Re^{i \theta})}{e^{i\theta /2}(1 + R^2e^{2i\theta})}d\theta \\
  \shoveleft = \int_{0}^{2\pi}\frac{ie^{i\theta /2}*log^2(Re^{i\theta})}{R^{3/2}\left(\frac{1}{R^2} + e^{2i\theta}\right)}d\theta \\
  \shoveleft \text{if } R \rightarrow \infty, \space \int_{\Gamma}f(z)dz \rightarrow 0 \\
  \shoveleft \\
  \shoveleft \text{So, we have } \\
  \shoveleft \quad \int_{0}^{\infty}\frac{2log^2x - 4\pi^2 +4\pi log(x)i}{\sqrt{x}(1+x^2)}dx = \frac{i\pi^3}{2\sqrt{2}} \\
  \shoveleft \quad \qquad \implies +\int_{0}^{\infty}\frac{4\pi log(x)}{\sqrt{x}(1+x^2)}dx = \frac{\pi^3}{2\sqrt{2}} \\
  \shoveleft \space \space \qquad \quad \qquad \text{or } \int_{0}^{\infty}\frac{log(x)}{\sqrt{x}(1+x^2)}dx = \frac{\pi^2}{2\sqrt{2}}
  \end{multline}$$ I don't understand the explanation in the solution, can anyone explain where is my mistake ? How to arrive at the answer?","['integration', 'complex-analysis', 'calculus', 'contour-integration', 'residue-calculus']"
3226796,$p \geq 5$ prime. $2p+1$ not a prime. Then $\phi(n)=2p$ has no solution.,"I am studying for my number theory final by doing past exams. The question is Let $p \geq 5$ be a prime. Prove that if $2p+1$ not a prime. Then $\phi(n)=2p$ has no solution. ( $\phi$ is Euler Totient function). In the case where $2p+1$ is prime, find all solutions to $\phi(n)=2p$ . I managed to 'prove' the first part, however without using the $2p+1$ not prime assumption. I spot if $2p+1$ is prime then $\phi(2p+1)=2p$ , assuming the first part this shows that $\phi(n)=2p$ has solutions $\iff 2p+1$ is prime. But how to find all solutions? So clearly the $2p+1$ not prime assumption is needed. So my proof is wrong but I can't see where it fails (edit: as pointed out I just missed a case, the proof itself is not wrong). Can someone show me where it fails, and or provide an alternative. My proof: Let $n=2^a\prod_{i=1}^tp_i^{\alpha_i}$ be the prime factorisation of $n$ with $a\geq 0$ , and $p_i$ odd primes. Assume that $\phi(n)=2p$ . Know that $$\phi(n)=\phi(2^a)\prod_{i=1}^t\phi(p_i^{\alpha_i})=2p.$$ If $t\geq 2$ , then $4 \mid 2p$ , since $\phi(p_i^{\alpha_i})$ is even. Hence we must have $t < 2$ . If $t=0$ then $\phi(n)=2^{a-1} \neq 2p$ . So we must have that $t=1$ and so we have $$n=2^ap_1^{\alpha_1}.$$ If $a>2$ then $ 4 \mid \phi(2^a) \mid 2p$ , which is a contradiction. So we must have $a \leq 2$ . If $a=0$ or $a=1$ , then $\phi(2^a)=1$ and we have $\phi(n)=p_1^{\alpha_1-1}(p_1-1)=2p$ . Hence $p_1-1=2$ and $p=p_1^{\alpha_1-1}$ , which leads to $p_1=p=3$ , which is a contradiction. Hence we must have $a=2$ , i.e $n=4p_1^{\alpha_1}$ . Then $\phi(n)=2p_1^{\alpha_1-1}(p_1-1)=2p$ . Which implies $p_1^{\alpha_1-1}(p_1-1)=p$ . So either $p_1-1=p$ , in which case they are consecutive primes, contradiction as $p\geq 5$ . Or $p_1^{\alpha_1-1}=p$ and $p_1-1=1$ , which leads to $p_1=p=2$ , also a contradiction. So all cases lead to a contradiction.",['number-theory']
3226815,linearly independent solution to second order ODE.,Let $y(t)$ be a nontrivial solution for the second order differential equation $\ddot{x}+a(t)\dot{x}+b(t)x=0$ to determine a solution that is linearly independent from $y$ we set $z(t)=y(t)v(t)$ . Show that this leads to a first order differential equation for $\dot{v}=w$ What do they even mean with linearly independent from $y$ ? Is it meant in the sense that the solution shouldn't be just different by a constant from $y$ like in linear algebra ? Also how would I go on showing that this leads to a solution of first order ? I'm kind of lacking any idea where to start.,"['calculus', 'proof-writing', 'ordinary-differential-equations']"
3226829,FIFA19 - overall rating is higher for specific country? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question does not appear to be about math within the scope defined in the help center . Closed 5 years ago . Improve this question Hy, I was studying this data set on Kaggle ( https://www.kaggle.com/karangadiya/fifa19 ) for my machine learning problem. Idea is to from features of player to count overall rating.
Ok, first we need a little bit of feature engineering to see what feature will be significant.
One of this is country of player such as Croatia or Brasil. Main idea is that country of player wouldn't have much impact on overall rating, but what if developer with intention give Brasil player much higher rating than Croatia player.The same idea can be used in club(Maybe equal player in Real Madrid and Dinamo Zagreb have higher rating if he play in RM). So the problem is to show that country of player has no connection to overall.
To try to solve this problem I use all Croatia and Brasil player and use T-test on their overall rating. The test show that Brasil player have higher rating, but this can be also reason that Brasil have better players.
Another idea was also use T-test again but overall / value for Croatia and Brasil but I didn't get any clear answer. Can you give idea how to approach the problem?","['machine-learning', 'statistics', 'anova', 'means']"
3226846,GAP code to calculate the a certain subgroup $E(G)$ of a group,"I am a research scholar from India.  At present,
I am working on a problem. For this problem,  I need to construct the subgroup $E(G)$ of a group $G$ in GAP. Please help me. My question is as follows: Questions:
For any group $G$ , the absolute center $L(G)$ of $G$ is defined as $$L(G) = \lbrace g\in G\mid \alpha(g)=g,\forall\alpha\in Aut(G)
\rbrace,$$ where $Aut(G)$ denote the group of all automorphisms of $G$ . An automorphism $\alpha$ of $G$ is called an absolute central
automorphism if $g^{-1}\alpha(g)\in L(G)$ for all $g\in G$ . Let $Var(G)$ denote the group of all absolute central automorphisms of $G$ . Let $$C_{Aut(G)}(Var(G))= \lbrace \alpha\in Aut(G)\mid\alpha\beta =
\beta\alpha, \forall\beta \in Var(G)\rbrace$$ denote the centralizer
of $Var(G)$ in $Aut(G)$ .
Let $$E(G)=[G,C_{Aut(G)}(Var(G))]=\langle g^{-1}\alpha(g)\mid g\in
G, \alpha\in C_{Aut(G)}(Var(G))\rangle.$$ One can easily see that $E(G)$ is a characteristic subgroup of $G$ containing the derived
group $G^{\prime}=[G,Inn(G)]$ . How to calculate $E(G)$ in GAP? I already have code which calculates $L(G)$ . Will this be helpful for calculating $E(G)$ ? The GAP code for finding the absolute center $L(G)$ of a group $G$ is written below: Fusionclass:=function(G,g)
local a,aut,l;
l:=[];
aut:=AutomorphismGroup(G);
for a in aut do
  Add(l,Image(a,g));
od;
return Set(l);
end;

autocenter:=function(G)
local M,N,g;
M:=Filtered(G,g->Size(Fusionclass(G,g))=1);
N:=Subgroup(G,M);
return N;
end;","['gap', 'group-theory']"
3226849,"Whether $\Bbb{R}^3\setminus \{0\}$ and $\Bbb{R}^3 \setminus \{0,1 \}$ are homeomorphic or not?","I am thinking about whether the two spaces $\Bbb{R}^3 \setminus \{0 \}$ and $\Bbb{R}^3 \setminus \{0,1 \}$ are homeomorphic or not? I guess they are not homeomorphic but cannot find out the proper reason. Till now I have come to the following : $S^2$ is a deformation retract of $\Bbb{R}^3 \setminus \{0\}$ where as I think one can deform the space $\Bbb{R}^3 \setminus \{0,1 \}$ on to two spheres with a single common point, i.e. Wedge of two Spheres ( For this I try to see the deformation visually).  But this means both of the space has trivial First fundamental group. So I think this idea didn't work...!! So how can I distinguish these to space topologically. Any suggestion is appreciated. Thank you. P.S: Let me clear that I am very new to Algebraic topology. I recently started the first fundamental groups and its properties and try to use it to distinguish two spaces. The spaces in the question is a very random that I thought that it could be solved using fundamental groups. So if this two spaces cannot be distinguished using General Topology and tools in First Fundamental group then let me know. Thank you..","['general-topology', 'differential-topology', 'algebraic-topology']"
3226917,Minimal surfaces defined on the plane is the plane itself,"My problem is: Let $S$ be a surface given by the graph of a smooth function defined on all points of $\mathbb{R}^2$ . Prove that if $S$ is minimal, then $S$ is a plane. Just by looking at the differential equation for the defining function dosend solve the problem. Can someone help me with this one?","['riemann-surfaces', 'surfaces', 'minimal-surfaces', 'geometry', 'differential-geometry']"
3226957,"definite integral of logarithmic functions. Like this one $ \int_0^{\pi/2} \ln\left(a^2\cos^2 \theta + b^2\sin^2 \theta\right)\, \mathrm{d}{\theta}$","Just playing with graph plotter I found some formulas for definite integrals of logarithmic functions such as $$
            \int \limits_0^{\pi/2} \ln\left(a^2\cos^2 \theta + b^2\sin^2 \theta\right)\, \mathrm{d}{\theta} = \pi \ln \left(\frac{a+b}{2}\right),
        $$ $$
        \int \limits_0^{\pi/2} \ln\left(4a^4\sin^4 \theta + b^4\cos^4\theta\right)\,  \mathrm{d}{\theta}= \pi\ln\left(\frac{2a^2+b^2+2ab}{4}\right)
    $$ or even $$\int \limits_{0}^{1} \ln\left(a^2t^2 + b^2 (1-t)^2 \right) \, \mathrm{d}{t} = \frac{2a^2\ln a + \pi ab + 2b^2 \ln b}{a^2+b^2} - 2, $$ I hope you got the idea. The formulas look relatively simple, like it is not impossible to prove, but I have no idea what method can be used.
Not being a good mathematician, but rather the one who solves integrals by guessing in graph plotter, I asked a friend and he came up with an elegant way to prove the first one (partial derivatives along $a+b=\mathrm{const}$ are zero), but it does not seem to work well for the others as the contour lines have more complicated shapes. Do you have any helpful thought about that? At least, where might some similar integrals have appeared before, what book/paper to search for? Thank you.",['multivariable-calculus']
3226963,Difference between two connections,"I have the following exercise: Let $E \rightarrow M$ be a vector bundle, $\nabla, \tilde{\nabla}$ two connections on $E$ . Show that there exists $A \in \Omega^1(M,End(E)) := \Gamma(T^{*}M \otimes End(E))$ , s.t. $\tilde{\nabla}=\nabla+A$ . So far, I have that $\Gamma(T^{*}M \otimes End(E))\cong Mult_{C^{\infty}(M)}(X(M) \times \Gamma(E) \times \Gamma(E^{*}))$ . Now it's obvius to define $A:= \tilde{\nabla}-\nabla$ and to show that $\tilde{\nabla}-\nabla \in Mult_{C^{\infty}(M)}(X(M) \times \Gamma(E) \times \Gamma(E^{*}))$ .
Is that correct? Now I know that $A(X,s) \in Hom_{C^{\infty}(M)}(\Gamma(E^{*}, C^{\infty}(M)) \cong \Gamma(E)$ but I'm not sure how to shows multilinearity here. Can anybody give me a hint?","['connections', 'differential-geometry']"
3227007,How to understand the convergence of Fourier Series in $L^p$,"My professor told me that Suppose that $f \in L^p(-\pi, \pi)$ (i.e. $f$ is 2 $\pi$ -periodic and $\|f\|_{L^p} < \infty$ ). If $1<p<\infty$ , then the Fourier series of $f$ converges to $f$ in $L^p$ . If $p = 2$ , then this statement is easy to understand since $e^{inx}, \, n = 0, \pm1,\pm 2,\dots$ form an orthonormal basis of $L^2$ . Also, $L^2$ is Hilbert. Thus, $\sum\langle e^{inx}, f(x)\rangle e^{inx} = f(x)$ in $L^2$ sense (i.e. $\|\left(\sum\langle e^{inx}, f(x)\rangle e^{inx}\right) - f(x)\|_{L^2} = 0$ ). But how to understand the above statement if $p \ne 2$ ? Then the space $L^p$ with $1<p<2$ or $2<p < \infty$ is not even Hilbert. Hope someone can give a nice interpretation.","['lp-spaces', 'fourier-analysis', 'functional-analysis', 'real-analysis']"
3227026,Derivative rules,"I have some problems when I have to derive: I don't know where I have to begin and where I have to stop. For example, if I have $$f(x)=(x^2 +1)(x^2 +3)$$ I know that I have to use the product rule so I get $$f'(x)=(x^2 +1)'(x^2 +3)+(x^2 +1)(x^2 +3)'$$ and the resolution is $$f'(x)=4x^3 +8x$$ . But why can't I derive the stuff inside the brackets, like $$f(x)'=(2x)(2x)$$ and then $$f'(x)=4x^2$$ And I always have that problem, I don't know what rule I should use first.
Thank you.","['calculus', 'derivatives']"
3227102,Given $A^2 = A - I$ find $A^{15}$,"We should find matrix A such that $A^2 = A - I$ find $A^{15}$ . I solved this with observing the pattern with raising A to different powers up to 6 and I realized that $A^{15} = -I$ . However I'm not sure if this is the correct method, or if the result is correct.","['matrices', 'matrix-equations', 'linear-algebra']"
3227256,How to show that $f(z)= 1/(z-a)$ is periodic with period $2\pi i$?,"From Ahlfor's book, Complex Analysis, page 149: ""The particular function $1/(z-a_j)$ has the period $2\pi i$ ."" How can one see this is true?
I tried writing $z$ as $|z| e^{i \arg{z}}$ and using the definition of periodic $f(z+\omega)=f(z)$ , but I can't seem to work out the details this way.","['complex-analysis', 'complex-numbers']"
3227300,"Primes number $n,n+2,n+6,n+8,n+12,n+14$","Find all natural number $n$ such that all the following numbers are primes : $$n,\;\; n+2,\;\;n+6,\;\;n+8,\;\;n+12,\;\;n+14$$ are all prime numbers","['number-theory', 'modular-arithmetic', 'elementary-number-theory', 'prime-numbers']"
3227325,Dominating function for derivative of moment generating function,"Let $X$ be a random variable and the moment generating function $$\psi_X:(-\varepsilon,\varepsilon)\rightarrow \mathbb{R}_+,\quad \psi_X(t):=E[e^{tX}]$$ be defined, such that $\psi_X(t)<\infty$ for all $t\in(-\varepsilon,\varepsilon)$ . According my textbook we have $$\psi^{(n)}_X(0)=\frac{d^n}{dt^n}E[e^{tX}]\bigg|_{t=0}=E[\frac{d^n}{dt^n}e^{tX}\bigg|_{t=0}]=E[X^n],$$ where differentiation and integration can be interchanged by using dominated convergence. However what is the dominating function here? It is clear that for all $t\in(-\varepsilon,\varepsilon)$ , we have $$\frac{d^n}{dt^n}e^{tX}=X^n\ e^{tX}$$ So I need to find a integrable dominating function $h:\Omega\rightarrow\mathbb{R}_+$ , such that $$\forall t\in(-\varepsilon,\varepsilon): |X^n\ e^{tX}|\le h$$ Does someone has a hint on this one? Thanks a lot in advance!","['moment-generating-functions', 'characteristic-functions', 'probability-theory', 'real-analysis']"
3227391,Prove that $2^{30}$ has at least two repeated digits.,"Prove that $2^{30}$ has at least two repeated digits. I assume that the question is asking me to prove that $2^{30}$ has at least one digit that appears twice. Correct me if I'm wrong. (I later checked $2^{30}$ has three digits each of which appears twice, I initially thought that if I could prove the $2^{30}$ has 11 digits, then I can prove the given, but calculated the number of digits only to find out that it has 10 digits).","['discrete-mathematics', 'decimal-expansion']"
3227522,Evaluating sum $\sum_{m=0}^{\infty}\frac{(2-\delta_m^0)(-1)^m \lambda_0}{a(\lambda_0^2 -(\frac{m\pi}{a}))}\cos(m\pi x/a)$,"How Can I evaluate the following sum $$\sum_{m=0}^{\infty}\frac{2-\delta_m^0}{a}\frac{(-1)^m \lambda_0}{\lambda_0^2 -(\frac{m\pi}{a})}\cos\left(\frac{m\pi x}{a}\right)=\frac{\cos(\lambda_0 x)}{\sin(\lambda_0 a)}$$ I have read this in a research paper I have tried evaluating the sum using finite cosine transform 
We have $$\frac{2}{a}\frac{1}{\lambda_0}+\frac{2}{a}\sum_{m=0}^{\infty}\frac{(-1)^m \lambda_0}{\lambda_0^2 -(\frac{m\pi}{a})}\cos\left(\frac{m\pi x}{a}\right)=f(x)$$ So $$\frac{(-1)^m \lambda_0}{\lambda_0^2 -(\frac{m\pi}{a})}=\int_{0}^{a} f(x)\cos\left(\frac{m\pi x}{a}\right) dx $$ How to find $f(x)$ ? And Is there any other way to evaluate the sum ? Thanks In advance.","['summation', 'definite-integrals', 'real-analysis', 'sequences-and-series', 'fourier-series']"
3227528,"Solve ODE initial value problem: $\dot{u}=(2t+u-3)^2-2 , u(1)=0$ Separation of variables fails",So I have this ODE initial value problem $\dot{u}=(2t+u-3)^2-2 \hspace{2cm}u(1)=0$ So I tried seperating the variables somehow but to no avail. How else could I tackle this problem ?,"['calculus', 'ordinary-differential-equations']"
3227537,How to derive this relation that I found intuitively?,"By intuition, I found that the result of evaluating the following expression $$ \frac{1}{M} \frac{\sum_{N=0}^M \frac{M!}{(M-N)!N!} N e^{cN}}{\sum_{N=0}^M \frac{M!}{(M-N)!N!}  e^{cN}}  $$ does not depend on the positive value of the integer $M$ , i.e. it only depends on $c\in\mathbb R$ . I corroborated this with the help of a simple Python script. How to show  analytically that this is true?","['problem-solving', 'probability']"
3227544,Example of unstable attractor,"While defining the notion of assymptotically stable solution of an ODE (stable + atractor), my notes warn that there are unstable attractors and accompany this with the following diagram: What is a simple example of an unstable attractor.","['ordinary-differential-equations', 'dynamical-systems']"
3227568,Derivative at point but point itself converges,"Say, that $\lim_{x\to 0} f(x)=1$ anď $\lim_{x\to 0} \frac{f(x)-1}{x} = 1$ then we get $\lim_{x\to 0} f'(x)=1$ Is this an obvious conclusion? I think there is one omitted thing for this approach. $$\lim_{x\to 0, \tau\to 0} \frac{f(x)-f(\tau)}{x-\tau} = \lim_{x\to 0} f'(x)$$ Am I right? I don't know how to prove this since I haven't learned higher math but naive definition of derivative with graph (slope of tangent line)","['limits', 'calculus', 'derivatives']"
3227606,Finding center and rotation angle of ellipse that contains three points,"Given three points $p_1, p_2, p_3 \in \mathbb{R}^2$ , and an ellipse with shape parameters $(a,b)$ (the semi-major and semi-minor), is it possible to determine, if they exist, a center $c \in \mathbb{R}^2$ and a rotation angle $\theta \in [0, \pi]$ , such that the ellipse centered at $c$ rotated by $\theta$ contains $p_1, p_2, p_3$ ? In other words, let $$E(p, \theta)=\dfrac{(p_x\cos{\theta} + p_{y}\sin{\theta})^2}{a^2} + \dfrac{(p_x\sin{\theta} -p_y\cos{\theta})^2}{b^2}$$ I want to determine $c\in \mathbb{R}^2$ and $\theta \in [0, \pi]$ , such that: \begin{equation}
E(p_1-c, \theta) = 1\\
E(p_2-c, \theta) = 1\\
E(p_3-c, \theta) = 1
\end{equation}","['conic-sections', 'geometry']"
3227626,"""Counterexample"" for the Inverse function theorem","In a lecture we stated the theorem as follows: Let $\Omega\subseteq\mathbb{R}^n$ be an open set and $f:\Omega\to\mathbb{R}^n$ a $\mathscr{C}^1(\Omega)$ function. If $|J_f(a)|\ne0$ for some $a\in\Omega$ then there exists $\delta>0$ such that $g:=f\vert_{B(a,\delta)}$ is injective and ... This only is a sufficient condition, so is there any function whose jacobian has determinant $0$ at every point but still is injective? If the determinant only vanished on one single point something similar to $f(x)=x^3$ at $x=0$ in $\mathbb{R}$ would do the trick, but if $|f'(x)|=0$ for every $x\in\Omega\subseteq\mathbb{R}$ then $f$ is constant and not injective. Does the same hold in $\mathbb{R}^n$ ? Thanks","['inverse-function-theorem', 'examples-counterexamples', 'real-analysis']"
3227685,Inequality of Product and Sum,"Let $\forall i \in \{1,\dots,K\}, a_i \in (0,1)$ and $\sum_{i=1}^{K} a_i = 1$ . Let $P_i = \prod_{j=1}^{i} (1-a_j)$ and $S_i = \sum_{j=1}^{i} a_j$ . 
Is there proof or counterexample to $\forall i, (1-P_i)/S_i \geq (1-P_K)$ ?","['algebra-precalculus', 'inequality']"
3227723,Can solution to differential equation be continuous extended?,"Let $v:\mathbb{R}^n\to\mathbb{R}^n$ be continuous. Let $\gamma:[0,T)\to\mathbb{R}^n$ be the unique solution to $\frac{d\gamma}{dt}=v(\gamma),\gamma(0)=p$ . Suppose $\gamma$ remains bounded. Show that $\lim_{t\to T}\gamma(t)$ exists so that $\gamma$ admits a continuous extension to $[0,T]$ . I don't have much idea. I'm thinking about Picard-Lindelof Theorem. Does the converse work? The solution is unique so $v$ is lipschitz? If so, uniform continuity can somehow get to what we want? And how does $\gamma$ being bounded come into play? The class I'm taking is not mainly about differential equations and I don't have much knowledge in it as well. This is like a question for us to play around ourselves. Any help is appreciated!","['ordinary-differential-equations', 'real-analysis']"
3227824,"Discrete math: Inverse, converse, contrapositive - simplifying expressions","State the inverse, converse, and contrapositive of the following implication expression as English sentences. Ensure that you list the symbols you will use for each ATOMIC predicate. You must also simplify your expressions and distribute your negation operations as much as possible before translating. Given statement: If it is entertaining then it is not impossible and it is not difficult So I get how to do the inverse, converse, and contrapositive, but I don't really know what my practice worksheet means by ""simplify your expressions and distribute your negation operations as much as possible before translating."" Like if I were to find the contrapositive I would do: Let e be the predicate ""if it is entertaining"", i be ""it is not impossible"" and d be ""it is not difficult"" $e → (i\lor d) $ $¬(i \lor d) → ¬e $ $(¬i \land ¬d) → ¬e $ Translation: If it is impossible and difficult then it is not entertaining. but I don't know if that meets the requirements for ""simplifying the expression and distribute the negation operations as much as possible before translating.""","['predicate-logic', 'logic', 'discrete-mathematics']"
3227835,"Is there a dual to term ""vacuously true"" for a universal set?","For an empty set, any statement that claims ""for all ... is true/false"" are considered ""vacuously true"". So, can we construct a universal set in which any statement that claims ""there exists ... is false/true"" as a dual to the vacuously true statements?","['elementary-set-theory', 'logic']"
3227876,Derivatives of matrix norms,"I am reading The Matrix Cookbook , which has the following  for the Frobenius norm $$ \frac{\partial }{\partial X} \| X\|_{F}^{2} = \frac{\partial}{\partial X}\textrm{Tr}(XX^H) = 2 X$$ If, in general, the norm $\| \cdot \|_{p,q}$ is given by $$ \| X \|_{p,q} =  \Bigg( \sum_{j=1}^{n} \Bigg( \sum_{i=1}^{m} |x_{ij}|^{p} \Bigg)^{\frac{q}{p}}  \Bigg)^{\frac{1}{q}} $$ how would you go about finding $\frac{\partial}{\partial X}\| X\|_{p,q} $ ?","['normed-spaces', 'matrices', 'matrix-calculus', 'matrix-norms', 'derivatives']"
3227884,Matrix derivative and product rule,"Let $A$ be a square matrix with non-negative elements. Let $n$ be a positive integer. How to evaluate the following for all possible $n$ ? $$f_{n}(A, i, j) = \frac{\partial }{\partial A_{ij}}\left(\vec{1}A^{n}\vec{1}^{\intercal}\right)$$ where $\vec{1}$ is a row vector and $\vec{1}^{\intercal}$ is transpose of $\vec{1}$ . Attempt to solve I thought $$f_{3}(A, i, j) =\vec{1}(BAA + ABA +AAB)\vec{1}^{\intercal}$$ where $$B_{i'j'} = \begin{cases} 1, & i = i', j=j' \\ 0, &\text{otherwise}\end{cases}$$ But the problem is that the expression is always non-negative. Unless the function is monotonic, I would not expect the first derivative to always have the same sign. What is the correct answer?","['matrices', 'matrix-calculus', 'derivatives']"
3227892,How to find the radius of this smaller circle?,"The question says, ""A circle is inscribed in a triangle whose sides are $40$ cm, $40$ cm and $48$ cm respectively. A smaller circle is touching two equal sides of the triangle and the first circle. Find the radius of smaller circle."" I can find the radius of the inscribed circle fairly easily by assuming the radius as $r$ , and using the Heron's Formula: $$\frac{1}{2} * r * (40 + 40 + 48) = \sqrt{\left(\frac{40 + 40 + 48}{2}\right) \left(\frac{40 + 40 + 48}{2}-40\right)\left(\frac{40 + 40 + 48}{2}-40\right)\left(\frac{40 + 40 + 48}{2}-48\right)}$$ Which evaluates to give : $r = 12$ , so The inscribed circle has a radius of $12$ cm. But The smaller circle is only in touch with the other circle, and I can't get anything to work like constructions or etc. Trigonometry doesn't work too (maybe I'm doing it wrong, I'm a Grade 11 student anyway). The most I can do is to find the area which is not occupied by the circle, but occupied by the triangle simply by subtracting the areas of both. [Which is $768 - \pi*(12)^2$ cm]. And this question was on a small scholarship paper I've attended, and it also had some more questions like it (I came to solve most of them).",['geometry']
3228027,A geometric interpretation of the conditional Variance,"We know that we can see conditional expectation as a projection. To be more specific, let be $<X,Y> = E[XY]$ the usual inner product in $L^{2}$ . We know that: $$E(Y|X) = \hbox{argmin}_{Z \in \mathcal{F}} E[(Y - Z)^2]$$ or $$E(Y|X) = \hbox{argmin}_{Z \in \mathcal{F}} ||Y - Z||^2$$ where $\mathcal{F}$ is simply the sigma algebra generated by $X$ , i.e., $\mathcal{F} = \sigma(X)$ . I would like to know if there is any geometric interpretation for the conditional variance $V(Y|X)$ . I do not know I'm right in the following reasoning: if $U:= Y -E(Y|X) $ , then $V(Y|X)= E(U^2|X)$ . In this way, we can say that $V(Y|X)$ is the projection of the random variable $U^2$ in $\mathcal{F}$ . However, if my reasoning is right, I am not satisfied. Perhaps there is another interpretation more interesting.",['probability-theory']
3228051,Equivalency of all norms on a finite dimensional vector space: compactness theorems vs. the open mapping theorem,"Going through my functional analysis course notes, I feel like there are two different proofs for the following theorem. In $\mathbb{R}^n$ (or $\mathbb{C}^n$ ), any two norms are equivalent. One uses the compactness-related extreme value theorem (i.e., a continuous function on compact set must achieve its maximum and minimum values), while the other uses the open mapping theorem (i.e, for every continuous linear mapping $T$ from a Banach space $X$ onto another Banach space $Y$ , and every $U \in X$ open, $T(U)$ is open). These two theorems use different hypothesis and are not equivalent. Therefore, I am suspicious that I am doing something wrong. My questions is whether both these proofs are correct, or if I am doing something wrong here . Common steps of both proofs Define (recall) the $\|.\|_\text{sup}$ norm as $\|x\| = \sup_{i} |x_i|$ . (*) Show that for any norm $\|.\|_b$ on $\mathbb{R}^n$ , there exist an $M_b > 0$ , such that for all $x \in \mathbb{R}^n$ , $\|x\|_b \leq M_b \|x\|_\text{sup}$ (see for example here on how to find $M_b$ ). Proof with extreme value theorem From (*) we deduce that any norm $\|x\|_b$ is continuous w.r.t the $\|x\|_\text{sup}$ norm. (+) Use the fact that the unit sphere (of the sup norm) is compact in $\mathbb R^n$ , (*), and the extreme value theorem to deduce that $\|x\|_b$ achieves a minimum $m_b$ on the unit sphere (of the sup norm). In other words, there exists $m_b > 0$ such that $\|x\|_b \geq m_b \|x\|_\text{sup}$ for all $x \in \mathbb R^n$ . Combining (+) and (*), we get that any norm $\|.\|_b$ and $\|.\|_\text{sup}$ are equivalent $\blacksquare$ Proof with the open mapping theorem This is the proof that I am not sure about. From the open mapping theorem, one can prove that (see for example here for a proof): Let $\|.\|_1$ and $\|.\|_2$ be norms on a Banach space $X$ , such that $\|x\|_1 \leq\|x\|_2$ . Then, the norms are equivalent. Now combine this with (*) with the fact that $\mathbb R^n$ is complete (Banach), and you get that any norm in $\mathbb{R}^n$ is equivalent to the $\|.\|_\text{sup}$ norm $\blacksquare$","['functional-analysis', 'real-analysis']"
3228053,Inflection point at Vertical tangent?,"In Wikipedia and many other places, it is stated that $f''(a)=0$ is a necessary condition for a function to have an inflection point at $x=a$ . I was wondering, if a function had a vertical tangent, would an inflection point also exist there? For example, let $f(x)=x^{1/3}(x-1)$ , $f'(x)=\frac 4 3 x^{1/3} - \frac 1 3 x^{-2/3} $ which has a root only at $x=1/4$ and for $x=0$ , it has a vertical tangent. $f''(x) = \frac 4 9 x^{-2/3} + \frac 2 9 x^{-5/3}$ which has a root only at $x=-1/2$ . By nth derivative test or by observing that $f''(x)$ changes sign in the neighborhood of $-1/2$ we conclude that $x=-1/2$ is an Inflection point. But on drawing the graph of $f(x)$ , we observe that even $x=0$ is an inflection point, where the nature of the function changes from concave down to concave up. So is my assertion true that it is not necessary for the double derivative of a function to be $0$ , to have an inflection point, provided a vertical tangent exists at that point?","['convex-analysis', 'maxima-minima', 'calculus', 'functions', 'derivatives']"
3228068,Estimating mean from a biased sample,"Imagine that somebody had chosen $N$ numbers from a normal distribution with mean $\mu$ and variance $1$ ( $\mu$ is unknown to you) and only showed you all $n \le N$ numbers which are greater that $\mu$ . Is there a way to find an unbiased estimator of $\mu$ based on the given sample? This does not come from any textbook, I've came up with this problem recently (maybe it's even known but I haven't found anything), so feel free to play with the conditions (for example you may assume that $N$ is known or not or even assume an unknown variance). I found it interesting because in some situations you are presented with only one side of the coin and you somehow have to make a judgement out of the evidence you have. There are obviously some easy estimates (as for example a minimum which seems to be a $MLE$ ) but they are biased. Also I understand that since the mean of folded normal distribution has such a terribly looking formula the estimator might not be that pretty. And also what about other distributions? For example for uniform on $[0,\theta]$ the variable greater than the mean will have expectation $\frac{3}{4}\theta$ so the unbiased estimator will be $\hat{\theta}=\frac{4}{3}\overline{X}$ (or $\frac{2}{3}\overline{X}$ as an estimator for the mean).","['statistics', 'parameter-estimation', 'normal-distribution']"
3228089,"If $f_n \rightarrow 0$ with $f_n ' \rightarrow g$, then is $g=0$ in some sense?","Suppose $f_n :[a,b] \rightarrow \mathbb{R}$ are differentiable functions (need not be $C^1$ ) with $f_n \rightarrow 0$ , $f_n ' \rightarrow g$ pointwise.  Can we say that $g=0$ in some sense? (Say, a.e.) In particular, is it possible for $g$ to equal $1$ everywhere? cf) Interchanging pointwise limit and derivative of a sequence of C1 functions This question deals with the $C^1$ case.","['calculus', 'real-analysis']"
3228101,Taylor series leads to two different functions - why?,"Suppose, I want to find a function such that its Taylor series expansion is $$f(x) = \sum_{n=0}^{\infty}\frac{x^{n+1}}{(n+1)a^n}$$ I could start with $$\frac{1}{1-x}=\sum_{n=0}^{\infty}x^n$$ Integrate it, substitute $x\rightarrow  \frac{x}{a}$ , multiply by $a$ and get $$F(x) = -\ln|x-1| = \sum_{n=0}^{\infty}\frac{x^{n+1}}{n+1}$$ $$a F\left(\frac{x}{a}\right) = -a \ln\left|\frac{x}{a}-1\right| = \sum_{n=0}^{\infty}\frac{x^{n+1}}{(n+1)a^n}$$ On the other hand, I could start with subtituting $x \rightarrow \frac{x}{a}$ before integration to get $$\frac{a}{a-x} = \sum_{n=0}^{\infty}\frac{x^n}{a^n}$$ and then integrate it to get $$-a\ln|x-a| = \sum_{n=0}^{\infty}\frac{x^{n+1}}{(n+1)a^n}$$ As you can see, arguments of $\ln$ are not equal. Where did it go wrong?","['calculus', 'taylor-expansion']"
3228188,What online graphing tools handle complex numbers well?,"What online graphing tools handle complex numbers well? Desmos is generally excellent by breaking functions down into their real and imaginary parts and plotting on the Euclidean plane. For example it can relatively easily graph: $f:\Bbb N\to\Bbb C$ $f(x)=x\cdot\exp{(2\pi i\log_{\frac23}x)}$ as shown here , and it displays and prints nicely. But I want to plot $f(x)=x\cdot\exp{(2\pi i\log_{\frac{-1}3}x)}$ which is a little more tricky as it requires the imaginary unit within the exponent because $\log(-1/3)=i\pi-\log(3)$ Is there a way with desmos, or an easy-to-use alternative tool?","['functions', 'graphing-functions', 'roots-of-unity', 'complex-numbers']"
3228193,"Prove $f(x,y)=c=\ln|x|-2\ln|y|-\dfrac{1}{x^2y^2}$ is a solution for ODE $(x^2y^3+2y)dx+(2x-2x^3y^2)dy=0$","I have an ODE $(x^2y^3+2y)dx+(2x-2x^3y^2)dy=0$ And I know how to solve this ODE. So, I claimed that it's a Non-Exact PDE, then I change it to Exact PDE for finding the solution. And the solution of the ODE is $f(x,y)=c=\ln|x|-2\ln|y|-\dfrac{1}{x^2y^2}$ And I'm pretty sure that the solution is right because I've already checked it on Wolfram Alpha. But how I can prove this solution is the solution of the ODE? If the answer is to change it to $\dfrac{dy}{dx}$ yeah I've already tried it but it seems like didn't match with the solution.
Please help me to prove this solution. Thanks.
And sorry if I have some mistakes.",['ordinary-differential-equations']
3228263,"Showing that $f(x)=x^3-3x+1$ has at least two zeros in the interval $[0,2]$","I was given this task by my professor: Let $f:\mathbb{R}\rightarrow\mathbb{R}$ be defined by $f(x)=x^3-3x+1$ Show that $f$ has at least two zeros in the interval $I := [0,2]$ . My answer is: Since $f:\mathbb{R}\rightarrow\mathbb{R}$ and $f$ is an polynomial it follows that f is continuous $$f(0) = 1; f(0,5)=-0,375$$ by the intermediate value theorem since f(0,5) < 0 < f(0) $\Rightarrow \exists x_1\in[0;0,5]: f(x_1) = 0$ and since $[0;0,5] \subset [0,2]$ it follows that $f$ has at least one zero in the intervall $I:= [0,2]$ $$f(1) = -1; f(2) = 3$$ by the intermediate value theorem since f(1) < 0 < f(2) $\Rightarrow \exists x_2\in[1,2]: f(x_2) = 0$ and since $[1,2] \subset [0,2]$ it follows that $f$ has at least tow zeros in the intervall $I:= [0,2]$ q.e.d Is this formally and content correct?","['proof-verification', 'roots', 'real-analysis', 'functions', 'polynomials']"
