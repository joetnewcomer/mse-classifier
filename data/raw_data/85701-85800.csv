question_id,title,body,tags
1131480,Existence of a holomorphic connection implies existence of a flat connection,"Let $E$ be a holomorphic vector bundle on a complex manifold $X$, and let $D: E \to E \otimes \Omega_X$ be a holomorphic connection on $E$ i.e.
$$
D(fs) = s\otimes \partial(f)+ fD(s),
$$
for any local holomorphic function $f$ and local section $s$. Locally such conections look like 
$$
D = \partial + A,
$$
where $A$ is a holomorphic section of $\operatorname{End}(E)\otimes \Omega_X$. If $D$ is a holomorphic connection on $E$ then $D+\bar{\partial}$ is an ""ordinary"" connection on $E$. How can one show that if $E$ admits a holomorphic connection then it admits a flat connection? In other words there is $B \in\operatorname{End}(E)\otimes \Omega_X$ s.t.
$$
(\bar{\partial} +D+B)^2=0.
$$","['vector-bundles', 'complex-geometry', 'differential-geometry', 'holomorphic-bundles', 'connections']"
1131526,Problem with proof of multivariable limit,"I've got a problem with this limit:
${\lim_{(x,y) \to (0,0)} \frac{ x^{5} + 2y^{3} }{ x^{4} + y^{2} }}$
Can you help me, please? I think it equals 0, but I don't know how to prove it.","['multivariable-calculus', 'limits']"
1131618,Is a bounded operator with finite trace trace class?,"Let $\mathcal{H}$ be a separable Hilbert space, $A\in\mathcal{B}(\mathcal{H})$ a bounded linear Operator and assume we have an orthonormal basis $(x_n)_{n=1}^\infty$. If $A$ is trace-class, then $\sum_{n\in\mathbb{N}}\langle x_n,Ax_n\rangle$ is finite. But what about the converse , i.e. if we know that $$\sum_{n\in\mathbb{N}}\langle x_n,Ax_n\rangle<\infty,$$ can we deduce that $A$ is trace class? If not, what can be said if $A$ is known to be positive, i.e. $A\ge 0$?","['trace', 'hilbert-spaces', 'functional-analysis']"
1131621,Show that $E[X_t^2]<\infty$,"Show that $E[X_t^2]<\infty$, where
$$
X_t=e^{3W_t-\frac{3t}{2}}-3e^{W_t-\frac{t}{2}}\underbrace{\int_0^te^{2W_s-s}ds}_{A_t},\quad. t\geq0,
$$
where $t$ is a fixed number and $W_t$ is Brownian motion.
What I did was: By Itō's formula: $X_t=\int_0^t\left(3e^{3W_s-\frac{3s}{2}}-3e^{W_s-\frac{s}{2}}A_s\right)dW_s$ Itō isometry: \begin{align*}
E[X_t^2]&=E\left[\left(\int_0^t\left(3e^{3W_s-\frac{3s}{2}}-3e^{W_s-\frac{s}{2}}A_s\right)dW_s\right)^2\right]\\[1.ex]
&=E\left[\int_0^t\left(3e^{3W_s-\frac{3s}{2}}-3e^{W_s-\frac{s}{2}}A_s\right)^2ds\right]\\[1.ex]
&= ...\\[1.ex]
&= \int_0^t\left(9e^{-3s}\underbrace{E\left[e^{6W_s}\right]}_{=e^{18s}}-18e^{-2s}\underbrace{E\left[e^{4W_s}A_s\right]}_{(1)}+9e^{-s}\underbrace{E\left[e^{2W_s}A_s^2\right]}_{(2)}\right)ds
\end{align*} My main problem is that I don't know how to make an estimation of $(1)$ and $(2)$. I've tried using Cauchy-Schwarz, but it does not help me. Any help would be appreciated. Thanks!","['stochastic-processes', 'stochastic-integrals', 'stochastic-calculus', 'brownian-motion', 'probability']"
1131642,Isometries preserving distance but not angles,"In Euclidean geometry, every distance-preserving map (isometry) also preserves angles between two vectors. Is there any example of a non-Euclidean geometry in which an isometry need not preserve the angle between two vectors?","['geometry', 'inner-products', 'isometry']"
1131673,"How can a field have a finite characteristic $p$, given that a field has no zero divisors?",The characteristic of a field is defined to be the smallest positive integer $p$ such that $$p \cdot 1 = 0.$$ But I have learned that field has no zero divisors. How is this possible?,"['positive-characteristic', 'abstract-algebra', 'field-theory']"
1131722,Determining whether a given set can be an image of continuous function,"The problem asks as, whether there exists a continuous function $f: \Bbb{R} \rightarrow \Bbb{R}$ an image of which is set: $[0,1)$ $(0,1]\cup[2,3]$ $\Bbb{Q}$ So - for $[0,1)$ you can see that you can create function $f$ for which $\lim_{x\rightarrow +\infty} f(x) = 1$, and from $-\infty$ to some finite number it is constant $f(x)=0$ and than you can make a ""smooth"", parabolic transition between $0$ and $1$. For the second and third set you kinda see that it's not possible, as there is a gap between every rational number and between $1$ and $2$. But how to prove such things formally?","['algebra-precalculus', 'continuity', 'functions', 'limits']"
1131742,Derivatives of a Dirichlet polynomial,"I am new here, so I don't know how this works exactly. If I do something wrong, please let me know. I'd like help to solve a problem I am studying: Let $A$ be finite set of positive integers and denote by $|A|$ the number of elements in $A$. Let $$D(s)=\sum_{n \in A}a(n)n^{-s}$$ be a Dirichlet polynomial with coefficients supported in $A$, e supose that $D(s)$ is not constant. For each complex number $w$, define $$M(w)=|\{m \geq 0; D^{(m)}(w)=0\}|,$$ i.e, $M(w)$ is the number of derivatives of D such that $D^{(k)}(w)=0$. Show that $M(w)<|A| \forall w \in \mathbb{C}$ . I know that $D^{(k)}(w)=(-1)^k\sum_{n \in A}a(n)\log^k(n)n^{-w}$. But I don't know how to find the zeroes of these derivatives and how to estimate then... 
Do someone has any idea of how to start this?","['dirichlet-series', 'analytic-number-theory', 'complex-numbers', 'complex-analysis', 'derivatives']"
1131763,Prove that if $\forall_{x\in\Bbb{R}} f(x)=f(x+1)$ and $f$ is continuous then there are infinitely many $c$ such that $f(c+\pi)=f(c)$,"We have 3 assumptions about $f$: $f: \Bbb{R} \rightarrow \Bbb{R}$ $f$ is continuous $\forall_{x\in\Bbb{R}} f(x)=f(x+1)$ The problem asks us to prove 2 things: That $f$ reaches its supremum and infimum and also there exist infinitely many $c\in\Bbb{R}$ such that $f(\pi+c)=f(c)$. So the first thing can be proven (I think) discovering that $f([0,1]) = f(\Bbb{R})$ (because the function is periodic) so supremum and infinimum is in $f([0,1])$ and by the extreme value theorem it can be reached. As for the second problem I can't see why it should be true. That would mean that there exist $x\in\Bbb{R}$ such that $f(\pi +x+1) = f(x+1) = f(x)$. Wouldn't that mean that function must have 2 periods - $1$ and $\pi$? But this $\pi$ makes no sense then. Am I understanding this correctly?","['calculus', 'continuity', 'functions', 'limits']"
1131769,$ \int_1^2\int_1^2 \int_1^2 \int_1^2 \frac{x_1+x_2+x_3-x_4}{x_1+x_2+x_3+x_4}dx_1dx_2dx_3dx_4 $,Evaluate $$I=  \int_1^2\int_1^2 \int_1^2 \int_1^2  \frac{x_1+x_2+x_3-x_4}{x_1+x_2+x_3+x_4}dx_1dx_2dx_3dx_4$$ Answer Options: $1$ $\frac{1}{2}$ $\frac{1}{3}$ $\frac{1}{4}$ I need some suggestion here. I tried to evaluate one by one but it becomes messy. I think there some trick involved here.,"['definite-integrals', 'multivariable-calculus', 'calculus', 'integration']"
1131788,What is order in $n-$tuple?,"$n-$tuple is a sequence (or ordered list) of n elements, where n is a non-negative integer. By sequence i understand a pattern either increasing or decreasing. But if  $(2, 7, 4, 1, 7)$ is an example of $5-$tuple, then where is the order here ? It is neither increasing nor decreasing.","['linear-algebra', 'sequences-and-series', 'algebra-precalculus']"
1131793,"$\gcd(|G|, |\text{Aut}(G)|)=1$ means G is abelian?","Prove the following assuming that $G$ is finite group with $\gcd(|G|, |\text{Aut}(G)|)=1$ . a) G is abelian (done). b) Every Sylow subgroup of $G$ is cyclic of prime order. Since G is abelian than every Sylow subgroup is unique, but does it mean cyclic? Any suggestion?","['abelian-groups', 'abstract-algebra', 'sylow-theory', 'finite-groups', 'group-theory']"
1131796,Proof that inverse of a matrix is unique [duplicate],"This question already has answers here : Proof that the inverse of a square matrix is unique (3 answers) Closed 9 years ago . If B and C are both inverses of the matrix A,then B=C . Can't i prove it in following way ? Proof: AB=BA=I and AC=CA=I ,then BA=CA=I By postmultiplication $\Rightarrow (BA)(A^{-1})=(CA)(A^{-1})=(I)(A^{-1})\Rightarrow B=C=A^{-1}$, or by premultiplication $AB=AC=I\Rightarrow (A^{-1})(AB)=(A^{-1})(AC)=(A^{-1})(I)\Rightarrow B=C=A^{-1}$.","['matrices', 'linear-algebra', 'inverse']"
1131843,Proof of Hall's subgroup Theorem,"So I'm working through Hall's Theorem for Solvable groups and there is one part of it which I cannot seem to prove. I am following through Isaac's book on Finite group Theory for reference. Currently I can prove Hall-E (existence of a Hall-$\pi$-subgroup), Hall-C (any two such are conjugate) however the proof of Hall-D eludes me. For those without the book it is stated as;
 Let $U \subseteq G$ be a $\pi$ subgroup, where $\pi$ is a set of primes and $G$ is a finite solvable group. Then $U$ is contained in some Hall-$\pi$-subgroup of $G$.","['finite-groups', 'group-theory']"
1131854,Number of digits $d$ in $d^k$,"The title says it all really. For example, how many occurences of $6$ are there in $6^k$? It starts $6, 36, 216, \dots$ so $1, 1, 1,\dots$ The question can now be generalized into any digit or group of digits.",['number-theory']
1131859,"If $(a_n)$ is such that $\sum_{n=1}^\infty a_nb_n$ converges for every $b\in\ell_2$, then $a\in\ell_2$","Please help me with this question. I've been thinking about it for almost two days.
Let $a_n$ a real series that have the following property:
for every series $b_n$ in $l_2$: $\sum_{n=1}^\infty a_nb_n$ converges.
prove that $a_n$ in $l_2$.","['convergence-divergence', 'sequences-and-series', 'functional-analysis', 'lp-spaces']"
1131863,Differentiation on matrix algebra,"Describe all differentiation on matrix algebra $M_n(F)$ over an associative commutative ring with identity $F$ Well as I understand that task I have Leibniz notation which says that every differentiation must satisfy $D(F,G) = F*D(G)+D(F)*G$. Also we have differentiation that looks like $D_A(B) = A*B-B*A$. So to describe I should to find how matrix A looks like. But how to do that?",['abstract-algebra']
1131889,Blow-up and base change,Consider a complex smooth (projective) surface $X$ and a blow-up $\epsilon:S\longrightarrow X$ at a point $x\in X$. Let $\sigma\in\text{Aut}(\mathbb C)$ be a field automorphism and moreover let $$\varphi:=\epsilon\times_{\text{Spec}\mathbb C}\text{id}_{\text{Spec}\mathbb C}:S\times_{\text{Spec}\mathbb C}\text{Spec}\mathbb C\longrightarrow X\times_{\text{Spec}\mathbb C}\text{Spec}\mathbb C$$ be the morphism induced by the base change through the automorphism $\sigma$. Is the morphism $\varphi$ again a blow-up? I think that the answer is yes since the base change induces many isomorphisms of schemes. What do you think? Many thanks in advance.,"['projective-schemes', 'algebraic-geometry', 'schemes', 'surfaces']"
1131947,"Find the value of k, (if any), for which the system below has unique, infinite or no solution. [duplicate]","This question already has answers here : System of Linear Equations - how many solutions? (3 answers) Closed 9 years ago . The system of equations are: $\begin{cases}x+y+kz = 1\\x+ky+z=1\\kx+y+z=1\\
\end{cases}$ I am looking to finding values of $k$, for which this system has either no solutions, infinite many solutions or a unique solution (if any). I've had a look around the web for some help, and know that this question has been asked, but in a way that I have not yet learnt (something to do with determinants I think). However, I have only been working with reducing the matrix to REF/RREF and thus I'm trying to find rows, such as $( 0 \ 0 \ 0 \mid 2)$ and $( 0 \ 0 \ 0 \mid 0)$ etc to show if we have no solutions or infinite many solutions, for instance. So far, I've got the following: $\left[\begin{array}{ccc|c}1&1&k&1\\1&k&1&1\\k&1&1&1\end{array}\right]$ Then, $R_2$$\mapsto$$R_2-R_1$ $\left[\begin{array}{ccc|c}1&1&k&1\\0&k-1&1-k&0\\k&1&1&1\end{array}\right]$ Then, $R_2$ $\leftrightarrow$ $R_3$ $\left[\begin{array}{ccc|c}1&1&k&1\\k&1&1&1\\0&k-1&1-k&0\end{array}\right]$ This is where I got stuck, and I'm not sure how to continue. Thank you in advance, and I'm sorry if this question has been asked and solved in the same way as presented above. Cheers.","['matrices', 'linear-algebra', 'systems-of-equations']"
1131956,Image of the union and intersection of sets.,"Let $f:X\to Y$ be a function, and let $\{S_{i}:i\in I\}$ be a family of subsets of $X$. Then, $$f\left(\bigcup_{i
\in I}S_i\right) = \bigcup_{i
\in I}f(S_i).$$ The case where $f(A\cup B)= f(A)\cup f(B)$ is trivial and I've proved this many times in other classes. However, I believe that the problem I am running into is with notation. That is, I don't understand what the set $I$ is. Will my proof method be just the same? Also, I would like a little help on one more problem. If $S_{1}$ and $S_{2}$ are subsets of a set $X$, and if $f:X\to Y$ is an injection, then $f(S_{1}\cap S_{2})=f(S_{1})\cap f(S_2)$. Now, I know how to prove $f(S_{1}\cap S_{2})\subseteq f(S_{1})\cap f(S_2)$ if our function is not injective, and I know counterexamples of why it isn't equal our function isn't injective. Unfortunately, I am not sure how to use the fact that our function is injective to prove $f(S_{1})\cap f(S_2) \subseteq f(S_{1}\cap S_{2})$. Any help would be much appreciated. Thank you very much! Note: These questions are coming from Rotman's Intro to Abstract Algebra Chapter 2.","['elementary-set-theory', 'functions']"
1131957,Do absolute convergence of $a_n$ implies convergence of $K_n=\frac{1}{\ln(n^2+1)}\sum_{k=1}^{+\infty}a_k\frac{3k^3-2k}{7-k^3}\sin k$?,The problem asks us to decide whether the following statement is true: Let $\{a_n\}_{n\geq1}$ be any absolutely convergent sequence. Does that imply that the sequence: $$K_n=\frac{1}{\ln(n^2+1)}\sum_{k=1}^{n}a_k\frac{3k^3-2k}{7-k^3}\sin k$$ is convergent? The term $\frac{1}{\ln(n^2+1)}$ goes to $0$ so if we showed that the series is convergent we would finish this problem. The thing is it doesn't look like a convergent series - and even if it is I have no idea how to show it - this $\sin$ function inside means I can't use any convergence test (at least I think so). So how to reason about $K_n$? UPDATE: by absolute convergence od $a_n$ I of course mean that $\sum |a_n|$ is convergent,"['sequences-and-series', 'calculus', 'limits']"
1131977,A bit challenging integration. (at least for me its challenging),"Hello everybody I am trying to solve this integral. I show you how far I 've gone.
$\displaystyle\int^{\infty}_{-\infty} \frac {e^{-i\vec{k}.\vec{x}}e^{-ik^{\circ}x_{\circ}}\delta(k^{\circ})}{k^2-\mu^2}d^2kdk^{\circ}$.
Taking to plane polar coordinates $=\displaystyle\int^{\infty}_{0}\displaystyle\int^{2\pi}_{0}\displaystyle\int^{\infty}_{-\infty}\frac {e^{-i|\vec{k}| |\vec{x}|\cos\theta}e^{-ik^{\circ}x_{\circ}}\delta(k^{\circ})}{k^{\circ 2} -|\vec{k}|^2-\mu^2}|\vec{k}|dkd\theta dk^{\circ}$. Where 
$k^2=k^{\circ 2} -|\vec{k}|^2 $. Now
solving delta function we get. $=\displaystyle\int^{\infty}_{0}\displaystyle\int^{2\pi}_{0}\frac {e^{-i|\vec{k}| |\vec{x}|\cos\theta}}{-|\vec{k}|^2-\mu^2}|\vec{k}|dkd\theta$. Now bring in Bessel function $=-\sum_{n=0}^\infty  (-1)^n \frac{2\pi}{n!n!}\displaystyle\int^{\infty}_{0}\left(\frac{|\vec{k}||\vec{x}|}{2}\right)^{2n}\frac {1}{|\vec{k}|^2+\mu^2}|\vec{k}|dk\\$. Nowwwww I don't know what to do.........","['mathematical-physics', 'calculus', 'integration', 'discrete-mathematics']"
1131987,Trace inequality involving $A^TA-AA^T$,"Let $A\in\mathbb{R}^{n\times n}$ and $B=(A^TA-AA^T)/2$. Furthermore, let
$$
f(A)=\frac{1}{n}\text{Tr}(A),\qquad g(A)=\sqrt{f(A^TA)-(f(A))^2}
$$
where $\text{Tr}(A)$ denotes the trace of the matrix $A$. After numerous experiments I think that the following bound holds:
$$
g(B)\leq (g(A))^2
$$ How to prove/disprove this statements ? Some useful properties that I have found: $g(A)\geq 0$ for all $A$, follows directly from Cauchy-Schwarz inequality. $g(sI+A)=g(A)$, for all $s\in\mathbb{R}$. EDIT: I see now that I must have misread my notes, and in fact, the inequality I was after is $C=(A-A^T)/2$ and
$$
g(C^2)\leq(g(A))^2
$$
Sorry for the inconviencience.","['trace', 'matrices', 'linear-algebra', 'inequality']"
1131993,Are the odds one in a million? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question This is a from a card game call Magic the Gathering And my question is regarding this video during a tournament match (best of 5). One in a million . You dont need watch the video I will explain the scenario here, but is very exciting. In this match, player Gabriel Nassif is at 9 life. And player Patrick Chappin cast 5x copies of Ignite Memories targeting Nassif Ignite memories: select a card a random from player hand and deal damage equal to that card convert mana cost or CC for short. Nassif have 3 cards in hand at that moment. Ignite Memories CC = 5 Grapeshot CC = 2 Rite of Flames CC = 1 Dont be confused because the 5x Ignite Memories are from Chappin. But Nassif also have one Ignite Memories in hand. In Magic this is call a mirror match because players are using similar strategies So if a single Ignite Memories is select from Nassif hand, Nassif will loss 1x 5 CC + 4 * {1 CC or 2CC} >= 9 life If select 5x Grapeshot mean 10 life, also lose. Max damage possible is selecting 5x the Ignite of Memories for 5x 5CC = 25 life loss Min damage possible is selecting 5x the Rite of Flames for 5x 1CC = 5 life loss Again Nassing beign at 9 and 5x copies of Ignite Memories, You loss if your life reach 0 or lower. What are the odd of survive?. At the end Nassif survive and won that game at 1 life but finish lossing the match in the next game. I only could add 2 link so if anyone want check for the other 2 cards: gatherer.wizards.com/Pages/Card/Details.aspx?name=GRAPESHOT gatherer.wizards.com/Pages/Card/Details.aspx?name=rite+of+flame I will try to add some context. As far I can go the total number of outcomes is $3^5$ Now how count wich of those outcomes cause the player to lose can't figure it out. Also give the motivation of because this is interesting, for a game planning the possible outcomes afect how you make the strategy.","['puzzle', 'recreational-mathematics', 'probability']"
1131996,Minimum value of trigonometry function,"How can I get the minimum value of function
$$f(x) = (2 + \sin x)(5 - \sin x)$$ I have used the differential ways but the answer was not match with the key answer. By the way the key answer is $6$.","['trigonometry', 'functions']"
1132001,Generalizing the Fibonacci identity $F_{2n}=-F_{n-1}^2+F_{n+1}^2$,"Using an integer relations algorithm, we get, $$F_{2n}=-F_{n-1}^2+F_{n+1}^2$$ $$6F_{4n}= -F_{n-2}^4-3F_{n-1}^4+3F_{n+1}^4+F_{n+2}^4$$ The pattern of the subscripts is clear. Expressing the coefficients as a number triangle and including higher powers, $$F_{2n} = -1,\,1$$ $$6F_{4n} = -1,\,\color{brown}{-3},\,3,\,1$$ $$120F_{6n} = -1,\,\color{brown}{-4},\,20,\,-20,\,4,\,1$$ $$21840F_{8n} = -1,\,\color{brown}{-14},\,91,\,364,\,-364,\,-91,\,14,\,1$$ $$24504480F_{10n} = -1,\,\color{brown}{-33},\, 748,\, 3927,\, -17017,\,17017, \dots\quad\quad\quad\quad$$ Question: Anybody knows the formula for the coefficients? P.S. One pattern easy to spot is $F_n\,L_{n+1}=0,3,4,14,33,\dots$ See this related post for the slightly different form for odd powers (it contains both the $F_n$ and $F_{pn}$ terms), and Ron Knott's article on fibonomials .","['fibonacci-numbers', 'recurrence-relations', 'sequences-and-series', 'number-theory']"
1132015,"PDF of Random Variable $\sin\alpha \cdot \cos\beta$ with $\alpha,\beta$ uniform","As part of a bigger problem, I want to compute the probability density $f_Z(z)$ of 
$$Z = \sin\alpha \cdot \cos\beta$$ 
where $\alpha, \beta$ are random variables, independently and uniformly distributed over $[0,\pi/2]$. Looks quite simple, but I have a really hard time. What I tried is writing it like $Z = X \cdot Y$ and compute $f_X(x)$, $f_Y(y)$ to then use the product distribution formula ( http://en.wikipedia.org/wiki/Product_distribution ). The calculation went: $$x = g(\alpha) = \sin\alpha, \ \ \ g^{-1}(x) = \arcsin x$$
$$\frac{d g^{-1}(x)}{dx} = \frac{1}{\sqrt{1-x^2}}$$
$$f_\alpha(g^{-1}(x)) = \frac{2}{\pi} \ \ \text{for} \ \ 0\leq x \leq 1$$
$$f_X(x) = f_\alpha(g^{-1}(x)) \cdot \left| \frac{d g^{-1}(x)}{dx} \right| = \frac{2}{\pi} \frac{1}{\sqrt{1-x^2}} \ \ \text{for} \ \ 0\leq x \leq 1$$ Similarly,
$$f_Y(y) = \frac{2}{\pi} \frac{1}{\sqrt{1-y^2}} \ \ \text{for} \ \ 0\leq y \leq 1$$ and the product distribution then gives: \begin{align*}
f_Z(z) 
&= \int_\mathbb{R} f_X(x) f_Y(z/x) \frac{1}{|x|}dx\\
&= \left(\frac{2}{\pi}\right)^2 \cdot \int_z^1 \frac{dx}{\sqrt{(1-x^2)(x^2-z^2)}}
\end{align*} While that integral doesn't look too hard (just like the initial problem), even Mathematica fails to give me any answer. Is this problem really that hard or am I missing something?","['trigonometry', 'random-variables']"
1132069,Expected interarrival time,"Given that there are 40 arrival times in 3 hours which are uniformly distributed on $(0,3)$, what is the expected time till the tenth arrival? My book says that the answer should be as follows: The expected interarrival time is $\frac{3}{41}$, so the time till the tenth arrival has an expected value of $\frac{30}{41}$. This might be a very basic question, but why is the expected interarrival time $\frac{3}{41}$, and not $\frac{3}{40}$?","['algebra-precalculus', 'probability']"
1132131,connected and compact subset of $\mathbb{C}$ is either a singleton or has uncountable boundary,"Let's say that $A\subseteq\mathbb{C}$ is connected and compact but not a singleton.  I want to conclude that $\partial A$ is uncountable.  Can anyone help me find a reference to cite? I can see how to prove this in a routine way, by picking distinct elements $a$ and $b$ in $A$, which we may assume without loss of generality have distinct real parts, and then finding an element in $\partial A$ with any real part strictly between the real parts of $a$ and $b$.  However, I would much rather just give a reference, since the argument is uninteresting.","['general-topology', 'reference-request', 'complex-analysis']"
1132147,Exponential Generating Function of rooted minimal directed acyclic graphs,"I am trying to find the exponential generating function 
of directed minimal acyclic graphs (which I now call dag ), 
where every non-leaf node has two outgoing edges. Context: A simple tree compression algorithm consists of saving repeated subtrees only once. 
Further occurrences of repeated trees are simply linked to the first occurrence. 
This way one gets a unique minimal directed acyclic graph, and since we started with a tree it's also rooted. 
For simplicity I would like to treat binary trees, hence two outgoing edges per non-leaf node. A natural question is how big dags of binary trees of size $n$ are, 
and the question has been answered here (the paper is Analytic Variations on the Common Subexpression Problem , by Flajolet et al). I would like to ask a different question, namely how many different dags of size $n$ there are, or equivalently, how many rooted plane binary trees have a dag of size $n$? As an example, for $n=3$, we have three such trees, namely 
$a(a(a,a),a(a,a))$, $a(a(a,a),a)$ and $a(a,a(a,a))$. For $n=4$ there are $15$ trees, for $n=5$ there are $111$. A promising sequence from OEIS is A001063 , but I can neither make sense of the differential equation mentioned there, nor do I have a combinatorial explanation for the formula there that calculates $a_{n+1}$, given $a_1,\dots,a_n$:
$$
a_{n+1} = \sum_{k=0..n} \frac{n!}{k!} \cdot \binom{n-1}{k-1}\cdot a_k
$$ If requested, I could add where I got stuck (I mostly tried to make sense of the formula), but I think my post is already too long. Addendum . This question has generated its own OEIS-series ( A254789 )! Thanks to everyone involved!","['trees', 'generating-functions', 'sequences-and-series', 'combinatorics']"
1132149,"Solve for $n$, with factorial.","If $\sqrt{n! + 23}$ is an integer, then $n=$? I started: $k \in \mathbb{N}$ and: $$k = \sqrt{n! + 23}$$ It follows, $n! = k^2 - 23$ $\Gamma(n+1) = k^2 - 23$ but that doesnt help?","['number-theory', 'elementary-number-theory', 'real-analysis', 'analysis', 'combinatorics']"
1132153,Proof of Young's inequality,"The following problem is from Spivak's Calculus. Suppose that $f$ is a continuous increasing function with $f(0)=0$. Prove that for $a,b \gt 0$ we have Young's inequality $$ ab \le \int_0^af(x)dx+\int_0^bf^{-1}(x)dx$$, and that equality holds if and only if $b=f(a)$. It is enough to consider the case $f(a) \gt b$, and show that the strict inequality occurs in this case. I've tried proving this using the theorem 
$$ \int_a^bf^{-1}=bf^{-1}(b)-af^{-1}(a)-\int_{f^{-1}(a)}^{f^{-1}(b)}f$$ but I got stuck along the way. How may I show this rigorously using the definition or properties of integrals? Any hint, suggestions or solutions would be appreciated.","['calculus', 'real-analysis']"
1132188,Proving $(A\triangle C)\cup(B\triangle C)=A\cup B\cup C$,"Let $A,B,C$ be sets and $A\cap B=\emptyset$. Prove $(A\triangle C)\cup(B\triangle C)=A\cup B\cup C$. My attempt: Let $x\in (A\triangle C)\cup(B\triangle C)$ and from $\triangle$ definition: $$\begin{align}&x\in(A\triangle C)\cup(B\triangle C)\\ & \equiv 
x\in(((A\cup C)\setminus (A\cap C))\cup ((B\cup C)\setminus (B\cap C)))\\
& \equiv 
((x\in(A\cup C)\wedge x\not\in(A\cap C))\vee (x\in(B\cup C)\wedge x\not\in (B\cap C)))\\\\
& \overset{*}\equiv
\color{green}{(x\in(A\cup C)\vee x\in(B\cup C))}\wedge(x\in(A\cup C)\vee x\not\in(B\cap C))\wedge(x\not\in(A\cap C)\vee x\in(B\cup C))\wedge\color {blue}{(x\not\in(A\cap C)\vee x\not\in(B\cap C))}
\end{align}$$ Blue part is equivalent to (using De Morgan): $(A\cap C)\cap C\overset{A\cap B=\emptyset}=\emptyset$ $*$ applying double distribution. That's how far I got, I can see the goal in the green part, but I'm not sure what to do with the two other parts. I'd also like to know if there's a way that doesn't involve the double distribution. Also, I can't simply discard the parts where $x\not \in X$ right?",['elementary-set-theory']
1132211,Prove Intersection of Large Enough Subsets is Non-empty,"I am trying to prove the following claim. I did not find the claim in a book, but I believe it to be true. Claim : Consider a finite set $P\neq \emptyset$ and subsets $S_1, S_2, S_3 \subset P$, each of size
  $s$. Suppose $s > \frac{2}{3} |P|$. Prove that $S_1 \cap S_2 \cap S_3 \neq \emptyset$. Here is my proof. Proof : Consider the elements of $S_1$ and $S_2$. There must be at minimum $\left\lfloor \frac{2|P|}{3} \right\rfloor + 1$ elements in
  each set. Therefore  $$\begin{align*} |P - S_1| &= |P| - s \\ &\le |P|
 - \left\lfloor \frac{2|P|}{3} \right\rfloor - 1 \\ &= \left\lceil \frac{|P|}{3} \right\rceil - 1  \end{align*}$$ Thus $S_1$ and $S_2$ can have at most $\left\lceil \frac{|P|}{3} \right\rceil - 1$ distinct
   elements. The other elements must belong to their intersection.
   $$\begin{align*} |S_1 \cap S_2|  &\ge \left\lfloor \frac{2|P|}{3}
 \right\rfloor + 1 - \left(\left\lceil \frac{|P|}{3} \right\rceil -
 1\right)\\ &\ge \left\lfloor \frac{2|P|}{3} \right\rfloor - 
 \left\lfloor \frac{|P|}{3} \right\rfloor + 1\\ &=  \left\lfloor
 \frac{|P| + 1}{3} \right\rfloor + 1 \end{align*}$$ Thus, 
  $$\begin{align*} |S_1 \cap S_2 \cap S_3| &= |S_1 \cap S_2| +
 |S_3| - |(S_1 \cap S_2) \cup S_3| \\ &\ge \left\lfloor \frac{|P| + 1}{3} \right\rfloor + 1 + \left\lfloor \frac{2|P|}{3} \right\rfloor + 1 - |P|\\ 
&>0 \end{align*}$$ I am looking for verification, criticism, and for alternative proofs.","['discrete-mathematics', 'elementary-set-theory', 'proof-verification']"
1132220,Intersection between a sphere and a plane and parametrization,"I am given that a circle is formed when the unit sphere $x^2+y^2+z^2=1$ intersects the plane $x+y+z=0$. I would like to find the equation of that circle using cylindrical coordinates so that I later can parametrize the equation of the circle. Here is the illustration:
$$\left\{ \begin{array}{l}
{x^2} + {y^2} + {z^2} = 1\\
x + y + z = 0
\end{array} \right.$$ 1. Converting to cylindrical coordinates Since I am only familiar with cylindrical coordinates (not the way equations should be expressed), I thought that the natural thing would be to simply substitute $x=r\cos(\theta)$ and $y=r\sin(\theta)$, $z=z$ in both equations.
Then, I got the following:
$$
\left\{ \begin{array}{l}
{r^2} + {z^2} = 1\\
r(\cos \theta  + \sin \theta )+z = 0
\end{array} \right.$$ 2. Finding the parametrization As I know, there are infinitly many parametrizations, so there is no ""right one"". So, since I have a representation of the system in cylindrical coordinates, I simply substitute $z=-r(\cos \theta  + \sin \theta ) $ into the first eq. so that I get: $$
\begin{array}{l}
{r^2} + {( - r(\cos \theta  + \sin \theta ))^2} = 1\\
{r^2} + {r^2}({\cos ^2}\theta  + {\sin ^2}\theta  + 2\cos \theta \sin \theta ) = 1\\
{r^2}(1 + 1 + \sin 2\theta ) = 1\\
r = \sqrt {\frac{1}{{1 + 1 + \sin 2\theta }}} 
\end{array}$$ In a similar way, I would find $z$. Now the thing that worries me is the square root sign. I now that sometimes, having a square root sign involved will cause paramatrization of only parts of the curve. My question is, am I correct in my reasoning and do I have the parametrization for the entire surface?","['multivariable-calculus', 'algebraic-geometry']"
1132226,Does $\int_0^\infty \frac{\cos x}{1+x}$ absolutly converge?,"Does the following indefinite integral converge?
  $\int_0^\infty \frac{\cos x}{1+x}$ converges, absolutely converges? i can say that by the Dirichlet test it does converge. i am trying to prove it diverges absolutely (seems close to $\frac{1}{x}$)
unsuccessfully so far how do i prove /disprove it absolutely converge?","['improper-integrals', 'convergence-divergence', 'calculus', 'integration', 'definite-integrals']"
1132243,Uniform limit of analytic functions,"Let $\{f_n(z)\}$ be a sequence of analytic functions converging uniformly to a function $f(z)$ on all compact subsets of a domain $D$ . Then $f(z)$ is analytic in $D$ . Suppose we proceed as follows: It is enough to prove that $f(z)$ is analytic at a point $z_0\in D$ . Let $D_0$ be disk with center $z_0$ and contained in $D$ . Clearly $f(z)$ is continuous on $D_0$ . Moreover because of uniform convergence $$\lim_{n\to\infty}\left( \int_C f_n(z)dz\right)=\int_C f(z)dz$$ for every closed contour $C$ in $D_0$ and hence using Cauchy's theorem, we see that the $\int_C f_n(z)dz=0$ for every closed contour $C$ in $D_0$ . Now Morera's theorem finishes the proof. Question: Where is uniform convergence on compact subsets used?","['uniform-convergence', 'complex-analysis']"
1132313,Utility and meaning of the relative setting in Scheme theory,"I'm sorry if my question is rather trivial, but I'm starting to learn scheme theory and I have a very basic question. When talking about schemes I see that very often, instead of taking ""a point of a scheme $X$"", is customary to take a $T$-point of $X$ (where $T$ is another scheme) i.e. a morphism $T\rightarrow X$. In this way, under the hypothesis that both $X$ and $T$ are schemes over a field $k$, we obtain a scheme $X\times_k T$ over $T$ (this is also called ""base change"" as I understand). My question is: why is this ""relative setting"" so useful and so what is the importance of the $T$-points? In other words, why can't we just consider usual points, as we do for topological spaces or complex varieties? Thank you very much.","['algebraic-geometry', 'schemes']"
1132336,When is a power map a homomorphism?,"Let $G$ be a finite group and define the power map $p_m:G\to G$ for any $m\in\mathbb Z$ by $p_m(x)=x^m$ .
When is this map a group homomorphism? Elaborately : Can we somehow describe or classify those groups $G$ and numbers $m$ for which $p_m$ is a homomorphism?
For example, is the image $p_m(G)$ necessarily an abelian subgroup like in all of my examples?
If a group admits a nontrivial $m$ (that is, $m\not\equiv0,1\pmod N$ ) for which $p_m$ is a homomorphism, is the group necessarily a product of an abelian group and another group? Observations The $p_m$ is clearly a homomorphism whenever $G$ is abelian. Also, if $N$ is the least common multiple of orders of elements of $G$ , then $p_{m+N}=p_m$ for all $m$ so the answer only depends on $m$ modulo $N$ .
(Note that $N$ divides $|G|$ but need not be equal to it.)
Also, $p_0$ and $p_1$ are always homomorphisms and $p_{-1}$ is so if and only if $G$ is abelian. Examples If $G=C_4\times S_3$ (where $C_n$ denotes the cyclic group of order $n$ ), then $p_6$ is a nontrivial homomorphism (neither constant nor identity).
Its image is $C_2\times0<C_4\times S_3$ . More generally, if $G_1$ is any nonabelian group and $n$ coprime to $m=|G_1|$ , then $p_m$ is a nontrivial homomorphism for $G=C_n\times G_1$ .","['finite-groups', 'group-theory']"
1132342,"Determining a limit of parametrized, recursively defined sequence $a_{n+1}=1+\frac{(a_n-1)^2}{17}$","For every $c\in [0;2]$ determine whether the sequence $\{a_n\}_{n\geq 1}$ which is defined as follows: $a_1=c$, $a_{n+1}=1+\frac{(a_n-1)^2}{17}$ for $n\geq 1$ is monotonic for sufficiently large $n$, and determine whether its limit exits and if it exists, give its value. I have no idea what to do with this problem. I was able to see that $a_{n+1}-a_n$ is a quadratic function and I also found ot that limit, if exists, is equal to either $1$ or $18$ (that's beacause if $a_n$ id convergent to $g$ then every subsequence is also convergent to $g$). So how to determine the limit for every $c\in [0;2]$?","['sequences-and-series', 'limits']"
1132369,Convolution and absolute value,"I have some problems to do the convolution between $f(x)=e^{-|x|}$ and $g(x)=e^{-|x|}$. $$f*g=\int_{-\infty}^{+ \infty}f(y)g(x-y)\, dy=\int_{-\infty}^{+ \infty}e^{-|y|}e^{-|x-y|}\, dy$$ I have tried to analyse the different cases $$(y>0 \text{ and } x>y,\quad y>0 \text{ and } x<y,\quad y<0 \text{ and } x>y,\quad y<0 \text{ and } x<y)$$ but I have never done an exercise of this kind and I don't want to make a very big confusion... Could you write the correct proceeding? Many thanks","['convolution', 'integration']"
1132376,What's the difference between an axiomatization and a characterization of a structure?,"Regarding structures such as the natural numbers, complex numbers, groups, etcetera. Would it make sense to say that a collection of properties is a characterization of sets? I know that there are axiomatizations (ZFC, NBG, New foundations, etcetera) but I have never heard them referred to as characterizations , is that convention or due to a fundamental difference?. It's much better for me if you can also mention a reference that discusses the topic of axiomatization vs characterization. Regards and thanks.","['reference-request', 'book-recommendation', 'elementary-set-theory', 'terminology']"
1132438,Is it highly unusual to win a lottery with 10 tickets in 6 weeks out of 7? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question A woman in my local Rotary Club has won our weekly drawing 6 out of 7 weeks and I wanted to know the actual odds of this happening. On average 10 tickets are bought which I know makes her daily odds $1/10$. How to find the odds to win 6 out of 7?",['probability']
1132492,Exponential fields as structures with three binary operations.,"The exponential rings and fields are usually studied as structures with two binary operations $(+,\cdot)$ and one unary operation $\exp(x)$ defined on a set $K$. Why not consider the exponential as a binary operation $\star : K\times K\rightarrow K\;,\quad x\star y=x^y$ and search for properties of a structure with three binary operations with suitable axioms? There is some subtle ''obstruction'' to study such kind of structures? PS. I tag as a soft question because I search for a not too tecnical answer ( if possible). Added one month after.
This question gained some reputation, but no answers nor comments. I read this result as : "" the question seems interesting, but it's too hazy to talk about  it"". So I report here some my work, with the aim to better define the question. The structure that i'm searching is $(E,+,\cdot,\star)$ where E is a not void set and: Axiom 1) $(E,+,\cdot)$ is a ring with a multiplicative identity $1$. We assume that this ring has caracteristic $0$. (This in fact is a list of axioms ). In this ring we adopt the usual notations for $n\in \mathbb{N}$:  $nx$ is the sum of $n$ identical elements and $x^n$ is the product of $n$ identical elements. The binary operation $\star: E \times E \rightarrow E$ is  such that, $ \forall x,y,z, \in E$ ve have: Axiom 2) $\quad x\star (y+z)=(x\star y) \cdot (x\star z) $ From this  we have : $x\star(ny)=(x \star y)^n$ Axiom 3) $\quad (x \cdot y)\star z= (x \star z) \cdot (y \star z) $ Axiom 4a) $ \quad 0 \star x=0 \qquad \forall x \in E$ Axiom 4b) $ \quad \forall x \ne 0 \Rightarrow \exists y \in E$ such that $x \star y \ne 0$ Axiom 4c) $ \quad \forall  x\ne 1_E \Rightarrow \exists y \in E$ such that $x \star y \ne 1_E$ where $1_E$ is the neutral element of the product. These last two axioms are introduced to avoid triviality. From these axioms we can proof some simple proposition, as: Prop.1) $ \forall x,y,z, \in E$ we have:$(x\star y) \cdot (x\star z)=(x\star z) \cdot (x\star y)$. Prop.2) $\forall x \in E$, if $(1_E-x\star 0)$ is a right zero divisor than it is also a left zero divisor and $x\star y$ is a zero divisor for all $y \in E$. If $(1_E-x\star 0)$ is not a zero divisor than $x \star 0=1 \; \forall x \in E$. Prop.3) If $(1_E-x\star 0)$ is not a zero divisor the set $ R_x=\{y : \exists z \in E \rightarrow y=x \star z\}$ is a group under ring multiplication. Prop 4) $\forall y \in E$,  if $(1_E-1_E\star y)$ is a right zero divisor than it is also a left zero divisor and $x\star y$ is a zero divisor for all $x \in E$. Prop. 5) If $(E,+,\cdot)$ is a division ring than $R=\bigcup_x R_x$ is a group under multiplication with $1_E$ as neutral element. I stop here(for now).
So my question is if these axioms are sufficient to define a ''nice'' structure, and if this approach can be interesting.
Since my knowledge of universal algebra and category theory are very poor, I don't know if all this work has a sense, or if there are general results that can be used or that show that eventually this is  an impasse.","['soft-question', 'exponential-function', 'abstract-algebra']"
1132510,Chain rule proof doubt,"I was reading this pdf document that
shows a proof of the chain rule. My doubt is in the second slide I dont understand why the $k$ value is equal to $g'(x)$ plus $v$ all of this plus $h$ . Sorry I dont write the equations, I dont know how to do it thats why I added the link to the pdf","['calculus', 'derivatives']"
1132521,"Bound on $f(0)^2$ by integrals of $f^2$ and $(f')^2$ on $[0,1]$.","Let $f$ be a function which is $C^1((0,1))\cap C([0,1])$. I would like to be able to show
$$
 \frac{1}{2}f(0)^2 \leq \int_0^1 f(x)^2dx + \int_0^1f'(x)^2dx
$$
where we are assuming that $f$ is a real-valued function. We have attempted to use Young's inequality to reduce to $\frac{d}{dx}[f(x)^2]$, but this does not work. Thanks in advance for any ideas! edit: Counterexamples are welcome, obviously, but we believe this at the moment.","['calculus', 'real-analysis', 'integral-inequality']"
1132550,$f(x) = \int_0^x\frac{1-t^2}{\sqrt{t^4+1}}dt$ find it's derivative and tangent where x = 0,"I am given this function: $$f(x) = \int_0^x\frac{1-t^2}{\sqrt{t^4+1}}dt$$ I have to find it's derivative $f'(x)$ and I have to find the equation of it's tangent in the point $x = 0$. I'm a bit confused about this one. I think it's derivative is: $$\frac{1-x^2}{\sqrt{x^4+1}}$$ Is that right? I've tried finding it's tangent, where $x = 0$. I've found $k_t = 1$, $x_0 = 0$, $y_0 = f(0)$ and inserted this into the equation: $$y - y_0 = k_t(x - x_0)$$
$$y = x - f(0)$$ Did I do this correctly or did I entirely miss the point?","['definite-integrals', 'integration', 'derivatives']"
1132558,For which complex numbers does a given series converge,"During studying for an exam, I came across the following exercise: For which $z \in \mathbb{C}$ does the series
$$\sum\limits_{n=1}^{\infty} \frac{n^n z^n}{n!}$$
converge? By using the ratio test (or alternatively: calculating the radius of convergence), I can see that the series converges for $|z|<\frac{1}{e}$ and diverges for $|z|>\frac{1}{e}$. However, I am not able to find out what happens if $|z|=\frac{1}{e}$. Does anyone have an idea?","['sequences-and-series', 'convergence-divergence', 'calculus', 'analysis']"
1132567,Proving statement $\sum^{\infty}_{n=1}a_n$ converges iff $\sum^{\infty}_{n=1}(1 + \frac{1}{n})a_n$ converges,"Is it true that $\sum^{\infty}_{n=1}a_n$ converges $\iff$ $\sum^{\infty}_{n=1}(1 + \frac{1}{n})a_n$ converges? 
I think that I can prove the $\implies$ implication:
$$\sum^{\infty}_{n=1}(1 + \frac{1}{n})a_n = \sum^{\infty}_{n=1}(a_n+\frac{a_n}{n})$$
We know that $\sum^{\infty}_{n=1}\frac{a_n}{n}$ converges from Dirichlet's test so the sum of these two series is finite so the series above converges. 
I don't have any idea how to prove <= implication. Any hints?","['convergence-divergence', 'sequences-and-series']"
1132591,Inverse of diagonally dominant matrix with equal off-diagonal entries,"Is there an explicit expression for the inverse of strictly diagonally dominant matrix with identical off-diagonal elements? For example: $$ \begin{pmatrix} a & -b & -b \\
                  -b &  c & -b \\
                  -b & -b &  d \end{pmatrix} $$ where $|a|\gt 2|b|$, $|c|\gt 2|b|$, and $|d|\gt 2|b|$. I'm looking for an inverse for an arbitrary $n\times n$ matrix with the above property.","['matrices', 'symmetry', 'linear-algebra', 'inverse']"
1132608,Why must a locally compact second countable Hausdorff space be second countable to imply paracompactness?,"The textbook version of the result I've seen states: A locally compact second countable Hausdorff space is paracompact. Is the property of being second countable needed, or have I missed something? My thinking: If the space is locally compact then each point has a compact neighborhood. For this compact neighborhood each covering has a finite sub-covering. The finite sub-covering is a locally finite refinement. Thanks in advance.","['general-topology', 'examples-counterexamples', 'second-countable', 'compactness']"
1132630,Example of Transcendental Extension with no Intermediate Field,"It can be shown that given $F \subset R \subset K$, where $K/F$ is an algebraic extension and $R$ is an integral domain, that $R$ is then an intermediate field. However, is there an explicit counter example for this statement when $K$ is not algebraic over $F$. I was considering $\mathbb{Q}(\pi)/ \mathbb{Q}$ which is a transcendental extension because there does not exist a polynomial with rational coefficients for which $\pi$ is a root. However how can one show that there does not exist intermediary fields. Is it recommended that I got about in showing that for $R$ where $\mathbb{Q} \subset R \subset \mathbb{Q}(\pi)$, $R$ does not contain multiplicative inverses? Or should I focus on the infinite degree of $[\mathbb{Q}(\pi):\mathbb{Q}]$. Any and all help would be appreciated!","['extension-field', 'abstract-algebra', 'field-theory']"
1132649,Integrating Joint Random Variable Distributions - Defining Integration Intervals,"I'm currently studying for a stats quiz using the course text book, and I'm discovering that I'm a little rusty on setting up regions for double integrals. The current question I'm hung up on is as follows: If the joint probability density of $X$ and $Y$ is given by: 
$$f(x,y) = \begin{cases} 2 & \text{for } x>0, y>0,x+y<1 \\ 0 & \text{elsewhere}\end{cases}$$ find: a. $P(X \leq \frac{1}{2}, Y \leq \frac{1}{2})$ b. $P(X+Y > \frac{2}{3})$ c. $P(X > 2Y)$ I got part a correct, with the region of integration being $A = \{(x,y) \mid 0 < x < \frac{1}{2}, 0 < y < \frac{1}{2}\}$, but b and c I'm finding a bit more difficult. I have yet to attempt c, but I've set the following regions up for b: $$A = \{(x,y) \mid 0 < x < \frac{2}{3}, 0 < y < 1-x\}$$ and $$A = \{(x,y) \mid \frac{2}{3} < x < 1, 0 < y < 1-x\}$$
Both regions yielded incorrect answers $\frac{8}{9}$ and $\frac{1}{9}$ respectively, with the correct answer being $\frac{5}{9}$. Generalized, how does one go about setting up the region of integration when given bounds as described above? Thank you.","['statistics', 'probability', 'integration']"
1132652,What is the smallest eularian graph?,"Which one is smallest eularian? I think that (1,2)-eularian. Thank you for your helps in advance.","['graph-theory', 'discrete-mathematics', 'proof-verification']"
1132681,Is there a clever shortcut to showing that this function is in O(N^2)?,"This problem is from Discrete Mathematics and its Applications I am currently working on 2a. I am trying to apply an example the book gave earlier Is there some similar clever trick I can apply to 2a to shorten the math I would have to do?
Here is the work I have so far I prefer not to go through the quadratic equation solver http://www.mathsisfun.com/quadratic-equation-solver.html and getting some floating point value but i can't find something like  x > 7 for 17x + 11","['computational-complexity', 'quadratics', 'discrete-mathematics']"
1132697,Is it feasible to think of laplace transform and z transform as projections?,"For Fourier transform, it has been ingrained in my head that all we are doing is projecting a function onto its Fourier basis, namely $(1, cos(t), sin(t),...cos(nt), sin(nt) ...)$ Can anyone comment whether we can also think of the laplace transform and the z-transform as projections on their respective basis? On some level this is more difficult because the kernel of the laplace transform is $e^{st}$ which is not intuitive as to what the basis would be. More difficult is the z-transform, which has the kernel $z^{-k}$. In this case can we say that we are projecting our function onto a set of discrete basis $(1, z^{-1}, z^{-2}...z^{-n})$, where each $z$ is a complex number. It is not clear what these basis are. Can someone clarify this issue? Thanks.","['z-transform', 'laplace-transform', 'fourier-analysis', 'functional-analysis']"
1132703,An equation $p^a=q^b+r^c$ for powers of primes,"I´m preparing for math contests and found the following problem from this pdf . Find all integers $a, b, c >1$ and all prime numbers $p, q, r$ which satisfy the equation $p^a=q^b+r^c$ ($a, b, c$ and $p, q, r$ does not have to be distinct). I guess we can solve this problem by examine possible divisors, from which we conclude that $p$ is a divisor in both $q$ and $r$, or none of them. But since $p, q, r$ are all primes, the first case is only possible if $p=q=r=2$. If $p=q=r=2$ we see that $a=k+1$ and $b=c=k$ for some integer $k$ satisfies the equation. Let now $p, q, r$ be distinct. Then, because of parity, one (and only one) of them must be 2.  But I´ve not come further than that. Any suggestions?","['prime-numbers', 'diophantine-equations', 'contest-math', 'number-theory']"
1132730,Generating M well separated points in an n-dimensional hypercube,"I want to generate M n-dimensional points constrained inside a hypercube such that the points are relatively well separated. I'm playing around with this using a scripting language like R or python. For example, if we're working with n=2 and the rectangle with vertices (0,0), (5,0), (0,5), (5,5), and I want to generate 4 points inside it, then I might cut the rectangle into 4 separate smaller rectangles, and then generate a point in the middle of each square. The problem is that I'm having a lot of trouble visualizing how to go about this when it goes beyond 2 dimensions. Is this the best approach to solve my problem? What kind of topics should I even be searching or googling to try and find a solution? Is this question about calculating a spread of m vectors in n-dimensional space possibly relevant to what I want to do? I also found a lot of questions about choosing evenly distributed points on a sphere or this question about Well separated points on a sphere , but I'm more interested in the case for hypercubes which I'm hoping is easier. The Wolfram Alpha page on Hypercube Point Picking goes completely over my head unfortunately. Thanks in advance for any insight anyone can offer!","['geometry', 'combinatorial-geometry']"
1132735,Is simple closed curve homeomorphic to a circle?,"For sure every curve that is homeomorphic to a circle is a simple closed curve, but is every simple closed curve homeomorphic to a circle? Is there a proof for that, or is there some topological invariant that is not not shared with simple closed curve and a curve that is homeomorphic to a circle? "" Simple closed curve "" = "" non-self-intersecting continuous closed curve in plane .""","['general-topology', 'plane-curves', 'algebraic-topology']"
1132750,ways to see whether the Pontryagin class of a quaternionic line bundle over a CW-complex is zero,"the first pontryagin class of a quaternionic line bundle over a CW-complex is zero if and only if the quaternionic line bundle is trivial or not? Let $\xi^\mathbb{H}$ be a given quaternionic line bundle. Is there any method to see whether $p_1(\xi^{\mathbb{H}})=0$? Could you give references? Quaternionic line bundles are classified by maps to $B GL_1(\mathbb{H}) \cong BSp(1)$. This has cohomology a polynomial algebra $$H^{*}(BSp(1)), \mathbb{Z}) \cong \mathbb{Z}[p_1]$$ on the Pontryagin class $p_1 \in H^4$. For complex line bundle and chern class, I obtained that the first chern class is zero if and only if the complex line bundle is trivial. This is obtained by 
$$
c_1(\xi^\mathbb{C})=e((\xi^\mathbb{C})_\mathbb{R})=o_2((\xi^\mathbb{C})_\mathbb{R}).
$$
By page 140, 143, 158, Charachateristic class, Milnor and Stasheff, we obtain that the first chern class is zero if and only if the complex line bundle is trivial. But for quaternionic line bundle $\xi^{\mathbb{H}}$, page 174, Charachateristic class, Milnor and Stasheff, 
$$
p_1(\xi^\mathbb{H})=p_1((\xi^\mathbb{H})_\mathbb{R})=-c_{2}((\xi^\mathbb{H})_\mathbb{R}\otimes\mathbb{C}).
$$
I do not know how to do.","['characteristic-classes', 'geometric-topology', 'differential-geometry', 'algebraic-topology', 'differential-topology']"
1132764,spectral norm of a sparse Gaussian matrix,"Suppose $G$ is an $m \times n$ matrix such that each entry of $G$ is a standard normal variable. We know that the spectral norm of $G$ scales as $\sqrt(m) + \sqrt(n)$. Now, given a set of indices $S$ suppose we construct a new matrix $A$ such that $A_{ij} = G_{ij}$ if $(i,j) \in S$, and 0 otherwise. Can we show that the spectral norm of $A$ is upper bounded by the spectral norm of $G$?","['matrices', 'probability', 'random']"
1132783,Exactly how does it mean to negate a statement?,"Is $\lnot p,$ the negation of a statement $p,$ just the opposite of $p,$ or is it anything but $p\;?$ For example, let's say $p$ = ""None of the basketball players are blond"". Is $\lnot p$ : ""All of the basketball players are blond"" (exact opposite of $p$ )? Or is $\lnot p$ : ""At least one of the basketball players is blond"" (anything but $p$ )? A side question: what is the precedence of ∧ (and), ∨ (or), ¬ (negation), $→$ (implies), etc.?","['logic', 'propositional-calculus', 'discrete-mathematics', 'predicate-logic']"
1132796,Two definitions of equicontinuity,"Rudin's Principles , p. 156, says A family $\mathscr{F}$ of complex functions $f$ defined on a set $E$
  in a metric space $X$ is said to be equicontinuous on $E$ if for
  every $\epsilon>0$ there exists a $\delta>0$ such that
  $$|f(x)-f(y)|<\epsilon$$ whenever $d(x,y)<\delta$, $x \in E$, $y\in
> E$, $f\in \mathscr{F}$. On the other hand Munkres's Topology , p. 276, says Let $(Y,d)$ be a metric space. Let $\mathcal{F}$ be a subset of the
  function space $\mathcal{C}(X,Y)$. If $x_0 \in X$, the set
  $\mathcal{F}$ of functions is said to be equicontinuous at $x_0$ if given $\epsilon>0$, there is a neighbourhood $U$ of $x_0$ such that
  for all $x \in U$ and all $f \in \mathcal{F}$, $$d(f(x),f(x_0)) < \epsilon.$$ If the set $\mathcal{F}$ is equicontinuous at $x_0$ for each $x_0 \in X$, it is said to 
  be equicontinuous . For equicontinuity on a subset $E$ of the domain the two definitions appear not to be equivalent since Rudin's requires that the $\delta$ for a given $\epsilon$ be the same across $E$ whereas Munkres's does not. Am I right in believing this? If so, are there any interesting special cases where the two definitions are equivalent?","['general-topology', 'real-analysis']"
1132826,Inner Product on $\mathbb{R}$ and on $\mathbb{C}$,"This is a question of the book Linear Algebra of Kenneth Hoffman. Describe explicitly all inner products on $\mathbb{R}$ and on $\mathbb{C}$. I think that if $<,>$ is one inner product on $\mathbb{R}$ (or $\mathbb{C}$) then $< ,>=K[,]$, where $[,]$ is the standard inner product. Is that correct?",['linear-algebra']
1132830,Show that Möbius transformations that preserve the unit disk are of the matrix form $\tiny \begin{bmatrix}a & b \\ \bar{b} & \bar{a} \end{bmatrix}$,"Show that Möbius transformations that preserve the unit disk are of the matrix form $$\begin{bmatrix}a & b \\ \bar{b} & \bar{a} \end{bmatrix},$$ where $|a|^2 - |b|^2 = 1$ and $a,b \in \mathbb{C}$. I tried approaching this by noting that these transformations must first and foremost preserve the unit circle. So I looked at whether I'd get anything useful out of seeing what a random matrix $\begin{bmatrix}a & b \\ c & d \end{bmatrix}$ would need to satisfy in order for, say, $1, -1$ and $i$ to stay on the unit circle. However, I got nothing useful out of that. I looked at some threads here already (for example, Möbius Transforms that preserve the unit disk ), but none of them seem to help in getting me this form. Help would be greatly appreciated.","['mobius-transformation', 'complex-analysis']"
1132855,The Matching Problem/Derangements - n letters to n people,"There are n letters addressed to n eople at different addresses. The n addresses are typed on n envelopes.  A disgruntled secretary shuffles the letters and puts them in the envelopes in random order, one letter per envelope. Find the probability that at least one letter is put in a correctly addressed envelope. [Hint: use the inclusion-exclusion formula.]
What is the probability approximately, for large n ? My attempt at a solution: $P(\text{all correct}) = \frac{1}{n!}$ $P(\text{$n-1$ correct}) = {n \choose n-1} \frac{1}{n!} = \frac{1}{1!(n-1)!}$ , since ${n \choose n-1}$ ways of selecting n-1 correct letters. $P(\text{$n-2$ correct}) = {n \choose n-2} \frac{1}{n!} = \frac{1}{2!(n-2)!}$ $\ldots$ $P(\text{$n-n$ correct}) = {n \choose n-n} \frac{1}{n!} = \frac{1}{n!(n-n)!} = \frac{1}{n!}$ This all looks ok to me, but I tested this for a case of 4 people, (I think the theoretical value should be $\frac{9}{24}$ but obviously that is not what I got. Can someone correct my logic please? Also, with regards to the hint about inclusion/exclusion - where would that come in? I read about derangements on Wikipedia but it did not make total sense to me (the derivation). I would appreciate any advice whatsoever including references to other material.","['inclusion-exclusion', 'probability', 'combinatorics']"
1132869,Differential Equation of the Form $\frac{dy}{dx}=\sin(x+y)$ [duplicate],"This question already has answers here : Ordinary differential equation $y'(t)=\sin(f(t,y))$ (3 answers) Closed 9 years ago . I have been attempting to solve the above differential equation for some time now, and I remain stuck on one step. After substituting $u=x+y$, separating the variables, and integrating both sides, I am left with $$\frac{\sin(u)-1}{\cos(u)}=x+c$$ I have to solve for $y$, and thus, for $u$, but I cannot think of any identity which helps me here. Any help would be appreciated. I followed the step in the solution, and set $$\frac{\tan(\frac{u}{2})-1}{\tan(\frac{u}{2})+1}=x+c$$ Then, I used the substitution $z=\frac{1}{1+\tan(\frac{u}{2})}$, which led to $1-2z=c+x$, which in turn, simplified to $z=\frac{1}{2}-\frac{c}{2}-\frac{x}{2}$. Then, substituting back: $$u=-2\arctan\left(1-\frac{1}{\frac{1}{2}-\frac{c}{2}-\frac{x}{2}} \right)$$ Thus, for all $n \in \mathbb Z$, the solution of the differential equation is $$y=-x-2\arctan\left(\frac{c+x+1}{c+x-1}\right)+2\pi n$$ Is my process correct, and do I require the $2\pi n$ generalization in my final expression? Edit: The solution can also be expressed in indefinite form as $$\tan(x+y)-\sec(x+y)=x+c$$","['trigonometry', 'ordinary-differential-equations']"
1132885,"Using Quantifiers to express ""At least two""","I have been stumped trying to solve problem e . I am confused as how to state ""At least two students..."" using quantifiers! I know if it were ONE student it would be: ∃x,y(Q(x,Jeopardy)). And all students would be:∀x,y(Q(x,Jeopardy)) So how can I expand on this?","['quantifiers', 'discrete-mathematics']"
1132929,Do entries in augmented columns count as pivot?,"I am in a basic linear algebra course, and we are learning to solve linear equations with augmented matrices. We learned that when an augmented matrix is in row echelon form or reduced echelon form, you can tell if the system has one, infinitely many, or no solutions by looking if there is a pivot in every column or a pivot in every row. When you look for pivots, do entries in the augmented column count?","['matrix-equations', 'matrices', 'linear-algebra']"
1132936,Solve the Differential Equation $\frac{dy}{dx}=2+\sqrt{y-2x+3}$,"I re-arranged the equation to appear as such: $$1+2x=y+4\cdot\frac{dy}{dx}-\left(\frac{dy}{dx}\right)^2$$ None of the techniques I have learned so far help me to proceed here; particularly, the $\left(\frac{dy}{dx}\right)^2$ term makes it difficult to assess. I know that it is first-order non-linear, however. Is there a classification for this equation, or a formula that I may use to proceed? Thanks in advance!",['ordinary-differential-equations']
1132937,"Finding a normal vector to the surface $F(u,v)=0. u=xy, v = \sqrt {x^2+z^2}$ at the point $x=1,y=1, z=\sqrt 3$","The three equations $F(u,v)=0. u=xy, v = \sqrt {x^2+z^2}$ define a surface in $xyz$ space. Find a normal vector to this surface at the point $x=1,y=1, z=\sqrt 3$ if it is known that $D_1F(1,2)=1$ and $D_2F(1,2)=2$ Solution Attempt: Since, $F(u,v)=0$ represents a level surface, hence, the gradient vector will be a normal vector to the surface at a given point. $F(u,v)=0 \implies \dfrac {\partial F}{\partial u} \cdot  \dfrac {\partial u}{\partial x} +  \dfrac {\partial F}{\partial v} \cdot  \dfrac {\partial v}{\partial x} =0$ $\implies \dfrac {\partial F}{\partial u} \cdot  y +  \dfrac {\partial F}{\partial v} \cdot  \dfrac  {x} {\sqrt {x^2+z^2}} =0$ At the given point, this becomes equal to : $ \dfrac {\partial F}{\partial u}  +  \dfrac {\partial F}{\partial v} \cdot  \dfrac  {1} {2} =0~~~~~........(1)$ Similarly: $\dfrac {\partial F}{\partial u} \cdot  \dfrac {\partial u}{\partial y} +  \dfrac {\partial F}{\partial v} \cdot  \dfrac {\partial v}{\partial y} =0$ $\implies \dfrac {\partial F}{\partial u} \cdot  x +  \dfrac {\partial F}{\partial v} \cdot  0 =0~~~~~......(2)$ From $(1),(2)$, we get that $ \dfrac {\partial F}{\partial u}= \dfrac {\partial F}{\partial v} = 0  $ This means, that the normal vector is $0$? Could anyone please tell me where I could have possibly gone wrong in my solution attempt? Thank you for reading through and helping!","['multivariable-calculus', 'calculus', 'vector-analysis']"
1132971,Is there an Analytical solution for Blasius equation?,"Blasius Equation was introduced to me during my University time ...and I would like to have a solution for it $$y''' + yy'' = 0$$ the $y$ here makes the equation from a linear simple to solve to a non-linear almost impossible to solve , one solution is to use the numerical method but I would like to have the exact analytic solution .",['ordinary-differential-equations']
1132974,"Consider the set $Q=\{p+q \sqrt2 : p,q \in\Bbb Q\}$. Prove that if $a\in Q\setminus\{0\}$ then $1/a\in Q$","Given (For all $a,b\in Q$, $a+b\in Q$ and $ab\in Q$) This was a two part question. Part a) is to prove that $Q$ is closed under addition and multiplication. Part b) is prove that if $a\in Q$ and $a\ne0$, then $\frac1a\in Q$. I proved part a but I'm stuck on part b... 
I know that I have to let $a=c+d\sqrt2$ and some how try and move things around to try and make it ""look"" like $p+q\sqrt2$ but I can't seem to get it.","['discrete-mathematics', 'contest-math', 'recreational-mathematics']"
1133002,Prove the Lorentz group is not compact,"I cant seem to figure how to prove this. I want to show that the Lorentz group $O(3,1)$ is not compact. I was thinking that the best way to show it was not compact was to show it was unbounded. Any ideas?","['algebraic-topology', 'group-theory']"
1133017,Compact space X is totally disconnected if and only if C(X) is generated by its projections,"If $X$ is compact, show that $X$ is totally disconnected if and only if $C(X)$ as a C*-algebra is generated by its projections. My attempt: Suppose $X$ is totally disconnected, then $X=\{x_i\}_{i\in I}$. In this case clearly $C(X)$ is generated by the family of projections $\{\chi_{x_i} ; i\in I\}$. Conversely, suppose $X$ is not totally disconnected, so there is a subset $Y$ of $X$ such that $Y$ is a connected component and it has at least two points. If $X\not\subset \Bbb C$, then there is a compact subset $X'$ of $\Bbb C$ such that $C(X)$ is an $*-$ isomorphism onto $C(X')$. Thus we can suppose $X\subset \Bbb C$. Clearly $id_Y$ is a generator for C(X) and is not a projection which is a contradiction. Please check my attempt and allow me to know your opinion about that. Thanks.","['general-topology', 'functional-analysis', 'c-star-algebras', 'operator-theory']"
1133055,Where is the homothety in the problem?,"I have to solve the following problem using homothety but I don't see where it is. Given triangle $ABC$. $D$ is an arbitrary point inside the triangle. Points $M, E$ and $F$ are mid points of the sides $AB, AC$ and $BC$ respecitvely. Points $N, P$ and $Q$ are midpoints of $DM, DE$ and $DF$. Prove that the lines $AQ, BP$ and $CN$ intersect at a point.","['homothety', 'geometry']"
1133071,Reference: Continuity of Eigenvectors,"I am looking for an appropriate reference for the following fact. For each $X \in \mathbb{R}^{n \times n}_{\text{sym}}$ (symmetric matrix),
  there exist $\varepsilon, L > 0$, such that
  for all $H \in \mathbb{R}^{n \times n}_{\text{sym}}$ with $\|H\| \le \varepsilon$
  the following holds: There are orthogonal matrices $P, Q$, such that
  \begin{equation*}
	Q^\top \, X \, Q = \Lambda(X)
\end{equation*}
  and
  \begin{equation*}
	P^\top \, (X + H) \, P = \Lambda(X + H)
\end{equation*}
  and
  \begin{equation*}
	\| P - Q \| \le L \, \| H \|.
\end{equation*} Here, $\lambda(X)$ is the diagonal matrix containing the eigenvalues of $X$.
That is, $P$ and $Q$ are bases of eigenvectors of $X$ and $X + H$, respectively.
Here, it is crucial that we can choose $Q$ in dependence of $H$. This result can be found in this article , see Lemma 4.3.
I feel, however, that a reference from 2003 is not appropriate for this ""simple"" fact.","['eigenvalues-eigenvectors', 'linear-algebra', 'reference-request', 'perturbation-theory']"
1133077,Show that $ABCD$ has an incircle if and only if $\frac {1}{PE} + \frac {1}{PG} = \frac {1}{PF} +\frac {1}{PH}$,"Let $ABCD$ be a convex quadrilateral.Let the diagonals $AC$ and $BD$ intersect in $P$.Let $PE,PF,PG,PH$ be the altitudes from $P$ onto the sides $AB,BC,CD$ and $DA$ respectively.Show that $ABCD$ has an incircle if and only if $\frac {1}{PE} + \frac {1}{PG} = \frac {1}{PF} +\frac {1}{PH}$","['geometry', 'quadrilateral']"
1133113,How do we define arc length?,"In trying to write a nice proof of the derivatives of $\sin(x)$ and $\cos(x)$, I encountered a serious problem, namely that I have never seen a proper definition of the notion of arc length . Based on visual intuition (for whatever that means), I tried to argue as follows: Consider the following diagram: The chord $AC$ is shorter than the red arc which is again (by visual intuition ) shorter than the path $ABC$. This means that $$2s<arc<2d$$
  Note that $|OD|=\sqrt{1-s^2}$ by the Pythagorean theorem. Now, since $\Delta ABD$ and $\Delta OAD$ are similar, we see that $$\frac sd=\frac{\sqrt{1-s^2}}1$$ so dividing the chord length $2s$ by $2s,arc$ and $2d$ considering inequalities from before we then have $$1>\frac{2s}{arc}>\frac{2s}{2d}=\sqrt{1-s^2}$$ and it follows that $$\frac{2s}{arc}=\frac{chord}{arc}\longrightarrow 1\quad\text{when}\quad chord,arc\longrightarrow 0$$ Problem: Since the inequality $arc<2d$ was based solely on intuition, I could just as well have claimed that $\frac{chord}{arc}\longrightarrow 1$ by intuition in the first place anyway. Perhaps my intution about the inequality is stronger than my intuition about the limit, but that does not make it more rigorous ... Question: How can we define the notion of arc length and based on that show rigorously that $arc<2d$?","['geometry', 'definition', 'axioms', 'proof-verification', 'circles']"
1133147,Show that the average of n observations is equal to the expected value,"Show that the average of n observations is equal to the expected value
  with the density function with index k is equal to
  the number of observations equal to k divided by the total number of
  observation, that is, $$\frac{y_1 +...+y_n}{n} = \sum_{k=1}^{n}k*p_k$$
  there $p_k=\#(y_i: y_i = k)/n$ Any hints? I really don't know how to show the statement above.","['statistics', 'stochastic-analysis', 'probability']"
1133149,$\mathbb{R}$ -trees are CAT(0) space,"An $\mathbb{R}$-trees is a metric space $(X,d)$  such that there is a unique geodesic segment (denoted $[x,y]$ ) joining each pair of points $x,y\in X$ ; if $[x,y]\cap[y,z]=\{y\}$ , then $[x,y]\cup[y,z]=[x,z]$. $\mathbb{R}$-trees are CAT(0) space but I can't prove it! How can I Prove $\mathbb{R}$-trees are CAT(0) space? Thanks for helping","['geometry', 'metric-spaces', 'geodesic']"
1133163,is the Jacobian Determinant continuous,"Is the Determinant of the Jacobian a continuous function? i.e. 
$$f:\mathbb{R}^n \rightarrow \mathbb{R}^n $$
$$ \forall \varepsilon >0 \quad \exists \delta >0 : |x-x_0 |<\delta \Longrightarrow |det(Jf(x))-det(Jf(x_0))|<\varepsilon $$ How would I go about showing this? Does the $\varepsilon - \delta$ definition help in this case or would it be more appropriate to use the inverse function theorem? Any suggestions appreciated","['multivariable-calculus', 'determinant']"
1133197,"How many three digit numbers are not divisible by 3, 5 or 11?","How many three digit numbers are not divisible by 3, 5, or 11? How can I solve this? Should I look to the divisibility rule or should I use, for instance, 
$$
  \frac{999-102}{3}+1
$$","['discrete-mathematics', 'divisibility', 'combinatorics']"
1133203,Derivation of multivariable functions,"I know that the derivative of $f(x)$ defined as: $\, f(x)=\dfrac{1}{2} \cdot \left|\left|g(x) \right|\right|^2_2$ is $\nabla f(x) = J_g(X)^T \cdot g(x)$ where $g:\mathbb{R}^n \rightarrow \mathbb{R}^m$, $f:\mathbb{R}^n \rightarrow \mathbb{R}$, and $\left|\left|x \right|\right|_p$ is the $p$-norm of $x$ : $\left|\left|x \right|\right|_p=\left( \sum\limits_{i=1}^n \left|x_i \right|^p \right)^\frac{1}{p}$ First of all why is the norm sign removed after derivation? Secondly, what is the derivative in for example this case where the norm and exponent differ: $f(x)=\dfrac{1}{2} \cdot \left|\left|g(x) \right|\right|^8_3$ Could you please explain the reason behind the two cases?","['multivariable-calculus', 'calculus', 'real-analysis', 'analysis', 'derivatives']"
1133234,Prove $|f|$ is constant implies $f$ is constant,"Let $f$ be an entire function (differentiable everywhere over $\mathbb{C})$. Suppose that $|f|$ is constant. Prove that $f$ is constant. Hint: $|f|\equiv c$ implies that $u^2+v^2\equiv c^2$. Take partial derivatives and apply the Cauchy-Riemann equations. Proof: Suppose $|f|=c$ for some $c \in \mathbb{C}$. Writing $f(z)=f(x+iy)=u(x,y)+iv(x,y)$, this means
\begin{equation}
u(x,y)^2+v(x,y)^2=c^2
\end{equation}
Please correct me if I'm not differentiating correctly, but taking the partial with respect to $x$ I find that
\begin{equation}
2u(x,y) u_x(x,y)+2v(x,y)v_x(x,y)=0
\end{equation}
Simiarly, taking the partial with respect to $y$ shows that
\begin{equation}
2u(x,y) u_y(x,y)+2v(x,y)v_y(x,y)=0
\end{equation}
Is this correct so far? Edit: Thanks to AlexR for his tip. I continue the proof below. Substituting the C-R equations ($u_x=v_y$ and $v_x=-u_y$), the first equation gives two possible equations:
\begin{equation}
2\left(u(x,y) v_y(x,y)+v(x,y)v_x(x,y)\right)=0
\end{equation}
or
\begin{equation}
2\left(u(x,y) u_x(x,y)-v(x,y)u_y(x,y)\right)=0
\end{equation} Similarly, depending on the choice of substitution, the second equation gives two possible equations:
\begin{equation}
2\left(v(x,y)v_y(x,y)-u(x,y)v_x(x,y)\right)=0
\end{equation}
or
\begin{equation}
2\left(u(x,y) u_y(x,y)+v(x,y)u_x(x,y)\right)=0
\end{equation}
(does it matter which equations we choose to use?)","['multivariable-calculus', 'derivatives', 'complex-analysis', 'proof-verification']"
1133239,Can we change order of integration and differentiation here.,"Assume that $P(x,y)$ have continuous first order partial derivatives. Let $\int P(x,y) dx$, denote the antiderivative with respect to x. Is it then true that $\frac{\partial}{\partial y}\int P(x,y)dx=\int \frac{\partial P(x,y)}{\partial y}dx$? I am struggling with how I can show this. Does it help if we restrict ourselves to a rectangle? Update: In the comments I got a tips of a Wikipedia article: http://en.wikipedia.org/wiki/Leibniz_integral_rule . I tried to modify the proof to my situation, can someone check if it is correct? Proof: Let $\{y_n\}$ be a sequence that goes to zero, but is never actually zero. We then have: $\frac{\partial }{\partial y}\int P(x,y) dx=\frac{\partial}{\partial y} [\int_a^xP(t,y)dt +C]=lim _{n \rightarrow \infty} \frac{\int_a^xP(t,y+y_n)dt-\int_a^xP(t,y)dt}{y_n}=lim_{n \rightarrow \infty}\frac{\int_a^x[P(t,y+y_n)-P(t,y)]dt}{y_n}$. Because of the same reason here: http://en.wikipedia.org/wiki/Leibniz_integral_rule#Proof_of_basic_form that the term inside the integral is bounded, we get that our intgral is bounded.(P and it's partial derivatives are continuous, we can restrict ourselves to a closed local place, so we get compactness). Since all the terms are Riemann integrable, they are alse Lebesgue integrable, and hence we can use the bounded convergence theorem to get(they didn't say anything about riemann vs: Lebesgue in the article, but I assume we have to do that?): $=\int_a^xlim_{n \rightarrow \infty}\frac{P(t,y+y_n)-P(t,y)}{y_n}dt=\int_a^x\frac{\partial  P(t,y)}{\partial y}dt=\int\frac{\partial P(x,y)}{\partial y}dx +C$ So in conclusion we have that: $\frac{\partial }{\partial y}\int P(x,y) dx=\int\frac{\partial P(x,y)}{\partial y}dx +C$, but when working with antiderivatives, we can overlook the constant, so we get:
$\int\frac{\partial P(x,y)}{\partial y}dx $ Is this proof correct?","['multivariable-calculus', 'partial-derivative', 'integration', 'real-analysis']"
1133285,Proving $\mathcal P(\mathbb N) \sim (\mathcal P(\mathbb N)\setminus \{\emptyset\})$,"Prove: $\mathcal P(\mathbb N) \sim (\mathcal P(\mathbb N)\setminus \{\emptyset\})$ My attempt: One side is obvious since $\mathcal P(\mathbb N) \supset (\mathcal P(\mathbb N)\setminus \{\emptyset\})$ so $|\mathcal P(\mathbb N)| > |(\mathcal P(\mathbb N)\setminus \{\emptyset\})|$ so we know there's an injective function from the RHS to LHS. For the other side, define $f$ to be: $$ f(X)=\begin{cases}
\{1\} &,X=\emptyset \\
\{n+1\} &, X=\{n\} \\
X &, else
 \end{cases} $$ We just performed a linear operation on all sets $X=\{n\}$ otherwise the function is the identity, therefore it's injective. From CSB we can conclude that $\mathcal P(\mathbb N) \sim (\mathcal P(\mathbb N)\setminus \{\emptyset\})$ Is that alright?","['proof-verification', 'elementary-set-theory', 'functions']"
1133290,Is the product of pro-$\mathcal C$ groups also a pro-$\mathcal C$ group?,Let $\mathcal C$ be a class of finite groups which is closed for subgroups and direct products and call a topological group $G$ a pro-$\mathcal C$ group if it is an inverse limit of $\mathcal C$-groups. I'm trying to show that a product $\prod_{i\in I}G_i$ of pro-$\mathcal C$-groups is a pro-$\mathcal C$ group and I'd be grateful for some help. I know that a pro-$\mathcal C$ group is isomorphic to a closed subgroup of a product of $\mathcal C$-groups- but I'm not sure if an arbitrary product of closed topological spaces is closed in the product topology.,"['topological-groups', 'profinite-groups', 'group-theory', 'abstract-algebra']"
1133298,Trouble understanding the tangent bundle,"First of all, have I understood the preliminary notion of a tangent space to a point on a manifold correctly? To each point $p\in\mathcal{M}$ on an $n$-dimensional manifold $\mathcal{M}$ there exists a tangent space $T_{p}\mathcal{M}$ whose elements are the set of vectors $\lbrace\mathbf{v}\rbrace$ whose 'base' is fixed at $p\in\mathcal{M}$. Given a local coordinate chart, these vectors can be identified with the set of derivative operators which encode information about all possible speeds and directions in which one could pass through said point (at which they are bound to). The tangent space to a particular point will be an $n$-dimensional vector space, and thus, in general, contains an infinite number of vectors (as one can construct an infinite number of vectors from a chosen $n$-dimensional basis). As such, once a point is chosen, one can (essentially) independently choose a vector in the tangent space to that point [This part I'm very unsure of?!] So, as I understand it, given this one can construct a new manifold by taking the disjoint union of the tangent spaces of all the points on the manifold. This new manifold is called the tangent bundle, $$\mathcal{TM}= \bigcup_{p\in\mathcal{M}} T_{p}\mathcal{M}$$ Intuitively I kind of see how this is a $2n$-dimensional manifold, as for each point $p\in\mathcal{M}$ on the $n$-dimensional manifold $\mathcal{M}$ there is an $n$-dimensional tangent space $T_{p}\mathcal{M}$, and as such a point in the manifold $\mathcal{TM}$ is an ordered pair, $(p,\mathbf{v})\in \mathcal{TM}$, uniquely determined by specifying a point $p\in\mathcal{M}$ and a vector $\mathbf{v}\in T_{p}\mathcal{M}$ in the tangent space to that point. However, my confusion arises in why we can treat $p$ and $\mathbf{v}$ as independent variables (surely we need to specify a particular value of $p$ be we can choose a tangent vector $\mathbf{v}$. If they were truly independent shouldn't it be possible to choose them in any order, e.g. choose a $\mathbf{v}$ be choosing a value $p$)?","['vector-analysis', 'differential-geometry']"
1133316,"Of fibonomials, pellonomials, and tribonomials, etc","I. Linear recurrence with order 2 Given the Fibonacci numbers $F_n$, we have $$\begin{aligned}
&F_n+F_{n+1}-F_{n+2}=0\\[1mm]
&F_n^2-2F_{n+1}^2-2F_{n+2}^2+F_{n+3}^2=0\\[1mm]
&F_n^3+3F_{n+1}^3-6F_{n+2}^3-3F_{n+3}^3+F_{n+4}^3=0\\
&\small\text{and so on.}
\end{aligned}$$ The coefficients are called fibonomials . (The version for the Pell numbers are quaintly called the pellonomials .) II. Linear recurrence with order 3 For the tribonacci numbers $T_n$, we have, $$\begin{aligned}
&T_n+T_{n+1}+T_{n+2}-T_{n+\color{brown}3}=0\\[1mm]
&T_n^2 - T_{n + 2}^2 + 6T_{n + 3}^2 - 3T_{n + 4}^2 - 2T_{n + 5}^2 + T_{n + \color{brown}6}^2 = 0\\[1mm]
&T_n^3 - 2T_{n + 1}^3 + 2T_{n + 2}^3 - T_{n + 3}^3 - 14T_{n + 4}^3 \;\;+\;\; \dots \;\;+\;\; T_{n + \color{brown}{10}}^3 = 0\\
\end{aligned}$$ Notice that $3,6,10$ (and next is $15$) are generated by $m=\tfrac{1}{2}(k+1)(k+2)$. III. Question: Given a linear recurrence of order $d$, $$s_n = a_1s_{n-1}+a_2s_{n-2}+\dots+a_ds_{n-d}$$ with $a_d\neq0$. Assume one can find a formula valid for all positive integer $n$, $$c_0s_n^k+c_1s_{n+1}^k+c_2s_{n+2}^k+\dots+c_{m}s_{n+m}^k=0$$ with integer $c_i$ and positive integer $k$. How do we show that the required $m$ is a function of $k$ (and $d$) and in fact is a figurate number ? Hence, $$\begin{array}{|c|c|c|}
\hline
\text{Order}\; d&m&\text{Name}\\
\hline
2&k+1&\text{linear}\\
\hline
3&\tfrac{1}{2}(k+1)(k+2)&\text{triangular numbers}\\
\hline
4&\tfrac{1}{6}(k+1)(k+2)(k+3)&\text{tetrahedral numbers}\\
\hline
\end{array}$$ P.S. I tested it with the Padovan sequence $P_n = 1, 1, 1, 2, 2, 3, 4, 5, 7, 9,\dots$ (and others with 3rd order) and it has the same pattern, $$\begin{aligned}
&P_n+P_{n+1}-P_{n+\color{brown}3}=0\\[1mm]
&P_n^2 - P_{n + 1}^2 + P_{n + 2}^2 - P_{n + 3}^2 - P_{n + 4}^2 - P_{n + 5}^2 + P_{n + \color{brown}6}^2 = 0\\
\end{aligned}$$ and so on. I also tested the tetranacci sequence and for $k = 1,2,3$ we have $m=4,10,20$ which are the first tetrahedral numbers.","['fibonacci-numbers', 'recurrence-relations', 'sequences-and-series']"
1133325,"Given an irreducible representation, is there a *unique* unitary representation that it is equivalent to?","I might need help here in understanding my own question in places and please don't hesitate in asking for edits and clarifications. Background : A representation $\rho$ of a finite group $G$ is a group homomorphism from $G$ into $GL(V)$ for some vector space $V$. If $W$ is a subspace of $V$ invariant under $\rho(G)$, then $\rho_{\left.\right|W}$ is called a subrepresentation. In the usual way we can show that every representation is a direct sum of irreducible representations. If we endow $V$ with an inner product $\langle \cdot,\cdot\rangle$, then we can show that
$$\langle u,v\rangle_\rho=\sum_{t\in G}\langle \rho(t)u,\rho(t)v\rangle$$
is another and furthermore, with respect this inner product, the operators $\rho(s)$ are unitary. Where $d_i$ is the dimension of the vector space $V_i$, where $\rho_i:G\rightarrow GL(V_i)$ it can be shown that the regular representation, which acts on the vector space $V_r=\mathbb{C}^{|G|}$, can be decomposed as $$V_r=d_1V_1\oplus d_2V_2\oplus\cdots d_nV_n,$$
where $\{\rho_i\}_{i\in[n]}$ are the unitary irreducible representations
 $\rho_i:G\rightarrow GL(V_i)$ and so $$r:G\rightarrow GL\left(\bigoplus_{i\in[n]}d_iV_i\right),$$
and we write
$$r=\bigoplus_{i\in[n]}d_i\rho_i.$$ Using the fact that the irreducible representations are equivalent to unitary ones allows us to show that the matrix elements of the unitary irreducible representations are orthogonal as elements of $F(G)$ with respect to the inner product
$$\langle f,g\rangle=\frac{1}{|G|}\sum_{t\in G}\overline{f(t)}\cdot g(t),$$ and as there are $|G|$ of them, the matrix elements form an orthogonal basis of $F(G)$. Questions With respect to the canonical basis of $F(G)$, in what sense can I talk about the matrix elements of the unitary irreducible representations? Is there any natural way that the matrix elements of unitary irreducible representations form a basis? Example: I think I have for $G=\mathbb{Z}_3$, that there are unitary irreducible representations $\{\tau,\rho_1,\rho_2\}$ with matrix elements
$$a_0:=\left(\begin{array}{c}1 \\ 1 \\ 1\end{array}\right),\,a_1:=\left(\begin{array}{c}1 \\ \omega \\ \omega_2\end{array}\right) \text{ and }\,a_2:=\left(\begin{array}{c}1 \\ \omega^2 \\ \omega\end{array}\right)\in F(\mathbb{Z_3}).$$ These are written with respect to the canonical basis of $F(\mathbb{Z_3})$ (although everything here is easier as $\mathbb{Z}_3$ is abelian). Consider, with respect to the canonical basis of $F(G)$, 
$$f=\left(\begin{array}{c}1 \\ 2 \\ 3\end{array}\right).$$ With respect to the basis $\{a_0,a_1,a_2\}$ basis, I think $$f=\left(\begin{array}{c}2 \\ \frac{1}{\sqrt{3}}e^{5\pi i/6} \\ \frac{1}{\sqrt{3}}e^{7\pi i/6}\end{array}\right).$$","['linear-algebra', 'finite-groups', 'representation-theory']"
1133327,Vector Laplace equation with constraint,"I want to solve Laplace equation for a vector $\boldsymbol v=(v_x,v_y)$: $$\nabla^2 \boldsymbol{v}=0$$ but under the constraint that $$(1+v_x)^2+v_y^2=1$$
which becomes $v_y = -(2v_x+v_x^2)^{1/2}$. My boundary conditions are: $$\lim_{r\rightarrow\infty} v(x,y)=0$$
$$v(r=a,\theta)=( \cos(\theta/2), \sin(\theta/2) )$$ Normally, without the constraints, I would have $$\boldsymbol v = \frac{a^{1/2}}{r^{1/2}} ( \cos(\theta/2), \sin(\theta/2) )$$ But how could I use Lagrange multipliers in this situation, if I want to impose the condition $|\boldsymbol{\hat{x}}+\boldsymbol{v}|=1$? Are there any other straightforward methods?","['ordinary-differential-equations', 'physics', 'constraints', 'partial-differential-equations', 'vector-analysis']"
1133346,"Is $L^2(0,\infty;L^2(\Omega)) = L^2((0,\infty)\times \Omega)$?","If $\Omega$ is a bounded $C^1$ domain, is $L^2(0,\infty;L^2(\Omega)) = L^2((0,\infty)\times \Omega)$? Are they the same? I know this is true when instead of $(0,\infty)$ we have a bounded interval.","['bochner-spaces', 'functional-analysis', 'lp-spaces']"
1133434,Prove that if $f: \mathbb{R} \to \mathbb{Q}$ is continuous then $f$ is constant,"Suppose that  $f: \mathbb{R} \to \mathbb{R}$ is continuous and that $f(x) \in \mathbb{Q}$ for all $x \in \mathbb{R}$. Prove that f is constant. I have the idea that because there is an irrational number between any two rational number then if the function is continuous, the function must be constant. But I don't know how to write out a proper proof for it. Any help is appreciated. Thanks in advance.","['continuity', 'real-analysis']"
1133452,Can the Riemann hypothesis be relaxed to say that this matrix A consists of square roots?,"I realize that asking this question is like presenting to a patent attorney a wheel-less skateboard while asking to patent a hoverboard. Anyways. Lagarias version of the Riemann hypothesis sets a bound on the sum of divisors: $$\sigma(n) \le H_n + e^{H_n} \ln H_n$$ where $H_n$ is a harmonic number. The von Mangoldt function matrix, as I call it, can be generated from the matrix product of two matrices: $$A = \left(
\begin{array}{ccccccc}
 1 & 0 & 0 & 0 & 0 & 0 & 0 & \cdots \\
 1 & \sqrt{2} & 0 & 0 & 0 & 0 & 0 \\
 1 & 0 & \sqrt{3} & 0 & 0 & 0 & 0 \\
 1 & \sqrt{2} & 0 & \sqrt{4} & 0 & 0 & 0 \\
 1 & 0 & 0 & 0 & \sqrt{5} & 0 & 0 \\
 1 & \sqrt{2} & \sqrt{3} & 0 & 0 & \sqrt{6} & 0 \\
 1 & 0 & 0 & 0 & 0 & 0 & \sqrt{7} \\  \vdots&&&&&&&\ddots
\end{array}
\right)$$ which is equal to $A(n,k)=\sqrt{k}$ if $k$ divides $n$, else $A(n,k)=0$ The matrix inverse of $A$ is by its terms essentially equal to the matrix: $$B = \left(
\begin{array}{ccccccc}
 1 & 1 & 1 & 1 & 1 & 1 & 1 & \cdots \\
 0 & -\sqrt{2} & 0 & -\sqrt{2} & 0 & -\sqrt{2} & 0 \\
 0 & 0 & -\sqrt{3} & 0 & 0 & -\sqrt{3} & 0 \\
 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 0 & 0 & 0 & 0 & -\sqrt{5} & 0 & 0 \\
 0 & 0 & 0 & 0 & 0 & \sqrt{6} & 0 \\
 0 & 0 & 0 & 0 & 0 & 0 & -\sqrt{7} \\  \vdots&&&&&&&\ddots
\end{array}
\right)$$ which is equal to $B(n,k)=\mu(n)\sqrt{n}$ if $n$ divides $k$, else $A(n,k)=0$ where $\mu(n)$ is the Möbius function defined by: $$\mu(n)=\begin{cases} (-1)^{\omega(n)}=(-1)^{\Omega(n)} &\text{if }\; \omega(n) = \Omega(n)\\
0&\text{if }\;\omega(n) \ne \Omega(n).\end{cases}$$ or as in the Wikipedia page: $\mu(n) =  1$ if $n$ is a square-free positive integer with an even number of prime factors. $\mu(n) =  -1$ if $n$ is a square-free positive integer with an odd number of prime factors. $\mu(n) =  0$ if $n$ has a squared prime factor. The von Mangoldt function matrix is then the matrix product $A$ times $B$: $$T = A.B = \left(
\begin{array}{ccccccc}
 +1&+1&+1&+1&+1&+1&+1&\cdots \\ +1&-1&+1&-1&+1&-1&+1 \\ +1&+1&-2&+1&+1&-2&+1 \\ +1&-1&+1&-1&+1&-1&+1 \\ +1&+1&+1&+1&-4&+1&+1 \\ +1&-1&-2&-1&+1&+2&+1 \\ +1&+1&+1&+1&+1&+1&-6 \\ \vdots&&&&&&&\ddots \end{array}
\right)$$ And the von Mangoldt function is then: $$\Lambda(n) = \sum\limits_{k=1}^{k=\infty}\frac{T(n,k)}{k}$$ as proven by joriki here . or as the Dirichlet generating functions of the columns as proven here by GH from MO at Mathoverflow: $$\Lambda(n)=\lim\limits_{s \rightarrow 1} \zeta(s)\sum\limits_{d|n} \frac{\mu(d)}{d^{(s-1)}}$$ Here comes the hoverboard / wheel-less skateboard: Since according to the explicit formula, the von Mangoldt function is a sum of logarithmic square root waves as follows: $$\sum_{n=1}^{n=k} \Lambda(n) = \Re\left(-\sum _{j=1}^{\infty} \left(\frac{x^{1-\rho _j}}{1-\rho _j}+\frac{x^{\rho _j}}{\rho _j}\right)-\frac{1}{2} \log \left(1-\frac{1}{x^2}\right)+x-\log (2 \pi )\right)$$ or as a Mathematica one-liner from Alex Kontorovich web page: Plot[Re[X - Log[2 Pi] - Log[1 - 1/X^2]/2 - 
   Sum[X^(N[ZetaZero[j]])/(N[ZetaZero[j]]) + 
     X^(1 - N[ZetaZero[j]])/(1 - N[ZetaZero[j]]), {j, 1, 30}]], {X, 
  1.1, 30}] Can the Riemann hypothesis be relaxed/be made precise to say that the so called von Mangoldt function matrix $T$ is a matrix product $T=A.B$ as in the example above? (*Matrix T Mathematica  8*)
nn = 32;
A = Table[
   Table[If[Mod[n, k] == 0, k^(ZetaZero[k]), 0], {k, 1, nn}], {n, 1, 
    nn}];
B = Table[
   Table[If[Mod[k, n] == 0, MoebiusMu[n]*n^(ZetaZero[-n]), 0], {k, 1, 
     nn}], {n, 1, nn}];
MatrixForm[T=N[A.B]] It appears to work for any complex number sequence in the exponents as long as the sum of the two matrices $A$ and $B$'s respective real parts is equal to 1, and the imaginary parts are each others negatives. In other words a condition that applies to any two complex number sequences of that form, of which the zeta zeros are a subset, so no progress. To demonstrate this I have made this variant of the program above: (*Matrix T Mathematica 8 start*)nn = 32;
a = Table[RandomComplex[], {n, 1, 32}]
A = Table[
   Table[If[Mod[n, k] == 0, k^(a[[k]]), 0], {k, 1, nn}], {n, 1, nn}];
B = Table[
   Table[If[Mod[k, n] == 0, MoebiusMu[n]*n^(1 - a[[n]]), 0], {k, 1, 
     nn}], {n, 1, nn}];
MatrixForm[T = Chop[N[A.B]]]
(*end*) which produces matrix $T$. This probably has to do with the elementary fact that: $$n=n^{a} n^{1-a}$$ $n$ is here a substitute for the terms in matrix $T$. So for some arbitrary complex number sequence $a$ like for example: $$a=0.771518+0.640552I,0.192739+0.923147I,0.931096+0.758704I,...$$ or the non-trivial Riemann zeta zeros: $$a=0.5 + 14.1347 I, 0.5 + 21.022 I, 0.5 + 25.0109 I,...$$
we have in general the matrices: $$A = \left(
\begin{array}{ccccccc}
 1 & 0 & 0 & 0 & 0 & 0 & 0 & \cdots \\
 1 & 2^{a_2} & 0 & 0 & 0 & 0 & 0 \\
 1 & 0 & 3^{a_3} & 0 & 0 & 0 & 0 \\
 1 & 2^{a_2} & 0 & 4^{a_4} & 0 & 0 & 0 \\
 1 & 0 & 0 & 0 & 5^{a_5} & 0 & 0 \\
 1 & 2^{a_2} & 3^{a_3} & 0 & 0 & 6^{a_6} & 0 \\
 1 & 0 & 0 & 0 & 0 & 0 & 7^{a_7} \\  \vdots&&&&&&&\ddots
\end{array}
\right)$$ $$B = \left(
\begin{array}{ccccccc}
 1 & 1 & 1 & 1 & 1 & 1 & 1 & \cdots \\
 0 & -2^{1-a_2} & 0 & -2^{1-a_2} & 0 & -2^{1-a_2} & 0 \\
 0 & 0 & -3^{1-a_3} & 0 & 0 & -3^{1-a_3} & 0 \\
 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 0 & 0 & 0 & 0 & -5^{1-a_5} & 0 & 0 \\
 0 & 0 & 0 & 0 & 0 & 6^{1-a_6} & 0 \\
 0 & 0 & 0 & 0 & 0 & 0 & -7^{1-a_7} \\  \vdots&&&&&&&\ddots
\end{array}
\right)$$ Which have the same property as the earlier matrices $A$ and $B$ producing matrix $T$ as the matrix product: $$T = A.B = \left(
\begin{array}{ccccccc}
 +1&+1&+1&+1&+1&+1&+1&\cdots \\ +1&-1&+1&-1&+1&-1&+1 \\ +1&+1&-2&+1&+1&-2&+1 \\ +1&-1&+1&-1&+1&-1&+1 \\ +1&+1&+1&+1&-4&+1&+1 \\ +1&-1&-2&-1&+1&+2&+1 \\ +1&+1&+1&+1&+1&+1&-6 \\ \vdots&&&&&&&\ddots \end{array}
\right)$$","['riemann-hypothesis', 'matrices', 'number-theory']"
1133453,Affine space terminology,"I am wondering about the terminology ""affine space"" in algebraic geometry. As I understand it, given a basis field $k$, the affine space $\mathbb{A}^n$ is simply the space of n-tuples $k^n.$ I know the general definition of an affine space (i.e. a set which admits a transitive and free vector space action).  So I'm guessing that the decision to relabel $k^n$ as $\mathbb{A}^n$ is meant to indicate that elements of this space should not be added, subtracted, ect. Is this indeed the case? (As an aside, differential geometers often seem to write $\mathbb{R}^n$ as $\mathbb{E}^n.$ I have always assumed that this was meant to emphasize that $\mathbb{R}^n$ should be viewed as a vector space but rather as a smooth manifold which does not a priori admit a vector space structure.)","['algebraic-geometry', 'soft-question']"
1133525,Particular solution of $\sin^2(x)$,"I have the differential equation:
$$y'' + y = \sin^2(x)$$ 
and to solve it I need to use variation of parameters and therefore I need to find the form of the particular solution. What is your way of finding the form of the solution? Any suggestions on how to do this would be appreciated.",['ordinary-differential-equations']
1133527,Mixed Boolean Arithmetic Identity,"I'm trying to prove/derive the equivalence of the following formula: $$
x*y = (x \land y) *  (x \lor y) + (x \land \neg y) * (\neg x \land y)
$$ whereas $(\land, \lor, \neg)$ correspond to bitwise operations over Boolean algebra ($B^n, \land , \lor, \neg)$ and arithmetic operations are in integer modular ring $Z/(2^n)$. Rearranging by using DeMorgan rules gives me:
$x * (x \lor y) \land y * (x \lor y)$. However, I cannot simply factor out $(x \lor y)$ so I'm stuck at that point. The issue seems to be, that this whole thing is a non-linear expression . I came across this identity in this paper and was wondering how one could derive/generate such identities.
Similar identities can be found in Hackers Delight chapter 2 (and are much simpler, i.e., linear combinations of the 16 boolean functions). Is it because the last term always equals to zero? How would one prove that? The last term isn't always zero (e.g. $1*524288$). Example in $Z/2^{32}$ $$
4 * 5 = (4 \land 5) * (4 \lor 5) + (4 \land \lnot 5) * (\lnot 4 \land 5)
\equiv (4) * (5) + (4 \land 4294967290) * (4294967291 \land 5)
\equiv (4) * (5) + (0) * (0)
\equiv 20
$$ Update: Let's split the formula into the two parts for easier reference:
$$
t0 = (x \land y) *  (x \lor y) \\
t1 = (x \land \neg y) * (\neg x \land y)
$$ I've used an SMT solver (z3) to prove that for all values of $x,y$ either $t0$ or $t1$ can be $\neq 0$, but not both at the same time. Counter example: $x = 1431655427, y = 427$","['nonlinear-system', 'boolean-algebra', 'abstract-algebra']"
1133544,Proving $\mathrm{SL}_2(\mathbb{R})\trianglelefteq\mathrm{GL}_2(\mathbb{R})$,"I've been struggling to show that $\mathrm{SL}_2(\mathbb{R})$ is a normal subgroup of $\mathrm{GL}_2(\mathbb{R})$. I already proved that $\mathrm{SL}_2(\mathbb{R})\leq\mathrm{GL}_2(\mathbb{R})$ (not shown). Now I want to show that
$$
A\cdot \mathrm{SL}_2(\mathbb{R})=\mathrm{SL}_2(\mathbb{R})\cdot A 
$$
for every $A\in \mathrm{GL}_2(\mathbb{R})$. I know that $\det(AB)=\det(A)\det(B)=\det(B)\det(A)=\det(BA)$. Thus,
$$\det(A\cdot \mathrm{SL}_2(\mathbb{R}))=\det(\mathrm{SL}_2(\mathbb{R})\cdot A )$$
but this does not seem to help me prove normality. I thought that perhaps rearranging in the following form would help: $$
A\cdot \mathrm{SL}_2(\mathbb{R})\cdot A^{-1}=\mathrm{SL}_2(\mathbb{R})
$$
If I can show that $A\cdot \mathrm{SL}_2(\mathbb{R})\cdot A^{-1}$ has determinant 1, then I am done. How can I do this? I would like a hint (no full solutions, please) on how I can proceed. Thanks!","['matrices', 'group-theory', 'abstract-algebra']"
1133558,Product of stochastic integral and brownian motion,"I am trying to compute the following expectation:
$$
M_T = \mathbb E\left[W_T\int_0^T\,t\,d W_t \right]
$$ where $0<t<T$ and $W = (W_t)_{t\geq 0}$ is a standard Brownian Motion started at $0$. I already know the solution is given by $M_T = \int_0^T t\,dt$ thanks to one of the answers given in this other question . This looks trivial, but integration by parts is not working for me (I seem to be getting to the same place over and over) and alternative efforts like finding an expression that is equal in law have not being very fruitful. I have seen in the forum that this case might be similar to this other question , but instead this last one involves working with sines and cosines, thus I have the feeling that in my particular case the solution is much simpler. Is there an strategy to solve products of stochastic integrals and a function of brownian motion?","['stochastic-processes', 'stochastic-integrals', 'probability-theory', 'stochastic-calculus', 'brownian-motion']"
