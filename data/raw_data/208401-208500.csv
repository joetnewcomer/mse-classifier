question_id,title,body,tags
4178126,Mapping Cylinders of inclusions,"So an instructor made the following claim today: Let us consider the inclusion $A \hookrightarrow X$ of topological spaces, and let M be it's mapping cylinder. There is a natural continuous bijection $M \to X \times \{0\} \cup A \times [0,1] \subseteq X \times [0,1]$ , induced by inclusion $X \to X \times \{0\} $ and identity on $A \times [0,1]$ . The claim made was that this may not be a homeomorphism. This seems a little strange to me - the map looked closed. If B is closed in the domain, it is closed when intersected with $X \times \{0\}$ and with $A \times [0,1]$ , and therefore, closed in their union (This looks like it should be true by looking at limit points in the union - at least, for the spaces I can think of). I suppose my error is in this preceding sentence, because I don't have a proof of it. In any case I would appreciate a counterexample to the map being a homemorphism.","['general-topology', 'algebraic-topology']"
4178129,"A tough integral $\int_0^{\infty}\frac{\operatorname{sech}(\pi x)}{1+4x^2}\, \mathrm dx $","I was working on an integral which I found on Quora. I simplified it a lot and ended up with this intgeral $$\int_0^{\infty}\dfrac{\operatorname{sech}(\pi x)}{1+4x^2}\, \mathrm dx $$ I tried converting this into exponential form and using geometric series which ended up in this. $$2\sum_{k=0}^\infty (-1)^k\int_0^\infty \dfrac{e^{-(2k+1)\pi x}}{4x^2+1}\, \mathrm dx $$ I didn't try to solve this using exponential integral, as I am not that much familiar with it. Using Wolfram|Alpha, I figured out that this integral is equal to $\frac{1}{2}\ln{2}$ . The simple answer makes me suspect if the integral is just a tricky one. How can I evaluate this integral, using this method or any other method, except contour integration?","['integration', 'summation', 'definite-integrals', 'geometric-series']"
4178144,Prove a triangular matrix is invertable if and only if all diagonal values are non-zero. [duplicate],"This question already has answers here : Prove that an upper triangular matrix is invertible if and only if every diagonal entry is non-zero. (4 answers) Closed 3 years ago . Let $A \in K^{n×n}$ be an (upper) triangular matrix, so $A = (a_{ij})_{i,j = 1,...,n}$ and $a_{ij} = 0$ for $i > j$ .
Then A is invertable exactly then, when all $a_{ii} \neq 0; i = 1, . . . , n$ . I have proven that If A is invertable then all the diagonal elements have to be non-zero like this: Let A be an invertible Matrix and let one $x_{ii}=0$ . Because A is invertible, it represents a bijective linear transformation, so the kernel of T is trivial, which implies linear independence of the columns of the matrix. Because A is an upper triangular matrix, its diagonal entries represent a linearly independent set of vectors. But if one $x_{ii} = 0$ , then the set of vectors is no longer linearly independent, which is a contradiction. My problems are a) i dont know how to prove the other direction b) I am unsure as to wether this proof works. Any help is appreciated :) P.S.: since we didnt introduce the determinant yet, I am not allowed to just say that the diagonals have to be non-zero, so the determinant is non-zero, so it is invertible...","['matrices', 'inverse']"
4178185,"How can curves approximate curves, but lines cannot approximate lines?","This is my first question on StackExchange, and i have very little knowledge of mathematics to tell if it is a physics issue or a math issue, so any info will be useful. Main question Let's say i want to find the length of a line. Take the following image for reference (1): it is a right triangle, and a naive/wrong way of finding the length of the hypotenuse . Is simple to show how this way of thinking can go wrong with a counterexample, if both smaller sides of the triangle have length $a$ , the hypotenuse has length $a\sqrt{2}$ . While the ""zigzagging"" gives the answer $2a$ . Again, i have a shamefully poor background on Real Analysis, so i could not explain the following main question : How can one of these two ""curvy"" lines approximate the other? My physics professor used this ""zigzagging"" argument (but with curves) to show how to calculate the variation of entropy in a thermodynamic process. And i just could not stop thinking about this problem in the first figure. Some context I had this problem in my mind when i saw this on my thermodynamics book (the book is in Portuguese), it showed how to approximate a small line element with fragments that make up a small Carnot Cycle . I don't think this is important to the discussion, so i will just put info regarding the context, just for curiosity: page 22 of this book (there should be an equivalent in English literature).","['calculus', 'geometry', 'analysis']"
4178190,What are the solutions for $\sinh(y)$ $=$ $(-1)^n$ $\sinh(1)$?,"What I thought first is, assuming two cases Case I : $\sinh(y)$ $=$ $\sinh(1)$ $=>$ $y=1$ Case II : $\sinh(y) = -\sinh(1) = \sinh(-1) => y = -1$ Is this correct way of solving? Or should I convert them into exponential function and solve for $y$ ?","['trigonometry', 'hyperbolic-functions']"
4178208,Finding a general solution of pde,"$(x^2-y^2-u^2)\cdot u_x+(2xy)\cdot u_y=2xu$ how can I solve this partial dif. equation. I try to use Langarange methods This is my solution; $$\frac {dx}{x^2-y^2-u^2}=\frac {dy}{2xy}=\frac {du}{2xu}= λ$$ $$\frac {dy}{2xy}=\frac {du}{2xu}$$ $$\frac {du}{u}-\frac {dy}{y}=0$$ $$\ln u-\ln y=\ln c_1$$ $$\frac {u}{y}=c_1=w$$ then i know that we now need to ﬁnd another function. but i am stuck. $$F(w,v)=0$$ $$w=f(v)$$ can u help me to find $v$ with steps, please?  i would appreciate it if you help.","['characteristics', 'ordinary-differential-equations', 'partial-differential-equations']"
4178215,Is $ \int \frac{f'(x)}{f(x)} \ dx = \log |f(x)| + C$ true for all differentiable functions $f$?,"Let $f$ be a differentiable function. Is the following identity true for all such $f$ ? $$
\int \frac{f'(x)}{f(x)} \ dx = \log |f(x)| +  C
$$ I ask because there exist differentiable functions whose derivatives are not Riemann integrable (see here for instance). On the other hand, if we use the substitution $u = f(x)$ for $f$ on $[a,b]$ , $$
\int_a^b \frac{f'(x)}{f(x)} \ dx  = \int_{f(a)}^{f(b)} \frac{1}{u} \ du
$$ and the RHS appears to be integrable. How can we reconcile this? Any comments, help and explanations are welcome.","['integration', 'riemann-integration', 'calculus', 'derivatives']"
4178222,Behaviour of density function when flattening the hemisphere,"Suppose I keep my hollow sphere centred at the origin and I define a uniform scalar value (say mass density) at each point of it, call it $\phi$ . If I were to smoothly flatten the hemisphere into the $z=0$ plane, I would get a disc. Now, since the mass must remain constant under compression, the new flattened disc has some density function $\rho$ such that: $$ \int_{disc} \rho dA = \int_{sphere} \phi dA$$ That is masses are conserved. Given the functional form of $\phi$ can determine what $\rho$ should be? If not, what about the special case where $\phi$ is uniform? How does the result generalize? Context: I was reading this truly beautiful question on physics stack exchange and after some thought on what went wrong in OP's calculation , I think the question in OP's post will be solved if the answer to the above questions I've asked is answered.","['multivariable-calculus', 'vector-analysis', 'differential-geometry']"
4178226,About the inequality : $x^{x^{x^{x^{x^x}}}}\geq x^{x^{x^{((e-2)(1+e))x\left(1+\sqrt{x}\left((\sqrt{x})^3-1\right)\right)}}}\geq x^{x^{\frac{16}{27}}}$,"This inequality is due to user RiverLi : Let $0<x\leq 1$ then we have : $$x^{x^{x^{x^{x^x}}}}\geq x^{x^{\frac{16}{27}}} \geq 0.5x^2+0.5$$ I propose  another one wich states : Let $0<x\leq 1$ then prove or disprove we have : $$x^{x^{x^{x^{x^x}}}}\geq x^{x^{x^{\left(\left(e-2\right)\left(1+e\right)\right)\left(x+x^{3}-x^{\frac{3}{2}}\right)}}}\geq x^{x^{\frac{16}{27}}} \geq 0.5x^2+0.5$$ Some background : Some days ago user RiverLi proposed an inequality (see reference) with a really nice and clever proof . So the inequality : $$x^{x^{x^{x^{x^x}}}} \geq 0.5x^2+0.5$$ is already proved . So there many tricks we can use to show the refinement I propose .It seems that  each inequality is a steps with two exponents . My attempt : The first LHS is equivalent to : $$x^{x^{x}}\leq \left(e-2\right)\left(e+1\right)x\left(1+x^{0.5}\left(x^{1.5}-1\right)\right)$$ So we can use the lemma (see the reference [1] p136): Let $0<a\leq 1$ and $c>0$ then we have : $$a^c\leq(1−c)^2+ac(2−c)−ac(1−c)\ln(a)$$ But it doesn't works... So if we substitute $y^2=x$ the function : $$h(y)=\left(\left(e-2\right)\left(e+1\right)y^{2}\left(1+y\left(y^{3}-1\right)\right)\right)$$ Is convex for $y\in[0,1]$ .So we can use the same argument as below.A good value is $y=0.51$ it gives us for $x\in(0.14,0.9)$ : $$\left(e-2\right)\left(e+1\right)x\left(1+x^{0.5}\left(x^{1.5}-1\right)\right)\ge 1.193075\left(x^{0.5}-0.51\right)+0.387383\ge x^{x^x}$$ So next we can take the log on both side and use the power series of $x^x$ around $x=1$ wich is well-know .Furthermore I build an inequality wich states : let $x\in[\frac{1}{5},\frac{3}{5}]$ it seems we have : $$x^x\leq \left(x\ln\left(x\right)+1+\left(\left(x\ln\left(x\right)\right)^{2}+\left(x\ln\left(x\right)\right)^{3}\right)\right)^{\frac{1}{3e-e\ln\left(-1+e-e^{2}+e^{3}\right)}}$$ Unfortunately we cannot use the inequality above .Anyway since $f(x)=x^x$ is convex on $(0,1)$ we can use the same way to get someting like $x,x_0\in(0.14,0.9)$ : $$x^{x^x}\leq\exp(\ln(x)(f'(x_0)(x-x_0)+f(x_0))\leq^{?} 1.193075\left(x^{0.5}-0.51\right)+0.387383$$ To works we need to have $x$ near $x_0$ wich is a little bit embarrassing . Edit : We introduce the function : $$t(x)=x^{2x^{x}}$$ It seems that $t(x)$ is convex on $(0,1)$ so we can get inequality like $x\in(0.15,0.19)$ : $$x^{2x^x}\leq \left(\frac{\left(t\left(0.15\right)-t\left(0.19\right)\right)}{0.15-0.19}\left(x-0.15\right)+t\left(0.15\right)\right)\leq \left(1.193075\left(x^{\left(0.5\right)}-0.51\right)+0.387383\right)^{2}$$ Remains to show the convexity of this function $t(x)$ .To show it we stop at the first derivative wich seems to be the product of two increasing function we have : $$a(x)=x^{2x^{\left(x\right)}+x-1.376}$$ It seems that $a(x)$ is increasing on $(0,1)$ And : $$b(x)=x^{1.376}(\ln(x))^{2}+\ln(x)x^{1.376}+x^{0.376}$$ It seems that $b(x)$ is increasing on $(0,1)$ . And we have : $$t'(x)=a(x)* b(x)$$ . Edit 2 : Some ideas to show if $a(x)$ and $b(x)$ are increasing : For $a(x)$ :
We use the formula over the reals : $$(a+b)(a-b)=a^2-b^2$$ Then take the logarithm . For $b(x)$ differentiate and we can substitute as $x=y^{\frac{1}{1.376}}$ before. Correct me if I'm wrong For the second it's equivalent to : $$g(x)=\left(x^{\left(e-2\right)\left(e+1\right)x\left(1+x^{0.5}\left(x^{1.5}-1\right)\right)}\right)>\frac{16}{27}$$ It seems that the function $g(x)$ is convex for $x\in(0,1]$ .So we can use the fact , convex functions lie above their supporting lines . A related result :Let $x\in(0,1)$ then it seems we have : $$x(x^{2}-2x+2)\geq x^{x^{x}}$$ To show it we can use the convexity on $(0,1)$ of : $$v(x)=\frac{\ln\left(x(x^{2}-2x+2)\right)}{\ln\left(x\right)}$$ And : $$j(x)=x^x$$ We can improve the inequality we have on $(0,1)$ : $$\left(x^{1.15}\left(x^{2}-2x+2\right)\right)^{0.85}\geq x^{x^x}$$ Question : How to (dis)prove it ? Reference : About the inequality $x^{x^{x^{x^{x^x}}}} \ge \frac12 x^2 + \frac12$ [1] : Vasile Cirtoaje, ""Proofs of three open inequalities with power-exponential functions"", The Journal of Nonlinear Sciences and its Applications (2011), Volume: 4, Issue: 2, page 130-137. https://eudml.org/doc/223938 https://www.planetmath.org/convexfunctionslieabovetheirsupportinglines","['inequality', 'power-towers', 'real-analysis']"
4178257,How can I show that this set is linearly independent?,"Given the set: $\{(1,β,1),(β,1,0),(0,1,β)\}$ For which values of $β \in \mathbb R$ is the set a basis for $\mathbb R^3$ ? I decided to write the set as a matrix: \begin{bmatrix}1&β&1\\β&1&0\\0&1&β\end{bmatrix} Then through pivoting, I thought I could find out if it is linearly independent with $\dim=3$ , which would make it a basis for $R^3$ . However, I'm stuck. How can I proceed?","['solution-verification', 'linear-algebra']"
4178354,Stochastic dominance in a Banach lattice,"For real-valued random variables $X$ and $Y$ , if $X$ is strictly first-order stochastically dominated by $Y$ , then $\mathbf{E}X < \mathbf{E}Y$ (where $\mathbf{E}$ is the expectation operator, and assuming both expectations are well-defined). Is the same true for random variables that take values in an arbitrary Banach lattice? To be explicit, by strict first-order stochastic dominance I mean that for all $x$ in the Banach lattice, $P(X \ge x) \le P(Y \ge x)$ , and for some $x$ , $P(X \ge x) < P(Y \ge x)$ .","['probability-theory', 'functional-analysis']"
4178366,Condition on endomorphisms satisfying $\operatorname{Ker} f=\operatorname{Im} f$,"Let $E$ a finite dimensional vector space and $f \in \mathcal{L}(E)$ . Show that: $$\operatorname{Ker} f=\operatorname{Im} f \Leftrightarrow (f^2=0) \wedge (\exists h \in \mathcal{L}(E) \mid h \circ f + f \circ h=Id_E)$$ My attempt: I managed to show the $\Leftarrow$ implication. For $x \in \operatorname{Im} f$ , $x=f(y)$ , then $x \in \operatorname{Ker} f$ because $f(x)=f^2(y)=0$ so $\operatorname{Im} f \subset \operatorname{Ker} f$ . For $x \in \operatorname{Ker} f$ , we have $h \circ f(x) + f \circ h(x)=f \circ h(x)=x$ which shows that $x \in \operatorname{Im} f$ . So $\operatorname{Ker} f \subset \operatorname{Im} f \Rightarrow \operatorname{Ker} f = \operatorname{Im} f$ . Now, assuming $\operatorname{Ker} f = \operatorname{Im} f$ , for any $x$ , we have $f^2(x)=f(f(x))=0$ , hence $f^2=0$ . Yet, I can’t figure out the other part of the $\Rightarrow$ implication. I guess we would need to construct explicitly a function $h$ satisfying the equality. Generally in these kind of problems, a trick is to consider the decomposition $E=\operatorname{Ker} f + \operatorname{Im} f$ but it is here clearly not possible. Could anyone give me a hint on how to proceed?",['linear-algebra']
4178383,Unpacking a proof that filter convergence characterizes continuous maps,"Statement: Let $f : (X, \tau) \to (Y, \sigma)$ be a mapping between topological spaces. Then $f$ is continuous iff, whenever $\Phi$ is a filterbase on $X$ converging to a limit $p \in X$ , then the filterbase $f(\Phi)$ converges to $f(p) \in (Y, \sigma)$ . Proof: (i) Suppose $f$ is continuous. Let the filterbase $\Phi$ converge to $p$ (that is, each neighbourhood of $p$ contains some $F \in \Phi$ ). If $N$ is a neighbourhood of $f(p) \in Y$ then $f^{–1}(N)$ is $_1$ a neighbourhood of $p \in X$ so $f^{–1}(N)$ contains some $F \in \Phi$ , that is, $f(F) \subseteq_2 N$ ; therefore $f(\Phi)$ converges $_3$ to $f(p)$ . (ii) Suppose $f$ is not continuous. Then $\exists$ closed $K \subseteq Y$ such that $f ^{–1}(K)$ is not closed in $X$ , so $\exists \ p \in \overline{f^{–1}(K)}$ such that $p \not \in_4 f^{–1}(K)$ . Then $\Phi = \{N \cap f^{–1}(K) : N \in \text{set of neighborhoods of $p$}\}$ is $_5$ a filterbase that converges $_6$ to $p$ . Yet $f(\Phi)$ does not $_7$ converge to $f(p)$ , since $Y \setminus K$ is a neighbourhood of $f(p)$ containing no $f(F)$ for $F \in \Phi$ . My questions (each index in the proof above corresponds to the number of a question below): Suppose $N$ is a neighborhood of $f(p).$ Then by definition of neighborhood,  there some open $G \in \sigma$ s.t. $f(p) \in G \subseteq N$ . Then $p \in f^{-1}(G).$ But $G \subseteq N \implies f^{-1}(G) \subseteq f^{-1}(N)$ . By definition, $f^{-1}(N)$ is a neighborhood of $p$ . Is that correct? (a) Suppose $y \in f(F).$ Then there is $p \in X$ s.t. $f(p) = y.$ And so there's some $F \subseteq X$ s.t. $p \in F$ . By assumption, each neighbourhood of $p$ contains some $F \in \Phi$ and since $f^{-1}(N)$ is a neighborhood of $p$ , we have $F \subseteq f^{-1}(N)$ meaning $p \in f^{-1}(N)$ implying $f(p) = y \in N.$ Is that correct? (b) Why can't we simply say $f(p) \in f(F) \implies f(p) \in N$ as $N$ is a neighborhood of $f(p)$ ? That's true because $\Lambda = \{N \subseteq Y: \exists f(F) \in f(\Phi), \ f(F) \subseteq N\}$ is a filter on $Y$ and $f(\Phi)$ is a base for $\Lambda.$ Since $\Lambda \to f(p)$ , we have $f(\Phi) \to f(p)$ by definition. Is that correct? Since $f^{-1}(K)$ is not closed, $f^{-1}(K) \ne \overline{f^{-1}(K)}$ ? $\Phi$ is a filterbase because $\{p\} \subseteq \left((N_1) \cap f^{-1}(K)\right) \cap \left((N_2) \cap f^{-1}(K)\right)$ (is this correct?) and $\varnothing \not \in \Phi.$ But how do we know the latter? What if $f^{-1}(K) = \emptyset?$ Then $N \cap f^{-1}(K) = \emptyset?$ $\Phi$ converges to $p$ because $N \cap f^{-1}(K) \subseteq N$ and the set of neighborhoods of $p$ - $\mathcal N(p)$ - is a filter on $X$ that converges to $p$ and $\Phi$ is a base for $\mathcal N(p)$ . Is that correct? Suppose $y \in f(F).$ Then $y \in f(N \cap f^{-1}(K))$ . And so there's some $p \in X$ s.t. $f(p) = y.$ That means we can find some $N_1$ s.t. $N_1 \cap f^{-1}(K) \subseteq X$ with $p \in N_1 \cap f^{-1}(K)$ meaning $p \in f^{-1}(K)$ impliying $f(p) \in K$ further implying $f(p) \not \in Y \setminus K.$ Thus $f(F) \not \subseteq Y \setminus K.$ Correct?","['elementary-set-theory', 'proof-explanation', 'general-topology', 'filters']"
4178391,Does the sum of reciprocal of the numbers which digital expansion does not have an even amount of the digits $0-9$ converge?,"Does the sum of reciprocal of the numbers which digital expansion does not have an even amount of the digits $0-9$ converge? An example of a number that wouldn't be added is $\frac{1}{11}$ because $1$ shows up an even amount of times, same with $\frac{1}{1235412134}$ because $2,3,$ and $\space 4$ appear an even amount of times. The sum would be $$\frac{1}{1}+\frac{1}{2}+\frac{1}{3}+\frac{1}{4}+\frac{1}{5}+\frac{1}{6}+\frac{1}{7}+\frac{1}{8}+\frac{1}{9}+\frac{1}{10}+\frac{1}{12}+\frac{1}{13}+\dots+\frac{1}{1222}+\frac{1}{1234}+\dots$$ I think it would diverge because the elements are so close to the sum $\sum_{n=1}^{\infty} \frac{1}{n}$ which diverge, but I don't know how to prove it diverge, so it might converge.","['number-theory', 'convergence-divergence']"
4178420,"Show that $T : [0,\sqrt{3} + \sqrt{5} + \sqrt{7}] \to [0,\sqrt{3} + \sqrt{5} + \sqrt{7}] $ is mixing.","Is this shuffling map on the unit interval mixing ? $$ f(x)  = \left\{
\begin{array}{ccl}
x + (\sqrt{5} + \sqrt{7}) & \text{ if } & 0 < x < \sqrt{3} \\ 
x + (\sqrt{7} - \sqrt{3}) & \text{ if } & \sqrt{3} < x < \sqrt{3} + \sqrt{5} \\ 
x - (\sqrt{3}+\sqrt{5}) & \text{ if } & \sqrt{3} + \sqrt{5} < x < \sqrt{3} + \sqrt{5} + \sqrt{7}\\ 
\end{array} \right. $$ Here $f : [0, \sqrt{3}+\sqrt{5}+ \sqrt{7}] \to [0, \sqrt{3}+\sqrt{5}+ \sqrt{7}] $ yet we could rescale so to be map $f: [0,1] \to [0,1]$ . this is a 1-1 map this exchanges the permutations in the interval $\pi = (3,2,1)$ . it's called an interval exchange map . Such a map is very likely to be ergodic and weak-mixing . Let's review those definitions. for every measurable set $A \in \mathcal{B}$ we have $T^{-1}(A) \subset A$ implies either $\mu(A) = 0$ or $\mu(A) = 1$ . strong mixing $\displaystyle \lim_{n \to \infty} \mu(A \cap T^{-n}B) = \mu(A) \cdot \mu(B)  $ so the two sets $A$ and $B$ are eventually ""independent"". weak-mixing $\displaystyle \lim_{n \to \infty} \frac{1}{n} \left| \sum_{k=0}^{n-1} \mu(A \cap T^{-k}B) - \mu(A)\mu(B) \right|= 0 $ so the ""average"" over all the over lap with the pre-images should be independent. Maybe one could show that the invariant measure of the interval exchange map, is just Lebesgue measure (which served as a replacement for the Riemann integration).  We are guessing as much. Then one could ask what the strong mixing and weak-mixing statements should represent here.  What number theory problem could be represented there? Here is the image after $n = 10^5$ iterations.  So we have $\big\{ (x, T^n (x)) :  x = \frac{m}{10^5} \text{ and }0 < m < 10^5 \big\}$ . This looks like it might be mixing.  Here is after a million ( $n = 10^6$ ) iteratios. There's no formula for the quantative mixing of exchange maps.","['number-theory', 'dynamical-systems']"
4178434,Where do toric varieties appear naturally?,"I'm reading Fulton's book. There's an awesome theorem that classifies all smooth toric surfaces as blowups at points starting from either $P^2$ or some Hirzebruch surface. I want to be more excited about the result rather than the proof, but I don't have intuition to if many surfaces are toric, do we ever meet toric varieties naturally without building them on purpose? It seems rare we'd have a torus action","['algebraic-geometry', 'blowup', 'toric-varieties']"
4178486,$\int_0^{\infty} \frac{\sin x}{x}\frac{\sin \frac{x}{3}}{\frac{x}{3}} dx = \frac{\pi}{2}$ and more general results?,"Problem: evaluate that $\int_0^{\infty} \frac{\sin x}{x}\frac{\sin \frac{x}{3}}{\frac{x}{3}} dx = \frac{\pi}{2}$ and prove if a more general case, $\int_0^{\infty} \frac{\sin x}{x}\frac{\sin \frac{x}{3}}{\frac{x}{3}} \frac{\sin \frac{x}{5}}{\frac{x}{5}} ...  \frac{\sin \frac{x}{2n+1}}{\frac{x}{2n+1}} dx = \frac{\pi}{2}$ holds? So it's a rather well known results to prove Evaluating the integral $\int_0^\infty \frac{\sin x} x \,\mathrm dx = \frac \pi 2$? and I use a computer program to validate that the general case does appear to hold, but not sure how to prove it..","['integration', 'trigonometry', 'definite-integrals']"
4178520,"Evaluating $\sum_{k=-m}^{m}(-1)^k \, e^{-\frac{i\pi k}{m}}\frac{2\left(ze^{\frac{i\pi k}{m}}\right)^2}{\left(ze^{\frac{i\pi k}{m}}\right)^2 - q^2}$","From quite some time I'm struggling on proving that: $$\sum_{k=-n}^{n}(-1)^k \, e^{-\frac{i\pi k}{m}}\dfrac{2\left(ze^{\frac{i\pi k}{m}}\right)^2}{\left(ze^{\frac{i\pi k}{m}}\right)^2 - q^2} = 2z^2m\,\dfrac{q^{m-1}z^{m-1}}{z^{2m} - q^{2m}} $$ where $m = 2n+1$ . My intuition to prove this would be proving that the partial fraction expansion of the right-hand side coincides with the left-hand side. However I've no idea if that would get us anywhere. I'm looking for a real analytic proof but a proof using complex analysis and residue theorem would be most welcomed. Any help or hints would be highly appreciated. Thanks for reading.","['complex-analysis', 'number-theory', 'closed-form', 'real-analysis']"
4178522,Why is this integration proof incorrect?,"I recently came across the fact that $\displaystyle\int_{\frac{m}{a}}^{\frac{n}{a}}\frac{f(ax)}{x}\,dx$ is independent of the value of $a$ . This lead me to this integral here: $\displaystyle \int_0^\infty \frac{\sin(ax) \cos(bx)}{x}\,dx$ . From the above result of independence, it is clear that: $
\begin{align}
\int_0^\infty \frac{\sin(bx+ax)}{x}\,dx &= \int_0^\infty \frac{\sin(bx-ax)}{x}\,dx\\
\int_0^\infty \frac{\sin(bx+ax)}{x}\,dx - \int_0^\infty \frac{\sin(bx-ax)}{x}\,dx &= 0\\
\int_0^\infty \frac{\sin(bx+ax) - \sin(bx-ax)}{x}\,dx&= 0\\
2\int_0^\infty \frac{\sin(ax) \cos(bx)}{x}\,dx&= 0\\
\int_0^\infty \frac{\sin(ax) \cos(bx)}{x}\,dx&= 0.
\end{align}
$ However, it's obvious that this is incorrect by counterexample, say $a = 2$ and $b = 1$ . Where is the mistake in this proof? Is there a restriction on $a$ and $b$ that I need to take into consideration? Any help or guidance would be greatly appreciated!","['integration', 'calculus', 'solution-verification']"
4178533,"What are the odds that after hitting shuffle twice on a 155 unique songs playlist on spotify, 3 of the 6 first songs are the same on both shuffle.","Imagine you have $155$ unique songs in a playlist on Spotify. You hit shuffle. Out of the first $6$ songs, you have $3$ particular songs that we'll name ""song A"", ""song B"", and ""song C"". The order in which these $3$ songs show up within those first $6$ songs doesn't matter. Then, you hit shuffle again and get another set of $6$ songs. $3$ of those $6$ songs are once again A, B, and C. What are the odds of this happening? I'm kinda stuck trying to math this. I know that you have $$\frac{155!}{6!(155-6)!}$$ different ways to select $6$ songs and that would be a denominator for a probability ""P"". You would then get a numerator and multiply $P$ by itself ( $P^2$ ) because we shuffle $2$ times. Anyways, I think that's what I need to do. The numerator is where I get stuck. Not sure how to calculate it. Anyone can help? Am I on the right track?","['combinations', 'probability']"
4178555,'elementary' proof that all matrix with zero trace has the form $AB-BA$,"How to prove the fact mentioned in the title without using the theory of lie algebras? For the record, though questions about this fact has indeed appeared in MSE several times, yet up til now, I think no one has given any 'elementary'(only use linear algebra) proof of this fact on MSE. So it's not a duplicate. Any reference or answer would be greatly appreciated. Thanks in advance. P.S. this question is not equivalent to this: If $V_0$ is the subspace of matrices of the form $C=AB-BA$ for some $A,B$ in a vector space $V$ then $V_0=\{A\in V|\operatorname{Trace} (A)=0\}$ or this: Dimensionality of null space when Trace is Zero","['matrices', 'linear-algebra']"
4178556,A problem about Prime Numbers and Perfect Squares,"Can we find all $n$ such that there exists a prime number $p$ s.t. $1+p+p^2+\cdots+p^n$ is a perfect square, where $n$ is a natural number? For $n=1$ , when $p=3$ , $1+p=4$ , which fits our standards. For $n=2$ , we can know that $p^2<1+p+p^2<1+2p+p^2=(1+p)^2$ , so $1+p+p^2$ cannot be a perfect square. For $n\geqslant3$ , I want to use the identity $x^n-1=(x-1)(x^{n-1}+x^{n-2}+\cdots+1)$ . If there exists a prime number $p$ s.t. $1+p+p^2+\cdots+p^n\;\;(n\geqslant3)$ is a perfect square, let $1+p+p^2+\cdots+p^n=m^2$ . Then, $m^2(p-1)=p^{n+1}-1$ . For the $n\geqslant3$ case, I don't what can I do next, or should I split it into more cases. There are several links below  that focus on particular cases of $n$ . $n=4$ link , another $n=4$ link . Note: $\mathbb{N}=\mathbb{Z}^+$ . I want to clarify that I couldn't find any other questions that are similar to my problem. I hope this is not another duplicate .","['number-theory', 'square-numbers', 'elementary-number-theory', 'prime-numbers']"
4178659,Solving a recursive inequality,"I have the following inequality for $\{x_t\}_{t\geq 0}$ and trying to find an upper bound for $x_t$ . Let $c$ be a constant. $$x_{t+1}\leq c^2\left[x_t+\frac{2t-3}{4}-\frac{tc^t}{2}+\frac{3c^{2t}}{4}\right]+\frac{1}{4}\tag{1}$$ My attempt: If we had an equality instead of inequality in $(1)$ , I would have used generating function of $x_t$ to solve for $x_t$ but for an inequality I don't think I can use generating functions (?). So I tried to think of $x(t)$ as a continuous function of $t$ and $(1)$ being a finite difference approximation. Then: \begin{align*}
x_{t+1}-x_t &\leq (c^2-1)x_t+c^2\left[\frac{2t-3}{4}-\frac{tc^t}{2}+\frac{3c^{2t}}{4}\right]+\frac{1}{4} \\ \\
x_{t+1}-x_t - (c^2-1)x_t &\leq c^2\left[\frac{2t-3}{4}-\frac{tc^t}{2}+\frac{3c^{2t}}{4}\right]+\frac{1}{4} \\ \\
\frac{dx}{dt}-(c^2-1)x &\leq c^2\left[\frac{2t-3}{4}-\frac{tc^t}{2}+\frac{3c^{2t}}{4}\right]+\frac{1}{4} \\ \\
\frac{d}{dt}\left( e^{-(c^2-1)t}x\right) &\leq e^{-(c^2-1)t}c^2\left[\frac{2t-3}{4}-\frac{tc^t}{2}+\frac{3c^{2t}}{4}\right]+\frac{1}{4} \\ \\
\end{align*} and then integrate to find an upper bound on $x=x(t)$ but I'd think this is an approximation for an actual upper bound for $x_t$ and am not sure how to solve $(1)$ with or without using what I did above.","['recurrence-relations', 'discrete-mathematics']"
4178687,How many license plate numbers contain the digit 4 exactly once in the string of $3$ digits (after the region code)?,"So I have been stuck on this question for a few days now and I am honestly just floored at how to get the correct answer. The question is as follows: A license plate number consists of eight characters. The first two characters are a $2$ -character code representing one of $39$ regions. The next three characters are digits $0,1, \ldots,9$ , and the last three characters are capital letters A, B, $\ldots$ , Z. How many license plate numbers contain the digit 4 exactly once in the string of $3$ digits (after the region code)? My initial thought is that the first and last three ""spots"" of the string do not change, so the value will be some multiple of: $39 \cdot 26^3$ . I am extremely confused as to how to approach the digits that are found in the middle of this question, as my initial logic of generating the value $9 \cdot 9 \cdot 1$ (4 has to be used only once, when it is used it is removed from the set of digits) but my professor claims that this does not quite account for the ORDER (??) of the digits. Any explanation of where I am going wrong? Any help would be greatly appreciated.","['combinatorics', 'discrete-mathematics']"
4178706,Intersection of Sphere and Plane - Lagrange Multiplier,"I got a sphere with $x^2+y^2+z^2=1$ and a plane with $x+y+z=1$ . I should minimize and maximize the distance from the intersection to (0,0,0). First thing that threw me off, is that $x^2+y^2+z^2=1$ is centered around $(0,0,0)$ . So, every point that is on the sphere, and therefore every point that is on the intersection, has the same distance to $(0,0,0)$ , right? Not sure what to minimize? Since we are so supposed to use Langrage Multipliers, I tried $$
f:x^2+y^2+z^2=1$$ $$g:x+y+z-1=0
$$ $$
\nabla_f=\nabla_g \lambda,
$$ and got $$\left\{\begin{array}{l}2x=\lambda \\2y=\lambda \\2z=\lambda \end{array}\right.$$ Together with g that gave me $x=y=z=1/3$ . Geometrically I have $(1,0,0),(0,1,0),(0,0,1)$ on my intersection, and I concluded that the intersection is the circle with the center $(1/3,1/3,1/3)$ and radius ${\sqrt2/\sqrt3}$ . Why did the Lagrange Multplier Method give me the center of the circle? Shouldn't it give me the circle itself? I am not sure what I did wrong. Also: Any guesses what one could maximize/minimize here? Every help is much appreciated! Best regards!","['multivariable-calculus', 'lagrange-multiplier', 'real-analysis']"
4178708,mean and variance formula for negative binomial distribution,"The equation below indicates expected value of negative binomial distribution. I need a derivation for this formula. I have searched a lot but can't find any solution. Thanks for helping :) $$
E(X)=\sum_{x=r}^\infty x\cdot \binom {x-1}{r-1} \cdot p^r \cdot (1-p)^{x-r} =\frac{r}{p}
$$ I have tried: \begin{align}
E(X) & =\sum _{x=r} x\cdot \binom{x-1}{r-1} \cdot p^r \cdot (1-p)^{x-r} \\[8pt]
& = \sum_{x=r}^\infty x \cdot \frac{(x-1)!}{(r-1)! \cdot ((x-1-(r-1))!} \cdot p^r \cdot (1-p)^{x-r} \\[8pt]
& = \sum_{x=r}^\infty \frac{x!}{(r-1)!\cdot ((x-r)!} \cdot p^r \cdot (1-p)^{x-r} \\[8pt]
\Longrightarrow & \phantom{={}} \sum_{x=r}^\infty r\cdot \frac{x!}{r!\cdot (x-r)!}\cdot p^r \cdot (1-p{)}^{x-r} \\[8pt]
& = \frac{r}{p} \cdot \sum_{x=r}^\infty \frac{x!}{r!\cdot (x-r)!}\cdot p^{r+1}\cdot (1-p)^{x-r}
\end{align} If the power of $p$ in the last equation were not $r + 1,$ I can implement Newton Binomial. So It will be true. But I am stuck here.","['self-learning', 'statistics', 'probability-distributions', 'negative-binomial']"
4178728,Intuition with multivariate Gaussian distribution conditional probability,"I have a problem with the intuition of the conditional probability. Suppose we have a multivariate normal distribution (bivariate for simplicity) with mean $\mu$ and covariance matrix $\Sigma$ with the following form. I undertand that the intuitive idea of conditional probability is to fix one of the dimensions to certain value doing what would be a ""slice"" to the multivariate Gaussian distribution, something like this . Whose result is another Gaussian distribution with one dimension less, mean $\mu'$ and covariance matrix $\Sigma'$ . Seeing that figure, intuition tells me that the conditioned probability function should vary depending on the fixed point, that is to say, higher and peaked when the fixed point is near the mean $\mu$ and flatter at the extremes. But what I find is that only the mean is affected, the variance is constant regardless of the point. See this and this . How can this be possible, is there something I am misunderstanding? Thank you in advance!","['statistics', 'conditional-probability', 'normal-distribution', 'gaussian', 'probability']"
4178753,"Determinant of ""quasi-circulant"" matrices","Several weeks ago I asked a question regarding the determinant of a $5 \times 5$ matrix: Determinant of a matrix when its diagonal elements have a certain property Here I would like to consider a more general problem:the non-diagonal element will still share a circulant fashion, whereas some of them can be $0$ instead of all being $-1$ . To be more specific, it follows a pattern that in each row, the first $i^{th}$ elements that follow the diagonal element are $-1$ while the rest are $0$ . For instance, in a $5\times5$ case, things can be $A=\begin{pmatrix}
l_1&-1 &-1 &-1&0 \\
0&l_2 &-1 & -1 & -1\\
-1 & 0 &l_3 & -1 &-1\\
-1 & -1 & 0 & l_4 & -1\\
-1 & -1 &-1 & 0 &l_5
\end{pmatrix}$ or $A=\begin{pmatrix}
l_1&-1 &-1 &0 &0 \\
0&l_2 & -1 & -1 & 0\\
0 & 0 &l_3 & -1 &-1\\
-1 & 0 & 0 & l_4 & -1\\
-1 & -1 & 0 & 0 &l_5
\end{pmatrix}$ Again, I would like to know if there is any delicate way to show that det $(A)<0$ when one of the $l_i$ equals to $0$ whereas others are positive. Some of my thoughts:
Consider $l_1=l_2=...=l_n=l$ ( $n$ is the dimension of the matrix). In this case, $A$ is a circulant matrix, and det( $A$ ) can be demonstrated as a polynomial of $l$ . It suffices to show that $l^n$ is the only term with positive coefficient, yet for me this is something too tedious to show.(with all those roots of unity to deal with) I have also tried the matrix determinant lemma, which is helpful when all the non-diagonal elements are $-1$ but not that helpful when some of the non-diagonal elements are $0$ . Any hints or ideas will be greatly appreciated. Thanks! Sorry for not making this clear in the first place, but this is just a conjecture (though I believe this is correct). A counterexample will also be greatly appreciated!","['matrices', 'determinant', 'linear-algebra']"
4178760,How to compute this winding number integral?,"I am trying to compute the following integral: \begin{equation}
I =\frac{1}{2\pi}\int_{-\pi}^{\pi}\frac{ae^{ik}-be^{-ik}}{ae^{ik}+be^{-ik}}dk.
\end{equation} I know that the answer should be that $I = 1$ if $|a|>|b|$ and $I = -1$ if $|a|<|b|$ (since it's a winding number of a curve around the origin I'm trying to find), but I cannot seem to get this. My attempt: \begin{equation}
I =\frac{1}{2\pi}\int_{-\pi}^{\pi}\frac{ae^{ik}-be^{-ik}}{ae^{ik}+be^{-ik}}dk = \frac{1}{2\pi}\int_{-\pi}^{\pi}\left[1-\frac{2be^{-ik}}{ae^{ik}+be^{-ik}}\right]dk = 1-\frac{1}{\pi}\int_{-\pi}^{\pi}\frac{1}{\frac{a}{b}e^{2ik}+1}dk.
\end{equation} But how do I continue from here?","['integration', 'complex-analysis']"
4178766,On the construction of convex $n$-gons with convex $(n-k)$-gons,"I am trying to determine how many convex $(n-k)$ -gons, with their vertices in general position and such that at most they pairwise intersect in one vertex, guarantee that we can construct a convex $n$ -gon using only the vertices of the convex $(n-k)$ -gons. I would like to know if there are some known results, literature in the subject, or some useful lemmas and theorems that you could share to help me. Thanks in advance! EDIT An example of what I mean for $n=4$ would be to ask how many triangles (convex $(4-1)$ -gons) such that their vertices are points in general position (no more than two in the same line) and such that at most they pairwise interesect in one vertex, guarantee that we can construct some convex cuadrilateral using only the vertices of the triangles. In this regard, it is easy to show that two triangles guarantee that we can construct some convex cuadrilateral, as five points in general position guarantee the construction of some convex cuadrilateral (as proved in the context of the the happy ending problem ). Indeed, the question is somewhat related to this last problem, adding the constraint of local independent convexities to the points in general position.","['geometry', 'polygons']"
4178771,What does it mean for a complex function to have a period of 1?,"If a complex valued function $f$ has a period of $1$ does it mean that $f(z)=f(z+1)$ in the same sense as real functions? Moreover, if $f$ has lets say a period, that is not necessarily real say $w$ , is it also the case that $f(z)=f(z+w)$ ?",['complex-analysis']
4178792,Characterization of functions in the Sobolev space $H_0^2(U)$ as zero trace functions in $H^2(U)$,"Firstly, I am wondering if there exists a trace operator $$T:H^2(U)\rightarrow L^2(\partial U)$$ such that it satisfies analogous properties to that of the usual trace operator for functions in $W^{1,p}(U)$ . Secondly, I would like to know if the functions $u\in H_0^2(U)$ are those characterized by the following two conditions $$Tu=0,\quad\frac{\partial u}{\partial\nu}=0\quad\text{on }\partial U$$ Motivation : In problem 3 of section 6 of Evans' PDE book, second edition, it is asserted that the weak formulation corresponding to the boundary problem of the biharmonic equation $$\begin{cases}
		\Delta^2u&=f\quad\text{in }U\\
		u=\frac{\partial u}{\partial\nu}&=0\quad\text{on }\partial U\end{cases}$$ is $$\int_U\Delta u\Delta vdx=\int_U fv$$ for each $v\in H_0^2(U)$ . However, if we want to derive the latter identity, after integrating the equation of the problem, we find out through the third Green identity, that $$\int_U\Delta^2uvdx=\int_U\Delta u\Delta vdx+\int_{\partial U}v\frac{\partial\Delta u}{\partial\nu}dS-\int_{\partial U}\Delta u\frac{\partial v}{\partial\nu}dS$$ In order to obtain the idenity proposed by Evans, we have to impose the boundary conditions $$\frac{\partial v}{\partial\nu}=0,\quad v=0\quad\text{on}\partial U$$ for every $v$ in our space of weak solutions. However, how can we conclude that this completely characterizes functions in $H_0^2(U)$ ? I understand this should be a characterization of such a space, and via aproximation by functions with compact support I can get an idea of why this must be the case, but there is no mention of this fact in Evans' book. I would like to have some references to learn more about this, and the notion of the trace operator extended to other Sobolev spaces, because I am only familiar with the aforementioned book. Thanks in advance for your answers.","['reference-request', 'sobolev-spaces', 'functional-analysis', 'trace-map', 'partial-differential-equations']"
4178843,A trigonometric non-linear differential equation,"I am stuck with the following initial value problem: \begin{equation}
\dot{Y}_t = 4 \arctan(1/Y_t) = 2\pi - 4\arctan(Y_t), \quad Y_0 = y > 0
\end{equation} (These are the same thing, by a trig identity.) I tried rewriting a couple of times, but didn't succeed in determining an explicit solution. Is there one? I appreciate any hint. Edit: If we differentiate, the above line, we get $$
(1+Y_t^2)\ddot{Y}_t + 4 \dot{Y}_t = 0.
$$ This seems helpful. Is this explicitly solvable?","['ordinary-differential-equations', 'real-analysis']"
4178854,How many charts are minimally required to cover any compact 2-manifold?,"As mentioned in one of the answers to the question: Upper bound on the number of charts needed to cover a topological manifold , Every topological $n$ -dimensional manifold $M$ (compact or not) admits a cover by $n+1$ charts. For compact 2-manifolds, are 3 charts really necessary? Can anyone point out an example that minimally requires 3 charts? Is it the real-projective plane? If so, is it true that only 2 charts are required to cover any compact 2-manifold that is not a connected sum of real projective planes with or without holes/boundaries?","['manifolds', 'general-topology', 'surfaces']"
4178863,"Calculate $\iint \sqrt{2-x^2-y^2} \, dx \, dy$ over the circle $x^2+y^2=x\sqrt{2}$","so as my question states I have to calculate $$\iint_\limits A \sqrt{2-x^2-y^2}\,dx\,dy$$ where $A$ is the circle defined by $$x^2+y^2=x\sqrt{2}$$ After introducing polar coordinates $(x = r\cos\theta, y= r\sin\theta)$ , I get that: The left side of the equation of the circle is always nonnegative, so the right side also has to be nonnegative. This means that $x \ge 0$ , or $$\theta \in \left[-\frac{\pi}{2}, \frac{\pi}{2}\right].$$ Also we have that $$r=\sqrt{2} \cos\theta$$ Here's where I have a slight problem. If I think about it, $2-x^2-y^2$ has to be $\ge 0$ for the square root to be real. Now, that means that $r \le \sqrt{2}$ . How do I determine the boundaries of $r$ ? I think that the boundaries for $r$ are $r \in [\sqrt{2}\cos\theta, \sqrt{2}]$ . If yes, could anyone explain why exactly? I'm confused because I don't have an inequality in $r=\sqrt{2}\cos\theta$ !","['integration', 'multivariable-calculus', 'multiple-integral', 'polar-coordinates']"
4178890,Using topological tricks to prove algebraic identities with full generality,"I had a vague idea that algebraic identities proved with such tricks in $\mathbb{R}, \mathbb{C}$ should hold in other rings. In other words, $\mathbb{R}$ or $\mathbb{C}$ does not add new identities, so we can work in those fields without loss of generality. Here are my observations: Let $R$ be a commutative ring with identity. Let's say that we want to prove that $A\operatorname{adj}(A) = \operatorname{adj}(A)A$ for square matrices $A \in M_{n \times n}(R)$ given that $A\operatorname{adj}(A) = \det(A)I$ . First we prove for $R = \mathbb{C}$ . Since the set of singular matrices is Zariski closed in $\mathbb{C}^{n \times n}$ it is nowhere dense in the usual topology, thus we can assume that $A$ is nonsingular. Inverse matrices commute, so we are done. Now since the theory of algebraically closed fields of characteristic zero is complete, the identity(identities) hold in the algebraic closure of the fraction field of $\mathbb{Z}[(x_\alpha)_{\alpha<\kappa}]$ , the polynomial ring in $\kappa$ indeterminates over $\mathbb{Z}$ , where $\kappa$ is an arbitrary cardinal, thus a fortiori in $\mathbb{Z}[(x_\alpha)_{\alpha<\kappa}]$ . Since every commutative ring with identity is a quotient ring of such polynomial rings, we gain the full generality. Furthermore, by elementary arguments, we get $\mathbb{Z}$ has also same identities with $\mathbb{C}$ . So does every commutative ring with characteristic zero. Is this correct?","['matrices', 'abstract-algebra', 'logic', 'field-theory']"
4178905,How are Markov Kernels Related to SDEs,"(Disclaimer: I've been working with SDEs for some years now but have not worked with general Markov processes before... so I'm trying to reconcile some ideas with this post. ) I recently read the definition of a Markov kernel $K$ on a measurable space $(\Omega,\mathcal{F})$ as being a map $K:\Omega,\times \mathcal{F}\rightarrow [0,1]$ satisfying: $\omega \mapsto K(\omega,A)$ is measurable, for any $A \in \mathcal{F}$ , $K(\omega,\cdot)$ is a probability measure on $(\Omega,\mathcal{F})$ for any $\omega \in \Omega$ . Suppose that $(X_t)_{0\leq t\leq 1}$ is an $\mathbb{R}$ -valued solution to the SDE: $$
X_t = \mu(t,X_t)dt + \sigma(t,X_t)dW_t,
$$ for some Brownian motion $(W_t)_{0\leq t\leq 1}$ and some smooth Lipschitz functions $\mu$ and $\sigma$ .  I know that $(X_t)_{0\leq t\leq 1}$ has the Markov property, but how  does this to relate this to a Markov kernel ? In other words... what is the Markov kernel determining $(X_t)_{0\leq t\leq 1}$ . (Excuse me if the question is silly, but I'm self-teaching Markov processes...)","['markov-chains', 'markov-process', 'stochastic-differential-equations', 'probability-theory', 'probability']"
4178918,Use the chain rule to compute the derivative of an inverse function.,"Given a function $f(x)$ , let $g=f^{-1}(x)$ . Then define the composite function $f(g(x))$ . Then, by the Chain Rule, $(f(g(x)))'=f'(g(x)) g'(x)$ . However, since $f(x)$ and $g(x)$ are inverses, $f(g(x))=x$ and $(f(g(x)))'=(x)'=1$ . So $1=f'(g(x)) g'(x)$ . If you solve for $g'(x)$ , you get $$\frac{1}{f'(g(x))}$$ which is the derivative of an inverse function. QED Is the above proof correct and if so, can it be considered mathematically rigorous?","['calculus', 'solution-verification', 'derivatives', 'real-analysis']"
4179009,"The Birth-Death Process, the Umbrella Problem and the running shoes problem, or why is it so difficult to assign Markov Chain states.","Disclaimer: I have been thinking about this problem for 3 days and my previous thoughts, as well as the details of the problem, are in this question , so please take a look there to understand the context. Thanks. Long story short, I had thought of a state assignment that turned out to be wrong because there is some dependency that is not being accounted for. Now, I was solving the MIT OCW problem set on Markov Chains , and I noticed that the first problem is so similar to the umbrella problem. However, the state assignment used in the solution is different. Applying the same logic to the umbrella problem, I will draw the Markov chain for a single place (assume it's home, there is no loss of generality since the other place will have the remaining umbrellas anyway). State $i$ means that this place has exactly $i$ umbrellas. This should be correct since (1) half of the time I'm going from home to office, and the other half I'm going from office to home, (2) For state $0$ , the probability that home stays at $0$ is that [it doesn't rain, or it rains but I'm going from home to office], so $p_{00} = 1-p + \frac{1}{2}p = 1-\frac{1}{2}p$ , and so on. Therefore, the steady state probabilities are each $\frac{1}{5}$ , and the probability that I get wet is that [home is at state $0$ and I am going from home to office and it rains] or [home is at state 4 and I am going from office to home and it rains]. That is, the probability that I get wet should be $\frac{1}{5}\times \frac{1}{2} \times p + \frac{1}{5} \times \frac{1}{2} \times p = \frac{1}{5}p$ . This does not agree with the famous solution for the umbrella problem, which is $\frac{p(1-p)}{5-p}$ . Could somebody please explain to me whether the two problems are actually essentially different, or are there multiple solutions to this problem depending on the initial set of assumptions? And in the latter case, what assumptions have been made here to make the solutions so drastically different?","['conditional-probability', 'markov-chains', 'markov-process', 'probability-theory', 'probability']"
4179064,Number of Derangements of the word BOTTLE,"I am wondering how to calculate the number of derangements for the word BOTTLE. I understand how to actually do the formula for derangements already. My issue is what do you do with repeated letters. Obviously, I will be over counting if I do the typical formula. Makes me think it is the number of derangements with the letter T in their original space, but I am not sure. Can anyone help, as I am wondering if I am supposed to use PIE to solve this. Thanks.","['combinations', 'derangements', 'extremal-combinatorics', 'inclusion-exclusion', 'combinatorics']"
4179099,"Exist or Not ? $\displaystyle \lim_{x\to\infty} \dfrac{1}{x} - \dfrac{1}{x-k}$, $1 \leq k \leq x-1$","I was trying to evaluate $$
\lim_{n\to \infty} \left(\dfrac{n!}{n^n}\right)^{\dfrac{1}{n}}
$$ without resorting to a certain theorem that states : $$
\limsup_{n\to \infty}\; a_n\,^{\frac{\Large 1}{\Large n}} = \lim_{n\to \infty} \left(\dfrac{a_{n+1}}{a_n}\right).
$$ With my own idea: By using the discreet definition of factorial using the product notation (also converting $n^n$ into discreet product) : $$
n! = \prod_{0\leq k \leq n-1} (n-k)= n\cdot\left(\prod_{1\leq k \leq n-1} (n-k)\right)
$$ $$
n^n = \prod_{1\leq k \leq n} n = n\cdot\left(\prod_{1\leq k \leq n-1} n \right)
$$ And by dividing $n-k$ by $n$ and duplicating the limit (one for evaluating the limit inside product notation and another for reminding myself that $x$ goes to $\infty$ ) into two I get this limit : $\displaystyle \lim_{n\to\infty} \prod_{1\leq k \leq n-1} \lim_{n\to\infty}\left(1-\dfrac{k}{n}\right)^{\dfrac{1}{n}}$ (1) Evaluating the inner limit by logarithm and L'Hopital get me into this point : $a =  \displaystyle \lim_{n\to\infty} \dfrac{1}{n} - \dfrac{1}{n-k}$ , $1 < k < n-1$ where $y =  \displaystyle \lim_{n\to\infty} \left(1-\dfrac{k}{n}\right)^{\dfrac{1}{n}}$ , and $a = \ln(y)$ My Question : $1$ ) Does $a$ exist as $k$ varies and goes to $n-1$ ? (Continue to Q $2$ ) $2$ ) How to evaluate it ? (Continuation of Q $1$ ) $3$ ) Is my way of doing the limit at equation (1) valid (Duplicating the limit) ?? $4$ ) Any other way to do $\displaystyle \lim_{n\to \infty} \left(\dfrac{n!}{n^n}\right)^{\dfrac{1}{n}}$ without that sequence theorem I mentioned earlier My opinion about Q $1$ : because the main limit (at the very beginning) exist and has a value, I think somehow $a$ exist, but what confuse me is that $a$ varies between $0$ and $-1$ ( $a = -1$ when $k$ goes to $n-1$ ). Q $2$ : I don't have any idea as $k$ value is varying (at least I know that when $k$ is small then $a$ goes to $0$ , and when $k$ value is approaching $n-1$ then $a$ goes to $-1$ )","['products', 'limits', 'asymptotics', 'real-analysis']"
4179100,Looking for other approaches to evaluate $\lim _{x\to 0^+}\frac{\sin 3x}{\sqrt{1-\cos ^3x}}$,Here is my approach: $$\lim _{x\to 0^+}\frac{\sin 3x}{\sqrt{1-\cos ^3x}}=\lim _{x\to 0^+}\frac{1}{\sqrt{\cos^2x+\cos x+1}}\times\frac{\sin 3x}{\sqrt{1-\cos x}}$$ $$=\lim _{x\to 0^+}\frac1{\sqrt3}\times\frac{\sin 3x}{\sqrt{1-\cos x}}\times\frac{\sqrt{1+\cos x}}{\sqrt{1+\cos x}}=\frac{\sqrt2}{\sqrt3}\times\lim _{x\to 0^+}\frac{\sin 3x}{\sin x}=\sqrt6$$ Can you evaluate $\lim _{x\to 0^+}\dfrac{\sin 3x}{\sqrt{1-\cos ^3x}}$ with other approaches?,"['limits', 'calculus']"
4179102,Integrating product of harmonic functions over sphere,"Im a math major student and taking a course in multivariable calculus. I straggled with the following homework exercise. Let $u,v :\mathbb{R}^n \to \mathbb{R}$ be harmonic functions (i.e. $\Delta u,\Delta v \equiv 0)$ , and let $a,b,p,q>0$ constants such that $ab=pq$ . Prove that: $$
\int_{S^{n-1}}u(ax)v(bx)-u(px)v(qx)\,\mathrm dS(x)=0,
$$ where $S^{n-1}$ is the unit sphere in $\mathbb{R}^n$ . As a context for the problem, I'll add that the main tools we have been taught before this exercise (concerning harnomic functions) are: The average principle, the maximum principle, Liouville's theorem and Poisson kernel My first attempt was to check if the integrand is harmonic but it not seems to be the case. After that I thought to add some function under the integral so the new integrand will become simpler, but I fell short on that attempt too. Can you guys give me direction or a hint?","['multivariable-calculus', 'surface-integrals', 'harmonic-functions']"
4179125,Does removing a closed contractible subset from a closed connected topological manifold leave the resulting manifold connected?,"From looking at small examples, it appears that if you remove a closed contractible subset of a closed, connected topological manifold the resulting manifold will be connected. Is this statement true in this level of generality, or does it require additional assumptions (orientability of the manifold, that the manifold is triangularizable, that the closed subset have nonempty interior, that the boundary of the closed subset is homeomorphic to a sphere...)? Especially nice would be a reference to an existing proof.","['manifolds', 'general-topology']"
4179127,Is there an error in my work book? (Double integral),"Hello it is my first post here! I have integral $$
\iint\frac{x^2}{x^2+y^2}\,\mathrm dx\mathrm dy
$$ over the area bounded by $y=x$ , $2y=x^2$ . I tried to draw the area and it seemed like a pretty straightforward integral. Integrating by $\mathrm dx$ , I have that $x\in[0,2]$ , $y \in [\frac{x^2}{2}, x]$ . The integral then is: $$\int_0^2 \int_{\frac{x^2}{2}}^x \frac{x^2}{x^2+y^2} \,\mathrm dy\mathrm dx$$ (swapped the integrals because I can't integrate by dx first since it's in a boundary) which evaluates to $2 - \frac{\pi}{2}$ . However my workbook says that the solution is $\ln{2}$ . Is there an error?","['integration', 'multivariable-calculus', 'multiple-integral']"
4179133,Expectation of the product of a stopping time and a stochastic process [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question $S_t$ is a geometric Brownian motion, i.e., $dS_t = \mu S_t dt + \sigma S_t dW_t.$ Does the following hold: $$
\mathbb{E}_t (S_T \mathbb{1}_{\left\{ \tau (\delta) < T \right\}}) = \mathbb{E}_t (S_T) \mathbb{E}_t (\mathbb{1}_{\left\{ \tau (\delta) < T \right\}}) $$ where $\tau$ is a stopping time and defined as $$\tau (\delta) = \inf\left\{0<t<T: S_t < \delta\right\}?
$$ I only have some rough intuitions regarding the independence between $S_T$ and $\mathbb{1}_{\tau (\delta) <T }$ : $S_T$ is at the end point and its distribution is independent of the path leading to $S_T$ , while $\mathbb{1}_{\tau (\delta) <T }$ is pretty much dependent on the path, therefore, I thought the equation holds.","['expected-value', 'stochastic-processes', 'stochastic-differential-equations', 'stopping-times', 'probability-theory']"
4179139,"$\triangle ABC$ is an equilateral triangle with circumcentre $O(1,2)$ and vertex $A$ lying on the line $5x+2y=4$.Find area of quadrilateral $BCDE$.","$\triangle ABC$ is an equilateral triangle with circumcentre $O(1,2)$ and vertex $A$ lying on the line $5x+2y=4$ . A circle with
centre $I(2,0)$ passes through the vertices $B$ and $C$ and intersects the sides $AC$ and $AB$ at $D$ and $E$ respectively. Find area of quadrilateral $BCDE$ . My Attempt All I could do here was finding the perpendicular distance of $O$ from the given line. How do I use $I(2,0)$","['analytic-geometry', 'triangles', 'circles', 'geometry']"
4179164,Partial derivative of a fraction with a summation in the denominator,"Suppose I have the following function $$
f(\beta_1,\beta_2,s,p)=\frac{e^{\beta_1 s+\beta_2 s^2}}{\sum_{s=1}^p e^{\beta_1 s+\beta_2 s^2}},
$$ which can be rewritten as $$
e^{\beta_1 s+\beta_2 s^2}\cdot\sum_{s=1}^p e^{-(\beta_1 s+\beta_2 s^2)}.
$$ I would like to find $\frac{\partial f(\beta_1,\beta_2,s,p)}{\partial \beta_1}$ . My approach: $\frac{\partial e^{\beta_1 s+\beta_2 s^2}}{\partial \beta_1} = s \cdot e^{\beta_1 s+\beta_2 s^2} $ $\frac{\sum_{s=1}^p e^{-(\beta_1 s+\beta_2 s^2)}}{\partial \beta_1} = \sum_{s=1}^p -s \cdot e^{-(\beta_1 s+\beta_2 s^2)}$ Yielding according to the product rule: $\frac{\partial f(\beta_1,\beta_2,s,p)}{\partial \beta_1}=s \cdot e^{\beta_1 s+\beta_2 s^2}\cdot \sum_{s=1}^p e^{-(\beta_1 s+\beta_2 s^2)}+e^{\beta_1 s+\beta_2 s^2} \cdot \sum_{s=1}^p -s \cdot e^{-(\beta_1 s+\beta_2 s^2)}$ Can anyone confirm whether or not this is correct? I look forward to your suggestions! Another approach: $\frac{\sum_{s=1}^p e^{(\beta_1 s+\beta_2 s^2)}}{\partial \beta_1} = \sum_{s=1}^p s \cdot e^{(\beta_1 s+\beta_2 s^2)}$ Then using the quotient rule $\frac{\partial f(\beta_1,\beta_2,s,p)}{\partial \beta_1}=\frac{s \cdot e^{\beta_1 s+\beta_2 s^2} \cdot \sum_{s=1}^p e^{(\beta_1 s+\beta_2 s^2)}+ e^{(\beta_1 s+\beta_2 s^2)}\cdot \sum_{s=1}^p s\cdot e^{(\beta_1 s+\beta_2 s^2)} }{(\sum_{s=1}^p\cdot e^{(\beta_1 s+\beta_2 s^2)})^2}$","['partial-derivative', 'summation', 'derivatives']"
4179211,Give an example of a function $f : R → R$ whose graph is invariant under a $90^{\circ}$ rotation about the origin.,"Give an example of a function $f : R → R$ whose graph is invariant under a $90^{\circ}$ rotation
about the origin. The answer to this question was the function $$
f(x) = \frac{x}{|x|} - (-1)^{\lfloor{-|x|}\rfloor}x.
$$ There was no explanation given.
How does one come up with such a complicated function?
The link given below also has some interesting examples , however, I want to know if some standard technique exists for solving such questions. Will the answer be correct if the floor function is replaced by the ceiling function? Finally, is there any place that you think/know such a graph may show up?","['functions', 'polynomials', 'planar-graphs']"
4179258,Sum of iid variables where number of summands is random,"Let $(X_n)$ be a sequence of iid random variables with mean $\mu$ and variance $\sigma^2\lt \infty$ . Set $S_0=0$ and $S_n=X_1+...+X_n$ for $n\ge 1$ . Let $N$ be a bounded non-negative integer-valued random variable which is independent of the sequence $(X_n)$ . a) Show $E(S_N)=\mu E(N)$ . b) Find $E(S^2_N)$ and $\text{Var}( S_N)$ in terms of $\text{Var}(N)$ . Now consider the case where $X_1$ only takes values $1$ and $-1$ . Fix $a\ge 0$ and set $T=\min\{n\ge 0:|S_n|=a\}$ . c) Show $E(S_T)=\mu E(T)$ and find $\text{Var}(S_T)$ I've solved a) and b) using the law of total expectation but I'm at a loss as to why we need the assumption that $N$ is independent of the sequence $(X_n)$ and this is preventing me from making sense of c). For instance, my steps for a) are essentially $E(S_N)=E(E(S_N|N=n))$ $E(S_N)=\sum_n E(S_n)P(N=n)$ $E(S_N)=\sum_n \mu nP(N=n)$ $E(S_N)=\mu E(N)$ The steps for b) are very similar with only algebraic manipulation beyond the above. To the best of my knowledge, every step above did not care about what $N$ is independent of, so, I could just replace $T$ with $N$ thus the results for c) are the same in terms of $E(T)$ and $\text{Var}(T)$ ?(but surely the question setter would not do that). Please don't answer this problem for me, I will be very grateful for a small nudge in the right direction just so I can proceed with the question myself. EDIT: I am interested in whether this question has not been answered because I have explained my intentions poorly or if my case is plausible? Please leave me a comment either way.","['conditional-expectation', 'probability']"
4179268,Asymptotic expansion of $\sum_{k=1}^n {n \choose k} (-1)^k \frac 1 {1-x^k} $,"I'm trying to find the limit (and asymptotic expansion as $n\to\infty $ ) of $$\sum_{k=1}^n {n \choose k} (-1)^k \frac 1 {1-x^k} $$ for $0<x<1$ . So far, I have no idea... I found this question when dealing with the expected value of $\max (X_1, \dots X_n)$ when $X_1, \dots, X_n$ are geometric random variables with same success probability $p$ ... Thus, the expected value is this sum for $x=1-p$ (in absolute value)... Could you help me please ? Thanks in advance.","['limits', 'summation', 'asymptotics']"
4179277,Is there a non-measure-theoretic foundation of probability?,"The mathematical foundations of modern probability theory are based on the works of Kolmogorov who formalized the notion of a probability measure. In my experience this framework has at-worst been counter intuitive, and often quite fruitful to understand, but I have wondered if there are alternative foundations for probability. Is there a mathematically rigorous alternative to measure theory as a foundation for probability theory?","['measure-theory', 'foundations', 'probability-theory']"
4179305,Consecutive multiples of squares,"I noticed $49=1\cdot7^2$ and $50=2\cdot5^2$ , and I was curious if there exists longer runs of this form. Specifically, consecutive positive integers such that the first is a square, the second is twice a square, the third is $3$ times a square, etc.. Messing around trying to find a run of $3$ , I figure the first number $x$ must be odd because the second number is even, and $x$ must be one more than a multiple of $3$ , because the third number is a multiple of $3$ . This means the first number is one more than a multiple of $6$ , and therefore square of a number one more or one less than a multiple of $6$ . Using similar logic, I figured that the second number is twice the square of a number one more or one less than a multiple of $6$ , and the third number is $3$ times the square of an odd number, but that was all I was able to figure. Any help on getting further would be great. Edit:
Trivially, $1=1\cdot1^2, 2=2\cdot1^2, 3=3\cdot1^2, $ etc. besides $49$ and $50$ , I also found $1681=1\cdot41^2$ and $1682=2\cdot29^2$","['number-theory', 'square-numbers', 'sequences-and-series']"
4179341,"$f: [0,1] \to [0,1],$ such that $| (f^n)'(x_0)| \leq e^{-2n}$ $\Rightarrow $ $|f^n(x_0) - f^n(x_0 + h) | \to 0,$ for $h$ small","Let $f:[0,1] \to [0,1]$ be a smooth function and let $x_0\in[0,1]$ such that $$\left|\frac{\mathrm{d}f^n}{\mathrm{d}x}(x_0)\right| <e^{-2n}, \ \forall \ n\in\mathbb N,$$ where $$f^n := f \circ \ldots \circ f,\ n\ \text{times}.$$ I would like to know if the above conditions imply that there exists an open neighbourhood $U_{x_0}$ of $x_0,$ such that $$ y\in U_{x_0}\Rightarrow \lim_{n\to\infty}|f^n(x_0) - f^n(y)| = 0. $$ Or at least, that given $\varepsilon >0,$ $$ y\in U_{x_0}\Rightarrow |f^n(x_0) - f^n(y)|\leq \varepsilon,\ \forall \ n\geq n_0. $$ The only idea that I had was using Taylor expansion. For every $n\in\mathbb N$ we can write $$|f^n(x_0 + h) - f^n(x_0)| = | (f^n)'(x_0)| h + \mathcal O_n(h^2), $$ where $\mathcal O_n$ is function of order $2,$ that depends on $n.$ The problem is that $$|f^n(x_0 + h) - f^n(x_0)| = | (f^n)'(x_0)| h + \mathcal O_n(h^2), $$ but I do not know why $\mathcal O_n(h^2),$ should be uniformly small on $n$ .","['lyapunov-functions', 'dynamical-systems', 'functions', 'real-analysis']"
4179366,How to solve for the angle of an arc in this circumstance?,"This is a shape I came upon during work (3D modelling), and I have been trying to figure out how to better describe it. The shape is comprised of four equal arcs of a circle, such that the radius of each arc is the distance between their midpoints, and the origin of each arc is the midpoint of the arc opposite: How to I determine the angle of the arc, $\theta$ ? I know from playing around graphically that $\theta\approx48.59°$ , but I would love to know how to actually solve for it. It should be noted that $\theta$ is a constant, and is independent of the radius $r$ .","['trigonometry', 'geometry']"
4179385,Prove this multiple integrals equation,"let $T$ be the triangle bounded by the $x$ axis, the $y$ axis, and the line $x+y=1$ . Let $\varphi$ be a continuous function on the interval $[0,1]$ , and $m,n\in \mathbb Z^+$ , Show that $$\iint_T \varphi(x+y)x^my^n\,dx\,dy=c_{mn}\int_0^1 \varphi(t)t^{m+n+1}\,dt$$ where $$c_{mn}=\int_0^1(1-t)^mt^n\,dt$$ First i tried to evaluate the right hand side integral to get the other one, but the integrand is a bit hard to evaluate, so i did this change of variables $$x=u-v\\ y=v$$ So the equation will be $$\iint_T\varphi(u)(u-v)^m v^m \,du\,dv= c_{mn}\int_0^1 \varphi(t)t^{m+n+1}\,dt $$ you may wanna ask where is the jacobian determinant? it’s equal to $1$ . Despite the change of variables, the integrand is still hard to integrate.","['multivariable-calculus', 'multiple-integral']"
4179386,Discontinuities in the expectation of a stopping time (Bayesian coin-tossing),"Suppose a coin is either Unbiased ( $P(\text{Head})=1/2$ ), or Biased with $P(\text{Head})=b\ne{1\over 2}$ , where $b$ is a known value. To decide between Unbiased vs. Biased --assumed equally likely a priori-- we toss the coin until one alternative has a posterior probability at least $9$ times that of the other, deciding in favor of the more probable one. Let $N$ be the number of tosses needed to reach a decision, and consider the expectation $EN(b)$ as a function of $b.$ (We can focus on $b\in(0,{1\over 2})$ , since the function is symmetric about $b={1\over 2}$ .) Here's a plot of Monte Carlo simulation results, with simulation errors less than the width of the ""dots"": The above plot seems unremarkable, but closer inspection suggests that $EN(b)$ is neither monotonic nor continuous on $(0,{1\over 2})$ . In the following plots, the very-light-grey lines give 3-sigma error bounds that vary with sample size from plot-to-plot: These images show, row-wise from the top, apparent ""jump discontinuities"" at $b\approx 0.05054567564, 0.1339745962, 0.1666666666,$ and $0.28867513459.$ (The first is an instance of what seems to be a negative jump, where $EN(b)$ surprisingly decreases .) Numerically, we notice -- and it seems intuitively clear -- that the jumps occur at the ""threshold"" values of polynomials appearing in the definition of $N$ (see the formulation below): $$N:=\inf\left\{n\ge 1:\ 2^nb^{S_n}(1-b)^{n-S_n}\not\in\left({1\over 9},\,9\right)\right\}.$$ Thus, for threshold value $t\in\{{1\over 9},9\}$ , the set of candidate discontinuities is simply $$D_{t}:=\left\{b\in\left(0,{1\over 2}\right): 2^{n}\,b^s\,(1-b)^{n-s}=t,\ n\in\mathbb{Z^+},s\in\{0,\ldots,n\}\right\},$$ and indeed all of the apparent discontinuities that I've so far checked do seem to fall in the set $D_{1\over 9}\cup D_{9};\ $ e.g., the jumps in the top two plots above are at the points in $D_{9}$ with $(s,n)=(1,8)$ and $(0,4)$ , respectively, and the bottom two plots are at the points in $D_{1\over 9}$ with $(s,n)=(2,2)$ and $(4,4)$ , respectively. Question #1 : How to prove that $EN(b)$ is discontinuous at every $b\in D_{1\over 9}\cup D_{9}?$ Can a formula be found to estimate the size and/or direction of the jump? Question #2 : Is it the case that every nonempty open interval $I\subseteq(0,{1\over 2})$ contains an element of $D_{1\over 9}\cup D_{9}?$ Question #3 : Presumably, for any $b\in(0,{1\over 2})$ there is a well-defined proportion of the value $EN(b)$ that's due purely to jump discontinuities at points $b'\in(0,b]$ . What can be said about this quantity as $b\to{1\over 2}?$ (Asymptotically, can a nonzero proportion of the growth be attributed purely to ""jumps""?) Formulation : For $n=1,2,3,\ldots,$ $$\begin{align}(X_1,\ldots X_n)\mid p &\sim \text{i.i.d. Bernoulli($p$),}\\[3mm]
p &\sim\text{Uniform$\left(\left\{{1\over 2},\,b\right\}\right)$},\end{align}$$ where $b\ne{1\over 2}.$ Given $(X_1,\ldots,X_n),$ we have the posterior odds for $\ p=b\ $ vs. $\ p={1\over 2}\ $ as follows (because of the uniform prior, this is the same as the Bayes factor, or likelihood ratio): $$R_n:={P(p=b\mid X_1,\ldots,X_n)\over P(p={1\over 2}\mid X_1,\ldots,X_n)}={P(p=b\mid X_1,\ldots,X_n)\over P(p={1\over 2}\mid X_1,\ldots,X_n)}=2^nb^{S_n}(1-b)^{n-S_n},\quad S_n=\sum_{i=1}^nX_i.$$ The number of tosses required to make a decision is then $$N:=\inf\left\{n\ge 1:\ R_n\not\in\left({1\over 9},\,9\right)\right\}.$$ Since the distribution of $R_n$ is invariant under $b\mapsto 1-b$ , the function $EN(b)$ is symmetric about $b={1\over 2}$ ; hence, WLOG we can take $b\lt {1\over 2}.$","['random-walk', 'expected-value', 'polynomials', 'stopping-times', 'probability']"
4179482,Zero is an interior point of a surjective bounded operator with nonempty kernel,"Let $T$ be a linear bounded operator on a Banach space $X$ over $\mathbb{C}$ , and $T$ is surjective but not injective. Then $0$ is an interior point of the spectrum of $T$ . I came across this question a few days ago. It has been closed, but I want to check my proof of the statement. Proof Preparations: $\ker T := Y$ is a closed subspace of $X$ . We can take a factor $X/Y$ and the respective quotient map $Q$ . It is well-known that $X/Y$ is Banach space w.r.t. the quotient norm $||x + Y|| = \inf_{y \in Y}||x + y||$ . By the inverse mapping theorem $S := TQ$ , which is bijective, has a bounded inverse. Denote $r = 2||S^{-1}|| > 0$ . By the definition of the quotient norm $\forall x \in X$ $\exists x' \in X$ s.t. $Tx' = x$ and $||x'|| \leq r ||x||$ . For any given $x \in X$ we will denote the corresponding $x'$ as $R(x)$ . There are many vectors that fits, but we will assume that only one is chosen for each $x \in X$ . Main part: Fix an arbitrary $\lambda \in \mathbb{C}$ s.t. $|\lambda| \le (3r)^{-1}$ . Fix an arbitrary $x_0 \in Y$ s.t. $||x_0|| = 1$ . Denote $x_n = \lambda^n R^n(x_0)$ , $n \in \mathbb N$ . By the definition of $R$ $||x_n|| \leq (\lambda r)^n \le 3^{-n}$ . Consider an element $w \in X$ defined by the following absolutely convergent series: $$
w = \sum_{n = 0}^\infty (-1)^n x_n.
$$ Since $$
\left|\left|\sum_{n = 1}^\infty (-1)^n x_n\right|\right| \leq \frac 12,
$$ $w$ is a nonzero vector. Now we observe that $$
(T + \lambda E) w = \sum_{n = 0}^\infty (-1)^n T x_n + \sum_{n = 0}^\infty (-1)^n \lambda x_n = \sum_{n = 1}^\infty (-1)^n \lambda x_{n-1} + \sum_{n = 0}^\infty (-1)^n \lambda x_n = 0.
$$ Hence $\ker (T + \lambda E) \neq 0$ , so $-\lambda$ belongs to the spectrum of $T$ (moreover, it's in the point spectrum). Q.E.D.","['spectral-theory', 'operator-theory', 'solution-verification', 'functional-analysis']"
4179509,Volume of the intersection of the unit ball with a polyhedral cone,"Given vectors $x_1,...,x_n\in\Bbb R^d$ . The conic span of these vectors is $$\mathrm{cone}\{x_1,...,x_n\}:=\{\alpha_1 x_1+\cdots +\alpha_n x_n\mid \alpha_1,...,\alpha_n\ge 0\}.$$ Question: Is there a ""simple"" explicit formula for computing the volume of $\mathrm{cone}\{x_1,...,x_n\}\cap \Bbb B^n$ , where $\Bbb B^n$ is the unit ball centered at the origin? $\mathrm{Vol}$ indicates the volume that I am interested in.","['lebesgue-measure', 'convex-cone', 'volume', 'convex-geometry', 'linear-algebra']"
4179550,Calculating $Df$ for $f(z)=\frac{z^3}{\overline{z}}$,"Please verify my attempted solution. How would one calculate ${D}{f}$ for ${f{{\left({z}\right)}}}=\frac{{{z}^{{3}}}}{{\overline{{{z}}}}}$ ? I am aware that $\overline{{{z}}}$ is a nowhere analytic function. If we loosen the problem to ask for ${D}{f}$ instead of ${f}'{\left({z}\right)}$ , we need only find a ${D}{f{{\left({h}\right)}}}$ s.t. the following holds. $${f{{\left({a}+{h}\right)}}}={f{{\left({a}\right)}}}+{D}{f{{\left({h}\right)}}}+{\left|{h}\right|}{\epsilon}{\left({h}\right)}$$ In the above, $\lim_{{{h}\to{0}}}{\epsilon}{\left({h}\right)}={0}$ and $h$ lies in a neighborhood of sufficiently small modulus on the complex plane. $${f{{\left({z}\right)}}}=\frac{{{z}^{{3}}}}{{\overline{{{z}}}}}=\frac{{{\left({x}+{i}{y}\right)}^{{3}}}}{{{\left({x}-{i}{y}\right)}}}$$ Writing ${z}={x}+{i}{y}$ and using the fact that ${\mathbb{{{R}}}}^{{{2}}}$ is isomorphic to ${\mathbb{{{C}}}}$ , we may define ${D}{f}=\frac{{\partial{f}}}{{\partial{x}}}{\left({a}\right)}{\left.{d}{x}\right.}+\frac{{\partial{f}}}{{\partial{y}}}{\left({a}\right)}{\left.{d}{y}\right.}$ . $$\frac{{\partial{f}}}{{\partial{x}}}=\frac{{{3}{\left({x}-{i}{y}\right)}{\left({x}+{i}{y}\right)}^{{2}}-{\left({x}+{i}{y}\right)}^{{3}}}}{{{\left({x}-{i}{y}\right)}^{{2}}}}=\frac{{{3}{\left|{z}\right|}^{{2}}{z}-{z}^{{3}}}}{{{\left(\overline{{{z}}}\right)}^{{2}}}}$$ $$\frac{{\partial{f}}}{{\partial{y}}}=\frac{{{3}{i}{\left({x}-{i}{y}\right)}{\left({x}+{i}{y}^{{2}}\right)}+{i}{\left({x}+{i}{y}\right)}^{{3}}}}{{{\left({x}-{i}{y}\right)}^{{2}}}}=\frac{{{3}{i}{\left|{z}\right|}^{{2}}{z}+{i}{z}^{{3}}}}{{{\left(\overline{{{z}}}\right)}^{{2}}}}$$ $${D}{f}=\frac{{\partial{f}}}{{\partial{x}}}{\left.{d}{x}\right.}+\frac{{\partial{f}}}{{\partial{y}}}{\left.{d}{y}\right.}=\frac{{{3}{\left|{z}\right|}^{{2}}{z}{\left({\left.{d}{x}\right.}+{i}{\left.{d}{y}\right.}\right)}+{z}^{{3}}{\left({i}{\left.{d}{y}\right.}-{\left.{d}{x}\right.}\right)}}}{{{\left(\overline{{{z}}}\right)}^{{2}}}}=\frac{{{3}{\left|{z}\right|}^{{2}}{z}{\left.{d}{z}\right.}-{z}^{{3}}{d}\overline{{{z}}}}}{{{\left(\overline{{{z}}}\right)}^{{2}}}}$$ I find my solution to be inelegant and doubt that it is correct. Although I can't take the true complex derivative, would my reasoning be the most appropriate appeal to MVC? Furthermore, if I were to try and determine when ${D}{f}\in\mathscr{L}_{{{\mathbb{{{C}}}}}}{\left({\mathbb{{{C}}}}\right)}$ , would checking the holomorphicity of ${D}{f}$ suffice? I had read that a linear transform ${L}={P}{\left.{d}{x}\right.}+{Q}{\left.{d}{y}\right.}$ satisfies ${L}\in\mathscr{L}_{{{\mathbb{{{C}}}}}}{\left({\mathbb{{{C}}}}\right)}\Leftrightarrow{Q}={i}{P}$ , which is truly just the Cauchy-Riemann equations. The primary reason that I believe I am mistaken is the fact that my definition for ${D}{f}$ does not appear to be holomorphic on ${\mathbb{{{C}}}}$ or ${\mathbb{{{C}}}}^{{\cdot}}={\mathbb{{{C}}}}\setminus{\left\lbrace{0}\right\rbrace}$ .","['complex-analysis', 'partial-derivative']"
4179582,Showing$ \int_{0}^{\infty} \frac{1-3\cos 2x+2\cos 3x}{x^2} dx=0$,"Showing $$\int_{0}^{\infty} \frac{1-3\cos 2x+2\cos 3x}{x^2} dx=0$$ We can show this by re-writing $I$ as $$
\implies I=6\int_{0}^{\infty}\frac{\frac{1-\cos(2x)}{2x}-\frac{1-\cos(3x)}{3x}}{x}\,\mathrm dx,
$$ which is Frullani Integral . $$J=\int_{0}^{\infty} \frac{f(ax)-f(bx)}{x} dx=[f(\infty)-f(0)]\ln(a/b).$$ Here, $f(x)=\frac{1-\cos(x)}{x},$ hence $I=0.$ So the question is how to show (1), otherwise?","['integration', 'improper-integrals']"
4179624,A function is called nice,"We define a real-valued function to be nice, if $\dfrac{f(x)+f(y)}{2} \ge f\bigg(\dfrac{x+y}{2}\bigg) + |x - y|$ holds for any $x,y \in \mathbb{R}$ . Prove that there doesn't exist any nice functions. My Work: Let $y=-x$ . Then we have, $\dfrac{f(x)+f(-x)}{2} \ge f(0) +2x$ Similarly for $x=y=0$ we have, $f(0) \ge f(0)$ I stopped because I think I am going in a completely wrong direction. Help would be greatly appreciated. Thank you","['functional-equations', 'functions']"
4179634,Visualizing derivatives w.r.t another function,"I came across some derivatives w.r.t functions such as, $\frac{d(7^x)}{d(x^7)}$ , I tried plotting their graphs and seeing how we can relate the change in the value of $7^x$ as the function $x^7$ is changing . Can someone please provide visualization for this specific example or just a general intuitive explanation? Thank you!","['related-rates', 'derivatives']"
4179675,Explicit equation for geodesic mapping,"Let $M$ and $N$ be two Riemannian manifolds. A geodesic mapping is a diffeomorphism $F: M \to N$ . $F$ maps each geodesic arc on $M$ to a geodesic arc on $N$ . I am looking for the explicit equation satisfied by $F$ . For each curve $\gamma$ on $M$ , $F \circ \gamma$ is a geodesic curve on $N$ , that is: for all $\gamma$ such that $\nabla_{\dot{\gamma}} \dot{\gamma} = 0$ , one has $\nabla_{\dot{(F \circ \gamma})} \dot{(F \circ \gamma)} = 0$ which will be expanded out to obtain an equation of $F$ that I am interested in. So far, I have been unable to expand this out.
I think the question is quite natural, but I haven't found a reference yet.","['connections', 'geodesic', 'differential-geometry']"
4179711,"Why is $SL(2,\mathbb{Z}[1/p])$ a group of interest?","Other than ""a natural generalization of $SL(2,\mathbb{Z})$ "" (or any sort of better understood $SL(2,?)$ "" (such as $SL(2,\mathbb{R})$ which is acts isometrically on the upper half plane which lives in the crossroad of many fields), is there any direct reason why one would want to understand this group (and its cohomology ring)? (In case you're wondering, I'm looking at this paper by Adem and Naffah: https://arxiv.org/pdf/math/9503230.pdf ) Thanks in advance, and please pardon my ignorance.","['algebraic-number-theory', 'number-theory', 'abstract-algebra', 'group-cohomology', 'algebraic-topology']"
4179720,Triple integral - how to make a projection on the $xy$ plane?,"I'm starting to study triple integrals. In general, I have been doing problems which require me to sketch the projection on the $xy$ plane so I can figure out the boundaries for $x$ and $y$ . For example, I had an exercise where I had to calculate the volume bound between the planes $x=0$ , $y=0$ , $z=0$ , $x+y+z=1$ which was easy. For the projection on the $xy$ plane, I set that $z=0$ , then I got $x+y=1$ which is a line. However, now I have the following problem: Calculate the volume bound between: $$z=xy$$ $$x+y+z=1$$ $$z=0$$ now I know that if I put $z=0$ into the second equation I get the equation $y=1-x$ which is a line, but I also know that $z=xy$ has to play a role in the projection. If I put $xy=0$ I don't get anything useful. Can someone help me understand how these projections work and how I can apply it here?","['integration', 'multivariable-calculus', 'multiple-integral']"
4179797,Computationally efficient way to compute projection matrix,"Is there some computationally efficient way of computing $(A^\top A)^{-1}$ ?
I would like to know this cause I want to compute the projection matrix $$
P = A(A^\top A)^{-1} A^\top
$$ efficiently.","['matrices', 'linear-algebra', 'numerical-linear-algebra', 'projection-matrices', 'matrix-decomposition']"
4179802,"Don't need help solving this problem, just need some info. A push in the right direction would be nice.",Find $\displaystyle\frac{dy}{dx}$ given that $$\sqrt{3x^7+y^2}=\sin^2y+100xy.$$ Should I start off by squaring both sides to get rid of the radical on the left? And then start the derivative process? Thank you. This is what I have so far: Differentiating both sides with respect to $x$ : $$\begin{align}\frac{21x^6+2y\displaystyle\frac{dy}{dx}}{2(3x^7+y^2)^{1/2}} &= 2\sin(y) \cos(y) \cdot \displaystyle\frac{dy}{dx} +100\left(y+x\displaystyle\frac{dy}{dx}\right)\end{align}$$ I think I had made the left side $1/2$ to get rid of the root and forgot to apply it to the right side of the equation. – I'm at $$3x^7+y^2=(\sin^2y+100xy)^2$$ then I think I would start from left to right until they are all in their derivative form?,"['calculus', 'implicit-differentiation', 'derivatives']"
4179824,"Prove that $f(n)=n$, $\forall n \in \mathbb N$ for the strictly increasing multiplicative function [duplicate]","This question already has answers here : Let $(a_n)$ be a strictly increasing sequence of positive integers such that: $a_2 = 2$, $a_{mn} = a_m a_n$ for $m, n$ relatively prime. (2 answers) Closed 3 years ago . Problem Let $f : \mathbb{N}\to\mathbb{N}$ be a strictly increasing function such that $f(2) = 2$ and $f(mn) = f(m) \cdot f(n)$ for every relatively prime pair of positive integers $m$ and $n$ . Prove that $f(n) = n$ for every positive integer $n$ . My approach I tried to prove this using induction. For the base case, we need to find $f(3)$ . We have $$f(3) \cdot f(5)<2f(9)<4f(5)$$ $$\implies f(3)<4$$ And since $f(3)>f(2)=2$ , we have $f(3)=3$ . Now, we assume that $f(k-1)=k-1$ and $f(k)=k$ . Since $k$ and $k-1$ are relatively prime, we have $f(k(k-1))=f(k)f(k-1)=k(k-1)$ . But this does not prove. So, how do I complete the proof?","['contest-math', 'functional-equations', 'elementary-number-theory', 'functions', 'induction']"
4179825,"For which $n\in\Bbb N$ can we divide $\{1,2,3,...,3n\}$ into $n$ subsets each with $3$ elements such that in each subset $\{x,y,z\}$ we have $x+y=3z$?","For which $n\in \mathbb{N}$ can we divide the set $\{1,2,3,\ldots,3n\}$ into $n$ subsets each with $3$ elements such that in each subset $\{x,y,z\}$ we have $x+y=3z$ ? Since $x_i+y_i=3z_i$ for each subset $A_i=\{x_i,y_i,z_i\}$ , we have $$4\sum _{i=1}^n z_i=\sum _{i=1}^{3n}i = {3n(3n+1)\over 2}  \implies  8\mid n(3n+1) $$ so $n=8k$ or $n=8k-3$ . Now it is not difficult to see that if $k=1$ we have such partition. For $n=5$ we have: $$A_1= \{9,12,15\},  A_2= \{4,6,14\}, A_3= \{2,5,13\}, \\A_4= \{10,7,11\}, A_5= \{1,3,8\}$$ For $n=8$ we have: $$A_1= \{24,21,15\},  A_2= \{23,19,14\}, A_3= \{22,2,8\}, A_4= \{20,1,7\}, \\A_5= \{17,16,11\}, A_6= \{18,12,10\}, A_7= \{13,5,6\}, A_8= \{9,3,4\}$$ What about for $k\geq 2$ ? Some clever induction step? Or some ''well'' known configuration? Source: Serbia 1983, municipal round, 3. grade","['contest-math', 'combinatorial-designs', 'graph-theory', 'combinatorics', 'constructive-mathematics']"
4179839,"Bochner integral of a function from $[0,1]$ to $c_0$","I want to compute the Bochner integral of the function $$
f: [0,1]\to c_0\,, \quad f(x)= \left( \frac{\cos nx}{n} \right)_{n\in\mathbb N}.
$$ First, I need to check for strong measurability. Since $c_0$ is separable, strong and weak measurability coincide. However, how do I check whether the preimages of Borel sets (or open sets) are Borel?
It seems very hard to think about the preimages of sets of null sequences. For now, I'll just assume that it is measurable. Then $f$ is Bochner integrable if the function $$
x \mapsto \|f(x)\|_\infty
= \sup_{n \in \mathbb N} \left\vert\frac{\cos nx}{n}\right\vert
$$ is integrable. This is, of course, true because $\cos$ is bounded and thus $\cos(nx)/n \to 0$ . Now, how can I compute $ \int_{[0,1]} f\,\mathrm d\lambda$ ? By definition, I would need to find a sequence of simple functions $f_n: [0,1] \to c_0$ that converges to $f$ or the Hahn-Banach theorem could be used?","['integration', 'measure-theory', 'lebesgue-integral', 'functional-analysis']"
4179841,"Prove if $P(A \cup B) \le P(A \cap B)$, then $P(A) = P(B)$.","I am unsure if my thought process for proving this inequality is correct. This is what I have so far: $$
P(A \cup B) = P(A) + P(B) - P(A \cap B) ≤ P(A \cap B)
$$ $$
P(A) + P(B) \le 2  P(A \cap B)
$$ $$
P(A) + P(B) \le 2 P(A) P(B)
$$ and in order for the last line to be possible, $P(A)$ and $P(B)$ have to be $0$ , thus $P(A) = P(B)$ . This doesn't seem right because I feel like there should be more cases than just $0$ for this inequality to be true and I was wondering if anyone could help guide me in the right direction.","['probability-theory', 'probability']"
4179849,$U$ unitary: $\mathbb{T}\ne\sigma(U)$. Prove $\forall\varepsilon>0$ there exists a polynomial $p(z)$ such that $\|U^{-1}-p(U)\|<\varepsilon.$,Let $U$ be a unitary operator: $\mathbb{T}=\{\lambda:|\lambda|=1\}\setminus\sigma(U)\ne\varnothing$ (the spectrum does not cover the whole circle). Prove that $\forall\varepsilon>0$ there exists a polynomial $p(z)=\sum\limits_{i=0}^Nc_iz^i$ such that $\|U^{-1}-p(U)\|<\varepsilon.$ What can I say is that $\exists\lambda\in\mathbb{T}: U-\lambda I$ is invertible. It feels like functional calculus for unitary operators must be useful. Can you please help me? Any hint is appreciate.,"['functional-calculus', 'operator-theory', 'polynomials', 'functional-analysis', 'spectral-theory']"
4179964,Is it possible for a finite group to have two isomorphic subgroups which is maximal and non-maximal,"Let $G$ be a finite group. Is it possible that there exist two subgroups $H$ and $L$ of $G$ such that the following three conditions hold: $H \cong L$ $H$ is maximal in $G$ $L$ is not maximal in $G$ Any example is welcomed. Thanks in advance. Edit: This problem comes from computing unfactorizable morphisms in transporter category of group $G$ . I searched for all subgroup of $S_5$ (See for the lattice of S5 ) containing a subgroup of order 2 and find out that if the 2-order subgroup is maximal so is all other 2-order subgroup. This is also true for subgroups containing 3-order subgroup. On the other hand, I searched the key world ""maximal subgroup"" in Dummits AA book, find no useful result to disprove the statement. I Also find no related result on the internet. So I conjecture that the answer is negative. But maybe a big finite group can be an example?","['group-theory', 'abstract-algebra']"
4179966,Showing $\Delta(\Omega^p M)=d(\Omega^{p-1}M)\oplus \delta(\Omega^{p+1}M)$ [duplicate],"This question already has an answer here : Solvability of Poisson's equation for $p$-forms directly from Hodge decomposition (1 answer) Closed 3 years ago . Let $M$ be a compact Riemannian manifold, $*$ be the Hodge star operation, $d$ the exterior derivative, $\delta$ the codifferential $(\delta\omega=(-1)^{n(k+1)+1} *d*\omega$ where $n=\dim M$ and $k=\deg \omega$ ), and $\Delta=d\delta+\delta d $ the Laplacian operator. How can we show that $\Delta(\Omega^p M)=d(\Omega^{p-1}M)\oplus \delta(\Omega^{p+1}M)$ ? (Here $\Omega^pM$ denotes the space of $p$ -forms on $M$ .) To show this, we have to show the followings: $d(\Omega^{p-1}M)\subset \Delta(\Omega^pM)$ and $\delta(\Omega^{p+1}M)\subset \Delta(\Omega^pM)$ , $d(\Omega^{p-1}M)\cap \delta(\Omega^{p+1}M)=0$ , and $d(\Omega^{p-1}M)+\delta(\Omega^{p+1}M)=\Delta(\Omega^pM)$ . The third one is obvious by definition of $\Delta$ . The second one follows from the fact that they are orthogonal. But how can we show 1?","['hodge-theory', 'riemannian-geometry', 'smooth-manifolds', 'differential-forms', 'differential-geometry']"
4180023,Embedding of valued fields,"I am reading this Lecture notes on the model theory of valued fields. On p.71, he states the following lemma: 6.12. Lemma. If $(K, v, \Gamma)$ is $\aleph_{1}$ -saturated, then the discrete valued field $(\dot{k}, v, \mathbb{Z} 1)$ is complete. which is left as an exercise. I cannot prove it on my own. My attempt: I know that $\mathcal{M}$ is saturated if every type over a subset of smaller cardinality than M is realized. But I do not know how to actually use that. I would apprecaite any help or reference to a paper or a book where this lemma is proven.","['field-theory', 'abstract-algebra', 'logic', 'extension-field']"
4180028,Triple integral - cylindrical coordinates problem,"I have to figure out this here integral: $$\iiint \sqrt{x^2+y^2} dxdydz$$ in the boundaries $x^2+y^2=z^2$ , $z=1$ , $z=2$ Now, I know that the intersection of the two planes and the conic are circles. The area itself is the area between those planes. Now, if I introduce cylindrical coordinates: $x=r\cos\phi$ $y=r\sin\phi$ $z=z$ If I plug this in, I get that $r^2 = z^2$ , which after substituting the two values of $z$ I get that $r \in [1,2]$ $\phi \in [0, 2\pi]$ But what about the boundaries for $z$ ? Surely they can't be $z \in [1,2]$ ! I'm at a loss here, because if I express the boundaries for $z$ to be $ \in [1,2]$ , what about $r$ ? Could anyone help?","['cylindrical-coordinates', 'multivariable-calculus', 'multiple-integral']"
4180043,differentiation of a piecewise function at a point,"say I have the function $$ f(x)=\begin{cases}
x^{3}\sin(\frac{5}{x}) & x\ne0\\
0 & x=0
\end{cases} $$ I want to prove it is differentiable at $0.$ I first show that it is continuous by: $$ \lim_{x\to0}f(x)=x^{3}\sin(\frac{5}{x})=0 $$ That is because I have a bounded function multiplied by 0.
Now i need to show if f is differentiable and if so,is $f'$ continuous?
I started by doing $$ f'(0)=\lim_{h\to0}\frac{(0+h)^{3}\sin(\frac{5}{0+h})-(0)^{3}\sin(\frac{5}{0})}{h} $$ But I can't seem to understand how do I go about the $\sin (\frac{5}{0})$ part because that doesn't exist.
Do i take 2 limits of $ x\to 0 $ and $h\to 0 $ in that case?
As for the second part of showing that f' is continuous I just differentiated with the product rule and got that: $$ f'(x)=3x^2\sin(\frac{5}{x})-5x\cos(\frac{5}{x}) $$ And after checking both sides I saw that one of them is negative and the other is positive, hence it has different limits at the two sides.
How do I solve these problems by definition?","['calculus', 'derivatives']"
4180061,A fat Cantor set essentially containing a positive measure subset and uncountably many of its translates,"Edit: In writing out more details, I realized I needed to make a slight modification to the question. I switched all proper containments from the old version of the question to ""essential containment"". This question arises in looking for a counterexample to a claim made in the book by Dunford and Schwartz, but seems interesting in its own right. The question I really want to answer is: ""Does there exist a Lebesgue measurable set $C \subseteq [0,1]$ with $m(C)>0$ s.t. for every Lebesgue measurable $m(S \cap C^c) = 0$ s.t. $m(S) >0$ , the set $\{x : m((x+S) \cap C^c) =0\}$ is Lebesgue null?"" It would suffice to show the following claim which seems possibly true:
""Let $C$ a fat Cantor set. Then for every $S \subseteq C$ s.t. $m(S)>0$ , the set $\{x : m((x +S) \cap C^c)=0\}$ is countable."" Edit: Due to a request in the comments, I'll post a simplification of the claim made in Dunford and Schwartz that inspired the question. Let $(A, \mathcal{A},\alpha), (B, \mathcal{B},\beta)$ $\sigma$ -finite measure spaces and $(A \times B, \mathcal{A} \otimes \mathcal{B}, \alpha \times \beta)$ their product. Let $f : A \times B \to \mathbb{R}$ measurable. Then there exists a sequence $\phi_n$ of finite linear combinations of indicators on measurable rectangles (sets of the form $S \times T, S \in \mathcal{A}, T \in \mathcal{B}$ ) s.t. $\phi_n \to f$ pointwise a.e. and $|\phi_n| \leq |f|$ . If we have a set $C$ of the above type, let $D := \{(x,x) + (c,0) : c \in C, 0 \leq x \leq 1\}.$ Then the above property shows that if $\phi$ is a finite linear combination of indicators of measurable rectangles s.t. $|\phi| \leq 1_D$ , then $\phi = 0$ a.e. This contradicts the Dunford and Schwartz claim as we can show that $m(D)>0$ .","['measure-theory', 'cantor-set', 'real-analysis']"
4180071,Prove that operator between Banach spaces is continuous [duplicate],"This question already has an answer here : Weakly continuous operators are continuous (1 answer) Closed 3 years ago . Let $X$ be a Banach space and $A : X \rightarrow X$ linear operator such that for any $\phi\in X'$ operator $\phi \;\circ A$ is continuous. I want to prove that $A$ is also continuous. My work so far I wanted to use closed graph theorem (this situation is quite suitable for this theorem. We have linear operator between Banach spaces) To show that $A$ is continuous using closed graph theorem I should prove that for any $(x_n) \subset X$ , $x_n \rightarrow 0$ , $A(x_n) \rightarrow y$ we have $y = 0$ I tried some tricks, firstly, becuase $\phi \circ A$ is bounded: $$0 \le \|(\phi \circ A)(x_n)\| \le \|\phi\circ A\|\cdot \|x_n\| $$ but becuse $x_n \rightarrow 0$ then $(\phi\circ A )(x_n) \rightarrow 0$ Also because $A(x_n) \rightarrow y$ then $\phi(A(x_n)) \rightarrow \phi(y)$ (becuase $\phi$ is continuous). Out of these two facts we have that $\phi(y) = 0$ And then I tried to somehow prove that $\phi(y) = y$ but I couldn't. I also tried to rewrite somehow $\|y\| \le $ something that tends to $0$ but also I didn't figure out anything. Could you please give me a hand?","['convergence-divergence', 'operator-theory', 'functional-analysis', 'real-analysis']"
4180075,Generalized eigenvector for product of commuting matrices,"Suppose $A,B$ are commuting invertible matrices with a common generalized eigenvector $v$ with eigenvalues $a,b$ respectively. That is, suppose there exist positive integers $K,L$ such that $(A-aI)^K v= 0$ and $(B-bI)^Lv=0$ . Is it true that there exists a positive integer $M$ such that $(AB-abI)^Mv = 0$ ? A bit of context: I came across this while thinking about the analogous version of this for eigenvalues (when $K=1$ and $L=1$ ). This is easy to show. In fact, the above statement is also easy to show if only one of $K=1$ or $L=1$ is true (that is, $v$ is an eigenvector for one matrix and a generalized eigenvector for the other). Proof: WLOG suppose $L=1$ . Then we have \begin{align}
(AB-abI)^Kv &= \sum_{j=0}^K {K \choose j} A^{K-j}B^{K-j}a^jb^jv\\
&= \sum_{j=0}^K {K \choose j} A^{K-j}a^jb^Kv\\
&= b^K(A-aI)^Kv\\
&= 0
\end{align} A natural question: is it true if $v$ is a generalized eigenvector for both matrices?","['generalized-eigenvector', 'linear-algebra', 'eigenvalues-eigenvectors']"
4180100,"Is ""ternary metrizability"" equivalent to pseudometrizability?","Below, $X$ is always a set with at least three elements to avoid triviality. Say that a ternary metric on a set $X$ is a map $t:X^3\rightarrow\mathbb{R}$ with the following properties: Non-negativity : $t(x_1,x_2,x_3)\ge 0$ and $t(x_1,x_1,x_2)=0$ . (However, we may have $t(x_1,x_2,x_3)=0$ even if the $x_i$ s are distinct.) Symmetry : $t(x_1,x_2,x_3)=t(x_{\sigma(1)},x_{\sigma(2)},x_{\sigma(3)})$ for each permutation $\sigma\in S_3$ . Tetrahedral inequality : for all $x_1,x_2,x_3,y$ we have $$t(x_1,x_2,x_3)\le t(x_1,x_2,y)+t(x_1,x_3,y)+t(x_2,x_3,y).$$ The motivating example is $X=\mathbb{R}^{n\ge 2}$ and $t(x,y,z)=$ the area of the triangle with vertices $x,y,z$ . Now say that a topological space $(X,\tau)$ is ternary metrizable iff there is a ternary metric $t$ on $X$ such that $\tau$ is generated by the family of sets $$\{\{y: t(x_1,x_2,y)<\epsilon\}:\epsilon\in\mathbb{R}, x_1,x_2\in X\}.$$ For example, in $\mathbb{R}^3$ the ""area ternary metric"" mentioned above induces the usual topology: the (sub)basic open sets are infinite tubes. My question is: What is the relationship between pseudometrizability and ternary metrizability? The most natural guess is that they coincide exactly, and I do suspect that this is the case. However, I can't prove it (or indeed either of the implications involved) at the moment. It's not even obvious to me that for every metrizable space $(X,\tau)$ there is a ternary metric on $X$ inducing a topology $\sigma\subseteq\tau$ .","['metrizability', 'general-topology', 'metric-spaces']"
4180259,Behavior of inverse of $f(s)=\frac{1}{H_n}\sum_{i=1}^n \left(1-\frac{1}{i}\right)^s\frac{1}{i}$,"Take a function $f$ defined as follows with $H_n$ referring to Harmonic number $$f(s,n)=\frac{1}{H_n}\sum_{i=1}^n \left(1-\frac{1}{i}\right)^s\frac{1}{i}$$ Suppose $g(\epsilon,n)$ is the inverse of this function, ie $f(g(\epsilon,n),n)=\epsilon$ . I'm interested in behavior of $g(\epsilon,n)$ for fixed small $\epsilon>0$ as $n\to \infty$ . Plotting various values, it seems $g(10^{-6},n)\lesssim 10n$ . Can someone see a way to explain this analytically? Edit following Sal's suggestion, problem above can be rewritten as integral for large $n$ , and the inverse in $s$ seems to grow (sub)linearly as well $$f(s,n)\approx \frac{1}{\log n}\int_{i=1}^n \left(1-\frac{1}{i}\right)^{s} \frac{1}{i}$$ notebook Edit Trying to match Katsurda approximate expression, it seems to give good results for x<25 after which it diverges rapidly $$\sum_{j=2}^\infty \frac{(-x)^j}{j!}\zeta(j) \approx x(\log x + 2 \gamma -1)$$ After differentiating expression I get $$\sum_{j=1}^\infty -\frac{(-x)^j}{j!} \approx \log x+2\gamma$$","['integration', 'summation', 'sequences-and-series', 'limits', 'hypergeometric-function']"
4180278,An expected value puzzle,"While working on a larger problem, I encountered this smaller problem that I’ve enjoyed thinking about, but have yet to solve. Shuffle the numbers 0 to 24 into a 5 by 5 matrix. Sort each column in ascending order, then sort each row in ascending order. What’s the expected value of the $(i, j)$ entry?","['sorting', 'matrices', 'expected-value', 'symmetry', 'probability']"
4180309,How to show operator is compact [duplicate],"This question already has an answer here : Show that $T$ is a compact operator (1 answer) Closed 3 years ago . Currently I'm self studying functional analysis, namely compact operators. In the text, the author gives the following example: Example 1 : Let $C_1$ and $C_2$ be positive constants and let $$
M:=\left\{x(t)\in C[a,b]:|x(t)|<C_1\text{ and }|x'(t)|<C_2\right\}.\tag{1}
$$ Then $M$ is relatively compact. I completely understand Example 1 , it makes use of Arzela's theorem. Then the author gives the following example: Example 2 : The operator $$
Ax:=\int_0^tx(\tau)d\tau.\tag{2}
$$ on $C[0,1]$ is a compact operator (use the previous example). My question is fairly straightforward: using Example 1 , how is this operator compact on $C[0,1]$ ? As of now I have the following two definitions of compact operators: Definition 1 : A linear operator $A\colon X\to Y$ is called a compact operator if and only if for every bounded sequence $x_n\in X$ the sequence $Ax_n$ has a Cauchy subsequence. Definition 2 : An linear operator $A\colon X\to Y$ is compact if and only if the image of the unit ball of $X$ is a relatively compact set in $Y$ . Just going off terminology, I would guess that Definition 2 should be used to solve Exercise 2 , but I'm not seeing it through all the way. Any help is appreciated!",['functional-analysis']
4180311,"$M_t = \frac{1}{\sqrt{T_1}} \mathbb{1} (T_1 \leq t) - 2 \sqrt{T_1 \wedge t}, t\geq 0$ is a martingale","I try to solve an old exam question, but I find it difficult. Maybe someone can suggest a hint. Let $\{ T_i | i\in \mathbb{N} \}\subseteq \mathbb{R} _{\geq 0}$ be a homogeneous Poission point process with intensity 1, where we assume $T_1 < T_2 < \dots$ . Let $M_t = \frac{1}{\sqrt{T_1}} \mathbf{1} (T_1 \leq t) - 2 \sqrt{T_1 \wedge t}$ . Let $N_t = \# \{ i\in \mathbb{N} | T_i \leq t \}$ . Let $\mathcal{F} _t = \sigma ( (N_s) _{s\leq t} )$ . Prove that $(M_t)$ is an $(\mathcal{F} _t)$ -martingale. I already showed that $M_t$ is $\mathcal{F} _t$ -adapted by taking a careful look at events of the form $\{  \frac{1}{\sqrt{T_1}} \mathbf{1} (T_1 \leq t) \leq x \}$ and $\{ \sqrt{T_1 \wedge t} \leq x \}$ . I proved integrability by using upper bounds and the integration by parts technique. Now I have to show that $M_t$ satisfies the martingale property. So let $s<t$ . Then: \begin{align*}
E [ M_t | \mathcal{F} _s ] & = E \left [\frac{1}{\sqrt{T_1}} \mathbf{1} (T_1 \leq t) - 2 \sqrt{T_1 \wedge t} \ \mid \ \mathcal{F}_s \right ]\\
& = E \left [\frac{1}{\sqrt{T_1}} \mathbf{1} (T_1 \leq t) \ \mid \ \mathcal{F}_s \right ] - 2  E \left [ \sqrt{T_1 \wedge t} \ \mid \ \mathcal{F}_s \right ] \\
 & = E \left [\frac{1}{\sqrt{T_1}} (\mathbf{1} (T_1 \leq s) + \mathbf{1} (s < T_1 \leq t)) \ \mid \ \mathcal{F}_s \right ] - 2  E \left [ \sqrt{T_1 \wedge t} \ \mid \ \mathcal{F}_s \right ] \\
& = E \left [\frac{1}{\sqrt{T_1}} (\mathbf{1} (N_s \geq 1) + \mathbf{1} (N_s = 0) \cdot \mathbf{1} (N_t - N_s \geq 1))\ \mid \ \mathcal{F}_s \right ] - 2  E \left [ \sqrt{T_1 \wedge t} \ \mid \ \mathcal{F}_s \right ] \\
& = \frac{1}{\sqrt{T_1}} \mathbf{1} (N_s \geq 1) + \frac{1}{\sqrt{T_1}} \mathbf{1} (N_s = 0) \cdot P (N_t - N_s \geq 1)\  - 2  E \left [ \sqrt{T_1 \wedge t} \ \mid \ \mathcal{F}_s \right ] \\
& = \frac{1}{\sqrt{T_1}} \mathbf{1} (N_s \geq 1) + \frac{1}{\sqrt{T_1}} \mathbf{1} (N_s = 0) \cdot (1-\exp(s-t))\  - 2  E \left [ \sqrt{T_1 \wedge t} \ \mid \ \mathcal{F}_s \right ] \\
& = \frac{1}{\sqrt{T_1}} \mathbf{1} (T_1 \leq s) + \frac{1}{\sqrt{T_1}} \mathbf{1} (T_1 > s) \cdot (1-\exp(s-t))\  - 2  E \left [ \sqrt{T_1 \wedge t} \ \mid \ \mathcal{F}_s \right ] \\
& = \frac{1}{\sqrt{T_1}} \mathbf{1} (T_1 \leq s) + \frac{1}{\sqrt{T_1}} \mathbf{1} (T_1 > s) \cdot (1-\exp(s-t))\  - 2  E \left [ \sqrt{T_1} \cdot \mathbf{1} (T_1 \leq s) + \sqrt{T_1} \cdot \mathbf{1} (s < T_1 \leq t) + \sqrt{t} \cdot \mathbf{1} (T_1 > t) \ \mid \ \mathcal{F}_s \right ] \\
& = \frac{1}{\sqrt{T_1}} \mathbf{1} (T_1 \leq s) + \frac{1}{\sqrt{T_1}} \mathbf{1} (T_1 > s) \cdot (1-\exp(s-t))\  - 2  E \left [ \sqrt{T_1} \cdot \mathbf{1} (N_s \geq 1) + \sqrt{T_1} \cdot \mathbf{1} (N_s = 0) \cdot \mathbf{1} (N_t - N_s \geq 1) + \sqrt{t} \cdot \mathbf{1} (N_t = 0) \ \mid \ \mathcal{F}_s \right ] \\
& = \frac{1}{\sqrt{T_1}} \mathbf{1} (T_1 \leq s) + \frac{1}{\sqrt{T_1}} \mathbf{1} (T_1 > s) \cdot (1-\exp(s-t))\  - 2  \sqrt{T_1} \cdot \mathbf{1} (N_s \geq 1) - 2\sqrt{T_1} \cdot \mathbf{1} (N_s = 0) \cdot P (N_t - N_s \geq 1) - 2 \sqrt{t} \cdot P (N_t = 0)  \\
& = \frac{1}{\sqrt{T_1}} \mathbf{1} (T_1 \leq s) + \frac{1}{\sqrt{T_1}} \mathbf{1} (T_1 > s) \cdot (1-\exp(s-t))\  - 2  \sqrt{T_1} \cdot \mathbf{1} (N_s \geq 1) - 2\sqrt{T_1} \cdot \mathbf{1} (N_s = 0) \cdot (1-\exp(s-t)) - 2 \sqrt{t} \cdot \exp(-t)  \\
& = \frac{1}{\sqrt{T_1}} \mathbf{1} (T_1 \leq s) + \frac{1}{\sqrt{T_1}} \mathbf{1} (T_1 > s) \cdot (1-\exp(s-t))\  - 2  \sqrt{T_1} \cdot \mathbf{1} (T_1 \leq s) - 2\sqrt{T_1} \cdot \mathbf{1} (T_1 > s) \cdot (1-\exp(s-t)) - 2 \sqrt{t} \cdot \exp(-t)  \\
\end{align*} I do not know how to proceed further? Can someone give a hint? Thank you in advance. EDIT: I think I need to use the memoryless property somewhere. Also, I possibly made one or more mistakes with $\mathcal{F} _s$ -measurability and conditioning on $\mathcal{F}_s$ .","['measure-theory', 'stochastic-processes', 'poisson-process', 'martingales', 'probability-theory']"
4180314,Number of integer solutions of $a^2+b^2=10c^2$,"Find the number of integer solutions of the equation $a^2+b^2=10c^2$ . I can only get by inspection that $a=3m, b=m,c=m$ satisfies for any $m \in Z$ . Is there a formal logic to find all possible solutions? Any hint? Also i tried taking $a=p^2-q^2$ , $b=2pq$ and $10c^2=(p^2+q^2)^2$ which gives $$\frac{p^2+q^2}{c}=\sqrt{10}$$ which is invalid, since a rational can never be an irrational.","['elementary-number-theory', 'combinatorics', 'diophantine-equations']"
4180328,Calculus of variation - how to make a function stationary?,"I just started learning about the calculus of variations and the following question arose to me: Given some functional $J[y]$ , there exists the notation of a directional derivative defined as $$
\frac{d}{dy}J[y] = \lim_{\epsilon \to 0}\frac{J[y+\epsilon h] - J[y]}{\epsilon}
\quad\quad \quad(1)
$$ which denotes the derivative of $J[y]$ in the direction of the function $h$ (for simplicity let's don't further examine the particularities of the function space at consideration). Now, if we wanted to find a function that makes  the functional $J[y]$ stationary one would similarly to the function-case take the derivative and set it to zero. However, this seems like a very complicated task in this case since there is no particular function with respect to which we could take the derivative which is why one considers a different approach where we assume $\phi$ to be the function which makes $J[y]$ stationary and then consider a small variation $J[\phi + \epsilon h] $ and now want compute $\left[\dfrac{d}{d\epsilon}J[\phi + \epsilon h]\right]_0$ which is a simpler task because one now has to deal with an ordinary derivative instead of a directional $(1)$ . Am I on the correct path of understanding this or did I misunderstand something? If the latter holds, I would appreciate it if someone could maybe clarify those points for me.","['derivatives', 'functional-analysis', 'real-analysis']"
4180393,Doubt about the construction of $ \mathbb R$ by Cauchy sequences.,"The exercise says: Let $S$ be the set of Cauchy sequences of rational numbers. Define the
relation $ \sim $ in $S \times S$ as $(x_n)\sim (y_n)$ if $\lim_{n\to\infty} x_n - y_n =0$ . Prove that this is an equivalence
relation. What is the size of each equivalence class? How many
equivalence classes are? I did the prove that the relation is an equivalence relation and solved how many equivalence classes there are, but I'm not clear about the size of each equivalence class. I think there is the same than the cardinality of $ \mathbb R$ by the construction of $\mathbb R$ by Cauchy sequences, but I'm not sure.","['elementary-set-theory', 'real-analysis']"
4180409,"Help verifying proof about tensor fields in Abraham, Marsden, Ratiu, Manifolds, Tensor Analysis, and Applications","This question is apropos of a comment I received in the question: Lang Fundamentals of Differential Geomety definition of covariant derivative of a tensor field . The comment referred to a proposition in Abraham, Marsden, Ratiu, Manifolds, Tensor Analysis, and Applications (hereafter AMR). In the second edition, it is Proposition 5.2.20 and in the third edition it is Proposition 6.2.20. A complete
understanding of the AMR proposition would be useful in addressing the referred to
question. Proposition. Let $M$ be a finite-dimensional manifold or be modeled on a Banach space
with norm $C^\infty$ away from the origin. Then $\mathcal{T}^r_s(M)$ is isomorphic to $\mathfrak{T}^r_s(M)$ regarded as $\mathcal{F}(M)$ -modules and as real vector spaces. In particular $\mathfrak{X}^*(M)$ is isomorphic to $\mathcal{X}^*(M)$ . [Before citing the proof, here are the definitions given just before the proposition: $$L_{\mathcal{F}(M)}(\mathfrak{X}(M),\mathcal{F}(M))=\mathcal{X}^*(M)$$ the $\mathcal{F}(M)$ -linear mappings on $\mathfrak{X}(M)$ , and similarly \begin{equation*}
  \mathfrak{T}^r_s(M)=L^{r+s}_{\mathcal{F}(M)}(\mathcal{X}^*(M),\dots,\mathfrak{X}(M);
  \mathcal{F}(M))
\end{equation*} the $\mathcal{F}(M)$ -multilinear mappings. I'm pretty certain there is a typo (theirs, not mine) in that last display. It would make far more sense if the definition was \begin{equation*}
  \mathfrak{T}^r_s(M)=L^{r+s}_{\mathcal{F}(M)}(\mathfrak{X}^*(M),\dots,\mathfrak{X}(M);
  \mathcal{F}(M))
\end{equation*} where all I did was change the font from calligraphic to fraktur on the first of the $r+s$ elements listed. This same typo exists in both the second and third editions. I'll assume this latter display is the correct one.] Proof. Consider the map $\mathcal{T}^r_s(M)\to\mathfrak{T}^r_s(M)$ given by \begin{equation*}
  \ell(\alpha^1,\dots,\alpha^r,X_1,\dots,X_s)(m)=\ell(m)(\alpha^1(m),\dots,X_s(m)).
\end{equation*} [EDIT: It seems to me that it would make more sense notationally
if the right hand side $\ell$ was actually $t$ .] This map is clearly $\mathcal{F}(M)$ -linear. To show it is an isomorphism, given such
a multilinear map $\ell$ , define $t$ by \begin{equation*}
  t(m)(\alpha^1(m),\dots,X_s(m))=\ell(\alpha^1,\dots,X_s)(m).
\end{equation*} To show that $t$ is well-defined we first show that, for each $v_0\in T_mM$ , there is
an $X\in\mathfrak{X}(M)$ such that $X(m)=v_0$ , and similarly for dual vectors. Let $(U,\phi)$ be a chart at $m$ and let $T_m\varphi(v_0)=(\varphi(m),v_0')$ .
Define $Y\in\mathfrak{X}(U')$ by $Y(u)=(u',v_0')$ on a neighborhood $V_1$ of $\varphi(m)$ , where $w=\varphi(n)$ . [I have to believe there are a couple of AMR
typos there. I think the $w=\varphi(n)$ was probably supposed to be $u'=\varphi(u)$ ,
but in any case, it should not be needed, since $Y$ is supposed to be defined on $U'$ , which I assume is $\varphi(U)$ , so the definition of $Y$ should, I believe,
read $Y(u')=(u',v_0')$ .] Extend $Y$ to $U'$ so $Y$ is zero outside $V_2$ , where $\mathrm{cl}(V_1)\subset V_2$ , $\mathrm{cl}(V_2)\subset U'$ , by means of a bump
function. Define $X$ by $X_\varphi=Y$ on $U$ , and $X=0$ outside $U$ . Then $X(m)=v_0$ .
The construction is similar for dual vectors. As in Theorem 4.2.16 [same number in both second and third editions], $\mathcal{F}(M)$ -linearity of $\ell$ shows that the definition of $t(m)$ is
independent of how the vectors $v_0$ (and corresponding dual vectors) are extended
to fields. The proof goes on from there to prove smoothness and to give a simplification in
the finite-dimensional case. I have two problems with this proof: I don't see how to show that the definition of $t$ (given $\ell$ ) is independent of
the choice of chart $(U,\varphi)$ . The referenced 4.2.16 only gives an example of how to
prove that a particular definition is independent of the specifics of the bump function
used to define it. It doesn't deal with independence from the choice of chart. I don't see how to show that $t(m)$ is continuous (multilinear). The multilinear
part is easy; it's the continuous part that I can't figure out. EDIT: It occurs to me that if this proposition is going to be true,
then the meaning of $L^{r+s}_{\mathcal{F}(M)}(\mathfrak{X}^*(M),\dots,\mathfrak{X}(M);\mathcal{F}(M))$ has to be more than the stated
"" $\mathcal{F}(M)$ -multilinear mappings"". It seems that from the forward
direction of the isomorphism we are going to have that \begin{equation*}
  |\ell(\alpha^1,\dots,X_s)(m)|
  =|(t(m))(\alpha^1(m),\dots,X_s(m))|
  \leq||t(m)||\,||\alpha^1(m)|| \cdots ||X_s(m)||
\end{equation*} so I think this condition should be part of the definition of $L^{r+s}_{\mathcal{F}(M)}(\mathfrak{X}^*(M),\dots,\mathfrak{X}(M);\mathcal{F}(M))$ . That is, I think we should define \begin{equation*}
  \begin{split}
  L^{r+s}_{\mathcal{F}(M)}(&\mathfrak{X}^*(M),\dots,\mathfrak{X}(M);\mathcal{F}(M))=\\
  &\{\mathcal{F}(M)\text{-multilinear }\mathcal{F}(M)\text{-valued}\,\ell:
  \forall m\in M,\exists c(m)\geq 0\text{ such that}\\
  &|(\ell(\alpha^1,\dots,X_s))(m)|\leq c(m)||\alpha^1(m)||\cdots||X_s(m)||\}.
  \end{split}
\end{equation*} Of course, we will have to specify, for each $m$ , a norm of $T_m(M)$ and for $(T_m(M))^*$ . I think this will take care of question 2. That
still leaves question 1: showing chart-independence.","['proof-explanation', 'vector-fields', 'smooth-manifolds', 'differential-geometry']"
4180416,The Double Basel Problem [duplicate],"This question already has answers here : How to prove $\sum_{m=1}^\infty \sum_{n=1}^\infty \frac{1}{m^2+n^2}=+\infty$ (6 answers) Closed 3 years ago . I have been playing with the series which I had been calling the 'Double Basel problem' for the past couple of hours $$
\sum_{n=1}^{\infty} \sum_{m=1}^\infty \frac{1}{{n^2 +m^2}}.
$$ After wrestling with this for awhile, I managed to generalize a result demonstrated here . This identity is: $$
\sum_{m=1}^{\infty}\frac{1}{x^2+m^2} = \frac{1}{2x}\left[ \pi \coth{\pi x} - \frac{1}{x}\right].
$$ Hence the original series becomes: $$
\sum_{n=1}^{\infty} \frac{1}{2n}\left[\pi \coth{\pi n} - \frac{1}{n} \right].
$$ I have no idea where to go next with this problem.  I seriously doubt that this series is convergent; however, I have been unable to prove it. Can you prove that this series is divergent? If it converges what is its value? Thanks so much!","['fourier-series', 'harmonic-numbers', 'sequences-and-series']"
4180422,Are there an infinite number of integers $n$ such that $(3n)(n+1)$ is a perfect square?,"I am looking for cases in which $\sqrt{3n(n+1)}$ is an integer, i.e. cases in which $$
3n(n+1)=m^2,\quad m\in\mathbb{N}.
$$ I can find solutions such as $$
n=0,3,48,675,9408,131043,\dots
$$ and I expect this list to be infinite. Is it? Is there a straightforward way to prove these kinds of statements? There are many ways of reframing the problem: finding integers $n$ that are simultaneously 3 times a perfect square and 1 less than another perfect square (choosing $3n$ and $n+1$ to each be perfect squares), etc. Then I could set $n=3k^2$ and try to solve for cases in which $$
3k^2+1=l^2 \quad\Leftrightarrow\quad 3k^2=(l+1)(l-1)\quad k,l\in\mathbb{N}.
$$ It seems plausible that there are infinite solutions given the various formulas for perfect squares but none of the rabbit holes that I followed led me anywhere productive.","['elementary-number-theory', 'square-numbers', 'integers', 'sequences-and-series']"
4180495,For how many values of $x$ does $f(x)=\cos x+\cos(\sqrt{2}x)$ attain its absolute minimum.,"For how many values of $x$ does $$f(x)=\cos x+\cos(\sqrt{2}x)$$ attain its absolute minimum? My Attempt: Absolute maximum of $f(x)$ is clearly $2$ which occurs when $x=0$ . But what should be the approach to obtain absolute minimum. One can observe that $f(x)$ is bounded, continuous, even and non-periodic so it will achieve its absolute minimum at least twice. Can we say that it will achieve its minimum(absolute) exactly twice. And if yes what will that minimum be and for what value(s) of $x$ will it occur","['real-analysis', 'maxima-minima', 'calculus', 'trigonometry', 'algebra-precalculus']"
4180505,Is a symmetric matrix a subspace of nxn matrices?,"Let $M$ be a vector space for all 2x2 matrices. Show that the set of all the symmetric matrices $M2$ ={ $B ∈ M2 : B=B^t$ } is a subspace of M. My solution: The null matrix is symmetric $$B=\begin{pmatrix}0&0\\0&0\end{pmatrix}$$ Let $B$ , $C$ $∈$ $M2$ , where $B = B^t$ , $C=C^t$ . Then, $B+C=B^t + C^t$ . $$B = \begin{pmatrix}a&c\\c&b\end{pmatrix}$$ $$C = \begin{pmatrix}d&f\\f&e\end{pmatrix}$$ $$B+C = \begin{pmatrix}a+d&c+f\\c+f&b+e\end{pmatrix}$$ $$B^t = \begin{pmatrix}a&c\\c&b\end{pmatrix}$$ $$C^t = \begin{pmatrix}d&f\\f&e\end{pmatrix}$$ $$B^t+C^t = \begin{pmatrix}a+d&c+f\\c+f&b+e\end{pmatrix}$$ Therefore, $B + C ∈ M2$ . Let $B ∈ M2$ , $θ ∈ R$ . Then, $θB = θB^t$ $$B = \begin{pmatrix}a&c\\c&b\end{pmatrix}$$ $$θB = \begin{pmatrix}θa&θc\\θc&θb\end{pmatrix}$$ $$B^t = \begin{pmatrix}a&c\\c&b\end{pmatrix}$$ $$θB^t = \begin{pmatrix}θa&θc\\θc&θb\end{pmatrix}$$ Therefore, $θB ∈ M2$ . So, $M2$ is, indeed, a subspace of $M$ . I am just learning linear algebra, so I apologize if I've made any mistakes. Also, I just got into this community, so I am still learning the formatting, so I apologize for any mistakes as well. Appreciate all the answers.","['matrices', 'solution-verification', 'linear-algebra', 'vector-spaces']"
4180552,How to properly rotate the axes and translate this equation $x^2-2xy+y^2-5y=0$,"In Morris Kline Calculus book on page 194. exercice 7.e I have to reduce to standard form this equation $x^2-2xy+y^2-5y=0$ Starting with the rotation: $$\begin{cases}
x = x'\cos\theta-y'\sin\theta\\
y = x'\sin\theta+y'\cos\theta
\end{cases}$$ replacing $x$ and $y$ in the equation: \begin{align*}
&\mathrel{\phantom=} x^2-2xy+y^2-5y\\
&=(x'\cos\theta-y'\sin\theta)^2 - 2(x'\cos\theta-y'\sin\theta)(x'\sin\theta+y'\cos\theta)\\
&\mathrel{\phantom=} +(x'\sin\theta+y'\cos\theta)^2 - 5(x'\sin\theta+y'\cos\theta)\\
&=0
\end{align*} replacing the $\sin\theta$ and $\cos\theta$ value $$\tan2A = \frac{B}{A-C} = \frac{-2}{1-1} = \frac{-2}{0} = 270^\circ\\
\tan\theta = 135^\circ\\
\sin\theta = \frac{\sqrt{2}}{2} \cos\theta = -\frac{\sqrt{2}}{2},$$ $$(x'(-\frac{\sqrt{2}}{2})-y'\frac{\sqrt{2}}{2})^2 - 2(x'(-\frac{\sqrt{2}}{2})-y'\frac{\sqrt{2}}{2})(x'\frac{\sqrt{2}}{2}+y'(-\frac{\sqrt{2}}{2}))\\+(x'\frac{\sqrt{2}}{2}+y'(-\frac{\sqrt{2}}{2}))^2 - 5(x'\frac{\sqrt{2}}{2}+y'(-\frac{\sqrt{2}}{2}))=0$$ When I simplify this equation I get this for the rotation of axes $2x'^2 - \frac{5\sqrt{2}}{2}x' + 5\frac{\sqrt{2}}{2}y'$ The answer in the book after rotation AND translation is $ 4y''^2 - 5\sqrt{2} x'' =0 $ He gets a $y''^2$ but I get a $x'^2$ , so I will never get a $y''^2$ after translation, what have I done wrong?","['algebra-precalculus', 'trigonometry']"
4180563,prove or disprove these propositions about limits of sequences of convergent sets,"Propositions Let $ \{ A_{n}: n \in \mathbb{N} \}  $ be a sequence of sets such that $A_{n} \rightarrow A $ . And let $ \{ B_{n}: n \in \mathbb{N} \}  $ be a sequence of sets such that $B_{n} \rightarrow B $ . then 1. $\lim_{n\to \infty} A_{n}\cap B_{n} = A\cap B $ . 2. $\lim_{n\to \infty} A_{n}-B_{n} = A-B $ . In order to prove that $C_{n} \to C $ , where $ \{ C_{n}:n \in \mathbb{N} \}$ is a sequence of sets, I have to  show that $ \limsup C_{n} = \liminf C_{n} = C $ . i.e, $\liminf C_{n} = \cup_{N=1}^{\infty} \cap_{n = N}^{\infty} C_{n} = C \ \ \ \ \ $ and $\limsup C_{n} = \cap_{N=1}^{\infty} \cup_{n = N}^{\infty} C_{n} = C \ \ \ \ \ $ but when I define $C_{n} = A_{n} \cap B_{n} $ or $C_{n} = A_{n} - B_{n} $ , I don't know how to compute the $\limsup C_{n}$ and the $\liminf C_{n}$ . Questions: Do you know a counterexample for this propositions? Do you know how to prove them?. thanks in advanced.","['elementary-set-theory', 'convergence-divergence']"
4180569,Why does $\int_{-\infty} ^{\infty}\frac{\sin x}{x}dx$ have a definite integral?,"My question is kind of misleading but here is the thing. I know that $\int_{-\infty} ^{\infty}\frac{\sin x}{x}dx$ has an integral, as a lot of proofs are available here (and it is easily observable from its plot). But what I don't get is that it has a removable singularity and hence no residue whatsoever in the upper semicircle (I am assuming a regular upper semicircular contour) and by this, its integral should be 0 [Relating to: removable singularities give integral as 0] . So what am I getting wrong here? I am sure I messed up my fundamentals somewhere. Please help me out. PS: My inspiration for this question is a physics-based H.W. So less rigorous math would be appreciated. Thanks in advance.","['complex-analysis', 'calculus', 'contour-integration']"
4180615,An interesting identity regarding partitions of $m$ into powers of two,"This question appeared in an exam I was giving- Suppose we have $n$ balls and we place them in a sequence of bins as
follows. At least one ball is put into the first bin, and each
successive bin has at least as many balls as all the previous bins
combined . This process is continued until all the balls have been
placed into bins. Prove that the number of ways of doing this is the same as the number
of partitions of n into powers of 2, not necessarily distinct. Note: $1=2^0$ is also considered a power of two. I think this identity is superb. It breaks my brains to even think that the two processes are equivalent. But, that doesn't help me to solve it. All I can think of is that the tightest case of putting balls into bins is $1,1,2,4,8,\dots$ which is the sequence of powers of two. Also, I know that the number of partitions of $m$ into powers of two is the coefficient of $x^m$ in the product \begin{equation*}
\prod_{n=0}^\infty \sum_{j=0}^{\infty} x^{2^n j}
\end{equation*} But, none of these proved useful. Any help would be appreciated.","['number-theory', 'combinatorics', 'elementary-number-theory']"
4180665,Natural isomorphism in linear algebra: is the naturalness asymmetric?,"Let $V$ be a finite-dimensional vector space. It is well known that there is a natural isomorphism between $V$ and its double dual $V^{\ast\ast}$ defined by $T(x)(f)=f(x)$ for every $x\in V$ and $f\in V^\ast$ . However, I am unable to write down a definition of $T^{-1}$ directly without any reference to $T$ and without picking any basis. Thus it seems to me that the isomorphism between the two vector spaces is not really so natural if we look at the direction from $V^{\ast\ast}$ to $V$ . Is it possible to define $T^{-1}$ in a direct and natural way? If not, does this asymmetry in the easiness of definition have any significance in linear algebra or other branches of mathematics?","['soft-question', 'linear-algebra', 'vector-space-isomorphism']"
4180701,How are manifolds embedded into an euclidean space? [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 3 years ago . Improve this question I am really new to differential geometry and topology and I am trying to understand how it is possible to embed a minfold into an euclidean space.
In particular, I am looking at projective spaces, but as I have already said I am really new, so I don't know if it is really realated.
So, my question is really short and it is: How are manifolds embedded into an euclidean space? If possible, I would like to have a more intuitive explanation of how this happens.","['general-topology', 'algebraic-topology', 'differential-geometry']"
