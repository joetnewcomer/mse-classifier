question_id,title,body,tags
3234509,A Lipschitz function is $C^1$?,"I am wondering if a Lipschitz function $f:[a,b]\to\mathbb{R}$ is $C^1$ , that is its derivative is also continuous? I have seen that in a text however I could not prove it and does not seem so obvious for me! Any suggestion?","['lipschitz-functions', 'real-analysis', 'continuity', 'calculus', 'derivatives']"
3234526,Proof that $f$ is differentiable,"Let $$f(x) = \sum_{n=1}^{\infty} \frac{x^n}{2^n} \cos{nx}$$ Proof that $f$ is differentiable on $(-2,2)$ my approach let $ m := \frac{x}{2} $ so $m<1$ $$ \left| \frac{x^n}{2^n} \cos{nx}   \right| \le m^n \rightarrow 0 $$ So by comparison we have point convergence. But I don't know how to deal with diffentiable..","['convergence-divergence', 'derivatives', 'summation', 'real-analysis']"
3234527,Generalized Laplacian?,"I was wondering if any of you had ever encountered operators on $L^2(\mathbb{R}^d)$ of the form $$
- \nabla \cdot A(x)\nabla
$$ where $A(x)$ is some matrix field (viewed as $L^2(\mathbb{R}^{d^2}$ )), and if so where can I find some literature about it ? More precisely, I'm trying to get a lower bound, $i.e$ hopefully some function $h(x)$ such that $- \nabla \cdot A(x)\nabla \geq h(x)$ (in the sense of quadratic forms), when $A(x) = (2|x| - |x|^{-1})xx^T$ . Thanks a lot!","['multivariable-calculus', 'operator-theory']"
3234606,Partial derivative of the real part of a function,"I'm trying to understand the mathematical reasoning behind the example provided in this question. If we have $$z = Ae^{i(\omega _{o}t+\phi )}$$ and define $$x = Re (z),$$ then why is it that $$\frac{\partial x}{\partial t} = Re  \frac{\partial z}{\partial t},$$ instead of $$\frac{\partial x}{\partial t} =  \frac{\partial [Re(z)]}{\partial t}$$ In other words, why is it that the partial derivative of the real part of a function is equal to the real part of the partial derivative of the function, rather than being equal to the partial derivative of the real part of the function? I'm just trying to understand the mathematical reasoning behind this, rather than why it is nonsensical from a physical standpoint.","['complex-analysis', 'partial-derivative', 'complex-numbers', 'real-analysis']"
3234648,How to solve exponential equations like $2^x+x=5$?,"I tried the following: Let $y=5-x$ . Then, $2^{5-y}=y \implies y \cdot 2^y=32$ Taking the log of both sides yields $$\log_2 y + y = 5$$ And that's where I'm stuck.","['algebra-precalculus', 'transcendental-equations']"
3234729,"Representation theory of SO(p,q)","For a long time now, I have tried to look for the representation theory of $SO(p,q)$ . I am in particular interested in the unitary irreducible representations and the bilinear Hermitian form on the space of (homogeneous) functions. I know that for certain degrees, the representations are unitary, but I want to know the associated bilinear form. Any reference (other then Vilenkin for $SL(2,\mathbf{R})$ ) would be welcome :)","['group-theory', 'representation-theory', 'lie-groups']"
3234898,Characterization of weak compactness in a Banach space,"While studying the textbook of Fernando Albiac and Nigel J. Kalton (Topics in Banach Space Theory), I came across the following result: A subset $A$ of a Banach space $X$ is relatively weakly compact if and only if it is norm-bounded and the $\sigma(X^{**},X^*)$ -closure of $A$ in $X^{**}$ is contained in $A$ . I am relatively unexperienced with weak topologies, so I would appreciate help in comprehending how that result might be proven. I am especially interested in the ""if""-direction. A first idea to prove the ""if"" direction is, to apply the Banach-Alaoglu theorem in $X^{**}$ and use that the canonical map $i:X\to i(X) $ given by $i(x):=(X^*\ni f\mapsto f(x))$ is actually a homeomorphism with respect to $(X,\sigma(X,X^*))$ and $(X^{**},\sigma(X^{**},X^*))$ . If that might work, I would appreciate getting ideas on how to prove the $(X,\sigma(X,X^*))$ , $(X^{**},\sigma(X^{**},X^*))$ - continuity of $i$ .","['weak-topology', 'functional-analysis', 'compactness']"
3234914,Why is it possible to calculate multivariable limits using polar coordinates?,"Why is it possible to calculate multivariable limits using polar coordinates? Let's say I'm looking for some $\lim_{(x,y) \to (0,0)}$ and I'm substituting $x = r cos\theta$ and $y = rsin\theta$ so that I can look at $\lim_{r \to 0}$ .
Why can I do this? Am I not just looking at ""straight lines"" going to $(0,0)$ now? What about all the other possible sequences that converging in straight lines to (0,0)?","['multivariable-calculus', 'calculus', 'real-analysis']"
3234925,Understanding projection of vector field in homgeneous spaces,"I'm studying homogeneous spaces from the book of A.Arvanitoyeorgos, ""An introduction to Lie groups and the geometry of homogeneous spaces"".
Consider $G/H$ be a homogeneous space, and let $\pi:G\rightarrow G/H$ be the canonical projection. We can consider the differential $d\pi_e:T_eG\rightarrow T_o(G/H)$ (and remember that $\mathfrak{g}\cong T_eG)$ . Now we can compute what is the projection of a $X\in\mathfrak{g}$ . The author says that, for any $g\in G$ $$X^{\star}_{gH}=\frac{d}{dt}(\exp{tX})gH\Bigr\rvert_{t=0}$$ where $\exp{tX}$ is the corresponing 1-parameter subgroup. Now my doubt is: The author notice that $[X^{\star},Y^{\star}]=-[X,Y]^{\star}$ ; Unfortunately I tried lots of computation for proving this identity but this result keeps arising as a magic trick; moreover my gut feeling is that this identity is not true, since if we reduce to the case $gH=o$ we should en up with an identity without the minus sign. And this is a problem, because this identity is strongly used to obtain the Riemannian connection for a reductive homogeneous space. So i'd like to understand whhy this result should be true, and in the other case why the computation of the Riemannian connection are correct (or, if they're not, what is the known formula). Thanks in advance to anyone who will help me trying to understand this a little bit.","['homogeneous-spaces', 'lie-groups', 'differential-geometry']"
3234939,Forming equations for damped Simple Harmonic Motion,"I have a question that says ""A Particle $P$ of mass $m$ kg is attached to one end of a spring. When the displacement of $P$ from its equilibrium poisition is $x$ metres, the magnitude of tension in the spring is $4nx N$ and the resistance force on P is $5c\frac{dx}{dt}$ Write a differential equation which models the motion of the particle. My answer: $$m\frac{d^2x}{dt^2}=4nx-5c\frac{dx}{dt}$$ $$m\frac{d^2x}{dt^2}+5c\frac{dx}{dt}-4nx$$ The textbook answer: $$m\frac{d^2x}{dt^2}+5c\frac{dx}{dt}+4nx$$ I don't get why $4nx$ is positive? Wouldn't that require the resistant force to act in the same direction as the tension?","['classical-mechanics', 'ordinary-differential-equations']"
3234972,Using $|r|$ versus using $r$ for double integration,"Suppose that I have a double integral where the integrand has variables $x$ and $y$ , and I am using the polar substitution $x=r\cos(\theta)$ and $y=r\sin(\theta)$ . Suppose the region of integration is $x^2 + y^2 \leq 1$ . By calculating the Jacobian $J = |r|$ I can replace the $dxdy$ by $|r|drd\theta$ . I understand why the limits for $\theta$ will be $0$ to $2\pi$ . Here is where I am a bit confused. I know that $x^2 + y^2 = r^2 \leq 1 \implies -1 \leq r \leq 1$ , and so this suggests $-1$ and $1$ will be the limits for $r$ . But if I say that $r$ is always positive (thinking of it as the 'radius'), then it ranges from $0$ to $1$ , and I can also say that the Jacobian $J = r$ instead of using the modulus. This is the approach I see people take when they do these kinds of integrals. So, does the value of the integral change depending on whether I use $J = r$ and limits $0 \leq r \leq 1$ , or use $J = |r|$ and limits $-1 \leq r \leq 1$ ? If it does change (and I am guessing that the non-modulus way is correct) then why is this so? Whilst I get that if I think about it intuitively, the 'radius' is always positive, I still don't see what is mathematically wrong about using $|r|$ and the $-1 \leq r \leq 1$ limits instead.","['integration', 'multivariable-calculus', 'polar-coordinates']"
3234998,"Under Poincaré-Bendixson hypothesis, can a $\omega(p)$-limit set be like this picture?","Last class we were proving Poincaré-Bendixson theorem in $\mathbb R^2$ which states that: Assume that the positive orbit $\mathcal O^+(p)$ is contained in a compact subset $K$ of the planar domain $D$ of the differential equation $x'=X(x)$ . Assume further that $X$ has only finitely many fixed points in $K$ . Then one of the following is satisfied: a) $\omega(p)$ is a periodic orbit; b) $\omega(p)$ is a single fixed point c) $\omega(p)$ consists of a finite number of fixed points, together with a finite set of orbits such that for each orbit its $\alpha$ -limit set is a single fixed point and its $\omega$ -limit set is also a single fixed point. During the proof, he stopped the class and drew the following picture in the blackboard: and asked, can $\omega(p)$ be like that? So I assume that he asked that in the context given by the hypothesis of Poincaré-Bendixson theorem. Also he intended to picture with those dots the singularities of the field. I want to say that the answer is no, because I think that every singularity must be connected by an orbit, which does not happen in this picture. But the problem is: I can't justify that. I've read the poincaré-bendixson demonstration quite a few times, but I can't find this justificative there. Any insight would be very helpful. Thank you","['ordinary-differential-equations', 'dynamical-systems']"
3235037,Derivative of $f(x)=\int_{x}^{\sqrt {x^2+1}} \sin (t^2) dt$,Derivative of $f(x)=\int_{x}^{\sqrt {x^2+1}} \sin (t^2) dt$ Firstly I wanted to calculate $\int \sin (t^2) dt$ and then use $x$ and $\sqrt {x^2+1}$ . But this antiderivative not exist so how can I do this? Is this function at all possible to count?,"['calculus', 'derivatives', 'real-analysis']"
3235060,What is the formalism that allows Random Variables to be treated algebraically like real or complex numbers?,"We all know that if we have a variable x, then there is a meaning to - for example - $$y=e^x$$ . And we all know how to manipulate that algebraically and to do calculus.  For example, if $$y_1=e^{x_1}$$ and $$y_2=e^{x_2}$$ then $$y_1y_2 = e^{x_1+x_2}$$ But random variables are a very different beast. Ultimately we all know intuitively what we mean when we draw a PDF or, more accurately, the CDF which is itself an algebraic function mapping $[-\infty, \infty]$ to $[0,1]$ as part of that defines a random variable. But what is the actual math that makes that definition of an RV actually act algebraically, so that, as above, we can happily write things like $$Y_1=e^{X_1}$$ and $$Y_2=e^{X_2}$$ then $$Y_1Y_2 = e^{X_1+X_2}$$ where $X_1$ and $X_2$ are random variables - and get away with it???","['measure-theory', 'probability-theory', 'probability', 'random-variables']"
3235070,1st Yr Statistics Question: Create an approximate $\alpha$ level test of $H_0 : p_1 = p_2$,"Let $X_1$ and $X_2$ be binomial random variables with respective parameters $n_1, p_1$ and $n_2, p_2$ . Show that when $n_1$ and $n_2$ are large, an approximate level $\alpha$ test of $H_0 : p_1 = p_2$ versus $H_1 : p_1 \neq p_2$ is as follows, reject $H_0$ if $$ \frac{|X_1/n_1-X_2/n_2|}{\sqrt{\frac{X_1+X_2}{n_1+n_2} \left( 1 - \frac{X_1+X_2}{n_1+n_2}\right) \left(\frac{1}{n_1}+\frac{1}{n_2}\right)}} > z_{\alpha/2} $$ Hint below in screenshot. My attempt Given $H_0$ is true I can say that $p = p_1 = p_2$ and since $n_1$ and $n_2$ are large, I can use the normal approximation to the binomial to say that $$ V = \frac{X_1 - n_1 p}{\sqrt{n_1 p q}} = \frac{ \frac{X_1}{n_1} - p}{\sqrt{\frac{p q}{n_1}}} \, \dot\sim \, N(0,1)$$ $$ W = \frac{X_2 - n_2 p}{\sqrt{n_2 p q}} = \frac{ \frac{X_2}{n_2} - p}{\sqrt{\frac{p q}{n_2}}} \, \dot\sim \, N(0,1)$$ Then we have $\frac{V-W}{\sqrt{2}} \dot\sim N(0,1)$ and we can build a two sided hypothesis using the fact that $$P \left( -z_{\alpha/2} \le \frac{V-W}{\sqrt{2}} \le z_{\alpha/2} \right) = 1-\alpha  $$ The book answer seems superior because you don't need to know $p_1$ or $p_2$ . However I'm having difficulty getting rid of those two values. Thanks for your help and patience! Book problem with hint","['statistics', 'binomial-distribution', 'probability', 'hypothesis-testing']"
3235090,Let $x_{n+1} = \frac{1}{2}(x_n + \frac{a}{x_n})$. Prove that $x_{n+1} < x_{n}$,"Let $$x_{n+1} = \frac{1}{2}(x_{n} + \frac{a}{x_{n}})$$ Prove that $x_{n+1} < x_{n}$ for $a \geq 0$ . Hint: Let the initial guess satisfy $x_{1} > \sqrt{a}$ I am stuck at how to begin this. I would like to use an induction proof, but there is no simple way for me to relate the base case and begin. That is I can't even establish: $$x_{2} < x_{1}$$ How would I do this since there is no given initial term? Or is that a mistake and an initial term should be present?","['sequences-and-series', 'real-analysis']"
3235110,What Does a Set Represent?,"In Linear Algebra Done Right, Axler says that order and repetiton don't matter in a set. For example, the set {4} = {4,4} = {4,4,4} or {1,3} = {3,1}. My question is then what do these sets mean. What could {4,4} possibly represent in real life and why would that be equal to what {4,4,4} represents? And the same question for what {3,1} could possibly represent and why that would be equal to what {1,3} represents.",['elementary-set-theory']
3235111,Inequivalent Sequences of Positive Integers,"Let $A$ and $B$ be two sequences of positive integers.  We say $A$ and $B$ are inequivalent if whenever a finite initial sequence is removed from $A$ and whenever a finite initial sequence is removed from $B$ , the resulting two sequences $A'$ and $B'$ are not identical.  I want to show that the set consisting of all sequences which are pairwise inequivalent is uncountable.  I thought the Cantor approach of assuming we have a sequence of such sequences and changing the diagonal would work, but adding the condition of pairwise inequivalence seems to throw that off.  I'm sure this is pretty obvious but I'm just not seeing it right now.  Can anyone offer a hint?",['elementary-set-theory']
3235137,Remove even elements of partition of integration set,"Suppose I am integrating a continuous $f:\mathbb{R}\rightarrow\mathbb{R}$ in a measurable set $A\subseteq I$ , where $I$ is an interval: $$
\int_{A}f(x)dx
$$ Now suppose I partition the set $I$ in $N$ intervals $I_{i}$ of
equal length: $I=\cup_{n=1}^{N}I_{n}$ . Let $A_{n}=A\cap I_{n}$ ,
so that $\{A_{n}:n\in\{1,..,N\}\}$ is a partition of $A$ . Let $E_N=\cup_{n=1}^{N/2}A_{2n}$ (it considers only the even elements of the partition of $A$ ). I
am trying to show that $$
\lim_{N\rightarrow\infty}\int_{E_N}f(x)dx=\frac{1}{2}\int_{A}f(x)dx
$$ But no success. I figured this may be a known result, is it?","['integration', 'measure-theory', 'definite-integrals']"
3235160,Spanning forests of bipartite graphs and distinct row/column sums of binary matrices,"Let $F_{m,n}$ be the set of spanning forests on the complete bipartite graph $K_{m,n}$ .  Let $$S_{m,n} = \{(r(M), c(M)), M \in B_{m,n} \}$$ where $B_{m,n}$ is the set of $m \times n$ binary matrices and $r(M), c(M)$ are the vectors of row sums and column sums of $M$ , respecitvely.  That is, $S_{m,n}$ is the set of the distinct row-sum, column-sum pairs of binary matrices. (The term spanning forest here refers to a forest that spans all of the vertices of the given graph; it doesn't have to be a maximal acyclic subgraph.) Q: Is it true that $|F_{m,n}| = |S_{m,n}|$ ?  It is true for $m,n \leq 4$ .  For $m=n$ this is OEIS A297077 . There is an obvious mapping from $F_{m,n} \rightarrow B_{m,n}$ given by taking the reduced adjacency matrix, so if $U = \{u_1, \ldots, u_m\}$ , $V = \{v_1, \ldots, v_m\}$ are the color categories we set $M_{ij} = 1$ if $v_i \sim u_j$ in a forest $F$ , else $M_{ij} = 0$ .  However, this does not help because multiple forests may have the same row and column sums - and not every row-sum, column-sum pair is represented by a forest under this mapping. The numbers $|F_{m,n}|$ are given here: $$\begin{array}{|c|c|}\hline
m\backslash n & 1 & 2 & 3 & 4 & 5 \\ \hline
1 & 2 &  \\\hline
2 & 4 & 15 \\\hline
3 & 8 & 54 & 328  \\\hline
4 & 16 & 189 & 1856 & 16145 \\\hline
5 & 32 & 648 & 9984 & 129000 & 1475856 \\\hline\end{array}$$ For more see this answer (sum each row.)","['graph-theory', 'adjacency-matrix', 'matrices', 'combinatorics', 'bipartite-graphs']"
3235168,Put trivariate PDF in terms of bivariate PDFs,"Let there be the random variables $X$ , $Y$ , and $Z$ . Let all the bivariate PDFs $f_{X, Y}$ , $f_{X, Z}$ , and $f_{Y, Z}$ be known. Can we write the unknown trivariate PDF $f_{X, Y, Z}$ in terms of the known bivariate PDFs?","['statistics', 'probability-distributions', 'probability']"
3235288,"If $\space$ $\forall$ $x \in \Bbb R$, $\space$ $f(f(x))=x^2-x+1$. Find the value of $f(0)$. [duplicate]","This question already has answers here : If $f(f(x))=x^2-x+1$, what is $f(0)$? (4 answers) Closed 5 years ago . If $\space$ $\forall$ $x \in \Bbb R$ , $\space$ $f(f(x))=x^2-x+1$ . Find the value of $f(0)$ . I thought that making $f(x)=0$ implies that $f(0)= 0^2 - 0 + 1 = 1$ , but i think that this isn't correct, because the $x$ in $f(f(x))$ isn't equal to $f(x)$ . Any hints?",['functions']
3235330,"Show $ f(x) = \sum_{n=1}^{\infty} \frac{nx}{n^3 + x^3}$ ,$\ g(x) = \sum_{n=1}^{\infty} \frac{x^4n}{(n^3 + x^3)^2}$ are bounded on $[0, \infty)$.","If $f(x), g(x)$ are defined as following on $[0 , \infty)$ , $$\tag 1 f(x) = \sum_{n=1}^{\infty} \frac{nx}{n^3 + x^3}$$ $$\tag 2 g(x) = \sum_{n=1}^{\infty} \frac{x^4n}{(n^3 + x^3)^2}.$$ . Then how to show that $f,g$ are bounded function on $[0 , \infty)$ ? I found this problem on this Is $f(x)=\sum_{n=1}^\infty\frac{nx^2}{n^3+x^3}$ uniformly continuous on $[0,\infty)$? . In solution's last steps, i don't know why this is correct answer. Could you explain for me to elaborate? Thank you.","['sequences-and-series', 'real-analysis']"
3235339,Why probability of picking a random prime is 0? [duplicate],"This question already has answers here : Why does ""the probability of a random natural number being prime"" make no sense? (5 answers) Closed 5 years ago . ""It's well known that there are infinitely many prime numbers, but
  they become rare, even by the time you get to the 100s,"" Ono explains.
  ""In fact, out of the first 100,000 numbers, only 9,592 are prime
  numbers, or roughly 9.5 percent. And they rapidly become rarer from
  there. The probability of picking a number at random and having it
  be prime is zero. It almost never happens."" --Source: phys.org I feel really skeptical about the statement in bold above. I think the probability tends to approach zero but can never be zero. Please explain how the probability is being calculated mathematically?","['analytic-number-theory', 'number-theory', 'probability', 'prime-numbers']"
3235356,How can i Prove that the gray area is the same as white area? [duplicate],"This question already has an answer here : Prove the equality of circle's areas (1 answer) Closed 5 years ago . A circle is cut into 8 parts, each part has the angle 45 degrees from an arbitrary point. how to prove that the white area is the same as the Gray area? I just want any hint for solving this question. how can I prove this?","['algebra-precalculus', 'area', 'circles', 'geometry']"
3235359,Puzzling random number property,"For a series of values $A_{\text{peak}}\geqslant 0$ , I generated a large number ( $n$ ) of random values $A_{\text{noise}}$ (using the Mersenne Twister algorithm in PHP) within $[-A_{\text{peak}},+A_{\text{peak}}]$ , and from these calculated the average root-mean-square value : $\displaystyle\overline{\text{RMS}}_{\text{noise}}=\sqrt{\frac{1}{n}\cdot\sum_{1}^{n}A_{\text{noise}}^{2}}$ . Using regression analysis it then turns out that, with high accuracy : $A_{\text{peak}}=\sqrt{3}\cdot\overline{\text{RMS}}_{\text{noise}}$ . How can this $\sqrt{3}$ constant be derived mathematically ?","['random', 'statistics']"
3235384,Use the t-test to test below find its t-statistic,"Use the t-test to test $H_0 : \beta_1 = 0$ $H_1 : \beta_1 \neq 0$ at level significance $5 \%$ . Give test statistic and conclude within the context of the study Given $SSREG = 36460$ $s = 365$ $\hat\beta_1 = -5.98$ $n = 49$ attempt: $t^* = \frac{\hat\beta_1}{s(\hat\beta_1)}$ $s(\hat\beta_1) = \sqrt{\frac{s^2}{\sum_{i=1}^{n} (X_i - \bar{X})^2}}$ $\sum_{i=1}^{n} (X_i - \bar{X})^2 = \frac{SSREG}{\hat\beta_1^2} = 1019.5$ so then $s(\hat\beta_1) = \sqrt{\frac{s^2}{\sum_{i=1}^{n} (X_i - \bar{X})^2}} = \sqrt{\frac{365^2}{1019.5}} = 11.4$ and finally $t^* = \frac{(-5.98)}{11.4} = -0.52$ I have to show $|t^*| < t_{1 - \frac{\alpha}{2}, n - 2}$ or $|t^*| \geq t_{1 - \frac{\alpha}{2}, n - 2}$ but what is $\alpha$ equal to?","['regression', 'statistics']"
3235419,Parabola - Definition as a locus of points,"On Wikipedia, a parabola is defined as follows: A parabola is a set of points such that, for any point $P$ of the parabola, the distance $|\overline{PF}|$ to a fixed point $F$ , the focus, is equal to the distance $|\overline{Pl}|$ to a fixed line $l$ Isn't this definition wrong since an empty set is a parabola according to it? Is the following definition correct? For any set of points $S$ , $S$ is a parabola if and only if
  there exists a point $F$ and a line $l$ such that $F$ isn't on $l$ and for any point $P$ , $P$ is in $S$ if and only if $|\overline{PF}|=|\overline{Pl}|$ .","['locus', 'definition', 'conic-sections', 'geometry']"
3235428,Relationship between distances on homogeneous spaces and their Lie groups,"Consider the (round) sphere $M=\mathbb{S}^{n-1}$ as a homogeneous $O(n)$ -space. Then for $x,y\in\mathbb{S}^{n-1}$ there is $g\in O(n)$ such that $y=g\cdot x$ .
Denote the Riemannian distance on $\mathbb{S}^{n-1}$ by $d_{\mathbb{S}^{n-1}}$ . Intuitively, if $y$ and $x$ are not far apart then $g$ should be almost the identity (because the $O(n)$ -action is smooth).
I am able to explicitly construct such a rotation $g$ so that \begin{align}
  \|g-\operatorname{Id_{\mathbb{R}^n}}\|
    \leq 2\; d_{\mathbb{S}^{n-1}}(y,x)
\end{align} where $\|\cdot\|$ is the operator norm for matrices. Analoguously, if $M=\mathrm{Gr}_m(\mathbb{R}^n)$ is the Grassmannian, then by a similar construction using principle angles I can find a rotation $g$ such that $F=g\cdot E$ for $m$ -planes $E,F$ and \begin{align}
  \|g-\operatorname{Id_{\mathbb{R}^n}}\|
    \leq 2m\; d_{\mathrm{Gr}_m(\mathbb{R}^n)}(F,E)
\end{align} where $d_{\mathrm{Gr}_m(\mathbb{R}^n)}$ is the angle metric on $\mathrm{Gr}_m(\mathbb{R}^n)$ ( e.g. here ). However, I find these constructions rather unsatisfying and would like to understand if there is a more abstract underlying principle at play. Here is my question:
  Given a homogeneous $G$ -space $M$ , are there always ( $G$ -invariant ?) metrics on $M$ and $G$ such that for all $x,y\in M$ there is $g\in G$ such that $y=g\cdot x$ and which fulfils the quantitative estimate \begin{align}
  d_G(g,e)
    \leq C \; d_M(y, x) ?
\end{align} Feel free to add any hypotheses (such as compactness etc) that apply to $\mathbb{S}^{n-1}$ , $\mathrm{Gr}_m(\mathbb{R}^n)$ and $O(n)$ . EDIT: As proposed in the comments by levap and Moishe Kohan, I have edited my question.","['symmetric-spaces', 'homogeneous-spaces', 'lie-groups', 'differential-geometry']"
3235465,Entire function of finite order with infinitely many zeros,"Let $f(z)$ be an entire function of finite order of the form $$f(z)=\sum_{n=0}^\infty a_nz^{k_n}$$ where $a_n\neq0$ for all $n$ and $(k_n)_{n\geq0}$ is an increasing sequence of integers satisfying $$\limsup_n\;(k_{n+1}-k_n)=\infty.$$ Show that $f(z)$ has infinitely many zeros. I know that if $f(z)$ has only finitely many zeros then by Hadamard's theorem $f(z)$ is of the form $P(z)e^{Q(z)}$ for some polynomials $P$ and $Q$ , so a possible approach is to show that for such functions the condition $\limsup_n\;(k_{n+1}-k_n)=\infty$ is not possible, but I gave up after some time. Another possible way may be trying to prove that $f(z)$ has non-integer order, since in such a case it follows easily that $f(z)$ cannot have finitely many zeros. Any ideas?","['complex-analysis', 'entire-functions']"
3235529,Is composition of surjective continuous function with discontinuous function discontinuous?,"Let $I_1,I_2,I_3$ be intervals $\subset \mathbb{R}$ . Suppose $f:I_1 \to I_2$ is a surjective continuous function and $g: I_2 \to I_3$ is a discontinuous function. Must the composition $g \circ f$ be discontinuous? There are some easy counter-examples if $f$ is not assumed to be surjective, e.g. taking $f$ to be a constant function, or in a way that ""dodges"" the discontinuous point(s) of $g$ . However if such ""dodging"" is prohibited, I fail to construct such functions nor find an answer from many similar questions on this site. So I am interested to know whether counter-examples exist? If not, is there a proof? Does it have something to do with intermediate value theorem?","['continuity', 'calculus', 'functions']"
3235648,Subgroup of finitely-generated subgroup,"Is there a standard name for this concept: Let $H \leq G$ be groups. Say $H$ is ?? if there is a finitely-generated group $K \leq G$ such that $H \leq K$ . What should one use in place of ""??""? I'm also interested in this notion up to isomorphism. I've used ""finitely subgenerated"", though I have realized that ""finitely supergenerated"" probably makes a bit more sense. If you know a reference/situation where such a thing plays a key role, that may also be useful even if no name is given.","['finitely-generated', 'group-theory', 'terminology']"
3235677,When does a multiplication operator on $L^2$ have closed range?,"I'm working on the following problem in Conway's Functional Analysis. Here $\phi$ is a bounded measurable function on $(X, \Omega, \mu)$ . I was able to answer the first part of the problem but I am stuck on the second. My first idea was to look at the spectrum, as injectivity + closed range $\implies$ surjectivity. However, I haven't figured out the case when $\phi$ is zero on a set of positive measure. One sufficient condition I came up with is for $X \setminus ker(\phi)$ to be a closed set. I don't know if this is also a necessary condition and I would really appreciate some help!","['operator-theory', 'functional-analysis', 'analysis']"
3235687,"Is there a standard name for this relation property : "" aRb --> there is no c different from b such that aRc ""?","Maybe this property could be called ""exclusivity"" ? Does it have a standard name? It recalls the definition of a function as a "" single-valued relation"" (Enderton). But here, it is not required that any a ( in a given set) be related to some b .","['elementary-set-theory', 'relations']"
3235750,Integrals of the form $\int \log(2+2\cos x)^ndx$,"$\log$ will be the natural logarithm and $\zeta$ the Riemann zeta function. I'm interested in the following family of integrals: $$
I_n = \int_0^\pi(\log(2+2\cos x))^n\mathrm{d}x
$$ Some of the values are: $$\begin{array}{c|c|c|} 
 n& \text{$I_n$}\\ \hline
1 & 0 \\ \hline
2 & 2\pi\zeta(2) \\ \hline
3 & -12\pi\zeta(3) \\ \hline
4 & 114\pi\zeta(4) \\ \hline
5 & -1177.6529...\cdot\pi\zeta(5) \\ \hline
6 & 14420.2439...\cdot\pi\zeta(6) \\ \hline
7 & -203649.3734...\cdot\pi\zeta(7) \\ \hline
\end{array}$$ Now the values for $n=2,3,4$ are particularly nice when written in this form, and I managed to calculate those three integrals using dubiously rigorous contour integral methods which are far too unwieldy for anything more. The half-angle substitution leads to various ugly nested sums which I don't know how to evaluate. However (according to WolframAlpha) the patter apparently breaks at $n=5$ , even though it was going so well! Does anyone know if/how it is possible to obtain a closed form solution?","['integration', 'riemann-zeta', 'definite-integrals', 'logarithms']"
3235760,Cotangent lift of an action and its effect on the moment covector,"If I have an action of a Lie group on a configuration space。 $G\to \text{Diff}(M)$ , $g \mapsto \rho_g$ , $\rho_g : q \mapsto \rho_g(q)$ (for example a rotation). Then when we consider the phase spaces $T^*M$ , we provide it with the action : $G\to \text{Diff}(T^*M)$ , $g \mapsto \rho^*_{g^{-1}}$ , $\rho_{g^{-1}}^* \colon (q,p) \mapsto (\rho_g(q),\rho^*_{g^{-1}}(p))$ . Now I understand that the point $q$ is send to its image under the action, but I don't understand why the moment $p$ is transformed as $\rho^*_{g^{-1}}(p)$ under the action? Why is the reason we consider this weird action with a pullback on the moment? Why do we want the moment to transform in this way?","['moment-map', 'lie-groups', 'differential-geometry']"
3235793,How easy is it to create false evidence for a biased coin?,"I have a biased coin which comes up heads with probability $p$ . I know the value of $p$ , but I want to falsely claim that the coin has a different probability of heads, $q$ , where $q > p$ . To support my claim I decide to produce some false evidence: I flip the coin repeatedly and record the fraction of flips that were heads, and keep flipping until the fraction is at least $q$ . I also make sure I flip the coin at least $100$ times before stopping (so I flip $100$ times initially, then I keep flipping until the fraction of heads so far is at least $q$ ). I report the total number of flips, and the fraction of heads, as evidence that the coin has probability of heads (approximately) $q$ . In terms of $p$ and $q$ , what is the probability that I can successfully produce evidence for my false claim? (I.e. what is the probability that after $100$ initial flips, my repeated flipping will eventually terminate with a fraction above $q$ in a finite amount of time?) Given that I do successfully produce the false evidence, what is the expected number of flips required? I thought of this question out of curiosity, when pondering about how we can soundly use data to infer unknown probabilities. For Question 1, the probability is positive: in fact, it's at least $p^{100}$ since the first $100$ flips could all be heads. It's less clear if the probability is $< 1$ , but I think it is. The question can be phrased as a random walk in two dimensions, where the false evidence is produced if the random walk enters into the region of points $(x,y)$ where $y > q \cdot (x + y) \text{ and } x + y \ge 100$ . For Question 2, probably thinking about it as a random walk is also the first step. For either question, I would be happy with upper/lower bounds or approximations, if an exact answer is not easy.","['statistical-inference', 'statistics', 'random-walk', 'probability']"
3235824,Subset of $\mathbb{R}^n$ homeomorphic to $\mathbb{R}^{n-1}$.,"I have a feeling that the following statement is true (it's not from any book or paper, but it seems plausible): If $U\neq \emptyset$ is open and precompact (that is, $\overline{U}$ is compact) in $\mathbb{R}^n$ , then the boundary of $U$ has a subset $F\subset \partial U$ homeomorphic to an open set of $\mathbb{R}^{n-1}$ , or equivalently to $\mathbb{R}^{n-1}$ itself. The reason I think this is true is it is pretty easily shown for $n=1$ , since the boundary of such an open set consists of isolated points. And also, if you think about the general case you have that this is true for open balls in $\mathbb{R}^n$ , since the boundary is homeomorphic to $S^{n-1}$ . But I get stuck when I try to think of a way to solve this problem for any open precompact subset. Notice that I'm not trying to show that $\partial U$ is locally euclidean, since there is a simple counter-example in $\mathbb{R}^2$ , where on can get an X-shaped boundary for certain open precompact subsets. I only want to show that some subset of the boundary is locally euclidean (actually euclidean as whole). I am open for suggestions on how to prove/disprove this. Thank you all!","['general-topology', 'metric-spaces']"
3235839,Why is the open subscheme $D(p)\cup D(T)$ in $\text{Spec } \mathbb Z[T]$ not affine?,"In Liu's AG textbook, Example 2.3.6 says that when looking at $ \text{Spec }\mathbb Z[T]$ and open subscheme consisting of the union of the two basis opens $U:=D(p)\cup D(T)$ for some prime $p$ , $$\mathcal O_X(U)\subseteq \mathcal O_X (D(p))\cap \mathcal O_X (D(T)) = \mathbb Z[T,1/T]\cap\mathbb Z[T,1/p]=\mathbb Z[T].$$ And this implies that $\mathcal O_X(U)=\mathbb Z[T]$ (I don't see why it cannot be a proper subset). And then, using the fact that $\mathcal O_X(U)=\mathbb Z[T]=\mathcal O_X(X)$ , we can conclude that $U$ is not affine using the fact that for an affine scheme $Y$ and any scheme $X$ , $\hom(X,Y)\to\hom(\mathcal O_Y(Y),\mathcal O_X(X))$ is bijective. I'm assuming a contradiction is derived by supposing $U$ is indeed affine, and taking $Y=U$ , $X= \text{Spec }\mathbb Z[T]$ , but I don't see exactly how.","['affine-schemes', 'algebraic-geometry', 'schemes']"
3235915,How can I find the value of this [pathological] function?,"A few months ago, while attempting to create a parameterization of the Hilbert curve, I discovered an interesting function, given by the summation... $$f(x)=\sum_{n=1}^\infty \frac{\text{sgn}\left(\cos(nx)\right)}{n}$$ ...where $\text{sgn}$ is the signum function... $$\text{sgn}(x)=\begin{cases}1&x>0\\0&x=0\\-1&x<0\end{cases}$$ The function is noteworthy for being nowhere differentiable and nowhere continuous. I have found it nigh impossible to evaluate the function for any $x$ save integer multiples of $2\pi$ (where the sum diverges). The graph of the function (shown below) seems to be a self-similar fractal, but I don't know enough about fractals to verify this. Even if I did, I'm not sure what I would do with this information. Anyway, how can I find the value of $f(x)$ for arbitrary $x$ ?","['fractals', 'sequences-and-series', 'continuity', 'real-analysis']"
3235937,"What do you call a ""factor"" of a union","If we have numbers $a,b$ , they are called summands of $a+b$ or factors of $a\cdot b$ . Given two modules $M,N$ , they are direct summands of $M\oplus N$ . Likewise, given two sets $A,B$ , they can be called factors of $A\times B$ .  What word describes the relationship between sets $A,B$ and $A\cup B$ or $A\sqcup B$ ?","['elementary-set-theory', 'terminology']"
3235941,Show that $2 - \sqrt{2}$ is irrational,"I suppose $2 - \sqrt{2} $ is rational.
so $$2- \sqrt{2} = {a/b} $$ where a,b are integers and gcd(a,b) = 1. $$\text{Step 1. } 2 = (a/b)^2 \text{ //squared both sides }$$ $$\text{Step 2. } 2b^2 = a^2 \text{ //We see $a^2$ is even }$$ $$\text{Step 3. }2b^2 = (2k)^2$$ Step 3 since $a^2$ is even and so $a$ is even too. Also, k is an integer. $$\text{Step 4. }b^2 = (2k)^2 \text{ //We see $b^2$ is even }$$ Step 4 since $b^2$ is even and so $b$ is even too. We see $ a$ and $b$ are even. We see $gcd(a,b) \neq 1$ Is this proof correct ?","['irrational-numbers', 'proof-verification', 'discrete-mathematics']"
3235999,Polynomials in the Pancake problem,"I noticed something interesting in this table. The columns can be expressed by polynomials of degree k. I toke the first $k+1$ numbers from each column and used Lagrange's interpolation. Surprisingly, I got that this extrapolation gives exact values of all other numbers in the column. I can't check this for $k=7$ . $$k=0: 1$$ $$k=1: n-1$$ $$k=2: n^2-3n+2$$ $$k=3: n^3-5n^2+8n-5$$ $$k=4: n^4-\frac{15}2n^3+\frac{29}2n^2+3n-17$$ $$k=5: n^5-\frac{65}6n^4+\frac{173}6n^3+\frac{148}3n^2-\frac{862}3n+265$$ $$k=6: n^6-\frac{883}{60}n^5+\frac{157}3n^4+\frac{2155}{12}n^3-\frac{4570}3n^2+\frac{42767}{15}n-967$$ $$k=7: \frac{1679}{1680}n^7-\frac{2765}{144}n^6+\frac{21541}{240}n^5+\frac{69163}{144}n^4-\frac{717821}{120}n^3+\frac{1462277}{72}n^2-\frac{10388033}{420}n+5037$$ If I set the $n$ to one where the first positive value occurs, it is: $$k=0: 1$$ $$k=1: n$$ $$k=2: n^2+n$$ $$k=3: n^3+n^2-1$$ $$k=4: n^4+\frac92n^3+n^2-\frac92n+1$$ $$k=5: n^5+\frac{55}6n^4+\frac{31}2n^3-\frac{14}3n^2-2n+1$$ $$k=6: n^6+\frac{917}{60}n^5+\frac{713}{12}n^4+\frac{565}{12}n^3-\frac{5}{12}n^2+\frac{409}{30}n-3$$ $$k=7: \frac{1679}{1680}n^7+\frac{142}{9}n^6+\frac{192}{5}n^5-\frac{3743}{36}n^4-\frac{18917}{240}n^3+\frac{14119}{36}n^2-\frac{50761}{140}n+100$$ Questions: Can it be proven that the colums of that table are always polynomials? Can be the coefficients predicted in a way? There seems to be an order but I can't find it.","['polynomials', 'discrete-mathematics', 'sequences-and-series']"
3236042,Difficult Laplace Transform Type of Integral,"Good afternoon.  I have the following integral that I need help integrating; $$
\mathrm{F}\left(x\right) =
\int_{0}^{\infty}\mathrm{e}^{s\left(j - 1/x\right)}\,
\left[\mathrm{T}_{N}\left(s\right)\right]^{k - j}\,\mathrm{d}s
$$ where $\mathrm{T}_{N}\left(s\right)$ is the truncated exponential function $$
\mathrm{T}_{N}\left(s\right) = \sum_{n = 0}^{N}\frac{s^{n}}{n!}
$$ and $j,k$ are whole numbers. I figured that tackling this using integration by parts is the best choice, but naturally this could take a while given that my choice of $u_{1}=\mathrm{T}_{N}^{k - j}\left(s\right)$ yields a $\mathrm{d}u_{1}$ of $$
\mathrm{d}u_{1} =
\left(k - j\right)\mathrm{T}_{N}^{k-j-1}\left(s\right)
\mathrm{T}_{N - 1}\left(s\right)\,\mathrm{d}s
$$ since $\mathrm{d}\mathrm{T}_{N}\left(s\right)/\mathrm{d}s = \mathrm{T}_{N - 1}\left(s\right)$ .  This does not seem to be simplifying the problem though as the next iteration would require me to then choose my $u_{2}$ to be $$
u_{2} =
\frac{1}{k - j}\,\frac{\mathrm{d}u_{1}}{\mathrm{d}s} =
\mathrm{T}_{N}^{k - j - 1}\left(s\right)
\mathrm{T}_{N - 1}\left(s\right)
$$ Are there any other approaches to this without this drawn out IBP method or without considering expanding the truncated exponential ?.","['integration', 'calculus', 'integral-transforms']"
3236068,X is to vector like matrix is to linear operator?,"In linear algebra texts there is usually a clear distinction between linear operators and matrices. A linear operator is a map between two spaces that fulfills a set of conditions. A matrix is a 2D array of numbers (elements of the underlying field) that can be used to represent a linear operator with respect to bases of the two spaces. Slightly complicating but not muddling this distinction is the fact that together with appropriate operations, a matrix can also be seen as a linear operator itself. What I'm missing is a corresponding distinction for vectors. The term ""vector"" is interchangeably used for elements of a space, and for their representation by 1D arrays with respect to a basis. Is there terminology to distinguish between these two meanings of ""vector"", like there is for ""linear operator"" vs ""matrix""?","['matrices', 'linear-algebra', 'terminology']"
3236110,How does the Cantor set contain more points than the boundary points of those deleted open intervals?,"I'm trying to get an intuitive grasp of the Cantor set. Let $$C_0 = [0,1]$$ and $$C_n = \frac{C_{n-1}}{3} \cup (\frac{2}{3} + \frac{C_{n-1}}{3}).$$ Then we call $$\mathcal C = \bigcap_{n \in \mathbb N}$$ the Cantor set. Here's something that my intuition cannot resolve: The Cantor set is constructed in countably many steps where in each step a finite number of open intervals is deleted. Now, it's quite clear that all the end points of those deleted intervals will remain in the set. However, these are just countably many since we perform a countable number of steps and each step only adds a finite number of end points. Now, here's where my intuition escapes me: How is it that any point that is not an end point of one of these deleted open intervals remains in the set as well? Wouldn't any non-end-point be cut out eventually? How can I imagine this process properly?","['general-topology', 'measure-theory', 'analysis']"
3236126,How many solutions are there to $x_{1} + x_{2} + x_{3} + x_{4} = 15$,"How many solutions are there to (I think they mean non-negative integer solutions) $x_{1} + x_{2} + x_{3} + x_{4} = 15$ where $1\leq x_{1} \leq 4$ $2 \leq x_{2} \leq 5$ $7\leq x_{3}$ $2\leq x_{4}$ My ""Solution"" I use the method shown in this video: https://www.youtube.com/watch?v=Y0CYHMqomgI&list=PLDDGPdw7e6Aj0amDsYInT_8p6xTSTGEi2&index=7 $$N(\overline{C_{1}}\overline{C_{2}}\overline{C_{3}}\overline{C_{4}}) = $$ $$ N - (N_{C1}+N_{C2}+N_{C3}+N_{C4}) + N_{C1C2}+ N_{C1C3}+ N_{C1C4}+ N_{C2C3}+ N_{C2C4}+N_{C3C4}  - N_{C1C2C3} - N_{C1C2C4} - N_{C1C3C4} - N_{C2C3C4} + N_{C1C2C3C4}$$ $$N=\binom{18}{15}$$ Now this part (find NC1) i am unsure about. when $$1\leq x_{1} \leq 4$$ $$N_{C1}$$ $$x_{1} + x_{2} + x_{3} + x_{4} = 15$$ $$1\leq x_{1} \leq 4$$ $$ x_{1}{}' + x_{2} + x_{3} + x_{4} = 15 -4 = 11$$ $$x_{1}{}' \geq 0$$ $$N_{C1} =\binom{14}{11}$$ Is this the right way to find $$N_{C1} $$ ?",['combinatorics']
3236181,Triangle inequality for angles in Euclidean space [duplicate],"This question already has an answer here : Prove the triangle inequality on the sphere $S^2$ in $\mathbb{R}^3$. (1 answer) Closed 5 years ago . Is there any simple proof of the following statement: for all vectors $ v,w,u\in V\setminus\{0\} $ , where $ V $ is a Euclidean space, inequality $$ \angle(u,v)\le\angle(u,w)+\angle(w,v)$$ holds. Unfortunately, couldn't find anything useful in books or Google. I've seen this post: Triangle inequality for angles , but I'm not sure if the given answer is correct or not, and is there more clear proof or not.","['euclidean-geometry', 'angle', 'geometry']"
3236188,Why is the probability that a continuous random variable takes any one specific value equal to 0? [duplicate],This question already has answers here : Why is the probability that a continuous random variable takes a specific value zero? (4 answers) Closed 5 years ago . What would the intuitive explanation be? Would it be because there are infinately many values and so the probability of any specific value is infinitely small hence we say 'close enough' to 0?,"['statistics', 'probability']"
3236198,Problem with translating sets into logic,I'm starting to work through Munkres and in the first section there is an easy excercise that I have problem with when I'm formalizing it. The quesiton asks if the iff is valid or if not which way the implication runs $A \subset B \ \lor A \subset C \stackrel{?}{\iff} A \subset (B \ \cup C)$ It is obvious that if the A is subset of either B or C that it will be subset of their sum. Other way round it doesn't work as we can have A being a subset of elements of both B and C resulting in it being a subset of neither individually. This is my attempt to write it formally. $(x \in A \implies x \in B) \ \lor \ (x \in A \implies x \in C)$ // Rewriting the left hand site using implications $(x \notin A \ \lor x \in B) \ \lor \ (x \notin A \ \lor x \in C)$ // Material implication $(x \notin A \ \lor x \notin A) \ \lor \ (x \in B \ \lor x \in C)$ // Associativity $x \notin A \ \lor \ (x \in B \ \lor x \in C)$ // Idempotency $(x \in A \implies (x \in B \ \lor \ x \in C)$ // Material implication But this would suggest that the implication is running both ways which is nonsense and means I am making a mistake somewhere.,"['elementary-set-theory', 'logic']"
3236202,Surface area inside cylinder,"Find the surface area of the part $\sigma$ : $x^2+y^2+z^2=4$ that lies inside the cylinder $x^2+y^2=2y$ So, the surface is a sphere of $R=2$ . It looks there should be double integral to calculate the surface, but how, which way?","['integration', 'multivariable-calculus']"
3236205,Subgroup of coprime order with automorphism group is contained in center of group,"I'm studying for a qualifying exam in algebra and I've come across the following problem: Let $G$ be a finite group with a subgroup $N$ . Let $Aut(G)$ be the group of automorphisms of $G$ . Prove that if $|Aut(G)|$ and $|N|$ are relatively prime, then $N$ is contained in the center of $G$ . I'm struggling to find a good way to approach this. I'm able to prove a similar result that if $|G|$ and $|Aut(G)|$ are relatively prime, then $G$ is abelian: Let $\theta$ be a homomorphism from $G$ to the inner automorphism group of $G$ , denoted $\theta:G\rightarrow Inn(G)$ . Then because inner automorphisms are conjugations by fixed elements, the kernel of $\theta$ is the center of $G$ , denoted $ker(\theta)=Z(G)$ . By the first isomorphism theorem, it follows that $G/Z(G)\cong Inn(G)\subseteq Aut(G)$ . Hence, by Lagrange's theorem, $|G/Z(G)|$ divides $|Aut(G)|$ . Similarly, by consequence of Lagrange's theorem, $|G/Z(G)||Z|=|G|$ , as $Z(G)$ is a normal subgroup of $G$ . Since $|G/Z(G)|$ divides $|G|$ and $|Aut(G)|$ , and $|G|$ and $|Aut(G)|$ are relatively prime, it follows that $|G/Z(G)|=1$ , implying that $G=Z(G)$ . The desired result follows. $\blacksquare$ It's not obvious to me how to transform this proof into one of the desired problem (or if there even is a good way to simply modify what I already have). If I knew that $N$ were a normal subgroup, I could potentially apply the same kind of argument using Lagrange's theorem, but I don't have that assumption. Without more information on the structure of $G$ , it doesn't seem likely that I'll be able to use an element argument to show that $N\subseteq Z(G)$ .","['automorphism-group', 'group-theory', 'proof-writing', 'finite-groups']"
3236212,Solve $x^y + y^x = 499$ for positive integer solution,"I'm asked to solve this equation $$
x^y+y^x=499
$$ only positive integer solutions are permitted. First I found the apparent solutions $x=498, y=1$ and $x=1, y=498$ . I want to look for a way to solve for the other pairs that could be the answer. I noticed that $499$ is a prime but I don't know if it helps knowing this. I'm trying this:
let $f(y)=x^y+y^x$ , then $f'(y)=x^y\ln x+xy^{x-1}>0$ . So I'm considering cases like $22^2<499$ , $7^3<499$ , $4^4<499$ , and $3^5<499$ . But all the above cannot be the answer pair for $(x,y)$ . While $23^2>499$ , $7^4>499$ and so on so forth. If $x=2$ , then $2^8+8^2\neq 499$ and $2^9>499$ . Thus neither $x$ nor $y$ could be $2$ . Namely the only solution is either $x$ or $y$ must be 1. I am wondering if there is easier way to solve this problem? Like number theory method? Or any other approaches. Thank you for any help!","['number-theory', 'integers', 'diophantine-equations']"
3236243,Can an arbitrary ordering of the $\binom{n}{2}$ slopes of the lines connecting $n$ points in $\mathbb{R}^2$ always be realized?,"Given $n$ variable points on the plane, $(x_i,y_i)$ , let the slope of the line connecting point $i$ and point $j$ be $m_{ij}$ . If I specify an arbitrary ordering of all of these slopes, $m_{ij}<m_{i'j'}<...<m_{i''j''}$ do there always exist values $x_i,y_i$ such that this ordering is satisfied?",['geometry']
3236295,finding limit of a multivariable function,"I want to find the limit of $\dfrac{x^2 +y^4}{y^2+x^4}$ as $(x,y) \to (\infty, \infty)$ . I tried two different paths: $y=x$ : We have the limit of the above function $\lim (x^2+x^4)/(x^4+x^2)=1$ , $y=2x$ : We have $\lim (x^2+16x^4)/(x^4+4x^2)=16\neq1$ . So I concluded that the limit does not exist. Is there a better way to find the limit?","['multivariable-calculus', 'limits', 'calculus', 'functions']"
3236360,What is a fiber over a point?,Let $X\to S$ be a morphism of schemes. First what does it mean to be a fiber over a point? Is it like the presage of $s\in S$ under the morphism? Sometimes I see $X_s$ and sometimes I see $X_\bar{s}$ . What are the differences?,['algebraic-geometry']
3236382,How to show the sequence $x_n = (1 + \frac{x}{n})^{n}$ is bounded above by $e^x$?,"How to show the sequence $x_n = (1 + \frac{x}{n})^{n}$ is bounded above by $e^x$ ? Note: I'm not supposed to be able to use any differentiation techniques if possible. Since we techincally ""don't know"" it yet. As can be deduced I am trying to show that the sequence $x_n = (1 + \frac{x}{n})^{n}$ is convergent. I have to arrive at this conclusion using the monotonic convergence theorem. So we are given by definition that $$e^{x} = \lim_{n \rightarrow \infty} \Bigg(1 + \frac{x}{n} \Bigg)^{n}$$ I think I figured out how to show the sequence is montonically increasing. My problem is showing that it is bounded. So one idea I thought of trying to apply was using the binomial theorem: $$\Bigg(1 + \frac{x}{n}\Bigg)^{n} = \sum_{k = 0}^{n} \binom{n}{k} \bigg(\frac{x}{n}\Bigg)^{k}$$ and then since this would be some sort of finite quantity, I would compare it to $e^x$ : $$\Bigg(1 + \frac{x}{n}\Bigg)^{n} = \sum_{k = 0}^{n} \binom{n}{k} \bigg(\frac{x}{n}\Bigg)^{k} < e^{x} = \lim_{n \rightarrow \infty} \Bigg(1 + \frac{x}{n} \Bigg)^{n} = 1 + x + \frac{x^2}{2!} + \frac{x^3}{3!} + \dots $$ But I can't seem to get the finite binomial expansion in a comparable form. Questions: 1) Is this a correct approach ? 2) If it is how can I rewrite the binomial expansion to work in my favor ?","['sequences-and-series', 'real-analysis']"
3236406,"If $AB=A$, does B have to be the identity matrix?","Suppose $A$ and $B$ are square matrices and that $AB=A$ with $B \neq I$ . What does this say about the invertibility of $A$ ? This question showed up on an exam I took this past spring. I got stuck on it, but I thought about it for a while and think I figured it out. Here's something similar to what I got: Suppose $A$ is invertible. Then: $$\begin{align}
AB &= A \\
A^{-1}AB &= A^{-1}A \\
IB &= I \\
B &= I
\end{align}$$ This shows that if $AB=A$ , then $B$ must be an identity matrix if $A$ is invertible. Conclusion: If $AB=A$ and $B \neq I$ , then $A$ must be singular. An obvious example would be making $A$ a zero matrix. Is what I've got correct?","['matrices', 'matrix-equations', 'linear-algebra']"
3236420,Can an injective smooth map from a smooth manifold into another smooth manifold have a discontinuous inverse?,"I think the answer is yes. See the example below: we consider the open interval $(-1,\infty)$ as an open submanifold of the smooth manifold $(i,\mathbb{R})$ with $i:\mathbb{R}\rightarrow \mathbb{R},i(x)=x$ being the chart. Similarly, $(i,\mathbb{R^2})$ is a smooth manifold with $i:\mathbb{R}^2\rightarrow\mathbb{R}^2,i(\textbf{x})=\textbf{x}$ being the chart. Let $\varphi:(-1,\infty)\rightarrow\mathbb{R}^2$ by $\varphi(t)=\left(\frac{3t}{1+t^3},\frac{3t^2}{1+t^3} \right)$ . The trace of $\varphi$ (with subspace topology) is the portion of the ""folium of Descartes"" lying in the first and second quadrants together with the origin. Observe that $\varphi$ is injective but near the origin, $\varphi^{-1}$ is not continuous (since $\varphi(0)=\textbf{0}$ but $\varphi(t)\rightarrow\textbf{0}$ as $t\rightarrow \infty$ ). Hence, an injective smooth map between smooth manifolds can have a discontinuous inverse. $\varphi$ "">","['manifolds', 'smooth-manifolds', 'differential-geometry']"
3236443,"When can we ""reduce"" $(n\Bbb Z/m\Bbb Z)$?","$(3\Bbb Z/6\Bbb Z) \cong (\Bbb Z/2\Bbb Z)$ can be easily shown by using the first isomorphism theorem, but I heard that we cannot say that $(2\Bbb Z/6\Bbb Z) \cong (\Bbb Z/3\Bbb Z)$ . Why not? And what are the conditions in which we can ""simplify"" the ring?","['ring-theory', 'abstract-algebra', 'ring-isomorphism']"
3236455,Rotation Matrix and Triple Angle Formulas?,"Define $R_{\theta}:\mathbb{R}^2 \rightarrow \mathbb{R}^2$ as the rotation matrix by angle $\theta$ , where $$R_{\theta} = \begin{pmatrix} \cos\theta & -\sin\theta \\ \sin\theta & \cos\theta \end{pmatrix}$$ Observe that $$
(R_\theta)^2 = \begin{pmatrix} \cos^2\theta-\sin^2\theta & -2\sin\theta\cos\theta \\ 2\sin\theta\cos\theta  & \cos^2\theta-\sin^2\theta  \end{pmatrix}
= \begin{pmatrix} \cos2\theta & -\sin2\theta \\ \sin2\theta & \cos2\theta \end{pmatrix}=R_{2\theta}
$$ This all makes sense of course since if you rotate a vector by $\theta$ twice, the net result should be a rotation by $2\theta$ . The algebra of it all can be verified with the double angle formulas. However, how do you prove that $$
(R_\theta)^3 = R_{3\theta}
$$ or perhaps that $$
(R_\theta)^n = R_{n\theta}
$$ Are there triple angle formulas that can be used to make the algebra work? n-tuple angle formulas?","['trigonometry', 'angle', 'linear-algebra']"
3236481,Question of deck transformation on double cover $\tilde{M}$ of non-orientable manifold $M$.,"Suppose $(M,g)$ is a non-orientable, compact, connected Riemannian manifold with positive sectional curvature, $\tilde{M}$ is its orientable double cover . $\varphi$ is deck transformation of $\tilde{M}$ with $\varphi \not= id$ . $\varphi$ is deck transformation of $\tilde{M}$ means for smooth covering $\pi:\tilde{M}\to M$ , $\varphi$ is diffeomorphism s.t. $\pi=\pi\ \circ \varphi$ . Question 1 : Prove $\varphi$ reverses the orientation of $\tilde{M}$ . Background : Weinstein's theorem: Suppose $N$ is a compact, orientable $n$ -dim Riemannian manifold with positive sectional curvature, $f:N\to N$ is an isometry. If $f$ preserves orientation if $n$ is even and reverses orientation if $n$ is odd, then $f$ has a fixed point. Synge's theorem for odd-dim: $(M,g)$ is a compact, connected odd-dim Riemannian manifold with positive sectional curvature, then $M$ is orientable. I want to use Weinstein's theorem to prove Synge's theorem for odd-dim. Suppose on the contrary $M$ is non-orientable , $\tilde{M}$ is its orientable double cover, $\pi:\tilde{M}\to M$ is smooth covering and is isometry, so $(\tilde{M},\pi^*g)$ is compact, connected, orientable Riemannian manifold with positive sectional curvature. Let $\varphi$ be deck transformation of $\tilde{M}$ with $\varphi \not=$ Id, if I can prove $\varphi$ reverses the orientation of $\tilde{M}$ , then from Weinstein's theorem, $\varphi$ has a fixed point. From uniqueness of lifting or property of deck transformation, $\varphi$ = Id, contradiction. Thus $M$ is orientable. The only problem is to prove $\varphi$ reverses the orientation of $\tilde{M}$ . Double cover: Chapter 15 in Introduction to Smooth Manifolds by John.Lee. Question 2 Is that possible to use Weinstein's theorem to prove Synge's theorem for even-dim? $(M,g)$ is a compact, even-dim, orientable, connected Riemannian manifold with positive sectional curvature, then $M$ is simply connected. Thank you.","['riemannian-geometry', 'smooth-manifolds', 'geometric-topology', 'orientation', 'general-topology']"
3236495,Characterization of the geometric distribution,"$X,Y$ are i.i.d. random variables with mean $\mu$ , and taking values in { $0,1,2,...$ }.Suppose for all $m \ge 0$ , $P(X=k|X+Y=m)=\frac{1}{m+1}$ , $k=0,1,...m$ . Find the distribution of $X$ in terms of $\mu$ . I have a feeling that $X$ is a geometric random variable. I wrote $P(X=k)=p_k$ and tried to equate the coefficient of $p_k$ on both sides but it was futile. My teacher gave me a hint to try with probability generating functions. But I really can't implement it. Please help.","['statistics', 'probability-distributions', 'generating-functions', 'probability-theory', 'probability']"
3236556,Evaluate $\int \frac{dx}{\left(\frac{1}{x}-\frac{1}{a}\right)}$,Evaluate the following integral: $$\displaystyle \int\dfrac{dx}{\left(\dfrac{1}{x}-\dfrac{1}{a}\right)}$$ Where $a$ is an arbitrary constant. How do I solve this? I tried the substitution $$x=a\cos \theta$$ But that got me here (i.e. no where): $$\displaystyle a^{3/2}\int\dfrac{-\sqrt {\cos\theta}.\sin\theta.d\theta}{\sqrt{1-\cos\theta}}$$ How do I simplify this further?,"['integration', 'indefinite-integrals', 'calculus']"
3236636,$\forall a > 0$ $\sum_{n=1}^{\infty} f(na)$ is convergent. Prove that $\int_{0}^{\infty}f(x) dx$ is convergent.,"Hi can you help me solve this exercise? Thanks. Let $f: [0;+\infty) \to \mathbb{R}$ be nonnegative and continuous function. Suppose $\forall a > 0$ $\sum_{n=1}^{\infty} f(na)$ is convergent. Prove that $\int_{0}^{\infty}f(x) dx$ is convergent. I tried to solve it by using the Riemann sum, but for fixed a it doesn't work. I have no other ideas.","['analysis', 'real-analysis']"
3236661,How can an ordered pair be a set assuming there is no order in a set?,"The following propositions, I think, are generally considered as true ( though they may not all have the same level of rigor). (1) In a set there is no order ( due to the extensionality axion) : $\{a,b\} = \{b,a\}$ (2) In an ordered pair there is an order : $(a, b)$ is not equal to $(b,a)$ . (3) An ordered pair is a set: $(a,b) = \{ \{a\} , \{a,b\} \}$ . Does the problem lie in proposition (2) : should one say, instead of "" in an ordered pair there is an order"" that "" an ordered pair is an order""? How to formulate rigorously these propositions in order to make them compatible?","['elementary-set-theory', 'order-theory', 'definition', 'soft-question']"
3236822,Question regarding partially ordered sets,"I have encountered few questions while reading the book 'Modern Algebra'. Let $\mathbb Q$ be the set of rational numbers.
Let $B = \{ x : x\in\mathbb Q,\sqrt2 < x < \sqrt3 \}$ . How it can be shown that - $B$ has infinite number of upper and lower bounds. $\inf B$ and $\sup B$ do not exist . Why $\sqrt2$ and $\sqrt3$ cannot be taken as lower aqnd upper bounds? I am not able to understand that how can infimum and supremum can exist at the first place as the relation defined is not a binary relation. A detailed proof would be helpful.",['discrete-mathematics']
3236842,Frechet Space vs Banach Space,"What is Frechet Space? Is a Banach a Frechet space? If not, why? If yes, how do we prove it?
According to Wikipedia , Frechet spaces are locally convex topological space that is complete with respect to translation-invariant metric. It also says that: They are generalizations of Banach spaces (normed vector spaces that are complete with respect to the metric induced by the norm). So I am guessing that Frechet spaces are Banach Spaces. But how do we prove it?","['banach-spaces', 'functional-analysis']"
3236877,Evaluate $\lim\limits_{n \to \infty}\left(\frac{1}{1+a_1}+\frac{1}{1+a_2}+\cdots+\frac{1}{1+a_n}\right).$,"Problem Let $a_1=3,a_{n+1}=a_n^2+a_n(n=1,2,\cdots)$ . Evaluate $$\lim_{n \to \infty}\left(\frac{1}{1+a_1}+\frac{1}{1+a_2}+\cdots+\frac{1}{1+a_n}\right).$$ Attempt Notice $$\frac{1}{1+a_n}=\frac{a_n}{a_n+a_n^2}=\frac{a_n}{a_{n+1}}$$ Then $$\sum_{k=1}^{n}\frac{1}{1+a_k}=\sum_{k=1}^n \frac{a_k}{a_{k+1}}.$$ This will help?",['sequences-and-series']
3236897,Does a convex function preserve convexity of sets?,"A convex function is defined in a way that’s a bit weird to me, as it’s defined as a function whose area above the graph of a convex set is always convex. Is it also true that if $f:S\to T$ is convex, then any convex set in $U\subseteq S$ maps to a convex set $f(U)\subseteq T$ ? This would mean a convex function is a “structure preserving map for structures on which convexity is defined”.","['convex-analysis', 'real-analysis']"
3236970,Why do we choose the limits for double integrals in this way?,"This is a general question which I have been asking (to no avail) for a while around my class. I will ask my question using an example. Evaluate $I=\displaystyle\int_{0}^{1}\mathrm{d}x\displaystyle\int_{\sqrt{x}}^{1}e^{y^3}\mathrm{d}y$ . Where the solution provided by the lecturer is We cannot directly integrate $e^{y^3}$ with respects to $y$ , therefore we express $I$ as a double integral over a region $D$ , that is $$I=\iint_{D}e^{y^3}\mathrm{d}x\,\mathrm{d}y.$$ We can describe $D=\{(x,y):0\leqslant y\leqslant 1, 0\leqslant x\leqslant y^2\}$ : The lecturer goes on to solve the integral using these limits and everything is fine. My question is: why do we choose $0\leqslant x\leqslant y^2$ ? What is the difference between this and $y^2\leqslant x\leqslant 1$ ? The same can be asked for the limits of the first integral: what is the difference between $\sqrt{x}\leqslant y\leqslant 1$ and $0\leqslant y\leqslant \sqrt{x}$ ?","['integration', 'multivariable-calculus']"
3236982,Marginalizing by sampling from the joint distribution,"For two random variables $x$ and $y$ , if I can sample from the joint distribution $p(x, y)$ , I can obtain samples from the marginal $p(x)$ by sampling from the joint distribution and ignoring the values of $y$ . I want to make a formal argument for this. Something like: $$
\begin{align}
\mathbb{E}_{x \sim p(x)} [f(x)]
&= \int_{x \in \mathcal{X}} f(x)\,p(x)\,dx \\
&= \int_{x \in \mathcal{X}} f(x)\,\int_{y \in \mathcal{Y}} p(x, y)\,dy\,dx \\
&= \int_{x \in \mathcal{X}} \int_{y \in \mathcal{Y}}  f(x)\,p(x, y)\,dy\,dx \\
&= \mathbb{E}_{x, y \sim p(x, y)} [f(x)]
\end{align}
$$ Is this a reasonable argument?","['marginal-distribution', 'probability-distributions', 'probability']"
3236998,Exponential of Pauli Matrices,"Let $\vec{v}$ be any real three-dimensional unit vector and $\theta$ a real number. Prove that $\exp(i\theta \vec{v}\cdot\vec{\sigma}) = \cos(\theta)I + i\sin(\theta)\vec{v}\cdot\vec{\sigma}$ , where $\vec{v}\cdot\vec{\sigma} \equiv \sum_{k=1}^{3}v_{k}\sigma_{k}$ . $\vec{v}\cdot\vec{\sigma}$ is a scalar so let this scalar be a non-zero integer $n$ . Effectively, this gives $\exp(i\theta n)$ . $\exp(i\theta n) \Rightarrow (\cos(\theta) + i \sin(\theta))^{n}$ I would appreciates if anyone could provide to me a hint to this.
The computation becomes messy very quickly. Thanks in advance.","['trigonometry', 'linear-algebra', 'quantum-computation']"
3237091,Covering map from sphere with six points removed to doubly-punctured complex plane,"$X$ is $S^2\subset \mathbf{R}^3$ with its intersection points with the coordinate axes removed. Show that the following map is a covering map. $$\begin{align*}p:X&\longrightarrow \mathbf{C}-\{0,1\} \\ (x,y,z)&\longmapsto \left(\frac{x+iy}{1-z} \right)^4 \end{align*}$$ To check if it is a covering map, I should show that it is (1) continuous, (2) surjective and (3) that for all $w\in\mathbf{C}-\{0,1\}$ there is an open neighbourhood $U$ for which $p^{-1}(U)$ is the disjoint union of subsets $V_\alpha\subset X$ which are all homeomorphic to $U$ . We have never encountered such a difficult covering map before, the only one we have seen in class is the standard covering map $\mathbf{R}\to S^1:t\mapsto e^{it}$ and $S^1\to S^1:z\mapsto z^n$ for the circle $S^1$ . I know that the formula for stereographic projection $S^2-\{(0,0,1) \}\to \mathbf{C}$ from the north pole $(0,0,1)$ is $(x,y,z)\mapsto \frac{x+iy}{1-z}$ . This is clearly a bijection $\phi:S^2-\setminus \{0,0,1\}\leftrightarrow\mathbf{C}-\{0\}$ . Under $\phi$ , the missing points of $X$ are mapped to $0,1,-1,i$ and $-i$ . The map $z\mapsto z^4$ then 'rotates' the plane such that the points $1,-1,i,-i$ are sent to $1$ . The function is continuous since it's a formula, and $z\neq 1$ since we removed the point $(0,0,1)$ from the sphere. I tried proving that it is surjective by using spherical coordinates, but that did not work out. Since $X$ does not contain $(0,0,0)$ we never reach $0$ in the image, but then why don't we reach $1$ ? Could someone provide any help?","['general-topology', 'algebraic-topology', 'covering-spaces']"
3237169,Question in discrete mathematics about group permutations,"So I have this question and i got pretty much stuck. Let $\pi$ be the permutation $$\pi= (1 2 3 4 5 6 7)\circ(1 3 5 7)\circ(2 4 6)$$ of the set $\{1,2,3,4,5,6,7\}$ . Write $\pi$ as a product of disjoint cycles and determine if  is an
odd or even permutation. I learnt how to do permutations(i guess) but from the whole permutation rows. Can someone help me uderstand what am i missing? The solution is supposed to be $$\pi=(1 4 7 2 5)\circ(3 6)$$ Thanks a lot in advance!","['permutations', 'group-theory', 'discrete-mathematics', 'permutation-cycles']"
3237172,Internal direct sum of kernel of surjective homomorphism and cyclic subgroup,"I'm studying for a qualifying exam in algebra, and my abstract algebra skills are quite rusty. I'm attempting to solve the following problem: Suppose that $\Phi:G\rightarrow\mathbb{Z}$ is a surjective group homomorphism from the abelian group $(G,+)$ to the group of integers under addition. Let $K$ be the kernel of $\Phi$ , and let $g$ be an element of $G$ for which $\Phi(g)=1$ . Prove that $G$ is the (internal) direct sum of $K$ and the subgroup of $G$ generated by $g$ . I was initially thrown off by the fact that $\Phi(g)=1$ , thinking this meant $g\in K$ as $1$ is typically used to denote the identity. However, the codomain here is $(\mathbb{Z},+)$ , so the identity is actually the additive identity of the integers, $0$ . Thus $g\notin K$ . Which I believe makes it clear that $K\cap\langle g\rangle=0$ by a simple homomorphism argument (something to the effect of $\Phi(ng)=\Phi(g)+\Phi(g)+\cdots+\Phi(g)=1+1+\cdots+1=n\neq0$ ). What I'm stuck on is how to argue that $G=K+\langle g\rangle$ . I can use the first isomorphism theorem to claim that $\mathbb{Z}\cong G/K$ and $K\triangleleft G$ , but I'm not sure how this helps. Edit: I must be thinking of something wrong, as it seems to me that $\Phi(\langle g\rangle)=\mathbb{Z}_{\geq0}$ . But this doesn't allow the desired result, as $\Phi$ is surjective, meaning everything in $\mathbb{Z}$ gets mapped to, so specifically, $\exists h\in G$ s.t. $\Phi(h)=-1$ . There's no way to write $h=k+g'$ where $k\in K$ and $g'\in\langle g\rangle$ .","['group-homomorphism', 'proof-writing', 'direct-sum', 'group-theory', 'abelian-groups']"
3237242,Two dimensional induction,"I have the following problem: I need to prove that given the following integral $\int_{0}^{1}{c(k,l)x^k(1-x)^l}dx = 1$ , we the constant $c(k,l) = (k+l+1) {{k+l}\choose{k}} = \frac{(k+l+1)!}{k!l!}$ , with the use of two dimensional mathematical induction on $min(k,l)$ . 
Here $k$ and $l$ are two nonnegative integers. (THUS: I need to proof that $c(k,l)$ is equal to $(k+l+1) {{k+l}\choose{k}}$ ) For the base step I have proved that $c(k, 0) = c(0, k) = k + 1$ for all $k$ . I am given a hint that for the induction step I could try using integration by parts to show $c(k,l) = 􏰅\frac{k+1}{l} 􏰆c(k+1,l−1)$ . By integrating the following by parts I indeed managed to show the latter: $\int_{0}^{1}{c(k+1,l-1)x^{k+1}(1-x)^{l-1}dx}=1$ . However, I don't really see how this helps me to complete my proof, since I don't really get the idea of two dimensional induction. Can someone maybe clarify this a bit for me, and help me further with my proof?","['induction', 'probability-theory']"
3237279,Identity of tan(x),I came across the following formulas for analytical expressions of fundamental modes of asymmetric dielectric waveguide. $$ \tan(x) = x\frac{\pi^2-x^2}{\pi^2-4x^2} $$ This approximation is not present in Abramowitz's handbook. It has the same poles and zeros as $\tan(x)$ . Can someone guide me on its merits or where to find it. This doesn't seem like an identity to me.,"['trigonometry', 'numerical-methods']"
3237308,"Show that $\Omega \setminus N_A \ni x \mapsto 1_A(x) \cdot \int\limits_{\Upsilon} k(x,t)f(t)d\nu(t)$ is measurable","Assume $(\Omega,\mathcal{A},\mu)$ and $(\Upsilon,\mathcal{B},\nu)$ are measure spaces with $\sigma$ -finite measures $\mu, \nu$ and $k \in L^2(\Omega \times \Upsilon, \mathcal{A} \otimes \mathcal{B}, \mu \times \nu)$ . I have shown for all $A \in \mathcal{A}$ with $\mu(A) < + \infty$ and for all $f \in L^2(\Upsilon,\mathcal{B},\nu,\mathbb{C})$ that the function $(x,t) \mapsto 1_A(x) \cdot \int\limits_{\Upsilon} k(x,t)f(t) d\nu(t)$ is integrable. What I want to do now is to follow that for a null set $N_A \in \mathcal{A}$ the function $g: \Omega \setminus N_A \ni x \mapsto 1_A(x) \cdot \int\limits_{\Upsilon} k(x,t)f(t)d\nu(t)$ is measurable. My idea is that since the the integral of $g$ is finite it is finite almost everywhere. Now I define the set $N_A$ as the points $x$ for which $g(x)$ is not finite. Is it now guaranteed that $g$ is measurable?","['integration', 'measure-theory', 'functional-analysis', 'analysis']"
3237309,Prouhet-Thue-Morse sequence and Arithmetic Progressions,"This question is a fragment from a question posted by @Mathphile for which the link will be provided below. Let $(x_i)$ be an arithmetic progression of length $M$ . Let $(t_i)$ be the $i$ th element in the Prouhet-Thue-Morse sequence where we have: $$t_0=0$$ $$t_{2n}=t_n \quad (n \in \mathbb{N}_0)$$ $$t_{2n+1}=1-t_n \quad (n \in \mathbb{N}_0)$$ If all the elements of $(t_{x_i})$ are to be $0$ 's, can the value of $M$ be arbitrarily large? Link for Prouhet-Thue-Morse Sequence Link for @Mathphile problem","['number-theory', 'arithmetic-progressions', 'sequences-and-series']"
3237327,Circular permutation with constraints,"If four boys and four girls play tricks, how many ways can they join hands, provided that at least two girls are together? My plan is to determine the circular permutation of the eight (boys + girls), which is equal to 7! and to subtract from it the cases in which at least two girls are separated. That is, only two separate girls, only three separate girls or only four separate girls. How to proceed with this approach? The answer is 7! - 3! * 4! which, by the presence of less, suggests the use of the complementary combination. To get to 3! * 4 !, I believe that it is enough to calculate the circular permutation of the boys (which will be among the girls), which results in (4 - 1)! = 3 !, and multiply by the girls' permutation: 4 !. Why, considering that the boys should be among the girls, it is not correct to multiply the circular permutations of the two, getting 3! * 3! ?","['permutations', 'combinations', 'permutation-cycles', 'combinatorics', 'discrete-mathematics']"
3237335,Optimise allocation to minimise variance,"Background I am trying to allocate customers $C_i$ to financial advisers $P_j$ . Each customer has a policy value $x_i$ . I'm assuming that the number of customers ( $n$ ) allocated to each adviser is the same, and that the same customer cannot be assigned to multiple advisers. Therefore each partner will have an allocation of policy values like so: $P_1 = [x_1,x_2,x_3]$ , $P_2 = [x_4,x_5,x_6]$ , $P_3 = [x_7,x_8,x_9]$ etc. The Problem After allocating customers, the average policy value is calculated for each adviser. I want to allocate customers to advisers in a way that minimises the variance in average policy values between each of the advisers. What I have tried My current algorithm randomly samples $n$ customers without replacement from the dataset and assigns each sample to an adviser. Once the allocations are made, the average policy value for each adviser is calculated and I compute the variance between each of the advisers. I repeat this over a defined number of iterations and return the allocation with the lowest variance. As expected, when dealing with larger volumes of advisers and customers this is not the most efficient process. My Question Is there an algorithm that converges towards the optimal allocation rather than randomly allocating on every iteration? How can I frame this problem as an objective function to minimise the variance? Any links to implementations (preferably Python) would be appreciated if possible","['numerical-optimization', 'linear-programming', 'linear-algebra', 'optimization', 'problem-solving']"
3237403,"$\,m = {\rm lcm}(a,b)\iff a,b\mid m\ \, \& \ \gcd(m/a,m/b)=1$","For $a \in\Bbb  N$ , $b\in\Bbb  N$ , $μ \in\Bbb N^*$ ,
we have $μ = \operatorname{lcm}(a,b) \iff  μ = αa\text{ and }μ= βb$ and $\gcd(α,β)$ is $1$ Till now I succeeded to prove the left $\Rightarrow$ right implication, now I need to prove the reciprocal ( $\Leftarrow$ way) Here is my work: Can someone help me, or give me a hint? Rules : you can't use the expression ( $a \wedge b)(a\vee b)=ab$ , $(ka)\vee(vkb) = k(a\vee b)$ + You can also help me improve my redaction if possible..","['elementary-number-theory', 'arithmetic', 'discrete-mathematics']"
3237436,Pointwise multiplication by unbounded function throws us out of $L^2(\mu)$,"Let $(X,\mathcal{A},\mu)$ be a $\sigma$ -finite measure space and let $\phi$ be a measurable function that is not an element of $L^\infty(\mu)$ , i.e. $\phi\not\in L^\infty(\mu)$ . I am trying to construct a function $g\in L^2(\mu)$ such that $\phi\cdot g\not\in L^2(\mu)$ . I tried partitioning $X$ in the sets $A_k=\{k\leq|\phi|<k+1\}$ so i could somehow control the behavior of $g$ on those sets relative to $\phi$ , but I needed something more. I considered a partition of $X$ in disjoint sets of finite measure say $(X_n)$ and then I tried to take their co-partition. The problem arising is that I cannot determine which of the sets $A_k\cap X_n$ are of non-zero measure. I am really stuck here. Any ideas?","['measure-theory', 'lp-spaces', 'functional-analysis']"
3237447,Find the Measures of the Missing Angles,"Find the measures of the angles $x$ and $y$ in the diagram above. I've tried using angles in the triangles and quadrilateral, exterior angles, and parallel lines. Everything I come up with reduces to $x+y=48$ . How can I introduce a different equation to solve for $x$ and $y$ ?","['euclidean-geometry', 'geometry']"
3237476,Calculating sum of converging series $\sum_{n=1}^{\infty}\frac{1-n}{9n^3-n}$,"I have a trouble with calculating the sum of this series: $$2+\sum_{n=1}^{\infty}\frac{1-n}{9n^3-n}$$ I tried to split it into three separate series like this: $$2+\sum_{n=1}^{\infty}\frac{1-n}{9n^3-n} =2+\sum_{n=1}^{\infty}\frac{2}{3n+1}+\sum_{n=1}^{\infty}\frac{1}{3n-1}-\sum_{n=1}^{\infty}\frac{1}{n} $$ but I'm not able to continue, can you give me some tips?","['integration', 'sequences-and-series']"
3237556,Solve ODE $y'' + (y')^2 + y = \ln(x)$,I want to solve $y'' + (y')^2 + y = \ln(x)$ with boundary conditions $y(1) = 0$ and $y(2) = \ln(2)$ . The solution is $y = \ln(x)$ but I don't know how to start the problem.,['ordinary-differential-equations']
3237576,Equivalence relation by the symmetric difference of sets,"Let $A, B$ subsets of $X$ and $\mathbb P(X)$ the power set, 
we define the following equivalence relation on $\mathbb P(X)$ : Let $ S\subseteq X$ a fixed subset of $X$ and $A$ ~ $B$ $\iff A△B \subseteq S$ Prove that is is an equivalence relation and find the class of $X$ and $S$ My work: I have already shown that the relationship satisfies reflexivity and symmetry, all this is justified respectively by the fact that the empty set is a subset of any set and the symmetric difference is commutative. My problem is with transitivity, I do not know how to do it, that is when I try to use it for the definition of symmetric difference I fall in many cases. There is some way to test transitivity using only operations between sets. And with respect to the equivalence class of $S$ , I showed that they are all subsets of $X$ contained in $S$ . But with respect to the equivalence class of $X4 I do not see what it is. Any help would be useful. Thank you!",['elementary-set-theory']
3237588,Increasing function is measurable,"First of all, I want you to know that I've checked all the questions related to mine and they seem not to be complete, in my opinion. Let me tell you why. Here's the problem: Let $f:\mathbb{R}\to\mathbb{R}$ be an increasing function (for $a,b\in \mathbb{R}$ such that $a<b$ , $f(a)\leq f(b)$ ). Prove $f$ is a measurable function. So the proof seems to be easy. If $f$ is increasing, there exists $\overline{x}$ such that $f(x)\geq \overline{x}$ . That is, $x\in\{x\in\mathbb{R}|f(x)\geq \overline{x}\} \iff x\in f^{-1}([\overline{x},+\infty])$ . The proofs I've seen so far assume that $f^{-1}([\overline{x},+\infty])$ is an interval, and thus $f^{-1}([\overline{x},+\infty])\in B(\mathbb{R})$ which results in $f$ being measurable since $\overline{x}$ is arbitrary. Here's the doubt: why can I say that, for a not-necessarily-continuous increasing function $f$ , $f^{-1}([\overline{x},+\infty])$ is an interval? The only answer I could find about this specific doubt is that the set of discontinuity points in $[a,b]$ of the function $f$ is at most countable. Then, $f$ is continuous almost everywhere (I haven't seen this concept in class yet) and thus $f$ is measurable (??). Sorry if this question is too basic, but I'd appreciate a hint","['measure-theory', 'measurable-functions']"
3237598,University clubs - Counting two ways,"Consider a university with 2000 male and 2000 female students. Suppose that none of the 4000 students signed up for 100 or more clubs (Each student signed up for at most 99 clubs). You also know that each pairing of male,female student shares a club, that they're both signed up for. Decide if it's possible for every club to have either at most 10 male students or at most 10 female students, or if there must exist at least one club, for which at least 11 male and at least 11 female students signed up. The general idea I guess would be to count the number of male/female pairs $(2000^2?)$ and then try to get the number of clubs utilizing counting two ways. I believe that once I get the number of clubs I should be able to verify if it's possible to reach the desired number of pairings with the limitation for male/female students (at most 10 of one or the other). But I'm not sure how to proceed to actually get the number of clubs.","['combinatorics', 'discrete-mathematics']"
3237617,Analytical solution to system of linear ODE's,"Given $x'=Ax$ with initial data $x(0)=\xi$ , eigenvalues $\lambda_j=0,0,3$ and $$\begin{bmatrix}2&1&0\\0&2&4\\1&0&-1\end{bmatrix},$$ find the general
  solution to the system and a canonical Jordan form of the matrix $A$ .
  Find all initial conditions such that solutions to the IVP will be
  bounded. To do this, the book says I need to use the following: Let the matrix $A$ have $s$ distinct eigenvalues $\lambda_1,\dots,\lambda_s$ with corresponding generalised eigenspaces $E(\lambda_j)$ . Represent the initial data $x(0)=\xi$ for the solution $x(t)$ as a sum of its components from different generalised
  eigenspaces: $$\xi=\sum_{j=1}^{s}x^{0,j},\quad x^{0,j}\in
> E(\lambda_j).$$ Here $x^{0,j}\in E(\lambda_j)$ - are components of $\xi$ in the generalized eigenspaces $E(\lambda_j)=\ker(A-\lambda_j)^{m_j}$ of the matrix $A$ . These
  subspaces intersect only in the origin and are invariant with respect
  to $A$ and $\exp(At)$ . It implies that for the solution $x_z(t)$ with
  initial data $z\in E(\lambda_j)$ , we have $x_z(t)\in E(\lambda_j)$ for
  all $t\in\Bbb R$ . Let $m_j$ be the algebraic multiplicity of the eigenvalue $\lambda_j$ .
  We apply the formula $(11)$ to this representation and derive the an
  expression for solutions for arbitrary initial data as a finite sum
  (intead of series): $$\begin{equation}x(t)=e^{At}x_0=\sum_{j=1}^{s}\left(e^{\lambda_jt}\left[\sum_{k=0}^{m_j-1}(A-\lambda_jI)^{k}\frac{t^k}{k!}\right]x^{0,j}\right)\tag{13}\end{equation}.$$ Series expressing $\exp(At)x^{0,j}$ terminates on each of the
  generalised eigenspaces $E(\lambda_j)$ . (Image that replaced text). Let me try: An eigenvector corresponding to $\lambda = 0$ can be taken as $v_1=\begin{bmatrix}1&-2&1\end{bmatrix}^T$ . For $\lambda=3$ we can take eigenvector $v_2=\begin{bmatrix}4&4&1\end{bmatrix}^T$ . Since the eigenvalue of zero is of algebraic multiplicity $2$ we need to find an extra generalized eigenvector $v_1^{(1)}$ such that we can express $\xi$ as a linear combination of these. We solve the equation $(A-\lambda I)v_1^{(1)}=v_1$ . Solving this we get that $v_1^{(1)}=\begin{bmatrix}1&-1&0\end{bmatrix}^T$ . Since we are in $\mathbb{R}^3$ we know that there can not be more than three generalized eigenvectors. In my case, $s=2$ since the multiplicity of the zero eigenvalue is $2$ . Thus expression $(13)$ can be written as \begin{align}
x(t)&=\sum_{j=1}^2\left(e^{\lambda_jt}x^{0,j}\left[\sum_{k=0}^{1}(A-\lambda_jI)\frac{t^k}{k!}\right]\right)\\
&= \sum_{j=1}^2\left(e^{\lambda_jt}x^{0,j}\left[1+(A-\lambda_jI)\right]\right)
\end{align} The problem I have here is that I don't understand how to express the $x^{0,j}$ .",['ordinary-differential-equations']
3237752,Grade 12: Data Management; Probability/binomial distributions -Homework help needed,"Struggling to figure these out, I have tried on my own a few times and have yet to get an answer that is remotely close to the correct one or what would be correct. In answer please include all steps 1) It is estimated that $17\%$ of cars are black. In a sample of $150$ cars, what is the probability that less than $20$ will be black? 2) It is estimated that $7\%$ of cars are blue. in a sample of $50$ cars, what is the probability that more than $10$ are blue? I have tried to solve for if no black cars and then subtract it from one to get the total for black cars but that didn’t work. I did a bunch of the ways we did in class but none of them seem to work, one of the ways I tried got me a negative number which is not possible for these.
I have been attempting by using the formula $\displaystyle P(x=k) = \binom{n}{k} p^k q^{n-k}$ I am not $100\%$ sure what the answer is, we weren’t  given it to be able to check. I have been trying this for a few hours now and haven’t made a dent. This is for an online class and the teacher is no help.
I am not sure how to do a sum of all the binomials that won’t take a million year with writing every single one out. Is their a short form? I don’t understand this. That video is not what we have learned so far And we have used tables in the past but not yet for this.","['binomial-distribution', 'probability']"
3237784,Show that the restriction of a quotient map onto a saturated open subset is still a quotient map.,"Def: Let $X,Y$ be sets and $p:X \rightarrow Y$ be a surjective map, then $A\subset X$ is called saturated with respect to p if it is the preimage of its image under $p$ , i.e. $A=p^{-1}(p(A)).$ Def et $X, Y$ be topological spaces, then a map $p:X \rightarrow Y$ is called a quotient map if $p$ is surjective, continuous and mapping saturated open sets of $X$ to open sets of $Y$ . Problem: Let $X, Y$ be topological spaces and $p:X \rightarrow Y$ be a quotient map (i.e. p is a continuous surjection s.t. $\forall$ open subset $A\subset X$ that is saturated with respect to $p$ , $p(A)$ is an open subset of $Y$ ). Then for a saturated open subset $A\subset X$ , $p|_A=q:A \rightarrow p(A)$ is a quotient map, where $A,p(A)$ are endowed with subspace topologies. Attempt: It suffices to prove that for any saturated open subset $B\subset A$ , i.e. $B=q^{-1}(q(B))$ , we have $q(B)$ open in $p(A)$ . Because $q$ is obviously surjective, and $q=p|_A\Rightarrow q$ is continuous. Since for any open subset $B\subset A$ , $B=A\cap U$ where $U$ is an open set in $X$ , we may assume that we are given a saturated open set $A\cap U$ . Observa that $A\cap U=q^{-1}\circ q(A\cap U)=p^{-1}\circ p(A\cap U)$ , since $A$ is saturated with respect to $p$ . So we have $A\cap U$ is saturated with respect to $p$ . Also note that $A\cap U$ is open in $X$ because $A,U$ are open in $X$ . By the assumption that $p$ is a quotient map, we know that $q(A\cap U)=p(A\cap U)$ is open in Y. Then $q(A\cap U)=p(A\cap U) \cap p(A)$ is open in $p(A)$ . Since the choice of $A\cap U$ is arbitrary, we conclude that $q$ is a quotient map.","['general-topology', 'proof-verification']"
3237802,Finding $\lim_{x \to 0+}\frac{x^{(\sin x)^x}-(\sin x)^{x^{\sin x}}}{x^3}$,"Problem $$\lim_{x \to 0+}\frac{x^{(\sin x)^x}-(\sin x)^{x^{\sin x}}}{x^3}.$$ Attempt \begin{align*}
&\lim_{x \to 0}\frac{x^{(\sin x)^x}-(\sin x)^{x^{\sin x}}}{x^3}\\
=&\lim_{x \to 0}\frac{\exp [(\sin x)^x\ln x]-\exp [{x^{\sin x}\ln(\sin x)]}}{x^3}
\\=&\lim_{x \to 0}\frac{\exp [{x^{\sin x}\ln(\sin x)]}(\exp [(\sin x)^x\ln x-{x^{\sin x}\ln(\sin x)}]-1)}{x^3}
\\=&\lim_{x \to 0}\frac{\exp [{x^{\sin x}\ln(\sin x)]} [(\sin x)^x\ln x-{x^{\sin x}\ln(\sin x)}]}{x^3}
\end{align*} This will help?",['limits']
3237820,How to come up with the Jacobian in the change of variables formula,"According to the change of variables formula for multivariable calculus, $$d\vec{v}=\left|\det(D\varphi)(\vec{u})\right|d\vec{u}$$ where $\vec{v}=\varphi\vec{u}$ and $\det(D\varphi)(\vec{u})$ is the Jacobian matrix of the partial derivatives of $\varphi$ at the point $\vec{u}$ . How to come up with this relationship (preferably conceptually)?","['jacobian', 'multivariable-calculus', 'change-of-variable', 'determinant']"
3237838,If a function is one-to-one but not onto does it have an infinite number of left inverses?,"The question I have asks to show that if a function $f: A \rightarrow A$ is one-to-one but not onto, it has at least two left inverses. I've worked out what I consider to be a solution, but what I found differs slightly from what the question is asking. First note that since the function maps $A$ to itself and it is one-to-one but not onto, one can assume that A is not a finite set. Next, let $i,j \in \mathbb{N}$ and let $x_i \in A$ be a fixed element in A such that if $i \neq j$ then $x_i \neq x_j$ . Now, let $n \in \mathbb{N}$ and define $g_n: A \rightarrow A$ as follows: Let $a,b \in A$ . If $f(a)=b$ then let $g_n(b)=a$ . Note that this is well defined since $f$ is one-to-one. If for $b \in A$ , $\nexists a \in A$ such that $f(a)=b$ , let $g_n(b)=x_n$ This function is a valid left inverse $\forall n \in \mathbb{N}$ since if $f(a)=b$ , we have that $g_n(f(a))=g_n(b)=a$ . Since $f$ is onto, there must be at least one $b$ that satisfies the second rule. Also, since $A$ must be an infinite set, $x_n$ must be defined $\forall n \in \mathbb{N}$ . This means that $g_n$ must also be defined $\forall n \in \mathbb{N}$ , so there is an infinite number of left inverses. I understand that an infinite number of inverses is still technically at least two inverses, but this wording has led me to think I've gotten something wrong here, and if there are any mistakes in my argument it would be fantastic if someone could point them out. Thanks. EDIT This is what I handed in, of which I got full marks: Let $A$ be a set such that $A \neq \emptyset$ and let $f \in F_A$ be a function, that is $f: A \rightarrow A$ . Suppose $f$ is injective but not surjective. Note that this means that $A$ must be infinite set. Next, let $i,j \in \mathbb{N}$ and let $x_i \in A$ be a fixed element in A such that if $i \neq j$ then $x_i \neq x_j$ . Now, let $n \in \mathbb{N}$ and define the family of functions $g_n: A \rightarrow A$ as follows: If for $b \in A$ , $\exists a \in A$ such that $f(a)=b$ then let $g_n(b)=a$ . Note that this is well defined since $f$ is injective, so $a$ will always be unique. If for $b \in A$ , $\nexists a \in A$ such that $f(a)=b$ , then let $g_n(b)=x_n$ . Now, let $a,b \in A$ such that $f(a)=b$ . By rule i. for $g_n$ , we have that $g_n(b)=a$ , so $g_n \circ f(a)=g(f(a))=g(b)=a=\iota (a)$ . Since $g_n \circ f=\iota$ , $g_n$ is a left inverse of $f$ , regardless of the value of $n$ since we did not use rule ii. of the definition of $g_n$ . As we noted before, $A$ must be an infinite set, so $x_n$ must be defined $\forall n \in \mathbb{N}$ , hence $g_n$ must also be defined $\forall n \in \mathbb{N}$ . Lastly, we will show that no two left inverses by this definition can be equal, because if $g_1=g_2=g_3=\ldots$ then there would only be one left inverse.. Let $i,j \in \mathbb{N}$ such that $i \neq j$ and let $b \in A$ such that $\nexists a \in A$ where $f(a)=b$ , which is possible since $f$ is not surjective. By rule ii. for $g_n$ , $g_i(b)=x_i$ and $g_j(b)=x_j$ . Since $i \neq j$ , then $x_i \neq x_j$ , hence $g_i \neq g_j$ . $\therefore$ Since $f$ has an infinite number of left inverses in $F_A$ , $f$ has at least two different left inverses $F_A$ .","['functions', 'abstract-algebra', 'inverse-function']"
3237845,Solve this differential equation $\Biggr(\frac{dy}{dx} -1\Bigg)\Bigg(y-x\frac{dy}{dx}\Bigg)=\frac{dy}{dx}$,Solve this differential equation: $$\Biggr(\frac{dy}{dx} -1\Bigg)\Bigg(y-x\frac{dy}{dx}\Bigg)=\frac{dy}{dx}$$ How to solve this?,"['integration', 'calculus', 'linear-algebra', 'ordinary-differential-equations']"
3237887,Can we approximate a.e. invertible matrices with everywhere invertible matrices in $L^2$ sense?,"Let $\mathbb{D}^n=\{ x \in \mathbb{R}^n \, | \, |x| \le 1\}$ be the closed unit ball, and let $A:\mathbb{D}^n \to \mathbb{R}^{n^2}$ be real-analytic on the interior $(\mathbb{D}^n)^o$ and smooth on the entire closed ball $\mathbb{D}^n$ . Suppose that $n \ge 2$ , and that $\det A >0$ a.e. on $\mathbb{D}^n$ . Are there smooth maps $A_k: \mathbb{D}^n \to \mathbb{R}^{n^2}$ , such that $A_k \to A$ in $L^2(\mathbb{D}^n , \mathbb{R}^{n^2})$ and $\det A_k >0$ everywhere on $\mathbb{D}^n$ ? Edit: In Vogel's elegant answer, it is proved that we can approximate $A$ via continuous maps. Can we approximate it with smooth maps? I think the answer should be positive, but I am having trouble with the details: Using mollifiers, we can approximate any continuous $A_k \in L^2(\mathbb{D}^n , \mathbb{R}^{n^2})$ with a smooth version $\tilde A_k$ in such a way to ensure that $\tilde A_k$ will converge to $A_k$ uniformly on compact subsets of $(\mathbb{D}^n)^o$ . Since $$s_k=\min_{x \in \mathbb{D}^n}\text{dist}(A_k(x), {\det}^{-1}(0))>0,$$ then if $\| \tilde A_k(y) -A_k(y)\| < s_k$ we have $\det(\tilde A_k(y))>0$ as we wanted. The problem is that we only have uniform convergence $\tilde A_k \to A_k$ on compact subsets of the interior of $\mathbb{D}^n$ , so I think we might have a problem on the boundary... Any ideas about how to finish this reduction?","['measure-theory', 'determinant', 'real-analysis', 'lp-spaces', 'perturbation-theory']"
3237889,Applying the Fourier transform to Maxwell's equations,"I have the following Maxwell's equations: $$\nabla \times \mathbf{h} = \mathbf{j} + \epsilon_0 \dfrac{\partial{\mathbf{e}}}{\partial{t}} + \dfrac{\partial{\mathbf{p}}}{\partial{t}},$$ $$\nabla \times \mathbf{e} = - \mu_0 \dfrac{\partial{\mathbf{h}}}{\partial{t}}$$ According to my textbook (provided as a passing comment by the author), the Fourier transform, $$F(\omega) = \int_{-\infty}^\infty f(t) e^{-j \omega t} \ dt,$$ can be applied to Maxwell's equations to go from the time domain $t$ to the angular frequency domain $\omega$ . My understanding is that this would take us from $$\nabla \times \mathbf{h} = \mathbf{j} + \epsilon_0 \dfrac{\partial{\mathbf{e}}}{\partial{t}} + \dfrac{\partial{\mathbf{p}}}{\partial{t}}$$ to $$\nabla \times \mathbf{H} = \mathbf{J} + j \omega \epsilon_0 \mathbf{E} + j \omega \mathbf{P} = \mathbf{J} + j \omega \mathbf{D}$$ and $$\nabla \times \mathbf{e} = -\mu_0 \dfrac{\partial{\mathbf{h}}}{\partial{t}}$$ to $$\nabla \times \mathbf{E} = - j \omega \mu_0 \mathbf{H}$$ I want to understand how to do this for the learning experience. I have experience with the Laplace transform but not the Fourier transform, and I cannot find anything online that goes through the steps of the transformation.  Do we just apply the Fourier transform $F(\omega)$ to every term in Maxwell's equations? How do we deal with the presence of vector terms in the context of such an integration? For instance, we have $$\nabla \times \mathbf{h} = \mathbf{\hat{i}} (\partial_y h_z - \partial_z h_y) - \mathbf{\hat{j}} (\partial_x h_z - \partial_z h_x) + \mathbf{\hat{k}} (\partial_x h_y - \partial_y h_x)$$ I would greatly appreciate it if people could please take the time to clarify this.","['integration', 'electromagnetism', 'fourier-transform', 'real-analysis', 'multivariable-calculus']"
3237978,There are no non-constant morphisms from $\mathbb{A}^1$ to a cubic curve,"Consider the cubic curve $X$ defined, over an arbitrary field $K$ , by the equation $y^2 =x(x−1)(x−\lambda)$ in $\mathbb{A}^2$ , where $\lambda \neq 0,1$ . Show that there are no non-constant morphisms $f : \mathbb{A}^1 \mapsto X$ . My attempt: Suppose $f: \mathbb{A}^1 \mapsto X$ is such that $f(t)=(h(t),g(t))$ for some $g(t),h(t) \in K[t]$ non constant. Then $g^2=h(h-1)(h-\lambda)$ and if $(t-\alpha)$ is a factor of $g(t)$ we have $(t-\alpha)^2$ divides the product $h(h-1)(h-\lambda)$ ; however $h,h-1$ and $h-\lambda$ are pairwise relatively prime, hence they don't share an irreducible factor $(t-\alpha)^2$ . It follows that $(t-\alpha)^2$ divides one of $h$ , $h-1$ and $h-\lambda$ . Moreover, if $(t-\beta)$ divides one of $h$ , $h-1$ and $h-\lambda$ then it divides $g^2$ and hence $(t-\beta)^2$ must divide one of $h$ , $h-1$ and $h-\lambda$ . It follows that each of $h(t)$ , $h(t)-1$ and $h(t)-\lambda$ is a square in $K[t]$ , but this is impossible unless $h$ is constant (and consequently, also $g$ is). The problem is that a morphism is defined by quotient of polynomials, or is it enough in this proof to use polynomials?","['curves', 'morphism', 'algebraic-geometry', 'elliptic-curves']"
