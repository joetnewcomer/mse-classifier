question_id,title,body,tags
1543056,Evaluation of $\int_{0}^{1}\frac{x\ln (x)}{\sqrt{1-x^2}}dx$,"Evaluation of $\displaystyle \int_{0}^{1}\frac{x\ln (x)}{\sqrt{1-x^2}}dx$ $\bf{My\; Try::}$ Let $\displaystyle I = \int_{0}^{1}\frac{x\ln x}{\sqrt{1-x^2}}dx\;,$ Put $x=\cos \phi\;,$ Then $dx = -\sin \phi d\phi$ and Changing Limit, We get $$\displaystyle I = -\int_{\frac{\pi}{2}}^{0}\cos \phi \cdot \ln(\cos \phi )d\phi = \int_{0}^{\frac{\pi}{2}} \ln(\cos \phi)\cdot \cos \phi d\phi$$ Now Using Integration by parts, We get $$\displaystyle I = \left[\ln(\cos \phi)\cdot \sin \phi\right]_{0}^{\frac{\pi}{2}}+\int_{0}^{\frac{\pi}{2}}\frac{\sin^2 \phi}{\cos \phi}d\phi$$ So $$\displaystyle I = \left[\ln(\cos \phi)\cdot \sin \phi\right]_{0}^{\frac{\pi}{2}}+\int_{0}^{\frac{\pi}{2}}\frac{(1-\cos^2 \phi)}{\cos \phi}d\phi$$ So $$\displaystyle I = \left[\ln(\cos \phi)\cdot \sin \phi\right]_{0}^{\frac{\pi}{2}}+\int_{0}^{\frac{\pi}{2}}\sec \phi d\phi-\int_{0}^{\frac{\pi}{2}}\cos \phi d\phi$$ So $$\displaystyle I = \left[\ln(\cos \phi)\cdot \sin \phi\right]_{0}^{\frac{\pi}{2}}+\left[\ln\left|\sec \phi+\tan \phi\right|\right]_{0}^{\frac{\pi}{2}}-\left[\sin \phi\right]_{0}^{\frac{\pi}{2}}$$ So $$\displaystyle I = \left[\ln(\cos \phi)\cdot \sin \phi\right]_{0}^{\frac{\pi}{2}}+\left[\ln\left|\sec \phi+\tan \phi\right|\right]_{0}^{\frac{\pi}{2}}-1$$ Now How can I solve after that, Help Required, Thanks","['definite-integrals', 'integration']"
1543105,"If an entire function satisfies $|f(z)| \leq C e^{M|z|}$, then $f(x)$ can't decay super-exponentially as $x\to\infty$","Let $f$ be a non-zero entire function.  Suppose there are positive real numbers $C$ and $M$ such that $|f| \leq C e^{M|z|}$ . Show that there is no function $g(x)$ , defined on $x>0$ with $\lim_{x \to \infty} g(x)=+\infty$ such that $f(x)=O(e^{-xg(x)})$ as $x \to \infty$ . Source: I'm reading Complex Analysis by Stein. From the assumption, I can know the order of $f$ is less than or equal to $1$ . Then how can I get from there?","['asymptotics', 'complex-analysis']"
1543142,Why does Arccos(Sin(x)) look like this??,"I can kind of understand the main direction (slope) of $y$ over the different $x$ intervals, but I can't figure out why  the values of $y$ take on the shape of straight lines and not curves looking more like those of sin, cos... EDIT : I understand that the derivative of Arccos(Sin(x)) gives 1 or -1 depending on the x interval, but it doesn't give me intuition into why that's the case.","['inverse', 'function-and-relation-composition', 'trigonometry']"
1543143,Limit with trigonometric function,"Find $$\lim_{x \to \pi/4}\frac{1-\tan(x)}{\cos(2x)}$$
  without L'Hôpital. $$\lim_{x \to \pi/4}\frac{1-\tan(x)}{\cos(2x)}=\lim_{x \to \pi/4}\frac{\cos^2(x)+\sin^2(x)-\frac{\sin(x)}{\cos(x)}}{\cos^2(x)-\sin^2(x)}$$ How can I continue?","['calculus', 'limits']"
1543156,"Given a matrix $A$ such that $A^{\ell}$ is a constant matrix, must $A$ be a constant matrix?","This problem originates from an exercise in Richard Stanley's Algebraic Combinatorics .  The exercise in the text (Chapter 3, Exercise 2(a)) asks Let $G$ be a finite graph (allowing loops and multiple edges).  Suppose that there is some $\ell> 0$ such that the number of walks of length $\ell$ from any fixed vertex $u$ to any fixed vertex $v$ is independent of $u$ and $v$.  Show that $G$ has the same number $k$ of edges between any two vertices (including $k$ loops at each vertex. The hypothesis of the problem (that the number of walks of length $\ell$ between any two vertices is the same) tells us that the adjacency matrix $A(G)$ of $G$ raised to the $\ell$ power is a constant matrix
$$ (A(G))^{\ell} = \begin{pmatrix} c & c & \cdots & c \\ c & c & \cdots & c \\ \vdots & \vdots & \ddots & \vdots \\ c & c & \cdots & c \end{pmatrix} $$
for some constant $C$.  We would like to conclude that this means the adjacency matrix itself is a constant matrix (hence, the number of walks of length 1 between any two vertices is the same, i.e., the number of edges between any two vertices is the same). Update in response to comments below: In this case we also have that $A(G)$ is a symmetric matrix which would eliminate some trivial counter examples. Does this result follow from something in linear algebra?  What is the proof?  If not, is there some other approach that might be more fruitful?","['algebraic-combinatorics', 'linear-algebra', 'matrices']"
1543164,Prove that $\sqrt{10} - \sqrt6 - \sqrt5 + \sqrt3$ is irrational,"I tried the methods shown in Can $\sqrt{n} + \sqrt{m}$ be rational if neither $n,m$ are perfect squares? but I cannot extend them well into 4 numbers.","['radicals', 'number-theory', 'irrational-numbers', 'rationality-testing']"
1543200,Volume of the solid intersecting 3 spheres,"Let the next three spheres:
\begin{array}{lcccl}
S_1 : &(x-1)^2 &+ &y^2 &+ &z^2 &=1, \\
S_2 : &x^2 &+ &y^2 &+ &z^2 &=1, \\
S_3 : &(x+1)^2 &+ &y^2 &+ &z^2 &=1.
\end{array} I have to calculate the volume of the solid inside $S_2$ and outside $S_1$ and $S_3$. Can you help me to determine the bounds of each integral if I have to use the cylindrical coordinates?","['calculus', 'volume', 'integration', 'spheres', 'multivariable-calculus']"
1543221,Proof that $\sqrt x$ is absolutely continuous.,"I want to prove that $f(x)=\sqrt x$ is absolutely continuous. So I must show that for every $\epsilon>0$,there is a $\delta>0$ that if $\{[a_k,b_k]\}_1^n$ is a disjoint collection of intervals that $\sum_{k=1}^n (b_k-a_k)<\delta$, then $\sum_{k=1}^n \left(\sqrt{b_k}-\sqrt{a_k}\right)< \epsilon$. I tried but I can't obtain $\delta$ independent from $n$. What is my mistake? Is there any hint? Thank you.","['continuity', 'real-analysis']"
1543294,Positive and negative variation of signed measures,"It is question 3.1.7 from Folland's Real Analysis Suppose $\nu$ is a signed measure on $(X,M)$ with $E \in M$. Show that $\nu^+(E) = \sup \left\lbrace \nu(F) : E\in M, F \subset E \right\rbrace$ and $\nu^-(E) = -\inf \left\lbrace \nu(F) : E\in M, F \subset E \right\rbrace$ Here's what I've done: For any $F \subset E$, by the Jordan Decomposition, there exists a unique positive measure $\nu^+$ and $\nu^-$. By monotonicity, we know $\nu^+(F) \leq \nu^+(E)$ and $\nu^-(F) \leq \nu^-(E)$. So we have: $$\nu(F) = \nu^+(F) - \nu^-(F) \leq \nu^+(F) \leq \nu^+(E)$$ Similarly, $\nu(F) \geq -\nu^-(E)$ Since $F \subset E$ was arbitrary we get: $\nu^+(E) \geq \sup \left\lbrace \nu(F) : E\in M, F \subset E \right\rbrace$ and -$\nu^-(E) \leq \inf \left\lbrace \nu(F) : E\in M, F \subset E \right\rbrace$ However, I'm having problems showing the reverse inequalities to conclude equality.","['real-analysis', 'measure-theory']"
1543301,Function in $L^p$ but not in $L^{\infty}$,"Show that if $$f(x) = \ln\left({1\over x}\right),\quad 0<x\le 1$$ then $f\in L^p((0, 1])$ for all $1 \le p < \infty$ but $f\not\in L^{\infty}((0, 1])$. Intuitively I know I have to show that $\int_{[0,1]}|f|^p <\infty $ but $f$ is not essentialy bounded, that means $\exists M >0$, s.t. $|f(x)|>M$ but I forget how to compute the integral and I am not sure how to find $M$. Any help, Thanks.","['lp-spaces', 'real-analysis', 'measure-theory']"
1543369,Basis of Quaternion Algebras,"I was reading some notes in which the definition of quaternion algebra is given as : For $a,b \in k^{*}$ ,we define $k$-algebra
by generators and relations as follows: it has two genrators $i$ and $j$ and is subject to the relations $i^2 = a,  j^2 = b, ij=-ij$.Any k-algebra isomophic to this is called a quaternion algebra. Now,to prove that $ {{1,i,j,ij}}$ is the basis for the quaternion algebra,it is easy to check that this is the spanning set.But to show the $k$-linear independence,they say that it is enough to check that the $k$-algebra with ${1,i,j,ij}$ as basis is associative. I am not getting this that how will the associativity of the algebra will imply the linear independence.(it might be simple but I am stuck at this).","['abstract-algebra', 'number-theory', 'linear-algebra']"
1543373,"Prove set of points in $[0,1]$ with prime digits is measurable","Let $A$ be the subset of $[0,1]$ consisting of all numbers such that every digit of $x$ after the decimal point is a prime number i.e. $x=0.p_1p_2p_3\ldots$, where $p_i\in\{2,3,5,7\}$. For example, $0.2$, $0.32$, $0.557$, $0.7532$, et cetera. I want to prove that $A$ is a Lebesgue measurable set and evaluate the Lebesgue measure $m(A)$. I notice that $A$ is an infinite set: $A = \{0.2, 0.22, 0.222,\ldots , 0.7777\ldots\}$. $A$ is bounded above by $0.777\ldots$, and bounded below by $0.2$ . Is that $A$ is compact and therefore measurable? I know that $m(X) = \text{length of }X=\lambda(X)$ when $X$ is an interval Also for $X \subseteq (0,1)$ and \lambda(X) = \lambda((0,1)) - \lambda((0,1)\X) I have not idea about how to evaluate $\lambda((0,1)\setminus A)$. Any ideas?","['lebesgue-measure', 'decimal-expansion', 'measure-theory']"
1543413,a practical question about matrix derivative with inverse and chain rule: dimension mismatch,"Recently, I was trying to take the following derivative 
$$
\dfrac{\partial (X^TV^{-1}X)^{-1}}{\partial V} 
$$
I was referring to matrix cookbook to solve it, where I found several useful equations: Equation (59) says:
$$
\dfrac{\partial Y^{-1}}{\partial x} = -Y^{-1}\dfrac{\partial Y}{\partial x}Y^{-1}
$$
so, I think I have:
$$
\dfrac{\partial (X^TV^{-1}X)^{-1}}{\partial V^{-1}} = -(X^TV^{-1}X)^{-1} X^TX(X^TV^{-1}X)^{-1}
$$
and 
$$
\dfrac{\partial V^{-1}}{\partial V} = -V^{-1}V^{-1}
$$
According to the chain rule, it should be:
$$
\dfrac{\partial (X^TV^{-1}X)^{-1}}{\partial V} =\dfrac{\partial (X^TV^{-1}X)^{-1}}{\partial V^{-1}}\dfrac{\partial V^{-1}}{\partial V} = ((X^TV^{-1}X)^{-1} X^TX(X^TV^{-1}X)^{-1})^T V^{-1}V^{-1}
$$ However, I met one problem. $V$ is a matrix of size $(n, n)$ and $X$ is a matrix of size $(n, m)$. 
Then, the first half of the chain rule is of size of $(m, m)$, while the second half of the chain rule is of size $(n, n)$. Please help me figure out what goes wrong. Thanks ahead.","['derivatives', 'inverse', 'chain-rule', 'matrices']"
1543419,Find Area of trapezium with circle inside,"There is a link to the question on stackoverflow As well description: We have a trapezium $ABCD$ and a circle inside it. all $4$ sides of trapezium are touching the circle. left side AB have length of $26\ cm$, and right side is $22 \ cm$. radius of a circle is $10\ cm$. With that knowledge we have to find the area of trapezium $ABCD$.","['geometry', 'trigonometry']"
1543424,Why is this claim about limits true,"I didn't understand why this claim from wikipedia is true ...More specifically, when $f$ is applied to any input sufficiently close to $p$, the output value is forced arbitrarily close to $L$. Is not the contrary? we have formally from the definition of limits: for every $\epsilon>0$ we have one $\delta>0$ such that
  $0<|x-p|<\delta\implies |f(x)-L| < \epsilon$. So I think, the best claim is ... More specifically, any output sufficiently close to $L$, the input
  value is forced arbitrarily close to $p$. So my question is why the wikipedia claim is true?","['analysis', 'calculus']"
1543447,"If $g \circ f$ is one-to-one, is $g$ one-to-one?","Let $f:X\to Y, g:Y \to Z$ be functions. I'm trying to prove that if $g \circ f$ is 1-1, then is $g$ 1-1? Well the definition of a one-to-one (injective) function  is that if $f:X \to Y$ is a function such that each $x \in X$ is related to a different $y \in Y$. I'm not sure what do do about the $g \circ f$ or how to show that that makes $g$ 1-1","['elementary-set-theory', 'proof-verification', 'discrete-mathematics', 'functions']"
1543480,Multi-index notation confusion,"While trying to understand a proof of equivalence of norms for $H^k(\mathbb{R}^n)$ (Fourier Transforms) I came across a possible inconsistency in the multi-index notation. Can somebody please clarify it for me? It is surprisingly hard to find it explained clearly anywhere. Suppose $x \in \mathbb{R}^n$ and that $\alpha = (\alpha_1,...,\alpha_n)$ is a multi-index. In lines with the multi-index notation we have $x^{\alpha} = x_{1}^{\alpha_1}...x_{n}^{\alpha_n}$. But then what is $|x^{\alpha}|^2$? If we were to be consistent then $|x^{\alpha}|^2 = |x_{1}^{\alpha_1}...x_{n}^{\alpha_n}|^2$, but that's not what is meant in this scenario, right? Here $|x^{\alpha}|^2 = \sum_{i=1}^n (x_i^{\alpha_i})^2$ or something like this, as with $|x|^2 = \sum_{i=1}^n x_i^2 $ See this question for some reference: Sobolev spaces fourier norm equivalence or Evans book on PDEs, Theorem 8, page 297, which is exactly about proving this result. I am perhaps completely in the dark about the problem and simply there is here a mixture of a notational confusion plus me not understanding the proof. I would have commented on the referenced question to ask for some insight, but being a completely new user I am not allowed to. I would really appreciate any feedback (also about asking questions here as it is my first attempt). Thank you!","['sobolev-spaces', 'functional-analysis']"
1543553,Problem with units in number field,"Edit:There were several major mistakes by my side this post, most of which have been accounted for.Now, after editing these out, the post seems to have no purpose at all.Nevertheless, it feels wrong to delete it, so I am going to leave it as it is. Consider the splitting field of $$x^3-2$$ which is $$K=Q(\alpha,\omega),$$ where alpha is the real cube root of 2 and omega is a primitive third root of unity.One can check that in fact $$K=Q(\alpha+\omega).$$ The galois group of K over Q is isomorphic to $$Z_2\times Z_3$$ and is abelian, so , by the Kronecker-Weber theorem, lies in a cyclotomic field, the smallest of which is dependent on the conductor of K. EDIT This in fact is wrong, the galois group of this extension is nonabelian, so K doesn't lie in a cyclotomic field. I was trying to solve $$a^3+2b^3+4c^3=1$$ in integers, which is the norm of an element of the form $$a+b\alpha+c\alpha^2.$$EDIT The norm is actually $$a^3+2b^3+4c^3-6abc$$Let $$O_K$$ be the ring of integers, so $$Z(\alpha,\omega)$$ is contained in it.By Dirichlet's unit theorem, the ring of integers is generated by 2 elements.EDIT the fundamental units can be found here: http://www.math.uconn.edu/~kconrad/blurbs/gradnumthy/unittheorem.pdf The diophantine equation seems to have a lot of solutions:(1,0,0),(5,-4,1),(-1,1,0) etc.So to solve this, we have to see when an element of the previous form is a product of powers of the two units.But the fundamental units look terrifying, so maybe this won't be a very fruitful process. Also, if someone can tell me what the actual ring of integers is, that would be really helpful.","['field-theory', 'number-theory', 'galois-theory', 'splitting-field', 'algebraic-number-theory']"
1543578,Is every closure of a metric space a completion?,"I know that every completion is a closure of a metric space, since every convergent sequence is cauchy and  and the limit of that sequence will exist within the completion. At the same time, from my understanding, every cauchy sequence will bunch closer together and get arbitrarily close to something, but it is just a question as to whether or not that element it gets closer to actually exists in the space. This leads me to the question as to whether every closure of a metric space is a completion, because we would just be adding the limits to sequences which exist outside of the original space, including the limits of nonconvergent cauchy sequences. So is there an example of a closure which is not a completion? Or are these notions  equivalent?","['complete-spaces', 'cauchy-sequences', 'real-analysis']"
1543614,How to simplify a complex expression involving trig functions?,"Specifically (it wouldn't fit into the question title), I'm trying to figure out how to turn $$\frac{-2v^2}{a^2} \cdot \sin({\arctan({\frac{vt}{a}}})) \cdot \cos^3(\arctan(\frac{vt}{a}))$$ into $$\frac{-2v^3 \cdot a \cdot t}{(a^2+v^2t^2)^2}$$ Where $v$ and $a$ are constants and $t$ is the independent variable. Wolfram Alpha tells me the two expression are indeed equivalent, but I can't seem to turn the first one into the second one algebraically. My thinking was,  $\arctan({\frac{vt}{a}})$ gives me the angle $x$ such that $\tan(x) = \frac{\sin(x)}{\cos(x)} = \frac{vt}{a}$, so shouldn't $\sin(x) = vt$ and $\cos(x)=\frac{1}{a}$? But that doesn't give me the right result, and I can see a flaw in that thinking because $\frac{\sin(x)}{\cos(x)} = \frac{vt}{a}$ just gives use the ratio of $\sin(x)$ to $\cos(x)$, and we can't deduce from that the actual values of $\sin(x)$ and $\cos(x)$. But so, how do you turn the first expression into the second one? If WA can tell me they are equivalent, I assume there's a way to show it.","['algebra-precalculus', 'trigonometry']"
1543621,Show number of permutations on $[n]$ where $i$ is not followed by $i+1$ is $D_n + D_{n-1}$,"I have that $a_n$ is the number of permutations where $i$ is not immediately followed by $i+1$ and:
\begin{align*}
a_n = \sum_{k=0}^{n-1} (-1)^k (n-k)!
\end{align*}
Which I obtained using the inclusion exclusion principle. I am trying to show that $a_n = D_{n} + D_{n-1}$ where $D_n$ is the number of derangements on $[n]$. Given that
\begin{align*}
D_n = \sum_{k=0}^n \frac{(-1)^kn!}{k!}
\end{align*}
I have tried to expand the summation for all terms but i am having trouble showing equality.",['combinatorics']
1543622,Combinatorics Inclusion - Exclusion Principle,"Find the number of integer solutions to $x_1 + x_2 + x_3 + x_4 = 25$ with $ 1 \leq x_1 \leq  6, 2 \leq x_2 \leq 8,
0 \leq x_3 \leq 8, 5 \leq x_4 \leq 9.$ Firstly, I defined $y_i = x_i - lower bound$ so for example $y_1 = x_1 - 1$
This gives $y_1 + y_2 + y_3 + y_4 = 17$ with $$0 \leq y_1 \leq 5, 0 \leq y_2 \leq 6, 0 \leq y_3 \leq 8, 0 \leq y_4 \leq 4$$
Next I applied Inclusion-Exclusion Principle; Total number of ways = $17+3 \choose 3$ Number of ways with just $y_i$ breaking upper bound; $y_1;$$11+3 \choose 3$ $y_2;$ $10+3 \choose 3$ $y_3;$ $8+3 \choose 3$ $y_4;$ $12+3 \choose 3$ Similarly I calculated the number of ways with $y_i$ and $y_j$ breaking upper bound at the same time. And since there is no way in which 3 of them break their upper bounds simultaneously I was left with ; $${20 \choose 3} - {14 \choose 3} - {13 \choose 3} - {11 \choose 3} - {15 \choose 3} + {7\choose 3} + {5 \choose 3} + { 9 \choose 3} + {4 \choose 3} + {8 \choose 3} + {6 \choose 3} $$ as my final answer. Is this solution correct and is there a nicer way of solving it/ any insights about this type of problem? Note, this problem is from 'An Introduction to Combinatorics and Graph Theory'","['multisets', 'inclusion-exclusion', 'combinatorics']"
1543634,Why is abelianness such a precious property?,"My abstract algebra teacher said the other day that constructions like ideals and cosets and normal subgroups are ""trying to capture a little bit of abelianness."" He has used phrases like ""magic happens"" when speaking of this property, or qualities that mimic commutativity in some way. So why is it such a game-changing quality? Thanks!","['abstract-algebra', 'abelian-groups', 'intuition']"
1543643,Prove that $\tilde{W}_t := W_{t+r}-W_r$ is a Brownian motion.,"I am to prove that, given a Brownian Motion(Wiener Process) $\{W_t\}$, a newly defined $\tilde{W}_t=W_{t+r}-W_r$ where $r \geq 0$ is a Brownian motion. I am stuck with showing it is a Gaussian process.
So, for some $s<t$, I need $\tilde{W}_t-\tilde{W}_s \sim N(0,t-s)$.
I simply substituted $\{W_t\}$ to end up with $W_{t+r}-W_{s+r}$. I managed showing the mean $\mu=0$ for this random variable. I am confused with the variance. I think I am doing some very fundamental error but I don't see where. So I need $\text{Var}[W_{t+r}-W_{s+r}]$. 
I understand the definition of variance to be, $\mathbb{E}[X^2]-\mu^2$. Now I showed that $\mu=0$ for our random variable so essentially, I need to compute, $$\mathbb{E}[(W_{t+r}-W_{s+r})^2]$$ By expansion, I obtain $\mathbb{E}[W_{t+r}^2-2W_{t+r}W_{s+r}+W_{s+r}^2]$ and by linearity, 
$$\mathbb{E}[W_{t+r}^2]-2\mathbb{E}[W_{t+r}W_{s+r}]+\mathbb{E}[W_{s+r}^2]$$ By independence, the middle term disappears and I am left with $\mathbb{E}[W_{t+r}^2]+\mathbb{E}[W_{s+r}^2]$. Since $W_t$ is a Brownian Motion, the expression I have is simply the sum of each variance, so $\mathbb{E}[W_{t+r}^2]+\mathbb{E}[W_{s+r}^2]=(t+r)+(s+r)$. Which clearly doesn't give me $t-s$. Can anyone please tell me what mistake I am making here? Is it something arithmetic? Error in the use of variance and mean? I need to know why I am wrong...Thank you","['probability-theory', 'brownian-motion', 'expectation']"
1543654,Finding the Maximum value.,"Maximize $xy^2$ on the ellipse $b^2x^2 +a^2y^2= a^2b^2$ The steps I tried to solve: $$\nabla f = (y^2,2yx)\lambda\qquad g = (2xb^2,2y^2a^2)\lambda$$ $$y^2= 2xb^2\lambda$$ $$2yx= 2y^2a^2\lambda$$ $$
\left.
\begin{array}{l}
\text{}&y^2= 2xb^2\lambda\\
\text{}&
\end{array}
\right\}
*a^2y
$$ $$
\left.
\begin{array}{l}
\text{}&2yx= 2y^2a^2\lambda\\
\text{}&
\end{array}
\right\}
*b^2x
$$ $$y^3a^2= 2yxa^2b^2 \lambda$$ $$2yx^2b^2 = 2y^2a^2b^2x\lambda$$ $\color{maroon}{\mathbf{Equalize}}$ $$2a^2b^2xy = 2a^2b^2xy^2$$ $$y=1$$ My main problem is which equations does one set each equal to. If anyone knows which one equals the other this will lead me to the right place in finding the solution.","['lagrange-multiplier', 'calculus', 'multivariable-calculus']"
1543660,Riemann Zeta Function integral,"I was reading about the Riemann Zeta Function when they mentioned the contour integral $$\int_{+\infty}^{+\infty}\frac{(-x)^{s-1}}{e^x - 1} dx$$ where the path of integration ""begins at $+\infty$, moves left down the positive real axis, circles the origin once in the positive (counterclockwise) direction, and returns up the positive real axis to $+\infty$."" They specified that $(-x)^{s-1} = e^{(s-1)\log(-x)}$ so that $\log(-x)$ is real when x is a negative real number. Furthermore, $\log(-x)$ is undefined when x is a positive real number as a result of this choice of $\log$. They proceeded to evaluate the integral by splitting it into $$\int_{+\infty}^{\delta}\frac{(-x)^{s-1}}{e^x - 1}dx + \int_{|x|=\delta}\frac{(-x)^{s-1}}{e^x - 1} dx + \int_{\delta}^{+\infty}\frac{(-x)^{s-1}}{e^x - 1} dx$$
I do not understand the justification for the path of the second integral; if $(-x)^{s-1}$ is undefined on the non-negative real axis, how can the path of integration cross the real axis at $x=\delta$, when $\delta$ is implicitly non-negative? EDIT: I am aware that $\log(-x)$ is defined on the entire plane except for some ray from the origin. What I am specifically confused about is how the contour is allowed to cross the ray on which $\log(-x)$ is undefined. EDIT: They describe the first and third integrals of the sum as being taken ""slightly above"" and ""slightly below"" the positive real axis as the function is undefined on the positive real axis.","['riemann-zeta', 'logarithms', 'integration', 'analysis', 'complex-analysis']"
1543667,$L^2(\Omega)/\Bbb{R}$ in cited reference?,"The following is a theorem in the preliminary material section of Constantin and Foias's ""Navier-Stokes Equations"": Let $\Omega\subset\Bbb{R}^n$ be an open bounded set with locally
  Lipschitz boundary. If a distribution $p\in D'(\Omega)$ has all its first derivatives $D_ip$ in $L^2(\Omega)$ then $p\in L^2(\Omega)$ and 
  $$
 \|p\|_{L^2(\Omega)/\Bbb{R}}\leq C(\Omega)\|\nabla p\|_{L^2(\Omega)^n}
 $$ If a distribution $p$ has all its first derivatives in    $H^{-1}(\Omega)$ then $p\in L^2(\Omega)$ and 
  $$   
 \|p\|_{L^2(\Omega)/\Bbb{R}}\leq C(\Omega)\|\nabla
 p\|_{H^{-1}(\Omega)^n}    $$ In both cases, if no restriction is imposed on $\partial\Omega$ it
  follows that $p\in L_{\hbox{loc}}^2(\Omega)$. By
  $\|p\|_{L^2(\Omega)/\Bbb{R}}$ we mean $$
 \inf_{c\in\Bbb{R}}\|p-c\|_{L^2(\Omega)}= \|p-\frac{\int_\Omega p \
 dx}{|\Omega|}\cdot 1\|_{L^2(\Omega)}. $$ The space $L^2(\Omega)/\Bbb{R}$ defined in the theorem looks quite strange to me (since the notation usually suggests a quotient space). 
Could anyone come up with a cited reference about this space?","['notation', 'measure-theory', 'real-analysis', 'reference-request', 'partial-differential-equations']"
1543683,"Confused about multinomials. Can we write $\binom{n}{a,b,c}=\binom{n}{a}\binom{n-a}{b}\binom{n-a-b}{c}$ if $a+b+c \le n$?","Can we write $\binom{n}{a,b,c}=\binom{n}{a}\binom{n-a}{b}\binom{n-a-b}{c}$ if $a+b+c \le n$? The definition for multinomial says $a+b+c=n$ must hold or else $\binom{n}{a,b,c}=0$. I found that if $a+b+c \ge n$ we get $\binom{n}{a,b,c}=0$, but if $a+b+c \le n$, then $\binom{n}{a,b,c}=\binom{n}{a,b,c, n-(a+b+c)}$","['discrete-mathematics', 'multinomial-coefficients', 'definition', 'combinatorics']"
1543685,Limit as n tends to infinity of $\frac{\sum_{i=1}^{n} \frac{i^2}{(i+1)\ln(i+1)}}{n^2}$,"I've been trying to compute the following limit for a while, I think it's $0$ but I can't find a way of proving it... $$\lim_{n \to \infty}\frac{\sum_{i=1}^{n} \frac{i^2}{(i+1)\ln(i+1)}}{n^2}$$ I've tried to compare it, I've tried to simplify the expression of the sum to infinity, but nothing convincing came out... Could you hint me? Thank you!!!","['sequences-and-series', 'divergent-series', 'limits']"
1543687,"If X is normally distributed, and c is a constant, is cX also normally distributed?","If $X\sim N(\mu, \sigma^2)$, and if $c$ is a constant, is $cX$ also normally distributed? How do you show it? If yes, does this apply to other distributions? So if $Y$ follows some type of distribution, will $cY$ also follow that distribution? Thank you very much!","['statistics', 'probability-distributions', 'random-variables']"
1543722,Why does the sign have to be flipped in this inequality?,"We are learning about inequalities. I originally assumed it would be the same as equations, except with a different sign. And so far, it has been - except for this. Take the simple inequality:
$-5m>25$ To solve it, we divide by $-5$ on both sides, as expected.
$m>-5$. But, I have been told that now we have to flip the inequality sign because we divided by a negative (and this also applies to multiplying negatives). $m<-5$ And this does work. Plug in any value less than $-5$ and it does turn out to be more than 25, but why? Mathematically, why do we flip the sign here?","['algebra-precalculus', 'inequality']"
1543771,"Prove $f(x)=x\sin(1/x)$ is uniformly continuous on $(0,1)$","Prove $f(x)=x\sin(1/x)$ is uniformly continuous on $(0,1)$.
I have tried to use the definition to prove this. $|x-y|<\delta \Longrightarrow |f(x)-f(y)|<\epsilon $.","['continuity', 'functions']"
1543805,Is the Laplace Beltrami operator a uniformly elliptic operator?,"The condition of uniform ellipticty for an operator $L=    (-1)^k\sum_{\alpha} a_\alpha(x)\partial^{\alpha}$  is expressed as the condition that:
$$    (-1)^k\sum_{|\alpha| = 2k} a_\alpha(x) \xi^\alpha > C |\xi|^{2k},\, $$ for every non-zero $\xi$ in $\mathbb{R}^{d}$ A usual example of these type of operators is the Laplacian . A natural generalization of the Laplacian in a Rimaniann manifold is the Laplace-Beltrami operator. My question is: What are the geometrical and regularity conditions on the metric such that the Laplace Beltrami operator is a strongly elliptic operator?","['functional-analysis', 'partial-differential-equations']"
1543829,Seemingly impossible double integral reduction,"Show that $\int_{0}^{1}\int_{0}^{1}(xy)^{xy}dxdy = \int_{0}^{1}y^{y}dy$ I have tried the method used in the Gaussian integral, polar coordinates, exp(.) and ln(.) of both sides of the integrand... Gaussian integral: https://en.wikipedia.org/wiki/Gaussian_integral I have also looked at the sophomore dream function, but I am not sure how to proceed that way in this case. Sophomore dream function: https://en.wikipedia.org/wiki/Sophomore%27s_dream Now I am stuck. Any help would be appreciated.","['calculus', 'integration']"
1543833,Are mappings $f: \mathbb{R} \to \mathbb{R}$ with $|f'(x)| < 1$ contractions?,"This is an extension of this question found here . Can we safely assume that all differentiable maps $f:\mathbb{R} \to \mathbb{R}$ with $|f'(x)| < 1$ are contraction mappings? For clarity, given a metric space $M$, a contraction mapping is defined as a continuous map $f: M \to M$ such that for some constant $k < 1$ and all $x, y \in M$, $$d(fx, fy) \leq kd(x,y)$$ Also, contraction mappings are contrasted with weak contractions, which are functions similarly defined, but only with the requirement that $$d(fx, fy) < d(x,y)$$
Progress so far: I've tried constructing counterexamples that have derivatives that approach 1 asymptotically but to no avail. Most of the counterexamples require that the function $f$ contain $log$ or $\frac{1}{x^n}$ terms, which are not defined on all of $\mathbb{R}$, and so contradict the requirement that $f:\mathbb{R} \to \mathbb{R}$.","['real-analysis', 'functions']"
1543844,Find the value of $\int_{0}^{\pi}e^{\cos\theta}\cos(\sin\theta)d\theta$.,"Find the value of $\int_{0}^{\pi}e^{\cos\theta}\cos(\sin\theta)d\theta$. $e^{\cos\theta}\cos(\sin\theta)=Re(e^{e^{i\theta}})$,where $Re()$ represents real part of. So our integral becomes $$
\int_{0}^{\pi}Re(e^{e^{i\theta}})d\theta
$$ Now by Cauchy integral formula, $$
\int_{0}^{2\pi}e^zdz=2\pi i
$$ But in Cauchy formula, the limits of integration are from $0$ to $2\pi$ and in my question, limits of integration are from $0$ to $\pi$. So I think I cannot apply Cauchy formula as such. What should I do? Please help me, Thanks.","['calculus', 'integration']"
1543847,On irreducible orientable manifolds,"The assumption on a $3$-manifold of being orientable and irreducible, and containing an embedded projective plane, automatically implies that the manifold is diffeormorphic to $\mathbb{RP^3}$? I'm not asking for a proof of this, this is obviously not a trivial result. I think it may be a consequence of a strong theorem in 3-dimensional topology, like Alexander's or the Sphere Theorem, it's just that I can't find it.
Could you give me some reference, or any idea in this direction?","['differential-geometry', 'algebraic-topology']"
1543877,Why is $\equiv$ used for functions that are Identically Zero?,"I have encountered contexts in which the ""definition"" or ""equivalent"" sign ""$\equiv""$ is used to make definitions of variables or functions. However, a common way authors use it is when a functions is identically zero. For example, if some function is determined to be ""trivial,"" it is not unusual to see a statement like ""...so then the function $f$ would be identically zero: $f \equiv 0$."" Why is it so common to use the $\equiv$ sign when an equals sign would seem to serve the same purpose above?","['notation', 'functions']"
1543879,How to show that the series of $\frac{\sin(n)}{\log(n)}$ converges?,"Edit:  I am seeking a solution that uses only calculus and real analysis methods -- not complex analysis.  This is an old advanced calculus exam question, and I think we are not allowed to use any complex analysis that could make the problem statement a triviality. Show that the series $$\sum_{n=2}^{\infty} \frac{\sin(n)}{\log(n)}$$ converges. Any hints or suggestions are welcome. Some thoughts: The integral test is not applicable here, since the summands are not positive. The Dirichlet test does seem applicable either, since if I let 1/log(n) be the decreasing sequence, then the series of sin(n) does not have bounded partial sums for every interval. Thanks,","['sequences-and-series', 'calculus', 'real-analysis', 'convergence-divergence']"
1543880,Splitting a renewal process,"This is a follow-up question of the question "" When superposition of two renewal processes is another renewal process? "". How can we split a renewal process $P$ into a renewal process $P_1$ and another process $P_2$ (not necessarily renewal), where $P_1$ and $P_2$ can be independent or dependent to $P$ ? If the rate (expected value of number of jumps in duration of time $t$ ) of $P$ is $\lambda$ , we want to get the rate $\lambda'$ for $P_1$ for any $\lambda'<\lambda$ . My solution: Assume $x = [x_1 x_2 \dots x_n]$ is generated according to the renewal process $P$ in time interval $[0,t]$ , where $x_i$ is the $i^{th}$ jump time that is generated according to the inter-renewal probability distribution, $p(x)$ . I think if we randomly take $(\lambda-\lambda') t$ of the jumps and remove them, we obtain another renewal process with rate $\lambda'$ because: 1. since we choose the jumps randomly, the pdf of the jumps will remain identical 2. since each removing of a jump means replacing the two consequent jumps $x_i,x_{i+1}$ by their sum $x_i+x_{i+1}$ that is independent to other elements of $x$ . Is that correct? any idea what is the general answer?","['probability-theory', 'stochastic-calculus', 'renewal-processes', 'stochastic-processes', 'probability']"
1543884,Prove that $f(A)$ is an open set and $f^{-1}:f(A)\to A$ is differentiable.,"Let $A\subset \mathbb{R}^n$ an open set, and $f:A\to \mathbb{R}^n$ a one to one and continuously differentiable function so that $\det f'(x)\ne 0$ for all $x\in A$ Prove that $f(A)$ is an open set and $f^{-1}:f(A)\to A$ is differentiable. Any idea on how to prove this? I´m totally lost.  (This seems related to the inverse function theorem). Any help or hint will be appreciated, thanks.","['partial-derivative', 'real-analysis', 'general-topology', 'inverse-function-theorem', 'multivariable-calculus']"
1543895,f(a) = a using the mean value theorem,"Say that $f$ is differentiable and that the derivative of $f$ does not equal $1$ on $(-\infty, \infty)$. Show that there is at most one real number a such that $f(a)=a$. In order to solve this I am required to use the mean value theorem. I understand that this will be true when $f(x)=x$, or when $f(x)-x = 0$. Thus if I could show that $f(x) -x !=0$ at any point this would be proven. Let $g(x) = f(x)-x$ $\dfrac{\mathrm dg}{\mathrm dx} = \dfrac{\mathrm df(x)}{\mathrm dx}$, which does not equal one $\dfrac{\mathrm df(x)}{\mathrm dx} \neq \dfrac{f(b)-f(a)}{b-a}$, by the mean value theorem thus: $b-a\neq f(b)-f(a)$ This is as far as I can get. I know I'm really close, and any help would be greatly appreciated.",['derivatives']
1543934,Roots of Complex Polynomial in Disc,"This is a theorem that I have encountered before and proved using some homotopy-theoretic arguments, but I tried to prove this statement again without such tools and ended up failing.  It seems to be Rouche's Theorem, but I can't figure out how to jimmy it just right. The statement is very nice: All roots of $p(z) = z^n + a_{n-1}z^{n-1} + \cdots + a_0$ lie in the disc centered at zero with radius $R = \sqrt{1 + |a_{n-1}|^2 + |a_{n-2}|^2 + \cdots + |a_0|^2}$ I keep thinking I have done it correctly, only to find an error.  Does anyone have a slick proof of this that just uses complex-analytic techniques?  I would really like to see just a sketch, or just the first step to start it off, but hey, I won't stop you from finishing it up haha For those who would think it's useful to see the homotopy-theoretic version, check Munkres Topology, Ch. 9.56 and the first exercise, but it seems impossible to state this proof without using homotopy. Thanks a lot!","['polynomials', 'complex-analysis']"
1543975,"If $z_1$ and $z_2$ are two complex numbers,and if $z_1^3-3z_1^2z_2=2,3z_1z_2^2-z_2^3=11$,","If $z_1$ and $z_2$ are two complex numbers,and if $z_1^3-3z_1^2z_2=2,3z_1z_2^2-z_2^3=11$,then find the value of $|z_1^2+z_2^2|$. $z_1^3-3z_1^2z_2=2$ $3z_1z_2^2-z_2^3=11$ Adding them,we get $z_1^3-3z_1^2z_2+3z_1z_2^2-z_2^3=13$ $(z_1-z_2)^3=13$ We need to find $|z_1^2+z_2^2|$, I could not solve from here,I am stuck.Please help me.Thanks.","['complex-numbers', 'algebra-precalculus']"
1544008,Quotient of nilpotent group is nilpotent,"Edit: I managed to rephrase my proof in a way that does not resort to coset multiplication. I think the resulting proof is better. I've added it as an answer below, while preserving the original question to avoid wrecking the context. In his book Finite Group Theory , section 1.D, Isaacs mentions without proof the following result: Proposition 1: If $G$ is a nilpotent group and $H \lhd G$, then $G/H$ is nilpotent. I think I have a proof but would appreciate confirmation and any suggestions for improvement. Isaacs' definition is that $G$ is nilpotent if it has a central series: $G$ is nilpotent if it has a central series, meaning that there are subgroups $N_i \lhd G$ such that $1 = N_0 \leq N_1 \leq \cdots \leq N_r = G$ and $N_i / N_{i-1} \leq Z(G / N_{i-1})$. I would like to work directly with this definition rather than with upper or lower central series. The reasons for this: (1) Isaacs' treatment of upper central series assumes that the group is finite, and uses the result I am trying to prove in order to establish the equivalence between ""$G$ has a central series"" and ""$G$ has an upper central series which reaches $G$""; (2) lower central series are not covered until a later chapter. Initially I tried to prove this by defining $M_i = N_i H / H$ and attempting to show that this results in a central series. I think I made it work using a somewhat messy argument involving the isomorphism and correspondence theorems, but then it occurred to me that instead it suffices to prove the following result: Proposition 2: If $G$ is nilpotent and $\phi : G \to H$ is an epimorphism, then $H$ is nilpotent. Then we can apply this to the canonical epimorphism $\phi : G \to G/H$ given by $\phi(g) = gH$, which gives the desired result. Proof: We have $N_i \lhd G$ and $1 = N_0 \leq N_1 \leq \cdots \leq N_r = G$, with $N_i / N_{i-1} \leq Z(G / N_{i-1})$. The latter condition can be stated equivalently as follows: if $n \in N_i$ and $g \in G$, then $ngN_{i-1} = gnN_{i-1}$. Now define $M_i = \phi(N_i)$ for every $0 \leq i \leq r$. Note that $M_0 = \phi(N_0) = \phi(1) = 1$, and $M_r = \phi(N_r) = \phi(G) = H$. Also, $M_i \lhd H$ by the correspondence theorem since $N_i \lhd G$. Now, let $m \in M_i$ and $h \in H$. To show that $M_i / M_{i-1} \leq Z(H / M_{i-1})$, it suffices to show that $mhM_{i-1} = hmM_{i-1}$. We have $m = \phi(n)$ and $h = \phi(g)$ for some $n \in N_i$ and $g \in G$. Then $mhM_{i-1} = \phi(ngN_{i-1}) = \phi(gnN_{i-1}) = hmM_{i-1}$, where the second equality holds because $N_{i} / N_{i-1} \leq Z(G / N_{i-1})$. We conclude that $1 = M_0 \leq M_1 \leq \cdots\leq M_r = H$ is a central series for $H$, so $H$ is nilpotent.","['abstract-algebra', 'group-theory', 'proof-verification', 'nilpotent-groups']"
1544026,Applications of the Hahn Banach theorem for normed spaces?,"If $X$ is the Euclidean space $\mathbb{R}^3$ and $f(x)=a_1 x_1 + a_2 x_2$, $x=(x_1, x_2) $  a bounded linear functional on the subspace $\mathbb{R}^2$ of $X$, how do I find a bounded linear functional $f'$ that is an extension of $f$ with the same norm as that of $f$? Does the functional $f'(x) = a_1 x_1 + a_2 x_2 + 0 \cdot x_3$ work?",['functional-analysis']
1544027,Hardy-Littlewood theorem about the Poisson integral for $p=1$,"(Hardy-Littlewood Theorem) : Let ‎$ u(r,‎\theta)‎$‎ be the Poisson integral of
‎$ ‎\varphi ‎\in L‎^{p}‎‎$‎, ‎$ 1<P ‎\leqslant‎ ‎\infty‎$‎ , and let $ U(‎\theta)=\sup‎_{r<1}‎|u(r,‎\theta)|‎ $‎. Then $ ‎U ‎\in L‎^{p}‎‎$, and there is a constant $A‎_{p}‎ $ depending only on $p$ such that  ‎‎$ ‎\Vert ‎U‎\Vert‎_{P}‎‎‎ ‎\leqslant A‎_{p}‎   ‎\Vert ‎\varphi ‎\Vert‎_{P}‎‎‎‎‎$‎. The proof of theorem is easy. But my question is why for $p=1$ Theorem is False.
I try to use the modified Poisson kernel $ u(r,‎\theta)= ‎\dfrac{R^2-r^2}{R^2-2R r   \cos‎\theta+r^2}‎‎$ for $R>1$. I use max and min $ u(r,‎\theta)‎$ but I can't solve the problem.","['harmonic-functions', 'harmonic-analysis', 'complex-analysis', 'hardy-spaces']"
1544056,Show that $(l_1)^* \cong l_{\infty}$,"Suppose that $l_1 = \{ (x_n)_{n \in \mathbb{N}} | \sum|x_n| < \infty \}$ and $l_{\infty} = \{ (x_n)_{n \in \mathbb{N}}| \sup|x_n| < \infty \}$. Show that $(l_1)^* \cong l_{\infty}$, where $(l_1)^*$ is a dual space of $l_1$. My attempt: Define a map $L: l_{\infty} \rightarrow (l_1)^*$ given by 
$$L(x)(y) = \sum_{n \in \mathbb{N}}{x_ny_n}$$ where $y = (y_n)_{n \in \mathbb{N}} \in l_1$. My aim is to show that $L$ is an isometric isomorphism. Clearly $L$ is linear and and injective (choose $y = e_n$ for all $n \in \mathbb{N})$. How to show that $L$ is a surjection and isometry?","['dual-spaces', 'isometry', 'functional-analysis']"
1544068,Support of Pullback of Differential form,"This is a dumb question, but I'm learning about differntial forms, and it seems to me that if $f:N^n\to M^n$ is a diffeomorphism and $\omega$ a smooth $n$ form on $M^n$, then $\omega$ vanishes at $p\in M^n$ $\iff$ the pullback $f^*\omega$ vanishes at $f^{-1}(p)$. This implies that if $\omega$ has compact support in $M^n\iff$  $f^{-1}\omega$ has compact support in $N^n$. Question 1: Is the above correct? Question 2: Does ""$\omega$ vanishes at $p\in M^n$ $\iff$ the pullback $f^*\omega$ vanishes at $f^{-1}(p)$If $f$"" hold if $f$ is just a surjective smooth map, instead of diffeomorphism?","['differential-geometry', 'differential-forms']"
1544130,Pullback of a semistable sheaf to a product is semistable?,"Let $X$ be a smooth projective variety over $\mathbb{C}$. Let $L$ be an ample line bundle on $X$. Let $F$ be a $\mu_L$ semistable rank 2 vector bundle on $X$ (semistability in the sense of Mumford-Takemoto). We have the projections $p_i:X\times X\longrightarrow X$ for $i=1,2$. Then $L'=p_1^*L\otimes p_2^*L$ is an ample line bundle on $X\times X$. I want to know if \ (a) $p_1^*F\oplus p_2^*F$ and (b) $p_1^*F\otimes p_2^*F$ are $\mu_{L'}$-semistable on $X\times X$. The first doubt I have is as follows. 1) We have the morphism $f:X\times X\longrightarrow X\times X$, $(x,y)\mapsto (y,x)$. This is an isomorphism. So under this isomorphism $f^*p_2^*F=p_1^* F$ right? So doesn't this mean that the chern classes of $p_i^*F$ are the same? If (1) is correct, in order to check (a) it is enough to check that the pull back $p_i^*F$ is $\mu_{L'}$ semistable (since the direct sum of semistable sheaves with the same slopes is semistable). The toy case I tried is $\mathbb{P}^1\times\mathbb{P}^1\longrightarrow\mathbb{P}^1$. But in this case it looks to be trivial. Because any $F$ on $\mathbb{P}^1$ is a direct sum of line bundles of the same degree. So the pull back will also be a direct sum of line bundles with same slope, and hence will be semistable. So it does not seem to be a very illuminating example. (2) In case when $X$ is a curve or a  surface, can we say that (a) and (b) are $\mu_{L'}$ semistable? Thanks in advance!","['algebraic-geometry', 'vector-bundles']"
1544163,An alternative measure of scatter.,"The context: Let $X$ be a random variable. A familiar measure for its scatter is variance
$$\text{Var}(X)=\mathbb{E} \left( \left( X- \mathbb{E}(X) \right)^2 \right),$$
which has several nice properties. A less common alterative is the ""$L_1$-version"" of variance
$$\text{MAD}(X)=\mathbb{E} \left( \, \left| X- \mathbb{E}(X) \right| \, \right)$$
that is a lot more difficult to deal with theoretically. However, sometimes when considering samples of observations following a heavy-tailed distribution, this quantity is more useful for applications since it is more robust against extreme values. The question: Let $X$ and $Y$ be i.i.d. Clearly $$\text{Var}(X+Y) = \text{Var}(X)+ \text{Var}(Y) \geq \text{Var}(X).$$
Do we have a similar inequality for MAD? I.e. is it true that
$$\text{MAD}(X+Y) \geq \text{MAD}(X)?$$
Intuitively, yes, but I'm not sure what to do. Tried Google, but no luck.","['probability', 'statistics']"
1544164,What technique should I apply to find the derivative of a ceiling or floor function e.g d/dx(x*⌈x⌉) and d/dx(x*⌊x⌋)?,"May I know the technique to apply to find the derivative, whenever I see a ceiling function of floor function. Thank You! e.g   $$ \frac{d}{dx}(x*\lceil x \rceil )$$  and $$ \frac{d}{dx}(x*\lfloor x \rfloor )$$ Is there a solution to $ \frac{d}{dx}(x*\lceil x \rceil )$ ?","['ceiling-and-floor-functions', 'derivatives']"
1544173,Setting up an English pool table,"A friend and I were playing some English pool yesterday. When you rack the balls it has the specific set up in the picture where the 8 ball must be in that central position and the balls are laid out either as in the picture OR the opposite way round, i.e. the reds take the yellow's positions. When you set up the game you generally place all the balls in a triangle and then rearrange them into the correct set up positions. We wondered what would be the least amount of moves it would take to get to the correct set up from a random starting position. We define a move here as swapping the position of two balls. My thoughts are that the upper bound is 4 moves. In the worst case scenario, you can guarantee at least 6 balls in incorrect positions regardless of whether you choose the set up in the picture or the opposite set up where the reds take the yellow's positions. Two colours must be the same in the two top right positions, so placing one of each colour in those positions guarantees one incorrect placement. Using the same logic for other positions (such as the striped lines in the bottom left) and placing the 8 ball away from the centre, the second picture shows a starting position guaranteeing 6 incorrect balls. I suspect you can now place the remaining balls arbitrarily and the least number of moves will depend on which colour is in the 8 ball's position. I think that that swap should also determine whether you should choose the set up in the first picture or the opposite set up, but I can't quite formalise this. Anyway, I thought it was a fun problem if anyone cares to prove or disprove the conjecture!","['recreational-mathematics', 'combinatorics']"
1544224,Partitioning the integers into two subset,"Let $S=\{1,2,3,4,5,...2N\}$ be the set of the first $2N$ natural numbers. Partition the set into two subsets (each subset will have $N$ elements). Arrange one subset in increasing order and the other in decreasing order. If we Sum the absolute value of the difference of two corresponding elements, the answer is $N^2$. I've read an article online about this one but now I cannot find it. Can somebody show me a link about the statement above? or can somebody show me a proof? Does anybody know a more general statement related to the above? Thanks.",['number-theory']
1544324,"The number of solutions of $\sin(x) + 2\sin(2x) + 3\sin(3x) + 4\sin(4x) = 10$ in $( 0 , \pi )$?","Find the number of solutions in $( 0 , \pi )$ of the equation
  $$\sin(x) + 2\sin(2x) + 3\sin(3x) + 4\sin(4x) = 10.$$ I have no idea about how to approach this problem . I thought of converting everything into $\sin(x)$ and $\cos(x)$ but that would be too long and make it more complex .","['algebra-precalculus', 'trigonometry']"
1544355,Limit of a sequence using Hölder's inequality,"Let $a_1,\ldots,a_p$ be positive real numbers. Find the limit of $$\left(\frac{a_1^n+\cdots+a_p^n}{p}\right)^{1/n}$$ My attempt: I applied Hölder's and have obtained that this term is bounded below by $\frac{a_1+\cdots+a_p}{p}$ and since $a_1^p+\cdots+a_n^p \le (a_1+\cdots+a_p)^n$ is valid, applying log of limits technique, I get that it is bounded above by $a_1+\cdots+a_p$. However, I haven't obtained an actual limit. In fact I don't know the actual answer. I think it could be the lower bound I obtained, because that answer is validated for certain examples, like, by putting all values of $a_i$'s as a constant $k$, but I am not able to get a suitable idea to conclude that. Any help?","['limits', 'real-analysis', 'inequality']"
1544422,Calculating decimal digits by hand for extremely large numbers,"On the most recent Seton Hall Joseph W. Andrushkiw Competition, the final question was as follows: Let $A = (\sqrt{3}+\sqrt{2})^{2016}$. When A is written in decimal
  form, what is its $31^{st}$ digit after the decimal point? Brute forcing it via wolfram alpha reveals that the answer is [edit: I found the 31st number from the start, not the 31st after the decimal point] zero, yet this competition does not allow the use of a calculator. It seems to me that as irrational numbers are in the base of the exponent, there should not be an identifiable pattern in the digits. Searching this site has made me think that perhaps the answer has something to do with the Euler phi function (something which I will admit up front I have never been acquainted with), but I can't find anything which I understand enough to give me a concrete way to start to approach this. Any help on this frustrating problem would be appreciated. Thanks!","['elementary-number-theory', 'algebra-precalculus']"
1544449,Product of random variables convergence in probability,"I want to prove that if $X_n\overset{P}\to X$ and $Y_n\overset{P}\to Y$, then $$X_n+Y_n\overset{P}\to X+Y,$$
$$X_nY_n\overset{P}\to XY$$ Proof for the first one I simply use triangle inequality
$$
\mathbf{P}\left(\omega \mid |(X_n(\omega)+Y_n(\omega))-(X(\omega)+Y(\omega))|<\epsilon\right) \leqslant \mathbf{P}\left(\omega \mid |(X_n(\omega)-X(\omega))|+|Y_n(\omega)-Y(\omega)|<\epsilon\right)\leqslant$$
$$\leqslant \mathbf{P}\left(\omega | |X_n(\omega)-X(\omega)|<\frac{\epsilon}2\right)+\mathbf{P}\left(\omega | |Y_n(\omega)-Y(\omega)|<\frac{\epsilon}2\right)\underset{n}\to 0$$ I could use some ideas to prove convergence for the product.","['probability-theory', 'convergence-divergence']"
1544458,Proving that there's no translation invariant measure on the power set of $\mathbb{R}$,"The goal of this task given to me is to show that there is no (non-trivial) translation invariant measure on $P(\mathbb{R})$, the power set of $\mathbb{R}$, and I think I almost completed it, but I just can't find a way to prove the very last bit that's missing. But let's start at the beginning. Let $\mu: P(\mathbb{R}) \to [0, ∞]$ be a measure that satisfies the following conditions: $(*) \mu([0, 1]) = 1$ and $\mu(x + A) = \mu(A)$ for all $x \in \mathbb{R}, A \subseteq \mathbb{R}$. The assignment asks me to consider the equivalence relation $x \sim y :<=> x - y \in \mathbb{Q}$ Out of every equivalence class, we choose a representative $x \in [0, 1]$. Let $X \subseteq [0, 1]$ be the set of representatives that we got that way. I am now to consider the sets $\mathbb{R} = \cup_{x \in X} (x + \mathbb{Q})$ and $\mathbb{R} = \cup_{q \in \mathbb{Q}} (X + q)$, and find a contradiction by showing that $\mu$ would need to satisfy both $\mu(X) = 0$ aswell as $\mu(X) > 0$. What I've shown so far: I showed that $\mu(\mathbb{R}) = ∞$ (using the fact that $[0, 1]$ is sent to $1$), aswell as that $\mu(\{a\}) = 0$ for all $a \in \mathbb{R}$. From this, it also follows that all countable subsets of $\mathbb{R}$ are sent to $0$ by $\mu$ (so especially $\mu(\mathbb{Q}) = 0$). I've also shown that, since $\mu(\cup_{q \in \mathbb{Q}} (X + q)) = ∞$ and since $\cup_{q \in \mathbb{Q}} (X + q)$ is a countable, disjoint union, we have that $\mu(X) > 0$. The only part I'm still missing is to show that $\mu(X) = 0$ via the fact that $\mathbb{R} = \cup_{x \in X} (x + \mathbb{Q})$, as written above. I just can't get my head around how I could show this. $\cup_{x \in X} (x + \mathbb{Q})$ is a disjoint, but uncountable union because $X$ contains uncountably many elements; therefore, we can't use the $\sigma$-additivity of a measure. I see that $\mu(x + \mathbb{Q}) = 0$ for each $x \in X$, because $\mathbb{Q})$ is countable, but I don't know how that helps me. I've also thought about decomposing $[0,1]$ into a disjoint union of sets, but that didn't lead anywhere so far. If we ""remove"" countably many points of $[0,1]$, the remaining set would still be sent to $1$ by $\mu$, for the reasons given above. So how could I conclude that $X$ must be sent to $0$? I'm out of ideas.","['analysis', 'real-analysis', 'measure-theory']"
1544460,Group of $r$ people at least three people have the same birthday?,"What is the probability that in a randomly chosen group of $r$ people at least three people have the same birthday? $\displaystyle 1- \frac{365\cdot364 \cdots(365-r+1)}{365^r}$ $\displaystyle \frac{365\cdot364
        \cdots(365-r+1)}{365^r} +{r\choose 2}\cdot \frac{365\cdot364\cdot363 \cdots
        (364-(r-2) +1)}{364^{r-2}}$ $\displaystyle 1- \frac{365\cdot364
            \cdots(365-r+1)}{365^r} +{r\choose 2}\cdot \frac{365\cdot364\cdot363 \cdots (364-(r-2) +1)}{364^{r-2}}$ $\displaystyle\frac{365\cdot364 \cdots(365-r+1)}{365^r}
                $ My attempt : (May be typo in option $(3)$ of question !) $$P(\text{at least 3 persons have same birthday})$$ $$= 1 - \{P\text{(no one has same birthday) + P(any 2 have same birthday)\}}$$ So, option $(3)$ is true. Can you explain it, please? It asked here before,  but I'm not satisfied by explanation.","['birthday', 'probability', 'combinatorics', 'permutations']"
1544464,"Set all measurable real functions on $[0,1]$ with metric $\int_{0}^1 \min \{1,|f(t)−g(t)|\}dt$ is Fréchet without nonzero continuous linear functional","Bounty Edit: In the following, all the questions will be highlighted by a bold number and a text written in italics. I found the following statement in a book, and I am really struggling to see why it is true. The set of all measurable real functions on $[0,1]$, metrized via the map $$(f,g)\mapsto \int_{0}^1 \min \{1,|f(t)−g(t)|\}dt,$$ is a Fréchet space on which there is no nonzero continuous linear functional. (Even the linear functional $f\mapsto f(0)$ is not continuous on this space). Regarding the very last statement in braces, I should have a proof of it. Attempted Proof: Let $f=0$, i.e. for every $x \in [0,1], f(x) = 0$, and define $f_n$ as
  $$ f_n (x):=
\begin{cases}
1, & \text{ if } x \in [0, \frac{1}{n}],\\
0, & \text{ if } x \in (\frac{1}{n}, 1].\\
\end{cases}$$
  To see that $f_n \to f$, notice that, for an arbitrary $n \in \mathbb{N}$, we have
  $$ \begin{align*} d(f_n , f) &= \int_{0}^1 | f_n (t) - f(t) | \ dt \\
&\leq \int_{0}^1 | f_n (t)| + |f(t) | \ dt \\ 
&= \int_{0}^1 | f_n (t)|\ dt  + \int_{0}^1 |f(t) | \ dt \\
&= \int_{0}^1 | f_n (t)|\ dt \to 0 \end{align*} $$
  However, $f_n(0) \nrightarrow f(0)$, because for every $n \in \mathbb{N}$, $f_n (0) =1$, while $f(0)=0$. Concerning it, here there is my first question : 1) Is the way in which I wrote the proof correct? Regarding the main statement, the things that have to be proved are two: a) $\mathcal{M}$ (that denotes the set of all measurable functions on $[0,1]$) is a Frechét space (complete metric linear space); b) there are no nonzero continuous linear functionals on $\mathcal{M}$. Related to part (b) I found in Rudin's ""Functional Analysis"" (pp.36-37, section 1.47) a proof that the space $L^p$
with $0 < p <1$ behaves in the same way. Moreover, on the wikipedia page on locally convex TVS I found that there is still another space that behaves similarly, namely $L_0$, i.e. the set of all measurable functions with distance function $$d(f,g):= \int_{0}^1 \frac{|f(x) - g(x)|}{1+|f(x)-g(x)|}dx.$$ Thus, here there are my other questions . 2) Is it possible to prove part (a) in different ways, namely one less constructive, and another one more constructive, with an actual $f \in \mathcal{M}$ to which an arbitrary Cauchy sequence $(f_n) \subseteq \mathcal{M}$ converge? If yes, how? 3) Is it possible to prove part (b) by showing that $\mathcal{M}$ is homeomorphic to $L_0$, which is homeomorphic to $L^p$ with $0 < p <1$, and then exploiting Rudin's proof? Are all those spaces actually homeomorphic? If yes, how? 4) If they are not homeomorphic, and we cannot use Rudin's proof, essentially, how do we prove the result, namely part (a) and part (b)? I am looking forward to any answer, because being self-thaught I am having some real problems concerning this result, and I have the feeling that grasping this proof (with the techniques involved) would help me a lot. Thank you for your time.","['proof-verification', 'real-analysis', 'functional-analysis', 'linear-transformations', 'self-learning']"
1544484,"Show $S_N = \sum\limits_{n=1}^{N} \text{sign}(Y-X_n)$ is Markov, $(X_n),Y $ iid Uniform(0,1)","Let $(X_n)$ and Y be i.i.d. Uniform$(0,1)$ random variables and let 
$$S_N = \sum\limits_{n=1}^{N} \text{sign}(Y-X_n)$$ Show that $S_n$ is a Markov Chain and find its transition probabilities. Any help with this one? Its clear that $\mathbb{P}(S_N = x\,\,\vert\,\, S_{n-1},...S_0) = \mathbb{P}([(S_N = x)\cap S_{N-1} = x-1]\cup[(S_N = x)\cap S_{N-1} = x+1]\,\,\vert\,\, S_{n-1},...S_0) = \mathbb{P}([(S_N = x)\cap S_{N-1} = x-1]\cup[(S_N = x)\cap S_{N-1} = x+1]\,\,\vert\,\, S_{N-1})$ How would you find the transitional probabilities?","['probability-theory', 'probability', 'markov-chains', 'stochastic-processes']"
1544495,Continuous functions that attain local extrema at every point,"Let $f:[0,1]\to\mathbb R$ is a continuous function, and for all $x\in [0,1]$, $f(x)$ is either a local maximum or a local minimum. Then prove that $f$ is a constant. Here is what I have tried, I don't know whether it is correct: Assume $f$ is not a constant, by continuity, there exist $x_1$, $x_2$ such that $f(x_1)=m$ is a global minimum and $f(x_2)=M$ is a global maximum. Now if $m\ne M$, choose any $c\in(m,M)$ and define $$x_0=\sup (x\in[x_1,x_2]:f(x)<c)$$ Then we have $f(x_0)$ NOT a local minimum nor a local maximum (since according to the definition of $x_0$, there are always some points $<c$ in the left neighborhood of $x_0$ and the points in right neighborhood are always $>c$). Contradiction arises and so $f$ must be a constant.","['analysis', 'real-analysis']"
1544527,The maximum-likelihood estimators of $\sigma^2$,"A sample of size $n$ is drawn from each of four normal populations, all of which have the same variance $\sigma^2$ . The means of the four populations are $a+b+c$ , $a+b-c$ , $a-b+c$ and $a-b-c$ . What are the maximum-likelihood estimators of $c$ , $b$ , $a$ and $\sigma^2$ . $a$ , $b$ , $c$ solved. But for $\sigma^2$ .
Is this answer correct $\sigma^2 = \frac{1}{4}(s^2_1+s^2_2 + s^2_3 + s^2_4)$ .","['estimation', 'probability', 'statistics', 'statistical-inference']"
1544535,Partial sum of $\sum \frac {1} {k^2}$,"It is pretty well-known that $\sum_{k = 1}^{\infty} \frac {1} {k^2} = \frac {\pi^2} {6}$. I am interested in evaluating the partial sum $\sum_{k = 1}^{N} \frac {1} {k^2}$. Here is what I have done so far. Since we have $$\sum_{k = 1}^{N} \frac {1} {k^2} = 1 + \sum_{k = 2}^{N} \frac {1} {k^2}
< 1 + \sum_{k = 2}^{N} \frac {1} {k^2 - 1} =\\= 1 + \frac {1} {2} \left ( \sum_{k = 2}^{N} \frac {1} {k - 1} - \sum_{k = 2}^{N} \frac {1} {k + 1} \right )
= 1 + \frac {1} {2} \left ( \frac {3} {2} - \frac {2N + 1} {N^2 + N} \right )
= \frac {7} {4} - \frac {2N + 1} {2 N^2 + 2 N}$$
and $$\sum_{k = 2}^{N} \frac {1} {k^2 - 1} - \sum_{k = 2}^{N} \frac {1} {k^2} < \int_{2}^{N} \left ( \frac {1} {x^2 - 1} - \frac {1} {x^2} \right ) \textrm {d}x = \int_{2}^{N} \frac {\textrm {d}x} {x^2 - 1} - \int_{2}^{N} \frac {\textrm {d}x} {x^2} < \frac {1} {N^2 - N} - \frac {1} {2} + \log \sqrt {3},$$ we have $$\frac {7} {4} + \frac {1} {2} - \log \sqrt {3} - \frac {2 N^2 + N + 1} {2N^3 - 2N} < \sum_{k = 1}^{N} \frac {1} {k^2} < \frac {7} {4} - \frac {2N + 1} {2 N^2 + 2 N}$$ But how to obtain a more precise expression without using analytic methods such as Euler summation ?",['sequences-and-series']
1544552,"Find closed form of a sequence $2,5,11,23,...$","Find closed form of a sequence $2,5,11,23,\dots$ How to get generating function for this sequence (closed form)? Explicit form is $f(x)=2+5x+11x^2+23x^3+\cdots$ Is it possible to get to geometric series representation? I tried to derive the series multiple times, but that doesn't help. Could someone give a hint?","['sequences-and-series', 'generating-functions', 'discrete-mathematics']"
1544591,"Find the number of all ordered triplets $(A,B,C)$ of subsets of $X$ such that $A$ is a subset of $B$ and $B$ is a proper subset of $C.$","Let $X$ be as set containing $n$ elements.Find the number of all ordered triplets $(A,B,C)$ of subsets of $X$ such that $A$ is a subset of $B$ and $B$ is a proper subset of $C.$ I have no idea how to solve this problem.Please help me.Thanks.","['elementary-set-theory', 'combinatorics']"
1544610,Natural logarithmic derivative trick,"Hi chaps and chapesses, I was wondering if someone could just explain something. If I have a function which is dependent on $x$, the familiar $f(x)$. Now, if I take the derivative of this, and multiple by $x$ and divide through by $f(x)$. How does this then become true: $$
\frac{x}{f(x)}\frac{d(f(x))}{dx}=\frac{d\ln{f(x)}}{d\ln{x}}
$$ I'm thinking I'm either a.) tired, b.) stupud or c.) both","['logarithms', 'derivatives']"
1544618,is the inverse of a absolutely continuous function with almost everywhere positive derivation absolutely continuous?,"suppose $f$ is an absolutely continuous on $[0,1]$,that almost everywhere $f'>0$. is the inverse of $f$ necessarily absolutely continuous on $[f(0),f(1)]$? thank you very much!","['continuity', 'real-analysis', 'functional-analysis']"
1544623,Variational characterization of nuclear norm,"The nuclear norm $||\cdot||_{*}$ of a matrix is defined as the sum of its singular values. Working from the result at the bottom of this blog post , we have, for a matrix $\mathbf{X}$ and its decomposition $\mathbf{L} \mathbf{R}^T$, $$
\|\mathbf{X}\|_* = \min_{\mathbf{X=LR}^T} \|\mathbf{L}\|_F \|\mathbf{R}\|_F = \min_{\mathbf{X=LR}^T} \frac{1}{2} \left(\|\mathbf{L}\|_F^2 + \|\mathbf{R}\|_F^2\right)
$$ where, for example, $\mathbf{L} = \mathbf{U\Sigma}^{1/2}$, $\mathbf{R} = \mathbf{\Sigma}^{1/2} \mathbf{V}^T$, and $\mathbf{X} = \mathbf{U\Sigma V}^T$ is the SVD of $\mathbf{X}$. The basis for this is the paper by Recht et al. from 2007: ""Guaranteed Minimum-Rank Solutions of Linear Matrix Equations
via Nuclear Norm Minimization"" . In a paper on Robust Principal Component Analysis (RPCA) by Feng et al., this result is used to reformulate the RPCA problem so as to minimize the nuclear norm without needing to access all the samples to perform an SVD calculation (see Eq.2 in that paper). I'm interested in a possible extension to the case of two-dimensional SVD ( original paper and Wikipedia article ), where for a group of matrices $(\mathbf{X}_1,...,\mathbf{X}_n)$, we instead have the following type of decomposition: $$ \mathbf{X}_i = \mathbf{L} \mathbf{M}_i \mathbf{R}^T $$ Is the following correct? $$
\|\mathbf{X}_i\|_* = \min_{\mathbf{X}_i=\mathbf{L}\mathbf{M}_i\mathbf{R}^T} \frac{1}{2} \left(\|\mathbf{L}\|_F^2 + \|\mathbf{M}_i\|_F^2 + \|\mathbf{R}\|_F^2\right)
$$ Or am I being far too hopeful for such a simple solution...","['nuclear-norm', 'matrices', 'convex-optimization', 'normed-spaces', 'linear-algebra']"
1544625,Different colored dice placed in urns.,"You roll $6$ die, $2$ red dice, $2$ blue dice and $2$ green dice. Any  number rolled between $1-2$ is placed in Urn 1, any number rolled between $3-4$ goes into Urn $2$, and any number rolled between 5-6 goes into Urn $3$. a) What is the probability that each 2 of the same colored die end up in the same urn (ie. you cant have the 2 red and the 2 blue dice in the same urn)? b) What is the probability that exactly 2 die end up in each urn (color doesn't matter for this part)? For part a), I just thought of it like this... first die of any color can be placed anywhere and the die of the same color has a 1/3 chance of being placed with it. The second color die can be placed in 2 of the remaining urns (2/3) and the other same colored die needs to be placed in that urn as well (1/3), the final colored die need to be placed in the last remaining urn so (1/3) and the second die of that color needs to be placed in that urn as well (1/3). So i got $(3/3)*(1/3)*(2/3)*(1/3)*(1/3)*(1/3)=6/729$ For part b, i got the probability that exactly two die end up in each urn to be 1/3 since the die color doesnt matter here. Do these answer make sense? If they are incorrect where did i go wrong?","['probability-theory', 'probability', 'statistics']"
1544640,Theoretical link between the graph diffusion/heat kernel and spectral clustering,"The graph diffusion kernel of a graph is the exponential of its Laplacian $\exp(-\beta L)$ (or a similar expression depending on how you define the kernel). If you have labels on some vertices, you can get labels on the rest of the vertices by a majority vote of adding the kernel contribution. In spectral clustering, the sign of the eigenvector components of the largest eigenvalue of the Laplacian determines the class assignment of the vertices. Since these techniques seem to be doing similar things based on the graph Laplacian, is there a link between spectral clustering and the diffusion or heat kernel? Is one the generalization of the other under some assumptions? What I have found so far: The paper ""The Principal Components Analysis of a Graph,
and Its Relationships to Spectral Clustering"" by Saerens et al. seems to say something about this. They say that one flavor of the diffusion kernel (the Euclidean Commute Time Distance) is the same as one type of spectral clustering. The paper ""Diffusion Maps, Spectral Clustering and Eigenfunctions of Fokker-Planck Operators"" by Nadler et al. also has a result that I am yet to parse. Following ""Graph spectral image smoothing using the heat kernel"" by Zhan and Hancock, we can observe that if the Laplacian $L = USU^T$, (with $U$ as the eigenvectors and $S$ the diagonal matrix of eigenvalues)  and the heat kernel is $H=\exp(-\beta L)$, then $H = Uexp(-\beta S)U^T$. So for some $\beta$ we just have to take the smallest eigenvalue to get the approximate $H$. Disclaimer: This is cross-posted from CV .","['heat-equation', 'graph-theory', 'clustering', 'spectral-graph-theory', 'linear-algebra']"
1544641,Equivalence of Quadratic Forms that represent the same values,"An integer quadratic form is a function $Q(x,y) = ax^2 + bxy + cy^2$ where the numbers $a,b,c \in \mathbb Z$. Call the set of values a quadratic forms takes on $V(Q) = \{ Q(x,y) \in \mathbb Z | x,y \in \mathbb Z \}$. Two quadratic forms $Q,R$ are said to be equivalent if there is a $SL_2(\mathbb Z)$ matrix $M$ such that $R(x,y) = Q((x,y)M)$. This is the definition used in for example, 1.1 page 4 of http://www.rzuser.uni-heidelberg.de/~hb3/publ/bf.pdf . Under that definition two quadratic forms maybe be ""opposite"" but not equal, and take on the same set of values. I'm interested in the equivalence we get with $GL_2(\mathbb Z)$ matrices, We'll say $R \sim Q$ if there is a $GL_2(\mathbb Z)$ matrix $M$ such that $R(x,y) = Q((x,y)M)$. Let $Q,R$ be two integer quadratic forms: Does $V(Q) = V(R)$ imply $Q \sim R$?
  If it's true how would it be proved? If false when does it fail? I'm not assuming that the QFs have the same discriminant or are positive definite.","['number-theory', 'quadratic-forms']"
1544650,Tightest proven upper bounds for the smallest prime of the for $an + b$,"If $\gcd(a, b) = 1$, it is known that there are infinitely many primes of the form $an + b$. Denote $n(a, b)$ to be the smallest $n$ such that $an + b$ is prime. $n(a, b) \leq \max(a, b)$ holds for $1 \leq a, b\leq 10000$. What is the tightest PROVEN upper bound for $n(a, b)$ ?","['prime-numbers', 'number-theory']"
1544677,Equivalence relation on set $X$,"Me and my friends were complaining about one of the exercises in discrete math. If there are two equivalence relations $R_1$ and $R_2$ on set $X$.
Is $R_{1}\setminus R_{2}$ still an equivalence relation? My example: If set $X = \{a,b,c\}$ $$\begin{align}
R_{1} &= \{(a,a),(b,b),(c,c),(a,b),(b,a)\}\\
R_{2} &= \{(a,a),(b,b),(c,c),(a,c),(c,a)\}
\end{align}$$ $R_{1}\setminus R_{2} = \{(a,b),(b,a)\}$ which isn't an equivalence relation. Some of them say that $R_{1}\setminus R_{2}$ is still an equivalence relation (not necessarily on my example) Can someone make it clear for me and rest of us?","['computer-science', 'logic', 'discrete-mathematics']"
1544703,Negative solution to $x^2=2^x$,"Just out of curiosity I was trying to solve the equation $x^2=2^x$, initially I thought there would be just the two solutions $x=2$ and $x=4$, but wolfram shows that the two equations intersect at not 2 but 3 locations, the third being a negative value of $x$. The third solution isn't obvious like the other two, so I just have a few questions about the negative solution. Is it rational? is it commonly represented with a greek letter? If it is irrational is there a way to approximate it?","['exponential-function', 'functions']"
1544734,New angle formed after rotating pipe,"I am having a bit of an issue with a problem (home maintenance) and would need to figure out a new angle formed after rotating a pipe. I will try to be as descriptive as possible: This diagram shows the top view and the side view, so the pipe is both going down AND to the side , forming an angle of $35$ degree when seen from above. My question would be, if I were to rotate the STATIONARY horizontal pipe $11$ degrees, what would the NEW angle formed be from above (it is $35$ degrees now, what would it become after I rotate that horizontal component 11 degrees on itself, position stays the same). if possible, I would like two answers: the new angle after it is rotated clockwise and counterclockwise Thank you very much","['geometry', 'triangles', 'rotations']"
1544748,Newtons Method in 2D,"I need to learn how to use Newtons Method in the 2nd dimension for a research report, but have had a hard time finding any information on the topic that is not in python code. I have found the equation: $$x_{n+1}=x_n-J^{-1}f(x_n)$$ I do not really know where to go from here though. I wanted to know where the equation came from, how to use it, why the inverse Jacobian is used, and any other useful information that can be explained to me. Any help would be greatly appreciated.","['newton-raphson', 'multivariable-calculus']"
1544754,Lineal functions problem; interpreting $\;{g}^{-1}(x)=g(x)$,"I'm preparing for a local math competition/olympiad, so I've been researching for past exams, and I've found this problem: Consider the lineal functions $f$ and $g$ such that $f(2)=1$ , $\;g(2x)=-2f(x)\,$ and $\;{g}^{-1}(x)=g(x)$ . The value of $f(2013)$ is given by: a) 2 b) 2012 c) 2013 d) 2014 My first intuition was to consider $x=2$ , where $$g(4)=-2f(2)=-2$$ So if I were to graph $g(x)$ (which is linear), the line would go through the point $(4,-2)$ . Now, I know I need to use the fact that $\;{g}^{-1}(x)=g(x)$ , but I'm not exactly sure how to interpret it. I'm pretty sure it means that $g(x)$ and its inverse have the same output. But does this imply that $g(x)$ and $\;{g}^{-1}(x)$ are exactly the same function? Or can they be different functions which have the same output for any $x$ ? Is this last case even possible in linear functions? I've read somewhere that this is called an involution. Either way, how could I use this fact to, say, determine another point in the graph of $g(x)$ , and thus, determine $g(x)$ ? I know this is somewhat elementary, but I'm confused. By the way, this is my first question here, so please bear with any formatting mistakes I've made.","['contest-math', 'linear-algebra', 'involutions', 'functions']"
1544760,Can we form a basis for $2\times2$ matrix using only invertible matrices?,"In contrast, can we form a basis for $2\times2$ matrix using only non-invertible matrices?","['linear-algebra', 'matrices']"
1544773,Solve the equation $x^2+x+9\equiv 0\pmod {63}$,"Solve the equation $x^2+x+9\equiv 0\pmod {63}$ Quadratic equation $x^2+x+9=0$ can't be factorized (with integer roots). Also, $63$ is not a prime, and I have checked the method of completing the square . What method to use for this congruence relation?","['discrete-mathematics', 'congruence-relations']"
1544779,Number of samples needed to distinguish between two Bernoulli distributions,"In a paper I am reading, they make the following claim offhandedly (paraphrased): Suppose there are two Bernoulli distributions with means $p_0$ and $p_1$ where $\delta=p_1-p_0$. One distribution is chosen (by a fair coin flip) and then $n$ i.i.d. samples are drawn from it. The probability of error (incorrectly identifying the correct distribution based on the i.i.d. samples) is $\Omega(1)$ unless the number of samples is $n=\Omega(1/\delta^2)$. What is the intuition/reasoning behind this claim? I am also confused about the setup (this claim was stated rather hastily in the paper), such as whether the two means are known or just their difference $\delta$ is known, and also what statistic (sample mean?) and procedure (pick the distribution whose mean is closer to sample mean?) is being used to infer the distribution. Any references would also be appreciated.","['hypothesis-testing', 'probability', 'statistics']"
1544788,"$\sum_{n= 0}^{\infty}a_n$ converges, what other series must then also converge?",I got the following test question: Series $\sum_{n= 0}^{\infty}a_n$ converges. Which of the series below must also converge: 1) $\sum_{n= 0}^{\infty}na_n$ 2) $\sum_{n= 0}^{\infty}a_n^2$ 3 $\sum_{n= 0}^{\infty}(-1)^na_n$ To me it looks like non of the above should necessarily converge. 1) $\sum_{n= 1}^{\infty}\frac{1}{n^2}$ converges but $\sum_{n= 1}^{\infty}\frac{1}{n}$ does not. 2) $\sum_{n= 1}^{\infty}(-1)^n\frac{1}{\sqrt{n}}$ converges (Leibniz criterion) but $\sum_{n= 1}^{\infty}\frac{1}{n}$ does not. 3) $\sum_{n= 1}^{\infty}(-1)^n\frac{1}{n}$ converges but $\sum_{n= 1}^{\infty}(-1)^n(-1)^n\frac{1}{n}=\sum_{n= 1}^{\infty}\frac{1}{n}$ does not. What am I missing?,['sequences-and-series']
1544789,Calculating an Exponential Integral,"Calculate $\int_0^{\infty} \frac{x^{2N+1}}{a+x^{-b}} e^{-c x^2} dx$ where $a,c > 0$ and $b>1$. The best I could do about this integral is to find an upperbound for it: $\int_0^{\infty} \frac{x^{2N+1}}{a+x^{-b}} e^{-c x^2} dx \leq \int_0^{\infty} \frac{x^{2N+1}}{x^{-b}} e^{-c x^2} dx= \int_0^{\infty} x^{2N+b+1} e^{-c x^2} dx$ Then I can use $\int_{0}^{\infty} x^{n} e^{-ax^2}\,\mathrm{d}x = 
\begin{cases}
       \frac{1}{2}\Gamma \left(\frac{n+1}{2}\right)/a^{\frac{n+1}{2}} & (n>-1,a>0) \\
       \frac{(2k-1)!!}{2^{k+1}a^k}\sqrt{\frac{\pi}{a}} & (n=2k, k \;\text{integer}, a>0) \\
       \frac{k!}{2a^{k+1}} & (n=2k+1,k \;\text{integer}, a>0)
\end{cases} $ Any idea that how I can calculate the integral, not jut an upper bound?","['normal-distribution', 'gaussian-integral', 'definite-integrals', 'integration']"
1544797,Show the number of triangles in a random graph follows Poisson,"Define a random graph $\Bbb G(n,p)$ as a graph with $n$ vertices where an edge between two vertices occur with probability $p$. Let $X$ be the number of triangles in the random graph, show that if $p=c/n$ ($c$ is a non-negative constant), then $X$ asymptotically follows Poisson distribution as $n \to \infty$. Can anyone provide some help? Thank you!","['graph-theory', 'probability']"
1544800,Curvature measure for polygones on a 2D space,"I would like to implement a curvature measure for polygones on a 2D space. My goal is to compute shape parameters to know if the polygon is close to a circle or has a sinuous shape or an elongated shape... I already try to fit to various shapes, compute parameters based on length, area or perimeter so I would rather focus on angles or curvatures but both inspiration and Google failed me. I already have a measure based on perimeter to area ratio which is probably very correlated to a mean radius of curvature, I am looking for a different perspective. I know a curvature measure for continuous functions (defined here: https://en.wikipedia.org/wiki/Curvature#Curvature_of_a_graph ). That would probably be interesting if I could see how to implement it for a polygone with discontinuous derivatives at summits. I can imagine something similar to an energy cost that would penalize narrow angles, concavities... But I don't see how to translate it mathematically. I would be glad if you have ideas or precise measure definitions I could apply to this problem. Thank you.","['geometry', 'polygons', 'curvature']"
1544815,Calculate derivative: $\frac{d^\beta}{d\alpha^\beta}\frac{d^\alpha}{dx^\alpha}\sin(x)$,"Is it possible to ""calculate"" / simplify this expression? If it is, how can it be done? $$
\frac{d^\beta}{d\alpha^\beta}\frac{d^\alpha}{dx^\alpha}\sin(x)
$$ for $
\alpha,\beta\in\mathbb{R}_{\ge0}
$ I think it is equal to $\left(\frac{\pi}{2}\right)^\beta \sin\left(x+\frac{\pi}{2}\left(\alpha+\beta\right)\right)$, but i am absolutely not sure if this is true. Thank you, Best regards Kevin -edit- Here is the desription how i got my result (which maybe helps to verify it): https://en.wikipedia.org/wiki/Differintegral#A_selection_of_basic_formul.C3.A6 $$\Rightarrow \frac{d^\alpha}{dx^\alpha}\sin(x)=\sin(x+\alpha\frac{\pi}{2})$$ Because $\frac{d^n}{dx^n}f(ax)=a^nf^{\left(n\right)}(ax), n\in \mathbb{N}$ i think $\frac{d^\alpha}{dx^\alpha}f(ax)=a^\alpha f^{\left(\alpha\right)}(ax), \alpha\in\mathbb{R}_{\ge 0}$ is also true. Unfortunately i'm not sure if this is true. Because $\frac{d^n}{dx^n}f(x+a)=f^{\left(n\right)}(x+a), n\in\mathbb{N}$ is true, i also hope that $\frac{d^\alpha}{dx^\alpha}f(x+a)=f^{\left(\alpha\right)}(x+a), \alpha\in\mathbb{R}_{\ge 0}$ is true. With these new rules the expression can be calculated:
$$
\frac{d^\beta}{d\alpha^\beta}\frac{d^\alpha}{dx^\alpha}\sin(x)
$$
$$
=\frac{d^\beta}{d\alpha^\beta}\sin(x+\alpha\frac{\pi}{2})
$$
$$
=\frac{d^\beta}{d\alpha^\beta}\sin(\frac{\pi}{2}\left(\alpha+\frac{2}{\pi}x\right))
$$
This is just a shifted $\sin(\frac{\pi}{2}\gamma)$.
$$
\gamma=\alpha+\frac{2}{\pi}x
$$
$$
\Rightarrow\frac{d^\beta}{d\alpha^\beta}\sin(\frac{\pi}{2}\gamma)
$$
$$
=\left(\frac{\pi}{2}\right)^{\beta}\sin^{\left(\beta\right)}(\frac{\pi}{2}\gamma)
$$
$$
=\left(\frac{\pi}{2}\right)^{\beta}\sin(\frac{\pi}{2}\gamma+\frac{\pi}{2}\beta)
$$
$$
=\left(\frac{\pi}{2}\right)^{\beta}\sin(\frac{\pi}{2}\left(\alpha+\frac{2}{\pi}x\right)+\frac{\pi}{2}\beta)
$$
$$
=\left(\frac{\pi}{2}\right)^\beta \sin\left(x+\frac{\pi}{2}\left(\alpha+\beta\right)\right)
$$","['fractional-calculus', 'trigonometry', 'derivatives']"
1544822,Is it possible for this function on $R^2$ to be defined continuously at $0$?,"I wont post all the functions.I am practicing on continuity.So i wanna use definitions but i am not really sure how? Suppose i have the function $$f(x)= \frac{x^4-y^4}{(x^2+y^2)^2}$$ When $(x,y)\neq (0,0)$ and $f(x)=b $ when $(x,y)=(0,0)$ Proof:To be defined continouesly at $0$ the limit at zero must exist.So there must exist the $$\lim_{(x,y)\to(0,0)}\frac{x^4-y^4}{(x^2+y^2)^2} $$ Or if i do a variables change to polar coordinates  $x=rcosθ $  $y=rsinθ$
 then$$\lim_{(r,θ)\to(0,0)} cos^2θ-sin^2θ $$ but that function does not depend on $r$  and so will give the same limit for All $r's$ since it must be unique?. So i said the function cannot be defined continuously .Is it right?Does not seem that rigorous to me i think i need a better explanation as to why it might not be defined and why when it is not depended on both variables it doesnt work. Also i would like a proof using other  definitions(open sets of the preimage or  the ε,δ,) because i do not know how to use the other definitions except that a function is continuous to a point iff when x-->xo then f(x)-->f(xo).","['calculus', 'continuity', 'real-analysis', 'analysis', 'multivariable-calculus']"
1544878,Convergence of $X_nY_n$ in distribution,I have a short question: Is always true that if $X_n$ converges to $X$ in distribution and $Y_n$ converges to $Y$ in probability then $X_nY_n$ converges to $XY$ in distribution?,"['probability-theory', 'weak-convergence']"
1544887,Line Integrals with Vector Fields,"I am trying to find the line integral of the vector field $F(x,y)=(x^2-y^2)$ x $-2xy$ y from $(0,0)$ to $(1,2)$ along a few different paths. First path is along curve $y=2x^2$ Second path is curve described by $x=t^2$ and $y=2t$ Last path is the path that goes from $(0,0)$ to $(2,0)$ along the x-axis and then along line $(2,0)$ to $(1,2)$. This is what I have so far. For the first one: $$\int F(x,y)\cdot dr=\int ((x^2-y^2)+(-2xy)4t)  dt$$ I said $r(t)=x(t)$ x + $y(t)$ y . Therefore $dr=(1$ x +$4t$ y )dt. This part is algebra and derivatives. Thus by setting $x=t$ and $y=2x^2=2t^2$, we can solve the integral as follows: $$\int_0^1 (t^2-4t^4-16t^4)dt=\frac{-31}{15}$$ For the second one: Same process, but this time, $r(t)=t^2$ x +$2t$ y . Therefore, $dr=(2t$ x +$2$ y )$dt$. Now the integral becomes
$$\int F(x,y)\cdot dr=\int ((x^2-y^2)t^2+(-2xy)2)  dt$$ Now with substituting for $x$ and $y$, $$\int_0^1 (2t^5-8t^3+8t^3)dt=\frac{1}{3}$$ For the last one: I broke this up first along the x-axis then along the line $y=-2x+4$. Now we have $$\int F_x dx+\int F \cdot dr=\int_0^1(x^2-y^2)dx+\int_2^1((x^2-y^2)+2xy*-2)dx$$
I found out that $dy=-2$ since the line from $(2,0)$ to $(1,2)$. So for the first integral, y=0, but the second one, $y=-2x+4$. Thus left with $$\int_0^1(x^2-0^2)dx+\int_2^1((x^2-(-2x+4)^2)+2x(-2x+4)*-2)dx=\frac{-11}{3}$$","['line-integrals', 'calculus', 'integration', 'vectors', 'multivariable-calculus']"
1544891,What does it mean for a set to be countably infinite?,Why distinguish between countable and uncountable? What advantages does this property have? I haven't studied much set theory but I am writing about the set of algebraic vs transcendental numbers and found one is countable whereas the other is not. So this led me to ask these questions. Thanks for any guidance.,"['elementary-set-theory', 'intuition']"
1544914,linear Diophantine equation with real coefficients,"I am studying linear Diophantine equations with real coefficients:
\begin{equation}
ax+by=1\qquad a,b\in\mathbb{R}
\end{equation}
I have no clue about where to begin; could someone please point me to some starting point? I was not able to find anything in the question database.","['number-theory', 'diophantine-equations']"
1544917,Calculating Surface Integrals,"How does one calculate the surface integral of a vector field on a surface? I have been tasked with solving surface integral of ${\bf V} = x^2{\bf e_x}+ y^2{\bf e_y}+ z^2 {\bf e_z}$ on the surface of a cube bounding the region $0\le x,y,z \le 1$. Verify result using Divergence Theorem and calculating associated volume integral. How do all these things relate in simple terms please. I can read a definition, but examples would be helpful.","['calculus', 'surface-integrals', 'integration', 'vectors', 'multivariable-calculus']"
1544935,Show that $\iint_F f(ax+by+cz)dS = 2 \pi \int_{-1}^1 f(u \sqrt{a^2+b^2+c^2})du$,Show that $$\iint_F f(ax+by+cz)dS = 2 \pi \int_{-1}^1 f(u \sqrt{a^2+b^2+c^2})du$$ where $F$ is the sphere $x^2 + y^2 +z^2 = 1$ Please provide me hints on how to proceed with this proof.,['multivariable-calculus']
1544952,"Adjoint of the derivative operator on $C([0,1])$","Let $D \colon \operatorname{dom}(D) = C^1[0,1] \subseteq C[0,1] \to C[0,1]$
be the derivative unbounded operator $D(f) = f'$. 
Since $C^1$ is dense in $C$ we can define the adjoint operator 
$$D^* \colon \operatorname{dom}(D^*) \subseteq C[0,1]^* \to C[0,1]^*$$ We can identify $C[0,1]^*$ with the space of all bounded signed measures $M([0,1])$ and hence we can characterize $\operatorname{dom}(D^*)$ by the set of all bounded signed measures $\mu$ such that $$f \to \int_0^1 f'd\mu$$
is continuous. I want to use some kind of integration by parts but the only thing that I know is that $\mu$ is a Lebesgue-Stieltjes measure represented by the càdlàg with bounded variation function $$F(x) = \mu((0,x])$$ Any help will be appreciated.","['functional-analysis', 'measure-theory']"
1544955,Convergence of $\int f dP_n$ to $\int f dP$ for all Lipschitz functions $f$ implies uniform integrability,"I would like to prove or give a counterexample for the following statement: Let $(S,d)$ be a complete and separable space. We define:
$$
\mathcal{P}^1(S) := \{P: \mathcal{B}_S \rightarrow [0,1] \mid P \mbox{ probability measure, }\exists a \in S: \int d(x,a) P(dx) < \infty\}
$$
Let $(P_n)_n, P$ all be in $\mathcal{P^1}(S)$ and suppose we have for any $f:S \rightarrow \mathbb{R}$ with $\forall x,y \in S: |f(x) - f(y)| \leq d(x,y): \int f \, dP_n \rightarrow \int f \, dP$ then there is some $a \in S$ for which: 
$$\lim_{M \rightarrow \infty} \sup_{n\in \mathbb{N}} \int_{\{(d(a,\cdot) > M\}} d(a,x) \, dP_n =0.$$ Note that it follows easily by taking $f/k$ if $f$ is Lipschitz with Lipschitz constant $k$ that we have convergence $\int f \, dP_n \rightarrow \int f \, dP$ for all Lipschitz functions $f$ and thus by the Portmanteau theorem it follows that we have weak convergence (but this convergence is stronger than weak convergence since we also have convergence for unbounded functions).","['probability-theory', 'uniform-continuity', 'convergence-divergence', 'weak-convergence']"
1544956,Double integral using change of variables,"I must evaluate $\iint_B(x^2+y^2)dxdy$ using the change of variables $u=x^2-y^2,v=xy$, where $B$ is the region in the first quadrant bounded by $xy=1,xy=3,x^2-y^2=4,x^2-y^2=1$. I know that we must have: $$\iint_Df(x,y)dxdy=\iint_Sg(u,v) \left|\frac{\partial (x,y)}{\partial (u,v)}\right|dudv$$ I have computed this Jacobian to be $\frac{1}{4v}$, and $S$ will be represented by $1 \leq u \leq 4, 1 \leq v \leq 3$. However, I am unsure of how to find $g(u,v)$ in this scenario; from other examples I've seen, it's usually a simple substitution. Any help in how to transform $f(x,y)=x^2+y^2$ into a form $g(u,v)$ would be greatly appreciated. Thank you!","['calculus', 'multivariable-calculus', 'integration']"
1545006,Are these trigonometric expressions for the ceiling and floor functions correct?,"I believe that I have found a trigonometric expression for both the ceiling and floor function, and I seek confirmation that it is, indeed, correct. Update. $$\begin{align}
\lfloor x \rfloor &= x - \frac12+f(x) \\[4pt] 
\lceil  x \rceil  &= x + \frac12+g(x)
\end{align}$$ where $$\begin{align}
f(x) &= \begin{cases}
\frac12, & x\in\Bbb{Z} \\[4pt]
0, &x=\frac12n, n\in\Bbb{Z} \\[4pt]
\frac1\pi \tan^{-1}(\cot(\pi x)), &\text{otherwise}
\end{cases} \\[10pt]
g(x) &= \begin{cases}
-\frac12, & x\in\Bbb{Z} \\[4pt]
0, &x=\frac12n, n\in\Bbb{Z} \\[4pt]
\frac1\pi \tan^{-1}(\cot(\pi x)), &\text{otherwise}
\end{cases}
\end{align}$$","['ceiling-and-floor-functions', 'pi', 'trigonometry']"
1545013,Computation of the integral $ \iint_{D} \frac{x^2}{(x^2 + y^2)^{3/2}} dxdy $,"I'm having some troubles trying to compute the following integral: $$ I = \iint_{D} \frac{x^2}{(x^2 + y^2)^{3/2}} dxdy $$ where $ D = \{ (x,y) \in \mathbb{R} : 2 \leq x^2 + y^2 \leq 2y \} $. What I've tried so far: I plotted the domain $ D $: Using the following transformation (polar coordinates): $$ \left\{\begin{matrix}x = r\cos\theta\\y = r\sin\theta\end{matrix}\right. $$
I get the integral: $$ \int_{\pi/4}^{3\pi/4} \int_{\sqrt{2}}^{2\sin\theta} \cos^2(\theta) \, dr d\theta $$ The result I should arrive is: $$ I = \frac{2\sqrt{2} + 3\pi + 6}{6} $$ but according to Wolfram what I get is: $$ \frac{10 - 3\pi}{6\sqrt{2}} $$ Questions: What am I doing wrong? How should I write the integral? Could you recommend me a good source with several examples of problems like this one?","['multivariable-calculus', 'integration']"
1545027,"Evaluating $\iiint_\Omega z\,\mathrm dx\mathrm dy\mathrm dz$, wrong book solution?","Evaluate $$\iiint_\Omega z\,\mathrm dx\mathrm dy\mathrm dz,$$ where
  $$\Omega = \{(x, y, z) \in \mathbb R^3 \mid y \geq 0,\ z \geq 0,\ x^2 + y^2 \leq 4,\ (y - 1)^2 + z^2 \leq 1\}.$$ From the second and last conditions we get a semi-cylinder parallel to the $x$ axis, tangent to it and with radius $1$. The other two conditions give another cylinder, this time parallel to the $z$ axis. Therefore I choose to integrate as follows:
$$\iint_K\int_0^{\sqrt{1 - (y - 1)^2}} z\,\mathrm dz\,\mathrm dx\mathrm dy,$$
where $K$ is the projection on the $xy$ plane of the intersection of the two cylinders. That is, the red region in this graph: The integral becomes
$$\begin{align}
\iint_K\left[\frac12 z^2\right]_0^{\sqrt{2y - y^2}}\,\mathrm dx\mathrm dy &= \frac12\int_0^1\int_{-\sqrt{4 - y^2}}^{\sqrt{4 - y^2}}(2y - y^2)\mathrm dx\mathrm dy =\\
&= \int_0^1(2y - y^2)\sqrt{4 - y^2}\mathrm dy =\\
&= \frac{16}3 - 2\sqrt3 + \frac{\sqrt3}4 - \frac\pi3 =\\
&= \frac{16}3 - \frac{7\sqrt3}4 - \frac\pi3
\end{align}$$ However, the book's solution is just
$$\frac{16}3 - \pi$$ Is there an error in my solution or in the book?","['multivariable-calculus', 'integration']"
