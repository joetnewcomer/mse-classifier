question_id,title,body,tags
1137445,Having problems finding $x$ in terms of $a$ and $b$.,"I have attempted this question but have not found a solution. I am currently stuck. Hints on how I may go further would be helpful. Thank You in advance. The Question: $$\frac{a^2b}{x^2} + \left(1+\frac{b}{x}\right)a = 2b+ \frac{a^2}{x}$$ What I have done so far that I believe is correct:
$$\frac{a^2b}{x^2} + \frac{ab}{x} + a = 2b+ \frac{a^2}{x}$$ If you would like to see other work that I have attempted on this question I can also place it up.",['algebra-precalculus']
1137451,How to understand intuitively the Stolz-Cesaro Theorem for sequences?,"I have to give a presentation on the theorem in Real Analysis with a fellow student. While I've looked over the proof and verified that, yes, step B does indeed follow logically from step A, etc. and have internalized the proof to the extent that I can replicate it myself on paper, I still feel that I have made little progress as to why this theorem works the way it does, i.e. what is the intuition behind the theorem, such that it should make sense that it follows the way it does. Therefore I ask: what kind of intuition is there about this theorem? It would also be helpful to understand how the theorem can be used effectively in analysis. I have seen it referred to as a sort of L'Hopital's rule for sequences, which certainly seems to make sense, but I similarly have little intuitive understanding of how that rule works, either. I am asking this question not only for my personal understanding, but also for the sake of being able to present it in an illuminating manner, such that the rest of the class can also come away with the same sort of intuition of how the theorem works and how it is useful. Any help would be greatly appreciated. EDIT: I should point out that the formulation of the theorem we are being tasked to prove is the following: Let $\lbrace a_n \rbrace$ , $\lbrace b_n \rbrace$ be sequences, ${b_n}$ strictly increasing and unbounded. Then if $\lim\limits_{n \to \infty} \frac {a_{n+1} - a_n}{b_{n+1} - b_n} = l$ for some $l \in \mathbb R$ , then $\lim\limits_{n \to \infty} \frac{a_n}{b_n} = l$ also.","['sequences-and-series', 'intuition', 'real-analysis']"
1137505,Probability of $(a+b\omega+c\omega^{2})(a+b\omega^{2}+c\omega)=1$,"A fair die is thrown three times. If $a$, $b$, $c$ are the numbers obtained on the die, then what is the probability that $$(a+b\omega+c\omega^{2})(a+b\omega^{2}+c\omega)=1$$
  (where $\omega$ is a cube root of unity) My attempt: On simplification, $a^{2}+b^{2}+c^{2}=1+(ab+bc+ca)$. I can't figure how to find the number of cases where the condition is satisfied.","['complex-numbers', 'probability']"
1137509,Why is there different results when calculating a double sum?,"Consider:
$$
\begin{matrix}
-1 & 0 & 0 & 0& 0& \ldots\\
1/2 & -1 & 0 & 0& 0& \ldots\\
1/4 & 1/2 & -1 & 0& 0& \ldots\\
1/8 & 1/4 & 1/2 & -1& 0& \ldots\\
1/16&1/8 & 1/4 & 1/2 & -1& \ldots\\
\vdots&\vdots&\vdots&\vdots&\vdots&\ddots
\end{matrix}
$$ When I calculate the sum of each column first, I got $0,0,0\ldots$ then sum them up the answer should be $0$. But when I calculate the sum of each row, I got $-1, -1/2, -1/4, -1/8,\ldots$, then the sum will be $-2$. Why is there different results when I calculate the sum?","['sequences-and-series', 'calculus']"
1137512,Matrix multiplication by scalar is commutative,"Is matrix multiplication by scalar commutative, i.e. $(\alpha M)N=M(\alpha N)$? If so, can we prove it without induction?",['linear-algebra']
1137556,Pullback composed with pushforward of a line bundle under closed immersion,Let $X$ be a smooth surface in $\mathbb{P}^3$ and $\mathcal{L}$ be a line bundle on $X$. Denote by $i:X \hookrightarrow \mathbb{P}^3$ the natural closed immersion. Is it true that $i^*i_*\mathcal{L} \cong \mathcal{L}$?,['algebraic-geometry']
1137565,Let $A\Delta C\subseteq A\Delta B$. Prove $A\cap B \subseteq C$. (Proof.v),"Let $A\Delta C\subseteq A\Delta B$ . ( $\Delta$ denotes symmetric difference.) Prove $A\cap B \subseteq C$ . I am getting ready for a test and I could really use proof verification and any help with this. Proof : Let us look at the indicators, $x_{A\Delta C}=x_A+x_C-2x_Ax_C$ , $x_{A\Delta B}=x_A+x_B-2x_Ax_B$ , $x_{A\cap B}=x_Ax_B$ . Let $x_{A\cap B}(a)=1$ . Then $x_{A\Delta B}(a)=0$ which means $x_{A\Delta C}(a)=0$ . $x_A(a)=x_B(a)=1$ and therefore $x_C(a)$ must be 1. Therefore $x_{A\cap B}(a)=1\Rightarrow x_C(a)=1$ $\Rightarrow A\cap B \subseteq C$ .","['elementary-set-theory', 'proof-verification']"
1137596,Can we define the concept of limit without a topology?,"At the beginning the concept of limit is introduced for sequences thanks to the fact that the space in which we operate is a metric space. Then we introduce topology and we can define limits using neighbourhoods, and we see that any metric space is a topological space with a countable base of neighbourhoods (i.e. is a first-countable space). For a topological space that is not first-countable we can use nets and filters that generalize the concept of sequence, but we are always in a topological space. There is some way to define the concept of limit of a sequence in a set where a topology is not defined?","['general-topology', 'limits']"
1137603,Random walk on a tree,"Consider a Cayley tree with coordination number 3 ( http://en.wikipedia.org/wiki/Bethe_lattice ). Consider two sites, $x$ and $y$, having a distance $k$ one from another. What is the probability that random walk starting from $x$ will ever visit $y$? Jumps are distributed uniformly at random among the neighbours.","['random-walk', 'markov-chains', 'random-graphs', 'graph-theory', 'probability']"
1137628,Why are linear functions linear?,"I always thought linear functions need to satisfy
$$f(x+y)=f(x)+f(y).$$
I am a tad confused now, consider $f(x)=2x+3$. $f(1)=5$, $f(2)=7$, $f(1+2)=f(3)=9 \neq f(1)+f(2)$ which was what I thought linear functions should satisfy. Could someone clarify?","['arithmetic', 'linear-algebra', 'functions']"
1137656,Sufficient condition for martingale property,"Let $(\Omega,\mathcal{F},(\mathcal{F}_t)_{t \geq 0},\mathbb{P})$ be a filtered probability space and $M=(M_t)_{t\geq 0}$ an $\mathcal{F}_t$-adapted stochastic process. If
$$ \forall t<s, \ \mathbb{E}[M_s|\mathcal{F}_t]=M_t $$
$M$ is said to be a martingale. Now let assume I can integrate with respect to $M$ (say $M$ is a semi-martingale and I am using ItÃ´ integration). Then
$$ \forall t < s, \ \mathbb{E}[\int_t^s dM_u | F_t] = 0 $$
still implies that $M$ is a martingale. What about
$$ \forall t < s, \ \mathbb{E}[\int_t^s \alpha_u dM_u | F_t] = 0 $$
where $\alpha$ is a predictable stochastic process ? Under which conditions on $\alpha$ (except being constant) is $M$ still a martingale ?","['stochastic-processes', 'martingales', 'stochastic-integrals', 'probability-theory', 'stochastic-calculus']"
1137673,How do we know that we found all solutions of a differential equation?,"I hope that's not an extremely stupid question, but it' been in my mind since I was taught how to solve differential equations in secondary school, and I've never been able to find an answer. For example, take the simple differential equation $$y'=y.$$ While I understand that $y=C\cdot e^x$ satisfies this equation, I do not understand why there can't be other solutions as well. So, how do we know this?",['ordinary-differential-equations']
1137681,Show that there are infinitely many integers such that $ \binom{m}{n-1} = \binom{m-1}{n} $,"This question comes from the 1st Brazilian's IMO TST of 2004. I have found no solutions of it online, though I have developed one. After getting to $ mn = (m-n)(m-n+1) $, my solution relies on the claim that $ m_z = F(2z) \cdot F(2z+1) $ and $ n_z = F(2z-1) \cdot F(2z) $ (where $ F(z) $ is the Fibonacci function), which can be easily proved by finite induction. Another attempt I had finds that $ n = \dfrac{3m+1 \pm \sqrt{5m^2+2m+1}}{2} $, but I couldn't prove that there are infinitely many integers $ m $ such that $ \sqrt{5m^2+2m+1} $ is an integer $ \equiv m+1 \pmod2 $. Noticing $ 5m^2+2m+1 = (2m)^2 + (m+1)^2 $, I've tried setting a primitive Pythagorean triplet $ x^2-y^2=m+1, \; 2xy=2m $, but couldn't prove $ x^2-xy-y^2=1 $ has infinitely many integer solutions. I know that this is a hyperbola and that Pell can help me a lot here, but I've tried to restrain myself to using what I've learned in high school. Can someone conclude my second approach or provide me a different~easier one?","['fibonacci-numbers', 'binomial-coefficients', 'combinatorics']"
1137706,Prove that the empty set is a subset of every set,Does this proof work? By definition: $$[A \cap B = A] \wedge [A \cup B = B] \implies [A \subseteq B]$$ Therefore: $$[\emptyset \cap B = \emptyset] \wedge [\emptyset \cup B = B] \implies [\emptyset \subseteq B]$$ Thanks in advance.,['elementary-set-theory']
1137754,Prove or disprove that $\sin\lfloor x\rfloor$ is periodic.,The title says it all. I was plotting random functions on my phone and noticed this graph. I don't think this function is periodic (WA also agrees). Is there a way to prove if a function like this is periodic or not?,"['ceiling-and-floor-functions', 'trigonometry', 'graphing-functions', 'periodic-functions']"
1137766,Summing up series which is similar to Taylor expansion,"I am given series as 
$$S= \frac{1.2.3}{1!} + \frac{2.3.4}{2!} + \frac{3.4.5}{3!}+.........$$ 
I know this series looks similar to $e^x$ expansion and probably $x=1$ here so how to express my series in terms of $e$  ? I am unable to separate out numbers from numerator to look it like $e$","['sequences-and-series', 'taylor-expansion']"
1137770,Points at which a function is holomorphic,$f=\frac{1}{z^5-1}$ $z=1$ ofcourse makes it non-holomorphic. What other z's would make it non-holomorphic? Is it only $z=1$ ?,"['derivatives', 'complex-analysis']"
1137771,Can the same element be greatest and least in a partially ordered set?,"I have an exam soon, so I'm just looking at the previous exams and solving every problem I see. So the problem goes like this : $R$ is a partially ordered set(relation) on $A = \{1, 2, 3, 4, 5\}$ $""1""$ is a minimal element in relation $R$ and $""1""$ is a maximal element in relation $R$. a)Can you give an example of such relation on $A$ ? My answer : Let $R$ be a relation on $A$ that says : $(x,y) \in R$ iff $x|y$ and $y|x$ Which means : $R = \{(1,1), (2,2), (3,3), (4,4), (5,5)\}$ In this case $""1""$ is both minimal and maximal. b)Give a general proof that if $R$ meets the above conditions, $R$ does not contain a greatest element and $R$ does not contain a least element. My answer : The greatest and the least element in a partially ordered set are comparable to every other element in a set(unlike minimal and maximal elements), if a relation meets the above conditions, there is at least 1 element which is not comparable to any other element in a set, which means it can't contain a greatest/least element. c)This is the problem that is in the title, which goes like this : Is there partially ordered set(relation) $S$ on $A = \{1,2,3,4,5\}$, such that $""1""$ is the Greatest element in S, and $""1""$ is the least element in S.
Give an example of such relation (if it exists), or prove that it doesn't. Now, I can only think of a relation that goes : $(x,y) \in S$ iff $x+y = 2$ In this case, the relation should contain only the element (1,1), which means 1 would be the minimal, maximal, greatest and the least element in $S$, is this correct ?Can the same element even be greatest and least at the same time ? Any help is appreciated, would also be grateful if you told me whether the first 2 problems were answered correctly or not.","['discrete-mathematics', 'order-theory']"
1137773,"If ABCD is a square with A (0,0), C (2,2). If M is the mid point of AB and P is a variable point of CB, find the smallest value of DP+PM.","I assumed the coordinates of P = (h,2) to get the value of DP+PM= $\sqrt { (h-2)^2 +4}+\sqrt{h^2+1}$. Then I differentiated the equation wrt to h to get: $h(\sqrt{h^2+1}) -2\sqrt{h^2+1}+ h\sqrt{h^2+8-4h}$. On equating this expression with 0, I will probably get the answer. Is there any other~shorter method of solving this?","['geometry', 'coordinate-systems']"
1137794,is the pullback operator associated to a flow bounded in L^2?,"Let $M$ be a smooth compact manifold with a finite Borel measure $m$. Let $\{f_t\}_{t\in\mathbb R}$ be a $C^1$ flow on $M$. That is, a $C^1$ function
$$
\mathbb R\times M\ni(t,x)\mapsto f_t(x)\in M
$$
such that $f_0(x)=x$ for all $x\in M$, and $f_{t_1}\circ f_{t_2}=f_{t_1+t_2}$ for all $t_1,t_2\in\mathbb R$. Then, the pullback operator $f_t^*$ on $C(M)$ (with the sup-norm),
$$
f_t^*\;\!\psi=\psi\circ f_t,\quad t\in\mathbb R,~\psi\in C(M),
$$
is a bounded operator. I am wondering if $\;\!f_t^*$ could be extended to a bounded operator in $L^2(M,m)$ (with the $L^2$-norm), for instance when $|t|$ is small$\;\!$? The problem is we cannot use the tools of differential calculus such as the Jacobian, integration by parts, and so on, to estimate the norm of $f_t^*$ in $L^2(M,m)$ because (1) the measure $m$ is not given by a volume form on $M$ and (2) the flow $\{f_t\}_{t\in\mathbb R}$ does not preserve the measure $m$.","['operator-theory', 'measure-theory', 'functional-analysis', 'differential-geometry']"
1137810,$\zeta_m(s)=\prod\limits_{p\nmid m} \frac{1}{\left(1-\frac{1}{p^{f(p)s}}\right)^{g(p)}}$ is a Dirichlet series with non-negative coefficients,"Let $p$ be a prime number, $m$ be any integer, $f(p)$ be the order of $p$ in $(Z/mZ)^*$, $i.e.$ $p^{f(p)} \equiv 1 \pmod m$ with $f(p)$ smallest. Let $g(p)=\frac{\phi(m)}{f(p)}$ is a integer where $\phi$ is the euler $\phi$-function. Then why is $\zeta_m(s)=\prod\limits_{p\nmid m} \frac{1}{(1-\frac{1}{p^{f(p)s}})^{g(p)}}$ a Dirichlet series with positive integral coefficients? (The above formula is derived from $L$ functions, $\zeta_m(s)=\prod\limits_\chi L(s,\chi).$) A Dirichlet series is a series of the form $\sum a_ne^{-\lambda_n z}$$\,$ $(a_n, z\in \mathbb C,$ $\lambda_n$ increasing to $\infty $ in $\mathbb R$) , if let $\lambda_n=\log n$, then get $\sum \frac{a_n}{n^s}$, the Ordinary Dirichlet Series . It also has a formula $\sum\limits^\infty_1 \chi(n)n^{-s}=\prod\limits_{p}\frac{1}{1-\frac{\chi(p)}{p^s}} $, where $\chi$ is any multiplicative function--i.e. $\chi(xy)=\chi(x)\chi(y))$. I attempted to apply the product formula above, then I need $\left(1-\frac{\chi(p)}{p^s}\right)= \left(1-\frac{1}{ p^{f(p)s} }\right)^{g(p)}$, but it doesn't solve to a multiplicative function $\chi$, so why is $\zeta_m(s)$ a Dirichlet series? (All things above are found in Serre's A Course In Arithmetic .)","['special-functions', 'number-theory', 'analytic-number-theory', 'dirichlet-series', 'complex-analysis']"
1137827,Proving $1+\frac{4}{2^2}+\frac{1}{3^2}+\frac{1}{5^2}+\frac{4}{6^2}+\frac{1}{7^2}+\frac{1}{9^2}+\frac{4}{10^2}+\frac{1}{11^2}+\cdots=\frac{\pi ^2}{4}$,"Proving $$1+\frac{4}{2^2}+\frac{1}{3^2}+\frac{1}{5^2}+\frac{4}{6^2}+\frac{1}{7^2}+\frac{1}{9^2}+\frac{4}{10^2}+\frac{1}{11^2}+\cdots=\frac{\pi ^2}{4}$$
Firstly, I thought to prove it by comparison the terms with the terms of $1/n^2$ , but the problem with the missing terms, so I couldn't  reach to the proving . Can anybody help? Best regards.",['sequences-and-series']
1137841,Show that any solution of second order differential equation has atmost a countable number of zeroes $?$,"Question : Consider the second order differential equation $y''(t) + a(t) y'(t) + b(t) y(t) = 0$. Then any solution of the second order differential equation  has atmost a countable number of zeroes on $[a , b]$ . What I have tried: Let $S$ be the set of zeroes of $y(t)$. If $S$ is finite then there is nothing to prove. Let $S$ be infinite . I can easily prove that every zero of $y(t)$ is isolated. Since $[a ,b]$ is closed and bounded and $S$ is an ordered set,  So we can find a minimum element of $S$ say $t_1$ so that for  $t_1 \in S $, there exists a $\delta_{t_1}$ such that in $( t_1 - \delta_{t_1} , t_1 + \delta_{t_1})$, $y(t)$ has no zeroes other than $t_1$ Let $ t_2$  be the minimum of $S-\{t_1\}$ of $y(t)$ . So   for  $t_2 \in S $, there exists a $\delta_{t_2}$ such that in $( t_2 - \delta_{t_2} , t_2 + \delta_{t_2})$, $y(t)$ has no zeroes other than $t_2$ and $( t_2 - \delta_{t_2} , t_2 + \delta_{t_2}) \cap( t_2 - \delta_{t_2} , t_2 + \delta_{t_2}) = \phi$. Similarly we can proceed. Thus we can correspond for every $t \in S$ a rational number $ q_t $ which belongs to $( t - \delta , t + \delta)$ and since rational numbers are countable, so $S$ is countable. Please check my soution, i f you think any correction is required, please tell me. Thank you.","['ordinary-differential-equations', 'calculus', 'real-analysis']"
1137893,Relation between chief and compositions series of a group,Is there an example of a group with a composition series (of finite length) but without a chief series (of finite length)? Is there an example of a group with a chief series (of finite length) but without a composition series (of finite length)? Definition of composition series Definition of chief series,"['examples-counterexamples', 'group-theory', 'abstract-algebra']"
1137905,Norm in the space of Riemann-Liouville integrals/derivatives? (aka fractional integrals/derivatives),"What is the natural norm to consider in the space of Riemann-Liouville integrals/derivatives of a function? Context: Let $f\in L^2 ([a,b])$. Define the Riemann-Liouville fractional integral of order $\alpha\geq 0$ (respectively fractional derivative) as:
$$I_{a^+}^{\alpha} (f)(x) = \frac{1}{\Gamma (\alpha)} \int_a^x (x-y)^{\alpha-1} f(y)dy$$
respectively,
$$D_{a^+}^{\alpha} (f)(x) = \frac{1}{\Gamma (1-\alpha)} \frac{d}{dx}\int_a^x \frac{f(y)}{(x-y)^{\alpha}}dy.$$ It follows that $D_{a^+}^{\alpha} I_{a^+}^{\alpha} (f) = f$ and viceversa. Denote by $I_{a^+}^{\alpha} (L^2)$ the imagine of $L^2([a,b])$ by the operator $I_{a^+}^{\alpha}$. Question: if I have an operator $T_{\alpha}:I_{a^+}^{\alpha} (L^2)\rightarrow L^2([a,b]) $ which is a linear isomorphism. What is the norm considered on the imagine space? That is,
$$\|T_{\alpha}f\|_{L^2([a,b])} \leq \|T_{\alpha}\|_{op} \|f\|_{?}$$
where $\|T_{\alpha}\|_{op}$ denotes the operator norm.","['calculus', 'real-analysis', 'analysis', 'functional-analysis', 'derivatives']"
1137921,Does a reflexive element constitute asymmetry and anti-symmetry?,"I'm studying properties of relations and there is one area that i'm kind of unsure about regarding the properties of asymmetry and anti-symmetry. Suppose $R = \{(1,2),(3,4),(2,2)\}$ It would follow that $R$ is: Not reflexive,
Not irreflexive,
Not symmetric, I would say it is not asymmetric and not antisymmetric also, but I get hung up on the $(2,2)$ element. Does $(2,2)$ , or any reflexive ordered pair, count as $a = 2$ and $b = 2$ , such that $a R b$ and $b R a$ ?","['relations', 'discrete-mathematics', 'elementary-set-theory']"
1137972,Natural solutions to $4^n + 2^{n + 1} = 2^{k}$,"Is there such an $n$ and $k$ that $$4^n + 2^{n + 1} = 2^{k}$$ with $n, k \in \mathbb N$. I wrote a program and for $n, k < 5000$ have not found a solution. Is this possible?","['elementary-number-theory', 'algebra-precalculus', 'diophantine-equations']"
1137994,"Show that $\sqrt{7}\notin\mathbb{Q}(\alpha)$, with $\alpha$ a root of $X^7+6X^3+3X+15$","Let $f=X^7+6X^3+3X+15\in\mathbb{Q}[x]$, and $\alpha\in\mathbb{C}$ such that $f(\alpha)=0$. I want to show $\sqrt{7}\notin\mathbb{Q}(\alpha)$ First of all, by Eisenstein's criterion, $f$ is irreducible in $Q[x]$, so we can say that $\deg (\text{Irr}(\alpha,\mathbb{Q}))=7=\left[\mathbb{Q}(\alpha):\mathbb{Q}\right]$. Then, $\left\{1,\alpha,\ldots,\alpha^6\right\}$ is a $\mathbb{Q}$-basis of $\mathbb{Q}(\alpha)$. Then, $\sqrt{7}\in\mathbb{Q}(\alpha)\Longleftrightarrow \sqrt{7}=\lambda_0 1+\lambda_1\alpha+\cdots+\lambda_6\alpha^6$ with $\lambda_i\in\mathbb{Q}$. But I get stuck here. How should I proceed?","['irreducible-polynomials', 'extension-field', 'abstract-algebra', 'polynomials', 'field-theory']"
1138003,Solve a system of equations of ten unknowns.,"I have the following problem: Find all $a_1,a_2,a_3,....,a_{10} \in\{1,2,3,...,10\}$ satisfying $\hspace{2cm}\begin{align} a_1+a_2+a_3 &=k\\ a_3+a_4+a_5 &=k\\
a_5+a_6+a_7 &=k\\
 a_7+a_8+a_1 &=k \\
a_1+a_9+a_5 &=k \\
 a_7+a_{10}+a_3 &=k
\end{align} $ where $k$ is a constant positive integer. I am really stuck on this problem how to solve these $6$ equations to find the ten unknowns.Please help me. Thanks.","['algebra-precalculus', 'systems-of-equations']"
1138061,Using the Intermediate Value Theorem to prove a statement about an equation true,"I want to prove this statement true by using the IVF: For any real number $b > 2$, the equation $2^x = bx$ has a solution. Here are some questions I need help with answering: Define a function $f(x) = 2^x-bx$. How does finding a zero for $f(x)$ correspond to finding a solution to $2^x=bx$? (I know that $f(x)$ is continuous, but don't understand what the correlation is). Find a value $x$, when plugging it into $f$ gives a positive output, regardless of the value of the variable $b$, and Find a value $x$ when plugged into $f$, gives a negative output, as long as $b > 2$.","['calculus', 'proof-writing', 'functions']"
1138078,Representation of irrationals as $\sum_{n\ge 2}\frac{x_n}{n!}$,"Prove that every $x\in(0,1)\setminus\mathbb{Q}$ has a unique representation as $x = \sum_{n\ge 2}\frac{x_n}{n!}$, where $x_n\in\mathbb{Z}_n = \{0,1,2,\ldots,n-1\}$. Probably this is well known,
I'd be grateful for a book or article with a proof.","['number-systems', 'irrational-numbers', 'reference-request', 'number-theory']"
1138088,Showing $\int_{0}^{\pi }{x\cdot \sin \left( x \right)dx}=\; \frac{\pi }{2}\int_{0}^{\pi }{\sin \left( x \right)dx}$,"I'm working on integration by substitution and can't seem to get a hang on the following detail: How would one use the substitution $\displaystyle u = \pi - x$ to show the following equality: $\int_{0}^{\pi }{x\cdot \sin \left( x \right)dx}=\; \frac{\pi }{2}\int_{0}^{\pi }{\sin \left( x \right)dx}$ My approach so far with substitution has been to find a part of the integrand to substitute for ""$\displaystyle u$"" and then differentiate it to get a substitution of $\displaystyle du$ for the integral $\displaystyle dx$ (and then integrate in terms of $u$); however, in using the above substitution, I cannot see how to approach this to isolate ""$\displaystyle x$"" from ""$\displaystyle \sin(x)$"" in terms of $\displaystyle u$ and $\displaystyle du$...maybe I'm missing something obvious, but can't see it. Thanks a bunch if anyone has any insight.","['calculus', 'integration']"
1138116,Separate form for $f'(x)$ [duplicate],"This question already has an answer here : Proof for alternative definition of the derivative (1 answer) Closed 9 years ago . $\qquad^{\star\star}(b)$ Prove, more generally, that
  $$f'(x) = \lim_{h, k \to 0^+}\frac{f(x + h) - f(x - k)}{h + k}$$ ONLY HINTS PLEASE. The denominator is the issue. I thought of $u = h + k$ but that created an issue  for the limit bounds. I tried adding and subtraction $f(x)$ in the numerator but the denominator causes issues. ONLY HINTS PLEASE! Attempts: $$f'(x) = \lim_{h, k \to 0} \frac{f(x + h) - f(x + h + k) + f(x + h + k) - f(x - k)}{h+k} $$ $$ = \lim_{h, k \to 0} -\frac{f(x + h + k) - f(x + h)}{h+k} + \frac{f(x + h + k) - f(x - k)}{h+k}$$ let $u = x + k$. As $k , h\to 0,$ $u \to x$ and $x - k =  u - 2k$ Which makes things weird.","['calculus', 'real-analysis', 'analysis', 'proof-writing', 'derivatives']"
1138118,Simplifying $\csc^{-1}(\sec 2)$?,How do I simplify $\csc^{-1}(\sec 2)$? The answer in the book is $\frac\pi2 - 2$.,"['trigonometry', 'calculus']"
1138127,Prove $X$ is well ordered.,"Let $(X,\le)$ be a totally ordered set where $X$ is infinite. Given any countable subset of $X$ is well ordered, prove $(X,\le)$ is well ordered as well. It would really help me to know how accurate I am and how valid my arguments are, so that I can know how to improve them and still keep my way of arguing. $Attempt:$ $\le$ is a total order. Therefore, every subset of $X$ is a chain, naturally. Therefore finite subsets of $X$ are necessarily well ordered, since every two element are comparable and the minimal element is the minimum\lower bound. For infinite subsets it is given as well. Therefore: any subset has a minimum $\land$ every subset is a chain $\Rightarrow$ every chain has a lower bound $\Rightarrow$ there is a minimal element in $X$ by Zorn's lemma. $(X,\le)$ is totally ordered and therefore the minimal element is unique and is comparable with all the elements $\Rightarrow$ $X$ has a least element in the ordering $\Rightarrow$ $X$ is well ordered.","['elementary-set-theory', 'proof-verification']"
1138134,"What is the matrix used to find the reflected (x, y) coordinate in the line y=mx?","I hope this makes sense, I'm essentially looking for a matrix in which you can just substitute in the gradient m from y=mx and find the reflected coordinates? If this doesn't make any sense please say why? Regards Tom",['matrices']
1138153,Does $\log(f(X))$ concave implies $\log(f(X^{-1}))$ convex?,"One of my professor claims that $\log f(X)$ concave implies that $\log(f(X^{-1}))$ convex where $X$ is symmetric positive definite matrix. $\log(f(X))$ is a function defined on symmetric positive definite matrix. When I ask him why, he said if you do not believe it, give me a counterexample. So I wonder is it true or any counterexample to this claim. I only know how to check a composition function convex by computing its Hessian. But what would be the Hessian in this case? I do not know how to compute.","['matrices', 'convex-analysis', 'convex-optimization']"
1138189,Full subcategories of $\mathsf{Grp}$ with epis/monos which are not surjective/injective,"I read that there exist full subcategories of $\mathsf{Grp}$ in which there are epis which are not surjective, and ones in which there are monos that are not injective. I'm confused because they're full . For instance, a monic $m$ is an arrow which is left cancellable, i.e $$mf=mg\implies f=g$$ Hence, if the subcategory is not full, I can see it's possible for ""new monos"" to appear, since there are less arrows $f,g$ to check. Injectivity, however, is independent of ""context"", so an arrow cannot become injective after a change of category. Now  if the subcategory full, how can new monos appear?","['category-theory', 'group-theory']"
1138247,Invertability of Non-Square Derivatives and Implicit Function Theorem,"In the statement of the Implicit Function Theorem from Rudin, we are asked to assume as a condition that for some function:
$$ f: \mathbb{R}^{m+n} \rightarrow \mathbb{R}^n$$
The derivative at some point $Df(x)$ is invertible. My question is about the invertibility of this non-square matrix. We can see that $Df(x)$ is a linear operator from $\mathbb{R}^{n + m}$ to $\mathbb{R}^n$ so so its matrix representation is not square. This would mean that the the determinant is not defined and hence the definition of invertiblity does not apply. However, $Df(x)$ is still a linear mapping so it would make sense for us to talk about this function as having an inverse when it is 1-to-1 and onto. Just by visualizing the 1-dimensional case, my intuition says that this would be the case whenever $Df(x) \neq 0$. The proof for such a claim doesn't seem difficult but I was wondering if someone could contribute some clarification for the distinctions between these two definitions and how they relate to the Implicit Function Theorem.","['matrices', 'linear-algebra', 'inverse']"
1138255,What is the limit of the sequence $a_n=(1-\frac{1}{2^2})(1-\frac{1}{3^2})(1-\frac{1}{4^2})\cdots(1-\frac{1}{n^2})$?,"I am stuck on finding the limit of $$\left(1-\frac{1}{2^2}\right)\left(1-\frac{1}{3^2}\right)\left(1-\frac{1}{4^2}\right)\cdots\left(1-\frac{1}{n^2}\right)$$ Can anybody help? UPDATE
Is there a solution involving making the fractions like
$$(\frac{n^2-1}{n^2})$$
and using the formula
$$(2^23^24^2...n^2) = (n!)^2$$?","['sequences-and-series', 'limits']"
1138259,Complex Measure Agreeing on Certain Balls,"I came across this problem and am lost as to how to solve it. Let $r>0$ be fixed. Suppose $\mu,
\nu$ are complex Borel measures on $\mathbb{R}^d$ such that for each open ball B of radius $r$, $\mu(B)=\nu(B)$. Then $\mu=\nu$. I thought this might be an application of $\pi-\lambda$ theorem, but I realized we wouldn't have a $\pi$-system with the collection of open balls $B$ since intersecting such balls might not necessarily be open or have radius $r$ still. Any help would be greatly appreciated.","['measure-theory', 'fourier-analysis']"
1138286,$f(A\cap B)=f(A)\cap f(B)$ $\iff$ $f$ is injective.,"Let $f:X\to Y$ where $X$ and $Y$ are nonempty. Prove that a sufficient and essential condition for any two subsets $A,B\subseteq X$ to fulfill $f(A\cap B)=f(A)\cap f(B)$ is that $f$ is injective. I sense there is some problem in my proof. I would be glad if you assisted me. $Attempt:$ Let $f$ be injective and let $A,B\subseteq X$ be two subsets. If $A$ and $B$ are disjoint, then $A\cap B=\emptyset$ $\Rightarrow$ $f(A\cap B)=\emptyset$. Since $f$ is injective then there are no two elements with the same image and therefore $f(A)\cap f(B) =\emptyset =f(A\cap B)$. Now suppose $A\cap B\ne \emptyset.$ Let $ y\in f(A\cap B)$. There exists an $x\in A\cap B$ such that $f(x)=y$. Since $x \in A$ then $f(x)=y\in f(A)$ and since $x \in B$ then $f(x)=y\in f(B)$ $\Rightarrow$ $y\in f(A)\cap f(B)$. Therefore $f(A\cap B)\subseteq f(A)\cap f(B)$. Now let $y\in f(A)\cap f(B)$. ( $f(A)\cap f(B)$ is not empty because if it were then $A$ and $B$ would have an empty intersection as well, which they don't.). Therefore $y\in f(A)$ and $y\in f(B)$ and therefore in $A$ there exists $x_1$ such that $f(x_1)=y$. The same with $B$, $f(x_2)=y$. By injectivity: $x_1=x_2 \Rightarrow x_1=x_2\in A\cap B\Rightarrow f(x_1)=y\in f(a\cap B)\Rightarrow f(A)\cap f(B)\subseteq f(A\cap B) \Rightarrow f(A\cap B)=f(A)\cap f(B).$ Necessary: Suppose it weren't necessary that $f$ is injective. Then there would exist a non-injective function $f$ such that for any two subsets $A,B\subseteq X$ we get $f(A\cap B)=f(A)\cap f(B)$. $f$ is non-injective and therefore there would be $x_1,x_2\in X$ such that $f(x_1)=f(x_2)$. Let us look at $\{x_1\},\{x_2\}\subseteq X$. $f(\{x_1\})\cap f(\{x_2\})=\{f(x_1)=f(x_2)\}\ne f(\{x_1\}\cap\{x_2\})=f(\emptyset)=\emptyset$. A contradiction.","['elementary-set-theory', 'proof-verification']"
1138321,"Spectrum of Laplacian on Half line. $\left [0, \infty \right)$","I would like to calculate the spectrum of Dirichlet and Neumann Laplacian of the domain $\left [0,\infty \right)$. To be precise, Define the Operator
$T$ on $L^2\left[0,\infty\right)$ as $Tf=-f''$ and $D(T)=H^2\cap H_0^1$. And
$S$ on $L^2\left[0,\infty\right)$ as $Sf=-f''$ and $D(T)=H^2 \cap \left \{f\in H^2 | f'(0)=0 \right \}$. Find out the Spectrum of T and S. Here T is Dirichlet Laplacian and S is Neumann Laplacian.","['ordinary-differential-equations', 'operator-theory', 'partial-differential-equations', 'regularity-theory-of-pdes', 'spectral-theory']"
1138347,Calculate integral $ \int_0^1 \frac{x}{(2-x)\sqrt[3]{x^2(1-x)}} dx$,"I have to calculate the following integral using beta and gamma functions:
$$
\int\limits_0^1 \frac{x\,dx}{(2-x)\cdot \sqrt[3]{x^2(1-x)}}
$$ I came up with this terrible solution. Firstly, let's break it into two parts:
$$
\int\limits_0^1 \frac{(x-2)\,dx}{(2-x)\cdot \sqrt[3]{x^2(1-x)}} + \int\limits_0^1 \frac{2\,dx}{(2-x)\cdot \sqrt[3]{x^2(1-x)}}
$$ The first one is $-B\left(\frac 13,\frac 23\right)$. The second one can be simplified with substitution $x = 1 - \frac 1t$ to
$$
2\int\limits_{-\infty}^0 \frac{dt}{(t+1)(t-1)^\frac 23}
$$ But it's too unwieldy in my opinion. Furthermore, it's not so easy to evaluate $B\left(\frac 13,\frac 23\right)$. Is there any easier solution?","['gamma-function', 'improper-integrals', 'integration', 'beta-function']"
1138363,<Reference Request> Research done on whether the Euler prime can be the largest factor of an odd perfect number,"(Note:  This has been cross-posted to MO .) Good day! I would like to request for references to research done as to whether the Euler prime of an odd perfect number can also be its largest factor. To be more specific, the Euler prime $q$ of an odd perfect number $N$ is the sole prime factor that occurs to an (odd) exponent $k \equiv 1 \pmod 4$.  That is, we can write this odd perfect number in the form $N = {q^k}{n^2}$, where $\gcd(q, n) = 1$. In an e-mail, it was communicated to me by Douglas Iannucci that his advisor, Peter Hagis Jr. , considered this possibility.  I was wondering if anybody here knows of any partial results in this direction. Thank you! [Added Feb 8 2015] We do know that the Euler prime $q$ is not the smallest prime factor of an odd perfect number $N = {q^k}{n^2}$.  To see why, it suffices to consider: $$q + 1 = \sigma(q) \mid \sigma(q^k) \mid 2N.$$","['perfect-numbers', 'reference-request', 'open-problem', 'number-theory']"
1138386,Is $540^\circ$ a straight angle?,"The usual definition of a straight angle is a $180^\circ$ angle. however, because a $540^\circ$ angle is also the same shape, is it a straight angle as well?","['geometry', 'euclidean-geometry', 'definition']"
1138402,Express the quantified logical statements using the predicates,"I just started learning predicates and quantifiers. I am pretty confused so I was wondering if someone can help me. Using the predicates $P(x)$ to denote âx is a pro baseball playerâ, $R(x)$ to denote âx is richâ, $L(x)$ to denote âx is a pro football playerâ and $K(x, y)$ to denote âx knows yâ, write down quantified logical statements toexpress: All pro football player are rich. Some pro baseball players are rich. All pro baseball players know at least one pro football player. All pro baseball players know a rich a pro football player. Some pro football players know a rich pro baseball player. Everyone knows a rich pro football player or a rich pro baseball player. The domain of discourse is all people in the world. This is what I have so far: $âx (L(x) â R(x))$ $âx (P(x) â§ R(x))$ $âx(P(x)âây(K(x,y)â§L(y)))$ Unsure about 4 and 5 $âxây(P(x)âK(x,y)â§(R(y)â§(L(y)))$ $âxây(L(x)â§(K(x,y)â§(R(y)â§(P(y)))$ $âxây(K(x,y)â§R(y)â§(P(y)â¨L(y)))$","['predicate-logic', 'quantifiers', 'discrete-mathematics']"
1138408,Showing a sequence of integrals converges to zero,"Let $\varphi$ be a complex-valued function which is analytic on $\{z \in \mathbb C : |z| \leq 2\}$, let $\gamma$ be the unit circle in the complex plane, and define $$
F_n(z) = \int_\gamma \frac{1}{s-z} \int_{-2}^{2} e^{-nt^2} \frac{\varphi(t)}{t-s}\,dt\,ds,
$$ where $|z| < 1/2$. Main Question: Is it true that $F_n(z) \to 0$ uniformly for $|z| < 1/2$ as $n \to \infty$? We should note that the double integral exists.  Indeed, by properties of Cauchy-type integrals (see Gakhov, Boundary Value Problems or here ), the function $$
g(s) = \int_{-2}^{2} e^{-nt^2} \frac{\varphi(t)}{t-s}\,dt
$$ is analytic on $\mathbb C \setminus [-2,2]$ and has continuous extensions from the upper and lower half-planes to the interval $(-2,2)$ which satisfy $$
\lim_{\epsilon \to 0^+} g(x \pm i\epsilon) = \pm i\pi e^{-nx^2} \varphi(x) + \operatorname{P.V.} \int_{-2}^{2} e^{-nt^2} \frac{\varphi(t)}{t-x}\,dt
$$ for $-2 < x < 2$.  Consequently, $g(s)$ is continuous on $\gamma$ except for two jump discontinuities at $s = \pm 1$. Idea for an approach I have an idea for an approach which I have so far been unable to make rigorous.  At the end are a couple of problems that I see with it that I would greatly appreciate some feedback on. First I'd like to split the inner integral up into $$
\int_{-2}^{2} = \int_{|t| < 1} + \int_{1 < |t| < 2},
$$ and so write $$
F_n(z) = \int_\gamma \frac{1}{s-z} \int_{|t| < 1} e^{-nt^2} \frac{\varphi(t)}{t-s}\,dt\,ds + \int_\gamma \frac{1}{s-z} \int_{1 < |t| < 2} e^{-nt^2} \frac{\varphi(t)}{t-s}\,dt\,ds. \tag{1}
$$ Now switch the order of integration in both integrals.  The first becomes $$
\int_\gamma \frac{1}{s-z} \int_{|t| < 1} e^{-nt^2} \frac{\varphi(t)}{t-s}\,dt\,ds = \int_{|t|<1} e^{-nt^2} \varphi(t) \int_\gamma \frac{ds}{(s-z)(t-s)}\,dt,
$$ and the inner integral here is $$
\int_\gamma \frac{ds}{(s-z)(t-s)} = 2\pi i \left(\frac{1}{t-z} - \frac{1}{t-z}\right) = 0.
$$ The second integral in $(1)$ becomes $$
\begin{align}
\int_\gamma \frac{1}{s-z} \int_{1 < |t| < 2} e^{-nt^2} \frac{\varphi(t)}{t-s}\,dt\,ds &= \int_{1 < |t| < 2} e^{-nt^2} \varphi(t) \int_\gamma \frac{ds}{(s-z)(t-s)}\,dt \\
&= 2\pi i \int_{1 < |t| < 2} e^{-nt^2} \frac{\varphi(t)}{t-z}\,dt,
\end{align}
$$ so we conclude that $$
F_n(z) = 2\pi i \int_{1 < |t| < 2} e^{-nt^2} \frac{\varphi(t)}{t-z}\,dt.
$$ Then $$
\begin{align}
e^{n} |F_n(z)| &= 2\pi \left| \int_{1 < |t| < 2} e^{-n(t^2-1)} \frac{\varphi(t)}{t-z}\,dt \right| \\
&\leq 2\pi \cdot \operatorname{Length}(\{1 < |t| < 2\}) \cdot \sup_{1 < |t| < 2} \left( e^{-n(t^2-1)} \frac{|\varphi(t)|}{|t-z|} \right) \\
&\leq 2\pi \cdot 2 \cdot \sup_{1 < |t| < 2} \left(1 \cdot \frac{|\varphi(t)|}{1/2} \right) \\
&\leq C
\end{align}
$$ for some constant $C > 0$, so $$
|F_n(z)| \leq Ce^{-n} \to 0
$$ uniformly for $|z| < 1/2$ as $n \to \infty$. There are a couple of issues that I see with this: Can the interchange of order of integration be justified in both cases? Are the subsequent evaluations of the inner integrals using the residue theorem valid?","['proof-verification', 'singular-integrals', 'functional-analysis', 'complex-analysis']"
1138422,"Given monotonic sequences $(a_n), (b_n)$ does $\lim_{n \to \infty} a_n b_n $ always exist?","If we are given monotonic real sequences $(a_n)_{n\ge1}, (b_n)_{n\ge1}$ then does the limit $\lim_{n \to \infty} a_n b_n $ always exists (+-infinity is also considered as limit point)? The case that needs looking into is obviously the one when, for example $a_n \to \infty$ and $b_n \to 0$ . I've been thinking a bit and i can't seem to find a counterexample (i am pretty sure that a limit does not always exist) Thanks in advance!","['sequences-and-series', 'calculus', 'real-analysis']"
1138453,Limit of $\sum_{k=1}^{n} \frac{k}{3^k}$,"I need to calculate $$\lim_{n \to \infty}\sum_{k=1}^{n} \frac{k}{3^k}$$ and I can't really do it. I have a feeling it's simple and that there's a simple catch but I just can't see it. If anyone could provide me with a hint to solve this, I would be grateful. I know this question is classified as homework and that it seems like I haven't tried anything, but I have. I tried expanding this but that doesn't help at all. Geometric progression came to mind at first, but I realized it's not very useful either. 
Thanks.","['convergence-divergence', 'limits']"
1138462,Transpose matrix dual map,"How do I see that the representing matrix of the dual map $f^*$ between finite-dimensional dual spaces is given by the transpose of the representing matrix of $f$ ? Here I want to assume that the matrix $f^*$ is represented with respect to the dual basis. Apparently this result is very well-known, but I would like to see proof of this.","['matrices', 'linear-algebra']"
1138509,"The set $\{1,2,3,\ldots,n\}$, where $n \geq 5$, can be divided into two subsets so that the sum of the first is equal to the product of the second","A peer of mine showed me earlier today this problem, taken from a 7th grade math contest : Let $A=\{1,2,3,\ldots,n\}$; (where $n \geq 5$) prove that $A$ can be divided into two disjoint subsets such that the sum of the elements in the first subset is equal to the product of the elements in the second subset. This has been puzzling me for 15 minutes already, but I'm sure there's a simple, straight-forward way to do it since it's a 7th grade problem, albeit I can't see it. Can anyone shed some wisdom here ?","['elementary-number-theory', 'combinatorics']"
1138540,Limit of this Rational Expression,"so I just got through my first Calculus lesson in class, introduction to limits. One of the questions was: $\displaystyle \lim_{x \to 1}  \frac{\frac 1x-1}{x-1}$ When you substitute 1 into the function, it equals $\frac 00$. My teacher said that when you get $\frac 00$, you should either factor, rationalize the denom/numerator, or multiply by the conjugate to manipulate the equation. I've tried those and it hasn't worked. Any help please?","['calculus', 'limits']"
1138573,Inverse of laplacian operator,"I recently read a paper, the author treats 
$$\int_{\mathbb{R}^d}f(y)\cdot \frac{1}{|x-y|^{d-2}}\,dx = (- \Delta)^{-1} f(y)$$
up to a constant in $\mathbb{R}^d$. I am not familiar with unbounded operator, so my question is: Under what condition can one take the inverse of an unbounded operator like above? Can anyone refer some references? Thanks!","['compact-operators', 'operator-theory', 'distribution-theory', 'real-analysis', 'functional-analysis']"
1138578,"Strange behavior with {xor, and, or} bit operations on integer offsets","I thought of a problem today: given a range of integers $[a, b]$ , for all pairs of integers $(x, y)$ in that range, what is the number of them such that $x$ op $y \in [a, b]$ , where op is one of {xor, and, or} (all bit-wise)? I use this to find the percentage of all possible pairs of integers in the range, when applying the operation, is still in the range. Of course, these operations work on the binary representation of the integers. I will let $P_{op}([a, b])$ be a value between 0 and 1 which is the percentage of integer pairs $(x, y) \in [a, b] \times [a,b]$ such that $x$ op $y \in [a, b]$ . I have not found any material that finds the probability directly, so I wrote a program to do it for me. However, I am noticing strange behavior. As examples, I provide outputs of some runs, where $b-a \in \{284, 759, 951\}$ (randomly selected). The horizontal axis denotes $a$ (the low end of the range), and the vertical axis denotes the respective $P_{op}$ . It is strange to see that the ""or"" and ""and"" plots have somewhat of a recurring pattern, whereas the ""xor"" plot does not (and stays at 0 for most values). I'd like to know: Is there a closed form (or anything more efficient than brute force) to determine, for any interval $[a,b]$ , $P_{op}([a,b])$ for op $\in\{\text{or, and, xor}\}$ ? Why does the appear to be a recurring pattern in the plots and images below? Interestingly enough, there does seem to be a pattern! I generated algorithms for every single offset up to some number (~550 here since the algorithm was starting to take a long time) for each of {xor, or, and}, and then generated images displaying them. Each row corresponds to some offset, and each column represents the x-value in the images above (the lower bound of the range). Since each pixel represents a real value between 0 and 1, I multiplied each value by 255 and mapped them to an integerâââa value of 0 is black, 255 is white, and any value in between is linearly scaled. For example, 128 is grey (halfway between white and black). The patterns look really cool! ""And"" output: ""Or"" output ""Xor"" output","['computer-science', 'number-theory']"
1138586,Find point of right triangle by hypotenuse and another point,"Is it possible to find the coordinates of the point marked (?,?) if I have a rectangle/right triangle with a given point and the length of the hypotenuse? See image: Thanks everyone.",['trigonometry']
1138610,"Find marginal distribution of $Y$ where $Y\mid X$ is $N(a_1+a_2X,\sigma_1^2)$ and $X$ is $N(\mu,\sigma^2)$?","Let a random variable $X$ be normal $N(\mu,\sigma^2)$ and let the conditional distribution of $Y$ given $X$ be normal $N(a_1+a_2X,\sigma_1^2)$. a)Find the joint probability density function of $X$ and $Y$. b)Find the marginal distribution of $Y$ and the correlation coefficient of $X$ and $Y$. For (a), I just multiplied the conditional density of $Y$ given $X$ and density of $X$; and I think it's ok. For (b), I tried to write their joint density in the form of bivariate normal but couldn't do that. On the other hand, we know that if the random variables $X$ and $Y$ are bivariate normal then, the conditional distribution of $X$ given $Y$ is normal with mean $E[X\mid Y]$ and variance $(1-\rho^2)\sigma_X^2$. But is that true that if $X$ is normal and $Y$ given $X$ is normal, then they are bivariate normal? So that I can do (b) easily, or is there another way to solve this question? Thanks!","['statistics', 'normal-distribution', 'probability', 'covariance']"
1138648,"Fredholm Alternative as seen in PDEs, part 2","...continued from part 1. I have more questions concerning more of Evans' proof in the Fredholm Alternative. As stated in my previous question, I do not have functional analysis background, but I want to still understand the proof. So my five questions will be fundamental and basic. Any answers and clarifications are welcomed. NB: For anyone who is about to suggest me to read suggested books or point out that I have a lack of background in functional analysis (and even theoretical linear algebra), please don't. Because I already know that. As suggested by a user on my previous question, I plan to read the Haim Brezis textbook over the summer when I don't have classes in the regular school semesters. With that said, I am printing the theorem below, along with the second excerpt of the textbook's proof and my basic questions to follow. (PDE Evans, Appendix D, Theorem 5) THEOREM 5 (Fredholm Alternative) . Let $K : H \to H$ be a compact linear operator. Then (i) $N(I-K)$ is finite dimensional, (ii) $R(I-K)$ is closed, (iii) $R(I-K)=N(I-K^*)^\perp$ , (iv) $N(I-K)=\{0\}$ if and only if $R(I-K)=H$ , and (v) $\dim N(I-K)=\dim N(I-K^*)$ . The second excerpt of the textbook proof: Assertion (iii) is now a consequence of (ii) and the general fact that $$\overline{R(A)}=N(A^*)^\perp \text{ for each bounded linear operator }A: H \to H.$$ a. Can the overline in $\overline{R(A)}$ be explained? Why do we not need the overline for statement (iii), $R(I-K)=N(I-K^*)^\perp$ ? To verify (iv), let us suppose to start with that $N(I-K)=\{0\}$ , but $H_1=(I-K)(H) \subsetneq H$ . According to (ii), $H_1$ is a closed subspace of $H$ . Furthermore $H_2 \equiv (I-K)(H_1) \subsetneq H_1$ , since $I-K$ is one-to-one. Similarly if we write $H_k \equiv (I-K)^k(H)$ ( $k=1,\ldots$ ), we see that $H_k$ is a closed subspace of $H$ , $H_{k+1} \subsetneq H_k$ ( $k=1,\ldots$ ). Conversely, choose $u_k \in H_k$ with $\|u_k\|=1$ , $u_k \in H_{k+1}^\perp$ . Then $Ku_k-Ku_l=-(u_k-Ku_k)+(u_l-Ku_l)+(u_k-u_l)$ . Now if $k > l$ , $H_{k+1} \subsetneq H_k \subseteq H_{l+1} \subsetneq H_l$ . Thus $u_k-Ku_k$ , $u_l-Ku_l$ , $u_k \in H_{l+1}$ . Since $u_l \in H_{l+1}^\perp$ , $\|u_l\|=1$ , we deduce $\|Ku_k-Ku_l\| \ge 1$ ( $k,l=1,\ldots$ ). But this is impossible since $K$ is compact. b. I know that $I$ and $K$ considered linear transformations because $I$ is the identity operator (is this true?) and $K$ is given to be a compact linear operator. Hence, $I-K$ is a linear transformation, right? Due to a theorem from linear algebra, is it because $I-K$ established to be one-to-one because the nullspace $N(I-K)=\{0\}$ as initially given? c. Why does the one-to-one property $I-K$ implies that we can write $H_2 \equiv (I-K)(h_1) \subsetneq H_1$ , which would allow us to write after $k$ iterations $H_k \equiv (I-K)^k(H)$ ? d. How does $u_l \in H_{l+1}^\perp$ and $\|u_l\|=1$ suggest $\|Ku_k - Ku_l\| \ge 1$ , which would make $\{Ku_k\}$ not Cauchy and contradict the compactness of $K$ ? Ultimately, I cannot right now see the connection that allows us to conclude that the rank $R(I-K)=H$ , thereby proving the forward direction of (iv)... Now conversely assume $R(I-K)=H$ . Then owing to (iii), we see that $N(I-K^*)=\{0\}$ . Since $K^*$ is compact, we may utilize step 5 to conclude $R(I-K^*)=H$ . But then $N(I-K)=R(I-K^*)^\perp=\{0\}$ . This conclusion and step 5 complete the proof of assertion (iv). e. Given $R(I-K)=H$ , because of (iii) we have $N(I-K^*)^\perp=H$ . But how does the transpose of $N$ equivalency with $H$ imply $N(I-K)=\{0\}$ ? Follow-up part 3...","['linear-algebra', 'functional-analysis', 'partial-differential-equations']"
1138696,Conversion from Polar to Rectangular,"Can someone please explain to me how to convert the following equation from polar to rectangular? r=$2^\theta$ Thus far I got: $4^{\arctan(y/x)}$=$x^2$+ $y^2$ by squaring both sides and replacing $r^2$ with $x^2$+$y^2$ and $\theta$ with $\arctan(y/x)$ However when I graphed both of them, they were not the same and thus I think I went wrong somewhere. Any help would be very appreciated.
Sorry for the format, I'm new to this and not very good. Thank You","['polar-coordinates', 'algebra-precalculus']"
1138697,Find the solution of the given initial value problem (differential equations),"Question: $$\frac{dy}{dt}+ty=1+t$$ where $y(\frac{3}{2})=0$. So I know this is a non-homogeneous equation and as I started working on it, I ended up with: $$e^{\frac{t^2}{2}}y=\int_{\frac{3}{2}}^{t} e^{\frac{\tau^2}{2}}d\tau$$ and I'm stuck at this step. Any help?","['ordinary-differential-equations', 'calculus']"
1138706,Hierarchy of Convergence,"My motivating thought is if I have a sequence of functions that converges in C([0,1]), is it enough to show that it converges to something outside C([0,1]), to show that it doesn't converge in C([0,1])? Limits are unique in metric spaces, so I suppose in this case it would be enough- but then what forms of convergence are stronger and weaker than other forms? For instance, almost uniform convergence doesn't imply a unique limit- we could have a function that almost uniformly converges to both a continuous function, and a discontinuous function! So what is the hierarchy of convergence, and when can I just cite the uniqueness of a limit?","['convergence-divergence', 'limits']"
1138711,Fourier COSINE Transform (solving PDE - Laplace Equation),"I'm trying to solve Laplace equation using Fourier Cosine Transform (I have to use that), but I don't know if I'm doing everything OK. NOTE: $U(\cdot)$ is the Fourier transform of $u(\cdot)$ This are the equations (Laplace, boundary, etc.): $$u_{xx}+u_{yy} = 0 \text{ with } y>0,\  0<x<a$$ $$u_y(x,0) = u(0, y) =0$$ $$u(a,y) = g(y)$$ $$|u(x,y)|<M$$ I used ""Transform Methods for Solving PDE"", from G. Duffy and this is what I'm doing (maybe you have a better way): Now, since $x$ is between from $0$ to $a$ and $y$ is between $0$ and $\infty$ , I use the definition of Fourier Cosine Transform and: $$\int_{0}^{\infty} u_{xx} \cos{(w y)} \ dy + \int_{0}^{\infty} u_{yy} \cos{(w y)} \ dy = 0$$ where: $$\int_{0}^{\infty} u_{xx}.cos(w.y) dy = U_{yy}(x,w)$$ $$\int_{0}^{\infty} u_{yy}.cos(w.y) dy = [u_y(x,y).cos(w.y)] - w.[u(x,y).sin(w.y)] - w.\int_{0}^{\infty}u(x,y).cos(w.y) dy$$ Note: I don't know how to write the Barrow Rule in LaTeX. Where it says [...] it's Barrow from $0$ to $\infty$ Now, I know that: $[u_y(x,y).cos(w.y)] = 0$ because of the conditions: $u_y(x,0) =0$ and $|u(x,y)|<M$ (is that ok?) But now, I want to solve this: $[u(x,y).sin(w.y)]$ and I don't know why, because I don't have any condition for $u(x,0)$ (but I have a condition for $u(0,y)$ . What's wrong? I searched everywhere but I couldn't find anything that helps me. Thanks!!! Note 2: using Fourier Cosine Transform definition, I know that: $$\int_{0}^{\infty}u(x,y).cos(w.y) dy = U(x,w).$$ That's correct, isn't it?","['transformation', 'fourier-analysis', 'complex-analysis', 'integral-transforms']"
1138752,what is the minimum number of conjugacy classes for a group of order $n!$?,"i became curious about how one might measure the extent to which a given finite group departs from perfect commutativity. a rough-and-ready index of the degree to which a group $G$ is commutative may be computed as the proportion of ordered pairs $(g_1,g_2) \in G \times G$ for which $g_1g_2 = g_2 g_1$ calculating this index, let us call it $\kappa$, turned out to be simpler than i had anticipated. described in words, the probability of two randomly sampled elements commuting is equal to the number of conjugacy classes divided by the order of the group. let $\Gamma (=\Gamma_G)$ denote the set of conjugacy classes of the finite group $G$. for every element $g$ of $G$ belonging to $\gamma \in \Gamma$ the number of elements of $G$ which commute with $g$ is the order of $G_g$, the centralizer of $g$. by a basic result of group theory:
$$
|G_g| = \frac{|G|}{|\gamma|}
$$
thus the probability that a randomly-chosen pair of elements of $G$ commute (sampling with replacement) is:
$$
\kappa(G) = \frac{\sum_{g \in G} |G_g|}{|G|^2} \\
 = \frac{|\Gamma_G|}{|G|}  \\
$$
in particular for symmetric groups we have:
$$
\kappa(S_n) = \frac{P(n)}{n!}
$$
where $P(n)$ is the number of partitions of $n$ question is $P(n)$ the minimum number of conjugacy classes for a group of order $n!$, and if so, how can this be demonstrated?",['group-theory']
1138777,Cyclic properties of multiplicative group G of all the complex $2^n$ roots of unity,"Consider the multiplicative group G of all the complex $2^n$ roots of unity, $n=0,1,2,\ldots$ I am asked to verify whether $G$ is a cyclic group and  whether it has a finite set of generators. The answer to both these questions is coming as yes as $$G=\left\{e^{\frac{2\pi ik}{2^n}}\bigg|k=0,1,2,\ldots ,n-1\right\}.$$ and it has only one generator i.e.$e^{\frac{2\pi i}{2^n}}$ But the answer to both these questions is given as no. Any help?","['roots-of-unity', 'group-theory', 'abstract-algebra']"
1138796,How can one prove that $ \lim\limits _{n\rightarrow \infty}\int \limits_{0}^{\infty}\frac{\sin (x^{n})}{x^{n}}dx=1 $?,"I am trying to prove that $$ \lim _{n\rightarrow \infty}\int \limits_{0}^{\infty}\frac{\sin (x^{n})}{x^{n}}dx=1 .$$ My Attempt: Since $$ \lim _{a\rightarrow 0}\frac{\sin a}{a}=1 $$ and for each $ x\in [0,1) $, $$ \lim _{n\rightarrow \infty}x^{n}=0 $$ we can obtain $$ \lim _{n\rightarrow \infty}\frac{\sin (x^{n})}{x^{n}}=1 .$$
Also since for each $ a\in \mathbb{R} $, $ |\sin a|\leq |a| $, we have that for each $ x\in [0,1) $ and $ n\in \mathbb{N} $, $ \left |\frac{\sin (x^{n})}{x^{n}}\right |\leq 1 $. Then by dominated convergence theorem, $$ \lim _{n\rightarrow \infty}\int \limits_{0}^{1}\frac{\sin (x^{n})}{x^{n}}dx=\int \limits_{0}^{1}1dx=1. $$ So, I have to show that $$ \lim _{n\rightarrow \infty}\int \limits_{1}^{\infty}\frac{\sin (x^{n})}{x^{n}}dx=0. $$ But, I still haven't managed to show it. So, could anyone give me some help ? Any hints/ideas are much appreciated. Thanks in advance for any replies.","['convergence-divergence', 'integration', 'measure-theory', 'real-analysis', 'analysis']"
1138797,"How to prove if $u\in W^{1,p}$, then $|u|\in W^{1,p}$?","How to prove if $u\in W^{1,p}$, then $|u|\in W^{1,p}$? Since $|u|\in L_p$, I only need to show weak derivative of $|u|$ exists and $D|u| \in L_p$. Can anyone give me some hint?
Thanks!","['weak-derivatives', 'real-analysis']"
1138817,"If $f$ is integrable, then $\sum\limits_{n\ge 1}\frac{1}{\sqrt n}\vert f(x-\sqrt n)\vert$ is almost everywhere finite","I would like to show that $$\sum_{n\ge0}\left\vert \frac{1}{\sqrt n} f \left(x-\sqrt n \right)\right\vert \tag{$*$}$$ converges for almost every (a.e.) $x$. The only technique I have is based on the answer to If $f\in L^1(\mathbb{R})$, then $\sum_{n\ge 1}f(x+n)$ Converges for a.e. $x$. , but I think some additional technique is needed. In that question I was hoping for a technique general enough to answer both questions, but the $\sqrt \cdot$ is throwing me off. Here's what I have: Given an integer $k$, $\int_k^{k+1}\sum_{n\ge0}\vert \frac{1}{n}f(x-\sqrt n)\vert=\sum_{n\ge 0}\int_k^{k+1}\frac{1}{\sqrt n}\vert f(x-\sqrt n)\vert$. The idea is to show that this integral is finite (implying the sum $(*)$ converges on $(k,k+1)$) and use the fact that $k$ is arbitrary to conclude that the sum converges a.e. on $\mathbb{R}$.
A naive attempt would be to bound the RHS by $\sum_{n\ge 0}\int_k^{k+1}\vert f(x-\sqrt n)=\sum_{n\ge 0}\int_{-\sqrt n - k}^{-\sqrt n - k +1}\vert f(x) \vert$, but the latest expression is larger than $\int_{-\infty }^\infty\vert f\vert$. I don't have a nice way to (a) deal with the $1/\sqrt n$ and (b) deal with the limits of integration, but they can probably be dealt with simultaneously I just don't see how.","['summation', 'integration', 'real-analysis']"
1138819,Why is $z$ holomorphic but $\bar z$ not holomorphic,Can anyone show me how I can prove something as simple as $f(z) =  z$ is holomorphic but $\bar z$ is not?,['complex-analysis']
1138822,To prove ${2p - 1 \choose p } \equiv 1 \pmod{p^2}$ without using Wolstenholme's theorem,"How to prove  that ${2p - 1 \choose p} \equiv 1 \pmod{p^2}$ ? I don't want to use  Wolstenholme's theorem; but one might use $p|{p \choose k} , 1 \le k \le p - 1$ , and $(p - 1)! \sum_{k = 1}^{p - 1} \dfrac 1k \equiv 0 \pmod p$. Please help.","['divisibility', 'congruences', 'binomial-coefficients', 'number-theory']"
1138836,Proof attempt to the ratio test for sequences,"I'm trying to prove the ratio test for sequences.
Here's what I got: If $ \lim \limits_{n \to \infty} \frac{a_{n+1}}{a_n} = L < 1 $ and $ a_n>0 \;\ \forall n $ then $ a_n $ is bounded below by $0$. Also there's $N$ so that forall $n>N$,  $a_{n+1}<a_n $. Therefore, the sequence is decreasing and bounded below so it must converge. Now, according to the test, $ \lim \limits_{n \to \infty} a_n = 0 $. Why is that?","['convergence-divergence', 'sequences-and-series', 'real-analysis', 'limits']"
1138840,Non-linear (?) differential equation,"I'm walking through differential equations on my own, but I found example which make me stop for some time. $$(t^{2} - y^{2}) \cdot y' = 2ty$$
Any help would be appreciated - is this any special method for particular kind of square equations? Cheers!",['ordinary-differential-equations']
1138853,Expected number of cards you should turn before finding an ace,"NOTE: I want to check my solution only Same question here The question is this: Shuffle an ordinary deck of 52 playing cards containing four aces. Then turn up the cards
from the top until the first ace appears. On the average how many cards are required to be turned before
producing the first ace ? I want to check my solution.It definitely matches with the answers in that other question but I don't understand their solutions(haven't done much study on probability yet). I want to check mine: We consider all the cards except the aces indistinguishable,and we will consider the aces to be indistinguishable.Now a deck is just a binary string with $48$ $C$ and $4$ $A$ ( $A$ stands for aces and $C$ stands for the other cards.Obviously,the number of such strings is $\dbinom{52}{4}$ . Now we divide into cases: 1)Number of strings with the first A in the $1$ st position: $\dbinom{51}{3}$ 2)Number of strings with  the first A in the $2$ nd position: $\dbinom{50}{3}$ .

  .

  . Number of strings with the first A in the $49$ th position: $\dbinom{3}{3}$ Since there are $4$ A's,the first $A$ cannot be in the $50$ th position. Note that for case $1$ above,we need to turn $0$ cards before getting an ace.For case $2$ ,we need to turn $1$ card before getting an ace,...,in the $49$ th case,we need to turn $48$ cards before getting an ace.Therefore,the average of it all is: $$\dfrac{48\dbinom{3}{3}+47\dbinom{4}{3}+....+0\dbinom{51}{3}}{\dbinom{52}{4}}
=\dfrac{\dbinom{52}{5}}{\dbinom{52}{4}}
=\dfrac{48}{5}$$ which is indeed the answer given there.Note that the numerator was computed by repeated application of the hockey stick identity.My questions are : Is my solution correct? Why does assuming indistinguishability still preserve the answer?I have seen this several times,but never really thought about it. If we assumed distinguishability of the cards,we will get a huge expression. How can we compute that?","['discrete-mathematics', 'combinatorics']"
1138864,Challenging identity regarding Bell polynomials,"Note: [2015-03-08] A proof of the identity below was aimed to close the gap of a rather extensive elaboration of this answer of mine. The identity (1) below is part of a more complex one, which is stated in Part 3, (39)-(42) in this follow-up answer . The split in two answers was necessary due to the restriction of up to $30000$ characters per answer. I could prove the other parts, but this final part still needed a verification. In the meanwhile I found an answer and the solution is now provided as part of  my follow-up answer starting there with expression (48). I've checked the validity of the identity for small values of $n$. It was also checked in somewhat different representations all along the work of my related answer. In order to keep the calculations manageable, I've introduced some abbreviations: Let's consider a function $f=f(z)$ and its Taylor series expansion at a point $x$
\begin{align*}
f(z+x)=\sum_{n\geq 0}\frac{f^{(n)}(x)}{n!}z^n
\end{align*}
 then we use the following abbreviation for the Bell polynomials \begin{align*}
B^{f}_{n,k}(x):=B_{n,k}(f^{\prime},f^{\prime\prime},\ldots,f^{(n-k+1)})
\end{align*}
We use the Pochhammer symbol \begin{align*}
\left(f(x)\right)_k:= f(x)f(x-1)\cdot\ldots\cdot f(x-k+1)
\end{align*}
and a relationship with the Stirling numbers of the first kind , namely
\begin{align*}
(x)_n=\sum_{k=0}^{n}(-1)^{n-k}\begin{bmatrix}n\\k\end{bmatrix}x^{k}
\end{align*} I have also omitted the argument $x$ in the identity below, so for example \begin{align*}
\frac{(\ln\circ g)^{m-j}}{g^k} := \frac{\left(\ln(g(x))\right)^{m-j}}{\left(g(x)\right)^k}
\end{align*} Problem: Show that the identity is valid for $n \geq 2, 1\leq l \leq n-1$ and $1\leq m \leq l$: \begin{align*}
\sum_{k=1}^{n-l}&\sum_{j=0}^{m}\binom{m}{j}
\frac{(\ln\circ g)^{m-j}}{g^k}\frac{d^j}{d(f)^j}[(f)_k]B_{n-l,k}^{g}\\
&=\sum_{j=m}^{n}\sum_{q=1}^{j}\sum_{k=q}^{n-l}(-1)^{k-q}\frac{q!}{(j-m)!}\\
&\qquad\qquad\cdot\binom{m}{j-q}\begin{bmatrix}k\\q\end{bmatrix}f^{j-m}
\frac{ (\ln \circ g)^{j-q}}{g^k}B^{g}_{n-l,k}
\end{align*} Please note, that the indices of the Bell polynomials of the LHS and RHS in (1) coincide.","['stirling-numbers', 'closed-form', 'generating-functions', 'summation', 'combinatorics']"
1138884,Does a symmetric matrix with all entries $0$ or $1$ and with diagonal $0$ have integer eigenvalues?,"Suppose $A$ is an $nÃn$ symmetric matrix with all entries $0$ or $1$, and with diagonal $0$. Are all of the eigenvalues of $A$ integers? It works for all the cases I have tried so far.","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
1138928,Sum of sequence of $\binom{n}{r}$,How can we find the sum of $ \binom{21}{1}+ 5\binom{21}{5}+ 9\binom{21}{9}....+17\binom{21}{17}+ 21\binom{21}{21}$? I have no clue how to begin. I guess complex numbers might help. EDIT: Actually the real question was that the sum above was k and we had to find its prime factors. And the answer according to the key involves complex numbers. They have directly written that: $k=\frac{21( 2^{20} + 0^{20} + (1+i)^{20} + (1-i)^{20})}{4} = 21(2^{18}-2^9)$ I didn't get the above.,"['complex-numbers', 'combinatorics']"
1138950,"Mean value theorem for the second derivative, when the first derivative is zero at endpoints [duplicate]","This question already has answers here : Prove that $|f''(\xi)|\geqslant\frac{4|f(a)-f(b)|}{(b-a)^2}$ (2 answers) Closed 9 years ago . Suppose $f:[a,b]\to \mathbb R$ has derivative up to order $2$, and 
$f'(a)=f'(b)=0$. Prove there is  a point $c$ at $(a,b)$ such that 
$$
|f''(c)|\geq 4\frac{|f(b)-f(a)|}{(b-a)^2}.
$$ If it was factor 2, not 4, then I could use a Taylor expansion with Lagrange residue.","['inequality', 'calculus', 'derivatives']"
1138956,Center of Mass of objects with infinite length?,"Suppose you have $f(x) = \frac{\sin(x)}{x}$ And you have that shape, find the center of mass of $f(x)$ in $x \in (-\infty, \infty)$ Is it possible considering $f(x)$ is an even function?","['calculus', 'integration', 'real-analysis', 'analysis']"
1138958,Can every measure be normalized in order to be a probability measure?,"Let $\mu$ be a measure on $(X,\mathcal{A})$. Is it possible to normalize $\mu$ in order to get a probability measure? My idea is to set
$$
\mu'(A):=\mu(A)/\mu(X)~\forall~A\in\mathcal{A}.
$$",['measure-theory']
1138965,When a determinant is zero,"Is it true that if $C$ is a square matrix of size $n$ and $\det(C) = 0,$ then $C^n = O_n$ or the $0$ matrix? If yes, then why is that? I know that the reverse is obviously true, so I wondered if there is an equivalence relation between $\det(C) = 0$ and $C^n = \text{ the $0$ matrix. }$","['matrices', 'equivalence-relations', 'determinant']"
1138994,"Finding $\lim_{x\to0}\int_0^1\frac{xf(t)}{x^2+t^2}\,dt$","Let $f$ be a continuous function and $f:[0,1]\to\mathbb R$ . Find $$\lim_{x\to0}\int_0^1\frac{xf(t)}{x^2+t^2}\,dt$$ I am finding that the limit does not exist. But the question is stated in a way to enable one to think that the limit actually exists . But I don't think the limit exists, the reason being simple: By Mean Value Theorem we can write the integral as $$xf(c)\int_0^1\frac{dt}{x^2+t^2}=f(c)\tan^{-1}\left(\frac{1}{x}\right)$$ Consider a positive subsequence of $x_n\to0$ for which $f(c)\tan^{-1}(\frac{1}{x})\to f(c)\frac{\pi}{2}$ and for a negative subsequence of $x_n\to0$ we will have $f(c)\tan^{-1}(\frac{1}{x})\to-f(c)\frac{\pi}{2}$ . So the limit does not exist. So is it a situation of mis-statement of a question or am I doing something wrong? EDIT: I forgot to mention that in my solution, $c\in(0,1)$","['limits-without-lhopital', 'integration', 'definite-integrals', 'real-analysis', 'limits']"
1139001,Lexicographic order on $\alpha^\beta$ is well-ordered,"Suppose that $\alpha$ and $\beta$ are ordinals, and define the following order on $\alpha^\beta$, the set of all functions $\beta\to\alpha$ with finite support: $$f\,R\,g\iff\exists x\in\beta\,(f(x)<g(x)\land\forall y\in\beta\,(x<y\to f(y)=g(y)))$$ I wish to prove that $R$ is a well order of $\alpha^\beta$. I have already shown that $R$ is a total order on $\alpha^\beta$, so it remains to prove that if $S$ is a nonempty subset of $\alpha^\beta$ then it contains an $R$-minimal element, but I'm at a loss as for how to select this element and the Wikipedia section on this is rather terse with respect to actual proofs.","['ordinals', 'elementary-set-theory', 'order-theory']"
1139021,Prove $\cos(n)$ does not converge as $n$ tends to infinity,How do I go about proving that $\lim\limits_{n \to \infty} \cos(n)$ does not exist where $n\in \mathbb{N}$ using an $\epsilon-N$  style method?,"['epsilon-delta', 'convergence-divergence', 'sequences-and-series', 'trigonometry', 'real-analysis']"
1139022,Find the variance using the Law of total variance,Let a bacteria which behaves in one of two following ways: In the end of the day it may die but bring $2$ descendants with the probability of $p$ or die without bringing any descendants with the probability $1-p$. Let $X_k$ be the number of terms after $k$ days (And $X_0 = 1$). Find $\text{Var}(X_{k+1})$. I already showed the following using induction: $E[X_{k+1} | X_k] = 2pX_k$ and $E[X_k] = (2p)^k$. I'm trying to find the variance using the Law of total variance: $$V(X_{k+1}) = V(E(X_{k+1}|X_k)) + \color{Red}{E(V(X_{k+1}|X_k))}$$ How to evaluate the red part?,"['discrete-mathematics', 'probability', 'random-variables', 'combinatorics']"
1139030,Effective divisors and canonical section and exercise 14.3.B,"I have a question from R. Vakil's lecture notes: chapter 14 section 3 on Effective Divisors and Invertible sheaves. It says something like given an effective divisor on a scheme $X$, we may define the ideal sheaf corresponding to $\mathscr{I}$ be $\mathcal{O}(-D)$ in the exact sequence $$ 0\rightarrow \mathcal{O}(-D)\rightarrow \mathcal O_{X}\rightarrow \mathcal{O}_{D}\rightarrow 0$$ Then he defines the canonical section $s_{D}$ be as follows: tensoring with $\mathcal{O}(D)$ in the sequence, we get a morphism of sheaves $$ \mathcal{O}_{X}\rightarrow \mathcal{O}(D)$$ which gives us a canonical section. I don't understand what this means, so I presume that if we take the global section, we have a mapping of $A$-modules (all rings are denoted by $A$) $$ \mathcal{O}_{X}(X)\rightarrow\mathcal{O}(D)(X)$$ sending $1$ to some element $f\in \mathcal{O}(D)(X)=\mathcal{O}(-D)^{\vee}(X)=\text{Hom}_{\mathcal{O}_{X}}(\mathcal{O}(-D)|_{X},\mathcal{O}_{X}|_{X})$ So based on this observation, I need to show Ex 14.3.B: show that $Z(s_{D})$ is exactly the subscheme cut out by
  $D$. But an effective divisor in the sense of R. Vakil's notes is actually an effective Cartier divisor. In some other sources (See GÃ¶tz-Wedhorn Algebraic Geometry I, page 305, Remark 11.31(2)) the canonical divisor $s_{D}$ is defined to be as follows: since $D$ is effective Cartier, there exists $(U_{i},f_{i})_{i}$ where $U_{i}$ is an affine covering of $X$ and $f_{i}\in \Gamma(U_{i},\mathscr{K}^{*}_{X})$ Question 1 : If $D$ is effective but $X$ is NOT assumed to be reduced, can we still assume that $f_{i}\in\Gamma(U_{i},\mathcal{O}_{X})$? Because if it is not reduced, we cannot use Algebraic Hartog's lemma... Then in GÃ¶tz-Wedhorn, they define the canonical section $s_{D}$ to be exactly the data $(U_{i},f_{i})$. Or so it seems to me because it was written Let $V$ be any open subset of $X$. Then $\Gamma(V,\mathcal{O}(D))$
  consists of $s\in\Gamma(V,\mathscr{K}_{X})$ such that
  $sf_{i}\in\Gamma(V\cap U_{i},\mathcal{O}_{X})$. Then $s_{D}$
  corresponds to $1\in \Gamma(X,\mathscr{K}_{X})$. (Here, we assume that $X=U_{eff}$ since $D$ is an effective divisor.) Then it is clear from here that the zeros of the canonical section $s_{D}$ is defined by $V(f_{i})$ in $U_{i}$, which is exactly the closed subscheme as by the definition of an effective Cartier divisor (in the sense of R. Vakil). Question 2: How is this related to the $s_{D}$ in the definition in R. Vakil's notes? If they are related, then I can answer the exercise question straightaway. Otherwise, how should the definition be used to answer the question?",['algebraic-geometry']
1139052,How to show that $f\equiv 0$? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Let $f:[0;1]\to \mathbb{R}$ be a continuous function satisfying $$f\left(\frac{x}{2}\right) + f\left(\frac{x+1}{2}\right)=3f(x).$$ How to show that $f\equiv0$?","['continuity', 'real-analysis']"
1139067,Can this proof of existence of a Hamel basis using transfinite recursion be shortened/simplified?,"This is (I hope) a solution to Problem 112 in A. Shen and N. K. Vereshchagin, Basic Set Theory (AMS 2002). It is - I thought! - a semi-routine exercise, part of whose purpose is to enlighten the reader as to ""what transfinite induction is and why it is always replaced by Zorn's Lemma"" [from the blurb]. So, I'm moderately confident that the proof below is valid; also, given its context, I'm not surprised that it's longer and messier than a proof of the same result using Zorn's Lemma would surely be. However, I'm learning on my own, and I still feel clumsy and awkward in my use of set theory - it has never become a ""natural language"" for me - so, I'd like to know whether or not I've made unnecessarily heavy weather of this proof (as I did with some earlier exercises in the book). The book is excellent for self-study, by the way, and one of a small number of mathematical texts which I've found positively pleasurable to read.
$\newcommand{\powerset}{\mathscr{P}}$
$\newcommand{\sspan}[1]{\left\langle#1\right\rangle}$
$\DeclareMathOperator{\ham}{ham}$ The result to be proved is: Any linearly independent set $S \subset V$ in any linear space $V$ can
  be extended to a Hamel basis $S' \supset S$. The authors first prove this theorem themselves, using an auxiliary well-ordered set $I$, of cardinality greater than that of $V$.  They use transfinite recursion to construct a partial function $f$, defined on a proper initial segment of $I$, taking values in $V$; and they show that the union of $S$ with the range of this function $f$ constitutes a Hamel basis of $V$, as required.  Then they write: We could also have avoided the use of an auxiliary set $I$ of large
  cardinality by introducing a well-ordering on $V$.  At each step we
  c0nsider some element $v \in V$; if it is not a linear combination of
  current basis elements, then we add $v$ to the basis; otherwise the
  basis remains unchanged. Problem 112. Provide missing details in this proof. I don't know how transfinite recursion is normally presented, so I quote in full a theorem which they proved earlier (changing the notation for the least element of a well-ordered set from '$0$' to '$\bot$', to avoid confusion with the zero element of $V$): Let $A$ be a well-ordered set, and $B$ an arbitrary set.  Let a
  recursive rule be given, that is, a mapping $F$ whose arguments are an
  element $x \in A$ and a function $g: [\bot, x) \to B$, and whose value
  is an element of $B$.  Then there exists exactly one function $f: A \to B$
  such that
  $$ f(x) = F\big(x, f|_{[\bot, x)}\big) $$
  for all $x \in A$. Choose separate well-orderings for $S$ and $V \setminus S$, and well-order $V$ as
$S + (V \setminus S)$. In the theorem just quoted, take $A = V$, and $B = \powerset(V)$. For $x \in V$ and $f: V \to \powerset(V)$, define:
$$
f(x-) = \bigcup_{w < x} f(w), \\
\ham(f) = \{ x \in V : x \notin \sspan{f(x-)} \}.
$$ [I'm accustomed, from some time long ago, to using the notation '$\sspan{X}$' for the subspace spanned by a subset $X$ of a vector space, but can this notation be used without explanation, as I've just done?] From the theorem, it follows that there exists a unique function $f: V \to \powerset(V)$ such that, for all $x \in V$:
$$
f(x) =
\begin{cases}
f(x-) & \text{if } x \notin \ham(f) \\
f(x-) \cup \{x\} & \text{if } x \in \ham(f)
\end{cases}
$$ For all $x \in V$, if $w \leqslant x$ and $w \in \ham(f)$, then $w \in f(w) \subseteq f(x-) \subseteq f(x)$; so, $f(x) \supseteq \ham(f) \cap [\bot, x]$. Conversely, also, $f(x) \subseteq \ham(f) \cap [\bot, x]$. This is proved by transfinite induction on $x$, thus: if $f(w) \subseteq \ham(f) \cap [\bot, w]$ for all $w < x$, then
$f(x-) \subseteq \ham(f) \cap [\bot, x)$, and so $f(x) \subseteq \ham(f) \cap [\bot, x]$. We have proved $f(x) = \ham(f) \cap [\bot, x]$, for all $x \in V$. Hence, $f(x-) = \ham(f) \cap [\bot, x)$ for all $x \in V$. Therefore, for all $x \in V$, $x \in \ham(f)$ if and only if
$x \notin \sspan{\ham(f) \cap [\bot, x)}$. In particular, because $S$ is linearly independent, and because it is an initial segment of $V$, for all $x \in S$ we have $x \notin \sspan{[\bot, x)}$, therefore $x \in \ham(f)$. So, $S \subseteq \ham(f)$. If $F$ is a non-empty finite subset of $\ham(f)$, let $x$ be its largest element (w.r.t. the well-ordering of $V$); then $x \notin \sspan{F \setminus \{x\}}$.  Hence, $\ham(f)$ is
linearly independent. Also, for all $x \in V$, we have $x \in \sspan{f(x)} \subseteq \sspan{\ham(f)}$. So, $\ham(f)$ spans $V$. Therefore, $\ham(f)$ is a Hamel basis of $V$, which extends $S$.  Q.E.D. [I had to break off from writing this question, yesterday, in order to go to bed; and when trying to sleep, I managed to simplify and shorten the proof.  I really only managed to complete it today, because it wasn't as ""routine"" as I imagined.  It doesn't look quite so clumsy now, but the question still seems worth asking.] D'oh!  Wouldn't a much simpler approach have been to use transfinite recursion to define a function from $V$ into a two-element set, such as $\{0, 1\}$, or $\{false, true\}$, instead of $\powerset(V)$?  I'll think about it tomorrow - I don't want another exhausting bedtime, when I find it's not as simple as it looks! (Is there a tag for 'confounded-idiocy'?)","['vector-spaces', 'solution-verification', 'elementary-set-theory', 'hamel-basis', 'transfinite-recursion']"
1139086,"Orthogonal complement of subspace of continuous functions and odd in the interval $[-1,1]$.","The follow question was found on the Hoffman's book. Let $V$ be the real inner product space consisting  of the space of real-valued continuous functions on the interval, $-1\leq t \leq 1$, with the inner product $(f|g)=\displaystyle \int_{-1}^{1} {f(t)g(t)}dt$ Let $W$ be the subspace odd functions, ie, functions satisfying $f(-t)=-f(t)$. Find the orthogonal complement of $W$. I suppose that orthogonal complement of $W$ is the subspace of functions that satisfy $f(t)=f(-t)$. Someone have ideas to proof that?",['linear-algebra']
1139097,A question about partially ordered sets and their subsets,"I was reading about partially ordered sets and in the book, a theorem was proven. The theorem was that, given an poset, $(X, \le)$ there exists a set $Y$ of subsets of $X$ such that $(X, \le) \cong (Y, \subset)$. The proof went as follows: ""For each $a \in X$, let $Z_a = \{b \in X : b \le a\}$, and let $Y = \{Z_a : a \in X\}$. Define a map $\pi$ from $X$ to $Y$ by $\pi(a) = Z_a$. Clearly $\pi$ is a bijection. Moreover $a_1 \le a_2 \iff Z_{a_1} \subset Z_{a_2}$, so $\pi$ is an isomorphism between $(X, \le)$ and $(Y, \subset)$."" I understand why these two sets are isomorphic, but I don't understand why $Y$ is a subset of $X$. If $(X, \le)$, then there is a relation on $X$ and a relation is defined to be a subset of the Cartesian product. If thats the case, then the relation set must be a set of ordered pairs. The set $Z_a$ is the set of all elements which have a partial order on $a$. $Y$ is the set of all $Z_a$'s. But, if every $Z_a$ is based on only that which has a relation on $a$, doesn't that break the ordered pairs (since they are in the form $(a,b)$, and with any $a$ considered, only the $b$ elements would be in the set) and imply that ordered pairs cant be in any $Z_a$ set? The only other interpretation I can think of is that $a$ itself is an ordered pair, because its a member of $X$, but then, I don't see how its possible for any $Z_a$ to have elements, given its definition. Am I misunderstanding something?","['elementary-set-theory', 'order-theory']"
1139123,proving a median in a triangle base on center of mass,"I was wondering: I know that the center of mass in a triangle is divided the medians in the ratio of $2:1$. Is the opposite is true? I mean, if i have triangle $ABC$ and point $D$ is on $BC$, point $E$ is on $AB$ such that the point of intersection, divided $AD,CE$ in the ratio of $2:1$. Can i say that $AD,CE$ are medians? In Addition : what about if i have one median and a point on that median that dividing it by the ration of $2:1$, is it true to say that this point will definitely be the center of mass? Thanks.","['geometry', 'triangles']"
1139124,Linear combination of independent poisson random variables,"We know that if $X_1$  and $X_2$ are independent random variables such that  $ X_1 \sim \text{Poisson}(\lambda_1) $ and $X_2 \sim \text{Poisson}(\lambda_2)$ that $X_1+X_2 \sim \text{Poisson}(\lambda_1+\lambda_2)$ Is there any result about a linear combination of two independent poisson random variables $a_{1} X_1+a_2 X_2$ where $a_1, a_2 \in \mathcal{R}$?","['statistics', 'stochastic-processes', 'poisson-distribution', 'probability']"
1139217,Calculate integral with cantor measure,"Calculate the integral $$\int_{[0,1]}x^2d\mu_F$$ where F is the cantor function. Use the following hints about the cantor function: $F(1-x)=1-F(x)$ $F(\frac x 3)=\frac{F(x)}{2}\quad\forall x\in[0,1]$ $F(0)=0$ I thought that $$\int_{[0,1]}x^2d\mu_F=\int_{[1,0]}(1-x)^2d\mu_{F}=\int_{[0,1]}x^2d\mu_{1-F(x)}$$ but here I'm stuck and I don't know how to continue calculating this integral. Furthermore, how do we use the second and third properties when given the cantor function above?","['definite-integrals', 'measure-theory', 'integration', 'real-analysis']"
1139246,"How are ""scalar curvature"" and ""sectional curvature"" related?","I was browsing wikipedia and was puzzeling about what is the difference between: ""scalar curvature"" https://en.wikipedia.org/wiki/Scalar_curvature and 
""sectional curvature"" https://en.wikipedia.org/wiki/Sectional_curvature ? For 2-dimensional surfaces they  both describe the ""Gaussian curvature"" https://en.wikipedia.org/wiki/Gaussian_curvature (From the scalar curvature page ""the scalar curvature is twice the Gaussian curvature"") So that made me wonder, they both seem to describe the same thing  (curvature of a manifold )
but how are they related, and how can you calculate one from the other? Also I was editing the page on hyperbolic geometry on wikipedia https://en.wikipedia.org/wiki/Hyperbolic_geometry and was wondering to which of the three curvatures I should refer. For the two dimensional case I can safely refer to the Gaussian curvature , but for higher dinensional cases which curvature is correct/best? PS Under similar question I found Relationship beween Ricci curvature and sectional curvature , but am not sure if that makes this question a duplicate (if anything that question is about positive curvature, while mine is about negative curvature)","['riemannian-geometry', 'differential-geometry']"
1139251,Fermat's Last Theorem simple proof,"I came across this simple proof of Fermat's last theorem. Some think it's legit. Some argued that the author's assumptions are flawed. It's rather lengthy but the first part goes like this: Let $x,y$ be $2$ positive non-zero coprime integers and $n$ an integer greater than $2$. According to the binomial theorem:$$(x+y)^n=\sum_{k=0}^{n}\binom{n}{k}x^{n-k}{y^k}$$
then,$$(x+y)^n-x^n=nx^{n-1}y+\sum_{k=2}^{n-1}\binom{n}{k}x^{n-k}{y^k}+y^{n}$$
$$(x+y)^n-x^n=y(nx^{n-1}+\sum_{k=2}^{n-1}\binom{n}{k}x^{n-k}y^{k-1}+y^{n-1})$$ $$y(nx^{n-1}+\sum_{k=2}^{n-1}\binom{n}{k}x^{n-k}y^{k-1}+y^{n-1})=z^n$$ In the first case, he assumed that the 2 factors are coprime when $\gcd(y,n)=1$ . Then he wrote: 
$$y=q^n$$
$$ nx^{n-1}+\sum_{k=2}^{n-1}\binom{n}{k}x^{n-k}y^{k-1}+y^{n-1}=p^n$$
By replacing $y$ by $q^n$,
\begin{equation} nx^{n-1}+\sum_{k=2}^{n-1}\binom{n}{k}x^{n-k}q^{n(k-1)}+q^{n(n-1)}=p^n (*)
\end{equation} from this bivariate polynomial,he fixed alternatively $x$ and $y=q^n$ and by applying the rational root theorem, he obtained  $$q^{n(n-1)}-p^n=nxt   $$ and $$  nx^{n-1}-p^n=q^ns $$ 
($s,t$ non-zero integers)
by equating $p^x$: $$ q^{n(n-1)}-sq^n=nx(t-x^{n-2})$$
Then, he uses one of the trivial solutions of Fermat's equations. He wrote, when $x+y=1$,if $x=0$ then $y=1$ and vice versa. Therefore, he wrote: 
$x=0$ iff $q^{n(n-1)}=sq^n$, he obtains: $$q=1$$ or $$s=q^{n-2}$$ By substituting $s$ by $q^{n-2}$ in $nx^{n-1}-p^n=q^ns$, he obtains: $$nx^{n-1}-p^n=q^{n(n-1)}$$
Then, he replace that expression in equation (*) and pointed out that:$$\sum_{k=2}^{n-1}\binom{n}{k}x^{n-k}q^{n(k-1)}=0$$. Since $x,y=q^n$ are positive integers for all $n>2$, a sum of positive numbers can not be equal to zero. Which leads to a contradiction. What do you think?","['solution-verification', 'fake-proofs', 'diophantine-equations', 'number-theory']"
1139270,$\operatorname{PSL}_2(\mathbb{Z})$ is the free product of two cyclic groups.,"Let $G$ be a group generated by two matrices
$ S=\left( \begin {array}{cc} 0&{-1}\\1&0\end{array}\right),\, T=\left( \begin{array}{cc}1&1\\0&1\end{array}\right) $
in $SL_2(\mathbb Z)/ \{ \pm 1 \} ,$ i.e., $G=\langle S,T\rangle$. Then how to show that $ \langle S,X ; S^2,X^3\rangle$ where $X=ST$ is a presentation of $G$? It's hard for me to show all relations can be generated by $S^2$ and $X^3$. (BTW, these groups rise from modular group.)","['number-theory', 'abstract-algebra', 'matrices', 'group-theory', 'modular-forms']"
1139325,Can this lattice be realized as an intermediate subgroups lattice?,Let $G$ be a finite group and $H$ a subgroup. Let $\mathcal{L}(H \subset G )$ be  the lattice of all the intermediate subgroups between $H$ and $G$. Let the lattice $\mathcal{L}$ as follows: Question: Can $\mathcal{L}$ be realized as an intermediate subgroups lattice? Remark : I've checked by GAP that there is no example for $[G:H]<32$.,"['gap', 'lattice-orders', 'finite-groups', 'group-theory']"
1139335,Proving the irreducibility of a specific family of polynomials,"I want to show that $f(x)=x^{4k} - 3x ^{3k} + 4x^{2k}-2x^k +1$ is irreducible in $\mathbb{Q}$ for all $k\in \mathbb{N}$. When $k=1$, it is easy to show; however I have trouble in proving this while $k\ge 2$. I have tried lots of irreducibility tests, but I have not found a way to prove this. Can anyone give me, at least, a hint?","['irreducible-polynomials', 'abstract-algebra']"
1139377,"Can I get some guidance on solving $\int_{-\infty}^{\infty} \frac{\sin^2(x)}{x^2} \, dx$?","I am trying to evaluate:
$$I = \int_{-\infty}^{\infty} \frac{\sin^2(x)}{x^2} \, dx.$$
Using a contour semi-circle (upper plane), I can get:
$$ \oint_{C} f(z) \,dz = \oint_{C} \frac{1 - e^{2iz}}{z^2} \, dz.$$
The whole issue is the $z^2$. I cannot use the residue theory, because it lies on the contour. I donât want a full solution. I really want to try on my own, I just need some guidance!","['residue-calculus', 'calculus', 'integration', 'analysis', 'complex-analysis']"
1139383,Tightness of probability measures,Prove: If there is a $\phi(X)\geq0$ such that $\phi(x)\rightarrow \infty$ for $|x|\rightarrow \infty$ and $\sup_n\int\phi(x)dF_n(x)<\infty$ Then $F_n$ is tight. The definition of tightness of probability measures: $F_n$ is called tight. If for every $\epsilon>0$ there is a compact set $K_{\epsilon}$ such that $\mu(K_{\epsilon})>1-\epsilon$ Can someone give me a tip?,"['probability-theory', 'probability-distributions', 'probability']"
1139391,Proving set of density points is an open set,"Let $A\subset\mathbb{R}$ measurable and denote the set of density points $$\tilde{A}:=\{x\in\mathbb{R}\mid \lim_{\epsilon\to 0}\frac{m([x-\epsilon,x+\epsilon]\cap A)}{2\epsilon}=1\}$$Porve/Dsiprove this set is open. I thought building a set $A$ which it's density points are a finite number of singletons (or countable) and then it'll contradict the claim above. My question is how can I build a set based on number of density points? More specific: Does exist a set $A\subset \mathbb{R}$ with finitely number of density points or s.t $|\tilde{A}|<\infty$?","['lebesgue-integral', 'measure-theory', 'lebesgue-measure', 'real-analysis']"
1139408,Prove that if $\lim_{n \rightarrow \infty}n(f(\frac{1}{n})-f(0))=L$ then $f'(0)=L$.,"$f$ is differentiable. Prove that if $\lim_{n \rightarrow \infty}n(f(\frac{1}{n})-f(0))=L$ then $f'(0)=L$. I tried L'Hopital: $\lim_{n \rightarrow \infty}n(f(\frac{1}{n})-f(0))=\lim_{n \rightarrow \infty} \frac {f(\frac{1}{n})-f(0)}{\frac{1}{n}}$, but it didn't get me far... Any assistance would be much appreciated!","['calculus', 'derivatives']"
