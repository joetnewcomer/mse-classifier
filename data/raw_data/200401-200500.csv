question_id,title,body,tags
3920843,The 'ratio' of a 2x2 matrix,"Define the 'ratio' of a 2x2 matrix $$A= \begin{pmatrix} a & b\\ c & d \end{pmatrix} $$ to be $\frac{b}{c}$ when $c\neq 0$ . Show that the ratio of $A^n$ is equal to the ratio of $A$ , when the ratio of $A^n$ is well-defined. My instinct is to go with a proof by induction, but I really can't see a way to prove this.","['matrices', 'linear-algebra']"
3920853,Simultaneous diagonalizability of infinitely many endomorphisms in infinite dimension,"Let $V$ be a vector space and let $(f_i)_{i \in I}$ be a family of endomorphisms of $V$ . Question. Suppose that each $f_i$ is diagonalizable and that $f_i$ commutes with $f_j$ for any two indices $i$ and $j$ .
Is the family $(f_i)_{i \in I}$ simultaneously diagonalizable? I’m using here the following notion of simultaneous diagonalizability. The family $(f_i)_{i \in I}$ is simultaneously diagonalizable if we have the decomposition $$
    V = \bigoplus_{(\lambda_i)_{i \in I}} \operatorname{Eig}( (f_i)_{i \in I}, (\lambda_i)_{i \in I} )
  $$ where $\operatorname{Eig}( (f_i)_{i \in I}, (\lambda_i)_{i \in I} ) = \{ v \in V \mid \text{$f_i(v) = \lambda_i v$ for every $i \in I$}\}$ is the common eigenspace of the family $(f_i)_{i \in I}$ for the eigenvalues $(\lambda_i)_{i \in I}$ .
Equivalently, $V$ admits a basis consisting of common eigenvectors of the $f_i$ . It is (well-)known that the the answer to the question is yes if $I$ is finite; $V$ is finite-dimensional; or more generally if the linear subspace of $\operatorname{End}(V)$ spanned by the $f_i$ is finite-dimensional. But I don’t know what happens in general if both $I$ is infinite and $V$ is infinite-dimensional.","['diagonalization', 'linear-algebra']"
3920948,Differentiable convex function that is not continuously differentiable,"Does there exist a convex function that is differentiable over an open convex set but not continuously differentiable there? Any differentiable function defined on an interval is continuously differentiable due to the monotonicity and Darboux property of its derivative. Therefore, the function, if exists, has to reside in a $2$ - or higher-dimensional space. In addition, it needs to be continuously differentiable along any straight line. Any comments or criticism will be appreciated. Thanks. Update : Indeed, there does not exist such a function. See [Corollary 25.5.1, Convex Analysis , Rockafellar 1970].","['real-analysis', 'multivariable-calculus', 'calculus', 'derivatives', 'convex-analysis']"
3920972,Why is there a condition on L'Hopital's Rule?,Why is the presence of an indeterminate form necessary for L'Hopital's rule to work? Why can't it work on functions not containing an indeterminate form? Is there an intuitive way to understand why this happens?,"['limits', 'calculus']"
3920993,Why is $x^4-3x^2+18$ irreducible over the $3$-adics?,"Let $f = x^4 - 3x^2 + 18 \in \mathbb{Q}_3[x]$ . Since there is an LMFDB page of an extension defined by this polynomial , I assume that $f$ is irreducible. Could you verify if this is true and also why that is (not) the case? It is not an Eisenstein polynomial (as $3^2$ divides $18$ , the constant coefficient of $f$ ). I also tried the substitution $y = x^2$ and asked myself if $g = y^2 - 3y + 18$ is irreducible. Its reduction mod $3$ is $y^2$ which is not irreducible, so I cannot say whether $g$ is irreducible or not.","['irreducible-polynomials', 'p-adic-number-theory', 'abstract-algebra']"
3921019,Limit of $\frac{1}{\sqrt[n] n}$,"I would like to show that the limit of the sequence $(\frac{1}{\sqrt[n] n})_{n=1}^{\infty}$ is equal to 1 using the definition of the limit of a sequence. (Another way to say this is that it converges to 1). Definition: A sequence $(a_n)_{n=1}^{\infty}$ converges to a real number A iff for each $\epsilon > 0$ there is a positive integer N such that for all $n \geq N$ we have $|a_n - A| < \epsilon$ . Edit: Here is my work. Let $\epsilon > 0$ . There exists $N$ such that for $n \geq N$ , $$|\frac{1}{\sqrt[n] n}-1| = |\frac{n^{\frac{n-1}{n}}}{n} - 1| = |\frac{n^{\frac{n-1}{n}} - n}{n}| = \frac{n-n^{\frac{n-1}{n}}}{n}$$ Here is where I am stuck.","['epsilon-delta', 'real-analysis', 'calculus', 'sequences-and-series', 'limits']"
3921115,"$ \bigcap\limits_{k \in \mathbb{N}} \bigcup\limits_{n \in \mathbb{N}} A_{n, k}$ prove the properties of injection.","For $n, k \in \mathbb{N}$ we describe $A_{n, k}$ as a set of all functions $f \in \mathbb{N}^\mathbb{N}$ , such that for for every function $f(n) = k$ . For each of sets determined below (A and B) decide which descriptions (from 1 to 6) can be applied and prove that. $$ (A) \bigcup\limits_{n \in \mathbb{N}} \bigcap\limits_{k \in \mathbb{N}} A_{n, k}$$ $$ (B) \bigcap\limits_{k \in \mathbb{N}} \bigcup\limits_{n \in \mathbb{N}} A_{n, k}$$ Descriptions: $\emptyset$ $\mathbb{N}^\mathbb{N}$ all functions $f \in \mathbb{N}^\mathbb{N}$ that are injective all functions $f \in \mathbb{N}^\mathbb{N}$ that are surjective all functions $f \in \mathbb{N}^\mathbb{N}$ that are constant none of those FIrst of all, as I understand, we can interpret the sets as: $$ (A) \bigcup\limits_{n \in \mathbb{N}} \bigcap\limits_{k \in \mathbb{N}} A_{n, k} = \exists n \forall k$$ $$ (B) \bigcap\limits_{k \in \mathbb{N}} \bigcup\limits_{n \in \mathbb{N}} A_{n, k} = \forall k \exists n$$ Descriptions with my thinking and answers: $\emptyset$ $\implies $ I think that it is $A$ because there are no $n$ (arguments of function) that would return all $y$ (possible values of function) $\mathbb{N}^\mathbb{N}$ $\implies $ none all functions $f \in \mathbb{N}^\mathbb{N}$ that are injective $\implies $ none all functions $f \in \mathbb{N}^\mathbb{N}$ that are surjective $\implies $ I am sure that it is $B$ because if for all $y$ (possible values of function) exists some $n$ (argument of function) that returns that value, then that is a surjection all functions $f \in \mathbb{N}^\mathbb{N}$ that are constant $\implies $ none none of those $\implies$ X The problem is that I need to prove that my answers are correct (if they are). I don't know how to do that but it seems pretty repetitive (I suppose it has to be done ""both ways"") I would be very grateful if  somebody could prove one of them so that I can try to do similarly all the others by myself.","['elementary-set-theory', 'functions']"
3921137,Max and min of sets,"For real numbers a,b, I define $\land$ and $\lor$ as: $$a \land b = \min \{a, b\} $$ $$a \lor b = \max \{a,b\} $$ Now I want to proof the the distributive properties: $$a \land (b \lor c) = (a \land b)\lor(a \land c)$$ $$a \lor (b \land c) = (a \lor b)\land(a \lor c)$$ I have done it already like this: First case: $a<b<c$ , then ... Second case: $a<c<b$ , then ... But this takes me ages, is there a short and neat way to prove this? Any hints or ideas would be very helpful. Thanks.",['elementary-set-theory']
3921145,if $f' = f - g$ and $g' = g - f$ and $f(0) = g(0) = 1$ find$ f$ and $g$,"If $f' = f - g$ and $g' = g - f$ and $f(0) = g(0) = 1$ find $ f$ and $g$ . To me, this seems to be a differential equation question. $$f''=f'-g'=f'-(g-f) \rightarrow f''-f'-f=-g$$ Is this the right idea?","['calculus', 'ordinary-differential-equations']"
3921166,Can this be proved using Combinatorics or generating functions?,"What is the proof for this identity? $\displaystyle\sum_{r=0}^{n}\binom{n}{r}\binom{m+r}{n}\ = \displaystyle\sum_{r=0}^{n}\binom{n}{r}\binom{m}{r}2^{r}$ I thought of changing $r$ to $n-r$ on left and right both. Then, I thought of building a set with atleast $n$ elements and atmost $2n$ elements with atmost $n$ elements from $m$ element set, and we can do this on LHS by choosing $n-r$ elements from n and out of remaining $r+m$ elements we can choose n more elements. On RHS, we can again choose $n-r$ elements from $n$ and $r$ elements from $m$ , then remaining $r$ elements from n element set have 2 choices each. But I think it has a flaw. Can someone please help? If my proof is not correct, please suggest a combinatorial or a generating function proof.","['summation', 'combinatorial-proofs', 'binomial-coefficients', 'combinatorics', 'generating-functions']"
3921176,i need to proove that An∪B→A∪B,"If $A_n\rightarrow A$ , show that $(A_n \cup B) \rightarrow (A \cup B)$ . My attempted solution used $\lim \inf(A_n \cup B)$ and lim sup but I'm not sure how to proceed.","['probability-theory', 'probability']"
3921257,Least number of scalene triangles formed from $13$ points in a plane,"Given $13$ points in a plane with no three on a line, prove that there are at least $130$ scalene triangles formed from the points. I thought the highest number of non-scalene triangles with $13$ points would happen in a $13$ side polygon, so I tried to calculate this value, and I got $78$ so I subtracted it from the number of triangles formable by $13$ points, $13 \choose 3$ and then I got $208$ . I know it's wrong but I can't think of anything else. Any help would be greatly appreciated. Thanks!","['combinatorial-geometry', 'combinatorics', 'extremal-combinatorics']"
3921376,Does being well approximated by a polynomial characterize higher differentiability?,"Suppose $f:\mathbb R\to \mathbb R$ admits a polynomial $\sum_{k=0}^n\lambda_k(x-a)^k$ of degree $\leq n$ satisfying $f(x)-\sum_{k=0}^n\lambda_k(x-a)^k\in \mathrm o(|x-a|^n)$ as $x\to a$ . Then dividing by powers of $(x-a)$ shows $$\begin{aligned}\lambda_0 & =\lim_{x\to a}fx, \\ \lambda_1 & =\lim_{x\to a}\tfrac{fx-\lambda_0}{x-a}, \\ \lambda _2 & =\lim_{x\to a}\tfrac{fx-fa-\lambda_1(x-a)}{(x-a)^2}=\lim_{x\to a}\tfrac{\tfrac{fx-fa}{x-a}-\lambda_1}{x-a}, \\  & \vdots \\ \lambda_n & = \lim_{x\to a}\tfrac{fx-\sum_{k=0}^{n-1}\lambda_k(x-a)^k}{(x-a)^n}. \end{aligned}$$ Thus the asymptotic condition determines the polynomial, so it is unique when it exists. If $f$ is furthermore continuous at $x=a$ then $\lambda_0=fa$ whence $\lambda_1=f^\prime(a)$ . If $f$ is $n$ -times differentiable at $x=a$ then Peano's form of Taylor's theorem tells us $R^n_af\in \mathrm o(|x-a|^n)$ as $x\to a$ . Here $R^n_af(x)=f(x)-j^n_af(x)$ and $$j^n_af(x)=\sum_{k=0}^n\tfrac 1{k!}f^{(k)}(a)(x-a)^k$$ is the $n^\text{th}$ order Taylor series of $f$ about $x=a$ . By uniqueness we therefore have $\lambda_k=\tfrac 1{k!}f^{(k)}(a)$ . For instance taking $k=0,1,2$ gives $$\tfrac 12f^{(2)}(a)=\lambda _2  =\lim_{x\to a}\tfrac{fx-fa-f^\prime(a)(x-a)}{(x-a)^2}=\lim_{x\to a}\tfrac{\tfrac{fx-fa}{x-a}-f^\prime(a)}{x-a}.$$ I am interested in the converse: are continuous maps which are well approximated by a polynomial of degree $\leq n$ necessarily $n$ -times differentiable? Question. Suppose $f$ is continuous and admits a polynomial $\sum_{k=0}^n\lambda_k(x-a)^k$ of degree $\leq n$ satisfying $f(x)-\sum_{k=0}^n\lambda_k(x-a)^k\in \mathrm o(|x-a|^n)$ as $x\to a$ . Does it follow that $f$ is $n$ -times differentiable at $x=a$ , with $\lambda_k=\tfrac 1{k!}f^{(k)}(a)$ ? Already for $k=2$ this amounts to the assertion $$\tfrac 12f^{(2)}(a)=\lambda _2  =\lim_{x\to a}\tfrac{fx-fa-f^\prime(a)(x-a)}{(x-a)^2}=\lim_{x\to a}\tfrac{\tfrac{fx-fa}{x-a}-f^\prime(a)}{x-a}.$$ This is not obvious at all to me.","['limits', 'calculus', 'derivatives', 'taylor-expansion']"
3921394,Independence of the statement that a union of $<\mathfrak{c}$ many measure zero sets has measure zero,I read that that the statement that a union of fewer than continuum many measure zero sets has measure zero is independent of $\sf{ZFC}$ . Is there a standard reference to this result?,"['measure-theory', 'set-theory', 'reference-request']"
3921505,"Without solving explicitly show that for the IVP $x'=x^{3}-x,x(0)=0.5$ the solution converges to $0$ for $t\rightarrow\infty$","I am trying to determine whether the solution to the following IVP converges to $0$ for $t\rightarrow\infty$ . The IVP is $x'(t)=x^{3}-x=f(x)$ , $x(0)=\frac{1}{2}$ . By looking at the ""extended phase portrait"" I would infer  that this is indeed the case. However I would like to have solid argument. I would argue as following: Let $x(t)$ be the solution to the above IVP. For $x\in(0,1)$ $x^{3}-x<0$ . Therefore $x'(t)<0$ and $x(t)$ is decreasing. Since $\tilde{x}(t)=0$ is a (equilibrium) solution $x(t)>0$ , which follows from the uniqueness theorem. Hence, $0$ is a lower bound. Because $x(t)$ is bounded below and monotonically decreasing $lim_{t\rightarrow\infty}x(t)$ exists and $lim_{t\rightarrow\infty}x(t)\geq 0$ . Here is the part were I am stuck. I have two approaches. One works and the other doesn't I think. What I want to show is that $\lim_{t\rightarrow\infty}x'(t)=0$ . Because then $0=\lim_{t\rightarrow\infty}x'(t)=lim_{t\rightarrow\infty}f(x(t))=f(lim_{t\rightarrow\infty}x(t))=f(c)=c^{3}-c\iff c=0,c=1,c=-1$ . $c=-1$ is not possible, because the $x(t)$ would intersect $\tilde{x}(t)=0$ , hence by the uniqueness it follows that $x(t)=0$ and thus $0>x'{t}=0$ .
If $c=1$ , then we can find $t_{1}\in\mathbb{R}_{>0}$ such that $|x(t_{1})-1|<\frac{1}{2}\iff x(0)=\frac{1}{2}<x(t_{1})$ . Hence, by the mean value theorem it follow that there is $\eta\in(0,t_{1})$ such that $f'(\eta)=\frac{x(t_{1})-x(0)}{t_{0}-0}>0$ , but $f'(\eta)<0$ . Therefore $c=0$ . Approach 1. Here I am stuck: From the inequality $x'(t)<0$ it follows that $0\geq lim_{t\rightarrow\infty}x'(t)$ . Since $x(t)$ is a solution and because of the continuity of the r.h.s. of the IVP it follows that $0\geq lim_{t\rightarrow\infty}x'(t)=lim_{t\rightarrow\infty}f(x(t))=f(lim_{t\rightarrow\infty}x(t))=f(c)=c^{3}-c$ . $(*)$ Therefore $c\in[0,1]$ or $c\in(-\infty,-1]$ . If the latter is the case then $x(t)$ would intersect with at least one equilibrium solution. Hence, this is not possible. Therefore $c\in[0,1]$ . I think I can rule out any $c\in[\frac{1}{2},1]$ , since then by the mean value theorem. $f'(\eta)>0$ , which is not possible. Can I somehow show that $f(c)=c^{3}-c\geq 0$ . Then it would follow that $\lim_{\rightarrow\infty}x'(t)=0$ , wouldn't it? But isn't it the case that $f(c)\leq 0$ , since $c\in[0,1]$ in equation $(*)$ ? Therefore we would have $0\leq f(c)\leq 0\iff f(c)=0$ . Hence, $\lim_{t\rightarrow\infty}x'(t)=f(c)=0$ Is there a shorter way? Approach 2: We know that $\lim_{t\rightarrow\infty}x(t)=c$ . Then $\lim_{t\rightarrow\infty}x'(t)=\lim_{t\rightarrow\infty}\lim_{h\rightarrow 0}\frac{x(t+h)-x(t)}{h}=\lim_{h\rightarrow 0}\lim_{t\rightarrow\infty}\frac{x(t+h)-x(t)}{h}=\lim_{h\rightarrow 0}\frac{c-c}{h}=0$ .
I think all requirements for changing the order of the limits to be legal are met...or at least I hope so. I would really appreciate any help. Thank you very much in advance!","['initial-value-problems', 'ordinary-differential-equations']"
3921507,Why can you check closedness on the fibers? (Hartshorne's proof of Bertini's theorem),"In Hartshorne's proof of Bertini's theorem, given a linear system $|H|$ , he defines the locus of ""bad"" hyperplanes $B_x$ for each point $x\in X\subset \Bbb P^n$ a projective variety, shows that this is a proper linear subset of $\{x\}\times |H|$ , defines $B$ to be the union of all pairs $(x,H)$ so that $H\in B_x$ , and then claims that ""clearly $B$ is the set of closed points of a closed subset of $X\times|H|$ "". I don't understand this. Clearly the statement ""if a subset has proper closed intersection with all fibers of a map over closed points, then it's a proper closed subset"" is false - consider the inclusion of a copy of $(\Bbb P^1\setminus\{0\})\times\{p\} \to \Bbb P^1\times\Bbb P^1$ followed by a projection. How can I rigorously see Hartshorne's claim?",['algebraic-geometry']
3921513,Every measurable set in $X \times Y$ is contained in a measurable rectangle,"If $X$ and $Y$ are any two sets (not necessarily subsets of the
same space), the Cartesian product $X \times Y$ is the set of all ordered
pairs $(x,y)$ , where $x \in X$ and $y \in Y$ . Thus, for instance, if $A \subset X$ and $B \subset Y$ , we shall call the set $E = A \times B$ (a subset of $X \times Y$ ) a rectangle
and we shall refer to the component sets $A$ and $B$ as its sides. In our context the word ""class"" should be understood as a set of sets. So the class of measurable rectangles refers to the set of measurable rectangles. So I want to use the fact that a rectangle $A \times B$ in the Cartesian product of two measurable spaces $(X, S)$ and $(Y, T)$ , (where $S$ and $T$ are $\sigma$ -rings of subsets of $X$ and $Y$ respectively), is measurable if $ A \in S $ and $ B \in T $ . I am reading the Measure Theory book by Paul Halmos, I have found this.
Exercise (6) Section 33. If $(X,S)$ and $(Y,T)$ are measurable spaces, then every  measurable set in $X \times Y$ is contained in a measurable rectangle. My idea is the following: the class of all those sets which way be covered by a measurable rectangle is a $\sigma$ -Ring. I think this class contains every measurable set of $ X\times Y$ , on the other hand if I test that it is a $ \sigma $ -Ring I have finished",['measure-theory']
3921542,Is a finite tiling of 45-45-90 triangles uniquely determined from the resulting union (up to trivial flips)?,"Suppose I take a union of nonoverlapping $1-1-\sqrt{2}$ triangles in the plane: The same shape can be tiled in another way, by flipping two triangles joined together into a square: In general, are these the only such decompositions possible? That is, given two planar configurations of finitely many nonoverlapping $1-1-\sqrt{2}$ triangles whose unions are the same, are they necessarily related by some number of ""square flipping"" operations? In the infinite case, this is not true, as seen by the following tilings of an infinite quadrant:","['triangles', 'geometry', 'tiling', 'plane-geometry']"
3921618,Show that $\lim_{n \to \infty} \left(1+\frac{a_n}{n}\right)^n= e^a$ when $a_n \to a$,"I have seen a proof that shows $$\lim_{n\to\infty} \left(1+\frac{x}{n}\right)^n = e^x$$ by looking at the Taylor series expansion of $\ln(1+x)$ at $x=0$ . To prove a theorem, my textbook uses the fact $$\lim_{n \to \infty} \left(1+\frac{a_n}{n}\right)^n = e^a$$ when $a_n \to a$ . How can I prove this?","['limits', 'exponential-function']"
3921626,Rewriting $\max \log \det (I+ X + Y + Y^T)$ as max-det problem,"The following optimization is convex: \begin{align}
\max_{X\succ0,Y} &\ \ \log \det (I + X +Y + Y^T)\\
& \text{s.t.} \begin{pmatrix} X& Y \\ Y^T & Z \end{pmatrix}\succeq 0, \ \ \ \mathbf{Tr}(X)\le P
\end{align} where $Z\succ0$ and $P>0$ are given. My question is whether the decision variable $Y$ can be transformed or replaced with a be positive semi-definite decision variable. My motivation is to write the optimization as a standard max-det problem or in a nicer form in order to show that the maximizer is unique.","['convex-optimization', 'optimization', 'linear-algebra', 'control-theory']"
3921645,complex numbers structure of Chern classes,I have started to read on Chern classes. I cannot quite yet see where the complex numbers and their properties come in as we define Chern classes and other properties. I do see it in later theorems and computation. It seems we could have defined projectivization for any vector bundle for example or even Chern classes. Am I missing something? Where and when do complex field properties really come in? I am reading Bott and Tu book differential forms in Algebraic Topology. There the construction is based on line bundles and then projectivization and at least in initial steps I do not see any complex field requirement in definitions or proofs. See pp 267 and 270. https://www.maths.ed.ac.uk/~v1ranick/papers/botttu.pdf,"['complex-analysis', 'complex-geometry', 'algebraic-geometry', 'algebraic-topology']"
3921658,Proving that $|\sin(z)|^2 = \sin(x)^2+\sinh(y)^2$,"Goal: Prove $|\sin(z)|^2 = \sin(x)^2+\sinh(y)^2$ I have \begin{align*}
\sin(x+iy)
&=\sin(x)\cos(iy)+\cos(x)\sin(iy)\\
&=\sin(x)\cosh(y)+i\cos(x)\sinh(y)\\
|\sin(z)|^2
&=\sin(x)^2 \cosh(x)^2+\cos(x)^2\sinh(y)^2
\end{align*} How do I proceed?","['trigonometry', 'complex-numbers', 'hyperbolic-functions']"
3921708,Why are the graph of $f(x) = (x^2)^\frac{1}{6}$ and the graph of $f(x) = x^\frac{1}{3}$ not the same?,"Why is the graph of $f(x) = (x^2)^\frac{1}{6}$ not the same graph as $f(x) = x^\frac{1}{3}$ ? Shouldn't they be the same because when you apply the exponent rules to the first equation, you get the same result as the second equation? By the way, I am an Algebra 2 student in High School.","['exponentiation', 'algebra-precalculus', 'functions', 'graphing-functions']"
3921761,Show a function such that $f'(c)\neq \dfrac{f(b)-f(a)}{b-a}$ for any $a<b$,"Could you help me with the following please: Give an example of a differentiable function $f:\mathbb{R} \rightarrow \mathbb{R}$ that has a point $c$ such that $f'(c)$ is not equal to the difference quotient $\dfrac{f(b)-f(a)}{b-a}$ for any $a<b$ . Why does this not contradict the mean value theorem? In a graphical way what can be seen is that this occurs when the second derivative of $ f $ is 0, but trying to find this function, I have considered a polynomial with this property, but I cannot see that it fulfills this characteristic. One attempt has been to consider the $ f(x)=x^3+3x+2 $ , but it failed to conclude that this is an example of what the exercise asks of us. And well, I think this does not contradict the MVT for the domain of said function.","['derivatives', 'real-analysis']"
3921790,Solving $|2x-3|+7 \le 3x-3|x-7|$,"I was trying to solve this inequality with two absolute values: $$|2x-3|+7 \le 3x-3|x-7|$$ I've got an empty set of solutions, but it's not correct. How I've tried to solve it: I've put in a number line the signs (+ or -) to see what happens in three different cases: first case:
if $x \le 3/2$ , then both of them are negative, so I've rewritten the inequality (by changing the signs) as "" $-(2x-3)+7 \le 3x+3x-21$ "". if $3/2<x<7$ , then the first absolute value is positive and the other one is negative "" $2x-3+7 \le 3x+3x-21$ "". if $x \ge 7$ , then both of them are positive, so I simply canceled out the absolute values. Now, I've found the solutions for each system of inequality, by putting them in a number line. first system of inequalities: $x<3/2, x<31/8$ . the set of solutions is "" $x<3/2$ "". second system of inequalities: $3/2<x<7, x<25/4$ . the set of solutions is "" $3/2<x<25/4$ "". third system of inequalities: $x>7, x<17/2$ . by putting on another number line these sets, the solution is an empty set of solution. -- edit: Okay, thanks to the comment discussion, I've solved it. It was an error (because of distraction), the set of solution is "" $25/4<x<17/2$ ""(not strict) the first system of inequalities has an empty set of solution. I think it is correct. let me know if it's an error. -- If you know a fastest method to solve inequalities like this, let me know.","['algebra-precalculus', 'absolute-value', 'inequality']"
3921807,How to show that explicit generator of the fundamental group is the one I found?,"I am working on an exercise: Let $X$ be $\mathbb S^2$ with a straight line segment having the north pole and the south pole as its end points. Compute the fundamental group of $X$ (with the north pole as a base point) of $X$ and find generators. For the first part, I was able to find that the fundamental group of $X$ is isomorphic to $\mathbb Z$ using Van Campen theorem, and intuitively, I think the generator of the group should be a path that starts from the north pole, goes down the straight line segment, and comes back to the north pole via the path in the sphere, as any path that does not go through the straight line segment would be null homotopic. However, I am not sure how to rigorously justify that the path I mentioned above is the generator for the fundamental group. P.S. Also, during my proof for the first part, there was a part where I needed to show that $X \setminus \{ (1, 0, 0) \} \simeq \mathbb S^1$ , and I feel like I did not show it rigorously. Is there a way to show this rigorously as well using deformation retraction?","['general-topology', 'fundamental-groups', 'algebraic-topology', 'spheres']"
3921816,Constant derivative of a function implies is an affine map.,"I am trying to prove the next: Let $f :\Omega\subset\mathbb{R}^n\rightarrow\mathbb{R}^m$ be differentiable, where $\Omega$ is an open
connected subset of $\mathbb{R}^n$ . Suppose $D_{f}(x)$ is constant on $\Omega$ , that is, $D_{f}(x) = T$ for all $x\in\Omega.$ Show that $f$ is the restriction to $\Omega$ of an affine transformation. I was trying to prove that the set $A=\{x\in\Omega: f(x) = f(a) + T(x-a)\},$ where $a\in\Omega$ is fixed, is an open and closed subset of $\mathbb{R}^n,$ then for connected of $\Omega$ implies $\Omega = A$ and the proposition is true, but it seems quite hard to prove that; I was thinking about the definition of differentaiblity of $f$ in $a,$ however the best that we get of such definition is an inequality. I saw a proof of this using gradient theorem but I do not know yet integration; this proposition appears in the section of differential calculus only, hence it must be possible prove it without integration. Any kind of help is thanked in advanced.",['multivariable-calculus']
3921862,"Differentiating and integrating $r(t)=\langle 8t^4+\frac{5}{t} ,\sec^2(\frac{t\pi}{6},3e^t-2t\ln(t))\rangle $","I am asked to differentiate and integrate $$r(t)=\langle 8t^4+\frac{5}{t} ,\sec^2(\frac{t\pi}{6},3e^t-2t\ln(t))\rangle $$ Am I supposed to differentiate/integrate each term independently? For example, I have that $r'(t)$ of $-8t^4 + 5/t$ is $-32t^3 - 5/x^2$ .","['multivariable-calculus', 'linear-algebra']"
3921886,A question on floor function.,"Prove that for $n \in N$ , $[\sqrt{n} + \frac{1}{2} ] = [\sqrt{n-\frac{3}{4}} + \frac{1}{2}]$ where [.] is the greatest integer function. My attempt: k < $\sqrt{n} + \frac{1}{2} $ < k+1 .
Obviously, $\sqrt{n-\frac{3}{4}} + \frac{1}{2}$ < $\sqrt{n} + \frac{1}{2} $ , so it would suffice to show that $\sqrt{n-\frac{3}{4}} + \frac{1}{2}$ > k , but it turns out that the inequlity is very weak so i am not able to prove it. Is there any way to do this using induction? Or am i trying the right thing? Any help is appreciated , thanks!","['inequality', 'ceiling-and-floor-functions', 'number-theory', 'induction', 'radicals']"
3921965,prove MLE don't exist,"so the pdf is $$f(x)=\frac{1}{2}\frac{1}{\sqrt{2\pi}}\exp^{-\frac{x^2}{2}}+\frac{1}{2}\frac{1}{\sqrt{2\pi}\sigma}\exp^{-\frac{(x-\mu)^2}{2\sigma^2}}
$$ $\mu$ and $\sigma$ are unknown,prove that they don't have MLE it is a gaussian mixture model I guess? And I know there are no analytic solve for the derivative of log likehood function. But the text seems to mean that there are no numerical solve either. And I really don't know any methodology for prove MLE don't exist","['statistics', 'maximum-likelihood']"
3921967,Change of variables when integrating over matrices,"I have the following integral \begin{align}
    \int f \left(U(X)\right) g \left(U(X) \right) dX
\end{align} Where, $X,U(X) \in \mathbb{R}^{n \times d}$ ; $f,g: \mathbb{R}^{n \times d} \xrightarrow{} \mathbb{R}$ . $f$ is a PDF and $g(X)$ is a positive function for every $X$ . The connection between $X$ and $U(X)$ is given as follow: \begin{equation}
\label{Eq: relation}
    U\left( X \right)^{T} U\left( X \right)
    =X^{T} X + B
\end{equation} I would like to change the integral such that the integration variable will be $V=U(X)$ . It should have the general form of \begin{align}
    \int f \left(U(X)\right) g \left(U(X) \right) dX
    &=\int f \left(V\right) g \left(V \right) 
    \det (J\left(X,V \right)) dV
\end{align} $J\left(X,V \right)$ is some sort of Jacobian matrix, but I can't figure out what should it be and how to calculate its determinant. Any help will be appreciated.","['integration', 'change-of-variable', 'matrices']"
3921973,Solve: $3\sin{2x}+4\cos{2x}-2\cos{x}+6\sin{x}-6=0$,"Solve: $3\sin{2x}+4\cos{2x}-2\cos{x}+6\sin{x}-6=0$ My Try $6\sin{x}\cos{x}+4(\cos^2{x}-\sin^2{x})-2\cos{x}+6\sin{x}-6=0$ I have expanded the equation, But I cannot proceed further, Any hint would be appreciated. Thank you!",['trigonometry']
3921974,Another limit points task.,"Let $x_n, y_n$ -- two numerical sequences with pairwise distinct terms (i.e $x_i \neq x_j$ and $y_i \neq y_j$ for all $i \neq j$ ). We decided that $\lim_{n \to \infty} (x_ny_n) = \lim_{n \to \infty} (x_n + y_n) = 5$ . The question is to find all limit points of the set $A$ , where: $A = \{e^{x_n} + e^{y_n} \ | \ n \in \mathbb{N}\}$ . Definition of limit point which I know: $a \in X, A \subset X$ is limit point if for every $\varepsilon > 0$ punctured ball $B_{\varepsilon}(a)$ contains an element from $A$ . In our case $X = \mathbb{R}$ . I found that: $x = \lim_{n \to \infty} (x_n) = \frac{5 + \sqrt{5}}{2}$ $y =\lim_{n \to \infty} (y_n) = \frac{5 - \sqrt{5}}{2}$ With solving a system $xy=5$ $x+y=5$ . (We've got case with swapped values of x and y, but it's easy to show that we can do the same for them if we find solution). My idea is to find $z = \lim z_n$ , where $z_n = e^{x_n} + e^{y_n}$ . And then we can say that limit point is only $z$ (from the limit defenition). But I've got some troubles with finding this limit.","['limits', 'metric-spaces']"
3921980,Circle intersections algorithm with $O((n+s)\log(n))$ complexity,"I have found a few different posts about finding the intersections of circles in $O((n+s)\log(n))$ time with $n$ the amount of circles and $s$ the amount of intersections. The problem is that none of  the answers are giving a clear and steady answer. I found this answer that looked very interesting, but I still have my doubts about it. Snetfel explained that we can use a sweep-line algorithm. Here is a brief summary: We make a priority queue containing all $x$ points of left $(x-r)$ and right $ (x+r)$ extremas of the circles. We
then use a binary tree to respresent the sweep-line status. Whenever we encounter a left extrema of a circle, we add it to the status and check for intersections with every other active circle in the status. Whenever we encounter a right extrema of a circle, we remove it from the status. Here you can find a video I made so you can have a better understanding. But does this method do the job in $O((n+s)\log(n))$ time as we are still checking each added circle to all other circles in the status? I tried another method which failed miserably. My failed attempt What I tried is the following. We again make a priority queue containing all $x$ points of left $(x-r)$ and right $(x+r)$ extremas of the circles. Start of circle $c$ Insert the circle with its center y value into a binary tree. (so you sort the binary tree by its $y$ value) Check for intersection between circle $c$ and its predecessor. Check for intersection between circle $c$ and its successor. End of circle $c$ Check for intersection between the predecessor and successor of circle $c$ . Remove the circle from the binary tree. But I noticed that this doesn't find all intersection points on a circle. For example, a circle with a high $y$ value and a huge radius, will not be compared to a circle with a very low $y$ value, eventhough they have an intersection. Here you can find a sketch of my idea. I found on different sources online that you can divide the circle in two semicircles. But by what value do you key your tree? How do you sort it so you can find the right neighbours?","['computational-complexity', 'geometry']"
3921990,Holomorphic differential on $y^3=x^5-1$,"I'm trying to study the canonical map $\phi_K$ for the algebraic curve $\mathcal{C}:y^3=x^5-1$ and to do this I need to find a basis for $\Omega^1(\tilde{\mathcal{C}})$ where $\tilde{\mathcal{C}}$ is the nonsingular model (the curve is singular at $[0:0:1]$ ). I have found that $div(dx)=\sum_{k=0}^4[1:\xi_5^k:0]-2[0:1:0]$ and that $div(\frac{dx}{x^5-1})=3[0:1:0]$ . Now, I am stuck at this point. How can I find other differentials? Are they correct? I have tried to solve this looking on Miranda's book and there were informations about divisor on nonsingular curves or curve with nodes.",['algebraic-geometry']
3922017,Is the union of partially ordered sets also partially ordered?,"I am in the process of doing a proof exercise for showing that a function $f : L_1 \to L_2$ between partially ordered sets $L_1 = (L_1, \sqsubseteq_1)$ and $L_1 = (L_1, \sqsubseteq_2)$ is monotone (or isotone or order-preserving ) if $\forall l, l^\prime \in L_1 : l \sqsubseteq_1 l^\prime \Rightarrow f(l) \sqsubseteq_2 f(l^\prime)$ . I want to use the idea that the union of partially ordered sets also partially ordered; however, I'm unsure if this is even true. Is it true that the union of partially ordered sets also partially ordered?","['elementary-set-theory', 'order-theory', 'monotone-functions', 'relations']"
3922056,Finding the structure of a group without using sylows theorem.,"If $ |G|=pq $ and $p $ doesnt divide $(q-1)$ and $p <q$ then $G$ is cyclic. My proof stands as this .I have used the fact that $(i)$ If $|G|=pq$ then I showed that there will only be one element of order $p$ and one element of order $q$ . My approach in proving this part has been to show that if there are two elements of order $p$ say $x_1$ and $x_2$ , then say $H_1$ is a group of order $p$ generated by $x_1$ and $H_2$ is a group of order $p$ generated by $x_2$ .We assume that the intersection is {e} if not then we can get $H_1$ = $H_2$ (by property of subgroup). Proving that the elements are distinct . We assume that the elements $(x_1)^{i}.(x_2)^j$ are not distinct then $(x_1)^{i}.(x_2)^j =(x_1)^{i'}(x_2)^{j'}$ .From here we can arrive at a contradiction as $H_1 \cap H_2 =e$ .So if there are $p^2$ elements then we can arrive at a contradiction as $p$ and $q$ are both primes. Similar results will hold in the case of $q$ . $(ii)$ Now  there is only one subgroup of order $p$ and one subgroup of order $q$ so they are both normal $(iii)$ let $H$ and $K$ be two subgroups of order $p$ and order $q$ .Then we know that $H \cap K={e}$ . $H$ and $K$ are both normal .Then I showed that $x^{-1}y^{-1}xy \in H \cap K$ and $xy=yx$ . So the order of the element $xy$ is $pq$ .Where am I going wrong in my proof and since I have not used the fact that $p $ doesnot $q-1$ .","['group-theory', 'abstract-algebra', 'finite-groups']"
3922122,consistency of MLE estimator example,"Given the density function $f(x;\theta)=\theta x^{\theta -1}$ with $\theta \gt 0$ and $x \in (0,1)$ , once found the MLE estimator $\hat{\theta}=\frac{-n}{\sum{\log{X_i}}}$ i want to show the consistency of such an estimator. I was suggested to apply the strong law of large numbers, although i am not sure how. Should I first obtain the expected value of the random variable $\log(X_i)$ and then apply the SLLN on them or is there another way?",['statistics']
3922138,Why is this a proof for Brouwer's fixed point theorem,"our teacher said that we can prove the Brouwer's fixed point theorem using the index $n(f\circ \gamma_r,0)$ where $\gamma_r (t)=re ^{it}$ , but I don't understand how come any help would be a lot appreciated.Here's what he's done Let $D$ the closed unit disk. $f : D\rightarrow D$ a continuous function. $f$ has a fixed point in $D$ . So we have : $n(f\circ \gamma_0,0) = 0 $ if $f$ has no fixed point in $D$ , we can show that : The image of $\partial D$ by $1+\frac{f}{g}$ is in the open half plane { $z=x+iy|x>0$ }, where $g:D\rightarrow D$ s.t $z \mapsto -z.\;\;$ (1) We can conclude that : $n(f\circ \gamma_1,0) = n(g \circ \gamma_1,0) = 1.\;\;$ (2) Hence we have a contradiction. I don't see exactly why (1) & (2) are true and what gives us the contradiction.Thanks in advance for your help.","['complex-analysis', 'proof-explanation', 'fixed-point-theorems']"
3922161,Analytic continuation and singularities,"Suppose that $z\in\mathbb{C}$ and $f$ is a holomorphism on $U$ such that there is no holomorphism $g$ extending $f$ on $V\supseteq U$ such that $z\in V$ . Is it possible for there to be such a $g$ and a holomorphism $h$ on $W$ with $V\cap W\neq\emptyset$ such that $g|_{V\cap W}=h|_{V\cap W}$ with $z\in W$ ? That is, are singularities preserved by analytic continuation?","['complex-analysis', 'singularity', 'analytic-continuation']"
3922204,"We have $AB = BC$, $AC = CD$, $\angle ACD = 90^\circ$. If the radius of the circle is '$r$' , find $BC$ in terms of $r$ .","We have $AB = BC$ , $AC = CD$ , $\angle ACD = 90^\circ$ . If the radius of the circle is ' $r$ ' , find $BC$ in terms of $r$ . What I Tried : Here is a picture :- Let $AC = CD = x$ . As $\angle ACD = 90^\circ$ , we have $AD$ the diameter of the circle, so $AD = 2r$ .
From here, using Pythagorean Theorem :- $$2x^2 = 4r^2$$ $$\rightarrow x = r\sqrt{2}$$ We have the green angles to be $45^\circ$ , now as $ADCB$ is cyclic, $\angle ABC = 135^\circ$ and each of the brown angles are $22.5^\circ$ . So we can use :- $$\frac{a}{\sin A} = \frac{b}{\sin B}$$ $$\rightarrow a \div \frac{\sqrt{2 - \sqrt{2}}}{2} = r\sqrt{2} * \frac{2}{\sqrt{2}}$$ $$\rightarrow \frac{2a}{\sqrt{2 - \sqrt{2}}} = 2r$$ $$BC = a = r\sqrt{2 - \sqrt{2}}$$ However, the answer to my question is given as $r\sqrt{\sqrt{2}}$ , so where did I go wrong?","['problem-solving', 'trigonometry', 'circles', 'geometry']"
3922251,What is a manifold on a Euclidean space?,"In this semester I study differential geometry and in this chapter we want to define what is a surface. In order to do that we first define what a manifold is on a Euclidean space, not generally what is a manifold, and Euclidean space I mean $(\mathbb{R}^{n},\left \| \cdot  \right \|)$ . That been said, if someone who doesn't study math ask you ""what this a manifold?"" how would you answer, in simple terms (as Feynman says). Can we just say it's a homomorphic function from open sets to open sets ? Older posts had been made on this topic (but I don't think they answer well  my question, in my option) and have already been answered if there isn't  anything new to add  I will delete this.",['differential-geometry']
3922274,Does almost sure convergence and $L^1$-convergence imply almost sure convergence of the conditional expectation?,"Question. Let $ X_{n}, X  $ be random variables on some probability space $ ( \Omega, \mathcal{F},\mathbb{P} ) $ and let $ \mathcal{G} \subset \mathcal{F} $ be a sub- $\sigma$ -algebra. Moreover suppose that $ X_{n } \to X $ a.s. and in $ \mathrm{L}^{ 1 } ( \Omega, \mathcal{F}, \mathbb{P}) $ . Does this already imply that $ \mathbb{ E}  ( X_{ n } | \mathcal{G} ) \to \mathbb{ E}  ( X | \mathcal{G} ) $ a.s.? We know that the $ \mathrm{L}^{1} $ -convergence implies that $\mathbb{ E}  ( X_{ n } | \mathcal{G} ) \to \mathbb{ E}  ( X | \mathcal{G} ) $ in $\mathrm{L}^{ 1 } $ . However, we can in general only expect a subsequence to converge a.s. This can be seen by looking at $\mathcal{ G } = \mathcal{ F } $ and taking the usual counterexample that $ \mathrm{L}^{ 1 } $ convergence does not always imply a.s. convergence.
But what happens if we additionally assume the a.s. convergence of the original sequence?","['conditional-expectation', 'convergence-divergence', 'probability-theory', 'random-variables']"
3922289,Show that $F$ is a monotone function,"I am currently studying the textbook Principles of Program Analysis by Flemming Nielson, Hanne R. Nielson, and Chris Hankin . Chapter 1.3 Data Flow Analysis says the following: The least solution. The above system of equations defines the twelve sets $$\text{RD}_\text{entry}(1), \dots, \text{RD}_{\text{exit}}(6)$$ in terms of each other. Writing $\overrightarrow{RD}$ for this twelve-tuple of sets we can regard the equation system as defining a function $F$ and demanding that: $$\overrightarrow{RD} = F(\overrightarrow{RD})$$ To be more specific we can write $$F(\overrightarrow{RD}) (F_\text{entry}(1)(\overrightarrow{RD}), F_\text{exit}(1)(\overrightarrow{RD}), \dots, F_\text{entry}(6)(\overrightarrow{RD}), F_\text{exit}(6)(\overrightarrow{RD}))$$ where e.g.: $$F_\text{entry}(3)(\dots, \overrightarrow{RD}_\text{exit}(2), \dots, \overrightarrow{RD}_\text{exit}(5), \dots) = \overrightarrow{RD}_\text{exit}(2) \cup \overrightarrow{RD}_\text{exit}(5)$$ It should be clear that $F$ operates over twelve-tuples of sets of pairs of variables and labels; this can be written as $F : (\mathcal{P}(\mathbf{\text{Var}_\star \times \mathbf{\text{Lab}_\star}))}^{12} \to (\mathcal{P}(\mathbf{\text{Var}_\star \times \mathbf{\text{Lab}_\star}))}^{12}$ where it might be natural to take $\mathbf{\text{Var}_\star} = \mathbf{\text{Var}}$ and $\mathbf{\text{Lab}_\star} = \mathbf{\text{Lab}}$ . However, it will simplify the presentation in this chapter to let $\mathbf{\text{Var}_\star}$ be a finite subset of $\mathbf{\text{Var}}$ that contains the variables occurring in the program $\mathbf{S_\star}$ of interest and similarly for $\mathbf{\text{Lab}_\star}$ . So for the example program we might have $\mathbf{\text{Var}_\star} = \{ x, y, z \}$ and $\mathbf{\text{Lab}_\star} = \{ 1, \dots, 6, ? \}$ . It is immediate that $(\mathcal{P}(\mathbf{\text{Var}_\star \times \mathbf{\text{Lab}_\star}))}^{12}$ can be partially ordered by setting $$\overrightarrow{\text{RD}} \sqsubseteq \overrightarrow{\text{RD}}^\prime \ \ \ \text{iff} \ \ \ \forall i : \text{RD}_i \subseteq \text{RD}_i^\prime$$ where $\overrightarrow{\text{RD}} = (\text{RD}_1, \dots, \text{RD}_{12})$ and similarly $\overrightarrow{\text{RD}}^\prime = (\text{RD}_1^\prime, \dots, \text{RD}_{12}^\prime)$ . This turns $(\mathcal{P}(\mathbf{\text{Var}_\star \times \mathbf{\text{Lab}_\star}))}^{12}$ into a complete lattice (see Appendix A) with least element $$\overrightarrow{\emptyset} = (\emptyset, \dots, \emptyset)$$ and binary least upper bounds given by: $$\overrightarrow{\text{RD}} \sqcup \overrightarrow{\text{RD}}^\prime = (\text{RD}_1 \cup \text{RD}_1^\prime, \dots, \text{RD}_{12} \cup \text{RD}_{12}^\prime)$$ It is easy to show that $F$ is in fact a monotone function (see Appendix A) meaning that: $$\overrightarrow{\text{RD}} \sqsubseteq \overrightarrow{\text{RD}}^\prime \ \ \ \text{implies} \ \ \ F(\overrightarrow{\text{RD}}) \sqsubseteq F(\overrightarrow{\text{RD}})^\prime$$ This involves calculations like $$\text{RD}_\text{exit}(2) \subseteq \text{RD}_\text{exit}^\prime(2) \ \ \text{and} \ \ \text{RD}_\text{exit}(5) \subseteq \text{RD}_\text{exit}^\prime(5)$$ imply $$\text{RD}_\text{exit}(2) \cup \text{RD}_\text{exit}(5) \subseteq \text{RD}^\prime_\text{exit}(2) \cup \text{RD}_\text{exit}^\prime(5)$$ and the details are left to the reader. Appendix A gives the following definition for monotone function : The function $f$ is monotone (or isotone or order-preserving ) if $$\forall l, l^\prime \in L_1 : l \sqsubseteq_1 l^\prime \Rightarrow f(l) \sqsubseteq_2 f(l^\prime)$$ I am trying to do as the author said, and show that $F$ is a monotone function. However, although I have tried to solve this in various ways (see here ), I have so far been unable to make progress. It seems to me that such a proof should proceed by showing that, for some arbitrary element of the set of elements $F(\overrightarrow{\text{RD}})$ , if we use the fact that $\overrightarrow{\text{RD}} \sqsubseteq \overrightarrow{\text{RD}}^\prime$ , then we can deduce that said arbitrary element is also an element of the set $F(\overrightarrow{\text{RD}})^\prime$ , and so $F(\overrightarrow{\text{RD}}) \sqsubseteq F(\overrightarrow{\text{RD}})^\prime$ . However, it seems to me that the textbook is very poorly written, and so it is difficult for me to even understand what said arbitrary elements of the set $F(\overrightarrow{\text{RD}})^\prime$ even are (they seem to be some kind of cartesian product, but I get very confused when trying to figure out precisely what they are). So how is it shown that $F$ is a monotone function?","['monotone-functions', 'relations', 'order-theory', 'elementary-set-theory', 'computer-science']"
3922308,Isomorphism between graphs,"Are the graphs G1 and G2 isomorphic? I think that the graphs are not isomorphic because G2 has a cycle tuwzt, where all vertices have deegree 4. No such cycle can be found in G1. Therefore because isomorphism preserves cycles G1 and G2 can’t be isomorphic. Is that correct?
/Erika","['graph-isomorphism', 'discrete-mathematics']"
3922360,Show that $\lim\limits_{n \to +\infty}(\sin(\frac{1}{n^2})+\sin(\frac{2}{n^2})+\cdots+\sin(\frac{n}{n^2})) = \frac{1}{2}$,"Show that the sequence defined as $$x_n = \sin\left(\frac{1}{n^2}\right)+\sin\left(\frac{2}{n^2}\right)+\cdots+\sin\left(\frac{n}{n^2}\right)$$ converges to $\frac{1}{2}$ . My attempt was to evaluate this limit by using squeeze theorem. I managed to show that $x_n < \frac{n+1}{2n}$ by using $\sin(x) < x$ , but I haven't been able to find a sequence smaller than $x_n$ that also converges to $\frac{1}{2}$ . I tried showing by induction that $x_n > \frac{1}{2}-\frac{1}{n}$ , but I got nowhere with that. Any help would be appreciated.","['limits', 'sequences-and-series', 'real-analysis']"
3922418,"Solve in real numbers the system of equations $x^2+2xy=5$, $y^2-3xy=-2$","Solve in real numbers the system of equations $x^2+2xy=5$ , $y^2-3xy=-2$ I couldn't do this question and hence I looked at the solution which goes as follows: if $x=0$ then $x^2+2xy=0\ne5$ hence $x\ne0$ I state that $y=lx$ . Hence the system becomes: $x^2(1+2l)=5$ , $x^2(l^2-3l)=-2$ which becomes $5l^2-11l+2=0$ , hence $l=2$ or $l=\frac{1}{5}$ . Hence the possible solutions are: $(1, 2), (-1,-2), (\frac{5}{\sqrt{7}}, \frac{1}{\sqrt{7}}), (-\frac{5}{\sqrt{7}}, -\frac{1}{\sqrt{7}})$ . My question is why was I supposed to think of substituting $y=lx$ ? Why was this supposed to be intuitive and is there a more intuitive approach?","['contest-math', 'real-numbers', 'intuition', 'algebra-precalculus', 'problem-solving']"
3922421,The Ricci form and the Chern class?,"Let's take the tangent bundle $TM\rightarrow M$ (not to be Kahler), and the first Chern class $$c_1(M)=[tr(\frac{\sqrt -1}{2\pi}\Omega)]$$ We know that the inside trace of the curvature form is a closed form. But I try to write the form in the bracket more explicitly $$tr(\Omega_i^{j})=\Omega_i^{i}=R^{i}_{ik\bar l}dz^k\wedge dz^{\bar l}=Ric_{k\bar l}dz^k\wedge dz^{\bar l}$$ It seems that the first Chern class $c_1(M)$ can be represented by $\frac{\sqrt -1}{2\pi}[Ric]$ （I know this is true for Kahler manifold, since the Ricci form $\partial_i \bar{\partial_j}log (detg) dz^i\wedge dz^{\bar j}$ is closed by using Kahler condition, but I cannot guarantee the Ricci form for any complex manifold is still a closed one. What am I missing?","['kahler-manifolds', 'complex-geometry', 'curvature', 'characteristic-classes', 'differential-geometry']"
3922422,Constructing a Lyapunov function for an ODE system that describes epidemic spreading on scale-free networks,"I was recently studying an epidemic spreading model, where two competing viruses spread over a scale-free network. $$
\begin{aligned}
\frac{dI_{1,k}(t)}{dt} = - I_{1,k}(t) + \psi_1 k (1-I_{1,k} - I_{2,k}) \Theta_1(t)\\
\frac{dI_{2,k}(t)}{dt} = - I_{2,k}(t) + \psi_2 k (1-I_{1,k} - I_{2,k}) \Theta_2(t),
\end{aligned}
$$ where $\Theta_1(t) =  \frac{\sum_{k'}k'P(k')I_{1,k'}}{\langle k \rangle}$ and $\Theta_2(t) =  \frac{\sum_{k'}k'P(k')I_{2,k'}}{\langle k \rangle}$ . Here is the interpretation: $k$ represents the degree of a vertex. There are only finite degrees. $P(k)$ is the portion of the vertices that has degree $k$ , hence $\sum_{k'}P(k') =1$ . $\langle k \rangle \triangleq \sum_{k'} k'P(k')$ is the average degree. $I_{1,k}$ represents the portion of nodes that are infected by virus $1$ among the nodes with degree $k$ . $0 \leq I_{1,k},I_{2,k}$ and $I_{1,k}+I_{2,k}\leq 1$ . The term $-I_{1,k}(t)$ in the ODEs gives the recovery speed. The term $\psi_1 k (1-I_{1,k} - I_{2,k}) \Theta_1(t)$ is the transmission speed. Checking the steady-state by setting $$
\begin{aligned}
 - I_{1,k}(t) + \psi_1 k (1-I_{1,k} - I_{2,k}) \Theta_1(t) = 0\\
 - I_{2,k}(t) + \psi_2 k (1-I_{1,k} - I_{2,k}) \Theta_2(t) = 0,
\end{aligned}
$$ gives the equilibrium $(I_{1,k}^*,I_{2,k}^*)= (I_{1,k}^*,0)$ when $\psi_1 > \psi_2$ , where $I_{i,k}^*$ satisfies the relation $I_{i,k}^* = \frac{\psi_1 k \Theta_1^*}{1 + \psi_1 k \Theta_1^*}$ for all $k$ . The question is how to show this equilibrium is actually globally stable whenever $0< I_{1,k}(0)$ . Similation shows global stability. But I have not found a Lypunov function to show theoretical guarantees. I have tried several forms of Lyapunov candidates $$
\begin{aligned}
V(t)= \sum_{k} \left\{ b_1(k) (I_{1,k} - I_{1,k}^*)^2 + b_2(k) (I_{2,k}-0)^2 \right\} + \Theta_1 - \Theta_1^* - \ln \frac{\Theta_1}{\Theta_1^*} + \Theta_2 \\
V(t)= \sum_{k} \left\{ b_1(k) (I_{1,k}- I_{1,k}^* - \ln \frac{I_{1,k}}{I_{1,k}^*}) + b_2(k) I_{2,k} \right\} + \Theta_1 - \Theta_1^* - \ln \frac{\Theta_1}{\Theta_1^*} + \Theta_2
\end{aligned}.
$$ I was trying to find $b_1(k),b_2(k)$ which are constant functions of $k$ . I tried $b_1(k) = \frac{kP(k)\psi_1}{\langle k \rangle}$ , $b_1(k) = \frac{kP(k)\psi_1}{\langle k \rangle}$ . Just couldn't find my way to show that $\dot{V} \leq 0$ . Do anybody have any idea about how to find a Lyapunov function for this kind of ODE systems? Or any form of Lyapunov candidates should I look after?","['nonlinear-system', 'lyapunov-functions', 'ordinary-differential-equations']"
3922452,How to prove this inequality on trace of inverse of a positive definite matrix?,"I was stuck for a long time to prove the following trace inequality \begin{equation}\label{ine1}
{\text {tr}} ({\bf A}_1^{-1}) \leq {\text {tr}} ({\bf A}^{-1}),  \tag{1}
\end{equation} where ${\bf A} \in {\mathbb C}^{K \times K}$ is a positive definite matrix and ${\bf A}_1$ consists of the diagonal elements of ${\bf A}$ , i.e., ${\bf A}_1 = {\text {diag}} ( {\text {diag}} ({\bf A}))$ .
I have run a lot of simulation using Matlab and this inequality always holds.
(1) in the simple case with $K=2$ can be easily proven.
However, I can not prove it for the more general $K>2$ case.
Some of my efforts are as follows. Denote ${\bf A}_1 = {\text {diag}} \{ a_1, \cdots, a_K \}$ and the eigenvalues of ${\bf A}$ by $ \{ \lambda_1, \cdots, \lambda_K \}$ .
Then, it is obvious that \begin{equation}\label{e1}
\sum_{k=1}^K a_k = \sum_{k=1}^K \lambda_k. \tag{2}
\end{equation} In addition, using Hadamard's inequality, we have \begin{equation}\label{ine2}
\prod_{k=1}^K a_k \geq \prod_{k=1}^K \lambda_k. \tag{3}
\end{equation} Since (1) is equivalent to \begin{equation}
\sum_{k=1}^K \frac{1}{a_k} \leq \sum_{k=1}^K \frac{1}{\lambda_k}, \tag{4}
\end{equation} I tried to prove (4) using (2), (3), and the relationship between different means (Harmonic mean, etc.). But they didn't work. Anyone providing the proof or relevant hints will be much appreciated. Thank you.","['trace', 'matrices', 'inverse', 'inequality', 'positive-definite']"
3922547,"Product of $\cos(a^kx)$ where $k=1,2,3,\ \dots$ and $a$ is a natural number","I have quite frequently encountered the relation, $$\cos(x)\cos (2x)\cos(4x)\dots \cos(2^{n-1}x)= \frac{\sin(2^nx)}{2^n\sin(x)}$$ but is there any explicit formula for the series, $$\cos(x)\cos (3x)\cos(9x)\dots \cos(3^{n-1}x)$$ I have tried hard to come up with a relation, but in vain. If there is such a formula, I would really be interested in how to prove it, that is you can give me a hint.","['trigonometry', 'sequences-and-series', 'real-analysis']"
3922554,Convergence of Sturm-Liouville eigenfunction expansions at the endpoints of an interval.,"Let $\{\phi_n\}_{n=0}^\infty$ be the eigenfunctions of the regular Sturm-Liouville problem \begin{align}
 -(p\,\phi')' + q\, \phi = \lambda \, r \, \phi \quad &\textrm{for } x \in (x_1,x_2)\\
  - a_i \, \phi(x_i)  + b_i\, (p\,\phi')(x_i) = 0 \quad &\textrm{for } i=1,2.
\end{align} Assume that $p$ and $r$ are positive and twice continuously differentiable; assume that $q$ is continuous; the coefficients $a_i,b_i$ for $i=1,2$ are real. Let $F(x)$ be a twice continuously differentiable function on the interval $[x_1,x_2]$ . Under the above conditions, I know that \begin{equation}
  \textrm{(I)} \quad \quad  F(x) = \sum_{n=0}^\infty \left(\int_{x_1}^{x_2} F(z) \, \phi_n(z)\, r(z)\, \textrm{dz} \right)\, \phi_n(x)
\end{equation} with point-wise equality in the open interval $(x_1,x_2)$ . My question is: to what value does the end-point $(x=x_i)$ series \begin{equation}
\textrm{(II)} \quad \quad  \sum_{n=0}^\infty \left(\int_{x_1}^{x_2} F(z) \, \phi_n(z)\, r(z)\, \textrm{dz} \right)\, \phi_n(x_i)
\end{equation} converge to? Is there a general closed form expression? If $F(x)$ satisfies the same boundary conditions as the eigenfunctions $\phi_n$ , then I know that the series (I) converges to $F(x)$ uniformly on the closed interval $[x_1,x_2]$ (and so I obtain point-wise equality on the closed interval). On the other hand, if the eigenfunctions $\phi_n$ satisfy the simpler boundary conditions $\phi_n(x_i)=0$ then the endpoint series (II) must converge to zero. The series (I) must then have a finite-jump discontinuity at the end points, e.g., jumping from $\lim_{x\rightarrow x_2}F(x)$ to $0$ at $x=x_2$ . However, I am interested in the more general boundary conditions above. I am aware of closed-form expressions for the endpoint series in the case of a Fourier expansions; I am wondering whether an analogous expression exists for regular Sturm-Liouville expansions. Any references would be greatly appreciated. Edit: I've linked a related question here. Is there an analogous result for Sturm-Liouville series? Do we obtain point-wise  convergence to $F(x)$ on the closed interval $[x_1,x_2]$ whenever $b_1,b_2 \neq 0$ ? Edit #2: The Sturm-Liouville article on the Encyclopedia of Mathematics states that, with $b_1,b_2 \neq 0$ , the expansion (I) converges under the same conditions as a Cosine series for any $F\in L^1$ . Presumably, from the previous edit, this would imply that we obtain point-wise convergence to $F$ on the whole interval if $F$ is differentiable and $b_1,b_2 \neq 0$ . Unfortunately, I do not have access to the articles cited in the encyclopedia.","['fourier-analysis', 'ordinary-differential-equations', 'sturm-liouville', 'real-analysis', 'sequences-and-series']"
3922559,Can an equilateral triangle be dissected into 5 congruent convex pieces?,"There is a rather surprising dissection of an equilateral triangle into 5 congruent pieces: However, these pieces aren't very ""nice"", consisting of 2 or 6 connected components depending on how one counts single-point overlaps. I expect that the analogous question for arbitrary connected pieces is quite difficult, but I wonder if the case of convex pieces is sufficiently restricted to allow for a proof of impossibility (which I strongly suspect is the case). One aspect of this problem that makes it much more tractable is that the pieces have to be polygons, because any border between two pieces must be a straight line to preserve convexity of both pieces. In fact, this analysis can be extended a little further to show that the pieces have at most 5 sides. The number of edges on a piece is at most the number of edges of the triangle it touches, plus the number of other pieces it touches. $K_5$ is non-planar, so there is a piece touching at most 3 others. If this piece touches all three sides of the triangle, then its complement has at least two disconnected regions (since it can't take up an entire side), so the pieces in those regions are at most pentagons by a similar analysis. If it does not touch all three sides of the triangle, then it is itself at most a pentagon. If the polygons are triangles, then I can go through some casework on the edges to show that the triangles must be $30-60-90$ triangles, and from there derive a contradiction. So the only remaining cases are those of quadrilaterals and pentagons. Can such dissections be shown impossible? Interestingly, the answer is known to be yes for some squarefree multiples of $5$ like $180$ ; see this MathOverflow thread for a picture.","['dissection', 'geometry', 'tiling']"
3922567,if $f(x)=x^2-2$ then real solutions of $f^n(x)=x$,"if $f(x)=x^2-2$ where $x\in[-2,2]$ then find the number of real solutions $f^n(x)=x$ for some natural $n$ where $f^n(x)=f(f^{n-1}(x))$ I had no clue on how to start , a recurrence relation seemed unobvious.Hence i started with examples! $f(x)=x\Rightarrow x^2-x-2=0$ has two solutions. Now $f(f(x))=x\Rightarrow x^4-4x^2-x+2=(x-2)(x+1)(x^2+x-1)=0$ has $4$ solutions. By the time it reached $f(f(f(x)))=x$ i lost my patience.I hence went to WA which says that there are 8 roots.I see the pattern it looks like number of roots is $2^n$ ...... Any hints?? I would love a solution without calculus but i am ok with it otherwise..","['contest-math', 'algebra-precalculus', 'functions', 'recurrence-relations']"
3922592,Calculate the angle x,"In the figure, AB is diameter, PM = MH and PN = NB.
If PEB arc = 108 °, calculate ""x"" Drawing to obtain the right triangle in P: $\Delta APB $ . $\hat{A}$ as $\hat{B}$ are angles inscribed on the circumference, they are equal to half the arc you see. Therefore, $\hat{A} = 54^o$ , $\hat{B} = 36^o$ and  note also that $\overline {MN}$ t is  average base $\Delta HPB $ . If $\hat{B} = 36^o$ . $\hat{H} = 90^o$ then $H\hat{P}B = 54^o$ In the right triangle, the middle base is parallel to the base of the original triangle. Therefore, the triangle $\Delta PMN$ is $\hat{M}$ rectangle is $P \hat{N} M = 36^o$ and In addition $R \hat{Q}N$ and $O \hat{Q}M$ are opposed by the vertex. From this, it is easy to conclude that $\Delta OMQ$ $\simeq$ $\Delta NRQ$ Therefore,  in the triangle $\Delta OMQ$ we obtain that $ x + 90^o + 36^o = 180^o \Rightarrow x = 54^o $ how to demonstrate the similarity of $\Delta OMQ$ $ and \Delta NRQ$ ?",['geometry']
3922627,very ample divisors on curves using Riemann Roch Spaces,"Let $C$ be a projective non-singular irreducible curve, let $D$ be a divisor on $C$ . Suppose the Riemann-Roch Space is $L(D)=\langle f_1,...,f_n\rangle$ .
Define $\phi_D:C\to \mathbb{P}^{n-1}$ by $\phi_D(P)=(f_1(P):...,f_n(P))$ . We say that $D$ is very ample if $\phi_D$ is an embedding. Suppose $P\neq Q\in C$ , $\phi_D(P)=(1:0:...:0),\phi_D(Q)=(0:1:...:0)$ . I need to show that if $D$ is very ample, then $L(D-P)\neq L(D)$ . I'm not sure how to go about that. Some literatures incorporate a base point free property to the definition of very ample, but I don't have such a definition in this case. Since $f_1$ achieves minimum order at $P$ across all $f\in L(D)$ , is it true that $f_1\notin L(D-P)$ ? How to show this? It is clear that $f_1\notin L(D-P)\iff L(D-P)\neq L(D)$ , but I'm not sure how to prove either side of this equivalence.","['curves', 'divisors-algebraic-geometry', 'algebraic-geometry', 'projective-geometry']"
3922631,Proving Chromatic Number without 5-Color Theorem,"We are currently studying planar graphs and I have come across a review exercise that is proving to be more trouble than it's worth. The problem is as follows: Let G = (V;E) be a planar graph with at most 12 vertices. Without using the 4-colour theorem or the 5 colour theorem (Theorems 13.4.1 or 13.4.2 in the Discrete Math book), prove that G has chromatic number at most 5. I've got a few tools at my disposal, mostly that of Euler's equation of $|V|+|F|=|E|+2$ , and it's later derivation of $|E| \leq 3|V|-6$ . From these two, I can prove the six color theorem, as we can say by Handshake Lemma there must be at least one vertex of degree 5 or less in order to not break the $|E| \leq 3|V|-6$ inequality. As, with 12 vertices max, that would mean there is a max of 30 edges. However, I keep coming back to the fact that it seems I'm going to have to basically pseudo-prove the 5 color theorem again. Can I utilize the amount of vertices to my advantage, as it bounds vertices, edges, and faces? Any help would be appreciated.","['graph-theory', 'coloring', 'discrete-mathematics', 'planar-graphs']"
3922686,Prove that there is a matrix $B$ so that $\det(M + tB) \neq 0$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Let $M$ denote an $n\times n$ matrix with entries in a field $\mathbb{F}$ . Prove that there is a $n\times n$ matrix $B$ with entries in $\mathbb{F}$ so that $\det(M + tB)\neq 0$ for every non-zero $t\in\mathbb{F}$ .","['matrices', 'determinant', 'linear-algebra']"
3922725,Local ring of a generic point on an integral scheme is a field,"Let $X$ be an integral scheme and let $\eta \in X$ be its generic
point. Then the local ring $K(X) := \mathcal{O}_{X, \eta}$ is a field.
Moreover, if $U = \text{Spec} A$ is any open affine subset of $X$ , then $K(X) \cong \text{Frac} A$ . I would like to prove this proposition. I have already seen a proof that I understand, for example here . But I would like to see if my partial approach can somehow be extended to a full proof. Since $X$ is integral, $A$ is an integral domain and $\text{Frac} A$ is well-defined and a field. So we only need to show the last part. Let $U = \text{Spec} A$ be an affine open subset of $X$ . Then since $\eta$ is the generic point, it is contained in all open subsets of $X$ . We have $A=\mathcal{O}_X(U)$ so $\text{Frac} A = \{ f/g \ | \ f, g \in \mathcal{O}_{X}(U), \ g\neq0 \}$ . Define the map \begin{align*}
			\phi: \text{Frac} A &\to K(X) = \mathcal{O}_{X, \eta}\\
			f/g & \mapsto (U \cap D(g), f/g).
		\end{align*} Consider $(U \cap D(g), g) \in \mathcal{O}_{X, \eta}$ . Provided $(U \cap D(g), g) \notin m_{\eta}$ , then this element has an inverse $(U \cap D(g), 1/g) \in \mathcal{O}_{X, \eta}$ and we can multiply it with $(U \cap D(g), f) \in \mathcal{O}_{X, \eta}$ . This is how our map $\phi$ is defined. So we now show that $(U \cap D(g), g) \notin m_\eta$ . How do we show that? It is obvious that $\phi$ is a ring homomorphism. Let $f/g \in \ker \phi$ . Then $(U \cap D(g), f/g) =0 \in \mathcal{O}_{X, \eta}$ and so the product $(U \cap D(g), f)(U \cap D(g), 1/g) =0 \in \mathcal{O}_{X, \eta}$ . Because $X$ is integral, $\mathcal{O}_{X, \eta}$ has no zero-divisors. Since $(U \cap D(g), 1/g)$ is a unit, it is not $0$ , hence we must have $(U \cap D(g), f)=0$ . So there is an open set $V \subset U \cap D(g)$ such that $f$ restricted to $V$ is $0$ . So $f(\eta)=0$ and because $\eta$ is dense in $U$ and $\mathcal{O}_X(U)$ has no nilpotent elements we have $f=0$ . So $\phi$ is injective. How to prove surjectivity?","['local-rings', 'algebraic-geometry', 'schemes']"
3922758,Decomposition of a topological manifold into sets with low-dimensional intersections,"Let $f:M\rightarrow N$ be a continuous function between connected topological manifolds, modelled respectively on $\mathbb{R}^m$ and $\mathbb{R}^n$ ; $n,m\in \mathbb{Z}^+$ .  Can we always find a cover $\{C_i\}_{i \in I}$ of $N$ such that: $I$ is finite, The $C_i$ are regular closed subsets, i.e. $\overline{\text{int}(C_i)}=C_i$ , $\text{int}(C_i)\cong \mathbb{R}^n$ , $\text{dim}(C_i\cap C_j)<n$ ? and $C_i\cap C_j$ is a Borel set? When $N$ is compact, this is clear, since we just cover $N$ with locally Euclidean neighbourhoods, take their closures, and reduce to a finite set using compactness.  However, what about in general?","['geometry', 'smooth-manifolds', 'geometric-topology', 'manifolds', 'differential-geometry']"
3922797,Differential equation in Complex numbers,How do I solve this differential equation $$Z'=Z^*$$ such that $Z$ is complex numbers and $Z^*$ is the conjugate of $Z$ ? Sketch the phase portraits of solutions.,"['complex-analysis', 'ordinary-differential-equations']"
3922841,Why is $2f(x)$ in the same function?,"My SAT Math essentials book says: $$f(x) = 8x - 2$$ becomes $$f(3) = 8(3) - 2f(3) = 24 - 2 = 22$$ So, when $x = 3$ , the value of the function is $22$ . Why did the author insert $2f(3)$ if that line equals $44$ ?","['algebra-precalculus', 'functions']"
3922849,Show the convergence of $\sum_{n=0}^{\infty}\frac{1}{2}\cdot \frac{(2n)!}{n!(n+1)!}\cdot \left(\frac{1}{4}\right)^n$,"As stated by the prompt, I'm looking to show the convergence of the series $$\sum_{n=0}^{\infty}\frac{1}{2}\cdot \frac{(2n)!}{n!(n+1)!}\cdot \left(\frac{1}{4}\right)^n$$ I've tried using the ratio, root, and Limit Comparison test (w/ a geometric series), and all have given me inconclusive answers.  If anyone has some insights for how I might be able to show this series converges, your help would be much appreciated.",['sequences-and-series']
3922867,asymptotic normality of z-estimator,"I'm working on Problem 5.4.1 in Bickel and Docksum's Mathematical Statistics
Let $X_1, \dots, X_n$ be i.i.d. random variables distributed according to $P\in\mathcal{P}$ . Suppose $\psi:\mathbb{R}\to\mathbb{R}$ : (i) is monotone nondecreasing (ii) $\psi(-\infty)<0<\psi(\infty)$ (iii) $|\psi|(x)\le M<\infty$ for all $x$ And suppose for all $P\in\mathcal{P}$ , $\theta(P)$ is the unique solution of $\mathbb{E}_P\psi(X_1-\theta) = 0$ . Let $\hat{\theta}_n = \theta(\hat{P})$ , where $\hat{P}$ is the empirical distribution of $X_1,\dots,X_n$ . Now set $\lambda(\theta) = \mathbb{E}_P\psi(X_1-\theta)$ and $\tau^2(\theta) = \text{var}\psi(X_1-\theta)$ . Assume $\lambda'(\theta)<0$ exists and that $$\frac{1}{\sqrt{n}\tau(\theta)}\sum_{i=1}^n\left[\psi(X_i-\theta_n)-\lambda(\theta_n)\right] \xrightarrow{\mathcal{L}} N(0,1)$$ for every sequence $\{\theta_n\}$ with $\theta_n = \theta = t/\sqrt{n}$ for $t\in\mathbb{R}$ .\ $\textbf{The problem is to show that}$ $$\sqrt{n}(\hat{\theta}_n-\theta) \xrightarrow{\mathcal{L}} N(0,\frac{\tau^2(\theta)}{[\lambda'(\theta)]^2})$$ Hint: $P(\sqrt{n}(\hat{\theta}_n-\theta)<t) = P(\hat{\theta}_n<\theta_n) = P(-\sum_{i=1}^n\psi(X_i-\theta_n)<0)$ . $\textbf{My question}$ is that I don't understand the last equality in the hint, and also how this could lead to the conclusion. Any help will be appreciated! (I manage to prove the consistency of this z-estimator $\hat{\theta}_n$ , but not sure whether this could help this problem or not)","['statistics', 'central-limit-theorem', 'asymptotics']"
3922901,Limit in two variables of $x e^{-y^2/x}$,"I'm trying to compute the limit $$\lim_{(x,y)\rightarrow (0,0)} x e^{-y^2/x}$$ In order to compute it, I would just use the following bound: $$e^{-\frac{-y^2}{x}} \leq 1$$ and hence $$|x e^{-y^2/x}|$$ and hence the limit is $0$ . Is it right? Using polar coordinates I obtain $\lim_{r \rightarrow 0} r cos(\theta) e^{- r \frac{sin^2(\theta)}{cos(\theta)}}$ why isn't this $0$ ?","['limits', 'multivariable-calculus', 'solution-verification']"
3922922,Homomorphism between $Q_8$ and $S_4$,"Prove that there does not exist a homomorphism $\phi :Q_8 \rightarrow S_4$ such that $\phi (i) = (1 2 3 4), \phi (j) = (1 2 4 3) $ . Using homomorphism properties, we obtain $\phi(i) \phi(j) = \phi(ij) = \phi(k) = (1 2 3 4)(1 2 4 3) = (1 3 2)$ , then $\phi(j) \phi(k) = \phi(jk) = \phi(i) = (1 2 4 3)(1 3 2) = (3 4)\neq (1 3 2)$ , hence $\phi$ is not even a well-defined function. Is what I did right? I am not completely convinced. Thanks!","['group-homomorphism', 'group-theory']"
3922939,Characterization of Hilbert spaces using orthogonal decomposition,"Using the closest point property of Hilbert spaces we can prove that for any closed subspace $A \subset H$ we can decompose H as $$H = A \oplus A^{\bot}.$$ Is this property characterizing Hilbert spaces? Namely, if we have an inner product space H such that for every closed subspace $A \subset H$ we can write $$H = A \oplus A^{\bot}$$ then space is Hilbert? I've seen some specific cases, where the space was not complete and $H \neq A \oplus A^{\bot}$ for some closed $A$ ; for example for $H = c_{00}$ (space of sequences with finite support) with inner product inherited from $\ell^2$ and $A = \{ x \in c_{00}: \sum_{n=1}^{\infty} \frac{x_n}{n}=0\}$ so I wonder if we can generalize example like this and always find a closed subspace $A$ of an incomplete inner product space $H$ , such that $H \neq A \oplus A^{\bot}$ ? Or if there is a different way of approaching this question perhaps.","['hilbert-spaces', 'functional-analysis']"
3922945,Why does this weird iteration converge to the square root ??,"Let $1 < x < 4$ , $a_1 = x$ and $b_1 = 0$ . Now consider the (conditional) iterations if $a_n > b_n$ then $a_{n+1} = 4(a_n - b_n - 1)$ $b_{n+1} = 2(b_n + 2)$ else ( $a_n = b_n$ or $a_n < b_n$ ) $a_{n+1} = 4 a_n$ $b_{n+1} = 2 b_n$ Now consider $c_n = \frac{b_n}{2^n}$ Now define $f(x) = \lim_{n \to \infty} c_n $ Now apparently $ f(x)  = \sqrt x$ Despite being a simple limit of a conditional iteration, I do not get it. I am even surprised limits of conditional iterations can be analytic functions with respect to the starting value. I have never seen these type of iterations during my education nor in a book.
Not even in books about numerical methods. Sure the algorithm converges slowly but it has benefits too and it does not use complicated functions. Im clearly missing the big picture here. Conditional iterations (or recursions) is a topic I know nothing about it seems. How and why does this algorithm give the square root ? What is the bigger picture ? How to generalize this ? I could be wrong, but is this related to the mediant when $x$ is rational ?","['limits', 'radicals', 'analyticity', 'recursion']"
3922982,Trying to get an intuitive understanding of compositions of rotations in $\mathbb{R}^3$,"Lately I've been looking at the special orthogonal group $SO_\mathbb{R}(3)=\{M\in O(3),\, \det M =1\}$ , where $O_{\mathbb{R}}(3)$ is the group of real matrices such that $AA^\top=I$ . I'm looking to get a intuitive understanding of a ""simple fact"". To my understanding its elements can be seen as rotations around a line through the origin (ie a subspace of dimension 1). $ SO_\mathbb{R}(3)$ forms a group with respect to matrix multiplication, so the product of two elements is still an element of the group. That is to say, if one composes two rotations, around two possibly different lines (through the origin), the resulting automorphism of $\mathbb{R^3}$ is another rotation around some line through 0. Why should that be?  Algebraically it checks out, but intuitively I can't see why it should be the case that combining rotations around different axes would have to be another rotation. Why is there always one line left unmoved, fixed by the composition of rotations?
Anyway, if anyone has a good mental image or intuitive perspective they'd like to share, I'd appreciate.","['euclidean-geometry', 'geometry', 'orthogonal-matrices', 'linear-algebra', 'intuition']"
3923066,What is the meaning of group extension?,"I frequently see the notation $1\to N\to G\to Q\to 1$ . Wikipedia explains that this is the notation to describe situation where there is an injective map from $N$ to $G$ called $i$ and $G/i(N)\cong Q$ . It says that if $N\subset Z(G)$ then it is called central extension and if $N$ is cyclic, then this is called successive cyclic extension. Why is there $1$ on the end in this notation and why is this notation important? I was just learning about supersolvable group and nilpotent group, and this notation seems out of context. Can you explain a little bit of context with simple terms without using Galois extension?",['group-theory']
3923123,Gaussian curvature is affected by a conformal map,"I'm studying Tu's book Differential Geometry.
Problem is Two Riemannian manifolds $M$ and $M′$ of dimension 2 with a diffeomorphism $T:M→M′$ between them. For every point $p \in M$ , there is a positive number $a(p)$ such that $$⟨T^∗(u),T^∗(v)⟩_{M′,F(p)}=a(p)⟨u,v⟩_{M,p}$$ for all $u,v\in T_pM$ . Find the relationship between the Gaussian curvatures between the two manifolds. I saw How Gaussian curvature is affected by a conformal map (using forms) . But I cannot derive $\tilde\omega_2^1 = \omega_2^1 + \left(-\frac{\lambda_2}\lambda\theta^1 + \frac{\lambda_1}\lambda\theta^2\right)$ part in Ted Shifrin's answer. Can you explain it more specifically? Thank you.",['differential-geometry']
3923124,Upper bounds for $\frac{x_1}{1+x_1^2} + \frac{x_2}{1 + x_1^2 + x_2^2} + \cdots + \frac{x_n}{1 + x_1^2 + x_2^2 + \cdots + x_n^2}$,"Problem : Let $x_1, x_2, \cdots, x_n$ ( $n\ge 2$ ) be reals. Find upper bounds for $$\frac{x_1}{1+x_1^2} + \frac{x_2}{1 + x_1^2 + x_2^2} + \cdots + \frac{x_n}{1 + x_1^2 + x_2^2 + \cdots +  x_n^2}. $$ There is also the following Ji Chen's estimation (mentioned in the link below): $$\frac{x_1}{1+x_1^2}+\frac{x_2}{1+x_1^2+x_2^2}+\dotsb+\frac{x_n}{1+x_1^2+x_2^2+\dotsb+x_n^2}<\sqrt{n}-\dfrac{\ln{n}}{2\sqrt{n}}.\tag{1}$$ This is the follow up of Prove that $\frac{a}{1+a^2}+\frac{b}{1+a^2+b^2}+\frac{c}{1+a^2+b^2+c^2}+\frac{d}{1+a^2+b^2+c^2+d^2}\leq\frac{3}{2}$ . Question : How to prove the bound (1)? Can we obtain better upper bounds? Any comments and solutions are welcome and appreciated. Edit (2022/02/22): The problem can be rephrased as follows: Let $c_1 = 1/2$ and $c_{k + 1} = g(c_k), k \ge 1$ where $$g(c) = \frac18\sqrt{-2c^4 + 40c^2 + 16 + 2c(c^2 + 8)\sqrt{c^2 + 8}}.$$ Find the upper bounds of $c_n$ . Some bounds : IMO ShortList 2001, algebra problem 3, see: https://artofproblemsolving.com/community/c6h17449p119163 $$\frac{x_1}{1+x_1^2}+\frac{x_2}{1+x_1^2+x_2^2}+\dotsb+\frac{x_n}{1+x_1^2+x_2^2+\dotsb+x_n^2}<\sqrt{n}. \tag{2}$$ zhaobin@AoPS gave a very nice proof for (2): \begin{align*}
&\mathrm{LHS}^2\\
\le\ & n\left(\frac{x_1^2}{(1+x_1^2)^2}+\frac{x_2^2}{(1+x_1^2+x_2^2)^2}+\dotsb+\frac{x_n^2}{(1+x_1^2+x_2^2+\dotsb+x_n^2)^2}\right)\\
\le\ & n\Big(\frac{x_1^2}{1\cdot (1+x_1^2)}+\frac{x_2^2}{(1+x_1^2)(1+x_1^2+x_2^2)}+ \frac{x_3^2}{(1+x_1^2+x_2^2)(1+x_1^2+x_2^2+x_3^2)}\dotsb\Big)\\
\le\ & n\Big(1 - \frac{1}{1+x_1^2} + \frac{1}{1+x_1^2} - \frac{1}{1+x_1^2+x_2^2} + \frac{1}{1+x_1^2+x_2^2} - \frac{1}{1+x_1^2+x_2^2+x_3^2}\cdots\Big)\\
\le\ & n\left(1 - \frac{1}{1+x_1^2+x_2^2 + \cdots + x_n^2}\right)\\
<\ & n.
\end{align*} My attempt : I found the following relation: Let $y_k = \frac{x_{k+1}}{\sqrt{1+x_1^2}}, k = 1, 2, \cdots, n-1$ and we have $$\sum_{m=1}^n \frac{x_m}{1 + \sum_{k=1}^m x_k^2} = \frac{x_1}{1 + x_1^2} + \left(\sum_{m=1}^{n-1} \frac{y_m}{1 + \sum_{k=1}^m y_k^2}\right)\frac{1}{\sqrt{1+x_1^2}}.$$ By this, if we have $\sum_{m=1}^{n-1} \frac{x_m}{1 + \sum_{k=1}^m x_k^2} \le F(n-1)$ on $\mathbb{R}^{n-1}$ for some function $F(\cdot)$ , then we have $\sum_{m=1}^n \frac{x_m}{1 + \sum_{k=1}^m x_k^2} \le g(F(n-1))$ on $\mathbb{R}^n$ where $$g(c) \triangleq \max_{x\in \mathbb{R}} \frac{x}{1+x^2} + c \frac{1}{\sqrt{1+x^2}}.$$ Remark: $g(c)$ admits a closed form: $$g(c) = f\left(\sqrt{\tfrac{2}{c^2 + 2 + c\sqrt{c^2 + 8}}},\ c\right)
= \frac{\sqrt{\frac{2}{c\, \sqrt{c^2 + 8} + c^2 + 2}}}{1 + \frac{2}{c\, \sqrt{c^2 + 8} + c^2 + 2}} + \frac{c}{\sqrt{1 + \frac{2}{c\, \sqrt{c^2 + 8} + c^2 + 2}}}$$ where $f(x, y) = \frac{x}{1+x^2} + \frac{y}{\sqrt{1+x^2}}$ . We immediately have the following results: The maximum of $\sum_{m=1}^n \frac{x_m}{1 + \sum_{k=1}^m x_k^2}$ is given by $$\underbrace{g\circ g \circ \cdots \circ g}_{n-1} \left(\frac{1}{2}\right).$$ Indeed, denote the maximum of $\sum_{m=1}^n \frac{x_m}{1 + \sum_{k=1}^m x_k^2}$ by $M(n)$ , and
we have $M(n) = g(M(n-1))$ . Also, $M(1)$ is equal to the maximum of $\frac{x_1}{1+x_1^2}$ which is $1/2$ . The desired result follows. A upper bound for $\sum_{m=1}^n \frac{x_m}{1 + \sum_{k=1}^m x_k^2}$ is $\sqrt{n}$ . We use mathematical induction. When $n=1$ , it is true.
Assume $\sum_{m=1}^n \frac{x_m}{1 + \sum_{k=1}^m x_k^2} < \sqrt{n}$ . We need to prove that $g(\sqrt{n}) < \sqrt{n+1}$ . It is true. Similarly, we can obtain $\sum_{m=1}^n \frac{x_m}{1 + \sum_{k=1}^m x_k^2} \le \sqrt{n} - \frac{1}{2\sqrt{n}}$ . However, this does not work for $\sum_{m=1}^n \frac{x_m}{1 + \sum_{k=1}^m x_k^2} < \sqrt{n}-\frac{\ln{n}}{2\sqrt{n}}$ since $g(\sqrt{n}-\frac{\ln{n}}{2\sqrt{n}}) < \sqrt{n+1}-\frac{\ln{n+1}}{2\sqrt{n+1}}$ is not true.","['inequality', 'upper-lower-bounds', 'summation', 'real-analysis']"
3923151,Looking for a function that approximates a parabola,"I have a shape that is defined by a parabola in a certain range, and a horizontal line outside of that range (see red in figure). I am looking for a single differentiable, without absolute values, non-piecewise, and continuous function that can approximate that shape. I tried a Gaussian-like function (blue), which works well around the maximum, but is too large at the edges. Is there a way to make the blue function more like the red function? Or, is there another function that can do this?","['approximation', 'conic-sections', 'gaussian', 'functions', 'quadratics']"
3923171,"Applying differential forms to non-vectors $\omega(X,Y)$","$\omega=2xdx\wedge dy + y^2dx\wedge dz$ $X=x^2y\frac{\partial}{\partial y} + x\frac{\partial}{\partial z}$ $Y=x\frac{\partial}{\partial y}$ Calculate $\omega(X,Y)$ I understand how to apply the differential form onto parameters given vectors $(v1,v2)$ , where you take  the determinant. Would I perform the same for this operation? I am trying this, but I'm not sure where to go from here. Should I be taking the partials as each parameter? $2xdet\begin{bmatrix}
0&0\\ x^2y&x\\ \end{bmatrix} + y^2det\begin{bmatrix}
0&0\\ x&0\\ \end{bmatrix} = 0$ I have looked through Do Carmo Differential Forms, and Faris' Vector fields and differential forms, but have not been able to find an explanation or example.","['exterior-algebra', 'differential-forms', 'differential-geometry']"
3923225,Generalisation of IMO 1990/P3:For which $b $ do there exist infinitely many positive integers $n$ such that $n^2$ divides $b^n+1$?,"For which positive integers $b > 2$ do there exist infinitely many positive integers $n$ such that $n^2$ divides $b^n+1$ ? It was from my LTE/ Zsigmondy handout. By taking examples, it looks like for $b= 2^k-1 , 2$ it's not true . Here's my progress: I got $b=4,5,6,8,9$ works ( $2,3,7$ doesn't ) $n$ is odd : If not then $4\mid b^n-1$ , but $b^n \equiv 0,1 \mod 4$ If $b+1$ is a power of $2$ and $n^2\mid b^n+1$ , then $n=1$ : Let $p$ smallest prime dividing $n$ ( note that it can't be $2$ ) . Then $n^2\mid b^{2n}-1 \implies p\mid b^{2n}-1 \implies p\mid b^{\gcd(2n,p-1)}-1 \implies p\mid b^2-1\implies p|b-1 \text{(since $b+1$ is power of $2$)}\implies p\mid b^n+1 \implies p|2.$ Contradiction. Any hints? Thanks in advance!","['contest-math', 'number-theory', 'elementary-number-theory']"
3923229,Deriving formula for curvature of a curve in $\mathbb{R}^n$,I am trying to prove that given a parametric function of a regular curve in $\mathbb{R}^n$ the curvature of the curve for each $\gamma(t)$ is given by the following expression : $$k(t)=\frac{\sqrt{||\gamma’(t)||^2||\gamma’’(t)||^2-(\gamma’(t)\cdot\gamma’’(t))^2}}{||\gamma’(t)||^3}$$ I have tried to use an arc-length parametrization of the curve but it leads me nowhere.,"['curvature', 'multivariable-calculus', 'parametric']"
3923283,"Convergence or divergence of the gaussian hypergeometric function $_{2}F_1(a,b;c;z)$ where $a,b$ and $c$ are complex.","I'm studying the convergence of the hypergeometric function and I have some questions. First, I define the hypergeometrical functions as \begin{equation}
_{2}F_{1} (a,b;c;z)=\displaystyle\sum_{n=0}^{+\infty}\dfrac{(a)_n(b)_n}{(c)_n}\dfrac{1}{n!}z^n,
\end{equation} where $(w)_n$ is the rising factorial and it is defined by \begin{equation}
(w)_n=\left\lbrace \begin{array}{cc}
1 & \text{for}~n=0\\
w(w+1)\cdots (w-n+1) & \text{for}~n\neq 0
\end{array}\right.
\end{equation} and the parameters $a$ , $b$ and $c$ are complex. Then, I know that: For $|z|=1,z\neq 1$ , we have that it is not absolutely convergent, but convergent for $0\leq \Re(a+b-c)<1$ . But I don't know how to prove that it is convergent there. Moreover, in this case, if $\Re(a+b-c)>1$ we obtain that it is divergent and if $\Re(a+b-c)=1$ and $\Re(a+b)\leq\Re(ab)$ it is also divergent. But I don't know again how to see it. Thanks a lot.","['complex-analysis', 'convergence-divergence', 'sequences-and-series']"
3923298,Matricial Cauchy-Euler equation,"It's well-known how to find, in theory, solutions to a Cauchy-Euler equation $$a_kt^k x^{(k)}(t)+\cdots + a_1tx'(t)+a_0x(t)=0:$$ one sets $x(t)=t^p$ , plug that into the equation, solves a (polynomial) characteristic equation for $p$ , and proceeds from there looking at the multiplicities of the roots. I believe I ran into a matrix version of that in $\Bbb R^n$ : $$t^k A_k {\bf x}^{(k)}(t)+\cdots+tA_1{\bf x}'(t)+A_0{\bf x}(t) = {\bf 0},$$ where the $A_i$ are square $n\times n$ matrices. Is there any known general method to attack this? Thanks.","['linear-algebra', 'ordinary-differential-equations']"
3923324,Maximum of N iid random random variables with Gumbel distribution,"I know that the maximum of iid random variables has Gumbel distribution. For example, this is true when iid random variables have Exponential distribution. Does this hold when iid random variables have Gumbel distribution themselves? Let's say there are $N$ iid random variables with distribution $X_n\sim Gumbel(\mu, \beta),~n=1,...,N$ . What is the distribution of $\text{max}_n~X_n$ ? If it is also a Gumbel distribution, say $Gumbel(\mu_{\text{max}}, \beta_{\text{max}})$ , how are parameters $\mu_{\text{max}}$ and $\beta_{\text{max}}$ related to $\mu$ and $\beta$ ? I tried to find an answer in multiple textbooks, but could not find anything.","['statistics', 'probability-distributions', 'probability', 'random-variables']"
3923330,Duality pairing between finite signed measures and bounded continuous functions,"Let $E$ be a metric space, $C_b(E)$ denote the set of real-valued bounded continuous functions on $E$ and $\mathcal M(E)$ denote the set of finite signed measures on $\mathcal B(E)$ . How can we show that $$\langle f,\mu\rangle:=\int f\:{\rm d}\mu\;\;\;\text{for }(f,\mu)\in C_b(E)\times\mathcal M(E)$$ is a duality pairing between $C_b(E)$ and $\mathcal M(E)$ ? Do we need impose further restrictions on $E$ (e.g. completeness and/or separability) and/or $\mathcal M(E)$ (e.g. regularity of the measures)? We need to show that \begin{align}\forall f\in C_b(E)\setminus\{0\}&:\exists\mu\in\mathcal M(E)&:\langle f,\mu\rangle\ne0\tag1;\\\forall\mu\in\mathcal M(E)\setminus\{0\}&:\exists f\in C_b(E)&:\langle f,\mu\rangle\ne0\tag2.\end{align} $(1)$ Should be easy. If $f\in C_b(E)\setminus\{0\}$ , there is a $x\in E$ with $f(x)\ne 0$ . Now we can choose $\mu$ to be the Dirac measure $\delta_x$ concentrated at $x$ and obtain $\langle f,\mu\rangle=f(x)\ne0$ . But how can we show $(2)$ ?","['probability-theory', 'functional-analysis', 'measure-theory']"
3923334,"Evaluate the triple integral $\iiint\limits_E\frac{yz\,dx\,dy\,dz}{x^2+y^2+z^2}$ using spherical coordinates","How to evaluate triple integral $$\iiint\limits_E\frac{yz\,dx\,dy\,dz}{x^2+y^2+z^2}$$ when $E$ is bounded by $x^2+y^2+z^2-x=0$ ? I know that spherical coordinates mean that $$x=r\sin\theta\cos\varphi,\quad y=r\sin\theta\sin\varphi,\quad z=r\cos\theta$$ and this function in spherical coordinates is \begin{align*}
&\iiint\limits_E\frac{yzdxdydz}{x^2+y^2+z^2} = \iiint\limits_E\frac{r^2\sin\theta}{r^2\sin^2\theta\cos^2\varphi + r^2\sin^2\theta\sin^2\varphi + r^2\cos^2\theta}drd\theta d\varphi = \\ &\iiint\limits_E\frac{r^2\sin\theta}{r^2(\sin^2\theta\cos^2\varphi + \sin^2\theta\sin^2\varphi + \cos^2\theta)}drd\theta d\varphi = \iiint\limits_E\frac{\sin\theta}{\sin^2\theta\cos^2\varphi + \sin^2\theta\sin^2\varphi + \cos^2\theta}drd\theta d\varphi
\end{align*} but I don't know how to write $E$ as set and convert it to spherical coordinates, and also what happens with this function after conversion. Triple integrals is now topic for me and I have never used spherical coordinates before, so I would be grateful if anyone can help me with this.","['integration', 'multivariable-calculus', 'spherical-coordinates', 'multiple-integral']"
3923351,"Why do elliptical copula densities contain $x_1$ and $x_2$, but Archimedean copula densities contain $u_1$ and $u_2$?","$$c\left(u_{1}, u_{2}\right)=\frac{1}{\sqrt{1-\rho_{12}^{2}}} \exp \left\{-\frac{\rho_{12}^{2}\left(x_{1}^{2}+x_{2}^{2}\right)-2 \rho_{12} x_{1} x_{2}}{2\left(1-\rho_{12}^{2}\right)}\right\}$$ is the copula density of the Gaussian copula, which is an elliptical copula , where $\rho_{12}$ is the parameter of the copula, $x_{1}=\Phi^{-1}\left(u_{1}\right), x_{2}=$ $\Phi^{-1}\left(u_{2}\right)$ and $\Phi^{-1}(\cdot)$ is the inverse of the standard univariate Gaussian distribution function. $$
c\left(u_{1}, u_{2}\right)=\left(1+\delta_{12}\right)\left(u_{1} \cdot u_{2}\right)^{-1-\delta_{12}} \times\left(u_{1}^{-\delta_{12}}+u_{2}^{-\delta_{12}}-1\right)^{-1 / \delta_{12}-2}
$$ is the copula density of the Clayton copula, which is an Archimedean copula ,
where $0<\delta_{12}<\infty$ is a parameter controlling the dependence. Perfect dependence is obtained when $\delta_{12} \rightarrow \infty,$ while $\delta_{12} \rightarrow 0$ implies independence. Question As you can see the elliptical copula density, despite being a function of $x_1$ and $x_2$ , has the actual random variables $u_1$ and $u_2$ on the right hand-side, whereas the Archimedean copula densities do not have $x_1$ and $x_2$ on the right hand side, but instead what we would expect from the function: $u_1$ and $u_2$ . This property seems to be a shared between all elliptical versus Archimedean copula densities. Why? Source of formulas: Aas et al 2009 ""Pair-copula constructions of multiple dependence""","['statistics', 'marginal-distribution', 'ellipsoids', 'marginal-probability', 'copula']"
3923358,Constructing triangle $\triangle ABC$ given median to the side $c$ and angles $\alpha$ and $\beta$,"Constructing triangle $\triangle ABC$ given median to the side $c$ and angles $\alpha$ and $\beta$ I started with the median. Then I constructed a circle to each side of the median, such that the circle is a set of all points which are the vertices of angle $\alpha$ and $\beta$ above the given segment (the median) respectively. Now, if I only could create a line segment $AB$ , such that it passes the point $C_1$ (the endpoint of the median and the middle point of side $AB$ ), each endpoint is on a different circle (to get the correct angles), and the line segments $AC_1$ and $C_1B$ are the same length ( $C_1$ is the endpoint of a median), I would be done. Any ideas?","['geometry', 'geometric-construction']"
3923376,Why is noncentral t-distribution for sample size determination for small sample?,"For sample size determination for small sample, population distribution of which is normal, the test statistic $$T = \frac{\bar{x}-\mu_0}{S/\sqrt{n}}, ~~~\text{where $\mu_0$ is null value}$$ is considered under the assumption of the alternative hypothesis $\mu = \mu' \gt \mu_0$ .
Since $T$ follows noncentral $t$ distribution, chart or table is used to determine sample size $n$ with desired type II error. The above is typical explanation available in statistics text books. Now I'm curious what's wrong with the following reasoning: If we assume that the alternative hypothesis $μ=μ′$ is correct $T = \frac{\bar{x} - \mu'}{S/\sqrt{n}}$ should follow $t$ -distribution by the same argument that $T = \frac{\bar{x} - \mu_0}{S/\sqrt{n}}$ follows $t$ -distribution when $μ=μ_0$ . Then we can proceed on to calculate $$
Pr(\frac{\bar{x}-\mu'}{S/\sqrt{n}} \leq \frac{\mu_0 + t_{\alpha, n-1}s/\sqrt{n} - \mu'}{s/\sqrt{n}}) = \beta(\mu')~~~\text{(*)}
$$ to determine sample size n that satisfies the required $\beta$ .
noncentral t-distribution cannot be involved at all. Specifically, if my assumption that $(\bar{x}-\mu')/(s/\sqrt{n})$ follows t distribution is correct, we can simply set: $$
\frac{\mu_0 + t_{\alpha, n-1}s/\sqrt{n} - \mu'}{s/\sqrt{n}} = t_{\beta(\mu')}
$$ and solve for $n$ . No need to summon noncentral t distribution, no need to use $\beta$ curve to find $n$ =================================================================
With help of @BruceET, I found my silly mistake. The equation to determine a rejection region is $$
Pr(\frac{\bar{x} - \mu_0}{S/\sqrt{n}} > t_{\alpha, n-1}) = \alpha
$$ From this I wrongly thought the rejection region in terms of $\bar{x}$ is $$
\bar{x} > \mu_0 + t_{\alpha, n-1}\frac{s}{\sqrt{n}}
$$ This is wrong because $s$ itself is a random variable and therefore cannot be included in the bounds. If it were, I could have argued the eq.(*) could be used to calculate power for the alternative hypothesis.","['statistical-inference', 'statistics']"
3923440,Approximating a double sum by a double integral,"Related to this question , I'm interested in bounding from above the following sum $$
S:=\sum_{x=0}^\infty \sum_{y=0}^\infty (x+y)^m e^{-\frac{x^2}{2i} - \frac{y^2}{2j}},
$$ which I hope to do by relating it to the integral $$
I:=\int_0^\infty \int_0^\infty (x+y)^m e^{-\frac{x^2}{2i} - \frac{y^2}{2j}} dx\,dy.
$$ Answers to the previous questions confirmed my expectation that $I = O\left(\exp\left(m\log\sqrt{(i+j)(m)}-\frac{m}{2}\right)\sqrt{ij}\right)$ , the intuition for which is probably that the function behaves approximately like a gaussian around its maximum at $(x_0,y_0) = \left(i \sqrt{\frac{m}{i+j}},j \sqrt{\frac{m}{i+j}} \right)$ , where the function takes the value $\exp\left(m\log\sqrt{(i+j)(m)}-\frac{m}{2}\right)$ . However I've been unable to show that the difference $|I-S|$ is significantly smaller than this bound. For simple one dimensional integrals, for example with a unique maximum, it's not too hard to bound this difference in terms of the maximum by considering appropriate telescoping sums. However, a naive analogue of this argument doesn't seem to work in two dimensions, and trying to apply this argument to each `slice' of the integral led to some pretty horrendous calculations. I also looked into using the Euler-Maclaurin formula but it's a bit out of my area of expertise. I suspect that there should be a relatively standard way to approximate $|I-S|$ , and I also wouldn't be surprised if someone more proficient in computing can get a CAS to provide a proof. The former would be more useful, just so that I have a tool for approaching similar questions. So, very explicitly, I would like to know if $$
|I-S| = o\left(\exp\left(m\log\sqrt{(i+j)(m)}-\frac{m}{2}\right)\sqrt{ij}\right),
$$ where even big-O would be sufficient for the application I have in mind, and I wouldn't be surprised if the difference is even bounded by a multiple of the maximum of the function. I'm interested in the asymptotics for $i$ and $j$ tending to infinity, $m$ can be fixed or also a function of $i$ and $j$ . For the application I have in mind it would probably be sufficient to have such a result for $i = (1+o(1))j$ and $m = o(i)$ .","['multiple-integral', 'asymptotics', 'real-analysis']"
3923453,Can we take the exponential function of a vector?,"Main question: If $x=(x_1,x_2)\in \mathbb R^2$ , can we have the exponential function of the vector, i.e. $$
e^{i \pi x}=e^{i \pi (x_1,x_2)} \quad? \tag 1
$$ Follow-up question: Can we in some way ""split"" $e^{i \pi (x_1,x_2)}$ ?
I'm thinking of the rule the $e^{ia}e^{ib}=e^{i(a+b)}$ , where $a,b\in \mathbb R$ . A test, if we use the standard basis and write the vector as $$
x=(x_1,x_2)=\hat e_1 x_1+\hat e_2x_2 \tag 2
$$ Can we now write $(1)$ as \begin{align}
e^{i \pi (x_1,x_2)} &=
e^{i \pi (\hat e_1 x_1+\hat e_2x_2)}  \tag 3\\
&=
e^{i \pi (\hat e_1 x_1)}
e^{i \pi (\hat e_2 x_2)}
\quad? \tag 4
\end{align} Is this legitimate?","['multivariable-calculus', 'functions', 'linear-algebra', 'vectors']"
3923464,"What does $\Gamma$ notation (as in ""$A=\Gamma(x_1)$"" for a vertex $x_1$) mean in graph theory?","I was looking at a proof for Let $G$ be a connected graph of order $n$ and $\delta(G) \geq k/2$ for some integer $k < n$ . Then $G$ contains a simple path of length $k$ . which is Lemma 4 (page 4) in Heng Guo's lecture notes ""Forbidden Paths and Cycles"" (PDF link via ed.ac.uk) . I was confused by this notation: ... Since $P$ is a maximal path, the neighbours of $x_0$ and $x_\ell$ must be all inside $P$ . Let $$A = \Gamma(x_1), \quad B = \{x_{i+1} : x_i \in \Gamma(x_\ell)\}$$ Any help would be greatly appreciated.","['graph-theory', 'notation', 'combinatorics']"
3923613,Unique property of differentiable functions,"Recently I was going through the chain-rule derivative proof in Stewart Calculus - It's a great approach to avoid the objections of $\Delta$$u$$=0$ . But I don't understand why do we need to prove that $\epsilon$ is a continuous function of $\Delta$$x$ . The book claims it to be a property of a differentiable function, but what is the significance of this property and how are we helped here by using it? Also, does it really help in some later stages of calculus? If so, then how? It'd be really helpful if someone pointed out why it was necessary to use $\epsilon$ as a continuous function here.","['derivatives', 'chain-rule']"
3923658,"Using Stone-Weierstrass theorem prove that $f\equiv 0$ in $[0,1]$ under certain conditions.","Let $f$ be a continuous function over $[0,1]$ and $\displaystyle \int_0^1 f(x)\,dx=0$ . If for any positive integer $n$ , $\displaystyle \int_0^1 x^{12+3n}f(x)\,dx=0$ then using Stone-Weiersterass Theorem prove that $f\equiv 0$ in $[0,1]$ . Since $f$ is contnuous on $[0,1]$ so by Stone-Weierstrass Theorem there exists a sequence of polynomials $\{p_n(x)\}_n$ which converges uniformly to $f$ on $[0,1]$ .  That is  , $p_n\to f$ , implies $p_n(x)f(x)\to f^2(x)$ as $n\to \infty$ , which implies that $\displaystyle \int_0^1p_n(x)f(x)\,dx \to \int_0^1 f^2(x)\,dx$ . But from the given condition I can't say that $\displaystyle \int_0^1 f^2(x)\,dx =0$ . So how to proceed to solve this problem ? Any hint. please.","['weierstrass-approximation', 'analysis', 'real-analysis', 'polynomials', 'functional-analysis']"
3923692,Converse of Napoleon's Theorem,"Consider a fixed scalene triangle $ABC$ together with a point $X$ in the semiplane determined by $BC$ opposite to $A$ , a point $Y$ in the semiplane determined by $AC$ opposite to $B$ and a point $Z$ in the semiplane determined by $AB$ oppocite to $C$ . Suppose that $\Delta AYC$ , $\Delta CXB$ and $\Delta BZA$ are similar triangles (in that order) and moreover $\Delta XYZ$ is equilateral. Is it true that the angles of $\Delta CXB$ are $30°$ , $120°$ and $30°$ ?","['contest-math', 'euclidean-geometry', 'geometry', 'plane-geometry']"
3923697,"Name and reference for ""ultra holomorphic"" functions","Any holomorphic function $f : U\to \mathbb{C}$ from a domain $U\subset\mathbb{C}$ induces a real-analytic mapping $f(x+iy)=u(x,y)+iv(x,y)$ which as such induces by complexification of $x,y$ and $u,v$ a holomorphic mapping $f^* : U^* \to \mathbb{C}^2$ for some domain $U^*\subset  \mathbb{C}^2$ . Of course the construction can be iterated to produce mappings $f^{*\cdots *}$ in $2^n$ complex variables for any $n\in \mathbb N$ . I guess that  such ""ultraholomorphic"" functions have a standard name in the litterature, perhaps related to terms like Cauchy-Riemann but I wasn't able to find anything in my search engine. Is there some classic reference I should be aware of? Is there some nice/surprising property of $f^*$ (except the obvious real+Cauchy-Riemann)?","['complex-analysis', 'several-complex-variables', 'reference-request']"
3923700,Proof that the minimum of a bounded differentiable real function occurs at a stationary point or at an endpoint,I couldn't find a proof for this well-known result on this site... The minimum of a bounded differentiable real function occurs at a stationary point or at an endpoint. I prove the contrapositive to this statement in my answer below. Alternative proofs are most welcome.,"['solution-verification', 'derivatives', 'real-analysis']"
3923727,Finding the $p$-value from Bernoulli hypothesis test,"So I'm told that $X_i \sim Bern(p)$ , $Y = \sum_{i=1}^N X_i$ and $H_0: p \geq 0.5$ vs $H_1: p < 0.5$ with $\alpha = 0.05$ . I have to find the $p$ -value at $n=30$ and $y=5$ . I'm not sure if this correct, but I figured the $p$ -value was simply: $$P(Y \leq 5) = \sum_{i=1}^5 \binom{30}{y}(0.5)^y (0.5)^{30-y}$$ which works out to be $0.00016$ . If this is correct, then why have I been given $\alpha$ ?","['p-value', 'statistics', 'hypothesis-testing']"
3923734,"Is there $m,n \in \mathbb Z$ satisfies $m \arctan \frac{1}{2}+n \arctan \frac{1}{5}=\frac{\pi}{4}$?","I know that $\arctan \frac{1}{2}+\arctan \frac{1}{3}=\frac{\pi}{4}$ and $2\arctan \frac{1}{2}-\arctan \frac{1}{7}=\frac{\pi}{4}$ . Is there $m,n \in \mathbb Z$ satisfies $m \arctan \frac{1}{2}+n \arctan \frac{1}{5}=\frac{\pi}{4}$ ?","['trigonometry', 'pi']"
3923743,Is $(4+\sqrt{5})$ a prime ideal of $\mathbb{Z}[\sqrt{5}]$?,"Consider the integral domain $\mathbb{Z}[\sqrt{5}]$ . Is $(4+\sqrt{5})$ a prime ideal of $\mathbb{Z}[\sqrt{5}]$ ? I do not know the answer, so any help is welcome. Note that $4+\sqrt{5}$ is an irreducible element of $\mathbb{Z}[\sqrt{5}]$ , since its norm $N(4+\sqrt{5})=11$ is a prime number (here as usual $N(a+b\sqrt{5})=a^2-5b^2$ for every $a, b \in \mathbb{Z}$ ). Anyhow $\mathbb{Z}[\sqrt{5}]$ is not a unique factorization domain, as it can be easily seen from the following factorizations $4=2 \cdot 2 = (3+\sqrt{5})(3-\sqrt{5})$ . So the question is not so trivial, at least for me!","['ring-theory', 'abstract-algebra', 'algebraic-number-theory']"
3923762,Where $Arg(z)$ is differentiable?,"Let $f(z)=Arg(z)$ denotes the principal argument of $z$ . If $f(z)=u(x,y)+iv(x,y)$ , then for $x\neq0$ , we obtain that $u(x,y)=\arctan(y/x)+\{-\pi,0,\pi\}$ and $v(x,y)=0$ , so $$
u_x(x,y)=-\frac{y}{x^2+y^2}\quad
u_y(x,y)=\frac{x}{x^2+y^2}
$$ and $v_x(x,y)=v_y(x,y)=0$ . Hence, the Cauchy Riemann equations does not hold unless $(x,y)=(0,0)$ . Therefore $f$ is not differentiable at every point with $x\neq0$ . Comment: we say that $f$ is differentiable at $z_0$ if the following limit exists $$
\lim_{z\to z_0}\frac{f(z)-f(z_0)}{z-z_0}
$$ (a) What about differentiable in points with $x=0$ ? (b) How to prove that $f(z)=Arg(z)$ is not differentiable without using the Cauchy Riemann equations?",['complex-analysis']
3923797,"Bessel function, characteristic function, semicircle distribution","I am trying to prove that $\dfrac{1}{x} J_1(2x)$ , where $J_n$ is the Bessel function of order n, is the characteristic function of the semicircle distribution, i.e. $σ(x)=\dfrac{1}{2π}\sqrt{4-x^2} 
 \textbf{1}_{|x|<2} $ . Basically, I would like to calculate the integral $$\dfrac{1}{2π} \displaystyle\int_{\mathbb{R}}{\dfrac{1}{t}J(2t)}e^{-itx} dt $$ So, I do not want to calculate the characteristic equation of $σ$ , I want to find $σ$ when I am given the characteristic function. I have tried some integral forms of $J_1$ but can't seem to find what I am looking for. Any hints?","['integration', 'probability', 'bessel-functions']"
3923822,Calculating limit of series.,"Given a series $\sum_{n=1}^{\infty}\frac{4n+1}{2n(2n-1)(2n+1)(2n+2)}$ , how do I find the limit? I understand I need to find the sequence of partial sums, which goes something like this $s_n=\{\frac{5}{24}, \frac{7}{30}, \frac{27}{112}....\}$ which will probably converge at 0.25, but I am having trouble finding a description of the sequence on which I could evaluate the limit.","['limits', 'convergence-divergence', 'sequences-and-series', 'real-analysis']"
3923833,Does $\sqrt{1+\sqrt{2}}$ belong to $\mathbb{Q}(\sqrt{2})$?,"Does $\sqrt{1+\sqrt{2}}$ belong to $\mathbb{Q}(\sqrt{2})$ ? We know the answer is of the form $ a + b \sqrt{2}$ . Since $(a + b\sqrt{2})^2 = a^2 + 2ab\sqrt{2} + 2b^2 = 1 + \sqrt{2}$ , the system we need to solve is \begin{align*} 
2ab &=  1 \\ 
a^2 + 2b^2 &=  1
\end{align*} We write $b = \frac{1}{2a}$ and substitute this in the second equation. \begin{align*} 
a^2 + 2\left(\frac{1}{2a}\right)^2 &=  1 \\
a^2 + \frac{1}{2a^2} &=  1 \\
2a^4 - 2a^2 + 1 &= 0
\end{align*} Let $z = a^2$ , so $z^2 = a^4$ . The equation is then \begin{equation} 
2z^2 - 2z + 1 = 0
\end{equation} Using the quadratic formula we find $z = \frac{1 \pm i}{2}$ . This worked out when checked. Thus $a = \sqrt{\frac{1 \pm i}{2}}$ .
We then find $b$ using $a$ in our original system of equations. \begin{align*} 
\frac{1 \pm i}{2} + 2b^2 &=  1 \\
1 \pm i + 4b^2 &=  2 \\
\pm i + 4b^2 &=  1 \\
4b^2 &=  1 \pm i \\
2b &=  \sqrt{1 \pm i} \\
b &=  \frac{\sqrt{1 \pm i}}{2} \\
\end{align*} Substituting $a$ and $b$ into the equation $2ab = 1$ , leads to inconsistent solutions.
What do I need to reconsider? How can I improve my answer?","['algebra-precalculus', 'quadratics']"
3923852,How to solve a third order nonlinear ODE (Falkner-Skan wedge equation),How can I solve the following ODE numerically $$F'''+FF''+1-F'^2=0$$ $$F(0)=F'(0)=0\qquad F'(\infty)=1$$ Thank you.,"['numerical-methods', 'ordinary-differential-equations']"
