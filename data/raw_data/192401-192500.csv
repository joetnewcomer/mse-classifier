question_id,title,body,tags
3666327,"Prove. $\lim_{x \to 2} \frac{x+3}{x-1} = 5$, from first princibles.","I am a student and I'm practising proving limits from first principles. I've been asked the question above, I have attempted an answer, but any tips or tricks anyone has to prod me in the right direction would be much appreciated! Firstly I fix $\epsilon > 0$ and fing $\delta > 0$ such that. $$0< |x-2| < \delta \implies \bigg| \frac{x+3}{x-1} -5 \bigg|<\epsilon$$ $$\impliedby \bigg|-\frac{4(x-2)}{x-1} \bigg|$$ $$\impliedby \bigg|\frac{4(x-2)}{x-1} \bigg|$$ $$\impliedby \frac{4}{|x-1|}|x-2| $$ Let $|x-2| < 1$ then $-1 < x-2 < 1$ or $0<x-1<2$ Let $\epsilon >0$ be given. Choose $\delta = min(1,\frac{\epsilon}{2}$ ) Then $|x-2|< \delta \implies \frac{4}{|x-1|}|x-2| < 2\delta \leq \epsilon  $ Thanks for your time!","['limits', 'solution-verification', 'real-analysis']"
3666348,"Solve the matrix equation $X ^ 3 = A$, with $X \in M_2(\mathbb{R})$ and given $A$.","I have to solve the matrix equation: $$X^3 = A$$ where $$A = \begin{pmatrix}
2 & 1\\
1 & 2
\end{pmatrix}$$ So in the end I have to solve: $$X^3 =  \begin{pmatrix}
2 & 1\\
1 & 2
\end{pmatrix}$$ Since we have $2$ x $2$ matrices I tried the following: $$X ^ 3 = A$$ $$\det(X^3) = \det(A)$$ $$\det(X)^3 = 3$$ $$\det(X) = \sqrt[3]{3}$$ I did this in hopes that it would result in the determinant of $X$ being $0$ so then I could've used the Cayley-Hamilton identity : $$X^2 - tr(X) X + det(X) I_2 = O_2$$ where $tr(x) = (a + d)$ (trace of the matrix). But since the determinant is not $0$ , I can't abuse that, it looks complicated since that last term does not get canceled. Then I tried to use the notation: $$X = \begin{pmatrix}
a & b\\
c & d
\end{pmatrix}$$ and to do the multiplication $X \cdot X \cdot X$ and then to equate it to $A$ and try to find $a, b, c, d$ but the algebra got very ugly very fast and I lost myself in the calculations. So how should I approach this?","['matrices', 'matrix-equations']"
3666385,prove that $3(a+b+c) \geq 8(a b c)^{1 / 3}+\left(\frac{a^{3}+b^{3}+c^{3}}{3}\right)^{1 / 3}$,"Question - Suppose a,b,c are positive real numbers , prove that $3(a+b+c) \geq 8(a b c)^{1 / 3}+\left(\frac{a^{3}+b^{3}+c^{3}}{3}\right)^{1 / 3}$ (Thailand $2006$ ) My attempt - we can assume that $a+b+c=1$ so we have to prove that $3 \geq 8(a b c)^{1 / 3}+\left(\frac{a^{3}+b^{3}+c^{3}}{3}\right)^{1 / 3}$ but i am not able to show that it is true.. then i tried some AM-GM on RHS but none of them work,
i think this is most different inequalities i have came across so i did not know where to go . any help will be appreciated thankyou","['contest-math', 'uvw', 'multivariable-calculus', 'inequality', 'holder-inequality']"
3666392,Probability zero vs impossible,"I understand that probability $0$ does not mean 'impossible' - because if we look for instance at a uniform distribution over $[0, 1]$ then while each of the singleton events $\{r\}$ for $0\leq r \leq 1$ has probability $0$ , if we carried out the experiment then we would get exactly one of the numbers in $[0,1]$ , and so these events are not actually impossible, even though they have probability $0$ . However, if we look at a distribution defined by a density function which is zero on $[0,\frac{1}{2}]$ and non-zero on $(\frac{1}{2},1]$ (let's say with a continuous transition between them), then we know that for any $0\leq r\leq \frac{1}{2}$ the event $\{r\}$ is impossible, and for $\frac{1}{2}<r\leq 1$ the event is possible, yet still has probability $0$ . Both have probability $0$ , but one of them is possible, and the other is not. Is there a definition that captures this distinction between the two cases?","['probability-distributions', 'probability-theory', 'probability']"
3666438,Proving pivotal quantity has given form and using it to get the confidence interval,"This is a homework which I don't know how to solve. All other examples of pivotal quantities examples I've tackled were relatively easy, this one though seems hard. Suppose $\rm{X}=(X_1, \dots, X_m)$ and $\rm{Y}=(Y_1, \dots, Y_n)$ are samples from $N(\mu_1, \sigma_1^2)$ and $N(\mu_2, \sigma_2^2)$ respectively. Let $\sigma = \sigma_1^2 = \sigma_2^2$ , $\theta = (\mu_1, \mu_2, \sigma)$ and $g(\theta) = \mu_2 - \mu_1$ . Prove that pivotal quantity of $g(\theta)$ has the form of $$
\frac{\overline{Y}-\overline{X}-g(\theta)}{\sqrt{\frac{(m-1)S_X^2+(n-1)S_Y^2}{n+m-2}}\sqrt{\frac{1}{m}+\frac{1}{n}}}
$$ where as usual $S_X^2 = \frac{\sum_1^mX_i-\overline{X_i}}{m-1}$ , $\overline{X} = \frac{\sum_i^nX_i}{m}$ . Use the pivotal quantity to approximate confidence interval of $g(\theta)$ with confidence $1 - \alpha$ . I've got a couple of hints from my professor: for $Z \sim N(0,1)$ and $Y \sim \chi^2_n$ we know $X = \frac{Z}{\sqrt{Y/n}}$ has t-Student distribution with n d.o.f. for $X_i \sim N(0,1)$ we have $\sqrt n (\overline X - \mu)/\sigma \sim N(0,1)$ and $(n-1)S^2/\sigma^2 \sim \chi^2_{n-1}$ I tried playing with the equations but that led me nowhere. I assume I should somehow find the forms shown in the second hint and then move on to the first one. Any help greatly appreciated.","['statistics', 'normal-distribution', 'probability']"
3666464,What is an example function of a transitive yet non-reflexive and non-symmetric relation?,"If I were to come up with a function $f: \mathbb{N} \to \mathbb{N}$ that makes relation $R_a$ transitive yet non-reflexive and non-symmetric such that $$q \, R_a \, z  \text{ if } f(q) = z,$$ what kind of function should I come up with? I spent the past three hours trying to come up with one but I still don't understand how inputting one number can produce two different results... Do I need to use a piecewise? Because isn't it transitive when you input $1$ and by some relation, you then get $2$ .
Then when you input $2$ into that relation you get $3$ . 
Because of transitivity $1$ now should also produce $3$ . This makes no sense to me...",['functions']
3666522,Non-isomorphic elliptic curves with the same j-invariant.,"Two elliptic curves over finite field F with the same j-invariant are isomorphic over the algebraic closure of F. But they do not have to be isomorphic over F itself. I'm looking for example of such situation. 
Here is example for Q: J-invariant and isomorphism of elliptic curves over $\mathbb{Q}$ I would like to see example for finite field.
There is no example in Blake-Seroussi-Smart book I own.
Thanks in advance.","['number-theory', 'algebraic-number-theory', 'elliptic-curves']"
3666567,All functions such that $\lim_{n\to \infty} \int_n^{n+\frac 1n} f(x)dx$ is a non-zero finite value,"I’m interested in finding all functions $f(x)$ (if any), such that $$\lim_{n\to \infty} \int_n^{n+\frac 1n} f(x)dx$$ is a finite non-zero value. Let’s try evaluating this limit for a few functions that one would expect to follow this property. All I could deduce was that $\lim_{x\to \infty} f’(x) \ne 0$ otherwise our limit would be zero. $$\int_n^{n+\frac 1n} x^2 \ dx = \frac13 \left[ \left(n + \frac 1n \right)^3 - n^3\right] \\ = \frac{3n^2 + 3+ \frac{1}{n^2}}{3n}$$ It’s easy to see that the limit of this diverges to $\infty$ . $$\int_n^{n+\frac 1n} \sqrt x \ dx = \frac 23 \cdot \frac{3n + \frac 3n + \frac{1}{n^3}}{\left(n + \frac 1n \right)^{\frac 32} + n^{\frac 32} } $$ This time, the limit goes to $0$ . So, there must be one (or more than one?) value of $k$ with $\frac 12 \lt k \lt 2$ such that $f(x)=x^k$ satisfies our property. I saw that $\lim_{n\to \infty} \int_n^{n+\frac 1n} x \ dx = 1$ Are there other such functions? Can this be generalized?","['integration', 'limits', 'calculus']"
3666602,Trouble with Poisson integral,"I'm continuing my studies about the space $\mathbb{T}$ and I reach the point in which are introduced the Harmonic functions. Well up to now I have a little trouble with understanding the Poisson's integral. I know that this particular integral is defined as: DEF: If $\mu\in\ M(\mathbb{T})$ we define the Poisson integral of $\mu$ by the expression for $z= re^{i\theta}$ : $P(\mu)(z)=\int_{-\pi}^{\pi}P(ze^{-it})d\mu (t)$ . Now to understand better how to use it, I am trying doing some exercise about this Poisson integral. In particular, I'm trying to calculate $P(\mu)$ for this two cases: For $\mu=\delta_{0}-\delta_{\pi/2}$ where $\delta_{x}$ is the Dirac measure for the points $d\mu=D_{N}(t)dm(t)$ where $D_{N}$ is the kernel of Dirichelet. I've tried to apply directly my definition but something goes wrong! Can someone help me?","['integration', 'harmonic-functions', 'harmonic-analysis', 'poisson-integrals', 'complex-analysis']"
3666657,forward - backward differencing = central differencing,"From Taylor series, we can derive: Forward Differencing Formula: $$ f'(x_{i}) = \frac{f(x_{i+1}) - f(x_{i})}{h} - \frac{f''(x_{i})h}{2!} $$ $$\tag 1 f'(x) \approx \dfrac{f(x+h)-f(x)}{h}$$ (1) Backward Differencing Formula: $$ f'(x_{i}) = \frac{f(x_{i}) - f(x_{i-1})}{h} + \frac{f''(x_{i})h}{2!} $$ $$\tag 1 f'(x) \approx \dfrac{f(x)-f(x-h)}{h}$$ (2) I know that in order to calculate the central differencing formula, we subtract (2) from (1). However, I am unable to do the subtraction properly. I must obtain an error term consisting of 1/6 after the subtraction, along with the central differencing formula. However, I just get 2f(x+h).... which is wrong. A step by step subtraction would be really helpful.","['truncation-error', 'taylor-expansion', 'numerical-calculus', 'numerical-methods', 'derivatives']"
3666704,Spivak Calculus. Why is the books proof valid? Is my attempt at a proof valid?,"Here is the problem. If f and g are continuous and $f(x)\ge g(x)$ for all x in a dense set A, prove that $f(x)\ge g(x)$ for all x. Here is the proof I gave on my own attempt. I will prove $f(x)\ge 0$ for all x using $f(x)\ge0$ for all x in A. Now in an earlier problem I already proved that if $f(x)=0$ for all x in A, then $f(x)=0$ for all x. So I only need to prove it for the case $f(x)\gt0$ . Since f is continuous, for all $\epsilon\gt0$ there is some $\delta\gt0$ such that for all $x$ if $$\vert x-a \vert \lt \delta$$ then, $$\vert f(x)- f(a) \vert \lt \epsilon.$$ So there is some $a\in A$ in the interval $(x-\delta, x+\delta)$ since A is dense. Choosing $\epsilon=f(a)$ we obtain $$-f(a)\lt f(x)-f(a).$$ So $f(x)\ge0$ for all x. Applying this to the funtion $f(x)-g(x)$ we get the desired solution. Now here is the books solution. It suffices to show that if $f$ is continuous and $f(x)\ge0$ for all x in A, then $f(x)\ge0$ for all x. Now there is a $\delta\gt0$ such that, for all x, if $$0\lt \vert x-a\vert \lt\delta,$$ then $$\vert f(x)-l \vert \lt \frac{\vert l \vert}{2}.$$ This implies that $$f(x)\lt l+ \frac{\vert l \vert}{2}.$$ Now if $l\lt0$ , it would follow that $f(x)\lt0$ , which would be false for those x in A which satisfy $0\lt \vert x-a \vert \lt \delta$ . So this brings me to my questions. Why is his proof correct? Couldn't $\frac{\vert l \vert}{2}=0$ ? Then it would not be an $\epsilon \gt0$ . And also is my proof correct? I am guessing I did something wrong since it seems much cleaner than the one he gave and I would assume he would have used it if it is correct.","['calculus', 'real-analysis']"
3666707,Frobenius between $\mathbb{Z}_p[p^{1/p^m}]$-modules etale,"The questions are motivated by P. Scholze's answer in MO question https://mathoverflow.net/questions/132438/why-is-faltings-almost-purity-theorem-a-purity-theorem . Consider for every $m \in \mathbb{N}$ and $p$ prime the rings $$A_m = \mathbb{Z}_p[p^{1/p^m},T^{\pm 1/p^m}]$$ Each $A_m$ is a $R_m:= \mathbb{Z}_p[p^{1/p^m}]$ -algebra given by canonical inclusion $$i_m:\mathbb{Z}_p[p^{1/p^m}] \to \mathbb{Z}_p[p^{1/p^m},T^{\pm 1/p^m}]$$ We can also endow the $R_m$ with transition maps $t_{mn}: R_m \to R_n$ for $m >n$ induced by iterations of the canonical inclusions: $$t_{m,m+1}: \mathbb{Z}_p[p^{1/p^{m}},T^{\pm 1/p^{m}}] \to \mathbb{Z}_p[p^{1/p^{m+1}},T^{\pm 1/p^{m+1}}]$$ I have some questions about the properties of $i_m$ and $t_{mn}$ . Question I Why is $i_m$ is a smooth ring map? What might be the most elegant/ conventional/standard way to show smoothness of $i_m$ in this question? One criterion for smoothness I'm familar with is that a morphism of schemes $f: X \to Y$ is smooth iff it is flat and all geometric fibers are smooth. That's a very general criterion working for arbitrary schemes. Here $i_m$ induce a morphism $\operatorname{Spec} \ A_m \to \operatorname{Spec} R_m$ between affine schemes, so I hope that in this case there is a more ""simple"" way to show smoothness without passing explicitely to the $\operatorname{Spec}$ structure and for example not to talking about geometric fibers? In my searching I found in Stacks this: https://stacks.math.columbia.edu/tag/00T1 They are working with the concept of cotangent complex and the criterion/definition Definition 10.136.1 requiring to check quasi-isomorpism looks not really more accesible than the criterion above. Question II: Why the transition maps $t_{m+1,m}$ are etale after inverting $p$ ? ie when we invert $p$ in $R_m$ or localize $R_m$ at $p$ we obtain $(R_m)_p:=\mathbb{Z}_p[p^{ \pm 1/p^m},T^{\pm 1/p^m}]$ , right? So the question boils down why is the induced Frobenius $$(t_{m,m+1})_p: (R_{m})_p \to (R_{m+1})_p$$ etale? One criterion for etaleness (that I know) is flat and unramified. On flatness I have no idea, on ramification we have to show that the discriminant ideal becomes unit ideal after interting $p$ . The proplem is I haven't here an ideal how to calculate the discriminant ideal of $R_m$ .","['algebraic-number-theory', 'p-adic-number-theory', 'algebraic-geometry', 'arithmetic-geometry']"
3666725,Help solving shallow water equations initial value problem?,"The question is as followed: ""Consider the initial value problem (IVP) for the linearised shallow water equations (1) $\frac{\partial h}{\partial t} + H_0 \frac{\partial u}{\partial x} = 0$ ; (2) $\frac{\partial u}{\partial t} + g \frac{\partial h}{\partial x} = 0$ With the initial conditions $h(x,0)=h_0$ ; $u(x,0)=0$ ; for $-\infty<x<\infty$ Specify the function $h_0(x)$ and find the corresponding solution to the IVP. "" Now I have attempted this to the best of my ability, but this topic was one which we were not formally taught due to the current circumstances meaning that my knowledge is entirely from a set of typed notes which only show how the linearised equations are generated and not how they are solved. Firstly I realised that differentiating equation (2) w.r.t. $t$ and then substituting the expression for $\frac{\partial h}{\partial t}$ gives and expression in the form of the wave equation: $u_{tt}-c^2u_{xx}=0$ where $c^2=gH_0$ The same can be done to equation (1) w.r.t. $x$ to give the wave equation: $h_{tt}-c^2h_{xx}=0$ where $c^2=gH_0$ . I have found examples on how to solve the wave equation assuming the solution is in the form $u(x,t)=p(x-ct)+q(x+ct)$ when given initial conditions $u(x,0)=u_0(x)$ and $u'(x,0)=a_0(x)$ but I cannot understand how to do it with only $u(x,0)$ and $h(x,0)$ provided? Any tips would be greatly appreciated. Edit: I have since found that you can deduce that $h_t(x,0)=0$ given that $u(x,0)=0$ . Can anyone confirm this?","['ordinary-differential-equations', 'wave-equation', 'partial-differential-equations', 'derivatives', 'fluid-dynamics']"
3666775,Finding product of $n$ numbers in circle using minimal number of questions about 3 of them,"Each of $n$ tablets lined on a circle is marked by a number $1$ or $-1$ . What is the minimum number of questions you should ask to determine the product of all $n$ numbers ( $n \in \mathbb{N}$ , $n > 3$ ), if one question is allowed to know the product numbers of any three tablets? any three tablets placed in a row? I converted this problem to problem in $GF(2)$ and suspect that number of questions $Q(n)$ is $$Q(n) = \begin{cases}
    \frac{n}{3},& \text{if } n \equiv 0 \mod 3\\
    \lfloor{\frac{n}{3}\rfloor}+3, & \text{if } n \not\equiv 0 \mod 3
\end{cases} $$ for the first case. And $$Q(n) = \begin{cases}
    \frac{n}{3},& \text{if } n \equiv 0 \mod 3\\
    n, & \text{if } n \not\equiv 0 \mod 3
\end{cases} $$ for second case. But I'm not sure if it is a correct result and how to prove it's optimality.","['discrete-mathematics', 'algorithms']"
3666794,Do the lim sup and lim inf always exist?,"Let's focus on the $\lim \inf$ . While trying to prove that the $\lim \inf$ always exists, [this page] https://mathcs.org/analysis/reals/numseq/proofs/lub_ex.html established that the sequence $A_j = \inf\{a_j, a_{j+1}, \dots\}$ is monotone increasing then the $\lim \inf$ exists even though it may be possibly infinite. My question is that if we define the limit of a sequence as a real number as [the same page] https://mathcs.org/analysis/reals/numseq/sequence.html has done then how do we reconcile this definition to allow for ""a limit that is infinite""?","['limsup-and-liminf', 'real-analysis', 'sequences-and-series', 'limits', 'convergence-divergence']"
3666824,How we calculate the asymptotes of a general hyperbola?,"I was reading about the asymptotes of the following hyperbola: $$\frac{x^2}{a^2} - \frac{y^2}{b^2} = 1 \quad \quad (1)$$ and the book said that the inclined asymptotes are $ y = \pm \frac{b}{a} x $ and the book mentioned that you can find them by setting the RHS of eqn.(1) equal to $0$ but I do not know why we should do this, Could anyone explain this for me please? Also, I know that the correct way of finding the inclined asymptote (y = mx + c) for a function $f(x)$ is that if this line satisfies $$\lim_{x \to \pm \infty} [f(x) -  (mx + c)] = 0.$$ Then it is an asymptote. but I do not know how we found that line in the case of the hyperbola mentioned above. could anyone explain this for me please?","['multivariable-calculus', 'calculus', 'conic-sections']"
3666890,Conditional Probability: Papoulis/Pillai Ex 2-13,"Question: A box contains white and black balls. When two balls are drawn without replacement, suppose the probability that both are white is 1/3. (A) Find the smallest number of balls in the box. Solution from the text: Let a and b denote the number of white and black balls in the box, and $W_k$ the event $W_k=$ “a white ball is drawn at the k th draw” We are given that $ P(W_1 \cap W_2) = 1/3 $ . It follows that $$\begin{align} P(W_1 \cap W_2) &= P(W_2 \cap W_1)\\ &= P(W_2 | W_1)P(W_1)\\&=\frac{a-1}{(a-1)+b}\frac{a}{a+b}\\&=1/3 \;\tag1\end{align}$$ The author goes on to state the following: Because $b > 0$ , $$\frac{a}{a+b} > \frac{a-1}{(a-1)+b}$$ We can rewrite $(1)$ as $$\left(\frac{a-1}{(a-1)+b}\right)^2 <  1/3 < \left(\frac{a}{a+b}\right)^2 \: \tag2$$ Which gives the inequalities $$ (\sqrt{3} + 1)b/2 < a < 1+ (\sqrt{3} +1)b/2 \: \tag3$$ And later goes to show that $a = 2$ for $b=1$ . It is the last two inequalities, $(2)$ and $(3)$ , that are giving me trouble, as I can’t figure out how the author got there. I have attempted just looking at the denominators (to no avail), as well as multiplying it out (also to no avail). The only thing that got me close to an answer was focusing on $(2)$ without the two exterior terms squared, and looking solely at the left side of the inequality. Thanks for your time.","['conditional-probability', 'discrete-mathematics', 'probability']"
3666961,Topology: Boundary of a set,"Consider a set $ D = \{ x \in \Bbb R^n\mid h(x) < 0 \} $ where $ h:\Bbb R^n \to\Bbb R$ is a continuous function. On what condition, can I say that the set $ \{ x \in \Bbb R^n\mid h(x) = 0 \} $ is the boundary of $ D $ ? Or, equivalently, $ \{ x \in \Bbb R^n | h(x) \leqslant 0 \} $ is the closure of $ D $ ? My initial guess is that the solution of $ h(x) = 0 $ only has to form a curve. But is it enough? I need a rigorous mathematical condition. Thank you!","['general-topology', 'real-analysis']"
3666963,Combinations of elements from multiple sets with constraints,"Given four sets of numbers: $$A=\{1,2,3,4\}$$ $$B=\{1,2,3,4\}$$ $$C=\{1,2,3,5\}$$ $$D=\{1,2,6\}$$ I need to find number of all possible combinations of numbers from these sets in following format: $$(a,b,c,d)$$ where $a\in A, b \in B, c \in C, d \in D$ and where each number can be present only once per combination (e.g. combination $(1,2,3,4)$ is valid, but combination $(1,1,2,3)$ is not (number 1 repeats) and neither is combination $(2,3,5,2)$ (number 2 repeats)). My idea is to use inclusion-exclusion principle. First I calculate number of all possible combinations: $$\vert{A}\vert \cdot \vert{B}\vert \cdot \vert{C}\vert \cdot \vert{D}\vert = 192$$ And then I need to remove all combinations where elements are repeating 2 or more times. These sets are: $$\vert{A\cap B}\vert \cdot \vert{C}\vert \cdot \vert{D}\vert = 48 $$ $$\vert{A\cap C}\vert \cdot \vert{B}\vert \cdot \vert{D}\vert = 36 $$ $$\vert{A\cap D}\vert \cdot \vert{B}\vert \cdot \vert{C}\vert = 32 $$ $$\vert{B\cap C}\vert \cdot \vert{A}\vert \cdot \vert{D}\vert = 36 $$ $$\vert{B\cap D}\vert \cdot \vert{A}\vert \cdot \vert{C}\vert = 32 $$ $$\vert{C\cap D}\vert \cdot \vert{A}\vert \cdot \vert{B}\vert = 32 $$ The problem here is that I have duplicates during removal, since sum of all combinations above is $216$ (some combinations that I remove - I remove multiple times). My questions is - how to find intersections between all these sets, in order to get correct number for removal (in this case it should be $142$ and not $216$ ) - so correct answer in the end should be $192-142=50$ . I guess I need to find following intersections but not sure how to calculate all of these: $$\vert(\vert{A\cap B}\vert \cdot \vert{C}\vert \cdot \vert{D}\vert) \cap (\vert{A\cap B}\vert \cdot \vert{C}\vert \cdot \vert{D}\vert)\vert = 9 \tag{1}\label{1}$$ $$\vert(\vert{A\cap B}\vert \cdot \vert{C}\vert \cdot \vert{D}\vert) \cap (\vert{A\cap C}\vert \cdot \vert{B}\vert \cdot \vert{D}\vert)\vert = 8$$ $$\vert(\vert{A\cap B}\vert \cdot \vert{C}\vert \cdot \vert{D}\vert) \cap (\vert{A\cap D}\vert \cdot \vert{B}\vert \cdot \vert{C}\vert)\vert = 9$$ $$\vert(\vert{A\cap B}\vert \cdot \vert{C}\vert \cdot \vert{D}\vert) \cap (\vert{B\cap C}\vert \cdot \vert{A}\vert \cdot \vert{D}\vert)\vert = 8$$ $$\vert(\vert{A\cap B}\vert \cdot \vert{C}\vert \cdot \vert{D}\vert) \cap (\vert{B\cap D}\vert \cdot \vert{A}\vert \cdot \vert{C}\vert)\vert = 8$$ $$\vert(\vert{A\cap B}\vert \cdot \vert{C}\vert \cdot \vert{D}\vert) \cap (\vert{C\cap D}\vert \cdot \vert{A}\vert \cdot \vert{B}\vert)\vert = 8$$ $$...$$ $$\vert(\vert{A\cap D}\vert \cdot \vert{B}\vert \cdot \vert{C}\vert) \cap (\vert{B\cap C}\vert \cdot \vert{A}\vert \cdot \vert{D}\vert)\vert = 6 \tag{2}\label{2}$$ $$...$$ $\eqref{1}$ duplicates are $(1,1,1,1),(1,1,1,2),(1,1,1,6),(2,2,2,1),(2,2,2,2),(2,2,2,6),(3,3,3,1),(3,3,3,2),(3,3,3,6)$ $\eqref{2}$ duplicates are $(1,1,1,1),(1,2,2,1),(1,3,3,1),(2,1,1,2),(2,2,2,2),(2,3,3,2)$ -> what is the rule here if I have more than 4 sets like here? and then I need all 3 intersections: $$\vert((\vert{A\cap B}\vert \cdot \vert{C}\vert \cdot \vert{D}\vert) \cap (\vert{A\cap C}\vert \cdot \vert{B}\vert \cdot \vert{D}\vert) \cap (\vert{A\cap D}\vert \cdot \vert{B}\vert \cdot \vert{C}\vert))\vert = 2$$ $$...$$ and then 4,5 intersections (not shown here) and finally I need remaining (6) intersection of all: $$\vert((\vert{A\cap B}\vert \cdot \vert{C}\vert \cdot \vert{D}\vert) \cap (\vert{A\cap C}\vert \cdot \vert{B}\vert \cdot \vert{D}\vert) \cap (\vert{A\cap D}\vert \cdot \vert{B}\vert \cdot \vert{C}\vert) \cap (\vert{B\cap C}\vert \cdot \vert{A}\vert \cdot \vert{D}\vert) \cap (\vert{B\cap D}\vert \cdot \vert{A}\vert \cdot \vert{C}\vert) \cap (\vert{C\cap D}\vert \cdot \vert{A}\vert \cdot \vert{B}\vert))\vert = 2$$ In the end I get result: $192-(216-119+65-30+12-2)=50$ I tried to generalize this to more than 4 sets, but cannot find strict rule to calculate these intersections that I wrote above. Any help would be appreciated. UPDATE Based on answer below, I found a formula that makes computation much easier per partition: $$ Part(p) = \prod_{n=1}^{g} (-1)^{l_n} \cdot l_n! \cdot s_n $$ Here, $p$ is one of partitions - e.g. $\{\{A,B\},\{C\},\{D\}\}$ ; $g$ is number of groups in that partition (in this case 3 - $\{A,B\}$ , $\{C\}$ and $\{D\}$ ); $l_n$ is number of elements in a group minus 1 - in this case it would be $2-1=1$ , $1-1=0$ and $1-1=0$ per group; $s_n$ is number of elements in that group - in this case $\vert\{A,B\}\vert=4$ , $\vert\{C\}\vert=4$ and finally $\vert\{D\}\vert=3$ . You can see all the formula for this example in the uploaded picture below:","['combinations', 'combinatorics', 'inclusion-exclusion']"
3666982,Show that: $p_{n+1}\nmid2^{p_1p_2...p_n}+1$,Let $p_1>p_2>...>p_{n+1}>3$ prime numbers. Show that: $$p_{n+1}\nmid2^{p_1p_2...p_n}+1$$ I tried to prove it by contradiction using Fermat's Theorem but i'm struggling.,"['number-theory', 'arithmetic', 'elementary-number-theory', 'prime-numbers']"
3667002,Bounded number of zeros of derivatives can imply analyticity,"I'm trying to prove that if $f\in C^{\infty}(]-1,1[,\mathbb{R})$ and there exists a $p \in \mathbb{N}$ so that for all $n\in\mathbb{N}$ , $f^{(n)}$ has at most $p$ zeros in $]-1,1[$ then $f$ is analytic. I still don't have any concrete idea to move on so any kind of help is fine. Thanks","['complex-analysis', 'calculus', 'analyticity', 'derivatives']"
3667008,Heron's formula vs 'complex cross products' for triangle area?,"I would like to prove the equivalence between the following two ways of calculating the area of the triangle between points $\;p\;$ , $\;q\;$ , and $\;r\:$ in the complex plane. First, there is Heron's formula, $$
\tag{0} \sqrt{s(s-a)(s-b)(s-c)}
$$ where $$
a = \left| p-q \right| \\
b = \left| q-r \right| \\
c = \left| r-p \right| \\
s = {1 \over 2} (a+b+c)
$$ Second, there is $$
\tag{1} \left| {1 \over 2i} (p \times q + q \times r + r \times p) \right|
$$ where $$
x \times y \;=\; {1 \over 2} (\overline{x}y - x\overline{y})
$$ is the 'complex cross product' of complex numbers $\;x,y\;$ .  (See my question Complex integral to determine area inside of parameterized closed curve for the reference that gave me $(1)$ , by adding the 'directed area' of triangles $\;\triangle 0 p q\;$ , $\;\triangle 0 q r\;$ , and $\;\triangle 0 r p\;$ .) How do I prove $(0)$ and $(1)$ are equivalent?  It seems it should be a fairly simple calculation, but I've tried multiple approaches and cannot yet get anywhere...","['triangles', 'area', 'geometry', 'complex-numbers']"
3667029,What is the derivative of $\log \det X$ when $X$ is symmetric?,"According to Appendix A.4.1 of Boyd & Vandenberghe's Convex Optimization , the gradient of $f(X):=\log \det X$ is $$\nabla f(X) = X^{-1}$$ The domain of the $f$ here is the set of symmetric matrices $\mathbf S^n$ . However, according to the book ""Matrix Algebra from a Statistician's Perspective"" by D. Harville, $\log \det X$ for a symmetric $X$ must be (see eq. 8.12 of book) $$\log \det X = 2 X^{-1} - \text{diag} (y_{11}, y_{22}, \dots, y_{nn})$$ where $y_{ii}$ represents the $i$ th element on the diagonal of $X^{-1}$ . Now I'm not a mathematician but to me the formula of Harville seems correct, because he makes use of the fact that the entries of $X$ are not ""independent"". Indeed, in the case where the entries are ''independent'', Harville provides another formula (eq. 8.8 of his book), which matches that of Boyd & Vandenberghe. Is this an error on the book of Boyd & Vandenberghe, or am I missing something here? To me it does seem like an error, but at the same time I find this extremely unlikely as the book is very popular and if it were an error it would already be on Errata; it's much more likely that I'm misunderstanding something. This formula has already been mentioned in many questions in this website, but no question or answer that I saw mentions (the possibility of) $\log \det X$ in Boyd & Vandenberghe being wrong. Edit based on response of Profs. Boyd & Vandenberghe Prof. Boyd kindly responded to my email about this issue, provided an explanation that he and Lieven Vandenberghe think can can explain the discrepancy between the two formula. In essence, their reply suggests that the discrepancy can be due to the inner product choice. To better explain why, I need to summarize their proof in Appendix A.4.1 of the Convex Optimization book. The proof is based on the idea that the derivative of a function gives the first-order approximation of the function. That is, the derivative of $f(X)$ can be obtained by finding a matrix $f(X)$ that satisfies $$f(X+\Delta X) \approx f(X)+\langle D,\Delta X\rangle.$$ In the book Boyd&Vandenberghe use the $\text{trace}(\cdot)$ function as the inner product $\langle \cdot, \cdot \rangle$ , and show that $$f(X+\Delta X) \approx f(X)+\text{trace}(X^{-1}\Delta X).$$ The book is publicly available ; how they arrived at this expression can be seen in the Appendix A.4.1. In their reply, Prof. Boyd suggests that they suspect the discrepancy to stem from the inner product use. While they used $\text{trace}(\cdot)$ , he suggests that some other people  may use $\langle A,B\rangle = \sum_{i<=j} A_{ij}B_{ij}$ . Authors claim that this can explain the discrepancy (although I'm not sure if they looked at the proof of Harville or others about the implicit or non-implicit usage of this inner product), because the trace function puts twice as much weight on the off-diagonal entries. Some questions where Boyd & Vanderberghe's formula is mentioned: Second order approximation of log det X How to calculate the gradient of log det matrix inverse? Why the gradient of $\log{\det{X}}$ is $X^{-1}$, and where did trace tr() go??","['scalar-fields', 'determinant', 'matrices', 'matrix-calculus', 'derivatives']"
3667068,Two linear connections have the same geodesics if their difference tensor is antisymmetric,"Given two linear connections $\triangledown^a$ and $\triangledown^b$ on a manifold M, their assosciated difference tensor is $D(X,Y)=\triangledown^a_XY-\triangledown^b_XY$ . I have confidently verified that this is a $(2,1)$ -type tensor and that if it is antisymmetric, then $\triangledown^a$ and $\triangledown^b$ have the same geodesics. I am now trying to show the converse. Proof Attempt: Assume $\triangledown^a$ and $\triangledown^b$ have the same geodesics and let $D(-,-)$ be their difference tensor. We want to show that $D(X_p,Y_p)=-D(Y_p,X_p)$ for all vectors in $T_pM$ ; Equivalently, I will show that $D(X_p,X_p)=0$ for all $X_p \in T_pM$ Let $X_p$ be a vector in $T_pM$ , then by hypothesis and the existense and uniqueness of geodesics, there  exists a unique geodesic $\gamma$ for $\triangledown^a$ and $\triangledown^b$ such that $\gamma(0)=p$ and $\gamma'(0)=X_p$ , where $\gamma$ is defined on some neighborhood of $0$ in $\mathbb{R}$ . Extend $X_p$ to a vector field on the image of $\gamma$ by $X_{\gamma(t)}=\gamma'(t)$ . Then we have that: $D(X_p,X_p)=\triangledown^a_XX-\triangledown^b_YY=\triangledown^a_{\gamma'(0)}\gamma'(0)-\triangledown^b_{\gamma'(0)}\gamma'(0)=0+0=0$ Thus $D$ is antisymmetric. Is this proof is okay? The part about extending $X_p$ to a vector field feels a bit sketchy for some reason.","['riemannian-geometry', 'connections', 'tensors', 'solution-verification', 'differential-geometry']"
3667098,Proving $\int_0^\infty\frac{\mathrm dw}{(n+w)(\pi^2+(\log w)^2)}=\frac1{\log n}-\frac1{n-1}$ for any positive integer $n\geq 2$,"For any positive integer $n\geq 2$ prove that $$\int_0^\infty\frac{\mathrm dw}{(n+w)(\pi^2+(\log w)^2)}=\frac1{\log n}-\frac1{n-1}.$$ Wolfram Alpha unfortunately cannot give a step-by-step solution (it does not even give me the form on the above RHS even if I set $n=10$ , say, but comparing first few decimal digits shows that the result is almost surely correct). The only idea I had was $w=\mathrm e^{\pi\tan \theta}$ in order to kill the second multiplier of the denominator, but then I cannot deal with $$\frac{1}{\pi}\int_{-\pi/2}^{\pi/2}\frac{\exp(\pi\tan \theta)}{(n+\exp(\pi\tan \theta))}\,\mathrm d\theta.$$ Any help appreciated! UPDATE: Letting $w=\mathrm e^z$ and then using the residue theorem on $\displaystyle \int_{-\infty}^{\infty} \frac{\mathrm dz}{(n\mathrm e^{-z}+1)(\pi^2 + z^2)}$ with the semicircular contour centered at $0$ and radius $R$ (in the upper-half plane) seems to be a very promising idea, but unfortunately the contribution from the circular part does not tend to $0$ as $R\to \infty$ . :(","['integration', 'complex-analysis', 'real-analysis']"
3667126,Classifying Ideal Class Group,"I wish to show that the ideal class group of the ring of integers of $\mathbb{Q}[\sqrt{-199}]$ is the cyclic group $\mathbb{Z}_9$ for some practice identifying ideal class groups. I know there is a way to solve this by using binary quadratic forms, but I want to classify the group using ideals and ideal classes only. Here is a summary of some of  the progress I have made: ( 1 ) Since $-199 \equiv 1 \pmod 4$ , we see that the algebraic integers are $\mathbb{Z}[\frac{1 + \sqrt{-199}}{2}] \cong \mathbb{Z}[x]/(f(x) = x^2 - x + 50)$ ( 2 ) Calculating the Minkowski bound, I need to check whether $2,3,5,7$ split in $\mathbb{Z}[\frac{1 + \sqrt{-199}}{2}]$ . I found that all but 3 split. ( 3 ) Here, $(2) = PP^{*}$ , $(5) = QQ^{*}$ and $(7) = SS^{*}$ , where $P = (2, \frac{1 + \sqrt{-199}}{2})$ , $Q = (5, \frac{1 + \sqrt{-199}}{2})$ , and $S = (7, 3 - \frac{1 + \sqrt{-199}}{2})$ . I determined that these prime ideals do not equal their conjugate prime ideals. ( 4 ) Finally I determined that the order of $[P], [Q], [S]$ are 9,9, and 3 respectively. Is there a way for me to write $[Q], [S]$ as powers of $[P]$ ? If I can, then I would be able to achieve my goal, but I do not know how to do this. Any help will be appreciated.","['group-theory', 'ideal-class-group', 'maximal-and-prime-ideals']"
3667203,Sequentialization of a topological space has the same convergent sequences?,"Let $(X,\tau)$ be a topological space. We define the sequentialization $\kappa$ of $X$ as the topology $\kappa$ for which a set $A$ is closed iff for every sequence $(x_n)_n$ in $A$ with $x_n\to x$ , we have $x\in A$ . Trivially, $\tau \subseteq \kappa$ . Question: Do $\tau$ and $\kappa$ have the same convergent sequences, or equivalently: If $x_n\to x$ for $\tau$ , do we have $x_n\to x$ for $\kappa$ ? I'm not sure this is even true, but it sound like something that could be true.","['general-topology', 'sequences-and-series']"
3667206,Limit $\lim _{t\to 0 }\frac{ \int_0^{\infty} \frac{e^{-xt}}{\pi^2+(\log x)^2}dx }{ \int_0^{1/t}\frac{dx}{(\log x)^2}}$,"$$
\mbox{Prove}\qquad
\lim _{t \to 0}{\displaystyle\int_{0}^{\infty}{\mathrm{e}^{-xt} \over
\pi^{2} + \log^{2}\left(x\right)}\,\mathrm{d}x
\over
\displaystyle
\int_{0}^{1/t}{\mathrm{d}x \over \ln^{2}\left(x\right)}}
\qquad\mbox{tends to a finite limit.}
$$ ( It might be the case that the limit is in fact $1$ , but I am not sure. ) I was not able to find any theorem regarding a situation in which both the range and function depends on $t$ . The Monotone Convergence theorems I have seen are the closest related, but they are either only for ""function independent of $t$ and range dependent on $t$ "" or ""function dependent on $t$ and range independent of $t$ "". Any help appreciated !.","['integration', 'limits']"
3667235,Prove that $\int_{0}^{\infty}\frac{(\arctan x)^3}{x^3}dx=\frac{3π}{2}\ln2-\frac{π^3}{16}$,"Question : How to prove $$\int_{0}^{\infty}\frac{(\arctan x)^3}{x^3}dx=\frac{3π}{2}\ln2-\frac{π^3}{16}\: ?$$ I was able to prove $$\int_{0}^{\infty}\frac{(\arctan x)^2}{x^2}dx=π\ln2$$ using, $$f(x,y)=\int_{0}^{\infty}\frac {{\arctan(xt)}\cdot{\arctan(yt)}}{t^2} dt$$ at $ f(1,1)$ . But i'm not able to evaluate 1st integral using same method. Is there any other method to evaluate this?","['integration', 'calculus', 'definite-integrals']"
3667317,Why integrate on cubes that's not injective?,"Again, this is a conceptual(soft) problem I had while reading Spivak's calculus on manifold. There, to develop the theory of integration, Spivak chose to integrate k-forms on singular cubes. However, as pointed out here , singular cubes can collapse dimension, so it seems theoretically possible that one pulls back a differential form onto a higher dimension cubical region for evaluating the integral, and I wonder when could that ever be useful? Why don't we just add the assumption that singular cubes are injective? Also, without this injectivity I find the picture of chains even less geometrically intuitive...","['multivariable-calculus', 'differential-topology', 'differential-forms']"
3667336,What is the density of distribution which is obtained by acting with a Mobius transformation on the unit disc with uniform distribuition?,"So, I have given a Mobius transformation that preserves unit disc. In unit disc I have uniform distribution (distribution that has constant density). I have to act with this Mobius transformation on this uniform distribution. What will I get?What density it will have? Can anybody please help me with this? Or at least tell me which literature available on internet I should look that would give me the best answer on this...
Thank you!","['complex-analysis', 'statistics', 'uniform-distribution', 'mobius-transformation']"
3667392,Set of numbers from $1-9$ multiplied together to get the smallest possible value,"The numbers $x_1,$ $x_2,$ $x_3,$ $y_1,$ $y_2,$ $y_3,$ $z_1,$ $z_2,$ $z_3$ are equal to the numbers $1,$ $2,$ $3,$ $\dots,$ $9$ in some order. Find the smallest possible value of $$x_1 x_2 x_3 + y_1 y_2 y_3 + z_1 z_2 z_3.$$ I would assume the lowest number, $1,$ would have to be multiplied by $9,$ the highest.  I do not know how to approach this with AM-GM, though.","['algebra-precalculus', 'inequality']"
3667515,Determine all $f : \mathbb R \rightarrow \mathbb R$ such that $f(f(x) + y) = f(x^2 - y) + 4yf(x)$. [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Determine all $f : \mathbb R \rightarrow \mathbb R$ such that $$f\big(f(x) + y\big) = f(x^2 - y) + 4yf(x)$$ for all $x,y\in\mathbb{R}$ . $f(x) = 0$ is obvious , but how can we find all other functions? Thanks in advance!","['contest-math', 'functional-equations', 'algebra-precalculus', 'functions']"
3667550,How to understand this polar coordinate transformation of ODE,"I am reading a textbook and it considers the following ODE: $$(u-x)u_x+u+x=0,$$ with $$u_x = \frac{\partial u}{\partial x}.$$ Use the following polar coordinate transformation $$x = r\cos\theta, \ \ \ \ \ u = r\sin\theta.$$ The ODE becomes $$\frac{dr}{d\theta}=r$$ How to obtain this final result?   Thanks in advanced.","['polar-coordinates', 'ordinary-differential-equations']"
3667591,Determine all $f : \mathbb R \rightarrow \mathbb R$ such that $f(x^3 + y^3) = x^2f(x) + yf(y^2)$.,"Determine all $f : \mathbb R \rightarrow \mathbb R$ such that $$f(x^3 + y^3) = x^2\,f(x) + y\,f(y^2)$$ for all $x,y\in\mathbb{R}$ . I put $x = y = 0$ then $x = 0$ and $y = 0$ respectively. This implies Cauchy’s Functional Equation , but I can’t continue after this.","['contest-math', 'functional-equations', 'algebra-precalculus', 'functions']"
3667612,Showing that $f(x) = \dfrac{x}{(2\ln x)^2}$ is an increasing function for $x \ge 8$,"I apologize for the repetition.  I asked a similar question here before. I was trying to generalize the result.  Does the following reasoning also work to show that $f(x) = \dfrac{x}{(2\ln x)^2}$ is an increasing function for $x \ge 8$ Please let me know if any of these steps are wrong: (1)  Using the quotient rule with $g(x) = x$ and $h(x) = (2\ln x)^2$ : $$f'(x) = \frac{g'(x)h(x) - g(x)h'(x)}{(h(x))^2}$$ (2) Using the exponent rule for derivatives with $s(x) = 2\ln x$ : $$h'(x) = (s(x)^2)' = s(x)^2\left(s'(x)\dfrac{2}{s(x)}\right) = 2s(x)s'(x)$$ (3) $s'(x) = \dfrac{2}{x}$ so that: $$h'(x) = \dfrac{8\ln(x)}{x}$$ (4) With $g'(x) = 1$ , it follows that: $$f'(x) = \dfrac{(2\ln x)^2 - \frac{8x\ln(x)}{x}}{(2\ln x)^4} = \dfrac{(2\ln x) - 4}{(2\ln x)^3}$$ (5)  It is increasing at $x\ge 8$ since: $$\dfrac{(2\ln 8) - 4}{(2\ln(8))^3} > 0.0022 > 0$$ Are these steps correct? Edit:  I changed step(5) to $x\ge 8$ since that is my goal. It looks like my result may be correct for $x=8$ but insufficient for $x \ge 8$ . Edit 2:  Made a fix based on John Omielan's comment.","['inequality', 'solution-verification', 'derivatives']"
3667633,"Cardinality of $\{𝑓:\{1, \ldots , 𝑛\} → \{0,1,2\}\mid ∀𝑖 ∈ \{1, \ldots , 𝑛 − 1\}: 𝑓(𝑖) + 𝑓(𝑖 + 1) ≠ 4\}$","What is the cardinality of this set? $$\{𝑓:\{1, … , 𝑛\} → \{0,1,2\}\mid ∀𝑖 ∈ \{1, … , 𝑛 − 1\}: 𝑓(𝑖) + 𝑓(𝑖 + 1) ≠ 4\}$$ On a logical level, I understand that it must be the set of all functions for which $f(i+1)\neq f(i) \neq 2$ . But there's no formula for the function, so.. How can this be found?","['recurrence-relations', 'combinatorics', 'discrete-mathematics', 'sequences-and-series', 'elementary-set-theory']"
3667676,Green's theorem (integration by parts) on the unit sphere,"List item I am missing something here and I need help to find it: Since the unit sphere $\mathbb{S}^{n-1}$ in $\mathbb{R}^{n}$ has no boundary, then given a smooth function $\phi$ and a smooth vector field $\psi$ we can integrate by parts $$\int_{\mathbb{S}^{n-1}}\phi \nabla_{\mathbb{S}^{n-1}}\cdot\psi\, d\omega_n=-
\int_{\mathbb{S}^{n-1}} \nabla_{\mathbb{S}^{n-1}} \phi\cdot\psi\, d\omega_n \qquad (1)$$ where $\nabla_{\mathbb{S}^{n-1}}$ is the surface gradient on the sphere, and $\omega_n$ is the standard Surface measure on $\mathbb{S}^{n-1}$ . Therefore we have that $$\int_{\mathbb{S}^{n-1}} \nabla_{\mathbb{S}^{n-1}}\cdot\psi d\omega_n=0\qquad \qquad\qquad\qquad (2)$$ for any smooth vector field $\psi$ . Obviously, the smoothness condition is not necessary in the aforementioned statements. It can be relaxed to some appropriate integrability conditions. 
   Now, take the simple explicit example of the 
unit sphere $\mathbb{S}^{2}$ in $\mathbb{R}^{3}$ , and for each point $(x,y,z)\in \mathbb{S}^{2}$ , consider the parametric representation $(x,y,z)=(\cos{\theta},\sin{\theta}\cos{\varphi},\sin{\theta}\sin{\varphi})$ , $0\leq \theta \leq \pi$ , $0\leq \varphi< 2\pi$ . Then, we have $$d\omega_3=\sin{\theta} d\theta d \varphi,$$ $$\nabla_{\mathbb{S}^{2}}=\frac{\partial}{\partial \theta} \widehat{\theta}+\frac{1}{\sin{\theta}}\frac{\partial}{\partial \varphi} \widehat{\varphi}$$ where $\widehat{\theta}$ and $\widehat{\varphi}$ are the standard orthonormal unit vectors tangent to the sphere pointing in the direction of increase of $\theta$ and $\varphi$ respectively. We can write $$\frac{1}{\sin{\theta}}=\nabla_{\mathbb{S}^{2}}\cdot
\left(\frac{\theta}{\sin{\theta}} \nabla_{\mathbb{S}^{2}} \theta\right).$$ To verify this, one needs to recall that $\nabla_{\mathbb{S}^{2}} \cdot\nabla_{\mathbb{S}^{2}} \theta=
\Delta_{\mathbb{S}^{2}} \theta$ , where $\Delta_{\mathbb{S}^{2}}=\frac{1}{\sin{\theta}}\frac{\partial}{\partial \theta} \left(\sin{\theta}\frac{\partial}{\partial \theta}\right)+
\frac{1}{\sin^2{\theta}}\frac{\partial^2}{\partial \varphi^2}$ is the Laplace Beltrami operator on $\mathbb{S}^{2}$ . On the other hand $$\int_{\mathbb{S}^{2}} \frac{1}{\sin{\theta}}d\omega_3=
\int_{0}^{2\pi}\int_{0}^{\pi} \frac{1}{\sin{\theta}}\sin{\theta}d \theta d\varphi=2\pi^2\neq 0.$$ Where is my mistake ?","['spherical-geometry', 'analysis', 'greens-theorem', 'multivariable-calculus', 'spherical-coordinates']"
3667776,Why is the euler characteristic of a sphere 2?,"When calculating the Euler Characteristic of any regular polyhedron the value is 2. Since a sphere is homoeomorphic to all regular polyhedrons, the sphere ought to have a Euler Characteristic of 2 as well. So: $V-E+F=2$ holds true A sphere obviously do not have vertices nor edges, which ought to mean they have 2 faces, which i assume are the inside and outside. If that is the case, why dont you count the inside and outside as two seperate faces on any of the other regular polyhedrons? A tetrahedron for example only has 4 faces. If not, then where is the other face.","['general-topology', 'polyhedra', 'spheres']"
3667826,Calculating diameter of neighboring circles,"I have one circle C1 with known diameter d1 . That circle is surrounded by N circles ( C2 ) of unknown diameter d2 where each of C2 circles touches two neighboring C2 circles and C1 circle in one point. Have to find d2 . Something like this... So, what have I tried so far... I'm not mathematician and to be honest, I haven't been in touch with any by basic everyday math for almost 20 years. If I remember well from school, solution to this problem falls under trigonometry. So I tried to use triangles in many different ways and finally ended up with something like this... I could solve this by basic trigonometric formulas if any of the sides of triangle is known, but I have only partial data and some relations. So this is my best shot. I don't know if this is the right way to solve it or do I have enough of known values to get desired result but that's all I have this far. Maybe my approach seems apsurd for most of you doing stuff like this on daily basis, so don't blame me. Anyway, eneded up here because I'm trying to solve practical problem using math so guess that place where mathematicians are around is good to start with. I couldn't even search the web for solutions just because I really don't know what to look for or technical terms to search for. Hope someone here may help me with formula to get d2 from first figure when N and d1 are known. Hope I provided enough of details to explain my problem because I really don't know any other way to do this.","['trigonometry', 'circles']"
3667847,"Show that $(0,1)$ and set of positive real numbers are equivalent sets [duplicate]","This question already has answers here : bijection from $(a,b)$ to $\Bbb R$ (2 answers) Monotonic bijection from positive reals to reals between 0 and 1 (3 answers) Closed 4 years ago . I try to prove that the open interval $(0,1)$ and $\mathbb{R}_+$ are equivalent sets. I thought maybe if I define a bijective function between those two sets; it would help, but I couldn't. Can you help with it?",['elementary-set-theory']
3667870,A bound on the moment generating function,"Let $X$ be a random variable such that $|X|\le{K}$ for some $K>0$ . I am trying to prove the following bound on the moment generating function of X: $$\mathbb{E}[\exp(\lambda{}X)]\le{}\exp(g(\lambda)\mathbb{E}[X^2])$$ where $$g(\lambda):=\frac{\lambda^2\space{}/\space{}2}{1-|\lambda|K\space{}/\space{}3}$$ provided we have $|\lambda|<3\space{}/\space{}K.$ I've managed to show that if $X\le{}K$ a.e. then $$\mathbb{E}[\exp(\lambda(X-\mathbb{E}[X]))]\le{\exp\bigg(\frac{\lambda^2/2\mathbb{E[X]}}{1-K\lambda/3}\bigg)}$$ for $\lambda\in{[0,3/K]}$ . But can't see where to go from here or if this is even the right direction. p.s. I got to that inequality by considering the function $h(\lambda):=2\big(\frac{e^X-X-1}{2}\big)$","['real-analysis', 'expected-value', 'moment-generating-functions', 'upper-lower-bounds', 'probability-theory']"
3667887,Are all nondecreasing $f: \mathbb R^d \to \mathbb R$ Borel-measurable?,"It is well-known that any nondecreasing function $f: \mathbb R \to \mathbb R$ is Borel-measurable. Can this property be generalized to nondecreasing functions defined on $\mathbb R^d$ ? To be precise, let's fix the following definitions: A function $f: \mathbb R^d \to \mathbb R$ is said to be Borel-measurable if $f^{-1}(B) \in \mathcal B (\mathbb R^d)$ holds for all $B \in \mathcal B(\mathbb R)$ , where $\mathcal B(\mathbb R^k)$ denotes the Borel sigma algebra on $\mathbb R^k$ . Given $x, x' \in \mathbb R^d$ write $x \le x'$ if $x_k \le x'_k$ holds for all $k = 1,\dots, d$ . A function $f: \mathbb R^d \to \mathbb R$ is said to be nondecreasing if $\forall x, x' \in \mathbb R^d$ , $x \le x'$ implies $f(x) \le f(x')$ Question: Is every nondecreasing function $f: \mathbb R^d \to \mathbb R$ Borel-measurable?","['measure-theory', 'probability-theory', 'real-analysis']"
3667898,When are Hamming codes cyclic?,"Motivation The following statement appears to be true: The $q$ -ary Hamming code of codimension $r$ over $\mathbb{F}_q$ is equivalent to a cyclic code if and only if if $q-1$ and $r$ are coprime. See for example this answer by Dietrich Burde as a in-house quotation. The $\Leftarrow$ -direction is not too hard to show (making use of a primitive element of the finite field $\mathbb{F}_{q^r}$ ), but I could not find a proof for the other direction anywhere. I've checked various sources like web search, search on this page math.stackexchange, as well as standard books on coding theory like MacWilliams-Sloane, van Lint or Huffman-Pless. Question Assume that $q-1$ and $r$ at not coprime. Show that the $q$ -ary Hamming code of codimension $r$ is not equivalent to a cyclic code. Dietrich Burde pointed me to the book of Huffman & Pless, ""Fundamentals of Error-Correcting codes"", 2003. I checked this book again, but I cannot find the full desired statement nor a proof. The closest things I can find are: Theorem 5.1.4 on page 169 shows that for $\gcd(r,q-1) = 1$ , the $q$ -ary Hamming code of codimension $r$ is a narrow-sense BCH code, which gives "" $\Leftarrow$ "". Corollary 5.1.5 on page 170 observes that as a consequence, all binary Hamming codes are primitive narrow-sense BCH codes. Example 5.1.6 shows that the $[4,2,3]$ ternary Hamming code is not cyclic, which is close to this question . Part of the reasoning is left as the subsequent Exercise 288. (In my opinion, the direction proposed by Huffman and Pless using the automorphism group of order $48$ is unnecessarily complicated. Better observe that there are only two cyclic ternary $[4,2]$ codes and their generator polynomials have weight only $2$ .) I certainly did not check the whole book, but I could not find anything else. If the statement indeed was there, I would expect a pointer at Theorem 5.1.4 orExample 4.1.6 to the general statement.","['finite-fields', 'abstract-algebra', 'linear-algebra', 'discrete-mathematics', 'coding-theory']"
3667964,Another Hadamard matrix of order 4?,"Wikipedia states that there is, up to equivalence, a unique Hadamard matrix of order 4, namely $$
\def\p{\phantom+}
\begin{pmatrix}
\p1&\p1&\p1&\p1 \\
\p1&-1&\p1&-1 \\
\p1&\p1&-1&-1 \\
\p1&-1&-1&\p1
\end{pmatrix}.$$ As equialence operations are allowed negating some rows/columns or interchanging some rows/columns.
But isn't the following another Hadamard matrix of order 4 that cannot be obtained in this way? $$
\begin{pmatrix}
-1&\p1&\p1&\p1 \\
\p1&-1&\p1&\p1 \\
\p1&\p1&-1&\p1 \\
\p1&\p1&\p1&-1 \\
\end{pmatrix}.$$","['equivalence-relations', 'matrices', 'hadamard-matrices', 'linear-algebra', 'combinatorics']"
3667969,Help with the definition of the Gradient in Multi-variable Calculus,"I was studying Multi-variable Calculus, and I got confused with the definition of the Gradient. The definition that I learned was this: But, doing some examples, and searching in Google I saw that the Gradient vector can be normal to every tangent plane to the surface given. The picture below gives the tangent plane and the gradient vector normal to that tangent plane. So, I got confused because I do not understand is the Gradient vector normal only to the level curves or also to other tangent planes?
And if they are tangent to other planes, why there are a lot definition that define it differently? Update: Based on the comments what I understood was that a function of two variables has a level CURVE, and gradient is normal to that level curve. But, functions of three variables don’t have level curves but level SURFACES, that is why the gradient is normal to every point in that level surface. So, the second picture is the gradient vector normal at the level surface of some function with three variables. This is what I understood. If you believe that is not correct, than please provide with some explanation. The sources for the 1st and 2nd pictures: http://tutorial.math.lamar.edu/Classes/CalcIII/GradientVectorTangentPlane.aspx https://bvmtc.math.tamu.edu/~glahodny/Math251/Section%2012.6.pdf","['multivariable-calculus', 'vector-analysis']"
3668013,Could this integral expression for $\zeta(3)$ be simplified any further?,"I managed to derive the following integral: $$\zeta \left( s \right) ={\frac { \left( s-2 \right)}{\Gamma \left( s \right) } \int_{0}^{\infty }\!{u}^{s-3} \left( \zeta(2)-{\it Li_2} \left(1-{{\rm e}^{-u}} \right)  \right) \,{\rm d}u}\qquad \Re(s) \gt 2 \tag{1}$$ where $Li_2(z)$ is the dilogarithm . For $s=3$ this reduces to: $$\zeta \left( 3 \right) =\frac12{\int_{0}^{\infty } \zeta(2)-{\it Li_2} \left(1-{{\rm e}^{-u}}  \right) \,{\rm d}u} \tag{2}$$ or after the variable change $u=\ln(x)$ : $$\zeta \left( 3 \right) =\frac12{\int_{1}^{\infty } \frac{1}{x}\left(\zeta(2)-{\it Li_2} \left(1-\frac{1}{x}  \right)\right) \,{\rm d}x} \tag{3}$$ or with $u=-\ln(x)$ : $$\zeta \left( 3 \right) =\frac12{\int_{0}^{1} \frac{1}{x}\big(\zeta(2)-{\it Li_2} \left(1-x\right)\big) \,{\rm d}x} \tag{4}$$ Searched the web for similar expressions, but haven't found anything related yet. Could this be simplified any further into know expressions? ADDED 1: A surprise outcome is that: $$\zeta \left( 5 \right) =\frac12{\int_{0}^{1} \frac{1}{x}\big(\zeta(2)-{\it Li_2} \left(1-x\right)\big)^2 \,{\rm d}x} \tag{5}$$ ADDED 2: Found one more: $$\zeta \left( 4 \right) =\frac{4}{5}{\int_{0}^{1} \frac{1}{x}\big(\zeta(3)-{\it Li_3} \left(1-x\right)\big) \,{\rm d}x} \tag{6}$$","['riemann-zeta', 'number-theory', 'polylogarithm', 'definite-integrals']"
3668064,"If $H_1$ and $H_2$ are isomorphic normal subgroups of $G$, when do we have an isomorphism between $G/H_1$ and $G/H_2$?","This question is related to the following three questions: Two subgroups $H_1, H_2$ of a group $G$ are conjugate iff $G/H_1$ and $G/H_2$ are isomorphic If $H_1, H_2\leq G$ are such that $H_1\cong H_2$ then $G/H_1\cong G/H_2$? Isomorphic quotients by isomorphic normal subgroups Let $G$ be a group, and $H_1$ , $H_2$ be two normal subgroups of $G$ , and $\varphi : H_1 \to H_2$ be a group isomorphism. Consider the following proposition: $$(P): \text{The groups $G/H_1$ and $G/H_2$ are isomorphic.}$$ In If $H_1, H_2\leq G$ are such that $H_1\cong H_2$ then $G/H_1\cong G/H_2$? , we can see that $(P)$ does not necessarily  hold, even if $G$ is  assumed to be abelian and finite. On the other hand, it is quite easy to show that $(P)$ holds in the following cases : If $\frac{|G|}{|H_1|} = \frac{|G|}{|H_2|}$ and if this number is prime. More particularly, $(P)$ holds for all subgroups $H_1$ and $H_2$ of $G$ if $|G|$ is the product of two prime numbers. Question: Let $G \simeq \mathbb{Z}/q_1\mathbb{Z} \times\dots\times
\mathbb{Z}/q_r\mathbb{Z}$ be some finite abelian group, where $q_1,\dots,q_r$ are prime powers. Do we know a necessary and sufficient condition on $(q_1,\dots,q_r)$ so that $(P)$ holds for all subgroups $H_1$ and $H_2$ ? What if we restrict $H_1$ and $H_2$ to be subgroups of $G$ of cardinality $d$ , where $d$ is a factor of $\prod_{i=1}^r q_i$ ?","['finite-groups', 'group-theory', 'quotient-group', 'normal-subgroups', 'abelian-groups']"
3668134,"Proving that $|f(x)-f(y)| \ge \log(1+|x-y|)$ for all $x,y \in R$ is onto",How do I prove that it is onto?The function $f$ is continuous  in $\mathbb{R}$ . I have thought about it without any progress. Some hint would be appreciated.,"['continuity', 'functions']"
3668144,How to construct a degree $4$ polynomial $h(z)$ such that $h(z)$ has a triple root and $h(z) - 1$ has a double root?,"This is a homework question, so please do not give me the full answer. I only need a hint that pushes me in the right direction. I have been asked to construct a holomorphic function $h(z)$ whose dessin d'enfant looks like this: For simplicity, I have assumed that $h(z)$ is a polynomial. Therefore $h$ must have degree $4$ , because the preimage of a generic $t \in \mathbb C$ , exemplified by those $0 < t < 1$ drawn in red, has four points. The leftmost white point is a triple root of $h(z)$ , whereas the rightmost black point is a double root of $h(z) - 1$ . It seems reasonable to assume that the other two black points are complex conjugates. Taking the preceding considerations into account, I postulate that $h(z)$ is such that $h(z) = k (z-a)^3 (z-b)$ and $h(z) - 1 = k (z^2 + c^2) (z - d)^2$ , for some $k < 0$ . How could I construct a polynomial $h(z)$ with these characteristics? EDIT: Never mind, I found $h(z) = 16 z^3 (2 - 3z)$ . Obviously it has a triple zero at $z = 0$ and a simple zero at $z = 3/2$ . Then $h(z) - 1 = - (1 - 2z)^2 (1 + 4z + 12z^2)$ , which has a double zero at $z = 1/2$ and two simple zeros at two complex conjugate points.","['riemann-surfaces', 'algebraic-geometry', 'polynomials']"
3668182,Is there any situation where the derivative ${ dy \over (dx)^2 }$ makes sense?,"Is there any situation where the following expression ever make any sense in calculus? ${ dy \over (dx)^2 }$ If we imagine a square with side length $x$ and increase by a small amount $dx$ , and $dy$ is the increase in area, then $$dy = 2xdx+(dx)^2$$ Normally, the purpose is to calculate ${dy \over dx}=2x+dx = 2x$ by saying the extra $dx$ term is infinitesimal and can be treated as zero. However, if we divide $(dx)^2$ instead we get $${dy \over (dx)^2}={2x \over dx}+1$$ Now in this example the ${2x \over dx}$ term becomes infinity and therefore the expression makes no sense, but I am wondering is there any case that doing a similar thing would make sense and there is a meaning for the term ${ dy \over (dx)^2 }$ . It seems impossible to me at a glance for any expression to have a non-infinity term on the right, but once things get complicated and infinite series are involved I am wondering if it is really impossible or actually there is some field of study that the expression actually makes sense.","['calculus', 'derivatives']"
3668189,zero extension of positive currents are always positive,"In Demailly's Complex Analytic and Differential Geometry page 139: He said the trivial (zero) extension of the positive current $T$ (on $X\setminus E$ ), which denoted by $\tilde T$ is always positive on $X$ . It seems like quite obvious, but I came across some obstacle when verifying that claim. Notice that a current $T\in\mathcal D^{'}_{p,p}(X)$ is said to be positive if $\langle T, u\rangle\geqslant 0$ for all test forms $u\in\mathcal D_{p,p}(X)$ that are strongly positive at each point.Another way of stating the definition is: $T$ is positive if and only if $T \wedge u \in \mathcal D_{0,0}^{'}(X)$ is a positive measure for all strongly positive forms $u \in\mathcal C_{p,p} ^{\infty}(X)$ . This is so because a distribution $S\in\mathcal D^{'}(X)$ such that $S(f)\geqslant 0$ for every non-negtive function $f\in\mathcal D (X)$ is a positive measure. Here is my thought: First, select arbitrary $u \in\mathcal C_{p,p} ^{\infty}(X)$ , we have $u \in\mathcal C_{p,p} ^{\infty}(X\setminus E)$ , then we would like to show that $$\langle \tilde T\wedge u,f\rangle=\langle  T\wedge u,f\rangle\geqslant 0, \qquad f\in\mathcal D(X),$$ due to the construction of $\tilde T$ . However, supp $(f)\cap (X\setminus E)$ isn't compact in $X\setminus E$ . Then, how can I infer LHS is non-negative? Any help and suggestion are appreciated. Thanks a lot!","['complex-analysis', 'complex-geometry', 'several-complex-variables', 'differential-geometry']"
3668240,"Find the group with presentation $\langle x, y: xy=yx, x^5=y^3\rangle$.","Here's the problem: Find the group with presentation $\langle x, y: xy=yx, x^5=y^3\rangle$ . Here's my answer: The group is commutative by the first relation, so every ""word"" is of the form $x^iy^j$ for $i,j \in \mathbb{Z}$ . By the second relation we have $x^a y^b $ for $0 \leq a \leq 4$ and $b \in \mathbb{Z}$ . Hence the group is  isomorphic to $\mathbb{Z_5} \times \mathbb{Z}$ . Is this correct?","['combinatorial-group-theory', 'group-presentation', 'group-theory', 'solution-verification']"
3668376,"Given $ a_n= 6a_{n-1} -4a_{n-2}$ and initial values, find a closed form for $a_n$","I have a recursive formula: $$ a_n= 6a_{n-1} -4a_{n-2}$$ with $a_0=1$ and $a_1=3$ , and I need to find a closed-form expression of $(a_n)_{n\in \mathbb{N}}$ . I managed to calculate almost everything but at the end I get this expression: $$ a_n= \frac{(3+\sqrt{5})^n}{2} + \frac{(3-\sqrt{5})^n}{2} $$ Is there a way to prove the following statement? Because Everything I have tried up till now doesn't do the job, and are these two expressions equal at all? $$ \frac{(3+\sqrt{5})^n}{2} + \frac{(3-\sqrt{5})^n}{2} = \left \lceil \frac{(3+\sqrt5)^n}{2} \right \rceil$$","['algebra-precalculus', 'discrete-mathematics', 'sequences-and-series']"
3668385,Example of sequence $\langle x_n\rangle$ with $x_n>0$ such that series $\sum x_n$ is convergent but $\langle nx_n\rangle$ is NOT a null sequence. [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question Please provide an example of  sequence $\langle x_n\rangle$ of positive terms such that series $\sum x_n$ is convergent but sequence $\langle nx_n\rangle$ is NOT  a null sequence. I try hard but could not  find one such. Please help.","['examples-counterexamples', 'analysis', 'real-analysis', 'sequences-and-series', 'convergence-divergence']"
3668424,Evaluating: $\lim_{x\to\infty} \frac{\sum_{k=0}^{x/2}\binom{x}{2k}2k(x-2k)}{\sum_{k=0}^{x/2}\binom{x}{2k}(x-2k)^{2}}$,"I'm trying to solve the following limit $$\lim_{x\to\infty} \frac{\sum_{k=0}^{x/2}\binom{x}{2k}2k(x-2k)}{\sum_{k=0}^{x/2}\binom{x}{2k}(x-2k)^{2}}$$ My thoughts: I've tried to use Stirling's formula for the binomial coefficient $\binom{x}{2k}\approx\frac{x^{2k}}{2k!}$ . Using that, the limit takes the value $-1$ which is wrong since it must be positive. Thanks in advance.","['limits', 'binomial-coefficients', 'sequences-and-series']"
3668529,Is ODE factorisation with split-quaternions possible?,"In Simple complex ODE's in matrix form? we discussed how we can solve certain complex ODE's in matrix form. As an example: $$y(x)^2+y'(x)^2=0$$ can be factored as $$(y(x)+ iy'(x))(y(x)-iy'(x))=0$$ and if we insist we could solve the two above equations by representing each term in a matrix form, i.e. $$y(x)\equiv \begin{pmatrix}y_r(x)&-y_i(x)\\y_i(x)& y_r(x)\end{pmatrix}\\
y'(x)\equiv \begin{pmatrix}y'_r(x)&-y'_i(x)\\y'_i(x)& y'_r(x)\end{pmatrix}\\
i \equiv  \begin{pmatrix}0&-1\\1& 0\end{pmatrix}\\ $$ Multiplying the matrices out we get a system of coupled ODE's and the solution is found. However, I was trying to apply this technique for a different problem: $$y(x)^2+y'(x)^2-1=0$$ This expression cannot be factored as a product of two complex numbers (except the trivial factoring of 1). However, I tried to factor it over different types of numbers and in this post we discussed, that split-quaternions allow the following factorisation: $$(y(x)+i y'(x)+j)(y(x)-i y'(x)-j)=0$$ Just like regular complex numbers allow a representation by 2x2 real matrices, split-quaternions can be written as 2x2 complex matrices. Wikipedia . The true solution is: $${y(x) = c_1\sin(x)}\\
 {y(x) = c_2\cos(x)}$$ and what we get from the method I developed is the following $$y(x)= c_1 \cos(x)-c_2 \sin(x)+\\(c_1 \sin(x)+c_2 \cos(x))i+ \\(c_4 \sin(x)+c_3 \cos(x)-1)j+ \\(c_4 \cos(x)-c_3 \sin(x))k$$ So that $\mathcal{R}\{y(x)\}=c_1 \cos(x)-c_2 \sin(x)$ and the results agree. My question is: when can I use this technique? Is it legitimate or is it just a lucky coincidence?","['quaternions', 'factoring', 'ordinary-differential-equations']"
3668542,"Erase every other number from $1, 2, 3, ... 2000$ until only one number left","One writes $1, 2, 3, ... 2000$ on the blackboard. We erase every other number from left , so after one iteration we are left with $2, 4, ... 2000$ Then we erase every other number from right .. We keep repeating to erase from left and right one after another, eventually there is only one number left. What would be that number? I wrote a program, unless there is a bug, the answer should be 982. But is there a way to mathematically induce the results, and generalize to arbitrary number (not just 2000?) Following the suggestion, it seems like for power of 2, the answers go like this $N=2$ , final number is 2 $N=4$ , final number is 2 $N=8$ , final number is 6 $N=16$ , final number is 6 $N=32$ , final number is 22 $N=64$ , final number is 22 $N=128$ , final number is 86 $N=256$ , final number is 86 The answer will jump to 4 times previous answer minus 2, for every time we multiply $N$ by 4...","['recreational-mathematics', 'puzzle', 'combinatorics', 'sequences-and-series']"
3668568,$P^2$ blow up nine points,"I quote the following paragraph form Kollar-Mori on page 22: Let $X$ be obtained from $P^2$ by blowing up at the nine
base points of a pencil of cubic curves, all of whose members are
irreducible. Choosing one of the nine points as the zero section,
we get an infinite group of automorphisms of $X$ generated by the
other eight sections. So $X$ has infinitely many (—1)-curves, all of
which span an extremal ray of NE(X). $|-K_X|$ is the elliptic
pencil, thus $-K_X$ is nef, but not ample. I have following questions in understanding this paragraph: (1) What does it mean by taking one point as a section? And why from this we can deduce the autommorphism group is infinite and there are infinitely many $-1$ curves. (2) Why we can deduce that it is nef but not ample?","['algebraic-geometry', 'blowup', 'birational-geometry']"
3668590,"There exist $n$ different integers in the interval $\big(k^n,(k+1)^n\big)$ whose product is a perfect $n$-th power.","Given a positive integer $ n> 2 $ . Prove that there exists a natural number $ K $ such that for all integers $ k \ge K $ on the open interval $ \big({{k} ^{n}}, \ {{(k + 1)} ^{n}}\big) $ there are $n$ different integers, the product of which is the $n$ -th power of an integer. Source Ukrainian TST 2011 Progress : Maybe one can choose the smallest prime divisor $q$ of $n$ and then one can choose all $\frac{n}{q}$ powers and among these powers, one can choose $n$ integers whose product is a $q$ -th power
In this way, we would just have to prove that 
Between $k^q$ and $(k+1)^q$ we have $n$ integers with their product being a $q$ -th power.","['contest-math', 'number-theory', 'elementary-number-theory', 'analytic-number-theory', 'perfect-powers']"
3668595,Limit Laws for a Partial Sum of an Infinite Series [duplicate],"This question already has answers here : Can't we compute $\lim_{n \to \infty}\frac{1+ \cdots +n}{n^2}=\lim_{n\to\infty}\frac{1}{n^2}+\cdots +\lim_{n\to\infty}\frac{n}{n^2}=0$? (5 answers) Closed 4 years ago . I came across a question in my High School Calculus textbook: Find $\lim_{n \to \infty} a_n$ where $a_n = \frac{1}{n^2} + \frac{2}{n^2} + \frac{3}{n^2} + ... + \frac{n}{n^2}$ My approach was to simply distribute the limit to each term in the partial sum. I believed this would be legitimate according to the limit laws. Once I evaluated the individual limits, the limit of the partial sum came out to equal $0$ : $$\begin{aligned}
\lim_{n \to \infty} a_n &= \lim_{n \to \infty}(\frac{1}{n^2} + \frac{2}{n^2} + \frac{3}{n^2} + ... + \frac{n}{n^2})
\\
&= \lim_{n \to \infty}(\frac{1}{n^2}) + \lim_{n \to \infty}(\frac{2}{n^2}) + \lim_{n \to \infty}(\frac{3}{n^2}) + ... + \lim_{n \to \infty}(\frac{n}{n^2})
\\
&= 0+0+0+...+0
\\
&=0
\end{aligned}$$ However, the textbook first combined the fractions and simplified it, only to find that the limit of the partial sum equals $1/2$ : $$\begin{aligned}
a_n &= \frac{1+2+3+...+n}{n^2}
\\
&= \frac{\frac{n(n+1)}{2}}{n^2}
\\
&= \frac{1}{2}(\frac{n+1}{n})
\\
&= \frac{1}{2}(1+\frac{1}{n})
\end{aligned}$$ $$\therefore \lim_{n \to \infty}a_n = \frac{1}{2}$$ Both solutions seemed to be legitimate. However, after pondering on the question for a bit, I starting to think that maybe the limit laws don't apply to partial sums...
As $n\rightarrow\infty$ , the number of terms also approaches infinity, so then distributing the limit an ""infinite"" number of times might be wrong, considering how weird infinity is. But I'm not so convinced about that. Is there some sort of restriction on how the limit can be distributed? Is there something I'm missing that completely invalidates my approach to the problem?","['limits', 'calculus', 'sequences-and-series']"
3668618,Equalities of the Petersson inner product for two related modular forms,"Let $\Gamma_1(N)$ be the usual congruence subgroup of $\text{SL}_2(\mathbb{Z})$ and let $f\in S_k(\Gamma_1(N))_{\text{new}}$ be a normalized primitive form, and write $f=\sum_{n\geq 1}a_nq^n$ . Let $w_N$ be the Fricke, or Atkin-Lehner, operator, which is known to preserve the space of newforms. Define the newform $f^*\in S_k(\Gamma_1(N))_{\text{new}}$ by $f^*(z)=\overline{f(-\overline{z})}$ . It can be shown that $w_Nf=\eta_f f^*$ for some $\eta_f\in\mathbb{C}$ , known as the Atkin-Lehner pseudo-eigenvalue. For proving that this pseudo-eigenvalue satisfies, amongst other interesting properties, $(-1)^k\eta_{f^*}=\overline{\eta_f}$ , I write, with the Petersson inner product $$
\langle f^*,w_nf\rangle_{\Gamma_1(N)}=\overline{\eta_f}\langle f^*,f^*\rangle_{\Gamma_1(N)}
$$ $$
\langle f^*,w_nf\rangle_{\Gamma_1(N)}=\langle w_n^\dagger f^*,f\rangle_{\Gamma_1(N)}=(-1)^k\eta_{f^*}\langle \underbrace{f}_{=f^{**}},f\rangle_{\Gamma_1(N)},
$$ but now I need these two inner product to be equal, but I don't see how this is true. I first tried to show that $f\cdot \bar{f}=f^*\cdot\bar{f^*}$ , but this didn't seem to hold, and then tried to prove by subsitution of variables ( $z\mapsto -\bar{z})$ in the Petersson inner product, but I don't see how the fundamental domain is invariant under this transformation, as it's not given by a $\text{SL}_2(\mathbb{Z})$ -matrix. What is a way to show that the inner product are in fact equal?","['number-theory', 'real-analysis', 'linear-algebra', 'modular-forms', 'group-theory']"
3668696,"Every collection of 5 subsets of size 6 drawn from $\{1, 2, . . . , 15\}$, at least two of the subsets must intersect in at least two points.","Theorem: Suppose that $A_1, . . . , A_k$ is a collection of $k ≥ 2$ sets. Show that (using induction), $$\big| \bigcup\limits_{i=1}^{k}A_i \big| \ge \sum\limits_{i=1}^{k} \big|A_i| - \sum\limits_{\{i,j\}} \big|A_i \cap A_j \big| $$ where the second term on the right sums over all subsets of [k] of size 2. Question: Deduce that in every collection of 5 subsets of size 6 drawn from $\{1, 2, . . . , 15\}$ ,
at least two of the subsets must intersect in at least two points. What I've tried: Let $|I| = 6$ and $i$ be one of 5 subsets s.t. $$\big| \bigcup\limits_{i=1}^{k}A_i \big| = \sum_{0 \neq I \subseteq [k]}(-1)^{6 + 1} \big| \bigcap\limits_{i \in I} A_i \big|$$ Since, 6 does not divide 15, $$\big| \bigcap\limits_{i \in I} A_i \big| = 0$$ $$\implies \big| \bigcup\limits_{i=1}^{k}A_i \big| = 0$$ Since, RHS of the inequality cannot be negative as $$\sum\limits_{i=1}^{k} \big|A_i| > \sum\limits_{\{i,j\}} \big|A_i \cap A_j \big|$$ We are left with, $$\sum\limits_{i=1}^{k} \big|A_i| - \sum\limits_{\{i,j\}} \big|A_i \cap A_j \big| = 0$$ And going back to the fact that $\frac{15}{6} = \frac{5}{2}$ each subject must contain at-least two common elements with another subset. Is my proof correct? - I think I may be over thinking it...","['inclusion-exclusion', 'discrete-mathematics']"
3668730,Fibration and a morphism which is homotopic to a fiber bundle,"Let $f:X\to Y$ be a surjective holomorphic map between two compact complex manifolds. Suppose that $R^if_*\mathbb{Q}_X$ are locally constant sheaves over $Y$ for all $i$ , and $f$ is homotopic to a $C^{\infty}$ -fiber bundle. Q: Is it true that $f$ is a fibration, in particular, all the fibers of $f$ are homotopic to each other? Any related reference is wellcome.","['complex-geometry', 'algebraic-geometry', 'homotopy-theory', 'algebraic-topology']"
3668752,"Unable to invert matrix on Galois Field, even though the matrix should be invertible by construction","We are trying to implement a general file recovery algorithm using Galois Fields. We have implemented the operations for Galois Fields GF(2^8) succesfully, but we're are running into a problem for the case with 4 data drives and 4 parity drives. More specifically, the case where data drives 0, 1, and 2, and parity drive 2 are missing. Following the implementation in this paper , we construct an 8 by 4 matrix: 1   0   0   0 
0   1   0   0
0   0   1   0
0   0   0   1
1   1   1   1
1   2   3   4
1^2 2^2 3^2 4^2
1^3 2^3 3^3 4^3 Since datadrives 0, 1, and 2, and parity drive 2 are compromised, we omit the rows 0, 1, 2, and 6. That leaves 0   0   0   1         0  0  0  1 
1   1   1   1     =   1  1  1  1
1   2   3   4         1  2  3  4
1^3 2^3 3^3 4^3       1  8 15 64 Let's call this matrix A'. If D is the data vector, and E' is the vector corresponding to the data on the drives that did not fail, we should be able to solve A' D = E' for D. D = A'^{-1} A' D = A'^{-1} E' However, matrix A' doesn't seem to be invertible. See also this code snippet at sageMath: SageMath even shows that the matrix can be simplified to A' =
[0 0 0 1]
[1 1 1 1]
[1 0 1 0]
[1 0 1 0] which is clearly not invertible. Somehow the parity rows [1^1, 2^1, 3^1, 4^1] and [1^3, 2^3, 3^3, 4^3] are linearly dependent. 
We thought these rows were constructed to be independent, even with the operations on GF(2^8) Clearly, we're missing something, but at this point, we're not sure what's happening here. UPDATE 1 So it turns out the generator matrix in that paper was completely wrong. Following the suggestion by Jyrki in the comments here , we constructed the desired matrix starting from a variant of the Vandermonde matrix. This variant is of the form: $$G = \left( \begin{array}{ cccc }
  \alpha_0^0 & \alpha_0^1 & .. & \alpha_0^d \\
  \alpha_1^0 & \alpha_1^1 & .. & \alpha_1^d \\
  .. & .. & .. & .. & .. \\
  \alpha_{d+p}^0 & \alpha_{d+p}^1 & .. & \alpha_{d+p}^d \\
\end{array} \right)$$ where the $d$ is the number of data bits, $p$ is the number of parity bits, and $\alpha_i$ are chosen elements of order $2^8$ in $GF(2^8)$ . These alpha can be constructed by taking the Galois Field element with 2 as its integer representation, and raising it to a power that shares no prime factors with $2^8 - 1$ . So: $\alpha_0 = 2^1$ , $\alpha_1 = 2^2$ , $\alpha_2 = 2^4$ (skip $2^3$ because 3 has a prime in common with $2^8-1$ ), $\alpha_3 = 2^7$ (skip $2^5$ and $2^6$ because 5 and 6 share prime factors with $2^8-1$ ), $\alpha_4 = 2^8$ , etc I must admit that I don't understand this argument completely, but it works for now. For the top $d \times d$ block (let's call it $P$ ), we compute $P^{-1}$ and calculate $GP^{-1}$ to get it in the desired form. We also tried the matrix on described in this paper , which uses the same base $\alpha$ , which also works as far as we can tell. We have also looked at multiple other software implementations, where they appear to determine the parity block in one go (so without calculating $GP^{-1}$ . The code however is very difficult to understand. Could there be a standard procedure to immediately generate that bottom block or do these software packages only work for a specific order of the field and polynomial?","['galois-theory', 'finite-fields', 'linear-algebra']"
3668789,Is Hartshorne exercise II.2.15(b) correct as written?,"Here is the text of the exercise: If $f:X \rightarrow Y$ is a morphism of schemes over $k$ , and $P \in X$ is a point with residue field $k$ , then $f(P) \in Y$ also has residue field $k$ . In the case where $X$ and $Y$ are spectra of fields, this reduces to: If $K \subset L \subset M$ are fields and $K \cong M$ , then $K \cong L$ . which I believe is false, or else we could derive, for example, $\mathbb C \cong \mathbb C (x)$ . Am I mistaken?",['algebraic-geometry']
3668824,Basic question for Conditional expectation conditioned on X=x,"I have a basic question on conditional expectation. First I'll summarize my understandig of them (could be wrong). On a probablity space $(\Omega,\mathcal{A},\mathbb{P})$ the conditional expectation $\mathbb{E}[ X \vert \mathcal{H} ]$ of an $\mathbb{P}$ -integrable random number $X$ conditioned on
a sub- $\sigma$ -field $\mathcal{H}\subset \mathcal{A}$ is the almost sure unique $\mathbb{P}$ -integrable and $\mathcal{H}$ -measurable random number $E$ with \begin{equation}
    \int_A E \; d\mathbb{P} = \int_A X \; d\mathbb{P},
    \qquad\qquad
    \forall \; A\in\mathcal{H}
\end{equation} In particular $\mathbb{E}[X\vert \mathcal{H}] = \mathbb{E}X$ almost surely, if $X$ and $\mathcal{H}$ are
independent. If $\mathcal{H}=\sigma H$ for a random variable $H$ in some measurable space $(S,\mathcal{S})$ , then $\mathbb{E}[ X \vert H ]=\mathbb{E}[X\vert \mathcal{H}]$ has the form $E = f\circ H$ for a $\mathcal{S}$ / $\mathcal{B}$ -measurable function $f:S\rightarrow \mathbb{R}$ . One writes $\mathbb{E}[ X \vert H=s ] = f(s)$ for $s\in S$ . Now lets say $X$ is of the form $X=g(Y,H)$ for a measurable function $g$ and a random variable $Y$ , 
where $Y$ is independent of $H$ . Now the question: What is $\mathbb{E}[ g(Y,H) \vert H=s ]$ ? is it $\mathbb{E}[ g(Y,s) ]$ ?","['conditional-expectation', 'conditional-probability', 'probability-theory']"
3668942,Ideas for parameterizing this curve in the complex plane and calculating its length by (numerical) contour integration?,"Let $Z (t)$ be the Hardy Z function. Then define \begin{equation}
  Y (t) = \tanh (\ln (1 + Z (t)^2))
\end{equation} Let us define the length $L_n$ of the curve which intersects the $n$ -th Zero
of $Z (t)$ as a contour integral of the indicator function \begin{equation}
  \label{cont} L_n = \oint_{H_n} 1 d t
\end{equation} where \begin{equation}
  H_n = \{ (t, s) : {Re} (Y (t + i s)) = 0 : H_n \cup \{ y_n \} = \{ y_n
  \} \}
\end{equation} is the $n$ -th set of points determining the curves where the real part of $Y$ vanishes and $y_n$ is the $n$ -th real zero of the Hardy Z function ordered by
ascending magnitude, independently of the Riemann hypothesis; which states
that all of the roots lie on the real line. If there are roots of the zeta
function off of the line, they will appear as complex roots of $Z (t)$ other
than the trivial ones or the points where Z(t)=i*sqrt(2) To calculate the value of the contour integral  , the following
algorithm is proposed: a. Choose parameter $n$ , the zero of the index; b. Choose parameter $h$ , the delta with which the integral will be
calculated Let $x_0 = y_n$ and ${L_n} = 0$ Determine angle $\theta_m \in \left[ 0, \frac{\pi}{2} \right]$ where \begin{equation}
  \label{angle} \theta_m = \left\{ a : {Re} (Y ({circle} (x_{m - 1},
  h, a))) = 0, 0 < a < \frac{\pi}{2} \right\}
\end{equation} when iterating from $x_{(m - 1)}$ to $x_m$ a step length of $h$ and angle $\theta_m (h)$ given by the circle with radius $h$ centered at $z$ defined by
the formula \begin{equation}
  {circle} (z, h, \theta) = z + h (\cos (\theta) + i \sin (\theta))
\end{equation} where angle parameter $\theta$ varies from $0$ to $\pi$ and $z = t + i s$ . Set \begin{equation}
  x_m = {circle} (x_{m - 1}, h, \theta_m)
\end{equation} and \begin{equation}
  {L_n} = {L_n} + h
\end{equation} then $m$ represents the index of the $m$ -th iterate of the Newton iteration $\theta_m (h) = \lim_{k \rightarrow \infty} N_{\theta_m} (a_k ; h)$ defined
below. If $x_m = y_n$ then terminate because the loop has reached its beginning
point, and ${L_n}$ will be its length; else set \begin{equation}
  m = m + 1
\end{equation} and goto Step 4. In order to find an explicit expression for the angle $\theta_m (h)$ we can use Newton's method \begin{equation}
  \label{N} N_{\theta_m} (a_k ; h) = a_{k - 1} - \frac{Y ({circle} (x_m,
  h, a_{k - 1}))}{\frac{d}{da} Y ({circle} (x_m, h,
  a))_{|_{a = a_{k - 1}}}}
\end{equation} so that \begin{equation}
  \theta_m = \theta_m (h) = \lim_{k \rightarrow \infty} N_{\theta_m} (a_k ; h)
\end{equation} which is dependent on $h$ , but the when the dependence is not written as $\theta_m (h)$ it is still implied. To calculate $\frac{d}{d a}
Y ({circle} (x_m, h, a))_{|_{a = a_{k - 1}}}$ let \begin{equation}
  \rho_{} (h, a) = h (i \cos (a) - \sin (a))
\end{equation} and differentiate $Y (t)$ to get \begin{equation}
  \frac{d}{d t} Y (t) = \frac{d}{d t} \tanh (\ln (1 + Z
  (t)^2)) = \frac{8 (1 + Z (t)^2) Z (t) \frac{d}{d t} Z (t)}{(Z
  (t)^4 + 2 Z (t)^2 + 2)^2}
\end{equation} then it can be seen that $\begin{array}{ll}
  \frac{d}{da} Y ({circle} (t, h, a)) & = \frac{d}{
  da} Y (t + h e^{i \pi a})\\
  & = \frac{d}{d a} \tanh (\ln (1 + Z (t + h e^{i \pi a})^2))\\
  & = \frac{8 (1 + Y (t)^2) Y (t) }{(Y (t)^4 + 2 Y (t)^2 + 2)^2}
  \frac{d}{d t} Y (t) h e^{i \pi a}\\
  & = \frac{8 (1 + Y (t)^2) Y (t) }{(Y (t)^4 + 2 Y (t)^2 + 2)^2} \frac{8 (1 +
  Z (t)^2) Z (t)}{(Z (t)^4 + 2 Z (t)^2 + 2)^2} \frac{d}{d t} Z (t) h
  e^{i \pi a}\\
  & = i 8 \pi h \hspace{0.17em} \mathrm{e}^{i \pi a} Z (t) \frac{ (Z (t) + i)
  (Z (t) - i) }{(Z (t)^2 + 1 + i)^2  (Z (t)^2 + 1 - i)^2}
  \frac{d}{d t} Z (t)
\end{array}$ and therefore the Newton iteration for the angle is expressed as \begin{equation}
  \begin{array}{ll}
    N_{\theta_m} (t, a_k ; h) & = a_{k - 1} - \frac{Y (t)}{\frac{8 (1 + Y
    (t)^2) Y (t) }{(Y (t)^4 + 2 Y (t)^2 + 2)^2} \frac{d}{d t} Y (t)
    \rho_{} (h, a_{k - 1}) )}\\
    & = a_{k - 1} - \frac{Y (t)}{\frac{8 (1 + Y (t)^2) Y (t) }{(Y (t)^4 + 2 Y
    (t)^2 + 2)^2} \frac{8 (1 + Z (t)^2) Z (t) \frac{d}{d t} Z
    (t)}{(Z (t)^4 + 2 Z (t)^2 + 2)^2} \rho_{} (h, a_{k - 1}) )}
  \end{array}
\end{equation} by the change-of-variables \begin{equation}
  \begin{array}{ll}
    t \rightarrow & {circle} (x_m, h, a_{k - 1})\\
    & = x_m + \rho (h, a_{k - 1})\\
    & = x_m + h (\cos (a_{k - 1}) + i \sin (a_{k - 1}))
  \end{array}
\end{equation} The set $H_1$ is black  depicted as the boundary of the 1st hour-glass figure in this plot of the Real part of Y over -12..27 and imaginary part -3..3 . The values of the real part of $Y$ have opposite signs inside and outside of the sets defined by the union of the curves $H_n$ . Here $H_n$ is the Julia set of some dynamical system. My question: Is there a better or different way of calculating the length of these curves? Maple code to calculate the length at https://github.com/crowlogic/Y/blob/master/tracecurve.mpl The first top-half curve length is  4.263..
The second is                       2.982... Real part of Y from Re=12..27 and Im=-3..3 Imag part of Y from Re=12..27 and Im=-3..3 Complex plot of Y from Re=12..27 and Im=-3..3 The sign of the argument of Y which gets very small is shown here: See https://gist.githubusercontent.com/crowlogic/027ea86b58b0fabf8e99d25a685d9196/raw/d55bbc5c866c185b106b44e84d39b6a37f24bb95/maple%2520tracecurve%2520log.txt for the maple script output","['arc-length', 'plane-curves', 'curves', 'complex-analysis', 'riemann-zeta']"
3668949,Recent developments in the proof of fermat's last theorem,It's been 20 years since fermat's last theorem was proved by Andrew Wiles. Has there been any simplification in proof in the last 20 years? What I do only know is that different proofs of faltings's theorem were given by Vojta and Bombieri.,"['number-theory', 'algebraic-geometry', 'elliptic-curves']"
3668979,Is this an okay way to calculate covid-19 death rates?,"I'm a tad rusty on my math skills but this isn't too hard. Can you confirm that I am doing this right. I wanted to know what percent of people die from covid-19 so I started looking for statistics. To my surprise the CDC , the WHO , and Google publish statistics: But then I found this article in Science which says that 86% of all infections go undocumented. To adjust for that I do: (total)(1-.86)=confirmed
total = confirmed/.14 Which works out to: Then I wanted to see how that works out by age. To my surprise (again) the CDC has an awesome tool for that (Thank you CDC!). Here's a link to the tool . I can't link to my results because you have to login to save your search and I don't want to mess with that right now. Anyways I created the following report: Dimension: Age Group
Measure: COVID-19 Deaths
Filters:
    From 2/1/2020-5/10/2020
    Sex (Male and Female) And the results are : Which for the particular date range that I selected amounts to 87,116 deaths. If you transform that into what percent of people are dying by age you get: Next, I used the Census information for 2019 to get what percent each age range is of the total U.S. population (super lucky the age ranges matched up!!!): So right off the bat you can see it has a massively disproportionate effect on older folks ( interesting graph ). The last thing then is to figure out what the odds are of dying from covid-19 for each age range. I had to get some help for this part. I think I have all the numbers plugged in right. It just uses Bayes' Theorem (which sadly I never studied): *using 35-44 as example:
P(age range death rate | population death rate) = (age range death rate)(population death rate) / P(age range) = (.016)(.0097)/.126 = .0012 = .12% Filling out the rest of the table the death rates by age are: I would be much obliged if you could check that the mathematical operations that I performed support the conclusions I drew in my final table. Especially if you could double check that I used Bayes' Theorem the right way. Thank you!","['statistics', 'probability']"
3668983,On Complex sequences inequalities,"Attempt: (a) If $m>n$ , Notice that $\dfrac{1}{1+|m-n|} < \dfrac{1}{|m-n|} < \dfrac{1}{m-n} < \dfrac{1}{n} $ . So that if choosing $N > 1/\epsilon$ then we obtain $|z_m-z_n| < \epsilon$ so (z_n) is cauchy so convergent. I claim that limit is $0$ . We need to observe that as $n$ gets large, the separation of the terms of the sequence gets smaller. In fact, if $m = 2n $ , then $$ |z_{2n} - z_n | < \dfrac{1}{1+n} < \dfrac{1}{n} \to \infty
$$ Im having some difficulties making this formal. Any suggestion? As for (b), we know $|w_n| < B$ for all $n$ and after some $N$ , we have that $|z_n| < \epsilon / B $ . So, with this same $N$ , we obtain that $$ | w_n z_n |  < B \cdot \frac{ \epsilon }{B} = \epsilon $$ and we have the result. (c). We can find $N$ so that for $n>N$ we have $|z_n - A| < \epsilon $ So that with this same $N$ , we have $$ \left| \dfrac{ z_1 + ... + z_n }{n } - A \right| = \left| \dfrac{ z_1+...+z_n - n A }{n} \right| \leq \dfrac{ \sum_{i=1}^n |z_i - A | }{n} \leq \dfrac{ n \sup_{n \in \mathbb{N} } |z_n - A | }{n} < \epsilon$$ and result follow. Is this a valid argument?","['analysis', 'real-analysis', 'complex-analysis', 'solution-verification', 'sequences-and-series']"
3668992,"The only group $G$ with one $A$ and one $B$ as composition factors is $G = A\times B$ (where $A$ and $B$ are non-abelian, finite and simple)","Is it true that if $A$ and $B$ are two non-abelian finite simple groups, then the only finite group $G$ which has one copy of $A$ and one copy of $B$ as composition factors is $G = A \times B$ ? If not, could someone give a counterexample or even better, a reason why this isn't true? Certainly, these are the two types of extensions we have to consider: $$1 \to A \to G \to B \to 1$$ $$1 \to B \to G \to A \to 1$$ It seems true so for all the examples I tried, but I don't have definitive proof.","['direct-product', 'group-extensions', 'exact-sequence', 'abstract-algebra', 'group-theory']"
3669032,Intuition: $\frac{1}{p}+\frac {1}{q} = 1$ equivalent to $(p-1)(q-1)=1$.,"It is easy to show mathematically that if $p,q \ne 0$ then $$\frac{1}{p}+\frac {1}{q} = 1 \qquad \Leftrightarrow \qquad (p-1)(q-1)=1 .$$ But intuitively, I would never have guessed this relationship.  Does anyone have an intuitive argument that makes this obvious? Added later: There are two very nice answers that reduce it to $$ x+y = 1 \qquad \Leftrightarrow \qquad xy = (1-x)(1-y) .$$ They only actually show $\Rightarrow$ . One of the answers does this by reflecting around the line $x+y=1$ .  The other answer uses probability, but essentially boils down to saying that if $x+y=1$ , then the unordered pair $\{x,y\}$ is the same as the unordered pair $\{1-x,1-y\}$ , that is, a reflection which sends $(x,y)$ to $(1-y,1-x)$ .  So in some sense the two answers are identical, but expressed differently. Once you know $\Rightarrow$ , you can get $\Leftarrow$ as follows.  Suppose $(1-x)(1-y) = xy$ .  Let $z = 1-y$ .  From $\Rightarrow$ we get $(1-z)(1-y) = zy$ .  Hence $$ \frac{1-x}x = \frac y{1-y} = \frac{1-z}z $$ Hence $x=z$ and so $x=1-y$ . I would like to accept both answers, but I cannot.  So following principles of distribution of wealth (points), I am accepting the one that comes from the person with less points.","['algebra-precalculus', 'intuition']"
3669055,"A simple geometric problem, solving $f'(x)=\frac{f(x)}{\sqrt{r(x)^2-f(x)^2}}$, given $r(x)$.","Introduction Suppose we have a convex, real function $f(x)$ . We can define a tangent line to this function $t(x,s)$ . Then, we can find the intersection of $t(x,s)$ with the $x$ axis. Let's call this point $o(x)$ . Then we define $l(x)$ as $o(x)-x$ and $r(x)^2=l(x)^2+f(x)^2$ . See my poorly drawn graphic for a visual explanation: The simple questions we can ask ourselves are: What are $l(x)$ and $r(x)$ for a given $f(x)$ ? The answer is $$l(x)=\frac{f(x)}{f'(x)}\qquad\qquad 
r(x)=\sqrt{\frac{f(x)^2}{f'(x)^2}+f(x)^2}$$ A slightly more difficult question is to ask: What are $f(x)$ and $r(x)$ , if $l(x)$ is known? The answer is: $$f(x)=c\exp\left(\int_1^x \frac{1}{l(s)}\text{d}s\right)\label{f(l)}\qquad\qquad
r(x)=\sqrt{c^2\exp\left(2\int_1^x \frac{1}{l(s)}\text{d}s\right)+l(x)^2}$$ A real challenge is to find What are $f(x)$ and $l(x)$ , if $r(x)$ is known? I have no answer to that question. A simple way of deriving the necessary ODE's can be found from: $$    \arctan(f')=\arctan\left(\frac{f}{l}\right)\\
    \arctan(f')=\arcsin\left(\frac{f}{r}\right)\\
    \arctan(f')=\arccos\left(\frac{l}{r}\right)$$ which you can deduce from the figure above. If we find the solution for $f(x)$ in terms of $r(x)$ we can automatically find $l(x)$ . In short, my question reduces to Solve the following ODE for $f(x)$ knowing $r(x)$ : $$f'(x)=\frac{f(x)}{\sqrt{r(x)^2-f(x)^2}}$$ I hope you find the project interesting and I'm looking forward to your collaboration. Suggested approaches Try it with Maple. There is evidence that Mathematica doesn't handle this problem correctly, whereas Maple might. Compare the ODE to one of the forms in HANDBOOK OF EXACT SOLUTIONS for ORIDINARY DIFFERENTIAL EQUATIONS by Polyanin and Zaitsev, or any other similar source. Use Mathematica or similar software to generate a series expansion of the function in question and try to guess the pattern. The code in Mathematica is: sol1 = AsymptoticDSolveValue[{y[x]^2*y'[x]^2 + 
 y[x]^2 - (r[x])^2*y'[x]^2 == 0}, y[x], {x, 0, n}] where n is the order of the expansion (n=4 recommended for start). Using split-quaternions $(\mathbb{P})$ factorisation. We can rewrite the problem as: $$-r(x)^2 y'(x)^2+y(x)^2 y'(x)^2+y(x)^2=0$$ Notice that a polynomial $p\in \mathbb{R}[a,b,c], p=a^2+b^2-c^2$ can be factor in $\mathbb{P}[a,b,c]$ as $$p=(a+bi +cj)(a-bi-cj)$$ This suggests that we can factor $$y(x)^2 y'(x)^2+y(x)^2-r(x)^2 y'(x)^2=0\\
(y(x)y'(x) +y(x) i +r(x)y'(x) j)(y(x)y'(x) -y(x) i -r(x)y'(x) j)=0$$ and solve independently $$y(x)y'(x) +y(x) i +r(x)y'(x) j=0\\
y(x)y'(x) -y(x) i -r(x)y'(x) j=0$$ Here we discussed how this technique was applied to a simpler problem with success. Whether this technique is legitimate is still unclear to me. Solve for $r(x)$ as a function of $l(x)$ and then convert to $f(x)$ . One can use any of the techniques described above. Refer to this for one of the forms I obtained in terms of $l(x)$ . (Note that following the link $l(x)$ is replaced by $f(x)$ ) Physical applications Here we discuss the possible applications in the field of physics. Physical interpretation of $l(x)$ Imagine there is an object that you cannot see. However, this object casts a shadow on the surface of Earth, since the sun is shining on it. You can only measure the length of this shadow. Can you deduce the shape of the object by measuring the shadow as the sun progresses over the Earth?. The answer is yes, and if we denote this shadow by $l(x)$ we can use the formulas discussed in this question to find $f(x)$ . This easily generalizes to 3D but this is not interesting for us. In the real world this technique is applied in spectroscopy. Physical interpretation of $r(x)$ When $r(x)=const.$ we obtain an equation of a tractrix . For a generin $r(x)$ can this equation can be interpreted as an equation of a tractrix with a variable chain length? Still in progress. Other ways to contribute Properties of the solution for $f(x)$ or $l(x)$ If solving the ODE is out of reach, we could still try to find some of it's properties. Try to discuss the existence and uniqueness of the solution given that $r(x)>0$ , $l(x)>0$ and $f(x)$ is concave. Examples: The solution should be a function of $x+const.$ Constructing a table of special cases of the solution A good way of understanding the problem is to evaluate $r(x)$ for various $f(x)$ . Below is a table of some examples. The code for generating this in Mathematica is fs = {f[x], x, x^2, x^n, a + b x, a + b x + c x^2, Sin[x], Cos[x], 
Tan[x], Sinh[x], Cosh[x], Tanh[x], ArcSin[x], ArcCos[x], ArcTan[x], 
ArcSinh[x], ArcCosh[x], ArcTanh[x], Exp[x], Log[x]}
ys = {};
xs = {};
For[ii = 1, ii <= Length[fs], ii++,
g[x] = fs[[ii]];
AppendTo[ys, 
Simplify[Sqrt[g[x]^2 + g[x]^2/D[g[x], x]^2]] // Refine];
AppendTo[xs, fs[[ii]] // Refine]]
Text@Grid[Prepend[Transpose[{xs, ys}], {""f[x]"", ""r[x]""}], 
Background -> {None, {Lighter[Yellow, .9], {White, 
Lighter[Blend[{Blue, Green}], .8]}}}, 
Dividers -> {{Darker[Gray, .6], {Lighter[Gray, .5]}, 
Darker[Gray, .6]}, {Darker[Gray, .6], Darker[Gray, .6], {False}, 
Darker[Gray, .6]}}, Alignment -> {{Left, Right, {Left}}}, 
Frame -> Darker[Gray, .6], ItemStyle -> 14, 
Spacings -> {Automatic, .8}] PS I've been passively working on this problem for 5 years... I started it in my first year of University. A year ago my friend with whom I've shared this idea challenged me to solve this question before I turn 25 years of age. I must accept my defeat as today I turned 25 and hence I'm making this project public.","['physics', 'trigonometry', 'geometry', 'ordinary-differential-equations']"
3669066,Examining the convergence of $\sum\limits_{n=1}^{+\infty}(-1)^{n+1}\Bigl(1-2\exp\Bigl(\sum\limits_{k=1}^{n}\frac{(-1)^k}k\Bigr)\Bigr)$,"Problem: Examine the convergence of the series $$\sum_{n=1}^{+\infty}(-1)^{n+1}\left(1-2\exp\left(\sum_{k=1}^n\frac{(-1)^k}k\right)\right).$$ Solution (part): For the sequence $\alpha_n=(-1)^{n+1}\Big(1-2\exp\Big({\textstyle\sum_{k=1}^{n}\frac{(-1)^k}{k}}\Big)\Big)\,,\; n\in\mathbb{N}\,,$ we have that $\alpha_{n}>0$ for all $n\in\mathbb{N}$ . Indeed \begin{alignat*}{2}
\log2+\sum_{k=1}^n\frac{(-1)^k}{k}&=\begin{cases}
>0\,, &n\;{\text{even}}\\
<0\,,&n\;{\text{odd}}
\end{cases}\quad&&\Rightarrow\\
\exp\big(\log2+\textstyle{\sum_{k=1}^n\frac{(-1)^k}{k}}\big)&=\begin{cases}
>1\,, & n\;{\text{even}}\\
<1\,,&n\;{\text{odd}}
\end{cases}\quad&&\Rightarrow\\
2\,\exp\big(\textstyle{\sum_{k=1}^n\frac{(-1)^k}{k}}\big)&=\begin{cases}
>1\,, & n\;{\text{even}}\\
<1\,,&n\;{\text{odd}}
\end{cases}\quad&&\Rightarrow\\ 
1-2\,\exp\big(\textstyle{\sum_{k=1}^n\frac{(-1)^k}{k}}\big)&=\begin{cases}
<0\,, & n\;{\text{even}}\\
>0\,,&n\;{\text{odd}}
\end{cases}\quad&&\Rightarrow\\ 
\alpha_n=(-1)^{n+1}\Big(1-2\exp\Big({\textstyle\sum_{k=1}^{n}\frac{(-1)^k}{k}}\Big)\Big)&>0\,.
\end{alignat*} $(\alpha_{n})_{n\in\mathbb{N}}$ is decreasing. ( This I wasn't able to prove fully.) $\lim(n\,\alpha_n)\neq0$ . Indeed, for all $n\in\mathbb{N}$ we have \begin{alignat*}{2}
\log2+\sum_{k=1}^{2n}\frac{(-1)^k}{k}&\stackrel{(*)}{>}\log\big(1+\tfrac{1}{20n}\big)>0\quad&&\Rightarrow\\
\exp\big(\log2+\textstyle{\sum_{k=1}^{2n}\frac{(-1)^k}{k}}\big)&>\exp\big(\log\big(1+\tfrac{1}{20n}\big)\big)=1+\frac{1}{20n}\quad&&\Rightarrow\\
-1+2\exp\big(\textstyle{\sum_{k=1}^{2n}\frac{(-1)^k}{k}}\big)&>-1+1+\frac{1}{20n}=\frac{1}{20n}\quad&&\Rightarrow\\
\alpha_{2n}=(-1)^{2n+1}\Big(1-2\exp\big(\textstyle{\sum_{k=1}^{2n}\frac{(-1)^k}{k}}\big)\Big)&>\frac{1}{20n}\quad&&\Rightarrow\\
\lim_{n\to+\infty}(2n\,\alpha_{2n})&\geqslant\lim_{n+\infty}2n\,\frac{1}{20n}=\frac{1}{10}\,.
\end{alignat*} Because $\alpha_{n}>0$ for all $n\in\mathbb{N}$ , we conclude that $\lim(n\,\alpha_n)\neq0$ . By Abel's-Pringsheim's theorem the series diverges. (*) Proof? Ideas about the monotonicity of the sequence?","['convergence-divergence', 'sequences-and-series']"
3669086,How does Elo rating scale with games played?,I only take two players starting out at 0 Elo and have them play against each other with one player winning all games. Also I consider a pure version of the Elo system without artificially introduced cut-offs (like FIDE's 400 point rule). The winner is constantly gaining rating while the other player is losing Elo rating. The gain is decreasing because the rating difference of the players increases. How does (mathematically) the Elo rating scale with the number of games ( n ) played for large n ?,"['mathematical-modeling', 'probability']"
3669124,Do we need rectangles for the Riemann integral?,"The basic way the one-dimensional Riemann integral is extended to multiple integrals over bounded domains $D \subset \mathbb{R}^n$ is as follows. We extend the function $f:D \to \mathbb{R}$ we want to integrate to all of $\mathbb{R}^n$ , by defining $f(x)=0$ for all $x \in \mathbb{R}^n \setminus D$ . We enclose $D$ in a hyperrectangle $H \supset D$ , say $H=[a_1, b_1] \times [a_2, b_2] \cdots \times [a_n \times b_n]$ . A partition $P$ of $H$ is an $n$ -tuple $(I_1, I_2, ..., I_n)$ where each $I_i=\{S_{i,0}, S_{i,1}, \cdots, S_{i,k_i}\}$ $(k_i \geq 1)$ is a usual one-dimensional partition of $[a_i, b_i]$ into disjoint subintervals $S_{i,j}$ . Each such partition partitions $H$ into various sub-hyperrectangles, and a Riemann sum can be defined in the usual way by choosing ""tags"" in each such sub-hyperrectangle. If there is a meaningful limit that all such Riemann sums approach, independent of the choice of ""tags"", as the maximal subrectangle hyperrarea  of the partitions approaches $0$ , we say $f$ is Riemann integrable on $D$ , and the value of the limit is the value of the integral. Problem: can this be defined without hyperrectangles? Somehow, I don't feel that they are truly needed here, and any partitions of $D$ will do. Specifically, I would propose the following. We assume that $D$ is a ""nice"", closed and bounded region (perhaps homeomorphic to the closed $n$ -ball, but the answerer can propose any reasonable definition of ""niceness""). A partition of $D$ is a finite collection of disjoint, nonempty, compact (hence Lebesgue measurable), connected sets $\{S_i\}$ whose union is $D$ , and the norm $||P||$ of $P$ is defined to be $\max_{i} \mu(S_i)$ where $\mu$ is the $n$ -dimensional Lebesgue measure. We define Riemann sums as usual, namely sums of the form $\sum_{i} f(t_i) \mu(S_i)$ , $t_i \in S_i$ , and if a limit $\ell$ is approached as $||P|| \to 0$ , independent of the choice of tags, we say $f$ is Riemann integrable on $D$ with integral $\ell$ . The basic concern I have with this, however, is that now we're working with much more general partitions, and hence there is a possibility of pathological situations. In particular, there may be functions integrable with respect to the original definition, but not integrable with respect to the second definition. Question: does this work, and is it equivalent?","['riemann-integration', 'real-analysis']"
3669169,"construct an asymptotic, analytic function, which outperforms $\frac{x}{\log(x)}$ but isn't quite as good as $\text{Li}(x)$?","The offset logarithmic integral is defined as $$ \text{Li}(x)=\int_2^x\frac{1}{\log(t)}~dt. $$ It can be shown that $\text{Li}(x)\sim\pi(x)$ where $\pi(x)$ is the prime counting function. It can also be shown that $\frac{x}{\log(x)}\sim \pi(x).$ Is there any practical use in number theory for constructing an asymptotic, analytic function, which outperforms $\frac{x}{\log(x)}$ but isn't quite as good as $\text{Li}(x)$ ? Note: $\text {Li}(x)$ is the best possible asymptotic formula to approximate $\pi(x).$","['number-theory', 'asymptotics', 'prime-numbers', 'logarithms']"
3669179,Can an Perron eigenvector of a non-symmetric irreducible nonnegative matrix be also a Perron eigenvector of its transpose?,"Let $\mathbf{X}$ be nonnegative irreducible matrix such that $\mathbf{X} \ne \mathbf{X}^T$ . Let $\mathbf{p}(\mathbf{A})$ denote a right eigenvector corresponding to the Perron root of $\mathbf{A}$ , $\rho(\mathbf{A})$ . Similarly, $\mathbf{q}(\mathbf{A})$ denotes a left eigenvector corresponding to $\rho(\mathbf{A})$ . (In the textbook I'm reading, left eigenvectors are column vectors corresponding to the right eigenvector of $\mathbf{A}^T$ .) A remark in the textbook seems to imply that as long as $\mathbf{X} \ne \mathbf{X} ^ T$ , $\mathbf{p}(\mathbf{X}) \ne \alpha \mathbf{p}(\mathbf{X}^T)$ for any constant $\alpha$ . EDIT: As requested by @user1551, here is the exact remark from Fundamentals of Resource Allocation in Wireless Networks : Finally, as $\mathbf{X}^T\in W_K(\mathbf{X})$ for any $\mathbf{X} \in X_K$ , it follows from Theorem 1.14 that $\rho((1-\mu) \mathbf{X} + \mu\mathbf{X}^T)$ is a concave function on $\mu \in [0,1]$ . If, in addition, $\mathbf{X}\ne \mathbf{X}^T$ , we have $\mathbf{p}(\mathbf{X}) \ne \alpha \mathbf{p}(\mathbf{X^T})$ for any constant $\alpha$ . $X_K$ is the set of nonnegative irreducible $K$ -by- $K$ matrices. 
For $\mathbf{X}\in X_K$ , $W_K(\mathbf{X}) = \{\mathbf{Y}\in X_K : \mathbf{q}(Y)\circ \mathbf{p}(\mathbf{Y}) = \mathbf{q}(X)\circ \mathbf{p}(\mathbf{X}) \in \Pi_K^{+}\}$ , where $\Pi_K^+$ is the standard simplex restricted to positive values. In an effort to prove the remark, I started a proof by contradiction. Suppose that $\mathbf{p}(\mathbf{X}^T)\equiv \mathbf{q}(\mathbf{X})$ is also a right Perron eigenvector of $\mathbf{X}$ . By definition of left and right Perron eigenvectors, $\mathbf{X}^T \mathbf{q}(\mathbf{X}) = \rho(\mathbf{X})\mathbf{q}(\mathbf{X})$ and $\mathbf{X}\mathbf{q}(\mathbf{X}) = \rho(\mathbf{X})\mathbf{q}(\mathbf{X})$ . Subtracting the two equations, I get $(\mathbf{X}-\mathbf{X}^T)\mathbf{q}(\mathbf{X}) = \mathbf{0}$ , and I'm not sure how to proceed. The only conclusion I get from this equation is that $\mathbf{q}(\mathbf{X})$ is in the null space of $\mathbf{X} - \mathbf{X}^T$ .","['transpose', 'linear-algebra', 'eigenvalues-eigenvectors']"
3669214,How to apply Leibniz rule for this integral?,"I am struck with the problem of how to evaluate the following integration: $$\frac{d}{dt}\int_0^{a(t)}{(a (t)-s)^{\alpha-1}f (s) ds}$$ where $f(s)$ is differentiable and $\alpha\in (0,1)$ . The problem is the integrand might not converge when substituting the upper limit","['integration', 'calculus', 'derivatives']"
3669227,Potentially new approach to factoring big numbers,"Update on 5/27/2020: I summarized all discussions related to this post, added a bit more about computational complexity, and published it on my blog, here . I've been working on this problem for a long time, read great books on the topic, and came up with the following. I am wondering if my approach could result in a very fast algorithm for factoring big numbers. 1. Algorithm As an illustration of how it works, let's apply it to factoring a very modest number, $z=x\cdot y = 1223 \times 2731$ . It involves the following steps. Step 1 . Compute $z_p = z \mbox{ Mod } p$ , for $p=2, 3, 5, 7, 9, 11, 13,\cdots, p_z$ . In this case, the upper bound can be as low as $p_z = 127$ (see section 2 about the choice of $p_z$ ). Check values of $p$ generating many identical $z_p$ values. Here, $z_p = 5$ or $z_p = 23$ for instance. Step 2 . We have $z_{59} = z_{85} = z_{111} = 23$ . Thus if $b = 59 \times 85 \times 111$ , because of Theorem A listed below, we have $z_b=23$ . Not sure if this is of any help. Step 3 . Find the set of $(x, y)$ with $x<y$ , with $x, y$ odd, and $x\cdot y \leq z$ satisfying all of the following: $x\cdot y = 23 \mbox{ Mod } 59$ $x\cdot y = 23 \mbox{ Mod } 85$ $x\cdot y = 23 \mbox{ Mod } 111$ You need to create 3 multiplication tables to identify the full list (intersection of 3 infinite lists) of candidates, and ignore those $(x, y)$ that result in $x\cdot y> z$ or $x$ even or $y$ even. Step 4 . The result is $(x, y) \in \{(61,36503),(173,12871),(211,10553),(829, 1327),(1223,2731) \}$ . Step 5 . Among all the 5 above candidates, check if one yields $x\cdot y = z$ . Here $(x=1223, y=2731)$ does and we've factored $z$ . The big question is: how difficult it is to perform step 3? The following elementary theorem could be useful. Could you find a reference for this theorem, or at least prove it? I discovered it myself, but I am sure it must be at least 300 years old. Theorem A Let $p_1, \cdots, p_k$ be $k$ pairwise co-prime positive integers, and $a>0$ an integer. If $z= a \mbox{ Mod } p_i$ for $i=1,\cdots,k$ , then $z= a \mbox{ Mod } (p_1\cdots p_k)$ . Also, let $$q = \arg \max_{p<z} \{z= a \mbox{ Mod } p\}.$$ Then $q+a = z$ . 2. Choice of $p_z$ In practice, in step 1, you can choose the smallest $p_z$ such that $2\cdot 3 \cdot 5\cdot 7 \cdots \cdot p_z > M z$ where $M$ is an absolute constant, maybe as low as $M=30$ . Then you have more than enough choices for step 3. In our example in section 1, we have $z= 3,340,013$ while $59\times 85 \times 111 = 556,665$ . It results in only 5 candidates in step 4. If instead, we consider $x\cdot y = 5 \mbox{ Mod } 21$ $x\cdot y = 5 \mbox{ Mod } 47$ $x\cdot y = 23 \mbox{ Mod } 59$ $x\cdot y = 23 \mbox{ Mod } 85$ $x\cdot y = 23 \mbox{ Mod } 111$ then there would be only 1 candidate in step 4, resulting in factoring $z$ . Note that the product $21 \times 47 \times 59\times 85 \times 111 =549,428,355$ is big enough (much bigger than $z$ itself) and this is what causes the candidate in step 4 to be unique, thus removing the need for step 5. Another example also producing a single candidate (the correct one) is $x\cdot y = 2 \mbox{ Mod } 3$ $x\cdot y = 3 \mbox{ Mod } 5$ $x\cdot y = 5 \mbox{ Mod } 7$ $x\cdot y = 6 \mbox{ Mod } 11$ $x\cdot y = 1 \mbox{ Mod } 13$ $x\cdot y = 6 \mbox{ Mod } 17$ $x\cdot y = 3 \mbox{ Mod } 19$ Again only one candidate in step 4 (thus no step 5) because $3\times 5 \times 7 \cdots \times 19 =  4,849,845$ is big enough, bigger than $z$ . 3. Working with non-primes and conjecture Weirdly enough, this choice works too, resulting in 4 candidates in step 4, including the correct one: $x\cdot y = 1242861 \mbox{ Mod } 2^{21}$ The result is $(x, y) \in \{(3,414287),(97,12813),(291,4271),(1223,2731) \}$ . Remember, $z = 1223 \times 2731$ . This leads to the following conjecture. Conjecture If $z$ is not a prime number, then the following system, with $x \cdot y \leq z$ , uniquely determines two non-trivial numbers $x, y$ such that $x\cdot y = z$ . The system is as follows: $$x\cdot y = m_i \mbox{ Mod } p_i, \mbox{ with } i=1,\cdots, k$$ where $p_1,p_2$ and so on are the prime numbers, $m_i = z \mbox{ Mod } p_i$ , and $k$ is the smallest integer such that $p_1\times \cdots\times p_k > C z$ where $C$ is an absolute constant. I don't know what would be the lower bound for $C$ , maybe $C=10$ works. The congruence system is linked to the Chinese Remainder Theorem. See page 88 in the book Prime Numbers - A Computational Perspective (2nd Edition), by R Grandall and C Pomerance (Springer, 2010). A careful choice of the moduli (rather than $p_1, \cdots, p_k$ ) could lead to a faster algorithm.","['number-theory', 'factoring', 'modular-arithmetic', 'prime-numbers']"
3669281,Deeper meaning and intuition behind $\frac{x}{1+x^2}$ having the same values for $x$ and for $\frac{1}{x}$,I was playing around with the function $f(x)=\frac{x}{1+x^2}$ and I noticed that $f(x)$ has the same values for $x$ and for $\frac{1}{x}$ . Is there any intuition or deeper meaning behind this? Thanks in advance!,"['algebra-precalculus', 'abstract-algebra', 'intuition']"
3669368,How do we prove this continued fraction for the quotient of gamma functions,"Given complex numbers $a=x+iy$ , $b=m+in$ and a gamma function $\Gamma(z)$ with $x\gt0$ and $m\gt0$ , it is conjectured that the following continued fraction holds $$\frac{\displaystyle4\Gamma\left(\frac{2a+3}{4}\right)\Gamma\left(\frac{2b+3}{4}\right)}{\displaystyle\Gamma\left(\frac{2a+1}{4}\right)\Gamma\left(\frac{2b+1}{4}\right)}=\cfrac{(2a+1)(2b+1)}{a+b+2+\cfrac{(a-b+1)(b-a+1)} {a+b+4+\cfrac{(2a+3)(2b+3)}{a+b+6+\cfrac{(a-b+3)(b-a+3)}{a+b+8+\ddots}}}}\tag{1a}$$ Corollary $$\frac{4}{\pi}=\cfrac{(2)^2}{3+\cfrac{(1)^2}{5+\cfrac{(4)^2}{7+\cfrac{(3)^2}{9+\ddots}}}}\tag{1b}$$ Q : How do we prove the continued fraction $(1a)$ rigorously?","['gamma-function', 'number-theory', 'conjectures', 'continued-fractions']"
3669390,Writing an expectation in terms of Fourier Coefficients,"I'm stuck on what should by all intents be a simple enough question. Suppose $n$ is an integer not divisible by 2 or 3 and let $f : \mathbb{Z}_n \to \mathbb{C}$ be a function and let $\hat{f}$ be it's discrete fourier transform, defined on $\mathbb{Z}_n$ as $\hat{f}(r) = \mathbb{E}_x(f(x)\omega^{-rx})$ where $\omega = e^{2\pi i/n}$ . For background info we can furthermore define the inner products $\left<f,g\right> = (\mathbb{E}_x f(x)\overline{g(x)})$ for functions and $\left<\hat{f},\hat{g}\right> = (\sum_r \hat{f}(x)\overline{\hat{g}(x)})$ for Fourier transforms (we do it in this way to avoid having to deal with normalising factors in Fourier Inversion etc). Then it is easy to show that Fourier inversion holds in the form $f(x) = \sum\limits_r \hat{f}(r) \omega^{rx}$ and also that Parseval holds in the form $\left<f,g\right> = \left< \hat{f},\hat{g}\right>$ . Furthermore convolutions behave as expected, i.e. $\widehat{f * g} = \hat{f}\hat{g}$ , where the convolution $f*g(x) = \mathbb{E}_y (f(y)g(x-y))$ . This should be all the background info that is necessary. Using this it should be possible to work out an expression in terms of $\hat{f}$ for the quantity $\mathbb{E}_{x,d} (f(x)f(x+d)f(x+2d)f(x+3d))$ , however I am not able to get very far as despite whatever I do I am not able to get to a position where it is possible to apply Parseval. Any help is much appreciated!","['expected-value', 'fourier-analysis', 'discrete-mathematics']"
3669449,"Given the equality $F_{X\cdot Y} = F_X \cdot F_Y$ of distribution functions, are $X,Y$ independent?","There is the well-known characterization that random variables $X,Y$ are independent if and only if $F_{X,Y}(x,y) = F_X (x) \cdot F_Y (y)$ . Due to a typo in a draft for an exam that I recently checked, this question was mis-stated as follows: If $X,Y$ are real-valued random variables such that $F_{X \cdot Y} = F_X \cdot F_Y$ , does it follow that $X,Y$ are stochastically independent? Here, $F_{X \cdot Y}$ is the distribution function of the product $X \cdot Y$ , i.e., $F_{X\cdot Y}(t) = \Bbb{P}(X\cdot Y \leq t)$ . The assumption means more explicitly that $F_{X \cdot Y}(t) = F_X(t) \cdot F_Y (t)$ for all $t \in \Bbb{R}$ . I would guess that the answer to the question is ""no"". The trouble I have with proving this is that it is difficult for me to construct at all random variables $X,Y$ (independent or not) which satisfy $F_{X \cdot Y} = F_X \cdot F_Y$ , except when $X$ or $Y$ are (almost surely) constant, in which case the claimed independence trivially holds. One further observation: If $X,Y$ are indeed independent, then $$
F_X (t) \cdot F_Y(t)
= \Bbb{P}(X \leq t) \cdot \Bbb{P}(Y \leq t)
= \Bbb{P}(X \leq t \text{ and } Y \leq t)
= \Bbb{P}(\max\{X,Y\} \leq t)
= F_{\max \{X,Y\}}(t).
$$ Thus, if the claim was true, we would have $F_{X \cdot Y} = F_{\max \{X,Y\}}$ , meaning that $X \cdot Y \sim \max \{X,Y\}$ . But even using this, I am unable to derive a contradiction.","['independence', 'probability-distributions', 'probability-theory']"
3669461,How should I restrict the points considered in each hexagonal lattice to correctly count all unique near-coincident lattices?,"Background: If a hexagonal lattice is defined by integers $i, j$ where $x = a_1 \left(i + \frac{1}{2} j\right)$ and $y = a_1 \frac{\sqrt{3}}{2} j$ , the distance to the origin for each point $r(a_1, i, j)$ will be $a_1 \sqrt{i^2 + j^2 + ij}$ . See this answer to my earlier question. If I have a second hexagonal lattice with constant $a_2$ it will form a coincident if there's some supercell of one that matches a supercell of the other, and since both are periodic it's sufficient to show that these lengths are equal: $$a_1^2 (i^2 + j^2 + ij) = a_2^2(k^2 + l^2 + kl)$$ The example in the plot below is for $(i, j), (k, l) = (5, 4), (2, 3)$ and $a_1=1$ , which makes $a_2 = \sqrt{\frac{61}{19}}$ To visualize the coincidence it's necessary to rotate the second lattice by $$\theta = \text{arctan2} \left(\frac{\sqrt{3}}{2}j, \ \ i+\frac{1}{2}j \right) - \text{arctan2} \left(\frac{\sqrt{3}}{2}l, \ \ k+\frac{1}{2}l \right)$$ or about -10.26°. We can know by symmetry that the negative of this angle or +10.26° will generate a second coincident lattice, and in fact every $\theta$ such that $\mod(\theta, \ 30°) \ne 0$ will have a complementary lattice at $-\theta$ . At integer multiples of 30 degrees the pair will be degenerate and we'll count it as only a single coincident lattice. Question: I am writing an algorithm to find near-coincident lattices, where the lengths differ by some small fraction $\delta$ , perhaps 1 percent: $$\left|\frac{a_1^2 (i^2 + j^2 + ij) }{ a_2^2(k^2 + l^2 + kl)} - 1\right| <= \delta$$ I want to count the number of unique near-coincident configurations. The algorithm will be used in a python script. My problem is that I don't want to miss any near-coincidences and at the same time don't want to double-count. Question: How should I restrict the points considered in each hexagonal lattice to correctly count all unique near-coincident lattices? I know I should restrict my search to a pie-shaped segment of all points in each of the two lattices, perhaps a 30° slice of one against a 60° slice of the other, but I haven't been able to convince myself that this guess is mathematically sound. Example of a proper coincident lattice: $(i, j), (k, l) = (5, 4), (2, 3)$ with $\frac{a_2}{a_1} = \sqrt{\frac{61}{19}}$","['linear-algebra', 'geometry']"
3669462,Dimension of linear system $|C|$ is the genus of $C$?,"Let $C \subset S$ be a smooth curve in a K3 surface $S$ . Why is the dimension of the linear system $|C|$ the genus of $C$ ? Here is what I tried: $\dim |C| = \dim H^0(\mathcal{O}(C)) - 1$ , and this appears in the Euler characteristic $\chi(\mathcal{O}(C))$ . Riemann-Roch on K3 surfaces is $$\chi(\mathcal{O}(C)) = \frac{1}{2} C^2 + 2,$$ and we can connect $C^2$ to the genus $g = g(C)$ using the adjunction formula, which on a K3 surface is $$2g - 2 = C^2.$$ Combining Riemann-Roch and the adjunction formula then leads to $$\chi(\mathcal{O}(C)) = g + 1,$$ so it remains to show $H^0(\mathcal{O}(C)) = \chi(\mathcal{O}(C))$ , i.e. $H^1(\mathcal{O}(C)) = 0 = H^2(\mathcal{O}(C))$ . By Serre duality $H^2(\mathcal{O}(C) = H^0(\mathcal{O}(-C))^*$ , and $\mathcal{O}(-C)$ is the ideal sheaf of $C$ , which does not have any global sections. Hence $H^2(\mathcal{O}(C)) = 0$ . But why does the superabundance $\dim H^1(\mathcal{O}(C))$ vanish? Or is that not true in general? In the application I'm interested in, $C$ also generates the Picard groups of $S$ .","['algebraic-curves', 'surfaces', 'curves', 'k3-surfaces', 'algebraic-geometry']"
3669467,"Intuitive reason for why $\int_1^{ab} \frac{1}{x} \, dx = \int_1^a \frac{1}{x} \, dx + \int_1^{b} \frac{1}{x} \, dx$?","The natural logarithm is sometimes defined as a definite integral: $\displaystyle \ln a = \int_1^a \frac{1}{t} \, dt$ . Since $\ln(ab) = \ln(a) + \ln(b)$ , we have $\displaystyle \int_1^{ab} \frac{1}{t} \, dt = \displaystyle \int_1^{a} \frac{1}{t} \, dt + \displaystyle \int_1^{b} \frac{1}{t} \, dt$ . Is there an intuitive/geometric reason for this?","['integration', 'calculus', 'intuition']"
3669492,The discard limit in fish containing mercury is too high. How should it be chosen such that average levels are as small as possible?,"This is a question I'm trying to answer for my probability homework. I've been looking at it for the last 2 days and I'm not getting anywhere so I ask for help. Below is the question. After are my thoughts which i have moved from a comment into the main body. The mercury content in swordfish sold in some parts of the US is known
  to be normally distributed with mean 1.1 ppm and variance 0.25 pp $m^2$ (see e.g. Lee and Krutchkoff and/or exercises 5.2 and 5.3 in Larsen),
  but according to the health authorities the average level of mercury
  in fish for consumption should not exceed 1 ppm. Fish sold through
  authorised retailers are always controlled by the FDA, and if the
  mercury content is too high, the lot is discarded. However, about $25\%$ of the fish caught is sold on the black market, that is, $25\%$ of the fish does not go through the control. Therefore the rule
  ""discard if the mercury content exceeds $1 ppm$ "" is not sufficient.
  How should the ""discard limit"" be chosen to ensure that the average
  level of mercury in the fish actually bought by the consumers is as
  small as possible? Basically, I'm not sure about what is expected from me here. The 75% of fish tested have a mean mercury content above the allowed limit. So is it possible to somehow make the mean lower by by having a cutoff at a high point to lower the average? Is that even what they mean by 'choosing the discard limit'? If we discard the top end and somehow truncate the normal distribution will we then have a lower mean? Is that even a legal move? Furthermore I don't like the sentence 'How should the discard limit be chosen'. Surely its chosen by the medically qualified and isn't something you can just change? I feel like the wording is also causing some miscommunication.","['statistics', 'probability']"
3669520,Unbiased estimator of variance,My question is why is the best and most commonly used estimator for the variance (in a Gaussian distribution) the sample variance with constant 1/n-1 when the sample variance with constant 1/n+1 instead has a lower mean squared error?,"['statistical-inference', 'statistics', 'parameter-estimation', 'normal-distribution']"
3669561,Does $B^{-1}-A^{-1}$ has r positive eigenvalues when A-B has r positive eigenvalues?,"Assume that A and B are 2 positive definite matrices of $n\times n$ . As is known, $A-B>0$ implies $B^{-1}-A^{-1} >0$ . That is to say, $B^{-1}-A^{-1}$ has n positive eigenvalues  when A-B has n positive eigenvalues. My question is :Assume that A and B are 2 symmetric matrices of $n\times n$ and B is positive definite and A is invertible.  Does $B^{-1}-A^{-1}$ has r positive eigenvalues  when A-B has r positive eigenvalues ?( $r\in \{1,2,\ldots,n\}$ )","['matrices', 'linear-algebra']"
3669590,Wrong notation/domain for the functions in this system of ODEs?,"For $x: \mathbb R\rightarrow \mathbb R^n$ and $u:\mathbb R \rightarrow \mathbb R^m$ we have the constrained ordinary differential equation (ODE) \begin{align}
\dot x(t) &= f(x(t),u(t)) \tag 1\\
0&\geq h(x(t),u(t)) \tag 2
\end{align} where $f:\mathbb R^{n\times m} \rightarrow\mathbb R^n$ and $h: \mathbb R^{n\times m}\rightarrow \mathbb R^n$ . From the notation I guess the domain of $f$ and $h$ are matrices, i.e. $\mathbb R^{n\times m}$ . 
But is that not a typo? Should it not be $+$ instead of $\times$ ? I mean the following: $f$ and $h$ are a compositions of $x$ with the range $\mathbb R^n$ and $u$ with the range $\mathbb R^m$ . Therefore \begin{align}
f&:\mathbb R^n \times \mathbb R^m = \mathbb R^{n+m} \rightarrow \mathbb R^n \tag 3
\\
g&:\mathbb R^n \times \mathbb R^m = \mathbb R^{n+m} \rightarrow \mathbb R^n \tag 4
\end{align} I.e. the cartesian product of $\mathbb R^n$ and $\mathbb R^m$ . Is this correct or am I wrong?","['ordinary-differential-equations', 'multivariable-calculus', 'calculus', 'linear-algebra', 'dynamical-systems']"
3669597,"How can we prove that $\gcd((n^4) + (n+1)^4 , (n+1)^4 + (n+2)^4) = 1$?","I have found through experimentation that the consecutive sums of consecutive natural numbers raised to certain powers $(1,2,4)$ are always coprime. I was looking for modular multiplicative inverses and came across this facet. 
If you define a sequence $a(n): n^k + (n+1)^k$ , then $a(n)$ and $a(n+1)$ are coprime when $k=1,2$ or $4$ but no others. How can we prove this? Since $a(n)$ and $a(n+1)$ are coprime when $k=1,2$ or $4$ , their modular multiplicative inverse exists, and are sequences in the OEIS already. I sincerely hope that this is moderately worthy and not cringe.","['gcd-and-lcm', 'modular-arithmetic', 'sequences-and-series']"
3669617,Existence of a measurable function such that the pushforward of a measure is equal to another measure,"Suppose we have two probability spaces $(\mathcal{X},\Sigma_\mathcal{X},\mathbb{P}_\mathcal{X})$ and $(\mathcal{Y},\Sigma_\mathcal{Y},\mathbb{P}_\mathcal{Y})$ . What are the conditions on the probability spaces such that there exists a measurable function $f:\mathcal{X}\rightarrow\mathcal{Y}$ such that $f_\#\mathbb{P}_\mathcal{X} = \mathbb{P}_\mathcal{Y}$ ? For instance if we had $\mathbb{P}_\mathcal{X} = \delta_x$ for some $x\in\mathcal{X}$ and if we had $\mathbb{P}_\mathcal{Y} = \frac{1}{2}(\delta_y + \delta_z)$ for some $y,z\in\mathcal{Y}$ , there exists no measurable function $f:\mathcal{X}\rightarrow\mathcal{Y}$ such that $f_\#\mathbb{P}_\mathcal{X} = \mathbb{P}_\mathcal{Y}$ . This is because we can't split the atom $\{x\}$ . My intuition says that if $\mathcal{X}$ and $\mathcal{Y}$ have no atoms then we can guarantee the existence of such an $f$ . However it may be more complicated than this and rely on more regularity in the structure of $\mathcal{X}$ and $\mathcal{Y}$ (e.g. they may have to be Borel spaces generated by diffeomorphic topological spaces say).","['measure-theory', 'probability-theory']"
3669693,How to solve the special ode with general solution,"The ode equation is $y'^2+2xy'+2y=0$ without initial value. Is there a general solution？ If $y(0)=0$ , what about the solution?","['ordinary-differential-equations', 'partial-differential-equations']"
3669700,Polynomial transformations and Vieta's formulas,"Let $f(x)$ be a monic, cubic polynomial with $f(0)=-2$ and $f(1)=−5$ . If the sum of all solutions to $f(x+1)=0$ and to $f\big(\frac1x\big)=0$ are the same, what is $f(2)$ ? From $f(0)$ I got that $f(x)=x^3+ax^2+bx-2$ and from $f(1)=-5$ that $a+b = -4$ however I'm not sure how to use the info about the transformations to find $f(2).$ It seems that $(x+1)$ is a root for $f(x+1)$ and the same logic applies for $f\big(\frac1x\big)$ ? Should I use Vieta's here or what's the appropriate way to go?","['contest-math', 'algebra-precalculus', 'polynomials']"
3669864,What are sufficient conditions such that consistency of ML estimate implies consistency of MAP estimate?,"I am interested in under what conditions the frequentist consistency of a Maximum-Likelihood estimator is enough to give the consistency of a maximum-a-posteriori point estimate, with the further restriction of i.i.d. models. That is, consider $y_1,\ldots,y_n$ $ \overset{\text{i.i.d.}}{\sim}$ $p(y\mid \theta_0)$ , and suppose that a sequence of maximum likelihood estimators $\hat{\theta}_n : = \underset{\theta}{\operatorname{argmax}} M_n(\theta),$ where $M_n(\theta):=\  \frac{1}{n} \sum_i\ln p(y_i\mid\theta)$ , exists and is consistent, that means $\hat{\theta}_n \overset {\mathbb{P}_{\theta_0}}{\rightarrow} \theta_0$ . Now consider some prior $p(\theta)$ and define the posterior mode estimate as $\hat{\theta}^\text{MAP}_n :=\underset{\theta}{\arg \max} \ M_n(\theta) + \frac{1}{n} \ln p(\theta))$ .  The question would be now, which conditions are sufficient such that, together with the consistency of $\hat{\theta}_n$ , they imply the consistency of the MAP estimate: $\hat{\theta}^\text{MAP}_n \overset {\mathbb{P}_{\theta_0}}{\rightarrow} \theta_0$ . Naturally, one should assume that the prior puts positive mass on $\theta_0$ , i.e. $p(\theta) >0$ in some neighborhood of $\theta_0$ . Besides of that , I could find that the following conditions from [1] are sufficient: Define $M(\theta) = \mathbb{E}_{\theta_0}[\ln p(y\mid \theta)]$ . If we have that $$ \sup_\theta \left| M_n(\theta) - M(\theta)\right| \overset{\mathbb{P_{\theta_0}}}{\rightarrow} 0 $$ $$  \sup_{\theta \,:\, d(\theta,\theta_0) \,\geq\, \varepsilon} M(\theta) < M(\theta_0) , \ \forall \varepsilon,$$ then $\hat{\theta}^\text{MAP}_n \overset {\mathbb{P}_{\theta_0}} {\rightarrow} \theta_0$ . The proof is basically the same as in [1]. This, however is unsatisfactory for at least 2 reasons: First, one has to make strong assumptions about the likelihood function, that may be too restrictive. Second, by imposing these restrictions, we are also implicitly proving the consistency of the $ML$ estimator again.  It would be nicer to have less assumptions on the likelihood or even have conditions that directly work with the fact that $\theta_n$ is consistent. Regarding the former, I tried to modify other proofs given in [1] regarding consistency of ML-estimates, but with these it seems to me that additional assumptions are needed. So my question would be:
- What are sufficient conditions for consistency of MAP estimates, given consistency of the ML? Edit: I will add some thoughts so that one can see the place where I am stuck and maybe someone else knows some solution. Assume we have that the prior is as above and we can bound it from above. Consider some small $\varepsilon$ . Then we have $$ (\hat{\theta}_n^{MAP} \notin B_{\varepsilon}(\theta_0))  \implies M_n(\hat{\theta}_n^{MAP}) + \frac{\ln p(\hat{\theta}_n^{MAP})}{n} \geq M_n(\hat{\theta}_n)  + \frac{\ln p(\hat{\theta}_n)}{n} \\ $$ By the consistency of $\hat{\theta}_n$ and the continuity and positivity of the prior, we can replace the last term on the right by $\frac{\ln p(\theta_0)}{n} - \delta$ for some arbitrarily small $\delta$ for large enough $n$ , and we can definitely replace the term involving the prior on the left by it's supremum. We then have $$M_n(\hat{\theta}_n^{MAP}) + \frac{\underset{\theta}{\sup} \ln p(\theta) - \ln p(\theta_0)}{n}   + \delta  \geq M_n(\hat{\theta}_n)$$ At this point then it seems to me that one needs some additional assumptions. If the convergence to the limit function $M(\theta)$ is uniform, and the limit function is well-separated, then of course the above inequality will be fulfilled with arbitrarily small probability. This is why the conditions given above work. [1] van der Vaart, A. W. , Asymptotic statistics , Cambridge Series in Statistical and Probabilistic Mathematics, 3. Cambridge: Cambridge Univ. Press. xv, 443 p. (1998). ZBL0910.62001 .","['statistics', 'probability-limit-theorems', 'bayesian', 'asymptotics', 'maximum-likelihood']"
3669889,"Find the all positive integer solutions $(a,b)$ to $\frac{a^3+b^3}{ab+4}=2020$.","Find the all positive integer solutions of given equation $$\frac{a^3+b^3}{ab+4}=2020.$$ I find two possible solutions, namely $(1011,1009)$ and $(1009,1011)$ , but the way I solve  the equation was messy and I don't know if there are any other solutions. Source: Turkey $1.$ TST for IMO $2020$","['contest-math', 'divisibility', 'number-theory', 'elementary-number-theory', 'diophantine-equations']"
3669932,Why isn't every metric space a manifold?,"What I mean with ""intuitive"": I can handle some formulas, but since I am not a professional mathematician I am not fluent in all the lingo, so I do not know by heart what ""second countable"" means. If I have to look up all these terms and try to understand them, it takes so much time, that I forget what I was researching in the first place... so basic terminology is appreciated. It was previously asked whether every manifold is a metric space , but I have to admit, I did not completely understand the answers. Assuming that a manifold is second-countable, the answer is ""yes"" (I cannot claim I full understood the property ""second countable""). My (non-completely) translation of the answer https://math.stackexchange.com/a/1530066/340174 into an intuitive explanation is I want to find the distance from $x_0$ to y, both of which are elements of the manifold. Since a manifold is locally Euclidean, I can walk a infinitely small way in an ""Euclidean"" manner. So, I go a small step from $x_0$ to $x_1$ and I calculate the distance I walked, which is possible, because I can just use the Euclidean distance. I walk from $x_1$ to $x_2$ until I reach y and add up all the distances to the total distance. From all the possible paths I take the one that is the shortest and that is my distance. First question: It seems intuitively obvious to me that the first three conditions of a metric apply to manifold distances, as I described it above. But how do I know that the triangular condition applies as well to the distance over a manifold? Is there an intuitive explanation in the style I tried above? Originally I would have guessed (without too much thinking) that every metric space is a manifold, but not the other way around. Since the second part is wrong, I would guess that now, that the first part is also wrong. (Otherwise there would be no need to differentiate the two, right?) But what is that so? I can come of with a metric space, like one based on the Levenshtein distance, which is not continuous and my usual impression of manifolds is that they are continuous (since they are supposed to be Euclidean locally). However it seem there are also discrete manifolds (which I do not understand either). Second question: What is an intuitive explanation, why metric spaces are not necessarily manifolds?","['manifolds', 'general-topology', 'metric-spaces']"
3670003,Translation invariance of Lebesgue integral,"I am looking at the following statement: Let $u:\mathbb{R^3} \rightarrow \mathbb{S}^1$ and $z\in \mathbb{R}^3$ and $h>0$ small. Then the integral $\int_{\mathbb{T}^3} dx$ is translation invariant and therefore $\int_{\mathbb{T}^3} u(x)-u(x-\sqrt{h}z) dx = \int_{\mathbb{T}^3} u(x-\sqrt{h}z)-u(x-2\sqrt{h}z) dx$ . I understand that the Lebesgue-measure is invariant under translation and this implies that the Lebesgue Integral is translation invariant as well, in the sense that for a measurable set $D \subset \mathbb{R}^3$ we have $\int_D u(x) dx = \int_{D-z} u(x+z) dx$ . The torus is defined as the quotient of the cartesian plane with the identifications $(x,y,z)\text{~}(x+1,y,z)\text{~}(x,y+1,z)\text{~}(x,y,z+1)$ . The thing I don't understand in the first statement is that we have both times the integral over $\mathbb{T}^3$ . I thought that on the righthand side it should be $\mathbb{T}^3+\sqrt{h}z$ for $\sqrt{h}z \notin \mathbb{Z}^3$ after our definition of $\mathbb{T}^3$ . Am I not understanding the notion of the three-torus correctly or where is my mistake?","['general-topology', 'lebesgue-integral', 'measure-theory', 'real-analysis']"
