question_id,title,body,tags
4556637,Length of boundary of level set,"Say we have $\phi\in C^1(\overline{\Omega})$ of a bounded domain $\Omega$ in $\mathbb{R}^2$ and $D=\{x:\phi(x)>0\}$ and $\nabla \phi(x) \neq 0$ for $x$ on the curve satisfying $\phi(x)=0$ . Question: What can we say about an upper bound of $L(\partial D)$ ? Do we have: $$\|\phi\|_{C^1}\leq M_1 \quad \Rightarrow \quad L(\partial D) \leq M_2,$$ where $M_1$ is some constant and $M_2$ is only dependent on $M_1$ ? Progress: My intuition (so far) is that $L(\partial D)$ is finite and we need a lower bound $|\nabla \phi|>c$ on $\phi^{-1}(0)$ and then $M_2=M_2(c)$ . Indeed for each $x\in \phi^{-1}(0)$ we can find a neighborhood of $x$ and a local $C^1$ parametrization $\psi$ (inverse function theorem) of that local piece of the surface $\phi^{-1}(0)$ . The length of this piece is finite and relates to $|\psi'|$ which somehow relates to $(\nabla \phi)^{-1}$ . Then by compactness we add finitely many pieces to get the total surface area. How to more precisely relate $|\psi'|$ to $|\nabla\phi|$ ?","['curves', 'multivariable-calculus', 'surfaces', 'differential-geometry']"
4556687,Why is there only one differentiation but several integration?,"Differentiation and integration are inverse operations of each other. However, there are Riemann, Lebesgue, Henstock–Kurzweil, etc… integrations, while there is only one differentiation $\lim\limits_{h\rightarrow 0}\frac{f(x+h)-f(x)}{h}$ . Quote from a book A Garden of Integrals : The derivative and the integral are the fundamental notions of calculus. Though there is essentially only one derivative, there is a variety of integrals, developed over the years for a variety of purposes, and this book describes them.","['integration', 'analysis', 'calculus', 'derivatives', 'soft-question']"
4556694,How can I prove this limit result associating with an infinite nested radical,"Let $a_n=\sqrt{1+\sqrt{2+\sqrt{3+...+\sqrt{n}}}}$ I can show that $\lim\limits_{n\to∞}a_n$ converges,let $l=\lim\limits_{n\to∞}a_n$ Now what puzzles me is that how to prove $\lim\limits_{n\to∞}\sqrt{n}\sqrt[n]{l-a_n}=\frac{\sqrt{e}}{2}$ I have already figured out that $\lim\limits_{n\to∞}\sqrt{n}\sqrt[n]{l-a_n}\le\frac{\sqrt{e}}{2}$ How about the other half? P.S. Here's how I work the upper bound out: Since $a_n$ converges, we have $\begin{aligned}
l-a_n=& \sum\limits_{i=n}^∞(a_{i+1}-a_i)\\
=& \sum\limits_{i=n}^∞(\sqrt{1+\sqrt{2+\sqrt{3+...+\sqrt{i+1}}}}-\sqrt{1+\sqrt{2+\sqrt{3+...+\sqrt{i}}}})\\
=&\sum\limits_{i=n}^∞\frac{\sqrt{2+\sqrt{3+...+\sqrt{i+1}}}-\sqrt{2+\sqrt{3+...+\sqrt{i}}}}{\sqrt{1+\sqrt{2+\sqrt{3+...+\sqrt{i+1}}}}+\sqrt{1+\sqrt{2+\sqrt{3+...+\sqrt{i}}}}}\\
\le&\sum\limits_{i=n}^∞\frac{\sqrt{2+\sqrt{3+...+\sqrt{i+1}}}-\sqrt{2+\sqrt{3+...+\sqrt{i}}}}{2\sqrt{1}}\\
\le&...(\text{repeat the process n times})\\
\le&\sum\limits_{i=n}^∞\frac{\sqrt{i+1}}{2^i\sqrt{i!}}\\
<&\sum_{i=n}^\infty \frac{\sqrt{i+1}}{2^i\sqrt{i!}}\\
\le&\frac{1}{2^n\sqrt{n!}}\sum_{i=n}^\infty\frac{\sqrt{i+1}}{2^{i-n}}\\
=&\frac{1}{2^n\sqrt{n!}}\sum_{i=0}^\infty\frac{\sqrt{n+i+1}}{2^i}
=\frac{\sqrt{n}}{2^n\sqrt{n!}}\sum_{i=0}^\infty\frac{1}{2^i}+\frac{1}{2^n\sqrt{n!}}\sum_{i=0}^\infty\frac{\sqrt{n+i+1}-\sqrt{n}}{2^i}\\
=&\frac{2\sqrt{n}}{2^n\sqrt{n!}}+\frac{1}{2^n\sqrt{n!}}\sum_{i=0}^\infty\frac{1}{2^i}\cdot\frac{i+1}{\sqrt{n+i+1}+\sqrt{n}}<\frac{2\sqrt{n}+C}{2^n\sqrt{n!}}<\frac{2\sqrt{n}+n}{2^n\sqrt{n!}}
\end{aligned}
$ Now by this estimation of the upper bound, we can show $\lim\limits_{n\to∞}\sqrt{n}\sqrt[n]{l-a_n}\le\frac{\sqrt{e}}{2}$ by calculation(with Stirling's approximation)","['limits', 'radicals', 'analysis']"
4556720,"Is this ""coincidence"" about representations of the Monster actually a coincidence?","I know that the Monster simple group's lowest dimension faithful representation (which is in characteristic $2$ ) has dimension $196882$ and that its lowest dimension faithful representation in characteristic $0$ has dimension $196883$ . Is there any simple explanation for the fact the dimension of the lowest dimension faithful representation has dimension one less than lowest dimension faithful representation in characteristic $0$ ? Are these reasons also valid for other simple groups, like $A_5$ and the Baby Monster groups? Are there representations of dimension $196882$ in other characteristics?","['sporadic-groups', 'simple-groups', 'abstract-algebra', 'group-theory', 'soft-question']"
4556723,When does the squeeze theorem fail?,"In introduction real analysis course, we have squeeze theorem which is: let $f,g$ and $h$ are functions from $\mathbb R$ to $\mathbb R$ and $f(x)\leq g(x)\leq h(x)$ such that $\lim\limits_{x\to a} f(x)= \lim\limits_{x\to a} h(x)=L$ , $L\in\Bbb R$ , then $\lim\limits_{x\to a} g(x)=L.$ In this course, we consider $\Bbb R$ with usual metric, that is, $(\Bbb R, d(x,y)=|x-y|)$ . The question came to my mind is that Can we find a system such that  the squeeze theorem will not be correct that, means, $f,g$ and $h$ are functions from $\mathbb X$ to $\mathbb Y$ and $f(x)\leq g(x)\leq h(x)$ such that $\lim\limits_{x\to a} f(x)= \lim\limits_{x\to a} h(x)=L$ , $L\in\Bbb Y$ , but $\lim\limits_{x\to a} g(x)\neq L,$ $X$ and $Y$ can be any sets, that is, $X$ and $Y$ might not be subsets from $\Bbb R.$ Any idea","['limits', 'functional-analysis', 'analysis', 'real-analysis']"
4556761,Are finite almost simple groups 2-generated?,"This is inspired by https://mathoverflow.net/questions/59213/generating-finite-simple-groups-with-2-elements and https://mathoverflow.net/questions/254164/is-every-finite-quasi-simple-group-generated-by-2-elements Which show that every finite quasi-simple group is 2-generated (indeed even every finite perfect group which is 2-generated modulo its center is 2-generated) Is every finite almost simple group https://en.wikipedia.org/wiki/Almost_simple_group 2-generated? I think this should roughly reduce to whether the outer automorphism groups of finite simple groups are 2-generated. Outer automorphisms of sporadic groups are cyclic 2 or trivial. Outer automorphism groups of $ A_n $ are mostly cyclic 2, exception $ Aut(A_6)=C_2 \times C_2 $ is still 2-generated.  I think outer automorphisms of finite groups of Lie type are all 2-generated but I have to check. a lot of small example, for example all the groups here https://brauer.maths.qmul.ac.uk/Atlas/v3/lin/ have 2-generated Out(G)","['group-theory', 'finite-groups']"
4556847,Solving $\frac{dy}{dx} = \frac{xy+3x-2y+6}{xy-3x-2y+6}$,I'm stuck with this problem... $$\frac{\operatorname{d}y}{\operatorname{d}x} = \frac{xy+3x-2y+6}{xy-3x-2y+6}$$ I have tried separating variables in the following way: $$\frac{\operatorname{d}y}{\operatorname{d}x} = \frac{x(y+3)2(-y+3)}{y(x-2)3(-x+2)}$$ $$\left(\frac{y+3 \cdot 2(-y+3)}{y}\right)\operatorname{d}y = \left(\frac{x-2 \cdot 3(-x+2)}{x}\right)\operatorname{d}x$$ $$\left(\frac{-y+9}{y}\right) \operatorname{d}y = \left(\frac{-2x+4}{x}\right) \operatorname{d}x$$ Then integrating both sides I end up with $$y=2x+\ln\left(\frac{y^9}{x^4}\right)+C$$ I'd appreciate very much if someone give me the right answer because I don't know if my solution is correct or not. Thanks in advance,"['calculus', 'ordinary-differential-equations']"
4556892,Show that there exists a $v$ s.t. $A^TAv=\|A\|_2^2v$,"Given $A \in \mathbb{R}^{m \times n}$ , show that there exists a $v$ , s.t. $\|v\| = 1$ and $A^T A v = \|A\|_2^2 v$ , where $$\|A\|_2 :=\max_{\|v\|=1}\|Av\|$$ is the spectral norm. My attempt: By the spectral theorem there exists $O \in O(\mathbb{R}^m): A^TA = O^TDO$ , with $D$ diagonal. Now: $$||A^TA||_2= \max_{||v||=1}||A^TAv||= \max_{||v||=1}\sqrt{v^TO^TDOO^TDOv}= \max_{||v||=1}||DOv||= \max_{||v||=1}||Dv||=|\lambda_{\max}|$$ With $\lambda_{\max}$ the largest eigenvalue by absolute value. So if I new that $\lambda_{\max}\geq 0$ I would know $\exists v: A^TAv=||A^TA||_2v$ . Now I would only have to show that $||A||_2^2= ||A^TA||_2$ , but somehow I can’t find a way to show that. I‘d be really thankful for some help:)","['matrices', 'spectral-norm', 'linear-algebra', 'matrix-norms']"
4557006,Find the probability of the sum of two chips equal to $10$,"Ten chips numbered $1$ through $10$ are mixed in a bowl. Two chips numbered (X,Y) are drawn from the bowl, successively and without replacement. What is the probability that $X +Y = 10$ ? Answer: $\frac{4}{45}$ My attempt: The possible ways to satisfy the condition would be $(1, 9); (2, 8); (3, 7); (4, 6)$ and the same numbers with the other order. And all the possible ways to drawn two chips from the bowl would be $10\times9$ . So the asked probability is given by: $P=\frac{8}{90}=\frac{4}{45}$ I think that my attempt is reasonable, I just want to know if problems like this could be solve in a more general way, without actually having to know all the ways the condition is satisfied.","['statistics', 'probability']"
4557037,Is the trace preserved (up to scaling) by Lie algebra homomorphisms (between matrix Lie algebras)?,"Suppose $\phi:V\rightarrow W$ is a Lie algebra isomorphism between matrix Lie algebras $V$ and $W$ . Since $V$ and $W$ are real vector spaces of matrices, we can consider the traces of their elements. My question is, do we have $\operatorname{tr} \phi(X) = \lambda\cdot\operatorname{tr} X$ for some $\lambda\ne 0$ ? If not, is there a good counterexample? I am thinking we can choose a basis $\{E_{1}, \ldots, E_{n}\}$ for $V$ , take $F_{j} := \phi(E_{j})$ for all $j$ , and then consider structure constants $$ [E_{i}, E_{j}] = c_{ijk}E_{k} $$ where we sum over repeated indices (Einstein summation notation).
Since $\phi$ is a Lie algebra isomorphism, we have $$ [F_{i}, F_{j}] = c_{ijk}F_{k}. $$ By taking the traces, and noting that the trace of commutators is zero, we find $$ c_{ijk}e_{k} = 0 \qquad\text{ and }\qquad c_{ijk}f_{k} = 0 $$ where $e_{k} := \operatorname{tr} E_{k}$ and $f_{k} := \operatorname{tr} F_{k}$ . Now my idea is to note that the $c_{ijk}$ 's are determined, and our question is simply what is the null space / kernel of the $n^{2}\times n$ matrix $C = (c_{ij, k})$ ( $ij$ determine row; $k$ determines column), but it's not clear how to proceed from here, or if this approach is any good to begin with. Unfortunately, I don't know of many non-trivial matrix Lie algebra examples at the moment.","['matrices', 'trace', 'lie-algebras']"
4557062,Are Subgroups' Quotients also Quotients' Subgroups?,"Let $G$ be a group, $G'\le G$ a subgroup, and $\varphi:G'\to H$ a surjective group homomorphism. Must there exist a surjective group homomorphism $\psi:G\to H'$ such that $H'\ge H$ ? I know the converse is true: Take $G'=\psi^{-1}(H)$ and let $\varphi=\psi$ . I know if $G$ is abelian then the question is true: Take $H'=G/\ker(\varphi)$ . Whether the full direction asked above is true or false is unclear. I have asked some friends for their help and we couldn't reach a conclusion. If anyone can point to a reference with a full solution to the problem, that is also great. Thanks in advance!","['quotient-group', 'group-theory', 'abstract-algebra']"
4557063,Find the probability that at least one digit will occupy its proper place.,"Suppose that the three digits $1$ , $2$ and $3$ are written down in random order. What is the probability that at least one digit will occupy its proper place? Answer: $\frac{2}{3}$ My attempt: In my first take I used the definition of probability with finite sample space and equally likely outcomes, which achieve: $3\times 2 \times 1 = 6$ possibilities to arrange the three digits. And the set with all these arrangements would be: $S=\{(1,2,3);(1,3,2);(2,1,3);(2,3,1);(3,2,1);(3,1,2)\}$ And the asked probability is: $P=\frac{4}{6}=\frac{2}{3}$ Trying to solve in a more general way which would be more efficient if the number of digits were much larger, I got this: $P(\text{getting 1 digit at the right place})= \binom{3}{1}\times(\frac13)\times(\frac23)^2=\frac{4}{9}$ $P(\text{getting 2 digits at the right place})=\binom{3}{2}\times(\frac13)^2\times(\frac23)=\frac{2}{9}$ $P(\text{getting all digits at the right place})=\binom{3}{3}\times(\frac{1} {3})^3=\frac{1}{27}$ And the probability of getting at least one digit at the right place would be the sum of all three. $P=\frac{4}{9} + \frac{2}{9} +\frac{1}{27}=\frac{19}{27}$ I know this problem could be solved like this: https://math.stackexchange.com/q/2882673 . I just want to know why I didn't get the same result in the second attempt and if I could make some adjustment to achieve the wanted result.","['statistics', 'probability']"
4557123,I can't figure out whether my answer is correct or not.,Consider part c of the following question - I understand why $p \land (q \lor r)$ is correct. Am I correct in saying $(p \land q) \lor r$ is a correct answer as well?,"['propositional-calculus', 'logic', 'discrete-mathematics']"
4557167,Bracelet isomorphism algorithms,"I feel like the problem should have been studied, but I wasn't able to find anything precise. Given two bracelets with $n$ beads and $m$ colors, given that the multiplicity of each color is the same, and excluding the obvious rotation to $n$ positions plus a reflection (for a total of $2n$ trials with $n$ comparisons, so with a complexity of $\mathcal{O}(n^2)$ ), what are better known algorithms to decide whether the two bracelets are isomorphic? For now, the only alternative that came to mind was making a polar Discrete Fourier Transform and then computing the ratio of the two to get the rotation angle before comparing the two bracelets.","['graph-theory', 'graph-isomorphism', 'combinatorics', 'algorithms']"
4557179,why $q\left(T\left(x-x_j\right)\right) \rightarrow 0$ implies $T\left(x_j\right) \rightarrow T(x)$?,"Let $\mathscr{X}$ and $\mathscr{Y}$ be locally convex vector spaces, let $\mathscr{P}$ and $\mathscr{Q}$ be inducing collections of seminorms for $\mathscr{X}$ , respectively $\mathscr{Y}$ , and let $T: \mathscr{X} \rightarrow \mathscr{Y}$ be a linear map.
lways continuous). Now let $\left\{x_j\right\}_{j \in J}$ be a net in $\mathscr{X}$ and $x \in \mathscr{X}$ such that $x_j \rightarrow x$ in $\mathscr{X}$ in this thesis An Introduction to
FUNCTIONAL SPACES by Marcel de Reus at page 158 in  Lemma A.1.2 we have To prove that $T$ is continuous, we should prove that $T\left(x_j\right) \rightarrow T(x)$ in $\mathscr{Y}$ , which is equivalent to the statement that $q\left(T(x)-T\left(x_j\right)\right)=q\left(T\left(x-x_j\right)\right) \rightarrow 0$ in $\mathbb{R}$ for every $q \in \mathscr{Q}$ , which in Why $q\left(T\left(x-x_j\right)\right) \rightarrow 0$ implies $T\left(x_j\right) \rightarrow T(x)$ ? This is what I tried. $q\left(T(x)-T\left(x_j\right)\right)\rightarrow 0$ means that given $\epsilon >0$ there exist an $j_{\epsilon}$ such that $q\left(T(x)-T\left(x_j\right)\right)<\epsilon$ whenever $j>j_{\epsilon}$ . Now  a neighborhood of $U$ of $T(x)$ is of the form $$U=\{ y:q_1(y-T(x))<\epsilon \wedge... q_k(y-T(x))<\epsilon \}$$ From the expression above we have that $T\left(x_j\right) \in U$ for $j>j_\epsilon$ wich is the definition of convergence to $T(x)$ I am not sure of proof because I am not sure if all my definition are correct.","['general-topology', 'topological-vector-spaces', 'functional-analysis', 'locally-convex-spaces']"
4557195,"Both $f(x,\cdot)$ and $f(\cdot,y)$ $\mathcal{A}$ measurable,but $f(x,y)$ not $\sigma \left ( \mathcal{A}\times \mathcal{A}\right )$ measurable","From Richard Bass' Real Analysis for Graduate Students Version 3.1  p.94: $\textbf{Example 11.5}$ There exists a set $X$ together with a partial order $""\leq""$ such that $X$ is uncountable but for any $y \in X$ , the set $\{x\in X: x\leq y\}$ is countable.  The $\sigma$ -algebra is the collection of subsets $A$ of $X$ such that either $A$ or $A^c$ is countable.  Define $\mu$ on $X$ by $\mu(A) = 0$ if $A$ is countable and 1 if $A$ is uncountable.  Define $f$ on $X\times X$ by $f(x,y)=1$ if $x\leq y$ and zero otherwise.  Then $\int \int f(x,y)\, dy\, dx = 1$ but $\int \int f(x,y)\, dx \, dy = 0$ .The reason there is no contradiction is that f is not measurable with respect to the product $\sigma$ -algebra. I don't understand why $f$ is not measurable with respect to the product $\sigma$ -algebra.
Let $\mathcal{A}$ denote the $\sigma$ -algebra the collection of subsets $A$ of $X$ such that either $A$ or $A^c$ is countable.
Actually,How can I prove either $\left\{\left (x,y \right )\in X\times X\right | x\le y  \}\notin \sigma \left (  \mathcal{A}\times \mathcal{A}\right )$ or $\left\{\left (x,y \right )\in X\times X\right | x> y  \}\notin \sigma \left (  \mathcal{A}\times \mathcal{A}\right )?$","['measure-theory', 'real-analysis']"
4557224,Differential equation $y''+(y')^2+1=0$,"I’m trying to solve this equation but at the end I’m stuck and can’t reach the answer. I use the substitutions $u=y'$ and $y''=du/dx$ : $$du/dx+u^2+1=0, \\ -du/(u^2+1)=dx, \\ -\arctan(u)=x+c$$ Here I don’t know how to go on. The answer should be $$y=\ln|\cos(c_1-x)|+c_2$$",['ordinary-differential-equations']
4557241,Proving that the Lagrangian Grassmanian is compact,"I am trying to prove that the Lagrangian Grassmanian $\Lambda_n$ , that is, the set of all Lagrangian subspaces of $\mathbb R^{2n}$ equiped with the standard symplectic tensor $\omega$ , is a compact manifold. I have observed that since a subspace $S$ is Lagrangian if and only if $\omega|_S\equiv0$ and $\dim S=n$ , one can characterize $\Lambda_n$ as the following subset of the Grassmanian $G_n(\mathbb R^{2n})$ : $$\Lambda_n=\{S\in G_n(\mathbb R^{2n})\,|\,\omega|_S\equiv0\}\text{.}$$ Since the Grassmanians are compact manifolds, we only need to prove that $\Lambda_n$ is closed in $G_n(\mathbb R^{2n})$ ; but the above characterization suggests that we should be able to express such a spaces as the zero locus of some continuous function, hence guaranteeing that $\Lambda_n$ is indeed a closed subspace. However, I am struggling to find such a function, and I am worrying that this approach might not work. Thanks in advance for your answers.","['submanifold', 'manifolds', 'general-topology', 'lie-groups', 'differential-geometry']"
4557270,Convergence of an integral with Legendre polynomials,"Let's consider the following integral $$
I(¥ell) = ¥int_{-1}^1 dx P_¥ell(x) A(x)
$$ where $ P_¥ell(x) $ is the $¥ell$ -th Legendre polynomial and $A(x) = ¥frac{1}{1-¥lambda x}$ with $0¥leq ¥lambda<1$ . I am interested in estimating the large- $¥ell$ behavior of $I(¥ell)$ . For this purpose, I thought of using the asymptotic expression for the Legendre Polynomials $$
P_{¥ell¥gg 1}(x) ¥simeq  ¥Re¥left[¥sqrt{¥frac{2}{¥pi ¥ell}} ¥frac{¥left(x+¥sqrt{x^2-1}¥right)^{¥ell+1/2}}{(x^2-1)^{1/4}}¥right]
$$ to compute $$
¥tilde{I}(¥ell) = ¥sqrt{¥frac{2}{¥pi ¥ell}} ¥lim_{¥epsilon¥rightarrow 0}¥int_{-1+i ¥epsilon}^{1+i ¥epsilon} dx ¥frac{¥left(x+¥sqrt{x^2-1}¥right)^{¥ell+1/2}}{(x^2-1)^{1/4}} A(x)¥,.
$$ Then, I will have $I(¥ell ¥gg 1) ¥simeq ¥Re¥left[¥tilde{I}(¥ell)¥right]$ I can solve this integral numerically and see that $¥tilde{I}(¥ell)$ is convergent for some values of $¥lambda$ . However, I can't prove analytically that this integral is convergent since the integrand diverges as $(¥epsilon)^{-1/4}$ around $x¥sim ¥pm 1$ . How can I show that $¥tilde{I}(¥ell)$ is convergent and estimate it? EDIT : Convergence Actually, I can show the convergence of the integral by performing the following change of variables $$
x = ¥cos{¥phi}
$$ after which the integral becomes $$
I(¥ell ¥gg 1) ¥simeq ¥sqrt{¥frac{2}{¥pi ¥ell}} ¥int_{0}^{¥pi} d¥phi ¥sqrt{¥sin{¥phi}} ¥cos¥left[ ¥phi(¥ell+1/2)-¥pi/4¥right] A(¥cos{¥phi})¥,.
$$ that is clearly convergent for $0¥leq ¥lambda < 1$ .
I still don't know how to estimate the high- $¥ell$ behaviour","['integration', 'legendre-polynomials', 'definite-integrals', 'estimation']"
4557275,Showing that if $f$ vanishes locally almost everywhere then integral of $|f|$ is 0,"I am studying measure theory from Cohn's Measure theory textbook. If $(X, \scr A, \mu)$ is a measure space then a subset $N$ of $X$ is said to be locally null if for every $A \in \scr A $ with $\mu (A) < + \infty$ , we have that $A \cap N$ is null set. Also, subset $B$ of $X$ is said to be null set if there is a set $A \in \scr A$ such that $B \subset A$ and $\mu (A) = 0$ . Now, here's what I am trying to prove: if $f: X \to \mathbb C$ and $f=0$ locally almost everywhere, that is, $\{ x\in X : |f(x)| >0 \}$ is locally null then $\int |f| \,d\mu = 0$ . This claim would be true if $f=0$ almost everywhere, that is, the $\{ x\in X : |f(x)| >0 \}$ is null. This holds true if $X$ is $\sigma$ -finite. Because $\sigma$ -finiteness would imply that every locally null set is null and we would be done. The claim remains to be proved when $X$ is not $\sigma$ -finite. I tried my best to prove it but could not reach anywhere. Hints to prove or disprove it will be appreciated!","['measure-theory', 'real-analysis']"
4557291,"Intuition behind associated bundles seems natural but I can't see how it's working out ""intuitively""!","Suppose $L_1\rightarrow P \xrightarrow{\pi} M$ is a $G$ -principal bundle with fibers diffeomorphic to $L_1 = G$ , and that $\sigma$ is an effective action of $G$ on $L_2$ , i.e. if $g.x := \sigma_g(x) = x$ for all $x \in L_2$ , then $g = e$ (with $e$ being the identity element of $G$ ). I have the following intuition about the associated bundle $L_2 \rightarrow P\times_G L_2 \rightarrow M$ . Suppose in above we have a principal $G$ -bundle $P$ and for some reason we are interested to replace the fibers that are diffeomorphic to $L_1$ , with new fibers that are diffeomorphic to $L_2$ . How could we do this? I was intuitively thinking that if somehow $L_2$ could have been embedded inside $L_1$ , then as in the quotient manifold theorem, if $L_2$ represents the quotient space $L_1/G$ for some action $\sigma$ , then we might be able to somehow do this: we get rid of the redundant information in each fiber $L_1$ to reduce the already given fiber to something diffeomorphic to $L_2$ . But not always do we find ourselves in a situation where $L_2$ could sit inside $L_1$ via an embedding. So, what could we do in these cases? I think this is why we first consider the bigger fibers $P_x \times L_2$ at each $x \in M$ and build the fiber bundle $P\times L_2$ ; To somehow fit $L_2$ in a bigger space that is also related to $L_1$ . Then
by defining an equivalence relation on this product fibers, we should be able to kill the info of $L_1$ and thus successfully replace our fibers with things that are $L_2$ . We can do this by the trivial equivalence relation $(a_1, b) \sim (a_2, b)$ for any $a_1, a_2 \in P_x$ and $b \in L$ but this is very trivial and probably wouldn't give us something interesting. So we move on to something that really engages $L_1$ and $L_2$ together and twists and curves the fibers nontrivially so that we get something cool! We can define an equivalence relation on it by demanding $(a.g, b) \sim (a, g.b)$ for $a \in P, b \in L_2$ and $g \in G$ . Here $a.g$ is given by the right transitive action of $G$ on the leaves of the principal bundle. Also $g.b$ is nothing but $\sigma_g(b)$ from the left effective action of $G$ on $L_2$ . The theorem in the associated bundle tells us that after quotienting over this equivalence relation, we obtain the new $G$ -fiber bundle $P\times_GL_2$ which has now fibers diffeomorphic to $L_2$ . My question is, although the statement of the theorem is saying that the information of the leaves of $P$ that were diffeomorphic to $L_1$ are gone and it only leaves us with the info of $L_2$ , I can't see why is this happening intuitively! The equivalence relation $(a.g, b) \sim (a, g.b)$ seems to treat $L_1$ and $L_2$ very symmetrically. Why is this then that in the end of the day the info of $L_1$ are lost after quotienting but the info of $L_2$ remains? I figure it has something to do with the effectiveness of the action $\sigma$ but for the longest time I haven't figured it out how is this helping? I wanted to share my intuition about this whole concept of associated bundles. Hopefully it helps to build an insight. I will be very happy if you could help me to find the last piece of this puzzle of mine! Some more insight: We know that the principal bundle from the beginning is also now the induced bundle of the second and thus induced bundles are also another way of replacing the fibers as well as kind of a left-inverse operation to building associated bundles. In fact the induced principal bundle forgets a huge chunk of information whereas the associated bundle seemingly removes the info if $L_1 = G$ but doesn't actually since the data of $G$ is still stored in the structure group of the associated bundle although its trace us removed from the fibers. Update: I think the effectiveness of the action is only there so that the associated bundle which is a $G$ fiber bundle to have a unique choice of an induced bundle. I think the effectiveness of $\sigma$ is not needed to delete the info of $G$ at all. Besides (as discussed in Dr. Will Merry's lecture notes) any $G$ -fiber bundle that its structure group is not acting effectively on its fibers could be made into one that has an effective action by just adding an equivalence relation. So this does not harm the generality.","['principal-bundles', 'fiber-bundles', 'geometry', 'intuition', 'differential-geometry']"
4557352,Differentiability of a piecewise function involving $\sin$,"$
f(x)=
\begin{cases}
 x^2\sin\left(\frac{\pi}{x}\right)\;,\quad x <  0\\
 A\;,\qquad\qquad     x = 0 \\
      ax^2+b\;,\qquad x > 0
\end{cases}
$ I need to find $A$ , $a$ and $b$ knowing that $f$ is differentiable. I am doing this by using the definition of the derivative and showing that the two one-sided limits at 0 from the negative and positive side exist, and they must be equal to each other. I guess they must also be equal to the derivative of $f(x)$ at $0$ , which would be 0 since any constant function is differentiable. For the negative side I got the limit as $x$ tends to negative $0$ of $x\sin\left(\frac{\pi}{x}\right)$ - $\frac{A}{x}$ . For the positive side I got the limit as $x$ tends to positive $0$ of $ax + \frac{b}{x} - \frac{A}{x}$ . I set these two limits equal to $0$ and each other. I know for the first limit that the limit as $x$ tends to negative $0$ of $x\sin\left(\frac{\pi}{x}\right)=0$ by the sandwich theorem if it is defined as $0$ at $x=0$ . For $\frac{-A}{x}$ to tend to $0$ , A must be 0. Similarly, I ended up with $b$ = $0$ and $a$ any real number. I'm unsure on my method and would like some help with it. Cheers. Would it be best to first use the fact that $f(x)$ must be continuous at $0$ for it to be differentiable at $0$ ? That way I know $x^2\sin\left(\frac{\pi}{x}\right)$ would be $0$ as $x$ tends to $0$ from the left, and that should equal $b$ , meaning $b=0$ . Since the two limits must equal $f(0)$ , that would also give $A = 0$ . I could then deduce that $a$ can be any real number using the differentiability fact ?","['continuity', 'calculus', 'derivatives', 'piecewise-continuity']"
4557396,Question on Spivak's Definition of a Manifold.,"I am reading the first volume of Spivak's Differential Geometry Series, A Comprehensive Introduction to Differential Geometry , and I don't understand his definition of a manifold. He says that A metric space $M$ is a manifold if for each $x\in M$ , there is some neighborhood $U$ of $X$ and some integer $n\ge 0$ such that $U$ is homeomorphic to $\mathbb{R}^n$ . I understand how the (usual) Hausdorff condition of a manifold comes from the fact that $M$ is a metric space in this definition (of course, one can get rid of the metric space condition and just let $M$ be Hausdorff or just a topological space), but how does Spivak's definition account for the condition that $M$ must be second countable? Thank you for your help.","['general-topology', 'differential-geometry']"
4557427,Proving a combinatorial identity having sums of fractions of binomial coefficients,"Recently I was solving a probability question , and I encountered a summation that I was unable to figure out. I put it on Wolfram Alpha, and it returned an unexpectedly simple solution. The answer I mention is here , and it is correct as I have checked the solution independently using a different method (the second method in the answer). The identity in question is as follows: $$\sum_{n=1}^{r+1}\frac{\binom{r}{n-1}}{\binom{b+r}{n}}=\frac{b+r+1}{b(b+1)}$$ The linked answer definitely gives a probabilistic proof for the same, but I would very much like a direct proof. Any kind of method is acceptable that is different from what has been done in the answer. Thank you in advance!","['summation', 'binomial-coefficients', 'combinatorics', 'discrete-mathematics']"
4557475,Classifying groups of order 8 (semidirect products),"I am trying to classify groups of order 8 (we call it $G$ ). I understand there are similar questions on this website, but none of them is compatible to what I am expecting. Basically, I understand that there is a subgroup of order $4$ , by the proposition that if $p^{\alpha} \mid |G|$ , then $G$ must have a group of order $p^{\alpha}$ . Call this subgroup of order $4$ $N$ . As $[G : N] = 2$ , we also know that $N \triangleleft G$ . Let $K \cong G/N$ . We know a short exact sequence $1 \rightarrow N \rightarrow G \rightarrow K \rightarrow 1$ . I am asked to show if this sequence does not split, then we have either the quaternion group or an abelian one.  Here is what I tried. If this sequence does not split, so $K \cap N = \{e, h\}$ , s.h. $h$ is an element of order $2$ . I believe if I can show that $N$ cannot be the Klein-4 group, but $\mathbb{Z}/4$ , I can prove that $G \cong Q_8$ or $G \cong \mathbb{Z}/8$ . Not sure which step I am missing here. The second part is to show that if the sequence splits, we can construct all the other three groups of order $8$ , using semidirect products, considering different automorphisms. The second part is more clear to me, but I am not sure how to proceed in the first part.
Could anyone help me?","['semidirect-product', 'group-theory', 'abstract-algebra', 'finite-groups']"
4557498,"Show that $P\left(\limsup\limits_{n\to\infty}D_{m_n,i}\right)=1$ by means of Borel-Cantelli lemma","Let be $(\Omega,\mathcal{F},P)$ a probability space and $$
\limsup\limits_{n\to\infty} A_n:=\bigcap\limits_{n\geq 1}\bigcup\limits_{m=n}^{\infty}A_m,\text{ where } A_m\in\mathcal{F}\text{ for all } m\in\mathbb{N}.$$ If all $A_n$ are stochastically independent, then ( Borel-Cantelli lemma): $$
\sum\limits_{n=1}^{\infty}P(A_n)=\infty\implies P\left(\limsup\limits_{n\to\infty} A_n\right)=1.
$$ We consider a Bernoulli experiment with probability $p$ and length $n$ where the random variable $X_j:\Omega\to \{0,1\}$ , with $1\leq j\leq n$ , denotes the $j$ -th step. Further, we define the set $$
D_{m,i}:=\{X_{mi+k}=1\text{ for all }k=1,\dots, m\},
$$ where $0\leq i$ denotes the $i$ -th array of $m$ -consecutive $1$ 's. If we define for some $0<\epsilon<1$ the array-length $m_n:=\lceil(1-\epsilon)\log_{\frac{1}{p}}(n)\rceil$ , then show that $P\left(\limsup\limits_{n\to\infty}D_{m_n,i}\right)=1$ . In our lecture the professor conducted the proof as follows: Let be $T_{m}:=\sum\limits_{i\geq 0} 1_{D_{m,i}}$ , i.e. a summation over all possible arrays of length $m$ . We have at most $\left(\frac{n}{m}-1\right)-$ many arrays. Then, it follows $$
\mathbb{E}(T_{m_n})\geq\left(\frac{n}{m_n}-1\right)p^{m_n}=\dots=\frac{p}{m_n}n^{\epsilon}-pn^{-(1-\epsilon)}.
$$ We see that $\lim\limits_{n\to\infty}\mathbb{E}(T_{m_n})=\infty$ , so by Borel-Cantelli lemma it follows $P\left(\lim\sup\limits_{n\to\infty} D_{m_n,i}\right)=1.$ I am highly skeptical that this proof is correct. 1.) What does $P\left(\lim\sup\limits_{n\to\infty} D_{m_n,i}\right)=1$ mean? If I simply apply the aforementioned definition, then I have to fix the $i$ and it yields $\limsup\limits_{n\to\infty} D_{m_n,i}:=\bigcap\limits_{n\geq 1}\bigcup\limits_{m_n=n}^{\infty}D_{m_n,i}$ . But if I fix $i$ , then the sets $D_{m_n,i}$ are not necessarily independent. So this makes no sense!? 2.) Instead if I fix the $m_n$ and consider the sets $D_{m_n,i}$ with $0\leq i$ , then they would be stochastically independent. But this would only allow us to apply Borel-Cantelli lemma at the sequence $(D_{m_n,i})$ where $i\to\infty$ and $m_n$ is arbitrary but fixed. Maybe someone is more familiar with this issue and can confirm that this proof is false or help me if I have misunderstood something?","['borel-cantelli-lemmas', 'proof-explanation', 'probability-limit-theorems', 'probability-theory']"
4557551,"What is the Order Of Symplectic Group(4,2) and Symplectic Group(4,3) from the Classical groups of Atlas?","I have been working on Symplectic group of classical groups. I am trying to find Sylow-2 Subgroups of Symplectic Group(4,2) and Symplectic Grouop(4,3) through GAP, I am facing a problem regarding order of these groups. Order of Symplectic Group(4,2) and Symplectic Group(4,3) is 360 and 25920 respectively according to Atlas of Finite Groups but according to Gap calculations it is giving order of Symplectic Group(4,2) and Symplectic Group(4,3) is 720 and 51840 respectively. Help me  of about the exact order of these groups. I am bit confuse between them.","['gap', 'classical-groups', 'finite-groups', 'sylow-theory', 'group-theory']"
4557588,Is $\Phi^{-1}(\frac{n}{n+1})$ an unbiased estimator of the maximum of $n$ draws from the probability distribution of $\Phi$?,"Consider a continuous probability distribution $\mathcal{D}$ on $\mathbb{R}$ with cdf $\Phi$ and let $X_1,\dots,X_n\sim\mathcal{D}$ be iid random variables.
Then I have the following conjecture: $$\mathbb{E}\left(\max_iX_i\right)=\Phi^{-1}\left(\frac{n}{n+1}\right)$$ Can someone tell me whether this is true indeed or not? I conducted several Monte Carlo Simulations and found that it seems to hold for all continuous distributions, but I have no idea how to prove this rigorously myself and I also could not find a relevant theorem.","['probability-distributions', 'probability-theory', 'probability']"
4557591,Help verifying and simplifying $ \int_0^\infty \cos x^2 dx $ (the Fresnel integral) via complex contour integration,"Find $ \int_0^\infty \cos x^2 dx $ . Note: This is the Fresnel integral, whose derivation is available on this site and elsewhere .  I'd like verification of my proof, as well any recommended improvements to the exposition, which to me is simpler than much of what's published. Solution : We use the technique of contour integrals in the complex plane, creating three contours: $\alpha$ , from $0$ to $R$ along the real axis; $\beta$ , from $R$ to $Re^{i \pi/4}$ in a circular arc, and $\gamma$ , from $Re^{i \pi/4}$ to $0$ in a straight line. We first show that $\lim_{R \to \infty} \int_\beta e^{-z^2}dz = 0$ . $\int_\beta e^{-z^2}dz = \int_0^{\pi/4}e^{-R^2e^{2i\theta}}\cdot iRe^{i\theta}d\theta$ .  Since $|e^z| = |e^{\Re(z)}|$ and $|\int f(x) dx| \leq \int |f(x)| dx$ , we have $|\int_\beta e^{-z^2}dz| \leq \int_0^{\pi/4} |Re^{-R^2\cos {2\theta}}|d\theta$ .  Since $0 \leq \theta \leq \pi/4$ , $0 \leq \cos {2\theta} \leq 1$ , and so this goes to $0$ as $R \to \infty$ .  From this, we conclude $\int_\gamma e^{-z^2}dz = - \int_\alpha e^{-z^2}dz$ , since $e^{-z^2}$ is entire. Since the Gaussian integral $\int^\infty_{-\infty} e^{-x^2}dx = \sqrt \pi$ , and $e^{-x^2}$ is even, $\lim_{R \to \infty} \int_\gamma e^{-z^2}dz = - \int_0^\infty e^{-x^2}dx = - \sqrt \pi / 2$ . Also note that $\int_\gamma e^{-z^2} dz = \int_R^0 e^{-[re^{i\pi/4}]^2}e^{i\pi/4}dr = \frac{-\sqrt 2}{2}(1+i)\int_0^Re^{-ir^2}dr$ .  Thus, $\lim_{R \to \infty} \int_0^Re^{-ir^2}dr = \sqrt{2\pi}/4 + ki$ for some real $k$ , and its complex conjugate $\int_0^Re^{ir^2}dr = \sqrt{2\pi}/4 - ki$ . Finally, we conclude $\int_0^\infty \cos x^2 dx = \int_0^\infty \frac{e^{ix^2} + e^{-ix^2}}{2} dx = \frac{\sqrt{2\pi}}{4}$ , QED. Is my proof correct? I tried to skip mechanical steps while not omitting any conceptual leaps.  My goal is for the exposition to be simple, clear, and direct.  Did I succeed? Could the writing and exposition be improved? How?","['complex-analysis', 'proof-writing', 'solution-verification', 'contour-integration']"
4557621,Circumference of convergence for the power series of $\ln(x^2+2)$,"a) Given $f(x)=\ln(2+x^2)$ . Prove f has a power series in the neighborhood of $x=0$ and find its radius of convergence. This is my solution: \begin{equation}
f(x) = \ln (x^2 + 2) = \ln4+ \sum_{n=1}^\infty \frac{\left(-1\right)^{n+1}\left(x^2-2\right)^n}{n\cdot4^{n}}
\end{equation} And I calculate the radius like this: $$
L=\lim \limits_{x \to\infty} \lvert 
\frac{\left(-1\right)^{n+2}\left(x^2-2\right)^{n+1}}{(n+1)\cdot4^{n+1}} \cdot\frac{n\cdot4^{n}}{\left(-1\right)^{n+1}\left(x^2-2\right)^n}\rvert=
\lim \limits_{x \to\infty}\lvert 
\frac{-n(x^2-2)}{4(n+1)}
\rvert =|x^2-2| \lim \limits_{x \to\infty}|\frac{n}{4(n+1)}|=\frac{|x^2-2|}{4}
$$ The series converges when $L <1$ , therefore it converges when: $
|x^2-2|<4\Rightarrow|x|<\sqrt6
$ b) Decide in which points of the circumference of convergence the power series is convergent. The power series defines a function $h$ over a subset $S$ contained in the circumference of convergence. Find $S$ and study the continuity of $h$ in $S$ . When it comes to b), I'm completely lost. I have not found anything on circumferences of convergence and my professor won't give us any clue. How could I approach this? Any tips would be gladly appreciated. EDIT after reading comments: \begin{equation}
f(x) = \ln (x^2 + 2) = \ln2+ \sum_{n=1}^\infty \frac{\left(-1\right)^{n-1}x^{2n}}{2^nn}
\end{equation} And I get that the radius of convergence is $\sqrt2$ . To find the interval of convergence I study the values x that give $L=1$ .
For $
x=\sqrt2: 
$ $$
\sum_{n=1}^\infty \frac{\left(-1\right)^{n-1}(\sqrt2)^{2n}}{2^nn}=
\sum_{n=1}^\infty \frac{\left(-1\right)^{n-1}2^{n}}{2^nn}=
\sum_{n=1}^\infty \frac{\left(-1\right)^{n-1}}{n}=\ln2
$$ For $x=-\sqrt2$ we get the same result. Therefore the interval of convergence is $-\sqrt2\le x\le\sqrt2$","['power-series', 'calculus', 'functions']"
4557650,Proof that $a_{n}:=\sup\{|\frac{nx}{1+n^2x^2}|:x\in \mathbb{R}|\}$ $(n\in \mathbb{N})$ does not converge to $0$,"I am trying to prove that the sequence $a_{n}:=\sup\big\{|\frac{nx}{1+n^2x^2}|:x\in \mathbb{R}|\big\}$ $(n\in \mathbb{N})$ does not converge to $0$ . Is the following correct? Consider arbitrary $n\in \mathbb{N}$ . Choose some $x>n$ . Then $$|\frac{nx}{1+n^2x^2}|\geq |\frac{n^2}{1+n^2x^2}|\geq |\frac{n^2}{n^2+n^2x^2}|=|\frac{1}{1+x^2}|:=b>0$$ Thus, for any $n\in \mathbb{N}$ , $\sup\big\{|\frac{nx}{1+n^2x^2}|:x\in \mathbb{R}|\big\}\geq b>0$ (as, otherwise, for any $n \in \mathbb{N}$ we could find an $x\in \mathbb{R}$ such that $|\frac{nx}{1+n^2x^2}|>\sup\big\{|\frac{nx}{1+n^2x^2}|:x\in \mathbb{R}|\big\}$ —a contradiction. Thus, $\lim_{n\rightarrow\infty} \sup\big\{|\frac{nx}{1+n^2x^2}|:x\in \mathbb{R}|\big\}>0$ .","['analysis', 'real-analysis', 'solution-verification', 'sequences-and-series', 'supremum-and-infimum']"
4557658,Question about Image and Set notation.,"In class we had to show that if $g∘f$ is surjective, then so is $g$ (Where $f: M \to N$ and $g: N \to P$ ). We used a proof by contradiction, but I wanted to solve it with a direct proof because it seemed more intuitive to me. So here is my thought process: We have given, that $g(f(M)) = P$ and since $ f(M)\subseteq N $ this means that $g(""\text{a subset of N}"") = P$ (how do you write this?). So if a subset of the domain maps onto the entire codomain, then obviously the entire domain will also map onto the entire codomain. So $g(N) = P$ thus $g$ is surjective. So here are my questions: Does this proof even make sense? How would you formally write this? Is the notation $Im(f) $ the same as $f(M)$ (if $ M $ is the domain)? If so, how would you write this proof using $Im ()$ notation?","['elementary-set-theory', 'functions']"
4557718,Wasserstein distance for two normal cdfs,"Just came to know about a fact that the Wasserstein distance between two cumulative distribution functions, $F_1$ and $F_2$ , can be expressed as: $$\int_{-\infty}^{\infty} |F_1 (x)-F_2(x)| dx$$ . Is it possible to compute this distance in case $F_1$ and $F_2$ are two normal distributions, with constant variance $1$ and means $\mu_1 \neq \mu_2$ by hand? I have no clue how to work with the absolute value along with the integral which does not seem to have a closed form!","['measure-theory', 'statistics', 'probability-distributions', 'probability-theory', 'probability']"
4557751,Does this relationship between representations in different characteristics hold?,"Is it possible for the dimension of the smallest faithful representation of a group to be the same or larger in all finite characteristics than in any field of characteristic $0?$ I know that this happens for the Thompson sporadic group, which has a faithful representation of dimension $248,$ but can this happen for groups where the smallest faithful representation has dimension $249$ or more?","['matrices', 'group-theory', 'abstract-algebra', 'representation-theory']"
4557757,Find angle $x$ in the given composite figure of $\triangle BAC$ and $\triangle BDC$.,"A very unique question featuring a composite diagram of two triangles, with a missing angle and two equal sides.
I am posting this here to see what kind of different approaches there could be to solve it. Please feel free to leave your own answers! (I have posted my own approach as an answer below)","['contest-math', 'euclidean-geometry', 'geometry', 'triangles', 'trigonometry']"
4557766,Why is the function $(-2)^{x}$ continuous?,"If we work over complex mumbers we have $$\lim_{x\to\infty}(-2)^{\frac πx}=(-2)^0=1$$ But, if we work over $\Bbb R$ then the limit $\lim_{x\to\infty}(-2)^{\frac πx}$ should be undefined.  Because, as far as I know $a^x$ is not well defined if $a<0$ and $x\not\in \Bbb Z$ . Thus I couldn't understand. Why is the function $(-2)^{x}$ continuous? What does Wolfram mean?","['limits', 'calculus', 'exponential-function', 'algebra-precalculus']"
4557792,Why does $\sum_{n=2}^{\infty} \frac{1}{n \ln(n)}$ diverge if $n \ln(n)$ is greater than $n$ for $n \geq 2$?,Why does $\sum_{n=1}^{\infty} \frac{1}{n \ln(n)}$ diverge if $n \ln(n)$ is greater than $n$ for $n \geq 2$ .  Shouldn't $\sum_{n=1}^{\infty} \frac{1}{n \ln(n)}$ be comparable to a convergent p-series?  P-series converge for all $p > 1$ and if we try to imagine $n \ln(n)$ as a power of $n$ wouldn't the power be greater than 1?  What am I missing?,"['calculus', 'convergence-divergence', 'sequences-and-series']"
4557825,An injective or surjective square matrix is bijective?,"Is the argument below valid? Let $A$ a square matrix $n \times n$ . Suppose $A$ is injective, ie $Ker(A) = {0}$ . Therefore the columns of $A$ are linearly independent. We have $n$ vectors that are linearly independent, which means the set of vectors (the columns of A) are a basis of $R^n$ . Therefore, all vectors $\in R^n$ are a (unique) linear combination of the columns of $A$ . Therefore, $A$ has a unique solution to all vectors in $R^n$ . Therefore, $Im(A) = R^n$ . Therefore $A$ is surjective. Therefore $A$ is bijective. Let $A$ a square matrix $n \times n$ . Suppose $A$ is surjective, ie $Im(A) = R^n$ . Therefore every element of $R^n$ is a linear combination of the columns of $A$ . We have $n$ columns, meaning a generating set of $R^n$ of $n$ vectors. Therefore the columns of $A$ must be linearly independent. Therefore $Ker(A) = {0}$ . Therefore $A$ is injective. Therefore $A$ is bijective.","['matrices', 'linear-algebra', 'vector-spaces']"
4557842,Fermat's Last Theorem Intuition [duplicate],"This question already has answers here : Is it possible that Fermat was NOT lying when he said he actually knew the proof for his last theorem? (3 answers) Closed 1 year ago . ""It is impossible to separate a cube into two cubes, or a fourth power into two fourth powers, or in general, any power higher than the second, into two like powers. I have discovered a truly marvelous proof of this, which this margin is too narrow to contain."" — Fermat (1670), in the margin of his copy of the Arithmetica (translated from Latin) [Wikipedia] . It's remarkable that Fermat never wrote down his proof of what is now his most famous theorem, yet he happened to be right about it. It took hundreds of years and dozens of pages to prove this, yet he was somehow able to conceptualize it on his own while casually reading the Arithmetica . To add, Andrew Wiles' proof of Fermat's Last Theorem recruits a great amount of abstract algebra—a field of math that would not be invented until around 200 years after Fermat made his famous note in that margin. How was Fermat able to grasp the reasoning behind this theorem's proof without abstract algebra? Is there a simple way to conceptualize Fermat's Last Theorem using only the mathematical knowledge available to Fermat during his time?",['number-theory']
4557954,Summation of a rational function,"Calculate $\sum_{r=2}^{n} \frac{3r^2-1}{(r^3-r)^2}$ . My approach till now: $T_r=\frac{3r^2 -1}{r^2(r+1)^2(r-1)^2}$ . Now let, $$3r^2-1= a(r^2)+ b(r+1)^2 + c(r-1)^2$$ we find, $a=4$ , $b=c=-\frac{1}{2}$ . now we break it up, $$T_r = \frac{4}{(r+1)^2(r-1)^2}-\frac{1}{2(r)^2(r+1)^2}-\frac{1}{2(r)^2(r-1)^2}$$ but now the problem is I can't convert any of them into a ""telescopable"" format another insight I had was to break it up in another way, $$T_r= \frac{r^2 + (r^2-1)+(r^2-1)+1}{r^2(r^2-1)(r^2-1)}$$ after a bit of simplifying, $$T_r= \frac{1}{(r^2-1)(r^2-1)} + \frac{2}{r^2(r^2-1)}+\frac{1}{r^2(r^2-1)(r^2-1)}$$ now two terms are solvable but how to do the third term maybe if you simplify it even more we get, $$T_r = \frac{1}{(r^2-1)(r^2-1)} + \frac{2}{r^2(r^2-1)}+\frac{r^2-(r^2-1)}{r^2(r^2-1)(r^2-1)}$$ $$T_r=\frac{1}{(r^2-1)(r^2-1)} + \frac{2}{r^2(r^2-1)}+ \frac{1}{(r^2-1)^2}-\frac{1}{r^2(r^2-1)}$$ now rewriting, $(r^2-1)^2 = (r+1)^2(r-1)^2$ , we get $$T_r= \frac{2}{(r+1)^2(r-1)^2}+\frac{1}{r^2(r^2-1)}$$ but now how to solve the first term...","['algebra-precalculus', 'sequences-and-series']"
4557966,"Proof that $f_n(y)=\frac{n^2 y}{1+n y+n^4 y^2}$ does not converge uniformly, on $[0, \infty)$, to the identically-0 function","For $n \in \mathbb{N}$ , the function $f_n:[0, \infty) \rightarrow \mathbb{R}$ is defined by $$
f_n(y)=\frac{n^2 y}{1+n y+n^4 y^2}
$$ I am trying to prove that the sequence $\{f_{n}\}_{n\in \mathbb{N}}$ does not converge uniformly to the identically-zero function (the function $f$ given by $f(y)=0$ , $\forall$ y). Is the following correct? Set $\epsilon=\frac{1}{3}$ . Consider arbitrary $N\in \mathbb{N}$ . Choose an arbitrary $n>N$ . Set $y=\frac{1}{n^2}$ . Thus $$\left|\frac{n^2 y}{1+n y+n^4 y^2}\right|\geq\left|\frac{n^2 y}{1+n^2 y+n^4 y^2}\right|= \left|\frac{1}{1+1+1 }\right|=\epsilon$$","['solution-verification', 'uniform-convergence', 'analysis', 'real-analysis']"
4558018,Show that intersection distributes over the symmetric difference,"I have been trying to show the following: $(A \Delta B) \cap C = (A \cap C) \Delta (B \cap C)$ Considering the Venn diagram, the relationship is easily confirmed. Algebraically, however, the furthest I have gotten, starting from the right side, is: $((A \Delta B) \cap ((C \setminus B) \cup (B \setminus A))) \cap (((A \setminus B) \cup (C \setminus A)) \cap (C \setminus (A \cap B)))$ Analogously, starting from the left side: $(A \Delta B) \cap (C \cup (B \setminus A)) \cap ((A \setminus B) \cup C) \cap C$ Though both expressions yield the same Venn diagram, I have not figured out how to make a connection between the two expressions.
Did I do unnecessary steps and overshot the easiest path for the solution or am I just not there yet? I am looking forward to your answers!
Thank you for taking your time.",['elementary-set-theory']
4558019,"When will ""permuted vectors"" be linearly independent?","Let $n\geq2$ be a natural number and let $x_1,\ldots,x_n$ be $n$ real numbers.  Is there a general sufficient condition to guarantee that the set of $n$ ""cyclicly permuted"" vectors $\left\{(x_1,x_2,\ldots,x_n), (x_n, x_1,\ldots,x_{n-1}), \ldots, (x_2,x_3,\ldots,x_1)\right\}$ is linearly independent? When $n=2$ it is sufficient and necessary that $(x_1+x_2)(x_1-x_2)\ne0$ .  When $n=3$ , the determinant of the matrix whose rows are those vectors is $(x_1+x_2+x_3)\left(\frac{{(x_1-x_2)}^2+{(x_1-x_3)}^2+{(x_2-x_3)}^2}{2}\right)$ , so the necessary and sufficient condition is that the sum of those $3$ numbers is not zero, and they are not all the same number. In general, the determinant of the matrix is $$
\prod_{k=0}^{n-1}\left(\sum_{\ell=0}^{n-1}e^{\frac{2\pi ik\ell}{n}}\cdot x_{\ell+1}\right).
$$ But I am unable to deduce some intuitive condition for that to be non-zero. Since I think that determinant is a product of discrete Fourier transforms, I also tag this as related to Fourier transform. If this is inappropriate, I will remove that tag. P.S. The determinant can be found as Lemma 5.26 in Washington's Introduction to cyclotomic fields. Any help is greatly appreciated.","['linear-independence', 'determinant', 'linear-algebra', 'fourier-transform']"
4558022,L'hopital's rule mistake for multivariable calculus,"I've been helping some students in multivariable calculus and they're currently working with limits and it's been expressed by the lecturer that L'hopital's is exclusively for single-variable functions. I know this to be true as well, but the students have found that using L'hopital's in the same way that they take partial derivatives, leads them to solutions to their limit problems. Take for example $$\lim_{(x,y)\to(0,0)} \frac{e^{xy}-1}{y}$$ If we plug in our limit, we get an indeterminate form. Students have found that if they ""fix $x$ "" and use L'hopital's in $y$ , they get $$\lim_{(x,y)\to(0,0)} \frac{xe^{xy}}{1} = 0\cdot 1 = 0$$ which is in fact the limit when you do it through less dubious means. It's worked in other problems as well, even those where the limit doesn't exist, students have just used L'hopital's with respect to different variables and found that they ""gave different limits in the end, so the overall limit must not exist"", which for that problem, it definitely did not exist by checking a few simple paths. Here are my questions. Why does this seem to work sometimes? How would you convince students that this is not the way to go? I've tried with counterexamples, but they seem to still prefer it because it works on all their actual homework problems (Marsden).",['multivariable-calculus']
4558038,"Given a list of numbers, probability of the first number being the maximum?","So I'm traversing this trivia book which has a question that has intrigued and widely confused me. 1.) Since we have $n$ number of elements, then the probability of it being the largest among the $n$ choices is $\frac{1}{n}$ , which seems intuitive. 2.) The probability of it being larger than the second number $x_{2}$ is: either it will be larger or not, therefore $\frac{1}{2}$ . Similarly, now this process is repeated $(n-1)$ times to check whether $x_{1}$ is larger than all other elements. Then the probability we will arrive at is : $\frac{1}{2^{n-1}}$ I equally believe in both processes, but of course, one is wrong. Apart from knowing which is right, it will be helpful to elucidate on why the other is wrong.",['probability']
4558076,Is the mapping sending the parameter to the corresponding fixed point continuous?,"Let $(X,d)$ be a complete metric space, let $T$ be a topological space, and $(f_t)_{t\in T}$ be a family of mappings $f_t:X\to X$ with the following properties : for each $x\in X$ , the map $T\to X,t\mapsto f_t(x)$ is continuous, and there exists a constant $k$ such that $$0<k<1,\;d(f_t(x),f_t(y))\le kd(x,y)\;\;\forall x,y\in X,\forall t\in T. $$ By the Banach fixed point theorem, for each $t\in T$ there exists a unique fixed point $x_t$ of $f_t$ . Is the map $T\to X,t\mapsto x_t$ continuous ? I think that if $T$ is a metric space then the answer is true. Now, suppose $T$ is just a topological space, is the mapping still continuous ?","['general-topology', 'functional-analysis', 'analysis']"
4558200,Find the length measure $x$ in right triangle $\triangle ABC$,"As title suggests, the objective is to solve for the missing length $x$ in this problem. I spent some time on the problem and figured out, what I believe, a very simple approach, I'll post it as an answer down below, please share your own approaches as well!","['triangles', 'euclidean-geometry', 'trigonometry', 'geometry']"
4558233,How can I find functions satisfying the Bessel equation $\frac{d^2}{dt^2}y(t)+p(t)\frac d{dt}y(t)+q(t)y(t)=0$?,"We are tasked with finding the functions $u(t), Q(t)$ such that the conversion $y(t) = u(t)v(t)$ takes us from \begin{align}
\dfrac{d^2}{dt^2}y(t) + p(t)\dfrac{d}{dt}y(t) + q(t)y(t) = 0
\end{align} to the form \begin{align}
\dfrac{d^2}{dt^2}u(t) + Q(t)u(t)=0.
\end{align} From then on we must use this to solve $t^2\dfrac{d^2}{dt^2}y(t) + t\dfrac{d}{dt}y(t) + \left(t^2-\dfrac{1}{4}\right)y(t) = 0$ . My take was this: I started differentiating (misusing the notation to make it easier to read) \begin{align}
&y(t)=u(t)v(t)\\
&y'(t)=u'(t)v(t)+u(t)v'(t)\\
&y''(t)=u''(t)v(t) + 2u'(t)v'(t) + u(t)v''(t)
\end{align} thus the original equation gives \begin{align}
u''(t) v(t) + 2u'(t)v'(t) + u(t)v''(t)+ p(t) \left[ u'(t)v(t)+u(t)v'(t) \right] + q(t)u(t)v(t) = 0
\end{align} dividing by $v(t)$ (we can assume it's nonzero) we have \begin{align}
\boxed{u''(t)} + \dfrac{2u'(t)v'(t)}{v(t)} + \boxed{u(t)} \dfrac{v''(t)}{v(t)} + p(t)u'(t) + \boxed{u(t)}\dfrac{p(t)v'(t)}{v(t)} + \boxed{u(t)}q(t)=0.
\end{align} All the boxed terms give us (by common factor) the $Q(t)$ we ask for. However the remaining non-boxed terms must be zero right? So let's ask the equation to zero this for us: \begin{align}
\dfrac{2u'(t)v'(t)}{v(t)} + p(t)u'(t) = 0\\
\implies u'(t) \left[ 2\dfrac{v'(t)}{v(t)} + p(t) \right] = 0\\
\implies u(t) = c \ \lor \ 2\left( \ln v(t) \right)' + p(t) = 0\\
\implies u(t) = c \ \lor \ v(t) = e^{-\int \left(\dfrac{p(t)}{2}dt\right)}.
\end{align} This is where I have arrived, and I am not sure how to proceed. Can we assume that $u(t)$ cannot be constant? What about $v(t)$ ? Nowhere is this asked to find right? Any help would be appreciated.","['derivatives', 'ordinary-differential-equations']"
4558261,Cohomology groups (on curves) under closed immersions,"Suppose $X$ is a separated, projective curve, and $Z = V(\mathcal{J})$ (where $\mathcal{J}$ is a nilpotent sheaf of ideals) is a closed subscheme of $X$ with closed immersion $i : Z \to X$ . Is it true that $H^{1}(Z,\mathcal{O}^*_Z) \cong H^{1}(X, i_*\mathcal{O}^*_Z)$ (in a canonical way?). I stumbled across this in the proof of Liu, Lemma 7.5.11, where he seems to use this to get from the exact sequence $$1 \to 1 + \mathcal{J} \to \mathcal{O}_X^* \to \mathcal{O}_Z^* \to 1$$ the exact sequence of cohomology groups $$\mathcal{O}_X(X)^* \to \mathcal{O}_Z(Z)^* \to H^{1}(X, 1 + \mathcal{J}) \to \text{Pic}(X) \to \text{Pic}(Z) \to 0.$$ (He assumes here that $\mathcal{J}^2 = 0$ .) Now, for a quasi-coherent sheaf $\mathcal{F}$ on $Z$ , we have $H^{1}(Z,\mathcal{F}) \cong H^{1}(X, i_*\mathcal{F})$ by Liu, Ex 5.2.3, but to my understanding, $\mathcal{O}_Z^*$ is not quasi-coherent.","['algebraic-geometry', 'sheaf-cohomology']"
4558316,Can a Lipschitz-continuous function take on every value more than $L$ times?,"Here's an interesting question I stumbled upon recently: can a Lipschitz-continuous function $f:[0,1]\to[0,1]$ with Lipschitz bound $L$ take on every value $y\in[0,1]$ more than $L$ times? Intuitively, I'd expect the answer to be no, but it's not at all obvious to me how that could be proven. It seems to me like there might necessarily be some measure theory involved, but I'm curious whether a more elementary proof exists as well.","['lipschitz-functions', 'real-analysis']"
4558386,"Prove or disprove: Let $f$ be a non-constant polynomial, then $f(x)f(1/x)=1~\Rightarrow~f(x)=\pm x^n,$ for some $n \in \Bbb N$","Prove or disprove: Let $f$ be a non-constant polynomial, then $$f(x)f(1/x)=1~\Rightarrow~f(x)=\pm x^n,$$ for some $n \in \Bbb N$ . I was trying to prove: If $$f(x)=a_0+a_1x+...+a_nx^n,$$ then $a_0=a_1=...=a_{n-1}=0$ and $a_n=\pm 1$ , from the equation $$(a_0+a_1x+...+a_nx^n)(a_0+a_1/x+...+a_n/x^n)=1,$$ I can see this yields $a_0^2+a_1^2+...+a_n^2=1$ , then how to reach at $a_0=a_1=...=a_{n-1}=0$ ?","['functions', 'polynomials', 'real-analysis']"
4558401,How to numerically calculate a eigenvalue problem?,"Suppose we have a eigenvalue problem: \begin{array}{c}
y^{\prime \prime}+\lambda y=0,0<x<l \\
y(0)=0,  y(l)=0
\end{array} and we know the eigenvalue is $\lambda =\frac{n^{2}\pi ^{2}  }{l^{2}}  $ , and eigenfunction $y\left ( x \right ) =C\sin \frac{n\pi x}{l}  $ . But if I want to calculate the eigenvalue numerically, I think first I should choose basis for the funtion, and then represent the linear operator in ODE as a matrix. My question is what basis should I pick for this problem? Can I choose basis such as $\left \{1,x,x^{2} , x^{3},... \right \}$ ? The eigenvalue for this problem is also determined by the boundary conditons, but how does the boundary conditons affect the matrix? I also found people with related  question:( Solve the eigenvalue problem $y''=\lambda y$ numerically ), and he numerically calculate the problem using finite difference. It seems that his method do not need to find basis. Is this a trick to solve this problem or still related to some kind of basis I am not aware of?","['ordinary-differential-equations', 'eigenvalues-eigenvectors', 'linear-algebra', 'boundary-value-problem', 'numerical-methods']"
4558551,Reference request for a proof that $x^2+1=0$ is soluble mod $p$ if $p\equiv 1$ mod $4$,"I came up with the following proof $(\star)$ for the famous result that $x^2+1=0$ is soluble in $\mathbb{Z}/p$ when $p=1$ mod $4$ and wondered if someone could refer me to where else it was given. Proof $(\star)$ . Let $A=\{(x,y)\in(\mathbb{Z}/p)^2 : x^2-y^2=1\}$ . Since $x^2-y^2=(x+y)(x-y)$ and the mapping $(x,y)\mapsto(x+y,x-y)$ is a bijection of $(\mathbb{Z}/p)^2$ it follows that $\#A=\#\{(a,b)\in (\mathbb{Z}/p)^2: ab=1\}=p-1$ is divisible by four. Now, one may act on $A$ by flipping the signs of $x,y$ . So nonzero solutions to $x^2-y^2=1$ come in groups of four. There are two solutions with $y=0$ (namely $x=\pm1$ ), and so there have to be two solutions with $x=0$ , which is what we want. Edit. To emphasize - I'm looking for any publication with this proof to know who it originally belongs to.","['number-theory', 'prime-numbers', 'elementary-number-theory', 'reference-request']"
4558595,Dyck Paths with varying upstep size,"A problem I have been thinking about for a few years boils down to something very similar to the generalized ballot problem. Consider (something that seems very close to) a Dyck path starting at $(0,I)$ and ending at $(N,0)$ with downsteps $(1,-1)$ . The upsteps are allowed to be one of the 4: $(1,R_1), (1,R_2), (1,R_3), (1,R_4)$ . I am trying to calculate the number of paths/sequences of the $4$ upsteps, and $1$ downstep that ultimately get you from start to finish, while never going below or touching the $x$ -axis. I have been stuck along while just trying to figure this out for a single upstep, so I can't say I have tried much. Any direction appreciated!","['combinations', 'combinatorics', 'sequences-and-series', 'probability-theory', 'probability']"
4558632,A mysterious equality $\int_0^1 \left( e^x+x-1\right) e^{-\frac{x}{\mathrm{e}^x-1}}~dx=(e-1)^2e^{\frac e{1-e}}$,"I can't prove this mysterious equality $$\int_0^1 \left(e^x+x-1\right)e^{-\frac{x}{\mathrm{e}^x-1}}dx=(e-1)^2e^{\frac e{1-e}}.$$ The changes of variables I used lead to nowhere. Origin :
My friend proposed  me two integrals: The first is the object of the question and the second is to prove that $\quad\displaystyle \int_0^\infty \dfrac{x}{1-\text{e}^{-x}}\exp\left(\dfrac{x}{\text{e}^{-x}-1}\right)dx=1$ . The second is of the form $\displaystyle \int_0^\infty g(h(x) dx$ where $h(x)=\dfrac{x}{1-\text{e}^{-x}}$ and $g(x)=xe^{-x}$ . By using properties of h and g and especially that $h(x)-h(-x)=x,\quad  \forall x\in \mathbb R$ , we can show that $\displaystyle \int_0^\infty g(x)dx=\int_0^\infty g\circ h(u)du$ and the result is proven.","['integration', 'calculus', 'definite-integrals']"
4558684,Integrate $\sqrt{1+x^2+y^2}$,"Calculate $$I=\int_{-1}^1\int_{-1}^1\sqrt{1+x^2+y^2}\,\mathrm{d}y\,\mathrm{d}x.$$ It's a problem from a book about calculus. My attempt: $$\begin{align}
I &= \int_{-1}^1\int_{-1}^1\sqrt{1+x^2+y^2}\,\mathrm{d}y\,\mathrm{d}x \\
  &= \int_{-1}^1\left.\frac{x}{2}\sqrt{1+x^2+y^2}+\frac{1+y^2}{2}\log\left(x+\sqrt{1+x^2+y^2}\right)\right|_{-1}^{1}\,\mathrm{d}y \\
  &= \int_{-1}^1\sqrt{2+y^2}+\frac{1+y^2}{2}\left(\log \left(\sqrt{2+y^2}+1\right)-\log\left(\sqrt{2+y^2}-1\right)\right)\,\mathrm{d}y \\
  &= \sqrt{3}+2\operatorname{arsinh}\frac{1}{\sqrt{2}}+\int_{-1}^1(y^2+1) \operatorname{arsinh} \frac{1}{\sqrt{y^2+1}}\,\mathrm{d}y \\
  &= \color{red}\ldots \\
  &= -\frac{2}{9} (\pi + 12 \log 2 - 6 \sqrt{3} - 24 \log (1+ \sqrt{3}))
\end{align}$$ (answer taken from the solutions, no idea how to reach it). [edit] Here is an attempt with polar coordinates. Due to symmetry, it's enough to integrate over $0 \le x \le 1$ and $0 \le y \le x$ , 1/8th of the initial square. $$\begin{align}
I &= 8\int_0^{\pi/4} \int_0^{1/\cos \theta}r \sqrt{1+r^2}\,\mathrm{d}\theta\\
&= 8\int_0^{1/\cos \theta} \frac{(1+1/\cos^2\theta)^{3/2}-1}{3}\,\mathrm{d}\theta\\
&= {?}
\end{align}$$","['calculus', 'definite-integrals']"
4558701,Squarefree parts of integers of the form $xy(x+2y)(y+2x)$,"The motivation for this question comes from Theorem 3.3 of the 1995 paper Tilings of Triangles by M. Laczkovich, which states: Let $x$ and $y$ be non-zero integers such that $x+2y\neq 0\neq y+2x$ . Then there is  a positive integer $k$ such that the equilateral triangle can be dissected into $n=|xy(x+2y)(y+2x)k^2|$ congruent triangles. I am curious about the realizable squarefree parts of such integers, hereafter $s(x,y)$ . Since we focus on the squarefree part, it suffices to consider the case where $\gcd(x,y)=1$ . In the range $|x|,|y|<10,000$ , the realizable values of $s(x,y)$ are $$1, 5, 6, 10, 11, 13, 14, 15, 17, 19, 21, 22, 23, 29, 30, 33,\ldots$$ of which the squarefree integers missing are $$2, 3, 7, 26, 31, 38, 43, 51, 53,\ldots$$ This sequence is not in OEIS, but I am very far from confident that it is complete; the smallest solution for $s(x,y)=19$ is given by $x=578,y=-225$ and for $s(x,y)=37$ it is $x=5929,y=648$ . However, if there are any squarefree integers missing from the image of $s$ then no compatible OEIS sequences exist, even allowing for an initial $0$ term. I would be curious to see a proof that specific values like $7$ are not realizable by this function, even if it does not generalize to a complete characterization. Alternatively, pointers to open problems that render solving this very difficult or conjectures that would imply certain results here would also be welcome. As an aside, here is a sketch of a rough heuristic argument (not a proof!) that the equation $s(x,y)=k$ should have only finitely many solutions for a fixed $k$ with $x$ and $y$ coprime: Consider the squarefree parts of $x$ , $y$ , $2x+y$ , and $x+2y$ , hereafter $a,b,c,d$ respectively. No prime greater than $3$ can be shared among two of $a,b,c,d$ without violating coprimality, so we have finitely many ways to partition the factors of $k$ among the four values times at most $4^4$ ways to assign them all an additional factor of $1,2,3,$ or $6$ . So we are seeking a solution to one of a finite number of equation systems of the form $x=\pm a\cdot p^2, y=\pm b\cdot q^2, x+2y=\pm c\cdot r^2, 2x+y=\pm d\cdot s^2$ . Let's estimate the expected number of solutions to one such equation system with $\frac z2 < |x|,|y|\le z$ . We have $O(\sqrt{z})$ choices for each of $x$ and $y$ in this range, hence $O(z)$ choices for the pair. For each such choice of $x$ and $y$ , if we model an integer $n$ of having an $O(1/n)$ chance to be square, and assume independence, we'll get an $O(1/z^2)$ chance of success (ie that both $c(x+2y)$ and $d(2x+y)$ ended up being perfect squares) for every such $x,y$ we pick. Adding up, we have (heuristically) an expected $O(1/z)$ total solutions for valid $x,y$ in this range. If we sum this over the ranges $[\frac z2=1,z=2],[\frac z2=2,z=4],[4,8],[8,16],\ldots$ we find that the sum converges. Hence, the expected number of solutions across all the equations, and so the expected number of solutions to $s(x,y)=k$ , is finite, though the expected size of a solution if one exists is infinite. This accords fairly well with the data so far, including the isolated very large solutions. (Of course, there might well be substantial correlations or patterns in the factors of $x+2y$ and $2x+y$ that make this model of the terms as independent random draws extremely
bad! But absent reasons to suspect such patterns in one direction or another, I'd guess this is roughly the behavior of this function.)","['number-theory', 'triangles', 'tiling']"
4558704,How to find the limit of $\sqrt[^n]{n+1}$ as n approaches $\infty$?,"How to find the limit of $\sqrt[^n]{n+1}$ as n approaches $\infty$ ? My teacher hasn't taught L'Hopital's Rule yet, so I am only able to solve this using some standard limits. The similar standard limit I can think of is $\lim_{n\to\infty} (1+\frac{a}{n})^n = e^a$ . What I have done so far: $\lim_{n\to\infty} \sqrt[^n]{n+1}$ $ = \lim_{n\to\infty} (n+1)^{\frac{1}{n}}$ Let $ m = \frac{1}{n} \therefore n = \frac{1}{m}$ . Since $n\rightarrow\infty$ , $m\rightarrow0$ . $\lim_{m\to0} (1+\frac{1}{m})^m$ But I'm stuck in this step because I don't know how to work out the answer. If I just substitute $0$ in m, $1+\frac{1}{m}$ is undefined. If I rewrite this as $e^{log((1+\frac{1}{m})^m)}$ , it's also undefined. I know the limit is $1$ by looking at the graph. I'm wondering how I'm able to solve it in a more rigorous way.","['limits', 'limits-without-lhopital']"
4558778,"Let $A, B, M ∈ M_n(C)$ such that $AM = MB$ . If $M ≠0$, Show that $A$ and $B$ must have at least one eigenvalue in common. [duplicate]",This question already has answers here : There exists $C\neq0$ with $CA=BC$ iff $A$ and $B$ have a common eigenvalue (5 answers) Closed 1 year ago . I supose that if $t$ is an eigenvalue of $B$ and hence there is an eigenvector $x$ associated such that $Bx=tx$ $MBx=M(tx)$ $AMx=A(Mx)=t(Mx)$ How can I ensure that $Mx$ is different from $0$ so that $t$ is an eigenvalue of $A$ ?,"['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
4558803,An ODE confusion,"I was thinking about a ODE problem recently when I was reading about dynamical system. In school we used to solve the ODE problem $\frac{dx}{dt}=\sqrt{1-x^2}, x=0, t=0$ as $x=\sin(t),$ which will have the graph Now in dynamical system we can see that the fixed points are $\pm 1$ so specifically we can observe if the solution hits $1$ or $-1$ it should not increase or decrease from there. Specifically if we draw the phase diagram we can conclude that the solution passing through $(0,0)$ should look like and it seems reasonable. So I am surprised that we were taught wrong for many days. Isn't it? Or, am I making any mistake?","['ordinary-differential-equations', 'real-analysis', 'stability-in-odes', 'nonlinear-dynamics', 'dynamical-systems']"
4558809,generation of symmetric group of prime degree,"Let $p$ be a prime, $a=(1,2,...,p)$ , $b$ is an odd permutation satisfying $b^{-1}ab\notin \langle a \rangle$ in $S_p$ , I found that $\langle a,b \rangle$ is always the symmetric group $S_p$ when p is small ( $p \leq 23$ , use GAP and Magma), but I have no idea to prove it. Is it always true? Can you prove it or find a counterexample for it? Thanks for any help!","['permutations', 'group-theory', 'symmetric-groups', 'finite-groups']"
4558831,Is there an interesting (graphical) intuition about what the condition $f\circ g=g\circ f$ implies?,"I have a few questions about continuous functions $f$ and $g$ that satisfy the condition $$f\circ g=g\circ f\tag{1}$$ (1) Is there an interesting (graphical) intuition about what this condition implies? I have to think a lot to come up with an example that isn't inverse functions. Is there some insight that would permit coming up with examples easier? (2) Given a function such as $f(x)=1+2x$ how do we find a $g$ that together with $f$ satisfies $(1)$ ? (3) If we impose the additional condition that $0\leq f,g\leq 1$ for all $x\in [0,1]$ , what are some examples in which (3a) $f(1)\neq g(1)$ ? (3b) in particular, $f(1)$ and $g(1)$ are in $(0,1)$ and $f(1)\neq g(1)$ ? Here are examples I came up with that aren't inverses. $f(x)=\sqrt{x}$ , $g(x)=x^4$ , $f(g(x))=g(f(x))=x^2$ Here we have a case of (3a) $f(x)=x$ , $g(x)=1-x$ , $f(g(x))=g(f(x))=1-x$ I haven't been able to come up with a case (3b). Some Context This question came up while solving a problem in Chapter 22, ""Infinite Sequences"", from Spivak's Calculus . The task there was to prove that if $f$ and $g$ are continuous functions on $[0,1]$ $f\circ g=g\circ f$ $0\leq f(x),g(x)\leq 1$ for all $x\in [0,1]$ $f$ increasing then $f$ and $g$ have a common fixed point. I was able to prove this, but even so I don't feel like I have a good feel for what the assumptions mean. Hence, my questions.","['algebra-precalculus', 'functions', 'graphing-functions']"
4558841,"Evaluate $\int x^2\log(1-x^2)dx$, and hence prove that $\frac1{1\cdot5}+\frac1{2\cdot7}+\frac1{3\cdot9}+...=\frac23\log2-\frac89$","Evaluate $\int x^2\log(1-x^2)dx$ , and hence prove that $\frac1{1\cdot5}+\frac1{2\cdot7}+\frac1{3\cdot9}+...=\frac23\log2-\frac89$ My Attempt: Integrating by parts, $$\log(1-x^2)\cdot\frac{x^3}3-\int\frac{-2x}{1-x^2}\cdot\frac{x^3}3dx\\=\frac{x^3}3\log(1-x^2)-\frac23\int\frac{1-x^4-1}{1-x^2}dx\\=\frac{x^3}3\log(1-x^2)-\frac23\int1+x^2-\frac1{1-x^2}dx\\=\frac{x^3}3(\log(1-x)+\log(1+x))-\frac23(x+\frac{x^3}3)+\frac13\log|\frac{1-x}{1+x}|+c\\=\frac{x^3-1}3\log(1-x)+\frac{x^3+1}3\log(1+x)-\frac23(x+\frac{x^3}3)+c$$ If we apply limits from $0$ to $1$ , we get $$\frac23\log2-\frac89,$$ which is the required RHS. How to get the required LHS?","['integration', 'indefinite-integrals', 'calculus', 'definite-integrals']"
4558858,Equality between a set and the limit superior of a sequence of sets,"I have been asked to discuss whether $\{x : \varlimsup f_n(x) \gt a\}$ is equal to $\varlimsup \{x : f_n(x) \gt a \}$ I know there are many missing details but this is the way my professor has given the class the exercise. I assume $a\in\mathbb{R}$ and $\forall n\in\mathbb{N} , f_n : \mathbb{R}\to\mathbb{R}$ .
The professor told us that the sets are not equal because we have $\{x : \varlimsup f_n(x) > a\} \subset 
\varlimsup \{x : f_n(x) > a \}$ but $\{x : \varlimsup f_n(x) > a\}  \not\supset 
\varlimsup \{x : f_n(x) > a \}$ I think I understand why the first statement is true. But the professor told us that the second is true because $y\in\varlimsup \{x : f_n(x) > a \}$ only implies $y\in\{x : \varlimsup f_n(x) \ge a\}$ which I don't understand. Could someone explain it to me ? Similarly, we have been told that $\{x : \varlimsup f_n(x) \ge a\}$ is not equal to $\varlimsup \{x : f_n(x) \ge a \}$ Is it for the same reasons ? Thanks in advance!","['limits', 'functions', 'sequences-and-series']"
4558859,"Can an uncountable set be chopped up into singletons using countably many ""slices""?","Let $X$ be an uncountable set. Can we find a countable family of subsets of $X$ , $(A_i)$ , such that for every $x\in X$ : $$\bigcap \{ A_i | x\in A_i \} = \{x\}$$ If you think of each $A_i$ as being a kind of ""chop"", where we cut out a section of $X$ with a cookie cutter, we're saying that after countably many chops we've completely chopped $X$ up into singletons. I sort of doubt the answer depends on $|X|$ , but if it does, what is the largest cardinal of $X$ such that this is possible?",['elementary-set-theory']
4558880,remarkable identity for complex numbers,"I have homework to do and the question is : $$\text{Prove that for all } z \in \mathbb{C} \setminus{\{-1\}}, \frac{1-z}{1+z} \in \mathbb{R} \leftrightarrow z \in \mathbb{R}$$ So I started by saying that $z = a+ib$ with $a\in \mathbb{R}$ and $b\in \mathbb{R}$ . Then I wanted to write something like $\frac{1-z}{1+z}= A+iB \text{ }$ with $A$ and $B$ real numbers.
So: $$ \frac{1-a-ib}{1+a+ib} = \frac{(1-a-ib)(1+a-ib)}{(1+a+ib)(1+a-ib)} $$ So here is the interesting part: i used the remarkable identity $(A-B)(A+B) = A^2-B^2$ with $A = 1$ and $B = a-ib$ (in the numerator). Wich would give $1^2-(a-ib)^2$ .
But why does it doesn't work ? When i develop this, I find $1-a^2+2aib+b^2$ and not $-a^2-b^2-2ib+1$ like wolfram alpha says. Can you enlighten me please ?","['algebra-precalculus', 'complex-numbers']"
4558909,Proof of Arzela-Ascoli Theorem on Conway's book,"CONTEXT Conway's Functions of One Complex Variable I, page 148, reads 1.23 Arzela-Ascoli Theorem. A set $\mathcal F \subset C(G,\Omega)$ is normal iff the following two conditions are satisfied. (a) For each $z$ in $G$ , $\{f(z) : f\in \mathcal F\}$ has compact closure in $\Omega$ . (b) $\mathcal F$ is equicontinuous at each point of $G$ . Proof. First assume that $\mathcal F$ is normal. Notice that for each $z$ in $G$ the map of $C(G,\Omega) \to \Omega$ defined by $f \mapsto f(z)$ is continuous; since $\mathcal F^-$ is compact its image is compact in $\Omega$ and (a) follows. ... Note that $C(G, \Omega)$ is the set of all continuous functions from $G$ to $\Omega \in \mathbb C$ with the usual metric $\rho$ defined in 1.4, page 143. $\mathcal F^-$ denotes the closure of $\mathcal F$ . A set is normal iff its closure is compact. QUESTION Let $\psi_z$ the map defined by the author in the proof. Since $\psi_z$ is continuous we know that $$\psi_z(\mathcal F^-) \subseteq \left(\psi_z(\mathcal F)\right)^-=\{f(z) : f\in \mathcal F\}^-.\tag{1}\label{1}$$ So, even if continuity and compactness of $\mathcal F^-$ imply compactness of $\psi_z(\mathcal F^-)$ , we cannot conclude immediately that the closure of $\{f(z) : f\in \mathcal F\}$ is compact. Is my way of reasoning correct? WHAT I HAVE TRIED I tried to get to the conclusion with some additional thoughts. I am also asking you if these are correct or erroneous/unnecessary . First note that $\psi_z$ is surjective. Let $w \in \left(\psi_z(\mathcal F)\right)^-$ , so that there exists a sequence $(z_k) \to w$ , with $z_k \in \mathcal F$ . By definition of $\psi_z$ and by surjectivity, therefore, there exists functions $f_k$ and $f$ such that $f_k(z) = z_k$ and $f(z) = w$ , so that now we have $$(f_k(z)) \to (f(z)).$$ Fix $\delta >0$ . For large enough $k$ we have $$|f_k(z)-f(z)| < \frac{\delta}3.$$ By continuity of $f_k$ and $f$ , there exists a compact set $K$ such that $$|f_k(\zeta)-f_k(z)| < \frac{\delta}3$$ and $$|f(\zeta)-f(z)| < \frac{\delta}3,$$ for all $\zeta$ in $K$ , so that $$|f_k(\zeta)-f(\zeta)| \leq |f_k(\zeta)-f_k(z)| + |f_k(z)-f(z)|+|f(\zeta)-f(z)|<\delta.$$ Since $\delta$ was arbitrary, we can choose $\delta$ , and thus $k$ , so that (Lemma 1.7, page 144) $$\rho(f_k,f) < \varepsilon,$$ for any $\varepsilon >0$ . This shows that $f \in \mathcal F^-$ , and since $f(z) = w$ , we have that $$\psi_z(\mathcal F^-) \supseteq \left(\psi_z(\mathcal F)\right)^-.$$ Together with \eqref{1}, this leads to our conclusion, i.e. that $\psi_z(\mathcal F^-) =\left(\psi_z(\mathcal F)\right)^-$ and that this set is compact.","['complex-analysis', 'general-topology', 'analysis', 'compactness']"
4559005,"Question on the integrability of $f''$, where $f$ is two times differentiable, verifying some conditions","Let $f : [0,\infty) \rightarrow [0,\infty)$ be a two times differentiable function verifying, \begin{align}
\exists M>0, \forall x \geq 0, f(x) \leq M \quad (1) \\
\exists \alpha>0, \forall x \geq 0,  f''(x) \geq \alpha^2 f(x) \quad (2) 
\end{align} It is asked at some point of an exercise to show that $ \lim\limits_{x \rightarrow +\infty} f(x) =0$ . At first glance, after showing that $f' \leq 0$ using the convexity and boundedness of $f$ , I wrote that, as $f$ is non-increasing and $0$ is a lower bound, then $\ell :=\lim\limits_{x \rightarrow +\infty} f(x)$ exists. By contradiction if $\ell>0$ then we have $f \geq \ell >0$ , and using $(2)$ yields $$f'' \geq \alpha^2 \ell >0.$$ That is where I wanted to integrate and use the fundamental theorem of analysis, but I realized I had not much information on the regularity of $f''$ . If I knew for example that $f$ was of class $\mathcal{C}^2$ , then I could say that, $$\forall x \geq 0, f'(x) \geq f'(0) + \alpha^2 \ell x \underset{x \rightarrow +\infty}{\longrightarrow} +\infty$$ giving us a contradiction. I was therefore wondering whether the initial hypothesis on the regularity of $f$ needed to be enhanced to show that $\lim\limits_{x \rightarrow +\infty} f(x) = 0$ or not. Thus, I would like to know if there is another argument which can help proving the statement, or if it is false (which might be harder). I know that we cannot apply the fundamental theorem of analysis to any differentiable function : Volterra's function provides a counter-example. Any insights on this question would be greatly appreciated. Feel also free to ask for more details if needed.","['integration', 'ordinary-differential-equations', 'real-analysis']"
4559013,Prove $P(\sum_nX_n\text{ converges})=P(\sum_nX_n\mathbb{I}_{\{|X_n|\leq c_n\}}\text{ converges})$,"$\{X_n\}$ is a sequence of random variables, $\{c_n\}$ is a sequence of positive numbers, $\sum\limits_{n}P(|X_n|> c_n)<\infty$ ,prove $P(\sum_nX_n\text{ converges})=P(\sum_nX_n\mathbb{I}_{\{|X_n|\leq c_n\}}\text{ converges})$ Here are my attempts.From $\sum\limits_{n}P(|X_n|> c_n)<\infty$ we get $\lim_nP(|X_n|> c_n)=0$ ,also $P(\sum_nX_n\mathbb{I}_{\{|X_n|\leq c_n\}}\text{ converges})=P(\lim\limits_n\sum\limits_{k\geq n}X_k\mathbb{I}_{\{|X_k|\leq c_k\}}\text{ converges})$ ,and when $n$ is large enough, $P(|X_k|>c_k)=0$ ,and the proposition seems right,but I don't know how to show that in a rigorous way.","['sequences-and-series', 'convergence-divergence', 'probability-theory', 'probability', 'random-variables']"
4559089,Can you spot any mistake in what I did (problem in elementary probability),"I am trying to solve the following problem. Let $(X_n \,:\,n\geq 1)$ be a sequence of IID random variable uniformly distributed on $[0,1]$ . Let $M_n:=max\{X_1,...,X_n\}$ . Show that the random variable $n(1-M_n)$ converges in distribution and find the limit distribution. The solution is straightforward: Noting that $\mathbb{P}(M_n\leq x)=x^n$ , one gets $\mathbb{P}(n(1-M_n)\leq x)=1-(1-x/n)^n\to 1-e^{-x}$ . Hence, by Portmanteau's theorem, the limit distribution is an exponential of parameter $1$ . However, I would like to get the same result using characteristic functions, i.e. I would like to show that $\phi_{n(1-M_n)}(t)\to \frac{1}{1-it}$ (where $\frac{1}{1-it}$ is the characteristic function of an exponential of parameter $1$ ). Integrating by parts I find $\phi_{M_n}(t)=\int_0^1 e^{itx} nx^{n-1}dx=(\frac{n}{it}-\frac{n(n-1)}{(it)^2}+...-\frac{n!}{(-it)^n})e^{it}+\frac{n!}{(-it)^n}$ . Then $\phi_{n(1-M_n)}(t)=e^{int}\phi_{M_n}(-nt)=-\frac{n}{int}-\frac{n(n-1)}{(int)^2}+...-\frac{n!}{(int)^n}+\frac{n!}{(int)^n}e^{int}$ . However, I am not sure whether this is right since $|\frac{n!}{(int)^n}e^{int}|\to0$ and the first part of the series does not seem to converge to $\frac{1}{1-it}$ . Can you spot any mistake? Thank you.","['probability-distributions', 'probability-theory', 'probability', 'sequences-and-series']"
4559097,"Generalising ""the mean of the means is the mean""","It's an interesting exercise to prove that the ""mean of the means is the mean"", by which I mean given a finite list $X=[x_1,\dots,x_n]$ we can define the arithmetic mean $$\mu(X)=\frac{1}{n}\sum_{i=1}^nx_i, \tag{1}$$ and we consider the list of means  of non-empty sublists of $X$ , writing $S_\mu(X)=[\mu(A)\mid A\subseteq X, A\neq\emptyset]$ (Note that $|S_\mu(X)| =2^n-1$ since both $X$ and $S_\mu(X)$ are allowed to have repeated elements). Then we have $$\mu(X) = \mu(S_\mu(X)). \tag{2}$$ Let's call property (2) sample invariance , as we can think of $S_\mu(X)$ as the list of all possible samples from $X$ . Once one has proved (2), it's simple to generalise this statement to show the sample invariance of function means: given an invertible function $f:\mathbb{R}\to\mathbb{R}$ we define the $f$ -mean by 'conguation' of $\mu$ (where $f$ is considered to act element-wise on $X$ ): $$\bar{f}(X) = f^{-1}\left(\frac{1}{n}\sum_{i=1}^nf(x_i)\right) = (f^{-1}\circ\mu\circ f)(X).$$ One can show that $\bar{f}(X) = \bar{f}(S_{\bar{f}}(X))$ . For expedient choices of $f$ this shows that the geometric and harmonic means are also sample invariant, along with countless others. However, there are other functions that we might expect to be sample invariant, perhaps the median or the mode? Does this characterise all sample invariant functions? I suspect not - there are clearly other functions such as $\max$ and $\min$ that are sample invariant but it's not immediately clear that they appear as $f$ -means. How would one prove this? Can we classify all sample invariant functions, or perhaps just provide equivalent conditions for sample invariance?","['average', 'central-tendency', 'statistics', 'means']"
4559108,Solve $f(x)+f(1+\frac{1}{x})=1+x$,"The title means Does there exists any function $f:\Bbb R\to\Bbb R$ s.t. it satisfies the following equation? $$f(x) + f(1+\frac1x)=1+x\quad\text{for all } x\not=0.$$ This question is made by my friend. He does not restrict the function with any further condition, though adding some condition may be necessary. I found some similar questions, e.g. $f(x)+f(1-\frac1x)=1+x$ . For this example, I could replace $x$ by $1-\frac1x$ and $\frac1{1-x}$ , then just solving the system of linear equations. Unfortunately, these operations can't be used for present question.","['functional-equations', 'algebra-precalculus', 'functions']"
4559206,Sum of continuous functions is continuous with multiple variables,"Background I have seen proofs showing that the sums of two continuous functions $f_1, g_1 :$ $\mathbb{R} \rightarrow \mathbb{R} $ are continuous, and I have also seen this result for functions $f_2, g_2 :$ $\mathbb{R}^n \rightarrow \mathbb{R}$ . However, I have not seen a generalisation of the claim for when we take the functions $f_3 : \mathbb{R}^k \rightarrow \mathbb{R}^n$ and $g_3 : \mathbb{R}^q \rightarrow \mathbb{R}^n $ . If both of these functions are continuous, then this should imply that the sum is also continuous, however, I am struggling to prove the claim. For clarity, we define the sum to be the function $h(x,y) := f_3(x) + g_3(y)$ , where we want to prove that this is continuous given that $f_3, g_3$ are continuous. Attempt I have shown that the projections of $ \mathbb{R}^k $ and $ \mathbb{R}^q $ $p_1(x,y) := x \space \space$ and $\space \space p_2(x,y) := y$ are both continuous. But am unsure of how to proceed from here. My initial thoughts are that an epsilon - delta argument should be able to work for two specified values of delta which are valid for showing that the individual functions are continuous (by our assumption). I’m assuming we can then use these to construct a new values of delta that will hold for the sum. However, I haven’t made much progress here as of yet. If anyone could help me construct a proof, or point me towards a reference, I would be grateful.","['continuity', 'functions', 'analysis', 'real-analysis']"
4559233,What is the formula for winding and unwinding a spool with changing radius due to the strap thickness being wound.,"I have a servo motor and I'm trying to come up with a formula that relates the angle of the motor to the length of a strap that is wound on it. Since the radius at <360 degrees is the radius of the motor shaft (r1) and at 360<theta<720 the radius is now r1 + Ct (cable thickness) and after 720 degrees, the new radius r2 = r1 + 2*Ct. Consider the thickness to be uniform. So the circumference is growing every 360 degrees when a new layer of cable is wound. Any ideas? The cable goes only on top of its previous layer, it does not move to the side. The ""spool"" is cylindrical ie. servo motor shaft. I want to treat each layer as a concentric circle, not a spiral. Thanks! rough work of what I've tried","['functions', 'geometry', 'mathematical-physics']"
4559236,Can de Morgan's laws be applied to probability?,"I know and understand what de Morgan's laws are in the context of Boolean algebra and set theory, but can they be applied to probability? For example, when calculating the probability of multiple things not happening, would it be reasonable to say, given de Morgan's laws, that: $$ \prod_{n=1}^{k}\left(1-P\left(n\right)\right)=1-\sum_{n=1}^{k}\left(P\left(n\right)\right) $$ With the first representing (for lack of a better phrase) ¬a ∧ ¬b, and the second representing ¬(a ∨ b).","['boolean-algebra', 'probability']"
4559276,Find the real root of the almost symmetric polynomial $x^7+7x^5+14x^3+7x-1$,"Find the real root of following almost symmetric polynomial by radicals $$p(x)=x^7+7x^5+14x^3+7x-1$$ Here are my attempts. The coefficients of $p(x)$ are : $1,7,14,7,-1$ . I wanted to try possible factorizations. But Wolfram Alpha can not factorise this polynomial. This can be a reason of our case, so factorisation over $\Bbb R$ seems impossible. The Rational root theorem also failed. Again I tried $$\begin{align}
x^7+7x^5+14x^3+7x-1
&=x^7+7x^5+7x^3+7x^3+7x-1 \\
&=x^7+7x^3(x^2+1)+7x(x^2+1)-1 \\
&=x^7+7x(x^2+1)^2-1
\end{align}$$ But, this manipulation also didn't work.","['galois-theory', 'algebra-precalculus', 'irreducible-polynomials', 'polynomials']"
4559291,What class of matrices permutes matrix entries?,"Let's start with the $2$ by $ 2$ case: We're given a matrix A $$\begin{pmatrix}
a & b \\
c & d.
\end{pmatrix}$$ What class of matrices ""rotates"" or ""permutes"" the entries upon left-multiplication, such that we obtain, for example, $$BA = \\
B\begin{pmatrix}
a & b \\
c & d
\end{pmatrix} = \begin{pmatrix}
b & c \\
d & a
\end{pmatrix}?
$$ As another example, let's consider a $3$ by $3$ \begin{pmatrix}
a & b & c \\
d & e & f \\
g & h & i \\
\end{pmatrix} . What matrix $B$ would permute these entries, such as, for instance, into \begin{pmatrix}
d & e & a \\
c & h & i \\
f & g & b \\
\end{pmatrix} . Does there exist a general class of matrices that permutes the entries of an $n$ by $n$ matrix to any desired result?",['matrices']
4559323,Sheafification without using stalks?,"Most definitions of sheafification either use stalks or (co)limits. Can we avoid that, at least in some nice cases? Say $\mathcal{F}$ is a sheaf of abelian groups on a topological space $X$ , thought of as functions with certain properties. For $U\subseteq X$ open, call $(f_i,U_i)_{i\in I}$ a generalized function if $(U_i)_{i\in I}$ is an open cover of $U$ , $f_i\in \mathcal{F}(U_i)$ and they are compatible, i.e., $f_i$ and $f_j$ agree on $U_i\cap U_j$ . Identify two generalized functions $(f_i,U_i)_{i\in I}$ and $(g_j,V_j)_{j\in J}$ if they cover the same open set $U$ , and there is another open cover $(W_k)_k$ of $U$ such that $f_i$ agree with $g_j$ on $U_i\cap V_k\cap W_k$ for all $i,j,k$ ; I think this is equivalent to the existence of $(W_k)_k$ a common refinement of $(U_i)_i$ and $(V_j)_j$ , and $f_i,g_j$ agreeing on $W_k$ . Can we define the sheafification $\mathcal{F}^\sharp$ by letting $\mathcal{F}^\sharp(U)$ be all the equivalence classes of generalized functions on $U$ ? Or if this disagree with the standard definition is there a simple counterexample? Is it even a sheaf? Edit: It seems it is standard that this works for separated presheaf, namely if two function agree on an open cover then they agree, but it doesn't work in general (although it does make the presheaf separate, and thus applying twice would work). Here is the argument. Use $[(f_i,U_i)_{i\in I}]$ to denoted the equivalence class of $(f_i,U_i)_{i\in I}$ . If $W\subseteq U$ is open, the restriction of $[(f_i,U_i)_{i\in I}]$ to $W$ is $[(f_i|_{U_i\cap W},U_i\cap W)_{i\in I}]$ . For simplicity say we have two classes [ $(f_i,U_i)_{i\in I}]$ and $[(g_j,V_j)_{j\in J}]$ that are compatible, that is the restrictions of $(f_i,U_i)_{i\in I}$ and $(g_j,V_j)_{j\in J}$ to $U\cap V$ are equivalent. I claim that $(f_i,U_i)_{i\in I}\cup(g_j,V_j)_{j\in J}$ is a generalized function, which means $f_i$ and $g_j$ agree on $U_i\cap V_j$ . What we know is that $f_i$ and $g_j$ agree on $U_i\cap V_j\cap W_k$ for some open cover $(W_k)_k$ of $U\cap V$ . To deduce that $f_i$ and $g_j$ agree on $U_i\cap V_j$ we do want the presheaf we started with to be separated.","['algebraic-geometry', 'abstract-algebra', 'sheaf-theory']"
4559343,Properties of Moment Functions,"I was watching this video here https://www.youtube.com/watch?v=ZLJqjiI0aHM/ From 5:00 - 5:20, the author of this video states that the "" variance of higher order moments tends to increase"". However, no real explanation in the video is provided as to why this is. I tried to search online but I could not find any explanation behind this. For instance, how can I be mathematically certain that the variance of higher order moments does in fact increase? Is there some mathematical proof for this? Thanks! Note: The only reason (non mathematical) I could think of is that since the Variance is ""additive"" - perhaps higher order moments have more terms and functions with more terms will likely have larger variances ... but I am not sure if this is the case.","['statistics', 'probability']"
4559388,Double integral whose answer doesn't make any sense,"SOLVED: READ BOTTOM How do I calculate the following double integral? I attempted multiple times and got the same answer (both by integrating with respect to y first and by integrating with respect to x, using IBP). I keep getting $\ln({\frac{3}{\sqrt{5}}}$ ); the answer is given as $\ln({\frac{7\sqrt{6}}{12})}$ . What am I doing wrong? The original question is $$ \iint_R \frac{x}{(2+xy)^2}dA, R={(x,y): 0 \le x \le 5, 1 \le y \le 2}$$ My steps: $$ \int_{x = 0}^5 \int_{y = 1}^2 \frac{x}{(2+xy)^2} dydx $$ Solving first integral: $$ x \int_{y = 1}^2 (2+xy)^{-2} dy$$ $$ u = (2+xy) $$ $$ \frac{du}{dy} = x $$ $$ dy = \frac{du}{x} $$ $$ \int_{y = 1}^2 u^{-2} du$$ $$ = -[u^{-1}] \Big|_{y=1}^2 $$ $$ = -[(2+xy)^{-1}] \Big|_{y=1}^2 $$ $$ = - (2+2x)^{-1} + (2+x)^{-1} $$ Now evaluate the x-integral: $$ \int_{x=0}^5 [(2+x)^{-1} - (2+2x)^{-1}] dx $$ $$ = \int_{x=0}^5 (2+x)^{-1} dx - \int_{x=0}^5 (2+2x)^{-1} dx $$ $$ = \ln{|2+x|} \Big|_{x=0}^4 - \frac{\ln{|2+2x|}}{2} \Big|_{x=0}^4 $$ $$ = [\ln{6} - \ln{2}] - [\frac{\ln{10}}{2} - \frac{\ln{2}}{2}] $$ $$ = \ln{3} - \frac{\ln{\sqrt{10}}}{\ln{\sqrt{2}}} $$ $$ = \ln{\frac{3}{\frac{\sqrt{10}}{\sqrt{2}}}} $$ $$ = \ln{\frac{3{\sqrt{2}}}{\sqrt{10}}} $$ $$ = \ln{\frac{3}{\sqrt{5}}} $$ And this is how I arrived at $ \ln({\frac{3}{\sqrt{5}})} $ ! Let me know if I made any mistakes. Thank you! :) Just realized I somehow swapped the bounds from $\int_{x=0}^5$ to $\int_{x=0}^4$ halfway through solving. Oops","['integration', 'multivariable-calculus', 'definite-integrals']"
4559448,Density of $\mathbb{Z}[\sqrt2]$,"Show that between any two numbers in $\mathbb{Z[\sqrt2]}$ , there is another number in $\mathbb{Z[\sqrt2]}$ . { $(-1+\sqrt2)^1,(-1+\sqrt2)^2,...,(-1+\sqrt2)^n$ } represents an infinite sequence of numbers in $\mathbb{Z[\sqrt2]}$ that approaches 0 from the right. Therefore, all elements of this sequence lie within the interval, (0, $\sqrt2$ ] which shows that there exists a number in $\mathbb{Z[\sqrt2]}$ between 0 and $\sqrt2$ . I have been able to extend this logice to show that there exists a number in $\mathbb{Z[\sqrt2]}$ that lies between 1 and $\sqrt2$ . Can the logic between extend to apply to the general case?",['abstract-algebra']
4559466,Intuition behind Hall's theorem.,"I have chosen combinatorics as my elective in my $3^{\text{rd}}$ semester.There is a theorem in combinatorics known as Hall's marriage problem.Let us first define some terminologies: Defn. A system of distinct representatives for a sequence of sets $S_1,S_2,...,S_m$ (not necessarily distinct) is a sequence of distinct elements $x_1,...,x_m$ such that $x_i\in S_i$ for all $1\leq i\leq m$ . Now the statement of Hall's theorem is as follows: Th. The sets $S_1,S_2,...,S_m$ have a sequence of distinct representatives if and only if for every $I\subset \{1,2,...,m\}$ , $|\bigcup\limits_{i\in I} S_i|\geq |I|$ . But I find this theorem hard to remeber because I don't understand what it really means.I have searched on internet but there it is something a bit different and explained using graph theory which I have not studied yet.So,I am looking for intuition behind this theorem.Can someone explain with a suitable example?","['intuition', 'combinatorics', 'discrete-mathematics']"
4559483,"Under the which condition, factorisation of $a_1^n+a_2^n+\cdots+a_n^n-na_1a_2a_3...a_n ?$ is possible?","Under the which condition, factorisation of the polynomial $$a_1^n+a_2^n+\cdots+a_n^n-na_1a_2a_3...a_n ?$$ is possible? I know possible cases: $$a^2+b^2-2ab=(a-b)^2$$ and $$a^3+b^3+c^3-3abc=(a+b+c)(a^2+b^2+c^2-ab-bc-ac)$$ There are $2$ things I'm interested in here.  For which number $n$ is factorization possible?  For which number $n$ it is not possible? What I'm interested in here is general factorization  possible?  If not, is there any proof? Based on the comments, I understand that general factorization is not possible.However, it is still unknown whether factorization is possible when $n > 3$ .","['irreducible-polynomials', 'number-theory', 'factoring', 'polynomials', 'algebra-precalculus']"
4559503,"Let $ f(x)=\frac{1+\cos(2\pi x)}2$ and $f^n=f\circ f^{n-1}$. Is it true that for almost every $x$, $\lim_{n \to \infty} f^n(x)=1$?","Let $\displaystyle f(x)=\frac{1+\cos(2\pi x)}2$ for $x\in\mathbb R$ , and $f^n=\underbrace{ f \circ \cdots \circ f}_{n}$ . Is it true that for Lebesgue almost every $x$ , $\displaystyle\lim_{n \to \infty} f^n(x)=1$ ? I'm more inclined to believe that the answer is ""yes"". This is the Problem $5$ of $2021$ Miklós Schweitzer . Recently, a related question reminds me of this problem. After spending some time on it, I found that it is a hard problem, as always as Miklós Schweitzer does. Almost every problem from that competition is very difficult for me. First of all, for a fixed $x_0\in\mathbb R$ , if $f^n(x_0)$ is convergent, then its limit $\ell$ must be a fixed point of $f$ . Since $f(x)=\cos^2(\pi x)\in[0,1]$ , we must have $\ell\in[0,1]$ . Let's find the fixed points of $f$ . Let $g(x)=f(x)-x$ for $x\in[0,1]$ , then we need to find the zeroes of $g$ . Since $g'(x)=-\pi\sin(2\pi x)-1$ , $g'$ has two zeroes $\eta_1,\eta_2\in[0,1]$ with $1/2<\eta_1<3/4$ , $3/4<\eta_2<1$ , and $\sin(2\pi\eta_1)=\sin(2\pi\eta_2)=-1/\pi$ . Hence, $g$ is decreasing in $[0, \eta_1)$ , then increasing in $(\eta_1, \eta_2)$ , and then decreasing in $(\eta_2,1]$ . Note that $g(1/2)=-1/2<0, g(1)=0$ , we know that $g(\eta_1)<0$ and $g(\eta_2)>0$ . Therefore, we can find three zeroes of $g$ , named by $\ell_1$ , $\ell_2$ and $\ell$ with $\ell_1\in(0,1/2)$ , $\ell_2\in(\eta_1, \eta_2)$ and $\ell=1$ . We can find the locations the fixed points $\ell_1, \ell_2$ more accurately. Indeed, since $$g\left(\frac14\right)=\cos^2\left(\frac\pi4\right)-\frac14=\frac12-\frac14>0,\qquad g\left(\frac13\right)=\cos^2\left(\frac\pi3\right)-\frac13=\frac14-\frac13<0,$$ we have $\ell_1\in(1/4,1/3)$ , hence $$f'(\ell_1)=-\pi\sin(2\pi\ell_1)<-\pi\sin\left(\frac{2\pi}3\right)=-\frac{\sqrt 3}2\pi<-1.$$ Also, $$g\left(\frac56\right)=\cos^2\left(\frac56\pi\right)-\frac56=\frac34-\frac56<0,\qquad g\left(\frac{11}{12}\right)=\frac{1+\cos\left(\frac{11}6\pi\right)}2-\frac{11}{12}=\frac{\sqrt3-2}4>0,$$ we have $\ell_2\in(5/6,11/12)$ , hence $$f'(\ell_2)=-\pi\sin(2\pi\ell_2)>-\pi\sin\left(\frac{11\pi}6\right)=\frac{1}2\pi>1.$$ The following are not rigorous. Therefore, locally, near $\ell_1$ , $f$ behaves like $-A(x-\ell_1)$ with $A>1$ . Consider the map $f_1: x\mapsto -Ax$ , then $f_1^n(x)$ converges if and only if $x=0$ . This indicates that, for fixed $x_0$ , if the sequence $\{f^n(x_0)\}$ doesn't reach $\ell_1$ , it will not converge to $\ell_1$ ; a similar analysis on $\ell_2$ indicates that $\{f^n(x_0)\}$ will not converge to $\ell_2$ if it doesn't touch $\ell_2$ ; hence, if $\{f^n(x_0)\}$ converges without touching $\ell_1, \ell_2$ , then the limit should must be $\ell=1$ . I think the ideas in this paragraph can be written down rigorously, although I don't know how to write a clean one. Another question I've not had any ideas: What if $\{f^n(x_0)\}$ diverges? To finish the problem, even if we write down a proof about the above paragraph, we also need to prove that for a.e. $x$ , the sequence $\{f^n(x)\}$ is convergent. Any help would be appreciated!","['contest-math', 'measure-theory', 'analysis', 'real-analysis', 'dynamical-systems']"
4559519,Evaluate $\int_0^{\pi/2}\ln{(\sqrt{\cos{x}+1}+\sqrt{\cos{x}})}dx$,"I'm trying to evaluate $I=\int_0^{\pi/2}\ln{(\sqrt{\cos{x}+1}+\sqrt{\cos{x}})}dx$ . My attempt: I have tried using the facts that $I=\int_0^{\pi/2}\ln{(\sqrt{\sin{x}+1}+\sqrt{\sin{x}})}dx$ , and $I=-\int_0^{\pi/2}\ln{(\sqrt{\cos{x}+1}-\sqrt{\cos{x}})}dx$ and then adding these various forms together. I have also tried finding a substitution that will convert $I$ into an integral of an odd function , as well as integration by parts. All without success. Context: This is part of my attempt to solve the following problem, which I made up. The diagram shows a quarter-circle of radius $2$ and line segments of lengths $l_0, l_1, l_2, ..., l_n$ with equal angles between them. Two of the line segments are tangent to the quarter-circle at the ends of the quarter-circle. Show that $\lim\limits_{n\to\infty}\prod\limits_{k=0}^n l_k =2$ . This amounts to showing that $I=\frac{\pi}{2}\ln{2}$ .","['integration', 'calculus', 'definite-integrals']"
4559538,Rate of change of a function,"Consider the surface $$
(S): z=f(x, y)=\dfrac{1}{x^2+y^2}
$$ and the point $P_0\left(1, 1, \dfrac12 \right)$ . Find the rate of change of $f$ at the point $P_0$ in the direction of the vector $\vec{u}=\hat{\imath}+\hat{\jmath}$ . I start solving in a straightforward proof, first we have $$
\|\vec{u}\|=\sqrt{1+1}=\sqrt{2} \implies \vec{v}=\dfrac{1}{\sqrt{2}}\hat{\imath}+\dfrac{1}{\sqrt{2}}\hat{\jmath}
$$ and $$
\vec{\nabla f}=\left(\dfrac{-2x}{(x^2+y^2)^2}, \dfrac{-2y}{(x^2+y^2)^2}\right) \implies  \vec{\nabla f}(P_0)=-\dfrac{1}{2}\hat{\imath}-\dfrac{1}{2}\hat{\jmath}.
$$ Consequently, $$
D_{\vec{v}}f(P_0)=\vec{\nabla f}(P_0) \cdot \vec{v}=-\dfrac{\sqrt{2}}{2}
$$ But my question is, if this answer is correct, why on introduce a point of 3 dimensions? when I find the directional derivative, do I need to introduce a new function $F(x,y,z)=f(x,y)-z$ ? Is my answer correct? Next, how one can write the equation of the plane parallel to (S) at $P_0$ ?","['multivariable-calculus', 'surfaces', 'vector-analysis']"
4559540,"Equation of the parabola $y=x^2$ sliding normally on the ellipse $x^2/6^2+y^2/3^2=1$, and opening outwards. How to avoid the use of $\text{sgn}(x)$?","By “sliding normally” I mean that the vertex of the parabola is a point $P$ that circulates around the ellipse, and that the axis of the parabola is normal to the tangent (to the ellipse) at $P$ . https://www.desmos.com/calculator/vewhhesehw Let a point $P= (f(a), g(a))=( 6 \cos(a), 3 \sin(a))$ (with $a$ a varying angle)  move on the ellipse $ x^2/6 + y^2 / 3^2 = 1$ . My goal is to find the cartesian equation of a  parabola (1) similar to $y=x^2$ but (2) the vertex of which is located at $P$ and (3) the axis of which is normal to the tangent (to the ellipse) passing through $P$ , and finally (4) that opens outwards. Saying that the axis is normal to the tangent passing through $P$ means that the inclination of the parabola is the angle $ R = \arctan \frac {g'(a)} {f'(a)} = \arctan \left(-\frac {3\cos(a)} {6\sin(a)} \right)$ . Using the “rotation about any point” formula, I first arrived at $$X(x,y)= (x- 6 \cos(a)) \cos(R) + ( y - 3\sin(a))\sin(R)$$ $$Y(x,y)= ( y- 3\sin(a))\cos(R) - ( x - 6 \cos(a)) \sin(R)$$ which yields, for the parabola, $$Y(x,y) = (X(x,y))^2 \space\space \Bigg(  \space \iff Y(x,y) - X(x,y)^2 =0 \Bigg)$$ The problem is that, with the above formula, the parabola opens inwards when $P$ is below the $X$ axis. The only way I found to fix this problem was $\DeclareMathOperator{\sgn}{sgn}$ (1) to put $\sgn(a)$ next to $Y(x,y)$ (2) and to limit the range of $a$ from $-\pi$ to $+\pi$ , which gives: $$Y(x,y)\sgn(a) = { (X(x,y))^2} \space\space \Bigg(  \space \iff  Y(x,y)\sgn(a) - X(x,y)^2 =0 \Bigg)$$ Can you find a way to solve the above problem without using these palliatives ?","['analytic-geometry', 'geometry', 'algebra-precalculus', 'transformation', 'rotations']"
4559553,"Mutually independent vectors with small, integer coefficients","Consider a family $\cal V$ of $n$ vectors $v_1,\ldots,v_n$ in ${\mathbb N}^3$ (here ${\mathbb N}$ denotes the set of positive integers, excluding $0$ ). Say that $\cal V$ is strongly independent if any three vectors $v_i,v_j,v_k$ in $\cal V$ with $i<j<k$ are linearly independent. Also, define the size of $\cal V$ to be $\max_{v\in {\cal V}} ||v||_{\infty}$ , where $||(x,y,z)||_{\infty}=\max(|x|,|y|,|z|)$ . Using a ""Van der Monde"" construction with $v_k=(1,k,k^2)$ , one achieves a strongly independent family with size $n^2$ . Question. For every $n\geq 3$ , is there a strongly independent family with size at most $n$ ? The answer is yes for $n\leq 9$ , by considering the family $v_k=(1,k,a_k)$ where $a_k$ is the $k$ -th element in $1, 2, 1, 2, 4, 3, 4, 3, 8$ .","['arithmetic', 'linear-algebra', 'examples-counterexamples']"
4559589,Stationary solutions of the Cauchy PDE problem,"Consider $$\partial_{t}u -y\partial_{x}u +x\partial_{y}u = 0$$ in $t>0, (x,y) \in \mathbb{R}^{2}$ , with initial condition $$ u(0,x,y) =
 u_{0}(x,y) $$ for $(x,y) \in \mathbb{R}^{2}$ . Find the stationary solutions (no dependence on $t$ ) and discuss their physical intepretation. My attempt: Suppose a solution $u$ is stationary. Then $\partial_{t}u = 0$ , so the PDE becomes $$-y\partial_{x}u +x\partial_{y}u = 0.$$ We can solve by using the method of characteristics which gives us the equations: \begin{align}
\frac{dx}{ds} &= -y, \\
\frac{dy}{ds} &= x, \\
\frac{du}{ds} &= 0.
\end{align} From here I am unsure. The first two equations can be solved to give $x=A\cos(s) +B\sin(s)$ and $y=C\cos(s) +D\sin(s)$ , and we also get that $u(s) = \rm constant$ . How can we proceed?","['continuity', 'characteristics', 'ordinary-differential-equations', 'partial-differential-equations']"
4559605,"How to determine whether the following subsets are open, closed, or dense in the Zariski topology?","Let $k=\mathbb{C}$ and decide for each of the following subsets $S \subset \mathbb{A}_{\mathbb{C}}^2$ whether they are closed, open or dense in the Zariski topology: (a) $S=\{(t, s t) \mid s, t \in \mathbb{C}\}$ (b) $S=\{(s, t) \mid s, t \in \mathbb{Q}\}$ (c) $S=\left\{\left(t, 2^t\right) \mid t \in \mathbb{Z}\right\}$ So the only way I know how to determine whether something is open or closed is whether the set is a zero set of some ideal or set of polynomials. But looking at these three sets, I don't think it is easy to show whether they are the zero sets or complement of some zero sets. How can I proceed? I have just studied mapping between algebraic sets, so maybe it is possible to find some isomorphisms between different sets, but I have read somewhere that they don't preserve topological properties.","['zariski-topology', 'algebraic-geometry', 'abstract-algebra']"
4559663,"Showing $\big\{(x,y)\in\mathbb{R}^n$ $\times$ $\mathbb{R}$ $\mid $ $\min ( f,g ) < y$ $< \max ( f, g)\big\}$ is open in $\mathbb{R}^{n+1}$","In a course on Multivariable Calculus, I came across the following problem, and am looking for some guidance on how to approach it. Question Consider continuous functions $f,g$ in $\mathbb{R}^n$ and define the set $$A =\big\{(x,y)\in\mathbb{R}^n\times\mathbb{R}\mid \min \big( f(x),g(x) \big) < y < \max \big( f(x), g(x)\big)\big\}$$ Prove that $A$ is an open subset of $\mathbb{R}^{n+1}.$ Thoughts I believe that a good first step here would be to try to prove the continuity of $\min\{f,g\}$ and $\max\{f,g\}$ separately. However, I haven’t made progress on this simplified exercise. Perhaps this suggested simplification doesn't end up being an avenue that is worth pursuing, although at the moment this is my only idea on how to make a start with this. I would be grateful for any help in solving either the problem itself or with the simplified problems (which should allow me to try to progress with the main problem).","['proof-writing', 'analysis', 'real-analysis', 'continuity', 'multivariable-calculus']"
4559788,Give a generating function for the number of ways for her to choose outfits. EXPLAIN how you model the problem.,"Mrs X must choose outfits for each day of the coming week, that is, she must decide on an outfit for Monday,
Tuesday, and so on (7 days). She has 20 out ts to choose from and she does not want to wear any outfit
more than twice. Give a generating function for the number of ways for her to choose outfits. EXPLAIN how you model the
problem. I have attempted the question and I have attached my working out as an image. I know I should get the coefficient of x^20 but I don't think I will get to that power with my answer. Is my solution correct? picture of my solution My solution is x^7(1+x/2)^7","['discrete-mathematics', 'probability', 'generating-functions']"
4559842,Change of variables for an ODE,"Question: Use the substitution $u = 2 \sqrt{x}$ to show that the equation: $$x^2\frac{d^2y}{dx^2}+x\frac{dy}{dx}-(1-x)y=0$$ becomes: $$u^2\frac{d^2y}{du^2}+u\frac{dy}{du}-(u^2-u)y = 0$$ My attempt: $$x^2\left[\frac{d^2y}{du^2}\left(\frac{du}{dx} \right)^2+\frac{dy}{du}\left(\frac{d^2u}{dx^2}\right)\right]+x\frac{dy}{du}\frac{du}{dx}-(1-x)y=0$$ simplifying with $$\frac{du}{dx}=\frac{1}{\sqrt{x}},\ \frac{d^2u}{dx^2}=-\frac{1}{2\sqrt{x}^3}$$ yielding: $$x\frac{d^2y}{du^2}+\frac{1}{2}\sqrt{x}\frac{dy}{du}-(1-x)y = 0$$ now using $\sqrt{x}=\frac{1}{2}u$ , $x = \frac{1}{4}u^2$ and multiplying across by $4$ : $$\implies u^2\frac{d^2y}{du^2}+u\frac{dy}{du}-(4-u^2)y= 0$$ Which disagrees with the proposed solution. Have I made an error somewhere here so far or is there a further manipulation possible? Attempting the substitution in reverse I find: $$ x^2\frac{d^2y}{dx^2}+x\frac{dy}{dx}-(x-\frac{1}{2}\sqrt{x})y=0$$ in disagreement with the starting equation.","['multivariable-calculus', 'change-of-variable', 'bessel-functions', 'partial-differential-equations']"
4559846,find the 2002th term of a binary sequence,"Source: 2002 UofT Math Competition, problem 9. A sequence whose entries are 0 and 1 has the property that, if each 0 is replaced by 01 and each 1 by 001, the sequence remains unchanged. What is the 2002th term of the sequence? Let $S_1 = 0$ and for $k\ge 2$ let $S_k$ be obtained from $S_{k-1}$ by replacing every 0 in $S_{k-1}$ with $01$ and every $1$ with $001$ . The crucial claim is that $S_k = S_{k-1}S_{k-2}S_{k-1}$ for all $k\ge 3$ . I'm not sure if this can be shown using some form of induction. The claim clearly justifies that the given sequence is well-defined, since $S_{k-1}$ is a prefix of $S_k$ . From the claim, the answer is easy: The length of the $S_k$ 's for $1\leq k\leq 10$ are $1,2,5,12,29,70,169,408,985,2378.$ Let $S_{k,i}$ denote the ith symbol of $S_k$ where $i$ is at most the length of $S_k$ . Then $S_{10,2002} = S_{9, 2002-985-408} = S_{9,609} = S_{8,609-408-169} = S_{8,32} = S_{7,32}=S_{6,32} = S_{4,32-29} = S_{3,3} = 0.$","['contest-math', 'combinatorics-on-words', 'combinatorics', 'discrete-mathematics']"
4559930,How to show that $\frac{n!}{n^{\frac{n}{2}}}$ diverges as $n \to \infty$? [duplicate],"This question already has answers here : Limits to infinity of a factorial function: $\lim_{n\to\infty}\frac{n!}{n^{n/2}}$ (6 answers) Closed 1 year ago . The exact question is, is it true or not that $$
n! = O(n^{\frac{n}{2}})
$$ I tried a few values of $n$ and guessed that it does not (this is obviously not very proper mathematics). I applied the definition, i.e. I want to show that there does not exist an $N$ such that for all $n > N$ it is the case that $$
n! \leqq c \cdot n^{\frac{n}{2}}
$$ I had two ideas as to how to proceed, carry out a proof by contradiction (i.e. assuming that this $N$ does exist, but I wasn't able to derive an absurdity). I tried something along the lines of Assume there exists an $N$ and a $c \in \mathbb{R}$ such that for all $n > N$ it is the case that $$
n! \leqq c\cdot n^{\frac{n}{2}}
$$ Then it is also the case that because $$
n! \geqq \left(\frac{n}{2}\right)^{\frac{n}{2}}
$$ Therefore, $$
\left(\frac{n}{2}\right)^{\frac{n}{2}} \leqq n! \leqq c \cdot n^{\frac{n}{2}}
$$ But this does not help, because $\left(\frac{1}{2}\right)^{\frac{n}{2}}$ just tends to 0. I thought that I could try to use a bigger lower bound, i.e. something in the form $(an)^{\frac{n}{2}}$ where $a > 1$ , but I'm not sure how to prove this exists. try to pair up items on the left and right-hand sides and show that each item on the left-hand side (e.g. for showing that $n! = O(n^n)$ as there are the same number of terms on the left and right hand side it is possible to cancel them out. Any help is greatly appreciated!","['limits', 'radicals', 'factorial', 'asymptotics']"
4559942,How to evaluate $\sum_{n=1}^\infty \frac{n^5}{e^{2\pi n}-1}$?,I recently found the following result on Twitter . $$\sum_{n=1}^\infty \frac{n^5}{e^{2\pi n}-1}=\frac{1}{504}$$ I know that $\int_0^\infty \frac{x^5}{e^{2 \pi x}-1} dx = \frac{5!}{(2\pi)^6}\zeta(6)=\frac{1}{504}$ How to show that the sum is also equal to the same number? Can this be generalized to a class of functions where the sum (over positive integers) and the definite integral (from 0 to $\infty$ ) are the same?,['sequences-and-series']
4560011,Tips for classifying $ (\mathbb{Z} / 2^n \mathbb{Z})^\times$ [duplicate],"This question already has answers here : Multiplicative group modulo $2^n$ (3 answers) Closed 1 year ago . To finish off a problem earlier, I had to classify the group $G =(\mathbb{Z} / 16 \mathbb{Z})^\times$ . I said $G$ is abelian with order $\phi(16) = 8$ , and found three order-2 elements (namely $7^2 = 9^2 = 15^2 = 1$ ), thus it's $C_2 \times C_2 \times C_2$ (using the Structure Theorem, since it can't be $C_2 \times C_4$ or $C_8$ ). EDIT: Actually, this means it's $ C_2 \times C_4 $ , my bad. I could only really do this since we have a small modulus like $2^4$ , but I'm interested as to whether there a general approach for $2^n$ ? Of course for odd primes $p \ge 3$ , we can use the theory of primitive roots, but this doesn't apply for powers of 2. It seems like this is a fairly important problem, since it arises quite naturally when decomposing $(\mathbb{Z}/m\mathbb{Z})^\times$ for general $m$ .","['group-theory', 'abelian-groups']"
4560097,"How to show that $X =\{(x,0)\mid x \le 0 \text{ and }x \in\Bbb R\}$ is closed?","I am comfortable with the intuition of closed sets, however, I am struggling to formalise these ideas. Consider the following question: Consider the set $$X = \{ (x,0) | x \le 0 \text{ and } x \in \Bbb R \} $$ Show that the set $X$ is closed. Formally, to do this, we must show that if we take some arbitrary convergent sequence of points in $X$ , then the limit must also be an element of $X$ . This set seems like a fairly simplistic set to apply this to, but I am not entirely comfortable with constructing these types of arguments, and I'm unclear how to show this generally for some arbitrary sequence. I would be grateful for any guidance or references.","['proof-writing', 'analysis', 'real-analysis', 'multivariable-calculus', 'general-topology']"
4560103,Travelling Salesman exercise : discrepancy between solutions,"I am solving an exercise from Mathematics High Level for the IB Diploma (the Discrete Math book). One of the exercises in graph theory is the following: We want to solve the traveling salesman problem for the graph $K$ shown here. (a) Use the nearest neighbour algorithm starting at vertex $B$ to find an upper bound for the traveling salesman problem. (b) By removing vertex $B$ find a lower bound. (c) Write down an inequality  satisfied  by $L$ , the length of the shortest Hamiltonian cycle in $K$ . The mark scheme follows: (a) $114$ (b) $89$ (c) $89 \leq L\leq 114$ What I got as an answer was very different from the book's answers. For question a , I got $16 + 19 + 17 + 19 + 18 + 22 = 111$ . In exercise b , shouldn't the authors specify after deleting such vertex what other vertex to start? And assuming that I would start with vertex A, I would get as a lower bound $73 + 16 + 17 = 106$ (corresponding to the minimum spanning tree plus the two smallest weights connecting B to the tree). Can someone verify my answers or tell me whether I'm thinking this wrong? Any help is highly appreciated.","['graph-theory', 'discrete-mathematics', 'discrete-optimization']"
4560128,Find all functions satisfying $f\left((1-xy)f(x)\right)+x^2f(y)=f(x)$,"To find all functions $f:\mathbb{R} \to \mathbb{R}$ satisfying $$f((1-x y) f(x))+x^2 f(y)=f(x) \label1\tag1$$ When $x=y=1$ we have $f(0)=0$ . Case I:
If $f(x)$ is a constant function, say $f(x)=\lambda$ , we have $$\lambda+x^2\lambda=\lambda$$ which makes sense only when $\lambda=0$ . Thus the only constant function satisfying the functional equation is $$f(x)=0$$ Case II:
If $f(x)$ is a non constant function, we have for $y=0$ in \eqref{1} $$f(f(x))=f(x)$$ Any help from here?","['functional-equations', 'calculus', 'functions', 'algebra-precalculus']"
