question_id,title,body,tags
1245559,What's the difference between finite and finitely generated algebras,"I didn't understand the difference between the two definitions: I thought the definition of $B[a_1,\ldots,a_n]$ is exactly the one in the item (b), i.e., $B[a_1,\ldots,a_n]=Ba_1+\ldots+Ba_n$. I need help Thanks","['abstract-algebra', 'definition']"
1245568,The finite-dimensional distributions of a centered Gaussian process are uniquely determined by the covariance function,"Let $I\subseteq\mathbb{R}$ and $X=(X_t)_{t\in I}$ be a centered Gaussian process, i.e.
 - $E[X_t]=0$ for all $t\ge 0$
 - $X$ is real-valued and for all $n\in\mathbb{N}$ and $t_1,\ldots,t_n\ge 0$ we've got $$(X_{t_1},\ldots,X_{t_n})\;\;\;\text{is }n\text{-dimensionally normal distributed}$$ How can we prove, that the finite-dimensional distributions of $X$ are uniquely described by the covariance function $$\Gamma(s,t):=\operatorname{Cov}[X_s,X_t]\;\;\;\text{for }s,t\in I\;?$$","['probability-theory', 'probability', 'stochastic-processes', 'measure-theory']"
1245591,Is the norm operator between normed spaces ever induced from an inner product?,"Assume $(V,\| \|_V),(W,\| \|_W)$ are both finite dimensional normed spaces.
We have the induced operator norm on $Hom(V,W)$. When does it occur that this norm is actually induced from some inner product? As observed by a comment of user225318, If $dimV=dimW=1$ then the answer can clearly be positive. It can be seen that in the case where $dimV=1   (V=\mathbb{R})$ and the norm on $W$ is induced by an inner product, the answer is positive. So let us require $dimV>1$ or that $\| \|_W$ is not induced by an inner product. To state this more clearly, I would be happy to find a complete characterization, i.e necessary & sufficient conditions on the dimensions of $V,W$ and on their respective norms that are equivalent to the operator norm being induced by an inner product.","['linear-algebra', 'inner-products', 'normed-spaces']"
1245606,Prove that $g(x):=|f(x)|$ is differentiable iff $f'(a)=0$,"Suppose that $f(a)=0$. Prove that $g(x):=|f(x)|$ is differentiable iff $f'(a)=0$ Not sure how to go about this at all. The limit definition that I am working with is $$
g'(a)=\lim_{x \rightarrow a} \frac{g(x)-g(a)}{x-a}=
\lim_{x \rightarrow a} \frac{|f(x)|-|f(a)|}{x-a}=
\lim_{x \rightarrow a} \frac{|f(x)|}{x-a}=\text{something}
$$ On the other hands, if $f'(a)=0$ $$
f'(a)=\lim_{x \rightarrow a} \frac{f(x)-f(a)}{x-a}=
\lim_{x \rightarrow a} \frac{f(x)}{x-a}=0
\quad\text{iff}\quad
\lim_{x\rightarrow a} f(x)=0
$$ Then, $g'(a)=\lim\limits_{x \rightarrow a} \dfrac{|f(x)|}{x-a}=0$. My only question is how to do the other direction.","['absolute-value', 'limits', 'real-analysis', 'derivatives']"
1245616,Fermat's last theorem and $\mathbb{Z}[\xi]$,"I heard that one can prove special cases of FLT by using unique factorization in $\mathbb{Z}[\xi]$ (whenever this is possible), where $\xi$ is a primitive $n$-th root of unity. How can one do this in detail, and is it known for which natural $n$ $\mathbb{Z}[\xi]$ is not a UFD? I mean assuming that $n$ is such that $\mathbb{Z}[\xi]$, how does one proceed? A reference is good enough.","['ring-theory', 'number-theory', 'reference-request']"
1245622,What is the difference between a vector and its transpose?,"I have seen a definition of orthogonality between two vectors something like this: $$<\vec{u}, \vec{v}> = u^T \cdot v = 0$$ I am wondering what is the purpose of using a transpose of a vector (in this case and in general). I have also seen this in the formula to find the projection of a vector over another, but I have used just the normal vector instead of its transpose and everything seems to work.","['vectors', 'linear-algebra']"
1245647,Explicit Galois Action for $X^3 - X -1$,"I have always been frustrated with how indirect discussions of Galois Theory are in Algebra textbooks.   Even in fine treatments such as Miles Reid . Are there any good examples where we can draw the Galois action explicitly as substitutions?? One possibility are the cyclotomic polynomials : $$ x^4 + x^3 + x^2 + x + 1 = 0 $$ Then for any $1 \leq a < 5$ we can make subsition $x \mapsto x^a$ and this polynomial is fixed. This gives me some intuition that the Galois action should behave something like the exponential operator and we often write $x \mapsto x^\sigma$ for $\sigma \in \mathrm{Gal}[p(x)]$ Iterating square roots is another examples such as $x = \sqrt{2} + \sqrt{3}$ and we should recover and explicit $\mathbb{Z}/2\mathbb{Z} \times \mathbb{Z}/2\mathbb{Z}$ action.  Even here I am not sure I can get the analogy to the exponential function. What can we do for the example $f(x) = x^3 - x - 1$ which I took from Keith Conrad [ 1 ] The Galois group is $S_3$.  How can we get the conjugates $x$? Have two equations for the roots $x + a+b = 0$ and $xab = 1$ which I can re-write: $$ a + b = - x \hspace{0.25in}\text{and}\hspace{0.25in} ab = \frac{1}{x} = x^2 - 1$$ Then the quadratic equation is $(z-a)(z-b) = z^2 + xz + ( x^2 - 1) = 0$ which is reducible in $\mathbb{Q}(x)$. With this satisfactory result, which explicity substitutions achieve the transpositions $S_3 = \langle (12), (13)\rangle$? It's not totally clear what I mean by ""explicit"".  The crossed out section seems to reproduce Theorem 2.6 in this @KCd's note except I forget to adjoin the square root of the discriminant. Since $[\mathbb{Q}(x):\mathbb{Q}] = 3$, I would like to compute the Galois action as a matrix in the basis $\{1, x, x^2\}$. ¿How to we write the element that performs (hopefully, I wrote the roots of $x^3 - x - 1$ correctly):
$$ x \mapsto x \hspace{0.25in}\text{and}\hspace{0.25in} z = \frac{-x + \sqrt{4-3x^2}}{2}\mapsto \frac{-x - \sqrt{4-3x^2}}{2}$$
and similar permutations? It seems that $4 - 3 x^2$ should be a perfect square in $\mathbb{Q}(x)$ since I have defined it as the splitting field. Since $x^3 - x - 1$ splits in the 6th degree extension $\mathbb{Q}(x, \sqrt{-23})$ how to compute the action of the Galois group $S_3$ on the basis $\{ 1, x, x^2 \} \times \{ 1, \sqrt{-23}\}$ as a $6 \times 6$ matrix with entries in $\mathbb{Q}$?","['number-theory', 'galois-theory']"
1245651,Eigenvalues and Spectrum,"In algebra, I learned that if $\lambda$ is an eigenvalue of a linear operator $T$ , I can have \begin{equation}
Tx = \lambda x
\tag{1}
\end{equation} for some $x\neq 0$ , which is equivalent to $\lambda I-T$ not being invertible. In functional analysis, it is said that if $\lambda$ is an element of a spectrum of the linear operator $T$ , then $\lambda I - T$ is not invertible. However, my Professor never mentioned $(1)$ . Is the definition/concept in functional analysis the same as $(1)$ in linear algebra? Can I use $(1)$ in functional analysis too? Does it depend on which spaces we are in? For example, suppose $\lambda$ is in the spectrum of $T$ , where $T$ is a linear operator on $E$ , a Banach space. I want to show $\lambda^n$ is in the spectrum of $T^n$ . Would this problem is equivalent to showing if $\lambda$ is an eigenvalue of a linear operator $T$ , then $\lambda^n$ is an eigenvalue of $T^n$ ? Thank you.","['eigenvalues-eigenvectors', 'spectral-theory', 'linear-algebra', 'functional-analysis']"
1245666,Do you need true randomness to beat the two-envelope game?,"A well-known (non-)paradox in probability involves a two-envelope game played between two players, $A$ and $B$: $A$ selects two distinct (real) numbers, $x$ and $y$, writing each one down on a card and sealing each card in an envelope, then presenting the two envelopes to $B$. $B$ chooses one of the envelopes and looks at the card inside.  They then guess whether the number on the card they've chosen is the larger or smaller of the two numbers. The 'paradox' here is that regardless of $A$'s scheme for choosing numbers — and even if $A$ knows $B$'s strategy in advance — there's a strategy for $B$ that will achieve a better-than-even success rate in the long run: choose an envelope at random, then map the number in it onto the interval $(0,1)$ using some (arbitrary) monotonic function.  Choose a random deviate $U\in(0,1)$, and then guess 'higher' or 'lower' according to whether (the mapping of) the number looked at is higher or lower than the generated random deviate. I'll skip the analysis of this strategy here (see Do better than chance or Who discovered this number-guessing paradox? for more details), but note that it explicitly relies on having a source of random deviates. My question is whether this is necessary for $B$ to have the advantage.  More specifically, consider the following variant of the game: B chooses computable functions $f():\mathbb{N}\mapsto\{0,1\}$ and $g():\mathbb{N}\mapsto\mathbb{Q}\cap(0,1)$.  Note that $A$ knows nothing about these functions, other than that they are computable. For each integer $n$, in turn: $A$ selects two distinct real numbers $x,y\in(0,1)$, writing each down on a card and presenting them in sealed envelopes.  (I'm restricting the numbers here to eliminate the mathematically-moot mapping step.) $B$ computes $f(n)$; if $f(n)=0$ then $B$ chooses $x$, and if $f(n)=1$ then $B$ chooses $y$.  Call $B$'s chosen number $z$. $B$ computes $g(n)$; if $g(n)\leq z$ then $B$ guesses 'higher', otherwise $B$ guesses 'lower'. Note that this is essentially $B$ following the strategy in the usual version of the game, except that $B$ is following a computable strategy rather than a purely randomized one. Can $A$ win this game in the long run? Since $A$ doesn't know what computable strategy $B$ is following, they'll clearly have to take some dovetailing approach; instinctively it feels like randomness is inherent in $B$'s ability to win with the usual strategy and that $A$, with the knowledge that $B$'s strategy is actually computable, should be able to 'game the system' and win.  Unfortunately, I can't see a clear proof here (and I wouldn't be entirely shocked to learn that I'm wrong).  Is anything known about this problem? EDIT: to clarify, I should point out that unlike $B$, the strategy that $A$ follows does not have to be computable; $A$ can, for instance, take advantage of an oracle that enumerates the total computable functions.  For example, this ensures that $A$ can guarantee they'll win at least once: enumerate all possible pairs $\langle f_n(), g_n()\rangle$ of recursive functions and in round $i$ behave as though $B$'s selections for the round will be $f_i(i)$ and $g_i(i)$ (by choosing values that will win given that these are $B$'s selections).  Also, I suspect $f()$ is actually superfluous and that we can ask the analogous question for the strategy where $B$ always guesses $x$, but if the presence or absence of $f()$ does matter then it'd be interesting to know that too.","['computability', 'probability', 'random', 'game-theory']"
1245696,Set Theory/Intuitive Set Theory,"Let $A_1, A_2, ..., A_i$ be sets, and define $S_{x}$ to be $A_{1}\cup A_{2}\cup ... \cup A_{x}$ for $x=1, 2, 3, ..., r$.  Show that 
$\alpha=\{A_{1}, (A_{2}-S_{1}), ..., (A_{r}-S_{r-1})\}$
is a disjoint collection of sets and that
$S_{x}=A_{1}\cup(A_{2}-S_{1})\cup ... \cup (A_{x}-S_{x-1})$.
When is $\alpha$ a partition of $S_{x}$? I have been trying to understand intuitive set theory and while doing some exercises, i came across this question in the section 'Algebra of Sets' and the author hadn't explained this section well.
I appreciate any hints given or clues.
Thank you.",['elementary-set-theory']
1245699,“$\sigma$-uniform continuity”,"Let $X$ be an arbitrary metric space and $f:X\to\mathbb R$ a bounded continuous function. Is it possible to choose a countable sequence $(A_n)_{n\in\mathbb N}$ of (preferably open or closed) subsets of $X$ such that $X=\bigcup_{n\in\mathbb N} A_n$ and $f$ is uniformly continuous on $A_n$ for each $n\in\mathbb N$? That is, is every bounded continuous real-valued function on a metric space “$\sigma$-uniformly continuous?” I would prefer an answer without further assumptions ( e.g. , compactness, $\sigma$-compactness, local compactness, separability, completeness, total boundedness, etc .). Thank you.","['metric-spaces', 'uniform-continuity', 'general-topology']"
1245705,"Are there general guidelines to make ""assumptions"" when proving limits?","I am studying the definition of the limit using Paul's Online Notes When proving the following limit (Example 3) $\lim\limits_{x \to 2} x^2+x-11 = 9$ At one point he assumes: $|x+5| < K$ He also asumes: $|x-4| < 1$ Because one is a nice number to work with. I have read multiple explanations and every author seems to make their own ""assumptions"" when dealing with limit proofs. So my question is: Why the assumptions they make are right? Lets say I have to prove the following: $\lim\limits_{x \to 4} x = 2$ While the above is impossible, what stops me from making my own ""assumptions"" like 2=4 to prove the limit? Thanks in advance.","['proof-verification', 'limits']"
1245754,Cauchy-Riemann equations in polar form. [duplicate],"This question already has answers here : Proof of Cauchy Riemann Equations in Polar Coordinates (6 answers) Closed 2 years ago . Show that in polar coordinates, the Cauchy-Riemann equations take the form
  $\dfrac{\partial u}{\partial r} = \dfrac{1}r \dfrac{\partial v}{\partial \theta}$ and $\dfrac{1}r \dfrac{\partial u}{\partial \theta} = −\dfrac{\partial v}{\partial r}$. Use these equations to show that the logarithm function defined by
  $\log z = \log r + i\theta$ where $z=re^{i\theta}$ with $-\pi<\theta<\pi$ is holomorphic in the region $r > 0$ and $-\pi<\theta<\pi$. What I have so far: Cauchy-Riemann Equations: Let $f(z)$ = $u(x, y)$ +$iv(x, y)$
be a function on an open domain with continuous partial derivatives
in the underlying real variables. Then f is differentiable at $z = x+iy$ if and only if $\frac{∂u}{∂ x}(x, y)$ = $\frac{∂ v}{∂ y}(x, y)$ and $\frac{∂u}{∂ y}(x, y)$ = −$\frac{∂ v}{∂ x}(x, y)$. So we have $f'(z)= \frac{∂u}{∂ x}(z) +i \frac{∂ v}{∂ x}(z)$.
Let $f(z)$ = $f(re^{iθ})$= $u(r,θ)$ +$iv(r,θ)$ be a function on an open domain that does not contain zero and with continuous partial derivatives in the underlying real variables. Then f is differentiable at $z$ = $re^{iθ}$ if and only if $r \frac{∂u}{∂r}=\frac{∂ v}{∂θ}$ and $\frac{∂u}{∂θ}$ = $−r \frac{∂v}{∂ r}$. Sorry, if this is not very good. I just decided to start learning complex analysis today...","['complex-analysis', 'polar-coordinates']"
1245756,An analytic function on the disk that sends the boundary into the boundary sends the interior onto the interior,"Consider $f$ analytic on $B(0; 1) = \{z \in \mathbb{C}\ |\ |z| < 1\}$ and continuous in $D(0; 1) = \{z \in \mathbb{C}\ |\ |z| \leq 1\}$ such that $f(S^1) \subset S^1$. I must show that $f(B(0; 1)) = B(0; 1)$. I've shown that $f$ must have the form $f(z) = \omega \prod_{j = 1}^{n} \frac{z - a_j}{1 - \overline{a_j}z}$ where $a_1, \ldots, a_n$ are the zeros of $f$ inside $B(0; 1)$ and $\omega \in S^1$. In particular, we can see that $f$ admits analytic extension to an open neighborhood of $D(0; 1)$. Furthermore, I know that each term in the product for $f$ is an automorphism of $D(0; 1)$. However, I still can't seem to conclude that $f(B(0; 1)) = B(0; 1)$. How might I proceed?","['mobius-transformation', 'complex-analysis']"
1245770,Proving $f$ cannot be onto,"If $f$ maps finite sets $A$ to $B$ and $n(A) < n(B)$, prove that $f$ cannot be onto. Proof by contradiction: If $f: A→B$ and $n(A) < n(B)$, $f$ is onto. Since, by definition of a function, $a∈A$ cannot be mapped to more than one value $b∈B$. This means that $f$ is not onto since $n(A)$ cannot be less than $n(B)$, which violates the contradiction. To me, this explanation seems simple yet complete enough to constitute a proof to the theorem. But the given solution to this problem is as follows: If we assume that $f$ is onto, then the range is $f(A) = B$ so $n(f(A)) = n(B)$. Knowing that $n(A) ≥ n(f(A))$, yields the expression: $n(A) ≥ n(f(A)) = n(B)$. However this is a contradiction to the fact that $n(A) < n(B)$, so $f$ is not onto. Are both proofs to this theorem deemed accurate? Should I always, when encountering these types of problems, try to prove the theorem based on the number of elements in the set versus constructing an argument by definition? Thanks so much!","['proof-writing', 'discrete-mathematics', 'functions']"
1245773,How to interpret p-value in this problem.,"The following is the question in particular, I got this question wrong. However nothing I run across explains why it is wrong. I answered C because with a p-value of 0.087 we don't have an ""unusual"" enough outcome to reject the null though the correct terminology would be ""extreme"". Thank you for your time. Use the following information to answer the question. A janitor at a large office building believes that his supply of light bulbs has too many defective bulbs. The janitor's null hypothesis is that the supply of light bulbs has a defect rate of p = 0.07 (the light bulb manufacturer's stated defect rate). Suppose he does a hypothesis test with a significance level of 0.05. Symbolically, the null and alternative hypothesis are as follows: H0: p = 0.07 and The janitor calculates a p-value for the hypothesis test of approximately 0.087. Choose the correct interpretation for the p-value. A) The p-value tells us that the true population rate of defective light bulbs is approximately 0.087. B) None of these C) The p-value tells us that if the defect rate is 0.07, then the probability that the janitor will have 27 defective light bulbs out of 300 is approximately 0.087. At a significance level of 0.05, this would not be an unusual outcome. D) The p-value tells us that the probability of concluding that the defect rate is equal to 0.07, when in fact it is greater than 0.07, is approximately 0.087.",['statistics']
1245774,"Show that $f(W_t)-\frac{1}{2} \int_0^t f''(W_s) \, ds$ is a martingale without using Itô's formula","I'm learning the basics about Brownian motion (I know nothing about stochastic calculus), and I've shown that if $W(t)$ is a standard Brownian motion, then $W(t)^2-t$ is a martingale. Now I'm trying to show that 
$$
f(W(t))-\frac{1}{2}\int_0^t f''(W(s))ds
$$
is also a martingale, where $f\in C^2$ and compactly supported. I've started by showing that the transition density satisfies the diffusion equation. Any guidance or hints would be appreciated!","['probability-theory', 'brownian-motion', 'martingales', 'stochastic-processes']"
1245787,SDE Modeling: Ito vs. Stratonovich,"In my SDE class last semester there were some hints that sometimes an SDE model makes more sense in the Ito sense, and sometimes in the Stratonovich sense. This was explained very briefly and vaguely. The idea was that SDEs containing white noise are really the limit of models which contain noise with a positive correlation time scale $\tau$, as $\tau \to 0^+$. Yet the model may also have some other limit as well. For instance, we may be interested in the motion of particles of small mass $m$ under the influence of noise with small $\tau$. My professor hinted that in one regime, the limit is an Ito SDE, while in another it is a Stratonovich SDE. As I recall we get the Ito SDE in particular when the correlation time scale is much smaller than the inertial time scale. Or more mathematically, by taking the limit in $\tau$ before the limit in $m$. Can anyone clarify this, or point to references which do so? Note that I am not asking about the theoretical advantages of Ito vs. Stratonovich integrals, I have already understood that part. I am asking about modeling advantages.","['probability-theory', 'stochastic-calculus', 'soft-question', 'stochastic-processes']"
1245791,Inverse of an ordered pair?,"Let $f: A \to B$ be a bijective function where $A = [0, 2\pi)$ and $B$ is the unit circle. Find the inverse of $f(\theta) = (\cos\theta, \sin\theta)$. I don't understand what it means to take the inverse of an ordered pair. I see that the function is mapping points from the interval $[0, 2\pi)$ to coordinates on the unit circle in $\mathbb{R^2}$ plane, so we have to take those coordinates back into the interval $[0, 2\pi)$. I would guess this involves some two-variable function $f(x,y)$ with inverse functions $\cos^{-1}x$ and $\sin^{-1}x$ since we want the value of the inverse function to be a real number in the interval $[0, 2\pi)$.","['circles', 'trigonometry', 'inverse', 'functions']"
1245801,Non-integrable function that has an antiderivative,"The wikipedia article on antiderivatives states: Non-continuous functions can have antiderivatives. [...] In some cases, the antiderivatives of such pathological functions may be found by Riemann integration, while in other cases these
  functions are not Riemann integrable. I'm looking for an example of such a function - a bounded function $f : [a, b] \to [m, M]$ that has an antiderivative $F$ such that $F' = f$ on its domain, while $f$ is not Riemann-integrable.",['integration']
1245830,Series for $\sin(z) / \sin(\pi z)$,"${\sin(z) \over \sin(\pi z)} = 1/\pi + {z \over \pi} \sum_{n \in {\bf Z} \setminus \{0\}} {(-1)^n \sin(n) \over n(z-n)}$ First I apply  Mittag-Leffler's theorem, to see that the RHS is a mereomorphic function with the appropriate residues and orders for each pole, thus the LHS and RHS differ by an analytic function. How can I then show that this analytic function is identically 0?  One idea is to use Liouville's theorem to show it it bounded; I do not see how to do that. We do not have periodicity on either side.","['sequences-and-series', 'partial-fractions', 'complex-analysis']"
1245843,"If $Y$ is a dense second countable subspace of a regular space $X$, then $X$ is second countable.","Problem: Let $X$ be a regular space. If $Y$ is a subspace that is dense and second countable (with respect to the subspace topology), then $X$ is second countable. I have this problem and I'm having trouble figuring it out. I have a hint, it says: consider B a countable basis for Y and show that $B' = \{\text{int}(\overline{U}) \, : \, U \in B\}$ is a countable basis for X, where $\overline{U}$ stands for the closure in $X$. Now, it's obvious that $B'$ is countable. The problem is to show that $B'$ is a basis for $X$. Let me show what I tried. Let $p \in X$ a point and $V$ a neighborhood of $p$. We know that $Y$ is dense, so $V \cap Y$ is a nonempty open set in $Y$. Because $B$ is a basis, there is a $U_V$ such that $U_V \subseteq V\cap Y \Rightarrow U_V \subseteq V$. I know that if I show $\overline{U_V} \subseteq V$ and $p \in \text{int}(\overline{U_V})$ then we're done: $p \in \text{int}(\overline{U_V}) \subseteq V$ and, therefore, $B'$ is a basis. I'm having trouble to prove both things in the above paragraph. I can't see where to use regularity or the closure of $U_V$ in $X$. Any help would be appreciated. Any solution not using the hint is welcome too. Thanks in advance. (P.S.: Sorry for my grammar mistakes. Englsh isn't my mother's tongue.)",['general-topology']
1245866,How to prove this argument valid?,"I was just wondering if some helpful person wouldnt mind helping me with this discrete maths question that has had be stuck for about a day now. The argument is: p or q
q implies ~p
q implies r
conclusion: r I cant for the life of me figure out how to prove this. Thanks heaps for any help you can give. Thanks
Corey",['discrete-mathematics']
1245875,Determining the sequence that yields a balanced search tree in the form of a recurrence / sequence,"Let's say I have a sequence of (distinct) monotonically increasing numbers S . I'll want to add them sequentially to a Binary Search Tree (BST) but as the numbers are monotonically increasing the resulting tree will be unbalanced (the tree will be nothing but a linked-list). To correct this problem, I can devise another sequence S' containing all the elements of S but in a different order. For instance, if $S = { 1..9 }$, then $S' = { 5, 2, 7, 1, 3, 6, 8, 4, 9 }$ would yield a balanced tree were I to add all these integers to an initially empty BST. The formula I followed was informally $a_{ij} = i + \frac{j-i+1}{2}$ It's easy for me to do this on paper or even to implement a function in a programming language that making use of a queue can yield S' from S (for an arbitrary value of n ) but I'm quite lost on how to do this making use of either sequences or recurrences. How would I go about ""formalizing"" this mathematically, without resorting to pseudo-code?","['computer-science', 'recurrence-relations', 'sequences-and-series', 'discrete-mathematics']"
1245882,Volume between sphere and cylinder with different centers,"I am working on a tumor model and need to calculate the volume enclosed between the sphere given by $$(x-d)^2+y^2+z^2=r^2$$
and the cylinder given by
$$x^2+y^2=R^2.$$ I have worked it out by using surfaces of revolution but this is tedious and required numerous cases. When I try to use cylindrical coordinates I end up the integral
$$\int^{2\pi}_0 \int^R_0 \int^{\sqrt{r^2-R^2+d^2-2dR\cos (\theta )}}_{-\sqrt{r^2-R^2+d^2-2dR\cos (\theta )}} R~dz~dR~d\theta$$
which won't compute. I suspect either I am making an error in my transformation to cylindrical coordinates or a different method is needed.",['multivariable-calculus']
1245886,Is the following a fundamental set?,"$$y''' - 4y' = 0$$ Is $\{e^{2x}, e^{-2x}\}$  a fundamental set?? If I'm doing the wronskian correctly it is but the answer key shows that it is NOT a fundamental set.",['ordinary-differential-equations']
1245926,Show that $\sup f_n = \sup g_n$ almost everywhere.,"Suppose that we have a sequence of (Lebesuge) measurable functions $f_n,g_n$ from $\mathbb{R}$ to $\mathbb{R}$. Suppose also that for each $n$, $f_n=g_n$ almost everywhere. I want to prove that $\sup f_n=\sup g_n$ almost everywhere, given above conditions. That is to say, I need to show that the set of points $x$ for which the two sequences $f_n(x)$, $g_n(x)$ have different supremum is null. However I only have very vague ideas about this problem: I tried to find a set which contains the set $\{ \sup f_n\neq \sup g_n\}$ which we can easily identify as a null set, and then by completeness of $\mathbb{R}$ (as a measure space) we are done. But I always get stuck at some point due to lack of further ideas/ or maybe because my approach wasn't a correct one. Any helps appreciated","['real-analysis', 'measure-theory']"
1245939,Standardized test problem: Packing spheres into a rectangular prism,"So, this was a problem in the new standardized high school tests California has started using(CAASP). These new tests are completely done on the computer, and feature what they call Computer Adaptive Testing. Basically, the test ""adapts"" to how the student is doing, and offers harder or easier problems based on it. However, this problem appeared as the second to last question, and was extremely tricky. I'm curious as to how one is supposed to do this problem. How many spheres with diameter $3$ can one fit into a rectangular prism with dimensions $24.1$, $30.1$, and $16.9$? If anybody needs any clarifications, I'll try to be fairly prompt. Thanks","['euclidean-geometry', 'geometry']"
1245940,Prove that $\Big|\frac{f(z)-f(w)}{f(z)-\overline{f(w)}}\Big|\le \Big|\frac{z-w}{z-\overline w}\Big|$,"Let $\mathbb{H}$ denote the upper half plane of $\mathbb{C}$, i.e. 
\begin{equation*}
\mathbb{H}=\{z \in \mathbb{C}: Im(z)> 0\}
\end{equation*}
Suppose $f:\mathbb{H}\to\mathbb{H}$ is analytic. Prove that $\Big|\frac{f(z)-f(w)}{f(z)-\overline{f(w)}}\Big|\le \Big|\frac{z-w}{z-\overline w}\Big|$, for all $z,w\in\mathbb{H}$. If $f\in Aut(\mathbb{H})$, then the equality in the above formula  holds for any $z,w\in\mathbb{H}$. If the equality in the above formula holds for any one pair $z_0\ne w_0\in\mathbb{H}$, then $f\in Aut(\mathbb{H})$. Hint: Recall that for any $z_0\in\mathbb{H}$, $h_{z_0}(z)=\frac{z-z_0}{z-\overline{z_0}}\in Iso (\mathbb{H},\mathbb{D})$. Fix $w\in\mathbb{H}$ and apply Schwarz lemma to $g=h_{f(w)}\circ f\circ h_{w}^{-1}$. Proof (attempt) Following the hint, I let $h_w(z)=\frac{z-w}{z-\overline{w}}$ and solved for its inverse, which is $h_w^{-1}(z)=\frac{\overline{w}z-w}{z-1}$. Then we have
\begin{align*}
g(z)&=\left(h_{f(w)}\circ f\circ h_{w}^{-1}\right)(z) \\
&=\frac{f\left(\frac{\overline{w}z-w}{z-1}\right)-f(w)}{f\left(\frac{\overline{w}z-w}{z-1}\right)-\overline{f(w)}}
\end{align*}
which looks like quite a mess. However, I see that
\begin{align*}
g(0)&=\frac{f\left(\frac{0-w}{0-1}\right)-f(w)}{f\left(\frac{0-w}{0-1}\right)-\overline{f(w)}} \\
&=\frac{f\left(w\right)-f(w)}{f\left(w\right)-\overline{f(w)}} \\
&=0
\end{align*}
which is a requirement of the Schwarz lemma , which, applying to $g$, says that
\begin{align*}
|g(z)|\le |z|
\end{align*}
i.e.
\begin{align*}
\left|\left(h_{f(w)}\circ f\circ h_{w}^{-1}\right)(z)\right| \le |z|
\end{align*}
or
\begin{align*}
\left|\frac{f\left(\frac{\overline{w}z-w}{z-1}\right)-f(w)}{f\left(\frac{\overline{w}z-w}{z-1}\right)-\overline{f(w)}}\right| \le |z|
\end{align*}
but I don't see the inequality I'm looking for. Any help with this one? Thank you very much!","['group-isomorphism', 'complex-analysis', 'conformal-geometry', 'inequality']"
1245946,Proof $\text{Si}(n) $ is convergent,"I am trying to prove that the sequence formed by the Si function, $\text{Si}(n) = \int_0^n \frac{\sin(u)}{u} \mathrm{d}u$, is convergent as $n\rightarrow \infty$. The only twist is the lower bound of the integral is 1 instead of zero. At first I looked at this as a sort of alternating series, and the sequence formed was that of the partial sums. I attempted to change the upper bound of the integral so that I was looking at integer multiples of $\pi$. I was then going to bound each ""bump"" with a rectangle with base pi, and height equal to the function value at the middle each interval. Shortly in I realized that the ""bumps"" were not symmetric about their centers, so I did not have a way to calculate the height of the function at these midpoints. I cannot think of another way to attack this problem. Any help appreciated.","['sequences-and-series', 'cauchy-sequences', 'real-analysis']"
1245952,Zeilberger's potential proof of Fermat's last theorem.,"Doron Zeilberger suggested the following potential proof for Fermat's last theorem: Let's define: $$W(n,a,b,c) \equiv (a^n + b^n - c^n)^2$$ I am almost sure that there exists a
  polynomial, discoverable by computer, with positive coefficients such
  that: $$W(n,a,b,c) = P\left(W(n,a-1,b,c), W(n,a,b-1,c), \ldots W(n -1,a,b,c), \ldots\right)$$ for $n>3$. Since $W > 0$ for $n= 3$, and $abc>0$ FLT
  would follow. $$$$ Could someone explain how / why exactly ""FLT would follow""? Moreover, why wouldn't one have to find a separate polynomial for each (unbound) $n$?","['number-theory', 'ultrafinitism']"
1245964,How to express the oscillator equation $y'' + 3y'+2y=\cos(t)$ as a first order system?,"Can someone please help me express this oscillator equation $y'' + 3y'+ 2y= \cos{(t)}$ as a first order system? I also need to plot an approximate solution curve for the initial condition $x_0 = 5, y_0=1$. I was asked to create a Maple Worksheet and graph multiple initial conditions but I am having a hard time starting on this problem. I tried to solve this by replacing $y' = V$.
So that $V' + 3V + 2y = \cos(t)$ $v' = -3V - 2y + \cos(t)$ But I cant get two differential equations. Thanks for your help.",['ordinary-differential-equations']
1245969,Series Proof $\sum_{k=1}^n (1/k) > \ln(n+1)$,"Prove that $\sum_{k=1}^n (1/k) > \ln(n+1)$. I have been trying to do this for some time now, but I cannot figure it out. It is on the study guide for my final exam, which is tomorrow so I am trying to figure it out. Thanks So I know that $\sum_{k=1}^n (1/k) = 1+1/2+1/3+1/4+1/5+\dots$, but I am having a tough time really figuring out how to prove it is greater than ln(n+1). Can someone help me please? Thanks so much",['sequences-and-series']
1245988,Boundary Value Problem and solutions,"The linear ordinary differential equation $y'' + y = 0$ has the family of solutions $y = A \sin(x) + B \cos(x)$  Determine whether $y(0)=2, y'(\pi/2)=3$ is a unique solution.  If not, does it have no solutions or infinite? I found $B=2$ and $A=5x$ giving the general solution $5x\sin(x)+2\cos(x)$ Am I right?","['boundary-value-problem', 'ordinary-differential-equations']"
1245997,If $n\equiv 4 \pmod 9$ then $n$ cannot be written as sum of three cubes? [duplicate],"This question already has an answer here : The sum of three integer cubes $x^3+y^3+z^3 \not\equiv \pm4 \pmod{\!9}$ (1 answer) Closed 2 months ago . Show that if $n\equiv 4 \pmod 9$ then $n$ cannot be written as sum of three cubes. This might be a silly question but I really don't see it? The thing I ended up was: let $n=a^3 + b^3 + c^3$, then we'll end up with $[a]^3+[b]^3+[c]^3=[4]$ in $Z_9$. I found several webpages and apparently this is quite ""obvious"".","['number-theory', 'congruences']"
1246003,"$a,b,c,p$ are rational number and $p$ is not a perfect cube","Given that $a,b,c,p$ are rational number and $p$ is not a perfect cube, if $a+bp^{1\over 3}+cp^{2\over 3}=0$ then we have to show $a=b=c=0$ I concluded that $a^3+b^3p+c^3p^2=3abcp$ but how can I go ahead? could you please help? Thanks","['number-theory', 'elementary-number-theory']"
1246022,"For X,Y random variables, with pdfs that are symmetric around 0, does $V(X)\geq V(Y) \Rightarrow E(|X|)\geq E(|Y|)$?","I need to show the following thing. Consider two continuous random variables $X,Y$ which take values in $[-1,1]$ and are have pdf's that are symmetric around zero. How can I show that $V(X)\geq V(Y) \Rightarrow E(|X|)\geq E(|Y|)$ ? I have tried a number of examples where this holds, but I straggle finding a general answer. As an example one can try $f_1(x)=\frac{1}{2}$ (uniform) and $f_2(x)=\frac{3}{2}x^2$ that satisfy the above conditions and the result holds.","['absolute-value', 'statistics', 'probability-distributions', 'expectation']"
1246023,"Let $X_1,\ldots,X_n$ i.i.d. negative binomial. Find the best unbiased estimator for $P(X\le3)$","I am not sure where I should even start with this problems. I know that the sum of negative binomial random variables is itself a negative binomial random variable. I am sure that I can show that the sum is also a sufficient and complete statistic. However, beyond this point I am not sure where to go with finding the ""best"" unbiased estimator. Any suggestions would be greatly appretiated",['statistics']
1246029,Geometric distribution converges to exponential distribution,"For $n\in \mathbb{N}$ let $X_n$ be geometric with parameter $p_n \in (0,1)$, that means $\mathbf{P}[X_n = k] = p_n(1-p_n)^k$, $k\in\mathbb{N}_0$. How must the sequence $(p_n)_{n\in\mathbb{N}}$ look like so that $X_n/n\overset{\mathcal{D}}{\longrightarrow} \mathrm{Exp}(\alpha)$ with $\alpha>0$? Note: ""$\overset{\mathcal{D}}{\longrightarrow}$"" denotes convergence in distribution. I'm pretty sure that the condition for the sequence is $p_n = \alpha/n$. Let $A \in \mathcal{B}([0, \infty))$. We have to prove that the associated image measures
  \begin{equation*}
    \mathbf{P}_{X_n/n}[A] = p_n(1-p_n)^k \, \delta_{k/n}(A) = \frac{\alpha}{n} \Bigl(1-\frac{\alpha}{n}\Bigr)^k \delta_{k/n}(A)
  \end{equation*}
  converge weakly against the image measure
  \begin{equation*}
  \mathbf{P}_{\mathrm{Exp}(\alpha)}[A] = \int_A \alpha  e^{-\alpha x} \, dx\,.
\end{equation*} Let $f \in C_b([0, \infty))$, i.e. an arbitrary real valued function on $[0, \infty)$ which is bounded and continuous, then
  \begin{align*}
    \int f \, d \mathbf{P}_{X_n/n} = \lim_{n\rightarrow\infty} \sum_{k=0}^{\infty} f\biggl(\frac{k}{n}\biggr) \, \frac{\alpha}{n}\Bigl(1-\frac{\alpha}{n}\Bigr)^{k} = \lim_{n\rightarrow\infty} \sum_{k=0}^{\infty} f\biggl(\frac{k}{n}\biggr) \, \frac{\alpha}{n}\biggl(\Bigl(1-\frac{\alpha}{n}\Bigr)^{n}\biggr)^{\frac{k}{n}} \, .
  \end{align*}
  Also using dominated convergence with the majorant $2 \|f\|_\infty \alpha e^{-\alpha x}$ we get:
\begin{align*}
  \int f \, d\mathbf{P}_{\mathrm{Exp}(\alpha)} &= \int f(x)\, \alpha e^{-\alpha x} \, dx \\
   &= \int \lim_{m\rightarrow\infty} \sum_{k=0}^{m^2} f\biggl(\frac{k}{m}\biggr) \, \mathbf{1}_{\bigl[\frac{k}{m}, \frac{k+1}{m}\bigr)}(x) \, \alpha e^{-\alpha k/m} \, dx \\
   &= \lim_{m\rightarrow\infty} \int \sum_{k=0}^{m^2} f\biggl(\frac{k}{m}\biggr) \, \mathbf{1}_{\bigl[\frac{k}{m}, \frac{k+1}{m}\bigr)}(x) \, \alpha e^{-\alpha k/m} \, dx \\
     &= \lim_{m\rightarrow\infty} \sum_{k=0}^{m^2} f\biggl(\frac{k}{m}\biggr) \, \frac{\alpha}{m} e^{-\alpha k/m}\, .
\end{align*} So, obviously it seems that we're very near the solution. But we have to partially take some limits and I don't know how to do that. For example, I can't use the M-test to draw the limit back into the infinite sum. Also, though it seems that I can substitute the $m^2$ by $\infty$ in the last equation, I'm not so sure. And even if possible, I don't know what to do about the limit there, too. If anybody could help me, please?","['probability-theory', 'limits']"
1246091,What is the purpose of Wronskian (linear independence/variation of parameters)?,"So as I understand, the Wronskian determinant can be used to show linear independence. Why is that? Also, how does this fit into understanding variation of parameters for solving a differential equation?","['linear-algebra', 'ordinary-differential-equations']"
1246092,"Is this proof for 1/4 mod 9 = x, correct?","Find an integer x so (1/4) mod 9 = x Proof: > 1/4 mod 9 = x 
> 1 mod 9 = 4 * x
> - using x = 7 - 
> 1 mod 9 = 28 
> 28 mod 9 = 1 (to validate)
> - using Euler division theorem m = nq + r - 
> 28 = 9(3) + 1
> r = 1, so 1 = 1 I appreciate the feedback.",['discrete-mathematics']
1246136,Maclaurin series expansion for $e^{-1/x^2}$,"I am currently extremely confused on how to proceed with the Maclaurin series expansion for my current function. I got my derivatives and I got my formula, however, plugging them in gives me a non-possible answers since division by $0$ is not possible.","['taylor-expansion', 'calculus']"
1246162,$x \perp y$ if and only if $\Vert x + \alpha y \Vert \ge \Vert x \Vert$ for all scalars $\alpha$,"Here's Prob. 8 in the Problems after Sec. 3.2 in Introductory Functional Analysis With Applications by Erwine Kreyszig: Show that in an inner product space, $x \perp y$ if and only if $\Vert x + \alpha y \Vert \ge \Vert x \Vert$ for all scalars $\alpha$. If $x \perp y$, then $\langle x, y \rangle = 0$; so for any scalar $\alpha$, we have 
$$
\begin{align*}
\Vert x + \alpha y \Vert^2 &= \langle x + \alpha y, x + \alpha y \rangle \\
&= \Vert x \Vert^2 + 2 \Re \bar{\alpha} \langle x, y \rangle + \vert \alpha \vert^2 \ \Vert y \Vert^2 \\ 
&= \Vert x \Vert^2 +  \vert \alpha \vert^2 \ \Vert y \Vert^2 \\ 
&\ge \Vert x \Vert^2. 
\end{align*}
$$
So 
$$
\Vert x + \alpha y \Vert \geq \Vert x \Vert.
$$ Am I right? Now how to prove the converse? It is my guess that we will have to put in a particular value for $\alpha$.","['inner-products', 'real-analysis', 'functional-analysis', 'orthogonality', 'analysis']"
1246168,What is the relationship between the trigonometric secant and the geometric secant of a circle? [duplicate],"This question already has answers here : What is the geometric interpretation of the value of the secant and cosecant of an angle? (4 answers) Closed 1 year ago . What is the difference between the geometric secant(the line that cuts two points of a curve) of a curve, and the trigonometric secant(=1/cosinex) ? If they are the same, can you explain how they are the same? Could you please explain, I am not able to see it intuitively. Thank you!",['trigonometry']
1246182,Rationale behind a proof regarding a continuous function and an open ball,"can I have the rationale for the first line of this proof? i.e. How did you know to start answering the question in this manner? I am guessing it is because you want to exploit the definition of continuity? (I am able to follow the rest of the proof, no problem) The question goes like this: Suppose that $f: \mathbb{R} ^{m} \rightarrow \mathbb{R} $ is a continuous function and that $f(x^{*}) \gt 0$. Show that there is an open ball B = $B_{\delta}(x^{*})$ such that $f(x) \gt 0$  for all x $\epsilon$ B. Solution: Let $\epsilon$ be such that $0 \lt \epsilon \lt f(x^{*})$ By continuity of f at $x^{*}$, there is a $\delta \gt 0$ such that
$|| x - x^{*} || \lt \delta \Rightarrow |f(x) - f(x^{*})| \lt \epsilon $ But $|f(x) - f(x^{*})| \lt \epsilon $ implies $f(x) \gt f(x^{*}) - \epsilon \gt 0$ So for all x satisfying $|| x - x^{*} || \lt \delta$, $f(x) > 0$ But this is simply saying that for all x $\epsilon B = B_{\delta}(x^{*}), f(x^{*}) \gt 0$ My question: How did you know to start the proof using this line: Let $\epsilon$ be such that $0 \lt \epsilon \lt f(x^{*})$? Many thanks","['continuity', 'general-topology', 'functions']"
1246222,"Computing $\int_{\gamma}e^zdz$, where $\gamma$ is a particular semicircle","How can I compute $\int_{\gamma}e^zdz$, if $\gamma$ is the semicircular arc depicted below? So, $\gamma=3e^{i\theta(t)}$, with $0\le\theta(t)\le\pi$, and then $$\displaystyle\int_{\gamma}e^zdz=\int_0^\pi e^{3e^{i\theta(t)}}\cdot\left|\left(3e^{i\theta(t)}\right)'\right|dt .$$ This looks awful, how can I compute the rest?","['contour-integration', 'complex-analysis']"
1246224,Is the max of two differentiable functions differentiable?,"Given that $f$ and $g$ are two real functions and both are differentiable, is it true to say that $h=\max{(f,g)} $ is differentiable too? Thanks","['calculus', 'real-analysis', 'multivariable-calculus']"
1246227,"Prob. 10, Sec. 3.2, in Erwin Kreyszig's ""Introductory functional analysis with applications""","Here is Prob. 10, Sec. 3.2, in the book Introductory Functional Analysis With Applications by Erwin Kreyszig: ... Let $T \colon X \to X$ be a bounded linear operator on a complex inner product space $X$ . If $\langle Tx, x \rangle = 0$ for all $x \in X$ , show that $T=0$ . ... My Solution: For any $x, y \in X$ and scalar $\alpha$ , we have $$ \big\langle T(\alpha x + y), \alpha x + y \big\rangle = 0. \tag{1}$$ But using the linearity of $T$ and the properties of a complex inner product, we obtain $$
\begin{align}
& \ \ \  \big\langle T(\alpha x + y), \alpha x + y \big\rangle \\ 
&= \big\langle \alpha Tx  + Ty , \alpha x + y \big\rangle \qquad \mbox{[because $T$ is linear]} \\ 
&= \big\langle \alpha Tx, \alpha x \big\rangle + \big\langle \alpha Tx, y \big\rangle + \big\langle Ty, \alpha x \big\rangle + \big\langle Ty, y \big\rangle \\
&= \alpha \overline{\alpha} \langle Tx, x \rangle + \alpha \langle Tx, y \rangle + \overline{\alpha} \langle Ty, x \rangle + \langle Ty, y \rangle \\
&= \lvert \alpha \rvert^2 \langle Tx, x \rangle + \alpha \langle Tx, y \rangle + \overline{\alpha} \langle Ty, x \rangle + \langle Ty, y \rangle \\
&= \lvert \alpha \rvert^2 \cdot 0 +  \alpha \langle Tx, y \rangle + \overline{\alpha} \langle Ty, x \rangle + 0 \\ 
& \qquad \qquad \mbox{[using the condition on $T$]} \\
&= \alpha \langle Tx, y \rangle + \overline{\alpha} \langle Ty, x \rangle. \tag{2}
\end{align}
$$ Using (1) and (2), we obtain $$ \alpha \langle Tx, y \rangle + \overline{\alpha} \langle Ty, x \rangle = 0. \tag{3} $$ In the last relation, putting $\alpha = 1$ and $\alpha = \iota$ , respectively, we obtain $$
\langle Tx, y \rangle +  \langle Ty, x \rangle = 0, \tag{4}
$$ and $$
\iota \langle Tx, y \rangle - \iota  \langle Ty, x \rangle = 0,
$$ and this last equation upon dividing both sides by $\iota$ yields $$
 \langle Tx, y \rangle -  \langle Ty, x \rangle = 0, \tag{5}
$$ Now adding (4) and (5), we get $$
 \langle Tx, y \rangle = 0 \ \ \ \mbox{ for all } \ x, y \in X. \tag{6}
$$ But for each $x \in X$ , the image $Tx$ also is in $X$ ; so we can put $y = T(x)$ in (6) to obtain $$
\Vert Tx \Vert^2 = \langle Tx, Tx \rangle = 0 \ \ \ \mbox{ for all } \ x \in X,
$$ and therefore $$
Tx = \mathbf{0} \ \ \ \mbox{ for all } \ x \in X, 
$$ Therefore we have shown that $T \colon X \to X$ is the zero operator, as required. Is the above proof correct? If so, then where does the boundedness of $T$ come in?","['inner-products', 'real-analysis', 'functional-analysis', 'analysis', 'linear-algebra']"
1246251,Find a binomial coefficient equal to ${n\choose k} + 3 {n\choose k-1} + 3{n \choose k-2} + {n\choose k-3}$,"Exercise. Find a binomial coefficient equal to: $${n\choose k} + 3 {n\choose k-1} + 3{n \choose k-2} + {n\choose k-3}.$$ I don't really understand what we are asked to do when we are told to find a binomial coefficient equal to the sum of some combinations, I suppose that in a combinatorial way we must show that the partition of some set S can be equal to some binomial coefficient. Can someone please give a brief explanation for the exercise?","['summation', 'binomial-coefficients', 'combinatorics']"
1246261,Rectangle randomly thrown on chessboard,") I'm an electrical engineer and having a tough problem with... math :) geometry and probability... Here's the problem : We have an infinite chessboard. Each square of the chessboard is of known height/width (x). I have four points, distances between these points being FIXED. They can be arranged as a rectangle, square, diamond, on a circle... Question : I want to throw the rectangle (or square, or diamond...) on the chessboard and get a 100% probability for two points of the rectangle to land on a white square and the two other points on a black square. What shape/dimensions regarding to x, do I have to adopt for this condition to be fullfilled ? Thanks for your help :) !","['geometry', 'probability', 'random']"
1246310,The colimit of all finite-dimensional vector spaces,"Let $\mathsf{iFinVect}_K$ be the category of finite-dimensional vector spaces with injective linear maps and $X : \mathsf{iFinVect}_K \to \mathsf{Vect}_K$ be the inclusion functor. Then $\mathrm{colim}(X)$ exists. This is because $\mathsf{Vect}_K$ is cocomplete and $\mathsf{iFinVect}_K$ is essentially small (although it is not small). This colimit seems to be a bit strange to me, though. We merge all finite-dimensional vector spaces into a single large vector space. The embeddings are natural with respect to all injective linear maps between finite-dimensional vector spaces. Can we make this vector space more explicit? Is it, perhaps, even a well-known object? Can we find a basis? Every element of $\mathrm{colim}(X)$ should have the form $\iota_V(v)$ for some finite-dimensional vector space $V$ and some vector $v \in V$, where $\iota_V : V \to \mathrm{colim}(X)$ is the colimit inclusion. This is because for every $V,W \in \mathsf{iFinVect}_K$ there is some $U \in \mathsf{iFinVect}_K$ with morphisms $V \xrightarrow{f} U \xleftarrow{g} W$, namely the coproduct. This implies $\iota_V(v)+\iota_W(w) = \iota_U(f(v)+g(w))$. Of course we have $\lambda \cdot \iota_V(v)=\iota_V(\lambda \cdot v)$ for $\lambda \in K$. This shows how to calculate with elements of $\mathrm{colim}(X)$. Notice, however, that $\mathsf{iFinVect}_K$ is not filtered (because the only parallel morphisms which may be coequalized by some morphism are already equal). For this reason I think that a priori it is not so easy to decide when two elements of a colimit, say $\iota_V(v)$ and $\iota_W(w)$, are equal. It suffices to find a criterion when some element $\iota_V(v)$ is zero. This can happen when $v \neq 0$! For example, we have $0=\iota_V(v)+\iota_V(-v) = \iota_{V \oplus V}((v,-v))$. So probably we should first answer: Do we have $\mathrm{colim}(X) \neq 0$?","['linear-algebra', 'category-theory']"
1246320,"Name for ""3-dimensional figure-8"" shape","Take a sphere or ellipsoid or similar (hereafter just called sphere) ... and imagine pinching it in the middle, deforming it by moving two points that were on opposite sides of the sphere inward until they overlap, becoming one point. The resulting shape is, as I said in the title, among those things you could imagine meant by ""three dimensional figure 8"" ... It could also be described as two raindrop lobes connected at a point to form one shape. Or, what you (kind of) make if you take a flexible round balloon and make a twist in one place. I have been assuming that this meets the criteria to be a shape, correct me if I am wrong there. If it is a shape, I want to know what its name(s) are, and anything else you might know about it, mathematically. The name is the important part, though, because I can use a name to look up more about it. Double lobe, or bilobe, maybe... I could make up a name, but would rather know what mathematicians call it. In my search, I have found lemniscates, but those do not seem right. They are more... membrane-like, not filled out. In pictures they appear dissimilar to the shape I'm asking about here. I am most knowledgable in biology, not math, or even physics, and don't really know where or how to look ... So, thank you very much to anyone who addresses or answers my question.","['solid-geometry', 'geometry', 'terminology']"
1246362,Tensor Notation Upper and Lower Indices,"I want to ask what the difference between the tensors $T_i^{\; j}$ , $T_j^{\; i}$ , $T_{\; i}^{ j}$ , and $T_{\;i}^{j}$ are. In particular I am asking about the matrix representations of these tensors and their relationships.","['tensors', 'matrices']"
1246417,Has the 3x3 magic square of all squares entries been solved?,It is my understanding that it has not yet been determined if it is possible to construct a $3$x$3$ magic square where all the entries are squares of integers.  Is this correct?  Has any published work been done on this problem?,"['number-theory', 'reference-request']"
1246423,If $a_n = \frac{e^{n}}{e^{2n}-1}$ how do I show that $a_{n+1} \leq a_n$?,"Let $$a_n = \frac{e^{n}}{e^{2n}-1}$$
How do I show that $a_{n+1} \leq a_n$? I don't know how to deal with the $-1$ in the denominator.","['exponential-function', 'sequences-and-series', 'inequality']"
1246452,I need help setting up these limits of integration (triple integrals),"I need to find the volume of the solid bound on top by $z=7$, bottom by $z=7x^2+7y^2$, integrating over $z$. I've looked in three different textbooks and still don't understand, asked my professor and they won't write back. So I have drawn a picture, and I have the following (the red limits are wrong):
\begin{align}
\int_{\color{red}{1/\sqrt{2}}}^{\color{red}{-1/\sqrt{2}}}\int_{\color{red}{-\sqrt{1/\sqrt{2}-x^2}}}^{\color{red}{\sqrt{1/\sqrt{2}-x^2}}}\int_{7x^2+7y^2}^7z\:dz\:dy\:dx.\tag{1}
\end{align}
Could anyone give me some pointers?","['multivariable-calculus', 'integration']"
1246464,Volume of a hole through cylinder (from the side),"I need to calculate the volume of a circular hole in a cylinder and I've come across a problem. The problem is finding the ""cap-volume"", which is needed to complete the volume of the hole. I created a quick example of the problem. Cylinder which will be drilled Hole. The cap is shown with the magenta coloured curves","['volume', 'geometry', 'integration']"
1246468,Bivariate Probability question,"Let $X$ be the time (in minutes) that John spends waiting for a bus on his way home from uni, and let$ Y$ be the time he spends waiting for a train. $X$ and  $  Y$ have joint density function,$$f_{X,Y}(x,y)=0.01e^{-0.1(x+y)}\quad x>0,y>0$$ i) Determine the probability that John has to wait less than half an hour in total. I did $\int_{0}^{30} 0.01e^{-0.1z} dz \approx 0.09 $ ii) Find the expected time that John spends waiting for a bus. Is it $\int_{-\infty}^{\infty}x\; f_{X}(x) dx $ or can I somehow infer this from the exponential distribution. iii) Find $f_{Y}(y)$ . I am pretty confident this is $\int_{-\infty}^{\infty} 0.01e^{-0.1(x+y)} dx $ iv) Find $f_{Y|X} (y|x)$. Is this just the joint density divided by marginal density of X? v) Are X and Y independent? Give reasons. I wanted to know if I'm on the right track as I have no solutions to these problems.","['probability', 'statistics']"
1246475,Name of the LU decomposition algorithm,On the wikipedia page of LU decomposition there is an algorithm that produce the decomposition. It is called Doolittle algorithm . I'm really interested who is Doolittle? Or from where the name comes from? Is there any citation for the original work of the algorithm? As I know the decomposition is invented be Alan Turing.,"['linear-algebra', 'numerical-methods', 'matrix-decomposition', 'matrices']"
1246481,Elementary question on set theory,"Suppose $A \subset B$ then does this imply $B^{c} \subset A^{c}$? Here, $B^{c}$ denotes the complement of $B$. I have tried drawing Venn Diagrams and it seems obvious but is there a formal rigorous proof for it?","['elementary-set-theory', 'proof-writing']"
1246484,Find the type of triangle from equation.,"In triangle $ABC$, the angle($BAC$) is a root of the equation $$\sqrt{3}\cos x + \sin x = \frac{1}{2}.$$ Then the triangle $ABC$ is a) obtuse angled b) right angled c) acute angled but not equilateral d) equilateral. Thanks in advance.","['geometry', 'triangles', 'trigonometry']"
1246496,The Lebesgue outer measure,"The Lebesgue outer measure on $\mathbb{R}$ is defined as: $\lambda^{*}(A)$ = $inf${$\sum_{n=1}^{\infty}(b_{n}-a_{n}): A \subset \bigcup_{n=1}^{\infty}(a_{n}, b_{n}) $} I want to show that $\lambda^{*}([a,b]) = b-a$. Although I have proofs for this lemma, they are incomplete and jump  from one statement to another without justification. So would anyone be kind enough to post a proof which is relatively simple?",['measure-theory']
1246505,Filtrations and Sigma-Algebras and Stopping Times,"In a previous post Filtrations and Sigma-Algebras I asked the question: $\textbf{Previous Question:}$ Let $\Omega=\{1,2,3\}, \mathcal{A}=\mathcal{P}(\Omega)$ and $P(\{\omega\})=\tfrac{1}{3}$ for each $\omega \in \Omega$. Define a stochastic process $(X(t):t\ge 0)$ by $X(t)(\omega) = \max\{t-\omega,0\}$.Then the filtration generated by the stochastic process $X$ computes as
\begin{align}
\mathcal{F} = 
\begin{cases}
\{0,\Omega\}, \qquad \qquad \qquad \text{if $t\in[0,1],$} \\
\{0,\Omega,\{1\},\{2,3\}, \phantom{xx}\text{if $t \in (1,2]$,}\\
\mathcal{P}(\Omega), \qquad \qquad \qquad \phantom{.}\text{if $t>2$.} \end{cases}
\end{align} The user V.C. explained most comprehensively how the filtration was obtained for which I am most grateful. 
\begin{align}
\end{align}
I would now like to extend the question to $\textbf{Stopping Times:}$ $\textbf{Extension:}$ In light of the previous question define
\begin{align}
\tau : \Omega \rightarrow [0,\infty), \quad \tau(\omega) := \inf\{t \ge 0: X(t)(\omega) > 0\}
\end{align}
Then it may be seen that $\tau$ is not a stopping time as $\{\tau \le 1\} = \{1\}$ but $\{1\} \not \in \mathcal{F}_1$.
\begin{align}
\end{align}
$\textbf{Question:}$ Could someone explain what $\{\tau \le 1\} = \{1\}$ represents please? I can see that the stochastic process $X_t(\omega) = t-1$ when $\omega = \{1\}$ and $t\in(1,2]$ and thus $0 < t-1 \le 1$. But I'm confused because in the definition of $\tau$ it is stated being a function of $\omega$, i.e. $\tau(\omega)$, thus I'm not sure what $\{\tau \le 1\}$ is supposed to represent. All help is appreciated. Many thanks, John","['probability-theory', 'stochastic-analysis', 'stochastic-processes', 'measure-theory']"
1246506,Rewriting $\sin(2\cos^{-1}{(x/3)})$ as a fraction?,"I'm looking to simplify
$$\sin(2\cos^{-1}{(x/3)})$$ I know it simplifies to $\frac{2x}{3}\sqrt{1-\frac{x^2}{9}}$, but I am unsure of the required steps. Thanks for any help",['trigonometry']
1246536,Show that every finite simple group G has a faithful irreducible representation,A representation $ \rho $ : G  $ \rightarrow $ GL(V) is faithful if ker($ \rho $)={$ e $}. A representation is irreducible if it contains no proper invariant subspaces G is a simple group its normal subgroups are {$ e $} and itself. Is there anything that can link these together to prove the above statement?,"['group-theory', 'representation-theory']"
1246538,Inequality with (1-x) as denominator,How do I solve $\frac{1}{x-1}>0$ for $x$? If I multiply both sides with $x-1$ then becomes $1\gt 0$. I know it's wrong. How do I solve it?,"['algebra-precalculus', 'inequality']"
1246554,Which (convergent) series can one find the sum of?,"I know about geometric series and how one can find the sum when they are convergent. I also have heard that one can prove that the $p$-series 
$$\sum_{n=1}^{\infty} \frac{1}{n^2}$$
has sum $\pi^2/6$ (but I don't know how this is actually proved). This might be an unanswerable question, but are there any tools or general rules that will tell you when you can find the exact sum of a given series? Are there, for example, rules/tools for how to find the exact value of any $p$-series? (like with geometric series).","['sequences-and-series', 'geometric-series', 'calculus', 'convergence-divergence']"
1246567,Expected number of turns for SPROUT,"As a mathematical father (and with apparently plenty of time on my hands) I long ago computed the expected number of turns for a number of children's games that are effectively Markov maps. ( Chutes and Ladders , Hi Ho! Cherry-O , Candy Land , etc.) And I've seen this and similar posts. (The TLDR version for this technique is that you have to diagonalize a matrix.) My, now older, son has introduced me to a new game and I was wondering about its expected number of turns. The game is SPROUT and it's rules are as follows: $n$ players play a game similar to every-man-for-himself dodge ball. Initally a ball is put into play and all players are free to run around the playing field. Free players can pick up the ball, take up to three steps with the ball, and throw it at another free player--if they hit the target that player is frozen and must sit down. If the target instead catches the ball then the Thrower is frozen and must sit. A frozen player is freed if the player that froze them becomes frozen. The freed player ""sprouts"" back up. The game ends when all players but one are frozen, this can only happen if that single free player has managed to freeze every every player. Apparently with 30 kids or so this game almost never ends. It's a great game to play I guess because the kids get exercise, but even if you get ""out"" or frozen, it's usually not long until you are back in the game. And you have a sweet sense of retribution at the moment of your freedom. Assuming that a turn of this game consists of one random free player freezing another random free player (and simultaneously freeing all the players that the newly frozen player had previously frozen), how many turns do we expect a game of $n$ players to take? This is harder to analyze because the state of the game is not just the number of free players and the number of frozen players, we must remember who froze whom so we can free the captives if their opressor ever becomes frozen. I can run numerical simulations for this but I'd be much more satisfied with an analytical understanding. Here's what I've done so far: We can keep track of the state of the game by an $n$ long vector that tracks the state of each player. Let a zero in position $i$ denote that player $i$ is free and a number from $1$ to $n$ represents the freezor of the frozen player $i$.
Initialize the state to be all zeros.
$$\{0,0,0,0,0,0,0,\ldots,0\}$$
At any later turn the state will be a combination of zeros and integers from $1$ to $n$ (e.g. $\{0,1,5,5,0\}$ ) but we also have the property that any non-zero integers appearing in the state vector imply that there are zeros in those positions of the state vector as well (due to property 4 above). This means that there are $$\sum_{k=0}^{n-1}{n \choose k}(n-k)^k$$ total states, including the initial state (which is never returned to) and the $n$ final states (one for each possible winning player). This number is crazy big but I imagine that these states are sparsely connected since I have seen a game of ten boys completed. (Maybe one boy was just really superior at the game??) I'd appreciate any feedback on my analysis. Am I thinking about this correctly? Is this just gonna be a hard problem? Is it really an easy problem?? Thanks Update: Upon further inspection I realize that there are actually far fewer states. If I do not care about player identity, only the total number of turns, I can relable my players as needed so that they are ordered with the free player indices lower than the the frozen players and each group further ordered as follows. For the free players let player 1 be the player in the ""lead"" i.e. the one who has frozen the most, let player 2 be the next according to this order and so on for $k$ free players. For the frozen players (beginning at index $k+1$) let them be ordered by the index of their Freezor. e.g.
$$\{0,0,0,0,1,1,1,2,2,3\}$$
Then the states are just ordered lists of non-negative integers with the only properties that The last element is not greater in value than the number (count) of zeros. The non-zero integers are monotonically non-decreasing in count. (Never fewer ones than twos, etc.) This drastically reduces the number of states but I do not yet have a good count of this.","['probability', 'markov-chains']"
1246618,Why sigma algebra and not other systems of sets?,I got a short question. Why we are considering sigma-algebras and not other systems of sets in measure-theory? Why not dynkin-system for example?,['measure-theory']
1246642,Show that the additive inverse condition can be replaced by $0v = v$ for all $v \in V$,"In the definition of a vector space, the additive inverse condition
  requires that for every $v \in V$ (where $V$ is a vector space over
  $\mathbf{F} = \mathbb{R}$ or $\mathbb{C}$), there exists $w \in V$
  such that $$v + w = 0$$  Show that this condition can be replaced with
  the condition that $$0v = 0$$ for all $v \in V$. The $0$ on the left side is the number $0$ in
  $\mathbf{F}$ and the $0$ on the right side is the additive identity of
  $V$. (The phrase ""a condition can be replaced"" in a definition means that the >collection of objects satisfying the definition is unchanged if the >original condition is replaced with a the new condition) (Taken from ""Linear Algebra Done Right (3rd edition), by S. Axler) I am new to abstract algebra and have close to no clue how to tackle this problem. Here is my futile ""attempt"" nonetheless: I tried some substitution and got $$v + w = 0v$$ but am unable to make any sense out of this, much less determine if I am headed towards the right direction.","['abstract-algebra', 'linear-algebra']"
1246647,"Find the sum of the n first series numbers: $7,77, 777,...$","Find the sum of the $n$ first numbers: $7,77, 777,...$ I thought to find an order by dividing $77/7=11, 777/7=111...$ but I don't know how to continue.",['sequences-and-series']
1246658,"Is function $f(x,y)=\begin{cases}(x^{2}+y^{2})(\sin(x^{2}+y^{2}))^{-1/2}, (x,y)\neq (0,0)\\0,(x,y)=(0,0)\end{cases}$ differentiable?","Is this function differentiable at (0,0)? . $f(x,y)=\begin{cases}\frac{x^{2}+y^{2}}{\sqrt{\sin(x^{2}+y^{2})}}, (x,y)\neq (0,0)\\0,(x,y)=(0,0)\end{cases}$ \begin{align*}
\lim_{h\mapsto 0} \dfrac{f(0+h,0)-f(0,0)}{h}=& \lim_{h\mapsto 0} \dfrac{\dfrac{h^{2}}{\sqrt{\sin(h^{2})}}}{h}\\
=& \  \text{not defined}
\end{align*} I tried to use the definition to figure out the partial derivatives. However I simply could not make it through. It looks like that the partial derivatives doesn't exist at $(0,0)$! This was in my exam at last week. However the teacher says that it is differentiable, and I disagree. So, simply, wich one is correct?",['derivatives']
1246662,Does A5 have a subgroup of order 6?,"I am trying to figure out if $A_5$ has a subgroup of order $6$. Rather than a yes/no answer I would prefer if someone could show me how they find their way to the answer. Below is my false attempt at a solution. Ideally I could get some tips on how to fix my attempt, but if it seems a dead end alternate solutions are really appreciated:). I began by counting the number of elements of each cycle type in S5 so that I could deduce the conjugacy classes and class equation for S5. Next I checked centralizers to determine which were conjugacy classes in A5 and I got the class equation for $A_5$ as $60 = 1 + 12 + 12 + 15 + 20$. Using the orbit-stabilizer theorem, we can deduce from the order of the last conjugacy class that there is a subgroup of order $3$, namely the centralizer of any element in this conjugacy class, for example $C((12345))={e, (12345), (15432)}$. It is easy to then find a subgroup of order $2$ such as $<(12)(34)>= {e, (12)(34)}$. Since the intersection of these two groups is ${e}$, my hope was that $<(12)(34)>(12345)$ would be a subgroup of order $6$, unfortunately not all the elements commute (If the elements of two subgroups $H$,$K$ commute and their intersection is ${e}$ then $HK$ is a subgroup with order equal to the product of the orders) so I'm left at a dead end.",['group-theory']
1246675,"$T,S: V\to V$, prove that $TS$ and $ST$ have the same eigenvalues","hey I was trying to prove this proposition by dividing to cases and this is what I've got so far:
let's assume without loss of generality that T is invertible:
ST = [T][S]
TS = [S][T] Pst(x) = |[T][S]-גI| = |[T][S]-גI|*|[T][T^-1]| = |[T^-1]|*|[T][S]-גI|*|[T]| =
|[S]-[T^-1]גI|*|[T]| = |[S]-ג[T^-1]|*|[T]| = |[S][T]-גI| = Pts(x) they have the same characteristic polynomial, thus the same eigenvalues.
but what about the case when both are non-invertible? would appreciate any kind of help.","['eigenvalues-eigenvectors', 'linear-transformations', 'linear-algebra', 'matrices']"
1246679,Expression of rotation matrix from two vectors,"What is the matrix expression of the rotation matrix in 3D which turns a vector $\vec{a}$ into a vector $\vec{b}$, with both vectors given by their coordinates? ($\vec{a} = (a_x, a_y, a_z)$ and $\vec{b} = (b_x, b_y, b_z)$, both already normalized). Other answers give a construction using an augmented 3D rotation matrix, where the angle and the base change matrices are given using the dot/cross products, but I couldn't find a direct expression of the 9 matrix fields using the 6 vector coordinates.","['rigid-transformation', '3d', 'matrices', 'rotations', 'linear-transformations']"
1246705,Linear homomorphisms of square matrices are conjugations,"I was doing some linear algebra exercises and came across the following tough problem : Let $M_{n\times n}(\mathbf{R})$ denote the set of all the matrices whose entries are real numbers. Suppose $\phi:M_{n\times n}(\mathbf{R})\to M_{n\times n}(\mathbf{R})$ is a nonzero linear transform (i.e. there is a matrix $A$ such that $\phi(A)\neq 0$) such that for all $A,B\in M_{n\times n}(\mathbf{R})$
  $$\phi(AB)=\phi(A)\phi(B).$$
  Prove that there exists a invertible matrix $T\in M_{n\times n}(\mathbf{R})$ such that 
  $$\phi(A)=TAT^{-1}$$
  for all $A\in M_{n\times n}(\mathbf{R})$. This is an exercise from my textbook and I am all thumbs when I attempted to solve it . Can someone tell me as to how should I , at least , start the problem ?","['lie-algebras', 'lie-groups', 'linear-algebra', 'matrices']"
1246742,Are points in general position generic points?,"In Harris' algebraic geometry book, $p_{1},\ldots,p_{r}\in\mathbb{P}^{n}$ are said to be in general position if no $n+1$ or fewer of them are dependent. I want to prove that, if $p_{1},\ldots,p_{r}\in\mathbb{P}^{n}$ are in general position, then they are generic points, i.e., there exists a Zariski open dense subset $\mathcal{U}\subseteq(\mathbb{P}^{n})^{r}$ such that
$$
\mathcal{U}\subseteq\{(p_{1},\ldots,p_{r})\in(\mathbb{P}^{n})^{r}:p_{1},\ldots,p_{r} \text{ are in general position}\}.
$$
I do not know if it is true, but I think so. By the way, since $(\mathbb{P}^{n})^{r}$ is irreducible, every open subset of $(\mathbb{P}^{n})^{r}$ is dense, so, if we find an open subset  $\mathcal{U}$ satisfying that property, we won't have to prove that it is dense.","['projective-geometry', 'algebraic-geometry', 'linear-algebra']"
1246743,Why does a singular matrix imply that it does not have a solution?,"(Trying to learn linear algebra over here) The augmented matrix in question: $$\begin{bmatrix}0 & 1 &5 & -4\\1 & 4 & 3 & 2\\2 & 7 & 1 & -2\end{bmatrix}$$ So I tried to solve the matrix above but I couldn't. I decided to see what happened when I pushed it through Numpy (Python): numpy.linalg.linalg.LinAlgError: Singular matrix So I went back to the definition for a singular matrix: A square matrix that is not invertible is called singular or
  degenerate. The book simply says it is inconsistent. So, now I'm wondering: How does a singular matrix relate to it not having a solution?","['linear-algebra', 'matrices']"
1246748,Distribution of an angle between a random and fixed unit-length $n$-vectors,"Suppose I have a random unit-length $n$-element vector $\mathbf{x}$ that is uniformly distributed on an $n$-dimensional sphere, and let vector $\mathbf{a}$ be some other unit-length $n$-element vector that is given (say the axis $[1,0,\ldots,0]$). Let $\phi\in[0,\pi]$ be the angle between $\mathbf{x}$ and $\mathbf{a}$.  I am wondering about the distribution of $\phi$. My intuition tells me that it's uniform, i.e. $f(\phi)=\frac{1}{\pi}$, but I can't rigorously prove it (and my intuition has been wrong in the past). Can anyone help?","['probability-theory', 'euclidean-geometry', 'geometry', 'probability-distributions']"
1246811,Prove $E[XE[Y\mid\mathcal{G}]] = E[YE[X\mid\mathcal{G}]]$,"Show that for bounded $X$ and $Y$ that $E[XE[Y\mid\mathcal{G}]] = E[YE[X\mid\mathcal{G}]]$. Attempt: Suppose that $X = _{\mathcal{X}_F}$, where $F \in \mathcal{D}$. Then for every $B \in \mathcal{D}$: \begin{align}
& \int_B E[Y\mid\mathcal{D}\hspace{2mm} dP_{\mathcal{D}}] = \int_B  Y \, dP_{\mathcal{D}} = \int_{B \cap F}  Y \, dP_{\mathcal{D}} = \int_{B \cap F}  E[Y\mid\mathcal{D}] \, dP_{\mathcal{D}} \\[8pt]
= {} & \int_{B} E[Y\mid\mathcal{D}] \, dP_{\mathcal{D}}  = X[E[Y\mid G]]\text{ a.s.} \tag 1
\end{align} (I'm trying to write out an $_{\mathcal{X}_F}$ infront of the conditional expectations in the last part, but it won't work) Then we can follow the same process for $Y = {\mathcal{Y}_F}$ to complete the proof (calling it $(2)$). Then saying by both $(1)$ and $(2)$, $E[XE[Y\mid\mathcal{G}]] = E[YE[X\mid\mathcal{G}]]$.","['probability-theory', 'lebesgue-measure', 'probability', 'measure-theory']"
1246832,Rational parametrization of circle in Wikipedia,"In http://en.wikipedia.org/wiki/Circle but also in the corresponding article in the German Wikipedia I find this formulation ( sorry, I exchange x and y as I am accustomed to it in this way ) : ""An alternative parametrisation of the circle is:
$$x=a+r\frac{1-t^2}{1+t^2}$$ and $$y=b+r\frac{2t}{1+t^2}$$ with real-valued parameter $t$."" But if I plot this curve I only get a half-circle with these formulas when $(a,b)\neq(0,0)$ which is obviously not what is searched for and expected. I recently found without any elementary trigonometry e.g. for the unit circle with $(a,b)=(1,0)$ a closed rational parametrization which plots the ""whole"" circle perfectly if $\lim_{t\to\infty}$. Now my 2 questions: What is your formula for the case of the unit circle with $(a,b)=(1,0)$
and how is your way to derive it ? Is there a way to calculate a rational parametrization for the unit    circle with general $(a,b)$ which allows ""whole""-circle plotting ? Maybe $a$ and $b$ must be rational numbers or even integers ?","['algebraic-curves', 'analytic-geometry', 'trigonometry']"
1246855,Divergence and Curl of the vectors,"How to find the divergence and the curl of the given vectors? a. $( \vec{u} \cdot \vec{r}) \vec{v}$ b. $( \vec{u} \cdot \vec{r}) \vec{r}$ c. $( \vec{u} \times \vec{r})$ d. $ \vec{r} \times(\vec{u} \times \vec{r})$ e. $ \psi (r) (\vec{u} \times \vec{r})$ where $\vec{u}$ and $\vec{v}$ are the constant vectors, $\vec{r}$ is the radius vector and $\psi(r)$ is a scalar function of the magnitude r of the $\vec{r}$ Thanks.","['vector-analysis', 'multivariable-calculus']"
1246868,Lebesgue integration of simple functions,"Define $f : [0,1] \to \Bbb R$ by $f(x) := 0$ if $x$ is rational, and
  $f(x) := d^2$ if $x$ is irrational, where $d$ is the first nonzero
  digit in the decimal expansion of $x$. Show that $\int_{[0,1]} f d m
  = 95/3$. Here $m$ is the Lebesgue measure I know that $f$ is simple, but can someone please suggest on how to proceed with this?","['lebesgue-measure', 'real-analysis', 'lebesgue-integral', 'measure-theory']"
1246881,Optimal scheduling dilemma (A textbook math problem IRL)?,"I am trying to solve a scheduling problem for a boys camp. I have 12 teams(A through L), 6 sports for them to play, and 6 periods for them to play in(P1 through P6). P1-P2-P3-P4-P5-P6
Soccer          |AB|KJ|IF|GB|EJ|CF|
Football        |CD|AL|KH|ID|GL|EH|
Kick-ball       |EF|CB|AJ|KF|IB|GJ|
Volley Ball     |GH|ED|CL|AH|KD|IL|
Hockey          |IJ|GF|EB|CJ|AF|KB|
Water Polo      |KL|IH|GD|EL|CH|AD| Here is how schedules are ranked: 1: Teams can only play one game per period. 2: Two points are awarded for every different sport a team plays 3: One point is subtracted every time a team match-up is repeated (e.g., Team C plays team F twice) Given this system, a perfect schedule(one where every team played every sport and never competed against the same team twice) would have a score of 144.","['puzzle', 'combinatorics']"
1246903,"If $BA$ has $-1$ as an eigenvalue, then so does $AB$?","I was just encountered with a rather tough problem as follows: Suppose $A,B\in M_n(\mathbb R)$, prove: $$\det(I_n+AB)\ne0\Rightarrow\det(I_n+BA)\ne0$$ Although at this moment I am still at a loss how to go about proving this, I seemed to have derived something that looks very stunning to me in my previous failed attemps: First, I think this one is obvious:
$$\det(I_n+AB)\ne0\Leftrightarrow-1\text{ is not an eigenvalue of }AB$$
And likewise,
$$\det(I_n+BA)\ne0\Leftrightarrow-1\text{ is not an eigenvalue of }BA$$
So what I'm asked to prove is actually equivalent to showing
$$-1\text{ is not an eigenvalue of }AB\Rightarrow-1\text{ is not an eigenvalue of }BA$$
Taking the converse-negative, that is to say
$$-1\text{ is an eigenvalue of }BA\Rightarrow-1\text{ is an eigenvalue of }AB$$
I cannot find any flaw in my reasoning. But if what I'm about to prove is true (I'm certain to say, yes it's true, because months ago I solved it in an extremely tricky way, which didn't, of course, follow my current threads), then it means for two arbitrary matrices $A,B$ of the same size, even if they don't commute, $AB$ and $BA$ will share $-1$ as an eigenvalue!! I think it is VERY unlikely. So could you please point out where the flaw of my reasoning lies? Or, could you help me prove this tough thing? Thanks in advance!","['eigenvalues-eigenvectors', 'determinant', 'linear-algebra', 'matrices']"
1246959,What is the motivation to continuous functions and measurable functions?,"In topology the objects of interest are the space open sets, and a function will be continuous if the inverse image of any open set is an open set. 
In measure theory the objects of interest are the measurable sets, and a function will be measurable if the inverse image of any measurable set is a measurable set. What is the motivation and importance of the ""inverse image"" operation, and how this idea has been generalized?","['motivation', 'general-topology', 'measure-theory']"
1246971,Is $f(x)$ reducible if $f(a)=0$,"I am confused about this seemingly trivial question: If $f(a) = 0$ for some $a\in D$, then when is $f(x)$ reducible in $D[x]$? ($D$ is an integral domain). My answer: Always. Let $f(a)=0$. Then $f(x)$ has $(x-a)$ as factor. So $f(x)$ can be written as $f(x) = (x-a)h(x)$. Now what is the guarantee that $h(x)\in D[x]$? I believe it is the division algorithm for polynomials (remainder = 0). Am I correct in proving $h(x)\in D[x]$?","['abstract-algebra', 'polynomials', 'proof-verification', 'ring-theory']"
1246974,How to use Cayley-Hamiltonian theorem in proving upper bound on linear space $W$?,"If $W = span(I,A,A^1,A^2, \dots)$. What is the upper bound on dimension of $W$? All matrices are $n \times n$. I know that the dim($W$) $\leq n$, by the Cayley-Hamiltonian theorem. However, I don't see how the Cayley-Hamiltonian (C-H) theorem is used to show this. From what I understand, the C-H theorem says once you get the characteristic polynomial equation for matrix $M$, $p(\lambda)$, then $p(M) =$ the zero matrix. I'm not sure how C-H can be used in showing that $dim(W) \leq n$. Second question: If $A=$ zero matrix, then would the dimension of $W = 1$ or $2$?","['characteristic-functions', 'linear-algebra', 'matrices']"
1246981,"Proving that a positive derivative means the function is smaller ""to the left"" and larger ""to the right"" for certain values","I was trying to prove that if $g$ is differentiable on an open interval $I$ with $a\in I$ and $g'(a)>0$ then we can find $x<a$  for which $g(x)<g(a)$ and $y>a$ for which $g(y)>g(a)$, I think I understand limits correctly but it confuses me when it comes to derivative so I just wanted to make sure I understand it correctly. My proof: Let $g'(a)=K>0$, that means that $$\lim_{x\to a}\frac{f(x)-f(a)}{x-a}=K$$ Therefore given $\epsilon=\frac{k}{2}$ we can find $\delta >0$ such that for $x\in I$ and $x\in (a-\delta , a+\delta )\setminus \{a\}$ $$\left|\frac{f(x)-f(a)}{x-a}-K\right|<\frac{K}{2}$$ (This is the part I'm not sure about).. hence $$-\frac{K}{2}<\frac{f(x)-f(a)}{x-a}-K<\frac{K}{2}$$ hence, $$\frac{K}{2}(x-a)<f(x)-f(a)<\frac{3K}{2}(x-a)$$ hence, $$\frac{K}{2}(x-a)+f(a)<f(x)<\frac{3K}{2}(x-a)+f(a)$$ Therefore if we choose $x\in (a-\delta ,a)$ and $y\in (a,a+\delta)$ (which we can find since $I$ is open) we get that $$f(x)<\frac{3K}{2}(x-a)+f(a)<f(a)\qquad \text{As }x-a<0$$ $$f(a)<\frac{K}{2}(y-a)+f(a)<f(y)\qquad \text{As }y-a>0$$ Is this proof correct? Also, I really got lost in trying to write the title :P","['proof-verification', 'real-analysis', 'derivatives']"
1246982,How do I weight votes based on number of possible voters?,"Scenario: I have a book club that reads a book every month. My website allows the readers to give a 5 star rating to each book. We have 10 members and a rule that a member may only vote on a book they have read. At the end of the year we read a book by the highest rated author. The problem: If only one person votes for a book but the other 9 didn't finish the that one person determines the sole vote for that book. Example: Book - number of votes - Average Vote Catcher in the Rye - 7 - 4.0 Catch 22 - 5 - 3.8 The Hunger Games - 1 - 5.0 In this example hunger games would win the year. But clearly Catcher in the Rye is more favored as most of the group just didn't bother to finish hunger games. Desired Outcome An ideal algorithm would weight the votes based on the number possible votes reducing the multiplier as the percentage of votes decreases. votes < 3 - (33% of total available) Multiply average by .5
3 > votes < 7 - (66% of total available) Multiply average by .75
votes > 7 - Vote stands. Is their a linear equation I can use to implement this type of weighting? or is there a more logical method of calculating the votes? Note: I want to avoid making the average by the number of possible voters (add 0 for each non vote) as this would bottom out some of the longer books that people did not get the time to read. A gradual decrease that only considers the votes cast is much preferred.","['voting-theory', 'statistics']"
1246990,Integrating over an embedded manifold: Jacobian factor?,"Let's say I want to integrate a function $$
f(x,y),\quad x\in\Gamma_1,y\in\Gamma_2
$$ where $\Gamma_1,\Gamma_2$ are both embedded manifolds in $\Bbb{R}^3$.  The dimension of $\Gamma_1$ is 1 (a smooth curve, say), while the dimension of $\Gamma_2$ is 2 (a plane or surface).  Formally, what I want to compute is: $$
\int_{\Gamma_1}\int_{\Gamma_2}f(x,y)dxdy
$$ If I choose (global) parametrizations of $\Gamma_1$ and $\Gamma_2$, what does the change of variables Jacobian factor look like?  The matrix of the transformation will not be square (it will be 6x3!) I think I know the answer, based on this very useful set of lecture notes: if $\Phi:\Bbb{R}^3\rightarrow\Bbb{R}^3\times\Bbb{R}^3$ is my parametrization, the answer should be $$
\int_{\Gamma_1}\int_{\Gamma_2}f(x,y)dxdy = \int_{\phi_1}^{\phi_2}\int_{\beta_1}^{\beta_2}\int_{\alpha_1}^{\alpha_2}f(\Phi(\alpha,\beta,\phi))\sqrt{\det (J^T_\Phi J_\Phi)}d\alpha d\beta d\phi
$$ Is this Jacobian factor correct?  Does anyone have a book reference for doing this?  The part I haven't seen before is the non-square Jacobian.  I must have somehow missed this in my calculus courses oh-so long ago.","['differential-geometry', 'reference-request', 'integration']"
1246996,Angle between slopes of a curve,"I am trying to understand what the change in angle of the slope of a curve means. It is hard to explain with words so here's an image that should help. The red curve has had its derivative approximated at three points. The tangent at each point is also shown in black. These slopes can be compared to one another, and using tan(z)=(m1+m2)/(1+m1*m2) we can calculate the angle between the slope at one point and the next. As shown in the image, the angle become smaller at the curve straightens out. What I'm trying to figure out is what this change in angle represents. My first instinct is that it can be thought of as the rate of change of the slope, therefore the second derivative should be analogous to the angle change. However the angles are changing due to the curvature of the curve, so I also feel like this is a sort of rate of change of curvature. If the curve was a circle, the angle would always be the same, therefore the change in curvature would be zero. Which, if any, of these two ways makes more mathematical sense? Thanks for the help.","['approximation', 'curvature', 'derivatives']"
1247003,Proving that if $S$ has an infinite subset then $S$ is infinite,"Definition $\quad$ A set $S$ can be defined as infinite if there exists a mapping from $S$ to $S$ that is one-to-one but not onto. Otherwise, $S$ is finite . Problem: Using the definition of infinite above, prove that if a set $S$ has an infinite subset, then $S$ is infinite. My attempt: Suppose $T\subseteq S$, where $T$ is infinite. By the supplied definition of infinite, there exists a mapping $\eta\colon T\to T$ that is one-to-one but not onto. That is, for all $x_1,x_2\in T$, we have $\eta(x_1)=\eta(x_2)\to x_1=x_2$, but there exists $\tau\in T$ such that $\eta(x)\neq\tau$ for all $x\in T$. Consider a one-to-one and onto mapping $\delta\colon S\setminus T\to S\setminus T$. There exists a mapping $\gamma\colon S\to S$ such that
$$
\gamma\colon S\to S\equiv
\begin{cases}
\eta\colon T\to T &\text{if $x\in T$},\\[0.25em]
\delta\colon S\setminus T\to S\setminus T &\text{if $x\in S\setminus T$}. 
\end{cases}
$$
The mapping $\gamma\colon S\to S$ is one-to-one because $x_1,x_2\in T\cup S\setminus T\to x_1,x_2\in S$ and $\gamma(x_1)=\gamma(x_2)\to x_1=x_2$ because $\eta$ and $\delta$ are both one-to-one mappings. However, $\gamma$ is not onto because there exists an element in $S$, namely $\tau$ (since $\tau\in T\to\tau\in S$ because $T\subseteq S$), that is not mapped to. Hence, there exists a mapping $\gamma$ from $S$ to $S$ that is one-to-one but not onto when $T\subseteq S$ and $T$ is infinite. Thus, $S$ is infinite. $\Box$ Question: Is this a good/correct proof? If not, where did I go wrong? If it is correct, then is there a way I can improve it or is there a more elegant approach?","['abstract-algebra', 'elementary-set-theory', 'proof-verification']"
1247064,Every Countable set has measure $0$,"I came across the following lemma in some book: Every countable set has measure $0$ and the proof involved ""breaking"" down the countable set into a countable union of points and then proved that every point has measure $0$ and hence by sub-additivity proved that a countable set has measure $0$, but am I right in assuming that this will only ever be true when we are talking about the Lebesgue measure? Because if we had instead defined the measure as a trivial measure then only the null set would have measure $0$",['measure-theory']
1247072,A strange Jensen's inequality for function of two variables,"I am reading a paper where they use implicitly the following ""Jensen's inequality which i find quite strange. Moreover i did not find this result in any textbook so, i would like an opinion before i cite their result.
Here is the ""Jensen's inequality"" they use : $f : \mathbb{R}^N \times \mathbb{R}^N \to \mathbb{R}$ a measurable map. $X$,$Y$ two measurable maps $X,Y : \Omega \to \mathbb{R}^N$ on a probability space $(\Omega,\mathcal{F}, \mathbb{P})$. $\mathcal{B}$ a sigma field (whose elements are in $\mathcal{F}$). Assuming for all $x$ $$y\to g(x,y)$$ is convex, is it true that $$E[f(X,Y) |\mathcal{B}] \geq f(X,E[Y|\mathcal{B}])$$ ? How can this be proved ? Do you have a counter example","['probability', 'measure-theory']"
1247087,"Prove that if $f''(x)+25f(x)=0$ then $f(x)=Acos(5x)+Bsin(5x)$ for some constants $A,B$","Suppose $f: \mathbb{R} \rightarrow \mathbb{R}$ is twice differentiable. Prove that if $f''(x)+25f(x)=0$ then $f(x)=Acos(5x)+Bsin(5x)$ for some constants $A,B$ Consider $g(x):= f(x)-Acos(5x)-Bsin(5x)$ where $A$ and $B$ are chosen so that $g(0)=g'(0)=0$ [ this portion is given, so can someone explain why it is important? ] For reference, we note that
$g(x):= f(x)-Acos(5x)-Bsin(5x)$
$g'(x):= f'(x)+5Asin(5x)-5Bcos(5x)$
$g''(x):= f''(x)+25Acos(5x)+25Bsin(5x)$ Consider the derivative of $\frac{25}{2}g(x)^2+\frac{1}{2}g'(x)^2$ $25g(x)g'(x)+g''(x)g'(x)$ if and only if $g'(x)[25g(x)+g''(x)]$ Following substitution, we conclude that $g'(x)[25g(x)+g''(x)]=g'(x)(0)=0$ Therefore, by the Constancy Theorem, $\frac{25}{2}g(x)^2+\frac{1}{2}g'(x)^2=C_0$, where $C_0$ is a constant $25g(x)^2+g'(x)^2=C$, where $C$ is a constant Thus, $25(f(x)-Acos(5x)-Bsin(5x))^2 + (f'(x)+5Asin(5x)-5Bcos(5x))^2=C$ Where do I go from here?","['derivatives', 'trigonometry', 'real-analysis', 'functions']"
1247108,Why is $\mathbb{R}^2$ not a subspace of $\mathbb{R}^3$?,"I cannot understand why $\mathbb{R}^2$ is not a subspace of $\mathbb{R}^3$. My reasoning is as follows:
Choose any elements $v_1$ and $v_2$ from $\mathbb{R}^2$, add them together you get an element of $\mathbb{R}^2$ and same for scalar multiplication and $0$ vector is an element of $\mathbb{R}^2$. So where did I go wrong?","['abstract-algebra', 'vectors', 'linear-algebra']"
1247110,Prove $\sin(45^°) + \sin(15^°) = \sin(75^°)$,"I rewrote the statement as 
$$
\sin(30^° + 15^°) + \sin(15^°) = \cos(15^°). 
$$
Then I got 
$$
(\sqrt{3}-2) \sin(15^°) = \cos(15^°).
$$",['trigonometry']
1247114,Strong convergence of convex combinations of a weakly convergent sequence,"Consider the Mazur's Lemma (H. Brezis - ""Functional analysis, ...""): Assume $(x_n)$ converges weakly to $x$. Then there exists a sequence $(y_n)$ made up of convex combinations of the $x_n$'s that converges strongly to $x$. The Lemma says that ""there exists a sequence...''. Is it true that every sequence $(y_n)$ made up of convex combinations of the $x_n$'s converges strongly to $x$? For example, if we consider 
$$y_n = \frac{1}{n}(x_1 + x_2 + ... +x_n),$$
is it true that $y_n$ converges strongly to $x$?","['convex-analysis', 'weak-convergence', 'functional-analysis']"
1247132,For what real values does $\phi(x):=1+x+ \dots + x^{2m-1}$ take the value $0$? What can you say about the sign as $x$ varies?,"For what real values does $\phi(x):=1+x+ \dots + x^{2m-1}$ take the value $0$? What can you say about the sign as $x$ varies? I need help adding rigor to my observation to create a formal proof. $\phi(x):=1+x+x^2+x^3+ \dots +x^{2m-2}+ x^{2m-1}$ $=(1+x)+x^2(1+x)+ \dots + x^{2m-2}(1+x)$ I think that this is fairly straightforward and obvious. How can I more rigorously prove that this re-forming is true? From this re-forming, obviously $\phi(x)=0$ if $x=-1$. Additionally, $\phi(x)<0$ if $x<-1$ and $\phi(x)>0$ if $x>-1$.","['polynomials', 'real-analysis', 'functions']"
