question_id,title,body,tags
149817,Derivative of cross-product of two vectors,"In finding the derivative of the cross product of two vectors $\frac{d}{dt}[\vec{u(t)}\times \vec{v(t)}]$, is it possible to find the cross-product of the two vectors first before differentiating?","['multivariable-calculus', 'calculus', 'vector-analysis']"
149820,How to factor the quadratic polynomial $2x^2-5xy-y^2$?,How do I factor this polynomial:  $2x^2-5xy-y^2$ ?,"['algebra-precalculus', 'quadratic-forms', 'polynomials', 'quadratics', 'factoring']"
149824,Computing the Gaussian integral with Fourier methods?,"There are many proofs that $$\int_{-\infty}^\infty e^{-x^2} \, \mathrm dx = \sqrt{\pi}.$$ For example, using a change to polar coordinates, differentiation under the integral sign, and the theory of the Gamma function. However, I am told there are very natural and simple ways to evaluate it using methods from Fourier analysis. This is not particularly surprising to me, considering, for example, that the Gaussian is its own Fourier transform, but I haven't seen an actual proof. So, how does one compute the Gaussian integral using methods from Fourier analysis?","['fourier-analysis', 'integration']"
149828,Mirror a function about x = c axis,"I'm trying to mirror a function $f(x)$ about the $x=c$ axis. To mirror it about the $x=0$ axis you just have to plot $f(-x)$. I tried to mirror $f(x) = x^2$ about the $x = c$ axis. And I found that the mirrored function of $f$ is $(x-2c)^2$. This just works for the $x^2$ function, but I need to mirror any function. How to do that?","['graphing-functions', 'functions']"
149829,Does $f(z+2\pi)=f(z)$ for all $z\in \mathbb{C}$?,"If $f:\mathbb{C}\rightarrow\mathbb{C}$ is a differentiable function and $f(x+2\pi)=f(x)$ for all $x\in \mathbb{R}$, would $f(z+2\pi)=f(z)$ for all $z\in \mathbb{C}$? Is there any theorem/lemma concerning this? Are there any examples/counter examples for this?",['complex-analysis']
149833,Is critical Haudorff measure a Frostman measure?,"Let $K$ be a compact set in $\mathbb{R}^d$ of Hausdorff dimension $\alpha<d$, $H_\alpha(\cdot)$ the $\alpha$-dimensional Hausdorff measure. If $0<H_\alpha(K)<\infty$, is it necessarily true that $H_\alpha(K\cap B)\lesssim r(B)^\alpha$ for any open ball $B$? Here $r(B)$ denotes the radius of the ball $B$. This seems to be true when $K$ enjoys some self-similarity, e.g. when $K$ is the standard Cantor set. But I am not sure if it is also true for the general sets.","['measure-theory', 'geometric-measure-theory']"
149842,understanding the symmetric/Hermitian matrix/operator,"The orthogonal/unitary matrix/operator can be seen as an isometric operation or transformation, which preserves the inner product (""length"" and ""angle""). But I have difficulties to intuitively understand the symmetric/Hermitian matrix/operator. I mean what kind of operation or transformation can be interpreted as the symmetric/Hermitian matrix/operator? Thanks!","['operator-theory', 'matrices', 'linear-algebra', 'functional-analysis']"
149843,"How to solve this equation, when the unknown variable just disappears?","This problem $\sqrt{1-x^2} + \sqrt{3+x^2} = 2$ has the solution $x = 1$ and $x = -1$. However, I always get stuck like this: $1-x^2 + 3+x^2 = 4$ $4 = 4$ How do I isolate that darn unknown?",['algebra-precalculus']
149851,How many eyes needed for higher-dimensional vision,"Our retinas are two-dimensional surfaces. With two eyes we combine images to perceive 3-dimensions. As a prelude to the main question below, there is the question of how can you describe mathematically the combining of two images like this ? So, 2 x 2-dimensional sensing in a coplanar configuration to construct 3-dimensional objects. Question: How does this generalize to higher-dimensions. i.e. how many ""eyes"" with m-dimensional sensing, and in what spatial configuration, is required to construct n-dimensional objects ? There is the complication that retinas are not flat - I don't know how that affects things. Some animals have more than two eyes, and it seems that two eyes only construct partial information about the 3D-ness of an object i.e. only info in one plane. Two more eyes on a vertical line could construct some up-down 3D-ness, and another set of eyes that are recessed compared with the others could allow sets of images from different distances to be combined so that the distance to an object can be perceived more accurately.",['geometry']
149862,Angle between two vectors?,"I have been taught that the angle between two vectors is supposed to be their inner product. However, the book I'm reading states: Recall that the angle between two vectors $u	= (u_0,\ldots,u_{n−1})$ and $v = (v_0,\ldots, v_{n−1})$ in $\mathbb{C}^n$ (the complex plane) is just a scaling factor times their inner product . What is a ""scaling factor""?","['vector-spaces', 'linear-algebra']"
149870,Proving Injectivity,"The problem is to show the function $f:\mathbb{R}^2\rightarrow\mathbb{R}^2$ given by $$f(x,y)=(\tfrac{1}{2}x^2+y^2+2y,\,x^2-2x+y^3)$$ is injective on the set $$M=\{(x,y)\in\mathbb{R}^2:|x-1|+|y+1|<\tfrac{1}{6}\}.$$ My idea is to consider the following map (here, $u,v\in\mathbb{R}^2$): $$\phi_v(u)=u-f(u)+v,\quad v\in M$$ If I manage to show that $\phi_v:D\rightarrow D$ is well-defined for some closed sets $\phi_v$ is a contraction (Lipschitz constant $<1$) on $D$ then by the Contraction Mapping Theorem, $\phi_v$ has a unique fixed point. Hence, $v$ has a unique preimage $u$ for each $v$. i.e. $f$ is injective as desired. But I ran into troubles when I attempted to find a suitable closed set $D$. Obviously it depends on the domain $M$. $M$ given here is really weird so I am not too sure how to proceed.","['functions', 'real-analysis']"
149872,How to show $|\sin(x+iy)|^2=\sin^2x+\sinh^2y$,"How would I show that $|\sin(x+iy)|^2=\sin^2x+\sinh^2y$? Im not sure how to begin, does it involve using $\sinh z=\frac{e^{z}-e^{-z}}{2}$ and $\sin z=\frac{e^{iz}-e^{-iz}}{2i}$?","['trigonometry', 'complex-numbers']"
149893,The behavior of a density function at infinity,"Give $f$ the density function of a random variable. Does it follow that 
$$\lim_{x\rightarrow \pm\infty}xf(x)=0?$$ I really appreciate it if someone can give me a clue.","['probability-theory', 'analysis']"
149901,Geometric interpretation of Young's inequality,"Is there a geometric interpretation of Young's inequality, $$ab \leq \frac{a^{p}}{p} + \frac{b^{q}}{q}$$ with $\dfrac{1}{p}+\dfrac{1}{q} = 1$? My attempt is to say that $ab$ could be the surface of a rectangle, and that we could also say that: $\dfrac{a^{p}}{p}=\displaystyle \int_{0}^{a}x^{p-1}dx$, but them I'm stuck.","['inequality', 'calculus', 'visualization', 'young-inequality', 'intuition']"
149912,Analogy between trace pairing on a number field and the dot product.,"How is the trace pairing function $(x,y) \mapsto Tr(xy)$ on a number field an analogue of the dot product in euclidean space? (This is a view shared by Keith Conrad and can be found in his notes Discriminants... and The Different Ideal )","['geometry', 'field-theory', 'algebraic-number-theory', 'number-theory']"
149920,linear subspace of dual space,"$X$ is a locally convex space and $X^*$ is its dual space with weak* topology or uniform topology. If $H$ is a linear subspace of $X^*$ such that $\bar H  \ne X^*$, then is there a non-zero $x \in X$ such that $f(x)=0$ for all $f \in H$?","['locally-convex-spaces', 'functional-analysis']"
149956,Binomial fraction sum to infinity,"Compute the limit: $$\lim_{n\to\infty} \sum_{k=0}^n \frac {\dbinom{n}{k}}{\dbinom{2n-1}{k}}$$ Here i tried to give some k values to the sum hoping to see a possible pattern, 
but i didn't figure out any such a pattern. I wonder if there is an easy way to
solve such a limit.","['binomial-coefficients', 'limits']"
149963,Algorithm for a conjugating matrix?,"Suppose that $A_{1},\ldots, A_{k}$ are rational $n\times n$ matrices that generate a finite group.  It is a well-known fact that there is a matrix $T$ such that $T^{-1}A_{1}T,\ldots, T^{-1}A_{k}T$ are integer matrices (and so generate an isomorphic subgroup of $\operatorname{GL}_{n}(\mathbb{Z})$.  Is there an algorithm which takes the given matrices $A_{i}$ and outputs a suitable matrix $T$?","['linear-algebra', 'group-theory']"
149966,"Set builder notation, left or right of :| convention","Set builder notation which specify a subset such as $Z$ or $R$ tend to put this condition on the left, whereas other conditions go on the right. $$\{ x ∈ Z : x > 0 \}$$ Why is this preferred over, say: $$\{ x : x > 0  \textrm{ and } x ∈ Z\}$$ I notice that if the left-side has more than a simple term it tends not to have the contains expression. For example: $$\{ x + 1 : x > 0 \}$$ In such a form could a $Z$ appear on the left, or must it appear on the right if it needs to be specified? In what situations can the conditions go on the left, as opposed to the right of the $:$ operator?","['notation', 'elementary-set-theory']"
149968,A set of positive measure contains a product set of positive measure?,"The following question arose in my research on variations on Bell's theorem . I have tried to solve it on my own, but my weak background in measure theory apparently doesn't allow me to do so within a reasonable amount of time. This is my first post on any SE site. Since the question is probably not research-level, I'm posting it here instead of on MO. Let $(\Omega_1,\mathcal{F}_1,P_1)$ and $(\Omega_2,\mathcal{F}_2,P_2)$ be probability spaces. The product $\Omega_1\times\Omega_2$ comes equipped with the standard product $\sigma$-algebra and product measure. If $A\subseteq \Omega_1\times\Omega_2$ is of positive measure, do there exist $B_1\subseteq\Omega_1$ and $B_2\subseteq\Omega_2$ of positive measure such that $B_1\times B_2\subseteq A$? If this turns out to be false, then what about the same question with $B_1\times B_2\subseteq_{a.s.} A$ instead of exact containment? Edit : I have accepted @leslie's answer as it resolves the original problem. I still hope for a positive answer to the revised question, where I allow $A$ to be modified by a set of measure zero. Can anyone say anything about this?","['probability-theory', 'measure-theory']"
149981,existence of Lebesgue integral,"Hi, I have a question on my homework. For each positive integer $n$, let $f_n:\mathbb{R}\to\mathbb{R}$ be integrable, $ ~f_n\geq 0$ and $f_n(x)\to f$ pointwise. I need to show that if $\int f_n$ converges to some finite $c\geq 0$, then $\int f$ exists and $0\leq\int f\leq c$. I am thinking that for an arbitrary function $f$ , the Lebesgue integral exists iff $f$ is Lebesgue integrable or $\int f$ is infinite (is this correct?). However, for a nonnegative function $f$, the Lebesgue integral always exists and $\int f = \sup\{\int g：0\leq g\leq f, ~~g$ bounded and supported on a set of finite measure$\}$. If what I am thinking is correct, then the question seems quite straigtforward. We have $f_n(x)$ converges to $f(x)$ for every $x$ and $f_n\geq 0$ for every $n$. So $f$ is nonnegative everywhere and $\int f$ exists since the Lebesgue integral exists for all nonnegative functions. That $0\leq\int f\leq c$ just follows from the fact that $f \leq 0$ and Fatou's Lemma. Can someone tell me under what condition the Lebesgue integral exists? Is my attempt correct?","['measure-theory', 'integration', 'real-analysis']"
149986,Predicate for intersection of polygons,"What is a (computationally) fast way of determining whether two polygons intersect, without actually computing this area of intersection? Definitions polygon: a counterclockwise simply connected sequence of points. intersects: have a nonzero area of overlap. An example predicate would be that when all segments from p1 are intersected with all segments of p2, there are at least two intersections. But this is an O(N^2) predicate to evaluate.",['geometry']
149995,Removing redundant sets from an intersection,"Let $I$ be a non-empty set and $(A_i)_{i\in I}$ a family of sets. Is it true that there exists a subset $J\subset I$ such that $\bigcap_{j\in J}A_j=\bigcap_{i\in I}A_i$ and, for any $j_0\in J$, $\bigcap_{j\in J-\{j_0\}}A_j\neq\bigcap_{j\in J}A_j$? If $I=\mathbb{N}$, the answer is yes (if I am not mistaken): $J$ can be constructed by starting with $\mathbb{N}$ and, at the $n$-th step, removing $n$ if that does not affect the intersection. What if $I$ is uncountable? I guess the answer is still ""yes"" and tried to prove it by generalizing the above approach using transfinite induction, but I failed. The answer ""yes"" or ""no"" and a sketch of a proof (resp. a counterexample) would be nice.",['elementary-set-theory']
150010,Maximizing a quadratic function subject to $\| x \|_2 \le 1$,"Consider the $n$-dimensional quadratically constrained quadratic optimization problem $$\begin{array}{ll} \text{maximize} & \frac12 x^T A x + b^T x\\ \text{subject to} & \| x \|_2 \le 1\end{array}$$ where $A$ is a symmetric $n\times n$ matrix that may be indefinite. Given the symmetry of the constraint, is there a nice closed-form solution, perhaps in terms of the eigendecomposition of $A$?","['optimization', 'qcqp', 'non-convex-optimization', 'linear-algebra']"
150016,Edge coloring of the cube,"We have a cube and we are coloring its edges. There are three colors available. We say that the two colorings are the same if one can obtain a second by turning cube and permuting colors. Find the number of different colorings. Any ideas? I've found Pólya enumeration theorem ,
but it's difficult to understand for me, also this approach does not take into account the permutation of colors...","['coloring', 'abstract-algebra', 'combinatorics']"
150023,Limit of $\left(\sum\limits_{k=0}^n \frac{{(1+k)}^{k}-{k}^{k}}{k!}\right)^{1/n}$,"Calculate the following limit:
  $$\lim_{n\to\infty} \left(\sum_{k=0}^n \frac{{(1+k)}^{k}-{k}^{k}}{k!}\right)^{1/n} $$ First of all, I am just looking for any helping hint that will allow me to solve
it. I thought of Stirling's formula, but I am not convinced that it helps me here. Maybe if I had $n!$ when $n$ goes to infinity it would work, otherwise I doubt I can do
something about it. Not sure how to approach it, yet.","['sequences-and-series', 'limits']"
150036,Normal distributions obey central limit theorem,"Let $X_1,\dots,X_n$ be independent random variables, each normally distributed as $X_k\sim N(m_k;\sigma^2_k)$. Let $S_n = \sum_{k=1}^n X_k - m_k$ and $T_n = \frac{S_n}{\sqrt{\operatorname{Var}(S_n)}}$. We wish to show that $\lim_{n\to\infty} T_n \sim N(0;1)$. I've laboriously proven that $T_n \sim N(m; \sigma^2)$ where $m=\sum_k m_k$ and $\sigma^2=\sum_k \sigma^2_k$. So now I'm wondering if I'm supposed to assume that the $\lim_{n\to\infty}m=0$ and similarly $\sigma^2\to 1$, which I don't really see a strong justification for. Is this what I'm supposed to do? What's the justification for it? (Note this is exercise 14.31.7 in Apostol's Calculus II. Looking online it seems like some other places don't define CLT as it approaches standard normal, just normal distribution of some mean and variance. So this could be an unusual definition he's using.)","['statistics', 'calculus', 'probability-theory']"
150050,How to determine $\mathbb{E}$ for which a maximum defined function is a bijection?,"Assume that $f\colon\mathbb{E}\subset\mathbb{R}\rightarrow\mathbb{R}$ , $f(x)=\max\lbrace2x-5,x-2\rbrace$ . Determine $\mathbb{E}$ for which $f$ is a bijection. I was thinking it is $\mathbb{R}$ ,  but I'm not sure. Can I get a confirmation and a way to prove it, please? Thank you very much!","['calculus', 'algebra-precalculus', 'functions']"
150051,analytic extension,Suppose that $f$ is analytic in the annulus $1<|z|<2$ and there exist a sequence of polynomials converging to $f$ uniformly on every compact subset of this annulus.  Show $f$ has an analytic extension to all of the disc $|z|<2$.,['complex-analysis']
150053,A differential equation introduced from a physics problem,"Try to solve the equation
\[
c_1 \sqrt{f(x)} + c_2f'(x) = c_3 \sqrt{f(x)} f''(x)
\]
holds for all $x \ge 0$.
There might be another condition: $f(0) = 0$. It is introduced from a high school physics exam problem on $s, v, a$. The answer to the problem makes a hypothesis that the motion is uniformly accelerated motion and checks and says that it is true. It is equivalent to only check when $f(x) = (\alpha x + \beta)^2$ where $\alpha, \beta \ge 0$, then the equation becomes
\[
c_1 (\alpha x + \beta) + 2c_2 \alpha (\alpha x + \beta) = 2c_3 \alpha (\alpha x + \beta)
\]
and find a solution with $\alpha, \beta \ge 0$, saying proved . I don't think it's a rigorous proof. I wonder whether the equation can be solved rigorously? Thanks for help.","['ordinary-differential-equations', 'calculus']"
150059,Alternative proof of the limitof the quotient of two sums.,"I found the following problem by Apostol: Let $a \in \Bbb R$ and $s_n(a)=\sum\limits_{k=1}^n k^a$. Find $$\lim_{n\to +\infty} \frac{s_n(a+1)}{ns_n(a)}$$ After some struggling and helpless ideas I considered the following solution. If $a > -1$, then $$\int_0^1 x^a dx=\frac{1}{a+1}$$ is well defined. Thus, let $$\lambda_n(a)=\frac{s_n(a)}{n^{a+1}}$$ It is clear that $$\lim\limits_{n\to +\infty} \lambda_n(a)=\int_0^1 x^a dx=\frac{1}{a+1}$$ and thus $$\lim_{n\to +\infty} \frac{s_n(a+1)}{ns_n(a)}=\lim_{n \to +\infty} \frac{\lambda_n(a+1)}{\lambda_n(a)}=\frac{a+1}{a+2}$$ Can you provide any other proof for this? I used mostly integration theory but maybe there are other simpler ideas (or more complex ones) that can be used. (If $a=-1$ then the limit is zero, since it is simply $H_n^{-1}$ which goes to zero since the harmonic series is divergent. For the case $a <-1$, the simple inequalities $s_n(a+1) \le n\cdot n^{a+1} = n^{a+2}$ and $s_n(a) \ge 1$ show that the limit is also zero.)","['sequences-and-series', 'integration', 'limits']"
150066,"Finding the left and right cosets of $H=\{(1),(12),(34),(12) \circ(34)\}$ in $S_4$","I have an exercise where I am supposed to find the left and right cosets of $H = \{(1), (12), (34), (12) \circ(34)\}$ in $S_4$ . But how do I generate the cosets? As I have understood it you are supposed to pick a number that is not in the set $H$ and multiply it with every number in $H$ . But this does not exactly give the right answer. I would really appreciate it if someone gave an easy to understand explanation of how to generate the left and right cosets.","['group-theory', 'symmetric-groups']"
150067,What is a cusp parameter?,"I was reading this paper , and on the first page they define a cusp form as $$
f(z) = \sum_{n > -\alpha} a(n) e^{2\pi i (n + \alpha)z}.
$$ Is this equivalent to the usual definition of a cusp form $$
f(z) = \sum_{n = 1}^\infty a(n) q^n.
$$
where $q = e^{2\pi iz}$? Also what is a cusp parameter?","['modular-forms', 'number-theory']"
150072,Elementary question about the  Stone-Cech compactification,"If $X$ is a Tychonoff space and $\beta X$ is it's Stone-Cech compactification, should $X$ be a dense $G_\delta$ subset of $\beta X$?",['general-topology']
150097,Must probability density be continuous?,"From other materials that I've read, the probability density of a continuous random variable must itself be continuous. Is this correct? If it is, I don't understand why that would be so, why can't the probability change abruptly?",['probability']
150107,How to show $\sum_{n=0}^m \frac{1}{n+1}\binom{m}{n} = \frac{2^m-1}{m+1}$,"This is the homework, and it shouldn't be difficult, but I can't find the proper identity that would help me simplify this sum: $$\sum_{n=0}^m \frac{1}{n+1}\binom{m}{n}$$ Through calculating the results, I can see that the simplified version is: $$\frac{2^m-1}{m+1}$$ But I don't know how to transform the former into the later. You need not give the complete solution (although, that's welcomed too), but the identities needed for the simplification should suffice. EDIT: How I counted: 
$\frac{m!}{(n+1)!(m-n)!}$ repeated $m$ times while $n$ increases from 0 to $m$. You can also see the code here: http://pastebin.com/RJ9jd966","['summation', 'binomial-coefficients', 'combinatorics']"
150108,Finding the inner product given the norm [duplicate],"This question already has answers here : Closed 12 years ago . Possible Duplicate: Norms Induced by Inner Products and the Parallelogram Law So suppose we are given a norm on a vector space. If the Parallelogram law holds does that automatically mean we have the inner product which we can find using the Polarisation identity? Or is showing the Parallelogram law holds not sufficient to show that there exists an associated inner product? Also, given that the Parallelgram law fails, e.g. $\Vert(x_1,x_2)\Vert_1 = |x_1| + |x_2|$ in $\ell^1(2)$, is there any significance in considering the Polarisation identity?",['functional-analysis']
150116,"How to show a compact, closed-range operator on an infinite-dimensional Hilbert space has finite rank, without using the open-mapping theorem?","If $H$ is an $\infty$-dimensional Hilbert space and $T:H\to{H}$ is a compact operator with closed range, how do I show that $T$ has finite rank, without using the open-mapping theorem? (The open-mapping theorem is not in my lecture notes). The definitions I have in my lecture notes are: (Let $B(H)$ denote the space of all bounded operators mapping $H\to{H}$, $K(H)$ denote the space of all compact operators mapping $H\to{H}$, $R(H)$ denote the space of all finite rank operators mapping $H\to{H}$). $T\in{B(H)}$ is compact if the closure of $T(B(0,1))$ is a compact set. $T\in{B(H)}$ has finite rank if $Range(T)=T(H)$ is finite-dimensional. I'm not sure how to do the proof, but I think that the following propositions in my lecture notes could be useful: $T\in{R(H)}$ iff $T\in{B(H)}$ is the norm limit of a sequence of finite rank operators, i.e. $K(H)$ is the closure of $R(H)$. Let $T\in{R(H)}$. Then there is an orthonormal set $\{e_1,...,e_L\}$  s.t.
$$Tu=\sum\limits_{i,j=1}^{L}{c_{ij}(u,e_j)e_i}$$
where $c_{ij}$ are complex numbers. Thank you in advance.","['hilbert-spaces', 'functional-analysis']"
150131,Positivity of a determinant,"I'm stuck to prove the following exercise : Given real numbers $x_1,\ldots,x_n$ and $y_1,\ldots,y_n$, show that 
$$
\det(e^{\large{x_iy_j}})_{i,j=1}^n>0
$$
provided that $x_1<\cdots<x_n$ and $y_1<\cdots<y_n$. Any idea ?","['linear-algebra', 'real-analysis', 'determinant']"
150132,Integral with Bessel function,"Let $n$ be half an odd integer, say $n=k+1/2, k \in \mathbb{N}$. Let $q\geq 1$. I would like to calculate (or approximate) the following integral:
$$
\int_0^{\infty}\left(\sqrt{\frac{\pi}{2}}\cdot 1\cdot 3\cdot 5\cdots (2k+1) \frac{J_{k+\frac 12}(t)}{t^{k+ \frac 12}}\right)^q t\ dt.
$$ Any ideas or references will be very helpful. Thank you.","['special-functions', 'integration', 'approximation-theory', 'approximation', 'bessel-functions']"
150138,Vectors - Find the vector $\vec{c}$ which is orthogonal to $\vec{a}$ and $\vec{b}$ and whose first component is 1,"Find the vector $\vec{c}$ which is orthogonal to $\vec{a}$ and $\vec{b}$ and whose first component is 1 $\vec{a}$ = (0 / 4 / -2), start point: $P$ (2 / -3 / 5), end point: $A$ (2 / 1 / 3) $\vec{b}$ = (-5 / 5 / -1), start point: $P$ (2 / -3 / 5), end point: $B$ (-3 / 2 / 4) I can only assume that $\vec{c}$ is supposed to be an unit vector. What I don't understand, is, how one vector is supposed to be orthogonal to both vectors $\vec{a}$ and $\vec{b}$ at once? Maybe the Point $P$ provides the place for the new vector to be orthogonal to both vectors, but how to find $\vec{c}$ respectively determine its properties (direction, x-, y-, and z-values)? Edit - As suggested by rschwieb here's the solution I worked out: The first component of $\vec{c}$ is $x = 1$, the other ones are unknown, thus: $\vec{c}$ = (1, y, z) Because the vector $\vec{c}$ is orthogonal to the other vectors $\vec{a}$ and $\vec{b}$, the scalar products are: $\vec{c} * \vec{a} = 0$ and $\vec{c} * \vec{b} = 0$. This results in the following system of equations: $\vec{a} * \vec{c} => (0, 4, -2) * (1, y, z) = (0*1) + (4*y) + (-2*z) = 0$ $\vec{b} * \vec{c} => (-5, 5, -1) * (1, y, z) = (-5*1) + (5*y) + (-1*z) = 0$ Which is then simplified to: $4y - 2z = 0$ $-5 + 5y - z = 0$ When calculating this system of equations, the solutions then are y = $\dfrac{5}{3}$ and z = $\dfrac{10}{3}$ Thus, the end result is: $\vec{c} = (1, \dfrac{5}{3}, \dfrac{10}{3})$","['vector-spaces', 'algebra-precalculus']"
150141,Linear independence of roots over Q,"Let $p_1,\ldots,p_k$ be $k$ distinct primes (in $\mathbb{N}$) and $n>1$. Is it true that $[\mathbb{Q}(\sqrt[n]{p_1},\ldots,\sqrt[n]{p_k}):\mathbb{Q}]=n^k$? (all the roots are in $\mathbb{R}^+$) Iurie Boreico proved here that a linear combination $\sum q_i\sqrt[n]{a_i}$ with positive rational coefficients $q_i$ (and no $\sqrt[n]{a_i}\in\mathbb{Q}$) can't be rational, but this question seems to be more difficult..","['galois-theory', 'algebraic-number-theory', 'number-theory']"
150148,A trigonometric-integral inequality,"This problem comes from a discussion with one of my friends: Prove that: $$\displaystyle \lim_{n \to \infty}\int_{1}^{n}{\sin (x)\sin(x^2)}\,{\mathrm dx}< \lim_{n \to \infty}\int_{1}^{n}{\sin(x^2)}\,{\mathrm dx}$$ I wonder if there is a reasonable way to somehow solve such a problem. Thanks.","['inequality', 'calculus', 'integral-inequality', 'limits']"
150154,How do I simplify this trig expression?,How do I simplify the expression of $\cos(2x+3x)\cos x+\sin(3x)\cos\left(\frac x2+x\right)$ ?,['trigonometry']
150162,Ranking System and Separated Populations,"I'm trying to modify the ELO ranking system formulas to adapt them to eSport (electronic sports, but more specifically Starcraft II). (The reason I'm using ELO, is the straight forward concept and the pretty easy maths it is using. I might change though if I find a solution that can't be implemented in ELO.) One of the big problems I have is the following : How do you rank two separate populations that encounter each other very rarely (basically players from different geographical regions), in the same raking ? Little explanation. Imagine that you have one player from England and one player from South-Korea, both have say ""2700"" rating. Now the problem is that you can't say that they have the same ""skill"" since they play in two different environments populated with different players that have a different level of skill. (In this particular use of the system (Starcraft II), about 10% of the games correspond to ""cross-population"" games. And in those 10%, I would say that the players are generally the same and correspond to roughly 20% of the total number of players in the population they are part of.) I looked at quite a lot of other ranking systems like Chessmetrics and Glicko I-II, but none of them seem to solve the problem. Most likely because they were designed for a more ""global"" game (Chess) and thus don't have this issue with ""separated populations"". The only potential solution I could think of was to inflate the ""K"" factor in the ELO formula for those particular ""cross-population"" games. This would increase the ""weight"" of this particular case. But honestly, I don't really like this solution ... Thank you a lot in advance ! --Awake","['statistics', 'algorithms']"
150192,Solutions of $p!q! = r!$,"The title says it all, more or less. Obviously, there are infinitely many ""trivial"" integral solutions of the form $p=n, q=(n!-1), r= n!$. How many non-trivial solutions are there? I came across this about ten years ago; as far as I can tell, it hasn't appeared here before, so I thought that it might be of interest. I'm actually most interested in finding whether there was any progress made since Florian Luca's 2007 article.","['factorial', 'diophantine-equations', 'number-theory']"
150218,Name for a non-square matrix with ones along the main diagonal? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Is there a name for a matrix that would be the identity matrix, except that it's not square?  In other words, it has ones along the main diagonal, and zeroes off of the main diagonal.  But as it's not a square matrix, it is not the identity matrix.","['matrices', 'linear-algebra']"
150242,Teenager solves Newton dynamics problem - where is the paper?,"From Ottawa Citizen (and all over , really): An Indian-born teenager has won a research award for solving a
  mathematical problem first posed by Sir Isaac Newton more than 300
  years ago that has baffled mathematicians ever since. The solution devised by Shouryya Ray, 16, makes it possible to
  calculate exactly the path of a projectile under gravity and subject
  to air resistance. This subject is of particular interest to me.  I have been unable to locate his findings via the Internet. Where can I read his actual mathematical work? Edit: So has he written an actual paper, and if so, will anyone get to read it?","['ordinary-differential-equations', 'classical-mechanics', 'physics']"
150251,Calculate the volume between $z=x^2+y^2$ and $z=2ax+2by$,"I'm trying to calculate the volume between the surfaces $z=x^2+y^2$ and $z=2ax+2by$ where $a>0,b>0$. Here's what I've tried: First I noticed the projection of the volume to the xy plane is a circle: $(x-a)^2+(y-b)^2\leq a^2+b^2$. Using this I simplified the calculation of the integral for the volume a little. Marking $B$ as the circle we get that the volume is: $$\iint_{}^{B} (2ax+2ay-x^2-y^2) = \iint_{}^{B} (a^2+b^2)-\iint_{}^{B} ((x-a)^2+(y-b)^2) $$ Using the symmetry of the circle we get: $$\iint_{}^{B} ((x-a)^2+(y-b)^2) = 2\iint_{}^{B} ((x-a)^2)$$ And we can also use the formula for the area of a circle to get: $$\iint_{}^{B} (a^2+b^2) = \pi (a^2+b^2)^2$$ So all I have left to do is calculate $\iint_{}^{B} ((x-a)^2)$, but this is where I get stuck. Trying to do it using iterated integrals becomes too complex (we have only covered Cartesian coordinates, so I can't use something like polar coordinates here). I know the result is supposed to be $(1/2)\pi (a^2+b^2)^2$. Assistance would be appreciated. Thanks!","['multivariable-calculus', 'integration']"
150268,Tensor product of Hilbert Spaces,"I am following this link under ""definitions"" I need to see why the suggested inner product on the pre-Hilbert space $H_1$ tensor $H_2$ is well defined.  Recall that the fundamental tensors are a spanning set, but not a linearly independent one, hence not free in the category of vector spaces.  How do I know that this definition is consistent no matter what representation of an element of the tensor space I give?","['linear-algebra', 'operator-theory', 'abstract-algebra', 'analysis']"
150297,From injective map to continuous map,"Let $X$ and $Y$ metric spaces, $f$ is an injective from $X$ to $Y$, and $f$ sets every compact set in $X$ to compact set in $Y$. How to prove $f$ is continuous map? Any comments and advice will be appreciated.","['general-topology', 'functional-analysis', 'real-analysis', 'analysis']"
150306,Prove that the normed space $L^{\infty}$ equipped with $\lVert\cdot\rVert_{\infty}$ is complete. [duplicate],"This question already has an answer here : Closed 12 years ago . Possible Duplicate: Understanding proof of completeness of $L^{\infty}$ Most of the materials I have in Real Analysis consider this statement as a trivial one: ""The normed space $L^{\infty}$ equipped with $\lVert\cdot\rVert_{\infty}$ is  complete"".
But to my suprise I can't see the triviality. I am searching for it now... Anybody with hint?","['measure-theory', 'banach-spaces', 'real-analysis']"
150319,Find the distribution of a transformation,"Let $$f_X (x, \theta) = \frac{1}{\theta} x^{\frac{1}{\theta} - 1}, \; x \in (0, 1)$$
find the distribution of:
$$Y = - \frac{1}{\theta} \ln X$$ 
[Solution provided: $Y \sim \mathcal{E}(1)$ ] I did: $$P(Y = y) = P(- \frac{1}{\theta} \ln X = y) = P( X = e^{-\theta y}),\; y \in (0, +\infty)$$
and so:
$$f_Y(y, \theta) = f_X(e^{-\theta y}, \theta) = \frac{1}{\theta} e^{-y(1-\theta)}$$ Am I missing something? Is this distrubition a $\mathcal{E}(1)$?If so why?","['statistics', 'probability-distributions']"
150329,Is a covering space of a manifold always a manifold,"Assume $M$ is a manifold and $q : E \to M$ is a covering map . I have been told a few times that a covering space of a manifold is again a manifold. Indeed, it is easy to verify that $E$ is both Hausdorff and locally euclidean. I am worried about whether $E$ needs to be second countable. If $E$ is not connected, then it does not need to be second countable. Take the standard covering map $\coprod_{i \in \mathbb{R}} M \to M$. Question: If $E$ is connected, then why is it second countable?","['general-topology', 'covering-spaces', 'manifolds']"
150330,Presentation of a subgroup of a quotient,"This is probably elementary but I know that in group theory the devil is in the details so I want to check. Assume I've a finitely generated group $G$ and a normal subgroup $U$ (if it does matter, in my situation $G$ is a semidirect product of $U$ by some $H$). Let $g_0,\dots,g_n$ be the generators of $G$. Assume that I know a presentation of $U$ and that $g_0 \not \in U$ (or even that $g_0 \in H$). Then, I want to find a presentation of the image of $U$ in the quotient $G/\langle g_0\rangle$. Formally what I'm looking for is the intersection between the normal closure of $g_0$ and $U$ but it's hard to make it explicit. On the other hand, it seems to me that the only way taking the quotient can add relations is as follows: since $U$ is normal, $g_0$ acts on it by conjugation, so for $u\in U$, let $w_u$ be $g_0ug_0^{-1}$ written as a word in the generators of $U$. Then, taking the quotient by $g_0$ forces this action to be trivial, hence add the relation
$$w_u\equiv u$$ Indeed I believe that there are no other new relations but didin't manage to write down a rigorous proof.",['group-theory']
150332,How to measure the clustering property of a sequence,"For a sequence of numbers with increasing order, $a_1 < a_2, \dots < a_n$, I want to know a measure to describe the the extend of clustering in the sequences. For instance, a sequence like $1, 2,3,4, 100, 101,102,103$ and another sequence $10, 12, 32, 45, 66,77, 89,102$, it is clear to see the first sequence have higher clustering property.","['sequences-and-series', 'probability', 'combinatorics']"
150338,Simple $d^2 y/dx^2$ - don't know what I'm missing,"I'm studying some Calculus on my own. I get what appears to be the wrong answer for this one implicit differentiation exercise, and I don't know why. I have to find $\frac {d^2 y}{dx^2}$ of  $y^2-2x = 1-2y$. I calculate $\frac{dy}{dx} = \frac{1}{1+y}$ and from there I get $\frac {d^2 y}{dx^2} = \frac{-y'}{(1+y)^2} = -\frac{1}{(1+y)^3}$ Now, Wolfram Alpha tells me I got $f'$ right but $f''$ wrong. It says $\frac{\delta^2y(x)}{\delta x^2} = - \frac{1}{2(1+x)(1+y)}$ WA hasn't steered me wrong so far. Pointers to where I'm going wrong would be appreciated.","['implicit-differentiation', 'calculus', 'derivatives']"
150348,Radius of convergence of Power Series!,"Given two power series $$\sum_{n=0}^{\infty} a_nx^n, \sum_{n=0}^{\infty} b_nx^n$$ with convergent radius $R_{1}$ and $R_{2}$ respectively. Suppose $R_{1}<R_{2}$,now what about the convergent radius of $\sum_{n=0}^{\infty} (a_n+b_n)x^n$","['power-series', 'real-analysis', 'analysis']"
150354,Area of circle cut by line,"Say I have a circle $x^2+y^2=R^2$ and a line $2ax+2by=R^2$ ($a,b>0$). How might I go about measuring the area of the smaller part of the circle cut off by the line? (This question is relevant to Calculate the volume between $z=x^2+y^2$ and $z=2ax+2by$ ) Thanks! P.S. I'm not sure if this question is correctly tagged. Please correct me if I tagged it wrongly.",['multivariable-calculus']
150357,Open properties of quasi-compact schemes,"I am following Ravi Vakil's Math 216: Foundations of Algebraic geometry notes , and there is a remark following an exercise that I don't understand at all, and if anyone could enlighten me then that would be brilliant. The exercise asks one to show that if $X$ is a quasicompact scheme, then every point has a closed point in its closure, which is clear from the preceding exercise asking to show that $X$ is quasicompact if and only if it can be written as a finite union of affine schemes. These I am fine, as well as the following implication that every nonempty closed subset of $X$ contains a closed point. However, then the notes then go on to state that this will be used in the following way: If a property $P$ is open (that is, if some point $x$ has $P$, then there exists an open neighbourhood $U$ of $x$ such that all points in $U$ have $P$), then to check that all points of a quasicompact scheme have $P$, then it suffices to check only the closed points. I do not seem to be able to see how this follows at all. It seems to me that everything in the exercises is regarding closed points being in closures, and to show the remark, I want to show that other points are in (all) open neighbourhood(s) if closed points. These seem relatively distinct to me - is this wrong? These comments/exercises are on pages 139-140 of the notes.","['algebraic-geometry', 'schemes']"
150360,"Logarithms - Find the solution of $\ln(x^2+1) = \ln(x) + 2$, how to isolate $x$ in a meaningful way?",When solving $\ln(x^2+1) = \ln(x) + 2$ I'm getting stuck at $e^2 = \dfrac{x^2+1}{x}$ How do I isolate $x$?,"['logarithms', 'algebra-precalculus']"
150373,Space of $T$-invariant probability measures is compact.,I'm trying to show that the space of $T$-invariant probability measures is compact in the weak* topology ($T$ is some measurable transformation from a compact metric space to itself). I'm trying to use a functional analysis method as that's what I'm most comfortable with. So suppose $m_n$ is a sequence of $T$-invariant measures converging to some measure $m$. Is it correct that: $$\int f dm = \lim_{n \to \infty} \int f dm_n = \lim_{n \to \infty} \int f(T) dm_n = \int f(T) dm$$ with $f$ any continuous function from $X$ to reals. from this we can infer that $m$ is $T$-invariant and hence the space of $T$-invariant measures is a closed subset in a compact space hence compact?,"['measure-theory', 'ergodic-theory']"
150391,Evaluate $\lim\limits_{n\to\infty}\frac{\sum_{k=1}^n k^m}{n^{m+1}}$,"By considering: $$\lim_{n\to\infty}\frac{\sum_{k=1}^n k^1}{n^{2}} = \frac 1 2$$
$$\lim_{n\to\infty}\frac{\sum_{k=1}^n k^2}{n^{3}} = \frac 1 3$$
$$\lim_{n\to\infty}\frac{\sum_{k=1}^n k^3}{n^{4}} = \frac 1 4$$ Determine if this is true:
$$\lim_{n\to\infty}\frac{\sum_{k=1}^n k^m}{n^{m+1}} = \frac 1 {{m+1}}$$ If it is, prove it. If it is not, evaluate $\lim\limits_{n\to\infty}\frac{\sum_{k=1}^n k^m}{{m+1}}$.","['algebra-precalculus', 'limits']"
150393,"Showing Linear Independence $\{1,\sin x,\cos x\}$",I don't know how to show that $a+b\sin(x)+c\cos(x)=0$ has no solutions... How should I go about doing this? Is the only way using the $\sin^2+\cos^2=1$ identity and substituting that?,"['trigonometry', 'linear-algebra']"
150407,The A^1-localization in the unstable motivic category,"I am currently trying to study $\mathbb{A}^1$-homotopy theory and I have a question about the construction of the unstable motivic category. Here is roughly the construction I try to understand : 1) Fix a noetherian scheme of finite Krull dimension $S$, and denote the category of smooth schemes of finite type over it by $\text{Sm}/S$. It is (essentially) small due to the finiteness condition. Endow it with the Nisnevich topology. OK. 2) The category of simplicial presheaves $[\text{Sm}/S^{\text{op}}, \text{sSet}]$, denoted by $M_S$, has (at least) 3 local model structures, the injective (Jardine), the projective (Dugger, Hollander, Isaksen) and the flasque (Isaksen). The weak equivalences in these structures are the local weak equivalences, which can be characterized either by being the maps inducing isomorphisms on all sheaves of homotopy groups (Jardine), or the maps inducing isomorphisms on all stalks. These models can be seen as a left Bousfield localization of the global model structures. Similar models hold by restricting to simplicial sheaves instead of presheaves, and they are Quillen equivalent by sheafification-embedding. OK. 3) There still is a localization to be done, and this is the one I don't quite understand. It is the $\mathbb{A}^1$-localization, or the localization with respect to the interval. Here is what I understand : In ""$\mathbb{A}^1$-homotopy theory of schemes"" of Morel and Voevodsky : They do a more general construction for any site with interval. Everything is done ""by hand"", Theorem 2.2.5 is the left Bousfield localization, Theorem 2.3.2 is the localization of the simplicial sheaves ""with respect to the interval"", and Definition 3.2.1 is the case of interest, the site $\text{Sm}/S$ with the interval $\mathbb{A}^1$. Their model structure seems to be a left Bousfield localization of the category of simplicial sheaves at the unique map $\mathbb{A}^1 \to \ast$. Magically, all the projections $\mathbb{A}^1 \times F \to F \in M_S$ are weak equivalences ? So the localization can be formally done by apllying a left Bousfield localization ? Moreover, this is done on simplicial sheaves, does a similar result hold for simplicial presheaves ? I would be very happy to hear that in the left Bousfield localization of some local model structure on $[\text{Sm}/S^{op},sSet]_{\text{Nis}}$ at the unique map $\mathbb{A}^1 \to \ast$, all the maps $\mathbb{A}^1 \times F \to F$ of simplicial presheaves are weak equivalences. Moreover, is this the property we want in the unstable category of motivic spaces ? We could of course try to do a left Bousfield localization at all maps $\mathbb{A}^1 \times F \to F$, but since it is not a set, this does not necessarily exists, a priori. Thanks. Feel free to redirect me to any reference.","['algebraic-geometry', 'homotopy-theory', 'algebraic-topology']"
150416,How do you find the limit of $\lim\limits_{x\rightarrow 0^-}\frac { \arcsin{ \frac {x^2-1}{x^2+1}}-\arcsin{(-1)}}{x}$?,"I'm trying to calculate the following limit, involving $\arcsin$, where $x$ is getting closer to $0$ from the negative side, so far with no success. The limit is:
$$\lim_{x\rightarrow 0^-}\frac { \arcsin{ \frac {x^2-1}{x^2+1}}-\arcsin{(-1)}}{x}$$
it's part of a bigger question, where I should prove that the same expression, but where $x\rightarrow 0$ has no limit. So, I prove that the limits from both sides are different. I already know that the solution to the above question is $(-2)$, but have no idea how to get there. Would appreciate your help!",['calculus']
150420,A mouse leaping along the square tile,"A $n \times n$ square is made of square tiles of dimensions $1\times1$. A mouse can leap along the diagonal or along the  side of square tiles. In how many ways can the mouse reach the right lower corner vertex of the square from the lower left corner vertex of the square leaping exactly  $n$ times? In one of my exam, I encountered a particular version of this problem with $n=5$. With a semi-brute force (case counting) kind of approach I derived the answer as $21$. How to derive the general solution for any $n \in \mathbb{N}$ ?","['recurrence-relations', 'contest-math', 'combinatorics']"
150448,Proof that angle-preserving map is conformal,"Let $\phi: S \to \bar{S}$ be a diffeomorphism between two surfaces in $\mathbb{R^3}$. Such a map is called conformal if for all $p \in S$, and $v_1, v_2 \in T_p(S)$ (the tangent plane) we have $$\langle d\phi_p(v_1), d\phi_p(v_2) \rangle = \lambda^2 \langle v_1, v_2 \rangle_p$$ for some nowhere-zero function $\lambda$. $\phi$ is said to be angle-preserving , if $$\cos(v_1, v_2) = \cos(d\phi_p(v_1), d\phi_p(v_2)),$$ which I take to mean $$\frac{\langle v_1, v_2\rangle}{\lVert v_1 \rVert \lVert v_2 \rVert} = 
\frac{\langle d\phi(v_1), d\phi(v_2)\rangle}{\lVert d\phi(v_1) \rVert \lVert d\phi(v_2) \rVert}
$$ From do Carmo, ""Differential Geometry of Curves and Surfaces"", 4.2/14: Prove that $\phi$ is locally conformal if and only if it preserves angles. The ""only if"" part is obvious, but how can the ""if"" portion be proved (i.e. how does preserving angles imply conformality)?",['differential-geometry']
150472,Showing $\int\limits_a^b h(x)\sin(nx) dx \rightarrow 0$,"Let $h\in C_0([a,b])$ arbitrary, that is $h$ is continuous and vanishes on the boundary.
I want to show that
$\int\limits_a^b h(x)\sin(nx)dx \rightarrow 0$. If $h\in C^1$, integration by parts immediately yields the claim, since $h'$ is continuous and thence bounded on the compact interval, using also the zero boundary condition. However, I believe the statement is also true for all $h\in C_0([a,b])$. My idea is to approximate $h$ by functions $h_m \in C_0^1([a,b])$. Then for all $m$, $$\begin{equation*}
\lim_{n \to \infty} \int h_m(x) \sin(nx) dx = 0.
\end{equation*}$$ $$\begin{align*}
\Rightarrow ~~~ \lim_{n \to \infty} \int h(x)\sin(nx) dx &= \lim_{n \to \infty} \int \lim_{m \to \infty} h_m(x)\sin(nx) dx\\ &= \lim_{m \to \infty}(\lim_{n \to \infty} \int h_m(x)\sin(nx) dx)\\ &= \lim 0 = 0.
\end{align*}$$ This is fine iff the second equality is. In fact, this is two different steps, as three limiting processes are involved. Hence the questions: First, can I make sure that I can interchange the $m$-limit with the integral sign? (Can I assume that $h_m$ converges uniformly? Or use some sort of Dominated Convergence Theorem?) And second, may I swap the $n$-limit for the $m$-limit? (The $n$-limit is in fact $C/n \to 0$) I hope it's not too messy. Many thanks for any kind of help!","['integration', 'real-analysis', 'limits']"
150479,Contour Integral Question,"I'm working through a contour integral question, which is rounded off by finding the integral: $$\int^{\infty}_{0} \frac{x-\sin(x)}{x^3} dx$$ I have already shown that the residue at $0$ of the function $$f(z)=\frac{1+iz-e^{iz}}{z^3}$$ on $\mathbb{C} - \{0\}$ is $\frac{1}{2}$, and that $$\int_{\gamma_R} f(z) dz \longrightarrow 0$$ as $R \longrightarrow 0$ where $\gamma_R:[0,\pi]\rightarrow \mathbb{C}$ is given by $\gamma_R(t)=Re^{it}$. Problem How do I progress from here to finding the required integral? It's an odd function, so clearly all that is left is to integrate from $R$ to $-R$ along the real axis and half it to find the integral, but I can't see how to pull out the '$x-\sin(x)$' and replace '$z^3$' with '$x^3$'. An explanation of how to finish this off would be much appreciated. Thanks in advance.","['complex-analysis', 'contour-integration']"
150480,"Bounding $\int_0^1 f(x) dx$, given $\int_0^1 f'(x)^2 dx \leq 1$ and $f(0) = 0$.","Let $S$ be the set of all differentiable function $f \colon [0,1] \rightarrow \mathbb{R}$ such that $\int_0^1 f'(x)^2 dx \leq 1$ and $f(0) = 0$. Define $J(f) := \int_0^1 f(x) dx$. Show that $J$ is bounded on $S$, find its supremum and see if there is a function $f_0$ in $S$ at which $J$ attains its maximum value.","['integration', 'real-analysis']"
150482,Probability of a random binary string containing a long run of 1s?,"For some fixed $n$, let $p_n$ be the probability that a random infinite binary string contains a run of consecutive $1$s, containing $n$ more $1$s than the total number appearing before the run. For example, if $n=2$, the binary string $010010111100...$ is of the sort we're looking for, but the string $01001011100...$ is not (yet). Call a run of $1$s that is sufficiently long, like the four $1$s in the first string, a satisfying run . Is there any reasonably nice way to compute $p_n$? Here's what I know: We can compute the expected number of satisfying runs in a string. Suppose a satisfying run begins after $k$ preliminary bits. If $k=0$, this occurs with probability $2^{-n}$; otherwise, it occurs with probability $\sum_{i=0}^{k-1} {k-1 \choose i} 2^{-n-k-i}=2^{-n-k}\left(\frac{3}{2}\right)^k$. Summing over all $k$, we get that the expected number of satisfying runs is $3(2^{-n})$, and so $p_n<3(2^{-n})$. You could extend this argument to compute $p_n$ by inclusion-exclusion, but it looks to me like it'd be incredibly ugly. In fact, $3(2^{-n})$ is a pretty good estimate for $p_n$, since the probability of a given string having multiple satisfying runs is so low. By conditioning on the location of the first $0$ in the string, we can get a recurrence relation: $p_n=2^{-n+1}+\sum_{i=1}^{n-1} 2^{-i+1}p_{n+i}$. This is not sufficient to compute $p_n$ on its own, even given some initial values -- the largest index that appears in it is $p_{2n-1}$, so if you try to use it recursively you'll never learn anything about $p_n$ for $n$ even. You might be able to get something out of it by repeatedly substituting it into itself (in the form I've given it in, with the smallest coefficient singled out), and using the bound from 1. to make some kind of limit argument, but this also looks nasty to me. Thoughts? (This originally comes from this Magic: the Gathering scenario, but I hope I've managed to successfully de- Magic it.)","['recurrence-relations', 'probability']"
150496,Radical Locally Solvable?,"A group $G$ is locally solvable if all finitely generated subgroups are
solvable. A group $G$ is locally finite if all finitely generated subgroups are
finite. A group $G$ is virtually locally solvable if it has a locally solvable
subgroup of the finite index. Let be $R(S)=\left\langle T\,;\,T\trianglelefteq G\,,\,T\text{ locally solvable }\right\rangle $ My question are: 1)Is $\,R(S)\,$ locally solvable? 2) If 1) is true: $G$ locally finite, $R(S)$ locally solvable and $G/R(S)$ virtually locally solvable $\Rightarrow G$
virtually locally solvable?",['group-theory']
150498,notation of differentiation in differential geometry,"I can't wrap my head around notation in differential geometry especially the abundant versions of differentiation. Peter Petersen: Riemannian Geometry defines a lot of notation to be equal but I don't really know when one tends to use which version and how to memorize the definitions and properties/identities. Directional derivative or equivalently the action of a vector field $X$ on a function ($f:M\to\mathbb R$): $X\cdot f=D_Xf=df\cdot X\ $, which is also denoted as $L_Xf$ This is mostly clear except why the notation $D_Xf\ $ exists. $grad(f)=\nabla f\ $ the gradiant of $f:M\to\mathbb R$ Has $\nabla$ something to do with the Levi-Civita connection? Lie derivative of vector fields: $L_XY:=[X,Y]= X\cdot Y - X\cdot Y\ $, where the action of one vector field on one another is given by: $X\cdot Y:=D_XY\ $ the directional derivative of $Y$ along an integral curve of the vector field $X$. Also mostly clear. The covariant derivative or Levi-Civita connection $\nabla_XY$ Here my understanding stops and my brain starts dripping out of my ears…
Are there mnemonics or other ways to get into all those ways of thinking about differentiating on manifolds. And why do most books use coordinates - are they necessary I rather like not using $X=\sum_ia^i\partial_i$ for vector fields especially if the author (ab)uses Einstein sum convention.","['notation', 'derivatives', 'differential-geometry']"
150503,$L^p$ space question,"Assume $(X,\mathcal{M},\mu)$ is a measure space and for some $1\leq p<\infty$, $1\leq q<\infty$, $L^p(\mu)\subset L^q(\mu)$.  Prove there is a constant $C>0$ so that $\|f\|_q\leq C\|f\|_p$ for all $f\in L^p(\mu)$. I need help getting started on this.","['measure-theory', 'banach-spaces', 'analysis']"
150504,How demonstrate the Craig representation for the Gaussian probability function?,"The Q-function is defined by : 
$$Q(x) =\frac{1}{\sqrt{2\pi}} \int_{x}^{\infty}\exp(-\frac{u^2}{2}) \ \mathrm{d}u \ \ (1).$$ According to the wiki page there is an alternative form of the Q-function based on John W. Craig 's work  that is more useful is expressed as:
$$Q(x) =\frac{1}{\pi} \int_{0}^{\frac{\pi}{2}}\exp\left(-\frac{x^2}{2\sin^2(\theta)}\right) \ \mathrm{d}\theta  \ \ (2).$$ Craig's proove is based on probabilistic  approach, there for I look for an analytic one. any help will be appreciated. Thanks.","['calculus', 'probability', 'integration']"
150512,Another limit related to pi number,"Find the value of the limit: $$\lim_{n\to\infty} \sum_{k=0}^n \frac{{k!}^{2} {2}^{k}}{(2k+1)!}$$ I'm trying to find out if this limit can be computed only by using high school 
knowledge for solving limits. Thanks.","['real-analysis', 'limits']"
150522,Proof about cubic $t$-transitive graphs,"I am reading ""Algebraic Graph Theory"" by Norman Biggs (1974). On page 119, there is a proposition which says the following: Proposition 18.1: Let $[\alpha]$ be a $t$-arc in a cubic $t$-transitive graph $X$. Then
  an automorphism of $X$ which fixes $[\alpha]$ must be the identity
  automorphism. To understand the Proposition, and the proof, some definitions and lemmas are needed. A $t$-arc is defined as follows: A $t$-arc in a graph $X$ is an ordered set $[\alpha] = 
 (\alpha_0,\ldots, \alpha_t)$ of $t+1$ vertices in $V(X)$, such that
   $\alpha_i \alpha_{i+1} \in E(X)$ and $\alpha_{i-1} \neq \alpha_{i+1}$
   for $1 \leq i \leq t-1$. We can concatenate such arcs by the following definition If $[\alpha]$ is a $t$-arc in a graph $X$ and $[\beta]$ is a $s$-arc in $X$, then we use $[\alpha . \beta]$ to denote the $(t+s+1)$-arc  $(\alpha_0,\ldots,\alpha_t,\beta_0,\ldots,\beta_s)$, provided that $\alpha_t \beta_0 \in E(X)$, $\alpha_{t-1} \neq \beta_0$ and $\alpha_{t} \neq \beta_1$. We also need the term succesive arcs Let $[\alpha]$ and $[\beta]$ be any two $s$-arcs in a graph $X$. We say that $[\beta]$ is a successor of $[\alpha]$ if $\beta_i = \alpha_{i+1}$ $(0 \leq i \leq s-1)$. We also need a Lemma which states Lemma 17.4: Let $X$ be a connected graph in which the degree of each vertex is at least three. If $s \geq 1$ and $[\alpha],[\beta]$ are any two $s$-arcs in $X$, then there is a finite sequence $[\alpha^{(i)}]$ $(1  \leq i \leq l)$ of $s$-arcs in $X$ such that $[\alpha^{(1)}] = [\alpha]$, and $[\alpha^{(l)}] = [\beta]$, and $[\alpha^{(i+1)}]$ is a successor of $[\alpha^{(i)}]$ for $1 \leq i \leq s-1$. and at last a Theorem which says Theorem 17.5: Let $X$ be a connected graph, where all vertices in $V(X)$ are at least 3 and let $[\alpha]$ be a $t$-arc in $X$. Suppose the vertices adjacent to $\alpha_t$ are $\alpha_{t-1}$ and $v_1,v_2,\ldots,v_l$, and let $[\beta^{(i)}]$ denote the $t$-arc $(\alpha_1,\alpha_2,\ldots,\alpha_t,v_i)$ for $1 \leq i \leq l$, so that each $[\beta^{(i)}]$ is a successor of $[\alpha]$. Now $Aut(X)$ is transitive on $t$-arcs if and only if there are automorphisms $g_1,g_2,\ldots,g_l$ in $Aut(X)$ such that $g_i[\alpha] = [\beta^{(i)}] (1 \leq i \leq l)$. The proof of the proposition goes as follows: Proof of Proposition 18.1: Suppose $f$ is an automorphism fixing $\alpha_0,\alpha_1,\ldots,\alpha_t$; if $f$is not the identity, then $f$ does not fix all $t$-arcs in $X$. Thus, it follows from Lemma 17.4 that there is some $t$-arc $[\beta]$ such that $f$ fixes $[\beta]$, but $f$ does not fix both successors of $[\beta]$. In fact, if $\beta_{t-1},u_1,u_2$ are the vertices adjacent to $\beta_t$, then $f$ must interchange $u_1$ and $u_2$. Let $w \neq \beta_1$ be a vertex adjacent to $\beta_0$. Since $X$ is $t$-transitive there is an automorphism $h \in Aut(X)$ taking the $t$-arc $(w,\beta_0,\ldots,\beta_{t-1})$ to $[\beta]$, and we may suppose the notation chosen so that $h(\beta_t) = u_1$. Then $h$ and $fh$ are automorphisms of $X$ taking the $(t+1)$-arc $[w.\beta]$ to its two successors, and by Theorem 17.5, $Aut(X)$ is transitive on $(t+1)$-arcs. This contradicts our hypothesis, and so we must have $f = 1$. I have some problem understanding parts of the proof. The first thing, which is not really essential for proving the proposition, is the part: In fact, if $\beta_{t-1},u_1,u_2$ are the vertices adjacent to $\beta_t$, then $f$ must interchange $u_1$ and $u_2$ The other problem, which is quite essential to the proof, is the part: Since $X$ is $t$-transitive there is an automorphism $h \in Aut(X)$ taking the $t$-arc $(w,\beta_0,\ldots,\beta_{t-1})$ to $[\beta]$, and we may suppose the notation chosen so that $h(\beta_t) = u_1$. Then $h$ and $fh$ are automorphisms of $X$ taking the $(t+1)$-arc $[w.\beta]$ to its two successors I get why there must be such a $h$, taking $(w,\beta_0,\ldots,\beta_{t-1})$ to $[\beta]$. But I do not get, why we can (without loss of generality) assume that $h(\beta_t)$ is a neighbor of $\beta_t$. Thus, I do not see how the other part; that $h$ and $fh$ are automorphisms of $X$ taking the $(t+1)$-arc $[w.\beta]$ to its two successors is true. This question has become rather long, and I have surely missed a definition of something. Everything in gray, can be found in Biggs 1974, on pages 112-115. I have understood the proof of Theorem 17.5, but the proof of Proposition 18.1 uses some arguments, which are non-obvious to me.","['group-theory', 'algebraic-graph-theory']"
150526,Finding the Dual Basis,"Define the four vectors in $\mathbb{R}^4$ by $$v_1=\left( \begin{array}{ccc}
1 \\
0 \\
0 \\
0 \end{array} \right),
v_2=\left( \begin{array}{ccc}
1 \\
1 \\
0 \\
0 \end{array} \right),
v_3=\left( \begin{array}{ccc}
1 \\
1 \\
1 \\
0 \end{array} \right),
v_4=\left( \begin{array}{ccc}
1 \\
1 \\
1 \\
1 \end{array} \right). $$ I'm now asked to find the basis dual to $\{v_1,v_2,v_3,v_4 \}$ in $\mathbb{R}^4$, wth each vector expressed as a linear combination of the standard basis in $\mathbb{R}^4$. Now, this is one of those situations where I 'know' all of the bookwork regarding dual bases etc. however, what seems like a simple application presents quite a hurdle. Any explanation of how to progress would be very appreciated.","['linear-algebra', 'transformation']"
150530,Sigma algebra and algebra difference,"An algebra is a collection of subsets closed under finite unions and intersections. A sigma algebra is a collection closed under countable unions and intersections. Whats the difference between finite and countable unions and intersections? Does ""countable"" mean it implies there can be infinitely many unions and intersections? Secondly, I was reading a definition For an algebra on a set: By De Morgan's law, $A \cap B = (A^c \cup B^c)^c$, thus an algebra is a collection of subsets closed under finite unions and intersections. What law are they using here to get $A \cap B = (A^c \cup B^c)^c$? I thought de morgan's law was $(A\cap B)^c = A^c \cup B^c$? Finally, what exactly do they mean by ""closed under finite unions and intersections?",['measure-theory']
150534,Show a certain group is contained in a Sylow p-group.,"Statement: Let G be a group and p a prime that divides $|G|$. Prove that if $K\le G$ such that $|K|$ is a power of p, K is contained in at least one Sylow p-group. I just started studying Sylow p-groups, so although I'm familiar with Sylow theorems and a couple of corollaries, I don't know how to get started with this problem. Any hint is more than welcome. PS: I looked for something related here at Math.SE but didn't find anything. Sorry if it's a duplicate.","['finite-groups', 'group-theory']"
150535,Is this $\left|\left(\frac{a}{b}\right)^n-\left(\frac{a}{b}\right)^{n-1}\right|$ bounded?,"Let $0.5<a<1$ and let $b=1-a$. Let $n\in \mathbb{N}$. $\left|\left(\frac{a}{b}\right)^n-\left(\frac{a}{b}\right)^{n-1}\right|\le C$. Is $\left|\left(\frac{a}{b}\right)^n-\left(\frac{a}{b}\right)^{n-1}\right|\le C$ bounded by a constant $C$ for all $n$? If so, how would I show it/explain it?",['analysis']
150547,Duality of $L^p$ and $L^q$,"If $X$ is an arbitrary measure space, I already know with proof that $L^p(X)$ and $L^q(X)$ are mutually duals as Banach spaces, when $1<p$ and $p$, $q$ are dual indices.  I also know a different proof that only works when $X$ is sigma finite, but then it establishes also that the dual of $L^1(X)$ is $L^\infty(X)$.  Is this still true when $X$ is not sigma finite? Please let me know how to prove your answer.","['functional-analysis', 'measure-theory', 'real-analysis', 'analysis', 'banach-spaces']"
150550,Find and Classify Singularities,"Find and classify the singularities of the following functions in $\mathbb{C}$: $\frac{1}{z(e^{\frac{1}{z}}+1)}$ $\frac{1}{(z^2+1)(z-1)^2}-\frac{1}{4(z-i)}$ OK, so I think the first is the easier (perhaps). There's clearly an essential singularity at the origin caused by the exponential. However, I think there are also singularities where $e^{\frac{1}{z}}=-1$, which occurs when $z=\frac{1}{(2n+1) \pi}$ for $n \in \mathbb{Z}$, though I am not sure how to classify there. Help with that would be very appreciated. For the second, we can split it into $\frac{1}{4(z+i)}-\frac{1}{2(z-1)}+\frac{1}{2(z-1)^2}$, which makes the position of the poles clear; at $-i, 1$. Is it the case that the pole at $-i$ is simple, and the pole at $1$ is a double pole. That seems to be the case. Any help/verification would be very helpful. Thanks in advance.",['complex-analysis']
150551,Is there an algorithm to determine whether rational matrices generate a finite group?,"This is inspired by this question.  Given finitely many invertible rational $n\times n$ matrices $A_{1},\ldots, A_{k}\in\operatorname{GL}(n,\mathbb{Q})$, is there an algorithm (a practical one) to determine whether the group $\langle A_{1},\ldots, A_{k}\rangle$ that they generate is finite?  One could, I suppose, use something like Dimino's algorithm to calculate the closure and stop when the size exceeds the maximum order possible (which is the order $2^{n}n!$ of the group of signed permutation matrices, except for some small exceptions, if I recall correctly) but that seems impractical.  Is there something better?","['reference-request', 'finite-groups', 'group-theory']"
150554,UFDs are integrally closed; so too are GCD & Dedekind domains.,"Let $A$ be a UFD, $K$ its field of fractions, and $f$ an element of $A[T]$ a monic polynomial. I'm trying to prove that if $f$ has a root $\alpha \in K$, then in fact $\alpha \in A$. I'm trying to exploit the fact of something about irreducibility, will it help? I havent done anything with splitting fields, but this is something i can look for.","['commutative-algebra', 'integral-dependence', 'abstract-algebra']"
150556,Can anybody recommend me a topology textbook? [duplicate],"This question already has answers here : Closed 12 years ago . Possible Duplicate: choosing a topology text Introductory book on Topology I'm a graduate student in Math. But I never learnt Topology during my undergraduate study. Next semester, I am going to take Differential Geometry. I assume this course would require a background of Topology. So I would like to take advantage of this summer and learn some topology myself. I don't need to become an expert in Topology. All I need is that after this summer, my topology knowledge will be enough for my Differential Geometry course. So can somebody please recommend me a textbook? I'd be really grateful!","['general-topology', 'reference-request']"
150575,What is the difference between $\omega$ and $\mathbb{N}$?,"What is the difference between $\omega$ and $\mathbb{N}$? I know that $\omega$ is the ""natural ordering"" of $\mathbb{N}$.  And I know that $\mathbb{N}$ is the set of natural numbers (order doesn't matter?).  And so, $\omega$ is a well-ordered set? an ordinal number? and $\mathbb{N}$ is an un-ordered set? Is this right, is there anything else? A little context: I'm wondering why people here have been telling me that a set $A$ is countable iff there exists a bijection between $A$ and $\omega$, as opposed to $A$ and $\mathbb{N}$.  Does it make a difference? Thanks.","['logic', 'elementary-set-theory']"
150579,Question about Riemann integral and total variation,"Let $g$ be Riemann integrable on $[a,b]$, $f(x)=\int_a^x g(t)dt $ for $x \in[a,b]$. Can I show that the total variation of $f$ is equal to $\int_a^b |g(x)| dx $?","['bounded-variation', 'integration', 'real-analysis']"
150583,Isometry in $\mathbb{R}^n$,"I'm trying to prove that if $f\colon\mathbb{R}^n \to \mathbb{R}^n$  is a $\mathcal{C}^1$ mapping such that $f'(x)$ is a (linear) isometry for every $x \in \mathbb{R}^n$, then $f$ is an isometry. By an application of inverse mapping theorem and mean value theorem, we have that $|f(x) - f(y)| = |x-y|$ as long as $x$ and $y$ are sufficiently close. How to extend this to the whole space?",['real-analysis']
150586,Expected Value of Max of Uniform IID Variables,"What is the expected value of the maximum of 500 IID random variables
  with uniform distribution between 0 and 1? I'm not quite sure of the technique to go about solving something like this. Could anyone point me the right direction? Thanks","['uniform-distribution', 'probability-distributions', 'probability', 'order-statistics']"
150592,"A finite graph G is $d$-regular if, and only if, its adjacency matrix has the eigenvalue $λ = d$","Show that a graph $G$ ﬁnite with $n$ vertices is $d$-regular if, and only if, the vector with all the coordinates equals to 1 is  eigenvetor from eigenvalue $λ = d$  from the  adjacency matrix
 $A$ from the graph $G$.
The question itself was a little confused for me...","['graph-theory', 'spectral-graph-theory', 'linear-algebra']"
150605,Classification of automorphisms of projective space,"Let $k$ be a field, n a positive integer. Vakil's notes, 17.4.B: Show that all the automorphisms of the projective scheme $P_k^n$ correspond to $(n+1)\times(n+1)$ invertible matrices over k, modulo scalars. His hint is to show that $f^\star \mathcal{O}(1) \cong \mathcal{O}(1).$ (f is the automorphism. I don't if $\mathcal{O}(1)$ is the conventional notation; if it's unclear, it's an invertible sheaf over $P_k^n$) I can show what he wants assuming this, but can someone help me find a clean way to show this?","['quasicoherent-sheaves', 'algebraic-geometry', 'schemes', 'projective-schemes']"
150615,References for Kolmogorov's strong law of a large numbers,"On the Wikipedia law of large numbers site, they mention ""Kolmogorov's strong law of large numbers"", which works even if the random variables are not identically distributed. Where can I find this theorem shown and proven? I know that a reference is provided on the Wikipedia site, but that book is out of availability. Are there any other references out there? (Interestingly, Allan Gut's book ""Probability: A Graduate Course"", has a theorem by the name of ""Kolmogorov's strong law"", but in his book, the random variables have to be identically distributed. Any ideas why this is?)","['statistics', 'reference-request', 'law-of-large-numbers', 'probability']"
150621,Relation on growth functions.,"I am having a hard time trying to solve the following problem. I am very novice to the topic of growth functions at the moment. I could use a little help with this problem. Let  $\preceq$ be the relation on growth functions defined by $f \preceq g$ if there is a constant $\lambda \ge 1$ such that $f(x) \le \lambda g(\lambda x + \lambda) + \lambda$ for all $x \in [0, \infty)$. Show that $\preceq$ is symmetric and transitive and that the relation $f \sim g$ - is defined to mean both $f \preceq g$ and $g \preceq f$.","['discrete-mathematics', 'abstract-algebra']"
150628,About alternating group $A_4$,"This is a simple exercise telling that $A_4$ cannot have a subgroup of order $6$. Here in my way: Obviously, for any group $G$ and a subgroup $H$ of it with index $2$; we have $∀$$ g\in G$ ,$g^2\in H$. I suppose that $A_4$ has such this subgroup, named $H$, of order 6. Then for any $\sigma\in A_4$; $\sigma^2\in H$. I think maybe the contradiction happens when we enumerate all $\sigma^2$. May I ask if there is another approach for this problem? Thanks.","['finite-groups', 'group-theory']"
150643,Can we construct a basis for Hermitian matrices made of positive semidefinite ones?,"let us consider $n\times n$ hermitian matrices.  They form a real space. Now we know that any such matrix $A$ can be written as 
$A=A_+-A_-$,
where $A_\pm$ are positive semidefinite matrices. Thus we can say that the (real) linear combination of positive semi-definite matrices spans the space of hermitian matrices. My question is, can we construct any basis for the space of hermitian matrices such that each basis element is a positive semidefinite matrix. please help or refer some literature  for it. ADDED: seeing the comment of Joriki I have decided to add a few more lines regarding my earlier (failed) approach, in the hope that someone can help me (in completing the line of argument, if possible; or by finding a fault in my argument). I can diagonalise and separate the positive and negative part. now let $A=UDU^*$, where $U$ is an unitary operator and $D$ is the diagonal matrix. This again can be written as $A=UD_1U^*-UD_2U^*$ where $D_i$ are diagonal matrices with all entries $\geq0$. hence, if we take a such a positive diagonal matrices and only consider unitary group action on it, we are going to find all the hermitian operators. in particular, i tried to take diagonal matrix $D_j$ ($j$-th entry $1$, others $0$) and applied unitary group. this method seemed to fail here, as i could not get any meaningful basis out of these actions.","['matrices', 'linear-algebra', 'functional-analysis']"
150645,"Why $\sin(nx)$ converges weakly in $L^2(-\pi,\pi)$?","Can anybody tell me why $\sin(nx)$ converges weakly in $L^2(-\pi,\pi)$. I can't see how $\sin(nx)$ can converge? Explanation with any other example will be nice as well.","['weak-convergence', 'hilbert-spaces', 'functional-analysis', 'real-analysis']"
150662,Does every curve over a number field have infinitely many rational functions of fixed degree,"Let $X$ be a curve over a number field $K$ of genus $g\geq 2$. Does there exist an integer $d$ such that $X$ has infinitely many rational functions (i.e., finite morphisms $f:X\to \mathbf{P}^1_K$) of degree $d$? If yes, can we choose/bound $d$ in terms of $K$ and $g$? Note. This is not the same question as in the title. The answer to the question in the title is in fact negative as the example below shows for $d=2$. Note: I want rational functions to be really different . So we mod out by the action of the automorphism group of $\mathbf{P}^1_K$. That is, $f$ and $\sigma\circ f$ are the same if $\sigma$ is an automorphism of $\mathbf{P}^1_K$. Example 1. We can not have $d=2$. Hyperelliptic maps are unique. Question 2. How does the answer to this question change if we replace $K$ by an algebraically closed  field $k$? Example 2. Let $X$ be a general curve of odd genus  $g\geq 3$ over an algebraically closed field. Then, it has an infinite number of (really different) gonal morphisms. In fact, this family is one-dimensional. Idea. I think the question can be reduced to a question on $\mathbf{P}^1_K$. In fact, it suffices to show that there are infinitely many (really different) rational functions on $\mathbf{P}^1_K$ of some degree, say $3$. In fact, once you know this, composing some  morphism $f:X\to \mathbf{P}^1_K$ with such a rational function gives infinitely many rational functions of degree $d \leq 3 \deg f$. The only problem is then finding (in a controlled way) a morphism $f:X\to \mathbf{P}^1_K$. This is a hard problem, but let's allow finite base change if necessary...","['number-theory', 'rational-functions', 'algebraic-geometry', 'algebraic-curves', 'arithmetic-geometry']"
150678,Forming equation of a plane by solving linear equation set,"Given three points on the plane: $ A(x_1, y_1, z_1) $, $ B(x_2, y_2, z_2) $ and $ C(x_3, y_3, z_3) $. I'm trying to obtain the equation of the plane in this format: $ ax + by + cz + d = 0 $ I substituted given three points into the plane equation above to form this matrix equation below: \begin{equation}
 \begin{bmatrix}
    x_1 & y_1 & z_1 & 1 \\
    x_2 & y_2 & z_2 & 1 \\
    x_3 & y_3 & z_3 & 1 \\
    ? & ? & ? & ?
 \end{bmatrix}
 \begin{bmatrix} a \\ b \\ c \\ d \end{bmatrix}
 =
 \begin{bmatrix} 0 \\ 0 \\ 0 \\ ? \end{bmatrix}
\end{equation} My aim is to find the coefficients $ a $, $ b $, $ c $ and $ d $ by solving this matrix equation. However, I can't find a fourth equation to complete the equation set. Can you please write me a fourth equation to complete the set? Note: My aim is not just finding the plane equation. My aim is to find the plane equation by this method, by means of solving a linear set of equations. I know the other more practical way of finding the plane equation, but I'm trying to find it this way on purpose. There is no reason, I just like trying different methods and playing with numbers occasionally out of interest. So, please consider this not while writing your answers and don't suggest me other methods.","['matrices', 'geometry', 'intuition']"
