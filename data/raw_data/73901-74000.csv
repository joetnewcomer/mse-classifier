question_id,title,body,tags
912353,Quaternion integration,"If the angular velocity is changing continuously, the following holds true $ q(t)=q(0)\exp\left({\int_{0}^{t}\frac{q_\omega(\tau)}{2}\ d\tau}\right) \tag 1$ Specifications and Data $q(t),q(0)$ represents quaternions $q_\omega(\tau)$ represents the quaternion representation of angular velocity at $\tau$. It implies  if $\omega(\tau) \in R^3 $ is the angular velocity,then  $q_\omega(\tau)=(0,\omega(\tau))$ at $\tau$ Exponent of a quaternion $J=( p,v)$  can be defined as 
\begin{eqnarray}
 e^{J}=e^{p}\left(cos|v| ,\frac{v}{|v|}sin|v|  \right) 
\end{eqnarray}$v$ is a vector. If you are given a vector, make it as a quaternion with $p=0$ Question How do we prove equation $ q(t)=q(0)\exp\left({\int_{0}^{t}\frac{q_\omega(\tau)}{2}\ d\tau}\right)  $ precisely?","['calculus', 'integration', 'rotations', 'quaternions', 'linear-algebra']"
912354,How to derive the closed form of the sum of $kr^k$,"$$
\sum_{k=0}^{n}kr^k = r\frac{1-(n+1)r^n + nr^{n+1}}{ (1 - r)^2 }
$$ How to derive it? I read about some finite calculus, and i understand how to tackle sums of $x^2$, $x^3$, etc.. But I don't know if the same methods can be used on this sum?","['closed-form', 'summation', 'sequences-and-series']"
912358,Show A and B have a common eigenvalue,"Let A, B and C complex square matrices such that:
$ C\neq 0 $ and $AC=CB $
prove that A and B has a common eigenvalue. It's worth mentioning that earlier in the assignment I have proved that $A^{n}C=CB^{n}$, 
but I'm not sure how to use it. This is taken from a linear algebra 2 course.",['linear-algebra']
912365,Showing that if the $n$th derivative of a function is bounded then it is real analytic,"I reproduce from my lecture notes: Suppose $f$ is $C^\infty$ on $[a,b]$ with $$\left|f^{(n)}(x)\right|\leqslant M~~\text{for all}~~x\in(a,b).$$ Then $f$ is real analytic in $[a,b]$ . Proof . Fix $x_0\in[a,b]$ .  Then for each $x$ in $[a,b]$ the error after truncating the series at the $n$ th term is given, for some $c\in[a,b]$ , by $$\left|\frac{f^{(n+1)}(c)}{(n+1)!}(x-x_0)^{n+1}\right|\leqslant \frac{M}{(n+1)!}\left|b-a\right|^{n+1}.\tag{$*$}$$ This tends to zero as $n\to\infty$ and so $f$ is real analytic in $[a,b]$ . Question: how did my lecturer deduce the inequality $(*)$ from $\left|f^{(n)}(x)\right|\leqslant M$ ? I am searching for different versions of this proof but they all somehow fail to explain this step, assuming that is is obvious. Any (fairly elementary) explanation is welcomed. Thanks.","['taylor-expansion', 'power-series', 'real-analysis', 'analysis']"
912377,Vertical asymptote (or any?) at removable discontinuity,"If I have a removable discontinuity, do i have any kind of asymptote? I originally thought no, but this confused me a bit: http://www.purplemath.com/modules/asymtote4.htm Close to the bottom, it says that the function (with a removable discontinuity) has both a vertical asymptote at x = 2 and a slant asymptote. Is this correct?",['functions']
912387,Can one prove existence of incommensurables without the Pythagorean theorem?,"Euclid's proof that the side and the diagonal of a square have no common measure, probably going back to Pythagoreans, reduces it to proving the irrationality of $\sqrt{2}$. This reduction uses the Pythagorean theorem, and therefore the axiom of parallels. However, there isn't a common measure for all segments in the hyperbolic plane either, so existence of incommensurables must be independent of the axiom of parallels. Since Cantor's axiom of continuity allows to construct real numbers geometrically it is also enough to produce incommensurables, but what if we leave out these two. If we take lines with rational slopes only in $\mathbb{Q}^2$ the axiom of congruence for segments isn't satisfied, there is no segment along the diagonal of a rational square congruent to its side and with endpoint at its vertex. Can one prove existence of incommensurables in elementary absolute geometry, i.e. without the axioms of parallels and continuity? Is commensurability at least consistent with the rest of Hilbert's axioms ? This question is a follow up to What are some examples of proofs using the Pythagorean assumption that all segments are commensurable? . EDIT: Without the axiom of parallels metric notions, and therefore correspondence between segments and numbers, can not be established. So variations on $\sqrt{2}$ and the golden ratio do not work. Proofs that the Euclidean construction cuts a segment in the golden ratio for example also use some equivalent of the axiom of parallels (angle sum $\pi$ or Euclidean trigonometry). Without the axiom of continuity cardinality arguments do not apply either. On the other hand, there is no obvious model of geometry with infinitely many points where all segments are commensurable, $\mathbb{Q}^2$ with rational slopes does not work exactly because of the unit square and its diagonal.","['geometry', 'logic', 'irrational-numbers', 'model-theory']"
912415,2000 Olympiad in Informatics Question on Box,I have an old Olympiad question on informatics. There are 31 boxes. In each box there is one number. We know the number if and only if we open the box. We want to calculate the minimum number of boxes that must be opened to find one number that is not lower than the numbers of its neighbor boxes. The first and last boxes have one neighbor (boxes are not a ring). All other boxes have two neighbors. I see a strange answer and it is 11. Any details or ideas are very appreciated.,"['discrete-mathematics', 'contest-math', 'recursive-algorithms', 'algorithms', 'computer-science']"
912418,Are these functions identical?,"Suppose we have an identity of the form $$x e^{f(x,y)}+y e^{g(x,y)} \equiv (x+y)e^{h(x,y)},$$ for all $x,y\in D$ where $D$ is some domain. Does this imply that $f(x,y)\equiv g(x,y)\equiv h(x,y)$ in general?",['functions']
912421,Limit of a sequence of products,"How do you prove the following? $$\lim_{n\,\to\,\infty}\,\frac{1\cdot3\cdot5\cdots(2n-1)}{2\cdot4\cdot6\cdots(2n)}\ =\ 0$$","['sequences-and-series', 'calculus', 'limits']"
912432,"Is there a theory of ""rings"" with partially defined multiplication?","Consider the abelian group $R [[\mathbb{Z}^d]]$ of all formal Laurent series over a commutative ring $R$ (a typical element has the form $\sum_{v \in \mathbb{Z}^d} \lambda_v \cdot X_1^{v_1} \dots X_d^{v_d}$ with $\lambda_v \in R$). Since there is no restriction on the coefficients, we cannot make $R [[\mathbb{Z}^d]]$ into a ring by the usual multiplication, but we get a partially defined operation in this way. It is easy to see that $R [[\mathbb{Z}^d]]$ satisfies all ring axioms, whenever all involved terms are defined. Maybe one could call such structures ""partial rings"". Is there a general theory of partial (commutative) rings which abstracts from this example? I am particularly interested in the notion of ideals and quotients of them. Thank you in advance!","['laurent-series', 'ring-theory', 'reference-request', 'abstract-algebra']"
912438,"Billingsley ""Probability and Measure"" on constructing $\sigma$-fields","I'm starting to read, very slowly, Patrick Billingsley's ""Probability and Measure"".  in chapter 1 ""Probability"", section 2 ""Probability Measures"", there's an optional section ""Constructing $\sigma$-fields"".  i'm struggling with something (located on page 31 of the 3rd edition, near location 1470 in the Kindle ""anniversary"" version). For context (though probably you will really need the text in front of you): this section is trying to show that starting from the ""rational"" intervals $I_0$ in (0,1], plus the empty set, and then going to a lot of effort forming countable unions of those intervals, complements of them, iterating over and over again, one still won't end up with the Borel set, $\sigma(I_0)$, the ""smallest $\sigma$-field containing $I_0$"" - there will still be bits and pieces missing. In doing this, Billingsley creates a set $B := \{\omega : \omega \notin \phi(\omega)\}$ (where the universe is $(0,1]$).  he then goes on to show that no element of B is contained in the set created in my previous paragraph, but that every element of B is in the Borel set, i.e., in $\sigma(I_0)$. (i apologize, but i don't think i can usefully summarize $\phi()$, though if someone asks, i can try; if you're willing/interested to help, you'll probably have the book to hand.) My question is this: how do we know that $B$ is non-empty? I apologize if this is blazingly obvious. (in getting to this point, Billingsley creates a 2-dimensional matrix of indices to use in his iterative procedures -- which makes me wonder if there isn't some sort of diagonal argument we can use to show that $B$ contains at least one element.  but, if there is, i don't see it.)","['probability-theory', 'measure-theory']"
912442,"Inverse of $f(x)=x^n+x$ on $[0,\infty)$","Fix integer $n > 1$. The function $f_n(x) = x^n + x$ is monotone increasing on $[0,\infty)$, and so has an inverse $f_n^{-1}(x)$ that is also monotone increasing on $[0,\infty)$. I'm interested in properties of $f_n^{-1}(x)$ (in particular, in its Taylor series). I'm sure that it's a well-studied function (or rather, family of functions), but I can't find any literature on it, mostly because I don't know what keywords to use. Does anyone know a name for this function?","['functions', 'real-analysis']"
912468,Comparison theorem for ODE,"Here is something I'm trying to prove: Conjecture: Suppose $f'(x) \leq \phi(f(x), x)$ and $f(a)=\alpha$. Suppose $g'(x)=\phi(g(x),x)$ and $g(a)\geq \alpha$. Then $f(x)\leq
 g(x)\,\,\forall x$. It definitely seems like it should be true, and I don't think we even need continuity of $\phi$. ( Edit: a user has correctly pointed out that we should require $\phi$ be locally Lipshitz in the first variable, uniformly with respect to the second variable. Let's add that assumption.) I can prove it in the case that the inequality is strict. I'll place my proof below the fold. How can I extend it to weak inequality? If it's wrong, I'd love to see a counterexample. A reference is fine; I have the book by Teschl, for example. A similar question with stronger assumptions was asked here . Proposition: Suppose Suppose $f'(x) < \phi(f(x), x)$ and $f(a)=\alpha$. Suppose $g'(x)=\phi(g(x),x)$ and $g(a)\geq \alpha$. Then $f(x)\leq
 g(x)\,\,\forall x$. Proof: Suppose not. Suppose WLOG there is a $b>a$ such that $f(b)>g(b)$. Let $c:=\inf \{x>a:f(x)>g(x)\}$. By definition of the derivative we have $f'(c)\geq g'(c)$, a contradiction, since $f'(c)<\phi(f(c),c)=\phi(g(c),c))=g'(c)$.","['inequality', 'ordinary-differential-equations', 'calculus']"
912480,Definition of multiplication in Grothendieck ring,"Let $X$ be a smooth variety over an algebraically closed field $k$ of dimension $n$.
Consider the Grothendieck Group $K(X)$ of coherent sheaves on $X$, i.e. the free abelian group generated by expressions $[\mathscr F]$ with $\mathscr F$ a coherent sheaf on $X$, modulo the relation $[\mathscr F]=[\mathscr K]+[\mathscr Q]$ whenever there is an exact sequence 
$$0\to\mathscr K\to\mathscr F\to\mathscr Q\to 0.$$ You can turn $K(X)$ into a ring with multiplication induced by the tensor product, i.e. $[\mathscr F]\cdot[\mathscr F]:=[\mathscr F\otimes \mathscr G]$. However, I saw the product defined as
$$[\mathscr F]\cdot[\mathscr G] := \sum_{i=0}^n (-1)^i [\operatorname{Tor}_i(\mathscr F,\mathscr G)]$$
in Positivity in the Grothendieck group of complex flag varieties by Brion, it's on page 5 in the arXiv version . Now this should come out of the very definition of $\operatorname{Tor}_i$ as the left derived of the tensor product. However, it does not work out that way for me, so I am looking for the mistake in my calculation. Choose a projective resolution of $\mathscr G$, say $0\to\mathscr R_n\to\cdots\to\mathscr R_1\to \mathscr R_0 := \mathscr G\to 0$. Apply $\mathscr F\otimes (-)$ to this sequence and with $\mathscr P_i := \mathscr F\otimes \mathscr R_i$, we get the exact sequence
$$0\xrightarrow{d_{n+1}=0} \mathscr P_n \xrightarrow{d_n} \cdots \xrightarrow{d_2} \mathscr P_1 \xrightarrow{d_1} \mathscr P_0 = \mathscr F\otimes \mathscr G\xrightarrow{d_0=0} 0$$
Now set $\mathscr K_i := \ker(d_i)$, $\mathscr I_i := \operatorname{im}(d_i)$ and $\mathscr T_i := \operatorname{Tor}_i(\mathscr F,\mathscr G)= \mathscr K_i / \mathscr I_{i+1}$. We then have two exact sequences,
\begin{align*}
0&\to \mathscr I_{i+1} \to \mathscr K_i \to \mathscr T_i \to 0 &&\text{and}&
0&\to \mathscr K_{i} \to \mathscr P_i \to \mathscr I_i \to 0
\end{align*}
Note that $\mathscr I_{n+1}=0$ and $\mathscr K_0=\mathscr P_0 = \mathscr F\otimes\mathscr G$, so we have 
\begin{align*}
\sum_{i=0}^n (-1)^i [\mathscr T_i] 
&= \sum_{i=0}^n (-1)^i ([\mathscr K_i]-[\mathscr I_{i+1}])
 = [\mathscr K_0] + \sum_{i=1}^{n} (-1)^i ([\mathscr K_i]+[\mathscr I_i]) 
\\ &= [\mathscr P_0] + \sum_{i=1}^n (-1)^i [\mathscr P_i]
 = \sum_{i=0}^n (-1)^i [\mathscr P_i]
 = \sum_{i=0}^n (-1)^i [\mathscr F\otimes \mathscr R_i]
\\ &= \sum_{i=0}^n (-1)^i [\mathscr F]\cdot[\mathscr R_i]
 = [\mathscr F]\cdot \sum_{i=0}^n (-1)^i [\mathscr R_i]
\end{align*}
But by basically the same calculation, by exactness of the complex $\mathscr R_\bullet$, we have $\sum_{i=0}^n (-1)^i [\mathscr R_i] = 0$. What am I doing wrong?","['homology-cohomology', 'homological-algebra', 'algebraic-geometry', 'algebraic-topology']"
912485,Book on advanced Hodge Theory,"I'm looking for a book on advanced real Hodge Theory. I finished working through Frank Warner's Foundations of Differentiable Manifolds and Lie Groups, which ends with the Hodge Decomposition,the Hodge theorem(stating that the space of harmonic p-forms is isomorphic to the p-th Cohomology Group)as well as formulating(and proofing) the Poincare Duality. Is there any book that covers this topic further? Thank you very much in advance.","['book-recommendation', 'differential-geometry', 'hodge-theory']"
912502,"An element of $SL(2,\mathbb{R})$","An element $A$ of $SL(2,\mathbb{R})$ is called an elliptic element if $|\text{tr}(A)|<2$ . Find the relationship between an elliptic element of $SL(2,\mathbb{R})$ and rotation. As $|\text{tr}(A)|<2$ the characteristic equation of $A$ does not have real roots, so it has no real eigenvalue. But I am unable to go ahead.","['matrices', 'linear-algebra', 'abstract-algebra']"
912507,Alternative Monty Hall Problem,"So the typical set up for Monty Hall problem, there are 3 doors where 2 have goats and 1 has a car. I, the contestant, get to randomly guess a door looking to get the one with the car, after this the host will open a door that will always be a goat. Thus out the two doors that are left, I have to choose to stay with the original door I chose or switch to the other door. As many analysis of this problem have been done, switching my choice gives me a higher probability of winning. This largely has to do with the fact that since the host always reveals a goat the asking of whether to stay or not, is the same as did you guess right or not, and you have $\frac{2}{3}$ of wrong so you should switch Now it seems, this ""strange"" result largely has to do with the fact that the host always reveals a goat. But what if alternatively you had this situation You are given 3 doors, 2 with a goat and 1 with a car. You randomly choose a door (looking to get one with the car). The host will randomly choose to reveal what is behind one of the 2 doors you haven't chosen. Given that he reveals goat, what is the probability of getting car if you chose to stay with choice? My analysis of this problem goes as follows: Let $D$ be event the door I guessed has car and Let $G$ reprsent the event that host reveals a goat thus what I want to calculate is $P(D|G)$ with this I have
$$P(D|G)=\frac{P(D\cap G)}{P(G)}=\frac{P(G|D)P(D)}{P(G|D)P(D)+P(G|D^{c})P(D^{c})}=\frac{1\left(\frac{1}{3}\right)}{1\left(\frac{1}{3}\right)+\frac{1}{2}\left(\frac{2}{3}\right)}=\frac{1}{2}$$ So it seems it doesn't matter if I choose to switch or not, and this is the result most people come up with when first thinking of problem. Question : First is my analysis correct for this problem? Second, is it true in general that if you guess out of $n$ doors and host reveals $k$ doors that all have goats, will the probability that car is behind door you choose just $\dfrac{1}{n-k}$? UPDATE So I ended up asking my statistics/probability professor about this question and he said the result I got was correct. He explained that the reasoning that the Monty Hall problem inherently causes confusion is because many don't notice the only randomness in the original problem is just in your choice while hosts choice of door is deterministic. Now the problem I asked now has two sets of randomness, your original choice of door and the hosts choice thus the problems are inherently different","['monty-hall', 'probability', 'conditional-probability']"
912542,Integral of the Square of the Elliptic Integral,"Someone must know a good technique for $$
\int E^{2}(x)dx
$$ Where $E$ is the complete elliptic integral of the second kind:
$$
E\left(k\right)=\int_{0}^{\frac{\pi}{2}}d\theta\sqrt{1-k^{2}\sin^{2}\left(\theta\right)}
$$ This is essentially the working for another integral I posted 
( Simple Integral Involving the Square of the Elliptic Integral ) though this is valuable in its own right.","['special-functions', 'integration', 'indefinite-integrals']"
912544,Are there counter intuitive interpretations of ZF or ZFC?,"Are there interpretations of ZF or ZFC that are non standard in the sense that $\epsilon$ is interpreted in a counter intuitive way that intuitively has nothing to do with "" belongs to "" or "" is part of "" (apart from formally modelling the axioms of ZFC )?","['set-theory', 'model-theory', 'foundations', 'abstract-algebra']"
912588,Tiling squares with L-Trominoes,Is there a simple proof that any square besides a 3x3 square with area divisible by 3 is tileable with L-trominos?,"['geometry', 'tiling', 'polyomino', 'recreational-mathematics', 'combinatorics']"
912598,When does $P(A|B) = P(B|A)$?,"If A and B are events, when does $P(A|B) = P(B|A)$? If it is not always true, please provide a counter example as I cannot.",['probability']
912613,Is there an injective function such that $f(x^2)-f^2(x)\ge \frac{1}{4}$?,"The exercise asks me this: Is there an injective function such that $f(x^2)-f^2(x)\ge \frac{1}{4}$? ps: $f: \mathbb{R}\to \mathbb{R}$ I really don't know how to start :c, I appreciate hints.","['calculus', 'algebra-precalculus', 'functions']"
912627,Prove that mean square error equals expected conditional variance,"I'm a first year grad student in Statistics. The book I'm using mentioned conditional variance, and I wanted to read up more about it. I dove down the google rabbit hole and found this website. I read through it and followed the proofs. Then I came to this chunk, and I can't prove it myself. From the definition of conditional variance and the basic property above, it follows that the mean square error when $E(Y∣X)$ is used as a predictor of $Y$ is: $$E([Y−E(Y∣X)]^2 )=E[\operatorname{Var}(Y∣X)]=\operatorname{Var}(Y)−\operatorname{Var}[E(Y∣X)]$$ When I expand the LHS, I get the following: $$\begin{split}
E([Y−E(Y∣X)]^2) &= E([Y^2-2YE[Y|X]+E[Y|X]^2) \\  
&= E[Y^2] - 2E[YE[Y|X]] + E[E[Y|X]^2] \\  
&= E[Y^2] - 2E[Y^2] + \operatorname{Var}(E[Y|X]) + E[E[Y|X]]^2 \\  
&= \operatorname{Var}(E[Y|X]) + E[Y]^2 - E[Y^2]  \\
&= \operatorname{Var}(E[Y|X]) - \operatorname{Var}(Y)
\end{split}$$    However, this is off by a factor of $-1$.  Can anyone point out where I went awry?","['statistics', 'conditional-expectation', 'probability']"
912650,When does L' Hopital's rule fail?,"This thought jumped out of me during my calculus teaching seminar. It is well known that the classical L'Hospital rule claims that for the $\frac{0}{0}$ indeterminate case, we have:
$$
\lim_{x\rightarrow A}\frac{f(x)}{g(x)}=\lim_{x\rightarrow A}\frac{f'(x)}{g'(x)}
$$
where the later could take any value including $\infty$. Here we assume that right hand side limit exist. However, to apply it one often has to take the derivative of $f'(x)$ again at $A$, and in principle one assumes by repeatedly applying this rule we can resolve the problem by plug in the value into the function's derivative at $A$. My question is, what if the student ask if it is possible for $\lim_{x\rightarrow A} f(x),\lim_{x\rightarrow A} f'(x)\cdots \lim^{n}_{x\rightarrow A}f^{n}(x)$ be all zero for any $n$, so the rule 'fails'. How should we answer the question properly? For example, consider the well-known non-analytic smooth function :
$$f(x)=
\begin{cases}
e^{-1/x}& x> 0\\
0& x\le 0
\end{cases}
$$
It is a trivial exercise to verify that $f^{n}(0)=0$ for any $n\in \mathbb{N}$. Now using L'Hospital rule we compute (as if we are a low level student)
$$
1=\lim_{x\rightarrow 0^{+}}\frac{f(x)}{f(x)}=\lim_{x\rightarrow 0^{+}}\frac{f'(x)}{f'(x)}=\lim_{x\rightarrow 0^{+}}\frac{f''(x)}{f''(x)}\cdots =\frac{0}{0}=?
$$
as the chain does not stop if the student applies the rule faithfully and blindly. This is a silly example, but in general for non-analytical functions I think this kind of thing could happen. And there should be more non-analytical functions than analytical functions. Is there a way for us to resolve this at introductory calculus level, so that the student know what to do, without introducing `confusing concepts' like $\epsilon-\delta$ language, Cauchy mean value theorem, Taylor series, and infinitesimals?","['education', 'calculus']"
912681,Integrals of integer powers of dilogarithm function,"I'm interested in evaluating integrals of positive integer powers of the dilogarithm function. I'd like to see the general case tackled if possible, or barring that then as many particular cases as possible. Problem. For each $n\in\mathbb{N}$, evaluate the definite integral $\mathcal{I}_n$:
  $$\mathcal{I}_n:=\int_{0}^{1}\left[\operatorname{Li}_2{(x)}\right]^n\,\mathrm{d}x=\,???$$ The first two cases aren't that difficult to evaluate, but for reference I'll just state their values without proof: $$\begin{align}
\int_{0}^{1}\operatorname{Li}_2{(x)}\,\mathrm{d}x
&=\zeta{(2)}-1\\
&=0.6449340668482264\dots;
\end{align}$$ and $$\begin{align}
\int_{0}^{1}\operatorname{Li}_2{(x)}^2\,\mathrm{d}x
&=\frac52\zeta{(4)}-4\zeta{(3)}-2\zeta{(2)}+6\\
&=0.6077123379430154\dots.
\end{align}$$ The next case, $n=3$, is much harder than the previous two. However, by combining my answer to this question with Omran Kouba's answer to the same question, and assuming both answers are correct, I was able to infer that $$\zeta{(5)}+6\zeta{(3)}+\frac{\pi^4}{15}-15=\frac{1}{3!}\int_{0}^{1}\left[\operatorname{Li}_2{(x)}-\zeta{(2)}\right]^3\,\mathrm{d}x.$$ Then by using the Binomial Theorem to expand the integrand on the RHS and by using the previous values of $\mathcal{I}_n$ for $n<3$, I was able to solve for the integral $\mathcal{I}_3$ and find the following value: $$\begin{align}
\mathcal{I}_3
&=\int_{0}^{1}\operatorname{Li}_2{(x)}^3\,\mathrm{d}x\\
&=6\zeta{(5)}+36\zeta{(3)}+\frac{\pi^6}{216}+\frac{19\pi^4}{60}+3\pi^2-2\pi^2\zeta{(3)}-90\\
&=0.6738641012555397\dots.
\end{align}$$ But surely there is a less circuitous way to prove this. Can anybody offer a more direct proof that the integral $\mathcal{I}_3$ has the conjectured value indicated above? Prove: $$\int_{0}^{1}\operatorname{Li}_2{(x)}^3\,\mathrm{d}x\stackrel{?}{=}6\zeta{(5)}+36\zeta{(3)}+\frac{\pi^6}{216}+\frac{19\pi^4}{60}+3\pi^2-2\pi^2\zeta{(3)}-90.$$ And finally, what of the $n>3$ cases? What is the largest $n$ for which $\mathcal{I}_n$ can be evaluated? Can $\mathcal{I}_4$ be evaluated? At the bottom of Omran Kouba's response to the question I referred to above, he says that, to his knowledge, the values of the integral of integer powers of the dilogarithm for powers larger than $2$ are not known. Clearly, for that statement to be true then, at the very least, it would have to be amended to reflect the fact that the value of the integral of the third power of the dilogarithm is indeed known (assuming I'm not somehow the first person to know it!). But are the values for $n>3$ really unknown? Update: As SuperAbound was able to show, finding $\int_{0}^{1}\operatorname{Li}_2{(x)}^3\,\mathrm{d}x$ via repreated integration by parts actually isn't that difficult at all! For comparison, let's see how much harder finding $\int_{0}^{1}\operatorname{Li}_2{(x)}^4\,\mathrm{d}x$ is if we try to recycle the same method. To evaluate $\int_0^1\operatorname{Li}_2{(x)}^4\mathrm{d}x$, integrate by parts using $$\frac{d}{dx}\operatorname{Li}_2{(x)}^{4}=-\frac{4\ln{(1-x)}\operatorname{Li}_2{(x)}^3}{x}.$$ Then, $$\begin{align}
\mathcal{I}_4
&=\int_{0}^{1}\operatorname{Li}_2{(x)}^4\,\mathrm{d}x\\
&=\left[x\operatorname{Li}_2{(x)}^4\right]_{0}^{1}-\int_{0}^{1}x\left(-\frac{4\ln{(1-x)}\operatorname{Li}_2{(x)}^3}{x}\right)\,\mathrm{d}x\\
&=\operatorname{Li}_2{(1)}^4+4\int_{0}^{1}\ln{(1-x)}\operatorname{Li}_2{(x)}^3\,\mathrm{d}x\\
&=\zeta{(2)}^4+4\int_{0}^{1}\ln{(1-x)}\operatorname{Li}_2{(x)}^3\,\mathrm{d}x.
\end{align}$$ Next, evaluate $\int_{0}^{1}\ln{(1-x)}\operatorname{Li}_2{(x)}^3\,\mathrm{d}x$ by integrating by parts again using $$\int\ln{(1-x)}\,\mathrm{d}x=(x-1)\ln{(1-x)}-x+constant,$$ $$\frac{d}{dx}\operatorname{Li}_2{(x)}^3=-\frac{3\ln{(1-x)}\operatorname{Li}_2{(x)}^2}{x}.$$ Then, $$\begin{align}
\int_{0}^{1}\ln{(1-x)}\operatorname{Li}_2{(x)}^3\,\mathrm{d}x
&=\left[\left((x-1)\ln{(1-x)}-x\right)\operatorname{Li}_2{(x)}^3\right]_{0}^{1}\\
&~~~~~-\int_{0}^{1}\left((x-1)\ln{(1-x)}-x\right)\left(-\frac{3\ln{(1-x)}\operatorname{Li}_2{(x)}^2}{x}\right)\,\mathrm{d}x\\
&=-\operatorname{Li}_2{(1)}^3\\
&~~~~~-3\int_{0}^{1}\left[\frac{\ln^2{(1-x)}}{x}-\ln^2{(1-x)}+\ln{(1-x)}\right]\operatorname{Li}_2{(x)}^2\,\mathrm{d}x\\
&=-\zeta{(2)}^3-3\int_{0}^{1}\frac{\ln^2{(1-x)}\operatorname{Li}_2{(x)}^2}{x}\,\mathrm{d}x\\
&~~~~~+3\int_{0}^{1}\ln^2{(1-x)}\operatorname{Li}_2{(x)}^2\,\mathrm{d}x-3\int_{0}^{1}\ln{(1-x)}\operatorname{Li}_2{(x)}^2\,\mathrm{d}x.
\end{align}$$ The third integral in the last line above has the value, $$\int_{0}^{1}\ln{(1-x)}\operatorname{Li}_2{(x)}^2\,\mathrm{d}x=2\zeta{(5)}+\frac{19}{2}\zeta{(4)}+12\zeta{(3)}+6\zeta{(2)}-4\zeta{(3)}\zeta{(2)}-30.$$ (to be continued...)","['closed-form', 'riemann-zeta', 'integration', 'definite-integrals', 'polylogarithm']"
912683,Show that there is no surjective ring homomorphism from $\mathbb Z_2[x]$ to $\mathbb Z_2 \times \mathbb Z_2\times \mathbb Z_2$,"I saw this question as a bonus from a past exam, and here's my solution for verification. I argued like so. I said suppose there is such a surjective homomorphism $f$,
then $f(0)=(0,0,0)$, $f(1)= (1,1,1)$ by ring homomorphism axioms. Suppose now that $f(x)= (a,b,c)$, where $a,b,c$ are either $0$ or $1$. Then $f(x^2)= (a^2,b^2,c^2)= (a,b,c)$ and same thing for $f(x^n)$ for any $n\geq 1$. Now this implies that any $p(x)$ will be mapped to either $(a,b,c)$ or $(a+1,b+1,c+1)$, depending on if they have a constant term (1). This means that $(a+1,b,c)$ for example is not in the image of $f$. Done. Is this a good argument? Thanks in advance.","['ring-theory', 'finite-fields', 'proof-verification', 'abstract-algebra']"
912691,Prove second derivative of $g$ is proportional to $g^2$,"From Apostol's Calculus Vol. 1, chapter 6.26, exercise 30: Let $f(x) = \int_0^x (1+t^3)^{-1/2} dt$. $a)$ Prove $f$ is strictly monotonic. $b)$ Let $g$ be the inverse of $f$.  Show that the second derivative of $g$ is proportional to $g^2$ and find the constant of proportionality $c$. The first part is simple, since the derivative is $( 1+x^3 )^{-1/2} > 0$ if $x \ge 0$. However, I'm having a lot of difficulty with the second part.  Since $g' = 1 / f'$, I calculated that $g''(x) = - \frac{3x^2}{2(1+x^3)^{3/2}}$.  However, this doesn't seem to get us any closer to finding the constant of proportionality since it doesn't seem at all obvious how to calculate $g$. I also tried applying the chain rule so that $g''(x) = - f''(x) / f'(x)^2 = - f''(x) g'(x)^2$.  Again, this expression doesn't seem to bring us any closer to solving the problem, since we are again left with the problem of calculating $g$, or at least $g^2$, in terms of $f''$ and $g'$. So how can these equations be manipulated so that we arrive at $g''(x) = cg^2(x)$?","['ordinary-differential-equations', 'calculus']"
912715,$L^{1}$ norm of a horizontally shifted measurable function,"Suppose we are in $(\mathbb{R}, \mathcal{B}(\mathbb{R}), m)$, where $m$ is Lebesgue measure and $\mathcal{B}(\mathbb{R})$ is the Borel $\sigma$-algebra on $\mathbb{R}$. Also, suppose $g: \mathbb{R} \to [-\infty, \infty]$ is in $L^{1}(dm)$. I want to understand why $\int \limits_{\mathbb{R}} |g(y)| dy = \int \limits_{\mathbb{R}} |g(y-x)| dy$.  That is, for each $x \in \mathbb{R}$, $||g(x)||_{1} = ||g(y - x)||_{1}$ holds. Is this an obvious fact?  I realize that $g(y - x)$ is measurable for each $x \in \mathbb{R}$.","['measure-theory', 'real-analysis', 'lebesgue-integral', 'lebesgue-measure', 'functional-analysis']"
912729,How to show $f(x)$ is bounded?,Consider: $$2x\sin(1/x) - \cos(1/x)$$. How to show $f(x)$ is bounded? Thanks!,"['calculus', 'real-analysis', 'limits']"
912742,How to prove this $\frac{\sin{(nx)}}{\sin{x}}\ge\frac{\sqrt{3}}{3}(2n-1)^{\frac{3}{4}}$,"let $n<\dfrac{\pi}{2\arccos{\dfrac{c}{2}}},c\in (0,2),c=2\cos{x}$, show that $$\dfrac{\sin{(nx)}}{\sin{x}}\ge\dfrac{\sqrt{3}}{3}(2n-1)^{\frac{3}{4}}$$ where $0<x<\dfrac{\pi}{2}$ My idea: let $$a_{n}=\dfrac{\sin{(nx)}}{\sin{x}}$$
then for any $k\in[1,n]$, then we have
$$a^2_{k}-a^2_{k-1}=\dfrac{1}{\sin^2{x}}[\sin^2{kx}-\sin^2{(k-1)x}]=\dfrac{\sin{(2k-1)x}\sin{x}}{\sin^2{x}}=\dfrac{\sin{(2k-1)x}}{\sin{x}}$$ since
$$n<\dfrac{\pi}{2\arccos{\dfrac{c}{2}}}=\dfrac{\pi}{2x}\Longrightarrow 0<kx\le nx<\dfrac{\pi}{2}$$
then 
$2kx\le 2n<\pi$, so $x\le (2k-1)x<\pi-x$
so $\sin{(2k-1)x}\ge \sin{x}>0$,so
$a^2_{k}-a^2_{k-1}\ge 1$ $$a^2_{n}=\sum_{k=2}^{n}(a^2_{k}-a^2_{k-1})+a^2_{2}\ge n\Longrightarrow a_{n}\ge \sqrt{n}$$ then I can't it, I'm sorry, I just to eat
,and I'm come back","['trigonometry', 'inequality']"
912754,a custom designed cutoff function whose derivative is bounded above.,"I am trying to find a $C^\infty$ function $\phi(t)$ with the following 
properties. $\phi(t) =1$ for $\lvert t \rvert \le 1$ $\phi(t)$=0 for $t \geq 2$ $\lvert \phi'(t) \rvert \le 2 $ I have tried the obvious function $\exp\left(\frac{1}{t^2-1} \right)$ as follows. $$ \phi(t)=\begin{cases}
1 & \mbox{if} & \lvert t \rvert \le 1\\
\exp\left(\frac{1}{t^2-1}\right) & \mbox{if} & -2 < t < -1 \; \mbox{or} \; 1 < t < 2 \\
0 & \mbox{if}& \lvert t \rvert \geq 2
\end{cases} $$ But I can't seem to get the required bound on the derivative of $\phi(t)$. Question ?: What am I doing wrong here?. How can I adjust/improve this to get the bound I want?. Any suggestions?","['partial-differential-equations', 'functional-analysis', 'real-analysis']"
912781,Find the volume below $\sqrt{x}+\sqrt{y}+\sqrt{z}=1$ in the first quadrant,"I understand that we have to use transformation
$$x = u^2, y = v^2, z = w^2$$
but I cannot figure out the limits. I just need a rough sketch of how to approach this. Could anyone give me some ideas?","['multivariable-calculus', 'calculus', 'integration', 'volume']"
912801,Induction proof for $ \sum\limits_{i=1}^n i^22^i = n^22^{n+1}-n2^{n+2}+3 \cdot2^{n+1}-6 $,"I am currently writing a proof for the following problem $$ \sum\limits_{i=1}^n i^22^i = n^22^{n+1}-n2^{n+2}+3*2^{n+1}-6 $$ By induction on $n\ge0$ My question isn't really about how to correctly prove this, but I am running into some trouble finishing the $(n+1)$ part of the proof. I have $$\sum\limits_{i=1}^{n+1} i^22^i=(n+1)^22^{n+2}-(n+1)2^{n+3}+3*2^{n+2}-6$$ So, I end up up with $$\sum\limits_{i=1}^{n+1} i^22^i=\sum\limits_{i=1}^n i^22^i+(n+1)^22^{n+1}$$ I am really having trouble simplifying from this point in order to prove that $(n+1)$ holds. I am having trouble with the algebra to the point where I am starting to think I must be making some other kind of mistake.","['induction', 'summation', 'discrete-mathematics']"
912804,Evaluation of $\sum_{k=0}^n{n\choose k}^2u^k$,"I am trying to evaluate the finite sum
\begin{equation}
f(u)=\sum_{k=0}^n{n\choose k}^2u^k,\quad 0<u\le1
\end{equation} In an first attempt, I think of the generating function
\begin{equation}
(1+x)^n(u+x)^n = \sum_{k\ge0}{n\choose k}x^k\sum_{k\ge0}{n\choose k}u^kx^{n-k}=\cdots+x^n\sum_{k\ge0}{n\choose k}^2u^k+\cdots
\end{equation} which means that $f(u)$ is the coefficients of the term $x^n$. Expanding $(1+x)^n(u+x)^n$ into $[1+(1+u)x+x^2]^n$, and using the multinomial expansion, I get an expression for the coefficient of $x^n$. However, such an expression is more complicated than $f(u)$. It seems I am making the problem even more difficult. Can someone help me find the value of $f(u)$. Thank you.","['sequences-and-series', 'binomial-coefficients']"
912824,Does the sum of the reciprocals of all primes of the form $4k+1$ converge?,"Let $S=\{p\in \mathbb{Z}^+ : p\ \text{is prime and}\  p\equiv 1  \mod \ 4\}.$ Is $\displaystyle\sum_{p\in S}\frac{1}{p}$ finite or infinite, and where can I find more information about it?","['elementary-number-theory', 'number-theory']"
912845,Tangent to $e^x$,"I have been asked to find the tangent to $y=e^x$ that passes through origin.
This is what i came up with. Tangent $f(x)=e^x(x-a)+f(a)$, where a is zero, I therefore conclude with $e^xx$ to be the tangent line, however the book says the answer is ex. By looking at the formula this makes more sense because it is a  straight line. But I have learned that the derivative of $e^x$ is $e^x$. Could someone explain what I am missing?","['calculus', 'algebra-precalculus']"
912852,Define an infinite subset of primes such that the sum of reciprocals converges,How can we define an infinite subset of primes such that the sum of reciprocals converges? $S=\{p\in \mathbb{Z}^+ : p\ \text{is prime and some condition on}\ p\}$ s.t. $\sum\limits_{p\in{S}}\frac{1}{p}\neq\infty$ A few options that come to mind for the condition on $p$ are: $\log_2(p+1)\in\mathbb{N}$ $\log_2(p-1)\in\mathbb{N}$ But it has not been proved that there are infinite many such primes for either one of these options. Any ideas?,"['prime-numbers', 'number-theory']"
912889,An interesting linear algebra question,"Let $A$ and $u$ be $n\times n$ matrix and $n\times 1$ vector of $\mathbb{C}$. Denote $\overline{A}$ is the matrix $(\overline{A})_{ij}=A_{ij}^*$, the conjugate number; ($\overline{A}$ is not the conjugate transpose matrix) and similarly $\overline{u}$. Prove that if $\lambda$ is a nonnegative eigenvalue of $A\overline{A}$, ie $\exists v\ne 0:A\overline{A}v=\lambda v$, then $\exists u\ne 0$ such that:
$$A\overline{u}=\sqrt{\lambda}u$$","['matrices', 'linear-algebra']"
912898,Curious identity involving symmetric difference,"While studying the properties of measurable null sets, I found the following identity:
$\bigcup_i B_k\triangle B_i=\bigcup_i B_i - \bigcap_i B_i $ Or in other words, the value of the expression is independent of the choice of $k$. I can prove this using a case separation in first principles, but it doesn't give me much intuition on why it is true. So I'm asking if the above can be deduced just using basic set algebra? Edit: I mean is there a sequence of rewritings that reveal the symmetry of the statement?","['boolean-algebra', 'elementary-set-theory']"
912931,Viewing a sequence as a function on the space of positive integers,"I see the following lines in a book : "" Consider a bounded sequence of real or complex numbers $\{\eta_n\}$. Such a sequence $\{\eta_n\}$ defines a function $x(n) = \{\eta_n\}$ defined on the discrete space $S=\{1,2,3,\dots \}$ "" Does it trying to say that because the sequence is bounded it can define the function. Why is that ? consider the sequence of natural numbers.","['functions', 'sequences-and-series', 'real-analysis']"
912946,Finite sequences of prime numbers,"There is a lot of prime sequences : prime numbers in a special form.
For example Mersenne primes are primes of the the form $2^n-1$, or Pythagorean prime are primes of the form $4n+1$. Even primes are primes of the form $2n$. The only even prime is $2$. Is that anything else? I mean primes sequences which are finite sequences by proof, and not by conjecture.","['prime-numbers', 'sequences-and-series', 'big-list', 'number-theory']"
912950,"If $f,g$ are entire functions and$\ fg\equiv 0$ then either $f \equiv 0$ or $g\equiv0. $","Let $f,g$ be entire functions such that $g \not\equiv 0.$ If $fg\equiv0$ in $\mathbb{C},$  could anyone advise me how to show $f \equiv0$ in $\mathbb{C} \ ?$  Thank you.",['complex-analysis']
912965,"Verlinde formula, moduli space vector bundle on genus 2,3 curves.","I'd like to prove ""by hands"" the Verlinde formula for moduli space of rank two semistable vector bundles with fixed determinant on a curve of genus two and three.
For a curve of genus two and even degree I proved that this moduli space is isomorphic to $\mathbb{P}^3$, using GIT techniques, so it's ok! For the odd case I know that this space is isomorphic to the intersection of two quadric in $\mathbb{P}^5$. For what concerne the proof I saw the Newstead's article. Does a modern proof of this statement exist?
Furthermore, could you give me a suggestion about how to proceed the genus three case? I studied the singularity and went on with three blow up for the even case following the work of Kiem. How can I say in this way something about the cohomology of this space?","['algebraic-geometry', 'algebraic-topology']"
912989,The differential $\text d F_p$ is injective iff the pullback $F_p^*$ is surjective.,"I'm trying to prove the following claim: Let $F\colon M \to N$ be a differentiable application beetween $C^\infty$ manifolds. Then the differential $\text dF_p\colon T_p M \to T_{F(p)}N$ is injective if and only if the pullback $F_p^*\colon C^\infty _N (F(p))\to C^\infty _M (p)$ is surjective. Where $C^\infty _S (q)$ are the germs in $q$, $F_p^*(\mathbf g)=\mathbf g \circ F$ and $\text dF_p (X)=X\circ F_p ^*$. I'll use Einstein's convention on summations.
Let $(\varphi = (x^1,x^2,\dots,x^n),U)$ be a local chart in $p$. Sufficiency: Proof by contrapositive: suppose that $\text d F_p(X^i \partial _i |_p)=O$ and $X^k\neq 0$. Then for all $\mathbf g \in C^\infty _N (F(p))$ $$0=\text d F_p(X^i \partial _i |_p)(\mathbf g)=X^i \partial _i |_p(F_p ^*(\mathbf g)).$$
This shows that $\mathbf x ^k$ is not in the image of $F_p ^*$, hence if $F_p^*$ is surjective then $\text d F _p$ is injective. [] Now for the converse, I was reasoning on these lines: if $F_p ^* (\mathbf h)\neq \mathbf g$ for all $\mathbf h \in C^\infty _N (F(p))$ and for some $\mathbf g \in C^\infty _M (p)$, then we can consider the ideal $$I=\{ \mathbf g \cdot \mathbf f_0 | \mathbf f _0 \in C^\infty _M (p)\}.$$
It is easily seen that $$\text {Im}F_p ^*\cap I= \{\mathbf 0 \}.$$
Now, if I could find a derivation such that $X(\mathbf g)=1$ and $X(C^\infty _M (p) - I)=\{0\}$ this would be done. My problem is to find such $X$. Since it is not restrictive to assume $\mathbf g(p)=0$, more generally a derivation would act on $I$ in this way: $$X(\mathbf f)=X(\mathbf g \mathbf f _0)=X(\mathbf g)\mathbf f(p),$$
however I'm not sure if I can use this fact in any way. Any help is appreciated; I'd prefer to complete my proof, but also a different one would be OK.",['differential-geometry']
912996,Errors and Residual,"Why are errors independent but residuals dependent? As far i know the sum of the residuals within a random sample is necessarily zero, and thus the residuals are necessarily not independent. But also we assume that $\mathbb E(\epsilon)=0$. Why doesn't it imply errors are also not independent?","['statistics', 'regression', 'sampling', 'normal-distribution', 'statistical-inference']"
913057,Riesz Functional Calculus vs. Holomorphic Functional Calculus,"""Functional calculus"" is a word used to describe the practice of taking some functions or formulas defined on complex numbers, and apply them in some way to certain kinds of operators, despite that operators are not complex numbers and so they are not in the domain of the function. There are many kinds of functional calculus.
(Correct me if I'm wrong about something: I'm studying these topics right now) There is the so called Continuous functional calculus, that applies a continuous function defined on the spectrum of a normal operator in a unital C*algebra to that operator. There is the Borel functional calculus that aims to apply a more general Borel function to a self-adjoint operator. And there are the Riesz and Holomorphic functional calculus, that apply the analytic functions to some kind of operators. I didn't catch the difference between these last two. Can someone please try to explain that to me briefly?
Thank you.","['operator-theory', 'operator-algebras', 'spectral-theory', 'functional-analysis']"
913060,Solve second order ODE knowing one of its solutions,"Solve $t^2x''-4tx'+6x=0$ knowing that $x_1(t)=t^2+t^3$ is a particular solution So I assumed the general solution will be in form of $x(t)=C_1 x_1(t)+C_2 x_2(t)$ and $x_2 = v(t)x_1(t)$ So now I have to find $x_2$ $$x_2=v(t^2+t^3)$$
$$x_2'=v'(t^2+t^3)+v(2t+3t^2)$$
$$x_2''=v''(t^2+t^3)+2v'(2t+3t^2)+v(2+6t)$$ And if I try to plug it into my equation I get something very complicated, as almost nothing reduces. Is it the right way to do it? EDIT: ill try to plug it in here and see what happens since I probably made a mistake $$t^2(v''(t^2+t^3)+2v'(2t+3t^2)+v(2+6t))-4t(v'(t^2+t^3)+v(2t+3t^2))+6(v(t^2+t^3))=0$$
dividing both sides by $t^2$
$$v''(t^2+t^3)+2v'(2t+3t^2)+v(2+6t)-4(v'(t+t^2)+v(2+3t))+6(v(1+t))=0$$
$$v''(t^2+t^3)+v'(2(2t+3t^2)-4(t+t^2))+v((2+6t)-4(2+3t)+6(1+t))=0$$
$$v''(t^2+t^3)+v'(4t+6t^2-4t-4t^2)+v(2+6t-8-12t+6+6t)=0$$
$$v''(t^2+t^3)+v'(2t^2)=0$$ Yeah I made a mistake, thanks for pointing that out.",['ordinary-differential-equations']
913070,"How ""far"" a differential form is from an exterior product","Consider two differential manifolds $X$ and $Y$.
Consider now a differential form (of any order) $\omega$ on $X\times Y$. The easiest example is taking $\omega=\xi\wedge\eta$, where $\xi$ is a differential form on $X$ and $\eta$ is a differential form on $Y$. In general, any form $\omega$ is not such an exterior product. Is there a way to ""measure"" how much $\omega$ differs from being such a decomposition? I'm looking for something in the ""spirit"" of: The rank of a matrix measures how much the matrix differs from being a tensor product of two vectors. Is there an analogous quantity for differential forms? Thanks.","['differential-forms', 'differential-geometry']"
913093,A normal matrix with real eigenvalues is Hermitian,"$A$ is a normal matrix (i.e. $AA^*=A^*A$, where * denotes the hermitian conjugate). If all its eigenvalues are real, prove that it is Hermitian (i.e. $A^*=A$). I have tried many things but could not complete a proof.
Could anybody please provide some help?","['matrix-decomposition', 'eigenvalues-eigenvectors', 'hermitian-matrices', 'matrices', 'linear-algebra']"
913108,In how many ways you can put n white balls and 2n black balls into n boxes if at least one black ball have to be in each box,"n - number of white balls 2n - number of black balls In how many ways you can put it into n boxes? It have to be at least one black ball in each box. My idea:
First of all let's put one black ball in each box.
We have got n white balls and n black balls to put into n boxes so my problem is how to put 2n balls into n boxes.
So it's like solving an equation:
$x_1+x_2+...+x_n=2n (x_n>=0)$
Is it correct?","['discrete-mathematics', 'probability']"
913115,Amalgams of two nontrivial group is trivial,"I got this question in the book Tree by Serre. 
Let A=$Z$. $G_1=PSL(2,Q)$ and $G_2=Z/2Z$. We take $f_1: A\rightarrow G_1$ to be an 
injective (I do not know what is this injective map ?) and $f_2:\rightarrow G_2$ to be natural surjection map. Show that $G_1*_{A} G_2$=1$. If I understand the injective map then I can play with the relation. Any help, hint will be very appreciated.",['group-theory']
913119,Determinant of Fisher information,"In information geometry, the determinant of the Fisher information matrix is a natural volume form on a statistical manifold, so it has a nice geometrical interpretation. But what is it in statistics? Does it measure anything meaningful? (For example, I would say that if it is zero, then the parameters are not independent. Does this go any further?) Also, is there any closed form to compute it? Thanks. Update : I posted a similar question on stats.se .","['statistics', 'information-theory', 'information-geometry']"
913156,"In an irreducible, aperiodic, null-recurrent Markov chain holds $\sum_n p_{ij}^{(n)} = \infty$","My lecture notes state the following theorem: Theorem 2. Let $(X_n)$ be an irreducible, aperiodic, null-recurrent Markov chain. Then $$\forall i,j \in S : p_{ij}^{(n)}\to 0 \text{ and } \sum_n p_{ij}^{(n)} = \infty$$ And the proof starts like this The divergence of the series $\color{red}{\text{follows}}$ from the Theorem 1, so we just need to show $p_{ij}^{(n)}\to 0$ . Okay, I go to the theorem 1 and see roughly the following: Theorem 1. Let $(X_n)$ be a Markov chain. If $i\in S$ is recurrent then $\sum_n p_{ii}^{(n)} = \infty$ . If $i\in S$ is transient then $\sum_n p_{ii}^{(n)} < \infty$ . I tried to figure out why would it follow by trying to come up with an inequality like $$p_{ii}^{(n+m+k)}\geq p_{ij}^{(n)} p_{jj}^{(m)} p_{ji}^{(k)}$$ yet it didn't help. In other sources, it seems to be a non-trivial result which is proven with Abel's lemma. So my question is: can the divergence of the series in theorem 2 be followed from theorem 1?","['stochastic-processes', 'sequences-and-series', 'markov-chains', 'probability-theory', 'divergent-series']"
913163,Software or tool for investigating groups,"I'm interested in software that has the ability to investigate finite groups. In particular, I'd like to be able to ask it questions like ""What are the solutions to $x^3 = 1$?"" (i.e. find cube roots of unity) for a permutation group. I've had a look at Maxima but don't see a way to ask it do that.","['finite-groups', 'group-theory', 'math-software']"
913166,Counting partition of set that $i$ and $i+1$ are not in one part,"I have to count the number of partitions of the set $\{1,\ldots,n\}$
under the constraint that for each $i$, the elements $i$ and $i+1$ are in different parts. The my idea is: We have two situation when it comes to $1,2,3
\to \{1\}\{2\}\{3\}$ or $\{1,3\}\{2\}\{\text{ one of }\{4,5,\ldots n\}\}$.
For every element I choose part (there are two possibilities)
Thus,
$$2^{n-3} + (n-3)2^{n-4} $$","['set-partition', 'combinatorics']"
913181,Solve $x^2+tx'+x=0$,"Solve $x^2+tx'+x=0$ this is clearly a Bernoulli's equation so I make a substitution $z=\frac 1 x$
$$x=\frac 1z$$
$$x'=\frac {-z'}{z^2}$$
$$\frac {1}{z^2}-\frac {tz'}{z^2}+\frac 1 z=0$$
$$1-tz'+z=0$$
$$z+1=tz'$$
$$log|z+1|=log|t|+C$$
$$z=Ct+1$$
$$x=\frac {1}{Ct+1}$$ But the actual answer to this is 
$$x=\frac {e^C}{t-e^C}$$
Wolfram alpha also shows the second answer, so my question is where did I make a mistake, and if I didnt then why these two solutions differ so much?",['ordinary-differential-equations']
913182,"A Question Pertaining to the Mean Value Theorem on the End Points of $[a, b]$","So I'm beginning numerical analysis and an interesting thing was brought up in class. I know the rules for MVT are: $F$ is continuous on $[a,b]$ $F$ is differentiable on $(a,b)$ So a question was brought up in class I couldn't answer. Why is it that we don't consider differentiability at the end points? The professor sort of assumed we knew the answer but I didn't. My calculus is rusty. Is there any reason we can't know why the end-points aren't differentiable? A person in class suggested it had to do something with not knowing whats on the other side of the point, but that didn't make any sense to me. Can anyone break this down for me so I can really understand it? Thank you!","['calculus', 'derivatives', 'limits']"
913195,Integral $\int_0^{\large\frac{\pi}{4}}\left(\frac{1}{\log(\tan(x))}+\frac{1}{1-\tan(x)}\right)dx$,"I am wondering if anyone would know how to evaluate this integral:
$$\int_{0}^{\Large\frac{\pi}{4}}\left(\frac{1}{\log(\tan(x))}+\frac{1}{1-\tan(x)}\right)dx.$$ I've tried, unsuccessfully, the change of variables $u=\tan (x)$.","['definite-integrals', 'closed-form', 'calculus', 'integration']"
913200,"Proof of paracompactness of CW-complexes (J. Lee, Introduction to Topological Manifolds)","I have a question about a proof in John Lee's Introduction to Topological Manifolds (5.22). Given CW-complex $X$ with skeletons $X_n$ and open cover $\left(U_\alpha\right)_{\alpha\in A}$, we inductively define partitions of unity $\left\{\psi_\alpha^n\right\}$ on $X_n$ subordinate to cover $\left(U_\alpha^n=U_\alpha \cap X_n\right)_{\alpha\in A}$, such that $\psi_\alpha^k\mid_{X_{k-1}}=\psi_\alpha^{k-1}$ If $\psi_\alpha^{k-1}\equiv 0$ on an open subset $V \subset X_{k-1}$, then there is an open subset $V'\subset X_k$, containing $V$ on which $\psi_\alpha^k\equiv 0$ At the end of the induction step, prof. Lee proceeds to argue that supports of $\left\{\psi_\alpha^{n+1}\right\}$ form locally finite family. If $x$ is in the interior of an $(n+1)$-cell, then that cell is a neighborhood of $x$ on which only finitely many of the functions $\psi_\alpha^{n+1}$ are nonzero by construction. On the other hand, if $x\in X_n$, because $\left\{\psi_\alpha^n\right\}$ is a partition of unity there is some neighborhood $V$ of $x$ in $X_n$ on which $\psi_\alpha^n\equiv 0$ except when $\alpha$ is one of finitely many indices, and then (2) shows that $\psi_\alpha^{n+1}\equiv 0$ on $V'$ except when $\alpha$ is one of the same indices. I don't understand why does this imply local finiteness. Because of (2), there is a $V'$ for each such $\alpha$, but unless I'm missing something obvious, there can be infinitely many such alphas. How can we conclude there is a single neighborhood of $x$ in $X_n$ on which all these functions vanish?","['general-topology', 'paracompactness', 'cw-complexes']"
913209,"Let $S$ denote the set of all functions $f :\{0,1\}^4 \rightarrow \{0,1\}$. What is the number of functions from the set $S$ to the set $\{0,1\}$?",They say the answer is $2^{2^{16}}$ but I think the answer is $3^{3^{16}}$ because they have not specified the functions to be total.  Am I correct? PS: I am a newbie so please don't be too harsh if I have made some terrible mistake.,"['combinations', 'combinatorics']"
913276,Units of vaiance when variable is in %.,"I have some confusion here. If some random variable is measured in some units, say $kg$
then clearly it's variance is measured in $kg^2$. But if the variable is dimensionless 
and measured say in  $\%$ or base points in what unit the variance is measured? $\%^2$?
Does it make sense?. It seems for me a bit weird.",['statistics']
913283,What is a geometric structure?,"Every elementary book on abstract algebra usually begins with giving a definition of algebraic structures; generally speaking one or several functions on cartesian product of a point-set to the set. My question is this: Is there a property that unifies different geometric structures like topology(I consider it a geometric structure), differential structure, incidence structure and so on? Can one say a geometric structure on a set one way or another involves a subset of its powerset ?","['geometry', 'soft-question']"
913287,Relationship between Primes and Fibonacci Sequence,"I recently stumbled across an unexpected relationship between the prime numbers and the Fibonacci sequence. We know a lot about Fibonacci numbers but relatively little about primes, so this connection seems worth exploring. I'm interested whether anyone knows of a theorem or proof of whether this relationship holds true in general for primes > 5 -- I've empirically tested it for the first 100k primes using Mathematica, but that's hardly a proof. $$
S_n = GCD(n, Fib(n+1))
$$
If we evaluate this for $n ~ in ~{1..100}$ we get: {1, 2 , 3 , 1, 1, 1, 7 , 2, 1, 1, 1, 1, 13 , 2, 3, 1, 17 , 1, 1, 2, 1, 1, 23 , 1, 1, 2, 3, 1, 1, 1, 1, 2, 1, 1, 1, 1, 37 , 2, 3, 1, 1, 1, 43 , 2,
     1, 1, 47 , 1, 1, 2, 3, 1, 53 , 1, 1, 2, 1, 1, 1, 1, 1, 2, 21, 1, 1, 1, 67 , 2, 1, 1, 1, 1, 73 , 2, 3, 1, 1, 1, 1, 2, 1, 1, 83 , 1, 1, 2, 3, 1,
     1, 1, 1, 2, 1, 1, 1, 1, 97 , 2, 33, 1} What's interesting about this result is that primes appears at their natural indexes: 2 appears at $n_2$, 13 appears at $n_{13}$, 83 appears at $n_{83}$, and so on. But some of the primes are missing, including: {5, 11, 19, 29, 31, 41, 59, 61, 71, 79, 89} But let's also examine the sequence:
$$
P_n = GCD(n, Fib(n-1))
$$ Here we find that in the first 100 terms we get: {1, 1, 1, 2, 1, 1, 1, 1, 3, 2, 11 , 1, 1, 1, 1, 2, 1, 1, 19 , 1, 3, 2,
1, 1, 1, 1, 1, 2, 29 , 1, 31 , 1, 3, 2, 1, 1, 1, 1, 1, 2, 41 , 1, 1, 1,
3, 2, 1, 1, 7, 1, 1, 2, 1, 1, 1, 1, 3, 2, 59 , 1, 61 , 1, 1, 2, 1, 1,
1, 1, 3, 2, 71 , 1, 1, 1, 1, 2, 1, 13, 79 , 1, 3, 2, 1, 1, 1, 1, 1, 2, 89 , 1, 1, 1, 3, 2, 1, 1, 1, 1, 1, 2} If we combine the sequences $S_n$ and $P_n$ we seem to get all of the primes, except 5: {2, 3, ( missing : 5), 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67,
71, 73, 79, 83, 89, 97} Below is a simple Mathematica program that tests this for the first few thousand values: fibSuc[x_] := GCD[n, Fibonacci[n + 1]];
fibPre[x_] := GCD[n, Fibonacci[n - 1]];
fibPRZ[w_, fp_] :=
  (Cases[Select[Transpose[{Table[fp[n], {n, 1, w}], 
     Table[x, {x, 1, w}]}], PrimeQ[#1[[2]]] & ], {a_, a_}]) /. {a_, a_} -> a;
genPrimes[z_] := Union[fibPRZ[z, fibSuc], fibPRZ[z, fibPre]];

With[{pz = genPrimes[50000]},
   Complement[Table[Prime[n], {n, 1, Length[pz] + 1}], pz]]","['divisibility', 'number-theory', 'prime-numbers', 'fibonacci-numbers', 'open-problem']"
913294,Guess the smallest number,"Three people play a game where each of them writes down a positive integer at the same time. The one who writes a unique and smallest number wins one dollar from every other person. This means if two people happen to write down the same number, then the third one gets one dollar from each of them regardless. Now what number would you put if you were to play this game?","['game-theory', 'probability']"
913317,"Prove that the symmetric group $S_n$, $n \geq 3$, has trivial center. [duplicate]","This question already has answers here : Find the center of the symmetry group $S_n$. (4 answers) Closed 6 years ago . I am trying to prove this: Let $\sigma$ be a non-identity element of $S_{n}$ . If $n \geq 3$ show that $\exists \gamma \in  S_{n}$ such that $\sigma\gamma \neq \gamma\sigma$ . Hint: Let $\sigma*k=1$ where $k \neq 1$ . Let $m$ not be an element of $\{k,1\}$ . Let $\gamma=(k,m)$ Here's the answer from the textbook: Let $\sigma*k=1$ for some $k \neq 1$ . Then as $m\geq 3$ , choose an $m$ not an element of $\{k,1\}$ . Now let $\gamma=(k,m)$ . This gives $\gamma*\sigma*k=\gamma*(1)=1$ but $\sigma*\gamma*k=\sigma*m \neq 1$ , since if $\sigma*m=1=\sigma*k$ , then $m=k$ , as $\sigma$ is one-to-one contrary to the assumption. I guess I'm just not understanding the steps to their proof. Can anybody make sense of this to someone new to proofs? I mostly don't understand how $\sigma*\gamma*k=\sigma*m=1$","['abstract-algebra', 'proof-verification', 'symmetric-groups', 'alternative-proof', 'group-theory']"
913320,what is vector $(\vec{a}\cdot \vec{b})\vec{c} + (\vec{b}\cdot \vec{c})\vec{a} - (\vec{c} \cdot \vec{a})\vec{b}$,"Suppose we have three non orthogonal vectors in $R^3$ as $\vec{a}, \vec{b}, \vec{c}$. The vector of $(\vec{b}\cdot \vec{c})\vec{a} - (\vec{c} \cdot \vec{a})\vec{b}$ is in the plane spanned by $\vec{a}$ and $\vec{b}$, and it is perpendicular to $\vec{c}$. Is there a similar geometric explanation for vector 
 $$(\vec{a}\cdot \vec{b})\vec{c} + (\vec{b}\cdot \vec{c})\vec{a} - (\vec{c} \cdot \vec{a})\vec{b}$$? EDIT: Answer by Muphrid indicates this is a normal vector (with dilation) of three consecutive reflections to normal vector $a, b, c$. Can this be carried out without using geometric products? Starting from a reflection as $x' = x - 2(x \cdot n)n$, it gets complicated for me.","['vector-spaces', 'geometry', 'geometric-algebras']"
913333,Definition of reciprocal derivative,"Suppose I define $y(x)=x^3$. Then, $$\frac{\mathrm dy(x)}{\mathrm dx}=3x^2.$$
however I don't see how $\displaystyle \frac{\mathrm dx(y)}{\mathrm dy}$=$\frac{1}{3x^2}$ because I never explicitly define $x(y)$ which has implications for coupling across equations of variables. $x(y)$ and $y(x)$ leads to a possible recursive definition $x(y(x))$ ... $y(x(y))$  Could someone help me resolve this?  Thank you!","['calculus', 'derivatives']"
913349,A group of order $120$ has a subgroup of index $3$ or $5$ (or both),"What I have tried that number of $2$-sylow subgroup can be $1,3,5$ or $15$.I have solved the problem when the number of $2$-sylow subgroup is $1,3,5$. But I am not able to solve it for $15$. Any help will be appreciated..","['sylow-theory', 'finite-groups', 'group-theory', 'abstract-algebra']"
913350,How to find the intersection point of two moving circles?,"I'm trying to develop a simulation in C#, and I have to find the intersection (or collision) point of two moving circles, in 2D space. Actually one of my circles will be stationary, so only one of them will be moving (linearly, i.e. constant velocity) So I have two circles with radii R1 and R2, and center points P1 and P2, and the point P1 is changing with constant velocity V1, so I need a way to determine at which point will they collide, also to check if they will collide at all. Thanks for any help ! Edit : For the checking (if they will collide) part, I think we can do it by simply calculating the shortest distance between the first circle's velocity line, and the second circle's center, and checking if the distance is greater than R1+R2, so the only thing remains is to find the collision point. So the question is : I am assuming the circles will collide, and I need an expression for the collision point P, in terms of P1, P2, R1, R2 and V1.","['collision-detection', 'geometry', 'circles']"
913366,A method of making a graph bipartite,"If we take a graph $G$, and sequentially delete the edge which belongs to the most odd cycles until we have a bipartite graph, will at least half the edges remain when the graph is bipartite? Background: It is well known every graph, $G$, has a bipartite subgraph with at least $e(G)/2$ edges ($e(G)$ is the number of edges in $G$). One way to find such a subgraph is to greedily add vertices to one of two glasses at each step minimizing the number of crossing edges.  So my interest is in a greedy method based on the cycle interpretation bipartiteness rather than the two color interpretation. Note: This problem has bean crossposted and solved in the negative on MO https://mathoverflow.net/questions/180370/a-method-for-making-a-graph-bipartite Interestingly, we can not even replace $1/2$ with any positive constant.","['extremal-combinatorics', 'combinatorics']"
913401,Example of limit of a function,"I'm self-studying from the book Understanding Analysis by Stephen Abbott, and I don't understand example 4.2.2 on page 105. The aim of the example is to show that:
$$
\lim_{x \to 2} g(x) = 4
$$ 
where $g(x) = x^2$. The author starts by writing:
$$
|g(x) - 4| = |x^2 - 4 | = |x+2||x-2|
$$
which I understand. But then the following paragraph makes no sense to me: We can make $|x-2|$ as small as we like, but we need an upper bound on $|x+2|$ in order to know how small to choose $\delta$. The presence of the variable $x$ causes some initial confusion, but keep in mind that we are discussing the limit as $x$ approaches $2$. If we  agree that our $\delta$-neighborhood around $c = 2$ must have radius no bigger than $\delta = 1$, then we get the upper bound $|x + 2| \leq |3 + 2| = 5$ for all $x \in V_\delta(c)$. By saying we are only considering the $\delta$-neighborhood around $c=2$ with a radius smaller than or equal to $1$, I would think we get:
$$
V_\delta (c) = \{ x \in \mathbb{R} \mid |x-2| < 1 \} = (1,3)
$$
so I don't understand where ""$|x + 2| \leq |3 + 2| = 5$ for all $x \in V_\delta(c)$"" comes from? Any help is much appreciated.","['functions', 'epsilon-delta', 'real-analysis', 'limits']"
913410,Isomorphism between $C^\infty_0(B_1)$ and $\mathscr{S}(\mathbb{R}^n)$,"Background: Related question I am trying to prove, that the countably-normed spaces $C^\infty_0(B_1)$ on the open unit ball (i.e. function and all derivatives vanish at the boundary) in $\mathbb{R}^n$ and the Schwartz Space $\mathscr{S}(\mathbb{R}^n)$ are isomorphic. Here, $\mathscr{S}$ carries the usual Schwartz topology and $C^\infty_0(B_1)$ the locally convex topology induced by the family $\|\varphi\|_i=\sup_{x\in B_1}\max_{|\alpha|\leq i}|D^\alpha\varphi|$. My ansatz is to use, that the open unit ball and whole $\mathbb{R}^n$ are diffeomorphic, e.g. via the diffeomorphism
$$
h:x\rightarrow \frac{x}{\sqrt{1+|x|^2}}
$$
therefore my guess for the isomorphism is
$$
I:C^\infty_0(B_1)\rightarrow \mathscr{S}(\mathbb{R}^n), f\rightarrow f\circ h
$$
However, I am unable to prove, that $I$ and $I^{-1}$ are continuous with respect to the locally convex topology. Concretely, I have to show that
for every pair $p,q\in \mathbb{N}$ there exist $r\in \mathbb{N},C>0$ with
$$
\sup_{x\in \mathbb{R}^n}\max_{\alpha\leq q} (1+|x|^2)^p|D^\alpha (\varphi \circ h) | \leq C \sup_{x\in B_1}\max_{\alpha\leq r} |D^\alpha \varphi |
$$ for all $\varphi\in C_0^\infty(B_1)$, similar for $I^{-1}$. The crux about the continuity has to be, that the vanishing at the boundary of $B_1$ for some function $\varphi$ somehow also implies the vanishing at infinity for $I(\varphi)$, however, I am not able to formulate a clean proof for this. Does anybody have an idea or a reference? I found a similar statement in Treves (Topological Vector Spaces) Theorem 51.4, unfortunately, the proof of the theorem was ""left as exercise"", and I am obviously too dumb to solve it. I would greatly appreciate any help!","['locally-convex-spaces', 'distribution-theory', 'functional-analysis']"
913422,Let $P$ be a finite poset. Show that the number of order ideals equals the number of antichains.,"Can someone please verify my proof or offer suggestions for improvement? I am aware that there are similar questions posted elsewhere, but I need help with my proof in particular. Some preliminaries: Let $P$ be a poset. An antichain $C$ is a subset of $P$ such that for all $x, y \in C$ with $x \neq y$, $x$ is incomparable with $y$. An order ideal $I$ is a subset of $P$ such that $x \in I$ and $y \leq x$ implies $y \in I$. Let $P$ be a finite poset. Show that the number of order ideals equals the number of antichains. Let $I$ be an order ideal, and let $M$ be the set of maximal elements of $I$. Then, $M$ is an antichain in $P$ (Let $x, y \in M$ with $x \neq y$. If $x \leq y$, then $x$ is not a maximal element of $I$, a contradiction.) Let $I_1$ and $I_2$ be two order ideals in $P$ with the same set of maximal elements $M$. We show that it must be the case that $I_1 = I_2$. Suppose, for the sake of contradiction, that there exists an $x \in I_2$ such that $x \notin I_1$. Then, it must either be the case that $x \leq m$ for some  maximal element $m$, or $x$ is incomparable with every maximal element. The first case implies that $x \in I_1$, and the second implies that $x$ is a maximal element of $I_2$. In either case, we arrive at a contradiction. Therefore, it must be the case that $I_1 = I_2$. Now, let $A$ be an antichain in $P$. Set $I_A = \{x \in P: x \leq y$ for some $y \in A\}$. Then, $I_A$ is clearly an order ideal in $P$. Also, if $A \neq A'$, $I_A \neq I_{A'}$. Since there is a one-to-one correspondence between the order ideals and the antichains in $P$, and $P$ is finite, it must be the case that the number of order ideals and antichains in $P$ are equal.","['order-theory', 'proof-verification', 'combinatorics']"
913431,Help with Differential Equation,"Our differential equation is:
  $$
y' + 2y/3 = 1-t/2
$$
  Consider $y_0$ and find the value for which the solution of our differential equation touches, but does not cross, the $t$-axis. EDIT I've resolved the original discrepancy that spurned this question. However, I'm having trouble answering the actual question above. That is, I am having trouble finding the point at which Y touches, but does not cross, the t-axis and solving for the solution. I have solved for $y=-3t/4+(21/8)+Ce^{-2t/3}$. This is correct, as confirmed by other posters below. Must I input this into some program like Matlab or can I answer this question using only pen and paper?",['ordinary-differential-equations']
913449,Is every finite group of isometries a subgroup of a finite reflection group?,"Is every finite group of isometries in $d$-dimensional Euclidean space a subgroup of a finite group generated by reflections? By ""reflection"" I mean reflection in a hyperplane: the isometry fixing a hyperplane and moving every other point along the orthogonal line joining it to the hyperplane to the same distance on the other side. Every isometry is a product of reflections; in $d$-space, at most $d+1$ reflections are needed.
So, every finite group of isometries is a subgroup of a group generated by reflections; just choose some reflections that yield each isometry, and take the group generated by those. The question is whether the reflections can always be chosen so that the resulting group is still finite, or even discrete. Every finite group $G$ of isometries has a fixed point. If we regard this fixed point as the origin, then $G$ is a finite subgroup of the orthogonal group $O(d)$. Orthogonal transformations are the product of at most $d$ reflections in hyperplanes through the origin. I have found some claims that the answer is ""Yes"", but it's not clear if they mean for arbitrary dimension, or just 3-space. Also, no proofs are provided. This monograph ""Symmetry Groups"" claims ""All the finite groups are reflection groups or subgroups thereof"" (p.11). This webpage says 
""All symmetry groups will be subgroups of groups generated by reflections.""","['coxeter-groups', 'discrete-geometry', 'finite-groups', 'symmetry', 'group-theory']"
913487,How do I solve $x^5 +x^3+x = y$ for $x$?,"I understand how to solve quadratics, but I do not know how to approach this question. Could anyone show me a step by step solution expression $x$ in terms of $y$? The explicit question out of the book is to find $f^{-1}(3)$ for $f(x) = x^5 +x^3+x$ So far I have reduced $x^5 +x^3+x = y$ to $y/x - 3/4 = (x^2 + 1/2)^2$ or $y = x((x^2+1/2)^2 + 3/4)$ but Im still just as lost.","['inverse', 'functions', 'polynomials']"
913494,Is there closed form for $\int_0^{\pi/4}\exp(-\sum_{n=1}^{\infty}\frac{\tan^{2n}x}{n+a})\ dx$?,"Is there closed form for  $$I(a)=\int_0^{\pi/4}\exp\left(-\sum_{n=1}^{\infty}\frac{\tan^{2n}x}{n+a}\right)dx $$where is $a\in (-1,3)$ I've tried with $\tan x=u$ and I got the result of sum in term of HurwitzLerchPhi but I failed.","['definite-integrals', 'closed-form', 'calculus', 'integration']"
913501,"Find $\int_0^\pi \sin(x)\,dx$ explicitly","A book asks me to prove that: $$\int_0^{\pi}\sin(x)\,dx = 2$$ Using the identity: $$\sin\left(\frac{\pi}{n}\right) + \sin\left(\frac{2\pi}{n}\right) + \cdots + \sin\left(\frac{n\pi}{n}\right) = \frac{\cos\left(\frac{\pi}{2n}\right)-\cos\left(\frac{(2n+1)\pi}{2n}\right)}{2\sin\left(\frac{\pi}{2n}\right)}$$ And the famous $\lim_{x\to0}\frac{\sin(x)}{x} = 1$ What I tried: Using the Right Riemann Sum Method: $$\int_a^{b}\sin(x)\,dx \approx \Delta x\left[f(a + \Delta x) + f(a + 2\,\Delta x) + \cdots + f(b)\right]$$ By taking $\Delta x = \frac{\pi}{n}$, $a = 0$ and $b = \pi$ we have: $$\int_0^{\pi}\sin(x)\,dx \approx \Delta x\left[f(\Delta x) + f(2\,\Delta x) + \cdots + f\left(\frac{n\pi}{n}\right)\right] = \frac{\pi}{n}\left[\sin\left(\frac{\pi}{n}\right) + \sin\left(\frac{2\pi}{n}\right) + \cdots + \sin\left(\frac{n\pi}{n}\right)\right] = \frac{\pi}{n}\left[\frac{\cos\left(\frac{\pi}{2n}\right)-\cos\left(\frac{(2n+1)\pi}{2n}\right)}{2\sin\left(\frac{\pi}{2n}\right)}\right]$$ So $$\int_0^\pi \sin(x)\,dx = \lim_{n\to\infty} \frac{\pi}{n}\frac{\cos\left(\frac{\pi}{2n}\right)-\cos\left(\frac{(2n+1)\pi}{2n}\right)}{2\sin\left(\frac{\pi}{2n}\right)}$$ I can't see, however, how to prove this limit to be $=2$","['calculus', 'integration']"
913513,Use Taylor Series method to solve $y''-2xy+y=0$,"I am doing some practice problems for solving second order ODEs, and I am a bit stuck on this one. Here is what I have: $y''-2xy'+y=0$ Let $y = \sum_{n=0}^{\infty} C_nx^n  \implies y' = \sum_{n=0}^{\infty} nC_nx^{n-1} \implies y'' = \sum_{n=0}^{\infty} n(n-1)C_nx^{n-2} $ Substituting this into the ODE, and I get: $$ \sum_{n=0}^{\infty} n(n-1)C_nx^{n-2}  -2\sum_{n=0}^{\infty} nC_nx^{n}+ \sum_{n=0}^{\infty} C_nx^n = 0$$ Then getting each term to $x^n$ and starting each sum at $n=0$, I have: $$ \sum_{n=0}^{\infty} [(n+2)(n+1)C_{n+2}-2 nC_n+ C_n]x^n = 0 $$
$$ \implies C_{n+2} = \frac{(2n-1)C_n}{(n+2)(n+1)}$$ I notice that this decouples into two series' for odd and even terms, but I am having trouble with determining the general formula for $C_n$ for each series: For $n$ even: When $n=0: C_2 = \frac{-C_0}{2} $ When $n=2: C_4 =  \frac{3C_2}{4 \cdot 3} = \frac{-3C_0}{4!} $ When $n=4: C_6 =  \frac{7C_4}{6 \cdot 5} = \frac{-7 \cdot 3C_0}{6!} $ When $n=6: C_8 =  \frac{11C_6}{8 \cdot 7} = \frac{-11 \cdot 7 \cdot 3C_0}{8!} $ For $n$ odd: When $n=1: C_3 = \frac{C_1}{3 \cdot 2} $ When $n=3: C_5 =  \frac{5C_3}{5 \cdot 4} = \frac{5C_3}{5!} $ When $n=5: C_7 =  \frac{9C_5}{7 \cdot 6} = \frac{9 \cdot 5C_1}{7!} $ When $n=7: C_9 =  \frac{13C_7}{9 \cdot 8} = \frac{13 \cdot 9 \cdot 5C_1}{9!} $ I am mainly finding it difficult to determine the closed formula for the numerator in each series, so that I can calculate the radius of convergence of each one. Thanks so much, any help is greatly appreciated.","['power-series', 'ordinary-differential-equations', 'taylor-expansion']"
913547,Statistical Estimation Book Request,"I am seeking a clear book for parameter estimation, estimation methods, properties of estimators, minimum variance estimators, asymptotic properties of estimators and interval estimation reducution.","['statistics', 'reference-request', 'parameter-estimation']"
913548,Map from real numbers to real numbers as abelian groups,"What is an example of an abelian group homomorphism from $\mathbb{R}$ to $\mathbb{R}$, respecting addition, that is NOT a linear transformation? I'm trying to understand to what extent the scaling condition for the linear transformation is necessary. For $\mathbb{Q}$ vector spaces, maps that preserve addition also preserves scaling.  It seems the situation is more complicated for $\mathbb{R}$.  I guess I can ""choose"" a basis of $\mathbb{R}$ as a $\mathbb{Q}$ vector space and go from there, but are there any explicit examples, preferably without using the Axiom of Choice? More generally, is there a description of the group of abelian group homomorphisms from $\mathbb{R}^n$ to $\mathbb{R}^m$?",['group-theory']
913557,Adding $2$ absolute values together: $|x+2| + |x-3| =5.$ [duplicate],"This question already has answers here : Solving $|x-2| + |x-5|=3$ [duplicate] (2 answers) Closed 9 years ago . I came across a very basic absolute value question $|x+2| + |x-3| =5.$ Initially, I thought the answer was $x=-2$ and $x=3$ because I let each absolute values be either positive and negative and that's what you get. But the correct answer was an inequality;   $-2\le x \le 3.$ 
Now, If you try subbing values in or solve it graphically, this inequality is correct. But how am I supposed to know if the solution is to be an inequality or equality? Is there anyway to tell by looking at the expression? Thanks,","['absolute-value', 'algebra-precalculus']"
913565,True or False: Matrices with linearly independent row and column vectors are square.,"True or False: Matrices with linearly independent row and column vectors are square. Here is the answer of my textbook: True; if the row vectors are linearly independent then $\text{nullity}(A)=0$ and $\text{rank}(A)=n=\text{the number of rows}$. But since $\text{rank}(A)+\text{nullity}(A)=\text{the number of columns}$, $A$ must be square. Why must a matrice with linearly independent vectors have $\text{nullity}(A)=0$? That is where I lose track of the question. Are zero rows considered to be linearly dependent?","['vector-spaces', 'matrices', 'linear-algebra']"
913566,Sum over all non-evil numbers,"I'm working on the following contest math problem: Define an evil number to be any positive integer that contains the
  digit $9$. Show that $$ \sum_{x} \frac{1}{x} < 80 $$ where the sum is over all non-evil positive integers $x$. I'm very confused on where to begin. Initially, I tried to consider this sum as part of the sum of $1/x$ over all positive integers, namely by noting that $$
\sum_{n=1}^{\infty} \frac{1}{n} = \sum_{x} \frac{1}{x} + \sum_{y} \frac{1}{y}
$$ where the first summation on the right side is the same as in the problem statement and the second is the sum over all evil numbers. However, I can't seem to find a way to use this since the sum of the left diverges. Could anyone lend a helping hand?","['sequences-and-series', 'contest-math']"
913589,Dummit and Foote as a First Text in Abstract Algebra,"I'm wondering how Dummit and Foote (3rd ed.) would fair as a first text in Abstract Algebra. I've researched this question  on this site, and found a few opinions, which conflicted. Some people said it is better as a reference text, or something to read after one has a fair deal of exposure to the main ideas of abstract algebra, while others have said it is fine for a beginner. Is a text such as Herstein's Topics in Algebra , Artin's Algebra , or Fraleigh's A First Course in Algebra a better choice? Here's a summary of the parts of my mathematical background that I presume are relevant. I've covered most of Spivak's famed Calculus text (in particular the section on fields, constructing $\mathbf{R}$ from $\mathbf{Q}$, and showing the uniqueness of $\mathbf{R}$ which is probably the most relevant to abstract algebra) so I am totally comfortable with rigorous proofs. I also have a solid knowledge of elementary number theory; the parts that I guess are most relevant to abstract algebra are that I have done some work with modular arithmetic (up to proving fundamental results like Euler's Theorem and the Law of Quadratic Reciprocity), the multiplicative group $(\mathbf{Z}/n\mathbf{Z})^{\times}$ (e.g. which ones are cyclic), polynomial rings such as $\mathbf{Z}[x],$ and studying the division algorithm and unique factorization in $\mathbf{Z}[\sqrt{d}]$ (for $d \in \mathbf{Z}$). I have only a little bit of experience with linear algebra (about the first 30 pages or so of Halmos' Finite Dimensional Vector Spaces and a little bit of computational knowledge with matrices) though. With this said, I don't have much exposure to actual abstract algebra. I know what a group, ring, field, and vector space are but I haven't worked much with these structures (i.e. I can give a definition, but I have little intuition and only small lists of examples). I have no doubt that Dummit and Foote is comprehensive enough for my purposes (I hope to use it mostly for the sections on group theory, ring theory, and Galois Theory), but is it a good text for building intuition and lists of examples in abstract algebra for someone who has basically none of this? Will I, more than just learning theorems and basic techniques, develop a more abstract and intuitive understanding of the fundamental structures (groups, rings, modules, etc.)? It is a very large and supposedly dense text, so will the grand ""picture"" of group theory, for example, be lost? I've heard it is a book for people who have some basic intuition in group and ring theory, and I hesitate to put myself in this category given my description of my relevant knowledge in the paragraph above. Do you think the text is right for me, or would I be more successful with one of the three texts I mentioned in the first paragraph? Thanks for reading this (lengthy) question. I look forward to your advice!","['book-recommendation', 'reference-request', 'abstract-algebra']"
913601,Finding all solutions to the equation $|||||x|-1|-1|-1|-1|=0$,"I was presented this question by a student I was tutoring: Suppose $x \in \mathbb{R}$. Find all solutions of the equation $$|||||x|-1|-1|-1|-1|=0.$$ What I explained to the student: Given $|||||x|-1|-1|-1|-1|=0$, one can drop the outermost absolute value bars, and place the plus/minus symbol on the right side, like this: $$||||x|-1|-1|-1|-1=\pm 0=0 \implies ||||x|-1|-1|-1|=1.$$ Repeating this process, $$|||x|-1|-1|-1=\pm 1 \implies |||x|-1|-1|=0,2.$$
And again, $$||x|-1|-1=0,2 \implies |||x|-1|=1,3.$$
And yet again, $$|x|-1=\pm1, \pm3 \implies |x|=0,2,4.$$
Finally, we arrive with $\boxed{x=-4,-2,0,2,4}$. Was this approach okay? How did I do as far as finding the solutions go?","['absolute-value', 'algebra-precalculus']"
913613,Issue differentiating the Lambert W function,"I want to differentiate the Lambert W function (the inverse of $y = xe^x$), I didn't think it would be that difficult a problem but it's causing me some problems. I tried this method: (1.) Implicitly differentiating $f(g(x)) = x$ and solving for $g'(x)$ yields $g'(x) = \frac{1}{f'(g(x))}$, so substituting $f = xe^x$ and $g = W(x)$ gives us $W'(x) = \frac{1}{x + e^{W(x)}}$. I then got paranoid and tried a second method, (2.) Implicitly differentiating $W(x)e^{W(x)} = x$ directly gives us $W'(x)e^{W(x)} + W(x)e^{W(x)}W'(x) = 1$, or $W'(x)(e^{W(x)} + x) = 1$. Solving for $W'$ gives us the exact same answer as (1.) My issue arises from the fact that WolframAlpha tells me that $W'(x) = \frac{W(x)}{xW(x) + x}$, which is nothing like what I got. What is wrong with my method?",['derivatives']
913616,Regular Value Theorem Using Implicit Function Theorem in Calculus.,"I want to prove the following: THEOREM. (Regular Value Theorem.) Let $f:\mathbf R^n\to\mathbf R^m$ be a smooth function and $\mathbf a\in\mathbf R^n$ be a regular point of $f$.
    Let $f(\mathbf a)=\mathbf 0$ and $\text{rank }Df(\mathbf a)=r$.
    Let $R$ be the set of all the regular points of $f$.
    Then $R\cap f^{-1}(\mathbf 0)$ is an $(n-r)$-manifold (without boundary) in $\mathbf R^n$. I can prove the above using the Rank Theorem but I was wondering if this can be proved using the Implicit Function Theorem. In fact, the instructor of my Differential Equations course hinted that this can be done. THEOREM (Implicit Function Theorem.) Let $f:\mathbf R^{m+n}\to \mathbf R^n$ be a smooth function.
Interpret $f$ in the form $f(\mathbf x,\mathbf y)$ for $\mathbf x\in\mathbf R^m$ and $\mathbf y\in \mathbf R^n$.
Let $(\mathbf a,\mathbf b)\in\mathbf R^{m+n}$ be such that $f(\mathbf a,\mathbf b)=\mathbf 0$ and $\det\displaystyle\frac{\partial f}{\partial \mathbf y}\neq 0$.
Then there exists a neighborhood $U$ of $\mathbf a$ in $\mathbf R^m$, and a unique continuous function $g:U\to \mathbf R^n$ such that $g(\mathbf a)=\mathbf b$ and $f(\mathbf x,g(\mathbf x))=\mathbf 0$ for all $\mathbf x\in U$.
Further, the function $g$ is a smooth function. The definitions I am using are DEFINITION. Let $f:\mathbf R^n\to\mathbf R^m$ be a smooth function.
A point $\mathbf a\in \mathbf R^n$ is said to be a regular point of $f$ if $$\text{rank }Df(\mathbf a)=\max\{\text{rank }Df(\mathbf x):\mathbf x\in\mathbf R^n\}$$ DEFINITION. A subset $M$ of $\mathbf R^n$ is said to be a $k$- manifold (without boundary) if for each point $\mathbf p\in M$, there is a set $V$ open in $M$ containing $\mathbf p$, an open set $U$ in $\mathbf R^k$, and a bijective map $\alpha:U\to V$ satisfying: $\alpha^{-1}:V\to U$ is continuous. $D\alpha(\mathbf x)$ has rank $k$ for each $\mathbf x\in U$. Attempt: Consider the statement of the Regular Value Theorem as given above and assume for a special case that $m=r$. Write $M=R\cap f^{-1}(\mathbf 0)$.
Then using the Implicit Function Theorem, there exists a neighborhood $U$ of $\mathbf a$ in $\mathbf R^m$, and a continuous function $g:U\to\mathbf R^n$ such that $f(\mathbf x,g(\mathbf x))=\mathbf 0$ for all $\mathbf x\in U$.
Now define the function $\alpha:U\to \mathbf R^n$ as $\alpha(\mathbf x)=(x,g(\mathbf x))$. The only trouble now is to show that $\alpha(U)$ is open in $M$.
Can anybody see how to do that? Also, can anybody suggest an approach when $m>r$? Thanks.",['multivariable-calculus']
913619,Fubini's theorem for complete $\sigma$-algebras vs. non-complete $\sigma$-algebras,"Suppose $(X, \Sigma, \mu)$ and $(Y, \tau, \nu)$ are both complete measure spaces.  Consider the following two measure spaces: $(X \times Y, \overline{\Sigma \times \tau}, \mu \times \nu)$ and $(X \times Y, \Sigma \times \tau, \mu \times \nu)$. I know Fubini's theorem for the complete $\sigma$-algebra $\overline{\Sigma \times \tau}$: If $f \in L^{1}(d\mu \times d\nu)$, then: The maps $y \mapsto f(x,y)$ are in $L^{1}(d\nu)$ for almost all $x$ The map $x \mapsto \int \limits_{Y} f(x,y) \,d\nu$ is in $L^{1}(d\mu)$ $\int \limits_{X \times Y} f(x,y) \,d(\mu \times \nu) = \int \limits_{X} \left [ \int \limits_{Y} f(x,y) \,d\nu \right ] \,d\mu$ My first question: in statement 1, I believe we also have that the maps are measurable for almost all $x$.  Then the map in 2 can only exist almost everywhere, so shouldn't it equal an $L^{1}(d\mu)$ function almost everywhere, rather than being in $L^{1}(d\mu)$ itself? My second question: What is different between Fubini's theorem above for $\overline{\Sigma \times \tau}$ and Fubini's theorem applied to $\Sigma \times \tau$?  I know that when we are dealing with $\Sigma \times \tau$, we have that the maps $y \mapsto f(x,y)$ are measurable for all $x$, not just almost everywhere, but aside from this, I don't know what else is different.","['lebesgue-integral', 'measure-theory', 'functional-analysis', 'real-analysis']"
913622,Blow up of reduced scheme is reduced,"Why is the blow up of a reduced scheme reduced? This is in Vakil's notes (22.2.C) right after he gives the universal property of the blow up involving Cartier divisors, but before the explicit construction of the blow up using Proj. Using only the universal property would be preferred, but an approach that uses the construction of the blow up involving the Rees algebra is better than nothing. I tried the second approach, but I didn't make it clean enough for me to believe its correctness or remember the idea for future reference. When I googled the question just now, I got http://stacks.math.columbia.edu/tag/0808 , and if you follow the links, you end up here: http://stacks.math.columbia.edu/tag/052S , where they omitted the proof.","['blowup', 'algebraic-geometry']"
913632,Question about left and right derivative.,"Let $f(x):\mathbb{R}\rightarrow\mathbb{R}$ be a function such that $\forall x\in\mathbb{R}$ there exist: $$f'_+(x)=\lim_{\delta\rightarrow 0^+}\frac{f(x+\delta)-f(x)}{\delta}$$
$$f'_-(x)=\lim_{\delta\rightarrow 0^-}\frac{f(x+\delta)-f(x)}{\delta}$$ and $\forall x:f'_-(x)=2f'_+(x)$. How to prove that $f$ is constant. I'm really in nowhere with this kind of problem. EDIT: Actually I'm having an idea of using similar technique as in https://math.stackexchange.com/a/79617/161212 but it's still getting nowhere.","['derivatives', 'real-analysis']"
913675,Find the side of an equilateral triangle given only the distance of an arbitrary point to its vertices,Triangle $ABC$ is an equilateral triangle and $P$ is an arbitrary point inside it. The distance from $P$ to $A$ is $4$ and the distance from $P$ to $B$ is $6$ and the distance from $P$ to $C$ is $5$. How to find the side of an equilateral triangle from this information?,['trigonometry']
913687,composition of $L^{p}$ functions,"Suppose $f, g\in L^{p}(\mathbb R), (1\leq p < \infty).$ For simplicity, let us assume that, $g,f:\mathbb R\to \mathbb R$ so that composition of $f$ and $g$, namely, 
$f\circ g(x)= f(g(x)); (x\in \mathbb R)$
is well-defined. My Question is : Given real-valued functions $f,g \in L^{p}(\mathbb R).$ Can we expect its composition $f\circ g$ is again in $L^{p}(\mathbb R)$ ? If not, under what condition on $f$ one can expect that, $f\circ g\in L^{p}(\mathbb R)$ for all $g\in L^{p}(\mathbb R).$ ? Thanks,","['lp-spaces', 'real-analysis', 'analysis']"
913760,What is an example of a function that is measurable but not strongly measurable?,"Let $(\Omega, \Sigma)$ be a measurable space and $X$ a Banach space. Let $f: \Omega \rightarrow X$. $f$ is called measurable if every the preimage of every Borel set in $X$ is an element of $\Sigma$. $f$ is called strongly measurable if $f$ is the pointwise limit of a sequence of simple functions. It is known that strongly measurable and measurable are equivalent when $X$ is separable. For this reason, the notion of strong measurability is only relevant when dealing with Bochner integration in full generality. What is an example of a function $f$ taking values in a non-separable Banach space $X$ such that $f$ is measurable but not strongly measurable?","['functional-analysis', 'examples-counterexamples', 'measure-theory', 'integration']"
913764,"Wolfram|Alpha returns the wrong result: how can I solve this ""high precision"" equation?","$$1-(1-1.40*10^{-36})^x \ge 1.09*10^{-9}$$ I want to estimate $x$ such that the probability on the left becomes larger than the probability on the right. A solution must exist because $1-(1-1.40*10^{-36})^0=0$, $\lim\limits_{n \to \infty} 1-(1-1.40*10^{-36})^n=1$ and the function is continuous. However Wolfram|Alpha seems to return a wrong result . Is my reasoning correct? Is there any (practical) way to estimate the result? For my problem would be sufficient to find the order of magnitude of $x$.","['wolfram-alpha', 'inequality', 'probability']"
913780,Piecewise linear function and absolute value,"While writing a solution to homeworks for my students, I had to write the function $$f(x)=\left\{\begin{array}{ll} \frac{x+2}{2}, & x\leqslant -4\\ \frac{x}{4}, & -4\leqslant x\leqslant 4 \\ \frac{x-2}{2}, & x\geqslant 4 \end{array}\right.$$ using one single formula and absolute values. After trials and errors, I obtained that $f(x)=\frac{4x+|x-4|-|x+4|}{8}$. My questions: Can every continuous piecewise linear function be written as a linear combination of linear functions and absolute values of linear functions? If possible, is there a systematic way to do it?","['absolute-value', 'algebra-precalculus', 'functions']"
913802,Help with $\lim\limits_{x \to 0^+}{x^a}{\ln x}$,Evaluate $$\lim\limits_{x \to 0^+}{x^a}{\ln x}$$ I used L'Hopital rule till $\Large \lim\limits_{x \to 0^+}{\frac{x^{a-2}}{-a}}$ but I can't go any further. Thanks for the help in advance!,"['calculus', 'limits']"
913829,Writing nonautonomous systems as autonomous systems,Apparently any mth order nonautonomous system is equivalent to a first order autonomous system in higher dimensional space. How does this work in practice? I would you write $\displaystyle \frac{d^3x}{dt^3}=sin(t) \frac{x\ddot{x}}{\dot{x}^2}$ as a first order autonomous system on $\mathbb{R^4}$. I would like hints on how to start this question and no full solutions please.,"['ordinary-differential-equations', 'manifolds']"
913830,"Evaluating $\lim\limits_{(x,y)\rightarrow(1,1)} \frac {\sin(x) - \sin (y)} {x-y}$","I am taking a calculus exam in less than one week, and I've stumbled upon this expression. $$\lim\limits_{(x,y)\rightarrow(1,1)} \frac {\sin(x) - \sin (y)} {x-y}$$ Which I know to be cos(1), but I cannot seem to find the inequalities to make an $\epsilon-\delta$ proof of said limit. I've tried coordinate change and Taylor, to no avail. Whenever I do Taylor(1) or equivalent infinitesimals, any variable I have manages to cancel out. If I don't, the thing just grows and grows... Is there something I am entirely missing from the start?","['multivariable-calculus', 'calculus', 'limits']"
913863,A second order differential equation,"How does one solve the following differential equation $y^{""}+xy^{'}+(1-x^2)y=y\sin x$? I don't know how to proceed?",['ordinary-differential-equations']
