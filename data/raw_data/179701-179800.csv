question_id,title,body,tags
3264935,"Does $(\Bbb{R}, +)$ admit an irreducible $2$-traversal?","For a given natural number $k$ , I'm going to call a subset $T$ of the plane $\Bbb{R}^2$ a $k$ -traversal if, for any $x \in \Bbb{R}$ , \begin{align*}
k &= \operatorname{card} \{(a, b) \in T : a = x\} \\
&= \operatorname{card} \{(a, b) \in T : b = x\} \\
&= \operatorname{card} \{(a, b) \in T : a + b = x\}.
\end{align*} It's not difficult to see that lines in the plane that aren't parallel to the $x$ -axis, the $y$ -axis, or the line $x + y = 0$ will be $1$ -traversals (but are far from the only examples!). We can make $2$ -traversals without difficulty by taking two disjoint $1$ -traversals and unioning them. My question is, Is there a $2$ -traversal that cannot be decomposed into the union of two $1$ -traversals? The idea of (irreducible) $k$ -traversals is a concept from latin squares. I'm trying to consider the concept when applied to an (uncountably) infinite Latin square generated by the group $(\Bbb{R}, + )$ . This was a question that popped into my head years ago when attending a combinatorics conference. Combinatorics is not my forte, but it seemed like an interesting question, and I thought I'd share it.","['elementary-set-theory', 'group-theory', 'latin-square']"
3265122,Reducibility of $x^3+nx+1$ over $ \Bbb Z$,"For what values of $n$ , where $n$ is an integer, the polynomial $x^3+nx+1$ is reducible over $\Bbb Z$ .
My attempt: When $n= 0,-2 $ , the given polynomial is reducible over $\Bbb Z$ as $x=-1$ and $x=1$ are zeros of the polynomial. But I couldn't find whether there exists any integer $n$ for which the polynomial $x^3+nx+1$ is reducible over $\Bbb Z$ . How can we proceed from here? Is the polynomial irreducible over $\Bbb Z$ if $n$ is not in $\{0,-2\}$ ?","['irreducible-polynomials', 'algebra-precalculus', 'integers', 'diophantine-equations']"
3265153,How to show that the number of triangles in G is $\frac{1}{6}Tr(A^3)$,Let's suppose we have a graph $G$ . How should I show the that the number of triangle of in $G$ is $$\frac{1}{6}Tr(A^3)$$ where A is the adjacency matrix of $G$ ? I have no idea what should I do first.  Thank you in advance,"['graph-theory', 'discrete-mathematics']"
3265167,How can I prove this sequence converges to 1?,"Suppose $0<a<1$ and define $a_n=(1+a^n)^n$ , show that $a_n \to 1$ by using binomial expansion on each $a_n$ and compare to a geometric sum. I know how to compute binomial on $a_n$ but I am really confused by ""using binomial expansion on each $a_n$ and compare to a geometric sum"".","['sequences-and-series', 'real-analysis']"
3265171,Hint for integral of a function,"Let $f:[0,1] \to \mathbb R$ be a continuous function and $f(x) > 0$ for all $x \in [0,1]$ Evaluate the integral below $$ \int_0^1 \frac{f(x)dx}{f(x)+f(1-x)} $$ I'm not sure about what should I do for this integral. I couldn't write Riemann sums because I don't know infimum and supremum. We only know that it's continuous and positive. How can I use continuity and positiveness for evaluating. I need some hints. Thanks a lot.","['integration', 'calculus', 'analysis']"
3265230,"$|x^2-3x+2|=mx$ with 4 distinct real solutions, find range of $m$ [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question I am working on my scholarship exam practice but not sure how to start here. Find the range of $m$ such that the equation $|x^2-3x+2|=mx$ has $4$ distinct real solutions. The answer provided is $0<m<3-2\sqrt{2}$ . Could you please give a solution or at least a hint to this question?","['algebra-precalculus', 'absolute-value']"
3265267,How could $\varnothing$ be unique if it could be vacuously false?,The argument  that people use to prove that empty set is unique is that: Let $A$ and $B$ be two empty sets then $\forall z : z \in A \implies z \in B$ since there is no such $x\in A$ hence this statement is vacuously true. Also the converse is true therefore $A=B$ . My objection is we could have equally stated $\forall z : z \in A \implies z \notin B$ and thus conclude that $A\neq B$ .,"['elementary-set-theory', 'logic']"
3265300,Transforming a nonlinear system to a new system that has an equilibrium point at the origin,"Take a look at the following system $$
\begin{align}
\dot{x}_1 &= x_2\\
\dot{x}_2 &= -x_1 + x^3_1 - x_2
\end{align}
$$ which has three equilibrium points (0,0),(1,0), and (-1,0). In the book I'm reading, the author asks to define a new system that has equilibrium point as the origin for (1,0) and (-1,0). The procedure in the book is as follows: 
let $y=x-x_e$ where $x_e$ is an equilibrium point and let's perform the transformation for $x_e = (1,0)$ , hence: $$
\begin{align}
y_1 &= x_1 - (1) = x_1 - 1 \implies \dot{y}_1 = \dot{x}_1 \\
y_2 &= x_2 - (0) = x_2  \implies \dot{y}_2 = \dot{x}_2
\end{align}
$$ The new system is now $$
\begin{align}
\dot{y}_1 &= y_2 \\
\dot{y}_2 &= -(y_1+1) + (y_1+1)^3 - y_2
\end{align}
$$ Now we need to show that the new system $\dot{y}=g(y)$ has an equilibrium point at the origin (i.e. $\dot{y}=g(y) \implies 0 = g(y_e)$ ), we get $$
\begin{align}
0 &= y_2 \\
0 &= -(y_1+1) + (y_1+1)^3 + y_2
\end{align}
$$ $y_2=0, -(y_1+1) + (y_1+1)^3 = 0 \implies y_1=0,-2$ . The new system has two equilibrium points and one of them are not at the origin. How to justify this issue. The actual question in the book states:","['nonlinear-system', 'transformation', 'ordinary-differential-equations']"
3265317,If $E[Y 1_{\{X \le p \}}]\le 2pk$ where $P[X \ge p]\le k/p$ then $Y $ is a.s. finite?,"I'm not able to follow the stated conclusion below. $Y $ is a nonnegative RV (to be precise it is a sum of the form $\sum_{n \in \mathbb Z }(X_{n+1 } - X_n )^2 $ , but I don't think that matter here). I can see that $P[X \ge p]\le k/p$ means that $X $ is almost surely finite and I also know that $E[Y] < \infty $ implies that $Y $ is almost surely finite (as $ Y $ is nonnegative) - so this is what I would need to show. Suppose $E[Y 1_{\{X \le p \}}]\le 2pk$ where $P[X \ge p]\le k/p$ then $Y $ is a.s. finite? How do I show this? Here $k \geq 0$ is fixed and $p\geq 1$ is any. Thanks in advance!",['probability-theory']
3265336,Sectional curvature on conformally equivalent metric,"Let $(M,g)$ be a Riemannian manifold, $\tilde{g}:=e^{2 \psi} g$ for some $\psi \in C^{\infty}(M)$ . I want to show, that for $X,Y$ orthonormal $e^{2 \psi}\tilde{K}(X,Y)= K(X,Y)-Hess_{\psi}(X,X)-Hess_{\psi}(Y,Y)-g(\text{grad} \psi, \text{grad}  \psi)+(X(\psi))^2+(Y(\psi))^2$ So far I computed the left hand side to be: $K(X,Y)-Y(\psi)g([X,Y],X)-X(\psi)g([X,Y],Y)$ but I don't know what to do with the right hand side. I somehow need to get rid of the Hessian and the gradient but the only thing I know about that is that 1) $Hess_{\psi}(X,X)=g(\nabla_X grad \psi,X)$ and 2) $g(grad_{\psi},X)=X(\psi)$ Using this and the Konszul formula for the right hand side I just always come back to the starting point. 
Does anybody have some hint for me here?","['hessian-matrix', 'riemannian-geometry', 'differential-geometry']"
3265376,"Prove $v_1,v_2,\cdots,v_m $ are linear independent.","$\Bbb{E}^n$ is an Euclidean space with dimension $n$ . $v_0,v_1,\cdots,v_m\in \Bbb{E}^n,m\le n $ , and $(v_i,v_j)\lt0$ for $0\le i\ne j\le m$ . Prove $v_1,v_2,\cdots,v_m $ are linear independent. My try: I tried to make an argument like this, if $v_1,v_2$ are linearly dependent, then there exists $a_1$ such that $v_2=a_1v_1$ , then $(v_2,v_2)=a_1(v_2,v_1)$ . At first I thought that the left hand $\ge 0$ , the right hand $\lt0$ . But I notice that the constant $a_1$ could also be negative. So this contradiction failed. Any  hints would be helpful.",['linear-algebra']
3265386,Can I use the Nullstellensatz?,"I have the next system of equations where $a_{ij}\in\mathbb{K}$ for a field $\mathbb{K}$ and are not all zero at the same time. Under what circumstances about the field can I ensure that the next system has a nontrivial solution? I can more or less figure that under the reals it should have and, then also, under the complex numbers. But I do not know about other fields and also about the properties I have to ask for this field to get a nonzero solution. I am also not sure about the use of the Hilbert Nullstellensatz in this situation because it affirms that V(I) is not empty... but I know it because $0\in V(I)$ obviously. \begin{equation}\label{E}
\left\{
\begin{aligned}
x_{1} &= a_{11}x_{1}^{2}+\cdots+a_{n1}x_{n}^{2}\\
\vdots\\
x_{n} &= a_{1n}x_{1}^{2}+\cdots+a_{nn}x_{n}^{2}.
\end{aligned}
\right.
\end{equation} What happen in the case $a_{ii}\neq0$ for all $i\in\{1,\dots, n\}$ ?","['algebraic-geometry', 'abstract-algebra']"
3265394,What is area of shaded region?,"Suppose the side length $a$ of the square is 10mm.
A circle is tangent to all four sides of the square. And two quarter-circles with the same radius of 10mm have centers on the opposite vertices. It may be easier to view it in the picture on the right. What’s the area of shaded region? Using some trigonometrical calculation, I got a complex formula $$S=\left[\frac{1}{2}(\pi -\arccos(-\frac{\sqrt{2}}{4}))+\sqrt{2}\sin(\arccos(\frac{5\sqrt{2}}{8}))-2\arccos(\frac{5\sqrt{2}}{8})\right]a^2$$ which gives 29.276 $mm^2$ . The way is far from beautiful. Don’t know if there are any simpler ways to do that? Is there any principles that I am not aware of? Thank you.","['trigonometry', 'area', 'geometry']"
3265402,Catenary Cable Problem: Timoshenko (2 solvers since last year only),"I was doing this amazing problem Chapter 4, Problem 10 from book Engg Mechanics Revised 4E by Timoshenko,  and here is the link having the modified problem which resembles a lot from book. Timoshenko modified problem Let me attach the image of the question in the above link also for better visual appearance. Last year I couldn't solve this problem, but today i see this question again. so i really wanted to solve it and wanna know how do we get to the solution! 
I have the final answer but dont know how to get these. I got some complex term involving $\coth$ function dont remember exactly.. as i solved this one last year. This is an example of catenary cable . So catenary equations are useful, but needs more mathematics than that. It's been more than a year, only 2 persons were able to solve this Let me attach the original problem from the book:
which is almost the same as in the link i shared, solve this please. I feel this is one of the most hard problem in the book. Bounty started : 19/06/2019","['maxima-minima', 'calculus', 'classical-mechanics']"
3265422,Hierarchy of subsets of $\mathbb{N}$,"I was wondering if there is an interesting way to build an ""hierarchy"" of natural numbers subsets in a transfinite sequence: $$(U_\alpha)_{\alpha < \lambda} \quad \text{with } U_\alpha \subset\mathcal{P}(\mathbb{N})$$ and $$U_\alpha \subset U_{\alpha+1} \; \forall \alpha < \lambda$$ $$U_{\lambda} = \bigcup_{\alpha < \lambda} U_\alpha = \mathcal{P}(\mathbb{N})$$ where the subsets are ordered by some kind of complexity of construction (like for Borel sets).  If it is correlated to their cardinality the better. By the way, would it be too much to ask for $\lambda \ge \omega_1$ ?","['elementary-set-theory', 'descriptive-set-theory', 'soft-question', 'natural-numbers']"
3265474,An integration-via-summation formula,"For symbolic transformation of integrals and series I occasionally use this formula: $$\int_0^1f(x)\,dx=-\sum_{n=1}^\infty\sum_{m=1}^{2^n-1}\frac{(-1)^m}{2^n}f\left(\frac m{2^n}\right)\tag{$\diamond$}$$ I believe it holds for all piecewise- smooth functions $f$ of bounded variation defined on $(0,1).$ Is it correct? I also think this condition might be too tight and can be relaxed. Could you please suggest a wider natural class of functions for which $(\diamond)$ holds? Is there a known name for this formula? Could you provide some reference for it?","['integration', 'summation', 'definite-integrals', 'calculus', 'sequences-and-series']"
3265495,Show the relation well-orders $S$,"Let $X$ and $Y$ be two well-ordered sets. Let $$S=(X\times\left\{0\right\})\cup( Y\left\{1\right\})$$ For all $x,x_1,x_2\in X$ and for all $y,y_1,y_2\in Y$ $(x_1,0)<(x_2,0)$ iff $x_1<x_2,$ $(y_1,1)<(y_2,1)$ iff $y_1<y_2,$ $(x,0)<(y,1)$ . Show the above relation well-orders $S$ My try. Let $U\subseteq (X\times\left\{0\right\})\cup( Y\left\{1\right\})$ . If $U\cap (X\times\left\{0\right\})\neq\emptyset$ , then define $$W=\left\{x\in X: (x,0)\in U\right\}$$ $W$ does have a minimal element, say $a$ . If $U\cap (X\times\left\{0\right\})=\emptyset$ , then if $U\cap (Y\times\left\{1\right\})\neq\emptyset$ , so define $$V=\left\{y\in Y: (y,1)\in U\right\},$$ $V$ does have a minimal element, say $b$ . I can't continue. Can you check my try, can you help to continue it? Thanks ...","['elementary-set-theory', 'proof-writing', 'proof-verification']"
3265602,Schrödinger equation involving the Dirac-Delta,"I am taking a course on quantum mechanics and I try to understand the time-independent Schrödinger-equation with the Delta-potential: $$\frac{-\hslash^2}{2m}\psi''(x)-V_0\delta(x)\psi(x)=E\psi(x)$$ where $V_0,m,\hslash>0$ and $\psi$ and $E$ are unknown. I can somehow mimic the procedure for solving the equation but I do not understand what I am doing there. The main problem is that I do not understand what $\delta(x)$ exactly means. I know that $\delta$ is a distribution which can for example be defined as being a functional or as being a measure. However, I don't understand why $\delta$ can take $x$ as an argument. I guess it is some abuse of notation, right? So, here are my questions: What does $\delta(x)$ in the above equation mean? Or more general: What does $\delta(x)$ mean if it occurs in an ODE? How is a solution for such an ODE defined? If $\delta(x)$ is abuse of notation, what would be the correct notation for such an equation? Of course, I know the ""physicist's explanation"" of $\delta(x)$ (i.e.: it can be used to describe a potential $V(x)=0$ for $x \neq 0$ and $V(0)=-\infty$ ). Unfortunately, this does not help me. I am looking for a mathematical precise explanation. A reference to a textbook would also be great (a mathematics book - not a physics book). I've asked a related question on physics stackexchange. You can find the link in the comments.","['dirac-delta', 'ordinary-differential-equations', 'reference-request', 'definition', 'quantum-mechanics']"
3265679,A horrendous sieve with potentially terrific consequences,"Sieves are useful when you can't concisely formulate what something is, but you can readily denote what it is not. For example, there is no concise formula that generates every prime number, but there are sieves that eliminate every composite number, accomplishing the desired result by indirection. The sieve of Sundaram is premised on the fact that no odd prime number can be expressed as the product of two odd factors. $$\forall (a,b,m) \in \mathbb N, \ (2m+1) \in \mathbb P:\ 2m+1 \ne (2a+1)(2b+1) \Rightarrow m \ne 2ab+a+b$$ Simply discard natural numbers of the form $2ab+a+b$ and the remaining whole numbers can be multiplied by $2$ and incremented by $1$ to yield every odd prime. There is no reason this logic cannot be extended to provide a sieve for odd semiprimes, which are simply odd composites that cannot be expressed as the product of three odd factors. $$\forall (a,b,m) \in \mathbb N, \ (2m+1) \not\in \mathbb P:\ 2m+1 \ne (2a+1)(2b+1)(2c+1) \Rightarrow m \ne 4abc+2(ab+bc+ac)+a+b+c$$ This sieve might be implemented by first performing the sieve of Sundaram, but keeping only those numbers of the form $2ab+a+b$ (i.e. values of $m$ that will generate composite $2m+1$ ), and then sieving a second time, discarding numbers of the form $4abc+2(ab+bc+ac)+a+b+c$ . I think that this approach is sufficiently obvious that it likely has been thought of before. Perhaps others who have conceived of it, like me, were impressed with the horrendous explosion of possibilities that flow from a complicated term in three variables. The ability to identify semiprimes has relevance to the twin prime conjecture (the product of twin  primes is a semiprime) and to Goldbach's conjecture, which posits every sufficiently large even number can be separated into one or more pairs of two prime addends; the product of such addends would be a semiprime. The objective would be to prove that there are always products of twin numbers (i.e. $d$ and $d+2$ ) or odd addends of even numbers that could not have the form $(2a+1)(2b+1)(2c+1)$ , by showing that when such products are stated in the form $2m+1$ , the resulting expression for $m$ cannot be expressed as $4abc+2(ab+bc+ac)+a+b+c$ . As I said in the title, horrendous sieve, but potentially very significant consequences. I have been thinking about this for some time, without much progress. It might be that the unwieldiness of the sieve defeats my limited skills, or, that the approach is doomed in light of deeper considerations. Perhaps others might be spurred to some insight that as yet eludes me. My questions are : Is this sieve for semiprimes an old idea? Are there other known sieving methods that yield semiprimes (all or only odd)?","['sieve-theory', 'number-theory', 'elementary-number-theory', 'soft-question', 'prime-numbers']"
3265705,Equation for geodesic in manifold of orthogonal matrices,"From the following post Geodesic of Stiefel manifold it reads that a geodesic (under the canonical metric) in the manifold of orthogonal matrices can be expressed as $Y(t) = Q e^{Xt} I_{np}$ for some matrix $Q$ and $X$ , and for $I_{np} = I$ , since $n = p$ . 1) Does it follow that the geodesic between two orthogonal matrices $Y_1$ and $Y_2$ is given by $Y(t) = Y_1(Y^\top_2 Y_1)^{-t}$ , for $t \in [0,1]$ ? 2) Does this curve have constant speed?","['manifolds', 'differential-geometry']"
3265724,Stiefel manifold of complex 2-frames in $\mathbb{C}^4$ is a product of spheres?,"I have in several places now seen it tossed off as common knowledge that there is a homeomorphism $$V_2(\mathbb{C}^4)\cong S^5\times S^7$$ between the Stiefel manifold of complex $2$ -frames in $\mathbb{C}^4$ and the product $S^5\times S^7$ . Of course $V_2(\mathbb{C}^4)\cong SU_4/SU_2$ . I suspect that there is a nice way to get this by identifying $V_2(\mathbb{C}^4)$ with some geometric object, and perhaps it is really a diffeomorphism? Or maybe it stems somehow from the identification of $\mathbb{C}^4$ with the octonions $\mathbb{O}$ ? Where does the homeomorphism come from?","['algebraic-topology', 'differential-geometry']"
3265733,Intuition for the role of diffeomorphisms,"I understand the general role of isomorphisms in mathematics.  If two groups are isomorphic, they are indistinguishable by group-theoretic means.  If two topological spaces are homeomorphic, they are indistinguishable by topological means.  And so on. However, I'm not quite sure if I understand the role of diffeomorphisms fully.  In Differential Geometry of Curves & Surfaces , do Carmo writes that ""from the point of view of differentiability, two diffeomorphic surfaces are indistinguishable.""  However, it is possible that two surfaces - say, the unit sphere and a sphere of radius 2 - are diffeomorphic although there are important differences: Because the diffeomorphism between them is a not an isometry, their inner geometry is different.  If a curve is moved by the diffeomorphism from one of the spheres to the other, it changes its length. So, the inner geometry is not necessarily preserved.  But what is preserved?  What does a diffeomorphism do that a homeomorphism doesn't do?  (FWIW, I'm more interested in the intuition than in a technical description.)","['diffeomorphism', 'smooth-manifolds', 'intuition', 'differential-topology', 'differential-geometry']"
3265747,Topologies on Categories: The big picture,"I have often come across the idea of placing different topologies  on the category of schemes $Sch$ .  This can be useful in proving that certain functors are representable.  However, whenever I read about these constructions I become lost as to when/how exactly the topology is actually placed on $Sch$ . I imagine that if we place a (Grothendieck) topology on a category the object of the category should act as open sets of the topological space. However, wikipedia write that: "" A Grothendieck topology $J$ on a category $C$ is a collection, for each object $c$ of $C$ , of distinguished sieves on $c$ , denoted by $J(c)$ and called covering sieves of $c$ . "" So, what exactly are the open subsets? Obviously I am confused as I don't understand the big picture underlying these constructions and thus I am getting caught up in the sea of definitions. I am hoping somebody can give a big picture description of how one goes about placing a topologies on $Sch$ .","['algebraic-geometry', 'category-theory']"
3265787,How to properly understand branches of complex functions,"$\DeclareMathOperator{\Log}{Log}$ I have several problems to understand the concept of branches and how to find analytic branches. From what I learned, for example for the complex logarithm, it is a multi valued function, and if we want it to be analytic we have to cut some part of the domain (because otherwise we get different limits in the same point). I understand then why $\Log(z)$ is analytic in the branch $\mathbb{C} \setminus (-\infty ,0]$ , since we can never complete a full circle around $0$ . Here it is a simple case so it is easy to see that we always need to throw a ray from the origin. My confusion starts when the function is not that simple. Let's take the function $Log(z^2-1)$ . I can understand why on the domain $\{ |z| < 1\}$ an analytic branch would be $\mathbb{C} \setminus [0,\infty )$ , since this function takes the unit circle to itself and moves it left by $1$ . So, the ray $[0,\infty )$ doesn't intersect with it. But what if the domain is $\{ |z| > 1\}$ ? How do I work with it since there is not such a pretty way? I thought of maybe using the main branch of the logarithm, and seeing where $z^2-1 \in (-\infty ,0]$ , but is it what needs to be done. Moreover, what about functions like $\sqrt{z^2-1}$ ? How do I start to look for an analytic branch there? It seems logical that the points $1$ and $-1$ play a part here but I am not sure how. Another thing is, how do I solve integral with such functions? For example $$\int_{|z| = 2} \sqrt{z^2-1}$$ When the branch is defined in the following way: $$\sqrt{z^2-1} = z\sqrt{1-\frac {1}{z^2}} = z\exp[\frac{1}{2}Log(1-\frac {1}{z^2})]$$ How does the definition of the branch even play a part here? Another example could be the integral: $$\int_{|z|=2} \frac{1}{\sqrt{z^4+4z+1}}$$ when $\sqrt{25} = 5$ Help would be tremendously appreciated. I someone could walk me thorugh an entire example, I would be really glad.","['complex-analysis', 'branch-points', 'branch-cuts']"
3265836,Show that $g(x)=x + f(x)$ is surjective,"Let $f: {\mathbb{R}}^n \rightarrow {\mathbb{R}}^n$ be continuously differentiable and $C \in (0,1)$ a constant, so that ${||Df(x)||}_{op} \leq C$ $\forall x \in {\mathbb{R}}^n$ with $op$ being a operator norm. Show that $g: {\mathbb{R}}^n \rightarrow {\mathbb{R}}^n$ , $g(x)=x+f(x)$ is surjective. I tried following: $g(x)=x+f(x)$ $\Leftrightarrow Dg(x)=Dx+Df(x)$ $\Leftrightarrow {||Df(x)||}_{op}={||Dg(x)-Dx||}_{op} \leq C$ I'm not realy sure how to get on from here. Is it possible to use the sub-additive of matrix norms even if there is a minus in the equation? I'm thankfull for every hint.","['multivariable-calculus', 'normed-spaces', 'real-analysis']"
3265900,Finding all positive real functions satisfying $xf(y)+f(f(y))\leq f(x+y)$,"Find function $f: \mathbb{R}_{> 0}\rightarrow \mathbb{R}_{> 0}$ such that: $xf(y)+f(f(y))\leq f(x+y)$ for all positive $x$ and $y$ ? That problem made me think a lot. This is the first time I solve functional inequality. Please show me the way to solve such problems. 
From the inequality, can we prove that $f$ is injective or surjective?","['functional-equations', 'algebra-precalculus', 'functions', 'inequality']"
3265907,Notation for set of functions between two sets,"I have recently come across the notation $\mathcal{B}^{\mathcal{A}}$ meaning the set of all functions from set $\mathcal{A}$ to set $\mathcal{B}$ . Using this fact, I am wondering if the following expressions are equivalent: \begin{align*}
&f:\mathcal{A}\times\mathcal{B}\to \mathcal{C}\\
&f:\mathcal{A}\to\mathcal{C}^\mathcal{B}
\end{align*} Apologies if this is trivial, I am just a bit confused about the usage of the set raised to another set notation.","['notation', 'functions']"
3265953,Why isn't $\bar{z}$ differentiable?,"I understand the process my book took to get there. They used the limit process from the ""real"" direction, and the ""complex direction."" To me, it seems obvious that if $z(x,y)=x-iy$ , $\displaystyle \frac{\partial z}{\partial x}=1$ , and $\displaystyle \frac{\partial z}{\partial (iy)}=-1$ . However, the book uses  this to justify why the function is not differentiable, because it approaches different values from different directions. Clearly then, I am missing something. I am confident that this intuition is correct for multivariable functions, but it doesn't work for $f(z)=\bar{z}$ ? Why can a function not have different derivatives in different directions? I was thinking about this some more and I'm wondering if multivariable functions DO have the ""same"" derivative in any direction. For example, consider the function $f(x,y)=3x^2+6y^2$ ; it's derivative is $6x\,dx+12y\,dy$ in every direction. Does that mean, that $\displaystyle \frac{d\bar{z}}{z}=\,dx-\,d(iy)$ ? Can someone comment on my reasoning or explain the difference between multivariable derivatives and complex derivatives?","['derivatives', 'complex-numbers']"
3265969,Confusion Over Ratio Limits and Difference Limits,"I have two functions, $f(x)$ : $$f(x)=\left(H\left(x\right)+\ln\left(H\left(x\right)^{\left(e^{H\left(x\right)}\right)}\right)\right)$$ and $g(x)$ : $$g(x)=e^\gamma x\ln\left(\gamma+\ln x\right)+\frac{x}{\ln\left(\ln\left(x\right)\right)}$$ where $H(x)$ is the harmonic series. What I find confusing is that $$\lim_{x \to \infty}\frac{f(x)}{g(x)}=1$$ but $$\lim_{x \to \infty}f(x)-g(x)\neq 1$$ Is there any way to consolidate these two facts?","['limits', 'calculus']"
3265982,Do these functions exist? [duplicate],"This question already has answers here : Is there a function $f\colon\mathbb{R}\to\mathbb{R}$ such that every non-empty open interval is mapped onto $\mathbb{R}$? (5 answers) Closed 5 years ago . I created this question, but, I do not know the answer: Is there a function $f: \mathbb R \to \mathbb R$ such that for every interval $I \subseteq \mathbb R$ we have $f(I)=\mathbb R$ ? It seems to me that existence of such a function would violate almost everything that I know about analysis, but, on the other hand, it would be awesome if there is at least one such $f$ , because it is known that there are many ""pathological"" examples in analysis. Also, many here are skilled in analysis more than I am, so I can expect an answer, curious about what it will turn to be.","['functions', 'examples-counterexamples', 'real-analysis']"
3265988,How do you determine the characteristic polynomial of a permutation matrix based on the cycle type of the corresponding permutation??,"I read in a paper that you could use the following equation to find the characteristic polynomial of any permutation matrix using the cycle type of the corresponding permutation, but did not understand what $n$ , $k$ , or $C_k$ stand for in the context of the equation: $$ p(\lambda) = \det(M \sigma − λI) = (−1)^n \prod_{k=1}^{n}(\lambda^k − 1)^{C_k} $$ Could someone please explain to me using a simple example such as (1 2 3) what numbers to plug in for $n$ , $k$ , and $C_k$ to arrive at the correct characteristic polynomial for the corresponding matrix (in this case [[0 0 1], [1 0 0], [0 1 0]])? Here is a link to the paper if this helps: https://www.math.arizona.edu/~ura-reports/003/blair-stahn/rpmevals.pdf Thank you so much for your help!","['permutation-matrices', 'permutation-cycles', 'matrices', 'abstract-algebra', 'linear-algebra']"
3266027,Systems of equations involving linear and quadratic terms,"Can we solve for $y$ in this system using algebra? $$\left\{
\begin{aligned}
x^2 - yz &= 3 \\
y^2 - xz &= 4 \\
z^2 - xy &= 5
\end{aligned}
\right.$$ I’ve tried to evaluate it using elimination and it just gives another equation with unknowns. First I've tried to multiply the first equation by $y$ , second by $z$ and third by $x$ . I get $x^2 - y^2z = 3y, y^2z - xz^2 = 4z,$ and $z^2x - x^2y=5x$ . Simplifying I get $5x + 4z + 3y = 0$ . I've tried it again by multiplying the 1st and 3rd equation by $z, x$ and $y$ respectively. I get $5y + 4x + 3z = 0$ . I don't know where to get my third equation.","['algebra-precalculus', 'systems-of-equations']"
3266088,What does it mean to not be able to take the derivative of a function multiple times? [duplicate],"This question already has answers here : Example of function that is differentiable, but the second derivative is not defined (3 answers) Closed 5 years ago . I'm taking a intro to mathematical analysis course and I'm having trouble understanding this definition. They are talking about how it can be interesting to see what happens if you take the derivative of a function multiple times (this is discussed in the intro to Taylor polynomials). They throw this definition at us, which they call $C^kfunctions$ : A function $f: I \rightarrow \mathbb{R} $ belongs to $C^k(I)$ if it is possible to take the derivative of the function k times on $I$ and if $f^{(k)}(x)$ is continuous on $I$ I'm a little confused by this. Aren't all functions $C^\infty$ then? Can't you just keep taking the derivative of a function even if it becomes $0$ ? Specifically I'm on a chapter now where they are discussing curve integrals and they keep mentioning that it is a $C^2$ function. What does this mean? Can you only take the derivative 2 times? I'm confused and can't wrap my mind around it. I would love if anyone was able to explain it in such a way that I could understand and apply it. Thanks in advance.","['derivatives', 'analysis']"
3266119,Number of subgroups of order $p^k$ in $p$-groups,Let $G$ be a non-abelian $p$ -group and $p^k\ge p^3$ be a proper divisor of $|G|$ . It is well known that the number of subgroups of order $p^k$ in $G$ is $1\pmod{p}$ . Divide the subgroups of order $p^k$ into two parts: abelian and non-abelian; which of them are $1\pmod{p}$ in number? Or is it possible that none of them are $1\pmod{p}$ in number? (Just stating the result is fine; I will try to prove it.),"['group-theory', 'finite-groups', 'p-groups']"
3266208,Sheaf on the big site $\operatorname{Sch}/S$ induced by sheaf on $S$,"On the Stacks Project it is claimed that, given a scheme $S$ , any sheaf of modules $\mathcal F$ on $S$ induces a functor $$\operatorname{Sch}/S^{\mathrm{op}}\to \operatorname{Ab}$$ by sending $h\colon T\to S$ to $\Gamma(T,h^\ast F)$ . Now I am having trouble believing that this is really a functor: Is it not true that for two morphisms $f\colon X\to Y$ and $g\colon Y\to Z$ of schemes one has $(g\circ f)^\ast \simeq f^\ast\circ g^\ast$ and not strict equality? After all, the assignment $(T\to S)\mapsto \operatorname{Mod}(T)$ is a pseudofunctor $$\operatorname{Sch}/S^{\mathrm{op}}\to \operatorname{Cat}$$ and not a functor.","['algebraic-geometry', 'grothendieck-topologies', 'sheaf-theory']"
3266238,Geometric consequence of absolute vectors,"If $| \mathbf{a} + \mathbf{b} | = | \mathbf{a} | + | \mathbf{b} |$ , where $\mathbf{a}$ and $\mathbf{b}$ are vectors, what is the geometrical significance of this? My first thought was that the vectors $\mathbf{a}$ and $\mathbf{b}$ must be in the first quadrant, only having positive components.","['vectors', 'geometry']"
3266241,Limits of the wave equation with piecewise constant propagation speed,"Consider a wave equation $$\frac{\partial^2 u}{\partial t^2} = c(x)^2 \frac{\partial^2 u}{\partial x^2} \tag{1}$$ In frequency domain this becomes an ODE: $$-\omega^2 u = c(x)^2 \frac{\partial^2 u}{\partial x^2} \tag{2}$$ We can solve (2) analytically when $c(x)$ is constant, then the solution is $\exp\left(\pm\frac{i \omega}{c} x\right)$ . We can also solve it analytically if $c(x)$ is piecewise constant: write in every region-of-constant- $c$ a linear combination of leftward and rightward propagating waves, impose the appropriate continuity conditions on the interfaces between regions with different values of $c$ , solve for the coefficients of the linear combinations. Suppose now that $c(x)$ is some arbitrary function. We can still write it as a limit of piecewise constant functions: $$c(x)=\lim_{\Delta\rightarrow 0^+} \sum_{i=-\infty}^{\infty} \left\{\begin{matrix}c(i\Delta) & x\in [i\Delta,(i+1)\Delta[ \\ 0 & \text{otherwise}\end{matrix}\right.$$ Let us call these piecewise constant approximations to $c$ , $c_{\Delta}$ $$c_{\Delta}(x)=\sum_{i=-\infty}^{\infty} \left\{\begin{matrix}c(i\Delta) & x\in [i\Delta,(i+1)\Delta[ \\ 0 & \text{otherwise}\end{matrix}\right.$$ We can analytically solve, for any strictly positive $\Delta$ , $$-\omega^2 u_{\Delta}= c_{\Delta}(x)^2 \frac{\partial^2 u_{\Delta}}{\partial x^2}$$ Question Is $\lim_{\Delta\rightarrow 0^+} u_{\Delta} = u$ ? In other words, can we approximate general solutions of (2) by substituting in a piecewise constant approximation of $c(x)$ , and then solving analytically? I expect the answer to be ""no"". because $\lim_{\Delta\rightarrow 0^+} c_{\Delta} = c$ , but $\lim_{\Delta\rightarrow 0^+} \frac{\partial}{\partial x}c_{\Delta} \neq \frac{\partial}{\partial x} c$ , in fact the limit doesn't even exist In literature on numerical solutions of PDEs, I have never seen this suggested as a viable way of approximating solutions of wave equations.","['approximation-theory', 'ordinary-differential-equations', 'reference-request']"
3266257,Number of ways two knights can be placed such that they don't attack.,"What are the number of ways two knights can be placed on a k×k chessboard so that they do not attack each other? For k from 1 to 8, the answer is given below. How do I find a general formula?
0
6
28
96
252
550
1056
1848 Edit: Here's my approach after @Peter 's help,  I came to a conclusion that number of ways such that they attack is equal to two times the number of possible ways I can put an ""L"" shape on the board. (2 times because knights can swap positions), am I right? I don't know how do I more forward from here. I tried finding number of ways to place L by this recursive formula: F[n][n]=4+F[i][i-3]+F[i-2][3]; But it's not working.",['combinatorics']
3266258,The Newton-Raphson method in Banach spaces,"Note: the screenshot at the bottom is where my question comes from. This question is quite different from other versions of conditions of convergence of Newton iteration. For example, Kantorovich theorem. I am now analysing the Newton-Raphson iteration in general Banach spaces $E,F$ . Let $x_0\in E$ , and let $f:B_t(x_0)\to F$ be a differentiable function. ( $B$ denotes an open ball with radius $t$ .) $L(E,F)$ is the set of linear mapping from $E$ to $F$ . By definition, $f$ is differentiable at $x$ with derivative $Df_x\in L(E,F)$ (which is a linear functional from $E$ to $F$ ) if $\exists r(h),f(x+h)=f(x)+Df_x(h)+r(h)$ , where $r(h)/\|h\|\to 0$ as $h\to 0$ . To make it simple, I assume that there exist $s>0$ such that $\|f(x_0)\|\leq t/(2s)$ If $x,y\in B_t(x_0)$ then $\|Df_x-Df_y\|\leq 1/(2s)$ $\forall x\in B_t(x_0),\exists J_x\in L(F,E)$ such that $J_xDf_x=Df_xJ_x=I_E$ and $\|J_x\|\leq s$ . Now let's work on the iteration. Let's fix $x\in B_t(x_0)$ . Set $x_n=x_{n-1}-J_x(f(x_{n-1}))$ . In real analysis course, we often take $x=x_{n-1}$ , but here I have to fix $x$ to be anything in $B_t(x_0)$ . Just assume for a moment that $\forall x\in B_t(x_0)$ . I will explain why later. Firstly I have to show that $x_n$ converges. Now I can use the inequality $$
\|f(a)-f(b)-T(a-b)\|\leq \|a-b\|\sup_{c\in [a,b]} \|Df_c-T\|,
$$ where $[a,b]$ is the line segment joining $a,b$ , and $T\in L(E,F)$ . To use this inequality, we define $g(y)=J_x(f(y))$ , so $x_n=x_{n-1}-g(x_{n-1})$ , and $Dg_y=J_xDf_y$ .( The reason why I cannnot set $x=x_{n-1}$ is that if I do it that way, then $g(y)=J_y(f(y))$ , and I cannot find the derivative of $g$ in this case.) Since $x$ is fixed, we can assume there is NO $x$ dependence in $g$ . Therefore, $$
\|x_{n+1}-x_{n}\|=\|f(x_{n})-f(x_{n-1})-(x_{n}-x_{n-1})\|\\ \leq \|x_{n}-x_{n-1}\|\sup_{c\in [x_n,x_{n-1}]} \|Dg_c-I\|\\=\|x_{n}-x_{n-1}\|\sup_{c\in [x_n,x_{n-1}]} \|J_xDf_c-J_xDf_x\|\\ \leq \|x_{n}-x_{n-1}\|\|J_x\|\|Df_c-Df_x\|\\ \leq \frac{1}{2} \|x_{n}-x_{n-1}\|.
$$ Also, $$
\|x_1-x_0\|=\|J_x(f(x_0))\|\leq t/2
$$ The conclusion is $\|x_n-x_{n-1}\|\leq t/2^n$ . My question: is it really OK to let $x$ be anything fixed in $B_t(x_0)$ ? Does that really work? If it is wrong, how can I fix it? To prove that $f(x_n)$ converges to zero, I feel that I should prove something like $\|f(x_n)\|\leq t/(2^{n+1}s)$ (Suggested in a book of real analysis). I try to start by considering this: $$
\|f(x_n)\|\leq \|Df_x\|\|x_{n+1}-x_n\|
$$ but it goes nowhere. From $\|J_x\|\leq s$ we cannot obtain an upper bound on $Df_x$ . So how can I prove $\|f(x_n)\|\leq t/(2^{n+1}s)$ ? It should be clear that $x_n$ is a Cauchy sequence - but it might not converge into $B_t(x_0)$ - is that a problem? It is a long question, so if I have made mistakes please point it out. Please look at the following screenshot if the above is not clear. Source of my problem: A course in mathematical analysis (screenshot) Here is a theorem of Kantorovich which is related but not the same.","['topological-vector-spaces', 'banach-spaces', 'derivatives', 'functional-analysis']"
3266348,Common volume of three cylinders with unequal radii,"I would like to solve it please for the case where the radii can be a similar size - so the case where this statement is NOT true: $$ \mathbf r_1^2 \mathbf \geq \mathbf r_2^2 \mathbf + \mathbf r_3^2  $$ How do you solve for the common volume of 3 cylinders with unequal radii? (If you could please include the integral needed - I think it might need a cartesian equation system? Or if you have any good idea of what direction or things I could read up on to please learn to solve this. Thank you so much for your help! $$x^2 + y^2 = r_1^2$$ $$x^2 + z^2 = r_2^2$$ $$y^2 + z^2 = r_3^2$$ where $r_1 \neq r_2 \neq r_3$ I can find that the common volume for equal radii using triple integration with circular co-ordinates to get the answer below (following this ) $$V_c = 8\cdot(2-\sqrt 2)\cdot r^3$$ Essentially I want to get to a place where I can find the equation for the common volume of three cylinders with different radii and at different angles.
So if anyone has an idea of how to calculate for cylinders at different angles other than 90 that would be great too! Thank you!","['multivariable-calculus', 'algebra-precalculus', 'volume']"
3266353,"At $x_0 \in \partial \Omega$, $\text{Hess}u(x_0) = \Delta u(x_0) (\nu \otimes \nu)$, $\nu$ outer unit normal","Let $x_0 \in \partial \Omega$ and $\nu(x_{0})$ is the exterior unit normal at $x_0$ , with $\nu_1(x_0) > 0$ , where $u \in C^{2}(\overline{\Omega_{\epsilon}})$ and $\Omega_{\epsilon}=\Omega \cap \{|x-x_0|<\epsilon\}$ , $u>0$ in $\Omega$ and $u=0$ on $\partial \Omega \cap \{|x-x_0|<\epsilon\}$ . We know that $u_{x_1}(x_0) = 0$ . Why does the following hold? $$
\Delta u = - f(0) > 0 \implies u_{x_{i},x_{j}}=-f(0)\nu_{i}\nu_{j} \quad \text{ at } x_0
$$ Moreover, in their paper, Gidas, Ni and Nirenberg claim, right before what inspires the question, that $\nabla u(x_0) = 0$ . It's a mistake, isn't it? Up to my understanding, we only know that $u_1(x_0) = 0$ . This expression appears specifically in the last part of the demonstration of Lemma 2.1 of this article https://projecteuclid.org/download/pdf_1/euclid.cmp/1103905359 of Gidas-Ni-Nirenberg's and I think that it is related to the second directional derivative and Hessian matrix.","['elliptic-equations', 'multivariable-calculus', 'maximum-principle', 'partial-differential-equations', 'hessian-matrix']"
3266367,Find the solution set of $\frac{3\sqrt{2-x}}{x-1}<2$,"Find the solution set of $\frac{3\sqrt{2-x}}{x-1}<2$ Start by squaring both sides $$\frac{-4x^2-x+14}{(x-1)^2}<0$$ Factoring and multiplied both sides with -1 $$\frac{(4x-7)(x+2)}{(x-1)^2}>0$$ I got $$(-\infty,-2)\cup \left(\frac{7}{4},\infty\right)$$ Since $x\leq2$ then $$(-\infty,-2)\cup \left(\frac{7}{4},2\right]$$ But the answer should be $(-\infty,1)\cup \left(\frac{7}{4},2\right]$ . Did I missed something?","['algebra-precalculus', 'inequality']"
3266419,Taylor series for $e^{a x} J_0 (b x)$,"How to derive the general term for the Taylor series around $0$ for this function? I found, using Wolfram Alpha, that: $$e^{a x} I_0 (|a| x)= \sum_{n=0}^\infty \frac{(2n)!}{n!^3} \frac{(a x)^n}{2^n}$$ I suspect that there should be a nice series for the general function. $$f(a,b,x)=e^{ax} J_0 (bx)$$ I see several ways to derive it: Finding an ODE for $f(a,b,x)$ and solving it with power series. Then maybe a recurrence relation will allow us to find a closed form for the coefficients. Using the integral representation of the Bessel function. I'll try the second way: $$J_0(x)= \frac{2}{\pi} \int_0^1 \frac{\cos (x u) du}{\sqrt{1-u^2}}$$ $$e^{a x} J_0(x)=\frac{2}{\pi} \int_0^1 e^{a x} \frac{\cos (x u) du}{\sqrt{1-u^2}}$$ Let's try expanding: $$e^{a x} \cos (u x)=\frac{1}{2} \left(e^{(a+i u) x}+e^{(a-i u) x} \right)= \\ = \frac{1}{2} \sum_{n=0}^\infty \frac{(a+iu)^n+(a-iu)^n}{n!} x^n$$ So we get: $$e^{a x} J_0 (b x)= \sum_{n=0}^\infty C_n(a,b) \frac{x^n}{n!}$$ Where: $$C_n(a,b)=\frac{1}{\pi} \int_0^1 \frac{(a+ib u)^n+(a-ib u)^n}{\sqrt{1-u^2}} du$$ Can we simplify this expression somehow? I suppose we could use Binomial series and then each term becomes a Beta function. On the other hand, we can directly represent this integral as a sum of two hypergeometric functions. I'll see what I can do, but I would welcome other ideas and answers.","['integration', 'bessel-functions', 'taylor-expansion', 'sequences-and-series']"
3266437,Calculating $\binom{n}{0}+\binom{n}{4}+\binom{n}{8}+\cdots$,Calculate: $$\binom{n}{0}+\binom{n}{4}+\binom{n}{8}+\cdots$$ The solution of this exercise: Let $$S_1=\binom{n}{0}-\binom{n}{2}+\binom{n}{4}-\binom{n}{8}+\cdots$$ $$S_2=\binom{n}{1}-\binom{n}{3}+\binom{n}{5}-\cdots$$ $$S_3=\binom{n}{0}+\binom{n}{4}+\binom{n}{8}+\cdots$$ $$S_4=\binom{n}{2}+\binom{n}{6}+\binom{n}{10}+\cdots$$ And we consider $$(1+i)^n=S_1+iS_2=\sqrt2^n\left(\cos\frac{n\pi}{4}+i\sin\frac{n\pi}{4}\right)$$ and $$2^{n-1}+S_1=2S_3$$ The problem is that i didn't get the part with $(1+i)^n$ .. from here i got lost.I saw more exercises like this with combinatorial sums whose solution was about complex numbers and i wish that someone explain me that method.Thanks!,"['binomial-coefficients', 'combinatorics', 'complex-numbers']"
3266482,A Question of Ordinal - İnitial Segment,"Let $\alpha$ be an ordinal. Let $z$ be an initial segment of $\alpha$ . Then either $z=\alpha$ or $z\in\alpha$ . Thus, an initial segment of an ordinal is an ordinal. Proof. If $z\neq\alpha$ , then $\alpha\setminus z$ does have a minimal element, say $x$ . Then $$z=\left\{y\in\alpha : y<\alpha\right\}=\left\{y\in\alpha : y\in\alpha\right\}=x\in\alpha.$$ I have a question in the proof: How did writer connect from $\left\{y\in\alpha : y<\alpha\right\}$ to the set $\left\{y\in\alpha : y\in\alpha\right\}=x\in\alpha.$ Can you explain?","['elementary-set-theory', 'proof-explanation', 'proof-writing', 'proof-verification']"
3266485,Prove that there exist infinitely many prime numbers $p$ such that $\mathrm{ord}_p(a)=\mathrm{ord}_p(b)$.,"Let $a$ , $b$ be distinct positive integers greater than $1$ . Prove that there exist infinitely many prime numbers $p$ such that $\mathrm{ord}_p(a)=\mathrm{ord}_p(b)$ . (Here $\mathrm{ord}_p(a)$ is the smallest integer $k>0$ such that $a^k\equiv1\pmod p$ .) This problem is from the 2018 Iranian Math Olympiad. I cannot find any sources for the official answer. I have tried to solve it, but it didn't work. The only thing that I found out is that if $p|\mathrm{gcd}(a-1,b-1)$ , then $\mathrm{ord}_p(a)=\mathrm{ord}_p(b)=1$ . Sorry for the lack of information. That is all I have to say. How can I solve the orange problem? If any sources were known, please post the answers in the answer section here. Any answers, solutions or comments will be appreciated. If this question cannot be answered, I will delete this post immediately.","['number-theory', 'elementary-number-theory', 'prime-numbers']"
3266560,"Why is the matrix derivative of the trace of $AB$ with respect to $B$ not a constant, but $A^T$?","Why is this true? $$\frac{d}{dB} Tr[A B]= A^\top$$ Trace is the sum of the diagonal elements. So, I'm expecting a number, a matrix! What's going on here? Example: Given matrix A with $m \times n$ , and B with $n \times p$ , in particular, we have the following, $$A= 
\begin{bmatrix}
a_{11} & a_{12} & a_{13} \\
a_{21} & a_{22} & a_{23}
\end{bmatrix}, 
B= 
\begin{bmatrix}
b_{11} & b_{12} \\
b_{21} & b_{22} \\
b_{31} & b_{32}
\end{bmatrix}
$$ To get the answer, we mulitply, take derivative, then, trace. First, we mutiply, $$AB= 
\begin{bmatrix}
a_{11}b_{11} + a_{12}b_{21} + a_{13}b_{31} & a_{11}b_{11} + a_{12}b_{21} + a_{13}b_{31} \\
a_{21}b_{11} + a_{22}b_{21} + a_{23}b_{31} & a_{21}b_{12} + a_{22}b_{22} + a_{23}b_{32}
\end{bmatrix} $$ Second, we take derivative. Fact: $\frac{d}{dB} Tr[A B]=  Tr[A \frac{d}{dB}B]$ , $$A\frac{d}{d B}= 
\begin{bmatrix}
a_{11}+ a_{12} + a_{13} & a_{11} + a_{12} + a_{13} \\
a_{21} + a_{22}+ a_{23} & a_{21} + a_{22}b + a_{23}
\end{bmatrix} $$ Third, we take trace, $$Tr\left[ A\frac{d}{d B}\right] = a_{11} + a_{12} + a_{13} + a_{21} + a_{22}b + a_{23} = k$$ The result is $\frac{d}{dB} Tr[A B] = k$ , this a constant. Not the matrix $A^T$ as established in the first equation.","['derivatives', 'trace', 'matrix-calculus', 'linear-algebra']"
3266583,"If $ \int_0^{2\pi}|f(re^{i\theta})|d\theta\le Ar^k $ for $f$ holomorphic and every $r>0$, then $f(z)=Cz^k$ for some constant $C$.","Suppose that $f(z)$ is a holomorphic function on all of $\mathbb C$ . Assume that there are constants $A>0$ and a non-negative integer $k$ so that $$ \int_0^{2\pi}|f(re^{i\theta})|d\theta\le Ar^k $$ for all $r>0$ . Prove that $f(z)=Cz^k$ for some constant $C$ . My attempt: Note that $$2\pi|f(0)|\le\int_0^{2\pi}|f(re^{i\theta})|d\theta\le Ar^k$$ for all $r>0$ , we have $f(0)=0$ . If we can show that there exists $C$ such that $$g(z):=\begin{cases}\frac{f(z)}{z^k},&z\ne 0 \\ C,& z=0\end{cases}$$ is bounded and holomorphic on $\mathbb C$ , then we are done. I was going to imitate the proof of Schwarz Lemma, but then I got stuck since $k$ can be less than $1$ which probably makes the limit $\lim_{z\to 0}\frac{f(z)}{z^k}$ go to infinity. So how to move on?",['complex-analysis']
3266639,Notation for partial derivative of functions of functions,"Say we have a function $f(x(t),t)$ and we take the partial derivative of $f(x(t),t)$ with respect to $t$ $$\frac{\partial f(x(t),t)}{\partial t}$$ Do we hold $x(t)$ constant? For example, if I had $f(x(t),t) = x(t)^2 + t$ where $x(t)=t^2$ , I believe $\frac{\partial f(x(t),t)}{\partial x(t)}=2x(t)$ but  does $\frac{\partial f(x(t),t)}{\partial t}=4t+1 $ or $1$ ? To further my understanding, is the following true: $$ \frac{\partial f(x(t),t)}{\partial t}=\frac{df(x(t),t)}{dt}$$ because $f(x(t),t)=f(t)$ after you simplify it by substituting in $x(t)$ into $f(x(t),t)$ ? But if this is true, in the above example, $\frac{\partial f(x(t),t)}{\partial x(t)}=0$ because $f(x(t),t)=f(t)$ doesn't actually depend on $x(t)$ . I see that my understanding is wrong but I can't figure out where. Any insight appreciated, thanks in advance!","['partial-derivative', 'multivariable-calculus', 'derivatives']"
3266647,Existence of $n-1$ dimensional invariant subspace of $V$ over $\mathbb{R}$ given characteristic polynomial has a real root.,"$V$ is a finite dimensional vector space over $\mathbb{R}$ with $\dim V \ge 1$ and $\phi \in L(V, V)$ is an endomorphism. Its characteristic polynomial $w_{\phi}(\lambda)$ has a real root. Prove the existence of an $n-1$ dimensional invariant subspace for $V$ . I tried to deduce something from Jordan Canonical Form but with no effect.","['invariant-subspace', 'linear-algebra', 'eigenvalues-eigenvectors']"
3266689,"Do all non-orientable have to ""close"" in some direction?","I am not a connoisseur in the topic of surfaces, the two non-orientable surfaces I know are the Möbius strip and the Klein bottle. Intuitively I understand that for a surface to be non-orientable, the basis vectors have to flip at some point (while following a given path without changing their relative direction... probably something like parallel transport), so that a basis that was once positively oriented changes to one that has negative orientation, and consequently it makes no sense to talk about orientation. Whenever I think about it, the following image is what comes to mind. But for this to happen there must be at least one path, tangent to some basis vector, that has to close on itself. In other words, at least one of the directions is bounded. In the particular case of the the Möbius strip and the Klein bottle we also know that the genus is greater than zero (one and two, respectively). My question is, Are there (finite dimensional) unbounded non-orientable surfaces? Also, Is the genus of these surfaces always greater than zero?","['geometry', 'general-topology', 'differential-topology', 'low-dimensional-topology', 'differential-geometry']"
3266714,Set of linear functionals span the dual space iff intersection of their kernels is $\{0\}$.,"I was wondering if anyone could offer some insight into the following problem: Let $\mathit{V}$ be a vector space over a field $\mathbb{F}$ . Assume that dim $\mathit{V}$ is finite. Let $f_1, \ldots, f_k$ $\in$ $\mathit{V}$ ' Show that $\{f_1, \ldots, f_k\}$ span $\mathit{V}$ ' iff $\bigcap_{i=1}^n \ker(f_i)$ = $\{0\}$","['linear-algebra', 'dual-spaces']"
3266719,"If $T-\lambda I$ is a Fredholm operator and $\lambda \in \sigma(T)$, then $\lambda \in \sigma_p(T)$ or $\overline{\lambda} \in \sigma_p(T^*)$?","Let $H$ be a Hilbert space and let $T: D(T) \subseteq H \to H$ be a densely defined operator. Is the following statement true? If $T-\lambda I$ is a Fredholm operator (an operator is Fredholm if its range is closed and both its kernel and its cokernel are finite-dimensional) and $\lambda \in \sigma(T)$ , then $\lambda$ is an eigenvalue of $T$ or $\overline{\lambda}$ is an eigenvalue of $T^*$ . Thanks in advance for any help.","['operator-theory', 'spectral-theory', 'functional-analysis']"
3266732,Balls and Bins Variant Unique Maximum Number of Balls in a Bin,"Suppose there are $m$ balls and $n$ bins where $m \geq n$ . The $m$ balls are thrown into the $n$ bins uniformly at random. At the end of each round, all bins with less than the maximum number of balls is removed. Let the remaining number of bins be $n_1$ . The process is repeated with $m$ balls and $n_1$ bins, and so on. The question is, what is the expected number of rounds necessary until one bin remains? One can get a weak bound of $\lg n$ rounds by using the well-known result for expected number of empty bins: $n/e$ . But I'm hoping for a tighter bound. Has anyone ever seen this question before perhaps named differently? Intuitively, this is the opposite of what we want with balls and bins (because that's used most often in load balancing), but I don't know a better name to ask this question under.","['discrete-mathematics', 'balls-in-bins', 'probability']"
3266774,Power of Two Choices: Picking the Heavier Bin,"Suppose there are $m$ balls and $n$ bins. We use the Power of Two Choices except we pick the heavier bin instead of the lighter bin: i.e. given a set of $n$ bins, the balls are thrown sequentially and two bins are picked uniformly at random (with replacement) and the ball is thrown into the bin with more balls out of the picked bins each time. I want to know what is the expected number of empty bins in this case. Does anyone know if the behavior of the Power of Two Choices has been studied in the context of picking the heavier instead of the lighter bin?","['discrete-mathematics', 'combinatorics', 'balls-in-bins', 'probability']"
3266784,"Proving that $\iint\frac{x-y}{(x+y)^3}\,dx\,dy$ does not exist over $0 \leq x \leq 1 , 0 \leq y \leq 1$","To prove that double integral does not exist: $$\iint\frac{x-y}{(x+y)^2}\,dx\,dy$$ over region $0 \leq x \leq 1 , 0 \leq y \leq 1$ . I put $x - y = u$ and $x+y = v$ and I got integral as $$\iint \frac{u}{v^3}\,du\,dv$$ Limits of $u$ are from $2-v \leq u\leq v-2$ and $v$ are from $0$ to $1$ . I am not sure about my new limits and how to prove it further. EDIT : The correct expression is $\iint\frac{x-y}{(x+y)^3}\,dx\,dy$","['multivariable-calculus', 'multiple-integral']"
3266813,Proving that the Quotient of an Algebraic Curve $X/G$ is an Algebraic Curve.,"I am self-studying Miranda's book Algebraic Curves and Riemann Surfaces and I am looking for a hint for a problem. For those with the book, it is on page 178, and is Problem VI. $1$ .L. The problem is the following: Let $G$ be a finite group acting effectively on an algebraic curve $X$ . (i) Show that $G$ acts on the function field $\mathcal{M}(X)$ . (ii) Show that the function field of the quotient Riemann surface $X/G$ is the field of invariants $\mathcal{M}(X)^G$ . (iii) Show that $X/G$ is an algebraic curve. Parts (i) and (ii) I found rather easy, so that for part (iii) I have $\mathcal{M}(X)^G\cong \mathcal{M}(X/G)$ . According to Miranda, an algebraic curve is a compact Riemann surface $X$ so that $\mathcal{M}(X)$ separates points and separates tangents. So, I am trying to demonstrate that $\mathcal{M}(X)^G$ separates points on $X/G$ . Now, by assumption $\mathcal{M}(X)$ separates points on $X$ , the issue however is finding a function $f\in \mathcal{M}(X)^G$ separating points $x$ and $y$ lying in distinct $G$ -orbits. I tried fixing $f\in \mathcal{M}(X)$ such that $f(x)\ne f(y)$ . Then I produced a $G$ -invariant function $\overline{f}$ by $$ \overline{f}=\frac{1}{\lvert G\rvert}\sum_{g\in G} f\circ g$$ where I identify $G$ with a subgroup of $\operatorname{Aut}(X)$ . I suspect I might be able to show that this function has the desired property, but I have not succeeded. I am having similar difficulties with separation of tangents.","['complex-analysis', 'riemann-surfaces', 'algebraic-geometry', 'algebraic-curves']"
3266832,"Example of a complex function with ""essential singularity"" all along the unit circle","I found myself curious whether there existed a complex function which is analytic on the interior of the unit disc, but such that there is no extension of the function to a holomorphic function on a strictly larger connected open set.  This was because all the typical examples I could think of with a finite radius of convergence of the Taylor series had natural analytic extensions near all but finitely many points of the boundary of the region of convergence. The example I came up with was: $$f(z) := \sum_{n=0}^\infty \frac{z^{2^n}}{2^n}.$$ This function has radius of convergence 1, and at every point of $|z| = 1$ it converges to a function whose imaginary part has $\Im f(e^{i \theta})$ equal to the Weierstrass function.  Therefore, the restriction to the unit circle is not differentiable (as a function on the real $C^\infty$ manifold $S^1$ ) at any point, which makes it impossible for any extension of $f$ to be holomorphic at any point on the unit circle (since Abel's theorem implies such an extension wouldn't have a pole at such a point). My question is: is this a valid example, or is there something I'm missing?  And also, is there a more natural example of such a function in terms of the usual examples of analytic functions?",['complex-analysis']
3266867,"First order differential equation with $y,y',$ and $\sqrt y$","I have been struggling with this equation: $(x^2+1)y'-2xy=4\sqrt{(x^2+1)y}\arctan x$ I have tried with $y=z^m$ to make homogeneous equation, but I didn't get anything anything useful. Left side also looks a lot like quotient rule, so I tried solving in that direction, but again it didn't work. Whatever I do I can't seem to get it to any standard form. Thanks for help.",['ordinary-differential-equations']
3266873,Use of congruence arithmetic laws to solve linear congruences,"My question is somewhat related to this thread: How to solve congruence with two variables x and y I can not post a comment to ask directly there, therefore I need to create this thread Anyhow, as was pointed out in there, $8x+8y≡x+y≡0\mod7$ $y≡−x\mod7$ My questions are: How do you get the scalar 4 in order to obtain $8x+8y$ . Is it because $8≡1\mod7$ and therefore we need an $ 8$ , $8/2 = 4$ , and that's it? Or is there a totally different logic behind this step? I assume you get rid of the $8$ s simply by dividing the whole congruence by $8$ ? In the final solution it is stated that $y=-x+7k$ ; to obtain the $-x$ , can you simply move it on the other hand of the equation? So if we had anything else, could we just move it, like in normal equations? Thanks in advance!","['elementary-number-theory', 'convergence-divergence', 'modular-arithmetic', 'discrete-mathematics']"
3266908,Visualizing a fiber bundle,"Define the torus $$(S^1)^3=\left\{ (e^{2\pi ir_1},e^{2\pi ir_2},e^{2\pi ir_3});\ \   r_1,r_2,r_3\in \mathbb R\right\}$$ and consider the dense subgroup $$Q:=\left\{ (e^{2\pi ir_1},e^{2\pi \alpha r_1},e^{2\pi ir_3})\right\}$$ where $\alpha\in \mathbb R\setminus\mathbb Q$ . Now consider the projection $$p:(S^1)^3\to (S^1)^2$$ $$ (e^{2\pi ir_1},e^{2\pi ir_2},e^{2\pi ir_3})\mapsto (e^{2\pi ir_1},e^{2\pi ir_3})$$ I would like to visualize the restriction $p|_Q$ . I mean an illustration figure with the following components: The space $Q$ and the fiber $(p|_Q)^{-1}(y)$ as a dense subset of the circle $S^1$ and the torus as the base. Any good pictures! Suggestion: Since $Q\cong \mathbb R\times S^1$ and the factor $\mathbb R$ makes $Q$ dense, then neglecting $S^1$ allows us to correspond $Q$ to a skew (dense) line in the base?? Does this help to draw a nice picture?","['geometric-topology', 'fiber-bundles', 'algebraic-topology', 'differential-geometry']"
3266985,Uniform convergence of sequence of analytic functions,"I am having trouble with the following question: Let $\Omega$ be a non-empty open subset of $\mathbb{C}$ , and let $f$ be a continuous function on $\Omega$ . Suppose that $f_1, f_2,f_3,...$ are analytic on $\Omega$ , and that $$\lim_{n\rightarrow \infty} \int_{D} \vert f_n (x+ iy) - f(x + iy)  \vert dxdy = 0, $$ for every closed disk $D \subset \Omega$ . Show that $f$ is analytic, and that $f_n \rightarrow f$ uniformly on compact subsets of $\Omega$ . $\textbf{Thoughts}:$ $\textbf{1.}$ I am aware that Cauchy's Theorem will ensure that $f$ analytic provided $f_n \rightarrow f$ uniformly. $\textbf{2.}$ The limit of the integral is zero namely for $\sup_{z \in D} \vert f_n(x+iy) - f(x+iy) \vert$ . $\textbf{3.}$ Triangle Inequality. I've pushed some things around, but I don't think I am properly timing $\vert \int \vert \leq \int \vert \vert$ to see what next steps should be. $\textbf{4.}$ Montel's Theorem and Normal families smell like they could be related. One concern is using some circular logic that is wrapped up in the relationship of Dominated Convergence and Uniform Continuity. Clarification, tips, resources, etc., will all be greatly appreciated.","['complex-analysis', 'uniform-convergence']"
3266992,Expectation of X divided by Y,Say we have two continuous independent random variables $X$ and $Y$ . I understand that $E[XY] = E[X]E[Y]$ but what about $E[X/Y]$ . Can I say: $E[Xg(Y)]$ where $g(x) = \dfrac{1}{x}$ $E[X]E[g(Y)]$ by linearity Then solve for each? If not then how does one go about solving this type of problem?,"['expected-value', 'probability-theory', 'probability']"
3267049,How to calculate standard deviation?,"x(i) | freq. 8 | 11 10 | 9 12 | 13 14 | 24 16 | 16 18 | 10 20 | 15 The formula for standard deviation is $\sigma = \sqrt{\frac{\Sigma|x-\bar{x}|^2}{n}}$ . It would be easy with a graphing calculator, but I only have TI-30XA scientific calculator that can't do much. Can someone teach me a faster way to calculate the standard deviation by hand?","['statistics', 'standard-deviation']"
3267057,10 ties in a wardrobe,"I have $10$ ties in a wardrobe and I pick one at random with probability $0.1$ each day independently. I return the tie after usage, so we allow replacement. let $\,\theta$ be equal to the number of ties I used in course of $5$ days. what is the expected value and variance of $\, \theta$ random variable? Now , I know this is some type of  application of indicators, I would like to know which theorem or method in regards to the indicators does this problem use for the solution?","['probability-theory', 'probability']"
3267058,Why are theorems stated for $u(X)$ instead of just $X$?,"In Introduction to Mathematical Statistics by Hogg and Craig, they state the generalization of Chebyshev's Inequality as: Let $u(X)$ be a nonnegative function of the random variable $X$ .  If $E[u(X)]$ exists, then, for every positive constant $c$ , $\displaystyle Pr[u(X) \geq c] \leq \frac{E[u(X)]}{c}$ . Why do they state this for $u(X)$ instead of just $X$ ?  Is it just a matter of preference for applying the theorem later, or is it actually more general for some reason?  It seems like you can just make the substitution $Y=u(X)$ .","['probability-distributions', 'probability-theory']"
3267168,"Evaluate $\int_0^1 x^{a-1}(1-x)^{b-1}\operatorname{Li}_3(x) \, dx$","Define $\small f(a,b)=\frac1{B(a,b)}\int_0^1 x^{a-1}(1-x)^{b-1} \text{Li}_3(x) \, dx$$ $$=\frac a{a+b}{}_5F_4(1,1,1,1,a+1;2,2,2,1+a+b;1)$ Where $a>-1$ and $b>0$ . $1$ . By using contour integration one may prove $f(a,1-a)=-\frac{1}{6}H_{-a}^3-\frac{\pi ^2}{12} H_{-a}+\frac{1}{2} H_{-a} \psi ^{(1)}(1-a)-\frac16\psi ^{(2)}(1-a)-\frac13\zeta (3)$ Here $H_a$ denotes generalized harmonic numbers. $2$ . By using Fourier-Legendre expansion, I proved $2f\left(\frac34,\frac34\right)=4 \pi  G-8 G \log (2)-16 \Im\left(\text{Li}_3\left(\frac{1+i}{2}\right)\right)-\frac{21 \zeta (3)}{4}+\frac{\pi ^3}{2}-\frac{5 \pi ^2}{6}-4 \pi +16+\frac{\log ^3(2)}{3}+2 \log ^2(2)-\frac{5}{12} \pi ^2 \log (2)-2 \pi  \log (2)+8 \log (2)$ The calculation is so complicated that it may worth an individual question. $3$ . $f(1,1/2)$ and $f(1/2,1)$ can also be computed through FL expansion. Question. Concerning calculations above, I conjecture that there may be other non-trivial (at least one of $a,b\not\in\mathbb Z$ ) closed-forms of $f(a,b)$ (or even a class of them). So: Are there any non-trivial closed-forms of $f$ besides those I mentioned? I suspect $f(1/4,1/4)$ may have closed-form but have found none.  Also note that if closed-forms of $f(n,1/2)$ (resp. $f(1/2,n)$ ) could be found, the whole class $f(n,1/2+m)$ (resp. $f(1/2+m,n)$ ) would be solvable ( $n,m\in\mathbb Z$ ). Note. Here is a dilog counterpart of this problem.","['integration', 'definite-integrals', 'legendre-polynomials', 'polylogarithm', 'hypergeometric-function']"
3267186,Eigenvalue and similar matrices,"if $A$ and $B$ are two $n\times n$ matrices with same eigenvalues such that each eigenvalue has same algebraic and geometric multiplicity. Does $A$ and $B$ are similar? If $A$ is diagnalizable  then the claim is true. But does it true even when sum of geometric multiplicity is not $n$ . Please give me a hint to start with. If given a counter example, please help me to show they are not similar. Thanks","['matrices', 'linear-algebra', 'examples-counterexamples', 'eigenvalues-eigenvectors']"
3267279,Number of zeros of $z^4-z^3-4z+1$ in the ring $\{ 1 < |z| < 2 \}$,"I need to prove that the number of zeros of $z^4-z^3-4z+1$ in the ring $\{ 1 < |z| < 2 \}$ is equal to $3$ . What I have done so far; I've proved there is only one zero in the $\{|z|\leq1\}$ . So the only thing remaining is to prove there is no zeros in the $\{|z|\geq2\}$ . This part, however, creates a lot of issues for me. I've tried the classic way using Rouche's theorem and even adding new polynomials in order to use it, but nothing helped. Also tried assuming $z^4-z^3-4z+1=0$ and $|z|\geq2$ with some clever use of inequalites, that didn't help either. I don't know if I'm missing something, but according to WA, one zero is $\approx1.9325$ so that might be causing troubles in my opinion.","['complex-analysis', 'roots']"
3267310,On group quotient by a characteristic subgroup,"My question is: Let $H,K\leq G$ be two characteristic subgroups and assume $H\leq K$ . Do we have $K/H$ is characteristic in $G/H$ ? We know that any characteristic subgroup of $G/H$ must be of the form $K/H$ for some characteristic subgroup $K$ of $G$ since any automorphism of $G$ induces an automorphism of $G/H$ . But is the converse true? Or any counterexample?","['group-theory', 'abstract-algebra', 'characteristic-subgroups']"
3267424,p-value and t-distribution,"Given a data set $(x_1,\ldots, x_n)$ , ( for $n$ - large ) which is realization of a random sample $(X_1, \ldots , X_n)$ . Assume the null hypothesis $H_0:\mu = \mu_0$ and alternative hypothesis $H_1 : \mu > \mu_1$ . Then which is an appropriate method of testing whether or not to reject $H_0$ ? One way would be to use $t$ -test method and find $\pm t_{n-1,\alpha/2}$ ( if $\alpha$ - the significance level is given ) and check where our current observation $T_0 = (X_{\text{average}} - \mu_0)/(S_n/\sqrt n)$ lies. But I also thought about computing the probability that $T$ is at least as extreme as our current our observation ( i.e just compute the $p$ -value $P(T > T_0)$ . My question is when to use p-value and when t-distribution as a motivation for a decision whether to reject $H_0$ .","['statistics', 'probability', 'hypothesis-testing']"
3267464,Matrices with rows from an arbitrary vector space (and multiplication by number matrices),"Matrices consist of elements of some field. However, if we have a matrix $A\in M_{m,n}(F)$ , it is sometimes useful to look at each row as a vector from $F^n$ , i.e., we can view the matrix as $$A=\begin{pmatrix}\vec r_1\\\vec r_2\\\vdots\\\vec r_m\end{pmatrix}.$$ (Doing the same thing with columns make sense, too. I will describe stuff in this post with rows, it can be easily changed for columns.) Sometimes it might be useful to do same thing with vectors from arbitrary vector space $V$ over a field $F$ . I.e., we can use notation $$\mathbf{B}=\begin{pmatrix}\vec v_1\\\vec v_2\\\vdots\\\vec v_m\end{pmatrix}.$$ I will use bold for ""matrices consisting of vectors"". This is just a different notation for ordered $n$ -tuple of vectors. But at least in some ways they are similar to matrices.
For example, we can multiply such matrix by $A\in M_{k,m}(F)$ from the left to get $$A\cdot \mathbf{B},$$ which is the matrix where the $i$ -th row is the linear combination $\sum_{j=1}^m a_{ij}\vec v_j$ . (If we choose to work with columns, we would multiply from the right.) We can also add these matrices and multiply them by a scalar. With these definitions several properties of usual multiplication of matrices still hold - for the products that are allowed. For example, associativity $A(B\mathbf{C})=A(B\mathbf{C})$ or distributivity - both $(A+B)\mathbf{C}$ and $A(\mathbf{C}+\mathbf{D})$ . Also some properties which are valid for rank are still valid for dimension of the vector space generated by the rows. (For example, if $A$ is invertible then the ""rank"" of $\mathbf B$ and $A\mathbf B$ is the same. ""Rank"" of $A\mathbf B$ is bounded from above by the rank of $A$ and also by the ""rank"" of $\mathbf B$ .) We cannot multiply from the right, but we still can ""cancel"" on the right in the sense that if rows of $\mathbf B$ are linearly independent then $A\mathbf{B}=\mathbf{0}$ implies $A=0$ and $A_1\mathbf{B}=A_2\mathbf{B}$ implies $A_1=A_2$ . This notation can be used, for example, to make a compact notation for transition matrix between two bases by writing $\mathbf B_2=M\mathbf{B_1}$ . (And some proofs about transition matrices could be written in quite a compact way using this notation. Another possible advantage of this notation is that if we are careful only to do ""allowed"" multiplications, than we can use many properties of the usual matrix multiplication - which after some time spend with linear algebra and matrices are used almost automatically.) Question. Are there some text which use this formalism, where we can multiply by ""non-numerical"" matrices with rows (or columns) consists of vectors from arbitrary vector space (not necessary $n$ -tuples? Are there some situations when using this approach brings some advantages? Remark 1. In a sense, the above considerations can be bypassed easily. If we work with the type of ""matrices"" as above, we can simply take the finite dimensional subspace $S$ which contains rows of all matrices which we need at the moment. (For example, all rows which appear in some ""matrix"" identity we are looking at. Or if $V$ is finitely-dimensional, we can simply take $S=V$ .) If we fix some basis for $S$ , this induces and isomorphism between $S$ and $F^n$ , where $n=\dim(S)$ and we get a natural map $\mathbf{B} \mapsto B\in M_{m,n}$ . Once we fixed a basis for $S$ , any result concerning multiplication of ""matrices"" is now just the usual multiplication - we just need to transfer everything through this isomorphism. Still, I was curious whether sometimes it might be useful to avoid the need to fix a base and transfer things using the corresponding isomorphism. Remark 2. Matrix summability methods can be viewed as a multiplication of an infinite matrix (of dimensions "" $\mathbb N\times\mathbb N$ "") by a sequence considered as an infinite vector. Although in such ""matrices"" the rows do not have finitely many coordinates, this is different from what I have in mind, since I work here with matrices that have finitely many rows.","['vector-spaces', 'reference-request', 'matrices', 'change-of-basis', 'linear-algebra']"
3267497,A set which is the closure of its interior points,"I am trying to give a sufficient condition for a set in $\mathbb{R}^n$ which is the closure of its interior points. A priori, such a set has to be a closed set. A closed set in general is not the closure of its interior point. A trivial counter example is a set with empty interior, e.g the segment $[0,1]\times \{0\}$ in $\mathbb{R}^2$ . So the next candidate is one with non empty interior. One can come up with a counter example is a sphere with hair, e.g the union of $\{x^2+y^2 \le 1\} \cup [1,2]\times \{0\}$ in $\mathbb{R}^2$ . So to avoid these kinds of counter example, I propose the following question (""conjecture"" may be?) Question 1: Let $K$ be a closed connected subset of $\mathbb{R}^n , n \ge 2$ with nonempty interior $Int(K)$ . Suppose that the boundary $\partial K$ is a connected submanifold of $\mathbb{R}^n$ . Then $K = \overline{Int(K)}$ . Note: By submanifold of $\mathbb{R}^n$ I mean an embedded submanifold of $\mathbb{R}^n$ . In particular, $\partial K$ is orientable. The connectivity assumption on $K$ is to avoid the case that $K$ has an isolated point. I am not sure that I need the connectivity of the boundary $\partial K$ . The reason I put it there because the fact that $K$ is connected does not implies that $\partial K$ is connected. This is due to this question Connectedness of the boundary which asserts that (if I understood correctly) a connected set $K$ has connected boundary if and only if the complement $K^c= \mathbb{R}^n \setminus K$ is connected.  Again, the counter example to this situation (connected set with non-connected boundary) does not satisfy the assumption that the boundary itself is a submanifold of $\mathbb{R}^n$ . But even with this question I don't know how to tackle yet so just assume that $\partial K$ is a connected submanifold of $\mathbb{R}^n$ . My attempt: I am able to give an argument in the case when $K$ is compact. My argument goes as follows: Since $K$ connected, $Int(K)$ has no isolated point and $\overline{Int(K)} = Int(K) \cup \partial Int(K)$ . Note that $K = Int(K) \cup \partial K$ thus $\partial Int(K) \subset \partial K$ . Since $K$ is compact, $\partial K$ is a compact, connected submanifold of $\mathbb{R}^n$ . Denote by $k$ the codimension of $\partial K$ . It is enough to prove that $\partial Int(K)= \partial K$ . If $k \ge 2$ : consider a point $x \in \partial Int(K)$ and a local chart $(U,\varphi)$ of $\mathbb{R}^n$ so that $\varphi(U) =\mathbb{R}^n$ and $$\varphi(U \cap \partial K) = \mathbb{R}^{n-k} \times \{0\} $$ Since $k \ge 2$ , it follows that $U \setminus \partial K$ is connected. On one hand, since $x \in \partial Int(K)$ , $U \cap Int(K) \neq \emptyset$ . On another hand, we have a decomposition $$U \setminus \partial K = (U \cap Int(K)) \cup (U \cap K^c)$$ of $U$ as two disjoint open set. Thus the connectivity of $U \setminus \partial K$ implies that $U \cap K^c = \emptyset$ , i.e. $U \subset K$ . Since $U$ open, $U \subset Int(K)$ which yields a contradiction since $U$ contains a boundary point of $Int(K)$ . We deduce that $\partial K$ is a compact hypersurface of $\mathbb{R}^n$ which is orientable. By ""Lima, Elon L. ""The Jordan-Brouwer separation theorem for smooth hypersurfaces."" The American Mathematical Monthly 95.1 (1988): 39-42."", I can deduce that $\mathbb{R}^n \setminus \partial K$ has two connected component $U_1,U_2$ whose boundaries are exactly $\partial K$ . As $K^c$ is connected, without loss of generality, I assume that $K^c \subset U_1$ . It is enough to prove that $Int(K) \subset U_2$ , hence $Int(K) = U_2$ and it follows that $\partial U_2 = \partial Int(K)  = \partial K$ . Suppose that $Int(K) \setminus U_2 \neq \emptyset$ , thus $Int(K) \cap U_1 \neq \emptyset$ . Note that $$U_2 = (U_2 \cap Int(K)) \cup (U_2 \cap \partial Int(K)) \cup (U_2 \cap \overline{Int(K)}^c).$$ Hence by connectivity of $U_2$ , we can deduce that $U_2 \cap \partial Int(K) \neq \emptyset$ which is a contradiction since $\partial Int(K) \subset Int(K) \cap U_2 =\emptyset$ . (This is in fact an argument for a general fact: If $U$ is an open connected subset of $\mathbb{R}^n$ then for every $V \subset U$ and $V \neq U$ , we have $\partial V \cap U \neq \emptyset$ .) Is my argument correct? I am really grateful if anyone can come up with a proof or a counter example of Question 1 , with or without the hypothesis of connectivity of $\partial K$ . I prefer arguing by not so complicated machinery (not homology, cohomology, Mayer-Viertoris sequence, etc..) Thank you.","['connectedness', 'general-topology', 'proof-verification', 'differential-geometry']"
3267515,Tangent Space and Dual Numbers,"I have a question about exercise 2.8 from Hartshorne's ""Algebraic Geometry"" (see page 80): Assume $X$ is a scheme over field $k$ and $x \in X$ . Then the tangent space $T_x$ is defined as the set of $k(x) = O_{X,x}/m_x$ -linear morphisms $m_x/m_x^2 \to k(x)$ (so the dual to $m_x/m_x^2 $ ). We denote by $k[\epsilon]:=k[t]/t^2$ the ring of dual numbers. I have to derive a 1-to-1 correspndence between elements of Tangent space $T_x$ and $k$ -morphisms $f: Spec(k[\epsilon]) \to X$ with $f(\{*\})= x$ and $k(x)=k$ (so $x$ rational) Here I encountered following PROBLEM: At first glace it seems to be quite sraight forward: A map $f: Spec(k[\epsilon]) \to X$ induces on stalks the map $f_x: O_{X,x} \to k[\epsilon]=k[t]/t^2$ and since $f_x(m_x^2) =0$ (because $f_x$ is a local morphism since $f^{\#}$ is a morphism of local ringed spaces) and the composition $m_x \subset O_{X,x} \to k[\epsilon]$ induces the map $m_x/m_x^2 \to k[\epsilon]$ . If we futhermore quotient out $(t)$ from $k[\epsilon]$ then we obtain a canidate $m_x/m_x^2 \to k[\epsilon] \to k[\epsilon]/(t)=k$ . BUT: the problem is that this map is by construction a zero map since $f_*$ is again a local morphism so $f_x(m_x) \subset (t)$ and by $ k[\epsilon]/(t)=k$ we kill $(t)$ . So our $m_x/m_x^2 \to =k$ is always a zero map. What is the error in my reasonings? Which construction is expected here to settle the desired correspondence?","['algebraic-geometry', 'schemes']"
3267541,"How to write the symbols to ""generalize"" symmetric difference of set?","Given a set of sets $\{A_1,A_2,\dots,A_m\}$ in the power set of some set $S$ . How do we describe the set of elements in $S$ that belongs to exactly $k$ of the $A_i$ 's. I feel like i need to use the set notation to show that the above described set belongs to the event space $\mathscr{F}$ of some sample space $S$ with the assumption that $A_1,\dots,A_m$ are sets in the event space $\mathscr{F}$ .","['elementary-set-theory', 'probability']"
3267589,Prove that $257 + 32\cos 4t > 256 \cos^2t$,"Recently I found a problem in math SE(see here ) that ask on how many roots a polinomial has inside a ring and lead me to the following inequality $$257 + 32\cos 4t > 256 \cos^2 t$$ for all real $t$ . I've got a proof but I have doubt with it. My proof Let $f(t) = 257 + 32 \cos 4t - 256\cos^2 t$ . Note that $f$ is periodic. We will find the stationary points of $f$ . From $f'(t) = 0$ we have $64 \sin 4t - 256 \sin 2t = 0$ . Therefore $\sin 2t(\cos2t - 2) = 0$ . Thus, $\sin 2t = 0$ . From this we have $$f(t_0) = 257 -256\cos^2 2t_0 > 0$$ For all stationary point of $f$ . Is this sufficient to prove the inequality? I'm also looking another proof of this inequality without usage of derivative. Thanks","['alternative-proof', 'trigonometry', 'proof-verification', 'inequality']"
3267631,Dual Lefschetz Operator in Cohomology only depends on Kähler class,"Following Huybrechts book Complex Geometry - An Introduction , the author states in Corollary 3.3.10, that on a compact Kähler manifold $(X,g)$ the Lefschetz operator $L$ and its dual $\Lambda$ give rise to maps in Dolbeault cohomology, i. e. \begin{eqnarray} 
L\colon H^{p,q}(X) &&\rightarrow H^{p+1,q+1}(X)\\
[\alpha] &&\mapsto [\alpha \wedge \omega],
\end{eqnarray} where $\omega$ denotes the associated fundamental form to $g$ ; and \begin{eqnarray} 
\Lambda\colon H^{p,q}(X) &&\rightarrow H^{p-1,q-1}(X).
\end{eqnarray} For sure $L$ only depends on the Kähler class $[\omega] \in H^{1,1}(X)$ . My question is: Why does $\Lambda$ only depend on the Kähler class and not on the choosen metric $g$ ?","['complex-geometry', 'algebraic-geometry', 'kahler-manifolds']"
3267636,Drawing a pair of pants using python,"I am trying to draw a helicoidale trajectory on a pair of pants and to do this I need a parametric equation of the surface. Then I will compose $(\cos(t), \sin(t))$ with the parametrized equation. Thus, I am trying to find the equation of a pair of pants.
I found this: https://www.quora.com/What-is-the-mathematical-expression-which-when-plotted-looks-like-a-pair-of-pants The idea is well thought but I don't have really good results while drawing it... Q: Do someone have any idea of the equation of a pair of pants ? Thank you.","['parametric', 'surfaces', 'geometry']"
3267684,"Find a monotone increasing nonnegative function such that $f'(x)^2 \ge \alpha f(x)f''(x),\alpha>1$","Can we construct a function that is monotone increasing and nonnegative, such that $f'(x)^2 \ge \alpha f(x)f''(x)$ for each $x\in \mathbb R$ , where $\alpha$ is greater than $1$ . If not, how can we give a proof? Note: we say $f(x)$ is monotone increasing, iff $f(x)<f(y)$ for all $x<y$ . I have tried a lot of examples but havn't found a solution. For example, consider $f(x)=b\exp(ax)$ , then $f'(x)^2=f(x)f''(x)=b^2a^2\exp(ax)$ , so the constraint "" $\alpha$ is greater than 1"" is not true.","['calculus', 'functions']"
3267739,"If $x^3$ is a square, is $x$ a square?","Very simple question here, which I feel like I should be able to answer but am struggling with. Let $k$ be a finite field, and let $x\in k^\times$ . Is it true that $$x^3\in\left(k^\times\right)^2 \Longleftrightarrow x\in\left(k^\times\right)^2?$$","['number-theory', 'finite-fields', 'modular-arithmetic']"
3267775,"Closure of $\left\{\frac{\tan{n}}{n} | \, n \in \mathbb{N}\right\}$","I tried searching mathematical literature but I was unable to come across anything apart from the non-convergence of the sequence. Simply put: Define $\displaystyle A =
\left.\left\{\frac{\tan\left(n\right)}{n}\,\right\vert\,
n \in \mathbb{N}\right\}.\quad$ Is $\overline{A} = \mathbb{R}$ ?.","['general-topology', 'real-analysis']"
3267790,Show $\mathbb{N}^{\mathbb{N}}$ with lexicographic ordering has the least upper bound property (any nonempty bounded subset has a supremum).,"I need to use this statement in a paper.  I believe I've proved it, but I would prefer to simply cite it since the proof is unrelated to the rest of the paper and distracts from the main focus of the section.  I can find a lot of references to the fact that an infinite product of well-orderings is not necessarily a well-ordering, but finding this fact seems more difficult. As a secondary matter, here's my proof: Suppose $$\mathcal{S}:=\bigcup_{\alpha\in A} (s_1^\alpha, s_2^\alpha,\ldots)$$ is any nonempty subset of $\mathbb{N}^{\mathbb{N}}$ , with $(t_1,t_2,\ldots)$ an upper bound of $\mathcal{S}$ .  Note that $(t_1+1,0,\ldots)$ is also an upper bound of $\mathcal{S}$ . Thus the set $\mathcal{T}_1$ of upper bounds of $\mathcal{S}$ that are zero after the first coordinate is nonempty. Similarly we define $\mathcal{T}_k$ to be the set of upper bounds of $\mathcal{S}$ that are zero after the $k$ th coordinate.  As $\mathcal{T}_k\supseteq \mathcal{T}_j$ whenever $k>j$ , we then have $\mathcal{T}_k\not = \varnothing$ for all $k\geq 1$ . Beginning with any element of $\mathcal{T}_k$ , there are only finitely many elements in $\mathcal{T}_k$ lexicographically below it.  Thus each $\mathcal{T}_k$ has a minimal element $(t_1^k, t_2^k, \ldots)$ . Note that $(t_1^k,t_2^k,\ldots)$ is identical to $(t_1^{k+1},t_2^{k+1},\ldots)$ in the first $k-1$ coordinates, since $(t_1^{k+1},t_2^{k+1},\ldots, t_k^{k+1}+1,0,\ldots)$ is an element of $\mathcal{T}_k$ , which can't be lower than $(t_1^k,t_2^k,\ldots)$ .  Similarly $(t_1^k,t_2^k,\ldots)$ is also an element of $\mathcal{T}_{k+1}$ and so can't be lower than $(t_1^{k+1},t_2^{k+1},\ldots)$ .  So let $r_j:=t_j^{j+1}$ be the eventual value in the $j$ th coordinate. We will now show $(r_1,r_2,\ldots)$ is the least upper bound for $\mathcal{S}$ . If $(r_1,r_2,\ldots)$ was not an upper bound for $\mathcal{S}$ , then there is $\alpha\in A$ with $(s_1^\alpha,s_2^\alpha,\ldots) > (r_1,r_2,\ldots)$ .  Suppose $m$ is the first index at which $s_m^\alpha\not = r_m$ , in which case $s_m^\alpha>r_m$ by definition of lexicographic order.  But then $$(s_1^\alpha,s_2^\alpha,\ldots)> (r_1,r_2,\ldots,r_m,t_{m+1}^{m+1},0,\ldots) = (t_1^{m+1},t_2^{m+1},\ldots),$$ contradicting that the latter was an upper bound for $\mathcal{S}$ .  So $(r_1,r_2,\ldots)$ is an upper bound for $\mathcal{S}$ . On the other hand, if there were $(q_1,q_2,\ldots) <(r_1,r_2,\ldots)$ with $(q_1,q_2,\ldots)$ also an upper bound for $\mathcal{S}$ , then let $m$ again be the first index where $(q_1,q_2,\ldots)$ and $(r_1,r_2,\ldots)$ differ, so that $q_m<r_m$ .  Then $(q_1,q_2,\ldots,q_m,q_{m+1}+1,0,\ldots)\in \mathcal{T}_{m+1}$ , which means we would have chosen $r_m \leq q_m$ .  So $(r_1,r_2,\ldots)$ is the supremum of $\mathcal{S}$ .  As $\mathcal{S}\not = \varnothing$ was arbitrary, the lexicographic ordering on $\mathbb{N}^{\mathbb{N}}$ has the least upper bound property.","['elementary-set-theory', 'order-theory', 'infinite-product']"
3267805,Local homeomorphism between $\mathbb{R}^2$ and the space of real $2\times2$ matrices of rank one and norm one,"Let $\mathcal{M}$ denote the space of all real $2\times 2$ matrices,
  equipped with the norm $||A||=\sqrt{\mbox{tr}(A^TA)}$ , for $A\in\mathcal{M}$ (here $A^T$ denotes the transpose of the matrix $A$ and for any $2\times 2$ real matrix $B$ , $\mbox{tr}(B)$ denotes its
  trace). Consider the map $F$ from $\mathbb{R}^2$ to $\mathcal{M}$ given by the formula, for any $(s,t)\in\mathbb{R}^2$ : $$F(s,t) =
 \frac{1}{2}\cdot\begin{vmatrix}\cos(t)+\cos(s)&&\sin(t)+\sin(s)\\-\sin(t)+\sin(s)&&\cos(t)-\cos(s)\end{vmatrix}.$$ Denote by $\mathcal{N}\subset\mathcal{M}$ the space of all real $2\times2$ matrices of rank one and norm one. Prove that the image of the map $F$ is the space $\mathcal{N}$ and
  that the map $F$ is a local homeomorphism to its image (the latter
  with the induced topology). My attempt is as follows. Show that $\mbox{Im}(F)=\mathcal{N}$ means to show that $\mbox{Im}(F)\subseteq\mathcal{N}$ and $\mathcal{N}\subseteq\mbox{Im}(F)$ . For arbitrary tuple $(s,t)$ consider $$A = \frac{1}{2}\cdot\begin{vmatrix}\cos(t)+\cos(s)&&\sin(t)+\sin(s)\\-\sin(t)+\sin(s)&&\cos(t)-\cos(s)\end{vmatrix}, ~A\in\mbox{Im}(F).$$ Note that $\det(A)=0$ , therefore rows are linearly dependent and $\dim\mbox{Ker}(A)=1$ ( $\dim\mbox{Ker}(A)\neq2$ since $A$ isn't identically zero), so $\mbox{rk}(A)=1$ follows from the rank-nullity theorem. One can also check directly that $||A||=\sqrt{\mbox{tr}(A^TA)}=1$ , so we have proved that $\mbox{Im}(F)\subseteq\mathcal{N}$ . How can we show another inclusion -- that any $2\times2$ real matrix with rank one and norm one is apparently of that form? Show that $F$ is a local homeomorphism to $\mbox{Im}(F)$ . By definition, homeomorphism is a continuous bijection such that the inverse is also continuous. Here the real issues in my understanding begin. We can show that $F$ is onto by proving that $\mathcal{N}\subseteq\mbox{Im}(F)$ which is essentially my question above. However, how can $F$ be one-to-one and has an inverse if $\det(F)=0$ ? This immediately implies that matrix isn't invertible and has a non-empty kernel. I will very appreciate any help. Thanks in advance.","['multivariable-calculus', 'analysis', 'real-analysis']"
3267819,intuition behind tightness of measures,"What is the motivation behind the definition of tightness of probabilty measures (given below)? Wikipedia says: The intuitive idea is that the given collection of measures does not ""escape to infinity"" What does it mean to escape to infinity? Let $(S,\mathcal{S})$ be a measure space, where $\mathcal{S}$ is the associated Borel $\sigma$ -algebra. Let $\mathcal{M}_{1}(S)$ denote the space of probability measures on $S$ . A subset $\mathcal{R}$ of $\mathcal{M}_{1}(S)$ is said to be $\textit{tight}$ if $\forall \epsilon > 0, \exists$ compact set $K_{\epsilon}$ such that $\mu(S-K_{\epsilon}) < \epsilon, \forall \mu \in \mathcal{R}$","['measure-theory', 'probability-theory', 'real-analysis']"
3267849,"Positive integral solutions to $\frac{m(m+5)}{n(n+5)}=p^2$, where $p$ is prime.","Find all $(m,n)$ positive integers such that $\frac {m(m+5)}{n(n+5)}= p^2$ such that $p$ is a prime number. I tried a lot but could not find a way to start, i cannot proceed with mod bashing please help!","['number-theory', 'elementary-number-theory', 'diophantine-equations', 'algebra-precalculus', 'prime-numbers']"
3267976,"Finding extrema, non-critical points, and saddle points given a contour plot","I'm trying to interpret the contour plot as like a mountain, where all the segregated areas are plains that are higher when it proceeds inwards. What is the significance of the numbers on x-axis and y-axis, and wouldn't the points that are most centered be maximums? $\hskip 12 in$","['multivariable-calculus', 'graphing-functions']"
3268114,Average product of the digits in a car's licence plate,"A car's licence plate  is on the form $$\underbrace{A...A}_{k\,\text{letters}} \quad
  \underbrace{19\ldots9}_{n\,\text{digits}}$$ What is the average product of the digits in a car number with $n$ digits? Note: the digits in a licence plate never starts with a leading $0$ . I was thinking that the product of every number containing a $0$ is $0$ . And there are $9 \cdot 10^{n-1}$ digits in total, where $9^n$ does not contain a single zero. However, I am unsure if the average product of these numbers is simply $(4.5)^{n}$ . Leading to what I suspect is the final answer $$ \frac{(4.5)^n}{9 (10^{n-1} - 9^{n-1})} $$ Is this correct or is there something faulty with my logic?",['discrete-mathematics']
3268125,"Prove $f(a)^2\sin(2a)=f(b)^2\sin(2b)$ for every closed curve given by $(f(t)\cos(t),f(t)\sin(t))$","I stumbled upon this question recently, and actually managed to solve it. But, if to be honest - I don't like my solution. It feels too long, not very smart, and it is divided to cases (which is very unpleasant to me). I was wondering if there was a smarter solution to the problem; That's why I came here. The Question : Let $\gamma\subset\mathbb{R}^2$ be a closed, simple and piecewise-smooth planar curve, and let $f:\Bbb R\to \Bbb R$ be a differentiable function. Given $a,b\in\Bbb R$ , the parametrization of $\gamma$ is given by: $$\gamma(t)=(f(t)\cos(t),f(t)\sin(t))\\ t\in[a,b]$$ Prove the following equality: $$f(a)^2\sin(2a)=f(b)^2\sin(2b)$$ My Solution : Let $k_1,k_2\in\Bbb Z$ . We know that $\gamma$ is closed. Thus: $$
\left\{
\begin{aligned}
f(a)\cos(a) &= f(b)\cos(b)\\
f(a)\sin(a) &= f(b)\sin(b)\\
\end{aligned}
\right.
$$ Case 1 : $f(a)=0$ . If $f(a)=0$ , then we get from the system of equations that $f(b)=0$ too (since $\sin$ and $\cos$ are never $0$ for the same value), proving the desired equality. Case 2 : $a$ can be given by $a=\pi k_1$ . Thus: $$
\left\{
\begin{aligned}
f(a)(-1)^{k_1} &= f(b)\cos(b)\\
0 &= f(b)\sin(b)\\
\end{aligned}
\right.
$$ Assuming $f(b)\neq0$ , we'll get (according to the second equation) that $\sin(b)=0$ . In other words, $b$ can also be given by $b=\pi k_2$ . Therefore, $\sin(2a)=\sin(2b)=0$ , which proves the desired equality. Case 3 : $a$ can be given by $a=\frac \pi 2+\pi k_1$ . Thus: $$
\left\{
\begin{aligned}
0 &= f(b)\cos(b)\\
f(a)(-1)^{k_1} &= f(b)\sin(b)\\
\end{aligned}
\right.
$$ This case is very similar to the previous one: we'll assume again that $f(b)\neq0$ , and then we'll get from the first equation that $b$ can be given by $b=\frac \pi 2+\pi k_2$ , implying again that $\sin(2a)=\sin(2b)=0$ , which proves the desired equality. $(*)$ For cases 1,2 and 3, we have symmetry between $a$ and $b$ , of course. Thus, choosing the inital condition on $b$ (rather than on $a$ as we did) won't change the solution. Case 4: All other options: For all the other options, we will get that neither of the elements in the system of equations can be $0$ . Thus, we can divide one equation by the other and get: $$\tan(a)=\tan(b)\implies a=b+\pi k_1$$ Plugging this equality to one of the equations, we will get: $$f(a)(-1)^{k_1}\cos(b)=f(b)\cos(b)$$ And since $\cos(b)\neq0$ : $$f(a)(-1)^{k_1}=f(b)\implies f(a)^2=f(b)^2\tag{1}$$ Also, note that: $$\sin(2a)=\sin(2b+2\pi k_1)=\sin(2b)\tag{2}$$ Multiplying equation $(1)$ by $(2)$ , we will get the desired equation. $\blacksquare$ Thanks!","['multivariable-calculus', 'calculus', 'differential-geometry']"
3268159,In how many ways can one pay 1000 cents using,"The problem asks to determine the number of ways one can pay $1000$ cents using pieces of $10$ cents and $20$ cents. My approach was as follows : The sought number is but the number of couples of naturals $(x,y)$ satisfying $$10x+20y=1000$$ or $$x + 2y = 100$$ This number is the number of way to write $100$ as the sum of an even number and another natural so it's $51$ . I read somewhere that this depends on whether the order of choice of the pieces matters or not (the latter being the case I dealt with) Is my approach correct ? and What about the case where the order matters. Thanks.",['combinatorics']
3268165,How do i compute this differential equation?,"$$ y''(x) - \frac{B^2}{\cosh^2(Bx)}y(x)= Ay(x) $$ I know that can be solved analytically, but what method can I use?","['hyperbolic-functions', 'sturm-liouville', 'ordinary-differential-equations', 'hypergeometric-function']"
3268173,"How many ternary strings (that is, strings made up of 0s, 1s and 2s) of length 5 contain atmost two 0s, at most two 1s and at most two 2s?","There are 3 basic categories here, as there has to be at least one of one number, and two of the other two numbers. So we have: $\text{01122}$ $\text{10022}$ $\text{20011}$ So I take each these and permutate. Which gives me $3 \times 5!$ which is wrong. The answer is $90$ . I know it is wrong because $3 \times 5! > 3^5$ which shouldn't be possible. I can't find any intuitive reason why my answer is wrong. How did I approach it wrong?","['combinatorics', 'discrete-mathematics']"
3268188,Commutativity of a simple diagram,"Problem : Show that a diagram $\cdot\substack{\rightarrow\\[-1em] \leftarrow} \cdot$ commutes if and only if the maps assigned to the two arrows are inverse. I'm wondering how to prove the forward direction of this claim. I'll call the maps and objects $f\colon A \to B$ and $g\colon B \to A$ I can get that $f = fgf$ . Similarly, $g = gfg$ . This seems like it only proves that $fg$ and $gf$ are idempotent, or maybe that $f$ is a fixed point of $fg$ and $g$ is a fixed point for $gf$ , I don't see that it follows that $g$ and $f$ are inverses. The definition of commutative diagram I have is: A diagram in $\mathcal{C}$ commutes if for each pair $p$ , $q$ of dots in $G$ all paths in $G$ from $p$ to $q$ are interpreted as the same map in $\mathcal{C}$ . Am I allowed to use that I have maps $1_A\colon A \to A$ and $1_B\colon B \to B$ since they are objects in a category? I guess in that case we can easily derive the required statement since we then have e.g. $1_A = gf$ , but the examples in my textbook do not use any extra assumptions outside of explicit maps listed in the graph description. If I can't assume that, how can I proceed?","['functions', 'category-theory']"
3268194,"$\exp: \mathfrak{so}(1,n) \rightarrow SO(1,n)$ is surjective","I am looking for a reference where it is proven that the exponential map described above is surjective. Here, I am denoting by $\mathfrak{so}(1,n)$ the Lie Algebra of the group $SO(1,n)$ . So we have that \begin{align}
SO(1,n) & = \Big\{A\in \mathbb{R}^{n\times 1, n\times 1}:AHA^t=H, \det A = 1\Big\} \\
\mathfrak{so}(1,n) & = \Big\{ B\in\mathbb{R}^{n\times1, n\times1}: BH + HB^t = 0\Big\}
\end{align} And also $H = diag(1,-1,-1,...,-1)$ And $\exp$ is the matrix exponential. Now, I know this is true but I'm specifically looking for a book or paper where this is proven.","['lie-algebras', 'reference-request', 'linear-algebra', 'general-relativity', 'lie-groups']"
3268268,Why is the expectation of a trace equal to the trace of the expectation?,Some textbooks use the property $$\mathbb{E}\left[\operatorname{tr}\left(X\right)\right]=\operatorname{tr}\left(\mathbb{E}\left[X\right]\right)$$ But why? I would really appreciate it if someone could prove this.,"['statistics', 'proof-writing', 'linear-algebra']"
3268275,How to show that this multivariable limit exists or not?,"I was a given a problem to solve (if the limit exists): $$ \lim_{(x,y)\to(0,0)} \cos\left(\frac{x^3-y^3}{x^2+y^2}\right) .$$ My Approach: Approaching along the path $y=0$ , yield the limit to be $1$ . Similarly, going along the path $y=mx$ yields the limit to be $1$ . Thus, it seems that if the limit does exist, the limiting value has to be $1$ . To show that it exists, I decided to use the $\epsilon - \delta$ approach (I am unable to think of an algebraic approach). It will be sufficient to check whether the limit: $$ \lim_{(x,y)\to(0,0)} \frac{x^3-y^3}{x^2+y^2}  $$ exists or not and if it does exist it should be equal to $0$ . We know that for some $\epsilon \in \mathbb{R}$ , $$ 0< \left|\frac{x^3-y^3}{x^2+y^2}\right| < \epsilon,$$ we must be able to choose a $\delta$ such that $0<\sqrt{x^2+y^2} < \delta$ for the limit to exist. Now, $$ \left|\frac{x^3-y^3}{x^2+y^2}\right| = \left| \frac{(x-y)(x^2+y^2+xy)}{x^2+y^2} \right| < \frac{|(x-y)||xy|}{x^2+y^2} \leq \frac{|(x-y)|}{2} < |x-y| = \sqrt{x^2+y^2-2xy}.$$ We have 2 cases: Case I: $xy>0$ This will result in , $$ \left|\frac{x^3-y^3}{x^2+y^2}\right| < \sqrt{x^2+y^2}< \epsilon$$ Here $\delta$ can be chosen as $\epsilon$ . Case II: $xy<0$ . This is where I am not able to proceed further. Is there any alternative approach? Or can the case II part be proven?","['limits', 'multivariable-calculus']"
3268293,Expectation of multiplied matrices,"In p.50 of Quadratic forms in random variables: theory and applications by Mathai and Provost (1992) $$\mathbb{E}\left[\mathbf{X}^{\operatorname{T}}A\mathbf{X}\right]=\cdots =\mathbb{E}\left[\operatorname{tr}\left(A\mathbf{X}\mathbf{X}^{\operatorname{T}} \right ) \right ]=\operatorname{tr}\left(A\left(\Sigma+\mathbf{\mu}\mathbf{\mu}^{\operatorname{T}} \right ) \right )$$ where $\mathbf{\mu}=\mathbb{E}\left[\mathbf{X}\right]$ and $\Sigma=\operatorname{cov}\left[\mathbf{X}\right]$ . (The notation has slightly changed but the meaning should be the same.) I am having trouble with the last two steps shown above. I understand that $$\mathbb{E}\left[\operatorname{tr}\left(A\mathbf{X}\mathbf{X}^{\operatorname{T}}\right)\right]=\operatorname{tr}\left(\mathbb{E}\left[A\mathbf{X}\mathbf{X}^{\operatorname{T}}\right]\right)$$ but I am not sure why $$\operatorname{tr\left(\mathbb{E}\left[A\mathbf{X}\mathbf{X}^{\operatorname{T}}\right]\right)}=\operatorname{tr}\left(A\left(\Sigma+\mathbf{\mu}\mathbf{\mu}^{\operatorname{T}}\right)\right)$$ Breaking this down, the above equality is implying that $$\mathbb{E}\left[A\mathbf{X}\mathbf{X}^{\operatorname{T}}\right]=A\left(\Sigma+\mathbf{\mu}\mathbf{\mu}^{\operatorname{T}}\right)$$ I understand that $$\Sigma=\operatorname{cov}\left[\mathbf{X}\right]=\mathbb{E}\left[\mathbf{X}\mathbf{X}^{\operatorname{T}}\right]-\mathbf{\mu}\mathbf{\mu}^{\operatorname{T}}\Leftrightarrow\mathbb{E}\left[\mathbf{X}\mathbf{X}^{\operatorname{T}}\right]=\Sigma+\mathbf{\mu}\mathbf{\mu}^{\operatorname{T}}$$ Then this is implying that $$\mathbb{E}\left[A\mathbf{X}\mathbf{X}^{\operatorname{T}}\right]=A\,\mathbb{E}\left[\mathbf{X}\mathbf{X}^{\operatorname{T}}\right]$$ I do not know why $$\mathbb{E}\left[A\mathbf{X}\mathbf{X}^{\operatorname{T}}\right]=A\,\mathbb{E}\left[\mathbf{X}\mathbf{X}^{\operatorname{T}}\right]$$ I would really appreciate it if anyone can provide a proof for this. Thank you!","['statistics', 'linear-algebra']"
3268295,"The ""natural"" Sophomore's Dream integral: $\int_{0}^{\infty} x^{-x}\ dx$","I have been wondering about this for a while, but with no real luck in figuring it out. The famous ""Sophomore's dream"" identity refers to two similar integrals, one of which is $$\int_{0}^{1} x^{-x}\ dx = \sum_{n=1}^{\infty} n^{-n}$$ which has a pleasing symmetry between integrand and summand. However, I also notice that $x \mapsto x^{-x}$ is a rapidly-converging-to-zero function of $x$ , and hence it seems like it might be more ""natural"" to then wonder about the integral $$\int_{0}^{\infty} x^{-x}\ dx$$ . Numerical integration suggests it is approximately 1.99545596. Yet what I would like to find is some other representation that is not directly an integral, whether it be a series, or even a finite expression using any already-established mathematical functions and/or constants. And it doesn't seem very clear at all how to do this. Obviously, with upper limit $\infty$ , Taylor expansion of the integrand is of no use since it will only ever have finite radius of convergence. The other line of attack that I thus think of is to try and express $x^{-x}$ as a series of some form of decaying functions that are simpler to integrate. We do have that $$x^{-x} = e^{-x \ln x}$$ but this is of no use: it doesn't yield any series in terms of $e^{-x}$ -like terms. We have the interesting substitution $x = e^{W(u)}$ , $dx = \frac{1}{1 + W(u)}\ du$ (equiv. to $u = x \ln x$ ) with the Lambert W-function, which gives $$\int_{0}^{\infty} x^{-x}\ dx = \int_{0}^{\infty} e^{-u} \frac{du}{1 + W(u)}$$ but this doesn't help for series expansions. What is known about this integral?","['integration', 'calculus', 'definite-integrals']"
3268304,Continuity of a differential of a Banach-valued holomorphic map,"Let $U$ be an open set in $\mathbb{C}^{n}$ let $F$ be a Banach space (in my case even a dual Banach space), and let $\varphi:U\to F$ be a holomorphic map. I seem to be able to prove that the differential map $D\varphi:U\times\mathbb{C}^{n}\to F$ defined by $$D\varphi (z,v)= \lim\limits_{t\to 0}\frac{\varphi(z+tv)-\varphi(z)}{t}$$ is holomorphic. Is there a reference for this assertion? I tried to look into some sources on infinite-dimensional holomorphicity and could not find such a statement, but some of those sources are rather complicated, and so it is likely I missed it.","['complex-analysis', 'complex-geometry', 'several-complex-variables', 'reference-request']"
3268344,Equivalent to Tao's Analysis 1 Book for Statistics,"I am looking a book recommendation that is equivalent to Tao's Analysis I for Statistics. Would you share your recommendations? In particular, it would be ideal to find a book that starts with a measure-theoretic probability set-up and takes off from there, published primarily aiming for advanced undergrad or first-year Ph.D. student readers. Note I am not looking for a probability book, but a statistics book. Thanks in advance!","['statistics', 'book-recommendation', 'reference-request']"
3268351,Bounding the size of the inverse of $I+AB$ when $A$ and $B$ are both PSD,"If $A$ and $B$ are both positive semi-definite matrices, is it possible
to show that $$\left\Vert \left(I+AB\right)^{-1}\right\Vert _{2}\leq1$$ where $\left\Vert \cdot\right\Vert _{2}$ is the operator norm?","['positive-semidefinite', 'spectral-norm', 'matrices', 'inverse', 'matrix-norms']"
