question_id,title,body,tags
2138374,Switching summation limits with change of variables,"A very basic question, but I am missing something... Consider the series $\sum_{i=1}^{n}a_{n-i} = a_{n-1}+a_{n-2}+\dots+a_0$, which may therefore equivalently written $\sum_{i=0}^{n-1}a_i$. How does one arrive at the equivalence between the two summation representations by reindexing/change of variables? If we let $k=n-i$, then the lower limit of the sum at $i=1$ corresponds to $k=n-1$ and the upper limit at $i=n$ corresponds to $k=0$, which gives us an empty series $\sum_{k=n-1}^0a_k$.","['algebra-precalculus', 'real-analysis', 'summation']"
2138393,One one function,I came across a question which is as follows : Is the following statements always correct ? 1) If $f'(x) > 0$ for all $x$ in the domain of the function $f(x)$ then $f(x)$ is always one-one  . My attempt to the question: According to me the statement should always be correct since there would be no to $x$ for which the corresponding value of the function will be same . However the answer says it's false . Please explain this .,"['functional-analysis', 'graphing-functions', 'calculus', 'functions']"
2138401,Reference request (famous mathematicians for High School),"Some students of an High School asked me some books from famous mathematicians that they can read (so advanced high school level focused mainly on real-analysis). They were asking things like Cauchy, Fermat... but I think the language would be technical in an akward ancient way for them so that probably will not be suitable. I thought that maybe Riemann dissertation could do but maybe it's too advanced. I then thought Galois, but again the original papers are quite difficult to understand if you don't already have the right picture in your mind. I'm not sure there's effectively a book from an historically famous mathematician that could fit the request. They didn't specifically requested that the argument should be mathematical even if I think they implied this, otherwise I could suggest something of Poincaré which rather philosophical but at least readable. They didin't specify the period (even if I think they might want to already know the name of the writer). In modern period maybe I would suggest Mumford the Indra's Pearls. But I'm quite sure they don't know Mumford... I'm now thinking that maybe some kind of physicist would be better. But they were asking mathematicians. I really don't have a clue of what to suggest. Please help me! Edit. Someone correctly asked me why I'm "" limiting to Mathematicians they've heard of "". I totally agree with who's asking. Old mathematics would be kind of akward I think. The problem is not that "" I'm limiting "", the problem is that "" this is what they asked "". It's something like "" We have seen their theorems, heard a lot about them, we would like to read something written by them "". As pointed out is that probably this request cannot be fulfilled entirely or is not a good idea to fulfill their request. So any suggestion will be take into account. If it was physics Schroedinger ""What is Life"" and some Heisenberg essays would be in order... in mathematics I've no clue if exists something similar... I think maybe Poincaré is the only one...","['reference-request', 'real-analysis', 'soft-question']"
2138417,"$\frac{1}{\sin x}-\frac{1}{x}$ bounded on $[0,\pi/2]$.","Why is $$\frac{1}{\sin x}-\frac{1}{x}$$ bounded when $x\in [0,\pi/2]$. I've come across this fact in Fourier series, but I can't figure out a why this is true. I would appreciate any help.","['calculus', 'analysis']"
2138428,normalizer of two p-Sylow intersection,"Let $N(P_1 \cap P_2)$ be the intersection of 2 p-Sylow, $P_1$ and $P_2$. I have 2 questions (which I put in a single question here because connected, and I tried to prove the last one). First of all, given a group, is the intersection between p-Sylows always the same? (isomorphically) So if for instance I find two 2-Sylows of cardinality 8 whose intersection is a $\mathbb{Z}_2$, do I have that every intersection of every 2-Sylow is isomorphic to $\mathbb{Z}_2$? I had thought that if the action on the set of p-Sylow is double transitive then it's trivial, but is there some weaker criterion? Then I was wondering if given the example above it is always true that $P_1<N(P_1 \cap P_2)$, because my teacher once used this fact, but I am not sure if it is a general property or it worked only in the specific case. I have thought that since the conjugate of $P_1$ by the action of $P_1$ is itself, then the elements of $P_1 \cap P_2$ are bound to go on $P_1$, and so $P_2$ is bound to go on a $P_k$ whose intersection with $P_1$ is again $P_1 \cap P_2$. Would this be enough to prove that we always have $P_1<N(P_1 \cap P_2)$?","['finite-groups', 'abstract-algebra', 'group-theory', 'sylow-theory']"
2138581,Matrix Calculus: Derivative of Vectorized Symmetric Positive Definite Matrix w.r.t. its Vectorized Matrix Logarithm,"Setup: Let $k\in{}\mathbb{N},$ and let $\mathrm{M}_{k,k}(\mathbb{}{R})$ denote the set of $k\times{}k$ matrices over the field of real numbers. Let $X\in{}\mathrm{M}_{k,k}(\mathbb{}{R})$ be a symmetric, positive definite matrix. Then $X$ has $k$ positive eigenvalues $\lambda_{1},\dots{},\lambda_{k}$ with corresponding eigenvectors $v_{1},\dots{},v_{k}$. The eigendecomposition/spectral decomposition of $X$ is: $$X = V\Lambda{}V^{-1} = V\Lambda{}V',$$ where $\Lambda{}=\mathrm{diag}(\lambda_{1},\dots{},\lambda_{k})\in{}\mathrm{M}_{k,k}(\mathbb{}{R})$ is the diagonal matrix with the $k$ eigenvalues on the main diagonal and $V=(v_{1},\dots{},v_{k})\in{}\mathrm{M}_{k,k}(\mathbb{}{R})$ is the matrix whose $k$ columns are the orthonormal eigenvectors. We define the natural matrix logarithm of $X$, denoted $\log{}(X)$, to be
$$\log{}(X)=V\log{}(\Lambda{})V',$$
where $\log{}(\Lambda{})=\mathrm{diag}(\log{}(\lambda_{1}),\dots{},\log{}(\lambda_{k}))\in{}\mathrm{M}_{k,k}(\mathbb{}{R})$. Question: What, if it can be found, is the analytical form of the $[k(k+1)/2] \times{} [k(k+1)/2]$ Jacobian matrix $$\frac{\partial{}\mathrm{vec}(X)}{\partial{}\mathrm{vec}(\log{}(X))'}$$ where $\mathrm{vec}(\cdot{})$ is the half-vectorization operator that stacks the lower triangular part of its square argument matrix. (Background: This is a recurring problem in multivariate statistics when one adopts a ""log-parameterization"" of a covariance or precision matrix, which are both, by definition, symmetric and positive (semi-)definite.)","['matrices', 'logarithms', 'matrix-calculus', 'positive-definite', 'symmetric-matrices']"
2138612,How I find sufficient statistic for Student-t distribution? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question how can I find sufficient statistics for student-t distribution (centred in 0)","['statistics', 'probability-distributions']"
2138631,How often (i.e. asymptotic density) is the reversal of the binary representation of $7n$ is a multiple of $7$?,"If you reverse the binary digits of a multiple of $3$, the result is always a multiple of $3$. The same is not true for $7$, but it does appear to happen more often than $\frac{1}{7}$ of the time. For fun, I'll call a number $n$ such that the reverse of the binary digits of $7n$ represents a multiple of $7$ a ""sevenly"" number. I wrote a simple Python program to compute the frequency of sevenly numbers, and after letting it run for an hour the proportion had been decreasing overall, but not very steadily, and it had yet to fall below $0.25$. I was wondering if someone knew how to determine the asymptotic density of sevenly numbers. My intuition says it should be $\frac{1}{7}$, but the computations I've done seem to suggest it might not. EDIT My original program didn't tell me what number it was on, only the proportion, but I ran it for an hour, so it probably got into the millions. I've changed the program since then to print out the number it's on, too. Here is that code: def brev(n):
    return int(""0b""+(bin(n)[::-1])[:-2],2)

n = 1
sevenlies = 0
while True:
    if brev(7*n)%7 == 0:
        sevenlies += 1
    print(""%d\t%f""%(n,sevenlies/n))
    n += 1","['number-theory', 'binary', 'asymptotics']"
2138634,"Riemann-Stieltjes integral problem: $\int_{a} ^{b} g\, d\beta=\int_{a} ^{b} fg\, d\alpha$","Help, I've been stuck with this for hours, so far I've tried expanding the $\alpha$ integral using the definition of upper and lower integrals U and L but it doesn't seem to be a good way. Let be $\alpha,\ f,\ g\ :[a,b]\to\mathbb{R}$ continous, $\alpha$ non- decreasing and $f(x) \ge 0$. Let be $\beta(x) = \int_a^x f\, d\alpha$. Show $\int_a^b g\ d\beta = \int_a^b gf\, d\alpha$.","['real-analysis', 'analysis']"
2138663,Generalization of Improper Integral,"Suppose a function $f$ is Riemann integrable over any interval $[0,b]$. By definition the improper integral is convergent if there is a real number $I$ such that $$\lim_{b \to \infty}\int_0^b f(x) dx= I := \int_0^\infty f(x)dx.$$ I have shown that if $f$ is nonnegative then this is equivalent for $n \in \mathbb{N}$ to $$\lim_{n \to \infty}\int_0^n f(x) dx = I.$$ Now I would like to know for general $f$ (not just nonnegative) if the following proposition holds. Suppose the improper integral of $f$ over $[0,\infty)$ is convergent. Let $A_n \subset [0, \infty)$ be a nested sequence of compact sets
  such that $A_1 \subset A_2 \subset A_3 \subset ...$ and $\cup_n A_n 
 =[0,\infty)$, and where the Riemann integral is defined on each $A_n$.
  Then $$\lim_{n \to \infty} \int_{A_n}f(x) dx = \int_0^\infty f(x) dx.$$ This question is not about Lebesgue integration.  Thank you for any help you can give me.","['real-analysis', 'riemann-integration', 'calculus', 'improper-integrals', 'integration']"
2138684,How does one show that : $\int_{0}^{1}(\sin^{-1}x \cos^{-1}x)^n\mathrm dx=f(n)?$,"Consider $$\int_{0}^{1}(\sin^{-1}x \cos^{-1}x)^n\mathrm dx=f(n)\tag1$$
  $n\ge0$ Using wolfram integrator, it gives us a closed form for $f(n)$, we managed to identify a pattern as shown below. setting $n=1,2,3,4$ and $5$ We notices the closed from has a pattern that involved binomial coefficents. $$\int_{0}^{1}(\sin^{-1}x \cos^{-1}x)\mathrm dx=2!-1!\cdot{\pi\over 2}$$ $$\int_{0}^{1}(\sin^{-1}x \cos^{-1}x)^2\mathrm dx=4!-3!\cdot{\pi\over 2}-1!\cdot{3\pi^2\over 4}$$ $$\int_{0}^{1}(\sin^{-1}x \cos^{-1}x)^3\mathrm dx=6!-5!\cdot{3\pi\over 2}-4!\cdot{3\pi^2\over 4}+3!\cdot{\pi^3\over 8}$$ $$\int_{0}^{1}(\sin^{-1}x \cos^{-1}x)^4\mathrm dx=8!-7!\cdot{4\pi\over 2}-6!\cdot{6\pi^2\over 4}+5!\cdot{4\pi^3\over 8}+4!\cdot{\pi^4\over 16}$$ $$\int_{0}^{1}(\sin^{-1}x \cos^{-1}x)^5\mathrm dx=10!-9!\cdot{5\pi\over 2}-8!\cdot{10\pi^2\over 4}+7!\cdot{10\pi^3\over 8}+6!\cdot{5\pi^4\over 16}-
5!\cdot{\pi^5\over 32}$$ $$f(6)=12!-11!\cdot{6\pi\over 2}-10!\cdot{15\pi^2\over 4}+9!\cdot{20\pi^3\over 8}+8!\cdot{15\pi^4\over 16}-
7!\cdot{\pi^5\over 32}-6!\cdot{\pi^6\over 64}$$ We generalised $$f(n)=\sum_{k=0}^{n}(-1)^{\lceil {k/2}\rceil}(2n-k)!{n\choose k}\cdot{\pi^k\over2^k}\tag2$$ How does one prove (2)? An attempt: $I$ becomes $$\int_{0}^{1}\left[{\pi\over 2}\cos^{-1}x-(\cos^{-1}x)^2\right]^n\mathrm dx\tag3$$ probably using the binomial theorem to expand and integrate term by term, I guess I am stuck at this point, no sure what to do","['binomial-coefficients', 'calculus', 'integration', 'definite-integrals', 'sequences-and-series']"
2138688,Definition of the space of Hölder continuous functions,"I have a question concerning the definition of the space of Hölder continuous functions $C^{k,\alpha}(\Omega)$, where $\Omega\subset\mathbb{R}^n$ is an open set and $k\in\mathbb{N}$ and $\alpha\in (0,1]$. Often the following definition is used: $f\in C^{k,\alpha}(\Omega)$ if and only if $f\in C^{k}(\Omega)$ such that all its derivatives up to order $k$ are bounded functions and the $k-th$ order derivatives are Hölder continuous. I am wondering why only $D^{\beta}f:U\rightarrow \mathbb{R}$ with $\vert \beta \vert=k$ has to be Hölder continuous? Does it maybe follow that $f$ and its derivatives up to order $k-1$ have to be Hölder continuous as well? Otherwise the space of Hölder continuous functions would contain functions which are not Hölder continuous, which sounds very awkward to me. Best wishes","['real-analysis', 'partial-differential-equations', 'functional-analysis', 'continuity', 'holder-spaces']"
2138692,Proving the kernel is a normal subgroup.,"My professor proved that the kernel is a normal subgroup under a homomorphism f by saying. Let $h\in H$ 
by applying f to it
 $f(ghg^{-1})=f(g)f(h)f(g)^{-1}=e $ My question is how is this a proof that the kernel is normal. What is the reason we apply f to it ? By applying f dont we just prove that $f(ghg^{-1})$ is normal ?","['abstract-algebra', 'group-theory']"
2138693,How show that this set is closed?,"Question : Let $(X,M, \mu)$ a finite measure space and define a metric space $M'$ as follows:
for $A,B \in M$, define: $d(A,B) = \mu(A\triangle B)$. The space $M'$ is defined as all sets in $M$ where sets $A$ and $B$ are identified if $\mu(A\triangle B) = 0$. Let $\{v_k\}$ be a sequence of measures on the finite measure space $(X, M, \mu)$ such
that $\bullet v_k(X) < \infty$ for each $k$, $\bullet $the limit exists and is finite for each $E\in M$
$v(E) := \displaystyle\lim_{k \to\infty}
v_k(E)$, $\bullet v_k << \mu$ for each $k$. a)Prove that each $v_k$ is continuous on the metric space $(M', d)$. b)For each $\epsilon > 0$ let $F_{i,j}:=\{E \in M; |v_i(E) - v_j(E)| \leq \displaystyle\frac{\epsilon}{3}\}$ $i, j = 1, 2, ... $ and $F_p:= \displaystyle\bigcap_{i, j \geq p} F_{i, j}$  , $p = 1, 2,...$ Prove that $F_p$ is a closed set in $(M', d)$. The item a) is obtained from the theorem of Radon-Nikodym: For each $k$ there is a $f_k \in L^1(\mu)$ such that $v_k(E) = \displaystyle\int_{E} f_k d\mu$, hence $v_k$ is continuous. This is right? But for th item (b) i have not any idea. Any tip? Note that $F_p \subset F_q, q\geq p$; moreover if $A \subset M$ is limit of sequence $\{E_j\}$, $E_j \in F_p$, then $A \in F_q$ for some $q\geq p$.","['metric-spaces', 'lebesgue-integral', 'measure-theory']"
2138760,"Prove that a maximal planar (""triangulated planar"") graph has one of the three properties","Edit: A maximimal planar graph is a planar graph in which every face, including the unbounded face, is bordered by exactly three edges. Wikipedia . Prove that a maximal planar (sometimes called triangulated planar) graph has one one of the following properties A node of degree 1, 2, 3, or 4. Two adjacent nodes of degree five. A node of degree five adjacent to a node of degree six. To satisfy the first condition, I observe that from the most basic maximal planar graph is a graph of three nodes where each node is of degree 2 (the triangle graph). In order to maintain triangularity within the graph, if a new node is added, then three new edges must also be added to the graph. This means that when there are four nodes, an edge is drawn to every existing node, so every node is of degree 3. Therefore, when there is a fifth node added, there must exist two nodes of degree 4. Then if another node is added, $n_k$, and an edge connects $n_k$ and a node which previously had degree 4, in order to protect the triangularity of the unbounded face, an edge must also connect $n_k$ to a different node which formerly had degree 4. This satisfies the second condition. I use the discharge method to prove the second and third conditions in a more general sense, but I don't really see what the relationship between a positive charge and planar triangularity is. I also suspect that my proof for the first condition suffers from build-up error, but I don't know how I can approach the problem from in a more general sense.","['graph-theory', 'planar-graphs', 'discrete-mathematics']"
2138771,Gambler's Ruin - Probability of Losing in t Steps,"I would be surprised if this hasn't been asked before, but I cannot find it anywhere. Suppose we're given an instance of the gambler's ruin problem where the gambler starts off with $i$ dollars and at every step she wins 1 dollar with probability $p$ and loses a dollar with probability $q = 1 - p$. The gambler stops when she has lost all her money, or when she has $n$ dollars. I am interested in the probability that the gambler loses in $t$ steps. I know how to find the expected number of steps before reaching either absorbing state, and how to solve the probability that she loses before winning $n$ dollars, but this one is eluding me. Let $P_{i, t}$ be the probability that the gambler goes broke in $t$ steps given that she started with $i$ dollars. I have set up the recurrence:
$$ P_{i, t} = qP_{i-1, t-1} + pP_{i+1, t-1}$$
and we know that $P_{0, j} = 1$ and $P_{n, j} = 0$for all $j$, and $P_{i, 0} = 0$ for all $i > 0$. I'm struggling to solve this two dimensional recurrence. If it turns out to be too hard to give closed form solutions for this, can we give tighter bounds than just the probability that the gambler ever loses?","['gambling', 'random-walk', 'markov-chains', 'probability', 'martingales']"
2138866,$\int_{0}^{\frac{\pi}{4}}\frac{\tan^2 x}{1+x^2}\text{d}x$ on 2015 MIT Integration Bee,"So one of the question on the MIT Integration Bee has baffled me all day today $$\int_{0}^{\frac{\pi}{4}}\frac{\tan^2 x}{1+x^2}\text{d}x$$ I have tried a variety of things to do this, starting with Integration By Parts Part 1 $$\frac{\tan x-x}{1+x^2}\bigg\rvert_{0}^{\frac{\pi}{4}}-\int_{0}^{\frac{\pi}{4}}\frac{-2x(\tan x -x)}{\left (1+x^2 \right )^2}\text{d}x$$ which that second integral is not promising, so then we try Integration By Parts Part 2 $$\tan^{-1} x\tan^2 x\bigg\rvert_{0}^{\frac{\pi}{4}}-\int_{0}^{\frac{\pi}{4}}2\tan^{-1} x\tan x\sec^2 x\text{d}x$$ which also does not seem promising Trig Substitution $x=\tan\theta$ which results $$\int_{0}^{\tan^{-1}\frac{\pi}{4}}\tan^2 \left (\tan\theta\right )\text{d}\theta$$ which I think too simple to do anything with (which may or may not be a valid reason for stopping here) I had some ideas following this like power reducing $\tan^2 x=\frac{1-\cos 2x}{1+\cos 2x}$ which didn't spawn any new ideas. Then I thought maybe something could be done with differentiation under the integral but I could not figure out how to incorporate that. I also considered something with symmetry somehow which availed no results. I'm also fairly certain no indefinite integral exists. Now the answer MIT gave was $\frac{1}{3}$ but wolfram alpha gave $\approx$ .156503. Note The integral I gave was a simplified version of the original here is the original in case someone can do something with it $$\int_{0}^{\frac{\pi}{4}}\frac{1-x^2+x^4-x^6...}{\cos^2 x+\cos^4 x+\cos^6 x...}\text{d}x$$ My simplification is verifiably correct, I'd prefer no complex analysis and this is from this Youtube Video close to the end .","['contest-math', 'integration', 'definite-integrals', 'calculus']"
2138897,When do measurable functions descend?,"Suppose that $\pi : (X, \Sigma_X) \to (Y, \Sigma_Y)$ is a measurable surjection between two measurable spaces. Let $F = \pi^{-1} (\Sigma_Y)$ be the sub $\sigma$ algebra of $\Sigma_X$. Let $f : X \to (\mathbb{R}, B)$ be a measurable function to the reals with the Borel sigma algebra (or to any Hausdorff space with the Borel sigma algebra). Question: Is $f$ $F$ measurable iff there is a measurable function $g : Y \to \mathbb{R}$ so that $f = g \circ \pi$? I'm fairly certain I can prove this, and I can provide my argument if someone wants to see it. However, because these are all tricky measure theory technicalities, I'm asking here to be sure. Maybe someone knows a counter example off the top of their head. Rmk: The surjectivity of $\pi$ is necessary, a counter example is the inclusion of a non-measurable set $X$ into $Y = \mathbb{R}$, with $f = 1_{X}$ and the induced sigma algebra on $X$. Edit: Nevermind, I was being silly. $1_Y$ also pulls back to $1_X$ -- no uniqueness in this case. :)",['measure-theory']
2138915,Improper integral of $\frac{\log\left(\sqrt{x^2+a^2}\right)}{x^2+b^2}$,"Show that $$\int_{-\infty}^\infty \frac{\log\left(\sqrt{x^2+a^2}\right)}{x^2+b^2}\,dx = \frac{\pi}{b}\log\left(a+b\right)$$ for $a,b>0\in\mathbb{R}$. I stumbled on this answer empirically, but I'm not sure how to solve it directly.","['branch-points', 'complex-analysis', 'integration', 'contour-integration', 'branch-cuts']"
2138945,"For every pair of distinct primes $p_1$ and $p_2$, there are $z$ such that $p_1 + z$ is prime but $p_2 + z$ is not","Just a curiosity that occurred randomly.
Is there a proof of the following: For every two distinct primes $p_1$ and $p_2$, there exist an infinity of positive integers $z$ such that $p_1 + z$ is prime, but $p_2 + z$ is not prime. It just ""feels"" true, but I don't know enough number theory to get an idea on how to prove this.  I can't even guarantee that one such $z$ always exists.","['number-theory', 'prime-gaps', 'prime-numbers']"
2138965,Showing that the Lebesgue-Stieltjes measure is absolutely continuous with respect to Lebesgue measure (and one more thing).,"I aim to show the following result: Let $f:\mathbb{R}\to\mathbb{R}$ be a nondecreasing, continuously differentiable function and let $\lambda_f$ be the corresponding Lebesgue-Stieltjes measure generated by $f$. Prove: (a) $\lambda_f <<\lambda$ (that is, $\lambda_f$ is absolutely continuous with respect to Lebesgue-measure $\lambda$); (b) $\frac{d\lambda_f}{d\lambda}=f'$ (that is, $f'$ is the Radon-Nikodym derivative of $\lambda_f$). -#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#- For item (a), I tried consider the case when all the things happen in a compact interval $[a,b]$ (the general case easily follow from this one). So $f$ is uniformly continuous in $[a,b]$. Let $E\subset[a,b]$ with $\lambda(E)=0$ and let $\epsilon>0$ arbitrary. We want to find a cover $\{(a_k, b_k]\}_{k=1}^\infty$ of $E$ such that $$\sum_{k=1}^\infty [f(b_k)-f(a_k)]<\epsilon.\tag{1}$$
If we find $\{(a_k, b_k]\}_{k=1}^\infty$ sufficiently fine so that $f(b_k)-f(a_k)<\epsilon/2^k$ for all $k\in \mathbb{N}$, then (1) follows. Here we have a problem: $\epsilon/2^k$ depends on $k$. Since $\lambda(E)=0$, there exists a cover $\{(a_k, b_k]\}_{k=1}^\infty$ of $E$ such that $$\sum_{k=1}^\infty(b_k-a_k) < \frac{\epsilon}{\star},$$ where $\star\in\mathbb{R}^+$ I can control. But the number $\star$ cannot depends on $k$. Now, what should I do? Right now I will try to use the Mean Value Theorem in each interval and see what happen. -#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#- For item (b) (considering that item (a) is valid), the things become complicated to write. I just solve a half of this item. My attempt was to show that $\lambda_f(E)=\int_Ef'd\lambda$ for all $E$ measurable, because from Radon-Nikodym theorem, the derivative is $\lambda$-a.e. unique. Since $f'\geq0$ ($f$ is nondecreasing), if we set $$\mathcal{A} = \left\{\sum_{k=1}^\infty[f(b_k)-f(a_k)]:E\subset\bigcup_{k=1}^\infty(a_k, b_k]\right\}=\left\{\sum_{k=1}^\infty f'(c_k)(b_k-a_k):E\subset\bigcup_{k=1}^\infty(a_k, b_k]\right\}$$ (we used the Mean Value Theorem) and $$\mathcal{B}=\left\{\int_E sd\lambda:0\leq s\leq f'~\text{is simple}\right\}=$$ $$=\sup\left\{\sum_{k=1}^n\alpha_k\lambda(A_k):E =\sum_{k=1}^n A_i~\text{and}~0\leq\alpha_k\leq f', \forall k\in A_k, k\in\{1,2,...,n\}\right\},$$ from the definition we get $$\lambda_f(E) = \inf\mathcal{A}~~~~~~~~\text{and}~~~~~~~~\int_E f' d\lambda=\sup\mathcal{B}.$$ We need to prove that $\inf\mathcal{A}=\sup\mathcal{B}$. Let $x\in \mathcal{A}$ and $y\in\mathcal{B}$ arbitraries. Then there exists a cover $\{(a_k, b_k]\}_{k=1}^\infty$ and a partition $\{A_r\}_{r=1}^n$ for $E$ and numbers $\alpha_1, ..., \alpha_n \geq 0$ with $\alpha_r\leq f'$ in $A_r$, $r=1, ..., n$, such that $$x = \sum_{k=1}^\infty f'(c_k)(b_k-a_k)~~~~~~~~\text{and}~~~~~~~~y=\sum_{r=1}^n\alpha_r\lambda(A_r).$$
We can assume that the family $\{(a_k, b_k]\}_{k=1}^\infty$ is disjoint (in fact, we can split it into more sets and split the expression of $x$ into more parcels). So each set $A_r$ in contained in some of the sets $\{(a_k, b_k]\}_{k=1}^\infty$. Call $I_r\subset\mathbb{N}$ the minimal set of indices such that $A_r\subset \sum_{k\in I_r}(a_k,b_k].$ Since $\{(a_k, b_k]\}_{k=1}^\infty$ is disjoint, $\{I_r\}_{r=1}^n$ is a partition of $\mathbb{N}$. Then $\alpha_r\leq f'$ in $A_r$ and $\lambda(A_r)\leq\sum_{k\in I_r}(b_k-a_k)$, what implies $\alpha_r\lambda(A_r)\leq\sum_{k\in I_r} f'(c_k)(b_k-a_k)$. From this we concludes $$y=\sum_{r=1}^n\alpha_r\lambda(A_r)\leq\sum_{r=1}^n\sum_{k\in I_r} f'(c_k)(b_k-a_k) = \sum_{k=1}^\infty f'(c_k)(b_k-a_k) = x.$$ Since $x, y$ are arbitrary, we have $\inf\mathcal{A}\geq\sup\mathcal{B}$. How can I proceed to show that $\inf\mathcal{A}\leq\sup\mathcal{B}$? Any hint will be really appreciated.","['real-analysis', 'lebesgue-integral', 'measure-theory', 'lebesgue-measure']"
2138973,Find a matrix with a given null space,"I’m trying to solve the following question: Find a $3\times 3$ matrix $A$ such that $\operatorname{Null}(A)=\operatorname{span}\left\lbrace \begin{bmatrix}1 \\1 \\1 \\\end{bmatrix},\begin{bmatrix}1\\2\\3\end{bmatrix}\right\rbrace$ . My attempt was this. Let $A=\begin{bmatrix}a_{11}&a_{12}&a_{13}\\a_{21}&a_{22}&a_{23}\\a_{31}&a_{32}&a_{33} \end{bmatrix}$ . Then I solved $A\begin{bmatrix}1 \\1 \\1 \\\end{bmatrix}=\begin{bmatrix}0\\0\\0\end{bmatrix}$ and $A\begin{bmatrix}1\\2\\3\end{bmatrix}=\begin{bmatrix}0\\0\\0\end{bmatrix}$ which gave me the following conditions $a_{12}+2a_{13}$ =0 , $a_{22}+2a_{23}=0$ and $a_{32}+2a_{33}=0$ . Solving these I can get a matrix that look like this $A=\begin{bmatrix}1&-2&1\\1&-2&1\\1&-2&1\\\end{bmatrix}$ . Is my approach correct? I’m asking because I wanted to check my answer and calculated the null space for the matrix I found above and the null space was spanned by $\left\lbrace\begin{bmatrix}-1\\0\\1\end{bmatrix},\begin{bmatrix}2\\1\\0\end{bmatrix}\right\rbrace$ .","['matrices', 'eigenvalues-eigenvectors', 'matrix-rank', 'linear-algebra']"
2138995,Find the sum of the infinite series: $ 1 + \frac{1+2}{2!} + \frac{1+2+2^2}{3!} +\frac{1+2+2^2+2^3}{4!}+...$,Find the sum of the infinite series $$ 1 + \frac{1+2}{2!} + \frac{1+2+2^2}{3!} +\frac{1+2+2^2+2^3}{4!}+... ....$$ What I have done let $$ S = \underbrace{\frac{1}{1!}}_{\text{1st Term}} + \underbrace{\frac{1+2}{2!}}_{\text{2nd Term}}  +  \underbrace{\frac{1+2+2^2}{3!}}_{\text{3rd Term}}  + \underbrace{\frac{1+2+2^2+2^3}{4!}}_{\text{4th Term}}   +... ....$$ I can see the denominator can be written as such but I'm not sure how to manipulate the numerator? $$ S = \sum^{\infty}_{n=1} \frac{\text{?}}{n!} $$,['sequences-and-series']
2138997,Prove that $\sin\frac{\pi}n·\sin\frac{2\pi}n···\sin\frac{(n-1)\pi}n=\frac{n}{2^{n-1}}$ [duplicate],"This question already has answers here : Proving $\prod_k \sin \pi k / n = n / 2^{n-1}$ (2 answers) Closed 7 years ago . How to prove that $$
\sin\dfrac{\pi}n·\sin\dfrac{2\pi}n···\sin\dfrac{(n-1)\pi}n=\dfrac{n}{2^{n-1}}
$$ using the roots of $(z+1)^n-1=0$? My rough idea is to solve  $(z+1)^n-1=0$ and use De Moivre's Theorem to find the product of roots to prove the equality.",['complex-analysis']
2139026,Nowhere differentiable Fourier transform,Is there any $L_1$ function such that its fourier transform is in $L_1$ and the fourier transform is nowhere differentiable? Or every such Fourier transform must be differentiable a.e.?,"['derivatives', 'harmonic-analysis', 'fourier-analysis']"
2139051,How to solve system of equations containing trigonometry (in radians)?,"I am researching about the brachistochrone curve, which is the inverse of the cycloid. The equation for the cycloid is :
\begin{cases} x = b(t - \sin\;t) \\ y = b(1 - \cos\;t)  \end{cases} Based on this, I graphed the brachistochrone with the following equation:
\begin{cases} x = b(t - \sin\;t) \\ y = b(-1 - \cos\;t)  \end{cases} However, when I tried to plot a point and algebraically solve for the 2 variables, with $t$ being measured in radians, I wasn't able to solve it and I need help. For example, I was wondering how to find the $b$ and $t$ value algebraically that  would satisfy an x value of $20$ and a y value of $-5$. Here is a diagram of the situation. tl;dr  How do you solve this algebraically:
\begin{cases} b(t - \sin\;t) = 20 \\ b(\cos\;t - 1) = -5  \end{cases} Any help would be greatly appreciated!","['circles', 'parametric', 'cycloid', 'trigonometry']"
2139054,To prove $\frac{1}{\sin 10^\circ}-\frac{\sqrt 3}{\cos 10^\circ}=4$ [duplicate],This question already has answers here : Solving $E=\frac{1}{\sin10^\circ}-\frac{\sqrt3}{\cos10^\circ}$ (3 answers) Closed 7 years ago . To prove: $$\frac{1}{\sin 10^\circ}-\frac{\sqrt 3}{\cos 10^\circ}=4$$ I tried taking lcm but could not get to anything.,['trigonometry']
2139070,"Combinatorics looks incomprehensible, is it that I lack ""mathematical maturity"" and what should I do?","I think this soft question may be marked ""opinion-based"" or ""off-topic"", but I really do not know where else to get help. So please read my question before it's closed, I am really desperately in need of help... Thanks in advance for all people paying attention to this question! Background I am a high school student who has participated in mathematical olympiads, where there are tons of tough combinatorics problems. I already know the basic counting techniques (binomial coefficients, inclusion-exclusion principle, etc.), some notions and theorems in graph theory (trees, Ramsey numbers, etc.), yet I do not know much beyond the definitions. Accordingly, I plan to (self-)studying this subject systematically. (I actually study for fun, not for better performance in olympiads.) Context A few days ago I stumbled upon the book A Course in Combinatorics and started working through this book with dilligence. It was not long before I found the problems way too hard . I am just halfway in chapter 2, and there are three problems (out of a dozen or so) that I cannot solve even after I read the hints and literally thinking for hours. I am unsure about whether I should pursue reading this book but a more important question arises: Why do I find the problems too hard? Is it that I lack the so-called ""mathematical maturity"" required for an undergraduate text like that, or that I am not gifted enough, or something else? I am not sure whether I do have the slightest degree of mathematical maturity, but I have been reading mathematics texts for at least half a year. I have worked through the first seven chapters of baby Rudin (and solved all the exercises, which would look ""easy"" to me compared to the problems in that combinatorics book), and I am learning linear algebra from Hoffman & Kunze and abstract algebra from Herstein, and having fun reading the three volumes Analysis from Amann & Escher. Then there are other books like Folland's Real Analysis or Artin's Algebra , which I have read only several chapters. Of all the books in mathematics I have read about, the problems of this book are the hardest. However, no one has ever mentioned that the book has tough problems. (Maybe it is just me?) By the way, I posted a problem that I literally thought for an entire afternoon here . Questions All in all, my question boils down to these: Is it normal to find it hard to solve the problems in that book? Can you possibly tell me why I am finding it hard? I will surely provide more details if necessary. (This question seems impossible to answer, so feel free to ignore it.) What should I do if I still want to study combinatorics? For example, what books are recommended for my situation? And, more importantly, how can I improve my skills in solving combinatorics problems? Please tell me what else I should add to get better answers. Again, thank you for reading this!","['combinatorics', 'advice', 'self-learning', 'soft-question']"
2139075,Prove that $\cos(\pi/7)$ is root of equation $8x^3-4x^2-4x+1=0$,"Prove that $\cos\theta$ is root of equation $8x^3-4x^2-4x+1=0$, given $\theta=\frac{\pi}{7}$. I put $\cos\theta$ in equation, but couldn't show the left-hand side to be zero.","['self-learning', 'polynomials', 'roots', 'trigonometry', 'algebra-precalculus']"
2139077,Problem with $\int \frac{\sin^{3}x+\cos^{3}x}{\sin{x}\cos{x}} \text{dx}$,"I wrote 
\begin{eqnarray}
I 
&=& \int \frac{\sin^{3}x+\cos^{3}x}{\sin{x}\cos{x}} \text{dx}\\
&=& 
\int \frac{\sin^{3}x}{\sin{x}\cos{x}}\text{dx}+\int \frac{\cos^{3}x}{\sin{x}\cos{x}}\text{dx}\\
 &=& 
 \int \frac{\sin^{2}x}{\cos^2{x}}\cos{x}\text{dx}+\int \frac{\cos^{2}x}{\sin^2{x}}\sin{x}\text{dx}\\
 &=& 
 \int \frac{\sin^{2}x}{1-\sin^2{x}}\cos{x}\text{dx}+\int \frac{\cos^{2}x}{1-\cos^2{x}}\sin{x}\text{dx}\\
&=&
\int\frac{u^2}{1-u^2}du-\int\frac{m^2}{1-m^2}dm\\
&=&
\color{blue}{\int\frac{u^2}{1-u^2}du-\int\frac{u^2}{1-u^2}du}\\
&=&
0
\end{eqnarray}
and Other Let $x=\dfrac{\pi}{2}-t$ so
$$I=\int \frac{\sin^{3}x+\cos^{3}x}{\sin{x}\cos{x}} \text{dx}=-\int \frac{\sin^{3}t+\cos^{3}t}{\sin{t}\cos{t}} \text{dt}=-I$$
but correct answer is 
$$
I=\ln\left|\dfrac{1+\tan\dfrac{x}{2}}{1-\tan\dfrac{x}{2}}\right|+\ln\left|\tan\dfrac{x}{2}\right|-\sin x+\cos x+C
$$ Question.1 Where is wrong.? Question.2 what conditions guarantee that our changing variable in indefinite integrals doesn't change our final solutions!.","['integration', 'calculus', 'analysis']"
2139090,Find the Derivative of $f(x)=\frac{7}{\sqrt {x}}$ using the definition.,"I get that $$\frac{d}{dx}\left(7\times\dfrac{1}{\sqrt{x}}\right)=\frac{d}{dx}(7x^{.5})=\dfrac{7}{2}x^{-.5}$$ is the derivative, but I can't ever use $\lim_{h \to 0} \dfrac{f(x+h)-f(x)}{h}$. If someone or anyone could go step by step and do the problem, I would be eternally grateful.","['derivatives', 'calculus']"
2139102,How do I avoid silly algebraic mistakes as such?,"Problem: 
$\sqrt{x+3} -\sqrt{x-2} = \sqrt{6x-11}$
So I squared both sides:
$(\sqrt{x+3} -\sqrt{x-2})^2 = (\sqrt{6x-11})^2$
I was left with:
$x+3 - x-2 = 6x-11$ However, this is incorrect since I must first simplify within the parenthesis, I am having trouble with advanced precalculus problems because I often make algebraic mistakes such as that above and I would like to ask for any advice. Does anyone have a good source where I can review all the algebriac rules? I feel embarrassed asking this but I am seriously being held back by this.",['algebra-precalculus']
2139117,Is the space of continuous (may be unbounded) functions complete?,"I know that the space of continuous bounded function is complete in the sup norm.
However, I am confused that if $X\subset R$ is not compact, then is the space of continuous function on $X$, denoting by $C(X)$ still complete?","['functional-analysis', 'banach-spaces']"
2139128,Can the quadratic formula be used with variable coefficients? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question Could we use the quadratic formula on an expression such as $z^2xy - zx^2y+y = 0$ to find $z$ in terms of $x$ and $y$?","['algebra-precalculus', 'quadratics']"
2139137,Proving MAE(mean absolute error) argmin is median using functionals?,"For example, I was able to find that, using functionals, the squared mean error argmin is $[y]$: $f^* = argmin_f E_{x,y \sim p*(x,y)}(y-f(x))^2$ gives us after deriving with respect to f: $\int_y(-2y + 2f(x))p(y|x) = 0$, and thus: $2E[Y] - 2f(x)*1 = 0$, which leads to $f^*(x) = E[Y]$. However, I can't use the same logic to find the functional for: $f^* = argmin_f E_{x,y \sim p*(x,y)}|y-f(x)|$ I know it's not differentiable at its minima, but is there any way to use functionals to motivate the minima as the median? Thanks.","['machine-learning', 'statistics']"
2139142,How does Horner method evaluate the derivative of a function,"From my understanding, Horner method is mainly used to evaluate polynomial functions by altering the equation into a simpler recursive relation with lesser number of operations.
Say for example, I was given $f (x) = 4x^4 + 3x^3 +2x^2+x+5$
This can be rewritten as $5 +x (1+x (2+x (3+x (4)))$ Were we can evaluate the function as a recurrent relation of simpler terms starting from: $b_n=4 $ $b_{n-1} = 3 + b_n* x$ And $b_0$ would be the whole term evaluated and therefore the image of the function. 
What I want to understand how is running horner method to the $b_n$ values result in the derivative?","['derivatives', 'numerical-methods']"
2139181,Expansion of incomplete Gamma function.,"I need to estimate the following quantity
$$
K(m,y) \equiv \left(\frac e m \right)^m \times \Gamma(m,(1+y)m),
$$
as $m \to \infty$, where $\Gamma(a,z)$ is the incomplete gamma function . My question is, is there a valid expansion of the incomplete Gamma function in the range when $y \approx m^{-1/2}$ that can give us a good estimation of $K(m,y)$? Further details: As I need to estimate $K(m,y)$ for all $y > 0$, I looked up for uniform expansions of incomplete Gamma functions. The most promising formula that I can find is give by R. B. Paris :
$$
\Gamma(a,z)=
z^{a-1/2}e^{-z}
\left(\sqrt{\frac \pi 2}\cdot e^{\chi^2/2} \mathrm{erfc}\left(\frac{\chi}{\sqrt{2}}\right)+O(z^{-1/2})\right)
$$
where $\chi = (z-a)/\sqrt{z}$, and $\mathrm{erfc}$ is the complementary error function . So in my case, I have
$$
K(m,y) = \left(\frac{1+y}{e^y} \right)^m \frac{1}{\sqrt{(1+y)m}}
\left(\sqrt{\frac \pi 2}\cdot e^{\chi^2/2} \mathrm{erfc}\left(\frac{\chi}{\sqrt{2}}\right)+O(m^{-1/2})\right).
$$
with $\chi = y \sqrt{m}/\sqrt{1+y}$. When $y > m^{-1/2+\epsilon}$ or $y < m^{-1/2-\epsilon}$, i.e., when $\chi \to \infty$ or $\chi \to 0$, the above estimation is good, because we can expand $\mathrm{erfc}(\chi)$ easily. But when $\chi$ is bounded from above and below, all I can say is that $\mathrm{erfc}(\chi) = O(1)$, which implies that
$$
K(m, y) = O(m^{-1/2}).
$$
This is not good enough for my application. I would like to get the first order approximation of $K(m,y)$ for $y$ in this range. Even more details: I am actually trying is to upper bound the following
$$
H(n,m) = \int_0^\infty e^{-y(n-m+1)} (1+y)^{n-m} K(m+1, y) \mathrm dy \qquad (m \to \infty),
$$
where $n > m$ and $n, m$ are both integers. If I use $K(m+1,y) = O(m^{-1/2})$, I will only get $H(n,m) = O(m(n-m))^{-1/2}$. But again I actually want to get the first order approximation of $H(m,n)$.","['complex-analysis', 'asymptotics', 'gamma-function']"
2139188,Solve differential equation $y''+y=\cos^2x$,"Solve differential equation  $y''+y=\cos^2x$ We are looking at a homogeneous equation: $$y''+y=0$$
$$\lambda^2+1=0\Rightarrow \lambda_1=-i,\lambda_2=i\Rightarrow y_h=C_1e^{0x}\cos x+C_2e^{0x}\sin x=C_1\cos x+C_2\sin x$$ Now we find a particular solution:
$$y''+y=\cos^2x=\frac{1}{2}+\cos(2x)$$ $$y''+y=\frac{1}{2}$$ $$y_{p1}=1/2$$
$$y''+y=\cos(2x)$$
$$y_{p2}=A\sin 2x+B\cos 2x,y_{p2}''=-4A\sin 2x-4B\cos 2x$$
$$\Rightarrow A=0,B=-1/3, y_{p2}=-\frac{1}{3}\cos 2x$$
$$\Rightarrow y=y_h+y_{p1}+y_{p2}=C_1\cos x+C_2\sin x+\frac{1}{2}-\frac{1}{3}\cos 2x$$ Is this correct?",['ordinary-differential-equations']
2139299,How to evaluate a truncated binomial series in the infinity limit,"For a standard binomial series, if it is truncated in the following way:
$$\sum_{k=0}^{n'}{n \choose k}(1-x)^{n-k}x^k$$ with $n'<n$, say e.g. $n'=n/2$ 
what is the behavior of the truncated series in the limit of $n$ and $n'$ goes to infinity? Numerical calculations seem to suggest that it will give a step function. How to show this analytically?","['sequences-and-series', 'calculus', 'analysis']"
2139323,How to solve this system of equations in Lagrange Multiplier problem,"Find the maximum and minimum values of ${x^{2} + y^{2} + z^{2}}$ subject to the conditions ${\frac{x^{2}}{4} + \frac{y^{2}}{5} + \frac{z^{2}}{25} = 1}$  and ${x + y - z = 0}$. Using Lagrange multiplier method, I got following equations:
$$ {2x = \frac{\lambda_{1} x}{2} + \lambda_{2}}$$
$$ {2y = \frac{2 \lambda_{1} y}{5} + \lambda_{2}}$$
$$ {2z = \frac{2 \lambda_{1} z}{25} - \lambda_{2}}$$
$${\frac{x^{2}}{4} + \frac{y^{2}}{5} + \frac{z^{2}}{25} = 1}$$
$${x + y - z = 0}$$ I'm stuck after this. I've tried to solve this system of equations to get critical point many times. Any help will be greatly appreciated. Also is there any other way to approach this problem?","['systems-of-equations', 'discriminant', 'multivariable-calculus', 'qcqp', 'lagrange-multiplier']"
2139378,Squaring a floor value,"I know this is a very crude question and will receive down votes but my question still remains: Is it true that
$$\lfloor{x}\rfloor^2 = \lfloor{x^2}\rfloor$$ Or generalising it to any arbitrary power $k$:
$$\lfloor{x}\rfloor^k = \lfloor{x^k}\rfloor$$ Thanks a lot!","['ceiling-and-floor-functions', 'discrete-mathematics']"
2139408,A series involve combination,"I want find another Idea to find sum of $\left(\begin{array}{c}n+3\\ 3\end{array}\right)$ from $n=1 ,to,n=47$ 
or $$\sum_{n=1}^{47}\left(\begin{array}{c}n+3\\ 3\end{array}\right)=?$$ I do it first by turn $\left(\begin{array}{c}n+3\\ 3\end{array}\right)$ to $\dfrac{(n+3)(n+2)(n+1)}{3!}=\dfrac16 (n^3+6n^2+11n+6)$ and find sum of them by separation  $$\sum i=\dfrac{n(n+1)}{2}\\\sum i^2=\dfrac{n(n+1)(2n+1)}{6}\\\sum i^3=(\dfrac{n(n+1)}{2})^2$$ 
then I think more and do like below ... 
I think there is more Idea to find this summation . please hint, thanks in advanced","['sequences-and-series', 'calculus', 'algebra-precalculus', 'education', 'discrete-mathematics']"
2139415,An open subscheme of a variety is a variety?,"In Vakil's notes, he mentions that an open subscheme $U$ of a $k$-variety $X$ is automatically a $k$-variety. Why is this the case? Here a $k$-variety is defined as a reduced, separated scheme of finite type over $k$. It is immediately clear that $U$ is separable, because our map $U\to Spec(k)$ is equal to the composition $U\hookrightarrow X\to Spec(k)$, both of which are separable maps (the former because it is monic, and the latter by definition). And it is clear that $U$ is reduced, because stalks of points in $U$ are the same as their stalks in $X$, which are all reduced. So all I'm unsure about is, how can I see that $U$ is finite type over $k$?","['schemes', 'algebraic-geometry']"
2139469,Convergence of a sequence,"$$\huge{{\sqrt2},{\sqrt2}^{\sqrt2},{\sqrt2}^{{\sqrt2}^{\sqrt2}},{\sqrt2}^{{\sqrt2}^{\sqrt2^{\sqrt2}}},\cdots}$$ I want to show the sequence converges to $2$ First I plot $f(x)=\displaystyle{\sqrt2}^x ,g(x)=x$, this figure show me $f(x)=g(x)$ has two root $x=2,4$ then plot $\displaystyle y={\sqrt2},{\sqrt2}^{\sqrt2},{\sqrt2}^{\sqrt2^{\sqrt2}},...$ 
show me that $x=2 $ is convergence point .
If I write  ${\sqrt2}^x=x$ then put $x$ in l.h.s I will have ${\sqrt2}^{\sqrt2^x}=x$ so this is my way 
$$\displaystyle{{\sqrt2}^x=x\\{\sqrt2}^{{\sqrt2}^x}=x\\
{\sqrt2}^{{\sqrt2}^{{\sqrt2}^{x}}}=x\\
{\sqrt2}^{{\sqrt2}^{{\sqrt2}^{{\sqrt2}^{x}}}}=x\\\vdots \\{\sqrt2}^{{\sqrt2}^{{\sqrt2}^{{\sqrt2}^{\cdots}}}}=x\to 2}$$ $$$$
(1) Am I right ? (2)Is there another method to find convergence ? Thanks In advanced.","['alternative-proof', 'calculus', 'proof-explanation', 'sequences-and-series', 'graphing-functions']"
2139506,Sum of the squares of the sides of a triangle,"I have solved this problem, but I had to use a calculator, how do I solve it without using a calculator(wont be allowed to use a calculator in the examination). Here is my attempt:","['trigonometry', 'triangles', 'trigonometric-series']"
2139534,How to determine if the dataset is large enough?,"We are given a dataset $X=(x_1,\ldots,x_n)$ of words (it could be duplicates). We assume each $x_i$ was generated by a probability distribution with probability  $p_i$ (we do not know this values, we have to estimate them from the dataset). Define the metric $d_k=\sum_{j=1}^k p_{i_j}$, which sums up the biggest $k$ values of $p_{i_j}$. The question is: How will you determine whether the dataset $X$ is large enough to allow a good estimation of $d_k$? I can estimate the probabilities from the dataset $X$, $\overline{p_{i_j}}$ = $\frac{f_{i_j}}{|X|}$, where $f_{i_j}$ is frequency of $x_{i_j}$ in dataset $X$. Therefore, I have an estimation for my metric $d_k$ by taking the first $k$ highest values of $\overline{p_{i_j}}$ We know that $MSE=bias^2 + variance$, then I can decide whether $d_k$ is a good estimation by taking a look on $MSE$ value and comparing it with a threshold. If it is smaller than $X$ is large enough. Otherwise it is not. Is it a good approach?","['statistics', 'probability']"
2139624,How could I know that $X^4+1$ is $(X^2+\sqrt 2X+1)(X^2-\sqrt 2X+1)$?,"I thought that $X^4+1$ was irreducible, but in fact, $$X^4+1=(X^2+\sqrt 2X+1)(X^2-\sqrt 2X+1).$$ In general, how can I have the intuition of such a factorisation if I don't know it ?","['abstract-algebra', 'polynomials']"
2139634,Prove that $\ln2<\frac{1}{\sqrt[3]3}$,"Prove that $$\ln2<\frac{1}{\sqrt[3]3}$$
without calculator. Even $\ln(1+x)\leq x-\frac{x^2}{2}+\frac{x^3}{3}-...+\frac{x^{51}}{51}$ does not help here and we need another Taylor.","['algebra-precalculus', 'inequality', 'calculus']"
2139671,Why does integral and the imaginary part commute?,"I have many a times encountered (and used myself) the following technique: $$\int \sin x \mathrm{d}x = \int \operatorname{Im}(e^{ix}) \mathrm{d}x = \operatorname{Im} \left( \int e^{ix} \mathrm{d}x \right) = \operatorname{Im}( -ie^{ix}) + C = -\cos x + C$$ Not only in this case, but I've used this kind of transform many a times, instinctively, to solve many of those monster trig integrals (and it works like a miracle) but never justified it. Why and how is this interchange of integral and imaginary part justified? At first, I thought it might be always true that we can do such a type of interchange anywhere, so, I tried the following: $\operatorname{Im}(f(z)) = f(\operatorname{Im}(z))$. But this is clearly not true, as the LHS is always real but RHS can be, possibly, complex too. Second thoughts. I realized that we are dealing with operators here and not functions really. Both integral and imaginary parts are operators. So we have a composition of operators and we are willing to check when do these operators commute? I couldn't really make out any further conclusions from here and am stuck with the following questions: When and why is the following true: $\int \operatorname{Im}(f(z)) \mathrm{d}z= \operatorname{Im} \left( \int f(z) \mathrm{d}z \right)$? (Provided that $f$ is integrable) Is it always true? (Because like I've used it so many times and never found any counter example) Edit : I am unfamiliar with integration of complex-valued functions but what I have in mind is that while doing such a thing, I tend to think of $i$ as just as some constant (Ah! I hope this doesn't sounds like really weird), as I stated in the example in the beginning. To be more precise, I have something of like this in my mind: because a complex-valued function $f(z)$ can be thought of as $f(z) = f(x+iy) = u(x,y) + iv(x,y)$ where $u$ and $v$ are real-valued functions and we can now use our definition for integration of real-valued functions as
$$\int f(z) \mathrm{d}z = \int (u(x,y) + iv(x,y)) \mathrm{d}(x+iy) = \left(\int u\mathrm{d}x - \int v\mathrm{d}y\right) +i\left(\int v\mathrm{d}x + \int u\mathrm{d}y\right)$$","['integration', 'complex-numbers']"
2139745,A beautiful geometry problem,"Let $PP'$ and $QQ'$ be two parallel lines tangent to a circle of center $C$ and radius $r$ in the points $P$ and $Q$, respectively. $P'Q'$ cuts de circle in $M$ and $N$. Let $Y$ and $X$ be the points in which $Q'Q$ is cut by $PN$ and $PM$, respectively. Given the lengths $PP'= p$, $QQ'= q$ and $2r = d$, find the lengths $QY = y$ and $QX = x$. I've been struggling with this problem for a couple of days, so a hint or a solution would be welcome. Now, what makes this problem beautiful is the fact that if you let $p=-\dfrac{2a}b$ and $q =-\dfrac{c}{2b}$ then the lengths $y$ and $x$ will be the real roots of the equation $ax^2 + 2bx + c = 0$.","['geometric-construction', 'geometry']"
2139754,Can we use Power Series Solution for points other than x=0 to escape Frobenius Solution?,"Suppose I have an equation $y"" + P(x)y' + Q(x)y = 0$ Now we apply power series when $P$ and $Q$ are analytic at $x=0$ and apply Frobenius method when $P$ and $Q$ are not analytic at $x=0$ . Now, I want to know why do we apply the Frobenius method? We could equally have taken a power series in terms of $(x-a)$ , where $P$ and $Q$ would analytic at $a$ and $a$ could be anything i.e $(2, 3 ...100)$ . But we don't do that. We always use the Frobenius Method at $x=0$ . So why do we not do that? Is that wrong? Why do we always look for a series centered at $x=0$ ? Is it necessary that we find the series centered at $0$ ? And how does the multiplication of $x^r$ in the Frobenius method with our normal power series correct everything ? Can we use power series at points other than $0$ or Frobenius Method is the only way out?","['frobenius-method', 'ordinary-differential-equations', 'power-series']"
2139802,"If a,b and c are sides of a triangle, then prove that the following polynomial has no real roots","This is the polynomial: $$a^2x^2+(b^2+a^2-c^2)x+b^2=0$$ Now this is my progress: Assuming l,m, and n are sides of a triangle, then $$|m-n|\lt l\lt m+n$$
Also, if a second degree polynomial in the form $kx^2+px+q$ has real roots, then $$p^2-4kq\ge 0$$
 In this case, if there are no real roots, $$(b^2+a^2-c^2)^2-4a^2b^2\lt 0$$
 $$b^2+a^2-c^2\lt 2ab$$
 But by the first equation, $$a+b\gt c$$ $$a^2+b^2-c^2\gt 2ab$$ 
 Wich actually proves by contradiction there ARE real roots. What did I do wrong?","['algebra-precalculus', 'polynomials', 'geometry']"
2139807,"How is a Generator Matrix for a (7, 4) Hamming code created?","I see that a generator matrix is created with the following formulae: $$G = \left[I_{k}|P\right]$$ I do not understand what P is in this case. In my notes, I am told that in a (7, 4) Hamming code situation my
$$G =
\begin{pmatrix} 1 & 0 & 0 & 0 & 1 & 0 & 1 \\ 0 & 1 & 0 & 0 & 1 & 1 & 1 \\ 0 & 0 & 1 & 0 & 1 & 1 & 0 \\ 0 & 0 & 0 & 1 & 0 & 1 & 1   \end{pmatrix}$$ where P would be $$P=\begin{pmatrix}  1 & 0 & 1 \\  1 & 1 & 1 \\  1 & 1 & 0 \\  0 & 1 & 1   \end{pmatrix}$$ How is this P generated?","['matrices', 'coding-theory', 'linear-algebra']"
2139853,"Finding a $w\in\Bbb{R}^2$ fulfilling $dX|_pw=(x,y,0)^T$, $X$ a parameterization for $S^2$ and $p$ the north pole","Let $S^2$ be the unit sphere in $\Bbb{R}^3$. It is a regular surface. Let $\phi:S^2\rightarrow S^2$ be the reflection function, $p=(0,0,1)$ the north pole on the sphere, and $v=(x,y,0)^T$ a vector in the tangent plane $T_p S^2$ (which is the $XY$ plane). I need to show that $d\phi |_p (v)=-v$. For that, I use the definition: $d\phi|_p (v)=d(\phi \circ X)|_{X^{-1}(p)}(w)$ when $w\in\Bbb{R}^2$ is a vector fulfilling $dX|_p(w)=v$ (there exists one, from the definition on a tangent plane) and $X:U\subset\mathbb{R}^2\rightarrow S^2$ a parameterization of $S^2$. My problem was in finding $w$. If I take $X(\theta,\phi)=(\cos\phi\sin\theta,\sin\phi\sin\theta,\cos\theta)$, then $X^{-1}(p)=(\theta=0,\phi)$.  $\phi$ is general, because it can be anything, right? Now, I want to find a $w$ such that $dX|_{(\theta=0,\phi)}w=(x,y,0)^T$. But $$dX|_{(\theta=0,\phi)}=\begin{pmatrix}
        \cos\phi & 0 \\
        \sin\phi & 0  \\
        0 & 0  \\
        \end{pmatrix}$$ So $dX|_{(\theta=0,\phi)}\begin{pmatrix}
        w_1 \\
        w_2  \\
        \end{pmatrix}=\begin{pmatrix}
         w_1 \cos\phi\\
        w_1  \sin\phi\\
0\\
        \end{pmatrix}$ which can't be equal to $\begin{pmatrix}
         x\\
        y\\
0\\
        \end{pmatrix}$ with general $x,y\in\Bbb{R}$ unless we add $\phi$ as a variable, which is wierd because it shouldn't influence the answer. Note: if I ignore the fact I can't find $w$ and treat it as just a vector fulfilling $dX|_{(\theta=0,\phi)}w=(x,y,0)^T$, I can prove the statement easily. However, it really bothered me that I couldn't find $w$, even though it is not crucial for this very question.","['derivatives', 'differential-geometry']"
2139865,How to simulate a Super-Brownian Motion (SBM)?,"I'll start by doing this in MATLAB . A Standard Brownian Motion $dX_t$ can be approximated by a scaled random walk through $\triangle{X}=Z\sqrt{\triangle t}$. Analogously the drift of a Super-Brownian Motion can be approximated as $\dot{W}(t,x)=Z_{x,t}\sqrt{\triangle t}\sqrt{\triangle x}$ where $Z_{x,t}\sim N(0,1)$ or a random variable with variance 1. For example, a Bernoulli random variable taking 1 and -1 each with probability $\frac{1}{2}$ A Super-Brownian Motion is a continuous stochastic process satisfying the differential equation
$$\frac{\partial X}{\partial t}=\frac{X''(t,x)}{2}+\sqrt{X}\dot{W}$$
By Feyman-Kac's formula and Ito's Isometry
$$E[[\int_0^t\int_{\mathbb{R}}\sqrt{X(s,x)}dW(s,x)]^2]=E[\int_0^t\int_{\mathbb{R}}X(s,x)dxds]$$
Thus we may discretize the solution by $$E[\sum_{s<t}\sum_{s\in\mathbb{R}}\sqrt{X(s,x)}Z_{x,s}\sqrt{\triangle t}\sqrt{\triangle x}]\approx E[\sum_{s<t}\sum_{x\in\mathbb{R}}X(s,x)Z_{x,s}^2\triangle t\triangle x]$$
To simulate the stochastic differential equation, we may have $$\frac{X''(t,x)}{2}\approx \frac{1}{2}X(t,x+\triangle x)+\frac{1}{2}X(t,x-\triangle x)-X(t,x)$$
and $$\frac{\partial X}{\partial t}\approx X(t+\triangle t,x)-X(t,x)$$
For more about simulating Super-Brownian Motion, see Achim Klenke: http://www.aklenke.de .","['stochastic-processes', 'simulation', 'probability', 'stochastic-integrals']"
2139917,Computing: $\lim_{x\to\infty}\frac{\sqrt{1-\cos^2\frac{1}{x}}\left(3^\frac{1}{x}-5^\frac{-1}{x}\right)}{\log_2(1+x^{-2}+x^{-3})}$,Find the following limit: $$\lim_{x\to\infty}\frac{\sqrt{1-\cos^2\frac{1}{x}}\left(3^\frac{1}{x}-5^\frac{-1}{x}\right)}{\log_2(1+x^{-2}+x^{-3})}$$ I'm not sure whether my solution is correct. $t:=\frac{1}{x}$ $$\lim_{x\to\infty}\frac{\sqrt{1-\cos^2\frac{1}{x}}\left(3^\frac{1}{x}-5^\frac{-1}{x}\right)}{\log_2(1+x^{-2}+x^{-3})}=\lim_{t\to 0}\frac{\sqrt{1-\cos^2 t}\left(3^t-5^{-t}\right)}{\log_2(1+t^2+t^3)}$$ $$=\lim_{t\to 0}\frac{\frac{\sqrt{1-\cos^2t}}{\sqrt t^2}\cdot t\cdot\left(\frac{3^t-1}{t}\cdot t+(-t)\frac{(-5)^{-t}+1}{-t}\right)}{\log_2(1+t^2+t^3)}$$ $$=\frac{1}{2}(\ln 3+\ln 5)\left[\lim_{t\to 0}\log_2(1+t^2+t^3)^\frac{1}{t^2}\right]^{-1}=\frac{1}{2}(\ln3+\ln 5)\left(e^{{\lim_{t\to 0}\frac{t^2+t^3}{t^2}}^{-1}}\right)^{-1}=\frac{\ln3+\ln5}{2e}$$,"['real-analysis', 'limits-without-lhopital', 'calculus', 'limits']"
2139932,Arrange $m$ people in $m+r$ seats around a round table.,"The answer is, according to the book: $(m-1)!\cdot \binom{m+r-1}{r}$ I get why this is true. You arrange $m$ people in their seats in $(m-1)!$ ways and then you put $r$ empty spots inbetween them. I was thinking - choose $m$ seats out of $m+r$ to put the people on => $\binom{m+r}{m}$ Arrange them once you've chosen the seats $\to (m-1)!$ So in total: $\binom{m+r}{m} \cdot (m-1)!$ This is obviously not true. What's wrong with the way I'm thinking?",['combinatorics']
2139987,"Quick question regarding $\int \frac{\cos x + \sin x}{\sin 2x}\,dx$","I already asked a question here regarding the discrepancy between the answers I get when I work integrals by hand and the result I can verify using $Mathematica$. I only know enough about $Mathematica$ to type in the commands I need to verify results, plot graphs of polynomials, etc. Usually I get to the same answer that the program produces, which I always find a bit gratifying, but other times I get results that are equivalent but quite different and often tedious to transfer for one form to the other to verify the equivalence. Anyway, since this happens to me quite often lately, I wonder how I could check whether I am getting correct results in a reliable way. For example 
$$\int \frac{\cos x + \sin x}{\sin 2x}\,dx$$
I use the identity $\sin 2x = 2 \sin x \cos x $ and get
$$\frac 12 \int \frac {\cos x + \sin x}{\sin x \cos x}\, dx$$ $$=\, \frac 12 \int \frac {\cos x}{\sin x \cos x}+\frac {\sin x}{\sin x \cos x}\, dx$$ $$=\, \frac 12 \int \csc x \, dx \; + \; \frac 12 \int \sec x \,dx$$ $$=\, -\frac 12 \ln {|\csc x + \cot x|} + \frac 12 \ln {|\sec x + \tan x|}+C$$ This is not the same as the result from $Mathematica$, which gives 
$$-\frac 12 \ln \left(\cos \frac x2 \right) - \frac 12 \ln \left( \cos \frac x2 - \sin \frac x2 \right)+ \frac 12 \ln \left( \sin \frac x2 \right) + \ln \left( \cos \frac x2 + \sin\frac x2 \right)$$
is this equivalent to my result
$$=\, -\frac 12 \ln {|\csc x + \cot x|} + \frac 12 \ln {|\sec x + \tan x|}+C$$
and how could I reliably verify my answers with $Mathematica$?","['mathematica', 'trigonometry', 'calculus', 'indefinite-integrals', 'trigonometric-integrals']"
2140002,Bundle cohomology of a tensor product of line bundles,"Consider a complex manifold $X$, and let $V$ be a holomorphic vector bundle on $X$ given by a Whitney sum of $n$ holomorphic line bundles $L_i$, i.e. let $V=\oplus_{i=1}^n L_i$. Further, if it is useful let us assume that this complex manifold has trivial canonical bundle. The bundle cohomologies of the vector bundle $V$ are given by the sum of the bundle cohomologies of the line bundles $L_i$, so in particular for the cohomology dimensions we have,
$$ h^i(V,X) = \sum_{i=1}^n h^i(L_i,X) \,.$$
My question is as follows. Consider now the tensor product of line bundles, e.g. $\tilde{L}=L_1 \otimes L_2$. I gather that there is no simple statement analogous to the above for the cohomologies of $\tilde{L}$ in terms of those of $L_1$ and $L_2$. However, is there anything useful that can be said in general in this case, or alternatively are there any special cases for which we can make is a neat statement? There are some similar questions on here, but I wonder if perhaps more can be said in this case of only tensor products of holomorphic line bundles on a complex manifold with trivial canonical bundle.","['complex-geometry', 'algebraic-geometry', 'holomorphic-bundles', 'sheaf-cohomology', 'vector-bundles']"
2140039,"La Jolla Covering tables, how to use them? Are they optimized?","Recently I asked this question about guaranteeing matching a certain number of lottery numbers, and the answer gave the right direction to what I'm looking for, La Jolla Covering tables. But now that I've been studying the tables and trying to understand them, I'm not sure if I'm getting it at all. As I mention in my post, I play lotto, where I pick 8 numbers and make 5 combinations of 5 each, like this: 1,2,3,4,5 1,2,3,4,6 1,2,3,5,6 1,2,3,7,8 4,5,6,7,8 This gives me the certainty that if the 5 winning lotto numbers are contained in my 8 numbers, I will hit at least 4 in 1 of my 5 tickets. From what I've read in La Jolla Covering Repository : A $(v,k,t)-$ covering design is a collection of $k$ -element subsets, called blocks, of $\{1,2,\ldots ,v\}$ , such that any $t$ -element subset is contained in at least one block. From this, I think my design should be $(v=8,k=5,t=4)$ , if I'm understanding correctly. If I go and check the table at the La Jolla repository, I get a table with 20 rows, which leads me to believe that I'm not understanding this at all. What is it that I'm not understanding correctly? Can you elaborate your answer please?","['combinatorial-designs', 'combinatorics']"
2140082,Expression of $R_{ijk}^s$ in terms of coefficients $\Gamma_{ij}^k$ of the Riemannian connection,"Let $R$ be the curvature of a Riemannian manifold $M$ defined by 
  $$
R(X,Y)Z=\nabla_Y \nabla_X Z - \nabla_X \nabla_Y Z + \nabla_{[X,Y]}Z,
$$
  where $X,Y,Z$ are vector fields and $\nabla$ is the Riemannian connection of $M$. Let us indicate as usual $\frac{\partial}{\partial x_i}=X_i$. We put
  $$
R(X_i,X_j)X_k = \sum_\ell R_{ijk}^\ell X_\ell.
$$
  Thus, $R_{ijk}^\ell$ are the components of the curvature $R$ in $(U,\mathbf x)$. If
  $$
X=\sum_i u^i X_i, \qquad Y=\sum_j v^j X_j, \qquad Z=\sum_k w^k X_k,
$$
  we obtain, from the linearity of $R$,
  $$
R(X,Y)Z=\sum_{i,j,k,\ell} R_{ijk}^\ell u^i v^j w^k X_\ell.
$$
  To express $R_{ijk}^\ell$ in terms of the coefficients $\Gamma_{ij}^k$ of the Riemannian connection, we write
  \begin{align}
R(X_i,X_j)X_k &= \nabla_{X_j} \nabla_{X_i} X_k -  \nabla_{X_i} \nabla_{X_j} X_k \\
&= \nabla_{X_j} \left(\sum_{\ell} \Gamma_{ik}^\ell X_\ell \right) -  \nabla_{X_i} \left(\sum_{\ell} \Gamma_{jk}^\ell X_\ell \right),
\end{align}
  which by a direct calculation yields
  $$
R_{ijk}^s = \sum_\ell \Gamma_{ik}^\ell \Gamma_{j\ell}^s - \sum_\ell \Gamma_{jk}^\ell \Gamma_{i\ell}^s + \frac{\partial}{\partial x_j} \Gamma_{ik}^s - \frac{\partial}{\partial x_i} \Gamma_{jk}^s.
$$ This is taken from Riemannian Geometry by Manfredo do Carmo, pp. 93–94. My question is how do we justify this direction calculation? There are two expressions of $R(X_i,X_j)X_k$. Equating those two expressions and taking the $s$-th index of the summation $\ell=1,\ldots,n$, 
$$
R_{ijk}^s X_s = \nabla_{X_j} \Gamma_{ik}^s X_s -  \nabla_{X_i} \Gamma_{jk}^s X_s.
$$
Using product rule, I think we obtain that
\begin{align}
R_{ijk}^s X_s &= \left(\frac{\partial}{\partial x_j} \Gamma_{ik}^s X_s + \Gamma_{ik}^s \nabla_{X_j} X_s \right)- \left(\frac{\partial}{\partial x_i} \Gamma_{jk}^s X_s + \Gamma_{jk}^s \nabla_{X_i} X_s \right) \\ 
&= \Gamma_{ik}^s \nabla_{X_j} X_s - \Gamma_{jk}^s \nabla_{X_i} X_s + \frac{\partial}{\partial x_j} \Gamma_{ik}^s X_s - \frac{\partial}{\partial x_i} \Gamma_{jk}^s X_s.
\end{align}
Recalling the definition $\nabla_{X_i} X_k = \sum_\ell \Gamma_{ik}^\ell X_\ell$, 
\begin{align}
R_{ijk}^s X_s &= \sum_\ell \Gamma_{ik}^s \Gamma_{js}^\ell X_\ell - \sum_\ell \Gamma_{jk}^s \Gamma_{is}^\ell X_\ell + \frac{\partial}{\partial x_j} \Gamma_{ik}^s X_s - \frac{\partial}{\partial x_i} \Gamma_{jk}^s X_s \\ 
&= \sum_s \Gamma_{ik}^\ell \Gamma_{j\ell}^s X_s - \sum_s \Gamma_{jk}^\ell \Gamma_{i\ell}^s X_s + \frac{\partial}{\partial x_j} \Gamma_{ik}^s X_s - \frac{\partial}{\partial x_i} \Gamma_{jk}^s X_s.
\end{align}
(I achieved the last step by switching the dummy indices: interchanging the roles of $\ell$ and $s$.) Then I would cancel $X_s$ from both sides to obtain:
$$
R_{ijk}^s = \sum_s \Gamma_{ik}^\ell \Gamma_{j\ell}^s - \sum_s \Gamma_{jk}^\ell \Gamma_{i\ell}^s + \frac{\partial}{\partial x_j} \Gamma_{ik}^s - \frac{\partial}{\partial x_i} \Gamma_{jk}^s.
$$ However, the summations in my ""equality"" are over $s$, not over $\ell$ which is what the textbook printed. I would like to know where I went wrong in my alleged justification above.","['connections', 'riemannian-geometry', 'differential-geometry', 'curvature']"
2140113,How many edge covers are there for a complete graph?,"An edge cover of a graph $G = (V,E)$ is set $E' \subseteq E$ of edges such that for every vertex $v \in V$ there exists an edge $e \in E'$ such that $v \in e$. Examples: E is trivially an edge cover. $\{\{1,2\},\{3,4\},\{1,5\}\}$ is an edge cover of $K_5$, the complete graph over 5 vertices. Computing the total number of edge covers for any graph is #P-complete (from here ). I want to know the answer to a specialized version: What is the total number of edge covers of $K_n$, the complete graph on $n$ vertices?","['combinatorics', 'graph-theory']"
2140189,Is $\nabla^{n}$ a correct terminology for a partial derivative?,"I'm learning optimization techniques and came accross the gradient ( nabla ) operator : $\nabla$. If I'm right, the $\nabla$ operator of a function means the vector of all its partial derivatives. Then, if for example I'm talking about this specific partial derivative $\left(\frac{\partial}{\partial y}\right) F(x,y,z)$ is it a right terminology to write something like : $\nabla^{y}$ (since we can't use the standard i-th -element-in-vector notation like $\nabla^{2}$ as it would mean the Laplacian). If it is not a correct terminology, is there a correct terminlogy to specify a specific component of the partial derivatives vector?","['derivatives', 'terminology', 'optimization', 'calculus']"
2140190,Why is it necessary to talk about a pushforward measure?,"I understand that a random variable $X$ and a probability measure $P$ on a space $(\Omega,\mathcal{A})$ induce the distribution $P_X$ on a space $(\Omega',\mathcal{A}')$. But is there an example where it is important to differentiate between the distribution $P_X$ (the pushforward measure) and the probability measure $P$? Is there a theorem that deals with different distributions $(P_X)_n$ but only with one probability measure $P$? Or is this distinguishing between the two measure only formal?","['probability-theory', 'measure-theory', 'pushforward', 'probability-distributions']"
2140204,How do I find the diameters of the circles in this geometry puzzle?,My family and I like to do a daily quiz but this particular question has had us baffled for weeks. Please help. We only have basic mathematical knowledge.,['geometry']
2140232,"Evaluate $\int x \sec(x)\,dx$","So for one my exercise question is this: $$\int x \sec(x)\,dx$$ I tried every way that I can think of. I believe this could only be done in integration by parts. My class only learned three techniques which is PFD, $u$ -sub, and integration by parts. I tried $u = x$, $u = \sec(x)$ and then, $u = x\sec(x)$, which didn't help. Any help would be great.","['indefinite-integrals', 'integration']"
2140300,"Prove $\forall x\in\mathbb{Z}, k!\mid x(x+1)(x+2)\cdots(x+k-1)$. [duplicate]","This question already has answers here : The product of $n$ consecutive integers is divisible by $n$ factorial (7 answers) Closed 7 years ago . I need some help with this problem, can you help me? Given $k\in\mathbb{Z}^*$ prove $\forall x\in\mathbb{Z}, k\mid x(x+1)(x+2)\cdots(x+k-1)$. Sorry that one is pretty easy, I made a mistake. The problem is: [Update] Given $k\in\mathbb{Z}^*$ prove $\forall x\in\mathbb{Z}, k!\mid x(x+1)(x+2)\cdots(x+k-1)$.","['number-theory', 'combinatorics', 'divisibility', 'discrete-mathematics']"
2140312,Uncountable basis of vector space of infinite sequences in R [duplicate],"This question already has answers here : Vector space of infinite sequences in $\Bbb R$ [closed] (2 answers) Closed 7 years ago . How does one go about showing that the dimension of a vector space of infinite sequences is uncountable? My methods was to try and show the existence of an uncountable, linearly independent of sequences which implies that the basis must be uncountable. I have tried the set of following sequences i.e. 1) An = n^r where r is any real number 2) set of convergent sequences. However, I cant seem to show that they are uncountably infinite dimensional. Any tips? 
P.S Other solutions are welcomed but i have read other similar posts and do not understand the solutions","['linear-algebra', 'elementary-set-theory']"
2140356,Various methods to find value of $\sin 18^\circ$,To find value of $\sin 18^\circ$. Now my textbook gives a proof in which it takes $\theta=18^\circ$ and then multiply it out by 5 and write again as sum of $2\theta+3\theta$ and then taking sin on both sides forms a quadratic equation. Are there any other elegant ways to find its value? Thanks,['trigonometry']
2140378,"Division algorithm for polynomials in R[x], where R is a commutative ring with unity.","Is there a division algorithm for polynomials in R[x], where R is a commutative ring with unity? All the algebra books I read mention division algorithm for polynomials in F[x], where F is a field. Since the leading coefficient of a non zero polynomial in R[x] is not necessarily invertible, I find it difficult to proceed the same way we do for polynomials in F[x]. 
Can I get some help?","['abstract-algebra', 'ring-theory', 'polynomials']"
2140396,How to prove in this trig problem,i have to prove this $$\frac{\cos 3x}{\sin 2x \sin 4x}+\frac{\cos 5x}{\sin 4x \sin 6x}+\frac{\cos 7x}{\sin 6x \sin 8x}+\frac{\cos 9x}{\sin 8x \sin 10x} = \frac{1}{2}\csc x(\csc 2x - \csc 10x)$$ i tried taking lcm but does not leads to anything. i believe i have to write numerator as something in terms of denominator which i do not know how. Help. Thanks,['trigonometry']
2140411,Two boats leave at the same time,"Question: A cargo ship leaves port at 8:30 am going south at 20 knots. At the same time, a speed boat leaves port going east at 40 knots. Find the time of day, to the nearest minute,when the distance between the two boats will be approx. 536.66 nautical miles? I'm not sure how to answer this question. This is not a trig question so I wouldn't be able to solve it that way. I created a triangle to show the traveling but what confusing me is the time. I'm thinking since it's a distance question I would need the distance formula but I'm not entirely sure how I would set that up.  How would I solve this one? I maybe over thinking it.",['algebra-precalculus']
2140470,How to calculate the coefficients of finite product $\prod\limits_{i=1}^n{(z^i-1)}$ effectively,"How to caluclate the coefficients of finite product $$\prod\limits_{i=1}^{n}(z^i-1)=\sum\limits_{k=0}^{\frac{n(n+1)}{2}}a_{n,k}z^k$$ effectively? I have figured out a recursive rule for $n>1$: $$a_{n,k} = a_{n-1, k} - (-1)^na_{n-1,\frac{n(n-1)}{2}-k}$$ But I feel that there should be something much efficient than this. And also there is a sequence in OEIS: https://oeis.org/A231599","['recurrence-relations', 'products', 'functions']"
2140493,Counterintuitive examples in probability,"I want to teach a short course in probability and I am looking for some counter-intuitive examples in probability. I am mainly interested in the problems whose results seem to be obviously false while they are not. I already found some things. For example these two videos: Penney's game How to win a guessing game In addition, I have found some weird examples of random walks. For example this amazing theorem: For a simple random walk, the mean number of visits to point $b$ before returning to the origin is equal to $1$ for every $b \neq 0$ . I have also found some advanced examples such as Do longer games favor the stronger player ? Could you please do me a favor and share some other examples of such problems? It's very exciting to read yours...","['intuition', 'big-list', 'examples-counterexamples', 'probability', 'soft-question']"
2140501,"Is $\{(x,y)\in \mathbb R^2 : y=|x|\} \subseteq \mathbb R^2 $ a smooth manifold ?","Is the set $\{(x,y)\in \mathbb R^2 : y=|x|\} \subseteq \mathbb R^2 $ a smooth manifold ? I can only see that if it is a smooth manifold then it is of dimension $1$ . Please help . Thanks in advance","['multivariable-calculus', 'smooth-manifolds', 'differential-geometry']"
2140519,Converge uniformly on open interval implies on closed interval,"Suppose $f_n(x)$ is defined on $[a,b]$, and it converges uniformly to $f(x)$ on $(a,b)$. And the sequences $f_n(a)$ and $f_n(b)$ both converge (say, to points $c$ and $d$ respectively). I want to prove $f_n(x)$ is uniformly convergent on $[a,b]$. I know that when the goal is to proving convergence, we can combine the points $c,d$ and $f(x)$ to a new function, then the convergence is justified. But I do not know how to proceed for uniform convergence.","['real-analysis', 'cauchy-sequences', 'uniform-convergence', 'convergence-divergence', 'sequences-and-series']"
2140582,Permutation of coefficients of polynomials,"Are there any known results relating to permutation of coefficients of polynomials? for example given a polynomial, if the coefficients are permuted, then are there any results relating the two? related question, given set of all polynomials that are permutations of coefficients, are there any known results? The only possible example that I can think of is that if roots of a polynomial are not rational, then all polynomials permutations of it's coefficients also have no rational roots. Not sure if this is correct or incorrect.",['abstract-algebra']
2140605,Is $\sum\limits_{x = -\infty}^{\infty}x$ equal to $0$ or is it undefined?,"I'm not sure whether $\sum\limits_{x = -\infty}^{\infty}x$ is equal to $0$ or undefined. For example, $$\sum_{x = -\infty}^{\infty}x = \displaystyle \sum_{x = -\infty}^{-1}x + \displaystyle \sum_{x = 1}^{\infty}x = -\infty + \infty$$ So with that approach it is undefined. However, clearly all the negative elements in the summation cancel with the positive elements, so that makes it seem like it should be zero. So which is it?","['infinity', 'summation', 'sequences-and-series']"
2140677,Differential Equation of orbit of a planet,"Every where I found the solution of the differential equation orbit ( they make the differential equation in the 1st place )  by letting r=1/u  , using reciprocal coordinates. I was trying  to do away with this substitution but I couldn't form the equation. I was having a problem in whether (r) is a function of theta which in turn is a function of t or is r directly a function of t. Or is theta the function of r and then r is a function of t or theta directly a function of t . I tried this but produced a mess I need help in forming the equation without using u , just r and in understanding what is function of what both implicitly and explicitly ! Edit: After searching on the net I found out that without taking the substitution , I had actually formed the correct equation but that equation is non linear ! I got that correct non linear equation. To solve the equation we use the substitution r=1/u which will linearize it. So it's just linearization ! What I want is that please someone check 
This statement ""whether (r) is a function of theta which in turn is a function of t or is r directly a function of t. Or is theta the function of r and then r is a function of t or theta directly a function of t"" What is correct in the above statement ? I am getting confused because if theta is function of r then the differential equation would be different . Would it be so that we just replace r and theta in final answer and get the same answer back ?","['implicit-differentiation', 'ordinary-differential-equations', 'polar-coordinates', 'functions']"
2140678,QQ plot and visual analysis based on sample distribution,"When would you use a Box Plot, a Histogram, or a QQPlot to graphically summarize a SAMPLE of numbers? Interpretation: a sample of numbers: like a dataset that only contains numbers but not discrete values such as categories. OR: It means whether the change of the number of samples in the dataset would have some effect on the box plot, QQplot and histogram.","['statistics', 'probability', 'normal-distribution']"
2140680,Every singular quadric hypersurface in P^n is a cone.,"X in P^n is a cone iff there exists point P on X such that multiplicity of X at point P is 2.
The hint for this problem is that a tangent space of hypersurface X=V(F) at P is union of lines L which are tangent in point P in a sense that restriction of F to L has multiplicative root at P. Im not sure how to use this hint to solve the problem, and I would appriciate any help.","['algebraic-curves', 'algebraic-geometry']"
2140681,Birthday problem among k people,"Consider a group of $n$ people. Assume that each person's birthday is drawn uniformly at random from the $365$ possibilities. What is the smallest value of such that the expected number of pairs of distinct people with the same birthday is at least one?. My approach using indicator random variable: $X_{\bf i, j, i \neq j} = \begin{cases} 
&1 \qquad \text{ if ith and jth person having same birthday} \\
&0 \qquad \text{ if ith and jth person NOT having same birthday } \
\end{cases} \\\\$ $
\begin{align*} 
& E(X_{i,j}) = 1*P(X_{i,j}) + 0*\left ( 1 - P(X_{i,j}) \right ) \\
& \Rightarrow E(X_{i,j}) = P(X_{i,j}) \\
& \Rightarrow \text{Overall E} = \sum E_{i,j} \\
\\ \hline \\ 
&\text{ We need } E \geq 1 \\
&\Rightarrow \left [ \sum_{i=1}^{k}\sum_{j=i+1}^{k}E_{i,j} \right ] \geq 1 \\
&\Rightarrow \left [ \sum_{i=1}^{k}\sum_{j=i+1}^{k}P_{i,j} \right ] \geq 1 \\
&\Rightarrow \left [ \sum_{i=1}^{k}\sum_{j=i+1}^{k}\left ( \frac{1}{365} \right ) \right ] \geq 1 \\ 
&\Rightarrow \left ( \frac{1}{365} \right ) \left [ \sum_{i=1}^{k}\sum_{j=i+1}^{k}1 \right ] \geq 1 \\
& \Rightarrow \left ( \frac{1}{365} \right )\left [ \sum_{i=1}^{k-1}1 \right ] \geq 1\\
& \Rightarrow \left ( \frac{1}{365} \right )\left [ \frac{k.(k-1)}{2} \right ] \geq 1\\
& \Rightarrow k^2 - k - 730 \geq 0\\
& \Rightarrow k = \left \lceil \frac{1+ \sqrt{1+4*730}}{2} \right \rceil = \left \lceil 27.52 \right \rceil = 28 \\
\\
\end{align*}$ I hope there may be other ways to do this problem and there are other variations to this problem as well (a few are in Kenneth Rosen Book). Please help if there exist other methods. Thanks!","['birthday', 'probability', 'random-variables']"
2140683,What is the dual space if the measure is not $\sigma-$finite?,"Let $(X,M,\mu)$ measure space where $\mu$ is not $\sigma-$finite. What is the dual of $L^1(\mu)$ in this case? For example: Let $X = \{a,b\}$ and define $\mu(a) = 1$, $\mu(b) = \mu(X) = \infty$, and $\mu(\emptyset) = 0$. In this case, is $L^{\infty}(\mu)$ the dual of $L^1(\mu)$?","['functional-analysis', 'lp-spaces', 'measure-theory']"
2140690,How to prove a graph is a manifold?,"Let $f$ be a $C^k$ map defined in an open set $U\in \mathbb R^n$, I'm trying to prove this is a manifold. I couldn't find a parametrization. I've tried $\varphi(x_1,\ldots,x_n)=(x_1,\ldots,x_n,f(x_1,\ldots,x_n))$, but I couldn't prove this is an homeomorphism. I need help here.","['general-topology', 'real-analysis', 'smooth-manifolds', 'manifolds']"
2140697,"What is the rigorous definition of ""Touch"" in mathematics?","This is irking me a lot :How do we define ""touch"" rigorously in mathematics. I've literally wasted hours because of this,one example would be a question in my textbook asking to solve the equation of circle which touches a ceratin point and a line of certain equation passes through this point.I assumed it to be tangent line and solved for it but the question assumed that line to be a secant(without stating) and due to this I wasted hours pondering over what I am doing wrong. Does it mean a tangent? Does it mean a secant? Or does a touch satisfy the definitiont hat some ""geometrical object"" withing $\epsilon$ under ceratint constraints Does touch is used in the sense of only once or twice(like secant) or many times(imagine a sinusoidal curve folded around a circle.Thus 'touching' it many times) Why do I ask this? Most of the mathematics books use the words :touch"" throughout the world without a rigorous definition and same for the questions,they don't state what kind of 'touch' they mean and under what conditions. So is there any agreed upon definition of 'touch' reached upon consensus by mathematical community with rigors and well-founded reasoning behind it? FYI: I added certain tags which may not seem directly applicable but by use of those I want to highlight that this question should be answered in general [1 ]context applicable to those fields(since the things like point and 'touch' are closely intermingled with those[ofcourse when applying a certain geometric perspective, to be exact]) [1]I wonder there maybe different definitions of point and touching in different fields like my teacher once gave a brief light  intro into different definitions of 'curve' in light of/w.r.t to different fields such as differential geometry ,topology and then analytic one,although his explanation gave  intuiton(which might be wrong) that these defintion kinds of hint at same thing though seen from different light. So I wonder if there's a general definition?(since generality is seen as 'Beauty' in mathematics) but I am skeptic there might be some exception out there under certain constraint?","['general-topology', 'real-analysis', 'analytic-geometry', 'geometry']"
2140743,Some simple probability,"Brandon has 3 chances to roll a single die. He rolls 2 '6's, and a ‘5’ on his turn. Assuming the dice are fair, what is the probability of (i) ‘6’s on the first two rolls, and a non-six in the third roll, and (ii) getting exactly two ‘6’s? On first glance, I calculated my answer to be i) 1/6 ^3 and ii) 1/6 ^2 . Is this right? I think that each event (roll) is independent. In a game of Monopoly, 2 (fair) six-sided dice are rolled. Every face of each die is labelled 1 to 6.
A double occurs if both dice land up on the same number.
Instead of rolling both dice together, Brandon rolls one die at a time. The first die lands on a ‘6’. What is the probability that he rolls a double?
If the first die lands on either ‘1’, ‘2’, ‘3’, ‘4’, ‘5’ or ‘6’, what is the probability that he rolls a double? My answers to both the questions are 1/6 , because I think that the first event where he rolls a specific number, would make up a P of 1. Thus we only need to calculate the second roll. Am I thinking in the right direction?","['statistics', 'probability', 'dice']"
2140757,Searching for numbers like $4\times (102564)=410256$,"Consider the following relation
$$
a_{n+1}\times (a_1\,a_2\cdots a_n\,a_{n+1})=a_{n+1}\,a_1\,a_2\cdots a_n
 \tag{1}
$$
in which $(a_1\,a_2\cdots a_n\,a_{n+1})$ and $(a_{n+1}\,a_1\,a_2\cdots a_n)$ are two numbers with $(n+1)$ digits and $a_i$, $1\leq i \leq n+1$ are integer numbers such that $0\leq a_i \leq 9$, $1\leq i \leq n+1$. One solution for relation $(1)$ are $a_i=1$, $1\leq i \leq n+1$ that is called trivial solution. By full search, just I found one non-trivial 
 solution for relation $(1)$, as follows
$$
4\times (102564)=410256
$$ My question: Is there an analytic method to show that there is only one
non-trivial solution for relation $(1)$ or if it has other solutions how to find these numbers except full search method. I would appreciate any suggestions. Edit(1): By @Test123 comment, we can put conditions like $a_{n+1}a_1<10$. Relation $(1)$ can be expressed by
$$
(a_{n+1}\,a_n-a_{n+1})\,10^{n}+\sum_{i=2}^{n}\,(a_{n+1}\,a_{i-1}-a_i)\,10^{i-1}\,+\, a_{n+1}^2-a_1=0
$$","['number-theory', 'analytic-number-theory', 'systems-of-equations']"
2140766,Find all $x \in \mathbb{Z}_{501}$ for which $51x \equiv 36$,"I am stuck with one problem from my discrete math class and don't know how to solve it. I will be grateful for any help! Find all $x \in \mathbb{Z}_{501}$ for which $51x \equiv 36$, where the multiplication is in $\mathbb{Z}_{501}$. I started solving it like this: \begin{align}
51x & \equiv 36 \pmod{501}\\  
51x & \equiv 36 + k501\\  
51x + 501y & = 36  
\end{align} After this, I found $\gcd(51,501)$, which is $3$: \begin{align}
501 & = 9 \cdot 51 + 42\\  
51 & = 1 \cdot 42 + 9\\  
42 & = 4 \cdot 9 + 6\\  
9 & = 1 \cdot 6 + 3\\  
6 & = 2 \cdot 3 + 0
\end{align} After this, using back-substitution: \begin{align}
3 & = -6 \cdot 501 + 59 \cdot 51\\  
36 & = 708 \cdot 51 - 72 \cdot 501
\end{align} Then I divided equation by the $\gcd$ and solved $17x+167y = 0$. So my final answers are $x = 708 + 167k$ and $y= -72-17k$ (In our case we don't need $y$, though.) Answers from my book are $x_1 = 40$, $x_2 = 207$ and $x_3 = 374$, and I don't know how can I get them.","['diophantine-equations', 'discrete-mathematics', 'modular-arithmetic', 'elementary-number-theory']"
2140823,Easy way to check if multi-variable function is convex,"I know that a function with one variable has to have continuous positive second order derivative for every $x$. Is there an easy way like that to check convexity for multi-variable functions? For example let's consider the function $f(x_1,x_2)=\frac{1}{3}x_1^3-4x_1+\frac{1}{3}x_2^3-16x_2$","['multivariable-calculus', 'convex-analysis']"
2140824,Proof of Uncountable Basis for $\mathbb{N} \to \mathbb{R}$ over $\mathbb{R}$,Does anyone have a simple proof of the uncountability of bases of the vector space of all functions $f : \mathbb{N} \to \mathbb{R}$. I have seen a proof which uses the determinant of the Vandermonde matrix to show the linear independence of functions of the form $f_c=c^n$ but I believe that there might be a simpler one that doesn't require the use of matrices. I have attached a link of another proof that I found online but I find the use of the limit unsettling. https://minhyongkim.wordpress.com/2013/10/23/a-vector-space-of-uncountable-dimension/,"['set-theory', 'linear-algebra']"
2140828,"For (infinite) groups $H\leq G$, is it possible that $G/N\cong H/N$ but $G\ncong H$?","Let G be a group and H be a subgroup. Suppose N is a normal subgroup of G that is contained in H, and that $G/N\cong H/N$. Does this imply that $G\cong H$? If G is finite then $G/N\cong H/N$ obviously implies that $G=H$, so only the inifinite case is to be considered. I have tried to find a counterexample (since this proposition doesn't look true), but haven't been able to.","['abstract-algebra', 'group-theory']"
2140843,"Does there exist a triple of $distinct$ numbers $a,b,c$ such that $(a-b)^5 + (b-c)^5 + (c-a)^5 = 0$?","Does there exist a triple of distinct numbers $a,b,c$ such that $$(a-b)^5 + (b-c)^5 + (c-a)^5 = 0$$ ? SOURCE : Inequalities (PDF) (Page Number 4 ; Question Number 220.1) I tried expanding the brackets and I ended up with this messy equation : $$-5 a^4 b + 5 a^4 c + 10 a^3 b^2 - 10 a^3 c^2 - 10 a^2 b^3 + 10 a^2 c^3 + 5 a b^4 - 5 a c^4 - 5 b^4 c + 10 b^3 c^2 - 10 b^2 c^3 + 5 b c^4 = 0$$ There is no hope of setting $a=b$ or $a=c$ as the question specifically asks for distinct numbers. So, at last I started collecting, grouping, factoring and manipulating the terms around but could find nothing. Wolfram|Alpha gives a solution as : $$c=\dfrac{1}{2}\big(\pm\sqrt{3}\sqrt{-(a-b)^2} + a+b\big)$$ How can this solution be found? Another thing I notice about the solution is that it contains a negative term inside the square root, so does that mean that the solution involves complex numbers and that there is no solution for $\big(a,b,c\big)\in \mathbb {R}$ ? I am very confused about how to continue. Can anyone provide a solution/hint on how to 'properly' solve this problem ? Thanks in Advance ! :)","['algebra-precalculus', 'contest-math']"
2140906,"The plastic number, and Padovan and Perrin-like sequences","The ratio of $P_{n+1}$ to $P_n$ tends toward the plastic number ( https://en.wikipedia.org/wiki/Plastic_number ) as $n$ approaches infinity for the Padovan and Perrin sequences. There are other sequences that have this property? What makes the Padovan and Perrin sequences the most fundamental of such sequences? Are they equally fundamental, whatever equally fundamental may mean in this case? What is the most fundamental way of describing the relation between these sequences?",['number-theory']
2140933,Does $a\otimes b=0$ in $M\otimes_R N$ imply $ar=0$ or $rb=0$ for some non-zero $r\in R$?,"Let $R$ be a ring and let $M$ be a right $R$-module and $N$ be a left $R$-module. Then $M\otimes_R N$ is the tensor product over $R$. Consider $a\in M$ and $b\in N$ such that the pure tensor $a\otimes b=0$.
Then I understand that this does not imply that $a=0$ or $b=0$. My question is: is there $r\in R$, $r\ne0$ such that $ar=0$ or $rb=0$? If the question is true, I want to know the proof. If not, could you give me some counterexample?","['abstract-algebra', 'modules', 'tensor-products']"
2140943,How to prove $\lim \limits_{x \to 0}\frac {\tan (x)}{x} = 1$?,"I was going through a Calculus Textbook, when came across the following two identities : $$\lim \limits_{x \to 0}\dfrac {\sin (x)}{x} = 1
\qquad\text{and}\qquad\lim \limits_{x \to 0}\dfrac {\tan (x)}{x} = 1.$$ The first one is really popular/famous and has many proofs. But I am more interested in the second one. The fraction $\frac {\tan (x)}{x}$ becomes $\frac {0}{0}$ at $x=0$ , so the easiest approach is the L'Hopital's Rule. So $$\lim \limits_{x \to 0}\dfrac {\tan (x)}{x} = \dfrac{\frac{d}{dx}\tan(x)}{\frac{d}{dx}x} = \dfrac{\sec^2(x)}{1}
\\ \implies \lim \limits_{x \to 0}\dfrac {\tan (x)}{x} = \sec^2(0) = 1.$$ A geometrical proof of the same can be found here . I am looking for some non-geometrical proof for this identity.","['limits-without-lhopital', 'trigonometry', 'calculus', 'limits']"
2140983,PDE/Analysis graduate courses,"I'm just starting my graduate studies in Analysis and PDE's and am a bit lost about what topics should I cover in order to do a good Phd program.
I`ve already done the usual undergrad courses, plus Real and complex analysis (graduate level), functional analysis and measure theory. So, if you guys can recommend me which courses I should do, (I can get my university to open new courses as needed), and which books I should study, it'd make me really happy","['book-recommendation', 'analysis', 'partial-differential-equations']"
2140990,Showing that a function is Frechet Differentiable,"If I have a map $K\times K\rightarrow K$, which maps $(x,y)$ to the product $xy$. How would i prove by direct caculation that the map is Frechet Differentiable without using the product rule. I've been trying for a while but haven't really got anywhere. Any help would be greatly appreciated, thanks","['ordinary-differential-equations', 'linear-algebra']"
2141012,Continuous Random Variables,"Given the function: $$
f(x) = \begin{cases} 0 & x<0, \\ a(b-x) & 0\le x\le b, \\ 0 & b<x, \end{cases}
$$ where $a, b ∈ (0, ∞)$. We also know that $\operatorname{E}(X) = 1$. I need to find out $a,b$ and the distribution function. I made an equation system using $\operatorname{E}(X)=1$ and $F(X)=1$ from which I got $a = 2/9$ and $b = 3$, but I'm not really sure if my method is correct and I'm a bit lost on how to calculate the distribution function. Any help is greatly appreciated! :) $$\operatorname{E}(X)=\int_0^b y f(y) \,dy,$$
This gave me $ab^3=6$. $$F(X)=\int_0^b f(y) \, dy$$
This gave me $ab^2=2$.","['statistics', 'probability']"
2141021,Evaluate $\lim_{n\rightarrow\infty} \frac{a_n}{b_n}$,"Let $a_n$ and $b_n$ be a recursive sequence with seed value $a_0=0,a_1=1$, $b_0=1$ and $b_1=2$ such that $$\begin{align} \\ &a_{n+1}=(4n+2)a_n+a_{n-1}\\\\&b_{n+1}=(4n+2)b_n + b_{n-1} \end{align}$$ Find $\displaystyle\lim_{n\rightarrow\infty} \frac{a_n}{b_n}$. (Ans. $\frac{e-1}{e+1}$) I don't know how to start. Any help would be appreciated.","['recurrence-relations', 'real-analysis', 'sequences-and-series', 'limits']"
2141037,Fundamental period of two functions,I have the function $$f(t)=\sin(t)+\sin(\sqrt2t)$$ I would like to calculate the fundamental period of $f(t)$. I know that the period of $\sin(t)$ is $2\pi$ and the period of $\sin(\sqrt2t)$ is $\sqrt2\pi$. I sense that I must work out the lcm of $2$ and and $\sqrt2$ but I'm unsure on how to do this.,"['algebra-precalculus', 'periodic-functions', 'trigonometry']"
