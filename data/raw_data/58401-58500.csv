question_id,title,body,tags
642924,I want a good dictionary of mathematics/ geometry,"I noticed I a made a mistake in some geometrical terminology and wanted to better my life by buying  a new dictionary of mathematics or more specialised Geometry. (okay I am just a shopaholic for maths and books) i went to my local bookshop (and that was one of the biggest bookshops in London UK) but was a bit disapointed by what I could buy, there was only the ""Penguin Dictionary of Mathematics"" and the ""Oxford Dictionary of Mathematics"" I did some tests First test ""polar"": (see http://en.wikipedia.org/wiki/Pole_and_polar , this was a term I used in a wrong maner) 
Penguin does mention it but the description is a bit wonky, only explained for an ellipse and doesn't mention inversion Oxford doesn't mention polar at all, it goes straight to ""polar coordinates"" Second test "" stereographic projection "" ( see http://en.wikipedia.org/wiki/Stereographic_projection , specially the description or drawing should make sure that you can use this projection for more than a half sphere , and what is the name of the point where the lines start from, ""the pole"") Oxford, doesn't give related terminology (no wonder pole was missing anyway)
Penguin, bad drawing , looks like only a half spere can be projected. So at the end I was a disapointed in both of them, can somebody advice a better reference than the two above? I am specially interested in geometrical terms, and do like figures and construction instructions,  my budget is about the price of the two above together, systematic dictionaries (terms related to one object put together) would be even better. Or maybe even a geometry textbook with a very extensive glossary. a version for a kindle would also be okay. Any suggestions for me spending my new year money? (and getting used to use the right terminology)","['geometry', 'self-learning', 'reference-request']"
642939,What does the $L^p$ norm tend to as $p\to 0$? [duplicate],"This question already has answers here : Limit of $L^p$ norm when $p\to0$ (4 answers) Closed 5 years ago . This is something I was thinking about, so I'm going to post it as a question and post my own answer. I hope that anyone who wants will comment, correct me if I'm wrong, and add their own knowledge and thoughts. Suppose $f:[a,b]\to \mathbb{R}$ is a positive, continuous function. The $L^p$ norms of $f$ are the analogs to the weighted power means of a group of positive numbers $a_1, \dotsc, a_n$. (Perhaps it would be more precise to say that the expressions $\left(\int_a^b\frac{f^p}{b-a}dx\right)^{1/p}$ are the analogs.) The power means are given by $$M_p(a_1, \dotsc, a_n)=(w_1a_1^p + \dotsb + w_na_n^p)^{1/p},$$ where $w_i$ such that $\sum w_i =1$ are any weights we like (the simplest case is when $w_i=1/n$ for all $i$). It is well-known (see here ) that the power means $M_p$ tend to the geometric mean as $p\to 0$. What does $$\left( \frac{\int_a^b f(x)^p}{(b-a)}\right)^{1/p}$$ tend to as $p\to 0$?","['average', 'calculus', 'integration', 'lp-spaces']"
642944,"If $f_j \rightharpoonup f$ weakly in $W^{1,p}$ then $f_j \to f$ strongly in $L^p$?","Suppose $1<p<\infty$ and $\Omega$ is an open bounded set in $\mathbb R^n$ with nice boundary (say Lipschitz or even better). Let $(f_j)_j \subset W^{1,p}(\Omega)$ s.t. $f_j \rightharpoonup f$ weakly in $W^{1,p}(\Omega)$. Is it true that $f_j \to f$ strongly in $L^p(\Omega)$? For sure it is true that $f_j \rightharpoonup f$ and $\nabla f_j \rightharpoonup\nabla f$. 
Moreover, we should have the strong convergence of a subsequence thanks to reflexivity: $(f_j)_j$ is bounded hence is has a strong convergent subsequence in $L^p(\Omega)$ because the embedding $W^{1,p} \to L^p$ is (always) compact. Thanks.","['convergence-divergence', 'sobolev-spaces', 'weak-convergence', 'real-analysis', 'weak-derivatives']"
642946,The difference between a finite set and an ordered $n-$tuple? Proving the set of all finite subsets of a countable set is countable.,"For my point-set topology class, I'm working on proving the theorem: The set of all finite subsets of a countable set is countable. Please don't post the proof of the theorem. The proof was easy for the case of the set being finite, so now I'm working on the case that the set is infinite. I'm trying to use a result that we already proved: If $S$ and $T$ are countable sets, then $S \times T = \{ (s,t) | s \in S, T \in T\}$ is also countable. Then I'm saying, if $S$ is the set under consideration, and $n \in \mathbb{Z},n \geq 0$, then define $T_n = \{ U \subset S |\ |U| = n\}$. Then if $T$ represents the set of all finite subsets of $S$, it is clear that $T = T_0 \cup T_1 \cup T_2 \cup \cdots$. Also, since there are countably many different $T_i$, then from another theorem we already proved, as long as every $T_i$ is countable, then their union will also be countable. So, now I'm trying to just demonstrate that every $T_i$ is countable. Can I do it the following way? I think I'm wrong, because I think I might be confusing a finite set of cardinality $n$ with an ordered $n-$tuple.
\begin{align*}
T_0 & = \{ \{ \} \} \text{ is countable.} \\
\Rightarrow T_1 & = T_0 \times S \text{ is countable.} \\
\Rightarrow T_2 & = T_1 \times S \text{ is countable.} \\
\Rightarrow T_3 & = T_2 \times S \text{ is countable.} \\
\vdots
\end{align*}
Hence all of the $T_i$ are countable. I'm fairly certain this is wrong, so if you could explain to me what I'm doing wrong (and maybe point me in the right direction) without telling me the full answer, I would be very grateful! Update - I just got the idea, could I argue that $T_2 \subset T_1 \times S$, and since $T_1$ and $S$ are each countable, $T_1 \times S$ is countable, so $T_2$ is also countable? And then continue this argument for $T_3, T_4, \ldots$? I'm still a little worried that it might not be valid to claim that $T_2 \subset T_1 \times S$.","['general-topology', 'elementary-set-theory']"
642948,Does this integrating factor look right?,I am given $dy/dx-y-e^{3x}=0$ I moved $e^{3x}$ to the right side getting: $dy/dx-y=e^{3x}$ I then figured the integrating factor would be: $u(x)=e^{\int-1 dx}$ Therefore $u(x)= e^{-x}$,['ordinary-differential-equations']
642957,A problem related to the submarine puzzle,"Submarine puzzle: A submarine is located at an integer somewhere along the number line.
  It is moving at some integral velocity (an integral number of units
  per second). Every second you may drop a bomb which will destroy the
  submarine if the submarine is at that location. Can you be guaranteed of destroying the submarine? If so, what
  strategy would you use? (from http://math-fail.com/2011/01/submarine-puzzle.html ) And the answer is to enumerate all $(a,b)$ pairs, where $a, b$ are integers and the location of the submarine at time $t$ equals to $at+b$. My question is, if now $a, b$ can be any real numbers, and the bomb can now destroy the submarine in a region of length 1, i.e. if at time $t$ the bomb is dropped at $x_t$ and $x_t - 0.5 \le at+b \le x_t+0.5$, the submarine will be destroyed. Then can we be guaranteed to destroy the submarine? Some thinking: When $b$ is given, the mission can be done by enumerating $a$ in all rational number (since rational number is dense). When $a$ is restricted to an integer, the mission can be done by the same method as above. For general case, I think it is not possible to destroy the submarine, but I cannot prove it.",['analysis']
642971,Find $\alpha$ such that the given point is critical for a implicitly defined funtion.,"Can anyone check my solution for this exercise? Let $F:\mathbb{R}^3\rightarrow\mathbb{R}$ be given by $F(x,y,z) = \alpha xz + x\arctan(z) + z\sin(2x+y) -1.$ Prove that a function $z=f(x,y)$ can be defined around $(0, \pi/2,1)$ and find $\alpha$ such that $(0, \pi/2)$ is a critical point of $f$ . To show that $z=f(x,y)$ can be defined around $(0,\pi/2,1)$ I should apply the implicit function theorem, this is, I should check that $F(0,\pi/2,1)=0$ and $\displaystyle\frac{\partial F}{\partial z}(0,\pi/2,1) \neq .0$ I have $F(0,\pi/2,1) = \alpha(0)(1) + (0)\arctan(1) + (1)\sin(\pi/2) -1 = 0$ ; and also $\displaystyle\frac{\partial F}{\partial z} = \alpha x + \displaystyle\frac{x}{1+z^2}+\sin(2x+y)$ which means that $\displaystyle\frac{\partial F}{\partial z}(0,\pi/2,1) = \sin(\pi/2) = 1 \neq 0$ . Then by the implicit function theorem a function $z=f(x,y)$ can be defined. Now to find $\alpha$ such that $(0,\pi/2)$ is a critical point, this means that must be $\displaystyle\frac{\partial f}{\partial x} = \displaystyle\frac{\partial f}{\partial y} = 0$ . Considering that $\displaystyle\frac{\partial F}{\partial x} = \alpha z + \arctan z + 2z\cos(2x+y), \displaystyle\frac{\partial F}{\partial y} = z\cos(2x+y)$ and $\displaystyle\frac{\partial f}{\partial x} = \displaystyle\frac{\frac{\partial F}{\partial x} (x,y,f(x,y))}{\frac{\partial F}{\partial z}(x,y,f(x,y))}$ , $\displaystyle\frac{\partial f}{\partial y} = \displaystyle\frac{\frac{\partial F}{\partial y} (x,y,f(x,y))}{\frac{\partial F}{\partial z}(x,y,f(x,y))}$ . If $(x,y) = (0,\pi/2)$ then $F(x,y,z) = 0$ implies that $z=1$ . Also $\displaystyle\frac{\partial F}{\partial x}(0,\pi/2,1) = \alpha + \arctan(1), \displaystyle\frac{\partial F}{\partial y}(0,\pi/2,1) = 0$ and $\displaystyle\frac{\partial F}{\partial z}(0,\pi/2,1) = 1$ . Thus, $\displaystyle\frac{\partial f}{\partial y} = 0$ and $\displaystyle\frac{\partial f}{\partial x} = \alpha + \arctan(1) \implies \alpha = -1$ Am I missing something?.","['optimization', 'multivariable-calculus', 'implicit-function-theorem', 'solution-verification']"
642976,Origin of the modern definition of the tensor product,"Due to whom is the modern (i.e. via its universal property) definition of the tensor product, and in which article was it communicated?","['math-history', 'abstract-algebra', 'tensor-products', 'linear-algebra', 'commutative-algebra']"
643024,Complex numbers - Exponential numbers - Proof,"Let $z$ be a complex number, and let $n$ be a positive integer such that $z^n = (z + 1)^n = 1$. Prove that $n$ is divisible by 6. For this problem I am stumped...how should I begin?
Also there's a hint for it: From $z^n = 1$, prove that $|z| = 1$. What does the equation $(z + 1)^n = 1$ tell you? What do the resulting equations tell you about $z$? Could someone give me a hint on where to begin? thanks in advance","['trigonometry', 'complex-numbers', 'proof-writing']"
643040,Hints on evaluating this $\frac{3}{2\pi}\int_0^{2\pi}\frac{e^{-ikx}}{5 - 4\cos(x)} \mathrm dx$?,"I have the following integral I'm trying to solve: $$\frac{3}{2\pi}\int_0^{2\pi}\frac{e^{-ikx}}{5 - 4\cos(x)} \mathrm dx, \quad k \in \mathbb{Z}.$$ I've tried writing the exponential in terms of sines and cosines and then using the usual rational trig function substitutions, i.e. rewriting the integrand as $$\frac{\cos(kx)}{5 - 4\cos(x)} - \frac{i\sin(kx)}{5 - 4\cos(x)}$$ and then using the substitution $t = \tan{x/2}$ , but this doesn't result in anything useful that I could come up because of the different fequencies in the trig functions.  I also tried writing the cosine in terms of complex exponentials, but didn't end up with anything useful either. If the only solution involves residue calculus then please let me know, as I'm not familiar with that subject so I haven't tried anything like that.  Thanks! UPDATE: As was suggested I wrote the $\frac{1}{5 - 4\cos(x)}$ term as a geometric series $\frac{1}{5}\sum\limits_{n = 0}^\infty (\frac{4}{5}\cos(x))^n$ , so now I am trying to evaluate $$\int_0^{2\pi} \cos^n(x) e^{-ikx} dx,$$ but am stuck here again.  I am trying to do this without using the residue theorem, but if that's the only way then so be it!","['calculus', 'integration', 'complex-analysis']"
643084,Limit with geometric sequence,"I computed
 $$\lim_{n \rightarrow \infty } \sqrt[n]{n^n+n^{n+1}+\cdots+n^{2n}} \cdot\left(1-\cos{\frac{3}{n}}\right)$$ $$=\lim_{n \rightarrow \infty } n^2 \sqrt[n]{n^{-n}+n^{-n+1}+\cdots+1} \cdot \left(1-\cos \frac{3}{n} \right) $$
$$=\lim_{n \rightarrow \infty } \sqrt[n]{n^{-n}+n^{-n+1}+ \cdots +1} \cdot \frac{1-\cos \frac{3}{n} }{\frac{9}{n^2}}\cdot 9=\frac{9}{2} $$ 1) Is it correct to extract $n^{2n}$ from $\sqrt[n]{n^n+n^{n+1}+\cdots+n^{2n}}$ the way I did? 2)How do I show that $\lim_{n \rightarrow \infty } \sqrt[n]{n^{-n}+n^{-n+1}+\cdots+1}=1$? I came up with this:
for geometric sequence the sum can be computed as $s_n=a_1\frac{q^n-1}{q-1}$, but I learned this in high school and if I recall correctly we used it for finite number of terms. So I don't know if I can use it here as $n\rightarrow \infty$. $$\lim_{n \rightarrow \infty } \sqrt[n]{n^{-n}+n^{-n+1}+\cdots+1} = \lim_{n \rightarrow \infty } \sqrt[n]{n^{-n}\cdot \frac{n^n-1}{n-1}+1}$$ So I can estimate upper/lower bound: $$\sqrt[n]{1} \le \sqrt[n]{n^{-n}\cdot \frac{n^n-1}{n-1}+1} \le \sqrt[n]n $$ Then:
$$\lim_{n \rightarrow \infty } \sqrt[n]{n^{-n}+n^{-n+1}+\cdots+1}=1$$ Thank you.","['sequences-and-series', 'calculus', 'limits']"
643119,Is there any English version of Récoltes et Semailles?,"I felt like my question isn't appropriate for MO, so I thought maybe I should post it here. I want to read Alexander Grothendieck's ""Récoltes et Semailles"", but I don't know any French. I can easily find the French version, but as you see I need the English version. I have read that there have been several attempts to translate it into English. Is the full version in English available somewhere? My search lead to a website , though I find it kind of hard to navigate, and I don't know how much of the original materials it includes, and of course it is in a web form. I need it in a .pdf or .djvu or any other readable file format.","['algebraic-geometry', 'math-history', 'reference-request', 'soft-question']"
643128,Is $\cos x$ irreducible as a power series?,"Let $\mathbb{Q}_{\mathrm{ent}}[[x]]$ be the ring of entire functions with rational coefficients.  Is 
$$
\cos x \;=\; \sum_{n=0}^\infty (-1)^n\!\frac{x^{2n}}{(2n)!}
$$
irreducible in $\mathbb{Q}_\mathrm{ent}[[x]]$?","['power-series', 'ring-theory', 'irreducible-polynomials', 'complex-analysis']"
643152,Some questions concerning the symmetric group $S_n$,Let $a_n$ be the number of permutations in $S_n$ having an square root. Is it true that $a_{2n+1} = (2n+1)a_{2n}$ ? (experimental data's shows that this is true for small values of $n$). Is there any formula expressing $a_n$ in terms of $n$? Among all elements of $S_n$ which ones has the most number of square roots and what is this max value ?,"['group-theory', 'symmetric-groups', 'combinatorics']"
643155,Mana Maximization (Hearthstone),"I recently started playing Hearthstone and a statistic / probability question came up my mind. Here's a quick breakdown: The game is a turn-based card game which involves ""points"" that you can used called Mana. The amount of Mana each player gets start with 1 (in the 1st turn), 2 (in the 2nd turn) up to 10 (in the 10th turn), then 10 for any turn after that. Each card has a specific Mana costs (also range from 1 to 10) associates with it and each card deck has 30 cards total. Each player gets 3 card to start, with the person going 2nd (since it's a turn-based game) gaining an additional card and an additional freebie Mana that can only be used once. The players have special powers which costs 2 Mana regardless of the hero that they use, and the hero power can be used each turn. Assuming an average game length of 15 to 25 turns, my question is, what combination of cards in terms of Mana cost would maximize expected Mana spendage (i.e. always spend all of your mana at the end of each turn)? Also, the cards you draw are at random (in case that was not clear). I apologize if the explanation above is confusing or unclear; I've only started playing the game a few days ago. I will check regularly to see if I can clarify any of the game mechanics to anyone.","['statistics', 'optimization', 'probability']"
643156,How do I deal with sines or cosines greater than $1$?,"When I'm solving trigonometric equations, I occasionally end up with a sine or cosine that's greater than $1$ -- and not on the unit circle. For example, today I had one that was $3 \tan 3x = \sqrt{3}$, which simplified to $\tan 3x = \frac{\sqrt{3}}{3}$, which simplified to $\sin 3x = \sqrt{3}$ and $\cos 3x = 3$. So far as I know, I can't divide this by $3$ (to isolate $x$) until I get angles with a sine of $\sqrt{3}$ and a cosine of $3$, respectively. So, how do I reduce this cosine so that I can find an angle on the unit circle with that cosine? Or, am I doing something very wrong to get this as a cosine in the first place? Thanks! evamvid","['trigonometry', 'algebra-precalculus']"
643197,Connectedness of the complement of a homeomorph of a ball,"Let $n\geq 2$. My question is in two parts: If $B\subseteq\mathbb{R}^n$ is bounded and homeomorphic to the open unit ball in $\mathbb{R}^n$, is $\mathbb{R}^n\setminus B$ connected? Does the answer depend on the dimension $n$? If $B\subseteq\mathbb{R}^n$ is homeomorphic to the closed unit ball in $\mathbb{R}^n$, is $\mathbb{R}^n\setminus B$ connected? Does the answer depend on the dimension $n$?${}$","['general-topology', 'connectedness']"
643199,Why is a group of order 135 nilpotent?,Why does order 135 imply nilpotent?,"['sylow-theory', 'solvable-groups', 'group-theory']"
643217,How can I solve $\sin(x)=\sin(2x)$?,Solve $\sin(x)=\sin(2x)$ How do I solve this equation for $x$ without a calculator? It seems pretty simple but I'm not sure how to do it.,"['trigonometry', 'algebra-precalculus']"
643224,Prove the given inequality,"$$\sin^{2}A(\tan(B-C))>\sin^{2}B(\tan(A-C)) $$ $$\implies \frac{\sin^2 A}{\sin^2 B} > \frac{\tan(A-C)}{\tan(B-C)}$$ Given if $A>B>C$ and $A+B+C=180^\circ$ Is that implication correct if not then please correct it otherwise try to solve the first inequality. This is not the original problem, but this problem arose when I was solving another trigonometric equation. Now if anybody prove or disprove the above inequality then that will also be the solution of my problem.","['trigonometry', 'inequality']"
643227,"In the context of vectors, is there a difference between the terms ""magnitude"" and ""length""?","I noticed vectors are usually said to have ""length"" and ""direction"", but then it is said that people want to find the ""magnitude"". Is this just a difference in terminology or is there something more to it? For example, here they discuss ""magnitude"" and here they use the word ""length"".","['terminology', 'linear-algebra', 'vectors']"
643283,A definition of injectivity,"Def 1 : A function $f$ is said to be injective just in case: $$\forall a, b \in \mathrm{dom}(f): f(a) = f(b)\Longrightarrow a = b.$$ Will this alternative definition capture the same idea? Def 2 : A function $f$ is said to be injective just in case: $$f^{-1}~\rm{is~a ~function}.$$ If 'no', what might be added to make it work?","['elementary-set-theory', 'functions']"
643287,$\int_{-\infty}^\infty \frac{e^{ax}}{1+e^x}dx$ with residue calculus [duplicate],"This question already has answers here : Residue integral: $\int_{- \infty}^{+ \infty} \frac{e^{ax}}{1+e^x} dx$ with $0 \lt a \lt 1$. (2 answers) Closed 3 years ago . I'm trying to compute $\displaystyle \int_{-\infty}^\infty \frac{e^{ax}}{1+e^x}dx$, $(0<a<1)$ Let $f$ denote the integrand. I'm using the rectangular contour given by the following curves: $c_1: z(t) = R+it, t \in [0, 2\pi]$ $c_2: z(t) = -t+2\pi i, t \in [-R, R]$ $c_3: z(t) = -R + i (2\pi - t), t \in [0, 2\pi]$ $c_4: z(t) = t, t \in [-R, R]$ There is one singularity within the contour, at $z = \pi i$. Expanding out the denominator as a power series shows that it's a simple pole, and allows us to evaluate the residue as $\displaystyle \lim_{z \rightarrow \pi i} f(z)(z-\pi i) = - e^{a \pi i}$ This is computed by expanding $1+e^z$ as a Taylor series around $\pi i$. The first coefficient will be 0, and the second will be $-1$. The rest will have orders of $(z - \pi i)$ greater than 1, and will thus vanish when we take the limit. So the integral over the entire contour is $- 2\pi i e^{a \pi i}$ An easy enough estimate on the $c_1$ shows that the integral vanishes as $R \rightarrow \infty$. With a variable change, c_3 is the same as c_1 and also vanishes.
$c_4$ becomes the integral we want when we take a limit.
$c_2$ becomes $c_4$ with a constant: \begin{align*} \int_{c_2} f(z)dz &= \int_{-R}^{R} \frac{e^{-at}e^{a 2\pi i}}{1+e^{-t}e^{2\pi i}}dt
\\ &= e^{a 2 \pi i}\int_{-R}^{R} \frac{e^{-at}}{1+e^{-t}}dt
\\ &=e^{a 2 \pi i}\int_{R}^{-R} - \frac{e^{au}}{1+e^{u}}du \ \ \ (u = -t, du = -dt)  
\\ &= e^{a 2 \pi i}\int_{-R}^{R} \frac{e^{au}}{1+e^{u}}du
\\ &= e^{a 2 \pi i} I(R)
\end{align*} Where $I(R)$ is the line integral over $c_4$. Putting it all together and taking the limit gives us $\displaystyle \lim_{R \rightarrow \infty} I(R) = \frac{- 2\pi i e^{a \pi i}}{(1 + e^{a 2 \pi i}) }$ But this can't be the value of the integral, because it's a real-valued function integrated over $R$. I can't figure out where I'm going wrong. Note that I've avoided posting all the details of my solution since this is from a current problem set for a class on complex analysis.","['residue-calculus', 'complex-integration', 'integration', 'complex-analysis']"
643298,Do these theorems about power sets hold for the empty set?,"From the definition of the power set as the set of all subsets of a given set, I realize that $\mathcal P(\varnothing) = \{ \varnothing \}$, in other words, the power set of the empty set is the set containing just the empty set. But does this work for some theorems we're proving for homework? Consider the below two theorems: For any set $A$, there is a 1-to-1 function $f$ from $A$ into $\mathcal P(A)$. There is no function from a set $A$ onto $\mathcal P(A)$. I don't need help proving those theorems for non-empty sets, but I am confused about whether or not they are relevant for the empty set. I can't imagine how one could define a function from the empty set into another set, because the empty set doesn't have any elements to act as inputs for the function. Am I correct in thinking this?","['general-topology', 'elementary-set-theory']"
643325,How do I find the orthogonal basis for this plane?,"Question: $P$ is a plane through the origin given by $x + y + 2z = 0$. Find an orthogonal basis v 1 , v 2 ∈ $P$. My answer: I'm assuming the question asks for two vectors that span this plane $P$. But the chapter that this problem is for doesn't say anything about the $x,y,z$ equation of a plane that was given here...so I did some searching online and learned that this helps find the ""normal vector"". In this case it would be $n = (1,1,2)$, right? Then if all the vectors that span this plane are orthogonal to the normal vector, I can use the dot product. I chose the following two vectors: v 1 = $(1,1,-1)$ v 2 = $(3,3,-3)$ Was this question answered correctly?",['multivariable-calculus']
643334,Why integrating by substituion doesn’t directly work for sin squared,"Given that we know this is correct:
$\int\sin^2(u)du=\frac u2-\frac{\sin (2u)}4 + C$ Why can't we use it directly to solve the following equation by u-substitution:
$\int\sin^2(2\pi ft)dt$
Where
$u=2\pi ft$
and $du=2\pi fdt$ (where $f$ is a constant). These are the steps I used (ignoring the $+C$):
$\int\sin^2(2\pi ft)dt=\frac1{2\pi f}\int\sin^2(u)du=\frac1{2\pi f}\left(\frac u2-\frac{\sin (2u)}4\right)$ As you can see, $\frac1{2\pi f}$ distributes on both terms. While in the correct solution, it only multiply the second term. If I use the sine half-angle to replace the sine squared by a cos, and then do the u-substitution, I get the right answer. But I want to understand why it's not working in my more direct approach. I must have understood something wrong about how u-substitution works. Thanks","['trigonometry', 'calculus']"
643367,"If Z is a random variable with a standard normal distribution, what is $P(Z^2 \lt 3.841)$?","If Z is a random variable with a standard normal distribution, what is $P(Z^2 \lt 3.841)$? Can I just square root $3.841$ so that it becomes $P(Z \lt \sqrt{3.841})$ and use the normal distribution table to obtain the probability?","['statistics', 'radicals', 'normal-distribution', 'probability-distributions', 'probability']"
643433,Calculating $\zeta(0)$ by the residue of $\zeta(1)$,"$$\begin {aligned}\pi^{-s/2}\Gamma(s/2)\zeta(s)=&\pi^{-(1-s)/2}\Gamma((1-s)/2)\zeta(1-s) \\
\zeta(0) =&\frac{\pi^{-1/2}\Gamma(1/2)\zeta(1)}{\pi^{0}\Gamma(0)}=\frac{\zeta(1)}{\Gamma(0)}\end {aligned}$$ so that $\zeta(0)$ is the ratio of the residues of $\zeta(s)$ at $s=1$ end $\Gamma(s)$ at $s=0$. The latter is just $1$ since $$\lim_{s\rightarrow 0} s\Gamma(s) = \Gamma(1)=1.$$ To calculate the residue of $\zeta(s)$ at $s=1$, I simply used the expression, proved in Stein & Shakarchi Complex Analysis p. 171 $$\pi^{-s/2}\Gamma(s/2)\zeta(s) = \frac 1{s-1} -\frac1s +\frac12\int_1^\infty(u^{(-s/2)-1/2}+u^{s/2-1})[\theta(u)-1]du$$ I argued that since the integral on the RHS is holomorphic at $s=1$, the residue of the LHS at $s=1$ must be $1$ (the coefficient of the first fraction). Since $\pi^{-1/2}\Gamma(1/2)$ cancel each other, it should be the case that $\operatorname {res}_{s=1} \zeta(s)=1$, but then my argument says that $\zeta(0) = 1$. Where did I miss the $-\frac12$?","['riemann-zeta', 'complex-analysis']"
643434,What is the probability that no letter is in its proper envelope?,"Five letters are addressed to five different persons and the corresponding
envelopes are prepared. The letters are put into the envelopes at random.
What is the probability that no letter is in its proper envelope?","['probability', 'derangements']"
643463,Closed form for a trigonometric partial sum,I know that: $$\sum_{k=1}^n\arctan(2k^2)=\frac{\pi n}{2}-\frac{1}{2}\arctan(\frac{2n(n+1)}{2n+1})$$ Can a similar closed form expressions be given for $\sum_{k=1}^n \arctan(k^2)$? I was able to simplify it to: $$\sum_{k=1}^n\arctan(k^2)=\frac{\pi n}{2}-\arctan(\frac{2n(n+1)}{2n+1})+\sum_{k=1}^n\arctan(\frac{1}{4k^6+3k^2})$$ But I can't simplify the sum on the right hand side.,"['trigonometry', 'closed-form', 'summation', 'trigonometric-series']"
643475,Generalizations of Hilbert's Syzygy theorem,"Hilbert's Syzygy theorem states that a minimal free resolution of a finitely generated graded module over a (standard graded) polynomial ring in $n$ variables $k[x_1, \ldots, x_n]$ does not have more than $n+1$ terms in it.  To what rings other than the polynomial ring has Hilbert's theorem been generalized?  Does it hold for polynomial rings which are not standard graded?  Please give me a reference if the answers to these are known.",['algebraic-geometry']
643497,Find all proper nontrivial subgroups of $\mathbb Z_2 \times \mathbb Z_2 \times \mathbb Z_2$ - Fraleigh p. 110 Exercise 11.10,"$\newcommand{\lcm}[0]{\mathrm{lcm}}$ I tried to fill in the steps but I'm confounded by this solution . Here $i$ is the identity element, not $e$ . Because $\lcm(2, 2, 2) = 2$ hence all non-identity elements of $\mathbb{Z_2} \times \mathbb{Z_2}\times \mathbb{Z_2}$ ? have order 2. Because $|\mathbb{Z_4}| = 4$ hence $\mathbb{Z_2} \times \mathbb{Z_2}\times \mathbb{Z_2}$ has no subgroups $\simeq \mathbb{Z_4} $ . $\color{darkred}{(1.) \text{ Is this perfect? }}$ By cause of Fraleigh p. 61 Theorem 6.6, any subgroup of a cyclic group is cyclic. $\mathbb{Z_2} \times \mathbb{Z_2}\times \mathbb{Z_2}$ is cyclic hence the seven non-identity elements of order 2 generate 7 distinct subgroups. $\color{darkred}{(2.) \text{ Where does the 7 crop up from? Why are these distinct subgroups? }}$ By cause of Theorem 207 , $|subgroup|$ divides $|group|$ hence these 7 subgroups are of order $2$ . There are seven subgroups of order 4 that are all isomorphic to the Klein 4-group. $\color{darkred}{(3.) \text{ Where did this spring up from? Why fret about this? }}$ To list these subgroups, number the elements of $\mathbb{Z_2} \times \mathbb{Z_2}\times \mathbb{Z_2}$ . To construct a subgroup of order 4 in $\mathbb{Z_2} \times \mathbb{Z_2}\times \mathbb{Z_2}$ , start by choosing any two of the elements of order 2, call them $x,y$ and then add these elements together to get a third element $\color{green}{x + y}$ . $x,y$ has order 2 hence $\color{green}{x + y}$ has order 2. $\color{darkred}{(4.) \text{ Why? Is this true in general if $|x| \neq |y|$?  }}$ Notice $y + \color{green}{(x + y)} = x + 2y = x + id \tag{$\dagger$}$ $x +  \color{green}{(x + y)} = 2x + y = id + y \tag{$\ddagger$}$ This makes it clear that $\{i, x, y, x+y\}$ is a subgroup of order 4. $\color{darkred}{(5.) \text{ How? I don't see this. }}$ Also notice $\{i, x, y, x+y\}$ could've been constructed by starting from choosing either $\{y, x + y\}$ or $\{x, x + y\}$ . If we chose $\{y, x + y\}$ , add these elements to induce $x$ from $(\dagger)$ . If we chose $\{x, x + y\}$ , add these elements to induce $y$ from $(\ddagger)$ . There are $\dbinom{7 \text{ elements of order 2 } \in \mathbb{Z_2} \times \mathbb{Z_2}\times \mathbb{Z_2} }{2}$ choices to induce any pair of elements of order 2.
But we noted in the last paragraph, for each pair of $\{x,y\}$ , $\{y, x + y\} and \{x, x + y\}$ are two other pairs that determine the same subgroup of order 4. Hence conclude there are $21/3 = 7$ distinct subgroups of order 4. They are: $\{i, a, b, a+b\}, \{i, a, c, a + c\}, \{i, a, g,a+g \}, \\
\{i, b, c, b+c\}, \{i, b, e, b+e \}, \qquad \{i, c, d, c+ d\}, \qquad \{i, d, e, d+e\}$ . $\color{darkred}{(6.) \text{ Where did these 7 subgroups crop up from?
Are there better ways to find them}\\ \text{than  sallying forth one-by-one:}\\ \{i, a, b, a+b\}, ..., \{i, a, f, a+f\},\{i, b, c, b+c\}, ...,\{i, b, f, b+f\},...,\{i, d, e, d+e\},\{i, d, f, d+f\}, \{i, e, f, e+f\} }$ $\color{darkred}{(7.) \text{ How do you know these 7 are subgroups without doing the One-Step Subgroup Test?}}$ Update Jan. 19 2014: I updated questions (2.) and (6.) overhead.","['cyclic-groups', 'group-theory', 'solution-verification']"
643504,Understanding the Affine Case of a Stacky Result,"I'm going through Vistoli's sections of FGA Explained to begin to understand stacks. It is well-known and proven in the text that the fibered category $QCoh$ of quasi-coherent sheaves is a stack in the fpqc topology. In particular then, given two quasicoherent sheaves $\xi$ and $\eta$ on a scheme $S$, the functor $Hom_U(\xi,\eta):Sch$/$U\rightarrow(Set)$ sending each object $X\rightarrow U$ to the set $Hom_{O_X}(\xi|_X,\eta|_X)$ should be a sheaf in the fpqc topology (this is proposition 4.7 for those who have the text). So taking $U=SpecA$ affine, $X=U \rightarrow U$ the identity and $V=SpecB \rightarrow U$ a faithfully flat morphism (hence an fpqc covering of $U$), we should have an exact sequence $0 \rightarrow Hom_{O_U}(\xi,\eta)\rightarrow Hom_{O_V}(\xi|_V,\eta|_V) \rightarrow Hom_{O_{V \times V}}(\xi|_{V \times _U V},\eta|_{V \times _U V})\rightarrow0$ where the second nonzero map is given by the difference between the pullbacks along the two projections. Ok, so with all this fancy FGA stuff established, my question is actually pretty goofy and basic. Since everything above is affine, we can replace all the schemes by rings and all the sheaves by modules to obtain: $0 \rightarrow Hom_{A}(M,N)\rightarrow Hom_{B}(M\otimes_A B,N\otimes_A B)$
$\rightarrow Hom_{B \otimes_A B}(M\otimes_A B\otimes_A B,N\otimes_A B\otimes_A B)\rightarrow0$ My question is: what exactly is the second nonzero map in simple terms? For example, if $\phi \in Hom_{B}(M\otimes_A B,N\otimes_A B)$ and $\psi$ is its image in $Hom_{B \otimes_A B}(M\otimes_A B\otimes_A B,N\otimes_A B\otimes_A B)$, can you give me a formula for $\psi(m\otimes b \otimes b')$ in terms of $\phi$ and the letters given.  Because the way I'm interpreting the second map, it's always zero, which I'm pretty sure is wrong. EDIT: Vistoli's section of FGA Explained is available here: http://arxiv.org/abs/math/0412512 .",['algebraic-geometry']
643531,"If $\,A^k=0$ and $AB=BA$, then $\,\det(A+B)=\det B$","Assume that the matrices $A,\: B\in \mathbb{R}^{n\times n}$ satisfy 
$$
A^k=0,\,\, \text{for some $\,k\in \mathbb{Z^+}$}\quad\text{and}\quad
AB=BA.
$$ Prove that $$\det(A+B)=\det B.$$","['matrices', 'matrix-calculus', 'linear-algebra', 'matrix-equations', 'determinant']"
643552,Limit of $(a_{n+1}-a_{n}) e^{-a_{n}}$,"Consider a sequence $\{a_{n}\}$ satisfying $$a_{n+2}-2a_{n+1}+a_{n} \geq C > 0$$
Do we have : $\lim_{n\to \infty}(a_{n+1}-a_{n}) e^{-a_{n}}=0$ ? PS : This question is inspired from this continuous version which is still unanswered.","['sequences-and-series', 'limits']"
643588,"Why is $\operatorname{Hom}(A, B)$ an abelian group?","Can someone please explain why a Hom-set (the set of all morphisms between two abelian groups $A$ and $B$) does also form an abelian group with addition? By the way both groups $A$ and $B$ have the same operation ""$\cdot$"". Edit:  Yeah I've tried but: If $f$ and $g$ are morphisms between $(A,\cdot)$ and $(B,\cdot)$ then the result should still be a morphism from $(A,\cdot)$ to $(B,\cdot)$ right? (If the conclusion is true?) So the new $h=f+g$, which should be a morphism should respect $h(x\cdot y)=h(x)\cdot h(y)$ which adds up to:
$$f(xy)+g(xy)=f(x)g(x)+f(y)g(y)+f(x)g(y)+f(y)g(x)$$
which means that $f(y)g(x)+f(x)g(y)$ is $0$ and I can't explain that.","['abelian-categories', 'group-theory', 'abelian-groups']"
643594,"Mathematically, why does $[ma]\mathrm{d}x = [mv]\mathrm{d}v$?","I am taking an introductory level class, Physics with Calculus, using Priscilla Laws' Workshop Physics. The activity guide has asked me to prove that: $$ma\,\mathrm{d}x = mv\,\mathrm{d}v$$ My physics instructor informed me that the correct method to prove this is: Start with: $$ma\,\mathrm{d}x$$ Knowing that: $$a = \frac{\mathrm{d}v}{\mathrm{d}t}$$ Therefore: $$ma\,\mathrm{d}x = m\frac{\mathrm{d}v}{\mathrm{d}t}\mathrm{d}x$$ Rearrange using laws of multiplication: $$m\frac{\mathrm{d}v}{\mathrm{d}t}\mathrm{d}x = m\frac{\mathrm{d}x}{\mathrm{d}t}\mathrm{d}v$$ Knowing that: $$v = \frac{\mathrm{d}x}{\mathrm{d}t}$$ Therefore: $$m\frac{\mathrm{d}x}{\mathrm{d}t}\mathrm{d}v = mv\,\mathrm{d}v$$ Therefore: $$ma\,\mathrm{d}x = mv\,\mathrm{d}v$$ But every single mathematician I have talked to agrees; this is magic math. It is not good practice to, quite frankly, abuse infinitesimals in this way. And yet, the book suggesting that we do this has been under the careful eye of physicists nationally for years -- Surely if doing the above were wrong, someone would have pointed it out by now, and insisted that it be removed. By this reasoning, clearly the above is not necessarily wrong per se, but it is incredibly clear that there is a lot more mathematical complication going on under the hood which makes the above possible. It is my goal here to understand why in the name of goodness the above works, and what rules had to be maintained in order to ensure its validity. This brings me to the first part of my question -- Why does the above work? What could go wrong using the methods used above? How can I avoid making mistakes when manipulating infinitesimals in that way? Unfortunately, being an entry level calculus student, I am frankly not equipped to deal with such topics as partial derivatives, differential equations, or infinitesimals/hyperreals. Even so, I have been determined to understand, at least informally, the underlying math behind the above. And what little ""knowledge"" I have amassed thus far implies something which I find disturbing. Before I explain what I, personally, see wrong with the above, please allow me to informally define what I understand differentials to be, as well as a more explicit notation through which to write them. I am sure that an official notation exists for this, but I do not know enough in mathematics to use such a notation. When we have $y = f(x)$, and say $f'(x) = \frac{\mathrm{d}y}{\mathrm{d}x}$, what we are ""really"" saying is this: The ratio between the infinitely small change in $y$ at some solution set $x$ resulting from a corresponding infinitely small change in $x$, and the infinitely small change in $x$ at some location $x$ from a corresponding infinitely small change in $x$. The above sentence translates into mathematical notation, literally as: $$\lim_{h\to 0} \biggl[\frac{f(y + h) - f(h)}{x + h - x}\biggr]$$ where $\mathrm{d}y = \lim_{h\to 0} [f(x + h) - f(x)]$, and $lim_{h\to 0} [dx = (x + h - x)]$. Now, this is all fine and dandy, until we have a relationship such as: $$y = xz = f(x, y)$$ Suddenly $\mathrm{d}y$ could be either: $\mathrm{d}y = (f(x + h, z) - f(x, z))$ or: $\mathrm{d}y = (f(x, z + h) - f(x, z))$ (In fact, there exists a third situation where $\mathrm{d}y = y + h - y$ if $y$ is what we are taking the derivative/integral with respect to.) With these rather tedious ambiguities, it seems prudent to not only state the variable whose change we are observing, but to also state which variable we are changing to create this change. Furthermore, it would be nice if we could also keep track of what values all of our variables start with. Therefore, I shall define a new syntax to make this simpler: if $y = f(x)$ then: $$f'(A.x) = \frac{\mathrm{d}y_{A_x}}{\mathrm{d}x_{A_x}}$$ Where $A$ is the solution set vector (containing values of $x$, and $y$, and for instance $A.x$ is the $x$ value contained by $A$) where all of our variables start, and where $\mathrm{d}y_{A_x}$ means: Starting with the values contained in $A$, and changing $x$ by some infinitesimal $h$, what is observed change in $y$? and when $\mathrm{d}x_{A_x}$ means: Starting with the values contained in $A$, and changing $x$ by some infinitesimal $h$, what is observed change in $x$?"" By these definitions, we see that our notion of $f'(x)$ hasn't changed -- we are merely being more specific about what's changing, and what changes we are observing. Now, using this new notation, and trying to use the same proof that my physics instructor suggested, we run into some issues. Executing the first four steps: Start with: $$ma\,\mathrm{d}x_{A_x}$$ ($\mathrm{d}x_{A_x}$ was chosen (as opposed to, for instance, $\mathrm{d}x_{A_t}$) because it was originally the trailing $\mathrm{d}x$ of an integral taken with respect to $x$) Knowing that: $$a = \frac{\mathrm{d}v_{A_t}}{\mathrm{d}t_{A_t}}$$ Therefore: $$ma\,\mathrm{d}x_{A_x} = m\frac{\mathrm{d}v_{A_t}}{\mathrm{d}t_{A_t}}\mathrm{d}x$$ Rearrange using laws of multiplication: $$m\frac{\mathrm{d}v_{A_t}}{\mathrm{d}t_{A_t}}\mathrm{d}x_{A_x} = m\frac{\mathrm{d}x_{A_x}}{\mathrm{d}t_{A_t}}\mathrm{d}v_{A_t}$$ We end up with the expression $m\frac{\mathrm{d}x_{A_x}}{\mathrm{d}t_{A_t}}\mathrm{d}v_{A_t}$. Now, in the method suggested by my physics instructor, we wold normally try to replace $\frac{\mathrm{d}x}{\mathrm{d}t}$ (or in this case, $\frac{\mathrm{d}x_{A_x}}{\mathrm{d}t_{A_t}}$) with $v$ -- but there's a problem: $$v = \frac{\mathrm{d}x_{A_t}}{\mathrm{d}t_{A_t}}\text{ NOT }\frac{\mathrm{d}x_{A_x}}{\mathrm{d}t_{A_t}}$$ In order for us to replace $\frac{\mathrm{d}x_{A_x}}{\mathrm{d}t_{A_t}}$ with $v$, $\mathrm{d}x_{A_x}$ would have to equal $\mathrm{d}x_{A_t}$! That's an implication that I am not certain is true, and this is what bothers me about the method prescribed by my instructor. This brings me to the second half of my question: Am I correct in thinking that the method prescribed by my instructor is wrong for this reason? Are the concepts I am conveying here valid, or is there another way of viewing this? Is there an alternative method which I could use to prove the same thing, but does not fall prey to these problems? Does $\mathrm{d}x_{A_x} = \mathrm{d}x_{A_t}$? Will $\mathrm{d}x_{A_x}$ ALWAYS equal $\mathrm{d}x_{A_t}$ by definition, or do they only equal in this case, because of the nature of kinematic motion?","['differential', 'multivariable-calculus', 'calculus']"
643601,$a^n = e$ for $a \in G$ where $G$ is a group with finitely many elements.,"Let $G$ be a group with a finite number of elements. Show that for any $a \in G$, there exists an $n \in \mathbb{Z}^+$ such that $a^n = e$, where $e$ is the identity and $a^n = a * a * a \space ... *\space a$ where $*$ is a binary operation. Being a new student to algebra, I find this question very counterintuitive. Let, for example, $G$ be the group of the positive rational numbers over multiplication. Thus we have the identity $e = 1$ and inverse $\frac{1}{a}$ for any number $a \in G$. I claim that there is no positive integer  $n$ where $2^n = 1$. How does one make sense of all this?","['finite-groups', 'group-theory', 'abstract-algebra']"
643607,On non-Euclidean geometry,"Wandering around Wikipedia, I came across the idea that if we violate the parallel postulate, we arrive at new, non-Euclidean geometries. Specifically, if you violate it in one direction, you get elliptic geometry, and in the other direction you get hyperbolic geometry. It's a fascinating idea, but Wikipedia doesn't say a whole lot about it. I've spent a few weeks turning the idea over in my mind, and I now think I understand it. Basically I want to write down how I think it works, and have someone tell me whether I'm correct or not. However, I'm having trouble not making this into a 50-page essay that nobody will ever read! As best as I can understand it, it's a question of space. Elliptic geometry doesn't have enough of it. Hyperbolic geometry has too much of it. Let me explain... Euclidean geometry is the geometry of flat space. If you take a flat sheet of paper, cut wedges out of it, and glue the edges together, it forces the paper to curve. If you follow that curve far enough, it naturally closes into a complete sphere. Sure enough, if two ships set sail from the north pole on different headings, initially the distance between the two ships grows linearly, just like Euclidean geometry would suggest. However, by the time they reach the equator, they are actually sailing parallel to each other, and after that they actually sail towards each other. (Question: Is elliptic space finite in size? If you travel in a straight line for long enough, do you end up back where you started?) Basically, as you travel outwards, elliptic geometry has ""too little space"", compared to what you would expect from Euclidean geometry. Hyperbolic geometry is harder to think about; the Earth is spherical, but I'm not aware of any simple real-world shape that is hyperbolic. But, logically, if elliptic geometry is the geometry of missing space, hyperbolic geometry ought to be the geometry of too much space. That is, as you travel outwards form a point, you find too much space around you. I don't know exactly ""how much"" extra space, but more than you would expect. (Question: What's the formula for the circumference of a circle in elliptic geometry and in hyperbolic geometry?) This suggests that if two ships set sail towards each other, provided they start off far enough apart and the angle between them is shallow enough, the ""extra space"" that keeps materialising as they travel onward potentially means they could actually miss each other - which would explain why you can have more than one parallel line. At some point, the angle becomes sharp enough that the ships' paths do cross, but at any shallower angle, they will miss. (And there are infinity such angles.) Is any of this correct? Or an I barking up the wrong tree?",['geometry']
643611,How can one actually use Adjacency Matrix for understanding a graph?,"I don't see any real reason why we would use an AM to represent a graph, beside visual appeal and ease. Generally, we would perform matrix operations on Matrices like |A|, Transpose and loads of other things but that magic doesn't seem to add up to what I am looking at, AM. Anyone care to explain or give me some intuition so I may respect AM a bit more and use it to study the graph at hand purely by playing around with the numbers. Obviously, you get the point.","['matrices', 'graph-theory']"
643612,Looking for an elementary solution of this limit,"I was collecting some exercises for my students, and I found this one in a book: compute, if it exists, the limit
$$
\lim_{x \to +\infty} \int_x^{2x} \sin \left( \frac{1}{t} \right) \, dt.
$$
It seems to me that this limit exists by monotonicity. Moreover, since $\frac{2}{\pi}x \leq \sin x \leq x$ for $0 \leq x \leq \pi/2$, I could easily show that
$$
\frac{2}{\pi} \log 2 \leq \lim_{x \to +\infty} \int_x^{2x} \sin \left( \frac{1}{t} \right) \, dt \leq \log 2.
$$
WolframAlpha suggests a ""closed"" form for the integral, and by dominated convergence the limit turns out to be $\log 2$. However, passing to a limit in the $\operatorname{Ci}(\cdot)$ function is not really elementary. I wonder if there is a simpler approach that a student can understand at the end of a first course in mathematical analysis.","['limits', 'calculus', 'integration', 'analysis']"
643613,Any ball is connected?,"Let $X$ be a compact , metric space. 
Assume that the closure of every each open ball it the closed ball with same center and radius. Prove that any ball in this space is connected.","['general-topology', 'connectedness', 'metric-spaces', 'compactness']"
643649,"In a Hilbert space, every bounded and closed set is weakly relatively compact.","My aim is to prove that in a Hilbert space, any bounded sequence has a weakly convergent subsequence. To prove this, I'm trying to prove that: In a Hilbert space, every bounded and closed set is weakly relatively compact I have tried it via Banach-Alaoglu theorem but I find it difficult as this theorem applies to the dual space with the weak-* topology and not the weak one. Anyway I have the feeling that there is an easier way to prove it. Any help would be highly appreciated. Thank you.","['weak-convergence', 'compactness', 'analysis', 'hilbert-spaces', 'functional-analysis']"
643651,Projections are finite morphisms,"Let $X$ be a variety in $\Bbb{P}^n$. I would like to see as simply as possible why the projection of $X$ from a point is a finite map. Suppose $p=(1:0:\ldots:0)\notin X$ and let $\pi:X\rightarrow\Bbb{P}^{n-1}$ be defined as
$$ \pi(x_0:\ldots:x_n)=(x_1:\ldots:x_n)$$ To show finiteness we may consider $U_j=\{x\in X: \ x_j\neq0\}$ and show that the restriction
$$\pi:U_j\longrightarrow \pi(U_j)=Y\subset\Bbb{A}^{n-1}$$
is finite, i.e. any $g\in k[U_j]$ is an integral element over $k[Y]$. Edit: the question really is: how can we practically construct an integral equation for $g$, i.e.
$$g^k+b_{k-1}g^{k-1}+\cdots+b_0=0, \quad b_j\in k[Y]. $$","['commutative-algebra', 'algebraic-geometry']"
643664,On the size of a set of functions such that $f(i)\ne f(i+1)$ for every $i$ (and similar conditions),"For a finite set $A$,let $|A|$ denote the number of elements in the set $A$. (a) Let $F$ be the set of all functions $$f: \{1,2,\ldots,n \} \to \{1,2,\ldots,k\}~~~~~~~~~~ (n\ge 3,k\ge 2)$$satisfying $f(i)\ne f(i+1)$  for every $1\le i\le {n-1}$. Show that $|F|=k(k-1)^{n-1}$. (b) Let $c(n,k)$ denote the number of functions in $F$ satisfying $f(n)\ne f(1)$. For $n\ge 4$, show that $$c(n,k)=k(k-1)^{n-1}-c(n-1,k)$$. (c) Using (b) prove that for $n\ge 3$, $$c(n,k)=(k-1)^n+(-1)^n(k-1)$$ I could solve the part (a),it is quite trivial.But, then next two parts are critical. Please help!","['relations', 'recursion', 'functions']"
643670,How to find Influence function?,"Derive $IF(x;T,F)$ when 
  $$\displaystyle T(F)=\int_{F^{-1}(\alpha)}^{F^{-1}(1-\alpha)}x ~dF(x)$$
  Here $IF$ stands for Influence function. Trial: Here $$\begin{align}IF(x;T,F) &=\lim_{t\to 0}\frac{T((1-t)F+t\Delta_x)-T(F)}t \\ &=\lim_{t\to 0}\frac{g(t)-g(0)}t=\frac{d}{dt}g(t)|_{t=0} \end{align}$$ Then I try to simplify $T(F)$ as $$\int_{F^{-1}(\alpha)}^{F^{-1}(1-\alpha)}x ~dF(x) \\ =\int_{\alpha}^{1-\alpha}F^{-1}(y) ~dy$$ 
Then I am stuck. Please help.","['statistics', 'robust-statistics']"
643679,Lebesgue integral and Cantor set,"I need to evaluate the integral $\int_{[0,1]} f \; d\mu $ using Lebesgue integral
when $d\mu$ is Borel measurement and $f$ is given by: $$ f(x) = \begin{cases}x &x\in C, \\ 
 0&x\in[0,1]\setminus C ,
\end{cases}$$
$C$ is Cantor set. I understand that $\mu(C)=0$, so doesn't it mean that- 
 $$\int_{[0,1]} f \; d\mu =\int_{[0,1]\backslash\ C} f \; d\mu+\int_C f \; d\mu = 0+\int_C x \; d\mu$$
and $\int_C x \; d\mu =0$ because $\mu(C)=0$ ? I think I am misunderstanding something since I also get this ""clue"": if $  m\leq f(x) \leq M $, then $  \int_Am\; d\mu\leq \int_Af\; d\mu \leq \int_AM\; d\mu $. Thank you for your help.","['lebesgue-integral', 'measure-theory', 'lebesgue-measure']"
643680,Can $\le$ be used insted of < in the definition of continuity?,"A common definition of a continuous map $T:M_1\to M_2$ is that for every $x\in M_1$ and every $\varepsilon>0$ there exists a $\delta >0$ such that for all $y$ in $M_1$ $$d_1(x,y)<\delta \implies d_2(T(x),T(y))<\varepsilon,$$ i.e. we use a strict inequality. Now in a proof it reads that $T$ is continuous if for every $x\in M_1$ and every $\varepsilon>0$ there is a $\delta>0$ such that $$\|Tx-Ty\|\le\varepsilon\ \mbox{for all $y$ in $M_1$ satisfying } \|x-y\|\le \delta.$$ Here the norm is given by the metric. Is it correct to use $\le$ instead of the strict inequality <, and can one somehow prove the equality of these definitions? Or is this obviously the same condition? Thanks in advance!","['general-topology', 'continuity', 'real-analysis', 'metric-spaces', 'functional-analysis']"
643702,Why is this true: $\nabla \cdot (S\cdot \vec v )=S:(\nabla \otimes \vec v)+\vec v \cdot (\nabla \cdot S)$?,"I am doing fluid mechanics and I don't understand a particular step that is being used.
It is the following step which I don't understand: $\nabla \cdot (S\cdot \vec  v )=S:(\nabla \otimes \vec v)+\vec v \cdot (\nabla \cdot S)$ (In the above: $S$ is a matrix;  $:$ denotes a double contraction) Can someone please provide me some background/ intuition why this is a logical step?","['fluid-dynamics', 'multivariable-calculus', 'tensors', 'vector-analysis']"
643710,Find ordinal of a strange ordered set,"I was asked the following question: for every $x\in \mathbb R$ we define the set $Q(x)=\{q \in \mathbb Q|q\leq x\}$, the set of all rational numbers less or equal to $x$. Let $M=\{Q(x)|x\in \mathbb R\}$ the set of such sets $Q$, $M$ is a subset of the power set of $\mathbb Q$. 1) is $M$ linearly ordered with the relation $\subseteq$? 2) Find the ordinal $[(M,\subseteq)]$ I managed to show that 1) is true,$\subseteq$ defines a linear order on $M$, but how do I find the ordinal? it's infinite, but it isn't anything related to $\omega$ because $\omega$ has a beginning, it has a smallest value. $M$ doesn't have minimal element with respect to $\subseteq$.","['ordinals', 'elementary-set-theory']"
643730,Question about name-convention for secant and cosecant.,"Ok so if we take a right triangle and consider an angle $\alpha$ we get the following: From here we can define the fundamental trigonometric functions sine and cosine where $\sin(\alpha)=\frac{\text{Opposite}}{\text{Hypotenuse}}$ and $\cos\alpha=\frac{\text{Adjacent}}{\text{Hypotenuse}}$ Now there are 2 new functions called secant and cosecant which are the multiplicative inverses of the sine and cosine functions. What I don't understand is why $\csc(\alpha)=\frac{1}{\sin(\alpha)}$ and $ \sec(\alpha)=\frac{1}{\cos(\alpha)}$ Wouldn't it be easier to let the ""co""-secant  refer to the multiplicative inverse of the ""co""-sine function? Regards.","['trigonometry', 'education', 'reference-request', 'convention']"
643738,Inhomogeneous polynomial and points at infinity,"Let $f=X^2-Y$ be a polynomial in $k[X,Y]$, so $V(Z)$ is a parabola: $V(f)$: According to Bézout theorem the $y$-axis has to intersect the parabola two times. We know the y-axis meets the parabola in $P$. In order to find the point in the infinite of the intersection, let's the homogenization of $f$ be $F=X^2-YZ$. In order to find the points in the infinity we only have to find these points: $$V(F)\cap V(Z)=P_1=\{(0:1:0)\}$$ If we deshomogenize F in $Z$ we get  back $f=X^2-Y$, the points in the finite. Now, if we deshomogenize F in $Y$ and $X$ we get $f_1=X^2-Z$ and $f_2=1-YZ$. $V(f_1)$: $V(f_2)$: My question is what's the meaning of $f_1$ and $f_2$? I'm trying to understand intuitively the meaning of homogenization/deshomogenization of a polynomial and their relation with the points at infinity. I'm sorry if my question is a little vague, but I'm really confused with these concepts. I really need help Thanks a lot EDIT My doubt can be summarize in these questions: What happens if we deshomogenize the polynomial in another variable? (other than $z$) Is this procedure useful to understand the behavior of the curve at a given point? (in our case point $P$)","['algebraic-geometry', 'algebraic-curves']"
643742,Commuting matrices and simultaneous diagonalizability,"It is a known fact from linear algebra that if a set of matrices is pairwise commutable then they are simultaneously diagonalizable. A problem in the book I am currently studying asks to prove this claim using representation theory. Specifically If $G = \{M_1,\ldots,M_k\}$ is an abelian subgroup of $\rm{GL}_d(\mathbb{C}).$ How can one use representation theory to show that the matrices in $G$ are simultaneously diagonalizable?","['matrices', 'linear-algebra', 'representation-theory', 'abstract-algebra']"
643743,How find this $\lim_{n\to\infty}\left(\frac{1}{a_{n}+1}+\frac{1}{a_{n}+2}+\cdots+\frac{1}{a_{n}+b_{n}}\right)=x$,"Prove that for any $x\in[0,\infty)$ there exist sequences of positive integers $\{a_{n}\}_{n\in\mathbb N}$ and $\{b_{n}\}_{n\in\mathbb N}$, such that
$$\lim_{n\to\infty}\left(\dfrac{1}{a_{n}+1}+\dfrac{1}{a_{n}+2}+\cdots+\dfrac{1}{a_{n}+b_{n}}\right)=x.$$ I only know this
$$\lim_{n\to\infty}\dfrac{1}{n+1}+\dfrac{1}{n+2}+\cdots+\dfrac{1}{n+n}=\ln{2}$$ But for my problem I can't. Thank you","['sequences-and-series', 'calculus', 'analysis', 'integers', 'limits']"
643751,Find all subgroups of $\mathbb{Z_2} \times \mathbb{Z_2} \times \mathbb{Z_4}$ isomorphic to the Klein $4$-group.,"John Fraleigh. A First Course in Abstract Algebra (7 edn 2002). p 110. Exercise 11.12. I  have 8 questions on this Yahoo Answer . I know $|\mathbb{Z_2} \times \mathbb{Z_2} \times \mathbb{Z_4}| = 2\cdot2\cdot4$ . $order(\mathbb{Z_2} \times \mathbb{Z_2} \times \mathbb{Z_4}) = \mathrm{lcm}(2, 2, 4) = 4.$ Hence by Lagrange's Theorem, $|\text{subgroup}| = \text{$1$, $2$ or $4$}$ . You need to simply find two (distinct) elements of order 2. $\color{red}{\text{ Why simply two distinct elements of order 2 ?  }  } $ Their sum will also be of order 2.  What are the elements of order 2? $a = (1,0,0), \;
b = (0,1,0), \;
c = (0,0,2) $ These are the ""basic"" ones. $ \color{red}{\text{ How do you deduce these elements? Surely not by trial and error? }  } $ $ \color{red}{\text{ How do you envisage there are more elements of order 2?}  } $ As per p. 61 Theorem 6.6 in the aforementioned Fraleigh textbook, any subgroup of a cyclic group is cyclic. Hence by reason of my question 4 above] the sum of these 2 distinct elements will also have order 2. Those are the ""basic"" ones. Now take all possible sums. $a+b = (1,1,0), \; a+c = (1,0,2), \; b+c = (0,1,2), \; a+b+c = (1,1,2)$ .
These are the only elements of order 2. We will sort these out by the number of $\{a,b,c\}$ that are in the subgroup of $\mathbb{Z_2} \times \mathbb{Z_2} \times \mathbb{Z_4}$ of order 2. $ \color{red}{\text{ Why do we need to sort? }  } $ Notice that you can't have all three, since all three would give you the whole 7 elements of order 2 $ > |V_4| = 4$ . Possibility 1 of 3. Any two of $\{a,b,c\}$ are in the subgroup.   Then these 2 add to determine the third. If any pair of a,b,c are in it, it determines the third. So in this case, you are done -- there are $\binom{3}{2}$ ways to do that: \begin{aligned}
\langle a , b \rangle &= \{ e, a, b, a+b \}\\
&= \{ (0,0,0) , (1,0,0) , (0,1,0) , (1,1,0) \} \\
\langle a , c \rangle &= \{ e, a, c, a+c \}\\
&= \{ (0,0,0) , (1,0,0) , (0,0,2) , (1,0,2) \} \\
\langle b , c \rangle &= \{ e, b, c, b+c \}\\
&= \{ (0,0,0) , (0,1,0) , (0,0,2) , (0,1,2) \}
\end{aligned} Possibility 2 of 3. Only one of $\{a,b,c\}$ is in the subgroup. Finally, what about subgroups that contain exactly one of $\{a,b,c\}$ ?  If it contains a, for example, then it cannot contain a+b, or a+c, since that would give a+(a+b)=b or a+(a+c)=c. I rewrote this Possibility 2 more clearly. Suppose we're working with $a$ . Then why can't this subgroup  contain $a+b$ or $a+c$ ? If it did, then by group closure, $a + (a + b) = b$ or $a + (a + c) = c$ are in the subgroup. This contradicts our supposition that only one of $\{a,b,c\}$ is in the subgroup. So it must contain $\{b + c, a + b + c\}$ . $ \color{red}{\text{ Why must it ""contain $\{b + c, a + b + c\}$""?}}$ This gives our other three groups: $$\begin{aligned}
\langle a , a+b+c \rangle &= \{ e , a , b+c , a+b+c \}\\
&= \{ (0,0,0) , (1,0,0) , (0,1,2) , (1,1,2) \} \\
\langle a , a+b+c \rangle &= \{ e , b , a+c , a+b+c \}\\ 
&= \{ (0,0,0) , (0,1,0) , (1,0,2) , (1,1,2) \} \\
\langle a , a+b+c \rangle &= \{ e , c , a+b , a+b+c \}\\ 
&= \{ (0,0,0) , (0,0,2) , (1,1,0) , (1,1,2) \}
\end{aligned}$$ Possibility 3 of 3 . None of $\{a,b,c\}$ is in the subgroup. In that case, if you have $a+b+c$ , you are out of luck -- any third element will be something like $a+b$ and $(a+b+c)+(a+b)=c.$ $ \color{red}{ \text{ I can't grasp what this Possibility 3 is saying. Why ""out of luck""? How does $a + b + c \implies$ ""any third element will be something like  $a+b$ and $(a+b+c)+(a+b)=c$}""?  } $ Done. If you want a more ""advanced"" explanation of this, what's neat is that you have this: There are 7 elements of order 2. A subgroup contains exactly 3 of them. Any two of these elements determines the third (and thus the entire subgroup). Now notice the axioms of a finite projective plane of order 7: There are 7 points. Any line contains exactly 3 points. Any two points determine a unique line. Here, just make the correspondence point $\longleftrightarrow$ element of order 2 line $\longleftrightarrow V_4$ subgroup But a finite projective geometry of order 7 has 7 lines. That's the number of lines (subgroups) we already found by the ""boring"" method. But this is much cooler! Here is a diagram of this geometry: It is called the ""Fano plane."" I have labeled the points with their corresponding elements in your group. Notice how the three lines of the first type are the sides of the triangle, the three of the last type go from vertex to midpoint, and the ""exceptional"" line is actually a ""circle"" in shape (here ""line"" doesn't mean ""straight line"") through the three midpoints. I got an email from the asker, asking for clarification...
First, we can ignore the elements of order 4. $ \color{red}{\text{ Why can we ""ignore the elements of order 4""?}}$ We are looking at the subgroup of Z2 x Z2 x Z4 which consists of elements of order 2. Because the group is [A]belian, this is a legitimate subgroup. Call it H. Then the set ${a,b,c}$ is a generating set of H. Further, H has order 8. It has 7 nonzero elements, and they will all be order 2 by definition.
All Klein groups are subgroups of H, obviously. $\color{red}{\text{ This isn't obvious to me. How are all Klein groups subgroups of $H = {a, b, c}$?}}$ Then you just use the above logic to figure out how many subgroups of $H$ there are. The above logic tells us how. You ask why you can't have $a,b,c$ all in the same Klein group, but ${a,b,c}$ generates $H$ , so if they are in the same subgroup, that subgroup is too big to be a Klein group. The fact that $H$ forms a projective geometry is awesome, but if you are having trouble grasping the basic definitions, you can ignore that for now...","['cyclic-groups', 'group-theory', 'solution-verification']"
643756,Fourier Series doubt,"I have a doubt regarding the Fourier series usage in terms of the Fourier series formula, which has multiple variants and is quite complicated. EDIT: I would like to mention that this question (of mine) is a repeat of the one I had asked earlier, but I could not bump it however, to show the new comment I had added. So I am askign again - sorry for the double question. $A$ $summary$ $of$ $my$ $question$ $before$ $I$ $ask$ $it$: I need the exact Fourier series formula to compute the values of $a_0$, $a_n$ and $b_n$, for a function $f(x)$ where:
$$f(x) = a_0 + \sum_{n=1}^\infty(a_n\cos nx) + \sum_{n=1}^\infty(b_n \sin nx)$$ $Question:$ In one of my notes, it is given that, for a function $f(x)$ defined on an interval $-\pi$ to $\pi$, the function can be written as follows:$ f(x) = a_0 + \sum_{n=1}^\infty(a_n\cos nx) + \sum_{n=1}^\infty(b_n \sin nx)$. I need  the formula as follows: $$ f(x) = a_0 + \sum_{n=1}^\infty(a_n\cos nx) + \sum_{n=1}^\infty(b_n \sin nx)$$ And that: $$\begin{align}a_0 &= \dfrac 1{2\pi}\int_{-T_0}^{T_0}f(x)dx \\
a_n &= \dfrac 1\pi\int_{-T_0}^{T_0}f(x)\cos(nx)dx \\
b_n &= \dfrac 1\pi\int_{-T_0}^{T_0}f(x)\sin(nx)dx \end{align}$$ However, when I searched online, I found different formulae. In some of them, the integral limits went from $0$ to $\pi$, in others from $-T_0$ to $T_O$. Also, the fraction before the integral differed - in some cases, the integral was multiplied not with $\dfrac 1{2\pi}$, but $\dfrac 1T$, etc. I need the formula to solve the fourier series for basic functions such as $\sin^2(x)$, etc. My biggest confusion lies with regard to the 'n' term used in the formulae. In some formula, I have seen it written as, for example, where the $nx$ has been replaced with $nw_0x$, such as follows: $$ f(x) = a_0 + \sum_{n=1}^\infty(a_n\cos(nw_0x)) + \sum_{n=1}^\infty(b_n\sin(nw_0x))$$ $My$ $Confusion:$ What is the difference between $nx$ and $nw_0x$, and which one do I use to solve for the fourier series? I need an explanation of the connection between the two. Could you please list the three formula exactly as I need? I wish to use only the trigonometric Fourier series, please, and in terms of $nx$, not $nw_0x$. This is really urgent, please.","['trigonometry', 'fourier-series', 'calculus']"
643762,Finding extreme values when the determinant of the Hessian at a critical point is zero.,"We want to determine extreme values of $f(x,y)=x^3+xy^2-x^2y-y^3$.
We first determine critical points by solving $\dfrac{\partial f(x,y)}{\partial x}=0$ and 
$\dfrac{\partial f(x,y)}{\partial y}=0$ which gives that the only critical point is $(0,0)$.
Now we compute the determinant of the Hessian $$D(x,y)=(6x-2y)(2x-6y)-(2y-2x)^2$$
Hence $D(0,0)=0$ and the determinant of the Hessian test is not conclusive, so what to do next to verify existence of local and global extreme values? thank you for your help.",['multivariable-calculus']
643778,Bounded holomorphic functions on $\mathbb{C} \smallsetminus K$ are constant.,Suppose $K$ is a countable closed subset of the complex plane $\mathbb{C}$ and let $f$ be a bounded holomorphic function on $\mathbb{C}\smallsetminus K$. Why must $f$ be a constant?,['complex-analysis']
643786,Weak convergence implies uniform boundedness,"I want to show that if $(f_{n})_{n}$ converges weakly in $L^{p}(\Omega)$ then $(f_{n})_{n}$ is uniformly bounded in $L^{p}$. The following is my attempt at proving this: Assume $f_{n} \rightharpoonup 0$ in $L^{p}(\Omega)$ and let $\varphi \in (L^{p}(\Omega))^{*}$,  then by Riesz Representation Theorem there exists a unique $u \in L^{p^{'}}(\Omega)$ such that: $\langle \varphi, f_{n} \rangle = \int_{\Omega} u f_{n}$ for all $n \in \mathbb{N}$ Moreover, $||u||_{L^{p'}(\Omega)} = ||\varphi||_{(L^{p}(\Omega))^{*}}$ Since $f_{n} \rightharpoonup 0$ it follows that $\langle \varphi, f_{n} \rangle \rightarrow 0$ by characterization of weak convergence. We can also define the linear functional as a linear functional on $L^{p'}(\Omega)$ by $\langle \gamma_{n}, u \rangle := \langle \varphi, f_{n} \rangle$, it follows then that $\langle \gamma_{n},u \rangle \rightarrow 0$ is bounded for any $u$ since every convergent sequence is bounded. $\therefore$ $\text{sup}_{n} |\langle \gamma_{n},u \rangle| < \infty$ by ""Uniform Boundedness Principle"" it follows that $\text{sup}_{n}||\gamma_{n}||_{(L^{p'})^{*}} < \infty$. The result that I want is $\text{sup}_{n}||\gamma_{n}||_{(L^{p'})^{*}} = ||f_{n}||_{L^{p}}$. By Riesz Representation Theorem what I have is $||u||_{L^{p'}} = ||\varphi||_{(L^{p})^{*}}$, as stated above. Can anyone see how this desired result follows from my argument? Is there a different, more efficient way of getting this result? Is this result unique to $L^{p}$ spaces? Thanks.","['weak-convergence', 'functional-analysis', 'lp-spaces']"
643787,limit problem - can't get rid of $0$.,"I am trying to evaluate limit: $$\lim_{x\rightarrow 0}\frac{\arcsin x - \arctan x}{e^x-\cos x -x^2 -x}$$ I tried to use known limit in denominator to get: $$\lim_{x\rightarrow 0}\frac{\frac{\arcsin}{x} - \frac{\arctan x}{x}}{x( \frac{e^x-1}{x}\cdot \frac{1}{x}+\frac{1-\cos x}{x^2} -1 -\frac{1}{x})}$$ But I still get $1-1=0$ in numerator. I also tried to use L'Hôpital rule, but it didn't help.","['calculus', 'limits']"
643795,"Does $19,199,1999,\dotsc$ contain infinitely many prime numbers?","Are there infinitely many primes of the form $F_n =2\times10^n-1$? That is, does this sequence, $$19,199,1999,\dotsc$$ contain infinitely many prime numbers? I think about Dirichlet's theorem on arithmetic progressions , but the problem is difficult to start. Edit : $F_n$ is prime for $n=1, 2, 3, 5, 7, 26, 27,\dotsc, 55347$ ( A002957 ) and $n=1059002$ (Kamada's tables ). $F_{n}$ for $n=6m+4$ is divisible by $7$.","['prime-numbers', 'elementary-number-theory', 'number-theory']"
643835,Solve equation $ \cos x+\sin x=0$,"I'm trying to solve an equation here but unfortunately I can't.
The equation:
$$
\cos x + \sin x = 0
$$
I'm trying to solve this by replacing $\cos x$ with $(1-t^2)/(1+t^2)$ and $\sin x$ with $2t/(1+t^2), t=\tan x/2, \ $  but I can't get the right solution.
Also I have tried by squaring both sides but still nothing. Can anyone help me ?",['trigonometry']
643862,"associative R-algebra A, center","I would like to know why here http://en.wikipedia.org/wiki/Algebra_%28ring_theory%29 in the sentence An equivalent definition of an associative R-algebra is a ring homomorphism f:R\to A such that the image of f is contained in the center of A. im f should be contained in the center of A.
Which property of an associative R-algebra A this requires.
JG",['functions']
643886,"A proof that $C[0,1]$ is separable","Im reading Chapter11 of Carothers' Real Analysis, 1ed. Here is a proof of Separable C[0,1], I can understand ""Why"" from his figure11.1. But I do not how to prove it? I mean since g is a polygonal function and |f(x) - f(y)|<ε whenever |x-y|<$\frac{1}{n}$, how to prove that $||f-g||_∞$ =< ε on each interval ($\frac{k}{n}$,$\frac{k+1}{n}$) will be guaranteed?","['real-analysis', 'analysis']"
643901,Why is it called 'discrete' mathematics?,I understand why you would refer to mathematics which concerns itself with all of the numbers on the number line as 'continuous' but why would you refer to countable or finite mathematics as 'discrete'? Like it's the mathematics no one talks about? Where does this labeling come from?,"['discrete-mathematics', 'terminology', 'math-history']"
643944,"Showing that $\int \frac{ \sinh (az)}{\sinh (\pi z)} \, e^{ibz} \, dz $ vanishes along three sides of a rectangle in the upper half-plane","One of several ways to evaluate $$\int_{0}^{\infty} \frac{\sinh (ax)}{\sinh (\pi x)} \, \cos (bx) \, dx \, ,  \quad  \, |a|< \pi,$$  is to sum the residues of $$ f(z) = \frac{\sinh (az)}{\sinh (\pi z)} \,e^{ibz}$$ in the upper half-plane. But if you restrict $b$ to positive values, how do show that $\int f(z) \, dz$ vanishes along the right, left, and upper sides of a rectangle with vertices at $\pm N, \pm N + i\left(N+\frac{1}{2} \right)$ as $N \to \infty$ through the positive integers? I think we can use the M-L inequality (in combination with the triangle and reverse triangle inequalities) to show that that integral vanishes along the vertical sides of the rectangle. But showing that the integral vanishes along the top of the rectangle seems a bit tricky.","['hyperbolic-functions', 'complex-analysis', 'contour-integration']"
643946,Locally compact subspace is an intersection of an open and closed set,"Let X be a locally compact topological space. I need to prove that if $M\subset X$ is a locally compact subspace of X then there exist $U,F\subset X$ such that U is open and F is closed, and $M=U\cap F$.
It can be assumed that for every open $x\in V$ there exist an open subset U such that $x \in U \subset \overline U \subset V$ and $\overline U$ is compact. My thoughts about the problem are that for every $x\in M$ and for every neighborhood $x\in V_x$ there exist an open neighborhood $U_x$ in M such that $x\in U_x\subset \overline U_x \subset V_x$ and $\overline U_x$ is compact and closed in M. So there exist an open subset $Z_x\subset X$ such that $U_x = Z_x\cap M$. I can take $U = \bigcup _{x\in M}Z_x $, then U is open in X, but i was having trouble finding the closed set F. I thought  to take $F = \overline {\bigcup _{x\in M}U_x}$, that is closure in X. Now $M\subset U\cap F$, but I haven't succeeded in showing that $M\supset U\cap F$, maybe that's not even true. Thanks!",['general-topology']
643951,What is the point of intersection with x-axis for this function?,"I have this function: $$f(x)=\log(e^{2x}-5e^x+7)$$ I am supposed to find $f(x)=0$. I know that $log(x)=0$ when $x=1$. So I've put it this way: $$e^{2x}-5e^x+6=0$$ I don't know how to solve this, so I've tried substituting $e^x=t$ and I got $$t^2-5t+6=0$$ out of which I get two solutions: $t_1=3$ and $t_2=2$. When reverting back to $e^x$, I get: $e^x=3$ and $e^x=2$. Trying to solve for $x$, I get: $x_1=\log(3)$ and $x_2=\log(2)$.  However, according to Wolfram Alpha this is not correct. I don't know how to solve this, and I am not allowed calculator on the test. Do you have any ideas?
Thanks in advance!","['graphing-functions', 'functions']"
643954,Proving a map between the triangle and the square is bijective,"Prove that $$(u,v) \mapsto \left(\frac{\sin u}{\cos v}, \frac{\sin v}{\cos u}\right)=\left(x, y\right)$$ is a bijection between the interior of the triangle $T:= \{0\le u,v; u+v \le \frac {\pi}2\}$ and the square $S:=\{0\le u,v \le 1\}$. I managed to partly show injectivity in the following way: assume $$\begin{aligned} \frac {\sin u}{\cos v} &= \frac {\sin u'}{\cos v'} \\
 \frac {\sin v}{\cos u} &= \frac {\sin v'}{\cos u'} \end{aligned}$$ then it follows that $$\begin{aligned} \sin u\cos v' - \sin v'\cos u &= \sin u' \cos v - \sin v \cos u' \\
\sin(u-v')&=\sin(u'-v)\\
\Rightarrow u+v &=u'+v'\end{aligned}$$ Hence two points in the triangle are mapped to the same point in the square only if they lie on a straight line parallel to the hypotenuse. I also computed the jacobian of this map and I know it is equal to $1-x^2y^2$, so that the map is smooth in the interior of the triangle. I'm sure I can use this at some point in the proof but I don't know where.","['multivariable-calculus', 'differential-geometry']"
643968,Set that has itself as an element? [duplicate],"This question already has answers here : Example of set which contains itself (5 answers) Closed 10 years ago . Does there exist a set $A$ such that $A \in A$? The empty set doesn't work. Also, it seems clear that if $A$ exists, then it must be infinite. If no such set exists, then is there a simple proof of this?",['elementary-set-theory']
644002,What happens when $\lvert\omega\rvert =1$?,"If this is a duplicate in any way, I'm very sorry. I'm brushing up on some Complex Analysis with Special Functions in mind. Here's a problem I'm stuck on. Evaluate the integral $$I=\frac{1}{2\pi i}\oint_{\lvert z\rvert=1}f(z)\, dz$$ over the counterclockwise oriented unit circle centred at $0$, where $$f(z)=\frac{2z}{z^2+\omega^2}$$ for $\omega\in\Bbb{C}$. I'm pretty sure I know what happens when $\lvert \omega\rvert\neq 1$; it's simple: break it down into the two obvious cases. But what happens when $\lvert\omega\rvert =1$? What I've done so far is let $z=\gamma (t)=e^{it}$ for $t\in [0, 2\pi ]$ and arrived at $$\frac{1}{\pi}\int_0^{2\pi}{\frac{dt}{1+\left(\frac{\omega}{e^{it}}\right)^2}},$$ hoping to use the derivative of $\operatorname{arctan}$, which isn't going to work, of course. I'd like a few hints please :) A hunch : I'm tempted to say that the integral does not exist for $\lvert\omega\rvert=1$ but I've no idea why.","['integration', 'complex-analysis']"
644003,"Ramanujan-type trigonometric identities with cube roots, generalizing $\sqrt[3]{\cos(2\pi/7)}+\sqrt[3]{\cos(4\pi/7)}+\sqrt[3]{\cos(8\pi/7)}$","Ramanujan found the following trigonometric identity
\begin{equation}
\sqrt[3]{\cos\bigl(\tfrac{2\pi}7\bigr)}+
\sqrt[3]{\cos\bigl(\tfrac{4\pi}7\bigr)}+
\sqrt[3]{\cos\bigl(\tfrac{8\pi}7\bigr)}=
\sqrt[3]{\tfrac{5-3\sqrt[3]7}2}
\end{equation}
(see e.g. Ramanujan — For Lowbrows , (3.7) and around, for details and an analogue for 9 instead of 7). Are there analogous identities for all primes $p$ of the form $3k+1$ instead of 7? Let me try to explain what I mean. As I've learned from S. Markelov, for $p=13$
\begin{multline}
\sqrt[3]{\cos\bigl(\tfrac{2\pi}{13}\bigr)+\cos\bigl(\tfrac{10\pi}{13}\bigr)}+
\sqrt[3]{\cos\bigl(\tfrac{4\pi}{13}\bigr)+\cos\bigl(\tfrac{6\pi}{13}\bigr)}+
\sqrt[3]{\cos\bigl(\tfrac{8\pi}{13}\bigr)+\cos\bigl(\tfrac{12\pi}{13}\bigr)}=\\
\sqrt[3]{\tfrac{3\sqrt[3]{13}-7}2}
\end{multline}
and there are close analogues for all $p$ of the form $n^2+n+1$. For example, for $p=43=6^2+6+1$ three groups of numerators are {2, 4, 8, 16, 22, 32, 42}, {6, 10, 12, 20, 24, 38, 40}, {14, 18, 26, 28, 30, 34, 36} and the sum is $\sqrt[3]{\frac{3\sqrt[3]{86}-13}2}$. So it looks like there is some pattern reminding of... quadratic Gauss sums , perhaps. For any $p=3k+1$ one can partition $\mathbb F_p^\times$ into three groups, corresponding to $\mathbb F_p^\times/\mathbb F_p^{\times3}\cong\mathbb Z/3$ — and this is precisely the partitions from the last paragraph. This explains what LHS should look like. And indeed, at least for $p=19$ there is an identity \begin{multline}
\sqrt[3]{\cos\bigl(\tfrac{\pi}{19}\bigr)+\cos\bigl(\tfrac{7\pi}{19}\bigr)+\cos\bigl(\tfrac{11\pi}{19}\bigr)}+
\sqrt[3]{\cos\bigl(\tfrac{3\pi}{19}\bigr)+\cos\bigl(\tfrac{5\pi}{19}\bigr)+\cos\bigl(\tfrac{17\pi}{19}\bigr)}+\\
\sqrt[3]{\cos\bigl(\tfrac{9\pi}{19}\bigr)+\cos\bigl(\tfrac{13\pi}{19}\bigr)+\cos\bigl(\tfrac{15\pi}{19}\bigr)}=\\
\sqrt[3]{\tfrac12-3\sqrt[3]7+\tfrac32\sqrt[3]{3\sqrt[3]{49}+18\sqrt[3]7-25}+\tfrac32\sqrt[3]{3\sqrt[3]{49}+18\sqrt[3]7-44}}
\end{multline}
which is closely related to the fact that $2 \left( \cos \frac{4\pi}{19} + \cos \frac{6\pi}{19}+\cos \frac{10\pi}{19} \right)$ is a root of the equation $\sqrt{ 4+ \sqrt{ 4 + \sqrt{ 4-x}}}=x$ . So, more precisely: is it true, that for any $p=3k+1$ the sum of 3 cubic roots of sum of cosines (described above) can be expressed in real radicals? what can be said about RHS in this case (say, about the number of nested radicals)?","['galois-theory', 'trigonometry']"
644010,How to solve $ \sqrt 2 \cos 2x = -1$?,"I have this equation,   $ \sqrt{2} \cos 2x = -1$. I need all solutions between $[0,2\pi]$. I simplified that to $\cos 2x = -\frac{1}{\sqrt{2}}$. I could just use a calculator and do $\arccos{-\frac{1}{\sqrt{2}}}$, to get angles for $2x$, but I need it in terms of $\pi$, and I also feel like I'm missing something simple that will allow me to find the solutions without one. Should I just do it with a calculator? Or am I missing something here? Thanks!","['trigonometry', 'algebra-precalculus']"
644015,Solve Helmholtz equation,"$$U_{xx}+U_{yy}+k^2U=0$$ Solve by separation of variables by assuming $u(x,y)=X(x)Y(y)$ with the following conditions:
  $$
U(0,y)=0,\,\,
U(2,y)=0,\,\,
U(x,0)=0,\,\,
U(x,1)=0,
$$ This is what I have done so far:
$$
X''(x)Y(y)+X(x)Y''(y)+k^2X(x)Y(y)=0
$$
To separate divide through by $X(x)Y(y)$, this gives
$$
X''(x)/X(x)  +   Y''(y)/Y(y)   +k^2  =0
$$
Now I am not sure where to go from here. I know that if I take over the $y$'s then it will be separated, but where does the $k^2$ go? Does it even matter to the aux. equation? What I thought is that I can just set $X''(x)/X(x) =k^2$ and $Y''(y)/Y(y) =k^2$, but I think I am wrong. Can someone help?  Thank you","['multivariable-calculus', 'partial-differential-equations']"
644032,Name of the generalization of quadtree and octree?,What is the name of the equivalent of quadtrees and octrees in n-dimension ?,"['geometry', 'trees', 'algorithms', 'graph-theory', 'approximation']"
644038,1st Order Differential Equation - Existence and Uniqueness Theorem,"I have the following 1st order differential equation: $$y'=(x-4y)^{-2}$$ Which isn't continuous when $y=\frac{x}{4}$. Nevertheless, solutions exist and are unique on all the plane. How's that?",['ordinary-differential-equations']
644049,Proving convergence of a sequence,"Let the following recursively defined sequence: $a_{n+1}=\frac{1}{2} a_n +2,$ $a_1=\dfrac{1}{2}$. Prove that $a_n$ converges to 4 by subtracting 4 from both sides. When I do that, I get:
$2(\frac{1}{2} a_{n+1} -2)=(\frac{1}{2} a_n -2)$, so $y=2y$, 
which is true only for $0$. But I'm not sure how to formally use this in a definition of convergence?","['recurrence-relations', 'convergence-divergence', 'sequences-and-series', 'recursion', 'analysis']"
644064,a question about double integral,"Let $a,b$ be positive real numbers, and let $R$ be the region in $\Bbb R^2$ bounded by $\frac{x^2}{a^2}+\frac{y^2}{b^2}=1$. Calculate the integral 
$$
\int\int_R\left(1-\frac{x^2}{a^2}-\frac{y^2}{b^2}\right)^{3/2}dx\,dy
$$ my question is I don't know anything about $R$, the function $\frac{x^2}{a^2}+\frac{y^2}{b^2}=1$ is not the function of $R$, so then how can I get the answer? Could somebody give me some hints.","['multivariable-calculus', 'calculus', 'integration']"
644100,Prove the scaling property of a Brownian motion.,"I have to prove that $X_t:=c^{-1/2}W_{ct}$, $t\ge0$, where $c>0$ is a constant is a Wiener process. My attempt: 1) $X_0=c^{-1/2}W_0=0$ 2) We know that $(W_t)$ has continuous trajectories. It implies that $(X_t)$ has also continuous trajectories since continuous function multiplied by a constant and with scaled argument is still continuous. Right? 3) Independence of increments. We know that $W_i-W_j$ and $W_k-W_l$ are independent for all $i, j, k, l\in\mathbb{R}^+$. Now, $X_i-X_j=c^{-1/2}(W_{ci}-W_{cj})$ nad $X_k-X_l=c^{-1/2}(W_{ck}-W_{cl})$ so $(X_t)$ has independent increments. 4) $X_{s+\epsilon}-X_s=c^{-1/2}(W_{c(s+\epsilon)}-W_{cs})$ ~ $N(0,\epsilon)$","['stochastic-processes', 'probability']"
644151,Neighborhood of a point in Topology,"Let $x \in X$ and define a topological space $(X, \tau)$ and let singleton set {$x$} $\in \tau$. Then by definition of neighborhood of a point in topology, {${x}$} will be a neighborhood of point $x$. My question is If set {$x$} does not contain any other point then $x$, then how does it make sense to say that this singleton set is a neighborhood of $x$.",['general-topology']
644182,Show that the given function is a diffeomorphism,"Let $U=\{x\in\mathbb{R}^n: ||x||<1\}$. If we define $f:U\rightarrow\mathbb{R}^n$ by $f(x) = \displaystyle\frac{x}{\sqrt{1-||x||^2}}$, show that $f$ is a diffeomorphism and $f^{-1}:\mathbb{R}^n\rightarrow U$ is given by $f(y) = \displaystyle\frac{y}{\sqrt{1-||y||^2}}$. (1) Proving bijectiviy (1.1) Injectivity
$f(x) = f(y) \iff \displaystyle\frac{x_i}{\sqrt{1-||x||^2}}=\displaystyle\frac{y_i}{\sqrt{1-||y||^2}} \iff x_i^2[1-(y_1^2+\dots+y_n^2)] =y_i[1-(x_1^2+\dots+x_n^2)]$. Now adding all of the following identities $\begin{cases} x_1^2 -x_1^2y_1^2+\dots+x_1^2y_n^2 = y_1^2-x_1^2y_1^2+\dots+x_n^2y_1^2 & (1)\\ \dots\\ x_n^2 -x_n^2y_1^2+\dots+x_n^2y_n^2 = y_n^2-x_1^2y_n^2+\dots+x_n^2y_n^2 & (n)\end{cases}$ I have $x_1^2+\dots+x_n^2 = y_1^2+\dots+y_n^2 \implies ||x||=||y||$. Then $\displaystyle\frac{x_i}{\sqrt{1-||x||^2}}=\displaystyle\frac{y_i}{\sqrt{1-||y||^2}} \iff \displaystyle\frac{x_i}{\sqrt{1-\alpha}}=\displaystyle\frac{y_i}{\sqrt{1-\alpha}}\iff x_i=y_i\implies x=y$. (1.2) Surjectiviy
I'm not sure how should I do this, see (3.3) (2) Proving that $f$ is differentiable applying the quotient rule to the coordinate functions If $i\neq j$ then $\displaystyle\frac{\partial f_i}{\partial x_j}= \displaystyle\frac{\partial}{\partial x_j}\left( \displaystyle\frac{x_i}{1-||x||^2}\right) = \displaystyle\frac{\frac{2x_i}{2\sqrt{1-||x||}}}{{1-||x||}} = \displaystyle\frac{x_i}{(1-||x||^2)^{3/2}}$ which is continous for every $x\in U$. And $\displaystyle\frac{\partial f_i}{\partial x_i} = \displaystyle\frac{\partial}{\partial x_i}\left( \displaystyle\frac{x_i}{1-||x||^2}\right)\displaystyle\frac{\sqrt{1-||x||^2}-2x_i^2}{1-||x||^2} = \displaystyle\frac{1}{\sqrt{1-||x||^2}} - \displaystyle\frac{2x_i^2}{1-||x||^2}$ which is also continuous if $x\in U$, right?. By the continuity of the partial derivatives for $f_i$ I conclude that $f_i$ is differentiable and since it applies for every $i=1,\dots,n$ I conclude $f$ that is differentiable. (3) Some questions.
I'm not sure how to proceed from here, I have a few guesses and questions: (3.1) The differential for $f$ will be a matrix with values computed above, right?. I can use the inverse function theorem to find the inverse of $f$ by $(f^{-1})'(y)=1/(f'(y))^{-1}$, but how does it works? -I mean, am I supposed to divide by the matrix?-. (3.2) Even if I get $f^{-1})'$, how can I get $f^{-1}$. Should I integrate the coordinate functions? (3.3) I'm not sure how to prove the surjectivity either, could I use that $\operatorname{dim}(U)=\operatorname{dim}(\mathbb{R}^n)$ the injectivity implies surjectivity?. But wouldn't I need a basis for $U$?, can I use the canonical basis with the restriction that $\sum_i x_i^2 < 1$?.",['multivariable-calculus']
644193,Confusing definition of Jacobi field,"Let $\mathcal{M}$ be $n$-dimensional Riemannian manifold. In wikipedia article I've found that a vector field $J$ along a geodesic $\gamma$ is said to be a Jacobi field if it satisfies the Jacobi equation:
$$\frac{D^2}{dt^2}J(t)+R(J(t),\dot\gamma(t))\dot\gamma(t)=0,$$
where $D$ denotes the covariant derivative with respect to the Levi-Civita connection, $R$ the Riemann curvature tensor, $\dot\gamma(t)=d\gamma(t)/dt$ the tangent vector field, and $t$ is the parameter of the geodesic. What confuses me is the fact that to be able to compute $R(J(t),\dot\gamma(t))\dot\gamma(t)$ the vector field $\dot\gamma(t)$ should have values in some neighbourhood of $\gamma(t)$ (at least on curve $\alpha(s) : (-\epsilon, \epsilon) \to \mathcal{M}$, that is any curve with  $(d\alpha /ds )(0)=J(t)$), but it doesn't in common case. Of course, we can extend it, but not in a unique way, so the equation above doesn't make sense for me. Where am I wrong?","['riemannian-geometry', 'differential-geometry']"
644208,Feynman Parameters,"I'm trying to prove the following identity:
$$ \left(\prod_{j=1}^n A_j\right)^{-1} = \int_0^1dx_1 \dots \int_0^1dx_n \,\delta\left(\sum_{i=1}^{n}x_i -1\right) \frac{(n-1)!}{(\sum_{j=1}^nx_iA_i)^{n}}\,\,\,\,\,\,\,\,\forall n\in\mathbb{N}$$
My strategy is induction on $n$. The $n=1$ step is easy to show. Assuming the induction hypothesis, we have:
$$ \left(\prod_{j=1}^{n+1} A_j\right)^{-1} = \left(\Pi_{j=1}^{n} A_j\right)^{-1} \cdot \left( A_{n+1} \right)^{-1} = \int_0^1dx_1 \dots \int_0^1dx_n \,\delta\left(\sum_{i=1}^{n}x_i -1\right)\left((n-1)!\right)\frac{1}{A_{n+1}(\sum_{j=1}^nx_iA_i)^{n}}$$
Then I use an identity which is easy to prove by differentiation of both sides of the equation repeatedly w.r.t. $B$:
$$ \frac{1}{A\cdot B^n} = \int_0^1dx\int_0^1dy\delta\left(x+y-1\right)\frac{n\,y^{n-1}}{\left(xA+yB\right)^{n+1}}\,\,\,\forall n\in\mathbb{N}$$ 
to obtain:
$$ \left(\prod_{j=1}^{n+1} A_j\right)^{-1} = \int_0^1dx_1 \dots \int_0^1dx_n \,\delta\left(\sum_{i=1}^{n}x_i -1\right)\left((n-1)!\right)\int_0^1dx\int_0^1dy\delta\left(x+y-1\right)\frac{ny^{n-1}}{\left(xA_{n+1}+y\sum_{i=1}^nx_iA_i\right)^{n+1}}$$
Perform the $x$ integration to get:
$$ \left(\prod_{j=1}^{n+1} A_j\right)^{-1} = \int_0^1dx_1 \dots \int_0^1dx_n \,\delta\left(\sum_{i=1}^{n}x_i -1\right)\left((n-1)!\right)\int_0^1dy\frac{ny^{n-1}}{\left(\left(1-y\right)A_{n+1}+y\sum_{i=1}^nx_iA_i\right)^{n+1}}\\\ = \int_0^1dy\int_0^1dx_1 \dots \int_0^1dx_n \,\delta\left(\sum_{i=1}^{n}x_i -1\right)\left((n-1)!\right)\frac{ny^{n-1}}{\left(\left(1-y\right)A_{n+1}+y\sum_{i=1}^nx_iA_i\right)^{n+1}}$$
Now make the following $n$ substitutions:
$$ u_i := y x_i \forall i \in \left\{1,\dots,n \right\} $$
Which results in:
$$ = \int_0^1dy\int_0^y\frac{du_1}{y} \dots \int_0^y\frac{du_n}{y} \,\delta\left(\sum_{i=1}^{n}\frac{u_i}{y} -1\right)\left((n-1)!\right)\frac{ny^{n-1}}{\left(\left(1-y\right)A_{n+1}+\sum_{i=1}^n u_iA_i\right)^{n+1}}$$
Use the delta function identity:
$$ \delta\left(\sum_{i=1}^n \frac{u_i}{y} -1\right) = \delta\left(\sum_{i=1}^n u_i -y\right)\cdot y$$
To get:
$$ = \int_0^1dy\int_0^y du_1 \dots \int_0^y du_n \,\delta\left(\sum_{i=1}^{n}u_i -y\right)\frac{n!}{\left(\left(1-y\right)A_{n+1}+\sum_{i=1}^n u_iA_i\right)^{n+1}}$$
Finally, make the substitution $u_{n+1} := 1-y$ 
$$ = \int_0^1du_{n+1}\int_0^{1-u_{n+1}} du_1 \dots \int_0^{1-u_{n+1}} du_n \,\delta\left(\sum_{i=1}^{n+1}u_i -1\right)\frac{n!}{\left(\sum_{i=1}^{n+1} u_iA_i\right)^{n+1}}$$
Now I am stuck, because I don't know how to deal with the integration limits. I could stretch them all from $0$ to $1$, but as far as I can tell, that would mean I'd have to divide the whole thing by $n!$, which would not give me the result I'm looking for. What am I doing wrong?","['definite-integrals', 'calculus', 'integration']"
644209,Would you provide a study routine for Spivak's Calculus? [closed],"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 10 years ago . Improve this question I've been working on Spivak's Calculus for the past few days and although I can manage to solve most problems, they take a lot of time. Some chapters have over 20 exercises and it can take several days to get through the whole list. Would anyone care to provide a list of recommended exercises for each chapter? I take it that this book has been used in several honours course in Calculus, therefore someone should have a related material.
Thanks in advance.","['self-learning', 'calculus']"
644211,probability of choosing $k$ linear independent elements from a finite field,"Let $\mathbb{F}_q$ denote a finite field with $q$ elements. What is the probability of choosing $k$ linear independet elements from $\mathbb{F}_q^n$? I guess, it depends on how we choose from $\mathbb{F}_q^n$. If so, what's a considerable technique?","['probability-theory', 'finite-fields', 'probability']"
644213,Expression for a bounded function,"I have a bounded function, $$
y=
    \begin{cases}
        1 & \text{if $x>1$} \\
        x & \text{if $0\leq x\leq 1$}\\
        0 &\text{if $x < 0$}
    \end{cases}
$$
Does anyone know any simple math function to represent $y$? (not using a piece-wise function) For example, Heaviside function is a similar approach. Thanks","['regular-expressions', 'functions']"
644215,Limit as n approaches infinity of (log(n!) / nlog(n)) [duplicate],This question already has answers here : Limit of $\frac{\log(n!)}{n\log(n)}$ as $n\to\infty$. (11 answers) Closed 10 years ago . I'm stumped with a limit. I know the answer (because I looked on wolframalpha) but I really want to know how to reach the correct answer. If you have any hints or tips on getting there I'd be most appreciative!,"['calculus', 'limits']"
644220,Example of an affine scheme where closed points aren't dense.,"I'm looking for an example of an affine scheme where closed points aren't dense. It's easy to show (using Hilbert's Nullstellensatz) that if $A$ is a finitely generated algebra over a field, then the closed points of $\operatorname {Spec} A$ are dense. Therefore, I suppose that I can find an example where $A$ is not finitely generated. Specifically, I'm looking for an open set in $k[x_1,x_2,...]$ that doesn't contain any closed point. But then, how can it contain a prime ideal at all?","['affine-schemes', 'algebraic-geometry', 'schemes']"
644242,Some questions about Weierstrass approximation theorem,"Im reading chapter11 of Carothers' Real Analysis, 1ed talking about Weierstrass Approximation Theorem. Here is an introduction, How to explain the ""how"" there? Since q is the polynomial approximating f with rational coefficients, that is to say there exist two approximation methods(precisely, one is p containing at leat one irrational coefficient and the other is q) or in other words, Weierstrass approximation theorem guarantee the existence of polynomial but not its coefficients being rational?","['real-analysis', 'analysis']"
644295,Convergence in distribution of bernoulli rv over square root of uniform rv,"This is a question from an old comprehensive exam: Let $U$ be a $\operatorname{Uniform}[0,1]$ random variable and let $X$ be a $\operatorname{Bernoulli}(1/2)$ random variable independent of $U$.  Let $Y=\frac{X}{\sqrt{U}}$.  If $Y_1,\dots,Y_n$ are iid as $Y$, show that $\frac{\bar{Y}}{\sqrt{n\log n}}$ converges in distribution to a standard normal random variable. What I am being asked to prove seems like it can't be correct, since $\frac{\bar{Y}}{\sqrt{n\log n}}$ is nonnegative, and therefore $P\left(\frac{\bar{Y}}{\sqrt{n\log n}} < x\right) = 0$ whenever $x < 0$, which clearly does not converge to the normal distribution function.  What am I missing?","['probability-theory', 'weak-convergence', 'probability-distributions']"
644327,How unique are $U$ and $V$ in the singular value decomposition $A=UDV^\dagger$?,"According to Wikipedia: A common convention is to list the singular values in descending order. In this case, the diagonal matrix $\Sigma$ is uniquely determined by $M$ (though the matrices $U$ and $V$ are not). My question is, are $U$ and $V$ uniquely determined up to some equivalence relation (and what equivalence relation)?","['matrix-decomposition', 'svd', 'matrices', 'linear-algebra', 'singular-values']"
644344,Carlson's model and Sierpinski sets,"Suppose that every countably generated sigma algebra extending the Borel sigma algebra on $[0, 1]$ admits a measure extending the Lebesgue measure (This is true in Carlson's model which is obtained by adding $\omega_2$ random reals to a model of CH). Must there be a Sierpinski set, i.e., an uncountable set of reals all of whose uncountable subsets are Lebesgue non null? This is true in Carlson's model (the set of random reals added constitutes an $\omega_2$-sized Sierpinski set) and this is also true if there is a total extension of Lebesgue measure (via Gitik-Shelah theorem).","['set-theory', 'measure-theory']"
644347,Is a function determined by its integrals over open sets?,"If $f \in L^1(\mathbb R)$ satisfies
$$
  \int_U f = 0
$$
for every open set $U \subset \mathbb R$, then is it true that $f = 0$ a.e.?",['real-analysis']
644350,What is the connection between Weil's character bound and Riemann Hypothesis over finite fields,"Weil's character bound states that: Let $\mathbb{F}_{q}$ be a finite field of size $q$. Let $\chi$ be a multiplicative character of order $m$. Let $f(x)$ be a polynomial of degree $d$ such that $f(x) \neq c . g(x)^{m}$ for any $c \in \mathbb{F}_{q}$ and $g(x) \in \mathbb{F}_{q}[x]$. Then 
$$ \left| \sum_{x \in \mathbb{F}_{q}} \chi(f(x))  \right| \leq (d-1)\sqrt{q} $$ The Riemann Hypothesis over finite fields, or rather the Hasse-Weil bound is concerned with the number of rational points on curves. To put it simply, again suppose we have a finite field $\mathbb{F}_{q}$ and an absolutely irreducible polynomial $h(x,y)$ of total degree $d$ over $\mathbb{F}_{q}$, (a simple version of) it states that 
$$ \left| N - q \right| \leq O(d^2) \sqrt{q} $$
where $N$ is the number of rational points on the variety defined by the polynomial $h$ i.e.
$$N = \left|\left\lbrace (a,b) \in \mathbb{F}_{q}^2 : h(a,b)=0 \right\rbrace \right|$$ Now if $\chi$ is the quadratic character defined by $\chi(a) = (\frac{a}{q})$ where $(\frac{a}{q})$ is the Legendre symbol (whether $a$ is quadratic residues or not modulo $q$), then since $\chi$ takes only 1/-1 values, it is easy to see that the number of rational points on the curve $y^2 - f(x) = 0$ can be used to count the sum $\left| \sum_{x \in \mathbb{F}_{q}} \chi(f(x))  \right|$.
Most references simply state that the quadratic character bound, and the general character sum bound are special cases of counting points on varieties and the Riemann hypothesis.
But how are the two results related in the general case, where $\chi$ no longer takes only 1/-1 values? Is there a simple correspondence like in the quadratic case? Thanks.","['finite-fields', 'algebraic-geometry', 'number-theory']"
644354,What's the most efficient algorithm to determine the relative ordering of an unknown set of values?,"This comes from a question on Arqade . The background is, there's a mall level.  Vlad the organized crime
  boss wants $50,000 worth of mall property destroyed.  Your task is to
  shoot and blow stuff up until that happens. There are 12 stores in the mall, and you have 3 grenades.  After you
  blow up the first three stores, if you haven't ruined $50,000 worth of
  stuff in three explosions, you switch to your rifle and shatter store
  windows until you reach that limit.  Then you leave. Good wholesome fun. The absolute value of the stores is unknown, but I'm interested in determining the relative value - obviously, I want to use my three grenades where they'll do the most good.  As I see it, I have a set of 12 unknown variables, representing the value of each of the individual stores: $ {O,P,Q,R,S,T,U,V,W,X,Y,Z} $ and one constant $C$, representing the value of windows. I know which three stores I've destroyed and I can count how many windows I need to shoot to give me a Mission Accomplished. Knowing only those two pieces of information, it should be possible through experimentation to order the unknown set.  Let's say on trial #1 I destroy stores X,Y,Z and it takes me 4 windows to reach $50k.  On trial #2, I destroy stores W,Y,Z and it takes 3 windows. If $X + Y + Z + 4C = W + Y + Z + 3C$, then we can say that $W > X$. What's the most efficient way to run this algorithm to conclusion for all 12 stores?  Each trial takes about 6 minutes and I don't want to duplicate effort.","['algorithmic-game-theory', 'algebra-precalculus', 'algorithms']"
644394,Is there a name for this family of curves?,"I saw a space curve defined as the following before (but I don't remember the reference):
$$
\alpha_{p,q}(t)=\{\left((2+\cos pt)\cos qt,(2+\cos pt)\sin qt,\sin pt\right)|t\in{\Bbb R}\}
$$
where $p$ and $q$ are relatively prime. For example, $\alpha_{5,3}$ is something like Is there a name for this family of curves? Would any one come up with a reference?","['reference-request', 'differential-geometry']"
644408,"Prove that $n$ is even and $|A| \in \{-1,1 \}$","Let $A \in M_{n} (\mathbb R)$, such that $A^2=-I_{n}$. Prove that $n$ is even and $|A| \in \{-1,1 \}$. I started by compute the determinant of both sides: $A^2=-I_{n}\Leftrightarrow$ $|A^2|=|-I_{n}|\Leftrightarrow$ $|A|\cdot |A|=(-1)^n|I_{n}|\Leftrightarrow$ $|A|\cdot |A|=(-1)^n$ It's known that $|A|$ is a real number. The product of two equal real numbers is always positive. So $n$ must be even. I can write: $|A|\cdot |A|=1$ To get the previous result there are two possibilities, $|A|=1$ or $|A|=-1$. My doubt is if there is more posibilities. Thanks.","['linear-algebra', 'proof-verification']"
644409,Is there a name for an algebraic structure like this?,"I'm self studying abstract algebra. I see that in rings there's no requirement for a multiplicative inverse. Is there something similar except with no requirement for an additive inverse. For example, all the non-negative rational numbers. Every number other than 0 has a multiplicative inverse, but no additive inverses. We have both the multiplicative and additive identities. Multiplication is still associative over addition. Is there a name for such an algebraic structure, and has it been studied the way rings have?","['ring-theory', 'inverse', 'abstract-algebra']"
644444,Find the volume of the solid bounded by $z=x^2+y^2+1$ and $z=2-x^2-y^2$.,"Question: Find the volume of the solid bounded by $z=x^2+y^2+1$ and $z=2-x^2-y^2$. Setting the 2 equations equal w.r.t. $z$, $x^2+y^2+1=2-x^2-y^2 \rightarrow x=\pm\sqrt{\frac 12-y^2}$ Therefore the boundary of $y=\pm\frac {1}{\sqrt2}$. So to find the volume of the solid, take the integration by subtracting the volume above and below the boundaries. $\displaystyle V=\int_{-\frac {1}{\sqrt2}}^{+\frac {1}{\sqrt2}}\int_{-\sqrt{\frac 12-y^2}}^{+\sqrt{\frac 12-y^2}}(2-x^2-y^2)dxdy-\int_{-\frac {1}{\sqrt2}}^{+\frac {1}{\sqrt2}}\int_{-\sqrt{\frac 12-y^2}}^{+\sqrt{\frac 12-y^2}}(x^2+y^2+1)dxdy$ This is what I did. Without solving the equation, can someone tell me if it is correct? Thank you!","['multivariable-calculus', 'calculus', 'integration']"
644466,Characteristic Function and Random Variable Transformation,"Let $X$ be a random variable, and let $\phi_X(t)$ be its characteristic function. Let $Y = f(X)$ be a transformation of the random variable $X$ where $f$ is increasing and one-to-one. Is there a direct functional relationship between the characteristic function of the transformation $f(X)$ and the characteristic function $\phi_X(x)$? Meaning if $\phi_Y(t)$ is the characteristic function of the random variable $f(X)$, can we write $\phi_Y(t)$ in terms of $\phi_X(t)$?","['probability-theory', 'probability-distributions', 'probability']"
