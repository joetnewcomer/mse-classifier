question_id,title,body,tags
88167,Counterexample to $f_ng_n \not\to fg$ in measure,"I'm looking for a pair of sequences $f_n \to f$ in measure, $g_n \to g$ in measure, where $f_ng_n \not\!\to fg$ in measure. I've tried a number of things with characteristic functions that move around with $n$, and nothing seems to pan out. I've also tried looking at non-Lebesgue measures, like the counting measure. At least, I realize that whatever measure one uses must not be finite, or else $f_ng_n \to fg$ is always true. Any hints?","['measure-theory', 'real-analysis']"
88169,Fraïssé limits and groups,"I was recently reading up on Fraïssé limits in Hodges' ""A shorter model theory."" I was trying to think of some examples and wanted to see if I could take the Fraïssé limit on the category of finite groups. It is clear that this category has the hereditary and joint embedding property. However, I am having trouble showing that this category has the amalgamation property, by which I mean that if there are finite groups $G, H, K$ such that there are embeddings $\varphi: G\hookrightarrow H$ and $\psi: G\hookrightarrow K$, then there exists a finite group $J$ and embeddings $\vartheta: H\hookrightarrow J$ and $\eta: K\hookrightarrow J$ such that $\vartheta\circ \varphi = \eta\circ \psi$. One simplification is that we can, by taking isomorphic copies if necessary, assume that $H\cap K = G$, and that $\varphi $ and $\psi$ are just inclusion maps. I am not even sure what group $J$ should be. Any help would be appreciated.","['logic', 'group-theory', 'model-theory']"
88177,Are there nice circumstances under which connectedness of interior and boundary imply connectedness?,"Munkres problem 24.11: If $A$ is a connected subspace of $X$, does it follow that $\operatorname{Int}A$ and $\operatorname{Bd}A$ are connected? Does the converse hold? I've answered these questions, but I'm wondering if the converse might hold if $X$ satisfies some reasonable conditions, like being normal and connected, or perhaps locally connected, and assuming that neither the interior nor the boundary is empty.",['general-topology']
88180,How do you prove that the dunce cap is not a surface?,"The dunce cap results from a triangle with edge word $aaa^{-1}$. At the edge, a small neighborhood is homeomorphic to three half-disks glued together along their diameters. How do you prove this is not homeomorphic to a single disk?","['general-topology', 'manifolds', 'algebraic-topology', 'surfaces']"
88183,Sobolev meets Wiener,"Even though the Wiener process (Brownian motion) is continuous, it has no derivative at any point. Does it at least have weak derivatives?","['stochastic-processes', 'sobolev-spaces', 'derivatives', 'brownian-motion']"
88195,Discontinuous function at an uncountable set with not rationals,"Does there exists a function $f:[0,1]\to\mathbb{R}$ such that $D(f)$ (its points of discontinuity) is an uncountable set containing no rational number? First thing I thought of was $\mathbb{R}\setminus\mathbb{Q}$ (uncountable, with no rational), but it won't work, since it's not an $F_\sigma.$ So there is no function whose points of discontinuity is precisely $\mathbb{R}\setminus\mathbb{Q}$.","['real-analysis', 'analysis']"
88196,Weaker assumption to ensure $f_{n}^\prime \to f'$,"I learned in my real analysis class that if $f_n:[a,b] \to \mathbb{R}$ is a sequence of differentiable functions such that $f_n \to f$ uniformly and $f_{n}^\prime \to g$
uniformly then $f$ is differentiable and $f' = g$. Can the assumptions be weakened? In particular I'd like to dispense of the condition that $f_{n}^\prime$ converges uniformly to some function $g$. This question is motivated by the following:
Let $K = \{f:[a,b] \to \mathbb{R}: f \text{ is differentiable and } \|f\|_{\infty} + \|f'\|_{\infty} \le 1\}$. By the Arzelà-Ascoli theorem, the closure of this set is compact in $C([a,b])$. But I want it to actually be compact possibly after imposing some additional conditions on the possible functions $f$. This happens when $K$ is closed, hence the question. Thanks in advance.","['sequences-and-series', 'derivatives', 'real-analysis']"
88199,Function satisfying $x = f(f(x))$ and $x \not= f(x)$,"Is there a function that would satisfy the following conditions?: $\forall x \in X, x = f(f(x))$ and $x \not= f(x)$, where the set $X$ is the set of all triplets $(x_1,x_2,x_3)$ with $x_i \in \{0,1,\ldots,255\}$. I would like to find a function that will have as an input RGB color values (triplets) and return the original color after two applications of the function.","['functions', 'functional-equations']"
88202,"How do I show that $\mathbb{Q}(\sqrt[4]{7},\sqrt{-1})$ is Galois?","How do I show that $\mathbb{Q}(\sqrt[4]{7},\sqrt{-1})$ is Galois? At first I thought it was the splitting field of $x^4-7$, but I was only able to prove that it was a subfield of the splitting field. Any ideas? I'm trying to find all the intermediate fields in terms of their generators, but I don't understand how. I am trying to imitate Dummit and Foote on this. I am looking at the subgroups of the Galois group in terms of $\tau$ where $\tau$ is the automorphism that takes $\sqrt[4]{7}$ to itself and $i$ to $-i$, and $\sigma$ that takes $\sqrt[4]{7}$ to $i\sqrt[4]{7}$ and $i$ to itself. How do I, for example, find the subfield corresponding to $\{1, \tau\sigma^3\}$? I know I am supposed to find four elements of the galois group that $\tau\sigma^3$ fixes, but so far i can only find $-\sqrt[4]{7}^3$.",['abstract-algebra']
88217,Proof about trees,"Show that in any tree there exists a node such that, if we remove this
  node and the edges adjacent to it, we will obtain trees which have at
  most n/2 nodes (the removed node is not counted anymore). I've been thinking for a proof to that but couldn't come up with something. Any ideas?","['graph-theory', 'discrete-mathematics', 'trees']"
88221,Examine function extreme values,"I am studying for multivariable calculus exam and in homework we always had specific task regarding extreme values: find absolute minima, find local maxima, etc. In real exam questions are more like ""Examine function extreme values"". What are the steps that should be done for complete examination of function $f(x,y)$ extreme values?","['optimization', 'multivariable-calculus']"
88226,Universality of Tate-conjectures,"We all know that Prof.John Tate proposed a set of conjectures(along with Prof.Emil Artin) formally spread under the name of ""Tate conjectures"", they have a wide range of influence on various fields of studies, like for example recently Prof.Mathew Emerton in his magnificent answer quoted that Tate conjectures(in some sense) can be thought as an analogue of Birch and Swinnerton-Dyer conjectures and Prof.Emerton gave a short intuition into the subject by representing the how can one spread out elliptic curve into elliptic surface and also that how the conjecture can be restated in this case, and he writes that the equivalent formulation is "" every Frobenius invariant element actually arises from a curve defined over $\mathbb F$ "" . But Prof.Emerton didn't had a need of elaborating the meaning behind the statement as he was trying to answer another question ( but he was kind in mentioning all these details instead of directly going into the point ) ,  but I have thought that the comparision could be found on internet and I read quite many articles but I couldn't find atleast one such article clearly stating the link between those conjectures, so I wanted to ask it under another question (as Math.SE mandatorily sees the effort of user, so I took much time reading myself and then wanted to ask as its out of my reach). So my main doubt is that "" How can one think the B.S.D and Tate-conjecture imply each other ? "" Due to my past background I know that the rank-part of the B.S.D was intending to comment the cardinality of the group $E(\mathbb{Q})$ (set of rational points on $E$) by linking the algebraic part to analytic part, but it was clear in that case that if the curve has lot many rational points then the $N_p$ must be substantially large pushing the product to zero for range of large primes, but how can the link the frobenius-invariant to these things and how can one show that the statement is analogue of other. To be sharp I am expecting an answer in giving the explanation that How can one say that  [$L(E,1)=0 \iff E(\mathbb{Q})$ is infinite]$\iff$[every Frobenius invariant element actually arises from a curve defined over $\mathbb F$] I wanted to know the things happening under them, like I mean how can one compare each of them in deep.(comparing  analogous terms present on each side) P.S : If the person who answers this question has some time and energy left to answer, I will be happy to hear the  implication chain of B.S.D . (Implication chain length is a new word introduced by me just for the purpose of explaining, [B.S.D for modular forms]$\iff$[B.S.D for rationals]$\iff$[Tate-conjectures]... , so complete implication chain in all possible directions is what I am intending to hear. Thank you.","['number-theory', 'algebraic-geometry', 'elliptic-curves', 'algebraic-number-theory', 'surfaces']"
88239,Characteristic polynomial of a nilpotent matrix,"Let $A$ be $n\times n$ nilpotent matrix. How to calculate  its characteristic polynomial? I know it should be $X^n$, but I don't know why?",['linear-algebra']
88257,Uniform continuity and boundedness,"I have come across a proof which I understand almost completely, except for one part: THEOREM:  If $f$ is uniformly continuous on a bounded interval $I$, then $f$ is also bounded on $I$. PROOF: In this case we assume that $I$ is of the form $(a,b), (a,b], [a,b)$, or $[a,b]$, with $a,b \in \mathbb{R}$. Fix an $\epsilon > 0$, for instance $\epsilon = 1$.  Since $f$ is uniformly continuous, there is a $\delta > 0$ such that: $|f(x_1) - f(x_2)| < \epsilon = 1$ when $x_1, x_2 \in I$ and $|x_1 - x_2| < \delta$ Divide $I$ into $N$ intervals, $I_1, . . ., I_N$, where $N$ is chosen so that $\frac{b-a}{N} < \delta$. Let $z_i$ be the center point of $I_i$.  For each $i$ and $x \in I_i$, $|x - z_i| < \delta$, and then we have: $|f(x)| = |f(x) - f(z_i) + f(z_i)| \leq |f(x) - f(z_i)| + |f(z_i)| \leq 1 + |f(z_i)|$.  Then for $x \in I_i$, $|f(x)| \leq 1 + \max_{1 \leq i \leq N}\{|f(z_i)|\}$. Let $M = \max_{1 \leq i \leq N}\{|f(z_i)|\}$.  Then $|f(x)| \leq 1 + M$ QED OK, so the one thing I am a bit unsure of here, is when we write: Let $M = \max_{1 \leq i \leq N}\{|f(z_i)|\}$. How is it that we know for sure that each $|f(z_i)|$ is also bounded?  I see how the presence of a maximum value completes the proof, but why is it not possible that we have an $|f(z_i)|$ which is unbounded? If anyone could explain this to me I would greatly appreciate it!",['real-analysis']
88260,Sum of derivatives of a polynomial,"Let $p(x)$ be a polynomial of degree $n$ satisfying $p(x)\geq 0$ for all $x$. That is, for all $x$, $p(x) = a_n x^n + a_{n-1} x^{n-1} + \cdots + a_1 x + a_0 \geq 0$, $a_n\neq 0$. Show that $p(x)+p'(x)+p''(x)+\cdots+p^{(n)}(x)\geq 0$ for all $x$ where $p^{(i)}(x)$ is the $i^\text{th}$  derivative. My interest : I know that, we can rewrite the LDE as follows $$
p(x)+p'(x)+p''(x)+\cdots+p^{(n)}(x) = Lp(x)
$$ where $L := I + D + D^2  + \cdots + D^{(n)}$. Can we say anything about a linear operator of this kind so that it does not change the sign of the input it takes? I can try to solve the question by writing for all the derivatives and factoring them using $p(x)$, but I think there should be a clever way of showing this by the properties of $L$. Can I figure out a solution by just looking at $L$ and the sign of $p(x)$ as in the question? Where should I look for that?","['ordinary-differential-equations', 'polynomials']"
88274,Help with a geometry problem,"The problem says: A triangle has its lengths in an arithmetic progression,
with difference d. The area of the triangle is t. Find the dimensions. the solution says:
the notation can be even better if we make it more symmetrical, by making the
side lengths $b − d, b,$ and $b + d$ . by Heron’s formula we know that $t^2 = s(s − b + d)(s − b)(s − b − d)$ , where $s =
((b − d) + b + (b + d))/2$ is the semi-perimeter; and after simplification 
$$ t^2 = \frac{3b}{2}(\frac{3b}{2} - b + d )(\frac{3b}{2} - b ) (\frac{3b}{2} - b - d )  $$
$$ \implies t^2 = \frac{3b^2(b-2d)(b+2d)}{16} = \frac{3b^2(b^2-4d^2)}{16} $$ then we get $$ 3b^4 − 12d^2b^2 − 16t^2 = 0 $$ and using the quadratic formula :
$$ b^2 = \frac{12d^2 \pm \sqrt{144d^4 + 169t^2} }{6} = 2d^2 \pm \sqrt{4d^4 + \frac{16}{3} t^2} $$ and because b has to be positive , we get $$ b = \sqrt{2d^2 + \sqrt{4d^4 + \frac{16}{3}t^2}} $$ Which is the part that i have a problem with , my question is : why should we select only the positive sign solution of the quadratic formula ? is that because $\sqrt{ 4d^4 + \frac{16}{3}t^2} > 2d^2$ which means that the negative sign solution leads to the square root of a negative number which is not valid? why is the positive sign solution is the right solution ? In other words : If  $\sqrt{ 4d^4 + \frac{16}{3}t^2} > 2d^2$  , how is that ? how can we prove it ? thank you","['geometry', 'problem-solving']"
88279,Completing the square,"How might I find linear combinations $$\begin{align*}
A&=a_1x+a_2y+a_3z\\
B&=b_1x+b_2y+b_3z\\
C&=c_1x+c_2y+c_3z
\end{align*}$$ Such that I can transform the two polynomials $$2x^2+3y^2-2yz+3z^2\text{ and }x^2+6xy+3y^2+2yz-6zx+3z^2$$ into $A^2+B^2+C^2$ and $\alpha A^2+\beta B^2+\gamma C^2$ respectively for some $\alpha, \beta,\gamma\in \mathbb R$? I think I should be completing the square, but I can't see how to.","['algebra-precalculus', 'polynomials']"
88284,"Left and right ideals of $R=\left\{\bigl(\begin{smallmatrix}a&b\\0&c \end{smallmatrix}\bigr) : a\in\mathbb Z, \ b,c\in\mathbb Q\right\}$","If $$R=\left\{ \begin{pmatrix} a &b\\ 0 & c \end{pmatrix} \ : \ a \in \mathbb{Z}, \ b,c \in \mathbb{Q}\right\} $$
under usual addition and multiplication, then what are the left and right ideals of $R$?","['ring-theory', 'examples-counterexamples', 'abstract-algebra']"
88285,Are orbits equal if and only if stabilizers are conjugate?,"Let $X$ be a topological space and $G$ a group acting on $X$. 
Do we have this property: $$\operatorname{orb}(x)=\operatorname{orb}(y)\iff\operatorname{stab}(x)\sim \operatorname{stab}(y)\qquad ?$$
where $\operatorname{orb}(x)$ is the orbit of $x$, $\operatorname{stab}(x)=\{g\in G\mid gx=x\}$, and the symbol $\sim$ means conjugate to. One way is obvious: if $\operatorname{orb}(x)=\operatorname{orb}(y)$, then $x=gy$ for some $g\in G$, so $$\operatorname{stab}(x)=\operatorname{stab}(gy)=g\operatorname{stab}(y)g^{-1}.$$
But the other way is not obvious to me: if $\operatorname{stab}(x)\sim \operatorname{stab}(y)$, then $\exists k\in G$ such that
for all $g\in \operatorname{stab}(x)$,  $ \exists h \in \operatorname{stab}(y)$ such that 
$g=khk^{-1}$. Now since $gx=x$ and $hy=y$, then $khk^{-1}x=x$ so $hk^{-1}x=k^{-1}x$ hence $h\in \operatorname{stab}(k^{-1}x)$, but I can't go any further... Thanks for your help.","['general-topology', 'group-theory']"
88293,Can the Schwarz lemma be extended to functions $f : D \to \overline{D}$?,"Let $D$ be the open unit disc. The Schwarz Lemma states that if $f: D \to D$ with $f(0) = 0$, then $|f(z)| \leq |z|$ for all $z \in D$ among other things. Can this extend to the case when $f: D \to \overline{D}$, where $\overline{D}$ is the closed unit disc?",['complex-analysis']
88300,"If $f(x)$ is continuous on $[a,b]$ and $M=\max \; |f(x)|$, is $M=\lim \limits_{n\to\infty} \left(\int_a^b|f(x)|^n\,\mathrm dx\right)^{1/n}$?","Let $f(x)$ be a continuous real-valued function on $[a,b]$ and $M=\max\{|f(x)| \; :\; x \in [a,b]\}$. Is it true that:
$$
M= \lim_{n\to\infty}\left(\int_a^b|f(x)|^n\,\mathrm dx\right)^{1/n} ?
$$ Thanks!",['real-analysis']
88301,Finding the basis of a null space,"I am trying to understand why the method used in my linear algebra textbook to find the basis of the null space works. The textbook is 'Elementary Linear Algebra' by Anton. According to the textbook, the basis of the null space for the following matrix: $A=\left(\begin{array}{rrrrrr} 1 & 3 & -2 & 0 & 2 & 0 \\ 2 & 6 & -5 & -2 & 4 & -3 \\ 0 & 0 & 5 & 10 & 0 & 15 \\ 2 & 6 & 0 & 8 & 4 & 18 \end{array}\right)
$ is found by first finding the reduced row echelon form, which leads to the following: $(x_1,x_2,x_3,x_4,x_5,x_6)=(-3r-4s-2t,r,-2s,s,t,0)$ or, alternatively as $(x_1,x_2,x_3,x_4,x_5,x_6)=r(-3,1,0,0,0,0)+s(-4,0,-2,1,0,0)+t(-2,0,0,0,1,0)$ This shows that the vectors ${\bf v_1}=(-3,1,0,0,0,0),\hspace{0.5in} {\bf v_2}=(-4,0,-2,1,0,0),\hspace{0.5in} {\bf v_3}=(-2,0,0,0,1,0)$ span the solution space. It can be shown that for a homogenous linear system, this method always produces a basis for the solution space of the system. Question I don't understand why this method will always produce a basis for $Ax=0$. Could someone please explain to me why this method will always work? If it helps to explain, I already understand the process of finding the basis of a column space and row space. I also understand why elementary row operations do not alter the null space of a matrix. What specific properties of matrices or vector space that I need to be aware of in order to understand why this method works?",['linear-algebra']
88302,Volume of a cut sphere,The sphere $x^2 + y^2 + z^2 = 4$ is cut by the plane $z = 1/2$. How do you calculate the volume of two parts of the sphere using integrals? Thank you!,['multivariable-calculus']
88312,How is an integral with respect to a Hausdorff measure defined?,"In a reply by Corey : For integrals of scalar-valued functions on unoriented subsets of $\mathbb{R}^n$, one can use the Lebesgue integral with respect to $k$-dimensional Hausdorff measure $\mathcal{H}^k$. The line integral of a scalar function $f$ over a curve $C$ in $\mathbb{R}^3$ is then: $$ \int_C f \, ds = \int_{\mathbb{R}^3} f \, d\mathcal{H}^1,$$ where I assume that $f$ is defined to be 0 off of $C$. A Hausdorff measure is an outer measure on the power set of a metric space induced from the metric. I know how an integral wrt a measure is defined, but I wonder how an integral wrt a Hausdorff measure is defined? Or more generally, how is an integral wrt an outer measure defined, if it exists? Or is it an integral because $\mathbb{R}^3$ is measurable wrt the Hausdorff measure, and the Hausdorff measure is a measure on the set of subsets that are measurable wrt it? Thanks and regards!","['measure-theory', 'metric-spaces', 'functional-analysis', 'real-analysis']"
88324,How to compute the characteristic polynomial of $A$,"The matrix associated with $f$ is:
$$ \left(\begin{array}{rrr}
     3 & -1 & -1 \\
    -1 & 3 & -1 \\
    -1 & -1 & 3
  \end{array}\right) .
$$ First, I am going to find the characteristic equation of $\det(A- \lambda I)$. Please correct me if I'm wrong. $$= (3-\lambda)(3-\lambda)(3-\lambda)-1-1-(3-\lambda)-(3-\lambda)-(3-\lambda)
=-\lambda^3+9\lambda^2-24\lambda+16 .$$ How to factor this? I know the $\lambda$'s should be $1$, $4$ and $4$. But how am I supposed to find these values?","['matrices', 'eigenvalues-eigenvectors', 'roots', 'polynomials']"
88336,Intersection of compact sets,"I have a brief question about Theorem 2.36 in Baby Rudin. The theorem is as follows: If $\{K_\alpha\}$ is a collection of compact subsets of a metric space $X$ such that the intersection of every finite subcollection of $\{K_\alpha\}$ is nonempty, then $\bigcap K_\alpha$ is nonempty. I actually follow Rudin's proof, but the whole theorem seems a bit counterintuitive for me.  After all, it is quite easy to draw, say, three sets, $A$, $B$ and $C$ such that $A\cap B$ is nonempty, $A\cap C$ is nonempty, $B\cap C$ is nonempty, but where $A\cap B \cap C$ is empty.  Imagine for instance you draw to circle-sets, $A$ and $B$, on top of each other, where the top of the lower circle intersect the bottom of the upper circle.  Then you draw one more set, $C$, sorta formed like a snake, where the ""tail"" of the snake intersect the right side of the lower circle, extends a while out, curves $180$ degrees (sort of forming a donut-shape), and then its ""head"" intersects the top circle on the right side (wish I could upload a picture - but hope you get the point).  Then $A\cap B$ is nonempty, $A\cap C$ is nonempty, $B\cap C$ is nonempty, but $A\cap B \cap C$ is empty.  So if $A, B, C$ are compact, wouldn't the theorem then be invalid? If someone can explain to me what is wrong with my reasoning above, then I would be very grateful!  Is it perhaps that we here assumes that $K_\alpha$ is supposed to be a collection of inifinitely many sets?  And in my reasoning above I only use $3$ sets?","['general-topology', 'metric-spaces', 'examples-counterexamples', 'proof-explanation']"
88341,Branch cut and $\log(z)$ derivative,"I'm a little confused about the branch cut thing. Given an entire functions $f(z),g(z),h(z)$, $z\in \mathbb C$, such that $f(x)=g(x)+h(x)$ for all $x\in \mathbb R$, $f$ and $g+h$ doesn't vanish on $\mathbb  R$ . I take the $\log$ for both sides then differentiate and get: $$\log f(x)=\log(g(x)+h(x))$$
$$\frac{f'(x)}{f(x)}=\frac{g'(x)+h'(x)}{g(x)+h(x)}$$ I thought this is correct, but I was asked about ""what is the branch cut I used here?"", and I don't know what does this mean, and what is the answer for this question! Any help!? Edit: I also have the same problem with the following case: If $f(x)=e^{g(x)}$ then $\log f(x)=g(x)$, and $\frac{f'(x)}{f(x)}=g'(x)$, also a branch cut issue!",['complex-analysis']
88356,Parallelogram trigonometry,"(Sorry for the ambiguous title, couldn't think of a better one) While leafing through a highschool textbook, I found what looked like an interesting question in trigonometry. My trigonometry skills are borderline 0, but I didn't expect it to be too much of a challenge. Well, I was wrong: The sides of a parallelogram are $a$ and $b$ and its sharp angle is $\alpha$. The diagnols are $n$ and $m$, and the sharp angle between them is $\beta$. A. Prove: $\frac{mn}{2ab} = \frac{\sin\alpha}{\sin\beta}$ B. Let: $\alpha = \beta$, $a < b$, $m < n$ Prove: $6a^2 + 2b^2 = 3m^2+n^2$ And in (rough) drawing: Following the law of cosines (and that $\cos(180-\theta) = -\cos(\theta)$): $n^2 = a^2 + b^2 - 2ab \cos\alpha$ (in $\Delta ABC$) $m^2 = a^2 + b^2 - 2ab \cos(180-\alpha) = a^2 + b^2 + 2ab \cos(\alpha)$ (in $\Delta DAC$) $a^2 = (\frac{m}{2})^2 + (\frac{n}{2})^2 -2 \frac{m}{2} \frac{n}{2} \cos(\beta)$ (in $\Delta AEB$) $b^2 = (\frac{m}{2})^2 + (\frac{n}{2})^2 -2 \frac{m}{2} \frac{n}{2} \cos(180 - \beta)$ (in $\Delta BEC$) Expanding the last two equations: $$a^2 = \frac{m^2}{4} + \frac{n^2}{4} - \frac{mn \cos(\beta)}{2}$$ $$b^2 = \frac{m^2}{4} + \frac{n^2}{4} + \frac{mn \cos(\beta)}{2}$$ $$\Rightarrow$$ $$a^2 + b^2 = \frac{m^2}{2} + \frac{n^2}{2}$$ And that's where I hit a wall. I have six variables, and can't find a way to express them in a fashion which resembles the end result. A major setback is that I couldn't find a way to express both alpha and beta in the same triangle - if I could, then the law of sines will probably be a rescuer. If possible, I'd like that instead of solving it, maybe you can show me a guideline - where I went wrong, or what I'm missing. Thank you in advance.","['geometry', 'trigonometry']"
88363,Probability distribution and their related distributions,"I am taking a probability course right now and have encountered a lot of interesting distributions and their related distributions. For example, if we have two independent Poisson distribution random variables $X_1,X_2$ with parameters $\lambda_1,\lambda_2$ respectively, and $Y = X_1+X_2$, then $X_1\mid Y= y $ is a binomial distribution random variable with parameter $\left(y,\dfrac{\lambda_1}{\lambda_1+\lambda_2} \right)$. I am wondering if there is a nice summary or something like that about all the distributions and their related distributions.","['probability-distributions', 'probability']"
88369,How to create a formula for calculating armor effect in a rpg game?,"So I'm making a game and want to create an equation for calculating the effect of a stat called armor. The effect is in percent and determines how much damage reduction one has against attacks. The parameters are, 1, Player level and, 2, Armor points. Here's my initial approach: I created a matrix $A$ that looks like this: 
$$\left[\array{
1 &  5 & 0.05\\
30 & 170 & 0.5
}\right]$$
I want the effect to be 5% when the player is level 1 and has 5 armor points. And when the player is level 30 and has 170 armor points, the effect should be 50%. This all works fine, except for two problems: The solution to that Matrix result in something unsuitable: When a player increases his armor points (without gaining in level) the effect decreases . If you have ever played a rpg, it should increase . The changes to the effect are happening too fast. If $B$ is the effect when the player is level 25 and has 150 armor points and $C$ is the effect when the player is level 25 and has 151 armor points, $|B-C|$ is too big. Any suggestions on how to get by problem 1 and 2? To clarify: I rowreduce matrix A. That gives me $$\left[\array{
1 &  0 & 0.3\\
0 & 1 & -0.05
}\right]$$ So the equation I use is
$$\text{effect} = 0.3\text{ level}-0.05\text{ armor}\;.$$ Here's what I would like to happen:
1. I would like the effect to increase as armor increases(and level standing still).
2. I would like the effect to decrease as level increases(and armor standing still).","['matrices', 'linear-algebra']"
88378,Proof that the relation $5 \mid (a + 4b)$ is symmetric and transitive,"Take the relation $R$ to be defined on the set of integers: $$aRb \iff 5 \mid (a + 4b)$$ As part of a larger proof, I have to show that $R$ is both symmetric and transitive. I'm lost. I see the first steps, but I can't find how to progress further. Here's what I have at this point: Proof of Symmetry We have to prove that if $5 \mid (a + 4b)$, then $5 \mid (b + 4a)$. Clearly, this is true if $a = b$, but apart from that, it's unclear in my mind. Proof of Transitivity We have to prove that if $5 \mid (a + 4x)$ and $5 \mid (x + 4b)$, then $5 \mid (a + 4b)$. I've fiddled around with sample values, but I still don't see it. I'm pretty lost here. Thoughts?","['relations', 'modular-arithmetic', 'elementary-number-theory', 'discrete-mathematics']"
88386,Diffeomorphism group of the unit circle,"I am given to understand that the group of diffeomorphisms of the unit circle, $\operatorname{Diff}(\mathbb{S}^1)$, has two connected components, $\operatorname{Diff}^+(\mathbb{S}^1)$ and $\operatorname{Diff}^-(\mathbb{S}^1)$, the diffeomorphisms that preserve or reverse the canonical (counterclockwise) orientation, respectively. Question 1 : How does one prove that? Question 2 : Given $\Phi, \Psi \in \operatorname{Diff}^+(\mathbb{S^1})$, can one construct an explicit path joining them? I'd be satisfied already with a proof that we can join $\Psi, \Phi \in \operatorname{Diff}^+ (\mathbb{S}^1)$, without giving the path explicitly. I tried the obvious path, $t \mapsto \dfrac{t\Phi + (1-t)\Psi}{|t\Phi + (1-t)\Psi|}$, but that doesn't seem to work. Thanks.","['differential-topology', 'homotopy-theory', 'circles', 'differential-geometry']"
88390,How to control the range in a reciprocal function,"Given the reciprocal function $$\frac{a}{m \cdot x + b}$$ where $a,m,b$ are constants. I'm trying to figure out how/if I can control the range that this produces. The application of this problem is generating a ""score"" based on a locations' proximity to me. 
So for example, in my problem I know the range of possible values is $0$-$100$ km, I need to build a score between $1.0$ and $3.0$ where a proximity of $0$ km (i.e., very close) would generate a score closer to $3.0$ and a distance of $100$ km (i.e., very far away) would generate a score closer to $1.0$. I was previously using this successfully to produced a range of $0$-$1.0$, but it turned out that I need greater control over the range produced. Any advice appreciated.","['algebra-precalculus', 'functions']"
88392,How do you find the distance from a point to a plane?,"I am having trouble with this: Find the distance from the point $(1,1,1)$ to the plane $2x+2y+z=0$. Any ideas? Thanks.","['vector-spaces', 'geometry', 'linear-algebra']"
88404,"Definition of ""interior derivative"" and ""exterior derivative""?","In Willie Wong's reply to one question , he used some concepts: ""interior derivative"" of a differential form  and ""exterior derivative"" of a scalar function on $\mathbb{R}^3$. For ""exterior derivative"" of a scalar function on $\mathbb{R}^3$, I think it means the exterior derivative of the scalar function viewed as a 0-form. For ""interior derivative"", I am not able to find the definition from elsewhere.
Here is his original text: Let $\omega$ be a volume form on some manifold $M$. (So if $M$ has
  $n$-dimensions, $\omega$ is a differentiable $n$-form.) Via the volume
  form we can define the notion of volume, and the notion of an integral
  in the usual way. (I assume you are familiar with that already.) Then
  the interior derivative $\iota_v\omega$, which is the $n-1$-form
  defined by $$ \iota_v\omega(X_2,\ldots,X_n) = \omega(v,X_2,\ldots,X_n) $$ for $v$ a vector field on $M$, is a differentiable form of the top
  degree when restricted to any $n-1$-dimensional submanifold. Must an interior derivative of a differential form be specified relative to a vector field? May I have some clue and references here? Thanks in advance!","['differential-forms', 'reference-request', 'differential-geometry']"
88424,"If $ \operatorname{Tr}(M^k) = \operatorname{Tr}(N^k)\;\forall 1\leq k \leq n$, then how do we show the $M$ and $N$ have the same eigenvalues?","Let $M,N$ be $n \times n$ square matrices over an algebraically closed field with the properties that the trace of both matrices coincides along with all powers of the matrix. More specifically, suppose that $\mathrm{Tr}(M^k) = \mathrm{Tr}(N^k)$ for all $1\leq k \leq n$ . The following questions about eigenvalues is then natural and I was thinking it would be an application of Cayley-Hamilton but I am having trouble writing out a proof. How do we show that $M$ and $N$ have the same eigenvalues? Added (because this question is now target of many duplicates, it should state its hypotheses properly). Assume that all the mentioned values of $k$ are nonzero in the field considered; in other words either the field is of characteristic $0$ , or else its prime characteristic $p$ satisfies $p>n$ .","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
88431,Mathematics needed to understand Quantum Topology+Quantum Algebra?,"I've recently been given a book called Quantum Topology by Louis H. Kauffman from a friend of mine. I was wondering what branches of mathematics do I need to be able to read this? What branches of mathematics do I need to understand quantum topology? I understand that a knowledge of Hilbert spaces, algebraic topology and obviously QM is needed. I should have read Hatcher Algebraic Topology book by summer of 2012 as doing a course in it next year. I would like to be in the position to full understand the book in early 2013. Also, anyone got any recommended books on quantum algebra? To make it more concrete. What books should I read so I can understand quantum topology?","['general-topology', 'soft-question']"
88449,The subset of non-measurable set,"If $A$ is a non-measurable set in $\mathbb R^n$ (in the sense of Lebesgue), does it necessarily contain a positive measurable subset?","['measure-theory', 'real-analysis']"
88455,Stirling Numbers of the Second Kind and Finding a General Formula,"I just want to know if I solved this problem correctly, thanks! Find and verify a general formula for $\sum\limits_{k=0}^n k^p$ involving Stirling numbers of the second kind. So I expanded $$\sum_{k=0}^n k^p = 0^p + 1^p + \cdots + n^p\tag{1}$$ and the Stirling numbers of the second kind can be represented as: $$n^p = \sum_{k=0}^n S(p,k)[n]_{k}\tag{2}$$ After replacing each term in $(1)$ by $(2)$, I should get: $$\sum_{k=0}^n k^p = \sum_{k=0}^n S(p,k)[0]_{k} + \sum_{k=0}^n S(p,k)[1]_{k} + \cdots + \sum_{k=0}^n S(p,k)[n]_{k}\;.$$ Is this correct? How else am I supposed to verify this formula?","['stirling-numbers', 'combinatorics']"
88457,An unusual degree of a minimal polynomial,"Give two numbers $a$ and $b$ which are algebraic over $\mathbb{Q}$ with
  $[\mathbb{Q}(a):\mathbb{Q}]=2$, $[\mathbb{Q}(b):\mathbb{Q}]=3$, but the degree of the minimal
  polynomial for $ab$ is smaller than $6$. I have no idea how to approach. If you can't give me an answer, I'd appreciate a starting point suggestion. Thanks so much.",['abstract-algebra']
88467,"Set notation ""element-of"" multiple sets","Let's say I have defined $X$ = users type x and $Y$ = users type y, and I would like to define  $u$ is element-of $X$ and also element of $Y$, is there a simpler way to express, or the expression below is in the simplest form? $$u =\{ e | e \in X \wedge e \in Y  \} $$ Thank you. Regards,
Andy.","['notation', 'elementary-set-theory']"
88469,How do you use the Gram-Schmidt process to generate an orthonormal basis of $\mathbb{R}^3$?,"These vectors form a basis on $\mathbb R^3$: $$\begin{bmatrix}1\\0\\-1\\\end{bmatrix},\begin{bmatrix}2\\-1\\0\\\end{bmatrix} ,\begin{bmatrix}1\\2\\1\\\end{bmatrix}$$ Can someone show how to use the Gram-Schmidt process to generate an orthonormal basis of $\mathbb R^3$?",['linear-algebra']
88475,Continuity of the extension of a function between two locally compact Hausdorff spaces to their one point compactifications,"Let $X$ and $Y$ be two locally compact Hausdorff spaces, and let $X^+$ and $Y^+$ denote the one point compactifications of $X$ and $Y$, respectively.  Let $f: X\rightarrow Y$  be a continuous function and let 
$f^+: X^+ \rightarrow Y^+$ be the obvious extension of $f$.  Show that $f^+$ is continuous if and only if $f$ is proper. By proper, I mean that for every compact subset $U$ of $Y$, the preimage of $U$ is compact. Any help would be appreciated.",['general-topology']
88479,Integration by Parts with Trigonometric Functions,"Trying to evaluate this indefinite integral: $$ \int (x^2 + 1)\cos2xdx$$ So far I have the following: $u=x^2 + 1 \Rightarrow du = 2xdx$ and $dv=\cos2x \Rightarrow v = \frac {\sin2x}{2}$. So the integral is equal to: $$\int (x^2+1)\cos2xdx = (x^2+1)\frac{\sin2x}{2}-\int {\frac{\sin2x}{2}}2xdx$$ Next, I make another substitution for the integral on the right hand side; let $ u = x \Rightarrow du = dx$ and let $dv = \sin2x \Rightarrow v = \frac {-\cos2x}{2}$. Now I have the following: $$\int (x^2+1)\cos2xdx = (x^2+1)\frac{\sin2x}{2}-\left (-\frac {x\cos2x}{2} - \int -\frac {cos2x}{2}dx\right)$$ Which after integrating becomes: $$\int (x^2+1)\cos2xdx = (x^2+1)\frac{\sin2x}{2}-\left(-\frac {x\cos2x}{4} + \frac {\sin2x}{4}\right)$$ But when solving with the integrator on my calculator, I get a different answer (it looks like I am getting closer, but still off). What am I doing wrong here??","['trigonometry', 'calculus', 'integration']"
88482,Law of Large Numbers and Cauchy Distribution,"Let $\{X_n\}_{n=1}^\infty$ be a sequence of iid random variables under the Cauchy distribution with location parameter $0$ and scaling parameter $1$ (so that the density function is $f(x) = \frac{1}{\pi(1+x^2)}$). It can be shown that the characteristic function of these random variables will look like $\varphi(t) = e^{-|t|}$, so $\varphi$ is not differentiable at 0, and hence the weak law of large numbers cannot be applied (because the first moment is infinite). However, how would one go about actually showing that the result of the weak law isn't true (assuming it isn't)? In other words, how can one show that there does not exist a constant $b$ such that $\frac{1}{N} \sum_{n=1}^N X_n \stackrel{\mathbb{P}}{\to} b$? (Here $\stackrel{\mathbb{P}}{\to}$ denotes convergence in probability).",['probability-theory']
88483,"Every space is ""almost"" Baire?","There is this theorem called the Banach category theorem which states that in every topological space any union of open sets of first category is of first category.
Now doesn't this imply that every topological space X (let's say which is not of first category) is the union of a set of first category (the union of all open sets of first category of X) and a subspace which is Baire (the union of all open sets of second category)?
Doesn't this mean that every space is ""almost"" Baire if we understand sets of first category as negligible? A side question: Is there an easy example of a Baire space which is not a completely metrizable space?","['general-topology', 'baire-category']"
88506,Two conformal maps $\phi_i : \Omega \to \Omega$ are identical if they coincide at two different points,"I'm studying some complex analysis in preparation for a qualifier exam and I'm doing exercise $6.12$ from Robert Greene and Steven Krantz' book Function Theory of One Complex Variable. I have $\Omega$ a simply connected domain in $\mathbb{C}$, with $P,Q \in \Omega$ two different points. $\phi_1 : \Omega \to \Omega$ and $\phi_2 : \Omega \to \Omega$ are conformal maps (that is, bijective and holomorphic) such that $\phi_1(P) = \phi_2(P)$ and $\phi_1(Q) = \phi_2(Q)$. Then the question is to prove that $\phi_1 \equiv \phi_2$. I don't know why but I've been thinking about how to approach this without success for quite some time now. I've thought of maybe using the Riemann mapping theorem to say that there's a conformal map $\phi:\Omega \to \mathbb{D}$ to the open unit disk, and similar things but I'm not getting anywhere really. Thus I would really appreciate some help with this problem, maybe some hints on how to proceed would be very appreciated. Thanks in advance for any help.",['complex-analysis']
88517,Number of ways to represent a number as a sum of only $1$’s and $2$’s and $3$’s,"How do I find the number of ways to represent a number as a sum of only $1$’s and $2$’s and $3$’s? I think the title is self-explanatory. E.g., if I have to represent $13$ as a sum of only $1$'s and $2$'s, or $1$'s, $2$'s and $3$'s, what will the formula for finding the number of unordered ways this can be done, i.e., $2 + 2 + 1 = 2 + 1 + 2$? I'm sorry if this is an easy question, but it's been a long time since I used any permutations and combinations, and it's all hazy. P.S. Can you tell me a good online resource to brush up advanced permutations and combinations?","['integer-partitions', 'discrete-mathematics', 'combinatorics']"
88523,Is it true that $ \left| \int_{-\pi}^\pi f(x) \sin nx dx\right| \leq \frac{f(-\pi)-f(\pi)}{n}$?,"Let $f: [-\pi, \pi] \rightarrow \mathbb{R}$ be nonincreasing. Is it true  that
$$ \left| \int_{-\pi}^\pi f(x) \sin (nx) dx \right| \leq \frac{f(-\pi)-f(\pi)}{n}.$$
(Please, without Stieltjes integrals.) I obtain something similar by using the second mean value theorem for integrals but with right hand side equal $2 \frac{f(-\pi)-f(\pi)}{n}$. Thanks. Added. Sorry,  I  mistaked and this inequality is generally not true. It holds the following inequality $$ \left| \int_{-\pi}^\pi f(x) \sin (nx) dx \right| \leq 2 \frac{f(-\pi)-f(\pi)}{n}.$$ The proof goes in the followig way. By the second mean value theorem  there exists a $c\in [-\pi,\pi]$  such that 
$$\int_{-\pi}^\pi f(x) \sin nxdx=f(-\pi)\int_{-\pi}^c \sin nx dx+f(\pi) \int_c^\pi \sin nx dx$$       $$=-\frac{f(-\pi)}{n} (\cos nc-\cos n\pi)-\frac{f(\pi)}{n} (\cos n\pi-\cos nc)$$      $$=\frac{f(-\pi)-f(\pi)}{n} (\cos n\pi-\cos nc).$$
Since $|(\cos n\pi-\cos nc)| \leq 2$ we obtain 
$$ \left| \int_{-\pi}^\pi f(x) \sin (nx) dx \right| \leq 2 \frac{f(-\pi)-f(\pi)}{n}.$$","['integration', 'real-analysis']"
88529,How to prove the Fibonacci sum $\sum \limits_{n=0}^{\infty}\frac{F_n}{p^n} = \frac{p}{p^2-p-1}$,"We are familiar with the nifty fact that given the Fibonacci series $F_n = 0, 1, 1, 2, 3, 5, 8,\dots$ then $0.0112358\dots\approx 1/89$. In fact, $$\sum_{n=0}^{\infty}\frac{F_n}{10^n} = \frac{10}{89}$$ How do we prove that, more generally, for $p > 1$ then, $$\sum_{n=0}^{\infty}\frac{F_n}{p^n} = \frac{p}{p^2-p-1}$$ (The above simply was the case $p = 10$.)","['fibonacci-numbers', 'sequences-and-series']"
88546,Trigonometry basic question,"I am training Trigonometry just for fun, so I am not in a hurry, but would like to know how to answer this question - not the result, but how to do it. Sorry because I understand this is too basic for you, but I forgot almost everything from elementary school... Question says: A sheet of paper measures $210  \space mm \times 297 \space mm$. Consider a diagonal from
  one corner of the sheet to its opposite corner, and choose a point on
  the diagonal so that its distance to the furthest edge of the sheet is
  equal to the length of that edge, that is, $210 \space mm$. What is the
  distance of the point to the nearest edge of the sheet? This is the point I reached (did it in Paint - sorry about the quality): So as you can see I tried but with no success, and would like to know how to continue. Someone can help me? Thank you very much in advance.","['geometry', 'trigonometry']"
88554,Why is there implied an equality between vectors and $n$-tuples?,"Are they considered equal in some sense? For instance, I always write ""...for vector $\mathbf{x} \in {\mathbb{R}}^n$ we have ..."". I have a small problem with this (not a big one). The problem comes from the fact that the ""cartesian power"" of a set is defined as:  ${\mathbb{R}}^n =  \underbrace{ \mathbb{R} \times \mathbb{R} \times \cdots \times \mathbb{R} }_{n}= \{ (x_1,\ldots,x_n) \mid x_i \in \mathbb{R} \ \text{for all} \ 1 \le i \le n \}$. In other words, we are implying that the vector $\mathbf{x}$ is a tuple because we, with the relation ""is an element of"" ($\in$), are defining the $n$-dimensional vector to be a member of a set ${\mathbb{R}}^n$ in where members are $n$-tuples. Is there implied a tiny mathematical abuse of notation here? Or have I completely lost it? :)","['vector-spaces', 'elementary-set-theory', 'definition']"
88567,Prove that the equation $x^{10000} + x^{100} - 1 = 0$ has a solution with $0 < x < 1$,"Prove that the equation $x^{10000} + x^{100} - 1 = 0$ has a solution with $0 < x < 1$. This is a homework question. I know I could probably find a solution that would complete the proof, but I don't think that is what this question is asking. What proof-techniques should I use to prove this is true?","['real-analysis', 'polynomials']"
88615,Function such that its square is not integrable,"I have some set $A$ of Lebesgue measure $\mu(A)=1$. Does this imply that there is some measurable function $f: \mathbb{R}^n \to \mathbb{R}$ such that $$\int_A |f| d\mu< \infty, \int_A |f|^2 d\mu= \infty$$ Certainly if $A=(0,1]$ we could take something like $f(x)=\frac{1}{\sqrt{x}}$. Is there a canonical way to solve this for arbitrary $A$?","['measure-theory', 'integration', 'real-analysis']"
88627,Limit of Lebesgue integral $\int_F \; \frac{dx}{2 - \sin nx}$,"Let $F\subset\mathbb{R}$ be a measurable set of finite Lebesgue measure.
Find the limit 
$$ \lim_{n \to \infty} \int_{F} \frac{dx}{2-\sin nx}.$$ Let $f_{n}(x)=\frac{1}{2-\sin nx}$. This function is bounded and
continuous. Thus, it is integrable. I even use Mathematica to compute the Riemann integral. However, since we don't really know what is $F$. So we don't know $\int_{F}\frac{dx}{2-\sin nx}$. Or this could be seen as a hint, suggesting that the limit does not exist. I want to use the dominated convergence  theorem to show that since $\lim \limits_{n \to  \infty}f_{n}(x)$ does not exist, $\lim \limits_{n \to \infty}\int_{F}\frac{dx}{2-\sin nx}$
does not exist. However, the condition of that theorem is that $\lim \limits_{n \to \infty}f_{n}(x)$ exists. So I guess I can not use this theorem.",['real-analysis']
88640,How do you find the matrix representation of a linear transformation?,"I am having trouble with this problem. I have to find the matrix representation of a linear transformation. The example in my book got me my answer below but I do not feel that it is right/sufficient. Can someone explain matrix representation of a linear transformation? Given $P_2(x)$ and $P_3(x)$ and the linear transformation: $L:P_2(x)\rightarrow P_3(x)$ defined by $L(p(x)) =  \displaystyle \int p(x)dx$. Find the matrix representation $A$ of the linear transformation $L$. Then find the rank of $A$ and the null space of $A$. Here is what I have:
$$A =  \begin{bmatrix}0&1&0\\ 0&0&2\\ 0&0&0\end{bmatrix}$$ $R(A)$ = 2 $N(A)$ = 1","['matrices', 'linear-algebra']"
88651,"For continuous function $f$, prove: $\int_{0}^{x} \; \left[\int_{0}^{t}f(u) \;du \right] \;dt=\int_{0}^{x} f(u)(x-u)du$","I'd love your help with proving that: For continuous function $f$, $$\int_{0}^{x} \left[\int_{0}^{t}f(u) \; du \right] \; dt = \int_{0}^{x} f(u)(x-u)du$$ I'm not quite sure what I should do with this. From Newton-Leibniz theorem I get that the left side of the equation is $(F(t)-F(0))x$, while on the right side I wanted to do an integration by parts, but I'm not sure how or if it is the direction. Thanks a lot for the help.",['calculus']
88669,Is the absolute value function a linear function?,"I'm inclined to say yes, as it doesn't involve exponentiation, roots, logarithmic or trigonometric functions, but I watched a video where the teacher said that the absolute value function is ""clearly non-linear"". Why would he say that? Is he wrong? Wikipedia's graph for abs:","['absolute-value', 'linear-algebra', 'functions']"
88686,Help with a convergence almost everywhere (Rademacher),"I have been proving some facts about Rademacher functions: I know that the Rademacher functions are: $r_n(t)=\operatorname{sign}(\sin{2^n\pi t})$ or, equivalently: 
$$r_m(t):=\left\{\begin{array}{cl}-1 & \mbox{if }t\in\displaystyle\bigcup_{k=1}^{2^{m-1}} \left(\frac{2k-1}{2^m},\frac{2k}{2^m}\right)\\&\\0,&\mbox{if }t\in\left\{\displaystyle\frac{k}{2^m}\,:\,k=1,2,\ldots,2^m\right\}\\&\\1,&\mbox{if }t\in\displaystyle\bigcup_{k=1}^{2^{m-1}}\left(\frac{2k-2}{2^m},\frac{2k-1}{2^m}\right)\end{array}\right.$$ I know the next properties: $\triangleright$ If $n>m$ then  $\displaystyle\int_{I_j^m} r_n=0$, where $I_j^m=\left[\displaystyle\frac{j}{2^m},\frac{j+1}{2^m}\right],0\leq j<2^m$. $\triangleright$ If $n_1<n_2<\ldots<n_k$, then $\displaystyle\int r_{n_1}\ldots r_{n_k}=0$ $\triangleright$ $(r_n)_{n\geq 0}$ is an orthonormal system in $L_2([0,1])$ that is not basis. I have just proved this inequality:
$$\displaystyle\int_0^1\left|\displaystyle\sum_{i=1}^n a_i r_i(t)\right|^4\leq 3\left(\displaystyle\sum_{i=1}^n |a_i|^2\right)^2$$
where $a_1,\ldots, a_n$ are scalars (real or complex). Now I need to show that the sequence $\left(\displaystyle\sum_{i=1}^n \frac{r_i(t)}{n}\right)$ converges t0 $0$ almost everywhere in $[0,1]$ using the last inequality (is assumed that is immediate, but I don't control the convergence a.e.). I thought to use $a_i=\frac{1}{n}$ or something similar, but I don't know. Many thx.","['sequences-and-series', 'analysis']"
88687,Eigenvalues for matrices over general rings,"I am aware of the theory of eigenvalues for matrices over fields. I was wondering to what extent this theory extends? Do we have a corresponding theory for matrices over integral domains, or at least over UFDs?
H.C.Lee remarks here that there is no eigenvalue theory over general rings.","['reference-request', 'abstract-algebra']"
88689,"Show that the norm of the multiplication operator $M_f$ on $L^2[0,1]$ is $\|f\|_\infty$","I'm having some (hopefully small) issues computing the norm of an operator. Firstly, the problem, For $f\in L^\infty[0,1]$, define $M_f: L^2[0,1]\to L^2[0,1]$ by $M_f(g)(x) = f(x)g(x)$. Show that $M_f$ is a bounded linear operator and $\|M_f\| = \|f\|_\infty$. What I've done so far: To see that $M_f$ is linear, let $g_1,g_2\in L^2[0,1]$ and $\lambda\in\mathbb{R}$. Then
$$ M_f(g_1 + \lambda g_2)(x) = f(x)(g_1(x) + \lambda g_2(x)) = f(x)g_1(x) + \lambda f(x)g_2(x) = M_f(g_1)(x) + \lambda M_f(g_2)(x).$$ As $f\in L^\infty$ we know there is some minimal $N\in \mathbb{R}$ such that $|f(x)| \leq N$ almost everywhere (i.e., $\|f\|_\infty = N \lt \infty$). The fact that $M_f$ is bounded comes straight this assupmtion, as
$$ \|M_f\| = \sup \frac{\|fg\|_2}{\|g\|_2} \leq \sup \frac{\|Ng\|_2}{\|g\|_2} = N\sup \frac{\|g\|_2}{\|g\|_2} = N < \infty.$$
almost everywhere in $[0,1]$, for all non-zero $g\in L^2[0,1]$. So $M_f$ is a bounded linear operator on $L^2[0,1]$. To prove equality, we must show there is some $g\in L^2[0,1]$ so that $\frac{\|fg\|_2}{\|g\|_2} = N$. Now I want to say something along the lines of pick $g = 1$, but this won't have $\|g\|_2 = 1$ for all measures, so this won't work. Is there any simple way of picking a $g$ that does what we want? Or am I farther off than I'm expecting? Thanks!","['normed-spaces', 'analysis']"
88691,$(n^2 \alpha \bmod 1)$ is equidistributed in $\mathbb{T}^2$ if $\alpha \in \mathbb{R} \setminus \mathbb{Q}$,"I did the following homework question, can you tell me if I have it right? We want to show that the sequence $(n^2 \alpha \bmod 1)$ is equidistributed if $\alpha \in \mathbb{R} \setminus \mathbb{Q}$. To that end we consider the transformation $T: (x,y) \mapsto (x + \alpha, y + 2x + \alpha)$ on the $2$-dimensional torus $\mathbb{T}^2$ endowed with the Lebesgue measure $\lambda \times \lambda$. a) Show that the action of $T$ on the torus is ergodic, i.e., if a measurable set $A \subset \mathbb{T}^2$ is invariant under $T$, then $(\lambda \times \lambda)(A) \in \{0, 1\}$. Show this by checking the following equivalent definition of ergodicity: $\forall f \in L^2( \mathbb{T}^2)$, we have: if $f$ is $T$-invariant, then $f$ has to be constant almost everywhere. Hint: Use Fourier series. My answer: $$ 
\begin{align}
f(x,y) &= \sum_{j,k \in \mathbb{Z}} c_{jk} e^{ijx} e^{iky}
\\ &\stackrel{f = f\circ T}{=} \sum_{j,k \in \mathbb{Z}} c_{jk} e^{ij(x + \alpha)} e^{ik(y + 2x + \alpha)} 
\\ &=
\sum_{j,k \in \mathbb{Z}} c_{jk} e^{ij\alpha + ik\alpha} e^{ijx + ik2x}e^{iky}
\\ &\stackrel{j \rightarrow j-2k}{=}
\sum_{j,k \in \mathbb{Z}} c_{(j-2k)k} e^{i(j-k)\alpha} e^{ijx}e^{iky} .
\end{align}$$ Now we want $c_{jk} = c_{(j-2k)k} e^{i(j-k)\alpha}$, and we have $|c_{jk}| = |c_{(j-2k)k}| = |c_{(j-4k)k}| = \cdots$, and so on. The series only converges if $|c_{(j-4k)k}| \; \xrightarrow{k \rightarrow \infty} \; 0$ and so $c_{jk}$ has to be $0$, too. b) For $x \in \mathbb{T}$ show that $$ \frac{1}{m} \sum_{n=1}^m T^n_\ast (\delta_x \times \lambda) \rightarrow \lambda \times \lambda$$ using the equidistribution of $(n \alpha \bmod 1)$. My answer: $$ 
\begin{align}
\frac{1}{m} \sum_{n=1}^m T_\ast^n(\delta_x \times \lambda (A \times B)) 
&= 
\frac{1}{m} \sum_{n=1}^m \delta_x \times \lambda ((T^{-1})^n(A \times B)) 
\\ &= 
\frac{1}{m} \sum_{n=1}^m \delta_x \times \lambda (T^n(A \times B)) ,
\end{align}
$$
where I have the last equality because it doesn't matter which way the points are shifted. Then writing out what $T^n$ does I get: $$ 
\begin{align}
\frac{1}{m} \sum_{n=1}^m \delta_x \times \lambda (T^n(A \times B)) 
&= 
\frac{1}{m} \sum_{n=1}^m \delta_x \times \lambda ( (A + \alpha n) \times (B + \alpha n) ) \\ &=
\frac{1}{m} \sum_{n=1}^m \delta_x (A + \alpha n) \lambda(B + \alpha n)
\\ &=
\frac{1}{m} \sum_{n=1}^m \chi_{A + \alpha n}(x) \lambda(B + \alpha n) .
\end{align}
$$ And then using that the Lebesgue measure $\lambda$ is translation invariant I get:
$$
\begin{align}
\frac{1}{m} \sum_{n=1}^m \chi_{A + \alpha n}(x) \lambda(B + \alpha n) = 
\frac{1}{m} \sum_{n=1}^m \chi_{A + \alpha n}(x) \lambda(B) .
\end{align}
$$ And finally, by using the ergodic theorem: $$
\begin{align}
\frac{1}{m} \sum_{n=1}^m \chi_{A + \alpha n}(x) \lambda(B)=
\lambda(B) \int_{\mathbb{T}} \chi_{A + \alpha n} (x) d \lambda(x) = \lambda(B)\lambda(A) = \lambda \times \lambda (A \times B) .
\end{align}
$$ c) For $\eta \in (0,1)$ and $x,y \in \mathbb{T}$ define the two sequences
$$ 
\begin{align*}
\mu_m &= 
\frac{1}{m} \sum_{n=1}^m T^n_\ast \left(\delta_x \times \left(\frac{1}{2 \eta} \left. \lambda \right \vert_{[y-\eta, y + \eta]} \right) \right)
\\
\nu_m &= 
\frac{1}{m} \sum_{n=1}^m T^n_\ast \left(\delta_x \times \left( \frac{1}{1 - 2 \eta} \left. \lambda \right\vert_{\mathbb{T} \smallsetminus [y-\eta, y + \eta]} \right) \right)
\end{align*}
$$ Using exercise 3 of assignment 10 and weak$^\ast$-compactness of the unit ball we know that there exists a subsequence in $\mathbb{N}$ such that both sequences converge along these subsequences. Call the limit points $\mu$ and $\nu$ respectively. Show that $2 \eta \mu + (1 - 2 \eta) \nu = \lambda \times \lambda$. My answer: Exercies 3 of assignment 10 was to show that any weak$^\ast$ limit point $\mu$ of the sequence $\mu_n = \frac{1}{n}\sum_{j=0}^{n-1} T_\ast^j \nu_n$ is a Borel probability measure with $\mu = T_\ast \mu$. $$
2 \eta \lim_{m \to \infty} \frac{1}{m} \sum_{n=1}^m T_\ast^n \left(\delta_x \times \left( \frac{1}{2 \eta} \left. \lambda \right\vert_{[y- \eta, y + \eta]} \right) \right) +

(1 - 2 \eta) \lim_{m \to \infty} \frac{1}{m} \sum_{n=1}^m T_\ast^n \left( \delta_x \times \left( \frac{1}{1- 2 \eta} \left.  \lambda \right\vert_{\mathbb{T} \smallsetminus [y- \eta, y + \eta]} \right) \right) ,
$$
which, by part (b), is equal to 
$$
\left. \lambda \times \lambda \right\vert_{[y - \eta , y + \eta]} +  \left. \lambda \times \lambda \right \vert_{\mathbb{T} \smallsetminus [y - \eta , y + \eta]} = \lambda \times \lambda.
$$ d) Using the following proposition, show that $\mu = \lambda \times \lambda$. Proposition: A $T$-invariant probability measure is extremal if and only if its action is ergodic. My answer: Distinguish the cases $\eta \geq \frac{1}{2}$ and $\eta < \frac{1}{2}$. If  $\eta < \frac{1}{2}$ then by c) $\lambda \times \lambda = 2 \eta \mu + (1 - 2 \eta) \nu$ and since $2 \eta < 1$, by extremality, $\lambda \times \lambda = \mu = \nu$. If $\eta \geq \frac{1}{2}$ then $[y - \eta , y + \eta] = \mathbb{T}$ and so $$ \begin{align}
\mu(A \times B) &= \lim_{m \to \infty} \mu_m (A \times B) 
\\ &= \lim_{m \to \infty} \frac{1}{m} \frac{1}{2 \eta} \sum_{n=1}^m \chi_A(x + \alpha n) \lambda \mid_{[y - \eta , y + \eta]} (B) \\
&\stackrel{b)}{=} \frac{1}{ 2 \eta} \lambda \times \lambda
\end{align}$$ So I think I got the sums wrong here. e) Show that $\mu_m \to \lambda \times \lambda$. To that end prove and apply the following: Lemma: Let $X$ be a metric space and $x \in X$, $x_n$ a sequence in $X$. Assume that each subsequence of $x_n$ has a subsequence converging to $x$. Then $x_n$ itself converges to $x$. My answer: Assume that $x_n$ converges to $y \neq x$. Then there is a (sub)sequence (the sequence itself is a subsequence) not converging to $x$. Contradiction. Same argument for $x_n$ diverges. Now with c) and d), $\mu_m \to \mu = \lambda \times \lambda$. I'm stuck on: f) Show that for all $f \in C(\mathbb{T}^2)$ and for all $\varepsilon > 0$, there exists $\eta > 0$ such that we have $$  \left\vert \int f d \mu_m - \int f d \omega_m  \right\vert < \varepsilon ,$$
where $$ \omega_m = \frac{1}{m} \sum_{n=1}^m T^n_\ast (\delta_x \times \delta_y) .$$ Thanks for your help!","['ergodic-theory', 'equidistribution', 'functional-analysis']"
88695,Proof of an inequality: $\sqrt{n} < \frac{1}{\sqrt{1}} + \frac{1}{\sqrt{2}} + \cdots + \frac{1}{\sqrt{n}}$ [duplicate],"This question already has answers here : Closed 12 years ago . Possible Duplicate: Proving $\sum\limits_{k=1}^{n}{\frac{1}{\sqrt{k}}\ge\sqrt{n}}$ with induction How do I prove the following?
$$\sqrt{n} < \dfrac{1}{\sqrt{1}} + \dfrac{1}{\sqrt{2}} + \cdots + \dfrac{1}{\sqrt{n}},$$ for all $n \in\mathbb{Z}$, $n\ge 2$.","['inequality', 'algebra-precalculus']"
88697,Sufficient condition for a subset to be compact in a Hausdorff topological space,"I know that if $X$ is a Hausdorff topological space and $A$ is compact in $X$, then $A$ is closed in $X$. My question is that if $A$ is a closed set in $X$ (where $X$ is Hausdorff), what extra condition is needed to ensure that $A$ is compact in $X$?",['general-topology']
88715,Implicit function theorem for $f:\mathbb{R}^{3} \rightarrow \mathbb{R}$,"I am stuck at this problem and I would be glad if somebody helped me out: By the implicit function theorem, it should be shown that: $$f(x,y,z) := z^{3}+2xy-4xz+2y-1 .$$ The zero level set $f^{-1}(0)$ in a neighborhood $U$ of $(x_0, y_0) = (1,1)$ can be rewritten through a differentiable function $z=g(x,y)$ where $g(1,1)=1$. Then also the partial derivatives: $g_x(1,1), g_y(1,1)$ should be calculated. The partial derivative in respect to $z$ is: $f_z = 3z^2- 4x$ and it holds that $3z^2 - 4x \ne 0$, because otherwise the invertibility would not be given anymore. So if $(x_0, y_0)=(1,1)$ then $z^3- 4z+4=0$ gives $3$ solutions, of which none are such that $3z^2-4 = 0$. So the zero level set in $U$ can be rewritten through $g(x,y)$. Now the remaining task is to solve $z^3 +2xy-4xz+2y-1=0$ for $z$. I sit around at this end: $$z^3- 4xz=-2xy-2y+1 = z(z^2- 4x)=-2xy-2y+1 \Rightarrow z = \frac{-2xy-2y+1}{z^2-4x} .$$ According to Wolfram Alpha, there are 3 exact solutions .",['multivariable-calculus']
88716,Modified Cholesky factorization and retrieving the usual LT matrix,"I have been looking at the modified Cholesky decomposition suggested by the following paper: Schnabel and Eskow, A Revised Modified Cholesky Factorization Algorithm , SIAM J. Optim. 9, pp. 1135-1148 (14 pages). The paper talks about an implementation of the Cholesky decomposition, modified by the fact that when the matrix is not positive definite, a diagonal perturbation is added before the decomposition takes place. The algorithm given in the paper (Algorithm 1) suggests that it finds factorization such that $LL^\top = A + E, E \ge 0$. But, when implemented as stated in the paper, what I get is a lower triangular factor matrix $L$, such that:
$$P\cdot(L\cdot L^\top)\cdot P^\top = A + E$$
where, $P$ is a permutation matrix. This $L$ matrix is not the same as when using the normal Cholesky factorization for a PD matrix, where $A = L_1L_1^\top$, say. Now, I am using it in optimization context, specifically in trust region methods, where this decomposition is followed by inverting $L$ (to compute the trust region step), so it would be helpful to have factors in lower triangular form. Is there a way to get back $L_1$ (the original Cholesky factor) for a positive definite matrix from the $P$ and $L$ matrix obtained from the modified Cholesky factorization? I am a bit surprised that the algorithm misstates what it would produce, so maybe I am missing some step here. Related threads I have found so far: Cholesky factorization Cholesky decomposition and permutation matrix The second thread says that the relationship is not possible to find for any given set of matrix (not necessarily for a modified Cholesky decomposition as mentioned here). Not sure if the answer still holds in this case as well. Example: Consider the following $4\times4$ matrix which is PD.
$$A = \begin{bmatrix}6 & 3 & 4 & 8 \\ 3 & 6 & 5 & 1 \\ 4 & 5 & 10 & 7 \\ 8 & 1 & 7 & 25 \end{bmatrix}$$
The vanilla Cholesky factor $L_1$, such that $L_1L_1^\top=A$ is:
$$L_1 = \begin{bmatrix}2.4495 & 0 & 0 & 0 \\ 1.2247 & 2.1213 & 0 & 0 \\ 1.6330 & 1.4142 & 2.3094 & 0 \\ 3.2660 & -1.4142 & 1.5877 & 3.1325 \end{bmatrix}$$
Now, if I perform the modified Cholesky, I get:
$$L=\begin{bmatrix}5 & 0 & 0 & 0 \\ 1.4 & 2.83549 & 0 & 0 \\ 0.2 & 1.66462 & 1.78579 & 0 \\ 1.6 & 0.62070 & 0.92215 & 1.48471 \end{bmatrix}$$
and
$$P=\begin{bmatrix}0 & 0 & 0 & 1 \\ 0 & 0 & 1 & 0 \\ 0 & 1 & 0 & 0 \\ 1 & 0 & 0 & 0 \end{bmatrix}$$
Such that, $P\cdot (L\cdot L^\top)\cdot P^\top = A$. Of course, since $A$ is PD, $E=0$.","['matrix-decomposition', 'nonlinear-optimization', 'cholesky-decomposition', 'matrices', 'numerical-linear-algebra']"
88719,A group $G$ with a subgroup $H$ of index $n$ has a normal subgroup $K\subset H$ whose index in $G$ divides $n!$,"I would be very thankful if someone could give me a hint with proving this. It's a very common exercise in abstract algebra textbooks. If $G$ is a group with a subgroup $H$ of finite index $n$, then $G$ has a normal subgroup $K$ contained in $H$ whose index in $G$ is finite and divides $n!$. I found the proof on this Wikipedia page at some point (although the proof appears to be no longer there), but I got lost in one of the details.","['group-theory', 'abstract-algebra', 'normal-subgroups']"
88721,Expected value and Variance of a Random Variable,"I understand Mean (Expected Value) and Variance of Random variables as outlined on this page. I can't seem to apply those concepts to this problem, however. Say there's a class of 50 people answering a question. There is a 60% chance that any given student knows the answer. Let $X$ be the number of students who get the correct answer. My general sense for Expected Value in this case is just $0.6 \cdot 50=30$. But I don't think that's correct. I don't even know how to approach Variance in this case. Each student is equally likely to get the correct answer and I keep getting large numbers which make no sense: $$\sum_{i=0}^{50}\left(\left(i-30\right)^2\cdot0.6\right)\approx7395$$ That is obviously incorrect... can anybody offer any pointers?","['discrete-mathematics', 'probability']"
88722,"Convergence of the Integral $ \int_0^1 \frac{1}{\sqrt{\sin x}} \, dx$","Here is an old question from my real analysis exam. It has been bugging me for the good part of a year. Does the following integral converge? $$ \int_0^1 \frac{1}{\sqrt{\sin x}} \, dx$$ I'm pretty sure the comparison test is the way to go. Any insight would be greatly appreciated. Thanks.","['definite-integrals', 'calculus']"
88755,Prove: a countable intersection of open and dense sets in a compact Hausdorff $X$ is dense,"Let $X$ be a compact Hausdorff space and let $\{U_n\}$ be a countable collection of subsets that are open and dense in $X$. Show that the intersection $$\bigcap\limits_{n=1}^\infty U_n$$
is dense. I tried to show that the closure of this intersection is equal to the intersection of the closures of each set, but I'm not getting anywhere. Any help would be greatly appreciated.",['general-topology']
88764,Finding all positive integer solutions to $(x!)(y!) = x!+y!+z!$,"The equation is $(x!)(y!) = x!+y!+z! $ where $x,y,z$ are natural numbers. How to find out them all?","['factorial', 'combinatorics', 'diophantine-equations', 'number-theory']"
88767,dense subsets in metric spaces,"I am stuck on this problem. Any help? Problem a)- Let $X$ be a complete metric space and let $V_{n}$, $n=1,2,3,...$ be open and dense sets. Prove that $\bigcap_{n=1}^{\infty }V_{n}$ is dense in $X$ . b)- Use part a) to prove that the set of irrational numbers cannot be written as a union of countably many closed subsets of $R$.","['general-topology', 'real-analysis', 'analysis']"
88784,Function which has no fixed points,"Problem: Can anyone come up with an explicit function $f \colon \mathbb R \to \mathbb R$ such that $| f(x) - f(y)| < |x-y|$ for all $x,y\in \mathbb R$ and $f$ has no fixed point? I could prove that such a function exists like a hyperpolic function which is below the $y=x$ axis and doesn't intersect it. But, I am looking for an explicit function that satisfies that.","['general-topology', 'fixed-point-theorems', 'fixed-points', 'real-analysis']"
88793,"If $\{u,v,w\}$ is a basis for $V$, then $\{u+v+w,v+w,w\}$ is also a basis: is this proof correct?","Let $u,v,w \in V$ a vector space over a field F such that $u \neq v \neq w$. If $\{ u , v , w \}$ is a basis for $V$, then prove that $\{ u+v+w , v+w , w \}$ is also a basis for $V$. Proof: Let $u,v,w \in V$ a vector space over a field $F$ such that $u \neq v \neq w$. Let $\{ u , v , w \}$ be a basis for $V$. Because $\{ u , v , w \}$ is a basis, then $u,v,w$ are linearly independent and $ \langle \{ u , v , w \} \rangle = V$. Let $x \in V$ be an arbitrary vector then $x$ can be uniquely expressed as a linear combination of $\{ u , v , w \}$. Let's suppose $x=au+bv+cw$ for some $a,b,c \in F$. On the other hand, let us consider $\{ u+v+w , v+w , w \} \subseteq V$. Then $$ \begin{align*}
\langle \{ u+v+w , v+w , w \} \rangle &= \{d(u+v+w) + e(v+w) + f(w) \mid d,e,f \in F\} \\ &= \{du + (d+e)v +(d+e+f)w \mid d,e,f \in F \} . \end{align*}$$ If $x \in V$, then $x=du + (d+e)v +(d+e+f)w$ is another unique representation of $x \in V$ . Then for any arbitrary $x \in V$, we have $d=a$, $d+e=b $and $d+e+f=c \in F$. Because $\{ u , v , w \}$ is a basis for $V$, then $\{ u+v+w , v+w , w \}$ must also be a basis for $V$.",['linear-algebra']
88796,Two formulas for the minimal eigenvalue of a graph,"Hello again everybody, I'm reading Fan Chung's monograph Spectral Graph Theory . In it, she has two formulas for the minimal eigenvalue of a graph.  She doesn't explain why they're equivalent, and I'm having difficulty justifying it.  Below, I'll explain everything and state my question precisely. Let $G=(V,E)$ be a graph and let $d_v$ denote the degree of $v\in V$. Let $T$ denote the diagonal matrix whose $(v,v)^{\text{th}}$ entry is $d_v$. The Laplacian $\mathcal{L}$ of $G$ is the matrix defined by
$$ \mathcal{L}_{i,j} := \Bigg\{
\begin{array}{cc}
1 & \text{if } u=v \\
-1/\sqrt{d_v d_u} & \text{if } \{u,v\} \in E \\
0 & \text{otherwise}
\end{array}
$$
The eigenvalues $\lambda_0 \leq \lambda_1 \leq \dots \leq \lambda_{n-1}$ of $\mathcal{L}$ are called the eigenvalues of $G$.  Since it's not too hard to show that $0=\lambda_0$ for every graph, we call $\lambda_1$ the minimal eigenvalue of $G$. Since $\mathcal{L}$ is Hermitian, its eigenvalues are all nonnegative reals and the minimal eigenvalue is determined by the Rayleigh-Ritz ratio (see, e.g. Theorem 4.2.2 of Horn & Johnson):
$$ \lambda_1 = \min \frac{\langle g,\mathcal{L}g \rangle}{\langle g,g\rangle}
$$
Here the minimum is taken over all $g : V\rightarrow \mathbb{R}$ not identically $0$, which we think of as length-#$V$ real vectors.  With some algebraic manipulation that ratio becomes 
$$ \lambda_1 = \inf \frac{\sum_{\{u,v\}\in E} (f(u)-f(v))^2}{\sum_v f(v)^2d_v}
$$
where $g=T^{-1/2} f$ and the infimum is taken over all functions $f$ such that $f \bot T1$ where $1$ is the all-$1$ vector. That formula makes sense, I think.  However, later (in the proof of theorem 2.2) she states that 
$$ \lambda_1 = \frac{\sum_{v \in V_+} f(v) \sum_{\{u,v\}\in E_+} (f(v)-f(u))}{\sum_{v\in V_+} f^2(v) d_v}
$$
where $V_+ := \{ v : f(v) \geq 0\}$ and $E_+ := \{ \{u,v\} \in E : u \text { or } v \in V_+\}$. I can't understand why these two formulas for $\lambda_1$ are equivalent.  Chung's silence on this point may be because the equivalence is obvious.  But could someone shed light on this for me?","['graph-theory', 'spectral-graph-theory', 'eigenvalues-eigenvectors', 'combinatorics']"
88802,Expected value of the minimum of a random set of distances,"You are given a rectangular $n_1\times n_2$ grid with one light bulb $b_i$ at every node. Each bulb is on or off with probability $p$ and $1-p$, respectively, and furthermore you know that exactly $m$ bulbs are on. Equip the grid with the Manhattan metric $d$, and look at the set of distances between distinct bulbs which are on : $$S:=\{d(b_i,b_j): i\neq j, b_i \textrm{ and } b_j \textrm{ are on}\}.$$ To understand how close two lit bulbs should be, I would like to compute the expected value of the random variable $X:=\min S$ (in terms of $n_1,n_2,p$ and $m$). Any hints on how to start thinking about this problem? Thank you.","['discrete-mathematics', 'probability', 'combinatorics']"
88826,Integer coordinate set of points that is a member of sphere surface,"I have a graphic application to develop which involve many spheres. I should determine then on run time. Supposing that I have a sphere of radius r, how can I determine the sub set of the sphere surface points that are integer? E.g., $r = 10$ I can have $(10,0,0), (8,6,0),$ etc. (Obs.: I really think this is not a programming question, that's why I not posted In stack overflow. If I am wrong, please fell free to warn me that :) Pedro","['geometry', 'diophantine-equations']"
88837,"Which is the ""fastest"" paper-pencil method to compare $\sqrt[17]{6}$ and $\sqrt[16]{4}$?","Which is the ""fastest"" paper-pencil method to compare (find which one
  is greater) $\sqrt[17]{6}$ and $\sqrt[16]{4}$? My analysis bought this whole thing down to comparing which is greater between $6^{16}$ and $2^{34}$.Then by using the technique mention here doesn't gives the precise answer as $\log_2 6$ lies between $2 \text { and }3$, how else I could do this?","['exponentiation', 'algebra-precalculus']"
88840,Counting barcodes,"This certain problem is related to different combinations of strips in a barcode. The question is that how many different codes are possible in a barcode, reading from left to right, according to these rules: barcode should be composed of alternate strips of black and white barcode should always be beginning and ending with a black strip each strip (of either colour) has the width 1 or 2 the total width of the barcode is 12 For example, this barcode is one of the many which conform to the rules. I approached this problem by representing the four different strips by b1 (black of width 1) b2 (black of width 2) w1 (white of width 1) w2 (white of width 2) Then all codes would have this pattern b1 ...... b1 (width so far: 2) b2 ...... b2 (width so far: 4) b1 ...... b2 (width so far: 3) b2 ...... b1 (width so far: 3) since they always begin and end with black. Next step was the 2nd and 2nd last strips of white color. Again the pattern would be: w1 ...... w1 (width so far: 4) w2 ...... w2 (width so far: 8) w1 ...... w2 (width so far: 6) w2 ...... w1 (width so far: 6) with all the four patterns of black mentioned above. This seemed to get automated but the width was hinderance in deriving a formula. Then the question is that should  all of this be done manually or does MATH offer a solution?",['combinatorics']
88847,Frobenius maps and orthogonal groups,"I have recently encountered Frobenius maps in the context of orthogonal and symplectic groups. However, some aspects still strike me as odd. Maybe I'm making some stupid mistakes here. 
Let's just assume that $G$ is an orthogonal group of dimension $n$ over the algebraic closure of a finite field with $q$ elements. Let's view $G$ as a matrix group and say that $F$ is the standard Frobenius morphism (of the general linear group) raising each entry of a given matrix to the $q$-th power. Why is $F$ then a Frobenius morphism for $G$? I understand that the basic concept involved is $F$-stability, but... Is it obvious?","['finite-groups', 'group-theory', 'abstract-algebra']"
88881,Getting a standard form quadratic from a set of points ($3$ points),"I came home from school today, pulled out my homework, now I'm stumped.  I don't want the answer, I just want to know how to do it. Here is the question that I'm reading: Determine a quadratic function in standard form for the set of points $(x_1,y_2)(x_2,y_2)(x_3,y_3)$ Where the $x$'s and $y$'s represent the points. Here are the points I am working with (remember, I don't want the answer, I just want to know how to do it, there are lots of questions on this so I want to be able to know how to do it). $(-1, 2), (0, 1), (1, -4)$ Thanks!","['quadratics', 'algebra-precalculus']"
88882,"$G$ a bounded region, $f,g$ continuous and zero free follows $f(z)=\lambda g(z)$ for some $\lambda \in \partial G$","This is an exercise from a book called ""theory of complex functions"" I am trying to solve: Let $G$ be a bounded region, $f,g$ continuous and zero-free in $\overline{G}$ and holomorphic in $G$. With $$|f(z)|=|g(z)| \ \ \ \ \ \forall z \in \partial G$$ It follows that there exists a $\lambda \in S^{1}$ such that $f(z)= \lambda g(z) \ \ \ \forall z \in \overline{G}$ I dont know how to even begin. Does anybody see how to begin? Please, do tell.",['complex-analysis']
88900,Intersection $f(G\cap \mathbf{R}) \subset \mathbf{R} \Leftrightarrow f(\bar{z}) = \overline{f(z)}$,"$G\subset \mathbf{C} , G= \{z\in \mathbf{C}| \overline{z}\in G\} = \overline{G}$, then for $f\in \mathcal{O}(G)$ it holds that:$$f(G\cap \mathbf{R}) \subset \mathbf{R} \Leftrightarrow \forall z\in G : f(\overline{z}) = \overline{f(z)}$$ This is an example in the script of our professor, however there is no proof for it and it hasn't been shown during the lectures either. Proof   :
$""\Rightarrow "" :$ Let $f(G\cap \mathbf{R}) \subset \mathbf{R}$, so all points on the real axis are mapped to the real axis. That means $f$ does not have any imaginary part, because then this would not be true anymore. Since f does not have any imaginary part. it follows also that : $f(\overline{z}) = \overline{f(z)}$ $""\Leftarrow"" :$ Let $f(\overline{z}) = \overline{f(z)}$, so f can not have any imaginary part, otherwise this would not be true anymore. But if f doesn't have any imaginary part, then the map of the real axis is always on the real axis. So $f(G\cap \mathbf{R}) \subset \mathbf{R}$ What I mean with not having any imaginary part is that it is of the form $f(z) = z ; f(z)=2z; f(z) = 2z+z^{3}$ etc. I am not sure if this is the right thought, and how to express this better. Help is greatly appreciated.",['complex-analysis']
88902,"What is the constant $e$, fundamentally? [duplicate]","This question already has answers here : Closed 12 years ago . Possible Duplicate: Why is the number e so important in mathematics? Intuitive Understanding of the constant “e” The number $e$ is important in many respects. If you ask anyone why it is important, you will get multiple answers. Some say the defining property is that the derivative of $e^x$ is $e^x$. Some say that it is due to it being the limit $(1+\frac{1}{n})^n$, some define it using the integral of $\frac{1}{x}$. So far my personal intuition has been that all of those explanations are somewhat secondary. That is, rather than describing some fundamental property of $e$, they just demonstrate the consequences. I understand that this opinion is somewhat subjective and the question is vague, but I hope someone here might understand what I mean and, perhaps, provide a ""better"" answer to the simple question of ""what is $e$""? Intuitively, I feel there are several directions which might provide a ""satisfying"" response. Firstly, perhaps $e$ can be expressed as an elegant and very important general invariant? Something like ""for each isomorphism $f$ between the additive and the multiplicative groups of $\mathbb{R}$, $e=f(f(x)/f'(x))$"". If only it were clear why such (or a similar) invariant must play an important role and participate in all those multiple well-known equations, it would clear things up a lot. Secondly, perhaps there is a nice ""information-theoretical"" explanation for $e$ playing, in some sense, the same role in the multiplicative group as $1$ does in the additive group of $\mathbb{R}$. I.e. with some generalizations $1$ can be viewed as a generator of $(\mathbb{R},+)$ (because any $a = 1\cdot a$), and although any other nonzero number would also work, $1$ is the most ""reasonable"" choice. Similarly, it seems that $e$ is the best choice for a generator in the multiplicative group. If it can be shown to be the ""most reasonable"" choice, perhaps it would become obvious (or, at least, ""natural"") for $e$ to pop up everywhere where infinite multiplications are involved. Finally, maybe the question I am asking is better phrased as ""what properties of the field of real numbers can be stripped away for $e$ to still remain a fundamentally important object""? For example, is there a similarly-important ""$e$"" in any continuous group? Thanks.","['calculus', 'lie-groups', 'analysis']"
88904,Proof for constant function without Picard's little theorem,I need to prove without using Picard's Little Theorem the following statement: Let $f(z)$ an entire function such that $f(z) \notin \mathbb R$  for every $z \in \mathbb C$. Prove that $f$ is constant. Do you have a way to do it? Thanks,['complex-analysis']
88909,Conditions for convergence to symmetric stable distribution?,"Under which conditions converges a sum of i.i.d. random variables $$
\frac{1}{a_N} \sum\limits_{n=1}^N X_n
$$ to a symmetric stable distribution? Two examples of sufficient conditions are finite variance or symmetry of $X_n$. But can we say anything about the symmetry of the limit distribution without making any of these two assumptions? Thanks.","['statistics', 'sequences-and-series', 'probability-theory']"
88916,Correspondences between Borel algebras and topological spaces,"Though tangentially related to another post on MathOverflow ( here ), the questions below are mainly out of curiosity. They may be very-well known ones with very well-known answers, but... Suppose $\Sigma$ is a sigma-algebra over a set, $X$. For any given topology, $\tau$, on $X$ denote by $\mathfrak{B}_X(\tau)$ the Borel algebra over $X$ generated by $\tau$. Question 1. Does there exist a topology, $\tau$, on $X$ such that $\Sigma = \mathfrak{B}_X(\tau)$? If the answer to the previous question is affirmative, it makes sense to ask for the following too: Question 2. Denote by ${\frak{T}}_X(\Sigma)$ the family of all topologies $\tau$ on $X$ such that $\Sigma = \mathfrak{B}_X(\tau)$ and let $\tau_X(\Sigma) := \bigcap_{\tau \in {\frak{T}}_X(\Sigma)} \tau$. Is $\Sigma = \mathfrak{B}_X({\frak{T}}_X(\Sigma))$? Updates. Q2 was answered in the negative by Mike ( here ).","['general-topology', 'measure-theory', 'descriptive-set-theory']"
88918,Solving a logarithmic equation,"$\ln(x + 1) = 2 + \ln(x - 1)$; solve for $x$. From there I get 
$$\ln \frac{x+1}{x-1} = 2.$$ Am I headed in the right direction, in our examples we would exponentiate both sides, does that still stand for this even though there's only a 2 on the right hand side?","['logarithms', 'algebra-precalculus']"
88936,Is any subset of an open quasi-compact set quasi-compact?,"In a general topological setting what can be said about an open quasi-compact set?
Is it true that a subset of such a set is compact?  What if that set is open?
I ask because this came up in class today with someones solution to a problem (my
class consists mainly of student presentations). I should have asked at the time, but thought about it too much and didn't have an opportunity. So the statement seemed to be that any subset of an quasi-compact open set is quasi-compact- though for the problem we were discussing the subset was also open (though it seemed like this wasn't really used). It feels like it should be easy to prove or disprove but I haven't been able to come up with anything.
Thanks.
(Note: Hausdorff is not assumed) Edit: I must apologize I have been away. In all instances where I merely wrote compact I meant quasi-compact. The point being that there is no assumption on the Hausdorff property.",['general-topology']
88937,"$f:B_{1}(0) \Rightarrow$ holomorphic, $\max_{|z|=r} |f|$ monotonically and continuous","This is an exercise from a book called ""theory of complex functions"" I want to solve: $f\colon B_1(0) \Rightarrow$ holomorphic, then $M\colon[0,1)\rightarrow \mathbb{R}$ given by  $M(r ) := \max_{|z|=r} |f|$ is monotonically increasing and continuous. $M (r)$ strictly monotonically increasing $\Leftrightarrow f$ is not constant. For $m\in \mathbb{N}$ let $f(z) = \sum_{-m}^{\infty} a_{n}z^{n}$be holomorphic in $B_{1}(0)$. Then for every $r$ with $0<r<s$ defining $M( r) := \max_{|z|=r} |f(z)|$ gives :$$ |a_{k}|\le \frac{M (r )}{r^{k}},\qquad \forall k\ge -m .$$ Proof: If $\epsilon > 0$ with $k=0$, then one can choose $n\in \mathbb{N}$ so large that the remaining series $g(z) := \sum_{n+1}^{\infty} a_{n}z^{n}$ satisfies $\max_{|z|=r}|g(z)| \le \epsilon$. Then also: $q(z) := f(z) - g(z) = \sum_{-m}^{n} a_{n}z^{n}$ satisfies$$\max_{|z|=r}|q(z)| \le M( r)+ \epsilon.$$ Now a lemma has been shown before that says that $|a_{0}| \le M( r) + \epsilon ; \epsilon >0$, thus $|a_{0}| \le M( r)$. Now if $\displaystyle k\ge -m$, then $z^{-k}f(z)= \sum_{-(m+k)}^{\infty} a_{k+n}z^{n}$ is holomorphic in $B_{1}(0)$. Its constant term is $a_{n}$ and $\max_{|z|=r} |z^{-k}f(z)| = r^{-k}M( r)$. So$$|a_{k}| \le r^{-k} M( r),$$which means that $M( r)$ is monotonically increasing and continuous. If $f$ were constant, then $a_{k}$ is $0$, and one gets $0 \le M( r)/r^{k}$, so this series is monotonically decreasing. So $f$ can't be constant if $M(r)$ is strictly monotonically increasing. The book doesn't provide any solutions I can compare to. Does anybody see if my arguing is correct? Please, do tell. Merci.",['complex-analysis']
88938,"""Immediate"" Applications of Differential Geometry","My professor asked us to find and make a list of things/facts from real life which have a differential geometry interpretation or justification. One example is this older question of mine. Another example my teacher presented is proving that on a soccer ball which is made of regular pentagons and regular hexagons, the number of pentagons is fixed, as a consequence of Euler's polyhedral formula. I guess that there are many more of these. The idea is to find things/facts whose explanation is a theorem in differential geometry and eventually give a reference to a book/article where these connections are explained. My teacher wants us to make such a list and then each to pick a subject and make a project which presents the theorem which is applied (with proof, if the proof is not too long) and then present the application itself. Any reference or book on the subject is more than welcome.","['big-list', 'differential-topology', 'reference-request', 'differential-geometry']"
88958,Where is the topology hiding in this theorem on entire functions?,"There is a standard theorem that says if $f$ is analytic in the whole complex plane and never zero, then it has the form $e^g$ where $g$ is analytic in the whole plane; i.e. we can define a function $\log f$ that is analytic in the whole plane and satisfies $f=e^{\log f}$.  The argument is easy: $f$ is entire and never zero, so $f'/f$ is entire, so $g(z)=\int_0^z f'(\zeta)d\zeta/f(\zeta)$ is well-defined and entire, and then computation shows that $fe^{-g}$ has derivative zero, so is constant, so $f$ is a constant multiple of $e^g$, and the constant can be absorbed into $g$. The argument does not mention the topology of the situation, and this bugs me a little.  By the Little Picard theorem, the image of $f$ is the whole complex plane minus zero.  In general, of course, a continuous single-valued branch of $\log$ cannot be defined on this set. That's why the proof involved the integral of the logarithmic derivative of $f$, rather than merely the composition of $f$ with the right branch of $\log$.  That said, if we obtained a different function $h$ by picking some branch of $\log$ defined on $\mathbb{C}$ minus some ray from the origin (call this set $S$), and then defining $h(z)=\log f(z)$ on $f^{-1}(S)$, then of course $h$ would satisfy $f=e^h$ where it is defined, and then $1=e^{h-g}$, so that on each connected component of $f^{-1}(S)$, since $h,g$ are defined and continuous they must differ by a constant multiple of $2\pi i$. If I allow myself to use a different branch of $\log$ for each connected component of $f^{-1}(S)$, I could end up with $h$ exactly equaling $g$ and therefore being extendable by continuity to all of $\mathbb{C}$. What this adds up to is that I have the strong feeling that the theorem (in spite of the easy calculation-based proof) has some nontrivial topological content and I am trying to isolate this content. At this point, I was originally going to ask for help isolating the topological content.  But over the course of composing the question, I think I may have answered it. So, following is what I believe to be an alternative proof of the original result that makes the topological content explicit. My question is now, is the following proof correct? I would also be interested in your thoughts about (soft-question) where is the topology hiding in the original proof? Theorem: If $f$ is entire and never zero it has the form $f=e^g$ for $g$ entire. Proof: Let $f$ be an entire function that is never zero.  Then $f:\mathbb{C}\rightarrow\mathbb{C}\setminus\{0\}$ is continuous, so induces a homomorphism $f_*:\pi_1(\mathbb{C})\rightarrow\pi_1(\mathbb{C}\setminus\{0\})$, which is trivial because $\mathbb{C}$ is simply connected.  Therefore, $f$ lifts to a continuous function $\hat{f}$ from $\mathbb{C}$ to $\mathbb{C}\setminus{0}$'s universal cover $U$. But $U$ is the Riemann surface of the $\log$ function; in particular, the logarithm is well-defined and single-valued on $U$; so let $g=\log \hat{f}$; and then $g$ is such that $f=e^g$. $\hat{f}$ is actually holomorphic to $U$, so the $g$ thus defined is entire. EDIT: When I wrote this proof I was a little uncomfortable with speaking of $\hat{f}$ being holomorphic to $U$ and the log being holomorphic on $U$, since my understanding of covering space theory is strictly topological. Subsequently I realized that we can actually take $U$ to be $\mathbb{C}$, with the covering map given by $z\mapsto e^z$, and then the ""logarithm on $U$"" is just the identity on $\mathbb{C}$. I think the argument goes through, but can be made even shorter: By the lifting theorem, any function $f$ from a simply connected domain to $\mathbb{C}\setminus\{0\}$ has a lift $\hat{f}$ to $\mathbb{C}\setminus{0}$'s universal cover, $\mathbb{C}$, that factors through the covering map $z\mapsto e^z$. Then $f=e^{\hat{f}}$ and $\hat{f}$ is the desired $g$. Since the covering map is holomorphic, $f$ and $\hat{f}$ are simultaneously holomorphic. Done! Thanks to Jonas Meyer for highlighting that the key feature of the original argument is also the simple-connectedness of the domain, on which rests the invocation of Cauchy's theorem to show the integral is well-defined.","['general-topology', 'complex-analysis']"
88980,Infinite group with only two conjugacy classes,Can you show me a reasonably simple (using only elementary group-theoretic tools) example of infinite group with just 2 conjugacy classes ?,['group-theory']
89003,Best books on A Second Course in Linear Algebra [duplicate],"This question already has answers here : Closed 12 years ago . Possible Duplicate: Prerequisites/Books for Linear Algebra I've studied from David Poole's Linear Algebra: A Modern Introduction However, it's not very complete. I want to study subjects as Bilinear Forms, Transformations. And also, I want to study it more deeply. Do you know of any book on Linear Algebra that studies the subject deeply but also explains it clearly? I prefer the practical approach over the theoretic one. Thank you a lot.","['big-list', 'linear-algebra', 'reference-request']"
89030,Expectation of the maximum of gaussian random variables,"Is there an exact or good approximate expression for the expectation, variance or other moments of the maximum of $n$ independent, identically distributed gaussian random variables where $n$ is large? If $F$ is the cumulative distribution function for a standard gaussian and $f$ is the probability density function, then the CDF for the maximum is (from the study of order statistics) given by $$F_{\rm max}(x) = F(x)^n$$ and the PDF is $$f_{\rm max}(x) = n F(x)^{n-1} f(x)$$ so it's certainly possible to write down integrals which evaluate to the expectation and other moments, but it's not pretty. My intuition tells me that the expectation of the maximum would be proportional to $\log n$, although I don't see how to go about proving this.","['normal-distribution', 'probability', 'order-statistics']"
89040,No subgroup of $S_5$ with order 40,How can one prove that there are no subgroups of $S_5$ with order 40? Thank you!,"['finite-groups', 'group-theory', 'abstract-algebra']"
89060,Bijections on ordered pairs formed from other bijections?,"How could you go about proving the following: Let $f_1$ and $f_2$ denote bijections where $f_1:A_1 \rightarrow B_2$ and $f_2:A_2 \rightarrow B_2$. If $g:A_1 \times A_2 \rightarrow B_1 \times B_2$ where $g(x, y) = (f_1(x), f_2(y))$, then $g$ is a bijection. This is a sample exam problem. I'm not really sure how to go about proving this, as it seems intuitively correct to me, so I'm not really sure where to start. I'm not so much interested in a proof as some sort of starting point or hint that could tell me what I need to prove or what I might be able to use. EDIT : Just to be clear, we're using what I presume is the standard definition for a bijection, a function that is both an injection (one-to-one) and a surjection (onto).","['elementary-set-theory', 'functions']"
89061,Are there any compact embedded 2-dimensional surfaces in $\mathbb R^3$ that are also flat?,"Let $\overline{g}$ be the flat metric on $\mathbb{R}^3$. I would like to know if there is any compact embedded 2-dimensional surface $M$ in $\mathbb{R}^3$ (without boundary) such that $\iota^*\overline{g}$ is flat, where $\iota: M \hookrightarrow \mathbb{R}^3$ is the inclusion. It appears that the answer is ""no"", but I am having a hard time coming up a with a rigorous proof, which does not use any results about the existence or non-existence of isometric embeddings of abstract surfaces into $\mathbb{R}^3$. Any suggestions would be appreciated.",['differential-geometry']
89062,Powers of a densely-defined bounded linear operator,"This is a question I was thinking of some time ago. Suppose $\mathbf{X} \equiv (X, \|\cdot\|_X)$ is a (real or complex) Banach space, $U$ is a dense subspace of $\mathbf{X}$, and $\phi$ is a bounded linear operator $(U,\|\cdot\|_X) \to \mathbf{X}$. We know from the B.L.T. theorem that $\phi$ can be uniquely extended to a bounded linear operator $\Phi: \mathbf{X} \to \mathbf{X}$. Question. Provided $x \in X$, does there exist a sequence, $\{x_n\}_{n=1}^\infty$, in $U$ such that $\lim_n x_n = x$ in $\mathbf{X}$ and, for each $n \in \mathbb{N}^+$, $\{\Phi^k(x_n)\}_{k=1}^n \subseteq \phi(U)$?","['operator-theory', 'functional-analysis']"
89067,Prove $x = \sqrt[100]{\sqrt{3} + \sqrt{2}} + \sqrt[100]{\sqrt{3} - \sqrt{2}}$ is irrational,"Prove $x = \sqrt[100]{\sqrt{3} + \sqrt{2}} + \sqrt[100]{\sqrt{3} - \sqrt{2}}$ is irrational. I can prove that $x$ is irrational by showing that it's a root of a polynomial with integer coefficients and use rational root theorem to deduce it must be either irrational or an integer and then show it's not an integer, therefore, it must be irrational. I was wondering what are the other methods to prove $x$ is irrational. I'd be very interested in seeing alternative proofs.","['irrational-numbers', 'number-theory']"
