question_id,title,body,tags
2376267,Region of Convergence for Laurent Expansion,Find the Laurent expansion of $\frac{z}{(z+1)(z+2)}$ about the singularity $z=-2$. Specify the region of convergence and the nature of singularity at $z = -2$. The Laurent expansion I get is $1+(z+2)+(z+2)^2+ \ldots + \frac{2}{z+2}$ The singularity is a simple pole. But how to find the Region of Convergence.,"['laurent-series', 'complex-analysis', 'convergence-divergence']"
2376305,"$\int_{-\infty}^{\infty}\frac{e^{\mathrm{i}tx}} {(\,t - \mathrm{i})^{n/2}}dt$, Fourier transform via contour integral with branch cut","I am trying to evaluate the following Fourier transform 
$$F(x,n) =
\int_{-\infty}^{\infty}\frac{\mathrm{e}^{\mathrm{i}tx}}
{(\,t - \mathrm{i}\,)^{n/2}}\,\mathrm{d}t\,,\quad
\forall\ x \in \mathbb{R}^{+}\,,\ n\in \mathbb{N}.
$$ For even $n$, we can use the contour integral on the complex plane $t$ where the contour consists of the interval $\left[-a, a\right]$ on the real axis and a hemisphere on the upper half plane centered at the origin with a radius of $a$ for $a > 0$. We obtain the result using Cauchy's differentiation formula. For odd natural number $n$, there is a branch cut for
$\displaystyle(t - \mathrm{i})^{\frac n 2}$. Now if we make a slit from
$t = \mathrm{i}$ and integrate
$\displaystyle\frac{e^{\mathrm{i}tx}}{\left(\,t -\mathrm{i}\,\right)^{\frac n 2}}$ starting from $t = \mathrm{i}$ we will have a divergent integral for $n \geq 3$. What could be done ?","['complex-analysis', 'definite-integrals', 'contour-integration', 'fourier-transform', 'branch-cuts']"
2376306,Does anyone know what the series $\frac{n^x}{n!}$ converges to? [duplicate],"This question already has answers here : Infinite Series $\sum\limits_{k=1}^{\infty}\frac{k^n}{k!}$ (2 answers) Closed 6 years ago . Most people in math are familiar with the conventional taylor series,
$$\sum_{n=0}^{\infty} \frac{x^{n}}{n!}$$ which converges to $$e^x$$ I came across an uncommon series from working with very unusual exponents, and even though it looks simple, I'm not sure how to approach it or much less its result. This one has k in the base in the numerator instead. I am fairly certain it converges, but to what I am not sure, it's not really the same as dealing with x^n. For this specific problem, I don't need to know the method, I am wondering only what it converges to. $$\sum_{n=0}^{\infty} \frac{n^{x}}{n!} = ?$$ Does anyone know what this converges to?","['sequences-and-series', 'calculus']"
2376341,"Find the number of rearrangements of the string 12345 in which none of the sequences 12, 23, 34, and 45 occur.","My attempt: Let $A_{1}$ denote where 12 occurs, $A_{2}$ denote where 23 occurs, $A_{3}$ denote where 34 occurs, $A_{4}$ denote where 45 occurs. |$A_{1} \cup A_{2} \cup A_{3} \cup A_{4}$|= |$A_{1}$|+|$A_{2}$|+|$A_{3}$|+|$A_{4}$|-(|$A_{1}A_{2}$|+|$A_{1}A_{3}$|+|$A_{1}A_{4}$|+|$A_{2}A_{3}$|+|$A_{2}A_{4}$|+|$A_{3}A_{4}$|)+|$A_{1}A_{2}A_{3}$|+|$A_{1}A_{2}A_{4}$|+|$A_{1}A_{3}A_{4}$|+|$A_{2}A_{3}A_{4}$|-|$A_{1}A_{2}A_{3}A_{4}$| I don't know if I'm doing this write or not. I tried to glue the 12, 23, 34, and 45 together but I don't think this is correct. The total ways this can be done with no restrictions is |U|=5! The actual answer is: 5!-[96-3+8-1]=53. If someone can tell me how to get this answer that would be excellent.","['combinations', 'combinatorics', 'inclusion-exclusion', 'discrete-mathematics']"
2376349,Proof that $i\cot(t/2) = (1 + \alpha) / (1 - \alpha)$ where $\alpha = \cos t + i\sin t$,"I am reviewing complex analysis revision problems and I am stuck on this trigonometric solution to the identity. Can anyone give me a hint as to what steps I should follow. I have to show the following.
Suppose $\alpha = \cos(t) + isin(t)$ where $0<t<2\pi$. Show that $ \frac{1+\alpha}{1-\alpha} = i \cot(\frac{t}{2})$. I have tried expanding cot into exponential form and then playing with the algebra but I have had no luck. I have tried similar technique on the other side. Any suggestions?","['complex-analysis', 'trigonometry', 'complex-numbers']"
2376370,Question about total differentials,"Why is it true that if you move from point $(u,v,w)$ to point $(u+du,v+dv,w+dw)$, a scalar function $\phi(u,v,w)$ changes by an amount $$d\phi=\frac{\partial \phi}{\partial u}du+\frac{\partial \phi}{\partial v}dv+\frac{\partial \phi}{\partial w}dw$$","['multivariable-calculus', 'partial-derivative', 'differential']"
2376381,Wrong concept in Fubini's Theorem (Stronger form),"Example: Find the volume of the prism whose base is the triangle in the $xy-plane$ bounded by the $x- axis$ and the lines $y=x$ and $x=1$ and whose top lies in the plane $z = f(x,y) = 3-x-y$ The above is an example from my text book. The answer, of course, is to use the Fubini's Theorem (Stronger form). i.e. Set either $y-limits$ or $x-limits$ of integration as a function x or y respectively. The remaining one will be a constant. and I understand it. Now, given the question, I can literally picture the base region in my head with specific limits of integration. i.e. both (x-limits and y-limits) are from 0 to But, WHY can't I compute (As the above gives 2 instead of 1) Please help me to clear my concept T.T","['integration', 'measure-theory', 'calculus']"
2376385,Has anyone come across a geometric interpretation for fractional exponents of pi?,"Once in a while I'll see pi, not squared, but to a fractional power. For instance when dealing with a bell curve with its integral to infinity, you obtain $$ \frac{\sqrt{\pi}}{2}$$
When you evaluate certain elliptic integrals or fractional inputs of the gamma function like $\Gamma(\frac{2}{3})$, you might obtain a $$\pi^{\frac{2}{3}}$$ Getry: in Sterling's formula which is $$n! \sim \sqrt{2 \pi n} (\frac{n}{e})^n$$ you can see the square root of pi. But, where do fractional powers of pi occur geometrically? In what physical circumstances do these uncommon numbers like this typically occur? If I drew a circle...where is that theorem containing a fractional power of pi that relates its circumference to its diameter? Or maybe it's not a circle, maybe it pertains to a lemiscate, or maybe it pertains to  ellipse, but there has to be some something that can make sense of these numbers, they aren't random.","['pi', 'geometry']"
2376395,Difficult Homogeneous Differential Equation,Solve the differential equation: $$\frac{dy}{dx}=\frac{\sqrt{x^2+3xy+4y^2}}{x+2y}$$ I tried to solve it by putting $t=x+2y$ but that lead to a very complicated integral. The hint given is that equation is reducible to homogeneous form.,"['integration', 'ordinary-differential-equations']"
2376399,On the intersection of two open affine subscheme,"I'm doing exercises 3.1—3.4 in the book of algebraic geometry by Hartshorne. Meet the following question, and is  the following assertion true? 
Suppose $U_{1}=Spec A$ and $U_{2}=Spec B$ are two open affine subset of a scheme X, then
$Spec A \bigcap Spec B = \bigcup _{f \in A \bigcap B} D(f)$.",['algebraic-geometry']
2376401,What are good resources to learn about convergence spaces?,"What are good resources (books, lecture notes, introductory papers, ...) to learn about convergence spaces ? I read in an answer to a recent question the following: There's still a subtle issue. If you try to axiomatize topological spaces via filter convergence, you wind up with a significantly more general notion called a convergence space . Convergence spaces are really nice, and personally I wish people would start treating them as the basic objects of interest in general topology, and treat topological spaces as a mere special case. Unfortunately, I haven't been able to find an elementary introduction to such things that I can link you to, so you'll have to learn things the classical way until you're ready to go off on your own. This sounds quite intriguing, so I thought it might be reasonable to ask where to look if I decide to learn a bit more about convergence spaces.","['reference-request', 'book-recommendation', 'category-theory', 'general-topology', 'online-resources']"
2376408,"$\forall H, \exists G\unrhd H$ with automorphisms of $H$ obtained by restricting inner automorphisms of $G$ to $H$.","Show that if $H$ is any group then there is a group $G$ that contains $H$ as a normal subgroup with the property that for every automorphism $\sigma$ of $H$ there is an element $g\in G$ such that conjugation by $g$ when restricted to $H$ is the given automorphism $\sigma$, i.e., every automorphism of $H$ is obtained as an inner automorphism of $G$ restricted to $H$. For $G=H\rtimes_\varphi K$, view $G$ as the set of ordered pairs $\{(h,k)\}$ s.t. $(h_1,k_1)(h_2,k_2)=(h_1(\varphi(k_1)(h_2)),k_1k_2)$ My guess is that $G=\operatorname{Hol}(H)=H\rtimes \operatorname{Aut}(H)$. For example, let $H=\Bbb Z_2\times\Bbb Z_2=\{1,x,y,xy\}$, then $\operatorname{Aut}(H)\cong S_3$, where each symmetry permutes the $3$ non-identity elements of $H$. $G=\operatorname{Hol}(H)=(\Bbb Z_2\times\Bbb Z_2)\rtimes_\varphi S_3$:$$\varphi:S_3\rightarrow\operatorname{Aut}(\Bbb Z_2\times\Bbb Z_2)\cong S_3$$$$\varphi(12)=\sigma_{(12)}:x\mapsto y,y\mapsto x,xy\mapsto xy$$$$\varphi(123)=\sigma_{(123)}:x\mapsto y,y\mapsto xy,xy\mapsto x$$$$\vdots$$ We kind of embed both $H$ and $\operatorname{Aut}(H)$ in a larger group, in this case $G=\operatorname{Hol}(H)\cong S_4$, and $H\unlhd G$. Every automorphism $\sigma$ of $H=\Bbb Z_2\times\Bbb Z_2$ appears in the codomain of $\varphi$ and it corresponds to exactly one element in $S_3$ ($\varphi$ is a bijection). If we see $S_3$ as a subgroup of $S_4$, then $\sigma$ corresponds to $g=(1,\sigma)\in G$ s.t. conjugation by $g=(1,\sigma)$ when restricted to $H$ is $\sigma$, because this is exactly how we define a semidirect product: $K$ acts on $H$ by conjugation. e.g. $\sigma_{(12)}:x\mapsto y,y\mapsto x,xy\mapsto xy$ corresponds to the ordered pair $g=(1,(12))\in G$ s.t. conjugation by $g$ when restricted to $H$ (used during construction of the semidirect product) is $\sigma_{(12)}$. Is my guess correct? I know the example looks clumsy but I want to know if there is any problem with the above. Thanks!","['abstract-algebra', 'semidirect-product', 'group-theory']"
2376435,A special strictly positive Borel measure,"Given a metric space $X$, let $B(x,r)$ the open ball with center $x \in X$ and radius $r>0$. Fix also a Borel measure $\mu: \mathscr{B}(X) \to \mathbf{R}$ which is strictly positive, i.e.,
$$
\forall x \in X, \forall r>0,\,\,\mu(B(x,r))>0.
$$ Is there a name for the measures $\mu$ such that
  $$
\forall x\in X,\,\,\lim_{r\to 0}\mu(B(x,r))=0?
$$ I would say that it coincides with atomless measures, since
$$
\lim_{r\to 0}\mu(B(x,r))=\mu(\{x\});
$$
is it correct?","['reference-request', 'measure-theory']"
2376443,Proof of connection between improper Riemann Integral and Lebesgue integral,"""An improper Riemann integral is Lebesgue integrable if it is absolutely convergent. "" I've seen this statement quite often, but always without proof. I'd think if we have something like:
$$ \int_{0}^\infty |f(x)|dx<\infty$$ there has to be a point $c\in\mathbb{R}$, where the integral doesn't ""grow"" anymore i.e. $$ \int_{0}^\infty |f(x)|dx \leq \int_{0}^c |f(x)|dx<\infty$$ otherwise the integral could not be convergent ( similar as to how an infinite sequence has to be a zero sequence in order for the infinite sum to be convergent ). But I'm having trouble formalising this or in general finding a proper proof. What is a simple way to prove this theorem?","['improper-integrals', 'real-analysis', 'integration', 'lebesgue-integral']"
2376449,Differential equations: $(1+y)^2 = (1+x)^2 \frac{dy}{dx}$,"Solve the differential equation:
  $$(1+y)^2 = (1+x)^2 \frac{dy}{dx}$$ I don't know how to go about this? But let me try:
$$(1+y)^2 dx=(1+y)^2 dy$$
$$\frac{dx}{(1+x)^2} =\frac{dy}{(1+y)^2}$$
Integrating both sides gives:
$$\arctan x=\int \frac{dy}{(1+y)^2}$$",['ordinary-differential-equations']
2376456,"Prove there are no sets $A,B,C$ such that $ A ¥cap B ¥neq ¥emptyset$, $¥ A ¥cap C = ¥emptyset$, $¥ (A ¥cap B) - C = ¥emptyset$","Question: Prove there are no sets $A,B,C$ such that $ A ¥cap B ¥neq  ¥emptyset$, $¥  A ¥cap C = ¥emptyset$, $¥  (A ¥cap B) - C = ¥emptyset$ I am not sure how to prove this. I think we need to use proof by contradiction but I am not sure how to show a contradiction.","['proof-writing', 'elementary-set-theory']"
2376461,"Conversion of BVP $y'' + y' + y = 0 ,y(0) = 0, y(1) = 1$ to Integral equation.","I was trying to convert this Boundary Value problem to an integral equation(Fredholm Integral Equation) $y'' + y' + y = 0 ,y(0) = 0, y(1) = 1       \rightarrow (*)$ I tried but got stuck,here 
Integrating the above ODE we get $\int_{0}^{x}y''(x) dx + \int_{0}^{x}y'(x) dx + \int_{0}^{x}y dx = c$ $y'(x) - y'(0)+y(x)- y(0) + \int_{0}^{x}y dx = c$ at $x = 1$ $y'(1) - y'(0) + y(1) - y(0) + \int_{0}^{1}y dx = c$ So $c = y'(1) - y'(0) + 1 + \int_{0}^{1}y dx$ Next substituting this value of $c$ in $(*)$,we get $y(x) = -\int_{0}^{x}y dx - \int_{0}^{x}(x-t)y(t)dt + xy'(1) + x + x\int_{0}^{1}y dx$ I think I am making mistake somewhere as the form is $y = \int_{0}^{1} K(x,t)y(t)dt$, any help!","['boundary-value-problem', 'ordinary-differential-equations', 'integral-equations']"
2376479,"bisector theorem , cosine rule or other method?","A fixed point $A(a,0)$, where $a>0$ and a straight line $l$ is given $x = -1$, $B$ is a moving point on the second quadrant and lies on the straight line $l$, the angle bisector of $\angle BOA$ intersects $AB$ at point $C$. (a) Find the locus of point $C$ and state the range values of $x$ and $y$. (b) Discuss the relationship between the values of $a$ and the type of the curve of the equation obtained in (a). I have tried to use cosine rule to and bisector theorem to obtained the locus. but the equation seem too complicated. Any other good method please share with me !!","['triangles', 'geometry']"
2376517,left and right eigenvalues,"On the Stochastic Matrices article in Wikipedia there's a claim that left and right eigenvalues of a square matrix are the same. I tried looking this up, but can't find an explanation, only for hermitian matrices with real eigenvalues. Is it correct?","['matrices', 'eigenvalues-eigenvectors']"
2376519,Probability of getting a defined value by freely assembling the top 3 results of a D4+D6+D8+D10 roll,"I'm trying to compute the probability of getting a given value with the following rules : Roll one 4 sided dice + one 6 sided dice + one 8 sided dice + one 10 sided dice. Pick the 3 largest results. Choose a value by selecting one dice, assembling 2 dice or even summing all 3 dice. Example: I roll 2 on the 4 sided dice I roll 1 on the 6 sided dice I roll 6 on the 8 sided dice I roll 5 on the 10 sided dice I pick the 3 largest results : 2,6,5 Then, I can choose any of the following values: 2, 6, 5, 2+6=8, 2+5=7, 6+5=11, 2+6+5=13 What is the probability of getting a 2 or a 15 or even a 24 with this rules? In fact, I am searching for a way to generalize this problem so that I can change the number of dice or the number of sides of each dice or even the number of top dice to keep. I created a computer program to obtain this probabilities using brute force, but I would like a more elegant and faster solution.","['combinatorics', 'probability', 'dice']"
2376520,Is this neither a tautology or contradiction?,"I'm writing to verify my conclusion the following is neither a tautology nor contradiction: This can be rearranged into the form: $$(q \land(p\lor r)) \lor\lnot q$$ All it takes from here is to consider the case where both P and R are false, as well as Q being True; then the overall expression is false. All other cases this expression is true however. Am I correct on this?","['logic', 'proof-verification', 'discrete-mathematics']"
2376544,An example of symmetric associative increasing function which cannot be represented as addition,"Let $X$ be some connected subset of $\mathbb{R}$.
Let $f: X^2\to X$ have following properties: $\forall x, y$: $f(x, y)=f(y,x)$ (Symmetry) $\forall x, y, z$: $f(x, y)>f(x,z)\iff y>z$ (Strictly increasing on any argument) $\forall x, y, z$: $f(x, f(y, z))=f(f(x, y), z)$ (Associativity) We call $f$ addition-like, if there exists an injection $\phi:X\to\mathbb{R}$
such that $\forall x, y$: $\phi(f(x,y))=\phi(x)+\phi(y)$. Can $f$ be not addition-like? Some examples: $f(x,y)=xy, x>0,y>0$, then $\phi(x)=\ln(x)$ $f(x,y)=xy+x+y, x>0,y>0$, then $\phi(x)=\ln(x+1)$ I do not know the answer to the question because I have trouble finding such $f$ at all except explitictly using addition/multiplication with some mapping, which obviously yields addition-like function by definition and multiplication being addition-like.",['abstract-algebra']
2376548,Questions about stability in the sense of Lyapunov,"I have two questions that are related to stability in the sense of Lyapunov. Is a system with multiple poles on the imaginary axis (e.g. double pole at $z=0$ or double pole at $z=i$) unstable in the sense of Lyapunov? From the example of $y''=0$ I would think that this linear system is unstable. When using the Linearization method from Lyapunov for investigating the stability of a nonlinear system, I know that if the linear system is asymptotically stable in the equilibrium point, then the equilibrium point of the nonlinear system is also asymptotically stable. If the linear system is unstable at the equilibrium point, then the equilibrium point of the nonlinear system is also unstable. It is said that for the case in which the linear system is marginally stable at the equilibrium point, then the linearization method is indecisive. Does the case from question 1 belong to the indecisive case, or would it imply that the nonlinear system is unstable at the equilibrium point?","['stability-in-odes', 'ordinary-differential-equations', 'nonlinear-system', 'stability-theory']"
2376560,"From a standard deck of cards, the kings and queens are removed and arranged in a random order...","Find the probability that there is no king and queen of the same suit next to each other. My attempt: Let $A_{1}$ denote where $K\heartsuit\,Q\heartsuit$ occurs, $A_{2}$ denote where $K\clubsuit\,Q\clubsuit$ occurs, $A_{3}$ denote where $K\diamondsuit\,Q\diamondsuit$ occurs, $A_{4}$ denote where $K\spadesuit\,Q\spadesuit$ occurs, Then $\lvert A_{1}\cup A_{2}\cup A_{3}\cup A_{4}\rvert = 4(7!)-6(6!)+4(5!)-4!.$ Let $U$ be the set of all the Kings and Queens in the standard deck. So, $|U|=8!$. Then $$|U|-|A_{1}\cup A_{2}\cup A_{3}\cup A_{4}|=8!-[4(7!)-6(6!)+4(5!)-4!]=24024$$
Therefore the probability is $$\frac{24024}{\binom{52}{8}}$$ I'm not sure if I am doing this problem correctly. Inclusion/exclusion always threw me for a loop. Please help me understand how to do this problem.","['inclusion-exclusion', 'combinatorics', 'probability', 'discrete-mathematics']"
2376562,"Find the number of five-digit strings, using digits from $\{0, 1, . . . , 9\}$ in which there are no three consecutive equal digits.","(Hint: Let $A$ be the set of strings in which the first three digits are all equal.) Originally I thought of creating sets with three consecutive equal digits ($A_{0}:\{0,0,0\},\ A_{1}:\{1,1,1\},...,\ A_{9}:\{9,9,9\}$) and using inclusion/exclusion to solve. However, I soon realized that I was completely confused. I have no idea how I should solve this problem, and the hint isn't really clicking with me. Please help me. Thank you!","['combinations', 'combinatorics', 'inclusion-exclusion', 'discrete-mathematics']"
2376602,a problem about convergence in $L^{P}$ space,"I need a small certain hint for solving this problem please. Problem: 
Let 
$(f_{n})_{n} $
be a bounded sequence in 
$ L^{3}(\mathbb{R}), $
such that 
$ f_{n}\to f $
in
$ L^{\frac{3}{2}}(\mathbb{R}). $
Prove that 
$ f_{n}\to f $
in
$ L^{2}(\mathbb{R}). $","['functional-analysis', 'real-analysis', 'lp-spaces', 'analysis']"
2376628,A sheaf is flasque if all restriction maps are surjective,"A sheaf $\mathcal{F}$ on $X$ is called a flasque sheaf if every restriction map $\mathcal{F}(U)\rightarrow \mathcal{F}(V)$ is a surjective map. Question is as follows : If  $0\rightarrow \mathcal{F}'\xrightarrow{\psi} \mathcal{F}\xrightarrow{\varphi} \mathcal{F}''\rightarrow 0$ is an exact sequence of sheaves, and $\mathcal{F}'$ is a flasque sheaf, then, the sequence of abelian groups $0\rightarrow \mathcal{F}'(U)\xrightarrow{\psi(U)}\mathcal{F}(U)\xrightarrow{\varphi(U)} \mathcal{F}''(U)\rightarrow 0$ is exact. Fix an open subset $U\subseteq X$. It suffices to prove that $\mathcal{F}(U)\xrightarrow{\varphi(U)} \mathcal{F}''(U)$ is surjective. Given $s\in \mathcal{F}''(U)$ there exists an open cover $\{V_i\}$ and $t_i\in \mathcal{F}(V_i)$ such that $\varphi(V_i)(t_i)=s|_{V_i}$ in the following commutative diagram I am trying to prove that these sections $t_i\in \mathcal{F}(V_i)$ glue together to give a section $t\in \mathcal{F}(U)$ i.e., $t|_{V_i}=t_i$. Then,
$$\varphi(U)(t)|_{V_i}=\varphi(V_i)(t|_{V_i})=\varphi(V_i)(t_i)=s|_{V_i}.$$
By identity axiom, we then conclude that $\varphi(U)(t)=s$. I still have not used that $\mathcal{F}'$ is a flasque sheaf. I am confused what open sets should I consider whose restriction map is a surjective map. As we are talking about restrcition $t_i|_{V_i\cap V_j}$ of an element in $\mathcal{F}(V_i)$ I think surjectivity of restriction maps of these open sets 
$V_i,V_i\cap V_j, V_j$ gives some result. We have To use that restriction maps corresponding to $\mathcal{F}'$ are surjective, we need to get an element in $\mathcal{F}'(V_i\cap V_j)$. Suppose $a\in \mathcal{F}(V_i\cap V_j)$ is such that $\varphi(V_i\cap V_j)(a)=0$ then $a=\psi(b)$ for some $b\in \mathcal{F}'(V_i\cap V_j)$. We have 
$$\begin{align}\varphi(t_i|_{V_i\cap V_j}-t_j|_{V_i\cap V_j})
&=\varphi(t_i|_{V_i\cap V_j})-\varphi(t_j|_{V_i\cap V_j})\\
&=\varphi(V_i)(t_i)|_{V_i\cap V_j}-\varphi(V_j)(t_j)|_{V_i\cap V_j}\\
&=(s|_{V_i})|_{V_i\cap V_j}-(s|_{V_j})|_{V_i\cap V_j}\\
&=s|_{V_i\cap V_j}-s|_{V_i\cap V_j}=0\end{align}$$
So, $$t_i|_{V_i\cap V_j}-t_j|_{V_i\cap V_j}=\psi(a_{ij})$$ for some $a_{ij}\in \mathcal{F}'(V_i\cap V_j)$.
As restriction maps are surjective, there exists $b_i\in \mathcal{F}'(V_i)$
such that $b_i|_{V_i\cap V_j}=a_{ij}$ for all $i,j$. Then $\psi (V_i)(b_i)\in \mathcal{F}(V_i)$. I do not think this way would lead me anywhere near the final step. Any suggestions regarding this are welcome.","['sheaf-theory', 'algebraic-geometry']"
2376631,Why is cardinality of reals not $\aleph_0 \cdot 2^{\aleph_0}$?,"The real numbers in the interval $[0,1]$ can be put in one-to-one correspondence with the (uncountable) power set of the natural numbers, $2^{\mathbb{N}}$, and from this we know that the real numbers are uncountable since every subset of a countable set is also countable. I have seen this proof also used to show that the cardinality of the real numbers is that of $2^{\mathbb{N}}$, however, what troubles me is that this leaves out the integer component of real numbers, which have cardinality $\aleph_0$. It would seem to me that if we take into account all real numbers we must take into account the cardinality of those in the interval $[0,1]$ and the integers, which would be the product of both cardinalities, $\aleph_0 \cdot 2^{\aleph_0}$. What am I misunderstanding here?","['real-numbers', 'cardinals', 'elementary-set-theory']"
2376665,Wilson's theorem Prime Generator,"There is a famous theorem in number theory called Wilson's Theorem. Statement: $n$ satisfies, $(n-1)! + 1 = 0\pmod n$ if and only if $n$ is prime. Another way of looking at the statement is that,
$\dfrac{(n-1)! + 1}{n}$ is an integer only if $n$ is prime. I have noticed a pattern in these integers. They always come out to be prime.
I have made a code, to test primes upto a large number, and all of the integers that have come from the fraction, is found to be prime.
If the aforementioned statement always holds true for all primes, then it would 
behave as a prime generator. I haven't found any useful information currently 
existing on the internet. Hence, I am looking for a mathematical proof for the following: Let $f:\mathbb{N}\to\mathbb{N}$ be defined as,
  $$f(n) = \frac{(n-1)! + 1}{n}$$for all $n\in\mathbb{N}$. Prove that: $$f(n)\in \mathbb{P};\ \ \forall n \in\mathbb{P}$$
  Where $\mathbb{P}$ is the set of Primes. Now, I do know that for $n = {2,3},\  f(n) = 1$.
This should be ignored as sometimes, $1$ trivially shows up while working with primes.","['number-theory', 'proof-writing', 'prime-numbers']"
2376681,Existence of Lebesgue measurable set with the same outer measure of the given set,Let $A\subset \mathbb R^n$ be an arbitrary subset(not necessarily Lebesgue measurable). Denote the Lebesgue outer measure of $A$ by $m^{\ast}(A)$. Show that there exists a Lebesgue measurable set $B\subset \mathbb R^n$ such that $A\subset B$ and $m(B)=m^{\ast}(A)$. How should I deal with this problem? What I know is just the definition of outer measure $\mu^{\ast}(A)= \mathrm{inf}\{\sum_{i=1}^\infty l(U_i): A\subset\cup_i U_i\}$ where $U_i$'s are open sets in $\mathbb R^n$. I have no idea how to proceed. What should I do? Thank you for your help!,"['outer-measure', 'lebesgue-measure', 'measure-theory']"
2376694,Group Presentation of the Direct Product.,"This is Exercise 1.2.5 and Exercise 1.2.6 of ""Combinatorial Group Theory: Presentations of Groups in Terms of Generators and Relations,"" by Magnus et al. The Details: Definition 1: Let $$\langle a, b ,c, \dots \mid P, Q, R, \dots \rangle$$ be a group presentation, where $P, Q, R, \dots$ are relators, not relations ( i.e. , words, not equations). We say the words $W_1$ and $W_2$ in $a, b, c, \dots$ are equivalent , denoted $W_1\sim W_2$, if the following operations applied a finite number of times, change $W_1$ into $W_2$: (i) Insertion of one of the words $P, P^{-1}, Q, Q^{-1}, R, R^{-1}, \dots$ or one of the trivial relators between any two consecutive symbols of $W_1$, or before $W_1$, or after $W_1$. (ii) Deletion of one of the words $P, P^{-1}, Q, Q^{-1}, R, R^{-1}, \dots$ or one of the trivial relators, if it forms a block of consecutive symbols in $W_1$. The Question(s): Exercise 1.2.5 Suppose $G=\langle a, b\mid P(a, b), Q(a, b)\rangle$ and $H=\langle x, y\mid S(x, y), T(x, y)\rangle$. Then show that the direct product $G\times H$ has the presentation
  $$\langle a, b, x, y\mid P(a, b), Q(a, b), S(x, y), T(x, y), ax=xa, ay=ya, bx=xb, by=yb\rangle.$$ [$\color{red}{\text{Hint}}$: If $G$ is presented under the mapping $\theta: a\mapsto g, b\mapsto g'$, and $H$ is presented under the mapping $\phi: x\mapsto h, y\mapsto h'$, then show that the combined mapping $\theta\times \phi:a\mapsto (g, 1), b\mapsto (g', 1), x\mapsto (1, h), b\mapsto (1, h')$ determines a homomorphism of the alleged presentation for $G\times H$ onto $G\times H$. Next show that each element of the alleged presentation can be defined by a word $U(a, b)V(x, y)$. Show that if $U(a, b)V(x, y)\sim U'(a, b)V'(x, y)$, then $U(g, g')=U'(g, g')$ and $V(h, h')=V'(h, h')$ by mapping the alleged presentation for $G\times H$ into $G$ under $a\mapsto g, b\mapsto g', x\mapsto 1, y\mapsto 1$, and into $H$ under $a\mapsto 1, b\mapsto 1, x\mapsto h, y\mapsto h'$.] Exercise 1.2.6: Generalise Exercise 1.2.5 to arbitrary presentations $G$ and $H$. Generalise Exercise 1.2.5 to an arbitrary number of groups $G, H, \dots$. My Attempt: The hint for Exercise 1.2.5 is very detailed. The map $\theta\times\phi$ clearly defines a homomorphism from the presentation to $G\times H$ because on the generators, for example,
$$\begin{align}(\theta\times\phi)(ab)&=(gg', 1) \\
&=(g\times g', 1\times 1) \\
&=(g, 1)\times (g', 1) \\
&=(\theta\times\phi)(a)(\theta\times\phi)(b).
\end{align}$$ That the generators of $G$ commute with the generators of $H$ in the alleged presentation for $G\times H$ means we can clearly move blocks in $\{a, b\}$ in a word past and to the left of $x, y$, resulting in a word of the form $U(a, b)V(x, y)$. I have no idea how to show that if $U(a, b)V(x, y)\sim U'(a, b)V'(x, y)$, then $U(g, g')=U'(g, g')$ and $V(h, h')=V'(h, h')$. As for Exercise 1.2.6 , I have found that, for $G=\langle \mathcal G_G\mid \mathcal R_G\rangle$ and $H=\langle \mathcal G_H\mid \mathcal R_H\rangle$, $G\times H$ has the presentation $$\langle \mathcal G_G\cup \mathcal G_H\mid \mathcal R_G\cup\mathcal R_H\cup\{xy=yx : x\in \mathcal G_G, y\in \mathcal G_H\}\rangle,$$ though I don't know how to prove it. I have no idea how to generalise it to an arbitrary number of groups. Please help :)","['abstract-algebra', 'combinatorial-group-theory', 'group-presentation', 'direct-product', 'group-theory']"
2376695,Convergence or divergence of $\sum\limits_n(-1)^{\pi(n)}\frac1n$ where $\pi(n)$ is the number of primes less than or equal to $n$,Consider $$\sum_{n=1}^{\infty}\frac{(-1)^{\pi(n)}}{n}$$ where $\pi(n)$ is the number of primes less than or equal to $n$. Does this sum converge or does it diverge? Are there any results related to this?,"['number-theory', 'prime-numbers', 'sequences-and-series']"
2376795,Example of divisor $D$ such that $\deg D >0$ and $\ell(D)=0$,"It is easy to see that if a divisor $D$ on a projective curve $C$ over a field $K$ has negative degree, then $\ell(D) = \dim_K \{f \in K(C) \mid div(f)+D\ge 0\}$ is zero. However, I suppose that the converse is not true. Can someone give me the simplest example of a divisor $D$ on some curve $C$ satisfying $\deg(D)>0$ but $\ell(D)=0$?",['algebraic-geometry']
2376816,The Product $AB$ can be Written as a Sum of Rank $1$,"Let $A$ be an $m \times n$ matrix and $B$ be a $n \times \ell$ matrix. Prove that $AB$  can be written as a sum of $n$ matrices of rank one. I am having trouble seeing how this is true. Here is the best solution I could come up with. Let $A_p \in M_{m \times n}$ have its $p$-th column equal to $A$' $p$-th column, with zeros elsewhere, and let  $B_q$ be matrix whose $j$-th column is $B$'s $j$-th column, with zeros elsewhere. Clearly then $A = \sum A_p$ and $B = \sum B_q$. Then $$AB = \sum_{p,q=1}^n A_p B_q$$ $$= \sum_{p=1}^n A_p B_p + \sum_{p \neq q}^n A_p B_q$$ I claim that $A_p B_q = 0$ if $p \neq q$. To see this, consider the $(i,j)$-th entry of $A_pB_q$: $$(A_pB_q)_{ij} = \sum_{k=1}^n (A_p)_{ik}(B_q)_{kj}$$ $$= (A_p)_{ip}(B_q)_{pj} + (A_p)_{iq}(B_q)_{qj} + \sum_{k \neq p,q}^n (A_p)_{ik}(B_q)_{kj}$$ Now, if neither $k=p$ nor $k=q$, then $(A_p)_{ik}=(B_q)_{kj}=0$, which means the sum on the LHS vanishes. When $k=p$, $(B_q)_{pj}=0$ since $B_q$ has zeros across every row, except possibly the $q$-th row; and a similar conclusion is drawn when $k=q$. Thus $(A_pB_q)_{ij}=0$. As I was typing this up, I made a crucial mistake: I thought that the $p$-th column of  $A_pB_P$ was equal to $AB$ and had zeros elsewhere. I tried this on specific $3 \times 3$ $A$ and $B$ and found that every entry of $A_1B_1$ was nonzero; I did find that the $1$-st and $3$-rd column of my example were multiples of each other. So, it may be possible to fix this proof, but I cannot see it. In any case, these matrices $A_pB_p$ are clearly not necessarily rank $1$ matrices. What I find disconcerting is that both link1 and and link2 give roughly the same answer (cf problem 18 on page 75 and 170, respectively), except they conclude that matrices in the sum are of rank at most $1$, which is the conclusion I am coming to draw. So, is this an error in the book.","['matrices', 'matrix-rank', 'linear-algebra']"
2376835,How to interpret the curl and div geometrically? [duplicate],"This question already has answers here : Geometric intuition behind gradient, divergence and curl (3 answers) Closed 6 years ago . How to interpret the curl and div geometrically? My book said the vector derivative operator '$\nabla $' is considered as vector as follows : $$\left(\frac{\partial}{\partial x}, \frac{\partial}{\partial y}, \frac{\partial}{\partial z}\right)$$ Let $\mathbf F$ be  a vector field. First, 
I know the fact that the $\operatorname{curl}$ is the tendency of rotation and the pivot is $\operatorname{curl} \mathbf F$ However, why the curl is the tendency of rotation geometrically? Easily, when calculating the outer product between two vector, we can interpret the result.
The value is $\mathbf a\mathbf b\sin\theta$ and the direction is perpendicular to the two vectors. I want to know to draw $\nabla$ as vector. Second, the $\operatorname{div}$ is tendency of divergence or convergence. But which direction? If the result of $\operatorname{div} \mathbf F$ is plus, then the tendency is same direction to $\mathbf F$? (If minus, then opposite direction?)","['multivariable-calculus', 'multiple-integral', 'calculus', 'derivatives']"
2376855,Poisson process with stochastic intensity correlated with a Brownian Motion,"I am currently confused with the moment of non-homogeneous compound Poisson process and a Brownian Motion. I know that generally Poisson Process and Brownian Motion are independent if they are adapted to the same filtration. But what if the intensity of the Poisson Process and the Brownian Motion are correlated? For example, we have a CIR process $dX(t)=\kappa_1\Big(\theta_1-X(t)\Big)dt+\sigma_1\sqrt{X(t)}dW_1(t)$, and a non-homogeneous compound Poisson Process $J(t)=\int_0^t\int_{\mathbb{R}^+}Q\mu(dx,ds)$, with a stochastic intensity $\lambda$ satisfies $d\lambda(t)=\kappa_2\Big(\theta_2-\lambda(t)\Big)dt+\sigma_2\sqrt{\lambda(t)}dW_2(t)$ (another CIR process), and its jump size $Q$ has a normal distribution $N(\mu_Q, \sigma_Q^2)$, the correlation coefficient between $W_1(t)$ and $W_2(t)$ is $\rho$, but the jump size is independent of them. BTW, $\mu(dx,ds)$ is a Poisson random measure, $\tilde{\mu}(dx,ds)$ is a compensated Poisson measure. Question is, what exactly are the mixed moment of $X(t)$ and $J(t)$, i.e. $\mathbb{E}[X(t)J(t)]$, and $\mathbb{E}[X(t)\int_0^t\int_{\mathbb{R}^+}Q\tilde{\mu}(dx,ds)]$?","['stochastic-processes', 'statistics', 'probability']"
2376857,How to get the general form of the solution of exercise 5.4-2 of CLRS as showed in wikipedia?,"Exercise Suppose that we toss balls into b bins until some bin contains two balls. Each toss is independent, and each ball is equally likely to end up in any bin. What is the expected number of ball tosses? Answer It seems that this is quite a simple question, and every answers I have found through Google asks me to refer to the Birthday Paradox #Average number of people . Yet the section specifically deals with the same problem, which directly tells me the final answer(the expected number) is $$1 + \sum_{k=1}^{b}\frac{b!}{(b-k)!*b^k}$$ But the thing is that I don't understand where this form is from? Is there a more detailed explanation? My thought Assume $S_k$ means after $k_{th}$ tosses, there exists two balls in one same bin. As a result, $$P(S_k) = \frac{b!*(k-1)}{(b-k+1)! * b^k} (2 \le k \le b+1)$$ Thus, the expected number is $$\sum_{k=2}^{b+1}P(S_k) * k$$
which is $$\sum_{k=2}^{b+1}\frac{b!*(k-1)*k}{(b-k+1)! * b^k}\\=\sum_{k=1}^{b}\frac{b!*k*(k+1)}{(b-k)! * b^{k+1}}$$
Considering that $$\sum_{k=2}^{b+1}P(S_k)=\sum_{k=2}^{b+1}\frac{b!*(k-1)}{(b-k+1)! * b^k}=\sum_{k=1}^{b}\frac{b!*k}{(b-k)! * b^{k+1}}=1$$
I could simplify the former expect number as $$1+\sum_{k=1}^{b}\frac{b!*k^2}{(b-k)! * b^{k+1}}$$
But this form does not seem to me the same as what shows in wiki (or at least not as simplified), even though I have checked a few small numbers(2,3) showing that they are equal (!! I have just checked these two values, I am not sure for a bigger b. So please note that they are possibly not the same ). However, I fail to understand how to simplify my form further as in wiki, or it simply uses another way to approach that answer? Any ideas?","['balls-in-bins', 'statistics', 'probability']"
2376859,Why these 'elementary' facts do not solve the Inverse Galois Problem?,"Since every finite group $G$ is isomorphic to a subgroup of $S_{n}$ and according to the first answer on this question there is always (for all $n\geq 1$) a finite Galois extension $K/\mathbb{Q}$ with $\operatorname{Gal}(K/\mathbb{Q})\cong S_{n}$, doesn't the Fundamental Theorem of Galois Theory gives a positive answer to the Inverse Galois Problem? Where is the obvious point I am missing? Thanks!","['abstract-algebra', 'galois-theory', 'group-theory']"
2376860,Closest divisor,"Given two whole numbers, $N$ and $m$, a third whole number $c$ is the one that holds $N\bmod c= 0$ and has the minimal $|c-m|$. In other words, $c$ is a divisor of $N$ closest to $m$. Examples (in the form of $f(N, m) = c$): $f(10, 2) = 2$ $f(13, 10) = 13$ $f(25, 7) = 5$ $f(60, 10) = 10$ I'm trying to figure out an efficient algorithm to find $c$, but I can't find a similar problem to relate to it. I'm not sure if I'm not using the right keywords. What is the best way to do that?","['number-theory', 'gcd-and-lcm', 'elementary-number-theory']"
2376876,Find branch points as zeroes of derivative,A non-constant holomorphic function $f:X\to Y$ between Riemann Surfaces has a branch point at $p\in X$ if there is no open neighbourhood around p on which $f$ is injective. I looked up examples and saw that sometimes people only look at the zeroes of the derivative and say that these are the branch points. Why is this the case?,"['riemann-surfaces', 'complex-analysis']"
2376883,Is my proof of differentiability correct?,"Exercise : Let $f:\mathbb{R} \rightarrow \mathbb{R}$ be defined by $$f(x) =\begin{cases}x^2 & x \in \mathbb{Q} \\x^3 & x \in \mathbb{R - Q}   \end{cases}$$ for $x \in \mathbb{R}$. Using only the limit definition of derivatives, determine whether or not $f$ is differentiable at $0$. I think it is. Consider the difference quotient function $\phi:(-1, 1) - \{0\} \rightarrow \mathbb{R}$ defined by $$\phi(x) = \frac{f(x) - f(0)}{x - 0}$$ for $x \in (-1, 1) - \{0\}$. On this domain, we can say that $$\phi(x) = \begin{cases}x & x \in \mathbb{Q} \\x^2 & x \in \mathbb{R - Q}   \end{cases}$$ and $0 <|\phi(x)| \leq |x|$ on $(-1, 1)$ so $\lim_{x \to 0}\phi(x) = 0$ since $\lim_{x \to 0} |x| = 0$ implies $\lim_{x \to 0}|\phi(x)| = 0$. Hence, $f$ is differentiable at $0$ and $f'(0) = 0$.","['derivatives', 'analysis']"
2376889,"Find the smallest value of $n$ such that $19 \,|\, 10^n+1$","A riddle I'm working on reduces to this question. I don't have a number theory background and don't really know how to approach this kind of problem. In fact I'm not sure such an $n$ exists. I feel like it does, but my computer has been chugging on an R script for almost 20 minutes to find one. Any suggestions for resources/additional reading about evaluating divisibility appreciated!","['number-theory', 'prime-numbers']"
2376920,"Prove that the set of all real valued function on [a,b] is a vector space","Question - Show that the set of all real valued functions on [a,b] , $\mathrm F $[a,b] under usual addition and scalar multiplication is a vector space. What I did - let  $\mathrm L = \{ F:[a,b] \; | \; a,b \in \mathbb R \} \; $ & $\; \mathrm u, v \in L$ s.t $\mathrm u = f[a,b] \; \& \;  v= g[a,b] $ and after that I showed that the 10 axioms do satisfy under these conditions However , my instructor has marked it all wrong and she has highlighted that I have started the problem in the wrong way. She also have added the correct method , which is as follows ; $\mathrm L = \{ F:[a,b]\rightarrow \mathbb R^{2} \; | \; a,b \in \mathbb R \} \; $ let  $\; \mathrm x,y \in [a,b]$ Take any$ \,\mathrm F_1$ & $ \, \mathrm F_2$ in $\mathrm L \, $ s.t $\mathrm F_1(x,y) \in \mathbb R^{2} \; \& \;  F_2(x,y) \in \mathbb R^{2} $ Now Im really confused  because: 1.what is wrong with my approach ? , what is my mistake ? 2.why my instructor have used functions defined on (x,y) ? I think it should be [a,b] [please look into this photo to see if I have missed something else","['linear-algebra', 'vector-spaces']"
2376928,What is the significance of the quotient $m/m^2$?,"This is a curious question as much as anything. In many situations in commutative algebra, $m$ and $m^2$ (or better, $m^k$ and $m^{k+1}$, with $k \geq 0$ an integer) occur together, where $m$ is a maximal ideal of a ring $R$, or $m$ is an $R$-module, where sometimes there are assumptions on the quotient $m/m^2$ or conditions on some ideal/module lying between the powers: $m^2 \subseteq I \subseteq m$. I have always wondered what the significance of this is. What is the algebraic (or maybe geometric) intuition relating $m$ with $m^2$ (in either context)? For example, say that $R$ is local for simplicity. Then $K = R/m$ is the residue field, and considering $K$ as an $R$-module, $K \otimes_R m = m/m^2$. If on the other hand $m$ is any $R$-module, other properties of $m/m^2$ become interesting. Do these examples hint at anything? Matsumura's Commutative algebra is riddled with quotients and powers of this form, but I have never gotten (or remembered) any explanation or intuition as to why the above situations arise so often. Thanks in advance.","['modules', 'ideals', 'algebraic-geometry', 'commutative-algebra']"
2376952,The gradient as a special case of the differential (or push-forward),"I am tripping over something elementary (I think). Given a smooth map $f\colon M\to N$ between smooth manifolds, the differential of $f$ at $p\in M$ is defined as
\begin{align}\mathrm{d}_pf \colon T_pM &\to T_{f(p)}N\\
X&\mapsto X(-\circ f)\end{align}
The gradient of $f\colon M\to \mathbb{R}$ at $p$ is, if I understand correctly, just the previous definition with $T_{f(p)}\mathbb{R}\cong\mathbb{R}$. But this is were I get confused, because immediately after the gradient of $f$ is defined by
$$\mathrm{d}_pf(X):=X(f), \qquad \text{ with }X\in T_pM.$$
I understand this, since $\mathrm{d}_pf\colon T_pM\to\mathbb{R}$ (linearly) it is a covector and the right hand side works, but how can I see this as a special case of the above? (i.e. why does the $``\, -\ \circ\,''$ get dropped?) And how do the elements of $T_{f(p)}\mathbb{R}$ act on real functions? (perhaps this is more like what I am looking for).",['differential-geometry']
2376972,"$\int_{0}^{\frac{\pi}{2}}\frac{d\theta}{a + \sin^2(\theta)} = \frac{\pi}{2\sqrt{a(a+1)}}$, for $a > 0$","I want to show that $$\int_{0}^{\frac{\pi}{2}}\frac{d\theta}{a + \sin^2(\theta)} = \frac{\pi}{2\sqrt{a(a+1)}}$$ for $a > 0$ . I try several methods Substitutions to rationalize The famous $U = \tan(\frac{\theta}{2})$ Multiplying by conjugates and other calculus techniques and still, I can not prove the equality. Anyone can give me a hint of how should I begin to work this integral? I'm very ashamed that I can not solve this problem.","['integration', 'definite-integrals', 'trigonometric-integrals', 'calculus']"
2376973,Intersection numbers and multiplicities in Fulton's book,"I'm reading Algebraic Curves by Fulton where the concept of intersection numbers is introduced on page 36. They give both a definition
$$I(P,F\cap G) = \mathcal{O}_P(\mathbb{A^2})/(F,G)$$
And a characterisation using 7 properties. The 5th property of those is:
$$I(P,F\cap G) \geq m_p(F)m_p(G)$$
Where $m_P(F)$ is the multiplicity of $P$ on $F$. They also discuss when this inequality is an equality but that is not part of my question. The proof they give is the following: Question: Where do they use the fact that $m$ and $n$ are the multiplicities involved? What part of the proof would no longer be true if we changed $m$ or $n$?",['algebraic-geometry']
2376988,Computing the composition of a piecewise function,Question: $$ \text{Define } f:\mathbb{Z}\rightarrow\mathbb{Z}\text{ by }f(x)=\begin{cases}x+3\text{ if }x\text{ is ODD}\\ x-5\text{ if }x\text{ is EVEN}\end{cases} $$ Compute $ \  f \circ f$ My attempt: $ \  (f \circ f)(x) = f(f(x))$ From here do I have to create another piecewise function and consider the cases when $ f(x) = x+3$ and when $ f(x) = x-5$?,"['elementary-set-theory', 'piecewise-continuity', 'functions']"
2377017,Explain why $\liminf\frac{1}{n}\sum\limits^n_{i=1} X_i=\liminf\frac{1}{n}\sum\limits^n_{i=N} X_i$,"Let $(X_n)_{n \in \mathbb{N}}$ be real random variables. Then, why do we have $$\liminf_{n\rightarrow \infty} \frac{1}{n}\sum^n_{i=1} X_i=\liminf_{n\rightarrow \infty} \frac{1}{n}\sum^n_{i=N} X_i$$ for any $N\in \mathbb{N}$ ? Any help would be appreciated. Edit: The thing is that I'm reading this as $\liminf_{n\rightarrow \infty} \frac{1}{n}\sum^n_{i=1} X_i=\sup_{n\geq 1} \inf_{m\geq n} \frac{1}{m}\sum^m_{i=1} X_i$ and I don't see how $$\sup_{n\geq 1} \inf_{m\geq n} \frac{1}{m}\sum^m_{i=1} X_i=\sup_{n\geq 1} \inf_{m\geq n} \frac{1}{m}\sum^m_{i=N} X_i$$. Or maybe I'm just 'translating' wrongly the expression.","['probability-theory', 'limsup-and-liminf', 'sequences-and-series']"
2377018,Showing that a certain set is measurable.,"This is a follow up to this question of mine, this follow up question appears to be asked even in this other question but, to my knowledge, without an answer. Here is the question: Let $X$ be a stochastic process whose sample paths are RCLL a.s. Let $A$ be the event that $X$ is continuous on $[0,t_0)$. Show that $A$ can fail to be in $\mathcal{F}_{t_0}^X$. But if $\{\mathcal{F_t;t\ge 0}\}$ is a filtration satisfying $\mathcal{F}^X_t\subset\mathcal{F}_t,t\ge 0$ and $\mathcal{F}_{t_0}$
  is complete under P, then $A \in \mathcal{F}_{t_0}$. Where $\mathcal{F}_{t_0}^X:=\sigma{(\{X_s;0\le s\le t_0\})}$. My naive reasoning : If the sample paths are RCLL a.s. this means we can take a $t_1 \in [0,t_0)$ s.t. at $t_1$ the sample paths $X(w)_{t_1}$ have a jump discontinuity for any $w \in \Omega$. So it seems that $A$ can easily fail to be in $\mathcal{F}_{t_0}^X$. But this must be wrong because taking a complete filtration does not fix the problem with my line of reasoning. How is the question really solved?","['stochastic-processes', 'probability-theory', 'stochastic-calculus', 'measure-theory']"
2377043,On Kadec norms definition.,"So I have this definition of Kadec norm $\textbf{Definition:}$ Let $(X,\|\|)$ be a Banach space. The norm $\|\|$ is said to be a Kadec norm if $x_n \xrightarrow{w} \bar{x}$ and $\|x_n\|\to \|\bar{x}\|$ implies $x_n\to \bar{x}.$ I was wondering why is it necessary in this definition that $X$ to be a Banach space. I though that it is not at all, and that then the condition would imply that $X$ is Banach. But I was not able to prove that statement. Any thoughts?","['functional-analysis', 'normed-spaces', 'weak-convergence']"
2377054,What is the entropy of binomial decay?,"Let's play a game. I start with $N$ tokens, and I wait $T$ turns. Every turn, each token has probability $p$ of disappearing. I want an analytic formula for the entropy of this process, as a function of $N$, $T$, and $p$ . The calculation is straightforward for $N=1$ and $T=\infty$. The probability $p_i$ that our (only) token disappears at turn $i$ is $(1-p)^{i}p$, and the entropy $E$ is given by: $E(N=1, T=\infty, p=p) = \sum_{i}^{\infty}p_i\ln(p_i)$ $=\sum_{i}^{\infty}(1-p)^{i}p\ln((1-p)^{i}p)$ $=p\ln(1-p)\sum_{i}^{\infty}i(1-p)^{i} + p\ln(p)\sum_{i}^{\infty}(1-p)^{i}$ $=p\ln(1-p)\frac{1-p}{p^2} + p\ln(p)\frac{1}{p}$ $=\frac{1-p}{p}\ln(1-p) + \ln(p)$ For $N=2$ and $T=\infty$, my calculation (not shown) is a lot uglier, but simplifies down to: $E(N=2, T=\infty, p=p) = \frac{2-2p}{2-p}\ln(2) + 2\ln(p) + \frac{2-2p}{p} \ln(1-p)$ I'm about to calculate the $N=3$, $T=\infty$ case, but I've got the feeling I'm reinventing the wheel. Is the formula for $E(N, T, p)$ known? I'm particularly interested in the $T=\infty$ case. A good approximation is almost as useful to me as an exact formula, but I'm interested in both small and large values of $N$. As a sanity check, we can compare against a Python simulation: #!/usr/bin/python3
import numpy as np
from scipy.stats import binom

def entropy(n_initial, p, n_steps, n_trials):
    # Simulate many stochastic binomial decays, return the average of
    # the log of their binomial ""penalty""
    log_penalty = np.zeros(n_trials, dtype=np.float64)
    n = n_initial * np.ones(n_trials, dtype=np.int64)
    for i in range(n_steps):
        num_losses = np.random.binomial(n, p)
        log_penalty += binom.logpmf(k=num_losses, n=n, p=p)
        n -= num_losses
    return log_penalty.mean()

p=0.1
print(entropy(n_initial=1, p=p, n_steps=1000, n_trials=10000))
print(((1-p)/p)*np.log(1-p) + np.log(p))

print(entropy(n_initial=2, p=p, n_steps=1000, n_trials=10000))
print((2-2*p)/(2-p)*np.log(2) + 2*np.log(p) + ((2-2*p)/p) * np.log(1-p)) Please forgive/correct me if I've made errors in my math or I'm using the wrong terms; I'm an experimental physicist, not a mathematician, and my formal math is rusty.","['binomial-coefficients', 'statistics', 'entropy', 'probability', 'binomial-distribution']"
2377055,contradiction to characterization of second group cohomology,"Let $G$ be a group and $A$ be a $G$ -module. In Ken Brown book Cohomology of Groups , on page 93, $H^2(G,A)$ is characterized as the isomorphism classes of group extensions $ 0 \to A \to * \to G$ giving rise to the action $G \curvearrowright A$ . Now when I take $G=\mathbb{Z}/3$ and $A$ to be the trivial $G$ module $\mathbb{Z}/3$ , this characterization says that $|H^2(\mathbb{Z/3},\mathbb{Z/3})|=|\mathbb{Z/3}|=3$ is the number of group extensions $ 0 \to \mathbb{Z/3} \to K \to \mathbb{Z/3} \to 0$ . This cannot be correct because any extension group $K$ must have order 9, therefore be abelian and therefore must be either $\mathbb{Z/3} \oplus \mathbb{Z/3}$ or $\mathbb{Z/9}$ .  I claim that these gives rise to only 2 isomorphism classes of extensions: The only subgroups of $\mathbb{Z/3} \oplus \mathbb{Z/3}$ of order $3$ are the ones generated by $(1,0)$ , $(0,1)$ , $(1,1)$ and there are automorphisms of this group that permute the generators any way one likes.  Hence there is only one isomorphism class of an extension $ 0 \to \mathbb{Z/3} \to \mathbb{Z/3} \oplus \mathbb{Z/3} \to \mathbb{Z/3} \to 0$ . The only subgroups of order $3$ in $\mathbb{Z/9}$ is the one generated by $3 \in \mathbb{Z/9}$ .  Hence there is only one isomorphism class of an extension $ 0 \to \mathbb{Z/3} \to \mathbb{Z/9} \to \mathbb{Z/3} \to 0$ . These are inequivalent because the second extension does not split. Question:  Where is the third extension that the group cohomology calculation predicts?","['abstract-algebra', 'homological-algebra', 'group-cohomology', 'group-theory']"
2377069,Gaussian primes and an irrational number,"Let $p(n)$ be a Fibonacci number such that $p(n) = p(n-1) + p(n-2)$ for $p(1) = p(2) = 1$.
The golden ratio $(\phi = \frac{1+\sqrt{5}}{2})$ is diophantinely approximated:
as $n \to \infty$, $|p(n-1) \phi – p(n)| \to 0$. Does the sequence $(p(n-1) + p(n) i)$ contain an infinite number of Gaussian primes? Numerically it seems that the number of Gaussian primes divided by $n$ decreases to a number $ < 0.1$.","['number-theory', 'fibonacci-numbers']"
2377102,The Challenge of the Twin Prime Conjecture,"Are there an infinite amount of twin composite pairs (which are infinite)  ( https://oeis.org/A060461 ) whose prime factors are contained within a twin prime pair? Example: $ (119,121) $ $ 119 = 7 * 17  $ $ 121 = 11 * 11 $ $7, 11, 17$ are contained within $(5,7)$ $(11, 13)$ and $(17, 19)$ which are twin  prime pairs Are questions like this impossible to use to answer the Twin Prime Conjecture?","['number-theory', 'prime-numbers']"
2377109,Showing the following series is uniformly convergent,"Let $f(x)=\sum_{n=1}^{\infty}\frac{\sqrt n}{n+x}\sin nx$. Show that for any $x\in (-1,\infty)$ the series is convergent. Find the intervals on which the series is uniformly convergent. If $x=k\pi$, where $k$ is an integer, then $\sin nx=0$. Now suppose $x\neq k\pi$, then $|\sum \sin kx|\leq \frac{1}{\sin{\frac{x}{2}}}$. As $x\in (-1,\infty)$, then $\frac{1}{n+x}<\frac{1}{n-1}$, which implies $\frac{\sqrt n}{n+x}<\frac{\sqrt n}{n-1}$. Hence, for any $x\in (-1,\infty)$ by the Dirichlet test, we can guarantee that the series is convergent at least pointwise. But I need help for uniformly convergent part. Thank you.","['power-series', 'real-analysis', 'sequences-and-series', 'uniform-convergence']"
2377165,"If a function is constant on some domain and differentiable, is it constant on a larger domain?","If $f(x) = C$ on $(a,b)$ and differentiable does this imply that $f(x) = C$ on the whole domain ($\mathbb{R}$)?","['derivatives', 'calculus']"
2377194,Showing tensor product of f.g. reduced $k$-algebras is reduced where I should assume $k$ algebraically closed?,"This is a rough idea I have to prove the statement of the following. I want to prove algebraically the product of varieties is variety where variety means irreducible algebraic set. Let $A,B$ be f.g. reduced $k$ -algebras and I should assume $k$ algebraically closed. Then $A\otimes B$ is reduced. From Noether normalization, I obtain $k[x_1,\dots, x_n]\to A$ as integral extension and $k[y_1,\dots, y_m]\to B$ as integral extension. And Noether normalization does not require $k$ algebraically closed. So I obtained the following natural map. Denote $R_1=k[x_1,\dots, x_n],R_2=k[y_1,\dots, y_m]$ . $R=R_1\otimes R_2=k[x_1,\dots, x_n,y_1,\dots, y_m]\to A\otimes B$ . It suffices to show any $0\neq a\otimes b\in A\otimes B$ is integral over $R$ . Clearly $a\otimes 1$ integral over $R$ and $1\otimes b$ integral over $R$ as well. So $R\to R[a\otimes 1]\to R[a\otimes 1,1\otimes b]$ are the extensions and both extensions are finite. So I conclude that $a\otimes b$ is integral over $R$ . So if I have $0\neq x,y\in A\otimes B$ and $xy=0$ say $x$ satisfies equation $f(z)=0$ and $y$ satisfies $g(z)=0$ where $f,g\in R[z]$ are monics. Choose $f,g$ containing constant term say $f_0,g_0\in R$ . Then I check $f(x)g(y)=0$ by plugging in $x$ and $y$ values correspondingly. However $xy=0$ implies $f_0g_0=0$ . Since $R=k[x_1,\dots, x_n,y_1,\dots, y_n]$ is integral domain, I conclude that $g_0=0$ or $f_0=0$ which is contradiction. So $xy\neq 0$ for any $0\neq x,y\in R$ . I did not use that $k$ is algebraically closed. I feel I have done something wrong here. I think one the possible mistake would be $R_1\otimes R_2\to R_1\otimes B\to A\otimes B$ 's last extension as there is no reason to believe $B$ is flat over $k$ as a module first.","['integral-extensions', 'noetherian', 'algebraic-geometry', 'abstract-algebra', 'commutative-algebra']"
2377225,Finding Limit of an Integral: $\lim_{n\to\infty}\int_a^b f(x)\sin^3{(nx)} \:dx$,"Suppose $f:[a,b]\to\mathbb{R}$ is continuous. Determine if the following limit exists $$\lim_{n\to\infty}\int_a^b f(x)\sin^3{(nx)} \:dx.$$ As $f(x)$ and $\sin^3{(nx)}$ are continuous, so their product is Riemann integrable. However $\lim_{n\to\infty} f(x)\sin^3{(nx)} $ does not exist, so it's not uniformly convergence and we cannot pass the limit inside the integral. It also doesn't satisfy in the conditions of Dini Theorem. I don't know how to make a valid argument for this problem, but I think by what I said the limit doesn't exist. I appreciate any help.","['uniform-convergence', 'limits', 'continuity', 'integration', 'analysis']"
2377241,Convergence of $\sum\frac{1}{n(\ln n)^c}$,"What are the values of the positive constant, $c$, for which 
  $$ \sum_{n=2}^\infty \frac{1}{n(\ln n)^c}$$
  is convergent or divergent? I am a bit confused here, because usually the $c$ value is given, so I am not really sure how to approach this.","['real-analysis', 'convergence-divergence', 'calculus']"
2377289,Solutions in terms of the hypergeometric functions,"Is it possible to somehow express the solutions to the differential equations:
$$\frac{d^2y}{dx^2} + \bigg(\frac{1}{x + 8} - \frac{1}{x} + \frac{1}{x - 1} + \frac{1}{x - 4}\bigg) \frac{dy}{dx} + \bigg(\frac{1}{x^2} + \frac{3}{4x} - \frac{5}{6(x - 1)} - \frac{1}{4(x - 4)^2}\bigg) y = 0$$
and
$$\frac{d^2y}{dx^2} + \bigg(\frac{1}{x + 8} + \frac{1}{3x} + \frac{1}{x - 64}\bigg) \frac{dy}{dx} + \bigg(\frac{7}{144x^2} - \frac{7}{3072x} + \frac{7}{3072(x - 64)}\bigg) y = 0$$
in terms of the hypergeometric functions?","['complex-analysis', 'hypergeometric-function', 'special-functions', 'ordinary-differential-equations', 'power-series']"
2377367,"What does ""trivial solution"" mean?","What does ""trivial solution"" mean exactly? Must the trivial solution always be equal to the zero-solution (where all unknowns/variables are zero)?","['ordinary-differential-equations', 'systems-of-equations']"
2377456,Is there an error in this problem? $\sin^4(\frac{23\pi}{12})-\cos^4(\frac{13\pi}{12})$,"$\sin^4(\frac{23\pi}{12})-\cos^4(\frac{13\pi}{12})$ If there were written $\frac{23\pi}{12}$ instead of $\frac{13\pi}{12}$ it could be solved as $$\begin{align}[\sin^2(\frac{23\pi}{12})+\cos^2(\frac{23\pi}{12})][\sin^2(\frac{23\pi}{12})-\cos^2(\frac{23\pi}{12})]=&\\ -[\cos^2(\frac{23\pi}{12})-\sin^2(\frac{23\pi}{12})]=& \\ -\cos(\frac{23\pi}{6})=&\\ -\cos(\frac{11\pi}{6})=&\\ -\frac{\sqrt{3}}{2}\end{align}$$ Otherwise, there seems to be no way towards solving it.",['trigonometry']
2377485,How to simplify an expression involving several square roots without a calculator?,"$$\frac{5 \sqrt{7}}{4\sqrt{3\sqrt{5}}-4\sqrt{2\sqrt{5}}}- \frac{4 \sqrt{5}}{\sqrt{3\sqrt{5}}-\sqrt{2\sqrt{5}}}$$
This type of questions are common in the university entrance examinations in our country but the calculators are not allowed can someone help me to find the way to simplify the expression.","['algebra-precalculus', 'radicals']"
2377497,"How many order triple (a,b,c) are there such that $a.b.c \le 1000$","How many order triple of positive integers (a,b,c) are there such that $a\leq b\leq c$ and $a\cdot b \cdot c \leq 1000$? I have no idea how to attack this type of problem. Can anyone help. Thanks in advance.","['combinatorics', 'contest-math']"
2377506,What are the random variables for which $E[X^k]/E[X]^k\to\infty$?,"If $X$ is a random variable with distribution uniform in $[0,1]$, then $E[X^k] = 1/(k+1)$ and $E[X]^k = 1/2^{k}$ so: $${E\left[X^k\right] \over E[X]^k} \xrightarrow{k\to\infty} \infty$$ What other distributions (of non-negative random variables) have this property? NOTE: Jensen's inequality implies that for every non-negative random variable $X$: $E\left[X^k\right]\geq E[X]^k$ (is this true?) . But it does not imply that the ratio between them goes to infinity.","['probability-theory', 'expectation', 'random-variables']"
2377511,Derangement without replacement,"Each of $n \geq2$ people puts his or her name on a slip of paper (no two have the same
  name). The slips of paper are shuffled in a hat, and then each person draws one (uniformly
  at random at each stage, without replacement). Find the average number of
  people who draw their own names. Does this match the pattern of derangements? I can't wrap my head around the fact that this does not allow replacement. EDIT 2: Adding to the comment of @drhab . The probability that the first person draws his own name is $\frac1n$ .
By symmetry, anyone could be the first person.
So, $$P[X_i] = \frac1n.$$ And summing over $n$ (linearity of expectation), I get $1$ . Is my approach correct? I am not super confident. I am trying to self-study probability using Blizstein's lectures and book, and I keep getting stuck in most of the questions.","['probability', 'derangements']"
2377525,The upper bound of the sum of a series,"If $y_n$ is a nonincreasing series of real numbers and $0\leq y_n\leq1 $ for $n\geq 0$, $y_0 = 1$ and we know that $\sum_{n=0}^\infty y_n \leq A $, then is there a way to find a tight upper bound for $\sum_{n=0}^\infty y_n^m $, where $m$ is an integer number?","['sequences-and-series', 'upper-lower-bounds']"
2377569,Differentiation of $a^\top x x^\top a$,"I know that for matrix $A$ and vector $x$, the derivative of the quadratic form with respect to $x$ is $$\frac{\partial x^TAx}{\partial x} = (A+A^T)x$$ But how do we differentiate $a^T x x^T a$ with respect to $x$?","['derivatives', 'matrices', 'matrix-calculus', 'scalar-fields', 'multivariable-calculus']"
2377598,Is it always possible to create a intuition for abstract algebra theorems?,"I am a Ph.D student in computer science, and I work on graph isomorphism. My research work requires some level of mathematics (mostly group theory ). I have done basic level abstract algebra course. I try to write down the theorems on peace of paper and try to understand them; I usually repeat this process four five times. Some time by doing this I understand the theorem and its proof, but there are times when I find it difficult. The biggest problem I have faced is that theorems related to abstract algebra are really abstract I mean there is no way to create an intuition (Is it true ?). My question : How to create an intuition for abstract algebra theorems? For Example","['abstract-algebra', 'advice', 'group-theory', 'soft-question']"
2377620,"Prob. 8, Chap. 6, in Baby Rudin: The Integral Test for Convergence of Series","Here is Prob. 8, Chap. 6, in the book Principles of Mathematical Analysis by Walter Rudin, 3rd edition: Suppose $f \in \mathscr{R}$ on $[a, b]$ for every $b > a$ where $a$ is fixed. Define 
  $$ \int_a^\infty f(x) \ \mathrm{d} x = \lim_{b \to \infty} \int_a^b f(x) \ \mathrm{d} x $$
  if this limit exists (and is finite). In that case, we say that the integral on the left converges. If it also converges after $f$ has been replaced by $\lvert f \rvert$, it is said to converge absolutely. Assume that $f(x) \geq 0$ and that $f$ decreases monotonically on $[1, \infty)$. Prove that 
  $$   \int_a^\infty f(x) \ \mathrm{d} x $$
  converges if and only if 
  $$ \sum_{n=1}^\infty f(n) $$
  converges. (This is the so-called ""integral test"" for convergence of series. ) My Attempt: As $f(x) \geq 0$ on $[1, \infty)$, so for each $n\in \mathbb{N}$ we see that 
  $$ \sum_{k=1}^{n+1} f(k) = \sum_{k=1}^n f(k) \ + \  f(n+1) \geq \sum_{k=1}^n f(k). \tag{0} $$ 
  Thus the sequence $\left( \sum_{k=1}^n f(k) \right)_{n \in \mathbb{N} }$ is a monotonically increasing sequence of (non-negative) real numbers. Suppose $b$ and $c$ are any two real numbers such that $1 < b < c$. Then we have 
  $$
\begin{align}
\int_1^c f(x) \ \mathrm{d} x &=  \int_1^b f(x) \ \mathrm{d} x +  \int_b^c f(x) \ \mathrm{d} x \qquad \mbox{ [ by Theorem 6.12 (c) in Baby Rudin ] } \\
&\geq \int_1^b f(x) \ \mathrm{d} x + 0 \\
& \ \ \ \qquad \mbox{ [ by Theorem 6.12 (b) in Baby Rudin since $f(x) \geq 0$ on $[b, c]$ ] } \\
&= \int_1^b f(x) \ \mathrm{d} x. \tag{1}
\end{align}
$$ 
  which shows that the function $g$ defined on $(1, \infty)$ by 
  $$ g(b) = \int_1^b f(x) \ \mathrm{d} x \tag{A} $$
  is a monotonically increasing function. Now suppose that $b$ is a real number such that $b > 2$. Let $n$ be the natural number such that $n \leq b < n+1$. Then we see that 
  $$ 
\begin{align}
\int_1^b f(x) \ \mathrm{d} x &\leq \int_1^{n+1} f(x) \ \mathrm{d} x \qquad \mbox{ [ using (1) above; note that $n \leq b < n+1 $ ] } \\
&= \sum_{k=1}^n \int_k^{k+1} f(x) \ \mathrm{d} x \qquad \mbox{ [ by an extension of Theorem 6.12 (c) in Rudin ] } \\
&\leq \sum_{k=1}^n \int_k^{k+1} f(k) \ \mathrm{d} x \\
&\ \ \ \qquad \mbox{ [ using Theorem 6.12 in Baby Rudin and the monotonicity of $f$ ] } \\
&= \sum_{k=1}^n f(k). \tag{2} 
\end{align}
$$
  And, also 
  $$ 
\begin{align}
\int_1^b f(x) \ \mathrm{d} x &\geq \int_1^n  f(x) \ \mathrm{d} x \qquad \mbox{ [ using (1) above; note that $n \leq b < n+1 $ ] } \\
&= \sum_{k=1}^{n-1} \int_k^{k+1} f(x) \ \mathrm{d} x \qquad \mbox{ [ by an extension of Theorem 6.12 (c) in Rudin ] } \\
&\geq \sum_{k=1}^{n-1} \int_k^{k+1} f(k+1) \ \mathrm{d} x \\
&\ \ \ \qquad \mbox{ [ using Theorem 6.12 in Baby Rudin and the monotonicity of $f$ ] } \\
&= \sum_{k=1}^{n-1} f(k+1) \\
&= \sum_{k=2}^n f(k). \tag{3} 
\end{align}
$$ Thus from (2) and (3) we can conclude that for every real number $b > 2$, we have 
  $$ \sum_{k=2}^n f(k) \leq \int_1^b f(x) \ \mathrm{d} x \leq  \sum_{k=1}^n f(k), \tag{4} $$
  where $n$ is the natural number such that $n \leq b < n+1$. Now suppose that $\int_1^\infty f(x) \ \mathrm{d} x$ converges. This means that $\lim_{b \to \infty} \int_1^b f(x) \ \mathrm{d} x $ exists in $\mathbb{R}$,  and in the light of (1) we can also write $$\int_1^\infty f(x) \ \mathrm{d} x =  \lim_{b \to \infty} \int_1^b f(x) \ \mathrm{d} x = \sup \left\{ \ \int_1^b f(x) \ \mathrm{d} x \ \colon \ b \in \mathbb{R}, \ b > 1 \ \right\}. \tag{5} $$ Then for any natural number $n \geq 2$, if we take $b \in (n, n+1)$, then from (4) and (5) we can conclude that 
  $$ \sum_{k=2}^n f(k) \leq \int_1^\infty f(x) \ \mathrm{d} x, $$
  which implies that 
  $$ \sum_{k=1}^n f(k) \leq f(1) \ + \ \int_1^\infty f(x) \ \mathrm{d} x. $$
  Thus the sequence  $\left( \sum_{k=1}^n f(k) \right)_{n \in \mathbb{N}}$ of (non-negative) real numbers is bounded above, and (0) shows that this sequence is also monotonically increasing;  therefore this sequence is convergent (in $\mathbb{R}$). That is, the series $\sum f(n) $ is convergent. Conversely, suppose that the series $\sum f(n)$ is convergent. Then the sequence  $\left( \sum_{k=1}^n f(k) \right)_{n \in \mathbb{N}}$ converges in $\mathbb{R}$; but by (0) above this is a monotonically increasing sequence of real numbers; so it is a bounded above sequence and 
  $$ \sum_{n=1}^\infty f(n) = \lim_{n \to \infty} \sum_{k=1}^n f(k) = \sup \left\{ \  \sum_{k=1}^n f(k) \ \colon \ n \in \mathbb{N} \ \right\}. \tag{6} $$ Now let $b$ be any real number such that $b > 2$, and let $n$ be the natural number such that $n \leq b < n+1$. Then from (4) and (6) we can conclude that 
  $$ \int_1^b f(x) \ \mathrm{d} x \leq \sum_{k=1}^n f(k) \leq \sum_{n=1}^\infty f(n). $$ Thus the function $g$ given by (A) above is a monotonically increasing function on $(2, \infty)$ which is also bounded above. So $\lim_{b \to \infty} g(b)$ exists in $\mathbb{R}$; that is $ \lim_{b \to \infty} \int_1^b f(x) \ \mathrm{d} x$ exists in $\mathbb{R}$, which is the same as saying that 
  $\int_1^\infty f(x) \ \mathrm{d} x$ converges. Is my proof correct? If so, then have I managed to present it in enough detail and rigorous for it to be understood by someone who is not very sharp (like myself) and is also taking their very first course in analysis? Or, have I committed some blunders?","['real-analysis', 'integration', 'definite-integrals', 'sequences-and-series', 'analysis']"
2377636,"Find the function such $f(x+f(y)+xf(y))\ge y+f(x)+yf(x),\forall x,y\in(-1,+\infty)$","Let $ f ( x ) : ( - 1 , + \infty ) \to ( - 1 , + \infty ) $ be a continuous monotonic function, such that $ f ( 0 ) = 0 $, and
$$ f ( x + f ( y ) + x f ( y ) ) \ge y + f ( x ) + y f ( x ) \quad \forall x , y \in ( - 1 , + \infty ) \text {.} $$
Find $ f ( x ) $. Let $ x = 0 $, then we have
$$ f ( f ( y ) ) \ge y \text {.} $$","['functional-inequalities', 'functions']"
2377638,Additive function $T: \mathbb{R} \rightarrow \mathbb{R}$ that is not linear.,"A function $T:V \rightarrow W$ is additive if $T(x+y) = T(x) + T(y)$ for every $x, y \in V$. Prove that there exists an additive function $T: \mathbb{R} \rightarrow \mathbb{R}$ that is not linear. My attempt: Let $T$ be the function $T: \mathbb{R}$ (over the field $\mathbb{Q}$) $\rightarrow \mathbb{R}$ (over the field $\mathbb{R}$). The set $\{1, \sqrt{2}\} \subseteq \mathbb{R}$ is linearly independent for the vector space $\mathbb{R}$ over $\mathbb{Q}$. Then, there must exist a linearly independent set $W \subseteq \mathbb{R}$ (over $\mathbb{Q}$) such that $\{1, \sqrt{2}\} \subseteq W \subseteq \text{span}(W) = \mathbb{R}$ (over $\mathbb{Q}$). I have been told that the function defined as $T(1) = 1$ and $T(w) = 0$ for all $w \in \text{span}(W) \setminus \{1\}$ is additive but not linear, but I cannot see why this is? I can see why it is not linear, clearly $T(\sqrt{2} \cdot 1) = 0$ but $\sqrt{2} T(1) = \sqrt{2}$. But, why is $T$ additive? For example, $T(1+1) = T(2) =0$ but $T(1) + T(1) = 1+1 = 2$? Is there a mistake somewhere?",['linear-algebra']
2377661,Choosing the right correlation test for the given variables [closed],"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 6 years ago . Improve this question I need to choose between Pearson, Spearman and Kendall's tau correlations for the given varibles $A$ and $B$: $A,B$ are continuous with importance to value $A,B$ are ordinal variables $A$ is continuous and $B$ is ordinal $A,B$ are continuous with importance to order My try: The only correlation test which uses values is Pearson . It seems to me that Kendall's tau best fits though Spearman could be used as well. I've understood that Spearman is good for both continuous and ordinal, but technically we could use Kendall's tau, can't we? Kendall's tau - since the order is important So as you can see I'm somewhat confused regarding choosing the right test and I'd be glad if you could help me understand what are the appropriate choices. Thanks","['machine-learning', 'statistics', 'correlation']"
2377726,Let $p$ be an odd prime. Prove that if $P$ is a non-cyclic $p$-group then $P$ contains a normal subgroup $U$ with $U\cong\Bbb Z_p\times\Bbb Z_p$.,"Let $p$ be an odd prime. Prove that if $P$ is a non-cyclic $p$-group then $P$ contains a normal subgroup $U$ with $U\cong\Bbb Z_p\times\Bbb Z_p$. (Abstract Algebra: Dummit & Foote, Semidirect Products) The authors provide us with some hints. So I may as well incorporate them in the following attempt: We proceed with induction on $|P|$. The cases are trivial for $|P|=p$ or $p^2$. If $|P|=p^3$, $P\cong\Bbb Z_{p^2}\times\Bbb Z_p,$ or $\cong\Bbb Z_p\times\Bbb Z_p\times\Bbb Z_p$, or $\cong\Bbb Z_{p^2}\rtimes\Bbb Z_p$, or $\cong(\Bbb Z_p\times\Bbb Z_p)\rtimes\Bbb Z_p$. For an abelian group, every subgroup is normal. Both $\Bbb Z_{p^2}\times\Bbb Z_p$ and $\Bbb Z_p\times\Bbb Z_p\times\Bbb Z_p$ obviously contain such subgroup $U$. If $P\cong(\Bbb Z_p\times\Bbb Z_p)\rtimes\Bbb Z_p=\langle a,b,c$ s.t. $a^p=b^p=c^p=1,ab=ba,cac^{-1}=ab,cbc^{-1}=b\rangle$, take $U=\langle a,b\rangle$. If $P\cong\Bbb Z_{p^2}\rtimes\Bbb Z_p=\langle d,e$ s.t. $d^{p^2}=e^p=1,ede^{-1}=d^{1+p}\rangle$, take $U=\langle d^p,e\rangle$. $d^p$ and $e$ commute because $ed^pe^{-1}=(ede^{-1})^p=(d^{1+p})^p=d^{p+p^2}=d^p$. Now we really actually proceed with induction. But before that, notice that the result is true if $P$ is an abelian group: every subgroup is normal and it's non-cyclic so it contains two elementary divisors anyway. Write $P\cong\Bbb Z_{p^{\beta_1}}\times\Bbb Z_{p^{\beta_2}}\times\dots$. Find an element of order $p$ in the first factor and another in the second factor, they generate the $U$ we want. Now the inductive hypothesis: suppose the result is true for any group with order $<|P|=p^\alpha$. Let $Z\le Z(P)$ with $|Z|=p$. Then we use this: Lemma. if $P/Z$ is cyclic, then $P$ is abelian. So Assume $P/Z$ is not cyclic. $|P/Z|<|P|$. Being a quotient of a $p$-group $P$, $P/Z$ is a $p$-group. By the inductive hypothesis, $P/Z$ contains a normal subgroup $H/Z\cong\Bbb Z_p\times\Bbb Z_p$. Let $\pi:P\rightarrow P/Z$ defined by $\pi:p\mapsto pZ$ be the natural projection homomorphism of the quotient. $\pi^{-1}(H/Z)=H$, the complete preimage of $H/Z$, is of order $p^3$. Let $kerf=\{h\in H$ s.t. $h^p=1\}$ be the kernel of the following $p$-th power map. I also show some established results: Let $p$ be an odd prime. $|H|=p^3$, the $p$-th power map of $H$, $f$, is defined as $f:h\mapsto h^p$. This is a homomorphism of $H$ into $Z(H)$. If $H$ is not cyclic, $|kerf|=p^2$ or $p^3$. $H$ is not cyclic, because its quotient $H/Z$ is not cyclic. Also, $kerf\unlhd^{char}H$. This is because $kerf$ contains the identity and all the elements of $H$ that are of order $p$, and if $\sigma\in\operatorname{Aut}(H)$, $\sigma$ preserves orders of elements, so it permutes the elements of order $p$. So $\sigma(kerf)=kerf$. We have $kerf\unlhd^{char}H\unlhd P$, i.e. $kerf\unlhd P$. And $kerf\cong\Bbb Z_p\times\Bbb Z_p$ (if so, then we're done), or $\cong\Bbb Z_p\times\Bbb Z_p\times\Bbb Z_p$, or $(\Bbb Z_p\times\Bbb Z_p)\rtimes\Bbb Z_p$. What if $kerf\cong\Bbb Z_p\times\Bbb Z_p\times\Bbb Z_p$, or $(\Bbb Z_p\times\Bbb Z_p)\rtimes\Bbb Z_p$? Surely for the former one, I cannot find characteristic subgroups of order $p^2$. There has to be some other way of constructing normal subgroup... For the latter one, is $\langle a,b\rangle$ characteristic? Why if it is?","['p-groups', 'abstract-algebra', 'group-theory', 'semidirect-product', 'solution-verification']"
2377753,"Ulam's Conjecture, Graph isomorphism, Application","Here is a short takeout on Ulam's Conjecture: On the Wikipedia page it say it has been proven up to n=11. Now the Question: 
If I have to check for the Isomorphism, does this mean, if I take out an Vertex x in Graph one and then show that for all vertices in Graph two it is impossible to get G-x, then they could not be isomorphic? As long I am have less the 11 edges. Any suggestion on this?","['graph-theory', 'discrete-mathematics']"
2377793,An infinite list of irrational numbers from one irrational number.,"There is an interesting irrational number, in binary it is, .01101110010111011110001001101010111100110111101111... It is made by appending the numbers 0,1,2,3,4,5,6,7 etc one after the other in binary. 0,1,10,11,100,101,110,111,1000,1001,1010,1011,1100,1101,1110,1111 etc We can form a square matrix from this irrational number. The first twenty-five binary digits would be placed in this order. $
        \begin{matrix}
        1 & 4 & 9 & 16 & 25 \\
        2 & 3 & 8 & 15 & 24 \\
        5 & 6 & 7 & 14 & 23 \\
        10 & 11 & 12 & 13 & 22 \\
        17 & 18 & 19 & 20 & 21 \\
        \end{matrix}
$ So our matrix would begin with $
        \begin{matrix}
        0 & 0 & 0 & 1 & 0 \\
        1 & 1 & 0 & 0 & 0 \\
        1 & 1 & 1 & 1 & 1 \\
        1 & 0 & 1 &1 & 0 \\
        1 & 1 & 1 & 0 & 0 \\
        \end{matrix}
$ And the matrix would have an infinite number of digits to the right and bottom. We can convert our matrix to a list like this. 0.00010...  
    0.11000... 
    0.11111... 
    0.10110... 
    0.11100...
       ... We will have a fixed, infinite eternal object. It will contain an infinite number of irrational numbers. My question is, will this list contain numbers like the binary version of $\pi-3 = 0.141159 \ldots = 0.001001000011111100111110 \ldots$, and more important, will it contain any rational numbers like $ 0.10101010 \dots$",['elementary-set-theory']
2377797,Determine the number of ways to choose $a_i$,"Let $\{a_i\}_{i=1}^{n} \in \{ -1,1\}$ be $n$ numbers, each either $-1$ or $1$. Find the number of ways such that $$ \sum_{i=1}^{k} a_i \geq 0 \ \forall \ 1 \leq k \leq n $$ The number of $1$ should be greater than or equal to $-1$, but the restriction that it is so for all $k$ is creating some trouble. Any help will be appreciated. Thanks.","['algebra-precalculus', 'combinatorics']"
2377802,The algorithm to find an eigenvector of a symmetric tridiagonal matrix associated with a known eigenvalue.,"This question is related to my previous question The algorithm to find the largest eigenvalue and one of its eigenvector of a symmetric tridiagonal matrix? The matrix in question is a symmetric tridiagonal matrix in the form of $$\left( {\begin{array}{*{20}{c}}
  {{x_1}}&{{y_1}}&{}&{} \\ 
  {{y_1}}&{{x_2}}& \ddots &{} \\ 
  {}& \ddots & \ddots &{{y_{n - 1}}} \\ 
  {}&{}&{{y_{n - 1}}}&{{x_n}} 
\end{array}} \right)$$ where $y_1,...,y_{n-1}$ are all positive numbers. The question is Suppose now we already know an eigenvalue $\lambda$ of it, what is the right way to compute an eigenvector associated with  $\lambda$? There seems to be an naive method, but I am very not sure if it is correct. Suppose the eigenvector is $a=(a_1,...,a_n)$, Set $a_1$ to arbitrary non-zero number if $y_1 \neq \lambda$, and set $a_1 = 0$ otherwise, then solve $a_2$ by $x_1a_1+y_1a_2=\lambda (a_1+a_2)$, then solve $a_3$ by $y_1a_1+x_2a_2+y_2a_3=\lambda (a_1+a_2+a_3)$, and so on so forth. Will it really be so simple?","['eigenvalues-eigenvectors', 'tridiagonal-matrices', 'numerical-linear-algebra', 'matrices', 'linear-algebra']"
2377816,Applying law of total probability to conditional probability,"I was solving problems based on Bayes theorem from the book ""A First Course in Probability by Sheldon Ross"". The problem reads as follows: An insurance company believes that there are two types of people: accident prone and not accident prone. Company statistics states that accident prone person have an accident in any given year with probability $0.4$, whereas the probability is $0.2$ for not-accident prone person. If we assume $30\%$ of population is accident prone, what is the conditional probability that a new policyholder will have an accident in his or her second year of policy ownership, given that the policyholder has had an accident in the first year? The solution given is as follows: Book Solution $$
\begin{align}
P(A)=0.3 & & (given)\\  
\therefore P(A^c)=1-P(A)=0.7 & & \\
P(A_1|A)=P(A_2|AA_1)=0.4  & &(given)\\
P(A_1|A^c)=P(A_2|A^cA_1)=0.2 & & (given)
\end{align}
$$
  $$
P(A_1)=P(A_1|A)P(A)+P(A_1|A^c)P(A^c)
=(.4)(.3)+(.2)(.7)=.26  \\
P(A|A_1)=\frac{(.4)(.3)}{.26}=\frac{6}{13} \\
P(A^c|A_1)=1-P(A|A_1)=\frac{7}{13} 
$$
  $$
\begin{align}
P(A_2|A_1)& =P(A_2|AA_1)P(A|A_1)+P(A_2|A^cA_1)P(A^c|A_1) &&...(I)\\
&=(.4)\frac{6}{13}+(.2)\frac{7}{13}\approx .29\\
\end{align}
$$ I dont understand the statement $(I)$. My Solution Shouldnt it be like this:
  $$P(A_2|A_1)=P(A_2|AA_1)P(AA_1)+P(A_2|A^cA_1)P(A^cA_1)$$
  Continuing further: $$
\begin{align}
P(A_2|A_1)&=P(A_2|AA_1)P(A_1|A)P(A)+P(A_2|A^cA_1)P(A_1|A^c)P(A^c)\\
&=(.4)(.4)(.3)+(.2)(.2)(.7)=0.076
\end{align}
$$ Am I wrong? If yes, where did I go wrong? Added Later After going through comments and thinking more, it seems that I am struggling to apply law of total probability (and my above solution is very well wrong). The basic form of law of total probability, which I came across till now, is as follows: 
$$P(A)=P(A|\color{red}{B})P(\color{red}{B})+P(A|\color{magenta}{B^c})P(\color{magenta}{B^c})$$
I am first time facing application of this law for conditional probability, as done book solution:
$$P(A_2|A_1)=P(A_2|AA_1)P(A|A_1)+P(A_2|A^cA_1)P(A_c|A_1)$$ 
as it involves three events ($A,A_1,A_2$). Book did not explained this. Though in current problem, it looks ""somewhat"" intuitive, can someone generalize it, so as to make my understanding more clear? Say for $n$ events? Also, in $P(A_2|A_1)=P(A_2|\color{red}{AA_1})P(\color{red}{A|A_1})+P(A_2|\color{magenta}{A^cA_1})P(\color{magenta}{A^c|A_1})$, I feel red colored stuff should be same and pink colored stuff should be same, as in case of simple form law of total probability. I felt it should be $P(A_2|\color{red}{(A_1|A)})P(\color{red}{A_1|A})+P(A_2|\color{magenta}{(A_1|A^c)})P(\color{magenta}{A_1|A^c})$. Am I absolutely stupid here? For a moment I felt its related to:$P(E_1E_2E_2...E_n)=P(E_1)P(E_2|E_1)P(E_3|E_1E_2)...P(E_n|E_1...E_{n-1})$. Is it so? I am now screwed at my ability to apply law of total probability. Please enlighten me.",['probability']
2377861,Curvature of a 2D discrete curve,"Suppose one has a discrete plane curve in 2D, such that the curve is composed entirely of connected straight line segments. Clearly, the usual definition of curvature does not apply, as this curve is not smooth. However, is there a curvature definition one could use, that would converge to the usual definition as more and more line segments were used to describe a smooth curve? That is, for a discrete plane curve, at each vertex point, our discrete curvature should be defined such that at the limit of the smooth curve, the new curvature at the vertex, should be the curvature of the curve at that point. Is such a definition possible? If it is, are there standard definitions for this discrete curvature? Is more than a single definition even possible? $\qquad\qquad\qquad\qquad$","['discrete-geometry', 'differential-geometry']"
2377869,Adapting Solution of Second Order Differential Equations,"I am interested in solving the following system of differential equations
\begin{equation}
	\ddot{z}_j = \sum_{k\neq j}^n\frac{2\dot{z}_j\dot{z}_k}{z_j-z_k},\qquad \forall j\in\{1,\dots,n\},
\end{equation}
for $n$ even and initial conditions satisfying
\begin{equation}
	{z}_{j+n/2}(0) = {z}_{j}^{-1}(0),\qquad \forall j\in\{1,\dots,n/2\}.
\end{equation} I have found the following solution that works except for the fact that it does not satisfy the initial conditions (for $n>2$):
\begin{equation}
	{z}_{j}(t) = a + b e^{2\pi i \frac{j}{n}}(t-c)^{\frac{1}{n}}.
\end{equation} I am looking for a way to modify this solution in order to be able to satisfy the initial condition, but haven't been successful. Any hints or references would be very welcome.","['ordinary-differential-equations', 'initial-value-problems']"
2377883,To prove $n\binom{2n-1}{n-1}$ is divisible by $n(2n-1)$,Prove that for natural $n \ge 2$ $$n\binom{2n-1}{n-1}$$ is divisible by $$n(2n-1)$$ We have $$n\binom{2n-1}{n-1}=n \frac{(2n-1)!}{(n-1)! \:n!}=n(2n-1)\frac{(2n-2)!}{(n-1)! \:n!}$$ Now it suffices to prove $\frac{(2n-2)!}{(n-1)! \:n!}$ is an integer Now $$\frac{(2n-2)!}{(n-1)! \:n!}= \frac{1 \times 2 \times 3 \cdots \times (n-1) \times (n-2) \times (n-3) \cdots  \times (2n-4) \times (2n-3) \times (2n-2)}{(n-1)! \: n!}$$ hence $$\frac{(2n-2)!}{(n-1)! \:n!}=\frac{(n-2) \times (n-3) \cdots (2n-2)}{n!}$$ any clue to prove this is always an integer?,"['combinations', 'binomial-coefficients', 'combinatorics', 'factorial', 'elementary-number-theory']"
2377897,How to find points of extrema of $f(x)=\cos x+ \cos\left(\sqrt{2}x\right)$,"How to find points of extrema of $f(x)=\cos x+ \cos\left(\sqrt{2}x\right)$ we have $$f'(x)=-\sin x - \sqrt{2}\sin\left(\sqrt{2}x \right)=0 \tag{1}$$ $x=0$ is one of the solutions at which $f$ attains local Maximum since $$f''(x)=-\left(\cos x+2 \cos\left(\sqrt{2}x\right)\right)$$ we have$f''(0) \lt 0$ But $1$ has infinite solutions right, how to check whether they are points of Local Maxima and Minima?","['derivatives', 'algebra-precalculus', 'continuity', 'ordinary-differential-equations', 'convergence-divergence']"
2377899,Tangent at $0$ of $\sqrt{|x|}$,"This is a question regarding the solution to a question from Adams' book on Calculus. The question asks whether the function $f(x) = \sqrt{|x|}$ has a tangent line at $x = 0$. The answer is no. But when looking through the solution manual, Adams reasons like this. He writes: Since $\lim\limits_{h \to 0} \dfrac{\sqrt{|0+h|}-0}{h} = \lim\limits_{h \to 0} \dfrac{1}{|h|\operatorname{sgn}{(h)}}$ does not exist… My question is about this equality. The limit expressions are not equal, even close to $0$, for example at $h=\frac{1}{2}$. Is this a typo? Is this some property of limits I don't know about? My own calculations led me to the first limit  equalling $\frac{1}{\sqrt{|h|}}\text{sgn}{(h)}$ which also shows that the limit doesn't exist (right?). But it doesn't explain Adams' answer. And specifically, is there some situation where I can ""remove roots"" in this way? What if the limit did exist? Thank you in advance.","['calculus', 'limits']"
2377910,"If a series $\sum\lambda_n$ of positive terms is convergent, does the sequence $n\lambda_n$ converge to $0$? [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question Let $\lambda_n>0, n\in\mathbb{N}$ , with $\sum_n \lambda_n<+\infty$ . Can I conclude that $n\lambda_n\to 0$ ? In this question and this question and their answers, it is shown that this is true if $\lambda_n$ are decreasing. What happens if $\lambda_n$ are not decreasing?",['sequences-and-series']
2377949,Finding period of function from the functional relation $f(x+T) = 1 + \left(2f(x)-f(x)^2\right)^{\frac12}$,"I am supposed to find period of function following the below relation if exists, for domain belonging to all real numbers. $$f(x+T) = 1 + \left(2f(x)-f(x)^2\right)^{\frac12}$$ I just took $1$ to other side and squared and then differentiated to get $f(x+T) = f(-x)$ which indicates that period is $2T$ . Query: I don't think differentiation is a good way, because it is not mentioned that $f(x)$ is differentiable. Can someone please help in clarifying the underlying ideas or suggesting a altogether different approach.","['derivatives', 'periodic-functions', 'functions', 'functional-equations']"
2377962,Is my solution of a differential equation problem right?,"I tried to solve the following problem but I feel that I must work a little more specially for the second limit. Please let me know if I need to do more. Problem: Solve the following Cauchy problem.
$y'(x)=\frac{(y(x))^{2}}{1-(y(x))^{2}}\;\; and\;\; y(0)=1/2 .$ Compute the following limits $$\lim\limits_{x\to 1/2-}y(x)\;\; and\;\; \lim\limits_{x\to 1/2-}y'(x).$$ Here is my solution. At the first step, we have $$\frac{1-y^{2}}{y^{2}}dy=dx\;\Rightarrow\; 1/y+y=-x-c.$$ Since 
$y(0)=1/2\;$
so
$\;c=-5/2.$ Now, we put 
$x=1/2\;$ and $\;c=-5/2\;$
then we have 
$y=1$
by the 
$y+1/y=-1/2+5/2.$ Since 
$f(x,y)=\frac{1}{y}+y+x-\frac{5}{2}=0$
is continuous at every point except 
$y\neq 0.$
We have 
$\lim\limits_{x\to 1/2-}y(x)=1.$ Since we have 
$y'(x)=\frac{(y(x))^{2}}{1-(y(x))^{2}},$
therefore, 
$\lim\limits_{x\to 1/2-}y'(x)=\infty.$ Edit after comments: $$\frac{1}{y}+y+x-\frac{5}{2}=0 \Rightarrow y^{2}+(x-5/2)y+1=0 $$
$$\Rightarrow y=\dfrac{-(x-5/2)\pm\sqrt{(x-5/2)^{2}-4}}{2} $$
$$\Rightarrow \lim\limits_{x\to 1/2-}y(x)=1 $$
Also,
$$\Rightarrow \lim\limits_{x\to 1/2-}y'(x)=+\infty $$","['ordinary-differential-equations', 'calculus', 'limits']"
2377976,What is $S^2 \times S^2$?,"What does the product of these spaces mean? 
I really cannot understand or wrap my head around it.
What is it done for? If someone could help in visualizing it or provide intuition, it would be great.","['algebraic-topology', 'general-topology']"
2377978,"Convergence of series alternating at varying ""rates""","Motivation : We all know the alternating harmonic series $$\sum (-1)^{n+1} \frac 1n = 1 - \frac 12 + \frac 13  - \frac 14 \cdots$$ is convergent. This is a basic consequence of the alternating series test. Here, it's quite clear how the ""plus"" and ""minus"" signs are behaving. Each term, they switch. Half of the terms, loosely speaking, have $+1$, and the other half have $-1$. Well, then one may ask, what if we relax this condition, and allow the $-1$ and $+1$ factors to ""vary"" in the series in an arbitrary manner? Is convergence still a possibility? Definitions : Let $\alpha:\mathbb{N} \to S \subset \mathbb{R}$ be a real sequence. Define $\alpha^{-1}[x,n] \stackrel{\text{def}}{=} \{k : 1 \leq k \leq n \ \text{and}\ \alpha(k) = x\}$. In other words, $\alpha^{-1}[x,n]$ is the set of naturals at most $n$ which $\alpha$ maps to $x$. (Obviously, $x \in S$.) Define the density of $x$ in $\alpha$ as the quantity $$D(\alpha,x) \stackrel{\text{def}}{=} \lim_{n \to +\infty} \frac{|\alpha^{-1}[x,n]|}{n} $$ if the limit exists. Conjecture: For any $\epsilon \in [0, 1]$, there is always a mapping $s_{\epsilon}:\mathbb{N} \to \{-1,1\}$ such that $$\sum_{n \geq 1} \frac{s_{\epsilon}(n)}{n}$$ is convergent and $D(s_{\epsilon}, 1) = \epsilon$. Note that there is a sort of ""symmetry"" with the $+1$ and $-1$, which is why we can work with $D(s_{\epsilon}, 1)$ without loss of generality. Generalization: Consider the above conjecture with $\sum s_{\epsilon}(n)a_n$ where $\{a_n\}$ is such that $\sum a_n$ is conditionally convergent.","['real-analysis', 'sequences-and-series', 'convergence-divergence']"
2377980,Book recommendations for linear algebra [duplicate],"This question already has answers here : Where to start learning Linear Algebra? [closed] (16 answers) Closed 6 years ago . The community reviewed whether to reopen this question last year and left it closed: Original close reason(s) were not resolved I have been wanting to learn about linear algebra (specifically about vector spaces) for a long time, but I am not sure what book to buy, any suggestions?","['reference-request', 'abstract-algebra', 'book-recommendation', 'linear-algebra', 'vector-spaces']"
2377994,An interesting way of expressing any real number using the harmonic series.,"I recently saw the identity $$ \frac{1}{1} - {1 \over 2} +{1 \over 3} - {1 \over 4} + {1 \over 5} - {1 \over 6} \dotsb = \log(2) $$ 
which I found rather interesting. I was intrigued by the way a transcendental number like $\log(2)$ could be expressed by using the reciprocals of every integer once.
I then wondered what other real numbers could be represented this way, by using the infinite harmonic series, but changing the $+$ or $-$ signs before each fraction. I soon realized that every real number could be represented this way, although not necessarily with such a clear pattern to the signs. Since + and - are binary options, I realized that the pattern of $+$ or $-$'s in the series could be represented by using a binary decimal number between 0 and 0.11111... I called this number the ""harmonic sign number"" (or ""HSN"" for short). For instance, an example of a harmonic sign number for $\log(2)$ would be $0.\overline{10}$, because it alternates between $+$ and $-$, with the 1's representing a + and the 0's representing a -. However, $\log(2)$ is probably a special case, as it has a harmonic sign number that is rational. It seems like most numbers could only be represented by irrational harmonic sign numbers, however that is still up for debate. Another example of a rational HSN would be $0.\overline{1100}$, which is the HSN for ${\pi \over 4} + {\log(2) \over 2}$ Also, every real number has an infinite amount of HSN's, but every HSN corresponds to only one real number (or not, if it doesn't converge). Some questions that I have thought about: Which numbers have rational harmonic sign numbers? Can only trancendental numbers have rational HSN's? If not, is there a quick way to tell whether a number has a rational HSN? Are there any rational numbers that have rational or at least algebraic HSN's? Does there exist a number which is it's own HSN? Are there more than one? Infinite? Which HSN's actually converge? I would suggest that they would have to be normal. Please note, this is done purely out of interest, so only respond if you are actually interested!
If you would like clarification also please ask in comments and I will edit. 
Also, I'm not looking for full concrete answers. Feel free to answer with anything you have found or is of interest. It does not need to answer the questions posed above.","['real-numbers', 'rational-numbers', 'sequences-and-series']"
2378030,Is the Banach-Tarski paradox consistent with an invariant mass?,"As a physicist, I try to imagine  that the ""sleight of hand"" in the theorem is to split a ball with definable volume  into balls with no definable volume and then put them back into a thing with twice the volume. Somehow in the process the information about the original volume was ""lost"". I am not talking about entropy, just a layman's description. 1) Is this description accurate? 2) If this is accurate, can we still consistently define mass in a way that this mass is conserved during the process? (see below for what I mean by this) Let us imagine a classical Newtonian noiseless world in which bodies can be continuous. Assume there is a sphere that exists since the beginning of the universe. This sphere is charged with 5 different kinds of charges, and these charges are distributed in the same way as the points used in the theorem. Each of these porous subspheres also have mass. This gives us tools to split and reunite the spheres (let's say, by switching on a force in an outside shell that attracts or repulse the sphere rays radially). Is it mathematically consistent a world in which the Banach-Tarski theorem is true, but the mass is conserved?, so that when the spheres are split the mass also splits (and is well defined) and when the spheres are reunited in a different configuration this mass is still conserved (if we now have two spheres the density would be half of the original). That is, can I consistently define mass independently of volume, so that even if we do not have a volume we can still have a mass?","['physics', 'measure-theory', 'paradoxes']"
2378031,property of the measurable function from conditional expectation,"Let $(X,Y)$ be a pair of integrable random variables. We know for the conditional expectation $\mathbb E(X|Y)$, there is a measurable function $f$ such that $\mathbb E(X|Y)=f(Y)$. I would like to investigate property of the function $f$: namely, are there any generic condition on the distribution of $(X,Y)$ such that f is monotonically increasing? f is continuous, or even smooth (assuming the support of $Y$ is an interval for example)? f is linear?
etc... Necessary and sufficient conditions are certainly most desirable, but any idea and suggestion are greatly welcome! EDIT： One sufficient condition for $f$ to be increasing is that $supp(\pi)$ is a monotone set, where $\pi$ is the distribution of $(X,Y)$. That is, for any $x,y$ belonging to the support of $\pi$, $(x_1-y_1)(x_2-y_2)\geq 0$.
Apparently this is not a necessary condition which is not so satisfactory.","['probability-theory', 'conditional-expectation', 'probability', 'probability-distributions']"
2378038,$f(x)>0\implies\int_a^bf(x)\mathop{dx}>0$,"Suppose $f$ is Riemann-integrable on $[a,b]$ such that $f(x)>0, \forall x \in [a,b].$ Prove: $$\int_a^bf(x)\mathop{dx}>0$$ Provided solution: Suppose by contradiction that $I=\int_a^bf(x)\mathop{dx}=0.$ Let us take a sequence of normal partitions $T_n$ of $[a,b],$ that is partitons of $n$ intervals of length $\frac{b-a}{n}.$ Then for $n$ large enough, upper Darboux sum of $f$ is small as we wish. So there exists $n_0$ such that for all $n>n_0:$ $$\tag{1}\sum_{i=0}^{n-1}\sup_{[x_i,x_{i+1}]}f\cdot\Delta x_i=\frac{b-a}{n}\sum_{i=0}^{n-1}\sup_{[x_i,x_{i+1}]}f<\frac{b-a}{2}$$ Therefore, there exists an interval $I_1:=[x_i,x_{i+1}],$ such that: $$\tag{2}\sup_{[x_i,x_{i+1}]}f<\frac{1}{2}$$ By the integral monotonicity and positiveness of $f:$ $$\tag{3}0=\int_a^bf(x)\mathop{dx}\geq \int_{I_1}f(x)\mathop{dx} \geq 0$$ Hence, $\int_{I_1}f(x)\mathop{dx}=0.$ Repeating the process on $I_1,$ let us take a sequence of normal partitions of $[x_i,x_{i+1},$ that is intervals $[y_i,y_{i+1}]$ of length $\frac{x_{i+1}-x_i}{n}.$ Therefore, there exists $n_1$ such that for all $n>n_1:$ $$\tag{4}\sum_{i=0}^{n-1}\sup_{[y_i,y_{i+1}]}f\cdot\Delta x_i=\frac{x_{i+1}-x_i}{n}\sum_{i=0}^{n-1}\sup_{[y_i,y_{i+1}]}f<\frac{x_{i+1}-x_i}{4}$$ So there exists an interval $I_2:=[y_i,y_{i+1}] \subset I_1,$ such that: $$\tag{5} \sup_{I_2}f<\frac{1}{4}$$ Continuing like that, we get a sequence of intervals: $\ \dots \subseteq I_2 \subseteq I_1,$ such that: $$\tag{6} \sup_{I_n}f \leq \frac{1}{2^n}$$ By Cantor's intersection theorem: $$\tag{7} \bigcap_{n=0}^\infty I_n \neq \emptyset  $$ But, if $x \in \bigcap_{n=0}^\infty I_n,$ then $f(x) \leq \frac{1}{2^n},$ for all $n$ , hence $f(x)=0,$ contradicting $f(x)>0.$ My questions: $(a)$ At $(1),$ I know $\sum_{i=0}^{n-1} \Delta x_i = b-a,$ but why does it equal $\frac{b-a}{n}?$ And why is the inequality true? $(a)$ At $(3),$ how is the monotonicity is used? Any help is appreciated.","['riemann-sum', 'real-analysis', 'riemann-integration']"
2378122,"If $\mu$ is a probability measure on $\mathbb R$, is $t\mapsto\mu\{t\}$ differentiable almost everywhere?","In this question , the OP at one point says that since $t\mapsto P[X=t]$ is zero almost everywhere, it is almost everywhere differentiable. I pointed out that this need not be the case - $\mathbf1_{\mathbb Q}$ is the usual example of a function which is zero almost everywhere but continuous nowhere - but I realized the situation is a little more subtle in this case. If $\mu$ is a probability measure on $\mathbb R$, then for every $\varepsilon>0$, $\mu\{t\}\ge\varepsilon$ for at most finitely many $t$. In particular, $\lim_{s\to t}\mu\{s\}=0$ for all $t\in\mathbb R$, so $t\mapsto\mu\{t\}$ is continuous at every point of continuity of $\mu$. (Recall that point of continuity refers to the function $t\mapsto\mu((-\infty,t])$, so this statement isn't as meaningless as it appears.) Since there can be at most countably many atoms, this shows that at the very least we do have a.e. continuity. What about differentiability? This is a messier question. Obviously the function is not differentiable at any atom. If the derivative exists at $t_0$, then it must equal zero. We therefore have that differentiability at $t_0$ is equivalent to $$\mu\{t_0+h\}=o(h)\qquad\text{as }h\to0.\qquad\qquad(\dagger)$$ Does $(\dagger)$ occur for almost every $t_0$? I don't know. I also don't know how one would prove it if they did know, either.  I had an idea for a proof of the affirmative statement, trying to prove that the set of $t$ where $\mu\{t\}=0$ but $(\dagger)$ fails is at most countable, but it didn't pan out. A counterexample would surely be messy and hard to visualize - it would need to have a countable set of atoms whose closure had nonempty interior at a minimum. If the answer turns out to be negative, how badly behaved can the function be? Can the set $\{t:s\mapsto\mu\{s\}\text{ is differentiable at }t\}$ have zero measure?","['probability-theory', 'measure-theory']"
2378141,"A characterization of the ""Direct Integral"" construction in terms of the properties it satisfies?","Fortunately there's a wonderful thing called the ""direct integral"" which enables one to make sense of direct sums of uncountably infinite families of Hilbert spaces. Unfortunately I've tried to read about the constructions several times and while every time I walked away with a bit more confidence i'm still not sure how to spell out precisely what properties it satisfies - which is in practice much more important then the construction itself. Hence the question: Is there a ""unique"" characterization of the ""direct integral"" construction for hilbert spaces in terms of the list of the properties it satisfies? By ""unique"" I don't mean anything precise, I'm only looking for the most exhaustive list of properties of the construction such that it is more or less clear that the direct integral is not some aribtrary construction. I'm not asking for a precise categorical definition or anything like that (although if there is one i'd be happy to hear it). I'm just trying to understand the construction enough to be able to use confidently in places where it appears. In particular such a description should be easily adjusted to describe direct integrals of representations of groups/algebras etc...","['hilbert-spaces', 'functional-analysis', 'representation-theory', 'measure-theory', 'spectral-theory']"
2378164,$f : [m] \to [n]$ Prove $m=n$.,"Let $f$ be a bijection from $[m]$ to $[n]$. Prove that $m=n$. Induction: $n=0$ In this case $[n]= \emptyset$. A function from $A$ to $\emptyset$ is only defined if  $A = \emptyset$. Hence $m=0$. How do I show that $m=n$, do I have to show the inverse of $f$?","['algebra-precalculus', 'elementary-set-theory']"
2378165,Branch Cuts of $1/\sqrt{1-z^4}$,"I'm having a rather difficult time wrapping my head around branch points and branch cuts. Specifically I'm looking at $f : \mathbb C \to \mathbb C$ where $$ z \mapsto \frac{1}{\sqrt{1 - z^4}} $$ I know that $f$ can be rewritten as $$ f(z) = \left[ (z-i)(z+i)(1-z)(1+z) \right]^{-1/2} $$ so it has branch points at $z=\pm i, \pm 1$. Where do I draw branch cuts? If $z$ loops anti-clockwise around $0,2,\text{or }4$ branch points, then we're left with factors of $1,e^{2i\pi},e^{4i\pi}=1$, so we just need to prevent looping around $1$ or $3$ branch points. What cuts prevent this?","['complex-analysis', 'multivalued-functions', 'branch-points', 'branch-cuts']"
2378184,Question about $p$-limits on $\beta \omega$,"Let $p$ be a free ultrafilter on $\omega$, $X$ be a topological space and $s_n\,(n \in \omega)$ be a sequence. We say that $x \in X$ is a $p$-limit of a $s_n$ if, and only if for every neighborhood $V$ of $x$, $\{n \in \omega: s_n \in V\}\in p$. It's true that if $X$ is hausdorff, the $p$-limits are unique and that if $X$ is compact, they always exist. Question: Suppose that $X=\beta \omega=\beta \mathbb N$. Let $s_n, t_n\, (n \in \omega)$ be two sequences on $X$. Is it true that if $\{n \in \omega: s_n\neq t_n\} \in p$ then the $p$-limits of $s_n, t_n$ are distinct? I know that this is not true for $X$ in general, but I'm interested in the case $X=\beta \mathbb N$.",['general-topology']
