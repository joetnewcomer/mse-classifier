question_id,title,body,tags
4145817,Proof and Intuition of the Determinant Formula?,"[I did notice similar questions were asked here before, but I couldn't find a satisfactory answer for me to grasp as a beginner, so I chose to post this question] I'm just starting to teach myself linear algebra with Linear Algebra and Group Theory . The book starts with the concept of determinant with the definition of even & odd permutations by giving the example of a {3 by 3 array} with the following equation: $$\begin{vmatrix} a_{11}\ \ a_{12}\ \ ...\ \ a_{1k}\ \ ...\ \ a_{1n}\\a_{21}\ \ a_{22}\ \ ...\ \ a_{2k}\ \ ...\ \ a_{2n}\\...\ \ ...\ \ ...\ \ ...\ \ ...\ \ ...\\a_{n1}\ \ a_{n2}\ \ ...\ \ a_{nk}\ \ ...\ \ a_{nn}\end{vmatrix}=\displaystyle\sum_{(p_1, p_2, ..., p_n)}(-1)^{[p_1, p_2, ..., p_n]}a_{1p_1}a_{2p_2}...a_{np_n}$$ where $[p_1, p_2, ..., p_n] $ is the number of inversions of permutation $p_1, p_2, ..., p_n$ So because there is no justification given in the book for the above equation for { $n$ by $n$ array} and the concept of determinant feels a bit odd at the first place, I tried to investigate it myself: [Step 1]: I started with a {2 by 2 array} first, by taking a system of two equations in two unknowns: $$(eq1):\ a_{11}x_1+a_{12}x_2=b_1\\(eq2):\ a_{21}x_1+a_{22}x_2=b_2$$ $$A=\begin{Vmatrix} a_{11}\ \ a_{12}\\a_{21}\ \ a_{22}\end{Vmatrix}$$ with the determinant $detA$ [Step 2]: I then tried to eliminate { $x_2$ in $eq1$ } and { $x_1$ in $eq2$ } by doing the following: $$(eq1 \cdot a_{22})-(eq2 \cdot a_{12})=(a_{11}a_{22}-a_{12}a_{21})x_1\\(eq2 \cdot a_{11})-(eq1 \cdot a_{21})=(a_{11}a_{22}-a_{12}a_{21})x_2$$ [Step 3]: I noticed that the two coefficients above both give me the determinant of the array, so I then postulated the following statement: the determinant is {the coefficient of unknown $x_k$ in $k$ th row} after eliminating other unknowns from the $k$ th row by {multiplication} and {subtracting other rows} in the array. that is to say, if I have a $n$ th order array $$N=\begin{Vmatrix} a_{11}\ \ a_{12}\ \ ...\ \ a_{1k}\ \ ...\ \ a_{1n}\\a_{21}\ \ a_{22}\ \ ...\ \ a_{2k}\ \ ...\ \ a_{2n}\\...\ \ ...\ \ ...\ \ ...\ \ ...\ \ ...\\a_{n1}\ \ a_{n2}\ \ ...\ \ a_{nk}\ \ ...\ \ a_{nn}\end{Vmatrix}$$ I can eventually transfer $N$ into $$\begin{Vmatrix} detN & 0 & ... & 0 & ... & 0\\0 & detN & ... & 0 & ... & 0\\... & ... & ... & ... & ... & ...\\0 & 0 & ... & 0 & ... & detN\end{Vmatrix}$$ [Step 4]: I tested my statement with a {3 by 3 array} and it seems to work. And the idea of odd & even permutation seems to become more intuitive as it has to do with the order of subtracting depending on the row of the unknowns. So here comes my questions if my guess is right, how do I construct the permuatation formula at the beginning of the question for { $n$ by $n$ array} without defining determinant by using a set of formalistic operation at the first place ? I've seen multiple answers talking about the geometric intuition of determinant (and I roughly get the idea). How does the intuition of permutation connects, or transfers into the geometric intuition ? [Note: I have never studied abstract algebra, so answers without using notations in abstract algebra will be much appreciated :) ] ----------------------------------------------------------------------- EDIT: I think I figured out my question 2 (the geometric intuition).... correct me if I am wrong So again using a {2 by 2 array} as an example: [Step 1]: Assume again I have the following equations and array $$(eq1):\ a_{11}x_1+a_{12}x_2=b_1\\(eq2):\ a_{21}x_1+a_{22}x_2=b_2$$ $$A=\begin{vmatrix} a_{11}\ \ a_{12}\\a_{21}\ \ a_{22}\end{vmatrix}$$ with the determinant $detA$ [Step 2]: I can immediately transfer the array into $$\begin{Vmatrix} detA & 0\\0 & detA\end{Vmatrix}$$ [Step 3]: Becasue the above array is the coefficient of $x_1$ and $x_2$ , I can write the unknowns down as a vector $$\begin{bmatrix} x_1\\x_2\end{bmatrix}$$ which makes the { $detA$ array} a linear transformation when multiply with this vector","['determinant', 'linear-algebra', 'intuition']"
4145843,Tangent space of 3-sphere,"Consider the 3-sphere $S^3$ . If I look it as a embedded in $\mathbb{R}^4$ , then the tangent space in a point $x \in \mathbb{R}^4$ is isomorphic to $\mathbb{R}^3$ . But, if I consider $$S^3 = \{(z,w) \in \mathbb{C}^2| \ |z|^2 + |w|^2 = 1\},$$ given a point $a \in \mathbb{C}^2$ , how the tangent $T_a S^3$ looks like? I don't know if this question makes sense because $S^3$ is a real manifold. I saw questions related, but I didn't find the answer. Appreciate.","['spheres', 'complex-geometry', 'tangent-spaces', 'complex-numbers', 'differential-geometry']"
4145858,Bounding a complicated sequence,"I ecountered the following horrible sequence during an inductive proof of a bound for another sequence: $$
\sum\limits_{k = 0}^n {\frac{{(n + 3)^{1.47} }}{{(k + 1)^{1.47} (n - k + 1)^{1.47} }}} 
$$ for $n\geq 0$ . I would like to show that this sequence is bounded by $5.63$ . It seems to have a maximum at $n=3$ and that it is increasing for $n\geq 89$ . Using the symmetry about $n/2$ and Tannery's theorem, I was able to show that it converges to $2\zeta (1.47) = 5.475994 \ldots$ . Thus, the bound is true for $n$ large enough. It would be sufficient to show that the bound holds after some explicit value of $n$ and finish the proof by computing the first several terms numerically. Any comments and/or suggestions are welcome.","['inequality', 'sequences-and-series']"
4145874,How differential equations are just real?,"For sure this kind of stuff has a name, but I can't remember. So as to better understand what I mean, let's get concrete: Consider the linear ODE: $$y''+4\,y = 0$$ the characteristic polynomial has complex solutions: $$\lambda^2+4 = 0 \quad \Rightarrow\quad\lambda_{1/2} = \pm 2\,i$$ Now I just took it for granted that u can express such solutions as $$y = \mathrm{C_1}\,\cos(2\,x)+\mathrm{C_2}\,\sin(2\,x)$$ But if I were to plug the complex into the usual combination of exponentials: $$\mathrm{C_1}\,e^{+2\,i}+\mathrm{C_2}\,e^{-2\,i} = \\\\ \mathrm{C_1}\,\cos(2\,x)+\mathrm{C_2}\,\cos(-2\,x)+\mathrm{C_1}\,i\,\sin(2\,x)+\mathrm{C_2}\,i\,\sin(-2\,x)$$ that doesn't look to me as close as the solution. Furthermore to add even more confusion solving the ODE with MATLAB yields: $$y = \mathrm{C_1}+\mathrm{C_2}\,e^{-4\,x}$$ Apologies : this is the solution of $y''+4\,y'= 0$ As I mentioned I didn't really keep myself busy with the complex part of differential equation. I hope u might explain to me how all these solutions come together.","['complex-numbers', 'ordinary-differential-equations']"
4145882,Show that $C^\infty$ is dense in the space of weakly differentiable $L^p$-functions,"Let $\lambda$ denote the Lebesgue measure on $\mathcal B(\mathbb R)$ , $T>0$ , $I:=(0,T)$ , $X,Y$ be $\mathbb R$ -Banach spaces and $\iota$ be a continuous embedding of $X$ into $Y$ . If $p\in[1,\infty]$ , say $f\in\mathcal L^1(I,X)$ has a weak derivative in $L^p(I,Y)$ if there is a $g\in\mathcal L^p(I,Y)$ with $$\int_I\varphi'\iota f\:{\rm d}\lambda=-\int_I\varphi g\:{\rm d}\lambda\;\;\;\text{for all }\varphi\in C_c^\infty(I).$$ In that case, $f':=g$ . If $p,q\in[1,\infty]$ , let $E^{p,\:q}(I)$ denote the space of all $f\in\mathcal L^p(I,X)$ which admit a weak derivative in $L^q(I,Y)$ . Moreover, let $$\left\|f\right\|_{E^{p,\:q}}:=\left\|f\right\|_{L^p(I,\:X)}+\left\|f'\right\|_{L^p(I,\:Y)}\;\;\;\text{for }f\in E^{p,\:q}.$$ How can we show that if $p,q\in[1,\infty)$ , then $C^\infty(I,X)$ is a dense subset of $E^{p,\:q}$ ? There is a proof of this claim in Mathematical Tools for the Study of the Incompressible Navier-Stokes Equations and Related Models (Lemma II.5.10): The mentioned corollary is the (easy to verify) fact that $$\forall r\in[1,\infty):\forall g\in L^r(I,X):\left\|g\circ\tau_h-g\right\|_{L^r(I,\:X)}\xrightarrow{h\to\infty}0\tag2,$$ where $$\tau_h:\mathbb R\to\mathbb R\;,\;\;\;a\mapsto a+h$$ for $h\in\mathbb R$ . I don't understand the argumentation in the proof. How can we give a rigorous proof? And can we even find a suitable subspace "" $E_0^{p,\:q}(I)$ "" of $E^{p,\:q}$ s.t. $C_{\color{red}c}^\infty(I,X)$ is dense in $E_0^{p,\:q}(I)$ ? Let $f\in E^{p,\:q}(I)$ . We can clearly find $0\le\theta_i\in C_c^\infty(\mathbb R)$ (note that I'm not taking $\theta_i\in C^\infty(I)$ as in the book excerpt, since I think we need to $\theta_i$ to be defined on all of $\mathbb R$ in what follows, but please let me know in the comments if I'm missing something) with $\theta_1+\theta_2=1$ and $\operatorname{supp}\theta_1\subseteq\left[0,\frac23T\right]$ , $\operatorname{supp}\theta_2\subseteq\left[\frac13T,T\right]$ (although I'm not sure why exactly we need to consider these $\theta_i$ ). Now let $$g:=\begin{cases}\theta_1f&\text{on }I\\0&\text{on }\mathbb R\setminus I.\end{cases}$$ I'm not sure whether this will be important, but we should be able to show that $g\in E^{p,\:q}(\mathbb R)$ and $g'=\theta_1f'+\theta_1'\iota f$ . Now let $\eta$ be a ""mollifying kernel"", i.e. $\eta\in C_c^\infty(\mathbb R)$ with $\operatorname{supp}\eta\subseteq(-1,1)$ ; $\eta\ge0$ and $\int_{-\infty}^\infty\eta=1$ ; $\forall x,y\in\mathbb R:|x|=|y|\Rightarrow\eta(x)=\eta(y),$ and set $$\eta_\varepsilon(x):=\frac1\varepsilon\eta\left(\frac x\varepsilon\right)\;\;\;\text{for }x\in\mathbb R^d.$$ Note that $$g_h:=g\circ\tau_h\in L^p(\mathbb R)$$ and $$g_{h,\:\varepsilon}:=g_h\ast\eta_\varepsilon\in C^\infty(\mathbb R)$$ for all $h\in\mathbb R$ and $\varepsilon>0$ . Now, if I got the comment from daw in the comments below right, the idea is to show that $$\left\|g_{h,\:\varepsilon}-g\right\|_{E^{p,\:q}}\le\left\|g_h-g\right\|_{E^{p,\:q}}+\left\|g_{h,\:\varepsilon}-g_h\right\|_{E^{p,\:q}}\to0;\tag1$$ most probably as $h$ and $\varepsilon$ tend to $0$ (right?). However, the only things which are clear to me are $$\left\|g_h-g\right\|_{L^p(\mathbb R)}\xrightarrow{h\to0}0\tag2$$ and $$\forall h\in\mathbb R:\left\|g_{h,\:\varepsilon}-g_h\right\|_{L^p(\mathbb R)}\xrightarrow{\varepsilon\to0+}0\tag3.$$ And even if we can show $(1)$ , how does the claim for $f$ follow from that? From Jose27's comment below I suppose that there must be something crucial with the endpoints ...","['measure-theory', 'convolution', 'sobolev-spaces', 'functional-analysis', 'partial-differential-equations']"
4145902,Cartesian product of Vitali set and {0},"I am doing a measure theory problem which says: Let $V$ be the Vitali set in $\mathbb{R}$ . Deduce that $E=V \times \lbrace0\rbrace$ is Lebesgue measurable in $\mathbb{R}^2$ but it's not a Borel set. I think I did well the first part. Let $V$ be a Vitali set. We know that $V \subset [0,1]$ . Let $\varepsilon>0$ . We can take the rectangle $[0,1] \times (-\varepsilon,\varepsilon)$ , which contains $E=V \times \lbrace0\rbrace$ , and is measurable. Taking limit when $\varepsilon \rightarrow 0$ , we have a measure $0$ set. Since the Lebesgue measure is complete, every subset of a $0$ measure set has measure $0$ , so $E=V \times \lbrace0\rbrace$ is measuable. My problem is with the second part. I have an idea, but I don't know if it's correct or not: We know that the Vitali set is not Borel. We can see $E$ as the inverse image of the inclusion of $\mathbb{R}$ in the $X$ axis of $\mathbb{R}^2$ , which is a measurable function. So, I tried the typical proof by contradiction: Suppose $E=V \times \lbrace0\rbrace$ is Borel. Then, $g^{-1}(E)$ has to be borel. But that is $V$ ! So $E$ is not Borel. Is this ok? Thanks in advance","['borel-sets', 'measure-theory', 'lebesgue-measure']"
4145919,Hyperbolic Manifold Visualization,"I came across this interesting paper ""Low-Dimensional Hyperbolic Knowledge Graph Embeddings"" - Chami et al. . It is about embedding Graph Structures (more concretely: Knowledge Graphs) into Hyperbolic Space (Poincaré Ball model). In the Background section, the authors show the following figure of a hyperbolic manifold (Figure 2): The caption of the figure says: ""... to the hyperbolic manifold"". Hyperbolic space has a constant negative curvature. But for me, the manifold on this figure looks like it has positive curvature. I am confused and don't know if I misunderstood the key idea of Hyperbolic space and negative curvature OR if I interpret the figure wrong OR if it is actually not a hyperbolic manifold. I would really appreciate your help. Not understanding this figure drives me crazy. Thanks a lot!","['riemannian-geometry', 'visualization', 'geometry', 'hyperbolic-geometry', 'manifolds']"
4145934,Can any odd positive integer greater than $3$ be expressed as the sum of $2$ perfect square numbers (excluding $0$) plus $1$ prime number?,"I have been reading about the ""odd Goldbach conjecture"" which states that: Every odd integer greater than $7$ can be written as the sum of three odd primes I have also been reading about the fact that for large $𝑁$ there are considerably more primes than perfect squares  numbers. At first I have tried to run an experiment and see if any odd number can be written as the sum of one perfect square and one prime number, and although most attempts (in the beginning) were true, some others where false. So since the ""odd Goldbach conjecture"" involves three different numbers, I have allowed myself to check if any  odd number can be written as the sum of $2$ perfect squares and $1$ prime number. I have manually checked it for the first few hundreds' results, and so far I have found no counter example for any odd positive integers greater than $3$ A prime number (greater than $3$ ) can be written as $6n+1$ or $6n-1$ and a perfect square number can be written as $4n$ or $4n + 1$ . Also, even though perfect squares are more rare than prime numbers, unlike prime numbers, perfect squares have $1$ at their disposal ( $1^1 = 1$ ), and unfortunately for primes $1$ is not a prime number. So my question is: If there are any counter examples or any proofs? and if not what is the likelihood for this to be true? Edit per comment: I have not considered $0$ as a perfect square. Here are some examples of the early results: $5 = 1^2 + 1^2 + 3$ $7 = 2^2 + 1^2 + 2$ $9 = 1^2 + 1^2 + 7$ $11 = 2^2 + 2^2 + 3$ $13 = 2^2 + 2^2 + 5$ $15 = 2^2 + 2^2 + 7$ $17 = 1^2 + 3^2 + 7$ $19 = 2^2 + 2^2 + 11$ $21 = 2^2 + 2^2 + 13$ $23 = 3^2 + 3^2 + 5$ $29 = 3^2 + 3^2 + 11$ $31 = 5^2 + 2^2 + 2$ $33 = 3^2 + 1^2 + 23$ $35 = 3^2 + 3^2 + 17$ $37 = 3^2 + 3^2 + 19$ $39 = 5^2 + 1^2 + 13$ $41 = 1^2 + 3^2 + 31$ $43 = 4^2 + 2^2 + 23$ $45 = 6^2 + 2^2 + 5$ $47 = 6^2 + 2^2 + 7$ $49 = 1^2 + 5^2 + 23$ $51 = 6^2 + 2^2 + 11$ $53 = 6^2 + 2^2 + 13$ $55 = 3^2 + 3^2 + 37$ ,,,","['proof-explanation', 'goldbachs-conjecture', 'square-numbers', 'algebra-precalculus', 'prime-numbers']"
4145961,Inner product of p-forms,"This is a really basic question, but I cannot find a explicit answer on any book. Given a Riemannian manifold $(M,g)$ , the metric induces an inner product on vectors at any point, but it also induces an inner product on $p$ -forms for $1\leq p\leq \dim(M)$ . I am just looking for confirmation that for 0-forms it is given by the obvious one, i.e. for $f,g\in \Omega^0(M) = C^\infty(M)$ $$\langle f,g\rangle_{\Omega^0} = f \cdot g$$ and that I am not missing any factor (say volume - determinant of the metric).",['differential-geometry']
4145964,Why does a standard normal with $\frac{z^2}{2}=w$ equal $\Gamma(\frac{1}{2})$?,"In Berger, Casella (2002) I read that the standard normal pdf, given by $$ \int_0^\infty \exp\left(-\frac{z^2}{2}\right)\,dz$$ is equal to the gamma function $\Gamma(\alpha)$ evaluated in $\alpha=\frac{1}{2}$ when $w=\frac{1}{2}z^2$ , which results in: $$\Gamma\left(\frac{1}{2}\right) =\int^\infty_0w^{-\frac{1}{2}}e^{-w}dw=\sqrt{\pi}.$$ However, when I do my calculations and substitute $dz=\frac{dw}{\sqrt{2w}}$ I obtain a slightly different result, that is: $$2^{-\frac{1}{2}}\int^\infty_0w^{-\frac{1}{2}}e^{-w}dw.$$ Can somebody tell me what I missed?","['gamma-function', 'statistical-inference', 'statistics', 'normal-distribution']"
4145968,Why is Galois correspondence intuitively plausible?,"The Galois Correspondence Theorem (a.k.a. the Fundamental Theorem of Galois Theory) says that for any Galois extension of fields $K/F$ , there is a one-to-one inclusion reversing correspondence between the intermediate fields $K \supseteq E \supseteq F$ and subgroups of the Galois group $\text{Gal }K/F$ . I have two questions about this: Why this is theorem important? When I first learned it, I told myself that it was just a computational tool: it converts problems about fields, which are hard to understand, into problems about groups, which are easier to understand. But clearly, it is not just there for computational convenience, it is an important result in its own right. So I ask: is there a non-utilitarian reason why the theorem is profound? In other words, what deep ""underlying truth"" about the algebraic structure of fields does this theorem reveal? Why is this theorem intuitively plausible? The way I have understood it, if you place the subfield lattice of $K/F$ and the subgroup lattice of $\text{Gal }K/F$ side-by-side (with the latter flipped upside-down), then the diagrams are the same. This seems very out-of-blue to me. Why is it intuitively plausible that these two diagrams should look the same? Why should we expect that by studying the symmetries of a field extension, we can recover the structure of whole field itself? An explanation with a specific example of a field extension, would be great. Thanks for the help!","['field-theory', 'galois-theory', 'abstract-algebra']"
4145989,Variance of the Square,"Suppose $X_1, \cdots, X_n$ are a sample of independent variables taken from a normally distributed population with mean $\mu$ and variance $\sigma^2$ .
I would like to determine the variance of the squares $X_1^2, \cdots, X_n^2$ .
From a Monte Carlo simulation it seems that when $\mu$ is large enough, it is close to $\operatorname{Var}(X^2)= (2\mu\sigma)^2$ , but I have no proof, and I'm struggling to come up with one. I understand it has to do with the Chi-Square distribution, but I have not connected the dots.","['sums-of-squares', 'statistics', 'variance', 'normal-distribution']"
4145991,"How do I solve this integral $\displaystyle\int_{0}^{+\infty} \frac{x^{2} \sin x}{x^{4}+a^{4}} \,dx$?","To solve it, you need to factor the lower part and get squares instead of power $4$ . The problem is that the solution will be with imaginary numbers, since the denominator cannot be decomposed into factors other than through the roots of negative numbers. This results in the following: \begin{align}
\int\frac{x^2 \sin(x)}{x^4 + a^4}\,dx = {} & \frac1{4a} (-1)^{1/4} (-i \sin(a(-1)^{1/4}) \operatorname{Ci}(x - a (-1)^{1/4}) \\[4pt]
& {} - \sin(a (-1)^{3/4}) \operatorname{Ci}(x - a (-1)^{3/4}) \\[4pt]
& {} - \sin(a (-1)^{3/4}) \operatorname{Ci}(x + a (-1)^{3/4}) \\[4pt]
& {} - i \sin(a (-1)^{1/4}) \operatorname{Ci}(x + a (-1)^{1/4}) \\[4pt]
& {} + i \cos(a (-1)^{1/4}) \operatorname{Si}(a (-1)^{1/4} - x) \\[4pt]
& {} + \cos(a (-1)^{3/4}) \operatorname{Si}(a (-1)^{3/4} - x) \\[4pt]
& {} + i \cos(a (-1)^{1/4}) \operatorname{Si}(x + a (-1)^{1/4}) \\[4pt]
& {} + \cos(a (-1)^{3/4}) \operatorname{Si}(x + a (-1)^{3/4})) + \text{constant}
\end{align} $\mathrm{Ci}$ is the cosine integral, $\mathrm{Si}$ is the sine integral, $\mathrm{G}$ is the Meyer G-function.","['integration', 'complex-analysis', 'complex-integration', 'improper-integrals']"
4146015,Density of a set that is closed under halving and under Euclidean sum,"This is a problem that one of my neighbors (a sophomore Physics major) had in her last  Real Analysis test and was not able to solve. She posed it to me and I am also unable to bring and end to it. Suppose $E$ is a non-empty subset of $(0,\infty)$ and that For any $x\in E$ , $\frac{x}{2}\in E$ (i.e. $E$ is closed under halving) For any $x,y\in E$ , $\sqrt{x^2+y^2}\in E$ (i.e. $E$ is closed under Euclidean sum (sorry for the rather pedantic name, that is totally on me.) Problem: Show that that the $\overline{E}=[0,\infty)$ . So far, we can establish the following basic facts: (a) $E$ has arbitrarily small elements ( $x\in E$ implies that $2^{-n}x\in E$ ) (b) For any $x\in E$ and $n\in\mathbb{N}$ , $x\sqrt{n}\in E$ (by induction $x\sqrt{2}=\sqrt{x^2+x^2}\in E$ . Once, we have $x\sqrt{n}\in E$ , then $x\sqrt{n+1}=\sqrt{(\sqrt{n}x)^2+x^2}\in E$ . After this, I can't see how to kill the problem. hopefully other undergraduate students out there (others are of course welcome) may have some hints or a solution to this puppy.","['general-topology', 'real-analysis']"
4146026,Determine $\cos(\alpha+\theta)$ given $\sin \theta=3/5$ and $\cos \alpha=12/13$,"I'm having some trouble with this question. I don't really understand what it is asking. $\theta$ and $\alpha$ are acute angles in standard position. $\sin\theta=\frac{3}{5}$ and $\cos\alpha=\frac{12}{13}$ What is the exact value of $\cos(\alpha+\theta)$ ? I've tried to find a trig identity that will allow us to solve this and haven't had any success.
All Help is appreciated! :) I'm somewhat familiar with the cosine addition formula. So far, I have $\cos(\alpha+\theta) = \cos(\frac{12}{13})\cdot\cos(y)-\sin(\frac{3}{5})\cdot\sin(y)$ I now have $\cos^2\theta+\sin^2\theta=1$ $\cos^2\theta=1-\frac{9}{25}$ $\sqrt{\cos^2\theta}=\sqrt{\frac{16}{25}}$ $\cos\theta=\frac{4}{5}$ Edit:
Thanks to everyone who helped out!
Here is the answer I came up with: (cont. from above) $\sin^2\theta=1-\cos^2\theta\\\sin^2\theta=1-\frac{144}{169}\\\sqrt{sin^2\theta}=\sqrt{\frac{25}{169}}\\\sin\theta=\frac{5}{13}\\\cos(\alpha+\theta)=(\frac{12}{13})(\frac{4}{5})-(\frac{5}{13})(\frac{3}{5})\\\therefore\cos(\alpha+\theta)=\frac{33}{65}$",['trigonometry']
4146098,Why the Euler characteristics of a compact connected lagrangian submanifold of $\mathbb{R}^4$ is zero?,"Let's consider space $\mathbb{R}^4$ with the standard symplectic structure and let $L\subseteq \mathbb{R}^4$ be a compact connected embedded submanifold. There is a fact that if $L$ is lagrangian submanifold, then it is a torus, or, equivalently in this case, $\chi(L)=0$ . I saw this fact in many books and articles, but all proofs I could find are either not very detailed or too difficult for me. More precisely, I am interested in these facts: why, if $L$ is otientable, then $\chi(L)=0$ ; why, if $L$ is not orientable, then $\chi(L)\equiv 0 (\text{mod 2})$ . Both facts as I understood are easy, but in all proofs I saw there are some moments I do not understand. I will give some information about my knowledge and problems that I have reading proofs of this fact. I know about Weinstein's neighborhood theorem. I understood that I have to use that some neighborhood of $L$ is symplectomorphic to some neighborhood of zero-section in cotangent bundle $T^* L$ . Also, many proofs use isomorphism $TL≅T^* L≅NL$ . I understand that these isomorphisms exist but do not know why it is useful here. Then, I know about Euler characteristics as a number of zeros (with signes or modulo two) of a generic vector field on a manifold. Also, I am a bit familiar with the intersection index of two submanifolds, so as I understand Euler characteristics of submanifold is the intersection index of the zero-section in its tangent bundle with itself. It seems to me that I have all instruments to proof these facts but concrete steps I do not see. Could you help me please?","['differential-topology', 'symplectic-geometry', 'differential-geometry']"
4146139,Why does not differentiability at a point imply the existence of limit of derivative tending to the point,"What is wrong with the following argument? Let $f$ be a real continuous function which is differentiable at every point $x\not=a$ . By mean value theorem, $$ \frac{f(a+h)-f(a)}{h} = f'(\xi) \qquad (h\not=0)$$ where $\xi$ is between $a$ and $a+h$ . Letting $h\rightarrow0$ , we obtain $$ f'(a) = \lim\limits_{\xi\rightarrow a}f'(\xi) \mbox{.} $$ Therefore, f'(a) exists if and only if $\lim\limits_{\xi\rightarrow a}f'(\xi)$ exists. That the only if statement is false can be seen from $f(x)=x^2\sin\frac{1}{x}$ for $x\not=0$ , $f(0)=0$ , which shows that $f'(0)$ exists but $\lim\limits_{x\rightarrow0}f'(x)$ does not. Why?","['calculus', 'derivatives', 'real-analysis']"
4146148,Geometric proof or interpretation of the triple tangent and cotangent identities,"The not-so-well-known triple tangent and triple cotangent identities , If $x + y + z = \pi$ then $\tan x + \tan y + \tan z = \tan x\tan y\tan z 
 \;\;\; (x,y,z \neq \pi/2+\pi n)$ . If $x + y + z = \frac\pi 2$ then $\cot x + \cot y + \cot z = \cot x \cot y \cot z \;\;\; (x,y,z \neq \pi n)$ . are usually proved analytically. Are there geometric proofs of these identities? Or at least geometric interpretations that might provide some intuition for why they are true?","['alternative-proof', 'trigonometry', 'geometry', 'plane-geometry']"
4146164,Ordinary Least Squares Estimate,"In this paper ( https://www.stat.berkeley.edu/~brill/Papers/lehmannfest.pdf ), the author claims that (and more generally elsewhere I have seen that it is usually written as that) the Ordinary Least Squares estimate for the classical problem $y_i = \beta_0 + \beta_1^T x_i$ plus some noise (where $\beta_1, x_i$ are $p$ -dimensional vectors) satisfies: $$\hat{\beta_1} = \left( \sum_{i=1}^n (x_i - \bar{x}) (x_i - \bar{x})^T \right)^{-1} \left( \sum_{i=1}^n y_i (x_i - \bar{x}) \right) $$ Nevertheless, what I know ""in the modern days"" as the classical ordinary least squares estimate is the following quantity, see e.g. https://en.wikipedia.org/wiki/Linear_least_squares : $$\hat{\beta} = \left( \sum_{i=1}^n x_i x_i^T \right)^{-1} \left( \sum_{i=1}^n y_i x_i \right) $$ However, preliminary calculations of mine do not indicate that the two above quantities are equal, as they should be for the paper to hold. Does anyone have any idea why they are equal, if they are? Maybe it has to somehow do with the conditions of the least squares estimate? What am I missing?","['regression', 'statistics', 'linear-algebra', 'linear-regression']"
4146259,"How can I ensure the existence of this right-handed limit of the form $\lim_{\phi\to0^+}\{\frac1{\phi}\frac{\partial{F(\phi,\psi)}}{\partial\phi}\}$?","I'm working on a class of  models defined by a certain function $F(\phi,\psi)$ (there is a lot of freedom in this choice). Here, $\phi$ and $\psi$ are in fact real functions, which I know are non-negative, have at least two derivatives, and are bounded. For simplicity, let's say both have a maximum at one, so that $\phi, \psi\in[0,1]$ . However, I can't constrain the behavior of $\phi$ and $\psi$ , so I'd rather think of F as as function $F:[0,1]\times[0,1]\to\mathbb{R}^{+}$ for the purposes of this question. I have assumed that $F$ is bounded and twice differentiable (although I think I must use semi-derivatives at the boundary to make this rigorous, since the interval is closed). At one point in my calculations, the fraction $\frac{1}{\phi}\frac{\partial{F(\phi,\psi)}}{\partial\phi}$ appears. The problem is I that know $\phi$ and $\psi$ have a zero, so I'd like to ensure, under as few assumptions as possible, that this won't diverge when $\phi$ approaches zero from the right. In other words want to know what assumptions I must make about $F$ in order to ensure that the right-handed limit $$\lim_{\phi\to 0+}\left\{\frac{1}{\phi}\frac{\partial{F(\phi,\psi)}}{\partial\phi}\right\} $$ exists for every $\psi$ (it doesn't have to be the same number for every $\psi$ , I just don't want it to blow up). Now, I'm not very familiar with multi-variable analysis, semi-derivatives etc, so I'm not sure on how to proceed. I thought about assuming the second derivatives $\frac{\partial{^2F(\phi,\psi)}}{\partial\phi^2}$ and $\frac{\partial{^2F(\phi,\psi)}}{\partial\phi\partial\chi}$ are bounded (which would make physical sense in this case) to get a Lipschitz condition on the and partial derivatives. Then I could impose $\lim_{\phi\to 0^+}\frac{\partial{F(\phi,\psi)}}{\partial\phi}=0$ or something similar to make the derivative bounded. But I don't know if there is a version of this argument that makes sense when $\phi=0$ , since the usual derivative is not defined there. So, could someone help me find some simple (as in not too restrictive) conditions that would make this limit well defined?","['partial-derivative', 'limits', 'multivariable-calculus', 'lipschitz-functions']"
4146307,Proof of $\int_{0}^{\infty}\sin(x^2)dx=\int_{0}^{\infty}\cos(x^2)dx=\frac{\sqrt{2\pi}}{4}$,"If I want to prove that \begin{equation*}
\int_{0}^{\infty}\sin(x^2)dx=\int_{0}^{\infty}\cos(x^2)dx=\frac{\sqrt{2\pi}}{4}
\end{equation*} First method: It is possible to approach it by the method in which we consider a closed curve, then:
Let gamma be one eighth of a circle ( $\theta\in[0,\pi/4]$ ), then \begin{eqnarray*}
            0 = \int_{\gamma} e^{iz^{2}} dz 
            & = &   \int_{\gamma_{1}} e^{iz^{2}} dz + 
                    \int_{\gamma_{2}} e^{iz^{2}} dz + 
                    \int_{\gamma_{3}} e^{iz^{2}} dz \\
            & = &   \int_{0}^{R} e^{iz^{2}(r)} dz(r) + 
                    \int_{0}^{\pi/4} e^{iz^{2}(\theta)} dz(\theta) + 
                    \int_{R}^{0} e^{iz^{2}(r)} dz(r) \\
            & = &   \int_{0}^{R} \cos(x^{2}) + i\sin(x^{2}) dx + 
                    \int_{0}^{\pi/4} e^{iz^{2}(\theta)} dz(\theta) + 
                    \int_{R}^{0} e^{iz^{2}(r)} dz(r) \\
        \end{eqnarray*} Then \begin{equation*}
            -\int_{0}^{R} \cos(x^{2}) + i\sin(x^{2}) dx = \int_{0}^{\pi/4} e^{iz^{2}(\theta)} dz(\theta) + \int_{R}^{0} e^{iz^{2}(r)} dz(r)
        \end{equation*} where \begin{eqnarray*}
            \int_{R}^{0}\exp\left(iz^{2}(r)\right)dz(r) 
            & = & \int_{R}^{0}\exp\left(i(re^{i\pi/4})^{2}\right)e^{i\pi/4}dr \\
            & = & \int_{R}^{0}\exp\left(ir^{2}e^{i\pi/2}\right) \cdot e^{i\pi/4}dr \\
            & = & -e^{i\pi/4} \int_{0}^{R}\exp\left(ir^{2}e^{i\pi/2}\right)dr \\
            & = & -e^{i\pi/4} \int_{0}^{R}\exp\left(ir^{2}[\cos(\pi/2)+i\sin(\pi/2)]\right)dr \\
            & = & -e^{i\pi/4} \int_{0}^{R}\exp\left(-r^{2}\right)dr \\
        \end{eqnarray*} and we know that \begin{eqnarray*}
            \lim_{R\to\infty} \int_{0}^{R}\exp\left(-r^{2}\right)dr = \frac{\sqrt{\pi}}{2}
        \end{eqnarray*} Then \begin{equation*}
            \begin{split}
                &
                \lim_{R\to\infty}\int_{R}^{0}\exp\left(iz^{2}\right)dz  = -\left( \frac{\sqrt{2}}{2} + i\frac{\sqrt{2}}{2} \right) \frac{\sqrt{\pi}}{2}\\
                \Rightarrow
                &
                \lim_{R\to\infty}\int_{R}^{0}\exp\left(iz^{2}\right)dz = -\frac{\sqrt{2\pi}}{4}-i\frac{\sqrt{2\pi}}{4}
            \end{split}
        \end{equation*} And I wish that $\left|\int_{\gamma_{2}} e^{iz^{2}}dz\right|=|\int_{0}^{\pi/4} e^{iz^{2}(\theta)} dz(\theta)|\to 0$ when $R\to\infty$ . How can I argue this in detail? since using this I would have to \begin{equation*}
            \lim_{R\to\infty}\int_{0}^{R} \cos(x^{2}) + i\sin(x^{2}) dx = \frac{\sqrt{2\pi}}{4} + i\frac{\sqrt{2\pi}}{4}
        \end{equation*} then \begin{equation*}
        \int_{0}^{\infty}\sin(x^{2})dx = \int_{0}^{\infty}\cos(x^{2})dx = \frac{\sqrt{2\pi}}{4}
    \end{equation*} that concludes the desired. Second method: On the other hand, Also study the possibility of doing this problem using power series. We know that \begin{equation*}
 \sin(z) = \sum_{i=0}^{\infty}\frac{(-1)^{n}z^{2n+1}}{(2n+1)!}
 \Rightarrow \sin(z^{2}) = \sum_{i=0}^{\infty}\frac{(-1)^{n}(z^{2})^{2n+1}}{(2n+1)!}
\end{equation*} Then \begin{eqnarray*}
        \int_{0}^{r}\sin(x^{2})dx 
        & = &    \int_{0}^{r} \sum_{n=0}^{\infty}\frac{(-1)^{n}(x^{2})^{2n+1}}{(2n+1)!} dx\\
        & = &    \int_{0}^{r} \sum_{n=0}^{\infty}\frac{(-1)^{n}x^{4n+2}}{(2n+1)!} dx\\
        & = &    \sum_{n=0}^{\infty}\frac{(-1)^{n}}{(2n+1)!}\int_{0}^{r} x^{4n+2} dx\\
        & = &    \sum_{n=0}^{\infty}\frac{(-1)^{n}}{(2n+1)!}\left. \cdot\frac{x^{4n+3}}{4n+3} \right|_{0}^{r}\\
        & = &    \sum_{n=0}^{\infty}\frac{(-1)^{n}}{(2n+1)!} \cdot \frac{r^{4n+3}}{4n+3} \\
    \end{eqnarray*} But I do not know how to reduce or work with this expression, if someone could help me I would be very grateful. PD: If there is another method, perhaps by Fourier analysis it is also welcome, although my main interest is to exercise with the theory of the complex variable.","['complex-analysis', 'fourier-analysis', 'fresnel-integrals']"
4146444,Non-Hilbert Banach space isomorphic to $\ell_2$,"I know that $\ell_2$ is the only separable Hilbert space of infinite dimension up to isometric isomorphism, so in particular, any separable Hilbert space of infinite dimension is isomorphic to $\ell_2$ . So my question is, can someone give an example of a Banach space isomorphic to $\ell_2$ but not isometrically isomorphic to it? I know, for what is said above, that this space cannot be a Hilbert space but I can't think of any example.","['hilbert-spaces', 'banach-spaces', 'functional-analysis']"
4146457,Being trivial bundles can be checked on linear equivalent divisors?,"Let $X$ be a nice (for example, smooth and projective) variety, and let $D_1 \sim D_2$ be two linearly equivalent (smooth and effective) divisors. I would like to know if the following is true: Let $\mathcal L$ be a line bundle on $X$ . Then, $\mathcal L|_{D_1}\simeq \mathcal O_{D_1}$ if and only if $\mathcal L|_{D_2}\simeq \mathcal O_{D_2}$ . If $D_i$ is very ample, this will be true at least for ${\rm dim}(X)$ large, as $\mathcal L$ has to be trivial. If $\mathcal L= \mathcal O(D)$ with $D$ effective, this is also trivially to be true. However, I don't know how to approach this for more general cases. Moreover, if this is true, I also would like to know if this holds for vector bundles as well, i.e. Let $\mathcal E$ be a vector bundle on $X$ . Then, $\mathcal E|_{D_1}\simeq \mathcal O_{D_1}^{\oplus n}$ if and only if $\mathcal E|_{D_2}\simeq \mathcal O_{D_2}^{\oplus n}$ . Thanks in advance! Edit: Now I tend to believe this is false (even for line bundles), and it would be helpful to know a counterexample.","['complex-geometry', 'divisors-algebraic-geometry', 'algebraic-geometry', 'examples-counterexamples']"
4146467,"Prove that $x^2|\sin(\frac1x)|$ is absolutely continuous on $[0,1]$","Could you help me prove that $f = x^2|\sin(\frac1x)|$ is absolutely continuous on $[0,1]$ ? I tried to prove this with this:
f has a derivative f′ almost everywhere, the derivative is Lebesgue integrable, and $f(x)=f(a)+\int _{a}^{x}f'(t)\,dt$ for all x on [a,b].
The derivative of the function is: $2x \mid (\sin(1/x)) \mid - \sin(\frac2x)/(2 \mid \sin\frac1x\mid )$ . But I am not sure how to proceed, since there are many pointswhere $f$ is not differentiable. Thank you in advance!","['integration', 'analysis', 'real-analysis', 'absolute-continuity', 'derivatives']"
4146523,On Bayesian credible intervals,"Question Let $X \mid \mu \sim \mathrm{Poisson} (\mu)$ and $\mu \sim \mathrm{Gamma} (1, 1)$ and suppose that a very large number $x$ is observed. Find, in terms of $x$ , an approximate $95\%$ Bayesian credible interval for $\mu$ . (Hint: $\mathrm{Gamma} (n, 1)$ is the distribution of the sum of $n$ independent $\mathrm{Exponential} (1)$ random variables). My thoughts The comments have pointed out some of my errors previously and following their suggestions, I have re-worked this. I have found that $\mu \mid X \sim \mathrm{Gamma} (X + 1, \frac 1 2)$ using shape and scale parameters and since $x$ is large, the Central Limit Theorem can be applied, but I am unsure if the following is correct - does this mean $\frac 1 2 \mu \mid x \sim \mathcal{N} (x + 1, x + 1)$ approximately and since approximately $95\%$ of all normal data falls within $2$ standard deviations of the mean, then an approximate $95\%$ credible interval for $\mu$ is $[2(x + 1 - 2\sqrt{x + 1}), 2(x + 1 + 2\sqrt{x + 1})]$ ? P.S. We have just covered Bayesian statistics and this is my first ever encounter of a problem asking for a credible interval, so any intuitive explanations will be greatly provided!","['statistics', 'probability-distributions', 'bayesian', 'exponential-distribution', 'gamma-distribution']"
4146556,"Questions in the Proof of Lusin's Theorem (Rudin's RCA, Theorem $2.24$)","For context, it is assumed that $\mu$ is a measure on a locally compact Hausdorff space $X$ which has all properties that follow from Riesz Representation Theorem (regularity, etc.) in the book (if I'm not wrong, this means $\mu$ is a Radon measure). The author begins by assuming $0 \le f < 1$ and concludes the first part of the proof by noting $0\le f \le 1$ ? Though both seem to work, for the sake of consistency one of the two must be a typographical error - and I believe it's the first one. Could you confirm? Why is $2^{-n}h_n(x) = t_n$ except in $V_n - K_n$ ? I know that $h_n(x) = 1$ for all $x\in K_n$ and $h_n(x) = 0$ for all $x\notin V_n$ . Also, $0\le h(x) \le 1$ for $x\in V_n-K_n$ . How is the assumption of compactness dropped? If $\mu(A) < \infty$ then for every $\epsilon_0 > 0$ there is compact $K\subset A$ such that $\mu(A-K) < \epsilon_0$ . I'm thinking about $\tilde f = \chi_K f$ , and since $K$ is compact, it is clear that we can find a continuous real-valued function $g$ such that $\mu(\{x: g(x) \ne \tilde f(x)\} < \epsilon_0$ , for every $\epsilon_0 > 0$ . How do I use this to approximate $f$ by $g$ in the sense of Lusin's theorem? Next they consider $f$ to be complex measurable, $B_n = \{x: |f(x)| > n\}$ and claim $\bigcap_{n=1}^\infty B_n = \varnothing$ . To see this, assume $x\in \bigcap_{n=1}^\infty B_n$ , thus $x \in B_n$ for all $n$ , i.e. $|f(x)| > n$ for all $n$ . Taking limits as $n\to\infty$ , $|f(x)| \ge \infty$ , that is $|f(x)| = \infty$ . This is not possible, since $\infty$ is not in $\mathbb R$ . Seems fine? Thus, $\mu(B_n)\to 0$ as $n\to\infty$ . $f$ coincides with $\tilde f_n = (1 - \chi_{B_n}) f$ , which is bounded. So we can find a continuous $g$ such that $\mu(\{x: g(x) \ne \tilde f_n(x)\}) <\epsilon/2$ . Since $\tilde f_n$ and $f$ agree except on a set whose measure approaches zero as $n\to\infty$ , it is clear that we can find $n$ large enough so that $\mu(\{x: \tilde f_n(x) \ne f(x)\}) <\epsilon/2$ . What can I say about $\mu(\{x: f(x) \ne g(x)\})$ ? I can see that $g_1 = \varphi\circ g$ satisfies $(2)$ , but how do I show that it satisfies $(1)$ , given that $g$ satisfies $(1)$ ? Proof attached for reference: Apologies in advance for posting pictures of the proof (it is huge to type, and the pictures are only for reference). I have written all else in MathJax. Thank you!","['proof-explanation', 'measure-theory', 'real-analysis']"
4146577,How do I evaluate $\int_{-\infty}^\infty \frac{x\cos{(-\frac{\pi}{2}x)}}{x^2-2x+5} \mathrm{d}x$ using complex analysis?,"I am having trouble evaluating the following improper integral $$\int_{-\infty}^\infty \frac{x\cos{(-\frac{\pi}{2}x)}}{x^2-2x+5} \mathrm{d}x$$ It is for an upcoming exam in complex analysis, and I could really use a hint. I think i need to evaluate it using the residue of the integrand, but I have not had any luck. Any suggestions/comments are welcome.","['integration', 'complex-analysis', 'trigonometry', 'improper-integrals']"
4146619,What is the best way to make notation in multi-variable calculus rigorous?,"(Warning: long post worrying about formalism, may seem totally pointless to many.) Related to ""Can the idea of a 'function of a variable' be made rigorous?"" . There is a disconnect in how mathematics is usually formalized and how mathematicians tend to write about derivatives. For example, it's not uncommon to see notation like: \begin{alignat}{1}    v &= a^2b + 3ab
\\[5pt] \frac{\partial v}{\partial a} &= 2ab + 3b
\\[5pt] \frac{\partial v}{\partial b} &= a^2 + 3a
\\[5pt] a &= x^2 + y^2
\\[5pt] b &= xy
\\[5pt] \frac{\partial v}{\partial x} &= \frac{\partial v}{\partial a}\frac{\partial a}{\partial x} + \frac{\partial v}{\partial b}\frac{\partial b}{\partial x}
  \end{alignat} This notation assumes that A function 'knows' its variables, so that $\frac{\partial v}{\partial a}$ and $\frac{\partial v}{\partial b}$ are both well-defined and different Different Variables refer to different objects, so that $v(a,b)$ and $v(x,y)$ are both well-defined and different The same object can be both a function and a parameter, i.e., $a$ appears in the formulas $v=a^2b + 3ab$ and $a=x^2+y^2$ However, in the classical formalism, a function $f : \mathbb{R} \rightarrow \mathbb{R}$ , say the one that doubles all inputs, is just a set of tuples $\{(1,2), (2,4), (3,6), ...\}$ . (Alternatively, it may be a triple (domain, codomain, set-of-tuples), but this difference doesn't matter for this post.) This formalism doesn't support any of the above things: If $v = \{((1,1),4), ...\}$ , then $a$ and $b$ aren't objects of any kind. The function $v$ may be defineed using notation where 'a' an 'b' appear as bound variables, such as $v = \{((a,b),a^2b + 3ab) \;|\; (a,b) \in \mathbb R^2\}$ , but they're only bound within the expression that defines the set $v$ . This makes it ""impossible"" for $a = x^2 + y^2$ to refer to the $a$ that was used in $v = a^2b + 3ab$ . For the same reason, $v(a,b)$ and $v(x,y)$ cannot refer to different objects. If a function's domain consists of real numbers, it doesn't consist of functions, so if $a$ and $b$ are functions, one can never evaluate $v(a,b)$ . I see three ways to deal with this disconnect Ignore it and continue to do calculations that lead to correct results. That is, until one gets confused about things like 'wait $\frac{\partial v}{\partial a}$ is a function from what to what?'. In such a case, always stare at the expression long enough to figure it out. Proceed to pretend that there is no problem. Alternatively, never get confused, somehow (do people really do this?) Try to interpret all notation as shorthands that talk about sets Think of the notation as being grounded in a different formalism I've been doing #1.1 ever since learning about set theory, but I'm no longer satisfied with that. The problem with #2 is that it doesn't seem to correspond to how people think about what they're doing. Consider the fact that serious mathematicians write things like $v = v(a,b)$ or "" $f$ is a function of $x$ , and $g$ is a function of $y$ "". These statements have no meaning in terms of the underlying formalism (except to state that the domain of $f$ is one-dimensional): if one writes $f(x) = x^2$ , then $f$ is a well-defined set, but $x$ is nothing whatsover (except a bound variable in a formula that defines the set $f$ ). This would make the statement "" $f$ is a function of $x$ "" merely a hint for how to interpret future notation, similar to a statement like ""we write $p(x)$ for $p(\{x\})$ "". Again, this does not seem to correspond to how people are thinking about the material. #3 is something I'm very interested in but don't know much about. My question: is there a satisfying solution for #2 or #3? Could $\lambda$ -calculus be a candidate?","['notation', 'multivariable-calculus', 'functions']"
4146697,How to determine if a function is bounded?,"I'm in college calc class, so please keep explanations simple. Let $g(t)=\sqrt{1-\frac{1}{t+1}}$ . I've established its domain to be $(-\infty,-1) \cup [0,\infty)$ . I'm not sure how to go about determining boundedness, please provide feedback on my method below. My understanding is that a function is unbounded if it can output arbitrarily large positive or negative values. My strategy has been to look at what happens to the function when x is close to the edges of the domain. For example if $x=-1.01$ then $\frac{1}{t+1}$ becomes a ""large negative value"" -10 and thus the whole function becomes $\sqrt{1-{LargeNegativeNumber}}$ and thus on the whole we get $\sqrt{LargePositiveNumber}$ which is unbounded upwards (in the positive y direction). If we look at another edge of the domain, $ -\infty $ , we see that $\frac{1}{-\infty+1}$ becomes a small negative value. Thus the whole function becomes $\sqrt{1-{SmallNegativeNumber}}$ thus it approaches $1$ from above. (This dcheck doesn't alter our understanding of whether g is bounded or not, right?) Ok let's go on to looking at values close to 0, say $x = 0.01$ . In that case $\frac{1}{0.01+1}$ becomes a ""large negative value"" and the whole function becomes $\sqrt{1-{LargeNegativeNumber}}$ and thus $\sqrt{LargePositiveNumber}$ . Ok this confirms our understanding that g is unbounded upwards in the positive y direction. Ok then I look at what ahppens to the function when $x = \infty$ . We see that $\frac{1}{\infty+1}$ becomes a ""small positive number"" and thus the whole function becomes $\sqrt{1-{SmallPositiveNumber}}$ and thus 1 approached from below. My conclusion is that the function is unbounded upwards, but the answer says it's just ""not bound"" which I assume means unbounded upwards and downwards, but I've failed to show unboundedness downwards! What did I do erroneously?","['calculus', 'functions', 'real-analysis']"
4146720,Twisted Crossed Product von Neumann Algebra,"Let $M$ be a (tracial) von Neumann algebra acting on a Hilbert space $\mathcal{H}$ . A cocycle action of a discrete group $G$ on $M$ is a pair $(\sigma, v)$ with $\sigma : G \to Aut(N)$ and $v : G \times G \to \mathcal{U}(M)$ satisfying the following three conditions for all $k,l,m \in G$ : (1) $\sigma_{k} \sigma_{l} = ad(v(k,l))\sigma_{kl}$ (2) $v(k,l)v(kl,m) = \sigma_{k}(v(l,m)) v(k,lm)$ (3) $v(1,l) = v(l,1) = 1$ The twisted crossed product of $M$ by $G$ , denoted by $M \rtimes_{(\sigma,v)} G$ , is defined as the von Neumann algebra acting on $\ell^2(G,\mathcal{G})$ generated by $\pi_{\sigma}(M)$ and $\lambda_{v}(G)$ , where $\pi_{\sigma}$ is the faithful normal representation of $M$ on $\ell^2(G,\mathcal{H})$ defined via $$(\pi_{\sigma}(x) \xi)(l) = \sigma_{l^{-1}}(x) \xi (l)$$ and, for each $g \in G$ , $\lambda_{v}(g)$ is the unitary operator defined by $$(\lambda_{v}(k)(\xi))(l) = v(l^{-1},k) \xi (k^{-1}l)$$ for all $x \in M$ , $\xi \in \ell^2(G,\mathcal{H})$ , and $l \in G$ . My question is, are there necessary and sufficient conditions for when the twisted crossed product $M \rtimes_{(\sigma,v)} G$ is a $II_1$ factor?","['von-neumann-algebras', 'group-theory', 'operator-algebras']"
4146730,Does any metric on the real numbers imply a topology with countable many open subsets?,"a friend of mine came up with a question wich seems to be easy at first, but after some thinking I could not come up with a solution. The question is, weather you can define a metric $d$ on $\mathbb{R}$ such that the number of open sets via this metric is only countable. My guess is that it is not possible. I thought that for any $\epsilon > 0$ the open Ball $B_{\epsilon}(x)$ should contain infinitely many other elements (at least for uncountable many real numbers $x$ ) so you can't just have the set with only one element as an open leading to uncountable many open subsets. But I am not quite sure if that leads to an answer, I just wanted to mention it. I would be glad if someone is able to answer my question, thanks a lot already! Hannes L.","['real-numbers', 'general-topology', 'metric-spaces']"
4146732,Find the Angle and Distance to point B from the Origin,"I'm about average when it comes to math, so I probably have no business asking this question, but I'm going to ask anyway because I'm curious. I've been playing a video game with artillery, and the player shooting the artillery can't see the target. They can, however, see a different person who CAN see the target. The original person knows the distance and angle to the second person, and the second person knows the distance and angle to the target from themselves. The game's map is the grid, and angles are measured relative to it. North is 0 Degrees going counter-clockwise (West is 90, South is 180, East is 270). Game is top-down, so for the intents of this question, this is on a 2D plane. I'm just trying to make a program that will help me do this so I don't have to guess anymore. What I'm given: I'm given the angle and distance from the Origin (Player on Artillery) to Point A (the Spotter) and the Angle and distance from point A to point B (The target). What I'm looking for: How do I calculate the angle and distance from the Origin to point B (Artillery to target)? Redirect me if this has been asked before, and I'll try to remove this post. I just couldn't find anything that looked familiar to me when searching for this kind of problem. Also, if there are better tags for this, I honestly have no idea what to put down. My best guess was Trigonometry, as it relates to 3 points and the angles/distances related to them, but I honestly wasn't sure.",['trigonometry']
4146794,What is the number of distinct simple graphs G such that T is a spanning tree of G?,"Consider a tree T in which the degree of each vertex is either 1 or 3.
Let n = |V(T)|, where V() is the set of vertices. What is the number of distinct simple graphs G such that T is a spanning tree of G? So far here's what I've done: I've shown that n is even. I've shown that T has $\frac n 2 + 1$ leaves. T is a spanning tree of G => V(T) = V(G) I'm using a theorem that for any finite set V, there are $2^{
|V|\choose2}$ distinct simple graphs with vertex set V. Hence there are $2^{n\choose2}$ distinct simlpe graphs. Then I've used another theorem that for $n\ge2$ there are $n^{n-2}$ distinct trees with n vertices. Therefore, we have $n^{n-2}$ spanning trees with n vertices. Hence, total distinct simple graphs = $n^{n-2} . 2^{n\choose2}$ check?","['graph-theory', 'trees', 'discrete-mathematics']"
4146803,Why is the quotient rule in differentiation necessary?,Calculus - Derivatives - Quotient Rule Why is a quotient rule even necessary? Why can't we just consider $\frac{A}{B}$ as $A \cdot B^{-1}$ and use the multiplication formula?,"['calculus', 'derivatives']"
4146817,Soft question: What does it mean if the area integral of the divergence of a vector field over a region is negative?,"Let $\vec{F}(x,y)$ be a vector field over $\mathbb{R}^2$ and let $\nabla \cdot \vec{F}$ be its divergence.  Presume that $\delta$ is a circle in the $x,y$ plane.  If I compute: $$I = \int\int_\delta \nabla \cdot \vec{F}dA$$ and find that $I < 0$ , what does that mean?  Is it correct to say that the net flux of the vector field acrosss the boundary of that region is negative?  Is it further correct to say that $\vec{F}$ has more sinks than sources in that region?","['multivariable-calculus', 'soft-question']"
4146858,Can a differentiable function have positive slope at the end point of its co-domain?,"Q) For every twice differentiable function $f:\mathbb{R}\longrightarrow [-2,2] $ with $[f(0)]^2+[f'(0)]^2=85$ , which of the following statement(s) is(are) TRUE? (A) There exists $r,s \in\mathbb{R}$ , where $r<s$ , such that f is one-one on the open interval $(r,s)$ (B) There exists $x_0 \in (-4,0)$ such that $|f'(x_0)|\leq 1$ (C) $lim_{x\to \infty}f(x)=1$ (D) There exists $\alpha \in (-4,4)$ such that $f(\alpha)+f""(\alpha)=0 and f'(\alpha)=0$ I have problem with option B. Here's the given solution- But I think this is wrong because $f(0)$ cannot be equal to $2$ as that gives us the value of $f'(0)=9$ (from the condition given in the question). If the slope is positive at $x=0$ and the function is achieving its highest value there then for the points in the right neighbourhood of $x=0$ the slope would have to abruptly change to $0$ otherwise the function would obtain values greater than $2$ which are not in its co-domain. But it cannot abruptly change either coz it's given to be a twice differentiable function. And I took $f(x)=9$ only but of course similar argument can be made with the negative value and a similar argument can be made if they took $f(0)=-2$ and $f(-4)=2$ in the solution. My question- Is the given solution wrong because of what I just said? Or did I go wrong somewhere? If not then can this be put into some more concrete words or if there's a theorem related to this? Can an alternate solution be proposed for option B? I'm under confident about this because this is a JEE Advanced 2018 question and no objections were made against this that I'm aware of.","['calculus', 'functions', 'derivatives']"
4146880,Covering the graph of a function,"$f:[0,1]→\mathbb{R}, ∣f(x)−f(y)∣≤∣x−y∣ \forall x,y∈[0,1] $ . Show that the graph of $f$ can be covered by rectangles that the sum of their shorter sides is less than $ε$ , $ \forall ε>0$ . I am not sure how to conclude this. Of course the constant and linear functions can be covered like this, but I could not come up with a soultion for other functions having this property. EDIT:
I think one has to show that there is a partition on which in every interval $f$ can be approximated by different linear functions.","['graphing-functions', 'lipschitz-functions', 'analysis', 'real-analysis', 'functions']"
4146909,Basic matrix algebra in SVD,"For my math course I'm reading about SVD in Principal Component Analysis (Abdi et al., 2010), I get stuck in (I think) a simple matrix algebra. In the text, equation (1) define SVD as: $X = PΔQ^T$ (Eq.1) and factor scores $F$ is defined as: $F = PΔ$ (Eq. 2) The matrix $Q$ gives the coefficients of the linear combinations used to compute the factors scores. This matrix can also be interpreted as a projection matrix because multiplying X by $Q$ gives the values of the projections of the observations on the principal components. This can be shown by combining Eqs. 1 and 2 as: $F = PΔ = PΔQ^TQ = XQ$ I need help to see how to combining Eq1 and 2 I get $F=XQ$ . Thanks!","['matrices', 'statistics', 'svd']"
4147005,P-value changes based on removed variable?,"Problem Setting: Assuming that we have $p$ variables $x_1, x_2, ..., x_p$ and a response vector $y$ with length $n$ , and the p-value is associated with the F-test with the null hypothesis $H_0: \beta_j = 0$ , I am wondering whether we can simulate these cases: (1). the $j$ th variable has a p-value < 0.05 in the linear model with $y$ and all $p$ variables, but its p-value increases above 0.05 if we remove the $k$ th variable from the model; (2). the $j$ th variable has a p-value > 0.05 in the linear model with $y$ and all $p$ variables, but its p-value decreases below 0.05 if we remove the $k$ th variable from the model. I think the second case the is multicollinearity problem, so under (2). we can simulate a multicollinearity dataset, and we expect remove one of the multicolinear column can achieve desired property in (2). However, I can not figure out the first case that what kinds of problem related with it.","['linear-regression', 'statistics', 'simulation', 'hypothesis-testing']"
4147028,Can we find a topological group isomorphism $\overline{\{a^{k}:k\in\mathbb{Z}\}}\to\overline{\{b^{k}:k\in\mathbb{Z}\}}$ such that $a\mapsto b$?,"Let $G$ be a compact monothetic group, that is, $G$ is a compact group with a dense cyclic subgroup. Note that $G$ is necessarily abelian. Suppose that $$G=\overline{\{a^{k}:k\in\mathbb{Z}\}}=\overline{\{b^{k}:k\in\mathbb{Z}\}}.$$ Can we find a topological group isomorphism (i.e. isomorphism + homeomorphism) $\phi\colon G\to G$ such that $\phi(a)=b$ ? Without the closures and topology, I think one can define $\phi(a^{k}):=b^{k}$ . However, I'm not sure if this injective and that this can be extended continuously to the closure.","['topological-groups', 'group-theory', 'general-topology', 'locally-compact-groups', 'abelian-groups']"
4147033,"A positive proportion of the prime numbers is proven to have certain property, yet no specific prime is proven to have that property?","Suppose a property $\phi$ holds for a strictly positive proportion of the prime numbers, i.e. such that $$\liminf_{x\to\infty}{\pi_\phi(x)\over \pi(x)}\gt 0,$$ where $\pi_\phi(x)$ counts the number of primes less than or equal to $x$ having the property $\phi$ , and $\pi$ is the usual prime-counting function. According to [here] and [here] , cases of this include the following: $\phi_1(n)$ =""changing any single decimal digit of $n$ (not including leading zeros) produces a composite number"" $\phi_2(n)$ =""changing any single decimal digit of $n$ (including any leading zero) produces a composite number"" E.g., $n=294001$ has property $\phi_1$ , but not property $\phi_2$ (because $10294001$ is prime).
In fact: Infinitely many primes (indeed a positive proportion) have property $\phi_2$ , yet there is no known example . Q1 : What are some other number-theoretic properties proven to hold for a strictly positive proportion of the primes, yet there is no specific prime for which the property has been proven to hold? Q2 : Are there similar cases with respect to $\mathbb{N}?$ I.e., some property holds for a strictly positive proportion of $\mathbb{N},$ yet there is no specific $n\in\mathbb{N}$ for which the property has been proven to hold? In this case, I suppose the proportion of $\mathbb{N}$ satisfying property $\phi$ would be defined as $$\liminf_{x\to\infty}{C_\phi(x)\over x},\ \text{ where }\ C_\phi(x)=\#\{n\in\mathbb{N}: n\le x,\ \phi(n) \}.$$","['number-theory', 'reference-request']"
4147043,Complex value for arcsin(π)?,"Was bored and I just started finding a complex solution for $\arcsin(π)$ , and im not sure if the solution I got is correct.
I started with euler's formula, $e^{iθ} = \cos(θ) + i \sin(θ)$ , and then replace theta with $\arcsin(θ)$ , so we get: $e^{i \cdot \arcsin(π)} = \cos(\arcsin(π))+ i \sin(\arcsin(π))$ Next step I did was to factor it, by having the formula: $\cos(\arcsin(θ)) = \sqrt{1-θ^2}$ , and the formula: $\sin(\arcsin(θ)) = θ$ , and then I got: $e^{i \cdot \arcsin(π)} = \sqrt{1-π^2} + iπ$ Next step, I took the natural logarithm of both sides, then got: $i \arcsin(π) = \ln(\sqrt{1-π^2} + iπ)$ About next step, I tried to first simplify that natural logarithm in the second side of equation, by turning $\sqrt{1-π^2}$ into $\sqrt{-(π^2 - 1)}$ , which we can get it to: $i \sqrt{π^2 - 1}$ , where $i$ is the imaginary unit. Hence, my next equation was: $i \arcsin(π) = \ln(i \sqrt{π^2-1} + iπ)$ And then, factor the input of natural logarithm: $i \arcsin(π) = \ln(i(\sqrt{π^2-1} + π))$ Next, I applied to my natural logarithm, the following formula: $\ln(xy) = \ln(x) + \ln(y)$ , thus: $i \arcsin(π) = \ln(i) + \ln(\sqrt{π^2-1} + π)$ Last step, divide both sides by $i$ : $\arcsin(π) = \frac{\ln(i) + \ln(\sqrt{π^2-1} + π)}{i}$ Since that answer wasn't that satisfying for me, I approximated it, thus: $\arcsin(π) = \frac{1.81152627 + 1.57079633 i}{i}$ And here is last thing I do in here, it is simplifying it: $\arcsin(π) = 1.57079633 - 1.81152627 i$ Is there anything wrong I did, and If so, what was the mistake I have done here? Thanks for the attention.","['trigonometry', 'complex-numbers']"
4147116,"What is the average ""measure"" inside an $N$-dimensional ball?","What is the average ""measure"" inside an $N$ dimensional ball of radius $1$ ? Here ""measure"" is the length, area, volume, and so on of $N$ points in $N$ -dimensional space. For two dimensions my problem is what is the average distance between two random points in a radius $1$ disk. My friend Jay told me about this version of this problem and  that the answer for this is $\frac{128}{45\pi}$ but I don't know how to verify this. For three dimensions my problem is what is the average area of a triangle defined by three random points in a radius $1$ ball. For an $N$ -dimensional ball of radius $1$ , what is the average ""measure"" of the an $(N - 1)$ -dimensional triangle defined by $N$ random points in the $N$ -dimensional ball? I also would like to know why for two dimensions it is supposedly $\frac{128}{45\pi}$ . I know a little bit of calculus 1 and 2 from high school if that is needed to understand this problem.","['expected-value', 'spheres', 'circles', 'geometry']"
4147126,Does the prime number theorem tell us that the next prime number is guaranteed to be relatively nearby?,"Let $\ p_n\ $ be the $\ n$ -th prime number. Does the prime number theorem , $\Large{\lim_{x\to\infty}\frac{\pi(x)}{\left[ \frac{x}{\log(x)}\right]} = 1},$ imply that: $ \displaystyle\lim_{n\to\infty}\ \frac{p_n}{p_{n+1}} = 1\ ?$ Edit: I totally get where the vote-to-closes come from and I kind of agree with them. Yeah this is not the question I intended to ask actually. I think I've done an X-Y communication thingy. I'll leave the question and accept the answer though. But I have learned something about prime numbers along the way in reading the answers...","['limits', 'prime-gaps', 'number-theory', 'prime-numbers']"
4147162,Can I view the Taylor polynomial as a generalization of the derivative?,"We know that we can regard a derivative as the ""best linear approximation"" of a function $f: (a,b) \to \mathbb{R}$ at a given point $x_0 \in (a,b)$ . I was wondering whether we can view the Taylor polynomial as ""the best polynomial approximation"". Another person has already asked a quite similar question , but I am not very satisfied with the answer because the norm that was defined in the first answer seems a bit arbitrary. I would suggest to define a Taylor polynomial in the following way: Let $f:(a,b) \to \mathbb{R}$ be a real-valued function. A $k$ -th order polynomial $p_k$ is a Taylor polynomial of order $k$ of $f$ at $x_0 \in (a,b)$ , if there exists a function $r_k: (a,b) \to \mathbb{R}$ such that $$ f(x) = p_k (x) + r_k (x) \quad \text{ with } \quad \lim\limits_{x \to x_0} \frac{r_k(x)}{(x-x_0)^k} = 0.$$ I already know that if $f$ is $k$ times differentiable at $x_0$ , then this definition coincides with the usual one. My question is: Is it necessary for $f$ to be differentiable $k$ times at $x_0$ ? If not, does it have major implications on things like uniqueness, etc?","['calculus', 'derivatives', 'taylor-expansion', 'real-analysis']"
4147235,A square matrix (XX^T) made from column vector X always has an eigen vector as X,"I was asked in an interview that Given a column vector $X$ of order $n\times1$ , when we obtain the matrix $XX^T$ (order $n\times n$ ), give at least one of the eigenvectors of the matrix $XX^T$ without any calculation, just by looking Observing that all the columns of the matrix $XX^T$ are dependent on the column vector $X$ , thus there is only one independent vector basis in the column space of $XX^T$ , thus rank of $XX^T$ is $1$ . Hence in row echelon form of $XX^T$ , there is only one row and thus, $XX^T$ has $n-1$ eigenvalues as $0$ and one eigenvalue is non-zero. With their help I was able to conclude from trace property of a matrix that the non-zero eigenvalue was (sum of square of each element in column vector $X$ ) . But eigenvector I could not found during interview but by their surprised look, it was evident that The eigenvector was hiding in plain sight and I could not see! Later taking examples, I found $X$ to be an eigenvector. I could prove it by brute force taking general $(n\times1)$ column vector and then constructing $XX^T$ with all columns dependent then the product $XX^T\times X$ , will have in first row of product a multiple of first row of any of the column and similarly in all rows, and I could show that the eigenvector $X$ is corresponding to non-zero eigenvalue But, is there a CLEAN method, like from vector spaces geometric interpretation or property of $XX^T$ or anything much more conceptual than brute force general example taking?","['matrix-rank', 'eigenvalues-eigenvectors', 'matrices', 'linear-algebra', 'transpose']"
4147325,How to setup the correct fraction in word problems?,"The word problem: ""An old computer consists of 18000 vacuum tubes. One vacuum tube lasts 900 hours. How long can you run the computer before you have to replace one vacuum tube?"" My attempt: I thought ""How many times does $900$ fit in $18000$ "", so $$
\frac{18000}{900}=20 \, \text{hours} \tag 1
$$ But the answer is instead reversed $$ 
\frac{900}{18000}=\frac{1}{20} \, \text{hours} \tag 2
$$ I often confuse which value I should have in the numerator/denominator. How should I think? Is there any tricks?","['word-problem', 'fractions', 'algebra-precalculus']"
4147351,How can two seemingly identical conditional expectations have different values?,"Background Suppose that we are using a simplified spherical model of the Earth's surface with latitude $u \in (-\frac {\pi} 2, \frac {\pi} 2)$ and longitude $v \in (-\pi, \pi)$ . Restricting attention to the hemisphere, $H$ , where $u, v \in (-\frac {\pi} 2, \frac {\pi} 2)$ , a simple map projection from $H$ can be obtained by just taking the $x$ and $y$ coordinates via $x = \cos u \sin v$ and $y = \sin u$ , which is a smooth one-to-one transformation on $H$ . Now, picking a point with coordinates $(U, V)$ on $H$ uniformly according to surface area, the joint density of $U$ and $V$ is $$f_{U, V}(u, v) = \frac 1 {2\pi} \cos u, \quad \lvert u \rvert, \lvert v \rvert < \frac {\pi} 2.$$ Question $(a)\quad$ Find $\mathbb{E}[\lvert \sin U \rvert \mid V = 0]$ . $(b)\quad$ Find $\mathbb{E}[\lvert Y \rvert \mid X = 0]$ . $(c)\quad$ Observe that $\lvert Y \rvert = \lvert \sin U \rvert$ and the event $\{X = 0\}$ is exactly the same as the event $\{V = 0\}$ . How is it possible that $\mathbb{E}[\lvert Y \rvert \mid X = 0] \neq \mathbb{E}[\lvert \sin U \rvert \mid V = 0]$ ? My working I have omitted intermediate steps and only shown the essential parts to minimise the length of this post. $(a)$ $$\begin{aligned}
\because f_{U \mid V = v}(u) & = \frac 1 2 \cos u,\quad \lvert u \rvert, \lvert v \rvert < \frac \pi 2
\\[5 mm] \therefore \mathbb{E}[\lvert \sin U \rvert \mid V = 0] & = \int^{\infty}_{-\infty} \lvert \sin u \rvert \left(\frac 1 2 \cos u\right)\ \mathrm{d}u
\\[5 mm] & = \int^{\frac \pi 2}_0 \sin u \cos u\ \mathrm{d}u
\\[5 mm] & = \frac 1 2
\end{aligned}$$ $(b)$ $$\begin{aligned}
\\[5 mm] \because f_{X, Y}(x, y) & = \frac 1 {2 \pi \sqrt{1 - y^2 - x^2}}, \quad x^2 + y^2 < 1
\\[5 mm] \therefore f_{Y \mid X = x}(y) & = \frac {\frac 1 {2 \pi \sqrt{1 - y^2 - x^2}}} {\int^{\sqrt{1 - x^2}}_{-\sqrt{1 - x^2}} \frac 1 {2 \pi \sqrt{1 - y^2 - x^2}}\ \mathrm{d}y}
\\[5 mm] & = \frac 1 {\pi \sqrt{1 - y^2 - x^2}}, \quad x^2 + y^2 < 1
\\[5 mm] \implies \mathbb{E}[\lvert Y \rvert \mid X = 0] & = \int^{\infty}_{-\infty} \frac {\lvert y \rvert} {\pi \sqrt{1 - y^2}}\ \mathrm{d}y
\\[5 mm] & = \frac 2 \pi \int^1_0 \frac y {\sqrt{1 - y^2}}\ \mathrm{d}y
\\[5 mm] & = \frac 2 \pi
\end{aligned}$$ $(c)\quad$ Although $\lvert Y \rvert = \lvert \sin U \rvert$ and the event $\{X = 0\}$ is indeed identical to the event $\{V = 0\}$ , we must be mindful of the coordinate systems in play here. In particular, there are two - the $(x, y)$ plane and the $(u, v)$ plane, which are not identical but related by a transformation. Thus, since $\lvert Y \rvert$ and the event $\{X = 0\}$ concern the $(x, y)$ plane, while $\lvert \sin U \rvert$ and the event $\{V = 0\}$ concern the $(u, v)$ plane, it follows that $\mathbb{E}[\lvert Y \rvert \mid X = 0] \neq \mathbb{E}[\lvert \sin U \rvert \mid V = 0]$ . I think my answers to $(a)$ and $(b)$ are correct, but I am not sure about my answer to $(c)$ , so any intuitive explanations will be greatly appreciated!","['integration', 'statistics', 'conditional-expectation', 'solution-verification', 'probability-theory']"
4147380,Can you propose any hack for remembering the common derivative and integral formulas?,Calculus cheat sheet Remembering the following formulas has been a nuisance for me for years now. Common Derivatives Common Integrals They are too many in numbers Intuition doesn't work I mix up derivatives and integrals frequently Can anyone suggest the best way to remember them?,['calculus']
4147396,"If $\Omega$ is locally Lipschitz, then $\Omega = \bigcup_{k = 1}^N \Omega_k$ for $\Omega_k$ star shaped with respect to an open ball $B_k$.","I am reading Galdi's Introduction to the mathematical theory of Navier Stokes equations and there is an argument which comes up quite often that I really don't understand. In many theorems of Chapter $3$ , we prove the existence of solutions of a problem defined on an open set $\Omega \subset \mathbb R^n$ that statisfies the following condition: $$\Omega = \bigcup_{k  = 1}^N \Omega_k$$ where each $\Omega_k$ is star shaped with respect to some open ball $B_k$ with $\overline{B}_k \subset \Omega_k$ . Then, in the next chapters, he uses these results but for $\Omega$ bounded and locally Lipschitz. Therefore, it seems to me that a bounded locally Lipschitz open set should satisfy the above condition, but I really have no idea how to show that.. Clearly $\overline{\Omega}$ is compact, so we can cover it by a finite number of balls, but then how do we prove that they are star-shaped with respect to some other balls $B_k$ ? Any idea ?","['general-topology', 'metric-spaces', 'analysis']"
4147440,Are sorted i.i.d still i.i.d?,"I need help with that question. We have i.i.d. Let us sort the values in ascending order.Is new series is i.i.d? From my opinion the answers is yes because function y that sort the x is only mapping from x, but im not sure. Can anybody correct my understanding?","['statistics', 'probability-theory']"
4147452,Prove that the following limit depending on $\alpha$ is $0$,"Let $f$ be a smooth function with $\lim_{x\to \infty}f(x)=+\infty$ , $\lim_{x\to \infty}f'(x)=+\infty$ for $x\in [x_0,+\infty)$ , $x_0>0$ . I want to show that $$
\lim_{x\to \infty}\frac{x f'(x)}{(x^2+f(x)^2)^\alpha}=0,
$$ for $\alpha>c>0$ , which I should determine. I guess that I only need $\alpha>1$ to have the result. I am trying to prove it using Taylor expansion but I am not getting a clear argument. Is there any other way to do it or a clever use of Taylor series?","['limits', 'derivatives']"
4147460,Expected number of consecutive heads in 10 coin tosses,"I am having trouble formulating the exact recursive relation for this problem. The problem statement is A coin is tossed 10 times and the output written as a string. What is the expected number of HH? Note that in HHH, number of HH = 2. (eg: expected number of HH in 2 tosses is 0.25, 3 tosses is 0.5) The recursive relation I came up with is $$ E(10) = \frac{1}{2}E(9) + \frac{1}{4}E(8) + \frac{1}{4}(E(9)+1) $$ My reasoning behind this is: The last toss is T with a probability of 1/2, so we'll have to only look for no of consecutive heads in the first 9 tosses, but if the last toss is H, then it matters what the second last toss was, it we have TH situation, then the no of consecutive heads is the same as in first 8 tosses, but if we have the last two tosses as HH, then we have no of consecutive heads as one more than the no of heads in first 9 tosses. The solution given states the following recursive relation $$ E(10) = \frac{1}{2}E(9) + \frac{1}{4} E(9) + \frac{1}{4}(E(9)+1) $$ So basically, the difference is in the second term of the recursive relation. I am not able to wrap my head around this solution, is there a fundamental error in my understanding?","['expected-value', 'statistics', 'probability-theory', 'probability']"
4147466,Proof for this property of triangles,"In a handout of mine a 'geometrical fact ' is stated : Among such triangles ABC which have two fixed side lengths |BC|=a and |AC|=b<a, the triangle of largest angle ABC has BAC= 90° Being a fact to solve physics problems it was not explained but I would like to know why this is true. My attempt was to draw line segment BC and the locus of possible points of A (circle of radius b centered at C) and some how convince my self the tangent from B to this circle makes the greatest angle with BC But I could not ,any way forward ?","['triangles', 'geometry']"
4147467,Definition of Semicontinuity: Confusion in Rudin's RCA,"Rudin's RCA defines upper and lower semicontinuity as follows: Let $f$ be a real or extended-real function on a topological space. If $$\{x: f(x) > \alpha\}$$ is open for every real $\alpha$ , $f$ is said to be lower semicontinuous. If $$\{x: f(x) < \alpha\}$$ is open for every real $\alpha$ , $f$ is said to be upper semicontinuous. Clearly, the author defines upper and lower semicontinuity only for real (or extended-real) valued functions , and not explicitly for complex functions. Edit: I had confused this with Q2 of Chapter 2, which was unrelated for the most part. My question now boils down to extending the definition of semicontinuity to complex functions, or more generally. Thank you for the clarifications!","['measure-theory', 'semicontinuous-functions', 'real-analysis', 'continuity', 'definition']"
4147527,$\mathscr{F}\rightarrow i_*(i^*\mathscr{F})$ is an isomorphism for $i:V(\mathscr{I})\rightarrow X$,"This is Remark 7.36 of Görtz/Wedhorn. We have a scheme $X$ and a quasi-coherent $\mathcal{O}_X$ -module of finite type $\mathscr{F}$ , and we define $\operatorname{Ann}(\mathscr{F})$ as the kernel of the canonical homomorphism of $\mathcal{O}_X$ into the endomorphism sheaf of $\mathscr{F}$ over $\mathcal{O}_X$ . Then we assume that $\mathscr{I}$ is a quasi-coherent ideal of $\mathcal{O}_X$ , and we thus get an induced closed subscheme $V(\mathscr{I})$ of $X$ , whose inclusion into $X$ we denote by $i$ . If we assume further that $\mathscr{I}\subseteq \operatorname{Ann}(\mathscr{F})$ , then $\mathscr{F}$ is naturally an $\mathcal{O}_X/\mathscr{I}$ -module. The authors then say that $\textbf{this}$ shows that the canonical morphism coming from adjuntion $\mathscr{F}\rightarrow i_*(i^*\mathscr{F})$ is an isomorphism, which I don't really get at the moment. I think that since $i$ is an inclusion of a closed subscheme, we should get isomorphism on stalks, but I don't see how this uses the argument $\textbf{this}$ , and also I think my thought is invalid, because otherwise for every closed subscheme we would have this isomorphism. I would be grateful if someone could give me just a little hint.","['algebraic-geometry', 'schemes']"
4147551,Is there intuitionistic proof that $B \setminus (B \setminus A) = A$ for any sets $A \subseteq B$?,"Let $A$ and $B$ be sets such that $A \subseteq B$ . I am trying to investigate whether $A = B \setminus (B \setminus A)$ . I am attempting to prove this by showing $(\forall x)[x \in A \Leftrightarrow x \in B \setminus (B \setminus A)]$ . I was able to show that $x \in A \Rightarrow x \in B \setminus (B \setminus A)$ without resorting to the LEM, but I could only solve the other direction using either the LEM itself or the elimination of double negations. Is this even provable in intuitionistic logic? If so, can I get some directions on how to solve it? Thanks in advance. Here's how I solved the first direction: Let $x \in A$ . Since $A \subseteq B$ then $x \in B$ and we must now show $x \notin B \setminus A$ , i.e., $(x \in B \wedge x \notin A) \Rightarrow \perp$ . We assume $x \in B$ and $x \notin A$ and reach a wanted contradiction since $x \in A$ by our hypothesis.","['elementary-set-theory', 'intuitionistic-logic']"
4147579,Injective map from set cartesian product of perfect squares to set of natural number,"I am very interesting to figure out whether I am correct or not. Let $S$ denotes the collection of all perfect squares That is: $$S:\{1,4,9,\cdot \cdot \cdot \}$$ I am interested to define an injective map from $$ S\times S \to \mathbb{N}$$ .
My gauss is a following map $f$ : $$f: S\times S \to \mathbb{N}$$ given by $$f(m,n)=3m+5n$$ I tried to prove it by simple definition as follows let: $$f(m_{1},n_{1})=f(m_{2},n_{2})$$ $$3m_{1} + 5n_{1} =3m_{2} + 5n_{2}$$ $$3(n_{1} - n_{2} )=5(m_{2} - m_{1} )$$ .
I have a hard time proceeding further. I am in doubt whether my guess is correct at first place or not","['number-theory', 'discrete-mathematics']"
4147642,"Minimum of $\left(\frac{1}{a}+\frac{2}{b}+\frac{3}{c}\right)$ where $a,b,c$ are the roots of a polynomial","If $a,b,c$ are positive roots of $$x^3-lx^2+mx-48=0$$ Find the minimum value of: $\left(\cfrac{1}{a}+\cfrac{2}{b}+\cfrac{3}{c}\right)$ So: $$abc=48$$ $$a+b+c=l$$ $$ab+bc+ca=m$$ Through AM $\ge$ GM, I found that $$l\ge 6\sqrt[3]{6}$$ I don't think that's useful. Also, I tried AM $\ge$ HM: $$\cfrac{ \cfrac{1}{a}+\cfrac{1}{b}+\cfrac{1}{b}+\cfrac{1}{c}+\cfrac{1}{c}+\cfrac{1}{c} }{6} \ge \cfrac{6} {a+b+b+c+c+c}$$ But it's messing up, because I'm getting an extra $b+2c$ term in the denominator. Also I don't think Cauchy Shwarz/Lagranges would work here. Any hints would be helpful thanks. And I'm also unable to find the use of $m$ here.","['contest-math', 'inequality', 'a.m.-g.m.-inequality', 'sequences-and-series', 'algebra-precalculus']"
4147665,"Probability that $\int_0^tX_s\,dW_s$ lies within $1/t$ of $X_t$","Consider the inequality $$f(x)-\frac1x\le f’(x)\le f(x)+\frac1x$$ on the positive axis. This tells us that $f(x)\sim e^x$ with infinitesimal deviation, and we can use identities such as Grönwall's inequality to establish bounds on $f(x)$ . As there is no randomness in the function, this problem is deterministic. In the random scenario, consider a stochastic process $X_t$ under Brownian motion (BM); that is, $$dX_t=\mu(t,X_t)\,dt+\sigma(t,X_t)\,dW_t.$$ The problem thus becomes evaluating the value of $$F_{X_t}(t)=\operatorname P\left(\int_0^tX_s\,dW_s-\frac1t\le X_t\le\int_0^tX_sdW_s+\frac1t\right)\tag1$$ for any $t>0$ . Note that the analogous version of $f(x)\sim e^x$ can be described through geometric Brownian motion (GBM). If $X_t=W_t$ , we expect $F(t)\to0$ as $t\to\infty$ . Indeed, we have \begin{align}F_{W_t}(t)&=\operatorname P\left(-\frac12t-\frac1t+W_t^2\le W_t\le-\frac12t+\frac1t+W_t^2\right)\end{align} using Itô's lemma. This can be rewritten as $$F_{W_t}(t)=\operatorname P\left(\frac{2t^2+t-4}{4t}\le\left(W_t-\frac12\right)^2\le\frac{2t^2+t+4}{4t}\right)$$ to the form $\operatorname P\left(g(t)\le W_t\le h(t)\right)$ , which can then be converted to a standard Normal. But how about in the case of GBM (where $F(t)\to1$ with an appropriate choice of $\mu,\sigma$ ), or more generally any $X_t$ ?","['probability', 'asymptotics', 'stochastic-processes', 'brownian-motion', 'stochastic-calculus']"
4147693,Locally connectedness preserved after removing one point,Given a locally connected space $X$ with two or more points is it always true that for any point $x$ in $X$ the subspace $X \setminus \{x\}$ is also locally connected? I have proved it for Hausdorff spaces but I would like to know if it is true for any topological space.,"['locally-connected', 'general-topology', 'connectedness']"
4147735,$|𝐸[𝑋]|+𝜌(𝑋)≥1$?,"Suppose $X_1, X_2, ... \sim X$ are i.i.d. random variables on $\mathbb{Z}$ . Then the sequence $\{P(\sum_{i=1}^{d(X)n} X_i = 0)^{\frac{1}{d(X)n}}\}_{n=1}^\infty$ converges to some constant $\rho(X) \in [0;1]$ almost surely by Kingman’s subadditive ergodic theorem. Here $d(X) = \min\{d \in \mathbb{N}|P(\sum_{i=1}^{d} X_i = 0)>0\}$ . For some random variables $X$ the value $\rho(X)$ can easily be calculated. For example: If $P(X \geq 0) = 1$ or $P(X \leq 0) = 1$ , then $\rho(X) = P(X = 0)$ trivially. If $$X = \begin{cases} -a & \quad \text{ with probability } p \\ b & \quad \text{ with probability } 1-p \end{cases}$$ where $a, b \in \mathbb{N}$ , $p \in (0;1)$ , then $\rho(X)=\frac{p^{1-x}(1-p)^{x}}{x^x(1-x)^{1-x}}$ , where $x = \frac{a}{a+b}$ . That is due to the fact, that $P(\sum_{i=1}^{(a+b)n} X_i = 0) = C^a_{a+b}p^ac^b$ . I want to determine, whether the inequality $|E[X]| + \rho(X) \geq 1$ holds for all random variables $X$ on $\mathbb{Z}$ . So far I only managed to ""prove"" it in three trivial cases: If $P(X \geq 0) = 1$ . Then, by Markov inequality $1 - \rho(X) = 1-P(X=0) = P(X \geq 1) \leq E[X] = |E[X]|$ . If $P(X \leq 0) = 1$ . Then, by Markov inequality $1 - \rho(X) = 1-P(X=0) = P(-X \geq 1) \leq -E[X] = |E[X]|$ . If $|E[X]| \geq 1$ . That is because $\rho(X) \in [0;1]$ However, I do not know how to prove this inequality in general case. Neither have I found any counterexamples. Related question on upper bound for $\rho(X)$ : $\rho(X)E[X]^2 \leq Var[X]$?","['random-walk', 'stochastic-processes', 'inequality', 'probability-theory', 'probability']"
4147793,Diffeomorphism group and isometry group of torus $T^2$,"Let us consider a standard metric and differentiable structure on $T^2$ . We first consider the diffeomorphism group and isometry group of $T^2$ on itself. 1. What is the diffeomorphism group of $T^2$ ? According to Wiki ,
the diffeomorphism group of the torus has the homotopy-type of its linear automorphisms $S^1 \times  S^1 \times  GL(2, \mathbb{Z}).$ So is that true: $$\mathrm{Diff}(T^2)= S^1 \times  S^1 \times  GL(2, \mathbb{Z})?$$ 2. What is the isometry group of $T^2$ ? From isometry group of the riemannian manifold $\mathbb{T}^2$? , it seems that there is a ambiguity whether we have $$\mathrm{Isometry}(T^2)= D_8\rtimes_\varphi T^2?$$ where $\varphi\colon D_8\to \mathrm{Aut}(T^2)$ with $D_8$ the order 8 dihedral group. 3. Why are $\mathrm{Diff}(T^2)$ and $\mathrm{Isometry}(T^2)$ different?","['differential-topology', 'diffeomorphism', 'general-topology', 'isometry', 'differential-geometry']"
4147861,Finding a upper bound for a complex and algebraic function.,"I am stuck in understanding a proof, where I don't really understand one step, which i specify below: (suposse that $f$ is holomorphic, thus analytic) (I have no information about the holomorphism domain of $f$ ). Result. If $\phi(x,y)$ is an algebraic function in both variables, i.e. there are polynomials $P_k(x,y)$ such that \begin{equation*}
\sum_{k=0}^{N}P_k(x,y)[\phi(x,y)]^k = 0
\end{equation*} and also let $f$ be a holomorphic function such that \begin{equation*}
|f(z)|^2 = \phi(x,y)
\end{equation*} then $|f(z)|^2 \leq C|z|^m$ , for some $m$ . EDIT. Based on @MartinR comment, $f(z)=z+1$ would be a counterexample for the inequality above, which makes it invalid. Instead, he suggested (and very well) that: \begin{equation*}
|f(z)|^2 \leq C(1+|z|^m), \hspace{.2cm} \text{ for some $m$}
\end{equation*} which would also verify the demonstration I am talking about in the beginning. This is a step that appears in a proof, and I tried to write it formally as a proposition/theorem above.
I would like to know where this comes from, and even if it's valid, since it's not making much sense to me. Mainly coming here to understand the result and the proof itself, not building it by myself. Thanks for all the help in advance.","['complex-analysis', 'entire-functions', 'upper-lower-bounds', 'analytic-functions']"
4147980,Proving the non-existence of a sequence satisfying a set of inequalities,"There exist some type of conditions called sequential optimality conditions that usually require some inequalities to be ensured along with it,  see short introdution . Based on a conjecture on this type of sequences, It would be enlightening to this conjecture to find an analytic function $\boldsymbol{c} : \mathbb{R}^{n} \rightarrow \mathbb{R}^{p}$ and sequences $\{\boldsymbol{\mu}^{k}\} \subset \mathbb{R}^p_{+}$ , which means $\mu^k_i \geq 0$ for all $i\leq p$ and $k\in\mathbb{N}$ , and a convergent sequence $\{\boldsymbol{x}^{k}\} \subset \mathbb{R}^n$ such that, for all $k\in\mathbb{N}$ , it's true that $\boldsymbol{c}(\boldsymbol{x}^{k}) \geq \boldsymbol{0}$ , \begin{gather*}
\left( \sum_{i=1}^{p} c_{i}(\boldsymbol{x}^{k}) \mu_i^{k}\right)^{2\theta} \left( \sum_{i=1}^{p}\mu_i^{k}\right)^{2(1-\theta)} \leq M + \left( \sum_{i=1}^{p} (c_{i}(\boldsymbol{x}^{k}))^2 \right) \left( \sum_{i=1}^{p}(\mu_i^{k})^2\right),\\
\left( \sum_{i=1}^{p} c_{i}(\boldsymbol{x}^{k}) \mu_i^{k}\right) \geq \delta
\end{gather*} and $$
\lim_{k\rightarrow \infty} \sum_{i=1}^{p} c_{i}(\boldsymbol{x}^{k}) = 0
$$ for some $\delta>0$ and $M>0$ and all $0<\theta<1$ . Is it possible?","['multivariable-calculus', 'nonlinear-optimization', 'examples-counterexamples', 'inequality']"
4148000,Real coefficients such that any matrix is invertible,"Let $n>1$ . Does there exist $n^2$ real numbers $a_1, a_2, ..., a_{n^2}$ such that any $n \times n$ matrix using these coefficients is invertible? I wanted to use the fact that a matrix is invertible iff its rank is $n$ . My idea is to find numbers such that any column of $n$ of these numbers is not a linear combination of the other columns. So, I started looking at square roots of prime numbers. I was at first conjecturing that a sum of $n$ square roots of prime numbers cannot be itself a square root of prime numbers; It’s true for $n=2$ : If $p$ and $q$ are distinct prime numbers, let’s suppose by contradiction $\sqrt{p}+\sqrt{q}=\sqrt{k}$ with $k \in \mathbb{N}$ . Squaring this identity gives $p+q+2\sqrt{pq}=k$ which is absurd since $\sqrt{pq}$ must be irrationnal. For more primes, it gets more complicated since a similar proof for $n$ primes $p_1,...,p_n$ would lead to show that $\sum_{i<j} \sqrt{p_ip_j}$ cannot be a rationnal number, which I assume to be true but cannot prove it. Moreover, proving the result only for sums cannot be sufficient since we’re looking for linear combinations, and there obviously exist a real $\lambda$ such that $\sqrt{p_1}=\lambda \sqrt{p_2}$ , which makes impossible to do the study number by number as I was doing for now. Could my idea lead anywhere, or is there an easier approach to this problem?","['matrices', 'linear-algebra', 'inverse']"
4148010,Is the volume form a tensor?,"The definition of the volume form confused me whenever I read about it through a general relativity textbook. Perhaps it is better explained in Mathematics text, but I haven't taken a look at them. The volume form in general relativity is introduced through something called a tensor density. As far as I understand, tensor densities aren't really much different from tensors - they just come from looking at tensors differently. When physicists mean the form $dx^1 \wedge dx^2 \wedge ...\wedge dx^n$ is a tensor density what they mean is that in a new coordinate system $y^\alpha$ , the form becomes $J dy^1 \wedge dy^2 \wedge ... \wedge dy^n$ where $J$ is the Jacobian determinant. However, the n-form is actually a tensor; the only reason it picks up the factor of the Jacobian is because we represent the tensor in terms of wedge products and not tensor products. We multiply the the square root of the metric to compensate for this factor. I understand this fairly well. However, is the final volume form given by $\sqrt{-g} \text{ } dx^1 \wedge dx^2 \wedge ...\wedge dx^n$ a tensor? It seems that the $\sqrt{-g}$ messes with the transformation law because it cancels the partial derivatives that come from transforming the n-form.","['tensors', 'volume', 'differential-geometry']"
4148059,"If any two triangles of equal area can be mapped via affine maps, what can we say about the geometry?","Let $(M,g)$ be a two-dimensional compact surface, endowed with a Riemannian metric. Fix $s>0$ , and suppose that for any two geodesic triangles $A,B$ having area $s$ , there exists an affine onto map $f:A \to B$ , where I say $f$ is affine if $\nabla df=0$ . (equivalently, $f$ maps parametrized geodesics to parametrized geodesics.
Here $\nabla=\nabla^{T^*M} \otimes \nabla^{f^*TM}$ ). I assume $s<<\text{Area}(M)$ is very small, so there are a lot of triangles of area $s$ . What can we say about the metric $g$ ? Does it have to be flat? Are there any restrictions on its curvature? I do not require $f$ to be the restriction of an affine map $M \to M$ ;
(I think this is a stronger requirement than the existence of ""local"" or piece-wise affine maps. e.g. for the flat torus, globally we only have $SL_2(\mathbb{Z})$ .) Edit: I believe that the assumption means that that there a lot of affine maps locally $M \to M$ ; perhaps we can translate this into showing $M$ is flat. In fact, if $\nabla^{T^*M} \otimes \nabla^{f^*TM}$ has zero curvature, then $M$ is flat. And 'many affine maps' means roughly 'many parallel sections of $T^*M \otimes TM$ '-- although not exactly, since for every $f$ , $df$ is a section of different vector bundle, which is $T^*M \otimes f^*TM$ .","['geodesic', 'differential-geometry', 'riemannian-geometry', 'symmetry', 'affine-geometry']"
4148101,"Could there be exact solutions to the Lane-Emden equation for real n≥0 other than 0, 1, or 5?","This Astronomy SE answer says With a constant $k$ and the polytrop index $n$ . This is a result of the solutions of the Lane-Emden equation $$\frac{1}{\xi^2} \frac{\mathrm{d}}{\mathrm{d}\xi} \left(\xi^2\frac{\mathrm{d}\theta}{\mathrm{d}\xi}\right) + \theta^n = 0$$ which is a dimensionless form of the Poisson equation for a radially-symmetric self-gravitating polytropic fluid, thus where density follows a function of the form $\varrho = \varrho_c \theta^n$ with a central density $\varrho_c$ . This equation can be solved exactly for polytrop index 0 (isobaric polytrope), 1 (isothermal polytrope) and 5 (limited use as it results in infinite stellar radius)... Question: Wikipedia notes that exact solutions (not depending on converging series) are known only for $n=(0, 1, 5)$ . Could there be as-yet undiscovered exact solutions for other real $n \ge 0$ ? Or has it been shown that there are no others possible? Potentially related: I have a special solution for the Lane-Emden equation. Can I use it to find the general solution?","['applications', 'mathematical-astronomy', 'ordinary-differential-equations']"
4148109,Evaluating a Double Integral Involving Fractional Part Functions,"In my project, I am stuck with the following integral. Please help. $$  I = \int_{x = a}^b \int_{y = a}^b \left\{ \frac xy\right\} \left\{\frac >yx\right\}~dx~dy$$ $0 < a < b < 1, b < 2a$ , where $\lbrace \rbrace$ is the fractional part function. I found an approximation of the integral calculated on the square $(0,\alpha)^2, \alpha < 1$ on your forum. I tried using the known values of the integral on the squares $(0,a)^2, (0,b)^2$ in calculation of the integral in discussion. Let $f(x,y)=\left\{ \frac xy\right\} \left\{\frac yx\right\}$ , then $$\int_{x = a}^b \int_{y = a}^b  f(x,y)~dx~dy = \int_{x = 0}^b \int_{y = 0}^b  f(x,y)~dx~dy-  \int_{x = 0}^a \int_{y = 0}^a  f(x,y)~dx~dy - 2   \int_{x = 0}^b \int_{y = 0}^a  f(x,y)~dx~dy$$ I get stuck trying to follow the idea used in calculation of the integrals on the squares $(0,a)^2$ and $(0,b)^2$ in calculation of the last one. Even taking $b = 2a$ was not useful. I hope I'll have the chance to receive a response. Thank you in advance. Al","['fractional-part', 'multivariable-calculus', 'multiple-integral']"
4148140,Changing the order of integration to find the volume,"My goal is to set up the triple integral that will solve the volume $\iiint \ xyz \ dV $ if S if the region bounded by the cylinders $x^2 + y^2 = 25$ and $ x^2+ z^2 = 25$ and the 1st octant with dV = dxdydz. With order dV = dzdydx, the value of the volume is $\frac{15625}{24}$ . My attempt is to set up the triple integral with order dV = dxdydz in which it should have the same answer with the triple integral with order dV = dzdydx. The S I have computed is S $\lbrace (x, y, z) \in \mathbb{R}^3: 0 \leq x \leq 5, 0 \leq y \leq \sqrt{25 - x^2}, 0 \leq z \leq \sqrt{25 - x^2} \rbrace$ this is for triple integral with order dV = dzdydx The S I have computed is S $\lbrace (x, y, z) \in \mathbb{R}^3: 0 \leq x \leq \sqrt{25 - \frac{y^2}{2} - \frac{z^2}{2}}, 0 \leq y \leq \sqrt{50 - z^2}, 0 \leq z \leq \sqrt{50} \rbrace$ this is for triple integral with order dV = dxdydz When I set up the triple integral, I found out that it should be $\frac{1}{2} \int_0^\sqrt{50} \int_0^\sqrt{50-z^2} \int_0^\sqrt{25 - \frac{y^2}{2} - \frac{z^2}{2}} xyz \ dxdydz$ and not simply $\int_0^\sqrt{50} \int_0^\sqrt{50-z^2} \int_0^\sqrt{25 - \frac{y^2}{2} - \frac{z^2}{2}} xyz \ dxdydz$ . What is the principle behind this? Why I should divide the volume of this triple integral to 2?","['multivariable-calculus', 'calculus', 'definite-integrals']"
4148214,How to compute hyperbolic angle between a vertical geodesic and a circular geodesic?,I am trying to compute the area of an ideal triangle. I know I have to find the angles where the vertical geodesic meets the semi-circle but I am stuck trying to find the hyperbolic angle measure. I have the circle: $(x-\frac{1}{2})^2+(y)^2=\frac{1}{4}$ (on the poincare model so $y>0$ ). How do I go about computing the angle?,"['hyperbolic-geometry', 'geometry']"
4148264,How to calculate $\sin\frac{2\pi}{13}-\sin\frac{5\pi}{13}+\sin\frac{6\pi}{13}$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question How to calculate this trigonometric function? $$\sin\frac{2\pi}{13}-\sin\frac{5\pi}{13}+\sin\frac{6\pi}{13}$$ I think this function is related to $x^{26}=-1$ . This Problem is provided by Tieba(Chinese facebook) users.",['trigonometry']
4148284,Understanding Halmos’ proof of Schroeder Bernstein,"I'm trying to understand Halmos’ proof of the Schroeder-Bernstein theorem. I'm going to replicate as much of the argument as I can, pausing at steps I can't completely follow. If $|X| \leq |Y|$ and $|Y| \leq |X|$ , then $|X| = |Y|$ . Proof. Without loss of generality, suppose $X \cap Y = \emptyset$ . If not, we can replace $X$ and $Y$ with isomorphic copies $X'$ and $Y'$ such that $X' \cap Y' = \emptyset$ and, upon establishing a bijection $X' \to Y'$ , we have a bijection $X \to Y$ . Let $f: X \to Y$ and $g: Y \to X$ be injections. If one is also surjective, then, taking an inverse if necessary, there exists a bijection $X \to Y$ , so we assume neither are surjective. I am not sure if I need to rule out surjectivity, though when it comes to apply the inverse function to elements not in the image of either $f$ or $g$ , I want to be sure that these sets are nonempty to prevent any issues with well-definedness. If this isn't necessary, please let me know. Given $x \in X$ , we say $x$ is the parent of $f(x) \in Y$ , and given $y \in Y$ , we say $y$ is the parent of $g(y) \in X$ . We can then define the descendents of $x$ and $y$ by successively applying $f$ and $g$ , namely, the descendants of $x$ are $$f(x), g(f(x)), f(g(f(x)), \ldots$$ and the descendants of $y$ are $$g(y), f(g(y)), g(f(g(y)), \ldots$$ where the elements alternate between membership in $X$ and membership in $Y$ . Each term in the sequence of descendants is, by definition, an ancestor of all terms that follow. We partition $X$ and $Y$ as follows. Given any element in either $x$ or $y$ and upon tracing back its lineage by successively applying $f$ and $g$ , we have three mutually exclusive and exhaustive possibilities. First, an element may have no parent in $Y$ , i.e., it lives in $X - g(Y)$ . Second, it may have no parent in $X$ , i.e., it lives in $Y - f(X)$ . Third, its lineage regresses ad infinitum, and we can always find a parent no matter how far we go. I don't think I fully understand this process since we're partitioning $X$ and $Y$ simultaneously. Where exactly are we starting? Do I have to start at $x$ to end up in $X - g(Y)$ or at $Y$ to end up in $Y - f(X)$ ? Define $X_X$ to be the set of elements of $X - g(Y)$ and their descendants in $X$ . That is, $x_X$ consists of all $x \in X - g(Y)$ and $f(x), f(g(f(x))$ , ad infinitum. Am I incorrect that I can keep applying $f$ and $g$ since these elements ""died in $X$ ,"" in some sense? I don't fully grasp why I have to a tack on the descendants, especially since I'm looking for elements of $X$ , so I assume I need to omit all descendants starting with an application of $g$ . Define $X_Y$ to be the set of elements of descendants in $X$ of elements in $Y - f(X)$ . That is, elements $g(y), g(f(g(y))$ , ad infinitum. I defined this similarly to the above, and have the same confusion. Then define $X_{\infty}$ to be the set of all elements in $X$ that lack any parentless ancestor, i.e., all remaining $x$ . Define $Y_X$ , $Y_Y$ , and $Y_{\infty}$ similarly to partition $Y$ . I don't think I fully understand the partition of $Y$ . What exactly is the correspondence between $X_X$ and $Y_X$ , $X_Y$ and $Y_Y$ , and $X_{\infty}$ and $Y_{\infty}$ ? The argument from here becomes that we can biject $X_X$ with $Y_X$ , $X_Y$ with $Y_Y$ , and $X_{\infty}$ with $Y_{\infty}$ , giving a bijection $X$ to $Y$ . Any help with understanding this argument would be appreciated.","['elementary-set-theory', 'proof-explanation']"
4148319,Weak-Baire Spaces,"I define a topological space $(X,\tau)$ to be a weak-Baire space if every intersection of a countable collection of dense open sets is non-empty.  This is a natural weakening of the usual notion of Baire space, where the intersection is required to be dense rather than merely non-empty. What can we say about these spaces? Have they been studied? Thanks EDIT: I'm working in descriptive set theory (hence mainly on Polish spaces), and in many results I've encountered it is used the fact that any two dense $G_\delta$ sets have non-empty intersection. This is a weak consequence of the fact that Polish spaces are Baire spaces (by the Baire category theorem), and I wondered whether we could extend this fact to a wider known (studied) class of spaces.","['general-topology', 'baire-category', 'reference-request']"
4148324,Two properties of the set of Bernoulli numbers,"Let $\mathcal{B}$ be the set of all Bernoulli numbers . We are looking for an answer for
one of the following (or both) questions. (a) Is there an infinite subset $S$ of rationals such that $(\mathcal{B}-\mathcal{B})\cap (S-S)=\{ 0\}$ ? (b) Is it true that $(\mathcal{B}-\mathcal{B})+F\neq \mathbb{Q}$ , for every finite subset $F$ of rationals? Note that $A-A=\{a_1-a_2: a_1,a_2\in A\}$ and $A+B=\{a+b: a\in A , b\in B\}$ . Also, $(\mathcal{B}-\mathcal{B})\cap (S-S)=\{ 0\}$ is equivalent to the property that every element $x$ of $\mathcal{B}+S$ has a unique
representation $x=b+s$ with $b\in \mathcal{B}$ and $s\in S$ . Thanks in advance","['number-theory', 'additive-combinatorics', 'elementary-number-theory', 'bernoulli-numbers', 'rational-numbers']"
4148361,What is the range of $f(x) = \sec ^{-1}(x) + \tan^{-1} (x)$ .,"To find the range of this function $$f(x) = \sec ^{-1}(x) + \tan^{-1} (x)$$ I solved it like, Range ( $\sec ^{-1}(x)$ ) = $[0,π] $ ~ $ $ {π/2} and, Range ( $\tan^{-1} (x)$ ) = $(-π/2 , π/2)$ So the resultant Range will be the intersection of the two individual ranges. So I got my answer as $[0, π/2)$ , but the textbook answer is $(0,π)$ . Hence my question is what is happening here and where am I wrong. Please help me to get the fundamentals used here.","['trigonometry', 'functions', 'inverse-function']"
4148380,Partial derivative of a function with respect to product of variables,"If I have a function $f(x,y)$ , and all I know about this function is its partial derivatives $\frac{\partial f(x,y)}{\partial x}$ and $\frac{\partial f(x,y)}{\partial y}$ as well as the position $(x_i, y_i)$ at which these partial derivatives were obtained, is it possible to obtain the partial derivative of $f(x,z)$ with respect to a new variable $z = x y$ while keeping $x$ constant, i.e. $\frac{\partial f(x,z)}{\partial (z)}$ at the same point $(x_i, y_i)$ , or $(x_i, x_i y_i)$ ?","['partial-derivative', 'multivariable-calculus', 'derivatives']"
4148431,Volume integral over a cone,"I'm trying to integrate $I = \rho\int_V(y^2+z^2)dv$ over a cone of base radius $R$ and height $H$ , where $\rho$ is a constant. The coordinates $y$ and $z$ are coordinates of the volume element. In cylindrical coordinates, we have $$dv = rdrd\theta dz$$ and $$y = r\sin \theta$$ Now the integral $I$ should be $$I = \int_0^R\int_0^{2\pi}\int_0^H(r^3\sin^2\theta+z^2r)drd\theta dz$$ Is this conversion to cylindrical coordinates correct? The background of the question is the moment of inertia tensor of said cone.","['integration', 'multivariable-calculus', 'cylindrical-coordinates', 'multiple-integral']"
4148450,Angle of triangle,"Let $ABC$ be a triangle such that $\angle ABC=20^\circ$ , $AB=BC$ . Let $D \in AB$ , $E \in BC$ , $AD=BE=AC$ . Find angle $\angle BDE$ . Does this problem have a nice geometric solution? I don't like my trigonometric solution. Let $AC=b$ , $AB=a$ , $\angle BDE=x$ . From triangle $BDE$ we have: $$\frac{b}{\sin x}=\frac{a-b}{\sin\left(20^\circ+x\right)}$$ Then $\sin20^\circ \cot x+\cos20^\circ=\frac{a}{b}-1$ .
But $$\frac{a}{b}-1=\frac{\sin80^\circ }{\sin20^\circ}-1=2\cos20^\circ $$ Then $\cot x =\cot 20^\circ $ . Then $\angle BDE=20^\circ$ .","['euclidean-geometry', 'geometry', 'plane-geometry']"
4148459,Definitive integral from derivative,"I have a simple differential equation: $$\frac{\partial p(x,y)}{\partial y} = -g$$ $y$ is defined from $-1$ to $\zeta$ , and I also have a boundary condition, which is: $$y=\zeta:p=sinh(x)$$ I am 100% sure that the problem is stated correctly, but it looks to me that these two conditions: $y=\zeta:p=sinh(x)$ $y$ is defined from $-1$ to $\zeta$ contradict each other, because using the first condition I am getting: $p=-gy + F(x)$ and $F(x)=sinh(x)+g \zeta$ , so the full solution would be $p(x,y)=-gy+sinh(x)+g\zeta$ .
But by taking the definite integral from $-1$ to $\zeta$ I am getting $\int_{-1}^{\zeta} \frac{\partial p(x,y)}{\partial y} dy = p(x,y)=-g(\zeta+1)$ So, can someone tell me where is my mistake?","['definite-integrals', 'derivatives']"
4148490,Hitting time of open set for adapted cadlag process is stopping time,"Variants of this question have been asked many times (e.g. here ) but none of them touch on a particular step. I will first state the theorem and proof (from Protter's Stochastic Integration and Differential Equations } and then my attempt afterwards. Theorem statement: Let $X_t$ be a adapted cadlag process and let $\Lambda$ be an open set. Then the hitting time, T, of $\Lambda$ for $X_t$ is a stopping time. Proof from Protter: It suffices to show $\{T<t\} \in \mathcal{F}_t$ , $0 \leq t \leq \infty$ . We have, \begin{equation} \{T < t\} = \bigcup_{s\in \mathbb{Q} \cap [0, t)} \{X_s \in \Lambda\}. \end{equation} Then, $\{X_s \in \Lambda\} = X_s^{-1}(\Lambda) \in \mathcal{F}_s$ since $X_s$ is measurable and $\Lambda$ is open. Hence, $\{T < t\} \in \mathcal{F}_t$ and since $t$ was arbitrary the result
follows. Now, the part I do not completely follow is the equality: \begin{equation} \{T < t\} = \bigcup_{s\in \mathbb{Q} \cap [0, t)} \{X_s \in \Lambda\}. \end{equation} So I have tried to fill in the gaps, here is my proof of the above equality: First, \begin{equation} \{\omega:T(\omega)<t\} = \{\omega: \exists s<t \text{ such that } X_s(\omega) \in \Lambda\} =\bigcup_{s\in [0, t)} \{ \omega: X_s(\omega) \in \Lambda\}. \end{equation} So it suffices to
show equality of $A :=\bigcup_{s\in [0, t)} \{ X_s \in \Lambda\}$ and $B:=\bigcup_{s\in \mathbb{Q} \cap [0, t)} \{X_s \in \Lambda\}$ .
Clearly $B \subset A$ . To show $A \subset B$ , take $\omega \in A$ .
Then $\exists s<t$ with $X_s(\omega) \in \Lambda$ (and we assume $s \not\in \mathbb{Q}$ ).
Then there exists a sequence $\{s_n\}$ such that $s_n \searrow s$ through $\mathbb{Q}$ . This implies, by right
continuity of paths of $X_t$ , that \begin{equation} X_s(\omega) = \lim_{n\rightarrow \infty}X_{s_n}(\omega) \end{equation} Since $\Lambda$ is open and $X_s(\omega) \in \Lambda$ , then $s_N \in \mathbb{Q}$ , $s_N < t$ can be chosen with $X_{s_N}(\omega) \in \Lambda$ . This implies $\omega \in B$ and we are done. Is my attempt at filling in the gaps correct?","['stochastic-processes', 'stopping-times', 'probability-theory']"
4148515,A property of natural filtrations,"Let $(X_t)_{t \in [0,\infty)}$ be a stochastic process, and let $\mathcal{F}_t$ be the natural filtration generated by $X_t$ ; i.e. $$\mathcal{F}_t=\sigma(X_s:0\leq s \leq t).$$ Now we fix a $t \in [0,\infty)$ . Let $A \in \mathcal{F}_t$ and let $\omega \in A$ . Suppose that $\omega'\in \Omega$ satisfies $$X_s(\omega)=X_s(\omega')$$ for any $s \in [0,t]$ . How can we show that $\omega'\in A$ ?","['stochastic-processes', 'probability-theory']"
4148522,Upper semicontinuity in real analysis,"Exercise from book: Let $\left(f_{k}\right)_{k=1}^{\infty}$ be a sequence of functions and suppose that they are all upper semi-continuous at $x_{0}$ . Define the function $g$ by $g(x)=\inf _{1 \leq k<\infty} f_{k}(x)$ . Show that $g$ is upper semi-continuous at $x_{0}$ . My attempt: By definition of upper semi continuity we have $\lvert x-x_0\rvert \Longrightarrow f_{k}(x) < f_{k}(x_0)+\varepsilon$ $ \inf f_{k}(x) < f_{k}(x_0)+\varepsilon$ I think it completes the proof.
Is it right or I missing something????? I am not familiar with topology. so I am interested in only real analysis terms","['semicontinuous-functions', 'functions', 'real-analysis']"
4148527,Why is $\nabla_{\mathbf{x}}z \not= \nabla_{\mathbf{y}}z \times \frac{\partial\mathbf{y}}{\partial\mathbf{x}} $?,"I'm learning about the chain rule to compute the gradient, w.r.t to a subset of its variables, of a function that is a composition of vector-fields.
Let $\mathbf{x}\in \mathbb{R}^m, \mathbf{y}\in \mathbb{R}^n, \mathbf{g}:\mathbb{R}^m\to\mathbb{R}^n, f:\mathbb{R}^n\to \mathbb{R}$ . The result is ""If $\mathbf{y}=\mathbf{g}(x), z=f(\mathbf{y})=f(\mathbf{g}(x))$ , then $\nabla_{\mathbf{x}}z=\left(\frac{\partial\mathbf{y} }{\partial\mathbf{x}}\right) ^T \times \nabla_{\mathbf{y}}z$ "" But how is this derived?
My initial attempt to derive this is as follows. Please tell me where it's gone astray. $$z=f(\mathbf{g}(x))\implies
\frac{\partial z}{\partial \mathbf{y}} \times \frac{\partial \mathbf{y}}{\partial \mathbf{x}}
=\nabla_{y}z \times \frac{\partial \mathbf{y}}{\partial \mathbf{x}}$$ Where I have used the chain rule to obtain the second equality and the definition of the gradient to obtain the third.
This can't be correct as the dimensions don't agree, the final product an $n \times1 $ matrix times a $n \times m$ matrix. Where have I misapplied the chain rule and/or a definition?
Thanks :) $\nabla_{\mathbf{x}}z \not= \nabla_{\mathbf{y}}z \times \frac{\partial\mathbf{y}}{\partial\mathbf{x}} $","['multivariable-calculus', 'vector-analysis', 'chain-rule']"
4148528,$f$ is measurable $\iff$ $f^{-1}(G)$ is measurable for open $G$.,"$E$ : Lebesgue measurable set $f$ : $E \to \mathbb{R}$ I want to prove $f$ is Lebesgue-measurable function $\iff$ $f^{-1}(G)$ is Lebesgue measurable for all open set $G$ . ( $\Leftarrow$ ) is O.K. For all $a\in \mathbb{R}$ , $\{ f>a \} = \{x\in E | f(x)>a \} = f^{-1}((a, \infty)).$ Since $(a, \infty)$ is open, $f^{-1}((a, \infty))$ is Lebesugue-measurable and so is $\{ f>a \}$ . But I couldn't prove $(\Rightarrow)$ . My attempt is as following. Let $G$ open. Since $G$ is open, I can write $G=\cup_{n=1}^{\infty} O_n$ , where each $O_i$ is open interval and $O_i \cap O_j=\phi (i \neq j).$ $f^{-1}(G)= f^{-1}( \cup_{n=1}^{\infty} O_n)=\cup_{n=1}^{\infty} f^{-1}(O_n)$ . I cannot proceed from here. I would like you to give me some ideas.","['measure-theory', 'lebesgue-measure', 'lebesgue-integral', 'measurable-functions']"
4148615,"Indefinite integration of $\int\frac{1}{\cos(x-1)\cos(x-2)\cos(x-3)}\,\textrm dx$","Integrate $$\int\dfrac{1}{\cos(x-1)\cos(x-2)\cos(x-3)}\,\textrm dx$$ My Attempt: Using, $$\tan A-\tan B=\dfrac{\sin(A-B)}{\cos A\cdot \cos B}$$ The given integral can be transformed as $$\int\dfrac{\tan(x-1)}{\cos(x-2)}\,\textrm dx - \int\dfrac{\tan(x-3)}{\cos(x-3)}\,\textrm dx$$ The right most integral can be calculated easily by writing $\tan(x-3)$ as $\frac{\sin(x-3)}{\cos(x-3)}$ and then by a substituiton $\cos(x-3)$ as $t$ . But I have no clue for the left most integral. How to evaluate that?","['integration', 'indefinite-integrals', 'calculus', 'trigonometric-integrals']"
4148630,"Suppose that $f \in \mathcal{C}^{1}([a, b])$. Prove that $|f(x)| \leqslant \frac{1}{2}|f(a)+f(b)|+\int_{a}^{b}\left|f^{\prime}\right|$","I've tried to prove it through the following way but failed. There is a gap that I can't get through. $$
|f(x)| = \left|\int^b_x f'-f(b)\right| = \left| \int^x_a f'+f(a)\right|,
$$ So $$
2|f(x)|=\left|\int^b_x f'-f(b)\right| + \left|\int^x_a f'+f(a)\right|
$$ Thus $$
2|f(x)|
 = \left|\int^b_x f'-f(b)\right| + \left|\int^x_a f'+f(a) \right|
 \le \left| \int^b_x f'\right| + |f(b)| + \left|\int^x_a f'\right|+|f(a)|
$$ Since we have $$
\left| \int^b_x f' \right| \le \int^b_x |f'|
\quad \text{ and } \quad
\left| \int^x_a f' \right| \le \int^x_a |f'|
$$ Thus $$
\left|\int^b_x f'\right| + \left| \int^x_a f' \right|
 \le \int^b_x |f'| + \int^x_a |f'|
 =   \int^b_a |f'|
$$ But the problem is that I can't have $|f(b)|+|f(a)|\le|f(a)+f(b)|$ So I think I probably went in a wrong way.","['integration', 'real-analysis', 'sobolev-spaces', 'inequality', 'derivatives']"
4148692,Every compact subset of $\mathbb R^1$ is the support of a Borel measure,"I know this already has an answer here , though it is very cryptic. So, I'm making this post for solution/proof-verification (it is not a duplicate) - I've come up with a measure on Borel sets of $\mathbb R$ corresponding to a compact set. Please help me fill in the gaps, if any. Prove that every compact subset of $\mathbb R^1$ is the support of a Borel measure. Here's my work: Suppose $A \subset \mathbb R$ is compact. Compact metric spaces are separable, so there exists a set $B = (b_n)_{n\in\mathbb N} \subset A$ which is dense in $A$ (i.e. $\overline B = A$ w.r.t. the subspace topology on $A$ ). Define $\mu$ on Borel sets of $\mathbb R$ as follows, where $\delta_p$ is the dirac measure at point $p\in\mathbb R$ . Note that $\delta_p(X) = 1$ if $p\in X$ and $\delta_p(X) = 0$ if $p\not\in X$ , for every $X\subset\mathbb R$ . Also we know that the support of $\delta_p$ is $\{p\}$ , and the support of a finite sum of measures is the (finite) union of their supports. If $C$ is a Borel set in $\mathbb R$ , $$\mu(C) = \sum_{n=1}^\infty \frac{\delta_{b_n}(C)}{2^n}$$ To check that $\mu$ is a measure, we need to show that $\mu$ is countably sub-additive. I think it suffices to notice the countable sub-additivity of Dirac measures. Unfortunately, I'm unable to characterize the support of $\mu$ , because it is only in the finite case that we are allowed to union over the supports. However, I do feel that the above construction suffices. Could I please get some help in completing my proof? Thank you! Follow-up questions: What is special about Borel sets in this construction? Can we define $\mu$ over a larger $\sigma$ -algebra? There must be something special about Borel sets, otherwise, the statement would probably not be framed this way. How do we deal with the case when $K = \varnothing$ ? What's the corresponding measure? If $B$ is finite, I think we cannot work with the finite sum. Instead, if we have distinct $b_1,b_2,\ldots,b_N$ , we can define $b_n := b_N$ for $n > N$ ? (See this link ). Please clarify. The book gives questions 11 and 12 together (image below for reference) - so are we supposed to use the definition of support from Q11 in Q12? Hopefully, it is equivalent to the one here .","['measure-theory', 'borel-measures', 'solution-verification', 'borel-sets', 'compactness']"
4148694,How many words can you create of length 6 with given properties?,"How many words can you create of length 6, from the letters a, b, c
and d if you must include each letter at least once you must include each letter at least once, and a must appear exactly once. My take: 1. a b c d _ _ , I first try to find every variation of abcd fitting into 6 places, I have less elements then places so I flip the roles and think like, 6 places going into 4 elements so I get: $P(^6_4)$ Now I multiply this by the amount of variations with repetition that abcd can take in _ _ . Which is: $$\bar{P}\binom42= n^p=4^2 = 16$$ So my answer is: $$P\binom 64\cdot16$$ However the answer sheet tells me it's $
3*\binom6{2,2,1,1} = 540$ and I have no idea why","['combinatorics-on-words', 'combinatorics']"
4148700,Second-order linear homogenous ODE - I can't see any substitution!,"$$y'' - y' + e^{2x}y=0$$ At first it looks like it's an easy ODE, but I haven't been able to solve it. For example, if I let $y=u(x)\cdot z, z(x)$ and accordingly choose $u$ so that the coefficient of $z'$ (after performing the necessary derivations and grouping all terms by the order of derivation of $z$ ) is zero, I get the following equation: $$z'' + (e^{2x} - \frac{1}{2})z = 0$$ which isn't any easier to solve than the first one. I'm having trouble with this equation because I don't think there's an apparent substitution to be done. Can anyone help? Thanks!",['ordinary-differential-equations']
4148701,"Is $f(x,y)\in L^1([0,1]\times[0,1])$?","I have to study the Lebesgue integrability of $f(x,y)=\dfrac{x-y}{(x+y)^3}$ on $Q=[0,1]^2\subseteq\mathbb R^2$ . The sign of $f$ is variable in $Q$ , so I studied $|f(x,y)|=\dfrac{|x-y|}{(x+y)^3}$ in order to apply Tonelli's theorem (because $|f|$ is positive and measurable in $Q$ and I can evaluate the iterated integrals). $$\iint_{Q}|f(x,y)|dxdy=\iint_{[0,1]^2}|f(x,y)|dxdy=\int_0^1dy\int_0^1\dfrac{|x-y|}{(x+y)^3}dx$$ with the change of variable $\begin{cases}u=x-y\\v=x+y \end{cases}\implies\begin{cases}x=\dfrac{u+v}{2} \\y=\dfrac{v-u}{2}\end{cases}$ I have $|\det(J)|=\dfrac{1}{4}$ , with $\begin{cases}0<u+v<2\\0<v-u<2 \end{cases}$ as new set  of integration $\tilde Q$ in $(u,v)$ -plane. So we obtain $$\dfrac{1}{4}\Bigg(\int_{-1}^0|u|du\int_{-u}^{2+u}\dfrac{dv}{v^3}+\int_{0}^1|u|du\int_{u}^{2-u}\dfrac{dv}{v^3}\Bigg)=$$ $$=\dfrac{1}{4}\Bigg(\int_{-1}^0\dfrac{u}{2(2+u)^2}-\dfrac{1}{2u}du+\int_{0}^1\dfrac{-u}{2(2-u)^2}+\dfrac{1}{2u}du\Bigg)$$ and I think that this shows that $f\notin L^1([0,1]^2)$ .","['lebesgue-measure', 'lebesgue-integral', 'multivariable-calculus', 'solution-verification', 'multiple-integral']"
4148704,Find the intersection of $z=1-x^2$ and $x=y^3$ in $\mathbb R^3$,"I have these 2 surfaces, given in their Cartesian form, and want to find the resulting surface of intersection. My approach is to find parametric representations. But I have two approaches, and not sure if both approaches are proper, or if one or the other is only proper. Here are the equations: $$\tag{1}z = 1 - x^2$$ $$\tag{2}x = y^3$$ Approach 1 : Substitute (2) into (1),  we get the cartesian form of the intersection surface: $z = 1 - x^6$ , then try to parameterize this, but I run into $2$ independent parameters with this approach. Approach 2 : Direct parameterization: Just looking at both equations I see that ' $x$ ' is the common variable so I set $x= t$ . Then just plugging in ' $t$ ' into the equations, and put them together in $(x,y,z)$ , I get: $$(x,y,z) = (t, t^{1/3}, 1-t^2)$$ So not sure if either of these 2 approaches above give the correct parameterization. Not sure if there is a systematic procedure to do parameterization of surfaces of intersection in $\mathbb R^3$ , or if this is a creative type of process, and hence there is no systematic procedure to follow. Hope someone can explain how to think about this kind of problem.","['curves', 'multivariable-calculus', 'surfaces', 'differential-geometry']"
4148735,"If a (possibly nonconvex) pentagon tiles the plane, can it do so periodically?","From the classification of monohedral tilings with convex pentagons , we know that all convex pentagons which tile the plane can do so periodically; I'd like to know whether the same result is known to extend to non-convex pentagons. That is, if congruent copies of a pentagon $P$ tile the plane, is there necessarily one such tiling which is composed of a single patch of finitely many tiles, translated periodically in a lattice? There are unlikely to be any known counterexamples, since the Einstein problem remains open, but I am curious whether there exists a proof of this statement - if so, a reference would be appreciated.","['tessellations', 'geometry', 'tiling', 'reference-request']"
4148781,"Solving differential equation without IVP or fundamental solution : $\displaystyle \phi ^{""} -x \phi ^{'} + x^2 \phi = 0 $","While studying about Differential Equations I randomly came up with  the equation mentioned below. $\displaystyle \phi ^{""} -x \phi ^{'} + x^2 \phi = 0  $ is actually the equation I got while solving for the RICCATI EQUATION : $$\displaystyle y' = x^2 + xy + y^2 $$ When we use the substitution $\displaystyle y = \frac {- \phi ^{'} }{\phi} ,$ one can get the above mentioned Second Order homogeneous differential equation. My attempt : I thought to think of a general solution to $ \ \displaystyle \phi ^{""} -x \phi ^{'} + x^2 \phi = 0  $ So I used the same old ordinary technique, THE CHARACTERISTIC EQUATION ( i.e substituting $ \ \displaystyle \phi = e^{rx}) $ We will a quadratic equation : $ \ \displaystyle r^2 - rx + x^2 = 0 ; \text {giving} \ r= -x\omega , -x \omega ^2 .$ Then choosing any one of them, and using ABEL's theorem, I found another LINEARLY INDEPENDENT SOLUTION, using Wronskian (by definition). (But I doubt on their Linear Independent nature) But it was too complicated. Let me show you. Assuming $ \ \displaystyle r = -x \omega ^2 $ , one will get : $$ \displaystyle \phi = c_1 e^{x^2/2}. e^{\iota \sqrt {3}x^2/2}  - \frac {c_2 }{x^3 + x + \iota 2\sqrt {3} \ x} \left ( e^{-x^4/4}. e^{\iota \sqrt {3} x^2 /2} \right ) $$ Now solving for $y$ would be hard. But when I found solution for the Riccati equation on wolfram, it showed : $ \ \displaystyle y = \frac {1}{c - x} - \frac {x}{2}  .$ I would like to know that the function $\phi$ which I found is general or not. And if there is a method to find the solution to second order differential equation with variable coefficients (homogeneous or non-homogeneous) without the knowledge of any prior common function that solves the equation. And please tell a good method to solve for the Riccati equation mentioned above. Edit the tags if required, i do not know what to add more. EDITS: In relation to the comment by Winther , when I checked for the solution provided by wolfram... it did not satisfy the equation. Please share a method to solve it. THANK YOU.",['ordinary-differential-equations']
4148783,Does the truth of one imply the other? A simple Collatz generalization in terms of primes.,"Let $f_i:\mathbb{N} \to\mathbb{N}$ . The Collatz function states that the following iterated map will eventually equal to 1: $$f_0(n) =
\begin{cases}
n/2,  & \text{if}\  2\mid n\\
3n+1, & \text{otherwise} \\
\end{cases}$$ Noting that $2$ and $3$ are the first two primes I extended the Collatz conjecture prime by prime in the following way: First extension $$f_1(n) =
\begin{cases}
n/2,  & \text{if}\  2\mid n\\
n/3,  & \text{if}\  3\mid n\\
5n+1, & \text{otherwise} \\
\end{cases}$$ Second extension: $$f_2(n) =
\begin{cases}
n/2,  & \text{if}\  2\mid n\\
n/3,  & \text{if}\  3\mid n\\
n/5,  & \text{if}\  5\mid n\\
7n+1, & \text{otherwise} \\
\end{cases}$$ Third extension $$f_3(n) =
\begin{cases}
n/2,  & \text{if}\  2\mid n\\
n/3,  & \text{if}\  3\mid n\\
n/5,  & \text{if}\  5\mid n\\
n/7,  & \text{if}\  7\mid n\\
11n+1, & \text{otherwise} \\
\end{cases}$$ ....and so on. Surprisingly, or not so surprisingly, I ran a small test on this generalization for $n\leq40,000$ and found that for the first and second extensions, all numbers return to 1 but for the third extension a single cycle results when $n = 17$ , that is, $17 \to 188 \to 94 \to 47 \to 518 \to 259 \to 37 \to 408 \to 204 \to 102 \to 51 \to 17$ . My motivation for this generalization is this paper showing a link between Collatz and primes (see page 10). Questions: Has such generalization been studied before? Does it even make sense? If the Collatz problem, $3n +1$ , has no unbounded/diverging trajectory, does that imply the same for the extensions? Or how does one go about proving or disapproving this assertions? For my second question, I am leaning 'yes' because having more primes to divide by would only shrink the trajectory toward 1 faster; besides, if we divide any natural number by all primes that it is divisible by, as many times as possible, the transformation shrinks to 1 due to the Fundamental Theorem of Arithmetic.","['collatz-conjecture', 'number-theory', 'distribution-of-primes', 'iterated-function-system']"
4148786,Where is the mistake in my proof of $\lim_{x \to 0} f(|x|)=l \implies \lim_{x \to 0} f(x)=l$?,"Assume that $f:(-a,a) \setminus{0} \to \mathbb{R}$ . Does the implication $\lim_{x \to 0} f(|x|) =l \implies \lim_{x \to 0} f(x)=l$ hold? My textbook gives a counter-example of this statement using the example $f(x)=[|x|]$ ; before finding out a counter-example myself, I've tried to prove this and made a proof that is of course wrong (so I naively stopped searching for counter-examples; bad behaviour). However, I would like to learn from my mistake and identify where is my wrong reasoning. Can someone help me find where the mistake is? Wrong proof: by hypothesis $\lim_{x \to 0} f(|x|)=l$ , so it is true that for all $\epsilon>0$ there exists $\delta(\epsilon)>0$ such that for all $x\in(-a,a)\setminus{0}$ , $|x|<\delta(\varepsilon)\implies |f(|x|)-l|<\epsilon$ . But $|x|=||x||$ , so the condition $|x|<\delta(\varepsilon)$ is equivalent to $||x||<\delta(\varepsilon)$ ; so it is true that for all $\epsilon>0$ there exists $\delta(\epsilon)>0$ such that for all $x\in(-a,a)\setminus{0}$ , $||x||<\delta(\varepsilon)\implies |f(|x|)-l|<\epsilon$ . This (I believe) mean that $\lim_{|x|\to 0} f(|x|)=l$ ; letting $|x|=r$ , it is $\lim_{r \to 0} f(r)=l$ . Since (I believe) the variable in the limit is dummy, this means $\lim_{x \to 0} f(x)=l$ . I've written ""I believe"" in the steps I'm not sure about. My first impressions in trying to recognize my mistakes is that probably I'm using wrong the definition of limit or the theorem of change of variables in limits. Thanks to anyone who wants to help me.","['limits', 'solution-verification', 'analysis']"
4148793,"Munkres' *Topology,* 2nd edition, Theorem 34.3 at page 218, confusion.","I am currently learning point-set topology via the book “Topology, 2nd edition” written by James Munkres. Theorem 34.3 at page 218 states that a space $X$ is completely regular if and only if it is homeomorphic to some arbitrary product of interval $[0,1]$ in the uniform topology. First things first, the definition of Munkres of completely regular space, is $T_{3 \, \frac{1}{2}}$ (Tychonoff space). If this theorem is true, it implies that a Tychonoff space is metrizable and that a $T_4$ space is metrizable since it is homeomorphic to some arbitrary product of interval $[0,1]$ equipped with uniform topology which is metrizable. However we can find examples of $T_4$ space that are not metrizable. What is the issue? What did I miss?","['general-topology', 'metric-spaces', 'separation-axioms']"
4148825,How many Non-Borel sets are there?,"I'm currently doing a course on measure theoretic probability. In the course I learned that the cardinality of Borel $ \sigma $ -algebra $ \mathscr{B} $ is the same as that of continuum $ \mathbb{R} $ . But what is the cardinality of the set of Non-Borel Sets, let's call it $ \mathcal{S} $ . My inital guess is along these lines. That since $ \mathcal{S} = \mathscr{B^{c}} $ . We can write that, $$ \mathbb{2^R} = \mathcal{S} ~ \cup \mathscr{B} $$ Assume that $ \mathcal{S} $ has the same cardinality as $ \mathbb{R} $ . Now we know that $ \mathscr{B} $ also has the same cardinality as that of $ \mathbb{R} $ . But their union $ \mathbb{2^R} $ has a stricly greater cardinality than $ \mathbb{R} $ . Again assuming that union of uncountable sets of same cardinality has the same cardinality (I'm aware that this is true for countable sets, but not sure about uncountables), this results in a contradiction. Hence the set $ \mathcal{S} $ must have a strictly bigger cardinality than $ \mathbb{R} $ . Are the approach and the conclusion correct?","['borel-sets', 'measure-theory', 'set-theory']"
4148826,"Test for convergence for all $\alpha \in [0, 1)$ series $\sum_{n=1}^{\infty} \frac{(-1)^{\lfloor\sqrt{n}\rfloor}}{n^{\alpha}}$","$
%Define large versions of lfloor and rfloor (big enough to handle sqrt).
 \newcommand{\lf}{\large \lfloor \normalsize}
 \newcommand{\rf}{\large \rfloor \normalsize}
$ Note: $\lf\sqrt{n}\rf$ denotes integer part of $\sqrt{n}$ (floor rounding). So, I have such series $$A :=\sum_{n=1}^{\infty} a_n$$ where $$a_n = \frac{(-1)^{\lf\sqrt{n}\rf}}{n^{\alpha}}$$ This is what I tried to do: Let's group our $a_n$ such way that by doing that all elements in group will have same sign. If series that we get after grouping sequence such way converges, initial series will converge also. Let's denote by $t$ minimal $n$ such that $\lf \sqrt{n} \rf = t$ . 
But that means that $n = t^2$ . Now let's find other elements of that group. $ \lf\sqrt{n}\rf
= \lf\sqrt{t^2}\rf
= \lf\sqrt{t^2 + 1}\rf
= \lf\sqrt{t^2 + 2}\rf = \cdots
= \lf\sqrt{t^2 + 2t}\rf$ . We have $2t + 1$ elements in each group. So we can see how our series would look like $$\large\sum_{t = 1}^{\infty}\normalsize
\sum_{n = t^2}^{t^2 + 2t}\frac{(-1)^t}{n^{\alpha}}$$ Now we can see that $$(2t + 1) \cdot \frac{1}{(t^2 + 2t)^{\alpha}} \le \sum_{n = t^2}^{t^2 + 2t}\frac{1}{n^{\alpha}} \le (2t + 1) \cdot \frac{1}{(t^2)^{\alpha}}$$ So, is it accurate to say that for $\alpha \in (\frac{1}{2}, 1)$ we have convergence here? For instance, by applying Leibniz criterion. I have doubts since I apply it not to my sequence $a_n$ but to the sequence that I was able to use to evaluate it from right side (however, I believe that the one on the left is also such that $b_n \searrow 0$ and $b_n \ge 0$ if $\alpha \in \big(\frac{1}{2}, 1)$ ). And of course for $\alpha = 0$ it diverges. But what about case of $\alpha \in (0, \frac{1}{2}\big]$ ? How to see what happens there? And did I show everything right in case of $\alpha \in \big(\frac{1}{2}, 1)$ ? Idea: may be we can use evaluation of sum of each of block using definite integral? At least it’s absolute value. $|\sum_{n = t^2}^{t^2 + 2t}\frac{(-1)^t}{n^{\alpha}} - (-1)^t\int_{t^2}^{t^2 + 2t + 1} x^{-\alpha} dx| \le (t^2)^{-\alpha} - (t^2+2t + 1)^{-\alpha}$ . I tried to use it but it did not help much. All help will be appreciated!","['calculus', 'convergence-divergence', 'sequences-and-series']"
