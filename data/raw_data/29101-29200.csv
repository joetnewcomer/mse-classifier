question_id,title,body,tags
270373,If $P(A)=0$ then $A=\emptyset $?,Let $P$ be a probability function. It satisfied probability axioms . Can we deduce from it that if $P(A)=0$ then $A=\emptyset $ ?,"['probability-theory', 'probability']"
270385,What can we say about the map $G\mapsto \text{Aut}(G)$ on the proper class of all groups?,"Let's call $\frak{G}$ the class of all groups. Let's consider on $\frak{G}$ the equivalence relation $\sim$ such that $G \sim G' \Leftrightarrow \exists \varphi $ isomorphism of groups such that $G=\varphi(G')$ Consider $\chi: (\frak{G}/\sim) \rightarrow (\frak{G}/\sim)$ such that $\chi([G]_{\sim})=[Aut(G)]_{\sim}$. What can I say about $\chi$ (one-to-one, onto)? What if I just consider finite groups?","['category-theory', 'finite-groups', 'group-theory', 'abstract-algebra']"
270393,How to prove Boole’s inequality,I am trying to prove Boole’s inequality $$P\left(\ \bigcup_{i=1}^\infty A_i\right) \leq \sum_{i=1}^\infty P(A_i).$$ I can show it of any finite $n$ using induction. What to do for $\infty$ ?,['probability']
270401,"Any partition of $\{1,2,\ldots,9\}$ must contain a $3$-Term Arithmetic Progression","Prove that for any way of dividing the set $X=\{1,2,3,\dots,9\}$ into $2$ sets, there always exist at least one arithmetic progression of length $3$ in one of the two sets.","['ramsey-theory', 'combinatorics']"
270429,What are the probabilities of a tie when rolling to see who goes first in a board games for various numbers of dice and various numbers of players?,"When playing many board games, the first step is to have everyone roll a die to see who goes first, with a roll off in the case of a tie.  While doing that over the Christmas break, my husband suggested that we roll two dice instead of one, with the assertion that this would make ties less likely.  My brother disagreed, claiming it wouldn't make any difference.  I'm interested in investigating this question. I've been able to calculate the probability of ties for the case of rolling one die for any number of players, and the case for rolling two dice with two players.  However, I haven't actually found a general solution in either case (I mostly used a brute force approach in the one die case).  Is anyone here aware of any sources that have investigated this issue? (For the record, I'm pretty sure both my husband and brother have forgotten the conversation, so you don't need to worry about hurting anyone's feelings.  :) )","['dice', 'probability']"
270444,"Two player pool, probability of winning","I have what seems like a simple question, but it's been a while since I've done any P/S. So i come to SE for help! Two player pool/billiards: P1 has probability p of sinking a ball on any shot and has N balls remaining, while P2 has prob q and M balls remaining. Question: What is the probability of the first player winning? I can type out my reasoning (and will in an edit - will post before i reason it out though), but my answer has come down to: $$\sum_{j=0}^{M-1} [p^N q^j \sum_{i=0}^\infty [(1-p)^i (1-q)^i]]$$ Is this correct or close? Reasoning: not really theoretical reasoning, but extrapolating the simple cases outwards: (hit = h, miss = m, with probability p = w/p) 1 ball each: possible victory paths - P1 wins w/p, P1 m w/ (1-p), P2 m w/ (1-q), P1 wins w/ p ... etc - $p \sum_{i=0}^\infty (1-p)^i (1-q)^i$ 2 and above balls each: At some point, all the P1 hits must occur - $p^N$ All possible amounts of P2 hits must be accounted for - $\sum_{j=0}^{M-1} q^j$ Every miss variation is accounted for - * <-- This is where i think I am wrong. Is it actually a double sum in and of itself? IE $\sum_{i=0}^\infty \sum_{k=0}^\infty (1-p)^i (1-q)^k$ ? EDIT: Some wolfram alpha shows me that $\sum_{i=0}^\infty (1-p)^i = \frac 1 p$, so I guess my final final equation can be simplified to $$\sum_{j=0}^{M-1} \frac{p^N q^j}{pq} $$ ?? etc.",['probability']
270466,$f(X)$ dense in $Spec A$,"I have some problems solving the following exercise from Liu's book Algebraic Geometry and Arithmetic Curves , exercise 3.15 from chapter 2. Let $X$ be a quasi-compact scheme, $A=O_X(X)$. Let us consider the morphism $f:X\rightarrow Spec(A)$ induced by the identity on $A$. Show that $f(X)$ is dense in $Spec(A)$. So I want to prove that for every distinguished open $D(g)$ of $Spec(A)$, the intersection $f(X)\cap D(g)\neq\emptyset$.
Following my intuition, I would like to prove that the image of $X_g=\{x\in X\,|\,g_x\in O_{X,x}^*\}$ is in $D(g)$. (I have this idea, because $O_X(X_g)\simeq O_X(X)_g=A_g$, which is equal to $O_{Spec A}(D(g))$.) I don't know how to really prove this, and I don't see where to use the quasi-compactness condition. Thank you in advance!","['algebraic-geometry', 'schemes']"
270469,Smash product of pointed spaces is not associative,"I've read many times that the smash product of pointed topological spaces is not associative, for example $\mathbb{N} \wedge (\mathbb{Q} \wedge \mathbb{Q})$ is not homeomorphic to $(\mathbb{N} \wedge \mathbb{Q}) \wedge \mathbb{Q}$. How to prove this? In general $\mathbb{N} \wedge X = \bigvee_{n>0} X$, so that $\mathbb{N} \wedge (X \wedge Y) = \bigvee_{n>0} (X \wedge Y)$ and $(\mathbb{N} \wedge X) \wedge Y = (\bigvee_{n>0} X) \wedge Y$. By the universal property of the wedge sum, we get a canonical continuous map
$$\mathbb{N} \wedge (X \wedge Y) \to (\mathbb{N} \wedge X) \wedge Y,~(n,(x,y)) \mapsto ((n,x),y).$$
It is clearly bijective. For $X=Y=\mathbb{Q}$ it should not be open - why? Probably one has to take some open subset of $\mathbb{Q} \times \mathbb{Q}$ which approaches the base point $(0,0)$ in a weird way? Can someone explain/supplement Joriki's proof?","['general-topology', 'examples-counterexamples']"
270471,Where is the mistake using trivial formulas for conditional expectation?,"I want to calculate a conditional expectation and I do not see where my mistake is. I'm solving the following exercise (namely, 1a): ( source ) Here $S^1,S^2$ are stochastic processes, which model for example a stock price. At time (day) $0$, $S^1_0=100$, which means that the price of stock one is $100$ unit of money. Then the stock price can go up, with probability $p_u=\frac{2}{3}$ and go down with prob. $p_d=\frac{1}{3}$. Hence at day $1$ it can take the prices $S^1_1=104$ or $S^1_1=98$ and so on. The exercise want to construct an equivalent martingale measure for $S^1$.
To have an equivalent martingale for $S^1$ I need to find transition probabilities $q_u,q_d=1-q_u$ (u=up, d=down) and $q_{u,u},q_{u,d}=1-q_{u,u},q_{d,u},q_{d,d}=1-q_{d,u}$ such that $S^1=(S^1_k), k=0,1,2$ is a $Q^1$-martingale. The equivalence of the measure follows immediately if $q_j,q_{j,i}>0$, $i,j\in\{u,d\}$. The filtration is generated by $S^1$, i.e. $\mathcal{F}_0=\sigma(S^1_0)$ which is trivial and $\mathcal{F}_1=\sigma(S^1_1)$. To be a martingale under the measure $Q^1$ (which is characterized by transition probabilities $q_j,q_{j,i}$ $i,j\in\{u,d\}$ we have to solve the equations: $$E_{Q^1}[S^1_1]=100$$
$$E_{Q^1}[S^1_2|\mathcal{F}_1]=S^1_1$$ the first one is easy to solve and gives $q_u=\frac{1}{3}$ and $q_d=\frac{2}{3}$. Now for the second equation I want to use that $\mathcal{F}_1$ is generated by $\sigma(A_1,A_2)$, where $A_1=\{S^1_1=104\},A_2=\{S^1_1=98\}$. Then I know that $$E_{Q^1}[S^1_2|\mathcal{F}_1]=\sum_{j=1}^2\frac{E[S^1_2\mathbf1_{A_j}]}{Q^1[A_j]}\mathbf1_{A_j}$$ hence for writting this out gives two equations: $$\frac{1}{Q^1[A_1]}(116.48\cdot q_{u,u}+(1-q_{u,u})\cdot 99.84)=104$$
$$\frac{1}{Q^1[A_2]}(101.92\cdot q_{d,u}+(1-q_{d,u})\cdot 96.04)=98$$ where clearly $\frac{1}{Q^1[A_1]}=\frac{1}{q_u}$ and $\frac{1}{Q^1[A_2]}=\frac{1}{q_d}$. I would get the right result without the $\frac{1}{Q^1[A_j]}$ in the front of the equations. But I do not see why they do not have to be there. Right result: $q_{u,u}=\frac{1}{4}$, $q_{d,u}=\frac{1}{3}$. It would be very helpful, if someone could point out, where I my mistake is exactly. As mentioned in the comment, I used the following theorem for calculating the conditional expectation: Let $(\Omega,\mathcal{F},P)$ be a prob. space, $A_i\in \mathcal{F}$, for $1\le i\le N\le\infty$ pairwise disjoint measurable sets with $P(A_i)>0$ and $\bigcup_{i=1}^N A_i=\Omega$. Let $\mathcal{A}=\sigma(A_i;1\le i\le N)$. Let $X\in L^1(\Omega,\mathcal{F},P)$, then
  $$E[X|\mathcal{A}]=\sum_{i=1}^N\frac{E[X\mathbf1_{A_i}]}{P(A_i)}\mathbf1_{A_i}$$","['probability-theory', 'probability']"
270479,Spivak's Proof of Inverse function theorem (2nd question),"Suppose $\det f^\prime(a) \neq 0$, $f$ is continuously differentiable in an open set containing $a$. Spivak then show that there exist a closed rectangle $U$ containing $a$ in its interior such that $f(x) \neq f(a)$ for all $x \in U$. Question1: Spivak then asserts that since $f$ is continuously differentiable in an open set containing $a$, therefore $\det f'(x) \neq 0$ for all $x \in U$. Why? Question 2: $|D_j f^i (x)-D_j f^i (a)|<\tfrac{1}{2n^2}.$ How can we prove it?",['multivariable-calculus']
270495,How can an ultrafilter be considered as a finitely additive measure?,"From Wikipedia an ultrafilter $U$ on a set $X$ is a collection of subsets of $X$ that is a filter, that cannot be enlarged (as a filter). An ultrafilter may be considered as a finitely additive measure. Then every subset of $X$ is either considered ""almost everything"" (has measure 1) or ""almost nothing"" (has measure 0). ... define a function $m$ on the power set of $X$ by setting $m(A) = 1$ if $A$ is an element of $U$ and $m(A) = 0$ otherwise. Then $m$ is a finitely additive measure on $X$, and every property of elements of $X$ is either true almost everywhere or false almost everywhere. It says ""an ultrafilter may be considered as a finitely additive measure."" However, I only see how an ultrafilter induces a finitely additive measure, and don't see how a finitely additive measure induces an ultrafilter. In order for  a finitely additive measure to induce an ultrafilter, I think it is not enough that for any subset $A$ of $X$, either $m(A) = 1$ and $m(X-A) = 0$ or  $m(X-A) = 1$ and $m(A) = 0$, isn't it? Thanks and regards!","['filters', 'measure-theory', 'elementary-set-theory']"
270516,Clarification of Frobenius method roots,"The frobenius method states that for repeated roots or roots that differ by an integer, an alternative method must be used to find the second solution once one is found. When they say ""roots that differ by an integer"", does this mean any integer? Or only by the integer one? Because upon solving the differential equation $y'' - \frac{6y}{z^2} = 0$ I received roots $\sigma = 3, -2$. these both solved the equation as $y = c_1 z^3 + c_2 z^{-2}$ and this alternative method for a second solution was not required. $$y(z) = \sum_{n = 0}^{ \infty} a_n z^{\sigma + n}$$ $$y'' = \sum_{n = 0}^{ \infty} (\sigma + n)(\sigma + n - 1) a_n z^{\sigma + n - 2}$$ Plugging these in and setting $n = 0 \forall n >0$ I find the relation for $\sigma$ $$(\sigma(\sigma - 1) - 6)a_0 = 0$$ Because we demand that $a_0 \neq 0$ We find $\sigma = 3, -2$","['ordinary-differential-equations', 'sequences-and-series']"
270517,"If a series is conditionally convergent, then the series of positive and negative terms are both divergent","Let $ \sum_{n=1}^\infty a_n  $ be  a conditionally convergent series. Then the series $\sum_{n=1}^\infty b_n$ of positive terms of $\{a_n\}_{n=1}^\infty$ and $\sum_{n=1}^\infty c_n$ of negative terms are divergent. My proof : if $\sum_{n=1}^\infty a_n$ is conditionally convergent, then $\sum_{n=1}^\infty |a_n| = \infty$. Let's suppose that $\sum_{n=1}^\infty b_n$ and $\sum_{n=1}^\infty c_n$ are convergent, so since they are composed of positive and negative terms respectively, then $\sum_{n=1}^\infty |b_n| < \infty$ and $\sum_{n=1}^\infty |c_n| <\infty$ and we have that $$ \sum_{n=1}^\infty |a_n| = \sum_{n=1}^\infty |b_n| + \sum_{n=1}^\infty |c_n| < \infty $$ which is absurd since we supposed that the series was conditionally convergent. Edit Can I define $b_n := \left\{\begin{array}{ll} a_n &\text{if } a_n > 0 \\ 0 &\text{otherwise} \end{array} \right.$ and $c_n$ analogously for negative terms and say that $\sum a_n = \sum b_n + \sum c_n $ and, since $\sum a_n$ converges then both $\sum b_n, \sum c_n$ converge? Are the new series equal to the series of positive (and negative) terms? Is this correct? Thanks in advance","['convergence-divergence', 'sequences-and-series', 'real-analysis']"
270534,Arithmetic and geometric genus,"There are two notion of genus in algebraic geometry, namely arithmetic genus $p_a=(-1)^{\dim X}(\chi(\mathcal{O}_X)-1)$ and geometric genus $p_g=\dim H^0(X,\Omega^{\dim X})$. I keep forgetting definition of these, or being confused which is which. Are there any good ways to remember them? More precisely I would like to associate these definition with these names ""arithmetic"" and ""geometric"".","['algebraic-geometry', 'complex-geometry']"
270542,The Process of Choosing Projective Axes to Put an Elliptic Curve into Weierstrass Normal Form,"I'm reading the book ""Rational Points on Elliptic Curves"" and on page 23 the author takes an arbitrary (non-singular) elliptic curve in the projective plane and finds a rational point $O$, referring to it by $[1,0,0]$, and calling the line tangent to this point the line $Z=0$, a notation for a line I have never seen before but am assuming means that this line is supposed to be one of the new axes.  Then the third point of intersection of this line with the elliptic curve is referred to as $[0,1,0]$ and the line tangent to this point is called $X=0$ and finally a third line is drawn through $O$ and is called $Y=0$. Here is a picture I made which mimics the one given in the book: Edit: I just realized my picture isn't exactly correct, the line $Y=0$ goes through $O$ but doesn't have to go through the third red point with no label. I have some basic experience with the projective plane, but I have no idea what the author is doing here and how I should envisage these three lines as my new axes in the projective plane under some rational transformation or something.  Supposedly this is at least the first step in putting an elliptic curve into Weierstrass Normal Form, can someone explain this process to me?","['geometry', 'elliptic-curves', 'projective-geometry']"
270546,"If $X$ is an infinite set and there exists an injection $X \to \mathbb{N}$, is there also a bijection?","Full question is in the title.  It seems to me the answer is yes, because we can just order the numbers in the image of the function from starting from the least, and then there's 1-1 (is there?) correspondence with $\{1, 2, 3 , \dots \}$, but obviously this isn't a rigorous argument.  Help is appreciated.",['elementary-set-theory']
270550,Integration of $x^3 \tan^{-1}(x)$ by parts,"I'm having problem with this question. How would one integrate $$\int x^3\tan^{-1}x\,dx\text{ ?}$$
After trying too much I got stuck at this point. How would one integrate $$\int \frac{x^4}{1+x^2}\,dx\text{ ?}$$","['calculus', 'integration']"
270565,Biased Random Walk Converging to a Brownian Motion with drift (Donsker's Theorem),"Fix $N$ and suppose $\{X_n\}_{k=1}^{N}$ are i.i.d steps that are $\pm 1$ with equal probability. Then $S_n = \sum_{k\leq n} X_k $ is a simple random walk, and (with the right scaling) we know that the path $S_n$ converges to a Brownian motion as $N \to \infty$(This is an application Donsker's Theorem). I want to consider a related, but slightly different set up. Fix $N$ and suppose $\{X_n\}_{k=1}^{N}$ are i.i.d steps that are $+1$ with probability $\frac{1}{2} + \frac{\lambda /  2}{\sqrt{N}} $ and $-1$ with probability $\frac{1}{2} - \frac{\lambda / 2}{\sqrt{N}}$. Then and $S_n = \sum_{k\leq n} X_k $ is a biased random walk. I want to show that (in the same scaling as above) $S_n$ converges to a Brownian motion with drift $\lambda$ as $N \to \infty$. My attempt: I think we can do this by some manipulation and then applying Donsker's Theorem. Let $Y_k = \sqrt{1 - \frac{\lambda^2}{n}}\left( X_k - \frac{\lambda}{\sqrt{n}} \right)$  so that the $Y_k$'s are mean $0$ and variance $1$. Then applying Donsker's Theorem to the $Y_k$'s gets us very close to the result I want. However, there is a pesky factor of $\sqrt{1-\frac{\lambda^2}{n}}$ that is in front. I think the following is true and can fix the problem:
If $f_n \Rightarrow f$ are distributions in $C[0,1]$ and if $c_n \to 1$ are constants, then $c_n f_n \Rightarrow f$ in $C[0,1]$ too. My ""proof"" of this involves tightness and Prohorov's Theorem, so I'm hoping for an easier alternative.","['stochastic-processes', 'convergence-divergence', 'weak-convergence', 'probability-limit-theorems', 'probability-theory']"
270568,"$P$ is a point in the interior of a square $ABCD$, such that $\angle DCP = \angle CAP = 25^\circ$. What is $\angle BPA$? [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question does not appear to be about math within the scope defined in the help center . Closed 9 years ago . Improve this question Moderator Note: this is a question from the Federal Mathematics Competition 2013 . So here's another quite complex problem: $P$ is a point in the interior of a square $ABCD$, such that $\angle DCP = \angle CAP = 25^\circ$. What is $\angle ***PBA***$? Does anybody have any ideas on this problem? I tried to find as much angles as I could, but I just got stuck... Hope for some good answers :) Markus","['geometry', 'contest-math']"
270576,Problem about Hasse diagrams,Can someone help me to solve this problem. Are these Hasse diagrams lattices?,"['relations', 'lattice-orders', 'discrete-mathematics']"
270597,Möbius inversion,"The Möbius inversion formula says given two arithmetic functions $\hat{g}(k)$ and $g(k)$ related by $$\sum_{d\mid k}\hat{g}(d)=g(k)$$
Then $$\sum_{d\mid k}\mu(d)g\left(\frac{k}{d}\right)=\hat{g}(k)$$
Can someone give me a very elementary proof of this? I don't know anything about analytic number theory, though I know the definition of the Möbius function, and have used it before with out ever reading to deeply into it for example: I know that,
$\frac{x}{1-x}=x+x^2+x^3+x^4+\cdots$
And that if I subtract the even powers I get,
$\frac{x}{1-x}-\frac{x^2}{1-x^2}=x+x^3+x^5+x^7+x^9+\cdots$
And then If I subtract the the powers that are multiples of 3 I get,
$\frac{x}{1-x}-\frac{x^2}{1-x^2}-(\frac{x^3}{1-x^3}-\frac{x^6}{1-x^6})=x+x^5+x^7+x^{11}+\cdots$
Continuing in this matter one sees we are essentially yielding combinations of the original sum where the argument is a combination of distinct primes, and the coefficients are determined by weather or not the number of primes is even or odd. So by the definition of the Möbius function I can easily see, $\sum_{k=1}^\infty\frac{\mu(k)x^k}{1-x^k}=x$, although the first theorem I mentioned doesn't seem so obvious to me, and so I would appreciate a simple proof.",['number-theory']
270611,Find $n$ for which $\frac{n(n+1)}{2}$ is perfect square,Prove there is an infinite amount of natural numbers for which $\displaystyle \frac{n(n+1)}{2}$ is a perfect square.,"['diophantine-equations', 'number-theory']"
270614,"For a ring $R$, does $\operatorname{End}_R(R)\cong R^{\mathrm{op}}$?","Given a ring $R$, how to prove that $\operatorname{End}_R(R)\cong R^{\mathrm{op}}$, where $R^{\mathrm{op}}$ is the opposite ring of $R$. I read this proposition somewhere, but I think it is wrong. Because for any given $f\in\operatorname{End}_R(R) $ and any $r$ in $R$, we can get $f(r)$ by $r f(1)$, and $f(1)$can only be $1$, so $\operatorname{End}_R(R)$ is isomorphic to the trivil group. Is there anything wrong with my logic? Please help me identify where I am wrong in my understanding of $\operatorname{End}_R(R)$. Thanks!","['ring-theory', 'abstract-algebra']"
270622,Calculating triple integral over an ellipsoid,"I'm trying to calculate $$\iiint \frac{dx\,dy\,dz}{\sqrt{1 - \left(\frac{x^2}{9}+\frac{y^2}{16}+\frac{z^2}{25}\right)}}$$  over the ellipsoid $\frac{x^2}{9}+\frac{y^2}{16}+\frac{z^2}{25}=1$.
I couldn't find a solution. Can anyone help me?",['multivariable-calculus']
270628,Asymptotic integral expansion of $\int_0^{\infty} t^{3/4}e^{-x(t^2+2t^4)}dt$ for $x \to \infty$,"I'm still having a little trouble applying Laplace's method to find the leading asymptotic behavior of an integral.  Could someone help me understand this?  How about with an example, like: $$\int_0^{\infty} t^{3/4}e^{-x(t^2+2t^4)}dt$$ for $x>0$, as $x\rightarrow\infty$.","['asymptotics', 'integration', 'laplace-method']"
270631,some questions about differential equations,"when solving 1st order linear differential equations, we have some common method. I have some questions about the common methods. for example 
$\dfrac{dy}{-y + 5} = dt$ , why can we integrate on both side to get the equation of $y$? More specifically, we have different things to integrate, $y$ and $t$ respectively, why can we just integrate on both side? What's the underlying reason here? Also when we get $\,\ln |5 - y| =  -t + C,\,$ why can we immediately get $\,5- y = e^{-t + C}\,$ and get rid of the absolute sign? There is no information about the range of $y$, why can we do that? Thanks",['ordinary-differential-equations']
270635,$\emptyset={\{\emptyset\}}$,"Show that $X=\emptyset$ satisfies the following formula: ""$\forall x\in X, x\subset X""$. I´m not sure what this means. I think that it ask me to prove that $\emptyset={\{\emptyset\}}$.
My question is if the last equation is true.",['elementary-set-theory']
270639,Branch cut question,"I have a function $$f(z)=(z-1)^{3/5}(z+1)^{2/5}$$
and I have the branch of this function chosen such that $$-\pi<\arg(z\pm1)\leq\pi$$
How do I show that a branch cut is not required on the section $(-\infty,1)$ of the real axis? I have defined $(z-1)=r_1e^{i\theta_1}$ and $(z+1)=r_2e^{i\theta_2}$ and thus can get $f(z)$ into the form $$r_1^{3/5}r_2^{2/5}e^{i/5(3\theta_1+2\theta_2)}$$
Now here is where I get confused but I think I need to find $f(x\pm0i)$on the section $(\infty,1)$ of the real axis and determine continuity but I don't know how to do this for this specific example and would appreciate some help. Thank you.",['complex-analysis']
270640,Well-ordering the set of all finite sequences.,"Let $(A,<)$ be well-ordered set, using <, how can one define well-order on set of finite sequences? (I thought using lexicographic order) Thank you!",['elementary-set-theory']
270662,an irreducible quadric $ X \subset \Bbb A^n$ d is birational to some $\Bbb A^m$,"I want to prove that an irreducible quadric $ X \subset \Bbb A^n$ defined by a quadratic equation $ F(T_1,\ldots,T_n)=0$ is rational (i.e birational to some affine space $\Bbb A^m$ ). I'm not sure how to do this, the book ""Algebraic Geometry of Shafarevich"" says that it's the same as in the case of $ \Bbb A^2$ , in this case we take a point $(a,b)\in X$ (in the curve) where $X$ is defined by $ F(x,y)=0 $ and $F$ has degree $2$. We consider $ y = t(x-a)+b$ and then $ F( x , t(x-a)+b ) $ is a polynomial of degree $2$ on $x$ , one solution is $(x-a)$ so we can divide and have a polynomial $ H(x,t) $ $f$ degree $1$ on $x$ , so we parametrized $x$ and $y$ . Shafarevich says that the idea in $\Bbb A^n$ is the same, but I don't understand how, the hint is to consider a non singular point of the curve, and following the same idea.
Please help me with this )=",['algebraic-geometry']
270664,Finding $\displaystyle \lim_{n \to \infty} \int_0^\infty \frac{e^{-x}\cos{x}}{nx^2 + \frac{1}{n}}dx$,Prove that $\displaystyle \lim_{n \to \infty} \int_0^\infty \frac{e^{-x}\cos{x}}{nx^2 + \frac{1}{n}}dx$ exists and determine its value.,"['measure-theory', 'real-analysis']"
270671,Easiest way to prove that $2^{\aleph_0} = c$,"$\aleph_0$ is the cardinality of the set of natural numbers, $\aleph_0 = |N|$. $c$ is the cardinality of the continuum, i.e. the set of real numbers $c = |R|$. I know that $|P(A)| = 2^{|A|}$. This means that the cardinality of the power set of a set is 2 raised to the power of the cardinality of that set. This basically means that to prove  $2^{\aleph_0} = c$, I need to prove $c = |P(N)|$. I've seen the Cantor diagonal argument, although I have no idea on how to use it to prove this. Could anyone suggest ideas of the simplest way to prove that $2^{\aleph_0} = c$?","['cardinals', 'elementary-set-theory']"
270687,Irreducibility of Multivariable Polynomials,"Question: Let $k$ be a field and $p,q\in k[x]$ two relatively prime polynomials. Prove $p(x)y-q(x)$ is irreducible in $k[x,y]$. How does one show this? More generally, how does one show that multivariable polynomials are irreducible? In one variable we have access to tools like Gauss's lemma and Eisenstein's criteria, but I do not know any methods applicable to the multivariable case.","['irreducible-polynomials', 'abstract-algebra', 'polynomials']"
270703,$xH \cap yK$ is either empty or a coset of $H \cap K$: blanking,"$H, K$ are sub groups of a group $G$. What I have: Denote the left cosets $H_i$, $K_j$, and $(H \cap K)_k$, respectively. If $x, y \in H_i \cap K_j$, then $y^{-1}x \in H, K$, and so in $H \cap K$, so $x, y$ are in the same coset $(H \cap K)_k$ for some $k$. Where I'm blanking: what if $H_i \cap K_j$ has only one element? How to proceed then, and so conclude the proof? Thanks!",['group-theory']
270712,What's the difference between expected values in binomial distributions and hypergeometric distributions?,"The formula for the expected value in a binomial distribution is: $$E(X) = nP(s)$$
where $n$ is the number of trials and $P(s)$ is the probability of success. The formula for the expected value in a hypergeometric distribution is: $$E(X) = \frac{ns}{N}$$
where $N$ is the population size, $s$ is the number of successes available in the population and $n$ is the number of trials. $$E(x) = \left( \frac{s}{N} \right)n $$
$$P(s) = \frac{s}{N}$$
$$\implies E(x) = nP(s)$$ Why do both the distributions have the same expected value? Why doesn't the independence of the events have any effect on expected value?","['probability-theory', 'stochastic-processes', 'probability-distributions', 'probability']"
270721,How to evaluate the integral $\int e^{x^3}dx $,"How to evaluate the integral
$$\int e^{x^3}dx \quad ?$$ I've tried to set $t=x^3$, but it seems to be a blind alley; I don't know what to do with $\int\frac{e^t}{3\sqrt[3]{t^2}}dt$.","['calculus', 'integration', 'indefinite-integrals']"
270740,"Is there a finitely generated, algebraic $K$-algebra $A$ that is not a field?","There is a well-known theorem that states that if $A$ is a finitely generated $K$-algebra, an integral domain and algebraic over $K$, then $A$ is a field. Is the integral domain condition necesary? I mean, is there an example of an algebraic algebra over $K$, such that is not a field? It may be kind of simple, but I'm a bit confused. Thank you.","['commutative-algebra', 'abstract-algebra']"
270745,Compute probability of a particular ordering of normal random variables,"There are $m$ normally distributed, independent random variables $N_1, \ldots, N_m$ with distinct means $\mu_1, \ldots \mu_m$ and standard deviations $\sigma_1, \ldots, \sigma_m$. Then, we get a permutation of the numbers $\{1, \ldots, m\}$. How can we efficiently compute, numerically, the (log) probability of observing the random variables in same ordering as this permutation? An example: we have four independent random variables $N_1, N_2, N_3, N_4$, all with different means and variances. We are given the permutation (3, 1, 2, 4). What's $\Pr(N_3 > N_1 > N_2 > N_4)$? A closed-form solution is not necessary, but computing the solution using an efficient algorithm with good accuracy is. Also, it's probably necessary to compute a log probability due to the fact that when the number of variables becomes large, computing the actual probability will result in a floating-point underflow. Some starting points, perhaps... The most direct way to compute this value, using the example above, is evaluating one of the following integrals, which I believe are equivalent: $$ \int_{-\infty}^\infty \int_{n_4}^\infty \int_{n_2}^\infty \int_{n_1}^\infty p(n_1)p(n_2)p(n_3)p(n_4)\ dn_3 dn_1 dn_2 dn_4 $$ $$ \int_{-\infty}^\infty \int_{-\infty}^{n_3} \int_{-\infty}^{n_1} \int_{-\infty}^{n_2} p(n_1)p(n_2)p(n_3)p(n_4)\ dn_4 dn_2 dn_1 dn_3 $$ Where $p(n_i)$ is the density function of the variable $N_i$. However, when I tried to implement this numerically, it is inefficient, prone to inaccuracy, and runs into underflow errors when the number of variables gets large. If you think you can compute this integral in an acceptable way, please do post your answer! From one of the answers below, we observe that it's possible to compute $\Pr(N_3 > N_1 > N_2 > N_4)$ directly by evaluating a multivariate normal CDF of dimension $(m-1)$, or 3 in this case. However, this is still nontrivial (though there may be libraries for it), and will underflow for many variables. Perhaps we can divide the probability up as follows: $$\Pr(N_3 > N_1 > N_2 > N_4) = $$
$$\Pr(N_3 > N_1 \mid N_1 > N_2, N_2 > N_4 )\Pr(N_1 > N_2 \mid N_2 > N_4 )\Pr(N_2 > N_4)$$ Being able to compute the probabilities of each part directly would make it very easy to compute the log probability simply by adding. We can compute the conditional probabilities separately using the MVN CDF method, which could help if the product might underflow. Another observation: the $m!$ possible probabilities corresponding to the different permutations must sum to 1. Perhaps there is a way to compute the probabilities iteratively or using dynamic programming: i.e.: $(N_2 >  N_3)$, an ordering over a pair, has some fixed probability, which is further divided into three values by the three possible places to insert $N_1$ into the ordering, further divided into the four values by the possible places to insert $N_3$. This is semantically equivalent to the conditional probabilities above but it might be easier to think of it this way. Any math wizards have suggestions on how to solve this problem? I would greatly appreciate any ideas!","['integration', 'normal-distribution', 'probability-distributions', 'probability', 'combinatorics']"
270755,Using the identity theorem: can there be an analytic function $f$ with $f\left(\frac{1}{n^2}\right) = \frac{1}{n}$,"As Conway states it the theorem is as follows: Let $G$ be an open connected set and let $f:G\rightarrow \mathbb{C}$ is analytic on $G$ . Then the TFAE: $f\equiv0$ $\{z\in G: f(z)=0 \}$ has a limit point in $G$ . I get confused when I have to use this to solve problems. My understanding
on this is sort of like ""if $f$ goes to zero along a certain sequence"" then the function must be identically zero. Is this thinking correct? Even if I am I want
some good explanation on this. Also, if any of you could give a good reference to this that would help too. For example what can we say about an analytic function $f:\mathbb C\rightarrow \mathbb C$ , such that $f\left(\frac{1}{n^2}\right) = \frac{1}{n}$ . Can such a function exist? Can we even use the identity theorem to answer this question?
Thanks so much for your time.",['complex-analysis']
270761,When does $\|f*g\|_{p}=\|f\|_{1}\|g\|_{p}$?,"From Rudin, Real and Complex Analysis, 1st edition, Chapter 7, Problem 4 Suppose $1\le p\le \infty$, $f\in L^{1}(\mathbb{R}^{1})$, $g\in L^{p}(\mathbb{R}^{1})$. Show that the the integral defining $f*g$ exists for almost all $x$, that $f*g\in L^{p}$, and that $$\|f*g\|_{p}\le \|f\|_{1}\|g\|_{p}.$$ Show that the equality can hold if $p=1$ and if $p=\infty$, and find conditions under which this happens. Assume $1<p<\infty$, and equality holds, then either $f=0$ a.e or $g=0$ a.e. My thoughts: By Fubini's theorem we can prove $$\|f*g\|_{p}^{p}\le \|f\|_1^{p} \|g\|_p^{p}$$ So the first claim is okay. But I do not know how to show when the equality holds. So it suffice to prove $$\int\left(\int f(x-y)g(y)dy\right)^{p}dx<\left(\int |f|dx\right)^{p}\left(\int |g|^{p}dy\right)$$ By Fubini's theorem we have \begin{align}\int\left(\int f(x-y)g(y)dy\right)^{p}dx&\le \int (\int |f(x-y)|^{p}|g(y)|^{p}dy)dx\\&=\left(\int |g(y)|^p dy)(\int |f(x-y)| dx\right)^{p-1}\int |f(x-y)|dy\\&=\int |g(y)^p|dy (\int |f(t)|dt)^{p}
\end{align} using Lebesgue measure's translation invariance. Since the first inequality is just from absolute value, we may assume $f,g$ are non-negative without losing any generality. But I do not see which one of the last few equalities is just an inequality.","['convolution', 'inequality', 'measure-theory', 'lp-spaces', 'functional-analysis']"
270767,Find intersection of two 3D lines,"I have two lines $(5,5,4) (10,10,6)$ and $(5,5,5) (10,10,3)$ with same $x$, $y$ and difference in $z$ values. Please some body tell me how can I find the intersection of these lines. EDIT: By using the answer given by coffemath I would able to find the intersection point for the above given points. But I'm getting a problem for $(6,8,4) (12,15,4)$ and $(6,8,2) (12,15,6)$. I'm unable to calculate the common point for these points as it is resulting in Zero.
Any ideas to resolve this? Thanks, 
Kumar.","['analytic-geometry', 'geometry', 'linear-algebra']"
270782,Sphere with three Möbius strips glued and sphere with a handle and a Möbius strip glued,"I am reading the first chapter from Topology by Armstrong. There, after stating the classification theorem for closed surfaces, he has mentioned an example that a sphere with one handle and one Möbius strip glued is homeomorphic to a sphere with three Möbius strips glued. I am not able to see this. I know that to prove the above is to say that a torus with a Möbius strip glued is homeomorphic to a Klein bottle with a Möbius strip glued. How do I prove this? Or how do I at least convince myself that this is the case, in case I don't yet have the tools to prove it.","['general-topology', 'mobius-band', 'klein-bottle', 'algebraic-topology']"
270789,complex analysis/ Taylor expansion question,"Let $f:\mathbb C \rightarrow \mathbb C$ be holomorphic and $f(z)=f(-z)$ for all $z\in \mathbb C$. Show that there exists a holomorphic function $g$ such that
$g(z^2)=f(z)$. If I take $g(z):=(f(z)+f(-z))/2$ then I can prove that $g(z)=\sum_0^\infty a_{2n}z^n$. Of course $g$ thus defined is holomorphic. But how does this show that 
$g(^2)=f(z)$ as well?. I mean the coefficients of the two are different when you compare term by term. Can you guys help?. Or should this $g$ be defined differently?
Thanks for your help.",['complex-analysis']
270802,Construct polygon from random segments,"Given an arbitrary amount of ordered segments, with arbitrary lengths is there a way to determine if they can be formed into a simple polygon? And if so, is it possible to work out the angles needed to do so? Thanks","['geometry', 'polygons']"
270827,Divergence of an infinite product,"How can I prove that the infinite product $$\displaystyle\prod_{n=1}^{+\infty}(1+z^{2n})$$ diverges for 
$|z|>1$?","['convergence-divergence', 'infinite-product', 'complex-analysis']"
270850,uniform convergence of sequences of analytic functions,"Suppose you have a sequence $f_n$ of analytic functions on an open set $\Omega$, which converges uniformly on compact subsets of $\Omega$. Can you conclude that $f_n$ converges uniformly on the whole open $\Omega$?","['sequences-and-series', 'complex-analysis']"
270859,Simplicity of eigenvalue,"I have a matrix $A$ and I introduce $(I+A)^{m},$ where $I$ is the identity matrix of same order with $A$ and $m$ is a positive integer. I want to show that if $(1+ \lambda )^m$ is a simple eigenvalue of $(I+A)^m$, that is, it is not a repeated root of the characteristic polynomial of $(I+A)^m,$ then $ \lambda$ is a simple eigenvalue of $A.$ Any help with this will be highly appreciated. Edit: what I mean by a simple eigenvalue. For an arbitrary matrix $A$ of order $n \times n,$  let $  \lbrace \lambda_1,\lambda_2,\lambda_3, \dots ,\lambda_k \rbrace $ be the set of distinct eigenvalues of $A.$ The characteristic polynomial of $A,$ denoted $p(\lambda),$ can be written in the factorized form \begin{equation} p(\lambda) = (\lambda_1-\lambda)^{n_1}(\lambda_2-\lambda)^{n_2} \dotsm (\lambda_k-\lambda)^{n_k}\end{equation} with $n_1+n_2+ \dotsm +n_k = n.$ The exponent $n_i,$ corresponding to each eigenvalue $\lambda_i,$ is called the algebraic multiplicity of $ \lambda_i$ and the dimension of the null space of $ A - \lambda_i I,  \dim(N(A - \lambda_i I )),$ is called the geometric multiplicity of $ \lambda_i.$  If $n_i=1$ for some $i \in \lbrace 1, 2, \dots, k \rbrace,$ then $ \lambda_i$ is said to be a simple eigenvalue of $A.$","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
270862,Compact operators: why is the image of the unit ball only assumed to be relatively compact?,"Recall the definition of compact operators between Hilbert spaces: An operator $A$ is called compact if the image $A(\mathcal U_H)$ of the unit ball is relatively compact (i.e. its closure is compact) in the norm topology. However, I seem to be able to ""prove"" that the image is, in fact, compact , not just relatively compact. What went wrong? $\square$: We show that $A(\mathcal U_H)$ is sequentially compact. Since the topology is given by a norm / metric, this implies that it is also compact. Let $y_n = Ax_n$ be a sequence in $A(\mathcal U_H)$. The unit ball in a Hilbert space is weakly compact, so there is a weakly converging subsequence $x_{n_j} \to^w x$ which gives $Ax_{n_j} \to^w Ax$. On the other hand, by the sequential compactness of the closure of $A(\mathcal U_H)$, we know that a subsequence of $z_k = x_{n_{j_k}}$ has the property $Az_k \to y$ for some $y$ in the Hilbert space, though we do not yet know that $y$ is also in the image of the unit ball. But we have $z_k \to^w x$ as well, and hence $A z_k \to^w A x$. Since the weak limit must coincide with the norm limit, we have $y = Ax$, and $y \in A(\mathcal U_H)$ already. In other words, the original sequence $y_n$ has a subsequence that converges in the image of the unit ball. $\square$ I feel very stupid for not finding my mistake that must surely be very elementary. What went wrong? A counterexample would probably help my understanding as well.","['general-topology', 'compact-operators', 'functional-analysis']"
270882,"The deriviative of $\sqrt{\ln(x)}$, by definition","How do I find the deriviative of $\sqrt{\ln(x)}$, by definition? I got stuck thinking of a solution... Would be glad of getting help/hints. Thanks in advance!",['functions']
270883,In a ring homomorphism we always have $f(1)=1$? [duplicate],"This question already has answers here : Closed 11 years ago . Possible Duplicate: the image of $1$ by a  homomorphism between unitary rings I'm studying the Atiyah's commutative algebra book and I realized that in the beginning of the book, the author says as one of the conditions to a map be a homomorphism is $f(1)=1$, I would like to know if I can left this condition behind, i. e., if $f(x+y)=f(x)+f(y)$ and $f(xy)=f(x)f(y)$ we can have $f(1)=1$. Thanks","['ring-theory', 'abstract-algebra']"
270929,Finite generation of ideal in function ring,"Let $R$ be the ring of continuous functions from $[0,1]$ to the real numbers. Fix $c \in [0,1]$ and let $M_c$ = ker $E_c$ where $E_c$ denotes evaluation at $c$, a ring homomorphism from $R$ to the real numbers. That is, $E_c(f) = f(c)$ for $f \in R$. What is a nice clean way to show $M_c$ is not finitely generated? I figure that one way is to suppose that 
\begin{equation}
A = \{ f_1, f_2,\dots, f_n \}
\end{equation}
is a minimal generating set and try to come up with $f_{n+1}$ which cannot possibly be an R -linear combination of the $f_k$, but that feels like a lot of guesswork. (And I didn't succeed.) Thanks for the help.","['functions', 'ideals', 'abstract-algebra']"
270949,"Does $\bigcap_{n=1}^{+\infty}(-\frac{1}{n},\frac{1}{n}) = \varnothing$?","When I learn the below theorem: If $I_n$ is closed interval, and $I_{n+1} \subset I_n$, then $$\bigcap I_n \ne \varnothing$$ and someone says if we replace closed interval with open interval, can construct counter-example. So I have tried to construct the one: Does $$\bigcap_{n=1}^{+\infty}\left(-\frac{1}{n},\frac{1}{n}\right) = \varnothing\quad?$$ Thanks very much.",['elementary-set-theory']
270957,Infinite group with subgroups of finite index,"et $G$ be an infinite group and $H,K \leq G$ with $[G:H] = m$ and $[G:K] = n$. I want to show that $[G:H \cap K] < \infty$. My idea: Let $\{h_1,\cdots,h_m\}$ be representants of $\{gH \mid g \in G\}$ and similar $\{k_1,\cdots,k_n\}$. Then each $g \in G$ is in $h_iH \cap k_jK$ for some $1 \leq i \leq m$ and $1 \leq j \leq n$. Then I want to show that if $g \in h_iH \cap k_jK$ then $g( H \cap K) = h_iH \cap k_jK$. Does this show that $[G:H \cap K] <\infty$ ? I think that this shows that $[G: H \cap K] \leq mn$.",['group-theory']
270965,Set of locations where the Hilbert symbol is not equal to $1$,"Let $V$ be the set of prime together with the symbol $\infty$. For a prime $v=p$, denote the $p$-adic numbers by $\mathbb{Q}_p$ and the real numbers by $\mathbb{Q}_\infty$. For $v\in V$ the Hilbert symbol is defined for $a,b\in\mathbb{Q}^*_v$ as \begin{align*}
(a,b)_v=\begin{cases}+1,&\text{ if }ax^2+by^2=z^2\text{ has a non-zero solution }(x,y,z)\in \mathbb{Q}_v^3;\\-1,&\text{ else.}\end{cases}
\end{align*} Furthermore for $v\in V, a,b\in\mathbb{Q}^*$ we denote by $(a,b)_v$ the Hilbert symbol of $(\bar a,\bar b)_v$ where $\bar a,\bar b$ are the images of $a,b$ in $\mathbb{Q}_v$. Now a theorem by Hilbert says that $(a,b)_v=1$ for almost all $v\in V$ (and that furthermore $\prod_{v\in V}(a,b)_v=1$, but I'm not interested in this at the moment). The theorem can be found in ""A course in Arithmetic"" by Jean-Pierre Serre for example. It basically says that there is a finite set $E\subseteq V$ such that 
\begin{align*}
(a,b)_v=\begin{cases}+1,&\text{ if }v\notin E\\-1,&\text{ if }v\in E\end{cases}
\end{align*} My question is if this set $E$ has a common name in the literature. Something like $E_{a,b}$ would make sense to me (since it depends on $a$ and $b$). If there is no widely used name, what are your suggestions?","['p-adic-number-theory', 'algebraic-number-theory', 'abstract-algebra', 'number-theory']"
270970,"Homework: $(|H|,|K|)=1 \Leftrightarrow A=(A\cap H)(A\cap K) \forall A\leqslant G$.","Let $G$ is finite group and $H,K$ are normal subgroups of $G$ such that $G=HK$ and $H\cap K=1$ ($1$ is identity element). Show that $(|H|,|K|)=1$ if and only if for all subgroup $A$ of $G$ we have $A=(A\cap H)(A\cap K)$. PS. I had try to $$|A|=|(A\cap H)(A\cap K)|=\frac{|A\cap H||A\cap K|}{|A\cap H\cap A \cap K|}=\frac{|A||H|}{|AH|}\cdot \frac{|A||K|}{|AK|}$$
so
$$|A||H||K|=|AH|.|AK|=|AHAK|.|AH\cap AK|=|H||K||AH \cap AK|$$
implies $|A|=|AH\cap AK|$.","['finite-groups', 'group-theory']"
270973,Proving a theorem about continuity property with contradiction.,"Proving that if $f$ is continuous on an interval $I$, any $a,b\in I,a<b$ and for any $y$,where $f(a) < y < f(b)$, there exist a $x\in (a,b)$ s.t $f(x)=y$. I have seen a prove using the sequence but i want to prove it with my understanding of the definition of continuity so i decided to prove it with contradiction. Assume there is a $y$ which have no $x\in (a,b)$ s.t.$f(x)=y$ and i wanna prove that $f$ is then not continuous but I'am not sure how to prove it with contradiction. The definition i learnt about the continuous function on a set $X$ is :$\forall x,y\in X,\forall \epsilon>0,\exists\delta>0$ s.t.$d(x,y)<\delta\implies d(f(x),f(y)) < \epsilon$.","['functions', 'real-analysis', 'analysis']"
270976,Exercises about group actions,"I am having trouble with exercises from Chapter IV of Aluffi's Algebra: Chapter 0 . After spending many hours on the following two, I guess I need some help: Let $G$ be a finite group, and suppose there exists representatives $g_1,g_2,\dots,g_r$ of the $r$ distinct conjugacy classes in $G$, such that $g_ig_j=g_jg_i$. Prove that $G$ is commutative. Since proving the commutativity of $G$ is the same as proving all conjugacy classes are singletons, I am guessing I need to apply the commutativity of $g_i$'s to show that all conjugacy classes are of the same size, since we already know there is always an element whose conjugacy class is a singleton. To do this, I guess we need to use the class formula for group actions, but I do not know how to apply it. The second problem is: $G$ is a finite group acting transitively on a set $S$. If $|S|>2$, then there is a $g\in G$ without fixed points in $S$. The author gives a hint. Since $S$ is isomorphic to $G/H$ as $G$-sets for some subgroup $H$, we might as well let $S=G/H$. The hint says we should use a result we have proved: A finite group cannot be the union of the conjugacy classes of a proper subgroup. Again I do not know how to use this hint. Thanks!","['group-actions', 'group-theory', 'abstract-algebra']"
270982,Prove that prime ideals of a finite ring are maximal,Let $R$ be a finite commutative unitary ring. How to prove that each prime ideal of $R$ is maximal?,"['ring-theory', 'finite-rings', 'maximal-and-prime-ideals', 'abstract-algebra']"
270997,How fast does $\sum_{k=1}^n \frac{1}{k^\alpha}$ ( $\alpha\leq1$) diverge?,"The series $\sum_{k=1}^\infty \frac{1}{k^\alpha}$ diverges if $\alpha\leq 1$.
How can I estimate the divergent rate when $\alpha$ is given.
For example, if $\alpha=1$, $\sum_{k=1}^n \frac{1}{k^\alpha}=O(\log n)$; if $\alpha=0$, $\sum_{k=1}^n \frac{1}{k^\alpha}=O(n)$.",['sequences-and-series']
271003,Every partial order can be extended to a linear ordering,"How do I show that every partial order can be extended to a linear ordering? I think that I manage to prove that claim for finite set, how can I prove it for infinite set? Thank you.","['elementary-set-theory', 'reference-request', 'order-theory']"
271013,Approximating continuous functions with polynomials,"Given $\epsilon \gt 0$ and $f \in C^{0}[0,1]$, Weierstrass says that I can find at least one (how many? probably a lot?) polynomial $P$ which approximates f uniformly: $$\sup_{x \in [0,1]} |f(x) - P(x)| \lt \epsilon$$ This means that, under the sup norm $||.||_{\infty}$, the polynomials are dense in $C^{0}[0,1]$. So, in analogy to approximating irrationals with the rationals, I would like to know: What can we say about the order of $P$? Or, turning this around, given that $P$ is of order $n$, how small can $\epsilon$ get? I'm betting this should depend in some way on the properties of $f$: the intuition is that smoother functions should be somehow ""better"" approximated by lower-order polynomials, and less-well-behaved functions should require higher-order polynomials. But I am not sure how to formalize this. This is probably all well-understood, but I'm not well-read on approximation theory. Any guidance would be wonderful.","['approximation-theory', 'reference-request', 'real-analysis', 'polynomials']"
271020,Self-Intersection Number $-2$,"I am new here, but hopefully you can help me with a concrete problem I have. I try to compute a Self-Intersection Number of a constructed curve in an analytic surface. I know the answer by some references, but have no idea how it has been found. First my surface: Let $N\in \mathbb N$.
We take $M_N:=\coprod\limits_{n\in\mathbb Z} (\mathbb C \times \mathbb C) / \sim $, where $""\sim""$ is the following equivalence relation: $\forall a,b \in\mathbb C \setminus \{0\} \ \forall n,k\in \mathbb Z : (a,b)_n \sim (a(ab)^{-k},b(ab)^k)_{n+k}$ , where $(a,b)_n$ denotes the pair $(a,b)$ in the $n$th-copie of $\mathbb C \times \mathbb C$. $\forall b \in\mathbb C \setminus \{0\} \ \forall n,k\in \mathbb Z: 
(0,b)_n \sim (b^{-1},0)_{n+1}$ $\forall a,b \in\mathbb C \ \forall n\in \mathbb Z : (a,b)_n \sim (a,b)_{n+N}$ The elements of $M_N$ are equivalence-classes of Elements $(a,b)_n$ under $\sim$ and shall be denoted by $[a,b]_n$. The curve: For $n\in\mathbb Z$ let $S_n := \{ [0,b]_{n-1}\} \cup \{ [0,0]_n\}$.
Immedeatly we see:
1. $\forall n \in \mathbb Z : S_n \cup S_{n+1} = \{[0,0]_n\}$
2. $\forall n \in \mathbb Z : S_n \simeq \mathbb{P^1(C)}$ I am searching for the Self-Intersection Number $S_n.S_n$. I know it is -2. But why is it? I have no experience in computing Intersection Numbers. The usual way seems to intersect a sligthly moved copy of the curve with the original curve. But this won't work, if the result is negative. The idea must lie in the fact, that for $b\not =0$ the identity
$[a,b]_{n-1} = [b^{-1},ab^2]_n$ ist given. But how to use this? I am thankful for any hint. Shall I blow up anywhere?","['arithmetic-geometry', 'intersection-theory', 'algebraic-geometry']"
271028,"Optimization, Gradients, and Multivariate Data","I would like to learn gradient based optimization for multivariate data. For example, assume the data I have is $X = (x_0, ..., x_n)$ where $x_i$ are some random variables and $f$ a function measuring (Pearson, if you like) correlation. Then, I would like to minimize the value of $f(X)$ i.e. make the variables $x_0, ..., x_n$ uncorrelated. How could this be achieved using gradient based methods? After I have learnt this, the next thing is that I would like to implement the procedure in MATLAB. If you have any tips for that, I would like to hear those as well.","['statistics', 'multivariable-calculus', 'optimization', 'numerical-methods']"
271030,Stein's Paradox and James Stein Estimator,"I am trying to figure the intermediate steps in the proof of the Stein's paradox. 
How does it go from the left to the right?
$$\frac{\partial}{\partial Y_i} \left\{\frac{Y_i }{\sum_j Y_j^2}\right\} = \frac{\sum_j Y_j^2 - 2Y_i^2 }{(\sum_j Y_j^2)^2}$$ The part I have trouble with is: How would you differentiate this: $$ \frac{\partial}{\partial Y_i} \left\{ \frac{1}{\sum_j Y_j^2}\right\}$$","['multivariable-calculus', 'calculus', 'statistics', 'probability', 'derivatives']"
271035,calculating a multivariate integral via level sets,"I'm considering the possibility of calculating an integral of the form $\int_{S_n} f(x_1,\dots,x_n) dx_1\dots dx_n$ via level sets, where $S_n$ is the domain of integration. In my problem everything is real valued, and $f:R^n\to R$. Also, consider $f$ smooth, with no holes, etc. Now, consider $g$ a real number that solves the equation $g=f(x_1,\dots,x_n)$, i.e., a level set. Then, I think one can write the relation
\begin{equation}
\int_{S_n}f(x_1,\dots,x_n) dx_1\dots dx_n=\int g\rho(g)dg
\end{equation}
where $\rho(g)dg$ is the density distribution of $g$, or roughly speaking the number of solutions of the level set equation for $g$. A simple example: consider calculating the volume of a half sphere (radius $r$) centered at $(a,a,0)$. Then, the integral on the left hand of the identity is $\int dx \int dy \sqrt{r^2-(x-a)^2-(y-a)^2}$, and the right hand is $\int dz 2\pi\sqrt{r^2-z^2}z$ where $g=z$ and $\rho(g=z)=2\pi\sqrt{r^2-z^2}$. First, is this statement roughly correct? I suspect it's related to the coarea formula, but am not entirely sure as this is not my area of expertise. Does this result have a particular name? Also, it seems to me that $\rho(g)$ would relate to the Jacobian (modulus) in some way, although I don't think it's just equal. Any ideas? Finally, even if all of this is correct, in a concrete case it seems to me that unless $f$ is a very simple example, it is going to be difficult to make concrete calculations in most cases. However, I should still whether there are some techniques out there to deal with this analytically. Or should one consider numerical techniques? Thanks","['calculus', 'probability', 'analysis']"
271044,"Limit of ""simple"" function","I am trying to solve:
$$\lim_{x\to 0} ({1 - \sin x})^{\cot2x}$$ I know that this could be solved by different methods. Can anyone summarize the methods and give me some references to read? Thanks! PS: This is the way I started first
$$\lim_{x\to 0} ({1 - \sin x})^{\cot2x} = \lim_{x\to 0} e^{(1 - \sin x)\ln{\cot2x}} = \lim_{x\to 0} \frac{\ln{\cot{2x}}}{\frac{1}{1 - \sin x}}$$
Then I am trying Leibniz's theorem but I end up nowhere.","['functions', 'limits']"
271066,Bayesian inference,"I'm a bit confused with arranging the Bayes equation to update probability. Say, I have the following data: $P(\text{blue birds in the whole study area}) = 0.16$;
$P(\text{all except blue colored birds in the whole study area}) = 0.84$;
$P(\text{birds in NW of the study area is blue}) = 0.22$; and 
$P(\text{blue birds outside the NW part of the study area}) = 0.11$; Is that correct if I write: $P(\text{blue|NW}) = \frac{P(\text{blue}) \cdot P(\text{NW|blue})}{P(\text{blue}) \cdot P(\text{NW|blue}) + P(\neg \text{blue}) \cdot P(\text{blue|}\neg\text{NW})} = \frac{0.16 \cdot 0.22}{0.16 \cdot 0.22 + 0.84 \cdot 0.1}  = 0.28$? Therefore, the probability of finding a blue bird in the NW of the study site has increased from the prior estimate of $16%$ to $28%$. The confusing part is that we also know: $P(\text{birds in NW that are not blue}) = 0.78$ and if I use this information in the equation as $P(\neg\text{blue|NW})$, then the calculation stands as: $0.16*0.22/(0.16*0.22 + 0.84*0.78) = 0.054$ or $5.4\%$ only (though the probability of finding a blue bird in the NW is supposed to increase)?!? In sum, which one is correct to use: $P(\text{blue|}\neg\text{NW})$ or $P(\neg\text{blue|NW})$ in this particular case or the whole idea is wrong?? Thanks.","['statistics', 'bayesian']"
271080,Showing that $ae^x=1+x+\frac{x^2}{2}$ has exactly one real root (part 2),"I made this question here Show $a e^x=1+x+\frac{x^2}{2}$ has exactly one real root but I wrote the equation wrong. I reproduce the post with the correct equation: I'm struggling with the following problem: Show that the equation $a e^x=1+x+\frac{x^2}2$, where $a$ is a positive constant, has exactly one real root. Looking at the graphs of both $ae^x$ and $1+x+\frac{x^2}2$, they will intersect on the left half of the plane when $a>1$ and on the right half when $a<1$ (because a makes $e^x$ grow faster or slower). So if I could find a point $x_1$ where $a e^{x_1}-(1+x_1+\frac{{x_1}^{2}}2)<0$ and a point $x_2$ where $a e^{x_2}-(1+x_2+\frac{{x_2}^2}2)>0$, by the intermediate value theorem, the equation would have a real root. Also,since the derivative of $a e^x-(1+x+\frac{x^2}2)$ is always positive, I could colclude that there can't exist another real root. So my question is, how can I find $x_1$ and $x_2$? I can't figure out how to express $x$ in terms of $a$.",['calculus']
271081,Trading localisation for regularity,"When reading about Schrödinger's fundamental solution in 1D, $$u(t,x)=\frac{1}{\sqrt{4\pi it}} \int_\mathbb{R} u_0(y) e^{\frac{i(x-y)^2}{4t}}dy$$ the author says thus Schrödinger evolution is instantaneously smoothing for localised data: if $u_0$ is so localised as to be absolutely integrable but is not smooth, the previous shows that at all other times $t>0$,  $u(t)$ is smooth (but not localised) . I see that when differentiating under the integral sign, if $u_0$ is compactly supported (not necessarily smooth), the integral converges and thus the interchange is legitimate. What can localised mean apart from compactly supported? Schwartz space would do, of course, but what non-smooth initial data are considered localised? I'd like a good interpretation of the following too, please: high frequencies (Fourier space) travel very fast (we know dispersion is proportional to frequency in Schrödinger equation) and radiate quickly away from the origin (of physical space?) where they are initially localised, leaving only the low frequencies, which are always smooth, to remain near the origin . I see this when breaking an initial data in a finite number of waves which ""sum"" to it, but it seems to me that smoothness away from the origin wouldn't be guaranteed.","['partial-differential-equations', 'analysis']"
271090,Number of solutions for $x[1] + x[2] + \ldots + x[n] =k$,"Omg this is driving me crazy seriously, it's a subproblem for a bigger problem, and i'm stuck on it. Anyways i need the number of ways to pick $x[1]$ ammount of objects type $1$, $x[2]$ ammount of objects type $2$, $x[3]$ ammounts of objects type $3$ etc etc such that $$x[1] + x[2] + \ldots x[n] = k\;.$$ Order of the objects of course doesn't matter. I know there is a simple formula for this something like $\binom{k + n}n$ or something like that i just can't find it anywhere on google.",['combinatorics']
271094,convergence of complex power series - infinite convergence radius,"My books states that if the convergence radius of a complex power series is $+\infty$, then the power series is uniformly convergent over every 'disk' of the complex plane, although not necessarily over the entire complex plane. How is this possible?","['power-series', 'complex-analysis']"
271097,Evaluating $\int^{\infty}_{0}{\frac{\ln x}{(1+x^2)^2}dx}$,"$$\int^{\infty}_{0}{\frac{\ln x}{(1+x^2)^2}dx}$$ I've done a similar one: $\int^{\infty}_{1}{\frac{\ln^n x}{x^2}dx}$ using IBP, but in this case I've tried IBP multiple times, differentiating all of the possible choices, and it's only getting more convoluted. Also, no substitution I've tried like $x=e^u$ or $u=1+x^2$made the integral simpler. I'd appreciate a hint at this point, since I don't think it can be that hard.","['calculus', 'integration']"
271104,Convergence of the series $\sum_{n=1}^\infty \frac{(2n)!!}{(2n+1)!!} $,"Study the convergence of the next series: $$\sum_{n=1}^\infty \frac{(2n)!!}{(2n+1)!!} $$ My solution: since $$\frac{(2n)!!}{(2n+2)!!} \leq \frac{(2n)!!}{(2n+1)!!}$$
forall $n \in \mathbb{N}$ and since $$\sum_{n=1}^\infty \frac{(2n)!!}{(2n+2)!!} = \sum_{n=1}^\infty \frac{1}{2n+2} = \infty$$
then the first series diverges. Is there anything wrong? Thanks in advance.","['convergence-divergence', 'sequences-and-series', 'real-analysis']"
271106,Proof for generalized sum of powers,"Bernouli's Formula for sum of kth powers of first n natural numbers is given by: 
$$f_k(n)=\frac{1}{k+1}\sum_{j=0}^k{k+1\choose j}B_j(n+1)^{k+1-j}$$
where $Bj$ is the $j^{th}$ Bernoulli Number and is in a sense recursively given by:$$B_j=-\frac{1}{j+1}\sum_{i=0}^{j-1}{j+1 \choose i}B_i$$. I did find a generalized proof of this for Generalized case where powers can be complex numbers. I am looking for simpler proofs. Do you have any idea if this can be proved by induction. Thank you. PS. I am not sure of tags and appreciate if they are corrected. Added By simpler I mean that do involve only integer powers.","['exponential-sum', 'bernoulli-numbers', 'number-theory']"
271116,"Prove that $f\circ g$ is differentiable in t=0, but the chain rule doesn't work.","Given $f(x,y)=\begin{cases}\frac{x^2y}{x^2+y^2} &\text{ if }(x,y) \neq (0,0)\\\\ 0&\text{ if }(x,y)=(0,0)\end{cases}$ and let $g(t)=(t,-2t).$ Prove that $f\circ g$ is differentiable in t=0, but the chain rule doesn't work.","['multivariable-calculus', 'calculus', 'real-analysis']"
271117,Continuity of $\arg (z)$,"Let $\mathrm{arg}:\mathbb{C}\setminus \{0\} \to [0,2\pi) $ be the function with $\mathrm{arg}(re^{i\alpha})= \alpha$ and $\alpha \in [0,2\pi)$. How can we prove that $\mathrm{arg}: \mathbb{C}\setminus A \to \mathbb{R}$ is continuous when $A= \{z\in \mathbb{C} | x \geq 0, y=0\}$?",['real-analysis']
271123,When does the quotient of a manifold with boundary become a manifold?,"Given a manifold $M$ with boundary $\partial M \neq \varnothing$, when can we form a manifold $\tilde M$ from $M$ by collapsing the boundary? In the examples I've considered it seems like collapsing each component of the boundary to a separate point will result in a manifold. Obviously we can't collapse a disconnected boundary to a single point, e.g. $M = S^1\times [0,1]$ with $\partial M = S^1 \times \{0,1\}$, since the quotient here will be homeomorphic to a ""pinched"" torus with one of the noncontractible $S^1$ collapsed. However if we collapse $S^1 \times \{0\}$ and $S^1 \times \{1\}$ to separate points, then the result will be the suspension $SS^1 \approx S^2$. I believe that $(M,\partial M)$ will be a good pair due to the existence of a collar neighborhood, so we should have $H_i(M,\partial M) \cong \tilde{H}_i(M/ \partial M)$, and if $M$ compact and orientable, then by Lefschetz Duality we also have $H_i(M,\partial M) \cong H^{n-i}(M,\varnothing) \cong H^{n-i}(M)$. Anyhow, I'm quite sure where that gets us, and I have yet failed to construct a counterexample from my repertoire of spaces.","['general-topology', 'manifolds']"
271134,Is a surjective homomorphism of regular local rings necessarily an isomorphism?,"Let $R$ and $S$ be regular local rings, and $f: R\rightarrow S$ a surjection that induces an isomorphism on tangent spaces. Is $f$ necessarily an isomorphism? I believe the answer should be yes, based on how this setup is used in a paper, but I don't see why. The motivation is to show that the completion of the local ring of a certain scheme is a power series ring.","['commutative-algebra', 'algebraic-geometry']"
271138,convergence of a series involving $x^\sqrt{n}$,"I was trying to prove the convergence of the series $\sum_{n=1}^{\infty}x^{\sqrt{n}}$, for $0<x<1$. Unfortunately, I could not make one of the standard convergence tests give me an answer. Does anybody of you have a suggestion? any help is much appreciated! many thanks!",['calculus']
271141,Number of roots of a complex equation/ Rouche's theorem,"For $n\geq2$ consider the equation $z^n+z+n=0$ for $z\in \mathbb C$. Show that if 
$k$ is an integer with $1\leq k \leq n$ then inside the sector
$$
S_k=\left\{z\in \mathbb C: 0< Arg(z) < \dfrac{2\pi k}{n} \right\}
$$
There are exactly $k$ roots of the above equation. $Arg (z)$ is the principal argument of $z$. (Hint: Prove that $x^n+n>x$ for real $x$) The only thing I can think of is Rouche's theorem but then the region needs to be
bounded to be able to use that. Can anybody give some pointers as to how I should proceed here. Thanks.","['roots', 'complex-analysis']"
271147,"How to show that the 3-cycles $(2n-1,2n,2n+1)$ generate the alternating group $A_{2n+1}$.","I'm asked to show that the 3-cycles $(1,2,3),(3,4,5),(5,6,7),...$ and $(2n-1,2n,2n+1)$ generate the alternating group $A_{2n+1}$. I know the 3-cycles produce the group $A_n$, and it seems like I have to use that. 
Furthermore I know that $(123)$ and the $k$-cycle $(123...k)$ generates $A_k$ with $k$ odd. Seeing that the group $A_{2n+1}$ is odd this seems like a good way to tackle the problem, but from here on I'm stuck. This is not the only question I'm unable to answer about permutation groups.  In general I can't visualize them or see any obvious pattern in their behavior. Any help would be appreciated.","['finite-groups', 'group-theory', 'abstract-algebra']"
271148,True/False Questions for Complex Analysis,"I am studying for my (introductory) complex analysis final exam tomorrow. I am practicing an old final exam, which unfortunately has no answer key. Here is a link: http://www.math.ubc.ca/Ugrad/pastExams/Math_300_December_2008.pdf I just want to know if I am on the right track for Problem 1, which is collection of 10 (kind of tricky!) true/false questions. Here are my attempts: 1) If $f(z)$ satisfies Cauchy-Riemann equations at $z_0$, then $f(z)$ is differentiable at $z_0$. False. For differentiability, one also needs continuity of partial derivatives. 2) If $f(z)$ has a pole at $z_0$, then $\lim_{z\to z_0}|f(z)|=\infty$. True. Though I am not sure if I know how to prove it rigorously. 3) If $f(z)$ is analytic in a domain $D$ containing a simple closed contour $\Gamma$, then $\int f(z)dz=0$. False. For conclusion to be true in general, one needs simply-connected domain. 4) If the two power series $\sum_{k=0}^\infty a_k (z-z_0)^k$ and  $\sum_{k=0}^\infty b_k (z-z_0)^k$ converge to the same function in the disk $\{|z-z_0|\}$, then $a_k=b_k$ for all $k$. I think the answer is True for this one. I believe this follows from Taylor theorem. The coefficients $a_k$ and $b_k$ are determined from derivatives of $f$, so they must be equal. Is this correct? 5) There does not exist any function $f(z)$ which is analytic at the point $0$ and nonanalytic everywhere else. I think the answer is False. I can't think of a counterexample. Maybe the function $|z|^2$ ? 6) The function $\text{Log}(z^2)$ is analytic for all values of $z$ except those on the negative real axis. False. The function $\text{Log}(z^2)$ is analytic for all values of $z$ except those on upper half of imaginary axis. 7) Any entire function is the complex derivative of another entire function True. This follows from Cauchy Integral Formula. 8) If $f(z)$ has an essential singularity at $z_0$, then Res$((z-z_0)f(z); z_0)=0$. I am pretty sure this is false. For example, $f(z)=e^{1/z}$ would be a counter-example. 9) If $f(z)$ and $g(z)$ have a simple poles at $0$, then $(fg)(z)$ has a simple pole at $0$. I think it is true. By the way, I am not sure if the notation above stands for product, or composition. The question doesn't indicate the usage. But I think in either case, the statement would be true. Any comments on this one? 10) If the disk of convergence of the Taylor series of a function $f(z)$ is $\{|z|=2\}$, then the disk of convergence for the Taylor series of $f(z^2)$ is $\{|z|=4\}$. Frankly, I am completely struck at this one. I have not the slightest idea of relating radii of convergence for the functions $f(z)$ and $f(z^2)$. Any help and feedback on any of the questions is much appreciated. I suspect I have made couple mistakes above, apart from the ones I am stuck on. Confirming one of the my answers as correct would be just as awesome! :) Thanks.","['examples-counterexamples', 'complex-analysis', 'analyticity']"
271149,Check If a point on a circle is left or right of a point,What is the best way to determine if a point on a circle is to the left or to the right of another point on that same circle?,"['trigonometry', 'linear-algebra', 'circles']"
271159,Prove that $\int_0^1f(x)dx$$\int_0^1g(x)dx\ge1$.,"Suppose $f(x)$ and $g(x)$ are positive measurable functions defined on $(0,1)$, satisfying $f(x)g(x)\ge1$ for any $x\in(0,1)$. Prove that $\int_0^1f(x)dx$$\int_0^1g(x)dx\ge1$. Totally no idea about this problem. Any hints? Is there any theorem I'm supposed to apply?","['inequality', 'integration', 'real-analysis', 'integral-inequality']"
271162,Finite abelian group generated by elements of maximal order,"I'm trying to prove that a finite abelian group $G$ is generated by elements of maximal order. I can sort of see why that happens in a vague instinctive kind of way but no real hard logic. So far, I have tried to use this lemma: Let $G$ be a finite abelian group and a be an element of maximal order in $G$. Then any element $b$ is such that $|b|$ divides $|a|$. Then each cyclic group generated by the maximal order element contains exactly 1 element of each possible order for an element in the group. I have tried expanding from this idea in a few directions but I don't think it's the correct way to go since it's not going anywhere. Any help appreciated. Thanks guys.","['group-theory', 'abstract-algebra']"
271167,What is the definition of first/last element in a poset?,"I have read the terms first element/last elements in the context of
a basic course in set theory. When I learned about posets I didn't encounter those terms. I tried
looking up the definitions but I didn't find them. Can someone please write down the definitions for first/last element
in a poset ?","['elementary-set-theory', 'definition']"
271172,Bayes' Theorem in Stephen Baxter's Manifold: Time,"I am currently reading the sci-fi novel Manifold: Time by Stephen Baxter, which contains the following problem. You are given a box which has either 10 marbles or 1000 marbles. By pressing a lever on the box, one marble is randomly taken out and given to you. You know that there is exactly one red marble. After pressing the lever three times, you obtain a red marble. The book claims that this information implies, using Bayes' theorem, that the probability that there are 10 marbles in the box is 2/3. Can anyone explain how this computation actually works out, or at least how one is supposed to set up Bayes' equation to get this answer? Thanks.",['probability']
271184,The approximating Hausdorff measure is not Borel,"This is an exercise taken from Mattila, Geometry of sets and measures in Euclidean space , chapter 4. Exercise . Let $U$ be an open ball in $\mathbb{R}^n$ ($n\ge 2$) such that $d(U)=\delta$ [here $d$ stands for ""diameter""]. Show that for $0\le s \le 1$, 
  $$\tag{1} \mathcal{H}^s_\delta(U)=\mathcal{H}^s_\delta\left(\overline{U}\right)=\mathcal{H}^s_\delta(\partial U).$$ Here $\mathcal{H}^s_\delta(A)$ is the infimum of the sums 
$$\sum_{j=1}^\infty d^s(E_j), $$
where $\{E_j\}$ is a covering of $A$ such that $d(E_j)\le \delta$. As $\delta\downarrow 0$, $\mathcal{H}^s_\delta(A)$ tends to the Hausdorff measure $\mathcal{H}^s(A)$. The point of this exercise is to show that, even if $\mathcal{H}^s_\delta$ is a (outer) measure, it is not Borel since it fails to be additive on $\overline{U}=U\cup \partial U$. Can you help me with this exercise? Those things are new to me and I would use a hint to start with. Thank you!","['measure-theory', 'geometric-measure-theory']"
271193,When to use Closed Graph Theorem vs. Uniform Boundedness Theorem?,"I run in to problem that I often know is solvable with either the Closed Graph Theorem or Uniform Boundedness Theorem. I seem to mix up the solutions. Are there any hints on when to use which? Or can they both be used solve the same problem? One example: Let $X$ be a Banach space and let $T_n$ be a sequence of bounded linear maps from $X$ into itself, such that for every $x\in X$ we have $$ \lim_{n\rightarrow \infty} T_nx = x$$ in the norm of $X$. Show that the linear map $T:X\rightarrow X$ is continuous iff the maps $T_nT$ are continuous for each $n\geq 1$. For ($\Leftarrow$), I tried to use the Closed Graph Theorem as follows. Assume $x_n \rightarrow x$ and $Tx\rightarrow y$. Then $$\lim_{m \rightarrow \infty} T_mT\lim_{n \rightarrow \infty}x_n = \lim_{m \rightarrow \infty} T_my = y,$$
and
$$\lim_{m \rightarrow \infty} T_mT\lim_{n \rightarrow \infty}x_n = \lim_{m \rightarrow \infty} T_mTx = Tx,$$
and by the Closed Graph Theorem, we are done. However, the solution to the exercise solved it using the Uniformed Boundedness Theorem.","['operator-theory', 'functional-analysis', 'banach-spaces']"
271197,Every ideal in ring of integers contains a natural number,"Let $O$ be the ring of integers of some number field and $I$ any nonzero ideal of $O$ . Prove that there is some number $n \in \mathbb{Z}_+$ that is in ideal $I$ . I suppose I should use that $O$ is Dedekind domain, so every ideal can be written as product of prime ideals, but I don't know how to use that. Any help is appreciated.","['algebraic-number-theory', 'abstract-algebra']"
271198,Sheaf of meromorphic functions on non-compact Riemann surfaces,"Why does the first cohomology group $H^1(X, K)$ of the sheaf of meromorphic functions on a non-compact Riemann surface $X$ vanish?","['sheaf-theory', 'riemann-surfaces', 'complex-analysis']"
271199,Find all the continuous functions such that $\int_{-1}^{1}f(x)x^ndx=0$.,"Find all the continuous functions on $[-1,1]$ such that $\int_{-1}^{1}f(x)x^ndx=0$ fof all the even integers $n$. Clearly, if $f$ is an odd function, then it satisfies this condition. What else?",['real-analysis']
271202,Can a sequence of functions converge to different functions pointwise and on average?,"Is it possible for a sequence of functions in $\mathcal{C}\left[0,1\right]$
  to converge to one function pointwise (not necessarily to a continuous function) and to a different function in average (i.e with respect to $\Vert f\Vert=\left(\int\limits _{0}^{1}\left|f\left(x\right)\right|^{2}dx\right)^{\frac{1}{2}}$ ? I know neither convergence mandates the other but I'm wondering whether it's possible for both convergences to occur but to different functions. Thanks in advance! Following some of the replies let's take as an example the sequence of functions defined by $f_{n}\left(x\right)=x^{n}$
 , pointwise it has a limit which is $$f\left(x\right)=\begin{cases}
0 & x\in\left[0,1\right)\\
1 & x=1
\end{cases}$$
  but on average I can see that it converges to the zero function as $$\Vert f_{n}\left(x\right)-0\Vert\overset{n\to\infty}{\longrightarrow}0$$
 Obviously $f\left(x\right)$
  and $0$
  are a.e equivalent so $f_{n}$
  also converges to $f$
  on average. However, while the zero function is in $\mathcal{C}\left[0,1\right]$
  the pointwise limit $f$
  is not. So unless I'm missing something here, the limit only has to be same up to a.e equivalence even if it's a sequence of continuous functions. I assume that if the pointwise limit was also continuous then it would have to be equivalent everywhere?","['convergence-divergence', 'sequences-and-series', 'functions']"
271204,Prove that $\lim_{n \to \infty} \binom{n}{k}a^n = 0$,"I'm working with this problem but I have no idea how to solve it. Here $k$ is fixed and $0<a<1$. I was trying to use that $\lim_{n \to \infty} a^n =0$ and that $\binom{n}{k}\leq\frac{n^k}{k!}$ with the $\epsilon$ definition to prove it, my intention was to show that for $N$ large enough $a^N < \frac{k!}{N^k}$ but I got nowhere. I don't know if using the definition is the best aproach.","['calculus', 'binomial-coefficients', 'limits']"
271205,What's the reason why this sequence of function doesn't converge uniformly to $f$?,"Consider $f_n = \sqrt[n]{x}$ on $[0,1]$ So it converges to the step function $f = 0$ if $x = 0$ and $f=1$ otherwise I could see why it doesn't converge if i draw an epsilon rectangle over one part since for each $n$, $f_n$ lies completely outside of the function. If I draw an epsilon rectangle over the whole $f$, I don't see why this isn't uniform convergence EDIT: I got this from Spivak, so keep it at that level please... Added question : if $f_n\nrightarrow f$ for some $x \in \mathbb{R}$, can I conclude that it is not uniformly convergent over $\mathbb{R}$?","['sequences-and-series', 'real-analysis']"
271206,Evaluation of an integral involving the Lambert W function,"Wikipedia claims that $$\int_0^\infty W\left(\frac{1}{x^2}\right) \,\text dx=\sqrt{2\pi}$$ and a numerical computation seems to confirm this. How can this result be proven?","['definite-integrals', 'special-functions', 'integration', 'lambert-w']"
271226,Inequalities of Integer functions,"I have the following statement that I'm trying to prove: Assume that $f,g: \mathbb{N} \rightarrow \mathbb{R}^{\ge0}$. If $f(n) \ge g(n)$ then $\lceil f(n) \rceil \ge \lceil g(n) \rceil $. I have a kind of proof. But it is ugly (by using $f(n) - g(n) \ge 0$ and this will also mean $\lceil f(n) - g(n) \rceil \ge 0$, then check for different conditions, e.g. if the difference less than or equal to 1 etc.) and I'm sure there is a much simpler and more elegant way to prove this. But I couldn't figure out and seeking some help. Edit: I'm not sure if it will help for elegant proof but f and g are also eventually non-decreasing function.","['inequality', 'functions']"
271228,Evaluating series with factorial denominator (sanity check).,"Is my approach to evaluating this series correct? $$\sum_{n=1}^\infty \frac{n}{(n+1)!}$$ Has partial sum equivalent to: $$S_m = \sum_{n=1}^m \frac{n}{(n+1)!} = \sum_{j=2}^{m+1} \frac{j-1}{j!} = \sum_{j=2}^{m+1} \frac{1}{(j-1)!} - \sum_{j=2}^{m+1} \frac{1}{j!} $$ For $j$ such that $m+1>j>2$ the terms of the left sum are cancelled by the terms of the right, leaving $$ S_m =1-\frac{1}{(m+1)!}$$ Hence $ \lim_{m\rightarrow\infty} S_m  = 1$ Apologies for this one. The book I am using hasn't really offered anything on series with factorial denominators (yet). Thanks!",['sequences-and-series']
271232,Possible Jordan Canonical Forms Given Minimal Polynomial,"I was supposed to find all possible Jordan canonical forms of a $5\times 5$ complex matrix with minimal polynomial $(x-2)^2(x-1)$ on a qualifying exam last semester.  I took the polynomial to mean that there were at least two 2's and one 1 on the main diagonal, and that the largest Jordan block with eigenvalue 2 is $2\times 2$ while the largest Jordan block with eigenvalue 1 is $1\times 1$.  Did I miss any matrices or interrupt the minimal polynomial incorrectly? \begin{pmatrix}
  2 &1  &0  &0  &0\\
  0 &2  &0  &0  &0\\
  0 &0  &2  &1  &0\\
  0 &0  &0  &2  &0\\
  0 &0  &0  &0  &1
\end{pmatrix} \begin{pmatrix}
  2 &1  &0  &0  &0\\
  0 &2  &0  &0  &0\\
  0 &0  &2  &0  &0\\
  0 &0  &0  &2  &0\\
  0 &0  &0  &0  &1
\end{pmatrix} \begin{pmatrix}
  2 &1  &0  &0  &0\\
  0 &2  &0  &0  &0\\
  0 &0  &2  &0  &0\\
  0 &0  &0  &1  &0\\
  0 &0  &0  &0  &1
\end{pmatrix} \begin{pmatrix}
  2 &1  &0  &0  &0\\
  0 &2  &0  &0  &0\\
  0 &0  &1  &0  &0\\
  0 &0  &0  &1  &0\\
  0 &0  &0  &0  &1
\end{pmatrix} \begin{pmatrix}
  2 &0  &0  &0  &0\\
  0 &2  &0  &0  &0\\
  0 &0  &1  &0  &0\\
  0 &0  &0  &1  &0\\
  0 &0  &0  &0  &1
\end{pmatrix}","['jordan-normal-form', 'matrices', 'linear-algebra', 'abstract-algebra']"
271233,Why isn't the family of semi-algebras (aka semi-rings) of sets closed under intersection?,"A link says: Any type of algebraic structure on subsets of $S$ that is defined
  purely in terms of closure properties will be preserved under
  intersection. Examples are σ-algebras, π-systems, λ-systems, or monotone classes of subsets. ... Note however, this does not apply to semi-algebras,
  because the semi-algebras is not defined purely in terms of closure
  properties ( the condition on $A^c$ is not a closure property ). ... $S$ is said to be a semi-algebra if it is closed under intersection
  and if complements can be written as finite, disjoint unions: If $A,B∈S$ then $A∩B∈S$. If $A∈S$ then there exists a finite, disjoint collection $\{B_i:i∈I\}⊆S$ such that $A^c=⋃_{i∈I} B_i$. In ""the condition on $A^c$ is not a closure property"", what does ""the condition on a set operation such as taking complement is not a closure property"" mean? What is the meaning of ""closure properties""? How do you see the family of semi-algebras (aka semi-rings) of sets
isn't closed under intersection? Michael Greinecker also commented: The family of semi-rings on a
set are not closed under intersections. BTW, if I am correct,
the concept of a semi-algebra of sets is the same as semi-ring of
sets in Wikipedia . Thanks and regards!",['elementary-set-theory']
