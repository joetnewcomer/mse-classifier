question_id,title,body,tags
2492069,Pullback of ideal sheaf defining closed immersion,"Let $Z\to X$ be a closed immersion with ideal sheaf $\mathcal{I}$. To me the exact sequence $0\to\mathcal{I}\to \mathcal{O}_X\to i_*\mathcal{O}_Z\to 0$ says that the functions in $\mathcal{I}$ are precisely those functions that vanish when we pull them back along $Z\to X$. Based on this interpretation, I would expect that $i^*\mathcal{I}=0$, since we pull back functions that vanish when we pull them back. However, $i^*\mathcal{I}$ is actually the conormal sheaf, and hence not zero. I can do computations to see that $i^*\mathcal{I}$ is indeed the conormal sheaf in the sense that the dimensions of the fibers are indeed the codimension of $Z$ in $X$, so it works out. What I do not understand is why my first reasoning fails. It fails because its not true, but it suggests that I'm not thinking about the ideal sheaf exact sequence in a correct way. So I hope that someone can point out the flaw in the first reasoning.","['schemes', 'algebraic-geometry']"
2492178,irrationality or rationality of $\log(\log(2))$.,"I know the standard proof that $\log_{10}(2)$ is irrational. Can we prove irrationality of  $\log_{10}(\log_{10}(2))$ using, somehow, similar methods?","['irrational-numbers', 'calculus']"
2492189,Prove or disprove : $\sqrt{1 + \sqrt{4+\sqrt{16+\sqrt{256...}}}} = \sqrt{2+\sqrt{5}}$,"Edit: My initial question was regarding the expressions: $\sqrt{1 + \sqrt{4+\sqrt{16+\sqrt{64... + \sqrt{4^{n}}}}}}$ And in general: $\sqrt{1 + \sqrt{k+\sqrt{k^2+\sqrt{k^3... + \sqrt{k^{n}}}}}}$ And their limits, however, my working out was wrong. So, if someone can explain how to find the values of the above two expressions, that would be great! This is just something I've noticed playing around with the radicals, and I honestly don't have much idea on how to prove it. These were my ideas: Let $\sqrt{1 + \sqrt{4+\sqrt{16+\sqrt{256... + \sqrt{4^{2^n}}}}}} = A_n$ My logic was as follows: $A_n = \sqrt{1 + \sqrt{4+\sqrt{16+\sqrt{256... + \sqrt{4^{2^n}}}}}}$ $A_n^2 = 1 + \sqrt{4+\sqrt{16+\sqrt{256... + \sqrt{4^{2^n}}}}}$ $A_n^2 = 1 + 2\sqrt{1+\frac{1}{4}\sqrt{16+\sqrt{256... + \sqrt{4^{2^n}}}}}$ $A_n^2 = 1 + 2\sqrt{1+\sqrt{1+\frac{1}{16}\sqrt{256+... + \sqrt{4^{2^n}}}}}$ $A_n^2 = 1 + 2\sqrt{1+\sqrt{1+\sqrt{1+... + \sqrt{1}}}}$ $A_{\infty}^2 = 1 + 2\sqrt{1+\sqrt{1+\sqrt{1+... }}} = 1 + 2\phi = 2 + \sqrt{5}$ $A_{\infty} = \sqrt{2 + \sqrt{5}}$ Then, rather than this specific case, how would we evaluate: $L = \sqrt{1 + \sqrt{k+\sqrt{k^2+\sqrt{k^4+\sqrt{k^8+...}}}}}$ Would we also get $L = \sqrt{\sqrt{k}\phi + 1}$? And what about expressions such as: $\sqrt{1 + \sqrt{2+\sqrt{3+...}}}$ Thanks for any answers and guidance!","['radicals', 'nested-radicals', 'limits-without-lhopital', 'limits']"
2492194,"2-Sylow subgroup of $\operatorname{GL}(2,3)$","Consider the group $\operatorname{GL}(2,3)$, the group of invertible $2 × 2$ matrices over the field of 3 elements. It is of order $48 = 2^4 \cdot 3$. A 3-Sylow subgroup is easily seen to be the Heisenberg group (unitary upper triangular matrices). What about the 2-Sylow subgroups? Is there a nice way to identify one of them?","['matrices', 'abstract-algebra', 'finite-groups', 'sylow-theory', 'group-theory']"
2492206,Restriction of measurable function,"Let $(X, \mathcal{X})$ and $(Y,\mathcal{Y})$ be measurable spaces, and $f: X \to Y$ a measurable function. Let $A \in \mathcal{X}$ be a measurable subset of $X$. Is it guaranteed that $f_{\mid A}: A \to Y$ is measurable? The measurable space on $A$ is $(X, \mathcal{X})$ restricted to $A$. Formally, the $\sigma$-algebra on $A$ is $\mathcal{A}=\{ S \cap A \mid S \in \mathcal{X} \}$. Proof suggestion: My guess is that it is, because for a measurable $B \in \mathcal{Y}$, $f_{\mid A^{-1}}(B)=f^{-1}(B) \cap A$, and $f^{-1}(B)$ and $A$ are both measurable. On different notions of measurability : Does anything change if we use one of the following definitions for measurable functions? The preimage of every measurable set is measurable (this is the standard definition in my opinion) The preimage of every open set is measurable The preimage of every open set is open (this is a sub-case of the last case)","['measure-theory', 'proof-verification']"
2492260,Does $n+1$ divides $\binom{an}{bn}$?,Suppose that $a>b>0$ be integers.  Is it true that for an integer $n>2$ that $$n+1|\binom{an}{bn}$$ or is there a counter example.  Certainly i think the right hand side would reduce to $$\frac{an(an-1)(an-2)...((a-1)n+1)}{n(n-1)(n-2)...2\cdot 1}$$ But I'm not seeing how this could reduce better to show there is a factor of $n+1$ left. Examples show this is true for small n; for example $$\binom{9}{6}=\binom{3\cdot 3}{2\cdot 3}=\frac{9\cdot8\cdot7}{3\cdot 2\cdot 1}=4(3\cdot 7)$$ $$\binom{16}{8}=\binom{4\cdot 4}{2\cdot 4}=\frac{16\cdot15\cdot...\cdot 10\cdot 9}{8\cdot 7\cdot...\cdot2\cdot 1}=5(2\cdot 3^2\cdot11\cdot 13)$$,"['number-theory', 'combinatorics', 'binomial-coefficients']"
2492272,Increasing polynomial with real coefficients,"Let $P$ be polynomial with real coefficients such that $P(0)=0$ and $P$ is increasing for $x>0$.
I want to maximize $|P(z)|$ on a closed (complex) disk $D(x,r)$ with center $x$ and radius $r$, where $x>0$ and $0<r<x$. More precisely, I want to know if the maximum is necessarily attained on $x+r$ or not. If we also assume that the coefficients of $P$ are positive, then I can show that this holds. But is it in general true?","['complex-analysis', 'real-analysis', 'polynomials']"
2492303,What inequalities should one know to evaluate limits fluently?,"During the Calculus course, we often used common inequalities to estimate the terms of a sequence and find its limit in the end. The problem is that these inequalities, obvious though they may be, seldom come to mind if you have not used them to solve similar problems at least once. I have listed some of them but I think there are more - what should I add to the list? Bernoulli's inequality $n! > 2^n  \iff n \ge 4$ $2^n > n^2\iff n \ge5$","['inequality', 'big-list', 'limits', 'soft-question', 'sequences-and-series']"
2492346,Understanding the proof of $l_2$ being complete.,"Let $l_2$ be the collection of bounded real sequences $x = (x_n)$ for which $\sum_{n=1}^{\infty}|x_n|^2<\infty$. I have to prove that $l_2$ is complete (that every Cauchy sequence in $l_2$ converges to a point in $l_2$). Proof: Let $(f_n)$ be a sequence in $l_2$, where now we write $f_n = (f_n(k))_{k=1}^{\infty}$, and suppose that $(f_n)$ is Cauchy in $l_2$. That is, suppose that for each $\epsilon > 0$ there is a $n_0$ such that $||f_n - f_m||_2 < \epsilon$ whenever $m,n \geq n_0$. We now want to show that $(f_n)$ converges, in the metric of $l_2$, to some $f\in l_2$. 1) First show that $f(k) = lim_{n\to \infty}\,f_n(k)$ exists in $\mathbb{R}$ for each k: To see why, note that $|\,f_n(k) - f_m(k)|\leq ||\,f_n - f_m||_2$ for any k, and hence $(f_n(k))_{k=1}^{\infty}$ is Cauchy in $\mathbb{R}$ for each k. Thus, $f$ is the obvious candidate for the limit of $(f_n)$, but we still have to show that the convergence takes place in the metric space $l_2$; that is, we need to show that $f\in l_2$ and that $||\,f_n - f||_2 \to 0$ (as $n \to \infty$). 2) Now show that $f\in l_2$; that is, $||\,f||_2 < \infty$. We know that $(f_n)$ is bounded in $l_2$; say, $||f_n||\leq B$ for all n. Thus, for any fixed $N < \infty$, we have: $\sum\limits_{k=1}^{N}|\,f(k)|^2 = lim_{n\to\infty}\sum\limits_{k=1}^{N}|\,f_n(k)|^2 \leq B^2$. Since this holds for any N, we get that $||\,f||_2\leq B$. 3) Now we repeat step 2 (more or less) to show that $f_n \to f$ in $l_2$. Given any $\epsilon > 0$ choose $n_0$ such that $||\,f_n - f_m||_2 < \epsilon$ whenever $m,n > n_0$. Then, for any N and any $n\geq n_0$, $\sum\limits_{k=1}^{N}|\,f(k) - f_n(k)|^2 = lim_{n \to \infty}\sum\limits_{k = 1}^{N}|\,f_m(k) - f_n(k)|^2 \leq \epsilon^2$. Since this holds for any N, we have $||\,f - f_n||_2 \leq \epsilon$ for all $n\geq n_0$. That is, $f_n \to f$ in $l_2$. Questions: I think I understand the general idea of the proof. You take a sequence and suppose it's Cauchy. You then have to show that it has a limit and thus converges, and show that the limit lies in $l_2$, which would mean that any Cauchy sequence in $l_2$ is convergent to a point in $l_2$. So why is step 3 necessary? I must be mistaken, but it seems to me that in step 1 and 2 it has already been proven that the chosen sequence has a limit and that it lies in $l_2$. I don't understand the notation that is used in this proof: ""Let $(f_n)$ be a sequence in $l_2$, where we now write $f_n = (f_n(k))_{k=1}^{\infty}$"". Why is the letter $k$ added to the sequence and what does it mean? If you have a sequence $x_n$, the subscript is the argument right? Can't you write $x_n$ like $x\,(n)$? Why does $|\,f_n(k) - f_m(k)|\leq||\,f_n - f_m||_2$ imply that $f_n(k)$ has a limit? Perhaps this will be clear once I understand the use of the letter $k$. Thanks in advance!","['real-analysis', 'limits', 'continuity', 'convergence-divergence', 'sequences-and-series']"
2492355,"Are there any relations between $H^n(S\setminus\{p\}, \mathcal{O})$ and $H^n(S, \mathcal{O})$ when $\{p\}$ is rational singular point?","Let $S$ be a rational surface over $\mathbb{C}$, $\{p\} \subset S$ be a rational singular point. My question is, are there any relations between $H^n(S\setminus\{p\}, \mathcal{O})$ and $H^n(S, \mathcal{O})$ in general? Or, how to compute $H^n(S\setminus\{p\})?$ I think, because $S$ is normal and codim$_{S}(\{p\}) = 2$,
$H^0(S\setminus\{p\}, \mathcal{O}) \simeq  H^0(S, \mathcal{O}) \simeq \mathbb{C}$. 
(Is it true?) My motivation is as follow: Suppose there exists a map $\pi: V \rightarrow S$ onto a rational surface S  which contracts some divisor $D$ of $V$ to $\{p\}$, i.e. which is an isomorphism at every point of $V \setminus D$ and such that $\pi(D)$ is a single point (rational singular point).
Then, I would like to know $H^n(V \setminus D, \mathcal{O})$.","['sheaf-cohomology', 'algebraic-geometry']"
2492369,Evaluate $\int_{-\infty}^\infty \frac{\cos x}{1-x^4}dx.$,"It equals $\Re \int_{-\infty}^\infty \frac{e^{iz}}{1-z^4}dz.$ The integrand $f(z)=\frac{e^{iz}}{1-z^4}$ has one simple pole$(z=i)$ in the upper half-plane, two simple poles$(z=\pm1)$ on the real axis. $Res(f,i)=\frac{ze^{iz}}{-4} |_{z=i}=-\frac{ie^{-1}}{4}, Res(f,1)=-\frac{e^i}{4}, Res(f,-1)=\frac{e^{-i}}{4}.$ By contour integration, $\Re \int_{-\infty}^\infty \frac{e^{iz}}{1-z^4}dz = \Re[2\pi iRes(f,i)+\pi i\big(Res(f,1)+Res(f,-1)\big)]=\frac \pi 2(\sin 1+e^{-1}).$ But the answer gives ""$\frac \pi 4(e^{-1}-\sin1)$"". Where is wrong?","['complex-analysis', 'contour-integration', 'residue-calculus']"
2492371,Integral on a completion of measure space,"Let $(X,{\cal M}, \mu)$ be a measure space with completion $(X,\bar{{\cal M}},\bar{\mu})$. If $f \in {\cal L}^1(X,{\cal M},\mu)$, show that $f \in {\cal L^1}(X,\bar{\cal M},\bar{\mu})$ and $\int fd\mu = \int f d\bar{ \mu}$ My attempt: firstly to show that $f$ is $\bar {\cal M}$ measurable, let $E \in {\cal B}_{\mathbb{C}}$, then $f^{-1}(E) \in \cal{M}$, by the definition of completion, $\bar{\cal M} := \{F \cup G: F \in {\cal M}, G \subseteq N, N \in {\cal M}, \mu(N) = 0\}$, if we set $G = \emptyset $, then we can have $f^{-1}(E) \in \bar {\cal M}$, hence $f$ is $\bar {\cal M}$ measurable. Furthermore, $f \in {\cal L}^1(X, \bar{\cal M},\bar{\mu})$ will directly follow from $\int f d\mu = \int f d \bar{\mu}$, but how to show this? I appreciate your help!","['real-analysis', 'measure-theory']"
2492383,"What is the real thing when using Taylor to prove limits, such as $\lim_{x \to 0}\frac{\sin x-x}{x^3}=\frac16$?","I see some answers in this site proving many limits by Taylor, for example $$\lim_{x \to 0}\dfrac{\sin x-x}{x^3}=-\dfrac16$$ comes to my mind. However, my teacher didn't teach me this technique, also the popular calculus/analysis books I have do not even mention this technique. When people use Taylor to compute this limit, they often use big-$O$ operations, or omitting the terms having high order. However, what are the big-$O$ techniques? How does they work? Why is this rigorous? And how to choose where the omitting occurs? Should I use Taylor ""expansions"" (with Lagrange remainder) or Taylor ""series""? I totally have no idea. Need your help.","['real-analysis', 'taylor-expansion', 'limits']"
2492396,How do I transform $(\sin^2y + x \arctan y)y' = 1 $ to apply Lagrange's method?,"Orignal equation is: $$(\sin^2y + x \arctan y)y' = 1 $$ It is very well seen that the equation is first-order non-linear one, so I wanted to use Lagrange's method here, but I do not know how to transform it to $$y'+p(x)\cdot y = q(x)$$ which is standard form of the equation",['ordinary-differential-equations']
2492414,Minimum over Probability Measures,"Let $f$ and $g$ be polynomials in $\mathbf x \in \mathbb R^n$.  Let $X$ be a compact subset of $\mathbb R^n$.  Finally, Let $\mathcal M(X)$ be the set of probability measures over $X$. Can the optimization problem \begin{equation}
\inf_{P\in \mathcal M(X)} \left ( \int f \ dP\right )^2 - \left ( \int g \ dP\right )^2
\end{equation} be expressed exclusively in terms of the polynomials $f$ and $g$, without reference to the measure $P$? For example, my hunch is that the above optimization problem is equivalent to \begin{equation}
\min_{\mathbf x \in X} f(\mathbf x)^2 - g(\mathbf x)^2,
\end{equation} but I don't know how to prove this.  Anyone have any ideas?","['polynomials', 'optimization', 'sums-of-squares', 'probability-distributions', 'measure-theory']"
2492435,"Integral $\int^1_0\frac{\log\cos(\frac{\pi x}{2})}{x(1+x)}\,dx$ with logarithm of cosine and rational function.","I have to compute an explicit form for: $$\int^{1}_{0}\frac{\log\cos\left(\frac{\pi x}{2}\right)}{x(1+x)}\,dx$$ I tried with contour integration around rectangle but it failed.","['integration', 'definite-integrals', 'calculus', 'closed-form']"
2492505,Relationship between total support and fully indecomposability.,"I have to prove that if a nonnegative matrix $A$ has total support then there exist $P,Q$ permutation matrix such that $$PAQ=\bigoplus_{i=1}^k A_i$$ where $A_i$ is fully indecomposable $\forall i=1,\dots, k$ and the $\bigoplus$ symbol means ""direct sum"" of matrices. I found many reference on this theorem but no one is complete. Could you help me? Some papers I found cite , but I cannot find a link between the two ones.","['matrices', 'permutations', 'linear-algebra']"
2492517,How the Brownian motion escapes the minimum? A question based on the Lecture notes from Zeitouni on RWRE,"In the ""Lectures on Probability Theory and Statistics Ecole d’Eté de Probabilités de Saint-Flour XXXI - 2001"" in page 249 one reads $$A_n^{J,\delta}=\left\{\begin{array}{ll}\omega\in\Omega:\!\!\! & \overline{b} ^n =\overline{b} ^n_\delta, \text{ any refinement }(a,b,c)\text{ of }(\overline{a} _\delta^n,\overline{b}_\delta^n,\overline{c}_\delta^n)\text{ with}\\ & b\neq\overline{b}^n\text{ has depth }<1-\delta,|\overline{a}^n_\delta|+|\overline{c}_\delta^n|\leq J, \\ & \min_{t\in[\overline{a}^n,\overline{b}^n]\left\backslash\right. [\overline{b}^n-\delta,\overline{b}^n+\delta]}W^n(t)-W^n(\overline{b}^n)>\delta^3\end{array}\right\}$$ $\text{then}$ $\text{it}$ $\text{is}$ $\text{easy}$ $\text{to}$ $\text{check}$ $\text{by}$ $\text{the}$ $\text{properties}$ $\text{of}$ $\text{Brownian}$ $\text{motion}$ $\text{that}$ $$\lim_{\delta\to0}\lim_{J\to\infty}\lim_{n\to\infty}P(A^{J,\delta}_n)=1.\tag{2.5.2}$$ To check 2.5.2 I need to check $$ P(\min_{t\in[a^n,c^n]\backslash [b^n -\delta, b^n+\delta]} W_t - W_b > \delta^3) \xrightarrow[\delta \to 0]{} 1$$ where here $W_t$ is a Brownian motion. and $b$ is the minimum of the Brownian motion in the interval $[a,c]$ In words, I want to prove that the minimum of the brownian motion reached at $b$ is isolated and that nowhere on an interval $[a,c]$ it get's closer than $\delta^3$ to this minimum. I understand that the Brownian motion behaves in a scale that is almost $\sqrt{\delta}$ . But the typical results do not hold for special points like the minimum, once typically, say, at 0, one has that the Brownian motion visits infinitely often the positive and the negative numbers, a oscillatory behavior that certainly does not apply for the minimum. How do I prove this result?","['probability-theory', 'brownian-motion']"
2492520,Show that $f:\mathbb{R}\to\mathbb{R}$ is Borel measurable if $f$ is either right continuous or left continuous.,"$f$ is Borel measurable if $\forall c\in\mathbb{R}$ the set $\{w\in\mathbb{R}:f(w) < c\}\in \mathcal{B}$ Suppose the function is left continuous. Then we have that $$\lim_{x \nearrow a} f(x) = f(a)$$ From this we get that the set $\{w\in\mathbb{R}:f(w) < c\}$ is in fact a union of intervals in $\mathbb{R}$ and therefore in $\mathcal{B}$. Same argument can be used for right continuous functions if you use the set $\{w\in\mathbb{R}:f(w) > c\}$ instead. Does this make sense? I'm not sure if it is rigorous enough, especially the part where I say it's a union of internals. Maybe I could construct that somehow?","['borel-sets', 'borel-measures', 'measure-theory', 'proof-verification']"
2492533,"Why does dividing ""population"" by ""average life expectancy"" generate the ""death rate""?",I've a general basic question: why when we divide a population to the average life expectancy (average lifetime) creates the number of people who die at time t? I think this is related to the Little's law. but I can't really grasp why when we divide the number of people to its average lifetime creates the number of people who died. Can anyone explain in simple terms. I really appreciate your response. Regards.,"['integration', 'ordinary-differential-equations']"
2492564,When does $(\phi(n)-1)\mid (n-2)$.,"Find all integers $n>2\in\mathbb{N}$ such that $(\phi(n)-1)\mid (n-2)$. Did some manipulation i saw that $n=6,2^{k}$ or a prime. But i am not sure how to prove or disprove this. Of course here $\phi(N)$ is the Euler's totient function.","['number-theory', 'elementary-number-theory']"
2492624,Prove that $\mathbb Z_8$ and $\mathbb Z_{24}/\langle 8\rangle$ are isomorphic.,"Use the Fundamental Homomorphism Theorem to prove that $\mathbb Z_8$ and $\mathbb Z_{24}/\langle 8\rangle$ are isomorphic. The following function is a homomorphism from $\mathbb Z_{24}$ to $\mathbb Z_8$:
$\bigl(\begin{smallmatrix}
  0& 1 & 2 & 3 & 4 &5&6&7&8&9&10&11&12&13&14&1&16&17&18&19&20&21&22&23 \\
  0 & 1 & 2 &3 & 4&5&6&7&0&1&2&3&4&5&6&7&0&1&2&3&4&5&6&7
\end{smallmatrix}\bigr)$. Thus we can say $\operatorname{ker}(f)=\{0,8,16\}$. Thus $\mathbb Z_{24}/\langle 8\rangle$ is a homomorphism to $\mathbb Z_8$. By the FHT, $\mathbb Z_8 \cong \mathbb Z_{24}/\langle 8\rangle$. Is this the correct use of FHT? I thought I needed to show that group/ker $\cong$ im?","['abstract-algebra', 'group-theory']"
2492645,"When determining the solution of a system of equations with free variables, can any set of variables be selected as the free variable?","In this example $x_3$ and $x_4$ were the non-pivot variables and therefore used as the free variables. Is it possible to select any two variables as free variables and if not, is there a general rule/way to tell if the variables you want to use as the free variable can actually be used as free variables? I attempted manipulate the solution so $x_1$ and $x_2$ are the free variables but it seems I cannot escape using at least one of $x_3$ or $x_4$ as the free variable as one equation has $x_3 - x_4$ and another has $x_4 - x_3$.","['matrices', 'matrix-equations', 'linear-algebra']"
2492647,Smooth sections of a closed manifold form a complete metric space,"Let $M$ denote a closed, finite-dimensional smooth manifold. I could not find a single result stating that the set of (smooth) sections of the tangent bundle, i.e. $$\Gamma(TM)=\{s \in C^{\infty}(M,TM) \mid \pi \circ s=id_M\}$$ is a complete metric space (for some metric inducing the strong $C^{\infty}$-topology), so I tried the following: It is known that the weak and strong topologies on $$X=C^{\infty}(M,TM)$$ agree (because $M$ is compact) and that there exists a metric $d$ on $X$ such that $(X,d)$ is a complete metric space (a standard reference for this is the Differential Topology book by Hirsch). So if we are able to show that $$\Gamma(TM) \subset X$$ is closed we are done. So let $\left(s_n\right)_{n \in \mathbb{N}} \subset \Gamma(TM)$ be a convergent sequence of sections with limit $s \in C^{\infty}(M,TM)$. I didn't check it rigorously, but I'm pretty sure that the map $$\Gamma(TM) \to C^{\infty}(M), \; g \mapsto \pi \circ g$$ is continuous with respect to the $C^{\infty}$-topology on both sides. Then $s_n$ converging to $s$ implies that $id_M=\pi \circ s_n$ converges to $\pi \circ s$ and thus $$\pi \circ g= id_M.$$ Is this line of reasoning valid?","['general-topology', 'differential-geometry']"
2492668,Different behaviour of Newton's method for finding minimum of a function,"Given the following function of two variables $$f(x, y) = 2x^2 − 2xy + y^2 + 2x − 2y$$ I wanted to use Newton's method to find a minimum of this function. I started from $(x_1, y_1) = (0, 0)$ and applied the following formula $$x_{k+1} = x_k - \alpha \left(\nabla(f(x_k)^{2}\right)^{-1} \nabla(f(x_k))$$ where $$ \alpha = \frac{\nabla(f(x_k))^{T} \nabla(f(x_k))}{\nabla(f(x_k))^{T}(\nabla(f(x_k)^{2})\nabla(f(x_k)) }$$ I obtained $(x_2, y_2) = \left(0, \frac{1}{5}\right)$ and $(x_3, y_3) = \left(0, 0\right)$. So I decided to check by induction if in general we have $(x_{2k}, y_{2k}) = \left(0, \frac{1}{5}\right)$ and $(x_{2k+1}, y_{2k+1}) = (0, 0)$. It turns out that this is true, so I will never obtain a minimum for $k \rightarrow \infty$. Can anyone explain me this strange behaviour of this method.","['optimization', 'newton-raphson', 'multivariable-calculus', 'quadratic-programming', 'numerical-optimization']"
2492679,Absolute continuity for vector measures,"By definition, a real measure $\mu$ is absolutely continuous with respect to a real measure $\nu$ if, whenever $\nu(A)=0$, then $\mu(A)=0$. We also know that, for finite real measures, absolute continuity is equivalent to every of the following conditions $\forall$ $\varepsilon>0$ $\exists$ $\delta>0$ such that $\nu(A)<\delta$ $\Rightarrow$ $\mu(A)<\varepsilon$ There exists a $\nu$-integrable real function $f$ such that
$$\mu(A)=\int_A f d\nu$$ Does anyone know whether there exist similar conditions for vector measures, i.e. measures taking values in Banach spaces? At least, can you suggest any book where you think I may find more information? Thanks,
Alessandro","['functional-analysis', 'measure-theory']"
2492702,Hessian of a function at the critical points,"Let $f:M\to\mathbb{R}$ be a smooth function and $p\in M$ is a critical point of it. The Hessian of $f$ at a critical point $p$ is a symmetric bilinear form $\operatorname{Hess} f_p$ s.t. $\forall v,w\in T_pM$, 
    $$\operatorname{Hess} f_p(v,w)=V_p(W(f)),$$
    where $V,W$ are the extensions of $v$ and $w$ to vector fields such that $V_p=v$ and $W_p=w$. Let the critical set of $f$ contains a submanifold $C$. Put a Riemannian metric on $M$ and $\forall p\in C$ consider the decomposition  $$T_pM=T_pC\oplus T^{\perp}_pC.$$ Let $v\in T_pC$ and $w\in T^\perp_pC$. Then show that $$\operatorname{Hess} f_p(v,w)=0.$$ I would appreciate any comment","['hessian-matrix', 'riemannian-geometry', 'differential-geometry', 'morse-theory']"
2492760,Is the tangent space to a critical submanifold a subspace of the kernel of the Hessian?,"Trying to solve a question I have been faced with another question. Let $f:M\to\mathbb{R}$ be a smooth function and $b\in \mathbb{R}$ a critical value of it. Now the following relation is true? 
$$T_qf^{-1}(b)\subset \operatorname{Ker}\operatorname{Hess}_qf=E_0,$$
where $E_0$ is the eigenspace associated to the eigenvalue $0$. FYI: The Hessian of $f$ at a critical point $q$ is a symmetric bilinear form $\operatorname{Hess} f_q$ s.t. $\forall v,w\in T_qM$, 
    $$\operatorname{Hess} f_q(v,w)=V_q(W(f)),$$
    where $V,W$ are the extensions of $v$ and $w$ to vector fields such that $V_q=v$ and $W_q=w$. I would appreciate any comment","['hessian-matrix', 'riemannian-geometry', 'differential-geometry', 'morse-theory']"
2492770,All smooth real functions are related by coordinate change?,"Suppose you have two smooth functions $F,G:\mathbb{R}^n\rightarrow \mathbb{R}$ with the property that none of the partial derivatives vanish anywhere.  I wonder if it's possible to find functions  $P:\mathbb{R}^n\leftrightarrow \mathbb{R}^n$ and $Q:\mathbb{R}\rightarrow \mathbb{R}$ such that $$G = Q\circ F\circ P.$$ I feel like it should be possible, using Jacobians or something as a change of coordinates, but I'm not sure how to begin or if I need further restrictions. If this result is true, it would imply that in some sense all real functions of this form with non-vanishing partial derivatives are equivalent through a kind of change of coordinates. Here's a solution for a special case. If the dimension is $n=1$, then $F$ and $G$ are smooth monotone functions and are therefore invertible. Let $P$ be the identity function, and let $Q=G\circ F^{-1}$. Of course, if $F$ is not also surjective, then $Q$ is not well-defined everywhere; perhaps it is possible to extend $Q$ to all of $\mathbb{R}$, though I'm not sure how smoothly. And if the dimension $n>1$, then here is a sketch of what I think shows the result: Intuitively, there ought to be (integral?) curves $\gamma_1,\gamma_2:\mathbb{R}^1\rightarrow \mathbb{R}^n$ through the domains of $F$ and $G$ such that $F\circ \gamma_1$ is a monotonic function passing through all possible values of $F$, and similarly for $G$. These curves define a fixed transformation between the codomains of $F$ and $G$, by $Q\equiv (G\circ \gamma_2) \circ (F\circ \gamma_1)^{-1}$. Intuitively, it should be possible to parametrize the graphs of $F$ and $G$ using $n$ coordinates, where the first coordinate tells you the level and the remaining coordinates uniquely specify a point in the domain with that level. Because of the conditions on $F$ and $G$, I expect these can be expressed as smooth functions $\mathbb{R}^n\rightarrow \mathbb{R}^n$. In another way of looking at it, there should be smooth functions $T_1, T_2 : \mathbb{R}^{n-1} \times \mathbb{R}^n \rightarrow \mathbb{R}^n$ which carry points in $\mathbb{R}^n$ smoothly and invertibly through all other points in $\mathbb{R}^n$ with the same $F$ (respectively $G$) level. We think of the second argument as being the point $x$, and the first argument as being a ""displacement"" within the level surface at $F(x)$. (I am a little concerned about level sets shaped like $n$-spheres, in which case this construction doesn't work invertibly— but perhaps such level sets are not possible if $F$, $G$ have everywhere nonzero partials. In that case, the level sets will be sort of $\mathbb{R}^{n-1}$-shaped, always.) By combining the flow functions $T_i$ and the canonical curves $\gamma_i$, we obtain functions $H_i \equiv T_i(s, \gamma_i(t))$ which send $\mathbb{R}^{n-1} \times \mathbb{R}$ smoothly into all of $\mathbb{R}^n$. Intuitively, there should be a smooth isomorphism $P:\mathbb{R}^n\rightarrow \mathbb{R}^n$ which sends the level sets of $G$ to the level sets of $F$. In particular, we should be able to pick one which sends the canonical points $\gamma_2(\mathbb{R})$ to the canonical points $\gamma_1(\mathbb{R})$ so that $P\circ \gamma_2 = \gamma_1$. We can do so concretely by defining $P(x) = H_1\circ H_2^{-1}$ Hence our solution is to use $Q\equiv (G\circ \gamma_2) \circ (F\circ \gamma_1)^{-1}$, sending levels of $F$ monotonically to levels of $G$, and $P\equiv H_1\circ H_2^{-1}$, sending level sets of $G$ to level sets of $F$ in a monotonic-like way. (specifically, if $G(x) < G(y)$, then $F\circ P(x) < F\circ P(y)$ or something like that). (Here, $H_2^{-1}$ looks up the unique way of expressing point $x$ as ""distance"" traveled along a $G$-level curve from some canonical other point with the same $G$-level. The result is a flow amount $s$; $H_1$ looks up the point with the same $F$-level as $x$ and applies the flow amount $s$ to it, resulting in a uniquely defined new point $x^\prime$, with certain special properties.) Does this kind of construction work? I think if $n>1$ then we can construct $H_i$ as follows: because the partials of $F$ and $G$ don't vanish, we should be able to find unit vector fields $\mathbb{R}^n\rightarrow \mathbb{R}^n$ which are smooth and perpendicular to the gradients of $F$ and $G$, respectively; then the flow functions $H_i$ can simply translate along the integral surfaces of these vector fields.  I think the only obstacle I see is if the integral surfaces are of incompatible shape— for example, if one is a line and the other a circle. But maybe the level surfaces can't be things like circles, because then the functions $F$ and $G$ wouldn't have everywhere nonvanishing partials (?). Here's a concrete example of this construction for if $F$ is the sum function and $G$ is the multiplication function (ignoring the fact that $G$'s level sets have many branches): We can pick canonical curves $\gamma_1(t) = \langle \vec{0}, t \rangle$ and $\gamma_2(t) = \langle \vec{1}, t\rangle$ so that $F\circ \gamma_1$ and $G\circ \gamma_2$ pass through all possible values. These curves define the level-transforming function $Q \equiv (G\circ \gamma_2) \circ (F \circ \gamma_{1})^{-1}$; in this case, you can find that $Q$ is just the identity. We can pick flow functions to send points to all other points on the same level surface : $T_1(s,x) = x + \bar{s}$, where $\bar{s} \equiv \langle s_1, \ldots, s_{n-1}, \sum_i s_i\rangle$. $T_2(s, x) \equiv x \cdot \bar{s}$, where $\bar{s} \equiv \langle e^{s_1}, \ldots, e^{s_{n-1}}, e^{\sum_i s_i}\rangle.$ In combination with the canonical curves $\gamma_i$, these flow functions give us $H_i(s,t) = T_i(s, \gamma_i(t))$. Here, $H_1(s,t) = \langle \vec{s}, t - \sum_i s_i\rangle$ and $H_2(s,t) = \langle e^\vec{s}, t\cdot e^{-\sum_i s_i} \rangle$. Hence we define $P \equiv H_1 \circ H_{2}^{-1}$. To be clear, $H_2^{-1}(y) = \langle \log{y_1}, \ldots, \log{y_{n-1}}, \prod_i y_i \rangle$. In which case, $$P(x_1,\ldots, x_n) = \langle \log{x_1}, \ldots, \log{x_{n-1}}, \prod_i x_i - \sum_{i=1}^{n-1} \log{x_i}\rangle$$ And we find that $Q\circ F \circ P = F \circ P = \prod_i x_i = G$ (if you add up all the entries in $P$, the log terms all cancel and you're left with the product.) There are of course other $P$ and $Q$ with this same effect; it all depends on the choice of canonical curve $\gamma_1, \gamma_2$, for instance.","['multivariable-calculus', 'jacobian']"
2492791,Combinatoric problem with balls,"Suppose there are $10$ balls in an urn, $4$ blue, $4$ red, and $2$ green. The balls are also numbered $1$ to $10$. How many ways are there to select an ordered sample of four balls without replacement such that the number B $\geq 0$  of blue balls, the number $R \geq 0$ of red balls, and the number $G \geq 0$ of green balls are all different? If $|B|,|R|,|G|$ are all different and  $|B|+|R|+|G|=4$, then there can only be combinations with the numbers $0,1,3$. So I listed all of the possibilities : $310$,$130,031,301$ For $310$ we have $3$ blue balls, $1$ red ball and $0$ green. So we have $(4 \times 3 \times 2) \times (4) $ ways For $130$ we have $1$ blue balls, $3$ red ball and $0$ green. So we have $(4 ) \times (4 \times 3 \times 2) $ ways For $031$ we have $0$ blue balls, $3$ red ball and $1$ green. So we have $(4 \times 3 \times 2) \times (2)$ ways For $301$ we have $3$ blue balls, $0$ red ball and $1$ green. So we have $(4 \times 3 \times 2) \times (2)$ ways Adding up we get $96+96+48+48=288$ The real answer should be $1152$. What am I doing wrong?","['combinations', 'combinatorics', 'discrete-mathematics']"
2492867,"How to find a power function, representing a model for data?","In a calculus textbook by late James Stewart I encountered an exercise to find a power function, as a mathematical model approximately representing data: The table shows the number N of species of reptiles and
amphibians inhabiting Caribbean islands and the area A of
the island in square miles. 

a) Use a power function to model N as a function of A.

Island      A        N 
Saba        4        5
Monserrat   40       9
Puerto Rico 3,459    40
Jamaica     4,411    39
Hispaniola  29,418   84
Cuba        44,218   76 The confusing thing is that in the previous pages of the textbook there were no explanation of how to do it, except using special software like Mathematica© and only for a linear model. The correct answer from the textbook is: $N = 3.1046 A^{0.308}$ Could anyone explain to me, please, how this answer was obtained? I myself found another answer $N = A^{-2.47295*10^{-6} * A + 0.504732}$ by finding $log_A N$ for every item in the table (except the first one, which looked far out of order) and then finding the linear regression for these values with Mathematica©'s tool Fit (which I took as the exponent value for my function): Island      A        N(real)   N(the textbook's func.) N(my func.)
Saba        4        5         4.75817                 2.01314
Monserrat   40       9         9.6703                  6.43358
Puerto Rico 3,459    40        38.1946                 57.0098
Jamaica     4,411    39        41.1645                 63.0608
Hispaniola  29,418   84        73.848                  85.1851
Cuba        44,218   76        83.724                  68.6738 The right answer definitely looks more close to the reality, so could anyone, please, explain to me, how it was obtained?","['statistics', 'mathematical-modeling']"
2492941,Proving $3^n+2(17^n)$ can't be a perfect square for all positive integers n.,"I think I have a valid proof of this question, but as my textbook doesn't provide an answer, I would appreciate some clarification. Let $f(n)=3^n+2(17^n)$, and the question asks to show $f(n)$ is never a perfect square for positive integers n. Using quadratic residues, we see: $x^2(mod 5)$ is either $ 0, 1, 4 $ only. Taking $f(n)$ and breaking it up into $3^n$ and $2(17^n)$, we can see the following modulo-periodic sequences taking each part $mod5$ The sequence of $3^n (mod5)$ is: $ 3, 4, 2, 1 ,3...$, with a period of $4$, for positive integers $n$. The sequence of $2(17^n)$ $(mod5)$ is : $4, 3, 1, 2, 4...$, with a period of 4. Hence, $f(n)$ $(mod 5)$ is equal to the sum of each corresponding element in each sequence, taken $(mod 5)$. This produces the sequence: $2, 2, 3, 3, 2, 2, 3, 3, 2.....$ Hence, $f(n)$ $(mod5)$ leaves remainders of $2$ and $3$ only, and as a square $(mod5)$ leaves remainders of $0, 1, 4$ only, $f(n)$ can never be a perfect square. Thanks.","['number-theory', 'quadratic-residues']"
2492975,Sup of measure of intersection points,"This is a problem I've thought up myself while travelling in a car, and I have no idea how to solve it.
Let $f: [0,1] \to [0,1]$ be bijection. Consider unit square $[0,1] \times [0,1]$, and label one edge $x$ and the opposite edge $f(x)$. Connect all points $x$ in the $x$ edge to their corresponding points $f(x)$ in the $f(x)$ edge with straight lines. For any function $f(x)$ as described before, let $A(f)$ be the set of points where two or more lines intersect.
The question is this. If $\mu$ is the Lebesgue measure, when taken for all bijections $f(x)$ for which $\mu(A(f))$ exists,  what is $\sup \mu(A(f))$? Clearly, considering
$$f(x) = \begin{cases} 
      x + 1/2 & 0< x < 1/2 \\
      x - 1/2 & x \geq 1/2\\
      1 & x = 0
   \end{cases}
$$
The square is illustrated in the image below from which we get that
$$ \mu(A(f)) = 1/4$$
and so 
$$\frac{1}{4}\leq \sup \mu(A(f))\leq 1$$
The illustration below shows what the square with the lines looks like for $f(x) = 1-x$. In this case, $A(f)$ is clearly $\{(1/2,1/2)\}$ and so $\mu(A(f)) = 0$","['real-analysis', 'lebesgue-measure', 'measure-theory', 'geometry', 'general-topology']"
2493035,Difference between strictly increasing and increasing.,"I know that ,based on definitions, in the interval $(a,b)$ For increasing functions, $f(a) \leq f(b)$ and $f'(x) \geq 0$ For strictly increasing functions, $f(a)<f(b)$ and $f'(x)>0$ However, For example, I am given a question: Given that $y=4x^3 +3x^2 -6x -7$, find the range of values of $x$ for which $y$ is decreasing. For $y$ to be decreasing, 
$\frac{dy}{dx} \leq 0$ So, $-1\leq x\leq\frac12$ right? But for strictly decreasing, $-1<x<\frac12$ right? Then for increasing, it should be $x \leq -1$ and $x\geq \frac12$ For strictly increasing, it should be  $x< -1$ and also $x \geq \frac12$ (I heard it can start from $\frac{dy}{dx}=0$ ) Basically, the problem is what type of inequality sign do I use for which case? Yes, I did see the other posts on this topic and some quora posts. But I'm still lost.","['calculus', 'functions']"
2493037,Probability of rolling a double $6$ with two dice,"Two dice (with numbers 1 to 6 on the faces) are rolled. One die rolls a 6. What is the probability of rolling a double 6? One solution is to say that P(2 sixes) = $\frac{1}{6}$ since the first die gives a 6, so the only way to get a double six is by rolling a six on the other die (which has a 1 in 6 chance). Another solution is to say that there are 11 possible combinations if one die rolls a six i.e. (1, 6), (2, 6), (3, 6), (4, 6), (5, 6), (6, 6), (6, 5), (6, 4), (6, 3), (6, 2) and (6, 1). So the probability of rolling a double six if one six has already been rolled is $\frac{1}{11}$. Which answer is correct and why?",['probability']
2493043,Every solution of $x'' + x + x^3 = 0$ is set on $\mathbb R$. What happens with $x'' + x' + x + x^3 = 0$?,"Exercise : Show that every solution of $x'' + x + x^3 = 0$ are set on $\mathbb R$. What happens with the solutions of $x'' + x' + x + x^3 =0 $ ? Attempt : It is : $$ x'' + x + x^3 = 0 \Leftrightarrow x'' = -(x+x^3) \Leftrightarrow x'' \cdot x' = -(x+x^3)x' \Rightarrow \int x'' \cdot x'dt = \int [ -(x+x^3)x' ]dt \Leftrightarrow \frac{1}{2}x'^2 + c_2 = -\frac{1}{4}x^2(x^2 + 2)  + c_1 \Leftrightarrow x'^2 = C - 2x^2 - x^4$$ So we conclude that : $$x'^2 = C - 2x^2 - x^4$$ and we can see that the right-handed side of this differential equation becomes negative for any $C$ when $x$ becomes large enough (due to $x^2$ and $x^4$), which means that any solution associated to $C$ gets ""deleted"" before it reaches such a point. Which leads us to the conclusion that the only global solution is $x' = 0$ . But how can I derive from that, that all the solutions of that equation are set on $\mathbb R$ ? Also, I cannot seem to grasp how to work on the second given equation. Any help would be appreciated !","['dynamical-systems', 'boundary-value-problem', 'stability-in-odes', 'ordinary-differential-equations', 'initial-value-problems']"
2493045,Finding the Taylor polynomial of $f(x) = \frac{1}{x}$ with induction,"So I am asked to find the Taylor polynomial of $f(x) = \frac{1}{x}$ about the point $a=1$ for ever n$\in{N}$, and then use induction to justify the answer. I got the Taylor polynomial which was simple enough: $$T_{n}(x)=\sum_{n=0}^{\infty} \frac{f^n(x)(a)}{n!}(x-a)^n$$ $$f(x) = 1-(x-1)+(x-1)^2-(x-1)^3+(x-1)^4+...$$ $$T_{n}(x)=\sum_{n=0}^{\infty} (-1)^n(x-1)^n$$ That wasn't too bad. How do I justify this with induction though? I am a little confused as to how I would start this. I tried writing out the terms as such: $$1-(x-1)+(x-1)^2-(x-1)^3+(x-1)^4+...+(-1)^k(x-1)^k = \frac{1}{x}$$ I am not really sure how to go about doing this though... Is my step valid? I would appreciate is someone could guide me in the right direction.","['derivatives', 'induction', 'taylor-expansion']"
2493055,It is always possible to construct continuous function?,"Given $D \subset X \subset \mathbb R$, I want to create a function $f: X \rightarrow \mathbb R$ such that (1) it's continuous (2) it has fixed value for every element of D (different values) When it is possible? For example, if D is finite, is certainly possible (with a polynomial, for example). It is possible even if $D = \mathbb N$ and, for example, I want that f(n) = n for every $n \in \mathbb N$. Or it is possible for every D if I fixed a single value for every element. It's (obviously) not possible if I choose $D = \mathbb R$ and I set the values such that the function is discontinuous. It's also not possible if I choose $D = \{x_n\}$ with $x_0 = 0, x_1=0.9, x_2=0.99 ... x_n \rightarrow 1$ and I set $f(x_n) = n$, in fact $f(1) = lim_{n \to \infty}f(x_n) = \infty$ (it would be continuous in [0, 1)?) I think it is a well-known question, but I don't know how to search it. Thanks in advance. (edit: and what if I work in a generic topological space, not $\mathbb R$?)","['continuity', 'general-topology', 'analysis']"
2493101,About convex hull and closed sets,"Let S be a closed set. Show with an example that $conv(S)$ is not necessarily
  closed. Also show that if S is compact then $conv(S)$ is always closed. Here $conv(S)$ denotes the hull of S. Proof: (I didn't show an example I did the proof) Recall that $conv(S)$ is the intersection of all the sets X such that $S\subset X$. w.l.o.g we can suppose that all the sets X such that $S\subset X$ are open and also suppose their intersection is finite. Thus $conv(S)$ can't be closed, is open. Is my proof correct?","['linear-programming', 'convex-optimization', 'convex-analysis', 'analysis']"
2493133,Differences in abstract Poisson population samplings,"Given some abstract population, we take samples of sizes $n=15$, $n=25$, and $n=50$, and then do 10000 trials with each sample with Poisson distribution. As a result, we obtain the following plots: I'm trying to understand the following: Why does increasing the sample size also increases the range of the $y$-axis? Why are there fewer (thinner) columns in each histogram when samples increase? A sample of 10000 will plot a rectangle (just one wide column). What does this imply? Would appreciate some clarification.","['means', 'statistics', 'poisson-distribution']"
2493134,What can one say about the ratio $E[\mathrm{Var}[X\mid \mathcal H]]/E[\mathrm{Var}[X\mid \mathcal G]]$ if $ \mathcal G\subseteq \mathcal H$?,"Let $\{\mathcal{F}_n \}_{n \in \mathbb{N}}$ denotee a filtration with $\mathcal{F}_n \subset \mathcal{F}$ for all $n\in \mathbb{N}$, on the probability space  $(\Omega,\mathcal{F},P)$. If $X$ is a square integrable random variable, what can one say, for $m<n$, about the ratio
  $$\frac{\mathrm{E}[\mathrm{Var}[X\mid \mathcal{F}_n]]} {\mathrm{E}[\mathrm{Var}[X\mid \mathcal{F}_m]]}\ ?$$ My try: Consider $Y_n=\mathrm{Var}(X \mid \mathcal{F}_{n})$ for every $n \in\mathbb N$, then $$\mathrm{E}[Y_{n+1}\mid\mathcal{F}_{n}]=\mathrm{E}[\mathrm{Var}(X \mid \mathcal{F}_{n+1})\mid\mathcal{F}_{n}]=\mathrm{E}[\mathrm{E}[(X-\mathrm{E}[X\mid\mathcal{F}_{n+1})^2\mid\mathcal{F}_{n+1}]\mid\mathcal{F}_n]$$ $$=\mathrm{E}[(X-\mathrm{E}[X\mid\mathcal{F}_{n+1}])^2\mid\mathcal{F}_n]=
\mathrm{E}[X^2-2X\mathrm{E}[X\mid \mathcal{F}_{n+1}]+\mathrm{E}[X\mid\mathcal{F}_{n+1}]^2\mid\mathcal{F}_n]= $$
$$\mathrm{E}[X^2\mid\mathcal{F}_n]-\mathrm{E}[2X\mathrm{E}[X\mid \mathcal{F}_{n+1}]\mid\mathcal{F}_n]+\mathrm{E}[\mathrm{E}[X\mid\mathcal{F}_{n+1}]^2\mid\mathcal{F}_n]= X^2-2X^2+\mathrm{E}[\mathrm{E}[X\mid\mathcal{F}_{n+1}]^2\mid\mathcal{F}_n] $$
I don't know how to go on","['probability-theory', 'conditional-expectation', 'martingales']"
2493141,Solving for the last two digits of a large number $3^{1000}$?,"I found this question asking to find the last two digits of $3^{1000}$ in my professors old notes and review guides. What material must I know to solve problems like this with remainders.I know Wilson's Theorem and there is mention on this packet of Euler's Theorem. Would I look into that to be able to solve problems like this? Why can we solve problems like this. In summary, I decided to look a little bit ahead and in the meantime cool tips and pointers would be great for this area of 'future material type' that will be covered.","['number-theory', 'elementary-number-theory']"
2493149,A question about complex integration formula using Green's theorem,"Use the Green's theorem (complex form) to show that $$\frac{1}{2\pi i}\int_\gamma \frac{dz}{z-p}=\begin{cases}
0 & \text{if $p$ is outside $\gamma$} \\ 
 1& \text{if $p$ is inside $\gamma$}\\
\end{cases}$$ I proved this one by taking $z-p=re^{i\theta}$, but how could I prove it using Green's theorem?","['complex-analysis', 'complex-integration']"
2493197,identity operator isn't bounded,"Suppose we consider the identity operator between the spaces $(C([0,1]),\| . \|_{\infty}) \rightarrow (C([0,1]),\| . \|_{1})$. Then the identity operator is bounded but its inverse isn't bounded. I am a little bit confused about this. So suppose we call the identity operator as $T : (C([0,1]),\| . \|_{\infty}) \rightarrow (C([0,1]),\| . \|_{1})$. If we calculate the norm in for this operator we find that $$\|T\| = \sup_{||f||_{\infty} = 1} \int_{t = 0}^{t = 1} |f(t)| dt$$ I am not sure how can we argue that this is bounded. Also, I have troubles for the reverse side as well. That $T^{-1}$ isn't bounded. Can someone explain this?",['functional-analysis']
2493307,A variant of the dominated convergence theorem in probability theory,"The problem is from Durrett's book. Let $X_n\to X$ a.s. and let $g:\mathbb R\to (0,\infty)$ be a continuous function so that $|x|/g(x)\to 0$ as $|x|\to \infty$. We also assume $Eg(X_n)\leq C<\infty$. Show that $EX_n\to EX$. My attempt is to use Egorov's theorem. The set (denoted by $A$) on which the convergence is uniform is easy to handle. To handle the other part, I would like to estimate it as follows:
$$
\int_{A^c}|X_n-X|dP\leq \int_{A^c}\frac {|X_n-X|}{g(X_n-X)}g(X_n-X)dP.
$$
If $|X_n-X|$ is small, then it is easy to do. If $|X_n-X|$ is large, we use the assumption that $|x|/g(x)\to 0$. This gives us the only difficulty, which is to show that $Eg(X_n-X)<\infty$. But how to do that? Edited: It would be done if we assume in addition that $g(x)$ is increasing as $x\to \infty$, which is usually the case in applications. However, the continuity of $g$ is not used in this case.","['real-analysis', 'probability-theory']"
2493385,Evaluate $\lim_{n\rightarrow \infty}4\sqrt{n}\sin (\pi\sqrt{4n^2+\sqrt{n}})$,Evaluate the limit $$\lim_{n\rightarrow \infty}4\sqrt{n}\sin (\pi\sqrt{4n^2+\sqrt{n}})$$ We know that : $$\sin (\pi-x)=\sin x$$ So we have : $$\lim_{n\rightarrow \infty}4\sqrt{n}\sin (\pi-\pi\sqrt{4n^2+\sqrt{n}})$$ Now : $$(\pi-\pi\sqrt{4n^2+\sqrt{n}})\cdot \frac{\pi+\pi\sqrt{4n^2+\sqrt{n}}}{\pi+\pi\sqrt{4n^2+\sqrt{n}}}=\frac{\pi^2-\pi^2(4n^2+\sqrt{n})}{\pi+\pi\sqrt{4n^2+\sqrt{n}}}$$ $$\lim_{n\rightarrow \infty}4\sqrt{n}\sin \left(\frac{\pi^2-\pi^2(4n^2+\sqrt{n})}{\pi+\pi\sqrt{4n^2+\sqrt{n}}}\right)$$ Now what ?,"['limits-without-lhopital', 'sequences-and-series', 'calculus', 'limits']"
2493388,Translations along vector field orbits,"Let $X$ be a smooth projective variety over $\mathbb{C}$ and let $v \in H^0(X, T_X)$ be a vector field on $X$. Can this vector field be extended to an action of the group $\mathbb{G}_a(\mathbb{C}) \cong \mathbb{A}^1_\mathbb{C}$
$$
\rho: \mathbb{G}_a(\mathbb{C}) \times X \to X,
$$
representing ""translations along vector field orbits""? In analytic category this would be $\rho(t,x)=e^{tv}x,$ where $x \in X$, is there an algebraic analog?",['algebraic-geometry']
2493443,"What is the intuition behind why the integration of $f(x) = x$ for closed interval of negative to positive infinity diverges, rather than being zero?","I'm currently studying integrals in calculus. In teaching improper integrals over infinite intervals, I come across this example in my lecture notes, $$\int_{-\infty}^{\infty} x \ dx$$ Naturally, the integration is split into two halves, such as $\int_{-\infty}^{0}x\ dx=-\infty$ and $\int_{0}^{\infty}x\ dx=\infty$. The lecture notes conclude that since both these improper integrals diverge, then so does the above improper integral, i.e. $$\Rightarrow\int_{-\infty}^{\infty}x\ dx\ \mathrm{diverges}$$ Intuitively, however, I would expect that the first improper integral, $\int_{-\infty}^{\infty}x\ dx$ should evaluate to $0$, given that, An intuitive meaning of the definite integral is the area under the curve The curve of $y=x$ gives a negative area for $(-\infty,0)$ and positive area for $(0, \infty)$ The curve of $y=x$ is symmetrical about $y=0$ So, my questions are Why is this not the case, and Is $\int_{-\infty}^{\infty}x\ dx\ \mathrm{diverges}$ even what I think it means, that $\int_{-\infty}^{\infty}x\ dx=\infty$?","['limits', 'calculus', 'improper-integrals', 'integration', 'infinity']"
2493445,Error in calculation of $\pi$ using Monte Carlo method.,"So lets say we are trying to calculate value of $\pi$ using MonteCarlo method. By picking random points in a square and measuring their distance from the center and if $k$ points lie inside the circle using the ratio $\frac{k}N$ to calculate the value of $\pi$. How do I derive the formula for variance of the calculated value of $\pi$? This is what I have got so far. Say the probability that the point lies inside the circle is $p$. Say we have N random points in the square, of which k lie inside the circle. The probability that k points lie inside the circle is $\binom{N}{k}p^k(1-p)^{N-k}$. The error in estimate of $\pi$ is $e=||c\pi-\frac{N}k||$. So the expected value of error $E(e) = \sum_{k=0}^{k=N}\left\|c\pi-\frac{N}k\right\|\binom{N}{k}p^k(1-p)^{N-k}$? Is the expectation value of error that I have written correct, how do I evaluate it?","['monte-carlo', 'statistics', 'simulation', 'probability']"
2493520,Kalman decomposition using Hautus test,"In linear control theory, the Kalman decomposition is used as a similarity transformation to decompose a given linear time-invariant system $$\dot{x}(t)=Ax(t)+Bu(t)$$
$$y(t) = Cx(t) + Du(t)$$ into its controllable & observable, controllable & not observable, not controllable & observable and not controllable & not observable subsystems. A system is controllable if $\mathcal{C}=[B\quad AB \quad A^2B \ldots A^{n-1}B]^T$ has rank $n$ (number of rows/columns of the system matrix $A$). A system is observable if $\mathcal{O}=[C \quad CA \quad CA^2 \ldots CA^{n-1}]^T$ has rank $n$ (number of rows/columns of the system matrix $A$). It seems possible to construct the similarity transformation by using the eigenvectors of the Hautus test for controllability and observability. It states a system is controllable if for all eigenvalues $\lambda$ of $A$ the matrix $[A-\lambda I\quad B]$ has full rank $n$ for a $n \times n$ system matrix $A$. A similar statement reads: A system is observable if for all eigenvalues $\lambda$ of $A$ the matrix $[A^T - \lambda I \quad C^T]$ has full rank $n$ for a $n \times n$ system matrix $A$. The user fibonatic from Engineering Stack Exchange suggested that one could construct the similarity transformation for the Hautus test. I am wondering, how this is possible. This is the same example as in the post on Engineering Stack Exchange. $$\dot{x} = \begin{bmatrix}1 & 1 & 0 \\ 0 & 1 & 0 \\ 0 & 1 & 1 \end{bmatrix}x + \begin{bmatrix}0 & 1 \\ 1 & 0 \\ 0 & 1 \end{bmatrix} u$$
$$y = \begin{bmatrix}1 & 1 & 1 \end{bmatrix} x$$ The similarity transfromation is given by 
$$
M = 
\begin{bmatrix}
0 & 1 & 1 \\
1 & 0 & 0 \\
0 & 1 & -1
\end{bmatrix}.
$$
This is what I have tried. The three eigenvalues of $A$ are all $\lambda =1$ the eigenvectors are $v_1 = [1, 0,0]^T, v_2=[0,0,1]^T$ and $v_3=[1,0,1]^T$. The rank of the $[A-\lambda B]$ is 2. That means there is a deficit in rank for every eigenvector. If I include the eigenvectors to a ""similarity"" transformation $$\tilde{M} =
\begin{bmatrix}
1 & 0 & 1\\
0 & 0 & 0\\
0 & 1 & 1\\ 
\end{bmatrix}
$$ it turns out that it is singular and cannot be the similarity transformation that I need. So how can I use the Hautus test to construct the similarity
  transformation for the Kalman decomposition?","['control-theory', 'ordinary-differential-equations', 'dynamical-systems', 'linear-control']"
2493524,Ratio of Trigonometric Functions,"tanx/tany = 1/3;  sin2x/sin2y = 3/4 where 0 < x,y< pi/2. What is the Value of 
tan2x/tan2y I couldn't find the appropriate trig identities to use for this problem, and what relationship for sin and tan that we can exploit.",['trigonometry']
2493537,Smooth transition between linear functions,"I have two functions that are approximately linear. To keep thing simple, I will deal with linear functions in the following. Lets take $f(x)=x+15$ and $g(x)=3x+2$. I would like to stitch these functions together at the point $x=6$. For that I currently use a $\tanh$-function: $s(x) = 0.5+0.5\tanh((x-6)/w)$, where $w$ a width. So I ultimately get the function $h(x)=s(x)f(x) + (1-s(x))g(x)$ that looks like this This works as intended, however, at the transition point $x_0=6$ $h(x)$ has a small ""hump"", so $h(x)$ is pushed upwards relative to $f(x)$ at the transition point. This is undesirable for me. Is there a different transition function I can use that doesn't have this ""hump""? Maybe some exponential function?","['elementary-functions', 'exponential-function', 'functions']"
2493682,Least area of a triangle.,"A straight line $L$ with negative slope passes through the point $(8,2)$ and cuts the positive axes at points $P$ and $Q$, then find minimum area of $\triangle{OPQ}$ ($O$ is origin). Book hint: They wrote area is minimum when $(8,2)$ is the mid point of $PQ$. I don't understand this, please help.","['analytic-geometry', 'geometry']"
2493715,Topology induced by a convergence notion,"I've encountered the sentences ""topologized by convergence in probability"" or ""topologized by uniform convergences"" and I would like to get an idea of the big picture. Given notion of convergence on some set $X$ for which no topology has yet been specified (hence one cannot define convergence in the usual way), how it's possible to define a topology on $X$? In this answer is said that it's possible to axiomatize the notion of convergence even without nets (and I'd be happy to not involve nets). Suppose one has a similar notion, it's enough to declare the closed sets as the sequentially closed to get a topology?","['general-topology', 'convergence-divergence', 'definition']"
2493718,What is the limiting distribution of $Z_n = \frac{X_1 X_2 + X_3 X_4 + \cdots + X_{2n-1} X_{2n}}{\sqrt{n}}$,"Hope this isn't a duplicate. Let $ X_1,X_2, \ldots$  be iid RVs with mean $0$, variance $1$ and $E{X_i}^4 < \infty , \forall i \in \Bbb N$. So I was trying to find the limiting distribution of $$Z_n = \frac{X_1 X_2 + X_3 X_4 + \cdots + X_{2n-1} X_{2n}}{\sqrt{n}}.$$ I have recently learned Weak Law Of Large Numbers, Strong Law Of Large Numbers and Central Limit Theorem but currently have no idea how to approach the problem. Thanks in advance for help.","['probability-theory', 'convergence-divergence', 'random-variables']"
2493754,"Given that $\operatorname{E}[Y\mid X] = 1$, show that $\operatorname{Var}(XY)\geqslant\operatorname{Var}(X)$","Given that $E[Y\mid X] = 1$, show that $\operatorname{Var}(XY)\geqslant\operatorname{Var}(X)$. So I tried to expand $\operatorname{Var}(XY) = \operatorname{E}(X^2 Y^2) - 1$ and was stuck here.","['probability-theory', 'conditional-expectation', 'variance']"
2493771,L'Hospital's rule for $\lim_{n\rightarrow \infty} (a^n + b^n)^\frac{1}{n}$.,"I have recently come across a problem concerning the limit of a sequence given as, $$\lim_{n\rightarrow \infty} (a^n + b^n)^\frac{1}{n}$$ Where $0<a<b$. Solving the limit is not a concern. But applying L'Hospital's rule to this limit is one to me. On rearranging we get, $b \lim_{n\rightarrow \infty} ((\frac{a}{b}) ^n + 1)^\frac{1}{n}$. The solver had then applied the L'Hospital's rule to evaluate the limit. Here, as $n\rightarrow \infty$, the limit approaches the form $1^0$. I have tried to think about this limit approaching an indeterminate form. It does not. From my knowledge of Cauchy's Mean Value theorem, I say that we cannot apply the rule to determinate forms. But it seems to me that we can because it worked for the solver. I think I am not clear on this. Can somebody help?","['sequences-and-series', 'calculus']"
2493834,"If $a,b$ are positive real numbers, such that $a+b=1$, then prove that $(a+ \dfrac {1}{a})^3 +(b+ \dfrac {1}{b})^3 \ge \dfrac {125}{4}$","If $a,b$ are positive real numbers, such that $a+b=1$, then prove that $$\bigg(a+ \dfrac {1}{a}\bigg)^3 +\bigg(b+ \dfrac {1}{b}\bigg)^3 \ge \dfrac {125}{4}$$ I just learnt to prove If $a$ and $b$ are positive real numbers such that $a+b=1$, then prove that $\big(a+\frac{1}{a}\big)^2 +\big(b+\frac{1}{b}\big)^2 \ge\frac{25}{2}$ a few days ago, and it was  just basic application of CS. But I find this one really difficult. I can not apply CS here directly on the numbers $a+\frac{1}{a}$ and $b+\frac{1}{b}$ because CS is for squares. So some manipulation is needed. Anything from hint to full answer will be appreciated.","['inequality', 'a.m.-g.m.-inequality', 'cauchy-schwarz-inequality', 'algebra-precalculus', 'holder-inequality']"
2493851,Sanity check: does $D_{\omega_9}(9)$ exceed TREE(3)?,"TREE(3) For the Golf a number bigger than TREE(3) challenge I wrote a program but I'm not sure it is bigger than TREE(3). The function TREE(k) gives the length of the longest sequence of trees T1, T2, ... where each vertex is labelled with one of k colours, the tree Ti has at most i vertices, and no tree is a minor of any tree following it in the sequence. TREE(1) = 1, with e.g. T1 = (1). TREE(2) = 3: e.g. T1 = (1); T2 = (2)--(2); T3 = (2). Because of my limited knowledge of TREE(k) and ordinals I decided to post a question here first before submitting my answer. You can view the code and a limited explanation here but I will define and  explain the D function here. Notation My program is highly recursive, it produces functions to put inside other functions. $\omega_0=0$,  $\omega_1=\omega$,  $\omega_1=\Omega$,... $\alpha_n$ means $cf(\alpha)=\omega_n$
so $\alpha_0$ means $\alpha$ is a natural number I will represent ordinals as functions (in lambda calculus) which their fundamental sequence (e.g. $\omega_1\cdot 2=\lambda x_0. \omega_1+x_0$) and call these functions using square brackets e.g. $(\omega_1\cdot 2)[5]=\omega+5$ Definition $\omega_n=\lambda \alpha_k. \alpha_k$ with $k<n$ $\alpha_n+1=\lambda \beta_n. \alpha_n$ $D_\alpha(\beta)=H'_\alpha(H'_\alpha(\beta))=H'^{2}_\alpha(\beta)$ $H'_0(\alpha_n)=\alpha_n+1$ $H'_{\alpha_{n+1}}(\beta_k)=D_{H'_{\alpha_{n+1}}(\omega_n)}(\beta_k)$ if $k<n$ $H'_{\alpha_{n+1}}(\beta_n)=D_{\alpha_{n+1}[\beta_n]}(\beta_n)$ $H'_{\alpha_0+1}(\beta_n)=D_{\alpha_0}(\beta_n)$ $H'_{\alpha_{k+1}}(\beta_n)=\lambda \gamma_k. D_{\alpha_{k+1}[\gamma_k]}(\beta_n)$ if $0\le k<n$ My number is $D_{\omega_9}(9)$ but I can easily change it to $D_{\omega_{10^9}}(9)$ if required. In words $\omega_n$ is the identity function for ordinals of smaller cofanity. The successor of $\alpha$ is the function that returns $\alpha$ for all input (this is to avoid having to handle successor and limit ordinals separately ) $D$ is the doubling function it iterates $H'$ once. This is a balance between the hardy hierarchy , which doesn't iterate at all, and the fast-growing hierarchy , which iterates n times. $H'_0$ is the successor function, both for functions and numbers $H'_\alpha(\beta)$ : if the domain of $\alpha$ is so large a size smaller could still fit $\beta$, use $H'$ on $\alpha$ until the domain is just large enough. (this is a way to avoid having multiple calls to H' in my code e.g. $\alpha_1=H'_{\omega_2}(\omega_1)$ and $H'_{\alpha_1}(9)$ if the domain of $\alpha$ is just large enough use $\alpha[\beta]$ if the domain of $\alpha$ is too small : if $\alpha$ is an integer use it's predecessor. else define the result to be the function that uses $\alpha[\gamma]$ as
the new subscript when $\gamma$ is put in. The result has the same
domain as $\alpha$ note : $H'_{\alpha_n}(\beta_m) \in T_m \text{ if } m\le n \text{ or } n=0$ $H'_{\alpha_n}(\beta_m) \in T_n \text{ if } n<m$ The ordinal interpretation You don't have to read this is you don't want. The question is if $D_{\omega_9}(9)>TREE(3)$. But I want to give some more explanation for why I believe my number is bigger than TREE(3). The functions in program have strong similarities with ordinals
This is the definition for the set of tree-ordinals with order type $n$:
$$\alpha\in T_n \Leftrightarrow
 \begin{cases}
\alpha=0\\
\alpha=\beta+1 \text{ and } \beta\in T_n\\
\alpha:T_k\mapsto T_n \text{ with } k<n\\
\end{cases}$$ Note $T_k \subset T_n \text{ if } k<n$ but except for this it perfectly aligns with the explanation I gave earlier. $T_0$ is still the set of natural numbers, since the 3rd rule, which generates all the limit ordinals, can't be used yet. My definition of $\omega_n$ is different than usual, usually $\omega_1$ is the first uncountable ordinal ($\Omega$) but for me that's $\omega_2$ I did this to keep $\alpha_n \in T_n$ Notation interpreted as ordinals $\alpha_{k}$ is an ordinal with  order type k ( $k=\min(n:\alpha\in T_n)$ ) $\alpha_n[\beta_k]$ is the $\beta$th element of $\alpha$'s fundamental sequence. This is defined when $k<n$. The ordinal idea behind my number I believe $\omega_9$ acts as on ordinal about the size of $\tau[9]$ in $H'$. Since $H'_{\omega*\alpha}(n)>f_\alpha(n)$, My number $D_{\omega_9}(9)=H'^{2}_{\omega_9}(9)\approx H'^{2}_{\tau[9]}(9)>f_{\tau[9]}(9)>f_{ϑ(Ω^ω ω)+1}(9)>TREE(9)$ $H'$ is a modified version of the Hardy Hierarchy . The idea behind $H'$ is that $H'_{\alpha+1}$ = $H'^{2}_{\alpha}$ $\Rightarrow$ $H'_{\alpha_n+\omega_n} \text{ iterates } H'_{\alpha_n}$ $\Rightarrow$ $H'_{\omega*\alpha}(n)>f_\alpha(n)$. You can find a proof here . Than the idea of an ordinal hierarchy was expended from a using a countable ordinal to generate huge integers, to use huge $\alpha_{n+1}$ to generate huge $\beta_n$. The 5th definition was than added to iterate $H'$ on the ordinal slot. If I did this correctly this should mean that $H'_{\omega_{n+k}}(n)>f_\tau(n)$ for some reasonably small k. Examples These early expansions created a lot of insight into my function for me, so I'll post them here too. Some very early expansions The 5th definition makes $D_{\omega_9}(9)$ expand to $H'_{\omega_9}(H'_{\alpha_8}(H'_{\alpha_7}(H'_{\alpha_6}(H'_{\alpha_5}(H'_{\alpha_4}(H'_{\alpha_3}(H'_{\alpha_2}(D_{\alpha_1}(9)))))))))$ $= H'_{\omega_9}(H'_{\alpha_8}(H'_{\alpha_7}(H'_{\alpha_6}(H'_{\alpha_5}(H'_{\alpha_4}(H'_{\alpha_3}(H'_{\alpha_2}(H_{\alpha_1}(D_{\alpha_1[9]}(9))))))))))$ $$\alpha_8=H'_{\omega_9}(\omega_8)=D_{\omega_8}(\omega_8)=H'_{\omega_8}(H'_{\omega_8}(\omega_8))$$
\begin{align}
\ \alpha_7 & = H'_{\alpha_8}(\omega_7) \\
& = D_{\alpha_8[\omega_7]}(\omega_7) \\
& = D_{H'_{\omega_8}(H'_{\omega_8}(\omega_8))[\omega_7]}(\omega_7) \\
& = D_{D_{\omega_8[\omega_7]}(H'_{\omega_8}(\omega_8))}(\omega_7) \\
& = D_{D_{\omega_7}(H'_{\omega_8}(\omega_8))}(\omega_7) \\
& = H'_{H'_{\omega_7}(H'_{\omega_7}(H'_{\omega_8}(\omega_8)))}(H'_{H'_{\omega_7}(H'_{\omega_7}(H'_{\omega_8}(\omega_8)))}(\omega_7))\\
\end{align} \begin{align}
\ \alpha_6 & =H'_{\alpha_7}(\omega_6) \\
\ & = D_{\alpha_7[\omega_6]}(\omega_6) \\
\ & = D_{H'_{H'_{\omega_7}(H'_{\omega_7}(H'_{\omega_8}(\omega_8)))}(H'_{H'_{\omega_7}(H'_{\omega_7}(H'_{\omega_8}(\omega_8)))}(\omega_7))[\omega_6]}(\omega_6) \\
\ & = \ ...
\end{align} $$\alpha_5=H'_{\alpha_6}(\omega_5)$$
$$\alpha_4=H'_{\alpha_5}(\omega_4)$$
$$\alpha_3=H'_{\alpha_4}(\omega_3)$$
$$\alpha_2=H'_{\alpha_3}(\omega_2)$$
$$\alpha_1=H'_{\alpha_2}(\omega_1)$$ If you want too truly experience the madness I recommend trying to work out $\alpha_1[3]$ but I didn't get very far. Some very approximate expansions \begin{align}
D_{\omega_9}(9) & = H'^{2}_{\omega_9}(9)  \\
 & > H'_{\omega_9}(9) \\ 
 & = D_{H'_{\omega_9}(\omega_8)}(9) \\
 & > D_{\omega_{8}*2}(9) \\ 
 & > H'_{\omega_{8}*2}(9) \\
 & > H'_{\omega_{7}^2}(9)\\
 & > H'_{2 ↑^{\omega_{6}} \omega_{6}}(9)\\
 & >  ...
\end{align} Conclusion I couldn't get past $\omega_6$ and I ignored all the iteration of D so once $H'_{\alpha_1}(9)$ is finally reached the computer will have to work back up trough all of those extra iterations too. But that wouldn't even be necessary because $f_{ϑ(Ω^ω ω)}(9)>TREE(3)$ so if $\alpha_1>ϑ(Ω^ω ω)$ my number should be big enough. So is $\alpha_1>ϑ(Ω^ω ω)$? I think it should be, but it's quite possible I made a mistake somewhere. Did I?","['big-numbers', 'proof-verification', 'number-theory', 'recursion', 'ordinals']"
2493858,Largest rectangle that can fit isnide of equilateral triangle,"I have an equilateral triangle with a fixed side-length $x$. 
What is the largest area of a rectangle that can be put inside the triangle?","['rectangles', 'programming', 'geometry']"
2493889,The fractal dimension of the Kolakoski sequence is $2-1/e$,"The Kolakoski sequence, which is defined as the infinite sequence of symbols {1,2} that is its own run-length encoding (Wikipedia), has been suggested to be self-similar$^{1}$. The fractral dimension of a self-similar time-series is directly related to its Hurst exponent$^{2}$. I have estimated the Hurst exponent of the Kolakoski sequence for different sequence lengths, and found that the answer converges near $1 / e$ when the sequence length increases. This suggests that the fractral dimension of the Kolakoski sequence is $D=2-H = 2-1/e.$ Here is a small subset of the data sequence length    hurst exponent
1e2                .1167
1e3                .1796
1e4                .2236
1e5                .2579
1e6                .3108
1e7                .3464
1e8                .3657
2e8                .3720
3e8                .3766 My question is: Can you find a proof for this conjecture? If yes, I would be interested to write a brief note about this to a mathematical journal. References: $^{1}$ https://maths-people.anu.edu.au/~brent/pd/Kolakoski-ACCMCC.pdf $^{2}$ https://en.wikipedia.org/wiki/Hurst_exponent#Relation_to_Fractal_Dimension","['conjectures', 'exponential-function', 'sequences-and-series', 'fractals']"
2493898,Are GNS representations the way to build physical Hilbert spaces?,"Consider a separable $C^*$ algebra $\mathcal A$. The space of states is also separable in the weak* topology, let $S$ be a countable dense subset. Denoting with $H_\omega$ the GNS representation of a state $\omega$ we retrieve a representation of $\mathcal A$ on the Hilbert space $H(S)=\bigoplus_{\omega\in S}H_\omega$. This representation is isometric and $H$ is separable. In the context of quantum mechanics we have built a candidate for the physical Hilbert space just by knowing an algebra of observables. This construction however depends on how we chose our set $S$. My question is: Are the representations of $\mathcal A$ on $H(S)$ and $H(S')$ unitarily equivalent for any two dense countable subsets $S,S'$ of the state space of $\mathcal A$?","['quantum-mechanics', 'c-star-algebras', 'mathematical-physics', 'functional-analysis', 'quantum-field-theory']"
2493910,Determinant of circulant-like matrix,"Given is an $n \times n$ matrix $M_n$ with the following structure — $$M_n = \left(
\begin{array}{ccccc}
a_1 & 0 & \dots & 0 & b_1 \\
b_2 & a_2 &  &  & 0\\
 & \ddots & \ddots &  & \vdots \\
 &  & b_{n-1} & a_{n-1} & 0\\
 &  &  & b_n & a_n\end{array}
\right),$$ with $a_i$ and $b_i \in \mathbb{R}$ where $i \in \{1,\dots,n\}$ . Is there a name for this specific type of matrix? The non-zero entries in each row are shifted one position to the right compared to the previous row, which reminds me of a circulant matrix (though in that case, the rows share the same values, which is generally not the case for $M_n$ ). Is there a short/fast way (i.e. not just using Leibniz's formula ) to compute the determinant of this type of matrix? It might help to consider an example, so here's $M_5$ : $$M_5 = \left(
\begin{array}{ccccc}
a_1 & 0 & 0 & 0 & b_1 \\
b_2 & a_2 & 0 & 0 & 0\\
0 & b_3 & a_3 & 0 & 0\\
0 & 0 & b_4 & a_4 & 0\\
0 & 0 & 0 & b_5 & a_5\end{array}
\right) = \left(
\begin{array}{ccccc}
a_1 &  &  &  & b_1 \\
b_2 & a_2 &  &  & \\
 & b_3 & a_3 &  & \\
 &  & b_4 & a_4 & \\
 &  &  & b_5 & a_5\end{array}
\right)$$","['matrices', 'determinant']"
2493917,Two players alternately flip biased coin. What is bias of coin?,"Two players, A and B, alternately and independently flip a biased coin and the first player to get a head wins. Assume player A flips first. Player A wins the game 12/23 times. If the coin is biased, what is the bias of the coin? I am using the format from here Two players alternately flip a coin; what is the probability of winning by getting a head? except my equation looks
12/23 = p + (1-p)(11/23) 
and solving for p. 
I am getting p = 1/12. I am not understanding the answer or if it is correct. If player A is more likely to win and has first flip, why is the chance of getting heads 1/12??","['combinatorics', 'statistics', 'probability']"
2493951,"Order preserving,reflecting map between lattices is join-homomorphism?","Let $L_1, L_2$ be lattices and $f: L_1\to L_2$ a bijective (suffices to demand surjectivity) mapping such that
$$\forall a,b\in L_1,\quad a\leq b\iff f(a)\leq f(b) $$ Show that $f$ is an isomorphism of lattices. It remains to verify whether $f$ is a homomorphism and for that it suffices to check whether $f$ is a $\vee$-homomorphism ($\wedge$-hom is established dually) that is
$$\forall a,b\in L_1,\quad f(a\vee b) \overset{?}= f(a)\vee f(b) $$
Since $a \leq a\vee b$ and $b\leq a\vee b$, then 
$$f(a)\leq f(a\vee b)\quad\mbox{and}\quad f(b)\leq f(a\vee b) $$
By definition of least upper bound we have
$$f(a)\vee f(b)\leq f(a\vee b) $$
But how does one establish the converse inequality i.e
$$f(a\vee b)\overset{?}\leq f(a)\vee f(b) $$
Lecture notes say this is obvious :( We could assume $f(a\vee b) > f(a)\vee f(b)\geq f(a)$, for instance. Then order reflection gives $a\vee b\geq a$, but so what? Or is it $a\vee b > a$, then $a\vee b > b$, but still, so what? I don't understand how this claim is obvious.","['abstract-algebra', 'lattice-orders', 'order-theory', 'discrete-mathematics']"
2493970,"Find local maximum, minimum and saddle points of $f(x,y) = x^4 + y^4 - 4xy + 2$","Find maximum, minimum and saddle points of $f(x,y) = x^4 + y^4 - 4xy + 2$. For critical points, $f_{x} = f_{y} = 0$, $f_{x} = 3x³ - 4y$ and $f_{y} = 3y³ - 4x$. Therefore $f_{xx} = 9x²$, $f_{yy} = 9y²$, and $f_{xy} = f_{yx} = -4$. Hessian matrix determinant is positive for P($\frac{2}{\sqrt3},\frac{2}{\sqrt3},-14)$ and Q($\frac{-2}{\sqrt3}$,$\frac{-2}{\sqrt3}$,-14), so they are minimum points. And R(0,0,2) is a saddle point. Is this correct?","['hessian-matrix', 'a.m.-g.m.-inequality', 'partial-derivative', 'multivariable-calculus', 'maxima-minima']"
2493992,Tangent space to fixed point manifold and fixed point set of tangent space,"Assume a finite group $G$ acts smoothly on a smooth manifold $M$. Let $p\in M^G$. Then there is the action of $G$ on $T_pM$ given by differentials of diffeomorphisms being the actions of group elements. Is it true that
$$
T_p(M^G)=(T_pM)^G?
$$","['group-actions', 'differential-geometry', 'differential-topology']"
2494065,Confusion about centraliser of $D_5$ in $GL_4(\mathbb{Z})$,"I am trying to follow a derivation on a very old paper. My knowledge of group theory is limited, I have the basis but not much experience with advanced concepts. We are working in 4 dimensions, so the paper quotes the 4D representations of the generators of $D_5$, $r$ (a rotation by $\pi/5$) and $p$ (the reflection $x \rightarrow x, y \rightarrow y$) as:
$$
\mathcal{R}(r) = \left (\begin{array}{ccc}
0 & 0 & 0 & -1  \\
1 & 0 & 0 & -1  \\
0 & 1 & 0 & -1  \\
0 & 0 & 1 & -1  \\
\end{array} \right ), 
$$ $$
\mathcal{R}(p) = \left (\begin{array}{ccc}
0 & 0 & 0 & 1  \\
0 & 0 & 1 & 0  \\
0 & 1 & 0 & 0  \\
1 & 0 & 0 & 0  \\
\end{array} \right ).
$$ Question 1 : I thought all dihedral groups had irreducible representations of at most 2 dimensions, hence all >2 dimensional representations should be constructed from direct sums of these (so block diagonals)? Where do they get these expressions from? Then we calculate the centraliser of $D_5$ in $GL_4(\mathbb{Z})$, i.e. the largest subgroup of $GL_4(\mathbb{Z})$ which commutes with $D_5$. Unfortunately they skip directly to the answer because apparently ""computing these groups in straightforward"". The generators of the centraliser $C$ are given by: $$
\mathcal{R}(\delta) = \left (\begin{array}{ccc}
-1 & 1 & 0 & -1  \\
0 & 0 & 1 & -1  \\
-1 & 1 & 0 & 0  \\
-1 & 0 & 1 & -1  \\
\end{array} \right ), 
$$ $$
\mathcal{R}(\tau) = \left (\begin{array}{ccc}
-1 & 0 & 0 & 0  \\
0 & -1 & 0 & 0  \\
0 & 0 & -1 & 0  \\
0 & 0 & 0 & -1  \\
\end{array} \right ).
$$ Question 2 : where do these come from? Is it there something very trivial that I'm not getting? Where would I even start? My attempts : 1)I started this by building a 4D representation of $D_5$ just by direct summing its 2D irreps. I am using $r_{2D}$ as the 2D rotation matrix and $p_{2D} = \left (\begin{array}{cc}
1 & 0   \\
0 & -1   \\
\end{array} \right ), 
$, to then make $
\mathcal{R}(r_{4D}) = \left (\begin{array}{cc}
r_{2D} & 0  \\
0 & r_{2D}  \\
\end{array} \right ), 
$
$
\mathcal{R}(p_{4D}) = \left (\begin{array}{ccc}
1 & 0 & 0 & 0  \\
0 & -1 & 0 & 0  \\
0 & 0 & 1 & 0  \\
0 & 0 & 0 & -1  \\
\end{array} \right ),
$
etc. 2) I used the generic element of $GL_4(\mathbb{Z})$ as $
\beta = \left (\begin{array}{ccc}
a & b & c & d  \\
e & f & g & h  \\
i & l & m & n  \\
q & s & t & u  \\
\end{array} \right ). 
$ Then I brute-forced computed the relationships between the entries by requiring $h$ to commute with every element $d$ of $D_5$: $h^{-1}dh = d$. I found that the matrix above is reduced to $\beta = \left (\begin{array}{ccc}
a & 0 & c & 0  \\
0 & a & 0 & c  \\
s & 0 & u & 0  \\
0 & s & 0 & u  \\
\end{array} \right ). $ However this is where I stop, for I don't know how to compute the generator of the group of these matrices.","['finite-groups', 'dihedral-groups', 'group-theory']"
2494117,Let $f: \mathbb{N} \rightarrow \mathbb{N}$ a function such that $f(mn) = f(m) + f(n)$ whenever $m$ and $n$ are relatively prime.,"This question is from a Brazilian math competition: ""Olimpíada Cearense de Matemática (OCM)"". Let $f: \mathbb{N} \rightarrow \mathbb{N}$ a function such that $f(mn) = f(m) + f(n)$ whenever $m$ and $n$ are relatively prime. A natural number $m$ is called a bottleneck of $f$ if $n<m \implies f(n) < f(m)$ and $n>m \implies f(n) > f(m)$. If $f$ has infinity bottlenecks, shows that it is a strictly increasing function.","['functional-equations', 'functions', 'elementary-number-theory']"
2494188,How to preserve ignorance in backpropagation learning?,"In machine learning it is important not only to correctly classify things based on observations that have been made, but also to know how unsure one is in an area where not many observations have been made. How can this be achieved? Which methods exist to avoid getting the network to extrapolate into areas we actually don't know much? (I am particularly interested in approaches for neural networks trained by error back propagation). Here is an example of what I want to achieve which I just accidentally accomplished in this case The training data are the cluster points and the colored image is the prediction map. Pure blue, red or green color means close to 100% confidence and in between colors like purple and yellow mean a large uncertainty between the classes of which colors are mixed
:","['machine-learning', 'reference-request', 'probability', 'calculus']"
2494242,Showing an integral/kernel function is measurable.,"We have two measurable spaces $(X,A)$ and $(Y, B)$, and a kernel $K(x,y)$. Also, $f$ is some $B$- measurable function. We wish to show that $x \to \int f(y)K(x,y)$ is $A$-measurable. My thought process: Call the function in question $g(x)$. For our function to be $A$-measurable, we need that for any $b \in B$ $g^{-1}(b) \in A$. Now, we assumed $f$ is $B$-measurable and we know that by definition, for each $x \in X$, $b \to K(x,b)$ is a measure on $(Y,B)$. So the integral is well defined (with $K$ being like a very general version of ""dx"" in a sense, I think...) Though, none of this gives me a clue on how to tie it to $A$-measurability. Any suggestions?","['integration', 'measure-theory']"
2494271,two random variables and conditional expectation,"Consider two random variables $X$ and $Y$. Let $Z_1,Z_2$ be two random variables, measurable with respect to the $\sigma$-field generated by $X,Y$ such that 
$$\mathbb E (X\mid Z_1)=E (X\mid Z_2)$$
$$\mathbb E (Y\mid Z_1)=E (Y\mid Z_2)$$ What can I say about $Z_1$ and $Z_2$? Do they generate the same $\sigma$-algebra? Does there exist a one-to-one function $f$ such that $Z_1=f(Z_2)$?
Thanks!","['probability-theory', 'conditional-expectation']"
2494273,What is an unbiased estimator and utility of fisher information,"I am self learning estimation theory and finding it quite difficult to grasp the utility of Cramer Rao Lower bound. In text books and online tutorials always say that one should derive the CRLB of the estimator. If the variance of the estimator is greater than equal to the inverse of the Fisher information, then we say that no  other better estimator exists. The inverse of the Fisher information is the CRLB.  If the variance is equal to the CRLB, then the estimator is efficient. Intuitively, an estimator is nothing but a formula or an expression that is used to find an unknown value/ parameter. 1) Is there a better intuitive way to explain what CRLB bound tells us and why we need it? 2) What is meant by efficient estimator and efficiency to do what? With what do we compare the efficiency of an estimator. These questions may be trivial but I found very difficult to extract key information from highly mathematical heavy stuff. 3) Do we discard the estimator if inefficient? Please correct me if any information is wrong. Thank you.","['statistics', 'probability', 'parameter-estimation']"
2494296,Write formally: The set of all increasing functions of real numbers - quantifiers,"Write formally: The set of all increasing functions of real numbers I attempted to solve this problem and came up with two solutions, but I am not sure which version is good:
$$\{f(x)|(\forall m,n)(m,n \in \mathbb R \land m>n \land f(m) > f(n)\}$$
or
$$\{f(x)|(\forall m,n)((m,n \in \mathbb R \land m>n) \Rightarrow f(m) > f(n)\}$$
Which one of them works better?","['elementary-set-theory', 'calculus', 'functions']"
2494306,Restricting the codomain of a smooth map of manifolds to a submanifold is not necessarily smooth.,"In John Lee's introduction to smooth manifold book he gives the following example: Example 5.28: Let $S \subset \mathbb{R}^2$ be the figure eight submanifold with the topology and smooth structure induced by the immersion $\beta:(-\pi,pi)$; $\beta(t)=(\sin2t,\sin t)$. Define a smooth map $G: \mathbb{R} \rightarrow \mathbb{R}^2$ by $G(t)=(\sin2t,\sin t)$. The image of $G$ clearly lies in $S$, but as a map from $\mathbb{R}$ to $S$ it is not even continuous because $\beta^{-1} \circ G$ is not continuous at $t=\pi$. I am confused why he is looking at the composition $\beta^{-1}\circ G$ to show that $G$ is not continuous. I think that since $\beta$ is a diffeomorphism, then if $G$ were continuous then this composition would have to be continuous. But I still don't comprehend why we need to look a the composition to show it's discontinuous. Update:
  Okay so I think I've figured it out. This has to do with the topology given to the image of injective smooth immersion. It goes as follows: Let $F: N \rightarrow M$ be an injective smooth immersion. Then as in the proof of Lee's proposition 5.18, $S=F(N)$ is topologized by delcaring $U \subset S$ open iff $F^{-1}(U) \subset N$ is open. In the case at hand our $F$ is the map $\beta$. It's easy to see from how the image of $\beta$ traces out the figure-eight that at $t=\pi$ that the image of the composition $\beta^{-1}\circ G$ jumps from points near $\pi$ back down to zero which is obviously a discontinuity.","['smooth-manifolds', 'differential-geometry']"
2494317,Seating couples around 2 tables,"Here's my question and possible answer. How many possible ways can you arrange 8 married couples between 2 circular tables of 8 identical chairs each such that: 1) each couple must sit at the same table, and, 2) at each table, men and women must sit in adjacent chairs (NOTE: a couple can sit next to each other but doesn't have to). My solution: Number of ways 
= (number of ways to split 8 couples into 2 tables of 4 couples each) * (number of arrangements at each table) $=\frac{8!}{4!4!}*$(4 men and 4 women sitting alternately in 2 ways) $=\frac{8!}{4!4!}\!\cdot\! 4!\!\cdot\!4!\cdot\!2$ $=2 * 8!$ I feel that I'm wrong about this. Can someone verify this solution or provide the correct one?","['combinatorics', 'discrete-mathematics']"
2494408,Tangent lines to a curve passing through a given point,"Here is a cool exercise from Shafarevich's book (Ex. 7 in Chapter 1, Section 1): Given an irreducible (affine) plane curve $C$ over a field of characteristic
  $0$, and point $P$ in the plane, prove that there are only finitely
  many lines through $P$ that are tangent to $C$ at some point. Remark 1. In terms of the dual curve, this implies that, if $\operatorname{char}(k)=0$, then $C^{*}$ has no line as a component (because a line in a dual projective space exactly corresponds to the set of lines passing through a given point $P$). Remark 2. The conclusion is false if the characteristic is positive. Indeed, it is not hard to show that for the plane curve $y=x^{p+1}$ where $p=\operatorname{char}(k)>0$, every line through the origin is tangent to this curve (this example is the earlier part of the same exercise). I am aware that a problem similar to this has been discussed in Number of tangent lines to an algebraic curve passing through a given point However, the solution there uses the language of polar curves and proves something more precise for smooth curves. I think there should be a satisfactory proof that works for irreducible curves, and just shows finiteness of tangent lines through a given point. Attempt. Let's try the special case when $y=f(x)$ is the equation of the plane algebraic curve. After translating variables, we can assume that $P=(0, 0)$ is the origin. Then every line through the origin has the equation $y=mx$. We want to show that there are only finitely many values of $m$ for which the equation $mx=f(x)$ has a repeated root. This is where we need to use characteristic $0$ assumption. Maybe we can analyze the discriminant? Also, this is just a special case and most curves don't have the form $y=f(x)$. Overkill. I am fairly certain that Bertini's theorem can give the solution immediately. Indeed, the lines through a given point $P$ defines a linear system. This induces a linear system of divisors on the curve $C$ (by intersecting the lines with $C$). Since we are in characteristic $0$, Bertini's theorem guarantees that a general member of this linear series will be non-singular, which just means that a general line through $P$ will intersect the curve at distinct points (i.e. transversely). But this exercise appears in page 22 of the book, so there is gotta be a clean elementary solution! Thanks for your time!","['algebraic-curves', 'tangent-line', 'algebraic-geometry']"
2494409,"If $f,g$ are continuous functions, then $fg$ is continuous?","Let $X$ be a topological space and let $f:X \to \mathbb{R}$ , $g:X \to \mathbb{R}$ be continuous functions. Show that $fg$ is continuous. My work:
To show $fg$ is continuous at $x$ for each $x \in X$ , let $y=fg(x)$ . To show if $N_y$ is a neighborhood of $y$ , then the pre-image of $y$ is a neighborhood of $x$ . I know that there exists $B_\epsilon(y) \in N_y$ so I want to show that $（fg）^{-1}(B_\epsilon(y)) \in N(x)$ Let $N_x=（fg）^{-1}(B_\epsilon(y))$ , I want to find an open set in $N_x$ . Can anyone give me a hint of how to choose such open set or idea how to prove this ?","['continuity', 'general-topology', 'metric-spaces']"
2494440,Being a PID is not a local property,"I am proving that the property of all ideals being principal is not a local property. It suffices to find an example. And I have a hint that we can take $\Bbb Z[x]/\langle x^2+5\rangle$ to be such an example. I know that $\Bbb Z[x]/\langle x^2+5\rangle$ is not a PID because it is not a UFD. It can be seen by factorizing $6$. Which left to show is $\Bbb Z[x]/\langle x^2+5\rangle$ is a PID locally, to do this we need an open cover of it. That is, we can find $f_1,...,f_n$, such that every ideal in each $(\Bbb Z[x]/\langle x^2+5\rangle)[1/f_i]$ is principal. But may I please ask some way to find such a cover? Thanks in advance.","['algebraic-geometry', 'principal-ideal-domains']"
2494447,A way to show $\int_0^\infty e^{-t^2}dt=\frac{\sqrt{\pi}}{2}$,"Question Let $f(x)=[\int_0^x e^{-t^2}dt]^2$, and $g(x)=\int_0^1 \frac{e^{-x^2(t^2+1)}}{t^2+1} dt$ Show that $$f'(x)+g'(x)=0$$ Hence $$f(x)+g(x)=\frac{\pi}{4}$$ What I did for the first part: $$f'(x)=2(\int_0^x e^{-t^2}dt)\frac{d}{dx}\int_0^x e^{-t^2}dt=2(\int_0^x e^{-t^2}dt)(\int_0^x e^{-x^2}dt)=2xe^{-x^2}\int_0^x e^{-t^2}dt$$ and $$g'(x)=\int_0^1 \frac{\partial}{\partial x}\frac{e^{-x^2(t^2+1)}}{t^2+1} dt=-2x\int_0^1 e^{-x^2(t^2+1)}dt=-2xe^{-x^2}\int_0^1 e^{-x^2t^2}dt$$ So $$f'(x)+g'(x)=2xe^{-x^2}(\int_0^x e^{-t^2}dt-\int_0^1 e^{-x^2t^2}dt)$$ But I can't show that the last term =0, where did I make a mistake, or what should I do to take this further? Any help is appreciated.","['multivariable-calculus', 'ordinary-differential-equations']"
2494449,How to prove $f(M_1 \cap M_2) \subseteq f(M_1) \cap f(M_2)$,"I am familiar with what $M_1 \cap M_2$ means (and related), but how do I prove something like $$f(M_1 \cap M_2) \subseteq f(M_1) \cap f(M_2)$$ If this relation doesn't hold, I have to come up with a counter example to disprove, but in theory, imagining that would be true, how could I prove (or disprove) this? I seem to not get my head around that, and I'd appreciate any hint on how I could get a logic chain from the left-hand to the right-hand side. Many thanks.","['proof-writing', 'elementary-set-theory']"
2494470,"Prove that if p is an odd prime, the number of residues x modulo p for which both x and x+1 are quadratic residucs","Prove that if p is an odd prime, then the number of residues x modulo p for  which both x and x+1 are quadratic residucs is $\frac{p-(-1)^\frac{p-1}{2}}{4}-1$ I know that 0 is neither a quadratic residue nor a quadratic non-residue, so there is a ""-1"", but I have no idea how $\frac{p-(-1)^\frac{p-1}{2}}{4}$ comes. Can anyone help me with it? Thank you very much!","['prime-factorization', 'number-theory', 'elementary-number-theory', 'prime-numbers', 'legendre-symbol']"
2494482,How to find indicial equation,How can I find the indicial equation of $x(x-1)y''+3y'-2y=0$? I tried the method of Frobenius but I keep getting lost in the algebra. Is there any other way to get the indicial equation?,['ordinary-differential-equations']
2494501,$X(C) = \{\text{nilpotent elements in $C$}\}$ is not a scheme,"I am try to prove that 
$X(C) = \{\text{nilpotent elements in C}\}$ is not a scheme. I have proved that it is local, so what makes it is not a scheme must be the open cover stuff. And I think it is covered by $X_n(C) = \{x|\text{$x^n=0$ in C}\}$. So I think it is covered by an infinite union of affine schemes. Therefore, I think the problem is that the cover is not open. But even if I could prove this obvious cover is not open. It is still not sufficient to prove that $X$ has no open affine cover. And I have no idea for finding some contradiction assuming $X$ has an open affine cover. So how to show that $X$ has no open affine cover? Thanks for any help.","['schemes', 'algebraic-geometry']"
2494542,Does $z+z^2+z^4+z^8 + .... $ ever become unboundedly negative?,"I was analyzing the function $$ \Delta(x)  = \sum_{k=0}^{\infty} x^{2^k} $$ Over $x \in \mathbb{C}  \text{ s.t. } |x| \le 1$. What I'm trying to answer is: does there exist a sequence of complex numbers $x_i$ such that $|x_i| \le 1$ and $ \forall \delta < 0  \\ \exists \  \tau 
 \ | \  \forall \ n > \tau \    \Delta(x_n) < \delta  $ I.E. a sequence in the unit disk whose limit value under this function is $-\infty$. I'm finding that travelling from 0 towards any fixed point in unit circle (where there are known singularities) isn't fruitful, since it always tends towards positive infinity. My (rather superficial) argument is as follows, consider any such direction $a+bi$ where $a^2 + b^2 = 1$. Observe that for any choice of distance $\epsilon$ exists an arbitrarily close $u+vi$ such that $u+vi$ is the solution to $x^{2^j} = 1$ for some set of positive $j$ and therefore $\Delta(u+vi) = +\infty$. So if $\Delta(a+bi)=-\infty$ then for any positive $\epsilon$ one can find a point on the unit disk where $\Delta(u+vi) = +\infty$. So rigorously this means nothing. But intuitively, the function needs to be break continuity on its disk (which it already has) but in some weaker sense, I wonder if that has implications on the convergent series (to the respective points). All in all, I'm a bit stuck.","['complex-analysis', 'sequences-and-series']"
2494613,Middle Cancellation in Groups,"For a, b, c, d, x elements of a group G. If ab = cd does that mean that axb = cxd? What if ab = cd only in this one instance, does the equality still hold?",['abstract-algebra']
2494640,Evaluate $\int_{0}^{\pi\over 4}{\ln(\tan(x))\over \cos^{2n}(x)}\mathrm dx$,$$\int_{0}^{\pi\over 4}{\ln(\tan(x))\over \cos^{2n}(x)}\mathrm dx=F(n)\tag1$$ $n\ge1$ $F(1)=-1$ $F(2)=-{10\over 9}$ $F(3)=-{284\over 225}$ How do we evaluate the closed form for $(1)$? $u=\tan(x)$ then $\cos^2{(x)}\mathrm du=\mathrm dx$ $$\int_{0}^{1}{\ln(u)\over \cos^{2n-2}(x)}\mathrm du\tag2$$ $\sec^2(x)=1+\tan^2(x)$ $\sec^{2n-2}(x)=(1+\tan^2(x))^{n-1}$ $\sec^{2n-2}(x)=(1+u^2)^{n-1}$ $$\int_{0}^{1}(1+u^2)^{n-1}\ln(u)\mathrm du\tag3$$,['integration']
2494681,Range of a vector function,"May someone help me. Suppose that there exist two real functions $f_1$ and $f_2$ defined on $A\subset\Bbb{R}^n$. The images of them are denoted by $f_1(A)$ and $f_2(A)$, respectively. Let us define a vector function by $f=(f_1,f_2): A \to \Bbb{R}^2$. Am I right or not if I write $f(A)=f_1(A) \times f_2(A)$?. Is there a notion of the range for a vector function? If yes, the set $f(A)$ can be said the range of $f$ or not?","['multivariable-calculus', 'calculus', 'vector-analysis']"
2494687,Find the value of $x_{2014}$?,"A sequence of real numbers $(x_n)_n$ are defined as follows:
  $$x_{n+2} = \frac{1 + x_{n+1}}{x_n}\quad n = 0, 1, 2,\dots$$ 
  and $x_0 = 1$, $x_1 = 2$. Then $x_{2014}$ equals to (A) 1 (B) 2 (C) 3 (D) none of the above My attempts. here $x_0 =1$ and $x_1 = 2$, as $x_2 = (1 + x_1)/x_0  = (1 +2)/1 = 3$,  $x_3=(1+x_2)/x_1 = (1+3)/ 2 =2$... from this I can conclude that for even number sequence  I get value 3  and for odd number sequence I get the value 2. So 2014 is an even number so I get $x_{2014} =3$. So the correct option is  $3$... Is its correct or not... pliz tel me the solution, I would be more thankful","['real-analysis', 'sequences-and-series']"
2494705,intuition of decomposition of $\mathbb{R}$ into disjoint union of first category and null set,"Let the length of an interval $I$ be $|I|.$ A subset $B\subset \mathbb{R}$ is called a null set if for any $\varepsilon>0,$ there exists a sequence of open intervals $(I_n)_{n\in\mathbb{N}}$ such that $B\subseteq\bigcup_{n\in\mathbb{N}}I_n$ and $\sum_{n\in\mathbb{N}}|I_n|<\varepsilon.$ A subset $A\subseteq\mathbb{R}$ is of first category if $A=\bigcup_{n\in\mathbb{N}}A_n$ where $A_n$ is nowhere dense set. Oxtoby stated the following theorem: Theorem : The real line $\mathbb{R}$ can be decomposed into two disjoint union of first category set $A$ and null set $B$. Idea of Proof: Let $\mathbb{Q}=\{p_n:n\in\mathbb{N}\}.$ Fix $i,j\in\mathbb{N}.$ Let $I_{i,j}$ be intervals containing $p_n$ of length $1/2^{i+j}.$
Then $A=\bigcap_{j\in\mathbb{N}}\bigcup_{i\in\mathbb{N}}I_{i,j}$ is a null set while $B = \bigcup_{j\in\mathbb{N}}\bigcap_{i\in\mathbb{N}}I_{i,j}^c$ is of first category. Question: What is an intuition behind the construction of $A$ and $B?$ When I tried to prove the theorem on my own, I would not know that $A$ and $B$ are constructed as above. Any help is appreciated. EDIT: According to Dave's comment, the decomposition is due to Lebesgue outer measure being $G_{\delta}.$
However, I think that there should be a more elementary way to construct the decomposition. In particular, given that $\mathbb{R}$ can be decomposed into disjoint union of null set and set of first category, how do we construct them solely from their definitions?","['real-analysis', 'real-numbers', 'baire-category', 'measure-theory']"
2494711,Show that $E(|X-Y|^{3/2})\leq 2 E(|X|^{3/2})$ when $X$ and $Y$ are i.i.d.,"Let $X$ and $Y$ be i.i.d. random variables such that $E(|X|^{3/2})$ is finite. Prove that $$E(|X-Y|^{3/2})\leq 2 E(|X|^{3/2})$$ This is from a past qualifying exam. I'm really stumped by the question. I tried several things with Jensen, conditional expectations, ..., to no avail.","['inequality', 'expectation', 'independence', 'probability-theory', 'lp-spaces']"
2494732,"Prove that function is not C1 in every neighbourhood of (0,0)","$f(x,y)=(x^2+y^2)\sin{\frac{1}{\sqrt{x^2+y^2}}}$ Wolfram partial derivative:
$$\frac{\partial f}{\partial x}=\frac{-x\cos{\frac{1}{\sqrt{x^2 + y^2}}}}{\sqrt{x^2 + y^2}} + 2 x \sin{\frac{1}{\sqrt{x^2 + y^2}}}
$$ I figured out its partial derivatives are actually continuos by trying to find the derivatives from definition.
What is the correct way to approach this?","['multivariable-calculus', 'partial-derivative', 'limits']"
2494774,Questions concerning smallest fraction between two given fractions.,"I recently encountered this on a practice test Find the smallest positive integer $n$ such that there exists an integer $m$ satisfying $0.33 < \frac{m}{n} < \frac{1}{3}$ My answer: $$\begin{align}0.33 < \frac{m}{n} < \frac{1}{3}&\implies(\frac{33}{100} < \frac{m}{n})\land(\frac{m}{n}<\frac{1}{3}) \\ &\implies(33n<100m)\land(3m<n) \\\end{align}$$ and thus $n=3m+1$ . So $$\begin{align}33n<100m&\implies33(3m+1)<100m \\ &\implies 99m+33<100m\\ &\implies m>33\end{align}$$ Taking $m\geq34$ , we find that $n=34\times3+1=103$ After the test, I had the following thoughts, which I do not know how to answer. Questions Will the solution for $n$ always yield the smallest $m$ possible? Does this method (find minimum value of $n$ and substitute) work for all such problems? (where $m,n\in\mathbb{Z}$ ) Can we generalise $n$ for all possible fraction ranges, and if so, will $n$ always be of a certain form compared to $a,b,c,$ and $d$ ? (where $\frac{a}{b}<\frac{m}{n}<\frac{c}{d}$ ). note: sorry for asking multiple questions in one post (which I know some people frown on) but I feel posting multiple questions with the same 'introduction' (problem+proof) would clutter and be somewhat cumbersome.","['algebra-precalculus', 'contest-math', 'inequality', 'fractions']"
2494843,"Surjective, but not Injective Linear map between C[0,1]","Given the Banach space $C[0,1]$={$f$:$[0,1]$$\longrightarrow$$\mathbb{C}$, continuous} equipped with sup norm, I would like to find a bounded linear operator $T$ : $C[0,1]$$\longrightarrow$$C[0,1]$ that is surjective but not injective. And all I can think of is a differential operator, but not all continuous functions are differentiable. So a differential operator wouldn't work unless the domain is restricted. I have come up with $T(f(x))=f(\frac{x}{2})-f(1-\frac{x}{2})$ T is not injective, but I am not convinced if T is even surjective. So any help would be appreciated. Thank you.","['banach-spaces', 'differential-operators', 'analysis']"
2494847,"Rigorous concise books that cover commonly taught mathematical topics since primary school up to ""calculus"" in high school","I'll be doing some tutoring and (to help myself with the presentation of the material) I need to find a rigorous and concise book (or books) about the topics that are commonly taught since primary school until the end of high school (right before starting the ""calculus"" sequences). Does such books exist? Can you provide some examples?","['reference-request', 'calculus', 'algebra-precalculus', 'euclidean-geometry', 'soft-question']"
2494850,Markov chain on a graph,"Suppose $(X_0, X_1, X_2,...)$ is a Markov chain on a graph $G=(V,E)$ on which there is a distinguished node $v^* \in V$. The transition matrix $P$ is such that $P(x,y)>0$ iff $x$ and $y$ are neighbours, i.e. if $x \sim y$ and we also assume that for every $x\in V$, $x \sim x$ and consequently $P(x,x)>0$. Moreover, for a node $x\in V$,  $P(x,y) = p >1/2$ for the node $y$ such that $d(y,v^*)<d(x,v^*)$ (or one of those nodes, if there are multiple) and $P(x,z) \sim 1-p$ for all other neighbors of $x$. How can we prove that the invariant measure $\pi$ puts maximum mass on $v^*$, i.e. that $\pi(v^*)>\pi(v) \forall v\in V\setminus\{v^*\}$ ?","['random-walk', 'markov-chains', 'probability-theory', 'probability']"
2494860,Evaluation Map of invertible Sheaves Isomorphism,"Let $(X, \mathcal{O}_X)$ ringed space, $\mathcal{F}, \mathcal{G}$ invertible sheaves on $X$ and $\underline{Hom}_{\mathcal{O}_X}(\mathcal{F},\mathcal{G}) $ the $Hom$ - sheaf. There is always given the canonical evaluation map $\mathcal{F} \otimes \underline{Hom}_{\mathcal{O}_X}(\mathcal{F},\mathcal{G}) \to \mathcal{G}$. My question is how to prove that this map is an isomorphism?","['sheaf-theory', 'algebraic-geometry']"
2494886,Lebesgue measure on $\mathbb{R}$,"Let $l$ be the Lebesgue measure on $ \sigma$-algebra $L$ of Lebesgue measurable subsets of $\mathbb{R}$ and $A\in L$ with $l(A)>0$. How do I prove that for a $0<\epsilon<1$ there exists an open $U$ such that
  $$ l(A\cap U)>\epsilon\cdot l(U) ?$$ What I have tried: I know that the Lebesgue measure is given by
$$l(X)=\sup\{l(C):C\subset X,C\text{ compact}\}$$
or
$$l(X)=\inf\{l(O):X\subset O,O\text{ open}\}$$
Thus I can find an open $O$ with $A\subset O$ and $l(A)>l(O)-\delta$ for any $\delta$. Taking $\delta=l(A)(1/\epsilon-1)$, we then get $l(A)>\epsilon\cdot l(O)$. How do I continue from here?","['lebesgue-measure', 'measure-theory']"
2494899,Function is Continuous When Restricted to Closed Sets Which Cover the Space,"Suppose that $\{A_i\}$ is a finite collection of closed sets in $X$ such that $X = \bigcup A_i$, and $f : X \to Y$ restricted to each $A_i$ is continuous. Then $f$ is continuous. Okay. The base case ($n=2$) is just the pasting lemma. I am having a little trouble with the inductive case, specifically with what the hypothesis is and how to deal with continuity with respect to subspaces. I believe the inductive hypothesis is to assume that any function over a topological space that is the union of $n-1$ closed sets such that the function restricted to each of these $n-1$ closed set is continuous must be continuous over the whole space. Then I assume I have a topological space $X = \bigcup_{i=1}^n A_i$, where each $A_i$ is closed, and a function $f : X \to Y$ such that $f|_{A_i}$ is continuous for each $i$. Thus $X = \bigcup_{i=1}^{n-1} A_i \cup A_n$, where $C = \bigcup_{i=1}^{n-1} A_i$ is closed since it is a finite union of closed sets. If I can show $f|_C$ is continuous, then I simply apply the pasting lemma to finish the problem. Give $C$ the subspace topology, and notice that each $A_i$ is closed in $C$. Thus we have a topological space $C$ that is the union of $n-1$ closed. But do I still have continuity $f$ restricted to $A_i$ since I am no longer considering them subspaces of $X$ but of $C$? When one says $f|_{A_i}$ is continuous, is one saying that $f$ is continuous when restricted to $A_i$ and $A_i$ is given the subspace topology? EDIT: I think I figured out the lemma I need. Claim: Let $A$ and $C$ be subspaces of $X$ such that $A \subseteq C$. Topologize $C$ with subspace topology with respect to $X$. Then the subspace topology on $A$ as a subspace of $X$ (call it $\tau_X$) is the same as the subspace topology of $A$ as a subspace of $C$ (call it $\tau_C$). Proof: Let $U$ be open in $X$. Then $A \cap U$ is some open set in $A$ as a subspace of $X$. Since $C$ is a subspace of $X$, $C \cap U$ is open in $C$ as a subspace of $X$. Then $A \cap (C \cap U) = (A \cap C) \cap U = A \cap U$ is open in $A$ as a subspace of $C$, thereby proving $\tau_X \subseteq \tau_C$. Now let $O$ be some open set in $C$ as a subspace of $X$. Then $A \cap O$ is some open subset of $A$ as a subspace of $C$. But $O = C \cap U$ for some open set in $X$. Therefore $A \cap O = A \cap (C \cap U)= A \cap U$, which is also open in $A$ as a subspace of $X$. Hence $\tau_C \subseteq \tau_X$ Kind of obvious. But it was hard to spot the need for this lemma when I was considering subspace of subspaces and continuous functions, etc. Am I right in thinking this is the lemma I need?","['continuity', 'general-topology', 'solution-verification']"
2494905,Is $\frac{\partial}{\partial x_1}=\frac{\partial}{\partial y_1}$ if $x_1=y_1$?,"Let $M$ be a manifold, $p\in M$ and $(U,\varphi=(x_1,\dots,x_n))$, $(V,\psi=(y_1,\dots,y_n))$ two local charts such that $p\in U\cap V$ and $x_1=y_1$. Is it true that $(\frac{\partial}{\partial x_1})_p=(\frac{\partial}{\partial y_1})_p$? My professor says that the answer is yes, and so I build a proof. But then I found the following counterexample: Let $M=\mathbb{R}^2$, $p=(0,0)$, $U=V=\mathbb{R}^2$, $\varphi(u,v)=(u,v)$ and $\psi(u,v)=(u,u+v)$. Then $x_1(y_1,y_2)=y_1$ and $x_2(y_1,y_2)=y_2-y_1$. Using the formula for the change of basis I've got $$(\frac{\partial}{\partial y_1})_p=\sum_{i=1}^2(\frac{\partial x_i}{\partial y_1})_p(\frac{\partial}{\partial x_i})_p=(\frac{\partial}{\partial x_2})_p-(\frac{\partial}{\partial x_1})_p\neq (\frac{\partial}{\partial x_1})_p$$ What's wrong with this counterexample?","['manifolds', 'vector-fields', 'smooth-manifolds', 'differential-geometry']"
