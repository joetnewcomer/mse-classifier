question_id,title,body,tags
1173703,Language interpretation dilemma: How do I interpret this textual statement?,"How do I interpret this statement? Given a set S containing n real numbers and a real number x , there are two numbers in S whose sum is x . It's not clear to me what we can assume here.  I'm not sure if x is necessarily in S . My focus is on the assumption.  I guess there are two possible interpretations: 1)  $S = \{n_0, n_1, n_2, ...,n_n \}$ where $n \in \Re$, and $\exists x \in \Re$ or 2)  $S = \{n_0, n_1, n_2, ...,n_n, x \}$ where $n, x \in \Re$ Basically, is $x \in S$?","['formal-languages', 'elementary-set-theory']"
1173710,Evaluate $\sum_{n=1}^\infty \frac{n}{2^n}$.,"Evaluate $$\sum_{n=1}^\infty \frac{n}{2^n}$$ My Work: $$\sum_{n=1}^\infty \frac{n}{2^n} = \sum_{n=1}^\infty n \left(\frac{1}{2}\right)^n$$ If we denote $f(x) = \sum_{n=1}^\infty nx^n$ then we wish to evaluate $f(1/2)$. Now, $$\sum_{n=1}^\infty nx^n = x \sum_{n=1}^\infty nx^{n-1} = x\sum_{n=1}^\infty (x^n)' =  x\left(\sum_{n=1}^\infty x^n\right)' = x \left(\frac{-x}{1-x}\right)' = \frac{-x}{(1-x)^2}$$ Applying $x=1/2$ we get the wrong result of $-2$. Where is my mistake?","['sequences-and-series', 'summation', 'calculus']"
1173739,How do I show a function is Big-O of another function using the definition of Big-O?,"Definition : A function F(x) is Big-O of g(x) if we can find constant witnesses such that 
$f(x) <= Cg(x)$ when $x=k$. Use the definition of “$f (x)$ is $O(g(x))$” to show that: $x^4 + 9x^3 + 4x + 7$ is $O(x^4)$ I tried dividing both sides by $x^4$, but I'm not sure how to find a tight bound without repeatedly guessing and checking. Another way to phrase this problem: After modifying C, so that $g(x)$ approximates $f(x)$, how would one find the intersection of the two functions. P.S. I'm studying for a test so I'm looking for how to solve these problems in general.","['computer-science', 'discrete-mathematics']"
1173868,"Show that a 2x2 matrix A is symmetric positive definite if and only if A is symmetric, trace(A) > 0 and det(A) > 0","I need to show two parts of the implication are true. 
First: if $A$ is $2\times 2$ and is symmetric positive definite then $trace(A)>0$ and $\det(A)>0$. Second: if $trace(A)>0$ and $\det(A)>0$ then $A$ is symmetric positive definite. For the first part I was thinking: $A$ is symmetric and positive definite then $A$ has its eigenvalues positive. If $A$ is $2\times 2$  then characteristic polynomial of $A$ is
 $x^2−x.trace(A)+\det(A)=0$  If we compute the discriminant we get $(tr(A))^2 ≥ 4.\det(A)$ 
Now $tr(A)$ is squared so it is positive. How do I know that $\det(A)$ is also positive? After copper.hat's response we argue that the eigenvalues of A are all positive because $A$ is spsd and the $\det(A)$ is the product of its eigenvalues. Thus $\det(A)$ is strictly positive. Now, how do I verify the second part? Thanks.","['matrices', 'determinant']"
1173903,Centroids of a polygon,"Obviously, for any polygon we can define at least $3$ different centroids: $C1:\;$ mass center of the lamina; $C2:\;$ mass center of vertices with equal masses; $C3:\;$ mass center of the perimeter. For the triangle $C1 = C2 \ne C3$ ; for common, even convex, polygon $C1\ne  C2\ne  C3$ : I'm interested: are there any theorems, facts or conjectures about these points?","['geometry', 'polygons', 'centroid']"
1173920,Question about Picard group of $\mathbb{P}^1\times\mathbb{P}^1$,"Let $Q=\mathbb{P}^1\times\mathbb{P}^1$. Denote by $p$, $q$ the projections on the components. Then $\text{Pic}\,Q$ is generated by $D_1$ and $D_2$, where $D_1=p^*x$, $D_2=q^*y$ and $x,y$ are points in $\mathbb{P}^1$. This might be a silly question but how can I compute the intersection numbers of these divisors?",['algebraic-geometry']
1173930,General analytical solution for first order time varying system of ODEs,"I asked a question related to this previously, but not as explicitly as I should have, I'm restating it more concisely here. Assume we are given some matrix $\mathbf{A}(t)$, which is time dependent. This matrix is square and not invertible. A system:
$$
\frac{\text{d}\mathbf{x}(t)}{\text{d}t}=\mathbf{A}(t)\mathbf{x}(t)
$$ Admits the solution:
$$
\mathbf{x}(t)=\mathbf{x}(0)\text{exp}\left({\int^t_0\mathbf{A}(\tau)\,\text{d}\tau}\right)
$$ If the following property holds: $$
\mathbf{A}(t)\mathbf{A}(\tau)=\mathbf{A}(\tau)\mathbf{A}(t)
$$ The property is also know as the matrix being semi-proper . Is there an analytical solution for the cases when $\mathbf{A}(t)$ is not semi-proper? If there is no analytical solution, how should one go about constructing an approximate solution? What methods are commonly used?","['linear-algebra', 'ordinary-differential-equations', 'numerical-methods']"
1173935,Rearranging an equation to form the limit definition of derivative,"I am following a proof which starts with the following inequalities: $$S_{i}(v) \geq S_{i}(v+dv) + (-dv)P_{i}(v+dv)$$
$$S_{i}(v+dv) \geq S_{i}(v) + (dv)P_{i}(v)$$ From this, we rearrange to form: $$P_{i}(v+dv) \geq \frac{S_{i}(v+dv) - S_{i}(v)}{dv} \geq P_{i}(v)$$ Taking limits as $dv \rightarrow 0 $, we get:
$$ \dfrac{dS_{i}}{dv_{i}} = P_{i}(v_{i}) $$
using the sandwich theorem and limit definition of derivative. My question is regarding rearranging the first two inequalities to form the third inequality bounded by the two variables. In this case, we assume that $dv > 0$, as the signs do not change. If we assume $dv < 0$, the signs change directions, however after taking the limit we reach the same result. But what about if $dv = 0$? Is the proof not considering this case? Or we just stating the derivative is not defined at $dv = 0$? Can you still say the derivative of $S$ wrt $v$ is $P_i(v)$? Both functions are assumed to be continuous so even if $dv = 0$, therefore the final statement is still correct?","['calculus', 'proof-verification', 'derivatives', 'limits']"
1173973,morphism of ringed spaces glue,"Suppose $(X,O_X)$ and $(Y, O_Y)$ are ringed spaces, and let $X = U_1 \cup U_2$ be an open cover. Suppose we have morphism of ringed spaces $\pi_i: U_i \rightarrow Y$ such that they agree on the overlap. I want to show that there is a unique morphism of ringed spaces $\pi: X \rightarrow Y$ such that $\pi|_{U_i} = \pi_i$. I was able to show that the continuous map between $X$ and $Y$, but I am having trouble defining the map between the structure sheaves. I appreciate any help! Thank you! PS I would also appreciate if someone could explain me exactly what it means to ""agree on the overlaps"", what does this mean for the map of sheaves of the ringed space morphism?","['sheaf-theory', 'algebraic-geometry']"
1174013,Show that the distribution is of the form $C \delta + f$,"I'm trying to solve this problem: Let $ u = p.v.(1/x)$, $\phi$, $\psi \in C^{\infty}_c$. I want to show that the distribution $(\phi u )* (\psi u)$ is of the form $C \delta + f$ for some constant C and $f \in C^{\infty}$. I realize that $\widehat{(\phi u )* (\psi u)} = \widehat{\phi u} \,\cdot \widehat{\psi u}$, but how do I proceed from here? Thanks in advance.","['fourier-analysis', 'partial-differential-equations', 'distribution-theory', 'complex-analysis']"
1174029,Find the $2000^{th}$ digit of the series $1234567891011121314\cdots $,"Find the $2000^{th}$ digit of the series $1234567891011121314\cdots $ where $123456789\underbrace{1}_{10\text{th digit}}~~\underbrace{0}_{11\text{th digit}}~~\underbrace{1}_{12\text{th digit}}~~\underbrace{1}_{13\text{th digit}}~~\underbrace{1}_{14\text{th digit}}~~\underbrace{2}_{15\text{th digit}} \cdots $
and so on. I really have no clue how to begin, as it is totally different from the other sequence and series problems  ,thanks .","['sequences-and-series', 'number-theory', 'combinatorics']"
1174035,Interpretation of the Weierstrass Preparation Theorem,"I am reading Griffiths and Harris' Principles of Algebraic Geometry but I am having trouble making sense of a statement following the Weierstrass Preparation Theorem (p.9 in my edition). The Weierstrass Preparation Theorem says the following. Theorem (Weierstrass Preparation Theorem) . If $f$ is holomorphic around the origin in $\mathbb{C}^n$ and is not identically zero on the
  $w$-axis, then in some neighbourhood of the origin $f$ can be written
  uniquely as $$f=g\cdot h$$
  *where $g$ is a Weierstrass polynomial of degree $d$ in $w$, i.e., $g$ if of the form*$$g(z,w)=w^d+a_1(z)w^{d-1} + ... + a_d(z)$$ and $h(0)\neq 0$. I understand the theorem and its proof, but then the authors conclude the following which I am not being able to understand. ""(Therefore) The zero locus of an analytic function $f(z_1,...,z_{n-1},w)$, not vanishing identically on the $w$-axis, projects locally onto the hyperplane ($w=0$) as a finite-sheeted cover branched over the zero locus of an analytic function."" Could someone help me elaborate a little bit further so that I can understand the meaning of this last paragraph? I understand that as a consequence of the theorem, the zero locus of $f$ is locally (for most choices of coordinate systems) the same as the zero locus of $g$. This is evident since $h$ does not vanish around zero. So my intuition says that the sheets will be related to the zero loci of the functions $a_i$. But I am missing the geometric picture to see the branched cover.","['complex-geometry', 'several-complex-variables', 'complex-analysis']"
1174038,How to solve nonhomgenous recurrence relation?,"I'm studying this topic in advance and I'm working on textbook problems. The problem is simple : Solve the following recurrence relation a) $a(n+1)-a(n)=2n+3$ , $n$ is greater than or equal to $0$ and $a(0)=1$ b) $a(n+1)-a(n)=3n^2-n$ , $n$ is greater than or equal to $0$ and $a(0)=3$ The answer in the back of the text says: a) $a(n)=(n+1)^2$ , $n$ greater than or equal to $0$ b) $a(n)=3+n(n-1)^2$ , $n$ greater than or equal to $0$ I'm new to this topic and I want to know a efficient way to solve this problem. It is also good if you explain only one of them but step by step explanation to answer would be very much appreciated.","['recurrence-relations', 'discrete-mathematics']"
1174041,On subgroups of abelian groups,"Let $G$ be a product of $n$ finite cyclic groups. Is every subgroup of $G$ also a product of (at most) $n$ finite cyclic groups ? I do not know the answer to this question, but I'm tempted to say yes. I'm aware of the classification theorem of abelian groups but I don't know how to use it here, I've also tried modules and dual groups but nothing serious came out of it.","['finite-groups', 'group-theory', 'abelian-groups']"
1174054,"Calculate $\int_0^{\pi/2}\frac{\sin(x)\log{\sin{(x)}}}{x}\,dx$","Inspired by a question I saw these days, I try to calculate in closed form $$\int_0^{\pi/2}\frac{\sin(x)\log{\sin{(x)}}}{x}\,dx$$ So far no fruitful idea that is worth sharing. What way would you propose? Note I prefer ways suggested,  not necessarily solutions, but I have nothing against any of the options you prefer.","['definite-integrals', 'calculus', 'integration', 'real-analysis']"
1174076,Absolute value problem $|x-5|<|x+1|$,"So I have this basic absolute value problem: $|x-5|<|x+1$|. From what I understand, I need to consider what happens in every case. There are four cases, right? One where both sides are positive, one where both sides are negative and two where one side is negative and the other is positive. The case were both are negative gives me something absurd ($5<-1$). Since the solution set is the intersection of the solutions for every case, this would mean that it has no solution. But it has. Where is the error in my reasoning?",['algebra-precalculus']
1174114,Find all integral solutions of $y^2=x^3+7$,"Find all integral solutions of $y^2 = x^3+7$. I tried to use many different moduli, but it never works. With modulo $9$, you can get $x$ is divisible by $3$.","['contest-math', 'number-theory']"
1174116,Showing $\sum^\infty_{n=1} \frac 1 {e^{\sqrt n}} $ converges,Show that $\displaystyle\sum^\infty_{n=1} \frac 1 {e^{\sqrt n}}$ converges. My attempt: Using limit ratio test: $\displaystyle\lim_{n\to\infty} \frac {e^{\sqrt n}} {e^{\sqrt {n+1}}}=\lim_{n\to\infty}\frac {e^{\frac n 2}} {e^{\frac {n+1} 2}}=\lim_{n\to\infty}\frac {e^{\frac n 2}} {e^{\frac n 2+\frac 1 2}}=\lim_{n\to\infty}\frac 1 {e^{\frac n 2+\frac 1 2-\frac n 2}}=e^{-0.5}$ And since $e^{-0.5}<1$ the series converges. Is that alright?,"['sequences-and-series', 'calculus', 'proof-verification']"
1174118,Selection Sort Summation Simplification,"I am trying to simplify the summation for selection sort. Starting out with: $$\sum_{i=0}^{n-1}\sum_{j=i+1}^{n-1}1$$ I am able to get: $$\sum_{i=0}^{n-1}n-i-1$$ However, I don't understand how to simplify this summation any further. I don't know if I should pull the n outside of the summation, and I don't know what to do about the $i$. I would appreciate any help and detailed steps in how one gets from one step","['summation', 'discrete-mathematics', 'algorithms']"
1174158,Characters of group scheme represented by Cartier dual,"For a commutative group scheme $\pi \colon G \to S$ finite locally free over a base scheme $S$ we let $A := \pi_* \mathcal{O}_G$ and $A^* = \mathcal{Hom}_\mathcal{O_S}(A, \mathcal{O}_S)$. Then $A^*$ ist again a finite locally free $\mathcal{O}_S$-Algebra and the Cartier dual to $G$ is $G^* := Spec(A^*)$. I want to understand the fact, that $G^*$ represents the inner hom $T \mapsto Hom_{Grp/T}(G_T, \mathbb{G}_{m,T})$ in the category of $S$-schemes. I already have bijections
$$
Hom_S(S, G^*) \cong \{ x \in \Gamma(S, A)^\times \mid \Delta(x) = x \otimes x, \epsilon(x) = 1\} \cong Hom_{Grp/S}(G, \mathbb{G}_{m,S})
$$ where $\Delta$ and $\epsilon$ denote co-multiplication and augmentation of $A$ respectively. I got two questions: I think that $(G^*)_T \cong (G_T)^*$ canonically, but I am not quite sure why this is true. It would however suffice to obtain $Hom_S(T, G^*) \cong Hom_{Grp/T}(G_T, \mathbb{G}_{m,T})$ for any $S$-scheme $T$. I have absolutely no idea how to show this bijection to be functorial. I have tried to simply chase elements in the significant diagrams, but with all the isomorphisms I have used to obtain the bijection, it just seems impenetrable to me. Is there a way to reduce to a situation where the functoriality is easier to see?","['category-theory', 'algebraic-geometry', 'schemes']"
1174193,Trouble with a Notation in Lee's Introduction to Smooth Manifolds.,"In the proof of Proposition 9.7 of Lee's Introduction to Smooth manifolds, there is a certain notation which is giving me trouble. We have a smooth map $\theta :\mathbb R\times M\to M$ and smooth function $f:M\to R$.
  What is the meaning of $$\left.\frac{\partial}{\partial t}\right|_{(0,p)}f(\theta(t,p))$$
  Is there a more generalized form of this notation, where instead of $\mathbb R$ we have some other manifold? I am aware of a similar notation, which is as follows. Let $M$ be a smooth manifold and $(U,\phi)$ be a smooth chart on $M$. Say $\phi$ is expressed as $(x_1,\ldots, x_n)$ in local coordinates. Then $\left.\frac{\partial}{\partial x_i}\right|_p$ is defined by $$\left.\frac{\partial}{\partial x_i}\right|_pf=\left.\frac{\partial (f\circ\phi^{-1})}{\partial x_i}\right|_{\phi(p)}$$ where the las term is nothing but the usual partial derivative of ordinary calculus.","['notation', 'smooth-manifolds', 'differential-geometry']"
1174246,Simplifying $\frac{1/(\frac{1}{z_1}(1-t)+\frac{1}{z_2}t) - z_1}{(z_2 - z_1)}$,"This drives me mad! I am not very good in math but thought I could at least do basic things like this one, but can't figure it out and I spent a day on it. I am trying to simplify: $\dfrac{\dfrac{1}{\dfrac{1}{z_1}(1-t)+\dfrac{1}{z_2}t} - z_1}{(z_2 - z_1)}$ In Wolfram Alpha it shows me that the solution is: $\dfrac{tz_1}{t(z_1-z_2)+z_2}$ Which I know is right, but I simply can't figure out the steps to get there. If someone could please help me. I have been as far as doing: $\dfrac{\dfrac{1 - z_1(\dfrac{1}{z_1}(1-t)+\dfrac{1}{z_2}t)} {\dfrac{1}{z_1}(1-t)+\dfrac{1}{z_2}t}}{(z_2 - z_1)}$ $\dfrac{1 - z_1(\dfrac{1}{z_1}(1-t)+\dfrac{1}{z_2}t)} {(\dfrac{1}{z_1}(1-t)+\dfrac{1}{z_2}t)(z_2 - z_1)}$ And then develop the terms from there, etc. but I just can't get to the equation: $\dfrac{tz_1}{t(z_1-z_2)+z_2}$","['rational-functions', 'algebra-precalculus', 'rational-numbers']"
1174301,Torsion and inverse limits,"Given a countable family of (non-abelian) torsion groups $G_n$ (i.e. each element has a finite order) in an inverse system
$G_1\leftarrow G_2\leftarrow\dots G_n\leftarrow\dots$, where the maps are assumed to be surjective and given that the inverse limit $G=\lim_\leftarrow G_n$ is torsion,  can we derive that the set of these groups has some uniform bound $L$ on their orders, i.e. that, for all but finitely many n, $G_n^L=1$. I do not know the answer but I believe that it is a ""yes"".","['torsion-groups', 'group-theory', 'abstract-algebra']"
1174304,Derivative of a Matrix w.r.t. a Matrix,"I have a matrix product with $\mathbf{X} \in \mathbb{R}^{m\times n}$ as $\mathbf{F(X)} = \mathbf{XAA}^T$ where $\mathbf{A}$ is a constant matrix w.r.t. $\mathbf{X}$. I see that I can write the following according to Wikipedia .
$$
d\mathbf{F(X)} = (d\mathbf{X})\mathbf{AA}^T + \mathbf{X}d(\mathbf{AA}^T) = (d\mathbf{X})\mathbf{AA}^T
$$ From here, can I write,
$$
\frac{d\mathbf{F(X)}}{d\mathbf{X}} = \mathbf{I}_{m\times n}\mathbf{AA}^T = \mathbf{AA}^T
$$ Note that I have taken the help of the fact that the derivative of an ${m\times n}$ matrix $\mathbf{A}$ with respect to itself is $\mathbf{I}_{m\times n}$, as found in page 4 of the Notes on Matrix Calculus by Paul L. Fackler . I'm not sure what exactly $\mathbf{I}_{m\times n}$ is, but I'm taking it as some sort of generalized identity matrix and assuming that premultiplying $\mathbf{AA}^T$ with $\mathbf{I}_{m\times n}$ results in $\mathbf{AA}^T$ only. So, in short, my question is can I write $\frac{d\mathbf{F(X)}}{d\mathbf{X}}$ as $\mathbf{AA}^T$, in this case?","['matrices', 'linear-algebra', 'calculus']"
1174311,How to tell where parentheses go in functional notation?,The professor gave us a function $f(z) = \ln r + i \theta$ (this is for a complex analysis class). He doesn't like answering students' questions and there's no assigned textbook so I don't know where to look up such a function. How can I tell where the parentheses are supposed to go for this equation?,"['notation', 'functions']"
1174329,Prove that if $I-A$ is invertible then $I-A^p$ is invertible in $\mathrm{Mat}_n(\mathbb{Z}_p)$.,"How do you prove that if $I-A$ invertible then $I-A^p$ is invertible for  $A \in \mathrm{Mat}_n(\mathbb{Z}_p)$, where $p$ is prime?","['finite-fields', 'linear-algebra']"
1174359,Mathematical induction problem with inequality,"I have the following problem where n is a positive integer $(n >= 1)$: Prove that $\frac{1}{2n}\le\frac{1*3*5*...*(2n-1)}{2*4*...*2n}$ I know that I must start with the basic step showing that $P(1)$ is true as follows:
$1/(2*1) = 1/2$ so $P(1)$ is true. Now follows the induction step where I must show that ""if $P(k)$ then $P(k+1)$"" where 
$P(k)$ is $\frac{1}{2k}\le\frac{1*3*5*...*(2k-1)}{2*4*...*2k}$
and $P(k+1)$ is $\frac{1}{2(k+1)}\le\frac{1*3*5*...*(2k+1)}{2*4*...*2(k+1)}$ I will very much appreciate any help about how to continue.","['induction', 'discrete-mathematics']"
1174381,What is an importance of Gaussian and Eisenstein rings?,"Among quadratic integer rings, $\mathbb{Z}[i]$ and $\mathbb{Z}[\frac{1+\sqrt{-3}}{2}]$ have their special names, namely Gaussian integers and Eisenstein integers respectively. I guess this is named so because these rings are particularly more important than other quadratic rings. Moreover, one can completely characterize prime elements of these rings. I asked my professor (her major is number theory) and she said one reason why these rings are important is that $\mathbb{Z}$,Gaussian and Eisenstein rings are related to elliptic curves. However, it is not very clear to me how. Why are Gaussian & Eisenstein integers are important? And what is a use of their prime elements?","['quadratic-integer-rings', 'examples-counterexamples', 'abstract-algebra']"
1174410,A Formal proof of Green Theorem,"I want to go through the formal proof of Green theorem on a regular, simple and closed curve oriented counterclockwise and the vector space $F$ is a continuously differentiable  vector field such that $F: R^2->R^2$ defined on some open set containing C. I want to proof it by refinement in small rectangles. I proved that the cancelation does work, that means that if I have two adjacent rectangles I don't need to care about the edge in the middle. But I have trouble to use $\epsilon$ and $\delta$ to prove that the error is negligible. That means I want to proof that the for the compact set C, there is a compact set C' contained in C, such that C' is at most $\epsilon $ distance away from C. And my refinement can cover C' but contained in C.
Could any one give me some hint on it? I cannot find any information on how to deal with the refinement in the proof of Green theorem but only general idea. I really want to go through the detail about it. Thank you so much for your help","['vector-spaces', 'multivariable-calculus', 'vector-analysis', 'real-analysis']"
1174426,Does the series $\sum_{n=1}^{\infty} \frac{(-1)^n}{n(\sin(n)+2)}$ converge or diverge?,I was thinking about it and was stumped. Mathematica claims it converges.,"['convergence-divergence', 'sequences-and-series', 'real-analysis']"
1174431,Spivak alike books for Probability and/or Statistics,"I am looking for a Probability/Statistics book with an style alike to that of Spivak's Calculus, that is, a book with the following characteristics: Directed more towards Math majors rather than applied majors(engineers, economists, physicists). Every theorem, or almost every theorem is proven rigorously. Even though the book is very rigourous mathmatically, it gives a very deep intuitive understanding of the subject. I don't want merely to have a collection of formulas that work, but I want to know why they work, and what they mean.
Also, I when I say rigourous I don't mean technical or formal, the book doesn't need to use lots of technical words, it can be informal, as long as the proofs are proved rigorously. Rigorous proofs and deep understanding... Could you please reference me to a book like that? Thanks in advance","['statistics', 'probability']"
1174442,How to solve the following recurrence,"I know others have already posted about this recurrence $T(n) = 2T(n/2) + n\lg n$ on the following these two posts: post1 and post2 However, the style in which they have solved them, is not one with which I am ery familiar. I was hoping someone could look at my work so far, and then point me in the right direction or show me what I am doing wrong. This is my work up to this point: $$T(n) = 2T(n/2) + n\lg n$$
$$=2[2T(n/2^2) + (n/2)\lg (n/2)] + n\lg n$$
$$=2^2T(n/2^2) + n\lg(n/2)+n\lg n$$ I expanded this recurrence out a bit further and finally found the general formula: $$2^kT(n/2^k)+n\sum_{i=0}^klg(n)-lg(2^i)$$ I understand what to set $k$ equal to in order to arrive at $T(1)$, but I honestly don't understand how to simplify the summation in this problem. Should I keep the logarithm (which is base 2 by the way) in the following format $\lg(n/2^i)$ and split the summation, or is there another way to simplify this summation? I am stuck. EDIT So, I made some errors in my formular when I orignally posted this. Looking at the general formula above involving $k$ now, I am still wondering how to simplify and solve it. I am not sure what to do with the $\sum_{i=0}^klg(n)$. For the $lg(2^i)$ term I am thinking I can just pull the $i$ down and pull the $lg(2) outside of the summation.","['summation', 'discrete-mathematics', 'algorithms', 'recurrence-relations']"
1174446,"Determine if this series $\sum\limits_{n=1}^\infty \frac{(n!)^2}{(2n)!}$ converges or diverges, and prove your answer?","Determine if this series $$\sum\limits_{n=1}^\infty \frac{(n!)^2}{(2n)!}$$ converges or diverges, and prove your answer? I've been able to prove similar problems, but I'm confused now that there's a factorial involved. Can someone help me out here?","['factorial', 'sequences-and-series', 'real-analysis']"
1174449,How to prove that this is equal to $\pi$?,"I was trying to prove the formula for the area of a circle (without using integrals), so I started with the $\frac{Pa}{2}$ formula and started to manipulate it until I got, for an infinite number of sides (a circle), that it's area was equal to $$r^{2}\lim_{n\to\infty}\frac{n}{tan(90°\frac{n-2}{n})}$$
(as the apothem becomes the radius, where n is the number of sides, but that is not important) The point is, that I needed the expression after the $r^{2}$ to be equal to $\pi$ (so I got the $\pi r^{2}$ formula, which I as trying to prove). But both the numerator and denominator are infinite and I don't know how I could manipulate this to get my result. I searched in W|A but it only gave me the answer with no explanation. Could someone help?","['pi', 'trigonometry', 'limits']"
1174476,Multiplication order of rotation matrices,"I have three 3D coordinate frames: O, A and B, as shown below. I want to know the rotation matrix R AB between A and B, that is the rotation that is required, with respect to the frame A, to move from A to B. Let us imagine that all I know, is the rotation matrix R AO between A and O, and the rotation matrix R OB between O and B. By inspecting the above diagram: $$ R_{AO} = \left [\begin{array}{ccc}
1 & 0 & 0 \\
0 & 0 & -1 \\
0 & 1 & 0 \\
\end{array} \right ]$$ $$ R_{OB} = \left [\begin{array}{ccc}
0 & 0 & 1 \\
-1 & 0 & 0 \\
0 & -1 & 0 \\
\end{array} \right ]$$ So, what is the correct way to determine R AB ? There are two suggestions that come to mind: (1) R AB = R AO R OB (2) R AB = R OB R AO Now, my intuition is that (1) is correct, i.e. post-multiplication. This is because I am multiplying everything with respect to the local coordinate frame (as discussed in http://web.cse.ohio-state.edu/~whmin/courses/cse5542-2013-spring/6-Transformation_II.pdf ). However, when I compute this, I get: $$ R_{AB} = \left [\begin{array}{ccc}
0 & 0 & 1 \\
0 & 1 & 0 \\
1 & 0 & 0 \\
\end{array} \right ]$$ Whereas by inspection of the diagram, it should be: $$ R_{AB} = \left [\begin{array}{ccc}
0 & 1 & 0 \\
-1 & 0 & 0 \\
0 & 0 & 1 \\
\end{array} \right ]$$ Which, I have noticed, is equal to the pre-multiplication solution of (2). Please can somebody explain to me why (2) seems to be correct, rather than (1)? I was under the impression that if all your transformations are with respect to the current local frame, then post-multiplication should be done, i.e. multiply the matrices from left to right as you move between each frame. However, when doing the maths, pre-multiplication gives the expected answer.","['coordinate-systems', 'geometry', 'matrices', 'linear-algebra', 'transformation']"
1174494,Smooth curves on manifolds,"Assume that there is a parametrized smooth curve $c$ on the manifold $M$, mapping from $[a,b]$ to $M$. Also assume that there is a tangent vector on $M$ in the form $(p,v)$. Tu's text states that it is assumed that the curve $c$ is starting at $p$ if $c(0)=p$. Is there a way to show that $c(0)=p$ in any way? Any help would be appreciated! Thanks in advance!",['differential-geometry']
1174503,Cohomology with compact support for sheaves in separated schemes of finite type over a Noetherian scheme: three different definitions,"usually there are three notions of cohomology with compact (proper) support. The first one usually done in the étale site. However the second one is used in Verdier duality. The third one is done in algebraic topology. Let $X$ be a separated scheme of finite type over a Noetherian scheme $S$. Then Nagata compactification guarantees an open immersion $j : X \hookrightarrow \overline{X}$. In this context, the cohomology with compact support can be defined as $\text{H}^q (X, \mathscr{F}) = \text{H}_c^q (\overline{X}, j_{!}\mathscr{F})$. In this case, $R^{p}\text{H}_c^0 \neq \text{H}_c^{p}$. In the other approach, $\text{H}_c^{q} (X, \mathscr{F})$
 is defined as the $q$-th right derived functor of the proper supported global sections. In the third approach, $\text{H}_c^{q} (X, \mathscr{F})$
 is defined as the $q$-th right derived functor of the compact supported global sections. What's is the relation between these three approaches? Why the first one is used in étale cohomology? Would Verdier duality holds in the first and third approach? Why the first and second approach is called compact supported anyway (I can't see the sections that are compact supported!)? Thanks in advance.","['etale-cohomology', 'algebraic-geometry', 'duality-theorems', 'algebraic-topology', 'sheaf-cohomology']"
1174504,"The sum of orbit size of some element over the image of group ""polynomial""","$\DeclareMathOperator{\orb}{orb}$
Say I have a group ""polynomial"", $p$, on $S_n$, that is $p(x)=a_1 x^{\epsilon_1}...a_n x^{\epsilon_n}$ for all $x \in S_n$, fixed $a_i \in S_n$ and fixed $\epsilon_i \in \mathbb{Z}$. We will be considering $S_n$ with the natural action on $\{1,...,n\}$, $g \cdot i = g(i)$ for $i \in \{1,...,n\}$. Let $p S_n$ be the image of the polynomial. Generally, I am looking for $$ X(S_n,p,i)=\sum_{y \in p S_n} |\orb( \langle y \rangle, i)| $$ where $i \in \{1,...,n\}$ and $\orb(G,i)$ is the orbit of $i$ in $G$, or in the particular case we are looking at $\{j \mid g \in \langle y \rangle, j=g(i) \}$. For example, $p(x)=(1,2,3)x(1,2,3)x^{-1}$, then $p S_3=\{ (),(1,3),(1,3,2)\}$ and
$$\begin{align*}
 X(S_3,p,1)&=X(S_3,p,3)=1+2+3=6, \\ X(S_3,p,2)&=1+1+3=5.
\end{align*}$$ For these questions I mostly interested in references, although if you can prove it and don't know of a reference then I am happy with that too. I have a particular interest in how to calculate $X(S_n,p,i)$ when $a\in S_n$ is such that $\orb( \langle a \rangle,i)=\{1,...,n\}$, $p(x)=axa^{-1} x^{-1}$ without calculating each image and adding up. Note that each element in the image has multiplicity $n$ and so there are $(n-1)!$ elements in the image. Are there general ways to calculate $X(S_n,p,i)$ when I know the ""coefficients"" and the exponents on $x$ without just calculating each term? Question ""2."" except generalize these notions to general (finite) groups and group actions. Results on (non-trivial) upper and lower bounds for $X(S_n,p,i)$. For question 1. I suspect that figuring out for particular $a$, like $(1,...,n)$, and for $i \in \{1,...,n\}$, since we can look at conjugations of the polynomial, although I have not thought much about how that permutes the $i$: what $i,j$ gives $X(S_n,p,i)=X(S_n,bpb^{-1},j)$.","['reference-request', 'group-actions', 'symmetric-groups', 'group-theory', 'combinatorics']"
1174547,"In search of a ""perfect"" test on (positive) series convergence","Thus far mathematicians have developed many powerful tests on the convergence of a positive series (I mean $\displaystyle\sum_{i=1}^{\infty}a_i$ specifically), such as : Cauchy's Test which deals with the upper limit of $\lambda_n=\sqrt[n]{a_n}$, but comes to nothing when the upper limit is $1$. D'Alembert's Test which deals with the upper or lower limit of $\lambda_n=\frac{a_{n+1}}{a_n}$, but comes to nothing when the upper limit $\ge1$ or the lower limit $\le1$. Raabe's Test which deals with $\lambda_n= n\Big(\frac{x_n}{x_{n+1}}-1\Big)$, but comes to nothing when $\lim{\lambda_n}=1$. Bertrand's Test which deals with  $\lambda_n= (\ln n)\Big[n\Big(\frac{x_n}{x_{n+1}}-1\Big)-1\Big]$, but still comes to nothing when $\lim\lambda_n=1$. $$\vdots$$ And in my books it says, this progress never ends, ""...We can always go on and establish a even more powerful test, with more complicated proof, though..."" I don't really know how, but since this is not the point of my question, you may just skip it. Well, anyhow I hope you could take a close look at these tests. They are really brilliant in that they can tell you whether the series converges or otherwise based directly on the information of $a_n$, which won't be too obscure. But they are still NOT perfect. They are all ""if"" type but not ""iff"" type. I mean, they are all of such pattern: The series converges if $\lim \lambda_n$ blah blah blah, and diverges if $\lim \lambda_n$ blah blah blah. The worst is, if they both fail us, WE KNOW NOTHING! How I hope that I could replace ""if""s with ""iff""s, and get rid of the ""we know nothing"" case! So I'm quite wondering whether there is a perfect test that: (1) is based directly on $\lambda_n$ which $a_n$ gives rise to (2) is of such pattern as: The series converges iff $\lim \lambda_n$ blah blah blah, and diverges iff $\lim \lambda_n$ blah blah blah. (Say, we know everything!) I know there might be only dim hope, but I'm still curious. Any help will be specially appreciated. Best regards! Further Note In the first place, I'm sincerely grateful to all the help you guys provide for me. However, I'm afraid I have to make a note here because many answers posted here are not what I'm looking for. Well I'm far from criticizing, but I think I need to perhaps make my question clearer so that I'm not misleading your answers. The problem is that some answers here do not really meet the requirement (1) mentioned in my question. Please read (1) closely, I want the test to be based directly on $\lambda_n$ to which $a_n$ gives rise, just like the $\lambda_n$s in the tests listed above. In other words, $\lambda_n$ should be immediately accessible via $a_n$, or, $a_n$ gives all the immediate information needed to write out $\lambda_n$. Therefore, $\lambda_n$ is an expression that contains $a_n, a_{n+1}$ etc etc. I don't want to involve the partial sum in my test, nor am I looking for something like a powerful comparison test, because the knowledge of $a_n$ usually cannot enable us to gain the knowledge of the partial sum, or to find another $b_n$ to compare to. In short, I desire something that is based only and immediately on $a_n$. Thanks. (And, apologies if my post should look too wordy. I'm not a skillful English user)","['sequences-and-series', 'calculus', 'real-analysis', 'analysis']"
1174583,How to compute QR decomposition of a product of matrices,"Suppose I have $A=A_nA_{n-1}\cdots A_2A_1$ How can I compute the $QR$ factorization of $A$ without explicitly multiplying $A_1, A_2, \ldots, A_n$ together? The suggestion I got is that, suppose $n=3$ and $Q_3^T A =R$ The write 
$$Q_3^T A =Q_3^T A_3Q_2Q_2^T A_2Q_1Q_1^T A_1Q_0,  Q_0=I$$ Then find orthogonal $Q_i$ such that $Q_i^T A_iQ_{i-1}$ is upper triangular.","['matrix-decomposition', 'matrices', 'linear-algebra', 'triangulation']"
1174605,Prove that the following is true or provide a counterexample if it is false,"For all integers a, b, and c: If a|b and a|c then a|(b − c).
I think this is true and so for it's proof I have:
Since a|b then b=ak for some k in integers
Since a|c then c=al for some l in integers
I must show that b-c can be written as a * some integer
then b-c would be ak-al = a(k-l)
and since integers are closed under subtraction k-1 is an integer
And so I have shown b-c to be a*some integer My friend says this is false if a,b and c are the same numbers because then you would end up with a|0 which he says is not true. Am I doing this right?","['discrete-mathematics', 'number-theory']"
1174639,Series expansion of the determinant for a matrix near the identity,"The problem is to find the second order term in the series expansion of the expression $\mathrm{det}( I + \epsilon A)$ as a power series in $\epsilon$ for a diagonalizable matrix $A$. Formally, we will write the series as follows $$ \det( I + \epsilon A ) = f_0(A) + \epsilon f_1(A) + \epsilon^2 f_2(A) + \cdots +\epsilon^N f_N(A), $$ In particular, we are looking for an expression in terms of the trace of the matrix $A$.","['perturbation-theory', 'polynomials', 'approximation-theory', 'linear-algebra', 'determinant']"
1174647,Is it possible to turn infinite sums into infinite products?,"I am working on studying infinite products. I know that it is possible to convert an infinite product to an infinite sum using logarithms, where $$\log \prod s_n = \sum \log s_n$$ My question is, it always possible go from sum to product with $e$, where $$\exp \sum s_n = \prod e^{s_n}$$ Also, are there any other methods to convert sums into products? Thanks in advance.","['infinite-product', 'real-analysis', 'analysis']"
1174654,"how prove that $\lim_{n\to{}\infty} {\sum_{(i, j)\in{K_n}}^\infty{a_{ij}}}=\sum_{i=1}^\infty\sum_{j=1}^\infty{a_ {ij}}$","Let $a_{ij}\geq 0$ $(i,j)\in \mathbb{N}^2$ then $$\sum_{j=1}^\infty\sum_{i=1}^\infty{a_{ij}}=\sum_{i=1}^\infty\sum_{j=1}^\infty{a_{ij}}$$ Moreover, given $ K_1 \subseteq K_2 \subseteq \ldots \subseteq \mathbb{N}^2$  such that $\bigcup_{n\in{\mathbb{N}}}^{}{K_n}=\mathbb{N}^2$ then $\displaystyle \lim_{n\to{}\infty} {\sum_{(i, j)\in{K_n}}^\infty{a_{ij}}}=\sum_{i=1}^\infty\sum_{j=1}^\infty{a_ {ij}}$. I thought of applying the monotone convergence theorem, but not if this will help solve this problem.? Any ideas thanks","['lebesgue-integral', 'measure-theory', 'lebesgue-measure']"
1174685,Convergence of $\sum \frac{(-1)^{n+1}}{n}z^n$ at $|z|=1$,"I know that the power series $\sum \frac{(-1)^{n+1}}{n}z^n$ converges for $|z| \lt 1$ but I have been trying to determine what happens on $|z|=1$ Clearly the series converges at $z=1$ and diverges at $z=-1$. I thought that a good approach would be to write $z^n = \cos n\theta + i\sin n\theta$ and use Dirichlet's test for the two real series $\sum \frac{(-1)^{n+1}}{n} \cos n\theta, \space \sum \frac{(-1)^{n+1}}{n} \sin n\theta$ but I can't really use it here because $\frac{(-1)^{n+1}}{n}$ is not monotonic. Can someone give a hint with the right direction?","['power-series', 'sequences-and-series', 'complex-analysis']"
1174741,Mean Value Theorem problem,"Given:
$f:[0, 27] \to \mathbb R$ such that,
 $f(0)=0$ , $f(10)=1$ , $f(27)=1$ , where $f(x)$ is differentiable. Prove that , for some $\alpha$, $\beta$ $\in(0,3)$ , the relation $$2\int_0^{27} f(x)\, dx = 9[\alpha^{2}f(\alpha^{3})+\beta ^{2} f(\beta^{3})]$$
holds. I think this question is a question on the lagrange's mean value theorem.
By the form of the right hand side, I think I should use another function
$g(x)=\int_0^{x^{3}} f(x) dx$ so that $g'(x)= 3 x^{2} f(x^{3})$ but I cannot figure out the limits to apply, or how to proceed next","['calculus', 'functions']"
1174743,Finding and solving the recurrence relation of this ternary string.,"I am fairly confused with this problem and I am not looking for an answer, but an explanation as to why my initial set up of this problem is incorrect. I believe that once I Understand this bit of the question then I will be able to solve the rest my self, so please do not answer this question for me. I only want a partial explanation to my set up. Question: Consider ternary strings where $0$, $1$, $2$ are the only symbols used. Let $a_n$ count the number of ternary strings of length $n$ where there are no consecutive $1$'s and no consecutive $2$'s. Find and solve a recurrence relation for $a_n$. Basically I set it up as this
$$
a_n = a_{n-1} + a_{n-2}
$$
however, the hint given for the set up is
$$
a_n = 2a_{n-1} + a_{n-2}
$$
Can someone explain to me why we are multiplying $a_{n-1}$ by $2$? Note that $a_{n-1}$ represents strings that end in $0$ and hence the remaining sequences is $n-1$. If it ends in $1$ or $2$ then there are $n-2$ left sequences that have no consecutive $1$ and $2$.","['recurrence-relations', 'discrete-mathematics']"
1174748,Let A be a symmetric positive definite matrix. Find a matrix B such that $B^2=A$,"I believe this question is the same as asking find matrix B to be the square root of the matrix A. $B=\sqrt A$. Since the problem is not specific I am thinking to solve it in the general case by diagonalizing the matrix and find the eigenvalues and then take the square. Or, should I just take an example of a matrix A that is symmetric positive semidefinite and find $\sqrt A$ ? Any thoughts?","['matrices', 'eigenvalues-eigenvectors']"
1174756,Number of permutations of the sequence,"How can I find the number of permutations without repetitions of the sequence of all natural numbers from $1$ to $n$ such that every permutation starts with $1$ and ends with $n$ and the difference between any consecutive terms of permutation is no greater than $3$, i.e. $\lvert a_{i+1} - a_{i}\rvert\in\{1,2,3\}$? Thanks!",['combinatorics']
1174799,Existence of an holomorphic function,"Is there a simple way to prove this fact : For all holomorphic functions $f : \mathbb C \to \mathbb C$, there is an holomorphic function $\psi : \mathbb C \to \mathbb C$ such that $$\psi(z+1) = \psi(z) + f(z) $$ The solution I know use Galois covering spaces and summand of automorphy. Thanks in advance.",['complex-analysis']
1174800,Unknown Problem - Need Help,"This question is from an article I read online, titled: ""Why I Will Never Have a Girlfriend"" by Tristan Miller. The author shows his work, step-by-step throughout most of the article, except during the conclusion, when he makes the following statement: ""At first glance, a datable population of 18,726 may not seem like
such a low number, but consider this: assuming I were to go on a
blind date with a new girl about my age every week, I would have to
date for 3,493 weeks before I found 1 of the 18,726."" He does not explain how he determined 3,493 is the number required to find 1 of the 18,726. I would really like to know. It seems similar to the Birthday Paradox, but I'm not certain? Thank you in advance for any help / clue. I would especially appreciate anyone who explained, step-by-step how to figure this out, mathematically. P.S. Apologies; I am not even certain exactly what type of math problem this even is, or what to call it.","['statistics', 'probability', 'combinations']"
1174806,Number of distinct terms in the expansion of $\big(x+\frac{1}{x}+x^2+\frac{1}{x^2}\big)^{15}$,"Number of distinct terms in the expansion of $\bigg(x+\dfrac{1}{x}+x^2+\dfrac{1}{x^2}\bigg)^{15}$ is equal to ? We can write the above as, $$ \bigg(x+\dfrac{1}{x}+x^2+\dfrac{1}{x^2}\bigg)^{15} = \dfrac{1}{x^{30}}(1+x+x^3+x^4)^{15} $$
Now my teacher says that we can expand the polynomial $(1+x+x^3+x^4)^{15} $ as,
$$ (1+x+x^3+x^4)^{15} = a_0 + a_1x + a_2x^2 + a_3x^3.....a_{60}x^{60} $$ 
Hence, as each term is divided by $x^{30}$, the number of distinct terms would be equal to 61. But my question is how do we know that the expansion of the polynomial $(1+x+x^3+x^4)^{15} $  will contain all powers of $x$ from $x^0$ to $x^{60}$ ?","['multinomial-coefficients', 'combinatorics']"
1174808,What is the purpose of finding the kernel of a matrix,Can someone help me understand why you would ever want to calculate the kernel of a matrix? I kept on trying to find applications when $\ker(A) = 0$ is useful but I could not find any. Can someone please show an example where it is important to calculate $\ker(A)$ and we could obtain some information from calculating the kernel?,"['matrices', 'linear-algebra', 'matrix-rank']"
1174814,Find the distribution of the random variable given probability generating function,"Let $X$ be a non-negative, integer valued random variable such that $\phi_X(t)=-\log(1-qt)$. Determine $P(X=k)$ where $k=0,1,2,...$. Now nothing is said about $q$, so maybe we can assume $q$ such that $|q|<\dfrac{1}{|t|}$. Now I proceeded as follows: $$\phi_X(t)=\sum_{k\geq0}t^kP(X=k)=-\log(1-qt)=\sum_{k\geq1}\dfrac{(qt)^k}{k}$$
  By comparing the coefficients of $t$ on both sides of this power series, $$P(X=0)=0$$$$P(X=k)=\dfrac{q^k}{k}$$ Now quite surprisingly, I do not get $\sum_{k\geq0}P(X=k)=1$. To get the probability (total) $1$, I should have $\sum\dfrac{q^k}{k}=1$. But LHS is $-\log(1-q)$. Hence we need to choose $q$ such that $-\log(1-q)=1\implies q=1-e^{-1}$. The answer matches i.e. the answer is $P(X=k)=\dfrac{(1-e^{-1})^k}{k}$ But what kind of a question is this? Should not $q$ have been mentioned earlier? It seems that it is true for ANY $q$ which is not. Only for $q=1-e^{-1}$ is this correct.","['probability-theory', 'probability-distributions', 'probability']"
1174830,How to determine continuity in higher dim,"$$f(x,y) = \frac{1-\cos{\sqrt{xy}}}{y}$$ $$f(x,0) = \frac{x}{2}$$ How do I prove this is continuous in the quadrant $x,y \ge 0 $? I can't find counterexamples (weak). I'm just starting working in higher dimensions and don't have a feel for the tricks here. Something about cosines always being continuous? Is there a rule in $\mathbb R^2$ like how polynomials in $\mathbb R$ are always continuous on their domain? What tricks should I instinctively be thinking of in a problem like this?","['multivariable-calculus', 'continuity', 'limits']"
1174845,Why does $-\sec^2(x) \cot^2(x) = -\csc^2(x)$?,"this is the first time I've asked a question here, so bare with me... I'm in Year 12 Maths B (kinda like Maths Extension) and, though we have not been told anything at all whatsoever about Cosecant, Secant and Cotangent, I got curious. Please excuse my comparatively limited knowledge of mathematics. So, I had to differentiate $\frac{1}{\tan(x)}$ into it's simplest form, and I have no source of answers to check with, so I used Wolfram|Alpha. It told me that the simplest form was $\csc^2(x)$ (by the way, sorry if I haven't yet discovered how to make maths look proper on this page) which got me confused.
After many research, I discovered that these other three trigonometric functions are the reciprocals of the major three. So, working through my problem, I got to this point: $$-\sec^2(x) \cot^2(x) = -\csc^2(x)$$ This is where my understanding fails. What processes exist between the two equations immediately above this text? Why does $$-\sec^2(x) \cot^2(x) = -\csc^2(x)$$ A detailed, step-by-step instruction on how/why this is what it is would really help me understand, and would be much appreciated.",['trigonometry']
1174873,"How to show $\int_0^{\infty} \frac{\sin(bx)\sin(x)}{x^2} \prod_{k=1}^n \cos^{p_k}(a_kx) \, \text{d} x= \frac{\pi}{2}$?","I have found the following complicated integral in Table of Integrals, Series and Products (page 469; No. 37); the interesting thing about this integral is that for arbitrary parameters $p_k,a_k>0$ and arbitrary natural number $n$ it has the value $\frac{\pi}{2}$: $$\int_0^{\infty} \frac{\sin(bx)\sin(x)}{x^2} \prod_{k=1}^n \cos^{p_k}(a_kx) \text{d} x= \frac{\pi}{2}$$ A large integral that has only one value when integrated over the interval $[0, \infty]$, but how I can prove this interesting fact? Series expansion in the trigonometric functions does not make sense, I think. Can I use induction for proving this identity? The previous link to a PDF of the book no longer works.","['definite-integrals', 'calculus', 'integration']"
1174892,Locally free sheaf generated by global sections and vanishing cohomology on curves,Let $C$ be a smooth projective curve. Let $\mathcal{F}$ be a locally free sheaf on $C$ satisfying $H^1(\mathcal{F})=0$. Is it then true that $\mathcal{F}$ is generated by global sections?,"['algebraic-geometry', 'sheaf-cohomology', 'algebraic-curves']"
1174894,Explanation for divergence of $\ln(x)$,"$\ln(x)$ diverges as $x \to \infty$, yet the differential $\frac{1}{x}$ tends to $0$ as $x \to \infty$. To the naive mind, it seems that if the differential tends to $0$ then the original function should asymptote and, therefore, converge. I appreciate that this is elementary, but an intuitive explanation would really help me.","['convergence-divergence', 'calculus', 'limits']"
1174939,Finding all real solutions to the equation $3^x+4^x=5^x$,"Find all real solutions to the equation $$3^x+4^x=5^x.$$ My attempt: It is evident that $x=2$ is a solution. However, I think that there are no other solutions. So, I define a function $f(x)=3^x+4^x-5^x$. Differentiating w.r.t $x$, we get $$f'(x)=3^x\ln 3+4^x\ln 4-5^x\ln 5,$$ but that doesn't take me anywhere. Please help. Thank you.","['calculus', 'derivatives']"
1174961,Rank as norm on matrix,"Could we consider matrix rank $r$ a norm? Is other norm similar to rank $r$ possible to associate with a finite matrix? (We denote trivial valuation $|\alpha|=1,\quad\forall\alpha\in\Bbb F^*$ where $\Bbb F$ is field/division algebra). It seems to satisfy norm axioms: $1$ $\mathsf{rank}(M)=0\iff M=0$. $2$ $\mathsf{rank}(\alpha M)=|\alpha|\mathsf{rank}(M)=\mathsf{rank}(M)$. $3$ $\mathsf{rank}(M+N)\leq \mathsf{rank}(M)+\mathsf{rank}(N)$.","['noncommutative-algebra', 'matrices', 'normed-spaces', 'linear-algebra', 'metric-spaces']"
1174980,Standard deviation of phase for a random phasor sum,"I have a phasor sum $a e^{j \theta} = \frac{1}{\sqrt{N}} \sum_{k=1}^{N} \alpha_k e^{j \phi_k }$ where $\phi_k = [-\pi, \pi]$, the standard deviation $\sigma_{\phi}$ of the phase is known and the mean of the phase is $\mu_\phi = 0$. What is the standard deviation of $\theta$?","['statistics', 'standard-deviation', 'exponential-sum']"
1174990,"If x and y are both greater than or equal to 1, show that $|\sqrt{x}-\sqrt{y}|$ is less than or equal to $0.5| x-y |$","If x and y are both greater than or equal to 1, show that $|\sqrt{x}-\sqrt{y}|$ is less than or equal to $0.5| x-y |$ Would really appreciate any help! Thanks","['radicals', 'inequality', 'analysis']"
1174994,Suggestions for a good statistics book and a calculus book?,"I am studying machine learning and I am very interested in going into depth. I feel without good knowledge of differential calculus and statistics, it is very difficult to have perfection. I want to know about very good books on statistics and calculus where topics goes from school level to engineering level. Any suggestion will be appreciated.","['multivariable-calculus', 'book-recommendation', 'calculus', 'statistics', 'reference-request']"
1175008,How to approach questions that ask to prove a function exists?,"Consider the functions $r:S\rightarrow Q$ and $h:S\rightarrow T$ for arbitrary sets $S,T$ and $Q$. Prove that: if
$$r(y)=r(x)\Rightarrow h(y)=h(x) $$ then we can find a function $g:Q\rightarrow T$ such that $$ h(y)=g(r(y))$$ I am not sure how to approach this kind of proofs. I am inclined to do the following: Assume there exists a function $g:Q\rightarrow T$ . Then $$r(x)=r(y)\Rightarrow g(r(x))=g(r(y))$$ The above does not look helpful in proving the conclusion. In fact, I don't even think that the first step is correct, since it looks like I am assuming the conclusion is true. I thought of starting by assuming that that $h(y)=g(r(y))$ is true but this also looks like I am assuming the conclusion is true. Please advise. I am aware that I need to show two things: $g$ is a function, which means for $q_1,q_2\in Q, q_1=q_2 \Rightarrow g(q_1)=g(q_2)$ $h(y)=g(r(y))$","['proof-writing', 'functions']"
1175024,Why row vectors in stochastic processes?,"It seems reasonable to state that column vectors $\mathbf{x}$ are the most frequently seen standard notation, often using $\mathbf{x}^\intercal$ to denote a row vector (transposed column vector). However, in the study of stochastic processes and probability theory, it appears more standard to use a row vector to represent a probability vector. Why is this? Maybe it simply just makes more sense to read left to right as forward in 'time':
$$\mathbf{x}_n=\mathbf{x}_0P_1P_2\cdots P_n$$
where $P_i$ is the matrix of transition probabilities from the $(i-1)^\text{th}$ to the $i^\text{th}$ step, $\mathbf{x}_0$ is the initial distribution (a row vector), and $\mathbf{x}_n$ is the distribution after $n$ transitions. Maybe this reasoning is somewhat ethnocentric $-$ if a particular language reads right to left, the opposite might be true. Is there any interesting history on this? Are there stories of 'battles' over standardizing the notation? Are there any other mathematical reasons for choosing row vectors over column vectors? Also, the transition probabilities in the matrix $P$ can be written $$p_{ij}=\mathbb{P}(\text{next state is $j$ }|\text{ current state is } i).$$ Note that the conditional probability notation is always 'backwards in time', unless you are asking a question about the past conditioned on knowledge of the future. Even then, it is still 'backwards in the mental timeline' $-$ if the left slot is for past knowledge, and the right is for what we want to know about in the future. I'm getting a bit off-topic from the real question at this point though.","['probability-theory', 'stochastic-processes', 'math-history', 'notation']"
1175041,Convergence of sequence given by $x_1=1$ and $x_{n+1}=x_n+\sqrt{x_n^2+1}$,"Be $(x_n)_n\ge 1 $  such that $x_1=1$ and $x_{n+1}=x_n+\sqrt{x_n^2+1}$ for every $n\ge 1$. Prove that the sequence $y_n=(2^n/x_n)_n \ge 1$ is convergent and find it s limit. Being positive and decreasing, $y_n$ is clearly convergent. But finding it's limit really put me intro trouble. Any help?
 Thank you!","['convergence-divergence', 'sequences-and-series', 'recurrence-relations']"
1175042,Evaluating $\int_0^{\infty} \frac{\sin x}{x} dx$ with Fubini theorem.,"I have to calculate $\int_0^{\infty} \frac{\sin x}{x} dx$ using Fubini theorem. I tried to find some integrals with property that $\int_x^{\infty} F(t) dt = \frac{1}{x}$, but I cant find anything else but $F(t) = -\frac{1}{x^2}$ and unfortunetely I can't use this. If I choose $F(t) = -\frac{1}{x}$, then I have: $\displaystyle \int_0^{\infty} \frac{\sin x}{x} dx = -\int_0^{\infty} \sin x \int_{x}^{\infty} \frac{1}{t^2} dt$, but I don't know what next","['multivariable-calculus', 'integration']"
1175045,Find $\lim_\limits{x\to 0}\left({\tan x\over x}\right)^{1\over 1-\cos x}$.,Find $\lim_\limits{x\to 0}\left({\tan x\over x}\right)^{1\over 1-\cos x}$. Is there a way to do it without differentiating so many times? That is exhausting and confusing and will probably cause errors. I would really appreciate your help with this.,"['calculus', 'real-analysis']"
1175068,Sum of resulting values of dice,"We have thrown with $n$ dice. The sum of resulting values is $k$. We are looking for a function $f$ which gives the number of throws, with we can construct $k$ with $n$ dice.
Some example for $f(n,k)$: $f(3,3)=1$ because only the $1+1+1$ produces $3$. $f(3,4)=3$ because $1+1+2$, $1+2+1$, $2+1+1$ are the only sums, which give $4$. Can anyone give me an explicit formula for $f$?","['dice', 'probability', 'functions']"
1175072,About a technique used in the proof of Hahn-Banach Theorem,"Recall Hahn-Banach (cf. Kreyszig's book) : If $X$ is a real
vector space with a sublinear functional $p$ and if
  $f$ is linear on a subspace $Z$ with $p(z)\geq f(z),\ z\in Z$,
  then there exists an extension $F$ of $f$ on $X$ s.t. $$
 \ p(x)\geq F(x),\ x\in X,\quad\rm{and}\tag{1} $$
$$F(z)=f(z),\ z\in Z.\tag{2}$$ Try and Question : In the proof there exists following
technique : For $y_1\in X-Z$, define $$ F(y+ay_1):=f(y)+ac $$ This is linear. So we must show (1). To do this, in the book we have
$$ f(y)-f(z)\leq p(y+y_1)+ p(-y_1-z) $$ for all $y,\ z\in Z$. This inequality and remaining part of the proof
 is computational. But I do not know how we consider such inequality ? I have a question : How do we make this inequality ? Subsequent argument implies that we must take linearity from a norm (Note that norm is sublinear). Is there more approachable proof ? So have $$ f(y)-p(y+y_1)\leq p(-y_1-z)+f(z) )$$
If sup of lefthand side is $m_0$ and inf of righthand side is $m$,
then we have $$ m_0 \leq c\leq m $$ That is, when we extend $f$, we must find suitable bounds $m_0,\
m_1$ : (1) $X=l^2,\ Z=(e_1)\oplus \cdots \oplus (e_{n-1})$ and $
f(x)=\frac{1}{\sqrt{n}}
                      \sum_{i=1}^{n-1} x_i$ Then we have extensions : $$
                      F_1(x) = \frac{1}{\sqrt{n}}
                      \sum_{i=1}^{n} x_i,\ F_2(x)=\frac{1}{\sqrt{n}}
                      \sum_{i=1}^{n-1} x_i$$ (2) $X=l^\infty,\ Z=(e_1)$ and $ f(x)=x_1$ Then we can have only one
extension $$ F(x)=x_1
$$ In these example, wrt $X$, we have bounds $m_0,\ m_1$. The book,
without detailed calculations or concrete example, gives a concise
proof. Can you explain how we consider the above inequality ? Thank
you.","['normed-spaces', 'functional-analysis', 'real-analysis', 'banach-spaces']"
1175076,How to prove Laplace distribution is scale mixture of Gaussians?? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question How does one prove the Laplace distribution is a scale mixture of Gaussians? I.e, how does one show that $X \sim \text{Laplace}(\lambda)$ is a scale mixture of Normal
$Y \sim N(0,\tau)$ and exponential $\tau \sim \text{Exp}(λ^2/2)$?","['statistics', 'bayesian', 'probability']"
1175109,Show that $F(x) = f(\|x\|)$ is differentiable on $\mathbb{R}^n$. [duplicate],"This question already has answers here : Multivariate differentiability verification (2 answers) Closed 9 years ago . Let an even function $f:\mathbb{R}\to\mathbb{R}$ which is even and differentiable. We define $F:\mathbb{R}^n\to\mathbb{R}$  as $F(x) = f(\|x\|)$. Show that $F(x)$ is differentiable on $\mathbb{R}^n$. My Work: Let $x_0\in\mathbb{R}^n$. If $x_0\ne 0$ then the partial derivatives of the norm are well-defined and:
$$ \frac{\partial \|.\|}{\partial x_i} = \frac{x_i}{\|x\|}$$
$\frac{x_i}{\|x\|}$ continuous and since $f$ is differentiable it's partial derivatives are continuous. So we can conclude that $\frac{\partial F}{\partial x_i}$ is continuous and therefore $F$ is differentiable. If $x_0=0$ then the $\|x_0\| = 0$ and since $f$ is even $f(0)=0$ and it must be an extremum point. Therefore, $F'(0)=0$. I'd like to get a critique of my work. Am I being right/rigorous? Thanks.","['multivariable-calculus', 'normed-spaces', 'calculus', 'derivatives']"
1175150,Prove multiplication in fields is commutative,This is Problem $16$ from Halmos' Linear Algebra Problem Book. The problem asks whether or not multiplication must be commutative in a field. The solution uses the distributive properties $a(b+c)=ab+ac$ and $(a+b)c=ac+bc$ with $(0+1)x$ and $x(0+1)$ to show that both $0x=x0=0$. From here it states that this implies that multiplication is both commutative and associative. I can't seem to grasp the underlying logic of this. How does this imply that $xy=yx$ for every $x$ and $y$ in the field? Thanks for any help! -Tusike,"['abstract-algebra', 'field-theory']"
1175272,Changing order of integration in a double integral,"The question was to sketch the region of integration and change the order of integration.
$$\int^{3}_{0} \int^{\sqrt{9-y}}_{0} f(x,y) dxdy$$ When I sketch the region of integration I do not see a way that it is possible to change the order of integration. 
My region is bounded by, $y=3$, $y=0$, $x=0$ and $x=\sqrt{9-y}$.
Any insight would help, if there is a way to do this then I guess I have it sketched wrong.
My image is below of what I drew","['multivariable-calculus', 'integration']"
1175277,Why Isn't the $ {L}_{2} $ Norm Differentiable at $ x = 0 $?,Why doesn't the $L_2$ norm differentiable at $x=0$? Let's define $N(x)$ as the norm function. I know that for every $x\ne 0$: $$\frac{\partial N}{\partial x_i}(x) = \frac{x_i}{\|x\|}$$ What happens at the origin? I'd be glad to get an explanation involving minimal linear algebra :) Thanks in advance.,"['multivariable-calculus', 'calculus', 'normed-spaces', 'linear-algebra', 'derivatives']"
1175288,Solving a question by using special products (Students debate to Teacher),"So today,we got back our exam papers,and we found a question marked wrongly and teacher said that it is wrong.We all students do NOT believe this.So here is what happened. Before reading the next part,this is what we ONLY know (learnt) about rules of special products. (Under school secondary 2 learning in Singapore) Rule $1$: $a^2+2ab+b^2=(a+b)^2$ Rule $2$ :$a^2-2ab+b^2=(a-b)^2$ Rule $3$: $a^2-b^2=(a+b)(a-b)$ From the exam paper: Evaluate $10.2^2-9.8^2$ by using ONLY rules of special products. Correct solution: $(10.2+9.8)(10.2-9.8)=(20)(0.4)=8$ (Rule $3$) Student wrong (Marked as wrong) alternate solution: \begin{align*} (10+0.2)^2-(10-0.2)^2 &=[10^2+2(10)(0.2)+0.2^2]-[10^2-2(10)(0.2)+0.2^2]\\&=100+4+0.04-(100-4+0.04)\\&=104.04-96.04\\&=8\end{align*}(Rules $1$ and $2$) The question did NOT ask for the easiest and fastest way (and both solution uses ONLY rules of special products) to solve but yet why is student solution wrong? Teacher told us,""Aiya, why need to do so complicated one?"" yet she did not answer why is the answer wrong. I debated to her so long but to no avail. Can anybody think of why the student solution is wrong?","['algebra-precalculus', 'products', 'soft-question']"
1175297,Is antisymmetric the same as reflexive? [duplicate],"This question already has answers here : Whats the difference between Antisymmetric and reflexive? (Set Theory/Discrete math) (3 answers) Closed 7 years ago . Note: The following definitions from my book, Discrete Mathematics and Its Applications [7th ed, 598]. This is my book's definition for a reflexive relation This is my book's definition for a anti symmetric relation Is a reflexive relation just the same as a anti symmetric relation?  From what I've, the only way to meet that antisymmetric requirement is to have the same ordered pair, say an element a from Set A, (a,a). If you have anything other than the same ordered pair, (1,2) and (2,1), it will not meet the antisymmetric requirement. But the overall definition of reflexive relation is that it's the same ordered pair. Are they just two ways of saying the same thing? Is it possible to have one and not the other?","['discrete-mathematics', 'logic', 'equivalence-relations', 'elementary-set-theory', 'relations']"
1175348,What does the binomial theorem applied to integers count?,"I have a homework problem that I'm stuck on, but I feel like if I could get help on this one component (not the whole problem) I could make progress. Also, I'll note preemptively that I tried searching for this, but I really couldn't find anything so if this is a duplicate I apologize in advance. The problem asks: Evaluate $\sum_{k=0}^n {n \choose k} a^{n-k} (-b)^k$ for $a \geq b > 0$ using an involution. To save some searching, an involution is a function $I$ on $X$ such that $I \circ I = id_X$. My actual question is, what does $\sum_{k=0}^n {n \choose k} a^{n-k} b^k$ count? That is, what does the binomial theorem count when evaluated for positive integers $a,b$? My intuition is that if I understood this I might be able to define an involution that I can use. It's worth noting that the answer is easy if you just apply the binomial theorem with $x = a, y = -b$, but using an involution is the key component of the problem.",['combinatorics']
1175354,Stochastic matrices with orthogonal eigenvectors,"I stumbled across an odd fact while thinking about Markov chains, and I have an odd proof for it. Claim: Let $P$ be the transition matrix of a finite irreducible aperiodic Markov chain, and assume that $P$'s left eigenvectors are orthogonal. Then $P$ is doubly stochastic. Is this a special case of some well known result? In any case, here's my proof. Proof: Let $n$ denote the number of states. Since $P$ is the transition matrix of a finite irreducible aperiodic Markov chain, there is a unique stationary distribution $\pi$ and for any initial distribution $\mu$ there holds $\mu P^t \rightarrow \pi$ when $t \rightarrow \infty$.
Let $\mu$ be an arbitrary distribution, let $t \geq 0$, and consider the inner product $\langle \mu P^t,\pi \rangle$. Let $\{v_i\}$ be an orthonormal basis of left eigenvectors for $P$ whose corresponding eigenvalues are $\{\lambda_i\}$ with $v_1 = \pi/\|\pi\|_2$ and $\lambda_1 = 1$, and write $\mu = \sum_{i=1}^n{\alpha_i v_i}$. Then 
$$
\langle \mu P^t,\pi \rangle = \langle \sum_{i=1}^n{\alpha_i v_i P^t},\pi \rangle = \sum_{i=1}^n{\alpha_i \lambda_i^t \langle v_i,\pi\rangle} = \alpha_1 \langle v_1,\pi \rangle = \alpha_1 \|\pi\|_2.
$$ So $(\langle \mu P^t,\pi \rangle)_{t=0}^{\infty}$ is a contant series. On the other hand, $\mu P^t \rightarrow \pi$ so $\langle \mu P^t,\pi \rangle \rightarrow \langle \pi,\pi \rangle$. Now, if a constant series converges to a value, then all of the elements of the series are equal to the value. Therefore $\langle \mu,\pi \rangle=\langle \pi,\pi \rangle$. This holds for any distribution $\mu$. In particular consider indicator vectors $e_i$: We have that for any $i,j \in [n]$, 
$$
\langle e_i,\pi\rangle = \langle \pi,\pi\rangle=\langle e_j,\pi\rangle \Rightarrow \pi_i = \pi_j.
$$
So $\pi$ is uniform. Thus, $\bar{1}\cdot P = \bar{1}$, so $P$'s columns all sum to 1 and $P$ is doubly stochastic. $\square$ This is a very strange proof - I've never seen a proof that shows that two values are equal because the first belongs to a constant series that converges to the second value. Can anyone think of a direct, simple proof for this claim? Is this claim a special case of some well known result in linear algebra?","['markov-chains', 'linear-algebra']"
1175357,Bounded second derivative implies square root of f is Lipschitz.,"Can you help me with this exercise? Let $f \in C^2(\mathbb{R}) $ a function $ f(x) > 0, \forall x \in \mathbb{R} $ and $\|f''\|_\infty < \infty $  , prove that $\sqrt f$ is Lipschitz continuous. My attempt: i tried assuming that $f'' \ge 0$ , then $f'$ is increasing  and the following limits exist: $$ \lim_{x \to +\infty} f'(x) , \lim_{x \to +\infty} f(x)$$ then i can calculate using L'Hôpital's rule ( $f(x)$ is definitely increasing or decreasing):
$$ L=\lim_{x \to +\infty} |(\sqrt f(x))'| =  \lim_{x \to +\infty} |\frac{f'(x)}{2\sqrt f}| = \lim_{x \to +\infty} |\frac{f''(x)\sqrt f}{f'(x)}| \leq  \frac{\|f''\|_\infty}{2L}$$ and so L must be finite, similar with $-\infty$ limit, so $(\sqrt f(x))'$ is bounded.
However I'm not sure that $\lim_{x \to +\infty}|\frac{f''(x)\sqrt f}{f'(x)}|$ always exists.
Anyway I can't solve the other cases.","['lipschitz-functions', 'real-analysis', 'analysis']"
1175389,is this manifold diffeomorphic to the klein bottle?,"Consider the submanifold of $\mathbb{R}^4$ given for the equations $$x_1+x_2x_3x_4 = 0$$ $$x_2 + \sin(x_3x_4)^2 = 0$$ is this $2$-dimensional manifold diffeomorphic to the klein bottle?.
I first tried to see if it is orientable, but  I do not even know how to proceed.","['smooth-manifolds', 'differential-geometry']"
1175390,prove inequality by induction -- Discrete math,"Prove by induction that $∀n ≥ 3$ : $n^{2} + 1 ≥ 3n$ So I know I need to find my base case , would it be:
$n=3$ Then calculate the RHS and LSH RHS:$3(3)=9$ LHs: $3^{2} + 1= 10$ we see that the LHS is greater than or equal to the RHS. Now for the inductive step : Assume that the formula is true for an arbitrary $∀n ≥ 3$
We now have to prove $n^{2} + 1 ≥ 3n$ This is where I get stuck, how can I prove this? Edit : showing that the assumption applies to  $(n+1)^2+1≥3(n+1)$","['induction', 'discrete-mathematics']"
1175405,"Find the next term in the sequence. $\frac{7}{3},\frac{35}{6},\frac{121}{12},\frac{335}{36},\ldots $","$\dfrac{7}{3},\dfrac{35}{6},\dfrac{121}{12},\dfrac{335}{36},\ldots $ $\bf\text{Answer}$ given is $\dfrac{865}{48}$ I found that $4^{th}$ differencess of the numbers $7,35,121,335\cdots$ are not constant . and the second differences of the denominator drastically changes, $3\quad 6\quad 12\quad 36\quad 48\\~\\
\quad 3\quad 6\quad 24\quad \color{red}{12}$ decimal value is also not showing any pattern. $\frac{7}{3},\ \frac{35}{6},\ \frac{121}{12},\ \frac{335}{36},\ldots $ $2.33,\ 5.83,\ 10.08,\ 9.33,\ldots $","['puzzle', 'sequences-and-series']"
1175437,"Closed-form of $\int_0^{\pi/2} \arctan(x)\cot(x)\,dx$","I'm looking for a closed-form of the following integral problem. $$I = \int_0^{\pi/2} \arctan(x)\cot(x)\,dx.$$ The numerical approximation of $I$ is $$I \approx 0.96644524676637380447182915131032699868606574138656587245691342\dots$$ I've found nothing with Maple or Mathematica .","['definite-integrals', 'closed-form', 'calculus']"
1175477,Prove that the second derivative is positive iff the function is convex.,"Well, I want to prove the following: Let $f:(a,b)\to\mathbb R$ be double differentiable then $f$ is convex iff $\;\;f''(x)>0$ for all $x\in (a,b)$. Then I tried te following: $\Rightarrow]$ Lets suppose that $f:(a,b)\to\mathbb R$  is convex then if we define $h=-y+x$
we have that: $$ f(x+h) \leq (1-t)f(x)+tf(x+h)$$ $$0 \leq (1-t)f(x)+tf(x+h)-f(x+h)$$ I was expecting to have something of this form $$0 \leq f(x+h)-2f(x)+f(x-h)$$ and then take limit and have the result, I don't know how to define $h$ to have the above relation, Can someone help me ? $\Leftarrow]$ I checked this, but I don't know if it is right, If it is not Can you help me to fix the mistakes please: Second derivative positive $\implies$ convex Thanks a lot in advance","['multivariable-calculus', 'proof-writing', 'proof-verification', 'analysis']"
1175482,Prove that volume of a sphere with radius $r$ is $V=\frac43r^3\pi$,"Prove that volume of a sphere with radius $r$ is $V=\frac43r^3\pi$. I know to prove this in following way: If I rotate graph of the function $y=\sqrt{r^2-x^2}$ around $x$-axis, it will result a sphere with radius $r$. So, it can be computed as
$$V=\int_{-r}^ry^2\pi dx=\int_{-r}^r(r^2-x^2)\pi dx=\frac43r^3\pi$$
My question is: can we prove it without rotating anything? Can we just integrate a formula for sphere? From formula I get
$$
x^2+y^2+z^2=r^2\\
z=\pm\sqrt{r^2-x^2-y^2}
$$
Can we get a volume as
$$2\int_{-r}^r\int_{-r}^r\sqrt{r^2-x^2-y^2}\,dx\,dy$$
I tried to integrate this, but it looks very complicated.","['spheres', 'integration']"
1175509,Outer automorphisms of the infinite symmetric group,"Denote by S$_\infty$ the group of permutations of $\mathbb N$. Question: Does there exist an outer automorphism of S$_\infty$, and if so, can one be exhibited? Does this depend on the continuum hypothesis? Motivation: I'm trying to see whether the group of finitary permutations is characteristic in S$_\infty$.","['permutations', 'group-theory', 'axiom-of-choice']"
1175522,"confidence intervals for 20 different parameters - distribution, probabilit and most probable value.","I need help with the subexercise (c) in the following exercise. A researcher is planning a study where she must calculate confidence
  intervals for 20 different parameters. The intervals are independent of
  each other and all have 95% confidence . Let N be the number of
  intervals that is containing it's parameter. ( a) Wat is the distribution of N ? ( b) What is the probability that all
  the intervals that is containing its parameter? ( c ) What is the most probable value of N
  ? Solution : (a): $N$~$bin(20,1-α)=bin(20,0.95)$. I did get this by just using the definition/prove of binomial distribution. n=20 because we have 20 parameters which gives us 20 intervals. (b): using probability function for binomial distribution with k=20. my question is if following is right (c): The most probable value of N is the espected value of N, i.e $E(N)=np=20*0.95=19$. Hence the most proabable value is $N=19$","['statistics', 'descriptive-statistics', 'probability', 'statistical-inference']"
1175553,In how many ways can 10 identical laptops be distributed among five electronic stores,"In how many ways can 10 identical laptops be distributed among five electronic stores if there are no restrictions? each store gets at least one? the largest store gets at least three? each store gets at least two? Would I used the r-combination with repetition for part 1?
so for part 1 you do$\binom{14}{10}$ I am learning r-combination and r-permutation and now I keep getting confused when given a problem","['discrete-mathematics', 'combinatorics']"
1175555,"If $T^2=T$ then determine whether $\ker T=\operatorname{Range}\,(T)^\perp$.","Let $T$ be linear operator on a finite dimensional inner product space $V$ such that $T^2=T$. Determine whether $\ker T=\operatorname{Range}\,(T)^\perp$. I have proved that $\ker T=\operatorname{Range}\,(T)^\perp$ under the assumption that $T$ is Hermitian. I guessed that the answer is yes but still in trouble to make it. I also want to know whether $T^2=T$ on $V$ will imply that $T$ is Hermitian.","['orthogonality', 'inner-products', 'functional-analysis']"
1175572,"What is meant by ""A and B represent the same functor whence are isomorphic"" in this solution?","While browsing some old questions I came across the following: tensor product of sheaves commutes with inverse image It seemed like something interesting was going on in the answer, but I don't quite understand it.  I understand the calculation on Hom sets, but I don't understand what is meant by: ""So $f^*\mathcal{M} \otimes_{\mathcal{O}_X} f^*\mathcal{N}$ and $f^*(\mathcal{M} \otimes_{\mathcal{O}_Y} \mathcal{N})$ represent the same functor, whence they are canonically isomorphic."" Can someone give a general statement of the fact being used here?  I think this might have something to do with the Yoneda lemma, but unfortunately, I have never really been able to understand the Yoneda lemma very well.  At some point I verified that the Yoneda lemma was indeed true, but my understanding was poor so it didn't really stick.","['category-theory', 'sheaf-theory', 'algebraic-geometry']"
1175697,Compute Power Series Convergence to a function,"Consider the next power series
  $$
\sum_{n=1}^{\infty} \ln (n) z^n
$$
  Find the convergence radius and a the function $f$ to which the series converges. I have easily found that $R=1$ is the convergence radius, however I can not find the function. I was trying to found an elemental function with this power series expantion, but I have failed. Anyone knows such function and how to prove the convergence?","['power-series', 'logarithms', 'convergence-divergence', 'complex-analysis']"
1175701,Rigorous books on geometry,"I am looking for a rigorous book on both 2d and 3d euclidean geometry, and also how analytic geometry can be developed from synthetic geometry. I haven't really found such a book yet. I would be very glad if someone could reference such a book.","['geometry', 'book-recommendation', 'analytic-geometry', 'reference-request', 'euclidean-geometry']"
1175738,When is $20q^4-40q^3+30q^2-10q$ a square for positive integer $q$?,"For what $q$ is the following polynomial a square?
  $$
\begin{align}
&20q^4-40q^3+30q^2-10q\\
=\:&10q(q - 1)(2q^2 - 2q + 1)
&q\in\mathbb N
\end{align}
$$ I know of two single cases, $q=1$ gives $0$ and $q = 2$ gives $100$. I tested $3\le q\le12$ and found none. This is what I've tried so far: I found that
$$
\begin{align}
\gcd(q,q - 1) &= 1\\
\gcd(q, 2q^2 - 2q + 1) &= 1\\
\gcd(q - 1, 2q^2 - 2q + 1) &= 1
\end{align}
$$
The problem is the same as determining whether there exists a $t\in\mathbb N$ such that
$$
q(q - 1)(2q^2 - 2q + 1) = 10t^2
$$
If $q$ is even, write $q=2p$ and say
$$
p(2p-1)(8p^2-4p+1) = 5t^2
$$
The residues modulo $5$ are as follows
$$
\begin{align}
p\equiv0\pmod{5}\implies p(2p-1)(8p^2-4p+1)\equiv0\pmod{5}\\
p\equiv1\pmod{5}\implies p(2p-1)(8p^2-4p+1)\equiv0\pmod{5}\\
p\equiv2\pmod{5}\implies p(2p-1)(8p^2-4p+1)\equiv0\pmod{5}\\
p\equiv3\pmod{5}\implies p(2p-1)(8p^2-4p+1)\equiv0\pmod{5}\\
p\equiv4\pmod{5}\implies p(2p-1)(8p^2-4p+1)\equiv4\pmod{5}
\end{align}
$$
Which means that $p\not\equiv4\pmod5$, and we now need to test if it's a square in the rest of the cases. Case r = 5p In this case we are solving $r\cdot(10r - 1)(200r^2 - 20r + 1) = t^2$ and since the factors are coprime, they must all be squares, however modulo $7$ atleast one factor is not one of the quadratic residues for all cases. Case r = 5p + 1 In this case we are solving $(5r+1)(10r+1)(40r^2+12 r+1) = t^2$ and since the factors are coprime, they must all be squares, however modulo $3$ atleast one factor is not one of the quadratic residues for cases $1$ and $2$, and the last case $0$ we have an observed solution at $q=2$, however for $q=12$ we don't get a square, so it remains to prove whether there are other than $r=0$ which are square. At this point I stopped because there are many cases, and I don't know how to prove that it is only for $r=0$ when $r=5p+1$ that the polynomial is square, or if there are other such $r$. So the thing I'm asking specifically is: Is there a more elegant way, and if not, how do I prove that the observed cases are the only solutions (or if not, what is the set of solutions).","['modular-arithmetic', 'polynomials', 'square-numbers', 'number-theory']"
1175748,How many distinct factors of $n$ are less than $x$?,"For some (squarefree) integer $n$ and some integer $x$, I would like to find an expression that gives, for all $n$ and $x$, a good upper bound on the function $$f(n, x) = \sum_{d|n, d < x} 1$$ which counts the number of distinct factors of $n$ that are less than $x$. For example, taking $n = 30$ and $x = 11$, this function has a value of 6: (there are 6 distinct divisors of 30 that are less than 11: 1, 2, 3, 5, 6 and 10). Is there anything related to this in the literature? Any help or suggestions would be appreciated. One thing I notice: if $p$ is a prime and $p > x$ then $f(np, x) = f(n, x)$ (since no factors of $pn$ less than $x$ have $p$ as a divisor). So only integers $n$ all of whose prime factors are less than $x$ need be considered.","['elementary-number-theory', 'number-theory']"
1175758,Euler's method - Order of accuracy,"Theorem Let $f \in C([a,b] \times \mathbb{R})$ a function that satisfies the Lipschitz condition and let $y \in C^2[a,b]$ the solution of the ODE $\left\{\begin{matrix}
y'=f(t,y(t)) &, a \leq t \leq b \\ 
y(a)=y_0 & 
\end{matrix}\right.$. If $y^0, y^1, \dots, y^N$ are the approximations of Euler's method for uniform partition of $[a,b]$ with step $h=\frac{b-a}{N}$ then $$\max_{0 \leq n \leq N} |y(t^n)-y^n| \leq \frac{M}{2L} (e^{L(b-a)}-1)h$$ where $M=\max_{a \leq t \leq b} |y''(t)|$. From the above theorem, we conclude that the order of accuracy of Euler's method is at least $1$. We will show that the order of accuracy of Euler's method is exactly $1$. We consider the following ODE: $\left\{\begin{matrix}
y'=2t &, 0 \leq t \leq 1 \\ 
y(0)=0 & 
\end{matrix}\right.$ Its only solution is $y(t)=t^2,\ \  0 \leq t \leq 1$. Let $N \in \mathbb{N}, \ h=\frac{1}{N}, \ \ t^n=nh, \ n=0,1, \dots, N$ $$y^{n+1}=y^n+hf(t^n, y^n) \Rightarrow y^{n+1}=y^n+h2t^n=y^n+h2nh=y^n+2nh^2$$ $$y^0=y(0)=0$$ $$y^1=y^0+2 \cdot 0 \cdot h^2=0$$ $$y^2=y^1+2h^2=2h^2$$ $$y^3=y^2+2 \cdot 2 \cdot h^2=2h^2+4h^2=2h^2(1+2)$$ $$y^4=y^3+2 \cdot 3 \cdot h^2=2h^2(1+2)+ 2 \cdot 3 \cdot  h^2=2h^2(1+2+3)$$ $$\dots \dots$$ $$y^n=2h^2 \sum_{i=1}^{n-1} i=2h^2 \frac{(n-1)n}{2}=n(n-1)h^2$$ For $n=N$: $y^N=N(N-1)h^2=(Nh-h) Nh=1-h$ $|y(t^N)-y^N|=|1-1+h|=h$ Theorefore, we conclude that the order of accuracy is exactly $1$. According to the theorem: $$\max_{0 \leq n \leq N} |y(t^n)-y^n| \leq \frac{M}{2L} (e^{L(b-a)}-1)h$$ So, why do we conclude that  the order of accuracy of Euler's method is at least $1$ and not at most $1$? Also,  we take into consideration that the order of accuracy of the method is at least $1$ and then we take an example of an ODE and see that the order of accuracy is exactly $1$. 
Why do we conclude in this way something for the general case? How do we  deduce that for each ODE the same  holds?","['ordinary-differential-equations', 'numerical-methods']"
1175768,what is the proof for matrix multiplication being commutative,"I understand that if we have matrix $A$ and $B$
then $A \cdot B \neq B \cdot A$ 
as when you multiply the matrices in a different order, then their cells will shift in another form, thus making their multiplication equate differently in their product matrix. but what is valid proof i can give to illustrate this All help is much appreciated","['discrete-mathematics', 'matrices', 'matrix-calculus', 'math-software', 'matrix-equations']"
1175814,Showing a simple function is continuous on a restricted domain,"Motivation: I am studying for an exam over Chapters $1-3$ of Real Analysis by Royden and Fitzpatrick, 4th edition. I am stuck on understanding some of Proposition $11$, which I have reproduced below: Proposition 11: Let $f$ be a simple function defined on a set $E$ of finite measure. Then for each $\varepsilon>0$, there is a continuous function $g$ on $\mathbb{R}$ and a closed set $F$ contained in $E$ for which $f=g$ on $F$ and $m(E-F)<\varepsilon.$ Proof: Let $a_1,a_2,\ldots, a_n$ be the finite number of distinct values taken by $f$, and let them be taken on the sets $E_1, E_2, \ldots, E_n,$ respectively. The collection $\{E_k\}_{k=1}^{n}$ is disjoint since the $a_k$'s are distinct. According to Theorem $11$ of Chapter $2$, we may choose closed sets $F_1, F_2, \ldots, F_n$ such that for each index $k, 1\leq k \leq n,$ $F_k \subseteq E_k$ and $m(E_k-F_k)<\varepsilon/n.$ Define $g$ on $F$ to take the value $a_k$ on $F_k$ for $1 \leq k \leq n.$ Since the collection $\{F_k\}_{k=1}^{n}$ is disjoint, $g$ is properly defined. Moreover, $g$ is continuous on $F$ since for a point $x \in F_i,$
  there is an open interval containing $x$ which is disjoint from the closed set $\cup_{k \neq i} F_k$ and  hence on the intersection of this interval with $F$ the function $g$
  is constant. But $g$ can be extended from a continuous function on the closed set $F$ to a continuous function on all of $\mathbb{R}.$ The continuous function $g$ on $\mathbb{R}$ has the required approximation properties. Question: Please explain rigorously why the ""grey"" area is true?","['measure-theory', 'proof-verification', 'real-analysis']"
1175845,Critical numbers of the function: $x\sqrt{5-x}$,"Let f(x) = $$\displaystyle f(x) = x\sqrt{5-x} $$ On the interval: [-6,4] Critical numbers are the the values of x in the domain of f for which f'(x) = 0 or f'(x) is undefined. Derivative of the function:
$$ \frac{1}{2} \cdot x (5-x)^{\frac{-1}{2}} \cdot -1$$ $$ \frac {\frac{-x}{2}}{\sqrt{5-x}}$$ $f'(x) = 0$, when $x = 0, $ and is undefined when x= 5 Plugging in the roots of the derivative function and the end points of the interval into the original function:
\begin{align*}
f(0) & = 0\\
f(5) & = 0\\
f(-6) & = -6\sqrt{11}\\
f(4) & = 4 \cdot 1 = 4
\end{align*} So why is the 4 not the absolute maximum value? p.s. I assumed the first term goes to zero when taking a derivative by the product rule. I confused d/dx x = 1, with any number d/dd = 0","['calculus', 'derivatives']"
