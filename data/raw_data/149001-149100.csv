question_id,title,body,tags
2463416,Dual of a torsion sheaf is zero,"Let $X$ be an integral scheme and $Z \subset X$ a closed subscheme. Suppose $F$ is a coherent sheaf on $X$ s.t. $\operatorname{supp}(F)=Z$. Is it true that sheaf hom $\mathcal{Hom}_X(F, \mathcal{O}_X) = 0$? This is my attempt to prove this. We can show that $\mathcal{Hom}_X(F, \mathcal{O}_X) = 0$ locally: let $U=\operatorname{Spec}(R) \subset X$ be open affine subset, then $F|_U \cong \tilde{M}$ for some finite $R$-module $M$. Then 
$$
\operatorname{Ass}(\operatorname{Hom}_R(M,R))=\operatorname{Ass}(R) \cap \operatorname{supp}(M),
$$
but $\operatorname{Ass}(R) = \{ (0)\}$ and $M_{(0)}\cong M \otimes Q(R) =0$, thus $\operatorname{Ass}(\operatorname{Hom}_R(M,R)) = \emptyset$ i.e. $\operatorname{Hom}_R(M,R)=0$. This is true for any open affine, so $\mathcal{Hom}_X(F, \mathcal{O}_X) = 0$. It looks like essentially the same argument shows that the dual of a torsion sheaf is zero on any integral scheme. Is this correct?","['reference-request', 'algebraic-geometry', 'proof-verification']"
2463420,Every complete regular surface is closed?,"Problem. I'm working on an exercise from a book in basic Gaussian geometry, and as a part of my solution, I would like to make the following claim: Proposition. If $M\subseteq\mathbb{R}^3$ is a complete regular surface, $M$ is a closed subset of $\mathbb{R}^3$. given the following definition of completeness: Definition. A regular surface $M\subseteq\mathbb{R}^3$ is said to be complete if for every point $p\in M$ and every tangent vector $Z\in T_pM$, there exists a geodesic $\gamma\colon\mathbb{R}\to M$ defined on all of $\mathbb{R}$ such that $\gamma (0)=p$ and $\gamma'(0)=Z$. I have tried mainly two ways of proving it: Idea 1. What seems most natural to me is to do this by contradiction, and to use the limit point characterization of closed sets in metric spaces. I thus let $M\subseteq \mathbb{R}^3$ be a complete regular surface, and suppose that $M$ is not closed. This means there exists a convergent sequence $(p_n)_{n=1}^\infty$ in $\mathbb{R}^3$ with limit $q$, such that $p_n\in M$ for all $n\in\mathbb{Z}^+$ and $q\in\mathbb{R}^3\setminus M$. The way I picture this intuitively, is that the surface $M$ is punctured at $q$ or have something like an ""edge "" at $q$. Since there are $p_n$'s arbitrarily close to $q$, it feels like we should be able to find a $p_n$ and a $Z\in T_{p_n}M$, such that the geodesic $\gamma\colon \mathbb{R}\to M$, 
with $\gamma (0)=p_n$ and $\gamma'(0)=Z$, would have to pass through $q$, thus giving us the desired contradiction. I don't see any obvious ways to turn this into a formal argument though, and my gut feeling can very well be wrong. Idea 2. I have also looked a bit at the Hopf-Rinow theorem from Riemannian geometry, which seems to say that a Riemannian manifold $(M, g)$ being geodesically complete implies that $(M,\tilde{d})$ is complete as a metric space, where $\tilde{d}$ is the intrinsic metric. If something similar holds for regular surfaces in $\mathbb{R}^3$, I think we would be done (no!), because $\tilde{d}$ dominates the standard metric $d$ in $\mathbb{R}^3$ restricted to $M$. This means that if $\rlap{\rule[0.5ex]{2.5em}{0.2ex}}(M,\tilde{d})$ is complete, so is $\rlap{\rule[0.5ex]{3.5em}{0.2ex}}(M,d_{|M})$ (this is wrong, see my comment below!). Since $(\mathbb{R}^3,d)$ is complete, $(M,d_{|M})$ being complete implies that $M$ is closed by elementary point-set topology . However, my spontanious idea of how do show that geodesically complete implies complete as a metric space would be very similar to Idea 1 (I would seek a contradiction by supposing that we have a Cauchy sequence in $M$ that doesn't converge), so this doesn't seem to take me any further either. Question. Am I at all on the right track here, or would you recommend some other approach? Is the proposition I'm trying to prove even correct in the first place?","['differential-geometry', 'geodesic']"
2463442,Normal bundles and vector bundles,"Let $Y$ be a smooth manifold, and let $\pi:E\to Y$ be a smooth vector bundle over $Y$. Suppose that $X$ is an immersed submanifold of $Y$, which lies in $E$ as the zero set of some smooth section $s:Y\to E$. I am trying to show that $E|_X$ is isomorphic to the normal bundle of $X$ in $Y$ (defined as the quotient bundle $TY|_X/TX$). I proceed as follows. Let $x\in X$ and $z:Y\to E$ be the zero section. The map $\phi_x:E_x\to T_{z(x)}E,v\mapsto\dot\gamma_v(0)$ (where $\gamma_v(t)=(x,tv)$ is injective and $im(\phi_x)=\ker(d\pi_{z(x)})$, so $0\to E_x\to T_{z(x)}E\to T_xY$ is an exact sequence, which splits since $d\pi_{z(x)}\circ ds_x=id_{T_xY}$. Now the map
\begin{aligned}
\psi_x:T_{z(x)}E&\to E_x\oplus T_xY \\
w&\mapsto(\tilde\phi^{-1}_x(w-dz_x(d\pi_{z(x)}(w))),d\pi_{z(x)}(w))
\end{aligned}
is an iso, where $\tilde\phi_x$ is the map $\phi_x$ with codomain restricted to $\ker(d\pi_{z(x)}$. Hence we get map $F:=p_1\circ\psi_x\circ ds_x$, where $p_1:E_x\oplus T_xY\to E_x$ is the projection. This map should clearly become my isomorphism, and I have two concrete questions about it. Unraveling the definitions we see that $v\in T_xY$ is in $\ker(p_1\circ\psi_x\circ ds_X)$ if and only if $dz_x(v)=ds_x(v)$, and from here I want to conclude that this implies that $\ker F=T_xX$, but I'm not quite sure how. The inclusion $T_xX\subset\ker F$ is clear since $z|_X=s|_X\implies dz_x|_{T_xX}=ds_X|_{T_xX}$, but I'm not sure how $dz_x(v)=ds_x(v)$ implies that $v\in T_xX$. We do know that $z|_{X\setminus Y}\neq s|_{X\setminus Y}$, but I am not sure that that implies that $dz_x(v)\neq dz_x(v)$ if $v\in T_xY\setminus T_xX$. Secondly, I need this map to be surjective, but I have no idea how this follows. Any help or tips or references are greatly appreciated! Edit I think that the surjectivity question can be rephrased: since $z(x)=s(x)$ it holds that $d\pi_{z(x)}\circ ds_x=id_{T_xY}$, so the surjectivity of $p_1\circ\psi_x\circ ds_x$ is equivalent to the surjectivity of $\tilde\phi^{-1}_x(ds_x-dz_x)$, i.e. if each $v\in E_x$ can be written as $\tilde\phi^{-1}(ds_x(u)-dz_x(u))$ for some $u\in T_xY$.","['tangent-bundle', 'vector-bundles', 'differential-geometry']"
2463469,Why the covariant derivative does not depend of the parametrization?,"I'm studying Differential Geometry using the book ""Diferential Geometry of Curves and Surfaces - Manfredo P. do Carmo"", and he defines covariant derivative as: Let $S \subset \mathbb{R}^3$ a surface, $p \in S$ and $\omega:S \rightarrow \bigcup\limits_{p \in S} T_p S$ a field, such that $$\omega(p) \in T_pS, \hspace{0.1cm} \mbox{for all $p$ $\in S$}. $$ Consider a parametrization $\sigma : U\subset \mathbb{R}^2 \rightarrow V \cap S$, with $\sigma(q) = p$, and a curve  $\alpha(t) := \sigma(u(t),v(t))$, satisfying
$$\alpha(0) = p $$
$$\alpha'(0) = u'(0) \frac{\partial\sigma}{\partial u}(q) +v'(0) \frac{\partial\sigma}{\partial u} (q) =   y \in T_pS. $$ Using the symbols above, we can write the $\omega$ field as follows $$\omega(\sigma(u,v)) = a(u,v) \frac{\partial\sigma}{\partial u} (u,v) + b(u,v)\frac{\partial\sigma}{\partial v}(u,v), $$
where $b, a: U \rightarrow \mathbb{R}$ $\in \mathcal{C}^{\infty} (U,\mathbb{R}) $ So, we define the covariant derivative of $\omega$ in the diretion $y$ ($D_y 
\omega (p)$) as: $$D_y 
\omega (p) = \pi_{T_pS}\circ \left(\left.\frac{d \omega(\alpha(t))}{dt}\right\rvert_{t=0} \right)$$
$=\left((a\circ\sigma^{-1} \circ \alpha)'(0) + \Gamma_{11}^1(q) a(q) u'(0) + \Gamma_{12}^1 (q) a(q) v'(0) + \Gamma_{12}^{1}(q) b(q) u'(0) + \Gamma_{22}^1(q) b(q) v'(0)  \right)\sigma_u(q) + 
 + \left((b\circ\sigma^{-1} \circ \alpha)'(0) + \Gamma_{11}^2(q) a(q) u'(0) + \Gamma_{12}^2(q) a(q) v'(0) + \Gamma_{12}^{2}(q) b(q) u'(0) + \Gamma_{22}^2(q) b(q) v'(0)  \right)\sigma_v(q). $ where $\pi_{T_pS}$ is the projection on $T_pS$ and $\Gamma_{ij}^{k}$ are the Christoffel symbols. Writing the covariant derivative in this form is clear that this definition does not depend of the  curve $\alpha$ chosen. But why this derivative does not depend on the parametrization $\sigma$? Can someone help me?","['parametrization', 'differential-geometry', 'surfaces']"
2463480,"Prove that every positive integer divides a number such as $70, 700, 7770, 77000$.","Prove that every positive integer divides a number such as $70, 700, 7770, 77000$, whose decimal representation consists of one or more $7$’s followed by one or more $0$’s. Hint:$7$; $77$; $777$; $7777$ I know that I am supposed to use the pigeonhole principle, but I can't figure out how. I know that it probably comes down to proving that all odd numbers divide some number of the form $7, 77, 777$, etc.","['number-theory', 'pigeonhole-principle']"
2463497,Example of a sequence with integral → 0 but gn(x) does not converge to zero and >=0.,"I need to think of an example of a sequence $g_n$ with $\int_0^1g_n → 0 $ but $g_n(x)$ does not converge to zero for any $x∈ [0,1]$ and $g_n(x) ≥ 0$ for all $x$ and $n$. Hints and help wanted! The fact $g_n(x)$ does not converge to zero is what has caused most of my attempts to fail.","['real-analysis', 'integration', 'analysis']"
2463508,Determine $\lim_{n\to \infty} n\left(1+(n+1)\ln \frac{n}{n+1}\right)$,"Determine $$\lim_{n\to \infty} n\left(1+(n+1)\ln \frac{n}{n+1}\right)$$
I noticed the indeterminate case $\infty \cdot 0$ and I tried to get them all under the $\ln$, but it got more complicated and I reached another indeterminate form. The same happened when I tried to use Stolz-Cesaro. EDIT: is there an elementary solution, without l'Hospital or Taylor series?","['real-analysis', 'calculus', 'limits']"
2463511,Finding a $C^*$-subalgebra of $B(H)$ for $c_0$?,Let $c_0$ denote the set of all complex sequences that converge to zero. We can show that $c_0$ is a $C^*$-algebra with the $*$-involution defined as complex conjugate and norm $$\|x\| = \max_j |x_j|$$ for every $x \in c_0$. I know that every $C^*$-algebra is $*$-isomorphic to a $C^*$-subalgebra of $B(H)$ for some Hilbert space $H$. How do I go about finding this $C^*$-subalgebra of $B(H)$ for $c_0$? Any help pointing me in the right direction would be much appreciated.,"['c-star-algebras', 'hilbert-spaces', 'functional-analysis', 'representation-theory', 'operator-algebras']"
2463513,Minimum value of $|A - B |$,"Let $B = \{ x : x/3 \in \mathbb{Z}  \ , -4 \lt x \le 12\}$ and $A = \{ x^2 - m : x \in \mathbb{Z} \ , \ -3 \lt x\le m\}$ . The value of $|A  \cap B| $ is $3$ . Find minimum value of $|A - B |$ . The only way that I can do is trying different numbers for $m$ but it isn't convincing for me .","['algebra-precalculus', 'elementary-set-theory']"
2463515,$\textbf Z[\omega]$ is UFD for $\omega$ being $p-$th root of unity where $3 < p < 23$ is a prime number,"This is an assumption made in Marcus, Number Fields. $\textbf Z[\omega]$ is UFD for $\omega$ $p-$th root of unity with $3 < p < 23$. For $p = 2, 3$, one can use Neukrich geometric proof on the distance to the nearest lattice point. It seems that this proof fails for $p=5$ as there are lattice points which is not generated by shifting the fundamental lattice $0,\omega,i\omega,(1+i)\omega$. Q: Was there a unified approach to deal with this problem for $3 < p < 23$?","['number-theory', 'abstract-algebra', 'unique-factorization-domains', 'algebraic-number-theory']"
2463518,What is stochastic mapping?,Here the author uses something called stochastic mapping . My guess would be that a stochastic mapping from $A$ to $B$ is a function from $A$ to probability spaces with $B$ as its set of elementary events. A friend of mine suggested that it can also mean a probability space with functions from $A$ to $B$ as its elementary events. I am not sure whether these two definitions are interchangeable.,['probability-theory']
2463575,Is there any deep reason that 23456789 is prime? [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 6 years ago . Improve this question I was recently coding a prime factorization function and wanted to test that it could factor large numbers reasonably well. Arbitrarily, I slid my finger across the number pad, and got 23456789 as a test input. Surprisingly, it was prime! Was this just a strange coincidence, or is there any deeper number theoretic structure that leads to this result. Past research: all I've been able to do is confirm that 23456789 is indeed prime and is the largest prime with digits in ascending order. https://primes.utm.edu/curios/page.php/23456789.html","['number-theory', 'prime-numbers']"
2463618,Nested Summation Formula Help,"I'm currently taking a discrete mathematics course, and we're learning about summation formulas. I need to create a formula for the nested summation $$
\sum_{i=0}^{n} \sum_{j=0}^i 2^i
$$ I started with the inner summation: $$
\sum_{j=0}^{i} 2^i
$$ and arrived at $$
2^{i+1} - 1
$$ I plugged this into the outer summation $$
\sum_{i=0}^{n} 2^{i+1}-1
$$ The following is my work for evaluating the outer sum: $$
\sum_{i=0}^{n} 2^{i+1}- \sum_{i=0}^{n}1 = 2(\sum_{i=0}^{n} 2^{i})- n = 2(2^{n+1} - 1) - n = 2^{n+2} - 2 - n
$$ So my final answer is $\ 2^{n+2}-2-n$. However, when I checked my answer on Wolfram Alpha, it says my answer should be $\ 2^{n+1}(n+1)$ check here Wolfram source . Can someone please explain how I am supposed to arrive at what Wolfram Alpha is saying and point out where I went wrong with my computation? Thank you!","['summation', 'discrete-mathematics']"
2463631,Show that $\{v: (M+v)\cap N= \emptyset\}$ is dense,"Given $X\subset \mathbb{R}^p$ and $v\in \mathbb{R}^p$, let $X + v =
 \{x+v; x\in X\}$. Let $M, N\subset \mathbb{R}^p$ be surfaces of class
  $C^1$ such that $\dim M + \dim N <p$. Show that $\{v: (M+v)\cap N= \emptyset\}$  is dense in $\mathbb{R}^p.$ Suggestion: Prove that the set of points $x-y\in\mathbb{R}^p$, where $x\in M$ and $y\in N$ has measure zero Why proving that the vector from $M$ to $N$ has measure zero will help? I truly have no clue on this one, as I see no connection from the guess to the exercise.","['real-analysis', 'measure-theory', 'calculus']"
2463648,Probability of a biased coin obtaining its second heads or seconds tails on the $6^\text{th}$ toss,"Consider a coin for which the $P(\text{heads}) = {1\over3}$ and $P(\text{tails}) = {2\over3}$. Suppose that the coin will be repeatedly flipped  until at least two heads and at least two tails are obtained. Letting $X$ be the number of flips required, give the value of $P(X= 6)$ Attempted Solution: In order to get the second head on the $6^\text{th}$ toss, you need to get $4$ tails in the first $5$ tosses, and heads on the $6^\text{th}$ toss. Similarly, in order to get the second tail on the $6^\text{th}$ toss, you need to get $4$ heads in the first $5$ tosses, and tails on the $6^\text{th}$ toss. So would the answer just be $${5\choose4} \left(\frac{2}{3}\right)^4 \left(\frac{1}{3}\right)^2 + {5\choose4} \left(\frac{1}{3}\right)^4 \left(\frac{2}{3}\right)^2 = 0.1372$$","['combinatorics', 'statistics', 'probability']"
2463652,Group action induces a homomorphism between Lie algebras,"Let $\varphi:G\times M\rightarrow M$ be a Lie group $G$ (effective) action on a smooth manifold $M$. Fix $g\in G$ and let $\varphi_g(x):=\varphi(g,x)$. Then $\varphi $ induces a smooth homomorphism $\lambda: G\rightarrow Aut(M);g\mapsto \varphi_g$. Now, if $\frak g$ is the Lie algebra of $G$ and $\Gamma(M,TM)$ the algebra of smooth vector-fields on $M$. Then, is it true that $\lambda $ induces a homomorphism $\alpha:\mathfrak g \rightarrow \Gamma(M,TM)$? How $\alpha $ is  defined? Is $\alpha$ injective?  Can we say that the Lie algebra of $G$ is embedded in the Lie algebra of smooth vector-fields of $M$?","['smooth-manifolds', 'differential-geometry', 'lie-algebras', 'lie-groups']"
2463669,Proper Notation/Logic for Showing a Relation is a Function,"I'm currently working with relations that I want to show are functions. I know the general algorithm for doing this for some $f : A \rightarrow B$ , i.e, show: $f \subseteq A \times B$ $ \forall a \in A \,\exists b \in B  \,((a,b) \in f) $ $(a,x) \in f  \land (a,y)\in f \implies x=y $ My question is about how to show condition 3 properly, i.e, without using the notation $f(a)$. It seems that since we don't know what $f(a)$ is here that it would be difficult to show condition 3. I tried to do this for the function $f(x)=x^2$ on $\mathbb{R}$, but couldn't avoid the issue I'm referring to. I appreciate any advice. Thanks!","['elementary-set-theory', 'abstract-algebra', 'functions']"
2463714,"$|f(x)-f(y)|\ge c|x-y|$ with $c>0$, then for $g:B\to \mathbb{R}$ integrable, the composite $g\circ f:A\to \mathbb{R}$ is integrable","Let $f:A\to B$ continuous such that $|f(x)-f(y)|\ge c|x-y|$ with $c>0$
  constant and $x,y\in A$. Prove that, for all $g:B\to \mathbb{R}$
  integrable, the composite $g\circ f:A\to \mathbb{R}$ is integrable I'm studying analysis with a bit of measure theory. We say that a function is integrable if its Dasboux sums (inferior and superior) coincide. This answer says that it's only valid to Riemann-Lebesgue integration, which is my case, but doesn't provr anything: If $\|f(x)-f(y)\|\ge \alpha\cdot\|x-y\|$ and $g$ integrable $\Longrightarrow$ $g\circ f:A \longrightarrow \mathbb{R}$ is an integrable function Obviously this has something to do with the oscilation of $f$, becaue of the condition $|f(x)-f(y)|\ge c|x-y|$, and remember that $w(f,X) = \sup \{|f(x)-f(y)|; x,y\in X\}$ is the max variation seen in $f$ over the set $X$. So we have a case where the oscilation is $\ge |x-y|$. There are some theorems relating the oscilation of $f$ with its integrability. One is that for a bounded $f:A\to\mathbb{R}$ to be integrable, it's necessary and sufficient that given $\epsilon >0$, then for any partition $P$ of a block $A$ we have $$\sum_{B\in P} w_B\cdot vol \ B <\epsilon$$ How to relate this to the composite $g\circ f$ and its integrability? I thought even about using the same criteria for the integrability of $g\circ f$, but without success.","['continuity', 'real-analysis', 'integration', 'calculus']"
2463744,Find the derivative using limit definition: $\frac{x}{1 + x\sin(1/x)}$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question How can I find the derivative of this function  (defined below) using the definition of the limit? $$f(x):= \frac{x}{1 + x\sin(1/x)}$$ So I know the definition of the limit but I am unable to apply it here. Any help or hint would be appreciated.","['derivatives', 'calculus']"
2463756,"Proving that $f(x)=x^2-6x-40$ is injective for $f: [3, \infty) \rightarrow [-49, \infty)$ without using calculus","I'm trying to prove that $f(x)=x^2-6x-40$ is injective for $f: [3, \infty) \rightarrow [-49, \infty)$. Note that I cannot use calculus. I tried letting $f(a)=f(b)$ and I arrived at $a^2-6a=b^2-6b$. Then I tried to find a solution for $a$ in terms of $b$ and a solution for $b$ in terms of $a$ and I got $a=\frac{6 \pm \sqrt{36+4b^2-24b}}{2}=3 \pm \sqrt{9+b^2-6b}$ and $b=\frac{6 \pm \sqrt{36+4a^2-24a}}{2}=3 \pm \sqrt{9+a^2-6a}$. If I tried to equate to show that $a=b$ I basically arrived at where I started from. Then I tried the approach of seeing what happens if $a>b$ and $a<b$ but I couldn't get far with that either since for some numbers $a^2<6a$ and for some numbers $a^2>6a$. I'm wondering what the best method to prove that $f$ is injecitve is.","['real-analysis', 'functions', 'quadratics']"
2463768,Understanding The Math Behind Elchanan Mossel’s Dice Paradox,"So earlier today I came across Elchanan Mossel's Dice Paradox , and I am having some trouble understanding the solution. The question is as follows: You throw a fair six-sided die until you get 6. What is the expected
  number of throws (including the throw giving 6) conditioned on the event
  that all throws gave even numbers? Quoted from Jimmy Jin in ""Elchanan Mossel’s dice problem"" In the paper it goes on to state why a common wrong answer is $3$. Then afterwards explains that this problem has the same answer to, ""What is the expected number of times you can roll only $2$’s or $4$’s until
you roll any other number?"" I don't understand why this is the case. If the original problem is asking for specifically a $6$, shouldn't that limit many of the possible sequences? I also attempted to solve the problem using another method, but got an answer different from both $3$ and the correct answer of $1.5$. I saw that possible sequences could have been something like: $$\{6\}$$
$$\{2,6\}, \{4,6\}$$
$$\{2,2,6\}, \{2,4,6\}, \{4,2,6\}, \{4,4,6\}$$
$$\vdots$$ To which I set up the following summation and solved using Wolfram Alpha : $$\text{Expected Value} =\sum_{n=1}^\infty n\left( {\frac{1}{6}} \right)^n 2^{n-1} = 0.375$$
Obviously this is different and probably incorrect, but I can't figure out where the error in the thought process is. Any help on understanding this would be greatly appreciated. A blog post discussing the problem can be found here.","['means', 'conditional-expectation', 'probability']"
2463804,Redundant finite character family definition,"Definition: Let $F$ be a family of sets. $F$ is called of finite character if for each set $A$ , we have that: $A\in F\iff$ Each finite subset of $A$ , is also in $F$ . I can't see the point of this definition, I find it redundant. It seems trivial, if $A$ is in $F$ then every subset (finite or infinite) of $A$ will be always in $F$ . My thinking is that every family $F$ is of finite character, according to the definition.","['general-topology', 'elementary-set-theory', 'definition']"
2463811,How do you simplify an expression involving fourth and higher order trigonometric functions?,"The problem is as follows: Which value of $K$ has to be in order that $R$ becomes independent from $\alpha$?. $$R=\sin^6\alpha +\cos^6\alpha +K(\sin^4\alpha +\cos^4\alpha )$$ So far I've only come up with the idea that the solution may involve $R=0$, therefore $$\sin^6\alpha +\cos^6\alpha +K(\sin^4\alpha +\cos^4\alpha)=0$$ as a result the expression becomes $0$ thus independent from $\alpha$, however the result is like this $$-K=\frac{\sin^6\alpha +\cos^6\alpha}{\sin^4\alpha +\cos^4\alpha}$$ I am not sure if this is the right way. Moreover, how can I simplify this expression, as it has order four and six?","['algebra-precalculus', 'trigonometry']"
2463895,Epsilon-Delta Proof of Limits Being Equal,"How would I go about proving that two limits are equal to each other using the Epsilon-Delta definition? Moreover how can I prove that: $$\lim_{x\to0}f(x) = \lim_{x\to a}f(x-a)$$ using the Epsilon-Delta definition? The intuition for this seem clear. However, I have do not know how a formal proof can be developed.","['real-analysis', 'calculus', 'limits']"
2463896,Bayes rule for two conditioned events,"I only saw Bayes rule with one conditioned event and now I need to work with two events and I am not sure if this is a right way to do it: $$ p(A \mid B, C) = \frac{p(B \mid A, C)\ p(A \mid C)}{p(B \mid C)} = \frac{p(B, A \mid C)}{p(B\mid C)}$$ I honestly do not know if this makes sense, but I needed to have $p(B\mid C)$ in denominator for the problem that I am solving, so I thought this might be the way to do it. Why is the above true or false?","['bayes-theorem', 'probability', 'conditional-probability']"
2463904,Is the topology that has the same sequential convergence with a metrizable topology equivalent as that topology?,"Let $\mathscr T_1$ and $\mathscr T_2$ be two topologies on space $X$. Assume that $(X,\mathscr T_1)$ is metrizable, and any sequence in $X$ that converges in one of the two topologies must also converge in the other topologies, i.e., $$(\,\forall\{x_n\}_{n\in\mathbb N}\subset X\,)\Big(\big(x_n\xrightarrow[]{\mathscr T_1} x\big) \Leftrightarrow \big(x_n\xrightarrow[]{\mathscr T_2} x\big)\Big).$$ The question is, whether $\mathscr T_1$ and $\mathscr T_2$ are the same topology on $X$? The answer should be affirmative, since this argument is used in many analysis books without hesitation, such as the proof of metrizable of locally convex spaces in Conway's book of functional analysis . But I don't know how to prove. Any comments or hints will be appreciated! Edit: Very sorry! I'll explain here the details I thought about the link of Conway's book. The motivation is from the proof of Proposition IV.2.1 in that book as linked. To prove the necessity part of the proposition, that is, If a local compact space $X$ is metrizable, then its topology is determined by a countable family of seminorms. the author construct a countable family of seminorms $\{p_n\}$, and then show that $\{p_n\}$ determine the same sequential convergence as a given metric $\rho$ of $X$, that is, 
$$(\,\forall\{x_n\}_{n\in\mathbb N}\subset X\,)\Big(\big(x_n\xrightarrow[]{\{p_n\}} x\big) \Leftrightarrow \big(x_n\xrightarrow[]{\rho} x\big)\Big).$$
But how to assert from the preceding statement that $\{p_n\}$ determine the same topology as the original one?","['functional-analysis', 'general-topology', 'metric-spaces', 'locally-convex-spaces', 'topological-vector-spaces']"
2463910,"If a complete sufficient statistic exists, is every minimal sufficient statistic complete?","Bahadur's theorem says that every bounded complete sufficient statistic is also minimal sufficient. But any minimal sufficient statistic is a one-to-one function of any other minimal sufficient statistic，which implies any minimal sufficient statistic is also a one-to-one function of a bounded complete sufficient statistic. Thus if a bounded complete sufficient statistic exists, then every MSS is a one-to-one function of it, and thus every MSS is also complete. Is this right? I feel it is wrong, but I don't know where the flaw is.","['statistics', 'statistical-inference']"
2463935,What are all of these statistics and probability symbols?,"Given a sample space $\mathcal C=\{c:0<c<10\}$ with $C \subset \mathcal C$. The probability function is $$P(C)=\int_C \frac{1}{10} dz$$ and the variable $X(c)=c^2$. Find the CDF $F(x)$. By an example in the text, it seems that $F(x)=P(x)$. So the CDF should be $$\int_0^{10} \frac{1}{10} dz = 1.$$
There are several problems here. If it equals one, then it's a cumulative function (rather than distrib function) and the book says the answer is $F(x) = \frac{\sqrt x}{10},\ 0<x<100$. Something is being lost. $F(x)$ is not the same as $F(c)$ and $c=\sqrt x$ gives the right answer. But why? What is $X$ vs $x$? What is $F(x)$ vs $F(c)$? Or what am I misunderstanding (I'm not even sure what to ask here, so you can just say anything useful). P.S. I did read the text, but it's rather terse and no examples explain the rationale behind why the integral is done on $\sqrt x$.","['statistics', 'probability', 'calculus']"
2463974,Theorem 3.3 (d) Rudin,"This from Rudin's Principle's of Mathematical Analysis I'm having trouble getting an intuitive picture of this proof. Can you please show me how Rudin gets to the inequality $|s_n -s|< \frac{1}{2} |s|^2 \epsilon$ algebraically? And also a description (I don't expect you draw it out, it's fine) of what this would look like in a pictorial?? I'm guessing it has something to do with the two triangles in the third one. Also point out if I interpreted the picture wrong in any way. Thanks in advance! This sites a life saver.","['real-analysis', 'epsilon-delta', 'proof-explanation', 'general-topology', 'sequences-and-series']"
2463992,Big O with Taylor Series Expansion,"I've plotted the taylor series of $$e^x$$
on WolframAlpha and got the following Pretty straight forward, until the very last term
$$O(x^6)$$ Can anyone explain in simple words why it's there and how it was derived?","['taylor-expansion', 'calculus', 'discrete-mathematics']"
2464000,Pentagonal trapezohedron with face perpendicular to side,"How do I calculate the angles of the kites in a pentagonal trapezohedron (i.e., a d10) such that the edge opposite a face is perpendicular to that face? I.e., I'm trying to make $\alpha$ be 90 degrees in this picture:",['geometry']
2464001,Lebesgue and Gaussian measures are equivalent on R^n [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question I have been trying to solve a problem involving constructing a sub-family $H$ of a family $T$ of Gaussian measures on $(R, B(R))$ such that $H$ is dense in $T$ (in the sense that for any probability measures in $H$ and in $T$, they are mutually absolutely continuous). I am wondering how Lebesgue measure and Gaussian measure are equivalent in $R$ (I can prove Gaussian is dominated by Lebesgue, but cannot prove the other way). Could someone help me prove this remaining direction?","['statistics', 'lebesgue-measure', 'measure-theory']"
2464020,Definition of Expectation,"I found in a textbook this definition of expectation for a random variable $X$ $$E(X)=\lim_{n\to\infty}\sum_{i=1}^n\frac{i-1}{\sqrt{n}}P\left(\frac{i-1}{\sqrt{n}}<X\leq \frac{i}{\sqrt{n}}\right)$$ However, the textbook doesn't particularly mention where this definition comes from, when it's from, and how it's equivalent to the current definition to expectation.  Also, I cannot find any other references to this anywhere.  If anyone knows anywhere to further read about this, it would be highly appreciated.  Thanks!","['self-learning', 'probability-theory', 'probability', 'statistics']"
2464037,"Group $G$ is cyclic $\iff$ every subgroup of $G$ has the form $G^k$, where $G^k=\{g^k\mid g\in G\}$","Let $G$ be a group (finite or infinite). Given $k \in \Bbb N_+$ , define $G^k=\{g^k\mid g\in G\}$ I hope to prove that $G$ is cyclic if and only if every subgroup of $G$ has the form of $G^k$ . It's easy to see that if $G=\langle g\rangle$ is cyclic, then every subgroup $H$ of $G$ must have the form of $\langle g^k \rangle$ . Therefore $H=\langle g^k \rangle=\langle g \rangle^k=G^k$ . ...excluding the trivial subgroup {e} of an infinite group (complement) But I get into trouble proving the other side. I have no idea how to find a counterexample, i.e. there exists a subgroup of $G$ not having the form of $G^k$ if $G$ is not cyclic. Meanwhile, I tried to prove it directly. But I cannot even prove $G$ is Abelian, considering $G^2$ as a normal(proved) subgroup of $G$ . Could you please help me solve the problem or disprove this proposition? Thanks a lot! And sorry for my poor English..","['abstract-algebra', 'group-theory', 'cyclic-groups']"
2464102,What is the probability that you win the second game given that you won the first if the outcomes of the two games are independent?,"I’m working on a probability problem, but I’m having a hard time understanding the question exactly. The problem is: You are going to play two games of chess with an opponent you have never played against before. Your opponent is equally likely to be a beginner, intermediate, or master. Depending on which, your chances of winning an individual game are 90%, 50%, or 30%, respectively. a) What is your probability of winning the first game? b) Given the information that you won the first game, what is the probability that you will also win the second game ( assume that, given the skill level of your opponent, the outcomes of the two games of independent each other)? I’ve done problem a. $1/3\cdot 0.9+1/3\cdot 0.5+1/3\cdot 0.3=0.567$ For problem b, I am confused how independence works here.
I know that the two games are independent, but if I am playing with the same opponent as the first game for my second game, wouldn’t I have a higher probability for problem b compared to problem a?
Or does the question imply that I’ll get different opponents each time and the answer to problem b would be 0.567?
I’ve searched, and the answer seems to be divided. Probability questions seem too much like English problems to me:( Could you please help me understand? Thank you in advance!",['probability']
2464105,Solving an upper triangular system of linear equations,"Given $$(I+T_1T_2T_3)\,x = b$$ where $I$ is the identity matrix and $T_1$, $T_2$ and $T_3$ are invertible upper triangular matrices. Matrix $(I+T_1T_2T_3)$ is also invertible. I want to know what the fastest method to find vector $x$ is. I know that it is easy to Find $A = I + T_1T_2T_3$ with $\mathcal{O(n^3)}$ basic arithmetic operations. Find $A^{-1}b$ with $\mathcal{O(n^2)}$ basic arithmetic operations. As a result it needs  $\mathcal{O(n^3)}$ operations. I wonder if it is possible to do it with $\mathcal{O(n^2)}$ operations? Note: I updated the question by adding the invertible matrix $T_3$. For case of two matrices, we can write the LHS, in form of $T_1^{-1}(T_1^{-1}+T_2)x$, which needs $\mathcal{O}(n^2)$ operations to solve.","['numerical-linear-algebra', 'systems-of-equations', 'matrices', 'asymptotics', 'linear-algebra']"
2464118,Summing up $3+5+9+17+...$,"Find the sum of sum of $3
+5+9+17+...$ till $n$ terms. Using Method of differences , the sum of the series is
$$\sum\limits_{j=1}^n 2^{j-1}+n$$ I am facing difficulty in evaluating $$\sum\limits_{j=1}^n 2^{j-1}$$. How do I do that? Now I have $2^0 + 2^1 + 2^2 ... 2^{n-1}$
The sum of this series is : $2^n- 1$ as sum of GP is given by $a(1-r^n)/(1-r)$. Here $a = 1, r =2$","['sequences-and-series', 'algebra-precalculus', 'telescopic-series', 'summation', 'geometric-progressions']"
2464150,Integrate the function $\int \sqrt{2+ e^{2t} + e^{-2t} } \; dt$,"I'm unsure how to solve this arc length.  The original problem says to find the arc length of $r(t) = \langle \sqrt{2}t, e^t, e^{-t} \rangle $ deriving I arrive at $r'(t) = \langle \sqrt{2}, e^t, -e^{-t} \rangle $ Using the arc length formula I arrive at $\int \sqrt{2+ e^{2t} + e^{-2t} } \; dt$ I'm aware of $e^{2t} + e^{-2t} = 2 \cosh \, 2t$ via WolframAlpha but I'm sure how this might help with integrating.  Any help is appreciated!","['integration', 'arc-length']"
2464160,Laplacian in Polar Coordinates: $\nabla^2f(r)=f''(r)+\frac{2}{r}f'(r)$,"$\vec{R}=x \hat{i} + y\hat{j} + z\hat{k}$ and
  $r=|\vec{R}|=\sqrt{x^2+y^2+z^2}$ Prove that $\nabla^2f(r)=f''(r)+\frac{2}{r}f'(r)$ So we need to basically show that $$\frac{\partial^2}{\partial x^2}f(r)+\frac{\partial^2}{\partial y^2}f(r)+\frac{\partial^2}{\partial z^2}f(r)=\frac{d^2f}{dr^2}+\frac{2}{r}\frac{df}{dr}$$ $f(r)$ is a scalar function of $r$. I'm not sure how to go about proving this. How can we possibly express $\frac{d^2f}{dr^2}$ and $\frac{df}{dr}$ in terms of $\frac{\partial^2}{\partial x^2}f(r)$, $\frac{\partial^2}{\partial y^2}f(r)$ and $\frac{\partial^2}{\partial z^2}f(r)$ ?","['real-analysis', 'polar-coordinates', 'calculus', 'multivariable-calculus', 'vector-analysis']"
2464173,Spectral Decomposition: $A\psi = \lambda \psi \implies f(A)\psi = f(\lambda)\psi$,"I'm reading Simon & Reed's Functional Analysis, and attempting to write out the proof of the functional calculus form of the Spectral Theorem. See this link for their construction of $f(A)$ where $f \in \mathbb{B}(\mathbb{R})$ a bounded Borel function on $\mathbb{R}$: Continuity of the functional calculus form of the Spectral Theorem Let $A \in L(H)$ be self-adjoint. My question is this: How do I show that $A\psi = \lambda \psi \implies f(A)\psi = f(\lambda)\psi$? This argument is easy when proving the same statement in the continuous calculus because when dealing with a continuous $f$ it may be approximated by a sequence $p_n$ that converges to it uniformly, and hence point-wise too. To my knowledge, a bounded Borel function, $f$, has the property that $\exists \{f_n\} \subset C(\sigma(A))$ s.t $$\lim_n \int_{\sigma(A)}|f_n-f|du_\psi = 0.$$ Also I found that we have point-wise convergence a.e$[u_\psi]$. Using the definition of $f(A)$ I can show that $$\exists ~~\lim_n f_n(\lambda) \in \mathbb{C}$$ but not that it necessarily equals $f(\lambda)$. I wanted this to complete the attempt of: $(\psi, f(A)\psi) = \int_{\sigma(A)} fdu_\psi = \lim_n \int_{\sigma(A)}f_ndu_\psi = \lim_n(\psi, f_n(A)\psi) = \lim_n(\psi, f_n(\lambda)\psi)$","['functional-analysis', 'functional-calculus', 'spectral-theory']"
2464201,Prime ideals of a finite direct product ring,"Is it true that any prime ideal of a finite direct product ring $R=\prod_{i=1}^nR_i$ is of the form $P=\prod_{i=1}^nI_i$, where $I_j$ is a prime ideal of $R_j$ for some $j$ and $I_i=R_i$, for $i\neq j$? Any ideal of the form above is prime in $R$. Indeed, if $X=\prod_{i=1}^nA_i$ and $Y=\prod_{i=1}^nB_i$ are ideals of $R$ (where $A_i$'s and $B_i$'s are ideals of $R_i$) such that $XY\subseteq P$, then either $A_j$ or $B_j$ is a subset of a  prime ideal $I_j$, for some $j$. Hence either $X$ or $Y$ is a subset of $P$. Any help/suggestion would be appreciated!","['abstract-algebra', 'ring-theory', 'noncommutative-algebra', 'ideals']"
2464269,The limit of a divergent series,"Let $\{a_n\}_{n \in \mathbb{N}} \subset \mathbb{R_+}$ be a real positive sequence such that
$$
\sum_{n=1}^\infty
a_n
=\infty
$$
a
I would like to konw if is it true that: $$
\lim_{k \to \infty}
\sum_{n=k+1}^\infty
a_n
=0
$$ Thanks.","['divergent-series', 'sequences-and-series', 'analysis']"
2464277,Is $x\log\bigl(\cos(x)\bigr)$ an even or odd function?,Is $x\log\bigl(\cos(x)\bigr)$ an even or odd function? $$f(-x)=-x\log\bigl(\cos(-x)\bigr)=-x\log\bigl(\cos(x)\bigr)=-f(x)$$ So it seems an odd function and i've tried to draw the graph too. But the suggested solution in my book says that it is an even function.,"['real-analysis', 'functions', 'even-and-odd-functions']"
2464409,Why does the discriminant in the Quadratic Formula reveal the number of real solutions?,"Why does the discriminant in the quadratic formula reveal the number of real solutions to a quadratic equation? That is, we have one real solution if
$$b^2 -4ac = 0,$$
we have two real solutions if
$$b^2 -4ac > 0,$$
and we have no real solutions if
$$b^2 -4ac < 0.$$","['polynomials', 'discriminant', 'roots', 'algebra-precalculus', 'quadratics']"
2464413,Extending continuous function via Kan extension.,"A very classical problem in topology is the following: Consider a topological space space $X$ and a subspace $ A \hookrightarrow X$. Suppose you have a continuous function $A \to Y$, can we extend to a function $X \to Y$? Now we identify the topological space with the category if its open sets, thus we get: Suppose you have functors $X \to A$ and $Y \to A$, can we find a functor $Y \to X$ closing the diagram? Is it possible to solve this problem using Kan Extension? Topologically speaking what does it mean for X to be cocomplete? What does it mean for $X \to A$ to be full and faithful?","['category-theory', 'general-topology']"
2464439,Upper Bound Lemma implies the Ergodic Theorem for Random Walks on Groups?,"Cross posted on Mathoverflow Ergodic Theorem A random walk on a finite group $G$ driven by a probability $\nu\in M_p(G)$ is ergodic if $\operatorname{supp}(\nu)$ is not concentrated
  on a proper subgroup $S\subset G$ nor the coset of a normal subgroup
  $N\triangleleft G$. In this case the convolution powers of $\nu$ converge to the uniform distribution $\pi$ on $G$: $$\nu^{\star k}\rightarrow \pi.$$ Where $\|\cdot \|=\frac12\|\cdot\|_{\ell_1}$, 
$$(\nu\star \nu)(g)=\sum_{t\in G}\nu(gt^{-1})\nu(t),$$
$d_\alpha$ is the dimension of a representation $\rho_\alpha:G\rightarrow \operatorname{GL}(V)$, 
$$\hat{\nu}(\rho)=\sum_{t\in G}\nu(t)\rho(t),$$
and $T^*$ denotes the conjugate transpose of $T$ in $\operatorname{GL}(V)$, Diaconis & Shahshahani proved the following: Upper Bound Lemma Where $\operatorname{Irr}(G)\backslash \tau$ is the set of non-trivial unitary irreducible representations on $G$:
  $$\|\nu^{\star k}-\pi\|^2\leq \frac{1}{4}\sum_{\rho_\alpha\in \operatorname{Irr}(G)\backslash \tau}d_\alpha \operatorname{Tr}[\widehat{\nu}(\rho_\alpha)^k(\widehat{\nu}(\rho_\alpha)^*)^k].$$ The Upper Bound Lemma still holds if the random walk driven by $\nu$ is not ergodic. Question: Can the Upper Bound Lemma be used to prove the Ergodic Theorem? Can the Upper Bound Lemma show that for $\nu^{\star k}$ to converge to $\pi$ it is necessary that $\nu$ is not supported on a subgroup (irreducibility)? I suspect aperiodicity (not concentrated on the coset of normal subgroup) might be harder. My own MSc thesis should be a good reference for some of this.","['finite-groups', 'markov-chains', 'probability', 'representation-theory', 'group-theory']"
2464442,Minimize the sum of Type I and Type II errors,"Given $X_1,\dots,X_n$ a simple random sample with normal variables ($\mu, \sigma^2$). We assume $\mu$ is unknown but $\sigma$ is known. Now consider the hypothesis
$ 
	\begin{cases}
	H_0: & \mu=\mu_0 \\
	H_1: & \mu=\mu_1 > \mu_0
	\end{cases}
	$ Determine the critical region $R$ in order to minimize the risk $P_{H_0}(R)+P_{H_1}(R^c)$. I'm not sure how to start this problem, in particular due to the fact that I'm dealing with $n$ samples here. I believe the test statistic I have to apply here is $z=\displaystyle\frac{\bar{X}-\mu}{(\sigma/\sqrt{n})}$, but I'm not sure how the application of it follows. EDIT Alright, let's consider the following: using the error function above I have that the error function with mean 0 and variance $\sigma $ is $\frac{1}{2\pi}\int_0^{\alpha/(\sigma\sqrt{2})} e^{-t^2}dt$. This error gives the probability of falling in $(-\alpha,\alpha)$ but I am interested in the rejection region, this is $(-\infty, \alpha)\cup(\alpha, +\infty)$. Therefore, I think I should consider the complementary error function $$
\operatorname{erfc}(\alpha) = 1-\frac{1}{2\pi}\int_0^{\alpha/(\sigma\sqrt{2})} e^{-t^2} \, dt = \frac 1 {2\pi}\int_{\alpha/(\sigma\sqrt{2})}^\infty e^{-t^2}\,dt
$$ Now I could derive and get that $\frac{d}{dt}\operatorname{erfc}(\sigma) = - \frac{1}{2\pi}e^{-\alpha^2/(2\sigma^2)}$. I should set it to $0$ and find $\alpha$, to ""solve"" the problem. There are three issues here:
(1) $e^{-\alpha^2/(2\sigma^2)}$ will never be zero for any $\alpha$. (2) I didn't get involved the hypothesis testing. (3) It is not clear what the $\sigma$ in the error function is. The wikipedia entry linked above says that error generally have mean zero, but it is possible for the error to have a variance. Is the $\sigma$ in the normal distribution the very same $\sigma$ in the error function?","['statistics', 'hypothesis-testing', 'statistical-inference']"
2464446,Solving the equation $\tan{x} + \tan \frac{x}{4}=2$,"I am trying to solve the equation $\tan{x} + \tan \frac{x}{4}=2$. 1st attempt: I use the following identity $\tan2x=\frac{2\tan x}{1-\tan^{2}x}$. Then get the following equation $$
u^5 -2u^4-8u^3+12u^2+3u+2=0,
$$
where $u=\tan \frac{x}{4}$. But i can't find any root for this equation. 2nd attempt: $\tan{4x} + \tan x=2\Rightarrow \sin{4x}\cos{x}+\sin{x}\cos{4x}=2\cos{4x}\cos{x}\Rightarrow \sin{5x}=2\cos{4x}\cos{x}$ $\sin{5x}=2\cos{4x}\cos{x}\Rightarrow \frac{1}{2}\sin{5x}=\cos{4x}\cos{x}\Rightarrow \cos({2k\pi\pm\frac{\pi}{3}})\sin{5x}=\cos{4x}\cos{x}$. I can't continue from here.","['algebra-precalculus', 'trigonometry']"
2464510,Can I eliminate variables in systems of diophantine equations?,Consider the system of diophantine equations bellow. $\cases{a_1x+b_1y+c_1z=d_1 \\ a_2x+b_2y+c_2z=d_2}$ Am I allowed to eliminate variables like one would in linear algebra? I was doing an exercise the other day where I assumed this was allowed and the result I acquired did not seem to agree with the answer the authors gave. Perhaps I just expressed it differently but more than likely I messed up.,"['diophantine-equations', 'systems-of-equations', 'elementary-number-theory', 'linear-algebra', 'discrete-mathematics']"
2464512,Hartshorne Chapter 2 Example 3.2.6,"Example II.$3.2.6$ in Hartshorne (reduced induced closed subscheme structure) This question is essentially the same as mine but it seems to have a rather complicated answer without upvotes. Basically in this example Hartshorne says that you can reduce the problem of proving that the glueing properties hold for the reduced, induced closed subscheme of  $Y$ for an affine cover $\{U_i\}$ of $X$ to showing that given affine open $U= \operatorname{Spec}(A)$ and $f \in A$, show that the reduced structure on $D(f) \cap Y$ induced by the restriction of the reduced structure on $\operatorname{Spec}(A) \cap Y$ is the same as the reduced structure on $\operatorname{Spec}(A_f) \cap Y$. I can see it for the case that $Y \cap U_i \cap U_j$ is both $Y \cap U_i \cap D(f)$ w.r.t $U_i$ and $Y \cap D(g) \cap U_j$ w.r.t $U_j$ as then we can apply this result directly but if not it seems to me that we need a further glueing result to say that, since $U_i \cap U_j$ is open in both $U_i$ and $U_j$ then it is the union of some $D(f)$ in both, and then try to apply this result to the union. If this is unclear which I feel it might be I will try and add some more details.",['algebraic-geometry']
2464524,Napier analogy and algebra in triangle.,"If in a $\triangle{ABC}$, we define $x=\tan\frac{B-C}{2}\tan\frac{A}{2}$, $y=\tan\frac{C-A}{2}\tan\frac{B}{2}$ and $z=\tan\frac{A-B}{2}\tan\frac{C}{2}$, then show that $x+y+z=-xyz$. My attempts: By Napier analogy, $x=\frac{b-c}{b+c},\ y=\frac{c-a}{c+a},\ z=\frac{a-b}{a+b}$ Then one can simply put these values in LHS, but that is cumbersome, I need to use some beautiful algebra, please help. I just need to solve that algebra stuff, if such problem exists somewhere on this site then please comment with that link, I'll delete this, then.","['polynomials', 'trigonometry', 'algebra-precalculus', 'triangles', 'geometry']"
2464531,moving on a grid with integer condition,"assume you are a flea jumping on a grid (similar to $\mathbb{Z}^2$). You can do any jump that define an integer distance, but moreover it has to change both coordinates (for instance, the moves (3,4) or (5,12) are allowed, but not (1;0)). The first question is to prove that in a finite number of jumps, you can reach any element of $\mathbb{Z}^2$. This is the easy part and let as an exercise for the reader :) Now, you have done this easy part and you know that you can reach (1;0) in 3 jumps, which means that any point of coordinates (a;b) is reachable in at most 3(|a|+|b|) moves. Of course this bound is terrible. But here comes the real difficulty : is the number of moves needed to reach any point uniformly bounded ? Or, at least, can you do better than O(|n|) ? (say that n is max (|a|,|b|) for instance, it does not change anything as far as we are only studying what happens asymptotically). So far, I guess one can use some Euclidean algorithm trick to obtain something in O(ln(|n|)), but I don't have any better idea. Is this problem (well)-known ? Studied somewhere ? Thanks in advance for any comment ;)","['combinatorial-number-theory', 'discrete-mathematics']"
2464549,$\sin(\frac{\pi}{3})+\sin(\frac{2\pi}{3})+...+\sin(\frac{n\pi}{3})=2\sin(\frac{n\pi}{6})\sin(\frac{(n+1)\pi}{6})$ [duplicate],"This question already has answers here : How can we sum up $\sin$ and $\cos$ series when the angles are in arithmetic progression? (8 answers) Closed 6 years ago . I need to prove that $\forall n\in\mathbb N:$ $$\sum_{i=1}^n \sin(\frac{i\pi}{3}) = 2\sin(\frac{n\pi}{6})\sin(\frac{(n+1)\pi}{6})$$ Using induction only leads me to proving quite complicated trig identities. I guess it also can be solved using reminders because sins on the LHS are equal to: $$\frac{\sqrt3}{2},\frac{\sqrt3}{2},0,-\frac{\sqrt3}{2},-\frac{\sqrt3}{2},0$$
so per every 6th term they cancel out. Could You give me any hint?","['real-analysis', 'trigonometry', 'sequences-and-series']"
2464577,How to prove that the both definition of completeness of $\mathbb{R}$ are equivalent?,"In the definition of completeness of a set, in particular $\mathbb{R}$, I have seen the following definitions: Dedekind: Every non-empty bounded of subset has a least upper bound (with respect to the natural order). Cauchy: Every Cauchy sequence converges. However, how can one prove that both of these definitions are equivalent ?","['real-analysis', 'cauchy-sequences']"
2464584,"Why $\min_{a\in \Bbb C}\max \{|1-ax|,|1-ay|\}$ with given $x,y\in \Bbb C$ is attained at $a=\frac{2}{x+y}$","Consider complex numbers. Given $x,y \in \Bbb C$, how can we see the following $\min_{a\in \Bbb C}\max \{|1-ax|,|1-ay|\}$ is attained when $a=\frac{2}{x+y}$? The absolute value is the modulus of complex numbers. Many thanks! The previous post is not good (too many changes in the question), and there was no answer, so I open a new one.","['complex-analysis', 'complex-numbers', 'calculus']"
2464596,Show a statistic is complete but not suffcient,"Let $X_1, ...,X_n$$(n \geq 2)$ be i.i.d. random variables having the normal
distribution $N(\theta, 2)$ when $\theta = 0$ and the normal distribution $N(\theta, 1)$ when $θ ∈ R$ and $θ \neq 0$. Show that the sample mean $\bar X$ is a complete
statistic for $θ$ but it is not a sufficient statistic for $θ$. My idea is to show $E[f(\bar X)]=0$ implies $f(\bar X)=0$ (where $f$ is any measurable function), which is the definition of completeness.And I get the following formula:
$$\int_{{\mathbb{R}}^n}f(\bar X)\exp\left(-\frac{x_1^2+\cdots+x_n^2}{4}\right)\text{d}x_1\cdots\text{d}x_n=0
$$
when $θ = 0$ ,and
$$\int_{{\mathbb{R}}^n}f(\bar X)\exp\left(-\frac{(x_1-\theta)^2+\cdots+(x_n-\theta)^2}{2}\right)\text{d}x_1\cdots\text{d}x_n=0
$$ 
when $θ \neq 0$. But I don't know how to prove $f(\bar X)=0$ by the two formula above. Can someone help me?",['statistics']
2464703,Different limit for two Hausdorff topology?,"I was working on some exercises and I wonder if the following is true: Consider a Hausdorff topological space $(X,\tau)$ and a sequence $(x_n)_{n\in \Bbb{N}}$ of elements of $X.$ Suppose that $$x_n\to x\quad\mbox{as}\quad n\to \infty \quad\mbox{for the topology }\tau$$ with $x\in X.$ Now suppose I have another Hausdorff topology on $(X,\tau')$. Assuming that $(x_n)_{n\in \Bbb{N}}$ converges also for this topology, does it follow that$$x_n\to x\quad\mbox{as}\quad n\to \infty \quad\mbox{for the topology }\tau'?$$ All the counter exemples I can found are for non Hausdorff topology, I am convinced that is to ""beautiful"" to be truth. I tried with some probability i.e. convergence in distribution, but we don't really care of $\Omega$ for random variables so...","['general-topology', 'analysis']"
2464716,When can we factor $\displaystyle\sum_{l=0}^{n-1} m^l$,"Inspired by this question which in the case $k=2$ we would need to factor the second factor too: $$\displaystyle\sum_{l=0}^{n-1} m^l$$
Can we say anything in general for which $n$ or $m$ this will be possible? My own work is limited to concluding that if $n$ is a composite number $n = f_1\cdot f_2$, then: $$\displaystyle\sum_{l=0}^{n-1} m^l = \left(\displaystyle\sum_{l=0}^{f_1-1} m^l\right)\left(\displaystyle\sum_{l=0}^{f_2-1} m^{l\cdot f_1}\right)$$ For example $n=6 = 3 \cdot 2$ : $$m^5+m^4+m^3+m^2+m^1+1 = (m^2+m^1+1)(m^3+1) = (m+1)(m^4+m^2+1)$$","['number-theory', 'perfect-powers', 'factoring', 'soft-question']"
2464756,Is this equation known?,"When I was trying to prove a relation from solid state physics, I reached this mathematical problem. In the equation $$\sum_{i=1}^Nm_ix_i=n$$ $m_i$ and $n$ are known integers, $N=3$, and $x_i$ are unknown integers. Also we know that the greatest common factor of $\left\{m_i\right\}$ is 1. I don't need to find the solution; I must just show/state that the answer exists.",['discrete-mathematics']
2464781,"Solve system of equations: $\sqrt2 \sin x = \sin y, \sqrt2\cos x = \sqrt5\cos y$","$\sqrt2 \sin x = \sin y, \sqrt2\cos x = \sqrt5\cos y$ I tried to use tangent half-angle substitution, tried to sum these two equations and get this $\sin(x+ \pi/4) = \sqrt3 / \sqrt2 \sin(y+\tan^{-1}(\sqrt5))$
I stuck. Any Help is appreciated!","['trigonometry', 'systems-of-equations']"
2464813,Is my proof for $A\cup B=A\cap B\iff A=B$ correct?,"I would appreciate it if you could let me know whether my proof is correct. If not, I was hoping you could guide me in the right direction. Thank you in advance. For the forward arrow: (Assume $A\cup B=A\cap B$ ) ( $A\subset B$ ) Let $x\in A$ . Then, $x\in A\cup B\rightarrow x\in A\cap B\rightarrow x\in A \land x\in B\rightarrow x\in B.$ Thus, $A\subset B$ . ( $B\subset A$ ) Similarly, let $x\in B$ . Then, $x\in A\cup B\rightarrow x\in A\cap B\rightarrow x\in A \land x\in B\rightarrow x\in A.$ Thus, $B\subset A$ . $A\subset B \land B\subset A \iff A=B$ For the backward arrow: (Assume $A=B$ ) Assume $A=B$ . Then, $\ A\cup B= A\cup A= A= A\cap A= A\cap B$ .","['elementary-set-theory', 'proof-verification']"
2464865,Solve integral $\int\frac{dx}{\sin x+ \cos x+\tan x +\cot x}$,"I need to find: $$\int\frac{1}{\sin x+ \cos x+\tan x +\cot x}\ dx$$ My attempts: I have tried the conventional substitutions. I have tried the $\tan(x/2)$ substitutions, tried to solve it by quadratic but nothing has worked so far.","['integration', 'trigonometric-integrals', 'calculus']"
2464937,"Calculate the triple integral $\iiint_D \sqrt{x^2+y^2+z^2}\, dV$.","Calculate the triple integral of $$\iiint_D \sqrt{x^2+y^2+z^2}\, dV$$ where $D$ is bounded by (1) $x^2+y^2+z^2=2ay$ and (2) $y=\sqrt{x^2+z^2}$ . So far I was thinking that if I made $y$ turn to $z$ and $z$ turn to $y$ I could use cilyndrical coordinates So (1) $a^2=r^2+(z-a)^2$ and (2) $z=r$ and both intersect at $z=a$ It is correct to propose the integral $$\int_0^{2\pi}\int_0^a\int_0^{\sqrt{a^2-(z-a)^2}}r\sqrt{z^2+r^2} \,dr\,dz\,d\theta$$ ?
And if so I evaluate and get $a^3\pi$ but Im suspicious of this result","['volume', 'multiple-integral', 'multivariable-calculus', 'integration', 'definite-integrals']"
2464938,Proving binomial theorem in $\mathbb Z$ modulo $p$ where $p$ is prime,"How would I go about proving that for all $a, b \in \mathbb{Z} \pmod p$ where $p$ is prime, $$(a+b)^p = a^p + b^p$$ Also I was wondering if there was an intuitive way to think about and visualize exponentiation in modular arithmetic.","['binomial-theorem', 'modular-arithmetic', 'number-theory', 'prime-numbers', 'field-theory']"
2465012,Derivative of a square matrix to a power,"Suppose I have a function $f(x) = A^n$ where $A$ is a square matrix, $x$ is a positive real scalar, and $n$ is a natural number. I would like to calculate the derivative of $f$ with respect to $x$ (each entry in $A$ is a function of $x$). Is there a simple formula for this in general or do I need to know what $n$ is and use the product rule? I found this , but I don't understand it (in particular I don't understand what $DS(A)$ or $S(A)$ means). edit:
Each entry in $A$ is differentiable.","['matrices', 'matrix-calculus', 'calculus', 'derivatives']"
2465023,Proof of Homotopy Lemma in Milnor's Book,"In Topology from the Differentiable Viewpoint by Milnor the ""Homotopy Lemma"" is stated as follows Homotopy Lemma: Let $f, g : M \to N$ be smoothly homotopic maps between manifolds of the same dimension, where $M$ is compact and without boundary. If $y \in N$ is a regular value for both $f$ and $g$, then $$\#f^{-1}(y) = \#g^{-1}(y) \ \ \ \text{(mod $2$)}$$ Now when proving this Milnor let's $F : M \times [0, 1] \to N$ be a smooth homotopy between $f$ and $g$. He then supposes that $y \in N$ is a regular value for $F$. I won't write out the details here , but he proceeds to show that $\# f^{-1}(y) = \# g^{-1}(y) \ \ (\text{mod} \ 2)$. In the next part of the proof he supposes that $y \in N$ is not a regular value for $F$ and shows again that $\# f^{-1}(y) = \# g^{-1}(y) \ \ (\text{mod} \ 2)$ (using the result from the first part of the proof). Now I'm assuming that Milnor must have proved something stronger, that for any point $y \in N$, $\#f^{-1}(y) = \# g^{-1}(y) \ \ (\text{mod} \ 2)$, because any point $y \in N$ is either a regular value for $F$ or it is not a regular value for $F$, and both cases would be covered by the proof above. But then that leads me to question the following. Is $y \in N$ a regular value for both $f$ and $g$ if and only if $y \in N$ is a regular value for $F$? I'm not sure exactly how to prove this at the moment, or to provide a counterexample, but if the reverse direction holds, then the Homotopy Lemma would be proved. Does the reverse direction hold, do both directions hold, or does neither? Finally is my assumption that Milnor proved something stronger correct? If so why hasn't Milnor stated this stronger result in the book instead of the weaker version. If my assumption is not correct, then how has Milnor actually proved the Homotopy Lemma without actually assuming $y \in N$ is a regular value for both $f$ and $g$? Edit : Actually I just realized that in the second part of the proof $y$ is supposed to be not a regular value of $F$, but it is a regular value for $f$, otherwise $\# f^{-1}(y)$ wouldn't even be defined (in the proof on page 22). So the forward direction of my bolded question above doesn't seem to hold. Also are there any assumptions that Milnor is assuming implicitly that I'm not aware of?","['differential-topology', 'homotopy-theory', 'proof-verification', 'general-topology', 'differential-geometry']"
2465026,Determine the limit of $\lim_{x \rightarrow 0} \frac{\left | x \right | \cdot \left | \cos x \right |}{\left | \sin x \right |}$,"Determine the limit of $$\lim_{x \rightarrow 0} \frac{\left | x \right
| \cdot \left | \cos(x) \right |}{\left | \sin(x) \right |}$$ This is a task from an old exam. But I don't know if you can determine the limit of it at all because $sin$ and $cos$ oscillate. If I just look at it, I cannot really say the limit. So I tried to use L'Hôpital's rule (derivate the enumerator and denominator): $$\lim_{x \rightarrow 0} \frac{\cos(x)-x \cdot \sin(x)}{\cos(x)} = \lim_{x \rightarrow 0}\frac{\cos(x)}{\cos(x)}- \frac{x \cdot \sin(x)}{\cos(x)} = \lim_{x \rightarrow 0}\text{ }1 - \frac{x \cdot \sin(x)}{\cos(x)}$$ At this point I realized I have totally ignored the modulus signs :o I'm not sure how to deal with them? Can I just set them after I finished derivating? So I would end up with: $$\lim_{x \rightarrow 0}\text{ }1 - \frac{|x| \cdot |\sin(x)|}{|\cos(x)|}$$ Or just ignore the modulus signs and do the limit once going from left and once going from right side? This is confusing but as it looks like in the end, it goes towards $1$ ?","['absolute-value', 'calculus', 'limits']"
2465101,Show the quantified statements are not logically equivalent,"∀x(P(x) ⊕ Q(x)) and (∀xP(x)) ⊕ (∀xQ(x)) What I did was simplify the first statement Ǝx ~(P(x) ↔ Q(x))                       Expression for inclusive or Ǝx ~((P(x) -> Q(x)) ^ (Q(x) -> P(x)))   Expression for biconditional Ǝx ~(~(P(x) V Q(x)) ^ ~(Q(x) V P(x)))   Expression for implication Ǝx ((P(x) V Q(x)) V (Q(x) V P(x)))      DeMorgan’s law and double negation Ǝx (P(x) V Q(x))                        Indempotent law Then I said suppose this statement is true in a certain universe. We can say that P(a) is true or Q(a) is true. If Q(a) is true, then Ǝx P(x) is true, and by the rule of amplification we can say that Ǝx (P(x) V Q(x)) is true. Same thing applies for P(a). For the second I simplified ~(∀xP(x)) ↔ (∀xQ(x))                                Expression for inclusive or ~(((∀xP(x)) -> (∀xQ(x))) ^ ((∀xQ(x)) -> (∀xP(x))))  Expression for bicondtional ~(~((∀xP(x)) V (∀xQ(x))) ^ ~((∀xQ(x)) V (∀xP(x))))  Expression for implication (((∀xP(x)) V (∀xQ(x))) V ((∀xQ(x)) V (∀xP(x)))) DeMorgan’s + double negation ∀xP(x) V ∀xQ(x)                                     Indempotent law But I'm not really sure how to explain this in words. I'm also not completely sure if I'm doing this whole question the correct way.","['quantifiers', 'predicate-logic', 'logic', 'discrete-mathematics']"
2465106,Is the Lebesgue $\sigma$-algebra bigger than the Borel $\sigma$-algebra without axiom of choice?,"It is wellknown, that using the axiom of choice the Borel $\sigma$-algebra has cardinality $2^\mathbb{N}$, whereas the Lebesgue $\sigma$-algebra has cardinality $2^\mathbb{R}$. It immediately follows, that there are (many) Lebesgue-measurable sets, which are not Borel-measurable. Now I know, that the existence of avmeasure on $\mathcal{P}(\mathbb{R})$ is consistent with ZF. Though this really doesn't say anything about the Borel algebra in the absence of choice it lead me to the question if $Bor_\mathbb{R}=Leb_\mathbb{R}$, where the first is the smallest $\sigma$-algebra containing all intervals and the second are the measurable sets of the (outer) Lebesgue measure. Are there any sources on this?",['measure-theory']
2465108,Does convexity in each variable implies polynomial convexity?,"Let $\Omega$ be a domain in $\mathbb{C}^{m}$, $m\geq 1$. For each $a\in\Omega$, $i\in\{1,\ldots,m\}$, define $\Omega_{a,i}=\{z\in\mathbb{C}:a+ze_{i}\in\Omega\}$, where $e_{i}$ be the $i$-th standard basis element of $\mathbb{C}^{m}$. $\Omega$ is said to be convex in each variable if all of these $\Omega_{a,i}$'s are convex in $\mathbb{C}$. Does this force $\Omega$ to be polynomially convex $?$ A domain $D \subseteq \mathbb{C}^{m}$ is said to be polynomially convex if, for every compact subset $K$ of $D$, the polynomially convex hull of $K$, namely $\hat{K}=\{z\in\mathbb{C}^{n}:|p(z)|\leq \sup_{z\in K}|p(z)|$ for all polynomials$~p\}$ is contained in $D$.","['functional-analysis', 'complex-analysis', 'several-complex-variables', 'convex-analysis']"
2465120,How does a column of Zeros affect a Matrix?,"This was a sample test question and was not the answer to the question. I'm just curious about what the column of 0 does. For reference if needed, the question was ""Which of the following is the coefficient matrix for a homogeneous system Ax = 0 with only the trivial solution"" Here's the Matrix: \begin{bmatrix}1&0&0&0\\0&1&0&0\\0&0&1&0\end{bmatrix} I personally would assume that there would be only 1 solution as despite there being no pivot in the 4th column, the values in the 4th column are all 0. (I'm definitely doing this part wrong) Writing this in parametric vector form, I would get x 1 = 0 x 2 = 0 x 3 = 0 x 4 = free and now I'm kinda lost about what to do.. Taking a guess, would the result be: \begin{bmatrix}0\\0\\0\\1\end{bmatrix} * x 4 ? To be honest, I'm not exactly sure how to examine this matrix.. Simply put, how does the 0 column affect this matrix? Is the initial matrix equivalent to a 3x3 identity matrix? How many solutions are there? Infinitely many or just 1?","['matrices', 'matrix-calculus']"
2465128,"Are the measurable spaces $(\mathbb{R}^n, Bor(\mathbb{R}^n))$ and $(\mathbb{R}^m, Bor(\mathbb{R}^m))$ isomorphic for $n\neq m$","It is well known, that the topological spaces $\mathbb{R^n}$ and $\mathbb{R}^m$ are non-homeomorphic for $n\neq m$. However for a formal proof of this one usually needs strong methods like local homology. Now one can ask the same question (are there bi-measurable bijections) for the measurable space $(\mathbb{R}^n, Bor(\mathbb{R}^n))$, where $Bor(\mathbb{R}^n)$ denotes the Borel $\sigma$-algbra. Of course $(\mathbb{R}^n, Bor(\mathbb{R}^n))$ and $(\mathbb{R}^m, Bor(\mathbb{R}^m))$ are generated by the non-homeomorphic topologies, but I don't see how this would imply that the measurable spaces are non-isomorphic. 
Is there any sophisticated theory on measurable spaces comparable to the one for topological spaces one can use for this? If the measurable spaces are isomorphic, how about the measure spaces $(\mathbb{R}^n, Bor(\mathbb{R}^n), \mu^n)$ and $(\mathbb{R}^m, Bor(\mathbb{R}^m), \mu^m)$ where $\mu^n$ is the n-dimensional Lebesgue measure? If they are non-isomorphic: can there be measurable bijections between $(\mathbb{R}^n, Bor(\mathbb{R}^n))$ and $(\mathbb{R}^m, Bor(\mathbb{R}^m))$ for $n\neq m$?","['lebesgue-measure', 'measure-theory']"
2465135,Maximal compact topology iff compact sets are closed,"The theorem says: A compact space $(X,\tau)$ is maximal compact (i.e. no strictly larger topology on $X$ is compact) if and only if every compact subset of $X$ is closed in $\tau$. For ""if"", I prove by contraposition. Let $U\subset X$ be a compact subset of $X$ and $U$ is not closed in $\tau$. Define a finer topology $\tau':=\tau\cup\{X\setminus U\}$, and we show that $(X, \tau')$ is compact. Let $S$ be a subbasis of $(X,\tau')$ and let $S'\subseteq S$ be an open cover of $X$. By Alexander subbase theorem: https://en.wikipedia.org/wiki/Subbase#Alexander_subbase_theorem , it's enough to show that $S'$ has a finite subcover. Since $X\setminus U\in\tau'$, it is the finite intersection of elements in $S$. But this is not good enough because ideally I want to express $X\setminus U$ (and $U$) as a finite intersection of sets in $S'$, in order obtain a finite subcover of $S'$. How can I get around this? Let $X\setminus U=\cap_{k\leq n}S_k$ be a finite intersection of sets in $S$. Since $S'$ covers $X$, for each $k\leq n$, we have $S_k\subseteq\cup_{i\in I_k}S_i$, $S_k$ is a subset of some (possibly infinite) union of sets in $S'$. Hence $X\setminus U\subseteq\cup_{k\leq n}\cup_{i\in I_k}S_i$. This proof would work if I can somehow reduce $S_k$ to some finite union of sets in $S'$, but I'm not sure if that is at all possible. I feel like I need to use the compactness of the original space $(X,\tau)$.",['general-topology']
2465153,Distance between points on Earth,"So the problem is this: 
 Assuming the surface of the Earth
is a sphere of circumference 40, 000 kilometers, estimate the distance between
Philadelphia and Paris. I'm uncertain how to do this problem. I haven't done these kinds of question before, but besides doing some geometry of the earth how am I supposed to solve this? How do you go about using the latitude and longitude coordinates?","['trigonometry', 'curves', 'calculus', 'geodesy', 'geometry']"
2465154,Is there a universal or general “matrix-builder” notation?,"If one wants to compactly construct a series, one writes $$\sum_{i=1}^w a_i=a_1+a_2+a_3+\cdots+a_w$$ If one wants to compactly construct a set, one writes $$\bigcup_{j=1}^x B_j = B_1\cup B_2\cup B_3\cup\cdots\cup B_x$$ A benefit to these notations is that they require no extra explanation except for their arguments, which can actually be defined after the “big symbol” itself. If one wants to compactly construct a matrix , what “big operator” might one use to notate or stand in for $$\boldsymbol{C}(y,z) =
\begin{pmatrix}
c(1,1) & c(1,2) & c(1,3) & \cdots & c(1,z) \\
c(2,1) & c(2,2) & c(2,3) & \cdots & c(2,z) \\
c(3,1) & c(3,2) & c(3,3) & \cdots & c(3,z) \\ 
\vdots & \vdots & \vdots & \ddots & \vdots \\
c(y,1) & c(y,2) & c(y,3) & \cdots & c(y,z) \\
\end{pmatrix}$$ I suppose one could do something weird like defining $$\mathop{\LARGE\mathrm{M}}_{(k,\ell)=(1,1)}^{(y,z)}c(k,\ell)$$ but I would like something more universal, perhaps involving $\prod$, $\sum$, and $\boldsymbol{I}_{y\times x}$ (the $y\times z$ identity matrix).","['matrices', 'notation']"
2465203,Why do I think Lebesgue’s number lemma is wrong...,"Counterexample: $[0,1]\times[0,1]$ with induced subspace topology from $\mathbb{R}^2$ is compact. The open cover $\mathscr{U}$ is just the two circular sectors. When we look at the up-left corner and down-right corner, it fails - there is no such $\delta$, such that let the open ball be only in one of  circular sectors... what is wrong?",['general-topology']
2465221,Find the values of a and b that makes the following function differentiable,"I am told for the following piecewise function: $$f(x)=\left\{
\begin{array}{ll}
      ax+b, & x>-1; \\
      bx^2-3ax+4, & x\leq -1 \\
\end{array} 
\right. $$ I am asked to find the values of $a$ and $b$ that make $f(x)$ differentiable. So I simply differentiated $f(x)$ to get: $$f'(x)=\left\{
\begin{array}{ll}
      a, & x>-1; \\
      2bx-3a, & x\leq -1 \\
\end{array} 
\right. $$ So since a differentiable function must be continuous, I get that: $\displaystyle{\lim_{x \to -1^-}}(a)=f'(-1)$ So this implies: $a=-2b-3a$ $4a=-2b$ $-2a=b$ So that means as long as for any $a$, if I get a $b$ value such that $-2a=b$, $f(x)$ is differentiable. Is that correct?","['derivatives', 'continuity', 'limits']"
2465222,How to show the Jungle River Metric is Complete,"Currently, I'm struggling to prove that the Jungle-River Metric is complete over $R^2$. More generally, however, I'm having trouble grasping the approach that one should take when prooving completeness. Specific Question: Prove the Jungle River Metric, defined as $$d((x,y),(x',y')) = |y|+|y'|+|x-x'|$$ if $x \neq x'$. and $$d((x,y),(x',y')) =|y-y'|$$ if  $x = x'$. My approach so far: So, I know that a metric space is complete if every Cauchy space in the sequence converges. From what I understand, I want to define a general Cauchy Sequence $(x_n,y_n)_{n \in N}$ and then prove that the limit of this Cauchy sequence is inside of my metric space. However, I'm not too sure how to proceed from there. I've tried drawing open balls in my metric space in hopes of some inspiration. I found that the open balls in this metric space are diamonds centered around the x-axis, with possible vertical lines extending upwards and downwards depending on the radius of the ball. However, I don't see how this can help me. I feel like, please let me know if I'm wrong, but that I understand what it means to be complete, but I don't understand how specifically to begin proving that what I know needs to be true, is true. Any tips or advice would be greatly appreciated. Thank you!","['complete-spaces', 'real-analysis', 'metric-spaces']"
2465238,How can I prove this bijection between random walks?,"Let $R_n$ be the set of simple random walk paths such that $S_n=0.$ $P_n$ be the set of simple random walk paths such that $\forall i \in \{1,2,...,n\},$ $S_i > 0$ . $N_n$ be the set of paths such that $\forall i \in \{1,2,...,n\}, S_i \geq 0$ . Assume that all random walk paths start at the origin. How can I show that there is a bijection between $P_{2n}$ and $N_{2n-1}$ and that there is a bijection between $R_{2n}$ and $N_{2n}$ . Basically I want to show that a path in $R_{2n}$ with minimum value $k$ corresponds to a path in $N_{2n}$ with terminal value $2k$ . For this I'm thinking about cutting or shifting or reflecting paths. I don't think probability matters here. But I'm stuck on formulating the proofs. If we have sequence $S_0,S_1,...,S_n$ which is represented by a polygonal line with segments $(k-1,S_{k-1}) \rightarrow (k,S_k)$ a path is a polygonal line that is a possible outcome of simple random walk.","['random-walk', 'probability-theory', 'probability']"
2465274,How to show that $\int_0^x\cos(t^2)\ dt>0 $ for $x>0$?,"The Wikipedia article regarding the Fresnel integral seems to show that
$$
C(x):=\int_0^x\cos(t^2)\ dt>0
$$
for all $x>0$. But I can't find a reference. Could anyone give a proof or point me to some known reference?","['real-analysis', 'integration', 'calculus']"
2465342,Reference request for centralizer of a Banach space,"Definition : Let $(X,\|\cdot\|)$ be a Banach space over $\mathbb{R}.$ Let $ext(X^*)$ be the set of extreme points of the
  closed unit ball of the continuous dual space $X^*.$ A continuous linear linear operator $T:X\to X$ is said to be a multiplier if every point $p$ in $ext(X*)$ is an eigenvector for the adjoint operator $T*:X^*\to X^*.$ That is, there exists a function
  $a_T:ext(X^*)\to \mathbb{R}$ such that  $$p\circ T = a_T(p)p$$ for all
  $p\in Ext(X^*).$ The centralizer of $X$, denoted $Z(X),$ is the set of all
  multipliers on $X.$ To my knowledge, monographs which contains information on centralizer above are (Fleming and Jamison) Isometries in Banach Spaces: Vector-valued Function Spaces and Operator Spaces, Volume Two and (Behrends) M-Structure and the Banach-Stone Theorem . One article that I came across containing centralizer above is Aroujo's paper . Question : Does there exist any monograph, other than the two above, containing information on centralizer? If yes, may I know its
  title? I am interested to know more about centralizer stuffs.","['functional-analysis', 'reference-request', 'real-analysis', 'banach-spaces']"
2465363,"If $\nabla$ is the covariant derivative, why $\nabla: \mathcal{X}(S) \rightarrow \mathcal{X}(S) \otimes \Omega^{1}(S)$?","I'm studying differential geometry, and my professor defined covariante derivative in this way: Let $S \subset \mathbb{R}^3$ be a surface, $$\mathcal{X}(S) = \left\{ \xi:S\rightarrow \bigcup\limits_{p\in S} T_p S; \mbox{ }\xi(p) \in T_pS\hspace{0.1cm} \forall\hspace{0,1cm} p \in S \right\}$$ (the set of the fields over the surface $S$), and $\Omega^{1}(S)$ the set of 1-forms over $S$. Consider $p$ $\in$ $S$ and $y \in T_pS,$ choosing a curve $\alpha: I \rightarrow S$, satisfying $\alpha(0) = p$ and $\alpha'(0) = y$, we can define the covariant derivative at $p$ of the vector field $\xi$ relative to the vector $y$ as :
$$\nabla_y \xi (p) := \pi_{T_pS} \circ \left(\left.\frac{d\xi(\alpha(t)) }{dt} \right|_{t=0}\right).  $$
Where $\pi_{T_pS}$ is the projection of $\mathbb{R}^3$ over $T_p S$. It's easy to verify that this definition doesn't depend of the parametrization of the curve $\alpha$. Now, we can expand this notion of covariant derivative by changing the vector $y$ for a field $X$ $\in$ $\mathcal{X}(s)$, so $$\nabla_{X} \xi (p) := \nabla_{X(p)} \xi(p). $$ My problem is here. My teacher said that this caracterion show us that the operator $\nabla$ acts in $\mathcal{X}(S)$ and return tensor of $\mathcal{X(S)}\otimes \Omega^{1}(S),$ i. e; $$\nabla: \mathcal{X}(S) \rightarrow \mathcal{X}(S)\otimes\Omega^{1}(S)$$
$$\xi \mapsto \nabla\xi $$ I really want to know why $\nabla \xi$ $\in$ $\mathcal{X}(S)\otimes\Omega^{1}(S)$. From my knowledge and understanding of the circumstances, I see $\nabla \xi$ as
$$\nabla \xi : \mathcal{X}(S) \rightarrow \mathcal{X}(S)  $$ which implies  $\nabla \xi$ $\in$ $\mathcal{F}(\mathcal{X}(S),\mathcal{X}(S))= \{f:\mathcal{X}(S)\rightarrow \mathcal{X}(S) \}$. Is $\mathcal{F}(\mathcal{X}(S),\mathcal{X}(S)) = \mathcal{X}(S)\otimes\Omega^{1}(S)$ (or isomorphic as linear space) ? If yes, how I see this?","['derivatives', 'differential-geometry', 'geometry']"
2465407,Evaluate the sum ${1 - \frac{1}{2} {n \choose 1} + \frac{1}{3} {n \choose 2} + \ldots + (-1)^n \frac{1}{n+1} {n \choose n}}$ [duplicate],This question already has answers here : Alternating sum of binomial coefficients multiplied by (1/k+1) [duplicate] (4 answers) How to prove $\sum\limits_{r=0}^n \frac{(-1)^r}{r+1}\binom{n}{r} = \frac1{n+1}$? (5 answers) Closed 6 years ago . Evaluate the sum $${1 - \frac{1}{2} {n \choose 1} + \frac{1}{3} {n \choose 2} + \ldots + (-1)^n \frac{1}{n+1} {n \choose n}}.$$ I have tried comparing this to the similar problem here . I believe I need to differentiate or integrate? But I'm not sure how that might work. Any ideas? Thanks.,"['combinatorics', 'summation', 'binomial-coefficients']"
2465430,"use implicit differentiation to find $\partial z/\partial x$, $\partial z/\partial y$","I can't find the word implicit differentiation anywhere in the book, but I'm assuming it means solve for $z$ in this case and differentiate with respect to $x$, then $y$ in this problem. But when I took the derivative with respect to $x$ of 47 after solving for $z$, i get a different answer. I got $$z = \dfrac{\sqrt{-x^2-2y^2+1}}{\sqrt{3}}$$ and for the derivative of that: $$-\dfrac{x}{\sqrt{3}\sqrt{-x^2-2y^2+1}}$$ (i got these results on https://www.derivative-calculator.net/ ) this is different than the answer in the book. am i not supposed to solve for $z$ and differentiate with respect to $x$ then $y$? Is this another form of the answer? help.. the answer is $-x/3z$ ... which I don't get..","['multivariable-calculus', 'implicit-differentiation', 'partial-derivative', 'calculus']"
2465457,Strong Induction (with Splitting Boxes),"I am having an incredible amount of trouble understanding Strong Induction. I realize that Strong Induction means that we are assuming $P(1) \land P(2) \land P(3)\land...\land P(n-1) = P(n)$. But after this point, I'm lost. How does this chain of previous ""truths"" prove that $P(n) \implies P(n+1)$? For example, a HW problem I have deals with splitting stacks of boxes. The problem goes like this Lets say you have a stack of n boxes. You are allowed to split the
stack of boxes into stacks of size l and m, and in doing so, you earn
l * m in profit. You must repeatedly split the stacks until you have n stacks of
1 box.

Come up with a conjecture about the max profit you can earn and prove it by
strong induction. Basically, the question is asking about breaking a stack of n boxes down repeatedly until you get to n 1 box high stacks, and then compute the sum of profit earned by each successive splitting of the stack. It was fairly easy to come up with a formula that computes the profit earned, which is $n(n-1)/2$. To prove this by strong induction, I first start with a base case. Base Case: $P(1)$ is true because $1(1-1)/2) = 0$ and since you don't split any stacks, you don't earn any money. Inductive Step: Assume $P(1)$ up to $P(n)$ is true and consider $P(n+1)$. That is, $P(1) \land P(2)\land P(3)\land...\land P(n-1) = P(n)$ It is from this point that I'm lost. It can't be as simple as stating every case leading up to $P(n)$ is true, since we didn't prove this chain leading up to $P(n)$, only claiming it in the inductive step. I also don't understand how this chain inherently proves $P(n+1)$. If someone can please help understand where to go with this homework problem, (and ultimately an understanding of Strong Induction), I would greatly appreciate it. Proof by induction isn't too bad, but I get completely lost at Strong induction. Thanks","['induction', 'discrete-mathematics']"
2465466,Show that $\{|f''(z_0)|: f\in \mathcal{F}\}$ is a closed set for a compact family $ \mathcal{F}$ of holomorphic functions.,"I have the following problem: Let $\mathcal{F}\neq \emptyset$ be a compact family of holomorphic functions in a domain $U$, that is, every $f_n\in \mathcal{F}$ has a locally uniformly convergent subsequence whose limit also belongs to $ \mathcal{F}$. Let $z_0\in U$. Show that there is a function $f_0\in \mathcal{F}$ such that $|f_0''(z_0)|=\sup \{|f''(z_0)|:f\in \mathcal{F}\}$. My attempt: I only can prove that $\{f''(z):f\in \mathcal{F}\}$ is also compact. Since the statement is about ""subsequence"", I think it is far away from the desired conclusion. Also, the limit function $f$ of $f_n''$ may not be the one which can achieve the maximum of $|f''(z_0)|$ for some $z_0\in U$.","['functional-analysis', 'complex-analysis', 'supremum-and-infimum']"
2465561,Intersection of uncountable set and countable set.,"My friend told me that say you have an uncountable set $A$ and a countable set $B$, then the intersection of these two sets is the empty set. But wouldn't something like $A = [0,1]$ and $B = \{1, 2\}$ have the intersection of $\{1\}$? Also is there a way to prove this? Thanks!",['elementary-set-theory']
2465571,Removing points from a triangular array without losing information,"I'm trying to find insights about the following puzzle, to see if I can find it on the OEIS (and add it if it's not already there): Suppose I give you a triangular array of light bulbs with side length $n$ : o
    o o
   o o o
  o o o o
 o o o o o
o o o o o o
1 2  ...  n I'm going to turn on three lightbulbs that form an ""upright"" equilateral triangle as in the following example: o
    o x
   o o o
  o o o o
 o x o o x
o o o o o o Before I turn on the lights, your job is to remove as many lightbulbs as possible from the array—without losing the ability to deduce the triangle of bulbs that has been turned on. To be clear, if a lightbulb has been removed, it is not lit up when its position is turned on. For example, if you removed the following bulbs (marked by . ) you would only see the following two lights turn on (marked by x ), which is enough uniquely deduce the third (unlit) position: .              .
    . o            . x
   . . o          . . o
  o o o .   =>   o o o .
 o o o o .      o x o o . <- the third unlit position
o . . . o o    o . . . o o Let $a(n)$ be the maximum number of bulbs that can be removed without introducing any ambiguities. With a naive algorithm, I have checked values up to a triangle with side length 7, as seen below: .
                                                      .              . o
                                        .            . o            o . o
                           .           . .          . . o          . o o .
              .           . .         . o o        o o o .        o o . o .
 .           . .         . o o       o o . o      o o o o .      o . o . o o
. .         . o o       . o o o     o . . o o    o . . . o o    o . o . o o o

a(2) = 3    a(3) = 4    a(4) = 5    a(5) = 7     a(6) = 9       a(7) = 11 Searching for this sequence on the OEIS turns up dozens of results . As an upper bound for this sequence, we need the different configurations of 3, 2, 1, or 0 lights to be able to represent all of the $\binom{n + 1}{3}$ possible triangles. That is: $$\binom{n + 1}{3} \leq \binom{b(n) - a(n)}{3} + \binom{b(n) - a(n)}{2} + \binom{b(n) - a(n)}{1} + \binom{b(n) - a(n)}{0}$$ where $b(n) = \frac{1}{2}n(n+1)$ .","['puzzle', 'combinatorics', 'oeis', 'extremal-combinatorics']"
2465607,Exponentials of operators,"If $\{T_n\}$ converges in operator norm to $T$ does it follow that $\exp(T_n)$ converges to $\exp(T)$ at least in finite dimensions? 
I can handle this when the operators commute but not in general.",['functional-analysis']
2465617,On integer values which are attained by $n/\pi(n)$ only once,"Let $\pi (n)$ denote the prime counting function. I can prove that $\mathbb N \setminus \{1\} \subseteq \{n/ \pi(n) : n \in \mathbb N \}$ . Now for every integer $m>1$ , define $s(m) := \{ n \in \mathbb N : n>1 , n/ \pi(n)=m \}$ . Does there exist any integer $m$ such that $|s(m)|=1$ ? If there exists such integers , then are there infinitely many of them ?","['number-theory', 'analytic-number-theory', 'prime-numbers']"
2465628,Jaynes probability Exercise 3.3 (maximum-entropy),"Exercise 3.3 Suppose that in the previous exercise k is initially unknown, but we know that the urn contains exactly 50 balls. Drawing out 20 of them, we find three different colors; now what do we know about k? We know from deductive reasoning (i.e. with certainty) that 3 ≤ k ≤ 33; but can you set narrower limits k1 ≤ k ≤ k2 within which it is highly likely to be?
( Hint: This question goes beyond the sampling theory of this chapter because, like most real scientific problems, the answer depends to some degree on our common sense judgments; nevertheless, our rules of probability theory are quite capable of dealing with it, and persons with reasonable common sense cannot differ appreciably in their conclusions.) I guess the most likely answer is $ k = 3 $.
We can solve this problem by iterating $3 \le k \le 33$, within each situation, this may use the maximum entropy to get the most likely distribution and then we can compute the maximum probability to get 3 kinds of colors.
Through this method, We will get an optimized k.
Am i right, help, Thank you.","['combinations', 'probability-theory', 'information-theory', 'entropy']"
2465642,Summation of $1\cdot 3\cdot 5\cdot 7 + 3\cdot 5\cdot 7\cdot 9 ...$,"Find the sum of: $1 \cdot 3\cdot 5\cdot 7 + 3\cdot 5\cdot 7\cdot 9+...$ till $n$ terms. My attempt: I got the $i^{th}$ term to be $(2i-1)(2i+1)(2i+3)(2i+5)$ Expansion gives: $16i^4 +64i^3+56i^2+-16i-15$ Required: $$\sum\limits_{i=1}^n (16i^4 +64i^3+56i^2+-16i-15) $$ Using summation identities, I got: $\dfrac{16n(n+1)(2n+1)(3n^2+3n-1)}{30}+\dfrac{64n^2(n+1)^2}{4}+\dfrac{56(n)(n+1)(2n+1)}{6}- \dfrac{16n(n+1)}{2}- 15n$ However, answer given is simply $$\frac{1}{10}\{(2n-1)(2n+1)(2n+3)(2n+5)(2n+7)+1\cdot 3\cdot 5\cdot 7\}$$","['algebra-precalculus', 'sequences-and-series']"
2465690,The general solution of $y'=\vert y-t\vert$,"How to solve the following ODE? $$y' = | y-t |$$ To eliminate the absolute value, I divided the domain into two parts $\{ y(t) > t \}$ and $\{ y(t) < t \}$. In $\{y(t)>t\}$, the ODE becomes $y'=y-t$. I found $y_+(t)=Ce^t+t+1$. In $\{y(t)<t\}$, the ODE becomes $y'=-y+t$, so the solution is $y_-(t)=Ce^{-t}+t-1$. How to write the general solution?",['ordinary-differential-equations']
2465705,"If I am told to reparameterize a curve by arc-length, what is the curve originally parameterized by?","In differential geometry, you are often asked to reparameterize a curve using arc-length. I understand the process of how to do this, but I don't understand what we are reparameterizing from. What is the curve originally parameterized by (before we REparameterize it by arc-length)?",['differential-geometry']
2465706,Directional Derivative: why there is no cos($\alpha$) in formula,"I'm learning Directional Derivative on Khan Academy . Here is the definition of Directional Derivative: So the formula for calculating directional derivative is: But as I knew, the dot product should be: I don't understand this point. Please explain for me why the formula for calculating directional derivative doesn't have ""cos($\alpha$)"".","['multivariable-calculus', 'derivatives']"
2465787,Calculate $\iint_D x dxdy$ using polar coordinates,"Using polar coordinates, I want to calculate $\iint_D x dxdy$, where $D$ is the disk with center $(2,3)$ and radius $2$. $$$$ I have done the following: We have $D=\{(x,y)\mid (x-2)^2+(y-3)^2\leq 4\}$. We use $(x,y)=(r\cos \theta, r\sin \theta)$. From the inequality $$(x-2)^2+(y-3)^2\leq 4\Rightarrow x^2-4x+4+y^2-6y+9\leq 4 \Rightarrow x^2+y^2-4x-6y\leq -9$$ we get $$r^2\cos^2\theta+r^2\sin^2\theta-4r\cos\theta-6r\sin\theta\leq -9 \Rightarrow r^2-r(4\cos\theta-6\sin\theta)+9\leq 0$$ 
To find for which values of $r$ that inequality is true, we have to find first the roots of $r^2-r(4\cos\theta-6\sin\theta)+9=0$. The roots are $$2\cos \theta+3\sin\theta\pm \sqrt{12\cos\theta\sin\theta-5\cos^2\theta}$$ Therefore, we get the inequality $r^2-r(4\cos\theta-6\sin\theta)+9\leq 0$ for $$2\cos \theta+3\sin\theta-\sqrt{12\cos\theta\sin\theta-5\cos^2\theta}\leq r\\  \leq 2\cos \theta+3\sin\theta+\sqrt{12\cos\theta\sin\theta-5\cos^2\theta}$$ or not? So, at the integral do we use these limits for $r$ ? And what about $\theta$ ? Does it hold that $0\leq \theta\leq 2\pi$ ?","['multivariable-calculus', 'integration', 'polar-coordinates']"
2465803,What's the probability that a given permutation has exactly $k$ fixed points. [duplicate],"This question already has an answer here : Number of permutations with a fixed point (1 answer) Closed 2 years ago . Given a random permutation $\sigma \in S_n$ from $[n] \to [n]$ in a uniform probability space, what is the probability that $\sigma $ has exactly $k$ fixed points for a given $k$ between $1$ and $n$ ? In other words: what is the probability that $\exists x_1 ,...,x_k \in [n] : \sigma (x_i) = x_i  $ for $\ i\in \{1,...,k\}$ and for every $y \notin \{x_1 , ... , x_k\}$ we get $\sigma(y) \neq y$ . I saw that $\lim_{n \to \infty } prob(A_0) = e^{-1}$ using Inclusion–exclusion principle and i belive that for a given k : $\lim_{n \to \infty} prob(A_k) = \frac{e^{-1}}{k!}$ but I am not sure how to show it. * $A_k$ stands for the event ""k"".","['permutations', 'combinatorics', 'probability', 'derangements']"
2465859,Expected number of throws when encountering a pokemon,"I have a question about using geometric distribution to analyze a spefic issue of the Pokemon Go game. First let me describe the context. When a player throws a ball to catch a pokemon, the success rate is a fixed number p. If the pokemon is not caught by the ball, the probability that it flees is f. If the pokemon does not flee, the player can throw the ball again, and each throw is an independant event. Assuming the player continues to throw balls until either the pokemon is caught or it flees, we would like to calcuatel the expected # of balls the player throws when a pokemon is encountered. I will describe my derivation below, but my result is diffrenet from the well known web site Gamepress, so I'd like to confirm the right answer. There are two conditions: when the player succesds to catch it, and when the pokemon eventually flees. The probability of successfully catching the pokemon is: $$  p + (1-p)(1-f)p + [(1-p)(1-f)]^2p+... $$
$$= p\sum_{x=1}^\infty[(1-p)(1-f)]^{x-1}$$
$$= p\frac{1}{1-(1-p)(1-f)}$$
$$= \frac{p}{p+f-fp}$$ Similary, the probability that the pokemon flees is: $$  (1-p)f + (1-p)(1-f)(1-p)f + (1-p)[(1-f)(1-p)]^2f+... $$
$$= (1-p)f\sum_{x=1}^\infty[(1-p)(1-f)]^{x-1}$$
$$= (1-p)f\frac{1}{1-(1-p)(1-f)}$$
$$= \frac{(1-p)f}{p+f-fp}$$ The expected number of throws at the condition that the pokemon is caught is: $$= p\sum_{x=1}^\infty(x[(1-p)(1-f)]^{x-1})$$
$$= p\frac{d}{dZ}\sum_{x=1}^\infty[Z^x], Z=(1-p)(1-f)$$
$$= p\frac{d}{dZ}\frac{Z}{1-Z}$$
$$= \frac{p}{(1-Z)^2}$$
$$= \frac{p}{(p+f-fp)^2}$$ The expected number of throws when the pokemon flees is: $$= f(1-p)\sum_{x=1}^\infty(x[(1-p)(1-f)]^{x-1})$$
$$= f(1-p)\frac{d}{dZ}\sum_{x=1}^\infty[Z^x], Z=(1-p)(1-f)$$
$$= f(1-p)\frac{d}{dZ}\frac{Z}{1-Z}$$
$$= \frac{f(1-p)}{(1-Z)^2}$$
$$= \frac{f(1-p)}{(p+f-fp)^2}$$ The expected number of throws, without knowing whether the pokemon is caught is The probability of successfully catching the pokemon x The expected number of throws at the condition that the pokemon is caught + the probability that the pokemon flees x The expected number of throws when the pokemon flees: $$ \frac{p}{p+f-fp}\times\frac{p}{(p+f-fp)^2} + \frac{(1-p)f}{p+f-fp}\times\frac{f(1-p)}{(p+f-fp)^2}$$ $$ = \frac{p^2+f^2(1-p)^2}{(p+f-fp)^3}$$ Gamepress does not provide the equation ( https://pokemongo.gamepress.gg/catchcalc#/ ), but it appears it is using the same formula described here: https://www.reddit.com/r/TheSilphRoad/comments/59w7cj/analysis_pok%C3%A9mon_go_catch_calculator_new_tool_to/ Which is $$ \frac{1}{p+f-fp}$$ and appears to be $$ \frac{p}{(p+f-fp)^2} +\frac{f(1-p)}{(p+f-fp)^2}$$ Therefore my question is, which formula is correct, and why? Thanks!",['statistics']
2465869,Why not differentiate the Lagrangian w.r.t a lagrange multiplier?,"I've heard from a reuptable source that it is problematic to differentiate the Lagrangian w.r.t the lagrange multiplier. I know that doing so is rather a waste of time since it just goves you back the constraints $h(x)=A$ that you started with, but this repitable source said that there is an additional reason why it is not only a waste of time but also problematic? Any hints as to why it is problematic?","['multivariable-calculus', 'constraints', 'lagrange-multiplier']"
2465875,Continuously deformation (homotopy) of continuous function into an arbitrary close $C^{\infty}$-function,"Show that a continuous function $f$ can in fact continuously deformed (homotopy) into an arbitrary close $C^{\infty}$-function : There exist a continuous function (""homotopy"")$ H:I\times I \rightarrow \mathbb{R}$  s.t $H(t,0)=f(t) ,t\in I $ and s.t $H(.,s)$ is a class of $C^{\infty}$ for each fixed s, $0<s\leq1$ by uniform continuity (!) of $H$ , $H(.,s)$ will be arbitrarily close to $f=H(.,0)$ provided s is sufficiently small.
$\textbf{I have a hint for this to solve as given}$ Prove this by analyzing the known proof with the polynomial kernel $(1-x^2)^{n}$. The integer exponents n are used to obtain a $\textbf{discrete}$ approximation ( by polynomials ) . How to get a continuous approximation instead ( not necessarily with polynomials ) Please someone Can elaborate that problem in details . I have a hint that I can use $(1-x^2)^{1/s}$ instead of using the kernel  $(1-x^2)^{n}$ But I am unable to get the clear idea how it will work . I will either get a polynomial approximation or something else . If someone can suggest me some reference book to understand it I will be very thankful for it .","['complex-analysis', 'distribution-theory', 'homotopy-theory']"
