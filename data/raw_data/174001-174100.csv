question_id,title,body,tags
3104291,"Need Hint; Show that the Limit Exists when $f\in C^1(0,1)$ and...","The problem is as follows: Assume that $f\in C^1(0,1)$ and $$
\int_{(0,1)}x|f'|^p\,dx<+\infty\qquad\text{for some }p>2.
$$ Show that $\lim_{x\rightarrow 0^+}f(x)$ exists. Note: $C^1(0,1)$ is the space of continuously differentiable functions on $(0,1)$ . What I've considered so far; I know that $x\in C^1(0,1)$ . I know that $f$ is differentiable. I know that the definition of the right-hand limit here will be important (which I have written down on my scratch work). However, I am having difficulty in figuring out where to continue off from here. I think I might be missing some important Theorem.","['banach-spaces', 'analysis', 'real-analysis', 'lp-spaces', 'functional-analysis']"
3104293,Analytical Solution to Nonlinear Second Order ODE,"I'm trying to solve the following nonlinear second order ODE where $a$ and $b$ are constants: $$\frac{d^2y}{dx^2}+\frac{1}{x}\frac{dy}{dx}-\frac{y}{ay+b}=0$$ It looks somewhat like the modified Bessel equation , except the third term on the left makes it nonlinear. I've been trying to determine some way to find an analytical solution but haven't been able to come up with anything. It doesn't help much but it can also be written: $$\frac{1}{x}\frac{d}{dx}\left(x\frac{dy}{dx}\right)=\frac{y}{ay+b}$$ Any suggestions would be greatly appreciated, thanks!","['nonlinear-system', 'ordinary-differential-equations']"
3104304,Proving uniqueness of ODE solution,"The ODE is the following: $\begin{cases}
u''(x) = 0,\\[6pt]
u(0) = a, u'(0) = b
\end{cases}
$ I need to prove that ODE is well-posed and so far I have proven both the existence of the solution and the stability, but I am not sure how to approach the uniqueness problem, assuming I don't know any particular theorems regarding the uniqueness proof. My apologies if this is really trivial. I am not looking for an answer for this problem, but simply for a hint. Thanks.",['ordinary-differential-equations']
3104337,You flip a coin twice and get two heads. What's the probability that the coin is fair?,"I don't know how to approach this other than using Bayes' rule. Let $A$ be the event that the coin is fair and let $B$ be the event of getting two heads. We get $$P(A \mid B) = \frac{P(A\cap B)}{P(B)} = \frac{1/4}{P(B)}.$$ I don't know how to get $P(B)$ . Any suggestions? Also, how would I generalize this -- say, if we get $n$ heads rather than $2$ heads?","['probability-theory', 'probability']"
3104338,"$\frac{1}{3}\sum_{cyc}\frac{1}{\sqrt{1+a}}\ge\frac{1}{\sqrt{1+\sqrt[3]{abc}}}$ if $\;a, b, c\;$ are positive reals s.t. $abc\ge2^9$","$$\frac{1}{3}\sum_{cyc}\frac{1}{\sqrt{1+a}}\ge\frac{1}{\sqrt{1+\sqrt[3]{abc}}}$$ if it is given that $\;a, b, c\;$ are positive reals s.t. $abc\ge2^9$ . I have tried (many) dead-end solutions. Initially setting $\;abc\;$ to be greater than $512$ on the left-hand-side to make it $\frac{1}{3}$ lead to an untrue inequality. Letting $f(x)=\frac{1}{\sqrt{1+x}}$ we find that $LHS=\frac{1}{3}\big(f(a)+f(b)+f(c)\big)$ and, since $f''\ge0$ , $f$ is convex and, by Jensen's inequality, $$\frac{1}{3}\big(f(a)+f(b)+f(c)\big)\ge f\left(\frac{a+b+c}{3}\right)= \frac{1}{\sqrt{1+\frac{a+b+c}{3}}},$$ but the result is no longer greater than the original RHS; it is in fact less than or equal to the original RHS, as can be proven with a simple application of AM-GM. Do you have any hints on what to try next? I feel that I have exhausted all of my ideas at this point. Thanks beforehand!","['contest-math', 'inequality', 'multivariable-calculus', 'substitution', 'holder-inequality']"
3104339,1-form sufficiently $C^1$-close to the zero section,"Question: If $\mu$ is a 1-form sufficiently $C^1$ -close to the zero 1-form, then $$\{(p, \mu_p) ; p \in M, \mu_p \in T_p^*M \}\cong\text{Graph}\  f$$ for some diffeomorphism $f: M \to M$ . Attempt: Let $\sigma_0 : M \hookrightarrow T^*M $ the zero section (1-form) given by $\sigma_0 (p) =  0_p$ . Consider $\mu: M \to T^*M$ a 1-form sufficently $C^1$ -close to $\sigma_0$ , that is, a section of the bundle $T^*M$ ,  let $M' = \mu (M)$ be the image under $\mu$ . Given $p \in M$ , let $(q, 0_q) = \exp (p,\mu_p)$ be the point in $M_0 = \sigma_0 (M)$ given by the exponential map in a neighborhood of $M'$ seen as the zero section of the normal bundle $NM'$ . Define $f : M \to M$ as the composition where $\pi: T^*M \to M$ is the canonical bundle projection. Since $\pi \circ \mu = id_M$ , $\pi \circ \sigma_0 = id_M$ and $\exp$ is a diffeomorphism, $f$ is smooth bijective with smooth inverse $\pi \circ \exp^{-1} \circ \ \sigma_0$ . Identifying $(p,\mu_p) \mapsto (p,f(p))$ gives the desired isomorphism. Is it correct? Is there anything to be improved in the argument?","['vector-bundles', 'symplectic-geometry', 'differential-geometry']"
3104362,When square of an ideal is the square of a maximal ideal in a polynomial ring,"Question (1) Let $J$ be an ideal in $\mathbb C[X,Y]$ such that $J^2=(X,Y)^2$ . Then is it true that $J=(X,Y)$ ? Question (2) Let $J$ be an ideal in $\mathbb C[X,Y,Z]$ such that $J^2=(X,Y,Z)^2$ . Then is it true that $J=(X,Y,Z)$ ? If the answers to any one is no, then a further question would does some extra condition on $J$ (like being homogeneous or monomial, or some bound on $\mu (J)$ ) force $J$ to be equal to the corresponding maximal ideal ? For a similar question, see https://math.stackexchange.com/questions/3101911/ideal-in-local-domain-whose-square-equals-the-square-of-the-maximal-ideal Answer to any part of the questions is very appreciated.
Thanks in advance.","['ring-theory', 'algebraic-geometry', 'commutative-algebra', 'ideals']"
3104417,Is the Hairy Ball Theorem equivalent to saying that the Hopf Fibration has no global sections?,"The Hairy Ball Theorem states that $S^2$ has no nonvanishing tangent vector fields. But if we did have such a field then we could normalise each vector so that it lay on the unit circle of the tangent plane at that point. These unit circles form a bundle over $S^2$ with fibre $S^1$ . The Hairy Ball Theorem is therefore equivalent to saying that this bundle has no global section. Since this is a nontrivial $S^2$ -bundle with fibre $S^1$ I thought that it might be the Hopf Fibration. Is it? If not, what is the total space?","['fiber-bundles', 'hopf-fibration', 'general-topology', 'differential-topology', 'algebraic-topology']"
3104422,How fast the height of the cone is changing?,"Suppose that sand is collecting in the shape of a cone in such a way that the base radius of the cone is always one-third of its height. If $3\,\mathrm{cm^3/min}$ is the rate at which the sand is being added to the cone, how fast is the height of the cone changing when it is $7\,\mathrm{cm}$ tall? I got $Dv/dt=3cm^3 $ and $r=1/3h$ . So I'm looking for $dh/dt$ when $h=7$ . I'm not sure if I'm doing the problem right.","['calculus', 'derivatives', 'geometry', 'volume']"
3104432,Expansion of $n(n-1)(n-2)...(n-k)$,"Is there a way to express the following such that each coefficient of the expansion can be found selectively: $$n(n-1)(n-2)...(n-k)$$ For example, the first term is obviously $n^{k+1}$ and so it's coefficient is $1$ and the last term is $(-1)^k \cdot k! \cdot n$ which has coefficient $(-1)^k \cdot k!$ .
I am attempting to generalise the nth derivative of a probability generating function evaluated at $1$ in terms of $E(X^n)$ and this expansion will allow the result to be generalised.","['algebra-precalculus', 'probability']"
3104437,Counterexample to Lie's second theorem for SO(3),"Lie's second theorem says that if $G$ is a simply connected Lie group, then every isomorphism $\Phi$ of its Lie algebra $\mathfrak{g}$ lifts to an isomorphism $\phi$ of $G$ , i.e. such that $d\phi_e = \Phi$ where we identify $\mathfrak{g}$ with $T_e G$ , the tangent space to $G$ at the identity. Now consider $G = \mathrm{SO}(3)$ , which is not simply connected.  Is there an explicit counterexample to Lie's second theorem in this case?  That is, can we write down a Lie algebra isomorphism $\Phi$ of $\mathfrak{so}(3)$ which is not the differential of any isomorphism $\phi$ of $\mathrm{SO}(3)$ ? I feel like, if $(\eta_1, \eta_2, \eta_3)$ is the usual basis of $\mathfrak{so}(3)$ , where $[\eta_i, \eta_j] = \eta_k$ cyclically, then a map like $\Phi(\eta_1)=\eta_2$ , $\Phi(\eta_2)=\eta_1$ , $\Phi(\eta_3)=-\eta_3$ ought to work, but I can't figure out how to prove there is no such group isomorphism $\phi$ .  I've been trying to find $t_1, t_2, t_3 \in \mathbb{R}$ and a relation involving $(e^{t_1 \eta_1}, e^{t_2 \eta_2}, e^{t_3 \eta_3})$ that is not satisfied by $(e^{t_1 \eta_2}, e^{t_2 \eta_1}, e^{-t_3 \eta_3})$ but I can't come up with one.","['examples-counterexamples', 'lie-algebras', 'lie-groups', 'differential-geometry']"
3104513,"Is it true that $""\exists f: A\to B, \ f\text{ bijective}"" \iff ""\exists f: B\to A, \ f\text{ bijective}""$","Is it true that $$""\exists f: A\to B, \quad f\quad bijective"" \iff ""\exists f: B\to A, \quad f\quad bijective""$$ Is it the same $f$ ? Intuitively I would say yes to both of these questions, but this example got me doubting: Let $f(x)=e^x.$ It is true that $""f:\mathbb{R}\to\mathbb{R}^+, \quad f\quad bijective""$ , since every element in $\mathbb{R^+}$ can be reached (surjective) and from simply looking at the graph follows that it is injective. However, $""f:\mathbb{R^+}\to \mathbb{R}, \quad f \quad bijective""$ does not seem true since we can't reach the negative elements of $\mathbb{R}$ (not surjective). What's going on?",['elementary-set-theory']
3104535,Freaky Polynomial: $P_n(x)=\left(x\frac{d}{dx}\right)^n f(x)$,"I am investigating the polynomial $$P_n(x)=\left(x\frac{d}{dx}\right)^n f(x)=xP_{n-1}'(x)$$ for some known function $f$ . I defined $f_n(x)=\frac{d}{dx}f_{n-1}(x)$ with $P_0=f_0=f$ . And I also defined $$P_n(x)=\sum_{k=1}^{n}C_n(k)x^kf_k(x)$$ And I am interested in finding an explicit form, or at least a recurrence relation for $C_n(k)$ . With manual calculation, I was able to find up through $n=6$ , but I failed to recognize any pattern, so I thought I'd ask for help. For those interested, a 'table' of values: $n=1$ : $$C_1(1)=1$$ $n=2$ : $$C_2(1)=1,\quad C_2(2)=1$$ $n=3$ : $$C_3(1)=1,\quad C_3(2)=3,\quad C_3(3)=1$$ $n=4$ : $$C_4(1)=1,\quad C_4(2)=7,\quad C_4(3)=6,\quad C_4(4)=1$$ $n=5$ : $$C_5(1)=1,\quad C_5(2)=15,\quad C_5(3)=25,\quad C_5(4)=10,\quad C_5(5)=1$$ $n=6$ : $$C_6(1)=1,\quad C_6(2)=31,\quad C_6(3)=90,\quad C_6(4)=65,\quad C_6(5)=15,\quad C_6(6)=1$$ The only pattern I can see is $C_n(1)=C_n(n)=1$ . Also, it is easily shown that, since $P_n=xP_{n-1}'$ , $$\sum_{k=1}^{n}C_n(k)x^kf_k(x)=\sum_{k=1}^{n-1}C_{n-1}(k)x^k\left[f_k(x)+xf_{k+1}(x)\right]$$ Although I'm not sure that helps. I am very lost, please help. Thanks!","['recurrence-relations', 'calculus', 'polynomials', 'sequences-and-series', 'derivatives']"
3104542,Show that eigenvalues are symmetric with respect to the origin,"The matrices that I am considering are $$
M =
\begin{bmatrix}
A & B \\
C & -A^\top
\end{bmatrix},
$$ with $A,B,C\in\mathbb{C}^{n\times n}$ , $C = C^\top$ and $B = B^\top$ . I noticed from numerical calculations that the eigenvalues are symmetric with respect to the origin, i.e., if $\lambda$ is an eigenvalue of $M$ then $-\lambda$ is as well. I have not been able to shown that this has to be the case. Initially I tried to see if I could come up with a similarity transformation which would make it block diagonal, with one block the negative of the other, but with no success. Next I tried to use some tricks to manipulate the determinant, namely I showed that \begin{align}
\det(M - \lambda\,I) &= \det(B) \det((-A^\top - \lambda\,I) B^{-1} (A - \lambda\,I) - C) \\
&= \det(C) \det((A - \lambda\,I) C^{-1} (-A^\top - \lambda\,I) - B) \\
\end{align} assuming that either $\det(B)\neq0$ or $\det(C)\neq0$ . However, this did not seem to bring me any closer to showing that all eigenvalues are mirrored around the imaginary axis.","['matrices', 'symmetric-matrices', 'eigenvalues-eigenvectors']"
3104571,Proof by Induction: $ \sum_{i=1}^{n} i \cdot i! = (n+1)! -1$ [duplicate],"This question already has answers here : Prove by Mathematical Induction: $1(1!) + 2(2!) + \cdot \cdot \cdot +n(n!) = (n+1)!-1$ (4 answers) Closed 5 years ago . I am trying to solve the following proof and could use feedback on if I did it correctly and how to reduce the the second-to-the-last step to get to the last step Use mathematical induction to show that $$ \sum_{i=1}^{n} i \cdot i!
= (n+1)! -1$$ This is my solution: Proceed with induction. When $n=1$ , the left-hand side reduces to 1 and the right-hand side becomes $2!-1 = 1$ . Hence, the identity holds when $n=1$ . Assume that the identity holds when $n=k$ for some integer $n \geq 1$ . That is assume $$ \sum_{i=1}^{k} i \cdot i! = (k+1)!-1$$ For some integer $k \geq 1$ , we want to show that the identity still holds for $n=k+1$ . In other words, we want to show $$ \sum_{i=1}^{k+1} i \cdot i! = (k+2)!-1$$ From the induction hypothesis, we find $$ \sum_{i=1}^{k+1} i \cdot i! = \Bigg(\sum_{i=1}^{k} i \cdot i! \Bigg) + (k+1) \cdot (k+1)! $$ $$ \sum_{i=1}^{k+1} i \cdot i! = (k+1)! -1 + (k+1) \cdot (k+1)! $$ This is where I am stuck. I don't know how to reduce the previous step so that it looks like $$ \sum_{i=1}^{k+1} i \cdot i! = (k+2)! - 1 $$","['proof-writing', 'proof-verification', 'discrete-mathematics']"
3104581,"Why is $(0, \infty)$ an open set and $ [0, \infty)$ a closed set?","Specifically, I don't understand how to think about the infinity part. Closed and open seem to have pretty intuitive definitions when not considering infinity.",['general-topology']
3104587,show this inequality to with $n$ variables inequality,"Let $a_{i}\in R(i=1,2,\cdots,n),n\ge 3$ . such that $a_{i}\ge \dfrac{n}{2-n},\forall i=1,2,\cdots,n$ ,and $$a_{1}+a_{2}+\cdots+a_{n}=n$$ show that $$\sum_{i=1}^{n}\dfrac{1}{a^2_{i}}\ge\sum_{i=1}^{n}\dfrac{1}{a_{i}}$$ my attempt if $n=3$ ,then $a_{1}+a_{2}+a_{3}=3,a_{i}>-3$ ,so we must prove $$\sum (a_{1}a_{2})^2\ge \sum (a_{1}a_{2})$$ since $$\sum(a_{1}a_{2})^2\ge a_{1}a_{2}a_{3}(a_{1}+a_{2}+a_{3})=3a_{1}a_{2}a_{3}$$","['multivariable-calculus', 'inequality', 'real-analysis']"
3104589,Let $f : G → G_1$ be a surjective homomorphism (also called epimorphism) from $G$ to another group $G_1$. Prove that $f(Z(G)) \subseteq Z(G_1)$.,"I am working on a school assignment and have been stuck on this question for some time. Let $f : G \rightarrow G_1$ be a surjective homomorphism (also called epimorphism) from $G$ to another group $G_1$ . Prove that $f(Z(G)) \subseteq Z(G_1)$ I know we start by assuming we have an element in $f(Z(G))$ then showing it is also in $Z(G_1)$ . Also, $Z(G)$ is the center of $G$ , so $Z(G)$ is all the elements of $G$ that commute with all elements in $G$ . But how do we know that if we map the elements of $Z(G)$ to $G_1$ , then their image will also commute with all the elements in $G_1$ ? Does it have something to do with using commutativity with the homomorphism? i.e. $f(gz) = f(g)f(z) = f(zg) = f(z)f(g)$ .","['group-homomorphism', 'group-theory', 'abstract-algebra']"
3104603,Grassmannians as Gelfand Pairs,"Why are $(O(n), O(k) \times O(n-k))$ and $(U(n), U(k) \times U(n-k))$ (corresponding to the real and complex Grassmann manifolds) symmetric Gelfand Pairs? Is this true for $(Sp(n), Sp(k) \times Sp(n-k))$ (quarternions) as well? Also, for a general local field $\mathbb F$ , letting $K(n)$ denote the maximal compact subgroup of $\text{gl}(n,\mathbb F)$ , is $(K(n), K(k) \times K(n-k))$ a symmetric Gelfand pair as well?","['harmonic-analysis', 'representation-theory', 'geometry', 'grassmannian', 'abstract-algebra']"
3104629,Is there an accepted notation for the $n$th sum/integral of a function?,"I'm working on a thesis in image processing at the moment, and wanted to include a portion concerning the methodology for n dimension images (it will include a fully write up and functioning code for 2D and 3D images), and that would involve taking the $n$ th integral of a function of $n$ variables, which in this case would mean the nth sum. For the sum portion, it would something like the sum of $x_1$ from $0$ to $M$ , then the sum of $x_1$ from $0$ to $M$ , and so on with a total of of $N$ summations. Is there any sort of widely accepted convention for annotating this, or should I just put something like sum1 of sum2 /dots then the last sum? edit: specific examples (sorry, didn't know you could use LaTeX here): 2D: $$\sum_{x_1=0}^M \sum_{x_2=0}^M f(x_1,x_2)$$ 3D: $$\sum_{x_1=0}^M \sum_{x_2=0}^M \sum_{x_3=0}^M f(x_1,x_2,x_3)$$ Is there a nicer way to express something like: $$\sum_{x_1=0}^M \sum_{x_2=0}^M \dots \sum_{x_n=0}^M f(x_1,x_2,\dots,x_n)$$","['integration', 'summation', 'functional-analysis']"
3104643,Constructing an odd trigonometric function with no 1st-order term in Taylor expansion,"Is it possible to construct a polynomial $f$ of at least one of (the fewer, the better) $$\sin{x},\cos{x},\sin{y},\cos{y},\sin{z},\cos{z}$$ with the following properties? The smaller degree of $f$ , the better. Hopefully a linear or quadratic one. it's odd. $f(x,y,z)=-f(-x,-y,-z)$ the Taylor expansion of $f$ around $(0,0,z_0)$ (for some nonzero $z_0$ ) has a nonzero constant term but no 1st-order term. For example, $f=a-b\cos{y}=a-b+O(y^2)$ satisfies 1.3. but not 2 while $f=\sin{z}$ satisfies 1.2. but not 3.","['taylor-expansion', 'algebra-precalculus', 'functions', 'trigonometry']"
3104647,Analytical solution for a nonlinear coupled PDE,"I would like to find the solution to this nonlinearly coupled PDE: This is an equation involving quantum mechanics and found in this paper . (Technically these E's are operators, but you can simply treat them as functions of z and t. Also $E^+$ is the conjugate of E so $E^+E = E^2 = E(z, t)^2$ ) According to this paper, with some approximations, this has an analytical solution of the form $$E_{1,2}(z, t) = E_{1,2}(0,t') \exp(i \eta z |E_{2,1}(0, t')|^2)$$ where $t' = t-z/v_g$ If I am reading the paper correctly, the approximations are that $\beta \to 0$ and $F \to 0$ - but I'm not entirely sure. In my attempts to find the solution, I first tried to solve it as an ode (where the time derivatives are zero). $$ E_1'(z) = -k E_1(z) + (i \eta)|E_2|^2 E_1 $$ $$ E_2'(z) = -k E_2(z) + (i \eta)|E_1|^2 E_2 $$ But I'm struggling to even work this out. Any ideas for how I can proceed? EDIT: One of the answers suggests a method at arriving at the solution, and here I'm showing my handwritten attempt at getting a solution using this method. I was successful in finding a solution (maybe with mistakes?) but ended up with an answer that does not match what is described in the text.","['ordinary-differential-equations', 'partial-differential-equations']"
3104664,Proving James' Theorem,"I am reviewing the proof of James theorem, i.e. a Banach space is reflexive iff every continuous linear functional obtains its norm. Every thing I find online shows one direction ( $\Leftarrow$ ), but not ( $\Rightarrow$ ). I am having issues seeing it and any help would be appreciated.",['functional-analysis']
3104688,Method of moments with a Gamma distribution,"I'm more so confused on a specific step in obtaining the MOM than completely obtaining the MOM: Given a random sample of $ Y_1 , Y_2,..., Y_i$ ~ $ Gamma (\alpha , \beta)$ find the MOM So I found the population and sample moments $u_1^{'}= \alpha \beta  $ $ u_2^{'} = \sigma^2 + \mu^2 = \alpha ^2 \beta^2 +  \alpha \beta^2$ $  m_1^{'} = \overline  Y $ $   m_2^{'} = \frac{1}{n} \sum_{i=1}^{n} Y_i^2 $ solving for $ \hat \alpha_{MOM}$ I get $\hat \alpha_{MOM} = \frac{\overline Y}{\beta}$ The solutions say this ends up being equal to: $ \hat \alpha_{MOM} = \frac{\frac{1}{n} (\sum_{i=1}^{n} (Y_i - \overline Y) ^ 2)}{n \overline Y} $ I think I'm forgetting some property because I have no idea how they transformed the initial $ \hat \alpha_{MOM}$ equation into the 2nd $ \hat \alpha_{MOM}$ equation.","['statistics', 'parameter-estimation', 'gamma-distribution']"
3104700,Patterns in inequalities of triangle involving angles.,"I was reading this page and wondered as why, inequalities for $\cos A$ (with argument $A$ ) become the same inequality for $\sin\frac{A}{2}$ (with argument $\frac{A}{2}$ ), similarly for $\tan$ and $\cot$ . Examples, $$\sin\frac{A}{2}\sin\frac{B}{2}\sin\frac{C}{2}\le\frac{1}{8}$$ $$\cos A\cos B\cos C\le\frac{1}{8}$$ and $$\cos (A)+\cos (B)+\cos (C)\le\frac{3}{2}$$ $$\displaystyle\sin\frac{A}{2}+\sin\frac{B}{2}+\sin\frac{C}{2}\le\frac{3}{2}$$ Is there some greater Mathematics involved or just a pretty coincidence?","['trigonometry', 'geometric-inequalities', 'triangles', 'inequality']"
3104728,Curvature inequality involving a Curve within a disk,"If a closed plane curve $C$ is contained inside a disk of radius $r$ , prove that there exists a point $p \in C$ such that the curvature k of C at p satisfies $\lvert k\rvert \ge$ $1/r$ . I understand that the curvature of a circle (or disk) is always 1/r but I don't know how to go about comparing the arbitrary curve to the curvature of the circle. Is there possible a curvature comparison theorem I'm missing because I've been unable to find anything in Stack Exchange or elsewhere?","['plane-curves', 'curves', 'circles', 'curvature', 'differential-geometry']"
3104756,Lee Introduction to smooth manifolds problem 6-4,"Need help with one of the problems in Lee's intro to smooth manifolds. The problem is as follows: (6-4) Let $M$ be a smooth manifold, and $B$ be a closed subset of $M$ , and let $\delta:M\rightarrow\mathbb {R}$ be a positive function. Given any function $f:M\rightarrow \mathbb{R} ^k$ , show that there is a continuous function $\tilde{f}:M\rightarrow \mathbb{R}^k$ that is smooth on $M\setminus B$ and agrees with $f$ on $B$ and is $\delta$ close to $f$ . I think I might have a solution by revising the proof to the Whitney's approximation theorems for functions(theorem 6.21), along with the help of this post Smooth extension of a continuous function on the boundary of a domain . However, Lee provides a hint to use problem 6.3, which says under the same assumptions, we can find a smooth function $\tilde{\delta}:M\rightarrow\mathbb{R}$ that is zero on $B$ , positive on $M\setminus B$ , and satisfies $\tilde{\delta}(x)<\delta(x)$ everywhere. My question is : how to use 6.3 to show 6.4? The crucial difficulty is that $f$ is not assumed to smooth on $B$ in 6.4. Any help is immensely appreciated, this is not a homework question.","['manifolds', 'smooth-manifolds', 'differential-geometry']"
3104797,Are the following statements always true?,"I keep getting true for the following statements when testing them, but I've never been good with proof by contradiction, so I was wondering if anyone could help me out with the following: 1) For all sets $A$ and $B, A − (B − A) = A.$ 2) For all sets $A$ , $B$ and $C$ , $A \cup (B − C) = (A \cup B) − C.$",['elementary-set-theory']
3104801,Solving $\sin (100^\circ-x) \sin 20^\circ =\sin (80^\circ-x)\sin 80^\circ$,"Solve for $x$ such that $$\sin (100^\circ-x) \sin 20^\circ =\sin (80^\circ-x)\sin 80^\circ$$ First, I use the co-function formula: $$\sin 80^\circ = \cos 10^\circ \tag{1}$$ Also, $$\sin 20^\circ = 2\sin 10^\circ \cos 10^\circ \tag{2}$$ From these, I got $$\sin(100^\circ-x)\cdot 2\sin 10^\circ =\sin (80^\circ-x) \tag{3}$$ I thought to use $$2\sin a \sin b =\cos(a-b)-\cos(a+b) \tag{4}$$ but I'm stuck. Help me please.",['trigonometry']
3104833,How can I prove $\frac {d}{dx} {x^n} = n x^{n-1}$ for $ n \in \Bbb R$ without circular reasoning? [duplicate],"This question already has answers here : Prove that the derivative of $x^w$ is $w x^{w-1}$ for real $w$ (10 answers) Closed 5 years ago . I just cannot prove that $$\frac {d}{dx} {x^n} = n x^{n-1}$$ for $ n  \in \Bbb R$ . For $n \in \Bbb{N}$ , I can use the definition of a derivative : $$\frac {d}{dx}x^n = \lim_{h \rightarrow 0} \frac{(x+h)^n - x^n}{h}$$ Now applying ""Binomial Expansion"" for $\displaystyle (x+h)^n=\sum_{i=0}^{n}{n \choose i }x^{n-i}h^i$ and expanding, the $x^n$ term in the numerator cancels out and the $h$ from denominator divides the entire remaining expression . Taking limit $h$ tending to $0$ gives the required result. I have been taught that the derivative result holds for all real $n$ . But I am not aware of any ""formula"" which can allow me to expand a binomial expression with real index. I do know about the Taylor Expansion, but if I remember correctly, it utilises the very derivative that I am trying to find. How can I proceed ?","['limits', 'calculus', 'binomial-theorem', 'taylor-expansion']"
3104839,Prove that for all $n\ge2\in\mathbb{Z}$ and $p$ is prime then $n^{p^p}+p^p$ is composite.,"Prove that for all $n\ge2\in\mathbb{Z}$ and $p$ is prime then $n^{p^p}+p^p$ is composite. This question has been on my mind for some time now, and I needed some help.
What I have attempted so far:
If $p=2$ then $$n^4+4=(n^2+2n+2)(n^2-2n+2).$$ Since $n\ge 2$ , both parentheses are larger than $1$ and therefore this number is composite. If $p\gt2$ , $$n^{p^p}=(n^{p^{p-1}})^p.$$ Let $p^{p-1}=x \therefore n^{p^{p-1}}=n^x.$ Now we get that $$n^{p^p}+p^p=(n^x)^p+p^p.$$ Since $p$ is odd, then we can say that that equals $$(n^x+p)((n^x)^{p-1}-(n^x)^{p-2}p+\dots+p^{p-1}).$$ Now $n^x+p\gt1$ , but I got stuck with trying to prove that the right paranthesis is greater than $1$ . Any help would be appreciated.","['elementary-number-theory', 'algebra-precalculus', 'factoring']"
3104850,"$f : S \rightarrow S$ is called cool, if for all elements $x$ of $S ,$ $f ( f ( f ( x ) ) ) = x$","Let $n \geq 1$ be an integer and consider a set $S$ consisting of $n$ numbers. $A$ function $f : S \rightarrow S$ is called cool, if for all elements $x$ of $S$ $f ( f ( f ( x ) ) ) = x$ Let $A _ { n }$ be the number of cool functions $f : S \rightarrow S$ . $\bullet$ Let $f : S \rightarrow S$ be a cool function, and let $x$ be an element of $S$ . Prove that the set $\{ x , f ( x ) , f ( f ( x ) ) \}$ has size 1 or $3 .$ $\bullet$ Let $f : S \rightarrow S$ be a cool function, and let $x$ and $y$ be two distinct elements of $S$ .
Assume that $f ( y ) = y .$ Prove that $f ( x ) \neq y$ $\begin{aligned} \bullet \text { Prove that for any integer } n & \geq 4 \\ A _ { n } & = A _ { n - 1 } + ( n - 1 ) ( n - 2 ) \cdot A _ { n - 3 } \end{aligned}$ Hint: Let $y$ be the largest element in $S$ . Some cool functions $f$ have the property that $f ( y ) = y ,$ whereas some other cool functions $f$ have the property that $f ( y ) \neq y .$ $\textbf{My Solutions}$ (a) $Let \quad T = \left\{ x ,f ( x ) , f ( f ( x ) ) \right\}$ have size 1 Then all three of them are the same $\therefore$ let $x = f ( x ) = f ( f ( x ) )$ $\Rightarrow f ( f ( f ( x ) ) ) = f ( f ( x ) ) \quad \because f ( x ) = x$ $= x \quad \quad \because f ( f ( x ) ) = x$ since it meets the condition $f ( f ( f ( x ) ) ) = x$ Then T can have size 1 Let $T = \left\{ x , f ( x ) , f ( f ( x ) ) \right\}$ have size 2
Then any two of them are the same Case 1 $x = f ( x ) \neq f ( f ( x ) )$ $f ( f ( x ) ) = f ( x ) \quad \because f ( x ) = x$ $= x \quad$ contradiction case 2 $x \neq f ( x ) = f ( f ( x ) )$ $f ( f ( x ) ) = f ( f ( f ( x ) ) ) \quad \because f ( x ) = f ( f ( x ) )$ $= x$ $\because$ elements $x$ of $S$ in cool are such that $f ( f ( f ( x ) ) ) = x$ hence contradiction case 3 $f ( x ) \neq f ( f ( x ) ) = x$ $f ( f ( x ) ) = x = f ( f ( f ( x ) ) )$ $\because$ function cool is such that all elements $x$ of $S$ are such that $f ( f ( f ( x ) ) ) = x$ $f ( f ( x ) ) = f ( f ( f ( x ) ) )$ $f ( x ) = f ( f ( x ) ) \quad \cdot f ( a ) = f ( b ) \Rightarrow a = b$ contradiction Then T cannot have a size of 2 Let $T = \{ x , f ( x ) , f ( f ( x ) ) \}$ have size 3 Then all three are different,Let $x \neq f ( x ) \neq f ( f ( x ) )$ Hence $T$ can have a size of $3$ (b) Assume that $f ( y ) = y , x$ and $y$ are distinct elements Let $f ( x ) = y$ Since all elements $x$ of $S$ for the cool function adhere to to $f ( f ( f ( x ) ) ) = x$ $f ( f ( f ( x ) ) ) = f ( f ( y ) ) \quad \because \quad f ( x ) = y$ $= f ( y ) \quad  \quad \because f ( y ) = y$ $= y \quad \because \quad f ( y ) = y$ Since $f ( f ( f ( x ) ) ) = x$ this implies $x=y$ but we stated that $x$ and $y$ are distinct elements hence contradiction $\Rightarrow f ( x ) \neq y$ (c) Not sure how to do this one TL;DR I'm not sure if (a) is 100% correct confident with (b) Very lost on (c)","['permutations', 'functions']"
3104851,Proof verification - application of Girsanov to Brownian running max with nonzero drift,"Let $B_t$ be a standard BM w.r.t. $(\Omega, \{\mathcal F_t\}, \Bbb P)$ , $\mu$ a constant, $X_t:=\mu t+ B_t$ , and $M_t:=\max_{0\le\tau\le t} X_\tau$ . Find $\Bbb P(M_t\le a)$ for $a\ge 0$ . I have used the Girsanov's theorem to find that $$\Bbb P(M_t \le a)=2\left(\Phi\left(\frac{a - \mu t}{\sqrt{t}}\right) - \Phi\left(-\frac{\mu t}{\sqrt{t}}\right)\right)$$ where $\Phi$ is the CDF of standard normal. But I'm not exactly sure whether my approach is sound, especially about the application of the Girsanov. Would you please check if there's anything wrong? Thanks. Proof : By Girsanov's theorem, if we let $$E_t:=\exp(-\mu B_t - \frac12\mu^2t)$$ Then under the equivalent measure $\Bbb Q$ defined by the Radon-Nikodym derivative $d\Bbb Q = E_td\Bbb P$ , we have $X_t=\mu t+ B_t$ is a standard Brownian motion. We thus denote $B_t^{\Bbb Q} := X_t$ . And we know that under $\Bbb Q$ , the distribution of $M_t$ would be particularly simple, i.e. $$\Bbb Q(M_t\le a) = \Bbb Q(|B_t^{\Bbb Q}|\le a)=\Phi(a/\sqrt{t})-\Phi(-a/\sqrt{t})$$ Thus it is desirable to compute everything under $\Bbb Q$ . However, we are asked to compute the probability under $\Bbb P$ . So we will need the inverse Radon Nikodym derivative $d\Bbb P/d\Bbb Q$ . Now comes what I'm not very sure of: noting that $B_t=B_t^{\Bbb Q} - \mu t$ , we have $$\frac{d\Bbb P}{d\Bbb Q} = \exp(\mu B_t^{\Bbb Q} - \frac12\mu^2t).$$ Can we invert RN derivative like this? If not, then how? Assuming the above inversion is correct. We then have $$
\begin{align}
\Bbb P(M_t\le a) &= \int_{\{M_t\le a\}}d\Bbb P = \int_{\{M_t\le a\}}\frac{d\Bbb P}{d\Bbb Q} d\Bbb Q = \int_{M_t\le a}\exp(\mu B_t^{\Bbb Q} - \frac12\mu^2t)d\Bbb Q\\
&=\int_{\max_{0\le\tau\le t}B_\tau^{\Bbb Q}\le a}\exp(\mu B_t^{\Bbb Q} - \frac12\mu^2t)d\Bbb Q\\
&=\int_0^a \exp(\mu x - \frac12\mu^2t)f(x) dx
\end{align}
$$ where $f(x)$ is the PDF of the scaled half normal $\sqrt{t}|Z|$ where $Z\sim N(0,1)$ . Explicitly, we have that $f(x) = 2h(x)$ where $h(x):=(2\pi t)^{-1/2}\exp(-x^2/2t)$ is the PDF of $\sqrt{t}|Z|$ . Thus $$
\begin{align}
\Bbb P(M_t\le a) &=  2\int_0^a \exp(\mu x - \frac12\mu^2t)h(x) dx\\
& =2\Bbb P(\sqrt{t}Z+\mu t\in [0,a])\\
& = 2\left(\Phi\left(\frac{a - \mu t}{\sqrt{t}}\right) - \Phi\left(-\frac{\mu t}{\sqrt{t}}\right)\right)
\end{align}
$$","['proof-verification', 'stochastic-processes', 'brownian-motion', 'probability-theory', 'probability']"
3104854,How $H \cap P$ is a Sylow $p$-subgroup of $H$?,"I recently came across the following problem : True or false: If $P$ is a Sylow $p$ -subgroup of a finite group $G$ , then for any subgroup $H$ of $G$ , $H \cap P$ is a Sylow $p$ -subgroup of $H$ . The statement is false. For, take $G=S_3$ , $P=\{e,(13)\}$ and $H=\{e,(12)\}$ . Note that $P$ is the Sylow $2$ -subgroup of $G$ . Here $$H \cap P=\{e\}$$ but $\{e\}$ is not a Sylow $2$ -Sylow subgroup of $H$ . Am I correct? What is the importance of this(true/false) statement if any ?Any help?","['group-theory', 'abstract-algebra']"
3104867,Confusion about differentiability of a function between finite dimensional Banach spaces,"I'm a little bit confused about something that should actually be simple. If we have a function f between finite dimensional Banach spaces. Then we have the implications: If f is partially differentiable with continuous partial derivatives, then f is continuously differentiable, in particular, f is (totally) differentiable. However, the opposite implication is not true: There are functions that are differentiable, but don't have continuous partial derivatives. My confusion is about how continuous differentiability ties in. Since the derivative of f in any point is given as a linear function, this function between (finite dimensional!) Banach spaces should be continuous. But the function that maps any point to it's derivative doesn't have to be linear, so it doesn't have to be continuous either. Is that right? Otherwise (total) differentiability would imply continuous differentiability. So my last question is: Is, then, continuous differentiability equivalent to partial continuous differentiability? I feel silly even asking this, but I couldn't find any explicit explanation.",['analysis']
3104890,ways of selecting consecutive persons sitting at a table,"I'm trying to solve the following problem: Ten people are sitting around a round table. Three of them are chosen
  at random to give a presentation. What is the probability that the
  three chosen people were sitting in consecutive seats? I got the wrong answer but cannot see the error in my reasoning.  This is how I see it: 1) the selection of the first person is unconstrained. 2) the next person must be selected from the 2 spots adjacent to the first.  So this choice is limited to 2/9 of the possible choices. 3) the third choice must be taken from the one free spot next to the first person chosen, or the one free spot next to the 2nd person chosen.  So this choice is limited to 2/8 of the possible choices. 4) multiplying these we get: 2/9 * 2/8 = 1/18 However, the official answer is: Let's count as our outcomes the ways to select 3 people without regard
  to order. There are $\binom{10}{3} = 120$ ways to select any 3 people.
  The number of successful outcomes is the number of ways to select 3
  consecutive people. There are only 10 ways to do this -- think of
  first selecting the middle person, then we take his or her two
  neighbors. Therefore, the probability is $\frac{10}{120} =
> \boxed{\frac{1}{12}}$ .","['combinations', 'combinatorics']"
3104937,"We have two red, two white and two green marbles in an urn","We have two red, two white and two green marbles in an urn. We pick them one by one out of the urn and record their colors. Find the probability that at some point we will pick the same color back to back. For example, this happens
  when we get the sequence red, white, white, green, red, green, but also if we get red, red, white, white, green, green.) So far I have the following. Note that if we think about this problem as a sequence $(x_1,x_2,x_3,x_4,x_5,x_6)$ of the balls. Note that if we fix one of the balls, then we have a $\large\frac{4}{5}\cdot\frac{3}{4}$ chance of not picking the same color next to it. hence the probability of picking two consecutive balls of the same color is equal to $\large 1-\frac{3}{5}=\frac{2}{5}.$ However I am not confident in my reasoning and I think I have made a mistake. Any help is much appreciated.",['probability']
3104959,EGMO Problem 3.20 (BAMO 2013/3),"The problem statement follows: Let $H$ be the orthocenter of an acute angle triangle $ABC$ . Consider the circumcenters of triangles $ABH$ , $ BCH$ , and $CAH$ . Prove that they are the vertices of a triangle that is congruent to $ABC$ . So I first showed that the orthocenter of $ABC$ is the circumcenter of the second triangle, $A'B'C'$ and the circumcenter of $ABC$ is the orthocenter of $A'B'C'$ . Next if we take a homothety $h$ at $N_9$ of $ABC$ with scale factor $-1$ , this will send $H$ to $O$ and vice versa and we'll get a congruent triangle. But my question is, how do I prove that the triangle formed by taking the homothety is the very triangle in the question, namely $A'B'C'$ ?","['contest-math', 'euclidean-geometry', 'geometry', 'triangles', 'geometric-transformation']"
3104984,How to define convergence in probability in topological spaces?,"I want to expand on the question already posed here: Does convergence in probability w.r.t. a topology make sense? . Suppose we have a probability space $(\Omega,\mathcal{F},\mathbb{P})$ and a topological space $(E,\tau)$ , which is a measurable space once endowed with the Borel $\sigma$ -algebra $\mathcal{B}(\tau)$ . Given a sequence $\{X_n\}$ of $E$ -valued random variables, we can then try to define convergence in probability for such a sequence. In the aforementioned question, it is proposed to use the characterization "" $X_n\to X$ in probability iff every subsequence contains a subsequence converging $\mathbb{P}$ -a.s."", since the notion of convergence only relies on the topology (i.e. no metric structure is required). However, if the space $E$ is a bit more structured, like being a topological vector space, then one could say that "" $X_n\to X$ in probability iff $X_n-X\to 0$ in probability"", where by the latter we mean that \begin{equation}
\mathbb{P}(X_n-X\in U)\to 1\ \text{ as }\ n\to\infty\ \text{ for every } U \text{ neighbourhood of } 0
\end{equation} So a first possible question is: in this case, under which assumptions on $\tau$ the two notions are equivalent? I know that under some assumptions the topological vector space becomes metrizable and so the answer in that case becomes trivial, so I'm referring to ""the other cases"". Take for instance the following case: $E$ is an infinite dimensional, countable Hilbert space. On $E$ we have the natural topology induced by the inner product, but we can take instead the weak topology $\sigma(E,E^\ast)$ induced by such inner product. Then the weak topology is not metrizable, but it is locally metrizable (i.e. when restricted to closed balls $B(0,R)$ ) and the Borel $\sigma$ algebra generated is the same generated by the strong topology. So in this case, both of the above definitions are meaningful; do they coincide? Are there any other references in the literature to this, or similar definition, than those already given in the aforementioned question?","['convergence-divergence', 'topological-vector-spaces', 'probability-theory']"
3105024,Proving $\left(1+\frac{1}{m}\right)^m < \left(1+\frac{1}{n}\right)^n$,"Let $m,n\in \mathbb{N}$ . If $m > n$ show that $$\left(1+\frac{1}{m}\right)^m > \left(1+\frac{1}{n}\right)^n$$ My works: I tried to show if $g(x)=\left(1+\frac{1}{x}\right)^x$ then $g'(x) > 0$ . \begin{align}
g'(x) &= \frac{d e^ { x \ln(1+\frac{1}{x}) }} {dx} \\
&= e^{x\ln(1+1/x)} \left(\ln(1+\frac{1}{x}) - \frac{1}{1+x} \right) >0
\end{align}","['calculus', 'combinatorics', 'inequality']"
3105026,Characterisation of point-mass distributions,"Let X be non-empty and consider $a : X → [0,+\infty]$ . We define $\mu : 2^X → [0,\infty] $ by $$\mu(E)=\sum_{x\in E} a(x)$$ for every $E\subset X$ .
  The measure ( proposition easy to prove ) on $(X,2^X)$ defined above is called the point-mass distribution on X induced by the function a . I am trying to solve the following exercise Let $X\neq\emptyset$ . Prove that every measure $\mu$ on $(X,2^X)$ is a point-mass distribution. So we want to define a function $a$ on X such that $$\mu(E)=\sum_{x\in E} a(x)$$ for every $E\subset X$ . If the set X is at most countable this obvious. We just have to take $a(x)=\mu(\{x\})$ , for every $x\in E$ and use the countable additivity of the measure to gain the result, since $E=\cup_{x\in E}\{x\}$ . But we can't use the same argument in the general case. Which is my question. Also, in order to solve the exercise, I tried to find the point-mass distribution for a specific measure on a general non-empty set X. So I considered the measure $\mu(E)=0$ , if $E$ is countable or else is $+\infty$ . Which confused me more.",['measure-theory']
3105027,"Another marble and urn problem, this time to $\infty$","We have an urn with two marbles numbered $1$ and $2.$ We pick a marble randomly, write down its number and return it to the urn. Then we add a marble with the number 3 to the urn, choose one of the three marbles randomly, record its number and return it to the urn. We repeat this over and over: before the $(k+ 1)$ st pick we add a marble with with the number $k + 2$ in the urn (so that it contains the numbers $1, \dots , k + 2)$ , choose a marble randomly, record its number (that's the $(k + 1)$ st pick) and return it to the urn. At the end of the experiment we have an infinite sequence of integers. Show that with probability one the marble with the number $1$ will be picked at some point. It was recommended to break up the event into disjoint pieces. But I have no idea how to do this. Also, does this mean that all drawings must give a different number, with say $1$ in the $n$ th draw? Any hints are much appreciated.","['probability-theory', 'probability']"
3105034,Integration on manifolds?,"To integrate we need a measure . A measure is a set function, $\mu$ , which takes sets as arguments and spits out elements of $\mathbb{R}^*$ (positive real number with infinity included as a point). We write $\int f d\mu$ for the integral of a function $f$ -approximated by step functions- to mean $\sum \alpha_i \mu(A_i)$ ; where $\alpha_i$ are the values the step function assumes, and $A_i=f^{-1}\{(\alpha_i)\}$ the set of all $x$ that get mapped to that fixed value. How do we reconcile this picture with the fact that we can integrate differential forms, $\int A_\mu dx^\mu$ . The coordinate function $x^\mu$ is obviously not a set function, hence not a measure. What is even the meaning of $\int A_\mu dx^\mu$ ? Do we break up $A_\mu$ into a sequence of step functions? How do we define the measure?","['manifolds', 'measure-theory']"
3105054,The limit of $f(x) = \begin{cases} x & x\text{ rational} \\ -x & x\text{ irrational}\end{cases}.$,"Let $f : \mathbb{R} \to \mathbb{R}$ be a function defined by $$f(x) = \begin{cases} x & x\in \mathbb{Q} \\ -x & x \in \mathbb{Q}^c \end{cases}.$$ prove that $\lim_{x \to c} f(x)$ exists iff $c=0$ . 1) Suppose that $c=0$ , $\epsilon >0$ , and choose $\delta = \epsilon$ . If $0<|x-0|< \delta$ then $|f(x)-0|=|f(x)|=|x|<\epsilon$ By definition of the limit this means that $\lim_{x \to 0} f(x)=0$ 2) Let $\lim_{x \to c} f(x)$ exists, say $L$ , and we want to show that $c=0$ . $\lim_{x \to c} f(x)=L$ , this means that $\forall \epsilon >0, \exists \delta >0, |x-c|<\delta$ then $|f(x)-L|<\epsilon$ How can I complete that, please?","['limits', 'real-analysis']"
3105092,"Proof $\langle v,w\rangle=0\implies \langle Av,Aw\rangle=0$, given $A\in F^{m\times n}, \operatorname{rank}(A)=n$.","Given two vectors $v,w$ orthogonal, and a matrix $A$ which has orthogonal columns, how to prove that $\langle Av,Aw \rangle=0$ , i.e. their image is orthogonal?","['matrices', 'inner-products', 'linear-algebra', 'orthogonality']"
3105110,Prove that $4^n>{2n\choose n}$ [other version: $(2n!)<2^{2n}(n!)^2$],"$(4)^n$ > ${2n\choose n}$ I have attempted to prove this by placing it as $(4)^n$ = $(1+1)^n$ with another square like $2^{2n},$ since I can't write it properly; then I used the formula for ${2n\choose n}$ which I separated into a sum, ${2n\choose 0}$ + ${2n\choose 1}$ + ... + ${2n\choose n}$ , but I still came to the wrong conclusion that $(4)^n$ > $(4)^n$ ,
so could you please lend a hand?","['binomial-coefficients', 'discrete-mathematics']"
3105111,"For what metric spaces $(X, d) \ \exists s > 0$ s.t for all $\epsilon < s$ and all $x \in X$, we have $\text{diam}(B_d(x, \epsilon)) = 2\epsilon$?","I was trying to prove that, in general, the diameter of an open ball $B_d(x, \epsilon)$ in a metric space $(X, d)$ is equal to $2\epsilon$ . It then occurred to me that this is not the case if the metric induces the discrete topology, so one necessary (but probably not sufficient) condition is that $d$ doesn't induce the discrete topology. A trivial example of where this is true is $\mathbb{R}^n$ with the euclidean metric. So, what can we impose to make sure that the diameters are exactly twice the radius? Observation: if $A\subset X$ is bounded, the diameter of $A$ is $:= \displaystyle{\sup_{a_1, a_2 \in A} d(a_1, a_2)}$ EDIT: to the people voting to close the question - could you at least mention your reasons in a comment? It's hard to know just what I'm doing wrong otherwise... EDIT 2: It's been brought to my attention that maybe the initial question isn't that interesting so I've edited the title. Still, if we could find a necessary and sufficient condition, that would be super nice!","['general-topology', 'metric-spaces', 'real-analysis']"
3105125,Series power function over exponential function,"A typical exercise from calculus is to show that any exponential function eventually grows faster than any power function, i.e. $$ \lim_{k \to \infty} \frac{k^a}{b^k} = 0 \qquad \text{ for } a,b>1.$$ In fact, by the ratio test, we can show for $x=a=b$ the even stronger result that the series $$ \sum_{k=1}^\infty \frac{k^x}{x^k} $$ converges for any $x \in (1,\infty)$ . This gave me the idea to consider the function $F\colon (1,\infty) \to \mathbb{R}$ defined by $$ F(x) = \sum_{k=1}^\infty \frac{k^x}{x^k} \qquad \text{for } x \in (1,\infty).$$ Now I am curious what properties I can find for this function, but my literature search so far didn't give really fitting results. Is there a name for this function? For integer arguments I could already use the relation $$ F(n) = \text{Li}_{-n}\left(\frac{1}{n}\right), \qquad n \in \mathbb{N}$$ with $\text{Li}$ the polylogarithm to find the representation $$ F(n) = \frac{n}{(n-1)^{n+1}}A_n(n), $$ where $A_n$ is the $n$ -th Eulerian polynomial . Furthermore, $F$ seems to have a global minimum at around $$ x = 3.1200906359597\ldots \quad \text{with} \quad F(x)=4.1125402415512\ldots$$ that I found by bisection. The above results gave me hope that there is a closed formula for this minimum as well, e.g. something in terms of elementary functions, but I can't really figure it out. Any ideas?","['real-analysis', 'polylogarithm', 'sequences-and-series', 'optimization', 'eulerian-numbers']"
3105156,How to find the solution of this second order differential equation with the time-varying coefficients?,"Does this second order differential equation with the time-varying coefficient fit into any general form? $${d^2x(t)\over dt^2}+\Big(k_1+k_2\cos(\omega t)\Big){dx(t)\over dt}+\Big({1\over 1+k_\Delta \sin(\omega t)}+k_3 \cos(\omega t)\Big)
x(t)=F(t)$$ Some properties of the coefficients - $k_1$ and $k_2$ are in similar orders of magnitude and $k_\Delta<<1$ . How can we find the solution of this kind? Otherwise, how can we analyze the characteristics of a system governed by this? For instance, conditions for damping when we don't have any input excitation i.e., $F(t)=0$ , or when we have a harmonic excitation i.e., $F(t)=A \sin(\omega_0 t)$ ? Update 1 I understand that if we can get rid of the coefficient in $x'$ term (or remove the time dependency), then the equation can be reduced to a form of the Hill equation . Now, I am trying to do a variable substitution that is similar to this answer . Update 2 Thanks for the comments and suggestions so far.. From this answer , I understand that having a closed form of a solution would be really challenging (or even impossible). Now, I am trying to do some simplifications and my equation can be reduced to $${d^2x(t)\over dt^2}+\Big(k_1+k_2\cos(\omega t)\Big){dx(t)\over dt}+k_3 
x(t)=F(t)$$ It looks much simpler than the initial version, however, still I could not find any general form similar to this. Analytical solvers could not solve it either. Now, I am only interested in analyzing the characteristics of the system behavior. For example, I can see from numerical simulations that $x(t)$ will have a growing (close to exponential) oscillations when $k_2/k_1>\rm{a~threshold}$ , and otherwise stable oscillations.  But I could not find such relation analytically. Any suggestions to move forward from here is highly appreciated.",['ordinary-differential-equations']
3105190,"Find all values of $p-q$ if $p, q$ are prime and ${q+1\over q}+{p\over p+1}={2n\over n+2}$ where $n$ is a positive integer.","Find all values of $q-p$ if $p, q$ are prime and $${q+1\over q}+{p\over p+1}={2n\over n+2}$$ where $n$ is a positive integer. This problem is a hard problem in my opinion and I am trying to solve it but cannot. I tried to simplify this equation by multiplying by $q(p+1)$ but after later simplification, I got the following: $$2qp+2p+2q=nq-np$$ I couldn't benefit from this. I then tried to use this $2qp+2p+2q=2(1+q)(1+p)-2$ but couldn't. Any help, maybe a hint, would be appreciated. Thank you.","['elementary-number-theory', 'divisibility', 'discrete-mathematics']"
3105198,A Banach space that satisfies parallelogram law is a Hilbert space,"A Banach space that satisfies parallelogram law is a Hilbert space. I know the definitions of the space and also the law, but have no idea about how to use it to prove this fact. Thanks in advance for help!",['functional-analysis']
3105222,"Study convergence of $x_{n+1} = x_n^2 + 3x_n + 1$, where $x_1 = a$, and $a$ takes different values and find its limit.","Given a recurrence relation: $$
x_{n+1} = x_n^2 + 3x_n + 1 \\
x_1 = a\\
n\in\Bbb N
$$ Figure out whether this sequence has a limit (either finite or infinite) and find it for: $$
\begin{align*}
a = -{5\over 4}\tag1 \\
a = -{3\over 4}\tag2
\end{align*}
$$ Start with case $(1)$ . It took some time to notice but seems like the sequence is monotonically increasing no matter what initial conditions are given. That is because: $$
x_{n+1} = x_n^2 + 3x_n + 1 \iff x_{n+1}-x_n = x_n^2 + 2x_n + 1 = (x_n+1)^2>0
$$ Than means: $$
x_{n+1} - x_n > 0 \iff x_{n+1} > x_n
$$ That observation is crucial for all the next steps. In $(1)$ we are given that: $$
x_1 = a = -{5\over 4} > -2
$$ By monotonicity of $x_n$ : $$
\forall n\in\Bbb N : x_n > -2
$$ Let's suppose the limit exists. Then by finding fixed points of the recurrence we may get an insight of what that limit might be: $$
L = L^2 + 3L + 1 \iff (L+1)^2 = 0 \iff L = -1
$$ Thus the only possible finite limit in $\Bbb R$ is $L=-1$ . Let's try to bound $x_n$ above. Using induction: $$
x_1 < x_2 = -{19\over 16}  < -1
$$ Suppose $x_n < -1$ . Then: $$
x_n \in (-2; -1) \implies \underbrace{(x_n + 1)^2 + x_n}_{x_{n+1}} \in (-2, -1)
$$ Thus it follows that $x_{n+1} < -1$ . Now by monotone convergence theorem a monotonic bounded sequence has a limit. Therefore: $$
\boxed{\lim_{n\to\infty}x_n = -1}
$$ This case is more of a headache. Given $a = -{3\over 4}$ makes the sequence diverge to $+\infty$ . But to show this I had to calculate the value for $6$ first terms. It follows that: $$
\forall n \ge 6: x_n > 0
$$ Moreover: $$
\forall n \ge 7: x_n > 1
$$ So: $$
\boxed{\lim_{n\to\infty}x_n = +\infty}
$$ Does there exist a more elegant way to solve for case $(2)$ ? Also is this argumentation enough to show what's requested in question section? I have doubts about the second case. Because formally I should have shown that the sequence is not bounded, not sure how to do it. And the solution is ugly. Here is a sandbox I've been using to play around with the recurrence . Could you please verify the above and point to the mistakes just in case? Thank you!","['proof-verification', 'sequences-and-series', 'recurrence-relations', 'real-analysis']"
3105227,Unit ball of $X^{**}$ is weakly compact!,"Is it true that the closed unit ball in $X^{**}$ is compact with respect to the weak topology on $X^{**}$ , where $X$ is a Banach space? If so, how can we prove it?","['normed-spaces', 'functional-analysis', 'weak-convergence', 'weak-topology']"
3105277,Can we study representation of $p$-adic group by studying $p$-adic Lie algebra?,"While I'm studying about representation theory of $\mathrm{GL}(2)$ over local fields, I found that there's no one talking about $p$ -adic Lie algebra. However, for Lie groups over $\mathbb{R}$ or $\mathbb{C}$ , it is common to study the Lie algebra representation first, and then study the representation of Lie group using the results in Lie algebra. I want to know if there's any reference about representation theory of $p$ -adic Lie algebra that helps to study the representation of $p$ -adic Lie groups, such as $\mathrm{GL}(2, \mathbb{Q}_{p})$ . Maybe there's some technical problem with $p$ -adic Lie stuff, since the exponential map can't be defined on whole Lie algebra (since they do not converge), but they still converge locally, as I know. Also, to define $p$ -adic Lie algebra of given $p$ -adic Lie group, since I don't know much about these, let's just assume that $G = \mathrm{GL}(2, \mathbb{Q}_{p})$ and $\mathfrak{g} = \mathfrak{gl}(2, \mathbb{Q}_{p})$ , where the latter one is just $2\times 2$ matrices over $\mathbb{Q}_{p}$ with a Lie bracket given by $[A, B] = AB-BA$ .","['lie-algebras', 'number-theory', 'p-adic-number-theory', 'representation-theory', 'lie-groups']"
3105283,Determine if exists a subgroup of order $3$ of $H=\langle\sigma^{8440}\rangle$,"Consider the following permutation of $S_{13}$ . $\sigma=(1\;3\;13\;5\;11\;8)(2\;10\;4\;6\;12\;7\;9)$ Determine if exists a subgroup of order 3 of $H=\langle\sigma^{8440}\rangle$ . If yes, exhibit it if no say why. My attempt by using some properties of cyclic groups. First of all, I calculated the order of $\sigma$ which is $ \operatorname{lcm}(6,7)=42$ . Then the order of $\sigma^{8440}$ which is $\frac{42}{\gcd(8440,42)}$ . Since $\gcd(8440,42) = 2$ then $|H|=o(\sigma^{8440}) = 21$ (since we are working with cyclic groups). 
Finally, since $3\mid21$ , there exists a subgroup of $H$ of order $3$ . I call it $G$ and it is generated by $\langle\sigma^{\frac{21}{3}}\rangle=\langle\sigma^{7}\rangle$ . Is my attempt correct?","['group-theory', 'cyclic-groups', 'discrete-mathematics', 'permutation-cycles']"
3105294,Euler's Totient Function and Residue Classes,"I have been working on a formula that seems to be a generalization of Euler's Totient Function and have a number of questions: I have been researching online and can't seem to find this function anywhere.  I'm assuming that it is probably just in a different format.  Can anyone point me in the right direction? It is pretty easy to prove the equation below when $m$ and $n$ share the same prime factors since it is equivalent to Euler's Totient Function.  Any hints on how to prove when $m$ and $n$ do not share the same prime factors? Let $R_n =\{ a|a \in \mathbb{Z}, 1\leqq a\leqq n,gcd(a,n)=1 \}$ Let $T_n =\{a_1,a_2,...,a_k,a_1+n,a_2+n,...,a_k+n\}$ Let $g_m(n)$ represent the number of elements in $R_n$ such that $a_k+m$ also exists in $T_n$ . Let $n=p_1^{e_1}p_2^{e_2}...p_k^{e_k}$ represent the prime factorization of $n$ . We state that $$g_m(n) = \prod_{p|n,p|m} p_k^{e-1}(p_k-1) \prod_{p|n,p|m\notin \mathbb{Z}} p_k^{e-1}(p_k-2) $$ where $m$ is even and $m\leqq n$ For example, let $n=20$ and $m=6$ . It follows that $$R_{20} = \{1,3,7,9,11,13,17,19\}$$ $$T_{20}=\{1,3,7,9,11,13,17,19,21,23,27,29,31,33,37,39\}$$ $$g_6(20)=2^1*(2-1)*5^0*(5-2)=6$$ The elements of $g_6(20)$ are $1,3,7,11,13,17$","['number-theory', 'totient-function', 'elementary-number-theory']"
3105300,"Easy algebra manipulation, example $x^3/(1+x^2)$","I guess this is really basic but have trouble following some algebraic manipulations on fractions. For example with two cases $$\frac{x^3}{1+x^2}$$ is supposed to be: $$x -\frac{x}{1+x^2}$$ and this identity $$\frac{x^2}{1+x^2}$$ is supposed to the same as this: $$1 -\frac{1}{1+x^2}$$ Which steps do you come to these conclusions, my guess is that you add or multiply something to the nominator and denominator but what and what type steps and what type of thinking is behind? Thanks","['algebra-precalculus', 'rational-functions']"
3105301,Two players alternate flipping a coin until the result is head. How to derive that the probability for the first player to win is $2/3$? [duplicate],"This question already has answers here : Two players alternately flip a coin; what is the probability of winning by getting a head? (5 answers) Closed 5 years ago . Two players, $A$ and $B$ , alternately and independently flip a coin and
  the first player to obtain a head wins. Player $A$ flips first. What is
  the probability that $A$ wins? Official answer: $2/3$ , but I cannot arrive at it. Thought process: Find the probability that a head comes on the $n$ th trial. That's easy to do, it's just a Geometric random variable. Then find the probability that $n$ th turn is player's A turn. Finally, multiply both probabilities. When I came up with each probability, both of them depended on the amount of trials $n$ , so my answer was a non-constant function of $n$ . However, what I find quite fantastic is that the answer is a constant, so the amount of tries until a head comes doesn't seem to matter.","['geometric-series', 'discrete-mathematics', 'binomial-distribution', 'probability']"
3105348,For which $p$ does $ \sum_{n=2}^{\infty} \frac{\sin(\frac{\pi}{n})}{n^p}$ converge?,"For which $p$ does $\sum_{n=2}^{\infty} \frac{\sin(\frac{\pi}{n})}{n^p}$ converge? I tried to use a convergence test and all I got was that it converges for any $p>0$ . I am not sure about this, could you please help? I am using the fact that the series is absolutely convergent and testing with $\frac{1}{n^{(p+1)}}$ .","['convergence-divergence', 'sequences-and-series']"
3105405,Determine whether a polynomial is irreducible,"Consider the polynomial $P=X^5-X-1\in\Bbb{F}_3[X]$ . I want to show that $P$ is irreducible. We can easily check it has no roots, so the only way it could not be irreducible is by being a product of two polynomials of degree $2$ and $3$ respectively. So I determine all the irreducible polynomials of degree $2$ in $\Bbb{F}_3[X]$ . These are $$X^2+1;{~~} X^2+X-1 {~~}\text{and}{~~}X^2-X-1.$$ Finally I check using the Euclidean division algorithm that none of those polynomials divides $P$ , which concludes the proof. My question is this:  is there a more efficient way to do this? I had to first determine all the polynomials of a given degree ( $2$ ) and then apply Euclidean algorithm to each of them. That is quite some work, and we're still considering polynomials of relatively small degree, and fields of small cardinal. I can't imagine applying the same reasoning to determine whether $Q=X^9-X^2-1\in\Bbb{F}_{17}[X]$ is irreducible. So, is there a more efficient method to determine irreducibility, at least in the case of polynomials of small degree over small fields?","['irreducible-polynomials', 'finite-fields', 'ring-theory', 'abstract-algebra', 'polynomials']"
3105461,Existence of orthogonal Hamel basis for infinite dimensional vector space.,"Consider a $\mathbb{F}$ -vector space $V$ that is infinite dimensional and equip it with an inner product (i.e. it is a Pre-Hilbert space). We know that $V$ has a basis set, say $S$ , such that for any $v\in V$ , $v=\sum_{v_s\in S}a_sv_s$ where only finitely many $a_s\in\mathbb{F}$ are non-zero. For a finite dimensional vector space we can orthogonalize the basis vectors using (Gram-Schmidt) but is it possible to do the same in an infinite dimensional vector space? 
I feel that if the basis were countable, we could do this but when the basis is uncountable (like the free vector space generated by an uncountable set $S$ ) it might not be. Is it possible to find an orthogonal uncountably infinite basis?","['hilbert-spaces', 'hamel-basis', 'linear-algebra', 'functional-analysis']"
3105490,Formula for r-Permutations of a Multiset,"Suppose we have a multiset $M$ , which contains $k$ distinct elements. Each element $x_i$ has multiplicity $n_i$ for each $i\in\Bbb{N}$ such that $0\le i<k$ . $n$ , the number of elements in $M$ including repetition, is defined as $n=\underset{i=0}{\overset{k-1}{\sum}}n_i$ . How would I go about calculating the number of permutations of length $r$ of $M$ , where each element $x_i$ is repeated $t_i$ times for $0\le t_i\le n_i$ ? (The specific values of each $t_i$ may vary for each permutation, so long as they all add up to $r$ .) I have found this question answered in several places with the additional constraint that $t_i>0$ (which gives an answer of $\frac{n!}{\underset{i=0}{\overset{k-1}{\prod}}t_i!}$ ), but never in this general case.","['permutations', 'combinatorics', 'multisets']"
3105500,What does it mean that a function dominates over another function?,"Let $f,g$ be functions with Domain $\mathbb{R}$ and Range $\mathbb{C}$ What does it mean that $f$ dominates over $g$ ? Unfortunately I could not find any ressources online about this Topic. But I remember there was a distinction between the behaviour at infinity and at $0$ . I understand why we call $f$ to be dominating over $g$ if $\lim_{x\rightarrow x_0}f(x)=\infty$ and $\lim_{x\rightarrow x_0}g(x)=\infty$ and also $\lim_{x\rightarrow x_0}\frac{f(x)}{g(x)}=\infty$ Because the values for $f$ are bigger than those of $g$ However I don't understand why we also call $f$ to be dominating over $g$ if If $\lim_{x\rightarrow x_0} f(x)=0$ and $\lim_{x\rightarrow x_0}g(x)=0$ and also $\lim_{x\rightarrow x_0}\frac{f(x)}{g(x)}=0$ Because the values of $f$ are smaller than those of $g$ . If we let $f(x)=x^2$ and $g(x)= x$ Hope someone can tell me why in both cases we would call $f$ to be dominating over $g$ .","['limits', 'algebra-precalculus']"
3105528,Integral $\int_0^1 \frac{\arctan x}{x^2-x-1}dx$,"After seeing this integral I've decided to give a try to calculate: $$I=\int_0^1 \frac{\arctan x}{x^2-x-1}dx$$ That is because it's common for many integrals to have a combination of a polynomial in the denominator and a logarithm or an inverse trig function in the numerator. Mostly I tried standard ways such as integrating by parts, random substitutions, or using: $$\frac{\arctan x}{x}=\int_0^1  \frac{dy}{1+x^2y^2}$$ But I realised that is not a great idea since it gives some mess after partial fractions, so I decided to prepare the integral a little for a Feynman's trick using probably the only helpful thing with that denominator, it won't change while using $x\mapsto 1-x$ . $$I=\int_0^1 \frac{\arctan x}{x^2-x-1}dx=\int_0^1 \frac{\arctan (1-x)}{x^2-x-1}dx$$ $$\Rightarrow 2I=\frac{\pi}{2 \sqrt 5}\ln\left(\frac{3-\sqrt 5}{3+\sqrt 5}\right)-\int_0^1 \frac{\arctan(x^2-x+1)}{x^2-x-1}dx$$ $$\small J(a)=\int_0^1 \frac{\arctan(a(x^2-x-1)+2)}{x^2-x-1}dx\Rightarrow J'(a)=\int_0^1 \frac{1}{1+(a(x^2-x-1)+2)^2}dx$$ But I am stuck now. I would like to see a method which finds a closed form for this integral, hopefully something decent comes out. I already imagine there will be some special functions.","['integration', 'definite-integrals', 'closed-form']"
3105572,Show directly that if $\{s_n\}$ is a Cauchy sequence then so is $\{|s_n|\}$. Conclude that $\{|s_n|\}$ converges whenever $\{s_n\}$ converges.,"Show directly that if $\{s_n\}$ is a Cauchy sequence then so is $\{|s_n|\}$ . From this conclude that $\{|s_n|\}$ converges whenever $\{s_n\}$ converges. Let $\{s_n\}$ be a Cauchy sequence. Then by definition, for any given $\varepsilon>0$ there exists $m>0$ such that $|s_n-s_m|<\varepsilon$ for all $n\geq m$ .
Then we have $$||s_n|-|s_m||\leq|s_n-s_m|$$ Therefore, from the definition $$||s_n|-|s_m||\leq|s_n-s_m|<\varepsilon$$ for all $n\geq m$ . Hence, $\{|s_n|\}$ is a Cauchy sequence. And then to prove that convergence of $\{s_n\}$ implies the convergence of $\{|s_n|\}$ : Let $\varepsilon>0$ . If $\{s_n\}$ converges to $L$ , then there exists $N$ such that $|s_n-L|<\varepsilon$ , whenever $n\geq N$ . Hence, for $n\geq N$ , we have $||s_n|-L|\leq |s_n-L|<\varepsilon$ . Thus $\{|s_n|\}$ converges to $|L|$ . That's how I proved but I'm not sure if I possibly made some mistakes or missed some steps!?","['convergence-divergence', 'proof-verification', 'analysis', 'real-analysis']"
3105581,How to prove using elementary methods that this function is everywhere continuous but nowhere differentiable?,"Let $f$ be the function defined on all of $\mathbb{R}$ by the formula $$ f(x) \colon= \sum_{n=0}^\infty \frac{1}{2^n} \cos \left( 3^n x \right). $$ How to show (rigorously but through elementary logic) that the function $f$ is (1) continuous everywhere? (2) differentiable nowhere? This example has been given in Sec. 6.1 in the book Introduction To Real Analysis by Robert G. Bartle & Donald R. Sherbert, 4th edition. So ideally I would like to have an argument based purely on the machinary developed in the book upto this point. However, a proof using the relevant results in the subsequent chapters and sections of the book would also be fine, provided that due references are given of all the facts used. I do know that the infinite series in question does converge (in fact it converges absolutely). So the function is defined everywhere on the real line.","['analysis', 'real-analysis', 'continuity', 'sequences-and-series', 'derivatives']"
3105611,Is a finite centerless metabelian group always a semidirect product of two abelian groups?,"Suppose $G$ is a finite centerless metabelian group. Is it true that it is a semidirect product of two abelian groups? It does not seem true to me, but I failed to find any counterexamples. Actually, I know quite a few examples of finite metabelian groups that do not split into a semidirect product of two abelian groups, but all of them have a nontrivial centre. What I have tried: The only thing I managed to see here is that a group having an abelian normal Hall subgroup with an abelian quotient by it is a semidirect product of two abelian groups (as any finite group splits over its normal Hall subgroup). On the other hand, all Hall subgroups of a semidirect product of two finite abelian groups are normal (as Hall subgroups of finite abelian groups are always characteristic). So that question can be reduced to either finding a finite centerless metabelian group with a non-normal Hall subgroup or proving that any finite centerless metabelian group has an abelian normal Hall subgroup with an abelian quotient by it. Note that aforementioned implications are one-sided, so proving that all Hall subgroups of finite centerless metabelian groups are normal or finding a finite centerless metabelian group without a normal abelian Hall subgroup with an abelian quotient by it will not give us anything regarding this question. However, those two new ""questions"" do not seem any easier than the initial one...","['finite-groups', 'metabelian-groups', 'semidirect-product', 'abstract-algebra', 'group-theory']"
3105664,"Given $ I_n=\int_{0}^{1}\frac{(1-x)^n}{n!}e^x\,dx $, prove that $ I_n=\frac{1}{(n+1)!}+I_{n+1} $","$$
I_n=\int_{0}^{1}\frac{(1-x)^n}{n!}e^x\,dx
$$ Prove that $$
I_n=\frac{1}{(n+1)!}+I_{n+1}
$$ I tried  integration by parts and still can't prove it, I appreciate any hint/answer.","['integration', 'analysis', 'reduction-formula']"
3105668,Show that recursive sequence is decreasing,"I'm required to show that the above series is decreasing. However, I encounter a problem when I realize that in the inductive step, I have  a term for a(n) in both the numerator and denominator, which makes it difficult to show that a(n+1) > a(n+2). Any Help would be appreciated.","['limits', 'convergence-divergence', 'sequences-and-series']"
3105683,What is the Hessian of the spectral norm?,The spectral norm of a symmetric matrix is the absolute value of the top eigenvalue. The gradient of this norm is $uu^T$ where $u$ is the eigenvector associated with that top eigenvalue. Assume that $A$ has an isolated top eigenvalue. Then it is twice differentiable. What is its Hessian? Any comments about how one generally computes Hessians of matrix norms are also appreciated!,"['positive-semidefinite', 'spectral-norm', 'matrices', 'linear-algebra', 'hessian-matrix']"
3105685,"Prove by induction: $C(2n, 2) = 2C(n, 2) + n^2$","Show that if $n$ is a positive integer, then $C(2n, 2) = 2C(n, 2) + n^2$ . Here, $C(a, b)$ means the binomial coefficient $\dbinom{a}{b}$ . Prove this by induction. Here is my calculation: $n$ cannot be $1$ because $n$ should be equal or larger than $2$ for $C(n, 2)$ . If $n=2$ : $C(4, 2) = 2C(2, 2) + 2^2 = 6$ If $n=m$ : $C(2m, 2) = 2C(m, 2) + m^2 = 2m^2 - m$ If $n=m+1$ : $C(2m+2, 2) = 2C(m+1, 2) + (m+1)^2 = 2m^2 + 3m + 1$ And I think I have to prove that: \begin{align*}
C(2m+2, 2) & = [\dots]\\
           & = [2C(m, 2) + m^2] + [2C(m, 1) + (2m + 1)]\\
           & = 2C(m+1, 2) + (m+1)^2 && \text{(by Pascal's Identity).}
\end{align*} But I have no idea what to do on $[\dots]$ part. Thanks.","['induction', 'binomial-coefficients', 'combinatorics', 'discrete-mathematics']"
3105699,An inequality involving two probability densities,"I cannot prove the following inequality, which I state below: Let $p, q$ be two positive real numbers such that $p+q=1$ . Let $f$ and $g$ be two probability density functions. Then, show that: $$\int_{\mathbb{R}} \frac{p^2 f^2 + q^2 g^2}{pf + qg} \geq p^2+q^2~.$$ I tried to use Cauchy-Schwarz and even Titu's lemma, but got nowhere. Any help will be greatly appreciated. Thanks!","['inequality', 'probability']"
3105716,How to evaluate $\lim_{n->\infty}\frac{\sqrt[3]{n+1}-\sqrt[3]{n+\cos{}\frac{3}{n}}}{\sqrt[6]{n^2+\sin{\frac{2}{n}}}-\sqrt[3]{n}}?$,I tried to get rid off cube root as written below but still can not get throught the next steps. What should be the right step to take after the steps below? Did I start as I should or do I have to take completely different approach? $\lim_{n->\infty}\dfrac{\sqrt[3]{n+1}-\sqrt[3]{n+\cos{}\dfrac{3}{n}}}{\sqrt[6]{n^2+\sin{\dfrac{2}{n}}}-\sqrt[3]{n}}=$ $=\lim_{n->\infty}\dfrac{\sqrt[3]{n+1}-\sqrt[3]{n+\cos{}\dfrac{3}{n}}}{\sqrt[6]{n^2+\sin{\dfrac{2}{n}}}-\sqrt[3]{n}}\dfrac{(\sqrt[3]{n+1})^2+\sqrt[3]{n+1}\sqrt[3]{n+\cos{}\dfrac{3}{n}}+(\sqrt[3]{n+\cos{}\dfrac{3}{n}})^2}{(\sqrt[3]{n+1})^2+\sqrt[3]{n+1}\sqrt[3]{n+\cos{}\dfrac{3}{n}}+(\sqrt[3]{n+\cos{}\dfrac{3}{n}})^2}$ $=\lim_{n->\infty}\dfrac{1-\cos\dfrac{3}{n}}{(\sqrt[6]{n^2+\sin{\dfrac{2}{n}}}-\sqrt[3]{n})((\sqrt[3]{n+1})^2+\sqrt[3]{n+1}\sqrt[3]{n+\cos{}\dfrac{3}{n}}+(\sqrt[3]{n+\cos{}\dfrac{3}{n}})^2)}$,"['limits', 'calculus', 'real-analysis']"
3105735,Threading a two-holed torus which is hanging on a string.,"The problem concerns a two-holed torus and an infinite length of string that
passes through one of the holes. The object is to use continuous transformations
on either the 2-hold torus or the infinite piece of string so that the string
threads the two holes of the torus, i.e., it enters one hole and leaves
through the other. This is a problem posed in one of the video lectures of
N J Wildberger on youtube algebraic topology lectures. After a lot of head scratching, I am at a loss.","['general-topology', 'algebraic-topology']"
3105758,Can we setup the integral as this?,${\dfrac{d}{dx}\Large\int} _{0}^{sinx} x^2\sqrt t\ \ dt$ as ${\dfrac{d}{dx}\ x^2 \Large\int} _{0}^{sinx} \sqrt t\ \ dt$ if so can i do the same thing for this too but I will endup with dt ${\dfrac{d}{dx}\Large\int} _{x}^{\sqrt x} \dfrac{e^x}{x}\ dt$ here all the variables are x except the dt can we pull out the $\dfrac{e^x}{x}$ ${\dfrac{d}{dx}\dfrac{e^x}{x}\Large\int} _{x}^{\sqrt x} \ dt$ what can I do with ${\Large\int} _{x}^{\sqrt x} \ dt$ ? thanks in advance,['integration']
3105759,Show Three Sets are Equal,"Say I have three sets $S_1, S_2, S_3$ , and I want to show that they are equal. Is it enough to show that $S_1 \subset S_2$ , $S_2 \subset S_3$ , and $S_3 \subset S_1$ ? I think yes: (1) If $S_1 \subset S_2$ and $S_2 \subset S_3$ , then $S_1 \subset S_3$ . This result, together with $S_3 \subset S_1$ , implies that $S_1 = S_3$ . (2) If, $S_1 = S_3$ and $S_1 \subset S_2$ , then $S_3 \subset S_2$ . This result, with $S_2 \subset S_3$ shows that $S_2 = S_3$ . (3) If $S_1 = S_3$ and $S_2 = S_3$ , then $S_1 = S_2$ . So I think yes, but I'm planning to use this idea to prove something else, and I don't want to waste my time on a faulty premise! Thanks.","['elementary-set-theory', 'proof-writing']"
3105775,Literature suggestion for understanding Gauge theory from the perspective of a Mathematician.,"Can anyone please suggest some good literature or references for understanding Gauge theory from the perspective of a mathematician (from the point of view of differential geometry)? Being a Mathematics PhD student(differential geometry) I want the introduction mathematically as rigorous as possible. Specially I want to understand the space of connections and the action of Gauge group on it. My background is following: I have read Fibre bundles(principle G-bundles), Theory of Connections( Connection as distribution and as a Lie algebra valued 1-form, Local connection forms, Holonomy Theorem(Ambrose and singer), flat connections and some Affine Connections from Foundation of Differential Geometry(Kobayashi and Nomizu) Vol-1 , Characteristic Classes(Chern classes) from Foundation of Differential Geometry(Kobayashi and Nomizu) Vol-2 , general theory of fibre bundles(Milnor's classification for principle bundles) from Fibre Bundles Dale Husemoller and I have some idea about basic Algebraic topology, cohomology theory and Category theory( at level of a Masters student in Mathematics). Most of the literature I  came across in the internet I felt they were written from the perspective of a Physicist otherwise some research papers (which I felt too advanced for me now). Being  just a 1st year PhD student(differential geometry) it  would be really helpful for me if someone can refer (keeping in mind of my Mathematical background) a humble but Mathematically very rigorous literature in Gauge theory where action of Gauge group on the space of Connections is discussed in details. Thanks in advance.","['principal-bundles', 'connections', 'reference-request', 'gauge-theory', 'differential-geometry']"
3105796,Dense sets in $L_{\infty}$,"I know that for every probability measure $\mu$ on doubling metric space $X$ , 
the set of lipschitz functions (and therefore continuous functions) is dense in $L_1(\mu)$ . Is it true for $L_{\infty}$ as well? i.e. for every $\epsilon >0$ and a bounded function $g$ there is a continuous $f$ s.t. for all $x \in X$ we have $|f(x) - g(x)| <\epsilon $ (I assume $f:X \to \mathbb{R}$ ) If it is not true, is it correct with additional constraints on $X$ ?","['measure-theory', 'functional-analysis', 'metric-spaces']"
3105800,Give an example of a set $A$ for which the following sets are pairwise different.,"Give an example of a set $A$ for which the sets: $A, \text{Int}(A), \overline A, \text{Int}(\overline A), \overline {\text{Int}(A)}, \text{Int}(\overline{\text{Int}( A)}), \overline{\text{Int} \big( \overline A\big)} $ Are pairwise different. My prof gives a hint, the set $A$ will be $\mathbb{Q}\cap B$ where $B \subset \mathbb{R}$ , but $\text{Int}(\mathbb{Q})=\phi$ and then $\text{Int}(\mathbb{Q} \cap B)=\phi$ , also $\overline{\text{Int}(\mathbb{Q} \cap B)}=\phi$ , what’s the wrong? I need a hint, please. Thanks.",['general-topology']
3105807,"If then, sufficient for, necessary condition [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question How could I understand 
If p then q = q is necessary for p = p is sufficient for q ??? I am so confused why are they the same.",['discrete-mathematics']
3105837,Does $\{\} = \{\{\}\} \cup \{\{\}\} \cup \cdots \cup \{\{\}\}$,"Does any finite set $S = \{a, b, ..., c\}$ equal the union of it's elements? I believe so, but would I write that like $$S = \{a\} \cup \{b\} \cup \cdots \cup \{c\} \tag{A}$$ $$\text{vs} $$ $$S = a \,\cup \,b \cup \cdots \cup c \tag{B}$$ Because I'm not sure how that would work out when using, say, the empty set $$\{\} = \{\{\}\} \cup \{\{\}\} \cup \cdots \cup \{\{\}\} \tag{A}$$ $$ \text{vs} $$ $$\{\} = \{\} \,\cup \,\{\} \cup \cdots \cup \{\} \tag{B}$$ Here, the second one looks correct, although I'm curious if there's a distinction. I was inspired to ask that while was looking at some intro probability text in which I realized an event is simply the union of the elements—although the text doesn't explicitly say that. Which is funny because the other day I asked a question on here: what is the probability of flipping two fair coins (heads and tails is $H$ and $T$ , respectively) and and getting $HH$ given that we know one of the coins is $H$ ? Well, my previous post lead to some discussion about ambiguously worded probability problems. That specific question could be interpreted at least a few linguistically natural ways, and the conclusion was that we should avoid posing such questions that are ambiguous. Anyway, I've been thinking about the ambiguity of such questions. In the case of the question above, the author gave the answer of the probability being $1/3$ , which aligns with a natural interpretation of the question: the two coins land, we cannot see them, we only know that one of them is heads. That eliminates $TT$ from our remaining possible event set, and $HH$ is $1$ of the three events remaining. I have no disagreement about that. But, rereading the section today I came to what I hope is a legitimate realization: every event is the elements that satisfy that event connected with OR statements, i.e. the union of those elements . Consider the above question posed slightly differently: we imagine the same scenario (and interpretation) but now we wonder what is probability of getting a heads and a tails? This question can be more precisely (and boringly) posed as: what is the probability that $HT$ OR $TH$ occurs given that there is one $H$ in the event ? Here, it's clear the answer is 2/3. Notice that the only challenging part of this question was the line ""...what is probability of getting a heads and a tails?"" . This has to (1) be translated in our minds to an appropriate subset (event) of the sample space, and at the same time we have to account for the $HT \neq TH$ relative to our sample space but that $HT$ = $TH$ , relative to the event . We consider $HT$ and $TH$ unique in the sample space but the same for the event. Sorry if that seemed superfluous. What I'm asking is: am I correct to view an event as the elements that comprise it—their union? Second, I'm curious on the notation at the top, and third, I'm curious to any methods of thinking you might have on these (or more general) probability questions that are useful in avoiding confusion. Thank you.","['elementary-set-theory', 'elementary-probability', 'notation']"
3105887,"Let $T\colon \mathbb{R}^2 \to \mathbb{R}^2$ be linear transformation. Show that there are $a,b\in \mathbb{R}$ such that $T^2+aT+bI=0$.","This is a problem from the book Linear Algebra by Larry Smith and the author has so far introduced Vector Spaces. This problem shows up in the introductory chapter of Linear Transformations. Let $T\colon \mathbb{R}^2 \to \mathbb{R}^2$ be linear transformation.
  Show that there are $a,b\in \mathbb{R}$ such that $T^2+aT+bI=0$ . I think I have worked out the proof but I was looking for a simpler way. Here's how I did it: I defined $T\colon \mathbb{R}^2 \to \mathbb{R}^2$ by $T(x,y)=(t_1 (x,y) , t_2 (x,y))$ where $t_1$ and $t_2$ are functions from $\mathbb{R}^2$ to $\mathbb{R}$ . I showed that $T$ is a linear transformation iff $t_1$ and $t_2$ are linear transformations. Since every linear transformation from $\mathbb{R}^2$ to $\mathbb{R}$ is of the form $ax+by$ for all $(x,y)\in \mathbb{R}^2$ , I completed it by comparing the components. Is there any far far better way of doing this?","['linear-algebra', 'linear-transformations']"
3105900,Log det of covariance and entropy,"I understand log of determinant of covariance matrix bounds entropy for gaussian distributed data. Is this the case for non gaussian data as well and if so, why? What does Determinant of Covariance Matrix give? and http://web.ntpu.edu.tw/~phwang/teaching/2012s/IT/slides/chap08.pdf show connection between 'differential entropy' and log of determinant of covariance matrix for Gaussian case. Eqn. 26 of https://arxiv.org/pdf/1604.03924.pdf?fbclid=IwAR1tDOzgZ2iXSo3lDbXnr8TUkxawCA8NikHFlfY4E5OWmbmJ3_WHeVPotFE has some relations (I guess for non-Gaussian case, but yet to check that)","['statistics', 'covariance', 'entropy', 'information-theory', 'upper-lower-bounds']"
3105919,Show that this map is a contraction (PDE),"I was asked a question by my research advisor and I really don't know how to think about it. The goal is to prove the existence of a function $u(x,t):\mathbb{R}\times[0,T]\to\mathbb{R}$ satisfying the following PDE: $$\begin{cases}\partial_t^2 u-\partial_x^2 u=(\partial_t u)(\partial_x u)\\u(-,0)=f\in H^s(\mathbb{R})\\\partial_tu(-,0)=g\in H^{s-1}(\mathbb{R}),\end{cases}$$ where $H^s(\mathbb R)$ is the Sobolev space $$H^s(\mathbb{R})=\{f:\lVert f\rVert_{s,2}=\lVert\hat f(\xi)(1+\lvert\xi\rvert^2)^{s/2}\rVert_2<\infty\},$$ and $s$ is sufficiently large. To do this, I was told to define the norm $$\lVert u\rVert_X=\sup_{t\in[0,T]}(\lVert u\rVert_{s,2}+\lVert\partial_t u\rVert_{s-1,2})$$ on the space $$X=\{u\in C([0,T];H^s(\mathbb R))\cap C^1([0,T];H^{s-1}(\mathbb R)) :\lVert u\rVert_X\leq c(\lVert f\rVert_{s,2}+\lVert g\rVert_{s-1,2})\}.$$ Now let $w_0$ satisfy the wave equation $\partial_t^2 w_0-\partial_x^2 w_0=0$ with initial data $w_0(-,0)=f$ and $\partial_t w_0(-,0)=g$ , and for $n>0$ let $w_n$ satisfy $$\begin{cases}\partial_t^2 w_n-\partial_x^2 w_n=(\partial_t w_{n-1})(\partial_x w_{n-1})\\w_n(-,0)=f\\\partial_t w_n(-,0)=g.\end{cases}$$ If we can show $\Phi=(w_n\mapsto w_{n+1}):X\to X$ is a contraction mapping and that $X$ is complete, then we are done by the Picard iteration theorem. I do not know how to prove $\Phi$ is a contraction. I understand all of the definitions, I've tried to prove through direct computation, and I've tried to apply any of the relevant theorems I know, but I have had no luck. I also don't know how to show that $\Phi(u)$ even exists for general $u$ . If anyone has an idea of how to proceed with this, I would very much appreciate hearing their thoughts. Thank you.","['partial-differential-equations', 'fourier-analysis', 'functional-analysis', 'real-analysis']"
3105921,Two Euler sums each containing the reciprocal of the central binomial coefficient,"Is it possible to find closed-form expressions for the following two Euler sums containing the reciprocal of the central binomial coefficient? $$1. \sum_{n = 0}^\infty \frac{(-1)^n H_n}{(2n + 1) \binom{2n}{n}} \qquad \text{and} \qquad 2. \sum_{n = 0}^\infty \frac{(-1)^n H_{2n + 1}}{(2n + 1) \binom{2n}{n}}$$ Here $H_n$ is the $n$ th harmonic number . The reason I am interested in these two sums is as follows. It arose while considering alternative ways to evaluate the integral given here $$\int_0^1 \frac{\ln x}{x^2 - x - 1} \, dx = \frac{\pi^2}{5 \sqrt{5}}.$$ One way, very similar to the answer given, is to use the dilogarithm machinery and is relatively simple. A second way is as follows: \begin{align}
\int_0^1 \frac{\ln x}{x^2 - x - 1} \, dx &= - \int_0^1 \frac{\ln x}{1 + (x - x^2)} \, dx\\
&= - \int_0^1 \ln x \sum_{n = 0}^\infty (-1)^n (x - x^2)^n \, dx \tag1 \\
&= - \sum_{n = 0}^\infty (-1)^n \int_0^1 \ln x \, x^n (1 - x)^n \, dx\tag2.
\end{align} In (1) a geometric expansion has been used and is valid since $|x - x^2| < 1$ for $0 < x < 1$ . In (2) the summation and integration has been interchanged and is valid due to the dominated convergence theorem. Consider $$J(a) = \int_0^1 x^a (1 - x)^n \, dx, \quad a > 0.$$ Differentiating with respect to $a$ we have $$J'(a) = \int_0^1 \ln x \, x^a (1 - x)^n \, dx,$$ and we observe that $$J'(n) = \int_0^1 \ln x \, x^n (1 - x)^n \, dx.$$ Now $$J(a) = \operatorname{B} (a + 1, n + 1) = \frac{\Gamma (n + 1) \Gamma (a + 1)}{\Gamma (a + n + 2)}.$$ Thus $$J' (a) = \frac{\Gamma (n + 1) \Gamma (a + 1)}{\Gamma (a + n + 2)} \left [\psi (a + 1) - \psi (a + n + 2) \right ].$$ Here $\psi (z)$ is the digamma function . Setting $a = n$ then gives $$J'(n) = \frac{1}{(2n + 1) \binom{2n}{n}} \left [\psi (n + 1) - \psi (2n + 2) \right ] = \frac{1}{(2n + 1) \binom{2n}{n}} (H_n - H_{2n + 1}),$$ where we have used the result : $\psi(x) = H_{n - 1} - \gamma$ , with $\gamma$ corresponding the the Euler–Mascheroni constant. So on returning to our integral we see that $$\int_0^1 \frac{\ln x}{x^2 - x - 1} \, dx = \sum_{n = 0}^\infty \frac{(-1)^n}{(2n + 1) \binom{2n}{n}} (H_{2n + 1} - H_n) = \frac{\pi^2}{5 \sqrt{5}},$$ and brings me to the two Euler sums. Thoughts on finding the sums One thought is to somehow massage the result $$\sum_{n = 0}^\infty \frac{x^{2n + 2}}{(n + 1)(2n + 1) \binom{2n}{n}} = 4 \arcsin^2 \left (\frac{x}{2} \right ),$$ in conjunction with perhaps the result $$H_n = - n \int_0^1 x^{n - 1} \ln (1 - x) \, dx,$$ into a suitable form but the presence of the alternating term $(-1)^n$ is proving difficult.","['integration', 'improper-integrals', 'definite-integrals', 'euler-sums', 'harmonic-numbers']"
3105932,"A class of sets ""picking out"" a set","The idea of sets being shattered comes up a lot in statistical learning theory with applications to VC dimension. Before learning about this, I am trying to understand the following definition. Let $F=\left \{ x_{1}, x_{2},...,x_{n} \right \}$ be a finite set.  Let $G$ be a subset of $F$ .  We say that a class of sets $\mathcal{A}$ $\textbf{picks out}$ $G$ if $$A \cap F = G$$ for some set $A \in \mathcal{A}$ . The author then gives the following example: Consider the class of sets $\mathcal{A} =\left \{ (a,b): a \leq b \right \}$ .  Suppose that $F=\left \{ 1,2,7,8,9 \right \}$ and $G = \left \{ 2,7 \right \}.$ Then $\mathcal{A}$ picks out $G$ since $A \cap F = G$ , if we take $A= \left \{ 1.5,7.5 \right \}$ for example. Clearly, looking at this example, $$A \cap F = \emptyset \neq G.$$ So, what am I missing? Thanks in advance!","['machine-learning', 'statistics']"
3105996,"Two equal segments, two known angles, find angle in triangle","This is the problem. I have tried the obvious without success. Drawing some perpendiculars (from A for example), I only know the angle $\sphericalangle ADC = 54 ^{\circ}$ . How can I use the equality $AB = DC$ ?","['euclidean-geometry', 'trigonometry', 'geometric-transformation', 'geometry']"
3105997,Irreducible components of $V(y^2-x(x^2-1))$,"Let $V=V(y^2-x(x^2-1)$ . It's easy to know $y^2-x(x^2-1)$ is irreducible in $\mathbb{C}[x,y]$ , then $V$ is an irreducible curve in $\mathbb{A}^2(\mathbb{C})$ . If we consider it in $\mathbb{A}^2(\mathbb{R})$ , $y^2-x(x^2-1)$ is also irreducible and infinite, hence $V$ is also irreducible. But in this case, its picture shows $V$ may be reducible with two components. I'm confused with this example. Can you give me an explaination? Thank you!","['algebraic-curves', 'algebraic-geometry']"
3106000,Geometric interpretation of the Logarithm (in $\mathbb{R}$),"(Note: limited to $\mathbb{R}$ ) (Note: Geometric here means with straightedge and compass ) Standard approaches to introducing the concept of Logarithm rely on a previous exposition of the exponential or simply on that of a power. It then receives the dull definition of ""the inverse of the power"". A more intuitive and accessible introduction, which allows doing so even at grade 9, is that of the integer (discrete) logarithm ( $\mbox{i}\hspace{-0.15em}\log_b(x)\equiv \lfloor\log_b(x)\rfloor$ ), i.e., through repeated division by the base without ever getting a result smaller than 1. Ex: 8 can consecutively be divided 3 times by 2 (8/2/2/2) before the results gets smaller than 1. Hence $\operatorname{ilog}_2(8)=3$ . All the usual properties of logarithms can be derived from such a definition, albeit presumably only for integers. I'm looking, however, for a geometric description for $\log_b(x)$ (not just the integer one $\mbox{i}\hspace{-0.15em}\log_b(x)$ ) and geometric construction of the integer logarithm $\operatorname{ilog}_b(x)$ . I think I have such a geometric description : $\log_b(x)$ is the ratio in which a 1/x contraction stretches to 1 relative to the case of a 1/b contraction . or alternatively $\log_b(x)$ is the ratio in which a stretch by a factor of x contracts to 1 relative to the case of a stretch by a factor of b . Example: A contraction of 1/16 can be dilated (""zoom in"") 4 times by a factor of 2 to recover the original size, while that of 1/8 can be stretch 3 times by the same factor. Hence $\log_8(16)=4/3$ . By the same definition it is $\log_y(x)\,=\,1/\log_x(y)$ and thus $\log_{16}(8)=3/4$ . The fundamental law of the logarithm should come equally simple from there: $$\log_b(x)\,=\,\log_{b'}(x)\,\log_b(b')$$ This description of the logarithm is reminiscent of that of the cross-ratio, namely a ratio of ratios, and applies to lengths, areas and volumes. However, in terms of geometric constructibility, the Gelfond-Schneider theorem would seem to rule that out in most of the cases as $\log_b(x)$ is either rational or transcendental. But what about the integer logarithm, Is there a construction by compass and ruler of $\mbox{i}\hspace{-0.15em}\log_b(x)$ ? If a geometric construction would be impossible, what is the proof or a sketch of it? Given the above definition in terms of ratio of dilations, would projective geometry provide for a better insight? In this sense, is that resemblance to the cross-ratio more than a coincidence? Note: Calculus would seem to provide us with what looks like a geometric description as the area, $A(x)$ , of $f(x)=1/x$ between $1$ and $x$ . I don't like such an answer, however, because (1) it doesn't provide intuition on how to calculate it (makes an ad hoc reference to an hyperbola) and (2) $\log_b(x)$ is still but the ratio of two numbers, namely, $A(x)/A(b)$ , so the above geometric description would seem to encompass this other one. EDIT: Added pictures: Turning the dial A of a machine by 1 notch left/right scales the area of all your objects down/up by a factor of two; similarly, dial B works by a factor of 8. Hence, 3 turns of dial A transforms the green, unit square into the orange rectangle, while 4 turns makes it into the big salmon square. How much do you need to turn dial B in order to get the green, unit square into the salmon big square? Ans: 4/3 of a notch. Is the log an intrinsic projective measure? FWIW, Poincare hyperbolic distance d_h(p,q) is a projective measure involving the log of a cross-ratio. As mentioned in my second comment to this post, the discussion in here and the article referenced there may give a hint on this last point. Roughly, a metric tensor on the upper half-plane is given by $ds^2=(dx^2+dy^2)/y^2$ , which translates into $ds^2=(dx^2+dy^2)/(1-r^2),\;r^2=x^2+y^2<1$ for the Poincare disc. Further discussions can be found here and here","['projective-geometry', 'logarithms', 'geometry', 'discrete-logarithms', 'cross-ratio']"
3106007,"If $f: U \to V$ is holomorphic and injective , then $f'(z) \neq 0$ for all $z \in U$","Proposition : If $f: U \to V$ is holomorphic and injective , then $f'(z) \neq 0$ for all $z \in U$ . Proof : We argue by contradiction , and suppose that $f'(z_0) = 0$ for some $z_0 \in U$ . Then $$f(z)-f(z_0)=a(z-z_0)^k+G(z) \,\,\,\,\,\,\,\, \text{for all $z$ near $z_0$ ,}$$ with $a\neq 0 , k \ge 2$ and $G$ vanishing to order $k+1$ at $z_0$ . For sufficiently small $w$ , we write $$f(z)-f(z_0)-w=F(z)+G(z) \,\,\,\,\,\,\,\, \text{where $F(z)=a(z-z_0)^k-w$ .} $$ Since $|G(z)|\lt |F(z)|$ on a small circle centered at $z_0$ , and $F$ has at least two zeros inside that circle , Rouche's theorem implies that $f(z)-f(z_0)-w$ has at least two zeros there , a contradiction . My question : Why $F$ has at least two zeros inside that small circle ? We only know that $F$ has $k$ zeros in $C$ or for some large circle centered at $z_0$ . However , since $w$ is fixed , the radius $r$ of the small circle which satisfy $|G(z)|\lt |F(z)|$ can not be sufficiently large . So , how to deduce de desired conclusion by the proof given above ?","['complex-analysis', 'proof-explanation']"
3106019,Could $\langle \Gamma | R \rangle \cong \langle \Gamma | S\rangle$ if $\langle R\rangle \subsetneq \langle S\rangle$?,"If we have two finitely presented groups $\langle \Gamma | R\rangle$ and $\langle \Gamma | S\rangle$ with $\langle R\rangle \subsetneq \langle S\rangle$ , could they be isomorphic?","['group-presentation', 'group-isomorphism', 'combinatorial-group-theory', 'finitely-generated', 'group-theory']"
3106021,Uniqueness of weak derivative,"In this result, I understand almost everything but I don't understand why we using $\Omega' \Subset \Omega$ what is the major role of this why not we directly use $\Omega$ . thank you","['proof-explanation', 'sobolev-spaces', 'functional-analysis', 'weak-derivatives']"
3106029,limit and absolute absolute value problem,$$\lim_{x \to -2} \frac{2-|x|}{2+x}$$ If I calculate the left and right-hand limit I get different results. Left hand side: $$\lim_{x \to -2^-}\frac{2+x}{2+x}=1$$ Right hand side: $$\lim_{x \to -2^+} \frac{2-x}{2+x}=\text{undefined}$$ My question is that my procedure is right or wrong?,"['limits', 'absolute-value', 'real-analysis']"
3106051,Why is Catalan's constant $G$ important?,"I am aware that Catalan's constant appears in the evaluation of many definite integrals, as well as in the evaluation of certain infinite series, and is a special value of a function closely related to the Riemann zeta function, and so on. But is there a way in which we might think of this constant as important in its own right, and not come at it 'indirectly;' not approaching it only through other 'loftier' concepts first, or using it as a convenient shorthand for the numerical result of a certain integration or summation process, etc., but through some simple concepts that first lead you to the idea of some important constant, whose more sophisticated properties we can then deduce, and in doing so derive its relations to the transcendental functions, integral and series representations, so that we arrive at the idea of Catalan's constant itself as some important concept in its own right, without appealing to it as kind of a secondary idea? For example, we can do this with $\pi$ and $e$ quite easily. The concept of $\pi$ appears as a simple geometric idea. I only need to understand some basic geometrical ideas, and then it would be only a matter of time before I arrived at the idea of $\pi$ and understood its importance, even if I didn't fully understand the full depth of its importance. The same with $e,$ or even the Euler-Mascheroni constant $\gamma.$ I only need some basic concepts of calculus. With more sophisticated concepts I obviously need more sophisticated prerequisites, but regardless, it is often the case that many fundamental ideas actually have a very simple, and very intuitive germ, which is why you see them pop up again and again, and often there is still some fairly simple relationship between ideas which tells you immediately that something may be important, even if those ideas are themselves not quite 'basic'. With Catalan's constant, I haven't seen any kind of explanation that explains this. It's almost always 'Catalan's constant appears in the evaluation of ...' which only tells you that it is important, but not really where this importance comes from, or why you would be led to care about this constant as anything more than a useful notation for some integral or sum, unlike many other ubiquitous objects in mathematics, where you might first grasp them as an important idea, and then notice their many other uses. Can anyone explain why Catalan's constant is important, or why you would be motivated to care about this constant in its own right? I appreciate that this question may be vague but I'd love to hear any good answers.","['number-theory', 'constants', 'catalans-constant', 'big-picture']"
3106151,How to calculate $\int_{0}^{1} x^2 \sqrt{1+x^2} dx$?,"I'm trying to calculate the following integral: $\int_{0}^{1} x^2 \sqrt{1+x^2} dx$ I tried solving by parts but i'm getting nowhere close. I feel like some substitution will be good here, however neither $x=\cos(u)$ nor $x=\sin(u)$ get me anywhere.","['integration', 'definite-integrals']"
3106179,Can we rederive the axioms of topology from the structure of the category $\textbf{Top}$?,"The approach of category theory to the description of mathematical structures, is to look at how a class of mathematical structures relate to each other, and to forget the structure itself. e.g. in the category of topologies Top , objects are topological spaces, and morphisms are continuous functions. From a categorical perspective, Top only contains this information about the continuous functions, and forgets the ""internal structure"" of each object, i.e. the topological spaces. I have read that it is an interesting property of category theory that this relational information ""captures"" the information about topological spaces. Does this mean that we have literally all information about topological spaces in its category? e.g. can we rederive the axioms of topology from purely the categorical information in Top ? If not, then what does it mean concretely to say that the category $\textbf{Top}$ ""captures what a topology is""?","['general-topology', 'category-theory']"
3106199,Approximating $\int_1^3 \int_1^3 \int_1^3 x^{y^z} \mathrm dx\mathrm dy\mathrm dz$?,"I was given a really nasty integral to approximate, which was $$\int_1^3 \int_1^3 \int_1^3 x^{y^z}\mathrm dx\mathrm dy\mathrm dz$$ I was completely clueless; and my interviewer gave me some hints but I got nowhere. I was told that the order of magnitude is roughly $10^9$ . Could someone help me out? Thank you!","['integration', 'multivariable-calculus', 'approximation', 'volume']"
3106284,Flux through region : paraboloid and sphere,"I have this region : $D=\{(x,y,z)\mid y^2+z^2\le 3|x|,(x-2)^2+y^2+z^2 \le 4\}$ with vector field $\mathbf F=(-2x,-2y,xy)$ I can use the divergence theorem : $\mathrm{div}(\mathbf F)=-4$ Attempt : Let's see where they intersect : $(x-2)^2+3x=4 \implies x^2-x=0 \implies x=0,1$ In order to find the radius of integration I can plug $x=1$ into $y^2+z^2\le 3x$ . so radius is $r=\sqrt{3}$ Now It's time to get the $x$ range : $(x-2)^2+y^2+z^2 = 4 \implies x^2-4x+y^2+z^2=0 \implies x_{1,2}=\frac{4\pm\sqrt{16-4(y^2+z^2)}}{2}$ I take the positive one. $x\in\left[\frac{y^2+z^2}{3},2+2\sqrt{4-y^2-z^2}\right]$ Integration cylindrical coordinates : $x\in\left[\frac{r^2}{3},2+2\sqrt{4-r^2}\right]$ $\theta\in[0,2\pi]$ $r\in[0,\sqrt{3}]$ The final integral is : $$\text{Flux} = -4\int_{0}^{2\pi}\int_{0}^{\sqrt{3}}\int_{\frac{r^2}{3}}^{2+2\sqrt{4-r^2}}r\,\mathrm dx\,\mathrm dr\,\mathrm d\theta=...=-\frac{166}{3}\pi$$ Is my Integral set-up right ? UPDATE : I think I can also split the region into two parts : the first one is the paraboloid with $x \in [0,1]$ and the second one in the sphere with $x \in [1,4]$ $\int_{0}^{2\pi}\int_{0}^{\sqrt{3}}\int_{\frac{r^2}{3}}^{1}rdxdrd\theta=\frac{3}{2}\pi$ $\int_{1}^{4}(\sqrt{4x-4x^2})^2\pi dx=9\pi$ so Flux = $-4(\frac{3}{2}\pi+9\pi)=-42\pi$ ?","['integration', 'multivariable-calculus', 'proof-verification']"
3106299,When is $A\rtimes_{\phi_1} B \cong A\rtimes_{\phi_2} B$? [duplicate],"This question already has answers here : When are two semidirect products isomorphic? (2 answers) Closed 2 years ago . Suppose $1\to K \stackrel{m}{\rightarrow} G \stackrel{f}{\rightarrow} H \to 1$ is short exact sequence of groups. The followings are equivalent: $(1)\ G\cong K \times H;$ $(2)$ The sequence right splits (i.e. $\exists$ homomorphism $g:H \to G$ s.t. $f\circ g =$ Id $_H$ ) and $H\cong N \triangleleft G;$ $(3)\ G$ is semidirect product of $K$ and $H$ , and $H$ acts on $K$ trivially. $(4)$ The sequence left splits (i.e. $\exists$ homomorphism $h:G \to K$ s.t. $h\circ m =$ Id $_K$ ). However, if $H$ acts on $K$ nontrivially, $G$ may also be direct product. e.g. let $G$ be a nonabelian group with $h \in G\backslash Z(G)$ . for $1\to G \to G\times \Bbb Z \to \Bbb Z \to 1$ , splitting map $g: \Bbb Z \to G \times \Bbb Z, 1 \mapsto (h,1).$ $ \phi: \Bbb Z \to \text{Aut} G,\ \phi(1)(g,1)=(h,1)(g,1)(h,1)^{-1}=(hgh^{-1},1).$ Since $h \not \in Z(G)$ , this action is nontrivial. So under what condition, semidirect product of groups is isomorphic to their direct products? And more generally, when is $A\rtimes_{\phi_1} B \cong A\rtimes_{\phi_2} B$ ?","['semidirect-product', 'group-theory', 'abstract-algebra', 'direct-product']"
3106312,"If $f:\Bbb{R}^2\to\Bbb{R}^2$ is smooth and the derivative matrix has non-zero determinant everywhere, is the function injective?","Is the following generalization of the Inverse Function Theorem true: Let $f:\Bbb{R^2}\to\Bbb{R^2}$ be a smooth function. If the determinant of the derivative matrix is non-zero everywhere, then the function is globally one-to-one.","['multivariable-calculus', 'derivatives', 'analysis']"
