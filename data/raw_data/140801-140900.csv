question_id,title,body,tags
2272248,Regarding the sum $\sum_{p \ \text{prime}} \sin p$,"I'm very confident that 
$$\sum_{p \ \text{prime}} \sin p $$ diverges. Of course, it suffices to show that there are arbitrarily large primes which are not in the set $\bigcup_{n \geq 1} (\pi n - \epsilon, \pi n + \epsilon)$ for sufficiently small $\epsilon$. More strongly, it seems that $\sin p$ for prime $p$ is dense in $[-1,1]$. This problem doesn't seem that hard though. Here's something that (to me) seems harder. If $p_n$ is the nth prime, what is $$\limsup_{n \to +\infty} \sum_{p \ \text{prime} \leq p_n} \sin p?$$
  What is $$\sup_{n \in \mathbb{N}} \sum_{p \ \text{prime} \leq p_n} \sin p? $$ Of course, we can ask analogous questions for $\inf$. I'm happy with partial answers or ideas. For example, merely an upper bound.","['real-analysis', 'sequences-and-series', 'calculus']"
2272277,What is the maximum even number that can not be expressed as sum of two composite odd numbers?,"Question: What is the maximum even number that can NOT be expressed as sum of two composite odd numbers? For example, $14=7+7=5+9=3+11=1+13$ is one of such even numbers, but probably not the maximum number. $24=9+15=3\times3+3\times5$ is not one of such numbers. I have no idea how to tackle this one. Thanks.",['number-theory']
2272308,Show that $X = Y$ almost surely,"I am trying to solve this problem: Let $X,Y$ be random variables on $(\Omega, \mathcal{F}, P)$ such that $E(Y|\mathcal{G}) = X$ and $E(Y^2|\mathcal{G}) = X^2$, where $\mathcal{G} \subset \mathcal{F}$ is a sigma-algebra. Prove that $X = Y$ almost surely. What I have until now: From the given property, it's easy to see that $\int_{G}XdP = \int_{G} YdP$, for any $G \in \mathcal{G}$. Also, $X$ is $\mathcal{G}$-measurable. I know that if the integrals of two random variables, on the same probability space , over any element of the sigma-algebra in discussion agree, then they are equal almost surely. So, if I could prove that $Y$ is also $\mathcal{G}$-measurable I could apply this result. Or, in te other hand, if I could find a similar equality as above for any element $F \in \mathcal{F}$, then I think the problem is solved too. But I can't do it. Also, I can't see how the information the $X^2$ can be helpful here. Any ideas? Thanks in advance for the support.","['expectation', 'lebesgue-integral', 'probability', 'measure-theory', 'conditional-expectation']"
2272353,How can I prove that the mean of squared data points is greater than the square of the mean of the data points?,"The inequality I'm trying to prove is $$\frac{1}{n}\sum_{i=1}^nx_i^2 \geq \frac{1}{n^2}\left(\sum_{i=1}^nx_i\right)^2.$$ I tried simply expanding out the RHS but I can't seem to count the terms properly. I can reduce the inequality to $$(n-1)\sum_{i=1}^nx_i^2 - 2\sum_{i\neq j}x_ix_j \geq 0$$ but there appear to be $2(n-1)!$ terms in this $i\neq j$ sum and only $n(n-1)$ terms in the sum of the squares, which doesn't seem right to me. I've also ""assumed"" that $x_1 \leq\dots\leq x_n$ which allows me to set up the inequalities $x_1^2 \leq x_1x_2 \leq x_2^2$ etc. but my counting is letting me down. Is there an easier way to do this?","['means', 'real-analysis', 'probability']"
2272385,Conditions on integral cubic polynomial with cyclic group and prime coefficients,"Let $f=T^{3}+aT+b\in\mathbb{Z}[T]$ irreducible. To prove that  if $f$ has cyclic
  Galois group and primes coefficients $a,b$, then $a=b$, Edit: added irreducible. 
(which I didn't). The discriminant  $\Delta=-2^{2}a^{3}-3^{3}b^{2}$ is a square, $r^{2}\in\mathbb{Z}^{2}$. Then $a<0$. If $(a,b)$ is a solution, then $(a,-b)$ is also a solution so we can take $(a,b)=(-p,-q)$ with with $p,q$ prime. Not all cyclic polynomials $T^3-aT-a$ have prime coefficient: for example, $a=9,27,49,63...$. Furthermore, one has cyclic cubics with only one prime coefficient: $T^3-31T-62$. However, if both coefficients are prime, they seem to be equal and furthermore this prime is $p\equiv 1\mod 3$. Let $a=-p$, $b=q$ so the discriminant is the square $\Delta=r^2=4p^3-27q^2$. Suppose $p^2\mid r^2$, so $m^2p^2=4p^3-27q^2$ with $m\in \mathbb{Z}$. Then $p^2(4p-m^2)=27q^2$. The case $p=3$ can be eliminated. Since $m^2\neq 4p$, then $p\mid q$ so $p=q$. Hence, $r^2=p^2(4p-27)=m^2p^2$ and $m^2=4p-27$ must be a square. This has lots of solutions in terms of $(m,p)$. I am not able to eliminate the case $p\neq q$ ""by hand"". Perhaps one needs more results from the cyclicity of the group than only knowing that the discriminant is a square? My inspiration dried out there. Evidence of this by numerical research: the integral coefficients $a,b$  such that $f$ is cubic cyclic is printed, and polynomials with prime coefficients are exclusively on the $x=y$ line (green spots), and exclusion multiple roots/zero discriminant $4x^3+27y^2=0$ in red.","['number-theory', 'polynomials', 'algebraic-number-theory', 'elementary-number-theory']"
2272396,Understanding a corollary of the universal property of tensor products of modules,"This is a follow-up question of a previous one of mine. The following theorem is from the Abstract Algebra by Dummit and Foote (in the section 10.4 tensor products of modules): Here are my questions : What does ""largest quotient of $N$"" mean in the proof? (Being ""largest"" in what sense?) How does one get ""It follows that $N/\hbox{ker}\iota$ is the unique largest quotient of $N$ that can be embedded in any $S$-module""? Would anyone elaborate how ""the last statement in the corollary follows immediately""? Here is the reference for Theorem 8 mentioned above.","['abstract-algebra', 'ring-theory', 'modules', 'tensor-products']"
2272443,Rectangle with lattice points,"Given a positive integer $n\geq 2$, consider all the lattice points with each coordinate between $1$ and $n$, inclusive. At least how many points must we choose to guarantee that some four points form a rectangle with sides parallel to the axes? $2n-1$ points do not suffice, because we can select the points $$(1,1),(1,2),\dots,(1,n),(2,1),(3,1),\dots,(n,1),$$ then  no rectangle is formed. For $n=2$, the answer is obviously $4$. For $n=3$, even $2n=6$ points do not suffice. We can choose $$(1,1),(1,2),(2,1),(2,3),(3,2),(3,3),$$ and again there is no rectangle. However, with $7$ points, some row is chosen completely, and since some other row must have at least two points, this forms a rectangle.","['combinatorics', 'contest-math', 'combinatorial-geometry']"
2272506,"If $X \sim N(0,1)$ and $Y \sim N(0,1)$ are two random variables that may or may not be independent, what is $E(XY)$?","If $X \sim N(0,1)$ and $Y \sim N(0,1)$ are two random variables that may or may not be independent, I am wondering what $\operatorname{E}(XY)$ might be. It appears they have the same distribution, but does that imply anything about independence?","['probability-theory', 'probability', 'statistics']"
2272558,Problem from Algebraic Curves by Fulton,"Suppose $ V $ is a variety in $ \mathbb{P}^n $ and $ V \supset H_\infty $. Show that $ V= \mathbb{P}^n $ or $ V = H_\infty $. If $ V= \mathbb{P}^n, V_* = \mathbb
{A}^n $ while if $ V = H_\infty, V_* = \emptyset $. My attempt: $ H_\infty = \mathbb{P}^n $\ $ U_{n+1} \subset V \subset \mathbb{P}^n $. Suppose $ v \in V $. I am trying to prove that $ v \notin U_{n+1} $. Any help is much appreciated. Thanks in advance for any replies. Notation: $ \mathbb{P}^n = $ projective $ n $ space. $ H_\infty = $ Hyperplace at infinity. $ V_* = V(I^*) $ where $ I^* = \{ (F_*)|F \in I \} $. $ F_* = F(X_1,...,X_n,1) $. $ U_{n+1} = \{ [x_1:...:x_{n+1}] \in \mathbb{P}^n | x_{n+1} \neq 0 \}. $","['algebraic-curves', 'algebraic-geometry']"
2272564,Is closeness in total variation preserved in conditioning?,"If we have two joint distributions on $(X,Y)$, $P_{X,Y}$ and $Q_{X,Y}$ that are close in $L^1$ or ""total variation"" with $\|P_{X,Y}-Q_{X,Y}\|_1<\varepsilon$ then: Are the distributions on the conditional expectations $P_{E[X|Y]}, Q_{E[X|Y]}$ also close in $L^1$, e.g. $\|P_{E[X|Y]}-Q_{E[X|Y]}\|_1<N\varepsilon$? In particular, what about the case where $Y=X+Z$ with $X\perp Z$? If $X,Y$ are finite mean and variance, then are the means and variances of $E[X|Y]$ under the two distributions close? Assuming they are all continuous RVs, the difference is: \begin{align}
\left|P_{E[X|Y]}(w)-Q_{E[X|Y]}(w)\right| &= \left|\int_{y\in A_P} P_Y(y) dy -\int_{y\in A_Q } Q_Y(y) dy\right| 
\end{align} with $A_P=\left\{y:\int x P(X=x|Y=y) dx = w\right\},\ A_Q=\left\{y:\int x Q(X=x|Y=y) dx = w\right\}.$ I can't figure out how to make the difference between the two sets small, which makes me suspicious that conditional expectation is unfortunately not continuous in this sense.","['functional-analysis', 'real-analysis', 'conditional-expectation', 'probability-theory']"
2272572,Why does $\sqrt{i^4} \neq i^2$.,"I was looking at a problem $\sqrt{x}=-3$, and I had at first thought $x=9 i^4$ was a solution. ($\sqrt{9 i^4}=3i^2=-3$) Though I then realized that this would cause some problems. For example using this, we would have $\sqrt{i^4}=i^2=-1$. While on the other hand $\sqrt{i^4}=\sqrt{1}=1$. I checked Wolfram and it says that $\sqrt{i^4} \neq i^2$ (also $(i^4)^{1/2}$). Could any one explain to me why we can't treat the exponents of $i$ this way? Is it possible to algebraically show that $\sqrt{x}=-3$ has no solutions? I am trying to learn some complex analysis and this made me realize that I might have some really bad intuition on complex numbers.",['complex-analysis']
2272580,Why is eigendecomposition $V \Lambda V^{-1}$ not $V^{-1} \Lambda V$,"Say you have a linear transformation matrix $A$. In the basis of eigenvectors, this transformation simply becomes a scaling, represented by the diagonal matrix of eigenvalues. Thus, intuitively the transformation A can be decomposed into the following: Transform into the basis of eigenvectors (using the transformation matrix $V$, where the eigenvectors form the columns) Apply the scaling. Transform back. This would seem to correspond to $V^{-1} \Lambda  V$, where the standard notation of matrices being applied on the left and vectors on the right holds. Yet everywhere I always see the formula as $V \Lambda  V^{-1}$. Why isn't my intuition correct?","['eigenvalues-eigenvectors', 'linear-algebra', 'linear-transformations']"
2272615,Heisenberg inequality proof,"Suppose $f \in L^2(\mathbb{R})$. Pick $~f_n \in C^{\infty}_{\downarrow}(\mathbb{R})$ such that $$\|f_n-f \|_2 + \|f_{n}^{'}-f'\|_2 = \int(1+4\pi^2\gamma^2)\, | \, \hat f_n-\hat f|^2 \, d\gamma \rightarrow 0 ~~ \text{as}~n\rightarrow\infty,$$
where $f' := [2\pi i \gamma \hat f]^{\check{}}.$ (I've proved that we can always choose such functions $f_n$. Here,  $C^{\infty}_{\downarrow}(\mathbb{R})$ means that if $f \in C^{\infty}_{\downarrow}(\mathbb{R}),$ then $f$ is infinitely differentiable and $|x^p||D^q f| \rightarrow 0$ as $|x| \rightarrow \infty$ for any nonnegative integers $p$ and $q$.) I also know that $f_n \rightarrow f$ uniformly. What I want to know is: $$\int_{0}^{x} f'(y) \, dy = \lim_{n\rightarrow\infty} \int_{0}^{x} f_n'(y) \, dy$$
to check that $f'$ $really$ $is$ $the$ $derivative$ $of$ $f$. The book (Dym, Fourier Analysis) says that this can be easily checked, but I have no idea how to prove this. Any help will be appreciated!","['schwartz-space', 'fourier-analysis', 'measure-theory', 'fourier-transform']"
2272650,Find a continuous function having following properties.,"Which of the following statements is/are true? There exists a continuous map $f:ℝ\to ℝ$
  such that $f(ℝ)=\mathbb{Q} $. There exists a continuous map $f:ℝ\to ℝ$
  such that $f(ℝ)=\mathbb{Z} $. There exists a continuous map $f:ℝ\to ℝ^2$
  such that $f(ℝ)=\{(x,y)\in\mathbb{R^2: x^2+y^2=1}\}$. There exists a continuous map $f:[0,1]\cup[2,3]\to \{0,1\}$ So I try to solve and showed that first option is false, by assuming that there exists a continuous map from $f:ℝ\to ℝ$
such that $f(ℝ)=\mathbb{Q} $.  If there were, then we could find
$a,b ∈ R$ with $f(a) = 1$ and $f(b) = 2$. Either $a < b$ or $b < a$. Let’s suppose $a < b$. Since $f(x)$ is continuous on
$R$ it is also continuous on $[a,b]$. By the intermediate value theorem, and the fact that $1 <
\sqrt{2} < 2$, there exists
a $c ∈ (a,b)$ such that $f(c) =
√ 2$. But $\sqrt{ 2} \not \in Q$, hence $f(R)$, which includes $f(c)$, cannot just be $Q$. Now my concerns are- 
Can I argue similarly for option 2? My intuition says that option 3 and 4 are correct. But I am unable to find explicit functions so far. Can anyone help me to clear my doubts? Thanks.","['continuity', 'real-analysis', 'functions']"
2272651,leading order behavior and finding the first two terms of the solutions of $t^3u''-u=0$,"I am attempting to solve a problem regarding asymatotics. I would greatly appreciate if people would comment Problem Find the leading behavior of the ODE , ie the first two terms of each of the two solutions of the ode $t^3u''-u=0$ As $t \rightarrow 0^+$ My attempt If we let $u = e^\psi$, then that will imply $u'= \psi' e^\psi$ and $u''= \psi''e^\psi + (\psi ')^2e^\psi$. If we replace this into the ode, we get $$t^3(\psi'' + (\psi ')^2)=1$$ From here I decided to guess that $\psi = At^p$. If we plug this back into the previous line we get $$t^3(Ap(p-1)t^{p-2}+Apt^{p-2})=1$$ This observing the powers we get $3+p-2=0$ because on the left hand side we have a polynomial equation of power $3+p-2$ while on the right hand side we have a constant ie a polynomial of degree 0. Thus $p=-1$. I am not sure if this is correct, idea, please comment. I know some people do the method of dominant balance on $t^3(\psi'' + (\psi ')^2)=1$, but I am unsure how does that work and was thinking my idea has some merit.","['real-analysis', 'ordinary-differential-equations', 'asymptotics']"
2272699,Useful reformulation of Goldbach's conjecture?,"Let us assume there exists some infinite order differential equation whose solution is: $$ y= \sum_{n=1}^\infty A_n \exp(p_n^sx)  $$ Where $p_n$ is the $n$'th prime. Substituting $ y=\exp(\lambda x)$ as a trail solution and factorizing. The differential equation must be simplified and factorized to: $$ \prod_{j=1}^\infty (\lambda-p_n^s) = 0$$
$$ \implies \prod_{j=1}^\infty (1-\frac{p_n^s}{\lambda}) = 0$$ Expanding the above equation: $$\implies 1 - (\sum_{i} p_i^s)\frac{1}{\lambda} + \sum_{i < j} (p_i p_j)^s \frac{1}{\lambda^2} - \sum_{i<j<k} (p_i p_j p_k)^s \frac{1}{\lambda^3} + \dots + \lim_{n \to \infty} \sum_{i<j<\dots<n}(-1)^n (p_i p_j \dots p_n)^s \frac{1}{\lambda^n} = 0 $$ Writing more compactly: $$ 1+ \sum_{n=1}^\infty \sum_{x_i<x_j<\dots<x_n} (p_{x_i}p_{x_j} \dots p_{x_n})^s = 0 $$ We conjecture that $\sum_{x_i<x_j<\dots<x_n} (p_{x_i}p_{x_j}\dots p_{x_n})^s $ can be analytically continued as some function of $ P(s)$ where $P(s)$ is the prime zeta function Hence, for $f_1(P(s)) = P(s)$ And $ f_2(P(s)) = P(s)^2 - P(2s)$ And so on ... Where $f_n(P(s))$ is given by comparing the below equation to the equation before the analytic continuation: $$ 1 + \frac{f_1(P(s))}{\lambda} + \frac{f_2(P(s))}{\lambda^2} + \dots = 0 $$ Writing it compactly: $$ 1 + \sum_{i}^\infty \frac{f_i(P(s))}{\lambda^s} =0  $$ Note this can be thought as of the solution of a integral: $$ y + f_1(P(s))\int_{-\infty}^x y(x) dx +  f_2(P(s))\int_{-\infty}^x (\int_{-\infty}^k y(z) dz) dk + \dots$$ (To verify this subsitute $y=Ae^{2x}$)
Writing it compactly: $$ y + \sum_{i=1}^\infty f_i(P(s)) \int_{- \infty}^x (\int_{- \infty}^x (\dots( \int_{- \infty}^x y dx )dx)\dots \text{$i$ times})dx) = 0  $$ Strategy from Here My idea was to take some asymptotic limit as $s \nearrow 1$ and rewrite this as a integral equation for $y^2$. Since, $$ y=\sum_{i=1}^\infty A_i \exp{p_i x}  $$ Setting $A_1=0$ and squaring: $$ y^2 = \sum_{i,j}A_{ij}' \exp{(p_i + p_j)x} = \sum_i^\infty B'_i e^{2ix} $$ By Goldbach's conjecture the rightmost side must contain all the even powers. Questions Is this a viable strategy or useful reformulation of Goldbach's conjecture? (Is it easier to show $y^2 =\sum_i^\infty B'_i e^{2ix} $as a solution)? Is the analytic continuation valid?","['analytic-number-theory', 'goldbachs-conjecture', 'asymptotics', 'integral-equations', 'ordinary-differential-equations']"
2272712,Halving a vector and halving an angle,"An object is subjected to two equal forces along two different directions. If the magnitude of one of them is halved, the angle which the new resultant makes with the other component force is also halved. What is the angle between the forces? Well I'm not sure whether the vector notation in the second figure is right or not – if wrong please correct it (I'm learning vectors).","['analytic-geometry', 'vectors', 'geometry']"
2272738,On the sine of a two by two matrix with integer entries,"Let $A \in M(2,\mathbb Z)$ ; Let $\sin A :=\sum _{n=0}^\infty \dfrac {(-1)^n}{(2n+1)!}A^{2n+1}$ (This series is known to converge absolutely in the Banach space $\mathcal L(\mathbb R^2)$ under Operator norm ) . If $\sin A \in M(2,\mathbb Z)$ , then is it true that $A^2=O$ ?","['matrices', 'number-theory', 'banach-spaces', 'linear-transformations']"
2272755,The assumptions of the substitution theorem in double integral,"Let 
$$
\mathrm{T}: 
\left\{
  \begin{array}{l}
    u=u(x,y) \\
    v=v(x,y)
  \end{array}
\right.
$$
be a change of variables substitution, where $u$ and $v$ have continues partial derivative in an open set $D$. In addition we assume that the Jacobian 
$$
\frac{\partial(x,y)}{\partial(u,v)}
$$ 
of $T$ does not vanish in $D$ and that $f(x,y)$ is integlable in the image $T(D)$. Under these condition I know that the formula of substitution in double integral is 
$$
\iint_{\mathrm{T(D)}}f(x,y)\,dxdy
=\iint_{\mathrm{D}}f(x(u,v),y(u,v))\left|\frac{\partial(x,y)}{\partial(u,v)}\right|\,dudv
$$
Am I missing any condition on the boundary of the set $D$? What should we assume further on the set $D$? Should it be connected? bounded? Thanks!",['multivariable-calculus']
2272773,$A$ and $B$ are the positive acute angles satisfying the equations $3\cos^2 A + 2\cos^2 B=4$,"$A$ and $B$ are the positive acute angles satisfying the equations $3\cos^2 A + 2\cos^2 B=4$ and $\dfrac {3\sin A}{\sin B}=\dfrac {2\cos B}{\cos A}$. Then $A+2B$ is equal to: $1$. $\dfrac {\pi}{4}$ $2$. $\dfrac {\pi}{3}$ $3$. $\dfrac {\pi}{6}$ $4$. $\dfrac {\pi}{2}$. My Attempt $$\dfrac {3\sin A}{\sin B}=\dfrac {2\cos B}{\cos A}$$
$$3\sin A.\cos A= 2\cos B.\sin B$$
$$\dfrac {3}{2} \sin 2A=2\sin 2B$$. How do I proceed further?","['algebra-precalculus', 'trigonometry']"
2272790,"For a finite complement topology , to which point or points does the sequence converge?","For a finite complement topology on $R$  to which point or points does the sequence ${\frac{1
}{n}}$ converge? For a finite complement topology on real numbers the only set including the limit point of sequence is $R$ so the sequence converges to every point of $R$. Am I right?",['general-topology']
2272795,When eigenvectors for a matrix form a basis,"It is well known that if n by n matrix A has n distinct eigenvalues, the eigenvectors form a basis. Also, if A is symmetric, the same result holds. Consider $ A =\left[ {\begin{array}{ccc}
   1 & 2 & 3 \\
   0 & 1 & 2 \\
   0 & 0 & 1 \\
\end{array}}\right]
$
. This matrix has single eigenvalue $\lambda=1$, and is not symmetric. But, the eigenvectors corresponding to $\lambda=1$,
($
v_1 =\left[ {\begin{array}{c}
   1  \\
   0  \\
   0  \\
\end{array}}\right]
$
, 
$
v_2 =\left[ {\begin{array}{c}
   0  \\
   1/2  \\
   0  \\
\end{array}}\right]
$
,
$
v_3 =\left[ {\begin{array}{c}
   0  \\
   -3/8  \\
   1/4  \\
\end{array}}\right]
$
)
form a basis. What sufficient conditions offer the above result?","['eigenvalues-eigenvectors', 'matrices', 'matrix-calculus', 'matrix-decomposition', 'eigenfunctions']"
2272806,Does this type of matrix have orthogonal eigenvectors?,"In this paper , it is claimed that the following matrix has orthogonal eigenvectors:
$$M=\left[\begin{matrix} I & \Delta A \\ -\Delta A^T & I + \Delta^2 A^T A\end{matrix}\right]$$
where $A$ is a real matrix, $I$ is the identity matrix, and $\Delta$ is a real number. $M$ is neither Hermitian nor anti-Hermitian, either of which would imply having orthogonal eigenvectors. Does $M$ have orthogonal eigenvectors? How can this be proven?","['matrices', 'eigenvalues-eigenvectors']"
2272868,The change in rate and Poisson distribution,"I was given the births in a country follow a Poisson process in which on average number of babies born in $24$ hours is $11.7$. I figured out this indicates $0.4875$ babies are born per hour. So how can I find the probability of more than $3$ hours between births? Is this a change in rate? I'm new to probability and statistics. The answer is $0.2317$, but how was it calculated ?","['statistics', 'probability', 'poisson-distribution']"
2272872,Number of real roots to $4^{\sin^2{x}}-2^{\cos{2x}}+1=0.$,"Problem: Find the number of real roots to the equation $$4^{\sin^2{x}}-2^{\cos{2x}}+1=0 \ , \ \ \ \ \ \ \ \ \ 0<x\leq\pi.$$ Attempt: Simplifying i get $$2^{2\sin^2{x}}-2^{\cos{2x}}=2^{2(1-\cos{2x})}-2^{\cos{2x}}=\frac{2^2}{\left(2^{\cos{2x}}\right)^2}-2^{\cos{2x}}=-1.$$ Setting $t=2^{\cos{2x}}$ gives the third degree equation $$\frac{4}{t^2}-t+1=0 \Longleftrightarrow t^3-t^2-4=(t-2)(t^2+t+2)=0 \Longleftrightarrow t_{\mathbb{R}}=2.$$ So $$2^{\cos{2x}}=t=2=2^1 \Longleftrightarrow \cos{2x}=1 \Longleftrightarrow x=\pi k \ , \ k\in \mathbb{Z}. $$ So, $k=0\Rightarrow x=0$ and $k=1\Rightarrow x=\pi.$ The only solution of $x$ that lies in the interval $(0,\pi]$ is given when $k=1$, thus the equation only has one solution in the given interval. Questions: 1) I got the correct answer, but is my reasoning correct? Just wan't to make sure that the correct answer isn't just an accident/coincidence. 2) During the simplification step, I used that $\cos{2\theta} = 1-2\sin^2{\theta} \Leftrightarrow 2\sin^2{\theta}=1-\cos{2\theta}.$ Is there a more efficient way of using any other identity? 3) I factored the equation $t^3-t^2-4 = 0$ using a computer, but how can I solve it without knowing that one root is 2, in order to factor?",['trigonometry']
2272874,How is this histogram correct?,"Looking at this histogram in Wikipedia (one on the right and not the ones at the bottom), I am unable to understand how it is correct or is there a flaw in my understanding. Bin   Count
−3.5     23
−2.5     32
−1.5    109
−0.5    180
 0.5    132
 1.5     34
 2.5      4
 3.5     90 Given the above information, I can infer that the bins are -: -3.5 to less than 2.5 -2.5 to less than -1.5 and so on. Is this inference correct or am I missing something here ? If the above inference is correct then the looking at the first column is for 23 values occurring in the first bin. What is weird is the last bin(for 3.5, the last element in the table) for which there are 90 values in the table but the values shown in the histogram are lesser than the 23 values in the first column. How is that possible ? Is that correct ? Or are my concepts lacking somewhere ?","['statistics', 'visualization']"
2272875,Hrushovski's proof of the Manin-Mumford Conjecture,"For my master's thesis, I am studying Hrushovski's model-theoretic proof of the Manin-Mumford Conjecture. Among the references I have used are the following: Lecture notes 'Model Theory of Difference Fields' by Chatzidakis 'A Survey on the Model Theory of Difference Fields' by Chatzidakis 'Théorie des modèles et conjecture de Manin-Mumford' by Bouscaren https://eudml.org/doc/110272 Hrushovski's article on http://www.sciencedirect.com/science/article/pii/S0168007201000963 My first goal is to understand the following proposition (crl. 4.1.13 in (4)): Let $A$ be an Abelian variety, defined over $Fix(\sigma)$. Let $p(T)$ be a polynomial with integer coefficients. Then $\ker(p(
\sigma))$ is LMS $\iff$ $p$ has no cyclotomic factors. Here, a definable group $B$ is LMS (stable, stably embedded,
locally modular) if every definable subset of $B^n$ (with parameters possibly outside $B$)
is a finite Boolean combination of cosets of definable subgroups of $B^n$. References 2. and 3. both give the big steps in the proof without providing all details. As far as I understand, the strategy of the proof is as follows: Reduce to the case that $A$ is a simple Abelian variety. Let $H = \ker(p(\sigma))$. Towards contradiction, suppose that $H$ is not LMS. If $H = \ker(f_1\cdot \dots \cdot f_k)$ with $f_i$ irreducible in $\mathbb{Q}\otimes \operatorname{E}(A)$, where $E(A)$ the definable endomorphisms of $A$, then one of the $\ker(f_i)$ is not LMS. So reduce to the case that $H=\ker(f_i)$. It follows that $H$ is $c$-minimal and has finite $\sigma$-degree. By the classification of weakly normal groups of Hrushovski and Pillay, it follows that $H$ is not modular and stable. Then by the Dichotomy theorem in characteristic 0 (Chatzidakis and Hrushovski), $H$ is not orthogonal to $\sigma(x)=x$. It follows that $\ker(f_i)\subseteq \ker(\sigma^N -1)$ for some $N$. Now by choosing $N$ large enough, $f_i$ becomes invertible, which contradicts the assumption that it was irreducible. Therefore, $H$ is LMS. However, I do not succeed in matching these steps to the actual proof in the article by Hrushovski. I have the following specific questions: (i). In  reference no. 2., the dichotomy theorem is about stable formulas in the sense of stability theory. In reference no 3., an algebraic condition for a stable set is given. Why are these definitions equivalent in this context? (ii). What is the definition of a stable type? How does it follow that a superficially stable type is stable and stably embedded? (iv). Apparently, it follows from the classification of $c$-minimal subgroups of abelian varieties (Hrushovski prop. 4.1.2)  and the theorem by Hrushovski and Pillay that because $\ker(f_i)$ is $c$-minimal, that it is not stable and modular. However, I do not see how that follows, because the notion of weakly normal groups is not used in Hrushovski's article. Could somebody perhaps help me find an answer to these questions or refer me to literature?","['model-theory', 'stability-theory', 'algebraic-geometry', 'abelian-varieties']"
2272886,probability (Bayes' rule),"In a country, the prevalence of malaria is observed to be 43 out of every 1000 people. The test for malaria is a 90% chance of detecting it when the patient is suffering from malaria. The same test yields a negative result in 95% of the cases of people not infected with malaria. What is the posterior probability that a person has malaria if test returns positive ? what I have tried is- $$\frac{0.90 \times 0.043}{(0.90\times0.043+(1-0.95)\times0.043)}$$ is this correct ?? or this- $$\frac{0.90\times0.043}{(0.90\times0.043+0.95\times0.043)}$$","['bayes-theorem', 'probability-theory', 'probability']"
2272889,very hard differential equations,"Hi I would need help with solving the two following differential equations: $\dot{N} =\left(a\frac{\dot{x}(t)}{x(t)} -  b\frac{\dot{y}(t)}{y(t)} - c \frac{\dot{z}(t)}{z(t)} \right) \alpha N$ $\dot{N} =\left(a\frac{\dot{x}(t)}{x(t)} -  b\frac{\dot{y}(t)}{y(t)} - c \frac{\dot{z}(t)}{z(t)} \right) \alpha(t)N$ I also know that $N = (px(t) - ry(t) - sz(t))\frac{1}{\alpha+\kappa} $ and $N = (px(t) - ry(t) - sz(t))\frac{1}{\alpha(t)+\kappa}$ respectively - although I am not sure if this information is crucial or not. The way I was thinking to approach this problem is that I know there is a class of separable differential equations: $\frac{dx}{dt}= F(t)g(x)$ And I know how to solve these, but I have no idea if 1. or 2. can be expressed in such form. I think that this should be possible since everything in brackets is a function of t, but I don't think that it is rigorous to just say that $F(t)=\left(a\frac{\dot{x}(t)}{x(t)} -  b\frac{\dot{y}(t)}{y(t)} - c \frac{\dot{z}(t)}{z(t)} \right)$. But I don't know if then the rule for separable differential equation still applies as this would make F a compound function. I also tried to work with inverse functions $t(x)=x^{-1}(t)$, $t(y)=y^{-1}(t)$ and $t(z)=z^{-1}(t)$ and their derivatives, but I feel that just confused me even more. I have never encountered a complex problem such as this so any help would be much appreciated.","['multivariable-calculus', 'ordinary-differential-equations']"
2272903,"Do you ""sample"" a random number generator? If not, what's the correct word?","This is basically an English language question, but since it pertains to mathematics and programming quite directly, I'll post it here. Let $D$ denote a random number generator. More precisely, assume that $D$ is a probability measure on the real line. Maybe it's the standard normal distribution or something. Imagine we've implemented $D$ on a computer, and we decide to ""sample"" it 10 times and put the values thereby obtained the variables $x_0,\ldots,x_9$. Question. What's the correct word for what I'm refer to as ""sampling""?","['terminology', 'probability', 'computer-science']"
2272922,What is this equality: $\frac{\theta/(\theta+1)^{x+k}}{\theta^k}=(\frac1{\theta+1})^k(\frac{\theta}{\theta+1})^x$? How to work it out?,"I am struggling with this equality, which I found in George C. Canavos Applied Probability and Statistical Methods : $\frac{\theta / (\theta + 1)^{x+k}}{\theta^k} = \left(\frac{1}{\theta + 1}\right)^k \left(\frac{\theta}{\theta + 1}\right)^x$ How do I work it out? Is it a known equality? Cheers Update In sight of your kind answers, I start feeling this may be a typo in Canavo's book. I attach a capture from the book's page where the equality appears. As you see, there is no outer parenthesis:","['algebra-precalculus', 'fractions']"
2272972,How can we control $\beta$ to make the mass of the n-dimensional unit ball concentrate in a layer?,"As a special phenomenon of high dimension, we know that for arbitary $\epsilon>0$,  as $n \rightarrow ∞$. we have: Where $m$ denotes the Jordan measure and $B_n$ denotes the $n$-dimensional unit ball. We say that the mass of the ball $B_n$ concentrates in an $O(n^α)$ boundary layer if Now I am asked to find a infimum for $\alpha$ to make the mass concentrates in an $O(n^α)$ boundary layer. That is, find the $\beta$ defined as: $\beta:=inf\lbrace α < 0 :$ Mass of $B_n$ concentrates in an $O(n^α)$ boundary layer.$\rbrace$. And once we find the $\beta$, may I ask what can we say about the concentration of mass if (1)$α < β$, (2)$ \alpha=\beta$, (3) $\alpha>\beta$? I have not exposed to some convoluted high-dimensional geometry context and I find myself lost in this question so far. I searched but I cannot find any material which can lead me to a start point. May I please ask for an answer (together with some explaination) if possible? Or any help or reference would be appreciate. Thanks in advance!","['volume', 'real-analysis', 'measure-theory', 'geometry']"
2273069,A smooth map which has full rank at a point is locally a submersion/immersion.,"Let $F:M\rightarrow N$
  be a smooth map between manifolds and let $p\in M$
 . If $dF_{p}$
is surjective, then there exists a neighbourhood $U$
of p
such that $F|_{U}$
is a submersion. If $dF_{p}$
is injective, then there exists a neighbourhood $U$
of $p$
such that $F|_{U}$
is an immersion. I saw this theorem in Lee's Introduction to Smooth Manifolds. This is his proof: What I don't understand is the part where says ""by continuity"". Is he talking about a function that is continuous? If so, what function is it?","['continuity', 'differential-geometry']"
2273072,Exercise 5.3 in Calculus Made Easy: are these answers equivalent?,"Exercise 5.3 in Calculus Made Easy , by Silvanus Thompson, is to find $\mathrm d\over \mathrm dx$ when the following relationship holds ($a$ and $b$ are both constants): $$ay + bx = by - ax + (x + y)\sqrt{a^2 - b^2}$$ I tried differentiating both sides of this equation with respect to $x$ as follows: $$\begin{align}
{\mathrm d\over \mathrm dx}(ay + bx) &= {\mathrm d\over \mathrm dx}\left(by - ax + (x + y)\sqrt{a^2 - b^2}\right)\\
a{\mathrm dy\over \mathrm dx} + b &= b{\mathrm dy\over \mathrm dx} - a + \left(1 + {dy\over dx}\right)\sqrt{a^2 - b^2}\\
\left(a - b - \sqrt{a^2 - b^2}\right){\mathrm dy\over \mathrm dx} &= \sqrt{a^2 - b^2} - a - b\\
{\mathrm dy\over \mathrm dx} &= {\sqrt{a^2 - b^2} - a - b \over a - b - \sqrt{a^2 - b^2}}
\end{align}$$ The author has considerably more finess and first does some algebraic manipulation to get the equation into better shape. First he squares both sides, then pushes some things around, then takes the square root of both sides: $$\begin{align}
(a - b)^2y^2 + (a + b)^2x^2 + 2(a + b)(a - b)xy &= (x^2 + y^2 + 2xy)(a^2 - b^2)\\
\left[(a - b)^2 - \left(a^2 - b^2\right)\right]y^2 &= \left[\left(a^2 - b^2\right) - (a + b)^2\right]x^2\\
2b(b - a)y^2 &= -2b(b + a)x^2\\
y &= \sqrt{a + b \over a - b}x\\
{\mathrm dy\over \mathrm dx} &= \sqrt{a + b \over a - b}
\end{align}$$ I believe that both answers are correct, but if that is true, it should be possible to convert one to the other algebraically. For the life of me, I can't see how to do this. So my question is: are these two answers really equivalent?",['calculus']
2273095,Showing a Hilbert space operator to be zero under some conditions,"Let $H$ be a Hilbert space and $T:H\to H$ be a bounded linear operator satisfying $\left\langle T^{2}(x), x \right\rangle \geq 0$ and  $\left\langle Tx, x \right\rangle =0$ $\forall x \in H$.    Show that $T=0$. I want to show  $\langle Tx, y \rangle =0$ for all $x, y \in H$.  But I haven't been able to do it.  Also I think that the adjoint operator can come into play. But I cannot manipulate the two conditions. Thank you!","['functional-analysis', 'operator-theory', 'hilbert-spaces']"
2273100,Substitution Integral: $\int_0^3\frac {\sqrt{x}}{\sqrt{x}+\sqrt{3-x}} dx$,"$$\int_0^3\frac {\sqrt{x}}{\sqrt{x}+\sqrt{3-x}} dx   $$ I tried with substitution $t=3-x$ but I don't know what to do next.
Also how do I solve this limit: $$\lim_{x\to\infty}\frac{1}{x}\int_0^x\frac{dt}{2+\cos t} $$ I saw that most problems like this are solved by putting the period of the function in front,would it work here?","['integration', 'definite-integrals']"
2273108,Polygon-in-polygon testing,"I have a list of vertices of simple polygons, and I would like to test whether or not a polygon is fully contained in another polygon in the list. Is it sufficient to do something like: Let $p_0$ be the candidate polygon. Let $r_i, ~le_i, ~u_i, ~l_i$ denote the right most, left most, upper most and lower most vertex of the ith polygon in the list. For all polygons in the list, if any polygon has: $r_i(x) \ge r_0(x)$ AND $le_i(x) \le le_0(x)$ AND $u_i(y) \ge u_0(y)$ AND $l_i(y) \le l_0(y)$ where for example $r_i(x)$ denotes the $x$-coordinate of the rightmost vertex of the $i$-th polygon, then we may conclude that $p_0$ is fully contained within $p_i$. Does this make sense, and is there a counter example for which this algorithm doesn't work?","['algorithms', 'polygons', 'geometry']"
2273109,Roots of equation having x in the exponent: $9^x + 2(1-a) 3^x + a = 0$,The equation to be solved is  $9^x + 2(1-a) 3^x + a = 0$. We have to find all integral values of $a$ between $1$ and $30$ for which the above equation has roots of opposite sign. I substituted $3^x = t$ and got the equation $ t^2 + 2(1-a)t + a= 0$. Applied Discriminant $\ge 0$. But I could not get any solution.,"['algebra-precalculus', 'roots', 'exponentiation', 'quadratics']"
2273140,A Question From Shiryaev,"I was studying about $\lambda$-systems from Shiryaev where I countered the following statement about equivalence of conditions for defining a $\lambda$-system. I can check the equivalence of the second set of conditions given the first. However, going the other way, I am not able to show condition $(\lambda_{b})$ given conditions $(\lambda_{a}), (\lambda'_{b})$ and $(\lambda'_{c})$. Can someone please provide a hint on how to prove this?",['probability-theory']
2273172,Are these two equalities equivalent: $ABA=0$ and $BA=0$? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question There are two equalities as follows: $ABA=0$ , $BA=0$ where $A$ and $B$ are two $n\times n$ matrices. Are the mentioned equalities the same? if not, why? Thanks in advance.","['matrices', 'matrix-equations', 'examples-counterexamples', 'linear-algebra']"
2273189,Finding the minimum value of a given expression,"As the title pretty much sums it up, I'm wondering what is the best way of finding the minimum value of an expression. For instance, we have the expression $E$ defined as: $$E=x^2+4x+y^2-10y+1$$ I currently have solved it using two different methods: Forming squares of binomials Breaking it into two different expressions and finding the minimum value depending on their context - clarifications below Solution 1: $$E=x^2+4x+y^2-10y+1$$ $$E=(x^2+4x+4)+(y^2-10y+25) - 4 - 25 + 1$$ $$E=(x+2)^2+(y-5)^2 - 28$$ We know that $(x+2)^2 \geq 0$ and than $(y-5)^2\geq0$ , and thus $E_{min} = -28$ , for $x=-2$ and $y=5$ . Solution 2: Let $E_{x} = x^2+4x$ and $E_{y}=y^2-10y$ . Therefore, $E_{min}=E_{xmin}+E_{ymin}+1\tag1$ Now, for $E_{x}$ to be as small as possible, $x\leq0$ , and if so: $$E_{x} = x^2-abs(4x)\implies abs(4x)>x\cdot x\tag2$$ $$(2)\implies 0\geq x\geq -4$$ Checking all four values, $E_{xmin} = -4$ , for $x=-2$ . The same goes for $E_{ymin}$ , which results in $0\geq y\geq -10$ . Checking all the values, $E_{ymin} = -25$ , for $y=5$ . $$(1)\implies E_{min}=-25-4+1\implies E_{min}=-28$$ (Of course for the values of x,y mentioned above) I personally think that Solution 1 is the best, and I wonder if there is another possible solution and also which of these is recommended in this case.","['algebra-precalculus', 'optimization']"
2273190,Differentiation inside a conditional expectation,"Let $(\Omega, \mathcal{F},P)$ be a probability space. If $X:\Omega\to\mathbb{R}^n$ is a random variable such that $E[|X|]<\infty$, and if $\mathcal{H}\subset\mathcal{F}$ is a $\sigma$-algebra, then the conditional expectation of $X$ given $\mathcal{H}$, denoted by $E[X|\mathcal{H}]$, is defined as the (a.s. unique) function from $\Omega$ to $\mathbb{R}^n$ satisfying: (1) $E[X|\mathcal{H}]$ is $\mathcal{H}$-measurable (2) $\int_HE[X|\mathcal{H}]dP=\int_HXdP$, for all $H\in\mathcal{H}$ Suppose that $Y:U\times \Omega\mapsto \mathbb{R}^n$
for  some open subset $U\subset \mathbb{R}$.
Further suppose that $Y$ is $C^1$ for a.a. $\omega\in\Omega$, and a random variable, i.e. $P$-measurable, for each $x\in U$. Assume also that $E[|Y(x,\cdot)|]<\infty$ for all $x\in U$. Let $\mathcal G\subset \mathcal{F}$ be a sub-$\sigma$-algbebra. How do we know 1) if $\frac{\partial}{\partial x} E[Y(x,\cdot)|\mathcal G]$ exists for each $x$ a.s.? 2) when $$\frac{\partial}{\partial x}E\left[Y(x,\cdot)|\mathcal G\right]= E\left [\frac{\partial}{\partial x}Y(x, \cdot)|\mathcal G\right]$$ a.s.?","['derivatives', 'probability-theory', 'lebesgue-integral', 'measure-theory', 'conditional-expectation']"
2273194,A compact operator on a non-separable Hilbert space has $0$ in its point spectrum,"If $H$ is a non-separable Hilbert space and $T:H \to H$ be compact , then show that $0 \in \sigma_{p}(T)$. I have no idea about working on a non-separable Hilbert space. It is obvious that it won't have a countable orthonormal basis. Apart from that I don't know anything about non-separble Hilbert Space. Thanks in advance !!!","['functional-analysis', 'operator-theory', 'hilbert-spaces']"
2273202,The spectrum of a bounded linear operator on a $X=C[0;1]$,"I am working with the book ""Introductory Functional Analysis With Applications"", written by Kreyzig and I got the trouble with problem 1 and problem 2 in section 7.3, which are: Problem 1: ""Let $X=C[0;1]$ and define $T: X \rightarrow X$ by $Tx=vx$, where $v \in X$ is fixed. Find $\sigma (T)$. Note that $\sigma (T)$ is closed.
"" Problem 2: ""Find a linear operator $T: C[0;1] \rightarrow C[0;1]$ whose spectrum is a given interval $[a,b]$."" There is a hint for problem 1 that $\sigma (T)$ is the range of $v$. However, I have no idea of proving this. Could you please help me to explain those problems in detail? Thank you so much.","['functional-analysis', 'banach-spaces', 'operator-theory', 'spectral-theory']"
2273203,Uncountable sum of holomorphic functions is holomorphic?,"When I have a function $f\left( \alpha ,z \right)$ depending on a parameter $\alpha \in [0,1]$ and $z\in K \subset \mathbb{C}$, where $K$ is a domain on which $f\left( \alpha ,z \right)$ is holomorphic for all $\alpha \in [0,1]$ it's true in general that 
$\int_0^1 f\left( \alpha ,z \right) d \alpha$ is holomorphic again or there are some pathological cases where it's not?","['complex-analysis', 'holomorphic-functions']"
2273209,Question on an interval that makes the solution unique,"http://www.math.uiuc.edu/~tyson/existence.pdf (example 5) In the example, the solution for the interval is $\delta_2 = |x_0|$. I'm confused on how they got that. What was the algebraic step to solve for $\delta_2$? I mean I can reason it out, and it makes sense. However, how do I actually solve for it algebraically? Thank you!",['ordinary-differential-equations']
2273224,Two definitions of $\mathcal{O}_{\mathbb{P}^{n}}(l)$,"On the one hand, we may define $\mathcal{O}_{\mathbb{P}^{n}}(l)$ as the invertible sheaf with trivializing cover $\{D(X_i): i\in \{0,...,n\}\}$ and transition functions $\left(\frac{X_i}{X_j}\right)^l$. On the other hand, we may define it as the sheaf of modules induced by the graded module $K[X_0,...,X_n](l)$. I would like to proof that these definitions are equivalent. One way could be finding transition functions for the sheaf of the second definition. If they are $\left(\frac{X_i}{X_j}\right)^l$ we are done, but I am finding hard to show this.","['quasicoherent-sheaves', 'algebraic-geometry']"
2273226,"If $a\cos(θ)=b$ $\cos( θ+2π/3)=c\cos(θ+4π/3)$, prove that $ab+bc+ca=0.$","THE PROBLEM : If $a\cos(θ)=b$ $\cos( θ+2π/3)=c\cos(θ+4π/3)$, prove that $ab+bc+ca=0.$ MY THOUGHT PROCESS : We have to prove that $ab+bc+ca=0$. One method using which we can do this is, if we can somehow obtain the equation $k(ab+bc+ca)=0$ we can deduce that $ab+bc+ca=0$ using the zero product rule. Another method to do this would be to obtain an expression which has $(ab+bc+ca)$ in it. The identity $(a+b+c)^2=a^2+b^2+c^2+2(ab+bc+ca)$ has $2(ab+bc+ca)$ in it. Therefore if we can somehow show that $(a+b+c)^2=a^2+b^2+c^2$ our task would be over. MY ATTEMPT : I have proved the result using the first approach. I tried to do it using the second one but could not proceed far. I was facing problems showing that $(a+b+c)^2=a^2+b^2+c^2$. If i get any help i shall be very grateful.","['proof-writing', 'trigonometry']"
2273229,$T$ has $(x-1)^4$ as its characteristic polynomial then what is the largest possible dimension of the centraliser of $T$,"Q.If $ I\neq T\in M_{4}(\mathbb{C})$ has $(x-1)^4$ as its characteristic
  polynomial then what is the largest possible dimension of the
  centraliser of $T$ in $M_{4}(\mathbb{C})$.$(=$the space of all
  matrices that commute with $T)?$ I am looking for a hint. I know that $T$ is not diagonalizable. But how should I proceed further?","['matrices', 'abstract-algebra', 'contest-math', 'linear-algebra', 'vector-spaces']"
2273240,Minimize sum of quadratic form and regularizer with respect to a matrix,"I have an optimization problem where I am trying to minimize 
$$x^ \top A^{-1} x + Tr(A)$$ with respect to A, on the set of symmetric positive definite matrices. I can see the problem is convex (the first term is jointly convex in $x$ and $A$, the second one is linear) and that $Tr(A)$ acts as a regularizer to prevent the solution from being ""$+ \infty * Id$"", but otherwise I am stuck: I do not know how to apply Fermat's rule to the first term. I thought about diagonalizing $A$, but since this diagonalization depends on $A$ I also get stuck. Any ideas?","['derivatives', 'convex-optimization', 'linear-algebra', 'optimization']"
2273261,"Proof verification that $\sup_{||x||=1} |\langle Tx, x \rangle | = ||T||$","I have been trying to solve the following exercise: Suppose that for an operator $T$ on a Hilbert space $\left\||Tx_n - \lambda x_n \right\| \to 0$ with $||x_n|| = 1$ so that $\lambda$ is an approximate eigenvalue of $T$. If $|\lambda| = ||T||$ show that $\sup_{||x||=1} |\langle Tx, x \rangle | = ||T||$. Could you please verify my proof? The first direction is easy as for a unit vector $x$ $$|\langle Tx, x \rangle | \leq \left\|Tx\right\| \left\|x\right\| \leq \left\| T \right\| \left\|  x\right\|^2$$ so  $\sup_{||x||=1} |\langle Tx, x \rangle | \leq ||T|| $. For the other direction I was thinking I could again use the Cauchy-Schwartz inequality to get $$\left| \langle T x_n - \lambda x_n, x_n \rangle  \right| =  \left| \langle T x_n,x_n \rangle - \lambda  \right|< \epsilon$$ for large enough $n$. Hence by the reverse triangle inequality $$|\lambda| < \left| \langle T x_n,x_n \rangle  \right| + \epsilon \leq \sup_{||x||=1} |\langle Tx, x \rangle | + \epsilon $$ so $ |\lambda| = ||T|| \leq \sup_{||x||=1} |\langle Tx, x \rangle | $ and assuming this is correct, the proof is complete. Is everything alright in the above? Thank you.","['functional-analysis', 'normed-spaces', 'operator-theory', 'hilbert-spaces']"
2273273,How to find the residue of a pole?,"I am trying to integrate the function $f(z)=\frac{z}{1-\cos z}$ inside the unit circle. I found the only singular point inside the unit circle to be $z=0$ since $\cos(x+iy)=1\Leftrightarrow y=0,x=2 \pi n$ is this correct way in doing this? I also found out that this singular point is a pole because $\lim \limits_{z \to 0}f(z)$ does not exist but $\lim \limits_{z \to 0}\frac{1}{f(z)}$ does exist thus $z=0$ is a pole of $f(z)$. How can I now proceed to find the residue at this point?",['complex-analysis']
2273313,Calculating radius of circle through chords [duplicate],"This question already has answers here : Calculate the radius of a circle given the chord length and height of a segment (9 answers) Closed last year . It looks like a simple question, but for some reason I just can't figure out how to do it: I am given the following circle (see picture) and need to calculate the radius. I know how this works when you know the chord height, but not when you are given line segments as shown. Thanks in advance.","['circles', 'geometry']"
2273314,Integrability of shifted random variable,"Let $(\Omega,\mathcal{F},\mathbb{P})$ by a probability space, $X:\Omega\rightarrow[0,\infty)$ a (non-negative, finite) random variable and $F:[0,\infty)\rightarrow[0,\infty)$ a continuous function. Assume that $$\mathbb{E}[\;F(X)\;]<\infty$$ I am wondering, if we can immediately draw the following conclusion: $$\mathbb{E}[\;F(X + a)\;]<\infty$$ for all $a\in[0,\infty)$ (shift of the random variable). The interesting case clearly is, if $X$ is unbounded, i.e. for every $M\in[0,\infty)$ there exists a set $A\in\mathcal{F}$ with $\mathbb{P}(A)>0$ and $X(\omega)>M$ for all $\omega\in A$). Thank you very much for your help!","['probability-theory', 'lebesgue-integral', 'measure-theory']"
2273320,Can a topological manifold be non-connected and each component with different dimension?,"These are two definitions in page 48 of the book an introduction to manifolds by Loring Tu. Definition 5.1. A topological space $M$ is locally Euclidean of dimension $n$ if every point $p$ in $M$ has a neighborhood $U$ such that there is a homeomorphism $\phi$ from $U$ onto an open subset of $\mathbb R^n$. Definition 5.2. A topological manifold is a Hausdorff, second countable, locally Euclidean space. It is said to be of dimension $n$ if it is locally Euclidean of dimension $n$. In the last lines of page 48, we reed, Of course, if a topological manifold has several connected components, it is possible for each component to have a different dimension. But this is a bit strange for me. If a topological manifold has several connected components and each component has different dimension, then how this manifold can be locally Euclidean space, say for example of dimension $n$? That is, by the above definition of topological manifolad, can a non-connected toplogical space be a topological manifold?","['manifolds', 'riemannian-geometry', 'differential-geometry', 'smooth-manifolds']"
2273321,Calculating sample variance.,"This question is part of another question and the solution skips over how the value of the variance is found and I can't figure out how the variance was obtained for the rest of the question. We are given a sample of 15 heights of people $X_1, X_2, ... , X_{15}$ in metres. Also given $\sum \limits_{i=1}^{15}x_i = 26.7$, and $\sum \limits_{i=1}^{15}x_i^2 = 173.526$ The solution says that $\overline{x}=1.78$, and $S^2 = 9$. I think that $S^2 = \dfrac{1}{14}\sum \limits_{i=1}^{15}(x_i-1.78)^2$ but I can't figure out what $x_i$ is supposed to be to get $9$. Thanks.",['statistics']
2273404,The Gravity Potential of an Ellipsoid,"The Original Problem Recently, I have encountered the following volume integral $$\mathcal{I}=\int_{\Omega}\frac{1}{|\mathbf{x}-\mathbf{x}'|}dV(\mathbf{x}') \tag{1}$$ where $\Omega$ is an ellipsoid defined by $$\Omega=\bigg\{(x'_1,x'_2,x'_3):\frac{{x'}_1^2}{a_1^2}+\frac{{x'}_2^2}{a_2^2}+\frac{{x'}_3^2}{a_3^2}\le1\bigg\}$$ and $a_1,\,a_2,\,a_3$ are the semi-major axes of ellipsoid. This representation of $\Omega$ also implies that the origin of our coordinate system is at the center of the ellipsoid. Also, $\mathbf{x}$ is some arbitrary point in $\mathbb{R}^3$ which may belong to $\Omega$ or not. This integral arises in different problems of physics like the gravitation of a solid ellipsoidal mass or the electrostatic field of a solid ellipsoidal distribution of charges. I want to simplify this integral as far as possible. I have been told that it can be represented in terms a simple integral over the real line and the answer will depend on wheather the point $\mathbf{x}$ is inside or outside $\Omega$ . I first do a translation by using the change of coordinates $\mathbf{x}'-\mathbf{x}=\mathbf{y}$ \begin{align*}
\mathcal{I} &= \int_{\Omega}\frac{1}{|\mathbf{x}-\mathbf{x}'|}dV(\mathbf{x}') \\
&= \int_{\Omega}\frac{1}{|\mathbf{x}'-\mathbf{x}|}dV(\mathbf{x}') \\
&= \int_{\Omega}\frac{1}{|\mathbf{y}|}dV(\mathbf{y}) 
\end{align*} consequently, $\Omega$ can be represented as below $$\Omega=\bigg\{(y_1,y_2,y_3):\frac{(y_1+x_1)^2}{a_1^2}+\frac{(y_2+x_2)^2}{a_2^2}+\frac{(y_3+x_3)^2}{a_3^2}\le1\bigg\}$$ and then I use the following transformation of coordinates \begin{align*}
y_1&=r\sin\theta\cos\phi \\
y_2&=r\sin\theta\sin\phi \\
y_3&=r\cos\theta
\end{align*} so I can get \begin{align*}
|\mathbf{y}|&=r \\
dV(\mathbf{y})&=r^2\sin\theta dr\,d\theta\,d\phi \\
\Omega&=\bigg\{(r,\theta,\phi):\frac{(r\sin\theta\cos\phi+x_1)^2}{a_1^2}+\frac{(r\sin\theta\sin\phi+x_2)^2}{a_2^2}+\frac{(r\cos\theta+x_3)^2}{a_3^2}\le1\bigg\}
\end{align*} so the integral becomes \begin{align*} 
\mathcal{I}=\int_{\Omega}r\sin\theta\,dr\,d\theta\,d\phi
\tag{2}
\end{align*} I am stuck right here. Can someone help to determine the limits of integration in $(2)$ and proceed to do the integration? I don't need every detail. An outline will also suffice but not just the final answer! Any help is appreciated. :) Extension of the Original Problem Indeed Eq. (1) happens when the density of the distribution of mass or charges is uniform. A more interesting problem would be to evaluate the following integral. $$\mathcal{I}=\int_{\Omega}\frac{\rho(\mathbf{x}')}{|\mathbf{x}-\mathbf{x}'|}dV(\mathbf{x}') \tag{3}$$ as a special case of the above problem, I am interested in the evaluation of the following integral $$\mathcal{I}_{IJ\dots K}=\int_{\Omega}\frac{x'_Ix'_J \dots x'_K}{|\mathbf{x}-\mathbf{x}'|}dV(\mathbf{x}') \tag{4}$$ where $I,\,J,\dots,K$ are positive integers which range from $1$ to $3$ and $x'_I$ is the $I$ th component of $\mathbf{x}'$ with respect to the standard Cartesian basis.","['multivariable-calculus', 'integration', 'definite-integrals', 'calculus']"
2273430,Finding a second order ODE from a system of equations,"Consider the following system of ODEs 
$$\begin{bmatrix}
x\\
y
\end{bmatrix}'=
\begin{bmatrix}
-2& 3\\
-1 & 2
\end{bmatrix}
\begin{bmatrix}
x\\
y
\end{bmatrix}
$$
with initial conditions 
$x(0)=1, y(0)=1$. I'm used to going from a second order ODE to a system of equations using some sort of substitution, but going backwards, i.e. from a system to a single second order ODE, is not so intuitive. How might I reduce this system to a single second order ODE in terms of $x$?",['ordinary-differential-equations']
2273454,Rearrangement of series in a (not necessarily Banach) normed vector space.,"If $X$ is a Banach space, then the following theorem holds: Let $\sum x_n$ be a series in $X$ which converges absolutely. Then every rearrangement $\sum x_{\sigma(n)}$ converges, and they all converge to the same value. Proof:
Let $(s_n')$ be the sequence of the partial sums of $\sum x_{\sigma(n)}$ .
Since $\sum x_n$ is absolutely convergent, given $\epsilon>0$ there is an integer $n_0$ such that $$\sum_{k=n_0}^m ||x_k|| <\epsilon$$ for all $m\geq n_0$ . Let $$p=\max_{1\leq i< n_0}\sigma^{-1}(i).$$ If $n>p$ , we have that $\{1,2,\dotsc,n_0-1\}$ is a subset of $\{\sigma(1),\sigma(2),\dotsc,\sigma(n)\}$ . Hence all the $x_i$ for $i=1,2,\dots,n_0-1$ are cancelled in $s_n-s_n'$ . So, $$||s_n-s_n'||\leq \sum_{k=n_0}^m ||x_k|| <\epsilon.$$ We conclude that $(s_n')$ converges to the same value as $(s_n)$ . However, if $X$ is a normed vector space which is not necessarily Banach, is any of the following true? If $\sum x_n$ converges absolutely, then any rearrangement converges absolutely. or If $\sum x_n$ is a convergent series which converges absolutely, then any rearrangement converges absolutely. or If $\sum x_n$ is a convergent series which converges absolutely, then any rearrangement converges. If so, it's possible to modify my proof to handle the more general result?",['analysis']
2273470,The Universal Property of Projective Space,"Since the theories of affine and projective geometry are specified by certain axioms, we can consider the category $\mathcal{A}$ and $\mathcal{P}$ of affine and projective geometries, whose morphisms are maps preserving colinearity. Given an affine geometry $G$, there is a natural way to extend the geometry to a projective geometry $G_\infty$ by adding a single `line at infinity' on which all parallel lines intersect. The association $G \mapsto G_\infty$ is trivially a functor, because a map $G \to H$ induces a map $G_\infty \to H_\infty$, and these maps behave properly under composition. My question is whether there is a universal property which uniquely describes the projective extension of an affine geometry up to isomorphism, like we see for the universal properties of the free group over a set, or the Stone-Cech compactification.","['projective-geometry', 'affine-geometry', 'universal-property', 'geometry', 'category-theory']"
2273477,Bessel's (in)equality confusion -- always an equality?,"Bessel's Inequality Let $(X, \langle\cdot,\cdot\rangle )$ be an inner product space and $(e_k)$ an orthonormal sequence in $X$. Then for every $x \in X$ : $$ \sum_{1}^{\infty} |\langle x,e_k\rangle |^2 \le ||x||^2$$
where $\| \cdot\|$ is of course the norm induced by the inner product. Now suppose we have a sequence of scalars $a_k$ and that the series $$ \sum_{1}^{\infty} a_k e_k = x $$
converges to a $x \in X$. Lemma 1 We can easily show that $a_k=\langle x,e_k\rangle $ 
  (i'll do it fast) Proof. Denote $s_n$  the sequence of partial sums of the above series, which of course converges to $x$. Then for every $j<n$ , $ \langle s_n, e_j\rangle  = a_j$ and by continuuity of the inner product $a_j=\langle x,e_j\rangle $ Lemma 2 We can also show that since $s_n$ converges to $x$, then $σ_n = |a_1|^2 + ... + |a_2|^2 $ converges to $\|x\|^2 $ : Proof. $\|s_n\|^2 = \| a_1 e_1 +...+a_2 e_2\|^2 = |a_1|^2 + ... |a_n|^2  $ since $(e_k)$ are orthonormal (Pythagorean). But $||s_n||^2$ converges to $||x||^2 $ , which completes the proof. So we showed the following $$\sum_1^{\infty} |a_k|^2= \sum_1^\infty |\langle x,e_k\rangle |^2 = ||x||^2$$ Confusion So the equality holds for Bessel inequality, for $x$. We arbitrarily chose $a_k$, so does that mean the the equality holds for all $x \in X$ ? Obviously not, otherwise it would be Bessel's equality. What am I getting wrong?","['functional-analysis', 'inner-products']"
2273549,Radon-Nikodym-derivative as a martingale,"At the beginning of all the stuff about Girsanov theorem, we introduced the Radon-Nikodym derivative as $Z_\infty := \frac{d \mathbb{Q}}{d \mathbb{P}}\vert_{\mathcal{F}_\infty}$. Next, we considered the following: \begin{align}
Z_t = \mathbb{E}[Z_\infty\vert\mathcal{F}_t]=\frac{d \mathbb{Q}}{d \mathbb{P}}\vert_{\mathcal{F}_t}.
\end{align}
So this last line does not seems so obvious for me. I do not understand the last equality. The conclusion is that the derivative is a martingale. Do I have to work with the definition of conditional expectation?","['stochastic-processes', 'probability-theory', 'radon-nikodym', 'martingales', 'conditional-expectation']"
2273550,Why is a deck transformation completely determined by where it sends a single point?,"Hatcher says ""by the unique lifting property, a deck transformation is completely determined by where it sends a single point , assuming $\tilde{X}$ is path-connected"". But I have no idea how this unique lifting property should be used. Could anyone show me what he means here?","['algebraic-topology', 'general-topology']"
2273561,"If $t=\tan{\frac{x}{2}}$, then $\cos{x}$ can be expressed as...","If $t=\tan{\frac{x}{2}}$, then $\cos{x}$ can be expressed as a) $\frac{1+t^2}{1-t^2}$ b) $\frac{2t}{1+t^2}$ c) $\frac{1-t^2}{1+t^2}$ d) $\frac{2t}{1-t^2}$ Attempt: I tried using the half angle formula but it just leaves me with an expression in terms of $\tan{x}$'s and I don't know how to go to $t$, let alone express $\cos{x}$ in $t$.",['trigonometry']
2273563,What do metric spaces look like?,"I know that a metric is a way of measuring distance that can be generalized to sets outside of the real numbers.  I also know that the space is simply the set you are working in.  So is a metric space just the outcome of putting your set through the metric? For example, if we have $(\mathbb{R}, d_0)$ with $d_0$ being the discrete metric does $\mathbb{R}$ simply become $\left\{0, 1\right\}$ because they are the only possible outcomes, like taking an open or closed ball?  More likely, a set is the same no matter what metric it is under, but then why can the same set be open in one metric and closed in another? (asides from induced metrics I kind of understand that) I've done quite a lot of work with metrics at this point and still feel uneasy with them, especially with non-Euclidean metrics since the Euclidean metrics are the ones I've worked with the most.  I guess my question is what do spaces look like once they are under the effect of different metrics? I'm sorry this is a badly formatted and vague question, but I don't really know what I'm trying to ask.  I just can't get my head around the same space under different metrics and what they look like.  If anyone has examples or explanation that might give me a new understanding I would be very grateful.  If this question should be deleted, tell me and I will.","['general-topology', 'metric-spaces', 'soft-question']"
2273577,How do you handle errors when rotating vector data in 2D?,"I have a vector data set in component-form in two columns with error (x-component and y-component: $x+\delta x$ and $y+\delta y$). I need to rotate this data by an angle $\theta$ to a new coordinate system $x'$ and $y'$. To do this with perfect data, I understand that you can use the 2D rotation matrix: $$\begin{bmatrix}x' \\ y'  \end{bmatrix} = \begin{bmatrix} \cos (\theta) & -\sin(\theta)\\ \sin(\theta) & \cos(\theta)\end{bmatrix}\begin{bmatrix}x \\ y \end{bmatrix}.$$ However, for imprecise data where I have columns for $\delta x$ and $\delta y$, how can I handle this error? Is it as simple as: $$\begin{bmatrix}\delta x' \\ \delta y'  \end{bmatrix} = \begin{bmatrix} \cos (\theta) & -\sin(\theta)\\ \sin(\theta) & \cos(\theta)\end{bmatrix}\begin{bmatrix}\delta x \\ \delta y \end{bmatrix}$$
or something more complicated?","['rotations', 'error-propagation', 'statistics', 'vectors', 'vector-analysis']"
2273629,Finding a line that passes through a point and lies tangent to a curve,"I'm trying to find the equation of a line that passes through some point $(x_1,y_1)$ and lies tangent to an ellipse. There are two solutions in most cases. My work starts with the equation of a line $y-y_1 = m(x-x_1)$. The slope of the line, $m$, will be $$\frac{y_1 - f(x)}{x_1-x} = f'(x)$$Normally I could substitute the equation of the curve in for $f(x)$ and $f'(x)$ and after some sweat, tears and algebra, solve for $x$, which can then easily be used to solve for all other information I need. However, ellipses are a pain to work with, especially in $f(x)=$ form, which I would need to use for this method. Even using wolfram alpha, the general solution for x is so extremely long and complicated that it's basically useless to me. Ellipses can be much more simply expressed in parametric form, so I tried the same approach using parametric equations $y(t)$ and $x(t)$, but I ended up with $t \sin t = \cdots$ which isn't solvable conventionally and ended up being equally as useless. My final idea was set the equation of the line equal to the ellipse. $$m(x-x_1) + y_1 = \sqrt{b^2 \left( 1-\frac{(x-h)^2}{a^2} \right)}+k$$The tangent line touches the ellipse, not intersects it, in other words it only has one point of equality with the ellipse. So I would somehow need to find the two values of $m$ that gives one point of equality instead of two, also a potentially painful and time-consuming process which I don't know how to do. Is there a better way to solve this? If this last method is the most viable solution, how would I go about this?","['derivatives', 'elliptic-functions', 'systems-of-equations']"
2273646,"$x=(a+b\omega)^3$ with $\omega$ a primitive third root of unity. Then $x=(c+d\sqrt{-3})^3$. ($a,b,c,d \in \mathbb{Z}$)","Let $x=(a+b\omega)^3$ with $\omega$ a primitive third root of unity. Then $x=(c+d\sqrt{-3})^3$. ($a,b,c,d \in \mathbb{Z}$). Can someone give me a hint? Approach:
$x= a^3 + 3a^2 b\omega + 3ab^2\omega^2 + b^3$ and $\omega^2 = -\omega -1$. But then, I'm stuck. Thanks in advance.",['number-theory']
2273653,Find function such that $\sum y_i\le\sum x_i\Rightarrow\sum f(y_i)\le\sum f(x_i)$,"What kind of a function $f$ must be to satisfy the following? If $\sum_{i=1}^{n} y_i \leq \sum_{j=1}^{n} x_j$, where $x_j, y_i \in [0,1],\forall i,j$ then $$ \sum_{i=1}^{n} f(y_i) \leq \sum_{j=1}^{n} f(x_j).$$ Any help would be appreciated. Thanks in advance! Preferably $f$ must be convex and increasing. $f$ is linear from the answer given by the user grand_chat. What if the above inequalities($\leq$) are replaced by the strict inequality ($<$)?","['inequality', 'optimization', 'functions', 'convex-optimization', 'functional-inequalities']"
2273676,Solving $\sin z=\sinh z$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question I guess that the only $z\in \mathbb C$ such that  $\sin z=\sinh z$ is $z=0$. Well, I cannot see immediately a proof.","['hyperbolic-functions', 'trigonometry']"
2273712,When is $n\cdot m\cdot [(n-8)\cdot m+4]-4$ an integer square?,"For which odd integers $n$ and $m$, with $n \ge m$ is $$n\cdot m\cdot [(m-8)\cdot n+4]-4$$ a square? Part of my efforts so far: The product of the three factors above is a sum of two squares (the square we wish to find plus $2^2$), thus all three factors are a sum of two squares too (since their prime factorization is of the right form). But that is not enough, as their product minus 4 needs to be a square too. So $n=17$ and $m=13$ look to be OK at first sight, as the third factor then is $89=8^2+5^2$, but the product $13\cdot 17\cdot 89$ is not a square plus 4. On the other hand, $n=17$ and $m=17$ is OK, as the third factor now is $157=11^2+6^2$ and also $17\cdot 17 \cdot 157=213^2+2^2$. Taking the sum of two squares to be the determinant of a $2x2$ matrix
$$\left(\begin{array}{cc}a&b\\-b&a \end{array}\right)$$
it is easy to see that $n$, $m$ and $(m-8)\cdot n+4$ then correspond to matrices whose product is a matrix as above with $b=\pm2$.
For example $$\left(\begin{array}{cc}4&1\\-1&4 \end{array}\right)\cdot \left(\begin{array}{cc}4&1\\-1&4 \end{array}\right)\cdot \left(\begin{array}{cc}11&-6\\6&11 \end{array}\right)=\left(\begin{array}{cc}213&-2\\2&213 \end{array}\right)$$
Not sure if this helps finding the solution, though. A couple of the solutions I found are $$
\begin{array}{l|l|c|l}
\text{n} & \text{m} & (m-8)\cdot n+4 & \text{product} \\
\hline
17=4^2+1^2 & 17=4^2+1^2 & 157=11^2+6^2 & 45373=213^2+2^2 \\
29=5^2+2^2 & 13=3^2+2^2 & 149=10^2+7^2 & 56173=237^2+2^2 \\
3277=54^2+19^2 & 17=4^2+1^2 & 29497=171^2+16^2 & 1643248373=40537^2+2^2 \\
\end{array}
$$
What I would like to have is a general expression for all solutions, or an algorithm to find the next solution.",['number-theory']
2273730,Why use averages vs medians in statistics?,"Why in statistics is the average used instead of the median, why are P values for example always calculated with averages and not with median? I have always been taught that stats and P values always have to be used with the average
and I have no idea why, is it just a systemic choice of the person who created the data or can they be used interchangeably for the majority of statistical work?","['statistics', 'median', 'average']"
2273787,Solving a first order non linear PDE with the method of characteristics,"We have to find the function $u(x,y)$ for the following system: $u_xu_y = xy$ $u(x,y) = y+1$ for $x=y$ Using the method of characterstics I get: $F(x,y,u,u_x,u_y) = u_xu_y-xy = 0$ Defining $p = u_x$ and $q = u_y$ we get: $F(x,y,u,p,q) = pq-xy = 0$ I use a parametrisation for $s = 0$: $x(t) = y(t)$ $y(t) = t$ $u(t) = t+1$ We are supposed to find p and q out of the following system: $F(x,y,u,p,q) = 0$ $u_t = px_t+qy_t$ By filling in what we know we get: $pq-t^2 = 0$ $p+q = 1$ I am not quite sure how to find p and q out of this system. The characteristic differential equations are: $x_s = F_p = q$, for $s=0 : x=t$ $y_s = F_q = p$, for $s=0 : y=t$ $u_s = pF_p+qF_q = 2pq$, for $s=0 : u=t+1$ $p_s=-F_x-pF_u = y$, for $s=0 : p= ?$ $q_s = -F_y-qF_u = x$, for $s=0 : q= ?$ Help would be much appreciated.","['characteristics', 'analysis', 'partial-differential-equations']"
2273853,Is it possible to solve $x\sin(x) = 7$ algebraically?,"$$x\sin(x)=7$$ The only method to solve this that comes to my mind is to draw the left side of this equation. However, there is an infinite number of solution. Is it possible to come up with something like $x=x_o+nT$ where T is the ""period""?",['trigonometry']
2273860,"¿A Dedekind-infinite set $A$ has as many proper subsets, equipotent to $A$, as its own cardinality?","Definition: A set $A$ is said to be Dedekind-infinite if it has a proper subset $X$ equipotent (similar/in bijection) to $A$. My question is as follows, how to prove that if $A$ is a Dedekind-infinite set there exists $\{A_i\}_{i\in I}$, a collection of proper subsets of $A$, such that $A_i\subsetneq A$ and $A_i\sim A$ for each $i\in I$, where $I\sim A$, and $A_i\cap A_j=\emptyset$ if $i\not=j$? Here $X\sim Y$ means ""exists $f:X\rightarrow Y$ a bijective function"". The question comes to me in the middle of a proof and I think is intuitive correct. In addition, in the case of $\mathbb{N}$ we have that the sets of powers of prime numbers is a collection with that property. Thank you for all kind help and comments.",['elementary-set-theory']
2273876,Why is there no Zariski local trivial neighborhood of the origin?,"I'm looking at the following post from MO: https://mathoverflow.net/questions/213231/is-a-morphism-whose-all-fibers-are-mathbfpn-a-projective-bundle/213235#213235 The purpose of the example in question is to find a morphism of varieties $\pi:X\to Y$ such that all fibers are $\Bbb P^n$, but $X$ is not a $\Bbb P^n$-bundle over $Y$. We take $Y$ to be the variety cut out by $f(s,t)=t^2-s^2(1-s)$ in $\Bbb A^2$, and take $\nu:\Bbb A^1\to Y$ to be $\nu(u)=(1-u^2,u(1-u^2))$. Then let $V=\Bbb A^1\setminus\{1\}$, and take $X=V\times\Bbb P^n$, $\pi=\nu\circ\text{pr}_V:X\to Y$. All fibers are $\Bbb P^n$ because the morphism $\nu|_V:V\to Y$ is a bijection, and the point in $Y$ which doesn't have a trivial Zariski neighborhood must be the origin, because this is the only singularity of $Y$. My question is, how can I explicitly see that this point really doesn't have a trivial Zariski neighborhood?",['algebraic-geometry']
2273897,How can we apply the method of separation of variables?,"I want to check if the method of separation of variables can be used for the replacement of the following given partial differential equation from a pair of ordinary differential equations. If so, I want to find the equations. $u_{xx}+(x+y) u_{yy}=0$ Suppose that $u$ is of the form $u(x,y)=X(x) Y(y)$. Then  $u_{xx}+(x+y) u_{yy}=0 \Rightarrow X''(x) Y(y)+(x+y) X(x) Y''(y)=0 $. So we see that we cannot use the method. But in order to apply the method, we could set $z=x+y$. But then how do we proceed? Do we find the derivative of z as or x? EDIT :Let $z=x+y$. We have that $$\frac{dX}{dx}=\frac{dX}{dz}\cdot \frac{dz}{dx}=\frac{dX}{dz}$$ and $$\frac{d^2X}{dx^2}=\frac{d}{dx}\left (\frac{dX}{dz}\right )=\frac{d}{dz}\frac{dX}{dz}\cdot \frac{dz}{dx}=\frac{d^2X}{dz^2}$$ Then we have $$\frac{d^2X}{dx^2}\cdot Y+(x+y)\cdot X\cdot \frac{d^2Y}{dy^2}=0 \\ \Rightarrow \frac{d^2X}{dz^2}\cdot Y+z\cdot X\cdot \frac{d^2Y}{dy^2}=0 \\ \Rightarrow \frac{d^2X}{dz^2}\cdot Y=-z\cdot X\cdot \frac{d^2Y}{dy^2} \\ \Rightarrow \frac{1}{z\cdot X}\cdot \frac{d^2X}{dz^2}=- \frac{1}{Y}\cdot \frac{d^2Y}{dy^2}$$ But won't $X$ be a variable of both $y$ and $z$ since $x=z-y$? Or do we get somehow that $X$ will depend only on $z$?","['ordinary-differential-equations', 'partial-differential-equations']"
2273968,Will the solution of the boundary value problem be unique?,"Suppose that we have the following boundary value problem: $$a^2 u_{xx}=u_t, 0<x<L, t>0 \\ u(x,0)=f(x) , 0 \leq x \leq L\\ u(0,t)=0, u(L,t)=0, t>0$$ By supposing that $u(x,t)=X(x) T(t)$ we find that the solution is of the form $u(x,t)=\sum_{n=1}^{\infty} c_n e^{-\frac{n^2 \pi^2 a^2 t}{L^2}} \sin{\frac{n \pi x}{L}}$ where $c_n=\frac{2}{L} \int_0^L f(x) \sin{\frac{n \pi x}{L}}$. But do we know that this solution is unique? Or could there also be an other solution that will not be of the form $X(x) T(t)$ ?",['ordinary-differential-equations']
2273975,Logarithmic differentiation and negative valued functions,"I have seen the following proof for the power rule: $$
\begin{align*}
y &= x^n\\
\ln(y) &= n\ln(x)\\
\frac{d}{dx}\ln(y) &= \frac{d}{dx}(n\ln(x))\\
\frac{y'}{y} &= \frac{n}{x}\\
y' &= nx^{n-1}
\end{align*}
$$ However, what I don't understand is how is this proof valid if $y$ may be negative and then $\ln(y)$ would not be defined. Even if $y'$ is indeed $nx^{n-1}$, isn't this proof a wrong way to achieve the right answer?","['derivatives', 'real-analysis', 'proof-explanation']"
2273991,What is an explicit example of a lifting in the valuative criterion for properness?,"The valuative criterion states that given a diagram
$$
\begin{matrix}
\text{Spec}(K) \to & X \\
\downarrow & \downarrow f  \\
\text{Spec}(D) \to & Y
\end{matrix}
$$
where $K$ is a field and $D$ a valuation ring, there should be a lifting of $\text{Spec}(D) \to X$. What is an explicit example of this for $f:\mathbb{P}^n_\mathbb{Z} \to \mathbb{Z}$?","['schemes', 'valuation-theory', 'algebraic-geometry', 'projective-schemes']"
2274092,Characteristic Polynomial Independent From the Choice of Basis,"I want to prove that definition of characteristic polynomial of a linear operator on a finite-dimensional vector space $V$ is independent of the choice of basis for $V$. Proof>> Choose two different basis for V, $\beta, \beta '$. Let $Q = [I_v]_{\beta'}^\beta$. Then, $[T]_{\beta'} = Q^{-1
}[T]_\beta Q  $ ,which means that $[T]_\beta$ and $[T]_{\beta'}$ are similar. Since similar matrices are having same characteristic polynomial, $det([T]_\beta-\lambda I$) = $det([T]_{\beta '}-\lambda I$). How's this proof?",['linear-algebra']
2274104,The gambler makes 100 bets and wins 10. How much money does he have at the end?,"A gambler who makes 100 bets of $1, each at payoff odds of 8 to 1.
  He wins 10 of these bets and loses 90. How many dollars has the gambler gained overall? I don't seem to understand what ""odds of 8 to 1"" means. Can someone please explain this to me?","['gambling', 'algebra-precalculus', 'terminology', 'probability', 'word-problem']"
2274107,Show that $\sum_{j=M}^{\infty}\left(\frac{M}{j}\right)^{a+n} \to 1$ as $n\to \infty$,"Assume this is to be solved under timed conditions. Show that
  $\sum_{j=M}^{\infty}\left(\frac{M}{j}\right)^{a+n}
 \to 1$ as $n \to \infty$, where $M\geq 1$ is an integer and
  $a > 1$ is fixed (not necessarily an integer). I do have a solution available to me, but I'm not a fan of it - essentially, it breaks apart the summation into $1 + \sum_{j=M+1}^{\infty}(M/j)^{a+n}$ and then does some fancy inequality work to show that the resulting summation starting at $j = M + 1$ is less than or equal to some constant not dependent on $n$ times $\left(\dfrac{M}{M+1}\right)^n \to 0$ as $n \to \infty$, hence we get $1^{-1} = 1$ as $n \to \infty$. Long story short, I wouldn't have thought about doing this (particularly the breaking of the summation into two parts). Is there a better, more brute-force method of approaching this that wouldn't involve messing around with inequalities? Note that this was an intermediate step for a question from a grad-level statistics qualifying exam, covering material at the level of Casella and Berger's text.","['statistics', 'summation', 'probability', 'sequences-and-series']"
2274127,Find the domain of $\arcsin\left(\frac{3-x}{\sqrt{9-x^2}}\right)$,"Find the domain of
  $$\arcsin\left(\dfrac{3-x}{\sqrt{9-x^2}}\right)$$ This question is given in my book. The answer is as follows: For the function to be defined, $-1\le3-x\le1$ and $9-x^2>0$. Solve these inequalities and take their common region.
  $$2\le x\le4\tag1$$
  $$-3 < x < 3\tag2$$ The answer is $2\le x<3$. My question is why have they not taken $-1\le\dfrac{3-x}{\sqrt{9-x^2}}\le 1$, in which case the answer would have been different. Please help.","['algebra-precalculus', 'calculus', 'functions']"
2274144,Existence of finite endomorphisms on projective varieties,"Let $X$ be a projective variety over an algebraically closed field $k$, then I wish to obtain some general examples of finite morphisms from $X$ to itself. I know that if $X=\mathbb{P}_k^n$, then we can always consider the maps $$f_d:[x_0:\cdots:x_n]\mapsto[x_0^d:\cdots:x_n^d]$$ for $d\ge1$, interpreted appropriately as a morphism of schemes. However, these maps will in general not take a closed sub variety to itself. So, is there any wide class of finite endomorphisms over a general projective variety, or do examples only exist on a case by case basis?",['algebraic-geometry']
2274147,A function with no inflection point,"Suppose $g:\mathbb{R} \to \mathbb{R}$ is a twice differentiable function with second derivative continuous such that for every $a,b \in \mathbb{R}$ with $a<b$, there exist a unique $c \in (a,b)$ such that $g'(c)=\frac{g(b)-g(a)}{b-a}$. Prove that $f$ has no inflection points. I think this is not correct. Consider the function $f(x)=(x-1)(x-2)(x-3)$ thus function satisfies the above conditions, but we know that between a maxima and a minima lies a point of inflection. Is my reasoning correct? Else can you give a proof?","['real-analysis', 'calculus']"
2274173,Lawvere's Sets For Mathematics Exercise 2.29c,"I am enjoying the book Sets For Mathematics but am having trouble understanding part of exercise 2.29, which concerns the inverse image of a part along a map. Let me give the build-up to the exercise and the exercise itself. I transpose the commutative diagrams to symbolic expressions due to the apparently limited nature of MathJax in expressing them. Lawvere defines a part of a set to be a monomap with codomain equal to the set. He also defines $f \in i$ for map f and part i with common codomain to mean there exists another map $k$ such that $f = ik$. Given an arbitrary map $f$ from $X$ to $Y$ and an arbitrary part $V \xrightarrow{j} Y$ of the codomain, there is a part $U \xrightarrow{i} X$ of the domain such that (0) for all $T \xrightarrow{x} X$ $$x \in i \Leftrightarrow fx \in j.$$
This implies (1) there is a commutative square $j\bar{f} = fi$,
moreover (2) whenever $fx = j\bar{y}$ is another commutative square, for some $T \xrightarrow{x} X$ and $T \xrightarrow{\bar{y}} V$, there is an $T \xrightarrow{\bar{x}} U$ such that $x = i\bar{x}$ and $\bar{y} = \bar{f}\bar{x}$,
and lastly (3) $\bar{x}$ is unique (because we have assumed $i$ is a monomapping). Lawvere then writes (and I omit parts b and d because they are unrelated to my confusion) Exercise 2.29 a. Show that (0) $\Rightarrow$ (1), (2), and (3). c. Show that (1), (2), and (3) $\Rightarrow$ (0). I've solved part a. Here are those arguments. (0) $\Rightarrow$ (1): $i \in i$ so by (0) there exists such $\bar{f}$.  (0) $\Rightarrow$ (2): Consider such $x, \bar{y}$. Then $fx \in j$, implying by $(0)$ that $x \in i$, which means there is an $\bar{x}$ such that $x = i\bar{x}$. The original commutative square states $fi = j\bar{f}$, implying $j\bar{f}\bar{x} = fi\bar{x} = fx = j\bar{y}$. Since $j$ is mono we find $\bar{y} = \bar{f}\bar{x}$. (0) $\Rightarrow$ (3): Consider $\bar{x}'$, then $i\bar{x} = x = i\bar{x}'$. We have $\bar{x} = \bar{x}'$ since $i$ is mono. I've also ""solved"" c, but without requiring (3) as an assumption. So my question is 'where's the flaw?', since I doubt that (1) and (2) imply (3). Here's my argument: Consider an arbitrary $T \xrightarrow{x} X$. Take $i$ and $j$ to be the parts given in the commutative square of (1). We want to show (0). Suppose $x \in i$, i.e. that there exists $\bar{x}$ such that $x = i\bar{x}$. By (1) there exists $\bar{f}$ such that $fi = j\bar{f}$. Then $fx = fi\bar{x} = j\bar{f}\bar{x} = j(\bar{f}\bar{x})$, implying that $fx \in j$. Now suppose that $fx \in j$, i.e. that there exists $\bar{y}$ such that $fx = j\bar{y}$. By (2) there exists an $\bar{x}$ satisfying $x = i\bar{x}$, implying that $x \in i$.","['category-theory', 'topos-theory', 'elementary-set-theory']"
2274207,"Given complex polynomial with roots within an annulus, there exists its ""square root"" which is analytic outside this annulus","We are given a polynomial $f(z)$ of degree $2n$, which has all its roots within the annulus $|z|<a$. Now we must show that there is an analytic function $g(z)$ which is defined on $|z|>a$ which has the property that $g(z)^2=f(z)$. I have no idea what property I could use to show this is true (I don't even know why it is true). I think there could be some significance to the degree of the polynomial being even though - if it were odd, say degree $1$, then the square root can't possibly be a polynomial. I don't know how to formalise this, and more importantly I don't see the significance of the regions. Could someone please explain this to me?",['complex-analysis']
2274209,How can we show that $\int_{0}^{1}\cos(\ln x)\cdot{\mathrm dx\over 1+x^2}={\pi\over 4}\cdot{1\over \cosh\left({\pi\over 2}\right)}?$,"Proposed: $$\int_{0}^{1}\cos(\ln x)\cdot{\mathrm dx\over 1+x^2}={\pi\over 4}\cdot{1\over \cosh\left({\pi\over 2}\right)}\tag1$$ My try: $x=\tan u\implies dx=\sec^2 u du$, then $(1)$ becomes $$\int_{0}^{\pi/4}\cos(\ln\tan u)\mathrm du\tag2$$ Recall of $$\int_{0}^{\pi/2}\ln\sin x\mathrm dx=\int_{0}^{\pi/2}\ln\cos x\mathrm dx=-{\pi\over 2}\ln(2)\tag3$$","['integration', 'definite-integrals', 'calculus']"
2274252,Continuous and tempered $\Rightarrow$ bounded by a polynomial?,"If $f$ is a continuous function that is moreover in the space of tempered distributions, is it true that $f$ is necessarily bounded by a polynomial function?","['continuity', 'distribution-theory', 'functions']"
2274256,How many circles do 11 points define?,"I came across this question in my class: There are 11 different points in the plane with no 3 points are on the same line. a) How many circles do these points define? (Points define a circle if there is a unique circle through those points.) b) How many circles would they define, if 4 points were on the same line? I think, that we just need 2 points, to define a circle (one for the centre and 1 for the radius). In that case a) would be $11\times10=110$ different circles, however that seems to be incorrect. How would you solve it?","['circles', 'combinatorics', 'combinatorial-geometry', 'geometry']"
2274268,"Given a right triangle $ABC$, with right angle at $C$ and side lengths...","Problem: Given a right triangle $ABC$ , with right angle at $C$ and side lengths $|AB|=c \ , |BC|=a$ and $|CA|=b,$ let $r$ denote the radius of the inscribed circle. Then it is true that: a) $r=\dfrac{a+b-c}{2}$ b) $r=\dfrac{c-a-b}{2}$ c) $r=\dfrac{3a+2b-2c}{2}$ d) $r=\dfrac{2c-a-b}{2}$ This is a problem that one should be able to solve by eliminating the wrong answers without doing too much arithmetic and memorising different formulas. What is the most effective way of eliminating the wrong answers? I drew a picture of the problem but I can't really see how to relate $r$ to the sides of the triangle. I'd also know how to rigorously prove the correct answer, but this is just a curios sidestep.","['plane-geometry', 'euclidean-geometry', 'triangles', 'geometry']"
2274282,"$f:\Bbb R\to\Bbb R$ continuous at 0; prove $g:\Bbb R\to\Bbb R,g(x)=xf(x)$ differentiable at 0 and find $g'(0)$","Suppose that $f \colon ℝ → ℝ$ is continuous at $x = 0$. Prove that the function $g \colon ℝ → ℝ$ given by $g(x) = xf(x)$ is differentiable at $x=0$, and find $g'(0)$. I'm honestly confused about what I can do, my teacher said using the definition of derivative might help, however, I can't see how. Here's my attempt anyways: Since $f(x)$ is continuous at $x=0$, it must be differentiable at $x=0$. Therefore a scalar multiple of it is also differentiable at $x=0$, so $g(x)$ is differentiable at $x=0$. Second part: $g(x) = xf(x)+f'(x)$. Not sure what to do from here now.","['derivatives', 'continuity', 'calculus']"
2274330,Domain of $f(x)=\sqrt{\lfloor x\rfloor-1+x^2}$,"I drew the number line and tested with different values, getting the correct domain $(-\infty,-\sqrt3)\cup[1,\infty)$. However, how do I solve this faster by manipulating the function?","['inequality', 'functions']"
2274331,Show that $x^{12}-x^9+x^4-x+1\geq0$ for all $x$,"Show that $x^{12}-x^9+x^4-x+1\geq0$ for all $x$. When $x\leq0$ , this is easy. When $x\geq1$, then also this is easy. I need help with the case when $0\leq x\leq 1$",['functions']
2274365,Is this product of Gamma functions bounded?,"Consider the following term: $$q(z,x):=\bigg\vert\frac{\Gamma(\sqrt{z} + 1 + ix)\Gamma(\sqrt{z} + 1 - ix)}{\Gamma(\sqrt{z} + 1)\Gamma(\sqrt{z} + 1)}\bigg\vert\cdot e^{\pi x}. $$ I would like to know whether the function $q$ is bounded for all values $x\in\mathbb{R}$ and $z=a+ib$ with $a>0$ fixed and $b\in\mathbb{R}$. That is, I want to know if the following statement is correct: $$\exists\, c,a>0\,\forall x,b\in\mathbb{R}: \vert q(z,x) \vert \leq c,\, \text{where }z=a+ib.$$ Unfortunately, I could not find any reference for such an estimate and it indeed seems to be a tough problem. How could one analyze that function? In case the above statement is not true: What would be the best estimate one can hope for? I would very appreciate any help.","['asymptotics', 'complex-analysis', 'special-functions', 'gamma-function', 'analysis']"
2274438,$ f(x)\leq f(x+\frac{1}{n} )$ for all $x\in \mathbb{R}$ and $n\geq 1$ . Prove that $f$ is non-decreasing .,"Let $f:\mathbb{R} \rightarrow \mathbb{R}$ be a continuous function such that $ f(x)\leq f(x+\frac{1}{n} )$ for all $x\in \mathbb{R}$ and $n\geq 1$ . Prove that $f$ is non-decreasing . I realy don't have any ideas. My first try was that by archemddian and well ordering  property there exists a smallest $n$ such that $n(y-x)\geq 1  $ where it was chosen such that $y>x$ . 
Now if $y=x+\frac{1}{n} $ Then $f(y)=f(x+\frac{1}{n}) >f(x) $ . Now if $y>x+\frac{1}{n} $  i have no idea how to proceed . So provide a solution . Thank you .","['real-analysis', 'calculus', 'analysis']"
2274467,Primes dividing sum of binomial coefficients.,"Given that $p>3$ is a prime, we have $k=\lfloor \frac {2p}{3} \rfloor$ then prove or disprove that $\sum_{i=1}^k\binom{p}{i}\equiv 0\pmod{p^2}$. Its easy to see how $p$ divides each of the binomial coefficients, but I tried using maximal powers of $p$ in each coefficient but was stuck can someone help.","['number-theory', 'binomial-coefficients', 'elementary-number-theory']"
2274486,Green's Theorem for area using polar coordinates,"I've come across a Green's Theorem proof that has me perplexed. Using the area formula: $$A = \frac{1}{2}\int_C xdy - ydx $$
Prove that:$$A = \frac{1}{2}\int_a^b r^2d\theta$$for a region in polar coordinates. I assume a parametrisation is needed, but I'm not sure where to start due to the change in variables. My first thoughts are to change coordinates to $x=rcos\theta$ and $y=rsin\theta$. I also have assumed the $r^2$ is a result of the Jacobian being $r$ and some simplification of the $cos^2\theta + sin^2\theta$ identity. Any help would be appreciated. Thanks!","['polar-coordinates', 'greens-theorem', 'proof-verification', 'multivariable-calculus', 'change-of-variable']"
2274500,What is $\lim_{x\to0}\frac0{x^2}$?,"What is $$\lim_{x\to0}\frac0{x^2}$$ I would guess that it is $0$, because $0$ divided by anything is $0$. $x$ is just a very very small number like  $0.000001$. And in the case of $\cfrac1{x^2}$ the limit should be $\infty$ right?","['calculus', 'limits']"
