question_id,title,body,tags
2104883,Is there an irrational number containing only $0$'s and $1$'s with continued fraction entries less than $10$?,"The number $$0.10111001001000000000001$$ has continued fraction $$[0, 9, 1, 8, 9, 5, 1, 1, 5, 3, 1, 3, 1, 1, 4, 6, 1, 1, 8, 2, 5, 8, 1, 9, 9, 5, 2
, 8, 1, 1, 6, 4, 1, 1, 3, 1, 3, 5, 1, 1, 5, 9, 8, 1, 9]$$ So, the maximum values is $9$. But we are only at $23$ digits. Can we produce larger decimal expansions with the required property ? Perhaps arbitary large ones ? Is there an irrational number, such that the decimal expansion contains only ones and zeros and the continued fraction contains no entry larger than $9$ ?","['number-theory', 'continued-fractions', 'irrational-numbers']"
2104893,The notion of equality when considering composition of functions,"When going through some (very introductory) calculus homework I was given the function $f(x) = \frac{x}{1+x}$ and asked to find the composition $(f\circ f)(x)$ and then find its domain. Substituting, we find that $$(f\circ f)(x)= \frac{\frac{x}{1+x}}{1+\frac{x}{1+x}}$$ The domain is then found by solving $\frac{x}{1+x} = -1$ and to find that the composition is undefined at $-\frac{1}{2}$. It is also, of course, undefined at $-1$. Thus our domain is $\{x \in \mathbb{R} \mid x \neq -\frac{1}{2} $ and $x \neq -1$}. My question comes from noticing that if we take the algebra further we find that $$(f\circ f)(x)= \frac{\frac{x}{1+x}}{1+\frac{x}{1+x}} = \frac{x}{2x+1}$$ The domain is still surely unchanged. However, suppose I never did this problem and for some reason I simply desired to write down the function $\frac{x}{2x+1}$ on a sheet of paper and find its domain. I would find that it is defined for all reals except $-\frac{1}{2}$. (Wolfram alpha also verifies this). This would then imply that $$(f\circ f)(x)= \frac{\frac{x}{1+x}}{1+\frac{x}{1+x}} \neq \frac{x}{2x+1}$$ since the domain of the two functions is unequal. Couldn't we also work backwards from $\frac{x}{2x+1}$ in the following manner? $$\frac{x}{2x+1} = \frac{\frac{x}{1+x}}{\frac{1+2x}{1+x}} = \frac{\frac{x}{1+x}}{\frac{1+x}{1+x} + \frac{x}{1+x}} = \frac{\frac{x}{1+x}}{1 + \frac{x}{1+x}}$$ This is the function we orignally found the domain for. Did I some how just remove a point from the domain by just doing algebraic manipulations? My guess is perhaps there are two (or more?) notions of equality going on here. One notion would perhaps be the idea of two functions $f$ and $g$ being ""formally"" equivalent if $f$ can be algebraically manipulated to $g$ and vice versa. The other notion would be the more intuitive one where two functions are equal if they have the same domain and map the elements of the domain to the same points in the codomain. Thanks.","['algebra-precalculus', 'functions']"
2104899,"If $f(g(x)) = 4x^2-8x$ and $f(x)=x^2-4$, then what's the value of $g(x)$?","I'm a little stuck with this simple function: If ${f(g(x)) = 4x^2-8x}$ and ${f(x)=x^2-4}$, then what's the value of ${g(x)?}$ Any tips?",['functions']
2104951,"Function $f = (f_1,\dots,f_n)$ s.t. $[f_1(x),\dots,f_n(x)]$ goes from $[1,0,\dots,0]$ to $[0,\dots,0,1]$ in a smooth way","Question I would like to have a function:
$$
f: \mathbb{R} \rightarrow \left\{x \in \mathbb{R}^n \mid \sum_{i=1}^n x_i = 1\right\}:x \mapsto (f_1(x),\dots,f_n(x))
$$
s.t. $f(0) = (1,0,\dots,0)$ and $f(1) = (0,\dots,0,1)$. This is of course very easy to find but I would like to have these such that the conversion happens in a smooth way. What I mean by that is that I would like to have the following extra properties: $f_1(1/2) = \dots = f_n(1/2) = 1/n$ $f_1(x)$ is descending $f_n(x)$ is ascending If we define the function $g_x(k) := f_k(x)$ and we draw the graphs of $g_x(k)$ for $x$ going from $0$ to $1$ this should look like a bit like a wave (idea further explained in next two points) On $]0,1/2[$ we have $f_1(x) > \dots > f_n(x)$ and on $]1/2,1[$ we have $f_1(x) < \dots < f_n(x)$ Example method For example for $n = 2$ we can define:
$$
f(x) := (x, 1-x)
$$
now for $n  = 3$ we can write:
$$
f(x) := (x,f_2(x),1-x)
$$
but then we have a problem as we need to have $f_2(x) = 0$, therefore we need to let $f_1(x)$ descend to $1/3$ on $[0,1/2]$ and $f_3(x)$ ascend to $1/3$ on $[0,1/2]$ we define:
$$
f_1(x) :=\begin{cases}
 (1 - \frac{4}{3} \cdot x) & \mbox{ if } x \in [0,1/2]\\
\frac{2}{3}(1 -  x) & \mbox{ if } x \in [1/2,1]
\end{cases}
$$
and
$$
f_3(x) :=\begin{cases}
 \frac{2}{3} \cdot x & \mbox{ if } x \in [0,1/2]\\
\frac{4}{3} x - \frac{1}{3} & \mbox{ if } x \in [1/2,1]
\end{cases}
$$
then we automatically find for $f_2(x)$:
$$
f_2(x) = \begin{cases}
\frac{2}{3} x & \mbox{ if } x \in [0,1/2]\\
\frac{2}{3}(1 -  x) & \mbox{ if } x \in [1/2,1]
\end{cases}
$$ Now we can continue for $n = 4$, the logical way to continue would be to define $f_1(x)$ to be $(1 - \frac{3}{2} x)$ on $[0,1/2]$ and $f_4(x) := \frac{1}{2} x$ on $[0,\frac{1}{2}]$. We could then use $f_2 = f_3$ and solve the equation $f_1 + 2 f_2 + f_4 = 1$ on $[0,\frac{1}{2}]$. But this does not satisfy the last property and doesn't look enough like a wave to me. Reason For My Question The Reason I ask this is because I would like to have a sequence of Markov Chains which goes from perfect correlation (i.e. transition matrix the unity matrix) to some other Markov Chain which is strongly negatively correlated.","['multivariable-calculus', 'markov-chains', 'linear-algebra', 'functions']"
2105012,How do I weight Win/Loss Percentage Based on Games Played?,"I have a spreadsheet I use for tracking my statistics in a game across a number of different factors such as Map, Group Size and Class. In each case, I use the win percentage to determine a rating out of 5 (rounded to the nearest $.01$). For example, when playing with a friend, I have a win percentage of $44\%$, this translates to an overall rating of $2.20$ in my current spreadsheet. Likewise, when playing alone, I have a win percentage of $49.64\%$ which translates to a rating of $2.48$. I have $50$ games played with 2 people and $137$ games played alone. I would like to adjust the rating to reflect the number of games played, such that a win percentage of $50\%$ over $100$ games will be rated higher than $50\%$ over $50$ games. I'm not quite sure how to approach this. Has anyone any suggestions or places I can turn to to help me solve this problem?",['statistics']
2105075,Finding the matrix associated with a linear map,"Find the matrix associated with the linear map $f:R^2 \rightarrow R^2$ defined by $f(x,y)=(3x-y,y-x)$ with respect to the ordered basis ${(1,0),(1,1)}$ Let the matrix be $A$ and let $f(x)=AX$ where 
$$X=\begin{bmatrix} 
x \\
y 
\end{bmatrix}$$ and 
$$A=\begin{bmatrix} 
a & b \\
c & d 
\end{bmatrix}$$ I tried solving for $a,b,c,d$ by using the basis vectors as $(x,y)$. That is, I took $(x,y)=(1,0)$ and $(x,y)=(1,1)$ to find $a,b,c,d$. But I am not getting the given answer.","['matrices', 'linear-algebra', 'linear-transformations']"
2105111,Ultraproduct of partitions of an $L^p$-space isomorphic to itself?,"Let $L$ be an $L^p$-space, $1<p<\infty$, associated with an arbitrary measure space $(X, \mathcal F, \mu)$. A semi-partition of $X$ is a finite disjoint collection of measurable sets with finite measures. Let $A$ be the set of all semi-partitions of $X$. We introduce a partial order into $A$ as $\alpha\leq \alpha'$ meaning that each set in $\alpha$ is a union of some sets in $\alpha'$, this makes $A$ a directed set. Let $E_\alpha:L\to L$ be the conditional expectation operator with respect to the semi-partition $\alpha$, mapping functions to their average values on the sets of $\alpha$ and to zero outside of these sets. We have that for fixed $f\in L$, the net $\{E_\alpha f\}$ converges to $f$. Let $L_\alpha$ be the range of $E_\alpha$ (this is a finite dimensional $L^p$-space). Let $\mathcal U$ be an ultrafilter on $A$ containing all sets $\{\alpha\in A: \alpha\geq\alpha_0\}$ for arbitrary $\alpha_0\in A$. I would like to know if the ultraproduct $W$ of the $L_\alpha$ with respect to $\mathcal U$ is isometric isomorphic to $L$ itself. If $A$ contains a largest element this is true of course, but my intuition says it should be also true otherwise. Here is what I have tried: Let $\phi: L\to W, f\mapsto (E_\alpha f)_\mathcal U$, where $(x_\alpha)_\mathcal U$ denotes the equivalence class of $(x_\alpha)_{\alpha\in A}$ with respect to $\mathcal U$. The mapping is isometric: $\|(E_\alpha f)_\mathcal U\| = \lim_\mathcal U\|E_\alpha f\|$. Since $\|E_\alpha f\|$ net-converges to $\|f\|$ this is also true for the ultrafilter limit due to the property we demanded of our ultrafilter. I have problems with the surjectivity. Let $(f_\alpha)_\mathcal U\in W$ be arbitrary. My idea was to define a functional on $\varphi$ on $L^q(X)$ via $\varphi(g) = \lim_\mathcal U\int_{L_\alpha}(E_\alpha g)f_\alpha$. The limit exists because $\int_{L_\alpha}(E_\alpha g)f_\alpha$ is bounded. This also shows that $\varphi$ is bounded, hence there is $f\in L$ which induces $\varphi$. I think that we should have $(E_\alpha f)_\mathcal U = (f_\alpha)_\mathcal U$, but I can't show that $\lim_\mathcal U\|E_\alpha f-f_\alpha\| = 0$. If $(f_\alpha)_\mathcal U$ is already of the form $(E_\alpha f)_\mathcal U$ then this construction with the functional indeed gives back $f$, but in the general case I don't see it. Can anybody help me?","['functional-analysis', 'lp-spaces', 'filters']"
2105157,Integral of a function over the unit ball,"How does one compute the integral of $|x|^{- \alpha}$ over $B_1 (0) \subset R^n$, where $0 < \alpha < n$? I know the function is Lebesgue integrable because $\alpha < n$, but I'm need of an exact formula.","['multivariable-calculus', 'real-analysis', 'integration']"
2105167,Is it possible to construct a regular heptagon with just compass and straightedge?,"Is it possible to construct a regular heptagon (a figure with seven sides) with just compass and straightedge? If so, could you please give me directions for how to do this?","['geometric-construction', 'polygons', 'geometry']"
2105172,$(XY)^*=X^* Y^*$?,"Is it true for complex matrices $X,Y$ that
$$
(XY)^*=X^* Y^*?
$$
where $^*$ refers to complex conjugation.  How can we prove this if so?  Thanks! Note: I am referring to complex conjugation, not the hermitan transpose. The answer below refers to hermitan tranpose.","['matrices', 'linear-algebra', 'complex-numbers']"
2105175,Optimization and maximum geometry,"What is the side length of the largest square that will fit inside an equilateral triangle with sides of length 1. I created two equations:
Square: Area=$x^2$
Triangle: Area= $\sqrt{3 /4}$ However, how can I find the maximum??
I did $\sqrt{3 /4}=x^2$ ang got fourth root $3 / 2$ which is wrong","['derivatives', 'linear-algebra', 'optimization', 'geometry']"
2105182,Christoffel symbols and metric,"For Christoffel symbol and metric, we've the following identity $$\large
\frac{1}{2}g^{\alpha\gamma}(g_{\alpha\beta,\mu}+g_{\alpha\mu,\beta}-
g_{\beta\mu,\alpha})={\mathrm\Gamma^{\gamma}}_{\beta\mu}.
$$ Now even though I've seen the derivation, I still can't understand what is the motivation behind the steps taken, in all the index juggling being done. Can anyone please give a motivated proof for the identity? I mean that mentioning why we are doing instead of just what we are doing. What if the identity wasn't discovered yet and you were to, what will go inside your head to come up with this useful result and why would you do the following to arrive at it, instead of just Hit and Trial. $$\large
\begin{aligned}
  g_{\alpha\beta,\mu}&={\mathrm\Gamma^{\nu}}_{\alpha\mu}g_{\nu\beta}+
  {\mathrm\Gamma^{\nu}}_{\beta\mu}g_{\alpha\nu},\\
  g_{\alpha\mu,\beta}&={\mathrm\Gamma^{\nu}}_{\alpha\beta}g_{\nu\mu}+
  {\mathrm\Gamma^{\nu}}_{\mu\beta}g_{\alpha\nu},\\
  -g_{\beta\mu,\alpha}&=-{\mathrm\Gamma^{\nu}}_{\beta\alpha}g_{\nu\mu}-
  {\mathrm\Gamma^{\nu}}_{\mu\alpha}g_{\beta\nu}.
\end{aligned}
$$","['tensors', 'differential-geometry']"
2105211,Discrete Mathmatics (tautology proof w/ logical equivalents),"So I'm proving a tautology with logical equivalents, but as I get to the end I'm not getting a truth. The question states 'Prove that each statement is a tautology' which leads me to believe that the statement is in fact true. Was wondering if anyone could take a look at my work and tell me if they spot any errors? I've tried a couple different ways, but this is the closest I've been able to get. STATEMENT: [(p v q) ^ (p -> r) ^ (q -> r)] -> r L.E.1    : [(p v q) ^ ('p v q) ^ ('q v r) ] -> r //// implication L.E.2: ' [(p v q ) ^ ('p v q) ^ ('q v r)] v r ///// implication L.E.3: [ ' (p v q) v ' ('p v q) v ' ('q v r)] v r ///// demorgans L.E.4: [( 'p ^ q ) v ( p ^ q ) v ( q ^ r )] v r///// demorgans L.E.5: [('p ^ q) v ( q ^ p ) v ( q ^ r )] v r////// communicative L.E.6: [('p ^ q) v q ^ (p v r) ] v r/////////// distributive L.E.7: [( q ^ 'p ) v (q ^ (p v r)] v r/////////// communicative L.E.8: [( q ^ ('p v (p v r) )] v r///////////// distributive L.E.9: [(q ^ ( ('p v p) v r)] v r////////////// distributive L.E.10: [q ^ ( T v r ) ] v r ////////////////// complement L.E.11: [ q ^ T ] v r /////////////////////// identity L.E.12: q v r //final form. As you can see, I am unable to get it to evaluate to true, but merely 'q v r'","['logic', 'proof-verification', 'discrete-mathematics']"
2105212,trouble distinguishing between trigonometric functions and hyperbolic functions,"So I'm getting confused because for $z \in \mathbb{C}$ we have $$\cos(z) = \frac{e^z+e^{-z}}{2} \,\,\, \text{and} \,\,\,\,\ \sin(z) = \frac{e^z-e^{-z}}{2i}$$ where $z = x+iy$ with $x,y \in \mathbb{R}$. However we know that $\cos(iz) = \cosh(z)$ and $\sin(iz) = i\sinh(z)$ for $z\in\mathbb{C}$ right? But the definition of the hyperbolic functions is given as $$\cosh(x) = \frac{e^{x}+e^{-x}}{2}\,\,\,\, \text{and} \,\,\,\, \sinh(x) = \frac{e^{x}-e^{-x}}{2i}$$ but this looks exactly the same as the trigonometric functions. So my question is Since I couldn't find it on Wikipedia, is $x \in \mathbb{R}$ instead of $x\in\mathbb{C}$ when we are giving the definition of the hyperbolic functions? (sorry for the dummy $x$ in $z = x+iy$ and here) So fundamentally, can we say that the ""only"" difference in the definition of the trigonometric functions and the hyperbolic is that the argument (or the exponential) of the hyperbolic functions is real, whereas the argument of the exponentials for the trigonometric ones is complex? Edit can we say that $\cos(x) = \frac{e^{ix}+e^{-ix}}{2}$ for $x\in \mathbb{R}$, but also  $\cos(z) = \cos(x+iy) = \frac{e^{i(x+iy)}+e^{-i(x+iy)}}{2} = \frac{e^{ix-y}+e^{-ix+y}}{2} =\frac{e^{-y}e^{ix}+e^{y}e^{-ix}}{2} $  ?","['hyperbolic-functions', 'trigonometry', 'complex-numbers']"
2105218,Find CDF of random variable which depends on other variable,"Let $X$ be a random variable with uniform distribution on $[-1, 1]$. Find the CDF of random variable Y given by the following formula: $Y = \left\{\begin{matrix}
 -\frac{1}{2},& X < - \frac{1}{2}\\ 
 X,& -\frac{1}{2} \leq X \leq \frac{1}{4}\\ 
 \frac{1}{4}, & X > \frac{1}{4}
\end{matrix}\right.$ So I've found PDF and CDF of $X$: $f_X(x) = \begin{cases}
 \frac{1}{2}, & x \in [-1, 1]\\ 
 0, & \text{otherwise}
\end{cases}$ $F_X(a) = \int_{-\infty}^{a} f_X(x) dx = \left\{\begin{matrix}
 0, & a \leq -1\\ 
 \frac{a+1}{2}, & a \in (-1, 1) \\ 
 1, & a \geq 1 
\end{matrix}\right.$ I tried to find Y's CDF by: $F_Y(a) = P(Y \leq a)$ $= P(-\frac{1}{2} \leq a, X < - \frac{1}{2}) + P(X \leq a, - \frac{1}{2} \leq X \leq \frac{1}{4}) + P(\frac{1}{4} \leq a, X > -\frac{1}{4})$ But what should I do next? I'm finding such CDF for the first time and my notes say I need to consider a few different cases, but I have no clue what they should look like and how to do it. Any tips would be helpful.","['probability-theory', 'probability', 'random-variables', 'probability-distributions']"
2105224,"If $2^{2017} + 2^{2014} + 2^n$ is a perfect square, find $n$.","If $2^{2017} + 2^{2014} + 2^n$ is a perfect square, find $n$. My first shot would be to assume the perfect square is $2^{2018}$, but how would I prove that?  Even if it is, what is $n$?  All help is appreciated.",['algebra-precalculus']
2105301,About the proof of the Four Vertex Theorem of Do Carmo.,"I have problems understanding this part of the proof given by Manfredo Do Carmo in Differential Geometry of Curves for the theorem of The Four-Vertex Theorem . I understand that in the first part he considers that exists a maximum and a minimum just because the parametrization of the curve is a mapping from $\mathbb{R}$ to $\mathbb{R}^2$. The next part is the one that I don't understand; he considers a line $L$ through those vertices where are the max and min of the curve, then he says this: Let $Ax + By + C = 0$ be the equation of $L$. If there are no further
  vertices, $k'(s)$ keeps a constant sign on each of the arcs $\beta$ and $\gamma$ (until here, I understand it). We can then arrange the sign of all the coefficients $A, B, C$ so that the integral in Eq. (5)
  is positive. This contradiction shows that there is a third vertex and that
  $k'(s)$ changes sign on $\beta$ or $\gamma$, say, on $\beta$. Since $p$ and $q$ are points of maximum and minimum, $k'(s)$ changes sign twice on $p$. Thus, there is a fourth vertex. The integral he refferes as Eq.(5) is: $$\int_0^l (Ax+By+C)\frac{dk}{ds}ds=0$$ So I don't know how It would become a positive integral if it's zero.","['differential-geometry', 'proof-explanation']"
2105305,Power set of set with subsets,"This is a noob question, but I can't quite get my head around this. Suppose I have a set $A = \{\{a, b\}, x, y\}$, how would you go about getting the power set $P(A)$? Do you go into subset $\{a, b\}$ recursively, or do you treat $\{a, b\}$ as a single element of set $A$? In other words: would $P(A)$ = $\{\emptyset, \{\{a,b\}\}, \{x\}, \{y\}, \{\{a,b\},x\}, \{x,y\}, \{\{a,b\},y\}, \{\{a,b\},x,y\}\}$ be correct?",['elementary-set-theory']
2105317,Comparing Infinite Sets,"Hello Stack Exchange Community, I just read a book on Cantor and how he proved that the real numbers were a larger infinity than the natural numbers. He uses bijection and claims that if you were to write out all of the natural numbers you would be able to biject every single one with a real number, but after this bijection there would still be more real numbers. However, could you also use the same logic and biject all the real numbers with natural numbers and when you have a new real number, just add 1 to your previous real number? Also, since we can list all the fractions by listing 1 over every natural number, then 2 and 3 and on to infinity, couldn't we just write the ""first"" real number by just writing inifitely many zeroes, then a 1, then repeat but write 2, then 3, and all the natural numbers? This may just be a conceptual thing but I don't understand Cantor's logic and the different types of infinities.",['elementary-set-theory']
2105348,Minimize trace($MX$) with $M$ rank-deficient and $X$ positive semidefinite,"I have an optimization problem of the following form: $$\min_{X\succeq0} \mathrm{trace\;} MX$$ under the linear constraint $\mbox{diag} (X) = \mathrm{Id}$ and the non-convex constraint $\mbox{rank} (X) = 1$. The matrix $M$ is square and rank-deficient. The convex relaxation of this problem corresponds to dropping the rank-1 constraint, and merely keeping $X$ positive semidefinite. I tried running a standard SDP solver (Mosek) on this problem but it yields a matrix $X$ which, despite satisfying the linear constraint and being positive semidefinite, is not of rank one. Instead, it is typically of rank $(n - \mathrm{rank\;} M)$ where $n$ is the number of rows of $X$. Can you explain why I am getting this result?","['matrices', 'relaxations', 'semidefinite-programming', 'convex-optimization', 'linear-algebra']"
2105378,Descartes rule of signs for Taylor Series.,"Does descartes rule of signs for work with Taylor Series. For example, If we have $e^x-x$ then can we say because the Taylor series $1+\frac{x^2}{2}+\frac{x^3}{6}+\cdots$ does not have any sign changes then the equation has no positive roots?","['algebra-precalculus', 'calculus']"
2105419,What happens to an absolute value graph if $|x|$ has a coefficient,"I skipped Algebra I in school, and we have Mathematics midterms next week. While going through our review packet, I noticed graphing absolute values, something I had never seen before. I've figured out the basics: $|x+n|$ translates the graph $n$ units along the x axis, $|x|+d$ translates the graph $d$ units along the y axis, and $-|x|$ flips the graph so it opens downward. What happens, however, if we have $a|x|$, or $|ax|$? Is there an easy short hand way to draw this, or do I have to make a chart of the points and graph them one by one?","['algebra-precalculus', 'absolute-value', 'graphing-functions']"
2105421,Reproducing kernel Hilbert space of set functions,"Let $\Omega$ be a finite set. Can we construct a reproducing kernel Hilbert space (RKHS) of real-valued functions $2^\Omega \to \mathbb{R}$? If so, how can we construct one and how is the kernel defined? Thank you!","['functional-analysis', 'machine-learning', 'hilbert-spaces', 'reproducing-kernel-hilbert-spaces']"
2105428,Evaluate $\int_{0}^{1}\left ( x+\frac{x}{x+\frac{x}{x+\frac{x}{x+\cdots }}} \right )dx$,"How to evaluate the following integral
$$\int_0^1 \left ( x+\cfrac{x}{x+\cfrac{x}{x+\cfrac{x}{x+\cdots }}} \right )dx$$
I have no idea how to deal with the continued fraction.","['integration', 'definite-integrals', 'continued-fractions', 'calculus']"
2105469,Prove $\lim_{n\rightarrow \infty }\frac{1}{n}\int_{\frac{1}{n}}^{1}\frac{\cos2t}{4t^{2}}\mathrm dt=\frac{1}{4}$,"How to prove
$$\lim_{n\rightarrow \infty }\frac{1}{n}\int_{\frac{1}{n}}^{1}\frac{\cos2t}{4t^{2}}\mathrm dt=\frac{1}{4}$$
I used $x\to \dfrac{1}{t}$ but it didn't work. Any hint?Thank you.","['integration', 'limits']"
2105470,"Finding extreme values of $f(x,y,z)=x^2+2y^2+3z^2$ on unit sphere $x^2+y^2+z^2=1$","I defined $G(x)=x^2+y^2+z^2-1$, such that the gradient of G $\nabla G=(2x, 2y, 2z)$, so that $\nabla f=(2x, 4y, 6z)=\lambda (2x,2y,2z)$. The conclusion I drew was that the only possible value was either $\lambda=0$, or y and z were both 0 but x can be anything. This seems incorrect to me, but I'm not sure how to proceed.","['multivariable-calculus', 'optimization']"
2105487,What is $\lim\limits_{n\to\infty}\frac{n^\sqrt n}{2^n}$?,I am stuck at this question where I have to calculate what is big O of $2^n $and $n^\sqrt{n}$ Can I say that lim $2^n/n^\sqrt{n}$ = $\lim_{n\to\infty} (2/n^{1/\sqrt{n}})^n$ and then conclude that when it means $(2/0)^n\to \infty$ ? Any help would be appreciated,['limits']
2105528,Proof about continuity of a function involving the Banach fixed point theorem,"Be $X$ and $\Lambda$ metric spaces, with $X$ complete, and $f\in C(X\times\Lambda,X)$. Suppose that exists some $\alpha\in[0,1)$ and, for each $\lambda\in\Lambda$, some $q(\lambda)\in[0,\alpha]$ such that
  $$d(f(x,\lambda),f(y,\lambda))\le q(\lambda) d(x,y),\quad\forall x,y\in X$$
  By the Banach fixed point theorem, for each $\lambda\in\Lambda$, $f(\cdot,\lambda)$ has a unique fixed point $x(\lambda)$. Prove that $[\lambda\mapsto x(\lambda)]\in C(\Lambda,X)$. Im totally stuck with this exercise, I dont have a clue about what to do... I tried to show the continuity of $h$ defined as $$h:\Lambda\to X,\quad \lambda\mapsto x(\lambda)$$ trough the $\epsilon-\delta$ definition of continuity of $f$ and the information of the problem but I cant do it. Geometrically is easy to see it veracity because the function $h$ is just the intersection of $f$ with the plane defined by the set $\{\langle x,y\rangle\in X\times X:x=y\}\times\lambda$. My work: from the continuity of $f$ we have that for any fixed point $x:=f(x,\lambda_x)$ for any $\epsilon>0$ exists a $\delta>0$ such that $$d(\langle y,\lambda\rangle,\langle x,\lambda_x\rangle)<\delta\implies d(f(y,\lambda),x)<\epsilon$$ If we set $\langle y,\lambda\rangle=\langle x_0,\lambda_x\rangle$ then for the sequence defined as $$x_n:=f(x_{n-1},\lambda_x)$$ that converges to the fixed point $x$, we can rewrite the above as $$d(\langle x_0,\lambda_x\rangle,\langle x,\lambda_x\rangle)<\delta\implies d(x_1,x)<\epsilon\tag{1}$$ and from the contraction of $g_\lambda:=f(x,\lambda)$ for fixed $\lambda\in\Lambda$ we knows that $$d(f(x_0,\lambda_x),x)=d(x_1,x)\le q(\lambda_x) d(x_0,x)\tag{2}$$ for a fixed point $x$ (with any $0\le q(\lambda)<1$, hence the contraction). Moreover: we can suppose that the metric in $X\times\Lambda$ is the standard product metric, then: $$d(\langle a,b\rangle,\langle c,d\rangle)=\max\{d(a,c),d(b,d)\}\tag{3}$$ Then applying $(3)$ in $(1)$ we get $$d(x_0,x)<\delta\implies d(x_1,x)<\epsilon$$ But as I said Im stuck, I dont know how to show the desired continuity of $h$. Probably the last two (or three) identities are useless, I just take them to see if I can get something from there. Some help will be appreciated, thank you.","['continuity', 'banach-fixed-point', 'analysis']"
2105529,"How to calculate $\lim_{(x,y)\to(0,0)}\frac{xy^4}{x^2+y^6}$? [duplicate]","This question already has answers here : Multivariable limit proof: $\lim\limits_{(x,y)\rightarrow (0,0)}\frac{\left|x\right|^a\left|y\right|^b}{\left|x\right|^c + \left|y\right|^d} = 0$ (4 answers) Closed 6 years ago . $$\lim_{(x,y)\to(0,0)}\frac{xy^4}{x^2+y^6}$$ I know the limit is 0 if it exists. I want to solve using squeeze theorem but I don't know what to use for the upper function.","['multivariable-calculus', 'limits']"
2105546,Let $n>1$ be an odd integer . Show that $n\nmid 3^n+1$,"Problem from Burton's Number Theory : Let $n>1$ be an odd integer . Show that $n\nmid  3^n+1.$ Trying by induction on $n$. The result holds for $n=3 $ since $3\nmid 3^3+1=28$. Let the result hold for $n=m\implies m \nmid  3^m+1.$ Assume contrary, let $m+1\mid 3^{m+1}+1\implies 3^{m+1}+1=k(m+1)\implies 3.3^m=km+(k-1)$. I am unable to proceed further.Please help.","['number-theory', 'congruences', 'divisibility', 'elementary-number-theory']"
2105555,Proof that the 2-norm of orthogonal transformation of a matrix is invariant,"For any matrix A and an orthogonal matrix Q, I can prove in the standard way that $$\|QA\|_2 = \|A\|_2 $$ using $$\|QA\|_2^2 = (QAx)^T(QAx) = (Ax)^T(Ax) = \|A\|_2^2 $$ However, I am unable to cancel Q, when the transformation is AQ, i.e. $$\|AQ\|_2^2 = (AQx)^T(AQx) = x^TQ^TA^TAQx$$ After this point I am unable to prove the same that $$\|AQ\|_2 = \|A\|_2 $$","['matrices', 'normed-spaces', 'invariance', 'linear-transformations', 'linear-algebra']"
2105638,"What is $\frac{d}{dx}\int_0^{x^2}f(t) \,dt$?","What is $\frac{d}{dx}\int_0^{x^2}f(t) dt$ My understanding is that if $F(t)$ is antiderivative of $f(t)$, then it should be $F(x^2)-F(0)$, but it is $f(x^2)(2x)$ The entire problem is as follow: Find $f(4)$ if $\int_0^{x^2}f(t)\, dt=x\cos (\pi x)$ and the solution is $\frac{d}{dx}\int_0^{x^2}f(t) \,dt=\cos \pi x -\pi x \sin \pi x\Rightarrow f(x^2)x=\cos \pi x -\pi x \sin \pi x \Rightarrow f(x^2)=\frac{\cos \pi x -\pi x \sin \pi x}{x}$ Thus $x=2\Rightarrow f(4)=1/4$","['derivatives', 'integration', 'calculus']"
2105695,Evaluating $\iint_V x^4+y^4+z^4$ with the divergence theorem,"Use Gauss divergence theorem to evaluate $$\iint_S \left(x^{4} + y^{4} + z^{4}\right)$$ over sphere S of radius $a$ . So I wrote this as $$
\begin{align}
&a\iint_{\partial V} \Big(x^3 \hat{i}+y^3\hat{j}+y^3\hat{k}\Big)\cdot\Big(\frac{x\hat{i}+y\hat{j}+z\hat{k}}{a}\Big)\\
=\ &a\iiint_V \operatorname{div}(x^3,y^3,z^3)\\
=\ &3a\iiint_Va^2=3a^3\frac{4\pi}{3}a^3=4\pi a^6
\end{align}$$ But my answer is not matching. The answer key says it should be $\frac{12 \pi a^6}{5}$","['multivariable-calculus', 'divergence-theorem', 'surface-integrals']"
2105732,Why geometrically irreducible quartic curves in projective plane corresponds to an open subset of projective space of dimension 14,"Here's exercise 9.5G from Ravi Vakil's Foundation of algebraic geometry Recall that the quartic curves in $\mathbb{P}^2_k$ are parametrized by
  a $\mathbb{P}^{14}_k$. Show that the points of $\mathbb{P}^{14}_k$
  corresponding to geometrically irreducible curves form an open subset.
  Explain the necessity of the modifier “geometrically” (even if $k$ is
  algebraically closed). It is also remarked that the dimension $2$ and degree $4$ can be replaced by other numbers.
I think irreducible curves here mean irreducible and reduced curves. My first question is why the abverb ""geometrically"" is needed? A homogeneous polynomial of degree corresponds corresponds to an reducible or non-reduced closed subscheme if and only if the polynomial is reducible, which means that the polynomial is the product of two quadratic polynomial or a product of a linear polynomial and a cubic, and these should correspond to two closed subset of $\mathbb{P}^{14}_k$ since the map between two projective variety is proper (but this fact has not been proved before this exercise, so is there any other way to see this?), and thus the complement of their union, which corresponds to irreducible quartic curves, is open. It seems that this argument works without the term ""geometrically"". My second question is how to do the question when the term ""geometrically"" is added. Let $K$ be the algebraic closure of $k$, by using the arguments above (if it is correct), I can find an open subset $W$ of $\mathbb{P}^{14}_K$ which corresponds to irreducible quartic curves in $\mathbb{P}^2_K$. Let $\phi:\mathbb{P}^{14}_K\to\mathbb{P}^{14}_k$ be the pullback of the map $specK \to speck$. I would want to show that $\phi$ maps $W$ to an open set of $\mathbb{P}^{14}_k$. I want to show this by showing $\phi$ is both closed and surjective and hence open. I can show that $\phi$ is surjective on closed set: Let $p\in \mathbb{A}^{14}_k \subset \mathbb{P}^{14}_k$ be a closed point, then $p$ also corresponds to an ideal of  $K[x_1,\dots,x_{14}]$, let $m$ be any maximal ideal  containing this ideal, then the image of $m$ would be $p$, but I am not sure if the map is surjective or not since $\mathbb{A}^{14}_K$ is not a $k$ variety and we cannot use Chevalley's theorem on constructible sets.
To show that $\phi$ is closed, I find the same difficulties in showing that the map $specK[x_1,\dots,x_{14}]/I \to speck[x_1,\dots,x_{14}]/I\cap k[x_1,\dots,x_{14}]$ is surjective. Any helps are appreciated, thank you.",['algebraic-geometry']
2105733,Trouble with finding shortest distance between $y=x^2$ and $y=x-1$ with Lagrangian multipliers,"I've found another thread with a similar question, but none of the answers help with the specific part I'm stuck on. Just to make things simpler, I've used the square of the distance $f(x_1,x_2,y_1,y_2)=(x_1-x_2)^2+(y_1-y_2)^2$, and I have constraints $G_1=x_1^2-y_1$, and $G_2=x_2-y_2-1$. Taking the gradients of $f$, $G_1$, and $G_2$, I have the system of equations $2(x_1-x_2)=2\lambda_1x_1$ $2(y_1-y_2)=-\lambda_1$ $-2(x_1-x_2)=\lambda_2$ $-2(y_1-y_2)=-\lambda_2$ What I've done so far is, I've first observed that the immediate implication of the 2nd and 4th equations is that $\lambda_1=-\lambda_2$. Using this, I cancelled out the 1st and 3rd equations with the substituted value for $\lambda_2$, and got that $2\lambda_1x_1=\lambda_1\implies x_1=\frac{1}{2}$, and by constraint 1 that $y_1=\frac{1}{4}$. From here though, I'm not sure how to pin down the value of $\lambda$, and therefore determine $x_2$ and $y_2$.","['multivariable-calculus', 'optimization']"
2105737,Infinitely differentiable implicit function,"I have an infinitely differentiable function $F(x,y) : [0,1]^2 \rightarrow \mathbb{R}$. I know that for every $x \in [0,1]$ there is a unique $y$ for which $F(x,y)=0$. Can I claim that the function $y(x)$ given by $F(x,y) = 0$ is infinitely differentiable and differentiate $F(x,y) = 0$ w.r.t $x$?","['multivariable-calculus', 'implicit-differentiation']"
2105746,Is $x^3+1$ considered even or an odd function?,Question Is $x^3+1$ considered even or an odd function? I was wondering that because it shifted above by a factor of 1 so would that make it a non odd function?,"['algebra-precalculus', 'even-and-odd-functions', 'functions']"
2105761,Evaluating $\lim_{r \to \infty} r^c \frac{\int_0^{\pi/2}x^r \sin x dx}{\int_0^{\pi/2}x^r \cos x dx}$,"The question is basically to find out the following limit($c$ is any real number)
$$\lim_{r \to \infty} r^c \frac{\int_0^{\pi/2} x^r \sin x \, dx}{\int_0^{\pi/2}x^r \cos x \, dx}$$ I tried to use the property of definite integral and rewrote it as $$\lim_{r \to \infty} r^c \frac{\int_0^{\pi/2}(\pi/2-x)^r \cos x dx}{\int_0^{\pi/2}x^r \cos x dx}$$ and then expanded the numerator using binomial theorem.But this didnot take me to the answer.I also tried using integration by parts in the numerator but that too didnot helped me.Any hint to go ahead will be highly appreciated.Thanks.",['limits']
2105777,Jacobian with vanishing determinant everywhere,"This is from advanced calculus. Suppose $f: \mathbb{R}^n \rightarrow \mathbb{R}^n$ is continuously differentiable. The Jacobian of $f$ has zero determinant over $\mathbb{R}^n$. For example in 2-dimensional case, $f(x,y)=(y,y)$ is such a function. Let's suppose $n \ge 2$ since $n=1$ case gives a constant function. My question is :is it true that $f$ cannot be 1-1? My best attempt is that at each $x \in \mathbb{R}^n$ some directional derivative is zero, and perhaps an integral over some path will work, but I am not sure how to do it. Any idea is welcome. Thank you very much.","['multivariable-calculus', 'derivatives']"
2105795,Curve that looks like arctan(x) but is asymmetric,"I am working with some dataset which looks very similar to the negative of $\tan^{-1}(x)$ to me: The only thing is that this curve need not be ""anti-symmetric"" around zero. I have tried fitting functions of the form $-a\tan^{-1}(bx) + c$ but it doesn't always produce good fit because of the very fact that data can be asymmetric. Does anybody know any good function which would qualitatively look like negative $\tan^{-1}$ but is asymmetric about zero? Most probably, it would involve parameters which one can change to change the amount of asymmetry. Any ideas?",['functions']
2105807,Correct way to learn number theory?,"Background I am a college pass out. I have done my B.Tech in computer science and masters in quantum information. I am soon going to take up an industrial job. In the free time I got, after passing out from my college till now, ( few months ) I started reading Sipser's book on ""Complexity and Computability theory"". After reading it I wanted to learn more about it so I turned towards the book by Boaz and Barak on ""Complexity theory"". When I reached the chapter on ""cryptography"", I realized I did not know the fundamentals of number theory, so I started reading ""Theory of numbers"" by Hardy and Wright. Question I have read about one-third of Hardy and Wright. It got my really interested in elementary number theory. I am planning to read the complete book and pick it up as my hobby.  The problem I am facing is, although till know I am able to follows the proofs on my own, I keep forgetting what I read earlier. For example I am currently reading about continued fractions and approximations of irrationals by rationals. But I don't remember the proofs, tricks, topic etc in detail that I read before it ( although I can always go back and remind myself ). As I read further I only remember the current topic that I read. And I feel if I read the book completely, at the end I would only remember the broad topics and only get a broader view. Also I try to read couple of pages everyday, but there are breaks of long number of days where I go without reading a single page. And when I again start reading I tend to forget even the current topic. So I wanted to ask what is the correct way to learn number theory ? Should I read Hardy and Wright completely ( I have still to learn of many other topics like pell's equations, diophantine equations etc. ) ? Is there some other more practical way of learning number theory as a hobby ? How do I reach the threshold point of learning elementary number theory ?","['number-theory', 'self-learning', 'soft-question']"
2105844,Limit without L'Hopital rule,How to compute the limits for the following functions without using L'Hopital rule? 1) $\displaystyle\underset{x\to 0^{+}}{\lim} \frac{e^{1/x} + 2 e ^{-1/x} + \ln x}{3e^{1/x} + 5e^{-1/x} + 7\ln x}  $ 2) $\displaystyle\underset{x\to 0^{+}}{\lim} \frac{x+e^{-1/x}}{x-e^{-1/x}}$ I wouldn't know where to begin. Thank you very much.,"['limits-without-lhopital', 'calculus', 'limits']"
2105857,Probability of getting an odd number of heads if n biased coins are tossed once.,"The question is basically to find out the probability of getting odd number of heads when $ n$ biased coins,with $m^{th}$ coin having probability of throwing head equal to $\frac{1}{2m+1}$ ($m=1,2,\cdots,n$) are tossed once.The results for each coin are independent. If we consider first that only one head turns up.The probability then is equal to $$\sum_{m=1}^{n} [\frac{1}{2m+1} \prod_{k=1,k \neq m}^{n} (1-\frac{1}{2k+1})]$$ which seems very difficult to evaluate.It gets more complicated if we increase the number of heads.I couldnot find out a simple way to do this.Any suggestion would be highly appreciated.Thanks.",['probability']
2105865,infinite equivalent sets query,I want to know what is the criteria for two sets (finite and infinite to be equivalent) .Does the same criteria hold for both type of sets? I read that two sets are equivalent if their no. Of elements( cardinality) is same. Its alright for finite sets. But again in case of infinite sets as in this question cardinality is infinite. Here I read again that one to one correspondence should be there. But in the question above for an infinite set  if a subset is proper first of all its cardinality with its superset will never be equal .secondly for one - one correspondence how come a proper subset have one to one correspondence. It goes on till infinity. How can we be sure that there are no term which do not have one to one corresponce. If someone can please make me understand in simple language and convince me I ll be greatful.,['elementary-set-theory']
2105870,Division of Distributions on $\mathbb{R}$,"Let $H:\mathbb{R} \rightarrow \mathbb{C}$ be a function, with $H \in C^{\infty}(\mathbb{R})$, and $S \in \mathscr{D}'(R)$ a distribution such that there exists $x_0 \in \mathbb{R}$ which belongs to both the support of $H$ and the support of $S$. Assume that $H$ and all its derivatives vanish in $x_0$:
\begin{equation}
(D^{n}H)(x_0)=0 \qquad (n=0,1,2,\dots).
\end{equation}
I am trying to prove that in these hypotheses, the division of $S$ by $H$ is not possible. This means that there exists no distribution $T \in \mathscr{D}'(R)$ such that
\begin{equation}
H \cdot T = S.
\end{equation}
I could prove this statement only in a particular case (see Note (2) below), but I am quite convinced that it is true. Any help is welcome. Thank you very much in advance for your attention. NOTE (1). The statement above is a conjecture of mine, inspired by Schwartz, Théories des Distributions, Chapitre V, $\S 4$, p.126. He states that if $H$ is a function as described above, that is $H \in C^{\infty}(\mathbb{R})$ and $H$ vanishes with all its derivatives in a point $x_0$, then the division of a distribution $S$ by $H$ is not possible. Obviously, this is not true for a generic distribution $S$. To see this, assume that $H$ has as only zero $x_0$, and that $x_0$ does not lie in the support of $S$. For any non-empty open subset $\Omega$ of $\mathbb{R}$, define $S_{\Omega} \in \mathscr{D'}(\Omega)$ as
\begin{equation}
S_{\Omega}(\psi)=S(\psi) \quad (\psi \in \mathscr{D}(\Omega)).
\end{equation} Then if $\Omega_1$ is the complement of the support of $S$, the zero distribution $T_1=0 \in \mathscr{D'}(\Omega_1)$ satisfies 
\begin{equation}
H \cdot T_1 = S_{\Omega_1},
\end{equation}
since we have
\begin{equation}
T_1(H\psi) = S(\psi)=0 \quad \forall \psi \in \mathscr{D}(\Omega_1).
\end{equation}
Now put $\Omega_2=\mathbb{R} \backslash \{x_0 \}$. Since $1/H \in C^{\infty}(\Omega_2)$, $T_2=\frac{1}{H} \cdot S_{\Omega_2}$ is a well defined element of $\mathscr{D'}(\Omega_2)$ and we have
\begin{equation}
H \cdot T_2 = S_{\Omega_2},
\end{equation} 
that is
\begin{equation}
T_2(H \psi) = S (\psi) \quad \forall \psi \in \mathscr{D}(\Omega_2).
\end{equation}
Now let $\xi_1 \in \mathscr{D}(\Omega_1)$ be such that $0 \leq \xi \leq 1$, and $\xi=1$ on an open set $V$ containing $x_0$, and define $\xi_2 = 1 - \xi_1$. Define 
\begin{equation}
T(\phi)=T_1(\xi_1 \phi)+T_2(\xi_2 \phi) \quad (\phi \in \mathscr{D}(\mathbb{R})).
\end{equation}
It is immediate to see that $T \in \mathscr{D'}(\mathbb{R})$ and that
\begin{equation}
H \cdot T = S.
\end{equation} NOTE (2). I could prove the statement above in the specific case in which $S$ is the distribution defined by the constant function equal to one.
In this case, take $\psi \in \mathscr{D}(R)$ such that 
\begin{equation}
\int_{\mathbb{R}} \psi(x) dx =1,
\end{equation}
and define the sequence of test functions
\begin{equation}
\psi_{m}(x)=m \psi(m(x-x_0)+x_0) \quad (x \in \mathbb{R}, m=1,2,3,\dots).
\end{equation}
It is easy to see that $S(\psi_m) =1$ for all $m$. Now set
\begin{equation}
\phi_m(x) = H(x) \psi_m(x) \quad (x \in \mathbb{R}, m=1,2,3,\dots).
\end{equation}
Define for any non-negative integers $n, m$ the function 
\begin{equation}
F_{n,m}(x) = \begin{cases} \frac{(D^n H)(x)}{(x-x_0)^m} & x \neq x_0,
\\ 0 & x = x_0, \end{cases}
\end{equation}
We have $F_{n,m} \in C^{\infty}(\mathbb{R})$: in particular $F_{n,m}$ is continuous at $x_0$.
From this observation and Leibniz formula we easily get that $\phi_m \rightarrow 0$ in $\mathscr{D}(\mathbb{R})$. So if there existed $T \in \mathscr{D'}(\mathbb{R})$ such that
\begin{equation}
H \cdot T = S,
\end{equation}
we should have $T(\phi_m) \rightarrow 0$. But we have $T(\phi_m)=T(H\psi_m)=S(\psi_m)=1$ for all $m$, a contradiction.","['real-analysis', 'distribution-theory', 'analysis']"
2105876,Uniform Integrability implies boundedness of $\sup_i\int|f_i|dP$?,"We defined a family of functions $\{f_i\}_{ i\in I}$ to be uniformly
  integrable if for every $\epsilon>0$ there is a number M s.t $\forall$
  i: $\int_{|f_i|>M}|f_i|dP<\epsilon$ a) $\{f_i\}_{i\in I}$ are uniformly integrable b) $\sup_i\int|f_i|dP<\infty$. 1) Does $b) \Rightarrow a)$? 2) Does $a) \Rightarrow b)$? So for 1) I think I have a good counter example to disprove, I used $ f_i=i\mathbb{1}_{[0,\frac{1}i]}$. Obviously $\sup_i\int|f_i|dP=1<\infty$.  I want to prove that it's not U.I so by definition I want to show that there exists $\epsilon>0 \ s.t\  
\forall M, \exists i\ s.t \int_{|f_i|>M}|f_i|dP\geq\epsilon$ So if we choose $\epsilon$ to be 1 then for every $i>M$ we will get $\int_{|f_i|>M} |f_i|dP=1$. Now I'm not sure about proving $a) \Rightarrow b)$, what I did is the following: Because $\{f_i\}_{ i\in I}$ are UI, $\exists M s.t\  \forall i\ \int_{|f_i|>M}|f_i|dP<3$, so we have: $\sup_i\int|f_i|dP=\sup_i(\int_{|f_i|\leq M}|f_i|dP+\int_{|f_i|>M}|f_i|dP)\leq\sup_i\int_{|f_i|\leq M}MdP +3\leq \int_{0}^MMdP=M^2+3<\infty$ Is this correct?","['uniform-integrability', 'probability-theory', 'integration', 'probability', 'measure-theory']"
2105879,Order of elements in Groups Theory,"First of all, I'm new in Group Theory. I'm trying to understand how to determinate certain orders of elements in a group. For example: Indicate the order of the following elements: $a=35_{42} \in \mathbb{Z}_{42} , \ b=(3_{27},(123)) \in \mathbb{Z}_{27}\times S_5$ I know that the order of an element $x$ of a group G is the lower positive value $k$ such that $x^k=e_G$. 
Given this, I can compute for the element $a$: $35^1=35$, $35^2=28$, $35^3=21$, $35^4=14$, $35^5=7$, $35^6=42=0=e_G$ So the order of $a$ is $6$. However I don't know how to use this argument to determinate the order of $b=(3_{27},(123)) \in \mathbb{Z}_{27}\times S_5$",['group-theory']
2105919,Holomorphic Function in Disk and its Maximal,Given a complex-valued function $f(z)$ holomorphic in $|z|<2$. Prove that $$\max_{|z|=1} \left|f(z)-\frac{1}{z}\right|\geq1$$ I know the behaviour of holomorphic function but I can't do so much about that. Please help me.,"['complex-analysis', 'complex-numbers']"
2105973,Number coloring : same color sequence,The natural numbers are colored with two colors. Prove that there exists a sequence of natural numbers $ k_1 < k_2 < ... < k_n < ...$ with the property that the sequence $2k_1 < k_1 + k_2 < 2k_2 < k_2 + k_3 < 2k_3 < ...$ is of the same color. Please suggest.,"['combinatorics', 'ramsey-theory']"
2105987,Localic group as generalizations of topological groups,I have read about what locales and frames are (basic objects in pointfree topology) and now I'be seen that there exists localic groups as a generalization of topological groups. I have some questions: On which objects are groups are acting upon? What are the most important properties of localic groups? When will these localic groups be used? Moreover I would appreciate if someone would give some references for this topic.,"['heyting-algebra', 'locales', 'algebraic-topology', 'general-topology', 'group-theory']"
2106011,"Are Clifford and exterior algebras isomorphic as ""wedge product algebras""?","$\newcommand{\Cl}{\mathscr{Cl}(V)}$$\newcommand{\ext}{\Lambda(V)}$Let $V$ be a finite dimensional vector space over a field with characteristic not equal to two. Assume we have made a choice of symmetric bilinear form for $V$. It is known that the Clifford algebra $\Cl$ and the exterior algebra $\ext$ are isomorphic as vector spaces (this is an exercise in Greub's Multilinear Algebra, I believe it is mentioned in Wikipedia, and also see this and this and this related question on Math.SE). Now obviously the Clifford algebra $\Cl$ with the Clifford product is not isomorphic as an algebra to the exterior algebra $\ext$ with the wedge product . However, the wedge product is also defined on $\Cl$ and different from the Clifford product. Question: Is the Clifford algebra $\Cl$ with the wedge product , i.e. not with the Clifford product, isomorphic as an algebra to the exterior algebra $\ext$ with the wedge product? Attempt: I feel like this should follow immediately from the following two facts: The Clifford algebra $\Cl$ and the exterior algebra $\ext$ are isomorphic as vector spaces. A list of vectors $(v_1, \dots, v_n)$ is linearly independent if and only if its wedge product is non-zero: $$v_1 \wedge \dots \wedge v_n \not=0\,.$$ (I believe this second fact is correct, it is the content of at least one exercise in Lee's Introduction to Smooth Manifolds if I remember correctly, although I haven't gotten around to doing it yet.) Note: This is effectively a follow-up to this question I asked on MathOverflow. Wedge product on the Clifford Algebra This might not be correct; if so, please explain why and/or give a pointer to a reference which explains why and I will also accept your answer. (Note: what I had previously was definitely wrong, so here's a second attempt, again based on this document .) We can decompose the Clifford product $vw$ as follows: $$vw = \frac{1}{2}(vw + wv) + \frac{1}{2}(vw -wv) \,. $$ Noting that the first term on the RHS is symmetric and bilinear (in $v$ and $w$), the author Chisholm states that it is plausible that this could be the inner product. (See the top of p.4 ) I think if one takes the formal definition of Clifford algebra, it follows from the quotient relation $v^2 = \langle v, v \rangle$ that this makes sense. So then the second term on the RHS, $\frac{1}{2}(vw -wv)$, is denoted $v \wedge w$, one has from the definition that it is skew-symmetric. In the Euclidean case for $\mathbb{R}^3$, it follows from $\frac{1}{2}(vw+wv)=\langle v,w\rangle=|u||v|\cos\theta$ that $(v \wedge w)^2 = -|v|^2|w|^2 \sin^2\theta = -|v \times w|^2$. Also, the wedge product of any element of the Clifford algebra $\Cl$ with a scalar is just scalar multiplication (I think). I think the definition of the wedge product above generalizes so that for any $v_1, \dots, v_n \in V$: $$v_1 \wedge \dots \wedge v_n = \frac{1}{n!}\sum_{\sigma \in S_n} (\operatorname{sgn} \sigma) v_{\sigma(1)} \dots v_{\sigma(n)} \,, $$ where the multiplication is the Clifford product (see eq. (30) p.13 here ) but I'm not sure. If that formula is correct, then the answer to my question might automatically be affirmative due to a bijection between the Clifford algebra (with the wedge product) and alternating/skew-symmetric tensors of rank $\le n$. In other words the proposed formula is very similar to that given for creating the exterior algebra from the tensor algebra. Following Qiaochu Yuan's suggestion in the comments, the wedge product of three vectors would for example then be: $$u \wedge v \wedge w = \frac{1}{6}uvw + \frac{1}{6}vwu + \frac{1}{6}wuv -\frac{1}{6}vuw -\frac{1}{6}uwv -\frac{1}{6}wvu \\ = \frac{1}{6}u(vw - wv)+\frac{1}{6}v(wu-uw)+\frac{1}{6}w(uv-vu) \\ = \frac{1}{3}u(v \wedge w) + \frac{1}{3}v(w \wedge u) + \frac{1}{3}w(u \wedge v) \,.$$ My hope is that this would be enough to define (via induction) what is meant by the wedge product of arbitrary elements of the Clifford algebra $\Cl$. Basically the motivation for my claim/belief that the Clifford algebra $\Cl$ also has a wedge product is how many texts on the Clifford algebra of $\mathbb{R}^n$ with the Euclidean inner product treat the Clifford product (for vectors) essentially as a combination of the inner and wedge products, i.e. an extension of the wedge product. This seems like it might be compatible with the formal definition of Clifford algebra, based on the fact that one should have $v^2 = vv = \langle v, v \rangle$, but I was hoping/assuming someone here might have already learned all of this and can confirm/deny that this is true before I try to verify it all in detail by myself only to find out that I have been trying to prove something false. Wikipedia says that: ...if one takes the Clifford algebra to be a filtered algebra , then the associated graded algebra is the exterior algebra. To be honest I don't know what that means, but it seems like it might be stronger than: ""the Clifford algebra is isomorphic to the exterior algebra as a vector space"".","['geometric-algebras', 'exterior-algebra', 'multilinear-algebra', 'clifford-algebras', 'linear-algebra']"
2106041,Can we ignore terms of differential equation if coefficients go to zero at a point?,"Given a differential equation with variable coefficients, if at a given point some coefficients go to zero, can I take them to be zero and assume that the answer is correct for that point? I mean, let me give a concrete example: considering the following differential equation:
$$
a(x)\frac{dy}{dx}+b(x)\left(\frac{dy}{dx}\right)^{-1/2}+c(x)\left(\frac{dy}{dx}\right)^{1/2}+d(x)\left(\frac{dy}{dx}\right)^{-1}=0~. 
$$
if at a given point, say $x=0$, the coefficients $c(x)$ and $d(x)$ are zero, can I solve the simplified equation:
$$
a(x)\frac{dy}{dx}+b(x)\left(\frac{dy}{dx}\right)^{-1/2}=0~, 
$$
and get a valid result for $y(0)$? Moreover, does the validity of the result depends of, by solving the simplified equation, we get $\frac{dy}{dx}(0)=0$, $\frac{dy}{dx}(0)=\infty$ or $\frac{dy}{dx}(0)=\text{const.}$?",['ordinary-differential-equations']
2106044,De Rham Theorem,"I was just reading about De Rham theorem : Let $\Omega$ be an open set of $\mathbb R^n$.
Let pose $\mathcal V := \{u=(u_1,...,u_N)\in  \mathcal D^N (\Omega)\}$, And $f=(f_1,...,f_N) \in (\mathcal D'  (\Omega))^N $; So The two properties are equivalent: 1) $\exists P \in \mathcal D' (\Omega)$ such that: $f = \nabla  P . \\ $ 2) $\left \langle f,v \right \rangle = 0$, $\forall v \in \mathcal V .$ I want to prove that $2\Rightarrow 1 $, ($1\Rightarrow 2$  is OKEY). I need a reference for learning the proof. I will be very happy if someone could help me to prove it. Thanks!","['functional-analysis', 'real-analysis', 'analysis', 'partial-differential-equations']"
2106045,"Which polygons are ""mediogons"" of simple polygons?","Given a polygon, connect the midpoints of the sides, in order, to create a new polygon. We'll call this the mediogon of the original polygon. There's a theorem that every mediogon of a quadrilateral is a parallelogram. Proof: opposing sides of the mediogon are parallel to a common diagonal of the original quadrilateral. The generalization beyond quadrilaterals is: which n-gons are mediogons of some other n-gon? Using vector algebra, the following are very easy to prove: If n is even, then not all n-gons are mediogons (the class of mediogons can be described in a simple way), but each n-gon that is a mediogon is the mediogon of infinitely many n-gons. If n is odd, then every n-gon is a mediogon of a unique other n-gon. The problem is, every time I said ""n-gon"" above, I'm allowing the possibility that the edges might cross, so it's not a simple n-gon. Which n-gons are mediogons of some simple n-gon? My conjecture is that for even n, since every mediogon is a mediogon of infinitely many polygons, one of those polygons is always simple. For odd n, some subset of n-gons must be mediogons of simple n-gons. The problem is that I don't know any workable characterization of simple polygons. I came up with a rule for when two line segments cross, it's a pair of big cumbersome inequalities involving inner products. I don't think I can apply it to this problem.","['plane-geometry', 'euclidean-geometry', 'geometry']"
2106084,Does $x^{-1}$ have -1 zeroes?,"I asked How $y=x^4+1$ could have 4 zeroes yesterday, and figured it out on my own pretty quickly. I did some more thinking since then, and realized that according to the fundamental theorem of algebra, $0=x^{-1}$ has -1 zeroes (solutions?), because $-1$ is the largest exponent. Wouldn't it have $1$ zeroes though, because $\sqrt[-1]{0} = 0^{\frac{1}{-1}} = 0$? Or does it equal undefined? Or something else? Is there something important I'm missing, or does the question not make sense at all?",['algebra-precalculus']
2106119,Why does the generalised derivative have to be a linear transformation?,I am starting to learn Real Analysis and I have come across the generalised definition of the derivative for higher dimensions. I realise that the derivative being a linear transformation nicely accommodates the one dimensional case where the derivative is just a constant at any point. I also understand it can't be as simple as multiplication by a constant for higher dimensions since you can approach a point along multiple curves in higher dimensions. But where did we hit upon the fact that it has to be linear? Why couldn't it be some other type of function? I would like to get an intuitive explanation.,"['intuition', 'derivatives', 'real-analysis', 'multivariable-calculus', 'motivation']"
2106127,A solution of a given ODE is infinitely differentiable,"I got this problem in a class test: Prove that any solution of the DE $$y''e^x+y'\cos{x}+e^{2x^2}y=0$$ is infinitely differentiable. I solved this as follows but I'm not entirely sure if I'm correct: Let $y_0$ be a solution of the given DE. I need to prove that $y_0^{(n)}$ exists $\forall$ $n\in \mathbb{N}$. I prove this by induction. The statement is true for $n=1,2$ because the order of the DE is $2$. Induction hypothesis: Let the statement be true $\forall$ $n<k$. Now, $y_0''e^x= -y_0'\cos{x} -e^{2x^2}y_0 \Rightarrow y_0'' = F(y_0',y_0,x)$. Differentiating this $k-3$ times, I have $$y_0^{(k-1)}=G(y_0^{(k-2)}, \cdots, y_0', y_0, x)$$
By the induction hypothesis, the right hand side is differentiable, implying that $y_0^{(k)}$ exists. Is my solution correct? If not, how do I solve this problem?",['ordinary-differential-equations']
2106155,Does f(x) is differentiable,"I need to determine whether the following function is differentiable at $x_0 \ne 0$ according to the derivative definition : $$ f(x) = x^\frac{1}{3} $$ So I started by looking at the definition but not sure how to proceed:
$$ f'(x_0) =\lim_{x \to x_0} \frac{x^\frac{1}{3} - x_0^\frac{1}{3}}{x - x_0} $$ Thank you","['derivatives', 'limits-without-lhopital', 'limits']"
2106167,Which ranking system is best for time-based competitions (e.g. Rally car racing),"Let's suppose I have a database of 1000 competitors and 100 events.  Each event has anything from 150 to 300 entrants. The sport (e.g. rally car racing) is a simple against-the-clock event.  Participants set off at regular intervals, and the race is decided by finishing times. I assume there's already established algorithms for ranking competitors under these circumstances.  Where should I be looking? I've read up about Elo and TrueSkill, but it seems both are much more about 1-on-1 competition, or group-on-group, and not many-on-many.  While they could maybe be adapted I'm not quite sure how to go about it, and I'm also unsure if they're suitable at all in this case. I tried adapting Elo to change a competition of many people into hundreds of 1-on-1 matches, but you end up with the problem of a winner ""running away"" with a huge lead.  Maybe with some tweaking of various factors it could work, but I feel I'm probably barking up the wrong tree? Many thanks","['statistics', 'algorithms']"
2106229,Flipping Coins and Advantages,"You and I decide to play a game where we take turns flipping a coin.  The first player to flip 10 heads wins the game.  Naturally, there is an argument about who should go first. Simulations of this game show that the player to flips first wins 2% more than the player who flips second.  I'd like to make this more precise but have run into some problems. This isn't a binomial random variable, as there are no fixed number of trials (flip until someone gets 10 heads).  How can I model this?",['probability']
2106232,How to measure non-linearity of a function?,"Suppose I have an arbitrary FINITE function from $f: \mathbb{R} \rightarrow \mathbb{R}$. What could be the possible ways to measure the non-linearity of this function? By FINITE, I mean $f(x) < \infty, \, \forall x \in \mathbb{R}$ Link to relevant material is highly appreciated. Thanks.","['functional-analysis', 'nonlinear-analysis', 'functions']"
2106284,Does $\sum_{n=2}^{\infty}\frac{n^4}{\log(1)+\log(2)+\log(3)+\cdots+\log(n)}$ converge?,"I can't find a way to test the convergence/divergence of this series: $$ \sum_{n=2}^{\infty}\frac{n^4}{\log(1)+\log(2)+\log(3)+\cdots+\log(n)} $$ I tried the Cauchy method but in order to make the logarithms more manageable I grouped them all (so $\log(1)+\log(2)+\log(3)+...+\log(n)=\log(n!)$. The problem is, I don't know how to differentiate that when I need to. So I'd be grateful for some help if someone can think of a different way or just a way to improve mine (using the Cauchy method somehow so that it works).","['divergent-series', 'sequences-and-series', 'convergence-divergence']"
2106303,Does the reciprocal of a polynomial define a tempered distribution when it is locally integrable?,"Consider a complex polynomial in $n$ variables $z=(z_1,\dots,z_n)$:
\begin{equation}
P(z)=\sum_{|\alpha| \leq N} c_{\alpha} z^{\alpha},
\end{equation}
where as usual for every $\alpha=(\alpha_1,\dots,\alpha_n) \in \mathbb{N}^{n}$ we set $|\alpha|=\alpha_1+\dots+\alpha_n$, and $z^{\alpha}=z_1^{\alpha_1}\dots z_n^{\alpha_n}$. Let $Z= \{ x \in \mathbb{R}^n : P(x) = 0 \}$ and define $H:\mathbb{R}^n \rightarrow \mathbb{C}$ as
\begin{equation}
H(x)= \begin{cases} \frac{1}{P(x)} & \textit{if } x \in \mathbb{R}^n \backslash Z,\\
0 & \textit{if }x \in Z. \end{cases}
\end{equation}
Assume that $H \in L_{loc}^{1}(\mathbb{R}^n)$. Is it then true that $H$ defines a tempered distribution? More explicitly, if we set
\begin{equation}
T(\phi)=\int_{\mathbb{R}^n} H(x) \phi(x) dx, \quad (\phi \in \mathscr{D}(\mathbb{R}^n)),
\end{equation}
does $T$ extends to a continuous linear functional on $\mathscr{S}(\mathbb{R}^n)$? I guess the answer is positive, but I have no idea of a possible proof. NOTE (1). Let $x \in \mathbb{R}^n$, and let $Q(x)$ and $R(x)$ be respectvely the real and imaginary part of $P(x)$. $Z$ is the intersection of the zero sets of the two real polynomials $Q(x)$ and $R(x)$. Since the zero set of a non null real polynomial has zero Lebesgue measure (for a very simple proof see Daniel Fischer's answer in Zero Set of a Polynomial ), we conclude that $Z$ has zero Lebesgue measure, and for our question is totally irrelevant how we define $H$ on $Z$. NOTE (2). Let us note that $H$ can be locally integrable even if $Z$ is not empty when $n \geq 2$. Take e.g. for $n=2$ the polynomial $P(z_1,z_2)=z_1+ i z_2$, or for $n=3$ consider $P(z_1,z_2,z_3)=z_1^{2}+z_2^{2}+z_3^{2}$ or even $P(z_1,z_2,z_3)=z_1+ i z_2$. NOTE (3). If $Z= \emptyset$, then clearly $H \in L_{loc}^{1}(\mathbb{R}^n)$. In this case $H$ defines a tempered distribution. Indeed, by a remarkable result of Hörmander (see Lemma (2) in On the Division of Distributions by Polynomials ) there exist $C > 0$ and $\mu > 0$ such that
\begin{equation}
|P(x)| \geq C (1+|x|^2)^{-\mu} \quad \forall x \in \mathbb{R}^n.
\end{equation}
So for $M > 0$ big enough we have in this case
\begin{equation}
\int_{\mathbb{R}^n} (1+|x|^2)^{-M} |H(x)| dx < \infty,
\end{equation}
and we conclude that $H$ defines a temepered distribution. When $Z \neq \emptyset$, then Hörmander proves that there exists positive constants $C, \mu, \nu$ such that
\begin{equation}
|P(x)| \geq C (1+|x|^2)^{-\mu} [d(x,Z)]^{\nu} \quad \forall x \in \mathbb{R}^n,
\end{equation}
where 
\begin{equation}
d(x,Z)=\inf_{y \in Z} |x - y| \quad (x \in \mathbb{R}^n).
\end{equation}
I don't know if this remarkable inequality together with the assumption that $H \in L_{loc}^{1}(\mathbb{R}^n)$ implies that $H$ defines a tempered distribution.","['real-analysis', 'distribution-theory', 'polynomials']"
2106316,"Proof, that $d(x_n,y_n)$ converges to $d(x,y)$(proof explanation)","In a metric space $(S,d)$, assume that $x_n\,\to\,x$ and $y_n\,\to\,y$. Prove that $d\left(x_n,y_n\right)\,\to\,d(x,y)$. $\textbf{Proof:}$ Since $x_n\,\to\,x$ and $y_n\,\to\,y$, given $\epsilon>0$ there exists a positive integer $N$ such that as $n\ge N$, we have
\begin{equation}
d\left(x_n,x\right)<\epsilon/2 \text{ and }d\left(y_n,y\right)<\epsilon/2
\end{equation} Hence, as $n\ge N$, we have \begin{eqnarray}
\left\lvert\,d\left(x_n,y_n\right)-d\left(x,y\right)\,\right\rvert&\le&\left\lvert\,d\left(x_n,x\right)+d\left(y_n,y\right)\,\right\rvert\\
&=&d\left(x_n,x\right)+d\left(y_n,y\right)\\
&<&\epsilon/2+\epsilon/2\\
&=&\epsilon
\end{eqnarray}
I cannot understand why this is true:
\begin{equation}
\left\lvert\,d\left(x_n,y_n\right)-d\left(x,y\right)\,\right\rvert\le\left\lvert\,d\left(x_n,x\right)+d\left(y_n,y\right)\,\right\rvert
\end{equation} Can you please explain me that?","['sequences-and-series', 'convergence-divergence', 'proof-explanation']"
2106325,Integrating $\int \frac{\cos x}{\sin x+\cos x}dx$.,so I've just had my first exam (went pretty well) but I ran into this thing as the first part of the last question. $$\int \frac{\cos x}{\sin x+\cos x}dx$$ I had a look on wolfram after the exam and it advised to multiply top and bottom by $\sec^3x$. Is there another way to tackle this if you didn't know that trick? I find it hard to believe I was meant to know this and it was disproportionately harder than any type of integration question I've come across when practicing. I couldn't get anywhere when trying to solve this. Thanks.,['integration']
2106372,Inverse trigonometry integration,The magnitude of ans is correct but the sign is negative. Which is incorrect. But the procedure seem to be correct.,"['definite-integrals', 'trigonometry', 'inverse-function']"
2106376,Bisectors of a triangle meet at point.,"Prove that internal angle bisectors of  $\triangle ABC$ meet at a point. The problem is that I have to prove this using the locus of a straight line and its properties, I can't use vectors. The proof I can think of is very simple but extremely tedious. Let the coordinate of triangle be $(0,0), (a,0), (x_0,y_0)$ Let side connecting $(0,0)\ \& \ (a, 0)$ be C, $(0,0) \ \& \ (x_0, y_0)$ be A and $(x_0,y_0) \ \& \ (a, 0)$ be B. Then the equation to sides are, $$C : y = 0 \  ;  \ B : y(a - x_0) + xy_0 - ay_0 = 0\  ;  \ A: xy_0 - yx_0 = 0$$ The general form of angle bisectors between two angles is 
$${Ax + By + C\over \sqrt{A^2 + B^2}} = \pm {A_0x + B_0y + C_0\over \sqrt{A_0^2 + B_0^2}}  $$ Using this equation, and some very tedious math I got, $$ \operatorname{bisector(AC)} : y\left(\sqrt{x_0^2 + y_0^2} + x_0\right) -xy_0 = 0 \ ; \ \\ \operatorname{bisector(BC)} : y\left(\sqrt{(a -x-0)}- (a-x_0)\right)- xy_0+ay_0 = 0 \ ; \ \\ \operatorname{bisector(AC)} : x\left(\left(\sqrt{(a -x-0)}- (a-x_0)\right)y_0 - \sqrt{y_0^2 + x_0^2}y_0\right) - y\left(x_0\left(\sqrt{(a -x-0)}- (a-x_0)\right) + \sqrt{y_0^2 + x_0^2}(a-x_0)\right) +  \sqrt{y_0^2 + x_0^2}ay_0 = 0$$ Now I just need to prove that these three lines are concurrent, for which I to prove that the determinant of the coefficient of these three lines equal $0$ . I tried that but it does not come to zero, I probably lost somewhere in find the equations. There has to be some other way of doing this, either by using some clever method of calculating the bisectors or by choosing the coordinates of  the triangle such that we don't get such horrific equations. Any help is appreciated. Edit Though the answers by @Joffran and @Mark is what I needed, I want to see if somebody can prove this by the method I described.","['analytic-geometry', 'triangles', 'geometry']"
2106432,Why is $\int_0^\pi \sin(x)dx = 2$?,"I was exploring integrals, and I found something interesting that I couldn't prove. $$\int_0^\pi \sin(x)dx = 2$$ If you have ever seen the $\sin(x)$ or $\cos(x)$ function, you would notice it is wavy and makes ""bumps"" alternating positive and negative. Well, it turns out that the area of each of those ""bumps"" is equal to 2. Here is a visualization: The reason this stood out to me was because I didn't expect it to be 2. I expected some crazy random number, but I got 2! I'm assuming there some sort of rule in trigonometry that can explain this. Can anyone help?","['integration', 'trigonometry', 'area']"
2106470,Help for series calculation $\sum_{n\ge1} \frac{1}{4n^3-n}$,"I want to find the following series. $$\sum_{n\ge1} \frac{1}{4n^3-n}$$ So, fisrt of all, patial fraction : $$\frac{1}{4n^3-n}=\frac{1}{2n+1}+\frac{1}{2n-1}-\frac{1}{n}.$$ Next, I consider the geometric series $$\sum_{n\ge1} x^{2n-2}+x^{2n}-x^{n-1}=\frac{1}{1-x^2}+\frac{x^2}{1-x^2}-\frac{1}{1-x}\tag{1}$$ where ${-1\lt x\lt1}$. Then, I integrate both side of (1) from $0$ to $1$: $$\sum_{n\ge1}\frac{1}{2n-1}+\frac{1}{2n+1}-\frac{1}{n}=\int_0^1 \frac{x^2-x}{1-x^2}dx$$ Finally, I get the value that is equal to $ln(2)-1$  by improper integral but it's less than $0$. What did I do wrong? All help is appreciated.","['real-analysis', 'sequences-and-series', 'calculus']"
2106474,Asymptotic expansion of $I_n=\int_{0}^{1}\frac{1}{1+x^n} dx$,"The problem is to find the asymptotic expansion of $I_n=\int_{0}^{1}\frac{1}{1+x^n} dx$ (at least the first 3 terms). By using some simple bounding, I first showed that $I_n$ tends to $1$. Then I calculated the limit $n(1-I_n)$ using integration by parts and some more bounding. At the end I found: $I_n=1-\frac{\ln(2)}{n}+o(\frac{1}{n})$ I guess there is another way to find this result by invoking the expansion of $\frac{1}{1+x^n}$. This is more annoying, because you have to justify that you can switch the integral inside and the infinite sum, and at the end you will get the following sum $I_n\stackrel{?}{=}\sum_{k=0}^{\infty}\frac{(-1)^{k}}{kn+1}=1-\frac{1}{n}\sum_{k=1}^{\infty}\frac{(-1)^{k+1}}{k+\frac{1}{n}}$ In this case, one has to justify that the little $\frac{1}{n}$ doesn't create any problems and that we have in fact: $\lim_{n \to \infty} \sum_{k=1}^{\infty}\frac{(-1)^{k+1}}{k+\frac{1}{n}}\stackrel{?}{=}\sum_{k=1}^{\infty}\frac{(-1)^{k+1}}{k}=\ln(2)$ So my question is if the second approach can be made rigorous, and how can we find the third term in the asymptotic expansion of $I_n$? Also, is there a standard method to solve these types of problems?","['real-analysis', 'integration', 'asymptotics']"
2106488,Help Understanding Piecewise Defined Laplace Transformations,"I understand that I need to convert to Heaviside functions and I think I'm doing that correctly, however my answer is not what it's supposed to be. Below is one of the problems I am working on, with my workings and interpretation of what the  graph should look like. Could someone please explain how I am meant to get my answer to look like that.","['ordinary-differential-equations', 'laplace-transform']"
2106558,"Infinitely many rational triples $(a,b,c)$ such that $a + b + c = abc = 6$","Show that there are infinitely many rational triples $(a,b,c)$ such that $$a + b + c = abc = 6.$$ I first thought about proving that if a triangle $ABC$ has rational side lengths and rational area, then $\tan{\frac{A}{2}},\tan{\frac{B}{2}},\tan{\frac{C}{2}}$ are all rational. Thus, using the identity $\tan{2x} = \dfrac{2\tan{x}}{1-\tan^2{x}}$, we see that $\tan{A},\tan{B},\tan{C}$ are all rational. Thus since $$\tan{A}+\tan{B}+\tan{C} = \tan{A}\tan{B}\tan{C},$$ we just need $\tan{A}\tan{B}\tan{C} = 6$. How can we satisfy this or does this approach not work?",['number-theory']
2106565,"Is every irrational number containing only $2$ distinct digits, transcendental?","If we have an irrational number, consisting of only $2$ distinct digits, for example: $$0.01011011101111011111 \cdots$$ Can we conclude that the number is transcendental? It is conjectured that every irrational algebraic number is normal in base $10$ . This would imply that the answer to my question is yes. But can we prove it?","['number-theory', 'decimal-expansion', 'transcendental-numbers', 'irrational-numbers']"
2106616,Supermartingale variance bound?,"Suppose I have a supermartingale $$
\mathbb{E}[X_{n+1} \mid X_n,  \dots , X_2, X_1] \leq X_n
$$ There are 2 other conditions: bounded difference: $|X_{n+1} - X_n| \leq A$ with probability $1$ (almost surely) for all $n$, where $A$ is a constant all $X_n$ are lower bounded: $X_n \geq B$ with probability $1$ (almost surely) for all $n$, where $B$ is a constant My question is, is there a way to bound the variance $\mathrm{Var}[X_n]$ for all $n$? Ideally the bound on the variance $\mathrm{Var}[X_n]$ should $\to 0$ as $n \to \infty$ and $A \to 0$. So are there other (possibly known) conditions that are needed?","['reference-request', 'probability-theory', 'variance', 'probability', 'martingales']"
2106622,Independence of 3 random vectors,"I have the following question and could not find an answer in any other thread: Let $A$, $B$ and $C$ be random vectors and let it be given, that: $A$ is independent of $B$ $(A, B)$ is independent of $C$ How can I show, that this implies $A$ independent of $C$ ? It seems intuitive, but I am looking for a formal proof. I know, that from (1.) and (2.) follows, that: $f_{ABC}(a,b,c) = f_{ABC}((a,b),c) = f_{AB}(a,b)\cdot f_{C}(c) = f_{A}(a)\cdot f_{B}(b)\cdot f_{C}(c)$ With $a, b, c$ being observations of $A, B, C$ respectively. Does this help at all? I guess, I want to get an equation like this: $f_{AC}(a,c) = f_A(a) \cdot f_C(c)$ Any help/resource reference is greatly appreciated!","['independence', 'probability-theory', 'statistics', 'probability', 'random-variables']"
2106633,Asymptotic value of a sequence,"Assume a real sequence $1=a_1\leq a_2\le \cdots \leq a_n$, and $a_{i+1}-a_i\leq \sqrt{a_i}$. Does this hold:
$$\sum_{i=1}^{n-1} \frac{a_{i+1}-a_i}{a_i} \in O(\log n)$$","['asymptotics', 'sequences-and-series', 'discrete-mathematics']"
2106677,Why is $\sum_{n\ge1} \binom{s}{n}\left(1 - \zeta(n-s)\right)=2^s$ for all $s \in \mathbb{C}$?,"Probably an easy question, but I found the following identity that seems true for all $s \in \mathbb{C}$: $$\sum_{n=1}^{\infty} \binom{s}{n}\big(1 - \zeta(n-s)\big)=2^s$$ Why is this the case? Do similar identities exist for $3^s,4^s,...$? Additional observation: For $s \in \mathbb{N}$, only a finite sum up to $s+1$ is required to get the exact power, i.e.: $$\sum_{n=1}^{s+1} \binom{s}{n}\big(1 - \zeta(n-s)\big)=2^s$$ and also: $$\sum_{n=1}^{s+1} \binom{s}{n}\big(1+\frac{1}{2^{n-s}} - \zeta(n-s)\big)=3^s$$ etc. This trick doesn't seem to work for negative integers or non-integer values of $s$.","['number-theory', 'riemann-zeta', 'binomial-coefficients', 'sequences-and-series']"
2106689,Different ways to come up with $1+2+3+\cdots +n=\frac{n(n+1)}{2}$,"I am trying to compile a list of the different ways to come up with the closed form for the sum in the title. So far I have the famous Gauss story, the argument by counting doubletons, and using generating functions. Is there any other (significantly) different way to discover the closed form? To clarify, Gauss's method was to take $1+2+3+\dots+n$, write it backwards, and add it up.","['telescopic-series', 'summation', 'integration', 'education']"
2106768,Why there exist prime homogeneous ideals containing the Irrelevant ideal?,"The notion of irrelevant ideal is something the doesn't bother me long time now, though the last day I came across it again and realised something that didn't now. That simply I don't understand how the whole $\textbf{Proj}$ construction works. So my question is: In Wiki article about $Proj$ sonstruction says: ""Define the set $Proj(S)$ to be the set of all homogeneous prime ideals that do not contain the irrelevant ideal"". Now since the irrelevant ideal is a maximal ideal (in the usual sense regardless of the grading part/structure), how is possible for a homogeneous prime ideal to contain the irrelevant ideal? Apparently I'm missing something, so can you please help me out and make more clear how does the $Proj$ construction works? Thank you!","['projective-space', 'algebraic-geometry', 'projective-schemes']"
2106787,Are all stopped Brownian motions integrable?,"Let $(W_t)_{t\in[0,\infty)}$ be a standard Brownian motion and let $\tau$ be a stopping time that is finite almost everywhere, but otherwise arbitrary—it need not be a hitting time, in particular. I am wondering whether the random variable $\omega\mapsto W_{\tau(\omega)}({\omega})$ is integrable for all such stopping times or whether a counterexample can be constructed. Intuitively, the expected value of $|W_t(\omega)|$ for a fixed $t\geq0$ is proportional to $\sqrt{t}$, which tends to make it less likely that $\omega\mapsto W_{\tau(\omega)}({\omega})$ is integrable if one can make $\tau$ take on large values with sufficiently high probabilities. On the other hand, the probability of $\tau$ being “large enough” is small (given that $\tau$ is finite almost everywhere), which tends to favor integrability. I cannot see whether a counterexample can be constructed making the first of these two effects “win” against the second, yielding $$\int_{\omega\in\Omega}|W_{\tau(\omega)}(\omega)|\,\mathrm d\mathbb P(\omega)=+\infty.$$ Any hints and comments would be much appreciated.","['stochastic-processes', 'probability-theory', 'brownian-motion', 'stopping-times']"
2106796,What is the boundary of two manifolds with boundary?,"I know that if $M$ is a manifold without boundary and $N$ a manifold with boudary, then $\partial(M\times N)=M\times \partial N$, but, if I have the product of two manifolds with boudary, it's known what would be the boundary of that? I suppose it could be $\partial{M}\times \partial{N}$, but when I think in $I\times I$ $\left(I=[0,1]\right)$, the corners doesn't look as something differentiable.","['differential-geometry', 'manifolds-with-boundary']"
2106866,What is the point of a $1\times 1$ matrix?,"Surely a $1\times 1$ matrix can only 'produce' vectors with 1 entry, and can take as input also only one entry vectors. So, is there any use for $1\times 1$ matrices? Since to me they do the same like scalars, only worse.","['matrices', 'linear-algebra']"
2106879,"In the context of curl, what does the difference between two partial derivatives tell me about rotation in a plane?","Let $\mathbf{A}(x,y,z)$ be a vector field. The curl of this vector field is defined as $$\nabla \times \mathbf{A} = \left(\frac{\partial A_z}{\partial y} - \frac{\partial A_y}{\partial z}\right) \mathbf{i} + \left(\frac{\partial A_x}{\partial z} - \frac{\partial A_z}{\partial x}\right) \mathbf{j} + \left(\frac{\partial A_y}{\partial x} - \frac{\partial A_x}{\partial y}\right) \mathbf{k}$$ Let's consider a simple example from Wikipedia. $$\mathbf{A}(x,y,z) = y\mathbf{\hat{x}}-x\mathbf{\hat{y}}+0\mathbf{\hat{z}}$$ This corresponds to the following source: https://commons.wikimedia.org/wiki/File:Uniform_curl.svg The curl is $$\nabla \times \mathbf{A} =0\boldsymbol{\hat{x}}+0\mathbf{\hat{y}}+ \left({\frac{\partial}{\partial x}}(-x) -{\frac{\partial}{\partial y}} y\right)\mathbf{\hat{z}}=-2\mathbf{\hat{z}}$$ But there is where I am confused. I don't get what $\left({\frac{\partial}{\partial x}}(-x) -{\frac{\partial}{\partial y}} y\right)$ has to do with the rotation and size of the vectors in the picture shown above. My Question How do these derivatives tell me anything about the rotation? Any why must they be opposites? Why is it not $\frac{\partial A_x}{\partial x}$ ? I understand of course why, when you compute the cross product, it comes out that way, but I want to understand the intuition of why that is important for rotation.","['multivariable-calculus', 'vector-analysis']"
2106883,Graph-Third Quartle,"Find the third quartile class and frequency of the class from the given graph. How many students are there above the class? My attempt :
Here, $N=120$.
Third quartile lies in $\frac {3N}{4}$item.
$$=90 item$$
So, $Q_3 class = 20-30$. but I couldn't do that second part of the question. Please help. Thanks","['statistics', 'graphing-functions']"
2106886,Proof by strong induction question,"To do a proof by strong induction, we follow 3 steps: Statement : Begin with a precise statement of the formula to be proven. The Basis Case : State the number $k$ where you're starting your induction, and the formula $f(k)$ to be proven, and then prove it. The Induction Case : State the inductive hypothesis $f(n)$, and the formula $f(n+1)$ to be proven. Prove the result, clearly indicating when the inductive hypothesis is used. We have to give a proof for the following theorem: 2) Formalize the theorem: 
$$\sum_{i=1}^{n}i^k = \frac{1}{k+1}\cdot n^{k+1}$$
by proving by induction $\nabla n^{(k)}=kn^{(k−1)}$ for all natural numbers $k\geq 1$. It may help to first prove the product rule for differentiation: 
$$\nabla f(n)\cdot g(n)=f(n)\nabla g(n)+g(n−1)\nabla f(n) .$$","['induction', 'discrete-mathematics']"
2106896,Abelian group (Commutative group) [duplicate],"This question already has an answer here : Show that $\forall x,y\in G$, $(xy)^2=x^2y^2\iff G $ is an abelian group. (1 answer) Closed 5 years ago . Prove that if in a group $(ab)^2= a^2 b^2$ then the group is commutative. I am having a hard time doing this. Here is what I have so far: Proof: $a^2 b^2= a^1 a^1 b^1 b^1$ =$aa^{-1}bb$ =ebb Hence,$aa^{-1}=e$ I am stuck, I do not know if this is the right process in proving this",['abstract-algebra']
2106904,Projection of a function onto another,"In a metric space, I can imagine projection of a vector onto another (also called dot product). Or in general any vectors of form $[v_1,v_2,v_3,\cdots]$ I know how to compute their projection onto one another. But for continuous vectors, like when using functions as a vectors, I can't imagine what does dot-product (or inner product) or projection quite means. Can anyone help me with this?","['projective-geometry', 'functions', 'inner-products', 'vectors', 'vector-spaces']"
2106937,Evaluation of $\int\frac{1}{x+ \sqrt{x^2-x+1}}dx$,"Evaluate : $$\int\frac{1}{x+ \sqrt{x^2-x+1}}dx$$ After multiplying the denominator with $x-\sqrt{x^2-x+1}$ , I get $$x+\ln |x-1|-\int \frac{\sqrt{x^2-x+1}}{x-1}dx$$ Is $\int \frac{\sqrt{x^2-x+1}}{x-1}dx$ is integrable in terms of elementary functions?","['indefinite-integrals', 'integration', 'calculus']"
2106939,Intuition behind lack of cycles in the Collatz Conjecture,"The Collatz Conjecture concerns the function $f(n) = \begin{cases}
n/2,  & \text{if $n$ is even} \\
3n+1, & \text{if $n$ is odd}
\end{cases}$
. The conjecture says that if you start with any natural number and repeatedly apply the function, you will eventually end up at 1, after which you will cycle forever between 1, 4, and 2. To prove the conjecture, one would need to prove that No sequence generated in this fashion grows without bound. No sequence generated in this fashion falls into a cycle other than the aforementioned 1, 4, 2 cycle. The first of these requirements seems very likely to be true, but I don't see why the second holds up so well (computers have verified an absence of other cycles for mindbogglingly large starting numbers). It seems to me that if you're bouncing around the integers in a relatively random pattern, every now and then you should end up back where you started. Is there an intuitive explanation for why cycles are so rare?","['number-theory', 'collatz-conjecture']"
2106953,How to evaluate the integral $\int_0^{2\pi} \theta\exp(x\cos(\theta) + y\sin(\theta))) d\theta$,"I found five other related integrals whose proofs I am studying now A , B , C , D , and E $$\int^{2\pi}_0e^{\cos \theta}\cos(a\theta -\sin \theta)\,d \theta = \frac{2\pi}{a!}$$
$$\int_0^{2\pi} \exp(\cos(\theta)) \cos(\theta + \sin(\theta)) = 0$$
$$ \int_0^{2\pi} \exp(\alpha \cos(\theta))\cos(\sin(\theta)) = 2\pi I_0(\sqrt{1 - \alpha^2})$$
$$\int_0^{2\pi} \exp(x\cos(\theta) + y\sin(\theta))) = 2\pi I_0(\sqrt{x^2 + y^2})$$ 
$$ \int_0^\dfrac{\pi}{2}\beta^\alpha\exp\left(-\beta\cos(\theta)\right)d\theta = \dfrac{1}{2}\beta^\alpha\pi\left(J_0(\beta)-L_0(\beta)\right)$$ I was also able to find a very general statement in Gradshteyn as entry number 3.338. 
$$\int_{-\pi}^{\pi} \frac{\exp{\frac{a + b\sin x + c \cos x}{1 + p \sin x + q \cos x}}}{1 + p \sin x + q \cos x} dx = \frac{2\pi e^{-\alpha}I_0(\beta)}{\sqrt{1 - p^2 - q^2}}$$ $$\textrm{where } \alpha = \frac{bp + cq -a}{1 - p^2 - q^2},\; \beta = \sqrt{\alpha^2 - \frac{a^2 - b^2 - c^2}{1 - p^2 - q^2}}$$ But the simplest approach of using integration by parts to reduce my problem to one of these does not work. Background Here's some background into why I am interested in this integral, let $v = [x, y] \in \mathbb{R}^2$ and $r = [\cos(\theta), \sin(\theta)] \in \mathbb{R}^2$, Consider the value of $$\underset{\theta \tilde{} \textrm{Hill}}{E}[\exp(v^Tr)]$$ This is the expected value of exponential of the projection of a random vector chosen using the Hill distribution, where the ""Hill"" is an unnormalized distribution that linearly increases from $0$ at $-\pi$ to $1$ at $0$ and then decreases linearly from $0 \textrm{ to } \pi$. Discarding normalizing factor of Hill, This expectation will become: $$ \int_{-\pi}^{0} (\theta + \pi)\exp(x\cos\theta + y\sin\theta) d\theta + \int_{0}^{\pi} (\pi - \theta) \exp(x\cos\theta + y\sin\theta) d\theta $$ Now, there are simplifying unnormalized distributions I could assume in my model, instead of Hill, such as Uniform from 0 to $2\pi$, or $\exp(\cos(\theta))$ both of these distribution allow analytical calculation of the above expectation just based on the identities written below, but I want to know which distributions I can compute this expectation for (Can I do this for Hill?) I will guess that I can only do it for distributions that have some finite decomposition in terms of spherical harmonics. Unfortunately, my knowledge is lacking in complex analysis and spherical harmonics so I can't quickly assess my options.","['special-functions', 'integration', 'definite-integrals', 'calculus']"
2107016,Interesting closed form for $\int_0^{\frac{\pi}{2}}\frac{1}{\left(\frac{1}{3}+\sin^2{\theta}\right)^{\frac{1}{3}}}\;d\theta$,"Some time ago I used a formal approach to derive the following identity: $$\int_0^{\frac{\pi}{2}}\frac{1}{\left(\frac{1}{3}+\sin^2{\theta}\right)^{\frac{1}{3}}}\;d\theta=\frac{3^{\frac{1}{12}}\pi\sqrt{2}}{AGM(1+\sqrt{3},\sqrt{8})}\tag{1}$$ where $AGM$ is the arithmetic-geometric mean . Wolfram Alpha does not tell me whether this is correct, but it does appear to be accurate to many decimal places. I have three questions: Can anyone verify whether $(1)$ is in fact correct? Is there a way of generalizing $(1)$ to integrals of the form $\int_0^{\frac{\pi}{2}}\left(a+\sin^2{\theta}\right)^{-\frac{1}{3}}\;d\theta$ or is this integral more special? My derivation (see below) appears to only work for $a=\frac{1}{3}$. There is a superficial similarity between $(1)$ and elliptic integrals (e.g. the $AGM$ evaluation ); is there a way to transform this integral into an elliptic integral that I have missed, or is it merely a coincidence that an integral of this form is the reciprocal of an $AGM$? Derivation : I have put this here in case it helps to see where I am coming from; I apologize for its length. I began by using a multiple integration trick of squaring the integral and converting to polar coordinates to evaluate $\int_0^\infty e^{-x^6}dx=\frac{1}{6}\Gamma(\frac{1}{6})$ as follows: $$\left[\int_0^\infty e^{-x^6}\;dx\right]^2=\int_0^\infty\int_0^{\frac{\pi}{2}}re^{-r^6(\cos^6\theta\;+\;\sin^6\theta)}\;d\theta\;dx={\int_0^\infty re^{-r^6}\int_0^{\frac{\pi}{2}}e^{3r^6\cos^2\theta\sin^2\theta}\;d\theta\;dx}$$ $$=\int_0^\infty re^{-r^6}\int_0^{\frac{\pi}{2}}e^{\frac{3r^6}{4}\sin^22\theta}\;d\theta\;dx={\int_0^\infty re^{-r^6}\int_0^{\frac{\pi}{2}}e^{\frac{3r^6}{4}\cos^2\theta}\;d\theta\;dx}$$ I then made use of the following formula (see here ): $$\sum_{n=0}^{\infty}\frac{(2n)!}{(n!)^3}x^n=\frac{2}{\pi}\int_0^{\frac{\pi}{2}}e^{4x\cos^2\theta}\;d\theta\tag{2}$$ Using $(2)$ and formally interchanging integration and summation we get: $$\frac{\Gamma(\frac{1}{6})^2}{36}=\int_0^\infty re^{-r^6}\int_0^{\frac{\pi}{2}}e^{4\left(\frac{3r^6}{16}\right)\cos^2\theta}\;d\theta\;dx=\frac{\pi}{2}\int_0^\infty re^{-r^6}\sum_{n=0}^{\infty}\frac{(2n)!}{(n!)^3}\left(\frac{3r^6}{16}\right)^n\;dx$$ $$=\frac{\pi}{2}\sum_{n=0}^{\infty}\frac{(2n)!}{(n!)^3}\left(\frac{3}{16}\right)^n \int_0^\infty r^{6n+1}e^{-r^6}\;dx=\frac{\pi}{12}\sum_{n=0}^{\infty}\frac{(2n)!}{(n!)^3}\left(\frac{3}{16}\right)^n \Gamma\left(n+\frac{1}{3}\right)$$ I then used Laplace transform identities and $(2)$, freely interchanging integrals and sums, to write: $$\sum_{n=0}^{\infty}\frac{(2n)!}{(n!)^3}\frac{\Gamma\left(n+\frac{1}{3}\right)}{s^{n+\frac{1}{3}}}=L\left[\sum_{n=0}^\infty \frac{(2n)!}{(n!)^3}t^{n-\frac{2}{3}}\right](s)={\frac{2}{\pi}L\left[t^{-\frac{2}{3}}\int_0^\frac{\pi}{2}e^{4t\cos^2\theta}\;d\theta\right](s)}={\frac{2}{\pi}\int_0^\frac{\pi}{2}L\left[t^{-\frac{2}{3}}e^{4t\cos^2\theta}\right](s)\;d\theta}={\frac{2}{\pi}\int_0^\frac{\pi}{2}\frac{\Gamma(\frac{1}{3})}{(s-4\cos^2\theta)^{\frac{1}{3}}}\;d\theta}$$ Accordingly, since $\frac{4}{3}-\cos^2\theta=\frac{1}{3}+\sin^2{\theta}$ we can deduce that: $$\frac{\Gamma(\frac{1}{6})^2}{36}=\frac{\Gamma(\frac{1}{3})}{6}\left(\frac{4}{3}\right)^\frac{1}{3}\int_0^\frac{\pi}{2}\frac{1}{(\frac{1}{3}+\sin^2\theta)^{\frac{1}{3}}}\;d\theta$$ Reflection and duplication give $\Gamma(\frac{1}{6})=2^{-\frac{1}{3}}\sqrt{\frac{3}{\pi}}\Gamma(\frac{1}{3})^2$ and hence we have the following identity: $$\int_0^{\frac{\pi}{2}}\frac{1}{\left(\frac{1}{3}+\sin^2{\theta}\right)^{\frac{1}{3}}}\;d\theta=\frac{3^\frac{1}{3}\Gamma(\frac{1}{3})^3}{2^\frac{7}{3}\pi}\tag{3}$$ while $(1)$ may be obtained by using the following identity (see here ): $$\Gamma\left(\frac{1}{6}\right)=\frac{2^\frac{14}{9}3^\frac{1}{3}\pi^\frac{5}{6}}{AGM(1+\sqrt{3},\sqrt{8})^\frac{2}{3}}$$ This completes the derivation; I cannot see how a method like this (especially with the conversion to polar coordinates) could be used to give results more general than $(1)$ and $(3)$.","['calculus', 'closed-form', 'definite-integrals', 'elliptic-integrals', 'gamma-function']"
2107048,Find a minimum of $x^2+y^2$ under the condition $x^3+3xy+y^3=1$,"As in the title, I've tried to find a maximum and mininum of $x^2+y^2$ when $x^3+3xy+y^3=1$ holds. It is not too hard to show that $x^2+y^2$ has no maximum, but I can't find a minimum.
Lagrange multiplier gives a dirty calculation so I can't handle it. Is there any elegant way to find it? Thanks for any help. p.s. Sorry. I make a typo in the $xy$-coefficient.","['maxima-minima', 'calculus']"
2107054,Finite morphism of varieties - morphism of sheaves,"Let $f:X\rightarrow Y$ be a finite morphism of non-singular projective varieties of degree $d$. Consider the map of sheaves $O_Y\rightarrow f_*O_X$. Is this morphism injective? Why? $f_*O_X$ is a rank $d$ vector bundle. Suppose the above morphism of sheaves is injective. Consider the exact sequence where $L$ is the cokernel:
$$0\rightarrow O_Y\rightarrow f_*O_X\rightarrow L\rightarrow 0.$$
Does this exact sequence split and give us $ f_*O_X=O_Y\oplus L$? Suppose $f$ is of degree 2 and $X$ and $Y$ are non-singular surfaces. Let $C\subset Y$ be a non-singular curve along which $f$ is branched. Then is there is some relation between $L$ (as above ) and $O_Y(C)$?",['algebraic-geometry']
2107123,What is the definition of the slope of a degenerate line segment in simple terms?,"I have a (computer science) homework assignment which has this snippet: Treat the slope of a horizontal line segment as positive zero; treat the slope of a vertical line segment as positive infinity; treat the slope of a degenerate line segment (between a point and itself) as negative infinity. I don't know what is a degenerate line segment, and what is the slope of that. I googled that but got very limited useful results. Can someone explains to me what it is in simple terms?",['trigonometry']
2107176,A contractor had to finish a work in,"A contractor had to finish a work in $40$ days and he employed some men to do the work. They finished one-fifth of the work in $20$ days. When $80$ more men were added,  the work was finished on the specified time. How many men were employed in the beginning? My Attempt, Where did I made the error. The answer in my book is $80$ men..",['algebra-precalculus']
2107206,Prove that two angles are equal,"$M$ is the midpoint of $BC$ in the triangle $\Delta ABC$. $D$ lies on $AC$, and $AD = BD$. $E$ lies on the line $AM$, $DE$ is parallel to $AB$. How can I prove that the angles $D\hat{B}E$ and $A\hat{C}B$ are equal?","['angle', 'triangles', 'geometry']"
2107214,Show that axiom of replacement implies from the Axiom of Specification [Proof Verification],"Axiom $3.6$ (Replacement). Let $A$ be a set. For any object $x \in  A$ and any
  object $y$, suppose we have a statement $P(x, y)$ pertaining to $x$ and $y$,
  such that for each $x\in A$ there is at most  one $y$ for which $P(x,y)$ is
  true. Then there exists a set $\{y: P(x, y) \text{ is true for some } x \in A\}$ 
  such that for апy object $z$,  $$ z\in \{y : P(x, y)\text{ is true for some } x \in A\}  \iff  P(x,z)\text{ is true for some } x \in A.$$ Axiom $3.5$ (Specification). Let $A$ be a set, and for each  x$\in$  $A$, let $P(x)$ be a property pertaining to $x$ (i.e., $P(x)$ is either  a
  true statement or a false statement). Then there exists a set,  called
  $\{x \in A : P(x) \text{ is true}\}$ (or simply $\{x \in A : P(x) \text{ for short}\}$),  whose elements are precisely the elements $x$ in $A$ for which $P(x)$  is true. In other words, for any object $y$,  $$у \in \{x \in A: P(x)\text{ is true}\} \iff (y \in A \text{ and } P(y)\text{ is true}).$$ I have to show that $3.6\implies 3.5.$ Proof: By $(3.6)$ we can assume the following set $$\{x:P(x,x)\text{ is true for some }x\in A\}.$$ Let $Q(x)=P(x,x)$ then we get the set $$\{x\in A:Q(x) \text{ is true for some }x\},$$
which is what $(3.5)$ wants. Is this proof correct? PS. I have read other answers to this question on MSE, but none of them use this formulation of the axiom and I guess use more formal notation. I am learning from Tao's Analysis book and so I've not been introduced to such notation.","['elementary-set-theory', 'proof-verification']"
2107233,When are u and 1-u never both units?,"I was trying to generalize a solution to a problem (if $P\in \mathbb Z[x], n\in\mathbb Z,$ then $P(P(P(n)))\neq n$ unless $P(n)=n$), and I found a sufficient condition to replace $\mathbb Z$ with a domain $R$: $u$ and $1-u$ are never simultaneously units. Equivalently, $u(1-u)$ is never a unit in $R$ for $u\in R$. Unfortunately, the only examples I can find of rings with this property are the integers and the Gaussian integers. Are there other rings with this property, or perhaps a more general condition that implies this property? What if we restrict ourselves to rings of integers of number fields?","['number-theory', 'abstract-algebra', 'ring-theory']"
2107253,Evaluate $\lim _{x\to \infty }\left(\cos\sqrt{x}-\cos\sqrt{x-1}\right)$,How should I determine the following limit? $\lim _{x\to \infty }\left(\cos\sqrt{x}-\cos\sqrt{x-1}\right)$,"['radicals', 'limits', 'trigonometry', 'calculus', 'limits-without-lhopital']"
2107271,Find the determinant of a 5x5 matrix,"Find the determinant of the following matrix: 
$$\begin{bmatrix}
1& 1& 1& 1& 1\\
3 & 3 &3 &3 &2\\
4& 4& 4& 3& 3\\
5& 5& 4& 4&  4\\
 6& 5& 5& 5 &5\end{bmatrix}$$ Laplace doesn't seem like the best method here, can we somehow turn this into a triangular matrix so that the determinant is the product of the elements on the main diagonal? 
I multiplied the first row by $(-3)$ and added it to he second one, then by $(-4)$ and added it to the third one, by $(-5)$ and added it to the fourth one, and by $(-6)$ and added it to last one. 
$$\begin{vmatrix}
1& 1& 1& 1& 1\\
3 & 3 &3 &3 &2\\
4& 4& 4& 3& 3\\
5& 5& 4& 4&  4\\
 6& 5& 5& 5 &5
\end{vmatrix}=\begin{vmatrix}
1& 1& 1& 1& 1\\
0& 0 &0 &0 &-1\\
0& 0& 0& -1& -1\\
0& 0& -1& -1&  -1\\
 0& -1& -1& -1 &-1
\end{vmatrix}$$ What should I do now?","['matrices', 'linear-algebra', 'determinant']"
