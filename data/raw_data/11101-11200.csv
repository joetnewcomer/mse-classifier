question_id,title,body,tags
85591,Compact = Closed + Bounded + (?),"In $\mathbb{R}^n$ we know (Heine-Borel Theorem) that a set is compact if and only if it is closed and bounded. In $C(X)$ for a compact metric space $X$, we know (corollary of Ascoli-Arzela Theorem) that a set is compact if and only if it is closed, bounded, and equicontinuous. I am looking for as many examples as I can of other spaces where the extra condition for compactness is known. Also, I am looking for as many examples as I can of (important) spaces where the extra condition is not currently known. I am planning on doing some research (under a professor) and I thought this topic was particularly interesting, so I would very much appreciate some examples to start off with, just so I can get a feel for the problem.","['soft-question', 'real-analysis']"
85596,Variance of the number of empty cells,"If I place $k$ balls in $n$ cells randomly with uniform probability, then for large enough $n$ and $k/n$ small enough, I expect about $n e^{-k/n}$ cells to be empty (using the Poisson approximation to the Binomial.)  However, I cannot find the limit of the variance of the number of empty cells? One can compute explicit cases by using the probability that exactly $m$ cells are empty,
$$var = \sum_{m=0}^nm^2\binom{n}{m}\sum_{\nu=0}^{n-m}(-1)^\nu\binom{n-m}{\nu}\left(1-\frac{m+\nu}{n}\right)^k - \left(1 - \frac{1}{n}\right)^{2k}$$ but I cannot find the limit of this. The same question can be asked of singletons, doubletons, etc.",['probability']
85600,Finite abelian groups - direct sum of cyclic subgroup,"Let $G$ be a finite abelian $p$-group. It is quite elementary to see that if $g \in G$ is an element of maximal order (and thus its span is a cyclic subgroup of $G$ of maximal order) then $G$ can be written as the direct sum $G=\langle g \rangle \oplus H$ for some $H \leq G$ (subgroup of $G$). For a proof see this for example (page 2). My question: Do we need that $G$ is a $p$-group or does it also work for arbitrary finite abelian groups? I think it is wrong for general groups because I looked around quite a bit and always only found the above theorem, but I could not find a counter-example.","['finite-groups', 'group-theory', 'abelian-groups']"
85602,Hyperellipticity (or not!) of a Riemann surface and the singularities of the curve,"Largely I want to know as to how does one say anything about the hyperellipticity or the genus of the Riemann surface by looking at the algebraic curve and its singularities. To give a specific example, what is the meaning of the statement that, ""a curve of genus 2 can be expressed as a fourth degree plane curve possessing one double point"" ? Does this mean that any Riemann surface of genus 2 is a normalization of a fourth degree algebraic curve in $\mathbb{P}^2$ with one double point? In general the proof says that any compact hyperelliptic Riemann surface of genus $g$ is a normalization of a an algebraic curve of degree $2g+2$ of the form $y^2 = \prod _{i = 1}^{2g+2} (x-a_i)$ So I would have naively thought that a genus $2$ Riemann surface (which is always hyperelliptic) will need a $2\times 2 +2 = 6$ degree algebraic curve. Hence I am not clear as to what to read of the quoted statement. Is something very special happening for genus $2$? Is the general theorem not a sharp statement? The general statement seems to tell me that the $a_i$ being distinct guarantees the smoothness of the algebraic curve except may be at the points at infinity. Now if there is a lower degree curve that can equally well represent the genus $2$ surface then is that necessarily going to be a curve with singularities? If the general statement is not a sharp statement and one can in cases do with lower degree curves than $2g+2$ then how does one derive the genus of the Riemann surface by looking at the algebraic curve and may be its singularities. Is there a ""generalized"" genus formula that works always?","['differential-geometry', 'riemann-surfaces', 'algebraic-geometry', 'complex-analysis']"
85609,Banach-Tarski Paradox for the unit interval?,"Does there exist such a map $\phi: [0, 1] \rightarrow S^2$ which determines some sort of a Banach-Tarski decomposition for the unit interval $[0, 1]$? I did read through Stan Wagon's The Banach-Tarski Paradox but the language is somewhat terse. I did read somewhere that Felix Hausdorff proved that one can chop up the unit interval into countably many pieces, slide the pieces around, and fit them together into the interval $[0, 2]$. Not sure of any journals that describe the exact proof. Is it possible to find $\phi$ explicitly perhaps in terms of the middle-third Cantor set?","['general-topology', 'real-analysis']"
85612,Sum of two countably infinite sets,What is the sum of two countably infinite sets? Another countably infinite set? I am asked to find this in a question.,['elementary-set-theory']
85616,Definition of multivariate martingale,I cannot find a proper definition of multivariate martingale. If each component is $1$-dimensional martingale is it enough for a $d$-dimensional process to be a martingale? Thanks.,"['probability-theory', 'stochastic-processes', 'martingales']"
85622,proving that $\sup \limits_{x > 0} \frac{x\sin x}{x+1}=1$,"I am having trouble proving that $$\sup ~ \Big\{  \frac{x\sin x}{x+1} \,:\, x>0 \Big\}=1$$ for my homework assignment. I have managed to prove that there is no $x$ so that $f(x) >1$ but cant seem to manage to prove there is no smaller number then $1$ for which that is true. Can someone please help me out? Thanks.","['calculus', 'limits']"
85648,Why can the complex conjugate of a variable be treated as a constant when differentiating with respect to that variable?,"I'm trying to understand the derivation of Wiener deconvolution given on its Wikipedia page .  In the last couple steps under the derivation section, they take the derivative with respect to $G(f)$ of an equation that has both $G(f)$ and $G^\ast(f)$ in it.  They simply state that $G^\ast (f)$ acts as a constant in the differentiation.  However, it seems to me that if you don't treat $G(f)$ as a constant, then you shouldn't be able to treat $G^\ast (f)$ as a constant because they are directly related. I searched around some looking for an explanation.  I found this page , which seems to agree that the complex conjugate can be treated as a constant.  I also found some stuff about the Cauchy-Riemann equations , which seem to be related.  However, I haven't had any classes on complex analysis and don't understand the intuition behind why this can be done. Why can the complex conjugate of a variable be treated as a constant when differentiating with respect to that variable?",['complex-analysis']
85653,Relation between integral by parts and Fubini's theorem,"In probability, I have seen some examples for which both Fubini's theorem and integration by parts (for Riemann-Stieltjes integrals with cdf as integrator) provide different but correct solutions. For example In proving $E(|X|)=\int_0^\infty P(|X| > t)dt$ , Edvin and Did used Fubini's theorem, while
Ben used integration by parts; In proving $\operatorname{median}(X)$ solves $\min_{c \in \mathbb{R}} E |X-c|$ , Did used Fubini's theorem, while Sivaram
used integration by parts in Edit. So I wonder if the two are related somehow? 
For example, in some cases (especially the two examples above), can one lead to the other? A wide guess for going from Fubini's theorem to integration by parts is: Integration by parts says $$
    \begin{align} f(b)g(b) - f(a)g(a) & =  \int_a^b  g(x) \, df(x) + \int_a^b f(x) \, dg(x). \end{align}  $$ If there is some $c \in \mathbb{R}$ such that $g(c)=0$, then $$
\int_a^b g(x) \, df(x) = \int_a^b \int_c^x dg(t)  \, df(x ) $$ If
Fubini's theorem or some of its variants can apply, then for some $d
\in \mathbb{R}$, $$ \int_a^b \int_c^x dg(t)  \, df(x ) = \int_c^b
\int_d^t df(x)  \, dg(t )  = \int_c^b \int_d^x df(t)  \, dg(x )  $$
one step closer to $\int_a^b f(x) \, dg(x)$, but still far away from
integration by parts. No idea yet about going from integration by parts to Fubini's
theorem.","['probability-theory', 'integration', 'real-analysis']"
85656,Fitting a sine function to data,"I have a sequence of $n$ points $(x_i,y_i)$, for $i=1,\dots,n$. I would like to find the function, of the form $y=V\sin(x+\phi)$, which best fits the points. Which numerical method could I use? I have a slow system, with little memory, so I am searching for a fast and efficent method, even if not very accurate. I have tried with gradient descent, but it is slow.","['trigonometry', 'regression', 'numerical-methods']"
85658,"Expected value and Variance of $Y=\frac{1}{a} X-b$ where $X \sim N(\mu, \sigma^2)$","I absolutely know I am not doing this right. :[ Could I get some input or point back in the right direction? My work done so far is shown below. Let $X$ be a normal random variable with parameters $N(\mu, \sigma^2)$. Please find the Expected value and Variance of random variable $Y=\frac{1}{a} X-b$, where $a$ and $b$ are constant values. My work. $$
\begin{align*}
E(Y) &= aE(x)-b = \sum_x \Big(\frac{1}{a} x - b \Big) p_x(x) = \frac{1}{a} \sum_x x p_x(x) - b 
\\ &=  \frac{1}{a} \sum_x x p_x(x) - b \sum_x p_x(x) = a E(x) - b \cdot 1.
\end{align*}
$$ If $a = 0$, then $E(x-b) = E(x)$ and if $b = 0$, then $E(ax)= \frac{1}{a}E(x)$. $$
\begin{align*}
\mu &= E(X) = \int_{-\infty}^{\infty} x f(x) dx = \int_{0}^{1} x \Big(\frac{1}{a} X - b \Big) dx = \frac{1}{a} \int_0^1 X^2 - xb ~dx 
\\ & = \frac{1}{a} \Big( \frac{x^3}{3} - \frac{bx^2}{2} \Big) \text{ from } 1 \text{ to } 0 
\\ & = \frac{1}{a} \Big( \frac{1}{3} - \frac{b}{2} \Big) .
\end{align*}
$$ $$
\text{RV } Y = (X - E(x)^2).
$$ $$
\sigma^2 = \operatorname{Var}(x) = E[(x) - E[x])^2]
$$ $$
\operatorname{Var} \Big( \frac{1}{a} X - b \Big) = a^2 \operatorname{Var}(x).
$$
$$
\int_{\Box}^{\Box}\Big( \frac{1}{a} X - b \Big) - \Big( \frac{1}{a} X - b \Big)^2 \ldots
$$","['statistics', 'probability']"
85660,Bilinearity: what does it mean?,"What does bilinear really mean?  Everytime I heard the word, I think it should be ""linear in 2 ways?"" For example, from the definition of inner product (taken from Appendix A of ""Wavelets For Computer Graphics"" by Stollnitz): An inner product on a vector space V is any map from $ V \times V $ to $\mathbb{R}$ that is: Symmetric $ \langle u | v \rangle = \langle v | u \rangle $ Bilinear
$ \langle au + bv | w \rangle = a \langle u | w \rangle + b \langle v | w \rangle $ Positive definite $ \langle u | u \rangle > 0 $ for all $ u \ne 0 $ But how is bilinearity ""linear in 2 ways"" , (if bilinear really does mean $2\times$ linear!)","['bilinear-form', 'linear-algebra', 'terminology', 'intuition']"
85679,Who has the upper hand in a generalized game of Risk?,"So, I played a game of Risk the other day for the first time since I was very little. I was frustrated to discover that I couldn't compute (at least not in my head) whether the attacker or the defender has the upper-hand in large battles. Based on how the game unfolded, I guessed that the attacker has the advantage, and later I verified this by calculating the expected number of casualties in a round of ""combat"". But, my approach was just to brute-force the computation in a spreadsheet. I'm curious whether there is a more elegant approach and also I thought it might be nice to ask a more general question. Let $A$ and $B$ be two players. Let $a,b,n,k$ be positive integers with $k \leq a,b$. The game is as follows. Person $A$ has $a$ dice. Person $B$ has $b$ dice. All dice have $n$ sides labelled $1,2,\ldots,n$. Both players roll all of their dice, extract their $k$ highest rolls (with repetition) and sort them in (weakly) decreasing order. Say $a_1,\ldots,a_k$ are $A$'s $k$ best rolls and $b_1,\ldots,b_k$ are $B$'s $k$ best rolls. $A$ suffers one ""casualty"" for each index $i \in \{1,2,\ldots,k\}$ with $a_i \leq b_i$. $B$ suffers one ""casualty"" for each index $i \in \{1,2,\ldots,k\}$ with $a_i > b_i$. Note that player $B$ wins when the rolls are tied. What are the expected number casulties that $A$ suffers in terms of $a,b,n,k$? Note by linearity of expectation, the expected number of casualties that $A$ suffers plus the expected number of casualties that $B$ suffers sum to $k$.","['closed-form', 'recreational-mathematics', 'probability']"
85688,Hartshorne exercise II.5.12(b),"I've been working on the Hartshorne exercise in the title for quite a while, which goes like this: let $f : X \to Y$ and $g : Y \to Z$ be morphisms of schemes, $\mathscr{L}$ a very ample invertible sheaf on $X$ relative to $Y$, and $\mathscr{M}$ a very ample invertible sheaf on $Y$ relative to $Z$. Show that $\mathscr{L} \otimes f^*\mathscr{M}$ is a very ample invertible sheaf on $X$ relative to $Z$. After getting thoroughly stuck, I found the corresponding statement in EGA, namely Proposition 4.4.10(ii). The reason I am asking this question is that in EGA the claim is proved under some hypotheses (namely that $Z$ is quasi-compact, $f$ is of finite type, and $g$ is quasi-compact), and the conclusion is weaker: one can only say that there exists $n \geq 0$ such that $\mathscr{L} \otimes f^*(\mathscr{M}^{\otimes m})$ is very ample relative to $Z$ for all $m \geq n$. So is Hartshorne wrong, or is EGA using unnecessary hypotheses to reach a weak conclusion (I find this harder to believe), or am I misinterpreting one of the two? Edit: there is another possibility that just occurred to me: Hartshorne remarks that EGA uses a slightly different definition of very ample, and having consulted EGA I see that this is the case. So I should extend my question to ask if this is the reason for my difficulty, and if so how does it make a difference?","['algebraic-geometry', 'coherent-sheaves']"
85696,Does a median always exist for a random variable?,Does a median always exist for a random variable? Note that a median of a random variable $X$ is defined as a number $m \in \mathbb{R}$ such that $P(X \leq m) \geq \frac{1}{2}$ and $P(X \geq m) \geq \frac{1}{2}$. Thanks and regards!,"['probability-theory', 'median']"
85709,Maximize the Area of a Quadrilateral given Three Sides,"We have three sides of a quadrilateral given, each of side length 20.The third side length is known to be less than length 100. Determine the maximum area of such a quadrilateral. I would guess the answer is when it is a square, but I have no proof. How would we do this?","['optimization', 'geometry']"
85733,Probability that a family with $n$ children has exactly $k$ boys,"Let the probability $p_n$ that a family has exactly $n$ children be $\alpha p^n$ when $n\geq1$, and $$p_0=1-\alpha p(1+p+p^2+\cdots).$$ Suppose that all the sex distributions have the same probability. Show that for $k\geq1$ the probability that a family has exactly $k$ boys is $2\alpha p^k/(2-p)^{k+1}$.",['probability']
85753,I don't understand why the inverse is this?,"my question is related to matrix inverting and Hill cipher(you don't have to know what it is to help me) My teacher gave me an example. First we have a matrix (the key matrix) that multiplied by a vector of letters is another vector with the previous letters encrypted. To decrypt it you need the inverse of the key matrix and then multiply it by the vector of the encrypted letters, thus you get the vector of the decrypted letters (the real message) Well, this is the matrix, the key matrix that I have to multiply the vectors of letters by and get the encrypted message. $$ \left[
  \begin{array}{ c c }
     22&27&18 \\
     18&28&5  \\
     4&17&1
  \end{array} \right]
$$ However, when I try to invert it using multiple calculators on the internet and even programming languages (e.g. Ruby) I get a matrix (the inverted one) with a lot of 0.decimals numbers. Not whole numbers Why am I expecting to get whole numbers? Because my teacher gave me the inverse. This is it: $$ \left[
  \begin{array}{ c c }
     1&18&8 \\
     2&8&11  \\
     20&24&14
  \end{array} \right]
$$ I don't get something like this one. I know the inverse matrix is unique, but then who is wrong? Calculators bring on the same matrix, however, the matrix my teacher gave is the right matrix, because it can decrypt the encrypted message well, so it must be the good one. Not to forget to tell you, that the inverse is the matrix mod 29 . Any idea on how I could get to the same matrix as my teacher? Thanks a lot.","['matrices', 'linear-algebra', 'inverse', 'modular-arithmetic']"
85761,Distance Between A Point And A Line,"Any Hint on proving that the distance between the point $(x_{1},y_{1})$ and the line $Ax + By + C = 0$ is, $$\text{Distance} = \frac{\left | Ax_{1} + By_{1} + C\right |}{\sqrt{A^2 + B^2} }$$ What do I use to get started? All I know is the distance formula $\sqrt{(x_{2}-x_{1})^2+(y_{2}-y_{1})^2}$. Kindly Help","['analytic-geometry', 'geometry']"
85764,Derive a closed form for a sum with inverse binomial coefficients,"First off, I would like to apologize again for the integral I posted several days ago involving $\zeta(5)$.  I was careless and did not examine the decimals out far enough. With that said, I would now like to post a series I think is interesting. I am trying to derive a general form for $$ \sum_{n=1}^{\infty}\frac{nx^{n}}{\binom{2n}{n}}.$$ I thought about starting with $\displaystyle \sum_{n=1}^{\infty}\frac{2^{2n}x^{2n}}{\binom{2n}{n}}=\frac{x^{2}}{\sqrt{1-x^{2}}}+\frac{x\sin^{-1}(x)}{(1-x^{2})^{\frac{3}{2}}}$. I tried differentiating, integrating and so forth, but it turns into a mess and I do not know how to eliminate the $2^{2n}$ nor get the $x^{2n}$ down to $x^{n}$.  Is it possible to somehow integrate in terms of, say, $t$ from $0$ to $x$? Any thoughts on how to go about this?.  This would then lead to $\displaystyle \sum_{n=1}^{\infty}\frac{n2^{n}}{\binom{2n}{n}}=\pi +3$ and many other forms just by using a general formula. I ran across this in ""Irresistible Integrals"" by Boros and Moll. It is one of their 'Exercises'. Thanks very much.","['sequences-and-series', 'binomial-coefficients']"
85775,Geometry problem: Line intersecting  a semicircle,"Suppose we have a semicircle that rests on the negative x-axis and is tangent to the y-axis.A line intersects both axes and the semicircle. Suppose that the points of intersection create three segments of equal length. What is the slope of the line? I have tried numerous tricks, none of which work sadly.","['geometry', 'calculus']"
85782,When does a maximum likelihood estimate fail to exist?,"I have been told that a maximum likelihood estimate (MLE) does not always actually exist.  Why is this the case?  It is clear that the MLE may not be unique, but there should always be a maximum, no?","['probability', 'machine-learning']"
85793,Symbolic coordinates for a hyperbolic grid?,"Rephrasing (one year later)    (original question is below) Apparently the original question wasn't clear, or nobody knows an answer (or both).  So I will try to rephrase it. Look at your favorite hyperbolic grid .  This question asks for a labeling system for the points. Of course we could draw the grid on the Poincare disk, and use real numbers (the (x,y) coordinates of each point), but in practice that would raise all sorts of precision issues that could surely be avoided if one had a proper symbolic coordinate system.  You shouldn't need real numbers if you're staying on grid points! Just like (2,3)+(0,1) is trivial to do by hand (or in your head) for the square grid, we'd like some form of symbolic coordinates ( i.e. consisting of finite sequences of symbols) for a hyperbolic grid, in which simple operations on small grid vectors are similarly easy. If you take some sequence of left and right turns in a hyperbolic grid city, what should you keep track of in your head so you can take the optimal route back to your starting point?  In a Euclidean square grid, it is {(int)X, (int)Y, (enum)direction you are facing}, and we all know how to use this.  Is there any hyperbolic grid where this question has a nice answer? Original Question If we consider the Euclidean plane, then a square grid works well with using two integers (the coordinates) as a representation for vectors that lie on the grid. Does anybody know of a similarly nice representation for working in the hyperbolic plane? Desirable features of any such system: $-$
It should be easy to add two vectors. $-$
It should be easy to see if two vectors are the same. $-$
It should be easy to see if two vectors are close. $-$
It should be easy to rotate a vector by an angle that is a symmetry of the grid. $-$
Every point in the plane should be near some vector. (The grid shouldn't have large empty regions.) Note that ""addition"" using continuous coordinates would most naturally be defined in terms of parallel transport, and it is neither commutative nor associative.  On a grid, however, the issue of orientation needs to be addressed differently, since parallel transport along arbitrary grid vectors will introduce rotations that are not a symmetry of the grid, so to remain on the grid, addition will need to be defined using something other than parallel transport. Since hyperbolic grids have an exponential number of points (as a function of distance from the origin), our symbolic coordinates will need to have a length proportional to the length of the vector. Don Hatch has a web page which gives some possible grids . ("" Easy "" means an efficient algorithm that is doable by hand, like how the algorithms for addition and subtraction using the standard digit-sequence representation of integers can be used for the Euclidean square grid.
Using hyperbolic functions of real numbers, always keeping track of enough digits to identify the nearest grid point, does not count as easy!) Addendum: Many readers seem to be disturbed by a little voice saying ""But vectors don't make sense in the hyperbolic plane!"": What that voice is really saying is that the hyperbolic plane doesn't give you all the nice properties you are used to in Euclidean space or in vector spaces.  So if you define vectors as objects having specific properties you are used to (such as having a direction that is unaffected by parallel transport), then that definition may not correspond to anything in the hyperbolic world.  You could use the term isometry , but that is typically a fixed mapping from the space to itself, and in the hyperbolic plane the isometry corresponding to a vector would depend on the starting point. (However, isometries will be central to any solution, I assume.) And a geodesic is a fixed path within the space, no different from a hyperbolic line or segment.  The paper ""What is a vector in hyperbolic geometry?"" offers one solution. Gyrovectors offer another.  I deliberately leave them undefined in this question, as I am looking for any workable system.","['hyperbolic-geometry', 'discrete-mathematics']"
85808,Well-posedness of the Poisson problem with mixed boundary conditions,"Let $\Omega \subset \mathbb R^n$ be a subdomain with Lipschitz boundary, i.e. locally any part of the boundary looks like the graph of a Lipschitz continuous function, after some affine coordinate transformation. Suppose we are given a ""partition"" $\Gamma_D$ and $\Gamma_N$ of the boundary, s.t. these sets are submanifolds of $\mathbb R^n$ with Lipschitz boundary by themselves, and their intersection has measure zero. Let us be given $g \in L^2(\Gamma_D)$ and $h \in L^2(\Gamma_N)$ and some function $f \in L^2(\Omega)$. We want to solve Poisson's equation with mixed boundary conditions $\operatorname{div}\operatorname{grad}  u = f$ over $\Omega$ $u_{|\Gamma_D} = g$ over $\Gamma_D$ $\operatorname{grad} u_{|\Gamma_N} \cdot n = h$ over $\Gamma_N$ It is standard to prove well-posedness of these problems if either $\Gamma_D$ or $\Gamma_N$ is the empty set. I have not found a rigorous proof of well-posedness for general mixed boundary conditions in the standard books like, say, Gilbarg-Trudinger. On the other hand, certain papers suggest the boundary parts are required to meet at an angle that is not 180° in the case of Lipschitz boundaries, so the boundary is necessarily non-smooth. These influences appear confusing to me. I do not know how to learn more about this. Could please give a reference where to learn more about the Poisson problem with mixed boundary conditions? EDIT:
In order to motivate why this is interesting and why it confuses me, I would like to point to the paper Ott, Brown: The mixed problem for the Laplacian in Lipschitz domains and R.M. Brown. The mixed problem for Laplace’s equation in a class of Lipschitz domains . On the other hand, in numerical analysis lectures that I attend, this question is usually swept under the rug and one deals freely with mixed boundary conditions. So either I don't know the well-posedness results for simplicial domains, or the numerical examples all belong to the well-posed case.","['functional-analysis', 'partial-differential-equations']"
85811,Extension of real analytic map on the unit circle,"Given a real-analytic map $f : \mathbb{S}^1 \rightarrow \mathbb{S}^1$, where
$$\mathbb{S}^1 = \{z \in \mathbb{C} : |z| = 1\},$$
does it admit a complex-analytic extension $\tilde{f} : U \rightarrow V$, where $U$ and $V$ are open subsets of $\mathbb{C}$ containing $\mathbb{S}^1$? If so, how can you prove it? I'd appreciate a proof as elementary as possible (but complete). Thanks.","['complex-analysis', 'circles', 'real-analysis']"
85817,Order of the centralizer of a permutation,"Given a permutation $\sigma\in S_{n}$, is there a way to know the order of the centraliser $C_{S_{n}}\left(\sigma\right)=\left\{ \pi\in S_{n},\,\pi\sigma=\sigma\pi\right\}$ , i.e what is $\left|C_{S_{n}}\left(\sigma\right)\right|$? I would appreciate a proof if the answer is yes. Also, if the answer above is yes, is there also a way to calcualte the order of the centraliser of a given subset of $S_{n}$, or at least for a pair of permutations?","['permutations', 'group-theory']"
85819,Kronecker-Weber Theorem,"I'm stuck with an article ""A simple proof of Kronecker-Weber Theorem"" on this website . On page 7, the author proofs that $\mathbb{Q}_p((-p)^{\frac{1}{p-1}}) = \mathbb{Q}_p(\zeta_p)$. While I understand the reasoning of the proof ($[\mathbb{Q}_p((-p)^{\frac{1}{p-1}}):\mathbb{Q}_p] = [\mathbb{Q}_p(\zeta_p):\mathbb{Q}_p]$, so if one contains the other, we are done), I don't get how he makes his $u$ to use for Hensel's Lemma. Specifically, he defines a polynomial
$$g(X) = \frac{(X+1)^p-1}{X} = X^{p-1}+pX^{p-2}+\ldots +p,$$
so of course we have $g(\zeta_p-1)=0$, but I don't get how
$$g(\zeta^p-1)\equiv (\zeta_p-1)^{p-1}+p (\bmod(\zeta_p-1)^p).$$
Apart from understanding this lemma, is there an other (simpler) proof of this fact ? Any help would be appreciated.","['algebraic-number-theory', 'number-theory']"
85828,How to prove whether a polynomial function is even or odd,We know that a function is even if $f(-x) = f(x)$ and odd if $f(-x) = -f(x)$. With this reasoning is it possible to prove that a polynomial function such as  $f(x) = a_{2n}x^{2n} + a_{2n-2}x^{2n-2} + ...+a_{2}x^2 + a_{0}$  is even or odd? What do you suggest? How do we get started?,"['algebra-precalculus', 'polynomials']"
85839,"If $f(x)$ and $g(x)$ are Riemann integrable and $f(x)\leq h(x)\leq g(x)$, must $h(x)$ be Riemann integrable?",Let $f$ and $g$ be Riemann integrable (real) functions and $$f(x)\leq h(x)\leq g(x).$$ Is it true that $h(x)$ is Riemann integrable? Can someone post a proof (if there is)? Thanks.,"['integration', 'analysis']"
85845,"""Small sets"" in Markov chains","I came across a definition for a ""small set"" (of the state space) $A \subset \Omega$: there exists a $\delta > 0$ and a measure $\mu$ such that $p^{(k)}(x, \cdot) \geq \delta \mu (\cdot)$ for every $x \in A$. In this case, they say that $A$ has lag $k$. I have no intuition for this and I can't find anything anywhere that explains this with some examples. Can anyone tell me what it means? Why is it important?","['probability-theory', 'markov-chains', 'reference-request']"
85849,Calculating the probability that at least one of a series of events will happen,"I want to calculate the probability of at least one event happening in a series of multiple events. For example, let's say the probability of each event happening are: Event 1: 2/21 Event 2: 1/10 Event 3: 7/15 Event 4: 9/16 Event 5: 3/10 What is the probability that at least one of these events will happen? EDIT: Assume all events are independent.",['probability']
85854,What's the name for the property of a function $f$ that means $f(f(x))=x$?,"I can think of several examples of functions such that twice application of the function is equivalent to no application of it. Additive inverse Multiplicative inverse Fourier transform Complex conjugation Any group built up from $\mathbb{Z}_2$, applying (one of) the $\mathbb{Z}_2$ parts' operation. ""Idempotent"" came to mind, but that's wrong. It means $f(f(x)) = f(x)$, not $f(f(x))=x$. What is the word for this ""flip-flop"" property?","['matrices', 'complex-numbers', 'abstract-algebra', 'definition']"
85860,Properties preserved by diffeomorphisms but not by homeomorphisms,"Diffeomorphisms between manifolds are particular homeomorphisms, so each property preserved by homeomorphisms is preserved by diffeomorphisms. Can you show me some examples of properties preserved by diffeomorphisms on manifolds that are not preserved by homeomorphisms?","['differential-topology', 'differential-geometry']"
85867,Derivative I do not understand: $\ln (\ln x)$,"I'm currently taking Calculus. I'm pretty good with derivatives apart from when it comes to logarithmic differentiation etc. Here is one I'm having problems with, if anyone could help that would be appreciated. $$ f(x)=\ln (\ln (x) ) .$$ Can someone please explain the derivative of this? Thanks!","['calculus', 'derivatives']"
85882,On the number of caterpillars,"A caterpillar is a tree with the property that if all the leafs are removed then what remains is a path. Could you help me to prove that there are $2^{n-4}+2^{\lfloor n/2\rfloor-2}$ caterpillar on $n$ vertices, $n\geq3$? (It should use Polya's theorem)","['graph-theory', 'trees', 'combinatorics']"
85883,Solving a simple second order ODE with initial condition,"Okay i've been at it for far too long now. It comes from a bigger question from working with a PDE. I did seperation of variables and now I am stuck near the end of the problem. Here is the ODE in question
$$ \Phi''(y)= \lambda^2\cdot\Phi(y)$$ with the following initial condition
$$ \Phi'(H)=0$$ where $H$ is a positive number. Also I know $\displaystyle \lambda = \frac{n\pi}{L} >0$. There is another condition but I dont think it can help 
$$ \Phi(0) = \begin{cases} 0  & x > L/2  \\ 1 & x < L/2 \end{cases}$$
sorry, i dont know how to do cases in latex and yes, that is an $x$ in the initial condition. Like i said this is a bigger problem that has both x and y. The solution should be $$\Phi(y) = B \cdot \cosh{(\lambda(H-y))}$$ I've tried going through the following general solutions
$$\Phi(y) = Ae^{\lambda y} + B e^{-\lambda y}$$ and
$$\Phi(y) = A \sinh{\lambda y} + B \cosh{\lambda y}$$
but no luck that way :(","['ordinary-differential-equations', 'partial-differential-equations']"
85893,Central Limit Theorem is incorrect - where is my mistake?,"Say I flip a coin 80 times and I ask for the probability to get over 48 heads.
I then flip a coin 800 times and ask for the probability to get over 480 heads. Translating this into Central Limit Theorem concepts, we ask that the sample mean deviate from the expected value of the sample mean by a tenth. As N grows larger this same ""tenth"" chunk becomes smaller and so the answer to the second question is smaller than the first. I have been trying to visualize the distribution, starting with a sum of N flips and dividing by N to get the mean of N flips. Yet I keep getting the same picture in my head of the distribution for any N. In both questions above I look at the probability mass for the sum to go over 48 or 480 and this just seems to be the same probability. This gif has realized my confusion: If I understand it properly, every frame in this gif was generated by taking a distribution of the sum of say, N coin flips, and normalizing it to the same scale - dividing by N.
Where is that peak at the expected value the Central Limit Theorem is talking about?","['probability-theory', 'probability-distributions']"
85894,Proof by Induction: Alternating Sum of Fibonacci Numbers [duplicate],"This question already has answers here : Closed 12 years ago . Possible Duplicate: Show that $f_0 - f_1 + f_2 - \cdots - f_{2n-1} + f_{2n} = f_{2n-1} - 1$ when $n$ is a positive integer This is a homework question so I'm looking to just be nudged in the right direction, I'm not asking for my work to be done for me. The Fibonacci numbers are defined as follows: $f_0 = 0$, $f_1 = 1$, and $f_{n+2} = f_n + f_{n+1}$ whenever $n \geq 0$. Prove that when $n$ is a positive integer: \begin{equation*}
f_0 - f_1 + f_2 + \ldots - f_{2n-1} + f_{2n} = f_{2n-1} - 1
\end{equation*} So as I understand it, this is an induction problem. I've done the basis step using $n = 1$: \begin{align*}
- f_{2(1)-1} + f_{2(1)} &= f_{2(1)-1} - 1\newline
- f_1 + f_2 &= f_1 - 1\newline
- 1 + 1 &= 1 - 1\newline
0 &= 0
\end{align*} I've concluded that the inductive hypothesis is that $- f_{2n-1} + f_{2n} = f_{2n-1} - 1$ is true for some $n \geq 1$. From what I can gather, the inductive step is: \begin{equation*}
f_0 - f_1 + f_2 + \ldots - f_{2n-1} + f_{2n} - f_{2n+1} = f_{2n} - 1
\end{equation*} However, what I find when I try to prove it using that equation is that it is incorrect. For example, when I take $n = 1$ \begin{align*}
- f_{2(1)-1} + f_{2(1)} + f_{2(1)+1} &\neq f_{2(1)} - 1\newline
- f_1 + f_2 - f_3 &\neq f_2 - 1\newline
- 1 + 1 - 2 &\neq 1 - 1\newline
-2 &\neq 0
\end{align*} I suppose that my inductive step is wrong but I'm not sure where I went wrong. Maybe I went wrong elsewhere. Any hints?","['fibonacci-numbers', 'induction', 'discrete-mathematics']"
85914,The derived subgroup of an infinite nilpotent group has infinite index,"Another problem about nilpotent groups I cannot get a grip on: Let $G$ be a nilpotent group. If $G/D(G)$ is finite (resp. countable), then so is $G$. I've tried to use induction looking at the derived series, but nothing has come of it, and that's not a surprise, since it says ""nilpotent"" and not ""solvable"". Apart from that, I'm completely lost. Any kind of help will be highly appreciated.","['group-theory', 'abstract-algebra']"
85915,"If $[a_n, b_n] \cap [a_m, b_m] \neq \emptyset$ then $\bigcap_{1}^{\infty} [a_n,b_n] \neq \emptyset$","Let $[a_n,b_n]$, $n=1,2,3,\ldots$, be closed intervals with $[a_n,b_n] \bigcap [a_m,b_m] \neq \emptyset$ for all $n$, $m$. Prove $\bigcap_{1}^{\infty} [a_n,b_n] \neq \emptyset$. I can show by induction that $\bigcap_{1}^N [a_n,b_n] \neq \emptyset$. But I am not sure about the infinity bit, maybe, I am missing something obvius. Any hint guys? Thanks",['analysis']
85924,"""And"" symbol? Wedge product in a surface integral? — Is this a typo, or did I miss an important lecture?","This is the question I got on my final assignment (Calculus III): Evaluate the surface integral \begin{equation}
  \int \int_S xy \; \; dy\wedge dz - yz \; \; dz\wedge dx + xz \; \; dx\wedge dy
   \end{equation} Where $S$ is the part of the plane $x+y+z=1$ lying in the first octant. Use $x$ and $y$ as parameters. I am quite confused. I asked around and someone told me that this is also the symbol for something called the Wedge product, which I've not heard of before and appears in neither my calculus textbooks (Stweart's and Div Grad Curl ) nor any of my Linear Algebra books. From what I saw online, I still don't understand how it would make sense in this equation. Is this a typo? Seems like a strange typo. Should it just read: \begin{equation}
\int \int_S xy \; \; dydz - yz \; \; dzdx + xz \; \; dxdy
 \end{equation}","['multivariable-calculus', 'exterior-algebra']"
85928,"Is it ""often known"" how to compute a list of groups?","From the introduction of the article Construction of Finite Groups written by Hans Ulrich Besche and Bettina Eick: When attempting to determine up to isomorphism the groups of a given order it is often
  known how to compute a list of groups of this order which contains each isomorphism type
  at least once. The central problem is to reduce to isomorphism type representatives. Is it really known how to compute a list of groups of a given order that contains each isomorphism type at least once? If so, please tell me where to find such algorithm.","['computational-algebra', 'groups-enumeration', 'finite-groups', 'gap', 'group-theory']"
85940,How do you integrate imaginary numbers?,"How would you find, for instance, $\int_0^4 i\> x \,dx$ ?  Can you just treat $i$ as a constant, or do you have to do something more sophisticated? Thanks!","['complex-numbers', 'integration']"
85943,Are there any interpretations for the Gronwall's inequality in view of comparison theorem?,"One form of the Gronwall's inequality is that If $\alpha(x),u(x)$ are non-negative continuous functions on $[0,1]$, and $$\forall x\in [0,1], u(x)\leq C+\int_{0}^{x}[\alpha(s)u(s)+K]ds\;(C,K\geq0),$$ then we have that $u(x)\leq[C+Kx]e^{\int_{0}^{x}\alpha(s)ds}$. One form of comparison theorem is the following. Assume that $f(x,y),F(x,y)$ are continuous on a domain $\Omega\supset [0,1]\times\mathbb{R}$ and $f(x,y)<F(x,y)(\forall (x,y)\in\Omega)$, $y=\phi(x),y=\varphi(x)$ are solutions to $y'=f(x,y),y'=F(x,y)$ (respectively), and $\phi(0)=\varphi(0)$. Then we have that $\phi(x)<\varphi(x)\,(\forall x\in(0,1])$. Are there any interpretations for the Gronwall's inequality in view of the comparison theorem? I am not sure if they have any connections besides the fact that Gronwall's inequality can be used to prove the comparison theorem. Will someone be kind enough to give some comments on this?
Thank you very much!","['ordinary-differential-equations', 'integral-inequality']"
85944,Show that $\int_{-\pi}^\pi ~f(x) \cos (nx) \mathrm{d}\mu(x)$ converges to $0$,"I need some help on the following problem. Let $f\in L_1([-\pi,\pi])$. Then $\int_{-\pi}^\pi ~f(x) \cos (nx) \mathrm{d}\mu(x) \to 0$, where $\mu$ is the Lebesgue measure on $[\pi,\pi]$. Any hints and suggestions on how to begin is very much welcomed. Thanks.",['measure-theory']
85962,Does Itō isometry have different versions?,"Itō isometry from Wikipedia : Let $W : [0, T] \times \Omega \to \mathbb{R}$ denote the canonical
  real-valued Wiener process defined up to time $T > 0$, and let $X :
 [0, T] \times \Omega \to \mathbb{R}$ be a stochastic process that is
  adapted to the natural filtration $\mathcal{F}_{*}^{W}$ of the Wiener
  process. Then $$
     \mathbb{E} \left[ \left( \int_{0}^{T} X_{t} \, \mathrm{d} W_{t} \right)^{2} \right] = \mathbb{E} \left[ \int_{0}^{T} X_{t}^{2} \,
 \mathrm{d} t \right], $$ where $\mathbb{E}$ denotes expectation with
  respect to classical Wiener measure $\gamma$. In other words, the Itō
  stochastic integral, as a function, is an isometry of normed vector
  spaces with respect to the norms induced by the inner products $$
     ( X, Y )_{L^{2} (W)} := \mathbb{E} \left( \int_{0}^{T} X_{t} \, \mathrm{d} W_{t} \int_{0}^{T} Y_{t} \, \mathrm{d} W_{t} \right) =
 \int_{\Omega} \left( \int_{0}^{T} X_{t} \, \mathrm{d} W_{t}
 \int_{0}^{T} Y_{t} \, \mathrm{d} W_{t} \right) \, \mathrm{d} \gamma
 (\omega) $$ and $$
     ( A, B )_{L^{2} (\Omega)} := \mathbb{E} ( A B ) = \int_{\Omega} A(\omega) B(\omega) \, \mathrm{d} \gamma (\omega). $$ Wikipedia claims the reference for the above is Øksendal, Bernt K. (2003). Stochastic Differential Equations: An Introduction with Applications .
However, I didn't find things like ""$\mathbb{E}$ denotes expectation with respect to classical Wiener measure $\gamma$"" in the book. My understanding of Itō isometry is that given fixed $T$, $\left( \int_{0}^{T} X_{t} \, \mathrm{d} W_{t} \right)^{2}$ and $\int_{0}^{T} X_{t}^{2} \,
 \mathrm{d} t$ are both random variables not stochastic processes, and $\mathbb{E}$ denotes expectation with
 respect to the probability measure on the underlying probability space $\Omega$. Is my understanding correct? Why does Wiki's Itō isometry treat $\left( \int_{0}^{T} X_{t} \, \mathrm{d} W_{t} \right)^{2}$ and $\int_{0}^{T} X_{t}^{2} \,
 \mathrm{d} t$ as stochastic processes, and $\mathbb{E}$ as expectation with
 respect to classical Wiener measure $\gamma$ which is a measure on the functional space  $\mathbb{R}^{[0,T]}$ induced by the Wiener process $W$? I am not sure if Wiki is consistent with itself, because in the last two formulas for the inner products, the integrals are wrt the classical Wiener measure over the underlying probability space $\Omega$ instead of over the functional space. Or do I misunderstand Wiki? Is Wiki's Itō isometry a different version from the the one  that I understand? If yes, is there some reference for Wiki's version and relation between the two? Thanks and regards!","['probability-theory', 'stochastic-processes', 'stochastic-integrals']"
85975,Integrable function $f$ on $\mathbb R$ does not imply that limit $f(x)$ is zero,"1) Construct a continuous function $f$ on $\mathbb{R}$ that is integrable on $\mathbb{R}$ but $\displaystyle\limsup_{x \to \infty} f(x)  = \infty$. I took the function that is equal to $n$ on $[n, n + 1/n^{3})$ and made it continuous by saying that $f$ is the line segment joining $n$ and $n+1$ on $[n + 1/n^{3}, n+1)$. But I am failing to prove this integrable. For this, $\lim f(x) = \infty$ but how do you prove in general, if limit does not exist that $\limsup$ is infinity? 2) Prove that if $f$ is uniformly continuous and integrable on $\mathbb{R}$ we have $\displaystyle\lim_{|x| \to \infty} f(x) = 0$. Any help is appreciated. Thanks","['measure-theory', 'real-analysis']"
85984,Research in plane geometry or euclidean geometry,I was doing good at school in plane geometry and trigonometry - especially in geometric proofs like proving the equality of two line segments or two angles - more than I was doing in analytic geometry. I am considering doing research in mathematics to be my career (and my life) someday. and I am wondering about the most interesting research area for me. What I am asking about is : Is there still open research fields in plane geometry or Euclidean geometry? Or this area is considered to be fundamentals that are already investigated enough? Thank you!,"['geometry', 'soft-question']"
86030,Group structure on geometric vector bundles,"Let $S$ be a scheme and $\mathcal A$  a quasicoherent $\mathcal O_S$-Algebra. One knows that then one can associate the affine $S-$scheme $Spec(\mathcal A)$ over $S$. In particular I can consider $Spec(Sym(\mathcal E))$ for a quasicoherent sheaf $\mathcal E$ on $S$, where $Sym$ denotes the symmetric algebra of the sheaf. My question is: Is there a natural structure of a $S-$group scheme on $Spec(Sym(\mathcal E))$?
At least if $\mathcal E$ is locally free of finite rank, this should be true. One could argue that one just glues the local addition maps as locally on $S$ the bundle is just affine $n-$space. But I would be interested in what group functor it represents.","['algebraic-geometry', 'schemes']"
86031,"If $f$ and $g$ are integrable then is $\max\{f,g\}$? [duplicate]","This question already has answers here : Closed 12 years ago . Possible Duplicate: Is the pointwise maximum of two Riemann integrable functions Riemann integrable? Let $f$ and $g$ be two integrable real functions. Is this leads that $\max\{f,g\}$ is integrable too? Any proof? Thanks","['calculus', 'integration', 'real-analysis', 'analysis']"
86042,The Gauss Map in Algebraic Geometry,"At the moment I am reading Joe Harris' book on algebraic geometry. I am stuck at two points:
1.) The Gauss Map is a regular map
2.) The Gauss Map of a hypersurface is quasi-finite. Both statements can be found on page 188. I have unsuccesfully tried to prove them. For 2 I also tried some examples, but couldn't see any general pattern.
Any help is very much appreciated. Thanks a lot!!",['algebraic-geometry']
86047,Calculating the residues of $f(z)=\frac{e^{az}}{1+e^z}$,"Let $$f(z)=\frac{e^{az}}{1+e^z}$$
where $0<a<1$ Can anyone help me find the residues of this function? So $$e^z+1=0 \Rightarrow z=i\pi(1+2k)$$ where $k\in \mathbb{Z}$, so these are simple poles (if someone could explain a simple way of showing this that'd be great, other than expansion) $$\lim_{z\rightarrow i\pi(1+2k)}\frac{(z-i\pi(1+2k))e^{az}}{1+e^z}=\lim_{z\rightarrow i\pi(1+2k)}\frac{a(z-i\pi(1+2k))e^{az}+e^{az}}{e^z}=e^a$$ So i'm trying to evaluate $\int_{\infty}^\infty f(z)$ you see, so will I need to pick a contour with fixed height otherwise the integral around the contour will be equal to $2\pi i \sum_{n=0}^\infty e^a$","['complex-analysis', 'contour-integration']"
86050,Cauchy sequence and convergence,"A sequence is said to be Cauchy sequence if for given any integer n, there exists a positive real number R, such that for any n1, n2 > n, mod{n1th term - n2th term} 1,0,1,0,1,0,1,0........ Now for any integer n,  whenever n1,n2 >n mod{n1th term - n2th term} < or equal to 1.
So as per the definition of a Cauchy  sequence we can say that this sequence is a Cauchy sequence, however, this is not a convergent sequence. How come?
This implies there is gap in my understanding, can anyone kindly point out where am I wrong?. Edited version: A sequence $(a_n)$ is said to be Cauchy sequence if for given any integer $n$, there exists a positive real number $R$, such that for any $n_1, n_2 > n$, $|a_{n_1}-a_{n_2}|<R$. We can prove that every Cauchy sequence is a convergent sequence. Now let us consider the following sequence,
$1,0,1,0,1,0,1,0,\ldots$ Now for any integer $n$,  whenever $n_1,n_2 >n$ we have  $|a_{n_1}-a_{n_2}|\le 1$ . So as per the definition of a Cauchy  sequence we can say that this sequence is a Cauchy sequence, however, this is not a convergent sequence. How come? This implies there is gap in my understanding, can anyone kindly point out where am I wrong?.","['sequences-and-series', 'cauchy-sequences', 'analysis']"
86067,extension to the ball of sphere immersion,"What are the constraints to extend an immersion of the sphere $S^2$ into $\mathbb{R^3}$ to an immersion of the closed unit ball $B(0,1)$ to $\mathbb{R}^3$? Suppose, I get an immersion of $S^2$ into $\mathbb{R^3}$ which is close to $z\mapsto z^3$, where $\hat{\mathbb{C}}$ is identified with $S^2$. Is it possible that it comes from the restriction to $S^2$ of an immersion from the closed unit ball $B(0,1)$ to $\mathbb{R}^3$?","['general-topology', 'differential-topology', 'differential-geometry']"
86073,Geometrically find the center of a pentagon or hexagon,"I wondered, is there a geometrical way to find the center of a pentagon or a hexagon? I'm not talking about equal sides, just polygons with 5 or 6 corners. Like, with a triangle you can take the intersection of two medians to find the center. With a quadrilateral, the center is the intersection of the bimedians . Is it possible to construct the center of pentagons and hexagons in a similar way? Edit: Apparently is rather difficult, so I probably have to settle for a formula to calculate the centroid. I always learned that the $x$ and $y$ values of the centroid are just the mean values of the $x_i$ and $y_i$ values of the corners respectively, but Wikipedia says otherwise ( Wiki ): $C_x = \dfrac{1}{6A} \displaystyle \sum_{i=0}^{n-1} (x_i+x_{i+1})(x_iy_{i+1}-x_{i+1}y_i)$ $C_y = \dfrac{1}{6A} \displaystyle \sum_{i=0}^{n-1} (y_i+y_{i+1})(x_iy_{i+1}-x_{i+1}y_i)$ Where $A = \dfrac{1}{2} \displaystyle \sum_{i=0}^{n-1} (x_iy_{i+1}-x_{i+1}y_i)$ I'm not entirely sure, but wouldn't those $(x_iy_{i+1}-x_{i+1}y_i)$ terms cancel out because you divide by the summation over the same interval? That would leave: $C_x = \dfrac{1}{12} \displaystyle \sum_{i=0}^{n-1} (x_i+x_{i+1})$ which is rubbish, except for when your polygon has 6 corners -- and that's exactly the case on the source from Wikipedia, here . Therefore I wonder, is my math correct and is this formula just a very elaborate way to calculate the centroid of a hexagon ( and no other polygons ), or is it just coincidence? If so, please explain the formula.",['geometry']
86086,"$\left[G:H\cap K\right]=\left[G:H\right]\left[G:K\right]$ if $\left[G:H\right],\left[G:K\right]$ are coprime","Let $G$ be a finite group and $H<G, K<G$. I have shown that $\left[G:H\cap K\right]\leq\left[G:H\right]\left[G:K\right]$ But I do not know where to begin to prove the equality in case these indexes are coprime. I'd appreciate it much if a hint could be given.",['group-theory']
86093,why is ${n+1\choose k} = {n\choose k} + {n\choose k-1}$? [duplicate],This question already has answers here : Proving Pascal's Rule : ${{n} \choose {r}}={{n-1} \choose {r-1}}+{{n-1} \choose r}$ when $1\leq r\leq n$ (12 answers) Closed 7 years ago . Can someone explain to me the proof of $${n+1\choose k} = {n\choose k} + {n\choose k-1}$$?,"['binomial-coefficients', 'combinatorics']"
86094,Sequence Convergence of $\sum_n\frac{(-1)^{n+1}}{3n + n(-1)^n}$,"I have the following series $\displaystyle \sum_{n=1}^{+\infty} \frac{(-1)^{n+1}}{3n + n(-1)^n}$. Does it converge? I wanted to the alternating series test, but that's not easy because of the two $(-1)^n$, plus it's not monotone decreasing. I've split it into two series $n=2n \Rightarrow \sum{-\frac 1 {4m}}\Rightarrow$ diverges, $n=2n+1 \Rightarrow \sum{\frac 1 {2m}}\Rightarrow$ diverges. I can't say diverges + diverges = diverges, but I have this hunch, that the positive series diverges faster than the negative series and therefore it diverges. However, I don't know any test I can do to prove that? Alternating, ratio and root fails. I don't know with what I can compare it to. Thanks in advance for your help!","['convergence-divergence', 'sequences-and-series', 'real-analysis']"
86099,Fixed points of a holomorphic map on a simply connected domain,"Given a holomorphic map $f: \Omega\to \Omega$, where $\Omega$ is a simply-connected domain in $\mathbb{C}$, is the number of fixed points at most $1$ if $f$ is not the identity map? How many could they be? By the Riemann Mapping Theorem, I am able to reduce the problem to finding a fixed point of a holomorphic map from the unit disc to itself. How should I proceed? Thanks.",['complex-analysis']
86107,What are the least sets of generators for $S_n$,"Nearly all the books I read give $S_n$ $(n \geq 2)$ and the generating set $\{(i,i+1) | 1 \leq i < n \}$ as an example when talking about presentation groups. But is $\{(i,i+1) | 1 \leq i < n \}$ the least set of generators, i.e., is the order of any generating set for $S_n$ equal to or greater than $n-1$? If it is the least, how to prove? Are there any other least set of generators? In general, what do these least sets look like? Forgive me for so many questions. Thanks sincerely for any answers or hints.","['finite-groups', 'group-theory', 'symmetric-groups']"
86111,Uniform Lipschitz condition,"Does the function $f(x)=\sqrt{x}\sin(1/x),x\in(0,1],f(0)=0,$ satisfy the uniform Lipschitz condition $|f(x)-f(y)|<M|x-y|^{1/2},M>0$? Any help is appreciated. 
Thanks",['analysis']
86117,"$\mathrm{Ext}^n(\mathcal F, i_*\mathcal G) =\mathrm{Ext}^n(i^*\mathcal F,\mathcal G)$?","Given a closed immersion $i: Z \hookrightarrow X$ a coherent sheaf $\mathcal{F}$ on $X$ and a coherent sheaf $\mathcal{G}$ on $Z$, do we have $\mathrm{Ext}^n(\mathcal{F}, i_*\mathcal{G}) = \mathrm{Ext}^n(i^*\mathcal{F}, \mathcal{G})$? For $n = 0$ it is the usual adjunction, so can we deduce it by the usual ""universal $\delta$-functor"" argument? Consider the exact $\delta$-functors $\mathrm{Coh}(Z) \to (Ab), \mathcal{G} \mapsto \mathrm{Ext}^n(\mathcal{F}, i_*\mathcal{G})$ and $\mathcal{G} \mapsto \mathrm{Ext}^n(i^*\mathcal{F}, \mathcal{G})$ (exact since $i_*$ is exact). They coincide for $n = 0$, so we just have to check if they are both effacable to coincide for every $n$. Could we also derive this using derived categories? Edit: It seems to be wrong: Take $i$ the inclusion of a closed point, then the RHS is always trivial, but I don't think the LHS is. E.g. $\mathrm{Ext}^1(k(x),k(x)) = T_x$ the Zariski tangent space. So where does the above ""argument"" go wrong?",['algebraic-geometry']
86119,Exact definition of convergence,"Let us consider a sequence $x_n$. Now let it converge to a limit $L$.
Now which one of the following is the correct definition of convergence? A sequence  $x_n$ is said to be convergent to a limit $L$ if given any integer $n$ there exists a positive real number  $\epsilon$  such that for all $M\gt n$, $|x_M-L|\lt\epsilon$. A sequence $x_n$ is said to be convergent to a limit $L$ if given any real positive number $\epsilon$ there exists an integer $n$ such that for all $M\gt n$, $|x_M-L|\lt\epsilon$. If the two definitions are equivalent then how to prove it?",['analysis']
86128,"For a topological group $G$ and a subgroup $H$, is it true that $[\overline{H}, \overline{H}] = \overline{[H,H]}$? What about algebraic groups?","When discussing with awllower about this question , I begin to think about another one: For a topological group $G$ and a subgroup $H$, is it true that $[\overline{H}, \overline{H}] = \overline{[H,H]}$? where $[H,H]$ denote the derived subgroups of $H$. I think, if I define the map $\phi: G \times G \rightarrow G, (x,y) \mapsto xyx^{-1}y^{-1}$, then the question will become the equality between $\phi(\overline{H}\times \overline{H})$ and $\overline{\phi(H \times H)}$. Giving $G \times G$ the product topology, we will have $\phi(\overline{H} \times \overline{H}) \supseteq \overline{\phi(H \times H)}$ if $\phi$ is closed; and $\phi(\overline{H} \times \overline{H}) \subseteq \overline{\phi(H \times H)}$ because $\phi$ is continuous. (I hope I am not mistaken in thinking that $\overline{H \times H} = \overline{H} \times \overline{H}$, which is a condition of the above.) So, a derived question is: For a topological group $G$, is the map $\phi: G \times G \rightarrow G, (x,y) \mapsto xyx^{-1}y^{-1}$ closed if $G \times G$ is given the product topology? For the case when $G$ is an algebraic group, the topology will be changed to Zariski topology. Then is $\phi$ a closed map? Does $\phi(\overline{H}\times \overline{H})$ equal $\overline{\phi(H \times H)}$? In fact I am more concerned with the algebraic group case. But if the first case is dealt, hopefully the algebraic case will become easier. Thanks to everyone.","['general-topology', 'topological-groups', 'algebraic-groups']"
86139,"Why is $\mathbb{A}^2$ isomorphic to $\operatorname{Spec}k[x,y]$ as ringed spaces","Suppose that $k$ is an algebraically closed field, and let $\mathbb{A}^2$ denote the affine $2$-space $k^2$. An affine scheme is defined to be a locally ringed space $(X, \mathcal{O}_X )$ which is isomorphic (as locally ringed spaces) to the spectrum of some ring. Then is $\mathbb{A}^2$ an affine scheme? Is it isomorphic (as locally ringed spaces) to the spectrum of the polynomial ring $k[x,y]$? Let $\mathbb{A}^2_k = \operatorname{Spec}k[x,y]$, and $\phi: \mathbb{A}^2 \rightarrow \mathbb{A}^2_k, (a,b) \mapsto \langle x-a, y-b \rangle$, then $\phi$ injects $\mathbb{A}^2$ to the set of maximal ideals of $k[x,y]$, i.e., the set of closed points of $\mathbb{A}^2_k$. I see that $0$, as a prime ideal of $k[x,y]$, is also a point in $\mathbb{A}^2_k$, but it does not lie in $\phi(\mathbb{A}^2)$. The Krull dimension of $k[x,y]$ is $2$, so beside $0$ and maximal ideals, there is still another kind of prime ideals in $k[x,y]$. In fact, any irreducible polynomial $f(x,y) \in k[x,y]$ generates a prime ideal $\langle f(x,y) \rangle$. In a word, $\phi$ is not surjective. Can it still be the map of topological spaces in the isomorphism of ringed spaces? The definition for such isomorphism says that the map of topological spaces should be a homeomorphism. Can a non-surjective map be a homeomorphism? Or, is there any other way to define the map? Thank you very much. Edited : I neglected the condition of $k$ being algebraically closed, and I thought the denotation $\mathbb{A}^2$ is generally known. I add these in the front. Sorry for the misunderstanding :)","['algebraic-geometry', 'schemes']"
86141,Is the limit of a $L^2$-convergent sequence of random variables unique up to a.e.?,"Is the limit of a $L^2$-convergent sequence of random variables unique up to a.e.? In other words, if $X$ and $Y$ are both limits, will $X=Y$ a.e.? If yes, is Ito integral, which is defined as $L^2$ limit of a sequence of Ito integrals of simple processes, defined only up to a.e.? Conversely, if the sequence converges to a random variable $X$, and $Y$ is another random variable same as $X$ a.e., will $Y$ also be the limit of the $L^2$-convergent sequence? Similar questions for a sequence of random variables that converges in probability. Thanks in advance!","['probability-theory', 'real-analysis']"
86168,"How do you show that $\mathbb{Z}[x]/(x^2-29) \cong \{a+b\sqrt{29}|a,b \in \mathbb{Z}\}$?","$\mathbb{Z}[x]/(x^2-29) \cong \{a+b\sqrt{29}|a,b \in \mathbb{Z}\}$. I understand what $\mathbb{Z}[x]/(x^2-29)$ means: that every polynomial that can be factored by $(x^2-29)$ is equal to zero. However, I can't see how you show that isomorphism.","['ring-theory', 'abstract-algebra']"
86173,About the Riemann surface associated to an analytic germ,"I've taken a small course in Riemann surfaces, and there is one part that I still don't understand (and I've been unable to find a reference that explains this rigorously and in detail). It is about the construction of a Riemann surface associated to an analytic germ. By analytic germ we mean a couple $(z_0, (a_n)_{n \in \mathbb{N}})$ where $z_0$ and the $a_i$ are in the complex plane, and the series $\sum a_n (z-z_0)^n$ has strictly positive (but typically finite) radius of convergence. Then (without getting into technical details) the Riemann surface associated to such a germ is the connected component of that germ in the space of all analytic germs, equipped with a certain topology. I get that it defines a Riemann surface. I also understand ""intuitively"" what it does on the classic examples : for example, the Riemann surface associated to $(1,\log)$ is a sort of ""spiral surface"", since when we turn around zero, we add (if turning counter-clockwise) a $2 i \pi$ to the principal determination (so there are countably many sheaves). In the case of the germ of the square root at $z_0=1$, it is a two-sheaves surface. However I have no idea how one would go to determine this properly. In this example, I know that this surface is biholomorphic to $\mathbb{C}$ in the case of the log but I have no idea how to prove that. Can anyone either give me a detailed reference or a sketch of the proof (but with all the key arguments) ?","['geometry', 'riemann-surfaces', 'algebraic-topology']"
86184,How to find irreducible representation of a group from reducible one?,"I was reading this document to answer my question. But after teaching me hell lot of jargon like subgroup, normal subgroup, cosets, factor group, direct sums, modules and all that the document says this, You likely realize immediately that this is not a particularly easy
  thing to do by inspection. It turns out that there is a very
  straightforward and systematic way of taking a given representation
  and determining whether or not it is reducible, and if so, what the
  irreducible representations are. However, the details of how this can
  be done, while very interesting, are not necessary for the agenda of
  these notes. Therefore, for the sake of brevity, we will not pursue
  them. (>_<) I want to learn to do this by hand and then write a program. Please don't ask me to learn GAP or any other software instead. How to find irreducible representation of a group from reducible one? What is that straightforward and systematic way?",['group-theory']
86193,Constructing normalizations of algebraic curves vs constructing Riemann surfaces of functions,"This question is sort of a further extension to this question I have been asking, Relation between n-tuple points on an algebaric curve and its pre-image in the normalizing Riemann surface It seems that there is a method of constructing the Riemann surface of a function and its not clear to me that it is related to the idea of finding a ""normalization"". In the way I see the method of construction of a Riemann surface from a function is roughly like below - First one writes the function $f$ as a polynomial of degree $n$ in (say $x$) whose coefficients are rational functions in say $y$. Then from $\mathbb{P}^1$ one removes the points where the coefficients have poles or where the discriminant of the given function is $0$. Then for any $y_0$ in this punctured sphere there exists an open disk around it such that in that disk one can solve the equation to get $n$ function elements of the form $(x_\mu(y_0),y_0)$ (for $\mu =$ 1,2,...,n) such that $f(x_\mu(y_0),y_0)=0$ These analytic elements can be continued on the sphere by monodromy such that their extension depends only on the homotopy class of the loop in the punctured sphere. Its often not clear in the texts whether after doing this one has to - like in finding of the normalization - create symmetric functions of these local function elements which can be globally defined and unambiguous upto crossing a chosen line which has been removed from the sphere and which passes through all the punctures. What is the correspondence here? Now one is supposed to imagine that these $n$ local function elements are denoting the n-sheets of the Riemann surface over this Riemann sphere. And the removed points on the sphere lead to produce the ramification points of the projection map from the Riemann surface to this sphere. Can anyone kindly make the above step precise? One of the many things that confuses me above the above construction is that it seems to say that if I start with a degree $d$ algebaric curve then I will necessarily get the Riemann surface as a $d$ sheeted cover of $P^1$. But that is possibly not the case. How do the number of sheets get reduced in the above construction? Like I guess it is true that if there is a degree $d$ algebraic curve with a point of multiplicity of $d-2$ then it is necessarily normalized by a hyperelliptic Riemann surface which is necessarily a  $2$ sheeted branched cover of the sphere. One way I can imagine that is as follows - for every point on the Riemann sphere take its image point (under the normalization map) on the algebraic curve and try to pass a line through this point and the multiplicity point. Now this line may or may not pass through another point on the curve depending on whether this  image point is a simple intersection between the curve and the line or a double  intersection. In either case map the point on the Riemann surface to this line and if it happened through a simple intersection then there should exist another  point on the Riemann surface which maps to this same line. The space of lines in  $\mathbb{P}^2$ is $\mathbb{P}^1$ and hence I guess one has realized the Riemann surface as a ramified two sheeted cover of the sphere. (Though I don't know how to establish holomorphicity of this ramified covering map) But doing the initial kind of argument one would have thought that one is getting a $d$ sheeted cover of the sphere! Can someone kindly help reconcile these two points of view?","['differential-geometry', 'riemann-surfaces', 'algebraic-geometry', 'complex-analysis']"
86196,"Find the number of all four-digit positive integers that are divisible by four and are formed by the digits 0,1,2,3,4,5","Find the number of all four-digit positive integers that are divisible by four and are formed by the digits 0,1,2,3,4,5. The combination for all numbers would be $6^4$, but we have a few roadblocks to account for.  First off 0 must be taken into account.  If 0 were to be the first number it would only be a three digit number therefore: $6^4-6^3=1080$ So we know that the number of possibilities that are divisible by 4 is less than 1080. This is where I get stuck.  We must account for the numbers that are divisible by 4.  For a four digit number we have four place holders _ _ _ _.  The first two placeholders do not matter.  So for those locations we can denote $6^2$. However I must account for the first placeholder.  0 cannot be a placeholder, so I'm not sure how to denote its possibility from here.  I have a two element variation with repetition from {0,1,...5}.  But I must account for the zero.  If I simply had two variations that did not account for zero it would be $6^2$.  So is it possible for me to  use the same approach I used earlier? $6^2-6^1$ The last two placeholders determine divisibility.  In order for the four-digit number to be divisible by 4 the number created by the last four digits must also be divisible by 4. From 0,1,2,3,4,5,6 we have $4,8,12,16,20,24,28,32,36,40,44,48,52,56$ and from those selections we have
$04,12,20,24,32,40,44,52$ which gives us 8 possibilities. I'm a little confused when to use the multiplication rule so I'm not sure if this is acceptable. If my work is right would $(6^2-6)*8$ be the correct answer? $(6^2-6)*8 = 240 < 1080$","['elementary-number-theory', 'combinatorics']"
86202,"$\mathcal{L}$ is very ample, $\mathcal{U}$ is generated by global sections $\Rightarrow$ $\mathcal{L} \otimes \mathcal{U}$ is very ample","Let $\mathcal{L},\mathcal{U}$ be invertible sheaves over a
noetherian scheme $X$, where $X$ is of finite type over a noetherian
ring $A$. If $\mathcal{L}$ is very ample, and $\mathcal{U}$ is
generated by global sections, then $\mathcal{L} \otimes \mathcal{U}$
is very ample. Since $\mathcal{L}$ is very ample, there exists $n$, s.t. $i:
X\mapsto \mathbb{P}^n$ is an immersion with $\mathcal{L}=
i^*\mathcal{O}(1)$, and since $\mathcal{U}$ is generated by global
sections, one can construct $j:X \to \mathbb{P}^m$ with
$j^*\mathcal{O}(1) = \mathcal{U}$. From this I can construct the
following morphism: $$
h: X \xrightarrow{\Delta} X\times X \xrightarrow{i\times j}
\mathbb{P}^n \times \mathbb{P}^m \xrightarrow{ \operatorname{segre \
embedding}} \mathbb{P}^N $$ I can prove $\mathcal{L}\otimes \mathcal{U } \cong
h^*\mathcal{O}(1)$, and the segre embedding is a closed immersion.
But I don't know whether the map $(i\times j) \circ \Delta$ is an
immersion, which is suspicious to be such, especially for the
$\Delta$.",['algebraic-geometry']
86209,Steinhaus theorem (sums version),"This is a question from Stromberg related to Steinhaus' Theorem: If $A$ is a set of positive Lebesgue measure, show that $A + A$ contains an interval. I can't quite see how to modify the Steinhaus proof though.","['measure-theory', 'real-analysis']"
86213,Finite Simple Groups gap recently filled,"The recent paper,
""Aftermath,"" by
Peter Cameron ( arXiv:1111.4050v1 ), contains this remark concerning
the classification of the finite simple groups: The Classification of Finite Simple Groups [16] is the greatest collaborative effort ever in mathematics, running to about 15000 journal pages. (Ironically, although the theorem was announced in 1980, the proof contained a gap which has only just been filled.) Can someone explain (at a high level) what was the gap and who filled it?
(Cameron gives no reference.)  Thanks!","['finite-groups', 'group-theory']"
86220,"showing that $g=0$ almost everywhere on $[0,1]$","Let $g \in L^1[0,1]$. Suppose that given any pair of rationals $0\leq p\lt q \leq 1$, we have $$\int_p^q g(x) d\mu=0.$$ 
Please I would like help in showing that $g=0$ almost everywhere on $[0,1]$.",['measure-theory']
86222,"What is, how do you use, and why do you use differentials? What are their practical uses?","What is a differential? And how is it useful? What is its practical use? For example, in Electromagnetic Wave Theory as it pertains to diffraction gratings, we have an equation like this one: $$d_s\sin(\theta) = m\lambda.$$ (Not important, but in case you're curious: $d_s$ is the distance between slits in the grating, $\theta$ is an approximate angle at which light bends through each slit of the grating, $\lambda$ is the wavelength of the light passing through the gradient, and $m$ is the number of wavelengths by which distances traveled by one ray from one slit differ from an adjacent slit.) My physics book says that the differential of the above mentioned equation is $$d_s \cos(\theta)d\theta = md\lambda$$ (without confusing the single $d_s$ (distance) with the ones in $d\theta$ and $d\lambda$). What does this mean and how is it useful? I am trying to understand the concept behind the differentials more so than the physics so that I may later make sense of the physics. EDIT: In user6786's question , user6786 states that ""according to the formula $dy=f'(x)dx$ we are able to plug in values for $dx$ and calculate a $dy$ (differential)"". I'm trying to see how that works.","['ordinary-differential-equations', 'calculus']"
86228,Divide by a vector?,"When doing matrix multiplication can I carry a vector to the other side? For example if I have: $Ab = c$ where A is m by m invertable matrix, and b is m by 1 col vector, c m by 1. Can I do something like this: $A = c/b$ And what does that mean... I just need to find matrix A, as I have b and c vectors. P.S. Also, I know that inverse(A) is diagonal. If it helps.",['linear-algebra']
86238,Is there any relation between the principal eigenvalue of sub matrix and the original matrix?,"I am wondering whether there is any relation between principal eigenvalue of sub matrix and the original matrix. In fact I am facing a problem which is to select $n$ rows and $n$ columns from the original non-negative matrix to construct a new matrix. The principal eigenvalue of the small matrix selected need to be close to certain constant. I have totally no idea how to start... I guess figuring out the relation maybe a good starting point of this problem. UPDATE: I set up a conceptual optimization problem, hope this can help on the understanding of my problem. $\min |\max (xAx')-\lambda^*|$ s.t. $\lVert x\rVert_2=1$ $x_i=[w_iv_i]$ $v_i>0$ $w_i=\{0,1\}$ $\sum_i w_i=n$ $A$ is the original matrix, $n$ is the number of rows/columns I used to construct the small matrix, $\lambda^*$ is the target constant of the principal eigenvalue of small matrix. What I want to know is the $w$ vector","['optimization', 'matrices', 'spectral-graph-theory', 'eigenvalues-eigenvectors']"
86244,Determinant of a generalized Pascal matrix,"Let $M$ denote the infinite matrix defined recursively by $$
M_{ij} = 
\begin{cases}
  1, &  \text{if } i=1 \text{ and } j=1; \\
  aM_{i-1,j}+bM_{i,j-1}+cM_{i-1,j-1}, & \mbox{otherwise}.\\ \end{cases}
$$
($M_{i,0}$ and $M_{0,j}$ are both defined to be $0$.) ( Added : I just discovered that the numbers in the $M$ matrix are called weighted Delannoy numbers .) Let $M_n$ denote the $n \times n$ upper-left submatrix of $M$. For example, with $a = b = c = 1$, $M_1 = \begin{bmatrix} 1 \end{bmatrix}$, $M_2= \begin{bmatrix} 1 & 1 \\ 1 & 3 \end{bmatrix}$, and $M_3 = \begin{bmatrix} 1 & 1 & 1 \\ 1 & 3 & 5 \\ 1 & 5 & 13 \end{bmatrix}$, and $M_4 = \begin{bmatrix}
  		1 & 1 & 1 & 1 \\
  		1 & 3 & 5 & 7 \\
  		1 & 5 & 13 & 25 \\
  		1 & 7 & 25 & 63
  	\end{bmatrix}.$ A few years ago one of my students proved, by induction, that $$\det M_n = (ab+c)^{n(n-1)/2}.$$ My question is Is there a noninductive proof that $\det M_n = (ab+c)^{n(n-1)/2}$ that gives more insight into why the determinant works out so nicely? For example, when $a = b = 1$, $c = 0$, $M$ is the symmetric Pascal matrix .  I've seen more than one way to prove that $\det M_n = 1$ in this case.  For example, Edelman and Strang give four proofs of an LU-decomposition that does it.  I also once saw, at a conference, a combinatorial proof using the interpretation of the determinant in terms of nonintersecting paths in a directed graph.  (I think the talk was given by Art Benjamin, but it was several years ago, and I may be misremembering.)  So I know that there are some nice proofs in the special case of the Pascal matrix.  But what about the general case?","['matrices', 'linear-algebra', 'determinant', 'combinatorics']"
86248,IVP: error in initial conditions,"For an IVP $y' = f(x,y)$, with initial condition $y(x_0) = \alpha$, can something be said about how large the error at $x_1$, $x_1 > x_0$, is going to be if instead we had started with the initial condition $y(x_0) = \alpha + h$ for a small $h$? Of course, I'm assuming both solutions guaranteed by the Existence-Uniqueness theorem extend to $x_1$.","['ordinary-differential-equations', 'numerical-methods']"
86249,"Number of subsets of $\{1,2, \ldots, n\}$ containing no three consecutive integers: recurrence equation?","I'm thinking about the problem below. I know that I have to find a polynomial formula for that first, and then from that polynomial formula I can find the recurrence relation. I actually attempted finding a polynomial formula, but I think I'm leaving some options while thinking about three consecutive integers. Anyway, without further ado, here is the problem and your suggestions are appreciated: Let $f_n$ be the number of subsets of $\{1,2,3,\ldots, n\}$ that contain no three
  consecutive integers. Find a recurrence for $f_n$.","['recurrence-relations', 'discrete-mathematics']"
86263,Characteristic of a field is $0$ or prime [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question I'm trying to prove that the characteristic of any field $F$ is either $0$ or a prime number, but I have no idea what to do.  Help?","['abstract-algebra', 'field-theory']"
86271,Show that $\mathbb{R}\oplus\mathbb{R}$ is not ring isomorphic to $\mathbb{C}$.,Show that $\mathbb{R}\oplus\mathbb{R}$ is not ring isomorphic to $\mathbb{C}$. This is my first abstract algebra class and therefore if the explanation could be kept as simple as possible that would be very much appreciated. I dont even know how to approach this problem.,['abstract-algebra']
86309,what is the geometrical interpretation to positive definite matrix,"What is the geometrical interpretation of positive definite matrix ?
(not necessarily symmetric) if $A$ is positive definite, what does it do to a vector $x$ (i.e. $Ax$)?","['linear-algebra', 'intuition']"
86316,Is this matrix obviously positive definite?,"Consider the matrix $A$ whose elements are $A_{ij} = a^{|i-j|}$ for $-1<a<1$ and $i,j=1,\dots,n$ . E.g., for $n=4$ , the matrix is $$A = \left[
\begin{matrix}
1 & a & a^2 & a^3 \\
a & 1 & a & a^2 \\
a^2 & a & 1 & a \\
a^3 & a^2 & a & 1
\end{matrix}
\right]$$ Is this matrix always positive definite? If so, what is the simplest way to see that? I strongly suspect that the matrix is positive definite for all $n$ and $a$ , but am having trouble coming up with a proof. Extra credit: The eigenvalues seem to lie within an interval $[\lambda_{\rm min}, \lambda_{\rm max}]$ which is a function of $a$ but not of $n$ . For example, for $a=1/2$ all eigenvalues lie in $[1/3, 3]$ . Is it true for for general $a$ , the eigenvalues lie in $[\lambda(a)^{-1}, \lambda(a)]$ ? If so, what is $\lambda(a)$ ? Also, the eigenvectors seem to have a particularly regular form. In particular, they look like that could be expressed as simple combinations of trigonometric functions. Is this the case?","['positive-definite', 'symmetric-matrices', 'matrices', 'linear-algebra', 'toeplitz-matrices']"
86322,Trying to define the inverse function of the cartesian product,"This question must have been asked before but I couldn't find it anywhere. Defining a mapping from two sets to the set of their Cartesian product seems seems pretty easy, unless I'm completely wrong: $$f(A,B) = \{(a,b) \mid a∈A, b∈B\}$$ My question is - how do I define the inverse function?  I want to define a function that takes a set of ordered pairs and returns the original sets. The process is clear to me, but I find it hard writing it mathematically. Also what is a little unclear to me is the idea of inverting a pairing function: it takes two parameters and return one, so when you invert it you have two solutions from one parameter. How is it not a problem? Hope I was clear, thanks in advance.","['elementary-set-theory', 'functions']"
86331,How can I compare two matrices?,"I have a matrice A. It is model probability matrice for some process (Markov chain). Then, I have estimated matrice B. I have to somehow compare these two matrices to tell whether process that gave matrice B in result matches model matrice A.
How can I do this? I would like to have some parameter to change a tollerancy for difference. I need at least three different methods so I can compare their results. Those matrices are stochastic matrices. Their size is n x n. I don't know how to put this. I have two series of observations of state. One is a ""model"" and for other I need to decide if it matches the ""model"". From two different series of state observations I estimate ""model"" matrice A and matrice B.
Then I need to check if process that resulted in matrix B is the same process that gave model matrice A. Please, see my new question How can I compare two Markov processes?","['matrices', 'markov-chains']"
86332,Example of a non-algebraic $\ell^2$-function in two variables,"Let's call an $\ell^2$-function $\mathbb{N} \times \mathbb{N} \to \mathbb{C}$ algebraic if it is in the image of the natural algebra homomorphism $\ell^2(\mathbb{N}) \otimes \ell^2(\mathbb{N}) \to \ell^2(\mathbb{N} \times \mathbb{N})$, where on the left hand side we consider the usual, non-completed tensor product. In other words, $f(m,n)$ is algebraic iff it may be written as $\sum_{i=1}^{k} g_i(m) h_i(n)$ for some $k \in \mathbb{N}$ and $\ell^2$-functions $g_i,h_i$. Probably there are abstract reasons for the existence of non-algebraic functions. But I would like to know an explicit example of an $\ell^2$-function together with a concise and complete proof that it is not algebraic. For example: Question . Can you give a proof that the $\ell^2$-function $(n,m) \mapsto \dfrac{1}{2^{n \cdot m}}$ is not algebraic?","['tensor-products', 'hilbert-spaces', 'functional-analysis', 'functions']"
86340,How can I compare two Markov processes?,"There is a discrete-time irreductible Markov process with $r$ possible states.    $k$ observations were performed. At each observation a state of process was determined. $T_0 = \lbrace 0,1,\dots ,k-1\rbrace$ $T_1 = \lbrace 1,2,\dots ,k-1\rbrace$ $n_i(t) = 1$ means that process was in state $i$ at time $t$, ($t \in T_0$), $n_i(t) = 0$ otherwise, $v_{ij}(t) = 1$ means that process changed from state $i$ to state $j$ between time $t-1$ and $t$, ($t \in T_1$), 
$v_{ij}(t) = 0$ otherwise. I estimate probability of transition from state $i$ to state $j$ as $\hat{p}_{ij} = \frac{\displaystyle\sum_{t \in T_1}v_{ij}(t)}{\displaystyle\sum\limits_{t \in T_1}n_i(t-1)}$ First question: How many observations do I need to properly estimate transition matrix? If $p_{ij}$ is an ideal estimation, I don't want relative error between $\hat{p}_{ij}$ and $p_{ij}$ ( $\frac{|\hat{p}_{ij}-p_{ij}|}{p_{ij}}$ ) to be more than $\varepsilon = 0.01$ with probability $P \ge 0.99$. I need this in form $k=k(r,\varepsilon, P)$. I know that the  number will be large but this does not matter. I just want to know the number. For my purposes $r$ will be between 7 and 15, $\forall_i p_{ii} \neq 1$. If there would be a state $i$ that was never entered or was entered at the last step (what could be written as $\sum\limits_{t \in T_1}n_i(t-1)=0$), I will just simply exclude that state from further calculations. Second question: I have first transition matrix $A$. That matrix describes ""model"" process and was estimated with sufficient number of observations.
Then, second process was observed and new matrix $B$ was estimated (with sufficient number of observations). How can I decide if second process matches ""model"" process?
I want this method to have an ""error factor"" (I don't know how to name it) witch changeable value $\varphi$.
I need 3 or 4 of those methods for comparison.","['matrices', 'markov-chains', 'parameter-estimation']"
86352,How do you factor $x^3-3x^2+3x-1$?,"$$x^3-3x^2+3x-1?$$ I know this may seem trivial, but I, for the life of me, I cannot figure out how to factor this polynomial, I know that the root is $$(x-1)^3=0$$ because of wolframalpha, but I don't know how to get there. any help would be greatly appreciated. and also if you have any recommended web sites that help with higher order polynomial factoring that would be extremely helpful.","['factoring', 'algebra-precalculus', 'polynomials']"
86357,Does an uncountable discrete subspace of the reals exist?,Does an uncountable and discrete subspace of the reals exist?,['general-topology']
86381,What is the property of the function corresponds to this definition?,"$\exists \epsilon>0$ $\forall\delta>0: |x-x_0|> \delta \to $ $|f(x) - f(x_0)| < \epsilon$ It is very similar to the continuity of the function at a point, but it is not it.
I hope for your help! P.S. Sorry for my bad English.",['functions']
86383,"Proving $2,3,1+\sqrt{-5}$ and $1-\sqrt{-5}$ are irreducible in $\mathbb{Z}[\sqrt{-5}]$","Could anyone help me prove that $2,3,1+\sqrt{-5}$ and $1-\sqrt{-5}$ are irreducible in $\mathbb{Z}[\sqrt{-5}]$? As $6=2*3=(1+\sqrt{-5})(1-\sqrt{-5})$ so $\mathbb{Z}[\sqrt{-5}]$ is not a UFD. Therefore is not a PID or euclidean domain","['ring-theory', 'abstract-algebra']"
86395,Infinite product of connected spaces may not be connected?,"Let $X$ be a connected topologoical space. Is it true that the countable product $X^\omega$ of $X$ with itself (under the product topology) need not be connected? I have heard that setting $X = \mathbb R$ gives an example of this phenomenon. If so, how can I prove that $\mathbb R^\omega$ is not connected? Do we get different results if $X^\omega$ instead has the box topology?","['general-topology', 'connectedness', 'box-topology', 'product-space']"
86398,Does the completeness of a normed vector space only depend on its topology?,"Let $V \space$ be a vector space over $\mathbb{R}$, and $\Vert \cdot \Vert_1$, $\Vert \cdot \Vert_2$ norms over $V$, which generate the same topology. Is it always true that if $v_n$ is a Cauchy sequence with respect to both norms, and $v_n$ converges in $(V, \Vert \cdot \Vert_1)$ then it converges in $(V, \Vert \cdot \Vert_2)$?
If $dim(V)<+\infty$ the assertion is true, because there exist constants $c,C\in\mathbb{R}$ such that $\forall v\in V \space$ $c\Vert v \Vert_1 \leq \Vert v \Vert_2 \leq C\Vert v \Vert_1$, but I have a feeling it isn't in general (this would be strange, since completeness isn't a topological property; however maybe the additional structure of vector space might be used in some way). EDIT Thanks to everyone's answers I have realized that the above question was badly stated to begin with. What I meant to ask was whether the property of a normed vector space of being complete only depends on the topology generated by the norm, and not by the norm itself. As stated indirectly by many users, convergence, unlike the property of being a Cauchy sequence, is a topological property. Therefore the answer to the question I actually asked is always affermative. What I should have asked was: given two topologically equivalent norms $\Vert \cdot \Vert_1$, $\Vert \cdot \Vert_2$ on a vector space V, is it true that a sequence $v_n$ is a Cauchy sequence in $(V, \Vert \cdot \Vert_1)$ if and only if it is in $(V, \Vert \cdot \Vert_2)$?","['general-topology', 'convergence-divergence', 'banach-spaces', 'real-analysis']"
86400,Labelling the Nodes of a Hypercube,"I'm trying to find out how many ways can I label the nodes of a n dimensional hypercube.
The nodes of a n dimensional hypercube can be labelled from 0 to (2^n - 1) in such a way that there is an edge between any two vertices if and only if the binary representations of their labels differ by one and only one bit. It seems there are a lot of ways to label such a hypercube, but I'm having a hard time formulating it. I would appreciate your help.","['graph-theory', 'combinatorics']"
86416,How to find the probability of truth?,"A and B are independent witness in a case. The probablity that A
  speaks the truth is 'x' and that of B is 'y'.If A and B agree on a
  certain statement, how to find the probability that the statement is
  true ?",['probability']
86419,Coincidences with orders of simple groups,"The projective special linear groups $PSL(2,4)$, $PSL(2,5)$ and $PSL(2,9)$ have the property that their orders equal the order of an alternating group. They are also isomorphic to the respective alternating groups. In this case, we have that $|PSL(2,4)| = |PSL(2,5)| = |A_5|\ $ and $|PSL(2,9)| = |A_6|$. Let $F$ be a finite field. The order of $|PSL(2,F)|$ is given by $(2^n - 1)2^n(2^n + 1)$ when $F$ is of characteristic $2$. Otherwise it is equal to $\frac{1}{2}(p^n - 1)p^n(p^n + 1)$, where $p$ is the characteristic of $F$. I've been wondering about the following question: when is $|PSL(2,F)| = |A_k|$? In other words, for which $n$ and $k$ the equations \begin{align*}
& 2^{n+1}(2^n - 1)(2^n + 1) = k!\\
&(p^n - 1)p^n(p^n + 1) = k! \text{, where p is an odd prime}
\end{align*} have solutions? Are there only finitely many solutions? And to generalize, what about $PSL(m, F)$?","['elementary-number-theory', 'group-theory', 'simple-groups']"
86424,Is hypothesis testing at $\alpha=0$ possible?,"A while back I've asked a question on the relationship of the total variation distance between probability measures to hypothesis testing and got a very nice answer.  I understand that that answer gives a trade-off relationship between the probability of type I error (false positive) $\alpha$ and a type II error (miss) $\beta$, similar to what Neyman-Pearson lemma provides. Within the Neyman-Pearson framework, one can set $\alpha$ arbitrarily close to 0 at the expense of the power of the statistical test $1-\beta$, however, as far as I understand, one can not set $\alpha=0$. I am wondering if there are non-trivial hypothesis tests out there allow one to set $\alpha=0$.  I haven't encountered one in my reading.  My intuition tells me that there aren't because 1) a hypothesis test must be a threshold-based test; and 2) as long as the probability distributions associated with the hypotheses are different, any non-trivial threshold test (i.e. a test that doesn't always accept the null hypothesis) has some finite chance of falsely rejecting the null hypothesis. However, I thought I'd ask the experts here whether my intuition, and the reasoning behind this intuition, is correct.  Perhaps there are statistical hypothesis tests not based on thresholds out there...","['statistics', 'hypothesis-testing', 'statistical-inference']"
