question_id,title,body,tags
3583457,"How to calculate the tangent line of $\ln(x)$ through $(2,6)$ by hand?","I came up with my own question for a tutor student, but now I am stuck myself. The exercise was to calculate the equation of a tangent-line of $f(x) = \ln(x)$ , which goes through the point $(2,6)$ .
I'm trying to solve the problem by hand, but the equations I get to solve the problem aren't solveable with the lineair algebra I'm aware of. Is this right, or am I missing something? Representation of the problem, where the green line represents $\ln(x), A = (2,6)$ and the black line is the unknown which should be calculated:","['tangent-line', 'derivatives', 'logarithms']"
3583488,Why are these two definitions of a connection equivalent?,"I'm working through Kai Köhler's ""Differentialgeometrie und homogene Räume"" (Differential geometry and homogenous spaces) and struggle to understand the notion of a connection on a vector bundle. In particular, I do not completely understand why two definitions are equivalent. The main definition that the author gives is the following: Let $ E \to M$ be a vector bundle. A (covariant) connection $\nabla$ on $E$ is a $\mathbb{R}$ -linear map $\nabla:\Gamma(M,E)\to \Gamma(M,T^*M \otimes E)$ , that satisfies Leibniz's rule: $\forall f\in C^\infty(M),s\in \Gamma(M,E): \nabla(f\cdot s) = df \otimes s + f\nabla s$ . Apparently, it is equivalent to ask for $\nabla$ to be a map $\nabla:\Gamma(M,TM) \times \Gamma(M,E) \to \Gamma(M,E)$ , that is $C^{\infty}$ -linear in the first and satisfies the Leibniz rule in the second argument. Why does this hold? Also, what is a good intuition to think about $df \otimes s$ ?","['connections', 'vector-bundles', 'differential-geometry']"
3583546,"If you equip two isomorphic groups with homeomorphic topologies, are they isomorphic as topological groups?","I'm wondering if anyone has any insight regarding the truth of the above statement. Intuitively, if I have two topological groups in which their algebraic group structures are the same up to relabelling, and toplogical spaces that behave the same, it seems as though as topological groups they would have the same structure and behaviours, up to relabelling of course. Or is there an obvious counterexample that I'm missing? I've seen a similar question posted with a counterexample, however I believe that the counterexample proposed did not accurately satisfy the hypothesis.","['general-topology', 'topological-groups', 'algebraic-topology', 'group-isomorphism']"
3583590,Lower Dimensional Scalar Densities on a Manifold,"On a smooth $n$ dimensional manifold $M$ , it is possible to define a smooth scalar density as a pointwise-defined function $s$ which takes $n$ vector fields $X_1, \dots, X_n \in \Gamma(TM)$ , and return a $C^\infty(M)$ function $s(X_1, \dots, X_n)$ , such that for any section $A$ of $\text{End}(TM)$ (i.e. a map which associates with each point $p$ a endomorphism $A_p$ of $T_pM$ in a smooth manner), $$ s(AX_1, \dots, AX_n) = |\det(A)| \cdot s(X_1, \dots, X_n). $$ Intuitively $s$ can be viewed as assigning a volume to each $n$ dimensional paralleliped in space. Naturally, they are the core objects which can be integrated on a manifold (differential forms allow integration on an oriented manifold). One can form a one dimensional vector bundle $\xi$ whose sections are precisely the scalar densities. My question is whether there exists a similar construction which enables one to integrate on lower dimensional submanifolds. In particular, given a pointwise defined function $s$ which takes $k$ vector fields $X_1, \dots, X_k \in \Gamma(TM)$ , and spits out a $C^\infty(M)$ function, what properties should $s$ have in order for us to consider it as a natural way of measuring the area of $k$ dimensional paralleliped's on the tangent space to $M$ . One such property that should be true is that for any constants $$ \{ a_{ij} : i,j \in \{ 1, \dots, k \} \} $$ and any vector fields $X_1, \dots X_k \in \Gamma(TM)$ , we should have $$ s \left( \sum_i a_{1i} X_i, \dots, \sum_i a_{ki} X_i \right) = |\det(a_{ij})| \cdot s(X_1, \dots, X_k). $$ Certainly, if $N$ is a $k$ dimensional submanifold, then a function $s$ with this property restricts to a scalar density for vector fields $\Gamma(TN)$ , and can therefore be integrated on $N$ . But this doesn't seem like the only property that is necessary, since the family of functions at each point with this property is infinite dimensional (consider the case $k = 1$ where $s$ is simply a seminorm chosen smoothly on each tangent space, and there are infinitely many seminorms). Thus it seems unlikely we can make a vector bundle whose sections are precisely the ' $k$ dimensional' scalar densities. What further properties are needed?","['general-relativity', 'differential-geometry']"
3583603,Expectation of product of quadratic forms in Gaussian distribution,"Let $x \in \mathbb{R}^n$ be a random vector with i.i.d. entries distributed as $\mathcal{N}(0, 1)$ .  Let $A, B$ be two $n \times n$ symmetric matrices.  I would like to find $\mathbb{E} (x^T A x) (x^T B x)$ .","['expected-value', 'probability-distributions', 'normal-distribution', 'probability']"
3583657,Can every natural number be written as a sum of signed odd squares?,"Let $c_n \in \{ -1,1\}$ . Here , it is stated that every natural number may be written as $$\sum c_kk^2$$ Where $k$ runs from $1$ to some finite number. I am wondering whether every natural number $n$ can be written as follows: $$n = \sum c_n(2k-1)^2.$$ In other words, can every natural number be written as the sum of the first so-and-so signed odd squares? Obviously, $1=1^2$ . However, even to find such a writing of $2$ , I needed eight squares: $$2=1+9+25-49+81-121-169+225$$ And could not find one for $3$ . Any insight would be appreciated.","['number-theory', 'sums-of-squares', 'elementary-number-theory', 'sequences-and-series']"
3583677,Function with two conditions,"I need a function that fulfills these two conditions: $$
y'(0) = 1
$$ $$
\lim_{x\to\infty} y(x) = 70
$$ This results in a function that has two tangents: $y=x$ (blue) and $y=70$ (purple) I have already figured out one function that fulfills both conditions: $y=\frac{70x}{x+70}$ (red) The problem is that this function is too ""slow"" for my application. Is there any preferably simple equation that keeps the function's starting slope near 1 for a longer time so it ""reaches"" its limit (70) quicker? I made a quick drawing of what I mean: The function will never receive negative $x$ values, so the part left of the y-axis doesn't matter. The function should never cross any of its tangents.","['trigonometry', 'tangent-line']"
3583695,How is $\cos2\theta = \cos^2\theta- \sin^2\theta$?,"On Khan Academy in this video at 3:53 minutes in, Khan uses the equation $\cos2\theta = \cos^2\theta- \sin^2\theta$ , where can I view the proof for this statement? (He doesn't explain this part in that particular video)",['trigonometry']
3583713,simple Application of Gram-Schmidt Orthogonalization,"I wanted to apply the Gram-Schmidt orthogonalization to the following simple example of polynomials $1,x,x^2,x^3$ in $L^2[-1,1]$ , is it correct? $e_1 = 1$ $e'_2 = x - \int_{-1}^{1}xdx = x \implies e_2 = \frac{x}{\|x\|}$ $e'_3 = x^2 - \int_{-1}^{1}x^2dx -\int_{-1}^{1}x^2xdx = x^2 - \frac{1}{2} \implies e_4 = \frac{x^2 - \frac{1}{2}}{\|x^2 - \frac{1}{2}\|}$ $e'_4 = x^3 - \int_{-1}^{1}x^3dx -\int_{-1}^{1}x^3xdx -\int_{-1}^{1}x^3x^2dx = x^3 - \frac{2}{5} \implies e_3 = \frac{x^3 - \frac{2}{5}}{\|x^3 - \frac{2}{5}\|}$","['orthonormal', 'analysis', 'solution-verification', 'linear-algebra', 'functional-analysis']"
3583727,A base for the closed sets in a topological space $ X $,"A base for the closed sets in a topological space $ X $ is a family of closed sets in $ X $ , such that every closed set is an intersection of some subfamily. $   \mathcal{F}$ is a base for  the closed sets in $ X $ iff the familily of complements of members of $  \mathcal{F}$ is a base for the open sets. $ \mathcal{F} $ is a base for  the closed sets for some topology on $ X $ iff (a) whenever $ F_{1} $ and $ F_{2} $ belong to $\mathcal{F} $ , $ F_{1} \cup F_{2} $ is an intersection of elements of $ \mathcal{F} $ , and (b) $ \bigcap_ {F \in \mathcal{F}} {F} = \emptyset $ I have been demonstrating this problem directly using the definition of base and assuming that a base for closed sets in a topological space $ (X, \tau) $ is a family of closed sets in $ (X, \tau) $ , however, I have had difficulties reaching the desired result. I have also tried for reduction to the absurd, but the test turns out to be a bit cumbersome.",['general-topology']
3583728,"Let $f(x)=ax^2+bx+c$, $a, b, c \in I$. Let $f(1)=0$, $f(7)\in (50,60)$ and $f(8)\in (70,80)$, then find the range of $f(2)$","OPTIONS A) $(-2,0)$ B) $(0,10)$ C) $(1,12)$ D) $(20,30)$ From the first part, it is clear that $$a+b+c=0$$ And $$49a+7b+c\in (50,60)$$ $$64a+8b+c\in (70,80)$$ Subtracting them $$15a+b\in (10,30)$$ While adding them gives $$113a+15b+2c\in (120,140)$$ $$111a+13b\in (120,140)$$ But we have to find the range of $$4a+2b+c$$ $$=3a+b$$ What should I do next?",['functions']
3583740,Verifying a continued fraction related to $\log\varphi$.,"The continued fraction is the following, $${1+\cfrac{1\cdot 2}{3\varphi+\cfrac{1\cdot 2}{5+\cfrac{3\cdot 4}{7\varphi+\cfrac{3\cdot 4}{9+\ddots}}}}}=\frac{2}{3\log\varphi}\tag{1}$$ where $$\varphi=\frac{1+\sqrt{5}}{2},$$ something with I found in an aside [backside] of my previous notes where I kept my recreational math works. So can the closed form be verified in any sort (most preferably by using already established identities)?","['golden-ratio', 'number-theory', 'continued-fractions']"
3583759,Does Ricci flow preserve symmetries?,"What does the following sentence mean: (see p.66 The Ricci Flow in Riemannian Geometry By Ben Andrews, Christopher Hopper ) The Ricci flow preserves any symmetries that are present in the initial metric. What I understand is ${\rm Isom}(g_0)={\rm Isom}(g_t)$ $\forall t$ . or ${\rm Isom}(g_0)\leq{\rm Isom}(g_t)$ $\forall t$ . How to prove that? or any reference containing proof?","['ricci-flow', 'reference-request', 'differential-topology', 'symmetry', 'differential-geometry']"
3583764,Solving differential equation using an integrating factor,"The equation is as follows: $$(\cos(x)e^x+xy+4y^2-y)dx+(-x-8y)dy=0$$ I have worked out that it isn't exact and I have worked out the integrating factor to be $e^x$ I have then multiplied the original equation by $e^x$ to get $$(\cos (x)e^{2x}+xye^x+4y^2e^x-ye^x)dx+(-xe^x-8ye^x)dy=0$$ I am stuck trying to find the solution in terms of $f(x,y)=c$",['ordinary-differential-equations']
3583802,"Bijection from union of two finite, disjoint sets A, B to {1,2,...,|A| + |B|}","A and B are disjoint, finite sets. The goal is to prove that $|A\cup B| = |A|+|B|$ using a bijection from $A\cup B$ to $\{1,2,...,|A|+|B|\}$ . Its easy to begin with:
let $x \in A\cup B$ . However trying to determine a function that takes any value in $A$ or $B$ and outputs ordered natural numbers is proving difficult. My first attempt at the function gave me $f(x) = \begin{array}{ll}
      x & x \in A \\
      x+|A| & x\in B\\
\end{array} $ But this clearly doesn't yield $\{1,2,3,...,|A|+|B|\}$ , but $\{x_{a_1},x_{a_2},x_{a_3},...,x_{a_n},x_{b_1}+|A|,..., x_{b_m}+|A|\} $ Ideally I would just use: $f(x) = \begin{array}{ll}
      i & x \in A \\
      i+|A| & x\in B\\
\end{array} $ where $i$ is the index location of $x\in A$ or $x\in B$ , but I cannot find an example of a similar notation that could apply to any arbitrary finite set.","['elementary-set-theory', 'cardinals', 'functions']"
3583805,An explicit bijection between $\mathbb{Q}^+$ and $\mathbb{Q}$?,"I was trying to show that $\vert \mathbb{Q}^+\vert=\vert \mathbb{Q}\vert$ . An injection is so easy to find, but I’m having amhard time finding a surjection. Also, I don’t think there’s a similar question on stackexchange now...","['elementary-set-theory', 'real-analysis']"
3583829,Is $(f+g)x=f(x)+g(x)$ always true?,"My Attempt: 
If Variable is same then $$(f+g)x=f(x)+g(x)$$ it's always true.
Thanks in Advance..",['functions']
3583841,Generalized Least Squares results,"So, I've got the next problem: Let $Y\sim N_n(X\beta, \sigma^2 V)$ . Prove that, if $\hat{\beta} = (X^{\prime}V^{-1}X)^{-1}X^{\prime}V^{-1}Y$ then: $SSR = (Y-X\hat{\beta})^{\prime}V^{-1}(Y-X\hat{\beta}) \sim \sigma^{2}\chi^{2}_{(n-p)}$ . $SSR/(n-p)$ is UMVUE for $\sigma^{2}$ . If $\hat{Y} = X\hat{\beta} = PY$ then $P$ is idempotent but not necessarily symmetric. $\hat{\beta}$ is BLUE for $\beta$ . To note, the exercise didn't tell anything about the matrix $V$ , I'm guessing $V$ is, at least, a semi-positive definite matrix, or even positive-definite since $\sigma^{2}V$ is a covariance matrix... My attempt: Reading Seber's Linear regression analysis I realize there's a theorem that says that if $Y\sim N_n(\mu, \Sigma)$ where $\Sigma$ is positive-definite, then $(Y-\mu)^{\prime}\Sigma^{-1}(Y-\mu)\sim \chi^{2}_{n}$ . Since $Y-X\hat{\beta}\sim N_n(0,\sigma^{2}V)$ , and $\Sigma = \sigma^2 V$ positive-definite then $SSR = (Y-X\hat{\beta})^{\prime}\Sigma^{-1}(Y-X\hat{\beta})\sim \chi^{2}_{(n)}$ , but the exercise says the distribution is $\chi^2_{(n-p)}$ , that would be, if I'm not wrong, iff $\operatorname{rank}(\Sigma)=n-p$ . If that's so, then how can I prove $\operatorname{rank}(\Sigma)=n-p$ ? For this, I think the result is trivial once I have proved 1. I'm totally lost at this, for the idempotent property, it's as simple as $$P = X\hat{\beta} = X(X^\prime V^{-1}X)^{-1}X^{\prime}V^{-1}$$ $$P^{2} = X(X^\prime V^{-1}X)^{-1}X^{\prime}V^{-1} X(X^\prime V^{-1}X)^{-1}X^{\prime}V^{-1} = X(X^\prime V^{-1}X)^{-1}X^{\prime}V^{-1} = P. $$ But for proving that in general, $P$ is not symmetric I'm confused, should I give a counter example or something? I've already found that $$\mathbb{E}[\hat{\beta}] = \beta \mbox{ and } Var(\hat{\beta}) = \sigma^{2}(X^\prime V^{-1}X)^{-1}$$ Is that it to conclude $\hat{\beta}$ is BLUE? Any help would be appreciated.","['linear-regression', 'statistical-inference', 'statistics']"
3583961,Weak convergence of $\mu_n = \frac{1}{2n +1} \sum_{k=-n}^{n} \delta_{\frac{k}{n}}$,"Show that sequence of probabilities $$
\mu_n = \frac{1}{2n +1} \sum_{k=-n}^{n} \delta_{\frac{k}{n}}
$$ converges weakly. To which probability? Now, I've written down the first elements: $$
\mu_1 = \frac{1}{3}(\delta_{-1} + \delta_{0} + \delta_{1})
$$ $$
\mu_2 = \frac{1}{5}(\delta_{-1} + \delta_{\frac{-1}{2}} + \delta_{0} +\delta_{\frac{1}{2}} + \delta_{1})
$$ and so on. It is a convex combination of Dirac's deltas which ""denses"" around $[-1, 1]$ . It can't be $U(-1,1)$ because no irrational numbers will ever fall into $\mu_n$ . What probability is that? How can I show the weak convergence?","['uniform-distribution', 'probability-theory', 'weak-convergence']"
3583981,Coarse moduli space of relative Picard functor for affine line,"Consider the relative Picard functor $\mathrm{Pic}_{\mathbb A^1/\mathrm{Spec}(\mathbb C)}$ sending a complex scheme $X$ to $\mathrm{Pic}(X \times \mathbb A^1)/\pi_X^* \mathrm{Pic}(X)$ . 
Since $\mathrm{Pic}(\mathbb A^1) = \{\mathcal O_{\mathbb A^1}\}$ , the only possible coarse or fine moduli space to this is $\mathrm{Spec}(\mathbb C)$ . But there is an example of a scheme $X$ such that $\mathrm{Pic}(X \times \mathbb A^1) \neq \mathrm{Pic}(X)$ and thus the point cannot be a fine moduli space. My question is: Is $\mathrm{Spec}(\mathbb C)$ a coarse moduli space for $\mathrm{Pic}_{\mathbb A^1/\mathrm{Spec}(\mathbb C)}$ ? In other words, does every natural transformation $\mathrm{Pic}_{\mathbb A^1/\mathrm{Spec}(\mathbb C)} \to \mathrm{Morphisms}(-, M')$ for a scheme $M'$ factor through $\mathrm{Morphisms}(-, \mathrm{Spec}(\mathbb C))$ ? This would follow if for every line bundle $\mathcal L$ on a product $X \times \mathbb A^1$ we can find an epimorphism $X' \to X$ such that the pullback of $\mathcal L$ to $X' \times \mathbb A^1$ is a pullback from $X'$ (e.g. since $\mathrm{Pic}(X' \times \mathbb A^1) = \mathrm{Pic}(X')$ ). This is true e.g. for $X'$ normal, but I don't see how this helps if $X$ is non-reduced.","['algebraic-geometry', 'moduli-space', 'picard-scheme']"
3583996,Combinatoric proof of an equality,"I was doing exercises from my discrete mathematics class when I stumbled upon this one: Show that equality holds for all $n\in\Bbb{N}$ : $\sum_{k=0}^{n}(-1)^{k}$${n-k}\choose{k}$$2^{n-2k}=n+1$ . I've managed to prove it using induction, but when I looked at the back of the book to check for a nicer proof I've only found a hint: ""Count in two ways all binary sequences length $n$ such that a $1$ is never followed by $0$ "". So basically all sequences like $000111,11111,00000$ . It obvious where the $n+1$ part came from - it counts all possible positions of the change from a block of $0$ 's to a block of $1$ 's. By the look of this problem, it's obvious it's one where the solution utilizes the inclusion-exclusion principle, but I have trouble coming up with a way to use it. For example, I've tried considering a family of sets: $A_k=\{(x_1,...,x_n)\in\{0,1\}^{n}:\forall_{i<k}\space x_i=0\}$ , but that didn't yield any nice results. Any thoughts?","['combinatorics', 'combinatorial-proofs']"
3584055,When is the empty function injective? surjective? bijective?,"Let us think about the empty function $f:\emptyset\rightarrow X$ ( $X$ is an arbitrary set.) . My idea is $f$ is always injective. Iff $X=\emptyset$ , $f$ is surjective (so bijective). (Reasoning) Definition of injective is : $x\neq x'\rightarrow f(x)\neq f(x')$ . The empty set has no element, so $x\neq x'\rightarrow f(x)\neq f(x')$ is always true. Definition of surjective is : $\forall y\in Y$ , there exists $x\in X$ such that $f(x)=y$ . Iff Y is the empty set,there is no element of $Y$ , so $\forall y\in Y$ , there exists $x\in X$ such that $f(x)=y$ is true.","['elementary-set-theory', 'functions']"
3584098,A locally compact and dense subset of a Hausdorff space is open,"Following a reference from ""Elementos de Topología General"" by Angel Tamariz and Fidel Casarrubias. Definition A topological space is locally compact if for any its point there exist a compact neighborhood. Theorem Let be $X$ a Hausdorff locally compact space and let be $Y\subseteq X$ a dense set: so if $Y$ is locally compact, then $Y$ is open in $X$ . proof . Let be $y\in Y$ . Since $Y$ is locally compact there exist a open set $A$ in $Y$ and a compact $K$ in $Y$ such that $y\in A\subseteq K\subseteq Y$ . So we choose an open set $V$ in $X$ such that $A=Y\cap V$ and we prove that $y\in V\subseteq Y$ . Clearly $y\in V$ ; then we observe that $$\mathscr{cl}_X(Y\cap V)\cap Y=\mathscr{cl}_X(A)\cap Y=\mathscr{cl}_Y(A)$$ and moreover since $\mathscr{cl}_Y(A)$ is compact, then $\mathscr{cl}_X(Y\cap V)\cap Y$ is compact and so this set is a closed set in $X$ . Then $\mathscr{cl}_X(Y\cap V)\cap Y$ contains $Y\cap V$ and so $$\mathscr{cl}_X(Y\cap V)\subseteq\mathscr{cl}_X(Y\cap V)\cap Y$$ that is $\mathscr{cl}_X(Y\cap V)\subseteq Y$ . Howewer it result that $$\mathscr{cl}_X(Y)\cap V\subseteq \mathscr{cl}_X(Y\cap V)$$ and so by density of $Y$ it is $V\subseteq\mathscr{cl}_X(Y\cap V)\subseteq 
Y$ . Unfortunately I don't understand why $\mathscr{cl}_X(Y)\cap V\subseteq\mathscr{cl}_X(Y\cap V)$ . If someone know another proof he could show it. Could someone help me, please?",['general-topology']
3584149,Calculate limit of this sequence $I_n = \int_{0}^{\pi/2} (\tan x)^{1/n} dx$,"I need to find the limit of the sequence : $$I_n =  \int_{0}^{\pi/2} (\tan x)^{1/n} dx$$ The only thing I have done is : take substitution $\tan x =  z$ this gives $$dx = \dfrac{1}{1 + z^2}\,dz$$ So, integral becomes : $$I_n = \int_{0}^{\infty} \frac{z^{1/n}}{1 + z^2}\,dz$$ After this I am stuck how should I proceed ? Can someone help me here ? Thank you.","['improper-integrals', 'sequences-and-series', 'real-analysis']"
3584240,Egyptian fraction representation of $1$ where all denominators of the fractions are odd.,"Question: Is there an Egyptian fraction representation for $1$ where all the fractions have odd denominators? I tried to generate one below: $$\frac{1}{3}+\frac{1}{5}+\frac{1}{7}+\frac{1}{9}+\frac{1}{11}+\frac{1}{13}+\frac{1}{23}+\frac{1}{721}+\frac{109}{106711605}.$$ The last term can be further decomposed to: $$\frac{1}{979007}+\frac{158}{1.04471\cdot 10^{14}}.$$ or, it is impossible for any collection of $\frac{1}{n}$ where $n$ is odd to produce $1$ ?","['number-theory', 'egyptian-fractions']"
3584257,An example when the direct image of a locally free sheaf is not locally free,"Let $X$ be a scheme over $\mathbb{C}$ , and $\Sigma$ a smooth projective curve over $\mathbb{C}$ . Let $E$ be a locally free sheaf on $X\times \Sigma$ . Denote $\pi : X\times \Sigma \to X$ the natural projection to the first coordinate. Is it true that the direct image $\pi_*E$ is a locally free sheaf on $X$ ? In case it isn't, I would also want to know is there any simple assumption on $X$ or $E$ that would make it true. Thank you in advance.","['pushforward', 'vector-bundles', 'algebraic-geometry', 'fibre-product']"
3584272,Is $\{a \pm b\}$ correct notation?,"Is $\{a \pm b\}$ correct notation? I want to mean a set $\{a-b, a+b\}$ by this, but I need some shorthand notation to fit an equation to double-column paper.","['elementary-set-theory', 'notation']"
3584304,$L^{p}$ spaces for complex measures,"Let $(\Omega,\mathscr{A})$ be a measurable space and $\mu\colon\mathscr{A}\to\mathbb{C}$ a complex measure (i.e. a $\sigma$ -additive function from $\mathscr{A}$ to $\mathbb{C}$ ). Then $\mu$ can be decomposed into a (unique) real and imaginary part. In other words, there are (finite) signed measures $\mu_{1},\mu_{i}\colon\mathscr{A}\to\mathbb{R}$ such that $\mu=\mu_{1}+i\mu_{i}$ . The Jordan decomposition lets us split the real and imaginary part of $\mu$ into finite positive measures $\mu_{1}^{+},\mu_{1}^{-},\mu_{i}^{+},\mu_{i}^{-}\colon\mathscr{A}\to\mathbb{R}_{\geq0}$ such that $\mu_{1}=\mu_{1}^{+}-\mu_{1}^{-}$ and $\mu_{i}=\mu_{i}^{+}-\mu_{i}^{-}$ . So we have $$\mu=(\mu_{1}^{+}-\mu_{1}^{-})+i(\mu_{i}^{+}-\mu_{i}^{-}).$$ Then a measurable complex valued function $f\colon\Omega\to\mathbb{C}$ is called integrable with respect to the complex measure $\mu$ if and only if the real and imaginary part of $f$ are both integrable with respect to the measures $\mu_{1}^{+}$ , $\mu_{1}^{-}$ , $\mu_{i}^{+}$ and $\mu_{i}^{-}$ . If $f=f_{1}+if_{i}$ (with $f_{1}$ and $f_{i}$ real-valued) is integrable with respect to $\mu$ , then its integral is defined to be \begin{align*}\int_{\Omega}f \ \text{d}\mu&:=\int_{\Omega}f_{1} \ \text{d}\mu_{1}^{+}-\int_{\Omega}f_{1} \ \text{d}\mu_{1}^{-}+i\int_{\Omega}f_{1} \ \text{d}\mu_{i}^{+}-i\int_{\Omega}f_{1} \ \text{d}\mu_{i}^{-}\\
&=\int_{\Omega}f_{i} \ \text{d}\mu_{1}^{+}-\int_{\Omega}f_{i} \ \text{d}\mu_{1}^{-}+i\int_{\Omega}f_{i} \ \text{d}\mu_{i}^{+}-i\int_{\Omega}f_{i} \ \text{d}\mu_{i}^{-}.
\end{align*} I was studying complex measures, but the concept of $L^{p}$ spaces is very unclear to me in this case. I can't find any proper literature about it either. Can someone explain to me what is going on here? I have a few questions in particular: Can we make sense of the space $L^{p}(\Omega,\mathscr{A},\mu)$ for $1\leq p\leq\infty$ ? Can we define a $p$ -norm on this space? Is this norm also complete? In the case $p=2$ , do we still have a (complete) inner-product space? I think the total variation $|\mu|$ (which is a finite positive measure) of a complex measure $\mu$ has something to do with it, but I can't figure it out the details myself. Any help is greatly appreciated!","['measure-theory', 'lebesgue-integral', 'lp-spaces', 'complex-integration', 'total-variation']"
3584361,what is the difference between a projective mapping(transformation) and perspective mapping(transformation),(1) a projective but not perspective mapping indicates that they are different (2) Perspective Transform & Homography Matrix indicates these are the same thing (3) projective transformation = homography = collineation it is evident (1) conflicts with (2) and (3). how can  pinpoint  these ?,"['algebraic-geometry', 'projective-geometry']"
3584385,Analyzing logical forms clarification,"This example is from Velleman's ""How To Prove It"": Example 2.3.6. Analyze the logical forms of the following statements. $x \in \bigcup \{ \mathscr{P}(A)| A \in F \}$ On the next page, the solution is written as $\exists A \in F(x \in \mathscr{P}(A))$ . This makes sense to me, but it does not seem to follow the expansion rules. I worked it out as \begin{align*}
    x & \in \bigcup \{ \mathscr{P}(A)| A \in F \} \\
    \exists B & \in \{ \mathscr{P}(A)| A \in F \} (x\in B) & \text{(definition of union)} \\
    \exists B & (B \in \{ \mathscr{P}(A)| A \in F \} \wedge x \in B) \\
    \exists B & (\exists A \in F(B =\mathscr{P}(A) ) \wedge x \in B)
\end{align*} How does one go from $\exists B (\exists A \in F(B =\mathscr{P}(A) ) \wedge x \in B)$ to $\exists A \in F(x \in \mathscr{P}(A))$ ? Should it just be inferred, or can we transform one side into the other using basic rules?","['elementary-set-theory', 'proof-explanation', 'logic']"
3584397,How can I solve this limit using L'Hospital's rule somewhere?,I have to solve this limit $\lim _{x\to 0+}\left(\left(\left(1+x\right)^x-1\right)^x\right)$ as $x$ approaches $0$ from the positive numbers. I have tried to change it to e to the limit of the exponent and apply L'Hospital's on it but to no avail. Can someone help me?,"['limits', 'calculus', 'derivatives']"
3584458,How to find the derivative of $\sqrt{x+2} -x$ using limit definition?,"So the function is $f(x) = \sqrt{x+2} -x$ , and I keep hitting dead ends trying to solve it using the definition of derivative. If anyone can help, it would be greatly appreciated!",['derivatives']
3584518,Find the best unbiased estimator of $\theta^2e^{-\theta}$ from a Poi($\theta$) sample.,"Suppose $X_1....X_n$ is a random sample from a Poi( $\theta$ ) population.  Find the best unbiased estimator of $\theta^2e^{-\theta}$ My attempt: Let $\sum_1^nX_i=T$ .  We know $T$ is complete and sufficient. So we seek an unbiased estimator of $\theta^2e^{-\theta}$ then condition it on T then find the expected value. An unbiased estimator of $\theta^2e^{-\theta}$ is $2 \chi_{[X_1=2]}$ We calculate $E(2\chi_{[X_1=2]}\mid T=t) = 2\Pr(X=2\mid T=t)$ By Bayes this is $$2(tC2) \left( 1-\frac{1}{n}\right)^{t-2} \left( \frac{1}{n} \right)^2$$ I'm very unsure of this result. It matches none of my classmates, but I cannot see where I'm making an error.  I also would be curious to see alternative approaches.","['statistical-inference', 'statistics', 'solution-verification', 'parameter-estimation']"
3584552,Calculating a limit with Harmonic number,"I am trying to prove that $\lim_{n\to\infty} (\frac{\sum^n_{k=1} \frac{1}{k}} { \ln(n) })^{ \ln(n) } = e^γ$ where $γ$ the Euler-Mascheroni constant. We know that that: $\lim_{n\to\infty} \frac{\sum^n_{k=1} \frac{1}{k}}{ \ln(n) } = 1$ By approximating the sum with integrals $$
\ln(n+1)=\int_1^{n+1}\frac1x\mathrm dx\le\sum_{k=1}^n\frac1k\le 1+\int_1^n\frac1x\mathrm dx=1+\ln n
$$ since $1/k$ is decreasing for $k\ge 1$ . We have that $$
\frac{\ln(n+1)}{\ln n}=\frac{\ln n+\ln(1+\frac1n)}{\ln n}\to1
$$ as $n\to\infty$ and we obtain the result. But I can't calculate $\lim_{n\to\infty} (\frac{\sum^n_{k=1} \frac{1}{k}} { \ln(n) })^{ \ln(n) } = e^γ.$ Any help?","['limits', 'calculus']"
3584566,Does the product between two plus-minus signs yield a minus-plus sign?,"While studying the Complex Algebra section of Weber & Arfken's Mathematical Methods for Physicists, I've stumbled upon the following expression, concerning the solutions $y_{1,2}=-1\pm i \sqrt3 $ for $y(x)=0$ , $y(x)=x^2 +x + 1$ , $$\left[\frac 12  (-1 \pm i \sqrt{3})\right]^2+\frac 12(-1 \pm i \sqrt{3}) +1 = 
\frac 14 (1 -3  \mp 2i \sqrt3 -2 \pm 2i \sqrt3  ) +1 =0$$ I can't see clearly why the $\pm$ sign in the first brackets turns into $\mp$ after being squared, and I thought this question would fit better here than in the Physics forum. My book's edition is the 2004 international version, if needed.","['calculus', 'algebra-precalculus']"
3584589,What is the sum of the following infinite series?,"$$
\frac{1}{3} + \frac{2}{9} + \frac{1}{27} + \frac{2}{81} + \frac{1}{243} + \frac{2}{729} + \cdots
$$ So basically I separated it into two series where: one of them is $\left(\frac{1}{3}\right)^n$ And I use geometric series formula to find that this series equals $\frac{1}{2}$ . But I can't figure out the series of the other one. Apparently the answer for the series combined is: $\frac{5}{8}$ What is the other series?",['sequences-and-series']
3584592,Laurent series of exp(az+b/z),"I need to show that \begin{align}
		\exp \left(a z+b z^{-1}\right)&=\sum_{n=-\infty}^{\infty} a_{n} z^{n} \;\;\; a, b \in \mathbb{C} \\\
		a_{n}&=\frac{1}{2 \pi} \int_{0}^{2 \pi} e^{(a+b) \cos \theta} \cos \Big[(a-b) \sin \theta-n \theta\Big] d \theta
\end{align} I am stuck at one of my arguments, which I find shaky. What I have so far is: I note that f(z) is a composition of a polynomial, with the exponential function, it is holomorphic on the punctured disk K'(a,r) centered at the point a = 0 which is a singularity. This is analogous to the annulus $$A(a, R_1, R_2) , R_1 \rightarrow 0, R_1 \rightarrow \infty$$ There exists a Laurent series for the function at a. The general term a_n is given by \begin{align}
		a_n &= \frac{1}{2\pi i} \int_{\partial K(a,r)}\frac{f(z)}{(z-a)^{n+1}}dz \\\
			&= \frac{1}{2\pi i} \int_{\partial K(0,r)}\frac{\exp \left(a z+b z^{-1}\right)}{z^{n+1}}dz\\\
		&= \frac{1}{2\pi i} \int_{0}^{2\pi}\frac{\exp \left(a r e^{i\theta}+b (re^{i\theta})^{-1}\right)}{(re^{i\theta})^{n+1}}r i e^{i\theta}d\theta \\\
			&= \frac{1}{2\pi} \int_{0}^{2\pi} e^{\left(a r e^{i\theta}+b (re^{i\theta})^{-1}\right)}(re^{i\theta})^{-n}d\theta \\\
			&= \frac{1}{2\pi} \int_{0}^{2\pi} e^{\big( a r [cos(\theta)+i\sin(\theta)]+b [cos(\theta)-i\sin(\theta)]r^{-1} \big)} (re^{i\theta})^{-n} d\theta \\\
			&= \frac{1}{2\pi} \int_{0}^{2\pi} e^{\big( (a r+b r^{-1})cos(\theta)+i(a r-b r^{-1})\sin(\theta)\big)} (re^{i\theta})^{-n} d\theta \\\
			&= \frac{1}{2\pi} \int_{0}^{2\pi} e^{(a r+b r^{-1})\cos\theta}e^{i(a r-b r^{-1})\sin\theta}e^{-i\theta n} r^{-n} d\theta \\\
			&= \frac{1}{2\pi} \int_{0}^{2\pi} e^{(a r+b r^{-1})\cos\theta}e^{i\big[(a r-b r^{-1})\sin\theta -\theta n\big]} r^{-n} d\theta \\\
			&= \frac{1}{2\pi} \int_{0}^{2\pi} e^{(a r+b r^{-1})\cos\theta} \Big(\cos\left[(a r-b r^{-1})\sin\theta-\theta n\right] + i\sin\left[(a r-b r^{-1})\sin\theta - \theta n\right] \Big) r^{-n} d\theta
	\end{align} $f(z)$ has a primitive (as it is the composition of the exponential with polynomials),so the last term of the integral is zero, since it is the evaluation of its primitives at the upper and lower boundaries of the integral. The primitive of $i\sin z$ is $i \cos z$ , so evaluating the last term at $F(0)$ and $F(2\pi)$ yields $F(2\pi) - F(0) = i\cos(2\pi n)-i\cos(0) = i - i = 0$ , and thus \begin{align}
	a_n &=  \frac{1}{2\pi} \int_{0}^{2\pi} e^{(a r+b r^{-1})\cos\theta} \cos\left[(a r-b r^{-1})\sin\theta-\theta n\right]  r^{-n} d\theta
	\end{align} Now i need to get rid of the r's... I somehow want to just say they are equal to one, since the closed path integral is independent of the path. We are integrating around the boundary of the disc, a closed circle, and the integral must be independent of r. This means it must hold for any r. Is this reasoning correct?","['complex-analysis', 'laurent-series', 'analysis', 'sequences-and-series']"
3584649,The category of C* algebras has cokernels,"Let $\mathcal{C}^*$ be the category defined as follows: $1.\text{Ob}(\mathcal{C}^*)=\{C^*\text{-algebras}\}$ $2.$ For $A,B\in\mathcal{C}^*$ set $\text{Hom}_{\mathcal{C}^*}(A,B)=\{\varphi:A\to B\;|\; \varphi \text{ is a $*$-homomorphism} \}$ This is a category (it can be easily verified) and we know that $\text{Hom}_{\mathcal{C}^*}(A,B)$ is exactly the set of norm-decreasing homomorphisms (also easily proved). With these homomorphisms, $\mathcal{C^*}$ actually is NOT additive, as we cannot simply add $*$ -homomorphisms (the result is not a $*$ -homomorphism). However, we do have kernels. My question is : does $\mathcal{C}^*$ have cokernels? I believe so, and here is my work: Let $A\xrightarrow{\varphi}B$ be a morphism in $\mathcal{C}^*$ . Let $I$ denote the closed (double) ideal generated by $\varphi(A)$ . Then $B/I$ (with quotient norm) is a $C^*$ -algebra and we have the quotient $*$ -homomorphism $\pi:B\to B/I$ . I claim that $\text{cokernel}(A\xrightarrow{\varphi}B)=B\xrightarrow{\pi}B/I$ . The description of $I$ is the closed linear span of the set $S:=\{\varphi(a),\varphi(a)b, b\varphi(a), b\varphi(a)b': a\in A, b,b'\in B\}$ (maybe this can be simplified if we consider the unitization of $B$ , but I'd like to avoid it right now). If $B\xrightarrow{\psi}D$ is a $*$ -homomorphism such that $\psi\circ\varphi=0$ , then we define $\bar{\psi}:B/I\to D$ by $\bar{\psi}(b+I)=\psi(b)$ . First we need to show that $\bar{\psi}$ is a well defined $*$ -homomorphism. The only non-trivial thing is that $\bar{\psi}$ is well defined. But if $b-b'\in I$ , we need to show that $\psi(b-b')=0$ . But $b-b'=\displaystyle{\lim_{n\to\infty}u_n}$ where $u_n\in\overline{\text{span}(S)}$ . By $\psi$ 's continuity and preservation of sum and scale, it suffices to show that $\psi\equiv0$ on $S$ . but this is true, since $\psi(\varphi(a))=0, \psi(\varphi(a)b)=\psi(\varphi(a))\psi(b)=0,\dots$ and so on. Obviously $\bar{\psi}\circ\pi=\psi$ and if $\bar{\psi}':B/I\to D$ was another such morphism, then $\bar{\psi}'(b+I)=\bar{\psi}'\circ\pi(b)=\psi(b)=\bar{\psi}(b+I)$ , so we have uniqueness. This is the universal property of cokernels, so we are done. Does my proof contain mistakes? If someone can confirm that there are no mistakes, I suggest editing the title and taking the question mark off. A comment: Note that $\varphi(A)$ is not equal to the image in the categorical setting: an obvious reason: the image is defined as the kernel of the cokernel. but kernels are always ideals, $\varphi(A)$ is not necessarily an ideal. Also, we know that $\varphi(A)\cong A/\ker(\varphi)$ , the co-image of $\varphi$ .","['c-star-algebras', 'solution-verification', 'functional-analysis', 'category-theory']"
3584661,Number of ways to distribute $20$ identical pencils to $6$ children with no restrictions.,"First time posting a question so assistance is greatly appreciated.  I saw a similar question but didn't see the response to item d.) which is what I need to finish a comparable question. Number of ways to distribute 20 identical pencils to 6 children with no restrictions. d) If the pencils are given out randomly. What is the probability that there are at least two kids receive the same number of pencils if every kid receives at least one pencil? Please provide a step-by-step answer on how you got your final answer. I used combinations to arrive to the other answers so that will be helpful.  Please let me know if I'm unclear.  Thank you all for your assistance.  If this was already answered, please provide the link of the post.  Thanks! EDITED:
In a similar question, someone wrote...
If they all get the different number of pencils, then there would be at least 1+2+3+4+5+6=21 pencils which is impossibile. So the probability that at least two will get the same number of pencil is 1. It is impossible that everyone gets a different number of pencils if each gets at least one pencil. So the probability that at least two will get the same number of pencils is 100%. I understand that yes, two kids will at least receive the same number of pencils but I don't understand the equation if any.  I drew it out but can't think of the equation.  Would it be C(20,8)?","['permutations', 'combinations', 'discrete-mathematics', 'probability']"
3584669,Why is Proposition 29 in Book I of Euclid‘s Elements dependent on the Parallel Postulate?,"Proposition 29 says the following: A straight line falling on parallel straight lines makes the alternate angles equal to one another Euclid proves this using the Parallel Postulate. I don’t understand why that’s necessary.
I can prove it without the postulate: Let the straight line intersect the parallel straight lines in A and B. I claim that angle CAB= angle ABD.
Bisect AB in E and draw the circle with center E and A and B lying upon its circumference. The Circle intersects the straight parallel lines in F,A,B,G. Draw FG. Since angle AEF and angle BEG are vertical angles of two intersecting lines they are equal.
Since FE=AE=BE=DE and angle FEA=angle BEG we conclude that ΔFAE=ΔBGE and ΔFAE,ΔBGE are isosceles. Equal isosceles triangles have equal angles at their bases, so we have: angle FAE=angle EBG and thus: angle CAB=angle ABD Can anybody help me understand it please? I’ve heard that Proposition 29 is the first one in Book I that is depending on the 5. Postulate and thus doesn’t hold in hyperbolic geometry.","['euclidean-geometry', 'geometry']"
3584721,Finding $z=x+y$ such that $x^2 + y^2$ is prime,"For which integers $z$ can one write $z=x+y$ such that $x^2+y^2$ is prime? It feels like it should be possible for all odd $z>1$ , and I have tried to adapt Euler's proof of Girard/Fermat's assertion that any prime congruent to $1 \bmod 4$ can be uniquely expressed as the sum of two squares, but without success.","['integer-partitions', 'number-theory', 'prime-numbers']"
3584832,Proving that $\bigcap \mathcal P\subseteq\left(\bigcap\mathcal M\right)\cup\left(\bigcup\mathcal N\right)$,"I'm trying to prove the statement: Let $\mathcal M,\mathcal N,\mathcal P$ be families, none of which is the empty set. Assume that if $A\in\mathcal M$ and $B\in\mathcal N$ , then $A\cup B\in\mathcal P$ . Prove that $\bigcap \mathcal P\subseteq\left(\bigcap\mathcal M\right)\cup\left(\bigcup\mathcal N\right)$ Here is what I have written so far for my proof: Let us suppose $x\in \bigcap \mathcal P$ . Then, $x\in C$ for all $C\in \mathcal P$ . Let us now suppose $x\notin \bigcap\mathcal M$ . Then, $x\notin A$ for some $A\in \mathcal M$ . Let us now suppose there exists $B\in \mathcal N$ such that $x\notin B$ . Now we see that $A\cup B\in \mathcal P$ , so $x\in A\cup B$ and since $x\notin B$ and $x\in A$ , but $x\notin A$ , we see there is a contradiction. Hence, there does not exist a $B\in \mathcal N$ such that $x\notin B$ . Thus, $x\in B$ for all $B\in \mathcal N$ . Hence, $x\in \bigcup\mathcal N$ . Thus, $x\notin \bigcap\mathcal M$ implies that $x\in \bigcup\mathcal N$ . Therefore, $x\in \bigcap\mathcal M \cup \bigcup\mathcal N$ . Hence, $\bigcap \mathcal P\subseteq\left(\bigcap\mathcal M\right)\cup\left(\bigcup\mathcal N\right)$ I'm not sure if my proof is correct or if it even was going in the right direction. I get confused with families of sets and I struggle with proofs involving them. Any feedback or help is appreciated.","['elementary-set-theory', 'proof-explanation', 'proof-writing', 'solution-verification']"
3584936,Does the fundamental group detect the unlink?,"It is known that the unknot is the only knot whose complement has fundamental group $\mathbb{Z}$ . Does this fact generalize to links?  That is, suppose that $\ell= \ell_1 \cup \dots \cup \ell_n$ is an $n$ -component link in $\mathbb{R}^3$ such that $\pi_1(\mathbb{R}^3-\ell)$ is a free group on $n$ -generators. Is $\ell$ the unlink on $n$ -components?","['geometric-topology', 'fundamental-groups', 'knot-theory', 'differential-topology', 'general-topology']"
3584977,"Lifting criterion, where do we use ""X is locally path connected"" in the proof?","The following lifting criterion is well known. Let $p:E\to B$ be a covering map, $p(e_0)=b_0$ . Let $X$ be a path connected, locally path connected space (I know this is necessary). Let $f:X \to B$ be a continuous map, $f(x_0)=b_0$ .  If $f_*(\pi_1(X,x_0))\subset p_*(\pi_1(E,e_0))$ , then there exists a lift $\tilde{f}:X\to E$ of $f$ . Proof: For any $x\in X$ , choose a path $c(t)\subset X$ connecting $x_0$ and $x$ , then lift $c(t)$ to $E$ , we get $\tilde{c}(t)\subset E$ , define $\tilde{f}(x)=\tilde{c}(1)$ . We can check that for different paths, we get the same $\tilde{f}(x)$ , thus well defined. I check that $\tilde{f}(x)$ is continuous in the following way: For $x \in X $ , $\tilde{f}(x)\in E$ , choose a small open nbh $V_0\subset E$ such that $p:V_0\to p(V_0)\subset B$ is a homeomorphism. We claim that for any open nbh $V\subset V_0$ , there exists open nbh $W$ of $x$ , such that $\tilde{f}(W)\subset V$ . Since $E$ is locally path connected, choose a path connected open nbh $V'\subset V$ , then $p(V')\subset B$ is also path connected. For any $y \in f^{-1}(p(V'))$ , $f(y)\in p(V')$ . Choose a path $c(t)$ in $p(V')$ connecting $f(x)$ and $f(y)$ , then lift to $V'$ , we get $\tilde{c}(t)\subset V'$ . We can check that $\tilde{f}(y)=\tilde{c}(1)\in V'$ . Denote $W=f^{-1}(p(V'))\subset X$ , we have shown that $\tilde{f}(W)\subset V'\subset V$ . Since $p(V')$ is open, $W$ is an open nbh of $x$ . So we prove the claim, $\tilde{f}$ is continuous at $x$ . In the above argument, I haven't use that $X$ is locally path connected (I know it is necessary), so where am I wrong?","['general-topology', 'algebraic-topology']"
3584988,Exercise 8.1.A of Vakil's FOAG,"In Vakil's FOAG , definition 8.1.1 reads as A morphism $\pi : X \to Y$ of schemes is a closed embedding if $\pi$ is affine, i.e., for every affine open subset $\mathrm{Spec} B$ of $Y$ , $\pi^{-1}\mathrm{Spec} B \cong \mathrm{Spec} A$ is affine open in $X$ . And the induced morphism $\mathrm{Spec} A \to \mathrm{Spec} B$ on global section is a surjective map $B \to A$ Then, in Exercise 8.1.A , I'm asked to show that the closed embedding $\pi$ identifies the topological space
of $X$ with a closed subset of the topological space of $Y$ . The text uses the word ""identify"" . I believe that by using ""identify"" he means 
""homeomorphic"" as in the affine case: if we have a surjective ring map $B \to B/I$ , then we have an induced map $\mathrm{Spec} B/I \to \mathrm{Spec} B$ which is a homeomorphism from $\mathrm{Spec} B/I$ to the closed subset $V(I)$ of $\mathrm{Spec} B$ . The question is I don't know how to show this. I have some thoughts: I've managed to show that $\pi$ is injective : Take an affine open $\mathrm{Spec} B$ of $Y$ , let $\mathrm{Spec} A = \pi^{-1}\mathrm{Spec}B$ . By definition, on global sections, $\pi^\# : B \to A$ is surjective. Since we have the equivalence between category of affine schemes and rings, $\pi : \mathrm{Spec}A \to \mathrm{Spec}B$ is exactly induced by $\pi^\# : B \to A$ . Since $\pi^\#$ is surjective, we know that $\pi^\#$ induces homeomorphism from $\mathrm{Spec}A$ to a closed subset of $\mathrm{Spec}B$ , in particular, $\pi : \mathrm{Spec}A \to \mathrm{Spec}B$ is injective. By definition, $\pi$ is continuous, and we have just shown $\pi$ is injective. 
So it suffices to show that $\pi$ takes closed subsets of $X$ to closed subsets of $Y$ . By arguments above, we only know that $\pi$ takes each piece of some affine open cover of $X$ to some closed subset of affine open of $Y$ . 
How can one take care of this gap, or should I try some different way? Thank you for your help.",['algebraic-geometry']
3585007,"In a complete metric space,first category sets are 'meagre' in the sense that they cannot contain any non-empty open set.","I had just started studying Baire's Category Theorem and I was at first having problem with the seemingly technical definitions of nowhere dense sets,first category and second category sets.But slowly it was revealed to me that these definitions are not coming out of the blue,they have some significance.The idea of nowhere dense is quite simple to interpret,it is nowhere dense in the sense that it is not dense in any non-empty open set.But first category and second category sets are a bit complicated to be appreciated at first glance.Sometimes we say that first category sets are 'meagre' or small in the sense that they are countable(small enough) union of nowhere dense(sparse) sets.That would seem quite convincing but at the next glance you would figure out something else.Suppose we consider the metric space $\mathbb Q$ with usual distance $|.|$ ,consider an enumeration $(r_n)$ of this set.Then $\mathbb Q=\large\cup_{n\in \mathbb N}$$\{ r_n\}$ ,where each of the singletons in nowhere dense as $\mathbb Q$ has no isolated points.So, $\mathbb Q$ is of first category,but notice that here it is not small in that sense because it is the entire space.So,the thing small is not understood properly here.Now,it is best understood when we work with complete metric space.We know that complete metric spaces are of second category.Now here if we have a first category set,then it is clear that it cannot contain any open non-empty set(By Baire's Category theorem): We can proceed directly that if $X$ is a complete metric space and $U\subset A$ , $U$ being a non-empty open set,then $U$ is of second category.So any superset of $U$ in particular $A$ must be of second category.So,a first category set in a complete metric space cannot contain a non-empty open set. So,a first category set is indeed 'meagre' in true sense of the term when we consider a complete metric space.Also,we can say that first category set is 'meagre' because in complete metric space,its complement is of second category. So,I think the terms 'meagre' or 'small' in terms of category is best understood and in fact justified when we look at complete metric spaces.In fact,Baire developed his theorem for $\mathbb R$ which is a complete metric space.So,it think he thought of these terminologies like 'meagre'.Is it correct?","['metric-spaces', 'real-analysis', 'intuition', 'general-topology', 'baire-category']"
3585120,Prove or disprove (Eulerian Graphs),"Which part of the following question is correct? A graph is eulerian if and only if the maximum number of edge-disjoint paths between any two vertices of this graph is an even number. ( a graph is eulerian if it has a circuit which contains all of its edges) I personally think that if a graph is eulerian, then the maximum number of edge-disjoint paths between any two vertices of this graph is an even number. But I think the other side of this problem is not necessarily correct . My idea for proving the first part is that if we consider that the maximum number of edge-disjoint paths between two vertices like $u$ , $v$ is odd. For example name these paths as $p_1,\dots,p_{2k+1}$ . now omit the edges in these cycles : $up_1vp_2u$ , $up_3vp_4u$ , $\dots$ , $up_{2k-1}vp_{2k}u$ . The graph still remains eulerian. But there exist just one path between $u$ and $v$ and this is a contradiction.","['graph-theory', 'discrete-mathematics']"
3585130,Why is the Fisher information matrix both an expected outer product and a Hessian?,"If $X$ is a random variable distributed as $X \sim p(x ; {\theta^*})$ , the Fisher information matrix is defined as the expected outer product matrix: $$
I(\theta) = E_{X \sim p(x ; {\theta^*})} \left[
\,\left(\nabla_{{\theta}} \log p(X\,; {\theta}) \right) 
\left(\nabla_{{\theta}} \log p(X\,; {\theta}) \right)^\top \,\right].
$$ However, it is also defined as the expected Hessian matrix of the negative log-likelihood: $$
I(\theta) = E_{X \sim p(x ; {\theta^*})} \left[
\frac{\partial^2}{(\partial\theta)(\partial\theta^\top)} \bigl(-\log p(X;\theta)\bigr)
\right].
$$ I am puzzled by why these two definitions are equivalent. Specifically, I'm not sure why and (expected) outer product of first partial derivatives should be equal to the matrix of 2nd derivatives. Intuitions or derivations are appreciated!","['statistical-inference', 'multivariable-calculus', 'fisher-information']"
3585204,Explanation of all the incomplete details on Apery's theorem proof following van der Poorten article.,"I'm trying to fully understand Apery's proof of the irrationality of $\zeta(3)$ and after looking for a good source I ended up reading van der Poorten article A Proof that Euler missed... I think that the paper is really well explained but, at same points, it omits too many details (at least for me), so I'm going to state all my doubts the best way I can, and I hope that together with these other posts, if I get good answers, it can be a good source for anyone looking for details related with this paper. Section 3 Posts with some omited details in secction 3. Convergence of the sum $\sum_{k=1}^{N} \frac{(-1)^k}{(2k^3) \binom{N+k}{k} \binom {N}{k}}$ Proof that $\sum_{k=1}^\infty\frac{a_1a_2\cdots a_{k-1}}{(x+a_1)\cdots(x+a_k)}=\frac{1}{x}$ Section 4 In section 4 is defined the principal sequence of the proof, that is for $k \leq n$ $$c_{n,k}=\sum_{m=1}^n \dfrac{1}{m^3}+\sum_{m=1}^k \dfrac{(-1)^{m-1}}{2 m^3 {n\choose m}{n+m\choose m}}$$ It can be easily seen using the answer in the firts post I mentioned before that it converges uniformly in $k$ to $\zeta(3)$ , that is: Given $\varepsilon >0$ there exits a $n_0 \in \mathbb{N}$ such that if $n \geq n_0$ then $$\left| c_{n,k} - \zeta(3) \right| \leq \varepsilon \hspace{2mm} \forall k \leq n$$ Now, if we take $k=n$ , we have that $c_{n,n}$ converges to $\zeta(3)$ and in fact, we get the series discussed in section 3 but after that, it states that this series does not converge fast enough to proof the irrationality of $\zeta(3)$ . To explain that, he proofs a lema that states that $2[1,2, \cdots, n]^3 {n+k \choose k} c_{n,k}$ is an integer, where $[1,2, \cdots, n]=\mathrm{lcm}(1, 2, \cdots, n)$ .
So, we can express for some sequence of integers $z_{n,k}$ $$c_{n,k}=\dfrac{z_{n,k}}{2[1,2, \cdots, n]^3 {n+k \choose k}}$$ It is then stated that given $\varepsilon>0$ for $n$ large enough $$[1,2, \cdots, n] \leq e^{n(1+\varepsilon)}$$ (which can be rigurously proven using the prime number theorem and the sketch given below the assertion) and from here, he states that this sequence has too large denominator to proof the irrationality. So, my first doubt: Doubt 1: How can we explain in detail, based on what is said before, that the series $c_{n,k}$ is not enough to proof the irrationality of $\zeta(3)$ ? ( Solved ) After that, it explain Apéry's process to accelerate the convergence of the series, which consists on applying several transformations to the sequence $c_{n,k}$ until we get two sequences (the second one in the paper has no name, so I name it after $e_{n,k}^{(i)}$ ): $$d_{n,k}^{(5)}=\sum_{h=0}^{k}\sum_{l=0}^h {k \choose h} {n \choose h} {h \choose l} {n \choose l} {2n-l \choose n} c_{n,n-l}$$ $$e_{n,k}^{(5)}=\sum_{h=0}^{k}\sum_{l=0}^h {k \choose h} {n \choose h} {h \choose l} {n \choose l} {2n-l \choose n}$$ Now, my doubts here are: Doubt 2: Why is it true that in this process, we still have that the quotient $d_{n,n}^{(i)}/e_{n,n}^{(i)}$ still converges to $\zeta(3)$ ? ( Solved ) I don't know how to get around when we divide by a sum. Doubt 3: How do we get that $2[1,2, \cdots, n]^3 d_{n,k}^{(i)}$ is still and integer? ( Solved ) Doubt 4: Why does this process, in an intuitive way, accelerate the convergence of the sequence? Section 5 In this section, it takes $a_n=d_{n,n}^{(5)}$ , $b_n=e_{n,n}^{(5)}$ , and considering it satisfies the recursion stated at the beggining of the paper, it is proven the irrationality of $\zeta(3)$ . After some manipulations, it is shown that $$\zeta(3) - \dfrac{a_n}{b_n}= \sum_{k=n+1}^\infty \dfrac{6}{k^3b_kb_{k-1}}$$ so (correct me if I'm wrong in the next reasoning) $$\zeta(3) - \dfrac{a_n}{b_n} \leq \dfrac{1}{b_n^2}\sum_{k=n+1}^\infty \dfrac{6}{k^3} \leq \dfrac{1}{b_n^2}\sum_{k=1}^\infty \dfrac{6}{k^3}$$ and we get that $b_n=O(b_n^{-2})$ . From here on, I don't really get much on the secction. Doubt 5: How can we proof, based on the equation stated for $b_n$ that $b_n=O(\alpha^n)$ ? Doubt 6: How can we proof, that $q_n=O(\alpha^n e^{3n})$ ? I thought these one was because $[1, 2, \cdots, n]=O(e^n)$ but as I was pointed on here thats not true so, I don't know how does he get that relation. Doubt 7: How do we get these two equalities $\zeta(3) - \frac{p_n}{q_n}=O(\alpha^{-2n})=O(q_n^{-(1+\delta)})$ with $\delta=(\log(\alpha)-3)/(\log(\alpha)+3)$ Sections 6 and 8 In section 6, after defining $a_n$ and $b_n$ it states that it is easy to prove that its quotient converges to $\zeta(3)$ , but as I asked in doubt 2, I don't know how to treat the quotient of two sums to get what we desired. I suppose the same answer for doubt 2 will be useful here so I want state it again but, at the beggining of section 8, it shows the relation between this $b_n$ and $e_{n,n}^{(5)}$ but, I don't know why is it true the next equalities: Doubt 8: $\sum_{k=0}^{n}\sum_{l=0}^k {n \choose k}^2 {n \choose l} {k \choose l} {2n-l \choose n}=\sum_{k=0}^n {n \choose k}^2{2n-k \choose n}^2$ Doubt 9: $\sum_{k=0}^{n}\sum_{l=0}^k {n \choose k}^2 {n \choose l} {k \choose l} {2n-l \choose n} c_{n,n-k}=\sum_{k=0}^n {n \choose k}^2{2n-k \choose n}^2 c_{n,n-k}$ Now, the following doubts are all combinatorial. Maybe I'm lacking of some binomial coefficients propierties, but after pages full of expansion, I didn't get the following equalities. Given $B_{n,k}=4(2n+1)(k(2k+1)-(2n+1)^2){n \choose k}^2{n+k \choose k}^2$ Doubt 10: $B_{n,k}-B_{n,k-1}=(n+1)^3{n+1 \choose k}^2{n+1+k \choose k}^2-(34n^3+51n^2+27n+5){n \choose k}^2{n+k \choose k}^2+n^3{n-1 \choose k}^2{n-1+k \choose k}^2$ Now, I know how to derive that $$c_{n,k}-c_{n-1,k}=\dfrac{1}{n^3}+\sum_{m=1}^k \dfrac{(-1)^m (m-1)!^2(n-m-1)!}{(n+m)!} \hspace{2mm}(*)$$ but I don't get the other subsequent equalities although the paper says it is clear. Doubt 11: $$(*)=\dfrac{1}{n^3}+\sum_{m=1}^k\left( \dfrac{(-1)^m m!^2(n-m-k)!}{n^2(n+m)!}-\dfrac{(-1)^{m-1} (m-1)!}{n^2(n+m+1)!}\right)=\dfrac{(-1)^k k!^2(n-k-1)!}{n^2(n+k)!}$$ After all that definitions, it know defines $$A_{n,k}=B_{n,k}c_{n,k}+\dfrac{5(2n+1)(-1)^{k-1}k}{n(n+1)}{n \choose k}{n+k \choose k}$$ and states that (9) is equal to $A_{n,k}-A_{n,k-1}$ . Doubt 12: How is (9) equal to $A_{n,k}-A_{n,k-1}$ ? And, to my disgrace, even assuming the last equality and after three pages full of equlities, I've been unable to prove that $a_n$ satisfies the desired recursion. Doubt 13: How can we show, using all the previous definitions that $a_n$ satisfies the recurrence relation stated at the beggining of the paper? I know there are a lot of doubts, but I've been working on this for 3 weeks now and I'm not able to solve any of the questions asked by myself. I think the post can be very useful to anyone interested in this proof because I think all the details I'm trying to proof are not easy for any student who reads the paper, so it would be great if anyone interested can contribute and we can answer all of them and have a really complete post about Apery's proof. I will continue working on it anyway and if I get some answers I'll update the post.","['number-theory', 'irrational-numbers', 'asymptotics', 'combinatorics', 'riemann-zeta']"
3585229,Formal definition of definite condition of membership $\in$ in set theory?,"We have sets $\{ x \}$ and $\{ \{ x \} \}$ . Then it holds that $x \in \{ x \}$ but $x \notin \{ \{ x \} \}$ . It seems that the condition of membership ( $\in$ ) presupposes that only those things in a set $A$ which are only in $A$ and in no set in $A$ , are the members of $A$ . More simply, only those things that are in $A$ in its ""first layer"" are the members of $A$ . But apart from using natural language, how can one define $\in$ ? Is this even possible in set theory or do we have to use something outside of it (such as first-order logic) to formally define $\in$ ?","['elementary-set-theory', 'philosophy']"
3585230,What is the inverse cdf / ppf of the logit-normal distribution?,"In this post , I am trying to implement the logit-normal distribution in Python. The provided answer works for me, however, the rvs method that draws random variates failes for me. According to the documentation of the pdf class that I am using: ""The default method _rvs relies on the inverse of the cdf, _ppf, applied to a uniform random variate. In order to generate random variates efficiently, either the default _ppf needs to be overwritten (e.g. if the inverse cdf can expressed in an explicit form) or a sampling method needs to be implemented in a custom _rvs method."" This is what I am trying to figure out, but I couldn't find a description of the inverse logit-normal cdf anywhere. How do I do this?","['python', 'statistics', 'probability-distributions']"
3585247,"Groups of integers with equal sums, equal sums of squares, equal sums of cubes....","The following three groups of 6 numbers have equal sums, sums of squares, sums of cubes,... up to fifth powers. How would one go about finding such groups? 784 134
17  901
342 576 12  906
596 322
769 149 684 234
917 1
226 692 Trying to relate this to Newton's identities for sums of roots I have noticed that, when the numbers are taken as roots of polynomials, the polynomials produced are identical up to a constant: $x^6 - 2754 x^5 + 2845537 x^4 - 1356302772 x^3 + 292772763028 x^2 - 23245284585024 x + 316988249001984$ $x^6 - 2754 x^5 + 2845537 x^4 - 1356302772 x^3 + 292772763028 x^2 - 23245284585024 x + 239069505576384$ $x^6 - 2754 x^5 + 2845537 x^4 - 1356302772 x^3 + 292772763028 x^2 - 23245284585024 x + 22953865281984$ What is going on here?","['number-theory', 'sums-of-squares', 'polynomials']"
3585298,Intuitive motivation for limit computations,"This is a Q&A pair concerning intuitive motivation for limit computations. Usually, my standard advice is to use asymptotic expansions to compute limits (especially for harder things like this or this ), but if we wish to do it without asymptotic expansions yet in a well-motivated way, we may want to have some intuitive explanation for why various elementary tricks work. For example, to prove that $\dfrac{1+2x-\sqrt[3]{1+6x}}{x^2} ≈ 4$ as $x → 0$ , an elegant way is to let $p = 1+2x$ and $r = \sqrt[3]{1+6x}$ , so as $x → 0$ we have $p,r → 1$ and hence $\dfrac{p-r}{x^2}$ $= \dfrac{p^3-r^3}{x^2·(p^2+p·r+r^2)}$ $= \dfrac{12+{?}x}{p^2+p·r+r^2}$ $≈ \dfrac{12}{1+1+1}$ . This trick may seem mysterious. After all, why did 'multiplying by the conjugate' work, and it is always possible to find such tricks? What if we are asked to find $\lim_{x→0} \dfrac{\sqrt{1+4x}-\sqrt[3]{1+6x}}{x^2}$ ? Is there a systematic yet intuitive way to figure out that we can apply the above trick to both parts? Personally, I prefer computing it by asymptotic expansion, namely that as $x → 0$ we clearly have $\sqrt{1+4x} ∈ 1+2x-2x^2+o(x^2)$ and $\sqrt[3]{1+6x} ∈ 1+2x-4x^2+o(x^2)$ , and so the result follows quickly. But the question remains: Can we find the asymptotic expansion intuitively without higher-power tools (such as Taylor series or binomial expansion for non-natural powers)? And better still, can we find an elementary solution without even rigorously proving the asymptotic expansion?","['real-analysis', 'taylor-expansion', 'intuition', 'limits', 'soft-question']"
3585311,"Computing the width of a cusp of a congruence subgroup of level $N$ ""in characteristic $N$"".","Let $\Gamma$ be a congruence subgroup of $\text{SL}_2(\mathbb{Z})$ of level $N$ and let $\pi:\text{SL}_2(\mathbb{Z})\to\text{SL}_2(\mathbb{Z}/N\mathbb{Z})$ be the reduction map, which is surjective. Let $$
C_N=\bigg\{\begin{pmatrix}x\\y
\end{pmatrix}\in(\mathbb{Z}/N\mathbb{Z})^2\colon\text{$x$ and $y$ generate $\mathbb{Z}/N\mathbb{Z}$}\bigg\}.$$ Set $H=\pi(\Gamma)$ . Then there is a natural $H$ -action on $C_N$ , and a natural bijection $\Phi:\text{Cusp}(\Gamma)\to H\backslash C_N$ between cusps of $\Gamma$ and $H$ orbits in $C_N$ . Normally for a cusp $\mathfrak{c}\in\text{Cusp}(\Gamma)$ , set $H_{\mathfrak{c}}=\gamma_{t}^{-1}\Gamma\gamma_{t}\cap\text{SL}_2(\mathbb{Z})_\infty$ , where $\gamma_t\in\text{SL}_2(\mathbb{Z})$ such that $\gamma_t\infty=t\in\mathfrak{c}$ and $\text{SL}_2(\mathbb{Z})_\infty$ is the stabilizer of $\infty$ . Then the width of the cusp is defined as the index of $\{\pm\}H_{\mathfrak{c}}$ in $\text{SL}_2(\mathbb{Z})_\infty$ . Before going to lockdown, my professor told me that it is sometimes easier to compute these widths ""in characterstic $N$ "", by which he meant using $C_N$ and $\text{SL}_2(\mathbb{Z}/N\mathbb{Z})$ and this is where I came up with. Note that by the Orbit stabilizer $\text{SL}_2(\mathbb{Z}/N\mathbb{Z})/\text{SL}_2(\mathbb{Z}/N\mathbb{Z})_\infty=\text{SL}_2(\mathbb{Z}/N\mathbb{Z})\cdot\infty\cong C_N$ , so $\text{SL}_2(\mathbb{Z}/N\mathbb{Z})$ acts transitively on $C_N$ . Let $\mathfrak{c}$ be a cusp of $\Gamma$ and let $(x,y)$ be an element from the $H$ -orbit corresponding to $\mathfrak{c}$ . I choose $\gamma\in\text{SL}_2(\mathbb{Z})$ such that $\gamma(1,0)=(x,y)$ . Then I define $\tilde{H}_{\mathfrak{c}}:=\gamma^{-1}H\gamma\cap\text{SL}_2(\mathbb{Z}/N\mathbb{Z})_\infty$ . I have now two questions. Is is indeed true that $\tilde{H}_{\mathfrak{c}}=\pi(H_{\mathfrak{c}})$ ? and how does $[\{\pm1\}\tilde{H}_{\mathfrak{c}}:\text{SL}_2(\mathbb{Z}/N\mathbb{Z})]$ relate to $[\{\pm 1\}H_{\mathfrak{c}}\colon\text{SL}_2(\mathbb{Z})_\infty]$ ?","['number-theory', 'group-theory', 'modular-forms']"
3585343,Can we classify the solutions of $\ 2n-\sigma(n)=-12\ $ completely?,"This question A number-13 phenomenon contains the equation $$ 2n-\sigma(n)=-12 $$ where $\ \sigma(n)\ $ is the sum of the divisors of $\ n\ $ including $\ n\ $ . There are two families of solutions : If $\ p>3\  $ is prime  , then $\ 6p\ $ is a solution If $\ p=2^k-13\ $ , $\ k\ $ integer , is prime , then $\ 2^{k-1}\cdot p\ $ is a solution The only solution upto $\ 10^9\ $ that fits in neither family, is $\ n=54\ $ . Is the list complete with the two families and the additional solution $\ 54\ $ ?","['number-theory', 'summation', 'elementary-number-theory', 'prime-numbers']"
3585366,Continuous expanding self mapping between compact metric spaces,"I'm stuck with this exercise: Let $K$ be a compact set in a metric space $(X,d)$ and let the self mapping $ f:K \rightarrow K$ be continuous and expanding (i.e $d(f(x),f(y)) \ge d(x,y) \ \forall x,y \in K$ ). Show that $f(K)=K$ . In my attempt I've already shown that $f$ is a homeomorphism from $K$ to $f(K)$ . Now I want to show the double inclusion: $f(K) \subset K$ is clear, but I'm stuck with $K \subset f(K)$ .
My idea was to procede via contradiction and maybe after use a Fix Point theorem, i.e suppose that $\exists \ k \in K \ s.t \ k \notin f(K)$ . But now I'm stuck. Any help or suggestion would be greatly appreciated, thank you in advance.","['general-topology', 'functions', 'functional-analysis']"
3585369,Change of variables in proof of Bochner's theorem,"I have $\phi: \mathbb{R} \to \mathbb{R}$ continuous, bounded, and integrable. I'm going through a book which makes the following calculation: $$\frac{1}{2\pi}\int\limits_{-\infty}^{\infty}e^{-itx}\phi(t)dt = \lim\limits_{T\to \infty}
\frac{1}{2\pi}\int\limits_{-T}^{T}\left(1 - \frac{|t|}T \right)e^{-itx}\phi(t)dt = 
\lim\limits_{T\to \infty}
\frac{1}{2\pi T}\int\limits_{0}^{T} \int\limits_{0}^{T} e^{-i(t-s)x}\phi(t-s)dtds.
$$ The first equality holds by the Dominated Convergence Theorem and the second is supposed to hold by a change of variables. Can someone please show me how this change of variables goes? Edit: If it helps, this is in the book of Varadhan in the proof of Bochner's theorem. This computation is being made to use the positive-definiteness of $\phi$ .","['measure-theory', 'probability-distributions', 'fourier-transform', 'real-analysis', 'probability-theory']"
3585413,Simple groups satisfying some conditions,"We are looking for an example of simple groups $G$ of order $n$ such that the following condition (*) does not hold : (*) for every factorization $n=ab$ there exists a non-trivial subgroup of $G$ whose index is a divisor of $a$ or $b$ . Note that: If $G$ has a subgroup of prime index, then (*) holds, and so the simple groups of orders 60, 168, 660 etc., are removed from the list (of finite simple groups). Also, (*) holds for the simple group of order 360 (with no subgroup of prime index). Therefore, order of the first example, if exists, must be a number equal or greater than 2448. Note. I've made a correction for this question now, since the mentioned item 3 ( The simple groups of orders 504 and 1092 also admit (*)) was wrong. Indeed, the first three examples are $PSL(2,8)$ of order 504 with $(a,b)=(12,42), (21,24)$ , $PSL(2,13)$ of order 1092 with $(a,b)=(21,52)$ , and (as it is mentioned by Derek Holt) $PSL(2,17)$ of order 2448 with $(a,b)=(48,51)$ . Therefore, this question has been answered. Any idea for the problem? Thanks in advance.","['gap', 'group-theory', 'simple-groups', 'finite-groups']"
3585472,Sections of Cokernel sheaf,"The bounty expires in 7 days . Answers to this question are eligible for a +50 reputation bounty. LiminalSpace is looking for a canonical answer : An explanation of why this is true (or not) will certainly be sufficient for the bounty. Ideally, I'd like to see if a similar type of characterization applies to a broader class of not necessarily separated sheaves in algebraic geometry — is there an analogous characterization for, say, the symmetric algebra of a sheaf? Consider a sheaves morphism $f\colon \mathcal{F}\to \mathcal{G}$ , where $\mathcal{F}$ and $\mathcal{G}$ are sheaves on a topological space $X$ . Now we have the cokernel presheaf and its sheafification $\textit{Coker}(f)$ . How can we describe the sections of this sheaf? In Griffith-Harris, Principles of Algebraic Geometry, on page 37, is stated that a section of $\textit{Coker}(f)$ on an open set $U\subseteq X$ is given by an open covering $(U_{\alpha})$ of $U$ and by a family $ (s_{\alpha})$ with $s_{\alpha}\in \mathcal{G}(U_{\alpha})$ such that for every overlapping open sets $ U_{\alpha}, U_{\beta}$ we have $ {s_{\alpha}}_{|U_{\alpha}\cap U_{\beta}}-{s_{\beta}}_{|U_{\alpha}\cap U_{\beta}}\in f_{U_{\alpha}\cap U_{\beta}}(\mathcal{F}(U_{\alpha}\cap U_{\beta}))$ . My question is: why this is true? I know that a similar characterization holds for the sections of the sheafification of a separated presheaf, but the cokernel presheaf is not separated in general, if i am correct. For example this is true if $f$ is injective, but in general?","['complex-geometry', 'algebraic-geometry']"
3585479,How to evaluate limits of inverse trigonometric functions without L'Hospital and series expansion?,"I am studying limits and how to evaluate them without using l'Hospital Rule or series expansion.
Most of them aren't that hard, there are some common trick to do, but I have issues when I face limits of some not-so-common functions such as inverse trigonometric functions. An example of such a function is this: And also: I have no idea how to even approach such a limit so I would be happy if you could, besides just solving these two limits explain some approaches to evaluating limits with inverse trigonometric functions in general.","['limits', 'trigonometry', 'limits-without-lhopital', 'analysis']"
3585502,Find $f(x)$ such that: $ f'(x) + f(x^2) = 2x + 1 $,"How to find the function $f(x)$ that is derivable on $\mathbb{R}$ and satisfies the equation: $$ f'(x) + f(x^2) = 2x + 1 \text{ } \text{ } \forall x \in \mathbb{R}$$ My attempt: Substitute $-x$ for $x$ in the equation, we have a system of 2 equations : \begin{cases} 
f'(x) + f(x^2) &= 2x + 1\\ 
f'(-x) + f(x^2) &= -2x + 1
\end{cases} Take the difference of them, we have: $$ f'(x) - f'(-x) =4x $$ Integrate both sides: $$ f(x) + f(x) = 2x^2 + C_1 $$ Therefore, we have: $$ f(x) = x^2 + C_2 $$ However, this method results in an invalid solution to the original equation. I wonder whether there is another way to solve this problem or why my solution is wrong. Thanks in advance.","['integration', 'calculus', 'ordinary-differential-equations']"
3585505,Should infinite order elements not be called zero order elements?,"For a unital ring $R$ , there is a homomorphism $f:\mathbb{Z}\rightarrow R$ and the kernel is an ideal of the form $n\mathbb{Z}$ for unique $n\in \mathbb{N}$ , which we call the characteristic of the ring. In a similar kind of way, for a group $G$ , and $g\in G$ there is a homomorphism $f:\mathbb{Z}\rightarrow G$ sending $n$ to $g^n$ . The kernel of this homomorphism is again of the form $n\mathbb{Z}$ for unique $n\in \mathbb{N}$ which we call the order of $g\in G$ , except for when $n=0$ and then we say $g$ has infinite order. Wouldn't it be better to say $g$ has order zero in this case, for consistency?","['group-theory', 'abstract-algebra']"
3585516,Show that $f(x)$ is linear if $\frac{1}{2y}\int^{x+y}_{x-y}f(t)dt=f(x)$ for all $y>0$,"Let $f:\mathbb{R} \to \mathbb{R} $ be a twice differentiable function such that for all $y>0,$ $$\frac{1}{2y}\int^{x+y}_{x-y}f(t)dt=f(x)\ \ \ \ \forall\  x\in \mathbb{R}$$ Show that there exists $a, b\in \mathbb{R}$ such that $f(x)=ax+b\ \ \forall \ x\in\mathbb{R}$ I was able to get that $$f'(x)=\frac{f(x+y)-f(x-y)}{2y}\ \forall \ y>0$$ by using Newton-Leibniz rule for differentiation under the integral sign. I am not able to proceed further..Any of my further efforts ends in proving that $f(x)=f(x)$ and other such results.. Thanks for any answers!!","['limits', 'calculus', 'functions', 'real-analysis']"
3585521,Taking Limits of Expressions of Different Variables in Proof of L'Hopital's Rule?,"In my real analysis textbook, they present the proof of L'Hopital's by using Cauchy's mean value theorem. The part in the proof I am struggling to work out rigorously is a particular implication involving equivalent limits using different variables. We have assumed that $f(c)=g(c)=0$ , $f$ and $g$ are differentiable on a neighbourhood of $c$ , and that the limit $\lim_{x \to c} \frac{f'(x)}{g'(x)} = l$ . In the proof we consider a neighbourhood of $c$ , and we already know $f$ and $g$ are differentiable on the neighbourhood. We define $y$ to be a specific point such that $y > c$ . Then $f$ and $g$ satisfy Cauchy's Mean Value Theorem on $[c,y]$ . We then know that $$\frac{f'(z)}{g'(z)} = \frac{f(y)-f(c)}{g(y)-g(c)} = \frac{f(y)}{g(y)}$$ So now we let $y \to c^+$ and it follows that $z \to c^+$ . By simply renaming the domain variable, we know that $$\lim_{z \to c^+} \frac{f'(z)}{g'(z)} = l$$ My book then says: It follows that $$\lim_{y \to c^+} \frac{f(y)}{g(y)} = l$$ This step is intuitively obvious to me; and my reasoning is that by the way we have defined $y$ and $c$ , the expressions $\frac{f'(z)}{g'(z)}$ and $\frac{f(y)}{g(y)}$ are exactly equal for any corresponding values of $y$ and $c$ , and thus the sequences defined by these two expressions are exactly equal. Thus the limits are obviously equal. Is this reasoning correct? I also wanted to clarify how, if it is possible, I can take the limits of both the rhs and lhs of an equation when they are expressed using different variables? For example, if we have $f(x) = g(x)$ , then I can simply say $\lim_{x \to c} f(x) = \lim_{x \to c} g(x) = m$ . This is easy since there is only one domain variable. But in my particular case, how could I simultaneously take the limits of both sides of $\frac{f'(z)}{g'(z)} = \frac{f(y)}{g(y)}$ ? Is this even possible? The only justification I can think of is the one I described above, where I deduce that the two sequences must be the same for the particular limits I have chosen, and thus must have equal limits. In other words, I don't know a general method for taking the limit of equivalent expressions of different variables?","['limits', 'proof-explanation', 'real-analysis']"
3585540,Show that $K_2(F)$ is a direct summand of $K_2F(t)$,"I have a question regarding Example 6.1.2 (page 252) from the book ""The K-Book"" by Charles Weibel. Here is the statement: Example 6.1.2: Let $F(t)$ be a rational function field in one variable $t$ over $F$ . Then $K_2(F)$ is a direct summand of $K_2F(t)$ . $\text{ }$ I find it quite difficult to understand the argument, so I hope I can get some help from here. His goal is to construct an inverse map $\lambda: K_2 F(t)\to K_2(F)$ to the natural map $K_2(F)\to K_2 F(t)$ . Make the following definitions $$f(t)=\frac{a_0t^n+\cdots + a_n}{b_0t^m+\cdots+ b_m},$$ $\operatorname{lead}(f):=\frac{a_0}{b_0}$ and $\lambda(\{f,g\})=\{\operatorname{lead}(f),\operatorname{lead}(g)\}$ . Now he says that we may check the representation of Matsumoto's Theorem, to show that $\lambda$ is a homomorphism. We begin to show bilinearity. Let $f,f',g\in F(t)^\times$ then $$\lambda(\{f,g\}\{f',g\})=\lambda(\{ff',g\})=\{\operatorname{lead}(ff'),g\}=\{\operatorname{lead}(f)\operatorname{lead}(f'),g\}=\{\operatorname{lead}(f),g\}\{\operatorname{lead}(f'),g\}=\lambda(\{f,g\})\lambda(\{f',g\}).$$ By symmetry, the same argument works if we consider something like $\lambda(\{f,g\}\{f,g'\})$ instead. Let us now see that the Steinberg identity is, also, satisfied. Consider $f\in F(t)^\times$ and assume $m<n$ , then we have that $\operatorname{lead}(1-f)=-\operatorname{lead}(f)$ , since $$1-\frac{a_0t^n+\cdots a_{n-m}t^{m}+\cdots + a_n}{b_0t^m+\cdots + b_m}=\frac{b_0t^m+\cdots + b_m}{b_0t^m+\cdots + b_m}-\frac{a_0t^n+\cdots a_{n-m}t^{m}+\cdots + a_n}{b_0t^m+\cdots + b_m}=\frac{-(a_0t^n+\cdots a_{n-(m+1)}t^{m+1})+(b_m-a_{n-m})t^{m}+\cdots + (b_m-a_n)}{b_0t^m+\cdots + b_m},$$ and so $\operatorname{lead}(1-f)=-\operatorname{lead}(f)$ . It was showed earlier in the book that $\{x,-x\}=1$ for every $x\in E^\times$ , where $E$ is some field. Thus $\{\operatorname{lead}(f),\operatorname{lead}(1-f)\}=\{\operatorname{lead}(f),-\operatorname{lead}(f)\}=1$ . One can also show by similar reasoning that $\{\operatorname{lead}(f),\operatorname{lead}(1-f)\}=\{\operatorname{lead}(f),1-\operatorname{lead}(f)\}=1$ if $n=m$ and that $\{\operatorname{lead}(f),\operatorname{lead}(1-f)\}=\{\operatorname{lead}(f),1\}$ if $n<m$ . Lastly, they say that since $K_2$ commutes with filtered colimits, it follows that $K_2(F)$ injects into $K_2F(T)$ for every purely transcendental extension $F(T)$ of $F$ . Questions: Why does checking the criteria for Matsuomoto's Theorem prove that $\lambda$ is a homomorphism? Don't we want to pick symbols $\{f,g\},\{f',g'\}$ and check that it is a group homomorphism: $$\lambda(\{f,g\}\{f',g'\})=\lambda(\{f,g\})\lambda(\{f',g'\})?$$ By
checking Matsumoto's Theorem don't we just make sure that we map
elements from $K_2F(t)$ to $K_2(F)$ ? Why does the following equality hold $\{\operatorname{lead}(f),1\}=1$ ? How comes that the last paragraph implies that $K_2(F)$ injects into $K_2F(T)$ ? I don't really understand why $K_2$ commutes with filtered colimits but if I take it for granted for the moment, why does it prove the fact? Lastly, why does showing that $K_2(F)\to K_2 F(T)$ is injective show that $K_2(F)$ is a direct summand of $K_2F(t)$ ? The answers are maybe/probably easy, but I am quite confused right now, new to $K$ -theory and I don't manage to figure it out. Best wishes, Joel Edit: Matsumoto's Theorem (for completeness): If $F$ is a field, then $K_2(F)$ is the abelian group generated by the set of Steinberg symbols $\{x,y\}$ with $x,y\in F^\times$ , subject to (only) the following relations: $$\quad\quad\text{(Bilinearity)}\quad\{xx',y\}=\{x,y\}\{x',y\}\text{ and }\{x,yy'\}=\{x,y\}\{x,y'\}$$ $$\text{(Steinberg identity)}\quad\{x,1-x\}=1\text{ for all }x\not = 0,1.$$","['k-theory', 'group-theory', 'abstract-algebra', 'algebraic-k-theory']"
3585569,Sum of numbers $x+y$ satisfying $x^2+y^2=p$ with $p$ being a prime number,"(This question has been inspired by a similar one from James Johnson ) It's a well known fact that every prime number $p$ such that: $$p\equiv 1 \pmod 4\tag{1}$$ can be represented as a sum of two integer squares in a unique way: $$p=x^2+y^2$$ Suppose that $p_i$ is the $i$ -th number of the form (1). Create a sequence of numbers $z_i=x_i+y_i$ where $x_i^2+y_i^2=p_i$ : 3, 5, 5, 7, 7, 9, 9, 11, 11, 13, 13, 11, 13, 15, 15, 17, 17, 15, 19, 
19, 15, 17, 21, 19, 17, 23, 23, 21, 19, 25, 25, 25, 23, 25, 25, 27, 
25, 21, 23, 29, 29, 27, 25, 29, 27, 31, 31, 33, 33, 25, 31, 29, 35, 
35, 29, 35, 31, 35, 27, 31, 37, 29, 35, 39, 37, 39, 37, 33, 39, 37, 
41, 33, 35, 41, 43, 43, 39, 41, 35, 37, 43, 45, 41, 35, 37, 41, 43, 
35, 45, 47, 47, 47, 41, 39, 45, 49, 49, 47, 37, 43... If you plot points $(i,z_i)$ the graph looks like this: Two questions: Is this sequence listed somewhere on OEIS? I could not find it, though many similar ones exist. Conjecture: the sequence listed above contains every odd number $n\ge 3$","['number-theory', 'summation', 'elementary-number-theory', 'prime-numbers']"
3585702,The value of parameter $a$ for which $\dfrac{ax^2+3x-4}{a+3x-4x^2}$ takes all real values for $x\in R$ are:,"=> The value of parameter $a$ for which $\dfrac{ax^2+3x-4}{a+3x-4x^2}$ takes all real values for $x\in R$ are: My question is why we need to validate end points i.e. $1,7$ (Refer the last part of my attempt) My attempt is as follows:- $$y=\dfrac{ax^2+3x-4}{a+3x-4x^2}$$ $$ya+3yx-4yx^2=ax^2+3x-4$$ $$x^2(-4y-a)+x(3y-3)+ya+4=0$$ As $x$ can be any real, so $D\ge0$ $$9y^2+9-18y-4(ya+4)(-4y-a)\ge0$$ $$9y^2+9-18y+4(4y^2a+ya^2+16y+4a)\ge0$$ $$y^2(9+16a)+y(4a^2+64-18)+9+16a\ge0$$ $$y^2(9+16a)+y(4a^2+46)+9+16a\ge0$$ As range is $R$ , so discriminant of quadratic in $y$ should be less than equal to zero $$4(2a^2+23)^2-4(9+16a)^2\le0$$ $$(2a^2+23-9-16a)(2a^2+23+9+16a)\le0$$ $$(2a^2-16a+14)(2a^2+16a+32)\le0$$ $$(a^2-8a+7)(a^2+8a+16)\le0$$ $$a\in[1,7]$$ But in such type of questions, we always check at endpoints like here we need to check at $a=1$ and $a=7$ . But I don't understand what is so special about endpoints. From the above calculation I can only say at $a=1,7$ discriminant of quadratic in $y$ is zero, but what is so special about this. Please help me in this.","['functions', 'quadratics']"
3585705,Not valid projective algebraic set,"I need to prove that given a point $[a_0,..., a_n] \in \mathbb{P} ^n$ , expressions of the form $$V=V(x_0-a_0,...,x_n-a_n) \subseteq \mathbb{P} ^n$$ are not well defined algebraic sets. It's clear that the polynomials involved in the expression are not homogeneous, but I don't see how this allows me to conclude $V$ cannot be a well defined algebraic set. I've tried to reach a contradiction assuming that the ideal generated by $ x_0-a_0,...,x_n-a_n $ is homogeneous (i. e. it's generated by homogeneous polynomials), but I'm stucked. Any suggestion?","['algebraic-geometry', 'projective-geometry', 'polynomials']"
3585707,"Leibniz formula for $\pi$, is there any ways to relate the two proofs?","There are 2 common proofs of Leibniz formula $\frac{\pi}{4}=\sum_{n=0}^{\infty}(-1)^{n}(2n+1)^{-1}=\frac{1}{1}-\frac{1}{3}+\frac{1}{5}-\frac{1}{7}+\ldots$ Calculus proof: The first come by studying the power series $\sum_{n=0}^{\infty}(-x)^{n}(2n+1)^{-1}=\frac{x^{1}}{1}-\frac{x^{3}}{3}+\frac{x^{5}}{5}-\frac{x^{7}}{7}+\ldots$ and then ""take the limit $x\rightarrow 1^{-}$ "" (apply Abel's theorem). The proof proceed by differentiating, then recognize that this is a geometric series, and then integrating again, it can be shown that this is just the Taylor's series of $\arctan$ . This is a well-known in calculus. Leibniz's original geometric argument can be easily related to it: he basically showed, by drawing circle and chord, something that (after an algebraic manipulation) is equivalent to $\frac{d\arctan(x)}{dx}=\frac{1}{1+x^{2}}$ , a result much more easily obtained now using the more general theorem about inverse function theorem, or trig substitution, after knowing the derivative of $\tan$ . Circles even show up here due to trigonometric functions. Number theory proof: The second proof come by studying the Dirichlet series $\sum_{n=0}^{\infty}(-1)^{n}(2n+1)^{-s}=\frac{1}{1^{s}}-\frac{1}{3^{s}}+\frac{1}{5^{s}}-\frac{1}{7^{s}}+\ldots$ and then ""take the limit $s\rightarrow 1^{+}$ "" (perform analytic continuation to $Re(s)>\frac{1}{2}$ ). The proof proceed by showing that $2(\sum_{n=0}^{\infty}(-1)^{n}(2n+1)^{-s})(\sum_{z\in\mathbb{Z}\backslash\{0\}}|z|^{-s})=\sum_{z\in\mathbb{Z[i]}\backslash\{0\}}(|z|^{2})^{-s}$ . This can be shown from the following number theory fact: $r_{2}(n)=4(d_{1}(n)-d_{3}(n))$ . Here $r_{2}(n)$ that the number of ways to write a positive integer $n$ as a sum of 2 squares, counting swapping position as distinct, counting negative numbers squared as distinct, basically counting all possible ordered pair of integers $(a,b)$ such that $a^{2}+b^{2}=n$ . And $d_{1}(n)$ the number of positive divisors of $n$ that are $1(\mod 4)$ , $d_{3}(n)$ the number of positive divisors of $n$ that are $3(\mod 4)$ . This number-theoretic fact can be proved from Fermat's theorem about which prime can be written as the sum of 2 squares, and the fact that $\mathbb{Z}[i]$ is an Euclidean domain (since it forms a lattice). Once the equation $2(\sum_{n=0}^{\infty}(-1)^{n}(2n+1)^{-s})(\sum_{z\in\mathbb{Z}\backslash\{0\}}|z|^{-s})=\sum_{z\in\mathbb{Z[i]}\backslash\{0\}}(|z|^{2})^{-s}$ is known, taking limit is easy. $\lim_{s\rightarrow 1^{+}}\frac{1}{2}\frac{\sum_{z\in\mathbb{Z[i]}\backslash\{0\}}(|z|^{2})^{-s}}{\sum_{z\in\mathbb{Z}\backslash\{0\}}|z|^{-s}}$ can be computed by replacing the numerator and denominator by a continuous approximation $\lim_{s\rightarrow 1^{+}}\frac{1}{2}\frac{\int_{z\in\mathbb{C}\backslash\{0\}}(|z|^{2})^{-s}dz}{\int_{z\in\mathbb{R}\backslash\{0\}}|z|^{-s}dz}$ , and change to polar coordinate this is just $\frac{1}{2}\frac{\pi\int_{r\in\mathbb{R}^{+}}r^{-s}dr}{2\int_{r\in\mathbb{R}^{+}}r^{-s}dr}$ . So we obtain the result. Circles even show up as polar coordinate. Question: So while both proof has some similarities: they both extend the original question into a generating function, using some counting facts to relate it to other functions, and circles actually show up. Conceptually the 2 proofs are still very different, or at least seems to be. So my question is this. Is there a deeper connection behind the scene of these 2 proofs that I did not know about? Is there some sort of ""bijective"" transformation of one proof into another? Or are they just so completely different that there are no ways? EDIT: forgot to mention this, but this observation is obvious. In the number theory proof we use $\mathbb{Z}[i]$ , while in the calculus proof we use $\frac{1}{x^{2}+1}$ . But $i$ is the root of $x^{2}+1$ .","['number-theory', 'calculus', 'pi', 'intuition']"
3585771,Prove $\cos(\pi x)=\sinh(\pi)/\pi\sum_{n=0}^{\infty}\left(\frac{\left(-1\right)^{n}}{1+\left(x-n\right)^{2}}+...\right)$,It seems that $\cos(\pi x)$ is given by $$\cos(\pi x)=\frac{\sinh(\pi)}{\pi}\sum_{n=0}^{\infty}\left(\frac{\left(-1\right)^{n}}{1+\left(x-n\right)^{2}}-\frac{\left(-1\right)^{n\ }}{1+\left(x+n+1\right)^{2}}\right).$$ I found this by playing around in desmos . Do you know how we could prove this? Has a similar result to this been published elsewhere on the internet? I can't find anything.,"['trigonometry', 'sequences-and-series']"
3585812,Deriving the logarithmic expressions of inverse trigonometric functions,"I see here a list of inverse trigonometric functions written in terms of logarithms. The ones I'm most interested in for the purposes of this question are $\arcsin{z}=-i\ln\left(iz+\sqrt{1-z^2}\right)$ and $\arccos{z}=-i\ln\left(z+\sqrt{z^2-1}\right)$ . These look sort of reminiscent of certain properties of their inverses, namely: $e^{i\theta}=\cos\theta+i\sin\theta$ leading to the natural log being used, as well as $\sin$ being the imaginary component and $\cos$ the real component leading to an $iz$ term in the former's inverse's expansion, and a regular $z$ term in the latter's. Additionally, if you differentiate each of these and simplify, you get their expected derivatives. And, of course, if you plug in these definitions into their inverses' exponential forms you get $x$ . What I'm struggling with is proving that this is the case. How can I take $\sin{x}=\frac{e^{ix}-e^{-ix}}{2i}$ and $\cos{x}=\frac{e^{ix}+e^{-ix}}{2}$ and invert them to get the definitions above?","['trigonometry', 'inverse-function', 'complex-numbers', 'logarithms']"
3585834,Conceptual question about assuming the existence of a function in order to prove the existence of another function,"I would like to raise a question using an exercise from Tao's Analysis I as an example. The exercise is presented as follows: Let $f:\mathbb N \times \mathbb N \to \mathbb N$ be a function, and let $c$ be a natural number. Show that there exists a function $a : \mathbb N \to \mathbb N$ such that $$a(0) =c $$ and $$a(n++)=f(n,a(n)) \text{ for all } n \in \mathbb N$$ My question is not about how to solve this problem. Rather, I am trying to understand what exactly the assumption "" $f: \mathbb N \times \mathbb N \to \mathbb N$ "" is trying to suggest to the reader. I have just learned quite a bit more detail about functions (e.g. the difference between set functions and class functions ). In light of this, in the absence of providing a specific mapping rule , it seems to me that "" $f: \mathbb N \times \mathbb N \to \mathbb N$ "" must be some sort of shorthand for: "" $f$ is a set function... where the exact mapping rule is arbitrary...but we at least know the sets from which the first and second component of the ordered pairs come from "". Is this a correct interpretation? If so, then is this a correct abridged formalization of the overall proof? $\forall f \text{ such that } (\forall (x,y) \in f, x \in \mathbb N \times \mathbb N \land y \in \mathbb N)$ , $\exists a \text{ such that ...}$","['elementary-set-theory', 'proof-writing', 'functions', 'logic']"
3585868,Cardinality of a set of circles,Find the cardinality of a set of circles in the plane whose centre has rational coordinates and whose radius is the square root of a prime number.,"['elementary-set-theory', 'real-numbers', 'cardinals']"
3585894,Does the closure of a strict sublevel set of a continuous function equal a non-strict sublevel set?,"Let $X \subset \mathbb{R}^{n}$ be closed and $f$ be a continuous real valued function on $X$ . Consider now the sets \begin{align}
S_{<}   = \{ x \in X : f(x) < 0 \}, &&
S_{\le} = \{ x \in X : f(x) \le 0 \}.
\end{align} Is it generally true that if $ S_{<} \ne \emptyset$ , then $\overline{S_{<}} = S_{\le}$ ?","['functions', 'set-valued-analysis', 'real-analysis']"
3586026,"Integral $\mathcal{P}\int_{-\infty}^{\infty}\frac{\tanh\left(\frac{1}{x^2}\right)}{x-k}\,dx$","I need help solving the integral $$\mathcal{I}(k)=\mathcal{P}\int_{-\infty}^{\infty}\frac{\tanh\left(\frac{1}{x^2}\right)}{x-k}\,dx$$ for $k>0$ . The $\mathcal{P}$ denotes the Cauchy principal value. Mathematica has been unhelpful, but numerical tests show that it converges. I would also be happy with a series or asymptotic solution. Edit: I attempt to solve for the asymptotic behaviour using Maxim's useful comment. Note that $$\mathcal{I}(k)\sim-\frac{1}{k}\int_{-\infty}^{\infty}\tanh\left(\frac{1}{x^2}\right)\,dx$$ for large $k$ . Then $$\mathcal{I}(k)=-\frac{1}{k}\int_{-\infty}^{\infty}\tanh\left(\frac{1}{x^2}\right)\,dx+\int_{-\infty}^{\infty}\frac{\tanh\left(\frac{1}{x^2}\right)}{x-k}\,dx+\frac{1}{k}\int_{-\infty}^{\infty}\tanh\left(\frac{1}{x^2}\right)\,dx$$ $$\mathcal{I}(k)=-\frac{1}{k}\int_{-\infty}^{\infty}\tanh\left(\frac{1}{x^2}\right)\,dx+\int_{-\infty}^{\infty}\tanh\left(\frac{1}{x^2}\right)\left[\frac{1}{x-k}+\frac{1}{k}\right]\,dx$$ $$\mathcal{I}(k)=-\frac{1}{k}\int_{-\infty}^{\infty}\tanh\left(\frac{1}{x^2}\right)\,dx+\frac{1}{k}\int_{-\infty}^{\infty}\tanh\left(\frac{1}{x^2}\right)\left[\frac{x/k}{x/k-1}\right]\,dx$$ $$\mathcal{I}(k)=-\frac{1}{k}\int_{-\infty}^{\infty}\tanh\left(\frac{1}{x^2}\right)\,dx-\frac{1}{k^2}\int_{-\infty}^{\infty}x\tanh\left(\frac{1}{x^2}\right)\left[\frac{1}{1-x/k}\right]\,dx$$ $$\mathcal{I}(k)\sim-\frac{1}{k}\int_{-\infty}^{\infty}\tanh\left(\frac{1}{x^2}\right)\,dx-\frac{1}{k^2}\int_{-\infty}^{\infty}x\tanh\left(\frac{1}{x^2}\right)\sum_{j=0}^{\infty}\left(\frac{x}{k}\right)^j\,dx$$ $$\mathcal{I}(k)\sim-\sum_{j=0}^{\infty}\frac{\int_{-\infty}^{\infty}x^j\tanh\left(\frac{1}{x^2}\right)}{k^{j+1}}$$ $$\mathcal{I}(k)\sim-\sum_{j=0}^{\infty}\frac{\int_{-\infty}^{\infty}x^{2j}\tanh\left(\frac{1}{x^2}\right)}{k^{2j+1}}$$ $$\mathcal{I}(k)\sim-2\sum_{j=0}^{\infty}\frac{\int_{0}^{\infty}x^{2j}\tanh\left(\frac{1}{x^2}\right)}{k^{2j+1}}$$ Edit: This still doesn't work. My integrals diverge for $j>0$ . Perhaps useful: $$\tanh(x)=\sum_{j=0}^{\infty}2\frac{(-1)^{j}}{\pi^{2j+2}}\left(4^{j+1}-1\right)\zeta(2j+2)x^{2j+1}$$","['integration', 'improper-integrals', 'definite-integrals', 'asymptotics', 'contour-integration']"
3586069,"Given two functions with recurrence relations and starting values, prove that $f(2020)<5$","There are two functions $f:\mathbb N\to \mathbb R^+$ and $g:\mathbb N\to \mathbb R^+$ . For all $n\in \mathbb N$ : $$f(1)=1$$ $$g(1)=2$$ $$f(n+1)=\frac{1+f(n)+f(n)g(n)}{g(n)}$$ $$g(n+1)=\frac{1+g(n)+f(n)g(n)}{f(n)}$$ Prove that $f(2020)<5$ . Notes: It appears that $\lim_{x\to \infty}f(x)=5$ and $\lim_{x\to \infty}g(x)=\infty$ , though I haven't been able to prove either of these statements. First few results: $f(1)=1; f(2)=2; f(3)=2.6; f(4)=3.05$ and $g(1)=2; g(2)=5; g(3)=8; g(4)=11.\overline{461538}$ .","['contest-math', 'functions', 'recurrence-relations']"
3586112,Can't find why the proof is false (substitution rule).,"Statement : Suppose $f$ and $g$ are functions with domain $\mathbb{R}$ and we want to show that if $$\lim_{x \rightarrow a} f(x) = b\ \ \text{and}\ \lim_{x \rightarrow b} g(x) = c,\ \text{then}\ \lim_{x \rightarrow a} g(f(x)) = c.$$ I know that this statement is false $\bigg($ let $f(x)=0$ and $g(x)=\begin{cases}1&x= 0\\0&x\neq0\end{cases}$ , as $x\to 0$$\bigg)$ . But I don't understand where the following attempt to prove the statement fails. ""Proof"" : 
Since $\lim_{x \rightarrow b} g(x) = c$ , $$\forall\epsilon>0,\ \exists\delta_1,\ 0<|x-b|<\delta_1\Rightarrow |g(x)-c|<\epsilon.\tag 1$$ Since $\lim_{x \rightarrow a} f(x) = b$ , we can choose $\delta_2$ such that $$0<|x-a|<\delta_2\Rightarrow |f(x)-b|<\delta_1.$$ Now, using implication $(1)$ , $$\forall\epsilon>0,\ \exists\delta_2,\ 0<|x-a|<\delta_2\Rightarrow |f(x)-b|<\delta_1 \Rightarrow |g(f(x))-c|<\epsilon,$$ which is $\lim_{x \rightarrow a} g(f(x)) = c$ . The only suspicious point that I see is that to use $(1)$ , it should be the case that $f(x)\neq b$ . But the counterexample relies on the discontinuity of $g$ .","['limits', 'fake-proofs', 'real-analysis']"
3586125,When are these two definitions of a continuous action equivalent?,"Apologies in advance that this is a somewhat vague question. I attempt to make precise below what would constitute an answer for me. Let $G$ be a topological group and $X$ a topological space on which $G$ acts as a set. I have in my mind two different definitions of the statement "" $G$ acts continuously on $X$ ,"" and I would like to know when they are equivalent. The real definition, per Wikipedia , is the assertion that the action map $$\alpha: G\times X \rightarrow X$$ given by $$(g,x)\mapsto gx$$ is a continuous map. This definition is very concise and conceptually slim. But the following alternative definition feels natural to me too, probably because it consists of the information I actually want to know about the action: For any $g\in G$ , the map $\rho_g:X\rightarrow X$ given by $x\mapsto gx$ is a homeomorphism, thus there is a natural group homomorphism $\rho: G\rightarrow \operatorname{Homeo}(X)$ given by $g\mapsto \rho_g$ , where $\operatorname{Homeo}(X)$ is the group of homeomorphisms of $X$ . Endow $\operatorname{Homeo}(X)$ with the compact-open topology. Then $\rho:G\rightarrow \operatorname{Homeo}(X)$ is a continuous map of topological spaces. I assume that these definitions are not equivalent at the generality of my setup, since if $X$ is a totally general topological space, I know that weird things can happen. For example, my impression is that $\operatorname{Homeo}(X)$ needn't be a topological group. (While I am unaware of a specific example, there is a theorem due to Richard Arens [Theorem 4 here ] stating that if $X$ is locally compact, locally connected hausdorff, then $\operatorname{Homeo}(X)$ with the compact-open topology is a topological group; so presumably this fails in greater generality. Of course, it is possible in principle that the definitions are equivalent even when $\operatorname{Homeo}(X)$ is not a topological group.) On the other hand, the real definition does imply the alternative definition in full generality (see appendix below), and it seems likely to me that under some ""ordinary circumstances"" they will coincide. My question is: Under what topological conditions on $G$ and $X$ do the two above definitions of a continuous group action coincide with each other? This question is admittedly vague. I would be happy with any set of conditions sufficient for equivalence that are in the language of general (i.e., point-set) topology. For example, ""this is true if $G$ and $X$ are locally connected, locally compact hausdorff [or whatever]"" would be a satisfying answer, whereas, ""this is true if $G$ is a Lie group and $X$ is a manifold"" is narrower than what I am looking for. Appendix: proof that the standard definition implies the alternative one: Suppose that the action map $\alpha:G\times X\rightarrow X$ is continuous. A ""cross-section embedding"" $X\hookrightarrow G\times X$ given, for a fixed $g$ , by $x\mapsto (g,x)$ , is a continuous map. (An open set in $G\times X$ is a union of sets $V\times U$ , with $V\subset G$ and $U\subset X$ open, and the pullback in $X$ under this ""cross-section embedding"" will be the union of just those $U$ 's whose corresponding $V$ contains $g$ . This is a union of open sets, therefore open.) Therefore, fixing $g$ , the composite map $$ X\hookrightarrow G\times X \xrightarrow{\alpha} X $$ given by $$ x\mapsto (g,x) \mapsto gx$$ is continuous. This is the map $\rho_g$ . It is inverse to $\rho_{g^{-1}}$ , which is continuous for the same reason. Thus $\rho_g$ is a homeomorphism for every $g$ , in full generality. Let $K,U\subset X$ be compact and open, respectively, and let $[K,U]\subset \operatorname{Homeo}(X)$ be the set of homeomorphisms $f:X\rightarrow X$ satisfying $f(K)\subset U$ . Then $\rho^{-1}([K,U])$ consists of those $g\in G$ such that $\rho_g(K)\subset U$ . I would like to know that $\rho^{-1}([K,U])$ is open, since the $[K,U]$ 's form a subbase for the topology of $\operatorname{Homeo}(X)$ . Fix an arbitrary $g\in \rho^{-1}([K,U])$ . Let $k\in K$ be arbitrary. Then $gk = \rho_g(k)=\alpha(g,k)\in U$ , i.e., $(g,k)\in\alpha^{-1}(U)$ . Since $\alpha$ is continuous and $U$ is open, $\alpha^{-1}(U)\subset G\times X$ is open, thus $(g,k)$ is contained in a basis open set of the product topology on $G\times X$ that is entirely contained in $\alpha^{-1}(U)$ . Let it be $V_{gk}\times U_{gk}$ , where $V_{gk}\subset G$ and $U_{gk}\subset X$ are open, and $g\in V_{gk}$ while $k\in U_{gk}$ . Keeping $g$ fixed while allowing $k$ to vary across $K$ , we get an open cover $\{U_{gk}\}|_{k\in K}$ of $K$ . Since $K$ is compact, this cover has a finite subcover $U_{gk_1},\dots,U_{gk_s}$ . Let $V=\bigcap_1^s V_{gk_j}$ . Because this intersection is finite, $V$ is an open subset of $G$ . Since $V\times U_{gk_j} \subset V_{gk_j}\times U_{gk_j}\subset \alpha^{-1}(U)$ for each $j=1,\dots,s$ , we have $$ V\times K \subset V\times \bigcup_1^s U_{gk_j} = \bigcup_1^s V\times U_{gk_j} \subset \alpha^{-1}(U).$$ The first containment is because by construction, $U_{gk_1},\dots,U_{gk_s}$ is a cover of $K$ . Translating the containment $V\times K\subset \alpha^{-1}(U)$ in terms of $\rho$ , this says that $V\subset\rho^{-1}([K,U])$ . Now clearly $g\in V$ since $g\in V_{gk_j}$ for each $j$ (in fact, $g\in V_{gk}$ for each $k$ ). Thus we have identified an open set of $G$ containing $g$ and contained in $\rho^{-1}([K,U])$ . Since $g$ was arbitrary, it follows that $\rho^{-1}([K,U])$ is open. Therefore, $\rho$ is continuous. This proof that $\rho$ is continuous is a direct adaptation of this proof given by Olivier Begassat in the special case that $X=G$ and the action is regular.","['general-topology', 'group-actions', 'topological-groups']"
3586167,"Field of study dedicated to algebra 'tricks' such as change of variable, obscure identity substitution, etc.?","I'm an undergraduate math major and sometimes I find proofs that seem to use algebraic 'tricks' to reach their conclusions.  The 'trick' that I see most often is a change of variable or the use of an obscure identity, and intuitively I have no idea how someone would realize that this is a viable option. Is there a field of study that concerns itself with 'trick' algebraic operations, or maybe a field of study that explains how to determine if/when a change of variable/identity substitution might be an appropriate technique given a situation? For a specific example, I'll reference the proof of the equation for the expectation of the power of a Bernoulli random variable.  I can't imagine how someone would discover this proof. We will now examine the properties of a binomial random variable with parameters $n$ and $p$ . To begin, let us compute its expected value and variance. Now, $$\begin{align} E[X^k] &= \sum_{i = 0}^ni^k\binom{n}{i}p^i(1 - p)^{n - i}\\ 
&= \sum_{i = 1}^ni^k\binom{n}{i}p^i(1 - p)^{n - i} \end{align}$$ Using the identity, $$i\binom{n}{i} = n\binom{n - 1}{i - 1}$$ gives $$\begin{align} E[X^k] &= np\sum_{i = 1}^ni^{k - 1}\binom{n - 1}{i - 1}p^{i - 1}(1 - p)^{n - i}\\ &= np\sum_{j = 1}^{n - 1}(j + 1)^{k - 1}\binom{n - 1}{j}p^j(1 - p)^{n - 1 - j} && \overset{\text{by letting}}{j = i - 1}\\ &= npE[(Y + 1)^{k - 1}] \end{align}$$",['algebra-precalculus']
3586170,A stationary process defined by a really weird stochastic integral.,"A post here: Distribution of integral with respect to Brownian motion described a really weird stationary process. Let us make it simpler, by only considering for $n\in\mathbb{Z}$ , $$X_{n}:=\int_{0}^{2\pi}\cos(nx)Z(dx),$$ where the orthogonal stochastic measure $Z(dx)$ as described in the post has the property $$\mathbb{E}Z=0\ \text{and}\ Var(Z(dx))=\rho(dx)=dx,$$ where $\rho$ is the structure measure of $Z$ , which coincides with the spectral measure of $X_{n}$ . Then, following the post, I tried to compute the variance function, covariance function, mean, etc. For the mean, recall that $\mathbb{E}[Z(d\lambda)]=0$ , so we have $$\mathbb{E}X_{n}=\mathbb{E}\Big(\int_{0}^{2\pi}\cos(n\lambda)Z(d\lambda)\Big)=\int_{0}^{2\pi}\cos(n\lambda)\mathbb{E}[Z(d\lambda)]=0.$$ However, the covariance function is really weird. Below is my computation: \begin{align*}
\mathbb{E}(X_{n}\overline{X_{n+k}})&=\int_{0}^{2\pi}\cos(n\lambda_{1})\cos((n+k)\lambda_{2})\mathbb{E}[Z(d\lambda_{1})\overline{Z(d\lambda_{2})}]\\
&=\int_{0}^{2\pi}\cos(n\lambda)\cos[(n+k)\lambda]d\lambda\\
&=\dfrac{1}{2}\dfrac{\sin[2\pi(k+2n)]}{k+2n}+\dfrac{1}{2}\dfrac{\sin(2\pi k)}{k}.
\end{align*} The final answer can be easily computed using WolframAlpha. So, the covariance function depends not only on $k$ but also on $n$ ???? Then the process cannot be stationary.. right? To verify my computation, I changed a way to compute it by using Herglotz Theorem: $$c(n)=\int_{0}^{2\pi}e^{in\lambda}\rho(d\lambda),$$ but $\rho(d\lambda)=d\lambda$ , so that for $n>0$ , $$c(n)=\int_{0}^{2\pi}e^{in\lambda}d\lambda=\int_{0}^{2\pi}\cos(n\lambda)d\lambda+i\int_{0}^{2\pi}\sin(n\lambda)d\lambda=\dfrac{\sin(2\pi n)}{n}+i\dfrac{2\sin^{2}(\pi n)}{n}.$$ This times, $c(n)$ depends on $n$ but we create some complex number...Also, you can see that the case has to be discussed differently if $n=0$ , or $n<0$ . So the process is complex-valued?? What is the exactly this process? I am really confused.... Thank you!","['stochastic-integrals', 'stochastic-analysis', 'stochastic-processes', 'probability-theory', 'stochastic-calculus']"
3586196,Finding the expected value of a quadratic transformation,"I am given that X is a random variable with a mean of two and variance of 4, as per the question: So, I try to solve the problem by expanding $E[x+2]^2$ $$E[x+2]^2 = E[x+2] * E[x+2]$$ $$E[x+2] = E[x] + E[2] = 2 + 2 = 4$$ $$E[x+2]^2 = 4*4=16$$ However, the answer is 16. I think I am missing something obvious, but I haven't been able to figure it out. Does anyone know why?","['expected-value', 'probability']"
3586221,What is the definition of $X|(Y=y)$?,"Suppose $S$ is a sample space (the set of all outcomes $\omega_i$ ) for an experiment. A random variable $X$ is defined as a real-valued function which maps elements from the sample space to real numbers, i.e. $X:S\to \mathbb R$ . Discrete Random variable: The definition of the conditional probability mass function of $X$ given $Y=y$ is $$\mathbb P(X=x|Y=y)=\frac{\mathbb P(X=x, Y=y)}{\mathbb{P}(Y=y)} .$$ Question: In lecture slides I have seen the notation, for example, that $X|(Y=y) \sim \text{Bin}(m, \lambda).$ What is the definition of $X|(Y=y)$ ? Is it a random variable itself with a restricted sample space? Maybe $X|(Y=y): \{\omega\in S: Y(\omega)=y \} \to \mathbb R$ ? What would be the definition of $X|(Y=y)$ for $X$ and $Y$ being continuous random variables? (Note: If it isn't a random variable, then how can we talk about it's distribution and expected value?)","['conditional-probability', 'definition', 'probability-theory', 'probability']"
3586223,True or False: Every entire function $f(z)$ which goes to $0$ as $|z|\to \infty$ is bounded?,"I am almost positive I am incorrect, but I was hoping someone could explain why I am wrong because for the life of me I am at a loss. I am not asking for a counterexample or some contra-reasoning as to why my conclusion is incorrect, but rather I am hoping someone can point out the flaw in my actual argument. Suppose $f\in C^{\infty}(\mathbb{C})$ . Suppose $|f(z)|\to 0$ as $|z|\to \infty$ . My claim is that $f\equiv 0$ . Reasoning: If $f$ is smooth on $\mathbb{C}$ , then by definition $f$ is holomorphic, since $f$ is $\mathbb{C}$ -differentiable. So then $f$ is entire. But if $|f(z)|\to 0$ as $|z|\to \infty$ , then there exists some $N$ such that $|z|>N$ implies that $|f(z)|<1$ . So then consider the closed disk of radius $N$ . We know that $f$ is holomorphic on this disc. But such a disc is compact, so $f$ must achieve a maximum and minimum on this disc. So $f$ is bounded on this disc, and $f$ is also bounded outside of the disc by $1$ . So $f$ is bounded and entire, so then by Liouville it is constant. But we know that it goes to $0$ as $|z|\to \infty$ . So then $f\equiv 0$ . I am almost certain this is wrong somewhere, but to me my argument seems sounds. Any insight would be helpful.",['complex-analysis']
3586240,Denominators of Coordinates of Rational Points on the Unit Circle Are Odd,"Suppose you have a rational point $\Big( \frac{a}{b}, \frac{c}{d} \Big)$ on the unit circle $x^2 + y^2 = 1$ such that both coordinates are in lowest terms. What is the quickest way to show that $b$ and $d$ must both be odd? (if possible, without resorting to the Pythagorean triple standard form construction). I aim to assign a problem to my students which would require them to prove this fact, but we have not covered the proof for the standard form of Pythagorean triples.","['number-theory', 'pythagorean-triples']"
3586271,The parametric ratio $\frac{x}{y}$ with known $x+y$ and $x\cdot y$,"$x$ and $y$ are in fact $\lambda_1$ and $\lambda_2$ , the bigger and smaller eigenvalues of a parametric matrix $A'A$ , and $t$ is a very small constant. I have that $$
\begin{split}
x+y &= 1+ \frac{t^2}{2} \\
 xy &= \frac{t^2}{4}
\end{split}
$$ How would I prove that $\frac{x}{y}\ge \frac{1}{t}$ ? The solutions of the system are here , but it gets pretty messy. Is there an elegant way to go about this?","['algebra-precalculus', 'linear-algebra', 'inequality']"
3586278,"Let $g: \mathbb{R} \rightarrow \mathbb{R}$ be strictly increasing, continuous, and surjective","What we want to show is this: If $U$ is an open set in $\mathbb{R}$ , then $g(U)$ is open in $\mathbb{R}$ . Here is what I have:  For any $y \in g(U)$ , there is a $x \in U$ so that $g(x) = y$ . Since $U$ is open in $\mathbb{R}$ , $x$ is an interior point. There is an open interval $(x-\delta, x + \delta) \subset U$ . I am not sure what to do next. I want to say that $(g(x) - r, g(x) + r)\subset U$ and conclude that $g(x)$ is an interior point. Do I say this because that $g$ is onto. Am I on the right track? Thank you very much!!","['functions', 'functional-analysis', 'real-analysis']"
3586290,Quotient Scheme of a Proper Scheme,"Let $X$ be a scheme proper over $\mathbb{Z}$ , $G$ a finite group acting on $X$ . Suppose that the quotient scheme $Y := X/G$ is well-defined. Should $Y$ be then proper over $\mathbb{Z}$ as well?",['algebraic-geometry']
3586293,How to get the ordinary generating function for this series,"I came across the following sum: $$
\sum_{k \geq 0} \frac{2^k}{2^k+1}
$$ Is there a way to derive the ordinary generating function (OGF) for this sum?, i.e. given the series: $$
A(z) = a_0 + a_1z^1 + a_2z^2 + ... +a^kz^k + ...
$$ if we have for instance $a_k=1$ for all $k \geq 0$ , we have OGF $A(z)=1/(1-z)$ , or if the $a_k$ 's represent the harmonic numbers $H_k$ for $k \geq 0$ , we have the OGF $\frac{1}{1-z}\ln{(\frac{z}{1-z})}$ . So is there a way to get the OGF where $a_k=\frac{2^k}{2^k+1}$ ?","['generating-functions', 'summation', 'algorithms', 'sequences-and-series']"
3586298,Generalizing the Quadratic Formula to a Field with Characteristic $\neq 2$,"Here is a definition given by my book: Suppose $f(x)=ax^2+bx+c\in F[x]$ with $2a\in F^\times$ , and set $\Delta=b^2-4ac$ . 1) If there is a $\delta\in F$ such that $\delta^2=\Delta$ , then the roots of $f(x)$ are $\frac{-b\pm\delta}{2a}$ . 2) If there is no such $\delta\in F$ , then $f(x)$ has no roots in $F$ . Indeed, this definition seems familiar, and I know that, for polynomials in $\mathbb R[x]$ , this can be proven by completing the square. However, how can I generalize it from $\mathbb R[x]$ to $F[x]$ where $F$ can be any field with characteristic $\neq 2$ ? I'm unsure whether completing the square still works in this case, and the concepts of fields and polynomial arithmetic seem a bit abstract to the mathematically untalented me. Thanks in advance!","['abstract-algebra', 'quadratics', 'polynomials']"
3586309,Is OEIS A248049 an integer sequence?,"The OEIS sequence A248049 is defined by $$ a_n \!=\! \frac{(a_{n-1}\!+\!a_{n-2})(a_{n-2}\!+\!a_{n-3})}{a_{n-4}} \;\text{with }\; a_0\!=\!2, a_1\!=\!a_2\!=\!a_3\!=\!1.$$ is apparently an integer sequence but I have no proofs. I have numerical evidence using PARI/GP and Mathematica only. It is a real
problem because its companion OEIS sequence A248048 has the same
recursion with $\,a_0=-1, a_1=a_2=a_3=1\,$ but now $\,a_{144}\,$ has a denominator of $2$ . There is a
resemblance to the Somos-4 sequence but that probably won't help with an integrality proof. I have some interesting unproven observations about its
factorization algebraically and $p$ -adically for a few small values of $p$ , but nothing that would prove integrality. For example, if $\,x_0,x_1,x_2,x_3\,$ are indeterminates, and
we use initial values of $$ a_0=x_0,\; a_1=x_1,\; a_2=x_2,\; a_3=x_3 \;\text{ and }\;
x_4 := x_1+x_2,$$ with the same recursion, then $\,a_n\,$ has denominator a monomial in $\,x_0,x_1,x_2,x_3,x_4\,$ with
exponents from OEIS sequence A023434 .
Since $\,x_0=x_4=2\,$ with the original sequence I can't prove that the numerator
has enough powers of $2$ to compensate. Another
example is that $\,a_{12n+k}\,$ is odd for $\,k=1,2,3\,$ and
even for the other residue classes modulo $12$ . I also have
some further observations about its $2$ -adic valuation
behavior which I can't prove. By the way, the sequence grows very fast. My best
estimate is $\,\log(a_n) \approx 1.25255\, c^n\,$ where $\,c\,$ is the plastic constant OEIS sequence A060006 . Note
that $$x^4-x^3-x^2+1 = (x-1)(x^3-x-1) $$ and $\,c\,$ is the real root of the cubic factor. Can anyone give a proof of integrality of A248049?","['number-theory', 'oeis', 'recurrence-relations', 'sequences-and-series']"
3586317,Is this a contradicting definition for the symmetrical difference $\Delta$?,"The book I'm studying with has the following definition of the symmetrical difference: $$ M_1\Delta M_2 = \{ x | ( x\in M_1 \lor x\in M_2 ) \land \lnot(x\in M_1 \land x\in M_2)\} $$ However, when I try to expand the the negated conjunction in the latter half of this definition, I arrive at the following contradictory defintion: $$ M_1\Delta M_2 = \{ x | ( x\in M_1 \lor x\in M_2 ) \land (x\notin M_1 \lor x\notin M_2)\} $$ So, is that definition simply wrong or am I not even supposed to expand parts of definitions for some reason? Thanks!",['elementary-set-theory']
3586321,Lower bound for the square root sum of the roots of $x - \ln x - m$,"Let $f(x)=x-\ln x$ . Suppose $f(x_1)=f(x_2)=m$ ( $x_1<x_2$ ). How can I prove that $$\sqrt{x_1}+\sqrt{x_2}\ge\sqrt{m}+\frac{1}{\sqrt{m}}?$$ My Attempt I tried to rewrite the condition as \begin{align}
&x_1-\ln x_1=m,\\
&x_2-\ln x_2=m.
\end{align} By summing up the two equalities and by subtracting one equality from the other, we have \begin{align}
&x_1+x_2-\ln x_1x_2=2m,\\
&\sqrt{x_1}+\sqrt{x_2}=\frac{\ln x_2-\ln x_1}{\sqrt{x_2}-\sqrt{x_1}}.
\end{align} But I don't know how to continue then.","['calculus', 'inequality']"
3586348,"If $\frac{\sin^4x}{a}+\frac{\cos^4x}{b}=\frac{1}{a+b},$ then show that $\frac{\sin^6x}{a^2}+\frac{\cos^6x}{b^2}=\frac{1}{(a+b)^2}$","Question: If $\frac{\sin^4x}{a}+\frac{\cos^4x}{b}=\frac{1}{a+b},$ then show that $\frac{\sin^6x}{a^2}+\frac{\cos^6x}{b^2}=\frac{1}{(a+b)^2}$ . My approach: Since $$\frac{\sin^4x}{a}+\frac{\cos^4x}{b}=\frac{1}{a+b} \\ \implies \left(\frac{\sin^4x}{a}+\frac{\cos^4x}{b}\right)^2=\frac{1}{(a+b)^2} \\ \implies \frac{\sin^6x}{a^2}+\frac{\cos^6x}{b^2}-\sin^2x\cos^2x\left(\frac{\sin^2x}{a}-\frac{\cos^2x}{b}\right)^2=\frac{1}{(a+b)^2}.$$ Therefore, if we can prove that $$\frac{\sin^2x}{a}-\frac{\cos^2x}{b}=0,$$ then we are done. But, I am not able to prove the same.",['trigonometry']
3586472,Solve this equation : $\tan^{-1} \frac{x+1}{x-1} + \tan^{-1} \frac{x-1}{x} = \tan^{-1} (-7)$,"Solve this equation : $\tan^{-1} \frac{x+1}{x-1} + \tan^{-1} \frac{x-1}{x} = \tan^{-1} (-7)$ This was an exam question, my try was as follows: $$ \tan^{-1} \frac{x+1}{x-1} = \tan^{-1} (-7) - \tan^{-1} \frac{x-1}{x} $$ Now, assuming that $x = \tan x $ and substituting that in the above equation so that the equation changes and the $\tan^{-1} \frac{x-1}{x}$ vanishes, but, there is also one tan inverse function, so how to remove it? Thanks :)",['trigonometry']
3586480,Need Help Simplifying Set Expression Using Set Identities,"one of the questions in our textbook requires us to simplify a set expression using set laws such as distributive laws, associative laws and so on. $$
((A\cap (B\cup C))\cap (A-B))\cap (B\cup C')
$$ Here's what I have so far. $$
((A\cap (B\cup C))\cap (A\cap B'))\cap (B\cup C')
$$ $$
(((A\cap B)\cup (A\cap C))\cap (A\cap B'))\cap (B\cup C')
$$ $$
(((B\cap C)\cup A)\cap (A\cap B'))\cap (B\cup C')
$$ $$
((B\cap C)\cup A)\cap ((A\cap B')\cap (B\cup C')
$$",['discrete-mathematics']
3586599,"What is $\frac{\partial\det(L)}{\partial x_i}$, where $L_{i,j} = \exp\left(-\frac{(x_i-x_j)^2} {2\sigma ^2} \right)$ using Jacobi's formula?","We have $n \times n$ matrix $L$ , given by the following Gaussian kernel $$L_{i,j} = \exp\left(-\frac{(x_i-x_j)^2} {2\sigma ^2} \right)$$ where the points $x_i$ and $x_j$ are real numbers that can be thought as positions of points $i$ and $j$ . ( $L$ can be seen as a covariance matrix, describing covariance depending on distance between points. The higher distance between points $i$ and $j$ the less the covariance.) I am interested in finding $$ \frac{\partial\det(L)}{\partial x_i}$$ From Matrix Book , can I use Jacobi's formula? $$\frac{\partial\det(L)}{\partial x}= \det (L) \operatorname{Tr}\left( L^{-1} \frac{\partial L}{\partial x}\right).$$ Is it correct that $\frac{\partial\det(L)}{\partial x_i} = \det (L) \operatorname{Tr}\left( L^{-1} \frac{\partial L}{\partial x_i}\right)$ where $\frac{\partial L}{\partial x_i}$ is the matrix given by the terms $\frac{\partial L_{k,l}}{\partial x_i}=0$ for $k,l \neq i$ and $\frac{\partial L_{i,j}}{\partial x_i}=\frac{\partial L_{j,i}}{\partial x_i}=-\frac{(x_i-x_j)}{ \sigma ^2} L_{i,j}$ ?","['matrices', 'derivatives', 'partial-derivative']"
3586700,Show $\int_{\mathbb{R}^3} \frac{1}{\vert{\eta -v\vert}^2} \frac{1}{(1+\vert \eta \vert)^4} d\eta \leq \frac{C}{(1+\vert v \vert)^2}$,"$\textbf{Problem}$ \begin{equation*}
\int_{\mathbb{R}^3} \frac{1}{\vert{\eta -v\vert}^2} \frac{1}{(1+\vert \eta \vert)^4} d\eta 
\leq \frac{C}{(1+\vert v \vert)^2}
\end{equation*} For obtaining the above upper bound, I tried to change the variable $\eta \rightarrow v+ \sigma \rho $ for $\sigma \in \mathbb{S}^2, \rho \in \mathbb{R}^{+}$ . However, I stuck to handle the part $\displaystyle{\frac{1}{(1+\vert{\eta\vert})^4}}$ . $\textbf{Attempt}$ \begin{align*}
      \frac{1}{(1+\vert \eta \vert)^4} &= \frac{1}{(1+\vert v+\sigma \rho\vert)^4}\\
      \int_{\mathbb{R}^3} \frac{1}{\vert \eta - v \vert^2} \frac{1}{(1+\vert \eta \vert)^4} d\eta &= \int_0^{\infty} \int_{\mathbb{S}^2} \frac{1}{\rho^2} \frac{1}{(1+\vert v + \sigma \rho\vert)^4} \rho^2 d\sigma d\rho  
\end{align*} I don't know how to derive $(1+\vert v \vert)^2$ from the last integral term in my attempt. Any help is appreciated. Thank you!","['integration', 'calculus', 'analysis', 'real-analysis']"
3586721,Why does the inner product of two vectors have to be positive definite?,"I'm studying an undergraduate level geometry book and was studying about inner products when I got a bit confused. I've tried to find other answers here and elsewhere, but none of the answers were exactly intuitive and so it was hard for me to understand, and so decided to ask my own question. According to the book, one of the properties of the inner product between two vectors is that it must be positive definite. To borrow the exact words: An inner product on $\Bbb{R}^n$ is a function $\langle\ \cdot\ ,\ \cdot\ \rangle: \Bbb{R}^n \times \Bbb{R}^n \rightarrow \Bbb{R}$ on two vector variables that satisfies the following properties: Positive definiteness: The necessary and sufficient condition for $\langle\mathbf{a}, \mathbf{a} \rangle \ge 0$ and $\langle\mathbf{a}, \mathbf{a}\rangle = 0$ is $\mathbf{a} = \mathbf{0}$ . Commutativity: $\langle \mathbf{a}, \mathbf{b} \rangle = \langle \mathbf{b}, \mathbf{a} \rangle$ Linear on the first argument: $\langle \mathbf{a}_1 + \mathbf{a}_2, \mathbf{b} \rangle = \langle \mathbf{a}_1, \mathbf{b} \rangle + \langle \mathbf{a}_2, \mathbf{b} \rangle$ and $\langle \alpha \mathbf{a}, \mathbf{b} \rangle = \alpha \langle \mathbf{a}, \mathbf{b} \rangle = \langle \mathbf{a}, \alpha \mathbf{b} \rangle$ I'm having trouble understanding the positive definiteness. Why is that so? What is the geometric meaning of an inner product having to be positive definite? In fact, I've never even heard of this before when I was studying linear algebra. I merely learned that the inner product of two vectors $\mathbf{a}$ and $\mathbf{b}$ is: $$\mathbf{a} \cdot \mathbf{b} = \sum_{i = 1}^n a_ib_i$$ One Reddit answer brought up the concept of ""distance"" and that if an inner product is not positive definite then we cannot define distance between two vectors, but I'm having trouble understanding that as well. Also, I thought that positive definiteness did not include equality (i.e. $\ge$ ) and rather positive semi-definiteness is the one that included equality. Would anyone be able to shed some light on this concept? Thanks in advance.","['inner-products', 'geometry', 'positive-definite']"
3586744,Quotient of closed $G$-invariant subset of $G$-variety,"Let $X$ be an affine $G$ -variety where $G$ is a reductive group. All the varieties are over $k$ , where $k$ is a field (if it necessary we can assume it is algebraically closed). It is a known theorem that there exists an affine good quotient $p:X \to X//G$ . Let us call $X//G=Y$ . I'm interested in the following situation: $Z \subseteq Y$ is a closed subset (considered as a subvariety with the standard reduced structure). We consider the closed $G$ invariant subset $p^{-1}(Z)=W$ of $X$ : I'd like to prove that the map $p:W \to Z$ is actually a (categorical) quotient. This accounts to prove the following:we call $B$ the $k$ algebra $\mathcal{O}_X(X)$ . We then have $\mathcal{O}_Y(Y)=B^G$ . With this identification, the subscheme $Z$ corresponds to an ideal $I \subseteq B^G$ while $W$ corresponds to $\sqrt{IB}$ . We then want to prove that $$\dfrac{B^G}{I}=\left(\dfrac{B}{\sqrt{IB}}\right)^G .$$ We can think of $\sqrt{IB}$ as the function $f:X \to \mathbb{A}^1_k$ such that $f(p^{-1}(Z))=0$ . It should then be true  that $\sqrt{IB} \cap B^{G}=I$ :on the left hand side we have the $G$ invariant functions $f:X \to \mathbb{A}^1_k$ such that $f(W)=0$ ; these functions factorize through $Y$ to a function $f \in B^G$ such that $f(Z)=0$ so that $f \in I$ . Now, I would like to follow the approach used by Dolgachev in its Introduction to geometric invariant theory on page $44$ : he uses that reductive groups are actually geometrically reductive i.e given a representation $V$ and a fixed non zero vector $v \in V$ , there exists a homogenous $G$ invariant  polynomial $F$ on $V$ sucht hat $F(v) \neq 0$ . More precisely, if char $k=0$ we can assume $F$ to be linear and Dolgachev also proves the equality of invariant rings wanted. If char $k=p$ , it is actually true that we can assume $F$ to be homogenous of degree $p^r$ and that for every $a \in \left(\dfrac{B}{\sqrt{IB}}\right)^G$ there exists an $h_a \in A^G$ such that $h_a-a^{p^r} \in I$ . This does not really imply the claim, however it seems very close to me. I do not know how to conclude however.","['geometric-invariant-theory', 'algebraic-geometry', 'invariant-theory']"
3586751,Foliations and Geodesic Congruences,"I have a very basic question on the definition of foliations and geodesic congruences. My understanding is that: Geodesic congruences are families of geodesics such that locally, every point belongs to exactly one geodesic. Foliations an equivalence relation on an n-manifold, the equivalence classes being connected, injectively immersed submanifolds, all of the same dimension $p$ . One important distinction seems to be that foliations are defined on the entire manifold whereas geodesic congruences can be on any open subregion. For instance, a trivial example when the two coincide is when we have a family of parellel lines in $\mathbb{R}^2$ . We can also have the collection of axial circles on the torus. Unless I am mistaken, the collection of curves in both of these examples satisfy the definitions of geodesic congruences and foliations. My question: if given a foliation of a manifold by geodesics, do we have a geodesic congruence? The answer seems to be in the affirmative, and (at least in terms of the picture I have in my head) the two notions seem very closely related, however I have not found any resources that talk about both of them.","['general-relativity', 'differential-geometry']"
