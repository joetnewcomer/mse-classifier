question_id,title,body,tags
2210839,Zariski's Main Theorem in T.A Springer Linear Algebraic Groups,"I am not sure to understand the proof of the theorem 5.2.8 of Springer's LAG. More precisely I am wondering why he can replace $X$ and $Y$ by open affine neighborhoods. I have tried the following but I can't say whether this is correct: We have to prove that  $\phi$ is an isomorphism of ringed spaces. So we take $V\subset Y$ and we want to show that $\phi ^*: O_Y(V)\to O_X(\phi^{-1}(V))$ is a ring isomorphism. To do that we cover $V$ with affine opens $V = \cup _i V_i$. 
Now let $x\in U_i=\phi^{-1}(V_i)$. As $\phi$ is locally finite in $x$ by 5.2.6 there exists an affine open $U_{x_i}\subset U_i$ isomorphic (let $\nu$ this isomorphism) to an affine open subset $V_{x_i}^{'}$ of an affine variety $V_i^{'}$ which is finite over $V_i$ via a morphism $\mu$ such that we have $\phi|_{U_{i,x}}=\mu\circ\nu$. Then by normality and birationality, $\mu$ is an isomorphism. As we have a sheaf, it follows that $\phi ^*: O_Y(V)\to O_X(\phi^{-1}(V))$ is an isomorphism and we are done. Is this correct? Thanks for yout help.","['algebraic-groups', 'algebraic-geometry']"
2210876,$n^2+np$ is a perfect square,"Let $p > 2$ be a prime. Prove that there exists exactly one positive integer $n$ such that $n^2+np$ is a perfect square. I tried bounding the expression $n^2+np$ between two perfect squares, but I wasn't able to because there was no constant term. We know that $n^2+np < \left(n+\frac{p}{2}\right)^2$, but I couldn't get a lower bound. How can we solve the question?",['number-theory']
2210913,The product of the derivative and anti derivative is the function?,When is $$f(x) = f'(x)\int{f(x)}dx$$? I just though of the problem but couldn't solve it myself.,"['derivatives', 'integration', 'ordinary-differential-equations']"
2210914,A function linear in a matrix,"When we say a function $f:\mathbf{R}^{m\times n}\rightarrow \mathbf{R}$ is linear in a matrix $X\in \mathbf{R}^{n \times m}$, does that mean the function is linear in the elements of $X$, i.e., linear in $x_{11},...x_{nm}$?","['matrices', 'functions']"
2210945,What is wrong with this way of solving trig equations?,"Let's suppose I have to find the values of $\theta$ and $\alpha$ that satisfy these equations: $\cos^3 \theta$ = $\cos \theta $ $3\tan^3 \alpha = \tan \alpha$ on the interval $[0; 2 \pi]$. If I try to solve, for instance, the first equation like this: $$\cos^3 \theta = \cos \theta $$ $$\cos^2 \theta * \cos \theta = \cos \theta$$ $$\cos^2 \theta  = \cos \theta  \div \cos \theta $$ $$\cos^2 = 1$$ $$\cos \theta = \pm \sqrt {1}$$ $$\cos \theta = \pm 1$$ I end up getting only: $\theta = 0 ; \pi ; 2 \pi$ But I know that $\pi /2$ and $3\pi /2$ would also make the equation true since $\cos^3 (\pi /2) = cos (\pi /2) = 0$ and $\cos^3 ( 3 \pi /2) = cos (3 \pi /2) = 0$. The same problem arises when I try to solve the second equation: $$3\tan^3 \alpha = \tan \alpha$$
$$3\tan^2 \alpha * \tan \alpha = \tan \alpha$$
$$3\tan^2 \alpha = \tan \alpha \div \tan \alpha$$
$$3\tan^2 \alpha =1$$
$$\tan^2 \alpha =1/3$$
$$\tan \alpha =\pm \sqrt{1/3}$$
$$\tan \alpha =\pm 1/\sqrt{3}$$ The values of $\alpha$ that make the tangent equal to $\pm 1/\sqrt{3}$ between 0 and $2 \pi$ are only these: $ \alpha = \pi / 6 ; 5 \pi /6 ; 7 \pi / 6 ; 11 \pi /6$ However,  I should also find $0$ and $\pi$ because $3\tan^3 (0) = \tan (0) = 3 tan^3 (\pi) = tan ( \pi ) = 0 $. Something similar happens when I'm looking for the local minima and maxima of this function: 
$$ f(x) = \sin^2(x) + \cos(x)$$ on the interval $[0; 2 \pi]$ $f'(x) = 2 \sin(x) \cos(x) - \sin(x)$ $ 0 = 2 \sin(x) \cos(x) - \sin(x)$ $ \sin(x) = 2 \sin(x) \cos(x)$ $ \sin(x) / \sin(x) = 2 \cos(x)$ $1 = 2 \cos(x)$ $1/2 =  \cos(x)$ $x = \pi / 3 ; 5 \pi /3$ And again, plugging $x = 0$ or $x= \pi$ or $x = 2 \pi$ also make the derivative 0. I've noticed that in all of these 3 cases I have the same trigonometric function on both sides of the equation and I'm dividing both sides by that function. This is making one side of the equation equal to 1 at some point. What is wrong or incomplete with this method? Why am I missing some results when I do this?","['trigonometry', 'arithmetic']"
2210975,Determinants of square matrices filled with consecutive squares,"This is my first question, please forgive me if I mistake something, since I don't think I will be allowed to edit the question later. So, let me explain the kind of matrices I'm talking about. Think of a $n\times n$ square matrix, and think of a sequence of $n^2$ consecutive squares starting at $k^2$ (the most natural choice being $k=1$). Now place those squares in the matrix as if you were writing, row by row. I'll dare to invent a notation for these ""Square Matrice filled with Consecutive Squares"": $SMCS(n,k)$. So we have, for example:
$$ SMCS(3,4)=
        \begin{bmatrix}
        4^2 & 5^2 & 6^2 \\
        7^2 & 8^2 & 9^2 \\
        10^2 & 11^2 & 12^2 \\
        \end{bmatrix}=
\begin{bmatrix}
        16 & 25 & 36 \\
        49 & 64 & 81 \\
        100 & 121 & 144 \\
        \end{bmatrix}
$$
I wasn't able to find anything about matrices like these neither here nor elsewhere. Probably there are of no mathematical interest. My interest starts from a lecture, years ago, when the professor made us notice that the ""Square Matrice filled with Consecutive Integers"" $1$ to $9$ —it is the cell phone keypad! I'll call it $SMCI(3,1)$— is singular. That is:
$$
\det
\begin{bmatrix}
        1 & 2 & 3 \\
        4 & 5 & 6 \\
        7 & 8 & 9 \\
        \end{bmatrix}=0
$$
I find very intuitive that this elegant property holds for matrices of higher order and even if starting from a different integer, that is 
$$
\det \left[SMCI(n,k)\right]=0 \qquad n\geqslant 3, \;\forall k
$$
I can recognize a clear pattern (where the middle culumns are an ""average"" of the ones at their sides) so that I feel relieved from the need to provide an explicit proof for this result, that shouldn't be too hard anyway. Now I'm looking at the determinants of the matrices filled with squares. With no surprise I find nonsingular matrices of order $2$. Then, with some hope, I look at $SMCS(3,1)$ (the cell phone keypad with each number squared) but I find that the determinant is $-216$. So I find myself admitting that, understandably, the property doesn't hold for matrices filled with powers. Yet something curious happens: the result is the same even if I take a different starting point, that is
$$
\det\left[SMCS(3,k)\right]=-216\qquad \forall k
$$
This was a surprise, but it was pretty straightforward proving it with some direct algebra calculations. Here comes the big deal. I went on looking at higher orders, wondering if there were a characteristic constant for each $n$. Instead... $0$'s began to appear again! Me unbeliever! I've grown convinced that
$$
\det \left[SMCS(n,k)\right]=0 \qquad n\geqslant 4, \;\forall k
$$
but attempting a direct proof, if only for $n=4$, was out of the question. Let alone a general proof for any $n$, which is what I would really be interested in, but I wouldn't know even where to start from. I don't really need the rigorous proof, what I'd love is to be sure of the validity of the property, and possibly a way to ""understand"" it in a manner similar to what I could do with the $SMCI$ matrices, to be ""convinced"" of the result. Can anyone help my with this? Thank you! Wow, great, I got it! It took me some effort, but I got it all, thank you JeanMarie! Forgive me for coming back with some delay, but I saw you constantly improving your answer, and considering my time zone disadvantage I had to give up for the day. Understanding your ""trick"" allows to easily extend the property to even higher orders; for example rows (or columns) of consecutive cubes give singular matrices from $5 \times 5$ on. If I extend the notation to ""Square Matrix filled with Consecutive Powers"", I shall write $$
\det \left[SMCP(p,n,k)\right]=0 \qquad n\geqslant p+2, \;\forall k
$$ I couldn't resist exploring the case just before the first singularity occurence, when the matrix order is greater than the power only by $1$. I mean, in the general case, because it is easy to algebraically verify that $$
\det \left[SMCP(1,2,k)\right]=-2 \qquad \forall k
$$ $$
\det \left[SMCP(2,3,k)\right]=-216 \qquad \forall k
$$ I made a few direct attempts to find that (probably $\forall k$, but I don't dare writing it) $$
\det \left[SMCP(3,4,k)\right]=5308416
$$ $$
\det \left[SMCP(4,5,k)\right]=7776 \cdot 10^{10}
$$ I hoped to infer a rule from this sequence start, and try a proof at a later stage, but I cannot see anything. Nor I think that the kernel trick can be helpful at this. So the question now would be $$
\det \left[SMCP(p,n,k)\right]=\;? \qquad \forall k \;\textrm{  when  }\; n=p+1
$$ but I don't know how hard it can be to annswer it, and I won't ask anyone an eccessive effort about something that now has gone well beyond what I was looking for in the first place. I leave it here just in case someone is able to easily see something that doesn't occur to me. Again thank you!","['matrices', 'recreational-mathematics', 'linear-algebra', 'determinant']"
2210979,Derivative of Newton iteration in Banach spaces,"I'm studying the Newton's method on Banach spaces and having some trouble to understand its derivative. Given two Banach spaces $\mathbb{E}, \mathbb{F}$ and a smooth map $f:\mathbb{E} \to \mathbb{F}$, a Newton's iteration of $f$ is the map $N_f:\mathbb{E}\backslash\mathcal{S} \to \mathbb{E}$ such that $$N_f(x) = x - (Df(x))^{-1}f(x),$$ where $\mathcal{S}$ is the set of points $x \in \mathbb{E}$ such that $Df(x)$ is not invertible. After that, I know that if $x \in \mathbb{E}\backslash\mathcal{S}$ is a zero of $f$, then $DN_f(x) = 0$. I don't have a proof of this fact, they (the people of my book) just show this for complex functions and say it is the same thing for Banach spaces. I tried to prove and doesn't looks the same thing. Here are my thoughts: I can define the map $D_f^{-1}:\mathbb{E}\backslash\mathcal{S} \to \mathcal{L}(\mathbb{F},\mathbb{E})$ such that $D_f^{-1}(x) = (Df(x))^{-1}$. Doing this I can informally write $$N_f = I - D_f^{-1}\cdot f,$$
where $I$ stands for the identity map. If I just follow what they say and treat $N_f$ as an ordinary complex function, then $$DN_f = I - (-1)D_f^{-2}\cdot D(D_f^{-1})\cdot f - D_f^{-1}\cdot D_f = $$
$$ = I + D_f^{-2}\cdot D(D_f^{-1})\cdot f - I = D_f^{-2}\cdot D(D_f^{-1})\cdot f.$$
Note that I used the chain rule and the product rule in the usual way, which supposedly I'm allowed to do. Now we substitute to get $DN_f(x) = D_f^{-2}(x)\cdot D(D_f^{-1})(x)f(x) = D_f^{-2}(x)\cdot D(D_f^{-1})(x)\cdot 0 = 0$, as claimed. I have two questions: 1) Are my calculations correct (do they make sense)? 2) What is $D_f^{-2}$ and $D(D_f^{-1})$ ? Even if my calculations are ok, I just don't know what are these maps. I don't know how to interpret it. Thanks.","['derivatives', 'banach-spaces', 'newton-raphson']"
2211008,"Irrationality measure of $\alpha+\beta$, $\alpha\beta$","Let $\alpha$ and $\beta$ be real numbers with finite irrationality measures . My question is: Are the irrationality measures of $\alpha+\beta$ and $\alpha\beta$ also finite? I tried using triangle inequality 
$$
\left| \alpha - \frac {p_1}{q_1} + \beta - \frac{p_2}{q_2}\right| \geq \left| \left| \alpha - \frac{p_1}{q_1}\right|-\left|\beta-\frac{p_2}{q_2}\right|\right|$$for the sum, but this doesn't lead me anywhere. For the product, I am not even sure where to start. I wonder if this is well-known. If so, I am looking for a reference. If this is true, we would have results as $e+\pi$ has a finite irrationality measure. But, I could not find any reference for such results. My progress so far is: If one of $\alpha$, $\beta$ is  a rational number, then the result is true. From Hata's result , we have 
$\pi/\sqrt{k}$ has finite irrationality measure for any integer $k\geq 1$. So, $\pi/\sqrt{k} +1$ has a finite irrationality measure. But, that would not necessarily imply that $\pi+\sqrt{k}$ has finite irrationality measure. Added on 2017 May 22 In fact $\pi + \sqrt{k}$ has a finite irrationality measure. This can be done by Baker's theorem. [Baker's Theorem] If $\alpha_1, \ldots, \alpha_n$ are algebraic numbers, not $0$ or $1$. If $\log\alpha_1, \ldots, \log\alpha_n$ are linearly independent over $\mathbb{Q}$, then $1, \log\alpha_1, \ldots, \log\alpha_n$ are linearly independent over $\overline{\mathbb{Q}}$. 
  Moreover, there is an effectively computable constant $C>0$ such that for any algebraic $\beta_0, \ldots, \beta_n$ not all zero, 
  $$
|\beta_0+\beta_1\log \alpha_1 + \cdots + \beta_n \log \alpha_n |\geq H^{-C}
$$
  where $H=\max(h(\beta_i))$. For positive integers $p, q$, we have
$$
|q(\pi+\sqrt k)-p|\geq H^{-C}
$$
where $H=\max(h(q\sqrt k-p) , q^2)\ll q^{A}$ for some effectively computable 
constant $A>0$. This shows that $\pi+\sqrt k$ has a finite irrationality measure. This can be generalized that $\pi+\alpha$, $\pi/\alpha$ has a  finite irrationality measure for any nonzero algebraic $\alpha$.","['real-analysis', 'real-numbers', 'diophantine-approximation', 'irrational-numbers']"
2211031,Metric on $V \otimes V$,"Given an hermitian metric on a finite dimensional vector space $V$ over $\mathbb C $, is there a ""standard"" way to put a metric on $V \otimes V$ ? Thanks!","['metric-spaces', 'linear-algebra', 'algebraic-geometry']"
2211054,Condition number for polynomial interpolation matrix,"We want to interpolate a function $\,f:\mathbb{R}\to\mathbb{R}$ on the interval $[0,1]$ with, say, monomials. Assume we have set $\left\{x_i\right\}_{i=0}^{n}$ of $n+1$ points $x_i\in\left[0,1\right],\; i = 0,\dots, n,$ which are not uniformly distributed and for which we know values $\,f_i = f\left(x_i\right)$ of function $\,f$. Following standard interpolation techniques, we write approximating polynomial $P_n(x)$ as linear combination of monomials: $$
P_n\left(x\right) = a_0 + a_1 x + a_2 x^2 + \dots + a_nx^n 
= \sum_{i=0}^{n} a_ix^i
$$ where $a_i\in \mathbb R,\; i=0,\dots,n$ are unknown coefficients we need to determine.
Estimating monomials at points $\left\{x_i\right\}_{i=0}^{n}$ yields system of linear equations $$
\underbrace{
\begin{bmatrix}
1 & x_1 & x_1^2 & \cdots & x_1^n \\
1 & x_2 & x_2^2 & \cdots & x_2^n \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
1 & x_n & x_n^2 & \cdots & x_n^n \\
\end{bmatrix}}_{\quad\;\style{display: inline-block; transform-origin: 50% 50% 0px; transform: rotate(30deg); }{:= \boldsymbol{M}} }
\cdot
\underbrace{ \begin{bmatrix}a_0 \\ a_1 \\ \vdots \\ a_n\end{bmatrix} }_ {\quad\style{display: inline-block; transform-origin: 50% 50% 0px; transform: rotate(30deg); }{:= \overline{\boldsymbol{a}}} }
=
\underbrace{\begin{bmatrix}f_0 \\ f_1 \\ \vdots \\ f_n\end{bmatrix} }_ {\quad\style{display: inline-block; transform-origin: 50% 50% 0px; transform: rotate(30deg); }{:= \overline{\boldsymbol{f}}}  }
%\qquad \iff \qquad
%\boldsymbol{M} \cdot\overline{\boldsymbol{a}} = \overline{\boldsymbol{f}}
$$ which we can rewrite as $\;\boldsymbol{M} \cdot\overline{\boldsymbol{a}} = \overline{\boldsymbol{f}}$. I am trying to figure out how does condition number $\,\kappa\left(\boldsymbol{M}\right)$ of the matrix depends on the minimal distance $h$ between points $\left\{ x_i \right\}_{i=0}^{n}$: $$h=\min_{i,j=0\ldots n} \left\lVert x_i - x_j\right\rVert.$$ Intuitively $\kappa\left(\boldsymbol{M}\right)$ should grow as $h\to0$, which matches results of numerical experiments.
However, I am clueless about the exact type of relation between $\kappa$ and $h$.
Any help is appreciated.","['condition-number', 'linear-algebra', 'interpolation']"
2211094,"Application of Rolle's theorem? Establish existence of $c\in(a,b)$ such that $f(c)+f'(c)=f(c)f'(c)$","Following my question on Meta , I post this as a new question; it was originally asked by Gmgfg , and closed due to the lack of context, background, and shown  effort. Let $f\colon[a,b]\to\mathbb{R}$ be a function continuous on $[a,b]$ and differentiable on $(a,b)$ with $f(a)=f(b)=0$. Show that there exists $c\in(a,b)$ such that $f'(c)+f(c)=f(c)f'(c)$. Now, given the assumptions this looks like it should be a straightforward application of Rolle's theorem. However: as far as I can tell there is no simple auxiliary function $\Phi$ such that $\Phi'= f+f'-f\cdot f'$ to which one could apply Rolle's theorem. (If there is one, I failed to find it.) indeed, while the RHS could come from $\left(\frac{f^2}{2}\right)'$; it's mostly the LHS which looks difficult to handle (and there is no clear advantage I can see in introducing an antiderivative $F$ of $f$ to have it be $(F+f)'$). I verified the statement for some functions I could think of, such as $x\mapsto x(1-x)$ and $x\mapsto \sin \pi x$ on $[a,b]=[0,1]$. So, in that regard, it seems to hold at least against basic sanity checks. However , what bothers me is the lack of ""homogeneity."" Usually, in things like that I'm used to saying that ""without loss of generality, one can assume $[a,b]=[0,1]$."" It does not appear to be the case here: if, given $f$, one defines $g\colon[0,1]\to\mathbb{R}$ by $g(x) = f((b-a)x+a)$, finding $c\in(0,1)$ such that $g'(c)+g(c)=g(c)g'(c)$ does not directly yield $c'$ such that $f'(c')+f(c')=f(c')f'(c')$ (but rather would give $c'$ such that $f'(c')+(b-a)f(c')=f(c')f'(c')$, if I'm not mistaken). So, in short: is it true? And how to prove or disprove it — I'm at a loss, and embarrassed about it.","['real-analysis', 'rolles-theorem']"
2211110,Minimum Size of Word Search Containing All Strings of Length $l$,"The following is a problem I came up with and have been thinking through for the last several days, making little progress. The problem statement is deceptively simple, and (unless I'm missing something), the problem itself proves to be fairly difficult. Consider a $m * n$ grid, with $m$ rows and $n$ columns. Each element in this grid can contain one of $k$ letters. We will denote such a construction a word search. What is the minimum size of a word search that contains all strings of length $l$? Size here is defined as area, or $m*n$. Furthermore, you can find a string looking left, right, up, down, or diagonally, and strings can overlap. My progress: We first note that there are $k^l$ possible strings of length $l$. Therefore, we could take the trivial construction of a $k^l * l$ grid, each row containing one unique string of length $l$. However, this is inefficient in several ways. First, noting that we can read strings backwards as well as forwards, we can immediately cut the number of rows by almost a half (strings which are palindromes can't be cut). Also, this doesn't even begin to account for the number of ways we can look at strings vertically (both upwards and downwards), and diagonally. I also noted that the optimal construction will probably be a square, or close to it. My reasoning for this is because if we have a $m * n$ grid, assuming WLOG that $m < n$, note that adding one row will increase the net number of strings present by more than adding another column. One possible idea is to use a greedy algorithm that operates as follows: 1) Construct a set of all $k^l$ strings. We will use this to track progress - every time we add a new string to our search, we will remove it from the set, and our goal is to empty the set. 2) Create an empty $l * l$ grid. 3) Consider all possible ways to populate that grid with each of the $k$ letters in each element, and choose the population that minimizes the size of the set (ie removes the most number of strings from the set). 4) Recursive step: let the size of the grid be $n * n$ currently. Consider all possible additions of $2n+1$ letters, adding $n$ letters below the last row, $n$ the the right of the last column, and the remaining $1$ to fill in the square. Whichever one decreases the set size the most is chosen. Repeat this until we're done. This algorithm is clearly not perfect, as it requires the right choice of a kernel, and also could be very inefficient towards the end. We can also use this same algorithm, but instead of adding the L shape at the bottom right, we can surround the entire thing with a square. This may yield more accurate results. I'd appreciate any ideas, from establishing an upper/lower bound on the size combinatorically, to finding an algorithm, or any sort of geometric/algebraic approach. I'm not sure if probabilistic method would be helpful here, but after reading into it I think it may be. All progress will be really helpful! The following are a few similar, slightly easier, problems to get some ideas from: What is the shortest string that contains all permutations of an alphabet? Expected length of a sequence that contains all words of a given length.","['graph-theory', 'algorithms', 'geometry', 'combinatorics', 'probabilistic-method']"
2211124,Solve for $x$ in $\frac{x^2+12x+36}{x^2+4x-12}=2$,"$\frac{x^2+12x+36}{x^2+4x-12}=2$ I factored top and bottom to $\frac{(x+6)(x+6)}{(x+6)(x-2)}=2$
and eliminated the common factor (x+6) for $\frac{x+6}{x-2}=2$
then $x+6=2(x-2)$  and  $x+6=2x-4$  and  $6+4=2x-x$ and finally $x = 10$
Plugging this back into the original fraction proves true My instructor however in her exam prep test says
$\frac{x^2+12x+36}{x^2+4x-12}=2$ $$x^2+12x+36 = 2(x^2+4x-12)$$
$$x^2+12x+36 = 2x^2+8x-24$$
$$0 =2x^2-x^2 +8x -12x -24 -36$$
$$0 =x^2-4x -60$$ 
which she then factors to $(x-10)(x+6)$ saying the answer to the problem is $x=10$ or $x=-6$
But if you plug -6 back into the original fraction you get $0=2$. Where is the problem here? Thanks",['algebra-precalculus']
2211134,"In an infinite dimensional Hilbert space, when can we express any element in H as linear combination of the basis vectors?","Let H be a hilbert space, infinite dimensional. Let $(e_n)$ be an orthonormal basis for H. Can we express any x in H as $x=\sum_{i=1}^{\infty} c_i e_i$ where the constants are (maybe) $<e_i,x>$? Also when is an infinite linear combination of basis vectors like the one above an element in H? I ask because I know on one hand that by definition of Hilbert basis, any element in H can be approximated in the norm by a sequence of finite linear combinations of $e_k$ but have doubts as to whether we can write any element as an infinite linear combination of the one above.. What conditions garantee that such an infinite sum would even be in H? Thanks for any information.","['hilbert-spaces', 'operator-theory', 'analysis', 'linear-transformations']"
2211140,expand the product $\prod_{i=1}^n(a_i+b_i)$,"Is there a formula to expand the product $\prod_{i=1}^n(a_i+b_i)$, where $a_i,b_i$ are elements of a commutative domain?",['algebra-precalculus']
2211166,Qualitatively analyzing the local behavior of equilibria,"I have the system $$r' = r-r^3$$ $$\theta' = \sin(\theta)^2-\frac{1}{4}$$ I know the equilibria are $$(0,0) \space (1,\frac{\pi}{6}) \space (1,-\frac{\pi}{6}) \space (1, \frac{5\pi}{6}) \space (1, -\frac{5\pi}{6})$$ but I do not know how to analyze the local behavior of each one without using the hartman-grobman theorem. I want to be able to figure out if each one is a source or a sink, straight line solutions, spirals, centers, etc. All with minimal computation. Also try to try to draw the whole phase portrait using qualitative methods (I know this is possible because I saw a professor do it in thirty seconds in his head, writing on a blackboard. He did not, however, explain his thinking).  Any help is appreciated. If you give me hints that lead me to the answer , I will accept and post my solution in the question.",['ordinary-differential-equations']
2211193,Solving $\sqrt[3]{{x\sqrt {x\sqrt[3]{{x \ldots \sqrt x }}} }} = 2$ with 100 nested radicals,"I have seen a book that offers to solve the following equation: $$\underbrace {\sqrt[3]{{x\sqrt {x\sqrt[3]{{x \ldots \sqrt x }}} }}}_{{\text{100 radicals}}} = 2$$ The book also contains the answer: $$x = {2^{\left( {\frac{{5 \times {6^{50}}}}{{3 \times ({6^{50}} - 1)}}} \right)}}$$ How did they get the answer for such equation? I tried to obtain the recurrence relation , but could not find the way to get the above answer. EDIT $${u_{100}} = 2,$$ $$\sqrt[3]{{x{u_{99}}}} = 2,$$ $$x{u_{99}} = {2^3},$$ $${u_{99}} = \sqrt {x{u_{98}}} ,$$ $$x\sqrt {x{u_{98}}}  = {2^3},$$ $${x^2}x{u_{98}} = {({2^3})^2},$$ $${x^3}{u_{98}} = {2^6},$$ $${u_{98}} = \sqrt[3]{{x{u_{97}}}},$$ $${x^3} \times \sqrt[3]{{x{u_{97}}}} = {2^6},$$ $${x^9}x{u_{97}} = {({2^6})^3},$$ $${x^{10}}{u_{97}} = {2^{18}},$$ $${u_{97}} = \sqrt {x{u_{96}}} ,$$ $${x^{10}}\sqrt {x{u_{96}}}  = {2^{18}},$$ $${x^{20}}x{u_{96}} = {({2^{18}})^2},$$ $${x^{21}}{u_{96}} = {2^{36}},$$ $${u_{96}} = \sqrt[3]{{x{u_{95}}}},$$ $${x^{21}} \times \sqrt[3]{{x{u_{95}}}} = {2^{36}},$$ $${x^{63}}x{u_{95}} = {2^{108}}$$ $${x^{64}}{u_{95}} = {2^{108}},$$ $${u_{95}} = \sqrt {x{u_{94}}} ,$$ $${x^{64}}\sqrt {x{u_{94}}}  = {2^{108}},$$ $${x^{128}}x{u_{94}} = {2^{216}},$$ $${x^{129}}{u_{94}} = {2^{216}},$$ $$ \ldots $$ but I still have no idea how to find a generalized formula which allows to obtain the answer.","['algebra-precalculus', 'roots', 'nested-radicals']"
2211259,$X\subset \mathscr{P}(X)$,"Let $X$ be a  not empty set. If $X\subset \mathscr{P}(X)$, what can we say about the set $X$? For example: $$X=\{\emptyset\}$$ $$X=\{\emptyset,\{\emptyset\}\}$$ $$X=\{\emptyset,\{\emptyset\},\{\emptyset,\{\emptyset\}\}\}$$ approach : I think the empty set must be an element of $X$. Any hint would be appreciated.",['elementary-set-theory']
2211270,How to prove that a tangent cuts through a point when it has an odd order?,"I noticed that when a straight line which is a tangent to a polynomial at point $x_1$ is equated to the polynomial, we get a repeated root at point $x_1$. Let's define a cubic function: $$y=f(x)=ax^3+bx^2+cx+d$$ whose derivative is equal to: $$\frac{dy}{dx}=3ax^2+2bx+c$$ At point $x_1$, the slope is $3ax_1^2+2bx_1+c$. The tangent for point $x_1$ is thus: $$y-y_1=m(x-x_1)$$
$$\implies y-(ax^3_1+bx^2_1+cx_1+d)=(3ax_1^2+2bx_1+c)(x-x_1)$$
$$\implies y=(3ax_1^2+2bx_1+c)x-(2ax_1^3+bx_1^2-d)$$ This form of the tangent is general to every cubic. We can equate the tangent to the polnomial: $$ax^3+bx^2+cx+d=(3ax_1^2+2bx_1+c)x-(2ax_1^3+bx_1^2-d)$$
$$\implies ax^3+bx^2-(3ax_1^2+2bx_1)x+(2ax_1^3+bx_1^2)=0$$ Since we know $x-x_1$ is a factor, we can factor it out. $$\implies (x-x_1)[ax^2+bx+ax_1x-(2ax_1^2+bx_1)]=0$$
$$\implies (x-x_1)^2(ax+2ax_1+b)=0$$ Here the root is repeated. So going deeper into this I noticed that if $(x-x_1)$ is repeated thrice, then the tangent cuts through the line and that if it is repeated four times it touches the line. I came to the conjecture that if the root is repeated an even number times, the tangent will touch the curve, but if it is repeated an odd number of times, the tangent will cut through the curve. But how would one prove this conjecture?","['derivatives', 'calculus']"
2211281,Norm of covariance between scalar and vector,"I would like to show that if $Y\in\Re$ is a random real vector such that $\|Y\|≤ \bar Y$ and $X \in \mathcal H$ where $\mathcal H$ is a Hilbert space (whose field is $\Re$), then 
$$
\|\operatorname{Cov} (Y,X)\| = \|E(YX^*)\| ≤ \bar Y \|X\|_∞.
$$
The first idea is the following: if $X∈ \Re^p$, then I think that
$$
\|\operatorname{Cov} (Y,X)\| = \|E(YX^T)\| ≤ \sqrt{\operatorname{Var} (Y)}\max_{i=1,\ldots,p}\sqrt{\operatorname{Var}  (X_i)}
$$
which would yield the first equation based on the fact that if $|Z|≤\nu$, then $\operatorname{Var} (Z) ≤ ν^2$. The second idea (which yields the desired inequality in the real case when $X_i$ are independent one to each other) is to consider the fact that $X$ has limited total information upon $Y$.","['covariance', 'functional-analysis', 'statistics', 'probability', 'random-variables']"
2211294,"Is there a (""continuous"") base-$e$ number system?","Let $b=10$. Then for each $x \in [0,1)$, there is a unique sequence of numbers $a_1,a_2,\ldots$ in $\{0,\ldots,9\}$ not ending in an infinite sequence of $9$'s such that $$x=a_1b^{-1}+a_2b^{-2}+a_3b^{-3}+\cdots.$$ For example:
$$0.83 = 8\cdot b^{-1}+3\cdot b^{-2}+0\cdot b^{-3}+\cdots$$ I'm wondering if we there's a similar theorem involving $e$, but with everything made continuous. Something like this: Theorem. For each $x \in [0,1)$, there is a unique function $f: (0,\infty) \rightarrow [0,\infty)$ satisfying [insert deep condition here] such that $x = \int_0^\infty f(\alpha) e^{-\alpha} d\alpha$. (This is the Laplace transform of $f$ evaluated at $1$.) The idea is that we then proceed to define that $f$ is the ""base-$e$"" representation of the number $x$. It would then probably be easy to extend the idea to all of $\mathbb{R}_{>0}$, and hectic insights would hopefully follow.","['analytic-number-theory', 'laplace-transform', 'integral-transforms', 'functional-analysis', 'number-theory']"
2211461,Limit of Lebesgue Integral on a sequence of set whose measure tends to zero,"Given that $f$ is an integrable function on $X$ and $\{E_k\}_{k=1}^\infty$ where each $E_k$ is a measurable set such that $\lim_{k\rightarrow \infty} \mu(E_k) = 0$ Can we show that $$\lim_{k\rightarrow \infty} \int_{E_k} fd\mu = 0$$ I want to prove like this:
$$|\int_{E_k} fd\mu| \leq sup|f|\cdot \mu(E_k) \rightarrow 0 $$
The problem is when $|f| \rightarrow \infty$, I'm not sure if this is valid. And if we remove the condition $f$ integrable and instead make f positive measurable, does the result still hold?","['real-analysis', 'measure-theory']"
2211506,What are the methods for solving analytically an coupled system of second order linear PDEs?,"What are the methods for solving analytically an coupled system of second order linear PDE? (As I know we can solve by transforming to linear ODEs system. What else?) If you suggest some books or notes in order to learn to solving coupled system of second-order linear PDEs, I'm very pleased, your suggestions are very important for me.","['partial-derivative', 'systems-of-equations', 'ordinary-differential-equations', 'partial-differential-equations']"
2211523,Show that the function $f: N \to N$ given by ..,"Show that the function $f:N \to N$ given by 
$$f(x)= \begin{cases} x+1 & \text{If $x$ is odd} \\ x-1 & \text{If $x$ is even} \end{cases} $$ is bijective. My Attempt: Case$1$. Suppose $x_1$ is odd and $x_2$ is even.
$$f(x_1)=f(x_2)$$
$$x_1 + 1= x_2 -1$$
$$x_2 - x_1=2$$
This is impossible. So, our assumption is invalid. Case$2$. Suppose $x_1$ and $x_2$ are even.
$$f(x_1)=f(x_2)$$
$$x_1 - 1= x_2 -1$$
$$x_1=x_2$$ Case$3$. Supppse $x_1$ and $x_2$ are odd
$$f(x_1)=f(x_2)$$
$$x_1+1=x_2+1$$
$$x_1=x_2$$.","['algebra-precalculus', 'functions']"
2211539,"Navier-Stokes equation, about pressure...","I'm a computer science student writting a dissertation about fluid simulation on real time applications. I'm trying to understand a few things regarding the pressure term: 1) When talking about the Helmholtz-Hodge decomposition, my books say that you can decompose any vector field into a divergence-free field, and a gradient of a scalar fied, and that scalar field ""turns out"" to be the pressure. How do they get to that conclusion?
( http://http.developer.nvidia.com/GPUGems/gpugems_ch38.html chapter 38.2.4 section ""The Helmholtz-Hodge Decomposition"") 2) In many books or articles when computing pressure people say to take the divergence of the momentum equation, that ends up in a poisson equation. I don't understand why they take the divergence of everything, probably due to my lack of understanding of how poisson equation works or something related.
( http://http.developer.nvidia.com/GPUGems/gpugems_ch38.html chapter 38.2.4 section ""The Helmholtz-Hodge Decomposition - Second realization"" , in this article they don't take the divergence of the momentum equation but it's similar and with the same purpose) Keep in mind that I'm not a physics student so I kinda had to learn everything myself because in my university we don't really see much of this things, so probably my confusion is due to the lack of some basic concept that I haven't seen yet. Any help is appreciated, thanks.","['fluid-dynamics', 'calculus']"
2211580,Can we use numerical methods to get a symbolic/analytical solution of a PDE?,"I know the basic differences of numerical and analytical (symbolic) solutions to differential and complicated algebraic equations. Everyone knows that numerical solutions can be obtained even when an analytical solution can't be obtained. However, sometimes analytical solutions even if cannot be found would be preferred in many engineering and scientific applications, as they often give a physical insight to the mathematical description of a system that is not easy to get with a numerical solution. An example where it could be useful would be to see what inputs/parameters are influence the output the most in a model of a multi-input multi-output (MIMO) system. (See When are analytical solutions preferred over numerical solutions in practical problems? ). If indeed it was required, could it be possible to use numerical techniques to help in obtaining an analytical solution? Is it even remotely possible, or is what I am asking meaningless? Keep in mind that my knowledge of math is not advanced by any means, so am I missing something important here?","['numerical-methods', 'ordinary-differential-equations', 'symbolic-computation']"
2211614,Identify $\lim\limits_{x \to +\infty } x^2 \left(\sqrt{x^4+x+1}-\sqrt{x^4+x+5}\right)$,"Identify $$\lim\limits_{x \to +\infty } x^2 \left(\sqrt{x^4+x+1}-\sqrt{x^4+x+5}\right)$$ My Try : $$\sqrt{x^4+x+1}=\sqrt{x^4(1+\frac{1}{x^3}+\frac{1}{x^4})}=x^2\sqrt{(1+\frac{1}{x^3}+\frac{1}{x^4})}$$ Now : $$\frac{1}{x^3}+\frac{1}{x^4}=z$$ $$(1+z)^{\frac{1}{n}}= 1 + \frac1n x + \frac{1 - n}{2n^2}x^2 + \frac{2n^2 - 3n + 1}{6n^3}x^3 + O(x^4)$$
$$(1+(\frac{1}{x^3}+\frac{1}{x^4}))^{\frac{1}{2}}= 1 + \frac12 z - \frac{1}{8}z^2 + + O(z^3)$$ $$(1+(\frac{1}{x^3}+\frac{1}{x^4}))^{\frac{1}{2}}= 1 + \frac12 (\frac{1}{x^3}+\frac{1}{x^4}) - \frac{1}{8}(\frac{1}{x^3}+\frac{1}{x^4})^2 + O(z^3)$$ $$(1+(\frac{1}{x^3}+\frac{1}{x^4}))^{\frac{1}{2}}= 1 + \frac{1}{2x^3}+\frac{1}{2x^4} - \frac{x^2+2x+1}{8x^8} + O(z^3)$$ And : $$\sqrt{x^4+x+1}=\sqrt{x^4(1+\frac{1}{x^3}+\frac{5}{x^4})}=x^2\sqrt{(1+\frac{1}{x^3}+\frac{5}{x^4})}$$ So : $$(1+(\frac{1}{x^3}+\frac{5}{x^4}))^{\frac{1}{2}}= 1 +  \frac{1}{2x^3}+\frac{5}{2x^4} -  \frac{x^2+10x+25}{8x^8}+ O(z^3)$$ $$\lim\limits_{x \to +\infty }=x^4( 1 + \frac{1}{2x^3}+\frac{1}{2x^4} - \frac{x^2+2x+1}{8x^8} + O(z^3)-( 1 +  \frac{1}{2x^3}+\frac{5}{2x^4} -  \frac{x^2+10x+25}{8x^8}+ O(z^3)))$$ $$\lim\limits_{x \to +\infty }=x^4(\frac{1}{2x^4}-\frac{5}{2x^4})=x^4(\frac{-4}{2x^4})=-2$$ is it right ?",['limits']
2211626,Number of q-ary strings of length m which do not contain k consecutive zeros,"A finite q-ary-alphabet is given $$A_q = {0,1,2,...,q-1}.$$ Now I am considering the set of all finite strings over the alphabet $A_q$. I am interested on the number $$N(m,k)_{A_q}$$ of strings of length $m$ which do not contain $k$ consecutive zeros. Is there a general formulary for this number? Or how can I determine $N(m,k)_{A_q}$?","['combinatorics', 'bit-strings', 'discrete-mathematics']"
2211627,Zeros of complex function,"Consider the function
$f(z)=e^{z}+\varepsilon_1e^{\varepsilon_1 z}+\varepsilon_2e^{\varepsilon_2 z}$ of a complex variable $z=x+i y$, where
$\varepsilon_1=-\frac{1}{2}+i\frac{\sqrt{3}}{2}$, $\varepsilon_2=-\frac{1}{2}-i\frac{\sqrt{3}}{2}$.
Numerical calculations show that all zeros of the function $f(z)$ are located on the lines $y=0$, $y=\pm \sqrt{3} x$.
Are there any ideas how to prove it theoretically?",['complex-analysis']
2211636,Find the range of the function given by $f(x)=\sqrt {16-x^2}$,"Find the range of the function given by $f(x)=\sqrt {16-x^2}$. My Attempt:
$$f(x)=\sqrt {16-x^2}$$
$$y=\sqrt {16-x^2}$$
Squaring both sides, 
$$y^2=16-x^2$$ How do I proceed further?","['algebra-precalculus', 'functions']"
2211639,"> Find x, which satisfies the equation: $\sqrt{1-\cos (x)}+\sqrt{1+\cos (x)}=\sqrt 3$; SOLVED","* EDITED * Since I don't wan't to many ""votes down"" on my question; thereof I re-wrote my question in MathJax: I'm currently studying for an admission test and have encountered the following problem; Find x , which satisfies the equation: $\sqrt{1-\cos (x)}+\sqrt{1+\cos (x)}=\sqrt 3$ ; $ -\pi < x < \pi $ . Thereafter, calculate the sum of all squares of the specific x :s that have satisfied the above equation. C.A : $ \frac{13\pi ^2}9   $ I'm really not sure how to handle this problem. There are no direct-applicable rules that can compress expressions similar to the L.H.S in this problem. I have noticed the conjugates, but when I extend the expression, there seems to be a dead end? Am I missing something crucial? I'm thankful for every proposed clue to solve this problem!
//","['algebra-precalculus', 'trigonometry']"
2211650,"Solve the congruence $9x \equiv −3 \pmod{24}$. Give your answer as a congruence to the smallest possible modulus, and as a congruence modulo 24.","I've been able to find the answer as a congruence to the smallest possible modulus (i.e. mod 8) but unsure how to find answer as congruence to mod 24. Also, is everything I've done below correct?: gcd(9,24) = 3 Therefore, our congruence becomes 3x ≡ -1 (mod 8) So, 3x ≡ 7 (mod 8) We must find inverse 'c' of 3 (mod 8), i.e. 3c ≡ 1(mod 8) gcd(3,8) = 1 let 3c + 8y = 1 Using extended Euclidean Algorithm, we get c = 1 Therefore, solution of 3x ≡  7 (mod 8) (i.e. smallest possible modulus) is: x ≡ 7 (mod 8) Now, how to find solution as a congruence to modulus 24? Assuming everything I've done above is correct.","['modular-arithmetic', 'discrete-mathematics']"
2211651,Well-posedness of variational mapping problem,"Suppose $S_0,S\subseteq\mathbb{R}^3$ are embedded surfaces.  For a smooth map $\phi:S_0\rightarrow S$, define an energy $E[\phi]$ by
$$E[\phi]:=\int_{\Sigma_0}F[\Lambda(d\phi_p)]\,dA(p).$$
Here, $\Lambda(d\phi_p)\equiv (\sigma_1(d\phi_p),\sigma_2(d\phi_p))$ is the set of singular values of the Jacobian of $\phi$ at $p\in S_0$.  As an example, if we define $F[\sigma_1,\sigma_2]:=\sigma_1^2+\sigma_2^2$, then $E[\phi]$ is the Dirichlet energy of $\phi$. Here's my question: Given a smooth map $\phi_0:S_0\rightarrow S$, is there a sufficient condition on $F:\mathbb{R}^2\rightarrow\mathbb{R}$ guaranteeing existence of a map $\phi:S_0\rightarrow S$ in the homotopy class of $\phi$ that locally minimizes $E[\cdot]$? What I have in mind is the gradient flow of Eells and Sampson , which proves existence of harmonic maps when $S$ has negative Gaussian curvature by starting with an arbitrary $\phi_0$ and flowing along the gradient of the Dirichlet energy to a local optimum.  This is an elegant construction, but the drawback is that not all target surfaces $S$ admit a harmonic map $\phi:S_0\rightarrow S$. My intuition is that Eells and Sampson's construction fails in the presence of positive curvature because $F[\sigma_1,\sigma_2]=\sigma_1^2+\sigma_2^2$ ""wants to"" pinch points, i.e. reach a Jacobian with as small singular values as possible.  But perhaps objectives like the symmetric Dirichlet energy , which appears in computer graphics applications, which looks like $F[\sigma_1,\sigma_2]:=\sigma_1^2+\sigma_2^2+\sigma_1^{-2}+\sigma_2^{-2}$, would have better properties since it has an asymptote whenever $\sigma_i=0$ and is minimized when $\sigma_1=\sigma_2=1$.","['calculus-of-variations', 'riemannian-geometry', 'differential-geometry']"
2211655,If $f$ is bijective then $f(A^c) = f(A)^c$?,I am trying to show that if $f$ is bijective then $f(A^c) = f(A)^c$. My attempt: $y\in f(A^c) \iff y = f(x)$ where $x\in A^c \iff y = f(x)$ where $x\notin A \iff y \notin f(A)\iff y\in f(A)^c$. Is this correct (note that $A^c$ is the complement of $A$)?,['elementary-set-theory']
2211685,"Show that if $L^p$ is not a subset of $L^q$ for $q \gt p$ then $L^p$ contains indicators of sets of arbitrarily small, positive measure","Show that if $L^p$ is not a subset of  $L^q$ for $q \gt p$ then $L^p$ contains indicator functions of sets of arbitrarily small, yet positive measure. Since $L^p$ is not a subset of $L^q$, there exists $f \in L^p$ such that $f \not \in L^q$. For each $n_o \in \mathbb{N}$, Let $E_{n_0}=\{x \in X: |f(x)| \gt n_0\}$. Then we have $||f||_p^p=\int |f|^p d\mu \ge n_0^p \mu(E_{n_o})$ which implies that $\mu(E_{n_0}) \le \dfrac{||f||_p^p}{n_o^p}$. Now I claim that $\mu(E_{n_o}) \gt 0$ which will establish the claim. Suppose that $\mu(E_{n_o})=0$.  Now Let $F_1=\{x \in X : 0 \lt |f(x)| \le 1\}, F_2=\{x \in X : 1 \lt |f(x)| \le n_0\}$. Then $E_{n_0}^c=F_1 \cup F_2$. Now $\int_{F_1} |f| ^q \le \int_{F_1}|f|^p \lt \infty$ as $p \lt q$. Thus $\int |f|^q =\int_{E_{n_0}^c}|f|^q=\int_{F_1}|f|^q  +\int_{F_2}|f|^q= +\infty$ which implies that $\int_{F_2}|f|^q=\infty$ and therefore $\mu(F_2) =\infty$. On the other hand $\int |f|^p \ge \int_{F_2}|f|^p \ge \mu(F_2)=\infty $ which is a contradiction. Hence, the claim holds and we are done. Is this alright?","['real-analysis', 'lp-spaces', 'measure-theory', 'analysis']"
2211694,"If $f:\Bbb R\to \Bbb R$ defined by $f(x)=x^2+11, x\in \Bbb R$ then which of the following arguments is not true?","If $f:\Bbb R\to\Bbb R$ defined by $f(x)=x^2+11, x\in R$ then which of the following arguments is not true? State with justification. It is one to one. It is many to one It is onto. It is not bijective. My Effort: I guess the ans is $1$. But I neither know calculation nor the justification. Please help.","['algebra-precalculus', 'functions']"
2211736,Prove: $z^{12}+3z^8+101z^4+1$ has a root on the unit circle,"$\newcommand{\cis}{\operatorname{cis}}$>Prove that $$f(z)=z^{12}+3z^8+101z^4+1$$ has a root on the unit circle or $|z|\leq 1$ So started with looking at $$z^{12}+3z^8+101z^4+1=0$$ Therefore
$$z^{12}+3z^8+101z^4=-1$$ looking at $z=r\cis\theta$ we get $$r^{12}\cis(12\cdot\theta)+3r^8\cis(8\cdot \theta)+101r^4\cis(4\cdot \theta)=-1$$ And I can see that if $x=r^4\cis(4\theta)$ we get $$x^3+3x^2+101x+1=0$$ I also know that if $z$ is a solution so is  $\overline{z}$ How should I continue? Moreover: Can we say that $12$ degree polynomial as $12$ complex roots ($z$ and $\overline{z}$) but because we have $z^8$ and $z^4$ so there will be less than $12$ solutions?",['complex-analysis']
2211786,Probability that a random permutation fixes no elements for large $n$,"Here's a problem that's been going around my friend group. I have solved this problem, and am interested in a generalization of it. Here's the original problem: Pick an element of $\sigma\in S_n$ uniformity at random, and let $X(n)$ be the random variable that is the number of fixed points of $\sigma$. Compute $$\lim_{n\to\infty}P(X(n)=0)$$ Here's the extension: Suppose instead of $S_n$ we are interested in a class of subgroups, $\{H_n:n\in I\subseteq\mathbb{N}\}$. We can then ask: what is the probability the limit yields
$$\lim_{n\to\infty}\frac{\mu(H_n)}{|H_n|}$$ where $\mu(G)$ is the biggest number such that every element of $G$ fixes $\mu(G)$ or more elements of $[n]$ when viewed as a subset of $S_n$. The notion I'm trying to formalize here is ""the least number of fixed points that is actually achieved"" as for many groups, every element has a fixed point. This seems to be the right generalization of the problem, though other generalizations are welcome. I'm mostly asking this out of curiosity to see what can be proven. Results about transitive groups, doubly-transitive subgroups, $D_{2n}$, or any other reasonably interesting class of groups would be exciting for me. This link seems relevant, but it's not clear to me that this problem can be solved simply by summing Recontre numbers. This MSE post also seems relevant, but not quite enough to solve the problem on its own.","['permutations', 'combinatorics', 'probability', 'group-theory']"
2211823,Solve $\frac{2}{\sin x \cos x}=1+3\tan x$,"Solve this trigonometric equation given that $0\leq x\leq180$ $\frac{2}{\sin x \cos x}=1+3\tan x$ My attempt, I've tried by changing to $\frac{4}{\sin 2x}=1+3\tan x$, but it gets complicated and I'm stuck. Hope someone can help me out.","['algebra-precalculus', 'trigonometry']"
2211851,Operation satysfaying b*(b*a)=a=(a*b)*b for all a and b must be commutative,"Let $X$ be a nonempty set and $*$ operation defined on elements of $X$ such that for $a, b$ from $X$ there is $(a*b)*b=b*(b*a)=a$. Prove that operation $*$ is commutative. Exercise is taken from the ""Introduction to algebra"" by Kostrikin.","['algebra-precalculus', 'abstract-algebra', 'magma', 'binary-operations']"
2211896,Solve $\lim_{n\to \infty} \int_{0}^{\pi\over3} {{\sin^nx}\over \sin^nx+\cos^nx}dx$,"$$\lim_{n\to \infty} \int_{0}^{\pi\over3} {{\sin^nx}\over \sin^nx+\cos^nx}dx$$ I really don't know what to do. It was really simple if the upper limit was $\pi/2$, because I can change $x=\pi/2-t$, but in my case I have no idea.
Some help please? Thank you!","['integration', 'calculus', 'limits']"
2211907,Map not preserving vector addition but preserving scalar multiplication,"The question Map closed under addition but not multiplication asks for a map between two vector spaces where vector addition is preserved but also where scalar multiplication is not preserved. A student of mine switched this, and I have not found an example. Thus, what is an example of a map between two vector spaces where vector addition is not preserved but scalar multiplication is preserved? Thank you.",['linear-algebra']
2211921,Gamma distribution and probability less then expected value?,"Let $X\sim \operatorname{Gamma}(\alpha = 7, \beta)$, then $P(X > E(X))$ is: A) 0.35 B) 0.45 C) 0.55 D) 0.65 The answer is 0.45. This is what I have so far: $E(X)=\alpha\beta$ so I want $P(X > \alpha \beta)$, $\alpha=7$ so I can use the table for this if I divide by beta, but I don't have beta's original value. From the table I'm deducting that $X=7$.. My main question is, when I divide by $\beta$, am I also dividing the mean and variance by Beta? if that's the actual case I'm guessing $$P(X > E(X))= P(X > 7)$$ which then would make sense since $\alpha$ and $x$ are both 7. So is this the general rule when dividing by beta to make it equal to 1 to use the tables? Thank you!!! sorry for the rather lengthy question","['means', 'gamma-distribution', 'statistics', 'probability']"
2211939,How are these two exponential logarithmic equations equal? [duplicate],"This question already has answers here : How $a^{\log_b x} = x^{\log_b a}$? (4 answers) Closed 7 years ago . How does following assertion hold? I have tried some real values but can anyone explain it to me mathematically/algebraically? 
$$
a^{\log_{b}n} = n^{\log_{b}a}
$$ I'm reading something that asserts this, but I do not see the connection. Any help would be appreciated.","['algebra-precalculus', 'logarithms']"
2211983,Out of 10 people whats the probability that none gets his own umbrella...,"In a party there are 10 people with same umbrellas,at the end of the party they get one umbrella randomly.What is the probability that none gets its own umbrella?
I was thinking on solving this in the followin way:
The probability of the first person picking a wrong umbrella is $\frac{9}{10} $, then for the second guy it will be $\frac{8}{9}$, for the third $\frac {7}{8}$ and so on,so the probability of event A to happen would be: 
$$p(A) = \frac{9}{10} \cdot \frac{8}{9} \cdot \frac{7}{8} \cdots \frac{1}{2} \cdot 1$$
Is this solution correct,does the possibility of the first person getting the second person hats affect this solution?","['combinatorics', 'probability']"
2211991,Convex conjugate of a matrix function,"Let $S$ be some (not necessarily convex) subset of positive semidefinite matrices. What is the convex conjugate of the function
$$ f(x) = \sup_M \left\{ x^T M x \;:\; M \in S \right\},$$
that is, what is $f^*(y) = \sup_x \{ x^T y - f(x) \}$? I'm struggling with this one because there are essentially two maximization problems involved, and I don't really have any idea about how to approach this. I'd appreciate any help.","['matrices', 'matrix-equations', 'convex-optimization', 'convex-analysis']"
2212030,"Show there's an isomorphism between $\{ 0, 1 \}^A$ and $\mathcal{P}(A)$","I've gotten a lot of (constructive!) criticism by friends over this proof recently, so I've grown to feel it may be a bit lacking. I'd really appreciate it if someone could run through it and tell me if it's falling short of successfully proving what is required. Question: It is not unreasonable to use $2^A$ to denote the set of functions from an arbitrary set $A$ to a set with $2$ elements (say $\{0, 1\}$). Prove that there is a bijection between $2^A$ and the power set of $A$. Proof: Firstly, have $2^A$ be shorthand for $\{ 0,1 \}^A$, although note the proof is valid for any two element set. Let $S$ denote an element of $\mathcal{P}(A)$, and have $a \in S$. Let $\textbf{1}_S: \mathcal{P}(A) \to 2^A$ be an indicator function defined as
$$
\textbf{1}_S(a) :=
\begin{cases}
1 & \text{if $a \in S$} \\
0 & \text{if $a\notin S$}
\end{cases}
$$
for all sets $S$. Each $\textbf{1}_S$ for some set $S$ is then equal to the graph of some function $f \in 2^A$, where the graph $\Gamma_{f}$ is given by
$$ \{ (a,b) \in A \times \{ 0,1 \} \ | \ a\in A, \ b=f(a)\}.$$ Since no two subsets $S'$ and $S''$ are equal in $\mathcal{P}(A)$, they do not contain the same elements thus are mapped by $\textbf{1}_S$ to different function graphs in $2^A$, therefore $\textbf{1}_S$ is injective. Since $\mathcal{P}(A)$ contains all possible subsets of $A$, all possible mappings of the elements of $A$ are done through $\textbf{1}_S$, hence $\textbf{1}_S$ is surjective. Therefore $\textbf{1}_S$ is a bijection and $\mathcal{P}(A) \cong 2^A$","['elementary-set-theory', 'proof-verification']"
2212038,subharmonic on punctured disk but extends continuously to origin,"Suppose that $f$ is bounded and subharmonic on $\Omega = D(0,1) - \{0\}$.  Suppose also that $L = \sup_{z \in \Omega} f(z)$ and $\lim_{z \to 0}f(z) = L$. How can I prove that $f$ extends subharmonically to all of $D(0, 1)$ with $f(0) = L$?","['complex-analysis', 'harmonic-functions', 'analysis', 'harmonic-analysis']"
2212039,Probability that Random Harmonic Type Series Converges,"Recently I have come across a variety of truly wonderful results that deal with series that look like harmonic series: All of the series $$\sum_{n = 1}^{\infty} \frac{1}{n^{1+1/n}}, \ \sum_{n = 1}^{\infty} \frac{|\sin(n)|}{n}, \ \sum_{n = 1}^{\infty} \frac{1}{n^{2 - \epsilon + \sin(n)}}, \ \sum_{n = 1}^{\infty} \frac{1}{n^{1 + |\sin(n)|}}   $$ diverge. The proof for the latter three mostly hinges on the fact that the fractional parts of $\{\sin(n)\}_{n \in \mathbb{N}}$ are equidistributed in the unit interval. This leads me to ask the following question: Let $u_i \sim Unif([0,1])$. What is the probability that $$\sum_{n = 1}^{\infty} \frac{1}{n^{1+ u_n}}$$ diverges ? Similarly, we can ask an analogue question where $u_i$ are drawn from an arbitrary distribution $X$. I do not much knowledge in this area so any helpful comments and directions are welcomed.","['stochastic-processes', 'real-analysis', 'sequences-and-series', 'probability-theory']"
2212045,Modified sum of prime factors function,"Let $sopfr(n)$ be the sum of be the sum of prime factors (with repetition) of a number $n$. For example $sopfr(20)=2 + 2 + 5 = 9$ $^{(1.)}$ Then define: $m(n) = \min\limits_{k\ge n} sopfr(k)$. I am interested in a explicit formula for $m(n)$. The motivation for this is - what is the ""perimeter"" of the smallest $n$-dimensional (i.e. minimal sum of columns, rows etc.) table of elements that can fit $N$ elements? If $N$ is a nice number (say $10$), we can divide it into its divisors ($10=2*5$). Since $ab \ge a+b$ it follows that the smallest sum is of the numbers prime factors. Yet when dealing with a number like $17$, its better to substitute it for $18=2*3*3$ that is the best number by inspection. So $17$ can be best fitted into a ""box"" with dimensions $2,3,3$  i.e. $m(17)=2+3+3=8$ Obviously, it should be that the lower bound for $sopfr(n)$ should produce something close . The lower bound of $sopfr(n)$ is $3\log_{3} n$ $^{(2.)}$ Yet $m(n) - \lceil3\log_{3} n\rceil$ attains many, many zeroes and in general fits very well , except for odd strings of $1$ in between seas of zeroes. Defining in Mathematica the following: sopfr[n_] := Plus @@ Times @@@ FactorInteger@n; sopfr[1] = 0; m[n_] := Min[Table[sopfr[i], {i, n, 3^(Ceiling[Log[3, n]])}]] p[x_] := Ceiling[3*Log[3, x]]; Table[m[x] - p[x], {x, 1, 5000}] we get in the first $5000$ differences that there are a total of $925$ ones. The upper counting limit on $m(n)$ is from the fact that the minimum will be obtained quicker then the nearest greater power of $3$, (EDIT: by Matthews answer and inspection) Any help would be appreciated. Edit1: Counting up till $10000$ we get $2055$ ones, so the accuracy is decreasing from $0.185$ to $0.2055$ (ratio of ones to all) 1 Sum of Prime Factors 2 result by Rafael Jakimczuk , from here is the source and also definition of sopfr[n_] by Ray Chandler","['prime-factorization', 'prime-numbers', 'functions']"
2212065,A proof that there is an angle $\theta$ such that cos($\theta$) = $\theta$,"Would anyone be willing to provide and explain a geometric proof that there is an angle $\theta$ such that cos($\theta$) = $\theta$ I came across it in a textbook, but I have trouble understanding it.","['trigonometry', 'proof-explanation']"
2212107,A continued fraction with a delayed repeating part,"I had previously seen how to solve for infinite continued fractions by solving a quadratic polynomial. But in regard to the following I tried the same methods and could not seem to get it to work, maybe there is a good trick I could use? $C=[3,6,1,4,1,4,1,4,.....]$ I tried to split it into different fractions and use reciprocals, but I cant seem to get any form that works for solving a quadratic or polynomial.","['number-theory', 'continued-fractions']"
2212109,Localizing a divisor on a scheme,"Fix an integral Noetherian separated scheme $X$ that is regular in codimension 1, then let $D\in\operatorname{Div}X$ be any divisor, then Hartshorne claims that for any point $x\in X$, we can localize the divisor $D$ to obtain some divisor $D_x\in\operatorname{Div}\operatorname{Spec}\mathscr{O}_{X,x}$ in a natural (presumably linear, and possibly surjective) way. But how can we do this? I don't see any sufficiently clear connection between $\operatorname{Spec}\mathscr{O}_{X,x}$ and $X$ to obtain such a map.",['algebraic-geometry']
2212219,What is the closed form of $\sum_{n\geq 1}(-1)^{n-1}\psi'(n)^2$?,"This problem was proposed by Cornel Ioan Valean. What is the closed form of
  $$ S=\sum_{n\geq 1}(-1)^{n+1}\psi'(n)^2 $$
  ? I recall that $\psi'(z)=\frac{d^2}{dz^2}\log\Gamma(z)=\sum_{m\geq 0}\frac{1}{(m+z)^2}$ for any $z>0$. My attempt was to perform the following manipulation
$$ \sum_{n\geq 1}(-1)^{n+1}\psi'(n)^2 = \sum_{\substack{m,n\geq 1 \\ \min(m,n)\text{ odd}}}\frac{1}{m^2 n^2} \tag{A}$$
in order to turn the original series into
$$\begin{eqnarray*} 2\sum_{n\geq 0}\frac{\zeta(2)-H_{2n+1}^{(2)}}{(2n+1)^2}+\sum_{n\geq 0}\frac{1}{(2n+1)^4}&=&\frac{5\pi^4}{96}-2\sum_{n\geq 0}\frac{H_{2n+1}^{(2)}}{(2n+1)^2}\\&=&\frac{19\pi^4}{1440}+\frac{1}{2}\color{blue}{\sum_{n\geq 1}\frac{H_{2n}^{(2)}}{n^2}}\end{eqnarray*} \tag{B}$$
not so bad after all. My issue is that now I am not able to find a decent closed form for the last series. If we apply summation by parts we have:
$$\begin{eqnarray*} \color{blue}{\sum_{n\geq 1}\frac{H_{2n}^{(2)}}{n^2}}&=&\frac{\pi^4}{36}-\sum_{m\geq 1}\frac{H_m^{(2)}}{(2m+2)^2}-\sum_{m\geq 1}\frac{H_m^{(2)}}{(2m+1)^2}\\&=&\frac{37 \pi^4}{1440}-\color{green}{\sum_{m\geq 1}\frac{H_{m}^{(2)}}{(2m+1)^2}}\end{eqnarray*}\tag{C} $$
but the green series does not seem to be really ""better"" than the blue one. Maybe it is relevant to point out that
$$ \color{green}{\sum_{m\geq 1}\frac{H_{m}^{(2)}}{(2m+1)^2}} = -\int_{0}^{1}\frac{\text{Li}_2(z^2)}{1-z^2}\log(z)\,dz.\tag{D}$$ Do you see a way to tackle the last series, or the original one through a different approach? Numerically, $S\approx 2.3949463369266426$.","['special-functions', 'harmonic-numbers', 'sequences-and-series', 'digamma-function']"
2212228,A bound on $e^{A+B}$ for noncommutative $A$ and $B$,"It is folklore that when two complex $n\times n$ matrices $A$ and $B$ commute, the equality $e^{A+B}=e^Ae^B$ holds.  An elementary consequence of this is that for any submultiplicative norm, commuting matrices satisfy the inequality $$||e^{A+B}||\leq ||e^A||\cdot||e^B||.$$ Earlier this week, I was trying to prove a result (with $n=2$) that would have benefitted from the above inequality. However, my matrices did not commute. Testing a few thousand pairs of matrices in GNU Octave, not a single one failed to pass the test, which is reasonable evidence to suggest that the above inequality might hold generally or, if it fails, one might need to be clever in finding a counterexample. I could not find a counterexample and did not get very far in proving it. While I have moved on a proved the result without the inequality, it's still bothering me. Could somebody shed some light on this?","['matrices', 'analysis']"
2212327,The image of a complete normed space under an open linear continuous map is complete,"Let $X$ and $Y$ be normed linear spaces and let $T:X\rightarrow Y$ be open, linear and continuous. If $X$ is complete then show that $Y$ is complete. I have proceeded little bit. Since $T$ is an open map then $T$ is onto and  there exists a $\delta >0$ such that for each $y\in Y$ there exists $x\in X$ with $\|x\|<\delta \|y\|$ and $T(x)=y$. Now let us take a sequence $(y_{n})$ in $Y$ which is Cauchy. Now we will get $(x_{n})$ such that  $\|x_{n}\|<\delta \|y_{n}\|$ and $T(x_{n})=y_{n}$. Now if we can show that $x_{n}$ is 
Cauchy, the rest will follow. But I can't show that.","['functional-analysis', 'normed-spaces', 'banach-spaces', 'cauchy-sequences']"
2212333,Maximum area of a rectangle inscribed in the cos(x) function,"I have to find the maximum area of a rectangle inscribed in the cos(x) function with $0 < x < \pi /2$ (as in the picture below). The area, which I will call ""A"", is defined as $$ A = 2 x \cos(x)$$ I started by differentiating the area in terms of x: $\frac{dA}{dx} = 2\cos(x) + 2x (-\sin(x))$ $\frac{dA}{dx} = 2\cos(x)  -2x\sin(x)$ $\frac{dA}{dx} = 2[\cos(x)  -x\sin(x)]$ Now I look for the critical points $0 = 2[\cos(x)  -x\sin(x)]$ $0 = \cos(x)  -x\sin(x)$ $x\sin(x) = \cos(x)$ Here sin(x) is not 0 because the domain is restricted to $(0; \pi / 2)$ so I assume I can divide both sides by sin(x) (if this reasoning is wrong please correct me). $x = \frac{\cos(x)}{\sin(x)}$ $x = \cot(x)$ So this critical point that I'm looking for should be a fixed point of the cotangent on the interval $(0; \pi / 2)$. I made a graph and it seems to match my thinking: The red line is $x = \pi /2$ The cyan line is $y = x$ The black curve is the original area function $A = 2x \cos(x)$ The orange curve is $\frac{dA}{dx}$ The purple curve is $\cot(x)$ So it looks like the x value where the cotangent intersects the $y = x$ line is also where the area function peaks and where the derivative is 0. And here is where I'm stuck. How do I find that fixed point of $\cot(x)$? Or maybe I'm making a mistake and there is a simpler way to solve this problem without involving the cotangent, if that's the case I would like to know .","['trigonometry', 'arithmetic', 'geometry']"
2212372,Finding periodic orbits,"Given the following equations \begin{cases} 
    \dot x = - x - y + \cos t,\\
    \dot y = x - y + \sin t.
\end{cases} I am looking for periodic orbits. I managed to find the general solution for some initial conditions $x_0,y_0$
\begin{equation}
\begin{pmatrix} 
x \\ y 
\end{pmatrix}
= e^{-t}
\begin{pmatrix} 
\cos t & -\sin t \\ \sin t & \cos t 
\end{pmatrix}
\begin{pmatrix} 
x_0-1 \\ y_0
\end{pmatrix}
+
\begin{pmatrix} 
\cos t \\ \sin t 
\end{pmatrix}
\end{equation} However, I am not sure what to do and how to proceed to finding the periodic orbits. One way of doing that seems to be choosing the initial conditions so that the solution is a periodic function, so $x_0 = 1, y_0=0$ but it seems odd... Can someone suggest any hints/steps? Thank you.","['ordinary-differential-equations', 'dynamical-systems']"
2212388,Prove that the polynomial $a_nx^n+\cdots+a_1x+a_0$ has no rational roots,"Let $\overline{a_n \ldots a_1a_0}$ be the decimal representation of $65^k$ for some $k \geq 2$. Prove that the polynomial $a_nx^n+\cdots+a_1x+a_0$ has no rational roots. I thought about using the rational root theorem. We know that $a_0 = 5$ since $65$ ends in a $5$, so any rational root must be of the form $-\dfrac{5}{a}$ or $-\dfrac{1}{a}$ where $a$ is an integer factor of $a_n$. How can we continue?",['number-theory']
2212392,Simply Connected Domain of the plane and the Jordan Curve Theorem,"While reading Markushevich's complex analysis book, I realized that his definition of a simply connected domain differs from the one I have seen before. He takes the Jordan Curve Theorem for granted, and denotes the interior of a closed Jordan curve by $I(\gamma)$. Then he defines (pages 70~72 of vol.1) ; A domain $G$ is simply connected iff whenever $G$ contains a closed Jordan curve $\gamma$, $G$ also contains $I(\gamma)$. Then he shows some interesting results, such as a bounded domain is simply connected if and only if its boundary is connected (of course, with his definition). My question is : Does the above definition coincides with the usual one, given by the condition $\pi_1(G)=1$ for the fundamental group of $G$? I know that this has to be the case since otherwise the whole theory would break down.. but how exactly can we explain this equivalence? Do we need the Jordan–Schoenflies theorem? Any advice is welcome. Any reference is also welcome.","['algebraic-topology', 'complex-analysis', 'low-dimensional-topology', 'geometric-topology']"
2212394,Roots of unity notation,"The question I'm about to ask sounds furiously idiotic, but it's been driving me nuts so here goes. Recall Euler's formula,
$$e^{i\theta} = \cos\theta + i\sin\theta.$$
In particular, $e^{2\pi i} = 1$. Now, for a positive integer $n$, the $n^{th}$ roots of unity are denoted
$$(\zeta_n)^k\quad\text{where}\quad\zeta = e^{2\pi i/n},\quad k = 1,\dots ,n.$$
My question is: why? Wouldn't it make more sense to instead denote the first $n^{th}$ root of unity by $1^{1/n}?$","['notation', 'roots-of-unity', 'trigonometry', 'complex-numbers']"
2212446,Show that if $f(x+y)=g(x)+g(y) $ a.e. then functions are linear,"Let  $f(x), g(x), h(x)$ be measureable functions such that \begin{align}
f(x+y)=g(x)+h(y),
\end{align}
almost everywhere $(x,y) \in \mathbb{R}^2$. Can we show that 
\begin{align}
g(x)&=ax+b_1,\\
h(x)&=ax+b_2,
\end{align}
almost everywhere $(x,y) \in \mathbb{R}^2$ for some $a,b_1,b_2$. My attempt: Which I think is problematic. Since, $f(x+y)=g(x)+h(y)$, we have that 
\begin{align}
f(x+0)=g(x)+h(0)\\
f(0+y)=g(0)+h(y)
\end{align} Now adding the two equations and use our identity we get
\begin{align}
f(x+0)+f(y+0)=g(x)+h(y)+h(0)+g(0)= f(x+y)+f(0).
\end{align} So, we have that
\begin{align}
f(x)+f(y)=f(x+y)+f(0)
\end{align}
Next, difine a function $\phi(x)=f(x)-f(0)$ and we get 
\begin{align}
\phi(x)+\phi(y)=\phi(x+y).
\end{align} The above is know as Cauchy's functional equation and if $\phi(x)$ is measureable (which it is since $f$ is measurable) then it must be linear (i.e., $\phi(x)=ax$). Going backward this shows that $g(x)$ and $h(x)$ are given by \begin{align}
g(x)&=ax+b_1,\\
h(x)&=ax+b_2,
\end{align}
for some $a,b_1,b_2$. Questions: 1) Is this proof correct? 2) Since, we are assuming that equation $f(x+y)=g(x)+h(y)$ holds almost everywhere and not everywhere. Is this problem?   For example, in the very first step of the proof
\begin{align}
f(x+0)=g(x)+h(0)\\
f(0+y)=g(0)+h(y)
\end{align} can we do this? Is there problem of choosing $(x,0)$ and $(0,y)$? I think there is a possibility that $(x,0)$ and $(0,y)$ might belong to a set of measure zero on which the equations don't hold. 3) Another, question very similar to 2). Since,  $\phi(x)+\phi(y)=\phi(x+y)$ holds a.e. can we apply Cauchy equation?","['functional-analysis', 'real-analysis', 'functional-equations']"
2212455,How would I find the variance of a random variable with this distribution?,"Random variable $X$ has the following distribution:
$P(X=0) = 1/2$
For all non-zero integers, $P(X=n) = (1/2)^{|n|+2}$ How would I find the variance of this random variable? I know that the variance can be found by calculating $\operatorname{E}(X^2) - \operatorname{E}(X)^2$ but I am unsure of how to do this since the PMF has two parts. Thanks!","['statistics', 'probability', 'random-variables']"
2212496,Distance between sets with one closed set and one compact set,"I would like to prove the following statement. Let A and B be nonempty disjoint subsets of $\mathbb{R}$ where A is closed and B is compact. Then there exists $a \in A$ and $b \in B$ such that $inf${$|a-b|$:$a \in A, b \in B$}=$|a-b|$ A and B disjoint, A compact, and B closed implies there is positive distance between both sets I read a similar question above where the concept of ""limit point"" and others were used, but my class (Introduction to Analysis) has not gone that far; most of all, I would like to prove the statement from the knowledge that the class covered. So far, I have learned definition of limit of a sequence, Bolzano-Weierstrass Theorem. Also, I just learned (and proved) that there exists a sequence ${a_n}$ in E such that $\lim{a_n} = \inf{E}$ if E is a nonempty subset of $\mathbb{R}$ (whether E is bounded below or not due to the extended real numbers). From the things that I learned, first, I constructed a set $E$={$|a-b|$:$a\in{A}, b\in{B}$} and I know that there exists a sequence ${x_{n}}$ in E such that $\lim{x_{n}}=infE$. Since ${x_{n}} \in{E}, x_{n}=a_{n}-b_{n}$ where $a_{n} \in A, b_{n} \in B$. Let $infE = \beta$. Then, this leads to $\lim{(a_{n}-b_{n})}=\beta$. Then, for any $\epsilon$>0, there exists $N \in$ $\mathbb{N}$ such that $|a_{n}-b_{n}-\beta|<\epsilon$ for all n $\ge$ N. Then, I could not proceed. I should use conditions that A and B are disjoint, A is closed, and B is compact. Could anyone help me proceed? I had a feeling that using contradiction might work from the link above, but it is quite tough. Since I am a novice (just started taking Introduction to Analysis), I would very much appreciate it if you could help me prove this at the beginner level.",['analysis']
2212512,Convergence of $\sum_k \epsilon_k a_k$ implies $(\epsilon_1 + \cdots +\epsilon_k)a_k \rightarrow 0$,"Let $\epsilon_k \in \{\pm 1\}$, and suppose $\sum_k \epsilon_k a_k$ is convergent, where $a_k \geq a_{k+1} \geq 0$. Prove that $(\epsilon_1 + \cdots + \epsilon_k)a_k \rightarrow 0$ as $k \rightarrow \infty$.","['real-analysis', 'sequences-and-series', 'calculus']"
2212532,Can uncountable be defined as unable to be generated by any algorithm,"I'm trying to describe the concept of uncountable to someone with even less knowledge of math than myself ;-). I came up with the idea that for any countable set, $S$, you could create an algorithm $A$, such that for any proper subset $T$ of $S$, you could generate all elements of $T$ in a finite number with a sufficient number of iterations of $A$, but that for an uncountable set, there is no such algorithm that could do this for every proper subset. Is this a valid statement?",['elementary-set-theory']
2212568,How do actuaries calculate the premium of catastrophic insurance given the shortage of data?,"Since catastrophes seldom happen, there aren't enough data points for meaningful statistical analysis. So, how do actuaries go about doing their calculation for the premium of these kinds of insurance given the lack of data points?","['statistics', 'actuarial-science']"
2212580,Convex hull of a compact set in a normed linear space,"I want to show that the closure of the convex hull of a compact set in a normed linear space is compact. This came up in a book on Functional Analysis where the author wants to make sense of vector valued integration. In particular the problem is if $\varphi: [0,1]\rightarrow V$ be a continuous map from the unit interval to a real normed linear space then the closure of the convex hull of $\varphi([0,1])$ is compact. There are questions on stakexchange, for example, this and this , which deal with similar issues but they do not answer my question.","['functional-analysis', 'general-topology']"
2212604,Show that $\lvert \mathbb Z^n / N\rvert = \lvert \det (A) \rvert$. [duplicate],"This question already has answers here : Quotient group $\mathbb Z^n/\ \text{im}(A)$ [duplicate] (2 answers) Closed 7 years ago . Let $N$ be a rank $n$ submodule of $\mathbb Z^n$, and let $A$ be the matrix with rows being the generators of $N$. Show that $\lvert \mathbb Z^n / N\rvert = \lvert \det (A) \rvert$. So this is a homework problem, and I am a little confused. Shouldn't it be the case that $\mathbb Z^n$ is the unique (up to isom.) free module of rank $n$? Then, wouldn't this imply that $N = \mathbb Z^n$? I think I am missing something here, but even assuming that this is indeed the case, then we would be trying to prove that $\lvert \det (A) \rvert = 1$ for every invertible matrix $A$ with entries in $\mathbb Z$, which I don't think is true.","['abstract-algebra', 'ring-theory', 'modules', 'linear-algebra']"
2212613,Clarification regarding the Archimedean Property,"This is kind of a general question concerning the Archimedean property in the context of real analysis. I understand that for every real number, there exists a natural number that is greater than or equal to it. Specifically in this example, I am trying to understand what it means when the book states that $\frac{1}{K} \lt \epsilon$ . Then it says $n \ge K $ . $1/n \le 1/K \lt \epsilon$ . Is this saying that you can always find a number $n$ greater than or
equal to any natural number $K$ ? How is $1/n \le 1/K \lt \epsilon$ to be interpreted? What number system is $n$ from? Is it the naturals? What does the book mean when it states that $1/K \lt \epsilon$ ? What is epsilon representing in this case? I am using this to do some proofs on sequences of functions and uniform continuity and this seems to be a big part of it. I need some help interpreting what is actually going in this statement. Any help is appreciated.","['number-theory', 'real-analysis']"
2212673,Can you integrate over a removable discontinuity?,"$$\int_0^4 x+2\ \mathrm{d}x = 16$$ $$\int_0^4 \frac{x^2-4}{x-2}\,\mathrm{d}x = 16?$$","['integration', 'calculus']"
2212678,Ranges given instead of exact values in survey,"I gave a survey wherein one data there is stated as to how often do individuals watch tv in a day. I was hoping to get exact values from the individuals but some of them put ranges like 1-5 times in a day. Given that, how can I get the average of the data? Should I average each ranges? Thanks in advance","['descriptive-statistics', 'statistics', 'statistical-inference']"
2212679,Prove the existence of an element with order = exponent of a Finite Abelian Group,"Let $G$ be a finite abelian group. If $m=$exponent of $G$, then by definition $m=lcm(|g_1|,...,|g_n|)$ for all $g_i \in G$ . It suffices to show if $g \in G$ has the maximum order, then $\forall g_i \in G$, $|g_i|$ divides $|g|$. But then I'm stuck.","['abelian-groups', 'group-theory']"
2212683,"is Cov(X, E(X|Y)) equal to VAR( E(X|Y) )??","I am writing a code which uses the value of $Cov(X,E(X|Y))$. I thought it will be equal to $Var( E(X|Y) )$.
But my output seemed to be incorrect. Please let me know whether my understanding is correct. Let $Z = E(X|Y)$ which is basically $f(Y)$ and $$cov(X,Z) = E(XZ) - E(X)E(Z)$$ where $E(XZ) = E[ E(XZ|Y) ] = E [ E(f(Y)X|Y) ] = E[f(Y) E(X|Y) ] = E(Z^2)$
and $E(Z) = E(X)$ so then $Cov(X,Z) = E(Z^2) - E(Z) ^ 2$ which is $Var(Z)$ EDIT: with CODE I am writing code in octave. I will simplify my code.
Say X, Y have joint distribution. 
I computed PDF for X and PDF for E(X|Y) Joint PDF of X and Y X|Y  -1    0   1
2    1/6  2/6  0
3    2/6   0   0
4     0    0  1/6 PDF of X 1/2   2/6   1/6
  X  2     3     4 PDF of E(X|Y) 2/6   1/2   1/6
Z=E[X/Y]  2    8/3    4 CODE nSamples = 100000;

RX = [2 3 4];
PrX = [1/2 2/6 1/6];
X = randsample(RX,nSamples,true,PrX);

RZ = [2 8/3 4];
PrZ = [2/6 1/2 1/6];
Z = randsample(RZ,nSamples,true,PrZ);

disp(cov(X,Z))
disp(var(Z))","['statistics', 'probability']"
2212702,How do we show that $\int_{-\infty}^{+\infty}{\mathrm dx\over x^2}\cdot e^{-x^2}\sin^2(x^2)=\sqrt{\pi}\left(\sqrt{\phi}-1\right)?$,"Given the integral $(1)$ $$\int_{-\infty}^{+\infty}{\mathrm dx\over x^2}\cdot e^{-x^2}\sin^2(x^2)=\color{red}{\sqrt{\pi}\left(\sqrt{\phi}-1\right)}\tag1$$ How does one prove $(1)$? An attempt: $u=x^2$ $(1)$ becomes $${1\over 2}\int_{-\infty}^{+\infty}{\mathrm du\over u^{3/2}}\cdot e^{-u}\sin^2 u\tag2$$ Recall series $(3)$ $$e^{-x}\sin x=\sum_{n=1}^{\infty}{2^{n/2}(-x)^n\sin(n\pi/4)\over n!}\tag3$$ then $(2)$ becomes $$\sum_{n=1}^{\infty}(-1)^n{2^{n/2}\sin(n\pi/4)\over n!}\color{blue}{\int_{-\infty}^{+\infty}u^{n-3/2}\sin u\mathrm du}\tag4$$ The blue part diverges, so how else do we tackle $(1)?$","['integration', 'definite-integrals', 'calculus']"
2212722,Is $e^{|x|}$ differentiable?,"My thoughts go as follows: For $x > 0$, $e^{|x|} = e^x $ For $x < 0$, $e^{|x|} = e^{-x}$ Both $e^x$ and $e^{-x}$ are differentiable at every point in their domains, so $e^{|x|}$ will be differentiable for all $x \ne 0$ $e^{|x|}$ is certainly continuous everywhere, so I can't rule out differentiability with that criterion. I know the derivative of $e^x$ at $x=0$ is $1$, and the derivative of $e^{-x}$ at $x = 0$ is $-1$, so to me this indicates that the right hand limit and left hand limit of 
$\frac{e^{|x|} - 1}{x}$ approach different values as $x$ approaches $0$, so it cannot be differentiable at $0$. This seems logically correct to me, but I'm not completely certain, and it feels a little weak. Any advice?","['derivatives', 'exponential-function', 'absolute-value']"
2212726,Compute UMVUE of $\frac{\mu}{\sigma^2}$,"Given $X_1,\ldots, X_7$ are i.i.d r.vs which follow $N(\mu, \sigma^2)$. (a) Find the UMVUE of $\frac{\mu}{\sigma^2}$. (b) Compute variance of UMVUE in part (a) (c) Find the lower bound of the variance of unbiased estimator of $\frac{\mu}{\sigma^2}$ for $n$ i.i.d variables $X_1, X_2,...,X_n$ follows $N(\mu, \sigma^2)$. My thought: First, we realize that $E(S^2) = \sigma^2$ where $S^2 = \frac{\sum_{i=1}^{7} (X_i - \overline{X})^2}{6}$ is a sample variance. Thus, $E(\frac{1}{S^2}) = \frac{A}{\sigma^2}$ (I could not see how to compute this constant $A$). Since the sample mean and sample variance of $X_1,\ldots, X_7$ are independent, we have: $E(\frac{\overline{X}}{S^2}) = E(\overline{X})E(\frac{1}{S^2}) = \frac{\mu}{A}$, so $\frac{\overline{X}}{AS^2}$ is the unbiased estimator of $\frac{\mu}{\sigma^2}$. Now, this unbiased estimator could be expressed as a complete sufficient statistics $(\sum_{i=1}^{7} X_i, \sum_{i=1}^{7} X_i^2)$ because $S^2 = \frac{\sum_{i=1}^{7} X_i^2 - \frac{(\sum_{i=1}^{7} X_i)^2}{7}}{6}$. This implies $\fbox{$\frac{\overline{X}}{AS^2}$}$ is a UMVUE of $\frac{\mu}{\sigma^2}$ (b) Thanks to the work by NCH below, we obtain UMVUE of $\frac{\mu}{\sigma^2}$ is $\frac{2}{3} \frac{\overline{X}}{S^2}$. Thus, to compute $Var(\frac{\overline{X}}{S^2})$, we need to compute $E(\frac{\overline{X}^2}{S^4})$. First, since $\overline{X}$ and $\frac{1}{S^2}$ are independent, $\overline{X}^2$ and $\frac{1}{S^4}$ are independent. So $E(\frac{\overline{X}^2}{S^4}) = E(\overline{X}^2)E(\frac{1}{S^4})$. Now, since $Var(\overline{X}) = \frac{Var(X_1)}{7} = \frac{\sigma^2}{7}$, $E(\overline{X}) = \frac{\sigma^2}{7} + \mu^2$ My question: Could anyone please help me determine the constant $A$ above to complete this proof? I feel so shameful not to be able to compute $E(\frac{1}{S^2})$.","['statistics', 'statistical-inference']"
2212746,Order and Degree of Differential Equation,"I am unable to find the order and degree of the following differential equation: $x^2(dx)^2 + 2xy dx dy + y^2(dy)^2 - z^2(dz)^2 = 0$ My approach: Take the term $z^2(dz)^2$ to right hand side and then divide throughout by $(dz)^2$ we get  $$\mathrm{\dfrac{x^2(dx)^2}{(dz)^2} + \dfrac{2xy\ dx \ dy}{(dz)^2} +\dfrac{y^2(dy)^2}{(dz)^2} = z^2}$$ By seeing this, we can deduce that order is 1 and degree 2. But when I am looking at the middle term it contains dx dy/(dz)^2 term which is a term of order 2 and hence degree 1. Well am I right here? Is there any other way of finding the degree and order of this total differential equation? Do suggest, if any.",['ordinary-differential-equations']
2212757,Completeness and isometry,"İf the metric spaces $X_1$ and $X_2$ are isometric and $X_1$ is complete, show that $X_2$ is complete. I just know the definition. Can we conclude from the definition that every Cauchy sequence is convergent?","['functional-analysis', 'metric-spaces']"
2212765,Handling $\frac{dy}{dx}$ as a ratio. [duplicate],"This question already has answers here : Is $\frac{\textrm{d}y}{\textrm{d}x}$ not a ratio? (27 answers) Closed 7 years ago . I know that given a differential equation, one that is separable, it is not fully correct to handle the $\frac{dy}{dx}$ as a ratio. Meaning that it is not simply a small difference in $y$ over a small difference in $x$, as the difference is infinitesimal. It is simply a notation created by Leibnitz that is equivalent to $f'(x)$. My question is if this is the case then why is this method for ODE still used and taught? Is the answer always correct when dealing with ODE using this method or is does it lead to wrong results in some cases?","['derivatives', 'ordinary-differential-equations', 'notation']"
2212770,Normalization of a plane curve (showing equality of ideals),"I'm computing the normalization of the curve $y^3-x^4-x^3$ in $k[x,y]$, where $k$ is a field, and I'm only missing one key step. I want to show that the kernel of the map
$$
f:k[x,y]\to k[x,y,t]/(xt-y,t^3-x-1)\cong k[t]
$$
is precisely the ideal defined by the curve. It's clear that $(y^3-x^4-x^3)\subseteq\ker f$, yet I can't show the other contention. In case it's useful the map into $k[t]$ is given by $x\mapsto t^3-1$ and $y\mapsto t(t^3-1)$. I've tried messing with the polynomials with no success. It seems to be one of those problem where there is a method that works more generally, so if it's the case I'd appreciate an explanation. Any help is welcome.","['algebraic-geometry', 'commutative-algebra']"
2212773,Consider an isosceles triangle,Consider an isosceles triangle. Let $r$ be the radius of its circumscribed circle and $p$ the radius of its inscribed circle. Prove that the distance $d$ between the centres of these two circles is $d =\sqrt {r(r-2p)}$. I could not get any idea to solve. However I have tried to make a figure (partially).,"['circles', 'triangles', 'geometry']"
2212798,Complex limit of an exponential.,"For which values of $\arg(z)=k$ for $z\in\mathbb{C}$ does $$\lim_{z\rightarrow \infty}|e^z|$$ exist? Consider $k$ constant.
I don't have any idea on how to do this. Anyone can please help me?","['complex-analysis', 'complex-numbers']"
2212824,"If $a^3+a^2+a=9b^3+b^2+b$ and $a,b$ are integers then show $a-b$ is a perfect cube.","If $a^3+a^2+a=9b^3+b^2+b$ and $a,b$ are integers then show $a-b$ is a perfect cube. My attempt :I factorized it like below: $(a-b)(a^2+b^2+ab+a+b+1)=8b^3=(2b)^3$ I take $\gcd(a-b,a^2+b^2+ab+a+b+1)=d$ If $d=1$ then it is clear that $a-b$ is a perfect cube then consider $d>1$ then there is a $p$ that is prime and $p \mid d$ .We have : $p\mid a-b \Rightarrow p \mid (2b)^3 \Rightarrow p \mid 2b \Rightarrow p\mid 2$ or $p\mid b$ If $p\mid b$ then also $p\mid a$ (as $p\mid a-b$ holds). Then we will get to $p \mid 1$ because: $ p \mid a^2+b^2+ab+a+b,p \mid a^2+b^2+ab+a+b+1 \Rightarrow p \mid 1$ which is clearly wrong then we have $p\mid 2$ so $p=2$ means $d=2^k$ where $k$ is a natural number including $0$ .In the case $d=1$ we have the right result. So assemble $k \ge 1$ .Because $2 \mid a-b$ we can conclude that $a,b$ have the same parity @Ghartal showed in his answer that if $a,b$ are both even we have a right result but if $a,b$ are both odd we don't. So maybe we have to prove $a,b$ can't be both odd.","['number-theory', 'perfect-powers', 'gcd-and-lcm', 'elementary-number-theory']"
2212828,Prove that the determinant over $\mathbb F^{2\times 2}$ is a quadratic form,"I am working in the vector space $\mathbb F^{2\times 2}$, which denotes the space of $2\times 2$ matrices over the field $\mathbb F$ (the characteristic of $\mathbb F$ is not equal to $2$) and I would like to proof that: $\det:A\mapsto\det A$ is a quadratic form. Furthermore, I would like to show that $$\det(A+B) - \det(A) - \det(B) = tr(AB^\#)$$
whereas $tr$ denotes the trace of the matrix and $B^\#$ denotes the cofactor matrix of $B$. My definition of a quadratic form $q$ is that $q(cx) = c^2q(x)$ and that the map $$(x,y) \mapsto q(x+y)-q(x)-q(y)$$ is a bilinear form. I could easily prove the first criterion, but I am really stuck with the second. I also tried to first show the equality above (the trace equality), but for some reason, for matrices $$A= \begin{pmatrix} a & b\\c & d \end{pmatrix} \qquad B = \begin{pmatrix} w & x\\y & z 
\end{pmatrix}$$ the left side gives me $az+dw-by-cx$ and the right side leaves me with $az+dw-bx-cy$ I am pretty sure that I computed the determinants and the cofactor matrix correctly, so I am genuinely confused where my mistake lies and I also do not know how to prove the bilinear form criterion. Any help is greatly appreciated!","['matrices', 'quadratic-forms', 'linear-algebra']"
2212865,How come the Pauli Matrices are the generators of SU(2),"The special unitary group's elements fulfil the unitary condition, i.e. $aa^\dagger=1$, and have determinant 1 (special).
I have read, that the Pauli matrices generate SU(2).
Since all Pauli matrices have determinant -1, how can they generate the group, when they are not contained. I'm referring to the common representation
$\sigma_x=\begin{pmatrix}0&1\\1&0\end{pmatrix}$
$\sigma_y=\begin{pmatrix}0&-i\\i&0\end{pmatrix}$
$\sigma_z=\begin{pmatrix}1&0\\0&-1\end{pmatrix}$",['group-theory']
2212874,Strong Induction to find all possible combinations of two numbers,"Full disclosure, this is a homework question, so I'm only looking for hints not full solutions please. There is a store which offers two denominations of gift certificates, \$25 and \$40. Determine the possible total amounts that can be formed using the certificates, using strong induction to prove your answer. My first approach was to write out something like this, let $S$ be a possible amount where $S = 25a + 40b$ and $a, b \in \mathbb{Z}^+$ ($0$ being included in the positive integers). The problem is that I'm not sure how to use this as a propositional statement for strong induction. Second, I tried to make a table to find a pattern, like this:
$$
\begin{array}{c|ccccc}
0 & 0 & 1 & 2 & 3 & 4 \\
\hline
0 & 0 & 25 & 50 & 75 & 100 \\
1 & 40 & 65 & 90 & 115 & 140 \\
2 & 80 & 105 & 130 & 155 & 180 \\
3 & 120 & 145 & 170 & 195 & 220 \\
4 & 160 & 185 & 210 & 235 & 260 \\
\end{array}
$$ The issue with this approach was that, once again, I could see no particular path towards using strong induction (or any discernible pattern). I'm not sure how best to move forward, and I haven't been able to find many helpful resources. I'd be very grateful for some help, thanks!","['induction', 'discrete-mathematics']"
2212878,$\displaystyle \lim_{x \to 0+} \frac{d^k}{dx^k} \sqrt[x]{x}$ for all $k \in \mathbb{N}$ and $x>0$,"I managed to show with de L'Hospital that $$\lim_{x \to 0+}  \sqrt[x]{x} = 0.$$ I calculated the first two derivatives and realised that it is getting more and more complicated due to the product rule and powers of logarithms to show that the limit 
$$\lim_{x \to 0+} \frac{d^k}{dx^k} \sqrt[x]{x} = 0$$ which some plots that I made are indicating. I also thought about using 
$$\lim_{x \to 0+}  \exp\left(-{\frac{1}{x}}\right)^{\ln(x)}$$
because inductively the limits of $\exp\left(- \frac{1}{x} \right)$ are a lot easier to calculate, though I didn't come up with a general formula and don't know how to use it properly with the given problem above. A result that might be helpful, that I could proof, was that for all $\alpha >0$ it follows that
$$ \lim_{x \to 0+}  x^{\alpha} \, \ln(x) = 0.$$ Could you offer me any hints how to get to the desired result by induction? Is there an easy way to exchange the limit with the derivative? Ideas so far: Let's restrict ourself to the compact intervall $[0,1]$. $f$ being a realvalued continous and bounded function defined on $(0,1]$ is uniform continous iff $f$ is can be continously extended on $[0,1]$. As this is valid for $k=0$, we exchange the first derivative with the limit and get that $\lim_{x \to 0+} (x^{\frac{1}{x}}) ' = 0$. As $(x^{\frac{1}{x}}) '$ is bounded, we can repeat the argument inductively. The first two derivates are: $$(x^{\frac{1}{x}}) ' = \exp \left( \tfrac{\ln(x)}{x} \right)\,\left( \frac{1-\ln(x)}{x^2} \right) = \sqrt[x]{x}\,\left( \frac{1-\ln(x)}{x^2} \right)$$
$$ (x^{\frac{1}{x}}) ''  =  \sqrt[x]{x} \, \left( \ln^2(x) - 3\,x + 2\, (x-1)\, \ln(x) + 1  \right) \, \frac{1}{x^4} $$","['radicals', 'real-analysis', 'calculus', 'limits']"
2212884,Solve $x'\cos^2t+x\ln{x}=x\sin{t}\cdot te^{\tan t}$,"Solve $$x'\cos^2t+x\ln{x}=x\sin{t}\cdot te^{\tan t}$$ Hint is to find and use substitution $u(x)=\dots$ I try $u=\ln x$, then $x=e^u, x'=e^uu'$ And we obtain: $$u'+\frac{u}{\cos^2t}=\frac{\sin t}{\cos^2t}te^{\tan t}$$ So first we solve corresponding homogeneous equation and obtain $u=c\cdot e^{-\tan t}$. We assume that $c=c(t)$ and put it into inhomogeneous equation. The problem is that now we need to solve integral $$c=\int\frac{\sin t}{\cos^2t}te^{2\tan t}$$ and I do not know if it is even solvable. It would be easier if our equation to solve was $$x'\cos^2t+x\ln{x}=x\sin{t}\cdot te^{-\tan t}$$. But it isn't. So I do not know how to proceed.",['ordinary-differential-equations']
2212926,MMSE estimation: Unable to verify property of MMSE,"$\newcommand{\Var}{\operatorname{Var}}$I am trying to verify,using code, property of MMSE estimator. If $X_M=E[X\mid Y]$ is unbiased estimator of $X$, property I want to verify is $$\Var(X) = \Var(X_M) + \Var(\tilde{X})$$ where $\tilde{X}$ is the error in estimation. I am quoting from THIS online resource. Please tell me where I am wrong. I am writing code in octave. For matlab, equivalent function to randsample is datasample . Say X, Y have joint distribution. 
I computed PDF for X and PDF for E(X|Y) Joint PDF of X and Y X|Y  -1    0   1
2    1/6  2/6  0
3    2/6   0   0
4     0    0  1/6 PDF of X 1/2   2/6   1/6
  X  2     3     4 PDF of Z=E(X|Y) 2/6   1/2   1/6
Z=E[X/Y]  2    8/3    4 CODE nSamples = 100000;

RX = [2 3 4];
PrX = [1/2 2/6 1/6];
X = randsample(RX,nSamples,true,PrX);

RZ = [2 8/3 4];
PrZ = [2/6 1/2 1/6];
Z = randsample(RZ,nSamples,true,PrZ);

Xtilde = X - Z;
disp(var(X))
disp(var(Z))
disp(var(Xtilde))","['statistics', 'probability', 'statistical-inference']"
2212929,How to solve $(y''')^3-xy'''+y''=0$,"I have no idea how to solve this example: $$(y''')^3-x\cdot y'''+y''=0$$ This ODE is third order, but, what to do with the power: $^3$??? Thanks in advance!",['ordinary-differential-equations']
2212955,Probability of $12$ different dices containing at least one $5$ and at least one $4$?,A set of $12 $ different standard dices ($6$ sufaces with numbers $1$ to $6$) is thrown. What is the probability if it contains at least one $5$ and at least one $4$? My think that I have to choose the $2$ already known numbers $5$ and $4$ and multiply it by the rest of the possible results $6^{10}$. Finally dividing by all possibilities gives: $\frac{\binom{12}{2} \cdot6^{10}}{6^{12}}= 1.833333$ which does not make sense. The correct answer should be $0.7834$. I would like to understand the way how I can solve that task with combinatorics.  I also appreciate other solutions.,"['stochastic-processes', 'combinatorics', 'discrete-mathematics']"
2212997,Geometric fibers $\mathbb P^n$ + Vanishing of Brauer group implies projective bundle,"Let $\pi: X\to Y$ be a projective flat morphism over a Noetherian integral scheme all of whose geometric fibers are isomorphic to $\mathbb P^n$ over the geometric point. If there is a line bundle $\mathscr L$ that restricts to $\mathscr O(1)$ on the geometric fibers, then one can show that $\pi$ is a projective bundle (Exercise 28.1.L in Vakil's notes). He then has a remark that you don't need the existence of such a line bundle if you assume that $Y$ is a smooth curve over an algebraically closed field by Tsen' Theorem. I assume the real meat of this remark is saying that when the generic fiber of $Y$ has trivial Brauer group, then $\pi$ is a projective bundle. This makes some sense since the Brauer group classifies $\mathbb P^n$ torsors in some sense. Nevertheless, I don't quite see how to prove the remark. To be completely clear, let me state the theorem I am looking for: Question: Let $\pi: X\to Y$ be a projective flat morphism over a Noetherian integral scheme all of whose geometric fibers are isomorphic to $\mathbb P^n$ over the geometric point. Assume furthermore that the generic point of $Y$ has trivial Brauer group. Then, is $\pi$ a projective bundle - ie, is there a vector bundle $\mathcal E$ over $Y$ such that $X \cong \operatorname{Proj}(\operatorname{Sym}(\mathcal E))$? Perhaps this is not true - in that case, I would still be interested in a proof when $Y$ is a smooth curve over an algebraically closed field.","['brauer-group', 'projective-schemes', 'algebraic-geometry']"
2213101,$\int_0^1 \log(x) dx = -1$ but lower Riemann sum is $-\infty$?,"Consider $\int_0^1 \log(x) dx = -1$, where the answer $1$ was obtained by using the fundamental theorem of calculus - taking the antiderivative of $\log(x)$ and then evaluating at the endpoints. But $\log (x)$ is an unbounded function on the interval $[0,1]$ so the lower Riemann sum will be $-\infty$ and hence the integral doesn't even exist. So does mean that whenever we are using the fundamental theorem of calculus we are making the assumption that we are dealing with Lebesgue integration instead of Riemann integration?","['integration', 'lebesgue-integral', 'calculus', 'riemann-integration']"
2213109,"Prove that $\int_{0}^{1}\sin{(\pi x)}x^x(1-x)^{1-x}\,dx =\frac{\pi e}{24} $","I've found here the following integral. $$I = \int_{0}^{1}\sin{(\pi (1-x))}x^x(1-x)^{1-x}\,dx=\int_{0}^{1}\sin{(\pi x)}x^x(1-x)^{1-x}\,dx=\frac{\pi e}{24}$$ I've never seen it before and I also didn't find the evaluation on math.se. How could we verify it? If it is a well-known integral, then could you give a reference?","['integration', 'definite-integrals', 'calculus', 'closed-form']"
2213116,Notation for sections of sheaves,"Let $X$ be a topological space, and let $\mathcal{F}$ be a (pre-)sheaf of sets (groups, rings, etc.) on $X$. It seems to me that several authors in algebraic geometry prefer to use the global section functor $\Gamma$ to express the set (resp. group, ring, etc.) of sections $\mathcal{F}(U)$ as $\Gamma(U,\mathcal{F})$, for an open subset $U$ in $X$. For instance, see the fifth line in this Tag on the Stacks Project. Is there a good reason to prefer the expression $\Gamma(U,\mathcal{F})$ to $\mathcal{F}(U)$, apart from emphasising being contravariant in $U$ and  covariant in $\mathcal{F}$?","['notation', 'sheaf-theory', 'soft-question', 'algebraic-geometry']"
2213128,"Calculate the integral $\int e^{\sin x}\,dx$","I found this exercise in a book so it probably has an elementary solution.
I didn't succed but I hope maybe someone here will solve it. $$\int e^{\sin x}\,dx$$","['substitution', 'exponential-function', 'calculus', 'indefinite-integrals', 'integration']"
2213161,Properties of inverse Matrices,Is it possible for $A^3$ to be an Identity matrix without A being invertibe? If I do the following would it be correct: $A$.$A^2$= I Therefore A has to be invertible,"['matrices', 'linear-algebra', 'inverse']"
2213165,Find shortest distance between lines in 3D,Find shortest distance between lines given by $$\frac{x-2}{3}=\frac{y-6}{4}=\frac{z+9}{-4}$$ and $$\frac{x+1}{2}=\frac{y+2}{-6}=\frac{z-3}{1}$$ Is there any shortcut method for this problems?,"['3d', 'vectors', 'geometry']"
2213248,"Die fixed so it can't roll the same number twice in a row, using markov chains?","Studying for probability test and the following question came up: A six sided die is 'fixed' so that it cannot roll the same number twice consecutively. The other 5 sides each show up with a probability $\frac{1}{5}$. Calculate P($X_{n+1} = 5 \mid X_1 = 5$) and P($X_{n+1} = 1 \mid X_1 = 5$) What happens as $n \rightarrow$ $\infty$? It appears to be a markov chain problem but all I can think to do is to find the eigenvalues of the transition matrix. This seems unfeasible given that it's 6x6. 
My guess for the second part is that the probability tends to 1/6, as the first value becomes less and less relevant.","['markov-chains', 'probability']"
