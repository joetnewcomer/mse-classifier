question_id,title,body,tags
1379530,Helicity is Conserved,"In fluid mechanics, the helicity is defined as 
$$\int_{R^3} u(x,t)\cdot \omega(x,t),$$
where $u(x,t)$ is a smooth solution of the Euler equations
$$\partial_tu + (u \cdot \nabla) u = -\nabla p$$ $$\nabla \cdot u = 0,$$ 
and $\omega$ is the vorticity $\omega = \nabla \times u$.  We need to show that helicity is a conserved quantity. What I tried to do:  We also have the Euler equations in vorticity form $$\partial_t \omega + ((u\cdot \nabla )\omega) = (\omega \cdot \nabla)u.$$ So, if we write in component form, and then multiply the first equation by $\omega_j$, the second equation by $u_j$, and then sum over $j$, the left hand side has a term $\frac{d}{dt}\int_{R^3} (u \cdot \omega)$, which is what we are trying to show is $0$.  But then the rest of the terms don't seem to cancel (I would also think some sort of integration by parts should help here). Is there a different approach that you suggest works?","['calculus', 'fluid-dynamics']"
1379535,Using Ito theory to decide whether $M^f$ is martingale or a local martingale,"I came across the following while reading Ikeda & Watanabe book Stochastic differential equations and Diffusion processes , in page 163-164 At first the sentence 
$$f(X_t)- f(X_0) - \int_0^t Af(s,X)\, ds \in \mathcal{M}^{c,loc}_2 $$
seems strange, since $f \in C^2_b$ implies that $f, \partial_i f, \partial_i \partial_j f $  are bounded functions, so in principle the local martingale must be bounded (for each $t$) wich gives us that it is a true martingale and we should have
$$f(X_t)- f(X_0) - \int_0^t Af(s,X)\, ds \in \mathcal{M}^{c}_2 $$ But then, on second thought, we don't know if the terms $\alpha^i_k(s,X)$ are bounded so we must recognize that the first sentence was true. Now when we move to  the other expression, we read that (after correcting some typos)
$$M^{(l)}_i(t) = X^i(t\wedge \sigma_l) - X^i(0) - \int_0^{t \wedge \sigma_l} \beta^i(s,X)\, ds \in \mathcal{M}^c_2$$ But the only thing we know is that $X_{s \wedge \sigma_l}$  is on a bounded set, the functions $\alpha^i_k(s,X), \beta^i(s,X)$ might still be unbounded. So it seems that 
$$M^{(l)}_i(t) = X^i(t\wedge \sigma_l) - X^i(0) - \int_0^{t \wedge \sigma_l} \beta^i(s,X)\, ds \in \mathcal{M}^{c,loc}_2$$ What is going wrong?","['martingales', 'stochastic-integrals', 'stochastic-differential-equations', 'probability']"
1379536,Laplace Transform of a Heaviside function,"Find the Laplace transform. $$g(t)= (t-1) u_1(t) - 2(t-2) u_2(t) + (t-3) u_3(t)$$ I understand that the $\mathcal{L}\{u_c(t) f(t-c)\} = e^{-cs}*F(s)$ Finding $F(s)$ is the hard part for me. My professor has used, for example, 
$$f(t-2)=t^2$$
let $$s = t-2$$
$$t= s+2$$
$$f(s) = (s+2)^2$$
therefore $f(t) = (t+2)^2$ But then he said that $f(t-2) = 1$ therefore $f(t) = 1$. But why/how? By the previous logic if you let $s = t-2$ then $t= s+2$, and $f(s) = s+2$, so $f(t) = t+2$ not $1$. I'm having a tough time figuring this out.","['laplace-transform', 'ordinary-differential-equations']"
1379537,Is a space compact iff it is closed as a subspace of any other space?,"I am trying to come up with an alternate definition of a compact topological space that coincides with the usual one. Sorry if my topology is a little rusty. My proposed alternative definition is this. Let's say you have a space $X$. Then for any space $Y$, such that $X$ is a subspace of $Y$, then $X$ is closed in the topology $Y$. This seems to work. If you take $\mathbb N$, you can take the topology $\mathbb N^*=\mathbb N \cup {\infty}$, and then $\mathbb N$ is not closed in $\mathbb N^*$. On the other hand, $[0, 1]$ contains all its limit points, and should be closed in any topology (where the interval has its regular topology.) Is this equivalent to the open-cover definition of compact set? Has a similar definition been considered before (probably better than mine)?","['definition', 'general-topology', 'compactness']"
1379582,Prove that the given condition implies analytic continuation,"Here is an old qual problem I'm working on, I have some idea, but I'm not sure if I'm correct or not. I would be happy if anyone could possibly confirm or correct me: Let $U=\{z\in \mathbb{C} : \frac{1}{2}<|z|<2\}$. Suppose $f:U\rightarrow \mathbb{C}$ is holomorphic. Suppose that for every $n$, there is a holomorphic $g_n:U\rightarrow \mathbb{C}$ with $f(z)=(\frac{d}{dz})^n g_n(z)$, for all $z\in U$. Show that $f$ extends to a holomorphic function $\{z:|z|<2\}\rightarrow \mathbb{C}$. Yes, my idea was as follows: We know that we can write the Laurent series. Let's say the Laurent series is $\sum_{-\infty}^{\infty} a_n z^n$. I tried to show that $a_n=0$ for all $n<0$. I considered, for example, $a_{-1}$. Assume it's non-zero. But, we know that $f(z)=g_1'(z)$ on $U$ for some $g_1$, which is analytic on $U$. So, these two functions ($f$ and $g_1'$) will also have same Laurent series, by the uniqueness. But, we cannot get any term like $\frac{1}{z}$ by differentiating the Laurent series of $g_1$, which I thought shows that $a_{-1}=0$. Doing the same thing for higher order derivatives repeatedly, I thought I get the result. Is this correct, or do I have some fatal mistake? My doubt is that I haven't used the number $\frac{1}{2}$ in the problem at all, so it doesn't have anything special maybe? Thanks a lot in advance!","['analytic-continuation', 'proof-verification', 'complex-analysis']"
1379583,Why is $\zeta(1+it) \neq 0$ equivalent to the prime number theorem?,"Reading through Titchmarsh's book on the Riemann zeta function , chapter 3 discusses the Prime Number Theorem.  One way to prove this result is to check the zeta function has no zeros on the line $z = 1 + it,$ $$ \zeta(1 + it) \neq 0$$ Indeed the book has $3$ or $4$ proofs of this result.  Actually connecting it to the prime number theorem is another matter.  One version of the Prime Number Theoriem is: $$  \sum_{n \leq x} \Lambda (n) = x + o(x)$$ involving the van Mangoldt function, but why is this equivalent to the non-vanishing of the Riemann zeta function.  I think you can start from Perron's theorem $$ \frac{1}{2\pi i}\int_{1-iT}^{1+iT} \frac{\zeta'(w)}{\zeta(w)} \, \frac{x^w}{w}dw = \sum_{n \leq x} \Lambda (n) $$ and then I don't know how to proceed.","['number-theory', 'riemann-zeta', 'analytic-number-theory', 'contour-integration', 'complex-analysis']"
1379635,Can someone present a visualization of the partitioning of a $L^p$ space into equivalent classes?,"I am a bit confused by what it means for a $L^p$ space to be partitioned into equivalent classes instead of functions. I understand that give two or more functions $f$, $g$, $h,\ldots$ of which are ""almost equal"" i.e. differs on finite points, then the Lebesgue integral of these functions are identical and $f,g,h$ forms an equivalence class based on the relation ""almost equal"" But can someone please sketch a simple picture as to what this partitioning actually look like? For example. What would be the entire pink blob called? What would be each of the partition be called? What are elements within each partition? Thanks!","['elementary-set-theory', 'equivalence-relations', 'set-partition', 'relations', 'lebesgue-integral']"
1379647,"There exists a bijection between $(0,1)$, $(0,1]$ and $[0,1]$? [duplicate]","This question already has answers here : How to define a bijection between $(0,1)$ and $(0,1]$? (9 answers) Closed 8 years ago . There exists a bijection between $(0,1)$, $(0,1]$ and $[0,1]$? These 3 sets are not countable and since there are all in $\mathbb{R}$ they should have the same number of elements, so my question which are those bijective functions? I've been thinking, but I cannot find of any.",['elementary-set-theory']
1379652,Estimates for parabolic vs elliptic PDE,"Elliptic and parabolic PDE share many properties.  They each, for example, have an associated maximum principle and their value at any point depends on the entirety of the boundary data. I have been told that estimates for solutions to parabolic PDE typically mirror those for elliptic PDE, but are also more difficult to prove.  Since an elliptic PDE can be thought of as the steady state solution to a parabolic PDE, I am tempted to think of parabolic results as more general. My question: Is there some common method used to get results for elliptic PDE from results for parabolic PDE? My first guess would be to take $t\rightarrow \infty$ of a solution and, provided you have convergence in some appropriate sense, you get a solution to the associated steady-state problem.  However, I haven't found any source that does this.","['elliptic-equations', 'analysis', 'partial-differential-equations']"
1379719,why does the reduced row echelon form have the same null space as the original matrix?,What is the proof for this and the intuitive explanation for why the reduced row echelon form have the same null space as the original matrix?,"['linear-algebra', 'matrices']"
1379732,How are the pseudo-Riemannian metric tensor properties restricted by the manifold topology in pseudo-Riemannian manifolds?,"My understanding is that a pseudo-Riemannian metric tensor induces a topology that is not compatible with the manifold topology, and obviously the manifold topology prevails if we are to have a manifold like in this case. But then it is hard not to wonder how a pseudo-Riemannian manifold, generalization of Riemannian manifolds, departs from the latter. I mean they are formally distinguished by the different metric tensor structure (indefinite vs definite positive) on top of the smooth manifold, but if the pseudo-Riemannian metric tensor is restricted by the base manifold topology to the space metric properties of a Riemannian metric I can only see left as difference between Riemannian and pseudo-Riemannian manifolds those referred locally to a manifold point's tangent space. But even there the manifold topology makes some restrictions AFAICS. Timelike or spacelike vectors at a point are allowed but no nonzero null vectors, and therefore no light-cone structure, if we are to go strictly by the $\Bbb R^4$ topology. 
I have read the wikipedia article on spacetime topology that refers to Zeeman and Hawking topologies, but those are not manifold topologies (they are not locally compact, nor metrizable), the other topologies mentioned there are equivalent to the manifold topology.
Am I missing something here or is the above basically correct? [Edit: The next two paragraphs centered on Minkowski space are easily answered just by considering it an affine space rather than a smooth manifold] To be more specific when Zeeman writes in his paper of 1967 in Topology Vol. 6, 161-170 'The topology of Minkowski space': ""LET M denote Minkowski space, the real 4-dimensional space-time continuum of special relativity. It is customary to think of M as having the topology of real 4-dimensional Euclidean space, although there are reasons why this is wrong. In particular:The 4-dimensional Euclidean topology is locally homogeneous, whereas M is not; every point has associated with it a light cone separating space vectors from time vectors."" Does this mean that the Euclidean topology, wich happens to be the same as the manifold topology, is incompatible with light cones, and if so how is Minkowski 4 dimensional manifold different from Euclidean 4-space, other than for the curvature invariant of the immersed hyperboloid preserved by the local isometry that gives rise to the indefinite form in 4 dimensions to begin with?","['differential-geometry', 'quadratic-forms', 'general-topology', 'semi-riemannian-geometry']"
1379735,Exercise 6.5.F in Ravi Vakil's notes: Showing conic $x^2 + y^2=z^2$ in $\mathbb{P}_k^2$ is isomorphic to $\mathbb{P}_k^1$,"I have been stuck on Exercise 6.5.F in Ravi Vakil's notes for a little while now, and I would greatly appreciate any hints/comments/solutions! Let $k$ be a field that is not of characteristic $2$. I want to show that conic $x^2 + y^2=z^2$ in $\mathbb{P}_k^2 = Proj \ k[x,y,z]$ is isomorphic to $\mathbb{P}_k^1 = Proj \ k[u,v]$.","['algebraic-geometry', 'projective-schemes']"
1379745,Is there a holomorphic function $f$ on the unit disc such that $|f(z)|\rightarrow\infty$ as $|z|\rightarrow 1$?,"When I learnt that there exists a holomorphic function on the unit disc $D$ that cannot be continuously extended to a domain that is strictly larger $D$, I was taught the example $$z\mapsto\sum_{n=1}^\infty z^{n!}.$$ The reason why this function cannot be continuously extended is for at any root of unity $\xi$, there is a sequence in $D$ that converges to $\xi$ whose function values go to infinity and the roots of unity are dense on $\partial D$. This lead me to thinking that there should not be a holomorphic function $f$ on the unit disc such that $|f(z)|\rightarrow\infty$ as $|z|\rightarrow 1$, for otherwise such an $f$ would clearly be a holomorphic function on $D$ that cannot be continuously extended, and why bother with the above series? So I tried to prove that there is not a holomorphic function $f$ on the unit disc such that $|f(z)|\rightarrow\infty$ as $|z|\rightarrow 1$, but could not get anywhere. Can anyone prove this assertion? Or is it false? Many thanks!","['analytic-continuation', 'complex-analysis']"
1379758,"On every simply connected domain, there exists a holomorphic function with no analytic continuation.","I am working on a question that requires me to prove that on every simply connected open subset of $\mathbb{C}$, there exists a holomorphic function that cannot be extended to a holomorphic function on a larger connected open set. I know an example of such a holomorphic function on the open unit disc: $$f:z\mapsto\sum_{n=1}^\infty z^{n!}.$$ I tried to combine this with the Riemann mapping theorem. Let $\Omega$ be a simply connected open subset of $\mathbb{C}$ and one may assume that $\Omega$ is not the entire complex plane. By the Riemann mapping theorem, there exists a conformal equivalence $$\phi:\Omega\rightarrow D$$where $D$ is the open unit disc. Then my guess is that $f\circ\phi$ has no analytic continuation, but then I had to link the boundaries of $\Omega$ and of $D$ and I don't know what is going on between $\partial\Omega$ and $\partial D$. Could anyone offer any idea? Many thanks!","['analytic-continuation', 'complex-analysis']"
1379762,Asymptotic of Inverse Function,"Suppose we choose a positive constant $c$ and let $f_c(x)=\frac12x^2+cx^{3/2}$. I would like to get an asymptotic estimate for the function $f_c^{-1}(x)$ as $x\rightarrow\infty$. I assume it will be something of the form $f_c^{-1}(x)=\sqrt{2x}+O(g_c(x))$ for some function $g_c(x)$ of order less than $\sqrt x$, but I'm not sure how to get a nice estimate for $g_c(x)$.","['asymptotics', 'real-analysis', 'functions']"
1379764,Is there a deep reason why replacing $\cos(x)$ with $e^{ix}$ and taking the real part often makes a contour integral work out?,"I'm grading a complex analysis course right now and it turns out to involve a lot of contour integration.  For instance, students are asked to find the integral $$\int_0^\infty \frac{\cos (ax)}{(x^2 + b^2)^2} \, dx$$ where $a, b > 0$ are real parameters.  This can be done as follows: \begin{align}
\int_0^\infty \frac{\cos (ax)}{(x^2 + b^2)^2} \, dx
& = \frac{1}{2} \int_{-\infty}^\infty \frac{\cos (ax)}{(x^2 + b^2)^2} \, dx \\ \\
&= \frac{1}{2} \operatorname{Re} \left[\int_{-\infty}^\infty \frac{e^{iax}}{(x^2 + b^2)^2} \, dx\right] \\ \\
&= \frac{1}{2} \operatorname{Re} \left[\lim_{R \to \infty} \int_{-R}^R \frac{e^{iax}}{(x^2 + b^2)^2} \, dx\right].
\end{align} Now $$\int_{-R}^R \frac{e^{iax} \, dx}{(x^2 + b^2)^2} = \oint_{L_R+C_R} \frac{e^{iaz}\, dz}{(z^2 + b^2)^2} - \oint_{C_R} \frac{e^{iaz} \, dz}{(z^2 + b^2)^2}$$ where $L_R$ is the line segment going from $-R$ to $R$ and $C_R$ is the circular arc with center 0 going from $R$ to $-R$. By the residue theorem,
$$\oint_{L_R+C_R} \frac{e^{iaz}\, dz}{(z^2 + b^2)^2} = 2 \pi i \operatorname{res}_{z=bi} \left[\frac{e^{iaz}}{(z^2 + b^2)^2}\right] = \frac{\pi e^{-ab} (1 + ab)}{2 b^3}$$
for $R > b$.  Further, by Jordan's lemma
\begin{align}
\left|\left|\oint_{C_R} \frac{e^{iaz} \, dz}{(z^2 + b^2)^2}\right|\right|
&\leq \frac{\pi}{a} \max_{z \in C_r} \left|\left|\frac{1}{(z^2 + b^2)^2}\right|\right| = \frac{\pi}{a(R^2 + b^2)^2} \to 0
\end{align}
as $R \to 0$, from which we see that
$$\int_0^\infty \frac{\cos (ax)}{(x^2 + b^2)^2} \, dx = \frac{\pi e^{-ab} (1 + ab)}{4 b^3}.$$ Suppose, however, that instead of writing $\cos(a x)$ as $\operatorname{Re}[e^{i x}]$ and pulling the $\operatorname{Re}$ outside the integral we'd tried to do things the same way directly.  The problem in this case is that the integral
$$\oint_{C_R} \frac{\cos(az)}{(z^2 + b^2)^2}$$ doesn't vanish as $R \to \infty$.  By adding an extra term to our equation, though, we managed to make things work out quite nicely. If I try to distill the general technique here, it's something like this: We had a function $f(z)$ for which 
$$\lim_{R \to \infty} \oint_{C_R} f(z) \, dz$$
didn't vanish, so we found a function $g(z)$ which vanished along $L_R$ and for which
$$\lim_{R \to \infty} \oint_{C_R} f(z) + g(z) \, dz$$
vanished.  However, it seems incredibly fortuitous that we had such a readily available choice for $g$.  Is this just a consequence of picking a homework problem that can actually be done with pencil in paper in a reasonable amount of time?  Or is something deeper going on? Specific questions: Given a function $f$, is there any nice way of rephrasing the condition that
$$\oint_{C_R} f(z)\, dz \to 0 \text{ as } R \to \infty$$ as a more straightforward property of $f$?  (At first I wondered if $C_R$ was ""a closed curve around $\infty$ in the limit"" but this doesn't seem to be right.) Given a meromorphic function $f$ such that $$\oint_{C_R} f(z)\, dz \not \to 0 \text{ as } R \to \infty,$$ can we always find a meromorphic function $g$ such that $g|_\mathbb{R} = 0$ and $$\lim_{R \to \infty} \oint_{C_R} f(z) + g(z) =0?$$ If not, are there any nice constraints on $f$ that make it possible?  If so, how many such $g$ are there, and can we construct one of them easily? Same questions as above with $L_R$ and $C_R$ replaced by more general curves.","['contour-integration', 'complex-analysis']"
1379805,Intriguing Poisson sum with hyperbolic function,"I've been playing with lots of Poisson sums lately, and I thought this one to be interesting: $$\sum_{k\in\mathbb{Z}}\left(\frac{1}{(k+x)\sinh{(k+x)\pi q}}-\frac{1}{\pi q (k+x)^2}\right)$$I want to find a closed form for this sum and its derivatives over $x$ when $x=0$ and $q=1$. Since its poles are of the form $k+\frac{in}{q}\,(k,n\text { integers})$ with double-order poles at the integers, I figure its expression may include trigonometric and theta functions...but I can't figure anything beyond its singularities. Any help would be appreciated. I've managed to turn the sum into a Fourier series $\left(-4\sum_{k\ge 1}\ln(1+e^{-2k\pi / q})\cos{2k\pi x}\right)\quad\;$, but even with its simplicity, I haven't been able to crack it. (Edit) I think I have a way to evaluate the Fourier series: if I expand the cosines into Taylor series, then I just have to sum series of the form $$\sum_{k \ge 1}k^{2n}\ln(1+e^{-2k\pi/q})$$ which I can rewrite as $$\sum_{m\ge 1}\frac{(-1)^{m-1}}m\sum_{k\ge 1}k^{2n}e^{-2km\pi/q}$$and since $\displaystyle{\sum_{k\ge 1}e^{-2km\pi/q}=\frac1{e^{2m\pi/q}-1}}$, $\displaystyle{\sum_{k\ge 1}k^2e^{-2km\pi/q}=\frac14\frac{\cosh{\frac{m\pi}q}}{\sinh^3{\frac{m\pi}q}}}$ and subsequent sums consist of a hyperbolic cosine times an odd reciprocal polynomial in the hyperbolic sine, I've reduced my problem to evaluating sums of the form $$\sum_{m \ge 1}\frac{(-1)^{m-1}}m \frac{\cosh{\frac{m\pi}q}}{\sinh^{2n+1}{\frac{m\pi}q}}$$which is also $\displaystyle{\int{\sum_{k\ge 1}\frac{(-1)^{k-1}\sinh{kz}}{\sinh^{2n+1}{\frac{k\pi}q}}\, dz}}$ with $z=\frac{i\pi}q$. But here I am stuck.","['closed-form', 'fourier-series', 'sequences-and-series', 'hyperbolic-functions']"
1379823,Find all entire function $f$ such that $\lim_{z\to \infty}\left|\frac{f(z)}{z}\right|=0$,"If $f$ is an entire function such that $\lim_{z\to \infty}\left|\frac{f(z)}{z}\right|=0$ then find the function $f$. Replacing $z$ by $\frac{1}{z}$, we get $$\lim_{z\to 0}|zf(1/z)|=0$$This shows that $f(1/z)$ has removable singularity at $z=0$ , so $f(z)$ has removable singularity at $z=\infty$. As $f$ is entire so , $f$ must be constant . Is it correct?",['complex-analysis']
1379864,Is it possible to solve sudoku without backtracking?,"I occasionally solve sudoku puzzles on smartphone in spare time. My approach is based on the belief that at each stage in solving a sudoku puzzle there is at least one cell where there in only one choice of digit which satisfies all the constraints . And then I proceed to find one such cell and fill it with the suitable unique digit. This way the problem looks deterministic. Some other approaches use backtracking. This is typically used when you have a cell which has two choices of digits based on current data and you put one of the choices in the cell and after sometime if you discover any contradiction, you backtrack and fill the cell with other choice. If there is a sudoku puzzle with unique solution then can it be shown that there is at least one cell at each stage of the puzzle which has only one choice of the digit without using any backtracking? In other words will the following procedure work? Start with any empty cell. Eliminate the digits which are not suitable for that cell by looking in the row, column and the smaller square to which the cell belongs. If there is only one digit which fits this cell then fill it with that digit. If there are multiple options move to another cell and repeat the same logic. It is guaranteed that you will have one cell with only one choice of suitable digit. This way fill all the empty cells. I have highlighted the word eliminate in last paragraph because sometimes the elimination of digits gets tricky. One common scenario is that by various constraints you can fix two digits of a row (column) into one of the sub-squares and thereby these are eliminated from the remaining part of the row (column). Note : Just to clarify the sudoku I am talking is the usual one based on 9x9 cells and uses digits 1 to 9.","['recreational-mathematics', 'combinatorics']"
1379878,$C(M)=\{A\in M_n(\mathbb{C}) \mid AM=MA\}$ is a subspace of dimension at least $n$.,"Let $M_n(\mathbb{C})$ denote the vector space over $\mathbb{C}$ of all $n\times n$ complex matrices. Prove that if $M$ is a complex $n\times n$ matrix then $C(M)=\{A\in M_n(\mathbb{C}) \mid AM=MA\}$ is a subspace of dimension at least $n$. My Try: I proved that $C(M)$ is a subspace. But how can I show that it is of dimension at least $n$. No idea how to do it. I found similar questions posted in MSE but could not find a clear answer. So, please do not mark this as duplicate. Can somebody please help me how to find this? EDIT: Non of the given answers were clear to me. I would appreciate if somebody check my try below: If $J$ is a Jordan Canonical form of $A$, then they are similar. Similar matrices have same rank. $J$ has dimension at least $n$. So does $A$. Am I correct?","['vector-spaces', 'linear-algebra', 'matrices']"
1379888,Solving $y' + \frac{1}{2}xy + y^{2} = 0$,"I am trying to solve the ODE $$y' + \frac{1}{2}xy + y^{2} = 0.$$ Mathematica gives that the answer is $$y(x) = \frac{e^{-x^2/4}}{C + 2\int_{0}^{x/2}e^{-t^{2}}\, dt}.$$ Of course, if I take this answer and plug it into the ODE, I am able to get the answer, but how does one derive this solution from the ODE? If I multiply the ODE by $e^{x^{2}/4}$, then $$(e^{x^{2}/4}y)' = -e^{x^{2}/4}y^{2}$$ but then this gives $$e^{x^{2}/4}y = -\int_{0}^{x}e^{s^{2}/4}y(s)^{2}\, ds.$$ How does one get from here to the solution Mathematica gave me?","['calculus', 'ordinary-differential-equations']"
1379895,Are lightlike curves in the De Sitter space straight lines?,"I think that every lightlike curve in $\mathbb{S}_1^2 \subseteq \mathbb{L}^3$ must be a line. But I'm having trouble concluding it. Let $\alpha\colon I \subseteq \Bbb R \to \Bbb S^2_1 \subseteq \Bbb L^3$ be a lightlike curve. Then: $$\langle \alpha, \alpha \rangle = 1, \quad \langle \alpha', \alpha' \rangle = 0.$$From here, we obtain: $$\langle \alpha, \alpha' \rangle = 0, \quad \langle \alpha', \alpha '' \rangle = 0.$$So far all of this is trivial. Differentiating $\langle \alpha, \alpha'\rangle = 0$ we get: $$0 = \langle \alpha',\alpha'\rangle + \langle \alpha, \alpha''\rangle \implies \langle \alpha, \alpha''\rangle = 0.$$ Intuition says that $\alpha''$ is in the plane spanned by $\alpha$ and $\alpha'$ (since $\alpha''$ would point to the origin), so the above calculation would give that $\langle \alpha'',\alpha''\rangle = 0$, but I'm not sure of this. And even if this is true, it doesn't mean that $\alpha'' = 0$. Can someone help me or give a counter-example? This is a self-posed question, made after noticing that every line contained in $\mathbb{S}^2_1$ must be lightlike. I just wondered about the reciprocal. The Lorentz product is given by $\langle {\bf x},{\bf y}\rangle = x_1y_1+x_2y_2-z_1z_2$, and $\mathbb{S}^2_1$ is the set of all vectors $\bf v$ such that $\langle {\bf v},{\bf v}\rangle = 1$, in case I didn't make it clear before. Use whatever signature for $\langle \cdot,\cdot\rangle$ you want, though, it probably won't appear in the computations. The result seems to be true for $\Bbb L^n$ in general, if that's really the case.","['differential-geometry', 'curves', 'semi-riemannian-geometry']"
1379896,Can't Finish Double Integral in Polar or Cartesian,"Alright, so I'm stuck on what I think should be a simple double integral. It is $\int_0^1\int_{\sqrt x}^1e^{y^3} \, dy \, dx$. This is just the volume between the surface $z=e^{y^3}$ and the area bounded by $y=\sqrt x$ and $y=1$, $0\le x \le 1$. I could see pretty quickly that I can't integrate this, so I tried to switch the $dy$ with $dx$ and change limits. When I do that, though, I end up with $\int_0^1[y^2e^{y^3}] \, dy$, which I still can't integrate. So I try by converting to polar coordinates, and I get that $0\le\theta\le\frac{\pi}{2}$ and $\frac{2\cos\theta}{1-\cos 2\theta}\le r \le 1-\sin\theta$. That radius will be a major problem when I go to integrate, so I know I went wrong somewhere. Does someone see what I did wrong? Thanks in advance!",['multivariable-calculus']
1379915,Elements of $S_n$ which can not be product of $\leq n-2$ transpositions,"It is well known that every element of $S_n$ can be written as a product of at most $n-1$ transpositions. This theorem is proved in all the books which discuss the permutation groups. But, I find that the following natural question is usually neither discussed nor put in Exercise Section in the book. Question: Does there always exists an element in $S_n$ which can not be product of $\leq n-2$ transpositions? Can we list the cycle-type of such elements? The natural guess would be the $n$-cycles in $S_n$ would be the elements which answer the question. But I couldn't prove it . Can you help me? A hint would also be sufficient.","['group-theory', 'finite-groups', 'permutations']"
1379930,Hyperplane in a complex vector space,"My friend, who studies Physics, asked me about the meaning of ""functional"" so I gave the definition and some examples. To motivate its importance, I explained how a functional can be use to define a hyperplane without referring to a specific base of the space (A subset $H$ is a hyperplane iff there exists a non-trivial linear functional $x'$ and a scalar $c$ such that $x'(x) = c$ for all $x \in H$ ) and that it effectively divides the space into 3 parts e.g. $x'(x) < c$ , $x'(x) = c$ , and $x'(x) > c$ . I immediately notice that the argument works in real vector spaces but not the complex ones since complex numbers are not linearly ordered, thus the intuitive picture that hyperplanes ""divide space"" in the aforementioned sense seems to fail here. So, is there an intuitive way to visualize a complex hyperplane? For concreteness, you can assume that the space is a finite dimensional Hilbert space. Note that I am an undergraduate so I'd really appreciate some not too advanced answers (stuff like Hopf fibration would be considered too advanced for me, for example).","['intuition', 'linear-algebra', 'visualization', 'functional-analysis']"
1379949,"What is the group structure on the ring of power series around a point that makes it ""the completion of an elliptic curve"" along that point?","I've been struggling to understand the explicit details of the completion of an elliptic curve about the origin, and am desperately confused by the explicit details of the resulting group operation. My understanding of the completion of an elliptic curve is as follows. The goal is to get from algebraic group to complete topological (algebraic?) group. Begin with an (algebraic connected 1-dimensional( group $G$ over a commutative ring $R$, whose points are defined by, say, $f(x) = x^3 + ax + b$ (whose group operation is the group operation on $Pic(G)$). (Another perspective: If $A$ is an algebra over a ring $R$, that corresponds to a map $R \to A$, and dually that's a map, $\text{Spec }A \to \text{Spec }R$. In this sense, 'over R' just means 'with a map to Spec R' on the scheme side of things. An elliptic curve has charts $\text{Spec }R[X, Y]/(Y^2-X^3-aX-b)$, there's a natural map to $\text{Spec }R$ on each of these.) Pick a point $pt=(\alpha, \beta)$ on $G$. Edit: ""Change of coordinates"" is NOT a change of point on the formal group  (picking a different ""pt""), rather it is a different coordinate chart mapped onto the origin of the formal group. Expand $f(x)$ as a Taylor series around $(x-\alpha)$. $$f(x) = f(\alpha) + f'(x)(x-\alpha) + \frac{f'(x)}{2!}(x-\alpha)^2 + \frac{f''(x)}{3!}(x-\alpha)^3 + ... $$ Examine the ring of functions whose Taylor series (expanded about $(x-\alpha)$ agrees with the above series up to the nth term. Two functions are declared equal if their truncated Taylor series expanded around $(x-\alpha)$ are equal. This gives us equivalence classes of functions indexed by $n$, $[f(x)]_n$, aka the jet of $f$ at the point $pt$. Is this really a group? If $f_1(\alpha) = f_2(\alpha) = \beta^2$ on $(\alpha, \beta)$ then $f_1(\alpha)−f_2(\alpha)$ is zero on $(\alpha, \beta)$, or at least in the neighborhood of $(\alpha, \beta)$. We endow this collection of rings (of truncated Taylor series) $R[(x-\alpha)]$, $R[(x-\alpha)]/(x-a)^2 = 0$, $R[(x-\alpha)]/(x-a)^3 = 0$, etc. with the ($x-\alpha$)-adic topology : $$R[(x-\alpha)]/(x-\alpha = 0) \supset R[(x-\alpha)]/((x-\alpha)^2=0) \supset R[(x-\alpha)]/((x-\alpha)^3 = 0) \supset ...$$ A basis of open neighborhoods of this ring $R[(x-\alpha)]$ is given by the sets of the form $r + (x-\alpha)^n$, for $r \in R$. This gives us a complete topological group (or ring?). The underlying set of points will of course be the ordinary ring of power series around the point, but the group law must be different.  The completion doesn't seem to hold any of the structure of the elliptic curve at all! Here's my question: What is the group operation on the elliptic curve formal group? How does the additional law on the formal group relate to the addition law of elliptic integrals? Is it similar to the group law we define on the p-adics? How do the finite order points of the elliptic curve get involved with restricting our attention to the origin? I ask about the p-adics because if first few functions in the taylor series of two functions agree, than the functions are close, i.e., if they are divisible by large powers of $(x-p)$, then they are close. Edit: My general picture of how all of these vocabulary words fit together is as follows. I am not satisfied with this level of detail. I am trying to understand why we want to complete in the first place, and why the procedure of completion works.","['elliptic-curves', 'commutative-algebra', 'formal-groups', 'algebraic-geometry', 'localization']"
1379955,Converse of Chinese Remainder Theorem,"Chinese Remainder Theorem for commutative rings with identity Let $R$ be a commutative ring with identity. If $I, J$ are ideals of $R$ satisfying $I+J=R$, then there is an isomorphism of rings:
$$R/(I\cap J) \cong R/I \times R/J.$$ I am interested in the converse of this. I saw the following two cases: Converse V1 If we have positive integers $m, n$ with $(m,n)\neq 1$, then 
$$
\mathbb{Z}/mn\mathbb{Z} \not\cong \mathbb{Z}/m\mathbb{Z}\times\mathbb{Z}/n\mathbb{Z}.$$ This one is easy if we consider characteristics. Converse V2 Let $F$ be a field. If we have polynomials $f, g \in F[x]$ with $(f)+(g)\neq F[x]$, then 
$$
F[x]/(f(x)g(x))\not\cong F[x]/(f(x))\times F[x]/(g(x)).$$ This one is answered here . The idea is counting number of ideals of both sides. It is easy to see that if we have factorization of ideals into prime ideals (Dedekind Domain), the same idea applies. However, we have this example: Example If $R=\prod_{i=1}^{\infty} \mathbb{Z}$ and $I=J=(0)$, then $I+J\neq R$ and
$$
R/(I\cap J) \cong \prod_{i=1}^{\infty} \mathbb{Z} \cong \prod_{i=1}^{\infty} \mathbb{Z}\times \prod_{i=1}^{\infty} \mathbb{Z} \cong R/I\times R/J.$$ Thus, the converse of CRT does not hold in general for ""commutative ring with identity"". We have seen, however, the converse of CRT holds for ""Dedekind Domain"". My question is Quetion Do we have a commutative ring with identity which is not a ""Dedekind Domain"" such that the converse of CRT holds?","['abstract-algebra', 'chinese-remainder-theorem', 'ideals', 'ring-theory']"
1379963,FRACTRAN for natural numbers,"Is there a simple analogue of FRACTRAN that maps a natural number to a natural number, instead of mapping a list of fractions to a natural number? One could use Gödel encoding to translate FRACTRAN directly to natural numbers only, but such a construction would probably be contrived. Is there a more elegant alternative? I think a generalization of the Collatz function might be a candidate, but what is the simplest example of such a function that is Turing-complete? For example, it is undecideable whether functions of the form $$g(n)=a_in+b_i\qquad n\equiv i \pmod P$$ reach the number 1, for all $g$ and $n$, when iterated repeatedly.","['computer-science', 'number-theory', 'modular-arithmetic', 'sequences-and-series', 'computability']"
1379971,Some help on trigonometric equation,"So I have $\sin^3x = \frac 34 \sin x$. Can you expand so the answer is either $\sin x(\sin^2x +\frac 34)$ which leads to
 the answer $\frac 12 + 2n\pi$ or that $\sin^3x = \frac 14(3\sin x-\sin^3x) - \frac 34\sin x$ which leads to the answer $0 + 2n \pi$. Is that correct by any chance?",['trigonometry']
1380023,Topologies on the collection of $\sigma$-algebras,"Let $X$ be a non-empty set and let $\mathfrak S$ be the collection of all $\sigma$-algebras on $X$. That is, a typical element $\mathscr S\in\mathfrak S$ is a $\sigma$-algebra on $X$. For example, $\{\varnothing, X\}\in\mathfrak S$; if $A$ is a non-empty proper subset of $X$, then $\{\varnothing,A,A^{\mathsf c},X\}\in\mathfrak S$; and if $X$ is a topological space and $\mathscr B(X)$ is the Borel $\sigma$-algebra, then $\mathscr B(X)\in\mathfrak S$; and so forth. Question: Is there a “natural” way of endowing $\mathfrak S$ with a topology? Any reference or comment is greatly appreciated.","['reference-request', 'general-topology', 'measure-theory']"
1380031,How is $x \leq x^2$ false? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question There's an equation that says $$x \leq x^2$$ and $x \in \mathbb R$. What I can solve and clearly see is that this equation would be true for any value of '$x$' but then how come my maths teacher said that it can be false also? (he didn't explained why, probably because there were too many questions lined up). So, over to you guys. ;-)","['real-numbers', 'algebra-precalculus']"
1380077,Question on Egoroff-like theorem,"Hi all I was tackled by this question from Folland's real analysis second edition in the second chapter, it looks like a modified Egoroff theorem but I cannot really tackle it, it is question 41 of chapter 2 which reads as follows: Let $\mu$ be a $\sigma$-finite  measure and $ f_n \rightarrow f $ a.e. Then there exist measurable sets $E_1,E_2,\ldots \subset X $ such that 
  $$\mu\left(\left(\bigcup_{i=1}^\infty E_i\right)^C\right)=0$$ and $f_n \rightarrow f $ uniformly on each $ E_i. $ I think this might have something to do with Egoroff's theorem but that theorem mentions nothing about complement having measure zero, only as small as you would like, which is what confuses me. Can anyone point out a proof of this with an explanation?","['real-analysis', 'uniform-convergence', 'measure-theory']"
1380091,Combinatoric Birthday Paradox,"There is likely a closed form solution for this problem but it's had me puzzled for days. This is about a variant on the classic birthday paradox. To recap, the birthday paradox is where given only 23 students the probability that two have the same birthday is > 0.5. The variant is this: If each student has two (or K ) special days, what is the probability that given N students each student has at least one special day that is unique to them. I stumbled across this problem while working on a related cryptographic algorithm. Another way of phrasing this is in terms of a lottery: If a lottery drawing consists of 5 random numbers (with repetition) drawn from a set of 100 numbers, after N drawings what is the probability that each drawing had at least one unique number among it's 5. Explicitly, given these variables: $C = $ the size of the set of choices (e.g. 100 for the lottery or 365 for the special days) $K = $ # of random choices for each event (e.g. 5 for the lottery, 2 for the special days) $N = $ # of events that have taken place (e.g. lottery drawings, or number of students) Here is what I'm trying to solve for: $P(C, K, N) = $ the probability that after N events, where each draws K random items from a set of C items, each event has at least one item that was not drawn in any other event. Note that $P(C, 1, N)$ provides the solution to the classic birthday paradox. To be clear, repetition is allowed. That is, a student could have the same special day twice, or the lottery drawing could be (5, 5, 78, 10, 5). In that event, if at least one of those numbers was never seen before, it counts as unique. The best I've come up with is this: Given a function, $Q(C, K, N)$ that computes the probability that the $N^{th}$ event has at least one unique value: We would get these values in the student scenario: $$ Q(2, 365, 0) = 1 - \frac{0}{365}\frac{0}{365} = 1.00000 $$
$$ Q(2, 365, 1) = 1 - \frac{2}{365}\frac{2}{365} = 0.99996 $$
$$ Q(2, 365, 2) = 1 - \frac{4}{365}\frac{4}{365} = 0.99987 $$ And similarly for the lottery drawing: $$ Q(5, 100, 0) = 1 - \frac{0}{100}\frac{0}{100}   = 1.00000 $$
$$ Q(5, 100, 1) = 1 - \frac{5}{100}\frac{5}{100}   = 0.99999 $$
$$ Q(5, 100, 2) = 1 - \frac{10}{100}\frac{10}{100} = 0.99999 $$ This generalizes to: $$ Q(C, K, N) = 1 - (\frac{N * K}{C})^K $$ If $Q$ computes the probability of any given student having at least one unique day than the probability of N events all having at least one unique day is just multiplying all of the probabilities together: $$P(C, K, N) = \prod_{n=0}^N 1 - (\frac{n * K}{C})^{K}$$ This looks promising because for the case where $K = 1$, this simplifies to: $$\prod_{n=0}^N \frac{C - n}{C}$$ which is the formula for the traditional birthday paradox. The problem is that this proposed formula, beyond $K=1$, isn't actually correct, as verified by a monte-carlo simulation I've been running to compare it against. I can't seem to wrap my head around what the problem is though. I've tried about a dozen different ways to approach the problem. It seems that there may be no closed form solution, unfortunately.","['birthday', 'probability', 'combinatorics']"
1380121,Ideals of non semi-simple group rings.,"I worked for a long time on complex group rings and complex twisted group rings. In those cases the algebra is semi-simple and its structure is well understood from the decomposition to irreducible (projective in the twisted case) representations. For example $$\mathbb{C}S_3\cong \mathbb{C}\oplus \mathbb{C}\oplus M_2(\mathbb{C}).$$ Now I am trying to deal with a non-simple case in which the group is non-commutative (in the commutative case it is much easier). Now, I am stuck in the following example. Let 
$$G=C_7\rtimes C_3,$$
where the action of $C_3$ on $C_7$ is by sending its generator $\sigma$ to $\sigma ^4$. Describe (as best as you can) the ring structure of the group ring
$$\mathbb{F}_3G.$$ Here the group ring is not semi-simple. However, I am trying to find a maximal (length) chain of ideals $I_0,I_1,\ldots ,I_k$ such that
$$\{0\}=I_0\subseteq I_1 \subseteq I_2 \subseteq \ldots \subseteq I_k=\mathbb{F}_3G.$$ So far I made no progress. Thanks in advance for any help.","['abstract-algebra', 'group-theory', 'ring-theory']"
1380140,"Closed-form of $\int\limits_0^1\left(\frac{\left(x^2+1\right)\arcsin(x)}{\sqrt{1-x^2}}+2x\ln\left(x^2+1\right)\right)\frac{\ln x}{x^3+x}\,dx$","I've conjectured the following closed-form:
$$
I = \int\limits_0^1\left(\frac{\left(x^2+1\right)\arcsin(x)}{\sqrt{1-x^2}}+2x\ln\left(x^2+1\right)\right)\frac{\ln x}{x^3+x}\,dx = -2\,G\,\ln2,
$$
where $G$ is Catalan's constant .
Numerically
$$ I \approx -1.2697979381877088371491554851603117320986537271546606092465\dots$$
How to prove it?","['calculus', 'closed-form', 'definite-integrals', 'integration', 'polylogarithm']"
1380142,Order of statements in implication,"The question is from Exercise 13 of part 1.4 in Rosen's ""Discrete Mathematics and Its Applications"" (5th edition): ""let $M(x,y)$ be ""$x$ has sent y an e-mail message"", where the universe of discourse consists of all students in your class"". The sentence to be translated to predicate language is:
""g) there is a student in your class who has sent everyone else in your class an e-mail message"" My solution is: $$\exists x \ \forall y \ \ (M(x,y)\implies x \neq y) $$ The solution in the instructor's manual of Rosen's book has the statements of the implication in reverse: $$\exists x \ \ \forall y \ \ (x \neq y \implies M(x,y))$$ Which one is correct? To me it seems that the solutions manual is incorrect. The solution from the manual is true if the antecedent is F and the consequent T, which would mean that if the student is himself/herself, then he/she has sent himself/herself an e-mail message, so it seems to be wrong in my mind because the original idea was to exclude sending messages to oneself. The first solution allows x to send y an e-mail message only if it is not sent to oneself and if the e-mail is not sent, then it doesn't matter to whom it is sent.","['logic', 'discrete-mathematics']"
1380151,Second differential of the norm in an infinite dimensional Hilbert space,"Let $f: E \to \mathbb{R}$ sending  $x \mapsto \|x\|$ and make some simple hypothesis $E$ is a Hilbert Space Let's say that the norm $\|\cdot\|$ is derived from a scalar product [solved] So we can easily find the différential: $D\|\cdot\|(x)(h)=\langle x/\|x\|,h\rangle$ with $\nabla{ \|\cdot\|}(x)=x/\|x\| \, (grad)$ as shown below: http://www.les-mathematiques.net/phorum/file.php?4,file=43281 But computing the second order differential seems really complicated. I don't even know how to proceed! What about the 3rd order ? $D^3f(x)$ ?","['hilbert-spaces', 'functional-analysis', 'derivatives']"
1380153,"Is ideal an ""anti-field""?","I am comparing theorems on normal subgroup and ideal from Fraleigh 's, and come to this strange intuition. I hope my conclusion does not screw up, I hope I won't get ridiculed: Theorem 15.18: $M$is a maximal normal subgroup of $G$ if and only if $G/M$ is simple. To me this theorem makes sense because in $G/M$, the $M$ has been ""collapsed"" into either $0$ or $e$ (borrowing from Fraleigh 's term.) In other words, the maximal normal subgroup $M$ has been ""modded out"" of $G$ such that all that is left is a simple group. Having said that, let's us now go to the second theorem: Theorem 27.9: (Analogue of Theorem 15.18) Let $R$ be a commutative ring with unity. Then $M$ is a maximal ideal of $R$ if and only if $R/M$ is a field. Since $R$ becomes a field only after it is ""modded out"" of the ideal $M$, may I thus conclude that ideal can intuitively be seen as an ""anti-field,"" meaning that each and every element of an ideal does not have multiplicative inverse, whereas each and every element of field has multiplicative inverse? Thank you for your time and effort. POST SCRIPT : I found another theorem of similar flavor: An ideal $I$ of $R$ is prime if and only if $R/I$ is an integral domain. In similar vein, may I conclude that each element of prime ideal has zero divisor? This 4-year-old posting here strikes me as relevant to my conclusion. Thanks again.","['abstract-algebra', 'ring-theory']"
1380157,Composition series and its number determine a group?,"By Jordan-Holder thm, it is known that every finite group has a unique composition series.(Here, unique means that there is only one kinds of such series.) And it is known also that composition series of a finite group does not determine its group. For example, $\mathbb{Z}_2 \times \mathbb{Z}_2$ and $\mathbb{Z}_4$ have the same composition series. But $\mathbb{Z}_2 \times \mathbb{Z}_2$ has three different composition series in it and $\mathbb{Z}_4$ has only one such series. My question arises here. If two finite groups have the same composition series and their total number of such series are also same, then does the two groups equal? In other words, composition series and its number in it completely determines the original group?","['abstract-algebra', 'group-theory', 'finite-groups']"
1380165,Is Heisenberg group Euclidean?,"I'm reading an article speaking about Heisenberg group $\mathbb H^n$ and some of its properties. 
Now, I have some questions to ask, hoping to be clear enought. Reading the introduction I've understood that we can identify $\mathbb H^n$ with $\mathbb R^{2n+1}$ so we can denote points of Heisenberg group as $P=(x_1,\dots, x_n, y_1,\dots,y_n,t)$. On $\mathbb H^n$ we have an operation $\cdot: \mathbb H^n\times \mathbb H^n\to \mathbb H^n$ defined as $$P\cdot P'= (x_1+x'_1,\dots,y_n+y_n',t+t'+\frac{1}{2}\sum_{j=1}^n x_iy'_i-x'_iy_i),$$ which is not commutative. We can define dilatations $\delta_\lambda:\mathbb H^n\to\mathbb H^n$, $$\delta_{\lambda}(P)=(\lambda x_1,\dots,\lambda y_n,\lambda^2 t).$$ Now, we can equipe $\mathbb H^n$ with a norm $||\cdot||$ defined as $$||P||=max\{|(x_1,\dots,x_n,y_1\dots,y_n)|,|t|^{\frac{1}{2}}\},$$ turning $\mathbb H^n$ in a metric space with distance $d,\, d(P,Q)=||P^{-1}\cdot Q||.$ This said, I'm going to add some my considerations and I would like to know if they are a correct way of thinking or not. Since I can identify $\mathbb H^n$ with $\mathbb R^{2n+1}$, I can think about $(\mathbb H^n,d)$ as $(\mathbb R^{2n+1},d)$.
Then, since all norms on $\mathbb R^{2n+1}$ are equivalent, so are the distance $d$ and the Euclidean distance $D$, hence $(\mathbb H^n,d)$ and $(\mathbb R^{2n+1},D)$ are topologically equivalent. So, if I think about $\mathbb H^n$ as a smooth manifold, it coincides with $\mathbb R^{2n+1}$, in the sense that I have a unique chart ($\mathbb H^n$ itself) and the homeomorphism is given by the identity. On the other hand, in the introduction there's also written that $\mathbb H^n$ is not Euclidean and this seems to contrast what I've said so far. Could someone help me to understand?","['differential-topology', 'lie-groups', 'differential-geometry', 'general-topology']"
1380191,Definition of Equivalent Norms,"Two norms $F,G$ are equivalent when there are constants $a,b$ such that $aF \le G \le bF$.  I'm reading about this idea, and so far I've seen that equivalence of norms implies that the underlying space $X$ has the same topology with respect to either norm.  Maybe it preserves even more properties than this too. But I'm finding it very difficult to use this property when doing proofs or problems because although it's very simple to state, I don't immediately see what it is saying.  In comparison, when you define 'equivalence' in other settings, like in the definition of an isomorphism of abelian groups or a continuous map, it's very clear that a certain operation or object is being preserved as you pass across a map. To be concrete, here are my questions: (1) Is there another way to characterize when norms are equivalent that might provide more intuition for what it says about is being preserved and (2) is there a way to show that this definition is the one you want by starting with something more fundamental (like saying that the norms induce the same topology) and then proving that it's equivalent to the stated definition? Any intuition for the definition would be helpful for either of these questions.","['functional-analysis', 'banach-spaces', 'general-topology', 'analysis', 'intuition']"
1380212,How can I obtain this division's limit without using derivatives?,"$$\lim_{y\to 0} \frac{y}{\cos\left(\frac{\pi}{2}(1+y)\right)}$$
Can anybody help me? I can use basic properties of limits, and some of those basic known limits. I know it would be easier with derivatives, but I was just wondering if it's possible without  L-Hospital's rule, derivatives, Taylor series. Thank you in advance! My ideas for now:
changing cosine into sine.
Maybe that. I have no other clue.","['limits-without-lhopital', 'analysis']"
1380216,"$n$-th derivative of $(x^2-1)^n$ has distinct real roots in $[-1,1]$.","For $n=1,2,3,\ldots$, let
$$f(x) = (x^2-1)^n .$$
Show that the $n$-th derivative $f^{(n)}$ has distinct real roots in $[-1,1]$. I have no idea about the problem. Could I have a hint?","['analysis', 'derivatives']"
1380222,How to solve this definite Integral containing $E_{1}${.}!,"The integral is:
$$\int_{N}^{\infty}\frac{E_{1}(cz+d)}{az+b}e^{-pz}dz$$ where, $E_{1}${.} is the exponential integral, and $$a>0,\ b>0,\ c>0,\ d>0,\ p>0,\ N>0.$$ This is similar to another question of mine which I don't have any Idea to solve it. Any hint or coment  would be appreciated. It must be noted that I already have solved the integral using approximation of exponential integral. I am seeking an exact solution possible. Regards.","['special-functions', 'definite-integrals', 'integration']"
1380227,Multivariate normal density function of function of random variable,"Let $X_1,\dots,X_n$ be i.i.d random variables and $g$ be a symmetric function such that $$g(X_i,X_j)\sim N(\mu,\sigma^2)$$ for all $1\le i<j\le n$. I wish to know the density function of the joint random variable
$$Z=\left(g(X_1,X_2),g(X_1,X_3),\dots,g(X_{n-1},X_{n})\right)$$ which lies in ${n\choose 2}$-dimensional space. To do this, I assume that $Z$ follows multivariate normal distribution. However, the problem is that the covariance matrix $C$ of $Z$ is singular. Could anyone help me? Any advice or suggestion?","['probability-theory', 'probability-distributions', 'normal-distribution', 'covariance', 'matrix-rank']"
1380228,How to make statistical sense of this experiment:,"I have conducted an experiment but I am now unsure of how to say, from a statistics point of view, that the data supports or not that a certain phenomenon has occurred, meaning it could be mere measurement error. This was the experiment: a sample of steel had its ferrite(one common constituent of steels) content measured by a  certain device 10 times, resulting in 10 values(likely hovering around the true value), a mean value  and the standard deviation(is this really what should be being computed here?). Then the sample received a heat treatment and again had its ferrite content measured by the same device 10 times, resulting in 10 values, a mean value and the standard deviation. Let´s assume the values for the mean and standard deviation for the untreated sample are, respectively, 25 and 1.2. And the values for the treated sample are 23 and 1. How can I make the proper statistical treatment here? How to go about computing how certain  one can be when ascertaining the phenomenon did/did not happen? EDIT: Actually, in the experiment, one sample was used to measure the non-heat treated ferrite content. Then four sets of samples, of the very same material/same batch of course, were heat treated for different lengths of time at the same temperature, each of the four sets treated at a different temperature. For each set of samples, all of the samples were heat treated together, then at say, 300 seconds, one sample was taken out of the oven. Then, at 600 seconds another, at 6000 seconds another, and so on. The ferrite content of all samples was measured using the same device. The samples that were heat treated for long times have numbers that show clearly that something happened, even without proper statistical analysis. The problem is dealing with the samples treated for short times, as they showed numbers that are similar to the untreated sample, hence the need to test them for statistical significance.",['statistics']
1380257,Failure of group definition with weaker axioms,"In ""A First Course in Abstract Algebra"", Edition 7, p.43, Fraleigh writes that It is possible to give axioms for a group $\left<G,*\right>$ that seem at first glance to be weaker, namely: The binary operation $*$ on $G$ is associative. There exists a left identity element $e$ in $G$ such that $e*x = x$ for all $x \in G$. For each $a \in G$ there exists a left inverse $a'$ in $G$ such that $a' * a = e$ From this one-sided definition, one can prove that the left identity element is also a right identity element, and a left inverse is also a right inverse for the same element. Thus these axioms should not be weaker, since they result in exactly the same structures being called groups. It is conceivable that it might be easier in some cases to check these left axioms that to check our two-sided axioms. Of course, by symmetry it is clear that there are also right axioms for a group. Does the above few axioms assume that the right identity element exists in the first place? Consider $a * b = \left|a\right|b$. There are at least two possible solutions for a ""right identity element"", namely: $$-1 * x = -1 \implies x = -1$$
$$1 * x = 1 \implies x = 1$$ Even though the group with operation $*$ satisfies axiom 2 of the weaker definition, it seems that $\left<G,*\right>$ cannot be a group, because using the original axioms of a group, there is no identity element $e$ such that $e*a = a * e = a$ for all $a \in G$. How then do the above axioms ""result in exactly the same structures being called groups""?",['abstract-algebra']
1380277,Why is reflection in a plane an automorphism?,"I have not studied group theory, but would like to know in simple terms why reflection in a plane is an automorphism.
Dr. Hermann Weyl gives the definition of automorphism in his book 'symmetry' as A transformation which preserves the structure of space What does he mean by the structure of space? Why can reflection preserve the structure?","['group-theory', 'symmetry']"
1380278,Significance of the derivative of a scalar field,I read somewhere that if the temperatures of all points of a huge room were plotted then the derivative at a certain point would give a vector whose direction points in the direction of the hottest point in the room with its magnitude being equal to the temperature at that point. Later on I learned that finding the grad of a scalar field(a surface) gives you a vector perpendicular to the surface(the normal). But the normal points upwards and not in the direction of the largest scalar values being generated by the scalar field. I'm confused...,"['scalar-fields', 'multivariable-calculus']"
1380282,Singularity type of $\frac{1}{z} e^{-\frac{1}{z^2}} $,"I've been asked to compute the singularity type of $f(z) := \frac{1}{z}e^{-\frac{1}{z^2}} $. Here's my reasoning: $$ \frac{e^{-\frac{1}{z^2}}}{z} = z^{-1} \sum_{n=0}^\infty \big( -z^{-2} \big)^n \cdot \frac{1}{n!} = \sum_{n=0}^\infty (-1)^n \frac{z^{-2n-1}}{n!} = \sum_{n=0}^{-\infty} \frac{(-1)^{-n}}{(-n)!}z^{2n-1} = \sum_{n=-\infty}^\infty a_n z^n$$ with $$ a_n := \begin{cases}
    0 & \text{if } n\ge 0 \text{ or } (n<0 \text{ and } |n| \text{ is even})\\
    \frac{-1}{(-n)!} & \text{if } n < 0 \text{ and } |n| \text{ is odd}\\
\end{cases}$$ so, since the Laurent series of the function has infinitely many $a_n$ with negative index different from $0$ I would claim that the function has an essential singularity in $0$. Still the singularity should be removable as $$ \lim_{z \to 0} ~~z \cdot f(z) = 0$$ Where am I mistaken?","['laurent-series', 'complex-analysis', 'exponential-function']"
1380286,Pointwise almost everywhere convergent subsequence of $\{\sin (nx)\}$,"Can you prove or disprove that the sequence $\{\sin (nx)\}$ has a pointwise almost everywhere convergent subsequence with respect to the Lebesgue measure on $\mathbb{R}$ ? Edit: I am adding my thoughts here as a motivation, because otherwise this question will hit the bottom. So initially I thought whether $\{\sin{nx}\}$ is convergent in $L_1([0,\pi])$ or on other finite interval in $\mathbb R$. Then I computed the integral $\|\sin{nx}\|_1=\int\limits_{0}^{\pi}{|\sin{nx}|dx}=n\int\limits_{0}^{\pi/n}{\sin{nx}dx}=2$. Therefore $\|\sin{nx}\|_1\rightarrow 2$ but this doesn't tell me to which function converges. Then I thought about convergence in $L_2([0,\pi])$, but obviously it is not convergent there. This is because it is part of the orthonormal basis in $L_2$ (up to a constant), so it is not even Cauchy sequence. But still it is weakly convergent in $L_2$, because from Bessel's inequality it follows that $\langle f,\sin{nx}\rangle\rightarrow 0$ for each $f\in L_2([0,\pi])$. Finally, I decided to check whether $\{\sin{nx}\}$ has a convergent a.e subsequence. If there is no such sequence, then it can not be convergent in $L_1$. And if there is such subsequence, then by Lebesgue DCT it will follow that it converges in $L_1$ (and probably it might be the limit of the whole sequence). I just didn't see that LDCT will work again for $L_2$ : if there is a convergent a.e subsequence, then it should converge in $L_2$ also, but this is impossible since $\{\sin{nx}\}$ is orthonormal (up tp a constant) and  no subsequence of $\{\sin{nx}\}$ is Cauchy in $L_2$. This is actually the answer of @Julián Aguirre. Now I have another Question: Is it possible to prove that there is no convergent pointwise a.e subsequence of $\{\sin{nx}\}$ using only first year calculus and knowing of course what is a set with Lebesgue measure $0$ in $\mathbb R$ ? What is obvious is that for each $x$ there is a convergent subsequence since $\{\sin{nx}\}$ is bounded. But all $x\in [0,\pi]$ are uncountable set, so we can not apply for example Cantor diagonal argument.","['lp-spaces', 'lebesgue-measure', 'sequences-and-series', 'real-analysis']"
1380294,List of techniques to evaluate limits?,"I'd like to make a complete list of techniques to evaluate a limit. Definition of the limit Continuous functions Algebra of limits Addition, multiplication, division Composition Inverse function Showing inequalities Squeeze theorem Rewriting, try to factor out common factors in numerator and
denominator Rationalizing the denominator Substitutions, in particular the $1/t$ substitution. Use of derivatives, l'Hôpital's rule and Taylor series. If $\lim_{x\to a} f(x)=1$ and $\lim_{x\to a} g(x)=\infty$ then $$\lim_{x\to a} f(x)^{g(x)} = e^{\lim_{x\to a} g(x)[f(x)-1]}$$ for $$0^0\quad and\quad \infty^0 \quad form \implies $$ $$\lim_{x\to a} f(x)^{g(x)}=e^{\lim_{x\to a}[g(x) \log_e{f(x)}]}$$ However the list seems so short. Are there any other good strategies or techniques to solve limits?","['calculus', 'limits']"
1380300,Find the area of a triangle given the radius of its incircle and a tangential point,"A friend gave me recently the following interesting problem and I would like to share a couple of solutions. Any additional contributions are welcome. A triangle $\vartriangle ABC$ is given and we know the radius $r$ of its incircle $(O, r)$. Let $D$ be the tangential point of the incircle on $AC$ which partitions $AC$ into $AD=\alpha$ and $DC=\beta$. Determine the area of $\vartriangle ABC$ as a function of $\alpha$, $\beta$ and $r$.","['euclidean-geometry', 'geometry', 'trigonometry']"
1380305,Is the limit of càdlàg functions càdlàg?,Is the pointwise limit of càdlàg functions càdlàg? If not which are the weaker conditions to assure it? I cannot find a counterexample,"['probability', 'real-analysis']"
1380319,A curious proof of L'Hospital's rule,"I quote P. Nahin When Least is Best (2004), pp. 173-174 ""Since $g(x)=R(x)h(x)$, then differentiation of both sides gives $$g'(x)=R(x)h'(x)+R'(x)h(x).$$ Since $\lim_{x \rightarrow 0} h(x)=0$, and we assume $R(x)$ really does have a limit as $x \rightarrow 0$, i.e., $\lim_{x \rightarrow 0} R(x)=R$, then $$\lim_{x \rightarrow 0} g'(x)=\lim_{x \rightarrow 0} R(x)h'(x)+\lim_{x \rightarrow 0} R'(x)h(x)$$$$=R \lim_{x \rightarrow 0} h'(x) + \lim_{x \rightarrow 0} R'(x) \lim_{x \rightarrow 0} h(x).$$ The last term is zero because $\lim_{x \rightarrow 0} h(x)=0$ and because the very fact that $\lim_{x \rightarrow 0} R(x)=R$ implies that $\lim_{x \rightarrow 0} R'(x)=0$, too (i.e. the $y=R(x)$ curve must approach the horizontal zero- slope line $y=R$ as $x \rightarrow 0)$. So, $$\lim_{x \rightarrow 0} g'(x)=R \lim_{x \rightarrow 0} h'(x).$$ and we have L'Hospital's rule."" Please, can someone criticize this proof ? Every argument about the limits of the popularization of mathematics is welcome.","['proof-verification', 'calculus', 'real-analysis', 'limits']"
1380322,Measures on $\mathbb{R}$ that are not translation invariant,"I am looking for examples of measures on $\mathbb{R}$ which are not translation invariant. The only one I could come up so far is the dirac measure . In particular, I am looking for a measure $\mu$ on the measurable space $(\mathbb{R}, \mathcal{P}(\mathbb{R}))$ which is not invariant under translation but fulfills $\mu((a,a+1]) = 1$ for all $a \in \mathbb{R}$.",['measure-theory']
1380327,Show that $f(x) = \log(x + \sqrt {x^2+1})$ is an odd function,"I need to show that $f(x) = \log(x + \sqrt{x^2+1})$ is an odd function and from what I can understand from this question (found while searching): What is an odd function? , I have to show that$f(-x)=-f(x)$. I have struggled to figure it out for hours but I couldn't find a solution. Thanks in advance!",['functions']
1380337,The limit inferior of Borel functions [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Suppose $X$ is a separable metric space and $F \colon X \times ℝ_+→[0,1]$ is Borel. Let $f(x) = \liminf_{ε→0} F(x,ε)$. Is $f$ Borel?","['real-analysis', 'descriptive-set-theory']"
1380362,A simple expression to map $\mathbb N^*$ bijectively to $\mathbb N$,"Let $\mathbb N = \{ 1,2,3,\ldots \}$, then by the well-known ""Cantor""-Scheme we have $\mathbb N \times \mathbb N \cong \mathbb N$. But even nicer is that we can write this scheme $\varphi : \mathbb N \times \mathbb N \to \mathbb N$ as a simple function 1 (quadratic polynomial)
$$
 \varphi(n,m) = n + \sum_{i=1}^{n+m-2} i = \frac{1}{2}(n+m-1)(n+m-2) + n.
$$
which could be seen by looking at the infinite grid $\mathbb N \times \mathbb N$ the right way quite simply 2 . Setting
$$
 (n,m,k) \mapsto \varphi(\varphi(n,m), k)
$$
and so on we see that $\mathbb N^k \cong \mathbb N$ and we still got a simple formula. But now consider
$$
 \mathbb N^* := \bigcup_{k=1}^{\infty} \mathbb N^k
$$
which as a countable union of countable sets must themselve be countable. But beside this abstract proof, does there exists some simple (maybe polynomial)
function which realises this bijection? Denote by $p_n$ the $n$-th prime number and define $\psi$ by $\psi(n_1, \ldots, n_k) := 2^{n_1} 3^{n_2} \cdots p_k^{n_k}$, this gives such a correspondence based on the unique prime factorisation, but maybe you know some simpler ones, that could also be evaluated fast on a computer (computing the $n$ prime is not computationally simple). Footnotes: For $\varphi : \mathbb N_0 \times \mathbb N_0 \to \mathbb N_0$ we have
$$
 \varphi(n,m) = n + \sum_{i=1}^{n+m} i = n + \frac{1}{2}(n+m)(n+m+1).
$$ For $(n,m)$ consider the diagonal where $i + j = m + n$ and sum everything
underneath this diagonal, this is exactly $\sum_{i=1}^{n+m}$, after this add $n$ to move on this diagonal to the right point.","['arithmetic', 'elementary-set-theory', 'logic']"
1380373,Bernoulli product measure,"Let $\Omega=\{0,1\}^\mathbb{N}$ and $\mathcal{A}$ the sigma-algebra generated by the  cylinders sets $\{w\in\Omega\vert \forall s \in S, w_s=\epsilon_s\}$ with $S\subset\mathbb{N}$ finite and $\epsilon_s\in\{0,1\}$. Let $p\in(0,1)$. We take product measure with density $p$ on $(\Omega,\mathcal{A})$:$\mu=\prod_{n\in\mathbb{N}} \mu_n$ where $\mu_n$ is Bernoulli measure on $\{0,1\}$ given by $\mu_n(w_n=0)=1-p$, $\mu_n(w_n=1)=p$. I would like to prove that for all $\epsilon>0$ and $B\in\mathcal{A}$, there is a family of cylinders $(C_i)_{1\leq i \leq N}$ such as $\mu\left(B\Delta \bigcup_{1\leq i\leq N} C_i\right)<\epsilon$, where $\Delta$ is the symmetric difference. Actually, I'm also looking for a simple proof of the existence of the product measure. I would very much appreciate any help / references!","['ergodic-theory', 'measure-theory']"
1380378,Showing that the sequence $x_n=\frac{1}{3}x_{n-1}(4+x_{n-1}^3)$ where $x_0=-0.5$ quadratically converges,"I am stuck at a point in solving this problem: Show that the sequence defined by: For all $$n\in\mathbb{N}, 
x_n =
\begin{cases}
-\frac{1}{2},  & \text{if $n=0$} \\
x_n=\frac{1}{3}x_{n-1}(4+x_{n-1}^3), & \text{if $n>0$}
\end{cases}\,\,\,$$ quadratically converges In other words: Show that there exist some positive constant $\lambda$ such that $\lim_{n\to \infty}\frac{|x_{n+1}-p|}{|x_n-p|^2}=\lambda$ where $$p=\lim_{n\to \infty}x_{n}.$$ (Note: I've got this sequence by applying Newton's method to the function $f(x)=\frac{1}{x^3}+1$ on the interval $[-2,0)$ with initial approximation $x_0=-\frac{1}{2}$) I was able to show that $p=\lim_{n\to \infty}x_n=-1$. But when I try to calculate $\lim_{n\to \infty}\frac{|x_{n+1}-p|}{|x_n-p|^2}$ I got stuck. Thanks for any hint/help.","['sequences-and-series', 'calculus', 'numerical-methods']"
1380382,Differential equation with shifited term,"I have a differential equation (Or integral equation) of the form: $$ f(x) = a e^{-x} + b \int_0^x f(cz+dx) e^{-z} dz$$ $a,b,c,d$ are constants. I am considering whether the above equation has a closed form solution. If not, why it is the case? If so, I think guessing a functional form and using method of undetermined coefficients. But I am not sure how to guess. Thanks so much!","['integral-equations', 'calculus', 'ordinary-differential-equations', 'delay-differential-equations']"
1380388,When does interchangibility of limit and Riemann integral imply uniform convergence?,"Let  $\{f_n\}$ be a sequence of real-valued functions defined on an interval $[a,b]$ such that each $f_n$ is Riemann integrable, $\{f_n\}$ converges point-wise to $f$, $f$ is Riemann integrable and $\lim_{n \to \infty} \int_a^b f_n$ exists and equals $\int_a^b f$; then under what additional condition(s) can we conclude that $\{f_n\} $ converges uniformly to $f$?","['analysis', 'uniform-convergence', 'convergence-divergence', 'definite-integrals']"
1380423,Properties of matrices $M=UDU^*$ with $UU^*=Id$,"I recently came across some matrices of the form $M=UDU^*$ (the superscript $*$ denotes the conjugate transpose), where $U \in \mathbb{C}^{r\times n}$ with $r<n$, $D \in \mathbb{C}^{n \times n}$ a diagonal matrix, and $UU^*=\text{Id} \in \mathbb{C}^{r \times r}$ the identity matrix. (Note that $U$ is rectangular, so the last condition is not that $U$ is unitary). I am interested in the eigenvalues of $M$, in particular how they are related to the eigenvalues of the matrix $D$. Any hints?","['matrix-decomposition', 'linear-algebra', 'hilbert-spaces', 'matrices']"
1380428,One special case of Helly's theorem (for $\text{radius}=1$ circles),"There are $n$ points on the plane. Any $3$ of them can be covered with a radius $1$ circle. Prove that there is a radius $1$ circle that covers all the points. Came to this when tried to prove an easy case of Helly's theorem (for $r = 1$ circles). So it's obvious that the solution can not use Helly's . Definitely I am missing something, need a wise hint...","['euclidean-geometry', 'plane-geometry', 'geometry', 'discrete-geometry', 'circles']"
1380459,Holonomy computation in $S^2$,"If $\gamma$ is a closed Loop in $S^2$ and $p\in S^2$, where $\gamma$ is the boundary curve of some region $X$ in $S^2$ (and $\gamma$ satisfied some regularity conditions), someone told me that the holonomy map $H_\gamma:TS^2_p\rightarrow TS^2_p$ is just rotation by the area of $X$. I tried to obtain a reference/proof for this. Could someone help me out?","['holonomy', 'differential-geometry']"
1380463,Frobenius automorphism and non-split Cartan subgroup of $\mathrm{GL}_2(\mathbb{F}_p)$,"For completeness I give some definitions. Let $p$ a prime number and consider $V$ a 2-dimensional $\mathbb{F}_p$-vector space.
Consider $k$ a sub-algebra of $\mathrm{End}(V)$ that is a field of $p^2$ elements. Then $C=k^* \subset \mathrm{GL}_2(V)\simeq\mathrm{GL}_2(\mathbb{F}_p)$ is called a non-split Cartan subgroup. Let $\mathcal{N}$ be the normalizer of $C$ in $\mathrm{GL}_2(\mathbb{F}_p)$. Then each $s \in \mathcal{N}$ induce an automorphism of $k$ defined as
$$ x \mapsto sxs^{-1}$$
In particular the kernel of the map $\mathcal{N} \longrightarrow Aut(k)$ is $C$. Now, $k$ has only one non-trivial automoprhism that is the Frobenius automorphism $\sigma: a \mapsto a^p$, $a \in k$. So, can I say that each $s \in \mathcal{N} \setminus C$ has the form $\sigma x$ with $x \in C$? The idea come from the fact that $\sigma$ is an invertible $\mathbb{F}_p$-linear map of $\mathbb{F}_{p^2} \simeq k$, hence representable as a matrix of $\mathrm{GL}_2(\mathbb{F}_p)$ when we chose a basis for $\mathbb{F}_{p^2}$ over $\mathbb{F}_p$.","['abstract-algebra', 'number-theory', 'linear-algebra', 'finite-fields']"
1380490,Derivative of Bezier Rectangle,"From this page Derivatives of a Bézier Curve , I can see that the derivative of a degree $N$ Bezier curve is just a Bezier curve of degree $N-1$ and it explains how to calculate the control points by each control point just being $P_{i+1} - P_i$. Is it also true that the derivative of a Bezier rectangle of degree $(M,N)$ is also just a Bezier rectangle of degree $(M-1,N-1)$?  If so, how would you calculate the control points for the rectangle? By Bezier rectangle, I mean a tensor product Bezier surface, like the kind described here Wikipediate: Bezier Surface . I've been trying to work it out on paper but no luck so far.  I've been able to make progress on coming up with a derivative, but it has quite a few terms even for a biquadratic patch, and i'd like to do this with higher degrees. My end goal is that I'm trying to calculate the gradient of a univariate Bezier rectangle that has scalar control points.  Specifically, the rectangle takes $X$ and $Z$ values from 0 to 1 and outputs a $Y$ value for the given $(X,Z)$.  I want to find the gradient so that I can use it to calculate surface normals, as well as get a distance estimation for sphere tracing (ray marching). Thanks for any help you guys can provide!","['partial-derivative', 'bezier-curve', 'derivatives']"
1380500,How many two letter words can be formed from 26 English letters?,"There are 26 English letters(a-z). From layman approach, How can one calculate the possible two letter words from these 26 English letters?","['combinations', 'combinatorics', 'permutations']"
1380512,Compactifying $\mathcal{O}_{\mathbb{P}^1} (-2)$,"I have the total space of $\mathcal{O}_{\mathbb{P}^1} (-2)$ and I see that a ""standard"" way to compactify is to add the trivial line bundle, $\mathcal{O}_{\mathbb{P}^1}$, and then projectivize. That is
$$
\mathcal{O}_{\mathbb{P}^1} (-2) \rightarrow \mathbb{P}\left(\mathcal{O}_{\mathbb{P}^1} (-2) \oplus \mathcal{O}_{\mathbb{P}^1}\right).
$$ Can someone help me understand 1) Why this is a standard way to compactify something, and 2) Why do we add the trivial bundle $\mathcal{O}_{\mathbb{P}^1}$? Thanks for the help.","['complex-geometry', 'algebraic-geometry', 'vector-bundles']"
1380518,$\mathbb Z_n$ as $\mathbb Z[i]$-module,"I am trying to find all $n$ such that $\mathbb Z_n$ is a $\mathbb Z[i]$-module, where $\mathbb Z[i]$ is the ring of Gaussian integers. I proved that any $\mathbb Z[i]$-module $M$ is just an Abelian group with hommomrphism $\psi:M\rightarrow M$ and $\psi^2=-I_M$ .","['abstract-algebra', 'modules']"
1380530,"Cramer-Rao lower bound for normal($\theta, 4\theta^2$)","I am trying to find the Cramer-Rao lower bound for unbiased estimators of $\theta$, given a sample $X_1,\ldots, X_n \sim \textrm{normal}(\theta,4\theta^2)$. I am calculating the CRLB as $$
\frac{1}{-n\textrm{E}\left[\frac{\partial^2}{\partial\theta^2}\log f(x_i\vert\theta)\right]}
$$ Evaluating this I get $\frac{4\theta^2}{9n}$. For that distribution however, from the exponential family representation I think that $\left(\sum_i x_i, \sum_i x_i^2 \right)$ is a complete sufficient statistic, and therefore any estimator based only on this should achieve the CRLB. But the variance of $\bar{X}$, which is an unbiased estimator of $\theta$ based only on the above, is $\frac{4\theta^2}{n}$ which is larger. Where have I gone wrong?","['statistics', 'statistical-inference']"
1380538,Simultaneously vanishing quadratic forms,"Given a set of Hermitian matrices $\{A_i\}$, is there a simple way to check if there exists a vector $c$ such that for all $i$: $$c^* A_i c = 0?$$ Namely, when can the quadratic forms defined by the $\{A_i\}$ simultaneously vanish?","['systems-of-equations', 'linear-algebra', 'quadratic-forms', 'matrices']"
1380549,"If ${a_i} \to 0$ and $\{ {X_i}\} _{i = 1}^\infty $ is a sequence of iid random variables with zero mean, does ${a_i}{X_i} \to 0$ almost surely?","My problem is slightly more specific than the title of this question: Let $0 < \beta  < 1$ and let $\{ {X_i}\} _{i = 1}^\infty $ be a sequence of i.i.d. random variables with $E({X_i}) = 0$. In addition, I could assume that $E(X_i^2) = {\sigma ^2} < \infty $ if necessary. Does ${\beta ^i}{X_i} \to 0$ almost surely? But if the answer is yes, I would be curious to know if the result would also obtain for general real sequences that go to zero. That is when ${\beta ^i}$ is replaced by any ${a_i}$, with ${a_i} \to 0$.","['probability-theory', 'convergence-divergence', 'limits', 'random-variables']"
1380554,Random variables that span copies of $\ell_p$,"Consider the coin-toss measure $\mu$ on $\{0,1\}^\mathbb{N}$. Within this framework it is easy to construct a sequence of independent, symmetric Bernoulli random variables. Indeed the point-evaluation random variables $X_n$ defined below do the job: $$X_n((t_m)_{m=1}^\infty) = t_n\qquad ((t_m)_{m=1}^\infty\in \{0,1\}^{\mathbb{N}},\,n\in \mathbb{N}).$$ According to Kchinchine's inequality the linear span of $\{X_n\colon n\in \mathbb{N}\}$ in $L_1(\mu)$ is isomorphic to $\ell_2$. Are there easy ways to construct sequences of independent random variables that span copies of $\ell_p$ for $p\in (1,2)$ in $L_1(\mu)$? Such sequences exist (for instance if you take a sequence of independent $p$-stable random variables , then the linear span will be even isometric to $\ell_p$), however the formulae for such random variables will be rather complicated. In other words, I put emphasis on a nice closed-form formula for $X_n$ rather than the very existence.","['probability-theory', 'banach-spaces', 'random-variables', 'functional-analysis']"
1380557,How can I intuitively interpret this vector operation?,"In reading through some very old source code that I inherited and came across a three-dimensional Euclidean vector operation that I can't seem to gain an intuition for. Transcribing the program code into mathematics, the operation (which has three inputs, vectors $a$, $b$, and $c$) is as follows: $$
a - \frac{a \cdot b}{b \cdot c}c
$$ The comment alongside the source code advertises that the function ""projects a vector into a plane along a third vector"" and that the result is ""vector a projected into the plane defined by b along c"" . My geometric intuition is a bit rusty, but I've been unable to put together any combination of vector and plane projections that would yield the expression above. The comments are a bit ambiguous and can be interpreted in multiple ways, so I suppose that I'm not looking at it in the right way. Could someone elaborate on how this sort of operation might be described qualitatively?","['vector-spaces', 'linear-algebra']"
1380563,Using addition and subtraction in algebraic proving in set theory,"I am trying to prove (using algebraic way) the following statement: $A\Delta B=A$ iff $B=\emptyset$ So it goes like this in one direction: $A\Delta B=A$ $A\Delta B\Delta A=A\Delta A$ (I added $\Delta A$ to both sides) $B\Delta A\Delta A=A\Delta A$ (commutativity) $B\Delta\emptyset=\emptyset$ (Symmetric difference between a set and itself equals the empty set) $B=\emptyset$ (symmetric difference between a set and the empty set equals the set itself) So, is it correct this way?
The thing that makes me wonder whether it is correct or not is mainly the addition of $\Delta A$ to both sides in step 2. I think it still maintains the equality of both sides but I'm still not sure if it is valid in proving. And if it's not correct, can you offer me an alternative proof strategy (preferably algebraic)? Thanks a lot!","['elementary-set-theory', 'solution-verification']"
1380564,Bound on the difference of two determinants,"Let $A$ and $B$ be two real, $n\times n$ matrices. Using Hadamard's inequality, it is not hard to show that
$$
\left|\det A - \det B \right| \leq \|A-B\|_{2} \frac{\|A\|_{2}^n -\|B\|_{2}^n}{\|A\|_2 -\|B\|_2}.
$$
Where $\|A\|_2=\sqrt{\sum_{i,j}a_{ij}^2}$.  From this, I can derive a sup bound, for example 
$$
\left|\det A - \det B \right| \leq n^{n+1} \|A-B\|_{\infty} \max (\|A\|_{\infty}^{n-1},\|B\|_{\infty}^{n-1}).
$$
Where $\|A\|_\infty=\sup_{i,j}|a_{ij}|$. The constant $n^{n+1}$ is not the best bound possible : any reference (or proof) for a better (or the best) one? I show below that one can obtain $n^2(n-1)^{n-1}$, but that isn't much better.
I just tried  $10^5$ random matrices on Maple and obtained a maximal constant (much) smaller  than one : this is not a proof, but it looks like there is room for improvement nevertheless. Just for completeness (and in case someone sees a factor I missed), to get the first bound, writing $A=[A_1,\ldots,A_n]$ in terms of its column vectors, an expansion shows
\begin{eqnarray*}
\det A &=& \det (A_1 -B_1,A_2,\ldots,A_n) + \det (B_1,A_2,\ldots,A_n) \\
  &=& \sum_{j=1}^n \det (B_1,\ldots, B_{j-1}, A_j -B_j,A_{j+1},\ldots,A_n) \\
&& + \det B, 
\end{eqnarray*}
Thus by Hadamard's inequality ,
\begin{eqnarray*}
\det A -\det B &\leq&  \sum_{j=1}^n \prod_{i=1}^{j-1} \|B_i\|_{2}\prod_{i=j+1}^{n} \|A_i\|_{2} \|A_j-B_j\|_{2} \\
&\leq&  \|A-B\|_{2} \sum_{j=1}^n \|B\|^{j-1}_{2}\|A\|^{n-j}_{2} \\ 
&=& \|A-B\|_{2} \frac{\|A\|_{2}^n -\|B\|_{2}^n}{\|A\|_2 -\|B\|_2}.
\end{eqnarray*} The second bound is just that $x^n -y^n\leq n \max(|x|^{n-1},|y|^{n-1}) |x-y|$ and $\|A\|_2 \leq n\|A\|_\infty$. Another approach is calculus, namely, to write that
$\det B - \det A = f(1)-f(0)$, with $f(t)=\det(A + t(B-A))$. By the mean value theorem $f(1)-f(0)\leq \max |f^\prime (t)|$. We can compute that $$f^\prime(t) =  {\rm trace}\left({\rm Cofm}(A +t(B-A))(B-A)\right)$$ 
(if I did not mess up, using the formula for the differential of a determinant , where Cofm means the matrix of Cofactors). Then, it should deliver something better, if there is a nice way to bound it. The simplest thing is to use Cauchy-Schwarz, namely
$$
\left|{\rm trace}\left({\rm Cofm}(A +t(B-A))(B-A)\right)\right|\leq \|B-A\|_{2} \|{\rm Cofm}(A +t(B-A))\|_{2}
$$
and then, by lack of a better idea, 
$$
\|{\rm Cofm}(A +t(B-A))\|_{2}\leq n \max_{ij} |{\rm Cof}_{i,j}(A +t(B-A))|,
$$
and brutally, $|{\rm Cof}_{i,j}(A +t(B-A))|\leq ((n-1) \max(\|A\|_\infty,\|B\|_\infty))^{n-1}$ gives a slightly better constant, namely
$$
n^2(n-1)^{n-1} <n^{n+1}
$$
but that still seems a very rough way to bound a determinant, as it is never sharp, since to attain this bound all coefficients should be equal, and therefore the cofactor would be zero. They are of the same order in $n$, and I suspect this order is wrong.","['determinant', 'reference-request', 'matrices']"
1380569,Proving that $(A\setminus C)\cap(B\setminus C)\cap(A\setminus B)=\emptyset$,"For each $A,B,C$ how would I prove that $(A\setminus C)\cap(B\setminus C)\cap(A\setminus B)=\emptyset$ ? My thoughts are if $x\in (A\setminus C)\cap(B\setminus C)\cap(A\setminus B)$, then $x\in (A\setminus C)$ and $x\in (B\setminus C)$ and $x\in (A\setminus B)$ so $x \in A$ and $x \not \in C$ and $x \in B$ and $x \not \in C$  and $x \in A$  and $x \not\in B$. How would I continue from here?",['elementary-set-theory']
1380599,Convergence of Integrals of Exponential Functions,"Let $f$ be a non-negative real valued function on $[a,b]$, and let $p:[a,b]\to(1,\infty)$ such that $f^p\in L^1([a,b])$. Let $p_n:[a,b]\to(1,\infty)$ be a (uniformly bounded) sequence of (step-)functions converging to $p$ wrt. the $L^1$-norm, i.e. $||p_n-p||_{L^1([a,b])}\to0$ as $n\to\infty$. Question: Does
\begin{align*}
\lim_{n\to\infty}\int_a^bf(x)^{p_n(x)}dx=\int_a^bf(x)^{p(x)}dx
\end{align*}
hold in general? If $f$ is bounded, the proof is easy using the Lipschitz continuity of exponential functions. But what if $f$ is unbounded? I neither know if $f^{p_n}$ is in $L^1$, nor I could find a counterexample.
Any help, ideas, hints or even counter examples are highly appreciated.
Thanks in advance!",['integration']
1380614,Basic question about $\sigma$-fields,"Billingsley's text ""Probability and Measure"" has the following exercise problem: Problem 2.5(b): For a collection of sets $\mathcal{A},$ let $\mathcal{F}(\mathcal{A})$ be the intersection of all fields containing $\mathcal{A}.$ Show that $\mathcal{F}(\mathcal{A})$ is the class of sets of the form $\bigcup_{i=1}^m \bigcap_{j=1}^{n_i} A_{ij}$ where for each $i$ and $j$ either $A_{ij}$ or $A_{ij}^c$ belongs to $\mathcal{A}$ and where the sets $\bigcap_{j=1}^{n_i} A_{ij}$ are disjoint for $1\leq i\leq m.$ Is there an analogous statement for $\sigma$-fields where the finite set operations are replaced by countable ones?",['probability-theory']
1380623,Computing $\operatorname{Tr} \bigl( \bigl( (A+I )^{-1} \bigr)^2\bigr)$,"Suppose that $A \in \mathbb{R}^{n \times n}$ is a symmetric positive semi-definite matrix  such that $\operatorname{Tr}(A)\le n$. I want a lower bound on the following quantity 
$$\operatorname{Tr} \bigl( \bigl( (A+I )^{-1} \bigr)^2\bigr)$$
where $I$ denotes the identity matrix. My intuition tells me it should be $$
\operatorname{Tr} \bigl( \bigl( (A+I )^{-1} \bigr)^2\bigr) \ge 1/4
$$ However, I'm not sure how to show it. Also my intuition might be wrong?","['numerical-linear-algebra', 'matrices', 'eigenvalues-eigenvectors', 'linear-algebra', 'trace']"
1380624,"How Kriging, Bochner theorem and Positive definite (PD) function are related?","This question referes to the link: https://en.wikipedia.org/wiki/Kriging I can understand the relation between Bochner's theorem and PD function. But could not properly understand and connect all three elements namely, Kriging, Bochner's theorem and PD function. I would love to know a clear connection between these three. May be these three are related through Fourier transform, my wild guess; any clarification would be appreciated.","['definition', 'soft-question', 'functional-analysis', 'statistics', 'linear-algebra']"
1380639,Does the radius of the quadrant pass from the center of the inscribed circle?,"In the following picture: The smaller circle is inscribed inside the quadrant, whose radius (OB) is 8. The original question (but not the question of this post) is that ""find the radius of the inscribed circle and the area of shaded part"". I managed to solve the problem using the guess that the line OT passes from the point P (P is the center of the inscribed circle). But I am not able to prove this. Can you give me a hint about how can I prove that OT passes the point P?","['geometry', 'circles']"
1380640,Does anyone know when I would use this symbol ($\supseteqq$) and meaning?,"Does anyone know what this symbol means? Where would one use it? Someone recently asked me but I do not know what it means. I have seen it with just one line underneath to denote subset. With an equals sign would it mean the trivial subset, meaning $A$ is a subset of $A$?","['elementary-set-theory', 'notation']"
1380650,continuously differentiable multivariable functions,"What does it really mean to say a function $f:\mathbb{R}^n\rightarrow \mathbb{R}^n$ is continuously differentiable? A function $f:\mathbb{R}\rightarrow \mathbb{R}$ is continuously differentiable if $f$ is differentiable and $f':\mathbb{R}\rightarrow \mathbb{R}$ is continuous.. But what is $f'$ in case of $f:\mathbb{R}^n\rightarrow \mathbb{R}^n$.. Is it the jacobian $\begin{bmatrix}\frac{\partial f_1}{\partial x_1}& \frac{\partial f_1}{\partial x_2}& \cdots &\frac{\partial f_1}{\partial x_n} \\
\frac{\partial f_2}{\partial x_1}& \frac{\partial f_2}{\partial x_2}& \cdots &\frac{\partial f_2}{\partial x_n} \\
\vdots \\
\frac{\partial f_n}{\partial x_1}& \frac{\partial f_n}{\partial x_2}& \cdots &\frac{\partial f_n}{\partial x_n} \end{bmatrix}$ I could not understand how does this matrix act on $\mathbb{R}^n$.. As an example, for $f(x,y)=(xy,x+y)$ we see that jacobian is 
$\begin{bmatrix}y&x\\1&1\end{bmatrix}$.. I do not understand how do i define
 $Df: \mathbb{R}^2\rightarrow \mathbb{R}^2$.. In case of derivative at a point we have $Df((a,b))=\begin{bmatrix}b&a\\1&1\end{bmatrix}$ and we define $Df(a,b)(x,y)=\begin{bmatrix}b&a\\1&1\end{bmatrix}
\begin{bmatrix}x\\y\end{bmatrix}=\begin{bmatrix}bx+ay\\x+y\end{bmatrix}$ I mean there are already variables in $Df$ and so i am getting confused how to act on $\mathbb{R}^n$.. But in case of $Df(a,b)$ there are no variables.. So, it seems to be natural.","['multivariable-calculus', 'derivatives']"
1380656,algebra question.. [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question If $f : \mathbb{R}\rightarrow \mathbb{R}$, and $f(x)=\frac{2}{4^{x}+2}$ Find the value of $$f\left [ \frac{1}{11} \right ]+f\left [ \frac{2}{11} \right ]+ \cdots +f\left [ \frac{10}{11} \right ]$$","['number-theory', 'algebra-precalculus', 'functions']"
1380669,Proving that a polilinear operator is differentiable,"A Polilinear map operator is $P:X^1 \times ... \times X^n \to Y$ such that the foolowing applies: $\lambda, \mu \in R$ $$ P( \lambda x_1^1 + \mu x_2 ^1, x^2,...,x^n)= \lambda P(x_1^1,x^2,...x^n)+ \mu P(x_2^1,x^2,...x^n) \\...... \\\ ...... \\ P(x^1, x^2,...,\lambda x_1^n+ \mu x_2^n)= \lambda P(x^1,x^2,...x_1^n)+ \mu P(x^1,x^2,...x_2^n)$$ My definition of differentiability: Let $X$ and $Y$ be normed vector spaces upon the same field $\mathbb R$ or $\mathbb C$ and $U$ an open set in $X$. For a function $f:U \to Y$ it is said to be differentiable in point $x \in U$ if there exists a continuous linear map $A_x:X \to Y$ such that:
$$f(x+h)-f(x)=A_xh+R(h)$$ where $$\lim_{h \to 0}\frac{R(h)}{\|h\|}=0. \text{ or } R(h)=o(h)$$ Now to this example and my question:$$P(x^1+h^1,...,x^n+h^n)-P(x^1,...,x^n)=P(h^1,x^2,...,x^n)+...+P(x^1,...,x^{n-1},h^n)+ \sum P(y^1,...,y^n)\leftarrow\text{In this last sum } y^i=x^i \text{ or }y^i=h^i \text{ where }\\ y^i=h^i \text{ is at least for two indexes }i=1,...,n$$ Now it says that : $P(h^1,x^2,...,x^n)+...+P(x^1,...,x^{n-1},h^n)$is linear which is clear why and then it says: $$\| \sum P(y^1,...,y^n)  \|\leq \sum \|P\| \|y^1 \|...\|y^n \| \leq M \|P\|\|h\|^2\|x\|^{n-2}, M=2^n-n-1 \implies P(y_1,...,y_n)=o(h)$$ My question and confusion now that I have is the following: It seems I can make many different functions that are linear and have $R(h)=o(h)$ for example: $A_x=0$ and $$R(h)=P(y^1,...,y^n)\leftarrow\text{In this last sum } y^i=x^i \text{ or }y^i=h^i \text{ where }\\ y^i=h^i \text{ is at least for on index }i=1,...,n$$ $$\| \sum P(y^1,...,y^n)  \|\leq \sum \|P\| \|y^1 \|...\|y^n \| \leq M \|P\|\|h\|\|x\|^{n-1}, M=2^n \implies P(y_1,...,y_n)=o(h)$$ It is not unique, which it should be, or am I not understanding the idea. Any help?","['differential-topology', 'calculus', 'real-analysis', 'derivatives']"
1380670,"Is Spivak wrong here, or am I just missing something?","Chapter 1 Problem 18 has the reader doing various proofs with second-degree polynomial functions of the form $x^2 + bx + c$. My issue lies with problem 18d, but it uses knowledge from 18b and 18c, so bear with me. Part B has the reader prove that if $b^2 - 4c < 0$ then $x^2 + bx + c > 0$ for all x which was easy enough to show. Part C has the reader prove that if x and y are both not 0, then $x^2 + xy + y^2 > 0$ which was accomplished by substituting $y = b$ and $y^2 = c$ to get $x^2 + bx + c$ and then following the same logic of showing that because $b^2 - 4c = y^2 - 4y^2 < 0$ then $x^2 + xy + y^2 > 0$. Then we get to 18d, where the issue is. The question is: 18 (d) For which numbers $\alpha$ is it true that $x^2 + \alpha xy + y^2 > 0$, assuming x and y are both not 0? from the answer book it says that $\alpha$ must satisfy $(\alpha y)^2 - 4y^2 < 0$ (taken from part B, by substituting  $b$ for $\alpha y$ and c for $y^2$) $\Rightarrow$ $\alpha ^2 < 4$ $\Rightarrow |\alpha| < 2$ but this is clearly not true for many, many examples. Say for instance that we let x = 2 and y = 3 in our equation $x^2 + \alpha xy + y^2$ then any positive $\alpha$ would make $x^2 + \alpha xy + y^2 > 0$ be true. $\alpha$ could equal 612 and the inequality would hold true in that situation. I think the error in logic comes from Spivak's statement that $\alpha$ must satisfy $(\alpha y)^2 - 4y^2 < 0$ because it assumes that it's the only condition in which the polynomial could be positive, but it's clearly not the case. Also, it's easy to solve for the inequality because we can just do some basic manipulation to come up with the solution for $\alpha$ if $x^2 + \alpha xy + y^2 > 0$ then $ \alpha xy > -(x^2 + y^2 )$ then $\alpha > -(\frac{x^2 + y^2}{xy})$ In any case, let me know if there's any faults in my logic, or is there something I'm missing.","['calculus', 'algebra-precalculus']"
1380673,How to show that a statement in sets is false?,"How to show that a statement in sets is false and prove its negation is true? For example I have the exercise: Let's say that $E$ is a non-empty set and $A,B,C$ $\subseteq$$E$.For each $Α,Β,C$ how to show that the equation $(Α-Β)-C=A-(B-C)$ does not apply? Should we try to find a counterexample in these situations?",['elementary-set-theory']
1380683,Permutations minus Transpositions,"I want a formula that allows me to find all the permutations in $S_n$ (which is the set of all the integers from 1 to $n$) which don't contain a transposition. Attempt: Lets call $g(n)$ the formula, then $g(n)=n! - ($$\bigcup\limits_{i=1}^k A_{i}$$
)$, where $A_{i}$ is the set with permutations with only i transpositions. Now I know I need to use the inclusion-exclusion principle, my problem is I'm not able to count the number of permutations with exactly k transpositions. Thanks.","['number-theory', 'group-theory', 'combinatorics']"
1380685,Riemann-Roch Theorem and Ideals of a Ring,"I found in some Math book a comment stating that the study of Ideals in ring theory à la Dedekind (all kinds of ideals? only one-sided ideals?) could be transferred to other areas (specifically, geometry and topology) via something the author referred to as Riemann-Roch Theorem. Could anyone explain a little bit about the theorem and about that alleged connection? The comment goes as follows: ""Hilbert then shows how one of Dedekind's notions of a prime factor or ideal (the different) corresponds to the Riemann-Roch theorem, a geometric and arithmetic fact concerning the topology of Riemann's surfaces""","['ring-theory', 'algebraic-geometry', 'ideals', 'riemann-surfaces']"
1380693,"Show that this difference goes to zero,","$$\frac{1+\sqrt{2} + ... + \sqrt{N}}{N} - \frac{2}{3}\sqrt{N} \to  0.$$ The hint given in the question is this: choose appropriate Riemann sums and estimate the approximation error. My current work: $$\frac{1+\sqrt{2} + ... + \sqrt{N}}{N} - \frac{2}{3}\sqrt{N}$$ $$=: A_n =(\sum_{k=1}^N \sqrt{k}\frac{1}{N}) - \frac{2}{3}\sqrt{N}$$ The first term is in the form of a Riemann sum, so letting N go to infinity, we see that mesh(p) goes to zero, for some partition p, which gives the (improper) Riemann integral, over the interval [1,N]: $$\lim_{N->\infty}\int_1^N \sqrt{x}dx$$ Evaluation of the integral, without evaluating the limit, gives: $$\frac{2}{3}N^{\frac{3}{2}} - \frac{2}{3}$$ Then $$A_n = \frac{2}{3}N^{\frac{3}{2}} - \frac{2}{3} - \frac{2}{3}\sqrt{N}$$ And this is where I am currently stuck.  The above equation is a little suspect, because I let N go to infinity to get the improper integral, while I did nothing with the $\frac{2}{3}\sqrt{N}$ term -- and just included this term into the equation, since I feel it gets me a little closer to do some kind of approximation. Any hints would be greatly appreciated. Thanks,","['calculus', 'limits', 'riemann-sum', 'real-analysis', 'integration']"
1380715,Existence of Lebesgue measure on real line proof help,"I am reading a proof of the existence of Lebesgue measure and am struggling to understand one part. I will first get you up to where I am in the proof. We define for a set written as a finite disjoint union $A=(a_1,b_1] \cup \cdots \cup (a_n,b_n]$ the set function $\mu(A)=\sum\limits_{k=1}^n (b_k-a_k)$. Sets of the form of $A$ above form a ring $\mathcal{A}$ and generate the Borel sigma algebra. In order to apply Caratheodory extension theorem, we must show that $\mu$ is countably additive on $\mathcal{A}$. This is equivalent to showing (from an exercise done previously) that if $(A_n)$ is a decreasing sequence of sets in $\mathcal{A}$ with $\bigcap\limits_n A_n=\emptyset$, then $\mu(A_n)\rightarrow 0$ as $n\rightarrow \infty$. Suppose for contradiction that this fails. Then there exists $\epsilon>0$ such that $\mu(A_n)\geq 2\epsilon$ for all $n=1,2,\ldots$. THIS IS THE BIT I AM STUCK ON.... But then we can find, for each $n$, a set $B_n\in\mathcal{A}$ such that $\overline{B_n}\subset A_n$ and $\mu(A_n\setminus B_n)\leq \epsilon2^{-n}$. If somebody could explain the last line or reword it, I will be extremely grateful. (PS this isn't set work. I am doing it in my holidays as a bit of fun ;))
Thank you in advance!
B.","['lebesgue-measure', 'measure-theory']"
1380716,"Easy question Find $\sin 2x$, $\cos 2x$, and $\tan 2x$","Ok so I was absent from school yesterday because long story short I had no way to get to class b/c something happened last minute. I'm pretty sure this is easy but I keep getting the wrong answer for $\tan2x$. Find $\sin 2x$, $\cos 2x$, and $\tan 2x$ from the given information. $\tan x = -\frac{4}{3}$,   $x$ in Quadrant II So I used the double angle formulas and got $\sin2x = -24/25$ $\cos2x = -7/25$ But I keep getting wrong answers for tangent (I got both $-200/27$ and $-24/7$ somehow). Can someone do a step by step guide on how to get $\tan2x$? Thank you.",['trigonometry']
1380717,Is it possible to find a companion matrix of a polynomial which is also hermitian?,"The eigenvalues of a square matrix $A$ coincide with the roots of its characteristic polynomial $p[A]$. Conversely, if I have a polynomial
$$
a_0 + a_1 x + \cdots + a_{n-1}x^{n-1} + x^n ~,
$$
I can define a companion matrix
$$
A[p]=\begin{bmatrix}
0 & 0 & \dots & 0 & -a_0 \\
1 & 0 & \dots & 0 & -a_1 \\
0 & 1 & \dots & 0 & -a_2 \\
\vdots & \vdots & \ddots & \vdots & \vdots \\
0 & 0 & \dots & 1 & -a_{n-1}
\end{bmatrix}.$$
The characteristic polynomial of the matrix $A[p]$ is the original polynomial $p$. 
The companion matrix defined in this way is not Hermitian. Edit: Consider only hyperbolic polynomials, i.e., polynomials which have only real roots. However, the companion matrix is not the only matrix whose characteristic polynomial is the polynomial $p$. For an example, just consider the diagonal matrix of the eigenvalues ${\rm diag}{(\lambda_1,\lambda_2,\ldots,\lambda_n)}$. This matrix is indeed Hermitian, but one needs to calculate eigenvalues, which can be a difficult task for large matrix sizes. Therefore my question is:
Is it possible to define a ""companion"" matrix (a matrix whose characteristic polynomial is the given polynomial $p$) which is Hermitian, and which is easier to calculate than the diagonal matrix of the eigenvalues ${\rm diag}{(\lambda_1,\lambda_2,\ldots,\lambda_n)}$? With easy to calculate I mean a matrix which can be written in terms of the parameters $a_i$ and without calculating the eigenvalues.","['companion-matrices', 'matrices', 'eigenvalues-eigenvectors', 'hermitian-matrices', 'linear-algebra']"
1380722,Are there papers or books that explain why Bernhard Riemann believed that his hypothesis is true?,"I would like to know what are the mathematical reasons for which Bernhard Riemann believed that his hypothesis is true, and I would like to know if those mathematical reasons were cited in his original paper. My question Here : Are there papers or books or links that explain why Bernhard Riemann believed that his hypothesis is true? Note : I do not want to know if the Riemann Hypothesis is true or false. Thank you for any help","['math-history', 'number-theory', 'riemann-hypothesis', 'reference-request']"
1380746,What does $dx$ mean in a Lebesgue integral?,"This is an introduction for Lebesgue integral of simple function in Carothers' Real Analysis . We say that a simple function $\phi$ is Lebesgue integrable if the set { $\phi$ $\ne$ 0} has finite measure. In this case, we may write the standard representation for $\phi$ as $\phi = \sum_{i=0}^{n} a_i \chi_{A_i}$ , where $a_0 = 0, a_1, .., a_n$ are distinct real numbers, where $A_0 = \{\phi = 0\}, A_1, ..., A_n$ are pairwise disjoint and measurable, and where only $A_0$ has infinite measure, Once $\phi$ is so written, there is an obvious definition for $\int \phi$ , namely, $$\int \phi = \int_{\mathbb R} \phi = \int_{-\infty}^{+\infty} \phi(x) dx = \sum_{i=1}^{n} a_i m(A_i)$$ . I've noticed that wikipedia's definition of Lebesgue integral(see here https://en.wikipedia.org/wiki/Lebesgue_integration ) uses $d\mu$ . So What does $dx$ or $d\mu$ mean in Lebesgue integral? Update: I don't think it is a exactly duplicate one coz I didn't mean using $d\mu$ instead of $dx$ . Before my typing this question, I have read Rodyen's Real Analysis, 3rd and he also uses $dx$ in Lebesgue integral as well. $d\mu$ is just from wikipedia. I have this question in this May when I was reading Caorthers' book and during that time, I treated it as a whole of symbols and being equal to a fixed formula -- $\sum_{i=1}^{n}a_i m(A_i)$ . And then when I was trying to solve some problems with this symbol in Lebesgue integral, I felt weird for quite a while, recalling the Riemann's definition and then realized ""ohhh, man, it is not Riemann integral"".","['real-analysis', 'lebesgue-integral']"
1380750,"How to resolve the issue of two sequences converging to zero for $n, m \to \infty$?","My question is motivated by the following exercise in probability theory: Let $X_n \to X$ in probability and $X_n \geq Y$ a.s. Show that  $X \geq Y$ a.s. I noticed that for all $n, m \in  \mathbb N$: $$P(X < Y) \leq P\left(|X_n - X| > \frac{1}{m}\right) + P\left(X_n < Y+\frac{1}{m}\right)$$ so for the two terms on the RHS holds:
$$\forall m \in  \mathbb N: \ P\left(|X_n - X| > \frac{1}{m}\right) \to 0 \text{ as } n\to \infty$$
$$\forall n \in  \mathbb N: \ P\left(X_n<Y+\frac{1}{m}\right)\to 0 \text{ as } m\to \infty$$ Is there a way to finish the proof from this point? Note that I'm not asking for a proof of the statement (I've seen another one where the issue doesn't come up).","['probability-theory', 'alternative-proof', 'real-analysis', 'sequences-and-series', 'convergence-divergence']"
1380755,"Why do we have ""another"" definition for the kernel?","Why does the definition $\ker(f)=\{(a,a')\in A\times A: f(a)=f(a')\}$ exist?  This definition is for any sort of algebraic system and any sort of function.  But which came first... this definition or the more familiar one?  I haven't seen this used anywhere outside of pure algebra, maybe there are applications in other fields, maybe in functional analysis?  But what's the use?  If a function is injective in this setting then $\ker(f)$ is the diagonal of $A$.  But does this add anything?  Are there isomorphism theorems that use this language?  Do we loose anything or gain anything, when speaking about a function's kernel in this manner? As an example, I had an old homework assignment I found (that prompted me to ask this) Let $f:A\to B$ be surjective.  Then a map $h:A\to C$ can be factored over $f$ (i.e. $h=g\circ f$) for some $g:B\to C$, if only if, $\ker(f)\subset \ker(h)$. If this is the case then the map $g$ is unique. I don't need (or want) a solution to this exercise (I did it years back and posting it here would only take from future students), so please do not post a solution (this is just an example of where the 
""undegraduate"" kernel doesn't work).",['abstract-algebra']
