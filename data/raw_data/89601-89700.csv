question_id,title,body,tags
1200622,"Group of all $2\times2$ matrices where $a$, $b$, $c$, and $d$ are integers modulo $p$, Herstein Q$26$ Page $37$ [duplicate]","This question already has an answer here : Order of group $GL_{2}\left( \mathbb{F}_{p}\right) $ (1 answer) Closed 9 years ago . Let $G$ be group of all square matrices of order $2$ $$\begin{bmatrix} a & b\\ c & d \end{bmatrix}$$ such that $a$, $b$, $c$, and $d$ are integers modulo a prime number $p$, such that $ad-bc\ne0$. $G$ forms a group relative to matrix multiplication. What is order of $G$? I have tried for smaller values of $p$ by explicitly writing matrices. But how do I do this for general $p$. Thanks","['abstract-algebra', 'self-learning', 'group-theory']"
1200624,Compute $\int_{1}^{\infty} \frac{J^2_{n}(k)}{k^m} dk$,"Question as the title showed,in which J means Bessel functions, n and m are positive integers. How to get the analytic result? Any comment is much appreciated. Many thanks in advance.How to simplify  the following formula when $n>2m+1$ and $n$ is odd.","['analysis', 'calculus', 'special-functions']"
1200631,Is there a way to know if the solution curve to a differential equation is an even or odd function?,"Suppose you are given a differential equation and a set of initial conditions (or boundary conditions) pointing to a unique solution.  Is there any way to know off-hand if the solution will be an even function, an odd function, or neither? This is, I suppose, tricky, because the fundamental set of solutions could include both even and odd functions (say, sine and cosine).  The trick is knowing a priori that, for a given set of conditions, the constant coefficient for all of the odd solutions is zero and the constant coefficient for all (or some?) of the even functions are non-zero values.  Or vice versa. Can this be done?",['ordinary-differential-equations']
1200637,Lebesgue Integral: $\int_1^{\infty}\frac{1}{x}$,"The following is an exercise from Carothers' Real Analysis : Show that $$\int_{1}^{\infty}\frac{1}{x}=\infty$$ (as a Lebesgue Integral). Attempt: Let $E=[1,\infty)$. $\int_E f=\int f\cdot \chi_E=\sup\{\int\varphi:\varphi \text{ simple }, 0\leq \varphi\leq f\}\cdot \chi_E$ I'm not sure how to find out what $\sup\{\int\varphi:\varphi \text{ simple }, 0\leq \varphi\leq f\}$ is. (Maybe I can say something about $\sum_{n=1}^{\infty}\frac{1}{n}\cdot \chi_\mathbb{R}$, which diverges since it's the harmonic series?) I note that I can express $E=\bigcup_{n=1}^{\infty}[1,n)$, which is measurable since it is the union of measurable sets. I'm pretty new to the Lebesgue integral so a hint would be preferred over a full solution if possible. Thanks.","['lebesgue-measure', 'real-analysis', 'lebesgue-integral', 'measure-theory']"
1200654,Orbital dimension of the action of $S_n$ on 2-subsets,"I have a question on a proof in a paper on the orbital dimension of a permutation group. Let $G \le S^\Omega$ be a permutation group. A base for $G$ is a subset $\Sigma \subseteq \Omega$ for which the pointwise stabilizer $G_{(\Sigma)}$ is the identity.  The base size of $G$, denoted $b(G)$, is the smallest size of a base for $G$. Suppose $G$ has orbitals $\{R_1,\ldots,R_t\}$ (these are the $G$-orbits on $\Omega \times \Omega$).   Define the color $C(x,y)$ of an ordered pair $(x,y) \in \Omega \times \Omega$ to be the value of $i$ for which $(x,y) \in R_i$.  A resolving set for $G$ is a subset $S = \{x_1,\ldots,x_k\} \subseteq \Omega$ such that for any $y,z \in \Omega, y \ne z$, we have $C(y,x_i) \ne C(z,x_i)$ for some $x_i \in S$.  The orbital dimension of $G$, denoted $\mu(G)$, is defined to be the smallest size of a resolving set for $G$.  It can be shown that every resolving set for $G$ is a base for $G$, whence $b(G) \le \mu(G)$. Let $G$ be the action of $S_n$ on the 2-subsets of $\{1,\ldots,n\}$, and henceforth assume also that $n \equiv 1 \pmod 3$. In Proposition 2.24 of [Bailey and Cameron, ""Base size, metric dimension and other invariants of groups and graphs"", preprint], it is shown that $b(G) = \frac{2}{3}(n-1)$.  In Theorem 3.32, it is shown that a particular set $S$ of size $b(G)$ is not a resolving set for $G$, but augmenting this set $S$ by adding one more element to it gives a resolving set for $G$.  From what I understand, this implies only that $b(G) \le \mu(G) \le b(G)+1$, whereas the authors conclude that $\mu(G)=b(G)+1$.  How is this equality proved?  I can see that $\mu(G)$ is one of $b(G)$ or $b(G)+1$.  But to prove $\mu(G)=b(G)+1$, we need to show that any set $S$ of size $b(G)$ is not a resolving set for $G$. I think the proof of Theorem 3.32 implicitly uses the fact that a base for $G$ that has cardinality $b(G)$ is unique (up to graph isomorphism).  Using this fact and the fact that a resolving set for $G$ is a base for $G$, it follows that if $G$ had a resolving set $S$ of size $b(G)$, then this set $S$ would have to be the unique base for $G$, which can be shown to not be a resolving set, a contradiction.  Uniqueness of minimum bases would thus establish that $\mu(G)=b(G)+1$. Is this what was assumed implicitly in the proof?","['discrete-mathematics', 'algebraic-combinatorics', 'combinatorics', 'algebraic-graph-theory']"
1200655,Integral of $\log(\sin(x)) \tan(x)$,"I would like to see a direct proof of the integral $$\int_0^{\pi/2} \log(\sin(x)) \tan(x) \, \mathrm{d}x = -\frac{\pi^2}{24}.$$ I arrived at this integral while trying different ways to evaluate $\frac{1}{1^2} + \frac{1}{2^2} + \frac{1}{3^2} + ...$ and found this value using the known sum $\frac{\pi^2}{6}.$ It would be better to have a direct way to evaluate this.","['logarithms', 'calculus', 'definite-integrals', 'trigonometry']"
1200665,"If a, b are complex numbers then the maximum value of $\dfrac{a\bar b+\bar ab}{|ab|}$","If a, b are complex numbers then the maximum value of $\dfrac{a\bar b+\bar ab}{|ab|}$ is (A) 2 (B) 1 (C) the expression may not always be a real number and hence maximum does not make sense (D) none of the above. My Steps: Let $a=x+iy$ and $b=p+iq$. Then $$\begin{align}
\dfrac{a\bar b+\bar ab}{|ab|} &= \dfrac{(x+iy)(p-iq)+(x-iy)(p+iq)}{|(x+iy)(p+iq)|}\\
&= \dfrac{2xp+2yq}{(xp-yq)^2+(xq+yp)^2}
\end{align}$$ If I take $y=q=0$ and $x=p=1/n$, the maximum value can be taken to $\infty$. So, is the answer option D ? Please advise.","['complex-numbers', 'algebra-precalculus']"
1200700,Does the vector space of compactly-supported continuous functions $X \rightarrow \mathbb{R}$ satisfy an interesting universal property?,"Let $S$ denote a set. Then the vector space $FS$ freely generated by $S$ can be identified with the set of all finitely-supported functions $S \rightarrow \mathbb{R}$. This gave me the following idea; assume $X$ is a topological space. Then perhaps it is worth studying the set $C_0(X)$ consisting of all compactly-supported continuous maps $X \rightarrow \mathbb{R}$. This is a vector space in its own right, because: finite unions of compact sets are compact finite linear combinations of continuous functions are continuous. Note that if $X$ is a discrete space, then $C_0(X)$ agrees with $FX$, because the compact subsets of a discrete space are precisely the finite subsets. (And also because every function out of a discrete space is continuous.) Question. Does $C_0(X)$ satisfy an interesting universal property? One idea is that we should be thinking about the forgetful functor from the category of topological vector spaces to the category of topological spaces. If there's a sensible way of equipping $C_0(X)$ with a topology, then perhaps it is left-adjoint to the forgetful functor.","['vector-spaces', 'topological-vector-spaces', 'general-topology', 'category-theory']"
1200706,Solve trigonometric equation for x,"Solve for x: $$2 \sin^2 x + \sin 2x = 1$$ I've tried a few strategies, just applying known, standard, equalities to get to some point of understanding. The latest is along the line of trying to work out al cosinuses to sinueses and arrive at a quadratic equation which I could solve using the abc-formula. This got me stuck with something I don't know how to deal with. I'm really just looking for a small hint on how to get further from here or on starting a new strategy, so I can (try to) figure the rest out myself. It's really important I understand this thoroughly, there are a few exercises left in this paragraph I have issues with and I want to be able to solve them all by myself. TL;DR. $$2 \sin^2 x + \sin 2x = 1$$ $$ 2 \sin^2 x + 2 \cos x \sin x = 1$$ Since this isn't my first attempt, I'm just trying to get somewhere... $$ 2 \sin^2 x + 2 \cos x \sin x = \cos^2x + \sin^2 x$$ $$ \sin^2 x + 2 \cos x \sin x - \cos^2 x = 0$$ The above does look alot like something familiar, so I thought perhaps if I get rid of the cosinus... $$ \sin^2 x + 2 \sin(\frac{\pi}{2} - x) \sin x - (1 - \sin^2 x) = 0$$ $$ 2 \sin^2 x + 2 \sin(\frac{\pi}{2} - x) \sin x - 1 = 0$$ Now I don't know how to progess any further, what to do with $\sin(\frac{\pi}{2} - x)$, for example. My strategy is probably just wrong. Where to go from here?","['algebra-precalculus', 'trigonometry']"
1200707,$T$ linear operator s.t. $\lim\limits_{n\to\infty}x_n{=}0_X$ $\Longrightarrow$ $\lim\limits_{n\to\infty}T(x_n){=}0_Y$ then $T$ is bounded,"Let $X$ and $Y$ be two normed spaces, with $X$ a reflexive space.
I suppone that $T:X\rightarrow Y$ is an operator such that: $\lim\limits_{n\to\infty}x_n{=}0_X$ $\Longrightarrow$ $\lim\limits_{n\to\infty}T(x_n){=}0_Y$. I have to prove that $T$ is bounded. Here is my attempt: If $X$ is reflexive, I know that every bounded sequences in $X$ have a subsequence $\{ x_{n_k} \}$ such that $T(\{ x_{n_k} \})$ converges in $Y$. For the sake of contradiction I assume that $T$ is not bounded so there exists a vector $y_n$
such that $\| y_n\| \leq 1$ but $ \| T y_n\| > n^3$. Now let $x_n=\frac{1}{n} y_n$. I have proved in this way that exists a sequence $ (x_{n})_{n \in \mathbb{N}} $ in $ X $ that converges in norm to $ 0_{X} $ (therefore $(x_n)$ is bounded)  but for which $ \| T(x_{n}) \|_{Y} \geq n^{2} $ for all $ n \in \mathbb{N} $. So I have a contraddiction Is my solution correct? Moreover I was wondering if it necessary here the hypothesis that $X$ is a reflexive space. Is there a way to prove this proposition without it? Any help  will be greatly appreciated.","['solution-verification', 'functional-analysis', 'normed-spaces']"
1200729,"Show that {$\phi (x-n), n\in \Bbb{Z}$} is an orthonormal sequence in $L^2(\Bbb{R})$","Let $\phi$ be a compactly supported continuous function such that $\phi (x)=0$ outside of some finite interval. $\phi$ satisfies the following refinable equation: $$\phi (x)=\sum_{k=0}^{M}c_k\phi (2x-k)$$
and $\hat{\phi}(0)=1$ . $\hat{\phi}(\omega)$ is the Fourier transform of $\phi (x)$. I've shown that $\sum_{k=0}^{M}c_k=2$ Show that {$\phi (x-n), n\in \Bbb{Z}$} is an orthonormal sequence in $L^2(\Bbb{R})$ only if $$\sum_{k\in \Bbb{Z}} |\hat{\phi}(\omega + 2k\pi)|^2 = 1, \forall \omega \in \Bbb{R}$$ The question is asking for a biconditional proof so we have to prove both directions. For the forward direction,
Since {$\phi (x-n), n\in \Bbb{Z}$} is an orthonormal sequence, we know that $$
\int_{-\infty}^{\infty} \phi (x-n)\phi (x-m) dx = \left\{\begin{array}{ll}
1 & : n=m\\
0 & : n\neq m 
\end{array}
\right.\ \ \ (*)$$ We have that $$\int_{-\infty}^{\infty} \phi (x-n) e^{-i\omega (x-n)} dx = \hat{\phi}(\omega)\\\Rightarrow \int_{-\infty}^{\infty} \phi (x-n) e^{-i\omega x} dx = e^{-i\omega n}\hat{\phi}(\omega)$$ I'm not sure what to do next. Can I square both sides to try and get to the form of $(*)$ for the case $n=m$? Or am I not doing this correctly? Also I replaced $\omega$ with $\omega + 2k\pi$ but still nothing comes to mind about how to get to the required identity. Will greatly appreciate if someone can work out the reverse direction too, ie given $$
\sum_{k\in \Bbb{Z}} |\hat{\phi}(\omega + 2k\pi)|^2 = 1, \forall \omega \in \Bbb{R}$$
show that {$\phi (x-n), n\in \Bbb{Z}$} is an orthonormal sequence.","['fourier-analysis', 'functional-analysis']"
1200758,Vertical asymptote of $\frac {3x^2 - 18x - 81}{6x^2 - 54}$,"Vertical asymptote of  $f(x) = \frac {3x^2 - 18x - 81}{6x^2 - 54}$ is 3, but why not -3? The original function is already expanded, however, factoring it out a little bit, we get:
$ \frac {3(x-9) (x+3)}{6(x-3)(x+3)}$ The way Salman Khan explained it here didn't really answer that question. To find vertical asymptote of a rational function we see where it's undefined. And it's undefined when denominator is equal to $0$. As you can see from the factored version of the function, x = -3 does make the denominator equal to $0$!","['calculus', 'limits']"
1200778,Continuity of a piecewise function at a specific point,"I am having trouble proving the following function is not continuous at $x = 0$ using a formal definition of continuity. $
f(x) = \left\{
  \begin{array}{lr}
    \sin(\frac{1}{x}) & : x \neq 0\\
    0 & : x = 0
  \end{array}
\right.
$","['epsilon-delta', 'continuity', 'real-analysis', 'functions']"
1200779,Series of inverse function,"$A(s) = \sum_{k>0}a_ks^k$ and $A(s)+A(s)^3=s$.
I want calculate $a_5$. What ways to do it most efficiently?","['power-series', 'discrete-mathematics']"
1200781,Area enclosed by loop on $S^2$,"Let $l:S^1\to S^2$ be a simple closed loop on $S^2$. How do you calculate the area enclosed by this curve (Up to exchange of which ""cap""* you choose?) I wrote ""cap"" because the cap defined by the loop may not be a proper cap, because the loop may not necessarily be a circle on the sphere. EDIT To make it easier, let's say you have a closed simple curve in $\mathbb{R}^2$, then instead of doing $Area=\int\int_{inside\,curve} dx dy$ you would want something like $\int y(x) dx$ where you assume you can express the curve as a function $y(x)$ (if that's not possible perhaps one needs to make several divisions of horizontal lines). Now I'm looking for the analogue of that, moving from $$ \int_{\varphi,\theta\,in\,curve} \sin(\theta)d\theta d\varphi $$ to $$ \int_{\varphi=0}^{\varphi=2\pi} (1-\cos(\theta_l(\varphi))) d\varphi $$ where we assume that $l:S^1->S^2$ defines a function $\theta_l(\varphi)$ which is not always true if the curve bends... but perhaps for starters we can assume that $l:S^1->S^2$ indeed defines a function $\theta_l(\varphi)$.","['geometry', 'spheres', 'integration']"
1200794,When is a rational number a sum of three squares?,"Which rational number $\dfrac pq$ can be written in the form $\left(\dfrac a b \right)^2 + \left( \dfrac c d \right)^2 + \left( \dfrac e f \right)^2$ where $a,c,e,p$ are nonnegative integers and $b,d,f,q$ are natural numbers? It is known that a natural number can be written as sum of 3 squares iff it is not of the form $4^{a-1}(8b-1)$, where $a$ and $b$ is a natural number, due to a result of Legendre. Here by ""squares"" I mean they can be integers or non-integral rational. But I do not know how I can generalize these results to all rational numbers. For the case of 2 squares it is much simpler. For a rational number $\dfrac pq$, if $p$ and $q$ are coprime, then it is a sum of 2 squares iff $p$ and $q$ can be written in terms of 2 squares, i.e. their prime decompositions do not contain a factor of the form $(4a-1)^{2b-1}$, where $a, b$ are natural numbers. But such result does not easily generalize to 3 squares.","['number-theory', 'elementary-number-theory']"
1200799,"Question on showing a bijection between $\pi_1(X,x_0)$ and $[S^1, X]$ when X is path connected.","I am trying to do this question taken from Hatchers algebraic topology and I am struggling to understand the notation and the concepts. As far as I know $\pi_1(X,x_0)$ is the set of end point preserving homotopy classes of loops in X based at $x_0$ and a loop is just a path    $f:I \rightarrow X$ with $f(0)=f(1)$. The question says we can regard $\pi_1(X, x_0)$ as the set of basepoint preserving homotopy classes of maps $(S^1, s_0) \rightarrow (X, x_0)$. This confuses me, does it mean the set of basepoint preserving homotopy class on maps $g:S^1 \rightarrow X$ which map loops in $S^1$ based at $s_0$ to loops in X based at $x_0$? Then how can $\pi_1(X,x_0)$ be regarded as this set? If someone could explain this it would be really useful","['homotopy-theory', 'algebraic-topology', 'general-topology']"
1200803,Continuity of functions of several variables,"trying to understand this example of continuity of a a function on $R^2$ $$f(x,y) := \begin{cases}
    \frac{xy^2}{x^2 + y^2}& \text{if } (x,y) \neq (0,0)\\
    0              & \text{if } (x,y) = (0,0)
\end{cases}
$$ to prove continuity at (0,0) we need to show: $$ \left|{\frac{x_ny_n^2}{x_n^2 + y_n^2} - 0}\right| = \left|{\frac{x_ny_n^2}{x_n^2 + y_n^2}}\right|  \xrightarrow{n \to \infty} 0 ~~~~~~~~~
\text{whenever} (x_n, y_n) \xrightarrow{n \to \infty} (0,0)
$$ can someone explain the above criterion, I am struggling to make sense of it. 
The definition of continuity states $ \lim_{x \to x_0}  f(x) = f(x_0)  $ In this case $x_0~~ is ~~(0,0),$ we need to show that the limit from every direction is approaching $f(x_0)$. Is that right? Thanks for the answers, I get the idea when x, y are scalar variables, but in the text they are vectors defined on a set $D \subset R^n$ with values in $R^k $  and my text has 3 conditions out of which one needs to be satisfied to prove continuity. using the epsilon-delta definition if every component function $f_i~~of ~~ \pmb{f} = (f_1, ...., f_k) $ is continuous at $x_0$ $\pmb{f}(x_n) \to \pmb{f}(x_0)$ as $ n \to \infty $ for every sequence $x_n$ in D for which $x_n \to {x_0}$ I believe it is the 3rd option they are using in the text for the above question and that is the one I am having most difficulty understanding. Can someone please explain the 3rd criterion in plain english.","['sequences-and-series', 'continuity', 'multivariable-calculus', 'limits']"
1200823,Tangent surface of a twisted cubic curve,"I am trying to describe the tangent surface to a twisted cubic curve $C$, i.e. the curve which is given parametrically by $t\mapsto(t, t^2, t^3)$. This surface $S$ is given parametrically by $(t,u)\mapsto(t+u, t^2+2tu, t^3+3t^2u)$. Denote $x=t+u$, $y=t^2+2tu$, $z=t^3+3t^2u$. What is the polynomial equation of $S$ in terms of $x,y,z$?","['algebraic-geometry', 'analytic-geometry']"
1200829,All nilpotent $2\times 2$ matrices,"I want to find all nilpotent $2\times 2$ matrices. All nilpotent $2 \times 2$ matrices are similar($A=P^{-1}JP$) to $J = \begin{bmatrix} 0&1\\0&0\end{bmatrix}$ But how do I find all of these matrices? I do think that the only such cases are $J$ and $J^
T$","['matrices', 'abstract-algebra', 'nilpotence', 'jordan-normal-form', 'linear-algebra']"
1200833,Divergence in probability,"The sequence $(X_n)$ is said to diverge to $+\infty$ in probability if $\mathbb{P}\{X_n>b\}\to 1$ as $n\to\infty$ for every $b\in\mathbb{R}_+$. If  $(X_n)$ diverges to $+\infty$ in probability and $(Y_n)$ converges to $Y$ in probability ($X_n,Y_n,Y$ are real-valued random variables for all $n$), then $(X_n+Y_n)$ diverges to $+\infty$ in probability. Can't seem to start on this one. I even have trouble showing that $\mathbb{P}\{X_n>b-Y\}\to 1$ as $n\to\infty$ for every $b\in\mathbb{R}_+$. Any hints are appreciated.","['probability-theory', 'convergence-divergence']"
1200871,"The minimum of $I_{n,k}=\int_0^{2\pi}\sqrt{3+2\cos(nx)+2\cos(kx)+2\cos(nx+kx)}dx$ is attained for $k=n$","I have the following conjecture: ``For each given $n\in\mathbb{N},\ n\ge 2$ the minimum of the sequence of integrals $I_{n,k}=\int_0^{2\pi}\sqrt{3+2\cos(nx)+2\cos(kx)+2\cos(nx+kx)}dx,\ k=1,2,\dots,n$ is attained for $k=n$''. I checked this for $n=2$ ($I_{2,1}=10.052307$, $I_{2,2}=9.022598$), $n=3$ ($I_{3,1}=9.900680$, $I_{3,2}=9.924421 $, $I_{3,3}=9.022598$), $n=4$ ($I_{4,1}=9.859090$, $I_{4,2}=10.052307$, $I_{4,3}=9.903215$, $I_{4,4}=9.022598$), ..., until $n=50$. The final value of $I_{n,n}$ does not depend on $n$, but it is not very clear for me why this value is the minimum value. Could someone give me a hint on how to proceed? Edit: $\bullet$ The square root is well defined as
\begin{multline*}
3+2\cos(nx)+2\cos(kx)+2\cos(nx+kx)\hfill\\=\Biggl[2\cos\Bigl(\frac{n+k}{2}x\Bigr)\cos\Bigl(\frac{n-k}{2}x\Bigr)+1\Biggr]^2+4\cos^2\Bigl(\frac{n+k}{2}x\Bigr) \sin^2\Bigl(\frac{n-k}{2}x\Bigr)\ge 0
\end{multline*}
for every $k,n,x$. $\bullet$ Since $2\cos(x)+1<0$ iff $x\in\Bigl(\frac{2\pi}{3},\frac{4\pi}{3}\Bigr)$ one can easily deduce that
\begin{align*}
I_{n,n}=I_{1,1}& =\int_0^{2\pi}\sqrt{3+4\cos(x)+2\cos(2x)}dx=\int_0^{2\pi}|2\cos(x)+1|dx\\
& =\int_0^{\frac{2\pi}{3}}(2\cos(x)+1)dx-\int_{\frac{2\pi}{3}}^{\frac{4\pi}{3}}(2\cos(x)+1)dx+\int_{\frac{4\pi}{3}}^{2\pi}(2\cos(x)+1)dx\\
& =4\sqrt{3}+\frac{2\pi}{3}\ \text{for every $n\ge 1$.}
\end{align*} $\bullet$ Let $f$ and $g$ be periodical functions with period $2\pi$. Then
\begin{equation*}
I_{n,k}(f,g)=\int_0^{2\pi}\sqrt{3+2\cos(nx)+2\cos(kx)+2\cos(nx+kx)}+f(kx)+g(nx)dx
\end{equation*}
attains its minimum for $k=n$ if and only if $I_{n,k}$ attains its minimum for $k=n$. $\bullet$ $\sqrt{3+2\cos(nx)+2\cos(kx)+2\cos(nx+kx)}=|1+e^{inx}+e^{i(n+k)x}|$ for every $n,k,x$.","['optimization', 'definite-integrals', 'trigonometry']"
1200887,Expected value complex random variable,"I want to check that if $X: \Omega \to \mathbb{C}$ is a random variable, then the inequality $| \mathbb{E} X| \le \mathbb{E} |X|$ also holds like in the real case. We can write $$X = \Re X + i \cdot  \Im X$$ And $$|X| = \sqrt{(\Re X)^2 + (\Im X)^2}, \ \ \ \mathbb{E}|X|= \int_{\Omega} \sqrt{(\Re X)^2 + (\Im X)^2}$$ $$|\mathbb{E}X| = | \int_{\Omega} (\Re X + i \cdot \Im X) \text{d}P| = | \int_{\Omega} \Re X \text{d}P + i \int_{\Omega} \Im X \text{d}P| = \sqrt{ ( \int_{\Omega} \Re X \text{d}P)^2 +  ( \int_{\Omega} \Im X \text{d}P ) ^2}  $$ What can I use now to finish the argument? Could you give me a hint?","['probability-theory', 'probability', 'random-variables']"
1200916,"Infine Sequence ${1, 3, 2, 3, 1}$","I have an infine sequence where at the end of which the ones are written. Then till infinity we shall do the next procedure: for each segment with ends a and b (inside which the numbers are absent) we shall write in the middle the number a + b Sequence buiding: {${1, 1}$} $-$ {${1, 2, 1}$} $-$ {${1, 3, 2, 3, 1}$} $-$ ${1, 4, 3, 5, 2, 5, 3, 4, 1}$ How many times the positive integer n will be written on a segment?","['sequences-and-series', 'number-theory', 'algorithms', 'recursion']"
1200918,Sums and differences of a set of numbers,"I am trying to prove that, given a set of $25$ positive numbers, it is always possible to choose a pair of them such that none of the other numbers equals either their sum or their difference. For instance, if you take the set to be the numbers from $1$ to $25$, taking $12$ and $24$ will give a sum of $36$ which is not in the set, and a difference of $12$ which is not a different element of the set than the two chosen. I feel like the proof of this is a lot simpler than I am making it. So far I have split the situation into two cases, being able to generalise for evenly spaced numbers by simply suggesting the first element chosen be a number $y \in S$ such that $2ny \in S$ but $3ny \notin S$, where $n$ is the space between each number. Thus these two elements will always give a sum outside of the set and difference of $y$. However, this does not help at all for a random group of numbers and I feel there is a better argument that covers both cases. Considering the problem as a counting argument, I have determined that there are $300$ possible pairs within the set of $25$ numbers. If I can show that there are more pairs than possible sums and differences within the set, I am done. I have considered using a system of triples to express this, i.e. a subset of three elements $\{x_i,x_j,x_k\}$ of $S$ such that $x_i+x_j=x_k$. Thus each triple will give the sum of a pair and the difference of two pairs. However, counting the number of triples becomes difficult. I considered tackling this by counting the number of 'statements' created by each, i.e. sum or difference created by the pairs and triples. Each pair $(a,b)$ would give me a sum and a difference $a+b=c, a-b=d$ for $a,b \in S$ but $c,d$ not necessarily in $S$. Each triple gives me a sum and two differences $x_i+x_j=x_k, x_k-x_i=x_j, x_k-x_j=x_i$ for $x_i,x_j,x_k \in S$. Thus I figure this simplifies the proof into showing that there are more sums and differences created by the pairs than by the triples. Then I just want to show that $300\cdot 2 \geq |T|\cdot3$, where $T$ is the set of triples. Thus $|T| \leq200$. But then again, this doesn't ensure a single pair has neither its sum nor difference within the set, only that at least one pair has one of its sum or difference outside of the set. Argh! The circles begin! Now I am completely stuck. How do I go about proving that the number of triples is below a certain number? Am I going about this in the wrong direction? Have I oversimplified the problem? Any help at all is much appreciated!",['combinatorics']
1200963,Locally Euclidean Hausdorff topological space is topological manifold iff $\sigma$-compact.,"I'd like somebody to specify flaws in my outline of the proof of the above statement. I'm following the definition of topological manifold used in Lee's Introduction to Smooth Manifolds. (it is 2nd countable) Let $X$ to be a Locally Euclidean Hausdorff topological space. $\Rightarrow$: If $X$ is a topological manifold, then it has a countable basis of precompact coordinate balls by a lemma. Therefore, there is a countable set of precompact coordinate balls which cover $X$, and the set of closure of these balls is the set of countably many compact subspaces which cover $X$. Thus, $X$ is $\sigma$-compact. $\Leftarrow$: If $X$ is $\sigma$-compact, there is a set of countably many compact sets which cover $X$. Let $C$ be an arbitrary compact set of this set. Since $X$ (and $C$) is locally Euclidean, $C$ is locally metrizable. Since $C$ is locally metrizable compact Hausdorff space, it is metrizable and therefore 2nd countable. Thus, being the countable union of these compact spaces with countable basis, $X$ is 2nd countable and therefore a topological manifold. Should I add a proof that locally metrizable compact Hausdorff space is metrizable? I found this statement in Munkre's Topology, but is it really a widely known fact?","['differential-geometry', 'manifolds', 'general-topology']"
1200983,Irreducible conics,"An algebraic set (not necessairly a variety) $X \subseteq \mathbb{A}^2$ defined by a polynomial of degree $2$ is called a conic. The problem is: Show that any irreducible conic is isomorphic either to $Z(y-x^2)$ or to $Z(xy-1)$ after an affine change of coordinates in $\mathbb{A}^2$. However, with this definition of conic, I only can conclude that if the polynomial is irreducible, then the conic is irreducible (because $f$ irreducible $\Rightarrow Z(f)=X$ is irreducible) What can I do to prove that if a conic is irreducible, then the polynomial that defines the conic is irreducible? And for the main problem, how can I do the affine change of coordinates? Thanks",['algebraic-geometry']
1200985,"If $\int f\;d\mu=\int g\;d\mu$, then $f\equiv g$ almost everywhere","I'm wondering whether or not the following statement is true: Let $(\Omega,\mathcal{A},\mu)$ be a measure space $f,g:\Omega\to\overline{\mathbb{R}}$ be measurable with respect to $\mathcal{A}$ and $$\int f\;d\mu=\int g\;d\mu$$
Then, $$f\equiv g\;\;\;\text{almost everywhere}$$ Let $h:=f-g$. I know that if $h\ge 0$ almost everywhere, then $h\equiv 0$ almost everywhere iff $\int h\;d\mu=0$. But what can we say in the general case?","['probability-theory', 'analysis', 'real-analysis', 'measure-theory']"
1200986,Mathematical properties of two dimensional projection of three dimensional rotated object,"Please be gentle as I do not have any degree in maths. By using a compass/straighedge method to construct Metatron's cube, a regular dodecahedron can be inferred from intersecting points. I'm looking for the ratio between the lengths of the edges ( blue ) of the dodecahedron and the radius of the initial circle ( red ) used for the construction. What I actually want is to have on of the faces of the dodecahedron, to be a regular pentagon ( purple ) on the two dimensional plane on which it's being projected. If you take a horizontal line through the center of the dodecahedron and rotate the object over that line ( green ). 1. How many degrees does it need to be rotated to make the irregular pentagon below, regular? 2. Is it true that after this rotation, the circle is perfectly inscribed inside the pentagon? EDIT: please understand that the purple pentagon only appears after a rotation of the resulting dodecahedron in 3D space Can I then say that if $r = 1$ then $x = 1.45308505601$ by using the formula for calculating the apothem ($DB$) given the length of a side which is: $$y = \frac{s}{2tan\frac{180}{5}} $$ For $y=1$ that gives $1.45308505601$. (ref: http://www.mathopenref.com/apothem.html )","['geometry', 'linear-algebra', 'analytic-geometry', 'recreational-mathematics']"
1201005,If Matrix $A^3 = 0$ then what will be $I+A+A^2$,"Matrix $A$ is a square matrix such that $$A^3=0$$ then what would be value of $$I+A+A^2=?$$ such that $I$ is unit matrix of same order as $A$ I firstly supposed sum to be $X$ that is 
$X=I+A+A^2$ then 
$$AX=A+A^2+A^3$$
$$AX=A+A^2$$
and multiplying both sides with $A^{-1}$ we get 
$$K=I+A$$ but my answer was incorrect , what is correct solution to this problem?","['linear-algebra', 'matrices']"
1201060,Prove that the limit of $\lim\limits_{x \to 4}{\frac{\sqrt{x}-2}{x-4}} = \frac{1}{4}$,"I was asked to prove, using the definition of limit, that $$\lim\limits_{x \to 4}{\frac{\sqrt{x}-2}{x-4}} = \frac{1}{4}$$ I tried doing it but I am not completely sure my prove is correct. I am publishing it here so that more knowledgeable people can check it for me, maybe pointing any pitfalls. I need to prove that for any $\epsilon > 0$ there is a $\delta > 0$ such that if $0 < \left|x - 4\right| < \delta$ then $\left|\frac{\sqrt{x}-2}{x-4} - \frac{1}{4}\right| < \epsilon$ First part: Tying to find a suitable $\delta$, given an $\epsilon$ $$\left|\frac{\sqrt{x}-2}{x-4} - \frac{1}{4}\right| < \epsilon$$
$$\left|\frac{4(\sqrt{x}-2) - (x-4)}{4(x-4)}\right| < \epsilon$$
$$\left|\frac{4\sqrt{x} - 8 - x + 4}{4(x-4)}\right| < \epsilon$$
$$\left|\frac{4\sqrt{x} - x - 4}{4(x-4)}\right| < \epsilon$$
$$\left|\frac{-x + 4\sqrt{x} - 4}{4(x-4)}\right| < \epsilon$$
$$\left|\frac{-(x - 2\cdot\sqrt{x}\cdot 2 + 4)}{4(x-4)}\right| < \epsilon$$
$$\left|\frac{-(\sqrt{x} - 2)^2}{4(\sqrt{x}+2)(\sqrt{x}-2)}\right| < \epsilon$$
$$\left|\frac{-(\sqrt{x} - 2)}{4(\sqrt{x}+2)}\right| < \epsilon$$
$$\left|-\frac{1}{4}\right| \left|\frac{\sqrt{x} - 2}{\sqrt{x}+2}\right| < \epsilon$$
$$\frac{1}{4} \left|\frac{\sqrt{x} - 2}{\sqrt{x}+2}\right| < \epsilon$$
$$\left|\frac{\sqrt{x} - 2}{\sqrt{x}+2}\right| < 4\epsilon$$
$$-4\epsilon < \frac{\sqrt{x} - 2}{\sqrt{x}+2} < 4\epsilon$$ First inequation:
$$-4\epsilon < \frac{\sqrt{x} - 2}{\sqrt{x}+2}$$
Multiplying by $\sqrt{x} + 2$ (which is positive):
$$-4\epsilon (\sqrt{x}+2) < \sqrt{x} - 2$$
$$-4\epsilon \sqrt{x} -8\epsilon < \sqrt{x} - 2$$
$$ - 8\epsilon + 2 < \sqrt{x} + 4\epsilon \sqrt{x}$$
$$ 2(1 - 4\epsilon) < (1 + 4\epsilon) \sqrt{x}$$
$$ \frac{2(1 - 4\epsilon)}{1+4\epsilon} < \sqrt{x}$$
$$ \left[\frac{2(1 - 4\epsilon)}{1+4\epsilon}\right]^2 < (\sqrt{x})^2$$
$$ \frac{4(1 - 4\epsilon)^2}{(1+4\epsilon)^2} < x$$
$$ \frac{4(1 - 4\epsilon)^2}{(1+4\epsilon)^2} - 4 < x - 4$$
$$ 4\left[\frac{(1 - 4\epsilon)^2}{(1+4\epsilon)^2} - 1\right] < x - 4$$
$$ 4\left[\frac{(1 - 4\epsilon)^2 - (1 + 4\epsilon)^2}{(1+4\epsilon)^2}\right] < x - 4$$
$$ 4\left[\frac{1 - 8\epsilon + 16\epsilon^2 - 1 - 8\epsilon - 16\epsilon^2}{(1+4\epsilon)^2}\right] < x - 4$$
$$ 4\left[\frac{-16\epsilon}{(1+4\epsilon)^2}\right] < x - 4$$
$$ \frac{-72\epsilon}{(1+4\epsilon)^2} < x - 4$$ Second inequation:
$$\frac{\sqrt{x} - 2}{\sqrt{x}+2} < 4\epsilon$$
Multiplying by $\sqrt{x} + 2$ (which is positive):
$$\sqrt{x} - 2 < 4\epsilon (\sqrt{x}+2)$$
$$\sqrt{x} - 2 < 4\epsilon \sqrt{x} + 8\epsilon$$
$$\sqrt{x} - 4\epsilon \sqrt{x} < 8\epsilon + 2$$
$$ (1 - 4\epsilon) \sqrt{x} < 2(1 + 4\epsilon)$$
$$\sqrt{x} <  \frac{2(1 + 4\epsilon)}{1-4\epsilon}$$
$$(\sqrt{x})^2 <  \left[\frac{2(1 + 4\epsilon)}{1-4\epsilon}\right]^2$$
$$x <  \frac{4(1 + 4\epsilon)^2}{(1-4\epsilon)^2}$$
$$x - 4 < \frac{4(1 + 4\epsilon)^2}{(1-4\epsilon)^2} - 4$$
$$x - 4 < 4\left[\frac{(1 + 4\epsilon)^2}{(1-4\epsilon)^2} - 1\right]$$
$$x - 4 < 4\left[\frac{(1 + 4\epsilon)^2 - (1 - 4\epsilon)^2}{(1-4\epsilon)^2}\right]$$
$$x - 4 < 4\left[\frac{1 + 8\epsilon + 16\epsilon^2 - 1 + 8\epsilon - 16\epsilon^2}{(1-4\epsilon)^2}\right]$$
$$x - 4 < 4\left[\frac{16\epsilon}{(1-4\epsilon)^2}\right]$$
$$x - 4 < \frac{72\epsilon}{(1-4\epsilon)^2}$$ Therefore:
$$- \frac{72\epsilon}{(1+4\epsilon)^2} < x - 4 < \frac{72\epsilon}{(1-4\epsilon)^2}$$ Taking the minimum of $\frac{72\epsilon}{(1+4\epsilon)^2}$ and $\frac{72\epsilon}{(1-4\epsilon)^2}$ as the value for $\delta$: $$ \delta = \min\left[\frac{72\epsilon}{(1+4\epsilon)^2} , \frac{72\epsilon}{(1-4\epsilon)^2}\right]$$
$$ \delta = \frac{72\epsilon}{(1+4\epsilon)^2}$$ Second part: Prove Prove that $$ 0 < \left|x-4\right| < \frac{72\epsilon}{(1+4\epsilon)^2} \implies \left|\frac{\sqrt{x}-2}{x-4} - \frac{1}{4}\right| < \epsilon$$ Is it correct so far? How to proceed from here?","['calculus', 'limits', 'epsilon-delta']"
1201062,"Book Suggestion, Analysis (Multivariable Calculus)","I am doing my 4th Analysis course. Now we are doing functions from $\mathbb{R}^{n}$ to $\mathbb{R}^{m}$ And we are talking about differentiabiity . I have a lot of problems understanding the course because geometrically it is not very intuitive. I mean obviously for higher dimensions it's normal that it's not really intuitive, because we can't actually imagine it. But the idea is the same with three dimensions. So can anyone suggest a book that explains the subject and gives geometric intuition to what is going on? Maybe a book that you have studies during your analysis course that helped you with geometric intuition. Looking forward for replies. Thanks!","['analysis', 'book-recommendation', 'multivariable-calculus', 'advice']"
1201070,How to argue Existence of Unique solution of an IVP,"How do I show that there exists a unique solution for this given IVP without solving? Just mere argument. $$\frac{dy}{dx} = \frac{1}{2y\sqrt{1-x^2}}, \qquad y(0)=3$$ I'm having problems with this kind of question because we're not taught of proving without solving. Please help.",['ordinary-differential-equations']
1201071,"Why does it hold $\operatorname{E}[Y\mid\mathcal{F}]=\operatorname{E}[Y\mid Y]=Y$, if $Y$ is $\mathcal{F}$-measurable?","Let $(\Omega,\mathcal{A},\operatorname{P})$ be a probability space $\mathcal{F}\subseteq\mathcal{A}$ be a $\sigma$-algebra on $\Omega$ $Y\in\mathcal{L}^1(\Omega,\mathcal{A},\operatorname{P})$ be measurable wrt $\mathcal{F}$ Then, $$\operatorname{E}[Y\mid\mathcal{F}]=\operatorname{E}[Y\mid Y]=Y$$ From the definition of conditional expectation ( see below ) it's easy to see that we've got $$\operatorname{E}[Z]=\operatorname{E}[Z'],$$ where $Z:=\operatorname{E}[Y\mid\mathcal{F}]$ $Z':=\operatorname{E}[Y\mid\sigma(Y)]=\operatorname{E}[Y\mid Y]$ However, I don't see how we can conclude $Z\equiv Z'$ (almost surely) and $\operatorname{E}[Z']=Y$. Please note: A random variable $Z$ is called conditional expectation of $X$ given $\mathcal{F}$ $:\Leftrightarrow$ $Z$ is $\mathcal{F}$-measurable $\operatorname{E}[1_AX]=\operatorname{E}[1_AZ]$ for all $A\in\mathcal{F}$ We write $\operatorname{E}[X\mid\mathcal{F}]=:Z$. The notation $\operatorname{E}[X\mid X']$, with $X'$ being another random variable, is a shorthand for $\operatorname{E}[X\mid\sigma(X')]$","['probability-theory', 'probability', 'real-analysis', 'measure-theory']"
1201084,Levi-Civita tensor,"Show that $\epsilon_{ijk} A_{il}  A_{jm}  A_{kn}  = \det(A) \epsilon_{lmn}$ where $\epsilon$ epsilon is the standard Levi-Civita symbol and A is a three dimensional matrix. I found the above property in a book used for my course about turbulence, where it is used to prove that the $\epsilon$ is isotropic. The proof for the property however is not provided, and I'm struggling to prove it myself. 
Thanks.","['linear-algebra', 'tensors']"
1201097,Check if a point is inside a rotated 2D NACA 0012 airfoil,"I've already checked the rotated rectangle problem but this is (I think!) a little more complicated. I have a CFD calculation of a 2D NACA 0012 airfoil and I need to test if a point is inside the airfoil or not. 
This is the equation for the airfoil:
$$
y_t = 5tc \left[ 0.2969 \sqrt{\frac{x}{c}} - 0.1260 \, \frac{x}{c}
      - 0.3516 \left(\frac{x}{c}\right)^2 + 0.2843 \left(\frac{x}{c}\right)^3 
      - 0.1015 \left(\frac{x}{c}\right)^4 \right]
$$ The notation I'm using is the following: $c$ -> chord (airfoil length) ; $(x_C,y_C)$ -> coordinates of the $c/2$ (half chord) point of the airfoil ; $(x_0,y_0)$ -> coordinates of the point I need to know if it's inside or outside the airfoil ; For an un-rotated airfoil this is easily done: Check if $(x_C - c/2) < x_0 < (x_C + c/2)$ ; If 1. is true, compute $y_t$ as in the equation above, with $x = x_0 - (x_C - c/2)$; Check if $(y_C - y_t) < y_0 < (y_C + y_t)$; If 1. and 3. are both true, the point is inside the airfoil ; How about for an airfoil with a given angle of attack (like the one bellow)? I've been trying to find an easy way to do this, without much success so far (I was never very good with angles and rotations). My original idea was to rotate my reference frame to be aligned with the rotated airfoil and evaluate 1. trough 4. in that rotated frame. How can I do that? Is there a better way? Thank you for your time.","['coordinate-systems', 'rotations', 'geometry', 'algorithms', 'trigonometry']"
1201187,Find the Inverse Laplace Transforms,"Find the inverse Laplace transform of:
$$\frac{3s+5}{s(s^2+9)}$$ Workings: $\frac{3s+5}{s(s^2+9)}$ $= \frac{3s}{s(s^2+9} + \frac{5}{s(s^2+9)}$ $ = \frac{3}{s^2+9} + \frac{5}{s}\frac{1}{s^2+9}$ $ = \sin(3t) + \frac{5}{s}\frac{1}{s^2+9}$ Now I'm not to sure on what to do. Any help will be appreciated.","['laplace-transform', 'ordinary-differential-equations']"
1201191,Find a Fractional Linear Transformation that maps the region between $\{|z+1| = 1\}$ and $\{|z|=2\}$ to the region between $Im(z) = 1$ and $Im(z) = 2$,"I'm trying to find a Fractional Linear Transformation (if one exists) that maps the region between the circles $\{|z+1| = 1\}$ and $\{|z|=2\}$ to the region between the horizontal lines $\operatorname {Im}(z) = 1$ and $\operatorname{Im}(z) = 2$ . I know that since $-2$ is a point of both circles, I need to find a transformation which has a pole at $-2$ , so the denominator of the transformation should be $z+2$ so that both circles get mapped to parallel lines. From here, I'm getting really stuck.  I know how to find a transformation between two chosen triples, but I'm having trouble figuring out what other two points I need for those triples besides $-2$ and $\infty$ . Any hint or link to a place where I could do some more reading would be really helpful!  Thank you!","['online-resources', 'complex-analysis', 'transformation', 'linear-fractional-transformation']"
1201207,For what numbers does $\lim_{n\to\infty}\sin(2\pi xn!)$ converge,"For any real number $x\in\mathbb R$, when does the following limit converge?
$$
\lim_{n\to\infty}\sin(2\pi xn!)
$$
For $\frac{p}{q}=x\in\mathbb Q$ it converges to $0$ beacuse for any sufficiently large $n:xn!\in\mathbb N$ and then we get $\sin$ of a whole multiply of $2\pi$. (actually you can take $\pi$, not $2\pi$.) My question is, are there any $x\in\mathbb{R-Q}$ such that the limit converges? What about $x\in\mathbb C$?",['limits']
1201235,"stuck with (last) partial integration step for $\int x^2 e^{2x} \, dx$","I am stuck with this integral in the last step of partial integration:
\begin{align}
\int x^2 e^{2x}\,dx & = \frac{1}{2}e^{2x}x^2-\int \frac{1}{2}e^{2x} 2x \,dx \\[6pt]
& = \frac{1}{2}e^{2x}x^2-\int e^{2x} x \, dx \\[6pt]
& = \frac{1}{2}e^{2x}x^2-\frac{1}{2}e^{2x}x-\int \frac{1}{2}e^{2x} \,dx\\[6pt]
& = \frac{1}{2}e^{2x}x^2-\frac{1}{2}e^{2x}x- \frac{1}{2} \int e^{2x} \,dx
\end{align}
I have problems with evalautating the final integral, especially with the factoring of constants (the $\frac{1}{2}$ for the integral. The solution for the last integral is 
$+\frac{1}{4}e^{2x}$, but it seems I have a knot in my brain and can't get the last step right, because I would solve it to $-\frac{1}{4}e^{2x}$...
How does the last step evaluate to positive?","['calculus', 'indefinite-integrals', 'integration']"
1201257,Can every Hausdorff topological space be homeomorphically embedded in a topological vector space?,"It's true that for any metric space, we can isometrically embed it in a Banach space, so that the image of the metric space by that embedding is a linearly independent set. Is the analogous theorem for topological spaces true? Often topological vector spaces are required to be Hausdorff, so with that definition the theorem could only potentially be true for topological spaces which are also Hausdorff. So, to make it clear what I mean, rephrasing the title. Given a topological space $ (X, \tau) $ is it possible to find a topological vector space $ V $ and an embedding (homeomorphic onto the image) $ f:X \rightarrow  V $ such that $ f(X) $ is a linearly independent subset of $ V $? Or can we at least somehow weaken this statement to make it true?","['functional-analysis', 'topological-vector-spaces']"
1201295,"Given two idempotents $a,b \in R$ such that $a+b$ is idempotent then $a$ and $b$ commute.","Let $R$ be a ring with identity. An element $a \in R$ it is idempotent if $a^2=a$. Show that given two idempotents $a,b \in R$ such that $a+b$ is idempotent then $a$ and $b$ commute. Remark : I'm trying the following 
$a+b = (a+b)^2 = (a+b)(a+b) = a^2+ab+ba+b^2 = a+ab+ba+b \Rightarrow ab = - ba$. I am not able to conclude from this, I tried to $(ab)^2 = (-ba)^2$ but I can not conclude. Thanks for your help.","['abstract-algebra', 'idempotents', 'ring-theory']"
1201321,"If $X_1,X_2$ are independent beta then showing $\sqrt{X_1X_2}$ is beta","Here is a problem that came in a semester exam in our university few years back which I am struggling to solve. If $X_1,X_2$ are independent $\beta$ random variables with densities $\beta(n_1,n_2)$ and $\beta(n_1+\dfrac{1}{2},n_2)$ respectively then show that $\sqrt{X_1X_2}$ follows $\beta(2n_1,2n_2)$. I used the Jacobian method to obtain that the density of $Y=\sqrt{X_1X_2}$ is as follows:
$$f_Y(y)=\dfrac{4y^{2n_1}}{B(n_1,n_2)B(n_1+\dfrac{1}{2},n_2)}\int_y^1\dfrac{1}{x^2}(1-x^2)^{n_2-1}(1-\dfrac{y^2}{x^2})^{n_2-1}dx$$ I am lost at this point actually. Now, in the main paper, I found a hint had been supplied. I tried to use the hint but could not obtain the desired expressions. The hint is verbatim as follows: Hint: Derive a formula for the density of $Y=\sqrt{X_1X_2}$ in terms of the given densities of $X_1$ and $X_2$ and try to use a change of variable with $z=\dfrac{y^2}{x}$. So at this point, I try to make use of this hint by considering this change of variable. Hence I get, $$f_Y(y)=\dfrac{4y^{2n_1}}{B(n_1,n_2)B(n_1+\dfrac{1}{2},n_2)}\int_{y^2}^y\dfrac{z^2}{y^4}(1-\dfrac{y^4}{z^2})^{n_2-1}(1-y^2.\dfrac{z^2}{y^4})^{n_2-1}\dfrac{y^2}{z^2}dz$$which after simplification turns out to be (writing $x$ for $z$)$$f_Y(y)=\dfrac{4y^{2n_1}}{B(n_1,n_2)B(n_1+\dfrac{1}{2},n_2)}\int_{y^2}^y\dfrac{1}{y^2}(1-\dfrac{y^4}{x^2})^{n_2-1}(1-\dfrac{x^2}{y^2})^{n_2-1}dx$$ I do not really know how to proceed. I am not even sure that I am interpreting the hint properly. Anyway, here goes the rest of the hint: Observe that by using the change of variable $z=\dfrac{y^2}{x}$, the required density can be expressed in two ways to get by averaging $$f_Y(y)=constant.y^{2n_1-1}\int_{y^2}^1(1-\dfrac{y^2}{x})^{n_2-1}(1-x)^{n_2-1}(1+\dfrac{y}{x})\dfrac{1}{\sqrt{x}}dx$$Now divide the range of integration into $(y^2,y)$ and $(y,1)$ and write $(1-\dfrac{y^2}{x})(1-x)=(1-y)^2-(\dfrac{y}{\sqrt{x}}-\sqrt{x})^2$ and proceed with $u=\dfrac{y}{\sqrt{x}}-\sqrt{x}$. Well, honestly, I cannot understand how one can use these hints: it seems I am getting nowhere. Help is appreciated. Thanks in advance.","['probability-theory', 'probability', 'probability-distributions', 'definite-integrals']"
1201327,Question regarding transformation of function dealing with $\sin(x)$,I know that $\sin\left(x+\dfrac{\pi}{4}\right)$ is $\sin(x)$ shifted to the left by $\pi/4$. But I need to plot $\sin\left(3x+\dfrac{\pi}{4}\right)$ and it seems ( graph ) that it is not achieved by shifting $\sin(3x)$ to the left by $\pi/4$ but more like by $\pi/12$. What am I doing wrong? Must I first write $\sin\left(3\left(x+\dfrac{\pi}{12}\right)\right)$? Why?,"['trigonometry', 'functions']"
1201337,Finding the angle between two points,"First of all, I am doing some mathematical background information for a software I am creating. What I want to achieve is the point on an object rotating towards where the mouse is. Like in tank games, where the turret rotated depending on mouseX and mouseY In terms of programming, this can be achieved by using the atan2 function, that returns an angle between two points (I believe). What I want to do is find the angle between an object, and mouse click. Is there a special maths formula for this? Because my research on google, brings 'atan2' since I'm a programmer. Since most languages have their own maths library, it is abstraction. I want to know how the formula works, in terms of maths. The question is , what is the formula called for this; to find the angle between two points. So my object can rotate towards the mouseX and mouseY position",['trigonometry']
1201352,Easy calculation for room mates,"I have a very simple question which is bugging me. We are 3 roommates and our total electricity bill is $61 this month,
I was home for the whole month,
Friend X was home for 15 days,
Friend Y was home for 20 days now the easy question, how much would each person would pay? My calculation is 61/3=20,33 

Guy X : 20,33 / 2 = 10.16
Guy Y : (20,33 * 2) / 3 = 13.55
Me : 61 - (10.16+13.55) = 37.29 which doesn't make sense at all!!! Help me!!!",['algebra-precalculus']
1201359,Who discovered the first explicit formula for the n-th prime?,I just found out on Wolfram that there is a formula for the n-th prime in terms of elementary functions. I wonder who found it and if he was rewarded for this. The formula ( here ) is: Also shown at http://www.wolframalpha.com/input/?i=prime(n),"['math-history', 'prime-numbers', 'number-theory', 'elementary-number-theory']"
1201363,Tiny arithmetic trigonometry anomaly,"$1.96\sin(149^\circ) + 1.00842\sin(203^\circ) + 0.61446\sin(285^\circ) = 0.02193075901$ But if I calculated each of the terms separately, then add them together, I get a result that is a tiny bit different. $1.96\sin(149^\circ) = 1.009474627$ $1.00842\sin(203^\circ) = -0.3940210846$ $0.61446\sin(285^\circ) = -0.5935227832$ $1.009474627 - 0.3940210846 - 0.5935227832 = 0.0219307592$ The difference between the two answer is tiny: $0.0219307592 - 0.02193075901 = 1.8903 \times 10^{-10}$ But I'm curious why are they different? I don't think I made an arithmetic mistake or any sort of logic mistake in my process.","['arithmetic', 'recreational-mathematics', 'trigonometry']"
1201411,Integrate $3^{-4x^2}dx$ using gamma functions,"I'm having trouble solving this integral from 0 to infinity, I want to get it to the form $e^{-ax}x^b$ , but I can't do it when trying to use tricks such as putting the function to ln then to the power of $e,$ then using the substitution $u=\ln(3^{-4x^2})$ .  Any help is appreciated, thanks","['calculus', 'ordinary-differential-equations']"
1201485,How does $u$-substitution work?,"I'm in an introductory Calculus class and would really like to understand $u$-substitution. So far, I have been able to understand all the concepts but hit a brick wall here. I know that in $u$-substitution, you have $u\cdot\frac{du}{dx}$ and you set whatever $u$ is, well, equal to $u$. However, why is it that you then derive $u$ to get $\frac{du}{dx} = \text{something}$ and must solve for $dx$ and plug in? That's the part that got me lost. I understand what $u$ should be set to, but after that I'm unsure about what actually happens. Could someone guide me (simply) through the process and why $u$-substitution works like this?","['derivatives', 'calculus', 'integration']"
1201492,Is the modus ponens is an axiom in formal logic?,"Modus Ponens is a rule of inference, which is not exactly an axiom. As far as I understand an axiom is a starting point for a proof, while a rule of inference is tools used to make conclusions out the axioms given. So doesnt that make rules of inference axioms themselves? Correct me if im wrong.","['logic', 'discrete-mathematics']"
1201503,Limit proof; can $\varepsilon=\delta$?,"I am wondering about a beginner proof I am trying to do, and also a more general question. I am working on the question, $$\lim_{(x,y) \to (0,0)}\frac{x^2y^2}{x^2+y^2}$$ So I looked at a few cases and it seemed to me that it might be reasonable that the limit is 0, so I tried to do an epsilon delta proof. that is, I am under the impression that if I can show that for any $\epsilon >0$ there exists a $\delta > 0$, such that if $0< \sqrt{x^2+y^2}< \delta $ then  $| \frac{x^2y^2}{x^2+y^2}-0|< \epsilon$ ( also I can remove the absolute value signs because we have only squares). So then I thought I could do something like, $$x^2 \le x^2+y^2 \rightarrow \frac{x^2}{x^2+y^2} \le 1 \rightarrow \frac{x^2y^2}{x^2+y^2} \le y^2 \le x^2+y^2$$ ( using that $y^2 \le x^2+y^2$ as well) But now I am not sure how to proceed, should I say let $\delta=\epsilon$ ? Is that even valid to say. Also, I have not looked at solutions or anything so I am not sure if my work is correct either, so i appreciate any comments/answers! Thankyou.","['multivariable-calculus', 'limits', 'epsilon-delta']"
1201532,Is this proof of an elementary formula for the second derivative correct?,"Let $f : (a,b) \rightarrow \mathbb{R}$  be twice continuously differentiable. I want to rigorously show the well-known formula $$f''(t) = \lim_{h \rightarrow 0} \frac{1}{h^2} ( f(t+h) + f(t-h) - 2f(t)).$$ So define the functions $\epsilon(t,h), \xi(t,h)$ by the following formulas: $$ f'(t) = \frac{f(t+h)-f(t-h)}{2h} + \epsilon(t,h)$$ and $$ f''(t) = \frac{f'(t+h)-f'(t-h)}{2h} + \xi(t,h).$$ By the properties of $f$, $\xi, \epsilon$ are continuous in $t$ for fixed nonzero $h$, and for fixed $t$ tend to $0$ as $h$ tends to $0$. Applying these formulas we get $$f''(t) = \frac{1}{2h} \left( \frac{f(t+2h)- f(t)}{2h} - \frac{f(t)- f(t-2h)}{2h}\right) + \frac{\epsilon(t+h,h) - \epsilon(t-h,h)}{2h},$$ and it's enough to show that the second term goes to $0$ with $h$. But the second term equals $\epsilon'(t_0(h),h)=\xi(t_0(h),h)$ for some $t_0(h) \in [t-h,t+h]$ (the derivative is with respect to $t$ for fixed $h$) and looking at the definition of $\xi$ we see that $ \xi(t_0,h) = f''(t_0) - f''(t_1)$ for some $t_1(h) \in [t-2h,t+2h]$. Finally we see that $$ |f''(t_0)-f''(t_1)| \leq \sup_{x,y \in [t-2h,t+2h]} |f''(x) - f''(y)| \rightarrow 0 \quad \textrm{as} \quad h \rightarrow 0. $$ I use the Mean Value theorem repeatedly above. Is this argument rigorous? Many thanks for helping me.","['calculus', 'real-analysis', 'proof-verification', 'derivatives']"
1201562,"Regarding $\lim \limits_{(x,y,z)\to (0,0,0)}\left(\frac{x^2z}{x^2+y^2+16z^2}\right)$--is WolframAlpha incorrect?","$$      \lim_{x,y,z\to 0}         {zx^2\over x^2+y^2+16z^2}$$ So I am trying to evaluate this limit.. To me, by using the squeeze theorem, it seems that the answer must be zero. I trying using the spherical coordinates, which also gives in the same result. However, WolframAlpha says the limit does not exist . Could I know whether I am missing something or WolframAlpha is incorrect?(as it happens occasionally)","['wolfram-alpha', 'multivariable-calculus', 'limits']"
1201599,Probability on entering direction of a simple random walk,"Let $X(n)$ be a simple random walk on $\Bbb{Z}^2$. Also we define $S_{R} = \inf\{n > 0 : X(n) \notin [-R, R]^2 \} $ : the exit time of the square $[-R, R]^2$, $T_{v} = \inf\{n > 0 : X(n) = v\}$ : the hitting time of the lattice point $v \in \Bbb{Z}^2$, I want to consider two conditional probability $$ p(w \to v) := \Bbb{P}(X(T_v-1) = w \mid T_{v} < S_{R}). \tag{1} $$ In other words, I want to track the entering direction of my random walk when it hits $v$ before it hits the boundary. Now fix $x = (a, b)$ in the open square $(-1, 1)^2$. Then $v = v(R) = (\lfloor aR \rfloor, \lfloor bR \rfloor) \in \Bbb{Z}^2$ and we can consider $$ P(x, e) = p(v+e \to v) \quad \text{for} \quad e \in \{(0, 1), (0, -1), (1, 0), (-1, 0)\} $$ Question. Does $P(x, e)$ converge to $1/4$ as $R \to \infty$ for any $e$? If this is the case, how fast the convergence takes place? An ideal situation for my case would be that we have $$ P(x, e) = \tfrac{1}{4} + \mathcal{O}_x (R^{-1}), \tag{2} $$ where the bound for $\mathcal{O}_x$ behaves quite well away from the origin and the boundary of the square. But my Monte-Carlo simulation seems to suggest that convergence would be slower, so I wonder if we have any tool to analyze this probability. Postscript. I am also interested in the probability of 'last exit direction' $$ q(v \to w) := \Bbb{P}^{v}(X(1) = w \mid T_{v} > S_{R}), \tag{2} $$ but this is easy to analyze for at least two reasons: it does not depend on the history, and the conditioning event holds with high probability. So I omitted this from my question. Addendun. From numerical simulations with $R = 500, 1000, 2000, 4000$ and $x = (0, 0.5)$, I obtained the following log-plot for $$(R, \textstyle \max_e |P(x, e) - 1/4|)$$ as follows: So it seems not pessimistic to expect that (2) is actually true.","['probability-theory', 'probability', 'random-walk']"
1201612,Prove that the algebraic expressions are equivalent.,"$$\frac{3^{k+1}-1}{2} + 3^{k+1} = \frac{3^{k+2}-1}{2}$$ with steps make left hand side = right hand side by modifying one or both expressions Thanks for your help guys, I solved it like this: $$\frac{3^{k+1}-1}{2} + 3^{k+1} = \frac{3^{k+1}-1}{2} + \frac{2*3^{k+1}}{2} = \frac{3^{k+2}-1}{2} $$",['algebra-precalculus']
1201625,Having problems deriving coordinate expression for Lie derivative,"I am having serious problems in deriving the coordinate component expression for Lie derivative of vector fields. I already know how to do that using an outdated coordinate-based approach mostly used in old physics literature, and I also know I can do this in a more simple way by using a coordinate system adapted to my vector field, I want to get the correct form using the definition of the Lie derivative. Some of this might be because of my low understanding of flows. Let $M$ be a real, $n$-dimensional, $C^\infty$ manifold, let $X$ and $V$ be smooth vector fields defined in the neighborhood of a point $p\in M$, and let $ (U,x) $ be a chart so that $p\in U$ and $x(p)=(x^1(p),...,x^n(p))$. Let be $V=V^\mu \partial/\partial x^\mu$ and $X=X^\mu\partial/\partial x^\mu$ in $U$. Let $\Phi^X_t$ be the flow of $X$. If I understand this well, then $$ \frac{d}{dt}\Phi^X_t(p)=X(p). $$ The Lie-derivative should be $$ \left.\mathcal{L}_XV\right|_p=\frac{d}{dt}(\Phi^X_{-t})_*(\left.V\right|_{\Phi^X_t(p)}). $$ My attempt was as follows:
$$ \mathcal{L}_XV|_p[f]=\frac{d}{dt}(V|_{\Phi^X_t(p)}[f\circ\Phi^X_{-t}])= \\ =\frac{d}{dt}(V|_{\Phi^X_t(p)}[f\circ x^{-1}\circ x\circ\Phi^X_{-t}]), $$ then, I try to evaluate the vector field on that massive composition by $$ \frac{d}{dt}(V^\mu(\Phi^X_t)\left.\frac{\partial}{\partial x^\mu}\right|_{x(\Phi^X_t)}(f\circ x^{-1}\circ x\circ\Phi^X_{-t}))= \\ =\frac{d}{dt}(V^\mu(\Phi^X_t)\left.\frac{\partial}{\partial x^\mu}\right|_{x(\Phi^X_{-t})}(f\circ x^{-1})\frac{\partial}{\partial x^\nu}(x\circ\Phi^X_{-t})), $$ and then what? I am not even sure that where I wrote $\partial/\partial x^\nu$, should I have written $d/dt$ instead? In either case, I have no idea how to go any further, and any help is greatly appreciated.","['differential-geometry', 'multivariable-calculus', 'lie-derivative']"
1201642,Is it possible to construct a non-closed plane curve from a closed space curve via the curvature of the latter one,"I'm really stuck on this problem. Let $\alpha:[a,b]\subset \mathbb{R}\to \mathbb{R}^3$ be a smooth arc-length parametrized curve and let $\kappa:[a,b]\to \mathbb{R}$ be its curvature. I know from the ""Fundamental theorem of the local theory of curves"" that, roughly speaking, associated to each smooth non-zero curvature function and smooth torsion function there is a unique regular parametrized curve, up to rigid motions. In particular, defining a smooth non-zero curvature function, there is a unique plane curve associated. Let $\beta:[a,b]\to\mathbb{R}^2$ be the plane curve endowed with the curvature $\kappa$ and suppose that $\alpha(I)$ is a closed curve. Is it possible that $\beta(I)$ be a non-closed curve? I tried to read a paper called ""A differential-geometric criterion for a space curve to be closed"", the author is Hwang Cheng-Chung. But I don't know how to apply it to my problem.",['differential-geometry']
1201676,The Weaver Android app $\rightarrow$ cute combinatorics problem,"There's an Android puzzle app called ""The Weaver"". My question is why every level seems to be solvable in far fewer moves than one might naively think. Here's a link for people who want to play along on their Android devices, but this is not necessary to understand the question. (NB I am nothing to do with promoting this game in any way; I am an end user who just got interested in the mathematics behind the game). It's very easy to explain the objective of this puzzle game. A level looks like this when you start it: and it looks like this when you've finished it: The ribbons ""flow"" from top to bottom and you can twist or untwist two ribbons by tapping on where they meet. You can't change the order of the ribbons going ""in"" (from the top) or their colours. The object is to twist the ribbons around within the rectangular grid so that the ""output"" of the grid matches the small coloured squares. For example, in the game above, initially only one output square is matched -- the green square which is enabling a green ribbon to ""escape"" from the rectangular grid. All other squares don't match and so some ribbon-twisting is needed. A move on a level consists of twisting or untwisting two ribbons (by tapping on them). It's very cute. There is also a ""star"" system, and to get 3 stars in a level you must solve it using the minimum number of ""twists"". As you can see I've done a very bad job at solving level 2.4; I've got no stars at all. There are solutions to this level with fewer twists -- in fact this is obvious, because in my solution here the bottom ""switch"" is switched but it doesn't need to be -- those two orange ribbons could just pass over each other. The question. I worked through the levels of this game, and I was quite surprised to find that even on big boards (the biggest is 6x6) one always seemed to be able to solve them in far fewer moves than I expected. Although the the game's board size never gets bigger than $6\times 6$ and there are also only 6 colours in the app, one can of course just dream about arbitrarily large boards involving arbitrarily many colours. Conjecture On an $a$ by $b$ board, if the level is solvable at all, then it is solvable in at most $a+b-1$ moves (i.e. with at most $a+b-1$ ""untwists""). In particular I am conjecturing that the largest number of twists you need to make is $O(a+b)$ rather then $O(ab)$. Here is what I know about this conjecture. Lemma The conjecture is true if $a=1$. Proof: trivial (there are only $b=a+b-1$ switches on the board). Lemma the conjecture is true if $a=b=2$ Proof: the only counterexample would be a board for which the only solution would be with all four switches switched. But unswitching the top and the bottom switch leads to the same order of ribbon outputs. Lemma The conjecture is true if $ab\leq 20$. Proof: brute force computer search. Note that in this latter case I will allow an arbitrary number of colours (not just 6 as in the app). Lemma The conjecture is true for all 150 levels that come with the game. Proof: brute force check. Lemma For given $a,b\geq1$ there exists a level whose only solution involves $a+b-1$ twists (and in particular my conjecture is best possible). Proof: One checks that the level with $a+b$ distinct input ribbons and which is solved by switching the $a+b-1$ switches comprising the top right and bottom right sides of the grid of switches, has this property (NB the check is rather easier to do once you have played a few levels and got the hang of the combinatorics). I think that's everything I know. Can anyone finish the job by proving my conjecture? [Added two days later] Here is my interpretation of some discussions (now deleted) with Calum Gilhooley -- a group-theoretic interpretation of the conjecture (but it's a slightly strange group-theoretic question). We fix positive integers $a$ and $b$, and define a set $S=\{r_1,r_2,\ldots,r_a,s_1,s_2,\ldots,s_b\}$ of $a+b$ symbols (thought of as the ribbons). Each ""switch"" can be thought of as a transposition, and it's important to note that with the model I'm about to describe, the initial state of the switch is that the ribbons cross so the transposition is actually a transposition (i.e. it can be switched off rather than on). The following picture shows why the convention is sensible -- when all the switches are switched we have something that looks like the identity as you can see from the picture below. We read the transpositions from top to bottom in the picture; if the $r_i$ and $s_j$ are also numbered from top to bottom then the first transposition is $(r_1\ s_1)$, the next two (which commute so can be made in either order) are $(r_1\ s_2)$ and $(r_2\ s_1)$ and so on; at the $n$th step we consider $(r_i\ s_j)$ for $i+j=n+1$ and this goes down to the final transposition $(r_a\ s_b)$. Multiplying all of these $ab$ transpositions together gives us an element $X=(r_1\ s_1)(r_1\ s_2)(r_2\ s_1)\cdots(r_a\ s_b)$. This is the initial state of the board. Now for $S$ a subset of $\{1,2,\ldots,a\}\times\{1,2,\ldots,b\}$ we can consider the element $X_S$ obtained by taking the product representation of $X$ and then removing the transpositions $(r_i\ s_j)$ for $(i,j)\in S$ (and multiplying those that we didn't remove together in the same order as we did to get $X$). Reformulation of the question Is it true that for $S\subseteq\{1,2,,\ldots,a\}\times\{1,2,\ldots,b\}$ the permutation $X_S$ is equal to $X_T$ for some $T$ of size at most $a+b-1$? Here is a special case: is it true that the identity can be written as $X_T$ for some $T$ of size at most $a+b-1$? That's probably a relatively easy question. It's true for $a=b$, that's not hard to check.","['puzzle', 'group-theory', 'finite-groups', 'combinatorics', 'symmetric-groups']"
1201685,Showing closed immersions are stable under base extension without using that they are affine.,"This question is based on question $3.11$ from chapter $2$ of Hartshorne, found on page $92$. Part $a)$ of said question asks to show that closed immersions are stable under base extension. In other words, if $f:Y \rightarrow X$ is a closed immersions and $g:X'\rightarrow X$ a morphism of schemes, then the induced map $f':Z=Y\times_X X' \rightarrow X'$ is also a closed immersion. My question is: How can we prove this without using that a closed immersion is affine? I ask because although I can reduce to the case where $X'$ and $X$ are affine fairly easily, I have not been able to find a proof anywhere (including on related questions such as this one on the site) that doesn't use part $b)$ of the question in Hartshorne, namely that if $X = \operatorname{Spec}A$ then $Y$ is affine, and in fact is the closed subscheme determined by some ideal of $A$. Without this, I can't see how to reduce to the affine case since even if $X$ is affine, the restriction of $f$ to an arbitrary affine piece of $Y$ need not be a closed immersion. Although part $b)$ doesn't rely on part $a)$ and we therefore could use it to prove part $a)$, I can't help but think that if this is what Hartshorne had in mind then he would have switched the order around. This is the first time that I've had to use a later exercise to prove an earlier one and would like to avoid it if at all possible. Of course it's pretty much impossible to prove that such a proof doesn't exist. I would however accept an answer from someone who feels that they have enough experience to say that if such a proof exists they would most likely have seen it, or who can provide some reasonably convincing heuristic argument that it can't be done.","['algebraic-geometry', 'schemes']"
1201689,What happens if singleton set is not closed,"I'm reading Munkres and now is learning the separation axioms. When he starts to discuss regularity and normality, he says ""Suppose one-point sets are closed in $X$"". Our Prof. also didn't explain much in the class. So I'm quite curious what happens if singleton set is not closed. Will it be open in some cases or neither open nor closed? Also I can't come up with an example of such space. For $ x\in X$, $\overline{\lbrace x\rbrace}=\lbrace x\rbrace$ does not seem to depend on the topology or the set. Any explanation will be appreciated.",['general-topology']
1201746,probability measure on space of sequences,"Let $\Omega=\{0,1\}^\infty$. For some $n$, let $B\subset \{0,1\}^n$. I have seen these two statements which make me confused little bit. (1) If $A\subset \Omega$, $A=B\times \{0,1\}^\infty$, and then it says that the probability of $A$ is defined as $$P(A)=|B|/2^{n}.$$ Somewhere else it says, the probability of $\sigma\in\{0,1\}^k$ is given by $$P[\omega:(\omega_1,\omega_2,...,\omega_k)=\sigma]=1/2^k.$$ What is the connection between these two statements? Thanks in advance","['probability-theory', 'lebesgue-measure', 'general-topology', 'measure-theory']"
1201766,"Closed form for ${\large\int}_0^\infty\frac{x\,\sqrt{e^x-1}}{1-2\cosh x}\,dx$","I was able to calculate
$$\int_0^\infty\frac{\sqrt{e^x-1}}{1-2\cosh x}\,dx=-\frac\pi{\sqrt3}.$$
It turns out the integrand even has an elementary antiderivative ( see here ). Now I'm interested in a similar integral
$$I=\int_0^\infty\frac{x\,\sqrt{e^x-1}}{1-2\cosh x}\,dx.$$
Numerically, it is
$$I\approx4.0336314630136915863337257797951491097354689684433117747419802...$$ Is it possible to find a closed form for this integral?","['calculus', 'closed-form', 'definite-integrals', 'hyperbolic-functions', 'integration']"
1201784,Proving isomorphism between linear maps and matrices,"Theorem: Let $V$ and $W$ be finite dimensional vectorspaces over the same field $F$, with dimensions $n$ and $m$ respectively. Suppose also that $\beta$ and $\gamma$ are ordered bases for resp. $V$ and $W$. Then the function $\Psi : \mathcal{L}(V, W) \rightarrow M_{m \times n}(F)$, defined as $\Psi(T) = [T]_{\beta}^{\gamma}$ for an arbitrary $T \in \mathcal{L}(V,W)$, is an isomorphism. Attempt at proof: We need to show that it is bijective, and hence an isomorphism. This means that for every $m \times n$-matrix $A$ we need to find an unique linear map $T: V \rightarrow W$ such that $\Psi(T)=A.$  So let $\beta = \left\{v_1, v_2, \ldots, v_n\right\}$ and $\gamma = \left\{w_1, w_2, \ldots, w_m\right\}$ be ordered bases for $V$ and $W$. Then we know already that there exists an unique linear map $T: V \rightarrow W$ such that for $1 \leq j \leq n$ \begin{align*} T(v_j) = \sum_{i=1}^{m} a_{ij} w_i \end{align*} But this means that $[T]_{\beta}^{\gamma} = A$, so $\Psi(T) = A$. Hence $\Psi$ is an isomorphism. Can someone check if my proof is sound and valid? If not, where did I go wrong? Thanks in advance.","['linear-algebra', 'proof-verification', 'linear-transformations']"
1201789,An equivalence between group cohomology and sheaf cohomology,"I'm recently reading group cohomology from Serre's book local fields, and he uses there the following terminology $H^q(G,A)$ the q-th degree cohomology of G with coefficent in $A$. So i started to think that probably he used this terminology to create an analogy with the cohomology of a space with coefficient in a sheaf. So i started to think that maybe there is a canonical way to turn a sheaf in to a module over the fundamental group, in such a way that fixed points turns out to be global section, so i got to the following question: 1)Is there a natural way to associate to each sheaf(possibly with additional structure) over a (reasonable) space a module over his fundamental group(possibly with additional structure), and possibly the other way around? That is: is there an equivalence between sheaves(possibly with more structure) and modules over the fundamental group(possibly with more structure), inducing isomorphisms on the cohomology(respectively Cech, and group cohomology)? 2)(this is a very wild guess question, but i would be amused if the answer is yes)
Wondering about 1) i started to think that in many cases the obstruction to define a global section comes from the fact that after a non trivial loop(i have the complex logarithm in mind) a local object gets a different value in the starting point; so this seemed to me a possible link between the two concepts: if 1) is true, then the module in 1) should take account of all this local data, and the loops acts exactly via the change of value of the ""multi-function"" after that the loop is performed, in a way that well defined global sections are exactly those that keep fixed by this procedure. Does something like this exist? I know that 2) is not a precise question, but i hope that the link between the 2 concepts that i am asking suggest a reference to a precise statement of the form that i am hoping, from some of you. Many thanks and apologize for the ignorance(in usual life i think about arithmetic)","['sheaf-cohomology', 'homology-cohomology', 'abstract-algebra', 'algebraic-topology', 'group-cohomology']"
1201800,"Calculate the integral $\int_{[0,1]\times[0,1]}\frac{1}{(1-xy)^a}dydx$ for $a>0$","I'm having trouble with the integral $\int_{[0,1]\times[0,1]}\frac{1}{(1-xy)^a}dydx$ for the case in which $a\neq{1}$. For the case in which $a=1$ it was not difficult to calculate the integral and I got the convergent series $\sum_{n=1}^\infty\frac{1}{n^2}$. Now, for the case in which $a>0$ and $a\neq{1}$, first, I calculated the integral $\int_0^1\frac{1}{(1-xy)^a}dy$ and by making a change of variable I got the result $\frac{-1}{x}$($\frac{(1-x)^{1-a}}{1-a}$ - $\frac{1}{1-a}$) which can be simplified to $\frac{1-(1-x)^{1-a}}{x(1-a)}$ (I'm almost sure this is right, but if anyone finds my calculation of this integral with respecto to $y$ is wrong, let me know). So, then I would have to calculate the integral $\int_o^1\frac{1-(1-x)^{1-a}}{x(1-a)}dx$ and this is where I'm stuck. Maybe I should express one of the expressions in the integrand as a series? Or is there any easier approach to the problem? Any suggestions would be appreciated.","['multivariable-calculus', 'definite-integrals', 'integration']"
1201810,"Find integers $a,b,c,d$ such that","is it possible for someone to run a computer search for me to turn up integers $a,b,c,d$ such that $$1+\sqrt{2}+\sqrt{3}+\sqrt{6}=\sqrt{a+\sqrt{b+\sqrt{c+\sqrt{d}}}}$$? Note: I know they exist, I just can't find them.","['number-theory', 'elementary-number-theory', 'algebra-precalculus']"
1201815,Combinatorial interpretation of double factorial.,"Using some basic algebra (and proved afterwards using induction), I found that: $$ 1 \cdot 3 \cdot ... (2n-1) = \frac{(2n)!}{2^n \cdot n!}$$ After a bit of research, I found out that this is known as the 'double factorial', is there a combinatorial interpretation/proof for this result?","['factorial', 'combinatorial-proofs', 'combinatorics']"
1201854,Measure of an elementary set in terms of cardinality,"In Terry Tao's textbook on measure theory and integration, he notes that, given an elementary set $A$, the length of $A$, denoted $|A|$, may be written discretely as $$|A| = \lim_{n \to \infty}\frac{1}{n} \#\left(A \cap \frac{\mathbb{Z}}{n}\right).$$ Intuitively, this makes sense for intervals of whole numbers... Obviously an interval of length 1 contains 1 integer, etc. But, I don't quite see how to prove this explicitly, or how it works for an interval, say $[e,\pi]$. How can one go about explicitly proving this discrete notion of length? Here, $\#$ denotes cardinality. Moreover, $$\frac{\mathbb{Z}}{n} : = \{ \frac{a}{n} \, : \,  a \in \mathbb{Z} \}.$$","['elementary-set-theory', 'cardinals', 'measure-theory']"
1201884,Reversing the order of integration. (Picture included),"I wish to reverse the order of integration. So, I think the original integration is over the region above. So, reversing the order of integration, I split it into two cases. First region (from 0 to 1) comes first, then second region (from -1/2 to 0) comes next. But, I get the wrong answer. Where did I make a mistake?","['calculus', 'multivariable-calculus', 'integration']"
1201885,What is a endomorphism of vector bundle?,"Quick question: When we say $f:E\to E$ is an endomorphism of the vector bundle $\pi:E\to M$, do we require that $f$ maps each fiber $E_p$ to itself, or it could be to another fiber $E_q$? I couldn't find the answer online. Any reference?","['differential-geometry', 'definition']"
1201939,Simple Question About Contour Integration,"If you are integrating $$\int_\gamma y^2\,dz$$ Where $\gamma$ is the line segment from $1$ to $i$. You parameterize the line $$x(t)=1-t$$ $$y(t)=t$$ $$\implies z(t)=1-t+it$$ Now, if you want to use the formula: $$\int_\gamma f(z(t))z'(t)\,dt,$$ would you have the integral $$\int_0^1(t)^2(-1+i)\,dt$$ or would you have $$\int_0^1(it)^2(-1+i)\,dt.$$ I'm assuming its the first integral because you want the imaginary part, which is just $t$ and not $it$.","['contour-integration', 'complex-analysis']"
1201942,A general question about the Collatz Conjecture and finding that integer that doesn't work,"I apologize if this question gets down-voted ahead of time. I've been working on the Collatz Conjecture all day with Python, because that is the language I'm most familiar with (I'm not a CS student, just majoring in math). Below is the function I'm using for your reference during my comments: \begin{align}
T\left(n\right)&=\begin{cases}1 & \text{if}\;n=1\\
T\left(\frac{n}{2}\right) & \text{if}\;n\;\text{is even}\\
T\left(3n+1\right) & \text{if}\;n\;\text{is odd}\end{cases}\tag{1}
\end{align} I've created graphs of the number of iterations vs. the integers up to $10^7$, one of which I've shown below for integers up to $2\cdot 10^6$: I've read on Wolfram's Mathworld that the conjecture has been tested via computers for numbers up to $\approx 5.48\cdot 10^{18}$, which is quite impressive, although I was thinking ahead of time it would have been tested by this time for incredibly large integers given we've had computers for >50 years now. Now to my simple question: would it be true that, given such an integer actually does exist that does not satisfy the conjecture, the smallest such number must be odd because if it is even there must exist a smaller such integer that does not satisfy the conjecture? Further, suppose we did find such an integer. In my writings I've noticed that all integers within the sequences generated by this function eventually break down to a repeat of an earlier sequence. For instance, the following two sequences: $\color{red}{7}$-22-11-34-17-52-26-13-40-20-10-5-16-8-4-2-1 14-$\color{red}{7}$ These are simple, but even more lengthy sequences of numbers I've found break down to prior sequences that have already been computed, and must if we are to end up at $1$ unless it is defining a new sequence to be called by a later one (I wonder what the frequency of this is). But if we find such a number and it is odd, then all other numbers contained within this sequence must also not satisfy the conjecture. But is this true? Or am I thinking of ""not satisfying"" the conjecture in the wrong way? Thank you for your time,","['collatz-conjecture', 'number-theory']"
1201965,Conditional expectation of a bounded random variable,"Suppose we have a bounded random variable $X:(\Omega,\mathcal{F})\rightarrow(\mathbb{R},\mathcal{B})$
  and some other random variable $Y:(\Omega,\mathcal{F})\rightarrow(\mathbb{R},\mathcal{B})$
 . Then the conditional expectation $\mathbb{E}\left[X\mid Y\right]$
  is again a bounded random variable, measurable with respect to $\sigma(Y)\subseteq\mathcal{F}$
 . In particular, we can then find a Borel measurable function $f:\mathbb{R}\rightarrow\mathbb{R}$
  such that $\mathbb{E}\left[X\mid Y\right]=f(Y)$
 . My question is this: Obviously $f\circ Y$
  is bounded, but can I be sure that $f$
  is also bounded? Thank you in advance for any input.",['probability-theory']
1201986,Cauchy's Integral parametric conjugate,"By considering the conjugate of its parametric form, evaluate $$\frac{1}{2\pi i}\int_{\gamma(0;1)}\frac{\overline{f(z)}}{z-a}dz$$ when $|a|<1$ and $|a|>1$, where $f$ is holomorphic in in the disk $(0;R),  R>1$. Typically when doing these kinds of integration and parametrization, $|z|=n$ is given, but it's different in this case (or is it not?). Can someone help me out?","['complex-analysis', 'complex-integration']"
1202022,Generalizing Cauchy-Schwarz for more than two vectors,"For a complex inner product space, $X$, Cauchy-Schwarz inequality states $$ | \langle x,y \rangle |^2 \leq \langle x,x\rangle \cdot \langle y, y\rangle , $$
for any $x,y \in X$.  Equality holds if and only if $x$ and $y$ are linearly dependent.  I noticed that this can be restated as: $$ \left|\begin{array}{cc} 
\langle v_1, v_1 \rangle & \langle v_1, v_2\rangle \\
\langle v_2, v_1 \rangle & \langle v_2, v_2\rangle \\
 \end{array}\right| \geq 0$$ 
with strict equality if $\{v_i \}$ is linearly independent.  Does this (somehow) generalize for $n$ vectors?  That is, does the following hold:  $$ \left|\begin{array}{cccc} 
\langle v_1, v_1 \rangle & \langle v_1, v_2\rangle & \cdots &\langle v_1, v_n \rangle \\
\langle v_2, v_1 \rangle & \langle v_2, v_2\rangle & \cdots &\langle v_2, v_n \rangle \\
\vdots & \vdots & \ddots & \vdots \\
\langle v_n, v_1 \rangle & \langle v_n, v_2\rangle & \cdots &\langle v_n, v_n \rangle
 \end{array}\right| \geq 0$$ At the very least, can we prove that the above determinant is non-zero if $\{v_i \}$ is linearly independent?  I came across this working on a functional analysis problem set, but this isn't a homework problem. EDIT: For those tagging it as a duplicate, I see this as different because this question specifically concerns inequality, and not just proving that the determinant is non-zero if they are linearly independent.  Additionally, this post specifically suggests a connection to Cauchy-Schwarz that isn't mentioned in the other post. As a commenter (Algebraic) pointed out, this matrix is called the Gram matrix of the vectors $\{v_i\}$; Wikipedia states that this matrix if positive semi-definite, and is positive definite in the case where they are linearly independent.  This proves that the determinant is indeed greater than or equal to zero for arbitrary $\{v_i\}$ and is strictly positive in the case where the $\{v_i\}$ are linearly independent.","['linear-algebra', 'functional-analysis']"
1202026,What does $\Bbb{Z}/(2) \times \Bbb{Z}/(3) \times \dots$ do?,"Take the product of rings $M = \Bbb{Z}/(2) \times \Bbb{Z}/(3) \times \dots$ over the primes or in general take any infinite set of quotient modules of a ring $R$ and form their product.  It's true then that a copy of  $R$ lies in the product.  So $\Bbb{Z}$ lies in the infinite product, M. Can any more be said about $M$?  Can we identify all points in $M$ that don't lie in the isomorphic image of $\Bbb{Z}$, into a ""point at infinity"" and also introduce $\Bbb{Z} \cup \{\infty\}$, so that $\Bbb{Z} \cup \{\infty\} \approx M / \sim$ somehow?","['abstract-algebra', 'infinite-product', 'ring-theory']"
1202039,Simplifying $\scriptsize\sqrt{2+\sqrt{2}} + \sqrt{2+\sqrt{2+\sqrt{2}}} + \sqrt{2+\sqrt{2+\sqrt{2+\sqrt{2}}}} + \sqrt{2-\sqrt{2+\sqrt{2+\sqrt{2}}}}$,The question is in the title: is there a simpler form or result for $$\sqrt{2+\sqrt{2}} + \sqrt{2+\sqrt{2+\sqrt{2}}} + \sqrt{2+\sqrt{2+\sqrt{2+\sqrt{2}}}} + \sqrt{2-\sqrt{2+\sqrt{2+\sqrt{2}}}}\quad?$$,"['arithmetic', 'radicals', 'algebra-precalculus']"
1202079,How do you prove that $4^n > n^3$ for all positive integers $n$?,Prove that $4^n > n^3$ for every positive integer $n$ using the Principle of Mathematical Induction. I am well aware of how to use this proof technique. I first showed that P(1) is true: $4^1 > 1^3$. Then I made the assumption that $4^k > k^3$ for an arbitrary positive integer $k$. Thus the goal is to show that $4^{k+1} > (k+1)^3$. So I tried changing the expression to $4^k \times 4 > (k+1)^3$. This is where I am stuck.,"['induction', 'proof-verification', 'algebra-precalculus']"
1202110,How to design a differential equation to match a given general solution?,"I am in a first year differential equations course, and in class on Friday, the teacher did a problem from the book that I wasn't quite sure how to solve (yet I'm sure has a possibility of showing up on a test!). The question I have written in my notes is: ""create a differential equation that has $ y = C_1e^{-2x} + C_2e^{3x} + C_3xe^{3x} + e^x + x^2 + x $ as its general solution"". How would I go about doing this? I see that the general solution has $ C_1e^{-2x} + C_2e^{3x} + C_3xe^{3x} $, meaning the characteristic equation for the homogeneous equation ($Y_h$) should have roots $-2, 3, 3$. I guess for that I should make a polynomial which yields these roots? I also notice that the particular solution ($Y_p$) should be in the form $Ae^x + Bx^2 + Cx$. If we assume the DE I make is in the form $y'' + p(x)y' + q(x)y = f(x)$ - sorry if this isn't standard convention!), then $f(x)$ should contain something like $e^x + x^2 + x$ ? Perhaps I'm way off.",['ordinary-differential-equations']
1202196,Geometric proof of this property of the ellipse,"I came across the following property of the ellipse: The distance from a focus of an ellipse to any point on the ellipse is equal to $a(1-e \cos\theta)$. 
  Where the $a$ is the length of semi-major axis and $\theta$ is the eccentric angle of the point. I can prove this with coordinate geometry but I want a pure geometric proof of it. Please help.","['geometry', 'alternative-proof', 'conic-sections']"
1202208,Can a function $f:\mathbb{R^n} \mapsto \mathbb{R^m}$ where $n<m$ be surjective?,"I have thought about the following problem: We have a function $f$, which has as the domain $A \subseteq \mathbb{R^n}$ and maps its inputs to a higher dimensional space $B \subseteq \mathbb{R^m}$ where it is strictly $n < m$. Can this function be onto (surjective) where it exhausts all members of its codomain $B$ such that each $b \in B$ is mapped from a $a \in A$? For example we can have a function $f:\mathbb{R^n} \to \mathbb{R^m}$ where $n < m$, $f(u)=(x_1(u),x_2(u),\dots,x_m(u))$ with each of the $m$ coordinates is determined by $u \in \mathbb{R^n}$. Such a function should cover only a $n$ dimensional surface or collection of surfaces in $\mathbb{R^m}$ according to my intuition but I cannot show this. Is this intuition true? How can it be shown more or less formally, if it is correct?","['elementary-set-theory', 'algebra-precalculus', 'functions']"
1202223,Associativity of cartesian product and nested ordered n-tuples,"for 3 sets $A,B,C$ 
is $A\times B \times C = A\times (B\times C) = (A\times B)\times C$
OR to be more specific,
is the ordered pair $((a,b),c)=$ ordered triplet $(a,b,c)=$ ordered pair $(a,(b,c))$? Wikipedia states- in another article on Wikipedia (and many other e-books and pdfs on the web)- I think the root of confusion is the nested ordered pairs- is the ordered pair $((a,b),c)=$ ordered triplet $(a,b,c)=$ ordered pair $(a,(b,c))$? Please help","['elementary-set-theory', 'relations']"
1202227,Why is the wedge product associative?,"I have been reading on the wedge product (From Shutz's Geometrical Methods of Mathematical Physics) and I don't quite get why the wedge product is associative. The book defines the wedge product of two $1$-forms as: $$p\wedge q:=p\otimes q-q\otimes p.$$ Now writing down $p\wedge (q\wedge r)$ I get: $$\begin{align}
p\wedge (q\wedge r) &=p\otimes (q\wedge r)-(q\wedge r)\otimes p\\
&=p\otimes (q\otimes r - r\otimes q)-(q\otimes r - r\otimes q)\otimes p\\
&=p\otimes q \otimes r - p\otimes r \otimes q - q\otimes r\otimes p + r\otimes q \otimes p.
\end{align} 
$$ The latter is different from what I've computed doing it the other way, and different from what I've found online, even more, the expression for the wedge product of three forms has six terms everywhere I've looked. Am I misunderstanding something here? Thanks in advance.","['differential-geometry', 'differential']"
1202243,How do i visualize Cosets of a group,"The Lemma asserted in Herstein as given by $[a] = Ha$ seems very non intuitive to me. How do I think in order that this thing makes sense to me? LEMMA 2.4.4 For all $a$ in $G$ ,
  $$Ha = \{ x \in G : a \equiv x \mod H\}$$ Thanks","['abstract-algebra', 'self-learning', 'group-theory']"
1202269,Graphing $x^{3 / 2} + y^{3/2} =1$,"My brother asked me what I thought was a fairly straightforward question, graph the function below over the real numbers: $$ x^{3/2} + y^{3/2} = 1.$$ Now of course, we can't have any negative values in the square roots, so the graph looks 'similar' to the graph of a standard circle in the +X+Y quadrant of the XY plane. This is all well and good, next however; we simply rearranged the formula to: $$ y = \left(\left( 1-x^{3/2}\right)^{1/3}\right)^2$$ And this is where the confusion began. Now, it's clear that substituting a large x value would simply produce a large negative value inside the bracket, squaring this would simply make the value positive. So now the graph of the function contains all of the points that made up the original graph, plus another branch of values: This is unexpected. What step in my algebra permitted these positive values?","['graphing-functions', 'algebra-precalculus']"
1202296,"Proving that $m(E) = 0$ if for all $n$, $\int_E x^n \cos x\, d x = 0$","Suppose that $E\subset [0,2\pi]$ is measurable and $\int_E x^n \cos x\,dx = 0$ for all $n =0,1,2,\cdots$. Then prove that $m(E)=0$. In a non-rigorous fashion, if $\sum_{1}^{\infty} a_nx^n = \sec x$ (the Taylor series), then 
$$m(E) = \int_E 1 dx = \int_E \sum a_n x^n \cos x \overset{?}{=} \sum a_n\int_E x^n \cos x = 0.$$ But I'm unable to show the equality (labeled with a question mark). Can you provide a hint or an answer? This is problem 18.27 from Real Analysis, Carothers (so I think that there is a very elementary solution to this problem without any reference to strong theorems).","['lebesgue-measure', 'measure-theory', 'real-analysis', 'integration', 'lebesgue-integral']"
1202313,Denoting a proper subset,"Let $A = \{1,3, \{1,2\}, \{\{1,3\}\}\}$ Clearly, $\{1,2\}∈A$ is true because $\{1,2\}$ is a element in set $A$, but I'm confused as to why $\{1,2\}⊂A$ is false. Similarly, in this example, $\{\{1,3\}\}∈A$ is true but $\{\{1,3\}\}⊂A$ is false If an element is in a given set, is that element not a subset of the parent set? I could make these subsets using only the members of $A$, so it seems like it should work. I would think that the subsets I could make of $A$ would be denoted by $P(A)$ (all the power sets of $A$) and including the null set $\{$∅$\}$. Any clarification you could provide on this would be greatly appreciated!","['elementary-set-theory', 'discrete-mathematics']"
1202320,$f(x) = (\cos x - \sin x) (17 \cos x -7 \sin x) $,$f(x) = (\cos x - \sin x) (17 \cos x -7 \sin x)$ Determine the greatest and least values of $\frac{39}{f(x)+14}$ and state a value of x at which greatest values occurs. Do I just use a graphing calculator for this? Is there a way I could do this without a graphing calculator?,"['trigonometry', 'functions']"
1202337,Can I know all the elements of a matrix given that I know its sum along one dimension and the fact that it is axisymmetric?,"For this discussion I will assume a 9x9 matrix but my question is for a general nxn matrix. I have a matrix which is not only symmetric along the vertical and the horizontal axis, but is axisymmetric about its center. So for a 9x9 matrix I have the following set of constraints: $$x_{i,j} = x_{k,l}$$ if $$ (i-5)^2+(j-5)^2 = (k-5)^2 + (l-5)^2.$$
It goes without saying that $(i,j)\equiv(5,5)$ is the center of the matrix. I also know the sum of the matrix along one dimension say $$
\begin{matrix}
0 & 1 & 4 & 9 & 12 &9 & 4 & 1 & 0.
\end{matrix}
$$ I was trying to solve it using the lsqlin function in Matlab. However the function accepts a vector $x$ while I have a 2D matrix. Also, I am not able to figure out a way to tell Matlab the set of constraints I have mentioned above (i.e. the constraints imposed by axisymmetry). Before I start digging deeper I wanted to know if such a set of equations will and certainly will have a unique solution. For instance, in the case of a 9x9 matrix I have 81 unknowns and 9 equations (defined by the sum along the dimesion). The axisymmetry provides a few more equations (though I am not sure exactly how many).","['linear-programming', 'matrix-equations', 'matrices']"
1202356,Embed the Klein bottle into the 3-manifold $S^{2} \times S^{1}$,"Can the Klein bottle $K$ be embedded into $S^{2} \times S^{1}$ ? If so, how does it work? If not, what is the obstruction? Thanks in advance.","['differential-topology', 'klein-bottle', 'general-topology']"
1202434,Generating function for reciprocals of Harmonic numbers?,"Find an exponential or ordinary generating function of reciprocal Harmonic numbers. $f(x)=\sum\limits_{n=1}^{\infty} \frac{1}{H_n}\frac{x^n}{n!}$ or $f(x)=\sum\limits_{n=1}^{\infty} \frac{1}{H_n}x^n$ Also, it would be nice to see EGF or OGF for other reciprocals of common ""numbers"", like binomial coefficients, Stirling numbers, Catalan numbers, etc. P.S. I suspect one could use Digamma function here","['generating-functions', 'combinatorics']"
1202491,"Two sequences, same set, different limit","I recently saw a user write a sequence as $\{x_n\}_{n=1}^{\infty}$. This is generally bad notation, since it could lead people to think of the sequence as a set rather than as a sequence, although we (hopefully) all know what they mean. However, this raises the question: when does the set $\{x_n: n \in \mathbb{N}\}$ determine the limit $\lim_{n \rightarrow \infty} x_n$? Clearly, when the set is finite, it can't, e.g. $(1, 0, 0, 0, ...)$ and $(0, 1, 1, 1, ...)$. But if not? More precisely: Let $(x_n)_{n=1}^{\infty}$ and $(y_n)_{n=1}^{\infty}$ be real sequences such that: $\lim \limits_{n \rightarrow \infty} x_n$ and $\lim \limits_{n \rightarrow \infty} y_n$ both exist $\{x_n: n \in \mathbb{N}\} = \{y_n: n \in \mathbb{N}\} =: \mathcal{Z}$ for all $z \in \mathcal{Z}$, the sets $\{n: x_n = z\}$ and $\{n: y_n = z\}$ are both finite. Then do we always have $\lim \limits_{n \rightarrow \infty} x_n = \lim \limits_{n \rightarrow \infty} y_n$?","['sequences-and-series', 'real-analysis']"
1202515,Is $\{x : \sin{\frac{1}{x}} = 0 \}$ open in $\mathbb{R}$?,"The set consists of elements that satisfy $\frac{1}{x} = n\pi$ (or $x = \frac{1}{n\pi}$), but I can't visualize any open balls around any points because this is a trigonometric function in $\mathbb{R^2}$ and we want to check if this is open in just $\mathbb{R}$.","['metric-spaces', 'real-analysis', 'general-topology']"
1202573,"Given all the partitions of a number $N$, how many occurrences are there of a number $K$?","I am wondering about the problem briefly stated in the title.
Given two arbitrary integers $N$ and $K$, with $K<N$, I am interested in how many times the number $K$ appears in all the possible partitions of $N$. I am unsure where the problem complexity lies anywhere in the range from ""trivial"" to ""unsolved"", as my combinatorics/number theory is only elementary. I work with ""huge"" $N$'s so the asymptotic formula of Hardy well applies and the total number of partitions can be found. Now, how to ""count"" in each of them how many $K$'s appear, is a different problem altogether... Many thanks for your help, always the most appreciated.","['number-theory', 'combinatorics']"
1202643,Number Theory : Show that $\sum_{i=0}^\infty$ $ [\frac{n}{2^i}+\frac{1}{2}]$ $=$ $2n$,"I was doing some basic Number Theory problems and came across this problem : Show that for any integer $n$ $\geq$ $1$ ; $$\sum_{i=0}^\infty [\frac{n}{2^i}+\frac{1}{2}] = 2n$$ ; where $[x]$ represents the greatest integer / floor function I am all thumbs , even a hint would suffice P.S. In the book , this question is given in the section on the Greatest Integer Function , perhaps that might help . Also , this is not a homework question , I am just practicing number theory questions on my own from the book","['number-theory', 'ceiling-and-floor-functions', 'elementary-number-theory']"
1202646,Stone–Čech remainder of limit ordinals,"This is a follow-up question on an earlier question about the Stone–Čech compactification of limit ordinals ( Compactifications of limit ordinals ): For a limit ordinal $\alpha$, what is the cardinality of its Stone–Čech compactification  remainder $\alpha^*$? Here are some of my thoughts: We have $|\alpha^*| \leq 2^{2^{|\alpha|}}$ always. If $\alpha$ has uncountable cofinality, then it's well known that $\beta \alpha = \alpha +1$, i.e. we have a 1-point remainder. If $\alpha$ has countable cofinality, then considering the closure of a cofinal sequence in $\beta \alpha$, we find a copy of $\omega^*$ inside of $\alpha^*$, and hence $|\alpha^*| \geq |\omega^*|= 2^{2^{\aleph_0}}$. In particular, if $\alpha$ is a countable limit ordinal, the case is clear. But I am stuck with uncountable limit ordinals of countable cofinality. For example, what is $|\aleph_{\omega}^*|$? By writing 
$$ \aleph_{\omega}=\aleph_0 + (\aleph_0 + \aleph_1) + (\aleph_0 + \aleph_1 + \aleph_2) + \cdots $$
one can find $\aleph_\omega$ many disjoint cofinal sequences, and hence  $|\aleph_{\omega}^*| \geq \aleph_\omega \cdot 2^{2^{\aleph_0}}$. Is there a precise answer?",['general-topology']
1202678,Is a general solution of an ODE always unique?,"Let $y^{(n)} = F(t,y,\dots,y^{(n-1)})$ be an ODE of order $n$. In all treatments of ODEs that I have seen, it is assumed that if $u(t,c_1, \dots, c_n)$ is a general solution of this ODE then it is unique, i.e. $\nexists v: I \subset \mathbb{R} \to \mathbb{R}$ such that $v^{(n)} = F(t,v,\dots,v^{(n-1)}) \ \& \ \nexists c_1, \dots, c_n \in \mathbb{R} : v(t) = u(t,c_1, \dots, c_n)$ . Then they go on to show that if $u$ is a linear combination of linearly independent particular solutions (their Wronskian is nonzero) then it satisfies the ODE and a well-defined IVP. See for example here and here . Shouldn't we prove that all solutions are of this form? And how do we prove this? P.S. I've found that Picard–Lindelöf theorem proves this for a first-order IVP with some additional hypotheses. I am more interested about just the ODE with no initial conditions.",['ordinary-differential-equations']
1202693,Characteristic curves,"I have to solve the initial value problem: $$2u_{xx}(x, t)-u_{tt}(x, t)+u_{xt}(x, t)=f(x, t), x \in \mathbb{R}, t>0 \\ 
u(x, 0)=0, x \in \mathbb{R} \\ 
u_t(x, 0)=0, x \in \mathbb{R}$$ using Green's Theorem. To do that we have to find the characteristic curves, right?? We have the equation $$2u_{xx}-u_{tt}+u_{xt}=f(x, t)$$ This is equal to $$\left (\frac{2\partial^2}{\partial{x^2}}-\frac{\partial ^2}{\partial{t^2}}+\frac{\partial ^2}{\partial{x}\partial{t}}\right )u=f$$ To find the characteristics do we solve the homogeneous equation $$\frac{2\partial^2}{\partial{x^2}}-\frac{\partial ^2}{\partial{t^2}}+\frac{\partial ^2}{\partial{x}\partial{t}}=0$$ ?? EDIT: $$2u_{xx}-u_{tt}+u_{xt}=f \\ \Rightarrow  \left (2\frac{∂^2}{∂x^2}-\frac{∂^2}{∂t^2}+\frac{∂^2}{∂x∂t}\right )u=f \\ \Rightarrow  \left(\frac{∂}{∂x}+\frac{∂}{∂t}\right)·\left(2\frac{∂}{∂x}-\frac{∂}{∂t}\right)u=‌​f$$ The $g(x−t)$ and $h(x+2t)$ are solutions of the homogeneous differential equation $2u_{xx}−u_{tt}+u_{xt}=0$ for any twice differentiable functions. (Or once differentiable?? ) So, the characteristic curves are $x−t=x_0−t_0$ and $x+2t=x_0+2t_0$. Is this correct?? Is the formulation correct??","['curves', 'ordinary-differential-equations', 'partial-differential-equations']"
1202697,Limit of a ratio,"For a positive integer $n$, let $a_n, b_n, c_n, d_n $ be positive integers such that
$$\left(1+\sqrt 2+\sqrt 3\right)^n=a_n+b_n \sqrt 2+c_n\sqrt 3+d_n\sqrt 6$$
Then for large $ n$, find the limit of the expression
$$\frac{a_n^2+b_n^2+c_n^2+d_n^2}{(a_n+b_n+c_n+d_n)^2}$$ I tried some binomial theorem for the expansion, but no progress.","['limits', 'algebra-precalculus']"
