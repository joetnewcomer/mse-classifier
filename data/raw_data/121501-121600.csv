question_id,title,body,tags
1823987,Can path connectedness be defined without using the unit interval?,"Can path connectedness be defined without using the unit interval or more generally the real numbers? I.e., do we need Dedekind cuts or Cauchy convergence equivalence classes of the rational numbers (metric space completion) in order to define any object topologically equivalent to the unit interval? Compared to the definition of connectedness, which only uses open and closed sets, having to use the unit interval to define path connectedness seems somewhat like using a sledgehammer. I suspect that the answer might be no, since for every Hausdorff path connected space, the paths are homeomorphic to the unit interval (at least according to the relevant Wikipedia article). In particular, every locally path-connected Hausdorff space has a bunch of 1-manifolds as subsets. Still it is unclear to me, since it seems like it should be able to specify all of the unit interval's topological properties without having to recourse to its analytic definition. Your thoughts or help would both be greatly appreciated. EDIT: this question probably has something to do with homotopy theory: https://en.wikipedia.org/wiki/Homotopy , with which I am rudimentarily familiar at best.","['general-topology', 'soft-question', 'path-connected', 'connectedness']"
1824079,Re-write a quadratic equation in another form?,$x^2 + \sqrt{2}x = \frac{1}{2}$ I need to find the real solutions for this equation and write it in this form: $$\frac{-\sqrt{A} \pm B}{C}$$ So when I work the problem out with the quadratic equation I get: $x = 0.118121$ I had no idea how to even put that in the form described so I assumed they didn't want me to solve but just put it in that form so I put it as follows: $A = x^2$ $B = \sqrt{2}x$ $C = \frac{1}{2}$ That was wrong also. I'm not really sure what they're asking me to do. I know the answer is:  $x = 0.118121$ but is it even possible to put it in the form described? Any help would be appreciated.,"['algebra-precalculus', 'education', 'quadratics']"
1824110,Sufficient statistic for Uniform distribution.,"We are given that $ X_i \sim U( 0 , \theta )$ where $\theta$ is unknown. We need to find a sufficient statistic. First we write the conditional distribution : $$ f( x_1 ,\ldots ,x_n \mid \theta ) = \frac 1 {(\theta)^n}, \text{ where } ( x_i \leq \theta , i=1,2,\ldots,n).$$ So , we write the conditional distribution as follows : $$ f( x_1 ,\ldots ,x_n \mid \theta ) = {(\theta)^{-n}} \quad ( x_i \leq \theta , i=1,2,\ldots,n) \tag 1$$ where $(1)$ is taken as an indicator function which gives the value zero if $ x_i \notin [0,\theta]$ So if $x_i \in [0,\theta]$ then $ \max(x_i) \in U(0,\theta)$, so, $$ f( x_1 ,\ldots ,x_n \mid \theta ) = {(\theta)^{-n}} \quad ( \max(x_i) \leq \theta)\tag 1$$ And hence the sufficient statistic $\max(x_i)%$ is taken. Now my question is, in a very similar manner $\min(x_i)$ could also be taken, would that be wrong?",['statistics']
1824191,Is it possible to construct such a function in analytical form?,"Suppose $f\left(f\left(x\right)\right)=\sin(x)$ Is it possible to find $f$ in closed form, or any other forms so as to visualize $f(x)$ on $x\in[-\pi,\pi]$? Is it possible to prove the existence and uniqueness of such functions?","['analysis', 'functions']"
1824226,Convergent + divergent $\to$ divergent,"Given sequences $(x_n)$, convergent, but $(y_n)$ is divergent, then $(x_n + y_n)$ is divergent. I am confident that it is true, but having trouble getting the formalities correct. I have tried proof by contradiction, i.e. assuming 
$\forall \varepsilon > 0 \; \exists N \in \mathbf{N}:$
$$ |(x_n + y_n) - L| < \varepsilon \qquad  \forall n > N.$$
This seems to lead me nowhere. Equivalently, trying to find an $\varepsilon$ such that for all $N$ $|(x_n + y_n) - L| \geq \varepsilon$ have not gotten me any further.  Any hints are appreciated.","['real-analysis', 'sequences-and-series', 'analysis']"
1824260,How did Archimedes calculate rational bounds of pi from a 96-gon?,"Archimedes famously determined that $223/71 < \pi < 22/7$ using the 96-gons circumscribed by and circumscribing a circle of unit diameter. But I haven't found a reference that explains the final step, making the rational approximation. For example, the exact perimeter of the circumscribed 96-gon is: $$ 48\sqrt{2-\sqrt{2+\sqrt{2+\sqrt{2+\sqrt{3}}}}} $$ How did Archimedes come up with 223/71 from that?",['geometry']
1824339,Notation for enumerating a set,"Is there a common notation for enumerating a set? For example if $A=\{2,4,6,\ldots,n \}$ is the set of even numbers, I would like to know the notation that enumerates ordered pairs $(e,i) \in \operatorname{enumerate}(A)$, where $e$ is the $i$:th element of $A$. So the sequence would be $(2,1),(4,2),\ldots,(n,m)$. Would $(e,i) \in \operatorname{enumerate}(A)$ be ambiguous or is there a more common way of describing this kind of enumeration?","['notation', 'elementary-set-theory']"
1824345,Determine whether a random binary sequence was generated by human or natural process,"Given a binary sequence, how can I calculate the quality of the randomness? Following the discovery that Humans cannot consciously generate random numbers sequences , I came across an interesting reference : "" A professor of probability would have half of his class write down a list of zeros and ones from a bunch of coin tosses and the other half write down a list of zeros and ones that they would try to make look random. The professor could sort out the papers with only a glance at each paper. "" What method would be suitable to replicate the professor's act, i.e. judging which sequence is likely to be generated by a random process? A method I have in mind is: for a given sequence-length $ n $ , establish the
frequencies of each possible sub-sequence in the population of all possible sequences and than compare these with a particular sequence. As this very quickly becomes impractical (the number of sub-sequences grows exponentially with $ n $ ) the method may, instead, only measure a subset of all sub-sequences, e.g. all sequences of same digit. How good would such a method work? What are some better methods?","['probability-theory', 'random', 'random-variables', 'probability-distributions']"
1824355,dom(A) is a Banach space w.r.t. the Graph-norm,"Let $X$ and $Y$ be Banach spaces and let $A:dom(A)\to Y$ be a linear operator, defined on a linear subspace $dom(A)\subset X $. Prof that the graph of $A$ is a closed subspace of $X\times Y$ if and only if $dom(A)$ is a Banach space w.r.t. the graph norm. The graph norm of A on the vector space $dom(A)$ is the norm function $dom(A)\to [0,\infty):x\mapsto\Vert x\Vert_A$ defined by:
\begin{equation}
\Vert x \Vert_A:=\Vert x \Vert_X+\Vert Ax\Vert_Y
\end{equation}
for $x\in dom(A)$. Sketch of my solution: First assume that $graph(A)\subset X\times Y$ closed. So let $(x_n,y_n)\in graph(A)$ be a sequence with $\lim_{n\to \infty}(x_n,y_n)=(x,y)$ and let $(x_n)_{n\in \mathbb{N}}$ be a cauchy sequence in $dom(A)$ w.r.t. the graph norm. That is for every $\varepsilon>0$ it exists a integer $N$ s.t. 
\begin{equation}
\Vert x_n-x_m  \Vert_A=\Vert x_n-x_m\Vert_X+\Vert Ax_n -Ax_m\Vert_Y<\varepsilon
\end{equation} 
We also have that, since $X$ and $Y$ are both Banach space and by assumption the graph(A) is closed, so $X\times Y$ is a Banach space too: Fix $\varepsilon > 0 $ s.t.
\begin{equation}
\Vert (x_n,y_n)-(x,y) \Vert=\Vert x_n-x\Vert_X+\Vert y_n-y\Vert_Y<\varepsilon
\end{equation}
where $\Vert y_n-y\Vert_Y=\Vert A(x_n-x)\Vert_Y$. And the last line is exactly the deffinition of the Graph-norm. I'm really not sure about my solution, could someone tell me if I'm on the right track or not? Thank you.","['functional-analysis', 'banach-spaces', 'inner-products']"
1824375,How do I find all solutions to $\cos(x)^4-\sin(x)^4 = 1$,"The interval, when graphing this function, is that the equation is true every $x \in \{0,\pi,2\pi,3\pi\dots\}$ but how do I prove that this is the only solution? My assumption is that the solution $\cos(x)^2+\sin(x)^2=1$ could help me out, but I haven't really figured it out.",['trigonometry']
1824384,Why is a absolutely and uniformly convergent series in the complex plane holomorphic?,"Suppose I have some series $f(z) = \sum_{k = 0}^\infty a_n(z)$, with $a_i$ holomorphic on $\mathbf{H}$, that is absolutely convergent for all $z \in \mathbf{H}$ and uniformly convergent on compact subsets of the upper half plane $\mathbf{H}$. My lecture notes state that $f(z)$ then is holomorphic as a function on $\mathbf{H}$. But why is that so? Thanks!","['complex-analysis', 'holomorphic-functions', 'sequences-and-series']"
1824402,Proving that a function is surjective,"I want to prove that the function $\mathbb{N}_0 \times \mathbb{N}_0 \rightarrow \mathbb{N}_0$ defined as $(x,y) \mapsto 2^x \cdot (2y + 1) - 1$ is bijective. I have already proven that it is injective, but cannot figure out how to prove the surjectivity, since all other examples that I have seen only have 1 variable (i.e. $\mathbb{N} \rightarrow \mathbb{N}$).","['functions', 'elementary-number-theory']"
1824431,How would you find the roots of $x^3-3x-1 = 0$,"I'm not too sure how to tackle this problem. Supposedly, the roots of the equation are $2\cos\left(\frac {\pi}{9}\right),-2\cos\left(\frac {2\pi}{9}\right)$ and $-2\cos\left(\frac {4\pi}{9}\right)$ How do I start? The Cosines seem especially scary...","['algebra-precalculus', 'roots', 'polynomials']"
1824437,Prove $\int_0^{\pi/2} J_0 (\cos x) dx=\frac{\pi}{2} \left(J_0 \left(\frac{1}{2} \right)\right)^2$,"I got curious about this integral because we have the following identity: $$\frac{2}{\pi}\int_0^{\pi/2} \cos (x\cos t) dt=J_0(x)$$ So we have an interesting (if useless) symmetry: $$\int_0^{\pi/2} J_0 (\cos x) dx=\frac{2}{\pi}\int_0^{\pi/2}\int_0^{\pi/2} \cos (\cos x \cos t) ~dt~dx=\int_0^{\pi/2} J_0 (\cos t) dt$$ Wolfram Alpha doesn't show a closed form for this integral. However, if we use the series for the Bessel function: $$J_0(x)=\sum_{k=0}^\infty \frac{(-1)^k x^{2k}}{4^kk!^2}$$ And the known closed form for the family of integrals: $$\int_0^{\pi/2} \cos^{2k} (x) dx=\frac{\sqrt{\pi}}{2}\frac{\Gamma \left(k+\frac{1}{2} \right)}{k!}$$ We obtain: $$\int_0^{\pi/2} J_0 (\cos x) dx=\frac{\sqrt{\pi}}{2} \sum_{k=0}^\infty \frac{(-1)^k \Gamma \left(k+\frac{1}{2} \right)}{4^kk!^3}$$ Wolfram Alpha evaluates this series, giving a closed form for the integral: $$\int_0^{\pi/2} J_0 (\cos x) dx=\frac{\pi}{2} \left(J_0 \left(\frac{1}{2} \right)\right)^2=1.3834405\dots$$ This agrees with the numerical value. However, I have not been able to show this myself. How do we prove this closed form? Is there a more general case, involving Bessel functions of order $n$?","['special-functions', 'definite-integrals', 'sequences-and-series', 'bessel-functions']"
1824477,"Compact Sets of $(X,d)$ with discrete metric","Let $X \neq \emptyset$. Define the discrete metric on $X$ with:
  $
    d(x,y)=\left\{\begin{array}{ll} 1, & x \neq y \\
         0, & x=y\end{array}\right.$ (a) Ascertain the compact sets in $(X,d)$. (b) Ascertain the continuous functions $f: X \to \mathbb{R}$. I'm really confused about this tasks because I don't know what I have to do exactly. My ideas: (a) First all sets in (X,d) are open and closed, because in a ball $B(x,r)$ there is only the element $x$ and all singletons are open. So $\bigcap F_{open}, F \subset X$ is open too. The complement of these $F$ are closed. So all sets are open closed. How I ascertain the compact sets in $(X,d)$? This means one can find unlasting open covers for $X$, but how far I can find the compact sets with these information? (b) Unfortunately I haven't any idea.. Thanks for helping!","['continuity', 'general-topology', 'metric-spaces', 'elementary-set-theory']"
1824490,Value of the given limit.,"What is $$\lim _{ x\rightarrow 1 }{ \frac { x\log { \left( x \right) -x+1 }  }{ \left( x-1 \right) \log { \left( x \right)  }  }  } $$ 
 Note I have used $\lim _{ x\rightarrow 0 }{ \frac { \log { \left( 1+x \right)  }  }{ x }  } =1$ . So I wrote $\log(x)=\log(1+x-1)$ and hence I got $\frac{x^2-2x+1}{x-1}$ after cancelling I got the value as $0$. But the correct answer is $\frac{1}{2}$. Where's my mistake? Any hint. I don't want Lhospital rule or Taylor series if they aren't compulsory to work out the answer .","['limits-without-lhopital', 'limits']"
1824494,How to find explicit formula for two recursions?,"I have to find explicit solution for two intertwining recursions $$\begin{align}
f(n)&=f(n-2)+2g(n-1) \\
g(n)&=g(n-2)+f(n-1)
\end{align}$$ for $f(0)=1, f(1)=0, g(0)=0 ,g(1)=1$. What techniques are commonly used for this types of problem? Thanks!","['recurrence-relations', 'recursion', 'sequences-and-series']"
1824504,Proving Bijections,"i'm working on this question here but I am having some trouble: $f: ℝ ⇒ ℝ$, $f(x) = x^3 - 6x$. A) Is $f(x)$ injective? B) Is $f(x)$ surjective? C) Is $f(x)$ bijective? My attempted solution: A) $f(x)$ is injective if and only if $f(x) = f(y)$ $⇒$ $x = y$ $⇔$ $x^3 - 6x = y^3 - 6y$ $⇔$ $x(x^2 - 6) = y(y^2 - 6)$ $⇔$ $x(x - √6)(x + √6) = y(y - √6)(y + √6)$ I saw this step in a similar example but don't understand exactly what is going on here, an explanation would be great At this point I imagine from that last line above these $2$ values for x are derived from it?($0$ and $√6$) $f(0) = x^3 - 6x$ $=$ $0^3 - 6(0) $ $= 0$ $f(√6) = x^3 - 6x$ $= √6^3 - 6(√6)$ $= 0$ $∴ f(x)$ is not injective since $f(0) = 0 = f(√6)$ B) To show f(x) is surjective, we can assume $y =  x^3 - 6x$(a bit stuck on this step, or maybe there is nothing that can be done ∴ I know it's not surjective right away?) $y =  x^3 - 6x $ what more can I do from here? C) Regardless of figuring out part B or not, I still know that $f(x)$ is not a bijection since it's not injective. Thanks!",['discrete-mathematics']
1824548,"if the equation $(x-2)e^x+a(x-1)^2=0$ have two real roots,Prove $a>0$","if the equation $$(x-2)e^x+a(x-1)^2=0,x\in R$$ have two real roots. show that $$a>0$$ Following is a  solution since
$$-a=\dfrac{(x-2)e^x}{(x-1)^2}$$
Let $$g(x)=\dfrac{(x-2)e^x}{(x-1)^2}\Longrightarrow  g'(x)=\dfrac{e^x(x^2-4x+5)}{(x-1)^3}$$
so we have $$x>1,g'(x)>0\Longrightarrow g(x)\in (-\infty,+\infty)$$ and 
$$x<1,g'(x)<0\Longrightarrow g(x)\in (-\infty,0)$$ then have following Fig if $-a=g(x)$ have two real roots,then $-a<0$,so we have $a>0$ $\color{red} {Is ~there ~any ~other~ solution?and ~I~ want ~more ~solution}$",['functions']
1824597,"Given that $f(x)=\frac{1}{x^n}$, show that $x f'(x)+n f'(x)=0$.","This exercise was in my math book and of course had no solution as it's a ""show"" type of question. I don't see how this could hold except for when $x=-n$. Given that $f(x)=\frac{1}{x^n}$, show that $x f'(x)+n f'(x)=0$.",['derivatives']
1824603,Evaluate $\frac{0!}{4!}+\frac{1!}{5!}+\frac{2!}{6!}+\frac{3!}{7!}+\frac{4!}{8!}+\cdots$,$$\frac{0!}{4!}+\frac{1!}{5!}+\frac{2!}{6!}+\frac{3!}{7!}+\frac{4!}{8!}+\frac{5!}{9!}+\frac{6!}{10!}+\cdots$$ This goes up to infinity. Trying finite cases may help. My Attempt :It seems that it is going to be $\frac{1}{18}$. My calculations show that its going near $\frac{1}{18}$.,"['factorial', 'sequences-and-series', 'calculus']"
1824620,Correlation between lagged Brownian motions.,"Say I have two Brownian motions $X^1$ and $X^2$. Say they have constant correlation $\rho$. Then of course I know the correlation between $X^1_t$ and $X^2_t$. Furthermore I know that correlation between $X^1_t $ and $X^1_s$ is $min(t,s)$. Do I know the correlation between $X^1_t - X^1_s$ where $t> s$ and $X^2_t$ ? I can not recollect ever seeing a result regarding anything like this.","['stochastic-processes', 'probability-theory', 'probability']"
1824638,"Calculus question with circle, and string tracing an area","The figure shows a piece of string tied to a circle with a radius of one unit. The string is just long enough to reach the opposite side of the circle. Find the area of the region, not including the circle itself that is traced out when the string is unwound counterclockwise and continues counterclockwise until it reaches the opposite side again.",['calculus']
1824639,How do I calculate the integral $\int_{0}^{1}{\frac{xe^{ax}}{(1+ax)^2}dx}$? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question If $a>0$, how do I calculate the following integral? $$\int_{0}^{1}{\frac{xe^{ax}}{(1+ax)^2}dx}$$","['multivariable-calculus', 'integration', 'definite-integrals']"
1824725,Minimal polynomial of block matrix,"I'm trying to prove that the minimal polynomial of a diagonal block matrix i.e. a matrix $A = \begin{bmatrix}
       B & 0           \\[0.3em]
      0 & C       \\[0.3em]
     \end{bmatrix}$ is the less common multiple of the minimal polynomials of matrix B and matrix C. Well I checked down the answer that the user @AndreasCaranti gave here: Minpoly and Charpoly of block diagonal matrix However there is a crucial aspect of the proof that I would like to have some clarification please: ""the minimal polynomial $m(x)$ of $A$ vanishes when computed on each block do the minimal polynomial $m_i(x)$ of the $i$-th block divides $m(x)$"". Why? Is this a property of block matrices? Why does the minimal polynomial of each block divides the matrix. Thanks!","['matrices', 'block-matrices', 'minimal-polynomials']"
1824750,"A variation of Ahmed's integral $\int_{0}^{1} \frac{(x^2+4)\sin^{-1}x}{x^4-12x^2+16} \, dx $","Given that the closed form exist, evaluate the following Integral: $$\int\limits_{0}^{1} \frac{(x^2+4)\sin^{-1}x}{x^4-12x^2+16} \, dx $$","['integration', 'definite-integrals', 'contour-integration', 'complex-integration']"
1824751,Show that d generates the discrete topology,"Let X be any set, and let d be the discrete metric on X. Show
  that d generates the discrete topology. I just want  know if my following proof is valid or not: The discrete topology is the power set of X, which is
the set of all subsets of X. This means that in the Discrete Topology all sets are open. With the Discrete Metric all points can have a ball with radius between 0 and 1, that will contain only that individual point. This leads to the fact that all set are both open and closed under the Discrete Metric. Therefore the discrete metric generates the discrete topology.","['general-topology', 'metric-spaces', 'proof-verification']"
1824773,$\int \limits_{E}|f|d\mu<\varepsilon$ whenever $\mu(E)<\delta$.,"Suppose $f\in L^1(\mu)$. Prove that to each $\varepsilon>0$ there exists a $\delta>0$ such that $\int \limits_{E}|f|d\mu<\varepsilon$ whenever $\mu(E)<\delta$. Proof: Let $\varepsilon>0$ be given and $E$ be an arbitrary measurable set. Since $\int \limits_{E}|f|d\mu=\sup \limits_{0\leqslant s \leqslant |f|} \int \limits_{E}sd\mu$, there exists a simple measurable function $s(x)=\sum \limits_{i=1}^{n}\alpha_{i}1_{A_i}$ with $0\leqslant s \leqslant |f|$ such that: $$\left(\int \limits_{E}|f|d\mu\right)-\frac{\varepsilon}{2}\leqslant \int \limits_{E}sd\mu \Rightarrow \int \limits_{E}|f|d\mu\leqslant \left(\int \limits_{E}sd\mu\right)+\frac{\varepsilon}{2}$$
Let's wotk with last integral: $$\int \limits_{E}sd\mu=\sum \limits_{i=1}^{n}\alpha_i\mu(A_i)\leq \max\{\alpha_1,\dots, \alpha_n\}\sum \limits_{i=1}^{n}\mu(A_i)=\max\{\alpha_1,\dots, \alpha_n\}\mu(E)=L\mu(E)$$ where $L=\max\{\alpha_1,\dots, \alpha_n\}$. Taking $\delta=\frac{\varepsilon}{2L}$(if $L>0$, otherwise is obvious), for all $\mu(E)<\delta$, we get: $$\int \limits_{E}|f|d\mu<\frac{\varepsilon}{2}+L\mu(E)<\frac{\varepsilon}{2}+L\frac{\varepsilon}{2L}=\varepsilon$$ Sorry if this topic is repeated but I would like to know is my proof correct? EDITED VERSION: Since $|f|$ is measurable on $X$ and $\int \limits_{X}|f|d\mu=\sup \limits_{0\leqslant s\leqslant |f|}\int \limits_{X}sd\mu$. Let $\varepsilon>0$ be given then exists simple measurable function $s: 0\leqslant s\leqslant |f|$ on $X$ such that $\int \limits_{X}|f|d\mu-\dfrac{\varepsilon}{2}\leqslant \int \limits_{X}sd\mu$, where  $s=\sum \limits_{i=1}^{n}\alpha_i1_{A_i}$ where $\alpha_1, \dots, \alpha_n$ are distinct positive reals and $A_i=\{x: s(x)=\alpha_i\}$. Also $\sqcup_{i=1}^{n}A_i=X$. Note that for any $E\in \mathfrak{M}$ we have $$\int \limits_{E}(|f|-s)d\mu \leqslant \int \limits_{X}(|f|-s)d\mu\leqslant \frac{\varepsilon}{2}.$$
Taking $\delta=\dfrac{\varepsilon}{2L},$ where $L=\max\{\alpha_1,\dots,\alpha_n\}$. Note that $\delta$ in this case does not depends on $E$! Hence for $E$ with $\mu(E)<\delta$ we have: $$\int \limits_{E}|f|d\mu\leqslant \frac{\varepsilon}{2}+\int \limits_{E}sd\mu\leqslant \dfrac{\varepsilon}{2}+\sum \limits_{i=1}^{n}\alpha_i\mu(A_i\cap E)\leqslant \dfrac{\varepsilon}{2}+L\sum \limits_{i=1}^{n}\mu(A_i\cap E)$$$$\leqslant \dfrac{\varepsilon}{2}+L\mu((\sqcup_{i=1}^nA_i)\cap E)=\dfrac{\varepsilon}{2}+L\mu(E)=\varepsilon.$$","['real-analysis', 'measure-theory', 'proof-verification']"
1824782,Prove that $\int_{0}^{1}{(1-x)(x-3)\over 1+x^2}\cdot{dx\over \ln{x}}={\ln{8\over \Gamma^4(3/4)}}$,Prove $$I=\int_{0}^{1}{(1-x)(x-3)\over 1+x^2}\cdot{dx\over \ln{x}}=\color{blue}{\ln{8\over \Gamma^4(3/4)}}\tag1$$ $(1-x)(x-3)=-x^2+4x-3$ $${1\over 1+x^2}=\sum_{n=0}^{\infty}(-1)^nx^{2n}\tag2$$ $$I=-\sum_{n=0}^{\infty}(-1)^n\int_{0}^{\infty}{x^{2n+2}-4x^{2n+1}+3x^{2n}\over \ln{x}}dx\tag3$$ Rewrite (3) to apply Frullani's theorem $$I=-\sum_{n=0}^{\infty}(-1)^n\int_{0}^{\infty}{x^{2n+2}-x^{2n+1}-3x^{2n+1}+3x^{2n}\over \ln{x}}dx\tag4$$ $$I=\sum_{n=0}^{\infty}(-1)^{n-1}\ln\left({2n+3\over (2n+2)^4}\cdot{(2n+1)^3}\right)\tag5$$ This method is a bit boring method! I converted (1) into series and using Frullani's theorem and again have to solve the series is another step before we can reached our answer. How can I solve (1) without using series?,"['calculus', 'improper-integrals', 'integration', 'definite-integrals', 'sequences-and-series']"
1824797,Show that $\sum_{d\mid f} \varphi(f/d) a^{|d|} \equiv 0 \pmod f$,"This equation is correct when $f$ and $a$ are any integers. I want to show that this holds for $f,a\in K[x]$ where $K$ is any finite field. In the equation $\varphi(f)$ is defined as $|(K[x]/(f))^\times|$, the number of units in the quotient ring and $|d|$ defined as $|K[x]/(d)|$, the number of elements in the quotient ring. I tried many ways to prove this equation but I only know the proof of the integer case using group theoretic counting arguments and it is not easy to use them for polynomials. Edit : The proof for integers is based on the Polya counting. If you have a finite group $G$, acting on a finite set $\Omega$ and if $a$ is any integer, we have $\sum_{g\in G} a^{c(g)}\equiv 0 \pmod{|G|}$ where $c(g)$ is the number of orbits of the action of $\langle g\rangle$ on $\Omega$. (This fact follows easily from simple orbit counting formula and Polya counting) If we take $G$ as the cyclic group of order $n$ in this argument and let it act on itself via right multiplication, then for any $d$ dividing $n$, we have $\varphi(n/d)$ distinct elements of order $n/d$ and the subgroup generated by these elements form exactly $d$ different orbits on $G$ (cosets of the subgroup which is generated by them). Thus the result follows. It is not clear to me how to generalise this fact to polynomials since group theoretic counting arguments hold only for integers as I know.","['combinatorics', 'algebraic-number-theory', 'polynomials', 'group-theory']"
1824815,Help to simplify $\arctan\left(\frac{\sqrt{1 + x^2} -1}{x}\right)$,"Can someone help me simplify the argument of $\arctan$ in this problem ?
$$\arctan\left(\frac{\sqrt{1 + x^2} -1}{x}\right)$$",['trigonometry']
1824830,Monotone Convergence theorem for decreasing sequence,"Suppose $f_n: X\to [0, \infty]$ is measurable for $n = 1, 2, 3, \dots$, $f_1 \geqslant f_2 \geqslant f_3 \geqslant \dots \geqslant 0,$ $f_n(x) \to f(x)$ as $n\to \infty$, for every $x\in X$, and $f_1 \in L^1(\mu)$. Prove that then
$$\lim \limits_{n\to \infty}\int \limits_{X}f_nd\mu= \int \limits_{X}fd\mu$$
and show that this conclusion does not follow if the condition ""$f_1 \in L_1 (\mu)$"" is omitted. Proof: $$f_1 \geqslant f_2 \geqslant f_3 \geqslant \dots \geqslant 0 \implies -f_1 \leqslant -f_2 \leqslant -f_3 \leqslant \dots \leqslant 0 \implies 0\leqslant f_1-f_2\leqslant f_1-f_3\leqslant \dots\leqslant f_1.$$ In other words, sequence $g_n=f_1-f_n$ is increasing & measurable and $g_n(x)\to f_1(x)-f(x)$ for each $x\in X$ and we can use Monotone convergence theorem: $$\lim \limits_{n\to \infty}\int \limits_{X}g_nd\mu=\lim \limits_{n\to \infty}\int \limits_{X}(f_1-f_n)d\mu=\int \limits_{X}(f_1-f)d\mu.$$ If $f_1\in L^1(\mu)$ then $f_n\in  L^1(\mu)$ for each $n\in \mathbb{N}$ and $f\in L^1(\mu)$ then: $$\int \limits_{X}f_1d\mu-\lim \limits_{n\to \infty}\int \limits_{X}f_nd\mu=\int \limits_{X}f_1d\mu-\int \limits_{X}fd\mu$$ since $\int \limits_{X}f_1d\mu$ is finite we can subtract it and we get what we need! $\color{red}{Wrong \quad Counterexample:}$ Condition $f_1\in L^1(\mu)$ is crucial! Suppose the we omit this condition. Let $X=\mathbb{N}, \mathfrak{M}=2^{\mathbb{N}}$ and $\mu=|\cdot|$ is counting measure on $\mathfrak{M}$. Suppose $f_n(x)=\dfrac{1_{A_n}(x)}{n}$ where $A_n=\{1,2,\dots, n\}$. It's easy to check that $f_n(x)\to 0$ as $n\to \infty$ for $x\in X$. But $\int \limits_{X}f_nd\mu=\frac{1}{n}\mu(A_n)=1.$ So $$1=\lim \limits_{n\to \infty}\int \limits_{X}f_nd\mu\neq \int \limits_{X}fd\mu=0$$ Is my proof and its counterexample correct?
Would be very grateful for any suggestions & comments. EDIT: Let's consider triple $(X,\mathfrak{M},\mu):=(\mathbb{N},2^{\mathbb{N}},|\cdot|)$, where $|\cdot |$ - counting measure on $2^\mathbb{N}$. Let $A_n=\{n, n+1,\dots\}$.
Suppose that $f_n(x)=\dfrac{1_{A_n}}{n}$. It's easy to see that $f_1\geqslant f_2\geqslant \dots \geqslant f_n\geqslant \dots \geqslant 0$. Also note that $f_n(x)\to f(x)=0$ as $n\to \infty$ for $x\in X$. Also $\int \limits_{X}f_nd\mu=\dfrac{1}{n}\mu(A_n)=\infty.$ Hence $$\infty=\lim \limits_{n\to \infty}\int \limits_{X}f_nd\mu\neq\int \limits_{X}fd\mu=0.$$ Is it true?","['monotone-functions', 'real-analysis', 'measure-theory', 'proof-verification']"
1824848,Solve this differential equation.,How should I approach this problem? $$\dfrac{dy}{dx}=1+y^{2}$$ given that $y (2) = 0$.,"['ordinary-differential-equations', 'calculus']"
1824907,Partial fraction decomposition of $\pi\cdot \tan(\pi z)$,"Evaluate the partial fraction decomposition of $\pi \tan(\pi z)$ $$2\pi \tan(\pi z)=\cot\left(\frac{\pi}{2}-\pi z\right)-\cot\left(\frac{\pi}{2}+\pi z\right)$$ $$=\frac{2}{1-2z}+\sum_{k=1}^\infty \frac{1-2z}{(\frac{1}{2}-z)^2-k^2}-\frac{2}{1+2z}-\sum_{k=1}^\infty \frac{1+2z}{(\frac{1}{2}-z)^2-k^2}$$
$$=\frac{8z}{1-4z^2}+\sum_{k=1}^\infty \frac{4-8z}{1-2z+4z^2-4k^2}-\sum_{k=1}^\infty \frac{4+8z}{1+2z+4z^2-4k^2}$$
I know that the result should be $$\pi \tan(\pi z)=\sum_{k=1}^\infty \frac{8z}{(2k+1)^2-4z^2}$$ but I dont know how to get there.
Any suggestions?","['complex-analysis', 'partial-fractions', 'sequences-and-series', 'analysis']"
1824910,How to get the coordinates of the center of the ellipse after approximation,"I create an algorithm recognizing ellipses in images. I have five coordinates (points) possible ellipse. (8.8) (7.4) (6.3) (3.6) and (2.2) I use the formula of the conical section of the second order: $Ax ^ 2 + Bxy + Cy ^ 2 + Dx + Ey + F = 0$ And determines the type of conic section by the value of the discriminant. $B ^ 2-4AC$ Where, if the sign of the value < 0 , then this ellipse. On the basis of the coordinate values I find A, B, C, D, E, F . (Calculates them here ) A = 0.0763889 
B = -0.0902778 
C = 0.0763889 
D = -0.312500 
E = -0.312500 
F = 1.00000 But I do not know what to do next calculations. How do I need to get the coordinates of the center of the ellipse, the length of its two axes, and rotation about the coordinate axes? Thank you!","['quadratics', 'conic-sections', 'ordinary-differential-equations', 'discrete-mathematics']"
1824951,How is the kernel of a group action defined?,Question: Show that the kernel of the group action of $G$ acting on set $A$ is equal to the kernel of the corresponding permutation representation of this action. I'm lost in this definition as I am only familiar with the definition of a kernel of a homomorphism as $\{g \in G~|~\varphi(g) = I_A\}$ (the elements of the domain in which the image is the identity of the target group) How is this definition applicable to a map $f: G\times A \to A$ in which the target domain is a set?,"['group-actions', 'group-theory']"
1825002,"Real Analysis, Folland Theorem 1.19 Borel Measures","I made a post about this theorem before. But I decided to create a new post to see if I am proving this theorem correctly. Theorem 1.19 - If $E\subset \mathbb{R}$ , TFAE: a.) $E\in M_{\mu}$ b.) $E = V\setminus N_1$ where $V$ is a $G_{\delta}$ set and $\mu(N_1) = 0$ . c.) $E = H\cup N_2$ where $H$ is a $F_{\sigma}$ set and $\mu(N_2) = 0$ Proof a.) implies b.) - If $E\subset\mathbb{R}$ and $E\in M_{\mu}$ then by lemma 1.17 $$\mu(E) = \inf\{\sum_{1}^{\infty}\mu((a_j,b_j)):E\subset \bigcup_{1}^{\infty}(a_j,b_j)\}$$ so, $E\subset \bigcup_{1}^{\infty}(a_j,b_j)$ and $\bigcup_{1}^{\infty}(a_j,b_j)$ is open. Let $U_n = \bigcup_{1}^{\infty}(a_j,b_j)$ then clearly $U_{n+1}\subseteq U_n$ that contains $E$ such that $$\mu(E) > \mu(U_n) - \frac{1}{n}$$ Thus, $$\mu(E)\geq \mu\left(\bigcap_{1}^{\infty} U_n\right)$$ Since by monotonocity, $\mu(E)\leq \mu(U_n)$ for all $n$ , this implies that $$\mu(E) = \mu\left(\bigcap_{1}^{\infty}U_n\right)$$ Set $V = \bigcap_{1}^{\infty}U_n$ and $N_1 = \left(\bigcap_{1}^{\infty}U_n\setminus E\right)$ then clearly $E = V\setminus N_1$ where $V$ is a $F_{\delta}$ set and $\mu(N_1) = 0$ . Thus a.) implies b.). Proof a.) implies c.) Following the same reasoning as above we see that taking the complement of $V$ and setting equal to $H$ we get $$H = \bigcup_{1}^{\infty}U_n^c$$ which is a $F_{\sigma}$ set. Recall that $$E = V\setminus N_1 = V\cap N_1^c$$ and $$(V\cap N_1^c)^c = H\cup N_1$$ where $N_1 = \left(\bigcap_{1}^{\infty}U_n\setminus E\right)$ and $N_1^c = \bigcup_{1}^{\infty}U_n^c\cup E$ set $N_1^c = N_2$ since $\mu(N_1) = 0$ then $\mu(N_2) = 0$ and thus a.) implies c.). Proof c.) implies a.) not sure I am not sure if this is correct any suggestions is greatly appreciated.","['real-analysis', 'measure-theory']"
1825018,Is there a mathematical statement that is linking integer limits to real limits?,"I saw a question asking for the limit $$\lim_{n \to \infty}\frac{\tan(n)}{n}.$$ At first I thought that the limit assumed $n$ to be a real number. So I gave the advice to use $\pi/2+2\pi k$ and $2\pi k$ as two sequences with different limits. The real limit for $x\to \infty$, in which $x \in \mathbb{R}$, is much easier to handle than the limit $n \to \infty$, in which $n \in \mathbb{N}$. Here is my question: Is there a mathematical theorem that is linking the integer limit 
  $$\lim_{n\to \infty}f(n)$$ to the real limit $$\lim_{x\to\infty}f(x)?$$ Is the equidistribution theorem such a mathematical statement?","['real-analysis', 'elementary-number-theory', 'real-numbers', 'limits']"
1825026,Group whose all subgroups have infinite index,"Is there a group $G$ satisfying the following conditions? If $H$ is a proper subgroup of $G$ , then $[G:H]$ has infinite index. I guess $\mathbb{Q}$ is such group.",['group-theory']
1825030,Does continuity imply partial derivatives exist?,"I know that in functions of more than one variable, the existence of partial derivatives does not guarantee that the function will be continuous.  However, can the reverse be stated? i.e. that the continuity of the function implies that the partial derivatives exist? I have a feeling that the answer is no, just like in functions of one variable where e.g. $\mid x\mid$ is continuous at $x=0$ but does not have a derivative.","['multivariable-calculus', 'real-analysis']"
1825057,"$f(x) = 0$ when $x$ is $0$, and $1$ otherwise","I've been trying to create a function that will return $0$ when $x$ is $0$, and for any other $x$ value it should return $1$. I've searched for a pre-existing function online too and wasn't able to find one. Do you know of any function that can do this?","['boolean-algebra', 'binary', 'functions']"
1825079,"Real Analysis Folland, 1.20 Proposition Borel measures","1.20 Proposition - If $E\in M_{\mu}$ and $\mu(E) < \infty$, then for every $\epsilon > 0$ there is a set $A$ that is finite union of open intervals such that $\mu(E \ \triangle \ A) < \epsilon$. Proof - Let $E\in M_{\mu}$ and $\mu(E) < \infty$ then by lemma 1.17 there exists an open set $U\in M_{\mu}$ such that $E\subseteq U$ and $\mu(U)\leq \mu(E) + \epsilon/2$. Let $\{U_n\}_{1}^{\infty}$ be a sequence of disjoint open intervals such that $\bigcup_{1}^{\infty}U_n = U$ Then $$\sum_{1}^{\infty}\mu(U_n) = \mu(U) < \infty$$ so there exists an $N\in\mathbb{N}$ such that $\sum_{n=N+1}^{\infty}\mu(U_n) < \epsilon/2$. Define $A:= \bigcup_{1}^{n} U_n$ It follows that $$\mu(E \ \triangle \ A) = \mu(E\setminus A) + \mu(A\setminus E)\leq \mu(E\setminus U) + \mu(U\setminus E) + \mu(U\setminus A) = 0 + \mu(U) - \mu(E) + \mu(U) - \mu(A) < \epsilon/2 + \epsilon/2 = \epsilon $$ I am not sure if this is correct, any suggestions or comments are greatly appreciated.","['real-analysis', 'measure-theory']"
1825100,Example of Hilbert space non isomorphic to $L2$,"I'm looking for an example of a Hilbert space that can't be seen as the countable direct sum of $L^{2}(X,\mu)$ spaces nor subespaces of $L^{2}(X,\mu)$. Some idea to start? Thanks everyone.","['functional-analysis', 'hilbert-spaces']"
1825101,Is it always true that $\partial f(U)=f(\partial U)$ when $f$ is holomorphic?,"Let $D\subseteq\Bbb C$, $f:D\to\Bbb C$ holomorphic on $D$.
Let $U$ be an open subset strictly contained in $D$: in this way $\partial U$ would be contained in $D$. So I was asking myself if  $\partial f(U)=f(\partial U)$ is always true. 
It seems obvious simply passing to the limit; am I right?",['complex-analysis']
1825197,Finding the matrix of this particular quadratic form,"I have been working on problems related to bilinear and quadratic forms,
and I came across an introductory problem that I have been having issues with.
Take $$Q(x) = x_1^2 + 2x_1x_2 - 3x_1x_3 - 9x_2^2 + 6x_2x_3 + 13x_3^2$$ I want to find a matrix $A$ such that $Q(x) = \langle Ax,x \rangle$. My initial guess was to simply establish this via a coefficient matrix, i.e., $$A = \begin{bmatrix} 1 & 2 & -3\\ 2 & -9 & 6\\ -3 & 6 & 13\end{bmatrix}$$ However, upon closer inspection, I see that this matrix does not produce our
desired outcome. Is there a more reasonable algorithm for generating the
matrix $A$ of a quadratic form?","['matrices', 'quadratic-forms', 'linear-algebra']"
1825199,"How many bit strings of length 8 start with ""1"" or end with ""01""?","A bit string is a finite sequence of the numbers $0$ and $1$. Suppose we have a bit string of length $8$ that starts with a $1$ or ends with an $01$, how many total possible bit strings do we have? I am thinking for the strings that start with a 1, we would have $8 - 1 = 7$ bits to choose, so $2^7$ possible bit strings of length $8$ that starts with a $1$? Can I go about the second condition the same way and just add the total's together? That is, if my logic is even correct in the first place?","['computer-science', 'bit-strings', 'inclusion-exclusion', 'combinatorics', 'discrete-mathematics']"
1825205,Compute the area of that part of the surface of the sphere $x^2 + y^2 + z^2 = a^2$ cut out by the surface $\frac{x^2}{a^2}+\frac{y^2}{b^2} = 1$.,"I need help, I'm studying the area of surfaces using double integrals, I attempted to solve this exercise but I'm having trouble. The problem is to compute the area of that part of the surface of the sphere $x^2 + y^2 + z^2 = a^2$ cut out by the surface $\frac{x^2}{a^2}+\frac{y^2}{b^2} = 1$. This exercise is from  the book ""Problems-in-Mathematical-Analysis-Demidovich"". I know that the equation of the sphere is $z = \sqrt{a^2-x^2-y^2}$ , and  $\frac{dz}{dx} = -\frac{x}{\sqrt{a^2-x^2-y^2)}}$ , and $\frac{dz}{dy} = -\frac{y}{\sqrt{a^2-x^2-y^2}}$.
Then I have to use the formula $S = \sqrt{1+\left(\frac{dz}{dx}\right)^2 + \left(\frac{dz}{dy}\right)^2}$.
Here I'm having trouble, I don't know why the solution guide multiplies the formula $S$ by $8$. Can the somebody explain me why is this, please.","['multivariable-calculus', 'multiple-integral', 'surface-integrals']"
1825222,Trigonometry + Geometry,In the given triangle we have this point $O$ such that $\angle OAB=\angle OBC=\angle OCA=\omega$ Hence prove that $\cot\omega=\cot A+\cot B+\cot C$. I figured out the RHS by using sine and cosine identities but the LHS couldn't be worked out by me. Please help.,['trigonometry']
1825240,subset of a topological space is closed if and only if it contains all of its limit points.,"I'm trying to prove the following: Show that a subset of a topological space is closed if and only if it
  contains all of its limit points. Is my proof valid? Definition of limit point: $p$ is a limit point of a subset, if every neighborhood of $p$ contains a point in the subset other than $p$ (aka accumulation point). Lets call the subset, $A$. In this case we will take $A$ is a closed subset as a given. Lets assume that $p$ is a limit point of $A$, and $p \notin A$. Thus $p \in   \partial A $ because only at the boundary can a point, not in the set, have every neighborhood with points that ARE in the set.(More specifically, because EVERY neighborhood of $p$ intersects $A$.) However, we are given that $A$ is closed and closed sets contain all their boundary points. Thus, $p$ cannot exist (RAA). So if a subset is closed it must contain all of its limit points. Now the converse. In this case we will take $A$ contains all of its limit points as a given. Lets assume that $A$ is not closed, and thus does not contain all of its boundary points. Let $b$ be a point such that, $b \in \partial A$ and $b \notin A$. However $b$ must be a limit point, because every neighborhood of a boundary point contains a point in A.  Thus $A$ does not contain all of it limit points (RAA). So, if a subset contains all of its limits points it must be closed. QED","['general-topology', 'metric-spaces', 'proof-verification']"
1825281,Deriving the Airy functions from first principles,"I have just started reading about the Airy functions and am stuck on a particular step of their derivation. But first here is some background information to give this question some meaning, more information can be found from a previous question of mine: The general solution to Bessel's differential equation: $$\fbox{$y^{\prime\prime}+\left(\frac{1-2a}{x}\right)y^{\prime}+\left[\left(bcx^{c-1}\right)^2+\frac{a^2-p^2c^2}{x^2}\right]y=0$}\tag{1}$$ is $$\fbox{$y=x^aZ_p\left(bx^c\right)$}\tag{2}$$ where $Z_p$ stands for $J_p$ or $N_p$ or any linear combination of them, and $a,b,c,p$ are constants. $J_p$ is called the Bessel function of the first kind of order $p$ and $N_p$ is any combination of $J_p$ and $J_{−p}$: $$N_p(x)=\frac{\cos(\pi p)J_p(x)-J_{-p}(x)}{\sin(\pi p)}\tag{3}$$ So equation $(2)$ can be written as $$y=x^{a}\left[AJ_{p}\left(bx^c\right)+BN_{p}\left(bx^c\right)\right]\tag{4}$$ or $$y=x^{a}\left[AJ_{p}\left(bx^c\right)+B\left(\frac{\cos(\pi p)J_p\left(bx^c\right)-J_{-p}\left(bx^c\right)}{\sin(\pi p)}\right)\right]\tag{5}$$ The Airy differential equation is $$y^{\prime\prime}-xy=0\tag{6}$$ and has solution $$y=x^{1/2}Z_{1/3}\left(\frac23 ix^{3/2}\right)\tag{7}$$ By using $$I_p(x)=i^{-p}J_p(ix)\tag{8}$$
  $$K_p(x)=\frac{\pi}{2}i^{p+1}\left[J_p(ix)+i\left(\frac{\cos(\pi p)J_p(ix)-J_{-p}(ix)}{\sin(\pi p)}\right)\right]\tag{9}$$ My objective is to show that $(7)$ can be written in terms of $I_{1/3}$ and $K_{1/3}$ to obtain $$Ai(x)=\frac{1}{\pi}\sqrt{\frac{x}{3}}K_{1/3}\left(\frac23x^{3/2}\right)\tag{10}$$
  $$Bi(x)=\sqrt{\frac{x}{3}}\left[I_{-1/3}\left(\frac23x^{3/2}\right)+I_{1/3}\left(\frac23x^{3/2}\right)\right]\tag{11}$$ Starting from $(7)$: $$\begin{align}y&=x^{1/2}Z_{1/3}\left(\frac23 ix^{3/2}\right)\\&=x^{1/2}\left[AJ_{1/3}\left(\frac23 ix^{3/2}\right)+BN_{1/3}\left(\frac23 ix^{3/2}\right)\right]\\&=x^{1/2}\left[AJ_{1/3}\left(\frac23ix^{3/2}\right)+B\left(\frac{\cos\left(\frac{\pi}{3}\right)J_{1/3}\left(\frac23ix^{3/2}\right)-J_{-1/3}\left(\frac23ix^{3/2}\right)}{\sin\left(\frac{\pi}{3}\right)}\right)\right]\\&=x^{1/2}\left[AJ_{1/3}\left(\frac23ix^{3/2}\right)+B\left(\frac{\frac12J_{1/3}\left(\frac23ix^{3/2}\right)-J_{-1/3}\left(\frac23ix^{3/2}\right)}{\left(\frac{\sqrt3}{2}\right)}\right)\right]\\&=x^{1/2}\left[AJ_{1/3}\left(\frac23ix^{3/2}\right)+\frac{BJ_{1/3}\left(\frac23ix^{3/2}\right)}{\sqrt3}-\frac{2BJ_{-1/3}\left(\frac23ix^{3/2}\right)}{\sqrt3}\right]\\&=x^{1/2}\left[Ai^{1/3}I_{1/3}\left(\frac23x^{3/2}\right)+\frac{i^{1/3}BI_{1/3}\left(\frac23x^{3/2}\right)}{\sqrt3}-\frac{2i^{-1/3}BI_{-1/3}\left(\frac23x^{3/2}\right)}{\sqrt3}\right]\tag{a}\end{align}$$
where in $(\mathrm{a})$ I used $(8)$ rearranged as $J_p(ix)=i^{p}I_p(x)$ I don't understand how to proceed with this calculation as I am unsure how to use $(9)$; I also have no idea what $i(x)$ means. Is $i$ really a function of $x$? Is there anyone that could provide some hints or advice on how I can continue this calculation to obtain $(10)$ and $(11)$? Below are some images showing some of the relevant formulae to this question:","['intuition', 'airy-functions', 'bessel-functions', 'special-functions', 'ordinary-differential-equations']"
1825285,How many bit strings of length $5$ do not have consecutive $1$'s?,How many bit strings of length 5 do not have consecutive 1's ? I'm trying to think of a way to calculate how many ways we can arrange a string of length 5 starting with the first position (or index). I feel like in this case we would use a permutation because order matters. I also believe repetition is not allowed (hence no consecutive 1's) here? Please correct me if I'm going about this wrong.,"['permutations', 'combinatorics', 'discrete-mathematics']"
1825313,Is it true that the order of the group is a power of $2$ if every element has order $2$?,"I read in this old question that If $G$ consists only of elements of order 2, then $|G|=2^m$ for some
   $m$. But it's not clear to me. I tested the base case $G=\{a,b,ab,e\}$ but induction does not seem appropriate. Assuming the statement is true, how does one go about proving this?","['finite-groups', 'group-theory']"
1825337,$\lim\limits_{n\to \infty}\sum_{k=1}^{\infty}2^{-k}\sin(k/n)=0$,"I want to show that $$\lim\limits_{n\to \infty}\sum_{k=1}^{\infty}2^{-k}\sin(k/n)=0$$ I first thought if I can change the order of limit, it can be easy to show that. But I found that there exists counter example here . I know that $\sum_{k=1}^{\infty}2^{-k}\sin(k/n)$ absolutely converges, but how to show the result?","['sequences-and-series', 'analysis']"
1825354,"Matrices problem: $AB=B$ and $BA=A$, what is $A^2+B^2$?","If $A$ and $B$ are two matrices such that $AB=B$ and $BA=A$, then $A^2+B^2$ would be equal to?","['matrices', 'linear-algebra']"
1825372,Let $A$ be a $2 \times 2$ real matrix such that $A^2 - A + (1/2)I = 0$. Prove that $A^n \to 0$ as $n \to \infty$.,"Question: Let $A$ be a $2 \times 2$ matrix with real entries such that $A^2 - A + (1/2)I = 0$, where $I$ is the $2 \times 2$ identity matrix and $0$ is the $2 \times 2$ zero matrix. Prove that $A^n \to 0$ as $n \to \infty$. My attempt: Here is my idea so far. Consider $A$ as a $2 \times 2$ matrix over the field of complex numbers. Now, the polynomial $$g(t) = t^2 - t + \frac{1}{2} $$ factors as $$g(t) = \left(\frac{1}{2} - \frac{i}{2}\right)\left(\frac{1}{2}+\frac{i}{2}\right)$$ over $C$. This means that the minimal polynomial of $A$ over $C$ is: $$m(t) = \left(t-(\frac{1}{2} - \frac{i}{2})\right), m(t) = \left(t-(\frac{1}{2} + \frac{i}{2})\right), \ \ \ \text{ or } \ \ \ m(t) = \left(t-(\frac{1}{2} - \frac{i}{2})\right)\left(t-(\frac{1}{2} + \frac{i}{2})\right),$$ and thus we have $A = Q D Q^{-1}$, where $$D =\left[ {\begin{array}{*{20}{c}}
{\frac{1}{2}(1 - i)}&0\\
0&{\frac{1}{2}(1 - i)}
\end{array}} \right],$$ $$D = \left[ {\begin{array}{*{20}{c}}
{\frac{1}{2}(1 + i)}&0\\
0&{\frac{1}{2}(1 + i)}
\end{array}} \right],\ \ \ \text{ or } $$ $$D = \left[ {\begin{array}{*{20}{c}}
{\frac{1}{2}(1 - i)}&0\\
0&{\frac{1}{2}(1 + i)}
\end{array}} \right].$$ Now, $A^n = QD^nQ^{-1}$. Here is where I get stuck. $D^n$ doesn't seem to be converging to $0$ as $n$ approaches infinity. In addition, I am concerned that my strategy is bad, since we are talking about a real matrix and I'm using a minimal polynomial over $C$. Is it still true that $A$ must have one of the three forms above, even if $A$ is supposed to be real? Thanks for any help/suggestions you may be able to provide.","['matrices', 'linear-algebra']"
1825376,If $\sin x + \csc x =2 \tan x$. Find value of $\cos^9x +\cot^9x +\sin^7x$,"Problem: If $\sin x+\csc x=2\tan x$, Find value of $\cos^9x+\cot^9x+\sin^7x$ Solution: \begin{align*}&\sin x+\csc x=2\tan x \\ &\sin x+\frac{1}{\sin x}=2\frac{\sin x}{\cos x} \\ &\sin^2x+1=2\frac{\sin^2x}{\cos x} \\ &\sin^2x\cos x+\cos x=2\sin^2x \\ &(1-\cos^2x)\cos x+\cos x=2(1-\cos^2x) \\ &\cos^3x-2\cos^2x-2\cos x+2=0\end{align*} Am I doing right ? How to do further ?",['trigonometry']
1825392,Mean Value Property to show that entire function is a constant,"Let $f(z)$ be an entire function so that, $$ \int \frac{|f(z)|}{1 + |z|^3} dA(z) < \infty$$ where the integral is taken over the entire complex plane.  Show that $f$ is a constant. I believe that the idea is to use the mean value property; that is: $$f(z) = \frac{1}{\pi\delta^2}\int_{D(z, \delta)}f(w)dA(w)$$ and then do some manipulation to relate the two integrals. But I'm not sure otherwise how to proceed. Can anyone help?","['complex-analysis', 'harmonic-functions']"
1825418,Coupon collection with trading of doubles,"I've been answering old unanswered coupon collection questions recently, and in thinking what other variations might be interesting I came up with this: There are $n$ coupon types. You successively draw coupons of independently uniformly distributed types. Your friend will give you any type of coupon for a pair of  coupons of one type. What is the expected number of draws until you can have a complete set of all types? There's no point in trading away doubles, so we can assume that you trade if you have a triple (thereby converting it into two singles). We can consider two variations: a) You can trade whenever you like. b) You have to trade immediately when you get a triple. a) is more favourable, since you can wait until the end to get exactly the coupon types you're still missing, whereas in b) you might trade for a coupon type that you'll draw afterwards anyway. The setup seems simple enough, but I don't see how to get an expression for the expected number. Unlike in the standard coupon collector's problem, a continuous approximation is straightforward. Let $m(t)$, $s(t)$ and $d(t)$ denote the fractions of missing, single and double coupon types, respectively, at time $t$, with the initial conditions $m(0)=1$, $s(0)=d(0)=0$. We can approximate the discrete procedure by a continuous process governed by differential equations. In a), we can consider any triple to be immediately converted to a single plus a pair that we can trade as soon as the number of pairs is equal to the number of missing types. Then $m'=-m$, with solution $m=\mathrm e^{-t}$. Also $s'=m+d-s$ and $d'=s-d$, so $(s-d)'=m-2(s-d)$, with solution $s-d=\mathrm e^{-t}-\mathrm e^{-2t}$. For the fraction $p$ of pairs, $p'=d$ with $p(0)=0$, so, since $d'=s-d$ and $d(0)=0$, we get $p$ by twice integrating $\mathrm e^{-t}-\mathrm e^{-2t}$, yielding $p=\frac12t-\frac34+\mathrm e^{-t}-\frac14\mathrm e^{-2t}$. The process ends when $p=m$, that is, when $\mathrm e^{-2t}=2t-3$, which occurs at $t=\frac12\left(W\left(\mathrm e^{-3}\right)+3\right)\approx1.52374$ (where $W$ is the Lambert W function). In b), where a triple is immediately converted into two singles, $$
\pmatrix{m\\s\\d}'=\pmatrix{-1&0&-1\\1&-1&2\\0&1&-1}\pmatrix{m\\s\\d}\;.
$$ Diagonalising yields the solution $$
\pmatrix{m\\s\\d}=\pmatrix{-2+\sqrt5\\\frac12(1-\sqrt5)\\\frac12(3-\sqrt5)}\frac{\mathrm e^{-\frac12(3+\sqrt5)t}}{\sqrt5}+\pmatrix{2+\sqrt5\\\frac12(-1-\sqrt5)\\\frac12(-3-\sqrt5)}\frac{\mathrm e^{-\frac12(3-\sqrt5)t}}{\sqrt5}+\pmatrix{-1\\1\\1}\;,
$$ so the process ends with $m=0$ when $(-2+\sqrt5)\mathrm e^{-\frac12(3+\sqrt5)t}+(2+\sqrt5)\mathrm e^{-\frac12(3-\sqrt5)t}=\sqrt5$, which occurs at $t\approx1.67614$ ( Wolfram|Alpha computation ). Simulations suggest that in both cases, for $n\to\infty$ the expected number of draws (normalised by $n$) converges to the values from these continuous approximations. ( Here's the code. ) I'd be interested in any ideas (for one or both of the variations) for obtaining the expected number of draws or the distribution of the number of draws, or at least obtaining the limits derived above combinatorially rather than by solving differential equations.","['combinatorics', 'probability', 'coupon-collector']"
1825425,minimum number of dependent rows in a matrix,"Does the minimum number of dependent rows in a matrix have a specific name?
(the way ""rank"" refers to the maximum number of independent rows).
This comes up in calculating distances of codes.
There are plenty of algorithms to calculate rank; are there any for this
minimum other than brute force? Any reference to or description of the algorithm are appreciated; same for any sw package that might have that implemented.","['matrices', 'coding-theory', 'linear-algebra']"
1825452,Is $ f \circ g $ invertible in the diagram below?,I was working through Can the composition of two non-invertible functions be invertible? For the image below is $f \circ g$ invertible? Thanks!,"['elementary-set-theory', 'function-and-relation-composition', 'functions', 'inverse']"
1825486,Find the first digit of a number,"I have seen this question but i could not find any answers.Let A= a*b*c*d....   very huge multiplication So what we can do take log(base 10) of number log(A) = log(a)+log(b)+log(c).....
log(A) = S (summation of logs) From here onward how can i find the first digit.
I came to know that Fist digit = Number after decimals in S which is close to log of (1..9) Can you explain how to do that ?","['number-theory', 'elementary-number-theory']"
1825501,Why is this matrix neither positive nor negative semi-definite?,"After some search here and on Google, I couldn't find a way to determine the definiteness of this matrix: \begin{bmatrix}0&1\\1&0\end{bmatrix} My understanding is that it should be negative semi-definite since all principal minors are $\leq 0$. However, in the sample solutions of the book I am working through it stated that it is neither positive nor negative semi-definite. A general procedure (for positive and negative semi-definiteness) would be really helpful. Why is that?","['matrices', 'positive-definite', 'linear-algebra']"
1825503,Cumulative bivariate normal,"How do I calculate the cumulative probability distribution function for a bivariate normal distribution with conditions $P( x>a , y>b)$? Is there any method to solve
$$P(x>a,y>b)\\\int_{b}^{\infty}\int_{a}^{\infty}\frac{1}{2\pi\sqrt{1-\rho^2}}\exp\left(-\frac12\frac{x^2-2\rho xy+y^2}{1-\rho^2}\right)\,dx\,dy$$","['statistics', 'integration', 'normal-distribution', 'probability-distributions']"
1825569,Can we characterize all infinite Euclidean domains having exactly one invertible element?,"$\mathbb Z_2$ and $\mathbb Z_2[x]$ are two Euclidean domains having exactly one invertible element. My question is: Can we characterize all Euclidean domains $D$ having exactly one invertible element, i.e., $|D^{\times}|=1$ ? For finite domains it is easy because any finite ED is an ID so a field, so the only one is $\mathbb Z_2$, but what about infinite Euclidean domains ? Please help. Thanks in advance UPDATE : Obviously, as MooS has also noted, if $D$ is an ID with $|D^{\times}|=1$ then $D$ has characteristic $2$. Any progress regarding the problem is highly appreciated.","['euclidean-algorithm', 'abstract-algebra', 'ring-theory', 'soft-question', 'integral-domain']"
1825579,$\sin(nx)$ espansion into $n$-th grade $\sin(x)$ polynomial,"Maybe this is a well-know question, anyway I haven't found an exact duplicate. It is possible to express $\cos (nx)$ as a polynomial of degree $n$ in $\cos(x)$. As stated in this answer , it is possible to prove it starting from $\cos(nx)$ by repeatedly using $$
\begin{align*}
\cos(a\pm b) &= \cos a\cos b \mp \sin a\sin b\\
\sin(a\pm b) &= \sin a\cos b \pm \cos a\sin b\\
\sin^2(r) &= 1-\cos^2(r).
\end{align*}
$$ Now I would like to obtain $\sin(nx)$ as a polynomial of degree $n$ in $\sin(x)$. I started from the simplest case: $$\sin(2x) = \sin x \cos x + \cos x \sin x = 2 \sin x \cos x$$ All I could do was to use $\cos(2x) = 1 - 2 \sin^2 x$, but then I would get $$\sin(2x) = 2 \sin x \left[ 1 - 2\sin^2 \left( \frac{x}{2} \right) \right]$$ This is a polynomial with $\sin$, but not always $\sin(x)$. Moreover, this answer shows that $\sin(2x)$ can't be written as a polynomial in $\sin x$. So, for $n \neq 2$, is it possible to express $\sin(nx)$ in terms of $\sin x$ or it is always impossible?","['polynomials', 'real-analysis', 'trigonometry', 'calculus']"
1825628,"Limit and rate of convergence of the sequence $a_{n+1}=\frac{a_n^2+b_n^2}{a_n+b_n},~~b_{n+1}=\frac{a_n+b_n}{2}$","Define the sequence the following way for some $x,y \geq 0$ : $$a_0=x,~~~~~~~b_0=y$$ $$a_{n+1}=\frac{a_n^2+b_n^2}{a_n+b_n},~~~~~~b_{n+1}=\frac{a_n+b_n}{2}$$ Obviously: $$a_n \geq b_n,~~~~n \geq 1$$ For convergence rate we have: $$a_{n+1}-b_{n+1}=\frac{(a_n-b_n)^2}{2(a_n+b_n)} \tag{1}$$ We have a weak inequality: $$\frac{(a_n-b_n)^2}{2(a_n+b_n)} \leq \frac{(a_n-b_n)^2}{2(a_n-b_n)}=\frac{a_n-b_n}{2}$$ So our convergence rate is at least linear: $$\frac{a_{n+1}-b_{n+1}}{a_n-b_n} \leq \frac{1}{2} \tag{2}$$ But shouldn't $(1)$ imply faster (quadratic) convergence? (I know we need to subtract the limit to find the convergence, but I don't know the closed form, see below). Now for the limit. We have the following relations: $$a_{n+1}b_{n+1}=\frac{a_n^2+b_n^2}{2} \geq a_nb_n$$ $$a_{n+1}b_{n+1}-a_nb_n=\frac{(a_n-b_n)^2}{2}$$ Can we find the limit of this sequence in closed form? What is the true rate of convergence for this sequence?","['recurrence-relations', 'means', 'sequences-and-series']"
1825631,What does it mean for a scheme to be proper?,What exactly does it mean for a scheme to be proper? I can't seem to find an actual definition of this anyway despite the term being frequently used.,"['schemes', 'algebraic-geometry']"
1825639,Eigenvector of polynomial,"Suppose that $T: V \rightarrow V$ is an endomorphism of the linear space V (about $\mathbb{K}$) and that $p(X)$ is a polynomial with coefficients in $\mathbb{K}$. Show that if $x$ is an eigenvector of $T$ than it is also an eigenvector of $p(T)$. My attempt: So if $x$ is an eigenvector of $T$ that means that $T(x) = \lambda x$ ($\lambda$ being the eigenvalue associated to $x$). Ok so my next step is the one I feel is not correct $p (T(x)) = p (\lambda x)$ so $\lambda$ is an eigenvalue of the polynomial. I don't feel this is a correct assumption, that you can't immediately conclude this, can  we?","['eigenvalues-eigenvectors', 'polynomials', 'linear-algebra']"
1825645,Norms on an Ultraproduct,"Suppose $X$ is a Banach space and $\mathcal{U}$ is a non-principal ultrafilter on $\mathbb{N}$. I am interested in the Banach space $(X)_\mathcal{U}$, where we consider sequences $(x_i)_{i \in \mathbb{N}}$ with norm $\|(x_i)\| = \lim_\mathcal{U} \|x_i\|$ (quotiented out by the null sequences.) My question is related to how this norm behaves on certain sequences. My main notion is that the limit behaves (roughly) like a Banach Limit, and thus assigns some notion of average to the sequence. I then think of $\|x\| = LIM(\|x_i\|)$, where $LIM$ is a Banach limit. The first part of my question, is this true? Do ultraproducts of Banach spaces and Banach Limits mean roughly the same thing? (I have a gut feeling that this is either true, or can be made precise.) If this is true, then I can say the following. If I have a sequence in the ultrapower given by $x = (x_1,\dots,x_m, x_1,\dots, x_m, x_1,\dots)$ then the norm of such an element is $\frac{1}{m} \sum_{i=1}^m \|x_i\|$. Indeed, apply shift invariance $m$ times, add the results, and apply shift invariance again. So, I can think of $\|x\| = \lim_n \frac{1}{n} \sum_{i=1}^n \|x_i\|$ So my real question is the following: suppose $Y = \{(x_i) :$ those sequences for which  $ \lim_n \frac{1}{n} \sum_{i=1}^n \|x_i\| $ converges $\}$. Does $\|x\|_{\mathcal{U}} = \lim_n \frac{1}{n} \sum_{i=1}^n \|x_i\|$  on $Y$? I get the feeling that this is either correct or so completely wrong that my understanding of ultrapowers is unrescuable.","['functional-analysis', 'product-space', 'banach-spaces', 'filters']"
1825682,Parameterise linear combination of cosines,"How do I parameterise the following implicit surface? $$ \cos x + \cos y + \cos z = 0 $$ Motivation for this problem comes from attempting to find stable motion for an object balanced on one point. The equation seems so simple, but I really have no idea how to solve this problem. Apparently the surface approximates the Schwarz P minimal surface , however I do not have any knowledge of the theory behind that.","['algebra-precalculus', 'parametric', 'trigonometry']"
1825697,Leibniz rule; Solving differential equations,"Could you help me with a question? I get stuck at ii), Define the function $$I(x):=\frac{1}{\pi} \int^\pi_0 \cos(x\sin\theta) d\theta$$ i) Via application of Leibniz rule (or otherwise) calculate $I'$ and $I''$. ii) Thus, determine non-zero value(s) of $k$ for which $I$ will be a solution to the differential equation $$k^2x^2I''+xI'+x^2I=0$$ iii) Write down the values of $I(0)$ and $I'(0)$. So far what I have is 
$$I'(x)=\frac{1}{\pi} \int^\pi_0 -\sin\theta \sin(x\sin\theta) d\theta$$
$$I''(x)=\frac{1}{\pi}\int^\pi_0 -\sin^2\theta \cos(x\sin\theta) d\theta$$ No idea where to go from there :S","['differential', 'ordinary-differential-equations']"
1825713,Preimage of a function,"I'm having difficulties with the notion of preimage, specifically with this example: Let $A$ be a subset of $[0, 1]$. We define $$f(x) = \begin{cases} x, & x \in A;  \\ -x, & x \in [0, 1] \setminus A. \end{cases}$$ It is said that the premimage of $[0, 1]$ is equal to $A$. I don't understand why. I've read the definition of the preimage of a set several times and I understand it, but this example still does not make sense to me. I don't even understand what the function looks like. Can someone explain this to me?","['functions', 'calculus', 'analysis']"
1825747,Orthogonal Projection onto the $ {L}_{\infty} $ Unit Ball,"What is the Orthogonal Projection onto the $ {\ell}_{\infty} $ Unit Ball? Namely, given $ x \in {\mathbb{R}}^{n} $ what would be: $$ {\mathcal{P}}_{ { \left\| \cdot \right\| }_{\infty} \leq 1 } \left( x \right) = \arg \min_{{ \left\| y \right\| }_{\infty} \leq 1} \left\{ {\left\| y - x \right\|}_{2}^{2} \right\} $$ I managed to get an answer using the Moreau Decomposition . Yet I would be happy to see if someone can derive the answer directly. Thank You.","['optimization', 'convex-optimization', 'linear-algebra']"
1825761,Are we guaranteed that the harmonic series minus infinite random terms always converge?,"Consider the known harmonic series
$\sum_{n=1}^\infty \frac{1}{n}$ and modify it as follows $$\sum_{n=1}^\infty a_n\frac{1}{n}$$
where
$$a_n \sim \operatorname{Bern} \left({\frac{1}{2}}\right)$$
i.e. each $a_n$ is $0$ or $1$ with probability $\frac{1}{2}$ (basically what one is doing here is removing randomly an infinite number of terms of this series) Is it possible to know that this series is almost always convergent? Meaning that it converges with probability $1$?","['harmonic-numbers', 'sequences-and-series', 'random-variables']"
1825764,Prove an algorithm for logarithmic mean $\lim_{n \to \infty} a_n=\lim_{n \to \infty} b_n=\frac{a_0-b_0}{\ln a_0-\ln b_0}$,"Take: $$a_0=x,~~~~b_0=y$$ $$a_{n+1}=\frac{a_n+\sqrt{a_nb_n}}{2},~~~~b_{n+1}=\frac{b_n+\sqrt{a_nb_n}}{2}$$ Then we obtain as a limit the logarithmic mean of $x,y$: $$\lim_{n \to \infty} a_n=\lim_{n \to \infty} b_n=\frac{x-y}{\ln x-\ln y}$$ I don't know how to prove this. But I do know that numerically it fits really well. In fact, the best approximation is obtained if we take geometric mean of $a_n,b_n$: $$x=5,~~~~y=3$$ $$\begin{array}( n & \sqrt{a_nb_n} & \frac{x-y}{\ln x-\ln y} \\ 4 & \color{blue}{3.915}0640985032 & 3.9152303779424 \\ 10 & \color{blue}{3.915230}33734566 & 3.9152303779424 \\ 20 & \color{blue}{3.9152303779424} & 3.9152303779424  \end{array}$$ The convergence rate can be approximated by: $$\frac{a_{n+1}-b_{n+1}}{a_n-b_n}=\frac{1}{2}$$ This seems like a very simple way to compute logarithms, for example: $$x=2,~~~~y=1$$ $$\ln2=\lim_{n \to \infty}\frac{1}{\sqrt{a_nb_n}}$$ How do I prove that the limit of this sequence is really the logarithmic mean? Edit It turns out this algorithm is mentioned in (at least) two papers by B. C. Carlson as early as 1971: https://www.jstor.org/stable/2317088 https://www.jstor.org/stable/2317754 Still, if someone can provide their own proof, I would be grateful.","['recurrence-relations', 'means', 'logarithms', 'numerical-methods', 'sequences-and-series']"
1825768,PDF of the difference between two independent beta random variables,"I am having trouble deriving the distribution of the difference of two beta random variables and would like some help verifying the steps I have taken.  In particular calculating the bounds. Say I have $X_1\sim\text{Beta}(a_1,b_1)$ and $X_2\sim\text{Beta}(a_2,b_2)$, independent, and am interested in calculating the distribution of $X_1-X_2$. So here is what I have come up with so far: Let $Z=X_1-X_2$ and $W=X_1$ where $0\leq X_i\leq 1$ for $i=1,2$. So $X_1=W$ and $X2 = W-Z$. Likewise $\frac{dX_1}{dW}=1$, $\frac{dX_1}{dZ}=0$, $\frac{dX_2}{dW}=1$, and $\frac{dX_2}{dZ}=-1$. Then the determinant of the Jacobian would be $|J| = 0\times1 - (-1)\times1=1 $ Then we have that \begin{align}
f_{Z,W}(z,w)
&=f_{X_1,X_2}(J_1(z,w),J_2(z,w))\times|J|\\
&=f_{X_1,X_2}(w,z-w)\\
&=f_{X_1}(w) f_{X_2}(z-w)\\
&=\text{Beta}(w;a_1,b_1)\times\text{Beta}(w-z;a_2,b_2)\\
&=\frac{(w)^{1-a_1}(1-w)^{1-b_1}}{\beta(a_1,b_1)}\times\frac{(w-z)^{1-a_2}(1-(w-z))^{1-b_2}}{\beta(a_2,b_2)}
\end{align} From there I could integrate out $W$ from $f_{Z,W}(z,w)$ to get the quantity of interest, i.e., the distribution of $Z=X_1-X_2$. So now this is where I am stuck.  I have the following: $$f_Z(z)=\int f_{Z,W}(z,w)dw=\int \text{Beta}(w;a_1,b_1)\times\text{Beta}(w-z;a_2,b_2) dw$$ But I do not understand how to obtain the bounds for the integral, and if the integral needs to be broken into parts or not.  Let me know also if any of the above steps are incorrect.","['calculus', 'probability-distributions', 'multivariable-calculus', 'integration', 'probability']"
1825775,Does existence of the second weak derivative of $f\in L^2$ imply existence of the first?,"Let's consider a function $f\in L^2(\mathbb{R})$ for which the second weak derivative exists and lie in $L^2(\mathbb{R})$,
i.e. there exists $f''\in L^2(\mathbb{R})$ such that for all $\varphi\in C_0^\infty(\mathbb{R})$ the following integral equation stands:
$$
\int\limits_\mathbb{R}f(x)\varphi''(x)dx=\int\limits_\mathbb{R}f''(x)\varphi(x)dx.
$$ My question is, having this can we assume that weak $f'$ also exists in $L^2(\mathbb{R})$? Suppose we found a normal (not generalized) function $g:\mathbb{R}\to\mathbb{C}$ such that for all $\varphi\in C_0^\infty(\mathbb{R})$
$$
\int\limits_\mathbb{R}f(x)\varphi'(x)dx=-\int\limits_\mathbb{R}g(x)\varphi(x)dx.
$$
Then
$$
\langle -f'', f \rangle_{L^2}=-\int\limits_\mathbb{R}f''(x)f(x)dx=\int\limits_\mathbb{R}g(x)g(x)dx=\|g\|_{L^2}^2
$$
which means, that $g$ is in $L^2(\mathbb{R})$. But what guarantees us the existence of such $g$?","['functional-analysis', 'weak-derivatives', 'lebesgue-integral', 'sobolev-spaces']"
1825782,Prove $\int_{0}^{\infty}{\phi^3e^{4x}-\phi^4e^{3x}-\phi^3e^{2x}+e^x+2\over (\phi e^x)^5-1}\cdot2xdx=\left({\pi\over 5}\right)^2$,"Prove the following equation, given that $\phi$ stands for the golden ratio: $$I=\int_{0}^{\infty}{\phi^3e^{4x}-\phi^4e^{3x}-\phi^3e^{2x}+e^x+2\over (\phi e^x)^5-1}\cdot2xdx=\color{blue}{\left({\pi\over 5}\right)^2}\tag1$$ What I've tried: $${1\over (\phi e^x)^5-1}={1\over \phi^5e^{5x}}\cdot{1\over 1-\phi^{-5}e^{-5x}}={1\over \phi^{5(n+1)}e^{5x}}\sum_{n=0}^{\infty}e^{-5nx}\tag2$$ Apply $(2)$ to $(1)$ Hence Let $$S=\sum_{n=0}^{\infty}\phi^{-5(n+1)}$$ $$I=S\int_{0}^{\infty}(\phi^3 e^{-x(5n+1)}-\phi^4 e^{-x(5n+2)}-\phi^3e^{-x(5n+3)}+e^{-x(5n+4)}+2e^{-x(5n+5)})\cdot2xdx\tag3$$ integrate $(3)$ term by term using integration by parts Take an example from $(3)$ $$2\phi^3\int_{0}^{\infty}xe^{-(5n+1)x}dx= {2\phi^3\over (5n+1)^2}$$ This method it is definitely tedious. To evaluate the sum is another lengthy method. Anyone with a clever technique of tackling (1)? (Avoid series if possible)","['integration', 'definite-integrals', 'sequences-and-series', 'calculus']"
1825801,How many transitive relations on a set of four elements are functions?,"How many functions  $f:\left \{ a,b,c,d \right \}\rightarrow \left \{ a,b,c,d \right \}$ are also transitive relations? Sorry if I have mistakes in my English. I understand that $f$ is supposed to be vacuously transitive or if $$<a,b>\in f \implies <b,b>\in f $$ (because else if $ <b,c>\in f $ and $b\neq c$, then $ <a,c>\in f $, but that means that $f$ isn't a function.) But now I have a problem counting all the options. I can do it slowly and see all the options (I counted $41$) but I'm sure that there is a more elegant way to count them. Do you have any ideas?","['combinatorics', 'relations', 'discrete-mathematics']"
1825808,The function $(-1)^{-x}$,"I was bored so I put functions in Wolfram Alpha. And I got something that looks like a sin function. And in addition to that, the real part was continuous and the imaginary part was a cos function.
It might be obvious to most of you but the only math education I got is from high school. Thanks.",['functions']
1825825,Prove that $ 1+2q+3q^2+...+nq^{n-1} = \frac{1-(n+1)q^n+nq^{n+1}}{(1-q)^2} $,"Prove: $$ 1+2q+3q^2+...+nq^{n-1} = \frac{1-(n+1)q^n+nq^{n+1}}{(1-q)^2} $$ Hypothesis: $$ F(x) = 1+2q+3q^2+...+xq^{x-1} = \frac{1-(x+1)q^x+xq^{x+1}}{(1-q)^2} $$ Proof: $$ P1 | F(x) = \frac{1-(x+1)q^x+xq^{x+1}}{(1-q)^2} + (x+1)q^x = \frac{1-(x+2)q^{x+1}+xq^{x+2}}{(1-q)^2} $$
$$ P2 | \frac{1-(x+1)q^x+xq^{x+1}+[(x+1)(1-q)^2]q^x}{(1-q)^2} = \frac{1-(x+2)q^{x+1}+xq^{x+2}}{(1-q)^2} $$ 
$$ P3| \frac{x\color{red}{q^{x+1}}+[-(x+1)]\color{red}{q^x}+1+[(x+1)(1-q)^2]\color{red}{q^x}}{(1-q)^2} = \frac{x\color{red}{q^{x+2}}-(x+2)\color{red}{q^{x+1}}+1}{(1-q)^2} | $$ Here I just reorganize both sides of the equation, so LHS is explicity an expression with a degree of x+1 , while the degree of RHS is x+2 . Both LHS' $\color{red}{q^x}$ are added next. $$P4| \frac{xq^{x+1}+[-(x+1)+(x+1)(<1^2q^0+\binom{2}{1}1q-1^0q^2>)]q^x+1}{(1-q)^2}=\frac{xq^{x+2}-(x+2)q^{x+1}+1}{(1-q)^2} $$ $$P5 | \frac{xq^{x+1}+[2xq-xq^2+2q-q^2]q^x+1}{(1-q)^2} = \frac{xq^{x+2}-(x+2)q^{x+1}+1}{(1-q)^2} $$ I get stuck at this point. I don't know if i'm approaching  the problem the right way. So, any help would be appreciated. Thanks in advance.","['algebra-precalculus', 'proof-writing', 'sequences-and-series', 'proof-verification']"
1825837,Find the partial derivative of $\arctan (x/\sqrt{x^2+y^2})$ using the definition [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Let $f(x,y)=\arctan \frac{x}{\sqrt{x^2+y^2}}$. How to evaluate $$\lim_{h\to 0}\frac{f(4h,1)-f(h,1)}{h}?$$","['multivariable-calculus', 'partial-derivative', 'calculus', 'limits']"
1825847,Quadrics intersecting the twisted cubic and a line.,"I am trying to understand the determinantal approach on Harris book ""Algebraic Geometry: A first course"" on proving that the intersection of two quadrics containing the twisted cubic in $\mathbb{P}^3$ is the twisted cubic itself and a line (Pg. 110, 111). The twisted cubic can be described as the zero locus of the $2 \times 2$ minors of the matrix $$\left(\begin{array}
xx_0 & x_1 & x_2 \\ x_1 & x_2 & x_3
\end{array}\right)$$ If $\lambda = [\lambda_0 : \lambda_1 : \lambda_2] \in \mathbb{P}^2$ any quadric containing the twisted cubic can be neatly described as the zero locus of $$\left|\begin{array}
xx_0 & x_1 & x_2 \\ x_1 & x_2 & x_3 \\ \lambda_0 & \lambda_1 & \lambda_2
\end{array}\right|$$ Now,  given $[\mu_0 : \mu_1 : \mu_2] \neq [\lambda_0 : \lambda_1 : \lambda_2]$, Harris then claims that the intersection of two such quadrics away from the twisted cubic is the rank $\le 2$ locus of $$\left(\begin{array}
xx_0 & x_1 & x_2 \\ x_1 & x_2 & x_3 \\ \lambda_0 & \lambda_1 & \lambda_2 \\ \mu_0 & \mu_1 & \mu_2
\end{array}\right)$$ i.e. the zero locus of the $3\times 3$ minors of the matrix above, which gives the equations of the quadrics and $$\left|\begin{array}
xx_0 & x_1 & x_2 \\ \lambda_0 & \lambda_1 & \lambda_2 \\ \mu_0 & \mu_1 & \mu_2
\end{array}\right|= \left|\begin{array}
xx_1 & x_2 & x_3 \\ \lambda_0 & \lambda_1 & \lambda_2 \\ \mu_0 & \mu_1 & \mu_2
\end{array}\right|=0$$ which are equations defining a line. But why is that? I don't see how we can know a priori that this line resides in the intersection of the quadrics. Or even how we know a priori that the zero locus of these minors will give the part of the intersection which is not in the twisted cubic.","['proof-explanation', 'algebraic-geometry', 'determinant']"
1825875,$\ell^1$ is not complete for the norm $\|\cdot\|_\infty$,"Let $\ell^\infty = \{ (u_n) | u_n \in \mathbb{R}$ and $\sup_{n \in \mathbb{N}}|u_n| < \infty \}$ and $\ell^1 = \{ (u_n) | u_n \in \mathbb{R}$ and $\sum_{n=1}^{\infty} |u_n| < \infty \}$ We know that $\ell^1 \subset \ell^\infty$ , so $\ell^1$ inherits the norm $\|\cdot\|_\infty$ of $\ell^\infty$ .
We want to show that : $\ell^1$ is not complete for the norm $\|\cdot\|_\infty$ . I considered the sequence $(u^{(n)})$ defined by $u^{(n)}_k = \frac{1}{k}$ if $k \leq n$ and $u^{(n)}_k = 0$ otherwise. This sequence doesn't converge to an element $l \in \mathcal{l}^1$ . For if it does, we have necessarily that $l_k = \frac{1}{k}$ and $l \notin \ell^1$ . Moreover, my guess is that this sequence is Cauchy. But how exactly do we prove that ? My second question is: We still endow $\ell^1$ with the norm $ \|\cdot\|_\infty$ . Let $\phi : \ell^1 \times \ell^1 \to \mathbb{R}$ be such
that $\phi(U,V) = \sum_{n=1}^{\infty} u_n v_n$ .  Show that $\phi$ is
not continuous. I don't know which sequences $U$ and $V$ I might take with the assumption that $\phi$ is continuous in order to get a contradiction. Can someone help ?","['functional-analysis', 'real-analysis', 'lp-spaces', 'analysis']"
1825879,Find the value of special tridiagonal determinant,"Let $A_{n}$ be the following  tridiagonal determinant  of order $n:$ \begin{vmatrix}
 a_{0}+a_{1}&  a_{1}&  0&  0& \cdots&  0& \quad0\\ 
 a_{1}&  a_{1}+a_{2}&  a_{2}&  0&  \cdots&  0& \quad0\\ 
 0&  a_{2}&  a_{2}+a_{3}&  a_{3}&  \cdots&  0& \quad0\\ 
 \vdots&  \vdots&  \vdots&  \vdots&  &  \vdots& \quad\vdots\\ 
 0&  0&  0&  0&  \cdots&  a_{n-1}&   \quad a_{n-1}+a_{n}
\end{vmatrix} Find the value of $A_{n}.$ As we know,$$A_{n}=(a_{n-1}+a_{n})A_{n-1}-a^{2}_{n-1}A_{n-2}\Longrightarrow$$ $$\begin{bmatrix}
 A_{n}\\
 A_{n-1}
\end{bmatrix}=\begin{bmatrix}
 a_{n-1}+a_{n}& -a^{2}_{n-1}\\
 1& 0
\end{bmatrix}\begin{bmatrix}
 A_{n-1}\\
 A_{n-2}
\end{bmatrix}=$$$$\begin{bmatrix}
 a_{n-1}+a_{n}& -a^{2}_{n-1}\\
 1& 0
\end{bmatrix}\begin{bmatrix}
 a_{n-2}+a_{n-1}& -a^{2}_{n-2}\\
 1& 0
\end{bmatrix}\cdots\begin{bmatrix}
 a_{2}+a_{3}& -a^{2}_{2}\\
 1& 0
\end{bmatrix}\begin{bmatrix}
 A_{2}\\
 A_{1}
\end{bmatrix}.$$ But it is  not easy to deal with
 $$\begin{bmatrix}
 a_{n-1}+a_{n}& -a^{2}_{n-1}\\
 1& 0
\end{bmatrix}\begin{bmatrix}
 a_{n-2}+a_{n-1}& -a^{2}_{n-2}\\
 1& 0
\end{bmatrix}\cdots\begin{bmatrix}
 a_{2}+a_{3}& -a^{2}_{2}\\
 1& 0
\end{bmatrix}$$","['matrices', 'linear-algebra', 'determinant']"
1825883,Which groups have only real representations?,"An irreducible representation $\rho$ (with character $\chi$) of a finite group is called a ""real"" representation if its Frobenius-Schur indicator is 1:
$$\frac{1}{\lvert G \rvert} \sum_{g \in G} \chi\left(g^2\right) = 1$$
Alternatively, it is real if it has a symmetric bilinear, $G$-equivariant form. Finite groups can have real, quaternionic and complex representations. Some groups like the symmetric group have only real representations. Which groups have only real representations?","['finite-groups', 'representation-theory', 'group-theory']"
1825906,Proving linearity of an operator using boundedness.,"I am considering an operator $K\colon \ell^2 \to \ell^2$ given by $$Kx = \sum_{n=1}^\infty e^{-n} \langle x , e_n\rangle e_n $$
where $e_n = (\delta_{k,n})_{k\in \mathrm{N}}$ is the standard basis on the sequence space $\ell^2$ and $ \langle \cdot , \cdot \rangle$ denotes the usual inner product. I know that this operator is bounded with $ \Vert K \Vert = e^{-1}$. Now my textbook tells me that linearity of $K$ is easily shown using boundedness, yet I am not  sure whether boundedness is strictly necessary to prove this. 
\begin{align*}
K(x+y) &= \sum_{n=1}^\infty e^{-n} \langle x + y, e_n\rangle e_n\\
&= \sum_{n=1}^\infty e^{-n} (\langle x, e_n\rangle + \langle y, e_n\rangle) e_n\\
&= \sum_{n=1}^\infty e^{-n} \langle x, e_n\rangle e_n + \sum_{n=1}^\infty e^{-n} \langle y, e_n\rangle e_n \quad (*)\\
&= Kx + Ky.
\end{align*}
I suspect boundedness is used in $(*)$, so making it more precise I get 
$$ \left\Vert \sum_{n=1}^N e^{-n} \langle x + y, e_n\rangle e_n - Kx - Ky \right\Vert \leq \left\Vert \sum_{n=N+1}^\infty e^{-n} \langle x, e_n\rangle e_n \right\Vert + \left\Vert \sum_{n=N+1}^\infty e^{-n} \langle y, e_n\rangle e_n \right\Vert$$
by the triangle inequality. Now boundedness of $K$ shows that the right hand side converges to zero as $N \to \infty$. It seems to me that boundedness is unnecessary here, and that the only thing needed is that $Kx \in \ell^2$ for all $x \in\ell^2$. Is this correct? If so, I have a follow-up question: are there examples of unbounded operators where the above argument may be used to prove linearity? I was thinking of the defining $Tx = \sum_{n=1}^\infty n \langle x , e_n \rangle e_n$ as an example of such an operator, but I am not sure if this operator is well-defined on $\ell^2$",['functional-analysis']
1825936,Prove that there exists a sequence $(x_n)$ such that $\sum_n a_n x_n$ diverges,"So, here's a nice little result that I deduced using the closed graph theorem from functional analysis, but I'm wondering if there's a more elementary approach: Fact: Let $(a_n)$ be a sequence with $a_n > 0$ and $a_n \to \infty$ . Then there exists a sequence $(x_n)$ with $\sum |x_n| < \infty$ for which $\sum_{n=1}^\infty a_n x_n$ diverges. I'm thinking there may be a relatively easy to construct sequence $x_n$ here, but I myself can't think of any.  The reason that I know this must hold is that the map $(x_n) \mapsto (a_n x_n)$ is an unbounded operator from $\ell^1$ to $\ell^\infty$ with a continuous inverse defined over the image, but this provides me with no intuition as to how a suitable $(x_n)$ should be constructed.","['functional-analysis', 'real-analysis', 'sequences-and-series', 'alternative-proof']"
1825971,Why does $n \geq 2$ imply that $\frac n 2 < n$?,"It has been a while since I did math proof in school, and I just can't figure out why $$n \geq 2 \text{ implies that } \frac n 2 < n$$ Anything would help!  Thanks.","['algebra-precalculus', 'inequality']"
1825977,"Topology on $\mathcal{C}(X,Y)$ to work with homotopy.","We know that the compact open topology on $\mathcal{C}(X,Y)$ is a good choice for topology on the set of continuous maps, but this seems really efficient, both naively and with respect to existence of good theorems, when $X$ is a locally compact Hausdorff topological space. For instance, given a map $H:A \times X \to Y$, then, if $X$ is locally compact Hausdorff, we can assure that $H$ is continuous if and only if the induced map $\widetilde{H}: A \to \mathcal{C}(X,Y)$ given by $\widetilde{H}(a)=H(a, \cdot)$ is continuous. Now, in my intuition, I prefer to see homotopies as the maps $\widetilde{H}$, when $A=[0,1]$. However my point of view is not formally justified, given that there is an inconsistency regarding to what are homotopies in the two points of view, since the ""iff"" statement above need not hold on general spaces. Therefore, I was thinking, and this is my question: Q : What happens when instead of considering the compact open topology, we consider the final topology on $\mathcal{C}(X,Y)$, with respect to the family $\{\widetilde{H_{\lambda}}\}_{\lambda \in \Lambda}$ of induced maps coming from continuous maps $H_{\lambda}: A \times X \to Y$? Is this manageable/interesting/has this been done? Relevant: I've seen the following questions: Viewing Homotopies as Paths in $\mathcal{C}^0(X,Y)$ , https://mathoverflow.net/questions/35246/the-definition-of-homotopy-in-algebraic-topology/ , but none of them addresses the suggestion made here, which is the main interest of this question.","['algebraic-topology', 'general-topology', 'soft-question', 'homotopy-theory']"
1825999,Definition of degree of a coherent sheaf,"Let $E$ be a coherent sheaf on a scheme $X$. Let $d = \text{dim}X$ be the dimension of $E$. Huybrechts and Lehn define the degree of $E$ to be:
$$
\text{deg} E := \alpha_{d-1}(E) - \text{rk}(E)\cdot\alpha_{d-1}(\mathcal{O}_X)
$$
where $\alpha_i$ is the $i$th coefficient of the Hilbert polynomial, and $\text{rk}(E) := \frac{\alpha_d(E)}{\alpha_d(\mathcal{O}_X)}$.
Then they say that it follows from the Hirzebruch-Riemann-Roch formula that on a smooth projective variety this definition gives $\text{deg}(E) = c_1(E)\cdot H^{d-1}$ where $H$ is an ample divisor, and in particular that $\text{deg}(E) = \text{deg}(\text{det}(E))$. It is not clear to me why this follows from the HRR. Could you help me clear it up? Thanks.",['algebraic-geometry']
1826003,Probability in $S_{15}$,"We consider the set of permutations of the first fifteen natural numbers.
What is the probability that $1$ and $2$ aren't contiguous? My attempt: Denote by $C_{12}=$ ""The numbers $1,2$ are contiguos""; $R_i^{(1)}=$ ""The number $1$ is in i-th position "". Now, we have 
$$P(C_{12})=\sum_{i=1}^{15}P(C_{12}|R_i^{(1)})P(R_i^{(1)}),$$ 
where $P(R_i^{(1)})=1/15$ for $i=1,2,\ldots,15$ and $P(C_{12}|R_i^{(1)})=2/14$ for $i=2,3,\ldots 14$ conversely $P(C_{12}|R_1^{(1)})=P(C_{12}|R_{15}^{(1)})=1/14$.
In this way, we obtain $P(C_{12})=2/15$, then $$1-P(C_{12})=13/15.$$
Is it correct my attempt?","['permutations', 'probability-theory', 'probability']"
1826008,What is the logarithm of $(a-b)\delta_{ij}+b$?,"Just now I came across the expression similar to: $x_{ij} = (a-b)\delta_{ij}+b$ The author then somehow converts this expression, into: $\ln x_{ij} = (\ln a-\ln b)\delta_{ij}+\ln b$ This comes completely out of the blue for me since after taking logarithms on both sides, I would have never simplified R.H.S. $\ln [(a-b)\delta_{ij}+b]$ to the expression given above since the logarithm of a sum is not a sum of the individual logarithms in general. What is the justification of what author did? Does that Kronecker delta have some magic property which allows this? If I put $1$ or $0$ for Kronecker delta, I do get correct values of $x_{ij}$ which probably means that what author has done is actually right. Any help is highly appreciated. Thank you","['algebra-precalculus', 'logarithms']"
1826022,Does associativity imply commutativity?,"I used to think that commutativity and associativity are two distinct properties. But recently, I started thinking of something which has troubled this idea:
$$(1+1)+1 = 1+ (1+1)\implies 2+1=1+2$$ Here using associativity of addition operation, we've shown commutativity. In general, $$\underbrace{(1+1+\dots+1)}_{a \, 1\text{'s }}\ \ + \ \ \underbrace{(1+1+\dots+1)}_{b \, 1\text{'s }}=\underbrace{(1+1+\dots+1)}_{b \, 1\text{'s }}\ \ + \ \ \underbrace{(1+1+\dots+1)}_{a \, 1\text{'s }} \\ \implies a+b=b+a$$
For any natural $a,b$.
Hence using only associativity we prove commutativity. That this can be done, is disturbing me too much. Is this really correct? If yes, then are associativity and commutativity closely related? Or is it because of some other property of natural numbers? If yes, then can it be done for other structures as well?","['abstract-algebra', 'associativity', 'binary-operations', 'elementary-number-theory']"
1826031,How does analytic continuation lets us extend functions to the complex plane?,"I'm trying to understand analytic continuation and I noticed on wolfram that it allows the natural extension of the definition trigonometric,
  exponential, logarithmic, power, and hyperbolic functions from the
  real line $\mathbb{R}$ to the entire complex plane $\mathbb{C}$ So how does it extend, say, $f(x) = \sin(x)$, $x \in \mathbb{R}$ to the complex plane? What are the steps that have to be taken to extend this function (and others) to the complex plane?","['analyticity', 'complex-analysis', 'complex-numbers']"
1826038,Pork roast defrost using calculus,"I am really stuck on this problem for calculus and I could use some help A pork roast is removed from the freezer and left on the counter to defrost. The temperature of the pork roast was $−4^\circ C$ when it was removed from the freezer, and $t$ hours later was increasing at a rate of
$$T′(t)=8e^{−0.3t} \quad^\circ C\text{/hour}.$$ Assume the pork roast is defrosted when its temperature reaches $11^\circ C$.  How long does it take for the pork roast to defrost? (Estimate answer rounded off to 3 decimal places.) I found the integral to be $$\frac{-80}{3} e^{-3(t/10)}+C$$ but I don't know where to go from here please help me if you can","['derivatives', 'calculus']"
1826066,Algorithm for finding limits,"Programs like Mathematica or Wolfram Alpha are able to calculate very complex limits with apparent ease. I'm trying to make my own program to compute limits. I've searched all over, but haven't found anything about how they do it. What algorithm can I use to compute limits?",['limits']
1826075,About equivalent norms on a vector space,"Definition. A norm $\|\cdot\|$ in a vector space $X$ is said to be equivalent to a norm $\|\cdot\|_0$ on $X$ if there are positive numbers $a$ and $b$ such that for all $x \in X$ we have $$ a\| x \|_0 \leq \|x\| \leq b\|x\|_0 $$ My question . If two norms $\|\cdot\|$ and $\|\cdot\|_{0}$ on a vector space $X$ are equivalent, then $\|x_{n} - x\| \rightarrow 0$ if and only if $\|x_n - x\|_0 \rightarrow 0$. I know that two equivalents norms induce same the topology. How can I use it to prove the sentence. Ref: (Kreyszig) Introductory Functional Analysis with Applications.",['functional-analysis']
1826078,Sard's Theorem Using Integration?,"How exactly do we clean up this heuristic proof of Sard's theorem, from Schwarz' `Differential Topology for Physicists' using the Jacobian $J(f)(x)$: ""A heuristic justification for Sard's theorem is the following: if $f$ is a smooth one-to-one map on $S \subset E$, the volume of $S' = f(S)$ equals $\int_S |J(f)(x)|dx$. If $f$ is smooth, but not necessarily one-to-one, the volume of $S'$ is at most this integral. Applying this to the case where $S$ is the set of singular points of $f$, we conclude that the volume of $S'$ cannot be greater than zero, since $J(f)(x) = 0$ for all $x \in S$. This is not a complete proof because, strictly speaking, the formula $\mathrm{vol}S' = \int_S |J(f)(x)| dx$ only applies if $S$ satisfies certain conditions (for example, if $S$ is open). But it is not hard to make the proof watertight."" ? Does it link up with, or even maybe motivate, the proof from Milnor of Sard, If $F:M^m \to N^n$ is a smooth map between smooth manifolds of dimension $m$ and $n$ respectively, then $F(C)$ has measure zero in $N$ (where $C = \{x \in M : {rank}\; dF_x < n\}$) motivated here & given here , which amounts to writing $C = (C\smallsetminus C_1)\cup (C_1 \smallsetminus C_2) \cup \cdots \cup (C_{k-1} \smallsetminus C_k) \cup C_k$ (where $C_i$ denotes the set of points in $M$ for which all partial derivatives of order $\le i$ vanish at $x$) and then show that the image under $F$ of each of the sets in the union on the r.h.s. has measure zero in $N$. and invoking the constant rank theorem, Fubini's theorem & Taylor's theorem at various steps?","['manifolds', 'real-analysis', 'differential-geometry', 'differential-topology']"
1826100,"Derivate a function defined by an integral, whose variable are the integration limits","I have to find the derivative of the following one-variable function and evalue it for $t=0$: $$g(t)=\int_t^{t^2} \cos(tx)dx$$ In class, we saw a formula that says that a function such as $$F(t)=\int_{a(t)}^{b(t)}f(x,t)dx$$ has for a derivative $$F'(t)=f(b(t),t) \cdot b'(t)-f(a(t),t) \cdot a'(t)+\int_{a(t)}^{b(t)}\frac{\partial f(x,t)}{\partial t}dx$$ I succeeded applying the formula but the last term - the integral term - gives $$ t\cos(t^3) - \cos(t^2)+\frac{\sin(t^3)-\sin(t^2)}{t^2}$$ The thing is I cannot evalue it for $t=0$ because of the division by $t^2$, though the answer to the question is $f'(0)=-1$. How do I get that result?","['derivatives', 'definite-integrals']"
