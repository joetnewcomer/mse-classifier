question_id,title,body,tags
3593688,Calculating the tangent space of the manifold of probability measures on a finite set,"Let $I$ be a finite set, $\mathcal{F}(I):= \{I\to\mathcal{R}\}$ the vector space of functions on $I$ with basis $e_i$ , where $e_i(i)=1, e_i(j) = 0 (i \neq j)$ . Let $\mathcal{S}(I)$ be the corresponding dual space and $\{\delta^i\}_i$ the respective dual basis.
Consider $\mathcal{P}_+:= \{ \sum_{i\in I} \mu_i \delta^i  \mid \mu_i>0, \sum\mu_i=1 \}$ . In the book that I'm reading the authors say the tangent space in a point $\mu \in \mathcal{P}_+$ is obsviously $\mathcal{S}_0(I):=\{\sum_{i \in I} \mu_i \delta^i \mid \sum \mu_i = 0\}$ . Why is that ? I think in order to calculate the tangent space we would calculate the image of the differential of $\varphi: (\mu_1,...,\mu_{s-1})\to \sum_{i=1}^{s-1}\mu^i\delta^i+(1-\sum_{i=1}^{s-1}\mu_i)\delta^s$ , but I'm not sure how to do this. Can some one help? Of course $\mathcal{S}_0(I)$ has the correct dimension and so it is at least isomorphic to the tangent space but whats special about it ?","['information-geometry', 'tangent-spaces', 'differential-geometry']"
3593722,How to round binaries,"I was given this question as homework but unfortunately amid this COVID time schools are down and so prof is not too clear in his explanation and the book does not mention anything regarding rounding, only how to convert. Books: ""Fundamentals of Discrete Math for Computer Science"" - Tom Jenkyns, Ben Stephenson Convert 1203.201 from base 10 to base 2, but round your answer: (a) To 6 significant figures and to 12 significant figures. (b) To 3 places after the base point. (c) What is the rounding rule for base 2? From my calculation, it comes out to be (1203.201)base10 = (100|1011|0011|.0011|0011|0111)base2 a. 6 sig figures: 100|1100|0000 => since the 7th figure is '1' we round up but it looks to me like it only has 5 sig figures now. 12 sig figures: 100|1011|0011|.0 => this look simple since the 13rd figure is '0' b. 3 digits after base point: 100|1011|0011|.000 => the 4th digit after the base point is 1 so we round up but once again it doesn't look like 3 digits anymore. c. I am tempted to put it like for decimal whereas if the digit after is '1' then we round up Thank you for checking in.",['discrete-mathematics']
3593726,solution to recurrence relation $ a_{n+2}=-2 a_{n+1}+8 a_n+4n^2$,"Find the solution for the below recurrence relation with initial conditions $a_1=10$ , $a_2=31$ $$
a_{n+2}=-2 a_{n+1}+8 a_n+4n^2\,.
$$ Let us first consider the corresponding homogeneous recurrence relation $a_n = -2a_{n-1} + 8a_{n-2}$ The characteristic equation is $r^2 + 2r - 8  = (r + 4)(r - 2) = 0$ The characteristic equation has 2 distinct roots therefore the general solution is of the form $\alpha_1(-4)^n + \alpha_2(2^n)$ We also have that there is a Particular solution of the form $1^n(\mu_2 n^2 + \mu_1 n + \mu_0)$ , as 1 is not a root of the characteristic equation. $\mu_2 n^2 + \mu_1 n + \mu_0 = -2 (\mu_2 (n-1)^2 + \mu_1 (n-1) + \mu_0) + 8(\mu_2 (n-2)^2 + \mu_1 (n-2) + \mu_0) + 4(n-2)^2$ $\mu_2 n^2 + \mu_1 n + \mu_0 + 2 (\mu_2 (n-1)^2 + \mu_1 (n-1) + \mu_0) - 8(\mu_2 (n-2)^2 + \mu_1 (n-2) + \mu_0) - 4(n-2)^2 = 0$ $\mu_2 n^2 + \mu_1 n + \mu_0 + 2 (\mu_2 (n^2 - 2n + 1) + \mu_1 (n-1) + \mu_0) - 8(\mu_2 (n^2 - 4n + 4) + \mu_1 (n-2) + \mu_0) - 4(n-2)^2 = 0$ $\mu_2 n^2 + \mu_1 n + \mu_0 + 2 (\mu_2 n^2 - 2 \mu_2 n + \mu_2 + \mu_1 n - \mu_1  + \mu_0) - 8(\mu_2 n^2 - 4 \mu_2 n + 4 \mu_2 + \mu_1 n - 2\mu_1  + \mu_0) - 4(n^2 - 4n + 4) = 0$ $\mu_2 n^2 + \mu_1 n + \mu_0 + 2 \mu_2 n^2 - 2 \cdot 2\mu_2 n + 2 \mu_2 + 2 \mu_1 n - 2 \mu_1  + 2 \mu_0 - 8\mu_2 n^2 + 8 \cdot 4 \mu_2 n - 8 \cdot 4 \mu_2 - 8 \mu_1 n + 8 \cdot 2\mu_1  - 8\mu_0 - 4n^2 + 16n + -16 = 0$ $-5\mu_2 n^2 - 4n^2 - 5\mu_1 n +16n -5 \mu_0 + 28\mu_2 n + 14\mu_1 -30\mu_2  - 16 = 0$ $-n^2 (5\mu_2 + 4) + n(- 5\mu_1 + 28 \mu_2 + 16) + (14\mu_1 -30\mu_2 - 5\mu_0 -16)  = 0$ Then I want to solve for $\mu_2, \mu_1, \mu$ , and then find the values of $\alpha_1, \alpha_2$ using the initial conditions. Am I correct Up to this point? I feel like I may be over complicating it somewhat, as so far I have not been able to find a correct solution.","['recurrence-relations', 'discrete-mathematics']"
3593728,Aternating sum of an increasing sequence of positive integers,"Suppose $A = (a_n) = (a_1, a_2, a_3, . . .)$ is an positive, increasing sequence of integers. Define an $A$ - expressible number $c$ if $c$ is the alternating sum of a finite subsequence of $A.$ To form such a sum, choose a finite subset of the sequence $A,$ list those numbers in increasing order (no repetitions allowed), and combine them with alternating plus and minus signs. We allow the trivial case of one-element subsequences, so that each an is $A-$ expressible. Definition. Sequence $A = (a_n)$ is an “alt-basis” if every positive integer is uniquely $A-$ expressible. That is, for every integer $m > 0,$ there is exactly one way to express $m$ as an alternating sum of a finite subsequence of $A.$ Examples. Sequence $B = (2^{n−1}) = (1, 2, 4, 8, 16, . . .)$ is not an alt-basis because some numbers are B-expressible in more than one way. For instance $3 = −1 + 4 = 1 − 2 + 4.$ Sequence $C = (3^{n−1}) = (1, 3, 9, 27, 81, . . .)$ is not an alt-basis because some numbers (like 4 and 5) are not C-expressible. An example of an alt-basis is $\{2^n-1\}=\{1,3,7,15,31,\ldots\}$ Is there a fairly simple test to determine whether a given sequence is an alt basis? I have attempted to solve this from a limited knowledge in sequences and have found out various kinds of sequences do not work but fail to see what it is that could make it work.","['elementary-number-theory', 'sequences-and-series']"
3593740,Show that the stereographic projection is an homeomorphism,"I want to show that $f: \Bbb{R}^2 \to \Bbb{R}^3$ defined by $$f(x,y) = \left(\frac{2x}{1+x^2+y^2},\frac{2y}{1+x^2+y^2},\frac{1-(x^2+y^2)}{1+x^2+y^2}\right)$$ is a parameterization. My definition of parameterization is immersion that is a homeomorphism over its image. I can show that $Df$ is injective when $x,y \neq 0$ or only one of them is $0$ . My problem is when $x = y = 0$ . In the case of $x = y = 0$ , seems that $Df$ is not injective so, should I consider $\Bbb{R}^2 - \{(0,0)\}$ instead of $\Bbb{R}^2$ ? I'm not sure about that, because I think that in this case, we must find an homeomorphism between $\Bbb{R}^2$ and $S^2 - \{(0,0,1)\}$ . I appreciate any help. EDIT. I found $$Df(x,y) = \frac{2}{(1+x^2+y^2)^2}\left(\begin{array}{ccc}
1+y^2-x^2 & 1+x^2-y^2\\
-2xy & -2xy\\
-2x & -2y
\end{array}\right).$$ If, $x = y = 0$ , then I cannot conclude that $Df$ is injective.","['derivatives', 'differential-geometry', 'real-analysis']"
3593744,The intuition behind the idea of 'embedding' in rings,"Apologies in advance if this was asked before. Say we have $X$ is embedded into $Y$ , my understanding is that there exists an injective ring homomorphism from $X$ to $Y$ . I have the following questions about the idea of 'embedding': (as I want to get more familiar with this terminology) $1)$ Is the idea of embedding, loosely speaking, saying that there is a subring in $Y$ that is isomorphic to $X$ ? $2)$ I saw this question earlier today, where the answer says 'properly, you get an embedding $\mathbb N\to K$ '. However though, can the naturals be embedded to an arbitrary field $K$ if $K$ is finite? $3)$ Lastly, maybe just a check of my understanding, is an inclusion map always an embedding map?","['ring-theory', 'abstract-algebra', 'terminology']"
3593751,Geometric Intuition of Systems of Parameters,"I'm currently reading Eisenbud's Commutative Algebra with a View Toward Algebraic Geometry , and he defines a system of parameters in Section 10.1. He says that, geometrically, if $x_1,\ldots,x_d$ form a system of parameters for the local ring of a point $p$ on an algebraic variety, then the values of the functions $x_i$ determine points near $p$ up to a ""finite ambiguity"". The example given is that $y$ and $y-x^2$ form a system of parameters for $k[x,y]_{(x,y)}$ , and he points out that only finitely many points lie in the intersections of $y-x^2=\delta$ and $y=\varepsilon$ for small $\delta$ and $\varepsilon$ . Is the ""finite ambiguity"" in this sense that each point near $(0,0)$ is determined by its values on these functions up to the sign of the $x$ -coordinate? For example the point $(1,0)$ isn't quite defined uniquely by these values, but there are only finitely many other points which share the same values, namely just $(-1,0)$ . If that is the case, then I'm wondering if this characterisation is necessary and sufficient, but don't really know how to begin proving it. I've taken the notion of points ""near"" each other to mean they lie in some Zariski open neighbourhood. Let $V$ be an affine variety, and let $R$ be the local ring of a point $p$ on $V$ . Say that $\dim R=d$ , and let $x_1,\ldots,x_d$ be functions on our variety. Suppose that there exists some Zariski open neighbourhood $U\subseteq V$ with $p\in U$ such that, for every point $q\in U$ , we have that the set $$\{r\in U:x_i(r)=x_i(q)\text{ for }1\leq i\leq d\}$$ is finite. Then is this criteria necessary and sufficient for $x_1,\ldots,x_d$ to be a system of parameters for $R$ ? Edit: It seems like there are trivial counterexamples to my criteria as written. For example, if we localise at the point $(1,1)$ instead of $(0,0)$ as in his example, then clearly no power of $(x-1,y-1)$ lies in $(y,y-x^2)$ . Then $y,y-x^2$ cannot be a system of parameters for this new ring, despite satisfying my conditions. However if we specify additionally that $p$ lies in the subvariety $V(x_1,\ldots,x_d)$ , then this rules out such counterexamples. This is also consistent with his example. Update: I've added a potential answer based on another reading of his example. If anybody has any thoughts, or thinks that the argument is faulty, then please let me know.","['affine-varieties', 'algebraic-geometry', 'commutative-algebra']"
3593764,Can the derivative of a real function be imaginary?,Suppose $f$ is a real function (e.g. mapping $\mathbb{R} \rightarrow \mathbb{R}$ ). Is it possible for its derivative (i.e. $\frac{d}{dx}f(x)$ ) to be imaginary?,"['complex-analysis', 'derivatives']"
3593806,Proof of ${ \prod_{i=0}^{n}{x_i} < \overline{x}^{n} }$,"Problem Definition: I was studying randomized algorithms and the following appeared: ${ 1- \prod_{i=0}^{N}{(1- {y_i})} \ge  \beta_k {z_j} }$ We also know that ${ {y_i} + ... + {y_k} \ge {z_j} }$ And ${ {y_i},{z_j} \in [0,1] }$ And the following was written: ""The expression on the left is minimized when ${ {y_i} = {z_j}/k}$ "" by minimizing, it means: ${ 1- \prod_{i=0}^{N}{(1- {y_i})} \ge  1- \prod_{i=0}^{N}{(1- {{z_j}/k})}  }$ (Randomized Algorithms, Montwani && Raghavn; page 106, 107). My reasoning, first try: So, I figure that to minimize ${ 1- \prod_{i=0}^{N}{(1- {y_i})} }$ you need to minimize ${{y_i}}$ Now, At the very least: ${ {y_i} + ... + {y_k} \ge {z_j} }$ meaning, ${z_j/k}$ is the minimum average possible of all the y. ${z_j/k}$ can't then be always smaller than ${y_i}$ . Ok, so that didn't work... So, It seems to me that the only way possible out of this is if: ${ \prod_{i=0}^{n}{x_i} <  \overline{x}^{ n} }$ holds as a general property and if ${x_i}$ in this example would be ${1-y_i}$ My apologies if anything is wrongly explained or out of what's normal around mathematicians and this website, I'm fairly modest at math! Thanks for your help! I've search quite a bit, but I don't seem to find a proof about it or any mention. It's also hard to google math. Can you help me?","['calculus', 'linear-algebra', 'algorithms', 'probability-theory', 'probability']"
3593810,"Let $F_n$ be free on $n$ letters and $g_1,...,g_{2m}\in F_n$. Can $F_n/⟨⟨[g_1,g_2],...,[g_{2m-1},g_{2m}]⟩⟩$ have torsion elements?","Let $F_n$ be the free group on $n$ letters.  Let $g_1,...,g_{2m} \in F_n$ , can the group $$F_n / \langle\langle[g_1,g_2],...,[g_{2m-1},g_{2m}]\rangle\rangle$$ ever have torsion elements? The double angle brackets means ""normal subgroup generated by"" and $[a,b] = aba^{-1}b^{-1}$ . This problem arose when I saw a question in an old paper of Yanagawa (""On Ribbon 2-knots, II"") that mentioned that it was unknown if a complement of a ribbon 2-knot could have torsion. These groups have presentations that are special cases of what I asked about in the question so I was guessing there was a simple counterexample to my question, but I had no inspiration to find it. Just FYI - the main result of that paper is a well known open problem (are ribbon disk complements aspherical?), so the proof of the main result is flawed... Although I didn't go looking for the error. Edit : I just wanted to clarify that the elements $g_i$ are arbitrary elements (not necessarily the generators).  So user1729's nice answer answers the question in the case where the $g_i$ are generators, but I am still interested in the question for general $g_i$ .  Also,  for those interested in the topological origin of this problem, I actually messed up with the relations that arise in the context of the aforementioned paper.  The groups that arise as ribbon group complements are of the form $F_n / << x_1 = x_2^{g_1}, x_2 = x_3^{g_2},...,x_{n_1} = x_n^{g_n} >>$ where here the $x_i$ are the generators of $F_n$ and again the $g_i$ are arbitrary elements of $F_n$ .  I would like to know if these groups can have any torsion as well.","['combinatorial-group-theory', 'group-presentation', 'group-theory', 'torsion-groups']"
3593821,Approximate $L^2$ function by convolving with mollifiers,"Let $\eta_\delta$ be a mollifier (i.e. positive real-valued function on $\mathbb{R}^2$ , supported on the ball of radius $\delta$ centered at the origin, whose integral is 1), and $f$ is a compactly-supported $L^2$ -function. How can we prove that $$ || f - f*\eta_\delta||^2_{L^2} \rightarrow 0 $$ as $\delta\to 0$ ? (This is standard in the proof that we can approximate $L^2$ -functions via smooth functions, by the use of mollifiers). The computation leads to bounding $$ \int_{\mathbb{R}^2}\bigg| \int_{\mathbb{R}^2}  \eta_\delta(y)(f(x)-f(x-y)) dy\bigg|^2 dx \le \int_{|y|<\delta}|\eta_\delta(y)|^2\left(\int_{\mathbb{R}^2}|f(x)-f(x-y)|^2 dx\right) dy,$$ at which point I get stuck. Is it true that $|| f(x)-f(x-y)||^2_{L^2}\to 0$ as $|y|\to 0$ ? This could be used above but it wouldn't even finish, I think. Thank you for your help!","['convolution', 'analysis', 'real-analysis', 'lp-spaces', 'functional-analysis']"
3593878,How to integrate a function of $Ae^{kt} + Be^{-kt}$?,"How to integrate $$\int_0^T \frac{C(Ae^{kt} - Be^{-kt}) + D}{(Ae^{kt} + Be^{-kt})^2} dt$$ where A, B, C, D and k are some constants? I tried using integration by parts where $U = C(Ae^{kt} - Be^{-kt}) + D$ and $dV = (Ae^{kt} + Be^{-kt})^{-2}$ . Using the usual formula for anti-derivate, I got $V = -(Ae^{kt} + Be^{-kt})^{-1}(kAe^{kt} - kBe^{-kt})^{-1}$ . However, if I then recompute $dV$ from this $V$ , I can't get back to the original $dV = (Ae^{kt} + Be^{-kt})^{-2}$ . What did I do wrong?
Is there another way to derive this integral? Update Use substitution: Let $u = (Ae^{kt} + Be^{-kt})^{-1}$ . It follows that $du = -\frac{k(Ae^{kt} - Be^{-kt})}{(Ae^{kt} + Be^{-kt})^2}$ . But how do I incorporate the constant D? Solution See user5713492's answer below.","['integration', 'calculus', 'hyperbolic-functions']"
3593894,Misunderstanding the Taylor Remainder Theorem,"I believe I am misinterpreting the Taylor Remainder theorem somehow. The Taylor Remainder theorem is (taken from Briggs 3rd ed Calculus: Early Transcendentals) Let $f$ have continuous derivatives up to $f^{(n+1)}$ on an open interval $I$ containing $a$ . For all $x$ in $I$ , $$f(x) = p_n(x) + R_n(x)$$ where $p_n$ is the $n$ th-order Taylor polynomial for $f$ centered at $a$ and the remainder is $$R_n(x) = \frac{f^{(n+1)}(c)}{(n+1)!}(x-a)^{n+1}$$ for some point $c$ between $x$ and $a$ . Suppose that my function is $f(x)=e^x$ , $a$ is set to $0$ , and that I'm considering the 2nd-order Taylor polynomial for $e^x$ . Namely, $$p_2(x) = 1+x +\frac{x^2}{2}$$ Then the remainder will be $$R_2(x) = \frac{e^c}{3!}x^3$$ Here's where I think I might be messing up. If I consider the interval $(-5,5)$ , which is an open interval containing $0$ , where $f(x)$ is $(n+1)$ -times differentiable, I am unable to come up with a $c$ where the function $e^x$ is identical to $1+x +\frac{x^2}{2}+\frac{e^c}{3!}x^3$ in the interval $(-5,5)$ . Here is a link to a Desmos page where I tried to find such a $c$ . So I guess the main question here is this: Am I supposed to specify the interval $I$ from the beginning, or is the theorem stating that there is some interval $I$ containing $a$ where $f(x)=p_n(x)+R_n(x)$ for all $x\in I$ ? Or perhaps there's some other key idea that I'm missing here. Please let me know where I'm going wrong.","['calculus', 'taylor-expansion']"
3593905,Second Order Linear ODE (general solution),"Find the general solution to the ODE shown below: $$y''+4y'+4y=\frac{e^{-2x}}{\sqrt{x^2 - 1}}$$ Below is all of my progress so far: Clearly, this is a second-order linear, non-homogenous ODE. So, the general solution can be written as: $$y = y_h+y_p$$ So, yh: $$y''+4y'+4y = 0$$ $$r^2+4r+4 = 0$$ $$r^2+2r+2r+4 = 0$$ $$r(r+2)+2(r+2) = 0$$ $$∴r=-2$$ So, this means that: $$y = c_{1}e^{-2x}+c_{2}e^{-2x}$$ Now we must consider yp: We can use the method of undetermined coefficients. This is where I get stuck I have no idea how to use the method of undetermined coefficients to find yp. Any help with this question would be much appreciated since I've been stuck on it for a long time. Thanks in advance.","['derivatives', 'ordinary-differential-equations']"
3593945,Convergence of Approximations of the Identity in $L^p(\mathbb R^d)$,"(context: in a comment to an answer of mine mentioned below, a user has asked for the proof of one of the steps) In this answer , one of the steps mentions that If $f\in L^p(\mathbb R^d)$ , $g\in L^1(\mathbb R^d)$ with $\int_{\mathbb R^d} g=1$ and $g_n(x)=n^d\,g(nx)$ , then $$\lim_{n\to\infty}\|f-f*g_n\|_p=0.$$ What would be the proof of this?","['measure-theory', 'lp-spaces', 'lebesgue-integral', 'real-analysis']"
3594013,"Any errors? My proof that if $\left(A - B\right) \cup \left(B - A\right) = A \cup B$, then $A \cap B = \emptyset$","If $A\cup B=(A-B)\cup(B-A)$ , then $A\cap B=\emptyset$ . Proof by Contrapositive . If $A\cap B\ne\emptyset$ , then $A\cup B\ne(A-B)\cup(B-A)$ . Suppose that there exists a member of $A\cap B$ , $x$ . Then, $x\notin(A-B)$ because $x$ is in $B$ . Similarly, $x\notin(B-A)$ because $x$ is in $A$ . So, $x\notin(A-B)\cup(B-A)$ . However, since $x$ belongs to $A$ , $x\in A\cup B$ . Therefore, $A\cup B\not\subseteq(A-B)\cup(B-A)$ , and $A\cup B\ne(A-B)\cup(B-A)$ . Are there any errors or room for improvement in the above proof?","['elementary-set-theory', 'solution-verification']"
3594078,Show that these two conditional statements are tautologies without using truth tables.,"These are the two expressions : $$[(p \rightarrow q) \land (q \rightarrow r)] \rightarrow (p \rightarrow r)$$ $$[(p \lor q) \land (p \rightarrow r) \land (q \rightarrow r)] \rightarrow r$$ For the first statement this is what I have tried : $$
\begin{align}
& [(p \rightarrow q) \land (q \rightarrow r)] \rightarrow (p \rightarrow r) \\
& \equiv \neg[(p \rightarrow q) \land (q \rightarrow r)] \lor (p \rightarrow r) \space\space\space [\text{because} \space\space  p \rightarrow q \equiv \neg p \lor q] \\
& \equiv \neg (p \rightarrow q) \lor \neg (q \rightarrow r) \lor (p \rightarrow r) \space\space\space [\text{De Morgan's Law}] \\
& \equiv (p \land \neg q) \lor (q \land \neg r) \lor (\neg p \lor r) \space\space\space\space\space\space [\text{because} \space \neg (p \rightarrow q) \equiv p \land \neg q \space \text{and} \space p \rightarrow q \equiv \neg p \lor q] \\
\end{align}
$$ Am I proceeding correctly? What should I do next? I can't seem to figure out. And for the second one, $$
\begin{align}
& [(p \lor q) \land (p \rightarrow r) \land (q \rightarrow r)] \rightarrow r \\
& \equiv [(p \lor q) \land \{(p \lor q) \rightarrow r\}] \rightarrow r \space\space\space [\text{because} \space (p \rightarrow r) \land (q \rightarrow r) \equiv (p \lor q) \rightarrow r]\\
& \equiv [(p \lor q) \land \{\neg (p \lor q) \lor r\}] \rightarrow r \space\space [\text{because} \space\space  p \rightarrow q \equiv \neg p \lor q] \\
& \equiv [(p \lor q) \land \{\neg p \land \neg q \lor r\}] \rightarrow r \space\space \space [\text{De Morgan's Law}] \\
\end{align}
$$ I'm stuck here too. Any help would be appreciated. Thanks.","['propositional-calculus', 'logic', 'discrete-mathematics']"
3594100,"Is there a well known proof that shows solutions of $y^2=3x^4+1$ are only (1,2), (2,7) over positive integers?","I found a theorem from a book 'Diophantine equations', L. J. Mordell, which says The equation $y^2 = Dx^4+1$ where $D>0$ and is not a perfect square, has at most two solutions in positive integers. But I can't find any proof in this book, and I tried to find its proof but I failed.
Is there anybody knows its proof?","['number-theory', 'diophantine-equations']"
3594122,WTS) Geometric distribution is the only discrete memoryless distribution,"I want to prove that if a discrete distribution is memoryless, the distribution must be geometric. I read up on older posts asking this question, but I couldn't follow any of the answers. How should I get started on this proof? Any hints or steps would be appreciated.","['statistics', 'probability-distributions', 'stochastic-processes', 'markov-process', 'probability']"
3594167,Limit of an accumulation function(integral involved),"I was asked to evaluate the following limit: $$
\lim\limits_{x \to 0} \int_{0}^{x}\frac{\cos t^3}{t+x}dt
$$ I've tried to evaluate and indefinite form: $$
\int\frac{\cos t^3}{t+x}dt
$$ by partial integration assuming that $x=const$ . An hour later I got nothing. WolframAlpha also can't represent this in ""standard mathematical functions"". Now, I'm stuck with it. What am I supposed to try next?","['integration', 'limits', 'definite-integrals']"
3594219,Evaluating $\lim_{x\to 0}\left(\frac{e}{(1+x)^{1/x}}\right)^{1/x}$,"I need to evaluate the following limit, which is of the indeterminate form "" $1^{\infty}$ "". $$\lim_{x\to 0}\left(\frac{e}{(1+x)^{1/x}}\right)^{1/x}$$ The answer of this limit should be $\sqrt{e}$ . I have tried it many times (using both binomial expansion and exponential expansion) but it is not working out. I have even tried online limit calculator like mathway but it says ""I'm unable to solve this"". Then I tried MathPortal's Limit Calculator . This gives the answer correctly but doesn't shows steps. Then I tried WolframAlpha, but you can only access its step-by-step solution if you pro member (which is paid subscription) and I'm not one. So if anybody can help me solve this limit it would be highly appreciative. NOTE: I am a high school student.","['limits', 'algebra-precalculus']"
3594350,What are the unknown steps to show $\mathbf{F}=-\nabla\psi$?,"Given: $\mathbf{F}=F(r)\ \mathbf{\hat{r}}$ is a spherically symmetric radial vector field which is continuous everywhere except at origin. To prove: $\mathbf{F}=-\nabla \psi$ Proof: \begin{align}
\mathbf{F} \cdot \mathbf{\hat{r}}&=F(r)\ \mathbf{\hat{r}} \cdot \mathbf{\hat{r}}=F(r)=\dfrac{d(\int F\ dr)}{dr}\\ &=\dfrac{d\psi}{dr}=\nabla \psi \cdot \mathbf{\hat{r}}
\end{align} From here we cannot straight away deduce that: $\mathbf{F}=\nabla\psi$ UNKNOWN STEPS ??? $$\mathbf{F}=-\nabla\psi$$ $\mathbf{F}$ is conservative. Question: From what steps (unknown to me) can we get $\mathbf{F}=-\nabla\psi\ $ ?","['multivariable-calculus', 'calculus', 'physics']"
3594365,Tough definite integral,"I had this integral in my assignment and I can't figure out a way to solve this. I can see that in the bracket, there is $x \ln x$ and $\ln(x) +1$ which is the derivative of $x \ln x$ so I thought maybe some substitution; but the exponential powers of $e$ destroyed that hope. How do I solve this integral? Let $$
I_n = \int_1^{1+\frac{1}{n}}\left\{[(x+1)\ln x +1] e^{x (e^x \ln x +1)}+n \right\}\, dx\qquad (n=1,2,\ldots)
$$ Evaluate $ \lim_{n \to \infty} I_n^n$ .","['integration', 'limits', 'definite-integrals']"
3594384,A question about the proof of theorem 1 section 2.2.1 of the evans pde,"My question is about the part of proof of the theorem 1 section 2.2.1 of the evans pde(p24): The only thing that I don't understand is the 
inequality： $$\int_{B(0, \varepsilon)} \Phi(y) \Delta_{x} f(x-y) d y\leq C\left\|D^{2} f\right\|_{L^{\infty}\left(\mathbb{R}^{n}\right)} \int_{B(0, \varepsilon)}|\Phi(y)| d y \leq\left\{\begin{array}{ll}
C \varepsilon^{2}|\log \varepsilon| & (n=2) \\
C \varepsilon^{2} & (n \geq 3)
\end{array}\right.$$ $$ f \in C_{\mathrm{c}}^{2}\left(\mathbb{R}^{n}\right),\Phi(x):=\left\{\begin{array}{ll}
-\frac{1}{2 \pi} \log |x| & (n=2) \\
\frac{1}{n(n-2) \alpha(n)} \frac{1}{|x|^{n-2}} & (n \geq 3)
\end{array}\right.$$ I don't understand the meaning of $C$ ,it may be connected with the  inequality in p22： $$|D \Phi(x)| \leq \frac{C}{|x|^{n-1}},\left|D^{2} \Phi(x)\right| \leq \frac{C}{|x|^{n}} \quad(x \neq 0)$$ Someone can help me to  prove detailedly that inequality ？ Thanks in advance.","['harmonic-functions', 'analysis', 'calculus', 'partial-differential-equations', 'inequality']"
3594466,Egyptian fractions with prime power denominators summing to 1?,"Inspired by On the decomposition of $1$ as the sum of Egyptian fractions with odd denominators - Part II Can we solve the equation $$1=\frac{1}{a_1}+\frac{1}{a_2}+\frac{1}{a_3}+\cdots +\frac{1}{a_n}$$ where $a_1,a_2,a_3,\cdots ,a_n$ are distinct prime powers (primes are allowed) ? I tried a modified greedy-algorithm with different starting vectors and brute force with $6$ entris with limit $200$ , but did not find a representation.","['number-theory', 'summation', 'elementary-number-theory', 'prime-numbers']"
3594469,How to find the maximum of $\boldsymbol{x}^T \boldsymbol{A} \boldsymbol{x}$ subject to $\boldsymbol{q}^T \boldsymbol{x}=1$?,"I want to solve the following problem in $\boldsymbol{x} \in \mathbb R^{n}$ $$\begin{array}{ll} \text{maximize} & \boldsymbol{x}^T \boldsymbol{A} \boldsymbol{x}\\ \text{subject to} & \boldsymbol{q}^T \boldsymbol{x} = 1\\ & x_i \geq 0\end{array}$$ where matrix $\boldsymbol{A}$ is positive definite matrix and $x_i$ denotes the $i$ -th entry of $\boldsymbol{x}$ . Actually, I have tried to use Lagrangian multiplier. I directly transformed the objective function to $-\boldsymbol{x}^T \boldsymbol{A} \boldsymbol{x} + \lambda ( \boldsymbol{q}^T \boldsymbol{x} - 1 )$ and take its first derivative and set that to zero. However, the solution obtained did not maximize the objective function, it just makes $\boldsymbol{x}^T\boldsymbol{A} \boldsymbol{x}$ smaller and smaller. Then I found that the solution of $\min_{\boldsymbol{x}} \boldsymbol{x}^T \boldsymbol{A} \boldsymbol{x}$ with the same constraints is the same with that of $\max_{\boldsymbol{x}} \boldsymbol{x}^T \boldsymbol{A} \boldsymbol{x}$ . Any comments would be appreciated! Update
As comments suggested, I changed the situation to $x_i \geq 0, \forall i$ . Thus for example, when $\boldsymbol{A}= \left[\begin{matrix} {2 \; 0\\ 0 \;1 }\end{matrix} \right]$ and $\boldsymbol{q} = [1,1]^T$ . The problem has a solution $\boldsymbol{x} = [1 ,0]^T$ that maximize the objective function. Can this extend to more general case?","['matrices', 'optimization', 'quadratic-programming', 'non-convex-optimization']"
3594548,Use Szemerédi-Trotter to show that $n$ points in the plane determine at most $O(n^{7/3})$ triangles that contain a fixed acute angle $\alpha$.,I'm doing exercises in Lectures on Discrete Geometry by Jiri Matousek. There's an application of the Szemerédi-Trotter Theorem to a problem of acute-angled triangles: Fix an acute angle $\alpha$ . Use Szemerédi-Trotter to show that $n$ points in the plane determine at most $O(n^{7/3})$ triangles with each triangle having at least one angle $\alpha$ . How do I begin this?,"['euclidean-geometry', 'geometry', 'combinatorial-geometry', 'triangles', 'combinatorics']"
3594700,Condition for perfect packing of ellipse with circles along the major axis,"The question was inspired by this answer . Condition for perfect packing of ellipse with circles: $n$ circles can be perfectly packed
along the major axis of the ellipse with semi-axes $a,b\quad$ iif \begin{align}	
\frac ba&=\sin\frac{\pi}{2\,n}
\tag{1}\label{1}
.
\end{align} Here ""perfectly packed"" means that 
the chain of circles with the centers on the major axis
is inscribed into the ellipse, 
and the radii of the circles at both ends
agree with the curvature of the ellipse 
at the ends of the major axis. Condition \eqref{1} works for both odd (ex. $n=7$ ) and even $n$ (ex. $n=8$ ) Question: Is this a well-known condition? Any reference? Addendum General formula for the radius of $k$ -th circle 
in a chain of $n$ perfectly packed circles along the 
major axis of the ellipse \begin{align}
r_k&=a\,\sin\frac{\pi}{2\,n}\,\sin\frac{(2\,k+1)\,\pi}{2\,n}
,\quad k=0,\dots,n-1
,
\end{align} where $a$ is the major semi-axis, and the location of the center of $k$ -th circle is found as \begin{align}
O_k&=
F_1\cdot\cos^2 \frac{(2\,k+1)\,\pi}{4\,n}
+F_2\cdot\sin^2 \frac{(2\,k+1)\,\pi}{4\,n}
,
\end{align} where $F_1,F_2$ are the focal points of the ellipse. Distances from $F_1,F_2$ to the tangent point 
of the $k$ -th circle with the ellipse
are \begin{align}
|F_1T_k| &= 2\,a\,\sin^2\frac{(2\,k+1)\,\pi}{4\,n}
,\\
|F_2T_k| &= 2\,a\,\cos^2\frac{(2\,k+1)\,\pi}{4\,n}
.
\end{align} \begin{align}
\cos\angle T_kO_kF_2&=
\frac{\sin\frac{k\,\pi}n-\sin\frac{(k+1)\,\pi}n}
{\sin\frac{k\,\pi}n+\sin\frac{(k+1)\,\pi}n}
.
\end{align}","['conic-sections', 'circles', 'geometry', 'reference-request']"
3594753,Who'll win the baseball game when two really good teams play?,"Our team is playing another team that wins 70% of its games. Our team is pretty good but wins only 60% of its games. If these teams have never played before and they've played equally hard opponents, what is the chance our team will be victorius? I think I solved it by comparing the game to flipping coins, but was looking for an answer a little more mathematical or rigorous. My approach is based on flipping coins. The other team's ""coin"" comes up heads 70% of the time (and 30% tails) and our team's ""coin"" comes up heads 60% of the time (and 40% tails). If I flip the coins many times and disregard the outcomes when both coins are heads or both coins are tails, I would expect 18% of the flips our team's coin would have a head and their team's coin would be a tail (0.6*0.3); and 28% of the flips the other team would get a head and our team a tail (0.7*0.4). Thus, our team would be expected to win 39% of the games (0.18/(0.18+0.28) and the other team 71%. I thought I'd ask if this makes sense and for a more mathematical approach. Thank you","['statistics', 'probability']"
3594791,Difficulties in understanding Cassels' proof of the weak Mordell-Weil theorem,"I am currently working myself through Cassels' proof of the weak Mordell-Weil theorem in the book 'Lectures on Elliptic Curves' (chapter 15). I found myself stuck quite close to the end of the proof with a few statements that seem to be elementary number theoretic in nature. We have an elliptic curve $$Y^{2} = F(X) = X^{3} + AX + B$$ and define $\mathbb{Q}[\Theta] := Q[T]/F(X) $ with $ \Theta$ as the image of $X$ . Moreover, we define $M \subset \mathbb{Q}[\Theta]^*/(\mathbb{Q}[\Theta]^*)^{2}$ as the subgroup of all $\alpha(\mathbb{Q}[\Theta]^*)^2$ for which $Norm(\alpha)\in(\mathbb{Q}^*)^{2}$ . (The Norm is defined to be the determinant of the multiplication with $\alpha$ , seen as a linear map over the 3-dim. vector space $\mathbb{Q}[\Theta]$ over $\mathbb{Q}$ ). The clue of the proof is then to construct a homomorphism $$\mu: E(\mathbb{Q})\to M$$ with the properties $\mu(O) = 1(\mathbb{Q}[\Theta]^*)^2$ $\mu(a,b) = (a-\Theta)(\mathbb{Q}[\Theta]^*)^2$ if $b\neq0$ and since we can view $\mathbb{Q}[\Theta]$ as a direct sum of fields, if $(a,0)\in E(\mathbb{Q})$ , then $ F(a)=0$ and one component of $a-\Theta$ is $0$ . This one shall be patched with any element of $\mathbb{Q}^*$ so that the resulting Norm is in $(\mathbb{Q}^*)^2$ . Cassels then goes on to proove that $ker(\mu)=2E(\mathbb{Q})$ and the only thing left to proove is that $im(\mu)$ is finite: final part of Cassels' proof I cant wrap my head around why $gcd\{(r-e_{1}t^2),(r-e_{2}t^2)\}$ divides $(e_{1} - e_{2})$ and why it follows that $r-e_{j}=d_{j}v_{j}^2$ . Also, how does this help in concluding that the image is finite? I'm not sure if this proof is leaving out a few important details or if there's just a major misunderstanding on my side. It'd certainly be awesome if someone who knows/understands this proof could help me!
Thanks in advance! PS I'm also probably going to come up with a followup question for the general case of this last part of the proof. That one requires some algebraic number theory which I don't have a background in. But I wanted to make sure of this special case here first.","['elementary-number-theory', 'algebraic-geometry', 'proof-explanation', 'elliptic-curves']"
3594838,An alternative concept of a 'derivative',"The definition of the derivative of a function $f$ at $x$ $$f'(x) = \lim_{h \to 0} \frac{f(x+h) -f(x)}{x+h-x}$$ arises from considering its gradient , given by $\frac{\Delta y}{\Delta x}$ . This yields a gradient function from which the gradient at any suitable point $(x, f(x))$ can be calculated. This process is obviously very useful as the gradient is connected to concepts such as tangents and stationary points, and sometimes represents a useful physical quantity such as acceleration. However, what if we were interested in finding normals to a graph, rather than tangents? Considering the definition of the derivative from first principles, we could introduce an analogous definition for finding a 'normal function' rather than a gradient function; the gradient of the normal is given by $-\frac{\Delta x}{\Delta y}$ , so we could define this alternative 'derivative' by $$f\star(x) = \lim_{h \to 0} \frac{h}{f(x) -f(x+h)}$$ using $f\star(x)$ to denote this idea. My question is, has this process been explored, and does it have any applications? Of course, anything that can be accomplished with this can (presumably) be accomplished with the usual derivative and the negative reciprocal relationship $f'(x) = -\frac{1}{f\star(x)}$ so it may well be obselete, but I'm wondering if there is use for it elsewhere. In particular, the inverse of differentiation (in the standard sense) is definitely useful - integrals have geometrical significance and antiderivatives can also represent useful quantities. If we introduce an analogous 'integration' as the inverse of differentiation - so the process by which $f \star (x)$ becomes $f(x)$ - then what, if any, is the geometrical significance of these 'integrals'? Experimenting with this definition, I found analogies to the usual chain rule, quotient rule and product rule; for instance if $f(x) = g(h(x))$ , then $$f \star (x) = -\left[ g\star (h(x)) \right] * \left[h\star (x) \right]$$ although the others were more unwieldy. Are there any other properties of differentiating in the usual sense that can be translated into the analogous definitions? One consequence that is particularly apparent when 'differentiating' trigonometric functions is that the alternative derivative is undefined at stationary points; for instance if $f(x) = \sin x$ then $f \star (x) = -\sec x$ which is undefined at every $\frac \pi 2 + n \pi$ with integer $n$ . I couldn't find any examples of this idea but I wasn't sure what to search for, as clearly this isn't a derivative in the usual sense of the word and 'normal function' is not a very insightful search query - the proper terminology and notation would be very helpful, if it exists.","['calculus', 'derivatives']"
3594938,Can a function that selects between two random variables increase the variance more than twofold?,"Let $X_1,X_2$ be two real-valued zero-mean random variables, and assume w.l.o.g. that $\text{Var}[X_1]\ge\text{Var}[X_2]$ . Let $f:\mathbb R^2\to\{1,2\}$ be a ``selection'' function, and define $Y=X_{f(X_1,X_2)}$ to be the selected (real-valued) random variable. Is it possible to upper bound $\text{Var}[Y]$ as a function of $\text{Var}[X_1]$ ? For example, Is it correct that $\text{Var}[Y]\le 2\text{Var}[X_1]$ ?","['variance', 'random-functions', 'probability-theory', 'probability', 'random-variables']"
3594939,Big O notation and derivative,"Given a function $f(x) = x^2 + g(x)$ such that $g(x) = O(x)$ and that $f'(x)$ is monotonic non-decreasing for all $x \geq x_0$ I need to prove that $g'(x) = O(\sqrt{x})$ , and also that without the monotonic condtion such implication is false For the latter question I have $g(x) = \sin(x^2) = O( x)$ but $g'(x) = 2x \cos(x^2) = O(x)$ . Which means that the solution to the first question $g'(x) = O(\sqrt{x})$ depends on the fact that $f'$ is monotonic but I couldn't prove it. How to prove it then?","['number-theory', 'calculus', 'derivatives', 'asymptotics']"
3594984,prove the identity for a differentiable function,"Let $f$ be a smooth real function and $f(0)=0, f (1)=1$ , prove that exists various $x_1$ , $x_2$ $ \in [0;1] $ such that $$\frac{1}{f'(x_1)}+\frac{1}{f'(x_2)}=2$$ I tried to use the mean value theorem for different intervals, but it didn't help me.
Also I can't understand the behavior of this function.
Thank you for help!","['differential', 'analysis']"
3595027,"Let $N \sim \mathrm{Poisson}(c)$. Then what is $E[\exp(i\langle z, S_{N}\rangle)]$?","Let $N \sim  \mathrm{Poisson}(c)$ with $c  > 0$ .  Let $(S_n)_{n=0}^\infty$ be a random walk independent from $N$ . In a proof I'm reading, it is claimed that $$E\left[\exp(i\langle z, S_N\rangle)\right] = \sum_{n=0}^\infty P(N=n) E\left[\exp(i\langle z, S_n \rangle)\right].$$ I can't see why this holds. I tried writing $S_N = \sum_{n=0}^\infty S_{n} I_{\{N=n\}}$ and this gives a good intuition for why the formula should be true, but I can't justify why the formula holds. Any help will be greatly appreciated!","['poisson-distribution', 'random-walk', 'independence', 'expected-value', 'probability-theory']"
3595079,"Cantor's diagonal argument, is this what it says?","I've been reading about Cantor's diagonal argument all day, it's pretty confusing, but I think I get it now and I want to make sure asking you guys to confirm it. So, this is my understanding: Two sets, $A$ and $B$ have the same size if and only if there exists a one-to-one function that maps $A$ onto $B$ . A set $A$ is countably infinite if and only if there exists a one-to-one function that maps $A$ onto $ℕ$ . Now, if we want to show that the set $ℝ$ does not have the same cardinality as $ℕ$ and that ""it's larger"", from the above definition, we have to prove that there does not exists a one-to-one function that maps $ℕ$ onto $ℝ$ (or equivalently that $ℝ$ is not countably infinite). We proceed by contradiction:
We suppose there exists a one-to-one function that maps $ℕ$ onto $ℝ$ . All these are real numbers $f(1), f(2), f(3), …, f(n), …$ we arrange these numbers in this way: \begin{matrix}
f(1)=\:.\pmb{a_{11}}a_{12}a_{13}a_{14}…\\
f(2)=\:.a_{21}\pmb{a_{22}}a_{23}a_{24}…\\
f(3)=\:.a_{31}a_{32}\pmb{a_{33}}a_{34}…\\
…\\
f(n)=\:.a_{n1}a_{n2}a_{n3}a_{n4}…\\
...
\end{matrix} where all the $a_{ij}$ s represent random numbers from $0$ to $9$ (note the period at the beginning, it means that there should be another number there, like a normal decimal). Now if we find a number that is not in that list it means 2 things (which is actually the same thing): 1 - The function is not bijective (since at the beginning we supposed that there exists a one-to-one function that maps $ℕ$ onto $ℝ$ every element of $ℝ$ should have an element of $ℕ$ mapped to it, and we found an element of $ℝ$ that doesn't have one, since it's not in the list). 2 - That the set $ℝ$ is not countable, both because we can't ""list them"" (that list should represent every real number, but we missed one) and because that function is not bijective. To find this number that is not in the list we choose a number that should be in that list, let's say number $y$ , which since it has to to be real number it has the form of a decimal: $y=\:.y_1y_2y_3y_4…$ where again all the $y_i$ s are numbers between $0$ and $9$ , now to make different from all the other numbers, the trick is: Let the first digit $y_1$ be different from the first digit of the first number of that list, namely $a_{11}$ , the second digit $y_2$ be different from the second digit of the second number of that list, namely $a_{22}$ , $y_3$ different from $a_{33}$ and so on, so we will have a number that has at least 1 different digit from all those numbers and therefore it's none of those numbers, but at the same time since it's a decimal it should be in that list so we have a contradiction and we proved the 2 points, so in the end, even though $ℕ$ and $ℝ$ are both infinite they dont have the same number of elements, $ℝ$ has more since some elements ""stay free"" even after we paired every element of $ℕ$ with some element of $ℝ$ . Is this correct? I tried to explain it in the best way i can, i really hope it makes sense.. and please don't close the question, i know that there are a lot of questions about Cantor's diagonal argument but i can't be 100% sure i understand it if i don't write it down and someone confirms it. Thank you so much!","['elementary-set-theory', 'real-numbers', 'infinity', 'real-analysis']"
3595104,Closure and Interior Comparison,"I need to find a subset $A\subset \Bbb{R}$ such that the following sets are all different. $$A\qquad \mathring{A} \qquad \overline{A}\qquad \overline{\mathring{A}}\qquad \mathring{\overline{A}}\qquad \mathring{\overline{\mathring{A}}}\qquad \overline{\mathring{\overline{A}}}  $$ My best attempt was with the following set: $A=(1,2)\cup (2,3)\cup \{4\}$ I have: $$ 
\mathring{A}=(1,2)\cup(2,3) \\
\overline{A}=[1,3]\cup\{4\} \\
\overline{\mathring{A}}=[1,3] \\
\mathring{\overline{A}}=(1,3).
$$ All of these sets are different, but $$ \overline{\mathring{\overline{A}}}=\overline{\mathring{A}}=[1,3]\quad\textrm{and}\quad \mathring{\overline{\mathring{A}}}=\mathring{\overline{A}}=(1,3).$$ Can I add something to my attempt to fix this?",['general-topology']
3595184,Is $\sin(\alpha)=\frac{\tan(\alpha)}{\sqrt{1+\tan^2(\alpha)}}$ a true statment?,"I'm being asked to prove the following equality $$\sin(\alpha)=\frac{\tan(\alpha)}{\sqrt{1+\tan^2(\alpha)}}$$ and I support the idea that they are not equal (the rest of my class seems to desagree with me which made me doubt a little). The ""proof"" is simple: $$\frac{\tan(\alpha)}{\sqrt{1+\tan^2(\alpha)}}=\frac{\sin(\alpha)}{\cos(\alpha)}\cdot \frac{1}{\sqrt{\frac{\cos^2(\alpha)+\sin^2(\alpha)}{\cos^2(\alpha)}}}\\=\frac{\sin(\alpha)}{\cos(\alpha)}\cdot |\cos(\alpha)|=\sin(\alpha)\cdot\frac{|\cos(\alpha)|}{\cos(\alpha)}=\sin(\alpha)$$ Now, this doesn´t make sense to me since $\exists\alpha$ s.t. $\cos(\alpha)>0$ and also $\exists\alpha$ s.t. $\cos(\alpha)<0$ . Does the equality hold? Not much context is given when it comes to frasing the problem, the first question of our first physics homework. I'm aware that this is very simple but my classmates seem to disagree with me on the fact that the equality is just false, maybe they know something I don´t. Thanks in advance.","['trigonometry', 'solution-verification', 'fake-proofs']"
3595268,Evaluating a Triple Integral in Polar Coordinates,"I'm trying to evaluate $\iiint_{E}\sqrt{3x^{2} + 3z^{2}}~dV$ where $E$ is the solid bounded by $y = 2x^{2} + 2z^{2}$ and $y=8$ . My thought was to covert this to polar coordinates using $x^{2} + z^{2} = r^{2}$ .  Then the solid would be a cone originating in the $xz$ -plane with radius of 0 which stretches along the $y$ -axis until it terminates as a circle of radius 2.  So I converted $\sqrt{3x^{2} + 3z^{2}}$ to $\sqrt{3r^{2}}$ to $r\sqrt{3}$ and set the integral up this way $$\int_{\theta = 0}^{\theta = 2\pi}\int_{r=0}^{r=2}\left(\int_{y=0}^{y=2r^{2}} r\sqrt{3} dy\right) r~dr~d\theta$$ which equals $\frac{128\sqrt{3}}{5}\pi$ .  But the correct answer is $\frac{256\sqrt{3}\pi}{15}$ , which means I'm off by a factor of $\frac{2}{3}$ . Any help figuring out what I'm doing wrong would be greatly appreciated!",['multivariable-calculus']
3595315,Limit of operators,"Let $T:V\to V$ be a bounded linear operator on a finite vector space $V$ . If the sequence $\frac{1}{n}T^n$ converges, can we prove that its limit is the zero operator? I think that the answer is yes, but I am struggling a bit with the proof. One approach could be to prove that $\|T\|\leq 1$ but I don't know how to proceed. One could also play around with the sequence terms by setting $S_n=\frac{1}{n}T^n$ , $S_0:=\lim_{n\to+\infty}S_n$ and observing that $S_{n+1}=\frac{n}{n+1}TS_n$ which gives $S_0=TS_0$ but I don't know if it is helpful.","['operator-theory', 'linear-algebra']"
3595322,Continuous Time Optional Sampling Theorem for Submartingales,"I want to show the following result for continuous time submartingales: Suppose $\{X_t\}_{t \ge0}$ is a right continuous submartingale with respect to the filtration $\{\mathcal{F}_t\}_{t \ge 0}$ .  I want to show that for stopping times $\sigma \leq \tau$ , if EITHER (1) $\tau \leq C < \infty$ or (2) $\{X_t\}_{t \ge0}$ is uniformly integrable, then $X_\sigma \leq E(X_\tau| \mathcal{F}_\sigma)$ My attempt/start of a proof: It suffices to show that $E(X_\sigma) \leq E(X_\tau)$ for all stopping times $\sigma, \tau$ which satisfy either (1) or (2). I know how to prove the discrete time theorem of the identical form, so if we define $\tau_n \equiv \inf\{k/2^n : k, n \in \mathbb{N}\, k/2^n \ge \tau\}$ and similarly for $\sigma_n$ , we know that $$X_{\sigma_n} \leq E(X_{\tau_n}| \mathcal{F}_{\sigma_n})$$ as it is easy enough to show that $\sigma_n, \tau_n$ are both (discrete time) stopping times. Because $\mathcal{F}_\sigma \subseteq \mathcal{F}_{\sigma_n}$ for all $n$ , $$E(X_{\sigma_n}|\mathcal{F}_\sigma) \leq E(X_{\tau_n}| \mathcal{F}_{\sigma}) \quad \quad (1)$$ applying the tower property. If I knew that $X_{\sigma_n}$ and $X_{\tau_n}$ were uniformly integrable and that $X_\sigma, X_\tau$ were both in $L^1$ , I would be able to conclude the proof by taking expectations in (1) and subsequently taking limits because $X_{\tau_n} \xrightarrow{a.s.} X_\tau$ by right continuity and likewise for $\sigma_n$ .  Is the UI stuff true?  I really don't know where to start from here.  Any help would be massively appreciated.","['stochastic-processes', 'probability-theory', 'martingales']"
3595342,Normal subgroups of k-transitive groups.,"I am not understanding a proof in Cameron's Permutation Groups. Theorem 4.1. let G be k-transitive, but not $S_k $ , with k>1. Then a non-trivial normal subgroup N of G is (k-1)-transitive, except possibly when k=3, when N may be an elementary abelian 2-group. The proof given in the book is by induction on k. The base case of k=2 is clear: 2-transitive groups are primitive, and primitive groups' normal subgroups are transitive.
Now we assume the result holds for k-1 and endeavour to prove it for k.
Choose some $\alpha \in \Omega$ (where $\Omega$ is the set G acts on). Then the stabiliser $N_\alpha$ of $\alpha$ in N is a normal subgroup of the (k-1)-transitive stabiliser $G_\alpha$ of $\alpha$ in G (by second isom. thm.). Now the bit I struggle with:
by the induction hypothesis, one of three possibilities occurs: 1) $N_\alpha$ =1. Then N is regular, so N is an elementary abelian 2-group, and G is not 4-transitive. I won't list the other two possibilities, because I just want an explanation for why G is not 4-transitive. A previous theorem showed that if G is k-transitive for $k\ge 3$ then a regular normal subgroup is an elementary abelian 2-group. But that theorem says nothing about G not being 4-transitive, and the proof of the theorem in question implies that the previous theorem shows this. Why is G not 4-transitive?","['permutations', 'normal-subgroups', 'abstract-algebra', 'group-theory', 'abelian-groups']"
3595348,What is the distance from $G$ to centre of gravity set $S$?,"Let: $$G=\left\{x\in \mathbb R^n: x=(x_1,...,x_{n-1},0) \right\},$$ $S$ - cone based on the set $A\subset G$ which is bounded set, $$A'=\left\{x'\in \mathbb R^{n-1}: x'=(x_1,...,x_{n-1}) \right\}, \lambda_{n-1}(A')<\infty$$ Moreover assume that the tip of the cone $S$ lies at a distance $g$ from $G$ . What is the distance from $G$ to centre of gravity set $S$ ? If $A\subset \mathbb R^n$ is a measurable set then the point $x=(x_1,...,x_n)$ where $x_i=\frac{1}{\lambda_n(A)} \int_A y_i d \lambda(y_1,y_2,...,y_n)$ is the centre of gravity. But I don't know how to use this knowledge to do this task. Can you help me?","['integration', 'measure-theory', 'real-analysis']"
3595518,Doubt about the logic defining transitivity of a relation,"Kindly, correct me where I am wrong. Modified(11:50 AM, 26 March 20): [ for all a, b, c ∈ X ] Let us define P: $(a, b), (b, c)∈R$ ; and Q: $(a, c)∈R$ ; [A] When P is true : P is true, Q is true: Relation is TRANSITIVE . P is true, Q is false: Relation is NOT TRANSITIVE . [B] When P is false Now, I am going to deal with the condition P is false in this way. Consider the first case, (P is true and Q is true) $\implies$ Relation is TRANSITIVE. Then, the negation of this will be (P is false or Q is false) $\implies$ Relation is NOT TRANSITIVE. This implies that the condition P is false is enough to say that the relation is NOT TRANSITIVE . Is my argument valid?","['logic', 'relations', 'definition', 'solution-verification', 'elementary-set-theory']"
3595652,Quarentine modification to the SIR-model intepretation,"I'm trying to model the corona virus using the SIR model. I added in a new parameter to the model, that would simulate quarantine. My goal is to see what the effect of quarantine of the infectious would be, and thus not accounting for social distancing. The equations using the new c parameter become: $$S'(t)=-a \times S(t) \times I(t) $$ $$I'(t)=a \times S(t) \times I(t)-b \times I(t)-c \times a \times S(t) \times I(t) $$ $$R'(t)=b \times I(t)+c \times a \times S(t) \times I(t) $$ If t is measured in weeks, is it then true that this would put c percent of the newly infectious into R each week?",['ordinary-differential-equations']
3595687,∠C = 45° or 30°?,"I tried to solve the following math problem using both 'Pythagorean Theorem' and 'Trigonometric Ratios' and I got different answers. No matter what method is followed, both answer should be the same. I don't understand what I'm doing wrong. Q. In △ABC, ∠B = 90°. If AC = 2AB, then what is the value of ∠C? I'm not allowed to add any images for some reason, please click here to see the triangle. ' Pythagorean Theorem ' approach: AC 2 = AB 2 + BC 2 2AB 2 = AB 2 + BC 2 [since, AC = 2AB] 2AB 2 -  AB 2 = BC 2 AB 2 = BC 2 AB = BC If AB = BC, then △ABC is an isosceles right triangle and ∠C = ∠B = 45° . 'Trigonometric Ratios' approach: Suppose, ∠C = θ sin θ = AB/AC sin θ = AB/2AB [since, AC = 2AB] sin θ = 1/2 sin θ = sin 30° θ = 30° So, ∠C = 30°","['pythagorean-triples', 'trigonometry', 'angle', 'triangles']"
3595770,Question about finite analog of $\int_0^\infty \frac{\sin x\sinh x}{\cos (2 x)+\cosh \left(2x \right)}\frac{dx}{x}=\frac{\pi}{8}$,"The integral $$
\int_0^\infty \frac{\sin x\sinh x}{\cos (2 x)+\cosh \left(2x \right)}\frac{dx}{x}=\frac{\pi}{8},
$$ is given as equation $(17)$ in  M.L. Glasser, Some integrals of the Dedekind $\eta$ -function . More general integral $$
\int_0^\infty \frac{\sin x\sinh (x/a)}{\cos (2 x)+\cosh \left(2x/a\right)}\frac{dx}{x}=\frac{\tan^{-1} a}{2},\tag{1}
$$ can be deduced as a limiting case of formula $4.123.6$ in Gradsteyn and Ryzhik. I have been looking for finite elementary analogs of integral $(1)$ and have proved that \begin{align}\label{}
\int_0^{1}\frac{\sin \bigl(n \sin^{-1}t\bigr)\sinh \bigl(n \sinh^{-1}(t/a)\bigr)}{\cos \bigl( 2 n \sin^{-1}t\bigr)+\cosh \bigl(2 n \sinh^{-1}(t/a)\bigr)}\frac{dt}{t \sqrt{1-t^2} \sqrt{1+{t^2}/{a^2}}}=\frac{\tan^{-1} a}{2},\tag{1a}
\end{align} for an odd integer $n$ . When $n\to\infty$ equation $(1a)$ will give equation $(1)$ . This is easy to see because when $n$ is large then the main contribution to $(1a)$ comes from a small neighborhood around $0$ . Q: Can you explain why this integral has such a simple closed form and in particular why it has the same value for all odd $n$ ? I want to stress that I have a proof which is based on partial fractions expansion for odd $n$ \begin{align}
&\frac{\sin \bigl(n \sin^{-1}t\bigr)\sinh \bigl(n \sinh^{-1}(t/a)\bigr)}{\cos \bigl( 2 n \sin^{-1}t\bigr)+\cosh \bigl(2 n \sinh^{-1}(t/a)\bigr)}\frac{2n}{t^2}\\&=\sum _{j=1}^n\frac{i(-1)^{j-1} }{\sin\frac{\pi  (2 j-1)}{2 n}}\cdot \frac{\left(a\cos\frac{\pi  (2 j-1)}{2 n}+i\right) \left(a+i \cos\frac{\pi  (2 j-1)}{2 n}\right)}{t^2 \left(a^2-1+2 ia \cos\frac{\pi  (2 j-1)}{2 n}\right)-a^2 \sin ^2\frac{\pi  (2 j-1)}{2 n}},
\end{align} the elementary integral \begin{align}
\int_0^1 \frac{t}{t^2 \left(a^2-1+2 ia \cos\frac{\pi  (2 j-1)}{2 n}\right)-a^2 \sin ^2\frac{\pi  (2 j-1)}{2 n}}\frac{dt}{\sqrt{1-t^2} \sqrt{1+{t^2}/{a^2}}}\\=\frac{\tan^{-1}a+i\tanh^{-1}\cos\frac{\pi  (2 j-1)}{2 n}}{i\left(a\cos\frac{\pi  (2 j-1)}{2 n}+i\right) \left(a+i \cos\frac{\pi  (2 j-1)}{2 n}\right)},
\end{align} and summation formula which can be deduced from the partial fractions above $$
\sum _{j=1}^n \frac{(-1)^{j-1}}{\sin \frac{\pi  (2 j-1)}{2 n}}=n.
$$ But despite this prove I don't understand why all these cancellations occur to give such a simple result at the end. I suspect there is a very short and transparent proof which explains why the integral is $\frac{\tan^{-1} a}{2}$ for all odd $n$ . Maybe Glasser's master theorem or some contour integration can explain this formula? Motivation for this question is desire to understand this integration formula. Any alternative proof is welcome if it is not just a detailed version of the proof above. Any ideas and comments are welcome. Thanks.","['integration', 'definite-integrals', 'contour-integration', 'trigonometric-integrals', 'closed-form']"
3595775,"Does $p \mid \frac{|{\rm{Stab}}(Q)|}{|\bigcap_{P\in {\rm{Syl}}_p(G)}{\rm{Stab}}(P)|}, \space\forall Q \in \operatorname{Syl}_p(G)$?","Ancillary to the main problem I'm trying to solve, I've come up to a partial result whose generalization would read as follows: Let $G$ be a finite group, $p$ a prime divisor of $|G|$ and $\operatorname{Syl}_p(G)$ the set of the Sylow $p$ -subgroups of $G$ . Assume further that $|\operatorname{Syl}_p(G)|>1$ . With reference to the transitive action of $G$ by conjugacy on $\operatorname{Syl}_p(G)$ , the following holds: $$p \mid \frac{|{\rm{Stab}}(Q)|}{|\bigcap_{P\in {\rm{Syl}}_p(G)}{\rm{Stab}}(P)|}, \space\forall Q \in \operatorname{Syl}_p(G) \tag 1$$ So far I couldn't prove it nor find a counterexample. Just for the records, I'm using $(1)$ to prove that, if $G$ has eight $7$ -Sylow subgroups, then $G$ has a normal subgroup $N$ such that $56$ divides $[G:N]$ .","['finite-groups', 'abstract-algebra', 'sylow-theory', 'group-theory', 'group-actions']"
3595791,Is there a deep reason why strong estimates fail to exist for $L^1$ so often?,"For example, the Hardy-Littlewood maximal inequality fails to have a strong type estimate in the $(1,1)$ case. Another example is the Hilbert transform which has strong type $(p,p)$ bounds for $1<p<\infty$ but fails to be bounded on $L^1$ . Is there a deep reason why such estimates fail so often for $L^1$ ?","['lp-spaces', 'functional-analysis']"
3595797,Is $\int_0^x\left|\sin\left(\frac{1}{t}\right)\right|\mathrm{d}t$ differentiable at $0$?,Let $f(x)=\int_0^x\left|\sin\left(\frac{1}{t}\right)\right|\mathrm{d}t$ for $x\in\mathbb{R}$ . Is $f$ differentiable at $x=0$ ?,"['integration', 'derivatives']"
3595919,Elementary proof of tangent half angle formula,"Hi all, I am interested to find elementary proof of tangent half angle formula. My solutions are the following: Triangle $AOB$ is such that $|AB|=1$ and $\angle AOB=\theta$ . We then extend $OB$ to $P$ and $Q$ such that $|OP|=|OQ|=1$ . Thus we will have two isosceles triangles: $AOP$ and $AOQ$ . From the picture, $\tan{\left(\frac{\theta}{2}\right)}=\frac{AB}{BP}=\frac{\sin{\left(\theta\right)}}{1+\cos{\left(\theta\right)}}\ \ \ =\frac{BQ}{AB}=\frac{1-\cos{\left(\theta\right)}}{\sin{\left(\theta\right)}}$ Could You guys please check my solution. I am also wondering if there are other elementary solutions, please share, thanks!","['trigonometry', 'solution-verification']"
3595947,Prove that A-B=A ⇔ A⋂B=Φ,"Another question from my 11th grade Mathematics textbook. I actually proved it but I still want to confirm if it's right or not. Please check it out : In order to prove that A-B=A ⇔ A⋂B=Φ, we will first prove that A-B=A ⇒ A⋂B=Φ and then we'll prove 
that A⋂B=Φ ⇒ A-B=A
First part : Proving that  A-B=A ⇒ A⋂B=Φ :-
    Let x be an arbitrary element of A
    So, x ∈ A
    Since A=A-B, so x ∈ A-B
    So, x ∈ A and x ∉ B
    This means that for an arbitrary element of A, it is not an element of B
    So, A and B are both disjoint sets
    So, they have no element in common
    So, A⋂B=Φ
    So, A-B=A ⇒ A⋂B=Φ

Second part : Proving that A⋂B=Φ ⇒ A-B=A :-
    A-B = A-(A⋂B)
    Since A⋂B = Φ, so, A-B = A-Φ = A
    So,  A⋂B=Φ ⇒ A-B=A

So, A-B=A ⇔ A⋂B=Φ
Hence, proved Let me know about any flaws in this proof, even the slightest, especially if the proof can be made shorter and if I have included anything unnecessary in it. Thanks :)","['elementary-set-theory', 'solution-verification', 'discrete-mathematics']"
3595990,Identity for Catalan numbers,"Assume $C_{n}=\frac{1}{n+1} \binom{2n}{n}$ the Catalan numbers. I want to prove the following identity with generating functions. $$C_{n+1}=\sum\limits_{k=0}^{\lfloor \frac{n}{2}\rfloor} \binom{n}{2k}2^{n-2k}C_k$$ I know that the generating function for the Catalan numbers is $C(x)=\frac{1-\sqrt{1-4x}}{2x}$ and I can prove the following $C_{n+1}=\sum\limits_{k=0}^{n}C_kC_{n-k}$ . I tried to use those two results to derive the identity above but did not succeed so far. I'm not really sure if I approach this problem the right way, especially because I don't know how to obtain the floor function for the upper bound of the sum indexing.","['catalan-numbers', 'discrete-mathematics', 'generating-functions']"
3596019,How to solve the differential equation: yy''+2y'''=0 [closed],Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 4 years ago . Improve this question How do I solve yy''+2y'''=0 with B.Cs y(0)=y'(0)=0 & y'(∞)=1 ? Can somebody please hint at some substitution or refer any text related to these type of ode?,['ordinary-differential-equations']
3596024,Non-Strict Saddle Point vs Local Minima,"While going through Escaping Saddle Points Efficiently , I came across the definition of Strict Saddle Point. They define a stationary point to be a strict saddle if at least one of the eigenvalue of the Hessian Matrix is negative. This implies a non-strict saddle point will have all eigenvalues of the Hessian Matrix greater than or equal to zero. But, isn't this a sufficient and necessary condition for local minima? What is the difference between a non-strict saddle point and a local-minima?","['optimization', 'multivariable-calculus', 'linear-algebra']"
3596150,Showing that a complex-valued function is constant,"Let $H$ be the upper half plane and let $f : H → \mathbb C$ be
holomorphic on $H$ and continuous on $\bar{H}$ . Suppose that $f$ is constant on the real line, that is, there is $c ∈ \mathbb C$ such that $f(x) = c$ for all $x ∈ \mathbb R$ . 
Show that $f$ is constant. My attempt: I tried proving this using Liouville's theorem. Since $f$ is continuous on $\bar{H}$ , then it is continuous at each $p \in \bar{H}$ , so for all $\epsilon > 0$ , there exists $\delta > 0$ s.t if $|z-p|< \delta$ , then $|f(z) - f(p)|< \epsilon$ . Choose $\epsilon = 1$ Now we can rewrite $|f(z)|$ as: $|f(z) - f(p) + f(p)| ≤ |f(z) - f(p)| + |f(p)| ≤ 1 + |f(p)|$ Let $M := 1 + |f(p)|$ Hence $|f(z)| ≤ M$ and hence $f$ is bounded on $\bar{H}$ But since $p \in \bar{H}$ , it can also lie on the real line, so $f(p) = c$ for some $c \in \mathbb C$ and thus $|f(p)| = |c|$ and hence $f$ is bounded on $H$ . Therefore, by Liouville's theorem, if a function is holomorphic and bounded, it must be constant. Hence $f$ is constant. Is my attempt correct? Any other answers?","['complex-analysis', 'continuity', 'complex-numbers', 'upper-lower-bounds']"
3596172,A corollary of the Chernoff bound,"During my Statistic course, we were asked the following question: Let $ X_1, \ldots , X_n $ be a $n$ observations that are i.i.d and assume $ X_i \sim \mathcal{N} (0,\sigma^2) $ .
Use the Chernoff Bound, i.e. $$ \Pr( X \geq t ) \leq \frac{E(e^{\lambda X})}{e^{\lambda t}} $$ And the fact that the Moment Generating Function of $X_i$ is $$ M_{X_i} = E(e^{\lambda X_i}) = E(e^{\frac{1}{2} \sigma^2 \lambda^2}) $$ to prove that, for all $ t > 0$ $$ \Pr\left( \frac{1}{n} \sum_i^n X_i \geq t \right) \leq  e^{-n \frac{t^2}{2\sigma^2} } .$$ Using the MGM of the mean, I have: $$ \Pr\left( \frac{1}{n} \sum_i^n X_i \geq t \right) \leq  \frac{e^{-n^2 \frac{1}{2}\sigma^2 \lambda^2 }}{e^{\lambda t}} $$ (If I didn't miscalculate something). But I can't get any further...","['statistics', 'proof-writing', 'solution-verification', 'inequality', 'probability-theory']"
3596326,"Non diagonalizable normal, linear and bounded operator","If $H$ is a complex Hilbert space and $T:H\to H$ is a bounded linear operator, we say that $T$ is diagonalizable if there exists an orthonormal basis of $H$ formed by eigenvectors of $T$ ( $0\neq{x}\in H$ is a eigenvector if there exists $\lambda \in \mathbb{C}$ with $T(x)=\lambda x$ ). When $H$ is finite dimensional, it is known that if $T$ is normal then it is diagonalizable. However, by the spectral theorem for normal compact operator, in infinite dimensional Hilbert spaces we need to make an extra hypothesis: $T$ is compact. So, if I have understood correctly, there must exist bounded linear operator which are normal but not diagonalizable. Could someone give me an example of this?, because I have not found such operator.","['compact-operators', 'eigenvalues-eigenvectors', 'operator-theory', 'hilbert-spaces', 'functional-analysis']"
3596384,"A rollercoaster contains four cars, each with six seats. Four families, each containing six individuals wish to ride ...","A rollercoaster contains four cars, each with six seats. Four families, each containing six individuals wish to ride the rollercoaster together. In how many ways can the rollercoaster be “loaded” with the individuals so that two individuals ride in the same car if and only if they belong to the same family? My work: I am thinking about 4*3*2*1 = 24 ways, but I don't know if that's correct. The question is really saying that each family needs to stay together. There are four cars in the rollercoaster, so the first car will have four families, second car will have three, third car will have two, fourth car will have one.","['combinatorics', 'discrete-mathematics']"
3596418,The greatest measure of an orthogonal projection of an $n$-parallelepiped onto a $d$-dimensional affine subspace,"Let $P=[0,a_1]\times\ldots\times[0,a_n]$ be a parallelepiped in $\mathbb{R}^n$ . What is the greatest possible measure of an orthogonal projection of $P$ onto a $d$ -dimensional affine subspace in $\mathbb{R}^n$ (identified with $\mathbb{R}^d$ with its Lebesgue measure, say) for $0<d<n$ ? I'm sure the answer is $$\left(\displaystyle\sum_{1\leqslant n_1<\ldots<n_d\leqslant n}\prod_{k=1}^{d}a_{n_k}^2\right)^{1/2}.$$ As an easy special case $n=3$ , $d=2$ , the greatest area of an orthogonal projection of $[0,a]\times[0,b]\times[0,c]$ onto a plane is $\sqrt{a^2b^2+a^2c^2+b^2c^2}$ . An idea might be to consider the principle of ""a projection of a convex hull of points is the convex hull of the projections of the points"", and use Gram matrices. But I seem confused making a clean proof out of it.","['euclidean-geometry', 'geometry']"
3596488,"Can we pick representatives from the ""difference is rational"" equivalence classes?","Let us define an equivalence relation $\sim$ on $\mathbb{R}$ by saying that $x\sim y$ if $x-y\in \mathbb{Q}$ ?  This equivalence relation partitions $\mathbb{R}$ into uncountably many equivalence classes.  My question  is, is it possible to construct a set which has exactly one element from each of these equivalence classes? Can we define these elements explicitly?  Or failing that, can we at least prove that there exists a definable subset of $\mathbb{R}$ which has this property?  What about a Borel subset of $\mathbb{R}$ ?","['real-numbers', 'measure-theory', 'equivalence-relations', 'logic', 'real-analysis']"
3596496,"Relaxation method on a system of two second-order, coupled, non-linear ODEs (boundary value problem)","This is my first question on Stack Exchange - I welcome any suggestions if my approach to asking it does not match the usual conventions around here. So: I need to solve a system of two second-order, non-linear, coupled differential equations for the functions f and g which depend only on one free variable, i.e. f(x) and g(x). The functions f and g are defined on a finite interval (e.g. [0;10]) and the values of these functions are given at the boundaries (boundary value problem). I need to do this numerically because there is no analytical solution. I have been scouting a variety of numerical methods and it seems the so-called relaxation method as outlined in ''Numerical Recipes'' by Press et al. might be the way to go. Since I have no numerics background, I may be mistaken in assuming this method is standard knowledge; I will be more than happy to briefly explain what it does if required. Now, from what I understand, this method works fine for systems of first-order ODEs. In principle, your usual reduction of order does the trick and I can express my system as four coupled first-order ODEs. However, my problem is that I have no boundary conditions for the two additional equations, that is, no BCs for the derivatives of f and g. This is the point where I got stuck. Questions:
1) Does anyone know if this poses a conceptual problem to the method? How can I circumvent it?
2) Would it be possible to apply the aforementioned relaxation method to the second-order system by 'brute force'? Thank you very much in advance! EDIT: The system of first-order ODEs would look like this: $$ \frac{\partial f(t)}{\partial t} = u(t) \\ 
\frac{\partial u(t)}{\partial t} = a(t,f,g) \\
\frac{\partial g(t)}{\partial t} = v(t) \\
\frac{\partial v(t)}{\partial t} = b(t,f,g,v),$$ where $a$ and $b$ are non-linear functions of their arguments (am not showing them here, but of course I know how they look like). $f(0)$ , $g(0)$ , $f(10)$ and $g(10)$ would be known values. Should anyone know of a method that can solve these for sure - and I don't mind if it is a built-in method of Mathematica, MATLAB or the likes - I would appreciate any suggestion. Also, thanks to everyone who already commented!","['numerical-methods', 'systems-of-equations', 'relaxations', 'ordinary-differential-equations']"
3596578,Spectrum of the bi-Laplacian,"I have the following operator: $$\begin{align*}D(A)&=\{f \in C[0,1]:f''''\in C[0,1] \text{ and } f^{(k)}(0)=0 \ \forall\ 0\leq k\leq 3\}\\Af&=-f''''.\end{align*}$$ I'm trying to find the spectrum of $A.$ My attempt: Solving the equation $(\lambda - A) g =f$ with the given boundary condition gives: $$g(x)=\frac{1}{4^{1/4}\lambda^{3/4}}\int_0^x f(y) \left(\sin (c_{\lambda}(x-y))\cosh (c_{\lambda}(x-y))-\cos (c_{\lambda}(x-y))\sinh (c_{\lambda}(x-y)) \right) \ dy$$ where $c_{\lambda}=\left(\frac{\lambda}{4}\right)^{1/4}.$ I'm unsure how to proceed from here. I think from the expression of $g,$ we must have $0\in \sigma(A)$ but I am not so sure since the integrand also vanishes at $\lambda=0.$ How do I proceed from here?","['laplacian', 'spectral-theory', 'functional-analysis', 'ordinary-differential-equations']"
3596620,Quadrilateral in quarter circle,"My friend, who is an elementary school teacher, found this problem in one of their text books and asked me for help. Turns out I'm not much of a geometry buff. You have a quarter section of a circle. Inside this section, there is a quadrilateral with one corner at the center, with two corners at the axes, and with the last corner on the circle such that it creates a right angle. You are given that the non-trivial diagonal is $8$ . What is the radius of the circle? I observed that it is a cyclic quadrilateral, and I tried to apply Ptolemy's theorem to show that the radius is uniquely determined, but I didn't succeed and now I'm not convinced that it is true. What do you think?",['geometry']
3596636,Surjective sum measure,"Let $(a_n)$ be a sequence of positive real numbers convergent to $0$ . Let $\mu(A) = \sum_{n \in A}a_n$ for every $A \subset \mathbb{N}$ . What is the ""if and only if"" condition on $a_n$ for $\mu$ to attain every value from $[0, \mu(\mathbb{N})]$ ?","['measure-theory', 'sequences-and-series', 'real-analysis']"
3596821,Convergence in a generating algebra $\Rightarrow$ convergence in the weak* topology?,"Let $M$ be a compact metric space and $\mathcal{B}$ its Borelian $\sigma$ -algebra. Consider $\{\mu_{n}\}_{n\in\mathbb N}$ as a sequence of Borelian probabilities on $M$ . Suppose that there exists a Borelian probability $\mu$ on $M$ and a generating algebra $\mathcal{A}$ ( i.e. $\mathcal A$ is an algebra and $\sigma(\mathcal{A}) = \mathcal B$ ) such that $$\mu_n(A)\longrightarrow \mu(A),\ \forall\ A\in \mathcal A\ \text{and}\ \mu(\partial A)=0,\  \forall \ A\in\mathcal{A}. \quad \quad      (*)$$ I would like to know if $(*)$ implies that $\mu_n\to\mu$ in the weak* topology, i.e. for every continuous function $f: M \to \mathbb R$ $$\int_M f\ \text{d}\mu_n \longrightarrow \int_M f\ \text{d}\mu. $$ My attempt I tried to use the monotone class theorem for functions . I defined the set $$\mathcal H:=\left\{f:M\to\mathbb R;\ f \text{ is bounded, measurable and }\int_M f\ \text{d}\mu_n \longrightarrow \int_M f\ \text{d}\mu\right\}. $$ So if we prove that if $A\in \mathcal A\Rightarrow$ $1_A \in \mathcal H,$ if $f,g\in\mathcal H$ $\Rightarrow$ $f+cg \in\mathcal{H}$ , for any real number $c$ , if $f_n \in \mathcal{H}$ is a sequence of non-negative functions that increase to a bounded function $f$ $\Rightarrow$ $f \in \mathcal{H}$ , holds then, by the monotone class theorem for functions, $\mathcal H$ will all the bounded measurable functions, and we are done. The conditions $1$ and $2$ are obvious to be checked. However, I was not able to conclude the last condition. Can anyone help me? Edit: I was thinking and this approach does not make sense since the condition that I am trying to check is a way stronger than convergence in the weak* topology.","['measure-theory', 'ergodic-theory', 'functional-analysis']"
3596887,First-order initial-value problem,"Consider this first-order initial value problem: $$\begin{cases}
y'=1-x+y^2-xy^2\\
y(0)=1
\end{cases}$$ I've tried simplifying the right-hand side to $(y^2+1)(-x+1)$ and then integrating it. I obtained a general solution as a tangent function but it seems that this is not the answer.","['initial-value-problems', 'calculus', 'ordinary-differential-equations']"
3596974,Singular value of production of projection matrix and some other matrix,"if I have a matrix $X\in\mathbb{R}^{n\times d}$ , and some projection matrix $P\in\mathbb{R}^{n\times n}$ which projects things onto a $k$ -dim subspace of the column space of $X$ , is there some expression for the singular values of $PX$ ? Say WLOG that $\|X\|_{op}\leq1$ . Using Weyl's inequality we get an upperbound that $\sigma_i(PX)\leq \sigma_i(X)$ . But I suspect that this is too pessimistic since $P$ projects onto a subspace of $col(X)$ . For example, if $PX=X_k$ being the SVD of the top $k$ singular values, then $\sigma_1(PX)\leq \sigma_{k+1}(X)$ which can be very small. Thanks for any advice!","['matrices', 'singular-values', 'linear-algebra', 'matrix-decomposition']"
3597002,Boundary extension of conformal mapping,"Let $\phi:\Omega\to D$ be a conformal mapping, where $\Omega$ is a bounded domain in $\mathbb{C}$ and $D$ is the unit disk. Caratheodory's theorem says it can extend as a homeomorphism from $\overline{\Omega}$ to $\overline{D}$ if and only if $\Omega$ is a Jordan domain. What if I only know $\phi$ can extend continuously to $\overline{\Omega}$ ? Is there an example that $\phi$ can extend continuously but $\Omega$ is not a Jordan domain? Supplements: What I can see is that the conformal mapping from $D-[0,1)$ to $D$ cannot extend, as it goes forwards and backwards on the line [0,1] and gives multiple values at each point, but I don't know what happens if the boundary is more complicated. I found this discussion about the inverse $\phi^{-1}:D\to\Omega$ . It is said $\phi^{-1}$ can extend if and only if $\partial\Omega$ is locally connected. converse to the jordan curve theorem",['complex-analysis']
3597005,The bilinear functional cannot be continuous on the space X,"In the below exercise , the following argument I write is wrong, but I wondered to see what point I miss here. Also, I could not think of a counter example. since both functions $p,q$ are polynomials they are continuous and hence on the set $[0,1]$ they attain their maximum. let $\max_t |p(t)|= M <\infty$ and $\max_t |q(t)|= N <\infty$ so ; $$|B(p,q)| \le \int_0^1 |p(t)q(t)|dt \le M.N <\infty$$","['examples-counterexamples', 'solution-verification', 'functional-analysis', 'analysis']"
3597036,"What is the probability that the larger of two independent uniform variables on $[0,1]$ is greater than $3/4$ if the smaller one is less than $1/4$?","Two independent random variables are uniformly distributed on $[0, 1]$ . The question asks if the smaller of the two numbers is strictly less than $\frac{1}{4}$ , then what is the probability that the larger one is strictly greater than $\frac{3}{4}$ . I approached the question with trying to find a suitable area within the unit square. I got two lines that cut off a smaller square of $\frac{1}{4}$ length, hence I calculated the probability as $\frac{1}{16}$ ; but the answer given is $\frac{2}{7}$ and now I can't understand where I'm wrong.","['uniform-distribution', 'geometric-probability', 'probability']"
3597162,Is this matrix surjective? Textbook dispute,"\begin{bmatrix} 
1 & -2 & 3 & 0 \\
0 & 0 & 0 & 1 \\
\end{bmatrix} Is this matrix surjective? My textbook says no, but by all logic I've read it should be yes. For example, Check if $f$ is injective / surjective (matrix) says that if Rank is equal to number of rows then a matrix is surjective.","['matrices', 'linear-algebra', 'linear-transformations']"
3597258,Open/closed/constructible subsets of locally free sheaves,"Is there a ""canonical"" way to define open/closed/constructible subsets of a locally free sheaf/vector bundle $\mathcal{F}$ on a scheme $X$ ? There is a clear way to do this with topological vector bundles, but are things defined the same way in algebraic geometry? I came across them in a paper ( https://arxiv.org/abs/1910.05207 ), but couldn't find any other sources discussing possibly related concepts specifically in algebraic geomery other than those looking at subsets of global sections of these vector bundles. My guess was that this has something to do with interpreting a locally free sheaf/vector bundle $\mathcal{F}$ locally as (relative) $\text{Spec} (\text{Sym}^\cdot \mathcal{F}^\vee)$ (which are also discussed in section 4 of the paper above), but I'm not sure how to formulate a precise definition other than what was suggested at the beginning of this question. It may be helpful to list interesting examples/non-examples.","['definition', 'algebraic-geometry']"
3597301,How to find mode when modal class is first or last class?,"We know that formula of finding mode of grouped data is Mode = $l+\frac{(f_1-f_0)}{(2f_1-f_0-f_2)}\cdot h$ Where, $f_0$ is frequency of the class preceding the modal class and $f_2$ is frequency of the class succeeding the modal class. But how to calculate mode when there is no class preceding or succeeding the modal class.",['statistics']
3597312,"Sum of Bessel functions to the fourth power, $\sum_{k\in\mathbb{Z}} J_k(x)^4$","Let $J_k$ denote the $k$ -th order Bessel function of the first kind. I know that $$\sum_{k\in\mathbb{Z}} J_{\mu-k}(x) J_{\nu-k}(y) = J_{\mu-\nu}(x-y) \quad \forall x,y\in\mathbb{R},\mu,\nu\in\mathbb{Z},$$ so in particular, $\sum_{k\in\mathbb{Z}} J_k(x)^2 = 1 \ \forall x\in\mathbb{R}$ . Now I was wondering whether there is a closed form expression for $$\sum_{k\in\mathbb{Z}} J_k(x)^4,$$ if $x\in\mathbb{R}$ . Or, more generally, for $$\sum_{k\in\mathbb{Z}} J_{\mu-k}(x)^2 J_{\nu-k}(y)^2,$$ if $x,y\in\mathbb{R}, \, \mu,\nu\in\mathbb{Z}$ . Obviously, the result must be non-negative and $\leq 1$ in both cases, but I have neither been able to deduce a result myself nor find anything online.","['bessel-functions', 'sequences-and-series']"
3597318,Structure of double tangent bundle,"I have a problem in understanding the structure of the tangent bundle of the tangent bundle of a manifold. Let $M$ be an n-dimensional smooth manifold. Let $(U,\varphi)$ be a chart of $M$ , i.e. $U\subset M$ open and $\varphi:U\rightarrow\varphi(U)\subset\mathbb{R}^n$ is an homeomorphism. Assume that $\varphi$ induces local coordinates $(x^1,...,x^n)$ , that means that $\forall p\in U$ , $\varphi(p)=(x^1(p),...,x^n(p))\in\mathbb{R}^n$ .
Let $p\in U$ , then since $\varphi:U\subset M\rightarrow\varphi(U)\subset\mathbb{R}^n$ is an homeomorphism, then $(\varphi^{-1})_*|_{\varphi(p)}$ is an isomorphism of vector spaces: \begin{equation*}
(\varphi^{-1})_*|_{\varphi(p)}:T_{\varphi(p)}\varphi(U)\cong T_{\varphi(p)}\mathbb{R}^n\rightarrow T_pU\cong T_pM.
\end{equation*} Let \begin{equation}
\label{basis of TR}
\left\{\frac{\partial}{\partial x^1}|_{\varphi(p)},...\frac{\partial}{\partial x^n}|_{\varphi(p)}\right\}
\end{equation} be a basis of $T_{\varphi(p)}\mathbb{R}^n$ , then define \begin{equation*}
\frac{\partial}{\partial x^i}|_{p}:=(\varphi^{-1})_*|_{\varphi(p)}\left(\frac{\partial}{\partial x^i}|_{\varphi(p)}\right).
\end{equation*} By the fact that $(\varphi^{-1})_*|_{\varphi(p)}$ is an isomorphism, it maps basis into basis, hence \begin{equation*}
\left\{\frac{\partial}{\partial x^1}|_{p},...,\frac{\partial}{\partial x^n}|_{p}\right\}
\end{equation*} is a basis of $T_pM$ . In other words \begin{equation*}
T_pM=\left\{V^i\frac{\partial}{\partial x^i}|_{p}\mid V^i\in\mathbb{R}, \ i=1,...,n\right\}.
\end{equation*} This means that any $V\in T_pM$ , there exist $\{V^i\}_{i=1}^n\subset\mathbb{R}^n$ such that $V=V^i\frac{\partial}{\partial x^i}|_{p}$ . Consider now a smooth vector field V of $M$ , i.e. $V\in\Gamma(TM)$ is a section of the tangent bundle $TM:=\coprod_{p\in M}T_pM$ , then $\forall p\in U$ , $V(p)\in T_pM$ , hence we can write $V(p)=V^i(p)\frac{\partial}{\partial x^i}|_{p}$ , for some $V^i(p)\in\mathbb{R}$ , for $i=1,...,n$ . Since this can be done $\forall p\in U$ , we write locally \begin{equation*}
V=V^i\frac{\partial}{\partial x^i},
\end{equation*} where $V^i\in\mathcal{C}^\infty(M)$ are suitable smooth functions. The word locally means that $V(p)=V^i(p)\frac{\partial}{\partial x^i}|_{p}$ only for $p\in U$ . Since $TM$ is a manifold by its own right we would like to define its charts. We can induce a charts of $TM$ by charts of $M$ in this way. Let $\pi:TM\rightarrow M$ be the projection of the bundle and take $V\in TM$ , with $\pi(V)=p\in U\subset M$ , then we have shown that we can write $V=V^i\frac{\partial}{\partial x^i}|_p$ . Then we define the chart $(\tilde{U},\psi)$ , where $\tilde{U}:=\pi^{-1}(U)\subset TM$ and \begin{equation}
\label{chart TM}
\begin{array}{rcl}
\psi:\tilde{U}&\rightarrow&\psi(\tilde{U})\subset\mathbb{R}^{2n}\\
V=V^i\frac{\partial}{\partial x^i}|_p&\mapsto&(\varphi(p);V^1,...,V^n)
\end{array}
\end{equation} Since $TM$ is a manifold we can consider its tangent bundle $\pi_{TM}:TTM\rightarrow TM$ . Let $(x^1,...,x^n,y^1,...,y^n)$ be the local coordinates induced by $\psi$ . Let $V\in \tilde{U}$ , then since $\psi:\tilde{U}\subset TM\rightarrow\psi(\tilde{U})\subset\mathbb{R}^{2n}$ is an homeomorphism, then $(\psi^{-1})_*|_{\psi(V)}$ is an isomorphism of vector spaces: \begin{equation*}
(\psi^{-1})_*|_{\psi(V)}:T_{\psi(V)}\psi(\tilde{U})\cong T_{\psi(V)}\mathbb{R}^{2n}\rightarrow T_VT\tilde{U}\cong T_VTM.
\end{equation*} Let \begin{equation}
\label{basis of TTR}
\left\{\frac{\partial}{\partial x^1}|_{\psi(V)},...\frac{\partial}{\partial x^n}|_{\psi(V)};\frac{\partial}{\partial y^1}|_{\psi(V)},...\frac{\partial}{\partial y^n}|_{\psi(V)}\right\}
\end{equation} be a basis of $T_{\psi(V)}\mathbb{R}^{2n}$ , then define for $i=1,...,n$ \begin{equation*}
\frac{\partial}{\partial x^i}|_{V}:=(\psi^{-1})_*|_{\psi(V)}\left(\frac{\partial}{\partial x^i}|_{\psi(V)}\right)
\end{equation*} and \begin{equation*}
\frac{\partial}{\partial y^i}|_{V}:=(\psi^{-1})_*|_{\psi(V)}\left(\frac{\partial}{\partial y^i}|_{\psi(V)}\right).
\end{equation*} By the fact that $(\psi^{-1})_*|_{\psi(V)}$ is an isomorphism, it maps basis into basis, hence \begin{equation*}
\left\{\frac{\partial}{\partial x^1}|_{V},...,\frac{\partial}{\partial x^n}|_{V};\frac{\partial}{\partial y^1}|_{V},...,\frac{\partial}{\partial y^n}|_{V}\right\}
\end{equation*} is a basis of $T_VTM$ . In other words \begin{equation*}
T_VTM=\left\{\eta^i\frac{\partial}{\partial x^i}|_{V}+\tilde{\eta}^j\frac{\partial}{\partial y^j}|_{V}\mid \eta^i,\tilde{\eta}^j\in\mathbb{R}, \ i,j=1,...,n\right\}.
\end{equation*} Wikipedia instead says ( https://en.wikipedia.org/wiki/Double_tangent_bundle ): Since $(TM,\pi_{TM},M)$ is a vector bundle on its own right, its tangent bundle has the secondary vector bundle structure $(TTM,(\pi_{TM})_*,TM)$ , where $(\pi_{TM})_*:TTM\rightarrow TM$ is the push-forward of the canonical projection $\pi_{TM}:TM\rightarrow M$ .
In the following we denote \begin{equation}
\xi = \xi^k\frac{\partial}{\partial x^k}\Big|_x\in T_xM, \qquad X = X^k\frac{\partial}{\partial x^k}\Big|_x\in T_xM
\end{equation} and apply the associated coordinate system \begin{equation}
\xi \mapsto (x^1,\ldots,x^n,\xi^1,\ldots,\xi^n)
\end{equation} on $TM$ . Then the fibre of the secondary vector bundle structure at $X\in T_xM$ takes the form \begin{equation}
(\pi_{TM})^{-1}_*(X) = \Big\{ \ X^k\frac{\partial}{\partial x^k}\Big|_\xi + Y^k\frac{\partial}{\partial\xi^k}\Big|_\xi
\ \Big| \ \xi\in T_xM \ , \ Y^1,\ldots,Y^n\in\mathbb{R} \ \Big\}.
\end{equation} . Well, this is different from my fibre \begin{equation*}
T_VTM=\left\{\eta^i\frac{\partial}{\partial x^i}|_{V}+\tilde{\eta}^j\frac{\partial}{\partial y^j}|_{V}\mid \eta^i,\tilde{\eta}^j\in\mathbb{R}, \ i,j=1,...,n\right\}.
\end{equation*} What is the right fibre? Maybe they are just different vector bundle with the same base space $TM$ , so what is their difference?
Thank you everyone.","['vector-bundles', 'smooth-manifolds', 'differential-geometry']"
3597435,Rank of SO(3) and SO(4)?,"The rank of SO(3) is 1, the rank of SO(4) is 2.
I'm trying to understand the definition of rank of a group with those two examples. The rank of a group is the cardinality of the smallest generating set.
The definition from Wikipedia is given in the first sentence.
(Link to wikipedia: https://en.wikipedia.org/wiki/Rank_of_a_group ) Definition of generating set: ""a generating set of a group is a subset such that every element of the group can be expressed as a combination (under the group operation) of finitely many elements of the subset and their inverses. "" In the case of SO(3), the group operation would be (matrix-)multiplication and there is no way one could express all the uncountably many rotations in the xy-plane with a finite product of matrices.","['group-theory', 'linear-algebra', 'rotations']"
3597456,Denote if string contains any member of a set of characters,"I come from a computer science background and trying to properly document the following python if statement. for char in X:
    if char in ""abcdefghijklmnopqrstuvwxyz"":
        return true
        break Here I am checking if the string contains any of the alphabet characters. No matter the position or frequency, it's true as long as X contains any member of ""abcdefghijklmnopqrstuvwxyz"" . When X = ""hello"" is true. X = ""123"" is false. And X = ""hello 123"" is true. How would I mathematically denote this? I don't think the following is possible as it checks if the entire $X$ sequence is a member of $g$ . $g = \{a, b, c, \dots, z\}$ if $X \in g$ then Would it be a subset? if $X \subset g$ then Preferably I wouldn't have to denote the character loop as it's an unimportant detail. Just if the string contains any alphabet character","['elementary-set-theory', 'notation', 'computer-science']"
3597471,How to find the slope of $y.\ln x = x.\ln y$ at $x = e$?,"Let's say we have the following equation:- $$y.\ln x=x.\ln y$$ After graphing the equation on desmos (which included, not surprisingly, the line $y=x$ ), I realised that the equation has a slope of 1 at all points of the form $(a,a)$ , except it had two slopes at $(e,e)$ . I went on to try and algebraically find its second slope. $$y.\ln x=x.\ln y$$ $$\ln x.y' + y/x = (x/y).y'+\ln y$$ $$y' = (\ln y-y/x)/(\ln x-x/y)$$ Thus I got an expression for $y'$ which becomes indeterminate at $x=e$ . I wasn't sure how to apply a limit with two variables, and wasn't sure how I would get two slopes. How do I approach finding both the slopes in this self-intersecting graph?","['graphing-functions', 'multivariable-calculus', 'calculus', 'slope', 'exponential-function']"
3597522,Determine or find an upper bound for the limsup of a function with random variables,"Determine or find an upper bound for $$\limsup_{n \to \infty} \left|\frac{\frac{2}{n} (l(\beta) - l(\hat{\beta})) - (\beta - \hat{\beta})^T \nabla^2 l(\hat{\beta})(\beta - \hat{\beta})}{(\beta - \hat{\beta})^T \nabla^2 l(\hat{\beta}) (\beta - \hat{\beta})}\right|$$ where $l$ is the log-likelihood function in a model of logistic regression with $n$ samples of the form $(y_i,X_i)$ , where $y_i \in \{0,1\}$ and $X_i \in R^p$ , $\beta \in R^p$ is an unknown vector of parameters and $\hat{\beta}$ is the MLE. W.l.o.g. I assume that $y_i = 0$ for all $i = 1,\dots,n$ and rearrange the expression to $$\left|\limsup_{n \to \infty} \frac{\frac{2}{n} \sum_{i=1}^n \text{log}\left(\frac{1+e^{X_i^T\beta}}{1+e^{X_i^T\hat{\beta}}}\right) - (\beta - \hat{\beta})^T X^T \text{diag}\left(\frac{e^{X_1\hat{\beta}}}{(1+e^{X_1\hat{\beta}})^2},\dots,\frac{e^{X_n\hat{\beta}}}{\left(1+e^{X_n\hat{\beta}}\right)^2}\right)X(\beta - \hat{\beta})}{(\beta - \hat{\beta})^T X^T \text{diag}\left(\frac{e^{X_1\hat{\beta}}}{\left(1+e^{X_1\hat{\beta}}\right)^2},\dots,\frac{e^{X_n\hat{\beta}}}{\left(1+e^{X_n\hat{\beta}}\right)^2}\right)X(\beta - \hat{\beta})}\right|$$ $$= \left|\limsup_{n \to \infty} \frac{\frac{2}{n}\sum_{i=1}^n \text{log}\left(\frac{1+e^{\sum_{j=1}^p x_{ij}\beta_j}}{1+e^{\sum_{j=1}^p x_{ij}\hat{\beta}_j}}\right) - \sum_{s=1}^p \sum_{m=1}^p \sum_{i=1}^n \frac{e^{\sum_{j=1}^p x_{ij}\beta_j}}{\left(1+e^{\sum_{j=1}^p x_{ij}\hat{\beta_j}}\right)^2}x_{im}x_{is}(\beta_m - \hat{\beta}_m)(\beta_s - \hat{\beta}_s)}{\sum_{s=1}^p \sum_{m=1}^p \sum_{i=1}^n \frac{e^{\sum_{j=1}^p x_{ij}\beta_j}}{\left(1+e^{\sum_{j=1}^p x_{ij}\hat{\beta_j}}\right)^2}x_{im}x_{is}(\beta_m - \hat{\beta}_m)(\beta_s - \hat{\beta}_s)}\right|$$ An idea would be to use an application of the Borel-Cantelli lemma Let $a \in R$ be such that $$ \sum_{n=1}^{\infty} P(X_n > a) < \infty.$$ Then $$\limsup_{n \to \infty} X_n \leq a$$ almost surely. For my purposes it would be awesome if I could show this either for $a = 0$ or for $a = \frac{l(\beta)-l(\hat{\beta}) - \frac{1}{2} (\beta -\hat{\beta})^T \nabla^2 l(\hat{\beta}) (\beta - \hat{\beta})}{\lVert\beta - \hat{\beta}\rVert^2}$ . Another idea would be to use the law of large numbers by showing that $$\mathbb{E}\left[\frac{1}{n} \sum_{i=1}^n \text{log}\left(\frac{1+e^{X_i^T\beta}}{1+e^{X_i^T\hat{\beta}}}\right)\right] = \frac{1}{2}(\beta - \hat{\beta})^T X^T \text{diag}\left(\frac{e^{X_1\hat{\beta}}}{(1+e^{X_1\hat{\beta}})^2},\dots,\frac{e^{X_n\hat{\beta}}}{\left(1+e^{X_n\hat{\beta}}\right)^2}\right)X(\beta - \hat{\beta})$$ but I wouldn´t know how, especially since the distribution of $X_i$ is not specified. Both ideas would only deliver almost sure statements though but that would be better than nothing.","['statistics', 'limsup-and-liminf', 'borel-cantelli-lemmas', 'limits', 'law-of-large-numbers']"
3597559,Property of a semicyclic quadrilateral,"This question has already been asked yesterday by the user @anonymus. I tried to solve it unsuccessfully after leaving a longer comment to persuade the $OP$ to include personal thoughts in the post. Since nothing has happened up to this moment, I voted to close it and ask the same question here including my attempt. Here it goes: Let $ABCD$ be a quadrilateral inscribed in a circle, where $|DC|<|AB|$ and $DC\nparallel AB$ . Let $X$ be the intersection point of the diagonals $\overline{AC}$ and $\overline{BD}$ . And $Y$ be the foot of the perpendicular from $X$ on the edge $\overline{AB}$ . If $XY$ bisects the angle $\measuredangle{DYC}$ , prove that $\overline{AB}$ is the diameter of the (circum)circle, i.e. $ABCD$ is a semicyclic quadrilateral. My attempt: If $XY$ bisects $\measuredangle DYC$ , then $\measuredangle DYX=\measuredangle XYC$ . $$\color{red}{\measuredangle AYD}=90^{\circ}-\measuredangle DYX=90^{\circ}-\measuredangle XYC=\color{red}{\measuredangle CYB}$$ $$\measuredangle C'YA=\measuredangle AYD$$ When drawing, I noticed that $X$ is the center of the circle inscribed in $\Delta DYC$ $$\implies\color{green}{\measuredangle CDB=\measuredangle BDY}\;\&\;\color{blue}{\measuredangle YCA=\measuredangle ACD}$$ I tried using the following: $$\color{purple}{\Delta ABX\sim\Delta CDX}\;\&\;\Delta AXD\sim\Delta CXB$$ My reasoning is circular. 
I'm not sure if I should already assume $\color{brown}{\measuredangle{BDA}=\measuredangle{BCA}=90^{\circ}}$ . Then there's no point in stating that $BCXY$ is also a cyclic quadrilateral. How can I continue and improve what I've written so far? Thank you in advance! Update:
For all those wondering, thanks to @Blue in the comment section, I will read more on the topic: Incircle and excircles of a triangle. Picture:","['euclidean-geometry', 'quadrilateral', 'proof-writing', 'circles', 'geometry']"
3597563,Reciprocal of the Gamma function expressed as a vertical integral,"I want to understand the formula 8.315.2 in Gradshteyn and Ryzhik. It reads $$
\int_{-\infty}^{\infty}{ \frac{e^{ibt}}{(a+it)^k}dt} = \frac{ 2\pi e^{-ab}b^{k-1}}{\Gamma(k)},
$$ where $a,b,k$ are real with $a,b > 0$ and $k \geq 2$ (these are the ranges I am interested in, but the formula might hold more generally). Here, $(a+it)^k = e^{\log(a+it)k}$ , where the we take the standard branch of the logarithm (the one that agrees with the usual real logarithm on the real axis). If I did things correctly, the proof reduces to $$
\frac{1}{\Gamma(k)} = \frac{1}{2\pi i}{\int_{a -i\infty}^{a+ i \infty}\frac{e^z}{z^k} dz}
$$ (and the RHS is indeed independent of $ a > 0$ .). If $k$ is an integer , the above is easy to verify, by shifting the contour far to the left picking up the residue at zero (also, $\Gamma(k) = (k-1)!$ in this case). How can we prove the formulas for general $k$ ?","['complex-analysis', 'contour-integration', 'special-functions', 'gamma-function']"
3597731,What is a matrix with no Jordan canonical form?,Could somebody give me an example of a matrix that doesn’t admit a Jordan Canonical Form over $\mathbb R$ and explain why it does not?,"['matrices', 'jordan-normal-form', 'linear-algebra']"
3597739,Geometry of Balls and Cubes,"I'm stuck on a detail of a proof (Sard's Theorem in Lee's ISM) that deals with the geometry of balls and cubes in Euclidean space. Here's the setup (I'll rename some of the variables from the proof to simplify them and isolate my question): We have a closed cube $E \subset \mathbb{R}^m$ of side length $R$ on which a function $F : E \to \mathbb{R^n}$ is defined. We also know that there is a point $a \in E$ such that for all $x \in E$ , $|F(x) - F(a)| \leq A|x - a|^{k}$ for some fixed real $A \geq 0$ and $k \in \mathbb{Z}^+$ . It is claimed that $F(E)$ is contained within a ball of radius $AR^k$ . I can certainly see that $F(E)$ is contained in a ball of radius $Am^{k/2}R^k$ , because $|x - a| \leq \sqrt{m}R$ for $x \in E$ . But I can't improve this radius to what's given in the proof. What am I missing?","['multivariable-calculus', 'geometry', 'metric-spaces']"
3597825,A function with big eigenvalues acting on the unit ball.,"Let $B(0,1)=\{(x,y,z):x^2+y^2+z^2< 1\}$ denote the unit ball in $\mathbb{R}^3$ and $C$ denote a cylinder around the $z$ -axis with radius $2$ . Suppose that on each point $w$ in $B(0,1)$ we attach a pair of linearly independent vectors $ u_w,v_w$ . Suppose now that we can find a function $f:\mathbb{R}^3\to\mathbb{R}^3$ which is continuously differentiable everywhere and whose total derivative, $D_wf$ at a point $w\in B(0,1)$ has as its two biggest eigenvalues $\lambda_u$ and $\lambda_v$ for which the corresponding eigenvectors are $u_w$ and $v_w$ . Assume that the eigenvalues $\lambda_u$ and $\lambda_v$ corresponding to  those two vectors both satisfy $|\lambda_u|,|\lambda_v|>M$ , where $M$ is a big number. Question : Is it true that the image of the ball $f(B(0,1))$ will necessarily intersect the cylinder $C$ ,  assuming the number $M$ is big enough? Intuitively it seems to me that with all those assumptions our function $f$ stretches the unit ball  at two different directions locally by a lot so the answer to the question should be yes. Edit : We can also assume that $f$ is a homeomorphism. Added later: If we also knew that the smallest eigenvalue $\lambda_0$ is big,  meaning $|\lambda_0|>M$ , then the answer would be yes. That is because in this case  if $\gamma$ is the shortest curve joining $f(0)$ with $\partial f(B(0,1))$ then $$
\operatorname{length}(\gamma)\geq M.$$ This can be proved as follows :
Let $\gamma_1=f^{-1}(\gamma)$ be the inverse image of $\gamma$ which is a curve joining $0$ with $\partial B(0,1)$ . Then \begin{align*}
	\operatorname{length}(\gamma)&=\int_{\gamma}|dx|=\int_{f(\gamma_1)}|dx|=\int_{0}^{1}\left|\left(f\left(\gamma_1(t)\right)\right)'\right|dt\\&=\int_{0}^{1}\left|D_{\gamma_1(t)}f\left(\frac{\gamma_1'(t)}{|\gamma_1'(t)|}\right)\right||\gamma_1(t)'|dt\\&\geq\int_{0}^{1}\inf_{|x|=1}\left|D_{\gamma_1(t)}f\left(x\right)\right||\gamma_1(t)'|dt\geq M\int_{0}^{1}|\gamma_1(t)'|dt\geq M
\end{align*}","['multivariable-calculus', 'derivatives', 'analysis', 'eigenvalues-eigenvectors']"
3597830,"When drawing 14 cards from a set of 52 cards, is it more likely to have a full house or two consecutive pairs?","This is a problem that has been bothering me for quite some time now: When drawing 14 cards from a set of 52 cards (standard poker deck), is it more likely to have at least one full house or at least two consecutive pairs? Both questions seem to resist my attempts to telescope all possible hands into one expression, so here is, where I am: My sample space in both cases is $52\choose14$ .
For the 2 consecutive pairs, there are $12\choose1$ different consecutive pairs to consider. It might be that more cards of the same rank like these consecutive pairs are amongst the drawn cards, so I distinguish between the cases: case 1: no other cards of the ranks of the pairs are drawn ( $4\choose2$$4\choose2$ combinations) case 2: of one rank 3 cards were drawn, of the other one 2 ( $4\choose2$$4\choose3$ combinations) case 3: of one rank 4 cards were drawn, of the other one 2 ( $4\choose4$$4\choose2$ combinations) case 4: of one rank 4 cards were drawn, of the other one 3 ( $4\choose4$$4\choose3$ combinations) case 5: of both rank 3 cards were drawn ( $4\choose3$$4\choose3$ combinations) case 6: of both rank 4 cards were drawn ( $4\choose4$$4\choose4$ combinations) Now I also have to somehow avoid ""overlapping"", when counting the possible combinations of the remaining cards. I cannot for example count the combinations for case 1 with the expression $12\choose1$$4\choose2$$4\choose2$$44\choose9$ , because among the $44\choose9$ combinations of the remaining cards are also many combinations including consecutive pairs, which I count more than once like this. I also tried to approach the problem via the complement event, but it seems to expand even worse. The problem, I am facing with the full house, is similar to this. Maybe I just miss a much simpler way of looking at this. If anybody can give me some advice, it would be much appreciated.","['binomial-coefficients', 'combinatorics', 'card-games', 'poker', 'probability-theory']"
3597953,Prove that A-(B⋃C) = (A-B)⋂(A-C),"Please let me know if this proof is right, I think it is but I still want confirmation A - (B⋃C)
= A ⋂ (B⋃C)'           [X-Y = X⋂Y']
= A ⋂ (B'⋂C')          [(X⋃Y)' = (X'⋂Y') - De-Morgan's Law]
= (A⋂A) ⋂ (B'⋂C')      [A = (A⋂A) - Idempotent Law]
= A ⋂ A ⋂ B' ⋂ C'
= A ⋂ B' ⋂ A ⋂ C'      [Commutative Law]
= (A⋂B') ⋂ (A⋂C')
= (A-B) ⋂ (A-C)        [X⋂Y' = X-Y] Hence, Proved Let me know what you think Thanks...","['elementary-set-theory', 'solution-verification']"
3597956,For what values of $a$ does $\prod_{j=1}^nX_j$ converge in probability to zero?,"Let $(X_n)_{n>1}$ be sequence of independent random variables such that $X_n \sim Bern(1-\frac{1}{n^a})$ where $a>0$ is a constant. Let $Y_n=\prod_{j=1}^n X_j.$ For what values of $a$ does $Y_n$ converge in probability to zero? My approach is the following: $P(Y_n>0)=P((X_1,\ldots,X_n)>0)=\prod_j P(X_j>0)=\prod_j P(X_j=1)=(1−1/n^a)^𝑛$ . To ensure convergence in probability, we require $P(Y_n>0)\to 0$ as $n \to \infty$ . So it is required to check $\lim_{n\rightarrow \infty}(1−1/n^a)^n = 0$ . I am stuck here. I know that $\lim_{n\to \infty}(1−1/n)^n=e^{−1}$ but there is the $n^a$ in the denominator so it is not clear how to use the limiting formula. Any help is appreciated.","['convergence-divergence', 'probability-theory', 'probability']"
3597960,The equation $\sigma(n)=\sigma(n+1)$,"In OEIS A002961 , the solutions of $$\sigma(n)=\sigma(n+1)$$ where $\sigma(n)$ denotes the sum of the divisors of $n$ including $1$ and $n$ , are shown up to $n=10^{13}$ The entry can be found already by entering the first three solutions $14,206,957$ It is mentioned that it is unknown whether there are infinite many solutions. My questions : Has $$\sigma(n)=\sigma(n+1)=\sigma(n+2)$$ a solution ? I checked the OEIS-entries and upto $10^{13}$ there is none. Can we perhaps show that this double-equation cannot have a solution ? Is a family of solutions known that is probably infinite (but not proven, since the problem whether infinite many solutions exist is open) ? Can we find the next solution more efficiently than by just checking all cases ?","['number-theory', 'divisor-sum', 'elementary-number-theory', 'oeis']"
3598000,Colorings versus geometric group theory method,"Consider the following famous problem: Two opposite corner cells of a chessboard are removed. Prove that it is impossible to cover remaining cells with dominoes $2\times1$ . The standard proof uses coloring: the removed cells are of the same color and any domino covers 1 black and 1 white cell. However, there is another proof via geometric group theory: for each cell write $a, b, a^{-1}, b^{-1}$ on its left, upper, right, lower border correspondingly.  Suppose that chessboard without two opposite corners can be covered by dominoes. That would mean that any two elements $a, b$ of any group satisfying $a^2 b a^{-2} b^{-1}=1$ and $ab^2a^{-1}b^{-2} = 1$ will also satisfy $a^7 b a b^7 a^{-7} b^{-1} a^{-1} b^{-7}=1$ . The idea here is that we go clockwise along the border of some subset of cells and intepret the written word as a relation. When two regions have some part of border in common, it cancels out to give a new relation. (See the picture: if $xy=1$ and $y^{-1}z=1$ , then $xz=1$ ). So, it remains to show that $a^7 b a b^7 a^{-7} b^{-1} a^{-1} b^{-7}=1$ does not follow from $a^2 b a^{-2} b^{-1}=1$ and $ab^2a^{-1}b^{-2} = 1$ . Consider $S_3$ and let $a=(1 2), b= (13)$ , then $a^2=1, b^2=1$ , but $abab$ and $baba$ are different, since they are distinct 3-cycles. These two methods (colorings and group theory) can be applied to any problem of the same sort (covering some cell figure with given figures). The question is, are there examples of problems for which one of the methods is more powerful than the other , i.e. one method gives a solution while no solution using the other method is known? For example, there is the following problem: A table $a\times b$ can be covered by rectangles of the form $n\times 1$ and $1 \times n$ only when $n|a$ or $n|b$ . But this problem can be solved by either of the two methods.","['combinatorial-group-theory', 'geometric-group-theory', 'group-theory', 'chessboard']"
3598030,"Maximal Ideals of $F[x_{1} , \dots , x_{n}]$, $F$ not necessarily algebraically closed","Suppose that $F$ is a field (not necessarily algebraically closed) and $R = F[x_{1} , \dots , x_{n}]$ is the ring of polynomials in $n$ -variables. How can I classify the maximal ideals of $R$ ? If $F = \overline{F}$ , then the weak nullstellensatz, states that the maximal ideals of $R$ are the sets $I = (x_{1} - a_{1} , \dots , x_{n} - a_{n}) : a_{i} \in F , \forall i \in [n]$ . Is it the case that the maximal ideals of $R$ when $F$ is not algebraically closed are $I = \{ f \in R : f(a_{1} , \dots , a_{n}) = 0 \} \text{ for some } a_{i} \in \overline{F}$ ? If so how does one prove it? Could I argue that $I \subset \overline{I}$ , where $\overline{I} \unlhd \overline{F}[x_{1} , \dots , x_{n}]$ is a maximal ideal of the ring of polynomials in $n$ -variables over the algebraic closure of $F$ ? However, I believe this argument does not consider the fact that $I$ is maximal.","['maximal-and-prime-ideals', 'algebraic-geometry', 'abstract-algebra', 'polynomials', 'commutative-algebra']"
3598037,Show $S^2$ cannot have a smooth vector field with two zeros that are either both sources or both sinks,"Backround I have just learned the Poincaré-Hopf Index Theorem which says that if $\overrightarrow{v}$ is a smooth vector field on a compact,
oriented manifold $X$ with only finitely many zeros, then the global sum of the
indices of $\overrightarrow{v}$ equals the Euler characteristic of $X$ . This is great, but it may not be the whole story regarding the ""rules"" of which combinations of different qualitative types of zeros a vector field can and can't have on a given space. Particular Question Edit: my ""particular question"" assumed something that was wrong, so only the general question makes sense For example, my intuition tells me that on $S^2$ one cannot have just two zeros where both are sources or both are sinks. But this is not ruled out by Poincaré-Hopf since index doesn't distinguish between source and sink in two dimensions. So how can we rigorously rule this out? General Quesiton What are the key theorems or theories used for which combinations of different qualitative types of zeros a vector field can and can't have on a given space/manifold? I am generally interested in simple spaces such as balls and spheres (in arbitrary dimensions) and also cartesian products thereof. I am not so interested in spaces with complicated combinations of holes of various dimensions and so on. So far I have been reading Guilleman and Pollack's Differential Topology.","['differential-topology', 'reference-request', 'ordinary-differential-equations', 'differential-geometry']"
3598124,"Let $\frac{a}{b},\frac{c}{d}\in \mathbb{Q}$. prove that the product is well-defined","We have that $\frac{a}{b}\cdot \frac{c}{d}=\frac{a'}{b'}\cdot\frac{c'}{d'}$ , which can be rewritten as $\frac{ac}{bd} = \frac{a'c'}{b'd'}$ and again as $(ac)(b'd') = (bd)(a'c').$ If $\frac{a}{b} = \frac{a'}{b'}$ and $\frac{c}{d} = \frac{c'}{d'}, $ then $ab' = ba'$ and $cd' = dc'.$ $= (ab')(dd') = (ba')(dd')$ and $(cd')(bb') = (dc')(bb')$ $= (ab')(dd')(cd')(bb') = (ba')(dd')(dc')(bb')$ when multiplying the two equations. Here is where I got stuck. I was attempting to get the final equation equal to $(ac)(b'd') = (bd)(a'c')$ so as to prove that the multiplication is well-defined, but I am unsure of how to get there from where I am or whether I'm thinking about this wrong to begin with.","['proof-writing', 'discrete-mathematics']"
3598178,Intersection Theory and Blow up,"The following is from Fulton's Intersection Theory : Theorem 6.7 (Blow-up Formula). Let $V$ be a $k$ -dimensional subvariety of $Y$ , and let $\widetilde{V} \subset \widetilde{Y}$ be the proper transform of $V$ , i.e. the blow-up of $V$ along $V \cap X$ . Then $$f^{*}[V] = [\widetilde{V}] + j_{*} \bigl \{c(E) \cap g^{*}s(V \cap X, V) \bigr \}_{k}$$ in $A_{k}\widetilde{Y}$ . $$ \require{AMScd}\begin{CD}
\widetilde{X} @>j>> \widetilde{Y}
\\ @VV g V @VVfV
\\ X @>i >> Y
\end{CD}
$$ Where $f : \widetilde{Y} \longrightarrow Y$ is the blow up of $Y$ along $X$ with exceptional divisor $E$ . Now, for $Y = \mathbb{P}^{n}$ and $X \subset Y$ a smooth subvariety the second answer to the question   { https://mathoverflow.net/q/72710 } we have 1) $\widetilde{H}^{n} = 1$ , 2) $\widetilde{H}^{n-i} \cdot E^{i} = 0$ for $i < c = \text{codim}(X)$ , 3) $\widetilde{H}^{n-i} \cdot E^{i} = (-1)^{i-1}s_{i-c}H_{X}^{n-i}$ for $i \geq c$ , where $\widetilde{H} = f^{*}H$ is the pull-back of hyperplane class $H$ on $Y$ , and $H_{X} = H\cdot X$ . Do these equalities come from the above theorem? How? Every help is welcome. Thanks a lot.","['algebraic-geometry', 'intersection-theory', 'blowup']"
3598214,Fundamental domain for congruence subgroup.,"Let $\Gamma$ be a congruence subgroup of the modular group $\mathrm{SL}_{2}(\mathbb{Z})$ .
Let $R$ be coset representatives of the quotient $\Gamma\setminus\mathrm{SL}_{2}(\mathbb{Z})$ and let $\mathcal{D}$ be the standard fundamental domain for $\mathrm{SL}_{2}(\mathbb{Z})$ (actually we could consider any fundamental domain for $\mathrm{SL}_{2}(\mathbb{Z})$ ). I want to prove that $$\mathcal{D}_{\Gamma}=\bigcup_{\gamma\in R}\gamma\mathcal{D}$$ is a fundamental domain for the congruence subgroup $\Gamma$ , i.e. that for every $z$ in the upper complex half-plane $\mathbb{H}$ there exists $\gamma\in\Gamma$ such that $\gamma z\in\mathcal{D}_{\Gamma}$ and also that if $z,\gamma z\in\mathcal{D}_{\Gamma}^{\circ}$ then this $\gamma$ is unique up to multiplication by an element of $\Gamma\cap\{\pm I\}$ , where $I$ is the identity matrix. It is simple to prove the existence of $\gamma\in\Gamma$ . I have a problem showing the ""uniqueness"".
Here is my proof: Consider $z\in\mathbb{H}$ and $\gamma_{1},\gamma_{2}\in\Gamma$ such
that $\gamma_{1}z,\gamma_{2}z\in\mathcal{D}_{\Gamma}^{\circ}$ . This implies that there
exist $\gamma_{1}',\gamma_{2}'\in R$ and $z_{1},z_{2}\in\mathcal{D}$ such that $\gamma_{1}z=\gamma_{1}'z_{1}$ and $\gamma_{2}z=\gamma_{2}'z_{2}$ . Therefore, \begin{equation*}
    \gamma_{1}^{-1}\gamma_{1}'z_{1}=z=\gamma_{2}^{-1}\gamma_{2}'z_{2}.
\end{equation*} Set $w_{1}=\gamma_{1}'z_{1}\in\mathcal{D}_{\Gamma}^{\circ}$ , $w_{2}=\gamma_{2}'z_{2}\in\mathcal{D}_{\Gamma}^{\circ}$ , and $\gamma=\gamma_{1}\gamma_{2}^{-1}$ .
Then, we have that $w_{1}=\gamma w_{2}$ . We claim that $\gamma=I$ .
Indeed, since $w_{1}\in\mathcal{D}_{\Gamma}^{\circ}$ , there exists $\epsilon>0$ such that $B_{\epsilon}(z)\subseteq\mathcal{D}_{\Gamma}^{\circ}$ . $B_{\epsilon}(z)$ intersects some
translations of $\mathcal{D}$ in $\mathcal{D}_{\Gamma}$ . Let $R'$ be the set of representatives of such translations, i.e. $S\subseteq R$ and \begin{equation*}
    \delta\in S\iff B_{\epsilon}(z)\cap \delta \mathcal{D}\neq\emptyset.
\end{equation*} Now we have that $\gamma z\in\mathcal{D}_{\Gamma}^{\circ}$ and so there exists $\delta\in R$ such that $\gamma B_{\epsilon}(z)\cap \delta \mathcal{D}\neq \emptyset$ . This implies that \begin{equation*}
    B_{\epsilon}(z)\cap\gamma^{-1}\delta\mathcal{D}\neq\emptyset
\end{equation*} and so $\gamma^{-1}\delta=\delta'$ for some $\delta'\in R'$ .
Hence, \begin{equation*}
    \Gamma \delta'=\Gamma\gamma^{-1}\delta=\Gamma\delta
\end{equation*} and so $\delta=\delta'$ , which implies that $\gamma=I$ . My problems is the following: First, the above proof works if $\gamma B_{\epsilon}(z)=B_{\epsilon}(\gamma z)$ , which I suspect holds but I cannot prove, or at least $B_{\epsilon}(\gamma z)\subseteq \gamma B_{\epsilon}(z)$ . The second is that I miss the multiplication by an element in $\Gamma\cap\{\pm 1\}$ . Where is the error?","['modular-forms', 'group-theory', 'modular-group']"
3598227,"Construction of lines through a given point, cutting two given circles in congruent chords",Given a point $P$ and two circles $\Gamma$ and $\Gamma'$ with centers $O$ and $O'$ . I'm searching for a method to construct lines passing through $P$ and defining on each circle chords of same length. A geometer professor made the following drawing to illustrate the problem. Many thanks for any constructive idea or suggestions.,"['euclidean-geometry', 'geometry']"
3598253,Which solution to the integral $\int \frac {dx}{x \sqrt {x^2-1}}$ is correct and why?,"I have this integral: $$\int \frac {dx}{x \sqrt {x^2-1}}.$$ I solved it like this: $$ \sqrt {x^2-1} = t \to x = \sqrt {t^2+1} \to $$ $$dx = \frac {t}{\sqrt {t^2+1}}\,dt .$$ Solving for t: $$ \int \frac {dt}{t^2+1} = \arctan(t) + c .$$ In the solution I have, however, it is solved in another way: $$ x = \sec(t), \ \sqrt{x^2-1}=\tan(t), $$ $$dx=\sec(t)\tan(t)\,dt \to $$ $$\int \frac {\sec(t)\tan(t)} {\sec(t)\tan(t)}\,dt= \int dt = t +c= \operatorname{arcsec}(x) + c.$$ Which solution is correct and why?","['indefinite-integrals', 'calculus']"
3598263,An example of a $G$-torsor as a finite Galois extension,"I was looking for a definition of a $G$ -torsor $X \rightarrow Y$ of schemes where $G$ is a finite group acting on $X$ and also considered to act on $Y$ trivially. I have a vague impression that in this case $G$ should act on $X$ freely and transitively , thus the decomposition group $G_P = \{ \sigma \in G : \sigma(P) = P \}$ for each point $P \in X$ is trivial. Then I looked into examples on Wikipedia, where it states that for a finite Galois extension $L/K$ , Spec $L$ $\rightarrow$ Spec $K$ is an example of a G-torsor where $G = Gal(L/K)$ . And surely for each prime $\mathfrak{P} \in \text{Spec } L$ , its decomposition group can be non-trivial, especially when the extension is ramified at $\mathfrak{P}$ . Was I wrong to assume that all decomposition groups should be trivial when we have a $G$ -torsor? Thank you.","['algebraic-number-theory', 'algebraic-geometry']"
3598269,To each representation on $\mathbb{C}^n $ corresponds a representation on $\mathbb{R}^{2n} $,"So, I am supposed to show that to each representation $\rho$ of a group $G$ on $\mathbb{C}^n $ corresponds a representation $\tilde{\rho}$ , of the same group $G$ , on $\mathbb{R}^{2n} $ . Additionally: Show that, if the representation $(\tilde{\rho},\mathbb{R}^{2n}) $ is irreducible, then the representation $(\rho,\mathbb{C}^{n} )$ is also irreducible. My thinking: For the first part: Suppose we have the following map: $\phi(z):\mathbb{C}^{n}\rightarrow \mathbb{R}^{2n}, \space \phi(z)=
\begin{bmatrix}
    Re(z)   \\
    Im(z)    \\
\end{bmatrix}$ . This is obviously a bijection, additionally it follows that $\phi(z_1+z_2)=\phi(z_1)+\phi(z_2)$ . My idea then was to find a bijection $\eta$ between the sets $\rho(g)$ and $\tilde{\rho}(g)$ , for $g \in G$ . And this is what I came up with (I'll denote $\rho(g)$ as $\rho_g$ ): $$\eta:\mathbb{R}^{2n}\rightarrow \mathbb{C}^{n}, \space \eta:\space \tilde{\rho}_g(.)\rightarrow \phi^{-1}(\tilde{\rho}_g(\phi(.)))=\rho_g(.)$$ The map $\rho_g (.)=\phi^{-1}(\tilde{\rho}_g(\phi(.)))$ is clearly $\mathbb{C}^{n} \rightarrow \mathbb{C}^{n}$ , it is also a bijection and it follows that $\rho_g(z_1z_2)=\rho_g(z_1)\rho_g(z_2)$ , all together meaning that $\rho_g $ is a representation of $G$ on $\mathbb{C}^{n}$ . I have therefore shown that to each representation $(\tilde{\rho},\mathbb{R}^{2n})$ corresponds a representation $(\rho,\mathbb{C}^{n})$ , via $\eta$ . For the second part: (proof by contradiction) Irreducible means that for $\tilde{\rho}$ there is no (non-trivial) invariant subspace in $\mathbb{R}^{2n}$ . Lets take a (non-trivial) subset $R\subset \mathbb{R}^{2n}$ , so that for a subset $W \subset \mathbb{C}^{n}: \space$ $\phi(W)=R$ and $\phi^{-1}(R)=W$ . We suppose that the opposite holds ( $\rho$ is reducible): that $W$ is some non-trivial  invariant subset for $(\rho,\mathbb{C}^{n} )$ . This means that $\rho_g(W) \subset W$ for each $g \in G$ . But since $\phi^{-1}(\tilde{\rho}_g(\phi(W)))=\rho_g(W) \subset W$ , it follows that $\tilde{\rho}(\phi(W))\subset R $ and using $\phi(W)=R$ , we get that $\tilde{\rho}(R)\subset R$ . So we found a (non-trivial) invariant subspace for $\tilde{\rho}$ , but this contradicts the above statements that $\tilde{\rho}$ is irreducible, therefore $\rho$ must be irreducible. My question: Is my thinking correct? Could you please suggest some improvements or maybe show a different, more compact way to prove the above statements.","['group-theory', 'abstract-algebra', 'representation-theory', 'solution-verification']"
3598325,"Justifying the ""Physicist's method"" for ODEs using differential forms","I need some help in untangling and solving the following exercise: Let the curve $c:[a,b] \to \mathbb{R}^2, t \mapsto (t, y(t))$ be a
  solution for the ODE $$ y'(x) = f(x, y(x)). $$ Justify the
  ""Physicist's method"" (no offense intended) of rearranging the equation $\frac{dy}{dx} = f(x,y)$ through formal multiplication of $dx$ to $$
dy = f(x,y)dx, $$ by showing that both differential forms agree in
  every point $c(t)$ on the tangent space. As far as I understand the situation, we are considering the two differential forms $$\begin{equation}
dy: \mathbb{R}^2 \to {\bigwedge}^1(T_p\mathbb{R}^2)\\
f(x,y)dx: \mathbb{R}^2 \to {\bigwedge}^1(T_p\mathbb{R}^2)\\
\end{equation}
$$ Here $dy$ is a constant differential form, in the sense that $dy(p)(x,y) = y$ independent of $p=(v,w) \in \mathbb{R}^2$ . However, in general $f(x,y)dx$ is not a constant differential form.
Now, if we choose a point on the curve $c$ , say $p = c(t_0) \in c([a,b])$ then we have $$
f(p)dx = f(c(t_0))dx = y'(t_0)dx,
$$ since $c$ is a solution to the ODE given above. I don't know how to proceed from this point. How can we argue that this equals $dy$ ?","['differential-forms', 'differential-geometry', 'ordinary-differential-equations', 'real-analysis']"
