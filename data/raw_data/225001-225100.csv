question_id,title,body,tags
4635493,Analog of Cantor-Schroder-Bernstein theorem for surjective homomorphisms between groups?,"I'm thinking of the following problem: If we have two groups $G$ and $H$ , with surjective homomorphisms $\psi:G\to H$ and $\phi:H \to G$ , is it possible to prove that $G$ and $H$ are isomorphic? Or could we construct a counterexample? $G$ and $H$ must have the same cardinality (see this question ), but I don't know that whether they are necessarily isomorphic. I know that the Cantor-Schroder-Bernstein theorem doesn't hold for groups (see here ), but I'm wondering that whether the situation would be different for surjective homomorphisms.","['group-homomorphism', 'group-theory', 'abstract-algebra']"
4635508,How large can the range of Lebesgue densities of a measurable subset of $\mathbb{R}$ be?,"As mentioned in the bounty, I'm actually looking for a set $E$ such that $d(D)=[0,1]$ .  The original question follows for context. Let $E \subset \mathbb{R}$ be Lebesgue measurable, let $D \subseteq \mathbb{R}$ the set of all points for which the Lebesgue density of $E$ exists, and let $d : D \to [0,1]$ denote the density. Loosely speaking, my question is about how ""large"" $d(D) \subseteq [0,1]$ can be.  Specifically, I'm wondering about the following two questions: Can $d(D)$ be uncountable? Can $d(D)$ have nonempty interior? As long as I haven't made any simple mistakes thinking about the problem, then in higher dimensions, $d$ can be surjective, but the examples I've imagined only work because a line segment in $\mathbb{R}^n$ has measure zero for $n > 1$ (so they have no apparent parallel in $\mathbb{R}$ due to Lebesgue's density theorem). For $\mathbb{R}$ , at this point I've only done the ""trivial"" case, that $d(D)$ can contain any prespecified countable set as a subset, so in particular it can be dense in $[0,1]$ .  I don't even know if I have the tools to answer the questions I'm left with.","['measure-theory', 'lebesgue-measure', 'real-analysis']"
4635521,Solving $\cos A + \cos B + \cos C = 0$ and $\sin A + \sin B + \sin C = 0$ using complex numbers,"My teacher gave this question to me while teaching complex numbers: If $\;\sin A\!+\!\sin B\!+\!\sin C=\cos A \!+\!\cos B\!+\!\cos C=0$ , then find: $\cos 2A + \cos 2B + \cos 2C$ $\cos 3A + \cos 3C + \cos 3C$ $\cos(A\!-\!B)+\cos(B\!-\!C)+\cos(C\!-\!A)$ Now, I tried it simplifying using this formulae derived from Euler form of complex number: $\;2\cos x=e^{ix}+e^{-ix}\;$ , but nothing seems to work. I do not understand, what is the significance of solving this question with complex numbers ?","['trigonometry', 'complex-numbers']"
4635555,"Derivative of irrational function is undefined at zero, but it seems weird for me.","There is an example that confuses me: $$f(x) = x \sqrt x$$ Taking the derivative: $$f'(x) = (x)' \sqrt x + (\sqrt x)'x = \sqrt x + \frac {x}{2\sqrt x} = \frac {2x + x}{2 \sqrt x} = \frac{3x}{2 \sqrt x}$$ So far it makes sense. The derivative is undefined at zero because we can't put 0 in denominator.
But on the other hand, if we use the power rule: $$f'(x) = (x \sqrt x)' = (x^{1}x^{0.5})' = (x^{1.5})' = 1.5x^{0.5} = \frac{3 \sqrt x}{2}$$ Which IS actually defined at zero. Then I got it: $$\frac{3x}{2 \sqrt x} = \frac{3x}{2 \sqrt x} \frac{\sqrt x}{\sqrt x} = \frac{3x \sqrt x}{2x}$$ But x could possibly be 0, so we can't divide by it: $$\frac{3x \sqrt x}{2x} \not= \frac{3 \sqrt x}{2}$$ Why it appears when I use the power rule? What am I missing?","['algebra-precalculus', 'derivatives']"
4635570,How to prove $f^\infty (X)$ is not empty.,"Let $X$ be a topological space. $f: \ X \rightarrow X $ be a continuous function on X. Define $f^\infty (X)$ as follows: \begin{equation}
F_1 = f(X),\quad  F_2 = f(f(X))\ ,\quad \dots,\quad F_n = f^n(X) \\
 f^{\infty}(X) = \cap_{n=1}^{\infty} F_n 
\end{equation} I think the set $f^\infty (X)$ should be non-empty. How to prove it? Or under what condition would it be non-empty, could I remove continuity of $f$ ? This question come from another question: If $X$ is a compact Hausdorff Space, $f$ is a continuous function on $X$ , then there would be a non-empty closed subset $A$ of $X$ s.t. \begin{equation}
 f(A)=A
\end{equation} I am going to solve it by defining the $f^\infty(X)$ , but I could not prove it is non-empty. Could anyone give me some hint for it?","['general-topology', 'functions']"
4635582,Will this function always have a fixed point?,"$f:[0,\infty) \to [0,\infty)$ where $|f(x)-f(y)| \le \frac{1}{2}|x-y|$ Does this function always have a fixed point? My attempt: The function is continuous. If it becomes differentiable then it will have a fixed point. So I was looking for some non differentiable continuous function which doesn't have a fixed point. What I could think of is example of the form $|x-a|/2$ but I am unable to construct one. Some hints please.","['functions', 'fixed-point-theorems', 'real-analysis']"
4635599,Is it true that an arbitrary rotation $R\in SO(3)$ can be decomposed into rotations about any two fixed axes?,"This is from exercise 4.11 in Nielsen and Chuang's Quantum Computation and Quantum Information (10th Anniversary Edition), which I think might be in error. Background A quantum unitary operator on the state of a single qubit (a 2-level system whose state space is represented by a 2D complex Hilbert space) is a member of $SU(2)$. $SU(2)$ is related to $SO(3)$ in such a way that we can think of members of $SU(2)$ as rotations for the present application. In fact, they have the effect of rotating the Bloch vector representation of the quantum state: http://www.vcpc.univie.ac.at/~ian/hotlist/qc/talks/bloch-sphere-rotations.pdf It is known that an arbitrary such operation $U$ may be represented as follows: \begin{eqnarray*}U &\equiv& R_{\hat{n}}(\theta) \equiv e^{i \alpha} e^{i \frac{\theta}{2} \hat{n} \cdot \vec{\sigma}} \\ &=& \cos\left(\theta/2\right) I + i \sin\left(\theta/2\right) \hat{n} \cdot \vec{\sigma} \\ &=& \cos\left(\theta/2\right) I + i \sin\left(\theta/2\right) (n_x \sigma_x + n_y \sigma_y + n_z \sigma_z) \, \, , \end{eqnarray*} where the $\sigma_j$ are the Pauli matrices for $j \in \{x, y, z\}$, $\hat{n}$ is a unit vector in $\mathbb{R}^3$, and $\alpha$ is some phase angle (that incidentally is irrelevant to quantum mechanics, but its relevance might not be a consideration for this question). Note that this rotates the Bloch vector representation of a quantum state (let's call it $\vec{q}$) by an angle $\theta$ around $\hat{n}$, as is described in the link above and elsewhere. A theorem states that an arbitrary rotation may be decomposed into $z$ and $y$ rotations as follows: $U = e^{i\alpha} R_{\hat{z}}(\beta)\, R_{\hat{y}}(\gamma)\, R_\hat{z}(\delta) \equiv e^{i\alpha} e^{i\beta \sigma_z} e^{i\gamma \sigma_y} e^{i\delta \sigma_z}$, where $\alpha$, $\beta$, $\gamma$, and $\delta$ are phase or rotation angles. Claim The claim (which the exercise asks the reader to prove using the theorem mentioned in the previous paragraph) is that given some non-equal fixed axes $\hat{n}$ and $\hat{m}$, an arbitrary operation $U \equiv R_{\hat{r}}(\theta) = e^{i \phi} e^{i \frac{\theta}{2} \hat{r} \cdot \vec{\sigma}}$ may be decomposed as follows: \begin{equation*}
U = e^{i\alpha} R_{\hat{m}}(\beta)\, R_{\hat{n}}(\gamma)\, R_\hat{m}(\delta) \, \, ,
\end{equation*} for some angles $\alpha$, $\beta$, $\gamma$, and $\delta$. Contention Consider given $\hat{m}$ and $\hat{n}$ that are very close to each other (e.g. their dot product is very close to but not equal to 1, perhaps 0.99). Consider $\hat{r}$ that is very far away from either $\hat{m}$ or $\hat{n}$ (e.g. their dot product is close to 0, perhaps 0 or 0.01). Consider trying to rotate a vector $\vec{v}$ around $\hat{r}$, $\vec{v}$ being initially very close to $\hat{m}$ and $\hat{n}$ prior to the rotation (where $\vec{v}$ may be thought of as a Bloch vector in the quantum context we're discussing). Surely, we can think of rotations around $\hat{r}$ that cannot be achieved by rotations around $\hat{m}$ and $\hat{n}$ as claimed in the exercise. Note This set of errata mention this exercise having an error, but it refers to the printing from the year 2000 (see erratum referring to p. 176), and doesn't show what the original exercise had stated: http://www.michaelnielsen.org/qcqi/errata/errata/errata.html . I have the 2010 edition and so would expect that the error would have been corrected in my edition (I can't tell if the original erroneous exercise was the same as printed in the later 2010 edition). Thanks!","['quantum-mechanics', 'quantum-information', 'abstract-algebra', 'rotations']"
4635626,Proving an inequality of Lipschitz continuous functions,"Let $f : [0, \infty) \rightarrow \mathbb{R}$ be a function such that $|f(x) - f(y)| \leq |x - y|, \forall x, y \geq 0$ , and let $F$ be one of its antiderivatives such that $F(0) = 0$ . a) Prove that $|yF(x) - xF(y)| \leq \frac{xy|x-y|}{2}, \forall x, y \geq 0.$ b) Knowing that $f(x) \geq 0, \forall x \geq 0$ , how many solutions does the equation $F(x) = x^2$ have? My initial thought was observing that the function is Lipschitz with $L = 1$ , thus continuous, thus Riemann integrable. Because we are told that $F(0) = 0$ , I wanted to consider $F(x) = \int_0^x f(t)dt$ and then $F(x) - F(y) = \int_y^x f(t)dt$ , but since we need $|yF(x) - xF(y)|$ , I tried both integrating $\int_y^x tf(t)dt$ and seeing where that gets me, as well as integrating the first inequality with respect to x, using the fact that $|\int_a^b f(t)dt| \leq \int_a^b |f(t)|dt$ , but to no avail. For b), we know that $F'(x) = f(x) \geq 0$ , so then $F$ is an increasing function. I believe we have to show somehow that $x_0 = 0$ is the only solution to this equation using a), but I am missing something.","['integration', 'lipschitz-functions', 'analysis', 'real-analysis', 'calculus']"
4635660,Evaluate $\int \frac{dx}{(1-x^2)\sqrt[4]{(2x^2-1)}}$,"How can we evaluate the following integral? $$
\mathcal{I} = \int \frac{dx}{(1-x^2)\sqrt[4]{(2x^2-1)}}
$$ Some notes... Any standard integration methods (e.g., substitution method, integration by parts, etc.) does not work. I tried using integral-calculator.com, it does not work either. Trivially, I tried to set some possible limits (e.g., 0 $\rightarrow$ 1, $-\pi \rightarrow \pi$ , etc.) — with no success. This is not a homework question. I'm open to the ideas given by experts here.","['integration', 'indefinite-integrals', 'calculus']"
4635669,Relative extrema of function $2x^2+y^2+z^2-xy$,"I need to find the relative extrema of the function $$f(x,y,z)=2x^2+y^2+z^2-xy$$ I conclude that the only critical point is $(0,0,0)$ , and that it is a relative minimum, but I'm not sure if it is correct. Can somebody help me?
To conclude that $(0,0,0)$ is a relative minimum, I have calculated $$\text{Hess}f(x,y,z)=\begin{pmatrix}
4 & -1 & 0 \\
-1 & 2 & 0 \\
0 & 0 & 2 \\ \end{pmatrix}$$ and since it is positive definite, it has to be a relative minimum.",['functions']
4635743,Are these functions bewteen continuous and bounded functions?,"Denote by $P$ the set of all (Borel) probability measures with full support on $\left[a,b\right]$ .
Consider the following set: $$D \equiv \left\{f\in \mathbb{R}^{[a,b]}\vert -\infty<\int_a^b fdp<+\infty,\forall p \in P\right\}$$ My conjecture is $C[a,b] \subseteq D \subseteq B[a,b]$ . Is it right? For the part of $C[a,b] \subseteq D$ , I thought every continuous function is measurable by Lusin's theorem, and then I can use dominated convergence theorem. But this thread suggests it is not the case: $f$ a real, continuous function, is it measurable? I am confused. For the part of $D \subseteq B[a,b]$ , I guess if the function is not bounded, then one can find a probability measure such that the integral explodes but I am not sure how to implement this.","['measure-theory', 'probability-theory', 'analysis']"
4635744,Expected value and variance of $e^{\frac{2n}{\sum_{i=1}^n X_i^2}}$ (maximum likelihood estimator),"Let $\theta>1$ be an unknown parameter and let $X_1, X_2, ..., X_n$ be a random sample (which means i.i.d. in this case) from the density $f_\theta$ where $$f_{\theta}(x)=x\theta^{-\frac{x^2}{2}}\log(\theta)\mathbb{1}_{(0, \infty)}(x).$$ We are given that $\mathbb{E}_{\theta}[X_1^2]=\frac{2}{\log(\theta)}$ and $\mathbb{E}_{\theta}[X_1^4]=\frac{8}{(\log \theta)^2}$ . First, I was asked to compute the maximum likelihood estimator of $\theta$ , call it $\hat{\theta}_n$ . This isn't hard, I got $$\hat{\theta}_n=e^{\frac{2n}{\sum_{i=1}^n X_i^2}}.$$ What I don't know how to do is how to prove if this estimator is efficient, i.e. if the Rao-Cramer bound is attained. To do so I need to find the expected value of my estimator and its variance. But how would I do this? I have no idea what is the distribution of $\sum_{i=1}^n X_i^2$ to even be able to get started on this using the so called law of unconscious statistician. So, how is this supposed to be done?","['statistics', 'variance', 'expected-value', 'maximum-likelihood', 'probability']"
4635762,Non-$\zeta$ term of the sum $\sum\limits_{k = 1}^{\infty} \frac{H_k H_{k+m}}{k^2}$ for $m \in \mathbb{N}_0$,"While tinkering with Mathematica I found that it could evaluate sums of the form $$\sum\limits_{k = 1}^{\infty} \frac{H_k H_{k+m}}{k^2}$$ for some nonnegative integer $m$ . As it turns out (or the evidence is overwhelmingly in favor of it), this sum is always a linear combination of a constant term and the first three $\zeta$ -values, i.e. $\zeta(2)$ through $\zeta(4)$ . The coefficients of the $\zeta$ -values were not too hard to figure out with the help of the OEIS and a bit of intuition. We have $$\sum\limits_{k = 1}^{\infty} \frac{H_k H_{k+m}}{k^2} = -C -\left(\sum\limits_{k = 1}^{m}\frac{1}{k^2}\right)\zeta(2) + 2\left(\sum\limits_{k = 1}^{m}\frac{1}{k}\right)\zeta(3) + \frac{17}{4}\zeta(4)$$ with just the non-zeta term $C$ being undetermined. For $m = 1,\ldots,9$ this constant takes on the values $$C = 0,\frac{1}{4},\frac{4}{9},\frac{341}{576},\frac{679}{960},\frac{25921}{32400},\frac{19879}{22680},\frac{95594629}{101606400},\frac{182134073}{182891520}$$ which... isn't all that insightful, to say the least. Visually, this looks like Thanks to the comment by ho boon suan (and verification by Dr. Wolfgang Hintze) I was able to verify that indeed $$C = \frac{1}{2} \sum\limits_{j = 1}^{m} \frac{H_{j-1}^2+H_{j-1}^{(2)}}{j^2}$$ and thus $$\sum\limits_{k = 1}^{\infty} \frac{H_k H_{k+m}}{k^2} = -\sum\limits_{j = 1}^{m} \underbrace{\frac{H_{j-1}^2+H_{j-1}^{(2)}}{2j^2}}_{=\frac{1}{j^2(j-1)!} \begin{bmatrix}j \\ 3\end{bmatrix}} -H_m^{(2)}\zeta(2) + 2H_m\zeta(3) + \frac{17}{4}\zeta(4)$$ As a side product of an auxiliary calculation, we also have the identity $$\sum\limits_{k = 1}^{\infty} \frac{H_k}{k^2(k+j)} = \frac{H_{j-1}^2+H_{j-1}^{(2)}}{j^2} - \frac{1}{j^2} \zeta(2) + \frac{2}{j}\zeta(3)$$ for arbitrary $j \in \mathbb{N}$ .","['harmonic-numbers', 'sequences-and-series']"
4635770,Notion of `normal bundle' of a submanifold in a Finsler manifold,"Given a submanifold $N$ in a Riemannian manifold $(M, g)$ , we have the notion of normal bundle $$\nu(N) := \{(p,v) \in TM \; | \; p \in N, \, g(v, w) = 0 \, \forall w \in T_p N\}.$$ It is well-known that a distance minimimizing geodesic from $N$ has to start in the normal bundle. That is, if $\gamma :[0,1] \to M$ is a unit speed geodesic satisfying $\gamma(0) \in N$ and $\text{dist}(N, \gamma(t)) = t$ for some time $t \in [0,t_0] \subset[0,1]$ , then $\dot\gamma(0) \in \nu(N)|_{\gamma(0)}$ . Here $\text{dist}(\_,\_)$ is the induced distance. Now, suppose we have a Finsler manifold $(M,F)$ and a submanifold $N \subset M$ . Is there any notion of 'normal bundle' of $N$ here, so that the initial velocity of any distance minimizing geodesic from $N$ must lie in this normal bundle? Any references or comments regarding this will be highly appreciated. Cheers!","['finsler-geometry', 'riemannian-geometry', 'differential-geometry']"
4635833,Axioms of probability with finite (rather than countable) additivity,Probability measures are required to satisfy $\mu(\emptyset) = 0$ $\mu(\Omega) = 1$ $\mu\left(\bigcup_{i \in \mathbb{N}} A_i \right) = \sum_{i\in \mathbb{N}} \mu(A_i)$ for disjoint sets $A_i \subset \Omega$ . What happens if we only assume the last condition for finite sequences? Do we lose (lots of or all) important results?,"['measure-theory', 'definition', 'probability-theory']"
4635919,"some basic questions about topology- is this $[1,2]$ open under topology $\{\emptyset,X,[1,2]\}$","I remember the lecturer said when you ask if a set is open or closed you need to specify the topology, then the following example I am not sure if is it closed or open. Let's say define a topology on $X=[0,\infty)$ and the topology is $\{\emptyset,X,[1,2]\}$ I got the following questions: 1 is $[1,2]$ considered as open by definition? if so, then 2 $[0,1)\cup(2,\infty)$ considered as closed, what about $[0,1)$ ? closed or Neither? I love to think like the finite union of closed is closed, even though I know that the finite union of neither open nor closed sets could be closed, but that is for the usual topology. Thank you for clearing my mind about these two questions. Extra edited As I retrive this post I have another mind hope you guys may help me to clear up. I agree that $[0,1)$ cannot construct by finite intersection nor arbitrary union. But if I look another way by arguing evey points in $[0,1)$ equipped with $\epsilon$ -radius ball still lay in $[0,1)$ . Here is what my confusion come in : the point at $0$ with $\epsilon$ -radius ball do not fully lay in $[0,1)$ becasue left hand side of the ball do not lay in $[0,1)$ , so $[0,1)$ is not open. However my another argument goes:  when centered at $0$ , there is no left hand side of $\epsilon$ -radius ball, beacuse we only defined on $[0,\infty)$ , so it is open. (I personally incline to this), why is this argument incorrect.","['general-topology', 'analysis', 'real-analysis']"
4635930,"Analyzing whether the unit circle $S=\{(x,y)\in \mathbb{R}^2|x^2+y^2=1\}$ is Jordan measurable - 3 different ways","Let $D$ be a bounded set and $C$ a rectangular cuboid with $D\subset C$ . Let $P=\{C_i|i\in I\}$ be a partition of $C$ .
In our script $D$ is Jordan-measurable if: $D$ is Jordan-measurable  if and only if the indicator function $\chi_D$ is integrable on $C$ .
Then the Volume of $D$ is given by $F(D)=\int \limits_{C}^{}\chi_D$ . Its inner $F_i$ and outer $F_o$ volume are equal, with $F_i(D):=\underset{P}{\text{sup}}\sum \limits_{\underset{i\in I}{C_i\subset D}} F(C_i)$ $F_o(D):=\underset{P}{\text{inf}}\sum \limits_{\underset{i\in I}{C_i\cap D\neq \emptyset}}F(C_i)$ A set $D\subset \mathbb{R}^n$ is a Jordan null set if it is Jordan-measurable and $F(D)=0$ . $D$ is Jordan-measurable if and only if the boundary $\partial D$ is a Jordan null set. Is the unit circle $S=\{(x,y)\in\mathbb{R}^2|x^2+y^2=1\}$ Jordan-measurable? 1)
To calculte $\chi_S$ over a bounded set, one needs to continue the function over a cuboid $C$ with $S\subset C$ .
In our case $C=[-1,1]^2$ ensures that $S\subset C$ . Using the Fubini theorem: $$F(S)=\int \limits_C \chi_S=\int \limits_{[-1,1]\times [-1,1]}^{}\chi_S=\int \limits_{-1}^{1}\int \limits_{-1}^{1}\chi_S \, dy \, dx$$ The condition is that $(x,y)$ is on the unit-circle, so $y=\pm\sqrt{1-x^2}$ . I don't know how to continue? 2)
I didn't want to just write ""no idea"" so here are some thoughts: I know that $S$ has no inner points ( i proved that in another exercise), so I think that $C_i\not \subset S$ for every partition $P=\{C_i|i\in I\}$ of $C$ .
So I'm not sure what $F_i(S)=\underset{P}{\text{sup}}\sum \limits_{\underset{i\in I}{C_i\subset S}} F(C_i)$ even means in this case. A partition with $C_i\cap S\neq \emptyset$ is possible so $F_o(S)=\underset{P}{\text{inf}}\sum \limits_{\underset{i\in I}{C_i\cap S\neq \emptyset}}F(C_i)$ would be a meaningful expression. The boundary of the unit circle is $\partial S=S$ . So I need to use the definition $1)$ or $2)$ .","['multivariable-calculus', 'measure-theory', 'real-analysis']"
4635961,"For odd $k$, $\sum_{j=0}^{N-1}\cos^k(\pi j/N) = 1$. Is there a nicer proof? Is this well known?","In the course of answering this question , I stumbled into the following result: for any integer $N > 1$ and any odd $k$ , $$
\sum_{j=0}^{N-1}\cos^k(\pi j/N) = 1.
$$ My proof, which I suspect is much more complicated than it needed to be, was as follows: \begin{align}
\sum_{j=0}^{N-1}\cos^k\left(\frac{\pi j}{N}\right) &= 
\sum_{j=0}^{N-1} 2^{-k}(\omega^{j} + \omega^{-j})^k
\\ & = 
2^{-k} \sum_{j=0}^{N-1} \sum_{\ell = 0}^k \binom k{\ell}\omega^{(k - 2\ell)j}
\\ & = 
2^{-k}  \sum_{\ell = 0}^k \binom{k}{\ell} \sum_{j=0}^{N-1}\omega^{(k - 2\ell)j}
\\ & = 
2^{-k}   \sum_{\ell = 0}^k \binom{k}{\ell}
\cdot \begin{cases}
\frac {1 - \omega^{(k - 2\ell)N}}{1 - \omega^{(k - 2\ell)}} 
& 2N \nmid (k - 2\ell)\\
N & 2\ell = k
\end{cases}
\\ & = 
2^{-k}   \sum_{\ell = 0}^k \binom{k}{\ell}
\cdot \begin{cases}
\frac {1 - (-1)^{(k - 2\ell)}}{1 - \omega^{(k - 2\ell)}} 
& 2N \nmid (k - 2\ell)\\
N & 2\ell = k
\end{cases}
\\ & = 
2^{-k}   \sum_{\ell = 0}^k \binom{k}{\ell} \frac {1 - (-1)}{1 - \omega^{k - 2\ell}}
\\ & = 
2^{-k} \sum_{\ell = 0}^k \binom{k}{\ell} \frac 2{1 - \omega^{k - 2\ell}}
\\ &= 
2^{-k} \sum_{m = 0}^{(k-1)/2} \binom{k}{m} \left[\frac 2{1 - \omega^{k - 2m}} + \frac 2{1 - \omega^{-(k - 2m)}}\right]
\\ & = 
2^{-k} \sum_{m = 0}^{(k-1)/2} \binom{k}{m} 4\operatorname{Re}\left[\frac 1{1 - \omega^{k - 2m}}\right]
\\ & = 
2^{-k} \sum_{m = 0}^{(k-1)/2} \binom{k}{m} 4\operatorname{Re}\left[\frac {1 - \omega^{-(k - 2m)}}{|1 - \omega^{k - 2m}|^2}\right]
\\ & = 
2^{-k} \sum_{m = 0}^{(k-1)/2} \binom{k}{m} 4\operatorname{Re}\left[\frac {(1 - \cos((k - 2m)\pi/N)) + i\sin((k - 2m)\pi/N)
}{(1 - \cos((k - 2m)\pi/N))^2 + \sin^2((k - 2m)\pi/N)}\right]
\\ & = 
2^{-k} \sum_{m = 0}^{(k-1)/2} \binom{k}{m} 4
\frac{1 - \cos((k - 2m)\pi/N)}{2(1 - \cos((k - 2m)\pi/N))}
\\ & = 
2^{-k} \sum_{m = 0}^{(k-1)/2} 2\binom{k}{m}
 = 
2^{-k} \sum_{m = 0}^{k} \binom{k}{m} = 1
\end{align} Is there a nicer proof? Is this fact well known?","['complex-analysis', 'trigonometry', 'complex-numbers']"
4635964,All quadrangulations on $14$ vertices,I am looking for a list of all quadrangulations on $14$ vertices. Is there a database anywhere for this?,"['graph-theory', 'euclidean-geometry', 'discrete-geometry', 'discrete-mathematics']"
4635966,Initial value problems for Laplace equation,"Usually in the textbooks well-posedness of the boundary value problem is studied for Laplace equation $$-\Delta u=0.$$ Why dont we study the Initial value problems like \begin{eqnarray}
-\Delta u&=&0 \quad \text{ in } \mathbb{R}^2\\
u(x,0)=u_y(x,0)&=&0  \quad  \text{ on } \mathbb{R} 
\end{eqnarray} Clearly, in the one dimensional case, the IVP given by \begin{eqnarray}
-u_{xx}&=&0 \quad \text{ in } \mathbb{R}\\
u(0)=u'(0)&=&0  
\end{eqnarray} is well-posed. Thanks in advance","['analysis', 'partial-differential-equations']"
4635973,What's the standard notation for summing over all subsets of a set?,"I'm reading this book on interpretable AI . In section 8.4 the author uses the following notation for a summation across all subsets of a set: $$ \sum_{S \subseteq \{1, \dots, p\}} \hat f_S(x_S) $$ Is this standard notation? Wouldn't it better to explicitly state: $$ \sum_{S \in P(\{1, \dots, p\})} \hat f_S(x_S) $$ where $P(\dots)$ represents the powerset of whatever's contained within the parentheses. Are these two equivalent, and which one is considered clearest?","['elementary-set-theory', 'summation', 'notation']"
4635980,Does a fiber product of a group $G$ by itself have $G$ as a subgroup?,"Consider a group $G$ and a fiber product of the form $G\times_H G$ . Is it true that such fiber product always have a subgroup isomorphic to $G$ ? I'm tempted to say ""Yes"" because it's true if you consider the extremal cases $H=G$ and $H=\{e\}$ . But I have no idea how to prove it in the general case. Thank you! Edit by Derek Holt : Let me attempt to state the problem more explicitly. Let $G$ and $H$ be groups and let $\phi_1,\phi_2:G \to H$ be surjective homomorphisms. Is it always true that the subgroup $\{ (g_1,g_2) : \phi_1(g_1) = \phi_2(g_2) \}$ of $G \times G$ has a subgroup isomorphic to $G$ ?","['group-theory', 'normal-subgroups', 'fibre-product']"
4636004,ODE: a specific question,"Determine the  equation of the curve for which the $y$ intercept of the normal drawn to a point on the curve is equal to the distance of that point from the origin . My attempt :
Consider an arbitrary point, $(x,y)$ , whose slope is $\frac{dy}{dx} $ .
Thus the slope of the normal is $\frac{-dx}{dy}$ .
Using the $y$ intercept form of a line $$y= \frac{-dx}{dy}x+ \sqrt{x^2 +y^2}$$ Now I have tried solving this using substitutions,( $y=ux$ , and $x=uy$ ), but that didn't work. To use the method of the integrating factor, Unless I'm mistaken, I'll need a subsitution to do that, but I can't seem to find any appropriate substitutions. Thanks for the help. This problem is problem 54, in chapter 1, in the second volume of N.piskunov's differential and integral calculus. There is a solution, but that does absolutely nothing to explain how to solve this The solution they have given $y+\frac{x}{y'}= \sqrt{x^2 +y^2}$ Whence $x^2=C(2y+C)$ Which is what I'm unable to understand TL;DR How did $y+\frac{x}{y'}= \sqrt{x^2 +y^2}$ Result in $x^2=C(2y+C)$","['integration', 'calculus', 'ordinary-differential-equations']"
4636011,How to prove a semigroup with properties $x^3=x$ and $x^2y^2=y^2x^2$ is commutative,"If $S$ is a semigroup such that $$(\forall x,y\in S)\quad x^3=x\quad\text{and}\quad x^2y^2=y^2x^2,$$ prove that $$(\forall x,y\in S)\quad xy=yx.$$ All I did is prove $$x^2y^2=(x^2y^2)^2\quad\text{and}\quad xy^2x=(xy^2x)^2.$$ Proof of $x^2y^2=(x^2y^2)^2$ : From $x^2y^2=y^2x^2,$ we deduce $x^2x^2y^2y^2=x^2y^2x^2y^2=(x^2y^2)^2.$ Taking into account $x^4=x^2,$ the result follows. Proof of $xy^2x=(xy^2x)^2$ : $xy=x^3y^3=xx^2y^2y=xy^2x^2y=(xy^2x)(xy)$ hence $xyyx=(xy^2x)(xy)(yx) =(xy^2x) ^2,$ which was the claim.",['semigroups']
4636012,Imaginary numbers and partial fraction decomposition in integration,"If I have a function whose denominator has only complex roots, could I integrate it and perform partial fraction decomposition by separating the factors? For example, am I allowed to evaluate $$\int\frac{1}{(x+i)(x-i)}dx$$ Or $$\int\frac{1}{(x+2i)(x-2i)}dx$$ By partial fractions (without getting rid of $i$ )?  I don't think I could continue since we are integrating along the $x$ -axis. Edit: I am asking if in general I could integrating with imaginary numbers, not just in this specific example. I was giving a background.","['integration', 'calculus', 'partial-fractions', 'complex-numbers']"
4636019,"$\text{Cov}(\max(X,Y), \max(X, Z)) \leq \text{Var}(X)$","Given three independent random variables $X, Y, Z$ , is it true that $$\text{Cov}(\max(X,Y), \max(X, Z)) \leq C \cdot \text{Var}(X)?$$ I am thinking about the case where the $\text{Var}(Y)$ and $\text{Var}(Z)$ are much larger than $\text{Var}(X)$ , so Cauchy-Schwartz inequality would not be useful here. My gut feeling this should hold because of the independence. I tried a few conditioning. For example, we know $\max(X, Z)\perp Y$ , so if we condition on $Y$ , we have $$\text{Cov}(\max(X,Y), \max(X, Z)) = \mathbb{E}[\text{Cov}_{\mathcal{F}_Y}(\max(X,Y), \max(X, Z))].$$ I also tried conditioning on $X$ , but these did not lead to anything at this moment.","['covariance', 'probability-theory']"
4636046,Show $\mathbb{E}(X)=\frac{1-p}{p}$ if $\mathbb{P}(X=k)=p(1-p)^k$,"This is a discrete math problem, $\mathbb{E}(X)$ is the expected value of $X$ : Let $X$ be a random variable with $P(X=k)=(1-p)^kp$ , $k=0,1,2,3,\ldots$ , $0 \leq p \leq 1$ . Show that $\mathbb{E}(X)=\frac{1-p}{p}$ . I think we're supposed to use generating functions. So far, I have $\mathbb{E}(X)=\sum_{k=0}^{\infty}(k(1-p)^k p)$ = $0+(1-p)p+2(1-p)^2 p+3(1-p)^3 p + \ldots $ .
To try and construct that sequence: $\frac{1}{1-(1-p)}=\frac{1}{p}=1+(1-p)+(1-p)^2+(1-p)^3+(1-p)^4+\ldots$ . The derivative of $\frac{1}{p}$ is $-\frac{1}{p^2}=(1-p)+2(1-p)^2+3(1-p)^3 + \ldots$ , so multiply by $p$ to get $p$ in every term, $-\frac{p}{p^2}=-\frac{1}{p}=(1-p)p+2(1-p)^2 p+3(1-p)^3 p + \ldots$ ,
but that would mean $\mathbb{E}(X)=-\frac{1}{p}$ , so I must have made a mistake somewhere. I think maybe the last step where I multiplied by $p$ to multiply every term by $p$ , am I allowed to do that if $p$ isn't a constant?","['expected-value', 'discrete-mathematics', 'generating-functions', 'probability', 'random-variables']"
4636071,Question regarding the equivalence of two relations in a finite group given a subgroup,"Let $(G, \cdot)$ be a group and $H$ a finite subgroup of $G$ (i.e. $H \leq G, \lvert H \rvert = n \in \mathbb{N}^*)$ . Prove the following two relations are equivalent ( $e$ is the identity element): $\forall x, y \in G-H, x \neq y \implies xy \neq yx;$ $(H, \cdot)$ is abelian, $\lvert G \rvert=2\lvert H \rvert, |Z(G)| = 1;$ I first assumed 2) then proved 1). $$\begin{align*}
x \in G-H &\implies xh \in G-H, \forall h \in H.\\
 xh_1=xh_2 &\implies h_1=h_2, \forall h_1, h_2 \in H.\\\
 |G-H|=|H| &\implies G-H= \{ xh \mid h \in H \}
\end{align*}$$ Now we have $$\begin{align*}
(xh_1)(xh_2)=(xh_2)(xh_1) &\implies h_2^{-1}h_1xh_2h_1^{-1}=e\\ &\implies (h_2^{-1}h_1)x(h_2^{-1}h_1)^{-1}=e.
\end{align*}$$ $(h_2^{-1}h_1)^{-1}=h_1^{-1}h_2=h_2h_1^{-1}$ because $(H, \cdot)$ is abelian. $gxg^{-1}=e$ has one solution, namely $x=e$ , when $g \in G$ . I did not use the fact that $Z(G)$ is trivial here and I have no idea how to prove 2) assuming 1). Is the question wrong or did I do a mistake?","['abelian-groups', 'group-theory', 'abstract-algebra', 'finite-groups']"
4636076,Plotting a Spiked Sphere,"My goal is to plot a 3D spiked sphere similar to I would like to realise this hypersurface in $\mathbb{R}^3$ as $$\{f(z)z : z \in S^2\},$$ where $f \in C^\infty(S^2)$ is a suitable smooth radial function on the sphere $S^2$ . Has someone an idea how to do this? Of course one can do such spikes individually, but this gets quite messy. I tried something similar to here , but this does not really work. The spikes do not have to be as regular as in the picture above. Some randomness of sizes would be nice as well as the location. Update: Thanks to the nice suggestion of @achillehui, I could generate the following plot","['spheres', 'geometry']"
4636083,Is there a subgroup of the general linear group isomorphic to the general linear group?,"Let $\mathbb{V}$ be a finite-dimensional vector space over some field $K$ . (Let us consider the case $K$ is characteristic 0 and the dimension of V is greater than one ) Is there a proper subgroup of $GL( \mathbb{V})$ isomorphic to $GL( \mathbb{V})$ ? Also, the same question for $SL( \mathbb{V})$ . If you do not know the answer, please give any idea/reference on approaching to the problem. My intuition is the answer is no, but I could not show it.","['group-theory', 'linear-algebra', 'infinite-groups']"
4636159,How is it the Kullback-Leibler divergence is always non-negative but differential entropy can be positive or negative?,"According to wikipedia , we have $$
 D_{KL}(f ||g ) \geq 0
$$ always, but if $f$ is the pdf of a random variable $X$ and $g$ is the density of the un-normalized Lebesgue measure i.e. the constant function $1$ , then $$
D_{KL}(f ||g ) = \int f \log(f/g) = \int f\log f = -h(X),
$$ the negative of the differential entropy. Many distributions however have positive differential entropy (as shown here ). So this means the left-hand side can take negative values. What's going on here?","['measure-theory', 'information-theory']"
4636179,How to define linearization of a dynamical system on a manifold with affine connection?,"In Euclidean space, if I have a smooth dynamical system $\dot{x}=F(x)$ , it's linearization about a solution $x(t)$ is $\dot{v}(t) = DF(x(t))v(t)$ , where $DF(x)$ is the Jacobian matrix of $F$ at $x$ . I am curious on how linearization works on smooth manifolds. Suppose $(M,\nabla)$ is a smooth manifold with affine connection $\nabla$ and $\dot{p}=F(p)$ describes a dynamical system on $M$ , where $F:M \to TM$ is a smooth vector field. What exactly is the ""right way"" to define the linearization of the system about a solution $p(t)$ ? By right, I guess the most intrinsic-to-the-manifold way. In the Euclidean set up, recall $DF(x)v$ can be interpreted as the directional derivative of $F$ along $v$ at $x$ . This leads me to say that the linearization of $\dot{p}=F(p)$ about the solution $p(t)$ is $\dot{v}(t) = \nabla_{v(t)} F|_{p(t)}$ . However, this seems a bit odd.  Under those dynamics (if they are even well-defined) $v(t) \in T_{p(t)}M$ . So, $v(t)$ is a tangent vector constantly varying through the tangent spaces. Is this the right way to do it? Is this even well-defined? I guess if $(E_i)$ is a local frame and $(\Gamma_{ij}^k)$ are the Christoffel symbols, we can write locally $\dot{v}^k = v(F^k)+v^iF^j(p)\Gamma_{ij}^k(p)$ .","['dynamical-systems', 'linearization', 'smooth-manifolds', 'differential-geometry']"
4636223,a fun grid combinatorics puzzle that has been bothering me,"Suppose that we fill out the grid with numbers given only three rules: each box gets its own distinct number the numbers that we are allowed to use are $1-8$ a box that contains a smaller number points to a box that contains a larger number How many ways can we fill out our grid? And if that question is solved, can we solve the same problem for a $10$ -box grid? What about a $n$ -box grid?",['combinatorics']
4636322,Relationship between periodic groups and cyclic groups,Suppose $G$ is a finite abelian group with period equal to $|G|$ . Prove $G$ is cyclic. We define the period of $G$ as the minimum $n \in \mathbb{Z}^{+}$ with $n\cdot g = 0$ for all $g \in G$ . So far I've tried to prove that $G$ is not isomorphic to any direct sum of finite abelian groups except for $\mathbb{Z}_{n}$ by means of The Fundamental Theorem of Finite Abelian Groups.,"['cyclic-groups', 'finite-groups', 'group-theory', 'abstract-algebra', 'abelian-groups']"
4636347,"Calculus Made Easy, Chapter 21, Exercise 14","This chapter in Thompson's book includes 'Dodges, Pitfalls and Triumphs' in using integration techniques -mainly integration by parts and substitution. I have been doing de exercises (boy, is integration tough...) and am currently stuck with number 14: $\displaystyle\int\frac{x}{\sqrt{a^2-b^2x^2}} dx$ Any clue on how to start tackling this beast, people? I've tried integration by parts, splitting into partial fractions and rationalizing the denominator. In theory, it can't use more fancy techniques...","['integration', 'calculus']"
4636362,Linear Sweep of a 2D Polygon,"Suppose we have a 2D simple polygon (no self-intersection) on the $XY$ plane defined by $n$ vertices and a 2D vector $V=(A,B)$ .
Is there an algorithm to detect if a generic point $P=(x,y)$ on the plane belongs to the area that is covered by the polygon when it ""slides"" along the line segment from $A$ to $B$ ?","['area', 'geometry', 'polygons', 'plane-geometry', 'algorithms']"
4636396,Can we bound the L1 distance between densities by Wasserstein distance of measures,"Let $\mu_1$ and $\mu_2$ be two probability measures over a closed interval $[a, b]$ , with respective density functions $\phi_1$ and $\phi_2$ . Is there a way to bound the $L^1$ distance of the densities by the Wasserstein distance of the probability measures?
More specifically; does there exist a $C > 0$ such that $$ \int_a^b | \phi_1(x) - \phi_2(x) | dx \leq C \cdot W_1(\mu_1, \mu_2) $$ holds? Apparently, we can bound the distance in the moments but this does not necessarily help us. I have the feeling that there may be a way to use the Kantorovich-Rubinstein duality theorem, however, I do not see how exactly.","['measure-theory', 'lp-spaces', 'wasserstein', 'probability-theory']"
4636435,Is uniform convergence a necessary condition for interchangeability of limits,"I am aware of the standard result (namely, please see Terence Tao's Analysis II, Page 54, Proposition 3.3.3 - Interchange of limits & uniform limits ) that uniform convergence implies the interchangeability of limits, however I am wondering if the converse holds. i.e. If we can interchange the limits of a function, does it imply the uniform convergence of this function please? I don’t think it holds but I am struggling to construct a counterexample. Many thanks in advance!","['uniform-convergence', 'real-analysis']"
4636471,Intuition regarding Lagrange multipliers with many constraints,"Studying for my finals in calculus 3, returning to the proof of Lagrange multipliers with multiple constraints, I'm having a hard time getting any form of intuition about why this is the case - why does this give us the extrema points. While looking at one constraint, I understand the geometric interpretation of the gradient vectors being linearly dependent. And I'm able to understand that each constant defines a surface one dimension lower since we are looking at the group defined by intersecting all: $\forall i\in [n]: g_i(x)=0$ If my function $f$ is linearly dependent on all other constraining functions, what does this mean visually(what does it mean visually that all other constraints are independent and $f$ is dependent on all of them)? Why is it necessary for all gradients of $g_i$ to be linearly independent? (or is this just the version of the proof I was shown, and a stronger argument exists? I'll add that we proved the Theorem using the Open Mapping Theorem). Additions I can see why (2) is required since we want to think of the simplified version with one constraint, which is only possible when the intersection defines some curve. I still am unsure if this is required since we know we can find local extrema on open groups and are not limited to a single curve. Or is the whole concept trying to avoid this method and use the dependency of gradients to optimize?","['multivariable-calculus', 'derivatives', 'lagrange-multiplier', 'intuition']"
4636479,To prove given elliptic curve is Jacobi variety of given genus $1$ curve,"Let $E$ be an elliptic curve $X^3+Y^3+60Z^3=0$ and $C$ be a genus $1$ curve given by $C:3X^3+4Y^3+5Z^3=0$ . I want to prove elliptic curve $E$ is Jacobi variety of $C$ .
What I should to prove is that $Pic^0(C) \cong E$ as a group.
But I cannot come up with explicit isomorphism. Cassel's lectures, chapter $20$ deal with this as an exrcise, but does not follow this way. Maybe $C$ is $E$ torsor ( $E$ acts simply transitively on $C$ ) has something to do with the proof of isomorphism?","['arithmetic-geometry', 'algebraic-geometry', 'elliptic-curves', 'abelian-varieties']"
4636494,Proving a Ring Commutative,"Let $(A, +, \cdot)$ be a ring with the following properties a) $1 + 1=0$ ; b) $x^2=0$ for any noninvertible $x$ ; c) $\forall x \in A$ that are invertible, $\exists x' \in Z(A)$ such that $x^2=(x')^2$ . Prove that $A$ is commutative. $1+1=0 \Rightarrow a+a=0 \Rightarrow a=-a\forall a \in A$ Let $a$ and $b$ be two elements in $A$ such that at least one of them is not invertible. Then $ab$ is not invertible, so $(ab)^2=a^2b^2$ . Now let $x$ and $y$ be two invertible elements in $A$ . $xy$ is invertible so there exists $a \in Z(A), (xy)^2=a \Rightarrow x(yx)y=a^2 \Rightarrow yx=x^{-1}a^2y^{-1}$ . Because $a^2$ is in $Z(A)$ it commutes with every element in $A$ , therefore $yx =x^{-1}y^{-1}a^2\Rightarrow (yx)^2=a^2=(xy)^2$ . I feel like $f:A \to A, f(x)=x^2$ should be a homomorphism, but I cannot seem to prove it. I know I should use the fact that $1+1=0$ , but I could not find a meaningful way to use it.","['ring-theory', 'group-theory', 'abstract-algebra']"
4636533,Probabilistic coin weighing [duplicate],"This question already has an answer here : choosing two sets that intersect every given subset in the same amount of points (1 answer) Closed last year . Let $S_1, \ldots, S_k$ be subsets of $\{1, \ldots, n\}$ with $k \leq 1.99 \frac{n}{\log_2(n)}$ , prove that there are two distinct subsets $X,Y$ of $\{1, \ldots, n\}$ , such that for all $1 \leq i \leq k$ we have $|X \cap S_i | = | Y \cap S_i | $ . I am sure this is supposed to be done with some concentration argument, but I have no idea what the right probability space to look at is. I've so far tried to pick X and Y independently with the same distribution by including every number in the set (independently) with some probability $p_j$ . This would then mean that the random variable $|X \cap S_i | - | Y \cap S_i | $ has mean zero and that I could use some concentration inequality to then get a union bound. To make sure that the sets $X$ and $Y$ also are distinct, I need to pick the parameters $p_j$ close enough to $1/2$ . The parameters $p_j$ should also somehow depend on the size of the smallest set covering the element $j$ . But the analysis got too messy and I doubt that this approach is even feasible? Does anybody know what the right space to look at is? Edit: $n$ is supposed to be taken sufficiently large as Mike earnest pointed out.","['concentration-of-measure', 'probabilistic-method', 'combinatorics', 'discrete-mathematics', 'probability']"
4636589,Multiple answers for the same limit expression?,"So I was trying to find the limit of the following expression. $$\lim_{x\to 0} \frac{\tan x - \sin x}{\sin^3 x}$$ When using the L'Hospital's rule I got the answer $\frac {1}{2}$ . My steps: $$\lim_{x\to 0} \frac{\tan x - \sin x}{\sin^3 x} $$ $$=\lim_{x\to 0} \frac{\sec^2 x - \cos x}{3\sin^2 x \cos x}$$ $$=\lim_{x\to 0} \frac{2 \sec^2 x \tan x + \sin x}{6\sin x \cos^2 x}$$ $$=\lim_{x\to 0} \left(\frac{2 \sec^2 x \tan x}{6\sin x \cos^2 x}+\frac{\sin x}{6\sin x \cos^2 x}\right)$$ $$=\lim_{x\to 0} \left(\frac{1}{3\cos^5 x}+\frac{1}{6\cos^2 x}\right)$$ $$=\frac{1}{3}+\frac{1}{6}$$ $$=\frac{1}{2}$$ Edit: My steps are incorrect from the 3rd line onward as pointed out by @Fishbane in the comments Just to check my answer I substituted $x = 0.000000001$ and so on, on my calculator just to be sure, but I got the result to be $0$ . Believing it to be some kind of error I used WolframAlpha's calculator as well and got the same result, $0$ . What is the reason for this difference?","['limits', 'calculus']"
4636595,"Given a convex quadrilateral $ABCD$, find the missing angle.","The problem is as the title suggests, in the figure given below, solve for the missing angle labeled ""?"". This problem is from my friend @geometri_hayattir on Instagram. I have solved the problem, and I will share my approach as an answer below. Since the solution of this problem was not posted, I'm unsure if my approach and answer are correct. Please let me know if there are any issues in my method, and please share your own answers and approaches!","['contest-math', 'euclidean-geometry', 'geometry', 'solution-verification', 'trigonometry']"
4636633,Show that $f(x) = \sum_{k=0}^{\infty}{\frac{\sin^2(kx)}{1+k^2 x^2}}$ uniformly converges.,"I want to show that $f(x) = \sum_{k=0}^{\infty}{\frac{\sin^2(kx)}{1+k^2 x^2}}$ uniformly converges for $|x| \geq \delta$ for any given $\delta > 0$ . I don't know how to use the M-test here, since it seems each term is constantly upper bounded by 0.359, regardless of the value of $k$ . I tried performing the Cauchy Criterion, but I am having a hard time showing that an $N$ exists for all $|x| \geq \delta$ . Any advice or hints would be great! For context, I'm a first year undergraduate maths student.","['real-numbers', 'uniform-convergence', 'analysis', 'real-analysis']"
4636638,Evaluating $\int^\infty_0 \frac{\tanh(x)}{x\cosh(2x)}dx$,"I am trying to evaluate $\int^\infty_0 \frac{\tanh(x)}{x\cosh(2x)}dx$ by Feynman's technique. Let $I(b)=\int^\infty_0\frac{\tanh(bx)}{x\cosh(2x)}dx$ , then $I'(b)=\int^\infty_0 sech^2(bx)sech(2x)dx$ . However, I am unable to find out the integral in terms of b. Or should I use another approach? Thanks for help.",['integration']
4636655,When does coordinate-wise differentiability imply $\ell^{p}$ differentiability?,"For $p \in [1,\infty]$ , consider the sequence space $\ell^{p}(\mathbb{N})$ consisting of real sequences $x = (x_{i})_{i =1}^{\infty}$ with norm $\lVert x \rVert_{p} = \left(\sum_{i=1}^{\infty}|x_{i}|^{p} \right)^{1/p}$ for $p < \infty$ and $\lVert x \rVert_{\infty} = \sup_{i}|x_{i}|$ . Let $A$ be a bounded linear operator on $\ell^{p}(\mathbb{N})$ for some $p$ . Let $u: [0,\infty) \to \ell^{p}(\mathbb{N})$ , and write $u(t) = (u_{1}(t), u_{2}(t),\dots)$ . Suppose that each coordinate function $u_{i}: [0,\infty) \to \mathbb{R}$ is differentiable on $(0, \infty)$ , right-differentiable at $0$ , and satisfies $$u_{i}'(t) = (Au(t))_{i}$$ for all $t \geq 0$ . My question: is it the case that $$\lim_{h \to 0}\left \lVert \frac{u(t+h) - u(t)}{h} - Au(t) \right \rVert_{p} = 0$$ for all $t$ ? If not, is there a reasonable counterexample?","['lp-spaces', 'functional-analysis', 'ordinary-differential-equations', 'real-analysis']"
4636662,Evaluate $\int_0^\pi \left(\frac{\sin{2x}\sin{3x}\sin{5x}\sin{30x}}{\sin{x}\sin{6x}\sin{10x}\sin{15x}}\right)^2 dx$ (from MIT Integration Bee 2023),"This is from the final round of MIT Integration Bee 2023. $$\int_0^\pi \left(\frac{\sin({2x}) \sin({3x})\sin({5x})\sin({30x})}{\sin({x})\sin({6x})\sin({10x})\sin({15x})}\right)^2 dx$$ The given answer is $7\pi$ . I found a way to do it using contour integrals (see answer below), but this is not a calculation I can finish within 4 minutes (the time limit in the competition). I am still looking for other elegant methods, possibly without using contour integrals.","['integration', 'definite-integrals']"
4636690,Show that $XY=0$ or $YX=0$,"We have $X,Y$ $(2×2)$ matrices with complex entries and $X=A^{2}-B^{2}$ and $Y=AB-BA$ . We know that $\det(X)=\det(Y)=0$ . Show that $XY=0$ or $YX=0$ . I see that Trace of $Y$ is $0$ and $\det(Y)$ is also $0$ so by $C-H$ , $Y^{2}=0$ . I also saw how we can write $(X+Y)$ as $(A-B)(A+B)$ but nothing more.","['matrices', 'cayley-hamilton', 'determinant']"
4636732,Prove $((P \cup Q) \cap (P \to R) \cap (Q \to R)) \to R $ is a Tautology,"$[(P \cup Q) \cap (P \rightarrow R) \cap (\neg Q \cup R)] \rightarrow R $ Logical Equivalences. $[(P \cup Q) \cap (\neg P \cup R) \cap (\neg Q \cup R)] \rightarrow R$ Logical Equivalences. $\neg[(P \cup Q) \cap (\neg P \cup R) \cap (\neg Q \cup R)] \cup R$ Logical Equivalences. $[\neg(P \cup Q) \cup \neg (\neg P \cup R) \cup \neg (\neg Q \cup R)] \cup R$ De Morgan’s Laws. $(\neg P \cap \neg Q) \cup (P \cap \neg R) \cup (Q \cap \neg R) \cup R$ De Morgan’s Laws. I'm thinking I can use the distributive property here, but I don't know how I would set that up. $(\neg P \cup P) \cap (\neg P \cup ¬R) \cap (\neg Q \cup P) \cap (\neg Q \cup \neg R)$ $\leftarrow$ That is as far as I have gotten as I am unsure if I continue to distribute the letters throughout the entire thing or not like this instead: $(\neg P \cup P \cup Q \cup R) \cap (\neg P \cup \neg R \cup \neg R \cup R) \cap (\neg Q \cup P \cup Q \cup R) \cap (\neg Q \cup \neg R \cup \neg R \cup R).$ Now that I look at it, I think the second way looks correct, but I'm still unsure.",['discrete-mathematics']
4636791,How can a board/card game be considered to be only moderately based on chance? [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed last year . Improve this question I'm not sure if this is the right forum to ask this, but I guess it's related to statistics...
My intuition is that, if a game has any element where luck is involved (e.g. rolling a dice or dealing shuffled cards), then that ultimately renders the game being entirely based on luck/chance. And yet, different games have different 'chance' ratings. For example, Monopoly's chance rating is high while Catan's rating is low/moderate.
I don't know if my question makes sense but hopefully someone understands what I'm trying to get at.","['statistics', 'card-games']"
4636870,Help With Geometric Interpretation,"Let $\mathbf{x} \in \mathbb{R}^3$ and let $\mathbf{x}=\mathbf{y}+\mathbf{z}$ , where $\mathbf{y}^\mathrm{T} \mathbf{z} = 0$ . Also, let $\hat{\mathbf{x}}$ be the unit vector in the direction of $\mathbf{x}$ . I am trying to wrap my head around the geometric interpretation of the following linear mapping $\mathbf{A} \in \mathbb{R}^{3\times 3}$ but have not been successful: $$
\mathbf{A} = 2\Vert \mathbf{y} \Vert^2 \mathbf{I} - \Vert \mathbf{x} \Vert^2 \left( \mathbf{I} - \hat{\mathbf{x}} \hat{\mathbf{x}}^\mathrm{T} \right)
$$ I have messed around with writing this every which way I can think of, but nothing stands out. Since $\Vert \mathbf{x} \Vert ^2 = \Vert \mathbf{y} \Vert ^2 + \Vert \mathbf{z} \Vert ^2$ and $\left( \mathbf{I} - \hat{\mathbf{x}} \hat{\mathbf{x}}^\mathrm{T} \right)$ is the projection onto the plane with normal vector $\hat{\mathbf{x}}$ , it seems like the above should have an intuitive geometric interpretation. Any help sussing one out is greatly appreciated.","['linear-algebra', 'geometry']"
4636898,Finding $\lim_{x\to0}\tan(x)^{1/x}$,"I'm not sure how to evaluate this limit. $$ \lim_{x\to0^{+}} \tan(x)^{\frac{1}{x}} $$ I've attempted to use L'Hopital's rule, but I'm not sure  if the indeterminate form (which I'll show below) from which I differentiate the numerator and denominator, is actually a true indeterminate form. Here is my process. $$ \lim_{x\to0^{+}} \tan(x)^{\frac{1}{x}} $$ $$ \lim_{x\to0^{+}} e^{\ln(\tan(x)^{\frac{1}{x}})} $$ $$ \lim_{x\to0^{+}} e^{\frac{\ln(\tan(x))}{x}} $$ $$ \exp \lim_{x\to0^{+}} \frac{\ln(\tan(x))}{x} $$ From here, direct substitution yields $ -\infty $ on top and 0 on the bottom, so what I did in order to get it into indeterminate form (as previously stated, what I do here is somewhat odd so I'm not sure if this is correct): $$ \exp \lim_{x\to0^{+}} \frac{\ln(\tan(x))}{\frac{1}{\frac{1}{x}}} $$ At this point, direct substitution gives $ -\infty $ on top, and, on the bottom as soon as 0 is plugged in we get a $ \frac{1}{0} $ . Now I know that division by zero is undefined, but the reason why I assumed that it was safe to treat it as infinity in the bottom was because, first of all, as $\frac{1}{x}$ approaches infinity it approaches $ 0 $ , and additionally I've seen a similar technique of turning $ ux $ into $ \frac{u}{\frac{1}{x}} $ and using that to our advantage in limits like $ \lim_{x\to0^{+}} x^{x} $ . From this point on: $$ \exp \lim_{x\to0^{+}} \frac{\ln(\tan(x))}{\frac{1}{\frac{1}{x}}} $$ We apply L'Hopital's Rule to yield $$ \exp \lim_{x\to0^{+}} \frac{\frac{\sec^{2}(x)}{\tan(x)}}{\frac{-1}{x^{2}}}$$ $$ \exp \lim_{x\to0^{+}} \frac{-x^{2}}{\cos(x)\sin(x)} $$ And, once again, from here I got a $ \frac{0}{0} $ indeterminate form, and this I L'Hopitaled yet another time. $$ \exp \lim_{x\to0^{+}} \frac{-2x}{\cos^{2}(x)-\sin^{2}(x)} $$ Finally, direct substitution gives $ \exp(0) $ , so $ 1 $ .
Now, the issue is, that according to almost every calculator like desmos and Wolfram Alpha , it is quite clear that the limit is actually $ 0 $ , not what I have gotten. I apologize for any blatant errors, over complications, and silly mistakes in my math and post. This is my first question on the Mathematics Stack Exchange.
Could somebody please point out where I have made my error and how the limit is properly evaluated? Thank You",['limits']
4636935,"What is the probability that the first ball drawn was black, given the event $X_3 \leq 5$","Im trying to solve the following question: There is a urn with 1 black ball and 1 red ball. A ball is drawn at random
from the urn, it is placed back in the urn along with 2 more balls with the
same color as the ball that was drawn. Denote the random variable Xi to be
the number of black balls after the i-th draw, i = 1, 2, . . .. Note that $X_i$ is
the random variable for number of black balls in the urn including the two
new balls added after the i-th draw. What is the probability that the first ball drawn was black, given the event $X_3 \leq 5$ ? This is what I have so far: $$P(X_3=1 | X_3\leq 5)=\frac{P(X_3=1 \cap X_3\leq 5)}{P(X_3\leq 5)}=\frac{P(X_3=1)}{P(X_3=1)+P(X_3=3)+P(X_3=5)}$$ Hence, $$\frac{\frac{5}{16}}{\frac{5}{16}+\frac{3}{16}+\frac{3}{16}}$$ Correct?","['solution-verification', 'combinatorics', 'probability']"
4636947,Cantor ternary function [duplicate],"This question already has an answer here : why is the Cantor-Lebesgue function increasing (1 answer) Closed last year . For $x \in [0,1]$ , there is a ternary expansion $$
x = \sum_{n=1}^{\infty} \frac{x_n}{3^n} \;, x_n \in \{0,1,2\} .
$$ Let $N_x=\infty$ if none of the $x_n$ are $1$ , otherwise
let $N_x$ be the smallest value $n$ s.t. $x_n=1$ .
Define the Cantor ternary function $f:[0,1] \longrightarrow \mathbb{R}$ by $$
f(x)=\frac{1}{2^{N_x}} + \sum_{n=1}^{N_x-1} \frac{x_n}{2^{n+1}} \;.
$$ Show that $f$ is an increasing function. My attempt:
Let $$
x=\sum_{n=1}^{\infty}\frac{x_n}{3^n} < 
y=\sum_{n=1}^{\infty}\frac{y_n}{3^n} \; ,
$$ let $N=\min\{n \in \mathbb{N} \mid x_n \neq y_n \}$ . Step $1$ : We claim $x_N < y_N$ . $$
\begin{aligned}
    0 > x-y &= \sum_{n=N}^{\infty} \frac{x_n-y_n}{3^n} \\
    &\geq \frac{x_N - y_N}{3^N} - 
    \sum_{n=N+1}^{\infty} \frac{2}{3^n} \\
    &= \frac{x_N - y_N}{3^N} - \frac{1}{3^N} \; ,
\end{aligned}
$$ so $x_N - y_N < 1$ , since $x_N, y_N \in \{0,1,2\}$ ,
and $x_N \neq y_N$ , then $x_N - y_N < 0$ . Step $2$ : We claim $$
\sum_{n=1}^{\infty} \frac{x_n-y_n}{2^{n+1}} \leq 0 \; .
$$ $$
\begin{aligned}
    \sum_{n=1}^{\infty} \frac{x_n-y_n}{2^{n+1}} &=
    \sum_{n=N}^{\infty} \frac{x_n-y_n}{2^{n+1}} \\
    &\leq \frac{-1}{2^{N+1}} + 
    \sum_{n=N+1}^{\infty} \frac{2}{2^{n+1}} \\
    &= 0 \; .
\end{aligned}
$$ Step $3$ : We claim $f(x) \leq f(y)$ .
Then I got stuck here.","['measure-theory', 'cantor-set']"
4636987,How to prove that $\sum_{n=0}^{\infty}(-1)^{n}\frac{\Gamma(n+\frac{3}{4})}{\Gamma(n+\frac{5}{4})}=\frac{\sqrt{\pi}}{2}$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last year . Improve this question How can I prove that: $$\sum_{n=0}^{\infty}(-1)^{n}\frac{\Gamma(n+\frac{3}{4})}{\Gamma(n+\frac{5}{4})}=\frac{\sqrt{\pi}}{2}$$ The closest I've gotten is that if I call the sum S, then using the definition of the Beta function: $$\sqrt{\pi}S=\intop_0^1\frac{x^{-\frac{1}{4}}}{(1+x)\sqrt{1-x}}dx$$ But I don't really know where to go from here.","['gamma-function', 'calculus', 'sequences-and-series']"
4637001,Why does partial derivative of the joint equation of two straight lines give another two straight lines belonging to the same family?,"If we are to find the point of intersection of the lines whose joint equation is $2x^2+3xy-2y^2-9x+7y-5=0$ then we can EITHER consider it as a quadratic in $x$ and then apply quadratic formula and get the equations of two straight lines and then their point of intersection. OR, we can differentiate the given equation first w.r.t $x$ and then w.r.t. $y$ and obtain two equations and then their point of intersection. We get the same point both ways. While the equations obtained in both ways are different. Looks like, partial derivative is giving the equations from the same family as the point of intersection is same. Why is this so? What exactly is partial derivative doing here?","['contest-math', 'coordinate-systems', 'geometry', 'partial-derivative', 'derivatives']"
4637040,Proof that $n$ points on a plane cannot be connected with straight lines under a certain angle treshold,"I have $n$ points on a two-dimensional coordinate plane. My goal is finding a path that visits every point once, with straight lines interconnection two points. Additionally, the angle of a line through the two prior points to a point to be connected has to be less than a certain value, say 90°. (See in the attached image) Is there any way to prove, that for a given complete graph there is no solution connecting all points under that angle threshold if there is one greedy (see below) path that can't connect all nodes? I am searching for a sort-of mathematical proof or disprove to that. In the image, there is a graph with 2 nodes connected already. The third node (or any other unconnected node) cannot be connected with the red line, because $\alpha > 90°$ . Can I prove that there is no path connecting all nodes in this graph and in any other graph, when at least one unfinished tour can be found, that can't visit any other unvisited node? I am happy to edit my question if I forgot sharing any additional information. Thanks in advance. Edit: Also, the connection between points follows a greedy principle where from each point the nearest one (that doesn't exceed the angle threshold) will be picked next. Edit 2: Is there a tour for greedy pathfinding and an allowed angle of $\alpha \leq 90°$ (instead of $\alpha < 90°$ ), so that right angles will work as well?","['graph-theory', 'geometry', 'hamiltonian-path']"
4637065,Reconciling different expressions for Riemann curvature tensor,"[Note: This has been crossposted to Physics SE, but I haven't found a thourough explanation there so far, so I'm posted the question here as well] I'm using Einstein's summation convention throughout. Also since I'm new to this subject, I'd be really grateful if any assertions can be shown through explicit calculations so that I can follow along and learn in the process. I'm reading Carroll's GR notes and I'm having trouble deciphering a particular expression for the Riemann curvature tensor. The coordinate-free definition is (eq. 3.71 in Carroll's notes): $$R(X,Y)Z=\nabla_X\nabla_YZ-\nabla_Y\nabla_XZ-\nabla_{[X,Y]}Z\tag{3.71}$$ Some more background on the first equation, based on my reading of ""Semi-Riemannian Geometry: The Mathematical Language of General Relativity"" by Newman: $R$ is a map from $\mathfrak{X}(M)^3$ to $\mathfrak{X}(M)$ such that (3.71) holds. Newman's book doesn't really treat $R(X,Y)$ as a separate object (as far as I've read). $R$ is just treated as a map of 3 vector fields and with the weird notation $R(X,Y)Z$ instead of $R(X,Y,Z)$ (again, as far as I've read). Then there is a theorem showing that $R$ is multilinear in all its arguments and anti-symmetric in its first 2 arguments. And then the following assertion: Let $(M,\nabla)$ be a smooth manifold with a connection, and let $(U,(x^i))$ be a chart on $M$ . Then in local coordinates, $R(\partial/\partial x^{\mu},\partial/\partial x^{\nu})\partial/\partial x^{\sigma}$ can be expressed as: $$R\bigg(\frac{\partial}{\partial x^{\mu}},\frac{\partial}{\partial x^{\nu}}\bigg)\frac{\partial}{\partial x^{\sigma}}=R_{\ \ \sigma\mu\nu}^{\rho}\frac{\partial}{\partial x^{\rho}}$$ Based on the above, if $V\in\mathfrak{X}(M)$ , then $$R\bigg(\frac{\partial}{\partial x^{\mu}},\frac{\partial}{\partial x^{\nu}}\bigg)V=R\bigg(\frac{\partial}{\partial x^{\mu}},\frac{\partial}{\partial x^{\nu}}\bigg)\bigg(V^{\sigma}\frac{\partial}{\partial x^{\sigma}}\bigg)
\\=V^{\sigma}R\bigg(\frac{\partial}{\partial x^{\mu}},\frac{\partial}{\partial x^{\nu}}\bigg)\frac{\partial}{\partial x^{\sigma}}=V^{\sigma}R_{\ \ \sigma\mu\nu}^{\eta}\frac{\partial}{\partial x^{\eta}}$$ where the second equality holds due to multilinearity of $R$ .
Now if I act this on the $x^{\rho}$ coordinate function, I get $$\bigg(R\bigg(\frac{\partial}{\partial x^{\mu}},\frac{\partial}{\partial x^{\nu}}\bigg)V\bigg)(x^{\rho})\equiv\bigg(R\bigg(\frac{\partial}{\partial x^{\mu}},\frac{\partial}{\partial x^{\nu}}\bigg)V\bigg)^{\rho}=V^{\sigma}R_{\ \ \sigma\mu\nu}^{\eta}\frac{\partial}{\partial x^{\eta}}(x^{\rho})
\\=V^{\sigma}R_{\ \ \sigma\mu\nu}^{\eta}\frac{\partial x^{\rho}}{\partial x^{\eta}}=R_{\ \ \sigma\mu\nu}^{\rho}V^{\sigma}\tag{1}$$ So far, so good. Important note: I'm using the notation $\nabla_{\mu}\equiv\nabla_{\frac{\partial}{\partial x^{\mu}}}$ , where $\partial/\partial x^{\mu}$ is the $\mu$ -th basis vector field on $(U,(x^i))$ . Now in eq. (3.71), I can replace $X,Y$ by fields $\partial_{\mu},\partial_{\nu}$ respectively and $Z$ by $V$ , then I can get the local coordinates for both sides by acting them on coordinate function $x^{\rho}$ : $$(R(\partial_{\mu},\partial_{\nu})V)(x^{\rho})\equiv(R(\partial_{\mu},\partial_{\nu})V)^{\rho}=([\nabla_{\mu},\nabla_{\nu}]V)(x^{\rho})-(\nabla_{[\partial_{\mu},\partial_{\nu}]}V)(x^{\rho})
\\=([\nabla_{\mu},\nabla_{\nu}]V)(x^{\rho})\equiv([\nabla_{\mu},\nabla_{\nu}]V)^{\rho}\tag{2}$$ Comparing (1) and (2), I get $$R_{\ \ \sigma\mu\nu}^{\rho}V^{\sigma}=([\nabla_{\mu},\nabla_{\nu}]V)^{\rho}\tag{3}$$ The above equation completely follows from (3.71). Now in Carroll's notes, an index-based expression for the Riemann curvature tensor is also given (eq. 3.66): $$R^{\rho}_{\ \ \sigma\mu\nu}V^{\sigma}=[\nabla_{\mu},\nabla_{\nu}]V^{\rho}+T_{\mu\nu}^{\ \ \ \ \lambda}\nabla_{\lambda}V^{\rho}\tag{3.66}$$ So far torsion-free assumption hasn't been made anywhere . To reconcile (3.71) with (3.66), I have to show (comparing RHS of (3) and (3.66)): $$([\nabla_{\mu},\nabla_{\nu}]V)^{\rho}=[\nabla_{\mu},\nabla_{\nu}]V^{\rho}+T_{\mu\nu}^{\ \ \ \ \lambda}\nabla_{\lambda}V^{\rho}\tag{4}$$ This is where I'm stuck and I really cannot wrap my head around it. How do I go about proving eq. (4)? The first term on the RHS - I can only infer that it's $[\nabla_{\mu},\nabla_{\mu}](V^{\rho})$ . If it were $([\nabla_{\mu},\nabla_{\nu}]V)^{\rho}$ , then it would equal the LHS and the 2nd RHS term would just be zero and meaningless to include - this can't be. But then if it's $[\nabla_{\mu},\nabla_{\mu}](V^{\rho})$ , well $V^{\rho}$ is a $C^{\infty}(U)$ function and this would evaluate to $\partial_{\mu}\partial_{\nu}V^{\rho}-\partial_{\nu}\partial_{\mu}V^{\rho}=0$ by equality of mixed partial derivatives. I'm not sure where I've gone wrong in the specific approach outlined in this question. I'd appreciate any help or corrections! EDIT : Some calculations I've done after looking at the accepted answer: $$A=\nabla_X(\nabla_YZ)=\nabla_X(\nabla_{Y^b\partial_b}Z)=\nabla_X(Y^b\nabla_{\partial_b}Z)$$ $$=X(Y^b)\nabla_{\partial_b}Z+Y^b\nabla_X(\nabla_{\partial_b}Z)=X(Y^b)\nabla_{\partial_b}Z+Y^b\nabla_{X^a\partial_a}(\nabla_{\partial_b}Z)$$ $$=X(Y^b)\nabla_{\partial_b}Z+Y^bX^a\nabla_{\partial_a}(\nabla_{\partial_b}Z)$$ $$\\$$ $$B=\nabla_{\nabla_XY}Z=\nabla_{\nabla_X(Y^b\partial_b)}Z=\nabla_{X(Y^b)\partial_b+Y^b\nabla_X\partial_b}Z$$ $$=\nabla_{X(Y^b)\partial_b}Z+\nabla_{Y^b\nabla_X\partial_b}Z=X(Y_b)\nabla_{\partial_b}Z+Y^b\nabla_{\nabla_X\partial_b}Z$$ $$=X(Y_b)\nabla_{\partial_b}Z+Y^bX^a\nabla_{\nabla_{\partial_a}\partial_b}Z$$ $$\\$$ $$A-B=X^aY^b\nabla_a\nabla_bZ
\\\implies \nabla_{\partial_a}(\nabla_{\partial_b}Z)-\nabla_{\nabla_{\partial_a}\partial_b}Z=\nabla_a\nabla_bZ\tag{5}$$ So now I have to convince myself that eq. (5) is correct.","['curvature', 'riemannian-geometry', 'differential-geometry']"
4637107,Solution of complex differential equation,"Finding solution of differential equation $\displaystyle \frac{xdy-ydx}{ydy-xdx}=\sqrt{\frac{x^2-y^2+1}{x^2-y^2}},$ Where $y=f(x)$ and $f(0)=0$ and $f(1)=1$ I have write $\displaystyle \int \frac{xdy-ydx}{x^2}=-\int \frac{1}{2x^2}(xdx-ydy)\sqrt{\frac{x^2-y^2+1}{x^2-y^2}}$ $\displaystyle \int d\bigg(\frac{y}{x}\bigg)=-\int \frac{1}{x^2}d(x^2-y^2)\sqrt{\frac{x^2-y^2+1}{x^2-y^2}}$ But I did not understand what I do with $x^2$ term in denominator
so that right side become integrable. Please have a look.",['ordinary-differential-equations']
4637145,"Suppose $a$ and $b$ belong to a ring. If $ab$ is a zero divisor, then is $ba$ also a zero divisor?","Suppose $(R,+,\cdot)$ be a ring and there is two elements, $a$ and $b$ are in the ring such that $ab$ is a zero divisor. My attempt has two parts. 1 - if $a$ or $b$ equal to $0$ ( $0$ is the zero element of the ring), then it is obvious that $a.b = 0$ and $b.a = 0$ . then for every $x ∈ R, a.b.x = 0$ so $a.b$ is a right zero divisor. Then $xba = 0$ so $b.a$ is right zero divisor. Similarly we can see that if ab is left zero divisor then $ba$ is right zero divisor. So for this case , if $ab$ is zero divisor, then $ba$ is also a zero divisor.(I think ring R should have at least one non-zero element so that $x≠0$ , otherwise zero divisor won't have meaning in such a ring ?) 2 - if $a$ and $b$ does not equal $0$ . so from the assumptions, we know that ab is zero divisor. It means that it is both right and left divisor. So there exists some $z ∈ R, z≠ 0, s.t, abz = 0$ .then if we consider the element $bz$ , it results that $ba.bz = b.(abz) = 0$ . Similarly , there exist some $z' ∈ R, z' ≠ 0, s.t, z'ab = 0$ . Then $z'a.ba = (z'ab).a = 0$ . But it now suffices to show that $z'a ≠ 0$ and $bz ≠ 0$ so that $ba$ can be a zero divisor. How can I show that? or there is some counterexamples that shows $ba$ is not necessarily zero divisor even hen ab is a zero divisor?","['ring-theory', 'abstract-algebra']"
4637174,"Does there exist a rational function $g(x,y)$ that picks out the first quadrant?","Problem statement: Let $V = \{(x,y) \in \mathbb{R}^2 : x,y>0\}$ be the first quadrant of the plane.
Does there exist a rational function $g : \mathbb{R}^2 \rightarrow \mathbb{R}$ such that $g(V)$ and $g(\mathbb{R}^2 \backslash V)$ are disjoint? An easier formulation of this problem could be: does there exist a rational function $g(x,y)$ such that $g(x,y)>0$ iff $x,y>0$ ? I think this could be solved by an appeal to this question , which shows the answer is no for polynomials, but I can't quite work out the details. I realize there is some ambiguity about whether $g$ is defined everywhere; feel free to interpret that however you wish. Context: This problem arose while trying to answer another question on this site .","['functions', 'rational-functions']"
4637191,"What's the probability of going to (6, 4) without ever visiting (3, 4)?","The ant starts at (0, 0). With each move it goes either up or right by one unit distance. After 10 moves, what is the probability that the ant settles down at point (6, 4) without ever visiting the point (3, 4)? My solution: Since the ant has to make 10 moves moving either up or right, the amount of possible routes is 2^10 = 1024. There are 10!/(6!4!) = 210 possible ways to reach (6, 4) in 10 moves. Hence, the probability of going to (6, 4) is 210/1024 ≈ 0.2051. Since the ant is only able to move either up or right, it has to make 7 moves (3 right, 4 up) to get to (3, 4). There are 2^7 = 128 possible routes to take in 7 moves. And so, there are 7!/(3!4!) = 35 possible ways to reach (3, 4) in 7 moves. So, the probability of going to (3, 4) in 7 moves should be 35/128 ≈ 0.2734. The probability of not going to (3, 4) is 1 - 0.2734 = 0.7266. With that, the probability of going to (6, 4) are 0.2051 and the probability of not going to (3, 4) is 0.7266. Since both of these events should occur to satisfy the condition, my answer would be 0.2051 * 0.7266 ≈ 0.149. However, I suppose my solution is wrong because if the ant goes to (7, 0) or (2, 5) in the first 7 moves, there's no way for it to reach (6, 4). Is there a way to fix my solution or have I gone absolutely the wrong way?","['conditional-probability', 'combinatorics', 'probability-theory', 'probability']"
4637201,We have $f:R\rightarrow R$ continuous with $f(x+y)=e^{3xy}f(x)f(y)$ and $f(1)=e$. Find f.,"We have $f:\mathbb{R}\rightarrow \mathbb{R}$ a continuous function
with $f(x+y)=e^{3xy}f(x)f(y)$ and $f(1)=e$ , Find $f$ . I showed by induction that f is strictly positive on $\mathbb{N}$ , then I showed again with induction that f is strictly positive on $\mathbb{Z}$ . I don't know how to show f is strictly positive on $\mathbb{Q}$ . If I can show that, by the density of $\mathbb{Q}$ in $\mathbb{R}$ we can say that $f\geq0$ . But if f is 0 at some point then f is 0 at all points by the relation so we get a contradiction. So f is strictly positive on $\mathbb{R}$ . Now I will take the function $g=\ln(f)$ , which is continuous.
We get the relation $g(x+y)=3xy+g(x)+g(y)$ From here we get $g(x+1)=3x+1+g(x)$ We have $g(x+1)-g(x)=3x+1$ By iteration we get $g(x+1)-g(x-(n+1))=\frac{(n+2)(3x-3n-2)}{2}$ The iteration I took looks very bad, so I don't have an idea right now. Can anyone help me with this problem?","['continuity', 'functions', 'functional-equations', 'real-analysis']"
4637209,Evaluating $\int \sqrt{\frac{2x+3}{2x-3}}dx$,"I was evaluating $\int \sqrt{\frac{2x+3}{2x-3}}dx$ and got an answer which, I think, is not correct as it is different from wolframalpha's answer. Here's my work: $$\begin{align}\int \sqrt\frac{2x+3}{2x-3} dx & = \int \frac{2x + 3}{\sqrt{4x^2 - 9}} \ dx\tag{1}\\& =\int \frac{x}{\sqrt{x^2 - (3/2)^2}}\ dx  + \frac32\int \frac{dx}{\sqrt{x^2 - (3/2)^2}}\tag{2}\\&= \sqrt{x^2 - (3/2)^2 } + \frac{3}{2}\cosh^{-1}\left(\frac{2x}{3}\right) + C\tag{3}\end{align}$$ Steps: $(1.)$ Rationalized the numerator. $(2.)$ Applied linearity. $(3.)$ The first integral is done by substituting $x^2 - (3/2)^2 = t$ and the  second one is inverse hyperbolic cosine. WolframAlpha shows this . I also tried differentiating both the answers, but still it's different from mine.","['integration', 'indefinite-integrals', 'calculus']"
4637301,May the proof of Calculus on Manifolds Theorem 3-11 (on compact sets) be simplified as follows?,"Theorem: Let $A\subseteq \mathbb{R}^d$ be compact, and let $O$ be an open cover of $A$ . Then there is a partition of unity subordinate to $O$ . Below I give Spivak's proof and my slight simplification. Is my proof (the simplified version of Spivak's) correct? Spivak's proof: My Proof: Let $U_1,\ldots, U_n$ be a finite subcover of $A$ in $O$ . By Lemma 1 there are compact sets $D_i$ such that $$A\subseteq \bigcup_{i=1}^nD_i^{\circ} 
\ \ \ \ \text{and} \ \ \ \ 
D_i\subseteq U_i.$$ Let $U:=U_1\cup \ldots \cup U_n$ . By Lemma 2 there are functions $\psi_i:U\to[0,1]$ so that $\psi_i$ is $C^{\infty}$ . $\psi_i$ is $1$ on $D_i$ . $\psi_i$ is $0$ outside of some closed set contained in $U_i$ .
Define $$\phi_i : U\to [0,1] : x\mapsto \frac{\psi_i(x)}{\psi_1(x) + \ldots + \psi_n(x)}.$$ The partition of unity $\Phi:=\{\phi_1,\ldots ,\phi_n\}$ is subordinate to $O$ . Lemma 1 (akin to Spivak's Problem 1-22): Let $U$ be open and $K\subseteq U$ compact. Then there is a compact set $D$ such that $$K\subseteq D^{\circ}
 \ \ \ \ \text{and} \ \ \ \ 
D\subseteq U.$$ Let $\{U_1, \ldots , U_n\}$ be an open cover of the compact set $K$ . Then there are compact sets $D_i$ such that $$K \subseteq \bigcup_{i=1}^nD_i^{\circ}
\ \ \ \ \text{and} \ \ \ \ 
D_i\subseteq U_i.$$ Lemma 2 (akin to Spivak's Problem 2-26): Let $U$ be open and $D\subseteq U$ be compact. Then there is a function $f:\mathbb{R}^n\to\mathbb{R}^n$ such that $f$ is $C^{\infty}$ . $f$ is $1$ on $D$ . $f$ is $0$ outside of some closed set contained in $U$ .","['alternative-proof', 'multivariable-calculus', 'solution-verification', 'real-analysis']"
4637348,show the coordinate axis form an algebraic set in $\Bbb{R}^3$,"So by coordinate axis in $\Bbb{R}^3$ im assuming they mean the subspace of $\Bbb{R}^3$ : $$A = \{(x,0,0),(0,y,0),(0,0,z): x,y,z \in \Bbb{R}\}.$$ Or should I write this as $$\{(x,0,0):x \in \Bbb{R}\}\cup \{(0,y,0):y \in \Bbb{R}\} \cup \{(0,0,z):z \in \Bbb{R}\}$$ Ive noticed that the $x-$ axis is the zero set $V(y,z)$ and the $y-$ axis is the zero set $V(x,z)$ and similarly the $z-$ axis is the zero set $V(x,y)$ am I headed in the right direction? and does being inside of $V(x,y$ ) for instance imply $x,y=0$ ? Also for the zero set associated to (if thats the right terminology) $A$ , do I take the union of these $V$ 's that I found or? So if anyone wants to help out, is it just $V(y,z) \cup V(x,z) \cup V(x,y)$ ?","['algebraic-geometry', 'abstract-algebra']"
4637396,Imaginary part of dilogarithm,"I have evaluated a certain real-valued, finite integral with no general elementary solution, but which I have been able to prove equals the imaginary part of some dilogarithms and can write in the form $\Im{\left(\operatorname{Li_2}\left(r\cdot e^{i\theta}\right)\right)}=\tfrac{1}{2i}\left({\operatorname{Li_2}\left(r\cdot e^{i\theta}\right)}-{\operatorname{Li_2}\left(r\cdot e^{-i\theta}\right)}\right)$ similar to the integral in this question and where we can assume $r≥0$ and $0<\theta<\pi$ . Since the input variables are real-valued and the answer is real-valued, I'd prefer a solution that avoids intermediate complex notation while at the same time keeping the underlying integral/series implicit.  I'm aware of some ""trivial"" solutions: $\lim\limits_{\theta \to 0^+}\Im{\left(\operatorname{Li_2}\left(r\cdot e^{i\theta}\right)\right)}=\begin{cases}0 & \text{if } r≤1\\ \pi\log{(r)} & \text{if } r>1\end{cases}$ $\Im{\left(\operatorname{Li_2}\left(r\cdot e^{i\pi/2}\right)\right)}=\operatorname{Ti_2}\left(r\right)$ $\Im{\left(\operatorname{Li_2}\left(1\cdot e^{i\theta}\right)\right)}=\operatorname{Cl_2}\left(\theta\right)$ Is it possible to separate $r$ and $\theta$ more generically?  That is to say, I prefer to write the solution in terms like the inverse tangent integral $\operatorname{Ti_2}\left(r\right)$ or the Clausen function $\operatorname{Cl_2}\left(\theta\right)$ where the arguments stay real-valued.  It is also acceptable to use other related functions such as the trigamma function, zeta functions, or even the original dilogarithm with real argument, as long as you don't get more abstract like hypergeometric functions. If not generically, are there particular values of $\theta$ where this is possible such as at angles that are rational numbers times $\pi$ ? $\theta=\pi/3$ or $2\pi/5$ or $\pi/4$ for instance?  I suppose this is my main goal, to get a function of $r$ for certain fixed $\theta$ other than $0$ and $\pi/2$ . If it helps, you can restrict your answer to $0≤r≤1$ or smaller and $0<\theta<\pi/2$ .  Can you extend your answer to $\left|\Re{\left(r\cdot e^{i\theta}\right)}\right|≤1$ ?  Can you extend it all the way to $0≤r≤2$ or more? See also a related question about the real part .","['complex-analysis', 'polylogarithm', 'closed-form']"
4637412,"Is $\ \{ \sin(p):\ p\ $ is prime $ \}\ $ a dense subset of $\ [-1,1]\ ?$","Is the set $A:= \{ \sin(p): \text{$p$ is prime} \}$ a dense subset of $[-1,1]$ ? Is it known whether or not $-1$ , $0$ or $1$ are
limit points of $A$ ? I would imagine so, otherwise this means the primes are related to $\pi$ in some special way, which I have not heard of. I'm not sure how to prove the affirmative though: I think the unpredictable nature of the primes makes this a challenge. All I know is that $\{ \sin(n):n\in\mathbb{N}\}$ is a dense subset of $[-1,1]$ . For example, see here . There are many known inequalities and bounds for the prime counting function, for example, see here. However, I'm not sure these are useful for answering the above question.","['number-theory', 'prime-numbers', 'real-analysis']"
4637420,Can this be solved this without sin and cos?,"My daughter got this homework problem, and I can't seem to solve it. What makes it stranger is they haven't done geometry yet: like no sin and cos stuff. They did do area of triangles, but it seems like this is too advanced.  I am wondering if maybe I am missing some simple trick or something like that. Here is the diagram: The instruction are to calculate s1-s2. Any ideas?  I know if you assume they are right angles you can use cos and sin, but I feel like something simpler should be involved.","['algebra-precalculus', 'geometry']"
4637438,Density of extended Mersenne numbers?,"Consider the subset of odd positive integers defined and constructed as follows by these rules : A) $1$ is in the set. B) if $x$ is in the set , then $2x + 1$ is in the set. C) if $x$ and $y$ are in the set then $xy$ is in the set. I call them extended Mersenne numbers because rule A and B alone give the Mersenne numbers $2^n - 1$ . And every product of Mersenne numbers must be in the set as well. So the set or list of extended Mersenne numbers starts like $$1,3,7,9,15,19,21,27,31,39,43,45,49,55,57,63,79,81,87,91,93,99,...$$ The main question is how dense is this within the odd integers ? Secondary is there an easy and efficient test to know if an odd integer is in the list ? I assume this sequence has no name yet but I could be wrong ? *** speculation *** I see $22$ odd elements from $1$ till $99$ , which is close to the number of odd primes under $99$ (that is $24$ ) $$ \dfrac11 + \dfrac13 + \dfrac17 + \dfrac19 + \ldots + \ldots+\dfrac{1}{99} = 2.034980..$$ So this (subjectively I admit ) seems to imply the sequence grows quite fast.
Therefore I guess maybe an asymptotic of the form $C* x * \ln(x)^D $ for some constants $C,D$ might be an asymptotic for the counting function. On the other hand I suspect much sharper asymptotics can be proven. Background This comes from abstract algebra where we want a commutative latin square with units and inverses such that ""Property A"" $$ x * (y * y^{-1}) = x = (x * y) * y^{-1} $$ holds for all elements $x,y$ . ( if this property has a name please tell me ) and for every element $z$ $$ z^2 = 1 $$ ( not the main question here, but I wonder how dropping the $z^2 = 1$ condition effects things ) The dimensions of these are then exactly these extended Mersenne numbers + $1$ . edit corrected forgotten terms and copy lulu's conjecture : The sequence is equal to https://oeis.org/A197625 ??? ( https://math.stackexchange.com/users/252071/lulu ) edit2 Greg Martin found counterexample 219 so lulu's conjecture is false. Greg also conjectured that $D=0$ or $D$ goes to $0$ . It seems that Greg believes we will get close to linear, but I want to point out that the set is denser than the products of mersenne numbers. On the other hand numbers like $63 = 3 * 21 = 2*31 + 1$ can be reached in $2$ ways so the rules have overlapping values, which could lower the density. I would not be surprised if the density is slightly higher than the sum of 2 squares or the density of $a^3 + b^3 + c^3$ which are both less than linear. It reminds me a bit of collatz, where the rules $2x$ and $(x-1)/3$ generate all integers , or so we believe. But these rules for the extented Mersenne numbers have no deminishing rule like $(x-1)/3$ ( deminish because that is smaller than $x$ ) , which is why I believe they might not have linear density. added Noticed how powers of $5$ or powers of $17$ are never in the list : $5$ and $25$ are not in. So $125,625,…$ are not created By products.
Also $125,625,…$ are of the form $4n + 1$ , so they did not come from the 2x + 1 rule either. Similar with $17$ or other primes missing of the form $4n + 1$ . This ofcourse highly influences the density. Also notice primes of the form $4n+1$ have to come from 2x + 1 themselves , where x must be odd !! 2 x + 1 maps 1 mod 4 to 3 mod 4, and maps 3 mod 4 to 3 mod 4 !! So primes 1 mod 4 are a key thing here !!","['sieve-theory', 'number-theory', 'mersenne-numbers', 'asymptotics', 'abstract-algebra']"
4637481,Is the cardinality of the dimension of an infinite-dimensional vector space well-defined?,"I thought of this question because of something in physics. In quantum mechanics, the state of a system is associated with a unit vector in a Hilbert space, which in many cases can be thought of as $L^2$ . Physicists often project this vector to different bases for convenience. However, sometimes the basis is countable and other times it is not, which looks very suspicious. Usually, when this happens, the uncountable basis is the Dirac delta functions (and maybe we could think of the countable basis as the Hermite polynomials or something). The Dirac delta functions are not functions at all so this is nowhere rigorous in the first place, but, could this phenomenon actually happen in math?",['functional-analysis']
4637604,Why are $p$-adic integers integers,"When constructing the $p$ -adic numbers, we proceed for instance as when constructing $\mathbb{R}$ for the usual distance. Then the integers are king of ``natural"", we are used to them (are we can see them as the rational algebraic numbers, but this also relies on the specific choice of $\mathbb{Z}$ which I cannot motivate, except maybe as the additive group generated by $1$ ?) In the case of $p$ -adic numbers, the same process with the $p$ -adic topology leads to $\mathbb{Q}_p$ . However, it is often defined right after that $\mathbb{Z}_p$ is the ring of $p$ -adic integers, e.g. as the unit ball or equivalently as the Laurent series that are power series in $p$ . Is there a deeper definition of $\mathbb{Z}_p$ ? Can we see them as the algebraic integers of $\mathbb{Q}_p$ for instance? Why are they termed ` ìntegers"", beyond the analogy of the positive powers appearing only in archimedean integers?","['number-theory', 'p-adic-number-theory', 'integers', 'algebraic-number-theory']"
4637629,Finding ideals of $C(X)$ where $X$ is compact Hausdorff space,Here is the question above. I am stuck in part a) . here I am able to find a positive $f\in J$ with $\|f\|_\infty \le 1$ such that $f\ne 0$ on $X-U$ to get $f=1$ on $X-U$ we need to extend $1/f$ on $X$ which can be done by Teitze-extension . But how to control the norm of $g$ such that $\|f.g\|_\infty\le1$ where $g$ is the extension of $1/f$ .,"['operator-theory', 'functional-analysis', 'operator-algebras']"
4637638,Can $n!+16$ be a perfect square when $n\geq5$?,"Can $n!+16$ be a perfect square? I think $n!+16$ can be a perfect square, since $n!+16$ is $0 \mod 4$ , and always $1 \mod 3$ ( when n is $> 5$ ), and always $5 \mod 11$ ( when $n$ is $> 11$ ). But when I tried to find if are there any perfect squares form of $n!+16$ , I didn't succeed. Are there any perfect squares form of $n!+16$ ?","['number-theory', 'perfect-powers']"
4637661,Differential of $h(x) = \Vert x \Vert ^4$,"Find the differential of $h: \mathbb R^k \to \mathbb R$ defined as $h(x) = \Vert x \Vert ^4$ (with $\Vert \Vert$ the Euclidean norm). I'm not sure if I'm correct. We can write $h(x) = \langle x,x \rangle^2$ with the standard inner product. To make things easier define $f(x) = \langle x,x \rangle$ and $g(x) = x^2$ , with $f : \mathbb R^k \to \mathbb R$ and $g : \mathbb R \to \mathbb R$ . $g'(x) = 2x$ and by the product rule $Df_x = 2\langle I,x \rangle$ . $h = g \circ f$ so by the chain rule: $Dh_x = Dg_{f(x)} \circ Df_x = (2 \langle x,x \rangle) \ \circ \  (2\langle I,x \rangle)$ .
Now, $2 \langle x,x \rangle$ is a scalar so I'm not sure if the composition with $Df_x$ should result in the product $4 \langle x,x \rangle \langle I,x \rangle = 4\Vert x \Vert ^2\langle I,x \rangle$ , or it should result in $2 \langle 2\langle I,x \rangle,2\langle I,x \rangle \rangle = 8 \langle \langle I,x \rangle,\langle I,x \rangle \rangle = 8 \langle I,x \rangle^2$ since $\langle I,x \rangle$ should result in a scalr when plugging in some vector $v$ (meaning $\langle I,x \rangle(v) = \langle v,x \rangle$ ). There might be a simpler way to do this but I would appreciate any help.","['multivariable-calculus', 'normed-spaces']"
4637668,Determining the limit of the function composition of a known limit,"For example, given $$\lim_{n \to \infty}\frac{n^2}{c+n^2} = 1,$$ are we allowed to ""square both sides"" $$\lim_{n \to \infty}\left(\frac{n^2}{c+n^2}\right)^2 = 1^2,$$ basically finding finding the limit of the composition $g f,$ where $g = x^2$ and $f = \frac{n^2}{x+n^2}.$","['limits', 'functions', 'continuity', 'real-analysis']"
4637697,"Is there a better than $O(n\log(n))$ algorithm for the following question: $A,B$ sets, $|A|=n,|B|=n-1,B\subset A$, calculate $A\setminus B$?","The Problem: I am looking for a fast algorithm for the following trivial-looking question: Let $n\in\mathbb{N}^+$ and $A,B$ be sets of integers such that $|A|=n$ $|B|=n-1$ $B\subset A$ Calculate the single element of $A \setminus B$ . Note: Even though mathematically I am denoting $A$ and $B$ as sets, computationally they are handled as lists . So I will denote the $i$ 'th element of $A$ as $A[i]$ and the $j$ 'th element of $B$ as $B[j]$ . It is important to mention that $A$ and $B$ are not necessarily ordered the same way. Example: $A := \{6,5,1,7,9\}$ , $B := \{9,1,5,6\}$ , then $A \setminus B = \{7\}$ . Note: Computationally the numbers inside $A$ and $B$ appear one after the other, so what the computer sees is $$A[1] = 6, A[2] = 5, \dots, B[1] = 9, \dots,B[4] = 6$$ $O(n^2)$ algorithm: There is a trivial $O(n^2)$ algorithm that can calculate $A \setminus B$ . This is its code in Python: def A_minus_B(A,B):
    for a in A:
        is_a_in_B = False
        for b in B:
            if a == b:
                is_a_in_B = True
        if not is_a_in_B:
            return a It checks all pairs of numbers in $A$ and $B$ , and if it doesn't find a pair for an $a \in A$ , it returns that as its output. However it never considers the fact that $B \subset A$ . Obviously this is an $O(n^2)$ algorithm. It makes $n(n-1)$ steps in the worst case, if the single $A \setminus B$ element appears at the last position of the input list $A$ . $O(n\log(n))$ algorithm: This is a faster algorithm. This time, instead of giving a Python code, I will simply outline the algorithm: $1$ . Sort $A$ in increasing order in $O(n\log(n))$ steps. $2$ . Sort $B$ in increasing order in $O((n-1)\log(n-1))$ steps. $3$ . Go through both $A$ and $B$ in at most $n-1$ steps with $i=1$ to $i=n-1$ . If $A[i] \ne B[i]$ , then $A[i]$ has to be the single element of $A \setminus B$ . If all elements are equal from $i=1$ to $i=n-1$ , then return $A[n]$ . Steps $1$ and $2$ can be done in $O(n\log(n))$ steps, and Step $3$ can be done in $O(n)$ steps, so this algorithm is $O(n\log(n))$ . Question: Is there a better algorithm? I refuse to believe that such a simple problem cannot be solved in linear time. Somehow we need to use that $A$ is almost the same set as $B$ . What makes this difficult is that the elements of $A$ and $B$ can appear in any order. Context: I am constructing an algorithm that works with Vines . Here, any cluster can be thought of as set $A$ in the above problem, and any connecting separator can be thought of as set $B$ . Calculating $A \setminus B$ gives us the element which has the lowest mutual information with the rest of $A$ , which, among other things, is useful to give an ordering for the entire Vine structure.","['elementary-set-theory', 'algorithms']"
4637699,Definition of normal state on von Neumann algebra,"I have a question about the notion of normal state on a von Neumann algebra and its relation to a particular representation of the algebra. Let me take from the book by Bratteli and Robinson: Definition 2.4.20: A state $\omega : \mathfrak{M} \to \mathbb{C}$ on a von Neumann algebra $\mathfrak{M}$ is called normal if $\omega ( \text{l.u.b.}_\alpha ~ A_\alpha ) = \text{l.u.b.}_\alpha ~ \omega (A_\alpha)$ , where $\text{l.u.b.}$ is the least upper bound and $\{ A_\alpha \}$ is an increasing net in $\mathfrak{M}_+$ with an upper bound. Theorem 2.4.21: Let $\omega$ be a state on a von Neumann algebra $\mathfrak{M}$ acting on a Hilbert space $H$ . Then $\omega$ is normal if and only if there exists a positive, trace-class operator $\rho$ on $H$ with $\text{Tr} ( \rho) = 1$ such that $$ \omega (A) = \text{Tr}  ( \rho A ) , \quad \forall A \in \mathfrak{M}  . $$ The definition is clearly independent of any representation of the algebra, while from the theorem it seems that a state might be normal in one representation and non-normal in another. Also, every state is a vector state in its GNS representation, so it's also normal. But then how is it possible that the definition of normal be representation independent?","['von-neumann-algebras', 'functional-analysis', 'operator-algebras']"
4637746,Finding variance of an estimator,"I'm not sure how to express the variance of this estimator. Here's the setup. We have $X\sim N(0,\sigma^2)$ and want to estimate $\mathbb{E}[\phi(X)]$ where $\phi : \mathbb{R}\to\mathbb{R}$ is some function such that $\mathbb{E}[\phi(X)]$ has finite mean and variance. We have iid samples $Y_1,\dots, Y_n \sim N(0,1)$ . This is the estimator proposed: $$\hat{\theta} = \frac{1}{n\sigma}\sum_{i=1}^{n} \exp\left[-Y_i^2\left(\frac{1}{2\sigma^2}-\frac{1}{2}\right)\right]\phi(Y_i)$$ . I have shown this estimator is unbiased. But I'm not sure how to express its variance. The most I can say is that since the $Y_i$ are iid, we have $$Var(\hat{\theta})=\frac{1}{n^2\sigma^2}\sum_{i=1}^{n} Var\left(\exp \left[-Y_i^2\left(\frac{1}{2\sigma^2}-\frac{1}{2}\right)\right]\phi(Y_i)\right)$$ . How can I express this further?","['statistical-inference', 'statistics', 'variance', 'parameter-estimation', 'probability']"
4637751,Deriving that a cube has six sides via a square and combinatorics,"Does there exist a derivation that a cube has 6 sides from knowing that a square has 4 edges and $4\choose2$ = 6? I was thinking maybe there exists some bijective map from any 2 given edges of a square to faces of a cube but I'm not really getting anywhere. I was thinking of this 2d --> 3d example, but I imagine if a derivation exists for this it could inductively find the number of externally touching distinct sides of a straight-edged shape (e.g. a line, square, cube, etc.) for higher dimesnions too. When looking at lower dimensions, though, a line has 2 edge facing sides but $\not\exists{x}$ s.t. $2\choose{x}$ $={4}$ , so maybe you can only start the induction from the 2nd dimension? I'm pretty lost so any help would be greatly appreciated. As for my background, I've taken a class on algebra but don't have any topology knowledge, so I apologize in advance if this question is rudimentary. Thanks!",['geometry']
4637764,What does it mean for $f:\mathbb{R}^2 \to \mathbb{R}$ to be twice differentiable [duplicate],"This question already has an answer here : A question about derivatives between Euclidean spaces: how should we construct it and interpret its definition? (1 answer) Closed last year . Given some function $g:\mathbb{R} \to \mathbb{R}$ , it is twice differentiable if $g'(x)$ and $g''(x)$ both exist. But what about something like $f:\mathbb{R}^2 \to \mathbb{R}$ . Now I have partials to worry about. What is the definition of being twice differentiable in this case?","['multivariable-calculus', 'derivatives']"
4637765,Ask minimal sufficient statistics for double-exponential distribution,"Let $X_1,...,X_n$ be a random sample from double-exponential $(\mu, 1), \mu \in \mathcal{R}$ , i.e., the joint pdf of $X$ is $$f_\mu (x)= \frac{1}{2^n} \exp(-\Sigma_{i=1}^n |x_i-\mu|)$$ Consider $\mathcal{F}_0=\{f_0,f_1,...,f_n \}$ , where each $f_j$ is the pdf with $\mu=j,j=,1,...,n$ . By Theorem 6.6.5a in Casella and Berger's statistical inference textbook, a minimal sufficient statistics for $\mathcal{F}_0$ is $$T=(\exp(\Sigma_{i=1}^n |X_i|-   \Sigma_{i=1}^n |X_i-j|),j=1,...,n)$$ which is equivalent to $$U=(\Sigma_{i=1}^n |X_i|-   \Sigma_{i=1}^n |X_i-j|,j=1,...,n)$$ We can further show that $U$ is equivalent to $S$ , the set of order  statistics. Since $S$ is sufficient, by Theorem 6.6.5b, $S, U$ and $T$ are all minimal sufficient. I need the help that how I can justify the step "" $U$ is equivalent to $S$ , the set of order  statistics.""","['statistics', 'probability']"
4637791,If $\lim_{n \rightarrow \infty}\sum_{k=0}^np_{k}=\infty$ show that $f$ has a fixed point,"We have $(p_{n})_{n\geq0}$ a sequence of strictly positive real numbers and $a$ a real number and the continuous function $f:\mathbb{R}\rightarrow \mathbb{R}$ such that the sequence $$\left(\frac{\sum_{k=0}^np_{k}f^{(k)}(a)}{\sum_{k=0}^np_{k}}\right)_{n\geq1}$$ is bounded, where $f^{(k)}$ is the composite of $k$ times of $f$ (and $f^{0}=\text{id}_{\mathbb{R}})$ . If $$\lim_{n \rightarrow \infty}\sum_{k=0}^np_{k}=\infty$$ show that $f$ has a fixed point. I need to say that this problem looked ugly when I first saw it. So if the series of $p_{n}$ diverges to $\infty$ and knowing that the ""big"" sequence is bounded then $$\lim_{n\rightarrow \infty}\sum_{k=0}^np_{k}f^{(k)}(a)$$ is $0$ or $+/-\infty$ . It is a fixed point problem right? So we can take the continuous function $g:R\rightarrow R$ , $g(x)=f(x)-x$ . So we need to show somehow this function $g$ it is 0 at some point. If $$\lim_{n\rightarrow \infty}\sum_{k=0}^np_{k}f^{(k)}(a)=-\infty$$ then there exists $f^{(k)}(a)<0$ right?","['fixed-points', 'fixed-point-theorems', 'function-and-relation-composition', 'continuity', 'sequences-and-series']"
4637801,Fastest way to get from one permutation to another (with distances between elements),"Imagine that I have some rows of shelves. Some shelves have items on them. Some may be empty. Imagine also that I have computed the shortest paths between each location (using Dijkstra's algorithm, for example). I want to rearrange the items on the shelves to some fixed permutation that I have in mind. Is there an algorithm to find the optimum way to rearrange the shelves i.e the sequence of relocations for which I will have to travel the least distance? Let's also say I can only carry one item at a time, although I would also be interested to find out how the algorithm would change if we allowed multiple people each carrying an item.","['combinatorics', 'discrete-mathematics', 'computer-science']"
4637853,Determining whether 2 logical statements are equivalent,"I recently encountered a problem which is to determine whether the following statements are logically equivalent to each other. The statements are: $$\text{$(\exists x\in U)[P(x)\land Q(x)]$ and $[(\exists x\in U)P(x)]\land[(\exists x\in U)Q(x)]$}$$ Suppose $(\exists x\in U)[P(x)\land Q(x)]$ is true. Let $x = a \in U$ s.t. $P(a)$ and $Q(a)$ is true. So both $P(a)$ and $Q(a)$ are true. Suppose $(\exists x\in U)[P(x)\land Q(x)]$ is false. Then its negation: $(\forall x \in U)[\neg P(x) \lor\neg Q(x)]$ is true. The negation holds true whenever $P(x)$ is false or $Q(x)$ is false for any $x \in U$ . Let $x \in U$ s.t. $\neg P(x) \lor\neg Q(x)$ is true, hence, we consider 2 cases: Case 1: $P(x)$ is false Since $P(x)$ is false for any $x\in U$ , $(\exists x\in U)P(x)$ is false, hence $[(\exists x\in U)P(x)]\land[(\exists x\in U)Q(x)]$ must be false. Case 2: $Q(x)$ is false Since $Q(x)$ is false for any $x\in U$ , $(\exists x\in U)Q(x)$ is false, hence, $[(\exists x\in U)P(x)]\land[(\exists x\in U)Q(x)]$ must be false. Since when $(\exists x\in U)[P(x)\land Q(x)]$ is true, $[(\exists x\in U)P(x)]\land[(\exists x\in U)Q(x)]$ is also true. And when $(\exists x\in U)[P(x)\land Q(x)]$ is false, $[(\exists x\in U)P(x)]\land[(\exists x\in U)Q(x)]$ is also false. Therefore we can conclude that they are logically equivalent. I would like to know whether my answer is valid and whether there is bug in my answer. Thanks!!","['logic', 'discrete-mathematics']"
4637878,"Calculate $\int \limits_{A}^{ }\frac{y}{x^3}\, dy\, dx$ with $A=\{(x,y)\in \mathbb{R}^2|1\leq xy\leq 2,\, 1\leq \frac xy\leq 2\}$, coordinate-transfo.","Calculate $\int \limits_{A}^{ }\frac{y}{x^3}\, dy\, dx$ with $A=\{(x,y)\in (\mathbb{R^+})^2|1\leq xy\leq 2,\, 1\leq \frac xy\leq 2\}$ . Define new coordinates $u=xy\,v=\frac yx$ . Now define $B:=[1,2]^2$ and $h: A\to B, (x,y)\mapsto (u,v)=(xy,\frac yx)$ It is known that $h$ is bijective and continuously differentiable on $B$ . Now The following theorem $(*)$ gets used: ""Let $U\subset \mathbb{R}^n$ be open, $f:U\to \mathbb{R}^n$ continuously differentiable (a $C^1$ -function) and $a \in U$ . If $J_f(a)$ is invertable then $f$ is a local $C^1$ -diffeomorphism. "" Now $J_h((x,y))=\begin{pmatrix} y & x \\ \frac{-y}{x^2} & \frac{1}{x} \end{pmatrix}\Rightarrow  \det \begin{pmatrix} y & x \\ \frac{-y}{x^2} & \frac{1}{x} \end{pmatrix}=2\frac{y}{x} >0$ for every $(x,y)\in A$ So $J_h$ is ivertable. First Question
In the solution to the problem it is stated that $h$ satifys the conditions of $(*)$ and is a $C^1$ -diffeomorphism but $A$ is not an open set. Why is $(*)$ applicable? Next step: Define $g=h^{-1}$ . Now one can apply the transformation formula: $\int \limits_{g(B)}^{}f(x,y)d(x,y)=\int \limits_{B}^{ }f(g(u,v))\cdot|\det J_g(u,v)|d(u,v)$ Now the second question: It is stated that the following is true: $f(g(u,v))\cdot|\det J_g(u,v)|= f(x,y)\cdot \frac{1}{|\det J_h(u,v)|}$ Do you have an idea, what the justification could be? Important Edit I made a mistake. I wrote $A=\{(x,y)\in \mathbb{R}^2|1\leq xy\leq 2,\, 1\leq \frac xy\leq 2\}$ instead of $A=\{(x,y)\in (\mathbb{R^+})^2|1\leq xy\leq 2,\, 1\leq \frac xy\leq 2\}$ !","['integration', 'diffeomorphism', 'inverse-function-theorem', 'multivariable-calculus', 'inverse']"
4637970,"Expectation of the max number of times an element is chosen, if repeatedly randomly choosing a subset out of a set","Given a set of $n$ elements. For a total of $s$ times, you randomly choose exactly $m$ elements among them. (i.e. each $m$ -element set has $p=\frac{1}{\binom{n}{m}}$ of being chosen) Here $n\gg m$ and maybe $s\sim\frac{n}{m}$ . If we denote $X_i$ as the number of times the ith element is chosen, I want to know about the maximum among $X_i$ , i.e. $X=\max\{X_1,X_2,\cdots,X_n\}$ . Specifically, I want to know either $E(X)$ when $s=O\left(\frac{n}{m}\right)$ , or an $s$ such that $E(X)=O(1)$ . I don't think there is a pretty answer to this, so I am trying some approximations. I'm not sure if I can safely ignore the covariance between $X_i$ and treat them as iid binomial distributions (i.e. $X_i\sim Binom(s,p)$ where $p=\frac{m}{n}$ ). But even so I fail to figure out the expectation of $X$ . I think there must be a better way to approximate $X_i$ but I do need help on it.","['expected-value', 'binomial-coefficients', 'combinatorics', 'probability']"
4637980,"Prove that if $A$ and $B \backslash C$ are disjoint, then $A \cap B \subset C$","I am new to mathematical proofs, I wonder if my evaluation is correct. I have to prove that 1 - $A \cap B \backslash C = \emptyset \to A \cap B \subset C$ i - Break the implication, and add the antecedent to the hypothesis 2 - Hyp: $A \cap B \backslash C = \emptyset$ 3 - Goal: $A \cap B \subset C$ ii - Rewrite the goal in line 3 the following way: $ \forall x (x \in A \cap B \to x \in C)$ iii - Now, make x arbitrary: $x \in A \cap B \to x \in C$ iv - Since there's another conditional, break it and bring the antecedent as a hypothesis. 4 - Hyp: $x \in A \cap B$ - That means $x \in A \land x \in B$ 5 - Goal: $x \in C$ vi - From hypothesis in line 2 we have the equivalent: $\forall x(x \in A \to x \notin B \backslash C)$ vii - From hyp in line 4: $x \in A$ , then by Modus Ponens we conclude: 6 - $x \notin B \backslash C$ - That means $\neg (x \in B \land x \notin C) $ vii - $\neg (x \in B \land x \notin C) $ $\equiv$ $x \notin B \lor x \in C $ vii - From hypothesis in line 4, we have that $x \in B$ . Therefore, for line vii be true: viii - $x \in C$ which is exacly the goal in line 6.","['elementary-set-theory', 'proof-writing', 'solution-verification']"
4637995,How to solve for the actual value of a relative error function?,"Given the following equation, how do I solve for both values of α
? $$\Delta=\frac{\lvert\alpha-\beta\rvert}{\alpha}$$ For context, in Numerical Analysis $\beta$ represents an estimate, to an actual value, $\alpha$ , and $\Delta$ represents their difference. I have tried to experiment with inequality properties of the absolute value function, but that might give me a range of values, instead of two values of $\alpha$ . Additionally, I couldn't find any helpful absolute value properties online. Bonus points for recommending good reads/cheat-sheets on absolute value properties with example problems.","['numerical-methods', 'functions', 'absolute-value']"
4638029,Is there a pattern in the complex roots of the Sine Integral $\mathrm{Si}\left(\frac{z}{2}\right)$?,"I was working with the Sine Integral $\mathrm{Si}\left(\frac{z}{2}\right)$ and found it has an infinite number of complex roots mirrored in all four quadrants. In the first quadrant these start with: $$
11.9303627666221643518173848082 + 6.01119131213006773157261708415 \cdot i\\
24.7070169417149873195705173033 + 7.37455299482618861728760608970 \cdot i\\
37.3725098362278317680187364308 + 8.17692229518364269643530815855 \cdot i\\
49.9976565288211086812290841074 + 8.74796328051411644007205709150 \cdot i\\
\cdots
$$ Below is an extended plot of these roots in the first quadrant ( $z=x+iy$ ): and it appears the roots all lie on a log-shaped curve. After some attempts, the curve $y=2\log(x)+\frac12\,\log(2\,\pi)$ offers a pretty decent fit: Q: Obviously, the above fitting is just some guess work of mine, but got curious whether anything more is known about the pattern of these roots. Searched the web extensively, however nothing comes up. Grateful for any reference and/or any steers on how to find the exact curve (if it exists) the roots reside on.","['integration', 'complex-analysis', 'roots', 'asymptotics']"
4638060,Is it circular to use L'Hospital's rule to find derivative?,"I was killing time by doing some random math on paper and came up with the idea of trying to use L'Hospital on the limit definition of the derivative. If I choose the function $f(x)=\ln x$ then I can do $$f'(x)=\lim_{h\to 0}\frac{\ln(x+h) - \ln x}{h}=\lim_{h\to 0}\frac{\ln(\frac{x+h}{x})}{h}=\lim_{h\to 0}\frac{\ln(1 + \frac hx)}{h}$$ The numerator approaches $\ln 1=0$ and the denominator approaches $0$ , so I take the derivative of both with respect to $h$ . $$f'(x)=\lim_{h\to 0}\frac{f'(1 + \frac hx)\cdot \frac 1x}{1}=
\frac 1x \cdot \lim_{h\to 0}f'(1+\frac hx)$$ $$f'(x)=\frac{f'(1)}{x}$$ This just so happens to match the truth, but I suspect that this is a flawed argument. Can you tell me specifically where any holes in the logic might be?","['limits', 'calculus']"
4638062,Stokes type-formula,"Let $X$ be a complex manifold.
Is the following identity true? $$\int_X\overline {\partial} \alpha=\int_{\partial X} \alpha$$ where $\alpha $ is a differential form on $X$ , and $\partial X $ is the boundary of $X$ . The same question if we replace $\overline {\partial} \alpha $ by $\partial \alpha $ ?","['complex-geometry', 'stokes-theorem', 'differential-geometry']"
4638066,"Determine $f:\mathbb{R}\to\mathbb{R}$ derivable such that : $\forall x\in\mathbb{R}$, $f'(x)+f(x)=f(0)+f(1). $","I want to determine the functions $f:\mathbb{R}\to\mathbb{R}$ derivable such that $$
 \forall x\in\mathbb{R}, f'(x)+f(x)=f(0)+f(1).\tag{$*$}
$$ For that, if $f$ a differentiable function, check $(*)$ . We set $C=f(0)+f(1)$ , so $f$ is a solution of $y'+y=C$ . The solutions of this equation are the functions $x\mapsto C+De^{−x}$ with $D\in\mathbb{R}$ . Therefore, there exists $D\in\mathbb{R}$ such that $f(x)= C+De^{−x}$ . Then $$
C=f(0)+f(1)=2C+D(1+e^{-1})\Longleftrightarrow D=-\frac{C}{1+e^{-1}}.
$$ Hence $f(x)= C\left(1-\frac{1}{1+e^{-1}}\right)e^{−x}$ . But, I see in an indication that the solutions are of the form $$
f(x)=−\lambda(1+e^{−1})+\lambda e^{-x}\text{ with }\lambda\in\mathbb{R}
$$ please where is the problem?","['functions', 'derivatives', 'ordinary-differential-equations']"
4638078,"What is the probability that Carlos's purchase of 5 CDs includes at least one rap, country, and heavy metal CD out of a total of 12?","Full Problem Carlos has chosen $12$ different CDs he would like to buy: $4$ are rap music, $5$ are country music, and $3$ are heavy metal music. (Carlos has very eclectic tastes in music!) Unfortunately, he has only enough money to afford to buy $5$ of them (they all cost the same price). So he selects $5$ of them at random. What is the probability that his purchase includes at least one CD from each of the three categories? My Response First, there are a total of $\dbinom{12}5$ total ways for Carlos to choose, without order, $5$ CDs from $12$ CDs. Then, there are a total of $\dbinom41 \dbinom51 \dbinom31 \dbinom92$ ways for Carlos to choose at least one CD from each category. This simplifies to $\dfrac{30}{11}$ , which is obviously not correct. What went wrong in my process?","['combinatorics', 'probability']"
4638096,Can Lawson's proof (that the canonical inclusion into a Clifford algebra is injective) be fixed?,"The first proof in Lawson & Michelsohn's Spin Geometry is known to be wrong. The claim, which appears in a paragraph on page 8 (not in an official proposition), is that the projection map $\pi_q|_V:\mathscr T(V)\to \text{Cl}(V,q)$ is injective. For completeness, here is their ""proof."" $(V,q)$ is a vector space with a quadratic form, $\mathscr T(V)$ is the tensor algebra over $V$ , and $\mathscr J_q(V)$ is the ideal of $\mathscr T(V)$ generated by elements of the form $v\otimes v+q(v)1$ . We prove that $\pi_q|_V$ is injective as follows. We say that an element $\varphi\in\mathscr T(V)$ is of pure degree $s$ if $\varphi\in\bigotimes^sV$ . (Every element of $\mathscr T(V)$ is a finite sum of elements of pure degree.) We want to show that any element $\mathscr J_q(V)\cap V$ is zero. Any such element can be written as a finite sum $\varphi=\sum a_i\otimes(v_i\otimes v_i+q(v_i))\otimes b_i$ where we may assume that the $a_i$ 's and $b_i$ 's are of pure degree. Since $\varphi\in V=\bigotimes^1V$ , we conclude that $\sum a_{i'}\otimes(v_{i'}\otimes v_{i'})\otimes b_{i'}=0$ , where this sum is taken over those indices with $\deg a_i+\deg b_i$ maximal. This equation implies, by contraction with $q$ , that $\sum a_{i'}q(v_{i'})b_{i'}=0$ . Proceeding inductively, we prove that $\varphi=0$ . I don't know what they mean by ""contraction with $q$ ,"" so I can't even tell how this proof is supposed to work, much less how it goes wrong. That said, I don't really care what they intended or what's wrong with it, but rather I'd like to have a correct version of this proof in the same ""spirit"" as was intended here. A correct proof is given in the above-linked MO post, but it resorts to a representation of the Clifford algebra acting on the exterior algebra, which feels like a very different approach to me. We essentially need to show that the ideal $\mathscr J_q(V)$ is not equal to all of $\mathscr T(V)$ , and I like the idea of showing this directly using the definition of $\mathscr J_q(V)$ and the structure of $\mathscr T(V)$ , which I think is the approach that Lawson & Michelsohn were intending.","['alternative-proof', 'multilinear-algebra', 'linear-algebra', 'quotient-spaces', 'clifford-algebras']"
4638143,$\lim _{x\to 1}\left(\sqrt{x-1}\right)$,"I want to be clear with limits of even index root function like this one: $f(x)=\sqrt{x-1}$ . The domain of this function is $[1,\infty)$ . If I'm looking for one-sided limits: $$\lim _{x\to 1^{-}}\left(\sqrt{x-1}\right)=DNE$$ doesn't exist because the function is not defined at the left of $x=1$ . $$\lim _{x\to 1^{+}}\left(\sqrt{x-1}\right)=0$$ does exist because the function is defined at the right of $x=1$ Then, $$\lim _{x\to 1}\left(\sqrt{x-1}\right)=DNE$$ doesn't exist because the one sided limits are not equal. Is my analysis right?","['limits', 'calculus']"
4638246,"When is it valid to convert ""$\le$"" or ""$\ge$"" to ""$=$""?","I don't understand why the conversion of ≤ to = in this proof in Spivak's Calculus is legitimate. (The conversion in the previous line from = to ≤ makes sense to me.)  Could someone please explain or elaborate on how $(2)$ follows from $(1)$ below? this proof is motivated by the observation that $$
|a|=\sqrt{a^2} \text {. }
$$ We may now observe that $$
\begin{align*}
(|a+b|)^2=(a+b)^2 & =a^2+2 a b+b^2 \\
& \leq a^2+2|a| \cdot|b|+b^2 \tag{1} \\
& =|a|^2+2|a| \cdot|b|+|b|^2 \tag{2} \\
& =(|a|+|b|)^2
\end{align*}
$$",['algebra-precalculus']
4638248,Evaluate $\int^1_0 (9x^9-x^{90}+9x^{99}-x^{900}+9x^{909}-x^{990}+9x^{999}-x^{9000}+\cdots){\rm d}x$ (From MIT integration Bee Semi-final 2023),"I am trying to evaluate a question from MIT Integration Bee Semi-final 2023 (candidates had to solve it within 3 minutes!): $$\int^1_0 (9x^9-x^{90}+9x^{99}-x^{900}+9x^{909}-x^{990}+9x^{999}-x^{9000}+\cdots){\rm d}x$$ The pattern of the index is $9$ * $(1, 10, 11, 100, 101, 110, 111, 1000, \cdots)$ , just like the binary sequence. However, I have no idea how to apply the sum of infinite series in this case. The answer for this integral is simply $1$ . Thanks for your advice.","['integration', 'sequences-and-series']"
4638267,Why do we need Lebesgue Integration and what are the limits to Riemann Integrals?,"I am studying Lebesgue integrals, or to be more general, Measure Theory. I am really having difficulties with understanding why we would go over to the Lebesgue measure. The books I'm studying are maybe to technical. Could you please elaborate a bit on the need for measure theory. Why would we want functions to be measurable? Why do we need Lebesgue Integrals? What are the limits of Riemann Integrals, and why wouldnt you maybe introduce Lebesgue Integrals first, if they are better? Thanks in advance.","['measure-theory', 'lebesgue-measure', 'lebesgue-integral', 'real-analysis', 'riemann-integration']"
