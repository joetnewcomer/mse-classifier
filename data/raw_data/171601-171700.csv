question_id,title,body,tags
3044456,"If $A$ is an $n$ by $n$ integer matrix such that $A^3 = I$, then $\operatorname{tr}(A) = n\mod3$","Attempt: We work with $A'$ , the matrix with entries $a_{ij}\mod 3$ . Note that cubing $A'$ still gives $I$ as $I$ is unchanged by considering remainders $\mod 3$ . For the rest of the proof, we will not differentiate between $A$ and $A'$ . The minimal polynomial of $A$ divides $x^{3} - 1$ so each eigenvalue $\lambda$ of $A$ satisfies $\lambda^{3} = 1$ . The trace of $A^3$ is clearly just $n$ as $A^3 = I$ . Next, note that for integers $a_1, ...., a_n$ we have that $(a_1 +... + a_n)^k = a_1^{k} + a_2^{k} ... + a_n^{k}\mod k$ . Now this is where I am stuck. I would like to say that this implies $\operatorname{tr}(A)^3 =\operatorname{tr}(A^3)$ , but why is it that $\operatorname{tr}(A^3)$ is the sum of the cubed diagonal entries of $A$ ? I can only say that $\operatorname{tr}(A^3)$ is the sum of the cubed eigenvalues of $A$ , but these eigenvalues need not be integers so the argument fails. If I am able to prove this, then the result follows since I have $a^3 = a\mod 3$ for all $a$ in $\{0,1,2\}$ . Edit: I can confirm that my proof does work since $\operatorname{tr}(A)^p = \operatorname{tr}(A^p)\mod p$ for prime $p$ as said here https://rjlipton.wordpress.com/2009/08/07/fermats-little-theorem-for-matrices/ But I can't find the proof for this statement itself.","['modular-arithmetic', 'eigenvalues-eigenvectors', 'trace', 'minimal-polynomials', 'linear-algebra']"
3044516,"Find the number of zeros of $f(z)=e^{z-1}-az$ inside unit disk, assuming $\mid a \mid >1$","This is an application of Rouche's theorem, I want to make sure I am doing it correctly: Let $f(z)=e^{z-1}-az$ , where $\mid a \mid>1$ and $g(z)=-az$ Now, on the unit circle we have: $$\mid g(z) \mid=\mid a \mid \mid z \mid=\mid a \mid >1$$ and $$\mid g(z)-f(z)\mid=\mid e^{z-1} \mid=e^{Re(z-1)}=e^{Re(z)-1}=e^{Re(z)}e^{-1}\leq e^{-1}<1$$ Thus, on the unit circle $\mid g(z)-f(z) \mid< \mid g(z) \mid$ . Therefore, $g$ and $f$ have the same number of zeros inside the unit circle, so $f(z)$ has one zero inside the unit circle. Is this correct?","['proof-verification', 'roots', 'complex-analysis', 'rouches-theorem', 'complex-numbers']"
3044576,"If $3^x = 5$, $5^y = 10$, $10^z = 16$, then what is $3^{xyz}$?","Can't post images so I'll type it here: $$3^x = 5,\qquad 5^y = 10,\qquad 10^z = 16$$ Then what is $3^{xyz}$ ? I've spent like an hour trying to solve it and I failed. Help would be super duper appreciated.
Thank you! Edit: uhh I think I solved it? Would the answer be $16$ ? Basically I put $3^x$ in place of the $5$ in $5^y = 10$ , so now I have $(3^x)^y = 10$ (which is $3^{xy} = 10$ ), did the same for the last equation and I got $16$ as an answer, but can anyone confirm this?","['exponentiation', 'algebra-precalculus']"
3044605,"Explicitly calculate shape operator for graph of $f(x,y)=xy$","This seems trivial but I am stuck. To gain intuition for a bigger problem, I am trying to compute the shape operator of the graph of $f(x,y)=xy$ at the point $p=(0,0,0)$ , call this surface $\Sigma$ . In class we defined the shape operator at $p\in \Sigma$ , in terms of the covariant derivative. $$S(\vec v) = -\nabla_{\vec v}N=-\frac{d}{dt}\bigg|_{t=0}N(p+t\vec v).$$ where $\vec v\in T_p\Sigma$ and $N$ is normal to $\Sigma$ . Let $F(x,y,z)=xy-z$ . I know $N = \frac{\nabla F}{|\nabla F|}=\frac{1}{\sqrt{1+x^2+y^2}}(y,x,-1)$ . Say $\vec e_1,\vec e_2$ are basis vectors for $\Sigma$ . I know I need to find $S(\vec e_1)$ and $S(\vec e_2)$ , from there I can find the matrix of $S$ . This is where I am stuck, if someone can show how to do the calculation, that would be helpful.","['multivariable-calculus', 'differential-geometry']"
3044608,Slant cone volume problem,"I was given a a problem to solve, I thought I solved it but my answers don't look like the ones provided. The Problem A cone with radius of base r and height h , is stretched to the left and right by length a and b respectively such that height of the stretched cones equals to the height of the original cone and apexes of all the three cones are colinear.​ Devise an algorithm to calculate the volume of the union of the two stretched cones (colored blue in the image). My first question was: what is the volume of a slant cone? What I've found so far is that the formula for the volume of a slant cone is the same as that of a regular cone (which made sense to me). So I though the answer would be 2 times the area of a cone given by radius r and height h minus the intersection of the two slant cones, which is also a cone with radius r . I just need to find out the height of that smaller cone. My thought was that I could just take the cross section of of the bodies and handle the problem in 2D. Where the base of the cone will lie on the x axis and the center for the circle lies in point (0,0) . What I did was calculate the equation of the line that goes from (-a,h) to (r,0) . And I would also calculate the equation of the line going from (-r,0) to (b,h) . I proceeded to calculate the line equations and then to calculate where they intersect. I would then take y value at intersection and use it as the height of the smaller cone. I really thought I nailed it since when I had a = 0 and b = 0 I got the volume of the original cone. However, when the answers where provided mine didn't match the ones given. Can someone point out the hole in my logic?","['analytic-geometry', 'puzzle', 'geometry', 'convex-cone']"
3044638,"Why is there an ""implication"" rather than and ""and"" in this definition of the derivative?","I am readig Pugh's Analysis book: Definition Let $f:U \to \mathbb{R}^m$ be given where $U$ is an open subset of $\mathbb{R}^n$ . The function $f$ is differentiable a $p \in U$ with derivative $(Df)_p = T$ if $T:\mathbb{R}^n \to \mathbb{R}^m$ is a linear transformation and $f(p+v) = f(p)+T(v)+R(v) \implies \lim_{|v| \to 0} \dfrac {R(v)}{|v|}=0$ . Partly due to the missing quantifiers, I'm having trouble understanding why there is a "" $\implies$ "" there rather than a "" $\wedge$ "". Isn't it more natural to say ""T is the derivative if we can write $f(p+v) = f(p)+T(v)+R(v)$ AND $\lim_{|v| \to 0} \dfrac {R(v)}{|v|}=0$ ""? I'm having trouble seeing what the impact of changing these would be.","['frechet-derivative', 'logic', 'analysis', 'real-analysis']"
3044640,Functional Analysis Reference Books,I'm taking a measure-theory based graduate course on Functional Analysis that covers essentially Folland's Chapter 5-9.  Is there another book that I could reference that perhaps has wordier exposition that explains things in a bit more detail (not Rudin please).  Thank you.,"['measure-theory', 'functional-analysis', 'real-analysis']"
3044642,divergence in polar coordinates,"For a vector field $X$ , the divergence in coordinates is given by $\nabla\cdot X=\sum_n\frac{X^i}{\partial x^i}$ . In polar coordinates, the metric is $\begin{bmatrix}1 & 0\\ 0 & r^2\end{bmatrix}$ , and so $\frac{1}{\sqrt{g(\frac{\partial}{\partial r},\frac{\partial}{\partial r})}}\frac{\partial}{\partial r}=\frac{\partial}{\partial r}$ and $\frac{1}{\sqrt{g(\frac{\partial}{\partial\theta},\frac{\partial}{\partial\theta})}}\frac{\partial}{\partial\theta}=\frac{1}{r}\frac{\partial}{\partial\theta}$ are unit vectors. Then for $X=X_{r}\frac{\partial}{\partial r}+X_{\theta}\frac{\partial}{r\partial\theta}$ , $\nabla\cdot X=\frac{\partial X_r}{\partial r}+\frac{\partial}{\partial\theta}\frac{X_{\theta}}{r}=\frac{\partial X_r}{\partial r}+\frac{1}{r}\frac{\partial X_{\theta}}{\partial\theta}$ . But this disagrees with the usual formula given in vector calculus books. Does anyone see the error?","['vector-spaces', 'differential-geometry']"
3044647,Must compact bijections be continuous?,"We say a map $f:X \to Y$ is compact if compact sets are mapped to compact sets. If $f:X \to Y$ is a compact bijection, must it be continuous? The bijection condition is necessary. Otherwise consider an appropriately constructed piecewise constant function $\mathbb{R} \to \mathbb{R}$ as a counterexample. You might notice I never specified what exactly $X,Y$ are. Let us first consider simply the case where $X=\mathbb{R}^n$ , $Y=\mathbb{R}^m$ . If that holds, then work our way up to $X,Y$ being generic metric spaces. If that holds, then work our way up to $X,Y$ being topological spaces [EDIT: it's not true for general topological spaces, see the comments].","['metric-spaces', 'real-analysis', 'continuity', 'general-topology', 'compactness']"
3044669,Percolation related counting problem,"I was trying to look into the following problem, which I intend to use for a lemma for a bigger problem. The question is: For the 2-dimensional integer lattice, what are some good lower and upper bounds for the number of connected components of size $k$ that contain the origin? (We say that two lattice points are connected if they are the two endpoints of an edge) I tried to tackle the 1-dimensional case, but for that, the answer is much easier since you can actually compute the total number of such connected components. I also tried to write a program that computes it and it seems like the boundaries should be some exponentials, but I didn't manage to find a proof for this. Thanks","['polyomino', 'combinatorics', 'percolation']"
3044675,Long Division Algorithm Proof,"As I was doing my homework today, a sudden thought popped into my head. Why does our long-division algorithm work and how can I prove it? Why does it the function the way it does? Why do we not do division starting from the right and going to the left? Thanks",['algebra-precalculus']
3044687,Solving the integral $\int_0^{\pi/2}\log\left(\frac{2+\sin2x}{2-\sin2x}\right)\mathrm dx$,"I am in the process of proving $$I=\int_0^\infty \frac{\arctan x}{x^4+x^2+1}\mathrm{d}x=\frac{\pi^2}{8\sqrt{3}}-\frac23G+\frac\pi{12}\log(2+\sqrt{3})$$ And I have gotten as far as showing that $$2I=\frac{\pi^2}{4\sqrt{3}}+J$$ Where $$J=\int_0^\infty \log\bigg(\frac{x^2-x+1}{x^2+x+1}\bigg)\frac{\mathrm{d}x}{1+x^2}$$ Then we preform $x=\tan u$ to see that $$J=\int_0^{\pi/2}\log\bigg(\frac{2+\sin2x}{2-\sin2x}\bigg)\mathrm dx$$ Which I have been stuck on for the past while. I tried defining $$k(a)=\int_0^{\pi/2}\log(2+\sin2ax)\mathrm dx$$ Which gives $$J=k(1)-k(-1)$$ Then differentiating under the integral: $$k'(a)=2\int_0^{\pi/2}\frac{x\cos2ax}{2+\sin2ax}\mathrm dx$$ We may integrate by parts with $u=x$ to get a differential equation $$ak'(a)+k(a)=\frac\pi2\log(2+\sin\pi a)$$ With initial condition $$k(0)=\frac\pi2\log2$$ And from here I have no idea what to do. I also tried tangent half angle substitution, but that just gave me the original expression for $J$ . I'm hoping that there is some really easy method that just never occurred to me... Any tips? Edit As was pointed out in the comments, I could consider $$P(a)=\frac12\int_0^\pi \log(a+\sin x)\mathrm dx\\\Rightarrow P(0)=-\frac\pi2\log2$$ And $$
\begin{align}
Q(a)=&\frac12\int_0^\pi \log(a-\sin x)\mathrm dx\\
=&\frac12\int_0^\pi\log[-(-a+\sin x)]\mathrm dx\\
=&\frac12\int_0^\pi\bigg(\log(-1)+\log(-a+\sin x)\bigg)\mathrm dx\\
=&\frac{i\pi}2\int_0^\pi\mathrm{d}x+\frac12\int_0^\pi\log(-a+\sin x)\mathrm dx\\
=&\frac{i\pi^2}2+P(-a)
\end{align}
$$ Hence $$J=P(2)-Q(2)=P(2)-P(-2)-\frac{i\pi^2}2$$ So now we care about $P(a)$ . Differentiating under the integral, we have $$P'(a)=\frac12\int_0^\pi \frac{\mathrm{d}x}{a+\sin x}$$ With a healthy dose of Tangent half angle substitution, $$P'(a)=\int_0^\infty \frac{\mathrm{d}x}{ax^2+2x+a}$$ completing the square, we have $$P'(a)=\int_0^\infty \frac{\mathrm{d}x}{a(x+\frac1a)^2+g}$$ Where $g=a-\frac1a$ . With the right trigonometric substitution, $$P'(a)=\frac1{\sqrt{a^2+1}}\int_{x_1}^{\pi/2}\mathrm{d}x$$ Where $x_1=\arctan\frac1{\sqrt{a^2+1}}$ . Then using $$\arctan\frac1x=\frac\pi2-\arctan x$$ We have that $$P'(a)=\frac1{\sqrt{a^2+1}}\arctan\sqrt{a^2+1}$$ So we end up with something I don't know how to to deal with (what a surprise) $$P(a)=\int\arctan\sqrt{a^2+1}\frac{\mathrm{d}a}{\sqrt{a^2+1}}$$ Could you help me out with this last one? Thanks.","['integration', 'definite-integrals', 'closed-form']"
3044701,Proving identity generalizing $\frac1{(a-b)(a-c)}+\frac1{(b-a)(b-c)} + \frac1{(c-a)(c-b)} = 0$,"It is simple to see $\frac{1}{a-b} + \frac{1}{b-a}=0$ and $\frac1{(a-b)(a-c)}+\frac1{(b-a)(b-c)} + \frac1{(c-a)(c-b)} = 0$ , but the generalization $$
\sum_{j=1}^n \frac{1}{(a_j-a_1) \cdots \widehat{(a_j-a_j)} \cdots (a_j-a_n)}=0$$ where the hat denotes omission, isn't as simple for me. I was unable to prove by induction. I also tried to show the derivative w.r.t. each $a_i$ vanishes, but this too is difficult. I've also tried to relate this to the determinant of a matrix with entries of the form $1/(a_i-a_j)$ but this didn't get me anywhere. Any help would be much appreciated.","['functions', 'combinatorics']"
3044716,Prove that $tr(A)^p = tr(A^p)\bmod p$ where $A$ is a square integer matrix and $p$ is a prime number.,"I'm looking for an elementary proof (one which does not use Galois theory). For the case $p = 3$ , we have that $tr(A^3) = tr(A)^3 - 3e_1e_2 + 3e_3$ where the $e_i$ are coefficients of the characterstic polynomial of $A$ , and are thus integers, so the result follows. I cannot see a way to generalize this for arbitrary $p$ . Any help would be great!","['matrices', 'trace', 'linear-algebra', 'modular-arithmetic']"
3044726,"Determine the limit, or show it doesn't exist: $\lim_{x\to 2} \left(\arctan\left(\frac{1}{2-x}\right)\right)^2$","Determine the limit of the following or prove it doesn't exist: $$\lim_{x\to 2} \left(\arctan\left(\frac{1}{2-x}\right)\right)^2$$ If I just plug in the value of $x$ , I get an undefined expression. But, unfortunately, I don't see how to expand this limit to either see it doesn't exist or get a value. Any help would be much appreciated.","['limits', 'calculus', 'trigonometry']"
3044775,Maximum Area Covered by an S-Shaped Tiling,"Define an s-tile as a path of squares that makes two turns in opposite directions. For instance, if one chooses the lower left corner, the middle square of the bottom side, the center, and the middle square of the right hand side of a 3 by 3 square, one has an s-tile (starting from the lower left, you turn left first to get to the center, then right to get to the middle square on the right edge).s-tiles must have length at least 4. If a 1000 by 1000 grid is tiled with s-tiles only, what is the maximum area that can be covered? My take: there is the tiling that just leaves $999 \cdot 2$ squares alone, where the leftmost and rightmost edges of the grid are not tiled except for one square on them. I doubt that this is optimal, and I have no clue how to find an optimal tiling.","['puzzle', 'combinatorics', 'discrete-mathematics', 'optimization', 'tiling']"
3044794,Lattice point problem,A lattice point in the plane is a point with integer coordinates.Suppose that circles with radius r are drawn using all lattice points as centres.Find the smallest value of r such that any line with slope 2/5 intersects some of the circles,"['trigonometry', 'geometry']"
3044810,Is there a connection between $\zeta(-1)$ and Ramanujan's calculation of the sum over $\mathbb{N}$?,"Let me elaborate a little on the matter that I've been mulling over for a little while. This essentially concerns the summation of $1+2+3+...$ , how it equals $-1/12$ (in a certain sense, obviously not normal circumstances), and how this seems to strangely coincide with the Riemann zeta function at $s=-1$ . I'm essentially concerned over whether this is a coincidence, or if there's something deeper at play here. It would certainly strike me as one heck of a coincidence. I'll elaborate a bit for those unfamiliar with these matters... The Value of $\zeta(-1)$ : We know, for $s \in \mathbb{C}$ , with $Re(s)>1$ , we can define the Riemann zeta function by $$\zeta(s) = \sum_{n=1}^\infty \frac{1}{n^s}$$ This can be analytically continued to the entirety of the complex plane, giving a definition of the function for $Re(s)<1, s\neq1$ : $$\zeta(s) = 2^s \pi^{s-1} \sin\left(\frac{\pi s}{2} \right) \Gamma (1-s) \zeta(1-s)$$ Through this and the known result $\zeta(2)=\pi^2/6$ we can see that $$\zeta(-1) = 2^{-1} \pi^{-1-1} \sin\left(\frac{\pi (-1)}{2} \right) \Gamma (1-(-1)) \zeta(1-(-1)) = \frac{1}{2} \left( \frac{1}{\pi^2} \right)(-1)(1)\left(\frac{\pi^2}{6}\right)=\frac{-1}{12}$$ We also know that people - often mistakenly - claim $1+2+3+4+...=-1/12$ through this result, since the summation of the natural numbers appears if you plug in $s=-1$ into the original sum, $\sum n^{-s}$ . This obviously isn't true - mistake aside, at least in what we consider the ""usual topology of $\mathbb{R}$ "", the summation $1+2+3+...$ doesn't converge in The limit of its partial sums (which are the triangle numbers) The limit of the averages of its partial sums (Cesaro summation) Through Abel summation (per Wikipedia - I don't really know of this myself) ...and apparently a number of other summation methods (again, according to Wikipedia; I'm only familiar with the first two methods). Yet, interestingly... Ramanujan's Summation of $1+2+3+...$ : Now, we know that in, the usual sense, we cannot assign a value to an obviously divergent series. For example, we cannot say $\sum a_n = x$ if this summation is divergent, and then perform manipulations on that as if it had a value, and try to deduce whatever $x$ is. This doesn't always have to hold, just in the sense of the usual topology of the real numbers. (At least, this is what I was told by Thomas Andrews in the comments of an semi-related question here - related in the sense that it dealt with an ""obviously divergent"" product. I honestly don't know much about topologies.) I take this to mean that we can assign values to these ""obviously divergent in the usual sense"" summations, but it changes the context, the framework in which we're working. So Ramanujan was essentially doing that, in a certain sense - implicitly considering an alternate topology of the reals, in which the summation over the naturals could be assigned a value $c$ , i.e. $$c = \sum_{n=1}^\infty n = 1+2+3+4+...$$ and then manipulating $c$ to try and determine its value. (At least, that's what he might have been doing, I'm not sure. He could've just been ignoring the topologies altogether and just seeing what he could do. Either way...) Subtracting $4c$ from $c$ , he obtained $$-3c = 1-2+3-4+5-6+...$$ This summation is the expansion of the power series for $(1+x)^{-2}$ and thus, taking $x=1$ , Ramanujan obtains $$-3c = \frac{1}{(1+1)^2} = \frac{1}{4} \;\;\; \Rightarrow \;\;\; c = \frac{-1}{12}$$ So, The Question, and What I've Found: So, by using the zeta function, we can show that $\zeta(-1) = -1/12$ . Erroneously, people claim this as the sum of the natural numbers, but interestingly enough, Ramanujan showed that, if you can assign the divergent sum of the naturals a value, then it coincidentally is $-1/12$ . So, is there a connection between the Riemann zeta function - in particular its value at $s=-1$ - and Ramanujan's method of summing over the naturals? Is a mere coincidence? And in particular, why does Ramanujan's summation yield the same result? I'm not really sure where to begin looking into this. Ramanujan's summation introduces the notion of a different topology on the reals, but I've never had a proper introduction into topology so I'm a bit loathe to go into learning a whole subject to understand a connection that might not even exist. I did find that a Wikiepdia article on the summation $1+2+3+...$ kinda touches on a possible connection but I don't really buy it. (In the section on zeta function regularization, it suddenly starts considering the Riemann zeta function instead of the summation which seems more like a ""similar but related"" thing than establishing a proper connection.) I mean, I understand where we're coming from in zeta function regularization , and I can sort of see it. We consider the summation over the naturals as a special case of the Riemann zeta function, then associate the value of the summation with the value of the zeta function there, or its analytic continuation if applicable. I can get that. But it doesn't answer what I feel is the heart of my question: I think more than anything, my big question is... Ramanujan's method relied nothing on ""regularization"" or ""zeta functions"" or any of this higher level stuff. He just assumed the summation had a value, and manipulated the summation to find that value. Yes, it broke some assumptions about the topology of the reals - that I myself don't understand well - yet somehow got the same answer that this regularization and all that would. How is it right? What is the connection? The ""obviously wrong"" method somehow got the right answer. I mean, sure, it's right in the sense of the topology of the reals in which these manipulations are valid, but it's wrong in the usual sense. Yet it achieves the right answer. So I think my biggest question is why it's correct. Coincidence? Perhaps the zeta function relies on likewise assumptions of topology that I've just not known about? I'm not really sure where to go from here; as it is my research is already broaching topics I know little to nothing about.","['divergent-series', 'natural-numbers', 'sequences-and-series', 'riemann-zeta', 'zeta-functions']"
3044849,A mistake I can't find about the Bochner formula,"Let $(M^n,g)$ be a Riemannian manifold, and $T$ a symmetric $(1,1)$ -tensor field, i.e., $\langle T(X),Y\rangle = \langle X,T(Y)\rangle $ . For convenience, denote $$\Delta_Tu=\sum_i\langle \nabla_{e_i}\nabla u, Te_i\rangle $$ and $$\mathrm{Ric}_T(X,Y)=\sum_i\langle R(X,e_i)(Te_i), Y\rangle , $$ where $u$ is a smooth function on $M$ and $\{e_i\}$ is a local ON frame field. Now assume that $T$ is a Codazzi operator, i.e., for any $X,Y\in \Gamma(TM)$ , $(\nabla_XT)Y=(\nabla_YT)X$ . We choose $\{e_i\}_{i=1}^n$ be a local orthonormal frame field of $M$ such that $\nabla_{\star }e_i=0$ at the considered point. For the distance function r(x) from a fixed point $x_0$ , by the definition, we have ( $\nabla_XT$ is symmetric since $T$ is symmetric) \begin{equation*}
    \begin{split}
      \Delta_{\nabla_{\partial_r}T}r=&\sum_{i=1}^n\langle \nabla_{e_i}\partial_r,(\nabla_{\partial_r}T)e_i\rangle=\sum_{i=1}^n\langle \nabla_{e_i}\partial_r,(\nabla_{e_i}T)\partial_r\rangle \\
      =&\sum_{i=1}^ne_i\langle \partial_r,(\nabla_{e_i}T)\partial_r\rangle -\sum_{i=1}^n\langle \partial_r,(\nabla_{e_i}\nabla_{e_i}T)\partial_r\rangle -\sum_{i=1}^n\langle \partial_r,(\nabla_{e_i}T)(\nabla_{e_i}\partial_r)\rangle .
    \end{split}
  \end{equation*} However, \begin{equation*}
    \begin{split}
      \sum_{i=1}^n\langle \partial_r,(\nabla_{e_i}T)(\nabla_{e_i}\partial_r)\rangle =&\sum_{i=1}^n\langle (\nabla_{e_i}T)\partial_r,\nabla_{e_i}\partial_r\rangle \\
      =&\sum_{i=1}^n\langle (\nabla_{\partial_r}T)e_i,\nabla_{e_i}\partial_r\rangle =\Delta_{\nabla_{\partial_r}T}r.
    \end{split}
  \end{equation*} Hence, we obtain \begin{equation}
    \begin{split}
      \Delta_{\nabla_{\partial_r}T}r=\frac{1}{2}\sum_{i=1}^ne_i\langle \partial_r,(\nabla_{e_i}T)\partial_r\rangle -\frac{1}{2}\sum_{i=1}^n\langle \partial_r,(\nabla_{e_i}\nabla_{e_i}T)\partial_r\rangle 
    \end{split}
  \end{equation} We now compute the two terms of the R.H.S. of the above equality. Firstly, notice that $\nabla_{\partial_r}\partial_r=0$ , we have \begin{equation}
    \begin{split}
      \sum_{i=1}^ne_i\langle \partial_r,(\nabla_{e_i}T)\partial_r\rangle =&\sum_{i=1}^ne_i\langle \partial_r,(\nabla_{\partial_r}T)e_i\rangle =\sum_{i=1}^ne_i\langle (\nabla_{\partial_r}T)\partial_r,e_i\rangle \\
      =&\sum_{i=1}^ne_i (\partial_r\langle T\partial_r, e_i\rangle )-\sum_{i=1}^ne_i\langle T\partial_r,\nabla_{\partial_r}e_i\rangle \\
      =&\sum_{i=1}^n\partial_r(e_i\langle T\partial_r,e_i\rangle )-\sum_{i=1}^n\langle T\partial_r, \nabla_{e_i}\nabla_{\partial_r}e_i\rangle \\ 
      =&\sum_{i=1}^n\partial_r\langle (\nabla_{e_i}T)\partial_r,e_i\rangle +\sum_{i=1}^n\partial_r\langle T\nabla_{e_i}\partial_r, e_i\rangle \\
       &+\sum_{i=1}^n\partial_r\langle T\partial_r,\nabla_{e_i}e_i\rangle -\sum_{i=1}^n\langle T\partial_r, \nabla_{e_i}\nabla_{\partial_r}e_i\rangle \\
      =&\sum_{i=1}^n\langle (\nabla_{\partial_r}\nabla_{e_i}T)\partial_r,e_i\rangle +\partial_r(\Delta_Tr)\\
       &+\sum_{i=1}^n\langle T\partial_r,\nabla_{\partial_r}\nabla_{e_i}e_i\rangle -\sum_{i=1}^n\langle T\partial_r, \nabla_{e_i}\nabla_{\partial_r}e_i\rangle \\
      =&\sum_{i=1}^n\langle (\nabla_{\partial_r}\nabla_{e_i}T)\partial_r,e_i\rangle +\partial_r(\Delta_Tr)+\mathrm{Ric}(\partial_r, T\partial_r).
    \end{split}
  \end{equation} Secondly, \begin{equation}
    \begin{split}
      \sum_{i=1}^n\langle \partial_r,(\nabla_{e_i}\nabla_{e_i}T)\partial_r\rangle =&\sum_{i=1}^n\langle \partial_r,\nabla_{e_i}((\nabla_{e_i}T)\partial_r)\rangle -\sum_{i=1}^n\langle \partial_r,(\nabla_{e_i}T)\nabla_{e_i}\partial_r\rangle \\
      =& \sum_{i=1}^n\langle \partial_r,\nabla_{e_i}((\nabla_{\partial_r}T)e_i)\rangle -\sum_{i=1}^n\langle \partial_r,(\nabla_{\nabla_{e_i}\partial_r}T)e_i\rangle \\
      =&\sum_{i=1}^n\langle (\nabla_{e_i}\nabla_{\partial_r}T)e_i-(\nabla_{\nabla_{e_i}\partial_r}T)e_i,\partial_r\rangle \\
      =&\sum_{i=1}^n\langle (\nabla_{\partial_r}\nabla_{e_i}T)e_i,\partial_r\rangle -\sum_{i=1}^n\langle (R(\partial_r,e_i)T)e_i,\partial_r\rangle \\
      =&\sum_{i=1}^n\langle (\nabla_{\partial_r}\nabla_{e_i}T)e_i,\partial_r\rangle +\mathrm{Ric}(\partial_r,T\partial_r)-\mathrm{Ric}_T(\partial_r,\partial_r).
    \end{split}
  \end{equation} From the above three equalities we obtain \begin{equation*}
    \begin{split}
      \Delta_{\nabla_{\partial_r}T}r
      =\frac{1}{2}\partial_r(\Delta_Tr)
       +\frac{1}{2}\mathrm{Ric}_T(\partial_r,\partial_r).
    \end{split}
  \end{equation*} Now, my question is that when $T=\mathrm{Id}_{TM}$ the above equation becomes \begin{equation*}
    \begin{split}
    \partial_r(\Delta_r)+\mathrm{Ric}(\partial_r,\partial_r)=0.
    \end{split}
  \end{equation*} But it is well known that the Bochner formula for the distance function \begin{equation*}
    \begin{split}
    |\mathrm{Hess}r|^2+\partial_r(\Delta_r)+\mathrm{Ric}(\partial_r,\partial_r)=0.
    \end{split}
  \end{equation*} This obtain a contradiction. What is wrong with the above derivation? Thanks in advence.","['riemannian-geometry', 'differential-geometry']"
3044870,"Is every normable topological vector space ""inner productable""?","Not every norm on a vector space is induced by an inner product on that vector space.  But suppose hat $X$ is a topological vector space that is normable, i.e. its topology is induced by some norm on the vector space.  Then my question is, does that imply that $X$ is ""inner product-able"", i.e. that its topology is induced by some inner product on the vector space? If not, then what is an example of a topological vector space which is normable but not ""inner product-able""?  And what properties must a topological vector space satisfy to be ""inner product-able""?","['inner-products', 'normed-spaces', 'topological-vector-spaces', 'examples-counterexamples', 'general-topology']"
3044871,How many sequences can be made with 5 digits so that the difference between any two consecutive digits is $1$?,"Using the digits $0$ , $1$ , $2$ , $3$ , and $4$ , how many ten-digit sequences can be written so that the difference between any two consecutive digits is $1$ ? I was wondering if my solution is right. Let $a(n)$ be the number of $n$ digit sequences that end with $0$ or $4$ so that the difference between any two consecutive digits is $1$ . $b(n)$ be the number of n digit sequences that end with $1$ or $3$ so that the difference between any two consecutive digits is $1$ . $c(n)$ be the number of n digit sequences that end with $2$ so
that the difference between any two consecutive digits is $1$ . $x(n)$ be the number of n digit sequences so that the difference between any two consecutive digits is $1$ . $x(n) = a(n) + b(n) + c(n)$ $a(n) = b(n-1)$ $b(n) = a(n-1) + 2c(n-1)$ $c(n) = b(n-1)$ By substituting $a(n-1)$ and $c(n-1)$ in the formula for $b(n)$ we get $b(n) = 3b(n-2)$ We know that $b(1) = 2, b(2) = 4$ . The characteristic equation for this recursion is $x^2-3 = 0$ with have the roots $3^{1/2}$ and $-3^{1/2}$ , so $b(n) = A{(3^{1/2})}^{n} + B{(-3^{1/2})}^{n}$ where $A = {(3^{1/2}+2)}/{3}$ and $B = {(2-3^{1/2})}/{3}$ . I think this is an integer. We get $x(n) = 2b(n-1) + 3b(n-2)$ and by substituting we get something.","['solution-verification', 'combinatorics']"
3044894,Is there a name for $f\mapsto g\circ f\circ g^{-1}$?,"Let $H$ and $K$ sets, $f:H\to H$ a map and $g:H\to K$ a bijection. Then $g$ induces a map $f^g:K\to K$ by $f^g:=g\circ f\circ g^{-1}$ . Is there a name for the map $f\to f^g$ ? In the special case when $H$ is a group, $K=H$ and both $f$ and $g$ are automorphisms of $H$ then $f\to f^g$ is conjugation of $f$ by $g$ . But what is it in general? Induced map? Pushforward? Lifting?","['functions', 'terminology']"
3044929,$L^2$ norm of a matrix: Is this statement true?,"I am following Nocedal and Wright's Numerical Optimization book for self study. In the Appendix section of the book, the following matrix norms are defined: They defined the $l_2$ norm of the matrix $A$ as the largest eigenvalue of $(A^TA)^{1/2}$ . But I have also seen the following definition: $||A||_2 =\max_{i:n} \sqrt\lambda_i$ where $\lambda_i$ is the i. eigenvalue of the matrix $A^TA$ . (source: http://www.maths.lth.se/na/courses/FMN081/FMN081-06/lecture6.pdf ) I am not sure how these two definitions are equal. $A^TA$ is a symmetric positive definite matrix, hence it has positive eigenvalues. Assume that $\lambda_i$ is its largest eigenvalue. $A^TA$ has a unique positive definite square root with the eigenvalues $\sqrt{\lambda_i}$ . Considering only this PD square root matrix, Nocedal's definition is correct. But there can be other square root matrices of $A^TA$ as well, for which different eigenvalues are the largest. And if $A^TA$ has repeating eigenvalues, it will have infinitely many square roots. Hence I think there is an ambiguity in the Nocedal's definition. Am I missing something here? How can be the book's definition correct?","['spectral-norm', 'normed-spaces', 'matrices', 'linear-algebra', 'matrix-norms']"
3045043,Double Integral unequal after switching $dy$ and $dx$. Exact reasoning required,"I have worked out $\int_{[0,1]}(\int_{[0,1]}\frac{x^2-y^2}{(x^2+y^2)^2} d\lambda(x)) d\lambda (y)=-\frac{\pi}{4}$ and $\int_{[0,1]}(\int_{[0,1]}\frac{x^2-y^2}{(x^2+y^2)^2} d\lambda(y)) d\lambda (x)=\frac{\pi}{4}$ What should my exact reasoning be as to why the double integral does not exist according to $\lambda^2$ ? Should I argue along the lines of $\int_{[0,1]\times[0,1]}\frac{x^2-y^2}{(x^2+y^2)^2}d\lambda^2(x,y)$ not being well-defined as $\int_{[0,1]\times[0,1]}\frac{x^2-y^2}{(x^2+y^2)^2}d\lambda^2(x,y)=\int_{[0,1]}(\int_{[0,1]}\frac{x^2-y^2}{(x^2+y^2)^2} d\lambda(x)) d\lambda (y)=-\frac{\pi}{4}$ and $\int_{[0,1]\times[0,1]}\frac{x^2-y^2}{(x^2+y^2)^2}d\lambda^2(x,y)=\int_{[0,1]}(\int_{[0,1]}\frac{x^2-y^2}{(x^2+y^2)^2} d\lambda(y)) d\lambda (x)=\frac{\pi}{4}
$ But I am not sure on this argument.","['integration', 'multivariable-calculus', 'measure-theory', 'real-analysis']"
3045055,Permutations with Repetition (example),"Assume a box that contains $20$ colored balls. \begin{align}
&-Red: 2 \\
&-Blue: 1 \\
&-White: 4 \\
&-Orange: 3 \\
&-Black: 5 \\
&-Yellow: 2 \\
&-Green: 3
\end{align} The possible ways to put all those $20$ in order are: $$
N_{20}=\frac{20!}{2!1!4!3!5!2!3!}
$$ However, what if we want to pick only $5$ and put them in order? I tried picking ordered groups of $5$ out of $20$ but ended up double-counting. Any hints?","['permutations', 'combinatorics', 'discrete-mathematics']"
3045093,Computing the solution of an ODE using power series,"I have a system of ODEs defined on $\mathbb{R}\times\mathbb{S}$ , $$\begin{aligned}\dot{x}={ }&y\\\dot{y}={ }&-0.2y+\frac{300\cos(2)\sin(x)}{1.8(1.3+\cos(x-2))-2\sin(x)\sin(2)},\end{aligned}$$ This system has a saddle at $(0,0)$ and I want to compute the unstable manifold which is supposed to be pretty close to a homoclinic trajectory. So, I eliminate time, and solve the resulting DE \begin{equation}\frac{dy}{dx}=-0.2+\frac{1}{y}\frac{300\cos(2)\sin(x)}{1.8(1.3+\cos(x-2))-2\sin(x)\sin(2)}\tag{*}\end{equation} using power series $y(x)=a_1 x+a_2x^2+\dots+a_kx^k +\mathcal{O}(x^{k+1})$ for different $k$ . That is, I plug my $y(x)$ into (*) and compute the coefficents $a_i$ . I do so using symbolic mathematics, so there are shouldn't be any stupid mistakes (hopefully). My problem: For all $k>3$ , the solutions behave pretty well halfway to the point when it comes closer to the equilibrium. But then it diverge wildly from the expected trajectory. When I add more terms to the expansion (i.e., increase $k$ ), the divergence becomes even bigger. See the picture below. Using numerical simulation I got a solution that leaves $(0,0)$ and makes an arc toward $(2\pi,0)$ . In this sense, the best result seems to be given by either $k=3$ or $k=7$ , but they are still very far from what I expect. Following @LutzL's suggestion I tried to determine the radius of convergence of the power series expansion of the fraction in the second DE. The denominator does not have any real zeroes, so I computed a complex zero, but it does not restrict the radius of convergence: $x_0\approx -227.7655 + 3.15i$ . However, I'm not sure if this pole is unique.","['approximation-theory', 'ordinary-differential-equations', 'dynamical-systems']"
3045136,Using the functor of points approach to show a scheme theoretic construction exists,"T am trying to refram what I have learned in algebraic geometry in the context of the functor of points approach. In particular, I want to practice proving the existence of a scheme satisfying a certain universal property by showing a corresponding functor is representable. The most common example of this in textbooks is the fibered product of schemes. If $X \rightarrow S$ and $Y \rightarrow S$ are schemes over $S$ , then to show that the fibered product over $S$ exists is to show that the functor $$
\hom(-, X) \times_{\hom(-, S)} \hom(-Y)
$$ is representable. This is done by showing that the functor is covered by open representable subfunctors, and that the functor is a sheaf in the Zariski topology. The representing object is then the desired scheme. My problem is that this method doesn't seem to be very practical in the vast majority of cases. My understanding was that the functor of points approach was preferred in modern abstract algebraic geometry. The problem I am currently trying to do is to prove that the normalization of a scheme exists via this method. For the sake of keeping things simple, let's just look at integral schemes, and we will define ""normal"" to mean all the local rings are integrally closed domains. So let's say that $X$ is an integral scheme. I want to find some functor $$ F: \text{Sch}^{\text{op}} \longrightarrow \text{Set} $$ which captures the universal property. The universal property in this case will be something like ""a scheme $\tilde{X}$ over $X$ is called the normalization of $X$ if every dominant morphism morphism $Y \rightarrow X$ with $Y$ normal factors uniquely through $\tilde{X}$ "". My question is, how do I turn that into a representable functor? Clearly it must be possible, since every scheme can be realized that way. Is this just the wrong situation to use it in to make life easier? The universal property isn't even in terms of schemes over $X$ , but in terms of very specific types of schemes with dominant structure morphisms. So it seems any representability criterion will need to be modified. Is this even a sensible thing to be trying to do?","['algebraic-geometry', 'schemes', 'category-theory', 'representable-functor']"
3045155,"Proving that $B(X,Y) $ is a Banach Space if $Y$ is.","Let $B(X,Y)$ be the family of all bounded maps from $X$ to $Y,$ normed linear maps. Then, $B(X,Y) $ is a Banach Space if $Y$ is. Remark: I've seen this question before $Y$ is a Banach space if $B(X,Y)$ is a Banach space , but it is the converse of my question statement. MY TRIAL Let $T_n\in B(X,Y),\;\forall\;n\in \Bbb{N} $ s.t. $T_n\to T,\;\text{as}\;n\to\infty. $ So, $T_n\in B(X,Y),\;\forall\;n\in \Bbb{N} $ implies for each $x\in X,\;T_{n}(x)\in Y.$ Since $Y$ is complete, $T_n(x)\to T(x)\in Y,\;\text{as}\;n\to\infty,\;\forall\;x\in X. $ i.e., $T:X\to Y. $ Also, $T_n\in B(X,Y),\;\forall\;n\in \Bbb{N} $ implies there exists $K\geq 0,$ s.t. $\forall\;n\in \Bbb{N},\;\forall\;x\in X, $ \begin{align} \Vert T_n(x)\Vert \leq K \Vert x\Vert. \end{align} As $n\to\infty,$ \begin{align} \lim\limits_{n\to \infty}\Vert T_n(x)\Vert= \Vert \lim\limits_{n\to \infty}T_n(x)\Vert= \Vert T(x)\Vert\leq K \Vert x\Vert, \end{align} which implies $T\in B(X,Y)$ and hence, $ B(X,Y)$ is a Banach space. Please, kindly check if I'm right or wrong. If it turns out that I'm wrong, kindly provide an alternative proof. Regards!","['banach-spaces', 'normed-spaces', 'functional-analysis']"
3045191,"Proof verification that $\{x_n\} = 0,\underbrace{77\dots 7}_{\text{n times}}$ is a Cauchy sequence.","Given a sequence $\{x_n\}$ : $$
x_n =  0,\underbrace{77\dots 7}_{\text n\ times}
$$ Prove that $\{x_n\}$ is a Cauchy sequence. Recall the definition of a fundamental sequence: $$
x_n\ \text{is fundamental} \ \iff \forall \epsilon>0 \exists N\in \Bbb N: \forall n, m >N\implies |x_n - x_m| < \epsilon
$$ Rewrite $x_n$ : $$
x_n = {7\over 10^1} + {7\over 10^2} + \cdots + {7\over 10^n} = \sum_{k=1}^n \frac{7}{10^k}
$$ By geometric series sum: $$
x_n = \sum_{k=1}^n \frac{7}{10^k} = \frac{7}{9}\left(1 - {1\over 10^n}\right) \\
x_m = \sum_{k=1}^m \frac{7}{10^k} = \frac{7}{9}\left(1 - {1\over 10^m}\right) \\
$$ Suppose $m > n$ : $$
\begin{align}
|x_n - x_m| &= |x_m - x_n| = \\
&= \left|\frac{7}{9}\left(1 - {1\over 10^m}\right) - \frac{7}{9}\left(1 - {1\over 10^n}\right)\right| = \\
&= \left|\frac{7}{9}\left(1 - {1\over 10^m} - 1 + {1\over 10^n}\right)\right| =
\\
&= \left|\frac{7}{9}\left({1\over 10^n} - {1\over 10^m}\right)\right| \le \left|\frac{7}{9}{1\over 10^n}\right| \le \frac{7}{9\cdot 10^N} < \epsilon
\end{align}
$$ This shows we've found $N$ which depends on $\epsilon$ and satisfies the definition of a Cauchy sequence. This is the first time I'm dealing with proving a sequence is fundamental, could someone please verify whether my proof is valid?","['cauchy-sequences', 'proof-verification', 'calculus', 'sequences-and-series', 'limits']"
3045192,Does $\frac{\dot y}{\dot x}=\frac{dy}{dx}$ always work?,"Let consider the system: $$\begin{cases}\dot x=x\\ \dot y=-y+x^2.\end{cases}$$ To solve this system, my teacher made: $$\frac{dy}{dx}=\frac{dy}{dt}\frac{dt}{dx}=(-y+x^2)\frac{1}{dx/dt}=(-y+x^2)\frac{1}{x}.$$ And thus $y(x)=\frac{x^2}{3}+\frac{c}{x}.$ Question:  Does this method always work? And if yes why? Because I have the impression that it really simplify the problem, and I know that: $$\frac{dy}{dt}\frac{dt}{dx}=\frac{dy}{dx}$$ is not always true as this can show . So why does it work here ?","['derivatives', 'ordinary-differential-equations']"
3045202,Totally bounded and closed implies compact??,"Is there a fault in exercice 9.3.1 b) from Analysis by Zorich? The exercice asks to prove that a subset of a metric space is compact if and only if it is totally bounded and closed. But I have a counterexample for it: Consider the open unit ball $B(0,1)$ in $\mathbb{R}^n$ as a metric space itself. Then it is closed in itself and totally bounded, but not compact. Am I right?","['general-topology', 'analysis']"
3045218,How to arrive at $(f'(x))^2<2f(x)$?,"Let we see a problem ahead of I asking what I want to ask. Define $f:\mathbb{R}\to(0,+\infty)$ differentiable satisfying $|f'(x)-f'(y)|\le|x-y|\,\, \forall x,y\in\mathbb{R}$ . Prove: $(f'(x))^2<2f(x)$ I came up with a proof which is as follows: In order to make the proof more rigorous, we pointed out in advance that $f'$ is (uniformly) continuous. 1. $\,$ If $f'(x)=0$ . Then through $f>0$ we arrive at the conclusion. 2. $\,$ If $f'(x)>0$ . $\,\,\,$ Let $x_0=x-f'(x)$ . so $f(x)=\int_{x_0}^{x}f'(t)\,dt+f(x_0)>\int_{x_0}^{x}f'(t)\,dt\ge\int_{x_0}^{x}(f'(x)+t-x)\,dt=\frac{1}{2}(f'(x))^2$ 3. $\,$ If $f'(x)<0$ . $\,\,\,$ Let $x_0=x-f'(x)$ . so $f(x)=f(x_0)-\int_{x}^{x_0}f'(t)\,dt>\int_{x}^{x_0}-f'(t)\,dt\ge\int_{x}^{x_0}(-f'(x)+x-t)\,dt=\frac{1}{2}(f'(x))^2$ Actually I got stuck on how to arrive at $(f'(x))^2<2f(x)$ . I thought $f(x)$ is influenced by $f'(t)$ where $t$ is around $x$ , so I came up with the proof as mentioned above. But at the same time I thought that for the similar questions such as $f(x)>f'(x)$ we can construct the auxiliary function $g(x)=\frac{f(x)}{e^x}$ . So what I really want to ask is how to arrive at $(f'(x))^2<2f(x)$ ? I thought this maybe relates to the solution of $(f'(x))^2=2f(x)$ . What's more, any new ideas for the above problem are welcomed. Thank you in advance!","['ordinary-differential-equations', 'real-analysis']"
3045282,Find the value of $1-\frac{1}{7}+\frac{1}{9}-\frac{1}{15}+\frac{1}{17}-\frac{1}{23}+\frac{1}{25}....$,Find the value of  this : $$1-\frac{1}{7}+\frac{1}{9}-\frac{1}{15}+\frac{1}{17}-\frac{1}{23}+\frac{1}{25}....$$ Try: We can write the above series as $${S} = \int^{1}_{0}\bigg[1-x^6+x^8-x^{14}+x^{16}-x^{22}+\cdots\bigg]dx$$ $$S = \int^{1}_{0}(1-x^6)\bigg[1+x^{8}+x^{16}+\cdots \cdots \bigg]dx$$ So $$S = \int^{1}_{0}\frac{1-x^6}{1-x^{8}}dx = \int^{1}_{0}\frac{x^4+x^2+1}{(x^2+1)(x^4+1)}dx$$ Now i am struck in that integration. Did not understand how to solve it could some help me to solve it. Thanks in advance,"['integration', 'definite-integrals', 'sequences-and-series']"
3045309,Is there a canonical extension of Euler's totient function to the reals?,"Assumption: if a set $X\times Y$ , exists such that $\forall\textbf{u},\textbf{v}\in X\times Y. \left(u_1=v_1\implies u_2=v_2\right)$ , then a function $f$ exists such that $f:X\to Y$ . The set of points $\Phi_\mathbb{N}=\left\{(n,\phi(n))\mid n\in\mathbb{N}\right\}$ describing the graph/image of the totient function is a subset of the reals. By definition, $\forall \textbf{x},\textbf{y}\in\mathbb{R}^2$ , where $x_1< y_1.\exists \textbf{z}\in\mathbb{R}^2:x_1<z_1<y_1$ . Thus, there is a continuous set of points between any two $\textbf{a},\textbf{b}\in\Phi_\mathbb{N}$ . It follows, that there is a a set $\Phi_\mathbb{R}\supset\Phi_\mathbb{N}$ which is the graph of a continuous function $\phi:\mathbb{R}\to\mathbb{R}$ , ( $n\in\mathbb{N}\implies \phi(n)\in\mathbb{N}$ ). Thus, it is at least possible to extend the totient function to the reals without breaking the original definition. Is there a canonical way to do this? If not, what is the most appropriate way to extend the totient function? Note: An extension to the complex numbers is perfectly acceptable too, I just assumed it would be best to ""keep it real"". Note: tagged analysis because that's where I'm going with this. Edit: This might help... probably not, though For coprime $a$ and $n$ $$a^{\phi(n)}\equiv1\mod{n}\qquad\text{(Euler's Theorem)}$$ For $x,y\in\mathbb{R}$ $$x\ \text{mod}\ y^{*}=\frac{|x|}{2\pi}\sum_{k=1}^\infty\frac{1}{k}\Im\left[\exp\left(\frac{2\pi kix}{y}\right)\right]$$ So $$a^{\phi(n)}\ \text{mod}\ n=\frac{|a^{\phi(n)}|}{2\pi}\sum_{k=1}^\infty\frac{1}{k}\Im\left[\exp\left(\frac{2\pi kia^{\phi(n)}}{n}\right)\right]=1\implies$$ $$|a^{\phi(n)}|=2\pi\left(\sum_{k=1}^\infty\frac{1}{k}\Im\left[\exp\left(\frac{2\pi kia^{\phi(n)}}{n}\right)\right]\right)^{-1}=$$ $$-4\pi i\left(\ln\left(1-\exp\left(\frac{2\pi ia^{\phi(n)}}{n}\right)\right)-\ln\left(\exp\left(-\frac{2\pi ia^{\phi(n)}}{n}\right)\left(-1+\exp\left(\frac{2\pi ia^{\phi(n)}}{n}\right)\right)\right)\right)^{-1}$$ Assuming $a^{\phi(n)}$ is positive, let $a^\phi(n)=u$ (because I'm running out of space) $$u=-4\pi i\left(\ln\left(1-\exp\left(\frac{2\pi iu}{n}\right)\right)-\ln\left(\exp\left(-\frac{2\pi iu}{n}\right)\left(-1+\exp\left(\frac{2\pi iu}{n}\right)\right)\right)\right)^{-1}$$ Solve for for $u$ (not sure how), then substitute $a^{\phi(n)}$ back in and take the base- $a$ logarithm to get $\phi(n)$ Assuming all the algebra is correct, this might work... $^*$ If I understand correctly, we can translate $x\equiv z\mod{y}$ to $x\ \text{mod}\ y=z$ , using $\text{mod}$ as a binary operation.","['complex-analysis', 'number-theory', 'totient-function', 'real-analysis']"
3045323,When is a topological vector space “inner product-able”?,"This is a follow-up to my question here .  A topological vector space is normable, i.e. its topology is induced by some norm on the vector space, if and only if it is Hausdorff and the $0$ vector has a bounded convex neighborhood.  My question is, under what circumstances is a topological vector space “inner product-able”, i.e. when is its topology induced by some inner product on the vector space? Note that this is not the same as asking under what circumstances a norm is induced by some inner product.  The answer to that question is when the norm obeys the parallelogram law.  But we could have a situation where the topology is induced by multiple norms, one which is not induced by any inner product and another which is induced by some inner product.  In any case, another way to phrase my question is, under what circumstances is a given norm equivalent to some norm obeying the parallelogram law?","['inner-products', 'normed-spaces', 'topological-vector-spaces', 'examples-counterexamples', 'general-topology']"
3045325,"How to ensure when the derivative approaches zero, the integral approaches a constant?","I asked a very similar question here . But now this is different. Suppose $f(t)$ is differentiable and $c$ is a finite constant, then the following statement looks correct, but in fact it is not: \begin{equation}
\lim\limits_{t \to \infty} f'(t) = 0 \implies \lim\limits_{t \to \infty} f(t)=c 
\end{equation} A counter-example is $f(t)=\ln(t)$ . Now the question is, what condition should be used for the above statement to be true?","['derivatives', 'real-analysis']"
3045416,Does every subgroup of finite index contain a power of each element of the group?,"Let $G$ be a group, not necessarily finite. If $H$ is a normal subgroup of $G$ of a finite index, say $(G:H)=n$ , then for every $g\in G$ we have $g^n\in H$ . Does this statement remain valid if do not assume $H$ to be normal? In particular let $SL_2(\mathbb Z)$ be the modular group, and let $\Gamma\subset SL_2(\mathbb Z)$ be a subgroup of a finite index. Does there exists a positive integer $\ell$ such that $\begin{pmatrix}1&1\\0 & 1\end{pmatrix}^\ell$ lies in $\Gamma$ ?","['group-theory', 'modular-group']"
3045422,A route that passes through all streets of the city,"You are driving a car in a city with $N$ long, straight streets. No two streets are parallel so there is an intersection (crossroads) for each pair of streets. Each intersection has only two intersecting streets. No street has strict north-south direction. There is only one driving rule: when you reach the intersection you have to make a turn so that the next street takes you eastwards (north-east, east, south-east, does not matter). On a map, it means that you have to keep driving to the right side of the map. Prove that it is always possible to make a drive through the city that visits all the streets at least once. Here is a city with $N$ =6 streets. Some fairly complicated routes do not visit all the streets (blue route does not visit street $a$ . But the red route will take you through all streets. I tried to solve the problem in the following way: Each street consists of segments created by intersecting streets. I have assigned a collor to each street. Obviously, each street has 6 segments and I have represented each segment with a colored dot: Look at the ""long"" routes, i.e. routes starting from some west-most street segment. Each such route represents a sequence of segments (colored dots). There are 6 such routes, one for each street in the city: ...or, with the streets removed: I was able to conclude several things from the final graph: There are $N$ different colors (with exactly $N$ vertices having one color), $N$ polygonal chains, $N^2$ colored vertices. The chains do not intersect (this can be proved fairly easily) In a single chain, there are at least two vertices between any two vertices of the same color. This basically means that in any chain you will find 3 different colors for any four consecutive vertices. Based on that I still could not prove that one chain must have vertices with all possible colors. Which probably means that my approach is 100% wrong. But the problem is still interesting.","['graph-theory', 'discrete-mathematics']"
3045468,Finding the Laurent series (complex numbers),"I have $$
f(z)={\frac{1}{z(1-z)}}
$$ Need to find the Laurent series around $z=0, z=1, z=\infty$ .
I did $$
{\frac{1}{z(1-z)}} = {\frac{A}{z}}+{\frac{B}{1-z}}
$$ and found $A=1, B=1$ . Therefore we get $$
{\frac{1}{z}}+{\frac{1}{1-z}} = {\frac{1}{z}} + \sum z^n
$$ But in the book this is the answer only for $z=0$ . How should I find the answers for the other two? Thanks.","['complex-analysis', 'laurent-series', 'complex-numbers']"
3045473,Functions with $\mathrm s(x)^n+ \mathrm c(x)^n \equiv 1$,"I came across a very nice STEP question - Q8, STEP 1, 2018. It assumed the existence of function $\mathrm s(x)$ and $\mathrm c(x)$ with the properties that $\mathrm s(0)=0$ , $\mathrm c(0)=1$ , $\mathrm s'(x) = \mathrm c(x)^2$ and $\mathrm c'(x)=-\mathrm s(x)^2$ . This leads immediately to familiar formulae like $\mathrm s(x)^3+\mathrm c(x)^3 \equiv 1$ . These hypothetical functions can then be used, for example, to show that $$ \int \frac{\mathrm du}{(1-u^3)^{4/3}} = \frac{u}{(1-u^3)^{1/3}}+K$$ These hypothetical functions can also be used, for example, to show that $$\int (1-u^3)^{1/3}~\mathrm du = \frac{1}{2}\mathrm s^{-1}(u)+\frac{1}{2}u(1-u^3)^{1/3} + K$$ I have a few questions: Are their names for these functions $\mathrm s$ and $\mathrm c$ ? How do we prove the existence/continuity/differentiability of such functions? Are their function with $\mathrm s'(x) = \mathrm c(x)^{n-1}$ , $\mathrm c'(x) = -\mathrm s(x)^{n-1}$ Do they have names? How effective can it be to posit the existence of hypothetical functions which help to simplify integration?","['integration', 'functional-equations', 'special-functions', 'functions', 'indefinite-integrals']"
3045513,Measure and metric,"What, in simple terms, is the difference between a measure and a metric, and what applications require a measure rather than a metric, and vice versa? Examples would be great.","['measure-theory', 'definition', 'metric-spaces']"
3045535,Squaring is not an injective operation so why is it allowed? [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 5 years ago . Improve this question I do have a problem with squaring, lots of students do it escpecially when they have to solve things like $\sqrt x$ but i do not why. This maybe a dumb example but lets assume $-2=2 $ if I $(..)^2$ i would have $4=4$ which would be no contradiction","['algebra-precalculus', 'logic']"
3045561,General Solution for Partial Differential Equation,"To be honest I'm a bit lost on this, and I would like to get a hint or something that can help me, thanks.
I need to find the general solution $U(x,y,z)$ of the next equation: $$U_{xx}+U_{yy}+4U_{zz}-2U_{xy}+4U_{xz}-4U_{yz}=xyz$$ I know that most sure exists a change of variable that would help to solve the equation, but I don't know how to find it, our teacher of Multivariable Calculus asked to solve this.
Thanks!","['partial-derivative', 'multivariable-calculus']"
3045573,"If a function is uniformly continuous restricted to each line, is it globally uniformly continuous?","Question: Suppose $f: \mathbb{R}^2\to \mathbb{R}$ is a continuous function such that for every line $L$ passing through the origin $(0, 0)$ , the restriction of the function $f|_{L} : L\to\mathbb{R}$ is uniformly continuous (we can view $L\cong\mathbb{R}$ if we wish). Does it follow that $f$ is uniformly continuous? Motivation. A friend and I were discussing the following fact: If $f: \mathbb{R}^2\to\mathbb{R}$ has bounded partial derivatives, then $f$ is uniformly continuous. One way to prove this fact is to show that $f$ must be Lipschitz, i.e. $|f(x)-f(y)|\leq C |x-y|$ for some constant $C$ . My proof for the latter fact uses the following idea: take two points $x$ and $y$ in $\mathbb{R}^2$ , look at the line $L$ joining $x$ and $y$ , then restrict $f$ to $L\cong\mathbb{R}$ , and use the Mean Value Theorem for the function $f|_{L}$ . The derivative of $f|_{L}$ will be bounded, because it is a directional derivative of $f$ , which is a linear combination of the partial derivatives of $f$ , which are themselves bounded. While formulating this proof, I was naturally lead to ask the question above.","['multivariable-calculus', 'uniform-continuity', 'examples-counterexamples', 'real-analysis']"
3045611,Derivation of the Riemannian metric tensor,"Firstly, I would like to say that I didn't do a course in Riemannian geometry, so my doubt is probably something that is not clear for me from the basis of the Riemannian geometry, which I'm self-studying. I'm reading Interior estimates for hypersurfaces moving by mean curvature and I'm trying understand the statement: ""Now note that $\nabla u = \omega - \langle \nu , \omega \rangle$ and $\nabla (|\textbf{x}|^2 - u^2) = 2(\textbf{x} - \langle \textbf{x} , \nu \rangle \nu - u \nabla u)$ "", where $M$ is an hypersurface of dimension $n$ which evolves under Mean Curvature Flow by the immersion $F: M \times [0,T) \longrightarrow \mathbb{R}^{n+1}$ , $\textbf{x} = F(p,t)$ , $u := \langle \textbf{x} , \omega \rangle$ , $\nu$ is the normal unit vector and $\omega$ is a fixed vector on $\mathbb{R}^{n+1}$ such that $\langle \omega, \nu \rangle > 0$ . First, I think the authors wanted to write $\nabla u = \omega - \langle \nu, \omega \rangle \nu$ , i.e., $\nabla u$ it's the projection of $\omega$ on tangent space of $M$ . I tried compute $\nabla u$ and I found $\nabla u = \langle \nabla \textbf{x}, \omega \rangle$ , which is the length  of the projection of $\omega$ on tangent space of $M$ . I did this computation by the fact that $u$ is a function defined on $M$ , by the compatibility of the tensor metric, but I found some problems because my computation of $\nabla u$ doesn't match with the computation of $\nabla u$ did by the authors and the other problem is that the compatibility of the tensor metric it's relationed with the derivation of a function along to a vector field by relation $$\nabla_X \langle Y,Z \rangle = X \langle Y,Z \rangle = \langle \nabla_X Y,Z \rangle + \langle Y, \nabla_X Z \rangle,$$ but I don't have explicitly along what vector field $u$ is being differentiated. I think this vector field defined on $M$ is arbitrary and this explain why the direction was omitted in the differentiation of $u$ . I had these same problems when I tried compute $\nabla |\textbf{x}|^2$ by an analagous argument. I would like to know how compute $\nabla u$ and $\nabla |\textbf{x}|^2$ . Thanks in advance!","['riemannian-geometry', 'differential-geometry']"
3045717,Show that $f(a)=f(a-1).$,"Suppose that $f :[0,2]\rightarrow \mathbb{R}$ is a continuous function with $f(0)=f(2)$ . Show that there is a real number $a\in[1,2]$ with $f(a)=f(a-1)$ . For the answer I tried to apply the mean value theorem to the function $g(x)=\int_0^2f(t)dt$ in the interval $[0,2]$ but it didn't lead any where.","['calculus', 'analysis']"
3045755,Not $\sigma$-compact set without axiom of choice,"Today in measure theory, we introduced the concept of a $\sigma$ -compact set, which is a set which can be expressed as the countable union of compact sets. Since the set of $\sigma$ -compact sets seemed to be very large (I couldn't think of a not $\sigma$ -compact set), I asked for a set which is not $\sigma$ -compact, but our instructor couldn't come up with a set, which he didn't have to explicitly construct with the axiom of choice, for which we didn't have time. My question is if there is such an set which can be constructed without the axiom of choice.","['axiom-of-choice', 'measure-theory', 'compactness']"
3045794,Solve the system of equations in the set of real numbers.,"Solve the system of equations in the set of real numbers: $$\begin{cases} 
\frac1x + \frac1{y+z} = \frac13 \\ 
\frac1y + \frac1{x+z} = \frac15 \\
\frac1z + \frac1{x+y} = \frac17
\end{cases}$$ I got: $$\begin{cases}
3(x+y+z)=x(y+z) \\
5(x+y+z)=y(x+z) \\
7(x+y+z)=z(x+y)
\end{cases}$$ However, no matter how I continue from here, I always get $x=y=z=0$ , which cannot be true; or I get a new system of equations, but still with 3 variables (which I cannot solve). How can I solve this problem or how should I approach it?","['algebra-precalculus', 'systems-of-equations']"
3045807,$\iint f(x)g(y)dxdy =\int f(x)dx \int g(y)dy $ Why?,"$\iint f(x)g(y)dxdy =\int f(x)dx \int g(y)dy $ . How could this be proven I tried this with Fubini, so on the LHS we can think of $g(y)$ as constant and take it out of the integral and in the following step we can think ok $f(x)$ as a constant such. In other word $\int g(y) \big[\int f(x)dx\big]dy=\big[\int f(x)dx\big]\int g(y)dy$ . But I do not know how to come from $\int f(x)dx \int g(y)dy \Rightarrow\iint f(x)g(y)dxdy $ pls help","['multivariable-calculus', 'calculus']"
3045819,Can $27$ points be packed into a $3\times3\times3$ cube and all be more than $\sqrt{3}$ from one another?,"This problem comes from a math test which I've already completed. I'll give the problem and my attempt at a solution. Part A : Given a $3\times3\times3$ cube $C$ containing $28$ points. Prove that some pair of points is within $\sqrt{3}$ of each other. Part B : Describe a distribution of $27$ points in $C$ such that every point is more than $\sqrt{3}$ from each other point. Part A was simple: Begin by partitioning $C$ into $27\;1\times1\times1$ cubes. Picture a Rubik's cube: Then, by the pigeonhole principle, one small cube must contain $2$ points. The distance between these two points is at most $\sqrt{3}$ (since the largest Euclidean distance in the small cube is between opposite vertices, which is $\sqrt{1^2+1^2+1^2} = \sqrt{3}$ ). Therefore, some pair of points is within $\sqrt{3}$ of each other. Part B was less simple. On the test, I claimed that $14$ is the greatest number of points which can be packed into $C$ while satisfying the condition: Put one point on each of the vertices of $C$ for a total of $8$ points. If you draw a $3\times3$ square with circles of radius $\sqrt{3}$ coming off each vertex, you will see that there is only a small area not within any circle. This region includes the center of the square. This picture represents a view of any face of $C$ so far. Then, put one point on the center of each face of $C$ for $6$ more points. These points are legal. Based on our previous diagram, each face of $C$ cannot hold any more points. But can the very center? No. The distance from the center of $C$ to the center of any of its faces is $1.5$ . We have now placed $14$ points. I believe we placed them with an optimal strategy, so I think that $15$ (and everything greater) is impossible. My attempt at Part B does not rigorously prove that $14$ is the maximum, so my questions are: Is this task possible with $27$ points? If so, how? If not, what is the maximum, and how can you prove it?","['discrete-mathematics', 'packing-problem']"
3045867,Solving $\int\limits_{-\infty}^\infty \frac{1}{x^8+1}dx$ through Glasser's Master Theorem,"Trying to find a way to solve $$\int_{-\infty}^\infty \frac{1}{x^8+1}dx$$ through Glasser's Master Theorem, more specifically the Cauchy–Schlömilch substitution. Preferably, I'm looking for the closed form solution, and I am already aware of how to attain this through contour integration. Solution: $$\frac{\pi}{4\sin(\frac{\pi}{8})}$$ Link to general closed form solution: solutions to $\int_{-\infty}^\infty \frac{1}{x^n+1}dx$ for even $n$","['integration', 'improper-integrals', 'definite-integrals', 'closed-form']"
3045910,How to implement an insurance risk model,"So the problem goes as follows: ""Suppose that the different policyholders of a casualty insurance company generate claims according to independent Poisson processes with a common rate $λ$ , and that each claim amount has distribution $F$ . Suppose also that new customers sign up according to a Poisson process with rate $ν$ , and that each existing policyholder remains with the company for an exponentially distributed time with rate $μ$ . Finally, suppose that each policyholder pays the insurance firm at a fixed rate $c$ per unit time. Starting with $n_{0}$ customers and initial capital $a_{0} \geq 0$ , we are interested in using simulation to estimate the probability that the firm’s capital is always nonnegative at all times up to time T ."" Well to simulate the preceding, we define the variables and events as follows: Time Variable : $t$ System State Variable : $(n, a)$ , where $n$ is the number of policyholders and $a$ is the firm’s current capital. Events : There are three types of events: a new policyholder, a lost policyholder, and a claim. The event list consists of a single value, equal to the time at which the next event occurs. EL : $t_{E}$ We are able to have the event list consist solely of the time of the next event
because of results about exponential random variables. Specifically, if $(n, a)$ is the system state at time t then, because the minimum of independent exponential random variables is also exponential, the time at which the next event occurs will equal $t + X$ , where $X$ is an exponential random variable with rate $ν +nμ+nλ$ . Moreover, no matter when this next event occurs, it will result from A new policyholder, with probability $\frac{v}{ν +nμ+nλ}$ A lost policyholder, with probability $\frac{nμ}{ν +nμ+nλ}$ A claim, with probability $\frac{nλ}{ν +nμ+nλ}$ After determining when the next event occurs, we generate a random number to determine which of the three possibilities caused the event, and then use this
information to determine the new value of the system state variable. In the following, for given state variable $(n, a)$ , $X$ will be an exponential random variable with rate $ν + nμ + nλ$ ; $J$ will be a random variable equal to $1$ with probability $\frac{v}{ν +nμ+nλ}$ , to $2$ with probability $\frac{nμ}{ν +nμ+nλ}$ , or to $3$ with probability $\frac{nλ}{ν +nμ+nλ}$ ; $Y$ will be a random variable having the claim distribution F. Output Variable : $I$ , where $I=1$ , if the firm’s capital is nonnegative throughout $[0,t]$ $I=0$ , otherwise Thinking of the algorithm it will look something like this: Initialize First initialize t = 0, a = a0, n = n0 then generate X and initialize t_E = X To update the system we move along to the next event, first checking whether it takes us past time T . Update Step Case 1: t_e > T : Set I = 1 and end this run. Case 2: t_e <= T : Reset a = a + nc(t_e − t) and t = t_e Generate $J$ : If J = 1 : reset n = n + 1 then if J = 2 : reset n = n − 1 then if J = 3 : Generate $Y$ . if Y > a , set I = 0 and end this run; otherwise
reset a = a − Y Generate $X$ : reset t_e = t + X The update step is then continually repeated until a run is completed. So far I think this could work, but since I'm not closely familiar with actuarial science (and insurance companies in general) my questions are: What values for $a_{0}$ and $n_{0}$ are the most suitable (realistic) for this model in actuarial science? What distributions $F$ for my $Y$ RV  are common and uncommon in this field? What range and in wich units of time $[0,t]$ are generally used to test models like this? My goal is to simulate this model on python and compare if changing the distributions or rates around could determine whether this company go bankruptcy or stays with a nonnegative capital over a defined time. PS: Please let me know what else should be taking in cosideration. Is this is just a trial and error problem (change values, variables, distribution, etc to look for a change in the end result)?.","['actuarial-science', 'statistics', 'simulation']"
3045933,"What finite non-abelian group is generated by $\operatorname{diag}(1,w,w^2,\ldots,w^{N-1})$ (with $w=e^{2\pi i/N}$) and a cyclic permutation matrix?","What is the finite nonabelian group? generated by the following elements and satifies the rules: $$A=\left(\begin{array}{ccccc}
1&0&0&\cdots&0\\
0&\omega&0&\cdots&0\\
0&0&\omega^2&\cdots &0\\
\vdots&\vdots&\vdots& &\vdots\\
0&0&0&\cdots&\omega^{N-1}
\end{array}\right)$$ where $\omega^{N}=1$ and $\omega = e^{2\pi i/N}$ . $$B=\left(\begin{array}{ccccc}
0&1&0&\cdots&0\\
0&0&1&\cdots&0\\
 \vdots&\vdots &\vdots & \ddots &\vdots\\
0&0&0&\cdots&1\\
1&0&0&\cdots&0
\end{array}\right)$$ $$AB=\omega \;BA$$ (or $AB=\omega^{-1} \;BA$ ) It looks like this nonabelian group has an order $N^3$ at least. Because $$
A^N=B^N=\omega^N=1,
$$ and all elements of these are distinct. When $N=2$ , the answer of this  nonabelian group seems to be a quaternion group of order $2^3=8$ .","['finitely-generated', 'group-theory', 'abstract-algebra', 'finite-groups']"
3045942,$\lim _{x\rightarrow c}f(x)=L$ if and only if $\lim_{x\rightarrow0}f(x+c)=L$,"Let $f:= \mathbb{R}\to\mathbb{R}$ and let $c\in\mathbb{R}$ . Show that $\lim _{x\rightarrow c}f(x)=L$ if and only if $\lim_{x\rightarrow0}f(x+c)=L$ . From the definition of limit, we get that it is enough to show: $\forall$ $\varepsilon>0$ $\exists$ $\delta>0$ s.t. if $|x-c|<\delta$ then $|f(x)-L|<\varepsilon$ $\Leftrightarrow$ $\forall$ $\varepsilon_0>0$ $\exists$ $\delta_0>0$ s.t. if $|x|<\delta_0$ then $|f(x+c)-L|<\varepsilon_0$ I can replace $x$ by $x+c$ everywhere in statement for the if $(\Rightarrow)$ part. But, I am not sure this is the correct method. What I need to do is manipulate the inequalities in each to get the other. But, I am not sure how to proceed with that.","['limits', 'analysis', 'real-analysis']"
3045951,Request for help to find a closed-form expression for $\sum_{n=0}^{\infty}\frac{(2n+15)^2}{(2n+11)^3\sqrt{(2n+13)}}$,"By the comparison test, the series converges. $$\sum_{n=0}^{\infty}\frac{(2n+15)^2}{(2n+11)^3\sqrt{(2n+13)}}=l$$ $$l\simeq0.39483198670640570922670209458869656945532664947383304288146572043505953641$$ (74 digits displayed) I would like to know if it is possible to find a closed-form expression for $l$ . Edit I used a PARI/GP function ( sumnum ) to compute an approximate value of $l$ : gp > #
    timer = 1 (on)
 gp > \p 74
    realprecision = 77 significant digits (74 digits displayed)
 gp > sumnum(n=0, (2*n+15)^2/(2*n+11)^3/sqrt(2*n+13),sumnuminit([+oo,-1.5]))
 time = 15 ms.
 %1 = 0.39483198670640570922670209458869656945532664947383304288146572043505953641
 gp > sum(k=0,97,binomial(-1/2,k)*(zetahurwitz(k+3/2,11/2)+4*zetahurwitz(k+5/2,11/2)+4*zetahurwitz(k+7/2,11/2)))/2/sqrt(2)
 time = 62 ms.
 %2 = 0.39483198670640570922670209458869656945532664947383304288146572043505953641
 gp > \p 400
    realprecision = 404 significant digits (400 digits displayed)
 gp > sumnum(n=0, (2*n+15)^2/(2*n+11)^3/sqrt(2*n+13),sumnuminit([+oo,-1.5]))
 time = 1,078 ms.
 %3 = 0.3948319867064057092267020945886965694553266494738330428814657204350595364122729251535099721677148100865638904442238183504239633022203492259575689525638233484603909542517059855919506733374353926795281971622814159109637670427399334579124116308394274900167149611375839262362929064148759669151317574581119034347857659144521214162698550204609725028401793070583608454779328237780415473232520384318559950198
 gp > sum(k=0,537,binomial(-1/2,k)*(zetahurwitz(k+3/2,11/2)+4*zetahurwitz(k+5/2,11/2)+4*zetahurwitz(k+7/2,11/2)))/2/sqrt(2)
 time = 3,532 ms.
 %4 = 0.3948319867064057092267020945886965694553266494738330428814657204350595364122729251535099721677148100865638904442238183504239633022203492259575689525638233484603909542517059855919506733374353926795281971622814159109637670427399334579124116308394274900167149611375839262362929064148759669151317574581119034347857659144521214162698550204609725028401793070583608454779328237780415473232520384318559950198","['closed-form', 'sequences-and-series']"
3045961,Convergence of $\sum_{n = 1}^\infty \frac{(-1)^n}{n + n^2(1 + (-1)^n)}$,Is $$\sum_{n = 1}^\infty \frac{(-1)^n}{n + n^2(1 + (-1)^n)}$$ convergent? It is not absolutely convergent and Leibniz test is inconclusive.,"['limits', 'convergence-divergence', 'sequences-and-series']"
3046000,Example of a parallelizable smooth manifold which is not a Lie Group,All the examples I know of manifolds which are parallelizable are Lie Groups. Can anyone point out an easy example of a parallelizable smooth manifold which is not a Lie Group? Are there conditions on a parallelizable smooth manifold which forces it to be a lie group?,"['tangent-bundle', 'smooth-manifolds', 'lie-groups', 'differential-geometry']"
3046139,Minimum transactions to settle debts among friends,"You are given $n$ integers $x_1,x_2,\dots,x_n$ satisfying $\sum_{i=1}^n x_i=0$ . A legal move is to choose an integer $a$ and two indices $i,j$ , and to increase $x_i$ by $a$ and decrease $x_j$ by $a$ . The goal is to have $x_1=x_2=\dots=x_n=0$ . What is an algorithm which achieves this goal in the fewest number of moves? There is an algorithm which always takes $n-1$ moves; at the $i^{th}$ step, decrease $x_i$ by $x_i$ and increase $x_{i+1}$ by $x_i$ . This is not always optimal, because if half of the $x_i$ equal $1$ and the other half equal $-1$ , then $n/2$ moves suffice. The motivation for this problem is the situation where $n$ friends have gone out to dinner, and have all contributed some amount of money bill, and now want to make it so they have all payed an equal amount.","['graph-theory', 'np-complete', 'combinatorics', 'algorithms', 'computational-complexity']"
3046154,"Let $G$ be a finite group and $M,N \lhd G$ such that $M \leq N\cap \Phi(G)$. Then $\frac{N}{M}$ is nilpotent iff $N$ is nilpotent.","Let $G$ be a finite group and $M,N \lhd G$ such that $M \leq N\cap \Phi(G)$ . Then $\frac{N}{M}$ is nilpotent iff $N$ is nilpotent, where $\Phi(G)$ is the Frattini subgroup of $G$ . The converse side is obvious. For first side I want to use the below fact. ""Let $G$ be a finite group and $N \lhd G$ such that $N\leq \Phi(G)$ . Then $\frac{G}{N}$ is nilpotent iff $G$ is nilpotent."" Let $\frac{N}{M}$ be  nilpotent. We have $M \lhd N$ . I want to show $M\leq \Phi(N)$ . If I show this we have the result from the fact above. But I don't know how to show it or is it true at all?","['finite-groups', 'nilpotent-groups', 'quotient-group', 'normal-subgroups', 'group-theory']"
3046177,Prove that $T$ is bounded and find its norm,"Consider $T\colon C[0,1] \to C[0,1]$ by $$T(f) = \int_{0}^1 \sin(t) \;f(t) \;dt$$ Show that $T$ is a bounded linear operator. Find the norm of $T$ . This is my solution Is it true? Thanks a lot..","['operator-theory', 'normed-spaces', 'functional-analysis']"
3046180,Find the value of $\cot^{-1}21+\cot^{-1}13+\cot^{-1}(-8)$,"Find the value of $\cot^{-1}21+\cot^{-1}13+\cot^{-1}(-8)$ My Attempt \begin{align}
\cot^{-1}21+\cot^{-1}13+\cot^{-1}(-8)&=\pi-\tan^{-1}\frac{1}{8}+\tan^{-1}\frac{1}{13}+\tan^{-1}\frac{1}{21}\\
&=\pi-\tan^{-1}\frac{1}{8}+\tan^{-1}\frac{1}{13}+\tan^{-1}\frac{1}{21}\\
&=\pi-\tan^{-1}\frac{1}{8}+\tan^{-1}\frac{4-3}{1+4.3}+\tan^{-1}\frac{5-4}{1+5.4}\\
&=\pi-\tan^{-1}\frac{1}{8}+\tan^{-1}5-\tan^{-1}3\\
&=\pi-\tan^{-1}\frac{1}{8}+\tan^{-1}\frac{1}{8}=\pi
\end{align} My reference gives the solution $0$ , so what's going wrong with my attempt ?","['trigonometry', 'inverse-function']"
3046210,"Evaluating $\int_{1/4}^1 \int_{\sqrt{x-x^2}}^{\sqrt x}\left(\frac{x^2-y^2}{x^2}\right)\,dy\,dx$","I am looking for an efficient way to evaluate $$\int_{1/4}^1 \int_{\sqrt{x-x^2}}^{\sqrt x}\left(\frac{x^2-y^2}{x^2}\right)\,\mathrm{d}y\,\mathrm{d}x$$ I have \begin{align}
I&=\int_{1/4}^1\left(\int_{\sqrt{x-x^2}}^{\sqrt x}\,dy-\frac{1}{x^2}\int_{\sqrt{x-x^2}}^{\sqrt x}y^2\,dy\right)\,dx
\\&=\int_{1/4}^1\left[\sqrt x-\sqrt{x-x^2}-\frac{(\sqrt{x})^3-(\sqrt{x-x^2})^3}{3x^2}\right]\,dx
\\&=\int_{1/4}^1\sqrt x\,dx-\int_{1/4}^1 \sqrt{x-x^2}\,dx-\frac{1}{3}\int_{1/4}^1 \frac{1}{\sqrt x}\,dx+\frac{1}{3}\int_{1/4}^1\frac{(x-x^2)^{3/2}}{x^2}\,dx
\\&=\frac{2}{3}\left(1-\frac{1}{4^{3/2}}\right)-\frac{1}{3}-\color{darkred}{\int_{1/4}^1 \sqrt{x-x^2}\,dx}+\frac{1}{3}\color{green}{\int_{1/4}^1\frac{(x-x^2)^{3/2}}{x^2}\,dx}
\end{align} Using this answer, $$\color{darkred}{\int_{1/4}^1 \sqrt{x-x^2}\,dx}=\frac{1}{4}\int_{-\pi/6}^{\pi/2}\cos^2\,dt=\frac{1}{8}\int_{-\pi/6}^{\pi/2}(1+\cos 2t)\,dt=\frac{1}{96}(3\sqrt 3+8\pi)$$ For $\color{green}{\int_{1/4}^1\frac{(x-x^2)^{3/2}}{x^2}\,dx}$ or even the indefinite integral, nothing comes to mind off the top of my head. In a different approach, if I try to change the order of integration right at the start, it complicates matters for me to rewrite the region $$\sqrt{x-x^2}<y<\sqrt x\,,\,1/4<x<1$$ keeping a separate range of $y$ free of $x$ and bounding $x$ with $y$ . Any suggestion regarding specific substitution or change of variables would also be helpful.","['integration', 'multivariable-calculus', 'multiple-integral']"
3046227,Uniqueness of a nonlinear ODE,"I'm currently looking through qualifying exam questions and one has had me stumped for a few weeks. We are asked to determine whether or not there exists a unique solution of this differential equation in a neighborhood of $x = 0$ . \begin{equation} y'' + \frac{yy'}{x^4} + y^2 = 0 , \text{ } y(0)=y'(0)=0 \end{equation} I believe that the solution is unique with $y = 0$ as the only solution. I have managed to prove that a non-trivial solution must satisfy $y \leq 0$ , but I cannot deal with $y < 0$ case. Edit: Thank you to Ingix for noticing a mistake in my proof, which I edited below. Indeed, assume there exists $f(x)$ that solves the above ODE such that $f(x) > 0$ on say $(0,\varepsilon_1]$ , where $\varepsilon_1$ is positive. Then by MVT, we see \begin{equation} f'(\xi) = \frac{f(\varepsilon_1) - f(0)}{\varepsilon_1-0} > 0, \xi \in (0, \varepsilon_1)  \end{equation} In particular by the continuity of $\text{ }f'$ , there's a neighborhood $(\delta_{1}, \delta_{2}] \subset (0,\varepsilon_1]$ such that $\text{ } f' > 0$ where $\delta_{1} = \sup_{x \in [0,\varepsilon_1]}$ such that $\text{ }f'(x)=0$ . Then by MVT again \begin{equation} \frac{f'(\delta_2)-f'(\delta_1)}{\delta_2 - \delta_1} > 0 \end{equation} Therefore, there's a neighborhood $[\eta_1, \eta_2] \subset (\delta_1, \delta_2)$ such that $f,f',f'' > 0$ . Therefore the ODE cannot be satisfied. I am unsure how to proceed for the case $y < 0$ because the above argument would not give a contradiction. I have tried rewriting the ODE into weak form, using $u = y^2 \Rightarrow u' = 2yy'$ , and I do not see any obvious transformations such as equidimensional in $x/y$ , scale invariant, or autonomous to simplify the ODE. Any hints on how to proceed will be very helpful!","['ordinary-differential-equations', 'real-analysis']"
3046303,Isotropy group of connection is isomorphic to centraliser of holonomy group,"I am asking for a proof of Lemma (4.2.8) of Donaldson, Kronheimer: The Geometry of Four-Manifolds . Let $P \rightarrow X$ be a principal bundle with structure group $G$ .
Denote by $\mathcal{G}$ the gauge group.
Let $A$ be a connection on $P$ and $H_A \subset G$ its holonomy.
Denote by $$
\Gamma_A=
\{u \in \mathcal{G} | u(A)=A \}
$$ the isotropy group of $A$ in $\mathcal{G}$ .
Then the claim of the lemma is: For any connection $A$ over a connected base $X$ , $\Gamma_A$ is isomorphic to the centraliser of $H_A$ in $G$ . My attempt to prove it:
Now if the bundle was trivial, i.e. $P=X \times G$ , we could take $g \in G$ in the centraliser of $H_A$ and get a unique element $u_g \in \mathcal{G}$ satisfying $u_g(x,e)=(x,g)$ .
If the connection $A$ is the trivial connection then it is easy to check that this satisfies $u_g \in \Gamma_A$ . In matrix notation we have $u(A)=u^{-1}Au+u^{-1} du$ .
Plugging in an $A$ -horizontal vector field to this formula shows that any $u \in \Gamma_A$ needs to be constant on $X \times \{e\}$ , i.e. $u=u_g$ for some $g \in G$ .
Plugging in a vertical vector field shows that $g$ must be in the centraliser of $H_A$ in $G$ , because $u^{-1} du$ vanishes on vertical vector fields. I believe I can make this argument work for non-trivial connections $A$ .
But no matter if I can or cannot: all of this assumed that the bundle was trivial.
If the bundle isn't trivial I don't even know how to write down a map from the centraliser of $H_A$ to $\Gamma_A$ .","['principal-bundles', 'gauge-theory', 'differential-geometry']"
3046313,Proving that any given element $hk$ appears $|H \cap K|$ times as a product in the list of $HK$,"I have been trying to prove that if $H, K$ are finite subgroups of $G$ then $|HK|=\dfrac{|H| |K|}{|H \cap K|}$ . I saw the proofs in Herstein and Gallian textbook and they are essentially the same. However, it confuses me. The claim is that any given element $hk$ appears $|H \cap K|$ times as a product in the list of $HK$ and what follows is my attempt of the proving the same but in a little different way and I wonder if it is correct. We define the set $\mathcal{R}(hk)=\{ (h',k') \in H\times K \, | \, hk=h'k' \}$ . Now, we define the map $f\colon H\cap K \to \mathcal{R}(hk)$ by $f(x)=(hx, x^{-1}k)$ . Clearly, $f$ is well defined and we will show that $f$ is bijective. Let $x,y \in H\cap K$ and suppose that $f(x)=f(y)$ . Then $(hx, x^{-1}k)=(hy, y^{-1}k)$ and hence $x=y$ . Let $(h' , k') \in \mathcal{R}(hk)$ . Then $hk=h'k'$ and let $x = h^{-1} h' = kk'^{-1}$ . Clearly, $x\in H \cap K$ and we have that $h'=hx$ and $k'=x^{-1}k$ . Thus, $f(x)=(h',k')$ . This shows $f$ is surjective. Hence, we have that $|\mathcal{R}(hk)|=|H \cap K|$ . This proves our claim. I wonder if this is okay. Are Herstein and Gallian doing the same thing? Here's the proof from Herstein:","['alternative-proof', 'proof-explanation', 'group-theory', 'proof-verification']"
3046406,Probability remains same Why?,A box has $m$ black and $n$ white balls. A ball is drawn at random and put back with $k$ additional balls of the same colour as that of the drawn ball. Now a ball is drawn again. Find the probability that it is a white ball. I got the answer $\frac{n}{m+n}$ . I just want to understand why it's not dependent on $k$ .,"['conditional-probability', 'elementary-probability', 'probability-theory', 'probability']"
3046451,Prove the ratio of the length and width of the rectangle is rational.,"Assume there is a rectangle be combined by finite squares, and the small squares are not of equal size. Also, the lengths of the squares may be irrational. The question is ""Can we know the ratio of the length and width of this rectangle is rational ?"" I guess the answer is ""yes!""(by considering many cases). However, I have no idea to prove it.",['geometry']
3046536,Is the notion of Cauchy sequences definable in a bornological topological space?,"Being a Cauchy sequence is not a topological property, i.e. two metrics can induce the same topology and yet a sequence which is Cauchy in one may not be Cauchy in the other.  It is a uniform property though, i.e. if two metrics induce the same uniformity then they have the same set of Cauchy sequences.  But I'm wondering if Cauchy sequences can be defined in weaker conditions than a uniform space. Let $X$ be a topological space endowed with a bornology , i.e. a structure which defines a notion of bounded sets.  My question is, is it possible to define the notion of Cauchy sequences in terms of this bornology?  To put it another way, if two metrics induce both the same topology and the same bornology, then do they have the same set of Cauchy sequences?","['cauchy-sequences', 'uniform-spaces', 'general-topology', 'metric-spaces']"
3046539,Solving the ODE $\frac{\mathrm{d}x}{\mathrm{d}t} = x^{-n} -2x$,"I'm preparing for my mock exams, and one of the past questions was to Solve $$\frac{\mathrm{d}x}{\mathrm{d}t}  = x^{-n} -2x$$ for $0<x<\infty$ where $n>0$ , subject to $x(1)=1$ . My work so far is as follows: 
Multiplying both sides of the ODE by $x^{n}$ gives $$
 x^n\frac{\mathrm{d}x}{\mathrm{d}t}  = 1 -2x^{n+1}.
 $$ Put $p = x^{n+1}$ . Then $$
\frac{\mathrm{d}p}{\mathrm{d}t} = (n+1)x^{n}\frac{\mathrm{d}x}{\mathrm{d}t},
$$ or $$
x^{n}\frac{\mathrm{d}x}{\mathrm{d}t} = \frac{1}{n+1}\frac{\mathrm{d}p}{\mathrm{d}t}.
$$ Therefore, the ODE in question may be rewritten in the form of $$
 \frac{1}{n+1}\frac{\mathrm{d}p}{\mathrm{d}t}  = 1 -2p.
$$ Assume, for the time being, that $1-2p\neq 0$ . Then separating variables leads to $$
\frac{1}{n+1}\frac{\mathrm{d}p}{1 -2p} = \mathrm{d}t,
$$ and integrating both sides gives $$
-\frac{1}{2}\frac{1}{n+1}\ln{|1-2p|} = t+C
$$ or $$
-\frac{1}{2}\frac{1}{n+1}\ln{|1-2x^{n+1}|} = t+C.
$$ The condition $x(1)=1$ leads to $$
-\frac{1}{2}\frac{1}{n+1}\ln{|1-2\cdot 1|}=-\frac{1}{2}\frac{1}{n+1}\ln{1}= 0  = 1+C,
$$ so that $C = -1$ and $$
-\frac{1}{2}\frac{1}{n+1}\ln{|1-2x^{n+1}|} = t - 1,
$$ and from here we get $$
|1-2x^{n+1}| = e^{2(n+1)(1-t)}.
$$ Now, I wanted to get $x(t)$ explicitly. I obtained that $1-2x^{n+1}\ge 0$ for $x\in\left(0, \frac{1}{2^{n+1}}\right]$ and $1-2x^{n+1}\le 0$ for $x\in\left[\frac{1}{2^{n+1}}, \infty \right)$ . This leads to ""solutions""( ?? ) $$ \begin{align}
x(t) = \begin{cases}
&\displaystyle\sqrt[n+1]{\displaystyle\frac{1 - e^{2(n+1)(1-t)}}{2}}\quad\text{ for }x\in\left(0, \displaystyle\frac{1}{2^{n+1}}\right]\\\
&\displaystyle \sqrt[n+1]{\displaystyle\frac{1 + e^{2(n+1)(1-t)}}{2}}\quad\text{ for }x\in\left[\displaystyle\frac{1}{2^{n+1}}, \infty \right).
\end{cases}
\end{align}$$ but this kinda doesn't make sense, because we're giving a formula for $x$ as a function of $t$ and at the same time imposing restrictions as to which interval has $x$ to be to be given by a particular formula... My question(a) is(are): Is there a simpler way to get $x(t)$ ? How can we reconcile the restrictions on $x$ (so that $1-2x^{n+1}$ is $><0$ ) with the formulas for $x$ as a function of $t$ ? And frankly, I'm not sure how to word my question(s); tl;dr would be how to get explicit formulae for $x(t)$ from the ODE - and not implicit relation between $|1-2x^{n+1}|$ and some $f(t)$ )",['ordinary-differential-equations']
3046611,Why is $\prod_{k=n}^{2n-3}\left(2n-k\right) = \prod_{j=3}^{n}j$?,"I am trying to figure out these two equal expressions from my textbook: $$\prod_{k=n}^{2n-3}\left(2n-k\right) = \prod _ {j=3} ^ {n}j$$ I have checked them and know that they apply, but what are the logical steps that lead me to the equation?","['discrete-mathematics', 'sequences-and-series']"
3046626,"Given two biholomorphic maps such that $f(z_0)=g(z_0)=0$, prove there exists $c$ such that $f(z)=cg(z)$","Given two biholomorphic maps $f:\Omega\rightarrow\mathbb{D}$ and $g:\Omega\rightarrow\mathbb{D}$ such that $f(z_0)=g(z_0)=0$ , prove that there exists $c\in\mathbb{C}$ with $|c|=1$ such that $f(z)=cg(z)$ If $f$ or $g$ is identically zero, it is trivial as $0=c0$ , so assume they are both not identically zero. Assume WLOG, $|f|\leq|g|$ . Then, $f(z)=(z-z_0)^mk(z)$ and $g(z)=(z-z_0)^nh(z)$ where $k(z_0)$ and $h(z_0)$ are both not zero. Then, for $z\neq z_0$ , $$\left|\frac{(z-z_0)^{m-n}k(z)}{h(z)}\right|\leq1$$ and there exists some constant $k$ such that $\left|\frac{k(z)}{h(z)}\right|\geq \frac{1}{k}$ so we have $$\frac{|z-z_0|^{m-n}}{k}\leq\left|\frac{(z-z_0)^{m-n}k(z)}{h(z)}\right|\leq 1\Rightarrow|z-z_0|^{m-n}\leq k$$ How do I proceed further to show that there is a constant $c$ ? or am I totally wrong?",['complex-analysis']
3046675,Method of Undermined coefficients,"The following equation: $y''+y=\cos(x)$ Solving $y''+y=0$ gives me $c_1\cos(x)+c_2\sin(x)$ Using the particular integral yp form of $a\cos(x)+b\sin(x)$ and substituting this back into the ODE $y = a\cos(x)+b\sin(x)$ , $y'=-a\sin(x)+b\cos(x)$ , $y''=-a\cos(x)-b\sin(x)$ Plugging this back into the ODE leaves me with $0=\cos(x)$ So how is the particular solution $y=1/2x\sin(x)$ with the coefficients value of $c_1=0$ and $c_2=1/2$ , and where does the $x$ come from?","['multivariable-calculus', 'calculus', 'numerical-methods']"
3046718,Why is split algebraic group quasi-split?,"One says a connected linear algebraic group $G$ over a field $k$ is quasi-split over $k$ if there exists a Borel subgroup defined over $k$ , and is split if there exists a split maximal torus $T$ over $k$ . From those definitions, why is a split algebraic group quasi-split?","['algebraic-geometry', 'algebraic-groups']"
3046732,"If $f_n\rightarrow f$ uniformly on compact subsets $\Omega$ and $f$ is not constant, prove $f(\Omega)\subseteq \Omega$","Let $\Omega$ be open and connected, and let $\{f_n\}$ be a sequence of holomorphic functions on $\Omega$ such that $f_n(\Omega)\subseteq \Omega$ . If $f_n\rightarrow f$ uniformly on compact subsets $\Omega$ and $f$ is not constant, prove $f(\Omega)\subseteq \Omega$ My attempt: Let $z_0\in \Omega$ and let $g(z)=f(z)-f(z_0)$ and $h(z)=f_n(z)-f(z_0)$ . Clearly, $g(z)$ has a zero in a small neighborhood of $z_0$ , which is $z_0$ . If I'm able to show that $h(z)$ also has a zero in that neighborhood, say $z_1$ , this implies that $f(z_0)=f_n(z_1)\in \Omega$ and this completes the proof. But I'm having trouble showing that $h(z)$ has a zero in the neighborhood of $z_0$ . I'm trying to use Rouche's theorem by showing if $|g(z)-h(z)|<|g(z)|$ in the boundary of some neighborhood of $z_0$ , $g(z)$ and $h(z)$ has the same number of roots in the neighborhood, hence, there exists some $z_1$ that satisfies my claim. Can anyone show me how to get the inequality?",['complex-analysis']
3046734,Are there any vector spaces that cannot be given a norm that makes the vector space a complete metric space?,"And if so, how can one prove that there is no such norm? I suppose one can use the form of Baire Category Theorem which states that a complete metric space cannot be written as a countable union of nowhere dense subsets to show that the metric space defined by the given vector space and norm is not complete but I have no idea on how to generalise this idea to all possible norms.","['general-topology', 'normed-spaces', 'baire-category', 'metric-spaces']"
3046735,Find the integrating factor and solve,"Find an integrating factor and solve $(2x^2y + x)\,dy + (xy^2 + y)\,dx = 0$ I checked if it was exact, which it wasn't. Then I found $M/Y$ to be $xy + 1$ $N/Y$ to be $2xy + 1,$ but when I tried to put it in the form of $n N/X - mM/Y$ I got $-2xy,$ which didn't really tell me much about the value of $n$ and $m.$ So I tried over by multiplying the original equation by $x^ny^m$ and didn't get two linear equations at the end but two equations, which still had $xy$ terms and am stuck now. Any help would be appreciated.",['ordinary-differential-equations']
3046758,Application of Gronwall Inequality to existence of solutions,"Consider the $N$ -dimensional autonomous system of ODEs $$\dot{x}= f(x),$$ where $f(x)$ is defined for any $x \in \mathbb{R}^N$ , and satisfies $||f(x)|| \leq \alpha||x||$ , where $\alpha$ is a positive scalar constant, and the norm $||x||$ is the usual quadratic norm (the sum of squared components of a vector under the square root). Using Gronwall’s inequality, show that the solution emerging from any point $x_0\in\mathbb{R}^N$ exists for any finite time. Here is my proposed solution. We can first write $f(x)$ as an integral equation, $$x(t) = x_0 + \int_{t_0}^{t} f(x(s)) ds$$ where the integration constant is chosen such that $x(t_0)=x_0$ . WLOG, assume that $t_0=0$ . Then, \begin{equation}
\begin{split}
||x(t)|| & = ||x_0 + \int_{0}^{t} f(x(s)) ds|| \\
 & \leq ||x_0|| + ||\int_{0}^{t} f(x(s)) ds|| \\
 & \leq ||x_0|| + \alpha\int_{0}^{t} ||x(s)|| ds 
\end{split}
\end{equation} Therefore, by the integral form of Gronwall's inequality , we see that \begin{equation}
\begin{split}
||x(t)|| & \leq ||x_0|| + \alpha\int_{0}^{t} ||x(s)|| ds \\
 & \leq  ||x_0||e^{\alpha(t)}
\end{split}
\end{equation} So, if we let $M = ||x_0||$ , then $||x(t)||\leq{{M}e^{\alpha(t)}}$ . Therefore, the solution is uniformly bounded on $[0,t]$ for $t>0$ . As $t>0$ was arbitrary, the solution is defined for all positive values of $t$ . We can then analyze what happens for negative values of $t$ by reversing time and applying the same argument to $[-t,0]$ . Once again assume that $t_0=0$ . Then, $$x(t) = x_0 + \int_{-t}^{0} f(x(s)) ds$$ Therefore, \begin{equation}
\begin{split}
||x(t)|| & = ||x_0 + \int_{-t}^{0} f(x(s)) ds|| \\
 & \leq ||x_0|| + ||\int_{-t}^{0} f(x(s)) ds|| \\
 & \leq ||x_0|| + \alpha\int_{-t}^{0} ||x(s)|| ds \\
 & \leq ||x_0||e^{\alpha(0+t)} \\
 & = {M}e^{\alpha(t)}
\end{split}
\end{equation} So, the solution is uniformly bounded on $[-t,0]$ for $t<0$ . Combining these two bounds, we see that the solution emerging from any point $x_0\in\mathbb{R}^N$ exists for any finite time. Is this approach correct? Please let me know if there are any better alternatives.","['proof-verification', 'integral-inequality', 'ordinary-differential-equations']"
3046760,Showing that is a normal operator,"Let $H$ is a Hilbert space $I$ is unit operator, $T \in B(H)$ and $\lambda \in \mathbb C$ $T$ is normal operator $\Rightarrow$ $T-\lambda I$ is a normal operator too. I could only write : I must show that $(T-\lambda I)(T-\lambda I)^{\ast}=(T-\lambda I)^{\ast}(T-\lambda I)$ $TT^{\ast}=T^{\ast}T$ $I^{\ast}=I$ $(T-\lambda I)^{\ast}=T^{\ast}- \bar{\lambda}I$ (where $\ast$ means adjoint and $\bar{\lambda}I$ means complex conjugate. I cannot continue. I really stuck Thanks for any help","['hilbert-spaces', 'operator-theory', 'adjoint-operators', 'functional-analysis']"
3046766,"Find the determinant of the $n\times n$ matrix $A_n$ with $(A_n)_{i,j}={n\choose |i-j|}$.","I'd like to find the determinant of the matrix $A_n$ given by $(A_n)_{i,j}={n\choose |i-j|}$ for all $n\in\mathbb{Z}_{\ge 1}$ and $i,j\in\{1,2,\ldots,n\}$ . Here is what I know so far: $\det(A_n)=0$ if and only if $6\mid n$ . $2^n-1$ is an eigenvalue of all $A_n$ , with eigenvector $(1,1,\ldots,1)$ If $n$ is prime, then $\det(A_n)\equiv 1\pmod n$ If $n+1$ is prime and $n>2$ , then $\det(A_n)\equiv 0\pmod {n+1}$","['determinant', 'number-theory', 'matrices', 'binomial-coefficients', 'linear-algebra']"
3046778,Upside-down equation: algebra puzzle,"This quirky equation was presented to me by a fellow teacher, along with the instruction ""solve it both ways up"". The equation is simple enough to solve, with one integer root. What's more interesting is that the page can be rotated $180$ ° and a new equation can be read. This second equation has two roots. I found it fairly satisfying that both of its roots are integers, but I was hoping that it would share a root with the first equation. I set about looking for an equation that makes sense when read upside-down, where the two equations share a root. My students immediately came up with trivial examples like "" $x=1+1$ "" and "" $1=\frac{1}{x}$ "". I haven't found anything more interesting yet. I haven't even figured out an approach better than trial and error, with different permutations of the digits $1$ , $6$ , $8$ and $9$ . Can anybody help me to find such an equation, ideally one that is similarly ""difficult""/""interesting"" as the equation presented to me? Edit: credit is due to Rob Eastaway who (I have learned since posting this question) originally posted the first image on Twitter.","['algebra-precalculus', 'puzzle', 'recreational-mathematics']"
3046794,"Need help in solving an equation involving volume, single and double layer potentials","Let be $V \subset \mathbb{R}^n $ , $ 3\leq n$ an open set, where you can apply Gauß's Theorem. To show is, that for all $ U \in C^{(1)} ( \bar{V} ) \cap C^{(2)} (V) $ with  bounded 2nd derivatives the following equation for $y \in V $ : $$ (n-2) \omega_{n-1} U(y) = \int_{ \partial V} \left[\frac{1}{|x-y|^{n-2}} \frac{ \partial U}{ \partial \nu} (x)-U(x) \frac{ \partial }{\partial \nu_x} \frac{1}{|x-y|^{n-2}}\right] d\sigma(x)- \int_V \frac{ \Delta U(x)}{ |x-y|^{n-2}} dx $$ where $ \nu_x $ is the outer normal unit vector on $x\in \partial V$ and $w_{n-1} := \frac{n \pi^{n/2}}{ \Gamma( \frac{n}{2} +1) }$ Well, I know that $W(x):= |x-y|^{-(n-2)} $ is not defined in $x=y$ .
Therefore, instead of integrating over $V$ , first integrate over $V_{\epsilon}:= V$ \ $ K_{\epsilon}(y) $ and use the limes $\epsilon \rightarrow 0+ $ Thats pretty much it. Do you guys maybe know what that is for an Equation? I didn't know a proper title for the question, sorry about that. I find it quite hard to solve. Any help is therefore very appreciated !!","['real-analysis', 'multivariable-calculus', 'multiple-integral', 'gaussian-integral', 'potential-theory']"
3046809,Sum of two invertible matrices [duplicate],"This question already has answers here : Product or sum of invertible matrix give an invertible matrix? (3 answers) Closed 5 years ago . If A and B are two n x n invertible matrices, would the matrix result from A+B be invertible? I think it would because for a matrix to be invertible its determinant would have to be greater than 0, and if you add the determinants of two matrices greater than 0 you would have to get a non zero answer. But is there any way to prove this?","['matrices', 'linear-algebra']"
3046845,When are $z^n - 1$ and $(z+1)^n - 1$ relatively prime?,"The question and answer from this post seem to imply that the polynomials $z^n - 1$ and $(z+1)^n - 1$ (over $\Bbb C[x])$ will be relatively prime if and only if $6 \nmid n$ . Is this true?  If so, is there a quick, direct justification that this is the case?","['abstract-algebra', 'linear-algebra', 'polynomials']"
3046867,Partially tiling a square with parallelograms,"I found the following puzzle on reddit , and am struggling to find the solution: You have an $n\times n$ square, and a supply of parallelogram tiles with side lengths $1$ and $\sqrt{2}$ and angle $45$ °. What is the largest number of non-overlapping tiles you can place in the square? Assume that the tiles must be placed so their vertices have integer coordinates. It seems like the answer is $n(n-1)$ , using $n$ rows of $(n-1)$ tiles. I am stuck proving this is optimal. I think the following idea might be helpful. Divide the square into an $n\times n$ array of square cells, and partition these cells into groups so that whenever a tile touches two cells, those two cells are in the same group. The groups will be snaking paths resembling the example below. At the end of each path are two uncovered triangles. Therefore, we need only show the $n\times n$ grid cannot be partitioned into fewer than $n$ such paths. X X X X
      X X
        X
        X X
          X X","['puzzle', 'combinatorics', 'geometry', 'tiling']"
3046926,"Apostol's Calulus: Prove that $[x+y] = [x]+[y]$ or $[x]+[y]+1$, where $[·]$ is the floor function.","Prove that $[x+y] = [x]+[y]$ or $[x]+[y]+1$ , where $[·]$ is the floor
  function I'm Having a little bit of trouble with the last part of this proof. First, I will use the definition of floor function: $[x] = m ≡ m ≤ x < m+1$ and $[y] = n ≡ n ≤ y < n+1$ so, $[x]+[y] = m+n ≡ m+n ≤ x+y < m+n+2$ This is where I get stuck; I have that $[x+y] = t ≡ t ≤ x < t+1 $ , so putting $m+n ≤ x+y < m+n+2$ in that form, seems impossible, let alone the one that corresponds to $[x]+[y]+1$ . Could you help me with this last part? Thanks in advance.","['calculus', 'algebra-precalculus', 'ceiling-and-floor-functions']"
3046942,Integration by part on a surface,"Let $f$ be a smooth positive function from $\mathbb{R}^3$ to $\mathbb{R}$ . Can we ""simplify"" the integral $$
\int_{\mathbb{S}^2} \dfrac{\Delta f(x)}{f(x)} d \sigma(x),
$$ where $\Delta f$ is the three-dimensional Laplacian of $f$ . For instance, what nice conditions on $f$ ensure that this integral have a sign?","['integration', 'multivariable-calculus']"
3046943,$x^n+nx-1$ has a unique solution,"Show that for any integer $n\geq1,$ the equation $$x^n+nx-1=0$$ has a unique positive solution $x_n$ . Furthermore, show that $x_n$ is such that for any $p>1$ the series $\sum_{n=1}^{\infty}x_n^p$ is convergent . For the first part of the question I can prove the solution by the intermediate value theorem (by considering $x=0$ and $x=1$ ). And also uniqueness is achieved because the function is increasing (since the first derivative is always positive.) But how about the convergence of the series?","['calculus', 'real-analysis']"
3046949,Explanation of proof that $c_{0}$ doesn't complemented in $l^{\infty}$,"I've stuck with a problem. We want to prove that $c_{0}$ doesn't complemented in $l^{\infty}$ . There is a proof given in Complement of $c_{0}$ in $l^{\infty}$ . The main problem I have connected with the second part of proof : ""Now fix $n$ and $k$ such that $I_{n,k}$ is uncountable. Let $J \subset I_{n,k}$ be finite and consider $y = \sum_{j \in J} \operatorname{sign}{[(Px_j)(n)]} \cdot x_j$ . Note that $$
(Py)(n) = \sum_{j \in J} \operatorname{sign}{[(Px_j)(n)]}\cdot (Px_j)(n) \geq \frac{\# J}{k}
$$ by our choice of $y$ . Since $A_i \cap A_j$ is finite for $i \neq j$ , we can write $y = f + z$ where $f$ has finite support and $\|z\| \leq 1$ . Thus $P(y) = P(f) + P(z) = P(z)$ by hypothesis on $P$ and therefore $\|P(y)\| \leq \|P\| \|z\| \leq \|P\|$ . This yields $$\# J \leq \|P\| k$$ whence the absurdity that $I_{n,k}$ must be finite"". As it said we consider finite subset $J \subset I_{n,k}$ . And then prove that $\#J \le \|P\| k$ , so it shows that $J$ is finite . It confuses me. And even if we show that $J$ is finite, how it shows that $I_{n,k}$ is finite?","['proof-explanation', 'banach-spaces', 'functional-analysis', 'real-analysis']"
3047004,Relation between roots of function and roots of its derivative,"I'm reading a section my Calculus book that is about the relation between the roots of a polynomial function and the roots of its derivative. So: Notice that if $x_1$ and $x_2$ are roots of $f$ , so that $f(x_1) = f(x_2) = 0$ , then by Rolle's Theorem there is a number $x$ between $x_1$ and $x_2$ such that $f'(x) = 0$ . Ok that makes sense. Then: This means that if $f$ has $k$ different roots $x_1 < x_2 < ... < x_k$ , then $f'$ has at least least $k-1$ roots: one between $x_1$ and $x_2$ , one between $x_2$ and $x_3$ , etc. That also makes sense, but what confuses me is ""at least least $k-1$ roots"". Why ""at least""? Didn't we just show that there are exactly $k-1$ roots for the derivative, or so to say, if we have a polynomial of degree $n$ , then its derivative has $n-1$ roots?","['proof-explanation', 'roots', 'real-analysis', 'polynomials', 'derivatives']"
3047020,If $A \times B$ is Lebesgue measurable in $\mathbb{R}^2$ and $B$ is Lebesgue measurable in $\mathbb{R}$ then $A$ is so?,"Though it seems simple but I am struggling to find a proof for it being a starter to measure theoty. I think this statement is true and I am trying to prove it. Here is my trial:
Write $A= A \times \{0\}= \cup_i(A_{i} \times B_{i})$ , $m_1(A)=m_2(A \times \{0\})=\cup_i m_1(A_i)m_1(B_i)$ I don't know what to do next! Is my approach correct? where $m_1,m_2$ are 1 and 2 dimensional measures in $\mathbb{R},\mathbb{R^2}$ respectively.","['measure-theory', 'lebesgue-measure', 'real-analysis']"
3047032,How to split up a fraction with a sum in the denominator?,"How would you split up the fraction $$\frac{x}{a+b}$$ (or $$\frac{1}{a+b}$$ )  so one fraction has $x$ and $a$ in it, only and another one has $x$ and $b$ , only?","['fractions', 'linear-algebra']"
3047048,"Does there exist a function such that the preimage of $x ^ { 2 } + y ^ { 2 } \leq 1$ is the closed interval $[-1,1]?$","Does there exist a continuous function $f : \mathbb { R } \rightarrow \mathbb { R } ^ { 2 }$ such
that the preimage of the closed unit disk $x ^ { 2 } + y ^ { 2 } \leq 1$ is the closed
interval $[ - 1,1 ] ?$ the open interval $( - 1,1 ) ?$ To be honest, I don't really know how to go about this problem.","['continuity', 'functions', 'real-analysis']"
3047049,Limit of matrix function,"Let $A\in\mathbb{R}^{n\times n}$ be a matrix whose real eigenvalues have negative real part, and $X=X^\top\in\mathbb{R}^{n\times n}$ be a positive semidefinite matrix, i.e., $X\succeq 0$ . Consider the following matrix-valued function $$\tag{1}\label{1}
F(X) = \left(\int_0^{\infty} e^{At} X e^{A^\top t} \mathrm{d} t\right)^{-1/2} X \left(\int_0^{\infty} e^{At} X e^{A^\top t} \mathrm{d} t\right)^{-1/2}
$$ which maps positive (semi)definite matrices into a positive (semi)definite matrices. (Here $\cdot^{1/2}$ denotes the symmetric square root of a positive semidefinite matrix and $e^{\cdot}$ is the matrix exponential). Note that \eqref{1} is a continuous function which is not defined for any $X\succeq 0$ such that $\int_0^{\infty} e^{At} X e^{A^\top t} \mathrm{d} t$ is singular. However, I wonder whether it is possible to define a continuous extension of $F(\cdot)$ in the set of positive semidefinite matrices. In more formal terms, let $\bar{X}\succeq 0$ be such that $\int_0^{\infty} e^{At} \bar{X} e^{A^\top t} \mathrm{d} t$ is singular, and let $\{X_n\}_{n\ge 0}$ , $X_n\succ 0$ , be any sequence such that $\lim_{n\to \infty} X_n = \bar{X}$ . Does $
\lim_{n\to \infty} F(X_n)$ exist and is finite? My question is motivated by the special case of scalar matrices $A=\alpha I$ , $\alpha<0$ , for which it is easy to see that the above limit exists and is finite. For general $A$ 's, however, it is not clear to me whether this limit still exists. Numerical simulations suggest that the answer is again in the affirmative, but I was not able to prove it.","['matrices', 'matrix-calculus', 'linear-algebra', 'limits', 'convergence-divergence']"
3047094,Markov semigroup for normal distributed kernels,"Let $\alpha,\sigma^2>0$ . I want to show that the kernels defined by $$K_t(x,\cdot):=\mathcal{N}\big(xe^{-\alpha t},\frac{\sigma^2}{2\alpha}(1-e^{-2\alpha t})\big)\quad\text{for}\quad t>0$$ $$K_0(x,\cdot)=\varepsilon_x$$ form a Markov semigroup, i.e. for all $(x,B)\in\mathbb{R}\times\mathcal{B}(\mathbb{R})$ and for all $s,t\in \mathbb{R}_+$ it holds $$K_{s+t}(x,B)=\int_\mathbb{R}K_t(y,B)K_s(x,dy)$$ Clearly we have $$K_{0+t}(x,B)=\int_\mathbb{R}K_t(y,B) \varepsilon_{x}(dy)=K_t(x,B)$$ and also $$K_{s+0}(x,B)=\int_\mathbb{R}\varepsilon_y(B)K_s(x,dy)=K_s(x,B)$$ For both $s,t>0$ my attempt is following: \begin{align}\int_\mathbb{R}K_t(y,B)K_s(x,dy)&=\frac{1}{\frac{\pi\sigma^2}{\alpha}\sqrt{1-e^{-2at}-e^{-2as}+e^{-2a(t+s)}}}\\
&\quad\cdot\int_\mathbb{R}\bigg(\int_{B-ye^{-\alpha t}}\exp\bigg(\frac{z^2}{\frac{\sigma^2}{\alpha}(1-e^{-\alpha t})}\bigg)dz\bigg)\exp\bigg(\frac{(y-xe^{-\alpha s})^2}{\frac{\sigma^2}{\alpha}(1-e^{-\alpha s})}\bigg)dy
\end{align} but I do not know where I have to go from here... I am grateful for any advice or help. Thanks in advance!","['stochastic-integrals', 'stochastic-processes', 'probability-theory', 'stochastic-calculus']"
3047204,Questions on a proof that $\mathbb F_2[x]/(x^2-1)$ and $\mathbb F_2[x]/(x^2)$ are isomorphic.,"This has been proven more generally for a field of characteristic 2 in another question. Here is the proof from brianbi.ca $$\mathbb F_2[x]/(x^2) \cong \mathbb F_2[x+1]/((x + 1)^2) =
\mathbb F_2[x]/(x^2 + 2x + 1) = \mathbb F_2[x]/(x^2 - 1)$$ Why is $$\mathbb F_2[x]/(x^2) \cong \mathbb F_2[x+1]/((x + 1)^2)$$ ? -We can use the correspondence theorem by the surjective homomorphism $\varphi:\mathbb F_2[x] \to \mathbb F_2[x+1], \varphi(p(x))=p(x+1)$ , so the ideal $(x^2)$ corresponds to the ideal $(x + 1)^2$ . Is this correct? Is injectivity irrelevant? Why is $$\mathbb F_2[x+1]/((x + 1)^2) = \mathbb F_2[x]/(x^2 + 2x + 1)$$ ? $\mathbb F_2[x+1] \cong \mathbb F_2[x]$ by the same homomorphism $\varphi$ because $\varphi$ is injective too. Is this correct? I think this proves only $\cong$ and not necessarily $=$ . Do we actually have $\mathbb F_2[x+1] = \mathbb F_2[x]$ ? If so, how? In general for a ring $R$ and $a,b \in R$ , when is $R[x-a] = R[x-b]$ ? When is $R[x-a] \cong R[x-b]$ ?","['modular-arithmetic', 'number-theory', 'field-theory', 'abstract-algebra', 'ideals']"
3047221,On differentiating $F(x)=\ln(2x)$,"If we differentiate $F(x)=\ln(2x)$ we will get $F'(x) =\dfrac2{2x}$ after the shortcut $F'(x)=\dfrac1x$ , right? Now if we integrate $F'(x)$ we will get $F(x)=\ln(x)$ but also $F(x)=\ln(2x)$ . This means $\ln(2x)=\ln(x)$ . What happened?","['calculus', 'derivatives']"
3047229,Determining properties of a polynomial $f$ satisfying $f(x^2)-xf(x) = x^4(x^2-1)$ for $x \in\Bbb R^+$,"Let $f$ be a polynomial satisfying $f(x^2)-xf(x) = x^4(x^2-1), x \in\Bbb R^+$ . Then which of the following is correct? A) $f$ is an even function B) $f$ is an odd function C) $\displaystyle\lim_{x\to \infty} \frac{f(x)}{x^3}=1$ D) $\displaystyle\lim_{x\to \infty} \left(\frac{f(x)}{x^2}-x \right)$ exist and is equal to a non-zero quantity. I have no idea what to do here. Looking at the options, one thing I could guess is that the question wants us to find $f(x)$ . After an analysis of few minutes, I could guess $f(x) = x^3$ . But that gives me the answer as B), C). But the answer given is just C). Any help would be appreciated.","['even-and-odd-functions', 'limits', 'calculus', 'functions']"
3047240,For which primes $p$ is $p^2+p+1$ prime as well?,"I am looking to find out for which prime numbers $p$ , the number $p^2+p+1$ is also prime. The first few are $$2,3,5,17,41,59,71,89,101$$ I tried to take the relation modulo $p+1$ and it turns out that in $\mathbb{Z}_{p+1}$ , $p^2+p+1$ is $\hat{1}$ , but I can't continue from here.","['number-theory', 'elementary-number-theory', 'prime-numbers']"
3047252,Show that the function $f$ is strictly bounded by an arbitrary number $A$,"Suppose the function $f(x)$ is differentiable on $[a,b]$ and there exists an arbitrary number $A$ such that for all $x \in (a,b)$ $$f(a)<A$$ $$f(x)+f'(x)<A$$ Show that $f(x)<A$ for all $x \in (a,b)$ . My attempt: Generate a function $h(x)$ such that $$h(x)=e^xf(x)$$ $$\Longrightarrow h'(x)=[e^xf(x)]'=e^x[f(x)+f'(x)]<e^xA$$ So $h'(x)$ is strictly bounded by $e^xA$ . By MVT, there exists two points $c,d \in (a,b)$ such that $$h(c)-h(d)=h'(\frac{c+d}{2})(c-d)$$ $$e^cf(c)<Ae^{\frac{c+d}{2}}(c-d)+Ae^d$$ $$f(c)<Ae^{\frac{d-c}{2}}(c-d)+Ae^{d-c}=Ae^{d-c}[e^{\frac{1}{2}}(c-d)+1]$$ It seems my proof is wrong and get discontinued when I focus on simplifying for $f(c)$ but the question requires that $f(x)$ is strictly bounded by $A$ for the interval $I=(a,b)$ .","['derivatives', 'real-analysis']"
3047260,Does there exist any probability density function ‎$‎f:‎\mathbb{R}\to‎\mathbb{R}‎$ ‎which is not Riemann integrable?,"Let‎  ‎ $‎‎f:‎\mathbb{R}\to‎\mathbb{R}‎$ be a probability density function.   Can ‎the following  be happened for ‎ $‎‎f$ ? (1) ‎‎ $‎‎f$ ‎is ‎not ‎integrable ‎on ‎an ‎(some) ‎interval ‎of ‎‎ $\mathbb{R}‎$ . ‎(2) ‎‎ $‎‎f$ ‎is ‎not ‎integrable ‎on every closed ‎interval ‎of ‎‎ $\mathbb{R}‎$ .‎‎‎
‎
I know that ‎if $‎f‎$ ‎is a‎ ‎‎probability density function then (1) ‎ $‎‎f(x)‎\geq‎0 ‎\quad‎\text{for all} \; x$ , (2) ‎ $\int_{-‎\infty‎}^{+\infty}f(x)\,dx=1$ . but ‎here ‎we ‎have‎ Lebesgue integral not Riemann integral. Moreover if ‎ $‎‎f$ ‎wants ‎to ‎be‎ Riemann integrable on the whole $\mathbb{R}‎$ , it must hold in the following conditions ‎‎(a) ‎‎ $‎‎f$ ‎is ‎integrable ‎on every closed ‎interval ‎of ‎ $\mathbb{R},‎$ ‎ (b) the following integral is convergent‎ $$\int_{-‎\infty‎}^{+\infty}f(x)\,dx=‎‎\int_{-‎\infty‎}^{0}f(x)\,dx+\int_{0‎}^{+\infty}f(x)\,dx.$$ According the mentioned things, the most pdf  are ‎ Riemann integrable, and I could not find any example as I asked. Would anyone help me to find that. thanks a lot.
‎","['integration', 'probability-distributions', 'probability-theory', 'probability']"
