question_id,title,body,tags
1592345,simple proof that $\sqrt{1+\frac{1}{x+1/2}}(1+1/x)^x\le e$,"It is well known that for $x>0$ that $\left(1+\frac{1}{x}\right)^x\le e\le\left(1+\frac{1}{x}\right)^{x+1}$ (see wikipedia ). However, one can obtain the stronger inequality 
$$
\sqrt{1+\frac{1}{x+\frac{1}{2}}}\left(1+\frac{1}{x}\right)^x\le e\le\sqrt{1+\frac{1}{x}}\left(1+\frac{1}{x}\right)^{x}
$$ 
The second inequality can be found in Proposition B.3 of ""Randomized Algorithms"", by Raghaven and Motwani (which itself refers to the book ""Analytic Inequalities"" by Mitrinović) , and can be proven straight-forwardly by calculus (showing a first derivative is non-negative and such). While I can also prove the first inequality using familiar calculus methods, it is a bit messy (ultimately requiring that $\frac{1}{y+2}+\frac{1}{3y+2}\ge \frac{1}{y+1}$ for $y\ge 0$). Does anyone know a ""simple"" proof of $\sqrt{1+\frac{1}{x+\frac{1}{2}}}\left(1+\frac{1}{x}\right)^x\le e$?","['inequality', 'exponential-function', 'analysis']"
1592346,What does it mean when people say that groups are a study of symmetry?,"I see many people make remarks to the effect that groups have basic symmetry properties. I am familiar with Cayley's Theorem and the symmetric groups $S_N$. However, when I think of the symmetric group, I think of a group of permutations, not anything to do with symmetries. Additionally, I have been told that semi-groups lack the basic symmetry properties that groups have. (Note: I only know the basic definition of a semi-group.) What does symmetry mean in this context?","['semigroups', 'group-theory', 'symmetric-groups']"
1592354,Let $P(x)=(x-1)(x-2)(x-3)$.For how many polynomials $Q(x)$ does there exist a polynomial $R(x)$ of degree 3 such that $P(Q(x))=P(x).R(x)?$,"Let $P(x)=(x-1)(x-2)(x-3)$.For how many polynomials $Q(x)$ does there exist a polynomial $R(x)$ of degree 3 such that $P(Q(x))=P(x).R(x)?$ Let $R(x)$ be a third degree polynomial $ax^3+bx^2+cx+d=0$ In $P(Q(x))=P(x).R(x)$,RHS is a sixth degree polynomial,so LHS must also be a sixth degree polynomial, So $Q(x)$ must be a quadratic polynomial(let us say $ax^2+bx+c=0$) But i dont know how to argue further and solve further.Please help me.Thanks.","['algebra-precalculus', 'polynomials']"
1592359,Groups of order $64$ with abelian group of automorphism,"G. A. Miller in 1913 constructed the first example of a non-abelian group of order $64$ with abelian group of automorphisms. It is the group 
$$G=(C_8\rtimes C_4)\rtimes C_2=\langle x,y,z\colon x^8, y^4, z^2, yxy^{-1}=x^5, zxz^{-1}=x,zyz^{-1}=y^{-1}\rangle.$$
After few years, following observations were made: There is no non-abelian group of order $<64$ with abelian group of automorphism. There are (exactly) two more non-abelian group of order $64$ with abelian automorphism group. Question: What are the other groups of order $64$ with abelian automorphism group? In the presentation, where they differs with $G$? (I mean, it may be a slight modification of $G$ above; if it is such, what is that modification?) Edit: James pointed error; there are two more non-abelian groups of order $64$, not one , with abelian automorphism group.","['p-groups', 'group-theory']"
1592361,Find the maximum modulus of $e^{z^2}$?,"The maximum modulus of $e^{z^2}$ on the set $S=\{z\in \mathbb{C}: 0\leq Re(z)\leq1, 0\leq Im(z)\leq1\}$ is $e/2$ $e$ $e+1$ $e^2$ My attempt: We know $|e^{z^2}|\leq e^{|z|^2}$ so maximum of $|z|=\sqrt{2}$ since $z$ can be $1+i$, so $|e^{z^2}|\leq e^{|z|^2}=e^2$, so $4$ is right? Is my solution correct? If it's not then how to solve this? Thanks.",['complex-analysis']
1592377,What is the derivative of: $f(x)=x^{2x^{3x^{4x^{5x^{6x^{7x^{.{^{.^{.}}}}}}}}}}$?,"I happened to ponder about the differentiation of the following function:
$$f(x)=x^{2x^{3x^{4x^{5x^{6x^{7x^{.{^{.^{.}}}}}}}}}}$$
Now, while I do know how to manipulate power towers to a certain extent, and know the general formula to differentiate $g(x)$ wrt $x$, where $$g(x)=f(x)^{f(x)^{f(x)^{f(x)^{f(x)^{f(x)^{f(x)^{.{^{.^{.}}}}}}}}}}$$ 
I'm still unable to figure out as to how I can adequately manipulate the function to differentiate it within its domain of convergence. General formula: $$g'(x)=\frac{g^2(x)f'(x)}{f(x)\left[1-g(x)\ln(f(x))\right]}$$","['derivatives', 'power-towers', 'calculus', 'functions']"
1592382,Define $R$ as the region in the first quadrant consisting of those points $C$ such that $ABC$ is a acute triangle.Find area of region $R$,"Let $A(2,2)$ and $B(7,7)$ be the points in the plane,Define $R$ as the region in the first quadrant consisting of those points $C$ such that $ABC$ is a acute triangle.Find area of region $R$. For the triangle to be acute angled triangle,angles $A,B,C$ should be all acute angles.But i cant figure out the boundary of the region $R$ in which $C$ can lie. Some hint/suggestion is needed.Please help me.",['geometry']
1592387,Gluing together functions on a closed subvariety,"I'm trying to get an intuition for what sheafification does. I came across a passage from Perrin's algebraic geometry book about closed subvarieties. If says that if X is an algebraic variety and Y is a closed subvariety, we can inherit a sheaf on Y from X. It suggests the natural thing to do would be to define: $O'(V) := \{ f : V \rightarrow K | \text{there is an open } U \in X \text{ such that } U \cap Y = V \text{ and } g|_V = f \text{ for some } g \in O_U \}$ And then it goes on to claim that this is typically not a sheaf, but merely a presheaf, and that the correct thing to do is to sheafify it. I was trying to justify this last line by finding a counterexample to the gluing axiom. This is what I came up with: Let $X = \mathbb{A}^2$, let $Y = \mathbb{V}(xy)$. Then let $U_1 = D(x)$ and $U_2 = D(y)$, which forms a cover of the open subset $Y - {(0,0)}$ of $Y$. Define $f_1 = 0$ and $f_2 = 1$, which are elements of $O'(U_1)$ and $O'(U_2)$ respectively. They have no overlap, since their would-be intersection at the origin has been left out. But when you glue them together, you seem to run into trouble near the origin. (Informally, the polynomial's value seems to approach both $0$ and $1$ as you approach the orign. Less informally, the density of this open set in $Y$ ought to allow you to extend the polynomial to the origin in two distinct ways). My question is simply, is my analysis above valid? I feel like I may have overlooked some assumption somewhere. If it is valid, then what function do you get when you glue together these two functions? If I made a mistake somewhere, could I get some guidance towards a true counter-example?","['sheaf-theory', 'algebraic-geometry']"
1592391,Number of ways to color n objects with 4 colors if all colors must be used at least once,"I have seen, and solved the following problem: How many ways to color n objects with 3 colors $\{A, B, C\}$, if all colors must be used at least once.
$\require{enclose}$
The answer is as follows: $$3^n-{{3}\choose{2}}\cdot2^n + {{3}\choose{1}}\cdot1^n$$
Because the number of forbidden colorings is: $${{3}\choose{2}}\cdot2^n - {{3}\choose{1}}\cdot1^n$$ The overall answer then reduces to: $$3^n - 3\cdot2^n + 3$$ The solution comes to me as follows. There are $3\cdot2^n$ configurations that are illegal because they only use $2$ colors. Of these, some are counted more than once so let's take a closer look: $$2^n\,\{B, C\}\qquad\qquad2^n\,\{A, C\}\qquad\qquad2^n\,\{A, B\}\qquad\qquad$$ All the formations you can make with EXACTLY two colors are unique and counted only once. How about all the formations you can make with EXACTLY one color? Well that answer is obviously ${{3}\choose{1}}$ but let's see how many times we have overcounted by subtracting $3\cdot2^n$. Just like we broke up $3^n$ into our $3\cdot2^n$ formations with two colors, let's break up each $2^n$ into $2$ single color $1^n$ formations and see if we have any repeats! $$2^n\,\{B, C\}\qquad\qquad2^n\,\{A, C\}\qquad\qquad2^n\,\{A, B\}\qquad\qquad$$ \begin{array}{cc}
\text{Each of the $2^n$ can make 2 single color sets so we will have repeats:}\\
\hline
\end{array} $$1^n\,\{B\}\qquad\qquad\qquad1^n\,\{A\}\qquad\qquad\qquad\enclose{updiagonalstrike}{1^n\,\{A\}}$$
$$1^n\,\{C\}\qquad\qquad\qquad\enclose{updiagonalstrike}{1^n\,\{C\}}\qquad\qquad\qquad\enclose{updiagonalstrike}{1^n\,\{B\}}$$ You can see that there are obviously only ${{3}\choose{1}}$ unique illegal single color formations, however we've accounted for each one twice by subtracting $3\cdot2^n$ from $3^n$ so we must add back the ones we overcounted. This is why we add back a ${{3}\choose{1}}$. If we overcounted each unique single color formation by 100, I believe we would add back 100 to the final answer so we could be left with only the unique single color formations that are illegal. I was working on the following problem: How many ways to color n objects with 4 colors $\{A, B, C, D\}$, if all colors must be used at least once. Following the same logic in this post's answer , the following process makes sense to me: Total number of ways to color N objects with any colors would be $4^n$. Of the $4^n$, there are: $$3^n\,\text{that use only}\,\{B, C, D\},\;3^n\,\text{that use only}\,\{A, C, D\},\;3^n\,\text{that use only}\,\{A, B, C\}$$ This givs us ${{4}\choose{3}}\cdot3^n$ invalid options. However this over-counts several invalid options several times. Let's take a closer look.
$$3^n\, \{B, C, D\}\qquad3^n\, \{A, C, D\}\qquad3^n\, \{A, B, D\}\qquad3^n\, \{A, B, C\}$$
\begin{array}{cc}
\text{Which breaks down to the following (${{4}\choose{2}}$duplicates crossed out):}\\
\hline
\end{array}
$$2^n\,\{B, C\}\qquad\qquad2^n\,\{A, C\}\qquad\qquad2^n\,\{A, B\}\qquad\qquad\enclose{updiagonalstrike}{2^n\,\{A, B\}}$$
$$2^n\,\{B, D\}\qquad\qquad2^n\,\{A, D\}\qquad\qquad\enclose{updiagonalstrike}{2^n\,\{A, D\}}\qquad\qquad\enclose{updiagonalstrike}{2^n\,\{A, C\}}$$
$$2^n\,\{C, D\}\qquad\qquad\enclose{updiagonalstrike}{2^n\,\{C, D\}}\qquad\qquad\enclose{updiagonalstrike}{2^n\,\{B, D\}}\qquad\qquad\enclose{updiagonalstrike}{2^n\,\{B, C\}}$$
\begin{array}{cc}
\text{Which breaks down to the following:}\\
\hline
\end{array}
$$2^n\,\{B, C\}\quad2^n\,\{B, D\}\quad2^n\,\{C, D\}\quad2^n\,\{A, C\}\quad2^n\,\{A, D\}\quad2^n\,\{A, B\}$$
\begin{array}{cc}
\text{Since all $2^n$ are unique, the only sets that we count many times here are the one with one letter}\\
\hline
\end{array}
$$1^n\,\{B\}\qquad\enclose{updiagonalstrike}{1^n\,\{B\}}\qquad\enclose{updiagonalstrike}{1^n\,\{C\}}\qquad1^n\,\{A\}\qquad\enclose{updiagonalstrike}{1^n\,\{A\}}\qquad\enclose{updiagonalstrike}{1^n\,\{A\}}$$
$$1^n\,\{C\}\qquad1^n\,\{D\}\qquad\enclose{updiagonalstrike}{1^n\,\{D\}}\qquad\enclose{updiagonalstrike}{1^n\,\{C\}}\qquad\enclose{updiagonalstrike}{1^n\,\{D\}}\qquad\enclose{updiagonalstrike}{1^n\,\{B\}}$$ We obviously know that there are going to be only 4 unique countings of 1 letter sets since there are only 4 colors, so the other 8 were counted many times, just like the other 6 sets of $2^n$ To me, this makes the answer: $$4^n - {{4}\choose{3}}\cdot3^n + {{4}\choose{2}}\cdot2^n + 8\cdot1^n$$ I am slightly suspicious as it doesn't follow the pattern that would make ${{4}\choose{1}}\cdot1^n$ be the last term, however walking through the logic it is clear to me that just as we counted 6 of the $2^n$ sets twice, we are counting, the monochromatic sets 8 extra times than necessary, so we need to give them back so I believe my first solution is correct? Could someone verify my logic here?","['combinations', 'combinatorics', 'discrete-mathematics']"
1592400,Equal cardinality implies isomorphism of ordering,"I think I have proved this (should-be false) lemma. For any set $X$, if $X$ is equipotent to an ordinal $\alpha$, then $X$ can be ordered so that it is isomorphic to $\alpha$. This is the proof Let $X$ be a set such that it is equipotent to an ordinal $\alpha$. Thus there exists a bijection $f:X\rightarrow\alpha$. We then define the set $\prec$ to be
      \begin{equation*}
	\prec:=\lbrace(x,y)\in X\times X:f(x)<f(y)\rbrace.
	\end{equation*}
  To prove that $\prec$ is really a strict ordering, we are required to show that $\prec$ is asymmetric and transitive. Firstly, to prove that it is asymmetric, we suppose that $x\prec y$ holds. We assume for the sake of contradiction that $y\prec x$ also holds. Thus $f(x)<f(y)$ and $f(y)<f(x)$ which is a contradiction. Thus $y\prec x$ does not hold and hence $\prec$ is asymmetric. Secondly, to prove that $\prec$ is transitive, we suppose that $x\prec y$ and $y\prec z$. Thus $f(x)<f(y)$ and $f(y)<f(z)$. Since $<$ is transitive, it follows that $f(x)<f(z)$. Since $x,z\in X$, this implies that $x\prec z$. Thus $\prec$ is transitive and indeed a strict ordering.
      Now, if $x,y\in X$ and $x\prec y$, then $f(x)<f(y)$ and thus $f$ is the isomorphism between $X$ and $\alpha$. The problem is, if this lemma is true, then this creates a lot of contradiction. For example, $\omega=\omega+1$. This is because $|\omega|=|\omega+1|$ and so (from this lemma) $\omega$ is isomorphic to $\omega+1$. But since no well-ordered set can be isomorphic to its own initial segment, it follows that $\omega=\omega+1$. Something here is wrong! 
Thank you in advance","['elementary-set-theory', 'ordinals']"
1592401,Nullstellensatz for non-algebraically closed fields,"I'm trying to prove that the Nullstellensatz holds for non algebraically closed fields, when the variety is taken over the algebraic closure. Let $R=K[x_1,...,x_n]$ and $\overline{K}$ the algebraic closure of $K$. I was able to prove that $\sqrt{I}\subseteq \mathcal{I}_R(\mathcal{V}_{\overline{K}^n}(I))$ for any ideal $I$. I'm struggling a bit with the other direction. My attempt goes as follows: It is clear that given any ideal $J$, $V_{K^n}(J)\subseteq  \mathcal{V}_{\overline{K}^n}(J)$. Applying $\mathcal{I}_{\overline{K}^n}$ reverses the order, so we have:
$$\mathcal{I}_{\overline{K}^n}(V_{K^n}(J))\supseteq  \mathcal{I}_{\overline{K}^n}(\mathcal{V}_{\overline{K}^n}(J))=\sqrt{I}$$
where the equality is just the normal Nullstellensatz. I don't know if this idea seems fruitful since I haven't been able to get the reverse inclusion. Any ideas on how to show this direction would he highly appreciated.","['abstract-algebra', 'algebraic-geometry', 'commutative-algebra']"
1592405,Let $A$ be a lebesgue null set in $\mathbb{R}$. Prove that $B:=\{e^x:x \in A\}$ is also a null set,"Attempt: Let $l$ be the Lebesgue measure. Since $A$ is a null set, there exists a countable open cover of intervals, $\{I_n\}_{n=1}^{\infty}$ such that $\sum_{n=1}^{\infty} l(I_n)<\epsilon$. Since $e^x$ is strictly increasing on $\mathbb{R}$. an interval $(a_n,b_n)$ is mapped to an interval $e^{I_n}=(e^{a_n},e^{b_n})$. I need to show that $\sum_{n=1}^{\infty} l(e^{I_n})<\epsilon$ Question: How should I proceed?","['real-analysis', 'measure-theory']"
1592414,Is semidirect product unique?,"This is about semi direct product on Dummit and Foote algebra text book.
Why is this statement true? Theorem 12. Suppose $G$ is a group with subgroups $H$ and $K$ such that $H\trianglelefteq G$, and $H\cap K=1$ Let $\varphi:K\to\operatorname{Aut}(H)$ be the homomorphism defined by mappinf $k\in K$ to the automorphism of left conjugation by $k$ on $H$. Then $HK\cong H\rtimes K$. In particular, if $G=HK$ with $H$ and $K$ satisfying $(1)$ and $(2)$, then $G$ is the semidirect product of $H$ and $K$. I think semidirect product of $H,K$ depends on the choice of homomorphism $\varphi$. But once $H,K$ is determined, $HK$ is unique, I think. For example, if $H =\mathbb{Z}/3\mathbb{Z}$ and $K=\mathbb{Z}/4\mathbb{Z}$ then $Aut(H)=\mathbb{Z}/2\mathbb{Z}$. Then homomorphism from $K$ to $Aut(H)$ is not unique.
(Namely, there are two cases.) So semidirect product of $H,K$ is not unique. So how can I understand this situation? Maybe, $HK$ is not unique, and there is a theorem such that $HK$ is isomorphic to the semidirect product of $H,K$ for some homomorphism $\varphi$? Thanks!","['abstract-algebra', 'semidirect-product']"
1592417,"Exercise in Taylor (PDE, volume 1) - Notation","I struggle to understand the following question. I expect I'm simply being dense about something. Let $F$ be a vector field on $U$, open in $\mathbb R^3,$ $F = \sum_1^3 f_j (x) \frac{\partial}{\partial x_j}$. Consider the $1$-form $\varphi=\sum_1^3 f_j(x) dx_j.$ Show that $d \varphi$ and $\operatorname{curl} F$ are related in the following way: $$\operatorname{curl} F = \sum_1^3 g_j(x) \frac{\partial}{\partial x_j}$$ $$d\varphi =g_1(x) dx_2 \wedge dx_3 + g_2(x) dx_3 \wedge dx_1 + g_3(x)dx_1 \wedge dx_2$$ What are the $g_i$? For reference, this is Exercise 5 in section 13 of Chapter 1.","['multivariable-calculus', 'differential-forms', 'notation', 'partial-differential-equations']"
1592421,Why does topology rarely come up outside of topology?,"I am currently taking topology and it seems like a completely different branch of math than anything else I have encountered previously. I find it a little strange that things are not defined more concretely. For example, a topological space is defined as a set $X$ with a collection of open sets $\tau$ satisfying some properties such as the empty set and $X$ are in $\tau$, intersection of two open sets are in $\tau$, and unions of open sets is in $\tau$. So, it seems that a lot of things are topological spaces, such as the real line equipped with a collection of open sets. But I have not seen anyone bringing this up in other areas of mathematics such as linear algebra, calculus, differential equations or analysis or complex analysis. Sure, open sets and closed sets are brought up but the concept of ""topology"", ""base"", etc. etc. are missing entirely. As you scratch the surface a little more you encounter things such as the subspace topology, product topology, order topology and open sets are defined differently with respect to each of them. But nonetheless outside of a course in topology, you never encounter these concepts. Is there a reason why topology is not essential for other courses that I have mentioned? Is there a good reference that meshes serious topology (as in Munkres) with more applied area of mathematics?","['education', 'topological-data-analysis', 'general-topology', 'soft-question']"
1592431,Bayesian information criterion from measure theoretic point of view?,Bayesian information criterion (BIC) is well known and it is derived from the maximizing the posterior density function which is equivalent to solving the marginal likelihood integral. My question is: Is there any measure theoretic analysis of BIC?,"['probability-theory', 'probability', 'linear-algebra', 'statistical-inference']"
1592447,Understanding precisely the dot product...,"There are two definitions of the dot product: $A \cdot B = A_1B_1 + A_2B_2 + \cdots + A_nB_n$ $A \cdot B = AB\cos(\theta)$ I have been trying to develop an intuition of the geometry and algebra of the dot product, and why they are what they are. Although carrying out operations with the derived formulae is quite simple, I am finding it slightly more difficult to understand what exactly is a dot product. I tried deriving $(2)$ from $(1)$ . However, I ended up circling back to $(2)$ - that is, in proving $(2)$ , I had to assume that $(2)$ was already true, which I had not yet proven. Let me illustrate: \begin{align}
\vec{v}\cdot\vec{w} &=(v_x\widehat{\imath}+v_y\widehat{\jmath})\cdot(w_x\widehat{\imath}+w_y\widehat{\jmath})\\
 &=v_xw_x\widehat\imath\cdot\widehat\imath+v_yw_y\widehat\jmath\cdot\widehat\jmath+v_xw_y\widehat\imath\cdot\widehat\jmath+v_yw_x\widehat\jmath\cdot\widehat\imath\\
&=v_xw_x+v_yw_y\end{align} So, now I am left asking: was the dot product arbitrarily defined as $(2)$ and $(1)$ derived, vice versa, neither, or what? Math is pretty fun, though.",['geometry']
1592457,Prove multi-dimensional Mean Value Theorem,"I've been asked to prove multi-dimensional Mean Value Theorem. I'd be
  grateful if someone could give me feedback if it is okay. Proof of Mean Value Theorem: Let $f: [a,b]\rightarrow \mathbb{R}$ be a continuous on $[a,b]$ and differentiable on $(a,b)$. Consider the function: $$g(x)=f(x)-f(a)-\frac{f(b)-f(a)}{b-a}(x-a) \mbox{.}$$ This function is continuous on $[a,b]$, differentiable on $(a,b)$ and $g(a)=g(b)$. Thus there is $c\in (a,b)$ such that $g'(c)=0$. But this means that there is $c\in (a,b)$ such that $$f'(c)=\frac{f(b)-f(a)}{b-a}\mbox{.}$$ Proof of multi-dimensional Mean Value Theorem: Let $f:U\rightarrow\mathbb{R}$ be a differentiable function ($U$ is an open subset of $\mathbb{R}^n)$. Let $\mathbf{a}$ and $\mathbf{b}$ be points in $U$ such that the entire line segment between them is contained in $U$. Define $h:[0,1]\rightarrow U$ in the following way: $$h(t)=(a_1+(b_1-a_1)t,\ldots,a_n+(b_n-a_n)t) \mbox{.}$$ This function is differentiable on $(0,1)$ and continuous on $[0,1]$, so is $f \circ h$. If we apply Mean Value Theorem to $f\circ h$ we get $$(f \circ h )'(c)=(f \circ h )(1)-(f \circ h )(0)$$ where $c\in (0,1)$ and $$f '(h(c))(\mathbf{b}-\mathbf{a})=f(\mathbf{b})-f(\mathbf{a}) \mbox{.}$$ If we set $\zeta=h(c)$ we get $$f '(\zeta)=\frac{f(\mathbf{b})-f(\mathbf{a})}{\mathbf{b}-\mathbf{a}} \mbox{.}$$ (Obviously $f '(\zeta)$ is a gradient vector.)","['derivatives', 'real-analysis', 'calculus']"
1592465,Alternative way to show that a simple group of order $60$ can not have a cyclic subgroup of order $6$,"Suppose $G$ is a simple group of order $60$, show that $G$ can not have a subgroup isomorphic to $ \frac {\bf Z}{6 \bf Z}$. Of course, one way to do this is to note that only simple group of order $60$ is $A_5$. So if $G$ has a cyclic subgroup of order $6$ then it must have a element $\sigma$ of order $6$, i.e. in (disjoint) cycle decomposition of $\sigma$ there must be a $3$ cycle and at least $2$ transposition, which is impossible in $A_5$.Hence,we are done. I'm interested in solving this question without using the fact that $ G \cong A_5$ . Here is what I tried: Suppose $G$ has a subgroup say $H$ isomorphic to $ \frac {\bf Z}{6 \bf Z}$, then consider the natural transitive action $G \times \frac {G}{H} \to \frac {G}{H}$, which gives a homomorphism $\phi \colon G \to S_{10}$. Can some one help me to prove that $\ker \phi$ is nontrivial ? Is there any other way to solve this question? Any hints/ideas?","['alternative-proof', 'abstract-algebra', 'simple-groups', 'group-theory', 'symmetric-groups']"
1592473,If $f(2x)=2f(x)$ and $f'(0)=0$ then $f(x)=0$,"Recently, when I was working on a functional equation, I encountered something like an ordinary differential equation with boundary conditions! Theorem . If the following holds for all $x \in \mathbb R$ 
  $$\begin{align}
f(2x) &=2 f(x) \\
f'(0) &=0
\end{align}$$
  then $f(x)=0$ on $\mathbb R$. Intuitively, it is evident for me that $f(x)=0$ but I cannot show this by a formal argument. In fact, I don't have any idea to work on it! :) I will be thankful if you provide me a hint or help to show this with a nice formal proof.","['real-analysis', 'calculus', 'functional-equations']"
1592496,Characterization for the convergence of a series,"Problem. Let $X$ be a topological spaces which is compact and Hausdorff, $\mathbb{K}\in\{\mathbb{R},\mathbb{C}\}$, and suppose there exists a sequence $\{x_n\}_{n\in\mathbb N}\subset X$, such that $x_n\neq x_m$ for $n\neq m$. Moreover, assume that we have a sequence $\{\lambda_n\}_{n\in\mathbb N}\subset \mathbb{K}$ with the property that for every $f\in C(X,\mathbb{K})$ the series $\sum_{n\in\mathbb N}\lambda_n\, f(x_n)$ is convergent. Show that $\sum_{n\in\mathbb N} \lvert\lambda_n\rvert<\infty$. The opposite implication also holds. It follows from Weierstrass theorem.","['functional-analysis', 'banach-spaces', 'convergence-divergence', 'analysis']"
1592500,Asymptotic behaviour / non-linear ODE,"I'm trying to find the behaviour at large $t$ of solutions to the non-linear differential equation:
$$\dfrac{d^2y}{dt^2}-\left(\dfrac{dy}{dt}\right)^2+(2-a)t\dfrac{dy}{dt}+2ay=0$$
I tried to replicate the approach detailed on Wikipedia , making the assumption that $y(t)\sim e^{S(t)}$ as $t\to\infty$ for some function $S(t)$, but the $\left(\dfrac{dy}{dt}\right)^2$ term in the DE leaves me with an extra factor of $e^{S(t)}$ that I don't know how to deal with. How do I go about finding the asymptotic series for $y(t)$?","['asymptotics', 'ordinary-differential-equations']"
1592502,Applying the Yoneda-Lemma to prove the existence of Tensor-products,"In class the professor said when he came to prove the existence of the tensor-product for $A$-modules ($A$ any ring) that the existence and properties of the tensor-product would be one-liners having proved the Yoneda-Lemma (stated below). He then proceeded to other stuff. I wanted to fill in the details of this remark, but I really can't see where to go. Could anyone help me on this? Thanks a lot! Lemma (Yoneda): Let $D$ be a category, $r$ an object in $D$, and $F : D \rightarrow \mathbf{Set}$ a functor. Then there is a bijection: $$\mathrm{Nat}(\mathrm{Hom}(r, -), F) \simeq F(r)$$
given by $(\alpha: \mathrm{Hom}(r, -) \rightarrow F) \mapsto \alpha_r (1_r)$.","['category-theory', 'abstract-algebra', 'tensor-products', 'commutative-algebra']"
1592506,Find $\lim\limits_{n \to \infty} \frac{1!+3!+\ldots+(2n-1)!}{2!+4!+\ldots+(2n)!}$,"$$\lim\limits_{n \to \infty} \frac{1!+3!+\ldots+(2n-1)!}{2!+4!+\ldots+(2n)!}$$ I have tried some standard approaches like dividing by $(2n)!$ and comparing consecutive terms. Hint, please :) Thanks in advance.","['factorial', 'limits']"
1592510,"Which line bundle has transition function $\psi_{12}([z_1,z_2])=\frac{z_1/z_2}{|z_1/z_2|}$?","We know that the complex line bundles over $\Bbb{CP}^1$ are classified by the integers. Each is isomorphic to one of the bundles $\mathcal{O}(n)$ for $n\in\Bbb Z$ , where $\mathcal{O}(-1)$ is the tautological line bundle. Question: In which class does the following line bundle belong? Let $U_i\subseteq\Bbb{CP}^1$ be the open set of elements $[z_1,z_2]\in\Bbb{CP}^1$ such that $z_i\neq 0$ . Let $L$ be the line bundle on $\Bbb{CP}^1$ defined by the transition function $$\psi_{12}:U_1\cap U_2\to \mathrm{GL}(1,\Bbb C),\quad \psi_{12}([z_1,z_2])=\frac{z_1/z_2}{|z_1/z_2|}.$$ We have that $\mathcal{O}(n)$ is the vector bundle with transition function $$\psi_{12}:U_1\cap U_2\to \mathrm{GL}(1,\Bbb C),\quad \psi_{12}([z_1,z_2])=(z_1/z_2)^n,$$ so our line bundle $L$ is not directly one of those. It should be isomorphic to one of those but I cannot find any explicit isomorphism.","['complex-geometry', 'smooth-manifolds', 'projective-space', 'vector-bundles', 'differential-geometry']"
1592512,Prove $(1+2+...+k)^2 = 1^3 + ... + k^3$ using induction [duplicate],"This question already has answers here : Proving $1^3+ 2^3 + \cdots + n^3 = \left(\frac{n(n+1)}{2}\right)^2$ using induction (16 answers) Closed 8 years ago . I need to prove that
$$(1+2+{...}+k)^2 = 1^3 + {...} + k^3$$
using induction.
So the base case holds for $0$ because $0 = 0$ (and also for $1$: $1^2 = 1^3 = 1$) I can't prove it for $k+1$ no matter what I try! Can you give me a hint?","['induction', 'discrete-mathematics']"
1592530,Is there a reason why Harmonic functions are defined on open sets?,"Whenever I see a definition of a harmonic function, it's always defined as follows A function $f : U \to \Bbb{R}$ is called harmonic (where $U$ is an open subset of $\Bbb{R}^n$) iff it is twice continuously differentiable on $U$ and satisfies Laplace's equation $\Delta f = 0$. Is there a reason why $U$ is always chosen to be open and what are the ramifications if $U$ is chosen to not be an open set in the context of the Laplace operator (in which we take the second partial derivatives)? Edit: I have recently read that for a ""good"" subset $V$ of $\Bbb{R}^n$ i.e. a submanifold of codimension 1 with boundary, we can extend the notion of differentiability by extending $V$ for any point $v \in V$ to involve a neighbourhood around $v$ over which we can differentiate. Then the derivative of $V$ is just the derivative of the extension. Supposedly, unless $V$ is ""good"", then the derivative needn't be uniquely defined. Why does this happen to be the case and what's the necessity in defining ""good"" as we have done? Thanks in advance!","['complex-analysis', 'harmonic-functions', 'differential-geometry', 'differential-topology']"
1592550,Examples of torsion-free abelian groups with finite automorphism group,$\mathbb{Z}$ is a torsion-free abelian group with finite automorphism group. Are there other examples of such groups? Jumping from $\mathbb{Z}$ to $\mathbb{Q}$ is not good; since $\mathbb{Q}$ has infinite automorphism group. Is there any group in-between $\mathbb{Z}$ and $\mathbb{Q}$ with required property?,"['abelian-groups', 'abstract-algebra', 'group-theory']"
1592553,Lebesgue measure of some sets,"Let $p(\mathbf{x})$ be a non-zero polynomial in the polynomial ring $\mathbb{R}[\mathbf{x}]$. It is known that the affine variety $$ V = \{\mathbb{x} \in \mathbb{R}^{n}:p(\mathbf{x}) =0 \}$$ has Lebesgue measure zero in $\mathbb{R}^{n}$. Now, consider the following set
$$ S_{\varepsilon} = \{\mathbb{x} \in \mathbb{R}^{n}: |p(\mathbf{x})| \leq \varepsilon\},$$ with $\varepsilon > 0$. 1) What can be said about the Lebesgue measure of $S_{\varepsilon}$? 2) Let $\mu$ be a Lebesgue measure. Is it true that $\lim_{\varepsilon \rightarrow 0^{+}} \mu (S_{\varepsilon}) = \mu(V)=0$? I just need some ideas to answer these questions. Thanks in advance!","['polynomials', 'lebesgue-measure', 'algebraic-geometry']"
1592558,Germs and local ring.,"I'm having trouble understanding the following argument (which I believe to be somewhat incomplete or flawed). Let $A=C(X)$ be the set of continuous functions from the topological space $X$ to the complex plane $\mathbb{C}$. We define $m_{x} = \{f \in C(X): f(x) = 0 \}$ and $A_x$ the ring of germs at point $x$. The statement is the following $A_x \simeq A_{m_x}$. (1) I don't see how one defines $A_{m_x}$ since the set contains global functions that might not be well-defined as we quotient by functions $f$ such that $f(x) \neq 0$, but it doesn't necessarily mean that $f \neq 0$. Though it's indeed well defined in a neighborhood of $x$. (2) Now using the universal property of localization, we sure want to define $\phi : A_{m_x} \rightarrow A_x$ s.t we have $\phi(a/s) = \iota(a)\iota(s)^{-1}$ where $\iota$ is the inclusion map $\iota: A \rightarrow A_x$. We want $\phi$ to be an isomorphism. It is surjective; now we want it to be one-on-one. Now I don't see how this is possible as $\phi(a/s) = 0$ iff $a = 0$ in a neighborhood of $x$, which doesn't imply that $a=0$ globally. I guess there's something I don't really fathom, or my textbook might just be flawed. Anyway, thanks for your help.","['abstract-algebra', 'general-topology', 'germs', 'commutative-algebra']"
1592591,"Is the Wave function a ""Smooth"" function of the Potential?","Consider the Schroedinger equation in a spherically symmetric system. In the unit system under which energy is measured in Hartree and length in Bohr radius $a_0$, the schroedinger equation can be written as $$
-{d^2 R_{l,\epsilon}(r) \over dr^2} + \left( V_d(r) + {l(l+1)\over 2 r^2} \right)R_{l, \epsilon}(r) = \epsilon R_{l, \epsilon}(r)
$$ . In the above equation, $V_d(r)$ is an attractive potential that's dependent on $d$. Specifically, we will consider the following potential. $V_{0}(r) = -Z(r)/r$, where $\lim_{r \rightarrow 0}Z(r) = Z$ and $\lim_{r \rightarrow \infty} Z(r) = 1$. $V_d(r) = V_0(r) + {1 \over r} - {e^{-r/d} \over r}$ ($d>0$). Consider the wave function $R_{l, \epsilon}^{reg}(r)$ that is regular at the origin and which is normalised to unit magnitude at infinity. In other words, $$
R_{l, \epsilon}^{reg}(r) \rightarrow \sin(k r + \phi)
$$,
as $r \rightarrow \infty$. $k = \sqrt{2 \epsilon}$. My question is, for at least $\epsilon>0$, is $R_{l, \epsilon}^{reg}(r)$ a ""smooth"" function of $d$?","['functional-analysis', 'ordinary-differential-equations', 'mathematical-physics']"
1592598,"A ""flowchart"" for handling Diophantine equations","There's no algorithm that correctly decides if a Diophantine equation does or doesn't have a solution. Still, many equations can be successfully analyzed, and I'm wondering if anyone wrote down a ""cookbook"" for dealing with Diophantine equations of various shapes and forms, including the higher-degree, higher-dimensionality ones. Given a system of polynomial equations with integer coefficients, we may wish to determine if there are any solutions in integers, and if so, whether there are finitely or infinitely many, and whether they can be explicitly described; we may also wish to determine if there are any solutions in rational numbers, and if so, whether there are finitely many, etc. If the system is linear, do this (easy). If there is just one variable, do that (easy). If there's one quadratic equation in two variables (or a homogenous one in three variables), there's again an explicit procedure: check if there's a singularity, determine if there are integer solutions at all (Hasse Minkowski), parametrize the curve, etc. I think all questions can be effectively answered in the case of genus 0 curves. If it's an elliptic curve, follow these steps... (I don't think all questions can be algorithmically answered, at present). Higher genus curve? What do you do? Find the Jacobian? What else? Higher dimensional surfaces and varieties? What do you do? Which heuristics do you try, what are some useful families of equations that can be attacked? All of those pieces are well covered in the literature - I'm just wondering if there's a good resource that succinctly describes the various alternatives that we may be able to handle. Note: this older question has similar goals, but it stops short of giving details on how to handle genus 0 and genus 1 and says nothing much about higher genera and higher dimensional varieties.","['number-theory', 'diophantine-equations']"
1592603,What is the Pedagogical Justification for Substitution?,"My mom is re-learning calculus for the third time (She tutors High School students). And she asked me a question invovling limits:
$$\lim_{x\rightarrow \infty} \frac{\ln 2x}{\ln 3x}$$
I led her through my solution which was as follows:
$$\lim_{x\rightarrow \infty} \frac{\ln 2x}{\ln 3x} = \lim_{x\rightarrow \infty} \frac{\ln 2 + \ln x}{\ln 3 + \ln x} =1 $$
When she didn't like that (the final jump), I tried:
$$ \lim_{x\rightarrow \infty} \frac{\ln 2 + \ln x}{\ln 3 + \ln x} =  \lim_{t\rightarrow \infty} \frac{\ln 2 + t}{\ln 3 + t}  = 1$$ This seemed to be more respectable to her, but still she questioned the substitution $$t \gets \ln x$$ I used here. I didn't have a ready answer for how and why and when-it-is-OK for substitutions in general. I thought I'd ask here if someone can point me to a better (pedagogically better) way to explain the use of substitutions in limits (or derivatives or integrals--which are both limits). 
Thanks.","['education', 'limits']"
1592610,Find highest product of natural numbers which sum to $S$?,"Given a number $S$, how can we find the highest $P$ such that there exist natural numbers $a$, $b$, & $c$ where $a + b + c = S$ and $a \times b \times c = P$?",['number-theory']
1592613,Chord of a parabola $y^{2}= 4ax$,"Prove that on the axis of any parabola
$y^2=4ax$
there is a certain point $K$ which has the property that,if a chord $PQ$ of the parabola be drawn through it ,then
$$\frac{1}{PK^2}+\frac{1}{QK^2}$$
is same for all positions of the chord.Find also the coordinates of the point $K$. We can apply the parametric equations of a parabola
Let the points $P$ and $Q$ be
$(at_1^{2},2at_1)$ and $(at_2^{2}, 2at_2)$ So the equation of the chord would be
$$y(t_1+t_2)=2x+2at_1t_2$$ Hence from there we have that the coordinates of $K$ are
$(−at_1t_2,0)$ Now our aim is to show that
$\frac{1}{PK^2}+\frac{1}{QK^2}$
is independent of
$t_1$ and $t_2$. I tried and applied the distance formula but no benefit.","['conic-sections', 'geometry']"
1592615,"Topology: reference for ""Great Wheel of Compactness""",This seems to be a very informative diagram showing the relationship between four forms of compactness in a general topological space. Prior to finding this I was trying to make sense of a seemingly countless (now seen to be countable = 12) collection of theorems relating one to another. The 12 relations are seen to simply to 6 proofs (A - F) and 6 corollaries by transitivity. I found a version of this here https://pantherfile.uwm.edu/ancel/www/OLD%20COURSES/MATH%20752%20SPRING%202011/CHAPTER%20III/751.F10.IIIB-C.pdf I haven't seen it anywhere else and would be interested if anyone has information about it.,"['reference-request', 'general-topology', 'compactness', 'soft-question']"
1592620,"Compute Lebesgue measure of set of all real numbers in $[0,1]$ whose decimal representations don't contain the number 7 [duplicate]","This question already has answers here : What is the measure of the set of numbers in $[0,1]$ whose decimal expansions do not contain $5$? (3 answers) Closed 3 years ago . Consider measure space $(S, \Sigma, \mu) = (\mathbb R, \mathscr B(\mathbb R), \lambda)$. Let $V^C \subseteq S$ denote the set of all numbers in $[0,1]$ whose decimal representations don't contain the number 7. Prove that $V^C \in \Sigma$. Compute $\lambda(V^C)$. What I tried: I think we have $$V = \bigcup_{n=1}^{\infty} V_n$$ where $v_n \in V_n$ can be written $v_n = 0.s_1s_2...$ where $s_1 \ne 7, ..., s_{n-1} \ne 7, s_n = 7$ $$V_n = \bigcup_{s_1, ..., s_{n-1} \ne 7} [0.s_1...s_{n-1}7, 0.s_1...s_{n-1}8)$$ $V$ is a finite union of pairwise disjoint $9^{n-1}$ intervals and hence is a Borel set, which is Lebesgue measurable. $V$ is a countable union of  pairwise disjoint Borel sets and hence is a Borel set, which is Lebesgue measurable. Thus, $V^C$ is Lebesgue measurable. 2. $$\lambda(V) = \lambda(\bigcup_{n=1}^{\infty} V_n) = \sum_{n=1}^{\infty} \lambda(V_n)$$ $$\lambda(V_n) = \lambda \left(\bigcup_{s_1, ..., s_{n-1} \ne 7} [0.s_1...s_{n-1}7, 0.s_1...s_{n-1}8)\right)$$ $$= \sum_{i=1}^{9^{n-1}} \lambda ([0.s_1...s_{n-1}7, 0.s_1...s_{n-1}8))$$ $$= \sum_{i=1}^{9^{n-1}} \frac{1}{10^n} = \frac{1}{10^n} \sum_{i=1}^{9^{n-1}} (1) = \frac{1}{10^n} (9^{n-1} - 1 + 1) = \frac{9^{n-1}}{10^n}$$ $$\to \lambda(V) = \sum_{n=1}^{\infty} \lambda(V_n) = \sum_{n=1}^{\infty} \frac{9^{n-1}}{10^n} = 1$$ $$\therefore, \lambda(V^C) = 0$$","['decimal-expansion', 'real-analysis', 'lebesgue-measure', 'measure-theory', 'elementary-set-theory']"
1592644,convergence of $\sum_{n=1}^\infty \sqrt{n}a_n$ implies the convergence of $\sum_{n=1}^\infty a_n$,"How the convergence  of $\sum_{n=1}^\infty \sqrt{n}a_n$ implies the convergence of $\sum_{n=1}^\infty a_n$? I know this if $a_n>0$. But for arbitrary $a_n$, I have no idea...",['sequences-and-series']
1592647,What is the difference between an impulse response and a transferfunction?,"An imupulse response, is the output you get when you apply an impulse, like a delta dirac function, to your system (only for LTI?).
By knowing the impulse response you know the system. The transferfunction relates the input to the output. I.e. this is a representation of the system. So aren't both the same? Or Did I misunderstand something?","['control-theory', 'ordinary-differential-equations', 'laplace-transform']"
1592650,"In the trigonometric identity $\cos(\frac{\pi}{2} -\theta)$, why are we reflecting the graph in vertical axis.","I was wondering why do we need to reflect the graph in vertical axis in the trigonometric identity: $\cos(\frac{\pi}{2} -\theta) = \sin(\theta)$. It seems that if we only translate the graph of $\cos(\theta)$ by $\frac{\pi}{2}$ it would take the same values as the graph of $\sin(\theta)$, so why do we reflect the graph by changing sign of $\theta$ to negative.",['trigonometry']
1592651,3 normals on a parabola,"If $(x_1, y_1), (x_2, y_2)$ and $(x_3, y_3)$ be three points on the parabola  $y^2 = 4ax$ and the normals at these points meet in a point then how will we  prove that
$$  
\frac{x_1 -x_2}{y_3} + \frac{x_2-x_3}{y_1} + \frac{x_3-x_1}{y_2} = 0?
$$ I tried as follows. Let the normals meet at $(h,k)$. Then, $$am^3 + (2a-h)m + k = 0.$$ After Solving the equation,
$$
x_1 y_1(y_2-y_3) + x_2 y_2(y_3-y_1) + x_3 y_3 (y1 - y2) = 0
$$ Substituting $x_k = y_k^2/4a$ for $k \in \{1,2,3\}$ But I am not getting the result.","['analytic-geometry', 'conic-sections', 'geometry']"
1592652,"Example of a relation that is symmetric and transitive, but not reflexive [duplicate]","This question already has answers here : Examples and Counterexamples of Relations which Satisfy Certain Properties (2 answers) Closed 3 years ago . Can you give an example of a relation that is symmetric and transitive, but not reflexive? By definition, $R$ , a relation in a set $X$ , is reflexive if and only if $\forall x\in X$ , $x\,R\,x$ . $R$ is symmetric if and only if $\forall x, y\in X$ , $x\,R\,y\implies y\,R\,x$ . $R$ is transitive if and only if $\forall x, y, z\in X$ , $x\,R\,y\land y\,R\,z\implies x\,R\,z$ . I can give a relation $\leqslant$ , in a set of real numbers, as an example of reflexive and transitive, but not symmetric. But I can't think of a relation that is symmetric and transitive, but not reflexive.","['relations', 'examples-counterexamples', 'elementary-set-theory']"
1592663,How find the sum of the last two digits of $(x^{2})^{2013} + \frac{1}{(x^{2})^{2013}}$ for $x + \frac{1}{x} = 3$?,Let x be a real number so that $x + \frac{1}{x} = 3$. How find the sum of the last two digits of $(x^{2})^{2013} + \frac{1}{(x^{2})^{2013}}$?,['algebra-precalculus']
1592684,Maths for economics: finding the level of production that minimises marginal cost [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Let the total cost function of a firm be given by: $$TC(Q)= 16Q^3 - 72Q^2 + 446Q + 90$$ Find the level of production that minimises the marginal cost of production . (This is basically taking the first derivative of $TC$ then equating it to zero and finding the value of $Q$ - this is the part I can't do).","['derivatives', 'economics', 'calculus']"
1592694,Minimizing the area of a square enclosing a given set of points,"I am learning about the science of algorithms and I'm studying some problems with their optimum algorithm. The problem I describe below is one of them. I need a lower and an upper bound of its runtime complexity. What is its optimum algorithm? I don't need any implementation. Problem: Given a set of coordinates in a $2$-dimensional plane, how do we find
  the area of a minimum square which includes all the points? The points
  can exist on the border also. And the square's orientation doesn't have
  to be parallel to the Cartesian axes. For example, Consider the points $(-1,1)$, $(1,3)$, $(0,2)$, $(-2,2)$. The minimum square height to cover these points is $2\sqrt{2}$. Hence the area is $8$. I hope that the explanation is clear.
Thank you in advance!","['optimization', 'complex-analysis', 'algorithms', 'computational-complexity', 'geometry']"
1592699,Car parking related probability,A driver parks a car in a row of $25$ cars randomly at any place but not ends. After coming back he finds $10$ cars are gone so what is the probability that both the neighbouring cars have gone? What I did $$\dfrac{{24\choose 8}}{{23\choose 1}{24\choose 10}}$$  $24C8$ as we want two cars to go so we want to select only $8$ cars. And driver can park in $23$ ways and cars can go in $24C10$ ways. But that doesn't yield the answer what am I missing on? Please any hints using basic probability equations.,"['combinatorics', 'probability']"
1592703,Derivative of dot product vs derivative of scalars,"Suppose $\vec{v}(t)$ is the velocity (vector) function. Then: $$\frac{\mathrm{d} (\vec{v}\cdot\vec{v})}{\mathrm{d} t}=2 \vec{v} \cdot \frac{\mathrm{d} \vec{v} }{\mathrm{d} t}=2 \vec{v} \cdot \vec{a}=2va \cos \varphi$$ where $\vec{a}$ is the acceleration vector and $\varphi$ - the angle between $\vec{a}$ and $\vec{v}$. On the other hand: $$\frac{\mathrm{d} (v\cdot v)}{\mathrm{d} t}=2 v \cdot \frac{\mathrm{d} v }{\mathrm{d} t}=2 v a \neq \frac{\mathrm{d} (\vec{v}\cdot\vec{v})}{\mathrm{d} t}$$ Although $\vec{v}\cdot\vec{v}=v\cdot v$ . Where is my mistake? I ask this because often times in physics I see the substitution $\vec{v} \cdot \vec{v}=v^2$ used in differentiation, although the results we get are different.","['derivatives', 'calculus']"
1592708,How to compute $\lim\limits_{x \to +\infty} \left(\frac{\left((x-1)^2-x\ln(x)\right)(x)!}{(x+2)!+7^x}\right)$? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question I have a problem with this limit, I don't know what method to use. I have no idea how to compute it. Can you explain the method and the steps used? $$\lim\limits_{x \to +\infty} \left(\frac{\left((x-1)^2-x\ln(x)\right)(x)!}{(x+2)!+7^x}\right)$$","['factorial', 'limits']"
1592720,Is the sequence $\{(\ln (n+1)/\ln n)^n \}$ convergent ? If so then what is its limit?,"Is the sequence $\{(\ln (n+1)/\ln n)^n \}$ convergent ? If so then what is its limit? I tried breaking it up as 
$$\Bigg(1+ \dfrac{\ln \dfrac{n+1}n}{\ln n}\Bigg)^n,$$ but nothing's coming up. Please help.","['real-analysis', 'sequences-and-series', 'limits']"
1592728,How to find $P(-1)$ for $\frac{P(2x)}{P(x+1)}=8-\frac{56}{x+7}$ and $P(1)=1$?,$P(x)$ is a polynomial such that $P(1)=1$ and $\frac{P(2x)}{P(x+1)}=8-\frac{56}{x+7}$ and $P(-1)$ is rational. How to find $P(-1)$?,"['algebra-precalculus', 'polynomials', 'linear-algebra']"
1592752,Why does the minimum exist in optimal transport?,"Let $P,Q$ be any two distributions and let $\mathcal{M}(P,Q)$  be the set of all couplings of $P$ and $Q.$ For a given metric $d(\cdot,\cdot),$ the optimal transport cost is: $$\min_{(X,Y)\sim M\in \mathcal{M}(P,Q)} \mathbb{E}d(X,Y)~.$$ Why is the minimizing coupling guaranteed to exist for $P,Q$ being distributions over some general space? This quantity frequently appears in the book Concentration Inequalities by Boucheron, Lugosi, Massart (Chapter: The Transportation Method). Yet, no argument is provided as to why the minimizer of the transportation cost must exist.",['probability-theory']
1592759,Is this some entropy I haven't heard of?,For a discrete finite probability distribution $p(s)$ the function $$\sum\limits_s p(s)\log ^2 p(s)$$ looks like the Shannon entropy but has a square on the $\log$. Is there a name for this? Or it is meaningless?,"['entropy', 'probability', 'probability-distributions']"
1592774,Hypothesis of dominated convergence theorem,"The dominated convergence theorem says : Suppose $(f_n)$ is a sequence of measurable function s.t. $f_n(x)\longrightarrow f(x)$ a.e. as $n\to \infty $. If $|f_n(x)|\leq g(x)$ and $g$ is integrable, then $$\lim_{n\to\infty }\int f_n=\int f.$$ Quest 1) If $|f|$ is integrable, do we directly have $\lim_{n\to\infty }\int f_n=\int f$ or we need to have $|f_n(x)|\leq |f(x)|$ ? Quest 2) If no, I have that $g$ is continuous with compact support (and thus integrable). Why the dominated convergence theorem allows me to conclude that $$\lim_{\delta\to 1}\int g(\delta x)dx=\int g(x)dx\ \ ?$$ Don't talks about change the variable $u=\delta x$ to prove it, it's not my question (I know how to prove this). My question is precisely : Why can we conclude using dominated convergence ? Because we don't necessarily have $|g(\delta x)|\leq g(x)$, and thus I'm a little annoyed by this argument.",['measure-theory']
1592781,Stability of sampled-data systems using Lyapunov functions,"For continuous systems, Lyapunov functions provide a general technique to establish stability. For example, the simple system $x' = -x$, a Lyapunov function is $V(x) = \frac{1}{2}x^2$. It is easy to see that $V(0) = 0$ $V(x) > 0$ for $x \neq 0$ $V(x)' = \frac{dV(x)}{dx}\frac{dx}{dt} = -x^2 < 0$ for $x\neq 0$ Is there an analogous technique for sampled-data systems? For example, suppose I take the simple continuous system $x' = -x$ and naively turn it into a sampled-data system by introducing a zero-order hold. In other words, every $\delta$ time units, $x'$ is set to $-x$ and held at that value for the next $\delta$ time units. More precisely, $$\forall k \in N, ~~~~ \forall t \in [k*\delta, (k+1)*\delta], ~~~~ x'(t) = -x(k*\delta)$$ Looking at the solutions to this system shows that it is asymptotically stable for $\delta < 2$. However, looking at the solutions of a system is only possible for simple systems. Is there instead a way of establishing asymptotic stability of this system using some sort of Lyapunov function?","['control-theory', 'ordinary-differential-equations', 'linear-control']"
1592788,Does the Morse homology depend on the orientation?,"Before asking my question I need to define some objects. I will follow the book ""M. Audin, M.Damian - Morse theory and Floer homology"", but the terminology is quite standard: Let $M$ be a smooth compact manifold and consider a Morse-Smale pair $(X,f)$ on $M$ ( $X$ is a gradient-like vector field and $f$ is an adapted Morse function). If $a,b$ are two critical points of $f$ , we indicate with $\mathcal L(a,b)$ the manifold such that every point is a trajectory of $X$ ''starting'' from $a$ and ''ending'' in $b$ . One can show that if $\text{ind}(a)=\text{ind}(b)+1$ then $\mathcal{L}(a,b)$ is a finite set. Moreover if we orient the stable manifold $W^s(a)$ , remember that it is a disk, we induce an orientation on $\mathcal L(a,b)$ , namely at each point we associate $\pm 1$ if $\text{ind}(a)=\text{ind}(b)+1$ . At this point one can define the Morse-Smale complex: $$C_k:=\sum_{a\in\text{Crit}_k(f)}\mathbb Za$$ where clearly $\text{Crit}_k(f)$ is the set of critical points of index $k$ . The map $d_k:C_k\longrightarrow C_{k-1}$ acts on the generators of $C_k$ in the following way: $$d_k(a)=\sum_{a\in\text{Crit}_{k-1}(f)}N(a,b)b$$ where $N(a,b)\in\mathbb Z$ is the sum of the $\pm 1$ (the orientations) attached to the points of $\mathcal L(a,b)$ . Question: From the above construction it is evident that the Morse-Smale complex (in particular the number $N(a,b)$ ) depends on the
  orientation that we fix on the stable manifolds $W^s(a)$ . This sounds
  very strange to me, indeed I'd expect a complex independent from the
  orientation. Maybe by passing to the homology group one can recover
  the independence but I can't see it. Many thanks.","['homology-cohomology', 'differential-geometry', 'differential-topology', 'morse-theory']"
1592800,Kähler metrics on the coadjoint orbits of a compact Lie group,"Let $G$ be a compact Lie group with Lie algebra $\mathfrak{g}$. It is well-known that each orbit for the coadjoint representation of $G$ on $\mathfrak{g}^*$ carries a canonical symplectic structure, known as the Kirillov-Kostant-Souriau symplectic form . Moreover, I've read at a few different places that the coadjoint orbits are also Kähler manifolds : Theorem. Let $G$ be a compact Lie group, $\mathcal{O}$ a coadjoint orbit and $\omega$ its Kirillov-Kostant-Souriau symplectic form. Then, there exists a unique $G$-invariant Kähler metric on $\mathcal{O}$ that is compatible with $\omega$. For example, this result is mentioned in Robert Bryant's lecture notes An Introduction to Lie Groups and Symplectic Geometry on page 150, and at the beginning of this paper by Kronheimer. However, I didn't find any proof of that theorem. Does someone know how to prove it or can point a good reference? According to Bryant, it is ""not hard"" to prove it ""using roots and weights"". But I wasn't able to do so.","['smooth-manifolds', 'symplectic-geometry', 'kahler-manifolds', 'differential-geometry', 'lie-groups']"
1592806,Periodical solutions of this system of differential equations,"We have the system of differential equations:
$$x'=(1+m)y+x(1-(x^2+y^2))(4-(x^2+y^2)),$$
$$y'=-x+y(1-(x^2+y^2))(4-(x^2+y^2)),$$
with $m>0$. How do I show that $(0,0)$ is the only (instable) critical point? How do I show that there is an $m_0$ such that for $0<m<m_0$ this system has TWO periodic (not-constant) solutions? What I have done so far: I wrote the sytem above in polar coordinates:
$$r'=mr\sin\theta\cos\theta+r(1-r^2)(4-r^2),$$
$$\theta'=-1-m\sin^2\theta.$$
But I don't know how this can help me. For question 2. I must use Poincare-Bendixson, but I don't see how exactly.","['ordinary-differential-equations', 'systems-of-equations']"
1592818,"Is the function $d(x,y) = \frac{\|x-y\|}{\|x\|\|y\|}$ a metric?","$d$ is defined for all $x,y \in \mathbb{R}^2 - \{0\}$. It's clear that $d(x,y) = 0 \iff x=y$ and $d(x,y)=d(y,x)$ I am having issues with triangle inequality. I couldn't find a counterexample for which the triangle inequality doesn't hold. So I tried to prove it. What I have so far is:
$$d(x,z) =  \frac{\|x-z\|}{\|x\|\|z\|} \leq  \frac{\|x-y\|}{\|x\|\|z\|}
+  \frac{\|y-z\|}{\|x\|\|z\|} $$ I'm stuck here.
I appreciate if you could give me some hints. Thanks.","['real-analysis', 'metric-spaces']"
1592823,3 Statements of axiom of choice are equivalent,"This winter I started to study much harder the set theory and especially the axiom of choice. Unfortunately, I have problems with solving the next exercise: Prove that the 3 statements of the axiom of choice are equivalent : 1) For any non-empty collection $X$ of pairwise disjoint non-empty sets, there exists a choice set. 2) For any non-empty collection $X$ there is a choice function. 3) For any non-empty set $X$, there exists a function $f:P(X)\setminus\{\varnothing\}\to X$ so that for any non-empty set $A\subseteq X$, $f(A) \in A$.","['set-theory', 'axiom-of-choice']"
1592830,"Find the domain and image of the relation $R=\{(a, b), (c, b), (a, b)\}$","Let $A={a, b, c}$, and let $R=\{(a, b), (c, b), (a, b)\}$. Find the domain of $R$ and the image of $R$. This would be very elementary, but I want to get my answer checked. Let $R$ be a relation from $A$ to $B$. Then by definition, then the domain of the relation $R$ in symbols is $$\operatorname{Dom}(R)=\{a\in A\;\vert\;(a, b)\in R\text{ for some }b∈B\}$$ and the image of the relation $R$ in symbols is
$$\operatorname{Im}(R)=\{b\in \;\vert\;(a, b)\in R\text{ for some }a\in A\}$$ So, $\operatorname{Dom}(R)=\{a, c\}, \operatorname{Im}(R)=\{b\}$.","['relations', 'elementary-set-theory', 'discrete-mathematics']"
1592872,How to compute $\lim_{x \to 0} (\frac{x^5 e^{-1/x^2}+x/2 - \sin(x/2))}{x^3})$?,"I have a problem with this limit. I have no idea where is the problem.
Can you correct my mistake? Thanks $$\lim\limits_{x \to 0} \left(\frac{x^5 e^\frac{-1}{x^2}+\frac{x}{2} - \sin(\frac{x}{2})}{x^3}\right)$$ I used the developments of McLaurin $e^x$ and $\sin x$ $$\lim\limits_{x \to 0} \left(\frac{x^5 (1-\frac{1}{x^2}+\frac{1}{2x^4})+\frac{x}{2} - ((\frac{x}{2})-(\frac{x^3}{48}))}{x^3}\right) = 
\lim\limits_{x \to 0} \left(\frac{x^5-x^3+ \frac{x}{2} +\frac{x}{2} - \frac{x}{2}+\frac{x^3}{48}}{x^3}\right)=$$ $$\lim\limits_{x \to 0} \left(\frac{-x^3+\frac{x^3}{48}}{x^3}\right)= 
\lim\limits_{x \to 0} \left(\frac{-\frac{47x^3}{48}}{x^3}\right)=\lim\limits_{x \to 0} \left(-\frac{47x^3}{48x^3}\right)= -\frac{47}{48}$$ but the result is wrong.","['taylor-expansion', 'limits']"
1592880,Meaning of the word dom.,"Let X be a set and $\sum$ a $\sigma$ algebra of subsets of X. Let f and g be real valued functions defined on domains : dom $f$ and dom $g$ $\subseteq X$. If $f$ and $g$ are measurable , so is $f+g$ where $(f+g)(x)=f(x)+g(x)$ for $x \in$dom$f \cap $ dom$g$ What does dom mean in this context? What are dom $f$ and dom $g$? And why are they so significant?","['notation', 'measure-theory']"
1592892,"Prerequisites for Vakil's ""Foundations of Algebraic Geometry"" (Or other texts)","Good day to you all. I'm currently an undergraduate student with quite a strong affinity for self studying certain topics which interest me. One area which has fascinated me for quite a while is algebraic geometry, especially the (apparently) incredibly abstract machinery used in the modern formulation. 
I've so far been able to ascertain that two good books on the subject are: Algebraic Geometry - R. Hartshorne Foundations of Algebraic Geometry - Ravi Vakil. Having looked through the ToCs for these books, it appears that Vakil's book is much more comprehensive, but I cannot entirely say for sure. I think I want to set this book as a goal, a mountain to be climbed, so to speak. Of course, before I set such a goal I need to know whether or not it is at all realistic. The introduction to the text seems to indicate that Aluffi's Algebra text, as well as some general topology and basic notions from 1st or 2nd year undergraduate, will suffice as prerequisites, and I'm wondering if anyone who has read the book could confirm or deny this. What more would be needed for this book, or for Hartshorne's? If you would like a rough idea of my current mathematical level, I am currently only in my first year of an undergraduate degree at Oxford, but have so far already worked through Introduction to Abstract Algebra by W. Nicholson (which covers the usual stuff up to Galois) as well as a few other topics such as some axiomatic set theory, basic real analysis (up to integration), and of course the linear algebra, geometry, etc. already covered in my course. I'm currently working through Algebra: Chapter 0 by Aluffi as a second Algebra text, as well as Introduction to Complex Analysis by H. Priestley, and Introduction to Metric and Topological Spaces by W. Sutherland. By the time I've finished these books, will I likely have enough of a background to begin to tackle Vakil's book? If not, what more would be required? I will understand if this is an incredibly naive question, and I apologise if this is so. I'm not entirely clear on the level of mathematical maturity required for the text, hopefully my current reading list will reveal mine. I welcome any suggestions of other places to look to sate my curiosity, though bear in mind one of the main attractions to me at the moment is the abstraction. As always, my tags are guesswork.","['book-recommendation', 'algebraic-geometry']"
1592898,What do we know about $\sum_\limits{n=0}^{\infty} \frac{(-1)^n}{kn+1}$?,"Let define, for $k \ge 1$ : $$ f(k) = \sum_\limits{n=0}^{\infty} \frac{(-1)^n}{kn+1}. $$ It is well-known that $f(1) = \ln(2), f(2) = \pi/4$. Some computations on WolframAlpha led me to $f(3) =1/9 (\sqrt3 \pi+\ln(8))$, $f(4) = (\pi+2 \ln(1+\sqrt2))/(4 \sqrt2)$ and also (if I'm not mistaken) :
$$ f(5) = 1/b \cdot \Big(\frac{8\sqrt2}{\sqrt a} \;\pi \;-\; 6 (\sqrt5 - 1)\ln(2) \;+\; 2 (3-\sqrt5)\ln(\sqrt 5 + 1)\\ - 4 \ln(\sqrt5 - 1)
\;+\; (\sqrt5 - 5)\ln\Big( \frac{\bar a}{a} \Big) \Big)$$ with $a = 5+\sqrt5, \bar a = 5-\sqrt5,b=20(\sqrt 5 - 1)$. Then, I would like to ask the following : is it true that (for general $k \geq 1$) $f(k) \in \overline{ \mathbb Q} (A)$ where $A = \{ \pi \} \cup \{ \ln(x) \mid x \in \overline{ \mathbb Q} \cap \mathbb R \}$, as it seems to be the case for small values of $k$ ?
Are there some available results on these series? I looked at some special functions : this result on the digamma function is related to my question. I don't know if it is possible to use this result in order to compute $f(k)$. Any comment or answer would be appreciated!","['reference-request', 'sequences-and-series', 'digamma-function']"
1592924,Is there an irreducible projective hypersurface such that its complement has zero Euler characteristic?,"We know that, if $f=X_0X_1...X_n \in \mathbb{C}[X_0,...,X_n]$ and $Z(f)\subset \mathbb{CP}^n$, then the Euler characteristic of its complement is zero, i.e.
$$
\chi(\mathbb{CP}^n\setminus Z(f))=0.
$$
But $f$ is not irreducible. Let $Z\subset \mathbb{CP}^n$ be a smooth, irreducible hypersurface. Then, we know that
$$
\chi(Z)=\frac{1}{d}((1-d)^{n+1}-1)+n+1,
$$
where $d$ degree of $Z$.
In particular, if $g=X_0^2+...+X_3^2 \in \mathbb{C}[X_0,...,X_3]$, we have
$$
\chi(Z(g))=\frac{1}{2}((1-2)^4-1)+4=4,
$$
then $\chi(\mathbb{CP}^3\setminus Z(g))=0$, since $\chi(\mathbb{CP}^3)=4$. So I ask: is there an irreducible homogeneous polynomial $h \in \mathbb{C}[X_0,...,X_n]$ such that deg$h>2$ and $\chi(\mathbb{CP}^n\setminus Z(h))=0$? Remark: this is not possible if $Z(h)$ is smooth (with deg$h>2$).","['algebraic-topology', 'complex-geometry', 'algebraic-geometry']"
1592928,Prove that a set in $\mathbb R^3$ is not an algebraic set,"I want to prove that the set $\{(\cos(t),\sin(t),t)\in A^3(\mathbb R); t\in \mathbb R \}$ is not an algebraic set. I already proved that the set $\{(\sin(t),t)\in A^2(\mathbb R);t\in \mathbb R \}$ is not algebraic but the method that I used doesn't seems to be general.","['algebraic-curves', 'algebraic-geometry']"
1592933,"Why is the integral $\int_0^1t\,dW_t$ a normal random variable?","Consider the random variable $X=\int_0^1t\,dW_t$, where $W_t$ is a Wiener process. The expectation and variance of $X$ are
$$E[X]=E\left[\int_0^1t\,dW_t\right]=0,$$
and $$
Var[X]=E\left[\left(\int_0^1t\,dW_t\right)^2\right]=\int_0^1t^2\,dt=\left.\frac{1}{3}t^3\right|_0^1=\frac{1}{3}.$$ A typical textbook, like Klebaner's one, concludes that the random variable $X$ is a normal random variable with mean $0$ and standard variation $1/\sqrt{3}$. However, two moments cannot lead to the conclusion that $X$ is a normal random variable. So, here is my question: How to prove that $X$ is normal? Is is necessary to calculate all moments of $X$ and to compare them with those of a normal distribution? Or is there a more elegant way?","['probability-theory', 'stochastic-integrals', 'brownian-motion', 'normal-distribution']"
1592954,Definition of integral in the context of measure theory,"Let $\left( X, \mathcal{F}, \mu \right)$ be a measure space. I want to make sense to the integral $$\int_{X}f(x)d\mu (x).$$
It's easy to give meaning to this when $f$ is a simple function. But if $f$ is not simple, the first idea is to approximate $f$ by simple functions such that
$$\int_{x}f(x)d\mu(x) = \lim_{n}\int_{X}f_{n}(x)d\mu(x).\qquad (1)$$
The problem is, that not all functions can be approximated by simple functions, why we need measureable functions which are those functions that can be approximated by simple functions. So the author gives the following definition (when $f$ is non-negative)
$$\int_{X}f(x)d\mu(x) = \sup_{\phi}\int_{X}\phi(x)d\mu(x) \qquad (2),$$
where the supremum is taken over the class of simple functions $\phi$ such that $0\leq \phi \leq f$. So if every measureable function can be approximated by simple functions why do we need (2); couldn't we just use (1) always ? I'm also confused since another author writes the following","['lebesgue-integral', 'measure-theory']"
1592958,Do functions whose domains are infinite sets sequentially or simultaneously map their elements,"Here are two equivalent definitions of the axiom of choice Let $x$ be a set. Suppose that if $y,w \in x$, then $y \neq \varnothing$ and $y\cap w = \varnothing$. Then there is a set $z$ such that if $y \in x$, then $y \cap z$ contains a single element. and Let $I$ be a nonempty, indexing set and let $\{A_i\}_{i\in I}$ be a family of nonempty sets indexed by $I$. Then there is a function $f: I \rightarrow \bigcup_{i \rightarrow I} A_i$ such that $f(i) \in A_i$ for all $i \in I$. The text says with regards to the first definition that if we want to choose one element from each set in an infinite family of nonempty sets, we must make the choices simultaneously instead of sequentially. I would like to know where in either definition it can be understood that the elements are chosen at the same time rather than one-by-one, or is this just mere terminology as to be didactily correct yet mathematically irrelevant. The author also mentions that in proving that if $f: A \rightarrow B$ is surjective, then $f$ has a right inverse, one element $a \in A$ is chosen simultaneously such that $b = f(a)$, which leads me to also wonder if whenever we say, ""Let $a \in A$ such that $b = f(a)$"", we mean that the elements in $A$ are being simultaneously mapped by $f$ to a $b$; and if that's true, then when would $f$ sequentially map the elements in $A$ to some of the elements in $B$? I know my issue with understanding how the elements are chosen is so trivial as to be a mere distracting quibble, but I really want some clarification. Note that this is not an axiom of choice question, since I'm really just curious as to how the elements are selected and in what ways do we distinctly want elements to be sequentially or simultaneously chosen.","['elementary-set-theory', 'terminology', 'functions']"
1592977,Divisors of degree $2g-2$ on a hyperelliptic curve of genus $g$,"Suppose I have a divisor $D$ of degree $2g-2$ on a hyperelliptic curve of genus $g$. Then I can prove that either a) $K_C\otimes\mathcal{O}(-D)=\mathcal{O}_C$, that is $K_C\cong \mathcal{O}(D)$, or b) $K_C\otimes\mathcal{O}(-D)\neq \mathcal{O}_C$, but is a non-trivial degree 0 line bundle. Hence $h^0(C, K_C\otimes\mathcal{O}(-D))=0$. Hence $h^0(\mathcal{O}(D))=2g-2+1-g=g-1$, by Riemann Roch formula. I am looking for an example of the following type. Say genus $g=2$. Let $i$ be the hyperelliptic involution. Can we find a divisor $D$ of the form $D=P+i(P)$ which satisfies (b). That is I want $h^0(C, K_C\otimes\mathcal{O}(-D))=0$.  Is this possible. Or more generally if $C$ is a hyperelliptic curve of genus $g$, is it possible to find a divisor $D=\Sigma_{j=1}^{g-1} p_j+\Sigma_{j=1}^{g-1} i(p_j)$ of degree $2g-2$ which satisfies b) or are all such divisors linearly equivalent to $K_C$? I will be thankful for an example of the above type. Thanks in advance!","['algebraic-curves', 'riemann-surfaces', 'algebraic-geometry']"
1592993,How to compute $\lim\limits_{x \to 0} \left(\frac{e^{x^2} -1}{x^2}\right)^\frac{1}{x^2}$?,"I have a problem with this limit, I don't know what method to use. I have no idea how to compute it.
Can you explain the method and the steps used? Thanks $$\lim\limits_{x \to 0} \left(\frac{e^{x^2} -1}{x^2}\right)^\frac{1}{x^2}$$ Note: In a previous version of this question the limit was written as $\left(\frac{(e^{x})^2 -1}{x^2}\right)^\frac{1}{x^2}$.",['limits']
1592999,Solutions intervals of a differential equation,"I cannot understand the difference between these two ODEs in terms of the intervals in which solutions are defined $y' y=(x+1)$ $y'=\frac{x+1}{y}$ The equation is actually the same but in the first case for $y=0$ I get $x=-1$ and I don't see what is the problem in that point, while in the second one it is necessary to impose $y\neq 0$ of course. What does that mean? Are the solutions different for the two equations? If yes, in what do they differ? Thanks a lot for your help","['ordinary-differential-equations', 'calculus']"
1593000,Proof of inequality involving binomial coefficients,"Proving things is not my forte. Stumbled upon following identity: $$\binom{n+k+1}{k}>\sum_{i=1}^k \binom{\alpha_i}{i}$$ 
For $\alpha_i<\alpha_j $ for $i<j$ $0\leq \alpha_i \leq n+k$ Also $\binom{a}{i}=0$ for $a<i$ Similar to the hockey-stick theorem. Not sure how to apply mathematical induction here. Edit: The right hand side of the inequality gets maximum value for $\alpha_1=n+1$ and $\alpha_k=n+k$. Therefore $$\binom{n+k+1}{k} >  \sum_{i=1}^k \binom{n+i}{i} $$ 
comparing with hockey-stick theorem
\begin{eqnarray}
\binom{n+k+1}{k} &=&  \sum_{i=0}^k \binom{n+i}{i}  \\
&=&\sum_{i=1}^k \binom{n+i}{i} + 1 \\
&>& \sum_{i=1}^k \binom{n+i}{i}\\
&>& \sum_{i=1}^k \binom{\alpha_i}{i}
\end{eqnarray}
Q.E.D Thanks to CuddlyCuttlefish for suggesting maximization of R.H.S of inequality.","['inequality', 'binomial-coefficients', 'induction', 'proof-writing', 'combinatorics']"
1593001,Examples of functions which maintain the ordering of an ordered set in an interesting way.,"I'm looking for functions $f(x, m)$ with the following property. Let $(x, y, z, ...)$ be an ordered set of positive real numbers such that $(x < y < z < \cdots)$. I'm looking for a function which for sufficiently large $N$, $f(x, N) < f(y, N) < f(z, N) < \cdots$, and for sufficiently small $n$, $f(x, n) > f(y, n) > f(z, N) > \cdots$. And for which there is no $m$, such that $n < m < N$, for which $f(x, m) = f(y, m) = f(z, m) = \cdots$. I'm looking for any functions which when given a very large parameter will maintain the sortedness of a set of numbers, and when given a very small parameter, will cause the set to be in reverse order, but which ""jumbles"" the ordering somewhere in the middle rather than simply condensing everything to a single point before the ordering is reversed. An example of a function which fails is $f(x, m) = mx$. For $m>0$ this will monotonically increase (maintaining the ordered property), and for $m<0$ it will monotonically decrease, but it fails on the last point since $m=0$ takes everything to the same point. This is just for my own interest, so anything remotely related is appreciated.","['analysis', 'functions']"
1593028,Example of a relation on $X$?,"I can understand ""relation $R$ in $X$"" through the following example in the book, but I haven't got a clue of what ""relation on $X$"" looks like. Can you give an example of of a relation on $X$? ""Often $A$ and $B$ are the same set, say $X$. In that case, we shall say that $R$ is a relation in $X$ instead of ""from $X$ to $X$. For example, in a community $X$, to say that $a$ (for Albert) is the husband of $b$ (for Bonita), is to consider Albert and Bonita as an (ordered) pair $(a, b)$ in the relation $H$ (of being the husband of...)"" Source: Set Theory: An Intutive Approach by Shwu-Yeng T. Lin, ‎You-Feng Lin, p.137 I understand from the above explanation that $a$ relation in $X$ means $R=\{(a, b)|(a, b) \in X \times X\}$ ""When the domain of a relation $R$ is obviously $X$ itself , most mathematicians prefer to say ""relation on $X$"" instead of ""relation $R$ in $X$"" "" Source: Set Theory: An Intutive Approach by Shwu-Yeng T. Lin, ‎You-Feng Lin, p.143 I understand from the above explantion that a relation in $X$, i.e. $R=\{(a, b)|(a, b) \in X \times X\}$, is called a relation on $X$ when Dom($R$)$=X$ But I can't find examples of the relation on $X$.",['discrete-mathematics']
1593032,On the Gaussian Poincare inequality,"Let $X$ be a standard normal random variable. Then, for any differentiable $f:\mathbb{R}\to\mathbb{R}$ such that $\mathbb{E}f(X)^2<\infty,$ the Gaussian Poincare inequality states that $$\mathrm{Var}(f(X))\leq \mathbb{E}[f^\prime(X)^2].$$ Suppose this inequality is proved for all functions that are twice continuously differentiable with compact support. Can you please tell me the precise argument that allows one to extend this to all differentiable functions $f$ with $\mathbb{E}f(X)^2<\infty$?",['probability-theory']
1593048,A linear transformation whose domain has higher dimension than the target space,"I have a doubt in this question. I would like to check if my answer for letter a is correct and a hint for letter b. Let $T:U\rightarrow V$ be a linear transformation where $U$ and $V$ are vector spaces such that $\dim_\mathbb{K}V<\dim_\mathbb{K}U < \infty$. a) Prove the existence of a nonzero element $u \in U$ such that $T(u) = 0$. b) Let $\mathbb{B}$ be an arbitrary basis of $U$. Does there always exists a vector $u \in \mathbb{B}$ such that $T(u) = 0$? Prove or give a counterexample. My attempt: a) Let $\dim_\mathbb{K}V = n$, $\dim_\mathbb{K}U = m$ and $B_U= \{ u_1, ..., u_n\}$ be a basis of U, so $u$ = $\sum_{i=1}^m \alpha_i u_i \Longrightarrow T(u)  =  \sum_{i=1}^m \alpha_i T(u_i)$ $n = \dim_\mathbb{K}V < dim_\mathbb{K}U = m$, so all lineary independent sets in $V$ have at most 'n' elements, but $A = \{ T(u_1), ..., T(u_m) \}$ has #$A = m > n$, therefore $A$ is lineary dependent. In other words, $\sum_{i=1}^m \alpha_i T(u_i) = 0$ for some $0<i<m+1$. So, there exists a nonzero $u \in U$ such that $T(u) = 0$. b) For this question I have no  idea, but I think I need to use my development in 'a'.","['linear-algebra', 'proof-verification', 'linear-transformations']"
1593052,Colored balls into unlabeled buckets,"I'm looking for a more generic way to apply this, but here's the problem in a nutshell. I have a number of balls that are divided up into partitions. For instance, I might have the following: 5 blue balls 4 green balls 2 yellow balls 1 red ball 1 black ball I'm trying to put them into a number of buckets, let's say 3 for this problem, although the number can vary. Each bucket must have a unique combination of balls when all is said and done, in other words, no two buckets can contain the same number of the same type of balls. All balls must be in a bucket to satisfy the conditions. An empty bucket is allowed. How many combinations are there? Just to explain a bit more, if two buckets each had 2 blue balls and 1 green ball, that would not be acceptable. However, if one had 2 blue balls and 2 green balls, and the other had 2 blue balls and 1 green ball, that's okay. Also, one empty bucket is okay, as it is distinct. For a very simple example, imagine 4 blue balls, 2 red balls, going into 4 buckets. There are 7 combinations, bbb|rr|b|0, bb|brr|b|0, b|bbrr|b|0, br|bbr|b|0, bbb|br|r|0, bbr|bb|r|0, and b|br|bb|r where 0 is empty, b is blue, r is red, and | is the divider between partitions. Note that I want to understand how this works to apply it to a larger problem I'm working on, but if I can understand this, then it will make the larger problem easier. I should add, I only need the exact number, I do not need to show every combination there is.",['combinatorics']
1593080,determinant of pascal matrix- proof,"Let $U_n$ be the upper triangular Pascal matrix, $L_n$ the lower triangular Pascal matrix of n-th degree, i.e.
$$
 u_{ij} =
  \begin{cases}
    \binom {j-1}{j-i} & \quad i\le j\\
    0  & \quad i>j\\
  \end{cases}
$$
$$
 l_{ij} =
  \begin{cases}
    \binom {i-1}{i-j} & \quad i\ge j\\
    0  & \quad i<j\\
  \end{cases}
$$ The question is how to prove that $P_n=L_n U_n$, where $P_n$ is a matrix, in which the Pascals triangle extends from the upper left corner and is symmetrical with respect to the main diagonal, i.e. 
  $$
p_{ij}=\binom {i+j-2}{j-1}
$$
  Let $[L_n U_n]_{ij}=c_{ij}$, $m=\min(i,j)$, then 
  $$
c_{ij}=\sum_{s =1}^{m}\binom{i-1}{i-s}\binom{j-1}{j-s}=...=(i-1)!(j-1)!\sum_{s =1}^{m}\frac {1}{(i-s)!(j-s)!((s-1)!)^2}
$$
  I am stuck on this step. Could you give me any suggestions how to continue or how to prove the identity $c_{ij}=p_{ij}$ somehow else? Thanks.","['matrices', 'combinatorics']"
1593087,Good introductory book coupling methods,"I am very interested in coupling methods, can you recommend me a good introductory books  on this subject? Thanks","['reference-request', 'markov-process', 'book-recommendation', 'probability', 'coupling']"
1593120,"Distribution of sums of inverses of random variables uniformly distributed on [0,1]","If I have $N$ random variables (denoted below as $X_i$) with uniform distribution on the $x$-axis $X_i = \rm{rand}[0,1]$ then the sum $$
S_N = \frac{1}{N}\sum_i^N\frac{1}{2X_i-1}
$$ seems to be a Cauchy distribution with $\gamma = \pi/2$.  I found this by trial and error.
$$
f_{S_N}(x)=\frac2{4x^2 + \pi^2}
$$ The plot of the distribution along with the ideal Cauchy distribution is shown below for $N=200$, with data accumulated from $10^5$ trials. Cauchy Distribution http://www.rearviewminor.com/cauchydist2.png However, what I would really like to find is the probability distribution of $$
T_N = \frac{1}{N}\sum_i^N\frac{1}{X_i}
$$ with the same flat random variable distribution $X_i = \rm{rand}[0,1]$ as above.  For different values of $N$ (the distribution is no longer independent of $N$ like the first distribution) the distributions of $T_N-\log N$ are plotted, showing a convergence for large $N$. Some Other Distribution http://www.rearviewminor.com/unknowndistshift2.png All of the distributions seem to have right tails that go as $x^{-2}$, which makes sense in light of A.S.'s comment.  Does anyone recognize what distribution this might be?  Or better yet, teach a man to fish: how does one go from a sum of random variables to figuring out what the probability distribution is? So far I have been doing some reading around on Wikipedia, and I found this pdf helpful, but I am still stuck.  Solving this will ideally be a stepping stone on my road to finding an answer to my other question .","['law-of-large-numbers', 'probability-theory', 'probability-distributions']"
1593134,Mixing process in statistics vs. mixing in classical ergodic theory texts,"In dynamical systems a transformation $T$ is strongly mixing if
$\lim_{n\rightarrow \infty} P(A \cap T^{-n} B) = P(A)P(B)$ (e.g., Patrick Billingsley's Ergodic Theory and Information) For stochastic processes, mixing is usually defined differently through mixing coefficients, e.g. $\alpha$-mixing: https://en.wikipedia.org/wiki/Mixing_(mathematics)#Mixing_in_stochastic_processes Since a stochastic process can also be modeled as a dynamical system (as opposed to a sequence of random variables), I'm wondering how the notion of mixing in dynamical systems is related to that in statistics. In particular, is $\alpha$-mixing coefficient simply the rate at which $|P(A \cap T^{-n} B)- P(A)P(B)|$ converges to zero?","['stochastic-processes', 'mixing', 'statistics', 'dynamical-systems']"
1593137,"Theta-space is a deformation retraction of the doubly-punctured plane, how to find equations.","That theta space is given by $S^1\cup(0\times[-1,1]) \subset\mathbb{R}^2$ it is said that this space is a deformation retract of the doubly punctured plane, here is the explanation I found: The first one I think is ok if you want to find the equations, if you assume that p and q are at the points 1 and -1. You can define the deformation retraction like this: $(x_1,x_2)(1-t)+2(x_1,x_2)/\|x\|t, \|x\| \ge 2$ $x, \|x\|\le2$. We can see that it is continuous by the pasting lemma, it is well defined, and we have a homotopy between the identity map and the disc of radius 2, so it is a deformation retraction. But what about the last one? Is it difficult to find the equations? I have seen many cases where they just use intuition here. But there are many things that has to be shown, That the deformation leaves $S^1\cup(0\times[-1,1])$ fixed(this is clear from the picture) That the deformation si continuous(not that clear) That the deformation is homotpic with the identity map, and that it leaves the theta space fixed during this homomorphism. How is this just ""seen"" from the picture? Could these things be ""seen"" or ""felt"" intuitively? And do you know how to construct the homotpy explicitely in the last case? I am not sure how to find the equations here. Maybe they are too messy?","['algebraic-topology', 'general-topology', 'fundamental-groups', 'homotopy-theory']"
1593167,Closed form expression for $n_j$ defined by $n_j=\lceil n_{j−1}/b\rceil$ clarification,"I came across this answer to this question: Closed form expression for $n_j$ defined by $n_j=\lceil n_{j-1}/b \rceil$ I was hoping someone could clarify the following step: $q−1 \leqslant \dfrac{(P−1)}{b} < \dfrac{x}{ab} ⩽ \dfrac{P}{b} ⩽ q $, which says $\left\lceil\dfrac{x}{ab}\right\rceil =
> \left\lceil\dfrac{1}{b}\left\lceil\dfrac{x}{a}\right\rceil\right\rceil $. I realize that the inequality is bounded between q-1 and q, so intuitively the ceiling equality makes sense. Testing real examples also shows that the equality is true. However, I'm a bit lost on how this is rigorously shown from the inequality. Any help would be very much appreciated!","['ceiling-and-floor-functions', 'computer-science', 'discrete-mathematics']"
1593183,Hints for an exercise on Morse theory,"Exercise : Let $M$ be a $3$-dimensional smooth manifold with boundary $\partial M$ which is a surface of genus $g$. Moreover let $f:M\longrightarrow [0,1]$ be a Morse function with the following properties: $f(\partial M)$ is a regular value. Lets denote with $\mu_i(f)$ the number of critical points of $f$ of index $i$, then $\mu_0(f)=1$ and $\mu_2(f)=\mu_3(f)=0$ Prove that $M$ is connected and determine $\mu_1(f)$. I tried different approaches to solve it; here you can see my wrong reasonings: $1)$  Lets reconstruct partially the Morse-Smale complex (over $\mathbb Z/2\mathbb Z$). We have one critical point of index $0$, therefore $C_0(M)\cong\mathbb Z/2\mathbb Z$ and in the same way we can conclude that
$C_2(M)=C_3(M)=0$. For compact manifolds we have the following theorem: Let $M$ be a compact manifold of dimension $n$, then the dimension as vector space of the Morse-Smile homology group $H_n(C^\bullet)$ (or $H_0(C^\bullet)$) is the number of connected components of $M$. In my case $H_3(C^\bullet)=0$ since $C_3(M)=C_4(M)$ so maybe I'm on the wrong way. Probably I can't use the theorem for two reasons: $M$ has boundary and it is not compact. $2)$ I tried to use the Morse inequalities but I have two main obstacles, $M$ ha boundary and I don't know the number of critical points of index $1$ (I have to find them). $3)$ I don't know if I can use the fact that $\chi(M)=0$ if $\text{dim}(M)$ is odd because I've seen this theorem only for compact manifolds without boundary. $4)$ If $M$ where without boundary I could conclude that it has the homotopy type of a CW-complex with only one $0$-cell. At this point I should prove that this type of $CW$-complexes are connected (it is easy). I don't know how to use the fact that the homology of $\partial M$ is known, because I don't understand how to relate it with the homology of $M$. Could you help me please?","['homology-cohomology', 'differential-geometry', 'differential-topology', 'morse-theory']"
1593188,Computing $\sum\limits_{n=1}^\infty\frac{\sin n}{n}$ with residues,"I'm running into some error in computing the sum. Since $\dfrac{\sin n}{n}$ is even, I'm considering the function $f(z)=\dfrac{\pi\sin z\cot\pi z}{z}$ and the contour integral
$$\oint_\gamma \frac{\pi\sin z\cot\pi z}{z}\,\mathrm{d}z$$
where $\gamma$ is a square centered at the origin surrounding the poles and extending off to $\infty$. So I have the impression that the integral should be
$$0=\mathrm{Res}(f(z),0)+\sum_{k\in\mathbb{Z}\setminus\{0\}}\mathrm{Res}(f(z),k)$$
where all the poles are simple. Since $\dfrac{\sin n}{n}$ is even, the second term is twice the sum over the positive integers. At $z=0$, the residue is $1$, so I'm left with
$$0=1+2\sum_{k\ge1}\mathrm{Res}(f(z),k)=1+2\sum_{k\ge1}\frac{\sin k}{k}$$
but this would suggest the value of the sum is $-\dfrac{1}{2}$. I'm off by $\dfrac{\pi}{2}$, but I don't know where I went wrong. Am I wrong in assuming the integral disappears? Apologies if this is a duplicate; all the questions I've run into involving this sum were just testing for convergence, not finding the exact value.","['residue-calculus', 'contour-integration', 'sequences-and-series']"
1593195,Convergence of improper integral with $f(x)\to 1$ as $x\to +\infty$,"Suppose $f\in \mathscr{R}$ on $[0,A]$ for all $A<\infty$, and $f(x)\to 1$ as $x\to +\infty$. Prove that $$\lim \limits_{t\to 0}t\int_{0}^{\infty}e^{-tx}f(x)dx=1 \quad (t>0).$$ Proof: Let's define $F(t)=t\int_{0}^{\infty}e^{-tx}(f(x)-1)dx$ for $t>0$. Let $\epsilon>0$ be given then $\exists A=A(\epsilon)>0$ such that for any $x\geqslant A$ we have $|f(x)-1|<{\epsilon}/{2}.$ Then $$|F(t)|=\left|t\int_{0}^{\infty}e^{-tx}(f(x)-1)dx\right|\leqslant t\int_{0}^{\infty}e^{-tx}|f(x)-1|dx=t\left(\int_{0}^{A}+\int_{A}^{\infty} \right)\leqslant$$$$\leqslant t\int_{0}^{A}e^{-tx}|f(x)-1|dx+t\frac{\epsilon}{2}\int_{A}^{\infty}e^{-tx}dx.$$ Since $|f-1|\in \mathscr{R}$ on $[0,A]$ then $|f-1|$ is bounded on $[0,A]$ (Rudin's assumption on Chapter 6) and let $C=\sup \limits_{[0,A]}|f(x)-1|$ then we get that: $$|F(t)|\le Ct\int_{0}^{A}e^{-tx}dx+t\frac{\epsilon}{2}\int_{A}^{\infty}e^{-tx}dx=C(1-e^{-At})+\dfrac{\epsilon}{2}e^{-At}<ACt+\dfrac{\epsilon}{2}$$ since $0<e^{-At}<1$ and $e^{-At}>1-At$. Taking $\delta=\dfrac{\epsilon}{2AC}$ then for any $t\in (0,\delta)$ we get $|F(t)|<\frac{\epsilon}{2}+\frac{\epsilon}{2}=\epsilon$ which is equivalent to $\lim \limits_{t\to 0+}F(t)=1$ and we get our desired result. Can anyone check my proof please? I would be very grateful for your help!","['improper-integrals', 'real-analysis', 'integration', 'limits']"
1593197,How to compute $\lim\limits_{x \to 1^+} \left(\frac{\tan \sqrt {x-1}}{\sqrt{x^2-1}}\right)$?,"I have a problem with this limit, I don't know what method to use. I have no idea how to compute it. Can you explain the method and the steps used? Thanks $$\lim\limits_{x \to 1^+} \left(\frac{\tan \sqrt {x-1}}{\sqrt{x^2-1}}\right)$$","['calculus', 'limits']"
1593221,Find all topology on finite set in especial case,"Let $X$ be finite set, Find all topology on finite set with this condition: For every subset $A \subset X$, either $A$ is open or $A$ is closed. I find one of them: $$T=\{ \emptyset, X, \{1\}, \{3\},...,\{n\},\{1,3\},\{1,4\},...\{1,n\},\{1,3,4\},...,\{1,3,4,...,n\}\} = \{A \subset X \bigm| A=X \, \text{or} \, 2 \not\in A \}
$$
It is clear that $T$ is topology and $T \neq P(X)$. Note that discrete topology is a trivial answer. So find the number of all topology with above condition.",['general-topology']
1593240,Calculate the discrete probability density of $Z=XY$,"$X$ and $Y$ are independent aleatory variables. $X$ : Poisson with 1 such as parameter $Y$ : Bernoulli with $\frac{1}{2}$ such as parameter Calculate the discrete probability density of  $Z=XY$ $$P(Z=0)=P(\{X=0\} \cup \{Y=0\})= \\=P(X=0)+P(Y=0)-P(X=0, Y=0)=\frac{1}{e}+\frac{1}{2}-\frac{1}{2e}=\frac{e+1}{2e} \\ \\ 
\forall n \in \mathbb{N^*}, P(Z=n)=P(X=n, Y=1)=\frac{1}{2 \ e \ n!}  $$ Is it correct?",['probability']
1593242,(i) Show that the drawings in Fig. $1.4$ represent the same graph. (ii) Find the group of automorphisms of the graph in Fig. $1.4$.,"From A Course in Combinatorics by van Lint, Wilson: Problem $1A$: (i) Show that the drawings in Fig. $1.4$ represent the same graph (or isomorphic graphs). (ii) Find the group of automorphisms of the graph in Fig. $1.4$. For part (i), I first labeled the vertices of both graphs using numbers in a clockwise fashion. Then I relabeled the second graph by following which vertices are connected to other vertices by an edge. Is this a proper technique? Could I have just said: In both graphs, each vertex has 3 edges incident with it, so they are isomorphic. I am stuck on part (ii). The hint in the back says: Show that the􏰁 $\binom{5}{2}$ 􏰂pairs from $\{1,...,5\}$ can be used to label the vertices in such a way that a simple rule determines when there is an edge. To find the full automorphism group, consider the subgroup that fixes a vertex and its three neighbors. This graph is known as the Petersen graph. I have found some automorphisms by just rotating the graph. (i.e., $1 \mapsto 2$, $2 \mapsto 3$, $\dots$, $6 \mapsto 7$, $\dots$)","['combinatorics', 'graph-theory', 'discrete-mathematics']"
1593274,Problem with the ring $R=\begin{bmatrix}\Bbb Z & 0\\ \Bbb Q &\Bbb Q\end{bmatrix}$ and its ideal $D=\begin{bmatrix}0&0\\ \Bbb Q & \Bbb Q\end{bmatrix}$,"Let us consider the ring
$
R:=\begin{bmatrix}\Bbb Z & 0\\ \Bbb Q & \Bbb Q\end{bmatrix}
$
and its two-sided ideal
$
D:=\begin{bmatrix}0 & 0\\ \Bbb Q & \Bbb Q\end{bmatrix}
$. Let then consider the free right $R$-module $F_R:=\bigoplus_{\lambda\in\Lambda}x_{\lambda}R$. I must show that
$$
\bigcap_{n\ge1}nF_R=\bigoplus_{\lambda\in\Lambda}x_{\lambda}D=F_RD\;\;.
$$
I proved the first equality using the fact that $\bigcap_{n\ge1}nR=D$. The second inequality: observing that $D\unlhd R$ (i.e. $D$ is a two-sided ideal of $R$) we have that $D=RD$, from which we would have
$$
\bigoplus_{\lambda\in\Lambda}x_{\lambda}D
=\bigoplus_{\lambda\in\Lambda}x_{\lambda}RD
=\underbrace{\left(\bigoplus_{\lambda\in\Lambda}x_{\lambda}R\right)}_{=F_R}D
$$
my problem is with the last equality in this last line: $""\supseteq""$ is obvious. What I cannot prove is the other inclusion $""\subseteq""$. I try writing the generic element of LHS, say $\sum_{\lambda\in F}x_{\lambda}r_{\lambda}d_{\lambda}=x_1r_1d_1+\cdots+x_nr_nd_n$, for some finite $F\subseteq\Lambda,\;|F|=n$. Then I should find some $d\in D$ and $r_1',\dots,r_n'\in R$ such that $x_1r_1d_1+\cdots+x_nr_nd_n=(x_1r_1'+\cdots+x_nr_n')d$: in such a way this last element would be in
$
{\left(\bigoplus_{\lambda\in\Lambda}x_{\lambda}R\right)}D
$
which is our RHS and I would have finished. I tried to write out the matrices to find $d$ and the $r_j$'s, even doing some not elegant computations, but I didn't found any way to go out! Can someone help me? Many thanks! EDIT: see my answer below.","['abstract-algebra', 'ring-theory', 'modules', 'direct-sum']"
1593293,Extremly simple combinatorics - divide to groups,"We have a group of $10$ men and $4$ women, we want to divide this group into two groups of $7$ such that each of those groups has at least $1$ woman. What I did: I actually solved this in two directions, both of them are wrong, I'd like to know why. First direction - First we choose a woman for group $A$, we have $4$ options for that. Then we choose a woman for group $B$, we have $3$ options for that. Now we have $12$ people that we need to divide into $2$ groups of $6$. We have $\begin{pmatrix} 12\\ 6\end{pmatrix}$ options for that. Overall thats $4 \times 3\times \begin{pmatrix} 12\\ 6\end{pmatrix} = 11088$ Second direction - Lets count all the number of groupings to groups of $7$ and subtract the ones where theres a group with no women.
Number of overall groupings - $\begin{pmatrix}14 \\ 7 \end{pmatrix}$. We have 14 people, we need to divide them into $2$ groups of $7$. Number of groupings where theres a group without a woman - $\begin{pmatrix}10 \\ 7\end{pmatrix}$. Choose how to group the $10$ men only. $\begin{pmatrix}14 \\ 7 \end{pmatrix} - \begin{pmatrix}10 \\ 7\end{pmatrix}=3432-120 = 3312$ Correct answer - $1596$. What? How? Why? I'd like to know where my logic fails.","['combinatorics', 'discrete-mathematics']"
1593295,Monotonic Function Optimization on Convex Constraint Region,"So I have the following function, which I want to maximize: $$f(x_1,...,x_n) = \sum_{i=1}^n\alpha_i\sqrt{x_i}$$ (where all $\alpha_i$ are positive), subjected to the following equality and inequality constraints: $$\sum_{i=1}^nx_i = B$$ $$l_i \leq x_i \leq u_i$$ for $l_i,u_i,B$ all positive. I want to say that there's a nice geometric way to think about this.  In particular, invoking the coordinate transformation $$x_i\mapsto {v_i\over \alpha_i^2} $$, we have $$f(v_1,...,v_n) = \sum_{i=1}^n\sqrt{v_i}$$ and constraints $$\sum_{i=1}^n{v_i\over \alpha_i^2}$$ $$l_i \leq {v_i \over \alpha_i^2} \leq u_i$$ In a global sense, given a fixed sum, $S$, of all the $v_i$ we know from the triangle inequality that the optimal solution is $v_i = {S\over n}$ for all $i$.  Is there a way to apply this knowledge of the global solution to finding one within our constraint region (which is the intersection of a hyperplane and a polytope).  If there's no easy way to divine a closed form solution, might there be an algorithm suited to this kind of optimization? Gradient ascent is applicable, but it seems to be too ignorant of what I want to call the nice-ness of the objective function and constraint region. I don't have much background by way of numerical analysis, so I'd really appreciate any insight. Edit: I should probably point out that I will eventually be attempting to code this algorithm, so solutions of exponential or worse order are scary to me. Edit2: I realize this question isn't the most interesting numerical exercise in the world, so I've attached a modest bounty.","['nonlinear-optimization', 'optimization', 'multivariable-calculus', 'algorithms', 'numerical-optimization']"
1593308,Prove that $\frac{a_1^2}{a_1+b_1}+\cdots+\frac{a_n^2}{a_n+b_n} \geq \frac{1}{2}(a_1+\cdots+a_n).$,"Let $a_1,a_2,\ldots,a_n,b_1,b_2,\ldots,b_n$ be positive numbers with $a_1+a_2+\cdots+a_n = b_1+b_2+\cdots+b_n$. $$\text{Prove that} \dfrac{a_1^2}{a_1+b_1}+\cdots+\dfrac{a_n^2}{a_n+b_n} \geq \dfrac{1}{2}(a_1+\cdots+a_n).$$ Attempt It seems like I should use AM-GM on the bottom of each fraction. We then get $\dfrac{a_i^2}{a_i+b_i} \leq \dfrac{a_i^2}{2\sqrt{a_ib_i}}$. But this doesn't seem to help as we get an upper bound. Since there is so much about $a_1+\cdots+a_n$ in this problem, I think a substitution for that might work.","['algebra-precalculus', 'contest-math', 'inequality']"
1593334,Need help with $\int_0^\pi\arctan^2\left(\frac{\sin x}{2+\cos x}\right)dx$,"Please help me to evaluate this integral:
$$\int_0^\pi\arctan^2\left(\frac{\sin x}{2+\cos x}\right)dx$$
Using substitution $x=2\arctan t$ it can be transformed to:
$$\int_0^\infty\frac{2}{1+t^2}\arctan^2\left(\frac{2t}{3+t^2}\right)dt$$
Then I tried integration by parts, but without any success...","['trigonometry', 'calculus', 'closed-form', 'integration', 'definite-integrals']"
1593338,Find number of integral solutions of $abcd=210$,"Find number of integral solutions of $a\times b\times c\times d=210$ $$210=2\times 3\times 5\times 7$$
I tried by assuming 2,3,5,7  as numbered balls. The above problem is equivalent to placing 4 balls on 4 boxes where emplty boxes are allowed or placing 3 partitions between 4 balls. (Empty box signifies 1). Assuming the partitions as sticks, I have to find the number of ways of arranging 4 different balls and 3 sticks. (The numbered balls between the sticks are like numbered balls in a box. So if two sticks come together, it means you get an empty box). Number of ways = $7!$. But answer given is $8\times 4^4$ (I don't know if negative solutions are allowed. If that is the case, my method will not work. But if only positive integral solutions are allowed, is my method correct?)",['combinatorics']
1593355,Two ways to define the fundamental vector field on a principal bundle?,"Let $\pi:P\longrightarrow M$ be a $G$-principal bundle. Let $\mathfrak{g}$ be the Lie algebra of left-invariant vector fields on $G$ and $\mathfrak{V}(P)$ be the space of vertical vector fields on $P$, that is: $$\mathfrak{V}(P):=\{X\in\mathfrak{X}(P): X_p\in T_p P_{\pi(p)}\},$$ where $\mathfrak{X}(P)$ stands for the space of vector fields on $P$. There are two ways to define a map $$\mathfrak{g}\longrightarrow \mathfrak{V}(P), X\longmapsto \sigma(X),$$ such that $$\mathfrak{g}\longrightarrow V_p, X\longmapsto \sigma(X)_p,$$ is a linear isomorphism for every $p\in P$ where $V_p:=T_pP_{\pi(p)}=\textrm{Ker}(d\pi_p)$. First Way: Take $(U, \phi)$ a local trivialization with $\pi(p)\in U$ and set $$\sigma(X)_p:=(d\phi_{\pi(p)}^{-1})_{\phi_{\pi(p)}(p)}(X_{\phi_{\pi(p)}(p)}),$$ where $\phi_{\pi(p)}:P_{\pi(p)}\longrightarrow G$ is the diffeomorphism associated to $\phi$, that is, $\phi_{\pi(p)}:=\textrm{pr}_2\circ \phi|_{P_{\pi(p)}}$.  Of course, it is possible to show this map does not depend on the choice of local trivialization. Second Way: Given $X\in\mathfrak{g}$ one defines $\sigma(X)\in \mathfrak{V}(P)$ setting $$\sigma(X)_p:=\frac{d}{dt}(L_p\circ \exp(tX))\biggr|_{t=0},$$ where $L_p:G\longrightarrow P$, $g\longmapsto p\cdot g$. Can anyone explain-me the relation between those constructions? Thanks. Remark. The action of $G$ on $P$ is given by $$p\cdot g=\phi_{\pi(p)}^{-1}(\phi_{\pi(p)}(p)g).$$","['principal-bundles', 'differential-geometry']"
1593360,On defining cross (vector) product.,"This has been bugging me for years so I finally decided to ""derive"" (for lack of a better term) the definition of the cross product in $\mathbb R{^3}$. Here was my method for finding a vector:
$\mathbf w = \mathbf u \times \mathbf v$ such that $\mathbf w \cdot \mathbf u = \mathbf w \cdot \mathbf v = 0$, where $\mathbf u = [$$
        \begin{matrix}
        a & b & c \\
        \end{matrix}$$
]$
and $\mathbf v = [$$
        \begin{matrix}
        d & e & f \\
        \end{matrix}$$
]$. This of course shows orthogonality between $\mathbf w$ and $\mathbf u$, as well as $\mathbf v$. I set up the 2x3 matrix to solve for $\mathbf w = [$$
        \begin{matrix}
        w_1 & w_2 & w_3 \\
        \end{matrix}$$
]$ as follows:
$
$$
        \begin{bmatrix}
        a & b & c \\
d & e & f
        \end{bmatrix}$$
\cdot \begin{bmatrix}
        w_1 \\ w_2 \\ w_3
        \end{bmatrix}$$ = \begin{bmatrix}
        0 \\ 0
        \end{bmatrix}$$
$
Of course this is 3 unknowns and 2 equations, so I knew there would have to be an arbitrary parameter. I was fine with this for the time being and after some dirty work, ended up with the following: $$\begin{bmatrix}
        w_1 \\ w_2 \\ w_3
        \end{bmatrix}
 = t 
\begin{bmatrix}
        \frac{\begin{vmatrix}b & c \\ e & f\end{vmatrix}}{\begin{vmatrix}a & b \\ d & e\end{vmatrix}} \\ -\frac{\begin{vmatrix}a & c \\ d & f\end{vmatrix}}{\begin{vmatrix}a & b \\ d & e\end{vmatrix}} \\ 1
        \end{bmatrix}$$ This looked very much like the ""traditional"" definition of the cross product, so I chose $t = \begin{vmatrix}a & b \\ d & e\end{vmatrix}$ and I finally ended up with
$\mathbf w = $$\begin{pmatrix}
        \begin{vmatrix}b & c \\ e & f\end{vmatrix}\\-{\begin{vmatrix}a & c \\ d & f\end{vmatrix}} \\ \begin{vmatrix}a & b \\ d & e\end{vmatrix}
        \end{pmatrix}$$ $ which is the definition of the cross product that I've seen in pretty much all of my calculus and physics texts (also shown in determinant form with unit vectors). But where does that value for $t$ come from? Why does that particular value of $t$ work, besides my hunch to make it look like a definition that is universally accepted? Is the rationale behind $t$ being negative for $\mathbf w = \mathbf v \times \mathbf u$ just to satisfy the right-hand-rule? Sorry if anything is messed up, this is my first ever time using MathJax. By the way, I've checked similar questions which ask for the rationale for the cross product existing which I have learned from studying electromagnetics myself. But I wanted to see the rational behind the length of the vector, hence my value for $t$. Thanks for any help you can offer!","['cross-product', 'linear-algebra']"
1593361,Function Definition Issue,"I'm currently working through an real analysis text and came across a definition that seemed a little strange to me. When defining  a function the text states: For a function, $$f:\,S\rightarrow T$$
  $S$ is called the Domain of $f$, and $T$ is called the Range of $f$. Shouldn't $T$ be called the Codomain of $f$?  Isn't $T$ the range of $f$ only if $f$ is onto? I'd appreciate any clarification. Thanks.","['definition', 'real-analysis', 'analysis', 'functions']"
