question_id,title,body,tags
2857214,How do I prove $x - \frac{x^3}3 < \arctan x < x$?,"Prove that $$x - \frac{x^3}3 < \arctan x < x$$ for every $x>0$? I tried taking the limit of $x-x^3/3$ and $\arctan(x)$ as $x$ approaches $0$, but I get $0$ which makes sense since they're both $0$ at $x=0$ I'm not sure what else to do algebraically. Would appreciate some help.","['inequality', 'trigonometry', 'calculus']"
2857236,Symmetrizing Polynomial,"For a polynomial $f(x_1, \dots, x_n)$, we define the operator $T_{\theta, i,j}$ which takes $f$ to $\theta f(x_1, \dots, x_{i-1}, x_j, \dots, x_{j-1}, x_i, \dots) + (1-\theta) f(x_1, \dots, x_n)$.  In words, this is the expected polynomial when one swaps indices $i$ and $j$ with probability $\theta$.  Does there exist a finite sequence of $T_{\theta_k, i_k, j_k}$ such that for any polynomial, the outcome of applying this sequence of operators is the symmetrized polynomial (i.e. the expected polynomial over a uniform distribution of all permutations of the indices)?","['combinatorics', 'polynomials']"
2857244,Embedding $S^1\times\cdots\times S^1$ into $\mathbb{R}^{k+1}$,"I'm currently attempting to come up with an explicit parametrization of the $k$-torus into $\mathbb{R}^{k+1}$. I've been following the answer here but I'm struggling to prove injectivity. Let $e_1,\ldots, e_{k+1}$ be the standard basis in $\mathbb{R}^{k+1}$ and $\varepsilon<1$. So according to the link, I should start with an element $v_1$ of length 1 in span$(e_1,e_2)$, i.e.
$$
v_1(\theta_1)=\cos(\theta_1)e_1+\sin(\theta_2)e_2
$$
Then from there I should choose an element $v_2$ of length $\varepsilon$ in span$(v_1,e_3)$, i.e.
$$
v_2(\theta_1,\theta_2)=\varepsilon\cos(\theta_2)v_1(\theta_1)+\varepsilon\sin(\theta_2)e_3
$$
and in general (for $1\leq j\leq k$), set
$$
v_j(\theta_1,\ldots,\theta_j)=\varepsilon^{j-1}\cos(\theta_j)v_{j-1}(\theta_1,\ldots ,\theta_j)+\varepsilon^{j-1}\sin(\theta_j)e_{j+1}.
$$
From this, the map
$$
\Phi:(e^{i\theta_1},\ldots,e^{i\theta_{k}})\mapsto\sum_{j=1}^{k}v_j(\theta_1,\ldots,\theta_j)
$$
is supposed to be the necessary embedding. This makes sense intuitively, but I can't seem to prove injectivity. Things Tried The only case I can make any progress is in the case $k=3$. I've tried doing induction and immitating this argument in the inductive step, but it doesn't seem to work. If $k=3$, then $$\Phi(e^{i\theta_1},e^{i\theta_1})=\Phi(e^{i\theta_1'},e^{i\theta_1'})$$
  implies
  $$
(1+\varepsilon\cos(\theta_2))v_1(\theta_1)+\varepsilon\sin(\theta_2)e_3=(1+\varepsilon\cos(\theta_2'))v_1(\theta_1')+\varepsilon\sin(\theta_2')e_3.
$$
  In this case the vectors being added together are orthogonal, so taking the norm-square of both sides gives
  $$
(1+\varepsilon\cos(\theta_2))^2+\varepsilon^2\sin(\theta_2)=(1+\varepsilon\cos(\theta_2'))^2+\varepsilon^2\sin(\theta_2'),
$$
  which after simplifying turns into
  $$
2\varepsilon\cos(\theta_2)=2\varepsilon\cos(\theta_2),
$$
  so $\cos(\theta_2)=\cos(\theta_2')$. This combined with the immediate fact that $\sin(\theta_2)=\sin(\theta_2')$ shows that $\theta_2=\theta_2'$ (in $[0,2\pi)$). The rest follows from the fact that $v_1$ is injective. Any help is greatly appreciated. Thanks in advance.","['general-topology', 'differential-geometry']"
2857262,Solving $a^3+a^2|a+x|+|a^2x+1|=1$,"Find all values of $a$ for which the equation $$a^3+a^2|a+x|+|a^2x+1|=1$$ has no less than four different integer solution. My attempts: If we rearrange it as $$|a^2x+1|+|a^3+a^2x|=(a^2x+1)-(a^3+a^2x)$$ Hence it requires us to solve following system of equation,
\begin{cases}a^2x+1&\geq0\\\ a^3+a^2x&\leq0\end{cases} And here I'm paused. Please help","['algebra-precalculus', 'inequality', 'integers', 'systems-of-equations']"
2857263,Finding zeros of function by integration: a novel relationship or not?,"It seems that in certain cases one can find the zero of a function by solving an integration problem instead. This surprises me, and I am wondering to what extent this (1) has been studied, and/or (2) is interesting. For example, consider $f(x) = x^3 +ax -1$. This has a (unique) zero on the positive real axis , $x_0 \in \mathbb R^+$ (for any value of $a \in \mathbb R$). I am surprised to find that one can express this zero as follows:
$$ x_0 =  \frac{3}{4a} \left( 2 - \frac{1}{\mathcal I} \right) \qquad \textrm{ where }\qquad \mathcal I := \frac{1}{\pi} \int_0^\infty \frac{1}{1+(y^{2/3}-a)^2 \; y^{2/3}} \mathrm d y. $$ I was indeed able to prove this using some unconventional methods (which can be found in a physicist's toolbox). Is the above correspondence surprising to mathematicians? (By the way, the fact that the $f(x)$ I chose above is a third-order polynomial is a red herring, as I found similar relationships where $f(x)$ contains, for example, logarithms.)","['roots', 'integration', 'calculus']"
2857279,Show that the rational cohomology ring $H^*(M;\mathbb{Q})$ needs at least two generators,"Let $M$ be a simply connected closed Riemannian manifold. How does one find a condition that may be imposed on $M$ (perhaps on the curvature of $M$ and on torsion) which guarantees that the rational cohomology ring $H^*(M;\mathbb{Q})=\bigoplus_{k\in\mathbb{N}}H^k(M;\mathbb{Q})$ needs at least two generators? That is, how does one force $M$ not to have rational cohomology that is the quotient of a polynomial ring? Cross-posting on MO: https://mathoverflow.net/questions/306490/show-that-the-rational-cohomology-ring-hm-mathbbq-needs-at-least-two-ge Any help would be much appreciated. Thanks in advance!","['algebraic-topology', 'homology-cohomology', 'group-theory']"
2857312,Evaluating $\sum_{k=1}^{\infty} 2\ln{(2k)} - \ln{(2k-1)} - \ln{(2k+1)} $,"I was trying to evaluate the following series, which I know converges:
$$\sum_{k=1}^{\infty} 2\ln{(2k)} - \ln{(2k-1)} - \ln{(2k+1)} \tag{1}\label{1} $$ In a telescoping fashion, I began writing out the terms in hopes to find a pattern: $$= (2\ln{2} - \ln{1} - \ln{3}) + (2\ln{4} - \ln{3} - \ln{5}) + (2\ln{6} - \ln{5} - \ln{7}) + \ldots \tag{2}\label{2}$$ while nothing canceled out, I grouped terms together: $$ = 2\ln{2} - 2\ln{3} + 2\ln{4} - 2\ln{5} + 2\ln{6} - 2\ln{7} + \ldots \tag{3}\label{3}$$ $$ = 2 \left[ \ln{2} - \ln{3} + \ln{4} - \ln{5} + \ln{6} - \ln{7} + \ldots \right] \tag{4}\label{4}$$ which left me with the following divergent series: $$ = 2 \sum _{k=2} ^{\infty} (-1)^k \ln{k} \tag{5}\label{5}$$ Clearly, $\eqref{5}$ can't be equivalent to $\eqref{1}$. I'm pretty new to calculus, and while I've covered telescoping series, it seems that this technique cannot be applied here. Though, I don't know why. Where did I go wrong?","['sequences-and-series', 'calculus']"
2857348,Examples for short exact sequences of real vector bundles that don't split.,"It is known that given a SES of real vector bundles
$$0\rightarrow E\rightarrow F\rightarrow G\rightarrow 0$$, there is a splitting $F\simeq E\oplus G$, if the base space $B$ is paracompact. We can do this by choosing a metric on $F$. If $B$ is not paracompact, what is an explicit example of such sequences that don't split?","['algebraic-topology', 'general-topology', 'vector-bundles']"
2857374,Lebesgue measure theory vs differential forms?,"I am currently reading various differential geometry books. From what I understand differential forms allow us to generalize calculus to manifolds and thus perform integration on manifolds. I gather that it is, in general, completely distinct from Lebesgue measure theory and is more like a generalization of Riemann integration. Ok so here's the problem. I have always viewed Lebesgue measure theory as 'solving the issues with Riemann integration'. For example, a big problem with Riemann integration  is that the space of Riemann integral functions is not complete. The fact that $L^p$ spaces in the Lebesgue theory are complete seems like a huge improvement on the Riemann situation, and is vital for so many concepts in functional analysis, PDEs, operator theory, and numerical analysis. So if we then consider differential geometry and integration via differential forms, unless I am misunderstanding something, we lose all the benefits of Lebesgue theory? It seems like if do lose all those benefits we are in a very bad situation. For example, how are we supposed to rigorously define solution spaces for PDEs if we can't use $L^p$ spaces and thus can't use Sobolev spaces? How can we obtain acceptable convergence of some sequence that may arise during our work if we are operating in this generalized Riemann setting where we lack completeness? In summary, if differential forms are a generalization of Riemann integration how are we supposed to perform analysis when we no longer have the power and utility of Lebesgue measure theory?","['partial-differential-equations', 'differential-forms', 'functional-analysis', 'measure-theory', 'differential-geometry']"
2857381,Unprojecting a 2D point to 3D space on a plane with perspective.,"I'm not a good mathematician, but I'm trying to unproject 2D screen coordinates to a plane in a 3D space with perspective. I first do an uniform scaling on the 3D scene. Then I rotate around X axis, the plane defined by X axis and Z axis. Then I translate the scene on Z axis, with a value of -1.0 . So I have a ProjectionView matrix, computed by the following way, using the library linmath.h, in language C: mat4x4 ProjectionView, matrix;

mat4x4 projection;
mat4x4_identity(projection);
mat4x4_perspective(projection, fova, width/height, zNear, zFar);

mat4x4 view;
mat4x4_identity(view);
mat4x4_translate(view, 0.0, 0.0, -1.0);
mat4x4_rotate(matrix, view, 1.0, 0.0, 0.0, theta);
mat4x4_scale_aniso(view, matrix, scale, scale, scale);

mat4x4_mul(ProjectionView, projection, view); Here is the graphic I use to try to unproject: The distance Oz is what I can compute using trigonometry, it is on the plane where are the unprojected points, but it doesn't take in consideration the effects of perspective. So I would like to know how to correct this Oz distance, using the perspective parameters, in order to have the unprojected z coordinate ? And then how to compute x coordinate, from the unprojected z and from the perspective parameters ? After some readings on internet, I tried using the inverse ProjectionView matrix, or with the inverse Projection matrix, without a good result, maybe due to the fact I don't know the z value to give to these matrices. So I wonder if there is a way to solve this problem without using an inverse matrix ? The computed Oz distance is close to the true result, I think it just need a correction due to the perspective.","['3d', 'geometry']"
2857399,Are there any natural numbers $n$ that satisfy the condition $7921\sigma(n) = 15840n$?,"Are there any natural numbers $n$ that satisfy the condition $7921\sigma(n) = 15840n$, where $\sigma(n)$ denotes the sum of divisors of $n$? This question arises from the theory of immaculate groups (or, equivalently, Leinster groups). An immaculate group is a group, such that its order is equal to the sum of all orders of its proper normal subgroups. It is easy to see, that if $A$ is a non-abelian simple group then $A\times\mathbb{Z}_n$ is immaculate iff $(|A|+1)\sigma(n) = 2|A|n$. Two well known examples of immaculate groups of that form are $A_5\times\mathbb{Z}_{15128}$ and $A_6\times\mathbb{Z}_{366776}$. In terms of immaculate groups this question thus can be reworded as:
""Does there exist such $n$, that $M_{11}\times\mathbb{Z}_n$ is immaculate?"", where $M_{11}$ stands for Mathieu simple group of order $7920$. Currently I know only two facts about such $n$-s: if they exist, then $7921|n$, and that such $n$-s, if they exist, are too large to be found by exhaustive search. Any help will be appreciated.","['finite-groups', 'normal-subgroups', 'divisor-sum', 'group-theory', 'elementary-number-theory']"
2857400,Volume in cone segment bent from rectangle.,"A flexible rectangle sheet size $(a,b),a>b $ is folded half  along side $a$ and glued to make a circular cone cut segment of vertex angle $60^{\circ}$ as shown with three edges $(b,a,b).$ ( $60^{\circ}$ choice for cone apex angle deformation arises due to maximum volume created by internal pressure at $90^{\circ}$ corner obtained by maintaining second order continuity along a line perpendicular to glue line.) After bending distorted edges $(a,b)$ are curved/mapped as conical helices with Clairaut minimal radii nearer to cone vertex as $ (r_a,r_b)= (a/4,b).$ The cone surface is a single boat shaped nappe. Calculate bent area to verify $A= ab $ conserved due to isometry. Calculate volume enclosed by parallel displacement of edge $AB$ (skew perpendicular to cone axis) along the helices. It refers to Jack D'Aurizio A4 paper sheet bent volume problem with two nappes.","['recreational-mathematics', 'differential-geometry']"
2857412,Derivative of a function at a point,"A friend who is still in highschool gave me the following problem. For $x>-1\,$ compute $f'(0)$  if $$f(x)=\left(x^2-\ln^2(x+1)\right)^\frac{1}{3}$$ Here is how I solved it. Since it just got messier if I computed the derivative then tried to plug in$x=0$ I used the definition of derivate: $$\lim_{x\to 0}\frac{\left(x^2-\ln^2(x+1)\right)^\frac{1}{3}-\left(0-0\right)^\frac{1}{3}}{x-0}=\lim_{x\to 0}\frac{\left(x^2-\ln^2(x+1)\right)^\frac{1}{3}}{x}.$$ We have the power series of $\ln(1+x)=x-\frac{x^2}{2}+O(x^3)\rightarrow\ln^2(1+x)=x^2-x^3+O(x^4)$ so the initial limit is just $$\lim_{x\to 0}\frac{\left(x^3(1-O(x)\right)^\frac{1}{3}}{x}=1$$ I couldn't solve it with any other method and my friend didnt learn series yet. Could you help me with an elementary approach for this problem?","['derivatives', 'limits']"
2857459,Derivative Operator as a Functor?,"Whilst I was trying to think of a proof for the chain rule for Fréchet derivatives, I realized it looks very similar to the naturality axiom for functors. (Except for the need to specify points for the derivative.) $$
D(f \circ g)_{p} = (Df)_{g(p)}\circ (Dg)_p \sim F(f \circ g) = F(f) \circ F(g)
$$ Is this just a coincidence? Or is this hinting at some deeper meaning of derivatives?","['category-theory', 'differential-geometry']"
2857502,Existence of Commuting Vector Fields in a Nonintegrable Distribution,"Let $M$ be a (smooth) manifold. Given tangent vectors $X_q,Y_q \in T_qM$ ($q \in M$), there exist (locally about $q$) vector fields $X,Y \in \Gamma(TM)$ extending $X_q$, $Y_q$ (i.e., $X(q) = X_q$ and $Y(q) = Y_q$), and such that $[X,Y] = 0$. My question is whether this result will extend to the following situation. Suppose that $\mathcal{D}$ is a nonintegrable subbundle of $M$, and $\mathcal{E}$ is a complement to $\mathcal{D}$ (so that $TM = \mathcal{D} \oplus \mathcal{E}$). Let $\pi : TM \to \mathcal{D}$ be the corresponding projection. Given $X_q,Y_q \in \mathcal{D}_q$, do there exist (local) $X,Y \in \Gamma(\mathcal{D})$ extending $X_q$ and $Y_q$ and such that $\pi([X,Y]) = 0$? I can think of two situations when this will be true: $M$ is a Lie group $G$, and $\mathcal{D}$, $\mathcal{E}$ are left invariant. (Take $X$ to be the left -invariant vector field corresponding to $TL^{-1}_q\cdot X_q$, and $Y$ to be the right -invariant vector field corresponding to $TL^{-1}_q\cdot Y_q$, where $L_q$ is left translation; then $X,Y \in \Gamma(\mathcal{D})$ extend $X_q,Y_q$, and $[X,Y] = 0$ since left- and right-invariant vector fields commute; hence $\pi([X,Y]) = 0$.) $\mathcal{E}$ is integrable. (Let $X,Y \in \Gamma(TM)$ be commuting extensions of $X_q$ and $Y_q$; then $\pi(X),\pi(Y) \in \Gamma(\mathcal{D})$ extend $X_q,Y_q$, and $\pi([\pi(X),\pi(Y)]) = 0$, since the $\pi([\mathcal{D},\mathcal{E}])$ and $\pi([\mathcal{E},\mathcal{E}])$ terms vanish.) This seems like a fairly straightforward question, but I haven't had any luck in the general case (either in finding a counterexample, or proving it).",['differential-geometry']
2857533,Find the probability that atleast one valve is defective.,"A factory A produces $10$% defective valves and another factory $B$ produces 20% defective valves.A bag contains $4$ valves of factory $A$ and $5$ valves of factory B.If two valves are drawn at random from the bag,find the probability that at least one valve is defective. $P(\text{at least one valve is defective})=\\=1-P(\text{none of the two valves are defective})=\\=1-\left(\frac{\binom{4}{2}}{\binom{9}{2}}(0.9)^2+\frac{\binom{5}{2}}{\binom{9}{2}}(0.8)^2+\frac{\binom{4}{1}\binom{5}{1}}{\binom{9}{2}}(0.9)(0.8)\right)=\frac{517}{1800}$, but the answer given is $\frac{303}{1800}$ I don't know where i am wrong.","['combinatorics', 'probability']"
2857537,Calculate $\lim_{n \rightarrow \infty}n^x (a_1 a_2\dots a_n)^{\frac{1}{n}}$.,"Suppose that $\{a_n\}$ is  a sequence such that $\displaystyle\lim_{n \rightarrow\infty} {n^x}a_n=a $ for some real $\,x$ . Calculate $$\lim_{n \rightarrow \infty}n^x (a_1\,a_2\dots\,a_n)^{\frac{1}{n}}$$ My attempts : I take $a_1=a_2 = \dots =a_n = a$ after that $\lim_{n \rightarrow \infty}$ $n^x (a_1\,a_2 \dots \,a_n)^{\frac{1}{n}}=  \infty \, a = \infty$ Is it correct ?? or not Please help me. Any hints/soluion.....","['real-analysis', 'limits', 'exponential-function', 'calculus', 'analysis']"
2857562,The number of real roots of $x^5 - 5x + 2 =0$,"How many real roots does the equation $x^5 - 5x + 2 =0$ have? I know the following facts: The equation will have odd number of real root. That function cannot have rational root. The function will have two real roots between $(1,2)$ and $(0,1)$. Can anyone please help me in solving this problem?","['algebra-precalculus', 'roots', 'polynomials']"
2857577,"Given $A\in\Bbb R^{n\times n}$, is $C_A := \{SAS^{-1} : S\in GL(n,\mathbb R)\}$ connected?","Let us define $\phi : GL(n,\Bbb R)\to C_A$, $\;\phi(S) = SAS^{-1}$ and the sets
$$
E_\pm := \{S\in GL(n,\Bbb R) : \pm\det S > 0\}.
$$
If $n$ is odd, then $\phi(E_+) = \phi(E_-) = C_A$ (because $\phi(-S) = \phi(S)$) and hence $C_A$ is connected. But what about even $n$? EDIT: I just saw that Lemma 1. If $\det A < 0$, then still $\phi(E_+) = \phi(E_-)$ and hence $C_A$ is connected. Proof. Indeed, if $T\in\phi(E_-)$, $T = \phi(S_0)$, $\det S_0 < 0$, then $\det(S_0A) > 0$ and $T = \phi(S_0A)\in\phi(E_+)$. The other inclusion is proved similarly. So the question reduces to $n$ even and $\det A\ge 0$. EDIT2: Here is another fact. Lemma 2. If there is $S_0\in E_-$ that commutes with $A$, then $C_A$ is connected. Proof. Let $T\in C_A$. Let us show that we can find a path within $C_A$ from $T$ to $A$. Let $T = SAS^{-1}$ with $S\in GL(n,\Bbb R)$. If $S\in E_+$, we find a path from $S$ to $I$ in $E_+$ and hence a path in $C_A$ from $T$ to $A$. If $S\in E_-$, we find a path within $E_-$ from $S$ to $S_0$. Its image under $\phi$ is again a path from $T$ to $A$ within $C_A$. EDIT 3: For arbitrary $\lambda\in\Bbb R$ we have $C_{A-\lambda I} = C_A - \lambda I$. As this is just a translation in $\Bbb R^{n\times n}$ of $C_A$ by $\lambda I$, it follows that $C_A$ is connected if and only if $C_{A-\lambda I}$ is connected. Therefore we can conclude the following: Let $J$ be the real Jordan form of $A$. Then $C_A = C_J$. If $A$ has a real eigenvalue $\lambda_0$ which appears in $J$ in a $k\times k$ Jordan block with $k$ odd, then $C_A$ is connected. Indeed, due to the above, we can shift $A$ and $J$ simultaneously and thus assume that $A$ and $J$ are invertible. Let $\tilde J$ be $J$, but with $-\lambda_0$'s instead of $\lambda_0$'s on the diagonal of the $k\times k$ Jordan block. Then $\tilde J$ commutes with $J$ and hence so does $\tilde JJ$. Since $\det(\tilde JJ) < 0$, $C_J = C_A$ is connected by Lemma 2. We summarize for the critical matrices: In the real Jordan form each Jordan block corresponding to a real eigenvalue has size $k\times k$ with $k$ even. I conjecture that the following are equivalent: $C_A$ is connected There exists $S\in E_-$ that commutes with $A$. There exists a Jordan block $J$ of $A$ for which $C_J$ is connected. There exists a real odd-sized Jordan block of $A$. I could only prove (4)$\Rightarrow$(3), (3)$\Rightarrow$(1), and (2)$\Rightarrow$(1) so far. Remark: This question is related to and motivated by Connectedness of matrix conjugacy classes of a fixed real $A$ but with the first column of $A$ invariant","['general-topology', 'linear-algebra']"
2857613,What's the series of $\sum_{n\geqslant1} \dfrac{\zeta(2n)}{n2^{2n}}$.,"I know with the formula
$$1-\sum_{n\geq 1}2\zeta(2n)\,x^{2n}=\pi x\cot(\pi x)$$
may I find the following relation used here $$
\sum_{n\geqslant1} \dfrac{\zeta(2n)}{n2^{2n}}=\color{blue}{\ln\dfrac{\pi}{2}}
$$ hardly, since I have
$$\int\sum_{n\geq 1}\zeta(2n)\,x^{n-1}dx=\int\left(\dfrac{1}{2x^{n+1}}-\dfrac{\pi}{2}  \dfrac{\cot(\pi x)}{x^n}\right)dx$$
and after integration set $x=\dfrac14$, but it seems so hard. Any suggestion, thanks in advanced!","['zeta-functions', 'integration']"
2857643,Parametrically Defined Curves: $f'$ and $g'$ Are Not Simultaneously Zero,"I can't find a clear, comprehensive explanation, on this site or elsewhere, for why parametrically defined curves frequently have the condition that the the derivatives of their points $x = f(t)$ and $y = g(t)$ cannot simultaneously be zero on the interval $[a, b]$. Most of the explanations use language that assumes that the reader already understands the concept they're explaining, or the explanations make the meaningless claim that the curve must be ""nice"". I would appreciate it if people could please take the time to explain, comprehensively (not rigorously), what is meant by this condition. If you're going to use words that are likely to be unfamiliar to someone who doesn't understand this concept, like ""regular"", then please take the time to define what it means.","['derivatives', 'real-analysis', 'curves', 'geometry', 'parametrization']"
2857672,Questions regarding peculiar statement involving empty sets,"I have some questions about the following statement involving empty sets: ""1) $ \forall a\in\{x|x\in \Re, x^2+1=0\} $ , we have $ a^{17}-72a^{12}+39=0  $ ""1) says that all elements of the empty set have a certain property; this is true because there are no elements in the empty set. Any similar ""$\forall$"" statement involving the empty set is true"" My questions are as follows: What does statement 1) mean? 2.Is  statement 1) true? 3.Why is the sentence that I've put in bold true?",['elementary-set-theory']
2857684,Determining $\sin(2x)$,"Given that $$\sin (y-x)\cos(x+y)=\dfrac 1 2$$ $$\sin (x+y)\cos (x-y) = \dfrac 1 3 $$ Determine $\sin (2x)$. As stated in my perspective, the question does not make any sense. We know that the double angle identity for $\sin(2x)$ is given by $$\sin(2x) = 2\sin\cos$$ Let us try simpiflying the second equation $$\sin(x+y)-\cos(x-y)=\sin x \cos y+\cos x \sin y-\cos x \cos y-\sin x\sin y=
\cos x(\sin y-\cos y)+\sin x(\cos y-\sin y)=\color{blue}{(\cos x-\sin x)(\sin y-\cos y})$$ However, there seems to be nothing useful.",['trigonometry']
2857711,Evaluating $\int_{0}^{1}{\frac{3x^3 - x^2 + 2x - 4}{\sqrt{x^2 -3x+2}}dx}$,"I've got one integration question which I first felt was not a hard nut to crack. But, as I proceeded, difficulties arose. This is the one: $\displaystyle\int_{0}^{1}{\frac{3x^3 - x^2 + 2x - 4}{\sqrt{x^2 -3x+2}}dx}$ I went ahead simplifying the two expressions and ultimately I reached this step: $\displaystyle\int_{0}^{1}{\sqrt{\frac{x-1}{x-2}} \ (3x^2 + 2x + 4) \ dx}$ I don't now what to do now, had I followed the correct pathway? Is there any other simpler method?","['integration', 'definite-integrals', 'calculus']"
2857721,"A better lower bound of the definite integral $\int_0^1\frac{\ln^2x}{e^{2x}}\,dx$","In this post of my blog, I proved that $$\int_0^1\frac{(x^2-3x+1)\ln x}{e^x}\,dx=-\frac1e.$$ Now if we apply the Cauchy-Schwarz inequality for integrals, we get $$\frac1{e^2}\le\int_0^1(x^2-3x+1)^2\,dx\int_0^1\frac{\ln^2x}{e^{2x}}\,dx.$$ The first integral is easy to evaluate, so we arrive at $$\int_0^1\frac{\ln^2x}{e^{2x}}\,dx\ge\frac{30}{11e^2}\approx0.36909\cdots$$ If I plug the integral into WA, the actual value is $2\,_3F_3(1,1,1;2,2,2;-2)\approx1.61511$ which involves hypergeometric functions. We can see that my approximation is not very useful. So could a closer lower bound be found using 'simple' methods (e.g. not requiring the use of hypergeometric or gamma functions)? P.S. An analytical method would be best.","['integration', 'definite-integrals', 'cauchy-schwarz-inequality', 'upper-lower-bounds']"
2857769,Find $t$ such that $\lim_{n\to\infty} \frac {\sum_{r=1}^n r^4\cdot\sum_{r=1}^n r^5}{\sum_{r=1}^n r^t\cdot\sum_{r=1}^n r^{9-t}}=\frac 45$,"Find $t$ such that $$\lim_{n\to\infty} \frac {\left(\sum_{r=1}^n r^4\right)\cdot\left(\sum_{r=1}^n r^5\right)}{\left(\sum_{r=1}^n r^t\right)\cdot\left(\sum_{r=1}^n r^{9-t}\right)}=\frac 45.$$ At first sight this question scared the hell out of me.  I tried using the general known formulas like $$\sum_{r=1}^n r^4=\frac {n(n+1)(2n+1)(3n^2+3n-1)}{6}$$ and $$\sum_{r=1}^n r^5=\frac {n^2(n+1)^2(2n^2+2n-1)}{12}.$$ But the denominator portion really doesn't go with it.  I tried to write it in form of integrals.  I also searched the internet for some information but it dealt higher level calculus relating the harmonic functions, Bernoulli numbers and the Riemann zeta function.  I read about it but couldn't get much out of it. Any help would be greatly appreciated. Thanks.","['sequences-and-series', 'calculus', 'limits']"
2857802,"knowing: $\cos x+\sin x=\frac{5}{4}$, obtain: $\cos(4x)$","knowing: $\cos x+\sin x=\frac{5}{4}$ , obtain: $\cos(4x)$ $$\cos x+\sin x=\frac{5}{4}$$ $$\sin^2x+\cos^2x+2\sin x\cos x=\frac{25}{16}$$ $$\sin2x=\frac{25}{16}-\frac{16}{16}=\frac{9}{16}$$ $$\cos4x=1-2\sin^22x=1-2\Bigl(\frac{9}{16}\Bigr)^2=\frac{47}{128}$$ Taken out of one of the TAU entry tests but unfortunately, they don't give solutions to most of the exercises, so… Am I correct?","['trigonometry', 'proof-verification']"
2857840,If $f$ and $1/f$ are harmonic then $f$ is holomorphic or antiholomorphic,"I have this problem. Let $f:D\to \mathbb{C}$ be a function such that $f$ and $1/f$ are harmonic (Their real and imaginary parts are harmonic). Then $f$ is holomorphic or antiholomorphic. I tried to solve it by computing the laplacian of real and imaginary parts, but it becomes very cumbersome. Is there a better way?",['complex-analysis']
2857843,There are open sets $U$ and $V$ such that $U\cap V = \emptyset $ and $ U \cap \tau(V) =\emptyset $?,"I am in a series of self-studies in the book Vector Analysis written by Klaus Janich. By page 15 of the book is made the affirmation (without explicit proof) that we can choose (under the considerations below) open sets $U$ and $V$ such that $U\cap V =\emptyset $ and $ U \cap \tau(V) =\emptyset $. In this page, $\tau:M\to M$ is a fixed-point-free involution ( i.e. a differentiable map with $\tau\circ\tau=\mathrm{id}_M$ and $\tau(x)\neq x$ for all $x\in M$) and $M$ a $m$-dimensional manifold. QUESTION. Under these considerations how can we prove that there are open sets $U\neq \emptyset$ and $V\neq \emptyset$ such that $U\cap V = \emptyset $ and $ U \cap \tau(V) =\emptyset $? In my attempts, the only things I have been able to prove are that
$$
U\cap V=\emptyset\Longleftrightarrow \tau(U)\cap \tau(V)=\emptyset
\qquad \mathrm{ and } \qquad 
U\cap \tau(V)=\emptyset\Longleftrightarrow \tau(U)\cap V=\emptyset
$$","['general-topology', 'self-learning', 'real-analysis', 'manifolds']"
2857860,Multiplicative group of $p$-adic numbers $\mathbb{Q}_p$,"$\DeclareMathOperator\Ker{Ker}\DeclareMathOperator\U{U}$I'm reading Serre's text, ""A course in arithmetic"". I have some problems with this argument. Let $\U=\mathbb{Z}_p^*$ the group of $p$-adic units.
For every $n \le 1$ let $\U_n=1+p^n\mathbb{Z}_p$.
I don't understand how to prove that $\U_n=\Ker(f_n)$ with $f_n:\U \to (\mathbb{Z}/p^n\mathbb{Z})^*$ morphism.
In particular, I see that $\U_n \subseteq\Ker(f_n)$ but not the inverse direction. Then Serre says that the map $(1+p^nx) \to x \pmod p$ from $\U_n/\U_{n+1}$ to $\mathbb{Z}/p\mathbb{Z}$ is an isomorphism because$(1+p^nx)(1+p^ny)=1+p^n(x+y)$ modulo $p^{n+1}$.
Also this point isn't clear to me.
Is there anybody who has some suggestions?
Thanks!","['abstract-algebra', 'p-adic-number-theory']"
2857872,"If sum of reciprocals of numbers is an integer, then there exists a subset with sum of reciprocals of 1","Suppose for $a_1,a_2,\cdots ,a_n$, where $a_i$ is a positive integer
$$\frac1{a_1}+\frac1{a_2}+\cdots+\frac1{a_n}=k$$, 
and $k$ is an integer. Is it true that there always exist $1\leq i_1<i_2<\cdots < i_m\leq n$, such that $$\frac1{a_{i_1}}+\frac1{a_{i_2}}+\cdots+\frac1{a_{i_m}}=1$$? I couldn't find any counterexamples or prove that we can always find such subset.","['algebra-precalculus', 'elementary-number-theory']"
2857897,Solution of differential equation $d/dt \langle N(t) \rangle=k-\Gamma \langle N(t) \rangle$ where brackets indicate average,"I have the following ODE yielded as a steady state solution to a more complicated ODE. The important part is just to consider the following: $$d/dt \langle N(t) \rangle=k-\Gamma \langle N(t) \rangle$$
where $\langle N(t) \rangle$ can be seen as $y$ or an average of $y$ (brackets indicating avg). I am not sure if that is the reason for the result. The solution is given by
$$\langle N(t) \rangle=k/\Gamma (1-e^{-\Gamma t})+\langle N(t) \rangle e^{-\Gamma t}$$ I do not see that however. So far, I've solved first for 
$$d/dt <N(t)>=\Gamma <N(t)>=0$$ Yielding
$$\langle N(t) \rangle>=C\cdot e^{-\Gamma t}$$ and $C$
$$C=k/\Gamma (1-e^{-\Gamma t})+c_0$$ I do not see how it solves the equation by inserting c. Any help is highly appreciated :) edit: I had a thought it may have to do with the average being additive, and starting and  $\langle N(0) \rangle$ being the same as $\langle N(t) \rangle$ since it is steady state. I am not completely sure however.",['ordinary-differential-equations']
2857907,Meaning of the nth order derivative,"We say that the number zero is infinitely differentiable(because every higher order derivative exists and is identically zero). But then if that is the case , shouldn’t every function be infinitely differentiable ? Suppose we differentiate a differentiable function $n$ number of times and we get zero , we can still differentiate it infinitely right ? Then why do many textbooks call a function twice differentiable , thrice differentiable etc. ? I’m sorry if this sounds really stupid but this was something me and my friends had a huge debate on so I wanted to clear it once and for all ! Please correct me if I am mistaken somewhere Thanks for your help","['derivatives', 'soft-question']"
2857929,Find $\log _{24}48$ if $\log_{12}36=k$,Find $\log _{24}48$ if $\log_{12}36=k$ My method: We have $$\frac{\log 36}{\log 12}=k$$ $\implies$ $$\frac{\log 12+\log 3}{\log 12}=k$$ $\implies$ $$\frac{\log3}{2\log 2+\log 3}=k-1$$ So $$\log 3=(k-1)t \tag{1}$$ $$2\log 2+\log 3=t$$ $\implies$ $$\log 2=\frac{(2-k)t}{2} \tag{2}$$ Now $$\log _{24}48=\frac{\log 48}{\log 24}=\frac{4\log 2+\log 3}{3\log 2+\log 3}=\frac{2(2-k)+k-1}{3\left(\frac{2-k}{2}\right)+k-1}=\frac{6-2k}{4-k}$$ is there any other approach?,"['algebra-precalculus', 'logarithms', 'exponential-function', 'ratio']"
2857946,How to estimate the following integral?,"I would like to estimate the integral $I_{s,t}$ by a constant $C$ independent of $s, t \in \mathbb S^1$: $$I_{s,t}=\int_{|r-s|\geq 2|t-s|} \frac{|t-s|}{|r-s|^2} \, dr,$$
where $r, s \, \mbox{and}\, t$ are in the unit circle $\mathbb S^1=\{\zeta\in \mathbb C: \, |\zeta|=1\}$. More precisely, I want to prove that, there exist a constant $C$ independent of $s, t \in \mathbb S^1$ such that 
$$I_{s,t}=\int_{|r-s|\geq 2|t-s|} \frac{|t-s|}{|r-s|^2} \, dr< C.$$ Thank you in advance","['inequality', 'real-analysis', 'calculus', 'complex-analysis', 'integration']"
2857975,What is $\int\frac{x^4}{1+ e^x} dx$?,"Here's the integral I have, $$ \displaystyle\int\dfrac{x^4}{1+ e^x} dx $$ I tried the usual methods I know, but I failed miserably. How would you all approach this problem?","['indefinite-integrals', 'integration', 'calculus']"
2857994,Prove that $a^4+b^4+1\ge a+b$.,"Prove that $$a^4+b^4+1\ge a+b$$ for all real numbers $a,b$ . What I've tried: 1.I checked how AM-GM may help but doesn't look like it's useful here. I've tried: $$(a^2+b^2)^2 -2(ab)^2+1 \ge a+b$$ But unfortunately, I can't find any way to continue this..
I'm sure that this isn't too hard, it's just that ""I'm not seeing it"", I would appreciate if clues are given first so I can answer this myself. *This exercise is from the TAU entry exams.","['algebra-precalculus', 'inequality', 'a.m.-g.m.-inequality', 'symmetric-polynomials']"
2858025,Estimating the smallest distance between $n$ points uniformly distributed on the unit circle.,"I'm working on the following question and would like some hints or solutions Let $n$ points be iid, uniformly distributed on the unit circle. Let
  $\Delta_n$ be the smallest distance between any two of these points. 
  Show that $n^\theta \Delta_n\to 0$ in probability as $n\to \infty$, for all $0<\theta<2$. HINT: Divide the circle into small arcs and find the probability that at
  least one arc contains 2 or more points So I tried following the hint, and I considered dividing up the circle into $n-1$ pieces that would give with probability 1, that two are in the same section.  However, $n^\theta/n-1$ does not go to zero.    The other things I tried were $n^2$ pieces and $n$ pieces, but the probability calculations are rather messy for these and I'd be dealing with factorials, which does not seem like it would go well with this problem. Source: Problem 2","['probability-theory', 'probability']"
2858046,Homomorphism from divisible group to finite group is always trivial,"Let $A$ be a divisible group, let $B$ be a finite group, and let $f: A \rightarrow B$ be a homomorphism. Show that $f$ is trivial. (A group $A$ is divisible if for each $a \in A$ and $n \ge 1$ there exists some $b \in A$ such that $b^n = a$) I wanted to know if my solution is correct - Let $a \in A$. And assume that $|B| = n$ for some $n \in \mathbb{N}$. So we can see that - $f(a)=f(b^n)=(f(b))^n=e_B$ and therefore $f$ is trivial. The first $=$ is because of $A$ being a divisible group, and the second is because of $f$ being an homomorphism.","['finite-groups', 'group-homomorphism', 'divisible-groups', 'group-theory']"
2858053,Generalization of the sum of angles formula for any number of angles,"In another question one user helped me prove that the sum of three angles was a multiple of 360 degrees with formulas for sine and cosine sums of three angles. The sine formula was:
$\sin⁡(α+β+γ)=\sin ⁡α\cos⁡\beta\cos ⁡γ+\cos ⁡α\sin ⁡β\cos ⁡γ+\cos ⁡α\cos ⁡β\sin ⁡γ-\sin ⁡α\sin ⁡β\sin ⁡γ$ I infer that the pattern for five angles is as shown below? For brevity, I'm using a shorthand, e.g. $\sin⁡(α+β+γ):s(a_1+a_2+a_3 )$ and $\sin ⁡α\cos ⁡\beta\cos ⁡γ∶s_1 c_2 c_3$. So, is the following the proper pattern for summing five angles?
$$s(a_1+a_2+a_3+a_4+a_5)=s_1 c_2 c_3 c_4 c_5+c_1 s_2 c_3 c_4 c_5+c_1 c_2 s_3 c_4 c_5+c_1 c_2 c_3 s_4 c_5+c_1 c_2 c_3 c_4 s_5-s_1 s_2 s_3 s_4 s_5$$ If so, I can also infer the pattern for cosine and use the patterns for any number of angles.",['trigonometry']
2858054,Counting number of ways a number can be written as the sum of distinct numbers within a certain range,"I am interested in counting the number of ways in which a number $n$ can be written as the sum of $k$ distinct numbers in increasing order such that every number is a natural number in the range $\{1,2,\dots,\ell\}$. For example, with $n=23$ and $\ell=9$ we have for the following values of $k$: $n=23,\ell=9,k=7$: There are zero ways as the smallest summation possible is $28$. $n=23,\ell=9,k=6$: There are two ways, namely $1+2+3+4+5+8$ and $1+2+3+4+6+7$ $n=23,\ell=9,k=5$: There are several ways, but I have difficulty counting them by hand $n=23,\ell=9,k=4$: There are several ways, but I have difficulty counting them by hand $n=23,\ell=9,k=3$: There is only one way, namely $6+8+9$ $n=23,\ell=9,k=2$: There are zero ways as the largest possible summation totals $17$ Given certain values of $n,k,\ell$, what type of techniques can be employed to count the number of summations?  What algorithms might we employ if we were to try to brute force the count with a computer?  What is a more common name for the objects I am trying to count and do these appear anywhere in literature? Related: In how many ways can I write a number $n$ as the sum of $4$ numbers?","['combinatorics', 'integer-partitions']"
2858068,Is there a metric space such that for a sequence of nonempty subsets $K_1 \supset K_2 ....$ the intersection of all subsets is empty?,"Is there a metric space $(X,d)$ such that for a sequence of $\emptyset \neq K_j \subset X$ with $K_1 \supset K_2 ....$ such that the intersection of all $\bigcap _{j\in \mathbb{N}}K_j$ is empty? It seems very obvious that since all $K_j$ are not empty, there is an element in $K_1$ that is also in all $K_i$ with $i \geq 1$ and that this element this is an element of the intersection, which thus is nonempty. However in the task it was specified that the metric space is compact and the subsets $K_j$ are closed . I have used neither in the argument above and cannot figure out a counterexample where it would be necessary to have the conditions to the sets.","['metric-spaces', 'compactness', 'elementary-set-theory']"
2858090,triangles in $\mathbb{R}^n$ with all vertices in $\mathbb{Q}^n$,"In the context of this post, a triangle will mean a triple $(a,b,c)$ of positive real numbers which qualify as side lengths of a triangle (i.e., the triangle inequalities are satisfied). Call triangle $(a,b,c)$ rationally realizable if, for some integer $n\ge 2$, a triangle with side lengths $a,b,c$ can be placed in $\mathbb{R}^n$ with all vertices in $\mathbb{Q}^n$. Some examples . . . If equilateral triangle $(a,a,a)$ has $a\in\mathbb{Q}$, then it's rationally realizable in $\mathbb{R}^6$.$\\[6pt]$ Proof: $\;$Use vertices 
$
({\large{\frac{a}{2}}},{\large{\frac{a}{2}}},0,0,0,0),\,
(0,0,{\large{\frac{a}{2}}},{\large{\frac{a}{2}}},0,0),\,
(0,0,0,0,{\large{\frac{a}{2}}},{\large{\frac{a}{2}}})
$. If right triangle $(a,b,c)$ with legs $a,b$ has $a,b\in\mathbb{Q}$, then it's rationally realizable in $\mathbb{R^2}$.$\\[6pt]$ Proof: $\;$Use vertices $(0,0),\,(a,0),\,(0,b)$. From the distance formula, for triangle $(a,b,c)$ to be rationally realizable, a necessary condition is $a^2,b^2,c^2\in \mathbb{Q}$. Is this condition also sufficient? More precisely: Question: $\;$If triangle $(a,b,c)$ has $a^2,b^2,c^2\in \mathbb{Q}$, must it be rationally realizable?","['diophantine-equations', 'elementary-number-theory', 'geometry']"
2858098,What is a differential form?,"can someone please informally (but intuitively) explain what ""differential form"" mean? I know that there is (of course) some formalism behind it - definition and possible operations with differential forms, but what is the motivation of introducing and using this object (differential form)?
I have heard that they somehow generalize integration, are used for integration of manifolds and can evaluate k-dimensional integrals in n-dimensional space ( $k \leq n$ ), but is it really true and is it the main motivation of introducing this object into mathematics?
Thank you for explanation",['multivariable-calculus']
2858168,How to properly read the … operator in this context?,"A polynomial expression can be written in this form 
$$a_nx^n+a_{n-1}x^{n-1}+\dots+a_2x^2+a_1x+a_0$$
Therefore, this is a polynomial
$$5x^4+3x^3+4x^2+3x+2$$
I understand this fairly well, because $n=4$. I know that when $n=2$, it is still a polynomial.
$$4x^2+3x+2$$
But if I attempt to use the formula for $n=2$, I will end up with something like this.
$$4x^2+3x^1+4x^2+3x+2$$
Do you see my reasoning? I want to have three values of $a$ such as $a_0=2,a_1=3,a_2=4$. The above form of the polynomial expression using the $\ldots$ operator appear to be requiring at least 4 $+$ symbols and the duplication of $a_1, a_2$ when $n=2$. I do not completely understand the usage of the $\dots$ operator.","['algebra-precalculus', 'polynomials', 'notation']"
2858213,Resonance in Mathieu's Equation,"Consider the Mathieu's Equation:
$$\frac{d^{2}u}{dt^2}+[\omega^2 + 2\epsilon \cos(2t)]u=0$$ with $u(0)=1$ and $u'(0)=0$ What I have done is, assume $u(t)=u_{0}(t)+\epsilon u_{1}(t)+\cdots$, substitute into the DE, and we get
$$u_{0}(t)=\cos(\omega t)$$ and $$u_{1}(t)=\frac{(1-\omega)\cos[(2+\omega)t]-2\cos(\omega t)+(1+\omega)\cos[(2-\omega)t]}{4-4\omega^2}$$. The question is, what modes are resonant at order $\epsilon$? and what frequencies are resonant at the next order (i think it means order $\epsilon^2$)? What are the definition of modes and resonance in this problem? I have no idea how to proceed because I do not know the definition. Can anyone tell me what does it mean by ""modes"" and ""resonant""? Moreover, What is ""frequency"" here? The problem is just an ODE, where does the word ""frequency"" come from?","['stability-in-odes', 'ordinary-differential-equations', 'perturbation-theory']"
2858232,"Is it true that $\forall \epsilon>0, \exists \text{ infinitely many } n \in \mathbb{N}, s.t. |\sin(n) - 1| < \epsilon$?","I'm wondering if the following statement is true or not. For me, it's quite 'intuitively' true, but I don't have any idea how to prove. Statement : $\forall \epsilon>0, \exists \text{ infinitely many } n \in \mathbb{N}, s.t.  |\sin(n) - 1| < \epsilon$ Is there anyone to help me out?","['epsilon-delta', 'real-analysis', 'trigonometry']"
2858233,Find $B$ if $B=A-{{1}\over{2}} A^2+{{1}\over{3}} A^3 -{{1}\over{4}} A^4+...$,"Let $$
\ A=\begin{bmatrix} 0 & a & a^2 & a^3 \\ 0 & 0 & a & a^2 \\ 0 & 0 & 0 & a \\ 0 & 0 & 0 & 0 \end{bmatrix}
$$ and
  $B=A-{{1}\over{2}} A^2+{{1}\over{3}} A^3 -{{1}\over{4}} A^4+...$ $i)$ Find the matrix $B$ $ii)$ Prove that $A=B+ {{1}\over{2!}} B^2+ {{1}\over{3!}} B^3+...$ My attempt: $i)$
I calculated $A^2$ by multiplying $A$ by itself, then foundnd $A^3$ by multiplying $A$ by $A^2$, ans so on. Then I noted that $A^n=0$ for $n\geq 4$ $A^2= A.A=\begin{bmatrix} 0 & 0 & a^2 & 2a^3 \\ 0 & 0 & 0 & a^2 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \end{bmatrix}
$ $A^3= A^2.A=\begin{bmatrix} 0 & 0 & 0 & a^3 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \end{bmatrix}
$ $A^4=A^3.A =\begin{bmatrix} 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \end{bmatrix}
$ $A^n=0$ for every $n\geq 4$, so: $B= \begin{bmatrix} 0 & a & {{1}\over{2}} a^2 & {{1}\over {3}}a^3 \\ 0 & 0 & a & {{1}\over{2}} a^2 \\ 0 & 0 & 0 & a \\ 0 & 0 & 0 & 0 \end{bmatrix}
$ But is there any way easier than my way ? And what about $(ii)$ ?","['matrices', 'linear-algebra']"
2858259,Confused between Single Value Decomposition(SVD) and Diagonalization of matrix,"I'm studying Principle Component Analysis (PCA), and came across this post. In which it's written that diagonalization of co-variance matrix ($C$) can be given by $$C = VLV^T$$ But as per difference between SVD and Diagonalization and this post , it's clear that diagonalization of any matrix can be given by:
$$C = VLV^{-1}$$ So why the definition of SVD and diagonalization is same here ?","['matrices', 'matrix-decomposition', 'machine-learning', 'svd', 'linear-algebra']"
2858261,Coordinate free definition of $\nabla$ operator,"There are a number of posts on this site asking similar questions and some of them have been answered (to my taste) at least partially but none give a complete answer that I am satisfied with. See links at the bottom of this question for a small selection of posts asking related (or even the same) questions. My question is as follows. The following is often written down: $$
\nabla = \frac{\partial}{\partial_x} \hat{x} + \frac{\partial}{\partial y}\hat{y} + \frac{\partial}{\partial z} \hat{z}
$$ Some people will call this an operator, some will call it a vector, some will call it a vector operator, and some will adamantly claim that it is not properly anything at all and you shouldn't call it any of these things and you should just treat it as a ""notational convenience"". One can then go on to use this ""vector operator"" to calculate things like $\nabla f$, $\nabla \cdot \vec{F}$ or $\nabla \times\vec{F}$ where the operator is treated notationally as if it were a vector. First I want to take issue with the final claim that it is purely a notational convenience. I think it is more than just a notational convenience for the following reason. It is possible, by following certain transformation rules, to express $\nabla$ in different coordinate systems, for example cylindrical or spherical. That might be fine, but there is a FURTHER point which makes me think $\nabla$ must be more than a notational convenience. if you express $\nabla$ in different coordinates you can then calculate something like $\nabla \cdot \vec{F}$ in the new coordinates and get the right answer. An answer which you could have arrived at by explicitly converting the cartesian expression for $\nabla \cdot \vec{F}$ into the new coordinate system. In other words, the $\nabla$ allows you to actually skip a step of calculation you would have had to do otherwise. This is evidence that the symbol carries some sort of mathematical structure to it which should be able to be captured in an independent definition. To that end I'm interested in a coordinate free definition of this symbol. The definition I gave above relies on using the usual Cartesian coordinates above. I have searched but haven't been able to find a coordinate free definition of the $\nabla$ symbol. Can one exist? In particular, I am interested in such a formula so that it is algebraically evident how one should calculate the components of $\nabla$ in any given coordinate system. Is there a coordinate free definition of $\nabla$? I am aware of a few complications with this endeavor that I'll just list here: 1) If this is to be some kind of vector or some kind of operator then it is not clear what space it should live in. For example, it is an object which can take a function $f$ and map it to a vector space. But at the same time it is an object which can be fed as an argument to a dot product together with a vector (form a different space) and return a scalar. 2) If I put on my differential geometry hat it becomes a very weird object. In differential geometry I come to think of vectors as actually being things like $\frac{\partial}{\partial x}$ and that $\vec{x}$ notation is eschewed. However the $\nabla$ symbol above contains both of these sitting next to each other. it's like a vector of vectors.. The idea of two vectors sitting next to eachother made me think it might be some kind of rank 2 contravariant tensor but I think that may have been a stretch. 3) I am aware that the cross product and curl operator are only defined in 3 dimensions so it does not need to be pointed out that that limits the possibility of defining such an operator for arbitrary dimension. I am happy to say we are working in 3 dimension. 4) I understand that the idea of divergence and curl depends on the presence of a metric for a space. Ok, that is fine. We can work in a space that has a metric defined on it. 5) Maybe the metric needs to be flat? Even that is fine as long as we can work in coordinate systems such as cylindrical or spherical where the metric is still flat but no longer has a trivial component representation. I am happy to restrict analysis to $\mathbb{R}^3$ if that is necessary. 6) Finally if such a definition truly cannot be formulated then could you at least answer why I can calculate BOTH $\nabla f$ and $\nabla \cdot \vec{F}$ by either 1) computing $\nabla f$ or $\nabla \cdot \vec{F}$ in xyz coordinates, then convert everything to spherical or 2) compute $\nabla$ in xyz coordinates, covert to spherical, then calculate $\nabla f$ and $\nabla \cdot \vec{F}$ and get the same answer in both cases? It just seems slightly too powerful/structured to be JUST a notational convenience. Here are a few other related questions: Is there a general formula for the del operator $\nabla$ in different coordinate systems? Can $\nabla$ be called a ""vector"" in any meaningful way? Coordinate transformation on del operator","['notation', 'differential-geometry', 'vectors']"
2858266,Inverse matrix of matrix (all rows equal) plus identity matrix,"Let $A$ be a matrix where all rows are equal, for example, $$A=\left[\begin{array}{ccc}
a_{1} & a_{2} & a_{3} \\
a_{1} & a_{2} & a_{3} \\
a_{1} & a_{2} & a_{3}
\end{array}\right]$$ Then what is the inverse of the matrix $B=I+A$, where $I$ is the identity matrix? For example, $$B=\left[\begin{array}{ccc}
a_{1}+1 & a_{2} & a_{3} \\
a_{1} & a_{2}+1 & a_{3} \\
a_{1} & a_{2} & a_{3}+1
\end{array}\right]$$ I have a conjecture, which computation has so far confirmed: $$B^{-1}=I-\frac{A}{\mbox{tr}(A)+1}$$ Why is this true?","['matrices', 'linear-algebra', 'inverse']"
2858277,How many connected components for the intersection $S \cap GL_n(\mathbb R)$ where $S \subset M_n(\mathbb R)$ is a linear subspace?,Let $S \subset M_n(\mathbb R^n)$ be a linear subspace. Is there a way to determine how many connected components there are for $S \cap GL_n(\mathbb R)$? Let us assume the intersection is nonempty. $GL_n(\mathbb R)$ has two connected components. Does this intersection have two connected components or possibly more?,"['abstract-algebra', 'general-topology', 'linear-algebra', 'connectedness']"
2858303,The rationality theorem in birational geometry,"I am now reading the proof of rationality theorem in birational geometry of algebraic varieties written by Kollár-Mori. (pp.86)The main confusing  thing is the first step which reduced the big and nef divisor $H$ to the base point free case. Since $H$ is big and nef, by using the property, we can write it linearly equivalent to the sum of a $\mathbb{Q}$-Cartier ample divisor $A_k$ and $\frac{1}{k}E$ for any sufficiently large $k$ and some fixed effective divisor $E$, but how can it be still nef when change it into a linear combination of $H$ and $K_X+\Delta$? I see it is still big by change the coefficient, but how can it be nef? Here being nef is more important since we want to use the base point free theorem proved in the former section. Any help and hints are appreciated.","['algebraic-geometry', 'birational-geometry']"
2858371,How to follow matrix operations in proofs?,"I'm a software engineer trying to learn linear algebra and feel like I'm having a hard time following matrix computations. For example, this is a part of the least squared method for linear model: $$\sum\limits_{i=1}^n ||\mathbf\theta^T\mathbf x_i-y_i||^2=(\mathbf{X\theta}-\mathbf y)^T(\mathbf{X\theta}-\mathbf y).$$ How do we jump from the first line, where there's a lot going on like Sigma $i=1\to n$, norm squared, $x_i$, $y_i$, etc., to the second line where those are wrapped nicely in that matrix representation with transpose thing? I know that can arrive at the second line if I carefully write down, try playing with concrete matrices, and I'm very slow with this. Is there any other way to reason, or visualize it? How do mathematicians tackle this kind of thing? Or everyone's kind of struggle with it privately too?","['matrices', 'matrix-equations', 'linear-algebra']"
2858406,"Need help finding maximum unpayable amount between two coins of values 5 and 7, and understanding why.","I am currently taking in introduction course to Discrete mathematics, and came across this problem: Imagine we have only 5- and 7-coins. One can prove that any large enough integer amount can be paid using only such coins. Yet clearly we cannot pay any of numbers 1, 2, 3, 4, 6, 8, 9 with our coins. What is the maximum amount that cannot be paid? I am a bit stuck, I was told that the solution was simple enough and didn't require programming ( the course also is a crash course in Python) but I don't see any method that was presented in the lectures for arriving at the answer. How would I do it, and more importantly what should I take away for future similar problems?",['discrete-mathematics']
2858441,$BV(\Omega)$ is embedded compactly in $L^1 _{\mathrm{loc}} (\Omega)$,"Definition:
We say that a function $u: \Omega \rightarrow \mathbb{R}$ is a function of bounded variation iff $u\in L^1(\Omega)$ and $\sup\left\{\int\limits_{\Omega}u \operatorname{div}\phi : \phi \in C_c(\Omega, \mathbb{R}^d), ||\phi||_{\infty} \leq 1\right\} < +{\infty}$ . By definition it is clear that $\mathrm{BV}(\Omega)\subset L^1(\Omega)$ . How to show that this embedding is compact when $\Omega$ is bounded set?
Seems like this is a very standard result, but I could not find the proof of this in many of the functional analysis book.","['partial-differential-equations', 'regularity-theory-of-pdes', 'functional-analysis', 'bounded-variation', 'analysis']"
2858446,Is a manifold modulo a free action still a manifold?,"If $D$ is a manifold, and $G$ is a group that acts freely on $D$, then is it true that $D/G$ is still a manifold? Why? And why is it important that the action of $G$ on $D$ is free?","['manifolds', 'differential-geometry']"
2858450,"Find extrema (max,min) of a 3 variable function on a given domain","$f(x,y,z) = (x^2+y^2)e^z$
with domain = $D=\{x^2+y^2=4 , (x-2)^2+y^2 +z^2<= 4\}$ I found that a possible min/max could be the point $(0,0)$ (grad(f)=0..) I can see that the boundary of $D$ is $z^2-4x+4=0$ which is the intersection between the cylinder $x^2+y^2=4$ and the sphere $(x-2)^2+y^2 +z^2<= 4$ So I need to find the min/max on $D$ and on its boundary separately I checked the min/max using $Lagrange multiplier $ on the cylinder $x^2+y^2=4$, but here is the problem : The LaGrange system has 3 equation with 4 variables: $f_x+\gamma g_x=0$ 
$f_y+\gamma g_y=0$
$x^2+y^2=4$ I dont know how to behave without a z in my constrain ->$x^2+y^2=4$ I have the same problem with $z^2-4x+4=0$ if I do lagrange I dont know the $y$ Can you help me figure out the system clearly and find min/max constrained and not. Thx. EDIT : I managed to find the max/min on the constrain -> I did the LaGrange system of 5 equations , so I used two constrains inside the system (not just one at a time). and I found $(2,0,+-2)$ which is correct. But I still can't figure out how to calculate max/min inside the domain $D$","['multivariable-calculus', 'calculus']"
2858478,Posterior distribution of a random distribution sampled from Dirichlet process,"I was reading a bit into nonparametric Bayesian statistics and came across the expression of the posterior of a random distribution $G$ sampled from the Dirichlet process given data sampled from $G$, namely: Let $G\sim DP(\alpha, H)$ be a random probability measure on a standard Borel space $\mathcal{X}$. Let $X_1,\dots,X_n\stackrel{\text{iid}}{\sim} G$. Then $$G\mid X_1,\dots,X_n\sim DP\left(\alpha+n,\; \frac{\alpha H + \sum_{i=1}^n \delta_{X_i}}{\alpha+n}\right).$$ However, no proof was given in the lecture notes and in other notes I could only find short, hand-waving proofs. I wanted to do this rigourously but don't know if the proof is correct.
My proof follows from the fact that $G\sim DP(\alpha, H)$ if and only if for every partition $A_1,\dots, A_k$ of $\mathcal{X}$ we have that the vector $(G(A_1),\dots, G(A_k))\sim \operatorname{Dir}(\alpha H(A_1),\dots, \alpha H(A_k)).$ My proof:
Let $A_1,\dots,A_k$ be a partition of $\mathcal{X}$ and let $N_j$ be $\sum_{i=1}^n\mathbb{1}_{\{X_i\in A_j\}}$ for $j\in\{1,\dots,k\}$. For our notation, denote $V_A:= (G(A_1),\dots,G(A_k)),\; X := (X_1,\dots,X_n),\; N_A:=(N_1,\dots,N_k)$ and let $n_A:=(n_1,\dots,n_k)$ be our observation of $N_A.$ Then we have by Bayes' rule and the definition of $G$ that:
$$ f_{V_A\mid X}\left(p_1,\dots,p_k
\right) \stackrel{(*)}{=}f_{V_A\mid N_A}\left(p_1,\dots,p_k \right) \propto f_{N_A\mid V_A}\left(n_1,\dots,n_k\right) f_{V_A}(p_1,\dots,p_k)\\\propto \prod_{i=1}^k p_j^{n_j} e^{\sum_{j=1}^k(\alpha H(A_j)-1)\log(p_j)} = e^{\sum_{i=1}^k n_j \log(p_j)} e^{\sum_{j=1}^k(\alpha H(A_j)-1)\log(p_j)}= e^{\sum_{j=1}^k(n_j+\alpha H(A_j)-1)\log(p_j)}. $$
Hence $V_A\mid X\sim \operatorname{Dir}(\alpha H(A_1)+\sum_{j=1}^n \delta_{X_j}(A_1),\dots,\alpha H(A_k)+\sum_{j=1}^n \delta_{X_j}(A_k))$ and by normalizing the measure and using the if and only if statement above: $$G\mid X\sim DP\left(a+n,\frac{\alpha H + \sum_{i=1}^n \delta_{X_i}}{\alpha+n}\right).\tag{$\square$}$$ The part of the proof I'm not quite sure about is the equation with $(*)$ above it. I got some information from page 41 of this source: https://www4.stat.ncsu.edu/~sghosal/papers/BayesAsymp.pdf The crux here is that we can consider a finer partition $B_1,\dots, B_m$ of $\mathcal{X}$ than $A$. Following the notation above, we see that
$$V_B\mid N_B\sim \operatorname{Dir}(\alpha H(B_1)+\sum_{j=1}^n \delta_{X_j}(B_1),\dots,\alpha H(B_m)+\sum_{j=1}^n \delta_{X_j}(B_m))$$
If we now denote $s_{i,j}:=\mathbb{1}_{\{B_i\subseteq A_j\}}$ then we must have that $\sum_{i=1}^m s_{i,j}G(B_{i})=G(A_j)$ and hence by the aggregation property of the Dirichlet distribution and as the partition is disjoint:
\begin{align}
V_A\mid N_B & \sim \operatorname{Dir}\left(\sum_{j=1}^ms_{j,1}\left(\alpha H(B_j) + \sum_{k=1}^n \delta_{X_k}(B_j)\right), \dots, \sum_{j=1}^ms_{j,m} \left(\alpha H(B_j) + \sum_{k=1}^n \delta_{X_k}(B_j)\right)\right) \\
& \sim \operatorname{Dir}(\alpha H(A_1) + \sum_{j=1}^n \delta_{X_j}(A_1),\dots,\alpha H(A_k)+\sum_{j=1}^n \delta_{X_j}(A_k))\sim V_A\mid N_A.
\end{align} Now consider a nested sequence of partitions $(A_j)_{j\in\mathbb{N}}$ converging to a partition over the dense subset of the regular Borel space $\mathcal{X}$. Then we know by Lévy's upward theorem (as $V_A$ is bounded, hence in $L^1$) that $V_j:= V_A\mid N_{A_j}$ is a martingale converging almost surely to a version of $V_A\mid \mathcal{F}$ where $\mathcal{F} = \sigma(\cup_{j} \sigma(N_{A_j})).$ Now we have $\mathcal{F}=\sigma(X)$. This holds as $\sigma(X)=\sigma(X^{-1}(\mathcal{B}(\prod_{i=1}^n\mathcal{X})))$ (where $\mathcal{B}(\prod_{i=1}^n\mathcal{X})$ are Borel sets of $\prod_{i=1}^n \mathcal{X}$ and $\prod$ denotes Cartesian product) and $\sigma(N_{A_j})= \sigma(X^{-1}(\prod_{i=1}^n A_j))$ (where $A_j$ denotes the collection).
As every Borel set in $\mathcal{B}(\prod_{i=1}^n \mathcal{X})$ can be approximated arbitrarily close by (possible unions) of sets in $\prod_{i=1}^n A_j$ by taking $j$ large enough, the sigma algebra's are equal in the limit. Hence as $V_A\mid N_A\sim V_A\mid N_{A_j}$ for all $j$, and $V_j\stackrel{d}{\rightarrow}V_A\mid X$ (by almost sure convergence), we must have $V_A\mid N_A\sim V_A\mid X$ and hence the corresponding densities are the same. As I said I'm not quite sure about the last part, certainly the part with the sigma-algebra's. I hope you could give some feedback.. The other sources I checked were: http://stat.columbia.edu/~porbanz/papers/porbanz_BNP_draft.pdf http://www.math.leidenuniv.nl/~avdvaart/BNP/BNP.pdf https://www.stats.ox.ac.uk/~teh/research/npbayes/Teh2010a.pdf","['statistical-inference', 'probability-theory', 'bayesian', 'statistics', 'measure-theory']"
2858484,Why is it often said that dependent variable depends on the values of independent variable,"I hear it often from my teachers that dependent variable is called ""dependent"" because it depends on the values of independent variable. But I think, you can say the same for independent variable, how is independent variable any different then? Eg : $y = 5x$ $y$ is dependent variable. $x$ is independent variable. If I put $x= 5$, then $y= 25$. Surely I can also say, if $y = 25$ then $x$ has to be $5$. Don't they kinda depend on each other? Then what's the point of calling one dependent and other independent? Why do we even call them that in the first place?","['terminology', 'functions']"
2858498,Prove: $\sin\frac{\pi}{20}+\cos\frac{\pi}{20}+\sin\frac{3\pi}{20}-\cos\frac{3\pi}{20}=\frac{\sqrt2}{2}$,"Prove: $$\sin\frac{\pi}{20}+\cos\frac{\pi}{20}+\sin\frac{3\pi}{20}-\cos\frac{3\pi}{20}=\frac{\sqrt2}{2}$$ ok, what I saw instantly is that: $$\sin\frac{\pi}{20}+\sin\frac{3\pi}{20}=2\sin\frac{2\pi}{20}\cos\frac{\pi}{20}$$ and that, $$\cos\frac{\pi}{20}-\cos\frac{3\pi}{20}=-2\sin\frac{2\pi}{20}\sin\frac{\pi}{20}$$ So, 
$$2\sin\frac{2\pi}{20}(\cos\frac{\pi}{20}-\sin\frac{\pi}{20})=\frac{\sqrt2}{2}=\sin\frac{5\pi}{20}$$ Unfortunately, I can't find a way to continue this, any ideas or different ways of proof? *Taken out of the TAU entry exams (no solutions are offered)","['algebra-precalculus', 'trigonometry']"
2858524,How many colors are needed to color an infinite grid so that no sqaure have the same color in all 4 vertexes? [duplicate],"This question already has answers here : Monochromatic squares in a colored plane (2 answers) Closed 5 years ago . Suppose on a 2 dimension infinite grid, all nodes, or equivalently, all $(p,q)$ points, where $p, q \in \mathbb Z$, need to be painted with a color. Is there a way that, given enough kinds of paiting colors, e.g. $n$, all sqaures will have at least 2 colors? i.e we can avoid to have any square that all its 4 vertexes are painted in the same color? Or... is this impossible?","['combinatorics', 'graph-theory', 'coloring', 'recreational-mathematics']"
2858647,Integrating Heaviside Step Function of two Variables,"Suppose we have a definite integral like $$ I=\int_0^\infty dx \int_0^\infty dy \,  Θ(α-x-y) $$
where $a \in R_+^*$ and $Θ$ is the Heaviside step function . Of course this is easy in that we can find the answer without working with integrals,  since it's simply the area of a triangle with vertices $O(0,0)$ , $A(a,0)$, $B(0,a)$, which is $\frac{a^2}{2}$. However trying to work the integral out doesn't seem so trivial (to me at least). One could, naively, do for example $I=\int_0^\infty dx \int_0^{a-x} dy = -\infty$ (since $Θ=0$ for $y \ge a-x$) which is obviously wrong- somehow $Θ$ should affect both integral limits, but I can't see how this can happen. Probably I'm misunderstanding the definition of $Θ(α-x-y)$. EDIT : As @John Polcari pointed out, in the above exaple, we should limit $x$ such that $a-x \ge 0$, so we should have $I= \int_0^\infty dx \int_0^{a-x}Θ(a-x) \, dy $ which indeed gives the right result. However this seems to me like adding the $Θ(α-x)$ by hand, which is no different from the first argument with the triangle's area. Is there a prettier-more strict- way of doing it?","['multivariable-calculus', 'integration', 'step-function']"
2858655,How to compare $2^{\pi}$ and $\pi^2$ using calculus,How to compare $2^{\pi}$ and $\pi^2$ using calculus I guess $$f(x)=\frac{\ln x}{x}$$ wont help here since $2 \lt e \lt \pi$,['calculus']
2858658,Geometry: Prove that two angles are not equal,"(This is just a question for fun. I saw a commercial logo today and I was inspired. I have posted answers for this question and you may post alternative answers!) Question In the figure, $\triangle ABC$ is half of a square and $M$ is the midpoint of $BC$ . Prove that $\alpha\neq\beta$ . Solution $\triangle ABM$ and $\triangle AMC$ have the same area. They have a
 common side $AM$ .

 Note that the area of either triangle is given by $S=\frac12(AB)(AM)\sin\alpha=\frac{1}{2}(AC)(AM)\sin\beta$ .

 But $AB\neq AC$ . So the equality holds only if $\alpha\neq\beta$ .","['alternative-proof', 'geometry']"
2858672,"Is there a simpler way to determine m, n, p, such that the following holds for all reals?","I am given the following equation and I am asked to find $m$, $n$ and $p$, so that the equation holds for all reals: $$ \sin^4x + \cos^4x + m(\sin^6x + \cos^6x) + n(\sin^8x + \cos^8x) + p(\sin^{10}x + \cos^{10}x) = 1, \space \forall x \in \mathbb R $$ I have managed to solve it by, in advance, calculating the following power reduction formulas, and then applying them to the equation: $$
\sin^4x + \cos^4x = 1 - \frac12\sin^2{2x} \\
\sin^6x + \cos^6x = 1 - \frac34\sin^2{2x} \\
\sin^8x + \cos^8x = 1 - \sin^2{2x} + \frac18\sin^4{2x} \\
\sin^{10}x + \cos^{10}x = 1 - \frac54\sin^2{2x} + \frac5{16}\sin^4{2x}
$$ As a result, I managed to simplify it to the following, which is only in terms of powers of $\sin{2x}$: $$ \left( 1+m+n+p \right) - \left( \frac12 + \frac{3m}4 + n + \frac{5p}4 \right) \sin^2{2x} + \left( \frac{n}8 + \frac{5p}{16} \right) \sin^4{2x} = 1, \space \forall x \in \mathbb R $$ I then came to the conclusion that the only possible way for which this can be true is if:
$1+m+n+p=1$, $ \frac12 + \frac{3m}4 + n + \frac{5p}4 = 0 $ and $ \frac{n}8 + \frac{5p}{16} = 0 $. By solving the system of equations below I arrive at the solutions $m=6$, $n=-10$, $p=4$. $$
\left\{ 
\begin{aligned}
1 + m + n + p = 1 \\ 
\frac12 + \frac{3m}4 + n + \frac{5p}4 = 0 \\ 
\frac{n}8 + \frac{5p}{16} = 0
\end{aligned}
\right. 
$$ My question is if my reasoning is correct and if there exists any simpler way to solve the problem.",['trigonometry']
2858682,Is there a generating set of $\mathbb{Z}^3$ having cardinality $2$?,"Is there a generating set of $\mathbb{Z}^3$ having cardinality $2$? I believe that the answer is no... I looked over at possible generating sets, such as $<(1,1,0),(0,1,1)>$, and I can see that there are elements which can't be represented using that set, as since  $\mathbb{Z}^3$ can have $3$ different elements, the generating set must be of at least $3$ elements... And yet, I'm not sure, how to prove this formally?",['group-theory']
2858692,"Area bounded by $(\sqrt{|x|}+\sqrt{|y|})^{12}=xy$ , how to convert this to polar equation, what to do with absolute values?","The only problem finding the limits of integration. Thats why i want to convert to polar. I want to make a substitution so that the limits of r can be easily evaluated.   I was thinking of  $$ x=r^2 cos^2 \phi $$ $$ y=r^2 sin^2 \phi $$ The absolute values scare me a little.  I am not sure if they even change anything, r is positive, but i dont know what to do with absolute values of trig functions.","['polar-coordinates', 'problem-solving', 'calculus', 'multivariable-calculus', 'integration']"
2858695,Continuous homomorphisms of Lie groups are smooth,"I'm working on problem 20-11 from Lee's ""Introduction to Smooth Manifolds"", which asks us to prove: Every continuous homomorphism $\gamma : \mathbb R \to G$ is smooth ($G$ a Lie group). Every continuous homomorphism $F : G \to H$ of Lie groups is smooth. The first part comes with a hint: let $V \subseteq \mathrm{Lie}(G) = \mathfrak g$ be a neighborhood of $0$ such that $\exp: 2V \to \exp(2V)$ is a diffeomorphism (with $2V = \{2X : X \in V\}$). Choose $t_0$ small enough that $\gamma(t) \in \exp(V)$ whenever $|t| \leq t_0$, and let $X_0$ be the element of $V$ such that $\gamma(t_0) = \exp X_0$. Then one can show $\gamma(qt_0) = \exp(qX_0)$ whenever $q = m/2^n$ for some $m,n$. I've been able to show all of this in the hint, but I'm not sure why that implies $\gamma$ is smooth. Is it because it now depends smoothly on $X_0$, which is in one-to-one correspondence with $t_0$? But why should that be true? And why do we care about the dyadic rational $q$? Part 2 also comes with a hint: show that there's a map $\phi : \mathfrak g \to \mathfrak h$ so that the following diagram commutes: 
$\require{AMScd}$
\begin{CD}
    \mathfrak g @>\phi>> \mathfrak h\\
    @V \exp V V @VV \exp V\\
    G @>>F> H
\end{CD}
and then show $\phi$ is linear. But without knowing whether we can talk about $dF_e$, how could we construct such a $\phi$? Any help with either of these problems would be greatly appreciated (or even a good resource on why continuous homomorphisms of Lie groups are automatically smooth).","['smooth-manifolds', 'continuity', 'differential-geometry', 'lie-algebras', 'lie-groups']"
2858713,System of linear differential equation,"How to solve the system of linear differential equation of the form $$x' = Ax + b$$ I can solve the homogeneous form by finding the eigenvalues and respective eigenvectors, but how to find the particular solution part. Also is there any limitation from getting eigenvalues positive, negative or complex. Any other different method involving matrix algebra is also welcome. Thank you.","['matrices', 'ordinary-differential-equations', 'linear-algebra']"
2858747,How to evaluate $\int\frac{1+x^4}{(1-x^4)^{3/2}}dx$?,How do I start with evaluating this- $$\int\frac{1+x^4}{(1-x^4)^{3/2}}dx$$ What should be my first attempt at this kind of a problem where- The denominator and numerator are of the same degree Denominator involves fractional exponent like $3/2$. Note:I am proficient with all kinds of basic methods of evaluating integrals.,"['indefinite-integrals', 'integration', 'calculus']"
2858761,Taking the derivative of $\sum_\limits{n=1}^{\infty}\arctan(\frac{x}{n^2})$,"Problem : Study the possibility of taking the derivative of the following series: $$\sum_\limits{n=1}^{\infty}\arctan\left(\frac{x}{n^2}\right)\:\:,x\in\mathbb{R}$$ I have studied the following theorem: Theorem : Suppose that $\sum_\limits{n=k}^{\infty}f_n$ converges uniformly to $F$ on $S=[a,b]$ . Assume that $F$ and $f_n\:\:,n\geqslant k$ , are integrable on $[a,b]$ . Then: $$\int_\limits{a}^{b}F(x)dx=\sum_\limits{n=k}^{\infty}\int_\limits{a}^{b}f_n(x)dx$$ Following the theorem I would need to check out if the derivative converges uniformly $\sum_\limits{n=1}^{\infty}(\frac{1}{1+\frac{x^2}{n^4}}\frac{2x}{n^4})$ I tried to apply Dirichlet to latter. Once I know that $\sum_\limits{n=1}^{\infty}\frac{2x}{n^4}$ by the integral test converges uniformly. However I was not able to apply it due to the fact that I could not prove $$\sum_\limits{n=1}^{\infty}\left(\frac{1}{1+\frac{x^2}{n^4}}\right)\leqslant M$$ Question : How should I solve the problem? How should I prove the series $\sum_\limits{n=1}^{\infty}\arctan\left(\frac{x}{n^2}\right)$ converge? Thanks in advance!","['derivatives', 'real-analysis', 'uniform-convergence', 'calculus', 'sequences-and-series']"
2858794,Number of chords in a $n$-gon if each chord is crossed at most $k$ times,"Consider an $n$ -gon where we denote the points by $v_1, \dots, v_n$ .
If we allow each chord (internal edge of the $n$ -gon) to have at most $k$ crossings, how many chords can we put into the $n$ -gon (denoted as $c(n,k)$ ).
The answer to this question is the density of outer- $k$ -planar graphs (+ n for the boundary edges of the $n$ -gon):
For $k = 0$ , we have at most $n-3$ chords.
For $k = 1$ , we have $1.5n - 4$ .
One can show that $2n-5$ and $2.25n-6$ holds for $k = 2$ and $3$ .
Can we generalize this to any $k$ ?: Chaplick et al. 1 showed that outer- $k$ -planar graphs are $d$ -degenerate with $d = \lfloor \sqrt{4k+1}+1 \rfloor$ , hence we have less than $dn \approx 2\sqrt{k}n$ chords. Now the best lower bound I can think of (and I  suspect to be best possible) only has approximately $\sqrt{k}n$ chords (hence, the upper bound would be off by a factor of $2$ ). Alternative views of the problem: Consider the adjacency matrix $A$ of an outer- $k$ -planar graph. $A$ is symmetric, binary, has only zeroes in the diagonal and ones in the off-diagonal. Now if there exists an edge $(v_i,v_j)$ , we have at most $k$ edges that are incident to $v_p$ with $ i < p < j$ and $v_q$ with $q < i$ or $j < q$ , hence we have at most $k$ 1-entries in the marked areas, see Figure below. $okp$ graphs"" /> We can consider the intersection graph $IG$ of the graph, i.e. every possible chord is a node of $IG$ and it is connected to another node in $IG$ iff the respective chords in $G$ intersect. Then, the problem is to find a maximum induced subgraph in $IG$ such that the degree is bounded by $k$ . This problem is in general known to be NP-hard, but maybe this can be solved for our particular graph. (Note that this somehow has to be extended to any $n$ ). One can solve this problem for small $n$ and $k$ with an integer linear programm which yields \begin{array}{c|rrrrrrrrrrrrr}
{_n\,\backslash\, ^k} & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 \\
\hline
4 & 1 & 2 & & & & & & & & & & & \\
5 & 2 & 3 & 5 & & & & & & & & & & \\
6 & 3 & 5 & 6 & 8 & 9 & & & & & & & & \\
7 & 4 & 6 & 8 & 9 & 11 & 12 & 14 & & & & & & \\
8 & 5 & 8 & 11 & 11 & 13 & 14 & 16 & 18 & 19 & 20 & & & \\
9 & 6 & 9 & 12 & 14 & 15 & 17 & 18 & 20 & 22 & 23 & 24 & 25 & 27
\end{array} Interesting observation : $c(8,2) = c(8,3)$ 1 https://arxiv.org/abs/1708.08723","['combinatorics', 'graph-theory', 'polygons']"
2858811,"In compact embedding Theorem, $u_0$ lies in $W^{1,p}(\Omega)$?","We know that $W^{1,p}(\Omega)\hookrightarrow L^q(\Omega)$ if $\Omega\subset\mathbb R^N$ is a bounded open and $\partial \Omega$ is $C^1$, $1\leq p<N$ and $1\leq q<p^*:=\frac{Np}{N-p}$. Moreover, for every bounded sequence $(u_n)$ in $W^{1,p}(\Omega)$ (unless subsequence), $u_n\rightarrow u_0$ in $L^q(\Omega)$. I want to $u_0\in W^{1,p}(\Omega)$, but I only know that $u_0\in L^q(\Omega)$. Is it true that $u_0\in W^{1,p}(\Omega)$? and how can I prove it? My attempt: Since $W^{1,p}(\Omega)$ is reflexive, we obtain $u_n\rightharpoonup u_0$ in $W^{1,p}(\Omega)$. We conclue with compact embedding. The problem in my attempt is that $W^{1,p}(\Omega)$ is not reflexive for $p=1$.","['partial-differential-equations', 'functional-analysis', 'compactness', 'sobolev-spaces', 'analysis']"
2858843,Change to polar coordinate in ODEs,"Consider a planar ODE (e.g., $\dot{x}=f_1(x,y),\dot{y}=f_2(x,y)$). According to page $68$ of ODE with Applications by Chicone , a change to polar coordinates (i.e., $x=r\cos(\theta),y=r\sin(\theta)$) in this system introduces a singularity on the line $\{(r,\theta): r=0 \}$. Furthermore, if the original ODE has a rest point at the origin, this singularity is removable. Why is this true? What is the intuition? How can we prove this result?
Thank you.","['real-analysis', 'polar-coordinates', 'control-theory', 'ordinary-differential-equations', 'differential-geometry']"
2858882,What are the facets of the Birkhoff Polytope when $n=2$?,"I've read in several sources that the number of facets of the Birkhoff polytope $\mathcal{B}(n)$ is $n^2$. Is this supposed to hold when $n=2$? Since $\mathcal{B}(2)$ has dimension $1$, the facets would be the two $0$-dimensional vertices, which are the two permutation matrices below:
$$\begin{pmatrix}
1 & 0 \\ 0 &1 
\end{pmatrix} \text{ and } \begin{pmatrix}
0 & 1 \\ 1 &0 
\end{pmatrix}$$
However, the claim is that there should be $2^2 = 4$ facets. None of my sources have given any restriction on $n$. What am I missing?","['discrete-geometry', 'birkhoff-polytopes', 'polytopes', 'discrete-mathematics']"
2858902,Is the product of a $T_4$ space and a compact $T_4$ space necessarily $T_4$?,"Let $N$ be an arbitrary $T_4$ topological space and let $C$ be a compact $T_4$ space.  Is $N\times C$ (with the usual product topology) necessarily $T_4$? I know that the product of general $T_4$ spaces need not be $T_4$.  For example, the Sorgenfrey line is $T_4$, but the product of the Sorgenfrey line with itself is not $T_4$.  The product of two compact $T_4$ spaces, however, is $T_4$.  This follows from the fact that a $T_4$ space is $T_3$, the product of two $T_3$ spaces is $T_3$, the product of two compact spaces is compact, and a compact $T_3$ space is $T_4$. What I'm wondering is if the product of a general $T_4$ space with a compact $T_4$ space is always $T_4$.  My intuition says ""yes"" since compact spaces often act like a single point, but this isn't always so, and intuition can be wrong.  I have no idea how to formulate a proof and I can't think of an obvious counter-example.  For example, the product of the Sorgenfrey line with a compact $T_4$ space will be $T_4$, since the Sorgenfrey line is paracompact, the product of a paracompact space with a compact space is paracompact, and a paracompact $T_3$ space is $T_4$.  So can anyone provide or give a reference to a proof or counter-example to my question?","['product-space', 'general-topology', 'compactness', 'separation-axioms']"
2858906,Restrictions of compositions,"Considering two functions, $f,g:X\to X$ s.t. $Y\subseteq X$ is invariant for both $f$ and $g$, that is $f(Y)\subseteq Y$ and similar for $g$. Do we then have $f|_Y\circ g|_Y=(f\circ g)|_Y$. It seems trivial, but I'm not sure how to show it formally. It would be nice to see a set theoretic argument via the restrictions of relations.","['elementary-set-theory', 'function-and-relation-composition', 'functions']"
2858943,Fraction of $1$s in binary representation of $n!$,"I plotted a fraction of $1$s in binary representation of $n!$ (i.e. A079584 / A072831 ) for $n$ from $1$ to $10^4$: It appears it might converge to some limit for $n\to\infty$. Can we (dis-)prove that this limit exists, and find its exact value? Or, at least, find the limit inferior and limit superior of the sequence?","['limits', 'binary', 'limsup-and-liminf', 'number-theory', 'factorial']"
2858947,$n$-sphere enclosing the Birkhoff polytope,"I am not a mathematician by training, so please feel free to correct my logic or descriptions when necessary: Let $P$ denote a $\textit{permutation matrix}$:
$$
\begin{equation}
P := \{X \in \{0,1\}^{n\times n} : X \mathbf{1}_n = \mathbf{1}_n\,,\,\mathbf{1}_n^T X = \mathbf{1}_n^T\}.
\end{equation}
$$
where $\mathbf{1}_n$ denotes an $n$-dimensional ones vector. When doing optimizations, to circumvent the discrete nature, such matrices are generally relaxed using the doubly-stochastic matrices $\mathcal{DP}_n$, that live on the Birkhoff Polytope, an $(n - 1)^2$-dimensional convex submanifold of the ambient $\mathbb{R}^{n\times n}$, defined as:
$$
\begin{align}
\mathcal{DP}_n = \{\,\,X :& X_{ij}>0  \,,\, i,j \in\{1,...,n\} \,\,\, \wedge \sum\limits_{i=1}^n X_{ij}=1 \,\wedge\, \sum\limits_{j=1}^n X_{ij}=1 \,\,\}
\end{align}
$$
In other words, row and column sums equate to $1$ and entries can take real values between $0$ and $1$. The permutation matrices live on the vertices of Birkhoff Polytope. One can also describe the discrete set of permutation matrices as the intersection of Birkhoff Polytope $\mathcal{DP}_n$ with the orthogonal group (special case of Stiefel manifold when $m=n$):
$$
P=\{X \in \mathcal{DP}_n : X X^T=\mathbf{I}\}
$$
The orthogonal group $O(n)$ can be regarded as an $(n(n—1)/2)$-dimensional surface in the $n^2$-dimensional Euclidean space. This surface is a subset of the sphere of radius $n^{1/2}$. So, the orthogonal group touches the polytope exactly on the permutation matrices. In low-dimensions, one can probably think this as a tessellated shape, approximating the sphere. Or, in the other way around, we can speak of an encapsulating sphere of the polytope (though for higher dimensions this might not be true). Now comes my question : As $n \rightarrow \infty$, does the sphere become a good approximation of the polytope, or does the gap grow? In other words, instead of using the Birkhoff polytope itself as a relaxation of the discrete permutations, can we live with using just the sphere? And, if possible, would it be possible to bound the error of approximation? Thanks!","['birkhoff-polytopes', 'relaxations', 'permutations', 'general-topology', 'polytopes']"
2858950,Non smooth topological vector bundle of rank 3 base 1?,"Does there exist a topological (not necessarily trivial) vector bundle $\pi: E\to M$, with $\dim(M)=1$ and $\dim\big(\pi^{-1}(\{x\})\big) =3$, that has no $C^1$ (or $C^2,C^\infty$) structure? I know that every topological manifold up to dimension 3 has a unique smooth structure and there are 4-manifolds with no smooth structure. So the question here is that can such a non-smooth 4-manifold be a rank 3 base 1 vector bundle? I am guessing that the local triviality should forbid the existence of such bundles but I do not know for sure. $\textbf{Addition:}$ It would also be sufficient to prove that a general topological vector bundle $\pi:E\to M$ is automatically a $C^k$(or $C^\infty$) bundle if the base manifold $M$ is $C^k$(or $C^\infty$). In other words, to prove that it would be possible to construct an atlas of $E$ with bundle charts that are not only continuous but also has the same regularity of the charts of $M$. Any references are warmly welcome. Thanks.","['differential-topology', 'reference-request', 'smooth-manifolds', 'vector-bundles', 'differential-geometry']"
2858953,"From Single-Variable Integration to Multivariable Integration: What Happened to the ""Problem"" of ""Signed/Net Area""?","I remember that, when learning single-variable integration, we learned that, if a function $f(x)$ is negative, then the definite integral produces the negative of the rectangle's area. This fact made it so that, unless the function $y = f(x)$ is always above the $x$-axis, the value calculated by the definite integral is the signed or net area , rather than the total area . This is because the definite integral will calculate the area between $y = f(x)$ and the $x$-axis, which will be negative for the parts between $y = f(x)$ and the $x$-axis when $y = f(x)$ is below the $x$-axis, and positive for the parts between $y = f(x)$ and the $x$-axis when $y = f(x)$ is above the $x$-axis, causing some cancellation between; thus, we have the signed or net area . Area is always a nonnegative quantity. The Riemann sum approximations contain terms such as $f(c_k) \Delta x_k$ that give the area of a rectangle when $f(c_k)$ is positive. When $f(c_k)$ is negative, then the product $f(c_k) \Delta x_k$ is the negative of the rectangle’s area. When we add up such terms for a negative function, we get the negative of the area between the curve and the x-axis. If we then take the absolute value, we obtain the correct positive area. (Hass 285) Hass, Joel R., Christopher Heil, Maurice Weir. Thomas' Calculus, 14th Edition. Pearson. If we wanted to find the total area , then we would have to break-up the function $y = f(x)$ based on whether it was below or above the $x$-axis, and then do many single-variable integrals for each broken-up region, taking the absolute value of those definite integrals that are below the $x$-axis: To compute the area of the region bounded by the graph of a function $y = f(x)$ and the x-axis when the function takes on both positive and negative values, we must be careful to break up the interval $[a, b]$ into subintervals on which the function doesn’t change sign. Otherwise we might get cancelation between positive and negative signed areas, leading to an incorrect total. The correct total area is obtained by adding the absolute value of the definite integral over each subinterval where $f(x)$ does not change sign. The term “area” will be taken to mean this total area. (Hass 285) Hass, Joel R., Christopher Heil, Maurice Weir. Thomas' Calculus, 14th Edition. Pearson. I then went on to learn multivariable integrals (double, triple) and related concepts, such as different parameterisations/transformations (cylindrical coordinates, spherical coordinates), Green's theorem, Stoke's theorem, the Divergence theorem, etc. In learning these more advanced concepts, this issue with having negative function values was never again mentioned. However, this has been bugging me for a while now, since, as I understand it, this would still be a problem in the multivariable case; but, unlike the single-variable case, there has been no discussion about it or ""how to deal with it"", as there was with signed/net area. I would greatly appreciate it if people could please take the time to explain how the aforementioned ""problem"" of negative function values in the case of single-variable integration comes into play when we're dealing with these more advanced concepts and multivariable integration.","['real-analysis', 'multivariable-calculus', 'integration', 'definite-integrals', 'vector-analysis']"
2858964,Is there any plane in a quintic threefold?,"Sorry to bother if this question is trivial: For a general smooth quintic threefold $V$ in $\mathbb{P}^4$ over an algebraic closed field $k$ of characteristic $0$. Is there a plane in $V$? If Yes, how do I find it(them)? If no, under what condition there is a plane? Thanks for any hints and comments.","['algebraic-geometry', 'geometry']"
2858974,Pullback of an Immersion $j: \mathbb{R}^3 \to \mathbb{R}^4$,"I'm preparing for some exams and this problem is from an older exam: ""On $\mathbb{R}^4$, with standard coordinates $(x, y, z, t)$, consider the 1-form $\theta = x \, dy − y \, dx + z \, dt − t \, dz$. Is there a smooth immersion $j : \mathbb{R}^3 \to \mathbb{R}^4$ such that $j^∗ \theta = 0$ everywhere?"" I'm not sure of where to start besides of course supposing there is such an immersion and seeing if it leads to a contradiction. I've also differentiated the 1-form just to see if any patterns come of it but there are none as far as I can tell. However, the 1-form does look very symmetric and I'm sure it was chosen with care. I was told to look at some integrability conditions such as the kernel of some map and apply Frobenius' Theorem. However, I only know of the version of Frobenius' theorem in the context of taking the Lie bracket of vector fields. Any help or hints are helpful, thank you!","['differential-geometry', 'differential-topology']"
2858989,When does $S \cap GL_4(\mathbb R)$ have precisely two connected components where $S \subset M_4(\mathbb R)$ is a linear subspace?,"This is related to the question How many connected components for the intersection $S \cap GL_n(\mathbb R)$ where $S \subset M_n(\mathbb R)$ is a linear subspace? I asked. There is a nice example in the answer to show the intersection does not need to have two connected components as $GL_n(\mathbb R)$. The comment below by Travis is also very helpful. Let $S \subset M_n(\mathbb R^n)$ be a linear subspace. What property should $S$ process such that $S \cap GL_n(\mathbb R)$ has two connected components? I realized the question I asked before (crossed out above) might be too general to answer. Since it has not been answered, let me ask the specific question I am considering. The question is now cross-posted here at MO. Let $A \in M_4(\mathbb R)$ and $A = (e_2, x, e_4, y)$ where $e_2, e_4$ are standard basis in $\mathbb R^4$ and $x,y$ are undetermined variables. Let $\phi, \psi: M_4(\mathbb R) \to \mathbb R^4$ be linear maps defined by
  \begin{align*}
&\phi: B \mapsto (AB-BA) e_1, \\
&\psi: B \mapsto (AB-BA)e_3.
\end{align*}
  The subspace $S$ I am interested in is the intersection of kernels of the two linear maps, i.e., $S :=\text{ker}(\phi) \cap \text{ker}{\psi}$. In other words, the elements in $S \cap GL_4(\mathbb R)$ would preserve the structure of first and third columns of $A$ by conjugation, i.e., $(B^{-1}AB) e_1 = e_2, (B^{-1}AB)e_3 = e_4$ for $B \in S \cap GL_4(\mathbb R)$. I would like to determine: whether there exists $A$ with eigenvalues all lying on the left open half plane of $\mathbb C$, i.e., with negative real parts ( we can freely choose $x, y$) such that $S \cap GL_4(\mathbb R)$ has precisely two connected components or precisely one component. If there exists $A$, such that $\{V^{-1} A V: V \in S \cap GL_4(\mathbb R)\}$ is connected. Edit 1: If $S \cap GL_4(\mathbb R)$ has precisely two connected components, I guess they should be $S \cap GL_4(\mathbb R)_+$ and $S \cap GL_4(\mathbb R)_-$. So if $V \in S$ and $\det(V) > 0$, $V$ should be path-connected with $I$. It is not hard to check the condition implies $V = (v_1, Av_1, v_3, Av_3)$. Since $e_2 = Ae_1, e_4 = Ae_3$, the question is can we continuously change $v_1, v_3$ to $e_1, e_3$ such that $(v_1, Av_1, v_3, Av_3)$ stay linearly independent during the process. Edit 2: If the intersection only have one component, then the $2^{\text{nd}}$ question is immediate. Or if $A$ has two components but with a real eigenvalue, then $2$ should hold too. However, it is possible $2$ can be solve directly which I could not see. Edit 3: I crossed out the restrictions I put on $A$ although I feel this should not matter too much. The second question is newly added which is actually my end question. Before I had a feeling there should be some ""special"" $A$ such that the intersection would only give $1$ or $2$ components. As mentioned above, it's highly possible we can directly attack the second question.","['connectedness', 'matrices', 'abstract-algebra', 'general-topology', 'linear-algebra']"
2859002,Nontrivial U(1) bundles of a 3-manifold,"If G is a Lie group which is (1) a connected,
(2) simply connected
(3) compact,
then a G bundle on a 3-manifold is necessarily trivial. However, U(1) bundle does not satisfy this (2) simply connected criterion. Can we construct explicit nontrivial U(1) bundles of a 3-manifold? For the following examples: $S^3$ $\mathbb{T}^3$ $S^2 \times S^1$ $D^2 \times S^1$ $D^3$ ( $D^d$ is a $d$ -disk.) It looks that it is easier to do on $S^2 \times S^1$ if we consider a nontrivial Chern number $c_1$ over the $S^2$ (?). How about other cases?","['fiber-bundles', 'differential-topology', 'geometric-topology', 'general-topology', 'differential-geometry']"
2859010,Difference between Open sets of Interval and Open Sets of Topological Space,"I am trying to understand the difference between open sets on a real line and open sets in a topological space. For example, while reading about open sets in Real line, it says: Recall the following definitions about open and closed sets in
  $\mathbb{R}^d$. Open Sets: Write $B_d(x,r) :=\{y \in R^d: |y-x| < r\}$ for the open ball of radius $r$ about $x \in \mathbb{R}^d$. A  set $G \subset \mathbb{R}^d$ is open if  for  all $x \in  G$ there  exists  an $r > 0$  such  that $B(x,r) \subset G$. Now if talk about topological space: A topological space, also called an abstract topological space, is a
  set $X$ together with a collection of open subsets $T$ that satisfies
  the four conditions: The empty set $\emptyset$ is in $T$. $X$ is in $T$. The intersection of a finite number of sets in $T$ is also in $T$. The union of an arbitrary number of sets in $T$ is also in $T$. Members of the $T$ are called open sets Now, how these open sets of real line and Topological space are related?",['general-topology']
2859021,An alternative Lyapunov-like instability proof,"Let $\gamma$ and $\omega$ be two positive real numbers. Consider the following 1-dimensional linear time-varying system
$$
\dot{x}(t)=\underbrace{\left(-\frac{1}{2}(1+\gamma)-\cos(\omega t) + \frac{1}{2}\sqrt{4\cos^2(\omega t) +(1-\gamma)^2}\right)}_{=:a(t)}x(t), \quad x(0)\in\mathbb{R}.
$$ By direct computation of the solution of the above differential equation, it is easy to check that, for $\gamma$ sufficiently small , the origin of the above system is an unstable equilibrium point. However, I'd like to prove instability of the origin via a Lyapunov approach. More precisely, supposing that $\gamma$ is sufficiently small , I'd like to find a function $v(x,t):=q(t)x(t)^2$ such that The norm of $q(t)$ is bounded in $t$, i.e. $\|q(t)\|\le k$, $k>0$, for all $t\ge 0$; The derivative of $v(x,t)$ along the trajectories of the system is strictly negative for all $t$, that is $2a(t)q(t)+\dot{q}(t)<0$ for all $t$; There exists (at least) a $\bar{t}>0$ such that $q(\bar{t})<0$. So my question is: Is it actually possible to find such a Lyapunov function $v(x,t)$? I made several attempts but no one worked. So every comment/suggestion would be greatly appreciated. Thanks!","['dynamical-systems', 'lyapunov-functions', 'stability-in-odes', 'ordinary-differential-equations', 'analysis']"
2859095,"Approximating a multinomial as $p(\xi_1,\ldots,\xi_N)\propto\exp\left(-\frac{n}{2}\sum_{i=1}^N\frac{(\xi_i-p_i)^2}{p_i}\right)$","Question Suppose we have a multinomial distribution with $N$ possible outcomes, with probabilities $p_1,\ldots,p_N$. We sample this $n$ times, and denote the observed frequency of the $i$th outcome as $\xi_i$. In [1] the author claims that the distribution of the $\xi_i$ in the limit of large $n$ is: $$p(\xi_1,\ldots,\xi_N)\propto\exp\left(-\frac{n}{2}\sum_{i=1}^N\frac{(\xi_i-p_i)^2}{p_i}\right).\;\;\;\;\;(1)$$ We can see immediately that this must be an approximation, as it assigns nonzero probabilities for $\xi_1+\cdots+\xi_N>1$. However we can see that these have vanishing probability in the limit $n\rightarrow\infty$. My question is how do we derive (1) from the multinomial distribution, and show that they match in the $n\rightarrow\infty$ limit? My thoughts My first thought would be to appeal to the central limit theorem. The multinomial distribution has mean $\mu_i=p_i$ and covariance matrix $\Sigma_{ij}=\delta_{ij}p_i-p_ip_j$, so we would expect this in the large $n$ limit to be described by a multivariate Gaussian with mean $\mu$ and covariance $\frac{1}{n}\Sigma$. However, things are complicated by the fact that the multinomial covariance is singular (since $\xi_N$ is determined by the other $\xi_i$s), and so the multivariate Gaussian is not defined. To address this, we may try and consider only the first $\xi_1,\ldots,\xi_{N-1}$, which have a non-singular covariance matrix and hence well-defined multivariate Gaussian distribution. Let's take the Binomial distribution $N=2$. The frequency $\xi_1$, this has mean $p_1$ and variance $p_1(1-p_1)$, so this would be described the the Gaussian:
$$\propto\exp\left(-\frac{n}{2}\frac{(\xi_1-p_1)^2}{p_1(1-p_1)}\right).\;\;\;\;\;(2)$$
The expression (1) gives:
$$\propto\exp\left(-\frac{n}{2}\left(\frac{(\xi_1-p_1)^2}{p_1}+\frac{(\xi_2-p_2)^2}{p_2}\right)\right).\;\;\;\;\;(3)$$
If we substitute $\xi_2\rightarrow 1-\xi_1$, $p_2\rightarrow 1-p_1$ into (3), we can verify that this gives the same answer as (2). I have verified that this also works for $N=4$. I'm sure that if I just bashed out the algebra for general $N$ we would get agreement between the central limit theorem and (1) when we restrict the latter to $\xi_1+\cdots+\xi_N=1,p_1+\cdots+p_N=1$. However, how can we start with the multinomial distribution and derive (1) as a limit which is valid everywhere? One idea would be to say that (1) goes to zero as $n\rightarrow\infty$ when you are not on that plane, however I am a bit uncomfortable with this as it goes to zero everywhere except the mean as $n\rightarrow\infty$, so I don't know if that argument is good enough. [1] Wootters, William K. ""Statistical distance and Hilbert space."" Physical Review D 23.2 (1981): 357.","['probability-limit-theorems', 'statistics', 'probability-distributions']"
2859118,"Find an ""upper bound"" for a given sequence.","Let $a_1=5$ and let $$a_{n+1}=\frac{a_n^2}{a_n^2-4a_n+6}$$
Find the biggest integer $m$ not bigger than $a_{2018}$, that is $m\leq a_{2018}$. My go:
Apparently the limit must satisfy $$l=\frac{l^2}{l^2-4l+6}\Leftrightarrow l=0\vee l=3\vee l=2$$ Computing first few terms i see that $a_n\to 3$ as $n\to\infty$. The sequence seems to converge to 3, so i tried to show that $\forall n\geq 2,a_n\leq3$ proceeding by induction, we find that $a_1=5,a_2=25/11\approx2,27\leq3$. Now let $a_n\leq 3\Rightarrow a_{n+1}=\frac{a_n^2}{a_n^2-4a_n+6}\leq\frac{9}{a_n^2-4a_n+6}$ but here I'm stuck again, no idea what to do with the denominator. Any help appreciated.","['sequences-and-series', 'limits']"
2859153,Understanding this math notation in probability?,"I don't get this notation at all and cannot find a place to start with understanding this: $$\mathcal L_D=-\mathbb E_{x\sim P}[\log(D(x))]-\mathbb E_{\hat x\sim Q}[\log(1-D(\hat x))]$$ I don't get $\mathbb E$ there. Does it mean expectation? The equation says it's ""negative log-likelihood"". I understand that $D(x)$ is either 1 or 0. What does the $\mathbb E_{x\sim P}$ mean, especially in the context of statistics? Assuming that $E$ is expectation, what does it mean to have an expectation of a probability distribution $P$ ? Does it imply the mean of the distribution, and in that case what does $\hat x$ typically mean? Unfortunately the paper I'm reading doesn't spell these out so I'm guessing I lack a bit of statistics background here.","['statistics', 'probability', 'notation']"
2859196,Point wise maximum of the difference of two convex functions is also a difference of two convex functions,"Define function $f^i := h^i - g^i$ , where $f^i$ , $g^i$ are real-valued convex functions for all $i = 1,\dots, 10$ . Do there exist real-valued convex functions $h$ , $g$ where $h - g = \max\limits_{i} f^i$ ? I don't even know how to even approach this problem.","['real-analysis', 'convex-analysis', 'functions']"
2859232,"Evaluate $\lim\limits_{x\to\infty}\frac1x\int_0^x\max\{\sin t,\sin(t\sqrt2)\}dt$","I want to evaluate
$$L=\lim_{x\to\infty}\frac1x\int_0^x\max\{\sin t,\sin(t\sqrt2)\}dt$$ My attempt $$L=\lim_{x\to\infty}\frac1{2x}\int_0^x\Big(\sin t+\sin(t\sqrt2)+\big|\sin t-\sin(t\sqrt2)\big|\Big)dt\\
=\lim_{x\to\infty}\frac1{2x}\int_0^x\big|\sin t-\sin(t\sqrt2)\big|dt\\
=\lim_{x\to\infty}\frac1x\int_0^x\bigg|\cos\frac{\sqrt2+1}2t\cdot\sin\frac{\sqrt2-1}2t\bigg|dt$$
Denote $s_n$ the $n$th zero point of $\cos\frac{\sqrt2+1}2t\cdot\sin\frac{\sqrt2-1}2t\ (t\ge0)$. Since $1$, $\sqrt2$ and $\pi$ are linear independent in $\mathbb Q$, the order of the zero points should be $1$. According to the squeeze theorem, we have
$$L=\lim_{n\to\infty}\frac1{s_{n+1}}\sum_{k=0}^n(-1)^k\int_{s_k}^{s_{k+1}}\big(\sin t-\sin(t\sqrt2)\big)dt\\
=\lim_{n\to\infty}\frac1{s_{n+1}}\sum_{k=0}^n(-1)^k\bigg(\cos s_k-\cos s_{k+1}+\frac{\cos\sqrt2s_k-\cos\sqrt2s_{k+1}}{\sqrt2}\bigg)dt$$
I can't go further. I think the zero points of that function is the key point.","['integration', 'definite-integrals', 'calculus']"
2859284,How to use Kullback-Leibler Divergence if probability distributions have different support?,"I have two discrete random variables $X$ and $Y$ and their distributions have different support. Assume $X$ and $Y$ can both take on the same number of values. Lets say $X$ takes values in $\{10,13,15,17,19\}$ and $Y$ takes values in $\{12,14,16,18,20\}$. I would like to use the Kullback-Leibler Divergence but it requires that Q dominates P. Is it possible to modify the support of each random variable so that they have the same support? If not, are there any measures of statistical distance that do not require $X$ and $Y$ to have the same support? One solution I have created is to make kernel density estimators with a gaussian kernel using the datasets collected on $X$ and $Y$. Now the densities $\hat{f}(x)$ and $\hat{g}(y)$ have support on $( -\infty, \infty)$ and with suitable bandwidth they are multimodal with modes centered around the support of the original random variables. It remains to be seen how wise or foolish of an idea this is. Note: Since the KL divergence of a finite gaussian mixture does not have a closed form solution, I used monte carlo methods to estimate it.","['information-theory', 'probability', 'probability-distributions']"
2859299,$f(x+1)-f(x)=f'(x)$: prove $f(x)$ linear function [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question If I have a differentiable function $f:\mathbb{R}\to\mathbb{R}$ satisfies $f(x+1)-f(x)=f'(x)$ and $\lim_{x\to\infty}f'(x)=A$. Can I show $f(x)=ax+b$?","['ordinary-differential-equations', 'calculus']"
2859304,Eigenvalues of a matrix with repeating pattern of entries,"I observed that if $$A = \begin{bmatrix} a & b  \\ c & d \end{bmatrix}$$ with non-zero eigenvalues $\alpha$ and $\beta$, then $$\begin{bmatrix} A & A\\ A & A \end{bmatrix}$$ has eigenvalues $2 \alpha$, $2 \beta$, and $0$. Also, $$\begin{bmatrix} A & A & A \\ A & A & A \\ A & A & A \end{bmatrix}$$ has eigenvalues $3 \alpha$, $3 \beta$, $0$. Therefore, my conjecture is that for some $r$, $A^{[r]}$ has eigenvalues $(r+1) \alpha$, $(r+1) \beta$, $0$. Is it correct? Is there some theorems related to this? How about their eigenvectors? Can you please send me links that can help me with this kind of problem? PS. This is my first time asking here. I am an undergrad math student. Please help me.  Thank u so much.","['matrices', 'eigenvalues-eigenvectors', 'block-matrices', 'linear-algebra']"
2859312,What is $\log(n+1)-\log(n)$?,What is gap $\log(n+1)-\log(n)$ between log of consecutive integers? That is what precision of logarithms determines integers correctly?,"['logarithms', 'numerical-methods', 'real-analysis']"
2859353,Charged particles,"We are creating a circular hub consisting of charged 0 and 1 particles next to each other, beginning with four of them: 0, 1, -0 and -1 in this order. Every 1 sec we randomly select one of each kind and add it next to the last one. Whenever a 0 particle finds itself next to a -0 or a 1 particle next to a -1, they both vanish. Assuming it is equally likely to select each of the 4 kinds, what is the probability that at some point the hub vanishes completely? I assume it is not as easy as $\frac {1}{4}.\frac {1}{3}.\frac {1}{2}$, right? I can't figure out of anything else... Any help?",['probability']
2859382,Compute $\lim\limits_{x\to \infty }\sum\limits_{n=1}^\infty \frac{1}{n(n+x)}$,"I want to compute $$\lim_{x\to \infty }\sum_{n=1}^\infty \frac{1}{n(n+x)}.$$ Can I do as follow? Consider the measurable space $(\mathbb N,\mathcal P(\mathbb N),\mu)$ where $\mu(A)=\#A$. Then,
$$\sum_{n=1}^\infty \frac{1}{n(n+x)}=\int_{\mathbb N}\frac{1}{n(n+x)}d\mu(n).$$
Suppose $|x|\geq 1$. Then
$$\left|\frac{1}{n(n+x)}\right|\leq \frac{1}{n(n+1)}\in L^1(\mathbb N),$$
and thus, using DCT, we finally obtain $$\lim_{x\to \infty }\sum_{n=1}^\infty \frac{1}{n(n+x)}=\sum_{n=1}^\infty \lim_{x\to \infty }\frac{1}{n(n+x)}=0.$$ Does it work ?","['measure-theory', 'real-analysis', 'summation', 'sequences-and-series']"
2859507,Eigenvalues of sum of non-symmetric matrices,"Assume $A, B$ are real matrices. Weyl's inequalities provide bounds on the eigenvalues of $A + B$ if both are symmetric. Is there any bound if neither are symmetric? I am particularly interested about the case where $A$ and $B$ are positive stable , that is, have eigenvalues with positive real part. For instance, can one always produce $A, B$ positive stable such that $A+B$ has eigenvalues with arbitrarily negative real part?","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra']"
