question_id,title,body,tags
2265814,"If $f(z)$ is entire, and $f(z)$ is real iff $z$ is real, prove $f'(z)$ is not equal to $0$ for all real $z$","If $f(z)$ is entire, and $f(z)$ is real iff $z$ is real, prove $f'(z) \ne 0$ for all real $z$. Edit: Sorry, somehow my preliminary efforts didn't make it in here: I know that $f$ cannot be constant, that's a contradiction, and that if $f$ is entire, then it is analytic and holomorphic everywhere. I have seen (but not quite understood) proofs that $f$ can have at most one zero. I have not done ""winding numbers"" and it seems most proofs of this employ the use of these. Because $f$ is entire, it is continuous and so all $z$ in the upper half plane have the same sign of their imaginary part. My first thought was by contradiction. Assume $f'(z)=0$ for some $z_0 \in C$. Then $a_1 = 0$ in the taylor series of $f$, so then $f(z)= f(z_0) + a_2*(z-z_0)^2 + O((z-z_0)^2)$.  Then I'm not sure where to go from here. I was also thinking of setting $f = u(x,y) + iv(x,y)$, and noting that $v(x,0)=0$, but I can't see how this would get me anywhere with derivatives.",['complex-analysis']
2265822,Hypothesis of Stone-Weierstrass Theorem,"Why do we need compactness in the space as hypothesis in Stone-Weierstrass Theorem? Theorem: Let $A \subset C(K)$ such that $A$ is a subalgebra that vanishes nowhere. For each $x, y \in K $ with $x \neq  y $, there exists $f \in A$ such that $f(x)\neq f(y)$. Then $ \overline A = C(K)$, where $C(K)$ is the space of continuous functions over the compact space $K$.","['real-analysis', 'functional-analysis', 'compactness', 'general-topology', 'metric-spaces']"
2265828,pythagorean theorem extensions,are there for a given integer N solutions to the equations $$ \sum_{n=1}^{N}x_{i} ^{2}=z^{2} $$ for integers $ x_i $ and $ z$ an easier equation given an integer number 'a' can be there solutions to the equation $$ \sum_{n=1}^{N}x_{i} ^{2}=a^2 $$ for N=2 this is pythagorean theorem,"['number-theory', 'elementary-number-theory']"
2265850,Implications of inequalities,"For $i=1,2,3$, consider a random variable $Y_i$ taking value in 
$$
\mathcal{Y}:=\{(1,1), (1,0), (0,1), (0,0)\}
$$ and a random closed set $S_i$ taking value in $\mathcal{S}$ that is the power set of $\mathcal{Y}$ (without the empty set), i.e.
$$
\mathcal{S}:=\{\{(1,1)\}, \{(1,0)\}, \{(0,1)\}, \{(0,0)\},\\ \{(1,1), (1,0)\}, \{(1,1), (0,1)\}, \{(1,1), (0,0)\}, \{(1,0), (0,1)\}, \{(1,0), (0,0)\}, \{(0,1), (0,0)\},\\ \{(1,1), (1,0), (0,1)\}, \{(1,1), (1,0), (0,0)\}, \{(1,1), (0,1), (0,0)\}, \{(1,0), (0,1), (0,0)\},\\ \{(1,1), (1,0), (0,1), (0,0)\}\}
$$
$Y_i,S_i$ are defined on the same probability space $(\Omega, \mathcal{F}, P)$. Also, $Y_1, Y_2, Y_3$ are independent, $S_1, S_2, S_3$ are independent. Suppose that
$$
P(Y_i\in K)\leq P(S_i\cap K\neq \emptyset) \text{ } \forall K \in \mathcal{S} \text{ for } i=1,2,3
$$ For example, for $K=\{(1,1), (0,1)\}$ and $i=1$
$$
P(Y_1=(1,1))+P(Y_1=(0,1))\leq \\
P(S_1=\{(1,1)\})+P(S_1=\{(0,1)\})\\+P(S_1=\{(1,1), (1,0)\})+P(S_1= \{(1,1), (0,1)\})\\+P(S_1=\{(1,1), (0,0)\})+P(S_1=\{(1,0), (0,1)\})+P(S_1=\{(0,1), (0,0)\})\\+P(S_1= \{(1,1), (1,0), (0,1)\})+P(S_1=\{(1,1), (1,0), (0,0)\})\\+P(S_1= \{(1,1), (0,1), (0,0)\})+P(S_1= \{(1,0), (0,1), (0,0)\})\\+P(S_1= \{(1,1), (1,0), (0,1), (0,0)\})
$$ I would like your help to show that $$
(\star) \hspace{1cm}
P(Y_1=(1,1))\times P(Y_2=(1,1))\times P(Y_3=(1,1)) +\\P(Y_1=(0,0))\times P(Y_2=(0,0))\times P(Y_3=(0,0))\leq\\
 P(S_1\cap \{(1,1)\}\neq \emptyset \text{ and } S_2\cap \{(1,1)\}\neq \emptyset \text{ and } S_3\cap \{(1,1)\}\neq \emptyset \text{ OR }\\
 S_1\cap \{(0,0)\}\neq \emptyset \text{ and } S_2\cap \{(0,0)\}\neq \emptyset \text{ and } S_3\cap \{(0,0)\}\neq \emptyset)
$$ My attempt (A) I take the inequalities referred to $K=\{(1,1), (0,0)\}$ for $i=1,2,3$ and multiply them across $i$: 
$$
[P(Y_1=(1,1))+P(Y_1=(0,0))]\times [P(Y_2=(1,1))+P(Y_2=(0,0))]\times [P(Y_3=(1,1))+P(Y_3=(0,0))]\leq\\ [P(S_1\cap \{(1,1),(0,0)\}\neq \emptyset)]\times [P(S_2\cap \{(1,1),(0,0)\}\neq \emptyset)]\times [P(S_3\cap \{(1,1),(0,0)\}\neq \emptyset)]
$$ (B) On the lhs the terms ""in excess"" with respect to $(\star)$ are
$$
P(Y_1=(1,1))\times P(Y_2=(0,0))\times P(Y_3=(0,0))+\\
P(Y_1=(0,0))\times P(Y_2=(1,1))\times P(Y_3=(0,0))+\\
P(Y_1=(0,0))\times P(Y_2=(0,0))\times P(Y_3=(1,1))+\\
P(Y_1=(1,1))\times P(Y_2=(1,1))\times P(Y_3=(0,0))+\\
P(Y_1=(1,1))\times P(Y_2=(0,0))\times P(Y_3=(1,1))+\\
P(Y_1=(0,0))\times P(Y_2=(1,1))\times P(Y_3=(1,1))
$$ (C) On the rhs the terms ""in excess"" with respect to $(\star)$ are
$$
P(S_1\cap \{(1,1)\}\neq \emptyset \text{ and } S_1\cap \{(0,0)\}=\emptyset)\times P(S_2\cap \{(0,0)\}\neq \emptyset \text{ and } S_2\cap \{(1,1)\}=\emptyset)\times P(S_3\cap \{(0,0)\}\neq \emptyset \text{ and } S_3\cap \{(1,1)\}=\emptyset)+\\
P(S_1\cap \{(0,0)\}\neq \emptyset \text{ and } S_1\cap \{(1,1)\}=\emptyset)\times P(S_2\cap \{(1,1)\}\neq \emptyset \text{ and } S_2\cap \{(0,0)\}=\emptyset)\times P(S_3\cap \{(0,0)\}\neq \emptyset \text{ and } S_3\cap \{(1,1)\}=\emptyset)+\\
P(S_1\cap \{(0,0)\}\neq \emptyset \text{ and } S_1\cap \{(1,1)\}=\emptyset)\times P(S_2\cap \{(0,0)\}\neq \emptyset \text{ and } S_2\cap \{(1,1)\}=\emptyset)\times P(S_3\cap \{(1,1)\}\neq \emptyset \text{ and } S_3\cap \{(0,0)\}=\emptyset)+\\
P(S_1\cap \{(1,1)\}\neq \emptyset \text{ and } S_1\cap \{(0,0)\}=\emptyset)\times P(S_2\cap \{(1,1)\}\neq \emptyset \text{ and } S_2\cap \{(0,0)\}=\emptyset)\times P(S_3\cap \{(0,0)\}\neq \emptyset \text{ and } S_3\cap \{(1,1)\}=\emptyset)+\\
P(S_1\cap \{(1,1)\}\neq \emptyset \text{ and } S_1\cap \{(0,0)\}=\emptyset)\times P(S_2\cap \{(0,0)\}\neq \emptyset \text{ and } S_2\cap \{(1,1)\}=\emptyset)\times P(S_3\cap \{(1,1)\}\neq \emptyset \text{ and } S_3\cap \{(0,0)\}=\emptyset)+\\
P(S_1\cap \{(0,0)\}\neq \emptyset \text{ and } S_1\cap \{(1,1)\}=\emptyset)\times P(S_2\cap \{(1,1)\}\neq \emptyset \text{ and } S_2\cap \{(0,0)\}=\emptyset)\times P(S_3\cap \{(1,1)\}\neq \emptyset \text{ and } S_3\cap \{(0,0)\}=\emptyset)+\\
P(S_1\cap \{(0,0)\}\neq \emptyset \text{ and } S_1\cap \{(1,1)\}\neq\emptyset)\times P(S_2\cap \{(1,1)\}\neq \emptyset \text{ and } S_2\cap \{(0,0)\}=\emptyset)\times P(S_3\cap \{(0,0)\}\neq \emptyset \text{ and } S_3\cap \{(1,1)\}=\emptyset)+\\
P(S_1\cap \{(0,0)\}\neq \emptyset \text{ and } S_1\cap \{(1,1)\}\neq\emptyset)\times P(S_2\cap \{(0,0)\}\neq \emptyset \text{ and } S_2\cap \{(1,1)\}=\emptyset)\times P(S_3\cap \{(1,1)\}\neq \emptyset \text{ and } S_3\cap \{(0,0)\}=\emptyset)+\\
P(S_1\cap \{(1,1)\}\neq \emptyset \text{ and } S_1\cap \{(0,0)\}=\emptyset)\times P(S_2\cap \{(1,1)\}\neq \emptyset \text{ and } S_2\cap \{(0,0)\}\neq \emptyset)\times P(S_3\cap \{(0,0)\}\neq \emptyset \text{ and } S_3\cap \{(1,1)\}=\emptyset)+\\
P(S_1\cap \{(0,0)\}\neq \emptyset \text{ and } S_1\cap \{(1,1)\}=\emptyset)\times P(S_2\cap \{(1,1)\}\neq \emptyset \text{ and } S_2\cap \{(0,0)\}\neq \emptyset)\times P(S_3\cap \{(1,1)\}\neq \emptyset \text{ and } S_3\cap \{(0,0)\}=\emptyset)+\\
P(S_1\cap \{(1,1)\}\neq \emptyset \text{ and } S_1\cap \{(0,0)\}=\emptyset)\times P(S_2\cap \{(0,0)\}\neq \emptyset \text{ and } S_2\cap \{(1,1)\}= \emptyset)\times P(S_3\cap \{(1,1)\}\neq \emptyset \text{ and } S_3\cap \{(0,0)\}\neq\emptyset)+\\
P(S_1\cap \{(0,0)\}\neq \emptyset \text{ and } S_1\cap \{(1,1)\}=\emptyset)\times P(S_2\cap \{(1,1)\}\neq \emptyset \text{ and } S_2\cap \{(0,0)\}= \emptyset)\times P(S_3\cap \{(1,1)\}\neq \emptyset \text{ and } S_3\cap \{(0,0)\}\neq\emptyset)
$$ (D) One strategy could be to show that (B) $\geq $ (C), and, hence, because of (A), $(\star)$ holds. However, I am unable to do it. (E) What I have shown, instead, is that
$$
1-P(Y_1=(0,0))=P(Y_1=(1,1))+P(Y_1=(1,0))+P(Y_1=(0,1))\geq\\ P(S_1\cap \{(1,1)\}\neq \emptyset \text{ and } S_1\cap \{(0,0)\}=\emptyset)
$$
and
$$
P(Y_1=(1,1))\geq P(S_1=\{(1,1)\})
$$
and
$$
P(Y_1=(1,1))+P(Y_1=(0,0))\geq P(S_1\cap\{(1,1)\}\neq \emptyset \text{ and } S_1\cap\{(0,0)\}\neq \emptyset\})
$$
and
$$
P(Y_1=(1,1))+P(Y_1=(0,0))\geq P(S_1\cap\{(0,1),(1,0)\}=\emptyset)
$$
which, however, do not seem to be useful.","['inequality', 'probability']"
2265859,"Prob. 6, Chap. 5 in Baby Rudin: For $f$ continuous for $x\geq 0$ and differentiable for $x>0$ with $f(0)=0$, if $f^\prime$ is ...","Here is Prob. 6, Chap. 5 in the book Principles of Mathematical Analysis by Walter Rudin, 3rd edition: Suppose (a) $f$ is continuous for $x \geq 0$ , (b) $f^\prime(x)$ exists for $x>0$ , (c) $f(0)=0$ , (d) $f^\prime$ is monotonically increasing. Put $$ g(x) = \frac{f(x)}{x} \qquad  ( x>0)$$ and prove that $g$ is monotonically increasing. My Attempt: For any $x>0$ , as $f$ is continuous on $[0, x]$ and differentiable on $(0, x)$ , so by the Mean Value Theorem there is a point $p \in (0, x)$ such that $$ f(x) = f(x) - 0 = f(x)-f(0) = (x-0) f^\prime(p) = x f^\prime(p).$$ But as $f^\prime$ is monotonically increasing on $(0, +\infty)$ and as $0 < p < x$ , so we can conclude that $f^\prime(p) \leq f^\prime(x)$ and hence $$f(x) = xf^\prime(p) \leq x f^\prime(x),$$ which implies that $$x f^\prime(x) - f(x) \geq 0 \ \mbox{ for all } \ x > 0.$$ Now we see that, for any $x > 0$ , $$ g^\prime(x) = \frac{f^\prime(x)}{x} - \frac{f(x)}{x^2} =  \frac{ xf^\prime(x) - f(x)}{x^2} \geq 0,$$ which implies that $g$ is monotonically increasing on $(0, +\infty)$ . Is the above proof correct?","['derivatives', 'real-analysis', 'calculus', 'analysis']"
2265884,"For any set $A$, there is some $x$ not in $A$.","I am working through a set theory text and am having trouble giving a formal proof of the above statement. So far I have: Suppose the contrary. Then there exists a set $A$ such that $x\in A$ for all $x$. Thus $A$ is the set of all sets, which gives rise to Russell's paradox. Is there a more concise or direct proof of this fact using the axioms of $\sf ZFC$? I am concerned about asserting that $A$ is the ""set of all sets.""",['elementary-set-theory']
2265891,Find all functions $f$ such that $f(x)+f(\frac{1}{1-x})=x$,"I would like to find all functions $f:\mathbb{R}\backslash\{0,1\}\rightarrow\mathbb{R}$ such that $$f(x)+f\left( \frac{1}{1-x}\right)=x.$$ I do not know how to solve the problem. Can someone explain how to solve it? In one of my attempts I did the following, which is confusing to me: By the substitution $y=1-\frac{1}{x}$ one gets $f(y)+f\left( \frac{1}{1-y}\right)=\frac{1}{1-y}$ . So with $x=y$ it follows that $0=x-\frac{1}{1-x}$ . So it would follow that there is no solution. Is that possible or is there a mistake? Best regards","['analysis', 'functional-equations']"
2265900,"Prob. 7, Chap. 5 in Baby Rudin: If $f^\prime(x)$, $g^\prime(x)$ exist, $g^\prime(x)\neq 0$ and $f(x)=g(x)=0$, ...","Here is Prob. 7, Chap. 5 in the book Principles of Mathematical Analysis by Walter Rudin, 3rd edition: Suppose $f^\prime(x)$, $g^\prime(x)$ exist, $g^\prime(x) \neq 0$, and $f(x) = g(x) = 0$. Prove that $$ \lim_{t \to x} \frac{ f(t) }{g(t)} = \frac{f^\prime(x)}{g^\prime(x)}.$$ (This holds also for complex functions.) My Attempt: As $f(x) = g(x) = 0$ ans as $f^\prime(x)$ and $g^\prime(x)$ exist, with $g^\prime(x) \neq 0$, so we have 
  $$
\begin{align}
\lim_{t\to x} \frac{f(t)}{g(t)} &= \lim_{t\to x} \frac{f(t) - 0 }{g(t) - 0 } \\
&= \lim_{t \to x} \frac{ f(t) - f(x) }{ g(t) - g(x) } \\
&= \lim_{t \to x} \frac{ \frac{f(t) - f(x)}{t-x}}{ \frac{g(t)-g(x)}{t-x}} \\
&= \frac{\lim_{t \to x} \left(  \frac{f(t) - f(x)}{t-x} \right) }{ \lim_{t \to x} \left( \frac{g(t)-g(x)}{t-x} \right) } \\
&= \frac{f^\prime(x)}{g^\prime(x)}.
\end{align}
$$ Is this reasoning correct? If so, I reckon the above calculation is valid for complex as well as real functions $f$ and $g$. Am I right? I'm afraid we cannot resort to the Generalized Mean Value Theorem here even for real functions $f$ and $g$ because we have no information about the continuity of $f$ and $g$ in any interval containing $x$ or about the differentiability of these functions in a segment around $x$. Please refer to a questions of mine at Math SE at the following link. Any example of a function which is discontinuous at each point in a deleted neighborhood of a point at which that function is differentiable? Am I right?","['derivatives', 'real-analysis', 'calculus', 'analysis']"
2265907,Does this ring constructed from a group have an accepted name?,"Let $(G, +, 0)$ be a commutative group. Consider the set $R = G \times \mathbb{Z}$, equipped with the following operations:
\begin{align}
(g, m) + (h, n) &= (g + h, m + n) \\
(g, m)(h, n) &= (g + mh, mn)
\end{align}
It is easy to see that $R$ is a ring (in general non commutative) in which $(0, 0)$ is the zero and $(0,1)$ is the unit. Question . This construction is likely to be standard. Does it have an accepted name? Remark. I am not asking for a proof that $R$ is a ring, just a reference to the appropriate terminology. EDIT . The answer by rschwieb shows that $R$, as defined, is actually not a ring. He also gives the right definition as well as the appropriate terminology.","['terminology', 'ring-theory', 'group-theory']"
2265974,Find maximum and minimum value of inverse function .,We have to find maximum and minimum value of $x^2 +y^2$ My try how can I proceed,"['trigonometry', 'inverse-function']"
2266001,Evaluate $\lim\limits_{n \rightarrow \infty}\frac1{n^2}\sum\limits_{k=1}^n\sin\left (\frac{\pi k}n\right)\varphi(k)$,"Evaluate $$\lim_{n \rightarrow \infty}\frac{1}{n^2} \sum_{k=1}^{n}   \sin \left (\frac{\pi k}{n} \right)  \varphi(k)$$ where $\varphi$ denotes Euler's totient function. I first tried simplifying the sum $$\sum_{k=1}^{n}   \sin \left (\frac{\pi k}{n} \right)  \varphi(k)$$ by converting to exponentials: $\sin(x) = \dfrac{e^{ix}-e^{-ix}}{2i}$, so the sum is $$\sum_{k=1}^{n}   \sin \left (\frac{\pi k}{n} \right)  \varphi(k) = \sum_{k=1}^n \dfrac{e^{i \cdot \frac{\pi k}{n}}-e^{-i \cdot \frac{\pi k}{n}}}{2i} \varphi(k),$$ but I didn't see how to use this to simplify the sum. How can we calculate the limit?","['number-theory', 'real-analysis']"
2266019,"Prob. 8, Chap. 5, in Rudin's PMS, 3rd ed: If $f^\prime$ is continuous on $[a, b]$, then $f$ is uniformly differentiable on $[a,b]$","Here is Prob. 8, Chap. 5, in the book Principles of Mathematical Analysis by Walter Rudin, 3rd edition: Suppose $f^\prime$ is continuous on $[a, b]$ and $\varepsilon > 0$ . Prove that there exists $\delta > 0$ such that $$ \left\lvert \frac{f(t)-f(x)}{t-x} - f^\prime(x) \right\rvert < \varepsilon 
$$ whenever $0 < |t-x| < \delta$ , $a \leq x \leq b$ , $a \leq t \leq b$ . (This could be expressed by saying that $f$ is uniformly differentiable on $[a, b]$ if $f^\prime$ is continuous on $[a, b]$ .) Does this hold for vector-valued functions too? My Attempt: As $f^\prime$ is continuous on $[a, b]$ and as $[a, b]$ is compact, so $f^\prime$ is uniformly continuous on $[a, b]$ . So, for any real number $\varepsilon > 0$ , we can find a real number $\delta > 0$ such that $$ 
\left\lvert f^\prime(x) - f^\prime(y) \right\rvert < \varepsilon \tag{1} $$ for all $x, y \in [a, b]$ for which $\lvert x-y \rvert < \delta$ . Now suppose $a \leq t \leq b$ , $a \leq x \leq b$ , and $0 < \lvert t-x \rvert < \delta$ . Then by the Mean Value Theorem there is some point $y$ between $t$ and $x$ such that $$ f(t) - f(x) = (t-x) f^\prime(y), \tag{2} $$ and also $$ \lvert y-x \rvert < \lvert t-x \rvert  < \delta; \tag{3} $$ moreover, as $\lvert t-x\rvert > 0$ , so $t \neq x$ , and from (2) we can write $$
\frac{ f(t) - f(x)}{t-x} = f^\prime(y),$$ which together with (3) and (1) yields \begin{align}  
\left\lvert \frac{f(t)-f(x)}{t-x} - f^\prime(x) \right\rvert &= \left\lvert f^\prime(y) - f^\prime(x) \right\rvert \\ 
&< \varepsilon.
\end{align} Am I right? Now for vector-valued functions. Suppose $$\mathbf{f} = \left( f_1, \ldots, f_k \right) $$ be a mapping of $[a, b]$ into some $\mathbb{R}^k$ and suppose that $$ 
\mathbf{f}^\prime = \left( f_1^\prime, \ldots, f_k^\prime \right) 
$$ is continuous on $[a, b]$ . Then each of the component functions $f_1^\prime, \ldots, f_k^\prime$ is also continuous on $[a, b]$ . So, given any real number $\varepsilon > 0$ , we can find real numbers $\delta_i$ , for $i = 1, \ldots, k$ , such that $$
\left\lvert  \frac{ f_i(t) - f_i(x) }{ t-x } - f_i^\prime(x) \right\rvert  < \frac{ \varepsilon }{\sqrt{k}} $$ whenever $0 < \lvert t-x \rvert < \delta_i$ , $a \leq t \leq b$ , and $a \leq x \leq b$ . Now let $$\delta := \min \left\{ \delta_1, \ldots, \delta_k \right\}.$$ Therefore, If $a \leq t \leq b$ , $a \leq x \leq b$ , and $0 < \lvert t-x \rvert  < \delta$ , then for each $i = 1, \ldots, k$ , we obtain $0 < \lvert t-x \rvert < \delta_i$ and so $$
\left\lvert  \frac{ f_i(t) - f_i(x) }{ t-x } - f_i^\prime(x) \right\rvert < \frac{ \varepsilon }{\sqrt{k}}, $$ which then implies that \begin{align}
& \ \ \ \left\lvert  \frac{ \mathbf{f}(t) - \mathbf{f}(x) }{ t-x } - \mathbf{f}^\prime(x) \right\rvert \\ 
&= \left\lvert   \left( \frac{f_1(t) - f_1(x)}{t-x}, \ldots, \frac{f_k(t) - f_k(x) }{t-x} \right) - \left( f_1^\prime(x), \ldots, f_k^\prime(x) \right) \right\rvert  \\ 
&= \left\lvert \left( \frac{ f_1(t) - f_1(x)}{t-x} - f_1^\prime(x), \ldots, \frac{ f_k(t) - f_k(x)}{t-x} - f_k^\prime(x) \right) \right\rvert  \\
&= \sqrt{ \sum_{i=1}^k \left\lvert \frac{ f_i(t) - f_i(x)}{t-x} - f_i^\prime(x) \right\rvert^2 } \\
&< \sqrt{ \sum_{i=1}^k \frac{\varepsilon^2}{k} } \\
&= \varepsilon.
\end{align} Thus the above result holds for vector-valued functions as well. Am I right? Is my reasoning correct in each of the above two cases? If not, then where have I erred?","['derivatives', 'real-analysis', 'calculus', 'analysis']"
2266023,Question on invertibe function,In this I could not understand how they have written th first equation in the solution.,['functions']
2266030,"Polar form representation of $aX+bY+cZ$ ($X$, $Y$, and $Z$ are complex Gaussian random variable)","I need some help with the following problem: Let $X$, $Y$, and $Z$ are independent circularly symmetric complex Gaussian random variable with zero mean and unit variance, i.e., $X$, $Y$, and $Z \sim CN(0, 1)$. These random variables can be represented in polar form as 
  \begin{equation}
X=r_1 e^{i \alpha}\\
Y=r_2 e^{i \beta}\\
Z=r_3 e^{i \gamma}
\end{equation}
  where $r_1$, $r_2$ and $r_3$ are the magnitude (Rayleigh distributed) and $\alpha$, $\beta$ and $\gamma$ are the phase of the variables (Uniformly distributed over $[0, 2\pi]$). How can I represent the  random variable $aX+bY+cZ$ (where a,b, c are constant) in polar form as a function of the variables $a$, $b$, $c$, $r_1$, $r_2$, $r_3$, $\alpha$, $\beta$ and $\gamma$. Particularly I am interested to know the phase of $aX+bY+cZ$ in terms of these variables. Thank you very much","['polar-coordinates', 'normal-distribution', 'statistics', 'random-functions', 'random-variables']"
2266036,Integrals with fractions in exponentials,"I came across this integral in a research paper while trying to understand Bernstein's inequalities. I want to upper bound or evaluate this integral but it looks too complicated. The integral is:
\begin{align}
I=\int_0^\infty \exp \left ( \frac{-at^2}{bt+c} \right ) dt, \quad a,b,c >0.
\end{align}
Is there any procedure to upper bound the above integral? My attempt is to simplify the fraction so that I would get
$$
I= \int_0^\infty \exp \left ( \frac{-at}{b} + \frac{ac}{b} - \frac{ac^2}{b^3}\left(\frac{1}{t+c/b} \right)    \right) dt.
$$
But this doesn't seem too useful either. Any suggestions?","['improper-integrals', 'integration', 'definite-integrals', 'integral-inequality']"
2266079,Orthogonality relations for Legendre functions second kind,Does someone know the orthogonality relations for the associated Legendre functions of the second kind $Q_{n}^{m}(z)$? Are they the same as the orthogonality relations $\int{P_{n}^{m}(z) P_{j}^{k}(z) dz}=\frac{2(n+m)!}{(2n+1)(n-m)!} \delta_{jn} \delta_{km}$ for the associated Legendre functions of the first kind?,"['ordinary-differential-equations', 'calculus']"
2266086,"Complex differential geometry, complex algebraic geometry, and complex analytic geometry [closed]","Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 7 years ago . Improve this question From my limited understanding, complex differential geometry studies the differential geometry of complex manifolds, and complex algebraic geometry studies algebraic geometry where the underlying field is the field of complex numbers. I have come across the term complex analytic geometry in a number of places, and am puzzled as to exactly what study this refers to. What are the areas of geometry studied under complex analytic geometry? What are the relations between complex differential geometry, complex algebraic geometry, and complex analytic geometry?","['complex-geometry', 'differential-geometry', 'algebraic-geometry']"
2266095,When a module over a principal ring is free,"Let $R$ be a commutative, principal ideal ring that may have zero-divisors . Is there still a structure theory for the finitely-generated modules over $R$? In particular, I would like to know a condition that makes a finitely-generated $R$-module $M$ free. My guess is that this would be equivalent to $M$ not having ""too much torsion"", in the sense that a torsion element should only be annihilated by zero-divisors in $R$, but I am not sure whether such a condition is sufficient.","['abstract-algebra', 'ring-theory', 'modules', 'ideals']"
2266097,Solving the differential equation $y^{(4)} + 4y = 0$,"I have trouble solving the differential equation $y^{(4)} + 4y = 0$ This is a linear differential equation with constant coefficients. Solving for the roots of the associated polynomial gives: $$r^4 + 4r = 0 \iff r(r^3 + 4) = 0 \iff r(r+\sqrt[3]{4})(r^2 - \sqrt[3]{4}r + \sqrt[3]{4}^2) = 0$$ I get very ugly solutions for the roots of this quadratic equation. My book says the answer should be $$y = e^x(c_1\cos(x) + c_2\sin(x))+ e^{-x}(c_3\cos(x) + c_4\sin(x))$$ and wolfram alpha confirms this. But, in general, if $a + bi$ is a complex root of the polynomial of multiplicity $1$ then $e^{ax}(\cos(bx) + \sin(bx))$ will be a solution, so it seems I won't be able to reach that solution. Any help will be greatly appreciated!",['ordinary-differential-equations']
2266115,Find the asymptotic relative efficiency for two estimators from a Poisson family,"If two estimators $W_n$ and $V_n$ satisfy $$\sqrt n[W_n - \tau(\theta)] \rightarrow n[0,\sigma^2_W] \\ \sqrt n [V_n - \tau(\theta)] \rightarrow n[0, \sigma^2_V] $$ in distribution then the asymptotic relative efficiency (ARE) of $V_n$ with respect to $W_n$ is $$ ARE(V_n, W_n) = \frac{\sigma^2_W}{\sigma^2_V} .$$ Consider a random sample of size $n$ from a Poisson population with mean $\lambda$. I am asked to find the $ARE(\left(\frac{n-1}{n}\right)^{n \bar x}, e^{-\bar x})$ where $\left(\frac{n-1}{n}\right)^{n \bar x}$ is the uniformly minimum variance unbiased estimator of $e^{-\lambda}$ and $e^{-\bar x}$ is the maximum likelihood estimator of $e^{- \lambda}$ Its easy to see from the delta method that $$ \sqrt n[e^{-\bar x} -e^{- \lambda} ] \rightarrow n[0,\lambda e^{-2 \lambda}] $$ which takes care of finding the asymptotic variance of the MLE, $\sigma^2_{MLE} = \lambda e^{-2\lambda}$. 
But I run into a problem when trying to do the same for the UMVUE. First we note that $$ \sqrt n [\bar X - \lambda ] \rightarrow n[0, \lambda] $$ so by the delta method  $$ \sqrt n [g(\bar X) - g(\lambda) ] \rightarrow n[0,(g'(\lambda))^2 \lambda] .$$ If we let $ g(\lambda) = \left(\frac{n-1}{n}\right)^{n\lambda}$ then this implys that $$ \sqrt n \left[\left( \frac{n-1}{n} \right)^{n\bar x} - \left(\frac {n-1}{n} \right)^{n \lambda}\right] \rightarrow n\left[0, \lambda \left( \left(\frac{n-1}{n}\right)^{n \lambda} \ln{\left(\frac{n-1}{n} \right)^n} \right)^2 \right]. $$ I get the right answer is I use $\lambda \left( \left(\frac{n-1}{n}\right)^{n \lambda} \ln{\left(\frac{n-1}{n} \right)^n} \right)^2$ as the $\sigma^2_{UMVUE}$ but the condition was not met for the definiton of the ARE since the $\tau(\theta)$ my problem does not match like it requires in the definition of the ARE. However I noticed that $\left(\frac{n-1}{n} \right)^{n\lambda} \rightarrow e^{- \lambda}$ so I was wondering if that is good enough or is there another step that I need to take.","['statistics', 'convergence-divergence']"
2266142,The canonical map from the group algebra to the set of endomorphism of a vector space is surjective,"Let $G$ be a finite group. Suppose $\pi:G \rightarrow GL(V)$ be an irreducible representation of $G$. This representation gives a canonical map
$$\tilde{\pi}: \mathbb{C}[G] \rightarrow End(V)$$ where End(V) denotes the set of linear maps on $V$. Prove that $\tilde{\pi}$ is surjective.
I have no clue about the solution. There is a hint given that if we consider on the contrary that $\tilde{\pi}$ is not surjective we will get a linear functional on $End(V)$ which is zero on the image of $\tilde{\pi}$, which will contradict some kind of orthogonality relation. I have no idea where this hint leads to. I also don't have any other idea to solve. A little help will be appreciated. Thanks in advance!!!!","['finite-groups', 'abstract-algebra', 'representation-theory']"
2266159,Convergence of $\sum\limits_{k=0}^\infty {\binom{z}{k}} $ for complex $z$,"For what complex values of $z$ does the following sum converge? $$\sum_{k=0}^\infty {\frac{z(z-1)\cdots(z-k+1)}{k!}} $$ And how would you prove it? Mathematica seems to suggest the sum converges as long as $\Re(z) \ge 0$ , regardless of the imaginary part.  Is that right?","['complex-analysis', 'binomial-coefficients', 'sequences-and-series', 'convergence-divergence']"
2266172,Does the sum of three vectors originating from the centroid of a triangle and pointing to the angles always sum to zero?,"Consider an equilateral triangle as the one given in the figure below: Assume $$\vec{E_1},\vec{E_2},\vec{E_3}$$ are vectors (for instance complex numbers in the complex plane) originating from the centroid (N) and pointing each one to their respective angle (each vector is parallel to a median). For an equilateral triangle, the property (property 1): $$\vec{E_1}+\vec{E_2}+\vec{E_3}=0 $$ holds true. Now consider a generic triangle where the three vectors still originate at the centroid (N). My question is: is the above property (property 1) still true for a generic triangle? Additional information: this question is related to an electrotechnical problem and to a question I originally asked on Electronics SE. As far as my understanding goes, this geometrical property is the key to answering the electrotechnical question , therefore I thought it could be appropriate to ask it here. If you wish to know more about the original question please let me know.","['triangles', 'vectors', 'geometry']"
2266184,Prove that $f$ is an Affine function,"Definition: An affine function is a function composed of a linear function + a constant and its graph is a straight line. A topological space $X$ is said to be disconnected if it is the union of two disjoint nonempty open sets. Otherwise, $X$ is said to be connected. Question: Assume that $U \subseteq \mathbb R^n$ is a connected set and $f : U
 \to \mathbb R^m$ is a function such that we have $\forall x \in U
 \quad Df(x)=A$   Such that $A: \mathbb R^n \to \mathbb R^m$ is a
  linear transformation. Prove that $f$ is an Affine function. Note: We just know that the derivative is a linear transformation. I know that its like the case of working with normal derivaties in $\mathbb R$. But, It's not the same. I can't for example do integration! Any idea on reaching the statement?  (Please include more details so that i can understand it)","['multivariable-calculus', 'derivatives']"
2266191,Putting $m$ balls in $n$ limited-boxes.,Today I was thinking about this problem: I have $n\geq2$ boxes and $m\geq1$ balls. I know that the $i-$th box can contain at most $l_i\geq1$ balls and moreover I know that $l_1+\dots+l_n=2m.$ I want to compute the possible different combination in which I can fill the boxes. Is it possible? Can we at least find a rasonable lower bound? (for example when $m$ is big).,"['combinations', 'combinatorics', 'combinatorial-game-theory']"
2266227,Solving math captcha involving a limit and $\sin(1/x)$,"The other day, while I was accessing a Russian math enthusiast web site, I came across this captcha: Can you help me make sense of it, and enter that site?","['recreational-mathematics', 'limits']"
2266246,Translational Invariance of a Sigma Algebra.,"There are several questions relating to this topic, but these tend to be about Borel $\sigma$-algebras or the generators of $\sigma$-algebras. I would instead like this question to be answered using the following definition; Let $X$ be a set. A collection $\Sigma$ of subsets of $X$ is called a sigma-algebra if 1) $\emptyset \in \Sigma$; 2) $E \in \sigma$ implies $X\setminus E \in \Sigma  $; 3) $E_n \in \Sigma, n\geq 1$ implies $\cup^{\infty}_{n=1}E_n \in \Sigma$. My question is this: Let $X = \mathbb{R}$ and let $x \in R$ be a fixed number. Prove that the collection of sets $\{A+x : A \in \Sigma \}$, denoted $\Sigma + x$, is a sigma-algebra of subsets of $\mathbb{R}$. Here $A+x=\{a+x: a\in A \}$. The first criterion of the definition seems quite straightforward, but I am struggling with the other two.","['borel-sets', 'real-analysis', 'measure-theory']"
2266247,Prove that the Christoffel symbols vanish in $\mathbb{R}^n$,"Recently I started reading about connections (covariant derivatives), and one of the first exercises I encountered is the proof of  ${\Gamma^k_{ij}}=0$, in $\mathbb{R}^n$. My handout though doesn't mention what's the natural connection $\mathbb{R}^n$ is endowed with, hence I cannot understand why Christoffel symbols vanish. Can you explain me what is going on please, and how do we prove the above?","['connections', 'riemannian-geometry', 'differential-geometry']"
2266263,Prime Number Congruence Conjecture,"$6±1 = (5,7)$ 5 and 7 are twin primes $6 + 5 = 11$ $6 + 7 = 13$ 11 and 13 are twin primes $ 6 × 5 = 30 $ $ 6 × 7 = 42 $ 30 and 42 are adjacent to the twin primes (29. 31) and (41, 43) Is there any other multiple of 6 that is between twin primes (5,7),  produces this same pattern of primes in the sums (11, 13) and primes adjacent to its products (29. 31) and (41, 43)? If so, how often does it occur? Disclaimer: I don't know the mathematics necessary to figure it out on my own. I'm asking out of innocent curiosity.","['number-theory', 'twin-primes', 'prime-numbers', 'discrete-mathematics']"
2266266,Probability of $n$ heads if coin is flipped until 8 tails.,"Suppose a fair coin is flipped until 8 tails occur. Let X be the number of heads that appear. What is the probability mass function of X? I answered ${n- 1 \choose 7}*(0.5)^n$, since it is a negative binomial random variable but this got marked wrong. I don't see how to get to any other answer. Any help is appreciated!","['combinatorics', 'statistics', 'probability']"
2266285,Expected Entropy Based on Dirichlet Distribution,"The Dirichlet Distribution basically defines the probability that a sample came from a particular multinomial distribution if we assume that the prior probability of all multinomial distributions having generated the sample are equal. Each multinomial distribution has a corresponding categorical distribution, and the entropy of that categorical distribution is given by $$-\sum_x^{states}\Pr(x)\ln(\Pr(x))$$ Given a point $p=(p_1,p_2,p_3...p_n)$ randomly chosen according to a Dirichlet Distribution with parameters $k_1...k_n$, such that $\sum_ip_i=1$, the entropy of the corresponding categorical distribution is: $$H(p)=-\sum_i^n p_i \ln(p_i)$$ What the expected value of $\text H(p)$? In the special case where the Dirichlet Distribution is just defined by $k_1$ and $k_2$ and $p$ is 2-dimensional, the expected entropy $\text{H}(p)$ is given by the formula 
$$\frac{(k_1+k_2) H_{(k_1+k_2-1)}-k_1 H_{k_1}-k_2 H_{(k_2-1)}}{k_1+k_2}$$ Where $H_n$ is the $n$th harmonic number, however I haven't been able to calculate the answer for greater numbers of dimensions.","['information-theory', 'entropy', 'probability']"
2266309,Is $1-\zeta_n$ a unit in every ring where $n$ is invertible?,"Let $R$ be a commutative ring where $n\ge 2$ is invertible and containing a primitive $n$th root of 1, called $\zeta_n$, satisfying $\zeta_n^n = 1$ and $\zeta_n^k\ne 1$ for any $1\le k\le n$. Is $1-\zeta_n$ invertible on $R$? Thanks to Hurkyl's excellent point, one can consider the counterexample $k[t]/(t^2-1)$, where $t$ is a primitive square root of 1, but $t-1$ is a zero divisor, hence not a unit. In this example, my impression is that you get two connected components of $\text{Spec }k[t]/(t^2-1)$, where on one of them $t = 1$, and on the other $t = -1$. Thus, we have the follow up question: If $R$ is a local ring, must $1-\zeta_n$ be invertible on $R$? Also I don't really understand why this was put on hold. The question was apparently clear enough to garner short and yet valuable answers.",['abstract-algebra']
2266326,Creating a function F(x) such that all outputs exist between -5 and 5,"Take this sample graph illustration: As $X$ approaches negative infinity the output approaches $-5$ As $X$ approaches positive infinity the output approaches $5$ From what I recall this would be leveraging $\log, \ln$ or $e$ but I'm failing to remember the specific principles involved to come up with this function. Other things that would be nice for this function is that it accelerates very quickly from the origin and tapers off which I tried to illustrate. Bring this back to the real world and not just conceptual, realistic values of $X$ will primarily exist between $-10,10$ and much less frequently $-20,20$ and $-50,50$. My goal is to produce scoring algorithm with constrained limits on the output of the score. The simpler the function, the better. This function seems to be very close to what I'm looking for: $5*\frac{x}{1+|x|}$ The graph it produces is: At $F(5)$ and $F(-5)$ the graph is approximately 4 and -4. How can I stretch out this function that $F(10)$ and $F(-10)$ are roughly 4 and -4 instead? Able to answer this question myself, replace $X$ with $0.5X$",['functions']
2266343,Associating a prime ideal to a cotangent subspace in a complex variety,"This is a weakened alternative to a question that was answered here Let $X$ be a complex, smooth, projective variety. Let $x$ be a (closed) point, $A=\text{Spec}R$ an affine chart for $x$ and $V\subseteq T_x^*X=\mathfrak{m}/\mathfrak{m}^2$ a vector subspace, where $\mathfrak{m}\subseteq R$ is a maximal ideal naturally associated to $x$. If I'm given a basis $v_1,\dots,v_r$ of $V$ and an ideal $I=\langle p_1,\dots,p_r\rangle$ generated by representatives $p_i\in \mathfrak{m}$ of the basis (i.e. $v_i\equiv p_i\mod\mathfrak{m}^2$), can I find a prime ideal $J$, such that $I\subseteq J\subseteq \mathfrak{m}$ and $J\mod\mathfrak{m}^2=V$? Observation : as observed by MooS these two conditions are equivalent to having a prime $J$ between $I$ and $I+\mathfrak{m}^2$. If necessary, the $p1,\dots,p_r$ may be assumed irreducible.","['algebraic-geometry', 'commutative-algebra']"
2266379,Is there a general solution to $a^x + b^x =c^x$ for $x\in\mathbb{R}$?,"I found this question online: Solve for $x$, given $6^x + 4^x =9^x$. A straighforward but  unsatisfactory estimation can be obtained by graphing the two lines (on Desmos, say) and reading out the result of the intersection. Is there a more beautiful solution to this equation that one can arrive at without a graphing calculator? And is there a general solution to $a^x + b^x =c^x$ for $x\in\mathbb{R}$ and $a, b, c \in\mathbb{N}$?","['puzzle', 'functions']"
2266395,A floor function appeared after integration. What happended?,"I have laplace's equation, $\nabla^2f=0$, inside a circle (radius $a$) for which the boundary condition (polar coordinates) is $$
f(a,\phi) =
\begin{cases}
1\quad \text{for $0< \phi < \pi/2$}\\
-1\quad \text{for $-\pi < \phi < -\pi/2$}\\
0\quad \text{otherwise}
\end{cases}
$$ I went to solve it using the formula (for $r<a$):
$$
f(r,\phi) = \frac{a^2 - r^2}{2\pi} \int^\pi_{-\pi} \frac{f(a,\phi)}{a^2 + r^2 - 2ar \cos(\phi-t)}dt
$$ $$
f(r,\phi) = \frac{a^2 - r^2}{2\pi} \left[ \int^{-\pi/2}_{-\pi} \frac{-1}{a^2 + r^2 - 2ar \cos(\phi-t)}dt + \int^{\pi/2}_{0} \frac{1}{a^2 + r^2 - 2ar \cos(\phi-t)}dt\right]
$$ By using the universal trigonometric substitution , I arrived at
$$
f(r,\phi) = \frac{1}{\pi}\left[h\left(r,\phi,\frac{-\pi}{2}\right) - h\left(r,\phi,-\pi\right) - h\left(r,\phi,\frac{\pi}{2}\right) + h\left(r,\phi,0\right)\right]
$$ Where
$$
h(r,\phi,t) = \arctan\left(\frac{a+r}{a-r} \tan\left(\frac{\phi - t}{2}\right)\right)
$$ Which agrees with wolfram alpha's result . But then the plotting for various values of $r$ gave me When I did the symbolic integration using a hp 50g calculator, a $floor$ function appeared adding to $h$. $$
g(r,\phi,t) = h(r,\phi,t) + \pi\, \text{floor} \left( \frac{\phi-t}{2\pi} +\frac{1}{2} \right)
$$ The final result being $$
f(r,\phi) = \frac{1}{\pi}\left[g\left(r,\phi,\frac{-\pi}{2}\right) - g\left(r,\phi,-\pi\right) - g\left(r,\phi,\frac{\pi}{2}\right) + g\left(r,\phi,0\right)\right]
$$ Which plotting gave me the expected result Now I cannot understand what happenned. Why and how did (must) that floor function appear?","['integration', 'definite-integrals', 'calculus']"
2266401,Differential of complex function,"I understand how to find the derivative, but how should I find the differential of a complex function?",['complex-analysis']
2266405,Show $\frac{m}{12} \le \int_0^1 xf(x)dx \le \frac{M}{12}$,"Given: $f'$ is continuous on $[0,1]$ $\int_0^1 f(x)dx=0$ $m \le f' \le M$, where $m$ is minimum and $M$ is maximum of $f$ on $[0,1]$ Show: $$\frac{m}{12} \le \int_0^1 xf(x)dx \le \frac{M}{12}$$ Thoughts: I believe that we want to somehow use the mean value theorem, along with part 3, in order to solve this. I also think that we want to use integration by parts, but I'm not necessarily sure how. I think we want a product of two functions that is equal to $f'(x)$ (so maybe $1$ and $f'(x)$?), but I'm not sure about that. Any help would be appreciated - I'm happy to provide clarification!","['real-analysis', 'integration']"
2266422,Computing the exact value of $\sum_{n=1}^\infty \left(\frac{2n+3}{3n+2}\right)^n$,"I found this problem in my textbook, and I know that it converges, but I wanted to know if there was a way to find the exact value of the convergence (similar to what Euler did with the sum of reciprocal squares). I tried to rewrite the sum as a power series of sorts, but I don't know if it's correct, or if it made anything more complicated. Steps: $$\lim\limits_{a \to \infty} \sum_{n=1}^a \Big(\frac{2n+3}{3n+2}\Big)^n=\lim\limits_{a \to \infty} \sum_{n=1}^a \Big(\frac{2}{3} + \frac{5/3}{3n+2} \Big)^n =\lim\limits_{a \to \infty} \sum_{n=1}^a \Big(\frac{1}{3}\Big)^n\Big(2+\frac{5}{3n+2}\Big)^n$$
$$=\lim\limits_{a \to \infty} \sum_{n=1}^a \Big(\frac{1}{3}\Big)^n \sum_{m=0}^n 2^{n-m}\Big(\frac{5}{3n+2}\Big)^m \binom{n}{m}= \lim\limits_{a \to \infty} \sum_{n=1}^a \Big(\frac{2}{3}\Big)^n \sum_{m=0}^n \Big(\frac{5}{2(3n+2)}\Big)^m \binom{n}{m}$$
$$=\lim\limits_{a \to \infty}\sum_{n=1}^a \Big(\frac{2}{3}\Big)^n \sum_{m=0}^n\Big(\frac{5}{6n+4}\Big)^m \binom{n}{m}$$
I hit a wall here because I am not sure what do with the double sum part of the problem. (Note: I made the top limit of the outer sum $a$, and took the limit as $\,$$a\to\infty$$\,$ because when I tried to make a table to evaluate the double sum, I wanted to use something finite in order to get a finite answer.) EDIT: Is there an explicit formula if $a$ does not approach $\infty$?",['calculus']
2266428,Rotation of 3 lines in 3D space,"I hope you can help me with a mathematical problem I'm trying to solve (for many days) and so far no success. Given 2 sets P=[p_1,p_2,p_3] and Q=[q_1,q_2,q_3] of 3 infinite lines each in 3D space (each p_i and q_i (i=1,2,3) is a 3D line represented by a 3D point and a unit vector). so overall we have 6 lines. I need to find a rotation matrix R (3x3) so that if I rotate all the lines in P by R then I get new lines P_rotate=[p_1_rotate, p_2_rotate, p_3_rotate] so that p_i_rotate and q_i (i=1,2,3) intersect each other. I know there might not be such a rotation matrix and in some cases there might be infinite rotation matrices (for example if all the 6 lines are on the same plane and the axis of rotation is perpendicular to that plane). but the assumption here that for sure there exists such a rotation matrix and if there are more than one, then I can choose any of them. This is what I tried to do so far: It's actually solving 3 equations of 3 variables (the variables are the 3 angles around the axises x,y,z).
but the equations were extremely complex that I couldn't solve them (and I'm not even sure they are solvable).
You can calculate the rotated lines as a function of the 3 angles. meaning each rotated line will contain a new point and a new vector both as a function of the 3 angles. then I calculate for each line the distance to the relevant line in Q. and I need to find for which angles the 3 distances are zero. I assumed here that first I rotate around Z axis, then around Y axis and then around X axis. I think the order doesn't matter since whatever order I choose I may get different angles but the final rotation matrix will be the same.
Anyway, the final 3 equations were extremely long and with many multiplications of the unknown variables so it was actually impossible for me to solve them. I also tried to solve it in a different way. not using rotation matrix. but Rodrigues' rotation formula. in Rodrigues' formula I rotate around an axis line that passes through the origin by an angle theta. so I actually need to find v_x,v_y,theta where v_x, v_y are the x and y components of a unit vector of the axis line (v_z can be calculated by v_x and v_y since the vector is unit). and theta is an angle of rotation around this axis. again, I got 3 very long and complex equations that I couldn't solve. Anyone has any idea of how to solve it? or can refer me to a link that (hopefully) explains about it?
Will appreciate any help! Thank you David","['rotations', 'calculus', 'geometry']"
2266463,Elementary Doubt about Differential Forms and wedge product,"I'm working through Browder's Mathematical Analysis ( http://www.springer.com/in/book/9780387946146 ) and am having a bit of trouble being convinced by one of his definitions. On Page 288, for Definition 13.5, he says: 
Let $\omega_0 = dx^1 \wedge \dots \wedge dx^n$; for each $j, 1\leq j \leq n$, we put 
$$\eta^j = (-1)^j dx^1 \wedge dx^{j-1} \wedge dx^{j+1} \dots \wedge dx^n$$ The $(-1)^j$ is justified so that $dx^j \wedge \eta^j = \omega_0$. My doubt is that: Shouldn't it be  $(-1)^{j-1}$ ? I test Browder's definition with the $j =1, 2$ cases to get: 
$$dx^1 \wedge (-1)^1 dx^2\wedge \dots \wedge dx^n = -\omega_0 $$ and 
$$dx^2 \wedge (-1)^2 dx^1\wedge dx^3 \wedge \dots \wedge dx^n = -\omega_0$$ Each time, I swap positions of $dx^i$s, I multiply by $(-1)$. In the first case, no swapping was required and in the second case, one swap was required. Essentially, what I'm asserting is that in the general case, $j-1$ swaps are required so why are we multiplying the $\eta^j$ expression by $(-1)^j$  instead of $(-1)^{j-1}$?","['multivariable-calculus', 'differential-forms', 'differential-geometry', 'analysis']"
2266493,Version of identity theorem for functions in $\mathbb{R}^n$,"How to show the following version of the identity theorem for real-analytic function in $\mathbb{R}^n$ Let $g,f: \mathbb{R}^n \to \mathbb{R}$ be two real-analytic functions.
  Suppose, that $g(x)=f(x)$ on a set $E$ of positive Lebesgue measure.
  Then, $f(x)=g(x)$ for all $x \in \mathbb{R}^n$. Also, providing a reference for this would great. The question was first raised here and motivated by identity theorem on open sets. Where the case of $n=1$ was also solved. It was suggested that the case of $n>1$ can be solved by using induction. However, I was not able to follow the proof. Since one can come up with a number of identity theorems for analytic function in $\mathbb{R}^n$, I was wondering if there is a good source that summarizes these result. I found one for complex analytic functions here , but I don't think it is very complete.","['functional-analysis', 'complex-analysis', 'real-analysis']"
2266511,Residue of $e^{1/z(z-1)}$ at $z=0$,"How can I calculate the residue of $f(z) = e^{\frac{1}{z(z-1)}}$ at $z=0$? I can't just expand it formally in powers of $z$ like this
$$
e^{1/z(z-1)} = e^{1/z + 1 + z + \ldots} = 1 + \left(\frac1z + 1 + z + \ldots\right) + \frac12 \left( \frac1z + 1 + z + \ldots \right)^2 + \ldots
$$
and calculate the sum of the series of coefficients before $z^{-1}$ (or can I?). Even if it's valid it's not so easy. Also I thought about that finding that residue is about finding the integral of $f$ over the circle around $0$ with radius less than $1$: $\int_{R=\frac12} f(z) dz$. If I'd make a change of a variable $z = \frac1w$ it would become $\int_{R=2} \frac{1}{w^2} e^{\frac{w^2}{1-w^2}} dw$. The integrand is holomorphic in $\{z \in \mathbb C : |z| > 1\}$ so we just need to calculate the residue at $\infty$. But that looks too complex too.","['complex-analysis', 'residue-calculus']"
2266541,Explicit nontrivial examples of arc length parametrization,"For pedagogical purposes (and for some numerical experiments) I was looking for some nontrivial explicit (i.e. closed-form) examples of arclength parametrized curves. I know that arclength parametrization always exists for a regular curve, but it seems that the general consensus is that trying to compute this explicitly is generally madness. Of course any straight line and circular arc can be explicitly parametrized this way, but I was wondering if there are any other known nontrivial examples (especially ones with nonconstant curvature)?","['examples-counterexamples', 'arc-length', 'multivariable-calculus', 'parametric', 'geometry']"
2266550,Show that $\lim_{n\rightarrow\infty}\int_{0}^{\infty}\frac{x^{\frac{1}{n}}}{(1+\frac{x}{n})^{n}}dx=1.$,"Show that 
$$\lim_{n\rightarrow\infty}\int_{0}^{\infty}\frac{x^{\frac{1}{n}}}{(1+\frac{x}{n})^{n}}dx=1.$$ Remark: I must accept that I have a conflict when I am faced with a situation where I must know the relationship between Integrals of Riemann and Integrals of Lebesgue, the conflict is stronger when integrals are improper.
Most books address this relationship for integrals over intervals of the form $ [a, b] $, but very few address improper integrals. I would like to know the proof of the problem that I have proposed and that someone recommend me books where they propose exercises similar to the one I have proposed here.","['improper-integrals', 'lebesgue-integral', 'measure-theory', 'limits']"
2266567,How many four digit numbers divisible by 29 have the sum of their digits 29?,"How many four digit numbers divisible by $29$ have the sum of their digits $29$? A way to do it would be to write $1000a+100b+10c+d=29m$ and $a+b+c+d=29$ and then form equations like $14a+13b+10c+d=29m'$ and eventually $4a + 3b – 9d = 29 (m'' – 9)$. Analysing this equation for integer solutions using the advantage we have $\to$ $29$ is a prime; will give the solutions, but is tedious work. Are there better solutions?","['number-theory', 'combinatorics', 'elementary-number-theory']"
2266593,"Factoring real polynomials with no real zeros, and other polys whose zeros come in pairs","Of course a polynomial of degree at most $4$ may ""easily"" be factored .  And for a polynomial of degree $5$ or greater, no algebraic formula for the roots need exist.  What about when the zeros of the polynomial are known to come in conjugate pairs:  Suppose that $p(z)$ is a real polynomial (ie $p(t)\in\mathbb{R}$ for all $t\in\mathbb{R}$), but $p$ is non-zero on $\mathbb{R}$ (so that the zeros of $p$ come in conjugate pairs).  If $\deg(p)=8$ (or $6$), can the quartic (or cubic) formulas be used to find the zeros of $p$? Second and related question: suppose that $q$ has no zeros on the unit circle $\mathbb{T}$, and it is known that the zeros of $q$ are conjugate symmetric across the unit circle.  (Note, this is the case for the numerator of the derivative of a finite Blaschke product, and this is in fact the motivation for the first question as well.)  If $\deg(q)\leq8$, can $q$ be factored somehow using the quartic formula?","['complex-analysis', 'roots', 'polynomials', 'factoring']"
2266600,Finding the number of distinct extrema of polynomial.,"I want to find the number of possible $c \in \mathbb R$ such that the polynomial $$ f(x) = x(x+1)(x+2)\dots(x+2011) - c $$ has a double root ( root of multiplicity 2 ). I know that this corresponds to finding the number of distinct values of extrema of the function $$ g(x)= x(x+1)(x+2)\dots(x+2011) $$ after which I must set $c$ to be equal to the value of the extrema. I thought of using the symmetry about the point $x=-1005.5$ to show that (apart from the central extremum), distinct values of extrema occur in pairs. What remains to prove is that apart from symmetric pairs, all critical points have distinct values of $f(x)$ I have looked at the polynomials $x(x+1)(x+2)(x+3)$ and $x(x+1)(x+2)(x+3)(x+4)(x+5)$ and they seem to agree with my hypothesis but I am unable to prove it for the general case $$ P(x) = x(x+1)(x+2)(x+3)\dots (x+2k+1) $$","['polynomials', 'optimization', 'roots', 'combinatorics', 'graphing-functions']"
2266641,"What mistake is in my ""proof"" that the set of all subsets of R with lebesgue measure 1 has a maximal element?","I apologize in advance if the mistake is trivial. But I'm simply not seeing it. I must have misunderstood something along the way. The idea follows: Let $K = \{E \subset \mathbb{R} | m(E) = 1\}$, where m is the Lebesgue measure. Now, let's define the following order in $K$. We say that $A < B$ iff $B \subseteq A$. This is obviously a partial order. Now, let $(A_i)$ be any chain. (i.e. $A_i < A_{i+1}$) Let $A = \bigcap A_i$. Clearly $A > A_i$ for all $i$. Also $A_i \searrow A$, and $m(A_i) < \infty$ for all i. Then applying a Corollary we have that $m(A) = \lim_{n\rightarrow \infty} m(A_i) = 1$, and therefore $A \in K$ Therefore, every chain in $K$ has an upper bound in $K$. Using Zorn's Lemma, we conclude that $K$ has a maximal element. But this conclusion seems absolutely absurd to me. In fact, take any candidate $X$ to being a maximal element. Clearly $X$ is non empty. Let $x \in X$. Now $X - \{x\} \in K$ and $X < X - \{x\}$. I believe that my mistake is that, to be able to use the corollary, it is necessary that $A$ be measurable. What went wrong here? Thank you very much!","['lebesgue-measure', 'measure-theory']"
2266680,How to test if $\sum_{n=1}^{\infty }\frac{1}{n^{1+\frac{1}{n}}}$ converges?,How to test whether $\sum_{n=1}^{\infty }\frac{1}{n^{1+\frac{1}{n}}}$ diverges or converges? Can I apply ratio test? Thanks in advance.,"['convergence-divergence', 'sequences-and-series', 'calculus']"
2266685,Geometric Without Replacement?,"Is there a probability distribution corresponding to a geometric distribution without replacement? By this I mean the idea of the time until the first success, but with dependent rather than independent events? For example, the time it takes until you draw a spade from a standard deck of $52$ cards? Or if you have $5$ red and $5$ blue marbles in an urn, the time it takes until you draw a blue marble? Is this just the hypergeometric distribution? I am inclined to say no because the hypergeometric distribution specifies the number of samples.","['probability', 'probability-distributions']"
2266686,Are the principal components in the SVD of a symmetric matrix also symmetric?,"If we have a symmetric matrix $A$ and compute its singular value decomposition $A=U\Sigma V^T$, is it the case that $U$ and $V$ are also symmetric? I know that $U$ and $V$ must be equal since they are the singular vectors of $A$.","['matrices', 'svd', 'symmetric-matrices', 'singular-values', 'linear-algebra']"
2266693,"If the average age decreased by 6 months, calculate the average age of new students","The average age of 12 students in exam hall is decreased by 6 months, when two of them aged 13 years and 15 years are replaced by two new students. The average age of new students is ? I am not able to solve this problem and I am facing little ambiguity for solving, how the age will be decreased by six months? Any help appreciated please","['algebra-precalculus', 'word-problem', 'average']"
2266709,Is $ \lim_{n \to \infty} a_n ^{b_n} = e^{\lim_{n \to \infty}(a_n - 1)b_n}$ always true?,"Consider $a_n$ and $b_n$ are two sequences which $\lim _{n \to \infty} a_n  = 1$ and $\lim _{n \to \infty} b_n  = \infty$ . Can we always use this formula ? $$ \lim_{n \to \infty} a_n ^{b_n} = e^{\lim_{n \to \infty}(a_n - 1)b_n}$$ Also, when can we use this method for functions ? A famous case is $a_n = 1+ \frac{1}{n}$ and $b_n = n$ . So $\lim_{n \to \infty}(a_n - 1)b_n = 1$ and $a_n ^{b^n} = e^1 = e$","['limits-without-lhopital', 'limits']"
2266717,Smoothness of algebraic varieties: is there a finite type $k$-(group)scheme (variety?) $X$ without a regular point?,"Recall that $x$ is regular point if the local ring $\mathcal{O}_{x}$ is a regular local ring. I ask because secretly I'm thinking $X_k=G$ is an algebraic group over $k$, so that the existence one regular point, by homogeneity, implies all points are regular (justifying the name variety). Not being well versed in modern AG, I'm having trouble interpolating between the approaches of classical varieties over algebraically closed fields and the scheme theoretic approach taken, for example, in these notes. For a  classical variety $V$ over $k$ (so $k$ is algebraically closed) one shows that the set of regular points is an open dense subset of $V$, hence if one defines an algebraic group on top of this structure it is automatically smooth. However, in the aforementioned notes, they (sec.1 pgs 3-4) define an algebraic group as a finite type $k$-scheme with the added condition of smoothness, where $x$ is a smooth point iff $\mathcal{O}_{{X_{\overline{k}}} ,x}$ is regular, and $X_{\overline{k}}$ is base change to $\overline{k}$. From the notes: Let $G$ be a $k$-group scheme [of finite type]. The group $G(\overline{k})$
  acts on $G_{\overline{k}}$ by translation. Now $G$ is smooth if and only if the local
  rings of $G_k$ are regular, and over an algebraically closed field it is
  enough to check smoothness at the classical points $G_{\overline{k}}(\overline{k}) = G(\overline{k})$. But
  by commutative algebra plus the aforementioned “homogeneity”, it is
  thus enough to check that the completed local ring $\mathcal{O}_{G_{\overline{k}},e}$ is regular. So my question is: if it's enough to check regularity at classical points, why isn't smoothness immediate? In sections $6$ and $7$ of the notes, a lot of work is put into showing the equivalence between ($\mathcal{O}_{G_{\overline{k}},e}$ is regular) $\iff$ (Grothendieck's infinitesimal criterion for smoothness) which is then put to use to show smoothness of some classical groups like $G=Sp_{2n}$, which amounts to computing the tangent space at $e$ (kernel of $G(k[\epsilon]) \to G(k)$ where $\epsilon^2=0$), and showing the dimension of the tangent space equals the Krull dimension of $G$. This seems like a lot of work for something we get for free with classical varieties, what exactly prevents us from reproducing the density of regular points on scheme theoretic varieties? If it is an issue with the ground field, could I avoid all this work if I just assumed $k$ to be a perfect field or characteristic $0$? i.e. is this lemma from Stacks enough? I'm not sure because the lemma requires varieties to be reduced, so I'm not sure how all these subtly different definitions play out. If that lemma fails for non-perfect ground fields, I would still be interested in seeing an example of a finite type group scheme over $k$ without regular points, i.e. a non-smooth group, or a scheme $X$ in general.","['schemes', 'algebraic-groups', 'group-schemes', 'algebraic-geometry']"
2266750,Let $A$ be a $5 \times 5$ matrix such that $A^2=0$. Then how to compute the maximum rank for such A?,"Attempt : Suppose $A$ has a non-zero eigenvalue $\lambda$. Then corresponding to it's non-zero eigen vector $X$, we have $AX=\lambda X \Rightarrow A^2X=\lambda^2 X\Rightarrow 0=\lambda^2 X$. Which is a contradiction. Hence $\lambda=0$ with algebraic multiplicity $5$. Looking at all the Jordan normal forms $J$ of $A$, I found one $J$ which gives $J^2=0$ whose $\text {Rank} J=2$. (There is other Jordan normal form with rank$=1$) Here is that J := $$J = 
        \begin{pmatrix}
        0 & 1 & 0 & 0 & 0 \\
        0 & 0 & 0 & 0 & 0 \\
        0 & 0 & 0 & 1 & 0 \\
        0 & 0 & 0 & 0 & 0 \\
        0 & 0 & 0 & 0 & 0 \\
        \end{pmatrix}
$$ I found that Jordan normal forms with ranks $3,4$ don't satisfy $J^2=0$.
So the least upper bound for the rank is $2$. Is my attempt correct? Thanks.","['jordan-normal-form', 'matrices', 'proof-verification', 'matrix-rank', 'linear-algebra']"
2266800,"If elements of matrix are bounded, its determinant is bounded","If absolute values of all elements of $n \times n$ matrix A are less than 1,
  $|\det(A)| \leq n ^ {n/2}$ It's proved by induction by n. Base is obvious, and transition is the following: consider the $n \times n$ matrix A'. Let the elements from the first row be $a_0, ..., a_{n-1}$. Then $\det(A') = \Sigma_{i=0}^{n-1} (-1)^{i} a_i \det(A_i)$, where $A_i$ are the matrices obtained from $A'$ by deleting the $i$th column and the first row. $\forall A_i \det(A_i) \leq (n-1)^{(n-1)/2}$. So  $\det(A') = \Sigma_{i=0}^{n-1} (-1)^{i} a_i \det(A_i) \leq \Sigma_{i=0}^{n-1} a_i (n-1)^{(n-1)/2} \leq n(n-1)^{(n-1)/2}.$ The last step is to prove that $\forall n \geq 2$ it's true that $n(n-1)^{(n-1)/2} \leq n^{n/2} $. Here I am stuck. I've plotted it and it is true, but I have no idea how to prove it strictly. And maybe a more elegant solution exists? Induction is quite boring.","['matrices', 'induction', 'linear-algebra']"
2266804,Category theory and statistics,"I've been juggling with some concepts from statistics revolving around properties of estimators and sufficient statistics, and I can't help but notice that they have a strong categorical flavor, e.g. I'm pretty sure minimal sufficient statistics are terminal objects in an appropriate category. I know someone must have worked these things out but haven't been able to find it - I'd be grateful if someone could give me a pointer to some illuminating discussion of applications of category theory to statistics.","['category-theory', 'reference-request', 'statistics']"
2266827,Tricky Double integral over a union of two regions.,"Problem: Evaluate the integral, $$\int \int_D xydA$$ where $D$ is the union region shown below: I have solved the problem and have obtained the answer as $\frac{-1}{9}.$ Since there are no answers at the end of the book, I would like to confirm whether this is the correct answer or not. Thank you. The integral that I set up is as follows: $$\int_{-1}^{1}\int _{0}^{\sqrt{1-x^2}}xydydx+\int_{-1}^{1}\int _{-x/3-1/\sqrt{3}}^{\sqrt{x^2-1}}xydydx$$","['multiple-integral', 'calculus', 'multivariable-calculus', 'integration', 'geometry']"
2266859,Is there an 'intrinsic' characterization of the usual topology on a finite-dimensional vector space?,"Let $V$ denote a finite-dimensional vector space. Then $V$ becomes a topological space in a canonical way, by choosing a basis and using this to get an isomorphism to Euclidean space. It turns out that the topology you get is independent of choice of basis, so this makes $V$ into a topological vector space in a canonical way. Question. Is there a more intrinsic, or abstract, or basis-free approach to characterizing this topology, that gets closer to the heart of why it's important?","['real-analysis', 'functional-analysis', 'general-topology', 'topological-vector-spaces', 'vector-spaces']"
2266951,How can I prove that there is a function that is its own derivative? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question How can I prove that a function that is its own derivative exists? And how can I prove that this function is of the form $a(b^x)$?","['derivatives', 'real-analysis', 'ordinary-differential-equations', 'calculus']"
2266985,"How to prove $a_0 + a_1 \cos \theta + a_2 \cos 2\theta + \cdots + a_n \cos n \theta$ has $2n$ different zeros, $\theta \in (0,2\pi)$.","$0 < a_0 < a_1 < \cdots < a_n$. Prove that $a_0 + a_1 \cos \theta + a_2 \cos 2\theta + \cdots + a_n \cos n \theta$ has $2n$ different zeros, $\theta \in (0,2\pi)$. [Hint: First prove that $P_n(z)=a_o+a_1z+a_2z^2+\cdots+a_nz^n$ has $n$ zeros in unit ball $B(0,1)$.] This is an assignment I copied from my textbook. It's in the section ""The Argument Principle & Rouche Theorem"". Though I followed this hint, I still can't see how this would imply the desired conclusion. Help needed.",['complex-analysis']
2267020,If $\int_{\frac{1}{n+1}}^{\frac{1}{n}}\frac{\arctan(nx)}{\arcsin(nx)}dx=c_n$ then $\lim_{n\to\infty}{n^2c_n}=?$,"$$\int_{\frac{1}{n+1}}^{\frac{1}{n}}\frac{\arctan(nx)}{\arcsin(nx)}dx=c_n$$ Find the value of 
$$\lim_{n\to\infty}{n^2c_n}$$ I tried integrating the expression but couldn't. Need help.","['limits-without-lhopital', 'calculus', 'limits']"
2267036,Path connected space that is not locally connected,"I am trying to construct a topological space that is path connected, but nowhere locally connected. If we define $p = (0,1)\in\mathbb{R}^2$, and for all $q\in\mathbb{Q}\cap[0,1]$ $T_q = \{v\in\mathbb{R}^2\ |\ \exists t\in[0,1],\ v = (1-t)p + t(q,0)\}$, then 
$$
T = \bigcup\limits_{q\in\mathbb{Q}\cap[0,1]}T_q
$$
the space of all lines connecting rationals in $[0,1]\times\{0\}$ to $p$, can be shown to be path connected but locally connected only at $p$. I thought of attempts to maybe generalize the idea to make the desired result. The immediate one of these attempts was to maybe 'rational duplicate' $p$ along the $y = 1$ line, i.e. to let $T$ be all the lines connecting every rational point on $[0,1]\times\{0\}$ to every rational point on $[0,1]\times\{1\}$, but the proof attempt did not go (I am not sure if this is correct). Another idea was maybe a space-filling curve, but this seems a bit exotic.","['general-topology', 'path-connected', 'connectedness']"
2267051,On group graded algebras and Brauer groups,"I was reading the paper ""Algebras graded by groups"" by Knus. I want to test and further my understanding of the paper by asking several questions. Since the paper is not readily available I will detail everything necessary to understand my questions. Please do not be intimidated by the length of this post, the prelimenaries are very easy to read and are included in case of confusion. Prelimenaries Let $K$ be a field and let $G$ be an abelian group, a pairing (or bicharacter) of $G$ is a map $\phi:G\times G\rightarrow K^*$ such that $\phi(g_1+g_2,h)=\phi(g_1,h)\phi(g_2,h)$ , $\phi(g,h_1+h_2)=\phi(g,h_1)\phi(g,h_2)$ . A pairing $\phi$ is symmetric if $\phi(g,h)=\phi(h,g)$ . A pairing $\phi$ is called non-degenerate if $(\forall h\in G:\phi(g,h)=1)\Rightarrow g=e_G$ . A unital finite-dimensional $K$ -algebra $A$ is called $G$ -graded if $A=\bigoplus_{g\in G}A_g$ and $A_gA_h\subset A_{gh}$ , the unit lives in degree zero. A subspace $I\subset A$ is graded if it is the direct sum of the intersections $I\cap A_g$ . We call the graded algebra $A$ simple if there are no proper graded two-sided ideals. We call $A$ central if the only homogeneous elements $x\in A$ such that $xa=\phi(x,a)ax$ or $ax=\phi(a,x)xa$ for all homogeneous $a\in A$ , are in $K$ . Let $H^2(G,K^*)$ be the second cohomology group of $G$ with coefficients in the trivial $G$ -module $K^*$ . Let $f$ be a nonmalized $2$ -cocycle on $G$ and denote by $KG$ the group algebra on $G$ . We define the twisted group algebra $K_fG$ by twisting the multiplication on $KG$ , i.e. $g\cdot h:=f(g,h)gh$ . This turns $K_fG$ into an associative algebra. The Brauer group $\text{Br}(K,G)$ Let $\phi$ be a fixed pairing of an abelian group $G$ . Two $G$ -graded central simple algebras $A$ and $B$ are called equivalent if there exist two $G$ -graded vector spaces $V_1$ and $V_2$ such that $$A\otimes \text{End}_K(V_1)\cong B\otimes \text{End}_K(V_2).$$ Let $\text{Br}(K,G)$ denote the set of equivalence classes, the tensor product induces a group structure on $B(K,G)$ . Here $A\otimes B$ is given the structure of an algebra by defining $$(a\otimes b)(a'\otimes b'):=\phi(b,a')(aa'\otimes bb').$$ One can show that the tensor product of two graded central simple algebras as above is again graded central simple. Main theorem Let $G$ be an abelian group and $\phi$ a symmetric pairing on $G$ which is non-degenerate on any finite subgroup of $G$ . Then a graded central simple algebra $A$ such that $\text{char}(K)$ does not divide $\dim_K(A)$ is isomorphic to $$K_f(H)\otimes M_n(D,H').$$ Here $H$ and $H'$ are subgroups of $G$ such that $G=H\times H'$ , $f$ is an abelian class in $H^2(H,K^*)$ . $M_n(D,H')$ is a matrix algebra over a division ring $D$ graded by $H'$ . Questions What exactly is meant by $M_n(D,H')$ is a matrix algebra over a division ring $D$ graded by $H'$ ? Similarly what is the precise meaning of $\text{End}_k(V)$ if $V$ is $G$ -graded? Is this the usual endomorphism ring or a ring of graded morphisms? Suppose $G=\left\{e_G\right\}$ , then any $G$ -graded central simple $K$ -algebra $A$ is simply a central simple $K$ -algebra. Thus by the main theorem $A\cong K_f(G)\otimes M_n(D,G)$ . Clearly $K_f(G)\cong K$ , hence $A\cong M_n(D,G)$ . Whatever the answer to the previous question is, a trivial grading should give that $A\cong M_n(D)$ . Clearly the size of the Brauer group $\text{Br}(K,G)$ depends on the number of division rings over $K$ . Suppose $K=\mathbb{R}$ , by a result of Frobenius the only division rings over $\mathbb{R}$ are $\mathbb{R},\mathbb{C}$ and the quaternions $\mathbb{H}$ . Hence any central simple algebra over $\mathbb{R}$ is isomorphic to either $M_n(\mathbb{R}), M_n(\mathbb{C})$ or $M_n(\mathbb{H})$ . But $M_n(\mathbb{C})$ is not central as the center is two-dimensional. Does it follow that the Brauer group $\text{Br}(K,\left\{e_G\right\})$ contains at most two elements? To be more precise, a priori it's possible that $M_n(\mathbb{H})$ live in different classes for different $n$ . Let $B$ be an ordinary central simple algebra over $K$ , be declaring this thing to live in degree zero we can view any central simple algebra as a $G$ -graded central simple algebra. Can we view the usual Brauer group $\text{Br}(K)$ as a subgroup of $\text{Br}(K,G)$ ? Consider $K=\mathbb{R}$ and $G=\mathbb{Z}_2\times \mathbb{Z}_2$ and let $\phi$ be the trivial pairing. We know that the quaternions $\mathbb{H}$ are a real division ring. On the other hand we could view the quaternions $\mathbb{H}$ as a $G$ -graded algebra by declaring $\deg(i)=(1,0), \deg(j)=(0,1)$ and $\deg(k)=(1,1)$ . Let me denote the graded version by $\mathbb{H}_G$ . Notice that $\mathbb{H}_G$ is a graded central simple algebra. In light of the main theorem, $\mathbb{H}_G\cong K_f(H)\otimes M_n(D,H')$ , can we specify $H,H',f'$ and $n$ ? Depeding on the answer to $1$ , a natural answer could be $\mathbb{H}_G\cong M_1(\mathbb{H}, G)$ . Last but not least: In general one can define the Brauer group of a braided monoidal category. Now let $G$ be a group and $\phi$ a pairing. One can consider the Hopf algebra $KG$ and using $\phi$ one can define coquasi-triangular structure on $KG$ . Denote by $H$ the resulting coquasi-triangular Hopf algebra. Is the Brauer group $\text{Br}(K,G)$ equal to $\text{Br}(\text{Mod}^H)$ , the Brauer group of the braided monoidal category of $H$ -comodules?","['brauer-group', 'abstract-algebra', 'monoidal-categories', 'hopf-algebras', 'linear-algebra']"
2267059,Covariant derivative of tensor densities,"Note: This post is intended to be about Ricci-calculus. My definition of tensor densities in this post makes a scalar density of weight 1 essentially equivalent to a maximal-degree differential form, so answers along the line of modern differential geometry are almost useless to me here. Given an $n$ dimensional real $C^\infty$ manifold $M$, I hereby define a scalar density of weight 1, $\rho$, at $p\in M$ as a rule that assigns to any local chart containing $p$ a real number with the understanding that during coordinate change, this number transforms as $$ \rho'=\det\frac{\partial x}{\partial x'}\ \rho. $$ Let $\nabla_\mu$ be a linear connection that acts on vector fields in a local trivialization as $$ \nabla_\mu X^\nu=\partial_\mu X^\nu+C^\nu_{\mu\sigma}X^\sigma. $$ Linear connections are induced by $\nabla$ on the cotangent bundle and the tensor bundles by the natural conditions that $\nabla$ should commute with contractions and obey the Leibniz rule with respect to tensor products. Since scalar densities of weight 1 at different points, we also need to introduce a connection on the density bundle, given in a local trivialization as $$ \nabla_\mu\rho=\partial_\mu\rho+C_\mu\rho, $$ this $C_\mu$ is a priori independent of $C^\nu_{\mu\rho}$. Now, we can check that during coordinate change, $C_\mu$ transforms as $$ C_\mu'=\frac{\partial x^\mu}{\partial x^{\mu'}}C_\mu-\frac{\partial^2x^\nu}{\partial x^{\mu'}\partial x^{\nu'}}\frac{\partial x^{\nu'}}{\partial x^\nu}, $$ and this is the same as the transformation rule for $-C^\nu_{\mu\nu}$, so one natural way to extend the connection in the tangent bundle to a connection in the density bundle is to define $C_\mu=-C_{\mu\nu}^{\nu}$, however this approach relies a lot on transformation rules, and I don't like it. One other natural condition would be to abuse the relationship between scalar densities and differential forms, as the density $\rho$ corresponds to the differential form $\rho_{\mu_1,...,\mu_n}=\rho\pi_{\mu_1,...,\mu_n}$, where $\pi$ is Levi-Civita's symbol.
Then the natural condition is to demand that $\nabla_\nu\rho_{\mu_1...\mu_n}=(\nabla_\nu\rho)\pi_{\mu_1,...,\mu_n}$. I tried to check this, but this quickly became untractable as $$ \nabla_\nu\rho_{\mu_1...\mu_n}=(\partial_\nu\rho)\pi_{\mu_1...\mu_n}-\rho\left\{C^\sigma_{\nu\mu_1}\pi_{\sigma\mu_2...\mu_n}+...+C^\sigma_{\nu\mu_n}\pi_{\mu_1...\mu_{n-1}\sigma}\right\}, $$ and I have no clue how to evaluate the terms in the curly brackets. Question: Would this latter definition of the covariant derivative of a scalar density of weight 1 reduce to the $C_\mu=-C_{\mu\nu}^\nu$ relation implied by the transformation properties? If so, I would be terribly appreciative of any pointers as to how to perform the calculation that shows this. I tried using several identities and meanings related to the Levi-Civita symbol but nothing simplified the curly bracket.","['tensors', 'differential-geometry', 'connections']"
2267061,Interesting integral: $\int_0^1{\frac{nx^{n-1}}{x+1}}dx$,Find the value of $$\int_0^1{\frac{nx^{n-1}}{x+1}}dx.$$ I had no luck while integrating it. I also tried differentiating w.r.t n but still couldn't reach anywhere. Need help.,"['integration', 'definite-integrals', 'calculus']"
2267097,An approximate eigenvalue that is not an eigenvalue,Could you please help me understand why $\lambda$ in the example below is not an eigenvalue? It's easy to see that each $\lambda_n$ is an eigenvalue but I am having difficulty ascertaining that their limit is not. Thank you in advance.,"['functional-analysis', 'eigenvalues-eigenvectors', 'eigenfunctions']"
2267108,What is the value of $m+n$??,"Suppose that there are $5$ red points and $4$ blue points on a circle . Let $\frac{m}{n}$ be the probability that a convex polygon whose vertices are among the 9 points has at least one blue vertex when $m$ & $n$ are relatively prime. Then the value of $(m+n)$ is? This question came in recent JEE Advanced (unofficial) test and I'm stumped on how to approach this problem. The answer given is $460$ . I'm new to geometric probability and permutational concepts.
Please someone help me out on how to approacch this problem.","['permutations', 'probability']"
2267124,Maximum value of $f(x)$ if $f(x)+f\left(1/x\right)=x$,What is the maximum value of $f(x)$ if $f(x)+f\left(\frac{1}{x}\right)=x$ for all $x$ in the domain of this real valued function? Now $f(x)+f\left(\frac{1}{x}\right)=x$ and by symmetry $f(x)+f\left(\frac{1}{x}\right)=\frac{1}{x}$. Therefore $x=\frac{1}{x}$ $\implies$ $x=1$ or $-1$. Does it mean that the domain of the function is only $1$ or $-1$ ? And therefore substituting $x=1$ in the equation we get maximum value of $f(x)$ as $1/2$?,"['functions', 'proof-verification']"
2267131,Trigonometric Limit tends to $\infty$,$$\lim_{x \to 0}\lim_{n \to \infty} \frac{n}{\left(1^\left(\cot^2x \right)+2^\left(\cot^2x \right)+...+n^\left(\cot^2x \right)\right)^\left(\tan^2x \right)}$$ How to approach? Need hints.,"['limits-without-lhopital', 'limits']"
2267175,How can I prove that Game of Life's evolution function is continuous?,"Conway's Game of Life is a cellular automaton, but also a discrete dynamical system. In all the papers, books, notes I have read on it, it is never never never shown that its evolution function is continuous. I tried to show it myself, thinking it was trivial, but it reveals to be more challenging than I thought. Here is what I did so far: Since we work in an infinite orthogonal grid, I denote the space we work with as $S^{\mathbb{Z}^2}$, where $S=\{0,1\}$ with $0$ standing for a dead cell and $1$ for one alive. Therefore a point $x \in S^{\mathbb{Z}^2}$ would be an infinite $2-$dimensional sequence of zeros and ones. Next, I defined a distance on this space, by saying $d(x,y)=0$ if $x=y$ and otherwise $d(x,y)=2^{-k}$ where $k$ is the largest integer such that $x_{[-k,k]^2}=y_{[-k,k]^2}$ i.e two points $x,y$ are close if they agree on a square $\{-k,\dots,k\}^2$. I already managed to prove that $S^{\mathbb{Z}^2}$ is a compact metric space. Where I am now stuck, is that I have no clue how to apply the definition of continuity on Game of Life.. Here is the definition:
Let $(X,d)$ be a metric space. A map $f: X \mapsto X$ is called continous if for every $x\in X$ and $\epsilon > 0$ there exists a $\delta >0$ such that:
$$
d(x,y)<\delta \implies d(f(x),f(y))<\epsilon
$$ And I know the evolution function is continuous. According to a famous theorem of Hedlund, a map $f: S^{\mathbb{Z}^2} \mapsto S^{\mathbb{Z}^2}$ is a cellular automaton if and only if the map is continuous and commutes with the shift map $\sigma$. If you have any tips,ideas or hints.. would be highly appreciated! I am quite curious to know how to get there now, Thanks !","['dynamical-systems', 'cellular-automata', 'uniform-continuity', 'metric-spaces', 'discrete-mathematics']"
2267183,How does one show that $\int_{-\infty}^{+\infty}{\left(x\over 2+2^{x}+2^{-x}\right)^2}\mathrm dx={\zeta(2)-1\over 3}\cdot{1\over \ln^3(2)}?$,Motivated by this question due to the comment of @Olivier Oloa. $$\int_{-\infty}^{+\infty}{\left(x\over 2+2^{x}+2^{-x}\right)^2}\mathrm dx={\zeta(\color{red}2)-\color{blue}1\over \color{green}3}\cdot{\color{blue}1\over \ln^\color{green}3(\color{red}2)}\tag1$$ Here is my attempt: $u=2^x\implies du=2^x\ln 2dx$ then $(1)$ becomes $${1\over \ln^3(2)}\int_{0}^{+\infty}{\ln^2(u)\over (2+u+u^{-1})^2}\cdot{\mathrm du\over u}\tag2$$ $e^v=u$ then $(2)$ becomes $${1\over \ln^3(2)}\int_{-\infty}^{+\infty}{v^2\over (2+e^v+e^{-v})^2}\mathrm dv\tag3$$ Not sure what is next step...,"['integration', 'definite-integrals', 'calculus']"
2267202,Let $N$ be a normal subgroup of a finite group $G$,"Let $N$ be a normal subgroup of a finite group $G$. Suppose $|N|=5$ and that $|G|$ is odd. Prove $N$ is contained in $Z(G)$ , the center of $G$ because the order of $N$ is prime, then N is cyclic, but
I'm more concerned with how I can derive for  $g\in G$ and $g^{-1}ng=n$ for all $n\in N$","['abstract-algebra', 'group-theory']"
2267231,"Prove that the operator $Ax(t)= \int_{0}^{t}x(s)ds + x(t)$ is invertible and find $A^{-1}.$ $A:C[0,1]\to C[0,1]$","Prove that the operator $$Ax(t)= \int_{0}^{t}x(s)ds  + x(t)$$ is invertible and find $A^{-1}.$
$$A:C[0,1]\to C[0,1]$$
The metric on $C[0,1]$ is $\max_{t\in [0,1]}|x(t)|$ For the operator to be invertible this has to apply for every function $ x(t) \in C[0,1]: \exists m \text{ such that } \|Ax(t)\|_{C[0,1]}\geq m\|x(t)\|_{C[0,1]}$ I have that: $$ \|Ax(t)\|_{C[0,1]} = \max_{t\in [0,1]}|\int_{0}^{t}x(s)ds  + x(t)|$$
How can I find an $m$ so that this applies for every $x \in C[0,1]$","['functional-analysis', 'operator-theory']"
2267237,Cone geometry question,"A cube of side 8 cm stands on a horizontal table. A hollow cone of height 20 cm is placed over the cube so that it rests on the table and touches the top four corners of the cube. Find the vertical angle of the cone. I can't seem to figure out how to work out the length of the base, which seems to be necessary to work out the angle.","['trigonometry', 'geometry']"
2267238,Pointwise convergence of Random walk to the Brownian motion,"Let $\{X_i\}_{i \in \mathbb{N}}$ be a sequence of i.i.d random variables taking value in the set $\{-1,1\}$ with $P(X_i = 1) = \frac{1}{2}$ .
Let $S_n = \sum\limits_{i=1}^n X_i$ , and for $k \in \mathbb{N}$ define the random process $B^k$ as $$
B^k(t) = \frac{S_{[kt]}}{\sqrt{k}} \qquad t \in \mathbb{R} 
$$ where $[x]$ is the integer part of $x$ . I know that $(B^k(t))_{t \in \mathbb{R}}$ converges to the standard Brownian motion in distribution, does it also converges pointwise? i.e. is there a random process $\{B(t)\}_{t\in \mathbb{R}}$ so that $$
\forall t \in \mathbb{R} \quad  \lim_{k \to \infty} B^k(t) = B(t) \quad \text{a.s}
$$ and further that $B(t)$ is the Brownian motion.","['probability-theory', 'brownian-motion']"
2267245,Algebra (sequence & series): $\sum_{r=1}^{n}[rx]$,How to find summation of $\sum\limits_{r=1}^{n}[rx]$ and  $\sum\limits_{r=1}^{n}\left\{rx\right\}$? (where [ ] is greatest integer function & { } is fractional part),"['discrete-mathematics', 'summation', 'elementary-number-theory']"
2267263,"Prove that if $A$ is any infinite set, the set of all finite subsets of $A$ has the same cardinality as $A$","I have considered as following: Consider any infinite set $A$ with cardinality $m$ for some infinite cardinal $m$, for each natural number $n$, denote the set of subsets of $A$ with exactly $n$ elements as $A_n$. Denote the set of finite subsets of $A$ by $F$, thus $F=\lbrace \emptyset \rbrace \cup A_1\cup A_2 \cup...=\lbrace \emptyset\rbrace \oplus A_1\oplus A_2\oplus...$. There is the missing argument to conclude that for each $n\in \Bbb N$, $A_n\approx A$ Hence $\#F=\#(\lbrace \emptyset\rbrace \oplus A_1\oplus A_2\oplus...)=1+m+m+... =m+m+...=(1+1+1+...)m=\aleph_0\cdot m=m$ Is that correct? I fell I am stuck on proving that each $A_n$ has the same cardinality as $A$. It seems to be related to the product set but I can only find an injection from each $A_n$ to $A^n$. So could someone please help? Thanks so much!","['cardinals', 'elementary-set-theory']"
2267288,Find a function f(u) such that the following ODE becomes exact.,"So I'm a bit puzzled with this question: Find a function f(u) such that this function becomes exact: $$\ f(x+y)+\ln(x)+(e^{x+y}+y^2)y'=0,$$ my initial thoughts were setting $$\ P(x,y):= f(x+y)+\ln(x); Q(x,y):=e^{x+y}+y^2,$$ then$$\dfrac{\partial P}{\partial y}=f'(x+y)=e^{x+y}=\dfrac{\partial Q}{\partial x}, $$ ${}{}{}$ so $$\ f(x+y)=e^{x+y}, $$ Is this right? Thanks in advance. EDIT: to show correct answer, thanks everyone!",['ordinary-differential-equations']
2267310,Probability of rolling 3 and 4 in a row with 4 6-sided dice,"So I was playing a game and was wondering what the probability was to roll numbers in a row. Four fair six-sided dice are rolled. What is the probability that three of the numbers will be in a row. Also, that all 4 of them will be in a row. I've tried solving it but I couldn't get it. How can I solve this? I know that with 4 dice there are 1296 combinations but I have not come up with a way to determine the outcome.",['probability']
2267327,Frobenius morphisms of a scheme,"I'm trying to undersand the various frobenuis morphism we can consider on a scheme. Those are concepts I just touched, so I'm not sure about some stuff I'm writing and things became clearer while I develop the question; any comment or precisation will then be appreciated, in addition to the answers to the various questions that arises in what follows. If $A$ is a ring with characteristic $p$ then there is a Frobenius morphism $F:A\to A$ which sends $a$ to $F(a)=a^p$; this morphism is injective iif there are no nilpotent elements and in general is not surjective. From now on let $K$ be a field of characteristic $p$, and $X$ a $K$-scheme. Absolute Frobenius Whave the absolute Frobenius morphism $F^{abs}:X\to X$, which is defined on an affine open subset $U\cong \operatorname{Spec}(A)$ by the Frobenius on $A$. Since we are looking for the q-th roots of elements of prime ideals, $F^{abs}$ is the identity on the points of $X$, while sends a section in its q-th power as pointed in this answer. Unless $K=\mathbb F_p$, the absolute Frobenius is not a morphism of $K$-schemes , but it makes the following diagram commute
\begin{array}{rcl}
X&\overset{F^{abs}}{\longrightarrow}&X\\
\downarrow&&\downarrow&\\
Y&\overset{F^{abs}}{\longrightarrow}&Y
\end{array}
for any morphism $X\to Y$. This will be useful to define the relative version of this morphism. Frobenius Twist The Frobenius twist of $X$ is defined as the fibered product $X^{(p)}:= X\times_{\operatorname{Spec}(K)}\operatorname{Spec}(K)$, where $\operatorname{Spec}(K)$ is regarded as a $K$-scheme whith the absolute Frobenius as structure morphism. +++Here come the first questions: if $K=\mathbb F_p$ then $X^{(p)}\cong X$ since we are extending via the identity, but in general I cannot understand its structure. Wiki gives the explicit answer in the affine case (there is called extension by scalars ), but it's not clear to me how it works and furthermore I don't understand it geometrically: which are the points of $X^{(p)}$? Which are his $K$-points? Are the $\mathbb F_p$-points of $X$ and $X^{(p)}$ the same? In particular, what can we say if the field K is perfect (so F is an automorphism)? I expect them to be isomorphic, even though not naturally. I'm not very familiar with tensor product of $K$-algebras, but trying to think in the affine case $X\cong\operatorname{Spec}(A)$, it seems to me that $X^{(p)}$ should correspond to the tensor product algebra $A\otimes K$, where $v\otimes\lambda$ is identified to $\lambda^pv\otimes 1$, and where $K$ acts as $\alpha.v\otimes\lambda=\alpha v\otimes\lambda=v\otimes\alpha^p\lambda$ Relative Frobenius For what we've said, we find that there is a universal morphism $F^{rel}:X\to X^{(p)}$ which is called relative Frobenius . This is now a morphism of $K$-schemes: in the affine case it sends $v\otimes\lambda$ to $\lambda v^p$ and it's worth noting that the $K$-algebra structure on $X$ is given by $\alpha.v=\alpha^pv$ +++And here come more questions: If $K=\mathbb F_p$ then the relative and the absolute Frobenius coincide, modulo the iusomorphism we said before, and from the affine case I can have a hint of what happens in general to the structure sheaf, but what about the points? Is it surjective/injective? I would like to understand it at least in the case where $X\cong X^{(p)}$. For the moment it's all. I will ask other questions about the geometric and aritmetic Frobenius, for which we need to define first what is a $k$-structure on a $K$-scheme. I'm pondering if opening a new post for it, or expanding this one.","['schemes', 'arithmetic-geometry', 'algebraic-geometry']"
2267331,combinatorics sum 2,"Player 1 and Player 2 both start with 100 rupees. Each round of a game consists of the
following:
Both players choose a number randomly and independently from 1 to 5. If both players
choose the same number, then Player 1 gives rupees 10 to Player 2. Otherwise, Player
2 gives rupees 10 to Player 1. Then the expected amount of money Player 1 will be left
with after playing 10 rounds of this game is
A. 120 B. 100 C. 50 D. 160 My Approach:
Required expectation for 1 round= (1/5*1*(-10)+1/5*1/4*(10))=-1.5 rupees
Therefore Expectation for 10 rounds = -1.5*10=-15 rupees So the player 1 will be left with 100-15= 85 rs. But this does not match any of the answer options.","['combinatorics', 'expectation', 'probability']"
2267352,How to find an approximate solution of a three dimensional DE system,"Suppose A is a $3$ by $3$ matrix. How can I find the approximated solution as $t$ goes to $\infty$ of the system $$X' = AX$$ I think it has something to do with the Jordan decomposition of A, but how? If $A = SJS^{-1}$ can I just take the solution to the system $X' = JX$?","['ordinary-differential-equations', 'linear-algebra']"
2267370,Directional derivative of a vector field in the direction of another vector field,"So, I was reading some introductory things about differential geometry, and just discovered the big gap I have in analysis. For instance, I do understand what is means to ask for the directional derivative of a smooth real valued function $f: \mathbb{R}^n \rightarrow \mathbb{R}$, in $u \in \mathbb{R}^n$ direction, and how does this generalizes to the case of vector fields of the form $F: \mathbb{R}^n \rightarrow \mathbb{R}^n$, where we have $\nabla_u F(p) = \lim_{t \to 0} \frac{F(p+tu)-F(p)}{t},$ as the directional derivative. Now, I'm looking for the directional derivative of a vector field say $X$, in the direction of another vector field $Y$, but I can't find any reference or online handout with this sort of things. I presume that the definition should be look like 
$$\nabla_Y X(p) = \lim_{t \to 0} \frac{X(p+tY)-X(p)}{t},$$
but I need to see it written anyway, so any comments, references or online notes concerning those things are welcome.","['derivatives', 'reference-request', 'calculus', 'vector-analysis']"
2267373,Can you add a single point to any completely regular (not normal) space to get a normal space?,"This is a follow up to my previous question (unfortunately closed as a duplicate).  There the problem was to turn the Moore plane into a normal space by adding a single point. Brian M. Scott gave an answer to this specific problem years ago. This got me thinking about a more general question: Can you add one point to any completely regular not normal space $X$ to obtain a normal space $Y$ of which $X$ is a subspace? Note that for me a completely regular spaces and normal spaces are Hausdorff. The restriction to completely regular spaces is natural since every subspace of a completely regular space is itself completely regular, and normal spaces are completely regular. Since $Y$ is supposed to be normal, the subspace $X$ must be completely regular. I know that if $X$ is locally compact you can take $Y$ to be the one-point compactification. However if $X$ is not locally compact the one-point compactification fails to be Hausdorff.",['general-topology']
2267411,How may be prove that $\int_{-\infty}^{+\infty}\sin(\cosh x)\cos(\sinh x)\mathrm dx={\pi\over 2}?$,Given this integral $$\int_{-\infty}^{+\infty}\sin(\cosh x)\cos(\sinh x)\mathrm dx={\pi\over 2}\tag1$$ My try: Recall $$2\sin(A)\cos(B)=\sin(A-B)+\sin(A+B)$$ $(1)$ becomes $$\frac12\int_{-\infty}^{+\infty}\cos(\cosh x-\sinh x)+\sin(e^x)\mathrm dx\tag2$$ Recall $$\cosh^2 x-\sinh^2 x=1$$ $(2)$ becomes $$\frac12\int_{-\infty}^{+\infty}\sin(e^{-x})+\sin(e^x)\mathrm dx\tag3$$ How may be prove $(1)?$,"['integration', 'definite-integrals', 'calculus']"
2267418,determinant diagonal zero symmetric matrix,"Let
$$M=\begin{pmatrix}      
    0 & 1    &  1   &     1\\
    1 & 0    &  \alpha + \beta &  \alpha + \gamma\\
    1 & \beta + \alpha & 0    &  \beta + \gamma\\
    1& \gamma + \alpha  & \gamma + \beta  &   0
\end{pmatrix},$$
then it holds $$\det(M) = −4(\alpha\beta + \beta\gamma + \gamma\alpha).$$ What is the value of this when $\alpha,\beta,\gamma$ are the three roots of the equation $x^3 − 1 = 0$? Can anyone help me to do it by elementary row operation? My idea is just solving $\alpha,\beta,\gamma$ and then plug in $−4(\alpha\beta + \beta\gamma + \gamma\alpha)$
and when I try to find the determinant of the LHS I got $-4\beta\gamma$.","['matrices', 'determinant', 'symmetric-matrices', 'linear-algebra', 'vector-spaces']"
2267421,Ricci Flow on a Sphere of radius r,"Let $(M, g)$ be an $n$-sphere of radius $r$ with metric $g$ where $g = r^{2}g_{\mathbb{S}^{n}}$, $g_{\mathbb{S}^{n}}$ being the standard metric on the unit $n$-sphere. It is well known that $Ric_{g}=(n-1)g_{\mathbb{S}^{n}}$. If we apply Ricci flow on $M$ does the shape of the sphere change? The evolution equation is $\cfrac{\partial}{\partial t}g =\cfrac{\partial}{\partial t} (r^{2}g_{\mathbb{S}^{n}}) = -2Ric_{g}$. Now the left-hand side should give us $2r\dot{r} g_{\mathbb{S}^{n}}+\cfrac{\partial}{\partial t}g_{\mathbb{S}^{n}} $. However, most books and notes on Ricci flow say: $\cfrac{\partial}{\partial t} (r^{2}g_{\mathbb{S}^{n}}) = -2Ric_{g}$ 
$ \implies 2r\dot{r}g_{\mathbb{S}^{n}}= -2(n-1)g_{\mathbb{S}^{n}}$ $\implies r\dot{r}=-(n-1)$. My question is what happens to the term $\cfrac{\partial}{\partial t}g_{\mathbb{S}^{n}}$? Does the metric $g_{\mathbb{S}^{n}}$ not change under the flow? Why? Am I missing something? Thanks in advance.","['ricci-flow', 'differential-geometry']"
2267443,Why does$ \int_{0}^{\pi} \frac{dx}{\sqrt{\sin(x)}}$ converge while $\int_{0}^{\pi} \frac{dx}{\sin(x)}$ diverges?,"Essentially for me, the question boils to down finding a convergent majorant for $$\left|\frac{1}{\sqrt{\sin(x)}}\right|$$ in the interval $(0, \pi)$ thereby proving convergence of  $$ \int_{0}^{\pi} \frac{dx}{\sqrt{\sin(x)}}. $$ I can't think of a good majorant though.","['trigonometric-integrals', 'real-analysis', 'improper-integrals', 'convergence-divergence']"
2267456,How to prove ${n \choose p} \equiv\left\lfloor \frac{n}{p} \right\rfloor\pmod p$,Prove ${n \choose p} \equiv \left\lfloor \frac{n}{p} \right\rfloor \pmod p$ ($n$ is natural and $p$ is a prime number) How can i prove this statement?,"['number-theory', 'discrete-mathematics']"
2267493,16 Congruent Scalene Integer Triangles,"With any triangle, 8 copies can make an octahedron . With any acute triangle, 4 copies can make a tetrahedron. Make a scalene octahedron, then construct scalene tetrahedra on each face.  Here are samples with the 4-5-6, 6-12-13, 9-11-13, 11-12-15, and 11-13-16 triangles. These are cases where we almost get a 16-triangle outer shell. None of them quite works, the outermost vertices don't actually coincide in these cases. Is there an integer triangle that gives a perfect solution?","['polyhedra', 'solid-geometry', 'number-theory', 'triangles', 'combinatorics']"
2267509,When an ideal is generated by idempotents,"Let $f:R\rightarrow S$ be a ring homomorphism of commutative rings
with identities such that $f(1_R)=1_S$. And let $J$ be an ideal of
$S$ such that for every prime ideal $P$ of $R$ and every $n\in
\mathbb{N}$, $J\subseteq {\langle f(P)+J \rangle}^{n}$, where $\langle f(P)+J \rangle$ is the
ideal generated by $f(P)+J$ in the ring $f(R)+J$, as a subring of
$S$. How can we show that $J$ is generated by idempotents, as an ideal of $f (R)+J $ or $ S $?","['abstract-algebra', 'idempotents', 'ideals']"
2267553,Where can I find a clear overview of the grothendieck construction?,"I have seen the grothendieck construction referenced in the literature several times, but never have found a good clean overview of how it works. How can I go from a stack which is a category fibered in groupoids over a site, let's say $(Sch/S)_{et}$, to a groupoid in $(Sch/S)$, and then back? For example, consider the quotient stack associated to the ramified etale cover
$$
\text{Spec}(\mathbb{C}[x,y]/(x^5 - y)) \to \text{Spec}(\mathbb{C}[y])
$$
with isotropy group $\mathbb{Z}/5$ at the origin.","['algebraic-geometry', 'reference-request', 'algebraic-stacks', 'category-theory', 'grothendieck-construction']"
2267621,Conditional expectation defined on partition of the sample space,"Let $(\Omega,\mathscr{F},P)$ be a measure space.
  Let $\{A_1,A_2,\dots\}$ be a partition of the sample space $\Omega$, where $A_i \in \mathscr{F}$ and $\bigcup_i A_i=\Omega$ with $P(A_i)>0$. Let $X$ be an integrable random variable. Show that $\displaystyle{E[X|\sigma\{A_i,i\geq1\}]=\sum_i \frac{E[X \chi_{A_i}]}{P(A_i)}\chi_{A_i}}$ where $\chi$ is the characteristic function. Let $\displaystyle{Z=\sum_i \frac{E[X \chi_{A_i}]}{P(A_i)}\chi_{A_i}}$. Then I want to prove for every $A \in \sigma\{A_i,i\geq 1\}$ $\int_A X dP = \int_A Z dP$. and $Z$ is  $\sigma\{A_i,i\geq 1\}-$measurable. $Z$ is obviously measurable w.r.t. $\sigma\{A_i,i\geq 1\}$. But how to prove $\int_A X dP = \int_A Z dP$?","['probability-theory', 'measure-theory']"
2267644,"Given the length of 3 sides and 2 points, how do I find the third point of a right triangle","Prologue: I have very moderate knowledge of mathematics (highschool sophomore level). Any explanation needs to be broken down to chewable bits. I'm sorry if this inconveniences you guys. I have the following problem: How do I find out if a circle and an arc sector of another circle intersect? The small circles above are examples. The ones in red are the ones that do not intersect, the ones in green are that ones that do intersect. This is my approach, based on immediate data that I have available about the arc sector and the other circle: let $A$ be the arc sector of a circle defined as follows: $C$ $(Cx, Cy)$ is the centre of the circle. $D$ is a radius of the circle, of which we know the length. ($D$ stands for direction). $\alpha$ the angle of arc sector, so that $D$ bisects $\alpha$ We also know the point where $D$ intercepts the circle (not named in the drawing above) \begin{equation}
\\
\end{equation} For the smaller circles: let $P$ be a circle, defined as follows: $c$ $(cx, cy)$ is the centre of the circle. $r$ is the radius of the circle. First, i check if $P$ is inside or intersects the circle defined by $C$ and $D$: $$(D + r)^2 \geq (Cx - cx)^2 + (Cy - cy)^2$$
(sum of the radii squared is greater than or equal to the squared distance between $C$ and $c$) Secondly, if the above is true, my plan is to find the angle between the radius $D$ and each of the two tangents to circle $P$ (there's a problem here, read bellow) that pass through $C$; if any of these two angles is equal to or smaller than $\frac{\alpha}{2}$, then I have an intersection. Note: The problem with this approach is that it doesn't work in case $C$ is inside $P$ (like the small green circle that contains C in figure 1). I disregard this case, because I don't know how to deal with it. In short, I know my answer is wrong, I'm just letting you know what I have so far. Considering that the set of arguments of my function that will result in $P$ containing $C$ is almost negligible, a result where those cases are excluded is acceptable, even if not ideal. I know how to find the angle between $Cc$ and the tangents: $$\measuredangle uCc = \measuredangle vCc = \arcsin(\frac{r}{d})$$ But I think that's irrelevant. What I need is to find the angle between each of the tangents (the black lines) and $D$, and if such angle is equal to or lesser than $\frac{\alpha}{2}$, then it's a hit, otherwise, a miss. I think I need to find the slopes of the lines $Cu$ and $Cv$, so I can compare it to the slope of $D$ to find the angle between those lines, using the relation: $$\tan(\theta) = \left| \frac{m_{a} - m_{b}}{1 + m_{a}m_{b}}\right|$$ For me to find the slopes of those lines, I think I need to know the points $u$ and $v$. There's one last problem with my approach: the function $arctan$ (which I would use to find $\theta$, given $\tan(\theta)$) can give me wrong results in case one of the circles is in a position inside the opposite arc $A'$ formed by extending $D$ and the legs of the arc into diameters. I hear $arctan2$ can fix this, but I'm not sure how to use it. If there's an easier solution than mine, it's very welcome. As I mentioned, the third point of the triangle is necessary for me to know how to solve this according to my approach so far. If there's a better and faster way, please let me know, since this problem is to be used in a computational algorithm.",['trigonometry']
2267645,Travel Each Edge of A 6 Dimensional Hypercube Once,"I am trying to find a way to ""travel"" along each edge of a 6D hypercube once and only once. I know it is possible with a 2D square and a 4D tessarect. For the square, it is obvious how to accomplish this: Start at (0,0), move to (0,1), move to (1,1), move to (1,0), move to (0,0). Each edge has been traveled along only once. The tessarect is a bit more complicated, but it is possible (see the uploaded picture of the tessarect here ). Start at 0000, and then move in the following order: 1000, 1100, 0100, 0000, 0001, 1001, 1101, 0101, 0001, 0011, 1011, 1111, 0111, 0011, 0010, 1010, 1000, 1001, 1011, 1010, 1110, 1100, 1101, 1111, 1110, 0110, 0100, 0101, 0111, 0110, 0010, 0000. The 6-cube has stumped me. I am not sure how to move along every edge only once, but I assume that it is possible for all n-cubes where n is an even number.
The following picture of a 6-cube may help. I have one colored so that each color represents the dimension that a certain edge is in. For example, an orange line represents an edge in the 1st dimension, between vertices 000000 and 000001. There is another picture of a 6-cube which in which all of the edges of a single 3D cube are colored similarly, and each cube is connected in higher dimensions through different colors. Any help/insight is greatly appreciated, and please let me know if I need to elaborate. Thank you,
Mitch","['graph-theory', 'geometry']"
2267688,Locating a line perpendicular to an ellipse,"At any given point on an ellipse, the line of the perpendicular is easy to calculate; what about the inverse? Given a line of known orientation, at what point on the circumference of an ellipse would it be perpendicular?","['conic-sections', 'geometry']"
2267695,Show that a system has a period solution by finding a trapping region (Poincaré-Bendixson Theorem),"\begin{align*}
\dot{x}&=4x+2y-x(x^2+y^2)\\
\dot{y}&=-2x+y-y(x^2+y^2)
\end{align*} I want to show that this system has at least one periodic solution by constructing a trapping region where the Poincaré-Bendixson theorem can be applied. So far I've converted the system to polar coordinates and got: \begin{align*}
\dot{r}&=-\frac{1}{2}r(-5+2r^2-3\cos(2\theta))\\
\dot{\theta}&=-r(2+3\cos(\theta)\sin(\theta)).
\end{align*} Where I'm lost now is constructing the trapping region where $\dot{r}<0$ on the outside and $\dot{r}>0$ on the inside. Graphing this system using streamplot the region is visually clear, but I'm having trouble finding a closed form solution.","['ordinary-differential-equations', 'dynamical-systems']"
2267708,Some functional calculus of commuting positive operators,"Let $A,B$ be two positive operators on a complex Hilbert space. We know that we can define $A^a$ for any $a\geq0$. If $A$ commutes with $B$, then do we have $(AB)^a=A^aB^a$? I believe this is correct but I am not too sure whether my proof is correct (it uses the spectral theorem)? I would appreciate any hint. Thanks in advance.",['functional-analysis']
