question_id,title,body,tags
1613541,"Let $a,b,c,d$ be distinct integers such that the equation $(x-a)(x-b)(x-c)(x-d)-9=0$ has an integer root $r$,then find the value of $a+b+c+d-4r.$","Let $a,b,c,d$ be distinct integers such that the equation $(x-a)(x-b)(x-c)(x-d)-9=0$ has an integer root $r$,then find the value of $a+b+c+d-4r.$ As $r$ is the integer root of the equation $(x-a)(x-b)(x-c)(x-d)-9=0$,so $(r-a)(r-b)(r-c)(r-d)=9$ or $(a-r)(b-r)(c-r)(d-r)=9$ We need to find $(a-r)+(b-r)+(c-r)+(d-r)$ but i do not know how to find that.","['algebra-precalculus', 'roots', 'polynomials', 'quadratics']"
1613560,Sum(Partition(Binary String)) = $2^k$,"So given any binary string B: $$b_1 b_2 \dots b_n$$
$$b_i \in \{0,1\}$$ It would seem it is always possible to make a partitioning of B: $$ b_1 b_2 \dots b_{p_1}|b_{p_1 + 1}b_{p_1 + 2}\dots b_{p_2}|\dots|b_{p_m + 1}b_{p_m + 2}\dots b_n$$
$$= P_0 | P_1 |\dots|P_m$$ such that when $P_i$ is interpreted as the binary representation of an integer then: $$\exists{k}:\sum_{i=0}^{m}P_i = 2^k$$ For example here is the first few: 1 = 1
10 = 2
1|1 = 2
100 = 4
1|01 = 2
11|1 = 4
1000 = 8
1|00|1 = 2
10|10 = 4
1|0|11 = 4
... Additional examples are here: http://pastebin.com/3B2P4asC How can we prove this for all binary strings?","['number-theory', 'recreational-mathematics', 'discrete-mathematics']"
1613581,Moments of minimum of random variables,"Let $\mu$ be a non-atomic probability measure on $[0,\infty)$ and sample $X_1,X_2$ from $\mu$ independently. Does $\min(X_1,X_2)$ have twice as many moments as $X_1$? Is the quantity
$$
\frac{\mathbb E\min(X_1,X_2)}{\left(\mathbb E \sqrt{X_1}\right)^2}
$$
bounded away from $0$ and $\infty$? More generally, does $\min(X_1,\ldots,X_n)$ have $n$ times as many moments as $X_1$? Moreover is
$$
\frac{\mathbb E\min(X_1,\ldots,X_n)}{\left(\mathbb E \sqrt[n]{X_1}\right)^n}
$$
bounded away from $0$ and $\infty$? For nice distributions, the identity $\mathbb E X=\int \mathbb P(X>x)\; d\mu(x)$ allows us to reformulate the general versions as follows:
$$
\|\mathbb P(X_1>t)\|_n\approx\|\mathbb P(X_1>t^n)\|_1,
$$
where $\approx$ means bounded by constants.","['moment-problem', 'probability', 'random-variables']"
1613613,Calculus of variation with inequality constraints,"Find the function $y$ which maximizes the functional $$J[y] = \int_0^1 g(x) y(x) dx$$ subject to $0 \leq y(x) \leq 1$ for all $x\in [0,1]$ and $$\int_0^1 y(x) dx = k$$ where $g$ is a strictly increasing function. I know that I can take care of the isoperimetric constraint quite easily using the Lagrangian $$K[y] = \int_0^1 (g(x) y(x) + \lambda y(x)) dx$$ I also know that I can take care of constraints of the form $y(x) \leq 1$ using a substitution such as $u^2(x) = 1 - y(x)\geq 0$ to get $$K[u] = \int_0^1 \left( g(x) \left( 1 - u^2(x) \right) + \lambda \left( 1 - u^2(x) \right) \right) dx$$ However, I am quite at a loss with a constraint of the form $0 \leq y(x) \leq 1$ , i.e., when two inequalities are involved at the same time. How can I take care of this?","['inequality', 'calculus-of-variations', 'constraints', 'calculus']"
1613614,"When $x$ is a real number and $x>1$, why is $x^x>(x+1)^{x-1}$?","When $x$ is a real number and $x>1$, why is the following true? $x^x>(x+1)^{x-1}$ I tried finding the minimum of $x^x-(x+1)^{x-1}$ with my limited calculus knowledge, but it shortly appeared out of my range. It's good when I can understand a good answer, but I'd still be happy to come back years later when I'm better at math, so please don't hesitate to share your knowledge.","['calculus', 'proof-verification']"
1613639,Can you find the treasure??,"My big bro gave this problem one week ago. I could not still solve it.Please HELP. STORY A man was just looking for items in his store room. Suddenly he found a map , which showed then it stated
That if the man goes straight from the pole(P) to house A and turns 90* and moves to M such that PA=AM.
Similarly if he goes from P to B and turns 90* again to move from B to N such that BN=PN THEN a straight line MN is produced.In the midpoint of MN the TREASURE IS PRESENT. THE PROBLEM Now the man went to find the treasure but when he reached there he was shocked.
because the pole(P) was cut down (i.e the pole was absent from the place) NOW CAN HE FIND THE TREASURE???? thanks in advance!!","['analytic-geometry', 'problem-solving', 'euclidean-geometry', 'geometry']"
1613668,Nonempty intersection between approximate point spectrum and residual spectrum,"On the Wikipedia page on ""Spectrum (functional analysis)"", it is mentioned that the approximate point spectrum and residual spectrum are not necessarily disjoint. Is there a straightforward example to illustrate this? I can't come up with one.","['functional-analysis', 'spectral-theory']"
1613702,Find the eccentricity of a conic,"Find the eccentricity $e$ of the conic $$S \equiv 39x^2+11y^2-96xy+14x+2y-34=0.$$ My try: Comparing with general second degree conic $$ax^2+2hxy+by^2+2gx+2fy+c=0$$ we have $a=39$, $b=11$, $2h=-96$, $2g=14$, $2f=2$ and $c=-34$ The determinant $$\Delta=\begin{vmatrix}
39 &  -48&7 \\ 
 -48& 11 & 1\\ 
 7&1  & -34
\end{vmatrix} \ne 0$$ and $h^2-ab \gt 0$, and hence the conic is a Hyperbola. Now since there is $xy$ term one way is to rotate the axes to make $xy$ term zero by angle $$\tan(2\theta)=\frac{-96}{28}.$$ But the algebra is very tedious. Is there any other approach?","['conic-sections', 'geometry']"
1613740,What does $2^{\mathbb R}$ mean? [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 8 years ago . Improve this question Does it mean $2^{\mathbb R}= P{ (\mathbb R)}$ where $P$ is the power set. What does it mean in terms of functions like $l : 2^{\mathbb R} \rightarrow [0,+ \infty]$?","['notation', 'measure-theory', 'functions']"
1613758,Using definition of pre-image to prove $ X \subset f^{-1}(f(X)) $,I am trying to prove easy statements such as one listed here: http://mathworld.wolfram.com/Pre-Image.html My attempt: let $ x \in X$ then $f(x) \in f(X)$ so $x \in f^{-1}(f(X))$ but I am not really doing anything but looking at the definitions - how may i formalise this?,['discrete-mathematics']
1613782,$\pi$ -Hall normal subgroup is characteristic,"I've this exercise on my textbook: ""Show that if G is a group (not necessary soluble), a normal $\pi$ -Hall subgroup is characteristic."" I've tried to resolve it in the following way. 
Let $\alpha$ an automorhism of G; if H$\ne$H$^\alpha$ then since H is normal HH$^\alpha$ is a subgroup of G containing properly H. But, for order reasons HH$^\alpha$ is another $\pi$ -Hall subgroup of G, that is absurd. My solution is correct? Thanks in advice and sorry for my bad English!","['finite-groups', 'abstract-algebra', 'group-theory']"
1613811,Center of the group algebra of the symmetric group,"How to prove that the center of the group algebra of the symmetric group is generated by 1-cycle conjugacy classes? I mean, that the center (consisting on class functions) is multiplicatively generated by classes of cycle permutations.","['representation-theory', 'group-theory', 'symmetric-groups', 'symmetric-polynomials']"
1613855,Characteristic function of $\chi^2$ distribution with $n$ degrees of freedom,"I'm computing the formula for the characteristic function of the random variable $X \sim \chi^2(n), $ $n\in\mathbb{N}$. After some substitutions in the integral and some messing around with certain terms, I got: \begin{align*}
\varphi_X(t) &= E\left[e^{itX}\right] \\
&= \frac{1}{2^{n/2}\Gamma (n/2)} \int_0^{\infty} \! e^{itx-\frac{x}{2}}x^{\frac{n}{2}-1} \, \mathrm{d}x \\
&= \left| u=x\left(it-\frac{1}{2}\right) \implies \mathrm{d}u = \left(it-\frac{1}{2}\right)\mathrm{d}x \right| \\
&= \frac{1}{2^{n/2}\Gamma (n/2)} \left( it-\frac{1}{2} \right)^{-n/2} \int_0^{\infty} \! e^u u^{\frac{n}{2}-1} \mathrm{d}u \\
&= \left| y=-u \implies \mathrm{d}y = - \mathrm{d}u \right| \\
&= \frac{1}{\Gamma (n/2)}(2it-1)^{-n/2} \int_0^{-\infty} \! e^{-y} (-y)^{\frac{n}{2}-1} (-\mathrm{d}y) \\
&= \frac{1}{\Gamma (n/2)} (1-2it)^{-n/2} \int_0^{-\infty} \! e^{-y} y^{\frac{n}{2}-1} \mathrm{d}y.
\end{align*} So I've skipped some steps (like how I obtained the $(1-2it)^{-n/2}$ etc.) but that's beside the point. Could someone point me to an error I may have made? Or, tell me how I could get the integration limits to be from $0$ to $\infty$? Because then the integral would be $\Gamma(n/2)$ and my solution would be correct. Thanks!","['characteristic-functions', 'probability-theory', 'integration']"
1613857,$2^z$ behavior when changing real and imaginary components of $z$,"I'm reading The Music of the Primes by du Sautoy and I've come across a section that I'm having difficulty understanding: Euler fed imaginary numbers into the function $2^x$. To his surprise, out came waves which corresponded to a particular musical note. Euler showed that the character of each note depended on the coordinates of the corresponding imaginary number.  The farther north one is, the higher the pitch. The farther east, the louder the volume. My understanding here is that the results are dependent on the sine function and that the real part of the exponent affects the amplitude and the imaginary part of the exponent affects the frequency. I'd like to understand this more intuitively, which I tend to get through visualization.  So I went to Wolfram Alpha and started with graphing $2^{x+iy}$.  That wasn't very helpful. So I tried graphing it with fixed $x$ values , and indeed, I could see the amplitude of the (now 2D) graph changing . I also see that $2^{x+iy}$ is also expressed as $2^x \cos(y \log(2))+i 2^x \sin(y \log(2))$ and I think I can see that changing the value of $x$ would affect the amplitude. I'm unable to demonstrate the frequency changing by setting y to specific values. What am I missing? (...Other than a semester in a Complex Analysis class!) edit: So while reading more online, I came across this blog that makes a similar claim.  I suspect the book of oversimplifying, but wonder if this explains what was simplified? [...] But $x^{z-1} + x^{\bar{z} - 1}$ is just a wave whose amplitude depends on the real part of $z$ and whose frequency depends on the imaginary part (i.e., if $z=a+biz=a+bi$, then $x^{z-1} + x^{\bar{z}-1} = 2x^{a-1} cos (b \log x)$) [...] (I copied this from the blog, but removed some odd \'s ...) Is it the inclusion of the conjugates that causes this amplitude/frequency?","['complex-analysis', 'complex-numbers']"
1613877,Polyakov action in complex coordinates,"Let $\Sigma$ be a compact $2$-manifold with riemannian metric $g$ and $f:\Sigma \to \mathbf{R}^n$ given locally by $f_1(x_1,x_2),\dots,f_n(x_1,x_2)$. Define
$$
  S(f,g) = -\frac{1}{2\pi\alpha'}\int_{\Sigma}\left(\sum_{i=1}^n\sum_{k,j=1}^2g^{jk}(x)\frac{\partial f_i}{\partial x_j}\frac{\partial f_i}{\partial x_k}\right)\Phi,
$$
where $\Phi$ is the volume form. Suppose that $g$ is the euclidean metric. If $f:\Sigma \to \mathbf{C}^n$ is given locally by $\phi_1(z),\dots,\phi_n(z)$ (using a single complex coordinate for $\Sigma$), the source I'm following says the above changes to
$$
  S(f,g) = -\frac{i}{2\pi\alpha'}\int \sum_{j=1}^n\left(\frac{\partial \phi_j}{\partial z}\frac{\partial \overline{\phi_j}}{\partial \bar z} + \frac{\partial \overline{\phi_j}}{\partial z}\frac{\partial \phi_j}{\partial \bar z}\right) dz \wedge d\bar z.
$$ I get that in complex coordinates $\Phi = \frac{i}{2}dz \wedge d\bar z$ and $g^{jk} = 2$ if $j \neq k$ and $0$ otherwise, but I'm not sure how the $\overline{\phi_j}$ came up in the expression, and trying different guesses for what it should be didn't get me anywhere. What is going on here?","['complex-geometry', 'string-theory', 'differential-geometry']"
1613911,"For $n$ even, antipodal map of $S^n$ is homotopic to reflection and has degree $-1$?","How do I see that for $n$ even, the antipodal map of $S^n$ is homotopic to the reflection$$r(x_1, \dots, x_{n+1}) = (-x_1, x_2, \dots,  x_{n+1}),$$and therefore has degree $-1$? Thanks for your time. Progress. I think we want to create a continuous transformation from$$ \begin{pmatrix} -1 & 0 & \ldots & 0 \\ 0 & -1 & \ldots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \ldots & -1 \end{pmatrix}$$to$$ \begin{pmatrix} -1 & 0 & \ldots & 0 \\ 0 & 1 & \ldots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \ldots & 1 \end{pmatrix}?$$","['differential-topology', 'manifolds', 'algebraic-topology', 'general-topology', 'differential-geometry']"
1613939,What is the difference between linear manifold and linear vector subspace?,"Does linear manifold need to be closed in summation and multiplication? If it needs to be, then it seems it is the same as a linear vector subspace. However, some people mention in infinite dimension case, they are different.","['terminology', 'linear-algebra']"
1613956,Estimating Number of Scratch Tickets Remaining,"So, in my statistics class we discussed the recent huge jackpot, but we decided to focus on something more ""trackable""—scratch tickets.
A part of the assignment is to figure out how many tickets are remaining given the following data: chances of winning , number of prize brackets , number of prizes in each bracket , and number of prizes remaining in each bracket . I've made the following example in order to figure out an approach to solve this: 1 in 3 chance of winning , 3 prize brackets (e.g. $50, $25, $5) , 1, 3, 7, prizes in each bracket (respectively) and 1, 2, 5, prizes remaining (respectively) . Obviously, we know for a fact that at least 3 tickets were sold (3-2)+(7-5) = 3 , meaning that there are 30 tickets left. However, this isn't the best conclusion for how many tickets are remaining given that the chances of winning are 1 in 3. I'm having trouble figuring out how the 1 in 3, would factor in to show how possibly more than 3 tickets were sold given the number of prizes already claimed. Any suggestions?","['statistics', 'probability', 'education']"
1613964,Integral $\int_0^1(x(1-x))^n\frac{d^n}{d^n x}(\log x \cdot\log (1-x))dx$,"While playing around with the first values of the integral $$
I_n:=-\int_0^1\left(x(1-x)\right)^n\frac{d^n}{d^nx}\left(\log x \cdot\log (1-x)\right){\rm d}x, \quad \quad n=1,2,3,\cdots,
$$ I got 
$$
\small{\begin{align}
I_1&=0,&I_2&=\frac19,&I_3&=0,&I_4&=\frac3{25},\\
I_5&=0,&I_6&=\frac{40}{49},&I_7&=0,&I_8&=\frac{140}{9},\\
I_9&=0,&I_{10}&=\frac{72576}{121},&I_{11}&=0,&I_{12}&=\frac{6652800}{169},\\
I_{13}&=0,&I_{14}&=\color{#99004d}{3953664},&I_{15}&=0,&I_{16}&=\frac{163459296000}{289},\\
I_{17}&=0,&I_{18}&=\frac{39520825344000}{361},&I_{19}&=0,&I_{20}&=\color{#99004d}{27583922995200},\\
I_{21}&=0,&I_{22}&=\frac{4644631106519040000}{529},&I_{23}&=0,&I_{24}&=\color{#99004d}{3446935565184663552},\\
I_{25}&=0,&I_{26}&=\color{#99004d}{1636721540923392000000},&I_{27}&=0,&I_{28}&=\frac{777776389315596582912000000}{841},\\
I_{29}&=0,&I_{30}&=\cdots.
\end{align}}
$$ By splitting up the initial integral into $\displaystyle \int_0^{1/2}$,  $\displaystyle \int_{1/2}^1$ and by using the symmetry of the integrand, I've indeed proved that $I_{2n+1}=0, \, n=0,1,2,3,\cdots.$ Now observing the first values above, my question is: Does the integral $I_{2n}$ take on infinitely integer values?","['integration', 'definite-integrals', 'sequences-and-series', 'calculus']"
1613968,Homeomorphism between disk without two antipodal points and half-open square.,"Let $D^{2}$ be the unit disk in $\mathbb{R}^{2}$. Let $X=D^2-\{(0,1),(0,-1)\}$. Let $S$ be the square defined by $[-1,1] \times(-1,1)$. I was asked to find a homeomorphism from $f:X \to S$. Let $r^2=x^2+y^2$. Then, let $$f(x,y)=\frac{\sqrt{r^2+\min\{|x|,|y|\}^2}}{r}\cdot[x,y]$$ Basically, I want to just project every point in the disk outward so that it intersects the square. I feel that the bijectivity of this function is readily apparent. My main question is now how to prove that it is continuous (using only the most fundamental definition of continuity) Edit: if an alternative homeomorphism is provided, please also give proof that both $f$ and $f^-1$ are continuous, this is most of the difficulty for me .",['general-topology']
1613973,When doesn't a supremum exist?,"Other than ∞, is there another case where a supremum (or an infimum for that matter) doesn't exist?",['real-analysis']
1613991,Solution of $y'=(1+x)(1+y)$,"Differential equation: $$y'=(1+x)(1+y)$$ which is: $$y'=y(1+x)+1+x$$. Like this differential equation I try to solve by: $$y'(x)=a(x)y+b(x) $$ which solves non-homogenous differential equation.
In this case a(x)=1+x and b(x)=1+x are similar. We have:
$$y(x)=c(x)e^{\int a(x)dx}$$ and $$c(x)=\int b(x)e^{\int a(x)dx}dx$$
I am trying with this method but I can't get solution. What I got is:
$$y(x)=e^{\frac{1}{2}x(x+2)}$$ but this doesn't work. Where is my mistake or is any better way to solve it?",['ordinary-differential-equations']
1614050,Expected Value of Maximum of Two Lognormal Random Variables,"We have two random variables $X$ and $Y$ which are log normally distributed, with suitable parameters, what is the expected value for $\max(X,Y)$? Given, $$
X=e^{\mu+\sigma Z_{1}};\quad Y=e^{\nu+\tau Z_{2}};\quad Z_{1}\sim N(0,1);Z_{2}\sim N(0,1);
$$ $Z_{1}, Z_{2}$ can be assumed independent if it simplifies matters. We need to find an expression for $$E[\text{max}(X,Y)]$$ Please note I have reached the step below, but am unsure how to proceed further. Steps Tried \begin{eqnarray*}
E\left[\max\left(X,Y\right)\right]=\int_{0}^{\infty}xf_{Y}\left(x\right)F_{X}\left(x\right)dx+\int_{0}^{\infty}yf_{X}\left(y\right)F_{Y}\left(y\right)dy
\end{eqnarray*}
\begin{eqnarray*}
\int_{0}^{\infty}xf_{Y}\left(x\right)F_{X}\left(x\right)dx{\displaystyle =\int_{0}^{\infty}\frac{1}{\tau}\phi\left(\frac{\ln x-\nu}{\tau}\right)}\Phi\left(\frac{\ln x-\mu}{\sigma}\right)dx
\end{eqnarray*}
\begin{eqnarray*}
{\displaystyle =\int_{0}^{\infty}\frac{1}{\tau}\phi\left(\frac{\ln x-\nu}{\tau}\right)}\Phi\left(\frac{\ln x-\mu}{\sigma}\right)dx\quad\text{, Substitution }u=\left(\frac{\ln x-\nu}{\tau}\right)\Rightarrow du=\frac{1}{x\tau}dx
\end{eqnarray*}
\begin{eqnarray*}
{\displaystyle =\int_{-\infty}^{\infty}e^{u\tau+\nu}\phi\left(u\right)}\Phi\left(\frac{u\tau+\nu-\mu}{\sigma}\right)du
\end{eqnarray*}
\begin{eqnarray*}
{\displaystyle =e^{\nu}\int_{-\infty}^{\infty}e^{u\tau}\phi\left(u\right)}\Phi\left(\frac{u\tau+\nu-\mu}{\sigma}\right)du
\end{eqnarray*} Related Question Please note, an earlier question considers the case where there is only one source of randomness. This earlier question was mis-phrased due to my limited knowledge; but still provides an interesting and instructive solution. Expected Value of Maximum of Two Lognormal Random Variables with One Source of Randomness Please let me know of any other suggestions …","['expectation', 'probability', 'probability-distributions']"
1614052,Differential Equations to solve the changing radius of a drop of liquid,"This is the question: ""Your lab partner leaves a drop of bleach on the lab bench, which takes the shape of a hemisphere. The drop initially has a radius of 1.6mm, and evaporates at a rate proportional to its surface area. After 10 minutes, the radius is 1.5mm. How long until the drop is gone?"" What I currently have is $\frac{dv}{dr}=A$ where $v$ is volume and $A$ is the surface area of the drop. I was thinking of using the equation $\frac{dv}{dr} \frac{dr}{dt}$ and trying to solve the equation using $\frac{dr}{dt}=\frac{1.6-1.5}{10}$, is my approach to this correct?",['ordinary-differential-equations']
1614060,Solving the absolute value inequality $\big| \frac{x}{x + 4} \big| < 4$,"I was given this question and asked to find $x$:
$$\left| \frac{x}{x+4} \right|<4$$ I broke this into three pieces:
$$
\left| \frac{x}{x+4} \right| = \left\{
        \begin{array}{ll}
            \frac{x}{x+4} & \quad x > 0 \\
            -\frac{x}{x+4} & \quad -4 < x < 0 \\
            \frac{x}{x+4} & \quad x < −4
        \end{array}
    \right.
$$ Solving,
$$4>\frac{x}{x+4}$$
$$4x+16>x$$
$$3x>-16$$
$$x>-\frac{16}{3}=-5.3$$ and
$$4>-\frac{x}{x+4}$$
$$4x+16>-x$$
$$5x>-16$$
$$x>-3.2$$ The answer is $x<-5.3$ and $x>-3.2$. What am I doing wrong?","['algebra-precalculus', 'inequality', 'absolute-value']"
1614079,Short exact sequence on $\mathbb{P}^1$,Let F be a torsion free sheaf of rank $n+4$ over $\mathbb{P}^1$ which fits in the SES $0\longrightarrow\mathcal{O}_\mathbb{P^1}(-3)^{n+2}\longrightarrow F\longrightarrow\mathcal{O}_{\mathbb{P}^1}(-1)^2\longrightarrow0$ Is $F\simeq\mathcal{O}_{\mathbb{P}^1}(-3)^n\oplus\mathcal{O}_{\mathbb{P}^1}(-2)^4$? The reason for this guess is the Koszul SES $0\longrightarrow\mathcal{O}_{\mathbb{P}^1}(-3)\longrightarrow\mathcal{O}_{\mathbb{P}^1}(-2)^2\longrightarrow\mathcal{O}_{\mathbb{P}^1}(-1)\longrightarrow 0$,"['reference-request', 'exact-sequence', 'vector-bundles', 'algebraic-geometry']"
1614095,Can anyone explain this equation (about $\frac\pi2$ ),"$${\frac{\pi}{2} = \lim_{l \to \infty} \prod_{j = 1}^{l + 1} \frac{(2j)(2j)}{(2j - 1)(2j+1)}}$$ Hi all. My first impression of this equation is naive curiosity why ""limit"" is required. Can I just drop the limit sign and replace $l+1$ by $\infty$? Or If ""limit"" can not be omitted, why would we multiply all the terms upto $l+1$? Does it change anything if I replace $l+1$ by $l$?","['real-analysis', 'analysis']"
1614131,Construction of Tate curve and formal schemes,"In the notes websites.math.leidenuniv.nl/geom/tate.ps (and probably in other places), there is a construction of the Tate curve, where the steps are summarized below. 1) Take $\mathbb{P}^{1}_{\mathbb{C}[[q]]}$. We could do it over $\mathbb{Z}[[q]]$, but that's not what I want to focus on. 2) Take the 0 and $\infty$ sections over the generic fiber, and then take the intersection of the closures with the special fiber. If we are working over $\mathbb{C}$, then the intersection is two points. Blow up at those two points. 3) Repeat step 2 over and over. 4) In the limit, we will get a scheme $T$ over $\mathbb{Z}[[q]]$ where over the special fiber we get a countable chain of $\mathbb{P}^{1}$. 5) Take $n^{th}$-order neighborhoods of the fiber over the generic point, quotient by $\mathbb{Z}$ to get schemes $X_n$, then take the limit to get a formal scheme. Apply Grothendieck's algebraization theorem to get the Tate curve. I think I'm supposed to understand that we're taking the quotient ""$K^{\times}/q^{\mathbb{Z}}$"", where $T$ above is supposed to be a substitute for $K^{\times}$ in the formal scheme case. Do you know of a reference where I can learn about formal schemes in order to understand this? To a beginner like me, $T$ looks ugly and unmotivated.","['algebraic-geometry', 'reference-request', 'number-theory', 'schemes', 'elliptic-curves']"
1614133,The two definitions of a compact set,"In general, $A$ is compact if every open cover of $A$ contains a finite subcover of $A$. In $R$, $A$ is compact if it is closed and bounded. The second is very easy to understand because I can easily come up with an example like $[0,1]$ which is both closed and bounded so it's compact. However, I am very confused at definition (1) because I don't really understand what is meant by a cover and I don't understand how this is really related to a set being closed and bounded? Could someone please explain what is the relationship between (1) and (2)? Thank you.","['general-topology', 'real-analysis', 'compactness']"
1614137,the ant walk (year $12$) [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question An ant stands in the middle of a circle ($3$ metres in diameter) and walks in a straight line at a random angle from 0 to 360 degrees. Problem is, it can only walk one metre before it needs a break, the ant has the memory of a fish and forgets what direction it has just walked in.After the break, it gets all dizzy and thus chooses another random direction from $0$ to $360$ in an attempt to escape the circle again. As you can well imagine, it could escape the circle after just 2 walks (just one break needed). Or... it could take $20,000$ walks ($19,999$ breaks needed)!! There might even be the very slim possibility it might take ${20,000}^{20,000}$ walks. What is the average amount of walks required for the ant to escape the circle?","['probability', 'geometry']"
1614146,Tangent Surface to a 4D Surface,"I have been typing up notes for Multivariable Calculus. While doing so I have been pondering the terms I ought to use for higher dimensional surfaces and the associated tangent surfaces. With a curve  in $\mathbb R^2$ the tangent ""surface"" is a line. With a surface in $\mathbb R^3$ the tangent surface is a plane. However, this is where I am stuck... What is the equivalent tangen surface to a given surface in $\mathbb R^4$? Intuition tells me that it would be a rectangular prism with infinite length on each edge and thus infinite volume, but I am not even sure of this, not to mention what I ought to call such a surface in my notes. Thus far I have simply called the tangent surface in $\mathbb R^n$ an $n$-plane, but this doesn't seem very formal.","['multivariable-calculus', 'calculus', 'vector-spaces']"
1614224,How to show $\operatorname{curl}\operatorname{curl}(e_r) = 0$,"$\DeclareMathOperator{curl}{curl}$ I want to figure out how to calculate $\text{curl}(e_r$ ). Where $e_r$ is a base vector for the Spherical co-ordinate system. Taking $e_r = (\sin\theta \cos\phi)i+(\sin\theta \sin\phi)j+(\cos\theta)k$ and I tried taking the $\text{curl}(e_r)$ as follows, $\text{curl }e_r=\begin{vmatrix}i & j & k\\ \frac{\partial}{\partial r} & \frac{\partial}{\partial \theta} & \frac{\partial}{\partial \phi}  \\ (\sin\theta \cos\phi) & (\sin\theta \sin\phi) & (\cos\theta)\end{vmatrix}$ And then took the $\operatorname{curl}$ again for the output of the above. But this gives a non-zero value. I would like to know whether the above steps and the values I am using for $e_r$ are correct. If not can you please tell me what I am doing wrong.","['multivariable-calculus', 'curl', 'spherical-coordinates', 'vector-analysis']"
1614287,Unique factorization theorem in algebraic number theory,"Consider the set $S = a + b \sqrt {-6}$, where $a$ and $b$ are integers. Now, to prove that unique factorization theorem does not hold in set $S$, we can take the example as follows: $$
10 = 2 \cdot 5 = (2+\sqrt {-6}) (2-\sqrt {-6})
$$
""Thus we can conclude  that there is not unique factorization of 10 in set $S$. Note that this conclusion does not depend on our knowing that $2+\sqrt {-6}$ and $2-\sqrt {-6}$ are primes; they actually are, but it is unimportant in our discussion. "" Can someone explain why the conclusion is independent of nature of $2+\sqrt {-6}$ and $2-\sqrt {-6}$. Basically, unique factorization theorem is based on the fact that factors are primes. So, why is it independent? Note: This is from the book An Introduction to the Theory of Numbers , 5th Edition by Ivan Niven, Herbert S. Zuckerman, and Hugh L. Montgomery.","['number-theory', 'algebraic-number-theory']"
1614289,How to make sense of $(1-e^{tD})f$?,"I'm sophomore student in college. Recently, I'm thinking about series expansion of operators. When I supposed that f is an $C^\infty$-function and D is the differential operator d/dt. According to integation by parts,
$$ \begin{align} \int f'(t) dt &=tf'-\int tf''(t) dt \\ &=tf'-\frac{1}{2}t^2f''+\int \frac{t^2}{2}f'''dt \\ &= \left (\frac{tD}{1!}-\frac{(tD)^2}{2!}+\frac{(tD)^3}{3!}- \dots \right ) f \\ &=\left ( 1-e^{-tD} \right )f \end{align} $$ seems to make sense. But I don't know about 'functional analysis' or 'operator theory', etc.
I want to know how can I make a proof of things like that. What should I study to proof that?","['operator-theory', 'sequences-and-series', 'analysis', 'functions']"
1614337,Borel set that is not countable union or intersection of open or closed sets,"In this previous question, one can read the following: It is important to keep in mind, by the way, that Borel sets are more than just countable unions and intersections of open and closed sets. I tried to find an explicit example of a Borel set $A$ that can't be written only using a finite number of the following operations : countable unions of open or closed sets ; countable intersections of open or closed sets. I know that there are examples of Borel sets that are neither $G_{\delta}$ nor $F_{\sigma}$, but I could write them using the two operations above. According to this article on Borel hierarchy (if I understood it well), a Borel set can be obtained by a countable number of the two operations above. Thank you for your comments!","['lebesgue-measure', 'measure-theory']"
1614380,Equivalent condition for a linear map to coincide with another restricted to a line modulo certain hyperplane.,"Let $p$ be a line of the vector space $K^{n+1}$, and let $H$ be a hyperplane of $K^{n+1}$ such that $p\subseteq H$. We may also interpretate $H$ as a line $q\subseteq(K^{n+1})^{*}$. Let $\alpha\in\mathrm{Hom}(p,K^{n+1}/p), \beta\in\mathrm{Hom}(H,K^{n+1}/H)$. We can understand $\beta\in\mathrm{Hom}(q,(K^{n+1})^{*}/q)$. Let $v\in p,w\in q$. In p.208 of Harris's 'Algebraic Geometry: A first course' it is said that the condition
$$
\langle\alpha(v),w  \rangle+\langle v,\beta(w)\rangle=0\quad\text{ for } v\in p,w\in q
$$
where $\langle, \rangle$ is the map of the dual pairing, is equivalent to
$$
\beta|_{p}\equiv\alpha \text{ }(\mathrm{mod}\text{ } H).
$$
I don't really understand why this is true. Any hint would be appreciated.","['linear-algebra', 'algebraic-geometry', 'duality-theorems']"
1614392,Determinant of a function,"I was thinking about matrices and then why arent there matrices with uncountable many values? (Probably this conecpt already exists for a very long time, but i don't know it) Assume there are matrices $A$ and $B$ with the size $N\times N$. Then the product $C=A*B$ is defined as:
$$
C_{y,x}=\sum_{k=1}^N{A_{y,k}*B_{k,x}}
$$ Now this could to be done with an uncountable matrix (which is just a function): $$
A(x,y)=x^2+y, B(x,y)=x*y
$$ for $$
x, y\in[0,N]
$$ Then the value of $C=A*B$ ($*$ for the ""special matrix multiplication"") could be defined as:
$$
C(x,y)=\int\limits_0^N{A(k,y)*B(x,k)}\mathrm{d}k
$$ Now we can multiply two matrices with uncountable many values. There is also a neutral element which can be defined as $e(x,y)=\delta(x-y)$ (dirac delta function). Of course also vector with uncountable many values could be defined: $$
b(y)=exp(y)
$$ It is also no problem to define a multiplication of such a matrix and such a vector: $$
A(x,y)=x^2+y, b(y)=exp(y)
$$
for
$$
x,y\in[0,N]
$$ $$
C(y)=A*b=\int\limits_0^N{A(y,k)*b(k)}\mathrm{d}k
$$ And now another thing could be defined. A simple equation ($A,b$ are known, $x$ is unknown): $$
A(x,y)*x(y)=b(y)
$$ Or simpler:
$$
Ax=b
$$ Which is equal to:
$$
\int\limits_0^N{A(y,k)*x(k)}\mathrm{d}k=b(y)
$$ Now it is not obvious if such an equation has a solution or not. Is it possible to generalize the classic determinant to a function $f(x,y)$, where $x,y\in[0,N]$? So that it is possible to see if such an equation has a unique solution. All things here were just copied from the classic linear algebra, so i think something like a determinant should also be available? Thank you very much best regards Kevin","['matrix-equations', 'definite-integrals', 'linear-algebra', 'determinant']"
1614407,Problems with proving two sets are equal,Can someone help me with this? I tried solving it but I got stuck,['elementary-set-theory']
1614437,limit involving trig functions,"I'm not sure how to solve this limit.
$$
\lim_{x\to 0} \frac{\tan 6x}{\sin 2x}
$$ After some rearranging I get this. $$
\lim_{x\to 0} \frac{\sin 6x}{\cos 6x} \cdot \lim_{x\to0} \frac{1}{\sin 2x}
$$ I know the limit is 3, but how do you get there using algebra? What am I missing?","['trigonometry', 'limits']"
1614459,"Show that $d'(x,y)=\min\{1,d(x,y)\}$ induces the same topology as $d$","Let $(M,d)$ be a metric space and define: $d' : M$x$M \rightarrow R$ Show that $d'(x,y)=\min\{1,d(x,y)\}$ induces the same topology as $d$ I know that $d'$ defines a metric on M, since d is a matric (satisfying positivity, symmetry and triangle inequality. But how do I show it induces the same topology?","['general-topology', 'metric-spaces']"
1614468,Conjectured closed form for $\sum_{n=-\infty}^\infty\frac{1}{\cosh\pi n+\frac{1}{\sqrt{2}}}$,"I was trying to find closed form generalizations of the following well known hyperbolic secant sum
$$
\sum_{n=-\infty}^\infty\frac{1}{\cosh\pi n}=\frac{\left\{\Gamma\left(\frac{1}{4}\right)\right\}^2}{2\pi^{3/2}},\tag{1}
$$
as
$$
S(a)=\sum_{n=-\infty}^\infty\frac{1}{\cosh\pi n+a}.
$$
In particular I find by numerical experimentation
$$
\displaystyle \frac{\displaystyle\sum_{n=-\infty}^\infty\frac{1}{\cosh\pi n+\frac{1}{\sqrt{2}}}}{\displaystyle\sum_{n=-\infty}^\infty\frac{1}{\cosh\pi n}}\overset{?}=-\frac{1}{2}\left(1+\sqrt{2}\right)+\sqrt{2+\sqrt{2}}\tag{2}
$$
(Mathematica wasn't able to find a closed form directly, but then I decided to switch to calculation of ratios of the sums, calculated ratios numerically and then was able to recognize this particular ratio as a root approximant. This was subsequently verified to 1000 decimal places). I simplified this expression from the previous edition of the question. Unfortunately for other values of $a$ I couldn't find a closed form. Of course $(2)$ together with $(1)$ would imply a closed form for the sum $S(1/\sqrt{2})$ How one can prove $(2)$?","['calculus', 'closed-form', 'number-theory', 'sequences-and-series', 'analysis']"
1614484,"Show that $O(n)$, the set of orthogonal $n \times n$ matrices, is not connected","I want to show that $O(n)$, the set of orthogonal $n \times n$ matrices is not connected. I know that a connected space $X$ does not split into disjoint non-empty open subsets, so to prove $O(n)$ is not connected I need to find disjoint non-empty open subsets that partition $O(n)$. But I have not been able to get any Any help would be much appreciated","['matrices', 'orthogonal-matrices', 'general-topology', 'connectedness']"
1614506,Finding Laurent's series of a function,"I am trying express the function $$f(z)=\frac{z^3+2}{(z-1)(z-2)}$$ like a Laurent's series in each ring centering in $0$, but I do not now how could I express it, in first I said that $$f(z)=(z^3+2)\left[\frac{1}{z-2}-\frac{1}{z-1} \right] $$ Ok, now, I see two posibilities: $A\equiv open\ ring=A(C;r,R)$ where $$C\equiv center\\ r<R$$
so, I see: $a)$ $A(0;1;2)$ $b)$ $D(0,1)\cup\{\mathbb{C}-\overline{D}(0,2)$ It is correct? Ok, then I suposse that $a)$ I think that I have to try express like series of potence with $\frac{1}{z}$, and in the second case, $b)$, in $\overline{D}(0,1)$ like potences of $z$ and in $\mathbb{C}-\overline{D}(0,2)$ like potences of $\frac{1}{z}$ but I can not, I need someone help, please. All I know is that $\sum_{0}^{\infty} z^n=\frac{1}{1-z}$ when $|z|<1$ I do not know if it is so, I need someone clarify my doubts","['laurent-series', 'complex-analysis', 'power-series', 'functions']"
1614574,"Can we create an ""integration by parts"" with quotient rule?","Product rule says that $(uv)' = u'v + uv'$, so $\int (uv)' = \int (u'v + uv')$ implies $uv = \int u'v + \int uv'$ and this implies $$\int uv' ~dx = uv - \int u'v ~dx$$ This is integration by parts. I am wondering if this also works with quotient rule: $(u/v)' = \frac{vu' - uv'}{v^2}$ so $\int(u/v)' = \int\frac{vu' - uv'}{v^2}$ implies $u/v = \int\frac{vu'}{v^2} - \int\frac{uv'}{v^2}$ and also $$\int\frac{u'}{v} ~ dx = u/v +  \int\frac{uv'}{v^2} ~ dx$$ I am not sure if this relationship would have any uses but would it be a valid method?","['integration', 'soft-question', 'calculus']"
1614607,"Combinatorics problem; counting in two ways, china 1993","I'm trying to solve the combinatorics problems provided in Yufei Zhao's blog. Can you help me with this one? China (1993): A group of $10$ people went to a bookstore. It is known that Everyone bought exactly $3$ books; For every two persons, there is at least $1$ book that both of them bought. What is the least number of people that could have bought the book purchased by the greatest number of people?","['pigeonhole-principle', 'combinatorics', 'contest-math']"
1614615,Central Limit Theorem for Lévy Process,"I am reading a book, which uses the Central Limit Theorem of Lévy Processes $X_t$ without mentioning the exact theorem. 
Due to the infinite divisible property I can write $X_t$ as a sum of $N$ iid random variables $X^i$
$$
X_t=\sum_{i=1}^N X^i_{t/N}
$$
The Problem is, that i want $t\rightarrow \infty$ but for the CLT i have to keep my sequence of my equidistant iid random variables fixed (like $t/N$ fixed). But they do change, as $t\rightarrow \infty$.
The book now just says, that with the central limit theorem for Lévy Processes it holds for $t\rightarrow \infty$
\begin{align}
\frac{X_t-\overbrace{tE[X_{1}]}^{=E[X_t]}}{\sqrt{t}}\rightarrow \mathcal{N}(0,\operatorname{Var}[X_1])\\
\sqrt{t} \left(\frac{X_t}{t}-E[X_1])\rightarrow \mathcal{N}(0,\operatorname{Var}[X_1]\right)
\end{align}
I can't find any proofs, lectures or literature about it. Can you help me out?","['stochastic-processes', 'probability-theory', 'levy-processes', 'central-limit-theorem']"
1614617,Polarization of quadratic form yields sesquilinear form,How does polarisation of any quadratic form $Q: V \to \mathbb{C}$ on a complex vector space $V$ yields a sesquilinear form?,"['functional-analysis', 'sesquilinear-forms', 'quadratic-forms', 'hilbert-spaces']"
1614643,Is there a relationship between isometry as defined on metric spaces and those on vector spaces?,"I am taking a course on linear algebra and another on real analysis. In linear algebra we defined that two vector spaces are isomorphic if
there existed a bijective and linear map between the two vector spaces In real analyis we defined that two metric spaces are isometric if there existed a bijective, distance preserving map $d(x,y) = d'(fx, fy)$
  between the two metric spaces I looked up the definition of isometry online and many sources tell me it is a bijective ""structure preserving"" map. Is there some commonality between these so called structures? Or is it hopeless for me to guess what would be an isomorphism defined between topological spaces, Hilbert spaces or Banach spaces until I see the definitions?","['real-analysis', 'terminology', 'category-theory', 'linear-algebra', 'definition']"
1614647,Calculus of Variations Problem involving mixed constraints,"Motivation Let  $X$ be $\mathcal{N}\Big(-\frac{\sigma^2}{2},\sigma^2\Big)$ random variable, i.e. probability density function $f(x)$ is given by
\begin{equation}
f(x)=\frac{1}{ \sqrt{2\pi\sigma^2} } \exp\Bigg(\frac{-\big(x+\frac{\sigma^2}{2}\big)^2}{2\sigma^2}\Bigg)\quad \text{and}\quad F(x)=\int_{-\infty}^{x}f(x)dx
\end{equation}
With this choice of mean and variance $\mathbb{E}\big[e^X\big]=1$,$\forall x$. Assume $\mathbb{E}\big[X^2\big]\leq80$. This constraint gives that $0<\sigma\leq4$. Now we want to maximise $\mathbb{E}\big[(e^X-1)^+\big]$ w.r.t. $F$ (or $f=F'$), so that the following integral is maximised
\begin{equation}
\int_{0}^{\infty}(e^x-1)f(x)dx
\end{equation}
It turns out it is maximised by choosing $\sigma=4$, i.e. the second moment is highest possible. Now consider the generalisation of this problem in the sense that we allow $X$ to be any continuous random variable and thus we try to find the maximising density or distribution function. I think this leads to the Variational Calculus problem. PROBLEM Let $F:\mathbb{R}\to[0,1]$ be a non-decreasing absolutely continuos function such that 
\begin{equation}
\lim_{x\to-\infty}F(x)=0 \quad \text{and} \quad \lim_{x\to\infty}F(x)=1
\end{equation}
and $\exists$ $f:\mathbb{R}\to [0,\infty]$ such that
\begin{equation}
F(x)=\int_{-\infty}^xf(u)du
\end{equation}
i.e. $F'(x)=f(x)$.
Now consider the problem
\begin{equation}
\max_{F\in\mathcal{C}^1}J\big[x,F'(x)\big]
\end{equation}
where
\begin{equation}
J\big[x,F'(x)\big]:=\int_{-\infty}^\infty(e^x-1)\mathbb{1}_{(x\geq0)}F'(x)dx
\end{equation}
subject to
\begin{equation}
I_0\big[F'(x)\big]:=F'(x)\geq0 \quad \forall x
\end{equation} \begin{equation}
I_1\big[x,F'(x)\big]:=\int_{-\infty}^\infty e^xF'(x)dx-1=0
\end{equation} \begin{equation}
I_2\big[F'(x)\big]:=\int_{-\infty}^\infty F'(x)dx-1=0
\end{equation} \begin{equation}
I_3\big[x,F'(x)\big]:=Q-\int_{-\infty}^\infty x^2F'(x)dx\geq0
\end{equation}
for some real constant $Q>0$. Note that I defined $J$ and $I$'s to be functions of $x$ and $F'(x)$ only since they do not depend on $F(x)$ explicitly. I am trying to follow the Euler-Lagrange Equation (ELE) method. So my Lagrangian is
\begin{equation}
L\big[ x,F,F'\big]= J+ \lambda_0(x) I_0+\lambda_1 I_1 +\lambda_2 I_2 +\lambda_3 I_3
\end{equation}
Then ELE reads
\begin{equation}
\frac{dL}{dF}-\frac{d}{dx}\Big(\frac{dL}{dF'}\Big)=0
\end{equation}
Which I do not know how to compute in this case (my calculations give some non-sensical results). Also I think Lagrangian may not be correct since last constraint (with $I_3$) is inequality. My attempt: since none of the integrals depend on $F$ and just on $x$ and $F'$
\begin{equation}
\frac{d}{dx}\Big((e^x-1)\mathbb{1}_{(x\geq0)} + \lambda_0(x)+\lambda_1e^x + \lambda_2+ \lambda_3x^2\Big) =0
\end{equation}
and thus
\begin{equation}
e^x\mathbb{1}_{(x\geq0)} + \lambda_0(x)+\lambda_1e^x +\lambda_2+ \lambda_32x=c
\end{equation}
If I am correct now I should take partial derivatives of $L$ w.r.t. each of lambda and that would yield the constraints $I_0$, $I_1$, $I_2$, $I_3$. I guess I am doing something wrong or just cannot see how equation obtained from ELE would help me to find $F$. **Note: ** I think I am having problems with this because the optimal solution may be discontinuous and that is why ELE does not work.","['functional-analysis', 'calculus-of-variations', 'calculus', 'derivatives']"
1614673,"Is there an holomorphic function? If that function exists, is it unique?","I am solving a problem that asked me if exist an holomorphic function which satisfies only two condition. both equally: $$ f\left(\frac{1}{\alpha n} \right)=0\ \ \ \ and\ \ \ f\left( \frac{1}{\alpha n+1}\right)=1$$ where $\alpha, n \in \mathbb{N}$ where $\alpha$ is unique I think that I have to use Identity theorem for holomorphic function. Someone could help me with this? thanks for all. Note: I do not know if $f$ is or not holomorphic. (namely, I have to prove that exist, first, at least holomorphic function)","['functional-analysis', 'complex-analysis', 'functions']"
1614677,The equation $-1 = x^2 + y^2$ in finite fields,"In an ordered field we have $x^2 \ge 0$, hence the equation $-1 = x^2 + y^2$ has no solution. But what about finite fields in general? What is the solutions set
$$
 -1 = x^2 + y^2
$$
of this equation?","['finite-fields', 'abstract-algebra', 'field-theory']"
1614716,Is the integral $\int e^{2 \pi i z^2} dz$ uniformly bounded for any interval of $\mathbb{R}$?,"I was wondering if there exists a constant $C$ such that 
$| \int_I e^{2 \pi i z^2} dz | \leq C $ for any interval $I$ of $\mathbb{R}$?
Here I want $C$ to be independent of the choice of the interval $I$. 
Also $I$ is not necessarily a finite interval. 
I would any appreciate hint! Thank you!","['complex-analysis', 'improper-integrals', 'integration']"
1614774,Prove that $X_n \to X$ in $L^1$ if and only if $E(X_n1_{A}) \to E(X1_{A})$ uniformly on $A \in \mathcal{F}$,"This is a probability exercise from the Karr's book called ""Probability"". Prove that $X_n \overset{L^1}{\rightarrow} X$ if and only if $$\sup_{A \in \mathcal{F}} \left|E(X_n1_{A}) - E(X1_{A})\right|\rightarrow 0.$$ Where, according to the book's notation, $X_n$ is a sequence of rv's, $A$ is an event and $\mathcal{F}$ the $\sigma$ -algebra associated to $X_n$ , while $1_A$ denotes the indicator function over the set $A$ . My guess is that since convergence in $L_1$ implies uniform integrability, one could use this fact to proceed, but I am completely stuck.","['probability-theory', 'lp-spaces', 'expectation']"
1614806,Discrete valuation fields and representation as power series,"Let $(K,v)$ be a discrete valuation field ($v$ is surjective). Let $\mathcal O$ be the ring of integers of $v$ and moreover let $\mathfrak p$ be the unique maximal ideal of $\mathcal O$. Then we have the following theorem: Let $R\subset\mathcal O$ be a set of representatives for the residue field $\mathcal O/\mathfrak p$ such that $0\in R$. Then the completion $\widehat K$ (of $K$ w.r.t. $v$) is the set :
  $$\mathscr L:=\left\{\sum_{i\ge -m} a_i\pi^i\,:\, a_i\in R,\;a_{-m}\neq 0,\ \right\}$$
  where $\pi\in\mathcal O$ is an element such that $v(\pi)=1$. In other words every element of $\widehat K$ has a unique representation as convergent power series. Fundamental remark : We can endow $\mathscr L$ with a field structure by transferring the field structure of $\widehat K$. Note that here the product in $\mathscr L$ is not the usual convolution of power series since $\widehat K$ is a ring of Cauchy sequences (modulo...). Here I must link this other question of mine. Now consider the following example: $k$ is a field and consider the ideal $\mathfrak p=(t)\subset k[t]$. Then $k(t)$ is a discrete valuation field w.r.t the $\mathfrak p$-adic valuation $v_{\mathfrak p}$; moreover $\mathcal O=k[t]$ and the residue field $\mathcal O/\mathfrak p$ is isomorphic to $k\subseteq k(t)$.
It follows that $k$ is itself a system of representatives and
$$\mathscr L=k((t))=\left\{\sum_{i\ge{-m}} a_it^i\,:\, a_i\in k\right\}$$ If we want to consider $k((t))$ as a field through the above theorem , we notice that this  field structure isn't the same as the ""usual"" field structure on $k((t))$. Here, with the term usual I mean the component wise addition and the convolution product of power series. In other words I don't agree with the following proposition: ""$k((t))$ is the completion of $k(t)$ w.r.t. $v_{\mathfrak p}$"" Why is it instead true? Edit: The question has been edited because it contained many imprecisions.","['number-theory', 'algebraic-number-theory', 'field-theory', 'local-field']"
1614845,Area of the part of a sphere,"Let $x \in \mathbb{R^3}$ and $t>0$. Also let $R>0$. Why is the area of the part of the sphere $\partial B(x,t)$ inside $B(0,R)$ smaller than the area of $\partial B(0,R)$:
$$|\partial B(x,t) \cap B(0,R)| \leq |\partial B(0,R)|$$ How can this be shown rigorously?","['spheres', 'area', 'geometry']"
1614848,"Meaning of ""polynomially larger""","For example Is $n$ polynomially larger than $\frac{n}{\log n}$? Than $n \log n$? Is $n^2$ polynomially larger than $\frac{n}{\log n}$? Than $n \log n$? I am trying to understand the difference because apparently the first line isn't, but the second is (Master Theorem).","['number-theory', 'computational-complexity', 'asymptotics', 'polynomials']"
1614853,Confusion about the range of the sum of i.i.d. random variables,"Let $X_1, X_2, ...X_n$ be independent and uniformly distributed random variables on the interval $[0,1]$. Now suppose I wanted to calculate the probability density function of $Z = X_1 + X_2 + ... + X_n$. I think this can be done by $n-1$ successive convolutions, but that's not too important for me right now. My confusion stems from the plot on the bottom which shows the resulting PDF's where $n = 2,3,4,5,6$. Obviously we no longer get a uniformly distributed random variable, but what's puzzling to me is the fact, that the new PDF has range $[0,n]$. This result only makes sense to me if we assume that the $X_i$ actually all have the same range (in this case $0 \leq X_i \leq 1$ for all $i$). Informally, what keeps $X_1$ from being the amount of fuel in a passing car and say $X_2$ the number of passengers in said car?","['probability', 'random-variables', 'probability-distributions']"
1614900,"Name of property: $g(f(a), f(b)) = f(g(a, b))$","What's the name of the property of the functions $f$ and $g$ that lets one do this:
$g(f(a),f(b))=f(g(a,b))$ For example, I'm looking for a certain class of functions that do this:
$f(a) \oplus f(b)=f(a \oplus b)$. In this case, $g$ is the binary XOR operator which also happens to be symmetric, but symmetry isn't necessary. Sorry for the simple question that's probably been asked a million times, but it's hard to find the name of something of which one doesn't know the name. Thanks!","['terminology', 'functions']"
1614935,Integral of Lorentzian type with trigonometric function,"Consider the following Riemann integral
$$
\int_0^\infty \mathrm{d}x \frac{\alpha^2}{(x-x_0)^2+\alpha^2} \frac{\sin\left[{\left(x - x_1\right) t }\right]}{x-x_1}
$$
with the displacements $x_0,x_1 \in \mathbb{R}$ and broadening $\alpha \in \mathbb{R}$. The (claimed) solution should be
$$
\pi \left[\frac{\alpha^2}{\delta^2 + \alpha^2} + e^{-\alpha t}\frac{\delta^2 \sin{(\delta t)}- \alpha^2\cos{(\delta t)}}{\delta^2 + \alpha^2} \frac{}{} \right]
$$
with $\delta = x_0 - x_1$. Is an approximation involved, and how do I evaluate this integral?","['improper-integrals', 'integration', 'trigonometry']"
1614938,How to show this fraction is equal to 1/2?,"I have the fraction:
$$\frac{\left(2 \left(\frac {a}{\sqrt{2}}\right) + a \right) a} {2(1 + \sqrt{2})a^2}$$ Using Mathematica, I've found that this simplifies to $\frac{1}{2}$, but how did it achieve the result? How can I simplify that fraction to $\frac12$?",['algebra-precalculus']
1614973,"Why is $F=\frac{-y}{x^2+y^2}\vec{i} + \frac{x}{x^2+y^2}\vec{j}, (x,y)\neq 0$ not conservative?","My book says that $$F=\frac{-y}{x^2+y^2}\vec{i} + \frac{x}{x^2+y^2}\vec{j}, (x,y)\neq 0$$ is not conservative (besides $curl(F)$ being $0$), so I cannot use the theorem that $$\int_\gamma \vec{F} \cdot d\vec{r} = \int_a^b \nabla\phi(g(t))g'(t)dt =  \phi(b)-\phi(a)$$ but I can find $\phi$ such that $\nabla\phi = F$, so why this vector field cannot be conservative?","['multivariable-calculus', 'integration', 'definite-integrals', 'calculus']"
1614981,Is the cantor set a connected set?,The Cantor set is created by deleting the open middle third from each of a set of line segments repeatedly. Is the cantor set a connected set? Thank you.,"['general-topology', 'cantor-set']"
1615038,What is the category of models?,"I'm taking a look at Introduction to Algebraic Geometry and Algebraic Groups by Michael Demazure and Peter Gabriel, and I'm confused about some terminology.  Early in the book it says ""A $\mathbb{Z}$-functor is a functor from the category of models $M$ into the category of sets $E$.  The category of $\mathbb{Z}$-functors is denoted $ME$."" What is the category of models?  This book uses some rather nonstandard terminology, for example when they say geometric space , they mean a locally ringed space, and spectral space seems to refer to what everyone else calls a scheme.","['algebraic-groups', 'algebraic-geometry']"
1615044,Cardinality of set of fractional sums,"What is the cardinality of the set $S_2$: $$ \frac{1}{a_1^n} + \frac{1}{a_2^n}, 1 \leq a_1,a_2 \leq k \in N$$ for different values of $n$? I suspect there is an $n_0$ for which $|S_2| = \binom{k+1}{2}, \forall n \geq n_0$. Is there such an $n_0$ for all sets $S_m$: $$ \frac{1}{a_1^n} + \frac{1}{a_2^n} + \cdots + \frac{1}{a_m^n}, 1 \leq a_i \leq k$$ i.e. $n_0: |S_m| = \binom{k+m-1}{m}, \forall n \geq n_0$? Example: For the set $S_2$, with $k=3, n=2$: $$ S = \{\frac{1}{1} + \frac{1}{1}, \frac{1}{1}+ \frac{1}{2^2}, \ldots, \frac{1}{3^2} + \frac{1}{3^2} \} = \{ 2, \frac{5}{4}, \frac{10}{9}, \frac{1}{2}, \frac{13}{36}, \frac{2}{9} \}$$ so $$ |S_2(k=3,n=2)| = 6 $$","['combinatorics', 'discrete-mathematics', 'elementary-number-theory']"
1615048,Fourier transform of a Lévy density $\frac{1}{\sqrt{2\pi }}\int_{0}^{\infty} e^{ikx-\frac{1}{2x}}x^{-\frac{3}{2}}dx$,"A Lévy density is defined as $$q(x;1/2,1)=\frac{1}{\sqrt{2\pi }}e^{-\frac{1}{2x}}x^{-\frac{3}{2}}$$ for $x>0$ I am looking for it's Fourier transform: $$g(k;1/2,1)=\frac{1}{\sqrt{2\pi }}\int_{0}^{\infty} e^{ikx-\frac{1}{2x}}x^{-\frac{3}{2}}dx   = e^{-\sqrt{|k|}(1-i\text{ sign}(k))} $$ where sign$(k) = k/|k|$ How to evaluate this integral? The author from the book I took it from, suggests splitting the integral into real and imaginary part (V.V. Uchaikin, V.M. Zolotarev, 
Chance and Stability. Stable Distributions and their Applications). Unfortunatly, he ommits the evaluation, giving only the final result.","['fourier-analysis', 'probability-distributions', 'complex-analysis', 'integration', 'contour-integration']"
1615058,Weak Convergence in $\ell^p$,"First, my definition of weak convergence in $X$ is that $x_n \rightharpoonup  x$ if $\phi(x_n) \to \phi(x)$ for all $\phi \in X^*$ . I recently read the statement that $e_n \rightharpoonup 0$ in $\ell^p$ , $p>1$ , where $e_n$ is the canonical basis vector. In $\ell^2$ , this is clear to me, since the weak convergence $x_n \rightharpoonup x$ in $\ell^2$ (which is Hilbert) is equivalent to $\langle x_n, y \rangle \to \langle x, y \rangle$ for all $y \in \ell^2$ . But when $p \neq 2$ , I struggle to prove this since I don't know the form of a general functional $\phi \in X^*$ . Can you help me understand this?","['functional-analysis', 'lp-spaces', 'weak-convergence', 'convergence-divergence']"
1615110,"If $0<x<1$ then prove that $x^a \leq x < 1$ for all $a\in \mathbb{R}, a\geq 1$.","If this is true then can somebody please help me to get the proof. Thanks!
I am trying to see the proof of this for all $a\in \mathbb{R}, a\geq 1$.I saw that this is easy inequality to prove if $a\in \mathbb{N}, a\geq 1$.  It follows easily by induction.
 I was trying to do this for $a\in \mathbb{R}, a\geq 1$. Now, I have figured out the proof which I have given below in this thread.","['real-analysis', 'functions']"
1615140,When does a real matrix have a real square root?,"Given a real symmetric positive-definite matrix $A$, it is easy to show that there is a real square root: the spectral theorem says that there will be a real eigenbasis, and that reduces the problem to taking the square root of the diagonalization. In fact, we don't need symmetry, assuming we have some other way of determining that our matrix is diagonalizable with real and positive eigenvalues. However, there is no need for the eigenvalues to be real and positive.  For example, by using the Taylor series for $\sqrt{1+x}$, one can show that a real $2\times 2$ matrix $A$ will have a real square root if $\operatorname{tr}(A)>0$ and $0<\det(A)<\operatorname{tr}(A)^2/2$. Are there good general necessary or sufficient (or both) conditions under which a real square matrix has a real square root?","['matrices', 'linear-algebra']"
1615160,Groups that are not direct products of other groups?,"Is there any criterion for determining whether a group can be written as a direct product of two other (non trivial) groups or not? For example, finite cyclic groups of prime power order are not isomorphic to any direct product (at least, not one of abelian groups). If there is no criterion, are there specific classes of groups known to have this property?",['group-theory']
1615193,"Subspaces of $C^\alpha [0,1]$ are finite dimensional if closed in $C[0,1]$","For $0 < \alpha < 1$, let $C^\alpha([0,1])$ be the subspace of $C[0,1]$ consisting of continuous functions with norm
$$ \| f\|_\alpha = \|f\| + \sup_{x\neq y} \frac{|f(x) - f(y)|}{|x-y|^\alpha},$$
where $\|\cdot\|$ is the ordinary sup norm on $C[0,1]$. Problem: Let $X$ be a linear subspace of $C^\alpha[0,1]$. Suppose further $X$ is closed in $C[0,1]$. Then $X$ is finite dimensional. My strategy is to show that the unit ball $B \subseteq X$ is compact w.r.t. the $\| \cdot \|_\alpha$ norm. By the Arzela-Ascoli theorem, I can prove that $B$ is compact w.r.t. the $\| \cdot \|$ norm. It is clear to me that 
$$\|\cdot\| \leq \|\cdot\|_{\alpha}.$$
However, how can I show that there is some constant $C$ so that 
$$\|\cdot\|_\alpha \leq C\|\cdot\|?$$","['functional-analysis', 'banach-spaces']"
1615216,Stuck proving that if $m$ and $n$ are perfect squares. Then $m+n+2\sqrt{mn}$ is also a perfect square.,"I am relatively new to proofs and can't seem to figure out how to solve an exercise. I am trying to prove: Suppose that $m$ and $n$ are perfect squares.  Then $m+n+2\sqrt{mn}$ is also a perfect square. I know that per the definition of a perfect square, that $m=a^2$ and $n=b^2$, if a and b are some positive integer. I can then use substitution to rewrite the statement as: $$a^2+b^2+2\sqrt{a^2b^2}$$ I also know that $2\sqrt{a^2b^2}$ can be simplified to:
S
$$a^2+b^2+2ab$$ I am stuck after this point though.  I don't know how to eliminate the $2ab$.","['algebra-precalculus', 'discrete-mathematics', 'square-numbers', 'elementary-number-theory']"
1615222,Show $f_n = f \circ f \circ \dots \circ f \longrightarrow 0$ uniformly on compact sets,"I am seeking help on a complex analysis qualifying exam problem. Let $D$ be a bounded open connected subset of $\mathbf{C}$ containing $0$ and let $f \colon D \to D$ be an analytic function satisfying $f(0) = 0$ and $\left| f^\prime \right|(0) < 1$.  Define $f_n = f \circ f \circ \dots \circ f$ ($n$ times).  Prove that $f_n \longrightarrow 0$ uniformly on compact sets. The hint is to start locally around zero.  I was able to prove that there exists a neighborhood $U$ contained within the radius of convergence of $f$ about $0$ such that $f_n \longrightarrow 0$ uniformly on compact sets contained in $U$.  I note that the proof did not use the boundedness of $D$. I am having trouble extending the result to the entirety of $D$.  Perhaps I am supposed to exploit the connectedness of $D$, considering something like $E = \left\{ z \in D \colon \text{ the result is true locally around } z \right\}$ and showing this set is open and closed.  If this is true, then for an arbitrary compact subset of $D$ we can take a finite cover applying the local result and be done with it.  It is obvious that $E$ is open, but I am having trouble showing it is closed. I don't have an idea where the boundedness of $D$ comes into play... Many thanks in advance for your help.",['complex-analysis']
1615228,What is a proof of this limit of this nested radical?,"It seems as if $$\lim_{x\to 0^+} \sqrt{x+\sqrt[3]{x+\sqrt[4]{\cdots}}}=1$$ I really am at a loss at a proof here. This doesn't come from anywhere, but just out of curiosity. Graphing proves this result fairly well.","['nested-radicals', 'calculus', 'limits']"
1615257,solve the integral equation 2,"I want to solve the integral .Solve is difficult. I want to use statistical methods to solve them.
$$\int_{0}^{+\infty}x \exp\{ ax-b x^2\}d x=\int _{0}^{+\infty} x\exp\{-b(x^2-\frac{a}{b}x)\}dx=\\ exp\{\frac{a^2}{4b^2}\}\int_{0}^{+\infty}x\exp\{-b(x-\frac{a}{b})^2\}dx=\sqrt{\frac{\pi}{4}}\exp{\frac{a^2}{4b^2}}\int_{0}^{+\infty}\frac{\sqrt{2}}{\pi(1\2)}x \exp\frac{-b}{2(1\2)}(x-\frac{a}{b})^2dx=\frac{\pi}{4}\exp\{\frac{a^2}{4b^2}\}.E(HN) $$
Wherever a and b are fixed and HN half normal distribution. What is the final answer","['statistics', 'statistical-inference']"
1615267,"Show With High Probability, No Vertex Belongs to More than One Triangle","I am working on a random graphs problem, which is stated as follows: Suppose that $p = d/n$, where $d$ is constant. Prove that with high probability (w.h.p.), no vertex belongs to more than one triangle. For each $i \in \left[\binom{n}{3}\right] \cup \{0\}$, I define $X_{i}$ as the set of vertices in the graph that belong to $i$ triangles. I believe that I want to show that $Pr[v \in X_{0} \cup X_{1}] \to 1$ as $n \to \infty$. I begin by fixing a vertex $v$ and deriving $Pr[v \in X_{0}]$ and $Pr[v \in X_{1}]$. If $v$ belongs to no triangles, it may have up to $n-1$ neighbors. If $v$ has at least two neighbors, none of them may be adjacent. This yields the probability: $$Pr[v \in X_{0}] = (1-p)^{n-1} + (n-1)p(1-p)^{n-2} + \sum_{i=2}^{n-1} \binom{n-1}{i} p^{i} (1-p)^{n-i-1+\binom{i}{2}}$$ Similarly, if $v \in X_{1}$, it necessarily has at least two neighbors, and exactly two of its neighbors are adjacent. This yields the probability: $$Pr[v \in X_{1}] = \sum_{i=2}^{n-1} \binom{n-1}{i} \binom{i}{2} p^{i+1} (1-p)^{n-i-2+\binom{i}{2}}$$ Am I correct that I want to show $Pr[v \in X_{0} \cup X_{1}] \to 1$ as $n \to \infty$? Would it be possible to get a nudge in the right direction on how to show the desired result (w.h.p., no vertex belongs to more than one triangle)? I greatly appreciate everyone's time and effort to help me!","['combinatorics', 'graph-theory', 'random-graphs', 'probabilistic-method']"
1615279,Proof of Hoeffding's Covariance Identity,"Let $X,Y$ be random variables such that $\operatorname{Cov}(X,Y)$ is well defined, let $F(x,y)$ be the joint-CDF of $X,Y$ and let $F_X(x),F_Y(y)$ be the CDF of $X,Y$ respecitvely. Hoeffding's covariance identity states $$\operatorname{Cov}(X,Y)=\int\limits_{-\infty}^\infty \int\limits_{-\infty}^\infty \left[F(x,y)-F(x)F(y)\right] \, dx \, dy$$ It can easily be seen that $$[F(x,y)-F(x)F(y)] = \mathbb{P}(X\leq x,Y\leq y)-\mathbb{P}(X\leq x) \mathbb{P}(Y\leq y)
=\mathbb{E}[1_{\{ X\leq x\} }\cdot1_{\left\{ Y\leq y\right\} }] - \mathbb{E}[1_{\{ X\leq x\} }] \mathbb{E}\left[1_{\{ Y\leq y\} } \right] = \operatorname{Cov}\left(1_{\{ X\leq x\} }, 1_{\{ Y\leq y\} }\right)$$ So it would suffice to prove that $$\text{Cov}\left(X,Y\right)=\int\limits _{-\infty}^{\infty}\int\limits _{-\infty}^{\infty}\text{Cov}\left(1_{\left\{ X\leq x\right\} },1_{\left\{ Y\leq y\right\} }\right) \, dx \, dy$$ I haven't manged to prove this but I did manage to prove that $$\operatorname{Cov}(X,Y) = \int\limits_{-\infty}^\infty \int\limits _{-\infty}^\infty \operatorname{Cov}\left(1_{\{ X\geq x\} },1_{\{ Y\geq y\} }\right) \, dx \, dy$$ I would really appreciate some help getting from the result I did manage to prove to either the original Hoeffding identity or to the equivalent identity in terms of $\operatorname{Cov}(1_{\{ X\leq x\} }, 1_{\{ Y\leq y\} })$ .","['covariance', 'probability-theory', 'probability', 'random-variables']"
1615295,Finding order and degree of a differential equation,"The question was Find the sum of degree and order of the given DE (differential equation)$$ \frac{d}{dx} \left(\frac{dy}{dx}\right)^3=0 $$ So we have that $$ \left(\frac{dy}{dx}\right)^3=c $$ whee c is some constant. For knowing the order and degree of a DE, it should not contain any arbitrary constant.
$$ 3\left(\frac{dy}{dx}\right)^2\left(\frac{d^2y}{dx^2}\right)=0 $$ But this is not a polynomial form so degree shold not be defined. But the answer says that degree is 3 and order is 1.","['derivatives', 'ordinary-differential-equations']"
1615296,Showing that the polynomial $Y^2+X^2(X-1)^2$ is irreducible,"How to show that the polynomial $Y^2+X^2(X-1)^2$ is irreducible in $\mathbb R[X,Y]$? I tried to show that $\mathbb R[X,Y]$ modulo this ideal is an integral domain but I cannot find any homomorphism.","['irreducible-polynomials', 'abstract-algebra', 'polynomials']"
1615308,Diophantine equations for polynomials,"I know that there has been work on diophanitine equations with solutions in poynomials ( rather than integers ) of the Fermat and Catalan type $x(t)^n+y(t)^n=z(t)^n$ ; $x(t)^m-y(t)^n=1$ and these have been completely solved (For Fermat's equation with $n>2$ and in $\mathbb C[t]$ by Greeneaf and for Catalan's equation in $\mathbb C[t]$ by Nathanson ) . I would like to know whether there has been similar work on solutions in $\mathbb C[x]$ or $\mathbb Z[x]$ for Pell type equations $f(x)^2-ng(x)^2=1$ , where $n$ is given positive integer ; or similarly for say Erdos-Strauss conjecture $4f(x)g(x)h(x)=n(f(x)g(x)+g(x)h(x)+h(x)f(x))$,  where $n>1$ is given integer , or say concerning Ramanujan-Nagell-Lebesgue type equation $f^2+D=Ag^n$, where $D$,$A$ are given integers and we have to find polynomials $f,g$ and positive integer $n$  . Any reference or link  concerning these and other types of Diophantine equations with solutions in polynomials will be highly appreciated . Thanks in advance","['number-theory', 'reference-request', 'polynomials', 'diophantine-equations']"
1615393,"$\lim_{x\to\infty} \frac{\sin x+\sin^2x+\sin^3x+\dotsb}{x\sin x}$, infinite series limit","I saw this question yesterday. $$\lim_{x\to\infty} \frac{\sin x+\sin^2x+\sin^3x+\dotsb}{x\sin x}$$ I claim that the limit is $0$ because it can be written like the following. $$\lim_{x\to\infty} \left(\frac{1}{x}+\frac{\sin x}{x}+\frac{\sin^2x}{x}+\dotsb\right)$$ Then I say in this expression the numerator is limited between $[-1,1]$, and the denominator for each term goes as much as to infinity. Hence term by term we have 0, and adding these up we have 0 as the answer. But then some guy says its indeterminate, because $$\lim_{x\to\infty} \frac{1+\sin x+\sin^2x+\dotsb}{x} = \lim_{x\to\infty} \frac{1-\sin^nx}{(1-\sin x)x}$$ He claims what we have in the denominator is oscillating and we cannot have a limit. Also, he says I'm wrong because an infinite amount of zero does not equal to zero. I'd like to hear your ideas about the answer.","['calculus', 'limits']"
1615411,Group of order $2n$ and subgroups of order $n$,From a French oral examination (second year) : Let $G$ be a finite group of order $2n$. Show that the number of subgroups of $G$ of order $n$ is never $2$. I have no ideas !,"['finite-groups', 'group-theory']"
1615505,Simple system of two nonhomogeneous ordinary differential equations solved by elimination. (3.1-15),"My differential equations textbook states to use the ""elimination method"" to crack this for $x$ and $y$. The final answer uses $t$ as the independent variable which both $x$ and $y$ are dependent on. I was able to solve this for $x(t)$ but it is $y(t)$ where I am having difficulty duplicating the answer in text. The system consists of the following two linear ordinary differential equations written in linear differential operator forms: $$\begin{align*}
&(1) \: D(x + y) = x + t &\\
&(2) \: D^2y = Dx &
\end{align*}$$ The textbook states that the general solution for both $x$ and $y$ are: $$\begin{align*}
& x(t) = \frac{1}{2}t^2 + c_1t + c_2 &\\
& y(t) = \frac{1}{6}t^3 + \frac{1}{2}c_1t^2 + (c_2 - c_1)t + c_3 &\\
\end{align*}$$ Again I had no problem deriving $x(t)$. It is my solution for $y(t)$ which almost but not fully agrees with the answer in the text. The following steps shows my derivation for $y(t)$. I start by differentiating the known solution for $x$: $$\begin{align*}
& x = \frac{1}{2}t^2 + c_1t + c_2 &\\
& x' = t + c_1 &\\
\end{align*}$$ We now integrate twice to find $y$ with substitutions (shown in parenthesis) along the way for $x'$ and $x$ while combining arbitrary constants as needed yielding: $$\begin{align*}
& \: y'' = x' &\\
& \: y'' = (t + c_1) &\\
& \: y' = x + c &\\
& \: y' = (\frac{1}{2}t^2 + c_1t + c_2)+ c &\\
& \: y' = \frac{1}{2}t^2 + c_1t + c_2 \\
& \: y = \frac{1}{6}t^3 + \frac{1}{2}c_1t^2 + c_2t + c_3 &
\end{align*}$$ Again my textbook states that the general solution for $y$ should look like this: $$\begin{align*}
& y(t) = \frac{1}{6}t^3 + \frac{1}{2}c_1t^2 + (c_2 - c_1)t + c_3 &\\
\end{align*}$$ But I get this: $$\begin{align*}
& \: y(t) = \frac{1}{6}t^3 + \frac{1}{2}c_1t^2 + c_2t + c_3 &
\end{align*}$$ Where did the $-c_1t$ come from?","['multivariable-calculus', 'ordinary-differential-equations', 'systems-of-equations']"
1615508,A question about general Marcinkiewicz interpolation theorem,"The general Marcinkiewicz interpolation theorem states as following: If $T$ is a linear operator of weak type $(p_0,q_0)$ and of weak type
  $(p_1,q_1)$ where $q_0\neq q_1$, then for each $\theta\in(0,1)$, $T$
  is of type $(p,q)$, for $p$ and $q$ with $p\le q$ of the form
  $$\frac{1}{p} = \frac{1-\theta}{p_0}+\frac{\theta}{p_1},\quad
\frac{1}{q} = \frac{1-\theta}{q_0} + \frac{\theta}{q_1}.$$ When we say an operator $T$ is of type $(p,q)$ , it means $||Tf||_q \leq C||f||_p$ for some $C$. When we say an operator $T$ is of weak type $(p,q)$ , it means $||Tf||_{q,w} \le C||f||_p$ for some $C$. Here $||·||_{q,w}$ means the
    best constant $C$ such that $\lambda_f(t)\le \frac{C^q}{t^q}$ holds for all $t$ and $f$, where
    $\lambda$ is the distribution function. On wikipedia it says this follows from the former (the restricted from where $p_0=p_1$ and $q_0 = q_1$) through an application of Hölder's inequality and a duality argument. But I do not understand it. Can someone say something more clear?","['harmonic-analysis', 'real-analysis', 'lp-spaces', 'analysis']"
1615527,Solving this limit $\lim_{x\to 3}\frac{x^2-9-3+\sqrt{x+6}}{x^2-9}$.,The question is $\lim_\limits{x\to 3}\frac{x^2-9-3+\sqrt{x+6}}{x^2-9}$. I hope you guys understand why I have written the numerator like that. So my progress is nothing but $1+\frac{\sqrt{x+6}-3}{x^2-9}$. Now how do I rationalize the numerator? It is giving the $\frac{0}{0}$ form after plugging in $3$.,"['rationalising-denominator', 'radicals', 'calculus', 'limits']"
1615551,Function with infinitely many right inverses?,I was thinking about a function with infinitely many right inverses but I could not come up with anything. Does there exist a function with infinitely many right inverses?,"['elementary-set-theory', 'examples-counterexamples', 'inverse-function', 'functions']"
1615585,Evaluate this integral using cylindrical coordinates,"Find the volume of the solid bounded above by the paraboloid of revolution $z^{2}=x^{2}+y^{2}$ And below by the $xy$ plane, and on the sides by the cylinder $x^{2}+y^{2}=2ax$ We take $a>0$. I'm struggling to understand what this would look like graphically, I understand how to find limits of integration for $x$ and $y$ but struggling to find them for $z$. So far i have equated the two terms, but i have got no where with that. Thanks","['multivariable-calculus', 'integration', 'calculus']"
1615607,Finding the exact value of $b$ when given the argument in $z=(b+i)^2$,"In the answer to the above question, there are two methods. My method was that I expanded $(b+i)^2$ out and I do $\arctan \frac{2b}{b^2+1}$ and then solve quadratic equation. However, my friend did it in this way: I don't understand why he can ignore the squared bit of $(b+i)$ and then take the complementary angle - $30^\circ$? Please advise. Thanks in advance and sorry for any wrong tags or title naming.","['trigonometry', 'complex-numbers']"
1615610,Is matrix-vector product a dot or cross product,"Going through linear algebra tutorials on khanacademy I've found that matrix-vector products are not defined clearly as dot or cross products. Am I missing something? Is matrix-vector product a dot or cross product? At first I thought it's a cross product, because result is a vector, not a scalar. But cross-product is not defined in R2, however, matrix-vector product is allowed in R2. A bit confused.","['matrices', 'linear-algebra', 'vectors']"
1615626,Convergence of prime zeta function for $\mathfrak R(s)=1$?,"By doing some estimates for the partial sums of the Prime zeta function $P(s)=\sum_p p^{-s}$ for $\mathfrak R(s)=1$ I got that $P(1+i\alpha)$ converges for every $\alpha\neq0$... Since I did not encounter a source mentioning that it converges for these values of $s$, I thought something went wrong. Question. Is it true that $P(1+i\alpha)$ converges for $\alpha\neq0$? If not, where's the mistake in the proof below? Let $S_\alpha(x)=\sum_{p\leq x}p^{-1-i\alpha}$. Using Abel's summation formula and the PNT in the form $\pi(x)=\frac x{\log x}+O(\frac x{\log^2 x})$ we have $$\begin{aligned}S_\alpha(x)&=\pi(x)x^{-1-i\alpha} +(1+i\alpha)\int_2^x\pi(t)t^{-2-i\alpha}dt\\
&=O(1/\log x)+(1+i\alpha)\color{blue}{\int_2^xt^{-2-i\alpha}\left(\pi(t)-\frac t{\log t} \right )dt}+(1+i\alpha)\color{darkred}{\int_2^x\frac{t^{-1-i\alpha}}{\log t}dt}\end{aligned}$$ The first integral converges to $\color{blue}{\int_2^\color{red}\infty t^{-2-i\alpha}\left(\pi(t)-\frac t{\log t} \right )dt}$ with error term $\int_x^\infty t^{-2-i\alpha}\left(\pi(t)-\frac t{\log t} \right )dt=\int_x^\infty O(\frac1{t\log^2t})=O(1/\log x)$. For the second integral we have (where $\rm Li$ denotes the logarithmic integral ) $$\begin{aligned}\color{darkred}{I(x):=\int_2^x\frac{t^{-1-i\alpha}}{\log t}dt}&=\left[{\rm Li}(t)t^{-1-i\alpha} \right ]_2^x+(1+i\alpha)\int_2^x{\rm Li}(t)t^{-2-i\alpha}dt\\
&=O(1/\log x)+(1+i\alpha)\color{green}{\int_2^x\left({\rm Li}(t)-\frac t{\log t}\right)t^{-2-i\alpha}dt}+(1+i\alpha)\color{darkred}{I(x)}\end{aligned}$$
hence
$$\begin{aligned}\frac{i\alpha}{1+i\alpha}\color{darkred}{I(x)}&=\color{green}{\int_2^x\left({\rm Li}(t)-\frac t{\log t}\right)t^{-2-i\alpha}dt}+O_\alpha(1/\log x)\\
&=\color{green}{\int_2^\color{red}\infty\left({\rm Li}(t)-\frac t{\log t}\right)t^{-2-i\alpha}dt}+O_\alpha(1/\log x)\end{aligned}$$
(using ${\rm Li}(t)=\frac t{\log t}+O(\frac t{\log^2t})$ in the last step). So I get $S_\alpha(x)=\color{blue}{\int_2^\infty t^{-2-i\alpha}\left(\pi(t)-\frac t{\log t} \right )dt}+\frac{(1+i\alpha)^2}{i\alpha}\color{green}{\int_2^\infty\left({\rm Li}(t)-\frac t{\log t}\right)t^{-2-i\alpha}dt}+O_\alpha(1/\log x)$, which means $P(1+i\alpha)$ converges.","['analytic-number-theory', 'zeta-functions', 'asymptotics', 'proof-verification', 'sequences-and-series']"
1615659,Calculate: $\lim_{x\to 0} \frac{f(x^2)-f(0)}{\sin^2(x)}$.,"Let $f(x)$ be a differentiable function. s.t. $f^\prime(0)=1$. calculate the limit: $$\lim_{x\to 0} \frac{f(x^2)-f(0)}{\sin^2(x)}.$$ SOLUTION ATTEMPT: I thought that because $f$ is differentiable its also continuous, then we can say: $\lim_{x\to 0} f(x^2)=f(0)$ then, $\lim_{x\to 0} f(x^2)-f(0)=0$ and also $\lim_{x\to 0} \sin^2(x)=0$, so using L'Hoptal's rule, we get that: $\lim_{x\to 0 } \frac{f(x^2)-f(0)}{\sin^2(x)}= \lim_{x\to 0} \frac{f^\prime (x^2) \cdot 2x}{2\sin(x) \cdot \cos(x)}=\lim_{x\to 0} \frac{f^\prime (x^2) \cdot 2x}{2\sin(x) \cdot \cos(x)}$. I reached right here and I guess I need to do another L'Hopital, is that the right direction?","['proof-verification', 'limits']"
1615686,Minimal word length of factorization of invertible matrices into elementary matrices,"Let $K$ be a field. As is well known, one can decompose every matrix $A \in GL(n,K)$ into a product of elementary matrices. By an elementary matrix , I mean a matrix which belongs to one of the following types of matrices, which correspond to elementary row resp. column operations (depending on the side from which you multiply one of these matrices): I) $D_{j, \lambda} = diag(1,...,1, \lambda, 1,..., 1)$, a diagonal matrix which has $\lambda \in K \setminus \{ 0 \}$ as its $j$-th diagonal entry, or II) $E_{ij}(\lambda)$ for $i \neq j$ and $\lambda \in K \setminus \{0\}$, which is the $n \times n$-identity matrix plus the matrix which has $(i,j)$-th entry equal to $\lambda$ and $0$ otherwise. Now, given $A \in GL(n,K)$, is there a formula (or, at least a reasonable lower bound) for the minimal length of a factorization of $A$ into elementary matrices? What I have found: Let $E(n,K)$ be the subgroup of $GL(n,K)$ generated by the matrices $E_{ij}(\lambda)$. Then Hinson proves that if $A \in E(n, K)$, then $A$ is a product of at most $n^2+n-2$ matrices of the type II).","['matrices', 'abstract-algebra', 'group-theory', 'linear-algebra', 'lie-groups']"
1615695,Evaluate the integral using spherical coordinates,Given the integral  $\int^{1}_{0}\int^{\sqrt{1-x^{2}}}_{0}\int^{\sqrt{1-x^{2}-y^{2}}}_{0} \dfrac{1}{x^{2}+y^{2}+z^{2}}dzdxdy$ I need to evaluate this using spherical coordinates. So far I have that $0\leq r \leq 1$ and I understand that $\theta$ is the angle made in the xy plane and has to be less than or equal to $2\pi$ and $\varphi$ is the angle made revolving around the z-axis and is less than or equal to $\pi$ however I am not sure on how to workout the limits of $\theta$ and $\varphi$ for this question.,"['multivariable-calculus', 'integration', 'spherical-coordinates']"
1615708,Is $x_{n+1}=\frac{x_n}{2}-\frac{2}{x_n}$ bounded? [duplicate],"This question already has answers here : The sequence $x_{n+1}=\frac{x_n}{2}-\frac{2}{x_n}, x_0>0$ is bounded? (2 answers) Closed 7 years ago . Consider the sequence: $x_1=3, x_{n+1}=\frac{x_n}{2}-\frac{2}{x_n}$. This sequence is bounded or is unbounded? Attempt Checking a few terms we get $x_1 = 3, x_2 = \dfrac{5}{6}, x_3 = -\dfrac{119}{60},x_4 = \dfrac{239}{14280},\cdots$. I will prove by contradiction that it is bounded. Suppose that the sequence is bounded. Then there exists some $x_k$ such that $x_k \geq \dfrac{x_n}{2}-\dfrac{2}{x_n}$ or  $x_k \leq \dfrac{x_n}{2}-\dfrac{2}{x_n}$ for all $n$. I seem to get stuck here.",['sequences-and-series']
1615728,"Is $C^1([0, 1], E)$ dense in $C([0, 1], E)$ for a general Banach-space $E$?","I'm wondering if there is a result stating that the space of differentiable functions $C^1([0, 1], E)$ is dense in $C([0, 1], E)$ for a general Banach-space $E$. We define the derivative of a function $f : [0, 1] \rightarrow E$ simply as $$f'(t) := \lim_{h \rightarrow 0} \frac{f(t + h) - f(t)}{h}$$ I suspected this, since this is a Corollary from Stone-Weierstrass for $E = \mathbf{R}$. But of course one can't make generally sense of polynomials in Banach-spaces.","['functional-analysis', 'banach-spaces']"
1615737,How could one solve $\int_{0}^{\infty} \frac{1}{1-t^4}dt$ with special functions?,"How could one solve $$\int_0^\infty \frac{1}{1-t^4} \, dt\,?$$ I have to apply special functions, so I thought that I have to use the change variable $$u=t^4,$$ but $$du=4t^3\,dt$$ and when $$t\rightarrow0\qquad u\rightarrow0\ $$ I get $$t\rightarrow\infty\qquad u\rightarrow\infty, $$ whereas beta function is $\int_{0}^{1} t^{x-1}(1-t)^{y-1}dt$ so I cannot use that change. Help?","['calculus', 'integration', 'special-functions', 'gamma-function', 'beta-function']"
1615752,"Are $C^k[0,1]$, with the $C^k$ norm, distinct as Banach spaces?","Are the $C^k[0,1]$ (k times differentiable real valued functions on the interval), with the $C^k$ norm, distinct as Banach spaces? I know $C^k[0,1] \cong \mathbb{R}^k \oplus C^0[0,1]$, but I think this isomorphism is at best a homeomorphism, and not a isometry. It's not clear to me how to compare the different $\mathbb{R}^k \oplus C^0[0,1]$ for varying $k$. Is it possible for $C^0[0,1]$ to ""absorb"" copies of $\mathbb{R}$, maybe via some good description of $C^0$? Just curious.","['functional-analysis', 'real-analysis']"
1615784,How is it the matrix-vector multiplication with SVD is $O(m+n)$?,"Assuming the singular value decomposition is known, how is it the matrix-vector product of $\mathbf{A}$ ($m \times n$) and vector $\mathbf{x}$ ($n \times 1$) has $O(m+n)$ complexity? Somewhat related: Efficient low rank matrix-vector multiplication and this post on Using SVD to approximate matrix-vector multiplication? The way I break it down, for $\mathbf{Ax} = \mathbf{U \Sigma V}^T\mathbf{x}$: the product $\mathbf{L} = \mathbf{V}^T\mathbf{x}$ has $O(n^2)$ complexity the product $\mathbf{H} = \mathbf{\Sigma}\mathbf{L}$ has $O(n)$ complexity the product $\mathbf{U}\mathbf{H}$ has $O(mn)$ complexity. Why is the matrix-product complexity of order $O(m+n)$ instead of $O(n^2 + n + mn)$?","['matrix-equations', 'matrices', 'matrix-decomposition', 'svd', 'matrix-rank']"
1615793,How to multiply a vector from the left side with matrix?,"I have always dealt with vector - matrix multiplication where the vector is the right multiplicand, but I am not sure how to apply the product between a matrix and a vector when the vector is the left multiplicand. I have the following example $$\beta = \begin{pmatrix} \beta_0 & \beta_1 \end{pmatrix} \in \mathbb{R}^{1 \times 2}$$ and a general matrix $$A = \begin{pmatrix} a_{11} & a_{12} \\ a_{21} & a_{22}\end{pmatrix} \in \mathbb{R}^{2 \times 2}$$ What would be the algorithm to multiply $\beta \cdot A$? Of course the result is a $1 \times 2$ row vector.","['matrices', 'products', 'linear-algebra', 'vectors']"
1615853,Continuity of a 2 variable function - Munkres exercise,"Let $f:\mathbb{R}^2\rightarrow \mathbb{R}$ be defined as $f(0,0)=0$
 and $f(x,y)=\frac{xy(x^2-y^2)}{x^2+y^2}$ for $(x,y)\neq (0,0)$ Then question asks to prove that $f$ is differentiable. Hint that is given is : Show that $D_1f$ equals product of $y$ and a bounded function and $D_2f$  equals product of $x$ and a bounded function. I calculated $D_1f=y\frac{x^4+4x^2y^2-y^4}{(x^2+y^2)^2}$ and clearly
$\left|\frac{x^4+4x^2y^2-y^4}{(x^2+y^2)^2}\right|\leq 3$ So, we have $D_1f$ as product of $y$ and a bounded function.. Similarly $D_2f$ is product of $x$ with a bounded function.. I know that if $D_1f$ and $D_2f$ are bounded then $f$ is continuous.. But here it is product of a bounded function with $y$.. I do not know how to proceed.. Please help me... P.S : I am supposed to prove that it is differentiable. I think i should use condition that if partial derivatives are continuous then $f$ is differentiable...","['multivariable-calculus', 'partial-derivative', 'derivatives']"
1615884,What is a morphism of Tannakian categories?,"In this question, a Tannakian category over $k$ is a $k$-linear rigid symmetric monoidal tensor category, with the property that it has a fibre functor to $\mathbf{Vect}_\ell$ for some field extension $\ell/k$. The definition of morphisms between such objects should be quite simple. It should just be a morphism that preserves all of the structure ; the extra property of having a fibre functor should not come into it. For $F$ to be a functor between $k$-linear rigid symmetric monoidal tensor categories, it needs to: Be an additive, $k$-linear functor. Be (strong and symmetric) monoidal, i.e. there are natural isomorphism $F(X) \otimes F(Y) \to F(X \otimes Y)$, compatible with the unit, associativity and commutativity natural transformations. Be a rigid functor, so that $T(X^\vee) = T(X)^\vee$. That's all fine, and this should (in my opinion) also be the definition of functors between Tannakian categories (we ignore the existence of fibre functors). However, this doesn't seem to be the right notion for several reasons. For instance, it seems to clash with the common nomenclature that a full sub-Tannakian category is a full sub-($k$-linear rigid symmetric monoidal tensor) category together with the condition that it is also stable under taking subquotients in the ambient category . This is particularly relevant for instance when considering Mumford--Tate groups, and can be taken as a justification that this condition is in fact quite natural. My question is thus: is there a different notion of a functor between Tannakian categories than the above proposed definition, making it so that an embedding (=full, faithful exact ""Tannakian"" functor) $F \colon \boldsymbol{T}_1 \to \boldsymbol{T}_2$ necessarily exhibits $\boldsymbol{T}_1$ as a full sub-Tannakian category of $\boldsymbol{T}_2$, i.e. subquotients in $\boldsymbol{T}_2$ of objects in the image of $\boldsymbol{T}_1$ under $F$ are in the (essential) image of $\boldsymbol{T}_1$ under $F$? Or is this condition somehow already automatic (I don't see how)?","['category-theory', 'monoidal-categories', 'algebraic-geometry']"
