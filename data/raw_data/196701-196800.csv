question_id,title,body,tags
3791867,ideals with fixed norm in a Dedekind domain,"Given a general Dedekind domain $R$ is it true that there are at most finitely many prime ideals of $R$ with the same given norm? By ""norm"" I mean the index of the ideal in $R$ , assumed to be finite.","['ring-theory', 'abstract-algebra', 'commutative-algebra']"
3791868,Solving recursion by analogy with a differential equation,"I came across this problem: Let sequence $u_n$ be defined by its first term $u_0 > 0$ and $$\forall n \in \mathbb{N}, \quad u_{n+1} = u_n + \frac{1}{u_n}$$ Find an asymptotic formula for $u_n$ . I thought that we could solve it by analogy with the equation $$f' = \frac{1}{f}$$ which gives the asymptotic formula $u_n \sim \sqrt{2 n}$ , and this is indeed the right answer. More generally, is we take $u_0 > 0, \forall n \in \mathbb{N}, u_{n+1} = u_n + f(u_n)$ , what would be the conditions on a continuous, positive, decreasing function $f$ such that the method of analogy with a differential equation gives the right asymptotic formula ? Thanks a lot !","['recurrence-relations', 'asymptotics', 'sequences-and-series']"
3791877,any method to estimate determinant of a matrix?,"I'm writing a kernel on GPU to compute determinant for my image processing app. The matrices are binary (only have value $[0,1]$ ), sparse, and have size $32\times32$ .
Is there any method for estimating determinants quickly? The error can be high, $10$ %, even $20$ %. Some relevant discussions & papers: https://mathoverflow.net/questions/180604/are-bounds-known-for-the-maximum-determinant-of-a-0-1-matrix-of-specified-size?rq=1 https://stackoverflow.com/questions/47135703/determinant-of-sparse-matrix https://www.sciencedirect.com/science/article/abs/pii/S0024379518302593","['matrices', 'determinant', 'linear-algebra']"
3791880,Improper Definite integral $\int_{-\infty}^\infty -\frac{i \pi e^{-i a p} \text{sech}\left(\frac{c p}{2}\right)}{p}dp$,"I came across this improper integral that I couldn't solve $$\int_{-\infty}^\infty -\frac{i \pi  e^{-i a p} \text{sech}\left(\frac{c p}{2}\right)}{p} dp$$ My guess would be to use Residue theorem but it does not seem help. My try so far is that it has a pole at $p=0$ . With $a>0$ , closing the contour upward, I compute the residue $$\lim_{p\to 0}-\frac{i \pi  e^{-i a p} \text{sech}\left(\frac{c p}{2}\right)}{p} p =-I \pi $$ Thus, the value of the integral is $2\pi I Res(f,0)= 2\pi^2$ . This is definitely not the correct answer (which I confirmed by numerical integration). Taking the hint from the comment I proceeded the following way $\int_{-\infty}^\infty e^{-iap} sech(\frac{cp}{2})=\frac{2 \pi  \text{sech}\left(\frac{\pi  a}{c}\right)}{c}$ which comes from the fact that Fourier transform of sech function is sech function itself. Now, to account the p in the denominator, I need to integrate this result and add a delta function which gives $\int_{-\infty}^\infty \frac{ e^{-i a p} \text{sech}\left(\frac{c p}{2}\right)}{p} dp =\int \frac{2 \pi  \text{sech}\left(\frac{\pi  a}{c}\right)}{c} da =-\frac{2 \pi ^2 \tanh \left(\frac{\pi  a}{c}\right) \text{sech}\left(\frac{\pi  a}{c}\right)}{c^2}+ \delta(a)$ Multiplying by the factor $-i\pi$ on both sides, I get $$\int_{-\infty}^\infty -\frac{i \pi  e^{-i a p} \text{sech}\left(\frac{c p}{2}\right)}{p} dp=\frac{2 i \pi ^3 \tanh \left(\frac{\pi  a}{c}\right) \text{sech}\left(\frac{\pi  a}{c}\right)}{c^2}-i\pi \delta (a)$$ This is supposed to be the correct answer. But that still does not match with the numerical integration.","['improper-integrals', 'definite-integrals', 'complex-analysis', 'residue-calculus', 'complex-integration']"
3791894,Constant sequence of partial sums in a diverging series,"In the harmonic series, we have $$|H_{2n}−H_n|\geq \frac{1}{2}$$ for all $n$ , which implies divergence. However, the partial sums from $n$ to $2n$ , evaluated at $n$ , equal $\ln(2)$ for all $n$ . Doesn't this imply the sequence of partial sums has converged to the value $\ln(2)$ , which in turn, implies the series should converge? I feel like I'm not understanding something fundamental about the Cauchy criterion and convergence etc -- is this not a sequence of partial sums at all, due to the funny things we're doing with the interval? Thanks for your help.","['convergence-divergence', 'functions', 'sequences-and-series', 'real-analysis']"
3791897,"Plese help me to express this Jacobian determinant $\frac{ \partial (x,y) }{ \partial (u,v) }$ only using u and v","We define u and v as $$u=\frac{2x}{x+y+1}$$ $$v=\frac{2y}{x+y+1}$$ I'm trying to get  Jacobian determinant $\frac{ \partial (x,y) }{ \partial (u,v) }$ and express it only using $u$ and $v$ . What I have tried $$x=\frac{-uy-u}{u-2}=-\frac{2y}{v^2}$$ $$y=-\frac{2x}{u^2}=\frac{-vx-v}{v-2}$$ $$\frac{ \partial x }{ \partial u }=\frac{2y+2}{(u-2)^2}$$ $$\frac{ \partial y }{ \partial u }=-\frac{2x}{u^2}$$ $$\frac{ \partial x }{ \partial v }=\frac{2y}{v^2}$$ $$\frac{ \partial y }{ \partial v }=-\frac{2x+2}{(v-2)^2}$$ But even if you calculate the determinant with these values, it end up with result below and fail to cancel x and y out. $$\frac{-16yu^2x+64yux-64yx+4yu^2v^2+16yuxv^2-16yxv^2+16yu^2xv-64yuxv+64yxv+4u^2xv^2+4u^2v^2}{u^2v^2\left(u-2\right)^2\left(v-2\right)^2}$$ Can anyone help me?","['partial-derivative', 'jacobian', 'determinant', 'derivatives']"
3791936,Computing $\sum_{n=1}^\infty\frac{2^{2n}H_{n+1}}{(n+1)^2{2n\choose n}}$,"An advanced sum proposed by Cornel Valean: $$S=\sum_{n=1}^\infty\frac{2^{2n}H_{n+1}}{(n+1)^2{2n\choose n}}$$ $$=4\text{Li}_4\left(\frac12\right)-\frac12\zeta(4)+\frac72\zeta(3)-4\ln^22\zeta(2)+6\ln2\zeta(2)+\frac16\ln^42-1$$ I managed to find the integral representation of $\ \displaystyle\sum_{n=1}^\infty\frac{2^{2n}H_n}{n^2{2n\choose n}}\ $ but not $S$ : Since $$\frac{\arcsin x}{\sqrt{1-x^2}}=\sum_{n=1}^\infty\frac{(2x)^{2n-1}}{n{2n\choose n}}$$ we can write $$\frac{2\sqrt{x}\arcsin \sqrt{x}}{\sqrt{1-x}}=\sum_{n=1}^\infty\frac{2^{2n}x^{n}}{n{2n\choose n}}$$ now multiply both sides by $-\frac{\ln(1-x)}{x}$ then $\int_0^1$ and use that $-\int_0^1 x^{n-1}\ln(1-x)dx=\frac{H_n}{n}$ we have $$\sum_{n=1}^\infty\frac{2^{2n}H_n}{n^2{2n\choose n}}=-2\int_0^1 \frac{\arcsin \sqrt{x}\ln(1-x)}{\sqrt{x}\sqrt{1-x}}dx\tag1$$ But I could not get the integral representation of $S$ . Any idea? In case you find the integral, I prefer solutions that do not use contour integration or you can leave it to me to give it a try. Thank you. In case the reader is curious about computing the integral in $(1)$ , set $x=\sin^2\theta$ then use the Fourier series of $\ln(\cos \theta)$ .","['integration', 'real-analysis', 'harmonic-numbers', 'binomial-coefficients', 'sequences-and-series']"
3791938,Is it possible that $2^{2A}+2^{2B}$ is a square number?,"Let A and B be two positive integers greater than $0$ . Is it possible that $2^{2A}+2^{2B}$ is a square number? I am having trouble with this exercise because I get the feeling the answer is no, but I cannot elaborate on the proof. So far what I thought was to assume that there is some integer $C>0$ such that $2^{2A}+2^{2B}=C^2$ . Then $$(2^A+2^B)^2=C^2+2^{A+B+1}$$ I was trying to see if the previous expression could hold a contradiction but I got stuck. All I could find is that $C$ needs to be an even number but that doesn't seem to get me anywhere. I'd appreciate any help. Thanks in advance!","['number-theory', 'square-numbers', 'elementary-number-theory', 'diophantine-equations']"
3791943,What can be said about the sum of the series?,"Let $\{a_n \}_{n \geq 1}$ be a sequence of non-zero integers satisfying I. $|a_n| \lt |a_{n+1}|,$ for all $ n \geq 1$ II. $a_n$ divides $a_{n+1},$ for all $n \geq 1$ and III. every integer is a divisor of some $a_n.$ Then $\displaystyle\sum\limits_{n=1}^{\infty} \frac {1} {a_n}$ is (a) absolutely convergent and it's sum is a rational number. (b) absolutely  convergent and it's sum is an irrational number. (c) absolutely  convergent and it's sum is a positive number. (d) none of the above. My attempt $:$ It is easy to see that $\displaystyle\sum\limits_{n=1}^{\infty} \frac {1} {a_n}$ is absolutely convergent. Let $a_{k+1} = m_k\ a_{k},$ for $k \geq 1.$ By (I) it follows that $|m_k| \geq 2,$ for all $k \geq 1.$ So we have \begin{align*} \sum\limits_{n=1}^{\infty} \frac {1} {|a_n|} & = \frac {1} {|a_1|} + \frac {1} {|a_2|} + \frac {1} {|a_3|} + \cdots \\ & = \frac {1} {|a_1|} + \frac {1} {|m_1|\ |a_1|} + \frac {1} {|m_2|\ |a_2|} + \cdots \\ & = \frac {1} {|a_1|} + \frac {1} {|m_1|\ |a_1|} + \frac {1} {|m_1|\ |m_2|\ |a_2|} + \cdots \\ & \leq \frac {1} {|a_1|} \left ( 1 + \frac {1} {2} + \frac {1} {2^2} + \cdots \right ) \\ & = \frac {2} {|a_1|} < \infty \end{align*} So $\displaystyle\sum\limits_{n=1}^{\infty} \frac {1} {a_n}$ is absolutely convergent. Clearly (a) is false because we can take $a_n = n!,$ for all $n \geq 1.$ Then the sum is $e-1,$ which is clearly irrational. I may as well take $a_n = -n!,$ for all $n \geq 1.$ Which makes the sum $1-e,$ a negative quantity. Hence (c) is also false. But how can I conclude that whether the sum is always irrational or not? Any help in this regard will be highly appreciated. Thanks in advance.","['sequences-and-series', 'absolute-convergence', 'real-analysis']"
3791954,Unexpectedly simple patterns for the determinants of some matrices,"Edit: ""Spoiler"" Since it's a pretty wordy question, here's a quick spoiler... Why is the following true? $$\det \begin{pmatrix} 0 & 1 & 2\\ 1 & 0 & 1 \\ 2 & 1 & 0 \end{pmatrix} =\det \begin{pmatrix} 0 & 1 & 2 & 0 & 1 & 2\\ 1 & 0 & 1 & 2 & 0 & 1\\ 2 & 1 & 0 & 1 & 2 & 0 \\ 0 & 2 & 1 & 0 & 1 & 2 \\ 1 & 0 & 2 & 1 & 0 & 1 \\ 2 & 1 & 0 & 2 & 1 & 0\end{pmatrix} = \det \begin{pmatrix} 0 & 1 & 2 & 0 & 1 & 2 & 0 & 1 & 2 \\ 1 & 0 & 1 & 2 & 0 & 1 & 2 & 0 & 1\\ 2 & 1 & 0 & 1 & 2 & 0 & 1 & 2 & 0 \\ 0 & 2 & 1 & 0 & 1 & 2 & 0 & 1 & 2\\ 1 & 0 & 2 & 1 & 0 & 1  & 2 & 0 & 1\\ 2 & 1 & 0 & 2 & 1 & 0 & 1 & 2 & 0 \\ 0& 2 & 1 & 0 & 2 & 1 & 0 & 1 & 2 \\ 1 & 0 & 2 & 1 & 0 & 2 & 1 & 0 & 1 \\ 2 & 1 & 0 & 2 & 1 & 0 & 2 & 1 & 0\end{pmatrix} = \dots $$ Consider the matrix $$A=\begin{pmatrix} 0 & 1 & 2\\ 1 & 0 & 1 \\ 2 & 1 & 0 \end{pmatrix}\,.$$ It can be easily evaluated that $\det A = 4$ . More in general it's easy to show (by direct calculation) that given $x\in\mathbb{R}$ and defining $$A(x) = \begin{pmatrix} x-1 & x & x+1 \\ x & x-1 & x \\ x+1 & x & x-1\end{pmatrix}$$ then $\det A(x) = 4x$ . The interesting fact is that these matrices can be ""expanded"" in a way such that the determinant is invariant. Additionally, for a larger class of matrices there seems to be some ""simple"" regular patterns concerning the determinant. Introducing some notation... First, I need to introduce some notation. Let $\mathbf{c} = \{c_1,c_2\dots c_n\}$ . I'll denote $T(\mathbf{c})$ the $n\times n$ symmetric Toeplix matrix whose principal and upper diagonals are given by the coefficients $c_1\dots c_n$ . I mean something like $$T(\{c_1,c_2,c_3,c_4\}) = \begin{pmatrix} c_1 & c_2 & c_3 & c_4\\c_2 & c_1 & c_2 & c_3 \\ c_3 & c_2 & c_1 & c_2 \\ c_4 & c_3 & c_2 & c_1  \end{pmatrix}\,.$$ If we call $\mathbf{v}(x) = \{x-1,x,x+1\}$ , then $A(x) = T(\mathbf{v}(x))$ . Finally, given a $n$ -dimensional vector $\mathbf{c} = \{c_1\dots c_n\}$ , I'll call $\mathbf{c}^k$ the $(k\cdot n)$ -dimensional vector obtained joining together $k$ copies of $\mathbf{c}$ . For example $$\{c_1,c_2,c_3,c_4\}^3 = \{c_1,c_2,c_3,c_4,c_1,c_2,c_3,c_4,c_1,c_2,c_3,c_4\}\,.$$ The main question I've stated at the beginning that $\det A(x) = 4x$ . With the above notation, $\det T(\mathbf{v}(x)) = 4x$ . Actually it seems to be true (at least for what I've tried with Mathematica) that for all positive integer $k$ $$\det T(\mathbf{v}^k(x)) = 4x\,.$$ I guess this result can be proven by induction on $k$ , but it seems to be a bit painful. I would expect some simple and clean proof for what seems to be such a neat result. Any ideas about what's going on and why the determinants are so simple? Going a bit further... Having noticed that things were so simple for $\mathbf{v}(x)=\{x-1,x,x+1\}$ , the first thing I've tried is to slightly change $\mathbf{v}$ . Let's now consider $T(\{x-2,x-1,x,x+1,x+2\}^k)$ . Unfortunatly in this case things get much more complicated. For $k=1$ the determinant is $16 x$ . But then for $k=2$ it's $113288 x$ , for $k=3$ $65157184 x$ and so on. Things are clearly much messier here. But... Let's define $\mathbf{w}(x) = \{x+2,x-1,x,x+1,x-2\}$ . Then the sequence of determinants seems to be very regular. \begin{align}
&\det T(\mathbf{w}(x)) = 16 x\\
&\det T(\mathbf{w}^2(x)) = -8 x\\
&\det T(\mathbf{w}^3(x)) = 0\\
&\det T(\mathbf{w}^4(x)) = -8 x\\
&\det T(\mathbf{w}^5(x)) = 16 x\\
&\det T(\mathbf{w}^6(x)) = -8 x\\
&\det T(\mathbf{w}^7(x)) = 0\\
&\det T(\mathbf{w}^8(x)) = -8 x
\end{align} and so on. So there is a clear pattern in the dependence on $k$ : $$\{16, -8, 0, -8, 16, -8, 0, -8, 16, -8, 0, -8, 16, -8, 0, -8, 16, -8, 0, -8,\dots\}\,.$$ Then we may look at $T(\{x-3,x+2,x-1,x,x+1,x-2,x+3\})$ and again there is a pattern: $$\{64, 12, 4, 0, 4, 12, 64, 12, 4, 0, 4, 12, 64, 12, 4, 0, 4, 12, 64, \dots\}\,.$$ And again for $T(\{x+4,x-3,x+2,x-1,x,x+1,x-2,x+3,x-4\})$ a new pattern: $$\{256, -16, 0, -16, 0, -16, 0, -16, 256, -16, 0, -16, 0, -16, 0, -16, 256, -16, 0, -16,\dots\}\,.$$ I would bet in the existence of a simple explanation for these patterns, but as for now I've really no clue. Any ideas?","['matrices', 'toeplitz-matrices', 'determinant', 'linear-algebra']"
3791982,Determine all complex numbers which satisfy conditions - $|z|=2$ $\space$ and $\space$ Im$(z^6)=8$ Im$(z^3)$,"Determine all complex numbers $z$ which satisfy following conditions: $|z|=2$ $\space$ and $\space$ Im $(z^6)=8$ Im $(z^3)$ I first calculated $z^3$ and $z^6$ . $z^3=x^3-3xy^2+3x^2yi-y^3i$ $z^6=(x+yi)^6=\binom{6}{0}x^6+\binom{6}{1}x^5yi+\binom{6}{2}x^4(yi)^2+\binom{6}{3}x^3(yi)^3+\binom{6}{4}x^2(yi)^4+\binom{6}{5}x(yi)^5+\binom{6}{6}(yi)^6$ $=x^6+6x^5yi+15x^4(-y^2)+20x^3(-y^3i)+15x^2y^4+6xy^5i-y^6$ Then I put imaginary parts in equation Im $(z^6)=8$ Im $(z^3)$ and got following $6x^5y-20x^3y^3+6xy^5=8(3x^2y-y^3)$ $2xy(x^2-3y^2)\require{cancel} \cancel{(3x^2-y^2)}=8y\require{cancel} \cancel{(3x^2-y^2)}$ (*) $x(x^2-3y^2)=4$ $\space$ (1) from $|z|=2$ follows $\sqrt{x^2+y^2}=2$ $\space$ $\rightarrow$ $y^2=4-x^2$ (2) after putting (2) in (1) I got $x^3-3x=1$ and then $x=2\cos\varphi$ equation $8\cos^3\varphi-6\cos\varphi=1$ can be tranformed to $2\cos3\varphi=1$ (I got this with help of identity of $\cos {3x}$ ) and then $\varphi_1=\frac{\pi}{9}+\frac{2k\pi}{3}$ $\varphi_2=-\frac{\pi}{9}+\frac{2k\pi}{3}$ , $\space$ $k \in \mathbb{Z}$ Written differently solution is $\varphi_1=\frac{\pi}{9}+2k\pi$ $\varphi_2=\frac{5\pi}{9}+2k\pi$ $\varphi_3=\frac{7\pi}{9}+2k\pi$ $\varphi_4=\frac{11\pi}{9}+2k\pi$ $\varphi_5=\frac{13\pi}{9}+2k\pi$ $\varphi_6=\frac{17\pi}{9}+2k\pi$ In line with (*) expresions $3x^2-y^2$ are striked out. We have to include that $3x^2-y^2=0$ $3x^2-(4-x^2)=0$ $4x^2=4$ $x^2=1$ $(2\cos\varphi)^2=1$ $\cos^2\varphi=\frac{1}{4}$ After solving this equation we get $\varphi_7=\frac{\pi}{3}+2k\pi$ $\varphi_8=\frac{2\pi}{3}+2k\pi$ $\varphi_9=\frac{4\pi}{3}+2k\pi$ $\varphi_{10}=\frac{5\pi}{3}+2k\pi$ Solution from my textbook: $\require{enclose}
     \enclose{horizontalstrike}{z_1=2(\cos\frac{2\pi}{3}+i\sin\frac{2\pi}{3})}$ . $\require{enclose}
     \enclose{horizontalstrike}{z_2=2(\cos\frac{5\pi}{3}+i\sin\frac{5\pi}{3})}$ . $\require{enclose}
     \enclose{horizontalstrike}{z_3=2(\cos\frac{7\pi}{3}+i\sin\frac{7\pi}{3})}$ . Can someone help me find a mistake? If you find mistake feel free to edit. On the picture bellow are all 10 solutions.","['complex-analysis', 'complex-geometry', 'complex-numbers']"
3792016,Let $P(x)=a_0+a_1x+a_2 x^2+a_3x^3+.......+a_nx^n$ and $P(1)=4$ and $P(5)=136$,"Let $P(x)$ be a polynomial such that, $$P(x)=a_0+a_1x+a_2 x^2+a_3x^3+.......+a_nx^n,~~(a_i,n\in{Z^{\geq 0}})$$ $$ P(1)=4, P(5)=136$$ We have to find $P(3)$ This problem is harder than it looks (at least for me) What I tried to do was $$P(1)=a_0+a_1+a_2+a_3+.......+a_n=4$$ and $$P(5)=a_0+5a_1+25a_2 +125a_3+.......+a_n5^n$$ Let $P(1)=S$ , and we take $a_0$ to the side of $S$ and multiply $(S-a_0)$ by $5$ and some cancellations. Simply it leads nowhere Can I get some Hints on how to proceed?","['contest-math', 'algebra-precalculus', 'sequences-and-series']"
3792067,Prime Spectrum of a ring: why is Geometry captured by local rings?,"If a function $f: \mathbb R \rightarrow \mathbb R$ is continuous, $f$ is locally invertible at all non-vanishing points. That is, for all points $x_0$ such that $f(x_0) \neq 0$ , there exists an open neighbourhood $U$ of $x_0$ and a function $g: U \rightarrow \mathbb R$ , such that for all $u \in U$ , $(f \times g)(u) = f(u) \times g(u) = 1$ . Is the converse true? Is a function which is locally invertible at all non-vanishing points continuous? It seems not. Consider the function $
f(x) = \begin{cases}
1 & x \in \mathbb Q \\
2 & \text{otherwise}
\end{cases}
$ This has an inverse function $
g(x) = \begin{cases}
1 & x \in \mathbb Q \\
1/2 & \text{otherwise}
\end{cases}
$ even though $f$ is discontinuous everywhere. So clearly, this locally invertible definition is very far away from giving us continuous functions. I am now unmotivated about the spectrum of a ring. It is this ""local inversion""
property that (I thought) motivates the definition of the structure sheaf
on the spectrum of a ring. In $\operatorname{Spec}(A)$ , the ring of functions around a  point(prime) $\mathfrak p$ is $A_\mathfrak p$ . So all functions (ring elements) which are not zero
at $\mathfrak p$ will be forced to become invertible by way of localization. But this definition does not seem strong enough to actually capture what
we want --- it allows lots of pathological rings of functions, from which
we cannot recover the structure of the original space. The proof I know which recovers the original space given the ring of functions needs continuous
functions to apply Urhyson's lemma [this can be found in Atiyah Macdonald, Chapter 1, Exercise 26) What am I missing?","['algebraic-geometry', 'schemes', 'commutative-algebra', 'sheaf-theory']"
3792128,A different approach to a common question,"A unit stick is randomly broken into 3 pieces, it is given that these three pieces can make a triangle, what is the expected length of the medium-sized piece? This a question we are all familiar with and anyone who has seen it anywhere/solved it knows that the expected length of the medium piece is $\frac{5}{18}$ , we reach this conclusion by using $E(L+M+S) = 1$ , and we know we can calculate $E(L)$ and $E(S)$ , so we just use $E(M) = 1-E(L)-E(S)$ to get our answer, is there any way we can solely calculate the $E(M)$ without calculating the other two values? $L$ : Length of the longest part $S$ : Length of the smallest part $M$ : Length of the medium part Thank you :)","['geometric-probability', 'probability']"
3792157,"Prove existence of triangle with vertices in $\mathbb{Z}^2$, each angle of which is $\varepsilon$-close to $\pi/3$.","Let $\theta_1, \theta_2$ and $\theta_3$ angles of a triangle. Prove
that for every $\varepsilon>0$ , there exists a triangle with vertices
in $\mathbb{Z}^2$ such that $|\frac{\pi}{3}-\theta_i|<\varepsilon$ .","['elementary-number-theory', 'triangles', 'geometry', 'euclidean-geometry']"
3792166,Union of all Borel subgroups is the whole group,"Let $G$ be a connected algebraic group. Then the union of all of its Borel subgroups is $G$ itself. I am following this proof on page 70 lemma 26.3. Let's just focus on the first part proving the union of all Borel subgroups is closed. But I found the proof is a kinda flawed. Let $B$ be a Borel subgroup. Consider $$G\times B\xrightarrow{\phi} G\times G\xrightarrow{\pi} G/B\times G\xrightarrow{\gamma} G$$ where $\phi:(g,b)\mapsto(g,gbg^{-1})$ , $\pi:(g,h)\mapsto(gB,h)$ , $\gamma:(gB,h)\mapsto h$ . In total, the image is the union of the conjugates of the Borel subgroup. We would like to show it is closed. Then we want to show $im(\pi\phi)$ is closed then by $G/B$ projectivity, we could conclude. But then I ran into trouble of being convinced by the proof. First, he wants to show $im(\phi)$ is closed. He cited a result proved before, corollary 16.5, which claims that the image of an algebraic group homomorphism is an algebraic group (closed). But this $\phi$ is not a group homomorphism, because $\phi((g,h)(x,y))=\phi(gx,hy)=(gx,gxhyx^{-1}g^{-1})$ but $\phi((g,h))\phi((x,y))=(g,ghg^{-1})(x,xyx^{-1})=(gx,ghg^{-1}xyx^{-1})$ . Apparently, they are not equal... Second, even if assume we have got $im(\phi)$ is closed, we want the image under $\pi$ is closed but $\pi$ is an open (surjective) map which was also proved. However, I do not think open surjective map implies closed map.","['algebraic-geometry', 'algebraic-groups']"
3792182,"Intuitively, what is the general overlap/difference between conformal vs orthogonal transformations, or the terms in general?","I've been having difficulty finding a clear definition on the differences between the two in practical/geometric terms. Orthogonal transformations being those which the coordinate surfaces or trajectories meet at right angles, and conformal transformations being those which preserve angles. I can see how the notions overlap, and have a vague intuition on how they are different, but I am having trouble clarifying their exact distinction, specifically in the context of differential/vector calculus with respect to concepts like the Jacobian and it's area preserving properties, differential equations for orthogonal trajectories, integral transforms, etc. Or in more direct terms, when is something orthogonal but not conformal, and vice versa, and when are they both?","['differential', 'calculus', 'differential-forms', 'differential-geometry']"
3792199,Show expectation of minimum of the stopped martingale is $-\infty$,"Consider the random walk martingale $S_n=\sum_{k=1}^n X_k$ where $X_k$ are uniformly bounded, iid with $E(X_1)=0,E(X_1^2)=\sigma^2>0$ . Let $a>0$ and set $T=\inf\{n:S_n\geq a\}$ . Show that $E(\min_n S_{n\wedge T})=-\infty$ . I was thinking of defining $T(k)=\inf\{n:S_n\leq -k\}$ and using the martingale $S_{n\wedge (T\wedge T(k))}^2-(n\wedge T\wedge T(k))\sigma^2$ . We will then get (using MCT and boundedness and $S_{n\wedge (T\wedge T(k))}^2$ ) $E(S^2_{T\wedge T(k)})=\sigma^2(T\wedge T(k))$ . This implies $b^2P(T<T(k))+k^2P(T>T(k))=\sigma^2 E(T\wedge T(k))$ . I am not sure how to proceed from here.","['martingales', 'measure-theory', 'probability-theory']"
3792235,Is there a closed form for $\sum_{n=1}^\infty\frac{2^{2n}H_n}{n^3{2n\choose n}}?$,"I found $$\sum_{n=1}^\infty\frac{2^{2n}H_n}{n^3{2n\choose n}}=-8\int_0^{\pi/2}x^2\cot x\ln(\cos x)\ dx=I\tag1.$$ Mathematica failed to find $I$ , so I am not sure if there is closed form for it. I am just giving it a try here. First idea came to my mind is to use the Fourier series of $-\ln(\cos x)=\ln(2)+\sum_{n=1}^\infty\frac{(-1)^n\cos(2nx)}{n}$ and we have $$I=8\ln(2)\underbrace{\int_0^{\pi/2}x^2\cot x\ dx}_{\frac32\ln(2)\zeta(2)-\frac78\zeta(3)}+8\sum_{n=1}^\infty\frac{(-1)^n}{n}\int_0^{\pi/2}x^2 \cot x\cos(2nx)\ dx.$$ I got stuck here. Any help would be much appreciated. Proof of $(1)$ from here we have $$\arcsin^2(x)=\frac12\sum_{n=1}^\infty\frac{(2x)^{2n}}{n^2{2n\choose n}}$$ replace $x$ by $\sqrt{x}$ we get $$\sum_{n=1}^\infty\frac{2^{2n}x^n}{n^2{2n\choose n}}=2\arcsin^2(\sqrt{x})$$ multiply both sides by $-\frac{\ln(1-x)}{x}$ then $\int_0^1$ and use $-\int_0^1 x^{n-1}\ln(1-x)dx=\frac{H_n}{n}$ we get $$\sum_{n=1}^\infty\frac{2^{2n}H_n}{n^3{2n\choose n}}=2\int_0^1\frac{\arcsin^2(\sqrt{x})\ln(1-x)}{x}dx\overset{\sqrt{x}=\sin\theta}{=}-8\int_0^{\pi/2}x^2\cot x\ln(\cos x)\ dx$$","['integration', 'real-analysis', 'harmonic-numbers', 'binomial-coefficients', 'sequences-and-series']"
3792238,"Idea behind ""reparameterization hiding a corner"" in single variable calculus","I just solved question #2 on p. 248 from Spivak's Calculus Fourth Edition (2008). Solving it wasn't the issue. I'm trying to understand the idea behind it. This is a screenshot of the question: I'm trying to understand what is meant by ""reparameterizing hides a corner"". What does the author mean by ""hide"" in what sense is it being hidden? For reference, the function that this is being applied to is the following: $$ f(x) =  \left\{
       \begin{array}\
        x^{2},\ x \geq 0 \\
       -x^{2},\ x \leq 0 \\
      \end{array}  \right.$$ EDIT: Image of fig 21 as requested","['calculus', 'parametrization', 'real-analysis']"
3792278,Calculate the limit $\lim _{n \rightarrow \infty} \frac{[\ln (n)]^{2}}{n^{\frac{1}{\ln (\ln (n))}}}$.,"I would like to know how to calculate the limit $$
\lim _{n \to \infty}
{\ln^{2}\left(n\right) \over n^{ 1/\ln\left(\,{\ln\left(\,{n}\,\right)}\,\right)}}
$$ I have tried to change its form using $\exp\left(\,{\ln\left(\,{x}\,\right)}\,\right) = x$ and changing $X = \ln(\,{x}\,)$ but it came down to computing the limit of $$
\lim _{X \to \infty}
\left[X^{2}\mathrm{e}^{-X/\ln\left(\,{X}\,\right)}\right]
$$ Any suggestions ?. Thanks.","['limits', 'calculus', 'real-analysis']"
3792280,Number of partitions of countable and uncountable set,"For a countably infinite set (say N), we can find a partition into countably infinite number of countably infinite subsets with each disjoint with other. But how to find how many such partitions possible. I am a beginer and please explain me in layman language. Also how to find number of partions of uncountable set?","['self-learning', 'cardinals', 'set-partition', 'real-analysis', 'elementary-set-theory']"
3792412,Does the Chain Rule Hold for General Derivatives?,"For vector space $\mathbb{R}^n$ we have partial derivatives, which obey the chain rule, e.g: let $F:\mathbb{R}^n \to \mathbb{R}^m$ , $f:\mathbb{R}^m\to \mathbb{R}$ , assume standard basis for $\mathbb{R}^n$ is $x^i$ and standard basis for $\mathbb{R}^m$ is $y^j$ .So for composition we have: $$\left.\frac{\partial}{\partial x^{i}}\right|_{p}(f \circ F)=\frac{\partial f}{\partial y^{j}}(F(p)) \frac{\partial F^{j}}{\partial x^{i}}(p)$$ which is the standard chain rule. Now consider the general case derivative as linear map between algebra $v:A\to B$ with $v(fg) = fv(g)+gv(f)$ . In this case does chain rule for composition $v(f\circ g)$ still hold? It seems not? (we know for differential $dF_p:T_pM\to T_p N$ chain rule still holds)","['manifolds', 'differential-geometry', 'smooth-manifolds', 'real-analysis']"
3792434,Symbol for Graph Difference?,"Is there any well-defined symbol to denote the difference between the two graphs. The difference between two graphs $G$ and $H$ is defined as the remaining sub-graph $G'$ of $G$ after the subgraph $H$ is removed from $G$ (assuming $H$ is a sub-graph of $G$ ). For example (the image is taken from Wolfram ): Note that, $G'$ might not be unique, since $H$ can be positioned anywhere in $G$ , Although I can define my own symbol, it would be better to use the symbol that is well defined by the community.","['graph-theory', 'notation', 'discrete-mathematics']"
3792453,Counter example of rellich-kondrachov compact embedding theorem on unbounded domain,"The Rellich-Kondrachov Compactness Theorem says that when $U$ is a bounded set with $C^1$ boundary then $W^{1,p}(U)$ is compactly embedded into $L^{q}(U)$ for every $1 \leq q < p^{*}$ . What if $U$ is unbounded, e.g. $U=\mathbb{R}^n$ ?","['sobolev-spaces', 'functional-analysis', 'partial-differential-equations']"
3792480,Fair gambler's ruin tail probability,"I'm looking at the following variant of the fair gambler's ruin problem: The gambler starts with 1 dollar. They repeatedly flip a fair coin. Heads, +1 dollar; Tails -1 dollar. The game stops when the gambler reaches 0 dollars. It is well known that the game ends with probability 1, and that the mean time for the game to end is infinite. I am interested in the following question: What is the (asymptotic) probability that the game is not yet over after $n$ flips? From a heuristic argument, I'm fairly certain that the answer is $\theta(1/\sqrt{n})$ . From simulation, it appears that the answer is about $0.8/\sqrt{n}$ . I'd like to know the exact answer, and I'd like to know how to derive it analytically. At least, I'd like to know how to prove that the probability is $\theta(1/\sqrt{n})$ . I'm guessing the proof involves a martingale, but I can't find it myself.","['random-walk', 'martingales', 'markov-chains', 'probability']"
3792492,What is left composition of two binary relations?,"What is left composition of two binary relations? Consider sets $X$ , $Y$ , $Z$ : $$X = \{a,b,c\}$$ $$Y = \{1,2,3\}$$ $$Z = \{x,y,z\}$$ Then $R$ , $S$ are relations: $$R = \{(a, 1), (a, 2), (a, 3), (b, 1), (b, 2), (b, 3), (c, 1), (c, 2), (c, 3)\}$$ $$S = \{(1, x), (1, y), (1, z), (2, x), (2, y), (2, z), (3, x), (3, y), (3, z)\}$$ Then composition $R$ and $S$ will be: $$R \circ S =  \{(a, x), (a, y), (a, z), (b, x), (b, y), (b, z), (c, x), (c, y), (c, z)\}$$ What is left composition $R;S$ in this exapmle?","['relations', 'discrete-mathematics']"
3792512,Prove that if two persons do not know each other then they know the same number of people.,"Question : Consider a gathering of more than three people. Assume that knowing is a symmetric relation i.e., if person $A$ knows person $B$ then $B$ knows $A$ . Given any two persons, number of people they both know is exactly one. Prove that if two persons do not know each other then they know the same number of people. Now the given condition: Given any two persons, number of people they both know is exactly one. I think if $A $ and $B $ knows each other then they both know no one else and if they don't know each other then they both know only one another person let $C $ . I tried it to convert the problem to graph theory. Then according to the condition if $AB $ is joined then no other point is connected with both $A $ and $B $ and if $AB $ is not connected then they are both connected with only one other point. But now I am unable to think how to prove. I drew the graph of 6 points ,but did not get something that will help me to prove. Can you help me with this ?","['graph-theory', 'combinatorics']"
3792515,Compute line integrals $\int_C\text{F}\cdot d\mathbb{x}$,"$\def\hl#1#2{\bbox[#1,1px]{#2}}
\def\box#1#2#3#4#5{\color{#2}{\bbox[0px, border: 2px solid #2]{\hl{#3}{\color{white}{\color{#3}{\boxed{\underline{\large\color{#1}{\text{#4}}}\\\color{#1}{#5}\\}}}}}}}
\def\verts#1{\left\vert#1\right\vert}
\def\Verts#1{\left\Vert#1\right\Vert}
\def\pra#1{\left(#1\right)}
\def\R{\mathbb{R}}$ $\box{black}{black}{}
{Question}
{\text{Compute the following line integrals $\int_C\text{F}\cdot d\mathbb{x}$:}\\
\text{(a) F$(x,y)=(x^2,-y)$ and C is the graph of $y=e^x$ from $x=2$ to $x=1$}\\
\text{$(b)$ F$(x,y,z)=(z,-y,x)$ and C is line segment from $(5,0,2)$ to $(5,3,4)$}\\
\text{$(c)$ F$(x,y,z)=(x,y,z^2)$ and C is the intersection of cylinder $x^2+y^2=1$}\\
\text{and $z=x$ oriented counter-clockwise when viewed from above.}}$ My attempts $(a)$ Consider the parameterization i.e. $(x,y)=\left(1+t,e^{1+t}\right)$ , and $(dx,dy)=(1,e^{1+t})$ where $t\in[0,1]$ \begin{align}
\int_C\text{F}\cdot d\text{x}=&\int_C x^2dx-ydy\\
=&\int_0^1(1+t)^2-e^{2+2t}dt\\
=&\frac{7}{3} + \frac{e^2-e^4}{2}
\end{align} $(b)$ Let $(x,y,z)=(5,3t,2+2t)$ and $(dx,dy,dz)=(0,3,2)$ where $t\in[0,1]$ , have \begin{align}
\int_C\text{F}\cdot d\text{x}=&\int_Czdx-ydy+xdz\\
=&\int_0^1-9t+10dt\\
=&\frac{11}{2}
\end{align} $(c)$ Let $(x,y,z)=(\cos(t),\sin(t),\cos(t))$ , that $(dx,dy,dz)=(-\sin(t),\cos(t),-\sin(t))$ where $t\in[0,2\pi]$ \begin{align}
\int_C\text{F}\cdot d\text{x}=&\int_Cxdx+ydy+z^2dz\\
=&\int_0^{2\pi}-\sin(t)\cos(t)+\sin(t)\cos(t)-\sin(t)\cos^2(t)dt\\
\vdots\\
=&0
\end{align} Another approach for $(c)$ might be use Stokes' Theorem. Let $S=\{(x,y,z)\in\R^3:x^2+y^2\le1,z=x\}$ , that C is the Stokes' boundary of S. \begin{align}
\int_{C}\text{F}\cdot d\text{x}=&\iint_S\nabla\times\text{F}\cdot\text{n}dA\\
=&\iint_S(0,0,0)\cdot\text{n}dA\\
=&0
\end{align} Is my solutions correct?","['definite-integrals', 'multivariable-calculus', 'calculus', 'solution-verification', 'multiple-integral']"
3792534,how to prove that the segment $IF=HF+GF$,"$AE$ and $CD$ are the angle bisectors of $\triangle ABC$ . $F$ is an arbitrary point on line $DE$ . Prove that $GF+HF=IF$ . I noticed $3$ cyclic quadrilaterals. Any ideas.
Here is the picture","['euclidean-geometry', 'quadrilateral', 'geometry', 'triangles', 'plane-geometry']"
3792543,Spivak's Calculus: Chapter 3 Problem 24b,"24b) Suppose that $f$ is a function such that every number $b$ can be written $b = f(a)$ for some real number $a$ . Prove that there is a function $g$ such that $f \circ g = I$ I think I do understand this question and how to solve it, but I'm struggling to find a way to express my solution in a mathematically rigorous way, particularly when $f$ is not injective. Here's my idea: First of all, if $f$ is injective, then it's trivial. Let $g(x) = a$ , where $x = f(a)$ for any $a \in \text{domain}(f)$ Since $f$ is injective, by definition there is only one value of $a$ that satisfies $x = f(a)$ for each $x$ , which means $g$ is well defined. And $\text{domain}(g) = \text{image}(f)$ (by definition of $g$ ), which from the supposition in the question is $\mathbb{R}$ . Also, $\text{domain}(f) = \text{image}(g)$ , since $f$ and $g$ are injective (but that fact is not important). So $f(g(x))$ is defined for all $x ∈ \mathbb{R}$ . Finally, $f(g(x))$ = $f(a)$ , where $x = f(a)$ for $x ∈ \mathbb{R} \to f(g(x)) = I(x)$ . But now if $f$ is not injective, it gets more complicated. If I keep my original definition of $g$ , being "" $g(x) = a$ , where $x = f(a)$ for any $a \in \text{domain}(f)$ "", then that doesn't work because $g$ is no longer a function. Because since $f$ is not injective, there exists atleast 2 numbers $z$ and $w$ such that $z \neq w$ but $f(z) = f(w)$ , which means there exists $x$ such that: $g(x) = z = w$ . I think the idea is to simply redefine $g$ to simply ""choose"" either $z$ or $w$ , and assign it to $x$ . For example it could choose the smaller of the two. The only difference this would make is now $\text{domain}(f) \subset \text{image}(g)$ , instead of $\text{domain}(f) = \text{image}(g)$ . But since that fact wasn't important before, the conclusion in the question still holds. Here's my question. How do I explicitly write down a definition of $g$ that ""chooses"" the smaller of $z$ or $w$ ? Furthermore, recall there exists at least 2 numbers z and w. There could be arbitrarily more numbers such that $f(z) = f(w) = f(m) = f(n)$ and so on. And that's just one of the arbitrary branches the common values $f$ could take. There could be a different set of numbers $f(z_2)  = f(w_2) = f(m_2)$ and so on, that are not equal to $f(z)$ , etc. This is starting to get very messy. How can I express $g$ mathematically?","['notation', 'proof-writing', 'functions']"
3792551,Eigenvalues of a DAE and stability analysis,"I have a nonlinear system of differential algebraic equations (DAE) of index -1,  and I was wondering: what is the ""meaning"" of eigenvalues in that case? I know they do not indicate stability, as with regular ODEs, unless the Algebraic terms are eliminated, which is not an option in my case. What do they mean, then? How do I investigate the stability, in such a DAE?","['systems-of-equations', 'ordinary-differential-equations', 'dynamical-systems']"
3792562,Question on fractional inequalities,"$a,b$ are positive integers. Let $\frac{a}{b}$ be the fraction with the smallest possible denominator $b$ such that $\frac{386}{2019}$ < $\frac{a}{b}$ < $\frac{35}{183}$ . Determine the value of $a+b$ . I have tried simplifying the inequality, but I am stuck. However, I do know that as $b$ has to be smallest, so does $a$ . Any idea how I should do this question? Thanks for any help.","['number-theory', 'integers', 'continued-fractions', 'fractions', 'inequality']"
3792577,Curl of $\frac{\hat r}{r^2}$ using two different coordinates,"I am learning vector calculus. Here I wanted to take out the $\nabla\times(\frac{\hat r}{r^2})$ ,
So in spherical coordinates it is easy to take out. It is zero.
but while doing in Cartesian coordinates $\begin{bmatrix}
 \hat x & \hat y & \hat z \\
 \frac{\partial}{\partial x} & \frac{\partial}{\partial y} & \frac{\partial}{\partial z}\\
 \frac{1}{(x^2+y^2+z^2)} & \frac{1}{(x^2+y^2+z^2)} & \frac{1}{(x^2+y^2+z^2)} \\
 \end{bmatrix}
$ This on solving isn't coming to be zero. Why?","['vector-fields', 'multivariable-calculus', 'polar-coordinates']"
3792604,Why the reals with the operation $x \bullet y = \sqrt[3]{x^3 + y^3}$ is a group?,"The operation above is a group for the real numbers, since 0 is the identity element, and the negative of any real number is its inverse, as it can be observed trivially. Associativity is less trivial, but it holds. In fact, if we substitute 3 for any odd number (5, 7 ...), the operation satisfies the properties of the group. However, any even number fails. Is there any geometric / analytic / ... interpretation why an operation like $x \bullet y = \sqrt[3]{x^3 + y^3}$ is associative and, as a consequence, it gives the structure of a group to the reals?","['group-theory', 'abstract-algebra']"
3792636,Extraneous solution from substituting in equations [duplicate],"This question already has answers here : What's wrong with manipulating this algebraic equation? and why does a manipulated system of equations have a different solution than the original? (3 answers) Closed last year . I came across this example of how you could end up with an extraneous solution but I was wondering how it arose.
We have the equation: $$x^2+x+1=0 $$ Since x=0 does not satisfy the equation, you can divide by x on both sides which yields: $$x+1+\frac{1}{x}=0$$ which is equivalent to our first equation. From our first eqution we can conclude that: $$-x^2=x+1$$ We now substitute that into the second equation to get: $$x^2=\frac{1}{x}$$ which results in $$x^3=1$$ which is equivalent to our previous equation since x cannot be 0. However, one solution from our last equation is x=1, which is not a solution to our original equation.
I have a vague idea that it may have to do with the fact that you get a cubic equation and you began with a quadratic, and that steps imply the following and not vice versa, but can you provide a very detailed answer as to why it arises? Can you please provide more examples?",['algebra-precalculus']
3792655,How $\int_{0}^{\infty} \frac{\arctan(x)}{1+x}\frac{dx}{\sqrt[4]{x}}=\frac{\pi}{\sqrt2}\big(\pi/2+\ln{\beta}\big)$,"$$
\int_{0}^{\infty}\frac{\arctan\left(x\right)}{1 + x}
\,\frac{\mathrm{d}x}{\sqrt[{\large 4}]{x}} =
\frac{\pi}{\,\sqrt{\,{2}\,}\,}
\left[{\pi \over 2} + \ln\left(\,{\beta}\,\right)\right]
$$ $$
\mbox{Find the value of}\quad
\beta^{4} - 28\beta^{3} + 70\beta^{2} - 28\beta.
$$ How to do this question ?. I tried conventional approaches such as substituting $x$ with $1/t^{2}$ but none of them is yielding an answer.","['integration', 'calculus', 'inverse', 'trigonometric-integrals']"
3792663,Calculate integral $\int^{+\infty}_0 \frac{e^{-x^2}}{(x^2+\frac{1}{2})^2} dx$?,"I've posted a similar integral earlier, in which the Goodwin-Staton Integral is involved, making the integral unsolvable. Now I make a little modification to make it solvable and give my answer below.","['integration', 'probability']"
3792682,Borel sets versus Baire sets,"(1) Suppose that I have a compact Hausdorff space $X$ with a countable base. Why are the Borel algebra $\mathcal{B}(X)$ (the $\sigma$ -field generated by the open sets) and the Baire algebra $\mathcal{B}a(X)$ (the $\sigma$ -field generated by the compact $G_\delta$ sets) equal? Where can I find a proof of this? (2) Suppose now that $X$ has an uncountable base. In that case, $\mathcal{B}(X)$ and $\mathcal{B}a(X)$ do not coincide anymore, and I know that considering the Baire sets avoids some pathologies of the Borel sets. What are those pathologies? Also, what would be an example of a Borel set which is not Baire?","['general-topology', 'descriptive-set-theory']"
3792692,How to evaluate the double integral over a non-closed surface?,"Let $\vec{F}=(x+2y)e^zi+(ye^z+x^2)j+y^2zk$ and let $S$ be the surface $x^2+y^2+z=1$ , $z\geq 0$ . If $\hat{n}$ is a unit normal to $S$ and $$\left|\iint_S(\nabla\times \vec{F})\cdot \hat{n}\, dS\right|=\alpha\pi.$$ Then $\alpha=?$ We can't apply Gauss divergence theorem here since the surface S is not closed. How to proceed in this question then? Please help.","['integration', 'multivariable-calculus', 'divergence-theorem', 'multiple-integral']"
3792694,On the golden ratio and even perfect numbers,"(Note:  This post is an offshoot of this earlier MSE question .) Here is my question in this post: Is $I(2^{p-1}) - 1 > 1/I(2^{p-1})$ true when $I(2^{p-1}) = \sigma(2^{p-1})/2^{p-1}$ is the abundancy index of $2^{p-1}$ and $6 \neq 2^{p-1}(2^p - 1)$ is an even perfect number (with corresponding Mersenne prime $2^p - 1$ )? MY ATTEMPT Claim For $p \geq 3$ , $$\frac{7}{4} \leq I(2^{p-1}) < 2.$$ Proof: Only the left-hand inequality is not evident (as $2^{p-1}$ is deficient , being a proper divisor of the perfect number $2^{p-1}(2^p - 1)$ ). $$I(2^{p-1}) = \frac{\sigma(2^{p-1})}{2^{p-1}} = \frac{2^p - 1}{2^{p-1}} = 2 - \bigg(\frac{1}{2^{p-1}}\bigg).$$ But since $6 \neq 2^{p-1}(2^p - 1)$ , then $p \geq 3$ , which implies that $$2^{p-1} \geq 4 \implies \frac{1}{2^{p-1}} \leq \frac{1}{4} \implies 2 - \bigg(\frac{1}{2^{p-1}}\bigg) \geq 2 - \frac{1}{4} = \frac{7}{4}.$$ QED Checking now whether this inequality is satisfied: $$I(2^{p-1}) - 1 > \frac{1}{I(2^{p-1})}$$ For $p \geq 3$ : $$I(2^{p-1}) - 1 \geq \frac{3}{4} > \frac{4}{7} \geq \frac{1}{I(2^{p-1})}.$$ For general $p$ : $$I(2^{p-1}) - 1 = 1 - \bigg(\frac{1}{2^{p-1}}\bigg) = \frac{2^{p-1} - 1}{2^{p-1}}$$ $$\frac{1}{I(2^{p-1})} =  \frac{2^{p-1}}{2^p - 1}$$ $$\bigg(I(2^{p-1}) - 1\bigg) - \frac{1}{I(2^{p-1})} = \frac{2^{p-1} - 1}{2^{p-1}} - \frac{2^{p-1}}{2^p - 1} > 0 \text{ when } p \geq 3.$$ Note that, since $I(2^{p-1})=x$ satisfies the inequality $$I(2^{p-1}) - 1 > \frac{1}{I(2^{p-1})} \iff x - 1 > \frac{1}{x} \implies x^2 - x - 1 > 0 \text{ since } x > 1 > 0 \implies x > \frac{1 + \sqrt{5}}{2} = \varphi \approx 1.618,$$ which is trivial compared to the inequality $$I(2^{p-1})=x \geq \frac{7}{4} = 1.75.$$ Finally, notice that $6 = 2^{2 - 1} \cdot (2^2 - 1)$ was excluded in this analysis because it is squarefree.","['golden-ratio', 'perfect-numbers', 'number-theory', 'divisor-sum', 'inequality']"
3792707,How to construct an algebra / field that is infinitely countable?,"It is well-known that a $\sigma$ -algebra / $\sigma$ -field can only be finite or uncountable infinite, but how to construct an example of algebra / field that is infinitely countable? This is actually a question from Billingsley's Probability and Measure problem 2.12.","['measure-theory', 'lebesgue-measure', 'probability-theory', 'real-analysis']"
3792709,Catalan sequence problem,"For $4$ variables $g_{1}, g_{2}, g_{3}, g_{4}$ ,the sum of the expressions $$
(g_1-g_2)(g_3-g_4),(g_1-g_3)(g_4-g_2),(g_1-g_4)(g_2-g_3)\quad
\mbox{is}\quad {\large 0}
$$ ( known as Euler's Identity ). So the rank of the vector space is $2$ . For $6$ variables, let \begin{align}
& M = \left\{(g_a-g_b)(g_c-g_d)(g_e-g_f)\mid a,b,c,d,e,f\text{ is a}
\right.
\\[1mm] &
\left.\text{permutation of
1,2,3,4,5,6, and }a < b,c < d,e < f\right\}
\end{align} It is easy to check by hand that the rank of $M$ is $5$ . For $8,10$ variables, the rank is $14, 42$ respectively.
( I found it using $\tt Mathematica$ ). For $2n$ variables, I guess the rank is the $\left(n + 1\right)$ th Catalan Number . Is that right?","['catalan-numbers', 'discrete-mathematics']"
3792712,Generalizing the summation process for infinite sets,"Today I found myself wondering about the sum of all integers $\mathbb Z$ . We know that $\mathbb Z$ is a countable set, This means that we can list all the elements of $\mathbb Z$ , thus we can solve the problem using sums: $$\sum_{z\in \mathbb Z}z=\sum_{z=1}^\infty z + (-z) = 0$$ So we have that the sum of all integers is 0. By the same argument we have that the sums of all rational numbers $\mathbb Q$ is also 0. My first question is: Is this argument valid and correct? Then I wonder: Then what is the sum of all real numbers $\mathbb R$ ? Contrarily to $\Bbb Z$ and $\Bbb Q$ , the set $\Bbb R$ is not countable. This means that it is impossible to list the numbers of $\Bbb R$ and thus impossible to sum all numbers using a sum. The first thing that came to my mind was integrals. I sometimes tend to think of integrals like the continuous version of summation. So we can express the sum of all real numbers as: $$\int_{-\infty}^\infty x \ dx = 0$$ This allows us to sum all elements of uncountable sets. For example the of all elements of $(0,1)$ , using this method would be: $$\int\limits_{x\in (0,1)} x \ dx = \int_0^1 x \  dx = \frac{1}{2}$$ My second question is: Is this generalization correct? My third question occurs when, assuming that this method is correct, I tried to calculate the sum of all irrational numbers. If the method is correct, then the sum of all irrational numbers would be: $$\int\limits_{x\in\mathbb I} x \ dx$$ But I don't know how to evaluate the integral because (I don't know the proper mathematical term for what I'm about to say so I'm sorry if it sounds not very rigorous) It has ""Holes"" in it. Between every 2 irrational numbers there's allays a rational number! If we try to integrate a function over $(0,1) \cup (2,3)$ there's also a hole in this, but we can divide the integral in two: one over $(0,1)$ and the other over $(2,3)$ . If we try to make use of this in our integral over $\mathbb I$ we would get: $$\sum_{q \in \Bbb I} \int\limits_{x\in\{q\}} x \ dx$$ But we have two problems with this: Firstly, that integral is a integral over a point, and that's allays zero. So that is not ideal because it would mean that the sum of any uncountable set will always be zero. We can't use a regular summation there because again, the set $\Bbb I$ is not countable. So we where trying to avoid the regular summation by generalizing it with integrals, but then it pops out again! So my third and last question is: Even if my generalization is not correct, is it sill possible to evaluate this integral?","['integration', 'elementary-set-theory']"
3792772,Multivariate Elliptic Integral,"I want to find a ""closed form"" solution to the following integral: $$I(a)=\int_{-1}^1\int_{-1}^1\int_{-1}^1\sqrt{\frac{a+ xy+yz+xz }{(1-x^2)(1-y^2)(1-z^2)}}\, \text{d}x\,\text{d}y\,\text{d}z$$ where $a>1$ to keep the integrand real valued.
I hope that the symmetry of the integrand might help.
I have tried integrating one variable after the other, but this involves Integrals of elliptic integrals that I am not familiar with: Another form of the integral is: $$I(a)=\int_{0}^\pi\int_0^\pi\int_0^\pi\sqrt{ a+ \cos(x)\cos(y)+\cos(y)\cos(z)+\cos(x)\cos(z) } \,\text{d}x\,\text{d}y\,\text{d}z$$ Evaluating the first integral, Mathematica gives: $I(a)=\int_0^\pi\int_0^\pi 2\sqrt{ a+\cos(y)+\cos(y)\cos(z)+ \cos(z) }E\left[\frac{2\cos(y)+2\cos(z) }{ a+\cos(y)+\cos(y)\cos(z)+ \cos(z) }\right]  \,\text{d}y\,\text{d}z$ Where $E$ is the Elliptic Integral of second kind. I dont know how to proceed.
Is there maybe a nice coordinate system I could transform into? Maybe I have to try a completely different approach?
Any insight would be helpful. Edit: I have made some progress by using the FCC Lattice Green's function.
It is defined by: $$G(a)=\frac{1}{\pi^3}\int_{0}^\pi\int_0^\pi\int_0^\pi\frac{1}{ 1 - \frac{a}{3}( \cos(x)\cos(y)+\cos(y)\cos(z)+\cos(x)\cos(z)) } \,\text{d}x\,\text{d}y\,\text{d}z$$ and has a known closed form solution in terms of Complete Elliptic Functions that can be found here (equation 2.20) I will add more info soon.","['integration', 'elliptic-integrals', 'multiple-integral', 'closed-form']"
3792804,How to convince myself (imagine) that $\Bbb S^1$-action on $\Bbb S^3$ fixes a circle of sphere?,"How to convince myself (imagine) that $\Bbb S^1$ -action on $\Bbb S^3$ fixes a circle of sphere? Due to this comment of Jason DeVito , it is easy to see that action of $\Bbb S^1$ on $\Bbb S^3\subset \Bbb C^2$ defined by $z*(w_1,w_2)=(zw_1,w_2)$ fixes the entire circle $\{(0,w):|w|=1\}\subset\Bbb S^3\subset \Bbb C^2$ .
But I can't imagine it, because the common picture of action in my mind is that an circle action is a kind of rotation, so it has a rotation axis and spinning around this axis can fix at most 2 point. Is it possible that the axis of rotation is not a line? Now, how can I think about this action geometrically? $z*(w_1,w_2)=(zw_1,\bar zw_2)$ . Edit: My understanding of last action is that: one side of $\Bbb S^3$ is spinning clockwise and other side is spinning counterclockwise (in different plane from first action) and these actions effect on the middle of sphere and it become scarious and kink in middle, Like cylinder if we spin the boundaries of it in different directions it become kink in middle like screw.","['differential-topology', 'group-actions', 'riemannian-geometry', 'differential-geometry']"
3792878,Weak $L^p$ convergence for passing to the limit in piecewise linear approximation of sign function?,"Consider $$ S_\epsilon(\xi) = 
\begin{cases}
1 & \text{ if } \xi > \epsilon \\ 
\xi/\epsilon &\text{ if }  |\xi| < \epsilon \\
-1 &\text{ if }  \xi < - \epsilon 
\end{cases}$$ which is a smoothed version of the $\mathrm{sign}$ function. Suppose that $u_n \to u$ weakly in $L^p([0,1])$ for all $p \in [1,\infty]$ as $n \to \infty$ . Is it true that $S_\epsilon(u_n-1) \to S_\epsilon(u-1)$ weakly in some $L^p$ ?","['measure-theory', 'real-analysis', 'calculus', 'lp-spaces', 'functional-analysis']"
3792888,"Find the angle between two tangents drawn from point $(0, -2)$ to the curve $y=x^2$","Find the angle between the two tangents drawn from point $(0, -2)$ to the curve $y=x^2$ . This is my attempt: Let $P(\alpha, \beta)$ be a point on the curve. $$\therefore \beta = \alpha^2$$ $$\frac{dy}{dx}\quad \text{at}\quad P(\alpha,\beta) = 2\alpha$$ Equation of tangent at P: $2\alpha x-y=2\alpha^2-\beta
\Rightarrow2\alpha x-y = 2\alpha^2 -\alpha^2$ $$\Rightarrow2\alpha x -y -\alpha^2 =0$$ A/Q $(0, -2)$ should satify this equation. $\therefore 2\alpha\times0 - (-2) - \alpha^2 = 0\Rightarrow\alpha^2=2$ $$\therefore\alpha=\pm\sqrt2$$ $$\Rightarrow\beta=2$$ Now putting these values to find slope $(m)=\frac{dy}{dx}=2\times\pm\sqrt2$ $$\therefore m = +2\sqrt2\quad and\quad -2\sqrt2$$ We know that for $\theta$ =angle between the lines and $m_1\quad\&\quad m_2$ be slope of lines: $$\tan{\theta} =\big|\frac{m_1-m_2}{1+m_1m_2}\big|$$ $$=\big|\frac{2\sqrt2-(-2\sqrt2)}{1+2\sqrt2\times-2\sqrt2}\big|= \big|\frac{4\sqrt2}{1-8}\big|=\frac{4\sqrt2}7$$ My answer does not match the book. The book is a very appreciated one, so it can't be wrong. I cannot find an error in my solution.
The book states the answer as $$\pi - 2\arctan\sqrt8$$ Edit: The book actually states its answer as $\pi - 2\arctan\sqrt8$ . I was the blind who couldn't see the 2 .","['analytic-geometry', 'tangent-line', 'geometry', 'slope', 'derivatives']"
3792920,Expected Matrix Product,"This question has arisen from a question about a Markov chain where the transition matrix $T$ is random but structured. The idea being that the transition is composed of two parts, transition $A$ and $B$ which occur in known quantities $n$ and $m$ respectively but unknown order. This means that $T$ is the product of $n$ matrices $A$ and $m$ matrices $B$ in some ordering. For example when $m=1$ and $n=2$ $$T \in \{ABB, BAB, BBA\}$$ The question is, when each permutation $\begin{pmatrix} m+n \\ m\end{pmatrix}$ of these $n+m$ matrices is equally likely what is the expected transition matrix $T$ ? Interestingly this is like considering necklaces with fixed content where the colors are matrices. I say this because in the sense that I'm interested in the behavior of $T$ as it is applied to itself, if this problem could be solved invariant to rotations of the ordering of $A,B$ that would also be helpful. My thinking: My initial hope was that $$E[T] = \left(\frac{n}{n+m}A +\frac{m}{n+m} B\right)^{n+m}$$ But that does not seem to be the case by numerical experiments for small $n,m$ where the expected value can be calculated directed by summing over every permutation. My second hope was to be able to ""factor out"" the matrices $A,B$ in the expected value expression. By letting $D = diag(rep(A,n),rep(B,m))$ the (n+m)*size(A) block-diagonal matrix we can consider constructing one order from some permutation $\Pi_1$ . \begin{align*}
T(\Pi_1) &= \prod_i^{n+m} (e_i^T \otimes I) (\Pi_1\otimes I) D (\Pi_1\otimes I)^T (e_i \otimes I)\\
&= \prod_i^{n+m} (e_i^T \Pi_1\otimes I)D (\Pi_1^T e_i \otimes I)
\end{align*} each term of this product permutes the diagonal blocks of $D$ is the same way, then $(e_i^T \otimes I) \cdots (e_i \otimes I) $ selects off the $i$ th block. This way each of the $n+m$ blocks of $A,B$ occur in some order determined by $\Pi_1$ . My hope from this formulation was that in this form each $\Pi$ would factor out in the expected value of $T$ : $$E[T] = \frac{1}{(\begin{pmatrix} m+n \\ m\end{pmatrix}} \sum_{\Pi} T(\Pi)$$ by using vectorizations but it doesn't seem to work. Notably for each term in the product of $T(\Pi)$ we have $$vec\left((e_i^T \Pi_1\otimes I)D (\Pi_1^T e_i \otimes I)\right) = (\Pi_1 e_i^T \otimes I)\otimes(e_i^T \Pi_1\otimes I) vec(D) $$ The problem here is that despite the data matrix $D$ factoring out nicely from one term it does not help us simplify the product as far as I can tell. Thank you for any of your thoughts!","['markov-chains', 'matrices', 'expected-value', 'combinatorics', 'probability-theory']"
3792932,Conditional expectation with multiple conditioning,"For any r.v.s $X$ and $Y$ : $$E(Y|E(Y|X)) = E(Y|X)$$ But I cannot seem to be able to prove this. I tried using Adam's Law with extra conditioning ( $E(Y|X) = E(E(Y|X,Z)|Z)$ ) but I don't seem to get anywhere with it. What I tried is the following: $$g(X) = E(Y|X)$$ $$E(Y|g(X)) = E(E(Y|X,g(X))|g(X))$$ Since the event $X$ happened and $g(X)$ happened are equivalent, conditioning on both $X$ and $g(X)$ is the same as conditioning on only one of them.
Is there any intuitive interpretation of this ? Does this also mean that conditioning on $X$ or any function $g$ of $X$ is the same ?","['statistics', 'conditional-expectation', 'probability']"
3792963,"Let $L=\lim_{x\to 0} \frac{ a-\sqrt {a^2-x^2} -\frac{x^2}{2}}{x^4}$, $a>0$. If $L$ is finite, find $a$ and $L$","I need a hint to start this question, because I have no idea how to do it. It’s a $\frac 00$ form, so L’Hospital can be applied, but that would be extremely tedious. Expansion can’t be used because there is no function to use it for. How do I start it?","['limits', 'limits-without-lhopital']"
3792997,Pentagram and Golden Ratio,Pythagoreans used the pentagram as their mystical symbol. They believed that every number-shape had a hidden meaning and the pentagram is related with the golden ratio. My questions are: The only reason why the golden ration is so famous is because of this relationships: $\frac{\text{red}}{\text{green}}=\frac{\text{green}}{\text{blue}}=\frac{\text{blue}}{\text{purple}}=\varphi ??$ How can it be proved without using angles?,"['golden-ratio', 'recreational-mathematics', 'math-history', 'geometry']"
3793014,Generating Function Intuition,"I am trying to understand the use of generating functions. I understood that we can compress a sequence into a generating function, so that each coefficient of the polynomial that it generates are the elements of the sequence. But I don't understand what does the inputs change? Let's say we have the generating function: $$G(x)=\sum^\infty_{k=0} p_k x^k$$ What happens when we give different values to $x$ , what is changing intuitively? I thought the $x^k$ term was there to encode the coefficient's location in the sequence, since we can't add $p_ax^a$ and $p_bx^b$ if $ a \neq b$ , so that the terms  stay heterogenous. But I saw that for a probability distribution the property $G(1)=1$ must hold. Is this the only case where giving a value to x is useful? Thanks a lot in advance for the explanations.","['taylor-expansion', 'intuition', 'generating-functions', 'soft-question', 'probability-theory']"
3793023,Congruent sets of an arithmetic sequence and a geometric sequence,"Suppose we have a $a,d,$ and $q$ such that $a \neq 0, d \neq 0.$ Then, let $M = \{a, a + d, a + 2d\}$ and $N = \{a, aq, aq^2\}.$ Given that $M = N,$ find the value of $q.$ (A) $\frac12$ (B) $\frac13$ (C) $-\frac14$ (D) $-\frac12$ (E) $-2$ I immediately thought about setting $a + d = aq$ and $a + 2d = aq^2.$ I then proceeded to do $aq^2 - aq = d,$ and substitute in for $d,$ which gave me $a + (aq^2 - aq) = aq.$ Simplifying then gave me $aq^2 - 2aq + a = 0,$ and dividing by $a$ gave me $q^2 - 2q + 1 = 0,$ which should mean that $q = 1.$ However, that's not an answer choice. What should I do instead?","['proof-writing', 'arithmetic-progressions', 'elementary-set-theory', 'quadratics', 'geometric-progressions']"
3793038,Show that a group of order $pq$ has subgroups of orders $p$ and $q$ without using Sylow’s and Cauchy’s theorem,"If $o(G)$ is $pq$ , $p>q$ are primes, prove that $G$ has a subgroup of order $p$ and a subgroup of order $q$ . This question is from Herstein and it comes before Sylow’s and Cauchy’s theorem. So I’m expecting an answer without using any of these. Here’s what I got so far: If $G$ is cyclic, then we are done, otherwise we can assume that it is not cyclic, which means every non-identity element must be of order $p$ or $q$ . Case (1): if there exists $a \in G$ such that $o(a) = p$ and if there also exists an element of order $q$ , then we are done. So we can assume that every non-identity element is of order $p$ . Now pick $b \in G$ such that $b \notin \langle a \rangle$ then $o(b) = p$ and $\langle a \rangle \cap \langle b \rangle = \langle e \rangle$ . So we have $\langle a \rangle \langle b \rangle \subset G$ but $o(\langle a \rangle \langle b \rangle) = \dfrac {o(\langle a \rangle) o(\langle b \rangle)}{o(\langle a \rangle \cap \langle b \rangle)} = p^2$ but $p^2 > pq$ [since $p>q$ ] so we got a contradiction. Give me a hint for the second case and correct me if my argument for the first case is wrong.","['group-theory', 'abstract-algebra']"
3793040,"Numbers from $1,\frac12,\frac13,...........\frac{1}{2010}$ are written and any two $x,y$ are taken and we replace $x,y$ by just $x+y+xy$","This is a really good question!(Everyone has encountered a question which makes them love math, this is mine:) We write a series of numbers $$1,\frac12,\frac13,..........,\frac{1}{2010}$$ Now we can pick any two numbers $x$ and $y$ and we replace these two numbers by just one number $x+y+xy$ This process is repeated until only one number is left, find the last number. This has just baffled me! Seriously having no idea how to proceed.
Isn't it interesting that we end up with the same number despite where we start?
All Hints are welcome on how to solve it","['contest-math', 'algebra-precalculus', 'sequences-and-series']"
3793105,Solving $x^3-3x^2+4x-12=0$ Without Factoring (Cardano's Method),"The question:  solve $$x^3-3x^2+4x-12=0$$ without using factoring (Cardano's method?) So I first have to depress the equation so i make the substitution $x=z+1$ .  We know this is the substitition because it should be of the form $z-\frac{a_2}{3a_3}=z-\frac{-3}{3(1)}=z+1$ .  This then gives us $$z^3+z-10=0$$ By cardano's method, we know that $p=1$ and $q=-10$ .  Thus we have that $$1=-3ab \qquad -10=-a^3-b^3$$ Solving this system gives (i believe) for $a$ gives $$a=\sqrt[3]{5\pm\frac{26\sqrt{3}}{9}}$$ $$b=\sqrt[3]{5\mp\frac{26\sqrt{3}}{9}}$$ and so $$z=a+b=\sqrt[3]{5\pm\frac{26\sqrt{3}}{9}}+\sqrt[3]{5\mp\frac{26\sqrt{3}}{9}}$$ I have tried reducing this as best as I can, but I can not get anyone of the solutions. If I were to factor the original equation, I should getg $$x^3-3x^2+4x-12=x^2(x-3)+4(x-3)=(x^2+4)(x-3) \Rightarrow x=3, \pm2i$$ So where am I making my mistake?","['cubics', 'algebra-precalculus', 'problem-solving', 'polynomials']"
3793107,Find all functions $f$ such that $f(mn) = f(m)f(n)$ and...,"Find all functions $f : N → N$ such that (a) $f(2) = 2$ (b) $f(mn) = f(m)f(n)$ for all $m, n ∈ N$ (c) $f(m) < f(n)$ for $m < n$ First, I substituted $m=1,n=2$ to get $f(1)=1$ . Next, we can easily notice that all powers of $2$ will be equal to themselves. That is $f(4)=4,f(8)=8$ , and so on. Now, the next step I'm not so sure is correct.
As $f(4)>f(3)>f(2)$ , and $f : N → N$ , I think $f(3)$ can only be $3$ but again I'm not so sure. If it is so, then I believe the only possible function is $f(x)=x$ . Now for the next part of the problem- What happens if the third condition is not given to us? Unfortunately I don't even have the answer to the problem let alone a solution.
Any hints would also be helpful, thanks.","['contest-math', 'functional-equations', 'functions', 'discrete-mathematics']"
3793112,How to prove this equality of the determinant of matrix?,"Prove that \begin{equation*}
\det\begin{pmatrix}
a^2 & b^2 & c^2 \\
ab & bc & ca \\
b^2 & c^2 & a^2
\end{pmatrix}
=(a^2-bc)(b^2-ca)(c^2-ab)\end{equation*} My attempt: \begin{equation*}
\det\begin{pmatrix}
a^2 & b^2 & c^2 \\
ab & bc & ca \\
b^2 & c^2 & a^2
\end{pmatrix}
=\det\begin{pmatrix}
a^2 & b^2 & c^2 \\
a(b-a) & b(c-b) & c(a-c) \\
(b+a)(b-a) & (c+b)(c-b) & (a+c)(a-c)
\end{pmatrix}
\end{equation*} But I think my direction is incorrect. Can anyone give me some hints or the solution of this question?","['matrices', 'determinant', 'linear-algebra']"
3793127,Open mapping theorem can fail if codomain is not Banach,"Give an example of a Banach space $V$ , a normed space $W$ , a bounded linear surjective map $T: V \to W$ and an open subset $G \subseteq V$ such that $T(G)$ is not open in $W$ . Attempt : Consider $V= (C([0,1], \Vert \cdot \Vert_\infty), W= (C([0,1], \Vert \cdot \Vert_1)$ and $T: V \to V: f \mapsto f$ . Clearly $T$ is a linear surjection with $$\Vert Tf \Vert_1 = \int_0^1 |f| \le \int_0^1 \Vert f \Vert_\infty = \Vert f \Vert_\infty$$ so $\Vert T \Vert \leq 1$ and $T$ is bounded. Moreover, we have $\Vert f \Vert_1 \leq \Vert f \Vert_\infty$ . We now show that $G= B_\infty(0,1)$ is not open for $\Vert \cdot \Vert_1$ . Indeed, suppose to the contrary that $0$ is a $\Vert \cdot \Vert_1$ -interior point of $G$ . Then there  is $\epsilon > 0$ such that $$B_1(0, \epsilon) \subseteq G = B_\infty(0,1)$$ Thus, for $f \in C([0,1])\setminus \{0\}$ we have $$\Vert \frac{\epsilon}{2 \Vert f \Vert_1} f \Vert_\infty \leq 1$$ I.e. $\Vert f \Vert_\infty \leq \frac{2}{\epsilon} \Vert f \Vert_1$ for $f \in C([0,1])$ . But then the norms $\Vert \cdot \Vert_1$ and $\Vert \cdot \Vert_\infty$ are equivalent, which implies that $W$ is Banach. This is a contradiction. Question : Is my attempt correct?","['banach-spaces', 'open-map', 'normed-spaces', 'solution-verification', 'functional-analysis']"
3793160,Example: Constant scalar curvature metric but not Einstein,"I understand that a Kaehler manifold $(M, \omega)$ (or any Riemannian manifold) has constant scalar curvature if it is Einstein. The opposite is not true: it is possible to have a constant scalar curvature Kaehler metric which is not Einstein. I just can't think of any examples. Can you give me one? I think it would be useful for others too.","['kahler-manifolds', 'complex-geometry', 'riemannian-geometry', 'differential-geometry']"
3793192,How can you approach $\int_0^{\pi/2} x\frac{\ln(\cos x)}{\sin x}dx$,"Here is a new challenging problem : Show that $$I=\int_0^{\pi/2} x\frac{\ln(\cos x)}{\sin x}dx=2\ln(2)G-\frac{\pi}{8}\ln^2(2)-\frac{5\pi^3}{32}+4\Im\left\{\text{Li}_3\left(\frac{1+i}{2}\right)\right\}$$ My attempt : With Weierstrass substitution we have $$I=2\int_0^1\frac{\arctan x}{x}\ln\left(\frac{1-x^2}{1+x^2}\right)dx\overset{x\to \frac{1-x}{1+x}}{=}4\int_0^1\frac{\frac{\pi}{4}-\arctan x}{1-x^2}\ln\left(\frac{2x}{1+x^2}\right)dx$$ $$=\pi\underbrace{\int_0^1\frac{1}{1-x^2}\ln\left(\frac{2x}{1+x^2}\right)dx}_{I_1}-4\underbrace{\int_0^1\frac{\arctan x}{1-x^2}\ln\left(\frac{2x}{1+x^2}\right)dx}_{I_2}$$ By setting $x\to \frac{1-x}{1+x}$ in the first integral we have $$I_1=\frac12\int_0^1\frac{1}{x}\ln\left(\frac{1-x^2}{1+x^2}\right)dx$$ $$=\frac14\int_0^1\frac{1}{x}\ln\left(\frac{1-x}{1+x}\right)dx=\frac14\left[-\text{Li}_2(x)+\text{Li}_2(-x)\right]_0^1=-\frac38\zeta(2)$$ For the second integral, write $\frac{1}{1-x^2}=\frac{1}{2(1-x)}+\frac{1}{2(1+x)}$ $$I_2=\frac12\int_0^1\frac{\arctan x}{1-x}\ln\left(\frac{2x}{1+x^2}\right)dx+\frac12\int_0^1\frac{\arctan x}{1+x}\ln\left(\frac{2x}{1+x^2}\right)dx$$ The first integral is very similar to this one $$\int_0^1\frac{\arctan\left(x\right)}{1-x}\,
\ln\left(\frac{2x^2}{1+x^2}\right)\,\mathrm{d}x =
-\frac{\pi}{16}\ln^{2}\left(2\right) -
\frac{11}{192}\,\pi^{3} +
2\Im\left\{%
\text{Li}_{3}\left(\frac{1 + \mathrm{i}}{2}\right)\right\}$$ So we are left with only $\int_0^1\frac{\arctan x\ln(1+x^2)}{1+x}dx$ as $\int_0^1\frac{\arctan x\ln x}{1+x}dx$ is already nicely calculated by FDP here . Any idea? I noticed that if we use $x\to\frac{1-x}{1+x}$ in $\int_0^1\frac{\arctan x\ln(1+x^2)}{1+x}dx$ we will have a nice symmerty but still some annoying integrals appear. In $I$ , I also tried the Fourier series of $\ln(\cos x)$ but I stopped at $\int_0^{\pi/2} \frac{x\cos(2nx)}{\sin x}dx$ . I would like to see different approaches if possible. Thank you.","['integration', 'fourier-series', 'polylogarithm', 'real-analysis']"
3793208,Changing the direction of integration,"I need to change the direction of the integral: $$ \int_0^1 dy \int_{0.5y^2}^{\sqrt{3-y^2}} fdx$$ From what I know, I first need to find the shapes: $0.5y^2 = x$ and $\sqrt{3-y^2} =x$ Shape I is a parabola: $y^2 = 2x$ Shape II is a circle $x^2 + y^2 = 3$ (radius of $\sqrt{3}$ ) So we basically draw horizontal arrows from the parabola to the circle while we keep $0 \leq y \leq 1$ . Something that looks very similar to this picture: We need to draw vertical lines, so it looks like this, but we have 3 areas: Where we hit the parabola (red) Where we hit the line $y=1$ (green) Where we hit the circle (blue) And so my final answer is: $$ \int_0^{0.5} dx \int_0^{\sqrt{2x}} fdy + \int_{0.5}^{\sqrt{2}} dx \int_0^1 fdy + \int_{\sqrt{2}}^{\sqrt{3}} dx \int_0^{\sqrt{3-x^2}} fdy$$ Am I right so far? If I am not, then how do I fix it? I feel stuck as I have no idea how to keep going... I would appreciate your help!
Thanks!","['integration', 'multivariable-calculus']"
3793215,"Let $b_{n}$ denote the number of compositions of $n$ into $k$ parts, where each part is one or two. Find the generating series for $b_{n}$","I am stuck with this combinatorics problems - Let $n$ be a positive integer and let $b_{n}$ denote the number of compositions of $n$ into $k$ parts, where each part is one or two. For example, $(1, 2, 1, 2, 1)$ and $(2, 2, 1, 1, 1)$ are two compositions of $n = 7$ into $k = 5$ parts. Firstly, we need to find the generating series for $b_{n}$ Secondly, Prove that $b_{n} = {k \choose n-k}$ for $k\le n \le2k$ and $b_{n} = 0$ otherwise.","['bit-strings', 'combinatorics', 'recurrence-relations', 'generating-functions']"
3793223,Inequality for function of $\arctan(x)$,"I want to show that $$f(x) = \frac{1}{\arctan(x)} - \frac{1}{x} $$ is increasing on $(0, \infty)$ .  I can see this clearly by plotting it, but I'm struggling to write it out rigorously.  It obviously suffices to show its derivative is always positive in this range (which is also clear from plotting it).  We have $$f'(x) = \frac{(1+x^2)\arctan^2(x) -x^2}{x^2(1+x^2)\arctan^2(x)}$$ so again it suffices to show that $$g(x) \equiv (1+x^2)\arctan^2(x) -x^2 \ge 0 \quad \forall x >0$$ (and, yet again, this is clear from plotting it).  I've jumped down the rabbit hole of taking the derivative of $g$ as well (since it is $0$ at $x = 0$ so it would again suffice to show that $g' \ge 0$ ) and it doesn't yield anything immediately useful for me.  Please help if you can","['calculus', 'derivatives', 'inequality']"
3793249,Bounds related to satisfiability problem,"This question is regarding MAX-E3SAT problem: Given a set of clauses with exactly three literals, find the maximum number of clauses that can be satisfied. The clauses are expressed as disjunctions of three literals. The literals are variables $x_i\in\{0,1\}$ . Assume that the literals are all distinct in a clause, and no clause has both $x_i$ and $\neg x_i$ as the clause will be trivially satisfied. Furthermore, all clauses are considered to be distinct. Let's say at most a fraction $\alpha$ of the $m$ clauses are satisfiable. Let $k=\sum_i^n (g_i-1)$ , where $n$ is the number of variables and $g_i=\text{max}(\{\text{occurrences of }x_i, \text{occurrences of }\neg x_i\})$ . I want to find lower and upper bounds on the ratio $\frac{m}{k}$ given $\alpha$ . The bounds can be in terms of $\alpha$ . In my attempt I realized that for an instance of E3SAT, with $l$ variables, to be not satisfiable we need $2^l$ clauses at the minimum. So reversing this, if we have $m$ clauses, then the instance is unsatisfiable if it has $< \log_2(m)$ variables. However, I can't seem to find a way to get a constant bound, and carry forward the intuition to any fraction $\alpha$ of the clauses not being satisfiable. Edit:
I figured a rather conservative and simple bound for $k$ . Number of occurrences of all the variables in the instance is $3m$ . Then $k< 3m$ . However, this seems to be a very conservative bound.","['satisfiability', 'logic', 'combinatorics', 'upper-lower-bounds']"
3793296,How to proof uniqueness with the usage of function and proving an inequality,"My first problem is connected with showing that there is only one couple of natural numbers which fulfills the condition $$x^y=y^x, \ x<y.$$ Of course these numbers are 2 and 4. It can be done with the help of the function $f(x)=x^{\frac{1}{x}}$ . Unfortunately I don't see any connection here. Second problem associated with the first one is with proving the inequality $$ \left(\dfrac{33}{32}\right)^{32}<\dfrac{32}{3}.$$ I can't prove in explicitly. Intuitively it is quite clear, but I seek formal proof which does not come to my mind.","['inequality', 'functions', 'real-analysis']"
3793326,Probability inequality for sum of non-negative independent random variables,"Suppose $X_i$ , $i \in \mathbb{N}$ are independent binary random variables with $P(X_i = 1) = p_i = 1-P(X_i = 0)$ and define $S_n \equiv \sum_{i=1}^n X_i$ .  I want to prove that for every $x > 0$ , we have $$P(S_n \ge x) \leq \left(\frac{\mu e}{x}\right)^x $$ I can do this for $x \in (0,1]$ by noting that the function $f(y) \equiv y^x, y \ge 0$ is concave for $x$ in this range, hence we have $$P(S_n \ge x) \leq P(eS_n \ge x) \leq P(e^x S_n^x \ge x^x) \leq \frac{e^x E(S_n^x)}{x^x}\leq \frac{e^x E(S_n)^x}{x^x} = \left(\frac{\mu e}{x} \right)^x $$ where we apply Jensen's inequality to get the last inequality.  I am lost about trying to get this right for $x > 1$ .  We can't apply Jensen's again because the function $f(y)$ is now convex on $x \in (1, \infty)$ so we need a different strategy entirely.  I'm not sure if this is the right idea, but we can write down an expression for the probability exactly as being $$P(S_n \ge x) = \sum_{J \subseteq \{1, ... n\}, |J| \ge x} \prod_{i \in J} p_i \prod_{i \not \in J} (1-p_i) $$ I can't see anything fruitful from this though. Any help would be much appreciated!","['inequality', 'independence', 'jensen-inequality', 'probability-theory']"
3793342,Non-commutative vector space,"A field acting on an abelian group is called a vector space. Is there a name for a field acting on a non-abelian group? What I mean is a group $G$ a field $F$ , and an operation $F \times G \to G$ , $(a, x) \mapsto x^a$ such that: $x^0 = e$ $x^1 = x$ $x^{a+b} = x^ax^b$ $x^{ab} = (x^a)^b$ Is there a name for this kind of structure? Why aren't they studied?",['abstract-algebra']
3793363,Continuous function with upper dini derivative greater than 0 implies function is increasing,"Let $f$ be continuous on $[a,b]$ with $\bar D f \geq 0$ (upper Dini derivative of $f$ ) on $(a,b)$ . Show that $f$ is increasing on $[a,b]$ .
Hint: Show this is true for $g$ with $\bar D g \geq \epsilon > 0$ on $[a,b]$ . Apply this to the function $g(x) = f(x) + \epsilon x$ . This is question 19 from chapter 6.2 of Royden-Fitzpatrick Analysis 4th edition. My approach is as follows $g$ is continuous as it is the linear combination of 2 continuous functions. $\bar D g = \bar D f +  \epsilon \geq \epsilon > 0$ which means $g$ is strictly increasing on $(a,b)$ . $f = g - \epsilon x$ and $\bar D f = \bar D g - \epsilon \geq 0$ implies $f$ is increasing (it is not decreasing) on $(a,b)$ . Does it make sense? Thanks for any help. The question is also related to Continuous function on $[a, b]$ with bounded upper and lower derivatives on $(a, b)$ is Lipschitz.","['measure-theory', 'real-analysis']"
3793401,Step in proof on Riemann Sums from Spivak Calculus.,"I was working out a proof in Spivak's Calculus (2008) - pg 279 . The following is a screenshot of the portion of the proof I'm having trouble with. My question is in working out combining steps 1,2, and 3 correctly. I want to arrive at $$\bigg|\sum_{i = 1}^{n}f(x_{i})(t_{i}-t_{i-1}) - \int_{a}^{b}f(x)dx \bigg| < \epsilon \\ \Rightarrow\ -\epsilon < \sum_{i = 1}^{n}f(x_{i})(t_{i}-t_{i-1}) - \int_{a}^{b}f(x)dx  < \epsilon$$ Fiddling around with equation 2, I would get something of the form $$ 0 \leq \sum_{i = 1}^{n}f(x_{i})(t_{i}-t_{i-1}) - L(f,P) \leq U(f,P) - L(f,P) < \epsilon$$ The same would occur for $\int_{a}^{b}f(x) dx$ .  Now using this idea I get something of the form: $$\epsilon > U(f,P) - L(f,P) \geq \sum_{i = 1}^{n}f(x_{i})(t_{i}-t_{i-1}) - L(f,P) \geq  \sum_{i = 1}^{n}f(x_{i})(t_{i}-t_{i-1}) - \int_{a}^{b}f(x) \geq ?? $$ Here is my issue, I can't say for sure that $\sum_{i = 1}^{n}f(x_{i})(t_{i}-t_{i-1}) - \int_{a}^{b}f(x) \geq 0$ . Nothing that I have can imply such and as a result of this I can't conclude that $\sum_{i = 1}^{n}f(x_{i})(t_{i}-t_{i-1}) - \int_{a}^{b}f(x) > -\epsilon$ . Which would allow me to finish this part of the proof. From experience I know it is a minor algebraic thing I'm missing, but I suppose I'm mentally fatigued and not seeing it. Some assistance would be nice.","['calculus', 'riemann-integration', 'real-analysis']"
3793418,Uniqueness criterion for tetration based on signs of derivatives?,"Consider the fractional iterations of the expontential function denoted $$ \exp^{[t]}(x) $$ $$ \exp^{[0]}(x) = x $$ $$ \exp^{[t]}(x) = \exp(\exp^{[t-1]}(x) $$ $$ \exp^{[l + m]} = \exp^{[l]}(\exp^{[m]}(x))$$ Where $t,l,m,x$ are real and $t > 0$ . My friend Tommy proposed once a condition for an infinitely differentiable solution. $t,x$ are real and $t > 0$ : $$ \frac{d^n}{d^n x} \exp^{[t]}(x) > 0 $$ It seems impossible to satisfy for analytic solutions because for $ 0 < t < 1$ we have singularities in the complex plane that force the radius being finite and the signs of the derivatives of the taylor series alternating ( because the singularities have taylor series with alternating signs and near the singularities we must have it too). For instance if you are close to a log singularity your taylor series must eventually copy the sign changes of the logarithm. However if the bundle of functions $exp^{[t]}$ are nowhere analytic on the real line but infinitely differentiable, this might be true ?? CONJECTURE 1 (existance conjecture) There exist a bundle of infinitely differentiable functions solution satisfying $$ \frac{d^n}{d^n x} \exp^{[t]}(x) > 0 $$ CONJECTURE 2 (uniqueness conjecture) The solution to conjecture 1 is unique (if it exists!) ; there is only one (non-analytic) solution for tetration satisfying the condition $$ \frac{d^n}{d^n x} \exp^{[t]}(x) > 0 $$ Can we prove conjecture 1 or 2 ? Is this a very general thing or exclusive for iterations of exponential functions ?
I mean, do many entire functions $g(x)$ with all derivatives positive ( at any $x$ ) , no real fixpoint ( and thus above $id(x)$ btw )  (like exp) satisfy $$ \frac{d^n}{d^n x} g^{[t]}(x) > 0 $$ ?? If conjecture 1 or 2 fail for function $g(x)$ does it work for some real $v$ and function $g(x) + v$ ??
In particular the function $\exp(x) + v$ ?","['smooth-functions', 'real-analysis', 'calculus', 'derivatives', 'tetration']"
3793423,"Does there exist a pair of infinite fields, the additive group of one isomorphic to the multiplicative group of the other?","It is a common exercise in algebra to show that there does not exist a field $F$ such that its additive group $F^+$ and multiplicative group $F^*$ are isomorphic. See e.g. this question . One of the snappiest proofs I know is that, if we suppose for a contradiction they are, then any isomorphism sends solutions of the equation $2x = 0$ in the additive group to solutions of the equation $y^2 = 1$ in the multiplicative group. Depending on whether the characteristic of $F$ is or isn't 2, the former has either $|F|$ or $1$ solution(s), while the latter has $1$ or $2$ solutions, respectively. There is no field for which these numbers agree, so $F^+ \not\cong F^*$ ever. One might now ask whether there is a pair of fields, $E$ and $F$, for which $E^+ \cong F^*$ as groups. Clearly $\def\GF#1{\mathrm{GF}(#1)}\GF2^+ \cong \GF3^*$, $\GF3^+ \cong \GF4^*$, and in general if $p$ is a prime and $p+1$ is a prime power, then $\GF p^+ \cong \GF{p+1}^*$. You can see that this characterizes the situation in the positive characteristic case, from the same equation trick above: if $\def\c{\operatorname{char}}\c E = 2$ and $\c F \ne 2$, we can make $|E| = 2$ and get a solution. Else we must have $\c E \ne 2 = \c F$. If $\c E = c \ne 0$, then elements of $E$ must get mapped to $c$-th roots of unity in $F$, and there can be at most $c$ of those. This leaves the case where $\c E = 0$, for which there are no finite fields. In fact, none of the cases above permit any infinite fields, either. This brings me to my question: Do there exist infinite fields $E$ and $F$ such that $E^+ \cong F^*$? I believe the answer is no, and it seems unlikely that such an isomorphism would exist, but I can't make heads or tails of it, really. Here's what I have. As above, I can show that if $E$ and $F$ are infinite, and $\phi: E^+ \to F^*$ is an isomorphism, then we may assume $\c E = 0$—so WLOG it is an extension of $\mathbb Q$—and $\c F = 2$. Every element of $E$ has infinite additive order, so every element of $F^*$ has infinite multiplicative order, and there are no roots of unity except $1 = \phi(0)$. However, if $a \ne 1$ in $F$, then $a$ has a $k$-th root $\phi(\frac1k \phi^{-1}(a))$ for all $k$, since $E \supseteq \mathbb Q$.","['field-theory', 'group-isomorphism', 'positive-characteristic']"
3793426,"A simpler approach to solve ""how many k-permutations of aaabbccdef are there?""","Given a problem as follows. How many 4-permutations of ""aaabbccdef"" are there? Attempt Divide the problem into disjoint cases: 4-permutation of $\{a,b,c,d,e,f\}$ permutation of $\{2*x, y, z\}$ permutation of $\{2*x, 2*y\}$ permutation of $\{3*a, x\}$ The number of permutations for case 1: $P^6_4=360$ case 2: $C^3_1\times C^5_2\times\frac{4!}{2!}=360$ case 3: $C^3_2\times \frac{4!}{2!\times 2!}=18$ case 4: $C^5_1\times \frac{4!}{3!}=20$ Total number of permutation is $758$ . Question Is there any simpler approach which is very useful for longer words to be made?",['combinatorics']
3793432,How do you find the number of contiguous subarrays of size $k$ in a given array?,"For example: Given the array $[1,2,3,4,5,6,7,8,9]$ where $N$ is the length of the array and $k$ is the subarray size. Here $N = 9$ and given $k = 5$ , we find that $N-k+1$ contiguous subarrays of size $k$ can be found. How can we prove $N-k+1$ as the number of contiguous subarrays of size $k$ ? I'm sure it is intuitive, but I can't wrap my head around it.","['elementary-set-theory', 'data-structure', 'combinatorics', 'algorithms']"
3793447,Number of labeled trees with given subgraph using prufer code.,"Problem statement I want to count number of trees with vertex set $V$ = {1, 2, 3,..., 10} that have $\\$ tree $T=$ < {1, 2, 3}, {{1, 2}, {2, 3}} > (looks like 1 -- 2 -- 3) as a subgraph. So if I think correctly, I need to find number of labeled trees with n vertices and 2 fixed edges. By Cayley's formula there are $n^{n-2}$ trees with n vertices. My take is that tree -> prufer code algorithm is finding smallest leaf, appending sequence with parent of this leaf and removing this leaf and edge connected with it. We will have two slots at our prufer sequence occupied by either (2,2), (3,2), (1, 2). One of these subsequences can start on $n-1$ slots. Other slots can be used by any of n vertices. So we get $3 \cdot (n-1) \cdot n^{n-4}$ . But it is completely wrong. I tried to use some of proofs of similiar problems with one fixed edge, but I have problem with understanding these it seems...","['graph-theory', 'trees', 'combinatorics', 'discrete-mathematics']"
3793472,Axiomizing volume over rationals,"Is there a nonnegative extended real valued function on subsets of $\mathbb{Q}^3$ that is finitely additive on disjoint sets, translation invariant, and outputs $(\text{length} \times \text{width} \times \text{height})$ for boxes? It is a remarkable result of Lebesgue measure theory that no such function that is countably additive exists over $\mathbb{Q}^3$ or $\mathbb{R}^3$ . I am wondering if the same is true for finitely additive set functions over $\mathbb{Q}^3$ . If so, it would seem to suggest that there is some fundamental obstacle to formalizing the intuitive notion of volume.",['measure-theory']
3793473,Laurent expansion of square root,"I have the following two part problem: (a) Prove that $(z^2 - 1)^{-1}$ has an analytic square root in $\mathbb{C} - [-1,1]$ (b) Find the Laurent expansion of an analytic square root from part (a) on a domain $\{a: |z| > 1 \}$ , centered at $z = 0$ . For part (a), I note that the mobius transformation $F(z) = \frac{z-i}{z+i}$ maps the $\mathbb{C} - [-1,1]$ onto $\mathbb{C}-(-\infty,0]$ . Since $\mathbb{C} - (-\infty,0]$ is simply connected and $F$ is nonzero on $\mathbb{C} - [-1,1]$ , we can define a single-valued analytic branch of $\sqrt{F(z)}$ on $\mathbb{C} - [-1,1]$ . Then, by a quick computation $$G(z) = \frac{1}{(z+i)^2\sqrt{F(z)}}$$ is an analytic square root of $(z^2 - 1)^{-1}$ in $\mathbb{C} - [-1,1]$ . However, I do not know how to go about part (b). Any help would be appreciated.","['complex-analysis', 'branch-cuts', 'laurent-series', 'analytic-functions']"
3793474,Simplify $\sum_{k = 0}^n \left[ \binom{m + n + k}{k} 2^{n + 1 - k} - \binom{m + n + k + 1}{k} 2^{n - k} \right]$.,"This is Exercise 6 from page 44 of Analysis I by Amann and Escher. Exercise: Simplify the sum \begin{align*}
S(m, n) := \sum_{k = 0}^n \left[ \binom{m + n + k}{k} 2^{n + 1 - k} - \binom{m + n + k + 1}{k} 2^{n - k} \right]
\end{align*} for $m, n \in \mathbb N$ . Hint: for $1 \leq j < \ell$ we have $\binom{\ell}{j} - \binom{\ell}{j - 1} = \binom{\ell + 1}{j} - 2\binom{\ell}{j - 1}$ . My attempt: Unfortunately I don't understand how to use the hint. I don't see how it corresponds with the expression in the sum. \begin{align*}
\sum_{k = 0}^n \Bigg[ \binom{m + n + k}{k} 2^{n + 1 - k} - \binom{m + n + k + 1}{k} 2^{n - k} \Bigg] &= \sum_{k = 0}^n \Bigg[ 2^{n - k} \Big[ \binom{m + n + k}{k} 2 - \binom{m + n + k + 1}{k} \Big] \Bigg]\\
&= \sum_{k = 0}^n \Bigg[ 2^{n - k} \Big[ \binom{m + n + k}{k} + \binom{m + n + k}{k} - \binom{m + n + k + 1}{k} \Big] \Bigg]\\
&= \sum_{k = 0}^n \Bigg[ 2^{n - k} \Big[ \binom{m + n + k}{k} - \binom{m + n + k}{k - 1} \Big] \Bigg] \text{ (Pascal)}.
\end{align*} At this point I'm stuck. I'm not sure if this is a dead end, especially since I didn't use the hint. I appreciate any help.","['summation', 'solution-verification', 'combinatorics', 'binomial-coefficients', 'discrete-mathematics']"
3793491,Prove two angles add up to 90 degrees,"$\triangle ABC$ is inscribed within circle $O$ . $D$ is the midpoint of $AC$ . $E$ is on $AB$ such that $ED/EB=CD/CB$ . $CE$ intersects circle $O$ at $F$ . Prove that $\angle EDF + \angle CDB = 90^{\circ} $ . The condition $ED/EB=CD/CB$ is awkward. I am thinking of using Menelaus theorem on $\triangle ABC$ and line segment $DE$ because there are a lot of equal line segments and ratios, but I didn't go very far.","['contest-math', 'euclidean-geometry', 'geometry', 'triangles', 'plane-geometry']"
3793505,Classification of holomorphic functions on the right half plane with certain conditions,"The following problem comes from an old complex analysis prelim exam: Determine all analytic functions $f: H \rightarrow \mathbb{C}$ on the half-plane $H : = \{ z\in \mathbb{C} : \Re(z) > 0 \}$ that satisfy $f(\sqrt{n}) = n$ and $|f^{(n)}(1)| \leq 3$ for all positive integers $n$ . Clearly $f(z) = z^2$ satisfies this, and I wish to show that this is the only example. Note that $f(z) = z^2 + \epsilon \sin(\pi z^2)$ fail to satisfy the derivative bound for any $\epsilon > 0$ . Additionally, the derivative bound implies that any such $f$ is analytic and sub-exponential with order 1. I can apply Carlson's theorem to show that $h(z): =f(z) - z^2$ is exactly zero, but this seems like a very heavy hammer to use for a prelim problem. Any guidance on a more simple proof would be greatly appreciated!",['complex-analysis']
3793517,Motivation for defining tangent vectors with derivations and why they should act on $f\in C^\infty(M)$,"I'm revisiting the definition for tangent spaces in Lee's Introduction to Smooth Manifolds and I'm trying to convince myself why we might define tangent vectors as derivations at a point $p\in M$ : Let $M$ be a smooth manifold, and let $p\in M$ . A linear map $v:C^\infty(M)\to \mathbb{R}$ is called a derivation at $p$ if \begin{align*}
v(fg) = f(p)vg + g(p)vf
\end{align*} for all $f,g\in C^\infty(M)$ . So far, I know that if $M=\mathbb{R}^n$ , then each derivation can be given as a directional derivative in some direction in $\mathbb{R}^n$ . After reading the parts on the differential and its computation in coordinates, I'm still wondering why we would be interested in defining a tangent vector as a map that acts on functions on the manifold and the benefits from acting on smooth functions. The main reason that I can think of is that the collection of derivations at a point forms a vector space, which is we what want for a tangent space. I have also looked at the approach of defining tangent vectors with equivalence classes of curves, but it seems that there's also an action on $f\in C^\infty(M)$ going on; we call curves $\gamma:J\to M$ the tangent vectors, and they have a directional-derivative-like operators that act on $f\in C^\infty(M)$ by \begin{align*}
\left.\frac{d}{dt}(f\circ \gamma)(t)\right|_{t=0}.
\end{align*} This seems really similar to how a vector in $\mathbb{R}^n$ defines its own directional derivative, but again, I'm not sure why the action on $f\in C^\infty(M)$ would be useful/significant.","['tangent-spaces', 'differential-topology', 'smooth-manifolds', 'differential-geometry']"
3793561,Intuition about Euler's Theorem on homogeneous equations,"I wonder, what would be the intuition or motivation to studying Euler Formula for homogeneous function $f:\mathbb{R}^k \to \mathbb{R}$ such that $f(tx) = t^n f$ , for all $t>0$ . $\sum x_i \frac{\partial f}{\partial x_i} = n f$ I understand its proof and can do some problem but it feels really artificial or rather just manipulation process in doing such problems. Kindly share the intuition or importance of Euler theorem, or share the sources where I can read about it. It would be helpful for me. Thanks in advanced.","['motivation', 'multivariable-calculus', 'calculus', 'intuition', 'homogeneous-equation']"
3793594,Upperbound for Covariance Matrix,"Suppose $X_t \in \mathbb{R}^d$ is a vector valued time series, or in other words a vector valued stochastic process indexed by $t \in \mathbb{Z}$ . Assume for the moment that $X_t$ is (weakly) stationary with $EX_t=0$ , $E\|X_t\|^2<\infty$ , and let $$
C_h = E[X_0 X_h^\top]
$$ denote the autocovariance matrix at lag $h$ . What I wish to show is that $$
\|C_h\|_2 \le \|C_0\|_2,
$$ or find a counterexample to this statement. Here $\|\cdot\|_2$ is the Hilbert-Schmidt Norm: $$\|A\|_2^2 = \sum_{i,j=1}^d a_{i,j}^2. $$ So far all I can show is the weaker statement that $$
\|C_h\|_2 \le trace(C_0).
$$ To see this, we have by the Cauchy-Schwarz inequality for expectation and stationarity that $$
\|C_h\|_2^2 = \sum_{i,j=1}^d (E[X_{0,i}X_{h,j}])^2 \le  \sum_{i,j=1}^d E[X_{0,i}^2]E[X_{h,j}^2] = \sum_{i,j=1}^d E[X_{0,i}^2]E[X_{0,j}^2] =[trace(C_0)]^2.
$$ Part of me believes that this bound must be sharp, i.e. there is a counter example where $\|C_h\|_2 > \|C_0\|_2$ , but I really have no idea! Whatever simple examples I have tried have $\|C_h\|_2 \le \|C_0\|_2$ , for instance vector autoregressive processes. Any help/advice is much appreciated.","['statistics', 'stochastic-processes', 'linear-algebra', 'probability-theory', 'probability']"
3793596,Laplace Transform of $\cos(t)/t$,"this seems like a homework problem. yes! To some extent. But really I was not getting it. I was not able to get the Laplace transform of $\cos(t)/t$ .
using the property of Integration in Laplace Transform, but since the integral is not convergent, I am not able to get the laplace transform. but I know it exist! then how to get the Laplace Transform? how can It be possible that Using one Method you are getting and other (Integration method) you are not getting the answer ?","['integration', 'laplace-transform', 'conditional-convergence', 'trigonometry', 'convergence-divergence']"
3793621,"If $f$ analytic and $\neq0$ in a simply connected domain, show a single valued analytic branch of $\log f$ is defined on that domain","Question : Show that, if $f(z)$ is analytic and $f(z)\neq0$ in a simply connected domain $\Omega$ , then a single valued analytic branch of $\log f(z)$ can be defined in $\Omega$ My Thoughts : Since $f$ is analytic in $\Omega$ then $\int_{\Omega}f(z)dz=0$ .  Now, then assumption that $f(z)\ne 0$ makes me think that we are going to be considering $\frac{f'(z)}{f(z)}$ at some point, because I am not sure how else that assumption would be relevant here.  So would it be a good idea to try and play with something like $\int \log f(z)dz$ , or something like that?  Or, does the problem come down to us picking a single valued analytic branch of $\log f(z)$ ?  Any help is greatly appreciated!  Thank you.","['complex-analysis', 'complex-integration']"
3793626,"Let C=$\left\{(t\cos(t),t\sin(t),t^2):0\le t\le\frac{\pi}{2}\right\}$. Compute $\int_CF\cdot d\text{x}$","$\def\hl#1#2{\bbox[#1,1px]{#2}}
\def\box#1#2#3#4#5{\color{#2}{\bbox[0px, border: 2px solid #2]{\hl{#3}{\color{white}{\color{#3}{\boxed{\underline{\large\color{#1}{\text{#4}}}\\\color{#1}{#5}\\}}}}}}}
\def\verts#1{\left\vert#1\right\vert}
\def\Verts#1{\left\Vert#1\right\Vert}
\def\pra#1{\left(#1\right)}
\def\R{\mathbb{R}}
\def\N{\mathbb{N}}
\def\Z{\mathbb{Z}}$ $\box{black}{black}{}
{Question}
{(a)\text{ Let F$\pra{x,y,z}=(y+z,\alpha x+z,x+\beta y)$. For what values of $\alpha$,}\\
\text{$\beta$ is F conservative. For those cases, find $f$ s.t. F$=\nabla f$}\\
(b)\text{ Let C=$\left\{(t\cos(t),t\sin(t),t^2):0\le t\le\frac{\pi}{2}\right\}$. Compute $\int_CF\cdot d\text{x}\hspace{21.3ex}$}}\\
\box{black}{red}{}
{Theorem 1.}
{\text{Let $U$ be an open subset of $\R^n$ for $n\ge2$, and let $G:U\to\R^n$ be a continuous vector}\\
\text{field. Then the following are equivalent:}\\
\text{1. There exists a function $f:U\to\R$ of class $C^1$ such that $G=\nabla f$.}\\
\text{2. $\int_CG\cdot d\text{x}$ for any closed piecewise smooth oriented curve $C$ in $U$.}\\
\text{3. $\int_{C_1}G\cdot d\text{x}=\int_{C_2}G\cdot d\text{x}$ for any two piecewise smooth oriented curves $C_1,C_2$ in $U$ that}\\
\text{ both start at the same point $P\in U$ and end at the same point $q\in U.$}
}\\
\box{black}{green}{}
{Def.(Conservative Vector Field)}
{\text{A continuous vector field $G:U\to\R^n$ is said to be conservative if any one of these cond-}\\
\text{itions is satisfied.}}\\
\box{black}{red}{}
{Theorem 2.}
{\text{If G is a conservative vector field of class $C^1$ on an open set $U\subset\R^3$, then curl G$=0.\hspace{4ex}$}}\\
\box{black}{red}{}
{Theorem 3.}
{\text{If G$:U\to\R^3$ is a $C^1$ vector field, $U$ is a convex, and curl G$=0$, then G is conservative.$\hspace{1.3ex}$}}$ My attempts $(a)$ From Theorem $2.$ and $3.$ we know that If F has convex domain, then curl F $=0$ if and only if F is conservative As F $:U=\R^3\to\R^3$ where $U$ is convex. and \begin{align}
\text{curl F}=&\nabla\times F\\
=&(\beta-1,0,\alpha-1)
\end{align} i.e. curl F $=0$ if $\beta=1$ and $\alpha=1$ . Therefore F $(x,y,z)=(y+z,x+z,x+y)$ have \begin{align}
f(x,y,z)=&\int_a^xF_1(t,b,c)dt+\int_b^yF_2(x,t,c)dt+\int_c^zF_3(x,y,t)dt\\
=&\int_a^xb+c~dt+\int_b^yx+c~dt+\int_c^zx+y~dt\\
=&~x y + x z + y z-a b - a c - b c
\end{align} Where $(a,b,c)\in U=\R^3$ , take $(a,b,c)=(0,0,0)$ then $f(x,y,z)=x y + x z + y z$ s.t. F $=\nabla f$ $(b)$ Then by Fundamental Theorem of Line Integrals \begin{align}
\int_C \text{F}\cdot d\text{x}=&\int_C \nabla f\cdot d\text{x}\\
=&f\pra{\frac{\pi}{2}\cos\pra{\frac{\pi}{2}},\frac{\pi}{2}\sin\pra{\frac{\pi}{2}},\pra{\frac{\pi}{2}}^2}-f(0,0,0)\\
=&\cos\pra{\frac{\pi}{2}}\sin\pra{\frac{\pi}{2}}\pra{\frac{\pi}{2}}^2+\cos\pra{\frac{\pi}{2}}\pra{\frac{\pi}{2}}^3+\sin\pra{\frac{\pi}{2}}\pra{\frac{\pi}{2}}^3\\
=&\pra{\frac{\pi}{2}}^3
\end{align} Is my solution correct?","['vector-fields', 'multivariable-calculus', 'calculus', 'solution-verification', 'line-integrals']"
3793671,Why does the one paragraph solution to IMO Problem 6 1988 work?,"Emanouil Atanassov, famously said to have completed the ""hardest"" IMO problem in a single paragraph and went on to receive the special prize, gave the proof quoted below, Question: Let a and b be positive integers such that $ab+1$ divides $a^2+b^2$ Show that $\frac{a^2+b^2}{ab+1}$ is the square of an integer Proof: $k=\frac{a^2+b^2}{ab+1} \implies a^2-kab+b^2=k, k\in \mathbb{Z}$ Assume $k$ is not a perfect square. Note that for any integral solution $(a,b)$ we have $a>0, b>0$ since k is not a perfect square. Let $(a,b)$ be an integral solution with $a>0, b>0$ and $a+b$ minimum. We shall produce from it another integral solution $(a',b)$ with $a'>0 , \ b>0$ and $a'+b<a+b$ . Contradiction (We omit the argument for arriving at $(a',b)$ ) $a'=0$ is sufficient for $k$ being a square, but it is not true in general. This proof seems to imply $a'=0$ for all solutions $(a,b)$ . The only assumption contradicted is the minimality of $a+b$ , not the assumption $k$ is not a perfect square. How does the assertion trivially follow from this proof? EDIT:
Here is the proof modified, but without the assumption $k$ is not a perfect square. $k=\frac{a^2+b^2}{ab+1} \implies a^2-kab+b^2=k, k\in \mathbb{Z}$ Let $(a,b)$ be an integral solution with $a>0, b>0$ and $a+b$ minimum. We shall produce from it another integral solution $(a',b)$ with $a'>0 , \ b>0$ and $a'+b<a+b$ . Contradiction (We omit the argument for arriving at $(a',b)$ ) I have also removed the second sentence, because $a,b>0$ is given in the question. What does this proof imply that the first does not?","['contest-math', 'elementary-number-theory', 'proof-explanation', 'solution-verification', 'algebra-precalculus']"
3793695,Proving Brouwer's fixed point theorem in $\mathbb{R}$,"Brouwer's fixed point theorem says that any continuous function $f$ mapping a compact convex set $\mathbb{\Omega}$ to itself has a fixed point. The other day I was reading a piece in a pop-sci magazine, which asked to prove the theorem in $\mathbb{R}$ . I got this: could you please confirm if it's correct, and in case it's not, help me find a valid proof? Also, if you have a more elegant proof, I'd love to hear about it. Thanks! A compact convex set in $\mathbb{R}$ is a closed interval, so I need to prove this for $\mathbb{\Omega}=[a,b]$ . Now, let's consider $g(x)=f(x)-x$ , which is also continuous. We assume $g(a)\cdot g(b)\neq0$ , otherwise we already found a fixed point. Of course, we must have $g(a)>0$ , otherwise we would have $f(a)<a$ which contradicts the hypothesis that $f$ maps $[a,b]$ into itself. Similarly, we must have $g(b)<0$ . Since $g(a)\cdot g(b)<0$ , then by Bolzano's theorem there is at least one $x_0\in[a,b]$ such that $g(x_0)=0\implies f(x_0)=x_0\ \square$","['fixed-point-theorems', 'real-analysis']"
3793748,How were amplitudes of the $\cos$ and $\sin$ chosen?,"I don't understand why we use $\displaystyle\sqrt{1^2+\left(\frac{1}{2}\right)^2}$ in the below transformation. Can someone help to explain? from $$f(x)=\frac{3}{5}-\frac{3}{5}e^t\left(\cos(2t)+\frac{1}{2}\sin(2t)\right)$$ transform to $$f(x)=\frac{3}{5}-\frac{3}{5}\sqrt{1^2+\left(\frac{1}{2}\right)^2}e^t\left(\frac{1}{\sqrt{1^2+\left(\frac{1}{2}\right)^2}}\cos(2t)+\frac{\frac{1}{2}}{\sqrt{1^2+\left(\frac{1}{2}\right)^2}}\sin(2t)\right)$$ let $\displaystyle\frac{1}{\sqrt{1^2+\left(\frac{1}{2}\right)^2}}=\cos\phi$ and $\displaystyle\frac{\frac{1}{2}}{\sqrt{1^2+\left(\frac{1}{2}\right)^2}}=\sin\phi$ , $$f(x)=\frac{3}{5}-\frac{3}{5}\sqrt{1^2+\left(\frac{1}{2}\right)^2}e^t(\cos\phi\cos(2t)+\sin\phi\sin(2t))$$",['trigonometry']
3793751,"How to calculate $\int _{-\infty }^{\infty }\frac{x\sin \left(x\right)}{1+x^4}\,dx$","I want to calculate $\int _{-\infty }^{\infty }\frac{x\sin \left(x\right)}{1+x^4}\,dx$ , but I don’t want to use complex analysis.  How can I calculate it? I tried $$I\left(t\right)=\int _{-\infty }^{\infty }\frac{x\sin \left(tx\right)}{1+x^4}\,dx$$ $$I''\left(t\right)=-\int _{-\infty }^{\infty }\frac{x^3\sin \left(tx\right)}{1+x^4}\,dx=-\int _{-\infty }^{\infty }\frac{\sin \left(tx\right)}{x}\,dx\:+\int _{-\infty }^{\infty }\frac{\sin \left(tx\right)}{x\left(1+x^4\right)}\,dx$$ $$=-\pi \:+\int _{-\infty }^{\infty }\frac{\sin \left(tx\right)}{x\left(1+x^4\right)}\,dx$$ $$I''''\left(t\right)=-\int _{-\infty }^{\infty }\frac{x\sin \left(tx\right)}{1+x^4}\,dx$$ $$I''''\left(t\right)+I\left(t\right)=0$$ Solving the differential equation and then setting the initial conditions seem like a very long process. How else can I calculate?","['integration', 'improper-integrals', 'ordinary-differential-equations']"
3793797,"A continuous function $f:\left[-\frac{\pi}{4},\frac{\pi}{4}\right]\to[-1,1]$ and differentiable on $\left(-\frac{\pi}{4},\frac{\pi}{4}\right)$.","$\blacksquare~$ Problem: Suppose a continuous function $f:\left[-\frac{\pi}{4},\frac{\pi}{4}\right]\to[-1,1]$ and differentiable on $\left(-\frac{\pi}{4},\frac{\pi}{4}\right)$ . Then, there exists a point $x_0\in \left(-\frac{\pi}{4},\frac{\pi}{4}\right)$ such that $$|f'(x_0)|\leqslant 1+f(x_0)^2$$ $\blacksquare~$ My Solution: Let's take $g(x) = \tan^{-1} f(x) $ . Then $g : \left[ - \frac{\pi}{4}, \frac{\pi}{4}\right] \to \left[- \frac{\pi}{4}, \frac{\pi}{4} \right] $ . Now, as $f$ is cont in $\left[- \frac{\pi}{4}, \frac{\pi}{4} \right]$ and differentiable in $\left(- \frac{\pi}{4}, \frac{\pi}{4} \right)$ , $g$ is also the same. By LMVT, we have that $$\frac{g\left(\frac{\pi}{4}\right) - g\left(-\frac{\pi}{4} \right) }{\frac{\pi}{2}} = g'(x_0) \quad \text{for some } x_0 \in \left(- \frac{\pi}{4}, \frac{\pi}{4} \right)$$ $$\implies  \frac{ \frac{\pi}{4} - \left(- \frac{\pi}{4}\right) }{ \frac{\pi}{2} } \geqslant \frac{g\left(\frac{\pi}{4}\right) - g\left(-\frac{\pi}{4} \right) }{\frac{\pi}{2}} = \left(\tan^{-1}f(x_0) \right)' = \frac{f'(x_0)}{1 + f(x_0)^2} $$ $$ \implies 1 + f(x_0)^2 \geqslant f'(x_0) $$ Again, after the LMVT part, we have that $$ \implies  \frac{ - \frac{\pi}{4} - \left( \frac{\pi}{4}\right) }{ \frac{\pi}{2} } \leqslant \frac{g\left(\frac{\pi}{4}\right) - g\left(-\frac{\pi}{4} \right) }{\frac{\pi}{2}} = \left(\tan^{-1}f(x_0) \right)' = \frac{f'(x_0)}{1 + f(x_0)^2} $$ $$ \implies - \left( 1 + f(x_0)^2 \right) \leqslant f'(x_0) $$ Hence, combining these two we have that $$ \lvert f'(x_0) \rvert \leqslant 1 + f(x_0)^2 \quad \text{for some } x_0 \in \left( - \frac{\pi}{4}, \frac{\pi}{4} \right) $$ Is this fine? Is there any glitch? Another way of a solution will be great! Regards, Ralph","['calculus', 'solution-verification', 'real-analysis']"
3793804,To show the center of homothety of the biggest and smallest circle lies in the common tangent over T,"$c_1$ centered at $A$ passing through $B$ . $BB′$ is a diameter of $c_1$ . $T$ a random point in segment $BB′$ . $c_2$ centered at $B′$ passing through $T$ . $c_3$ centered at $B$ passing through $T$ . $c_4$ tangent externally to $c_2$ and $c_3$ and internally tangent to $c_1$ $F$ is center of $c_4$ and $H,I$ are tangency points. It is clear to me that $Z = HI \cap AF$ is the second homothety center of $c_1$ and $c_4$ and I would like to prove that it also lies in that line perpendicular to $AB$ through $T$ . important related result that you probably should know: Show these three circles share their external common tangent lines This seems to be a general result about soddy circles","['euclidean-geometry', 'homothety', 'geometry', 'geometric-transformation', 'soddy-circles']"
3793814,Verification of a solution to a mathematical logic problem,"The question is as follows: A detective has interviewed four witnesses to a crime. The detective has concluded the following based on how those interviews went : If the butler is telling the truth, the cook is doing so too. The cook and the gardener can't both be telling the truth. The gardener and the handyman aren't both lying. If the handyman is telling the truth, the cook must be lying. The question is, can the detective figure out whether each of the individuals is lying or not? Explain the reasoning. Answer: We're here only considering whether someone is truthful or not. So we can just take a variable, that's either True or False in any of the possible cases, and walk ourselves back from there. cook is one such variable [True means that specific person is telling the truth, and False means the exact opposite]. If we consider cook to be True, handyman must be False (Statement #4). According to statement #3, gardener and handyman can't both be False  at the same time, as we already know handyman is False (i.e. lying), gardener has to be True. If gardener is True, according to statement #2, cook has to be False. This contradicts our first assumption, that is cook is True, i.e. telling the truth. Which leaves us to cook being False. We can't straight out just say that cook is False and the case is solved. That's because if cook is False, then handyman is True. But this branches statement #3 into two different routes. gardener and handyman aren't both False, which means either either one of them is True, or both are. As handyman is True, let's first consider gardener is False. Now we're again in the same situation where  either either of them is False or both are. If cook is True, we'll be contradicting our initial assumption, so cook can't be True. Which leaves us to cook being False`. This gives us the first set of logically correct assumptions. Let's note it down. cook = False
handyman = True
gardener = False
butler = False Now we'll be considering gardener to be True. If gardener is True, cook has to be False. So now we have another solution set cook = False
handyman = True
gardener = True
butler = False Comparing the two logically correct solutions we can easily come to the assumption that the detective can't determine whether the each individual is lying or not, as there are more than one possible cases. Is the method too tedious? Is there any other method of achieving the same? Everything is self taught, so use of different terminologies are alien to me right now, if anyone can point me to the right direction I'd be grateful.","['puzzle', 'solution-verification', 'logic', 'discrete-mathematics']"
3793817,"If $f(x)=\sum_{n=1}^{50}(x-n)^{51n-n^2},$ then find $\frac{f(51)}{f'(51)}.$","My work so far follows: We have: $$\ln f(x)=\ln\left[\sum_{n=1}^{50} (x-n)^{51n-n^2}\right].$$ Now differentiating both sides w.r.t. $x,$ we obtain: $$\frac{f'(x)}{f(x)}=\frac{\displaystyle\sum_{n=1}^{50}(51n-n^2)(x-n)^{51n-n^2-1}}{\displaystyle\sum_{n=1}^{50}(x-n)^{51n-n^2}}.$$ Plugging in $x=51,$ we have: $$\frac{f'(51)}{f(51)}=\frac{\displaystyle\sum_{n=1}^{50}(51n-n^2)(51-n)^{51n-n^2-1}}{\displaystyle\sum_{n=1}^{50}(51-n)^{51n-n^2}}\\=\frac{\displaystyle\sum_{n=1}^{50}n(51-n)^{51n-n^2}}{\displaystyle\sum_{n=1}^{50}(51-n)^{51n-n^2}}.$$ How to handle this messy fraction? Please suggest..","['calculus', 'derivatives', 'sequences-and-series']"
3793819,Ramanujan's $\sqrt{\frac{\pi e}{2}}$ formula [duplicate],"This question already has answers here : An infinite series plus a continued fraction by Ramanujan (2 answers) Closed 3 years ago . The following identity is due to Ramanujan : $$\DeclareMathOperator{\k}{\vphantom{\sum}\vcenter{\LARGE K}} \sqrt{\frac{\pi e}{2}}=\frac{1}{1+\k_{n=1}^\infty \frac{n}{1}}+\sum_{n=0}^\infty\frac{1}{(2n+1)!!}$$ or $$\sqrt{\frac{\pi e}{2}}=\cfrac{1}{1+\cfrac{1}{1+\cfrac{2}{1+\cfrac{3}{\ddots}}}}+1+\frac{1}{1\cdot 3}+\frac{1}{1\cdot 3\cdot 5}+\cdots $$ I'm interested in the proof of this identity, but I couldn't manage to find any reference except for the linked page.","['continued-fractions', 'pi', 'reference-request', 'sequences-and-series']"
3793823,Use generating functions to solve the non-homogenous recurrence relation,"Let $a_0=0, a_1=2,$ and $a_2=5$ . Use generating functions to solve the recurrence equation: $$a_{n+3} = 5a_{n+2} - 7a_{n+1}+3a_n + 2^n$$ for $n\geq0$ . This is a book problem from Applied Combinatorics. I am really confused about tackling $2^n$ part of the recurrence relation using generating functions. Edit: I know I need to convert the recurrence into series and I have broken it down, but am struggling with getting it into a proper form to do partial fractions. These are the equations I have managed to get. If we let $A(x) = \sum_{n \geq 0} a_n x^n$ be the generating function for $a_n$ then after the calculations I got: $$A(x)\cdot(1-5x+7x^2-3x^3)= 12x^3 - 9 x^2 + \frac{2x}{1-2x}$$ After simplifying: $$A(x) = \frac{12x^3 - 9 x^2 + \frac{2x}{1-2x}}{1-5x+7x^2-3x^3}$$ $$= \frac{24 x^4 - 30 x^3 + 9 x^2 - 2 x}{(1-2x)(x-1)^2(3x-1)}$$ Then, the partial fraction decomposition is: $$A(x) = -\frac{8}{1-2x} + \frac{13}{4}\frac{1}{1-3x} + \frac{37}{4}\frac{1}{1-x} - \frac{1}{2} \frac{1}{(1-x)^2} - 4$$ I have tried to plug in the values, but something doesn't seem right. Please let me know where I would have gone wrong.","['recurrence-relations', 'discrete-mathematics', 'generating-functions']"
3793828,Why has there been no unification of topology axioms and measure theory axioms?,"Related thread here . The axioms of a topological space and a measure space at the outset seem very similar. They differ in the closure axioms of unions and intersections. The uncanny resemblance between a metric and a measure makes me wonder as to why these axioms have been defined separately. Couldn't they develop a theory with just the concept of a measure and a measure space? The one issue I see is that it might create circular logic. If we need topological space axioms to develop concepts in measure theory, that is a reason why we'd need to separate the two concepts. Closure of arbitrary unions versus countable unions, and finite intersections versus countable intersections, is not something I'd like to see as the only difference between the two concepts. Why have two separate systems when they are, at least from the outset, very similar concepts?","['general-topology', 'soft-question', 'measure-theory', 'real-analysis']"
3793834,What is the most frequent largest prime factor of the numbers between two primes?,"Let $p_n$ be the $n$ -th prime and $l_n, n \ge 2$ be the largest of all the prime factors of the composite numbers between $p_n$ and $p_{n+1}$ . Since there are infinitely many prime gaps, each of these gap will have a largest prime factor in the gap. Also the same prime can be the largest prime factor in more than one prime gap; for example, $3$ is the largest prime factor between $(5,7), (11,13),(17,19),(71,73)$ etc. For $p_n \le 3 \times 10^8$ , I counted how many times each prime was the largest prime in some prime gap. The plot of the frequency of each prime occurring as the largest prime is shown below. Within the available data, the prime $113$ is the most frequent largest prime in gap with $2550$ occurrences and all the most frequent prime are in the neighborhood of $113$ . Questions : Is there any reason why one prime or primes in a certain neighborhood should occur more frequently? The most frequent prime $l_f$ for prime $p_n$ up to $3\times 10^5$ is $29$ , up to $3\times 10^6$ is $53$ , up to $3\times 10^7$ is $71$ and up to $3\times 10^8$ is $113$ . As we go higher up the number line, the most frequent prime factor in the gaps increases. What is the asymptotic order for the most frequent prime factor in gaps for primes up to $p_n \le x$ ? Update : Comment by @Gerry Myerson and data shows that the most frequent primes increases as we go higher up the number line. Related question : Is every prime is the largest prime factor in some prime gap? Source code p1 = 3

i = s = 0
step = target = 10^6
l = []
while True:
    i = i + 1
    p2  = next_prime(p1)
    g   = p1+1
    d_max = 2
    while g < p2:
        x = prime_factors(g)
        if d_max < x[-1]:
            d_max = x[-1]
        g = g + 1
    f = open('C:/WorkArea/Bhavcopy/Simulation/gap_primes2.csv','a+')
    f.write(str((p1,p2,d_max)) + '\n')
    f.close()
    if i == target:
        print(target)
        target = target + step
    p1 = p2","['prime-factorization', 'number-theory', 'elementary-number-theory', 'analytic-number-theory', 'prime-numbers']"
3793857,Evaluating the integral for a random walk,"Could someone please evaluate the integral: $$P(\vec{l};z)=\frac{1}{(2\pi)^2}\int_{-\pi}^{\pi}\int_{-\pi}^{\pi}\frac{\text{exp}(-i(l_{1}k_{1}+l_{2}k_{2})d{k_{1}}d{k_{2}}}{1-z^2\lambda(\vec{k})}$$ $\vec{l}$ is the direction variable.
The integral is a representative of a random walk on the honeycomb lattice. $$\lambda(k)=\frac{1}{9}[1+(2\cos(k_{1}))^2+4\cos(k_{1})\cos(k_{2})]$$ $k_{1}$ and $k_{2}$ are the Fourier variables and $z$ is the $z$ transform/generating function variable. Edit source for the integral: https://arxiv.org/pdf/1004.1435.pdf Edit : I made some progress in the equation post modifying the integral to account for the basis vectors,
We can take $\exp(-ik_1)=t_1$ and similarly for $k_{2}$ , then we can write the cosine terms in terms of $t_{1}$ and $t_{2}$ which we assume are complex valued and hence we can evaluate it using contour integrals? Edit2 Another approach that I am exploring is expanding the terms-","['random-walk', 'probability-distributions', 'integer-lattices', 'elliptic-integrals', 'probability-theory']"
