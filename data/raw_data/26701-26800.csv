question_id,title,body,tags
245327,Weak Law of Large Numbers for Dependent Random Variables with Bounded Covariance,"I'm currently stuck on the following problem which involves proving the weak law of large numbers for a sequence of dependent but identically distributed random variables. Here's the full statement: Let $(X_n)$ be a sequence of dependent identically distributed random variables with finite variance. Let $\displaystyle S_n = \sum_{i=1}^n X_i $ denote the  $n^\text{th}$ partial sum of the random variables $(X_n)$. Assume that Cov$(X_i,X_j) \leq c^{|i-j|}$ for $i, j \leq n$ where $|c| \leq 1$. Is it possible to show that $\displaystyle \frac{S_n}{n} \rightarrow \mathbb{E}[X_1]$ in probability? In other words, is it true that given any $\epsilon>0$, $$ \lim_{n\rightarrow \infty} \mathbb{P}\bigg[\Big|\frac{S_n}{n} - \mathbb{E}[X_1]\Big| > \epsilon\bigg] = 0$$ EDIT: Following some comments, it turns out that I had the right approach so I've gone ahead and answered my own question below.","['measure-theory', 'probability-limit-theorems', 'probability-theory', 'law-of-large-numbers', 'covariance']"
245330,Linear extension and Hahn Banach Theorem. Am I missing some detail in this exercise?,"This is an exercise problem from a course in functional analysis. However, it is not a homework problem. I think I got it figured out, however my teacher said something during the lecture that I didn't understand, and was lagging behind with taking notes, so I thought I'd think about it at home rather than ask during lecture. Now I can't make sense out of what she said, and I'd rather not wait until the next lecture to ask her. Here's where you guys come in :) Exercise: Show that there exists a non-zero linear functional $F \in (L^\infty[a, b])^\ast$ such that for any
$f \in C[a, b]$, $F(f) = f((a + b)/2)$ My Solution: In $L^\infty[a, b]$ we identify all functions that are equal almost everywhere. In each such equivalence class there exist a continuous function and we let that function represent the equivalence class. Therefore we can conclude that $C[a,b] \subseteq L^\infty[a, b]$. Note that $\| \cdot \|_\infty$ is a norm on $L^\infty[a, b]$ (Hahn-Banach requires only semi-norm). Now define $F(f) = f((a + b)/2)$ on C[a,b]. This is linear and bounded functional, $$F(\lambda f + \mu g) = (\lambda f + \mu g)\left(\frac{a + b}{2}\right) = \lambda f\left(\frac{a + b}{2}\right) + \mu g\left(\frac{a + b}{2}\right) = \lambda F(f) + \mu F(g)$$ $$|F(f)| = \left| f\left(\frac{a + b}{2}\right) \right| \leq \| f \|_\infty $$ By Hahn-Banach Theorem we can extend $F$ to $L^\infty[a, b]$ with the same norm such that $F(f) \leq \| f \|_\infty$, $\forall f \in L^\infty[a, b]$. Hence $F \in (L^\infty[a, b])^\ast$ Is this a complete solution? My teacher pointed something out, that I couldn't really grasp because I was behind on taking notes. But this is what she said basically: Teacher's comment: You can try to show that this $F$ does not come from $f \in L^1[a, b]$ i.e. $F \neq \phi_f$ where $$ \phi_f(g) = \int_a^b fg dx.$$
Does this make any sense? Why is this relevant? I can't see how, but at the same time I am afraid of missing some detail here. Thank you very much in advance!",['functional-analysis']
245333,An identity involving the chain rule,"I have a question concerning a demonstration in Pommerenke's Univalent Functions : Let $\Phi(t)$ be twice continuously differentiable and $\Psi(t) = t\frac{d}{dt}[t \Phi'(t)]$, $(0\leq t < \infty)$. Let $f(z)$ be analytic in $D$ (open unit disk). Since
$r\frac{d}{dr}|f(z)| = |f(z)|\text{Re}z \frac{f'(z)}{f(z)}$ and
$\frac{d}{d\theta}|f(z)| = -|f(z)|\text{Im}z \frac{f'(z)}{f(z)}$, a short calculation shows that $\left(r \frac{d}{dr}\right)^2 \Phi(|f(z)|) + \left(\frac{d}{d\theta}\right)^2 \Phi(|f(z)|)  = \Psi(|f(z)|)\left|z \frac{f'(z)}{f(z)}\right|^2$. This short calculation turns out to be rather confusing to me.",['complex-analysis']
245341,Arc Length: Difficulty With The Integral,"The question is to find the arc length of a portion of a function. $$y=\frac{3}{2}x^{2/3}\quad \text{ on }\, [1,8]$$ I couldn't quite figure out how to evaluate the integral, so I appealed to the solution manual for aid. \begin{align*}
y & = \frac{3}{2}x^{2/3}\\
y' & = \frac{1}{x^{1/3}}, \quad 1 \le x \le 8\\
s & = \int_1^8 \sqrt{1+ \left ( \frac{1}{x^{1/3}}\right ) ^2}\, dx\\
& = \int_1^8 \sqrt{\frac{x^{2/3}+1}{x^{2/3}}} \, dx\\
& = \frac{3}{2} \int_1^8 \sqrt{x^{2/3}+1}\left ( \frac{2}{3x^{1/3}}\right )\, dx\\
& = \frac{3}{2}\left [ \frac{2}{3}(x^{2/3}+1)^{3/2} \right ]_1^8\\
 & = 5 \sqrt{5} - 2 \sqrt{2} \approx 8.352
\end{align*} I don't quite understand what they did in the 5th step. Could someone perhaps elucidate it for me?","['calculus', 'algebra-precalculus']"
245354,Expected value of sums,Suppose we draw cards out of a deck without replacement. How many cards do we expect to draw out before we get an ace?,['probability']
245360,Holomorphic Euler characteristics and topological Euler characteristics of curves.,"I noticed that the holomorphic Euler characteristic $\chi(C,\mathcal{O}_C)=1-g$ of a smooth complex curve $C$ of genus $g$ is just a half of the topological Euler characteristic $\chi_{top}(C)=2-2g$. Do they coincide by accident or is there any good explanation of this?","['algebraic-geometry', 'algebraic-curves', 'complex-geometry']"
245362,Inital value problem,"Let A be a constant matrix. Suppose u(t) solves the inital value
  problem $\dot u = Au$, $u(0) = b$. Prove that the solution to the
  inital value problem $\dot u = Au$, $u(t_0) = b$ is equal to $\hat u =
 u(t -t_0)$. How are the solution trajectories related? I am not good with proofs. Never have I done it before prior of taking this differential equation class. Can anyone show me how to prove this?",['ordinary-differential-equations']
245367,Product of Borel $\sigma$-algebras?,"I just have a quick question about the Borel sigma algebra $B$ . $B$ is, of course, a sigma algebra, and we also know that $B$ contains all open sets, and that it is as small as possible. I am wondering if the space $B \times B$ has the same properties? I am not sure if this is the case, but I am starting to think not.",['measure-theory']
245376,"Prove that $(B, \|-\|_{\infty})$ complete. B the set of bounded real valued functions on [0,1] which are pointwise limit of continuous functions.","Question: Prove that $(B, \|-\|_{\infty})$ is complete. B the set of bounded real valued functions on [0,1] which are pointwise limit of continuous functions on [0,1]. Context: Old exam problem I'm using to study. Real Analysis by Carothers. I've attempted to avoid a direct proof from the definition using Cauchy sequences by appealing to the fact that ($B_{\infty}, \|-\|_{\infty}$) is a normed space where $B_{\infty}$ is the set of bounded real valued functions on $\mathbb{R}$ that are pointwise limits of continuous functions. So $B \in B_{\infty}$ and by a Theorem a normed spacve is complete if and only if every absolutely summable series in $B$ is summable. I'm having trouble making a solid case for proving the condition in the last part and also how to say that $B$ is indeed a normed space. Thank you in advance.","['normed-spaces', 'banach-spaces', 'real-analysis', 'analysis']"
245379,"Proof of $\frac{Y^{\lambda}-\lambda}{\sqrt{\lambda}}\to Z\sim N(0,1)$ in distribution as $\lambda\to\infty$?","This is an exercise of the Central Limit Theorem: Let $Y^{\lambda}$ be a Poisson random variable with parameter $\lambda>0$.
  Prove that $\frac{Y^{\lambda}-\lambda}{\sqrt{\lambda}}\to Z\sim N(0,1)$ in distribution as $\lambda\to\infty$. I've done that 
$$
Z_n\to Z\sim N(0,1)
$$
in distribution using the CLT, where $Z_n=(Y^n-n)/\sqrt{n}$. Some naive attempt to go is considering 
$$
Y^{n}\leq Y^{\lambda}\leq Y^{n+1}\tag{*}
$$
where $n\leq\lambda\leq n+1$ and somehow use the squeeze theorem. But both (*) and the squeeze theorem in convergence in distribution are NOT justified. How can I go on? Or do I need an alternative direction?","['probability-theory', 'measure-theory', 'convergence-divergence']"
245386,Question Relating with Open Mapping Theorem for Analytic Functions,This problem is taken from Section VIII.4 of Theodore Gamelin's Complex Analysis : Let $f(z)$ be an analytic function on the open unit disk $\mathbb{D}=\{|z|<1\}$.  Suppose there is an annulus $U = \{r<|z|<1\}$ such that the restriction of $f(z)$ to $U$ is one-to-one.  Show that $f(z)$ is one-to-one on $\mathbb{D}$. Any hints?,"['analyticity', 'complex-analysis']"
245397,Can I execute this division at this point?,"I realize this is basic, but this little doubt has been around with me for quite a while: I have this: $$\frac{(2n+3)n+1}{(2n+1)(2n+3)}$$ I need it to end up with this shape: $$\frac{n+1}{2n+3}$$ At first, I thought ""well, I simply remove the $(2n+3)$ from the numerator and from the denominator and done!"", but I would like to know if there are any other steps in the middle I am ""jumping"" by doing so. Basically, I would like to do it as ""slowly"" as possible (because my professor will want to during the tests...). Is there any small step I am missing?",['algebra-precalculus']
245405,Legendre's Equation,"I'm given two solutions to Legendre's equation: $$P_1=x$$ $$Q_0=\frac{1}{2} \ln\left(\frac{1+x}{1-x}\right)$$ I'm trying to explain why their overlap integral (i.e. $\int_{-1}^{1} P_1 Q_0 dx$) is non-zero.  I computed it and it is indeed non-zero, but I'm having a difficult time justifying why that is. I'm thinking it has something to do with that fact that the $P_n$ and $Q_n$ solutions are constructed w.r.t different weight functions. Or perhaps it has something to do with the completeness of solutions. Any thoughts?",['ordinary-differential-equations']
245406,How to show that this set is a Lebesgue set,"Let $\mathcal{K}$ be ,not necessarily countable, a family of compact cubes in $\mathbb{R}^N$. How to show that $\bigcup${$K:K\in\mathcal{K}$} is a Lebesgue measurable set? Here all cubes are nondegenerate. I think it may be necessary to use the Vitali's covering Theorem. But I am not sure how to use it. Can someone give some hints?",['measure-theory']
245424,Geometric multiplicities of the same eigenvalue of $A$ and of $A^T$,"For a square complex/real matrix $A$, $A$ and $A^T$ have the same
set of eigenvalues, each with same algebraic multiplicities, since
their characteristic polynomials are the same. I wonder for each eigenvalue, are its geometric multiplicities for
$A$ and for $A^T$ the same? Similar question for $A$ and $A^H$, where $H$ means conjugate and
transpose, and the relation between their eigenvalues is conjugate. Thanks!",['matrices']
245434,Geometry Proof: Convex Quadrilateral,"A quadrilateral $ABCD$ is formed from four distinct points (called the vertices), no three of which are collinear, and from the segments $AB$ , $CB$ , $CD$ , and $DA$ (called the sides), which have no intersections except at those endpoints labeled by the same letter. The notation for this quadrilateral is not unique- e.g., quadrilateral $ABCD$ = quadrilateral $CBAD$ . Two vertices that are endpoints of a side are called adjacent; otherwise the two vertices are called opposite. The remaining pair of segments $AC$ and $BD$ formed from the four points are called diagonals of the quadrilateral; they may or may not intersect at some fifth point. If $X$ , $Y$ , $Z$ are the vertices of quadrilateral $ABCD$ such that $Y$ is adjacent to both $X$ and $Z$ , then angle $XYZ$ is called an angle of the quadrilateral; if $W$ is the fourth vertex, then angle $XWZ$ and angle $XYZ$ are called opposite angles. The quadrilaterals of main interest are the convex ones. By definition, they are the quadrilaterals such that each pair of opposite sides, e.g., $AB$ and $CD$ , has the property that $CD$ is contained in one of the half-planes bounded by the line through $A$ and $B$ , and $AB$ is contained in one of the half-planes bounded by the line through $C$ and $D$ . a) Using Pasch's theorem, prove that if one pair of opposite sides has this property, then so does the other pair of opposite sides. b) Prove, using the crossbar theorem, that the following are equivalent: The quadrilateral is convex. Each vertex of the quadrilateral lies in the interior of the opposite angle. The diagonals of the quadrilateral meet. I can’t seem to make sense of a) at all. For b) I approached it in this way - I made three separate proofs: If the quadrilateral is convex, then the diagonals of the quadrilateral meet. Proof: Assume quadrilateral $ABCD$ is a convex quadrilateral. We have to prove that segment $AC$ and segment $BD$ have a point in common. By the
    definition of a convex quadrilateral, $C$ is in the interior of angle $DAB$ . Hence, ray $AC$ intersects segment $BD$ at some point $E$ (by the
    crossbar theorem). Therefore, $E$ is the required intersection point
    of the diagonals $AC$ and $BD$ . If the diagonals of the quadrilateral meet, then each vertex of the quadrilateral lies in the interior of the opposite angle. Proof: If each vertex of the quadrilateral lies in the interior of the opposite angle, then the quadrilateral is convex. Proof: I’m also confused over the proofs for 2. And 3.. Theorems and axioms that might be helpful: Pasch’s Theorem : If $A$ , $B$ , and $C$ are distinct points and $l$ is any line intersecting $AB$ in a point between $A$ and $B$ , then $l$ also intersects either $AC$ , or $BC$ . If $C$ does not lie on $l$ , then $l$ does not intersect both $AC$ and $BC$ . Interior an angle : Given an angle $\angle CAB$ , deﬁne a point $D$ to be in the interior of $\angle CAB$ if $D$ is on the same side of Ray $AC$ as $B$ and if $D$ is also on the same side of Ray $AB$ as $C$ . Thus, the interior of an angle is the intersection of two half-planes. Crossbar Theorem : If ray $AD$ is between ray $AC$ and ray $AB$ , then ray $AD$ intersects segment $BC$ . Any help at all would be much appreciated.",['geometry']
245444,Seeking an example in module theory -- (In)decomposable modules,"Can anyone give me a module $M$ over a ring $R$, such that $M$ is indecomposable, but $M$ has a submodule $N$ such that $N$ is decomposable? In general, what further assumptions can we put on the ring $R$ or $M$ to guarantee that $M$ has no such decomposable submodule $N$?","['modules', 'abstract-algebra']"
245462,How to test null hypothesis for spatial distribution?,"I am given a sample from a spatial distribution $X$. For example, my variable $X$ is the number of certain diseases per city per capita. Null hypothesis is that variable $X$ does not depend on the location directly (it might be dependent on another spatial distribution which is known say the amount of mercury in the water or other forms of pollution $Y$). How can I test this null hypothesis for a spatially distributed variable? What happens if I have very few samples? Say, for variable $x_1$ I have several million measurements but for variable $x_2$ I have 100 measurements? In case if I do not know $Y$, but I have other variables which I know are uniformly distributed ($X_i$ depends upon $Y$, but does not depends on location directly) how can I test null hypothesis? How can my test see the difference between cases A) when $X$ is a function of not only $Y$ everywhere B) $X$ is function of only $Y$ in some subregions, say the USA but it depends on other factors somewhere else?",['statistics']
245487,Infinitely many primes in the ring of integers,"Let $K$ be a number field such that $\mathcal{O}_K= \mathbb{Z}[\alpha]$ for some $\alpha$ algebraic integer. Prove that there are infinitely many primes $\mathcal{P} \subset \mathcal{O}_K$, such that $f(\mathcal{P}/p)=1$, where $(p)=\mathcal{P} \cap \mathbb{Z}$. 
  HINT: Use that if $f (x) \in \mathbb{Z} [x]$ is not constant, there are infinitely primes $p$ for which $f (x)$ has a root modulo $p$. Any help is appreciated!","['integer-rings', 'algebraic-number-theory', 'number-theory']"
245502,Cardinal Exponentiation $\lim_{\alpha\to\kappa} \alpha^\lambda$,"On Page 57 of Jech's Set Theory, Lemma 5.19 If $\kappa$ is a limit cardinal, and $\lambda \geq \operatorname{cf}{\kappa}$, then $\kappa^\lambda = (\lim_{\alpha\to\kappa} \alpha^\lambda)^{\operatorname{cf}{\kappa}}$ I have difficulty in understanding one step of proof, which is $(\lim_{\alpha\to\kappa} \alpha^\lambda)^{\operatorname{cf}{\kappa}} \leq (\kappa^\lambda)^{\operatorname{cf}{\kappa}}$ Here's how far I understand this inequality. $\lim_{\alpha\to\kappa} \alpha^\lambda = \bigcup_{\alpha<\kappa}\alpha^\lambda$ , the later is the union of function spaces $\{f:\lambda \to \alpha \}$ for all $\alpha < \kappa$. Since $\lambda \ge \operatorname{cf}{\kappa}$, it's possible to have $\sup\{f(\xi): \xi<\lambda\}=\kappa \notin \kappa$. Thus we have an element doesn't belong to $\kappa^\lambda$ ,which implies the reverse $\lim_{\alpha\to\kappa} \alpha^\lambda \ge \kappa^\lambda$ for $\lambda \ge \operatorname{cf}{\kappa}$.","['cardinals', 'elementary-set-theory']"
245503,Bivariate polynomials over finite fields,"If $f$ is a bivariate polynomial of degree $r$ over $\mathbb{Z}_p$, then the
number of solutions to $f(x,y)=0$ should be less than $rp$. This can be seen
by writing $f(x,y) = \sum_{i=0}^r a_i(x) y^{r-i}$ where $a_i(x)$ are univariate
polynomials of degree utmost $i$. For each fixed $x$ the $f(x,y)$ is a univariate
polynomial in $y$ of degree $r$ and only $r$ roots are possible. There are $p$
$x$'s so the total is $rp$. I wanted to know if this is this the best bound possible. While the univariate 
case seems to be much studied, I could not find many references for this question
on multivariate polynomials. Thanks,
Phanindra",['abstract-algebra']
245516,Can we intuitively say if two graphs are isomorphic?,I'm having a hard time understanding the explicit definition and was hoping someone could help me make a connection between the theory of isomorphism and the way it's actually applied (ex. how can we tell if two graphs are isomorphic)?,"['graph-theory', 'discrete-mathematics', 'graph-isomorphism']"
245525,Application of Law of large numbers,Could you give me hints on solving the question below? Let $X_i$'s be iid r.v. Assume that they are mean zero ($EX_i$ = $0$) and they have finite variance. Consider $\bar{X_n} = \sum_{i = 1}^{n} \frac{X_i}{n}$. The goal is to show that $\sum_{i = 1}^{n} \frac{(X_i - \bar{X_n})^2}{(n - 1)} \rightarrow \sigma^2 \text{ almost surely as n} \rightarrow \infty$,"['statistics', 'law-of-large-numbers', 'probability-theory']"
245531,Application of Borel Cantelli,"I'm trying to solve the question below and after an hour no success yet! Here is the question: $X_1, X_2, ...$ are independent poisson random variables with $EX_j = \lambda_j$. Assume that $ 0 < \lambda_j < 1$. Define $S_n = \sum_{i = 1}^{n} X_i$. We need to show that: $$ \text{if } \sum_{j = 1}^{\infty} \lambda_j = \infty \text{ then} \frac{S_n}{ES_n} \rightarrow 1 \text{ almost surely}$$. I appreciate if you could give me some hints on how I should approach this question. There is a hint on this question that Borel-Cantelli lemma should be used. As you know Borel-Cantelli (lemma 2) says: Let $A_1, A_2, ...$ be events in the probability space. Then: if $A_1, A_2, ...$ are independent and $\sum_{k = 1}^{\infty} p(A_k) = \infty$ then $\rightarrow p(A_k, \text{ infinitely often}) = 1$ Thank you for your help.","['probability-theory', 'convergence-divergence']"
245541,Find number of sub-squares in portion of graph,"i cam across this puzzle, we are supposed to find out the total number of squares present in this picture... as being a computer programmer i designed a algo in my head for the solution and did a dry run in my head as well. Start counting by square with highest dimension and then decrement the dimension by 1  step by step and at every decrement iterate the whole graph for matching dimensions & count them untill the dimension becomes zero... so 4x4 squares = 1
3x3 square  = 4
2x2 squares = 9
1x1 squares = 16 that makes 30 squares.. i was thinking isn't there a mathematical formula to calculate the number of sub-squares in a given squared-section of graph? p.s. i can see a pattern, here in the above 
square(4) + square(3) + square(2) + square(1) but i don't enough skills in discrete mathematics & numerical analysis to bring it down to an equation or formula but i am sure the formula already exists","['discrete-mathematics', 'algorithms', 'numerical-optimization']"
245550,"Big Oh notation of $7x^2$, confused","I'm supposed to figure out the Big-Oh notation of $7x^2$. Take a look at this . Now this says: Show that $7x^2$ is $O(x^3)$ When $x>7, 7x^2<x^3$, So let $C=1$ and $k=7$, we see $7x^2$ is $O(x^3)$. Alternatively, when $x>1, 7x^2<7x^3$ and so that $C=7$ and $k=1$, we have the relationship $7x^2$ is $O(x^3)$ By this logic shouldn't the Big Oh of $7x^2$ be:
$$7x^2<8x^2$$ 
$$7x^2 \in O(x^2)$$
with C=8 and k=1? Since $7x^2$ is obviously less than $8x^2$ for each $k>=1$. Why do we need $x^3$? At the same time the link says Let $f(x)=a_nx^n+…+a_1x+a_0$, where a0, a1, …, an-1, an are all
  real numbers, then f(x) is $O(x^n)$ And doesn't the above mentioned rule specifically state that for a polynomial of degree n, the big oh will be $O(x^n)$? What am I missing here?","['computer-science', 'discrete-mathematics']"
245562,geodesic submanifolds,I have a question to find all geodesic submanifolds of the hyperbolic space in n-dim. I did an exercise that all geodesics must be either lines perpendicular to the boundary of the hyperbolic space (under half space model) or great circles of spheres centered at the boundary. But I am not sure how to prove that only planes perpendicular to the boundary and spheres perpendicular to the boundary the only manifolds. Could you please help?,"['riemannian-geometry', 'differential-geometry']"
245563,Integral over triple product of spherical Bessel functions,"I would like to carry out symbolically the following integral $$\int_0^\infty d r \,r^2\, j_0( k r)\, j_0( k_1 r)\,  j_0( k_2 r)\,, $$
where $j_0(r)$ is the zeroth order spherical Bessel function and $k$,$k_1$ and $k_2$ are real numbers. Idea? I am wondering if I should use this expansion $$J_\alpha (\beta) = \sum_{m=0}^{\infty}\frac{(-1)^m}{m!\Gamma(m+\alpha +1)} \left(\frac{\beta}{2}\right)^{2m}$$ from this reference Clue If I am to believe Mathematica $$\int_0^\infty d r \,r^2\, j_0(  r)\, j_0( 2 r)\,  j_0( 3 r)=\frac{\pi}{48}$$
for instance, so the integral seems possible.","['integration', 'analysis']"
245579,How does a branch cut define a branch?,"I am studying complex analysis and I have problem understanding the
concept of branch cut. The lecturer draw this as some curve that starts from a point and goes
on and on in some direction (for example, something like $y=x$ for $x\geq0$ , but it doesn't have to be straight). The definition given in the lecture is A branch cut is a curve that is being presented in order to define a
  branch and then he added a note Points on the branch cut are singular. Can someone please explain how does such a curve define a branch of
a function ? As I understand it, if $f(z)=u(r,\theta)+iv(r,\theta)$ then we want $\alpha<\theta\leq\alpha+2\pi$ for some real $\alpha$ . How does
a curve define this $\alpha$ ? Why are the points on a branch cut singular? Are we also assuming
something about the function that we are trying to define a branch
of it?",['complex-analysis']
245587,Are there any efficient ways to tell if a graph has a Hamiltonian circuit?,"For example, consider this graph.  What are some common methods for determining whether the graph has a Hamiltonian circuit?  After trying to find one, I'd conclude that it doesn't, but I don't know how to argue why it doesn't. Any insight on the topic would be great; thanks for the help!","['graph-theory', 'discrete-mathematics', 'hamiltonicity']"
245591,Period of linear congruential generator,"How can you calculate the probability distribution of the period length of a linear congruential generator? That is $X_{n+1} = (aX_n + c) \bmod m$ where $a$ is chosen uniformly at random from $\{1,\dots, m-1\}$ and $c$ is chosen uniformly at random from  $\{0,\dots, m-1\}$ and $m$ is a fixed prime.   Take $X_0$ to be some arbitrary value from $\{0,\dots, m-1\}$. If it is hard to do exactly, is it possible to give good bounds for the cdf?","['probability', 'random']"
245598,Triple integral of a function,"Upon integration, $\int f(x) \implies $ area of curve. $\iint f(x) \implies $ volume under the curve. $\iiint f(x) \implies $ ? . We are expected to come up with something 4 dimensional? I simply know. $\iiint 1 \implies $ Volume. $\iiint \rho(x) \implies $ gives mass.",['multivariable-calculus']
245608,Find an angle in a given triangle,$\triangle ABC$ has sides $AC = BC$ and $\angle ACB = 96^\circ$. $D$ is a point in $\triangle ABC$ such that $\angle DAB = 18^\circ$ and $\angle DBA = 30^\circ$. What is the measure (in degrees) of $\angle ACD$?,"['geometry', 'triangles']"
245610,The existence of second derivative,"Let $f(x)=|x|x$ then $f''(0)$ does not exist. Why? If $x>0$, $f'(x)=2x$ and if $x<0$, $f'(x)=-2x$. Then when $x=0$, does $f'(x)$ also not exist?",['derivatives']
245698,"Proving $\lim_{n\to \infty}\frac{n^\alpha}{2^n}=0, \alpha>1$","I'm attempting to prove a basic limit: $$\lim_{n\to \infty}\frac{n^\alpha}{2^n}=0, \alpha>1$$
(It seems like this should be here somewhere already, but I wasn't able to found it through search, I possibly need help with my searching skills? :) Here's what I came up with: A) There are $\alpha$ powers of $n$ in the numerator (duh). B) $2^n=(1+1)^n=1+n+\binom{n}{2}+\cdots+\binom{n}{n-1}+1$ C) The highest power of $n$ in the denominator is $\lfloor\frac{n}{2}\rfloor$ (from the binomial theorem) D) Thus the power of $n$ in the denominator grows indefinitely, while in the numerator it always stays $\alpha$. If these are true, it then follows that for some $n_0$ and all $n>n_0$, $2^n$ grows faster than $n^\alpha$ and the limit approaches zero. However, this is very vague and possibly untrue, and this is where I got stuck. Thanks a lot for any help!",['limits']
245705,Derivative of the composition of two differentiable functions,"Calculate  $$
\frac{\mathrm d}{\mathrm dt} f (g(t^2),g(t^4)),
$$
where $f$ is a differentiable function of two variables and $g$ is a differentiable function of one variable. Your answer should be expressed in terms of $f, g$ and their derivatives and/or partial derivatives. I am assuming it is a partial derivatives question. I have never encountered one like this before. Any help would be much appreciated.",['derivatives']
245720,"""How long 'til we get there?"" Road trip puzzle","Road trips can be fun, but they often appear to go slower the closer you get to your destination. I thought up this puzzle while on a recent trip. Thought it would be good food for thought. Curious about the different approaches to solving it. Suppose you have D miles until you reach your destination. The rule is that the speed at which you travel is equal to the distance to your destination. So when you are 60 miles from your destination your speed must be 60 mph; 50 miles from destination, 50 mph; etc. How long until you reach your destination? EDIT:
I'm pretty sure that the answer is infinity—you will never get to your destination because you will always be one hour away. I'm curious about how people come up with their solutions. So far, very entertaining.","['puzzle', 'ordinary-differential-equations', 'calculus']"
245723,Definition of a topological property,"""A topological property or topological invariant is a property of a topological space which is invariant under homeomorphisms. That is, a property of spaces is a topological property if whenever a space X possesses that property every space homeomorphic to X possesses that property. Informally, a topological property is a property of the space that can be expressed using open sets."" (I copied it from Wikipedia) Now my question is: What is the definition of a topological property ? Of course you can define it as wiki defines it. But I am more concerned about the the part of wiki's ""definition"" which says that ""Informally, a topological property is a property of the space that can be expressed using open sets."" Is there a definition of a topological property that says which well formed formulas are well formed formulas of topological properties and which are not ? Because of what I read in wikipedia, I was expecting to see a definition of a topological property that talks about the internal structure of the well formed formula of the property. Then, I also expected that there was a theorem that says that if $(X_1,T_1),(X_2,T_2)$ are any two homeomorphic topological spaces and the well formed formula $\phi(X,T)$ is a topological property, then: $\phi(X_1,T_1)$ iff $\phi(X_2,T_2)$ Is there such a definition and such a theorem ? Such a definition and such a theorem will enable one to spot many topological properties easily. Here is a similar question: Can you characterize all properties of topological spaces which are preserved by homeomorphisms","['general-topology', 'logic']"
245733,Index of a sublattice in a lattice and a homomorphism between them,"I am asked to show that if $\phi_A$ is the homomorphism from $\mathbb{Z}^k \rightarrow \mathbb{Z}^k$ given by $\phi_A(x)=xA$ then the index of $\phi(\mathbb{Z}^k)$ in $\mathbb{Z}^k$ is finite if and only if $A$ is nonsingular. While this seems intuitive to me, one obstacle to proving this is that I am not quite sure of how to represent the index of a sublattice in a lattice! The way I understand it, $j\mathbb{Z}^k$ has index $j^k$ in $\mathbb{Z}^k$, for an integer $j$. I am used to indices in finite groups but not infinite groups, so is the trick to show this sort of correspondence? Furthermore, I would like to know if this is a valid sketch of a proof: If $A$ nonsingular, $A'$ is in Smith Normal Form ($PAQ=A'$) and $\det A'$ is nonzero, so the columns of $P^{-1}$ form a basis for $\mathbb{Z}^k$ and the columns of $AQ$ form a basis for the sublattice such that each column in the basis for the sublattice is an integral multiple of the columns in the basis for the lattice $\mathbb{Z}^k$, and since these multiples are given by the diagonal entries of SNF, we have that for every one point in the sublattice, there are $\prod a_i=\det A'=\det A$ points in the main lattice. If $A$ singular, we have the same as (1) except now at least one of these columns is a multiple $0$ times the column for the basis in the main lattice, so there are infinitely many points in the main lattice for each point in the sublattice.","['integer-lattices', 'group-theory', 'abstract-algebra']"
245735,Pushout of open map is open,"I have been struggling with the following problem. Consider the pushout for topological spaces (or adjunction space) $B \cup_A C$ obtained by gluing together $B$ and $C$ along $A$ by means of continuous maps $f$ and $g$.
$$
\newcommand{\ra}[1]{\kern-1.5ex\xrightarrow{\ \ #1\ \ }\phantom{}\kern-1.5ex}
\newcommand{\ras}[1]{\kern-1.5ex\xrightarrow{\ \ \smash{#1}\ \ }\phantom{}\kern-1.5ex}
\newcommand{\da}[1]{\bigg\downarrow\raise.5ex\rlap{\scriptstyle#1}}
\begin{array}{c}
A & \ra{f} & B\\
\da{g} & & \da{g'}\\
C & \ras{f'} & B \cup_A C\\
\end{array}
$$
show that if $f$ is open and injective then $f'$ (the pushout of $f$) is open. I have tried to take an open set $U \subseteq C$, and show that $f'(U)$ is open, for this I have to show that $g'^{-1}(f'(U))$ is open in $B$, so I tried it to compare it somehow to $f(g^{-1}(U))$ which is an open in $B$, but have not been able to make any progress after that. Also I'm not sure how to use the injectivity of $f$, is it maybe for its inverse? so I can take the equality $f'(g(x)) = g'(f(x))$ and maybe manipulate it somehow to get something like $f'(g(f^-1(x)) = g'(x), x \in B$, but I'm not sure if that is helpful. Any help would be appreciated.","['general-topology', 'category-theory']"
245744,Must-read papers in Operator Theory,"I have basically finished my grad school applications and have some time at hand. I want to start reading some classic papers in Operator Theory so as to breathe more culture here. I have read some when doing specific problems but have never systematically study the literature. I wonder whether someone can give some suggestions on where to start since this area has been so highly-developed. Maybe to focus the attention let's, say, try to make a list of the top 20 must-read papers in Operator Theory. I believe this must be a very very difficult job, but maybe some more criteria would make it a little bit easier. I can only read English and Chinese and it's a pity since I know many of the founding fathers use other languages. I prefer papers that give some kind of big pictures, since I can always pick up papers related to specific problems when I need them (but this is not a strict restriction). I would like to focus on the theory itself, not too much on application to physics. I have already done a rather thorough study of literature related to the invariant subspace problem, so I guess we can omit this important area. Thanks very much!","['banach-spaces', 'operator-theory', 'operator-algebras', 'hilbert-spaces', 'functional-analysis']"
245745,What is the maximum volume of a cylinder that can fit in a sphere of a constant radius?,"The first question that comes into my mind here is whether any cylinder that touches(at 4 pts) the circumference of the sphere and does not go out of it, has equal volume? Second, how do i mathematically limit the volume of the cylinder to be less than that of a sphere? Squeeze theorem? Please help, thanks!","['geometry', 'calculus', 'derivatives']"
245749,How to tell if two matrices are similar? [duplicate],"This question already has answers here : How do I tell if matrices are similar? (6 answers) Closed 10 years ago . Two n-by-n matrices A and B are called similar if $$
     \! B = P^{-1} A P $$ for some invertible n-by-n matrix P. Similar matrices share many properties: Rank Determinant Trace Eigenvalues (though the eigenvectors will in general be different) Characteristic polynomial Minimal polynomial (among the other similarity invariants in the Smith normal form) Elementary divisors Given two square matrices A and B, how would you tell if they are similar? Constructing a $P$ in the definition seems difficult even if we know they are similar, does it? Not to mention, use this way to tell if they are similar. Are there some properties of similar matrices that can characterize
similar matrices? Thanks!",['matrices']
245760,A coupling card trick in Durrett's book,"This is an example in Durrett's book ""Probability theory: theory and examples"", it's about the coupling time in Markov chains, but I can't see the reason behind it. The trick is played by two persons A and B. A writes 100 digits from 0-9 randomly, B choose one of the first 10 numbers and does not tell A. If B has chosen 7,say, he counts 7 places along the list, notes the digits at the location, and continue the process. If the digit is 0 he counts 10. A possible sequence is underlined in the list: $$ 3\  4\  \underline{7}\  8\  2\  3\  7\  5\  6\  \underline{1}\  \underline{6}\  4\  6\  5\  7\  8\  \underline{3}\  1\  5\  \underline{3}\  0\  7\  \underline{9} \ 2\  3\ ...$$ The trick is that, without knowing B's first digit, A can point to B's final stopping location. He just starts the process from any one of the first 10 places, and conclude that he's stopping location is the same as B's. The probability of making an error is less than 3%. I'm puzzled by the reasoning behind the example, can anyone explain it to me ?",['probability']
245762,Continuous functions on discrete product topology,"Let $A = \{a_1,\dots,a_m\}$ be a finite set endowed with a discrete topology and let $X = A^{\Bbb N}$ be the product topological space. I wonder which bounded functions $f:X\to\Bbb R$ are continuous on $X$. For example, it is clear that if $f$ depends only on a finite number of coordinates then $f\in C(X)$, i.e. if there exists some finite $n$ such that
$$
f(x_1,\dots,x_n,x_{n+1},x_{n+2},\dots) = f(x_1,\dots,x_n,x'_{n+1},x'_{n+2},\dots) \quad \forall x_{n+1},x_{n+2},x'_{n+1},x'_{n+2},\dots
$$
then $f\in C(X)$. Thus it seems that only dependents on infinitely many coordinates may violate continuity. I would be happy, if one could tell me whether there are some useful necessary/sufficient conditions to assure $f\in C(X)$. In particular, if $B\subset A$ and $1_B(a)$ is the indicator (characteristic) function of $B$, does it hold that 
$$
  g(x):=\limsup\limits_{k\to\infty}1_B(x_k)
$$
is a continuous function on $X$.","['general-topology', 'reference-request', 'real-analysis']"
245774,Weakly Cauchy sequences need not be weakly convergent,"A sequence $(x_n)$ in a Banach space $X$ is called weakly Cauchy if for every $\ell \in X'$ the sequence $(\ell(x_n))$ is Cauchy in the scalar field. I want to show that weakly Cauchy sequences are not necessarily weakly convergent. This seems to be the case for Hilbert spaces On the limits of weakly convergent subsequences , whats the difference?","['weakly-cauchy-sequences', 'functional-analysis', 'banach-spaces']"
245798,Definite integral over triple products of higher order Bessel functions.,"As a follow up to this question I am also interested in a symbolic closed form for this integral $$\int_0^\infty d r \,r^2\, j_{n_1}( k_1 r)\, j_{n_2}( k_2 r)\,  j_{n_3}( k_3 r)\,, $$
where $j_n(r)$ is the $n^{\rm th}$ order spherical Bessel function, $k_1$,$k_2$ and $k_3$ are real positive numbers and $n_1,n_2$ and $n_3$ are positive integers. The spherical Bessel function $j_n$ can be defined by 
$$ j_n(x) = (-x)^n \left(\frac{1}{x}\frac{d}{dx}\right)^n\,\frac{\sin x}{x}.$$ Clue As an answer to this question , @joriki provided a nice solution for $n_1=n_2=n_3=0$. If I am to believe Mathematica again, for instance
$$\int_0^\infty d r \,r^2\, j_2(  r)\, j_2( 2 r)\,  j_2( 3 r)=-\frac{\pi}{48}$$
and
$$\int_0^\infty d r \,r^2\, j_2(  r)\, j_4( 2 r)\,  j_4( 3 r)=-\frac{\pi}{48}$$
 so the integral seems possible. On the other hand, if some $n_i$ are odd the integral seems ill defined. I would guess that for odd indices the answer is $\pi/(8k_1 k_2 k_3)$ times some function of the signs of $n_1$, $n_2$ and $n_3$. Update My guess seems to be wrong. Symbolic integration for the first $8\times8\times 8 $ values of $(n_1,n_2,n_3)$ yields (with $k_1=k_2=k_3=1$)","['integration', 'analysis']"
245804,Comparing sums with squares,"I need to show that: $$
 {\sum\limits_{i=1}^n {|x|} } \leq \sqrt{n\sum\limits_{i=1}^n |x|^2 }
$$ I tried to square both sides so I would get: $$
\left({\sum\limits_{i=1}^n {|x|} }\right)^2 =  \left(\sum_{i=1}^{N}|x_i|^2+2*\sum_{i,j,i j}|x_i||x_j|\right) \leq n\sum\limits_{i=1}^n |x|^2 
$$ but it just doesn't seem to work... I know that on both sides we have $n^2$ elements, I just don't know how to compare them.",['sequences-and-series']
245821,Prove that $\lim_{x \rightarrow 0} \frac{1}{x}\int_0^x f(t) dt = f(0)$.,"Assume $f: \mathbb{R} \rightarrow \mathbb{R}$ is continuous.  Prove that $\lim_{x \rightarrow 0} \frac{1}{x}\int_0^x f(t) dt = f(0)$. I'm having a little confusion about proving this.  So far, it is clear that $f$ is continuous at 0 and $f$ is Riemann integrable.  So with that knowledge, I am trying to use the definition of continuity.  So $|\frac{1}{x}\int_0^x f(t) dt - f(0)|=|\frac{1}{x}(f(x)-f(0))-f(0)|$.  From here, I'm not sure where to go.  Any help is appreciated.  Thanks in advance.",['real-analysis']
245828,Validity of empty sets,"As i have read that a set is a collection of well defined objects or elements but empty set means that there is no elements in the set.We say for example ""it is a set of cups,a set of pens"" and like wise then what is empty set and two empty sets can be different?",['elementary-set-theory']
245839,Relation between varieties in the sense of Serre's FAC and algebraic schemes,"This is a generalization of Hartshorne, Proposition 2.6 and Proposition 4.10, Chapter II. We fix an algebraically closed field $k$. Let $X$ be a topological space.
We denote by $\mathcal{F}_X$ the sheaf of $k$-valued functions on $X$.
We regard $\mathcal{F}_X$ as a sheaf of $k$-algebras in the obvious way. Let $X$ be a Zariski closed subset of $k^n$ for some integer $n \ge 0$.
Let $I(X) = \{f \in k[x_1,\dots,x_n]| f(p) = 0$ for every $p \in X\}$.
Let $A = k[x_1,\dots,x_n]/I(X)$.
Let $U$ be an open subset of $X$.
Let $f\colon U \rightarrow k$ be a function.
We say $f$ is regular at a point $p$ of $U$ if there exist an open neighborhood $V$ of $p$ contained in $U$ and $g, h \in A$ such that $h$ does not vanish at every point of $V$ and $f(x) = g(x)/h(x)$ for every $x \in V$.
We say $f$ is regular on $U$ if $f$ is regular at every point of $U$.
Let $\Gamma(U)$ be the set of regular functions on $U$.
Clearly $U \rightarrow \Gamma(U)$ defines a subsheaf $\mathcal{O}_X$ of $\mathcal{F}_X$.
We call the pair $(X, \mathcal{O}_X)$ an affine variety.
By abuse of notation, we usually say $X$ is an affine variety.
Note that we don't assume $X$ is irreducible. Let $X$ be a topological space.
Let $\mathcal{O}_X$ be a $k$-algebra subsheaf of $\mathcal{F}_X$.
Suppose $(X, \mathcal{O}_X)$ satisfies the following conditions. (1) $X$ is covered by a finite number of open subsets $U_i$. (2) Each $(U_i, \mathcal{O}_X|U_i)$ is isomorphic to an affine variety. Then $X$ is called a prevariety. Let $X, Y$ be prevarieties.
$X\times Y$ becomes a prevariety in the obvious way.
Suppose the diagonal subset $\Delta_X = \{(x, x)|\ x \in X\}$ is closed in $X\times X$. Then $X$ is called a variety. Let $X, Y$ be prevarieties.
Let $f\colon X \rightarrow Y$ be a continuous map.
Suppose $\psi\circ f$ is regular on $f^{-1}(U)$ for every open subset $U$ of $Y$ and every regular function $\psi$ on $U$. Then $f$ is called a morphism.
Thus prevarieties(resp. varieties) form a category. Let $X$ be a topological space.
Let $t(X)$ be the set of irreducible closed subsets of $X$.
If $Y$ is a closed subset of $X$, $t(Y) \subset t(X)$.
We can define a topology on $t(X)$ by taking closed sets as the subsets of the form $t(Y)$, where $Y$ is a closed subset of $X$.
Let $f\colon X \rightarrow Y$ be a continuous map.
We define $t(f)\colon t(X) \rightarrow t(Y)$ by $t(f)(Z) = cl(f(Z))$, where $cl$ means closure.
Thus $t$ is a functor on topological spaces.
We define a map $\alpha\colon X \rightarrow t(X)$ by $\alpha(x) = cl(\{x\})$.
It is easy to see that $U \rightarrow \alpha^{-1}(U)$ is a bijection from the set of open subsets of $t(X)$ to the set of open subsets of $X$. Are the following assertions true? (1) For every variety $V$ in the above sense, $(t(V), \alpha_*(\mathcal{O}_V)$ is a reduced separated scheme of finite type over $k$. (2) There is a fully faithful and essentially epimorpfic(*) functor $t\colon Var(k) \rightarrow Sch(k)$, where $Var(k)$ is the category of varieties over $k$ and $Sch(k)$ is the category of reduced separated schemes of finite type over $k$. (*) A functor $F\colon \mathcal{C} \rightarrow \mathcal{D}$ is essentially epimorpfic if, for every $Y\in Ob(\mathcal{D})$, there exists $X \in Ob(\mathcal{C})$ such that $F(X)$ is isomorphic to $Y$.",['algebraic-geometry']
245852,"Prime spectrum of a ring, understanding geometry","I am doing some exercises out of Atiyah & Macdonald these days. Doing the exercises isn't the problem, but I am having trouble understanding geometric about $\text{Spec}(A)$. Consider $A=\mathbb{C}[X,Y]/(Y^2 - X^3 + X + 1)$ or something. Are the elements of $\text{Spec}(A)$ (prime ideals of $\mathbb{C}[X,Y]$ containing $P(X,Y)=Y^2 - X^3 + X + 1$) supposed to be ""points on the curve"" $0 =  Y^2 - X^3 + X + 1$ or something? I can see why $\text{Spec}(\mathbb{C}[X])$ is an affine line over $\mathbb{C}$ (plus another ""generic"" point), but I haven't been able to conceptualise what's going on in general. Basically, the exercises keep coming back to commutative algebra, but I am not seeing the geometic ideas behind it. Here's my question: could someone point me to some elementary exercises that help interpret the geometry of $\text{Spec}(A)$ for the ring $A$ above?","['commutative-algebra', 'algebraic-geometry']"
245857,What is the easiest way to integrate $\left(\frac{1-x}{1+x}\right)^{1/2}?$,"This is an indefinite integral that's supposed to be very easy: $$I=\int\sqrt{\frac{1-x}{1+x}}\,dx$$ I can only think of one way of calculating it, and it's a bit complicated, that is: substitute $x=\sin u$, and obtain $dx=(\cos u)\,du$ and $$I=\int\sqrt{\frac{1-\sin u}{1+\sin u}}(\cos u) \,du=\int\frac{1-\tan\frac{u}{2}}{1+\tan\frac{u}{2}}(\cos u)\,du.$$ substitute $t=\tan \dfrac u2$, obtaining $du=\dfrac{2\,dt}{1+t^2},$ $\cos u=\dfrac{1-t^2}{1+t^2}$ and $$I=\int \frac{1-t}{1+t}\frac{1-t^2}{1+t^2}\frac2{1+t^2}\,dt=2\int\left(\frac{1-t}{1+t}\right)^2\,dt,$$ which can be calculated. I'm not even sure if this is correct though. But even if it is, I think this way is too difficult for the place in which I found this integral, which is a set of indefinite integrals where obvious substitutions work and no knowledge is necessary beyond how substitution works in general. I think there must be an easy way to do it that I don't see.",['integration']
245859,Rotating parametric curve,"Given parametric curve: $x=t\cos(t)$, $y=t^2$, how can i rotate the curve about the origin by an angle $\theta=\pi/3$?",['calculus']
245866,Minimum and Maximum eigenvalue inequality from a positive definite matrix.,"I got a positive definite matrix $B,$ that is, $V(x) = x^TBx > 0$ for any vector $ x \neq 0.$  I want to show that $ \lambda_\min \|x\|_2^2 \leq V(x) \leq \lambda_\max \|x\|_2^2$ for any $x \neq 0,$ where $\lambda_\min$ and $ \lambda_\max$ are defined by $$ \lambda_\min = \min \lbrace | \lambda|: \lambda \text{ is an eigenvalue of } B \rbrace$$ and  $$ \lambda_\max = \max \lbrace | \lambda|: \lambda \text{ is an eigenvalue of } B  \rbrace$$ 
Any hint please?","['matrices', 'linear-algebra']"
245871,The inverse of a lower triangular matrix is lower triangular,"The inverse of a non-singular lower triangular matrix is lower triangular. Construct a proof of this fact as follows. Suppose that $L$ is a non-singular lower triangular matrix. If $b \in \mathbb{R^n}$ is such that $b_i = 0$ for $i = 1, . . . , k \leq n$ , and $y$ solves $Ly = b$ , then $y_i = 0$ for $i = 1, . . . , k \leq n$ . Hint : partition $L$ by the first $k$ rows and columns. Can someone tell me what exactly we are showing here and why it will prove that the inverse of any non-singular lower triangular matrix is lower triangular?","['matrices', 'linear-algebra', 'inverse', 'proof-writing']"
245884,Does the Laplace transform biject?,Someone wrote on the Wikipedia article for the Laplace trasform that 'this transformation is essentially bijective for the majority of practical uses.' Can someone provide a proof or counterexample that shows that the Laplace transform is not bijective over the domain of functions from $\mathbb{R}^+$ to $\mathbb{R}$?,"['laplace-transform', 'examples-counterexamples', 'functions']"
245899,How to prove exponential of every square matrix is invertible?,"For a square matrix $A$. Define $exp(A)=I+\sum_{n}A^{n}/(n!)$
. I need to prove two things exp(A) converges and is invertible. Its inverse is given by exp(-A). Second part is straightforward. Can anyone help on first part?","['matrices', 'linear-algebra']"
245919,Problem 3-38 in Spivak´s Calculus on Manifolds,"This is not homework. Problem 3-38 reads: Let $A_{n}$ be a closed set contained in $(n,n+1)$. Suppose that $f:\mathbb{R}\rightarrow \mathbb{R}$ satisfies $\int_{A_{n}}f=(-1)^{n}/n$ and $f(x)=0$ for $x\notin$ any $A_{n}$. Find two partitions of unity $\Phi$ and $\Psi$ such that $\sum_{\phi\in\Phi}\int_{\mathbb{R}}\phi\cdot f$ and $\sum_{\psi\in\Psi}\int_{\mathbb{R}}\psi\cdot f$ converge absolutely to different values. A few observations: First, $n\ge 1$. Second, Spivak uses what he calls an extended integral , whose definition and relations with the usual integral can be found on p.65, which can be found here or here . It may be helpful to have an example of such a function in mind. Let $A_{n}=$ closed interval of length $1/2n$ centered at the point $(2n+1)/2$. Clearly $A_{n}\subset(n,n+1)$. then define
$$f(x)=\begin{cases}
        \hphantom{-}2& \text{if $x\in A_{n}$ for $n$ even}\\
        -2& \text{if $x\in A_{n}$ for $n$ odd}\\
        \hphantom{-}0& \text{otherwise}.
       \end{cases}$$ A possible approach: Let $a_{n}=(-1)^{n}/n$. Since $\sum_{n}a_{n}=\alpha\in\mathbb{R}$ but the convergence is conditional, then for any $\beta\not=\alpha$ there is a rearrangement $\{b_{n}\}$ of the sequence $\{a_{n}\}$ such that $\sum_{n}b_{n}=\beta$. Now, we form a family of open sets $\{U_{n}\}$, where $U_{n}$ is the union of $n$ intervals $(k,k+1)$, each corresponding to a term of the $n$-th partial sum of $\sum_{n}a_{n}$. We form a similar family $\{V_{n}\}$ looking at the partial sums of $\sum_{n}b_{n}$. E.g., if we let $\{b_{n}\}=\{-1,1/2,1/4,-1/3,1/6,1/8,-1/5,\ldots\}$ we have $V_{3}=(1,2)\cup(2,3)\cup(4,5)$ while since $\{a_{n}\}=\{-1,1/2,-1/3,1/4,\ldots\}$ we have $U_{3}=(1,2)\cup(2,3)\cup(3,4)$. If we slightly fatten-up the $U_{n}$ (resp. the $V_{n}$) we form open covers $\mathcal{U}$ (resp. $\mathcal{V}$) of all the reals greater or equal than 1 without ading points where $f$ in non-zero. My heart tells me that partitions of unity $\Phi$ and $\Psi$ subordinate to $\mathcal{U}$ and $\mathcal{V}$, respectively, will be the desired one. But alas I am lost! Does any one know how to show that the aforementioned partitions of unity are the desired ones? Other possible approaches to the solution are also welcomed. In addition to two posts linked above, related issues with other problems and statements about integration in Spivak´s book can be found here and here .","['multivariable-calculus', 'integration', 'differential-geometry', 'manifolds', 'differential-topology']"
245920,singularities and residues,"Consider the function $$f(z)=\frac{z^3}{1-\cosh(z)}$$. Find its singularities and compute residues. I know the denominator vanishes for $z_k=2k\pi i$, $k$ integer. I first consider $k=0$, so the function is analytic in $0<|z|<2\pi$, and i can write in this punctured disc the following Laurent expansion: starting from $$\cos(z)=\sum_{n=0}^{\infty}(-1)^n\frac{z^{2n}}{(2n)!}$$ i get $$\cosh(z)=\cos(iz)=\sum_{n=0}^{\infty}\frac{z^{2n}}{(2n)!}$$Hence $$1-\cosh(z)=-\frac{z^2}{2!}-\frac{z^4}{4!}\ldots$$
thus i can write $$\frac{1}{1-\cosh(z)}=\frac{1}{-\frac{z^2}{2!}-\ldots}=-\frac{2}{z^2(1-h)}=-\frac{2}{z^2}(1+h+h^2\ldots)$$ where $h=-\frac{2z^2}{4!}-\frac{2z^4}{6!}-\ldots$.
So we have $\frac{1}{1-\cosh(z)}=-\frac{2}{z^2}+\frac{4}{4!}+$ higther terms.
Finally, we get $\frac{z^3}{1-\cosh(z)}=-2z+\frac{4z^3}{4!}$+ higther terms, from which i desume that $z_0=0$ is a removable singularity for f. But now i don't know how to deal with $z_k$ with $k\neq 0$. I imagine those to be all poles of order 2 for $f$, but how to prove? A last question: is it correct to say: the poles $z_k$ accumulates to $\infty$, hence $\infty$ is not an isolated singularity, thus i cannot compute $Res(f;\infty)$?","['calculus', 'complex-analysis']"
245925,Is this series convergent or divergent?,"Kindly asking, what can I do about series $$
\left(\frac{1}{3}\right)^2+\left(\frac{1\times 4}{3\times 6}\right)^2+\left(\frac{1\times 4\times 7}{3\times 6\times 9}\right)^2+...+\left(\frac{1\times 4\times 7\times...\times (3n-2)}{3\times 6\times 9\times...\times3n}\right)^2+...$$ Indeed, the ratio test fails. Thank you.",['sequences-and-series']
245936,"Is there a $SL(2,\mathbb{Z})$-action on $\mathbb{Z}$?","Is there a $SL(2,\mathbb{Z})$-action on $\mathbb{Z}$? I read this somewhere without proof and I am not sure if this is true. Thank you for your help.","['group-theory', 'abstract-algebra']"
245944,Quadrilateral geometry,"It's given distance between $AB = 27$ $BC = 752$ $CD = 26.75$ $AD = 758$ $CE = 1$ $0 < FC < 752$ How do I find $FG = x$ for point $F$ on line $BC$? Is it even possible? EDIT: As André mentioned in comments, just by defining lengths doesn't make the structure ""rigid"" to calculate x. What if we define $90 < \angle C < 120$, does this makes approximate result possible?",['geometry']
245951,Trying to understand the basics of bayesian inference,"This paper gives a somewhat gentle introduction to Bayesian inference: http://www.miketipping.com/papers/met-mlbayes.pdf I got to section 2.3 without much problems but got stuck in understanding that section onwards. It starts by presenting a probabilistic regression framework where the likelihood of all data is given as: $$
p(t|x,w,\sigma^2) = \prod_{n}p\left(t_n|x_n,w,\sigma^2\right)
$$
where $t_n=y(x_n;w)+\epsilon_n$ is the 'target' value. Next, given a set of parameters $w$ and a hyperparameter $\alpha$, the prior is given as:
$$
p(w|\alpha)=\prod_{m}\left(\frac{\alpha}{2\pi}\right)^{1/2}\exp\left({-\frac{\alpha}{2}w_m^2}\right)
$$ I can then compute the posterior $p\left(w|t,\alpha,\sigma^2\right)$. What I don't understand is the following: In the first equation above, how should I interpret the product over the $N$ pairs of data $(t_n,x_n)$? Lets say I get two initial measurements from the real world, is $p\left(t|x,w,\sigma^2\right)$ supposed to give me a single real-valued probability? And how do I account for $w$ since it is not known yet? As far as I got it, $w$ is supposed to be a vector of size $M$ where $w_i$ contains the $i$th estimated value. Now, how can a prior for $w$ have a reference to its own vector elements if I don't know them yet? Shouldn't a prior be an independent distribution such as a Gaussian or Beta? Also, shouldn't a prior be independent of hyperparameters? Figure 4, on the article's page 8 has a plot from the prior and from the posteriors of an example using the $y=\sin(x)$ function with added Gaussian variance 0.2. How could I plot something similar in, say, Octave/Matlab or R? I don't have a strong background in statistics so forgive me if this is too basic. Any help is appreciated. Thanks in advance!","['statistical-inference', 'bayesian', 'probability']"
245965,Pull-back of sections of vector bundles,"I'm sure this is a silly question but I'm stuck at the concept of pulling back sections of a vector bundle. Let $\pi:E\to X$ be a vector bundle on a variety $X$ and $f:Y\to X$ a morphism. We have a bundle $\pi':f^\ast E\to Y$, the pullback of $E$. If we have a section $\sigma:X\to E$, which means $\pi\circ\sigma=1_X$, then I read in several places that I can pull-back this section by pre-composing it with $f$, and this gives me a section of $f^\ast E$. It seems to me that I only get an arrow $Y\to E$. So why do we call $\sigma':=\sigma\circ f$ a section of $\pi'$? My thoughts: call $g$ the morphism $f^\ast E\to E$. Perhaps the above means that if we start with some $y\in Y$ and we take any $z\in g^{-1}(\sigma'(y))$, then we have that $\pi'(z)=y$. Is this correct? In any case, I can only prove that $f(\pi'(z))=f(y)$, which doesn't imply $\pi'(z)=y$. However I feel like I'm really missing the point here. Thank you.","['algebraic-geometry', 'vector-bundles']"
245988,Solving for the trace of a matrix,"In my research I have commonly had to deal with the following matrix equation (where $\Theta$ is the unknown):
\begin{equation}
A \Theta + \Theta A^\text{T} = 2 D
\end{equation}
known as the continuous time Lyapunov equation. All matrices are $n\times n$ with real coefficients, with $\Theta$ and $D$ also being symmetric positive definite. This equation is known not to have a closed form solution and must be solved for each particular problem. However, all I really need is the quantity
\begin{equation}
F = \text{tr}(A^\text{T} D^{-1} A \Theta)
\end{equation} Since all I need is this trace, I was wondering if it was possible to bypass the solution of the Lyapunov equation or, at least, simplify the process in some way. Thus far I have not had any progress. Thank you in advance for your time. Best regards, Gabriel","['trace', 'linear-algebra']"
245990,Find all permutations that commute with $\omega$=(1 9 7 10 12 2 5)(4 11)(3 6 8) in $S_{12}$,"I'm asked in this exercise to find all permutations that commute with $\omega$=(1 9 7 10 12 2 5)(4 11)(3 6 8) in $S_{12}$. What I have so far: We could write $x$(1 9 7 10 12 2 5)(3 6 8)=(1 9 7 10 12 2 5)(3 6 8)$x$, which means (1 9 7 10 12 2 5)(4 11)(3 6 8)=$x^{-1}$(1 9 7 10 12 2 5)(4 11)(3 6 8)$x$=(1x 9x 7x 10x 12x 2x 5x)(4x 11x)(3x 6x 8x). This means $x$ commutes with $\omega$ iff $x$ 'transfers' one of the distinct cycles that construct $\omega$ unto itself. There are $7\cdot 2\cdot 3$ ways to 'present' $\omega$ disregarding the order of multiplication of the cycle ( should I disregard it? ), each of which creates a distinct commuting permutation if constructed by the algorithm: 1x$\rightarrow$( 1 9 7 10 12 2 5), 9x$\rightarrow$(1 9 7 10 12 2 5), et cetera. So all in all we end up with $7\cdot 2\cdot 3$ permutations. I guess what I should ask is: (a) does this sound correct? (b) since the question wants us to find all permutations and not count them, perhaps there is a more general 'form' for the commuting permutations?","['permutations', 'discrete-mathematics', 'abstract-algebra', 'finite-groups', 'group-theory']"
246001,Making a choice function if $A_i$ are well-ordered for each $i$,"Let $A_i$ be a family of sets such that each $A_i$ is well-ordered. Let $\varphi(x,S,W)$ be the formula $$ \forall z ( (z,x) \in W \rightarrow z \notin S)$$
where $W$ is the well-order on $S$. Then $\varphi(x,S,W)$ is true if and only if $x$ is the $W$-minimal element of $S$. Let's use Separation to obtain the family $A_i' = \{ x : \varphi(x,A_i,W_i) \} = \{a_i\}$ consisting of one element sets. Next let's make ordered pairs $(i,a_i)$ from these using Pairing. Finally, let's apply Union to pack these pairs into one set $F = \{(i,a_i)\}_{i\in I}$. So far we have not invoked the axiom of choice anywhere. But $F$ seems to be a function $F: I \to \{A_i\}_i$, choosing one element from each $A_i$. Where is the flaw in my construction? As I understand it's only possible to construct a choice function for $A_i$ if not only each $A_i$ is well-ordered but $\bigcup_i A_i$ is well-ordered, too. Thanks for your help.","['elementary-set-theory', 'axiom-of-choice']"
246011,local systems and Lefschetz pencils,"Let $X$ be a smooth, projective algebraic variety over a field of characteristic zero. Let $U \subset X$ be an open subvariety such that $D=X \setminus U$ is a normal crossing divisor. Let $\mathcal{E}$ be a local system on $U$. I would like to know how to compute the cohomology $H^k(U, \mathcal{E})$ by means of Lefschetz pencils. So let us us choice a Lefschetz pencil on $X$ whose base locus intersects properly the components of $D$. After blowing up the base locus, one gets a morphism $\rho: \tilde{X} \to \mathbb{P}^1$. (1) Can anybody help me to use Leray spectral sequence to relate this cohomology group with the cohomology of (an open of) $\mathbb{P}^1$ with values in $R^k\rho_\ast \mathcal{E}$? (2) Suppose we know the cohomology of the fibers of $\rho$ with values in $\mathcal{E}$. What can one say about $H^k(U, \mathcal{E})$? Thanks a lot",['algebraic-geometry']
246015,Supremum of the Difference of Two Functions,"Given two real-valued functions $f$ and $g$, is it true that $\sup(f-g) \geq \sup(f) - \sup(g)$",['real-analysis']
246025,Difficult word problem,"I have a problem I haven't been able to solve for a class. A man took a trip in a car.  He drove $70$ miles at a slower speed. Then, he went the next $300$ miles at a speed that was $40$ mph faster than earlier.  The time he spent driving at the faster speed was twice the time spent at the slower speed.  Find the two speeds. I think I could break this down to the following. Let $s_1$ be the slower speed, $s_2$ the faster speed, $d_1$ the shorter duration, and $d_2$ the longer duration. Then $d_1=\frac{70}{s_1}$ $d_2=\frac{300}{s_1+40}$ $d_2=2d_1$ and so $2d_1=\frac{300}{s_1+40}$ I think in my head I can come up with $35$ mph and $75$ mph but that's just because I tried a bunch of numbers that seemed normal for driving.  How can I solve this?",['algebra-precalculus']
246034,Calculating the Value of a complex limit,"I am given some limits that exist, I'm supposed to find their values. Seems really simple however I am struggling. Find the value of $\displaystyle \lim_{z\to\\i}\frac{z^4 - 1}{z-i} $. My approach was to paramaterize $z$ to $it$ and transform the limit to something like: $$\lim_{t\to\\1}\frac{(it)^4 - 1}{it-i} $$ Could anyone lend a hand as to how to solve something like this?","['complex-analysis', 'limits']"
246044,Conditional probabilities and order of operation,"I see terms of the form $P(A|B,C)$ a fair bit. Which of the following is true? $P(A|B,C)$ is the joint probability of $A|B$ and $C$ $P(A|B,C)$ is the probability of $A$ given both $B$ and $C$",['probability']
246047,The application of Doob's inequality and Doob's decomposition theorem,"1) What is the application of Doob's inequality?
Can we use Doob's inequality ($L^1$) to prove the convergence (maybe almost surely) of a martingale? Doob's inequality: Let $X$ be a submartingale taking on non-negative real values, that is, for all times $s$ and $t$ with $s < t$, $E[X_t\mid\mathcal F_s]\geq X_s$. Then, for any constant $C > 0$ and $T>0$ we have $$ \mathbf{P} \left[ \sup_{0 \leq t \leq T} X_{t} \geq C \right] \leq \frac{\mathbf{E} \big[ X_{T} \big]}{C}. $$ Doob's inequality ($L^p$): Let $X$ be a martingale, $$S_{t} = \sup_{0 \leq s \leq t} X_{s},\quad\text{for}\ p > 1$$ $$\| X_{T} \|_{p} \leq \| S_{T} \|_{p} \leq \frac{p}{p-1} \| X_{T} \|_{p}.$$ Maybe it is not clear enough. I know that to prove the $L^p$, $p>1$, convergence of a martingale, we can use Doob's inequality in $L^p$ form. However, it seems in the proof of convergence in $L^1$, that Doob's inequality is not used (as far as I understand, it is not enough - we need uniformly integrability). There are several formly analogous inequalities in probability theory, for example, Komolgorov's inequality, Doob's inequality, and an analogous Doob's inequality in ergodic theory. They all estimate the probability or expectation of a random variable, $|X_n|>M$ where $M$ is a constant. Why are they useful? 2) What is the application for Doob's decomposition theorem? Is it only formly?",['probability-theory']
246049,How do I prove whether something is a Euclidean domain?,"Is there a ""special formula"" one can follow to prove whether something is a Euclidean domain or not? I've been looking around, but I haven't seemed to be able to find one, so I was wondering whether I was blind, or there just isn't one. I have $\mathbb Z[\sqrt-3]=\{x+y\sqrt-3|x,y\in\mathbb Z\}$. I think I can remember having read somewhere that it's a Euclidean domain, but I'm not sure. I also don't know how to prove it. Any hints?","['ring-theory', 'abstract-algebra']"
246057,Points where function is continuous,"I have a function that is defined as such, $f(x)=x$, if x is rational, ie $x=\frac{p}{q}$ and $f(x)=1-x$, if x is irrational. What are all the points of continuity? I would say that all the points of continuity are the points where $p\neq q$ since at any the limit of f(x) as x approaches 1 is 0, while the functional value of the limit of x, as x approaches 1 is 1. Since they do not agree, the function is discontinuous at any point $p=q$ Is that view correct?",['analysis']
246065,Factorization of an invertible symmetric matrix,"Given any invertible symmetric matrix: $A=\begin{bmatrix}a&b&c\\ b&d&e\\ c&e&f\end{bmatrix}$ over the complex number, Can be it factored as $A=T^\top T$? where $T^\top$ is the transpose matrix of $T$, for some invertible matrix $T$. Any suggestions are welcome! Thanks!","['matrices', 'linear-algebra']"
246068,Equality condition in Minkowski's inequality for $L^{\infty}$,"I am trying to find out when equality holds in Minkowski's inequality for $L^{\infty}$ (i.e. a necessary and sufficient condition for equality). I did a search and there was a discussion for the case where $1<p<\infty$ but not when $p=\infty$ so I am hoping to get some ideas or for someone to point me to a source where this is discussed. I will list a couple of observations I made while working this out (though I'm not sure whether I'm right with these): If $\mu(\{x:|f(x)|\geq\|f+g\|_{\infty}-\|g\|_{\infty}\})=0$ (or with $f$ and $g$ interchanged), then I have the reverse inequality. If I pick $a,b$ such that $\|f\|_{\infty}\leq a<\|f\|_{\infty}+\varepsilon$, $\|g\|_{\infty}\leq b<\|g\|_{\infty}+\varepsilon$, $\mu(\{x:|f(x)|>a\})=0$, $\mu(\{x:|g(x)|>b\})=0$, and for all $c<a+b$ I have $\mu(\{x:|f(x)+g(x)|>c\})>0$, then I also have the reverse inequality.","['measure-theory', 'inequality', 'real-analysis']"
246071,Solve $x^2 + 10 = 15$,"How do I solve the following equation? $$x^2 + 10 = 15$$ Here's how I think this should be solved.
\begin{align*}
x^2 + 10 - 10 & = 15 - 10 \\
x^2 & = 15 - 10 \\
x^2 & = 5 \\
x & = \sqrt{5}
\end{align*}
I was thinking that the square root of 5 is iregular repeating 2.23606797749979 number. 2.236 multipled by itself equals 5ish. I've also seen another equation like this:
\begin{align*}
x^2 & = 4 \\
x^2 + 4 & = 0 \\
(x - 2)(x + 2) & = 0 \\
x & = 2 \text{ or } -2
\end{align*}
So I guess I could near the end of my equation do the following: $$x^2 + 5 = 0$$ and then go from there? Is my first attempt at solving correct?","['quadratics', 'algebra-precalculus', 'roots', 'solution-verification']"
246088,"Finding where the parametric curve $(2\sin 2t, 3\sin t)$ crosses itself","The parametric functions I am dealing with are: $x=2\sin2t$ and $y=3\sin t$ I know for a parametric graph to cross itself, there must be two distinct $t$, $t_1$ and $t_2$, that when placed into the two parametric functions, must produce the same ordered-pair; that is, $x=f(t_1)=f(t_2)$ and $y=g(t_1)=g(t_2)$. With this, I have two system of equations: (1) $2\sin 2t_1= 2\sin 2t_2 \implies 4\sin t_1\cos t_1=4\sin t_2\cos t_2 \implies \sin t_1=\dfrac{\sin t_2\cos t_2}{\cos t_1}$ (2) $3\sin t_1=3\sin t_2$ When I substituted $\sin t_1$ into (2), and simplified, I got $\cos t_2=\cos t_1$ Wouldn't that mean the graph intersects itself everywhere?","['parametric', 'algebra-precalculus']"
246097,Radon measure on a metric space X,"If $X$ is a metric space and $0<\mu(X)$, where $\mu$ is a radon measure and $\mu(\{x\})=0$. Can we always split $X = X_1 \sqcup X_2$ into two disjoint sets where $\mu(X_1) = a$, for any $0<a< \mu(X)$? Or more generally does there always exist a set  $X_1$ such that $\mu(X_1) = a$","['general-topology', 'measure-theory', 'metric-spaces']"
246108,How to find the general solution of $xy''-(2x+1)y'+x^2y=0$ when we know the general solution of $y''+2y'+xy=0$?,"Given that the general solution of $y''+2y'+xy=0$ is $y=C_1\int_0^\infty e^{-t^2}\cos\biggl(\dfrac{t^3}{3}-xt\biggr)dt+C_2\int_0^\infty\biggl(e^{-\frac{t^3}{3}+t^2-xt}+e^{-t^2}\sin\biggl(\dfrac{t^3}{3}-xt\biggr)\biggr)dt$ , find the general solution of $xy''-(2x+1)y'+x^2y=0$ . Note that according to Particular solution to a Riccati equation $y' = 1 + 2y + xy^2$ , both $xy''-(2x+1)y'+x^2y=0$ and $y''+2y'+xy=0$ come from the same Riccati equation.",['ordinary-differential-equations']
246131,Singularities of $ \frac{z-1}{z^2 \sin z} $,"Find all singularities of $$
\
\frac{z-1}{z^2 \sin z}
\
$$ Determine if they are isolated or nonisolated. This is not hard, it is $z = 0$ and $z = k\pi$ . But how do I: For isolated singularities, determine if they are removable or nonremovable
and, if nonremovable, determine their order. Do I need to expand this to a power series? If so, I have no idea where to attack... Please help! Thanks!","['trigonometry', 'complex-analysis', 'residue-calculus']"
246134,Could anyone explain how my textbook gets this modulu congruence statement?,"We say that two integers $a$ and $b$ are congruent modulo $m$ if $a − b$ is divisible by $m$. We denote this by $a≡b \pmod m$. Example 1:
$−31 ≡ 11 \pmod 7$ $11 \pmod 7$ is $4$, is it not? $-31 \neq 4$ last time I checked.","['modular-arithmetic', 'discrete-mathematics']"
246144,What is the nth derivative of $\dfrac{1}{\sqrt{1 + x^2}}$,"I'm trying to find a general formula for the $n$th derivative of 
$$\dfrac{1}{\sqrt{1 + x^2}}$$
I got up to,
\begin{eqnarray*}
		g^{(0)}(x) &=& g(x) \\
		g^{(1)}(x) &=& \dfrac{1}{(1 + x^2)^{1/2}} \\
		g^{(2)}(x) &=& \dfrac{-x}{(1 + x^2)^{3/2}} \\
		g^{(3)}(x) &=& \dfrac{2x^2 - 1}{(x^2 + 1)^{5/2}} \\
		g^{(4)}(x) &=& \dfrac{-6x^3 + 9x}{(x^2 + 1)^{7/2}} \\
		g^{(5)}(x) &=& \dfrac{24x^4 - 72x^2 + 9}{(x^2 + 1)^{9/2}} \\
		g^{(6)}(x) &=& \dfrac{-120x^5 + 600x^3 - 225x}{(x^2 + 1)^{11/2}} \\
		g^{(7)}(x) &=& \dfrac{720x^6 - 5400x^4 + 4050x^2 -225}{(x^2 + 1)^{13/2}} \\
		g^{(8)}(x) &=& \dfrac{-5040x^7 + 52920x^5 - 66150x^3 + 11025x}{(x^2 + 1)^{15/2}} \\
	\end{eqnarray*} Except for the first term in the numerator ($n!$), and the power in the denominator, I couldn't find a general pattern for the rest of the coefficients in the numerator. Could anyone shed me some light on this problem? Any idea would be greatly appreciated. Thanks.","['derivatives', 'taylor-expansion']"
246157,Finding the units in $\mathbb{Z}[\sqrt[3]{2}]$ and other questions,"I'm reading a paper in which they solve the equation: $$a^3-2b^3=\pm 1$$
in integers using algebraic number theory. The number $a-b\alpha$, with $\alpha=\sqrt[3]{2}$, is a unit in $\mathbb{Z}[\alpha]$. The units of this ring are, up to sign, powers of the single unit $1+\alpha+\alpha^2$. With some work one finds that $|a-b\alpha|$ can only be the zero'th power, so that $a=\pm 1$ and $b=0$. 1) Why are the units of the ring only powers of $1+\alpha+\alpha^2$? I can't find anything to this effect in my textbook and web searches won't turn up with anything. 2) Can't $|a-b\alpha|$ be the $(-1)$th power as well and $a=b=\pm 1$? The second question I've concluded is a minor error but I can't be satisfied with this solution without a proof for my first question. The Paper in question: http://www.ams.org/journals/bull/2004-41-01/S0273-0979-03-00993-5/S0273-0979-03-00993-5.pdf Relevant section is towards the end of second page.","['algebraic-number-theory', 'abstract-algebra', 'number-theory']"
246178,How would you write the aspect ratio when height is greater than width?,"If you have an image that is sized 200x100 you would say the aspect ratio is ""2:1"" correct? You can figure that out with width/height correct? What if the size was 100x200? Would you say the aspect ratio is ""1:2""? If so how do you do the math to get ""1:2"" instead of "".5:1"". More information: I have to figure this out in code and format it correctly. Here is as far as I got. Does the following look right? width = 200
height = 100

if (width > height) {
   ratio = width/height + "":1"" // results in ""2:1""
}
else if (height > width) {
   ratio = ""1:"" + height/width // results in ""1:2""
}
else if (width == height) {
   ratio = ""1:1"";
} I'm not even sure I described what I'm trying to do correctly. Sorry!",['algebra-precalculus']
246190,Find smallest number m such that $9^{32} + 19^{433} + m$ is divisible by $4$,"We went over this in class awhile ago, but I can't seem to figure out how to solve it. Obviously you can do it exhaustively with a supercomputer, but that doesn't seem practical when I know there's a simplistic way to solve it.",['discrete-mathematics']
246200,Resilient L'Hospital's rule question,"I'm trying to show that
$$\lim_{x\to 0} \frac{(1+x)^{\frac{1}{x}}-e}{x} = -\frac{e}{2}$$ At first it seemed like a routine application of L'Hospital's rule, but my standard bag of tricks isn't working. The $e$ in the numerator prevents any log trickery from separating nicely, and the limit being negative seems to also preclude analyzing the limit of the log. I tried to interpret this as the derivative of some function at a point, say, $g(u) = u^{\frac{1}{u-1}}$ and the point $u = 1$, but evaluating $g'(1)$ just got worse, and I had concerns about differentiability of $g$ there. Would choosing a different function work out better? I tried fiddling with one of the limit definitions for $e$ because the first term in the numerator tends to $e$ as $x\to 0$, but the function we're taking the limit of is not continuous at $x=0$ and so moving the limit in was a no-go. Edit: the $e$ in the numerator seems critical, as the limit diverges without it. I have a feeling I'm missing something simple. Any hints/solutions would be appreciated.","['calculus', 'limits']"
246202,Sample Range and order statistics?,"Let a random sample of size $n$ from an exponential distribution $X_i \sim EXP(1)$. Give the pdf of (1) The sample range, $R = Y_n - Y_1$ (2) The first r order statistics The answers are supposed to be (1) $f_R(r) = (n-1)e^{-r}(1 - e^{-r})^{n-2}$ and (2) $g(y_1, \dots, y_r) = \frac{n}{(n-r)!}\exp\left ( -\sum_{i=1}^{r} y_i -(n-r)y_r\right)$ I have absolute no idea how they got -2 in the first answer and I don't know how in the second answer, they got a sum EDIT : I figured out the sum part. They basically just put everything together into the exponent EDIT#2 . The largest order statistic $Y_n$ is $n e^{-y_n}(1 - e^{y_n})^{n-1}$.","['statistics', 'probability-distributions', 'probability', 'exponential-distribution']"
246226,Relation between a generalization of Weil's abstract varieties and algebraic schemes,"We would like to generalize this question when the base field $k$ is not necessarily algbraically closed. We fix an algebraically closed field $\Omega$ which has infinite trancendence dimension over the prime subfield.
Let $k$ be a subfield of $\Omega$ such that tr.dim $\Omega/k = \infty$.
Let $X$ be a topological space.
We denote by $\mathcal{F}_X$ the sheaf of $\Omega$-valued functions on $X$.
We regard $\mathcal{F}_X$ as a sheaf of $k$-algebras in the obvious way.
Let $\mathcal{O}_X$ be a $k$-algebra subsheaf of $\mathcal{F}_X$.
Namely, $\Gamma(U, \mathcal{O}_X)$ is a $k$-subalgebra of $\Gamma(U, \mathcal{F}_X)$ for every open subset $U$ of $X$ and the application $U \rightarrow \Gamma(U, \mathcal{O}_X)$ defines a subsheaf of $\mathcal{F}_X$.
We call the pair $(X, \mathcal{O}_X)$ a $k$-space.
By abuse of notation, we usually say $X$ is a $k$-space.
Let $X, Y$ be $k$-spaces.
Let $f\colon X \rightarrow Y$ be a continuous map.
Let $U$ be any open subset of $Y$.
Suppose $\psi\circ f \in \Gamma(f^{-1}(U), \mathcal{O}_X)$ for any $\psi \in \Gamma(U, \mathcal{O}_Y)$.
Then $f$ is called a morphism of $k$-spaces.
$k$-spaces form a category. Let $E$ be a subset of a polynomial ring $k[x_1,\dots,x_n]$.
We denote by $V(E)$ the common zeros of $E$ in $\Omega^n$.
It is easy to see that by taking subsets of the form $V(E)$ as closed sets, we can define a topology in $\Omega^n$.
We call this topology $k$-topology.
A closed(resp. open) subset of $\Omega^n$ with respect to $k$-topology is called $k$-closed(resp. $k$-open) subset Let $X$ be a $k$-closed subset of $\Omega^n$.
Let $I(X) = \{f \in k[x_1,\dots,x_n]| f(p) = 0$ for every $p \in X\}$.
Let $A = k[x_1,\dots,x_n]/I(X)$.
Let $U$ be a $k$-open subset of $X$.
Let $f\colon U \rightarrow \Omega$ be a function.
We say $f$ is $k$-regular at a point $p$ of $U$ if there exist a $k$-open neighborhood $V$ of $p$ contained in $U$ and $g, h \in A$ such that $h$ does not vanish at every point of $V$ and $f(x) = g(x)/h(x)$ for every $x \in V$.
We say $f$ is $k$-regular on $U$ if $f$ is $k$-regular at every point of $U$.
Let $\Gamma_k(U)$ be the set of $k$-regular functions on $U$.
$\Gamma_k(U)$ can be regarded as $k$-algebra in the obvious way.
Clearly $U \rightarrow \Gamma_k(U)$ defines a $k$-algebra subsheaf $\mathcal{O}_X$ of $\mathcal{F}_X$. A $k$-space which is isomorphic to $(X, \mathcal{O}_X)$ is called an affine $k$-variety. Let $(X, \mathcal{O}_X)$ be a $k$-space satisfying the following conditions. (1) $X$ is covered by a finite number of open subsets $U_i$. (2) Each $(U_i, \mathcal{O}_X|U_i)$ is an affine $k$-variety. Then $X$ is called a $k$-prevariety.
A morphism of $k$-prevarieties defined to be that of $k$-spaces.
It is also called a $k$-morhism. Let $X, Y$ be $k$-prevarieties.
$X\times Y$ becomes a $k$-prevariety in the obvious way.
Suppose the diagonal subset $\Delta_X = \{(x, x)|\ x \in X\}$ is closed in $X\times X$. Then $X$ is called a $k$-variety.
$k$-prevarieties(resp. $k$-varieties) form a category. Are the following assertions true? (1) For every $k$-variety $V$, $(t(V), \alpha_*(\mathcal{O}_V)$ is a reduced separated scheme of finite type over $k$, where $t(V)$ and $\alpha$ are those defined in this question . (2) There is a fully faithful and essentially epimorpfic functor $t\colon Var(k) \rightarrow Sch(k)$, where $Var(k)$ is the category of $k$-varieties and $Sch(k)$ is the category of reduced separated schemes of finite type over $k$.","['algebraic-geometry', 'schemes', 'ringed-spaces']"
246227,Solving Right Triangle Given Two Sides,I have a right triangle whose base has length 40 cm and whose hypotenuse has length 43 cm. How can I determine the height and the measures of the remaining two angles?,['geometry']
246252,"Example of a function f such that $f^2$ is Riemann-Stieltjes integrable on [a,b] but f is not. [duplicate]","This question already has answers here : Closed 11 years ago . Possible Duplicate: If $f^2$ is Riemann Integrable is $f$ always Riemann Integrable? Example of a function f such that $f^2$ is Riemann-Stieltjes integrable on [a,b] but f is not. I was considering f=$(\chi_{\mathbb{Q}}-\chi_{\mathbb{I}})$ the difference of the characteristic functions for the rationals and irrationals respectively. 
I know that this is not Riemann Stieltjes integrable but I'm wondering if $f^2$ is. $f^2$=$(\chi_{\mathbb{Q}}-\chi_{\mathbb{I}})^2$=$\chi_{\mathbb{Q}}^2 +\chi_{\mathbb{I}}^2 - 2\chi_{\mathbb{I}}\chi_{\mathbb{Q}}$ = $\chi_{\mathbb{Q}} + \chi_{\mathbb{I}}$ $\equiv 1$ on [a,b]. Is a correct way of viewing this?","['functions', 'integration', 'real-analysis', 'analysis']"
246289,Transpose of block matrix,"I'm attempting to prove that $$
\left[ \begin{array}{c c}
A & B \\
C & D \\
\end{array} \right]^\top =
\left[ \begin{array}{c c}
A^\top & C^\top \\
B^\top & D^\top \\
\end{array} \right].
$$ Intuitively, I can see that it's true. However, when I try to formally prove it, I quickly get lost in the indices. What tricks can I use to keep things straight? Source: Exercise 2.6.16, P116, Intro to Linear Algebra, 4th Ed by Strang","['matrices', 'linear-algebra', 'proof-writing', 'transpose']"
246309,Conformal mapping from triangle to upper half plane in terms of Weierstrass $\wp$,"I'm trying to explicitly compute a conformal map $f:\Delta \rightarrow \mathbb{H}$ where $\Delta$ is a triangle and $\mathbb{H}$ is the upper half plane, in terms of the Weierstrass $\wp$ function. I know that the function should be the inverse of a Schwarz triangle function, and there should be a relation to $\wp$ by elliptic integrals, but I'm a bit lost as to finding one explicitly. For example, how would one go about for finding such a map for the triangle with vertices, say, $(0,i,1)$? Examples or suggestions would be greatly appreciated! Wolfram gives an explicit function for another triangle here: http://functions.wolfram.com/EllipticFunctions/WeierstrassPPrime/31/01/ , but I'd like to how how they computed it.","['special-functions', 'elliptic-functions', 'complex-analysis']"
246326,QR decomposition help,What do Q and R stand for? Why must the diagonal entries of R be positive instead of just nonzero?,"['numerical-linear-algebra', 'matrices', 'linear-algebra']"
246337,Showing that $\lim_{x\rightarrow 0} \frac{1}{x}\int_0^x |\sin(1/y)| \mathrm{d} y \not=0$,"How to show that: $$\lim_{x\rightarrow 0} \frac{1}{x}\int_0^x |\sin(1/y)| \mathrm{d} y \not=0$$ It seems like a easy example of illustrating 0 is not in the Lebesgue set of $g(x)$ where $g(x)=\sin(1/x)$ if $x\neq 0$ and $g(0)=0$. But I fail to see why the above integral is true. I tried looking at the intervals such that $\sin(1/y)$ is greater or equal to some constant (for example, $\left[\frac{1}{k\pi+\pi/6}, \frac{1}{k\pi+5\pi/6}\right]$ such that $\sin(1/y)\geq \frac{1}{2}$), however, $$\sum_{k \text{ large}} \left(\frac{1}{k\pi+\pi/6}-\frac{1}{k\pi+5\pi/6}\right)$$ converges, which is not strong enough to prove the claim.
Any thoughts? Thanks in advance.","['lebesgue-integral', 'measure-theory', 'real-analysis', 'analysis']"
246353,"Do $e_1$, $e_2$, ... generate the entire $l_2$ space?","From our textbook goes some statement like this: ... let $X$ be the linear subspace of $l_2$ generated by the vectors $$\left\{e_1,e_2,e_3,...\right\}$$ ... Which feels strange to me because I thought $e_1=(1,0,0,...)$, $e_2=(0,1,0,...)$, ... are sufficient to generate the entire $l_2$ space, so the $X$ here is actually just $l_2$ itself. Isn't that true?",['functional-analysis']
246358,How to generate a random matrix whose eigenvalues are less than one,"I generate a random matrix. It has this general form: $$\mathbf{B}=\left[ \matrix{ \mathbf{A}_1&\mathbf{A}_2&\ldots&\mathbf{A}_{p-1}&\mathbf{A}_p \\ 
\mathbf{I}_M&\mathbf{I}_M&\ldots&\mathbf{I}_M&\mathbf{O}_M \\
 \vdots &\vdots &\ddots& \vdots& \vdots\\
 \mathbf{I}_M&\mathbf{I}_M&\ldots&\mathbf{I}_M&\mathbf{O}_M \\ } \right]:(pM \times pM)$$ in which $\mathbf{A}_i$ is $M \times M$ for $i=1,\ldots,p$ and $\mathbf{O}_M$ ($M\times M$) and $\mathbf{I}_M$ ($M\times M$) are zero and identity matrices. The elements of $\mathbf{A}_i$ are random (they are from a multivariate normal distribution). The eigenvalues of $\mathbf{B}$ should be less than one and I don't want to repeat random number generation process until this happens. I want to change some elements of a generated matrix (whose at least one of its eigenvalues is larger than one) so that all eigenvalues become less than one. Is there any way to do so? (I think I should answer this question: If I change the $B(i,j)$, how will eigenvalues of $B$ be affected? But I don't know the answer). edit:
I have this idea: What if I generate a set of random eigenvalues and then generate my matrix based on them. I don't know how to proceed. Thanks.","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
246364,Are vector subspaces of $\mathbb{R}^n$ always closed?,"Suppose $S$ is any proper vector subspace of $\mathbb{R}^n$. Is $S$ a closed set in the usual topology on $\mathbb{R}^n$? Geometrically, I think it is clear that $S$ must be closed in $\mathbb{R}^n$ for $1\leq n\leq 3$. If $x\in\mathbb{R}^n\setminus S$, then we can always find the shortest distance from $x$ to the point, line, or plane that is $S$ by taking the projection of $x$ onto $S$. Choosing $\epsilon$ to be less than this distance, $B_\epsilon(x)$ is an open ball around $x$ disjoint from $S$, so $S$ is closed. I believe that the idea should carry over for higher dimensions, but I'm not sure how to make a more rigorous argument. How could this claim be proven without geometric handwaving? Thanks.","['topological-vector-spaces', 'linear-algebra']"
