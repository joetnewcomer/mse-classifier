question_id,title,body,tags
2745276,Orbit and stabilizer of the representation of multiplication decomposition of $U(3)$,"We know that in SU(2), we have the multiplication of 2-dimensional representation (rep) decomposed as 
$$
2 \times 2= 1+3 \tag{a}
$$
where 1 is the singlet of SU(2). And 3 is the adjoint of SU(2) and vecto rep of SO(3). We can ask what is the orbit and stabilizer of each element. For the 3 in the above eq. (a), we should have the base space $S^2$ as the orbit and the fiber $S^1$ as the stabilizer, with the following relations:
$$
S^1 \hookrightarrow S^3 \to S^2
$$
$$
\text{stabilizer}\hookrightarrow \text{total space} \to \text{orbit}
$$
Naively, I write 
$$U(1) \hookrightarrow SU(2) \to SO(3),$$
as the SO(3) is the orbit that each object in $3$ can move around in the SO(3) space, while the stabilizer (a certain action of U(1)) makes the object invariant.
The more proper way to write $SU(2)/U(1)=\mathbf{CP}^1$ as complex protective space.
However, if we consider the total space as U(2), then the relations become:
$$U(1) \times \mathbb{Z}_2 \hookrightarrow U(2) \to \frac{U(2)}{U(1) \times \mathbb{Z}_2},$$ For the 1 in the above eq. (a), which is a trivial representation of SU(2), thus we have the object invariant under the full SU(2), thus we have,
$$SU(2) \hookrightarrow SU(2) \to pt,$$
the orbit is a single point. If we consider the full U(2) as the total space that can act on the SU(2) fundamentals, we have
$$SU(2) \hookrightarrow U(2) \to U(1)/\mathbb{Z}_2,$$ What are the orbits and stabilizers of the right hand side objects in the multiplication of 3-dimensional representation of SU(3):
  $$
3 \times 3= \bar{3}+6 \tag{b}
$$
  $$
3 \times \bar{3}= 1+8 \tag{c}
$$ question: What are the orbits and stabilizers of $\bar{3}$, $6$ and $1$, $8$ in the above decompositions, if we view the total space as SU(3) or U(3)? Namely, what is
$$
\text{stabilizer}\hookrightarrow SU(3) \to \text{orbit},
$$
$$
\text{stabilizer}\hookrightarrow U(3) \to \text{orbit},
$$
for each of $\bar{3}$, $6$ and $1$, $8$ in the above decomposition?","['fiber-bundles', 'representation-theory', 'group-theory', 'lie-algebras', 'lie-groups']"
2745330,Image of an analytic function near a branch point,"Picard's great theorem says that any analytic function of one complex variable defined on a punctured neighborhood of an essential singularity takes on every complex value (with at most one possible exception) infinitely often. Is there a similarly general statement that can be made about functions defined in the vicinity of a branch point? (Or a specific type of branch point, e.g. an algebraic or transcendental or logarithmic branch point? For example, is it the case that the image of a function defined near a logarithmic branch point is always unbounded?) Clearly we need to be a bit more careful about exactly what we mean by ""in the vicinity"" than in the case of an isolated singularity. For example, we could consider an arbitrary open subset of the domain of the corresponding global analytic function that contains the branch point, or we could consider a single branch of the function and take an open subset of $\mathbb{C} \setminus (\text{branch point}) \setminus (\text{branch})$. I'm curious whether any general statements can be made in either case. To give a few examples (in the ""global analytic function"" case): The image of $z^{1/n}$ for natural $n$, which has an algebraic branch point at $0$, is a neighborhood of $0$. The image of the function $\ln(z)$, which has an (obviously) logarithmic singularity near $0$, includes the entire half-plane $\mathrm{Re}(z) < x$ for some real $x$.","['complex-analysis', 'branch-points', 'branch-cuts']"
2745364,"What does the Gradient ""with respect to a position vector"" mean?","I was studying John R. Taylor's book on Classical Mechanics and he introduced a confusing concept in page 140 (2005 edition): $$\nabla_1 = (\frac{\partial}{\partial x_1}+\frac{\partial}{\partial y_1}+\frac{\partial}{\partial z_1})$$ Where $$\mathbf r_1 = (x_1+y_1+z_1)$$ He calls this ""the gradient with respect to the coordinates of $\mathbf r_1$"". In general, what is the gradient with respect to a position vector? Isn't the gradient (in physics) just dependent on where we sit our x-axis and our y-axis? In other words, I've always known the gradient as: $$\nabla = (\frac{\partial}{\partial x}+\frac{\partial}{\partial y}+\frac{\partial}{\partial z})$$ (If context gives a clue, he was talking about the gradient of a potential $U$ in an isolated, two body system where the positions of the two particles are $\mathbf r_1$ and $\mathbf r_2$, and the claim is that the force on particle 1 due to particle 2 $\mathbf F_1 = -\nabla_1U(\mathbf r_1-\mathbf r_2)$. The same would apply for particle 2 interchanging 1 with 2 in the last formula.)","['vectors', 'mathematical-physics', 'calculus', 'vector-analysis']"
2745376,"Why $C_c^{\infty}(I)$ is not dense in $W^{1,p}(I)$","Suppose $I$ is an open interval (bounded or unbounded). It is stated that $C_c^{\infty}(I)$ is dense in $L^p(I)$, $1\leq p<\infty$. However $C_c^{\infty}(I)$ is not dense in $W^{1,p}(I)$, we only have the result  $C_c^{\infty}(\mathbb{R})|_{I}$ is dense in  $W^{1,p}(I)$. What is the reason for that ?","['functional-analysis', 'sobolev-spaces', 'partial-differential-equations']"
2745389,"What is a Random Variable in the formulation of McCullagh's ""What is a Statistical Model?""","I'm relatively new to posting here so am not sure if this is the type of question I can ask, but I have been trying to understand for some time this paper by Peter McCullagh (it's not as long as it looks): https://pdfs.semanticscholar.org/4a01/7dd1ace17979828bb9f57e26ccf9c91f0b3b.pdf I have read some basic category theory so am able to follow along with most of the definitions. However, I am confused about how one would model something with no covariates, say, parametric estimation for a sequence of i.i.d. random variables, in this formulation, since it seems to be necessary to have a nonempty covariate space in order to construct the parameter space. Furthermore, we couldn't even have arrows from $U$ to $\Omega$ if $\Omega$ were empty (""a design is a map associating with each unit $u \in U$ a point $x_u \in \Omega$""p.1234). This is where I begin to question whether I understand this formulation at all. Would love some clarification on these definitions if anyone has read this paper (or feels inclined to skim through it). The construction of the definition of a statistical model is on p.1235. edit: This is the basic setup: There are three main building blocks with three different categories $cat_U$ the category with sets of statistical units as objects, injective maps as morphisms $cat_\Omega$ the category of covaraite spaces $cat_V$ the category of response scales Then we define a design to be a map $x:U \rightarrow \Omega$ and the set of all such designs to be a category $cat_D$. This is all on p.1234-1236. A choice of response scale $V$ determines an object $V^\Omega$. In the linear model our parameter space $\Theta_\Omega$ is a subspace $\subset V^\Omega$. A linear model is determined by a subrepresentation $\Theta_\Omega \subset V^\Omega$, together with a design pullback $\psi^*$:
$$
U \overset{\psi}{\rightarrow} \Omega \ \ \ \ \ \mathcal{S} = V^U \overset{\psi^*}{\leftarrow}\Theta_\Omega
$$ When we add a dispersion parameter to the parameter space,
$$
U \overset{\psi}{\rightarrow} \Omega \ \ \ \ \ \mathcal{P}(V^U) \overset{P_\psi}{\leftarrow}\Theta_\Omega
$$ we get the probability distributions on the sample space.","['category-theory', 'probability-theory', 'probability', 'statistics']"
2745462,Reverse type $1-1$ inequality,"If $\mu \in \mathcal{M}(\mathbb{T})$ is nontrivial and singular with respect to lebesgue measure, then 
$$|\{\theta \in \mathbb{T} : M\mu(\theta) >\lambda\}| \ge \frac C\lambda \|\mu\|$$
where $| \cdot | $ denotes Lebesgue measure, $|\lambda| > \|\mu\|$, which is the total variation norm, and $C$ is an absolute constant. That is the problem statement. I'm looking for advice on how to establish a weak 1-1 inequality going the other way. The standard tools (Besicovitch, Vitali) don't seem readily applicable. The maximal function $M\mu(x) = \displaystyle\sup_{I \supset x} \frac{\mu(I)}{|I|}$ where the sup is taken over all intervals $I$ containing $x$.","['real-analysis', 'harmonic-analysis', 'lebesgue-measure', 'measure-theory', 'singular-measures']"
2745497,Asymptotic decay rate of an infinite product of sinc functions,"( related to my previous question ) Consider the function
$$f(x)=\prod_{n=0}^\infty\operatorname{sinc}\left(\frac{\pi \, x}{2^n}\right),\quad\color{gray}{x\ge0},\tag1$$
where $\operatorname{sinc}(z)$ denotes the sinc function . The function $f(x)$ has zeros at positive integers, and oscillates with a quickly decaying amplitude. Its signs on the intervals between consecutive zeros follow the same pattern as the Thue–Morse sequence . Can we find a real-valued function $g(x)$ (elementary, if possible), such that it is analytic, positive and monotone decreasing (and having monotone derivatives of any order, if possible) and satisfies
$$\lim_{t \to \infty} \frac 1 {t-t_0} \int_{t_0}^t \frac{|f(x)|}{g(x)} \, dx=1\tag2$$
for large enough $t_0$? Or, at least,
$$\color{gray}{\exists A > 0, \, \exists B > A, \, \forall t > t_0,} \, A < \frac 1 {t-t_0} \int_{t_0}^t \frac{|f(x)|}{g(x)} \, dx < B\tag3$$
for large enough $t_0$? The ""for large enough"" provision means that $g(x)$ is permitted to be not monotone, or have zeros or discontinuities, or be not defined at all for small $t,$ and we only care about its ""eventual"" behavior. Empirically, it looks like $g(x)$ should decay faster than any negative power of $x$, but slower than exponentially. I'm thinking something close to $\exp(-\log^2x)$, but perhaps not exactly that. Update: Maybe this expansion can be useful:
$$\prod _{n=0}^m \operatorname{sinc}\left(\frac{\pi\,x}{2^n}\right) = \frac{2^{\binom m2}}{(\pi\,x)^{m+1}} \sum_{n=0}^{2^m-1} t_n\,\sin\left(\!\frac {\pi\,m}2+\frac{2n+1}{2^m}\,\pi\,x\!\right),\tag4$$
where $t_0=1,\,t_n=(-1)^n\,t_{\lfloor n/2\rfloor}$ (the signed Thue–Morse sequence).","['infinite-product', 'limits', 'asymptotics', 'calculus', 'sequences-and-series']"
2745498,Interesting pattern of primes occurred in pairs ($p$ and $p+10$) before $1000$,"I was flipping the math book where I saw a table of primes. The primes were marked in black bold. It's interesting to see that except 3,13,23, lots of primes (not necessarily consecutive) occur in pairs $p$ and $p+10$, and their distribution compare to other isolated primes didn't seem to reduce in $1000$. So I googled and there was a thing called https://en.wikipedia.org/wiki/Twin_prime . My question was that was the pair of primes of module 10 just a coincidence?","['number-theory', 'prime-numbers']"
2745566,"Dual of the fractional Sobolev space $W^{s,p}(\mathbb{R}^n)$","For $s\in\mathbb{R}$ and $1<p<\infty$, one can define the fractional Sobolev space $W^{s,p}(\mathbb{R}^n)$. Every element $f$ in $W^{s,p}(\mathbb{R}^d)$ is a tempered distribution such that the inverse Fourier transform of 
$$\widehat{f_s}(\xi):=(1+|\xi|^2)^{\frac{s}{2}}\hat{f}(\xi)$$ 
is an element of $L^p(\mathbb{R}^d)$ and we define 
$$\|f\|_{W^{s,p}}:=\|f_s\|_{L^p}.$$ 
Note that the function $(1+|\xi|^2)^{\frac{s}{2}}$ has at most polynomial order growth, thus $(1+|\xi|^2)^{\frac{s}{2}}\hat{f}(\xi)$ is in fact a well defined tempered distribution and so is its inverse Fourier transform. I'm looking for refrences which deal with the dual space of $W^{s,p}(\mathbb{R}^n)$. I have seen huge literatures on the case $p=2$, in which case the space $W^{s,2}(\mathbb{R}^n)$ is a Hilbert space with inner product
$$\langle f,g\rangle_{W^{s,2}}=\frac{1}{2\pi}\int_{\mathbb{R}^d}\hat{f}(\xi)\overline{\hat{g}(\xi)}(1+|\xi|^2)^sd\xi.$$
And the dual space of $W^{s,2}(\mathbb{R}^n)$ is precisely $W^{-s,2}(\mathbb{R}^d)$. Unlike the case $p=2$, I didn't find any resources which discuss the duality when $p\neq 2$. I've seen some resources mentioned that the dual of $W^{s,p}(\mathbb{R}^n)$ is $W^{-s,q}(\mathbb{R}^n)$, where $\frac{1}{p}+\frac{1}{q}=1$. Intuitively this makes sense from the duality of $L^p$ spaces. But I didn't see any proof of this. Could someone provide me some references related to this quesiton? Or maybe explain to me in details if applicable? Thanks in advance! P.S. I saw some resources which define the Sobolev spaces of negative powers to be the dual of Soboleve spaces of positive powers, i.e., they define
$$W^{-s,q}(\mathbb{R}^n):=(W^{s,p}(\mathbb{R}^n))'$$
when $s>0$ and $\frac{1}{p}+\frac{1}{q}=1$. I would like to see whether this coincides with the definition I provided above.","['fourier-analysis', 'dual-spaces', 'reference-request', 'fractional-sobolev-spaces', 'functional-analysis']"
2745587,Is it possible to define the flow of a continous function?,"Let $f$ $\in$ $\mathcal{C}^{1}(\mathbb{R}^n,\mathbb{R}^n)$  and consider the ODE: \begin{align*}
y'&=f(y)\\
y(0)&=y_0
\end{align*} Once $f$ is a $\mathcal{C}^1$ function we can define the flow $\varphi$ of $f$. The function $\varphi$ satisfies the following conditions: $\varphi:D\rightarrow \mathbb{R}^n $ $\varphi(p,0)=p \hspace{0.1cm}$; $\forall$ $p$ $\in$ $\mathbb{R}^n$ $ \frac{d}{dt}\varphi(p,t) = f(\varphi(p,t)) $, $\forall$ $(p,t)$ $\in$ $D$ where $D$ the ""definition domain of $f$"", i.e , $D =\{(x,s)\in \mathbb{R}^{n+1};$ $s$ $\in$ $(\omega_x^-,\omega_x^+)$}, being that $(\omega_x^-,\omega_x^+)$ the maximal domain of solution of the ODE \begin{align*}
y'&=f(y)\\
y(0)&=x
\end{align*} It's possible to prove that $D$ is an open set and $\varphi$ is a $\mathcal{C}^1$ function. Now, I would like to know if it is possible to define the flow of $f$ supposing $f$ just a continuous function, I know that maybe this is impossible because in this case, we do not have a solution uniqueness of the differential equation. My Question: If $f:\mathbb{R}^n\rightarrow \mathbb{R}^n$ is a continous function, is possible to define a continous function $\varphi:D\rightarrow \mathbb{R}^n$ (where $D\supset\mathbb{R}^n \times \{0\}$ is an open subset of $\mathbb{R}^{n+1}$) such that, $\varphi(p,0) = p$ and $\frac{d}{dt}\varphi(p,s) = f(\varphi(p,s))?$","['ordinary-differential-equations', 'dynamical-systems']"
2745659,st printed over equality symbol,"I'm reading an older statistical paper (1994 - not too old, but before computers were in every office) and the author writes the following: From (#) we see that $\mathbf P$ satisfies the distributional equation
  $$\mathbf P \stackrel{st}{=}\theta_1\mathbf D + (1 - \theta_1)\mathbf P$$ I should add for clarity that $\mathbf P$ is a vector obtained by applying a random probability measure on a measurable partition of the sample space and $\mathbf D$ is a series of indicator variables with respect to the same partition. I think I understand what's going on in the paper, and it would make sense based on this (and other uses in the paper) for this symbol to indicate equality in distribution - but I've never seen that notation before. (I've always seen it written with a lower case $d$: (e.g. $\stackrel{d}{=}$).  Is the ""obvious"" definition correct, or am I missing something subtle? For anyone interested (or who found my explanation overly simplistic), a link to the whole paper is here: http://www3.stat.sinica.edu.tw/statistica/j4n2/j4n216/j4n216.htm It should be open access.  My goal is simply to verify the meaning of the symbol. Thanks!","['statistics', 'measure-theory']"
2745711,How to teach ordinary differential equations to good students? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question does not appear to be about math within the scope defined in the help center . Closed 6 years ago . Improve this question I am TA-ing a introductory course on ODEs and PDEs this year. At my university most introductory math courses can be taken at ""basic"" and ""extended"" levels. This one is the extended one. My students seem to be not engaged in the subject. I don't blame them. They have already seen some abstract mathematical theories -- general topology, measure theory, abstract algebra. What I am teaching them is a lot of methods for solving specific ODEs. There are of course parts of general theory (existence theorems and some qualitative theory) and exercises to prove something, but mostly its calculation. They long for some abstraction, general framework. Unfortunately, i don't know how to provide it to them without functional analysis (which they haven't had). Please, give me any of your thoughts and advice on this problem.","['ordinary-differential-equations', 'education']"
2745723,Faithful action of $\operatorname{Gal}(\overline{\mathbb{Q}}/\mathbb{Q})$ on dessins of genus $0$,"In a nearly classic paper of '94, L. Schneps recalls a proof by Lenstra of the fact that the absolute Galois group acts faithfully on Shabat polynomials (i.e. on trees). As immediate corollary, she has that the absolute Galois group acts faithfully on dessins of genus $0$. I don't understand why it suffices to give the proof for trees in order to show the claim for general dessins. In fact, a dessin of genus $0$ could have more than one face, unlike trees that have only one face. Moreover, a ""multifaced"" (having more than one face) dessin is not isomorphic to a tree. So, how can she deduce the faithfulness of the action on the whole collection of dessins of genus $0$ through Lenstra's theorem?","['riemann-surfaces', 'complex-analysis', 'algebraic-geometry']"
2745731,Product of two Lebesgue measurable set is measurable,"Let $A,B \subset \mathbb{R}$ two bounded and Lebesgue measurable sets. I have to show that $A\times B \subset \mathbb{R}^2$ is measurable and \begin{align*}
\lambda(A \times B) = \lambda (A) \cdot \lambda (B)
\end{align*}
where $\lambda$ is the Lebesgue measure. I tried to show the equality of the measure using the Fubini's Theorem with the indicators function but I'm not sure is the right way and I have no idea how to show that $A \times B$ is measurable. Any suggestions? Thanks in advance!!","['real-analysis', 'lebesgue-measure', 'lebesgue-integral', 'measure-theory', 'analysis']"
2745782,Solving the equation $|z|^2-2iz+2c(1+i)=0$ for $c\in \mathbb{R}^+\cup \{0\}$,"Find all solutions to the equation $|z|^2-2iz+2c(1+i)=0$ for $c\in \mathbb{R}^+\cup \{0\}$ I tried as follows: Let $z_0$ satisfy the equation. Thus $$|z_0|^2-2iz_0+2c(1+i)=0$$ $$|z_0|^2-\overline{2iz_0}+2c(\overline{1+i})=0 $$ Taking the conjugate and adding, $$2|z_0|^2+2i(\bar z_0-z_0) +4c=0$$ $$\Rightarrow|z_0|^2+\bar z_0i+z_0\bar i+2c=0$$ Comparing with the standard equation of a circle, $$|z|^2+\bar za+z\bar a+b=0$$ This is the equation of a circle with radius $\sqrt{i\bar i - 2c}$ Hence $z_0$ lies on the circle (centered at the origin) with radius $\sqrt{1 - 2c}$ . Hence $z_0=(\sqrt{1 - 2c} )e^{i\theta}$ where $\theta \in [0,2\pi)$ . Could someone tell me if my approach is correct?",['geometry']
2745816,Convergence of convex sets in the complementary Hausdorff metric and in the usual Hausdorff metric,"First of all let me define what is the the complementary Hausdorff distance between  two open sets, I denoted by $d^{H}$ the usual Hausdorff distance in $\mathbb{R}^n$. Let $\Omega_1$ and $\Omega_2$ two open subsets of a (large) compact set $B \subset \mathbb{R}^n$, then their complementary Hausdorff distance is defined by :
$$d_{H}(\Omega_1 , \Omega _2) := d^{H}(B \setminus \Omega_1 , B\setminus \Omega_2)$$ Let $\Omega_n$ be bounded open subsets of $\mathbb{R^n}$ such that $\Omega_n$ are convex and converge to a nonempty convex open set  $\Omega$, in the sense of Hausdorff complementary  metric. I would like to prove that the closure of the sequence $\Omega_n$, denoted $\overline{\Omega_n}$, converges to $\overline{\Omega}$ in the usual Hausdorff metric. In other words : ($\Omega_n \longrightarrow \Omega $ in the complementary Hausdorff metric )$\Longrightarrow( \overline{\Omega_n} \longrightarrow \overline{\Omega}$ in the usual  Hausdorff metric ).","['convex-geometry', 'geometric-measure-theory', 'general-topology', 'hausdorff-measure']"
2745828,Showing that a function is one-to-one,"How can I show if the following function is one-to-one? $$y = x^2 - x \ (x \ge \frac{1}{2})$$
A function is one-to-one if $f(x_1) = f(x_2)$ then $x_1 = x_2$. So I put in $x_1$ and $x_2$ in the function and tried to see if $x_1(x_1 - 1) = x_2(x_2 - 1)$ made sense. However, I am stuck right here: how do I know that $x_1 = x_2$ in this situation? I think I might be missing something quite simple...please help!","['calculus', 'functions']"
2745840,Is {x : ϕ(x)} a set with ϕ(x) being the property: ∀y (x ∈ y),"The property  ∀y (x ∈ y) contradicts the axiom of regularity since x ∈  x is not true for any non-empty set x.
Does this mean that {x : ϕ(x)} = $\emptyset$ which is a set or because it violates an axiom does that mean it is not a set?","['separation-axioms', 'elementary-set-theory']"
2745886,Dirichlet generating function of Möbius function,"I am trying to figure out a question I have come across using Riemann Zeta function and Dirichlet generating functions. The function I am given is $$\sum_{d|n} \mu(d)^2 = g(n),$$ we have, $$\sum_{n=1}^{\infty} \frac{g(n)}{n^s} = \zeta(s) \sum_{n=1}^{\infty} \frac{\mu(n)^2}{n^s}.$$ I understand this step, however its the next step where they simplify into Riemann zeta functions where $$\zeta(s) \sum_{n=1}^{\infty} \frac{\mu(n)^2}{n^s}= \zeta(s) \frac{\zeta(s)}{\zeta(2s)},$$ Once again I know $\sum_{n=1}^{\infty} \frac{\mu(n)}{n^s}=\frac{1}{\zeta(s)} $ but still I am confused please may someone explain this for me.","['number-theory', 'riemann-zeta', 'generating-functions']"
2745909,"$X=A\cup B$ be an open cover of $X$. If $X,A,B$ are simply connected , then $A\cap B$ path-connected?","I'm trying to prove or find counterexample to the following : Let $X=A\cup B$ be an open cover of $X$. Assume that $X,A,B$ are simply connected , then  $A\cap B$ must be path-connected. I tried a proof by contradiction : Assume that  $A\cap B$ not path-connected , and pick loop which start at one of the connected components, say $C_1$ , travelling through all the other  connected components , then returning to $C_1$. I think the fact this loop is nullhomotopic will imply that A∩B is connected, but I haven't found such a proof. (I'm not sure if that true)","['algebraic-topology', 'general-topology']"
2745916,Function composition in $L^2$,"Let $f\in L^2(0,\infty)$ with $|f(x)| \leq |x|$. Further, define $g(x)=d^x$ for some $d>1$. Question: Is $f\circ g \in L^2(\mathbb{R})$? If yes, how do I show this? If no, under which conditions does this hold? Intuitively, this should hold, but I have no clue if this can be shown based on the above conditions. Any hints?","['functional-analysis', 'function-and-relation-composition']"
2745952,Computing the Grothendieck group of a polynomial ring (over a field) or affine n-space as a scheme?,"So this question arose from my attempt to do exercises II.6.10 and III.5.4, both from Hartshorne's algebraic geometry. I have almost finished, but am not quite sure how to make the last implication. My situation is as follows: I have a short exact sequence
$$
0 \longrightarrow \mathbb{Z}^{r-1} \longrightarrow K \longrightarrow K' \longrightarrow 0.
$$
where $K$ is the Grothendieck group of coherent sheaves on $\mathbb{P}_{k}^{r}$ and $K$ is the Grothendieck group of coherent sheaves on $\mathbb{A}^{r}$. I want to show that $K \simeq \mathbb{Z}^{r}$. By induction, I have that the Grothendieck group for $\mathbb{P}^{r-1}$ is $\mathbb{Z}^{r-1}$. So my task is reduced to showing that the Grothendieck group for $\mathbb{A}^{r}$ is just $\mathbb{Z}$. This is apparently a fairly standard problem. Stated another way, I was to find the Grothendieck group of finitely-generated modules on $R=k[x_{1}, \ldots , x_{r}]$. The approach I had planned to take was the following: Let $M$ be a finitely-generated module over $R$. Then we have a finite free resolution,
$$
0 \longrightarrow F_{k} \longrightarrow F_{k-1} \longrightarrow \cdots \longrightarrow F_{1} \longrightarrow F_{0} = M \longrightarrow 0
$$
Let $[M]$ denote the equivalence class of $M$ in the Grothendieck group. By this equivalence relation, we have 
$$
[M] = \sum_{i=1}^{k}(-1)^{i+1}[F_{i}]
$$
Since each $F_{i}$ is free, and the Grothendieck group respects direct sums, we have that
$$
[M] = \sum_{j} n_{j}[R]
$$
Also define
$$
\epsilon([M]) = \sum_{j}n_{j}.
$$
I will call this value the resolvent trace (for lack of a better term). Then if $K(R)$ is the Grothendieck group for $R$, we have a map,
$$
K(R) \longrightarrow \mathbb{Z}
$$
defined by
$$
M \longmapsto \epsilon([M]).
$$
My question is about well-definedness. Why is this process well-defined? In particular, surely a different choice of finite free resolution of $M$ would yield a different value of $\epsilon([M])$? Potential remedy to the problem: Since $R$ is regular, it has a well-defined projective dimension being the length of any minimal projective resolution. Moreover by Quillen-Suslin, any such resolution must be free. So I can always choose my free resolution to be minimal of the same length, in this case $r$. But this still doesn't allow me to conclude that what I've called the ""resolvent trace"" will be the same. The well-definedness in terms of respecting the equivalence relation defining the Grothendieck group should come from the Horseshoe Lemma, if I can resolve the above problem. Does this sound correct? Thanks","['algebraic-geometry', 'coherent-sheaves', 'projective-module', 'homological-algebra', 'free-modules']"
2745967,Suppose A be a matrix with Diagonal entries are $\alpha+1$ then $\alpha $ is?,"Suppose $A=(a_{ij})$ be a $10\times 10$ order matrix such that $a_{ij}$=$1$ for $i\neq j$ and$ a_{ii}=\alpha+1$ for $\alpha\ge 0$.Let $ \lambda$  and  $\mu $ be largest and smallest eigenvalues of $A$. If$\lambda+\mu=24$ then $\alpha=?$                           here is my attempt -- according to the question diagonal elements are $\alpha+1$ and remaining entries are 1 then as sum of eigen value =sum of diagonal $10\alpha+10$=$\lambda+\mu+\sum_{i=2}^9\lambda_i $ suppose $\lambda_1=\mu$ and $\lambda_{10}=\lambda$ then $10\alpha$=$14+\sum_{i=2}^9\lambda_i $ as $\lambda+\mu=24$ but how can I find $\alpha$, is my process is correct? If not then what is the correct process?","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra']"
2746001,How does the order of an element of $SL_2(\mathbb{F}_p)$ correspond to its trace?,"Suppose $g$ is a diagonalizable element of $SL_2(\mathbb{F}_p)$ (we call an element of $SL_2(\mathbb{F}_p)$ diagonalizable, iff it has two linearly independent eigenvectors). Then the order of $g$ is the Least Common Multiple of orders of its eigenvalues $e_1$ and $e_2$ (they lie in the algebraic closure of $\mathbb{F}_p$, ""order of a field element $x$"" stands for the minimal natural $n$, such that $x^n = 1$). However, as $det(g) = 1$, $e_1e_2 = 1$. That means, that orders of the eigenvalues of $g$ are equal (and thus equal to the order of $g$). Also, it is easy to notice, that $x$ is an eigenvalue of $g$ iff it satisfies the equality $x^2 - tr(g)x + 1 = 0$. So one can conclude, that the order of any diagonalizable element of $SL_2(\mathbb{F}_p)$ depends solely on its trace. So there exists a function $f$ from $\mathbb{F}_p$ to $\mathbb{N}$, such that $f(x)$ is order of any diagonalizable element of $SL_2(\mathbb{F}_p)$ with trace $x$. The question is: how to write the function $f$ in a closed form? Any help will be appreciated.","['eigenvalues-eigenvectors', 'abstract-algebra', 'trace', 'group-theory', 'linear-algebra']"
2746022,I lose a big class of solutions when making a differential equation homogenous substituting $y=z^m$,"Solve $2y+(x^2 y + 1)xy'=0$. The book that contains this problem suggests a way of solving such differential equations - do a substitution $y=z^m$, $dy=m z^{m-1}dz$ with such $m$ that the differential equation becomes homogenous. Here $m=-2$ works. However if I substitute $y=z^{-2}$ I lose all information about solutions with $y \leq 0$. Let's say I do this substitution nonetheless. $$2z^{-2} + (x^2z^{-2}+1)x(-2)z^{-3}z'=0$$ $$z^{-2}dx = (x^3z^{-5} +x z^{-3})dz$$ Now it's homogenous. Substitute $t=\frac{x}{z}, dx=tdz+zdt$
$$tdz+zdt = (t^3+t)dz$$
$$\frac{dz}{z}=\frac{dt}{t^3}$$
Note that we lost $t=x=0$, but it's not a solution.
$$\ln{|z|} = -\frac{1}{2t^2} + C,$$
Substitute back:
$$\ln{\frac{1}{\sqrt{y}}} = -\frac{1}{x^2 y} + C.$$ Check whether $y=0$ is a solution - it is. But the book containing this problem says the solutions are $x^2 y \ln{Cy}=1$ and $y=0$. It allows for $y$ to be negative, but our solution does not. How to go about it?","['homogeneous-equation', 'ordinary-differential-equations']"
2746031,Can we prove that $t$ must be a Mersenne prime?,"This question Equations involving arithmetic functions, totatives and even perfect numbers can be answered positive if the following can be proven. Let $t\ge 1$ be an integer and denote $$s:=\sigma\left(\frac{t(t+1)}{2}\right)$$ $$p:=\varphi\left(\frac{t(t+1)}{2}\right)$$ $\sigma(n)$ is the divisor-sum-function and $\varphi(n)$ the totient-function. Claim : If $s=4p+t+1$ holds, then $t$ is a Mersenne-prime. If $t^2-1=4p$ holds, then $t$ is a Mersenne-prime. The claim is true for $t\le 10^6$","['number-theory', 'prime-numbers', 'elementary-number-theory']"
2746063,"Limit of improper integral $ \lim_{x\to \infty} \ \int_1^x x\,e^{t^2-x^2} \,dt$","I need to calculate the limit of the following improper integral: $$ \lim_{x\to \infty} \ \int_1^x x\,e^{t^2-x^2} \,dt$$ My solution is $\infty$, but when I enter it in WolframAlpha the solution is $\frac{1}{2}$, so I guess mine is wrong, but I can't figure out where. This is my current solution: $$
First\ calculate\ the\ integral\ (leaving\ away\ the\ limit\ for\ now)\\[10pt]
Let \
u = t^2-x^2 \\
\frac{du}{dt} = 2t \leftrightarrow dt = \frac{du}{2t} \\[20pt]
\
Substitution:\\[5pt]
\begin{align*}
x \ \int_{1-x^2}^0 x\,e^{u} \frac{du}{2t}
&= \frac{x}{2t} \ \int_{1-x^2}^0 e^{u} \,du \\
&= \frac{x}{2t} \ {\bigl (}{e^u{\bigl )}{\bigl \vert }\,}_{1-x^2}^{0} \\
&= \frac{x}{2t} \ {\bigl (}{e^0-e^{1-x^2}{\bigl )}\,} \\
&= \frac{x}{2t} - \frac{e^{1-x^2} \ x}{2t} \\
&= \frac{x - e^{1-x^2} \ x}{2t} \\
&= \frac{x \ (1-e^{1-x^2})}{2t}
\end{align*}\\
\
\\[20pt]
Now\ calculate\ the\ limit:\\[10pt]
\lim_{x\to \infty} \ \frac{x \ (1-e^{1-x^2})}{2t}
= \infty
$$ What have I done wrong, that I don't get the solution $\frac{1}{2}$","['improper-integrals', 'integration', 'limits']"
2746066,Variance of variance of MLE,"I am trying to find the variance of maximum likelihod estimate $Var(s^2)$ where $ s^2 = \frac{1}{n} \sum^n_{i=1} (x_i-\bar{x})^2$ (model $X_i \sim N(\mu,\sigma^2)$).
I try getting $Var(s^2) = Var(1/n \sum^n_{i=1} x_i) - Var(\bar{x}^2)$ $ = 1/n^2 \sum E(x^4_i)-E(x^2_i)^2- Var(\bar{x}^2)$ $= \frac{2\sigma^4+4\mu^2\sigma^2$}{n} -  Var(\bar{x}^2) $ and from here I can't getting further. How can I derive the variance of $\bar{x}$, and is it correct to to type $\mu$ or should I type $\bar{x}$ here?","['maximum-likelihood', 'statistics', 'variance', 'parameter-estimation']"
2746071,trilateration with dimensionless distances,"I am trying to figure out how to calculate the coordinate of a point P using the coordinates of three nearby points (A, B and C).
The only problem is that I don't know the actual distances to P, only the ratio between them. For example: A(19.5mm,9mm)
B(120mm,40mm)
C(46mm,62.5mm) With as distances to P: AP = 0.5
BP = 1/3
CP = 1/6 Does anyone know how i get the coordinates of point P? EDIT Graphical representation If it helps, that is a graphical representation of what is going on.
I added the distances from the A, B and C to P in black but they can just as well be the ones in red with the same points A, B and C.
The value of the distances A-P, B-P and C-P don't matter, only the ratio between them. EDIT PT2. I found a part of the solution: Since the distance between A and B is known (can be calculated) and the ration between AP and BP is known, a triangle should be able to be calculated. But I don't know how yet...","['trigonometry', 'barycentric-coordinates', 'calculus']"
2746155,For Odd continuous functions from s2 to R there exist x s.t. f(x)=g(x)=0,"For two odd continuous functions $f$ and $g$ both from $S^2$ to $\Bbb R$ , there is a $x$ such that $f(x)=g(x)=0$. Please someone give me a hit about this...","['algebraic-topology', 'even-and-odd-functions', 'functions']"
2746204,How to factor $a^{3} + b^{3} + c^{3} - 3abc$ into a product of polynomials,"The question is in the title. This question is from ""Algebra"" by Gelfand. My initial thought is that if $a$, $b$ and $c$ are $1$ or $-1$, then the polynomial evaluates to $0.$ So, maybe two of the factors will be $(a + b + c - 3)$ and $(a + b + c + 3)$. An alternative option that combines these two might be $a^{2} + b^{2} + c^{2} - 3$. Is the thought process correct here, and would trial and error be a good way to decide between the linear and the quadratic options I described above? As you can tell, I am largely doing guess work here. Is there a more systematic way of deciding what terms to add and subtract in orders to factor the polynomial? Note: The factoring need not be done all the way to linear factors. All that is needed is a product of polynomials.",['algebra-precalculus']
2746230,Compactness in $\ell ^1$. Is $K := \{ (z_n)_n \in \ell^1 : |z_n| \leq |x_n| \}$ compact?,"I'm having some trouble with the following: Consider the following set $K := \{ (z_n)_n \in \ell^1 : |z_n| \leq |x_n| \}$ for a given $(x_n)_n \in \ell^1$. Is $K$ a secuencially compact space? This is my thoughts so far: I suspect $K$ is in fact compact. We want to see that given a $(\xi_k)_k \subset \ell^1$ we can find a convergent subsequence. So let $\xi_k= (z^k_n)_n$ and $(\xi_k)_k \subset K$. For a fixed $n$ we have that $(z^k_n)_k \subset \bar B_{|x_n|}(0) \subset \mathbb{R} $, which is compact. It follows then that $(z^k_n)_k$ has a partial convergent subsequence. Let then, $(z^{k'}_n)_{k' \in I(n)}$ where $I(n) \subset \mathbb{N}$ is an index set, denote such convergent subsuccession. My idea is that if we can see that $|\cap_n I(n)| = \infty$ then $(\xi_{k'})_{k'}$ with $k' \in \cap_n I(n)$ would be a convergent subsequence of $(\xi_k)_k$. I'm a bit stuck on how to proceed from here, suposing that this leads somewhere interesting.","['functional-analysis', 'compactness']"
2746254,attempting to solve the diff equation $y'(x^2+1)-2xy=4\sqrt{y(x^2+1)}$,$$y'(x^2+1)-2xy=4\sqrt{y(x^2+1)}$$ $$y'\sqrt{(x^2+1)}-\frac{2xy}{\sqrt{(x^2+1)}}=4\sqrt{y}$$ $$\frac{y'\sqrt{(x^2+1)}-\frac{2xy}{\sqrt{(x^2+1)}}}{x^2+1}= \frac{4\sqrt{y}}{x^2+1}$$ I tried to solve this but I can't get rid of the 2 which would have enabled me to wrtie $$(\frac{y}{x^2+1})'$$ how do I solve this?,"['ordinary-differential-equations', 'calculus']"
2746273,Closed form for $\frac{x}{1+x} +\frac{x^2}{1+x+x^2} +\frac{x^3}{1+x+x^2+x^3}+...$,"I am trying to evaluate this infinite series that looks beautiful to me $$S=\sum_{n=1}^{\infty} \frac{x^n}{1+x+...+x^n}$$ All I could do is prove that it converges for $|x|<1$ and I tried to find a suitable form so that I can exploit it with an integral, however I was not successful. I would love to see a closed form. (this is a question that was also posted on other sites like AoPS but it didnt receive an answer so I hope no one minds if I post here too)","['sequences-and-series', 'closed-form']"
2746310,The Importance of Minors,"Let $A \in K^{m \times n}$ be a matrix. A $r \times r$-minor is defined as the determinant of the $r \times r$-matrix formed by $r$ rows and $r$ columns of the original matrix. In a Linear Algebra lecture, my instructor told us that the notion of a minor is very vast and could alone be the subject of a whole course. We've then only introduced a possibility to find $\text{rank}(A)$ using minors. What else is there that makes minors cool/interesting?","['linear-algebra', 'determinant']"
2746311,What is the deep concept behind the Leibniz rule?,"There are quite a few occasions in mathematics, where some form of the Leibniz rule $(fg)'=f'g+fg'$ appears - often in connection with some kind of ""differential"". Some examples are: Of coure the standard Leibnitz rule for two functions $f,g:\mathbb{R}\rightarrow\mathbb{R}$, which we can easily generalize for higher dimensional or holomorphic functions and finaly to functions between manifolds. There is also the boundary-formula for the product of two manifolds with Boundary: $\partial(M\times N)=(\partial M \times N)\cup(M\times\partial N)$. There seems to be some connection to the first example via Stokes theorem, but I think it is already unclear wether this formula implies the formula of the first example or vice versa. In the case of an algebraic varietie $X$ over a field $k$ we define the tangent space at a point $x\in X$ is defined as the space $D$ of derivations i.e. the space of linear functions $\nu:\mathcal{O}_{X,x}\rightarrow k$ satisfying $\nu(fg)=\nu(f)g(p)+f(p)\nu(g)$. In the case $k=\mathbb{C}$ there is some intuition for this, but the Leibniz rule also seems to be the crutial part of the definition for any field and also tangent spaces seem to do what we want with this definition. Finally there is also the Serre-Spectral sequence $\lbrace E_r^{p,q}\rbrace$ in cohomology. It can be equipped with a product structure $E_r^{p,q}\times E_r^{s,t}\rightarrow E_r^{p+s,q+t}$ satisfying the (graded) Leibniz rule $d(xy)=d(x)y+(-1)^{p+q}xd(y)$. I'm quite new to the usage of spectral sequences, so I really don't know if there is any connection to anything connected to differentiation in analyis. So the Leibniz rule appears in quite a lot of occasions and moreover it seems to be sometimes the crutial part in a definition (note, that in the first case it follows from some other definition whilest in the third example it is a crutial part of the definition).  Now I wonder if there is some deeper principle or theory connecting all those cases, or maybe explaining why this formula is so important?","['derivatives', 'soft-question']"
2746337,"If two random variables have CDFs that have the same value for all x, can we assume the random variables are equal?","My text has the following theorem: Let $X$ have a CDF $F$ and let $Y$ have CDF $G$. If $F(x) = G(x)$ for all $x$, then $\mathbb{P}(X \in A) = \mathbb{P}(Y \in A)$ for all $A$. I don't see a way that X and Y could assign a different probability to the same event but still have their CDFs be equal at every point. If they disagreed at point j, then F(j) will not equal G(j). Therefore they must be the same?","['probability-theory', 'probability', 'random-variables', 'probability-distributions']"
2746355,"Solution of the differential equation $2\,y\, dx +(3x^2+y^2)\, dy =0$","Please give me some hint to solve first order first degree differential equation:$2\,y\,dx +(3x^2+y^2)\, dy =0$. This cannot be solved by variable separable method. This is not exact or linear equation either. Putting $y=vx $ will not help. So I am clueless now. A small hint will be sufficient.",['ordinary-differential-equations']
2746447,Conditional measure of SRB measures on leaves,"This might be a question for mathoverflow instead of math.stackexchange, but it feels like there should be a simple answer to this and I haven't been able to work it out. Suppose $M$ is a compact Riemannian manifold and $f : M \to M$ is a $C^1$ Anosov diffeomorphism (or more generally a nonuniformly hyperbolic diffeomorphism). Then for $\epsilon > 0$, at each point $x \in M$, there is a local foliation by local unstable manifolds :
$$
W^u_\epsilon(x) = \left\{ y \in M : d\left(f^{-n}x, f^{-n}y\right) < \epsilon\right\}.
$$
I'm working with the following definition (paraphrased from a few sources): Suppose $m$ is the Riemannian volume (or Lebesgue measure) on $M$. The probability measure $\mu$ is an SRB measure if the map $f$ has nonzero Lyapunov exponents $\mu$-a.e., and the conditional measures $\mu_{u,x}$ on the leaves $W^u_\epsilon(x)$ of the local foliation are absolutely continuous with respect to $m_{u,x}$, the induced Riemannian leaf volume. My question: What does it mean for $\mu_{u,x}$ to be a conditional measure? For a general probability space $(X, \mathcal A, \mu)$, if $A \in \mathcal A$ has $\mu(A) > 0$, then the conditional measure on $A$ is $\mu_A(B) = \mu(A \cap B)/\mu(A)$. But this definition makes no sense when $A$ is the leaf of the foliation, because since $\mu(M) = 1$, we must have $\mu(W^u_\epsilon(x)) = 0$. Is there a rigorous way to define $\mu_{u,x}$? My attempt at an answer: At most points of $M$ (in fact at all points if $f$ is Anosov), there is also a foliation by local stable manifolds $$
W^s_\epsilon(x) = \left\{ y \in M : d\left(f^{n}x, f^{n}y\right) < \epsilon\right\},
$$
which is transverse to the local unstable foliation. Suppose $A \subset W^u_\epsilon(x) \cap B(x,\delta)$ is an open set in the subspace topology, where $B(x,\delta) := \{ y \in M : d(x,y) < \delta\}$. By slightly moving $A$ along the leaves of the local stable foliation, we create an open set $A' \subset B(x,\delta)$ of positive Lebesgue measure, and presumably, of positive $\mu$ measure. So, can we take the measure of the unstable ""slice"" of $A'$ that goes through $x$? Perhaps the argument involves local product structure for small $\epsilon, \delta$?","['ergodic-theory', 'dynamical-systems', 'probability', 'measure-theory']"
2746473,Proving $x^{1/x}$ approaches $1$ as $x$ approaches infinity [duplicate],"This question already has answers here : How to show that $\lim_{n \to +\infty} n^{\frac{1}{n}} = 1$? (13 answers) Closed 6 years ago . I was trying to solve a question that was uploaded here ( Computing $\lim_{n\rightarrow \infty} \frac{1+\sqrt{2}+\sqrt[3]{3}+\cdots+\sqrt[n]{n}}{n}$. ): $$\lim_{x \to \infty} \frac  {1 + 2^{1/2} + 3^{1/3} +...+ x^{1/x}}{x}$$ So i used the identity $$\lim_{x \to \infty} x^{1/x} = 1$$ and tried to prove it myself. Since $$(\sqrt[x]{x})^x = x\implies f(x) = \sqrt[x]{x} =  \frac x{(\sqrt[x]{x})^{x-1}}$$ I tried to prove that there is a horizontal asymptote at $y=1$ when $\lim\limits_{x \to \infty} x$ using the latter function without using L'Hôpital's rule.
I want to emphasize that I am not currently trying to solve the first limit, but trying to prove the asymptote of the function $f(x)$. Any suggestions?","['limits-without-lhopital', 'limits']"
2746537,Differential Operators as vectors,Do differential operators form a vector space and if so can we safely say that the del operator is a vector?,"['multivariable-calculus', 'operator-theory', 'differential-geometry', 'vector-spaces']"
2746548,Find the two missing angles in a quadrilateral,"This problem originates from a student who came asking for help. After spending some time, we couldn't solve this problem using (Euclidean) geometry alone. We had to resort to trigonometry to solve this. I have since spent many hours on it and can't seem to get anywhere. Here is the problem. Given: Quadrilateral $ABCD$ Diagonals $\overline{AC}$ and $\overline{BD}$ $m\angle ABD=19^{\circ}$ $m\angle DBC=57^{\circ}$ $m\angle ACD=30^{\circ}$ $\overline{AB}\cong \overline{CB}$ Find: $m\angle ADB$. Here is a helpful digram. It is almost immediate that $m\angle BAC \cong m\angle BCA$ and you can easily fill in the following angles, shown in green. But $x$ and (now added) $y$ are still illusive. I have tried everything from extending lines to drawing parallel lines to looking at the circumcircles and nothing seems to work. The green angles are the ones which we can easily deduce and the missing/blank angles, I don't know. How can we deduce the value of the missing angle $x$ using only high school geometry? There is obviously enough ""information"" here because if nothing else, you can just draw the quadrilateral very carefully and just measure the angle. Physically, the missing angle can only be one value. It is constrained. One should be able to deduce this value with a geometric proof using basic theorems without resorting to advanced theorems or even trigonometry. The missing values are, just for giggles, Clarification High school geometry, at least in the USA, is ""distinct"" from trigonometry and it doesn't include law of sines or cosines. High school geometry tries to mimic Euclid and his ""Elements"" where students memorize some of the definitions and axioms and are forced to mindlessly derive theorems in an excruciatingly mind-numbing manner with cumbersome notation. High school geometry also does not include any ""advanced"" geometric theorems. The most advanced thing an average student might do is something like constructing a regular hexagon. My questions is, again, can this problem be solved using only the material taught in a typical high school geometry class? If yes, then how? If you believe no, then can you give a convincing argument why trigonometry is necessary? I am hoping that this is solvable with some basic theorems and doesn't require any advanced theorems. If we allow trigonometry, then the problem is easy.","['quadrilateral', 'angle', 'euclidean-geometry', 'triangles', 'geometry']"
2746557,The law of excluded middle in mathematics,"I want to make sure that I'm understanding this correctly. Let ZFC denote the Zermelo-Frankel theory of sets with the axiom of choice. Let H denote the continuum hypothesis. Let A be a formula of ZFC. Then (A or not A) is a theorem of ZFC. In particular, (H or not H) is a theorem of ZFC. However, neither H nor (not H) is a theorem of ZFC. That is, H is undecidable. Is any of this incorrect?","['logic', 'elementary-set-theory']"
2746579,How do I perform a change in order of integration here?,"I have a function $$\int^1_{y=0}\int^1_{x=y}e^{x^2}dx\ dy$$ Which I want to perform a change in order of integration. I have plotted the graph: And it seems it's the area bounded by the y-axis and x-axis. The answer I know is $(e-1)/2$ but it doesn't make sense since a quick check can tell the area of the triangle under is $1/2.$ The limits to be changed to is:
$$\int^1_{x=0}\int^x_{y=0}e^{x^2}dy\ dx$$
Giving
$$ \left[ \frac{1}{2}e^{x^2} \right]^1_0 = \frac{1}{2}(e-1)$$","['multivariable-calculus', 'multiple-integral', 'iterated-integrals']"
2746637,Regarding Hodge's theorem,"We have $*$ the Hodge operator, and $d $ the exterior derivative. We define $\delta=\pm *d*$ and $\triangle=d\delta+\delta d $. Warner (pp. 223) says that we have 
$$
\triangle (E^p (M))=d\delta (E^p (M))\oplus \delta d (E^p (M))=d (E^{p-1}(M))\oplus\delta (E^{p+1}(M)) 
$$
I understand why the first space is a subspace of the second, and why the second is of the third. My question is why are there inverse inclusions?","['differential-forms', 'hodge-theory', 'differential-geometry']"
2746667,Problems with the definition of an adjunction space,"Recently I've been looking at the definition of an adjunction space, and for the most part it makes sense, but there's one part I don't quite understand. let $X$ and $Y$ be topological spaces with $A$ a subspace of $Y$. Let $f : A → X$ be a continuous map (called the attaching map) . One forms the adjunction space $X \cup_f Y$ by taking the disjoint union of $X$ and $Y$ and identifying $x$ with $f(x)$ for all $x$ in $A$. Schematically, $$X\cup_fY=(X\sqcup Y)/\sim$$ (Definition copied from Wikipedia) What I'm having trouble with is the identification $\sim$ being given, it doesn't seem to meet any of the criteria for being an equivalence relation.
Here's how I've seen $\sim$ usually defined, $$p_1\sim p_2 \iff p_2\in A \; and \;f(p_2)=p_1$$
(I got this definition here ) Now I think it's pretty clear from this definition that it isn't symmetric and while for some functions it could be reflexive, it generally isn't. To top it off, transitivity in terms of this relation makes no sense, $f$ is mapping from $A\subset Y$ into $X$, meaning $p_2$ automatically would not be a viable input for the left hand side because it's not even in $A$. In summary, it doesn't meet any of the criteria to be an equivalence relation. I feel like I'm missing something here, like this is shorthand for something else but I can't really think of what. Or maybe I've just overthought the whole thing, either way, if someone could help break the definition down and actually explain how adjunctions work I would be immensely grateful.","['general-topology', 'quotient-spaces', 'definition']"
2746694,$X\in\mathfrak{X}(M)$ and $df(X)$ is bounded $\Rightarrow X$ complete,"Let $M$ be a smooth manifold and $X\in\mathfrak{X}(M)$. Suppose there is a positive, proper function $f\in C^\infty(M)$ such that $df(X)$ is bounded. Prove that $X$ is complete. Take $\gamma: I\to M$ a maximal integral curve of $X$. Then $(f\circ\gamma)'(t)=df_{\gamma(t)}(\gamma'(t))=df_{\gamma (t)}(X_{\gamma(t)})$ is bounded. My idea is to prove $f\circ\gamma(I)$ is contained in a compact, so that $\gamma(I)$ is also contained in a compact (since $f$ is proper). By the escape lemma (see Lee's Introduction to Smooth Manifolds, lemma $12.11$), $I=\mathbb{R}$, as desired. The problem is that I can't see how to prove this from the fact that $(f\circ \gamma)'$ is bounded. Any ideas?","['vector-fields', 'smooth-manifolds', 'differential-geometry']"
2746726,$3\mathbb Z$ as a direct summand of $\mathbb Z$,"Show that $\mathbb Z$ cannot have $\mathbb Z$ as a direct summand: Suppose $G$ and $3\mathbb Z$ are the two direct summands of $\mathbb Z$ and show that $G$ must be isomorphic to  $C_3$. First of all, what exactly does the assumption say:  $\mathbb Z=3\mathbb Z \oplus G$  or  $\mathbb Z\simeq 3\mathbb Z \oplus G$? Second, I have only an intuitive way of showing that $G\simeq C_3$. Namely, ""mod out both sides by $\mathbb 3\mathbb Z\oplus\{0\}$"". If I'm given that $\mathbb Z=3\mathbb Z \oplus G$, then the only problem I see is that formally speaking $\mathbb 3\mathbb Z\oplus\{0\}$ isn't a subgroup of $\mathbb Z$, so I need to say more words. What exactly the formal proof should look like? If I'm given $\mathbb Z\simeq 3\mathbb Z \oplus G$, then apart from the above think I should also justify that if two groups are isomorphic, then taking quotients by isomorphic (I guess) subgroups should yield the same result. Why is that true?","['finite-groups', 'abstract-algebra', 'group-theory']"
2746757,Taxonomy of polygons,"I've written a tree-like layout to help myself remember which polygons are sub-types of others, because I always get confused. I was just wondering if this is right: |quadrilateral
    |parallelogram
        |rectangle
            |square
            |oblong
        |rhomboid
        |kite (corrected after rschwieb's answer, a rhombus is a kite)
            |rhombus
                 |square
    |trapezoid(AmE) / trapezium (BrE)
    |trapezium(AmE) / irregular quadrilateral So a square is a rhombus and a parallelogram. Also, I know that there are two definitions of ""trapezoid."" Under the inclusive definition ""trapezoid"" is immediately under ""quadrilateral"" in the tree and above parallelogram and kite. Under this definition all squares are trapezoids. Is my tree correct, at least ignoring the difference in the trapezoid definition difference? Edit: Thanks to rschwieb for helping me realise that a rhombus is a kite.
There is also a nice Euler diagram Wikipedia",['geometry']
2746791,Bitstring that contains at least one occurence of 000,"Consider bitstrings that contain at least one occurrence of $000$. Let $S_n$ be the number of such strings having length $n$. Which of the following is true for $n ≥ 4$? Answer: $S_n = S_{n−1} + S_{n−2} + S_{n−3} + 2^{n−3}$ I cannot understand this answer. If a bitstring must have a $000$, then the possible ways to build this bistrings would be: Starts with: $0 \implies S_{n-1}$ Starts with: $1000 \implies S_{n-4}$ The rest: Any combination of 1's or 0's $\implies 2^{n-4}$ It can't start with $10$ for example, because then there is a posibility of the whole string being a repetition of $10$ which wouldn't satsify the problem. So, $S_n = S_{n-1} + S_{n-4} + 2^{n-4}$ According to myself, putting these in any order will ensure a $000$ if $n ≥ 4$ but it is clearly the wrong answer. I used to be great at these but I am rusty now!","['combinatorics', 'recurrence-relations', 'discrete-mathematics']"
2746855,Holomorphic functions which preserve orientation,"Still quite unsure about the chapter on orientation. For instance the Mobius map indeed preserves orientation, and I can show this rigorously, however I am still having difficulty understanding what it means for a holomorphic function $f$ to preserve orientation over some region in the complex plane. Which is why I asked a question regarding this $2$ days ago, but did not receive an answer. The problem I am still thinking about is, I cannot show or provide a counter argument for why there does or does not exist some holomorphic function $f$ on a $\{z:|z|\le1\}$ such that it sends the unit circle with the counter- clockwise orientation into the unit circle with the clockwise orientation? From the comment from this question asked earlier, one did suggest the use of the Argument principle which states that: Argument Principle: If $f$ is meromorphic on a simply connected region $D$ and $\Gamma$ is a simply closed curve in $D$ not passing through the roots $z_j$ nor the poles $p_k$ of $f,$ then $$\frac{1}{2\pi i}\oint_{\Gamma}\frac{f'(z)}{f(z)}dz=n-m$$
  Where $n$ is the number of roots of $f$(including multiplicities) in $\Gamma$ and $m$ is the number of poles of $f$ (including multiplicities) inside $\Gamma.$ I am really curious to find out why we can apply this to try and provide an explanation for my problem. I would appreciate some help because I am quite confused with orientation at the moment, and I think this problem is good in the sense it will help me understand some important notions on holomorphic functions which send or does not send certain orientation on a region to a different orientation of the same region. I would really appreciate some rigorous argument for this problem. Much help will be appreciated.",['complex-analysis']
2746901,Pairs of non-empty disjoint sets,"Question: Let $S=\{1,2, \cdots, 10 \}$. Then the number of pairs $(A, B)$, where $A$ and
$B$ are non-empty disjoint subsets of $S$ is? [I could solve the question as demonstrated below, but it involves calculating a tedious sum of products, which would take up a lot of time. It is typically expected to solve this in a couple of minutes, so I was wondering if there was a faster way to do this.] My approach: Let the set $A$ consist of $x$ elements. There are ${10 \choose x}$ ways of making that selection. We are now left with $10-x$ elements. Let the set $B$ consist of $y$ elements. This selection can be done by ${10-x \choose y}$ ways. The total number of ways can be found out by summing over the product of the two above as $\sum_{x=1}^{9} \sum_{y=1}^{10-x} {10 \choose x}{10-x \choose y} $ which comes out to be $57002$","['combinatorics', 'binomial-theorem', 'elementary-set-theory', 'discrete-mathematics']"
2746906,How many solution does $1/a+1/b+1/c+1/d=1$ have?,"From my friend, he gives me a competition question: ""How many solution $(a,b,c,d)$ does $\frac{1}{a}+\frac{1}{b}+\frac{1}{c}+\frac{1}{d}=1$ have where $a,b,c,d$ are positive integers? (the size of $a,b,c,d$ doesn't matter, either one can be the biggest or smallest, and they are not necessarily distinct)"" I want to ask if there is any solution shorter than mine? I think mine is too long, and maybe yields a wrong answer. My solution:
WLOG, let $a\leq b\leq c\leq d$
$$1=\frac{1}{a}+\frac{1}{b}+\frac{1}{c}+\frac{1}{d}\leq \frac{4}{a}$$
$$a\leq4$$
Because $a=1$ yields no solution, so consider $a=2,3,4$ Case 1:$a=2$, then $\frac{1}{b}+\frac{1}{c}+\frac{1}{d}=\frac{1}{2}$ Do that again: $\frac{1}{2}=\frac{1}{b}+\frac{1}{c}+\frac{1}{d}\leq\frac{3}{b}$, so $b\leq 6$. Let $b=6$,  then $\frac{1}{c}+\frac{1}{d}=\frac{1}{3}$, going to $$(c-3)(d-3)=9$$ $$(c,d)=(4,12),(6,6)$$ so in the case have: $(a,b,c,d)=(2,6,4,12),(2,6,6,6)$ then eliminate some case not satisfy $a\leq b\leq c\leq d$ Then going through when $b=5$,$b=4$,$b=3$... yields $184$ distinct solutions. Case 2: Following the same procedure as Case 1... yields $18$ solutions. Case 3: As above... yields only a solution which is $(4,4,4,4)$ Conclude it, the equation has $203$ solutions. That is my solution, I wrote it using one and a half piece of A4 paper, I have recently tried $abcd=abc+abd+acd+bcd$ but don't know how to continue, or should I use Vieta theorem? ---After first edit--- According to Robert Z, I had miscount quadruplet $(3,4,4,6)$ which add up the count to $215$ solutions. -- After last edit -- Seems like there is no faster solution, I will close this question and marked as solved. Thanks to everyone who spend effort to my question.","['algebra-precalculus', 'diophantine-equations']"
2746921,Excercise 1.75 from Manifolds and Differential Geometry,"I came across this exercise Exercise 1.75 Manifolds and Differential Geometry by Jeffrey M. Lee which states: Let M be a smooth manifold. Let K be a closed subset of M and O an
  open subset containing K. Show that there exists a smooth function
  $\beta$ on M that is identically equal to 1 on K, takes values in the
  interval [0,1], and has compact support in O. How can this be true? Set $M = \mathbb{R}$ and $K = \mathbb{Z}$ and let O be the union of small balls, one around each integer and none overlapping. How can the support of $\beta$ be compact then? It cant possibly be bounded since it contains $\mathbb{Z}$.","['smooth-manifolds', 'differential-geometry']"
2746934,Holomorphic function on the unit disc,"Let $D=\{z \in \mathbb{C} \mid |z| < 1  \}$ be the unit disc. Let $g: D \to D$ be a holomorphic function with $g(0)=0$. Let $h = \dfrac 1{1-g}$, and assume that
$$ h(z) = \sum_{k=0}^{\infty} a_k z^k ,|z|<1 $$ Show that $|a_n|<1(n = 1,2,3,\cdots)$. Equivalently, let $f:D \to F$ be a holomorphic function with $f(0)=1$, where $F = \{ z \in \mathbb{C} \mid \mathrm{Re} z > \dfrac12\}$ and
$$ f(z) = \sum_{k=0}^{\infty} a_k z^k ,|z|<1 $$ Show that $|a_n|<1$ $(n=1,2,\ldots)$",['complex-analysis']
2746958,Smooth floor function,"I want a monotonic function on the positive real numbers that behaves like floor but in smooth way, like smoothstep but for all integers.
It should follow this simple rule. slope is zero at integers and slope is maximum at median of two adjacent integers or in other words: slope is at $0$ when fract$(x) = 0$ and slope is at maximum when fract$(x)=0.5$ So far i was able to approximate this function my self with help of trigonometric functions. 
$$
f(x) = \lfloor x \rfloor + \max\left(\frac{(-1)^{\lfloor x\rfloor}}{2}(1-\cos(\pi x)), \frac{(-1)^{\lfloor x+1\rfloor}}{2}(1-\cos(\pi x + \pi))\right)
$$
can this be achieved in a simpler/shorter way?","['real-analysis', 'trigonometry', 'functions', 'approximation-theory', 'ceiling-and-floor-functions']"
2747025,$\lim\limits_{n\to \infty} \frac{1}{n}\cdot \big((m+1)(m+2) \ldots(m+n)\big)^{\frac{1}{n}}$ where $m$ is a fixed positive integer is?,$$\lim_{n\to \infty} \frac{1}{n}\cdot \big((m+1)(m+2) \ldots(m+n)\big)^{\frac{1}{n}}$$ where $m$ is a fixed positive integer. Here is my attempt: According to Cauchy's theorem of limit if $\lim\limits_{n\to \infty}a_n=l$ then $\lim{(a_1a_2 \ldots a_n)}^{\frac{1}{n}}=l$ hence $\lim\limits_{n\to \infty}\frac {m+n}{n}$ $\Rightarrow \lim\limits_{n\to\infty}\left(1+\frac{m}{n}\right)=1$ I'm 90 percent clear that my solution is correct. If not then please give me the right solution.,"['real-analysis', 'sequences-and-series', 'limits']"
2747182,Why is a probability space usually never explicitly written?,"In probability, a probability space $(\Omega,\mathcal{F},\mathbb{P})$ is usually never expressed explicitly and we just take it to be this 'mysterious' thing in the background (that satisfies certain axioms). Why is this the case? Especially in continuous time/financial models, we just assume $(\Omega,\mathcal{F},\mathbb{P})$ is some probability space and then we define  random variables or stochastic processes on it. Is it because the probability space is not really that important.  For example we may want to model an asset price process on some interval $[0,T]$ by $S_t$ - a standard (starting at 0) 1 dimensional brownian motion (this is not a good model) on $[0,T]$. And so we just model the whole thing by saying let $S_t$ be a standard 1 dimensional brownian motion on some probability space $(\Omega,\mathcal{F},\mathbb{P})$. So in real life do we only care about how things can be approximated using random variables/stochastic processes, and then we dont really care about specifying $(\Omega,\mathcal{F},\mathbb{P})$ explicitly, we just know its there in the background.",['probability-theory']
2747205,Dual norm of a truncated and ordered (decreasing order) $\ell_1$-norm,"I do not understand yet how the following dual-norm of a truncated and ordered (in decreasing fashion) $\ell_1$-norm $\lVert \mathbf{x}\rVert_{[k]}$ on $\mathbf{x} \in \mathbb{C}^n$ is: $$\lVert \mathbf{x}\rVert^*_{[k]}= \max\left\{\frac{1}{k} \| \mathbf{x} \|_1,\lVert \mathbf{x}\rVert_{\infty}\right\}$$ The  truncated $\ell_1$-norm is defined as the sum of the $k$ largest magnitudes of the entries in $\mathbf{x}$ vector, i.e., $\lVert \mathbf{x}\rVert_{[k]}=\lvert x_{i_1}\rvert+.....+\lvert x_{i_k}\rvert$ in which $\lvert x_{i_1}\rvert\geq\lvert x_{i_2}\rvert\geq.....\geq\lvert x_{i_n}\rvert$. Thank you","['optimization', 'convex-optimization', 'linear-algebra', 'convex-analysis']"
2747244,Geometric intuition of composition of hyperbolic and inverse hyperbolic trig functions,"We can evaluate $\cos(\arcsin x)$ with simple geometric intuition. Write $y = \cos(\arcsin x)$. Letting $\theta = \arcsin x$, $y = \cos \theta$ corresponds to a right triangle with angle $\theta$, adjacent side length $y$, and hypotenuse $1$. Pythagoras gives that the opposite side has length $\sqrt{1-y^2}$. Then $\sin \theta = \sqrt{1-y^2}/1 = \sqrt{1-y^2}$. Now $\sin \theta = \sin(\arcsin x) = x$ with appropriate bounds, so $x = \sqrt{1 - y^2}$ with appropriate bounds, so $y = \cos (\arcsin x) = \sqrt{1 - x^2}$ with appropriate bounds. It can be shown that $\cosh (\mathrm{arcsinh} \ x) = \sqrt{1+x^2}$. Can we derive this using a similar intuitive geometric construction, perhaps on a hyperbola? If so, how?","['hyperbolic-functions', 'trigonometry', 'geometry']"
2747253,Finding integration factor for an ODE,"I'm trying to get the following system of equation to exact differential equation form: $$
\left\{ 
\begin{array}
\dot \dot x =y^2-x \\ 
\dot y = 2y
\end{array}
\right. 
$$ What I tried: $$\frac{dx}{dy}=\frac{y^2-x}{2y} \quad \Rightarrow \quad 2ydx+(x-y^2)dy=0 $$ Next I tried to find an integration factor: $$\frac{N_x-M_y}{M}=-\frac{1}{2y} $$ $$\Rightarrow \quad \mu(y)=e^{\int-\frac{1}{2y}dy}=e^{-\frac{1}{2}ln|y|}=\frac{1}{\sqrt{|y|}}$$ Is there a way I can get rid of the absolute value? omitting it gives an exact differential equation but only for part of the domain.","['integration', 'ordinary-differential-equations']"
2747295,Homeomorphism of Quotient Space,"I am relatively new to topology and thought one should be able to prove the following:
Let $X = A \cup B$ be a topological space and $A,B \subset X$ (Maybe we need them to be closed subspaces?). Then $X/A \cong B/(A \cap B)$. This at least seems pretty intuitively, but i do not really know how to prove that. A hint/solution would be amazing! I tried something along the lines of: Since $X = A \cup B$, the identity on X yields a homeomorphism $X \cong A \cup B$. This induces a homeomorphism $X/A \cong (A \cup B)/A$. Now I would like the union to respect quotients, such that $(A \cup B)/A \cong A/A \cup B/(A \cap B)$. Now the left space is a singleton and i kind of get what I want.","['general-topology', 'quotient-spaces']"
2747297,Proving $\int_0^r{(r^m-x^m)^{1/m}dx}=\frac{\Gamma\left(\frac{1}{m}+1\right)\Gamma\left(\frac{1}{m}+1\right)}{\Gamma\left(\frac{2}{m}+1\right)}r^2$,"First let's put the question succinctly. How can I go about showing the following? $$\int_0^r{(r^m-x^m)^{1/m}dx}=\frac{\Gamma\left(\frac{1}{m}+1\right)\Gamma\left(\frac{1}{m}+1\right)}{\Gamma\left(\frac{2}{m}+1\right)}r^2$$ Now for some exposition: 
I am a math enthusiast and this result kind of fell into my lap after playing around a bit with ""circles""... This is my first encounter with the $\Gamma$ function. I am not quite sure how one goes about establishing such a claim. At this point I am at the ""I better look into this $\Gamma$ function"" part of my research but I figured I would document the question and take any input offered. Consider the equation $|x|^m+|y|^m=1$, for $m \in {1,2,3}$ The $m=1$ case then corresponds to the square in the picture which has side lengths $\sqrt{2}$. The whole square has area $2$ and therefore the area of the square limited to the first quadrant is $1/2$. $$\int_0^1{(1-x)dx}=\frac{\Gamma(2)\Gamma(2)}{\Gamma(3)}=\frac{(2-1)!(2-1)!}{(3-1)!}=\frac{1}{2}$$ I only invoke the idea that over the whole numbers $\Gamma(n+1)=n!$ here because I found the formula by examining this in the case when my inputs for $\Gamma$ were whole numbers. Then I replaced my factorial symbols with $\Gamma$s to get the claim above which I have only verified empirically. For the $m=2$ case. We have the unit circle. The area in the first quadrant should be $\pi/4$. And indeed: $$\int_0^1{(1-x^2)^{1/2}dx}
=\frac{\Gamma\left(\frac{3}{2}\right)\Gamma\left(\frac{3}{2}\right)}{\Gamma(2)}
=\frac{ \sqrt{\pi}}{2}\frac{ \sqrt{ \pi} }{2}=\dfrac\pi4$$ Cool! So now I was excited to see that this worked not only in the cases with whole number inputs to $\Gamma$. $m=3$ 
Well then what's the area under the curve $|x|^3+|y|^3=1$? This corresponds to the outermost curve in the diagram. Well... I assume this value must be some transcendental number. It's construction is similar to the way we think about $\pi$. But what is it? $$\begin{align*}\int_0^1{(1-x^3)^{1/3}dx}&=\frac{\Gamma(\frac{1}{3}+1)\Gamma(\frac{1}{3}+1)}{\Gamma(\frac{2}{3}+1)}\\ &\approx 0.883319375142724978656844749824219351285934269101278765063\end{align*}$$ Which matches up with numerical integration. Wolfram alpha can present this number in a few other ways. For example, $$\frac{\Gamma(1/3)^3}{4\sqrt{3}{\pi}}$$ These other representations all seem to invoke the Gamma function.","['complex-analysis', 'algebraic-geometry', 'geometry']"
2747376,Is the $2\pi$ factor correct in the Inverse Fourier transform formula?,"These two formulae were given in my circuit analysis textbook: Fourier Transform: $$F(\omega)=\int_{-\infty}^{\infty}f(t)e^{-i\omega t}dt$$ Inverse Fourier Transform: $$f(t)=\frac{1}{2\pi}\int_{-\infty}^{\infty}F(\omega)e^{i\omega t}d\omega$$ I have a bit of a doubt as to whether the second formula is true. I don't understand where the $2\pi$ factor is coming from in the second formula? If the above hold formulae true, is is the following provable? $$f(t)=\frac{1}{2\pi}\int_{-\infty}^{\infty}\left(\int_{-\infty}^{\infty}f(t)e^{-i\omega t}dt\right)e^{i\omega t}d\omega$$","['integration', 'definite-integrals', 'fourier-transform']"
2747403,Left tail bound for sum of exponential random variables,"Let $S_n = \sum_{i=1}^n X_i$ with $X_i$ iid $\exp(1)$ random variables. Fix a small $\epsilon >0$. What is the optimal bound for $P(S_n \leq \epsilon n)$? The best bound I know starts by noting that $S_n \leq \epsilon n$ implies at least $n/2$ of the $X_i$ are smaller than $2 \epsilon$. We can compute $$P(X_1 \leq 2 \epsilon) = 1- e^{- 2 \epsilon} \approx - 2\epsilon.$$
Using the bound $\binom n {n/2} \leq 2^n$ we then have
$$P( S_n \leq \epsilon n) \leq 2^n ( 2 \epsilon )^{n/2}) = (2 \sqrt {2 \epsilon} )^n.$$ This feels sub-optimal. Is there a better concentration inequality that can be applied?","['probability-theory', 'probability-distributions']"
2747404,Linear independence of indicator functions,"Question Let $X$ be a finite set, let $\mathbf{F}$ be a field. Let $\mathcal{A}$ be a subset of the power set of $X$, i.e. $\mathcal{A}\subseteq\mathcal{P}(X)$. Let $1_A:X\to F$ denote the indicator function of $A\subseteq X$. When is $\{1_A:A\in\mathcal{A}\}$ linearly independent in the vector space $\mathbf{F}^X$? Potential difficulty Unfortunately, this seems to depend on the characteristic of $\mathbf{F}$. For example, if $X=\{a,b,c\}$ and $\mathcal{A}$ consists of all two-element subsets of $X$, then $\{1_A:A\in\mathcal{A}\}$ is dependent when $\mathrm{char}(\mathbf{F})=2$, but independent otherwise. Partial answer All I can say so far is that $\mathcal{A}$ cannot contain an inclusion-exclusion family by which I mean a collection of the form $$\{A,B,A\cap B, A\cup B\}\text{ or}$$ $$\{A,B,C,A\cap B, A\cap C, B\cap C, A\cap B\cap C, A\cup B \cup C\} \text{ or so on}.$$","['inclusion-exclusion', 'abstract-algebra', 'combinatorics', 'linear-algebra']"
2747429,Expressing the sum of two simple functions,"I am reading through a book on measure theory and it says that for simple functions $f=\sum a_i \mathbf{1}_{A_i}$ and $g=\sum b_j\mathbf{1}_{B_j}$, the sum can be written
$$(f+g)=\sum_{i,j}(a_i+b_j)\mathbf{1}_{A_i \cap B_j}$$ I am having trouble showing how this can be done. I tried writing $f+g=\sum a_i \mathbf{1}_{A_i} +\sum b_j\mathbf{1}_{B_j}$ but didn't make a lot of progress. Is there a nice way to show this property? Note that $\{A_i\}$ and $\{B_j\}$ are pairwise disjoint collections of sets and $\mathbf{1}_{A_i}$ is the indicator function for set $A_i$. Thanks",['measure-theory']
2747439,Does the relation $\in$ follow the axiom of substitution for equality.,"I am trying to self-learn set theory from Analysis 1 by Terence Tao. I am facing a problem understanding how he shows the relation $\in$ for sets follows the axiom of substitution. He begins by informally defining sets and the $\in$ relation. He then states the axiom: all sets are objects. Instead of stating the axiom of extension, he defines what it means for two sets to be equal. (Definition 3.1.4.) Two sets $A$ and $B$ are equal iff every element of $A$ is an element of $B$ and vice versa. He then leaves proving the fact that equality of sets is reflexive, symmetric and transitive to the reader. This is what he says next: Observe that if $x \in A$ and $A=B$, then $x \in B$, by Definition 3.1.4. Thus the “is an element of” relation $\in$ obeys the axiom of substitution (see Section A7). Because of this, any new operation we define on sets will also obey the axiom of substitution, as long as we can define that operation purely in terms of the relation $\in$. What I don't understand is how does $x \in A$ and $A=B$, then $x \in B$ show that the relation $\in$ obeys the axiom of substitution? To me it seems like the argument implies that the relation of equality obeys the axiom of substitution instead. What am I missing here?",['elementary-set-theory']
2747521,"Show $ |k(x_o)| \geq \frac{1}{\|c(x_o)\|} $ , $c$ plane curve and $k(x)$ curvature.","Let $ c:(a,b)→\mathbb{R^2}$ be a regular arc length parametrized plane curve. Assume that there exists $x_o$ , $a<x_0<b$, such that the function  $x \rightarrow \|c(x)\|$ has a maximum in $x_0$. Prove: $$ |k(x_o)| \geq \frac{1}{\|c(x_o)\|} $$ ($k(x)$ curvature) My Work: We define a function $f : (a,b) \rightarrow \mathbb{R^2}$ , $ x \rightarrow  \|c(x)\|^2 $. We get: $$f'(x) = 2\langle c'(x),c(x)\rangle$$ and $$ f''(x) = 2( \langle c''(x),c(x)\rangle + \langle c'(x),c'(x)\rangle) = 2(\langle c''(x),c(x)\rangle + 1) = 2(\langle k(x)n(x),c(x)\rangle +1) = 2(k(x)\langle n(x),c(x)\rangle +1) $$ Is this right? ( $k(x)$ curvature , $n(x)$ normal ) f has a maximum in $x_o \Rightarrow f'(x_0) = 0$ and $f''(x_0) \leq 0$. Unfortunately I'm stuck here. Can somebody help me to finish this proof? Maybe we could consider $f''(x_o) = 2(k(x_o)\langle n(x_o),c(x_o)\rangle +1) \leq 0?$","['curves', 'normed-spaces', 'differential-geometry', 'curvature']"
2747542,Alice and Bob playing on a circle,"I want to solve this problem: Let there be $n \ge 2$ points around a circle. Alice and Bob play a game on the circle. They take moves in turn with Alice beginning. At each move: Alice takes one point that has not been colored before and colors it red. Bob takes one point that has not been colored before and colors it blue. When all $n$ points have been colored: Alice finds the maximum number of consecutive red points on the circle and call this $R$ . Bob finds the maximum number of consecutive blue points on the circle and call this $B$ . If $R \gt B$ , Alice wins. If $B \gt R$ , Bob wins. If $R = B$ , no one wins. Does any of the players have a winning strategy? We still seem not to know for which odd $n$ Alice has a winning strategy. She does for $n=3$ , and it seems also for $n=5$ . But in general, I'm not sure. Could someone help?","['game-theory', 'combinatorics', 'combinatorial-game-theory']"
2747569,Shortest path problem in general : Cube,We have $m\times n\times k$ cube. We want to go from $A$ to $B$ and we can only walk on the lines on the surface (horizontally or vertically). How many shortest paths are there? I know that for a square which dimensions are $m\times n$ shortest path is $  \binom{m+n}{m} = \binom{m+n}{n}$ how do you aproach this problem in 3 dimensions though? I saw similar question but size was fixed and there wasnt much explanation of the anwser: Combinatorics Path problem: Cube,"['combinations', 'combinatorics']"
2747588,the inclusion-exclusion principle for an infinite indexed family of sets,"Assume that $\{A_{i}\}_{i\in I}$ is a collection of non-empty sets indexed by an arbitrary indexing set $I$. How can I construct a pairwise disjoint collection $\{A'_{i}\}_{i\in I}$ such that $A'_{i}\subset A_{i}$ for every $i$, and $${\bigcup}_{i\in I}A_{i}'={\bigcup}_{i\in I}A_{i}?$$ (By pairwise disjoint, I mean, of course, that $i\neq j$ implies $A_{i}'\cap A_{j}' = \emptyset.$) If $I$ were finite, I could use the inclusion-exclusion principle. But would this work when $I$ is countably infinite, or when $I$ is uncountable?",['elementary-set-theory']
2747593,Can you take the derivative of a function at infinity?,"Exactly the title: can you take the derivative of a function at infinity? I asked my maths teacher, and while she thought it was an original question, she didn't know the answer, and I couldn't find anything online about this. Maybe this is just me completely misunderstanding derivatives and functions at infinity, but to me, a high schooler, it makes sense that you can. For example, I'd imagine that a function with a horizontal asymptote would have a derivative of zero at infinity.","['derivatives', 'real-analysis', 'calculus']"
2747640,Surjective measures,"Let $\Omega$ be an infinite set and suppose that ${\cal F}$ is a $\sigma$-algebra on $\Omega$ such that $|{\cal F}|\geq 2^{\aleph_0}$. Is there a measure $\mu : {\cal F} \to [0,1]$ such that $\mu$ is surjective as a function?","['real-analysis', 'measure-theory']"
2747669,A question about Existence of a Continuous function.,"Let $f$ be a continuous function on the interval $[1,2]$ . It follows from Stone-Weierstrass theorem that if $\displaystyle \int_1^2x^nf(x) \, dx=0$ for integers $n=0,1,2,\ldots$ , then $f$ must be identically zero. My question is, Does there exist a non-zero  continuous function $f$ on the interval $[1,2]$ , and a positive constant $M$ such that $\displaystyle \left|\int_1^2x^nf(x)\,dx\right|\leq M$ for all integers $n=0,1,2,\ldots$ ? If such a function exists, it must be an oscillating function which attains both positive and negative signs. I really appreciate for any answers, comments or suggestions.",['real-analysis']
2747776,Is it possible to blow-up in codimension one?,"In the context of complex manifolds, one can consider a blow-up along a complex submanifold. For a linear subspace of $\mathbb{C}^n$ there is a general procedure to perform such a blow-up: for a subspace $\mathbb{C}^m$ determined by the equations
$$
z_1 = z_2 = \ldots = z_{n-m} = 0 \,,
$$
we can introduce a projective space $\mathbb{CP}^{n-m-1}$ with coordinates $y_i$, and define the blown-up space $\tilde{X}$ by
$$
\tilde{X} = \{(z,y)~|~z_i y_j = z_j y_i \,, ~i,j=1,\ldots,n-m\} \subset \mathbb{C}^n \times \mathbb{CP}^{n-m-1} \,,
$$
with a blow-down map that simply projects onto the $\mathbb{C}^n$ factor. The equations ensure that the blow-down is an isomorphism away from the original subspace, and sends a $\mathbb{CP}^{n-m-1}$ to a point everywhere on the subspace. For codimension $n-m=1$, the above procedure doesn't define a blow-up, since $\mathbb{CP}^{n-m-1}$ is just a point. My question is: Is there any similar construction for codimension one subspaces?","['complex-geometry', 'algebraic-geometry', 'blowup']"
2747779,How can I find the Z score of 0.05?,"This is the question: To estimate the average speed of cars on a specific highway, an investigator
collected speed data from a random sample of 75 cars driving on the
highway. The sample mean and sample standard deviation are 58 miles per
hour and 15 miles per hour, respectively.
Construct a 90% confidence interval for the mean speed. I have the answer for it, and this is the answer: But, I don't understand why Z0.05 =1.645. On the  Standard Normal Distribution Table, P(Z < -1.645) = 0.05. Therefore, Z0.05 should be -1.645 instead of 1.645","['statistics', 'probability', 'normal-distribution']"
2747790,How is extension by analytic continuation done?,"I understand  that by defining an expression for a function to be analytic, we can extend the range of the expression beyond it's usual range. One case is that a series which is asymptotic to a function defined abstractly within certain domain could in fact diverage outside of that domain while the function is still defined. Can analytic continuation enable us to extend the range of an expression from just a little block of known domain and range to infinite range and domain? If so, how is it done? Could it be only done by computer simulation? Or algebraic manipulation is enough? What are the ways to do this? Could it be done by hand in special case? In general, how is it done?","['functional-analysis', 'complex-analysis', 'analytic-continuation']"
2747824,Second order autonomous system,"I am looking for a periodic solution (with period $2\pi m$, for some integer $m$) to the following ODE $$\ddot{x}+x-\frac{1}{x}=0.$$ ($x(t)=\pm 1$ trivially solves this equation). Note that this system is integrable, so the quantity $$E=\dot{x}^2+x^2-\log x^2$$ is constant for any solution. Separating variables and integrating gives $$t=\int\frac{dx}{\sqrt{E-x^2+\log x^2}}.$$ However, I haven't been able to solve the integral. Maybe thinking of this as a physical system with potential $V(x)=x^2-\log x^2$ would be useful (though I haven't been able to employ this fact). I'd appreciate any suggestions.","['ordinary-differential-equations', 'dynamical-systems']"
2747850,"If $\mu^{\ast}$ is an outer measure with enveloping property, $A_n \nearrow A$, $\mu^{\ast}(A) = \lim_{n\to \infty}\mu^{\ast}(A_n)$","Let $\mu^{\ast} : \mathcal{H} \to [0,\infty]$ an outer measure, where $\mathcal{H}$ is an hereditary $\sigma$-ring. Suppose that for each $A \in \mathcal{H}$ there is an measurable set $E$ such that $A \subset E$ and $\mu^{\ast}(A) = \mu^{\ast}(E).$ We say in this case that $\mu^{\ast}$ has the enveloping property . Prove that if a sequence $\{A_n\} \subset \mathcal{H}$ is such that $A_n \nearrow A$, then
$$\mu^{\ast}(A) = \lim_{k \to \infty}\mu^{\ast}(A_k). $$ I tried several naive things like: For each $k$ there is $\tilde A_k$ measurable such that $A_k \subset \tilde A_k$ and $\mu^{\ast}(A_k) = \mu^{\ast}(\tilde A_k).$ Then, I tried to show that $\tilde A_k \subset \tilde A_{k+1}$, but it seems not to be true. Then, I considered $\tilde A_N := \cup_{k=1}^N\tilde A_k$. It is true that $\tilde A_N \supset \bigcup_{k=1}^N A_k$, but is not true necessarily that $$\mu^{\ast}(\tilde A_N) = \mu^{\ast}(\bigcup_{k=1}^NA_k),$$ so it led to nowhere. Any hints? Thanks in advance.",['measure-theory']
2747872,$x-y> 1$. How is this relation neither symmetric nor anti symmetric?,"I have a assigned worksheet that claims so. ""This is irreflexive, as $x – x = 0$, which is never $> 1$. This is neither symmetric nor antisymmetric, example: $x=5, y=1$ works, $y=5, x=1$ doesn’t (would imply antisymmetric), but $x=2, y=1$ doesn’t work and neither does $x=1, y=2$, so can’t be antisymmetric. This is transitive. If the difference between $x$ and $y$ is greater than $1$ and between $y$ and $z$ is greater than $1$, then the difference between $x$ and $z$ must be greater than $2$."" I can appreciate that the relation is not symmetrical but am having confusions about the anti-symmetry. The way I understand anti-symmetry in relations is that if $(x,y)$ values exist such that $xRy$ and $yRx$, then $x=y$. Now, since there are no values $(x,y)$ that hold the relation, we cannot dismiss this anti-symmetry. I have stumbled upon similar cases in discrete mathematics where if you cannot dismiss a hypothesis, it is accepted as true. Wouldn't it be true here too? Why does $x=2, y=1$ doesn’t work and neither does $x=1, y=2$ dismiss anti-symmetry? Which condition of anti-symmetry is this breaking? It would be helpful if you could also state its transitivity and reflexiveness. Slide from my lecture regarding anti-symmetry.","['relations', 'discrete-mathematics']"
2747896,Can we say that cardinality of $\lvert \mathbb{R}\rvert$ is equal to infinity?,"I am a bit confused with cardinality at the moment. I know that the cardinality of $\mathbb{R}$ is equal to $\lvert(0,1)\rvert$, but does that mean they are equal to infinity, if not what are they equal to ?","['cardinals', 'discrete-mathematics']"
2747916,"If a point lies outside a triangle, show that there is a line through that point that does not intersect the triangle","I'm trying to prove that if a point is outside a triangle, then there is a line through that point that does not intersect the triangle.
This fact seems obvious, but I couldn't come up with a satisfying proof. I tried going by contradiction (that if any line intersects the triangle,then the point is surrounded by points contained on the triangle's sides, so the point is inside the triangle) but I do not find it satisfying, mainly because a line could intersect the triangle ""in the backside""(this would only be a problem if the point were to lie on one of the triangle's sides though), but it still doesn't feel rigorous enough. Another idea would be to consider parallels to the sides, but I couldn't finish this proof well enough. Any very clear and rigorous methods to prove this?",['geometry']
2747943,Does $R[[x]] \cong S[[x]]$ imply $R\cong S$,"Let $R,S$ be commutative unitary rings. Is it true that $$R[[x]] \cong S[[x]] \quad \Rightarrow \quad  R\cong S.$$ Here by $R[[x]], S[[x]]$ I mean the ring of formal power series and the isomorphisms as isomorphisms of rings. In fact, in this question Does $R[x] \cong S[x]$ imply $R \cong S$? the answer for the polynomial ring is negative and I became curious about the formal power series case.","['abstract-algebra', 'formal-power-series', 'commutative-algebra']"
2747959,Frobenius and operator norms of rank 1 matrices,"$\newcommand{\opnorm}[1]{\left\| #1 \right\|_{\mathrm{op}}}
 \newcommand{\norm}[1]{\left\| #1 \right\|}$
Suppose we have $X = x_1 x_2^\top \in \mathbb{R}^{n \times d}$ a rank-1 matrix which is non-symmetric in general. I want to either prove that $\| X\|_F =
\opnorm{X}$ or give an upper bound $\norm{X}_F \leq c \opnorm{X}$, where ideally $c$ does not depend on the dimensions of $X$. My attempt: $$
\opnorm{X} = \sup_{\norm{v} = 1} \norm{Xv}_2 =
\sqrt{\sup_{\norm{v} = 1} \norm{Xv}_2^2} =
\sqrt{\sup_{\norm{v} = 1} v^\top X^\top X v} =
\sqrt{\lambda_{\max}(X^\top X)}
$$ For the Frobenius norm, use $X$'s singular value decomposition to write
$X = USV^\top$, and obtain $$
\norm{X}_F = \sqrt{\mathrm{tr}(X^\top X)} =
\sqrt{\mathrm{tr}(V S U^\top U S V^\top)} = \sqrt{\mathrm{tr}(
S^2)} = \sqrt{\sum_{i=1}^{\mathrm{rank}(X)} \sigma_i^2} =
\sqrt{\sigma_1^2}
$$ However, we know that the singular values of $A$ are the square roots of the eigenvalues of $X^\top X$, therefore $\sigma_1^2 = \lambda_{\max}(X^\top X)$. Hence $\norm{X}_F = \opnorm{X}$. Is the above proof correct?","['singular-values', 'matrices', 'rank-1-matrices', 'matrix-norms', 'linear-algebra']"
2747967,Distribution of Sum of Independent Log-Gamma Random Variables,"Suppose $X_i\sim GAM(\alpha,\beta)$ with PDF $$f_{X_i}(x)=\frac{x^{\alpha-1}e^{-x/\beta}}{\Gamma(\alpha)\beta^\alpha}$$  Then, from univariate transformation, the random variable $Y_i:=ln(X_i)\sim LOGGAM(\alpha,\beta)$ with PDF $$f_{Y_i}(y)=\frac{e^{\alpha y}\cdot e^{-e^{y}/\beta}}{\Gamma(\alpha)\beta^\alpha}$$ Suppose I have a random sample of $Y_i$ that are independent and identically distributed from this log-gamma distribution, $i\in\{1,2,...,n\}$. What is the distribution of $\sum_{i=1}^n Y_i$?  That is, what is the distribution of the sum of independent and identically distributed log-gamma random variables? From the MGF technique, we can find that $$M_{\sum Y_i}(t)=\left(\frac{\beta^t\Gamma(\alpha+t)}{\Gamma(\alpha)}\right)^n$$ But I have no idea how to derive the PDF of a distribution that has this particular MGF.  We know that $\alpha>0, \beta>0,$ and $Y_i\in(-\infty, \infty)$, but even with those assumptions I'm still lost.  How can we get this PDF?","['probability-theory', 'probability-distributions', 'statistics', 'probability', 'gamma-function']"
2748114,"$(\mathbb{Q},+)$ has no maximal subgroup.","Definition. A maximal subgroup of a group G is a proper subgroup $M$ of $G$ such that there are no subgroup $H$ of $G$ such that $M<H<G$. Now, I want to solve the following problem: Problem: $(\mathbb{Q},+)$ has no maximal subgroup. There are solutions available here . But I find these hard to me...So I try to solve this own... My Solution: Suppose that $M$ be a maximal subgroup of $(\mathbb{Q},+)$. Then by Fourth Isomorphism Theorem the subgroups of $\mathbb{Q}/M$ are only $\{0\}$ and $\mathbb{Q}/M$. And then $\mathbb{Q}/M$ must be a finite group, Since it can be proved that A group is finite if and only if it has finite number of subgroups ( See here ).  Therefore $[\mathbb{Q}:M]=|\mathbb{Q}/M|<\infty$. Therefore $M$ becomes a proper subgroup of finite index of $(\mathbb{Q},+)$, and which, we know, is not possible. (*because, $(\mathbb{Q},+)$ has no proper subgroup of finite index). Hence we get a contradiction. *Theorem. $(\mathbb{Q},+)$ has no proper subgroup of finite index Proof: Suppose $H \le \mathbb{Q}$ such that $[\mathbb{Q}:H]=|\mathbb{Q}/H|=n$ (say) Now let $q \in \mathbb{Q}$. Then $(q+H)^n=H$ i.e. $nq+H=H$ i.e., $nq \in H$. Since $q$ is arbitrary in $\mathbb{Q}$ so this means $n\mathbb{Q} \subset H$. But look $n\mathbb{Q}=\mathbb{Q}$, since $q \mapsto nq$ is an automorphism of $\mathbb{Q}$. Hence $H=\mathbb{Q}$. Is this solution correct? Thank you..","['abstract-algebra', 'maximal-subgroup', 'group-theory', 'proof-verification']"
2748162,Which is the probability that a group of 10 people exceed the maximum load?,An elevator with capacity for 10 people is designed to support a maximum load of 750kg.If the weights  of people that use the elevator are distribuited with mean 70kg and standard deviation 8kg. Which is the probability that a group of 10 people exceed the maximum load ? Attempt: I know that I should have something like this $P(X>750)=1-P(X\le 750)=..$ but I don't know how to define the random variable $X$. I also don't know what is the distribution. I was thinking on 'Let $X$ be the random variable that represent the weights of 10 people'. Am I correct? Could someone guide me please?,"['statistics', 'probability', 'probability-distributions']"
2748176,"Graphical difference between $f(x)=x^2$ and $g(x)=(x,x^2)$","Graphically speaking what is the difference between: $f:\mathbb{R}\rightarrow\mathbb{R}$ such that $f(x)=x^2$, and $g:\mathbb{R}\rightarrow\mathbb{R}^2$ such that $g(x)=(x,x^2)$? I know that $f$ just looks like a parabola $P=\{(x,y):y=x^2\}$ in $\mathbb{R}^2$ but doesn't the second also look like that since the function $g$ would just be returning to each point point $x$ on the $x$-axis, the point $(x,x^2)$ in $\mathbb{R}^2$. But it seems obviously wrong that they would be the same. I have read that for any function $f:\mathbb{R^n}\rightarrow\mathbb{R}$, the graph of $f$ is in $\mathbb{R}^{n+1}$ so I assume for $g$ the graph should actually be in 3-dimensions but why would we need the $z$-axis? Similarly wouldn't the graph $h:P\subseteq\mathbb{R}^2 \rightarrow \mathbb{R}$ such that $h(x,x^2)=x$ just be the same parabola as $f$ but to each point $(x,x^2)$ of the parabola it returns the value on the $x$-axis. Why would this need to be 3-dimensional. I think I'm getting myself mixed up between functions and curves and can't stop confusing myself! I would really appreciate some help.","['functions', 'graphing-functions']"
2748203,Flows on a manifold as a group action.,"A flow on a manifold $M$ is a one-parameter group of diffeomorphism $\psi_t: M \to M$. In particular, this induces a smooth group action on $M$, 
$$ \mathbb{R} \times M \to M $$ 
$$ (t,m) \mapsto \psi_t(m)$$
So that we have a group homomorphism $\phi: \mathbb{R} \to Diff(M)$. My question is the following: Given any diffeomorphism $g \in Diff(M)$, does there exist a flow (and thus a vector field) on $M$ such that $g$ is in the image of $\phi$?","['differential-geometry', 'differential-topology']"
2748243,Prove an alternating binomial sum with odd weights,"How can the following identity for positive integer $n$ be proved? It has been confirmed symbolically by Mathematica: $$ \sum_{i=1}^n (-1)^{1+i} (2n+1-2i) \binom{2n+1}{i} = 2n + 1 $$ Induction seems quite cumbersome as $n$ appears in three instances on the left hand side. Also the usual binomial sum identities have an upper limit equal to the upper number in the binomial coefficient, whereas here these are $n$ and $2n+1$ respectively. Background. This identity arose from a series expansion where the functions $U_k(\phi)$ recursively satisfy a differential equation depending on $U_{k-2}(\phi)$. After computing the first few by hand, I was able to see the pattern, and proceeded to prove it by induction. However for odd $k \ge 3$, this involved showing the identity $$
  \sum_{\substack{j=1 \\ \text{$j$ odd}}}^{k-2}
    (-1)^{(j-1)/2} \frac{2j}{(k-j)!!(k+j)!!}
  = (-1)^{(k+1)/2} \frac{2k}{(2k)!!}.
$$ After rearranging and expanding the double factorials in terms of single factorials, obtained me $$
  \sum_{\substack{j=1 \\ \text{$j$ odd}}}^{k-2}
    (-1)^{(j+k)/2} \frac{j}{k} \binom{k}{(k-j)/2} = 1.
$$ Putting $j = 2i-1$ and $k = 2n+1$ gives $$
  \sum_{i=1}^n (-1)^i (2i-1) \binom{2n+1}{n+1-i} = (-1)^n (2n+1),
$$ and writing the sum backwards (i.e. replacing $i$ by $n+1-i$) yields the above.","['combinatorics', 'summation', 'binomial-coefficients']"
2748289,Can a function have a derivative where it has no value?,"Consider the following function: $$f(x) = x^2 \mid x \in \mathbb{R}, \ x \ne 0$$ The derivative at $x=0$ seems to want to be zero, in the same way that $\lim \limits_{x \to 0} f(x) = 0$ However, when I look at the definition of the derivative, this doesn't seem to work:
$$f'(x) =  \lim \limits_{\Delta x \to 0} \frac{f(x+\Delta x )-f(x)}{\Delta x}.$$ The function isn't defined at $f(x)$, so $f'(x)$ is also undefined. Would it make any sense to replace the $f(x)$ in the definition with $\lim \limits_{x \to 0} f(x) = 0$? Then, I suppose we'd have $\lim \limits_{x \to 0} f'(x) = 0$? Would it be permissible? Would there be any point?","['real-analysis', 'calculus']"
2748321,"Solving $x^2+y^2=9$, $\arctan\frac{y+2}{x+2} + \arctan\frac{y-2}{x+4} =2\arctan\frac{y}{x}$ without graphing?","The system of equations: $$\begin{align}
x^2 + y^2 &= 9 \\[6pt]
\operatorname{arctan}\frac{y+2}{x+2} + \operatorname{arctan}\frac{y-2}{x+4} &=2\,\operatorname{arctan} \frac{y}{x}
\end{align}$$ I tried to interpret the second equation by setting $x$ and $y$ as the legs of a right triangle, but I'm still unable to solve this system of of equations geometrically. Any tips?","['algebra-precalculus', 'trigonometry', 'systems-of-equations']"
2748339,Find all solutions to $f(x+f(x))=2x$,"Question: Find all solutions to $f(x+f(x))=2x$ Attempt: So $f(x)=x$ is pretty trivial, but by some trial and error I've also found $f(x)=-2x$. Are these the only solutions? If so, how could I go about proving that?","['functions', 'functional-equations']"
2748408,"When variance is finite, is expectation value also finite?","Let expectation value of $X$ be denoted as $E(X)$. Now we define the variance $V(X)$ as below. $V(X) \equiv E(X^2) - E(X)^2$ Now, if $V(X) < \infty$, is $E(X)$ also finite? My textbook says so but I don't understand the reason. Jensen's inequality states, for a convex function $h(x)$, $E(h(X)) \geq h(E(X))$ when $E(X)$ and $E(h(X))$ is both finite . For example, $h(x) = x^2$ is a convex function, so we can say $E(X^2) \geq E(X)^2$ but we can use this inequality only when $E(X)$ is finite. So, though Jensen's inequality may be a hint, I don't understand how to use this theorem. Could anyone give me a hint? Note:
I've already read Does finite variance imply on a finite mean? , but didn't think the answers were correct because they used Jensen's inequality though whether or not the mean was finite was unknown.","['statistics', 'probability']"
2748445,Show that $\sum_{k=0}^n \binom{n}{k}\Gamma(k+\frac 1 2)\Gamma(n-k+\frac 12) = \pi n!$,"Could someone please provide a detailed derivation of the following result?
$$\sum_{k=0}^n \binom{n}{k}\Gamma(k+\frac 1 2)\Gamma(n-k+\frac 12) = \pi n!$$
Also, is it possible to generalize the result for the following sum, given a generic integer $m$?
$$\sum_{k=0}^n \binom{n}{k}\Gamma(k+\frac 1 2)\Gamma(n-k+m+\frac 12).$$ Thanks in advance for your help. Graziano","['combinatorics', 'gamma-function', 'discrete-mathematics']"
2748451,How to find the inverse operator?,"Let $A: C([0,1])\to C([0,1])$ be a linear operator defined with:
$A(x(t)) = x(t) + \int_0^t x(s)\,ds$. It is actually easy to see that $A$ injective is, but it a bit of problem to show that it's bijective. Though, the main puzzle is: how to find the inverse operator? I myself tried but didn't far away of the expression $$
A^{-1} (x(t)) = A^{-1} \int_0^t x(s)\,ds - x(t)
$$ Thanks in forward!","['functional-analysis', 'linear-algebra', 'operator-theory']"
2748455,9-10th grade olympiad problem,"So first things first, I apologize for my bad English in advance. In one math olympiad (for 9-10th grade) there was a problem: There is given a rectangle $ ABCD $ such that $AB=1$ and $BC=2$. There is a point $P$ on diagonal $BD$ and a point $Q$ on $BC$. Find the lowest possible value of $CP+PQ$. So what I tried to do was to  prove that only if PQ $\bot$ BC we get the least possible value of PQ. Therefore, we get right-angled $\bigtriangleup CPQ$, where $\angle CQP=90°$. By using Pythagorean theorem, we get that $CP+PQ=\sqrt{CQ^2+PQ^2}+PQ$. I tried to find out if there is any dependence on CQ and PQ. Apparently, there is, such that $PQ=\frac{2-CQ}{2}$. I tried to write that in $\sqrt{CQ^2+PQ^2}+PQ$ and what I got was $\sqrt{1,25CQ^2-CQ+1}+1-\frac{CQ}{2}$. What I did next was one of the dumbest decisions I could have possibly made there. Since I didn't know how to calculate the minimum value of this expression of $CP+PQ$, I tried to make $\sqrt{1,25CQ^2-CQ+1}=1$, which was pretty logical (so we would get a rational answer), but absolutely not proved. So from this equation I got that $CQ=\frac{4}{5}$ and so $CP+PQ=\sqrt{1,25CQ^2-CQ+1}+1-\frac{CQ}{2}=1,6$ (by the way, $1,6$ IS the correct answer). So what I wanted to ask you was, is there any smart way to find the minimum value of $\sqrt{1,25CQ^2-CQ+1}+1-\frac{CQ}{2}$ (this is basically all I needed to get full 7 points for this problem).","['contest-math', 'geometry']"
2748526,"Prove $f'(x) = 2 f(x)$ if $f(x+y) = f(x) f(y)$, $f(x) \ne 0$ and $f'(0) = 2$. [duplicate]","This question already has answers here : Differentiable function, not constant, $f(x+y)=f(x)f(y)$, $f'(0)=2$ (2 answers) Closed 1 year ago . I'll state the question from my textbook below: A function $f: \mathbb{R} \to \mathbb{R}$ satisfies the equation $f(x+y) = f(x) f(y)$ for all $x,y \in \mathbb{R}, f(x) \ne 0$. Suppose that the function is differentiable at $x = 0$ and $f'(0) = 2$. Prove that $f'(x) = 2f(x)$. Firstly, I don't understand the first sentence completely. Does it mean that this equation holds true whenever $f(x) \ne 0$ or does it mean to say that $f(x) \ne 0, \forall x \in \mathbb{R}$. If it's the latter then $f(y) \ne 0$ too, right? And then I proceeded in many different ways to find $f'(x)$. I tried replacing $y$ by $0$ in the given equation and then differentiated it, first differentiated the equation and then replaced $y$ by $0$ and tried a few other things. None of these got me anywhere. Here's something I proved while trying to solve the question: Putting $x,y = 0$ in the given equation we have: $f(0) = f(0) f(0) \implies f(0)[f(0) - 1] = 0$ Since $f(x) \ne 0, \forall x \in \mathbb{R}$ (I'm not really sure if this is what the question meant, let's say it did), $f(0) - 1 =0 \implies f(0) = 1$ I don't know if this is even useful but it seems to be so, since we also have been given $f'(0) = 2$. Please help me prove the required equation. Any help would be appreciated.","['derivatives', 'calculus']"
2748530,"Is it true that $\int_a^{a+T}f(x)\,dx \,=\, \int_0^Tf(x)\,dx $ for function $f$ with period $T$?","I was wondering if the following property holds true for the definite integrals of periodic functions: Consider a function $f(x)$ with period $T$, ie; $$f (x + T) = f (x) $$ If $a$ is a real number in the domain of the function, then $$\int_a^{a+T}f(x)\,dx \,=\, \int_0^Tf(x)\,dx $$ Is this true? It seems intuitive, especially for functions like $\sin(x)$, $\cos(x)$ or $\{x\}$, but I was unable to prove it. Any kind of hint/help is appreciated.","['periodic-functions', 'integration', 'definite-integrals', 'calculus']"
