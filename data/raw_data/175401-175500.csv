question_id,title,body,tags
3138778,"Relatively Open Subset, Proof","The exercise is: Let $ A \equiv [0, 1). $ Prove that $ B \subset A $ is relatively open in A only if it is open in $ \mathbb{R} $ or it contains $0$ . Context: We're talking metric spaces with a distance $ d$ . I wanted to ask if my proof is watertight : Let $ A \equiv [0, 1) $ and $ B \subset A.$ WTS if $B$ is relatively open in $A$ then $0 \in B$ or $B$ open in $\mathbb{R}$ . Assume $ B \subset A $ is relatively open in $A$ . Then $ \forall x \in B , \ \exists \varepsilon>0$ such that $\{ y \in A | d(x,y)<\varepsilon \} \subset B.$ Assume $0 \not\in B$ , so $B \subset \text{int}(A) $ where $\text{int}(A) \equiv \{ z \in A |\exists \varepsilon > 0, B_{\varepsilon}(z) \subset A \}. $ Since $\forall x \in B, \exists \varepsilon>0$ such that $\{ y \in A | d(x,y)< \varepsilon \} \subset B\subset \text{int}(A)$ and $\text{int}(A)$ is an open set in $\mathbb{R}$ , it is the case that $\forall x \in B, \ \exists \varepsilon > 0$ such that $\{ y \in \mathbb{R} | d(x,y) < \varepsilon  \} \subset B.$ Therefore, $B$ is open in $\mathbb{R}$ . Thanks in advance.","['proof-verification', 'proof-writing', 'metric-spaces', 'elementary-set-theory', 'general-topology']"
3138779,Special elements in the $C^*$ algebra $A \otimes \mathcal{K}$.,"Context: Let $A$ be an ungraded (not necessarily unital) $C^*$ algebra. $\mathcal{K}$ space of compact bounded operators  on an infinite  separable graded Hilbert space $H=H_0 \oplus H_1$ . 
  Consider the space $$ A \otimes \mathcal{K} $$ Let us suppose there is a unique norm. Edit: I replaced a large part of text which can be seen in history. For streamlining the post. Claim 1' If we begin with a graded homomoprhism, $\mathcal{S} \rightarrow A \otimes \mathcal{K}$ , then the unitary $u$ we obtain this way (via the Cayley transform) has the property that $\alpha(u)=u^*$ . Claim 2: For any unital graded $C^*$ algebra $B$ containing $A \otimes \mathcal{K}$ , consider the grading element, $$
\epsilon = 
\begin{pmatrix}
 1 & 0 \\ 
0 & -1 
\end{pmatrix}
$$ which grades $\mathcal{K}$ . Any skew unitary $u$ is equal to $$p_\epsilon = \begin{pmatrix}
1 & 0 \\ 
0 & 0
\end{pmatrix}
$$ modulo $A \otimes \mathcal{K}$ , i.e. $p_\phi-p_\epsilon \in A \otimes \mathcal{K}$ . May someone elaborate the details? These  are from page 43, proof of Prop 3.17 , Higson's notes. Questions regarding Aweygan's reply So $p_\phi - p_\epsilon \in A \otimes \mathcal{K}$ , impies $[p_\phi]-[p_\epsilon]$ in fact may be regarded as an element $$K_0(A) = \ker [ K_0(A_+) \rightarrow K_0(\Bbb C) ] $$ Then how do we know $[p_\phi]-[p_\epsilon] = [p']-[q']$ the original element we were given? But then judging from the computations given by Aweygan, it seems that we have to prove, we let $u(0)=a$ . $$
\begin{pmatrix}
1+p'a/2  & 0 \\ 
0 & -q'a/2 
\end{pmatrix}
-
\begin{pmatrix}
1 & 0 \\ 
0 & 0 
\end{pmatrix} 
= 
\begin{pmatrix}
p' & 0 \\ 
0 & 0 
\end{pmatrix} 
-
\begin{pmatrix}
q' & 0 \\
0 & 0 
\end{pmatrix} 
$$ are equivalent in $G(V(A_+))$ the group completion of the commutative monoid of projections over $A_+$ . More: So if $j:S^1 \hookrightarrow \Bbb C$ is inclusion, its decomposition $j=u+1$ , where $u \in C_0(\Bbb R)$ , can be computed $(j-1) \circ c$ , where $c: \Bbb R \rightarrow S^1 $ is  Cayley tramsform.  This gives $u(0)=-2$ , - which I now substitute for $a$ . It is still unclear if these represents the same $k$ theory element (which I have made a separate post).","['operator-algebras', 'k-theory', 'operator-theory', 'abstract-algebra', 'functional-analysis']"
3138786,Show that $19^{31}>13^{33}$,How can i prove that $19^{31}>13^{33}$ ? What I tried $$\bigg(\frac{19}{13}\bigg)^2=\frac{361}{169}>2>1$$ then $19^{2}>13^{2}$ and $\displaystyle 19^{30}>13^{30}$ How do I show it. Help me please.,"['algebra-precalculus', 'number-comparison', 'exponential-function']"
3138791,Non-orthogonal invariant subspaces,"Let $\Gamma\subset\mathrm O(\Bbb R^n)$ be a finite group of orthogonal matrices. Let $U_1,U_2\subseteq\Bbb R^n$ be two irreducible invariant subspaces w.r.t. $\Gamma$ with $U_1\cap U_2=\{0\}$ , which are not orthogonal to each other, i.e. there are $u_i\in U_i$ with $\langle u_1,u_2\rangle \not=0$ . I was sceptic about the existence of such, but you can find examples here in a previous question of mine. Thinking a bit about such subspaces, I came to the following question: Question: Is it true, that: $\dim U_1=\dim U_2=:d$ . Every other $d$ -dimensional subspace $U\subset U_1\oplus U_2$ with $U\cap U_i=\{0\}$ is an irreducible invariant subspace as well. There are two orthogonal $d$ -dimensional irreducible invariant subspaces $\bar U_1,\bar U_2\subset U_1\oplus U_2$ . Update The second statement is not correct, but should be substituted by a different one. One version was given in the answer of Joppy . I can also think about something like this: every $u\in U_1\oplus U_2\setminus\{0\}$ is contained in exactly one $d$ -dimensional irreducible invariant subspace $U\subset U_1\oplus U_2$ .","['representation-theory', 'matrices', 'invariant-subspace', 'linear-algebra', 'group-theory']"
3138831,Problem with equivalent definition of a integrable $G$-structure,"I'm reading Kobayashi's book Transformation Groups in Differential Geometry and I don't understand a thing at page 2. It this proposition: My problem is that I don't understand the converse of this proposition. Is not clear how he is doing that linear change of coordinate, nothing is clear or formal and I'm also new to the subject. Can some one fill in some details for me please? Or maybe I should check another book on $G$ - structures. Can some one point me to a good book on this subject? EDIT: this is the definition of the integrability that is used here.","['principal-bundles', 'fiber-bundles', 'tensor-products', 'differential-geometry']"
3138847,Prove that $x^{y^x} > y^{x^y}$ for $x > y > 1$,"Prove that $x^{y^x} > y^{x^y}$ for $x > y > 1$ . So I've tried this so far: $x^{y^x} > y^{x^y}$ $e^{(y^x)\ln x} > e^{(x^y)\ln y}$ $(y^x)\ln x > (x^y)\ln y$ $e^{\ln({(y^x)\ln x)}} > e^{\ln({(x^y)\ln y})}$ $x\ln(y) + \ln(\ln x) > y\ln x + \ln(\ln y)$ And well, I got stuck there. Is there something I'm doing wrong or should I try a different approach? Edit: $x\ln(y) -  y\ln(x) > \ln(\ln y)-\ln(\ln x) $ $x\ln(y) -  y\ln(x) > \ln{\left(\frac{\ln y}{\ln x}\right)}$ $e^{x\ln y -  y\ln x} > \frac{\ln y}{\ln x}$ Since $\frac{\ln y}{\ln x} < 1$ , it would suffice to show that $\frac{e^{x\ln(y)}}{e^{y\ln(x)}} > 1$ . So: $x\ln y> y\ln x$ $\frac{x}{y} > \frac{\ln x}{\ln y}$ How do I prove the last bit though?","['exponentiation', 'real-analysis']"
3138893,Understanding better the topology of the circle and the representation of periodic function using function defined on the circle.,"I'm a bit in truble with the circle. Question 1 I want to use $\mathcal C=\{e^{it}\mid t\in [0,2\pi]\}$ . Since it's the image of $[0,2\pi]$ under the coninuous function $t\mapsto e^{it}$ , the set $\mathcal C$ is compact. But is it a metric space ? I know that I can put the euclienne metric, but I would like to use the metric $$d(e^{it},e^{is})=|t-s|.$$ I proved it was a metric but $t,s\in [0,2\pi)$ only because otherwise, we have $d(e^0,e^{2i\pi})=|2\pi|>0$ . So, to use this metric, I have to consider $\mathcal C=\{e^{it}\mid t\in[0,2\pi)\}$ , no ? And with this definition, it's not compact anymore, right ? Question 2 Now if I want to stud periodic function, I know that any $2\pi-$ periodic function can be seen as a function on the unit circle, i.e. $f:\mathbb R\to \mathbb R$ is a $2\pi-$ periodic function $\iff$ there is a function $F:\mathcal C\to \mathbb R$ s.t. $f(\theta )=F(e^{i\theta })$ . So, for example, $f$ is continuous $\iff$ $F$ is continuous or $f$ is derivable $\iff$ $F$ is derivable. But which topology I have to use on $\mathcal C$ to talk about continuity ? And for the derivability, I don't really understand how can such a function $F$ be derivable on the Circle... What would be the sense of $F'$ ?","['complex-analysis', 'general-topology', 'real-analysis']"
3138894,Checking the proof for the following prime question.,"Is my proof fully correct? I cannot see if I am missing anything critical so far. Prove that for all natural numbers $p>2$ , $p$ is prime if and only if for all natural numbers $a$ and $b$ , if $p|ab$ then $p|a$ or $p|b$ . Solution:
Since $p|ab$ there exists an integer $c$ such that $ab = pc.$ Since $p$ is prime, therefore, either $p|a$ or $(p,a)=1.$ If $p|a,$ we are done. If $(p,a)=1$ then there exist an integer $s$ and $t$ such that $ps + at=1$ Now multiply with $b$ on both sides $$
psb +(ab)t = b
$$ Put $ab=pc$ $\longrightarrow$ $p(sb+tc)=b$ Therefore, $p|b.$","['number-theory', 'elementary-number-theory', 'proof-verification', 'real-analysis', 'discrete-mathematics']"
3138896,Does replacing $\ge$ by $>$ lead to a strictly inequality too? (integral inequality) [duplicate],"This question already has answers here : Is the Riemann integral of a strictly positive function positive? (3 answers) Closed 5 years ago . I know that if $f:[a,b] \to \mathbb{R}$ is an integrable function such that $f(x) \ge 0,~\forall~x \in [a,b],$ then $$\int\limits_a^b f(x) \mathrm{d}x \ge 0.$$ What happens if we replace the condition $f(x) \ge 0$ by the condition $f(x)>0$ ? Will the last inequality be also strict? I tried to use Riemann sums but taking the limit turns $>$ into $\ge$ .","['integration', 'calculus', 'definite-integrals', 'inequality']"
3138906,Find $ \lim\limits_{x\to \infty} \left(x-x^2 \ln (1+\frac{1}{x})\right) $ with Taylor,"I have to calculate some limits and try to solve them in use of taylor. $$ 
\lim\limits_{x\to \infty} \left(x-x^2 \ln (1+\frac{1}{x})\right) 
$$ In taylor pattern I have $x_0$ to put, but there $x_0$ is $\infty$ so I want to replace it with something other $$ 
y = \frac{1}{x} \\
\lim_{y\to 0^+} \left(\frac{1}{y}-\frac{1}{y^2} \ln (1+y)\right) $$ Let $$ f(y) = \frac{1}{y}-\frac{1}{y^2} \ln (1+y) $$ $$f'(y) = -\frac{1}{y^2} + \left(-\frac{2}{y^3}\ln (1+y) - \frac{y^2}{1+y}\right) $$ but $f'(0)$ does not exists because I have $0$ in denominator.","['limits', 'taylor-expansion', 'real-analysis']"
3138907,A coding theory/probability puzzle,"I thought of the following problem and I am stuck in solving it. Suppose there is a deck of 4 cards with 2 red and 2 blue. I pick 2 cards at random and choose 1 and show the other to my friend. With what probability can my friend find the color of my card if we have agreed on a good strategy in advance? If my friend always guesses the color red, we only fail in this game if I get 2 blue cards. That happens with probability 1/4 and it is the best I can achieve in this case. However, if the cards are numbered we can do even better, i.e. there is red card 1 and red card 2, blue card 1 and blue card 2. In this case, we can agree that my friend chooses the color of the card I gave him if the number is 1 and flips the color if it is 2. You can check that the only way we can fail is if I get both the red and the blue card of 1. (If I get both cards of the same color I show him the number 1 card. If I get two cards of different colors I show him the number 2 card and we win.) Since the probability of drawing two cards with the number 1 is 1/6, having numbers on the cards clearly helps. My question is what happens when there are $N$ cards of $N$ colors ( $N^2$ in total) and I draw $N$ cards, choose 1 and reveal $N-1$ cards to my friend ( in a random order , i.e. the order cannot encode information). What is the strategy that maximizes our probability of winning? How does this differ if cards are numbered or if they are not? I am interested both in optimal strategies for small $N$ , or with asymptotic bounds for large $N$ in both the numbered and unnumbered cases. Could it be that the probability in the numbered case goes to 1 and the unnumbered case is small? This would be very unintuitive!","['coding-theory', 'puzzle', 'probability']"
3138945,Name for pair of functions,"If $f \circ g \circ f = f$ and $g \circ f \circ g = g$ , $f$ and $g$ are functions, is there a name for $(f, g)$ ?",['functions']
3138946,A decreasing transfinite sequence of subsets of a countable set.,"Let $X$ be a countable set and $(S_\alpha)_{\alpha< \rho}$ is a decreasing transfinite sequence of subsets of $X$ in the sense that $$
S_\alpha \supset S_\beta
$$ whenever $\alpha<\beta$ . Here $\rho$ is some fixed ordinal. Suppose that $(S_\alpha)_{\alpha< \rho}$ is strictly decreasing , i.e. $S_\alpha \ne S_\beta$ whenever $\alpha<\beta$ , how do we show that $\rho$ must be a countable ordinal? I am sorry if this question is elementary, I have very little training in axiomatic set theory. I think I could prove by contradiction but some crucial steps are missing and I don't know how to make it rigorous.","['elementary-set-theory', 'borel-sets', 'ordinals']"
3138978,Using Banach-Alaoglu theorem on $L^1$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question Let $C$ be a bounded closed set in $L^1(0,1)$ . Let $h_n$ be a sequence in $C$ . Prove or disprove that for every $f\in L^\infty(0,1)$ there is a subsequence $h_{n_k}$ such that $$\int_0^t f(s) h_{n_k}(s) ds\to \int_0^t f(s) h(s) ds$$ for every $t\in [0,1]$ and some $h\in C$ .","['banach-spaces', 'real-analysis', 'lp-spaces', 'functional-analysis', 'compactness']"
3138994,Evaluate the limit without using Stirling Formula,"I want to prove that $$\lim_{n \to \infty} p \frac{n^{(p+1)/2} (n!)^p p^{np+1}}{(np+p)!}
= p^{1/2} (2\pi)^{(p-1)/2}$$ So I am working the book The Gamma Function by Emile Artin . In the book this limit is involved for proving the Gauss multiplication formula of the Gamma Function. The book uses the Stirling Formula for $n!$ to show the limit is that. However I was wondering if there is another way of prooving this limit that doesn't use Stirling Formula. Does anyone sees any way of approaching this?? Edit The limit making some manipulations is the same as $$\lim_{n \to \infty} p \frac{(n!)^p p^{np}}{(np)!n^{(p-1)/2}}$$ maybe this helps someone attempmting this task","['gamma-function', 'limits', 'real-analysis']"
3139082,How many numbers of the form $m^2 + \sqrt{2} n^2$ are between $1 \times 10^6$ and $2 \times 10^6$?,"I have a purely computational question today.  How many numbers of the form $m^2 + \sqrt{2} n^2$ with $m,n \in \mathbb{Z}$ are between $1 \times 10^6$ and $2 \times 10^6$ ? $$ \# \big\{ (m,n):  1 \times 10^6 < m^2 + \sqrt{2} \, n^2 < 2 \times 10^6 \big\} =\;  ? $$ The asymptotic answer for this sequence of numbers can be found using Weyl's law , for exmaple that: $$ \# \big\{ (m,n) : 0 < m^2 + \sqrt{2} \, n^2 < X \big\} \sim \frac{\pi}{4 \sqrt{2}} \, X$$ This result is saing that numbers of the form $m^2 + \sqrt{2} \, n^2$ are roughtly linearly distributed on the real line $\mathbb{R}$ . The Weyl's law estimate gives $\frac{\pi}{4\sqrt{2}} \times 10^6 \approx 555,630 + 0.36726\dots$ Perhaps with a computer it's possible to obtain an exact answer?  E.g. using Python or sage .","['number-theory', 'spectral-theory', 'eigenvalues-eigenvectors']"
3139114,"Prove that if $f : M → M$ preserves a probability $\mu$, then for any $k \geq 2 $ $f^k$ preserves $\mu$","Prove that if $f : M → M$ preserves a probability $\mu$ , then for any $k \geq 2$ , $f^k$ also
preserves $\mu$ . Is the converse true? Attempt: 
The first part did induction in $k$ . The case $k = 1$ holds because $f$ preserves probability. assuming that the result holds for $k$ , for $k + 1$ we have: $\mu(f^{-k-1}(A))=\mu(f^{-k}(f^{-1}(A)))=\mu(f^{-1}(A))=\mu(A)$ . 
Is this part correct? Apparently for the converse, use only that $\mu(f^{-1}(A))=\mu(f^{-2}(f^{-1}(A)))=\mu(f^{-3}(A))=\mu(A)$ .","['measure-theory', 'ergodic-theory']"
3139129,"Is there a way to classify all finite groups $G$, such that $\pi(G) := \Pi_{H \triangleleft G} |H| = |G|^2$?","Is there a way to classify all finite groups $G$ , such that $\pi(G) := \Pi_{H \triangleleft G} |H| = |G|^2$ ? For abelian groups this problem is quite simple. All such abelian groups are exactly $C_{p^3}$ and $C_{pq}$ for any primes $p$ and $q$ : Suppose $P$ and $Q$ are abelian groups of coprime order. Then if $P \times Q$ satisfies that condition, then $\pi(P)|Q|^2 \leq \pi(P \times Q) = |P \times Q|^2 = |P|^2|Q|^2$ and thus $\pi(P) \leq |P|^2$ . So, to solve the problem we need to obtain the classification of all finite abelian $P$ -groups, satisfying the condition $\pi(P) \leq |P|^2$ . Suppose, a finite abelian $p$ -group $P$ is a direct product of $n$ cyclic groups. Then it contains a subgroup isomorphic to $C_p^n$ . So $\pi(P) \geq \pi(C_p^n) = \Pi_{k = 0}^n (p^k)^{C_n^k} = p^{\Sigma_{k = 0}^n kC_n^k} = p^{n2^{n-1}} > |P|^2$ for any $n > 1$ . So $P$ has to be cyclic. For cyclic $p$ -groups $P$ we can see $\pi({C_{p^n}}) = p^{\frac{n(n+1)}{2}}$ . So, the group satisfies our condition iff $\frac{n(n+1)}{2} \leq 2n$ which is exactly, when $n \leq 3$ . Now one can also see that $\pi(C_{p^2q}) = p^6q^3 \geq |\pi(C_{p^2q})|^2$ and $\pi(C_{pqr}) = (pqr)^3 \geq |\pi(C_{pqr})|^2$ for any prime $p$ , $q$ and $r$ . So, only possible examples are of one of the following forms: $C_{p^3}$ , $C_{p^2}$ , $C_{p}$ , $E$ , $C_{pq}$ . And one can via manual checking see, that only $C_{p^3}$ and $C_{pq}$ do actually satisfy that condition. However, I do not know, what to do there in non-abelian case.","['finite-groups', 'normal-subgroups', 'abstract-algebra', 'products', 'group-theory']"
3139159,"In a cyclic $\square ABCD$, $BC, CD$ and $DA$ are three tangents of such a circle that its center is on the side $AB$. Proving that $AD + BC = AB$","In a cyclic quadrilateral $ABCD$ , $BC, CD$ and $DA$ are three tangents of a circle. The center of the circle is located on the side $AB$ . Prove that $$AD + BC = AB$$ Attempt : First, I thought it to be very easy. So, I let the side $AB$ be the diameter of the large circle by which the quadrilateral $ABCD$ is circumscribed. So, I made another quadrilateral congruent to $ABCD$ to the opposite side. So, I got a regular hexagon, the one side of which is denoted as $a$ and the radius of large circle = $R$ and the radius of small circle = $r$ . We know that area of regular polygon = $\frac{na^2}{4} \cot \frac{180}{n}$ . $ABCD$ is the semi hexagon and so the area of $ABCD =\frac{1}{2}\cdot \frac{6a^2}{4} \cot (\frac{180}{6})^\circ = \frac{3a^2}{4} \cot 30^\circ = \frac{3a^2}{4}\cdot \sqrt3 = \frac {3\sqrt 3a^2}{4}........(i)$ Again $ABCD$ is a trapezium. So, $[ABCD] = \frac{1}{2}(2R + a)\cdot r..........(ii)$ Now from right angled triangle $DJA$ : $\frac{r}{a} = \sin 60^\circ$ so $r = \frac{\sqrt 3a}{2}$ So, from equation $(ii)$ again, we get $[ABCD] = \frac{1}{2} (2R + a)\cdot\frac {\sqrt 3a}{2} = \frac{\sqrt 3a}{4} (2R + a)........(iii)$ Now from equation $(i)$ and $(iii)$ we get $\frac{\sqrt 3a}{4} (2R + a) = \frac{3 \sqrt3 a^2}{4}$ and thus $(2R + a) = 3a$ so $2R = 2a$ . Hence, $R = a$ . And thus I proved that $2R = a + a \implies AD + BC = AB$ . But that wasn't a satisfactory solution for me in the case of letting $AB$ be the diameter of large circle and I reasonably made it specific. But I am very unaware of the fact that how could I solve that proof for any position of $AB$ such that other three sides of the quadrilateral $ABCD$ are tangents to the small circle? Thanks in advance. Source : IMO $1985$","['contest-math', 'euclidean-geometry', 'tangent-line', 'geometry']"
3139209,Validity of geometric series formula for $r=0$,"I can convince myself of the geometric series formula $$\sum_{n=0}^{\infty} r^n = \frac{1}{1-r}$$ for $0<|r|<1$ , but not for $|r|<1$ because I don't believe the formula for $r=0$ . If $r=0$ , we have $$\sum_{n=0}^{\infty} r^n = 0^0 + 0^1 + 0^2 + \ldots$$ It is not clear to me what this sum equals, much less that it equals $\frac{1}{1-0}=1$ . However, every source that I've consulted says that the result holds for $-1<r<1$ . Can anyone justify the $r=0$ case? Must we simiply accept $0^0=1$ in this context?","['calculus', 'sequences-and-series']"
3139259,A question about weak law for triangular arrays,"This is from Durrett(2.2.8). Let $p_k = \frac{1}{2^k k(k+1)}$ , $k=1,2,..$ and $p_0 = 1-\sum_k p_k$ . $X_i$ are $iid$ with $P(X_n = -1) = p_0$ and $$P(X_n = 2^k - 1) = p_k \text{  for  }  k\geq 1$$ Note $EX_n = 0$ and let $S_n = \sum_{k=1}^{n}X_k$ Use theorem $2.2.6$ with $b_n = 2^{m(n)}$ where $m(n)=min\{m|2^{-m}m^{-3/2}\leq n^{-1}\}$ to conclude that $S_n/(n/\log_2 n)\rightarrow -1$ . Theorem 2.2.6 : If $b_n> 0$ with $b_n\rightarrow \infty$ and $\tilde{X}_{n,k}=X_{n,k}.1_{|X_{n,k}\leq b_n|}$ and with $n\rightarrow \infty$ if (i) $\sum_{k=1}^{n}P(|X_{n,k}|>b_n)\rightarrow 0$ (ii) $b_n^{-2}\sum_{k=1}^{n} E\tilde{X}_{n,k}^2 \rightarrow 0$ the above hold, then $(S_n - E\tilde{X}_{n,k})/b_n \xrightarrow{p} 0$ I've proved (i), for (ii): $$b_n^{-2}\sum_{k=1}^{n} E\tilde{X}_{n,k}^2 = (2^{-m(n)})^2.n.E\tilde{X}_{1}^{2} = n.4^{-m(n)}.E|X_1|^2.1_{|X_1|\leq 2^{m(n)}} =$$ $$n.4^{-m(n)}.[p_0 + \sum_{k=1}^{m(n)}\frac{(2^{k}-1)^2}{2^k k(k+1)}] < n.4^{-m(n)}.[p_0 + \sum_{k=1}^{m(n)}\frac{(2^{k})^2}{2^k k(k+1)}] =$$ $$n.4^{-m(n)}.[p_0 + \sum_{k=1}^{m(n)}\frac{2^k}{k(k+1)}]\leq n.4^{-m(n)}.2^{m(n)}.[p_0.2^{-m(n)} + \int_{k=1}^{m(n)}\frac{dx}{x^2}] =$$ $$\text{Consider } n.2^{-m(n)}.\int_{1}^{m(n)}\frac{dx}{x^2} = n.2^{-m(n)}.[1-\frac{1}{m(n)}] = n.2^{-m(n)} - n.2^{-m(n)}.m(n)^{-1}\text{ -(*)}$$ $n.2^{-m(n)} = n.m(n)^{3/2}.m(n)^{-3/2}.2^{-m(n)}\leq m(n)^{3/2}$ and thus (*) $\leq m(n)^{3/2}-m(n)^{1/2}$ and since $m(n)\rightarrow \infty$ , I do not have proper upper bound that $\rightarrow 0$ . A hint is appreciated to find an upper bound that $\rightarrow 0$ . Thanks.","['statistics', 'probability-theory', 'real-analysis']"
3139347,$\int\frac{dx}{x(x+1)(x+2)\cdot\space...\space\cdot(x+n)}$ [duplicate],"This question already has answers here : Partial fraction expansion of $\frac{1}{x(x+1)(x+2)\cdots(x+n)}$ (2 answers) Closed 5 years ago . I've been trying to solve explicitly the following indefinite integral: $$\int\frac{dx}{x(x+1)(x+2)\cdot\space...\space\cdot(x+n)}$$ I tried to perform partial fraction decomposition, and after substituting some natural n's, I figured the Binomial Theorem might help here, but I couldn't figure out how to use it. Thank you and have a good day/night!","['integration', 'indefinite-integrals', 'calculus', 'binomial-theorem']"
3139383,Generalized Stalk Functor,"Let $X$ be a locally ringed space. If $X$ has a generic point, then $\text{colimit}_{U \text{ dense in } X} \mathcal{O}_X (U)$ is the stalk of $X$ at $U$ . What is this in general? That is, if $X$ does not have a generic point, then what is this? Is this the product of the stalks of the irreducible components? Also, could I have a reference for this? Edit: maybe it would be fair to call it the ring of rational functions.",['algebraic-geometry']
3139442,Unique factorization of dihedral group,"My goal is to prove the following about the dihedral group $D_{2n}$ : Prove that every element in $D_{2n}$ has a unique factorization of the form $a^{i}b^{j}$ , where $0 \leq i < n$ and $j=0$ or $1.$ I know that the cyclic subgroup $\left \langle a \right \rangle$ has order $n.$ From this, I know that this has index $2.$ Thus $D_{2n}$ is the disjoint union $$\left \langle a \right \rangle \cup \left \langle a \right \rangle b.$$ After this, I am pretty stuck.  Am I headed in the right direction?  What would be the correct way to finish this proof? Thanks in advance!","['group-theory', 'abstract-algebra', 'dihedral-groups']"
3139447,Commutative subring of matrices iff trivial unit group,"Let $R$ be a ring and let $T := \left\{\begin{bmatrix}a & b \\ 0 & c\end{bmatrix} \in \text{Mat}_2(R) \mid a,b,c \in R\right\}$ . I have shown that $T$ is a subring of $M_2(R)$ which is noncommutative for $R ≠ \{0\}$ , and $$\begin{bmatrix}a & b \\ 0 & c\end{bmatrix} \in T^* \iff \{a,c\} \subseteq R^*.$$ Now it should also be true that $T^*$ is abelian if and only if $R^* = \{1\}$ . Now of course you can, assuming $T^*$ is abelian, take two arbitrary elements $\begin{bmatrix}a & b \\ 0 & c\end{bmatrix}, \begin{bmatrix}x & y \\ 0 & z\end{bmatrix} \in T^*$ and derive the necessary equalities $ax = xa, ay+bz = xb+yc$ and $cz = zc$ , but I don't see how that would imply that $R$ has a trivial unit group. Another attempt would be to assume that $R^* \setminus \{1\} ≠ \emptyset$ , let $u \in R^* \setminus \{1\}$ and consider some products like $$\begin{bmatrix}u & 1 \\ 0 & u\end{bmatrix}\begin{bmatrix}u & 0 \\ 0 & u\end{bmatrix}.$$ Then you'd see that $u^2 = 1$ , but not necessarily that $u = 1$ .
It seems there should be a smarter argument.","['matrices', 'ring-theory', 'abstract-algebra', 'linear-algebra']"
3139486,Why do we call complex numbers “numbers” but we don’t consider 2-vectors numbers?,We refer to complex numbers as numbers. However we refer to vectors as arrays of numbers. There doesn’t seem to be anything that makes one more numeric than the other. Is this just a quirk of history and naming or is there something more fundamental?,"['matrices', 'philosophy', 'complex-numbers', 'terminology']"
3139488,Rudin's Construction of Inductive Limit Topology: unnecessarily abstruse?,"In Rudin's Functional Analysis Book, one of the examples in the first chapter is used later in the chapter on distributions. But when he gets to defining the inductive limit topology on a certain space, it seems unnecessarily abstruse and confusing to me, (probably because I am missing something essential). I want to check that I understand the ideas, and know if there is a particular reason for Rudin's definition. Here is the way he sets it up in Chapter one: take an open set $\Omega\subseteq \mathbb R^n$ , a compact $K\subseteq \Omega$ and define $\mathcal D_K$ to be the collection of $C^{\infty}(\mathbb R^n)$ functions supported in $K$ . Then, let $\{K_n\}$ be an exhaustion of $\Omega$ , so that the norms $p_N(f) = \max \{D^{\alpha}f(x): x\in  K_N;\ |\alpha|<N\}$ , (where $\alpha $ of course is a multi-index) induce a topology on $C^{\infty}(\Omega)$ , and $\mathcal D_K$ is a closed subspace whenever $K\subset \Omega.$ Now, in the chapter on distributions, Rudin goes on to define $\mathcal D(\Omega)=\bigcup_{K\subset \Omega}\mathcal D_K$ and topologizes this by a collection of norms whose restriction to each $\mathcal D_K$ induces the same topology as that induced by the $p_N$ . But $\mathcal D(\Omega)$ is not complete in this topology, so we look for a finer one that works. I see this as: to control what happens at the boundary of $\Omega$ we'd like to add seminorms to the ones we already have, until we get a complete space. The foregoing seems to be just the right setup for defining the topology we want on $\mathcal D(\Omega)$ to be the inductive limit topology, (even if we don't use the name) because clearly the inclusions $\mathcal D_{K_n}\to \mathcal D_{K_{n+1}}$ are continuous, so if we define $\tau_{D(\Omega)}$ to be the finest topology that makes the inclusions $\mathcal D_N\to \mathcal D(\Omega)$ continuous, then the results obtained in the rest of the chapter follow (more intuitively and clearly?) from this definition. In fact, this definition implies that for $\textit{any}$ seminorm $p$ on $\mathcal D(\Omega)$ ,  we have that $p$ is continuous if and only if its restriction to $\mathcal D _K$ is continuous for each $K\subset \Omega.$ So we could also just have declared the desired topology to be that induced by the collection $\mathscr P$ of seminorms $p$ that satisfy: $p\in \mathscr P\Leftrightarrow p|_{\mathcal D_K}$ is continuous. In fact, using this, I was able to get all the proofs that Rudin obtained by his characterization of the topology: $a).\ $ Let $\beta$ be the collection of all convex balanced sets $W\subseteq \mathcal D(\Omega)$ such that $\mathcal D_K\cap W\in \tau_K$ for every compact $K\subset \Omega.$ $b).\ $ the desired topology is then the collection of unions of the sets $\phi + W;\ \phi\in \mathcal D(\Omega)$ . In the first place, given the setup, why go to this more abstract approach? Why not do it the way the setup seems to lead naturally? I think part $a).$ is a restatment of the above definition $p\in \mathscr P\Leftrightarrow p|_{\mathcal D_K}$ is continuous, in which case, all is well. In any case, wouldn't it just be cleaner to note that, as we already have topologies on the $\mathcal D_K$ , why not just use the above definition in the first place? That is, topologize $\mathcal D(\Omega)$ by taking all seminorms on $\mathcal D(\Omega)$ such that their restrictions to each $\mathcal D_K$ are continuous.","['general-topology', 'fourier-analysis', 'functional-analysis', 'distribution-theory']"
3139500,Prove that $\inf \left\{ \int_E f d\mu : \mu (E) \geq \alpha\right\} > 0$,"The next problem appears in the book ""Real analysis"" by  Thomson/Bruckner in the chapter of Integrable functions. My proof seems good to me but I'm not confident enough with my proofs in this subject.
Here, $(X, \sigma, \mu)$ is a measurable space. I use the following: Definition
Given a succession $(E_n)$ of measurable sets, $\limsup E_n = \{x \in X : x$ belongs to $E_j$ for infinitely many $j \}$ Theorem: if $(E_n)$ is a succession of measurable sets and $\mu (\cup E_n) < \infty$ then $\limsup \mu(E_n) \leq \mu(\limsup E_n)$ Problem: Suppose that $f \in L_1(X)$ , that $f(x)>0$ for all $x \in X$ , and that $0 < \alpha < \mu(X) < \infty $ . Prove that $$ \inf \left\{ \int_E f d\mu : \mu (E) \geq \alpha\right\} > 0. $$ My attempt: Suppose that $\inf \left\{ \int_E f d\mu : \mu (E) \geq \alpha\right\} = 0$ . Then, we can choose a succession $(E_n)_{n \geq 1}$ such that $\mu(E_n) \geq \alpha$ and $$ \int_{En} f < \frac{\alpha}{2^n}.$$ Then, $f|_{E_n} < \frac{1}{2^n} $ . For if $f|_{E_n} \geq \frac{1}{2^n} $ then we have $$ \frac{\alpha}{2^n} > \int_{E_n} f d \mu \geq \int_{E_n} \frac{d \mu}{2^n} = \frac{\mu(E_n)}{2^n} \geq \frac{\alpha}{2^n},$$ a contradiction. Now, if there exist $ x \in X$ such that $x \in \limsup E_n$ then $f(x)<\frac{\alpha}{2^j}$ , for infinitely many $j's$ . So we must have $f(x) = 0$ , contradicting that $f > 0$ . Therefore $\limsup E_n = \emptyset$ and $\mu (\limsup E_n)=0$ .
However $\limsup \mu(E_n) \geq \alpha$ because $\mu(E_n) \geq \alpha$ for every $n$ .  And because we are in a space of finite measure, we can aply the above theorem and obtain $$  0 < \alpha \leq \limsup \mu(E_n) \leq \mu (\limsup E_n) = 0. $$ So $\alpha = 0$ is our final contradiction.","['measure-theory', 'proof-verification', 'lebesgue-integral']"
3139536,Integrate $\int \frac{dx}{(x^2-1)^{\frac{3}{2}}}$ via trig substitution,"$x = a\sec\theta, dx = \sec\theta \tan\theta$ $\int \frac{dx}{(x^2-1)^{\frac{3}{2}}}$ = $ \int \frac{dx}{(\tan^2\theta)^{\frac{3}{2}}}$ = $ \int \frac{dx}{\tan^{\frac{7}{2}}\theta}$ = $\int \frac{\sec\theta \tan\theta}{\tan\theta ^{\frac{7}{2}}}$ = $\int \tan^{\frac{-5}{2}}\theta \sec\theta$ Here is where I get stuck...I tried converting $\tan\theta$ and $\sec\theta$ in terms of $\cos\theta$ and $\sin\theta$ , but that didn't seem to get me anywhere...What is my next move from here? Did I even start this problem correctly? I can't tell :( Update with more work after initial answers: $\int \frac{\cos\theta}{\sin^2\theta}$ $u = \sin\theta, du = \cos\theta d\theta$ I found $\sin^{-1}\theta = \frac{\sqrt{x^2-1}}{x}$ $= \int \frac{du}{u^2} = \frac{1}{ \frac{1}{3}u^3} = 
\frac{1}{3\sin^3\theta}
= 3 \bigg( \frac{x}{\sqrt{x^2-1}} \bigg)^3$","['integration', 'trigonometry', 'derivatives']"
3139538,How to find a point from where three vectors originate?,"Okay so first of all I tried to make the title to sound like I understand something about mathematics, correct me if I am wrong with it. Backstory / context: I bumped into this problem when me and my friend were talking one night in discord about where my friend should order a pizza from. He then sent me a screenshot of the choices he had, but it was only showing two pizza places with distances to them, as each pizza place has some max delivery radius set. Suddenly a light went on in my head and I told my friend that if I he had sent me a third pizza place in the screenshot, I could find out where he lives based on the locations of the pizza places and the distances shown. So then he sent me a picture of a third pizza place and I got to work. I have heard about triangulation before so I thought that it would be a good idea to read about how that works, but in the end I either did not understand the idea or the idea of triangulation is basically that I ""kind of"" know where I am, but I just don't know where that location is on the map, but since I had no idea about where this said friend lived, I came into conclusion that I don't have enough data for triangulation. So the next thing I did was what felt like the second obvious one to me - I drew a circle around each pizza place with the distances as the circle's radiuses, probably because that is how they find people in CIA-style TV-shows. Well that did basically nothing, now I just had a VERY vague area where he might live aka. where all three circles overlap I guess. So on I went to the third obvious thing, which was to draw a triangle through the pizza places. I then googled about finding a triangle centroid and got pretty convincing results. I figured that since the centroid point is inside all of the three circles I drew - this has to be where my friend lives. I then sent an image of my solution to my friend ready to receive applauds. Well my solution was completely wrong. Not even close. I understand that the distances to the pizza places were probably calculated via roads and not with straight lines, so that might give me some error, but the solution of mine was too far off to blame it on error. Unfortunately I like my and my friend's privacy, so I am not going to post an image of the original problem, but instead I spend some time in photoshop and created a fake scenario: Distances are not actually meters, but pixel values photoshop gave me Green dot is the answer, or where my fake friend lives. This point is actually unknown. The pizzas are locations of fake pizzerias. These are known. The pink lines are the distances to the pizzerias as given by the website The cyan and the red lines, as well as the red midpoint dots and the blue centroid dot are parts of my solution or what I have tried to do to find the green point So how can we find the green point (where my friend lives)? Can it even be found? In mathematical terms, like said in the title, I guess this is a question about finding an originating point for three vectors of which lengths and directions we know. (If someone finds a use for it, I can provide the .psd file of the map image)","['trigonometry', 'vectors']"
3139620,Proving convergence/divergence of this series? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question $$\sum_{k=0}^{\infty}\frac{(k!)}{(k+1)!+2^k}$$ Anyone know how to show that this series converges or diverges? I've tried multiple tests and nothing seems to be working. Any help would be amazing!","['convergence-divergence', 'sequences-and-series']"
3139642,All positive solutions of $\tan x=x$,"If $x_1,x_2,\cdots$ are all positive solutions of the equation $\tan x-x=0$ Find value of: $$S=\sum_{k=1}^{\infty}\cos^2(x_k)$$ My try: The first solution will be in the interval $\left(\frac{\pi}{2}, \frac{3\pi}{2}\right)$ in which $\tan x$ is monotonic. So the solution in that interval is given by $$x_1=\tan^{-1}(x_1)$$ So $$\cos(x_1)=\cos(\tan^{-1}(x_1))=\frac{1}{\sqrt{1+x_1^2}}$$ Hence $$S=\sum_{k=1}^{\infty}\frac{1}{1+x_k^2}$$ Any way to proceed here?","['algebra-precalculus', 'trigonometry', 'transcendental-equations']"
3139655,Evaluate $I=\int_{0}^{\infty}\frac{(x^2+x+1)dx}{(x^3+x+1)\sqrt{x}}$,"Evaluate $$I=\int_{0}^{\infty}\frac{(x^2+x+1)dx}{(x^3+x+1)\sqrt{x}}$$ My try: Letting $\sqrt{x}=t$ we get $$I=2\int_{0}^{\infty} \frac{t^4+t^2+1}{(t^6+t^2+1)}\,dt$$ Now $$t^4+t^2+1=(t^2+1)^2-(t^2+1)+1$$ $$t^6+t^2+1=(t^2+1)^3-2(t^2+1)^2+(t^2+1)+1$$ Any clue then?","['integration', 'calculus', 'definite-integrals', 'polynomials']"
3139662,$T=AU \iff T $ is a normal operator on Hilbert space,"This is Exercise 16.(c) from Conway's Functional Analysis book. Suppose $H$ is a Hilbert space and $T$ is a compact operator on $H$ . Assuming the result that $\exists A$ positive operator and $U$ a bounded operator such that $T=UA$ (NOTE: here $A= \sqrt {T^* T} $ and $U$ is the operator defined as in the construction of the polar decomposition i.e. $\|Uh\|=\|h\|$ when $h \perp \ker(T)$ and $Uh=0$ when $h \in\ker(T)$ i.e. $U(Ah)=Th$ when $h \perp \ker(A)=\bar{Ran(A)}$ and $Uh=0$ when $h\in\ker(A)$ ) , I have to prove : $T=AU \iff T $ is normal I tried to compute products and tried to show the one direction that ( $T=AU \implies T $ is normal) , but since $U$ is just assumed to be bounded, not unitary, got stuck! EDIT : For $T$ Normal ,assuming $U$ to be unitary ( we can do that provided $T$ is normal), have been able to show that $AU=UA$ . But for the other direction, ( $T=AU=UA \implies T$ normal), got, $T^*T=AU^*UA$ and $TT^* = AU^*UA$ . So if U is at least normal, we are done! (as mentioned in an answer) . But , we have to be careful, because by construction of $U$ and $A$ , it is not clear to me how is $U$ normal. ( since we are trying to show that $T$ is normal, we cannot assume beforehand that $U$ is unitary, like the other direction) Please help!","['operator-theory', 'adjoint-operators', 'functional-analysis']"
3139694,Kelly Criterion for a finite number of bets,"I am not a mathematician but I have read extensively about the Kelly Criterion and understood it well (I think at least). Kelly criterion allows you find out the fraction f* of your bankroll that you should bet if the odds of a bet and the probability of its success are known such as to maximize the logarithmic growth rate of your account. For reference, the formula and derivation can be found on the wiki . However, in real life this is hardly ever the case that a bet (even if it had positive expectancy) is available to us infinitely. So let us say there was a limit on the number of a times you could make a bet. How can the Kelly formula be adjusted so that one could find the optimum fraction of bankroll to bet assuming there was a limit to the number of bets allowed. For example, let's say a casino offered you a bet that for every \$1 you bet, 60% of the times you would win \$1 in addition to the 1$ bet and 40% of the time you would lose the \$1. So according to the Kelly formula you would want to bet: f* = (0.6 * 1 - 0.4) / 1 = 0.2 20% of your bankroll. However, let us say I added an additional criteria that you are only allowed 10 bets or maybe even less (like 2 bets?) How can I extend the Kelly formula to calculate the optimum fraction of bank roll to bet when this new constraint is added. Thanks in advance! Cheers!","['gambling', 'statistics']"
3139705,Solve the inequality $x^2 - 3 > 0$,"For the inequality $x^2 - 3 > 0$ , we have \begin{align} x^2 - 3 & = (x+\sqrt 3)(x- \sqrt 3) > 0 \end{align} Therefore, \begin{align} x > -\sqrt 3 \end{align} and \begin{align} x > \sqrt 3 \end{align} But, this is clearly wrong as we should get $x < -\sqrt 3$ and $x > \sqrt 3$ as the two intervals. What have I done wrong?","['algebra-precalculus', 'inequality']"
3139736,How do find the fourth derivative of $e^{x^2}$,So using chain rule for the first derivative: $$f' = 2x\cdot e^{x^2}$$ then using product rule for the $$f'' = 2x(2xe^{x^2}) + e^{x^2}\cdot 2$$ Is there an easy way to get the third? Does the second deriative simplify to: $$4x^2e^{x^2} + 2e^{x^2} = (4x^2 + 2)(e^{x^2})$$ Can I then take chain rule again to get $f^{(3)}$ ?,['derivatives']
3139750,Why is my explanation wrong?,"A class of $30$ students, J. being one of them, has $5$ classes today. What is the chance, that J. will be the chosen student to explain the 
  homework in at least two classes? What is the chance that someone will be chosen at least twice? My solution is the following: The probability for J. being chosen at least twice is $$\left( \frac{1}{30} \right)^2 \cdot \left( \frac{29}{30} \right)^3 + \left(\frac{1}{30} \right)^3 \cdot \left( \frac{29}{30} \right)^2 + \left( \frac{1}{30} \right)^4 \cdot \left( \frac{29}{30} \right) + \left( \frac{1}{30} \right)^5 \approx 0.104\%$$ The answer for the second question is simply J.'s probability multiplied by the number of students, approcimately $3.12\%$ We had a debate with a fellow student about this explanation, but couldn't convince each other. Is my explanation correct, or if not, where did I make a mistake?",['probability']
3139829,Is there a simple perfect squaring of a 1366 by 768 rectangle?,"So, a simple perfect squaring of a rectangle is a tiling of that rectangle by squares whose side lengths are all distinct integers. Additionally, not subset of the squares must form a smaller rectangle. My question is if there is a simple perfect squaring of a 1366 by 768 rectangle? We could try reducing it to a simpler problem by splitting the rectangle into a square and a smaller rectangle, but then we need to ensure that the side lengths are different, and that the their combination is simple. So we basically back to where we started. P.S. If you are wondering why 1366 by 768, that's the dimension of my monitor, which I am trying to artistically square (hence the art tag).","['geometric-construction', 'rectangles', 'art', 'geometry', 'tiling']"
3139835,Do free modules over ring without identity exist?,"If { $e_i$ } is the generating set of a free R-module M, and there is no unity in R, how does, say $e_1$ exist in M anyway? Context Edit (by jgon ): The original author appears to have abandoned the question, as there are no new comment replies, and the question is now closed and has a delete vote, but I think this is a fairly worthwhile question to address and keep on the site, so I wanted to explain why I think this is so. When $R$ is a ring with unity, we have the well known notion of free $R$ -modules, which have many definitions. Per the definition suggested by the OP in the comments below, they are $R$ modules $M$ equipped with a basis $\{e_i\}$ such that every element $m$ of $M$ has a unique expression $$m = \sum_i a_i(m)e_i,$$ for coefficients $a_i(m)\in R$ , only finitely many of which are nonzero. Now if we thought about how to adapt this definition to define a free $R$ -module over a ring $R$ which doesn't have unity, we run into problems immediately. For example, if we pick a basis $\{e_i\}$ , it's not even clear that we can express any member of this basis, like $e_1$ , in terms of the basis, since we can't write $e_1=1\cdot e_1$ any longer. Thus we'd like to know how to generalize and make sense of free modules in the context of not necessarily unital rings.","['free-modules', 'abstract-algebra']"
3139893,Convergence in distrubution sense and convergence of distribution to a distrubution.,"The convergence in the test function is as follow : Let $\mathcal D(U)$ the space of test function. $(\varphi _n)$ to $\varphi $ in $\mathcal D(U)$ if there is a compact $K\subset U$ that contain all support of the $\varphi _k$ 's and $\partial ^\alpha \varphi _k\to \partial ^\alpha \varphi $ uniformly for all multi index $\alpha $ . Let $T\in \mathcal D'(U)$ a distribution. Now, if $(T_k)$ is a sequence of $\mathcal D'(U)$ , it convergence to $T\in D'(U)$ if $$\lim_{n\to \infty }\left<T_n,\varphi \right>=\left<T,\varphi \right>.$$ This looks to be a sort of ""pointwise convergence"" definition. Question 1 Is this the convergence in distribution sense ? Question 2 Let for example $$f_n(x)=\frac{n}{\sqrt\pi }e^{-n^2x^2}. $$ It is such that $$\lim_{n\to \infty }\left<f_n,\varphi \right>=\lim_{n\to \infty }\int_{\mathbb R}\varphi f_n(x)\,\mathrm d x=\left<\delta ,\varphi \right>.$$ So what is the situation here ? We can define an absolute continuous measure $\mu_n(dx)=f_n(x)dx$ . Now, the distribution $\mu_n$ converge in distribution sense to the dirac distribution $\delta $ ? (Well, in probability $\mu_n$ define a probability measure, and this is how is define the convergence in law. Is there a link between these convergences ?)",['functional-analysis']
3139900,Double limit $\lim_{x\rightarrow0} \lim_{y\rightarrow x} \frac{y^2 f(x) - x^2 f(y)}{(1-\cos x)\sin (x-y)}$,"Let $I$ be an open interval containing $0$ , and $f: I \rightarrow R$ be differentiable and $f'$ be continuous. Compute: $$\lim_{x\rightarrow0} \lim_{y\rightarrow x} \frac{y^2 f(x) - x^2 f(y)}{(1-\cos x)\sin (x-y)}$$ This is my work: $$\lim_{x\rightarrow0} \lim_{y\rightarrow x} \frac{y^2 x^2 (\frac{f(x)}{x^2}-\frac{f(y)}{y^2})(x-y)}{(1-\cos x)(x-y)\sin(x-y)}$$ $$ \lim_{x\rightarrow0} \frac{x^4}{1 - \cos x} \frac{xf'(x) - 2f(x)}{x^3}$$ $$ \lim_{x\rightarrow0}\frac{x}{1-\cos x} (xf'(x) - 2f(x)) $$ But it doesn't feel right because I'm ""missing"" one power of x to have $\frac{x}{1-\cos x}$ converge. Can anyone help me?","['limits', 'calculus', 'real-analysis']"
3139957,"If $f_n,f\in C_0$ and for all $x_n,x$ with $x_n\to x$ we've got $f_n(x_n)\to f(x)$, then $\left\|f_n-f\right\|_\infty\to0$","Let $E$ be a locally compact Hausdorff space (if necessary, assume $E$ is a complete locally compact separable metric space) and $$C_0(E):=\left\{f\in C(E):\left\{|f|\ge\varepsilon\right\}\text{ is compact for all }\varepsilon>0\right\}.$$ How can we show that if $(f_n)_{n\in\mathbb N}\subseteq C_0(E)$ and $f\in C_0(E)$ with $$\left|f_n(x_n)-f(x)\right|\xrightarrow{n\to\infty}0\tag1$$ for all $(x_n)_{n\in\mathbb N}\subseteq E$ and $x\in E$ with $x_n\xrightarrow{n\to\infty}x$ , then $$\left\|f_n-f\right\|_\infty\xrightarrow{n\to\infty}0\tag2,$$ where $\left\|\;\cdot\;\right\|_\infty$ denotes the supremum norm?","['continuity', 'convergence-divergence', 'functional-analysis', 'analysis']"
3139958,Gagliardo–Nirenberg–Sobolev inequality for weighted Sobolev space with exponential weights,"Consider the weighted $L^p_\omega(\mathbb{R}^d)$ space on $\mathbb{R}^d$ be the set of Lebesgue measurable functions such that $$\|f\|_{L^p_\omega}=\int_{\mathbb{R}^d}|f|^p\omega_\mu(x)\,dx< \infty,$$ where $\omega_\mu(x)=\exp(-\mu |x|^2)$ or $\omega_\mu(x)=\exp(-\mu\sqrt{1+|x|^2})$ for some $\mu>0$ . Consider the weighted sobolev space $W^{1,p}_\omega(\mathbb{R}^d)$ such that $$W^{1,p}_\omega(\mathbb{R}^d)=\{u\in L^p_\omega\mid  \partial_{x_i}u\in L^p_\omega,\, i=1,\ldots, d \},$$ where $\partial_{x_i}$ denotes the weak derivative in the distribution sense. Similarly we define the high-order sobolev space $W^{2,p}_\omega(\mathbb{R}^d)$ such that $\partial_{x_ix_j}u\in L^p_\omega$ for all $i,j$ . I was wondering whether the Gagliardo–Nirenberg–Sobolev inequality for the classical Sobolev space still holds? In particular, whether for $1\le p<n$ , we have $$
\|u\|_{L^{p^*}_\omega(\mathbf{R}^n)}\leq C \|Du\|_{L^{p}_\omega(\mathbf{R}^n)}.$$ with $1/p* = 1/p - 1/n$ ? Do you have a reference for this? The main motivation is that I would like to find some weighted spaces on $\mathbb{R}^n$ , such that $L^p_\omega(\mathbb{R}^n)\subset L^q_\omega(\mathbb{R}^n)$ if $q\ge p>1$ , and then study the elliptic equation on $\mathbb{R}^n$ , say $$
-\partial_i a^{ij}(x)\partial_j u+ru=f(x), \quad x\in \mathbb{R}^d,
$$ where $a^{ij}$ is strictly elliptic. That is why I introduce this decaying weight, such that $\omega (x)dx$ is a finite measure on $\mathbb{R}^n$ . The exponential weight is introduced to involve bounded functions or functions with polynomial growth at infinity.","['lebesgue-integral', 'reference-request', 'real-analysis', 'sobolev-spaces', 'partial-differential-equations']"
3139993,"Prove that for any integers a and b and c, gcd(a, b) = gcd(a + bc, a + b(c − 1))","Please help me with this question Prove that for any integers $a$ and $b$ , $$\mathrm{gcd}(a, b) = \mathrm{gcd}(a + bc, a + b(c − 1))$$ I tried to prove it but I didn't understand the part of $b(c-1)$ let $d=\mathrm{gcd} (a,b)$ $h=\mathrm{gcd}(a,btac)$ since $d= \mathrm{gcd}(a,b)\implies d|a\:\text{and}\: d|b$ and then $$
\begin{split}
d|b\:\text{ and }\:d|ac & \implies d|b+ac\\
d|a\:\text{ and }\:d|b +d|ac & \implies d|h
\end{split}
$$","['elementary-number-theory', 'gcd-and-lcm', 'discrete-mathematics']"
3140000,"$\lim\limits_{n\to \infty} \int_0^1 |f(x)-a_nx-b_n| dx=0$ implies $(a_n)_n,(b_n)_n$ are convergent","Let $f:[0,1] \to \mathbb R$ be a continuous function and the sequences $(a_n)_n,(b_n)_n$ s.t. $$\lim_{n\to \infty}  \int_0^1 |f(x)-a_nx-b_n| dx=0.$$ Prove that $(a_n)_n,(b_n)_n$ are convergent. I know that $$\left|\int_0^1f(x)dx\right| \le \int_0^1|f(x)|dx.$$ Can somebody help me, please?","['integration', 'calculus', 'convergence-divergence', 'sequences-and-series']"
3140018,Expectation of Maximum of Translated Gaussian,"Given $X\propto N(\mu,\psi^2)$ and $K$ constant, find $E(\max\{K-X,0\})$ . My attempt: $$
\begin{align}
E(\max\{K-X,0\})\\
&=\int_{-\infty}^{\infty}\max\{K-x,0\}f_X(x)dx\\
&=\int_{K}^{\infty}(K-x)f_X(x)dx\\
&=\int_{K}^{\infty}[(K-\mu)-(X-\mu)]f_X(x)dx\\
&=\int_{K}^{\infty}(K-\mu)f_X(x)dx-\int_{K}^{\infty}(x-\mu)f_X(x)dx\\
&=(K-\mu)(1-\Phi(K))-\int_{K}^{\infty}(x-\mu)f_X(x)dx\\
&=(K-\mu)(1-\Phi(K))-\int_{K}^{\infty}(x-\mu)\frac{1}{(2\pi \psi^2)^{1/2}}e^{-\frac{(x-\mu)^2}{2\psi^2}}dx\\
&=(K-\mu)(1-\Phi(K))-\int_{\frac{(K-\mu)^2}{2\psi^2}}^{\infty}\psi^2\frac{1}{(2\pi \psi^2)^{1/2}}e^{-z}dz\\
&=(K-\mu)(1-\Phi(K))+\frac{\psi}{\sqrt{2\pi}}e^{-z}|_{\frac{(K-\mu)^2}{2\psi^2}}^{\infty}\\
&=(K-\mu)(1-\Phi(K))-\frac{\psi}{\sqrt{2\pi}}e^{-\frac{(K-\mu)^2}{2\psi^2}}
\end{align}
$$ where I have used the change of variables $z=\frac{(x-\mu)^2}{2\psi^2}$ . However, when I check my answer numerically, I see that the integral is not correct. Here is working Python code to check: import numpy as np
from scipy.stats import norm

# simulation parameters for checking answers numerically
trials = 100000
K = 0.25
mu = np.pi/2
psi = 3.0

simulated = np.mean([np.max([K-x, 0])
                     for x in np.random.normal(mu, psi, trials)])
numerical = (K-mu)*(1-norm.cdf(K, mu, psi)) - np.exp(-((K-mu)**2)/(2*psi**2))*psi/np.sqrt(2*np.pi) 
print(simulated)
print(numerical) This gives: simulated = 0.6448298784565597 numerical = -1.9713797586737627 What is the issue with my integration?","['expected-value', 'statistics', 'normal-distribution', 'numerical-methods']"
3140020,Does the following mean value theorem type statement hold in $\mathbb{R}^{n}$,"Let $c: [0,1] \rightarrow \mathbb{R}^{n}$ be a $C^1$ curve. Suppose $c$ passes through two points $c(x_1), c(x_2) \in \mathbb{R}^{n}$ with $0 < x_1 < x_1 < 1$ . Does there exist a point $x_0 \in (x_1, x_2)$ such that $Dc(x_0)$ lies on the line $c(x_2)-c(x_1)$ ? I'm not sure if my question makes sense as written, let me know if it doesn't! I will provide some intuition/example for what I want below. This requirement seems much less strict than let's say the false, directly generalized MVT in this question: counterexample for direct generalization of the one-dimensional Mean Value Theorem .
In the case of the circle, as in the example in the answer to the above question, one could just slide the secant line determined by $c(x_1)$ and $c(x_2)$ until it became a tangent line, which would correspond to the point $x_0$ we are looking for. In $\mathbb{R}^{3}$ this becomes a bit more confusing. For instance, the curve $c$ can move away from being ""above"" the segment $c(x_1)c(x_2)$ . However, in that case what I'd like to say is something along the lines of: suppose the origin, $c(x_1)$ , and $c(x_2)$ are not collinear. Then the origin and $c(x_1)$ , the origin and $c(x_2)$ determine a plane. Does there exist a time point $x_0$ such that $Dc(t_0)$ lies in that plane? In general, the idea is similar to the mean value theorem, but most generalizations deal with the magnitude of the derivative, whereas here we just want the tangent to be parallel to the secant. This is probably very simple but given the discussion above, I have trouble formulating exactly what I want.","['multivariable-calculus', 'calculus', 'vector-analysis', 'real-analysis']"
3140034,Probability of matching 5 cards from a deck of 40,"Suppose we have a deck of 40 cards which has, 5 Aces, 6 Kings, 9 Queens, 20 Jacks. A game is played where a contestant will continuously draw cards until they have 5 matching cards (not necessarily in order). The cards are drawn without replacement. I'm trying to find the probability of the contestant getting the five matching cards they get are all Aces (i.e. they have to get this before they get any other five matching cards). Does anyone have any idea on how to approach this?",['probability']
3140066,"If $X_i∼fλ$, $Z∼\mathcal N(0,I_d)$ and $Y=X+\ell d^{-α}Z$ with $α<1/2$, then $\liminf_{d→∞}\text E\left[1∧\prod_{i=1}^d\frac{f(Y_i)}{f(X_i)}\right]=0$","Let $f\in C^3(\mathbb R)$ be positive $g:=\ln f$ $d\in\mathbb N$ , $$p_d(x):=\prod_{i=1}^df(x_i)\;\;\;\text{for }x\in\mathbb R^d$$ and $\lambda^d$ denote the Lebesgue measure on $\mathcal B(\mathbb R^d)$ $\ell>0$ , $\sigma_d:=\ell d^{-\alpha}$ for some $\alpha\in[0,1]$ and $$Q_d(x,\;\cdot\;):=\mathcal N(x,\sigma_d^2I_d)\;\;\;\text{for }x\in\mathbb R^d$$ $X$ be a $\mathbb R^d$ -valued random variable on $(\Omega,\mathcal A,\operatorname P)$ with $$X_\ast\operatorname P=p_d\lambda^d$$ $Y$ be a $\mathbb R^d$ -valued random variable on $(\Omega,\mathcal A,\operatorname P)$ with $$\operatorname P\left[Y\in B\mid X\right]=Q_d(X,B)\;\;\;\text{almost surely for all }B\in\mathcal B(\mathbb R^d)\tag0$$ Note that, by $(0)$ , $(X,Y)_\ast\operatorname P=X_\ast\operatorname P\otimes \:Q_d$ is the product of the distribution $X_\ast\operatorname P$ of $X$ under $\operatorname P$ and the Markov kernel $Q_d$ . Moreover, there is a $\mathbb R^d$ -valued random variable $Z$ on $(\Omega,\mathcal A,\operatorname P)$ with $Z_\ast\operatorname P=\mathcal N_d(0,I_d)$ and $Y=X+\sigma_dZ$ . It's easy to see that $X$ and $Y-X$ are independent. Assume $g'$ is Lipschitz continous (and hence $g''$ is bounded) and $g'''$ is bounded. I want to show that $$\liminf_{d\to\infty}\operatorname E\left[1\wedge\prod_{i=1}^d\frac{f(Y_i)}{f(X_i)}\right]=0\tag1,$$ if $\alpha<1/2$ and $$\lim_{d\to\infty}\operatorname E\left[1\wedge\prod_{i=1}^d\frac{f(Y_i)}{f(X_i)}\right]=1\tag2,$$ if $\alpha>1/2$ . By Taylor's theorem (and a measurable selection theorem), $$g(Y_i)-g(X_i)=g'(X_i)(Y_i-X_i)+\frac12g''(X_i)(Y_i-X_i)^2+\frac16g'''(W_i)(Y_i-X_i)^3\tag3$$ for some $\mathbb R^d$ -valued random variable $W$ with $W_i\in[X_i,Y_i]$ or $W_i\in[Y_i,X_i]$ for all $i\in\left\{1,\ldots,d\right\}$ . Note that $$\prod_{i=1}^d\frac{f(Y_i)}{f(X_i)}=\exp\sum_{i=1}^d(g(Y_i)-g(X_i)).\tag4$$ So, we may be able to conclude by showing that $$\liminf_{d\to\infty}\sum_{i=1}^d(g(Y_i)-g(X_i))=-\infty\tag5,$$ if $\alpha<1/2$ and $$\liminf_{d\to\infty}\sum_{i=1}^d(g(Y_i)-g(X_i))=0\tag6,$$ if $\alpha>1/2$ , in suitable modes of convergence. Maybe we can apply the central limit theorem to $$S_1^{(d)}:=\sum_{i=1}^dg'(X_i)(Y_i-X_i)$$ and the strong law of large numbers to $$S_2^{(d)}:=\sum_{i=1}^dg''(X_i)(Y_i-X_i)^2.$$ I'm not sure what we could do with $$S_3^{(d)}:=\sum_{i=1}^dg'''(W_i)(Y_i-X_i)^3.$$ The only thing I've noticed is that $$\operatorname E\left[\left|S_3^{(d)}\right|\right]\le2\sqrt{\frac2\pi}\left\|g'''\right\|_\infty d\sigma_d^3.\tag7$$ So, as long as $d\sigma_d^3\xrightarrow{d\to\infty}0$ (which should be the case precisely when $\alpha>1/3$ ), $S_3^{(d)}\xrightarrow{d\to\infty}0$ in $L^1$ .","['measure-theory', 'probability-limit-theorems', 'asymptotics', 'taylor-expansion', 'probability-theory']"
3140073,Prove that there are at least $1000$ beautiful numbers each of which is divisible by $37$,"Here is the problem: A nine-digit integer is called beautiful if all of its digits are different. Prove that there exist at least $1000$ beautiful numbers, each of which is divisible by $37.$ Here is what I did: Let $n$ be a beautiful number which is divisible by $37$ ,we have $$n=\overline{a_9a_8\ldots a_1}$$ Otherwise , $10^3\equiv 1 \mod 37$ so $$10^2(a_9+a_6+a_3)+10(a_8+a_5+a_2)+(a_7+a_4+a_1)\equiv 0 \mod 37$$ $$-11(a_9+a_6+a_3)+10(a_8+a_5+a_2)+(a_7+a_4+a_1)\equiv 0 \mod 37$$ $$10(a_8+a_5+a_2-a_9-a_6-a_3)+(a_7+a_4+a_1-a_9-a_6-a_3)\equiv 0 \mod 37$$ we see that if $a_8+a_5+a_2=a_9+a_6+a_3=
a_7+a_4+a_1$ we would be done Otherwise $1+9+5=3+4+8=6+7+2$ so $a_8$ has 9 choices  , $a_5$ has $2$ , $a_9$ has 6 , $a_6$ has $2$ , $a_7$ has $3$ , $a_4$ has $2$ So there are at least $1296$ beautiful numbers each of which is divisible by $37$ I just want to know if this is right.",['number-theory']
3140083,"What is the link between topology and graphs, if one exists?","In spirit, topology and graph theory seems fairly similar - you have points/vertices, and a notion of ""how they are connected"", loosely. However, it's not obvious how these fields relate, despite topology seeming like it might be the natural generalisation of graph theory to ""not-necessarily discrete graphs""; after all, it seems common for Euler's early results about graphs to be described as ""the beginning of topology"". This question was inspired by seeing phrases like ""the ordering relation on the real numbers induces a topology"", which makes sense, but then realising that trying to do the same with the integers results in the discrete topology, which is effectively structureless with regards to the original ordering. However, you could easily represent the ordering structure using a graph (up to the direction considered positive). This seemed incongruous to me, and worth asking a question. If there a way to subsume graphs into topology, or vice versa, or a common generalisation which subsumes them both? Please be easy on me, for I am a humble physics student.","['graph-theory', 'general-topology', 'motivation', 'intuition']"
3140093,"What is the distribution of all sums of numbers from the set $\{1,2,\cdots,n\}$?","I was wodering: if you have the set of integers $R = \{1, 2, \cdots , n\}$ , I would like to know the distribution of the sum of the members of all the posible non-empty subsets. I have done a simple calculation for some values of $n$ and here you can see at the bottom the distribution, which resembles a lot to a gaussian or binomial distribution. My intuition says that binomial coefficient must be involved, but with some modification. Can you please help me with this problem? Seems to be more innocent that it is. Many thanks in advance!","['probability-distributions', 'combinatorics', 'binomial-distribution']"
3140118,What is the order of the element $10 \in (\mathbb Z/p \mathbb Z)^*$?,Let $p \geq 23$ be a prime number such that the decimal expansion (base 10) of $\frac{1}{p}$ is periodic with period $p-1$ . Let $(\mathbb Z/p \mathbb Z)^*$ denote the multiplicative group of integers modulo $p$ . Then which of the following is true? 1) The order of the element $10 \in  (\mathbb Z/p \mathbb Z)^*$ is a proper divisor of $p-1$ . 2) The order of the element $10 \in  (\mathbb Z/p \mathbb Z)^*$ is $(p-1)/2$ . 3) The element $10 \in  (\mathbb Z/p \mathbb Z)^*$ is a generator of the group $(\mathbb Z/p \mathbb Z)^*$ My Attempt : I know that the group $(\mathbb Z/p \mathbb Z)^*$ is cyclic. And the prime number $p$ is a divisor of $10^{p-1} -1$ . I can not deduce anything else from the given question. Can anyone please help me to proceed?,"['group-theory', 'abstract-algebra', 'finite-groups', 'cyclic-groups']"
3140170,A consequence of Schanuel's lemma,"In Carlson's Cohomology and representation theory , the author states Schanuel's lemma, and then derives a consequence that I cannot understand. They define, for a $kG$ module $M$ , $\Omega (M)$ to be the kernel of a surjective map $P\to M$ where $P$ is projective of minimal dimension (here I'm assuming dimension means ""dimension over $k$ "" ); and then state that if $\gamma : Q\to M$ is another surjective map from a projective, then $\ker \gamma = \Omega( M) \oplus (\mathrm{proj})$ , and say that it follows from Schanuel's lemma. But I don't see how that follows from Schanuel's lemma. The exact statement is that $\ker \gamma \oplus P \cong \Omega(M)\oplus Q$ , but I don't see why the isomorphism should take $\ker\gamma$ to $\Omega(M)\oplus$ some projective submodule of $Q$ (actually the isomorphism I found when I wrote down a proof of the lemma doesn't send $\Omega(M)$ into $\ker \gamma$ at all)","['projective-module', 'homological-algebra', 'representation-theory', 'abstract-algebra', 'group-cohomology']"
3140217,Rank of a matrix over field extension.,Let $A$ be a matrix over a field $\mathbb{F}$ and $\mathbb{K}$ be a field extension  of $\mathbb{F}$ . As I know that characteristic and minimal polynomial of $A$ over $\mathbb{F}$ and $\mathbb{K}$ are same. Now can I say that rank of the matrix over both field will be same? I tried with particular matrices and got the same rank. Please suggest. Thanks.,"['matrices', 'matrix-rank']"
3140228,"Why do we say ‘pairwise disjoint’, rather than ‘disjoint’?","I don’t see the ambiguity that ‘pairwise’ resolves. Surely if $A$ , $B$ and $C$ are disjoint sets then they are pairwise disjoint and vice versa ? Or am I being dim?","['elementary-set-theory', 'definition', 'terminology']"
3140247,Difference between product distribution and joint distribution?,What is the difference between an $n$ -fold product distribution and a joint distribution with $n$ random variables? Is it only defined for independent random variables? I am confused as to what is the definition of a product distribution. Context: I am reading class notes by John Duchi that say the $KL$ -Divergence of product distributions $P = P_1 \times P_2 \ldots P_n$ and $Q = Q_1 \times Q_2 \ldots Q_n$ given by $KL(P || Q)$ satisfies the decoupling equality of being $\sum_{i = 1}^{n}KL(P_i||Q_i)$ .,"['measure-theory', 'probability-distributions', 'information-theory', 'probability-theory', 'probability']"
3140284,"A finite group $G$ and fixed $k\geq 1$ where for every $n\geq 1$, the $n$-direct product $G^n=G\times\dots\times G$ is $k$-generated?",Does exist a finite group $G$ and fixed $k \geq 1$ such that the $n$ -direct product $G^n = G \times \dots \times G$ is $k$ -generated for every $n \geq 1$ ? I suspect the answer is no. Does exist a simple proof of this fact (if true)?,"['combinatorial-group-theory', 'direct-product', 'group-theory', 'finite-groups']"
3140329,Is this system of differential equations coupled or not?,$$\begin{aligned} \dot{x_{1}} &= a\\ \dot{x_{2}} &= b \sin\Bigl(\omega(t-x_{1})\Bigr) \end{aligned}$$ Does it follow from here that $ x_{1} = at+c $ ? Or do I have to turn it into a single higher-order differential equation and then solve it? How to spot the difference easily?,['ordinary-differential-equations']
3140386,Solutions of $\tan(x)=-\lambda x$?,"Motivated by a physical problem I would be interested in the solutions of $$\tan(x)=-\lambda x$$ with $\lambda,x \in \Bbb R^+$ . Especially the first non-trivial solution (the trivial is $x=0$ ) would be of interest. The problem with $\lambda=-1$ has some intriguing solutions, discussed here . So maybe there is a chance for a nice solution here as well? Nice shall not mean non-transcendental. The methods from this link could maybe be modified?","['algebra-precalculus', 'trigonometry', 'transcendental-equations']"
3140430,Prove that $\lim\limits_{n\rightarrow\infty}\int_{1}^{a}\frac{1}{1+x^{n}}dx=\ln2$,"Prove that $$\lim_{n\rightarrow\infty}\int_{1}^{a}\frac{1}{1+x^{n}}\,\mathrm{d}x=\ln2.$$ We can write $$\frac{1}{1+x^{n}}=1-\frac{x^{n}}{1+x^{n}},$$ so $$\int_{1}^{a}\frac{1}{1+x^{n}}\,\mathrm{d}x=a-1-\int_{1}^{a}\frac{x^n}{1+x^n}\,\mathrm{d}x$$ and $$\int_{1}^{a}\frac{x^n}{1+x^n}\,\mathrm{d}x=\frac{1}{n}x\ln(1+x^n)|_{1}^{a}+\int_{1}^{a}\ln(1+x^n)\,\mathrm{d}x$$ The last can be manipulated to providing a limit using $e^x\geq x+1$ , in our case $x \geq \ln(x+1)$ , $x \geq0$ . However, I need help from this point on or, if the method is faulty, on the problem itself.
EDIT: Thanks for clarifications. I see the mistake. However, by changing it into $\lim_{n\rightarrow\infty}n\int_{1}^{a}\frac{1}{1+x^{n}}\,\mathrm{d}x=\ln2.$ I followed Cosmin's duplicate, but I am unable to grasp the proof, as the level is high. Could you give an easier proof for this than one using improper integrals, please?","['integration', 'definite-integrals', 'real-analysis', 'calculus', 'limits']"
3140460,Geodesics of null surface and induced connection,"Although this is a question related to GR this is purely a math question, so I think this is the right place to ask it. Let $(M,g)$ be a Lorentzian manifold. Let $\phi : \Sigma\to M$ be one null hypersurface, by which we mean its normal is null. It is common in GR to argue the following: Since the normal vector $\zeta$ to $\Sigma$ is null, it is orthogonal to itself. Hence the normal to $\Sigma$ also lives in its tangent bundle. In that case, one can consider its integral lines. One works formally to show that $\zeta$ satisfies the autoparallel equation $$\zeta^\mu \nabla_\mu\zeta_\nu=\alpha\zeta_\nu.$$ Now, I have one problem here. It seems intuitively clear to me that being a geodesic on a submanifold is not the same as being a geodesic on the ambient space. One example that comes to my mind is in $\mathbb{R}^3$ . The geodesics are straight lines. If one looks to the submanifold $S^2$ , the geodesics are great circles which as seen on curves on $\mathbb{R}^3$ are not geodesics. The central question seems to be: what is the connection with respect to which geodesics on $\Sigma$ are being considered, and how it connects to the Levi-Civita connection on $M$ ? Is it the pullback connection? Or is it some sort of ""projected"" connection, as when we ""project the covariant derivative to the tangent space of $S^2$ "" in $\mathbb{R}^3$ ? How it relates to the induced metric $\phi^\ast g$ ? In short: when physicists consider these generators of the null surface, which are integral lines of the normal as seen as a tangent vector, what is the appropriate way to make sense of the resulting geodesics? How to make this whole discussion rigorous?","['geodesic', 'connections', 'semi-riemannian-geometry', 'mathematical-physics', 'differential-geometry']"
3140468,Is this an application case of Bayes theorem? Is my book wrong?,"A sickness has a heterozygote frequency of $\frac{1}{20}$ ie. 1 in 20 people of a population will have the allele combination $Aa$ where a denotes the recessive and A the dominant allele. To become sick the carrier needs to have two $aa$ alleles. A mother is known to have the combination $Aa$ , what is the probability her child will be sick (have $aa$ ) if the combination of the husband is unknown (i.e. $AA, Aa, aa)$ ? Now here is where I struggle. If the husband has $AA$ , the child will never get $aa$ , if the husband has $Aa$ , the child will get $aa$ with a chance of $\frac{1}{4}$ . If the husband has $aa$ (is sick himself) then the child wil get $aa$ with a chance of $\frac{1}{2}$ The book states that the answer a priori is for the child to be sick in this situation is $\frac{1}{20} \frac{1}{2} \frac{1}{2} = \frac{1}{80}$ Shouldn't it instead  be : $\frac{1}{4}\frac{1}{20} + (\textbf{double aa frequency})\cdot \frac{1}{2}$ ?","['statistics', 'bayes-theorem']"
3140490,Taylor expansion of $g^{-1/2}$ where $g$ is riemannian metric in normal coordinates,"Let $(M,g)$ be a riemannian manifold. In normal coordinates for any $q\in M$ , there is a Taylor expansion of $g_q$ given by $$(g_q)_{ij}(x)=\delta_{ij}+\frac{1}{3}R_{kijl}(q)x^k x^l+O(|x|^3)$$ Now here is my question: How does one derive from the above expression, that $$\left(\sqrt{g_q}^{-1}\right)^{ij}(x)
=\delta^{ij}-\frac{1}{6}R_{kijl}(q)x^k x^l+O(|x|^3)$$ I know how one derives the Taylor expansion of $g$ , using a geodesic variation. Here $\sqrt{g_q}$ denotes the positive square root of $g$ (as a matrix). I am kinda clueless here, any help would be very much appreciated! I read this in a paper, but there is no further explanation.","['taylor-expansion', 'riemannian-geometry', 'differential-geometry']"
3140502,Do the 12 lines of a bingo card have equal chance of winning?,"(This question is inspired by: If I have an event where the outcomes aren't uniformly distributed, how would I make the ""fairest"" bingo card out of the events? ) You have a $5 \times 5$ bingo card filled with $25$ distinct numbers, one per square.  There is also a pot containing each number once and you draw them out one by one without replacement. A line is any of the $5$ rows, $5$ columns, or $2$ main diagonals.  A line is completed when its $5$ numbers have been drawn.  A line wins if it is the first line to be completed. Question: Do the $12$ lines have equal chance of winning?  If not, which lines have higher chance of winning? Why I ask: Define $T_l$ to be the time to completion for line $l$ .  It is obvious that all $T_l$ are equi-distributed, and thus all $E[T_l]$ are equal.  However, because the lines overlap, the different $T_l$ 's are dependent, and it is not clear to me that they have equal chances of being first. In particular, imagine that the $5$ -subsets are not arranged in rows, columns and diagonals, but are clustered in some non-uniform way.  Then a subset that shares a lot of elements with other subsets might have a lower chance to win than a subset that does not share a lot of elements with other subsets.  (I can provide a simple example if there is interest.) On the bingo card, the $5$ -subsets are pretty uniform but not exactly uniform, due to the diagonals.  So my suspicion is that the line win chances are almost equal but not exactly equal.  And I am curious as to which lines have higher chances. I imagine (but would be happy to be proven wrong) that calculating the exact win prob for a line might be difficult/tedious, so qualitative arguments based on e.g. symmetry are also welcome. Clarifications: A drawn number can complete multiple lines, so that needs some special handling.  However what I am interested in is the question of equality, so I will accept any reasonable way to handle such ""shared"" wins, i.e. if $N>1$ lines are completed at the same draw (and no line has been completed before this draw), then you can treat this as if... they all win (in which case the sum of the $12$ win probabilities exceed $1$ , but that doesn't matter since I am interested in which are higher/lower), or, the whole experiment is repeated from the beginning (i.e. we condition on such shared wins not happening), or, you flip an $N$ -sided die to determine the winner (i.e. this effectively counts as $1/N$ win for each involved line), etc.","['combinatorics', 'probability']"
3140505,"A difficulty in understanding the definition of ""Spaces of Matrix Elements.""","The definition is given below: If the definition of the Spaces of Matrix Elements is as given below: But I do not understand why: 1- Any linear combination of matrix elements can be expressed invariantly (without using coordinates) as given in Eq.(3), could anyone explain this for me please? 2-Also I do not understand the paragraph under eq.(3), and why it is c_{ji} and not c_{ij} , could anyone explain this for me with a concrete example please? 3-Could anyone give me a concrete example describing the difference between the space of matrix elements of the representation $T$ and the matrix elements of $T$ ? Thank you!","['matrices', 'representation-theory', 'linear-algebra']"
3140525,How can I know a value of this limit?,"$$
\lim_{t\to 1^-} (1-t) \sum_{n=0}^\infty \frac{t^n}{1+t^n}
$$ I try to use L'hopital's rule but not successfully. Also I know that exist formula Sonine but I can't understand how I can use it.","['limits', 'real-analysis']"
3140575,Topological Space on all Ideals,"$\text{Spec}$ is a topological space on the prime ideals of a ring. What fails if we try to make the ideals into a topological space? We might try something like this: the points of this space are ideals. For $f_1, ..., f_n \in A$ , put $D(f_1, ..., f_n)$ to be the set of ideals not containing any of $f_1, ..., f_n$ . Closing under unions (including the empty union) gives a topological space. We could try to make this into a sheaf $\mathcal{F}$ by declaring $\mathcal{F}(D(f_1, ..., f_n))$ to be the localization of $A$ at the multiplicative set generated by $f_1, ..., f_n$ . Something seems wrong here, but I don't quite see it.",['algebraic-geometry']
3140639,Proving that a system of ODEs has a focus at the origin,"Prove that the following system of ODEs has a focus at the origin. $$\begin{aligned} \dot{x} &= -x^3-y^3\\
                  \dot{y} &= x^3       \end{aligned}$$ Plotting the vector field confirms this fact. I've tried to convert the system to polar coordinates and I've shown that $\dot{\theta}\neq 0$ except at the origin. I believe it would suffice to show that $$r(\theta+2\pi)-r(\theta) < 0$$ for al $\theta$ when close to the origin. However, this seems to involve expressing $r$ in terms of $\theta$ , which I don't know how to do. Any help? Additionaly, is there an easier method? Thank you in advance. I also had the following idea: according to the fundamental theorem of calculus, $$r(\theta+2\pi)-r(\theta)=\int_\theta^{\theta+2\pi}\frac{dr}{d\theta}d\theta$$ If only I could somehow show this is strictly less than $0$ ...","['stability-in-odes', 'polar-coordinates', 'ordinary-differential-equations', 'dynamical-systems']"
3140666,What is a local group isomorphism?,What does it mean for 2 groups to be locally isomorphic? E.g. $SO(4)$ is locally isomorphic to $ SO(3)\times SO(3)$ -why not globally?,"['group-isomorphism', 'topological-groups', 'group-theory', 'lie-groups', 'terminology']"
3140677,direct sum of representation of product groups,"Given two finite groups $G_1$ and $G_2$ , and some representations $\rho_1: G_1 \to V_1$ and $\rho_2: G_2 \to V_2$ , it seems the standard way to create a representation for $G_1 \times G_2$ is to use the tensor product $$\rho_1(g_1) \otimes \rho_2(g_2) \quad g_1,g_2 \in G_1,G_2.$$ It seems to me that one could also use the direct sum $\rho_1(g_1) \oplus \rho_2(g_2)$ ,
because the blocks in the matrix form of the representation do not interact and one gets the desired effect. Given that this representation could have a lower dimension than using tensor product, why is it not used?","['representation-theory', 'group-theory', 'finite-groups']"
3140695,If $f(x)=x^{-n}$ for $n\in \mathbb{N}$,"If $f(x)=x^{-n}$ for $n\in \mathbb{N}$ then  prove $f^{(k)}(x)=(-1)^{k} \frac{(n+k-1)!}{(k-1)!}$ $x^{-n-k} $ Of course I'm taking it by induction, but the main issue comes when $k+1$ and my final result comes to this I derive $f^{(k)}(x)=(-1)^{k} \frac{(n+k-1)!}{(k-1)!}$ $x^{-n-k} $ therefore $f^{(k+1)}(x)=(-1)^{k} \frac{(n+k-1)!}{(k-1)!}$ $x^{-n-k-1}(-n-k) =$ $f^{(k+1)}(x)=(-1)^{k+1} \frac{(n+k)!}{(k-1)!}$ $x^{-n-k-1}$ but my intuition tells me that I should get to $f^{(k+1)}(x)=(-1)^{k+1} \frac{(n+k)!}{k!}$ $x^{-n-k-1}$ Any advice?","['calculus', 'derivatives', 'induction']"
3140696,How to define small circle on an ellipsoid,"I am trying to figure out the proper definition of a small circle on a biaxial ellipsoid of revolution. One definition is the intersection of the ellipsoid with a cone emanating from the center of the ellipsoid. The other way I can imagine to define it is a plane intersecting the ellipsoid in which the plane does not also intersect the center of the ellipsoid (or else it would be a great circle). This Wikipedia article also discusses sphere-intersection, but it is limited to spheres, and I am interested in ellipsoids. Does anyone know if these two methods, cone intersection and plane intersection, result in the same curve? If not, which one is a small circle, and what would be the name of the other resulting curve?","['conic-sections', 'geometry']"
3140703,What does a gradient multiplied by the inverse of the Hessian mean?,"In the paper VIME: Variational Information Maximizing Exploration , the authors suggest taking a single second-order step to efficiently optimize a variant of evidence lower bound They say To optimize Eq. (12) efﬁciently, we only take a single second-order step. This way, the gradient is rescaled according to the curvature of the KL divergence at the origin. As such, we compute $D_{KL} [q(\theta; \phi + \lambda\Delta\phi)\Vert q(\theta; \phi)]$ , with the update step $\Delta\phi$ deﬁned as $$
\Delta\phi=H^{-1}(l)\nabla_\phi l(q(\theta;\phi),s_t) \tag{13}
$$ in which $H(l)$ is the Hessian of $l(q(\theta;\phi),s_t)$ . I'm quite confused about how they obtain Eq. $(13)$ : why would they multiply the gradient by the inverse of the Hessian?","['multivariable-calculus', 'calculus', 'optimization']"
3140706,"Commutative diagrams for vector spaces, dual spaces, and adjoint of linear maps","I'm looking for a commutative diagram explaining the relationship between a vector space, $X$ the dual space, $X^*$ , the double dual, $X^{**}$ . I'm also looking for a diagram explaining the relationship between a linear map $T : X \longrightarrow Y$ , $T^{\dagger}$ and $T^{\dagger \dagger }$ . Ideally, I would like all of these ideas explained in a single diagram, but I haven't been able to come up with one on my own.","['linear-algebra', 'dual-spaces']"
3140731,"Odds of assembling a jigsaw puzzle ""perfectly""","A bunch of my coworkers have gotten way into assembling jigsaw puzzles during the workday, so I got this idea it'd be fun to bore them with random facts. I'm trying to think of the odds of assembling a 1000 piece jigsaw puzzle ""perfectly,"" i.e. choosing each piece such that it fits with one of the pieces already in the puzzle. Assuming that each piece is exactly 1 square inch, that means we probably have a 40x25"" puzzle. Using some basic deduction, I can conclude that this leaves 4 ""corner"" pieces with two possible connections, 122 ""edge"" pieces with three possible connections, and 874 internal pieces with four possible connections. From here, I'm sure that the answer has something to do with this: Jigsaw Probability Using that logic, the probability of our first two pieces matching is: (4/1000) * (2/999) + (122/1000)*(3/999) + (874/1000) * (4/999) The problem is, I can't figure out how to extrapolate this further, since the next iteration seems like it would depend on which type of piece was chosen. I'm not sure if this is the right approach, because I can envision a scenario where the puzzle is assembled from the center outward, after which every edge piece is guaranteed to fit with probability 1, and I'm not sure how the above sequence could be expanded in a way that accounts for that. The other approach I thought of was inspired by this: Proof by Induction: Puzzle Pieces Problem If I could derive the number of possible ""perfect"" sequences of 999 moves, I could just divide that number by 1000! total possible sequences of selections and that would be the probability. I might be missing something here though, as this line of thinking stands in contrast to this post: Probability of a n-piece puzzle being solved on the first try. Is my reasoning sound? ...which makes the assumption that there's only one possible way to select all pieces that solves it. He also gets into piece orientation which I don't really care about. Any thoughts are welcome!","['recreational-mathematics', 'combinatorics', 'probability']"
3140738,Extension of a vector field $X:A\subset \mathbb{R}^2 \to \mathbb{R}^2 $,"Define $A=\{(x,y)\in \mathbb{R}^2;\ x\leq 0\ \text{or }  y \leq x^2 \}$ ( a representation of $A$ can be found here .) Let $X:A\to \mathbb{R}^2$ be a smooth function such that $X(\partial A) = (1,0)$ and $\tau:\mathbb{R}\to \mathbb{R}$ a diffeomorphism satisfying $\tau'>0$ and $\tau(0) = 0$ . My Question: Is it possible to extend $X$ to a fuction $\tilde{X}:\mathbb{R}^2\to \mathbb{R}^2$ , such that the orbit of $\tilde{X}$ startig at the point $(0,y)$ (with $y>0$ ) also passes through the point $(\tau(y),\tau(y)^2)$ . Just for the records, I am searching for a smooth planar vector field $\tilde{X}$ , such that $\left. \tilde{X}\right|_{A} = X$ and $\forall$ $y>0$ the solution $\varphi_y$ of the ODE \begin{align*}\dot{x} &= \tilde
{X}(x) \\
x(0) &= (0,y).\\
\end{align*} satisfy the condition, $\exists$ $t_y \in \mathbb{R}$ such that $\varphi_y(t_y) = \left(\tau(y),\tau(y)^2 \right)$ . If the result is true just in the neighborhood of the origin it is good enough for me. I don't have any ideas on how to tackle this problem. Can anyone help?","['differential-topology', 'dynamical-systems', 'ordinary-differential-equations', 'real-analysis']"
3140761,Existence of Classical Solution to $\square u + u = 0$ in unbounded domains,"Let $\Omega \subseteq \mathbb{R}^n$ be a domain, not necessarily bounded. Let's also assume for simplicity that $\Omega$ has smooth boundary. Fix two functions $$
\alpha, \beta : \bar{\Omega} \to \mathbb{R},
$$ each assumed to be smooth in $\Omega$ , continuous up to the boundary, with $\alpha \equiv \beta \equiv 0$ on $\partial \Omega$ .  In the case that $\Omega$ is unbounded, we will assume in addition that $$
\alpha,\beta \to 0 \quad \text{as } {|x|} \to \infty.
$$ Can we ensure the existence of a smooth solution $u$ to the Cauchy problem \begin{align}
\square u + u \equiv 0 \quad \text{in }\Omega \times \mathbb{R},\\
u(x,0) \equiv \alpha(x) \quad \text{in } \Omega,\\
u_t(x,0) \equiv \beta(x) \quad \text{in } \Omega.
\end{align} Naturally, I wanted to obtain a weak solution to this problem and to then invoke regularity results to lift it to a classical solution. However, $\alpha$ and $\beta$ need not belong to $L^p(\Omega)$ for any $1 < p < \infty$ . Consequently, I cannot see how to formulate this problem in a ""weak sense"". Is this approach correct? Or am I missing something entirely?","['partial-differential-equations', 'functional-analysis', 'real-analysis']"
3140762,Is it true that $A^TA=A \implies A^2=A$? Is the converse true?,"I was asked this question in an exam. Let $A$ be a square matrix. $A^TA=A \implies A^2=A$ , true or false? $A^2=A \implies A^TA=A$ , true or false? I rewrote the equations as $(A^T-I)A=0$ and $(A-I)A=0$ , but I am unsure how to proceed.
I also tried to consider it in terms of columns and rows, A^2=A means that the dot product of row i and column j equals $A_{ij}$ , but that doesn't get me anywhere.
I know that if I assume $A$ to be symmetric, both statements are true. My hunch would be that 1 is false, 2 is true.","['matrices', 'linear-algebra']"
3140829,How to solve this nonlinear ODE?,"It is a nonlinear ODE. $$x(4ydx+2xdy)+y^3(3ydx+5xdy)=0$$ I can not solve it by dividing $x$ and $y$ into two parts. Also, if I let $\frac{dU}{dy}=2x^2+5xy^3$ and $\frac{dU}{dx}=4xy+3y^4$ , $\frac{d^2U}{dxdy}$ will not equal to $\frac{d^2U}{dydx}$ .",['ordinary-differential-equations']
3140832,Product of Normal and independent log-Normal. What is the density?,"Let $X$ and $Y$ be independent standard Gaussian random variabless -- i.e., $N(0,1)$ . Let $\sigma \in \mathbb{R}$ . Define $$Z=X \cdot e^{\sigma \cdot Y}.$$ Is there a closed form expression for the density of $Z$ ? The density can be expressed as either of the following two integrals. $$\mathsf{pdf}_Z(z) = \frac{1}{2\pi}\int_{-\infty}^\infty \exp\left(\frac{-z^2 \cdot e^{-2\sigma y} - y^2 - 2\sigma y}{2}\right) \mathrm{d}y$$ $$~~~~~~~~~~~~~~~~~~~=\frac{1}{2\pi|\sigma z|} \int_0^\infty \exp\left(\frac{-\sigma^2 x^2 - (\log(x/|z|))^2}{2\sigma^2}\right) \mathrm{d}x.$$ I think of $Z$ as being a symmetric version of the log-Normal distribution or, alternatively, a heavy-tailed version of the Normal distribution. I expect the density to resemble that of the log-Normal far from the origin, namely something like $e^{-(\log z)^2}$ . I would like an exact expression in order to be able to compute things about this distribution. Alas, computing this is beyond my powers of integration. Any help would be appreciated.","['integration', 'probability-distributions', 'normal-distribution', 'probability', 'density-function']"
3140840,How to solve $A^{\frac 12} B A^{\frac 12} = C$ for $A$?,"Suppose that matrices $A,B,C$ are symmetric and positive definite. Then, $A$ has a unique, positive square root, which we call $A^{\frac 12}$ . If $$A^{\frac 12} B A^{\frac 12} = C$$ then can we write an expression for $A$ in terms of $B, C$ ?","['matrices', 'matrix-equations', 'positive-definite', 'symmetric-matrices']"
3140871,"Given a closed linear subspace, is there always a projection that maps onto it?","Given a closed linear subspace, is there always a projection that maps onto it? Here, a projection $P$ should be a linear and continuous mapping and satisfies $P^2 = P$ .","['map-projections', 'functional-analysis']"
3140885,Method of Characteristics for $u_t + uu_x = -2u$,"Consider the following quasi-linear PDE : $u_t + uu_x = -2u$ , with the boundary condition $u(0,t) = e^{-t}$ . 
  Show, using the method of characteristics, that the solution to this boundary value problem is $u(x,t) = e^{-2t} / ( x + \sqrt{x^2 + e^{-2t}} )$ . So far I've followed the usual method when solving this and I've obtained that $t = r + s$ , $u = e^{-s-2r}$ $x = e^{-s}(1-e^{-2r})$ / 2, but I'm not sure where to go from here to find my solution $u(x,t)$ . Any help?","['boundary-value-problem', 'characteristics', 'ordinary-differential-equations', 'partial-differential-equations']"
3140900,"Given $n$ circles of radii $r_1,r_2,...,r_n$ inseparable by straight lines, prove that they can be covered by a circle of radius $r_1+r_2+...+r_n$","Definition: A subset $A\subset\mathbb R^2$ is inseparable by straight lines if there doesn't exist a straight line $L$ such that $L \cap A=\emptyset$ and $L$ divides $A$ into $2$ nonempty parts, lying on both sides of $L$ . Question: Given $n$ circles of radii $r_1,r_2,...,r_n$ inseparable by straight lines, prove that they can be covered by a circle of radius $r_1+r_2+...+r_n$ . I'm thinking about induction, but removing one circle could potentially lead to $n-1$ circles separable by straight lines, like this Any ideas? Edit: The one who told me this problem said it's in a book written by L. Fejes Tóth , not sure which one.","['circles', 'geometry', 'plane-geometry']"
3140929,Tic-Tac-Toe on the Real Projective Plane is a trivial first-player win in three moves,"Consider a $3 \times 3$ Tic-Tac-Toe board with opposite sides identified in opposite orientation. We play Tic-Tac-Toe in the Real Projective Plane. More precisely, consider a $3 \times 3$ Tic-Tac-Toe board on the unit square $[0,1]^2$ . We glue the boundary of the square in the following way to create the Real Projective Plane : $(x,0) \sim (1-x,1)$ and $(0,y) \sim (1,1-y)$ . That way, we have created a $3 \times 3$ Tic-Tac-Toe board on the Real Projective Plane. We still have $9$ cells, but we have more possible ways to form winning patterns since we can go beyond the sides of the planar board. A way to visualize the game is to create copies of the board (with appropriate rotations) around a planar board. Here is what it would look like for the Klein Bottle (picture taken from Mathematics Illuminated) : It seems that any three moves is a first-player win in the Real Projective Plane game. Is there a smart way to see it (except check all the $84$ cases) ? Is this result related in any way to the topology (or properties) of the Real Projective Plane ? There is an action by horizontal and vertical translations (with appropriate reflection when a line goes through a side) on the board from the group $\Bbb Z_6 \times \Bbb Z_6$ that preserves winning patterns. We could also consider $\pi/2$ rotations through the center of the board. Looking at the order of the symmetry group, there must be some inequivalent three-element subsets of the board. Maybe there is a smart way to identify the orbits ? This is related to Prove that a game of Tic-Tac-Toe played on the torus can never end in a draw. (Graph theoretic solutions only.) .
Similar arguments can probably be used to show that our game cannot end in a draw, if that's helpful in any way. This problem comes from https://concretenonsense.wordpress.com/2008/04/15/topological-tic-tac-toe-1-the-torus/ and https://concretenonsense.wordpress.com/2008/04/17/topological-tic-tac-toe-2-other-surfaces/ .","['tic-tac-toe', 'graph-theory', 'recreational-mathematics', 'combinatorial-game-theory', 'general-topology']"
3140965,Recurrence relation $a_{n+1}=a_n+(b-a_n)\cdot x$,"I'd like to know how to find a general term for this recurrence: $$a_{n+1}=a_n+(b-a_n)\cdot x, \text{where b, x are positive constants}$$ Background: Linear interpolation equation for a starting point $a$ and ending point $b$ looks like this: $f(x)=(b-a)\cdot x$ . I assume $x \in [0, 1]$ . So for $x=1$ we are at the point $b$ . It is used in computer graphics to move things around :) Very often the parameters of the function are swaped, $x$ becomes constant and $a$ is taken from the previous iteration of a recursion. It gives an effect of homographic-function-like approaching to $b$ (there is a horizontal asymptote in $b$ ). I want to find an exact solution for $a_n$ . If I'm correct the relation is a following recurrence: $$a_{n+1}=a_{n}+(b-a_n)\cdot x$$ I'm curious about the method to get the solution. Wolfram alpha gave me $$a(n)=c_1(1-x)^{n-1}-b(1-x)^n+b$$","['recurrence-relations', 'discrete-mathematics', 'sequences-and-series']"
3141096,Why does representing groups as linear operators provide insight about the groups themselves?,"An important aspect of group theory is how groups can be represented as linear operators acting on vector spaces.
While I understand how this works and how the (at least basic) tools are defined, what I struggle to understand is why this sort of thing is so useful. To my understanding, working on a ""group representation"" is kind of like saying that the elements of the group have been ""promoted"" so that I can now ""add"" them together, ""multiply them by scalars"", and have them ""act on other vectors"".
In other words, if before I could only write things such as $gh$ for $g,h\in G$ , now I can write things such as $(\alpha g+h)v$ with $\alpha\in\mathbb F$ and $v\in V$ . What I find odd is that now results obtained using this additional structure are used to infer things about the original groups. For example, I read in this other answer how the classification of finite groups ""would be unthinkable without representation theory"", and in here and here about many other applications.
I don't understand why this should be the case: why does adding ""fake structure"" (as in, structure that was not originally in the group under study) help classify groups, or help understanding groups in any other way? To be clear, I'm not asking why are group actions an important part of group theory, like is done for example in this question . Rather, I ask why specifically actions on linear spaces reveal so useful. What is it about empowering a group with an additional abelian structure (plus scalars etc) that makes is so useful in providing insight about the group structure itself? I am also not asking why is group representation theory important or useful for applications, or why groups are. Rather, I am asking why specifically adding a linear structure help us better understand the structure of groups.","['group-theory', 'representation-theory', 'vector-spaces']"
3141137,"$(\int f(x,y)\lambda(dy))^{-1}$ is a density of the absolutely continuous part of Lebesgue measure w.r.t. $P_X$?","Consider the following example from Achim Klenke's Probability theory I have two questions: 1) How is it that $(f_X(x))^{-1}$ is a density of the absolute continuous part of the Lebesgue measure w.r.t. $P_X$ ? 2) The regular conditional distribution of $Y$ given $X$ is a transition kernel such that for every $x$ the map $B \mapsto P[Y\in B|X=x]$ is a measure on $\mathbb R$ . Thus a density of this measure would rather be a map such that $P[Y\in B|X=x]=\int _B g_x(y)\lambda (dy)$ But the equation seems to show something else? What does it say? ( It looks more like $\int f_{Y|X}(x,y)\lambda (dy)$ is a density of $P_{(X,Y)}$ w.r.t. $P_X$ ) Thanks in advance!",['probability-theory']
3141139,calculate the surface area of the part of a cylinder $ x^2 + (y-1)^2 = 1 $ that is inside the sphere $ x^2 + y^2 + z^2 = 4 $.,"calculate the surface area of the part of a cylinder $ x^2 + (y-1)^2 = 1 $ that is inside the sphere $  x^2 + y^2 + z^2 = 4 $ . my trial : The Domain of integration on the YZ plane is : solving : (*) $  x^2 + (y-1)^2 = 1 $ $ x^2 + (y)^2 + z^2 \leq 4 $ We get : $ 0 \leq z \leq \sqrt{4-2y}$ and $ -2 \leq y \leq 2 $ $||\nabla{Cylinder(x,y,z)}|| = ||(2x,2(y-1),0)|| = 2 ~$ see(*) S = $2~\int_{-2}^{2}\int_{0}^{\sqrt{4-2y}}~~2~dydz$ ( by symmetry *2) I also tried solving by parmetrization and i didn't get the same answer i really need HELP is this way alright ? or is there something wrong","['multivariable-calculus', 'surface-integrals', 'surfaces']"
3141146,Finding the minimum value of a function without using Calculus,"Find the minimum value the function $f(x) = x^4 + \frac{1}{x^2}$ when $x \in \Bbb R^*$ My attempt: Finding the minimum value of this function using calculus is a piece of cake. But since this question appeared on my test when Calculus was not taught to me, there must definitely be a way (Probably by purely using Algebra) to find the minimum value of this function without using Calculus which I am unaware of. I tried making perfect squares but that got me nowhere. Maybe, I wasn't making the perfect, perfect square :) Any help would be appreciated.","['maxima-minima', 'functions']"
3141147,Derivative of the definite integral,"I have to find the derivative for $$\int_{-1}^x \frac{t^2}{t^2+4}dt-\int_{3}^x \frac{t^2}{t^2+4}dt$$ When I calculate their derivative separately $$\frac {d}{dt} \left(\int_{-1}^x \frac{t^2}{t^2+4}dt\right)-\frac {d}{dt}\left(\int_{3}^x \frac{t^2}{t^2+4}dt\right)$$ it gives me the right result, that is $0$ . But according to the law of additive \begin{aligned}
&\int_{-1}^x \frac{t^2}{t^2+4}dt-\int_{3}^x \frac{t^2}{t^2+4}dt \\
= & \int_{-1}^x \frac{t^2}{t^2+4}dt+\int_{x}^3 \frac{t^2}{t^2+4}dt \\= &\int_{-1}^3 \frac{t^2}{t^2+4}dt \\[2em]
\end{aligned} $$d/dt\int_{-1}^3 \frac{t^2}{t^2+4}dt = \frac{3^2}{3^2+4} = \frac 9{13}$$ Thanks.","['definite-integrals', 'derivatives']"
3141213,Why does the following not show $\zeta(0) = -\frac{1}{2}$?,"I am trying to evaluate the $\zeta(s)$ at $s=0$ , but I am not sure what is incorrect about the following? \begin{equation*} \label{eq:RiemannzetaFinal}
    \zeta(s) = 2^s\pi^{s-1}\sin \Bigl(\frac{s\pi}{2}\Bigr)\Gamma(1-s)\zeta(1-s), \text{ for } \Re(s) \leq 1 \text{ and } s \neq 0,1. \tag{1}
\end{equation*} Taking the limit of $(1)$ , as $s \to 0$ , \begin{align} \label{eq:Limit1}
    \zeta(0) & = \lim_{s \to 0} \Bigl[ 2^s\pi^{s-1}\sin \Bigl(\frac{s\pi}{2}\Bigr)\Gamma(1-s)\zeta(1-s) \Bigr] \nonumber \\
            & = \frac{1}{\pi} \cdot \lim_{s \to 0}\Bigl[ \sin \Bigl(\frac{s\pi}{2}\Bigr) \zeta(1-s) \Bigr].
\end{align} Writing $\zeta(1-s)$ in terms of its Laurent expansion, about the simple pole $s_0=1$ with residue $1$ and writing the series expansion of $\sin \bigl(\frac{s\pi}{2} \bigr)$ : \begin{align}
    \zeta(0) & = \frac{1}{\pi} \cdot \lim_{s \to 0} \Biggl[\Bigl( \frac{s\pi}{2} - \frac{(s\pi)^3}{48} + \dotsb \Bigr)  \Bigl(\frac{1}{s-1}+ a_0 + a_1(s-1) + a_2(s-1)^2 + \dotsb \Bigr)\Biggr] \nonumber \\
    & = \frac{1}{\pi} \cdot \frac{\pi}{2} \cdot \lim_{s \to 0} \Biggl[\Bigl( s - \frac{s^3\pi^2}{24} + \dotsb \Bigr)  \Bigl(\frac{1}{s-1}+ a_0 + a_1(s-1) + a_2(s-1)^2 + \dotsb \Bigr)\Biggr] \nonumber \\
    & = \frac{1}{2} \cdot \lim_{s \to 0} \Biggl[ \frac{s}{s-1} + \mathcal{O}(s) \Biggr] \nonumber \\
    & = 0?\nonumber
\end{align}","['complex-analysis', 'limits', 'riemann-zeta']"
3141254,Riemann integral of a function with Banach space values,"My question is: how to prove that Riemann integral of a continuous function $f\colon [a,b]\to Y$ , where $Y$ is a Banach space, is independent of the choice of intermediate points? Let $\{t_0,...,t_n\}\subset [a,b]$ be such that $a=t_0\le t_1\le...\le t_n=b$ and $\Delta Z_n=\max_{i\in\{i,...n\}}(t_i-t_{i-1})\to0$ as $n\to\infty$ . Let $S_{Z_{n}}=\sum_{i=1}^{n}f(x_i)(t_i-t_{i-1})$ , where $x_i\in [t_i-t_{i-1}]$ . I define the Riemann integral by $$\int_{a}^{b}f(t)\,dt :=\lim_{n\to\infty}S_{Z_{n}}.$$ First of all we notice that the function $[a,b]\ni t\mapsto\|f(t)\|$ is continuous on a compact set, so it is bounded. Hence $$\lim_{n\to\infty}S_{Z_{n}}\le \sup_{t\in [a,b]}\|f(t)\|\cdot\lambda([a,b])=M<\infty,$$ where $\lambda$ is meant to be Lebesgue measure. In order to justify the definition of Riemann integral I have to do two things. First, I need to prove that the limit $\lim_{n\to\infty}S_{Z_{n}}$ exists and secondly that the integral  is independent of the choice of intermediate points. We can prove it at one go by showing that the sequance $(S_{Z_{n}})$ is Cauchy I suppose. We shall prove that $\|S_{Z_{n}}-S_{Z_{m}}\|\to 0$ . Consider $$\|S_{Z_{n}}-S_{Z_{m}}\|=\|\sum_{i=1}^{n}f(x_{n,i})(t_{n,i}-t_{n, i-1})-\sum_{j=1}^{m}f(x_{m,j})(t_{m,j}-t_{m, i-j})\|\le\\
\le\sum_{i=1}^{n}\sum_{j=1}^{m}\|f(x_{n,i})-f(x_{m,j})\|\,\lambda([t_{n,i}-t_{n,i-1}]\cap [t_{m,j}-t_{m,j-1}])\le\\
\le \sum_{i=1}^{n}\sum_{j=1}^{m}\|f(x_{n,i})-f(x_{m,j})\|\max\{\Delta Z_{n}, \Delta Z'_{m}\}.
$$ Unfortunately, I can't deduce the desired convergance, since I have no info about the ratio of convergance of $\max\{\Delta Z_{n}, \Delta Z'_{m}\}$ . As concerns $\|f(x_{n,i})-f(x_{m,j})\|$ , we can easily estimate it from above or maybe it would be more sufficient to use the fact that $t\mapsto\|f(t)\|$ is uniformly continuous. What shall I do?","['integration', 'analysis', 'real-analysis']"
3141265,Electric field and curvature,"My physic teacher said that In a conductor the electric field, which is non-zero only on the surface, is stronger where the curvature is bigger*. But he did not provide a mathematical proof for this. Furthermore, I don't know the correct statement of this proposition: does curvature mean Gaussian curvature? And which are the hypotheses? Is the statement true for every equipotential surface? I am asking for The correct and complete statement; The proof (or a reference for the proof). Thanks in advance. EDIT That doesn't mean that the field is proportional to curvature. It means: if we pick two points A and B, and in A the curvature is bigger than in B, then the electric field in A will be stronger than in B.","['surfaces', 'vector-fields', 'curvature', 'physics', 'differential-geometry']"
3141280,"The ""range"" and ""image"" of a transformation refer to the same thing, right?","I'm hoping this is true because I've been told that ""the rank of a transformation is the dimension of its image"", and also that ""the rank of a transformation is the dimension of its range"". This doesn't make sense if range and image aren't the same thing, so I'm just wanting to be completely sure. Furthermore, does codomain refer to the image of the transformation or to the vector space to which the images of the transformation are brought?","['matrix-rank', 'linear-algebra', 'linear-transformations']"
3141322,"The third dual can be ""decomposed"" with the dual and his annihilator","My teacher says that is an easy exercise to see that $X^{***}= X^* \bigoplus J(X)^\bot$ . That is, $X^*$ is complemented in $X^{***}$ and $J(X)^\bot$ is the topological complement. 
Here $J$ is the canonical James map $J:X\to X^{**}$ .
( I've already read other similar questions on this forum, but they did not help me )","['banach-spaces', 'normed-spaces', 'functional-analysis']"
3141354,Show a specially defined matrix is positive definite,"Let $E_1, ..., E_n$ be non empty finite sets. Show that the matrix $A = (A_{ij})_{1 \leq i, j \leq n}$ defined by $A_{ij} = \dfrac{|E_i \cap E_j|}{|E_i \cup E_j|}$ , is positive semi-definite. This is part 5 of Exercise 1 in http://members.cbio.mines-paristech.fr/~jvert/svn/kernelcourse/homework/2019mva/hw.pdf . I start with the definition but it doesn't seem very promising. Any hint, please?","['matrices', 'linear-algebra', 'combinatorics', 'symmetric-matrices', 'positive-definite']"
3141361,Proof that $\lim\limits_{x\to \infty} (1+\frac{1}{\ln x})^x = \infty$,"I have been trying to prove that $$ \lim\limits_{x\to \infty} (1+\frac{1}{\ln x})^x = \infty $$ and this is what I got: $$ \lim\limits_{x\to \infty} (1+\frac{1}{\ln x})^x =
\lim\limits_{x\to \infty} e^{\ln (1+\frac{1}{\ln x})^x} = \lim\limits_{x\to \infty} e^{x * \ln (1+\frac{1}{\ln x})}  
$$ Then due to the fact that the e function is continuous and that $a*b=\frac{a}{\frac1b}$ $$
=  e^{ \lim\limits_{x\to \infty} \frac{\ln (1+\frac{1}{\ln x})}{\frac1x} }  
$$ Since both the top and the bottom go to 0 as ${x\to \infty}$ we can apply L'Hospital and after deriving both we get $$
e^{ \lim\limits_{x\to \infty} \frac{-\frac{1}{x*\ln x+x*\ln^2 x}}{-\frac{1}{x^2}}} = 
e^{ \lim\limits_{x\to \infty} \frac{x^2}{x*(\ln x+\ln^2 x)}} =
e^{ \lim\limits_{x\to \infty} \frac{x}{\ln x+\ln^2 x}}
$$ and then since the x function grows much more rapidly than the logarithmic functions at any power, we get $$
e^{ \lim\limits_{x\to \infty} \frac{x}{\ln x+\ln^2 x}} = e^{\infty} = \infty 
$$ Since I am quite new to calculus I don't feel sure at all about what I just did so it would be great if I could get some feedback from experienced people.
Also it's my first post here, I hope I didn't break any rule.
In the meantime, I wish everyone a nice day.","['logarithms', 'calculus', 'limits', 'derivatives', 'exponential-function']"
