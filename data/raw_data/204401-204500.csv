question_id,title,body,tags
4049174,Total convergence of a function series,"Let us consider the following function series: $$ \sum_{n=1}^{\infty} \frac{1}{n^x + n^{-x}}.$$ It seems that there is total convergence in $(- \infty, -1-\delta] \cup [1+ \delta, + \infty)$ for $\delta > 0$ . Thank-you in advance for any help!","['summation', 'functions', 'convergence-divergence']"
4049182,Looking for an other method to compare $100!$ and $50^{100}$,"There is a question asked me to compare $100! \ and \ 50^{100}$ . I think more than 2 hours to solve it.
I show my work below, but I looking for other Ideas to prove the inequality.  Thanks in advance for any hints or new Ideas. my work : $$50 \times 50 >  1 \times 99 \times 2\\
50 \times 50 > \ 2 \times 98\\
50 \times 50 > \ 3 \times 97\\
50 \times 50 > \ 4 \times 96\\ \vdots \\
50 \times 50 > \ 48 \times 52=(50+2)(50-2)=50^2-4\\
50 \times 50 > \ 49 \times 51=(50+1)(50-1)=50^2-1\\
50 \times 50 \geq 50 \times 50 $$ then multiply them $$50^{49}\times 50^{49}\times 50^2 >1.2.3...50....99.(2.50)\\50^{100}>100!$$ Remark: I use numerical approximation for $50^{100}\sim 7.8886\times 10^{169} $ and $100!=9.33236\times 10^{157}$ But is not interesting( Ithink).","['elementary-number-theory', 'algebra-precalculus', 'factorial', 'inequality']"
4049200,Understanding Higher-order Differentiability Conceptually,"I understand conceptually that a function $f\colon A\to\mathbf R$ is differentiable at a point $a\in A$ if it can be well approximated by a line there; more precisely, if we can find a constant $f'(a)$ such that $$f(a+h) = f(a) + f'(a)h+o(h).$$ My goal: I want to understand (intuitively) what it means when a function is twice differentiable, or thrice, etc, and likewise what it means when it isn't. In a very loose sense, I have the intuition that a function is somehow smooth er around a point if it has higher order differentiability there, and I suppose this somehow corresponds to the fact that it can be approximated well not only by a line but even better by a polynomial. (e.g. twice differentiability is $f(a+h) = f(a) + f'(a)h + \tfrac12f''(a)h^2 + o(h^2)$ , etc.). Does this mean polynomials canonically define the notion of ""smoothness""? Perhaps I can best get across what I'm asking for with an example. When I look at the graphs of $$y=x|x| \qquad \text{and} \qquad y=x^3$$ for instance, I see that the latter grows quicker than the former, but around zero, they both basically look ""smooth"" to me. Yes I know that one is made of the absolute value function which is pointy, but if you just showed me these two pictures: I wouldn't really feel that one is somehow ""smoother"" around zero than the other. Is there a better way I can think about this?","['calculus', 'derivatives', 'real-analysis']"
4049219,"Derive $\int_0^1 \frac{\ln(\sqrt2-1)-(\sqrt2-x)\ln x}{(\sqrt2-x)^2-1}\,dx=\frac{\pi^2}6+\frac14\ln^2(\sqrt2-1) $","I obtained the integral $$\int_0^1 \frac{\ln(\sqrt2-1)-\ln(x)(\sqrt2-x)}{(\sqrt2-x)^2-1}\,dx=\frac{\pi^2}6+\frac14\ln^2(\sqrt2-1)
$$ as a by-product while carrying out some complex analysis on an engineering problem. In short, given the real nature of the physical outcome, the imaginary part of the final expression has to vanish, which implies the result above and is numerically verifiable. However, the complex method employed is not intended to solve integrals such as this and produces it merely by accident. So, the question is: How to derive this elementary close-form directly, with real methods? Note that the integrand may not look as innocent as it appears. There is a hole as the denominator becomes zero at $x=\sqrt2-1$ and the term $\ln(\sqrt2-1)$ is present in the numerator to remove the singularity, thus ensuring convergence.","['integration', 'calculus', 'polylogarithm', 'improper-integrals']"
4049239,Creating a function based on specific values and derivatives. [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question The specific question asks me to sketch a possible graph with the following 4 conditions: F'(x)>0 on -2<x<1 F'(x)<0 on x<-2 and x>1 F(-2)=-3 F(1)=4 Now I know how to get the first two on their own, but the problem comes in trying to find an equation that will allow both the first and second pair of conditions to be realized. Is there a way to derive an equation from these conditions without creating an antiderivative, and then modifying it and guessing whether or not it will work?","['calculus', 'derivatives']"
4049267,N'th derivative of $f(x)$ to the power of $g(x)$,"I am trying to find a formula for the $n$ 'th derivative of $f(x)^{g(x)}$ .  I have tried using the formula bellow along with Leibniz rule without success. $$D^n(f(g(x)))=\sum_{k=0}^{n-1} \binom {n-1}{k}D^{\left(n-k\right)}g\left(x\right)D^{\left(k\right)}\left(f'\left(g\left(x\right)\right)\right)$$ This is how I went about it: Let $y=f(x)^{g(x)}$ This implies $\frac{y^\prime}{y}=g^\prime(x)\ln(f(x))+g(x)f^\prime(x)f(x)^{-1}$ Now, using Leibniz rule on the LHS as well as on the RHS (multiple times on the RHS since there is more than two functions multiplied) followed by the equation above for the $\ln(f(x))$ I got a long formula wich can be rearranged to obtain the value of $D^ny$ , however it could be easily seen it didn't work for a lot of functions in the form $f(x)^{g(x)}$ . Is there a well known formula for what I am trying to find? Or does the method I am trying to use fail at some stage?","['calculus', 'functions', 'derivatives', 'summation']"
4049273,Prove subset sum of squares errors are less than sum of squares error of the original set,"As part of a proof I'd like to show if $R_1 \cup R_2 \subseteq R_3$ , then $SSE(R_1) + SSE(R_2) \leq SSE(R_3)$ where SSE is the sum of squared deviations from the mean of each group.  I'm assuming the values of the group are real or rational numbers if that makes a difference. I know that since the mean minimizes the sum of squared errors, then each group must be minimized, I'm stuck on how to leverage the fact that the groups are subsets to show that $SSE(R_1 \cup R_2) \geq SSE(R_1) + SSE(R_2)$ .  Is there a basic piece of theory I am missing?  Any pointers would be appreciated!","['sums-of-squares', 'statistics', 'proof-writing']"
4049280,correlation between three variables -1 to 1,"Let $X,Y,Z$ be 3 random variables. If the correlation between $X$ and $Y $ is $c_1\ge 0$ and the correlation between $Y$ and $Z$ is $c_2\ge 0$ , what is the maximum and minimum possible correlation between $X$ and $Z$ in terms of $c_1$ and $c_2$ ? Show your work. So what I've figured out is that from the geometric interpretation of this, the min is -1 and max is 1. Use the dot product: x goes 'right', y goes 'up' z goes 'left'. This implies that the product between X and Y is 0 and Y and Z is 0, but X and Z is -1 (they are opp directions). So the minimum must be -1. The max must be 1 since we know that is the max value of correlation and there is no upper bound here. So we know the absolute max and min, but I'm having trouble sorting it in terms of $c_1$ and $c_2$ here. thanks",['discrete-mathematics']
4049282,"Why is this the trick to calculate $m\, 9$s $\times n\, 9$s?","Here is what observed for the results of $m\, 9$ s $\times n\, 9$ s ( $m \leq n$ ) $9\times9=81, 9\times99=891, 9\times999=8991$ $99\times99=9801, 99\times 999=98901, 99\times9999=989901$ $999\times999=998001,999\times 9999=9989001, 999\times99999=99899001$ Summarize the following trick  to get the result fast: For example to get $999\times99999 =99899001$ Write down $n\,$$9$ s $(n=5)$ first : $\to 99999$ Replace the $m\,$ th $(m=3) 9\,$ s with $8: \to 99899$ Attach $ (m-1)\, 0$ s $(m-1=2): \to 99899 00$ Attach last $1: \to  99899 00 1$ My question is how to prove this is true with algebra?","['algebra-precalculus', 'arithmetic']"
4049290,Which $N$ are multiples of $2020$ with all distinct digits where swapping any two of them makes $N$ not a multiple of $2020$?,"The question I have attempted problem 3 from the Senior O-level Tournament of Towns paper, Fall 2020 . The question is as follows: A positive integer number N is divisible by 2020. All its digits are
different and if any two of them are swapped, the resulting number is
not divisible by 2020. How many digits can such a number N have? Sergey Tokarev My attempt Let $n$ be the number of digits of $N$ . I initially noticed that $4 \leq n \leq 10$ , since for all digits of $N$ to be distinct we can have at most $10$ digits. This gave me the impression that this problem could be solved by investigating each of these cases. Let us first write $N$ as $2020k = 2000k + 20k$ . Let $2k$ have digits $d_1d_2\cdots d_m$ , then $N = (d_1d_2\cdots d_m)000 + (d_1d_2\cdots d_m)0$ . Case n = 4: Then $2k = d_1$ and $N = d_1000 + d_10 = d_10d_10$ , so $N$ must have a repeating digit. Case n = 5: Then $2k = d_1d_2$ and $N =d_1d_1000 + d_1d_20 = d_1d_2d_1d_20$ , so $N$ must have a repeating digit. Case n = 6: Then $2k = d_1d_2d_3$ and $N = d_1d_2d_3000 + d_1d_2d_30 = d_1d_2(d_3 + d_1)d_2d_30$ , so $N$ must have a repeating digit. This argument no longer works for $n \geq 7$ . But we do know that $d_m \in \{0, 2, 4, 6, 8\}$ since $2k = d_1d_2\cdots d_m$ , and $N$ must end in $0$ . I used this to find numbers for $n = 7, 8, 9$ and $10$ with all distinct digits that are also divisible by $2020$ because they satisfy the observations listed above. \begin{array}{|c|c|c|c|}
\hline
 n & 7 & 8 & 9 & 10\ \\ \hline
 N & 4981320 & 64975320 & 869753420 & 2537618940 \\ \hline
\end{array} Claim: If $N$ is a multiple of $2020$ and has all distinct digits, then swapping any two digits results in a number $N'$ where $2020 \not \mid N'$ . proof . Let $N = a_na_{n-1}\cdots a_j\cdots a_i\cdots a_1$ and $N' = a_na_{n-1}\cdots a_i\cdots a_j\cdots a_1$ for any $i < j$ . If $2020 \mid (N' - N)$ then $2020 \mid N'$ . Suppose, WLOG, that $a_i > a_j$ so that $N' > N$ , then $$N' - N = 10^{j - 1}(a_i - a_j) - 10^{i - 1}(a_i - a_j) = (a_i - a_j)(10^{j - 1} - 10^{i - 1})$$ So $N' - N$ must be a multiple of $10$ . Therefore, for the claim to hold, $N'$ must not be a multiple of $4$ or $101$ , since $2020 = 2^2 \times 5 \times 101$ . We know that $1 \leq a_i - a_j \leq 9$ , thus we can safely conclude that $N' - N$ is never a multiple of $101$ . Therefore, $2020 \not \mid (N' - N)$ . Therefore, $N$ can have $7, 8, 9$ or $10$ digits and we are done. I think my solution is correct, but I don't like that I had to manually find $N$ 's for $7 \leq n \leq 10$ . Is there a different way to argue for those cases or a more systematic way to find $N$ 's for those cases? Or if you have a different way to solve the problem, I would also like to see it.","['contest-math', 'number-theory', 'solution-verification', 'recreational-mathematics', 'problem-solving']"
4049293,Towards a consistent notation for entropy and cross-entropy,"I am learning about the cross entropy, defined by Wikipedia as $$H(P,Q)=-\text{E}_P[\log Q]$$ for distributions $P,Q$ . I'm not happy with that notation, because it implies symmetry, $H(X,Y)$ is often used for the joint entropy and lastly, I want to use a notation which is consistent with the notation for entropy: $$H(X)=-\text{E}_P[\log P(X)]$$ When dealing with multiple distributions, I like to write $H_P(X)$ so it's clear with respect to which distribution I'm taking the entropy. When dealing with multiple random variables, it thinks it's sensible to make precise the random variable with respect to which the expectation is taken by using the subscript $_{X\sim P}$ . My notation for entropy thus becomes $$H_{X\sim P}(X)=-\text{E}_{X\sim P}[\log P(X)]$$ Now comes the point I don't understand about the definition of cross entropy: Why doesn't it reference a random variable $X$ ? Applying analogous reasoning as above, I would assume that cross entropy has the form \begin{equation}H_{X\sim P}(Q(X))=-\text{E}_{X\sim P}[\log Q(X)]\tag{1}\end{equation} however, Wikipedia makes no mention of any such random variable $X$ in the article on cross entropy. It speaks of the cross-entropy between two probability distributions $p$ and $q$ which, like the notation $H(P,Q)$ , implies a function whose argument is a pair of distributions, whereas entropy $H(X)$ is said to be a function of a random variable. In any case, to take an expected value I need a (function of) a random variable, which $P$ and $Q$ are not. Comparing the definitions for the discrete case: $$H(p,q)=-\sum_{x\in\mathcal{X}}p(x)\log q(x)$$ and $$H(X)=-\sum_{i=1}^n P(x_i)\log P(x_i)$$ where $\mathcal{X}$ is the support of $P$ and $Q$ , there would only be a qualitative difference if the events $x_i$ didn't cover the whole support (though I could just choose an $X$ which does). My questions boil down to the following: Where is the random variable necessary to take the expected value which is used to define the cross entropy $H(P,Q)=-\text{E}_{P}[\log Q]$ If I am correct in my assumption that one needs to choose a random variable $X$ to compute the cross entropy, is the notation I used for (1) free of ambiguities.","['entropy', 'information-theory', 'notation', 'probability-theory', 'probability']"
4049294,"Vakil 14.2 isomorphism of the pair (invertible sheaf, rational section)","In Vakil's chapter 14 of ""The Rising Sea"", he talks about a map from invertible sheaves to divisors. Specifically, for a Noetherian irreducible (can be relaxed apparently) scheme regular in codimension one, it makes sense to talk about the divisor of a rational section $s$ of an invertible sheaf $\mathcal{L}$ . He then has a map: $$\{(\mathcal{L}, s)\}/ \text{isomorphism} \rightarrow \operatorname{Weil} X$$ I am not sure what this isomorphism of a pair $(\mathcal{L}, s)$ is supposed to mean. One way to interpret it is that two such pairs are isomorphic if there is sheaf isomorphism which takes one section to another.  But I don't think that's all there is to it, because we also have the case when we can extend a rational section to a bigger open set and in that case it is still supposed to be from the same isomorphism class. So what is it? Another way to think of it was along the lines of rational functions.  And I haven't studied the non-irreducible case but in case of irreducible scheme rational functions have a natural notion of ""isomorphism"" in the sense that they are same if they map to the same element in the function field.  Is there a similar notion for invertible sheaves?  Do we similarly have an injective map from regular sections on open sets to the stalk of the invertible sheaf at the generic point? Edit: In the last paragraph, I mean function field of an integral scheme, not just irreducible.","['divisors-algebraic-geometry', 'algebraic-geometry']"
4049304,A countable compact set has infinitely many isolated points,"I tried to prove that if $(X, d)$ is a complete metric space and $K$ a compact countable subset of $X$ , then $K$ has infinite many isolated points. I tried to prove it with Baire's Theorem but I can't.
My try: By reduction to the absurd, suppose that $ K $ has finitely many isolated points, that is, $ K \setminus K '=\{x_0, x_1, \ldots, x_n \} $ . Note that, \begin{align*}
    K \setminus \{x_0, x_1, \ldots, x_n \} & = K \setminus (K \setminus K ') \\
    & = K \cap (K^c \cup K') = K \cap K'
\end{align*} On the other hand, we have that $ K $ and $ K'$ are closed, therefore, $ K \cap K' $ also is, and therefore this set is complete. For all $ i \in \mathbb{N} $ such that $ 0 \leq i \leq n $ , we have that $ M_i = K \setminus \{x_i\} $ is an open set for the induced topology on $ K $ , moreover, $ \overline{M_i} \cap K = K $ , that is, $ M_i $ is dense in $ K $ . With this, $ \{M_k \}_{k = 0} ^ n $ is a family of open and dense sets in $ K $ , since $ K $ is closed, $ K $ is complete. Thus, using the Baire Category Theorem, we have that $ \overline{\displaystyle \bigcap_{k = 0}^n M_k} = K $ , but $ \displaystyle \bigcap_{k = 0}^n M_k =\emptyset $ , which is a contradiction. I note that $ \overline{M_i} \cap K = K $ this could be false and I do not use that $K$ is countable. Any help will be of use, thank you very much.","['general-topology', 'complete-spaces', 'baire-category', 'metric-spaces']"
4049312,Conditional expectation given sum,"There are two random variables $X$ and $Y$ , both of them distributed standard normal. Based on $X$ and $Y$ , define $Z = X + a  Y$ for $a$ a known parameter. I'm interested in $E(X | Z)$ . It seems to me that a starting point could be the approach taken here . So I start with: $ Z = E( X | Z) + a E(Y | Z) $ and then I write out the expectation terms explicitly, hoping to find an easy substitution: $ E(X | Z) = \frac{\int_{-\infty}^{\infty}x f(x)f(\frac{Z-x}{a})dx}{\int_{-\infty}^{\infty} f(x)f(\frac{Z-x}{a})dx} $ and $ E(Y | Z) = \frac{\int_{-\infty}^{\infty}y f(y)f(Z-ay)dy}{\int_{-\infty}^{\infty} f(y)f(Z-ay)dy} $ But here I'm stuck, I can't find an substition that would allow me to express $E(Y|Z)$ in terms of $E(X|Z)$ , in order to plug in above. So how to continue from here? Edit: For $a =1$ , one can simply use $E(X|Z) = E(Y | Z)$ , plug in above, and obtain $E(X|Z) = Z/2$ . I conjecture that in general, it holds that $$E(X|Z) = \frac{Z}{1 + a^2}.$$ This is supported by several numerical simulations I made. This would require showing that $E(Y|Z) = a E(X | Z)$ . In case substituting in the integral does not help, how else could I show that?","['statistics', 'conditional-expectation', 'probability']"
4049320,Nontrivial periodic solutions of second order ODE,"We consider the ODE $$x''(t)+x^3(t)=0.$$ Clearly, $x\equiv 0$ is a solution. But also, numerically solving this ODE shows that nontrivial periodic solutions exist, too. I am interested in proving the statement that the above ODE has a nontrivial periodic (say, $2\pi$ periodic) solution. How does one go about proving such a statement?","['analysis', 'ordinary-differential-equations']"
4049366,Normed Space $L^2$ and Vector Space $l^2$,"I am really confused about $L^2$ -Space and $l^2$ -Space. Can anybody explain what is the difference between the $L^p$ and $l^p$ space? Also in $L^p$ -Spaces, we see that $L^2 \subset L^1$ (for $L^2[(0,T_f)], T_f >0 $ ). On the other hand for $l^p$ -Spaces, we see that $l^1 \subseteq l^2$ . How can we show that $l^1 \subseteq l^2$ ? I don't understand why(/how) does the subset sign change for the two different cases. Thanks in advance.","['normed-spaces', 'functional-analysis']"
4049421,Polynomial such that $e^{2i\pi P(n)} \rightarrow 1$,"here is a  problem i’ve been having quite a lot of trouble with . Let $P$ be a polynomial such that the sequence $e^{2i\pi P(n)}$ converges to 1 $(i^2=-1).$ Show that $\forall n ,P(n)$ is an integer. Taking the imaginary part we are left with some $P$ polynomial such that $$\sin(2\pi P(n))\rightarrow0$$ But a half angle factorization also gives  that: $$\sin(\pi P(n))\rightarrow 0$$ And we wish to force P to , i guess even if it’s not equivalent, to have only integers coefficients. May you help me please.","['periodic-functions', 'integers', 'real-analysis', 'polynomials', 'sequences-and-series']"
4049430,Sum of residue systems is complete iff they are both complete,"Let $p$ and $q$ be distinct prime numbers. The integers $a_1, \ldots, a_p$ and $b_1,\ldots,b_q$ are such that the sums $a_i + b_j$ form a complete residue system modulo $pq$ (that is, there is precisely one sum which is $0$ mod $pq$ , precisely one which is $1$ mod $pq$ , etc.). Prove that $a_1,\ldots,a_p$ form a complete residue system mod $p$ and $b_1,\ldots,b_q$ form a complete residue system mod $q$ . Any idea on how to approach this? Any help appreciated!","['number-theory', 'reduced-residue-system', 'modular-arithmetic', 'elementary-number-theory']"
4049469,Finite rank nilpotent operators,"Let $H$ be a separable complex Hilbert space Let $\mathcal{F(H)} =\{T \in \mathcal{B(H)}: \text{rank}(T) < \infty \}$ , and $\mathcal{N(H)} = \{ T \in \mathcal{F(H)}: T^k=0 \text{ for some }  k \in \mathbb{N} \}$ Find the norm closure $\overline{\mathcal{N(H)}}$ . Ideas: I know that $\overline{\mathcal{F(H)}} = \mathcal{K(H)}$ , where $\mathcal{K(H)}$ is the set of compact operators. So the closure will be some compact operators. And $\mathcal{N(H)} \subset \mathcal{K(H)} $ . Also, through some research, I've found that the quasinilpotnets are limits of nilpotent. So I'm suspecting the that the norm close of finite rank nilpotents will be compact and quasinilpotents. Any help will be appreciated! Thank you in advance!","['operator-theory', 'compact-operators', 'functional-analysis', 'operator-algebras']"
4049481,Adjoint map $\text{Ad}:G\rightarrow \text{Aut}(\mathfrak{g})$ is smooth.,"Let $G$ be a lie group and let $\mathfrak{g}$ its lie algebra. Its not clear to me that $\text{Ad}:G\rightarrow \text{Aut}(\mathfrak{g})$ is smooth. It is clear to me that if we have a matrix group any $g\in G$ gives that $\text{Ad}(g)$ is smooth. Because $Ad(g)Y=gYg^{-1}$ consists of rational polynomials in each entry. However this does not tell us that $Ad$ is smooth,  only that it sends each $g$ to a smooth. How can we see that $Ad:G\rightarrow \text{Aut}(\mathfrak{g})$ is smooth? One approach might be to use that it is a group homomorphism between lie groups and then we need only show that it is continuous. I do not think this question is a duplicate of ( Adjoint action smooth (in Tapp's book)? ) because it seems to me that this question on explains why each $\text{Ad}(g)$ is smooth, not $\text{Ad}$","['smooth-manifolds', 'lie-algebras', 'lie-groups', 'differential-geometry']"
4049486,"Let $f:\mathbb{R} \to \mathbb{R}$ continuous with $f(f(x))=e^x$, show that $\lim_{x\to \infty } \frac{f(x)}{x^n}=\infty$ (Brazilian Olympiad)","Given $f:\mathbb{R} \to \mathbb{R}$ continuous with $f(f(x))=e^x$ for all $x\in\mathbb{R}$ . Show that $\lim_{x\to \infty } \frac{f(x)}{x^n}=\infty$ for all $n\in\mathbb{N}$ . I appreciate any help! Edit 1: It is easy to see that $f$ is injective. So, if $f$ increases anywhere, $f$ will be an increasing function. Edit 2: As said in the comments, $f$ must indeed be increasing, since $f(1)=f(e^0)=f(f(f(0)))=e^{f(0)}>f(0)$ .","['contest-math', 'limits', 'functional-equations', 'real-analysis']"
4049488,"I need a limit definition for the Hessian, does this work?","Let $f: \mathbb{R}^n \to \mathbb{R}$ be of class $C^2$ . Let $x$ be a non-degenerate critical point of $f$ . Prove that there is an open neighborhood of $x$ which contains no other critical points of $f$ . $\textbf{Proof:}$ Suppose the contrary. Then for every $n \in \mathbb{Z}_+$ there is an $x_n \in B\left(x,\frac{1}{n}\right)$ , which is a critical point of $f$ not equal to $x$ . So $x_n$ converge to $x$ . Now let $v_n = \frac{x_n - x}{||x_n-x||}$ . Let us just assume $v_n$ converges to some $v \in \mathbb{S}^{n-1}$ (since $v_n$ is a bounded sequence, it has a convergent subsequence). So by the definition of the Frechet derivative, and since $x_n \to x$ , we have that \begin{align*}
0 &= \lim_{n\to\infty}  \frac{||Df(x_n) - Df(x) - D^2f(x)(x_n -x)||}{||x_n - x||}\\
  &=\lim_{n\to\infty}  \frac{||- D^2f(x)(x_n -x)||}{||x_n - x||}\\
  &=\lim_{n\to\infty}  ||D^2f(x)v_n||\\
  &= D^2f(x)v,
\end{align*} where we use the fact that $Df(x) = Df(x_n) = 0$ for all $n \in \mathbb{Z}_+$ ( $x$ and $x_n$ are critical points). This implies that $D^2f(x)v = 0$ , but since $x$ is a nondegenerate point, $D^2f(x)$ is invertible, and since $v \ne 0$ , we have a contradiction. Thus, there is an open neighborhood of $x$ that contains no other critical points of $f$ . Does this approach work? I am not sure if I used a correct definition for the Hessian. Also, I did not use that the Hessian is continuous, which worries me. Regardless of whether this is correct or not, is there a direct approach, or even maybe a more elegant one?","['analysis', 'real-analysis', 'multivariable-calculus', 'solution-verification', 'hessian-matrix']"
4049516,Set with a property,"This was a mock math olympiad problem sent to me by a friend. Let $P$ be a set of prime numbers. Then, create a set $S$ of positive integers that satisfies the following property: For every element $p \in P$ , $p$ is a factor of at least three elements in $S$ . Prove that for all sets $P$ and $S$ , it is possible to divide $S$ into 4 nonempty subsets such that each $p$ is a factor of at least three integers. I tried to consider the element $a \in P$ that was a factor of the least number of elements in $S$ and see what I could discover, but got nowhere. I also thought that perhaps some sort of algorithm would work too, but I didn't make any progress. Overall, I'm just not quite sure how to even start.","['contest-math', 'combinatorics']"
4049607,What is the covariance of the exponential of two jointly distributed normal random variables?,"Suppose I have the bivariate normal variable $[X \ \ Y]'$ which has mean $[\mu_X \ \ \mu_Y]'$ and covariance matrix $ \left[ \begin{array}{cc}
\sigma_X ^2 & \sigma_Y \ \sigma_X \ \\ 
\sigma_Y \ \sigma_X \ & \sigma_Y^2 
\end{array} \right]$ . I am trying to figure out what is $\text{Cov}(e^X, e^Y)$ . I'm aware of Stein's lemma which says $\text{Cov}(g(X), Y) = \text{Cov}(X,Y)E[g'(X)]$ , but I don't know how it's derived, or how to extend it to functions on both $X$ and $Y$ . Presumably this case should be simpler since it's the exponential function. Otherwise I'm unsure what other steps to take. I don't need to prove this, but the answer is necessary for a calculation I am doing.","['statistics', 'covariance', 'normal-distribution', 'probability']"
4049630,The inverse type of Bernhard Leeb's solution for IMO‐1983–inequality,"Given three side-lengths $a, b, c$ of a triangle. Prove that $$a^{2}b\left ( a- b \right )+ b^{2}c\left ( b- c \right )+ c^{2}a\left ( c- a \right )\geq 3\left ( a+ b- c \right )c\left ( a- b \right )\left ( b- c \right )$$ Source: StackMath/@haidangel ft.@tthnew I used discriminant to create this inequality, also $constant\!:\!=\!\!3$ is the best here. See_ on.StackMath , that's what I'm doing research on, of course this inequality is a result. Not an answer. I think we use Bernhard Leeb's result to help a real lot $$a^{2}b\left ( a- b \right )+ b^{2}c\left ( b- c \right )+ c^{2}a\left ( c- a \right ):= \left ( c+ a- b \right )\left ( c- a \right )^{2}b- \left ( b+ c- a \right )\left ( a- b \right )\left ( b- c \right )c$$","['triangle-inequality', 'discriminant', 'research', 'real-analysis', 'optimization']"
4049794,Number of ways to arrange 7 distinct objects in 10 distinct spots with constraints,"There are 7 distinct objects and 10 distinct spots numbered 1-10. Two of spots 7, 8, and 9 must be open. How many ways are there to arrange these objects? I was helping a friend with this problem and was struggling to understand why our solutions differ numerically. Here are our approaches. Solution 1: There are ${3 \choose 2}$ = 3 ways to select the blocked spots, leaving 8 spots open.
There are ${8 \choose 7}$ = 8 ways to select available spots. Multiply by 7! for the total = 24 * 7! = 120,960 Solution 2: Consider the total number of possibilities - all 3 filled - only 2 filled. Total: ${10 \choose 7}*7!$ = $\frac{10!}{3!}$ Choose the 7 spots and order the objects. 3 filled: $7 * 6* 5 * {7 \choose 4} * 4! = 7 * 6 * 5 * \frac{7!}{3!}$ Fill the 3 spots (7 choices for spot 1, 6 for 2, 5 for 3), leaving 7 spots available. Choose 4 from these 7 and order the remaining objects. Only 2 filled: ${3 \choose 2}*7*6*{7 \choose 5}*5! = 3 * 7 * 6 * \frac{7!}{2!}$ Choose the 2 spots to fill, and then fill them with the objects (7 choices for spot 1, 6 for 2). Finally, choose the 5 remaining spots from the 7 available and order the objects. There are only 7 available since we assume the third spot must be open. Result: $\frac{10!}{3!} - (7 * 6 * 5 * \frac{7!}{3!}) - (3 * 7 * 6 * \frac{7!}{2!})$ = 110,880 I believe Solution 1 is right, but I'm not sure what specifically is wrong with Solution 2. Shouldn't they produce the same number? If not, is Solution 1 wrong?","['combinatorics', 'discrete-mathematics']"
4049818,Generic smoothness in the analytic setting.,"If $X, Y$ are non-singular algebraic varieties over an algebraically closed field of characteristic 0, and $f: X \to Y$ is a morphism, then there exists a Zariski-open, non-empty subset $U \subset Y$ , such that $f^{-1}(U) \to U$ is a smooth morphism. I wonder: Is the same true if $X, Y$ are non-singular complex analytic spaces? I know that Sard's theorem shows that ""most"" fibers are smooth, in the sense that $f(\operatorname{Sing}(f)) \subset Y$ has Lebesgue measure $0$ . But is $f(\operatorname{Sing}(f))$ also contained in a Zariski-closed subset? If this is true, what is a good reference?","['zariski-topology', 'complex-geometry', 'algebraic-geometry']"
4049833,Show that the series of derivatives of an entire function converges,"I was asked to show that if $f(z)$ is holomorphic at a neighbourhood of $a$ , and $\sum_{n\geq0}f^{(n)}(a)$ converges, then $f$ is entire and $\sum_{n\geq0}f^{(n)}(z)$ converges for all z in the complex plane.It is easy to prove that $f$ is entire since $f^{(n)}(a)$ is bounded and $\frac{|z-a|^{n}}{n!}$ is smaller than a geometric sequence for sufficiently large $n$ .
I have trouble with the second assertion. I can only get the result when the convergence at $a$ is absolute. The method was shown Show that the series of derivatives of a certain entire function converges everywhere . But for the non-absolute convergent case, I don't know how to proceed.",['complex-analysis']
4049835,On using sine and cosine substitutions in integration,"When you make a substitution of the form $x=asin\theta$ for sines and cosines, shouldn't you check if the values of x on which we're integrating allows for it? Otherwise, if x becomes greater than |x|, wouldn't there be no possible values of $\theta$ ? This is how it seems to work in cases like $\sqrt{9-x^2}$ , where, it's obvious that you're safe with substituting $x=3 sin\theta$ or $x=3 
cos \theta$ , since x can't go beyond |3|. But I haven't heard of any explicit rule about this. Is there one, and if there isn't, why so?","['integration', 'indefinite-integrals', 'trigonometry', 'trigonometric-integrals']"
4049855,Example of a rank-one operator to satisfy conditions about the spectrum,"$U$ is defined to be a bilateral shift operator such that $Ue_n= u_ne_{n+1}$ for $n\in \mathbb{Z}$ , where $u_n \ne 1$ . I am looking for an example of $U$ and a rank-one operator $T \in \mathcal{B}(\ell^2(\mathbb{Z}))$ so that $\sigma (U) = \{ z \in \mathbb{C} : |z| = 1 \}$ and $\sigma(U+T)=  \{ z \in \mathbb{C} : |z| \le 1 \}$ . Some thoughts: I showed that for any bilateral shift $U$ with $Ue_n=u_ne_{n+1}$ for $n \in \mathbb{Z}$ such that $|u_n|=1$ , we have $ \sigma (U) = \{ z \in \mathbb{C} : |z| = 1 \}$ . Also, I saw it from here The spectrum of the operators $\sigma(U+T) = \sigma(U) \cup \sigma(T)  $ . So I wonder if I could find some rank one operator to satisfy the condition based on that. But other suggestions will also be great. Thank you.","['operator-theory', 'functional-analysis', 'operator-algebras']"
4049872,Counting squares in a part of a graph. What is the correct answer?,"Consider the following set of points in the $x - y$ plane: $$
A = \{(a,\ b)\ |\ a,\  b\in \mathbb{Z}, \ 1\leqslant a\leqslant9\quad \text{and} \quad 1\leqslant b\leqslant 5\}.
$$ Find the number of squares whose vertices are points in $A$ . I reached an answer but don't know if it's right or not. (The source doesn't give the answer) This reflects the essence of the approach. First, we draw the blue line and choose any $2$ points on it and that will trace a square. The picture depicts $2$ cases. (The squares on the blue line) Continuing this and advancing rightwards with every line before we reach the final yellow line, where one choice of points is absurd, because that square should go outside the figure itself. So, we have $6$ lines $5$ points long with one choice of points absurd so we need to exclude it. After the $6\cdot\binom{5}{2} - 1$ squares we have, we only have to count squares in the last $3$ columns of points. Working on with the exact same reason and we have the lines in green, again with one choice of points absurd. So, there are $4\cdot\binom{3}{2}-1$ squares, totaling $$6\cdot\binom{5}{2} + 4\cdot\binom{3}{2} - 2\ \text{squares} = 70\ \text{squares}$$ but I doubt the number is too small. What is the correct answer? How can it be reached? What will be the answer for the case when $0\leqslant a\leqslant9\ \text{and} \ 0\leqslant b\leqslant 5$ ? Thanks!","['combinations', 'combinatorics']"
4049887,Evaluating a definite integral by introducing change of variables,"In a Physics class, I encountered the following integral: $$\int_{0}^{\infty} \left(\frac{x^2}{\exp\left(x-a\right)+1}-\frac{x^2}{\exp\left(x+a\right)+1}\right)\,\mathrm{d}x\text{,}$$ where $a$ is a constant. It is stated to yield: $$\int_{0}^{\infty}\left(\frac{x^2}{\exp\left(x-a\right)+1}-\frac{x^2}{\exp\left(x+a\right)+1}\right)\,\mathrm{d}x=\frac{1}{3}\left[\pi^2a+a^3\right]$$ I first introduced a change of variables: $$y:=x-a$$ $$z:=x^\prime+a$$ This gives: $$\int_{0}^{\infty}\frac{x^2}{\exp\left(x-a\right)+1}\,\mathrm{d}x-\int_{0}^{\infty}\frac{\left(x^\prime\right)^2}{\exp\left(x^\prime+a\right)+1}\,\mathrm{d}x^\prime=\int_{-a}^{\infty}\frac{\left(y+a\right)^2}{e^y + 1}\,\mathrm{d}y-\int_{a}^{\infty}\frac{\left(z-a\right)^2}{e^z+1}\,\mathrm{d}z$$ However, when introduced to a computer, the definite integrals are stated to have no solution. I actually expected to get integrals of the form: $$\int_{0}^{\infty}\frac{y}{e^y+1}\,\mathrm{d}y=\frac{\pi^2}{12}$$ What am I missing here?","['integration', 'calculus', 'definite-integrals']"
4049940,How should I think about this ring?,"I don't know much abstract algebra or ring theory. I have come across a ring, and it would be really great if somebody could help me to understand what else in mathematics it relates to, or how to visualize what is going on in this ring (especially for multiplication). The underlying set is $\mathbb R \times \mathbb R,$ so the elements are pairs of real numbers. Addition of $(a,b)$ and $(c,d)$ is defined as $(a,b) \oplus (c,d) = (a + c, b + d).$ Multiplication of $(a,b)$ and $(c,d)$ is defined as $(a,b) \odot (c,d) = (a \times c, (a \times d) + (b \times c)).$ I noticed that if we write $(a,b)$ as $b/a$ then $\oplus$ and $\odot$ look like Farey addition, and standard fraction addition, respectively. Although I suspect somebody can point out much deeper relationships between this ring and other ideas from mathematics. I'm not even sure what the ring is called. It is mentioned in the Kock-Lawvere Axiom.","['ring-theory', 'abstract-algebra', 'synthetic-differential-geometry']"
4049946,The Infinitely Nested Radicals Problem and Ramanujan's wondrous formula,"In mathematics, a nested-radical is any expression where a radical (or root sign) is nested inside another radical, e.g. $\sqrt{2 + \sqrt{3}}$ . By extension, an infinitely nested radical (aka, a continued root) is an expression where infinitely many radical expressions are nested within each other. A famous example would be: $\sqrt{x\sqrt{x\sqrt{x \dots}}} = \sqrt{x x} = x, \forall x \in \mathbb{R}$ . Another common (and easy to solve) variety occurs when the pattern of numbers within the radicals follows a regular repeating pattern.
A simple example of this type is $y = \sqrt{2 + \sqrt{2 + \sqrt{2 + \dots}}} = \sqrt{2 + y} = 2$ . The key is simply to notice that the expression after one repeated cycle is the same as the original and solve the resulting polynomial equation. (A couple of examples here . However, while the above examples were simple, nested roots can actually be quite important and satisfying beyond the surface level. a) The Golden Ratio :
The Golden Ratio, $\phi = \frac{1 + \sqrt{5}}{2}$ is well-known for its regularity and recurring appearance is diverse areas of nature, art and mathematics. The famous continued fraction expression $\phi = 1 + \cfrac{1}{1+ \cfrac{1}{1 + \cdots}}$ is however, also equivalent to the folowing continued square root $\phi = \sqrt{1 + \sqrt{1+ \sqrt{1 + \dots}}}$ b) Viète's formula : An approximation for $\pi$ that has been called the starting point of mathematical analysis and even ""the dawn of modern mathematics"", the formula is: $$\frac{2}{\pi} = \frac{\sqrt{2}}{2} \cdot \frac{\sqrt{2 + \sqrt{2}}}{2} \cdot \frac{\sqrt{2 + \sqrt{2 + \sqrt{2}}}}{2} \cdot \dots$$ which already contains nested radicals. Interestingly, this can also be expressed as: $$\pi = \lim_{k\to\infty} 2^k\cdot\sqrt{2-\sqrt{2+\sqrt{2+... (\text{k - 1 times})}}}$$ which not only contains an infinitely nested radical, but it also contains the same elementary example $\sqrt{2+\sqrt{2 + \dots}}$ from above in slightly modified form! (c) All real numbers in the range $[0,2]$ can be expressed as the infinitely nested radical $\sqrt{2 \pm \sqrt{2 \pm \sqrt{2 \pm \dots}}}$ Examples: $2=\sqrt{2 + \sqrt{2 + \sqrt{2 + \dots}}}=(+)$ , $1=\sqrt{2 - \sqrt{2 - \sqrt{2 - \dots}}}=(-)$ , $\phi=\sqrt{2 + \sqrt{2 - \sqrt{2 + \sqrt{2 - \dots}}}}=(+-)$ (The Golden Ratio again!) (d) Infinitely nested equations are related to polynomial equations and can be sued to find their roots There can be many more examples of such problems. However, the difficult problem here is to solve non-repeating continued-roots such as $\sqrt{1 + \sqrt{2 + \sqrt{3 + \dots}}}$ . From a cursory look, one might even expect that expression might be divergent! However, it is actually the Nested Radical constant $1.757932 \dots$ (OEIS A072449), for which no closed-form expression is known. Thus, one can have an arbitrary continued-root, say $\sqrt{a_1 + b_1 \sqrt{a_2 + b_2 \sqrt{a_3 + b_3 \sqrt{a_4 + \dots}}}}$ , where the constants might be determined by some complicated set of rules of formulae. And even for the simplest non-repeating cases, one's ability to solve will be entirely dependent on the ability for algebraic manipulation and knowledge of diverse theorems which might sometimes help. Or so I believed ... Enter Srinivasa Ramanujan... In 1911, around 2 years before he first contacted Hardy, Ramanujan published the following problem in the Journal of the Indian Mathematical Society : $$\sqrt{1 + 2 \sqrt{1 + 3 \sqrt{1 + \dots}}}$$ After waiting 6 months without any solutions, he supplied the following formula from page 105 of his first notebook: $$x + n + a = \sqrt{ax + (n+a)^2 + x \sqrt{a(x+n) + (n+a)^2 + (x+n) \sqrt{\dots}}}$$ And setting $x=2$ , $n=1$ and $a=0$ , we get the solution $$\sqrt{1^2 + (2) \sqrt{1^2+ (2+1)\sqrt{1^2 + \dots}}} = 2+1+0 = 3$$ . (Pg 86-87, The Man Who Knew Infinity: A Life of the Genius Ramanujan , Robert Kanigel, 5th ed. 1991) Right off the bat, we can notice some interesting things here: While we cannot use this formula for the Nested Radical Constant above, it does allow us to find the values of infinitely many continued-roots. In particular we can immediately solve any fraction where the terms are in an Arithmetic Progression $\sqrt{a + b \sqrt{(a+d) + (a+d) \sqrt{(a+2d) + (a+2d) \sqrt{\dots}}}} = a+d + 1$ . We can generalize this further: $\sqrt{c.a + b \sqrt{(a+d) + c.(a+d) \sqrt{c.(a+2d) + (a+2d) \sqrt{\dots}}}} = a+d + c$ . For any given natural number $n$ , we can use this formula to find a number of unique nested fraction expressions equal to $q(n)$ , the number of partitions of that number . And so on... My question: How can we prove this formula? While Ramanujan himself usually derived results with great insight via intuition, I expect that the formula itself should be provable with usual mathematical techniques, especially with the amount of influence Ramanujan had on subsequent mathematics, and the high volume of work on continued fractions which are related to nested-radicals. So, can anyone find any proof for this - either on their own or in existing literature? If we cannot prove this, is it possible to find some motivation that makes it more intuitively clear . This should be possible since that was the way it was originally obtained. Any other interesting observations about this formula? Is it related to any other mathematical results? Perhaps it is related to some series, constants or continued fractions?","['nested-radicals', 'number-theory', 'continued-fractions', 'math-history']"
4050008,Verification of solution: $\lambda\left(\bigcup\limits_{k=1}^\infty A_k\right) < \infty$,"$A_1$ , $A_2$ .... $\subset \mathbb{R}^n$ given through $$ A_k := \{
 (x,y)\in \mathbb{R}^n:\text{  } k\leq x^2+y^2 \leq k+\frac{1}{2k^2}\}
 $$ Show: a) $\bigcup\limits_{k=1}^\infty A_k$ is Borel-measurable b) $\lambda \left(\bigcup\limits_{k=1}^\infty A_k\right) < \infty $ I do understand how a) works.
But b) is a bit weird in my opinion. Edit: $\lambda$ is Lebesgue measure. My solution: I defined $r:= x^2+y^2$ . Then $r\in [k,k+\frac{1}{2k^2}]$ for $A_k$ . I also see $A_k \cap A_{k+1} = \varnothing$ .
Then it is $$ \lambda\left(\bigcup\limits_{k=1}^\infty A_k\right) \leq \sum\limits_{k=1}^\infty \lambda(A_k) = \sum\limits_{k=1}^\infty \left(k+\frac{1}{2k^2}-k\right) = \sum\limits_{k=1}^\infty \frac{1}{2k^2} < \infty $$ Official solution: In the offical solution they use open balls $\overline{B_{r_k}}$ and $B_{\rho_k}$ with $r_k = \sqrt{k+\frac{1}{2k^2}}$ and $\rho_k = \sqrt{k}$ $\Rightarrow A_k = \overline{B_{r_k}}\setminus B_{\rho_k}$ . Then $\sum\limits_{k=1}^\infty \lambda(A_k) \leq \sum\limits_{k=1}^\infty \frac{\pi}{2k^2} < \infty$ My question: Is my way to prove this also right? And if it isn't: Why? I understand the official solution but it didnt come to my mind at first and I am unsure if this is the only right way to prove b).","['measure-theory', 'lebesgue-measure']"
4050009,Boundedness in $L^2$ implies convergence in $L^2$ for martingales.,"a. Show that if $X = (X_n)_n$ is an $L^2$ martingale bounded in $L^{2}$ then there exists a positive r.v. $U \in L^{2}$ that satisfies : $$
P\left(\forall n \geq 1,\left|X_{n}\right| \leq U\right)=1
$$ b. Deduce from a) or otherwise that $X$ converges in $L^2$ . What I could do so far : since $(X^2_n)_n$ is a submartingale then $\sup_nEX^2_n = \sum_nEX^2_n < \infty$ and thus : $EX^2_n \to 0$ so $X_n$ converges to $0$ in $L^2$ . my questions : is my work for b, correct? how to show a) and can it actually be used to deduce b) ? Thanks!","['martingales', 'measure-theory', 'convergence-divergence', 'probability-theory']"
4050053,"If unit quaternions $q_1,q_2$ satisfy $q_1^2=q_2^2=-1$, then the map $S^3\to S^3$, $x\mapsto q_1xq_2^{-1}$ has a fixed point","Let $\Bbb H$ denote the quaternion algebra. We can identify $S^3$ as the subset of unit quaternions.
For fixed $q_1,q_2\in S^3$ , consider the map $\phi:S^3\to S^3$ defined by $\phi(x)=q_1xq_2^{-1}$ . How can we show that if $q_1^2=q_2^2=-1$ (so that $\phi^2=\text{id}$ ) then $\phi$ has a fixed point? (This is claimed in a lecture note that I was reading, contained in the sketch of proof of the statement that if $G$ is a subgroup of $SO(4)$ of order $2$ acting freely on $S^3$ , then $G=\{\pm \text{id}\}$ .)","['group-theory', 'group-actions', 'quaternions']"
4050166,How to prove that $\left\{\gamma \in \alpha^{+}: \beta + \gamma \leq \alpha\right\}$ is not a limit ordinal given that $\alpha \geq \beta$.,"I am proving the following theorem and somewhat got stuck: Suppose that $\alpha$ and $\beta$ are ordinals with $\alpha \geq \beta$ . Let $X = \left\{\gamma \in \alpha^{+}: \beta + \gamma \leq \alpha\right\}$ . Then $X$ is a successor ordinal. I have proved that $X$ is an ordinal and that $X \neq \boldsymbol{0}$ . But I am stuck at proving $X$ is not a limit ordinal. I tried to use transfinite induction on $\alpha$ , but the process is very verbose, and I was stuck in the middle. Can anyone provide hints?",['elementary-set-theory']
4050201,Sufficient condition for convergence in mean,"I want to prove that if $\xi_n$ is sequence of non-negative random variables, $\xi_n\xrightarrow {a.e.}\xi$ and $\mathbb{E}\xi_n^p \to \mathbb{E}\xi^p $ than $$\mathbb{E}|\xi_n-\xi|^p\to0 \text{ (i.e. }\xi_n\xrightarrow {L^p}\xi)$$ I don't know where to start. I would be very grateful for help!","['statistics', 'probability-theory', 'probability', 'random-variables']"
4050433,How to approximate a sharply peaked function with deltas?,"I have the function $$
f(x)=\cases{\frac{1}{\sqrt{\sinh^2(a)-\sinh^2(ax)}} & $-1 \leq x \leq1$ \\ 0 & otherwise}
$$ Where $a \in \mathbb{R}^+$ . Here is a plot of $f$ : It would be very convenient if I could justify (in any way: maybe distributionally?) that $$
f(x)=A\left[ \delta(x-1)+\delta(x+1) \right]+B+\mathcal{O}(?) \quad ; \quad a \to \infty \tag{1}
$$ For some $x$ independent constants $A$ and $B$ . I am uncertain of how to do this, or how to estimate the error. What I've tried My thought was to look at the Fourier series of $f$ , and associate terms with the Fourier series of (2). By expanding (1) around $x= \pm1$ , I can find a Laurent series in $(x \pm 1)$ , and perform the Fourier integral term by term. The result is messy, and worse: does not allow easy comparison to the Fourier series of (2). This may not be a fruitful approach. By looking at the wiki page about mollifiers , it seems I need to claim something like: $a f(x) \to \delta (x \pm1), \ a \to \infty$ . Superficially, this appears to work, but I'm not sure how to make it concrete, or if there should be any other factors next to $af(x)$ (other than a factor to ensure normalization to unity). Questions How can I estimate the error and find $A$ and $B$ in (1)? If $A$ and $B$ cannot be found, how can I find the ratio $A/B$ ? Background $f(x)$ will eventually appear beneath an integral with a Green's function $G$ . I'd like to formulate this for arbitrary $G$ . We can take some liberties about the 'niceness' of $G$ , as necessary. In particular, it has a well behaved Fourier transform.","['integration', 'approximation-theory', 'asymptotics', 'distribution-theory']"
4050434,Let $(x_n)$ and $(y_n)$ be sequences such that $(x_n)$ is a subsequence of $(y_n)$ and $(y_n)$ is a subsequence of $(x_n)$. $x_n=y_n$ for all $n$?,"Let $(x_n)$ and $(y_n)$ be sequences such that $(x_n)$ is a subsequence of $(y_n)$ and $(y_n)$ is a subsequence of $(x_n)$ . Given that $x_n$ converges, does it follow that $x_n=y_n$ for all $n$ ? I strongly suspect this is true. I have an idea but I'm not convinced its super tight. By our subsequence fact, let $x_{a_n}=y_n$ and $y_{b_n}=x_n$ . Since we have to fit these terms in the sequence and they are all in order, we must have $a_n\ge n$ and $b_n \ge n$ with equality if and only if the first $n-1$ terms are identical.
Assume BWOC $\exists k: x_k\neq y_k$ with $k$ minimal. Well $x_{a_k}=y_k$ with $a_k\gt k$ , but $y_{b_{a_k}}=x_{a_k}, b_{a_k}\gt a_k \ (>k)$ . In other words, $x_k \neq y_k \implies \text{$y_k$ appears later in the sequence ($x_n$)}\implies \text{another $y_k$ appears later in the sequence $(y_n)$}$ and this keeps going on back and forth. Since $(x_n)$ converges and $y_k$ appears infinitely many times in $(x_n)$ , it must converge to $y_k$ . But, by the same argument, we can show it converges to $x_k$ . Since $x_k\neq y_k$ , this is a contradiction. After writing this out, I feel like my idea is right but I just have this doubt in my execution that I can't shake. Is my argument correct or is the proposition false after all?","['solution-verification', 'sequences-and-series', 'real-analysis']"
4050438,Find the maximal interval of existence without actually solving the ODE.,"$$y^{\prime}=-\frac{4}{x^{2}}-\frac{1}{x} y+y^{2}, y(1)=1$$ This is a Ricatti equation, $f(x,y)$ is a polynomial in $y$ so it's locally Lipschitz and thus there exists a unique solution to the IVP above, $y_p = \pm \frac{2}{x}$ is a particular solution, we can go ahead and solve it using the change of variable $y = y_p +u$ but is there a way to find the maximal interval of existence without actually doing that?",['ordinary-differential-equations']
4050487,"Real-world example where two positively correlated pairs (X, Y ) and (Y, Z) of random variables give a negative correlation for (X,Z).","Let X, Y and Z be random variables with finite means and finite variances. Suppose that the correlations ρ(X, Y ) and ρ(Y, Z) have unspecified positive values. Then without additional information on the distributions of X, Y and Z, the correlation ρ(X,Z) could possibly be positive, negative, or zero. In particular, we can find specific random variables X,Y,Z such that ρ(X, Z) is negative. The question is to come up with a creative real-world example where two positively correlated pairs (X, Y ) and (Y, Z) of random variables could still give a negative correlation for (X,Z). For example: In basketball, NBA basketball players could play as many as > 80 games per year, and their points scored over the year are recorded. For a randomly selected NBA basketball player, define the following random variables: • Let X be the number of slam dunks made in a year. • Let Y be the total number of points scored in a year. • Let Z be the number of 3-pointers made in a year. In this case, X,Y and Y,Z are both positively correlated, however X,Z is negatively correlated. I want to think of other creative examples like this (not related to other sports, please)","['correlation', 'statistics', 'probability', 'random-variables']"
4050557,Find $x$ for $\overline{x}\oplus(\overline{7}\odot\overline{11}) = \overline{2} \odot (\overline{x}\oplus \overline{9})$,"Find $x \in \mathbb{Z}$ such that the equality $\overline{x}\oplus(\overline{7}\odot\overline{11}) = \overline{2} \odot (\overline{x}\oplus \overline{9})$ is true in $\mathbb{Z_{12}}$ My reasoning: Initially, defining an equivalence relation in $\mathbb{Z}$ with, such that $a\thicksim b \Leftrightarrow a - b$ is multiple of $n$ and $n>1$ . So we have $a\equiv b \text{ (mod }n)$ . For $x\in\mathbb{Z}$ and its equivalent class denoted as $\overline{x}$ , we have $$\overline{x} = \{a\in\mathbb{Z}: a\equiv z \text{ (mod }n)\}$$ So, the equivalent classes are $\overline{0} = \{..., -2n, -n, 0, n, 2n, ...\}\\
\overline{1} = \{..., -2n+1, -n+1, 1, n+1, 2n+1, ...\}\\
\vdots\\
\overline{n-1} = \{..., -n-1, n-1, n-1, ...\}
$ And the congruent modulo $n$ in $\mathbb{Z}$ gives $\mathbb{Z}_n = \mathbb{Z}/\sim = \{\overline{0}, \overline{1}, \overline{2}, ... , \overline{n-1}\}$ Once the equality given is true in $\mathbb{Z_{12}}$ , such that $\mathbb{Z_{12}} = \{\overline{0}, \overline{1}, \overline{2}, ... , \overline{11}\}$ , we know $x\in [0, 11]$ . Also, once $n > 1$ the following properties are true: $\overline{a}\oplus(\overline{b}\oplus \overline{c}) = (\overline{a}\oplus\overline{b})\oplus \overline{c} \quad (\text{Associativity of } \oplus)\\
\overline{a}\oplus\overline{b}= \overline{b}\oplus\overline{a} \quad (\text{Commutativity of } \oplus)\\
\overline{a}\odot(\overline{b}\odot\overline{c}) = (\overline{a}\odot\overline{b})\odot \overline{c} \quad (\text{Associativity of } \odot)\\
\overline{a}\odot\overline{b}= \overline{b}\odot\overline{a} \quad (\text{Commutativity of } \odot)\\
\overline{a}\odot(\overline{b}\oplus\overline{c}) = (\overline{a}\odot\overline{b})\oplus(\overline{a}\odot\overline{c}) \quad (\text{Distributivity of } \odot)\\
\text{For } \overline{a}, \overline{b}, \overline{c} \in\mathbb{Z}_n
$ Also, $\overline{a}\oplus\overline{b} = \overline{a+b}$ and $\overline{a}\odot\overline{b} = \overline{ab}$ Then, for the given question I tried the following $\overline{x}\oplus(\overline{7}\odot\overline{11}) = \overline{2} \odot (\overline{x}\oplus \overline{9})$ As $\overline{7}\odot\overline{11} = \overline{77}$ , we have $\overline{72} = \overline{0}$ for $\mathbb{Z}_{12}$ , then $\overline{77} = \overline{5}$ . $\overline{x}\oplus\overline{5} = \overline{2} \odot (\overline{x}\oplus \overline{9}) \implies \overline{x}\oplus\overline{5} = (\overline{2}\odot\overline{x})\oplus(\overline{2}\odot\overline{9}) $ As $\overline{2}\odot\overline{9} = \overline{18}$ , we have $\overline{12} = \overline{0}$ for $\mathbb{Z}_{12}$ , then $\overline{18} = \overline{6}$ . $\overline{x}\oplus\overline{5} = (\overline{2}\odot\overline{x})\oplus(\overline{2}\odot\overline{9}) \implies \boxed{\overline{x}\oplus\overline{5} = (\overline{2}\odot\overline{x})\oplus\overline{6}}$ From the last step I couldn't finish it. Taking all the solutions for $x$ I could find that $x=11$ , but I was not able to arrange the equality to get the solution. For $\color{red}{\overline{x}\oplus\overline{5}} = \color{blue}{(\overline{2}\odot\overline{x})\oplus\overline{6}}$ $x = 1: \color{red}{\overline{6}} = \color{blue}{\overline{8}}\\
x = 2: \color{red}{\overline{7}} = \color{blue}{\overline{10}}\\
x = 3: \color{red}{\overline{8}} = \color{blue}{\overline{12} = \overline{2}}\\
x = 4: \color{red}{\overline{9}} = \color{blue}{\overline{14} = \overline{2}}\\
\vdots\\
x = 11: \color{red}{\overline{16} = \overline{4}} = \color{blue}{\overline{28} = \overline{4}}\\
$ How can I solve the question? Sorry for the simple question, but I was not sure about how to proceed in the boxed step. In this context, what I could have done?","['elementary-number-theory', 'modular-arithmetic', 'discrete-mathematics']"
4050707,Approximation of a random number with quadratic integers,"Consider the following claim: Claim: Let $x$ be a real random variable distributed according to the uniform distribution on the unit interval $U(0,1)$ . Then for any quadratic irrational number $\alpha$ , and real $\epsilon>0$ , there exist finite real numbers $c,\gamma,\Delta>0$ such that $$
\mathrm{Prob}\left( \min_{\substack{(p,q) \in \mathbb{Z}^2 \\ q \neq 0}}|\alpha q - p - x|q^{1+\epsilon} < \delta\right) \leq c \delta^\gamma
$$ is true for all $\delta < \Delta$ . My Question: Does the claim hold? It may be helpful to note that one can always find a $p,q$ independent constant $C(\alpha,\epsilon)$ such that the bound $$
\left|\alpha - \frac{p}{q} \right| \geq \frac{C(\alpha,\epsilon)}{q^{2+\epsilon}}
$$ is tight.
This inequality holds for any algebraic $\alpha$ (Roth's theorem) and holds with probability one for $\alpha$ drawn from a piecewise continuous distribution (Gauss Kuzmin statistics). Thus for $x = 0$ , we have that $$
\min_{(p,q) \in \mathbb{Z}^2, \,q \neq 0}|\alpha q - p|q^{1+\epsilon} = C(\alpha,\epsilon),
$$ and the question is essentially about how frequently the constant on the RHS becomes small when $x$ is varied away from zero. My suspicion is that the claim holds, and that the bound is tight for $\gamma = 1$ . Thus I would also be grateful for any insight regarding the follow up questions Can we choose $\gamma = 1$ always? Can $c$ be bounded? Does the claim hold with probability one for $\alpha$ itself drawn randomly from the unit interval (i.e. for $\alpha$ with Gauss-Kuzmin statistics)?","['number-theory', 'irrational-numbers', 'irrationality-measure']"
4050710,Ovaloid is orientable,"Given a compact, connected regular surface $S$ in Euclidean space which has everywhere positive gaussian curvature = an ovaloid. It is a theorem of Hadamard that ovaloids are diffeomorphic to the sphere (discussed in Klingenberg), but the proof of this follows the proof of their orientability = that there exists a continuous, unit normal field defined globally on $S$ . Unfortunately, there is no proof of this in doCarmo (as far as I can tell) and the proof in Klingenberg is said to be obvious, but the details are not explained. (He says the second order surface approximating $S$ near any point is an elliptic paraboloid, but it is not explained how to define the unit normal field globally) Does anyone know a full proof of this theorem? Ovaloids were extensively studied by Blaschke in his book (kreis und kugel), unfortunately I do not speak German. I would be extremely grateful for any references on ovaloids in English (but only classical differential geometry)",['differential-geometry']
4050711,Equality of two elliptic integrals,"by wolfram 1 and wolfram 2 It's true that $\displaystyle \int_0^{\frac{\pi}{2}}\int_0^{\frac{\pi}{2}} \frac{2}{\sqrt{1-\sin^2\theta\sin^2\phi}} d\phi d\theta =\int_0^{\frac{\pi}{2}}\int_0^{\frac{\pi}{2}} \frac{1}{\sqrt{\sin\theta\sin\phi}} d\phi d\theta$ ? If yes,  I need  a way to prove the equality of the following two integrals I tried everything  but I am unable to convert  into a standard form so How do I solve this problem. Addition 1: For the second integral $\int_0^{\frac{\pi}{2}}\int_0^{\frac{\pi}{2}} \frac{1}{\sqrt{\sin\theta\sin\phi}} d\phi d\theta =\bigg(\int_0^{\frac{\pi}{2}}\frac{1}{\sqrt{\sin\theta}}d\theta\bigg)^2 $ and we can use that $2 \int^{\frac{\pi}{2}}_{0}\frac{1}{\sqrt{\sin x}} \mathrm dx = \frac{\Gamma(1/2)\Gamma(1/4)}{\Gamma(3/4)} = \frac{\Gamma \left( \frac{1}{4}\right)^2}{\sqrt{2\pi}}$ Addition 2: For the first integral Let $\displaystyle K(k)=\int_0^{\frac{\pi}{2}}\frac{1}{\sqrt{1-k^2\sin^2 t}}dt$ ( Complete Elliptic Integral of the First Kind). we know that $ \displaystyle K(k)=\frac{\pi}{2}\sum_{n=0}^\infty \left(\frac{(2n)!}{2^{2n}(n!)^2}\right)^2k^{2n}$ . Then it's not difficult de show that $\int_0^{\frac{\pi}{2}}\int_0^{\frac{\pi}{2}} \frac{1}{\sqrt{1-\sin^2\theta\sin^2\phi}} d\phi d\theta=(\pi /2 )^2 \sum _{n=0}^{\infty }(\frac{(2n)!}{4^n(n!)^2})^3$ . The egality of the two integrals hold if we can calculte $$\sum _{n=0}^{\infty }(\frac{(2n)!}{4^n(n!)^2})^3$$ Wolfram gives Addition 3: This link gives","['integration', 'calculus', 'elliptic-integrals', 'definite-integrals']"
4050731,Calculating the integral with an undefined function f(x),"I am having a problem with an excersice of calculating the integral I= $\int_{0}^{a}\frac{1}{1+f(x)}\,dx$ and we know that $f(x)f(a-x)=1$ , $a>0$ and $f(x)$ is continous and positive on the interval $[0,a]$ i've tried manipulating the expression with the fact that $f(x)= \ \frac{1}{f(a-x)} $ in order to find something to cancel or something that makes me solve the integral ""nicely"" However after 20 minutes i have no idea what to do, or what i am missing so if anyone could give me a tip or point me in the right direction i would appreciate it","['integration', 'calculus', 'analysis']"
4050762,"Prove that $c_V(X) \geq c_V(f(X))$ for $X>0$ and $f$ concave, positive, increasing,","I have a square-integrable random variable $X > 0$ . Function $f : \mathbb{R}^+ \rightarrow \mathbb{R}^+  $ is concave, monotonically increasing and $f(0) = 0$ .
I would like to prove that (and make sure that it is actually true): \begin{equation}
\frac{\mathbf{E}[X^2]}{\mathbf{E}[X]^2} \geq \frac{ \mathbf{E}[f(X)^{2}]}{ \mathbf{E} [f(X)]^2}
\end{equation} Which is equivalent to saying that the coefficient of variation ( $c_V$ , CV) decreases after applying $f$ to $X$ . Given of course that $\mathbf{E}[f(X)^{2}]$ and $\mathbf{E} [f(X)]$ exist. It seems to be true numerically and this Prove $\mathbf{E}[X^2] \geq \frac{ \mathbf{E}[X^{2\alpha}]}{ \mathbf{E} [X^{\alpha}]^2}$ seems to be a special case, but I can't come up with the analytical proof. It appears quite related to Jensen's inequality, but I can't use Hölder's inequality as in Prove $\mathbf{E}[X^2] \geq \frac{ \mathbf{E}[X^{2\alpha}]}{ \mathbf{E} [X^{\alpha}]^2}$ . Also, maybe the condition $f(0) = 0$ might not be needed for this to be true.
Thanks a lot of your help. Any leads would be highly appreaciated.","['variance', 'jensen-inequality', 'expected-value', 'inequality', 'probability-theory']"
4050784,"Show $\frac{(n-1)S^2}{\theta}$ is pivotal quantity of random sample $Y_1,...,Y_n$ from $N(\theta,\theta)$ then derive confidence interval","Show $\frac{(n-1)S^2}{\theta}$ is pivotal quantity of random sample $Y_1,...,Y_n$ from $N(\theta,\theta)$ then derive confidence interval $(1-\alpha)100%$ confidence interval for $\theta$ So I can show that $\frac{(n-1)S^2}{\theta}\sim \chi^2_{n-1}$ since $S^2=\sum_{k=1}^n \frac{(Y_i-\bar{Y})}{n-1}$ But I'm not sure how to find the confidence interval? I believe it is supposed to look like $P(\chi^2_{n-1}\leq \frac{(n-1)S^2}{\theta}\leq \chi^2_{n-1})=1-\alpha$ And then solving for $\theta$ in the middle. But I know $\chi^2_{n-1}$ is wrong, I don't understand what the bounds are supposed to be.",['statistics']
4050841,On understanding $\mathrm{ad}^0 \overline{\rho}$ and $\mathrm{ad}^0 \overline{\rho}(1)$ in Taylor-Wiles method,"I'm currently learning Taylor-Wiles method and modularity lifting and comming up with following difficulties, which I think is based on understanding how (global and local) Galois groups act on $\mathrm{ad}^0 \overline{\rho}$ and $\mathrm{ad}^0 \overline{\rho}(1)$ . Here: $\overline{\rho}: G_{F,S} \rightarrow \mathrm{GL}_2(\mathbb{F})$ is the residue representation. Here $S$ is a finite set of finite places of $F$ containing $\{v | p\}$ , where $F$ is a number field (a finite extension over $\mathbb{Q}$ ). Here $G_{F,S}$ is the Galois group of the maximum extension over $F$ which is unramified outside $S \sqcup \{ v | \infty \}$ . $\mathrm{ad}^0 \overline{\rho}$ consists of traceless matrices $M \in M_n(\mathbb{F})$ with $G_{F,S}$ -conjugation action $\sigma \cdot X := \overline{\rho}(\sigma) X \overline{\rho}(\sigma)^{-1}$ . $\mathrm{ad}^0 \overline{\rho}(1)$ is its Tate twist $\mathrm{ad}^0 \overline{\rho} \otimes \mathbb{Z}_p(1)$ . Via the $G_{F,S}$ -action on $\mathrm{ad}^0 \overline{\rho}$ and $\mathrm{ad}^0 \overline{\rho}(1)$ , we can consider the $G_{F,S}$ -cohomology with coefficients in $\mathrm{ad}^0 \overline{\rho}$ and $\mathrm{ad}^0 \overline{\rho}(1)$ accordingly. My question 1 : How to prove the following claim: If $\overline{\rho}|_{G_{F(\zeta_p)}}$ is absolutely irreducible, then $H_0(G_{F,S}, \mathrm{ad}^0 \overline{\rho}(1)) = 0$ . (Where $G_{F(\zeta_p)}$ is the absolute Galois group of $F(\zeta_p)$ ). My attempt : The zeroth cohomology group $H_0(G_{F,S}, \mathrm{ad}^0 \overline{\rho}(1))$ consists of exactly the elements in $\mathrm{ad}^0 \overline{\rho}(1)$ fixed by $G_{F,S}$ , so it is essential to figure out the action of $G_{F,S}$ on $\mathrm{ad}^0 \overline{\rho}(1)$ . Then I have found someone claimed that Elements in $H_0(G_{F,S}, \mathrm{ad}^0 \overline{\rho}(1))$ correspond to the intertwining operators $\overline{\rho} \rightarrow \overline{\rho}(1)$ between $G_{F(\zeta_p)}$ -modules. But how to prove this claim? . After proving this claim, Schur's lemma implies that $H_0(G_{F,S}, \mathrm{ad}^0 \overline{\rho}(1)) = 0$ and we are done. My question 2 : Let $v$ be a Taylor-Wiles prime of $F$ . (i.e. $v$ is a finite place of $F$ satisfying the two conditions: the norm of $v$ (denoted by $q_v$ ) satisfies $q_v \equiv 1 \pmod{p}$ ; and $\overline{\rho}(\mathrm{Frob}_v) \in \mathrm{GL}_2(\mathbb{F})$ has distinct eigenvalues.) Let $F_v$ be the completion of $F$ wrt $v$ and $G_v$ be its (local) absolute Galois group. Via $$
G_v \hookrightarrow G_F \twoheadrightarrow G_{F,S} \xrightarrow{\overline{\rho}} \mathrm{GL}_2(\mathbb{F}),
$$ we can consider the $G_v$ action on $\mathrm{ad}^0 \overline{\rho}(1)$ . Then how to prove the following claim : $H_0(G_{v}, \mathrm{ad}^0 \overline{\rho}(1)) = H_0(G_{v}, \mathrm{ad}^0 \overline{\rho}).$ So again the essential point is to understand how $G_v$ acts on $\mathrm{ad}^0 \overline{\rho}(1)$ and I have difficulty on this. I even guess The actions of $G_{v}$ on $\mathrm{ad}^0 \overline{\rho}(1)$ and $\overline{\rho}$ are the same . But I don't know how to prove this. (I feel like this is due to the condition that $q_v \equiv 1 \pmod{p}$ .)","['algebraic-number-theory', 'galois-representations', 'number-theory', 'galois-cohomology', 'group-cohomology']"
4050883,Explicit form for a difficult sequence,"Let us define infinite sequence $x_n$ as such: the first term of the sequence is $x_1=1$ . Then, the next $x_1$ terms are 2. The next term is 1. The next $x_2$ terms are 2. The next term is 1. The next $x_3$ terms are 2. The next term is 1. And so and so forth... Can anyone provide explicit formula for the $n$ th term of this sequence? Or please provide any insight on any patterns that may exist. For reference, here is how the sequence goes for the first several terms: 1 2 1 2 2 1 2 1 2 2 1 2 2 1 2 1 2 2 1 2 1 2 2 1 2 2 1 2 1 2 2 1 2 2 1 2 1 2 2 1 2 1 2 2 1 2 2 1 2 1 2 2 1 2 1 2 2 1 2 2 1 2 1 2 2 1 2 2 1","['combinatorics', 'sequences-and-series']"
4050895,Super-level sets of Hardy–Littlewood maximal function are open?,"I am working on the book Measure, Integration and Real Analysis by Sheldon Axler . I am stuck on Problem 9 of Section 4A. For $h: \mathbb{R} \to \mathbb{R}$ Lebesgue measurable, $h^*$ is defined as follows: $$ h^*(x)=\sup_{r>0}\frac{1}{|B(x,r)|} \int_{B(x,r)} |h(y)|dy.$$ Suppose $h: \mathbb{R} \to \mathbb{R}$ is Lebesgue measurable. Prove that $$\left\{ b \in  \mathbb{R} : h^{\ast}(b) > c\right\}$$ is an open subset of $\mathbb{R}$ for every $c \in \mathbb{R}$ . My Idea is like this: Let $A=\left\{ b \in  \mathbb{R} : h^{\ast}(b) > c\right\}$ . Pick $b \in A.$ I want to show that there is a ball $B(b,\epsilon)$ contained inside of $A$ . But I don't know how to get to this.
Any help?","['harmonic-analysis', 'measure-theory', 'real-analysis']"
4050930,Show that $x^{2}\frac{\partial^{2}u}{\partial x^{2}}+2xy\frac{\partial^{2}u}{\partial x\partial y}+y^{2}\frac{\partial^{2}u}{\partial y^{2}}=0$,"I want to prove that $x^{2}\frac{\partial^{2}u}{\partial x^{2}}+2xy\frac{\partial^{2}u}{\partial x\partial y}+y^{2}\frac{\partial^{2}u}{\partial y^{2}}=0$ where $u(x,y)=\frac{xy}{x+y}$ . I know that it could be done by calculating each partial derivative but I realized that $x^{2}\frac{\partial^{2}u}{\partial x^{2}}+2xy\frac{\partial^{2}u}{\partial x\partial y}+y^{2}\frac{\partial^{2}u}{\partial y^{2}}=[(x,y)\cdot \nabla]^{2}u$ .
So my question is if there exists some result that I can use to prove in an easy way that the equality holds.",['multivariable-calculus']
4050959,The Board Football Problem (Part I),"The original question is here ( The Board Football Problem (Probability) ) and part II is here( The Board Football Problem (Part II) ). I was told to segment the question in order to increase the chances of it being answered. As kids we used to play the game ""Board Football"". I'm not particularly sure of the popularity of the game but the rules were pretty simple to follow. The basic objective of the game was to score as many goals as possible and you played it with nothing more than dice and a notebook. It's a two player game, which goes on as long as the players don't bored. ie there isn't any way to win/finish the game.Both you (say A) and the opponent (say B) have a dice. Before starting the game you decide the minimum number of ""passes"" that need to be completed before a goal is scored(say p). Let's assume that A starts first.A rolls the dice and gets a certain number, say 5. This means that A completes 5 passes in that round and has to complete p-5 more passes in order to progress to the ""Final Stage"". However, before the round is completed the opponent(B) has the opportunity to ""intercept"" you and obtain possession of the ball. The way to do this is pretty simple. B rolls his dice and if he gets the same number as A, then B obtains possession of the ball and the round is completed. In the next round, B will start off from 0 passes. We weren't particularly finicky back then so even if we rolled a number to exceed the number of passes made, the player in possession was still allowed to progress to the ""Final Stage"". It didn't matter in what order the passes in each round were made as long as the required passes was obtained. Once the required passes were made and the player reached the ""Final Stage"", they had to flip a coin. If it turns up as heads,the player in possession scores and if it turns up as tails, he doesn't score. In both the cases, the possession is reverted back to B for the next round. We considered the coin-flipping part to take place in the same round as the round in which the player in possession completed the required passes. For example, let a 6 sided dice be used and the required number of
passes be 9.
(That is n=6,p=9) Let us say that A has the ball in the starting. In the first round, A rolls 4 and B rolls 5. A completes 4 passes within that round.A now has to complete at least 5 more passes in order to get an opportunity to shoot. In the second round, A rolls 3 and B rolls 3. Possession is overturned and now B controls the ball.B now has 0 passes completed. In the third round, B rolls 5 and A rolls 2.B has completed 5 passes in this round and needs to complete at least 4 more passes in order to get an opportunity to shoot. In the fourth round, B rolls 6 and A rolls 4. Although B has overshot the number of passes,  B is permitted to flip the coin. B tosses the coin and gets heads. B scores a goal.B leads by one goal to nil. Now A starts
off with possession of the ball. So my question is as follows:If we use an n-sided dice and the number of required passes is p, the what is the probability that the player in possession of the ball(starting off from 0 passes completed) scores a goal without losing possession of the ball. Is it possible to calculate the value for this in a non-computational /formulaic manner? ( BONUS QUESTION ) Form a graph with the Y-Axis being the probability that the player in possession scores without losing possession of the ball and the number of required passes be the X-Axis. (Let a 10 sided dice be used for this case.) If possible, determine how different the graph would look [in a visual sense, no need for deeper calculations] if the number of sides on the dice is made to vary. Is the graph just shifted along the x-axis or do the peaks become more gradual?). PS This isn't a homework question/problem so please don't close it because an answer is being requested. It is an original question. Consider this to be a challenge of sorts.","['contest-math', 'puzzle', 'combinatorics', 'recreational-mathematics', 'probability']"
4051030,Different definitions of ring and field.,"From Hanh and Rosenthal ""Set functions"" (1948, p.3): A system of sets which is closed with respect to addition and intersection is called a ring . A system of sets which is closed with respect to addition and subtraction is called a field . And by ""addition"" I understand ""union"". From Taylor ""Introduction to measure and integration"" (digital printed version, 2008, p.15): ...we see that a ring is a class of sets closed under the operations of union, intersection, and difference and... Thus a ring is a field if and only if it is closed under the operation of taking the complement. Very different definitions for me. I know that a ring (or field) in the algebra and in the set theory has different definitions (I am not sure). But here in both cases we talk about a class of sets. Question: what is going wrong? Maybe the last too definitions are more modern? Or there are some problems in my understanding?","['measure-theory', 'set-theory']"
4051045,Question regarding number of non decreasing functions,"I have a question that requires me to find the number of non decreasing functions $f: A \longrightarrow B$ where $A=\{1,2,3,4,5\}$ and $B = \{-2,-1,0,1,2,3,4,5\}$ I tried doing this by finding the Total number of functions, which according to me is $8^5$ . Then, I found the number of decreasing functions to be ${8 \choose 5}$ and there is only one way to order each of those combinations so number of decreasing functions is ${8 \choose 5}$ . Correct me if I'm wrong here. But here's why I don't get the next part, the answer for the number of non decreasing functions isn't $8^5- {8 \choose 5}$ I don't get why this is, shouldn't the total number of functions $-$ number of decreasing functions $=$ number of non-decreasing
functions? I need a few counter examples to convince me otherwise and I can't seem to be able to come up with one, any help on this/visualizing it would be appreciated. The number of decreasing functions I found to be ${8 \choose 5}$ , which isn't asked in the question, just something that I calculated. However, the question also does ask for the number of increasing functions $f:A\longrightarrow B$ , and that answer is stated as ${8 \choose 5}$ , which makes me question whether my number of decreasing functions is valid. A confirmation here would be highly appreciated too. Thanks in advance! (I know that there is a similar question from 2015, but since I had some trouble understanding the answers, and also had further questions of my own, I decided to repost rather than posting on a ~6 year old thread) Here's the link to the old question: Number of non-decreasing functions?","['permutations', 'functions', 'combinatorics']"
4051080,Find the area of the shaded region within the smaller equilateral triangle,"WLOG, let the side length of one of the smaller equilateral triangles by $1$ . So the overall area of one of the smaller equilateral triangles is $\frac{\sqrt{3}}{4}.$ To find the area of the shaded region (within the smaller triangle), I toyed with the idea of coord-bashing (I know, a bad method, but I didn't know what else to do), but quickly dismissed it. It would take way too much time. I am at a loss for what to do, can someone please provide me with a hint (not solution) that will help me on my way?",['geometry']
4051081,"If Anna goes from point A to point B, each step can only move up or move right. How many method(s) is / are there?(reference the grid below)","If Anna goes from point A to point B, each step can only move up or move right. How many method(s) is / are there?(reference the grid below) I’ve just recently learned permutations and combinations. Therefore, I understood how to answer problems regarding grids but only the type of questions with definite number of columns and rows. As shown in the picture above, the grids are different in size. I’m confused on how to solve this. I’d be happy if anyone could help.. Thank you.","['permutations', 'combinations', 'geometry', 'combinatorics', 'dynamic-programming']"
4051158,Finding the infinitesimal generator of Ornstein-Uhlenbeck process without using a theorem,"Consider the 1-dimensional Ornstein-Uhlenbeck process $$X(t)=\mu+e^{-\lambda t}(x-\mu)+\frac{\sigma}{\sqrt{2\lambda}}e^{-\lambda t}W^{(e^{2\lambda t}-1)}$$ with mean $\mu+e^{-\lambda t}(x-\mu)$ and variance $\frac{\sigma^2}{2\lambda}(1-e^{-2\lambda t})$ . I'd like to show the infinitesimal generator of O-U process is $$\mathcal{L}f(x)=\lambda(\mu-x)f'(x)dx+\frac{1}{2}\sigma^2f''(x)$$ My idea is first transform the equation by taking derivatives w.r.t. $t$ , $$dX(t)=\lambda\int_{0}^{t}(\mu-X(t))dt+\sigma dW(t),X(0)=x$$ Note that $\int_{0}^{t}e^{\lambda s}dW(s)$ has the same distribution as $(2\lambda)^{-1/2}W^{(e^{2\lambda t}-1)}$ , so I can make the adjustment. Here is a theorem in Oksendal's SDE: (Theorem 7.5.4) Let $f\in C^2$ , then $f\in\mathcal{D}_A$ and $$\mathcal{A}f=\sum_{i}b_i\frac{\partial{f}}{\partial{x_i}}+\frac{1}{2}\sum_{i,j}(\sigma\sigma)^T_{ij}\frac{\partial^2 f}{\partial x_i\partial x_j}$$ . Using this theorem, we can find the generator immediately. But I'd like to know methods without using this, since we have not covered it in our class yet. We have given the definition of infinitesimal generators: $$\mathcal{L}f=\lim_{h\to 0}\frac{\mathbb{E}[f(W^{(h)})]-f(x)}{h}$$ but using the definition, the calculation will be pretty messy. A similar question has been asked here before: Infinitesimal Generator for Stochastic Processes , but the answer does not quite solve my problem. Can anyone provide a derivation without using the theorem? Thank you.","['stochastic-integrals', 'stochastic-calculus', 'stochastic-processes', 'probability-theory', 'probability']"
4051204,Finding complex number for intersection of a line and a circle?,"How to find complex number for intersection of a line and a circle? In particular, if $M=$ midpoint $BC$ , then I want $AM ∩ (ABC)$ in complex numbers. Let me describe why I needed this, I was doing a problem which I reduced to proving $4$ points $(B,T,M',J)$ are cyclic where $ABC$ is an acute scalene triangle, $T$ is the intersection of tangents to $(ABC)$ from $B$ and $C$ , $M' = AM ∩ (ABC)$ ;( $M =$ midpoint $BC$ ) , and $J = AB ∩ CM'$ . I tried to prove this synthetically but I could not, so I decided to bash. First I tried coordinate but that was too long, so I decided to go with complex because that felt feasible. But then I remembered that I have not yet studied complex numbers (except when I would read EGMO complex numbers for fun, like a storybook). So I opened EGMO and could get complex numbers for everything like how to prove cyclic, intersection, $T$ etc. but Point $M'$ was a problem. I couldn't find how to get it anywhere so I come to MSE. Please help me, Thanks!","['contest-math', 'euclidean-geometry', 'geometry', 'complex-numbers']"
4051216,Why doesn't the multiplication rule work here?,"I have the following question: How many ways are there to select $3$ candidates from $8$ equally
qualified recent graduates for openings in an accounting firm? I was given the following solution to it: $\binom{8}{3}$ , however, I got the answer: $8 \times 7 \times 6$ by doing the multiplication rule, I was wondering why my answer doesn't work.
My initial reason is that in the multiplication rule there is the underlying assumption that order matters and here obviously order doesn't matter. However, I am posting this here as that is the first time I come to such a realization and I am not sure that my reasoning is correct, especially since that I never learned multiplication rule with the idea of order in my mind. Any clarification would be appreciated.",['combinatorics']
4051252,Support of a measure on Borel sets not well defined.,"Let $(X, \tau$ ) be a topological space and let $B$ be the Borel $\sigma$ -algebra generated by $\tau$ . Let $(X,B,\mu)$ be a measure space. Then the support of the distribution $\mu$ is defined as : $$\operatorname{supp}({\mu})=\{x\in X : \mu(U)>0\text{ for all U open neighborhood of }x\}.$$ Now in the wikipedia article about  Radon measures , it is written A common problem is to find a good notion of a measure on a
topological space that is compatible with the topology in some sense.
One way to do this is to define a measure on the Borel sets of the
topological space. In general there are several problems with this:
for example, such a measure may not have a well defined support.
Another approach to measure theory is to restrict to locally compact
Hausdorff spaces[...] But I don't see why the support is not well defined when we use the above expression.",['measure-theory']
4051263,Probability that a Particle which moves Unit distance in a Random direction on each step will be inside the Unit Sphere after $n$ steps,"The following integral equation arises while calculating the probability that, a particle which starts at the origin and moves a unit distance in a random direction on each ‘move’, will be within the unit sphere after $n$ moves: $$
f_n(x) = \begin{cases} 
\int_{1-x}^{1+x} \frac{df_{n-1}(t)}{dt}  \left( \frac{x^2-(t-1)^2}{4t} \right) dt, & 0\le x\lt 1  
 \\ f_{n-1} (x-1) + \int_{x-1}^{x+1} \frac{df_{n-1}(t)}{dt}  \left( \frac{x^2 -(t-1)^2}{4t} \right) dt, & 1 \le x \le n-2 
\\ f_{n-1} (x-1) + \int_{x-1}^{n-1} \frac{df_{n-1}(t)}{dt}  \left( \frac{x^2 -(t-1)^2}{4t} \right) dt, & n-2\lt x\lt n 
\\ 1, & x\ge n
\end{cases}
$$ Here, $n \ge 3$ . At first glance, this looks quite unsolvable, as it is a mixture of a recurrence relation and an integral equation, that too with differing arguments in $x$ . But just to make sure, is there a way to solve for $f_n(x)$ ? I’m ultimately looking for $f_n(1)$ so it’s also fine if that can be obtained without actually solving the equation. Note: $f_n(x)$ is defined to be the probability that the particle is inside the sphere of radius $x$ centered at the origin after $n$ moves. As the ‘base case’, $$f_2(x) =\begin{cases} \frac{x^2}{4}, & 0\le x\le 2 \\ 1, & x\gt 2 \end{cases}$$ Here are the graphs of $\color{blue}{f_2(x)}, \color{green}{f_3(x)}, \color{red}{f_4(x)} $ , and some initial values: $$f_0(1) = 1 \\ f_1(1) = 0 \\ f_2(1) = \frac 14 \\ f_3(1)= \frac 16 \\ f_4(1) = \frac{23}{192} \\ f_5(1) =\frac{11}{120} $$","['integral-equations', 'geometric-probability', 'recurrence-relations', 'calculus', 'probability']"
4051289,How is the pullback of a Riemannian metric defined?,"Let $M, N$ are two manifolds. Now I am interested in defining the pullback of an arbitrary tensor field of type $(r,s)$ under the diffeomorphism $\phi : M \rightarrow N$ as follows: $\phi^* T(\eta_1,\dots, \eta_r, X_1, \dots, X_s) = T( (\phi^{-1})^*(\eta_1), \dots, (\phi^{-1})^*(\eta_r), \phi_* X_1, \dots, \phi_* X_s)$ . where $\eta_i \in T_p^*(M)$ is a covector and $X_j \in T_p(M)$ is a vector. Actually I am interested in pullback of a metric tensor. We know that it is a $(0, 2)$ tensor. Therefore, the above formula becomes $$\phi^*g(X,Y) = g(\phi_*X, \phi_*Y)$$ . Now consider $g_{\alpha \beta}$ is a $(0, 2)$ tensor on $N$ . Now my question is can one write the formula as follows $$(\phi^*g)_{\mu \nu} = \frac{\partial y^{\alpha} }{\partial x^{\mu}} \frac{\partial y^{\beta} }{\partial x^{\nu}} g_{\alpha \beta}$$ . Please help me. Thanking in advanced.","['riemannian-geometry', 'smooth-manifolds', 'partial-derivative', 'manifolds', 'differential-geometry']"
4051291,Mumford Red Book proof of surjective morphism of schemes is stable under base change,"I am reading the following proof in the Red Book of Varieties and Schemes by Mumford saying that a surjective morphism of schemes is stable under base change and I came across some things that I didn't understand. ""The maps $r^*$ and $s^*$ define inclusions of fields"" The morphisms of schemes $r$ induces a map on stalks $\mathscr{O}_{S,r(x)}\to \mathscr{O}_{X,x}$ , which is a local homomorphism, so we get a map $k(r(x))\to k(x)$ . Why should this be an inclusion ? This might be obvious, but my intuition about this $k(x)$ is still very vague. Edit: This is clear now, morphisms of fields are always injective. ""defining $\alpha^*$ and $\beta^*$ to be the compositions"" Here, he is defining what the map on stalks should be. Does this then immediately define the morphism of sheaves? Any insight would be very much appreciated.","['algebraic-geometry', 'schemes']"
4051332,How to find the class of a function,"Let $$f(x) = \begin{cases} 
 x^3\sin(\frac{1}{x}); & \text{ if, } x \neq 0 \\
 0; & \text{ $x=0$ }
\end{cases}$$ How do I find the greatest value of n such that $f \in C^n ([-1,1])$ ? I know to find n, I must find the greatest n such that $f^{(n)}(x)$ is differentiable in the interval $[-1,1]$ . But how do I prove its differentiability?","['functions', 'taylor-expansion', 'analysis', 'real-analysis']"
4051354,What is the motivation behind the steps in this 'simple' proof that $\pi$ is irrational?,"In $1947$ , Ivan Niven published A Simple Proof that $\pi$ is irrational , which only requires knowledge of elementary calculus to understand. Since then, many variations of this proof have been published, one of which I will briefly outline here: Assume, for the sake of contradiction, that $\pi$ can be expressed in the form $a/b$ , where $a$ and $b$ are integers. Let $f$ be the polynomial function defined by $$
f(x)=\frac{x^n(a-bx)^n}{n!} \, ,
$$ where $n$ is a positive integer. Consider the integral $I=\int_{0}^{\pi} f(x)\sin x \, dx$ . Since $f$ and $\sin$ are positive on the interval $(0,\pi)$ , we have $0<I$ . Moreover, if $n$ is large enough, then $I<1$ . This is because $$
f(x)\sin x =\frac{x^n(a-bx)^n}{n!}\sin x<\frac{x^n\pi^n}{n!}
$$ and $$\int_{0}^{\pi}\frac{x^n\pi^n}{n!} \, dx <1$$ for sufficiently large $n$ . On the other hand, integration by parts tells us that \begin{align}
\int f(x) \sin x \, dx = &-f(x)\cos x +f'(x)\sin x + f''(x) \cos x - f'''(x)\sin x \\ &-f''''(x)\cos x +\ldots\pm f^{(2n)}(x)\cos x
\end{align} Every function $f^{(k)}$ (with $0 \leq k\leq 2n$ ) takes integer values when $x=0$ and $x=\pi$ . The same is true for $\sin$ and $\cos$ . Hence, $I$ must be an integer. But earlier we showed that if $n$ is sufficiently large, $0<I<1$ , thereby reaching a contradiction. $\blacksquare$ Although the steps in the proof are not too difficult to follow, it still leaves me scratching my head thinking why on earth someone would try to prove $\pi$ is irrational by defining a bizzarre-looking function and then proceeding to integrate it. The proof seems entirely unmotivated. Is there any insight into how someone could have thought of such a proof? Is there something about the function $f$ and the trigonometric functions that provide us with information about the irrationality of $\pi$ ?","['proof-explanation', 'irrational-numbers', 'real-analysis', 'calculus', 'pi']"
4051473,Determining a polynomial $p$ from its image of rationals.,"Let $f$ and $g$ be polynomials with rational coefficients, and let $F$ and $G$ denote the sets of values of $f$ and $g$ at rational numbers. Prove that $F = G$ holds if and only if $f(x) = g(ax + b)$ for some suitable rational numbers $a \not= 0$ and $b$ . This is a problem I found from ""Contests in Higher Mathematics"" whose problems are from the Miklos Schweitzer Competitions. I have found the problems in this competition deeply satisfying to think about and I would recommend for the reader to check them out I was hoping to get a hint for the solution. Please do not spoil the problem for me. I am only looking for a nudge.","['abstract-algebra', 'polynomials', 'rational-numbers']"
4051479,Probability of sampling linearly independent vectors,"Let $q$ be a prime so that $\mathbb{Z}_q$ is a field. I would like to sample $n$ vectors independently and uniformly from $\mathbb{Z}^n_q$ , to get a set $V = \{ v_i \}_{i=1}^n$ .
What is the probability that $V$ is a basis for $\mathbb{Z}^n_q$ ? I had the following proof idea, by induction. The problem reduces to what is the probability of sampling $n$ linearly independent vectors, and as such, we proceed by induction on the number of sampled vectors $k$ . For $k = 1$ , we only require that we are not sampling the zero vector, and as such we have that $\Pr[\{v_1\} \text{is LI} ] = 1 - q^{-n}$ . Now let us suppose that we have $k$ linearly independent vectors $\{ v_i \}_{i=1}^k$ . We sample a new vector $v_{k+1}$ . In order for it to be linearly independent, it must be that it is not a linear combination of the others, and as such there are at most $q^k$ possible 'forbidden' values. Namely these correspond to the possible coefficients $\alpha_i$ of the   linear combinations $\sum_{i=1}^k \alpha_i v_i$ . So we have that $\Pr[\{v_i\}_{i=1}^{k+1} \text{is LI} \, | \, \{v_i\}_{i=1}^{k} \text{is LI}] \geq 1 - q^{k - n}$ . As such we should have that $$\Pr[\{v_i\}_{i=1}^n \text{is LI}] = \Pr[\{v_i\}_{i=1}^n \text{is LI} | \{v_i\}_{i=1}^{n-1} \text{is LI}] \Pr[\{v_i\}_{i=1}^{n-1} \text{is LI}] \geq \prod_{i=1}^n (1 - q^{i - n})$$ Do you think this analysis is correct? What I am also interested in is the following generalizations, on which I, unfortunately, had less success. Suppose we set $n=3k$ and that instead of sampling the vectors independently we sample three matrices $M, M_0, M_1 \in \mathbb{Z}^{3k\times k}_q$ such that each matrix is of full rank . What would be an upper bound on the probability of the columns of said matrices spanning $\mathbb{Z}_q^{3k}$ ? I have found in the literature (Lemma 8) a claim that it should be at least $1 - \frac{2k}{q}$ but have not found any good argument Let us relax the very first statement, and admit that $q$ could be composite. Does this change the argument significantly? I am interested in this result both in the vector case and in the three matrices sample case. Thank you, I hope the formatting is clear enough :)
For context, I am investigating whether the construction in the linked paper would hold in nonprime order groups.","['probability-distributions', 'linear-algebra', 'probability']"
4051495,"If $a,b\in \mathbb R^+$, $ |a-2b|\leq\frac {1}{\sqrt{a}}$, $|b-2a|\leq\frac {1}{\sqrt{b}}$ Prove $a+b\leq 2$","Question: If $a,b\in \mathbb R^+$ , $|a-2b|\leq\frac {1}{\sqrt{a}}$ , $|b-2a|\leq\frac {1}{\sqrt{b}},$ prove $a+b≤2$ . I figured out that $a+b\leq \frac {1}{\sqrt{a}}+\frac {1}{\sqrt{b}}$ , but I am not sure how to prove that $a+b\leq 2$ after doing this. Can anyone help me?","['contest-math', 'algebra-precalculus', 'inequality']"
4051496,Linear combination of random variables and independence,"Given a set of real-valued normally distributed random variables $X_1, \dots, X_n$ , how do we show the following are equivalent? Any linear combination of $X_1, \dots, X_n$ is normally distributed There is a linear mapping $A$ such that the transformed random variables $AX_1, \dots, AX_n$ are independent Motivation: I want to reconcile two definitions of jointly Gaussian random variables. I believe a set of scalar Gaussian rvs $\{X_i\}$ can be shown jointly Gaussian under two characterizations: 1) $\{X_i\}$ are independent under some linear transformation, or 2) all linear combinations of $\{X_i\}$ are Gaussian-distributed. I don't know why these are equivalent, or how to prove this property for a given set of rvs $\{X_i\}$ . Edit: if the covariance matrix is known, how does this help? I think one case where 1 and 2 don't hold is if the covariance is singular.","['independence', 'probability-distributions', 'probability', 'random-variables']"
4051571,Why is the Maclaurin series for $\cos(x^2)$ simply the Maclaurin series for $\cos(x)$ with $x^2$ substituted for $x$?,"So I'm trying to understand why we can use expansions of Maclaurin series in this form. If I try to convert the following into a Maclaurin Series $$f(x) = x^3 \cos(x^2)$$ Using the following: $$\cos(x) = \sum_{n=0}^{\infty} \frac{(-1)^n x^{2n}}{(2n)!}$$ I get $$x^3 \cos(x^2) = \sum_{n=0}^{\infty} \frac{(-1)^n x^{4n+3}}{(2n)!}$$ Why can we plug in $(x^2)$ in in the place of $\cos(x)$ ? Isn't there a chain rule to consider, since the Maclaurin/Taylor Series have something to do with derivatives? Why is it that we can just plug in $x^2$ and it still works?","['power-series', 'calculus', 'taylor-expansion', 'sequences-and-series']"
4051576,Ramification points of projection to y-line,"Rick Miranda's ""Algebraic Curves and Riemann Surfaces"" chapter 2, lemma 4.6 says that: Let $X$ be a smooth projective plane curve defined by a homogeneous polynomial $F(x,y,z) = 0$ ; consider the map $G: X \rightarrow \mathbb{P}^1$ defined by $G[x:y:z] = [x:z]$ . Then $G$ is ramified at $p \in X$ if and only if $(\partial F/\partial y)(p) = 0$ . I understand that for point where either $x$ or $z$ is nonzero this theorem is true by looking at the affine parts and then considering local charts.  This only leaves the point [0:1:0] which might very well be a point in $X$ .  But the map $G$ is not even defined there. Is there something missing here? More generally, we know that for a curve $X$ , ratio of two homogeneous polynomials $P,Q$ such that the denominator does not identically vanish on $X$ gives a meromorphic function, and therefore gives a holomorphic map to Riemann sphere $\mathbb{P}^1$ as $[P : Q]$ . But for the points where both $P$ and $Q$ vanish, this map is not even defined?  What is going on?  Can I not write the  meromorphic function defined by $P/Q$ as $[P:Q]$ globally?  It seems to me that at points where both $P$ and $Q$ vanish I can simplify the function locally so that it either has a pole or a removable singularity. For a trivial example consider $P = Q = x$ and then $P/Q$ is just the constant function 1, but it still doesn't make sense to write $[x:x]$ because it won't be defined at points $x = 0$ , assuming there is such a point on $X$ .","['riemann-surfaces', 'algebraic-geometry']"
4051604,"Given a finite solvable group $G$, prove that a minimal normal subgroup $H$ is a $p$-group","Given a finite solvable group $G$ , and a minimal normal subgroup $H$ , prove that $H$ is a $p$ -subgroup for some prime $p$ . My Attempt: I am trying to write this proof without using the term ""characteristic subgroup"". I'm aware to the fact that by proving that $p$ -subgroup of $M$ is a characteristic subgroup will finish the proof. Let $p$ be a prime number such that $p$ is a divisor of the order of $M$ . By Sylow theorem, there exists a $p$ -subgroup of $M$ , let it be called $S$ . I'd like to prove that every element of $M$ is of order $p^n$ , for some $n \in \mathbb{N}$ .
let $s\in S, \  g\in G: g^{-1}sg \in M$ , as $S\le M$ and $M$ is normal in $G$ . but why and how I can prove that $=g^{-1}sg$ is of order $p^m$ , for some $m\in \mathbb{N}: m\le n$ .","['finite-groups', 'normal-subgroups', 'abstract-algebra', 'sylow-theory', 'group-theory']"
4051619,$\nabla\left(\nabla \boldsymbol{r}_{0} e^{i \boldsymbol{k} \boldsymbol{r}} e^{-i \omega t}\right) $- meaning?,"My physics professor wrote the following equation: $$
\nabla\left(\nabla \boldsymbol{r}_{0} e^{i \boldsymbol{k r}} e^{-i \omega t}\right)=-e^{-i \omega t} e^{i \boldsymbol{k r}} \boldsymbol{k}\left(\boldsymbol{k} \cdot \boldsymbol{r}_{0}\right)
$$ where $\mathbf{k}$ is a general $k$ -vector and $r=[r_x,r_y,r_z]^T$ a cartesian vector. Can someone explain how the right-hand side is obtained from the left-hand side? Usually $\nabla$ is used to denote the gradient, but calculating the gradient of the gradient of $\boldsymbol{r}_{0} e^{i \boldsymbol{k r}} e^{-i \omega t}$ does not lead to the expression on the right-hand side.","['notation', 'calculus', 'vector-analysis', 'algebra-precalculus', 'differential-geometry']"
4051635,Covariant derivative and $\nabla X$,"If I consider the covariant derivative of a vector field $Y$ with respect to $X$ this is usually indicated as $\nabla_X Y$ , but what's about $\nabla X$ ? This is the covariant derivative of $X$ and I have read it is  tensor field of type (1,1) such that if $Y\in \chi(\cal{M})$ (vector field) and $w\in \chi^*(\cal{M})$ (covector) $$\nabla X(Y,w)=w(\nabla_XY)$$ Why it is true? I only know that given a smooth function $f$ then $\nabla_{f X} Y=f\nabla_X Y$ , but really I can't understand the relationship between $\nabla X$ and $\nabla_X Y$ and so why the expression above holds. Can you help me please?","['tensors', 'derivatives', 'vectors', 'differential-geometry']"
4051652,"If the distances between every pair of airports is distinct, prove that more than $5$ planes can't land at any airport","The distances between any two airports of a country are distinct. From every airport one airplane takes off and lands at the closest airport. Prove that there doesn't exist an airport where more than 5 planes will land. I proved it in the following way: In order for a plane to take off from a certain airport and land at another, it means that the other airport is the closest to it at a distance $r$ . Hence it has a circle with radius r with center the airport which it took off from and with a point on its circumference, the airport at which it landed. If there are more than $5$ points which land at a certain airport, then you get a polygon $A_1A_2A_3...A_n$ with a point inside it $O$ . If $n\gt 5$ then we have that at least one $\angle OA_iA_{i+1}\lt60^o$ which is indeed a contradiction. This is what I managed to do for this question, but I am not completely certain I am completely correct. Could you please verify my solution and explain any other nice approaches and also explain to me why my last statement that $\angle OA_iA_{i+1}\lt60^o$ indeed is a contradiction as I worked it out only intuitively?","['contest-math', 'geometry', 'combinatorics', 'trigonometry', 'problem-solving']"
4051663,Poisson summation formula as a special case of the trace formula,"For $f \in L^1(\mathbb R)$ , the Fourier transform $\hat{f}: \mathbb R \rightarrow \mathbb C$ is defined by $$\hat{f}(x) = \int_{\mathbb R} f(y) e^{2\pi i xy}dy.$$ The Poisson summation formula asserts that for $f$ smooth and compactly supported, $$\sum\limits_{n\in \mathbb Z} f(n) = \sum\limits_{n \in \mathbb Z} \hat{f}(n).$$ I've heard that this formula arises as a special case of a trace formula for an integral operator of trace class on the Hilbert space $L^2(\mathbb R/\mathbb Z)$ , or that Selberg or Arthur's trace formula is a ""nonabelian Poisson summation formula.""  How can the Poisson summation formula be seen as arising in this way?","['harmonic-analysis', 'number-theory']"
4051672,Why does an empty intersection (for families) not make sense? [duplicate],"This question already has answers here : When would the intersection of the empty set mean anything? (1 answer) Unary intersection of the empty set (3 answers) intersection of the empty set and vacuous truth (3 answers) Closed 3 years ago . In Halmos' Naive set theory, on p. 35, he writes An empty union makes sense (and is empty), but an empty intersection
does not make sense. Suppose my index set is $I = \{1, 2\}$ and my indexed sets are defined as $A_i \equiv \{-i, i\}$ . Then $A_1 = \{-1,1\}$ , $A_2 = \{-2, 2\}$ , $\bigcup A_i = \{-2, -1, 1, 2\}$ and $\bigcap A_i = \emptyset$ . I don't see why that doesn't ""make sense"".",['elementary-set-theory']
4051673,Find all real numbers $x$ such that $\sqrt{x+2\sqrt{x}-1}+\sqrt{x-2\sqrt{x}-1}$ is a real number,"I want to find all values of $x\in \mathbb R$ such that the value of $\sqrt{x+2\sqrt{x}-1}+\sqrt{x-2\sqrt{x}-1}$ is a real number. I solved it as follows: $x+2\sqrt{x}-1\ge 0$ $(\sqrt{x}+1)^2-2\ge 0$ $(\sqrt{x}+1)^2\ge 2$ $\sqrt{x}+1\ge 2$ or $\sqrt{x}+1\le -\sqrt{2}$ The second can't hold, from the first $x\ge 3-2\sqrt{2}$ . Similarly $(\sqrt{x}-1)^2\ge 2$ , hence $x\ge 3+2\sqrt{2}$ . I find my solution to be very ugly. Is my solution correct and is there a neater approach?","['alternative-proof', 'algebra-precalculus', 'solution-verification', 'radicals']"
4051675,Limits using Cramer's Rule as determinant approaches 0,"I'm in Linear Algebra 1, and having just covered Cramer's Rule, the prof showed this interesting case that I have a further question about the significance of. Say we have a matrix containing a constant that can be adjusted, for instance, the system of equations 2cx+3y=6 4x+(c-1)y=4 giving $\begin{pmatrix}2c&3\\4&c-1\end{pmatrix}\begin{pmatrix}x\\y\end{pmatrix}=\begin{pmatrix}6\\4 \end{pmatrix}$ Since Cramer's rule only holds in cases where the determinant is nonzero, a typical question would be to find the values of c for which that is true. In this case, det(A)=0 when c=-2 or c=3. At c=-2 there are no solutions to the system, and at c=3 there are infinitely many solutions. In the case of c=3, we cannot simply apply Cramer's rule, because the denominator of x= $\frac{detA(1)}{detA}$ and y= $\frac{detA(2)}{detA}$ are both detA=0. However, what we can do is go back to the original system, leaving the variable c in the matrix, and calculate the values of detA, detA(1) and detA(2) in relation to c. If I do that, and completely factor, I get: detA=2(c+2)(c-3) detA(1)=6(c-3) detA(2)=8(c-3) Now I can use limits to get an answer from the formulation of Cramer's rule in the case of c=3. x= $\lim\limits_{c \to 3}\frac{6(c-3)}{2(c+2)(c-3)}$ y= $\lim\limits_{c \to 3}\frac{8(c-3)}{2(c+2)(c-3)}$ From which we can easily get the values of x= $\frac{3}{5}$ and y= $\frac{4}{5}$ , which is a valid solution. So Cramer's rule, despite its initial misgivings, has provided a solution to a system with a determinant of 0. My question (which my prof couldn't answer on the spot, which is why I'm bringing it here) is, which solution? What is special about these numbers, that they're the ones that happen to be spat out using this method? My first thought was that perhaps it's the particular solution, but it's not: the solution in parameterized form of the matrix when c=3 is $\begin{pmatrix}x\\y\end{pmatrix}=\begin{pmatrix}1\\0 \end{pmatrix}+s\begin{pmatrix}-1/2\\1 \end{pmatrix}$ So I am at a loss as to what these numbers ""are,"" if they ""are"" anything in particular. Surely they're not just random?","['limits', 'linear-algebra']"
4051723,Show there exists no diffeomorphism between positive real line and a spiral,"I'm given the following two subset of $\mathbb{R}^2$ : $$
M = \{(t,0) \in \mathbb{R}^2 \mid t>0\}, 
\quad 
N = \{(t \cos(1/t),\, t \sin(1/t)) \in \mathbb{R}^2 \mid t>0 \} 
$$ The goal of the exercise is to show that there exists no diffeomorphism $\varphi: \mathbb{R}^2 \to \mathbb{R}^2 $ such that $\varphi (M) = N$ . In a previous exercise I showed that there exists a homeomorphism such that the same conditions are fullfiled. I'm also given the hint that one should start by showing that the partial derivatives with respect to x of such a diffeomorphism $\varphi: \mathbb{R}^2 \to \mathbb{R}^2$ (if he would exist) would vanish in $(0,0)$ . I know how to finish the exercise if I find a way of showing that the partial derivatives with respect to x vanish at $(0,0)$ . Then the Jacobian determinant is zero at $(0,0)$ so the inverse function is not differentiable at $(0,0)$ and I find a contradiction to the existence of a differeomorphic $\varphi$ . So far I tried to use the difference quotient $$
\lim_{h\to 0} \frac{\varphi_1(x+h,y) - \varphi_1(x,y)}{h}. 
$$ For this Limit to be zero the numerator has to decrease faster than the linear denominator. I figure that I will have to use that the line segment around $(0,0)$ in $N$ is infintely long while the length of the line segment of the preimage is finite but so far I'm not sure how to combine this with the difference quotient. The concept of differentiating an unknown function is not something I encountered before so I would be thankful for any help.","['differential-topology', 'derivatives', 'analysis', 'differential-geometry']"
4051743,Evaluate conditional expectation $E[e^X | Y=1]$,"Given $X,Y \sim N(0,1)$ , X,Y follows a joint normal distribution and $corr(X,Y) = \frac{1}{2}$ . Evaluate $E[e^X|Y=1]$ . I'm not sure where to start on this one. I did a change of variable $Z = e^X$ and use the definition of conditional expectaion: $E[Z|Y=1] = \sum_{z} zp_{Z|Y}(z|y)$ but it isn't helpful.","['conditional-expectation', 'probability-theory']"
4051769,Area of the section enclosed by the curve,"Curve is formed by the intersection of the surface: $\displaystyle \frac{1}{x} + \frac{1}{y} + \frac{1}{z} = 0$ with the plane $2x + 2y + z = 1$ What is the area enclosed by this curve?
Eliminating z from both equations, I get an implicit equation relating $x$ and y, with terms in $x^2, y^2, xy, x,$ and $y$ . But I don't know where to go from there.","['integration', 'multivariable-calculus', 'calculus']"
4051788,Can a finite group act transitively on an infinite set?,"I had a question on my algebra exam, asking me to show that in case of a transitive action of a finite group $G$ on a set $X$ , $|X|$ divides $|G|$ . In case of a finite set, this is trivial, so I tried to see if I could come up with a possible counterexample with $X$ infinite (I failed to do so). Intuitively I feel like an infinite $X$ is ""too big"" for a finite group to act transitively on, but how would one show this formally?","['group-theory', 'group-actions', 'finite-groups']"
4051812,Prove inequality $\tan \left( \frac\pi2 \frac{(1+x)^2}{3+x^2}\right) \tan \left( \frac\pi2 \frac{(1-x)^2}{3+x^2}\right)\le\frac13 $,"How to determine the range of the function $$f(x)=\tan \left( \frac\pi2 \frac{(1+x)^2}{3+x^2}\right)
\tan \left( \frac\pi2 \frac{(1-x)^2}{3+x^2}\right)
$$ It it is straightforward to verify that $f(x)$ is even and $$f(0)= \frac13, \>\>\>\>\> \lim_{x\to\pm \infty} f(x) \to -\infty$$ which implies $f(x) \in (-\infty,\frac13]$ , i.e. $$\tan \left( \frac\pi2 \frac{(1+x)^2}{3+x^2}\right)
\tan \left( \frac\pi2 \frac{(1-x)^2}{3+x^2}\right)\le \frac13
$$ and is visually confirmed below However, it is not obvious algebraically that $f(x)$ monotonically decreases away from $x=0$ . The standard derivative tests are not viable due to their rather complicated functional forms. So, the question is how to prove the inequality $f(x) \le \frac13$ with rigor. Note that it is equivalent to proving $$\cot \left(\frac{\pi(1+x)}{3+x^2}\right)
\cot \left(\frac{\pi(1-x)}{3+x^2}\right)\le \frac13
$$","['calculus', 'trigonometry', 'inequality']"
4051815,Intuition behind the coupon collector problem. Is there inclusion-exclusion principle in play?,"As well-known the expected number of coupons $N$ required to collect the complete set of $n$ coupons in the general case of non-uniform probability distribution can be computed as: $$
\mathbb E (N)=\sum_i\frac1{p_i}-\sum_{(i,j)}\frac1{p_i+p_j}+\sum_{(i,j,k)}\frac1{p_i+p_j+p_k}-\cdots-\frac{(-1)^n}{\underbrace{p_1+p_2+\cdots+p_n}_{=1}},\tag1
$$ where $p_i$ is the probability to obtain $i$ -th coupon. My question is: can this pattern be explained on the basis of the inclusion-exclusion principle? It really strikes that the first term $\frac1{p_i}$ is nothing else as the expected number of coupons till obtaining the $i$ -th coupon, next term $\frac1{p_i+p_j}$ is the expected number of coupons till obtaining the $i$ -th or the $j$ -th coupon and so on. I am looking for intuitively understandable explanation which would be consistent with the above interpretation of the separate terms. I would appreciate any hint.","['expected-value', 'inclusion-exclusion', 'combinatorics', 'coupon-collector', 'probability']"
4051847,Intersection of sets is indeed a set,"My question is pretty straight forward - how do I use ZF axioms to prove that if $\{A\}_{i\in\Bbb{N}}$ is a family of sets, then $\bigcap_{i}A_i$ is a set? I feel like I should be using the axiom of union and the axiom of separation, but I'm not quite sure how.","['elementary-set-theory', 'axioms']"
4051848,"Given a normed vector space $X$, can you always define a bounded linear functional $f$ which is bounded above and below by the norm?","Let $X$ be a (possibly infinite-dimensional) normed vector space over $\mathbb{R}$ , whose norm is denoted $|| \cdot ||$ . Given two non-negative scalars, say $M, N \in \mathbb{R}$ with $M < N$ , can you always find a bounded linear functional $f: X \to \mathbb{R}$ such that $M||x|| \leq | f(x) | \leq N || x||$ for all $x \in X$ ? Obviously, if $f$ is bounded then $|f(x)| \leq ||f||_{op} || x|| \leq K || x||$ for some non-negative $K \in \mathbb{R}$ . But this fact is kind of going in the ""wrong direction"" so I'm not too sure if this is helpful. It does seem like there are several corollaries to the Hahn-Banach theorem that might also be related, but again, I'm not sure if there are additional assumptions that I would need to make to force this question to have a positive answer.","['normed-spaces', 'functional-analysis']"
4051879,Existence of subspace disjoint from manifold,"Suppose $M$ is a differentiable $m$ -submanifold of $\mathbb{R}^n$ , where $m < n$ . For $s < n − m$ , I would like to show there is an $s$ -dimensional affine subspace $A$ of $\mathbb{R}^n$ such that $A\cap M=\emptyset$ . Also, what happens for $s=n-m$ ? I am not really sure where to start. Intuitively, I can understand that for instance, if you have a surface in $\mathbb{R}^3$ , say, then you can find a curve which does not intersect that surface.","['manifolds', 'differential-topology', 'smooth-manifolds', 'differential-geometry']"
4051998,Estimate the number of sides of the die,"Suppose you have a fair die with an unknown number of sides, $T$ . Each side is distinct, marked with a complex symbol. Given enough rolls, can you estimate $T$ ? My intuition is that can do this via a generalization of the mark and recapture procedure . Roll the die some large number of times, keeping track of all the sides that you have rolled and the number of times you have rolled them. Since the probability of rolling a previously rolled side in $N$ rolls is completely determined by $N$ and $T$ , then expected proportion of unique to total sides $p$ should also be determined by $N$ and $T$ . What is the relationship between $p$ , $N$ , and $T$ ? As pointed out by Don Thousand, you can save yourself a lot of overhead and just track one arbitrarily picked side. Since the probability of rolling the chosen side on any one roll is $T^{-1}$ , you expect that you would see the side repeated $NT^{-1}$ times. You can use standard statistical techniques to determine how precise this estimate likely is. If you have reasonably strong priors about the likely size of the population, within an order of magnitude or so, you can probably figure out how big of an $N$ you need to satisfy your requirements. However, this procedure is inefficient, since we will likely have re-rolls of sides other than the one we have picked. The frequency of those re-rolls is almost equally as informative. How can we combine all the information we have to arrive at an estimate for $T$ ?","['probability', 'sampling']"
4052005,"Special permutations of $\{1,2,3,\ldots,n\}$","How do you show that number of permutations of $\{1,2,3,\ldots,n\}$ such that image of no two consecutive numbers is consecutive is $$n! + \sum_{k = 1}^{n}(-1)^k\sum_{i = 1}^{k}\dbinom{k - 1}{i - 1}\dbinom{n - k}{i}2^i(n - k)!$$ In short we need to find number of permutations of $\{1,2,3,\ldots,n\}$ such that none of the following occur: $12, 23, \ldots, (n-1)n \quad $ and $ \quad21, 32, \ldots, n(n-1)$ that is no adjacent numbers should be consecutive. I tried proving the formula but didn't get any satisfactory result, It seems to be inclusion exclusion principle would work, but there are too many cases to count. I tried to find a recurrence relation, but couldn't do it either. Afterwards I tried to get a generating function for the same but didn't succeed. I don't see any other approach to get through this but I think the most useful tool would be PIE however I'm not finding a good way to use PIE since number of cases are too much. Any help or hint would be highly appreciated. Thanks! Note that: I have read almost all the references related to the problem from OEIS. I have read the whole paper https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-38/issue-4/Permutations-without-Rising-or-Falling-omega-Sequences/10.1214/aoms/1177698793.full but in the paper there aren't any rigorous proofs and most of the proofs are just excluded simply by saying that 'use basic PIE to derive this'. I am looking for a more direct poof using enumerative combinatorics or generating functions. I highly appreciate your time and efforts. Thanks.","['permutations', 'combinatorics', 'permutation-matrices', 'recurrence-relations']"
4052131,Test to determine if a polynomial has only real roots?,"Given a polynomial $p(x)=x^n + c_{n-1} x^{n-1} + \cdots + c_0$ with real coefficients $c_{n-1}, \ldots, c_0$ , is there an efficient method to determine whether all roots to the polynomial are real and not complex? If it helps, you may assume all of its $n$ roots are distinct. I know, for the quadratic case, the discriminant $c_1^2 - 4c_0>0$ is necessary and sufficient to determine if all roots are real.","['roots', 'complex-analysis', 'algebraic-geometry', 'polynomials', 'algebra-precalculus']"
4052136,Understanding the Cauchy Integral Formula,"This is the statement of the Cauchy Integral Formual .  I have seen its proof, and I have used this formula many times to compute integrals. However, I feel like I do not understand this formula completely. Please note that Wikipedia says, ""it expresses the fact that a holomorphic function defined on a disk is completely determined by its values on the boundary of the disk."" This statement seems very strong and insightful. My question is: What does this exactly mean? I have some sort of vague intuitive understanding but I am not satisfied with my understanding at all. Since the integral of ${\frac {1}{z-a}}$ is $2 \pi i$ along the boundary of the disc, ""roughly"" we are taking ""the average"" of the function along the boundary of the disc to compute the function value $f(a)$ for every $a$ in the interior of $D.$ Could you help me understand the following sentence? ""It (the Cauchy Integral Formula) expresses the fact that a holomorphic function defined on a disk is completely determined by its values on the boundary of the disk."" Thanks so much.","['complex-analysis', 'complex-integration', 'cauchy-integral-formula']"
4052143,Calculate or evaluate double trigonometric integral,"I would like to calculate: $$\int_{0}^{\pi} \left( \int_{0}^{\pi} \frac{\sin\varphi}{1+\left(\cos2\theta-\cos\varphi \right)^2} \cos\left(j\varphi\right) d\varphi \right) \cos\left(2^i \theta\right)d\theta$$ where $i,j\in\mathbb N$ . I tried with integration by parts for: $$\int_{0}^{\pi} \frac{\sin\varphi}{1+\left(\cos2\theta-\cos\varphi \right)^2} \cos\left(j\varphi\right) d\varphi $$ but I came up with nothing. Maybe it is unmanageable. What do you think?","['integration', 'multivariable-calculus', 'calculus']"
4052162,Integrate $\frac{\log(x^2+4)}{(x^2+1)^2}$.,"Using residue calculus show that $$\int_0^{\infty}\frac{\log(x^2+4)}{(x^2+1)^2}dx=\frac{\pi}2\log 3-\frac{\pi}6.$$ I was thinking of using some keyhole or semi-circular contour here. But the problem is apart from poles at $x=-i$ and $x=i$ , the logarithm has singularities when $x=\pm 4i$ . I consider $C_R$ , a semicircle contour oriented clockwise with radius $R$ centered at origin. The semicircle resides in the lower half plane, so that it encloses $x=-i$ as a pole.  I set $$\int_{C_R} \frac{\log(2-ix)}{(x^2+1)^2}dx$$ But it seems like it leads to wrong answer.","['integration', 'complex-analysis', 'contour-integration', 'residue-calculus', 'complex-integration']"
4052304,Prove that a certain sum of binomial coefficients is divisible by a power of 2,As many will recognize the following expression is a closed form for the Fibonacci numbers. Can it be proved that $$\frac{1}{2^{n-1}} \sum_{j=0}^{\lfloor n/2 \rfloor} \binom{n}{2j+1} 5^{j} \quad \text{where} \quad n \in\mathbb{N}$$ are integers without using the fact that these are the Fibonacci numbers?,"['summation', 'fibonacci-numbers', 'binomial-coefficients', 'combinatorics', 'binomial-theorem']"
4052346,Why is the indicator function $\mathbb{1}_{\{|X_k| < \epsilon\}}$ in Lindeberg's condition of the CLT?,"I have seen two versions of Central Limit Theorems (CLTs) with Lindeberg's condition as a requirement. One for triangle schemes of the form $\{X_{n,k}|1 \leq k \leq n, n\in \mathbb{N} \}$ (1) $$\forall \epsilon>0 : \underset{n \rightarrow \infty}{\lim}\sum_{k=1}^{n} E[ X_{n,k}^2 \mathbb{1}_{\{|X_{n,k}| < \epsilon\}}] = 0$$ and another one for a 'simple' sequence of random variables (RVs) (2) $$\forall \epsilon>0 :\underset{n \rightarrow \infty}{\lim}\frac{1}{s_n}\sum_{k=1}^{n} E[ X_{k}^2 \mathbb{1}_{\{|X_k| < \epsilon s_n\}}] = 0$$ where $s_n^2 := \sum_{k=1}^{n} \sigma_{k}^2$ . In both cases the expectations of each individual RV are $0$ and the variances $\sigma_{n,k}^2$ and $\sigma_{k}^2$ respectively are finite (in the case of the triangle schemes one also demands that $\lim_{n \rightarrow \infty} s_n^2 = \sigma^2$ for some $\sigma \in \mathbb{R}_{+}$ ).
You can see a more general form of the condition and a corresponding CLT here: https://en.wikipedia.org/wiki/Lindeberg%27s_condition My understanding so far is that Lindeberg's condition guarantees that the variances are 'sufficiently small' and don't escalate towards infinity at any point. Feel free to correct me on that one. Now what I don't understand at all is why the indicator function $\mathbb{1}_{\{|X_k| < \epsilon\}}$ is in that sum. Couldn't I demand $$\underset{n \rightarrow \infty}{\lim}\sum_{k=1}^{n} E[ X_{n,k}^2] = 0$$ in the case of (1) and $$\underset{n \rightarrow \infty}{\lim}\sum_{k=1}^{n} E[ X_{k}^2 ] = \sigma^2 < \infty$$ in the case of (2) instead? I realize the question on the intuition of Lindeberg's condition ( Interpreting the Lindeberg's condition ) still does not have an answer, so I don't expect much. But any light you could shine on this issue in particular would be greatly appreciated.","['stochastic-processes', 'convergence-divergence', 'central-limit-theorem', 'probability-theory']"
4052391,Is there a space of all finite models?,"Let $\mathcal{L}=\{R_i\}_{i \in I}$ be a relational language. There is a natural construction of a compact space of countable $\mathcal{L}$ -structures, namely, the space $$ \prod_{R_i \in \mathcal{L}} 2^{\mathbb{N}^{n_i}}$$ where $n_i$ is the arity of the relation symbol $R_i$ . Here the intuition behind the topology is that the more the relations of two structures agree on finite fragments of the underlying set (which is chosen as $\mathbb{N}$ without loss of generality) the closer these structures are. This idea will clearly break down if one considers finite $\mathcal{L}$ -structures since a finite amount of data regarding its relations will enable us to distinguish a structure from all the others, so we should end up getting the discrete topology. Indeed, we do get this if $\mathcal{L}$ is finite and we replace $\mathbb{N}$ by $\{0,1,\dots,n\}$ and take the disjoint union of these spaces as $n$ ranges over $\mathbb{N}$ . Can one construct a topological space of all finite $\mathcal{L}$ -structures other than the discrete space? Just to avoid any non-trivial topologies arising from the cardinality of $\mathcal{L}$ , let us assume that $\mathcal{L}$ is finite; so we are looking for a countably infinite (preferably Hausdorff) topological space. Obviously I'd prefer to have some kind of intuition behind the notion of closeness in this space. Given how much the space of countable structures has been studied, surely someone must have tried to construct such a space.","['general-topology', 'logic', 'model-theory']"
