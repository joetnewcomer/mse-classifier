question_id,title,body,tags
4173209,Creating a set-builder notation with alternating negative and positive numbers,"I'm working on a problem: ""Convert the given set into a set in set-builder notation: $B = \{2, -5, 8, -11, 14, ...\}$ ."" I found that for the pattern of number changing is going up by $3$ and alternating between negative and positive integers. Negative when $x$ is odd and positive when $x$ is even. I've made this set-builder notation below for the changing by $3$ . $$\{x ∈ \mathbb Z | x\%3 - 2 = 0\}$$ What can I modify in the above set-builder notation to work with the alternating between positive and negative aspect.","['notation', 'discrete-mathematics']"
4173219,Visualizing the norm of a bounded linear functional,"$\def\b{\mathbb}\def\F{\b F}\def\R{\b R}\def\C{\b C}\def\n#1{\|#1\|}\def\abs#1{\left|#1\right|}$ Setup: Let $X$ be a vector space over a field $\F$ . (For simplicity, let $\F \in \{\R,\C\}$ .) Let $\n\cdot$ be a norm on $X$ , and let $f : X \to \F$ be a bounded linear functional. Norm of Functionals: Recall that we can define the norm of $f$ by $$\n f := \sup_{\substack{x \in X \\ x \ne 0}} \frac{\abs{f(x)}}{\n x} = \sup_{\substack{x \in X \\ \n x = 1}} \abs{f(x)}$$ Hyperplanes & $H_1$ : Define now a hyperplane as follows. Let $Y$ be a subspace of $X$ with $\mathrm{codim} \; Y := \dim X/Y = 1$ . The elements of the quotient space $X/Y$ are called hyperplanes parallel to $Y$ . In particular (cf. Kreyszig's Introduction to Functional Analysis , exercise $2.9.12$ ): if $f \ne 0$ is a functional on $X$ , then the set $H_1$ defined by $$H_1 := \Big\{ x \in X \; \Big| \; f(x) = 1 \Big\}$$ is a hyperplane parallel to the null space of $f$ , $$\mathcal N(f) := \Big\{ x \in X \; \Big| \; f(x) = 0 \Big\}$$ That is to say, since $\mathrm{codim}\, \mathcal N(f) = 1$ (as $f \ne 0$ ), then $H_1$ is parallel to $\mathcal N(f)$ , and $H_1 \in X/\mathcal N(f)$ . The Property of Concern: Another exercise in Kreyszig ( $2.9.14$ ) then gives the following property: within the previous circumstances, we may write $$\n f = \frac{1}{\displaystyle \inf_{x \in H_1} \n x}$$ Alternatively, taking the convention of a distance between a point $x$ and a set $S$ in a metric space with metric $d$ to be $$d(x,S) := \inf_{s \in S} d(x,s)$$ then we may equivalently write $\n f$ as being the reciprocal of the distance from the origin (or zero vector) and the hyperplane $H_1$ , i.e. $$\n f = \frac{1}{d(0,H_1)}$$ Of course in our context the distance (between points) is that induced by the norm, i.e. $$d(x,y) := \n{x-y}$$ My Question: Normally it is very hard for me to imagine what the norm of a functional or operator might look like in the sense that norms generalize the Euclidean length/magnitude of vectors that we're used to. However, this seems to be very close to a very nice visual in my opinion, though I don't know what. The reciprocal in the statement of the property in particular seems problematic, yet possibly also hints at the notion of circles of inversion in some sense, but I wouldn't know nearly enough about that to flesh it out. In any event, does anyone have a nice way to visualize the norm of a functional as given above? Examples in particular would be amazing; I would love to have some concrete visualizations of such an otherwise-abstract notion! (To be clear, I do not need help proving these properties, I have already done so. Rather I seek a means of visualizing the norm of an operator as the reciprocal of the distance between it and the hyperplane $H_1$ .)","['visualization', 'normed-spaces', 'functional-analysis', 'metric-spaces']"
4173260,Choosing elements from an abelian group $\mathbb{Z}_n$ that make the enumeration of partitions incomplete.,"Take an abelian group $(\mathbb{Z}_n,+)$ and enumerate all partitions of two elements (i.e. $x=x_1+x_2$ ) of each element $\{0,1,...,n-1\}=\mathbb{Z}_n$ . Take, for example, abelian groups $\mathbb{Z}_9$ and $\mathbb{Z}_{10}$ . Now, the enumerations of the partitions of these groups would be the following (note that $x=x_1+x_2$ where $x_1=x_2$ is not allowed, i.e. $x_1$ and $x_2$ may not be equal!): $\mathbb{Z}_9:$ $0=8+1,7+2,6+3,5+4$ $1=8+2,7+3,6+4,0+1$ $2=8+3,7+4,6+5,0+2$ $3=8+4,7+5,0+3,1+2$ $4=8+5,7+6,0+4,1+3$ $5=8+6,0+5,1+4,2+3$ $6=8+7,0+6,1+5,2+4$ $7=0+7,1+6,2+5,3+4$ $8=0+8,1+7,2+6,3+5$ $\mathbb{Z}_{10}:$ $0=9+1,8+2,7+3,6+4$ $1=9+2,8+3,7+4,6+5,0+1$ $2=9+3,8+4,7+5,0+2$ $3=9+4,8+5,7+6,0+3,1+2$ $4=9+5,8+6,0+4,1+3$ $5=9+6,8+7,0+5,1+4,2+3$ $6=9+7,0+6,1+5,2+4$ $7=9+8,0+7,1+6,2+5,3+4$ $8=0+8,1+7,2+6,3+5$ $9=0+9,1+8,2+7,3+6,4+5$ Now, my question is the following: how many ways can we choose the total of $\lfloor \frac{n-1}{2}\rfloor$ distinct elements from $\mathbb{Z}_n$ such that when these elements are deleted, there exists at least one remaining element in $\mathbb{Z}_n$ that may not be expressed as a partition $x=x_1+x_2$ anymore. For instance, if we look at $\mathbb{Z}_9$ then $\lfloor \frac{9-1}{2} \rfloor=4$ and if we delete $\{8,2,3,5\}$ from $\mathbb{Z}_9$ then we cannot express $0$ as a partition $0=x_1+x_2$ where $x_1,x_2\in \mathbb{Z}_9 \setminus \{8,2,3,5\}$ . I noticed that no $\lfloor \frac{n-1}{2} \rfloor$ consecutive elements may be deleted from $\mathbb{Z}_n$ so there must be at least $n$ different ways to do this. However, there have to be more than $n$ due to, for instance, my previous example of $\mathbb{Z}_9\setminus \{8,2,3,5\}$ .","['number-theory', 'abstract-algebra', 'combinatorics', 'discrete-mathematics', 'group-theory']"
4173271,The variance of $\left(\frac{kX}{1+kX}\right)$ when $X$ is lognormal,"I was wondering if $X$ is lognormal, and $k$ is ""small enough"", can we conclude that $var\left(\frac{kX}{1+kX}\right)$ is negligible? Notice that $$var\left(\frac{kX}{1+kX}\right)=k^2var\left(\frac{X}{1+kX}\right).$$ I guess this would depend if it's reasonable to assume that $var\left(\frac{X}{1+kX}\right)$ is bounded or does not go wild when $k\to 0.$ Any thoughts? Thanks!","['stochastic-processes', 'probability-distributions', 'probability-theory', 'probability']"
4173293,Constructing a smooth maximal atlas,"Firstly consider the following notations and definitions: Notation: Let $(M,\mathfrak{A})$ be a smooth manifold. Then $\color{red}{\tau_M(\mathfrak{A})}$ denotes the topology in $M$ induced by the maximal atlas $\mathfrak{A}$ . Definition: Let $(M,\mathfrak{A})$ a smooth manifold. Suppose that $E$ is a set and $\pi :E\to M$ is surjective map. We say that $(U,\varphi )$ is a local trivialization of $\pi$ with rank $r$ if the following propositions are true: $U\in \tau_M(\mathfrak{A})$ $\varphi :\pi ^{-1}[U]\to U\times \mathbb{R}^r$ is a homeomorphism with respect to the topology $\{\pi^{-1}[O]\cap \pi ^{-1}[U]:O\in\tau_M(\mathfrak{A})\}$ in $\pi ^{-1}[U] $ and the product topology of $\tau_M(\mathfrak{A})$ with the standard topology of $\mathbb{R}^r$ ; $\pi =\pi _1\circ \varphi $ in which $\pi _1:U\times \mathbb{R}^r\to U$ is given by $\pi _1(x,y):=x$ ; My question is: How can I prove the proposition below? Proposition: Let $(M,\mathfrak{A})$ be smooth manifold with dimension $m$ . Suppose that the following propositions are true: $\pi :E\to M$ is surjective map in which $E$ is any set; There's a collection $\big\{(U_i,\varphi _i)\big\}_{i\in I}$ of local trivializations of $\pi$ with rank $r$ such that $M=\cup_{i\in I}U_i$ and for all $i,j\in I$ the map $\varphi _i\circ \varphi^{-1}_j:(U_i\cap U_j)\times \mathbb{R}^r\to (U_i\cap U_j)\times \mathbb{R}^r$ is a smooth map with respect to the obvious product manifold. Then there's is a smooth maximal atlas $\mathfrak{E}$ such that $(E,\mathfrak{C})$ is a smooth manifold with dimension $m+r$ and $\pi :E\to M$ is a smooth map. What I did: I proved the above proposition. However the length of my proof may hide errors that I'm not being able to notice (so that proposition may even be false). For this reason I would like to know if there is a simpler proof. Also I would like to know if there is a book that contains the proof of the previous proposition. If that proposition is true, then $(\pi ,E,M)$ is a vector bundle because we can construct a $\mathbb{R}$ -vector space structure in $\pi^{-1}[p]$ for all $p\in U_i$ and $i\in I$ such that $\varphi _p:\pi^{-1}[p]\to \mathbb{R}^r$ given by $\varphi_p (x):=\pi _2\circ \varphi_i (x)$ is an isomorphism of vector spaces in which $\pi _2:U\times \mathbb{R}^r\to \mathbb{R}^r$ is given by $\pi _2(x,y):=y$ . Below is a sketch of my proof: Let $i\in I$ be any element. Let $(V_i,\psi _i)$ be $m$ -chart of $(M,\mathfrak{A})$ such that $V_i\subseteq U_i$ . Define $\psi _i\times \text{id}_r:V_i\times\mathbb{R}^r\to \psi [V_i]\times \mathbb{R}^r$ by $(\psi _i\times \text{id}_r)(x,y)=(\psi _i(x),y)$ . It's easy to show that this map is smooth. We can show that $\varphi_i |_{\pi ^{-1}[V_i]}:\pi ^{-1}[V_i]\to V_i\times \mathbb{R}^r$ is a homeomorphism. Define $\sigma _i:\pi ^{-1}[V_i]\to \psi_i [V_i]\times \mathbb{R}^r$ by $\sigma _i(x):=(\psi _i\times \text{id}_r)\circ \varphi _i(x)$ . We can show that $\big\{(\pi ^{-1}[V_i],\sigma _i)\big\}_{i\in I}$ is a smooth atlas of $E$ (see the hypothesis 2 of the ""Proposition"" above). So there's a smooth maximal atlas $\mathfrak{E}$ such that $(E,\mathfrak{E})$ is a smooth manifold with dimension $m+r$ . We can also show that $\varphi _i:\pi ^{-1}[U_i]\to U_i\times \mathbb{R}^r$ is a smooth map using the manifold $(E,\mathfrak{E})$ . Since $\pi |_{\pi^{-1}[U_i]}=\pi _1\circ \varphi _i$ for all $i\in I$ and $\pi_1$ is smooth, then we can prove that $\pi :E\to M$ is indeed smooth.","['smooth-manifolds', 'reference-request', 'vector-bundles', 'manifolds', 'differential-geometry']"
4173299,Does the maxima of $\sin x + \sin (\sin x ) + \sin(\sin (\sin x )) + \sin(\sin(\sin (\sin x ))) + ...$ converge?,"Does the maxima of $\sin x + \sin (\sin x ) + \sin(\sin (\sin x )) + \sin(\sin(\sin (\sin x ))) + ...$ converge? Given that $f^{n+1}(x) = f(f^n(x))$ , where $f(x) = \sin x$ , each ""next"" term grows by $f^{n+1}(x)$ . Thus, if there's a convergence point, it would mean that $f^{\infty}(\pi/2) = 0$ . Is there any way to prove this? Another form of this expression would be the repeated integral bounds of $\cos x$ , something like $\int_0^{\int^{pi/2}_0\cos xdx}\cos x dx$ repeating.","['convergence-divergence', 'recursion', 'sequences-and-series']"
4173323,"Is there an ellipse with rational major and minor axes which has a ""simple"" closed form perimeter?","Other than the trivial case of an ellipse with equivalent major and minor axes (a circle) or the degenerate case where one axis is $0$ , is there any known ellipse that has rational length major and minor axes and whose perimeter can be represented in closed form as either an algebraic number, or else an algebraic multiple of $\pi$ ?* If, by some chance, the answer is yes and such an ellipse is possible I would very much like to know what proportions one such ellipse has. EDIT: *Or more generally, an algebraic multiple of an algebraic power of $\pi$ .","['conic-sections', 'geometry']"
4173470,Find all functions $f(x)$ such that $f(x)+f\left(\frac{x-1}{x}\right)=2 x+4$ [duplicate],"This question already has answers here : Find all functions $f$ such that $f(x)+f(\frac{1}{1-x})=x$ (3 answers) Closed 3 years ago . Here we have $$f(x)+f\left(\frac{x-1}{x}\right)=2 x+4$$ Find the function $f(x)$ . Firstly, I let $t=\frac{x}{x-1}$ then I got the equation $$f\left(\frac{1}{t-1}\right)+f(t)=\frac{4t-2}{t-1}$$ After that I don’t find any notices to do more. Please kindly give me a hint . Thank beforehand!","['calculus', 'functions']"
4173505,Explicit map from $\mathbb{N}^t \to \mathbb{N}$,"I know how to proof the following map from $\mathbb{N}\times \mathbb{N} \to \mathbb{N}$ is injective : $(n_1, n_2) \to  \binom{n_{1}+n_{2}} 2 + n_{1}$ . An obvious generalization of the above map from $\mathbb{N^t} \to  \mathbb{N} $ seem like as follows: $(n_1, \dots, n_t) \to \sum_{j = 1}^t \binom{\sum_{i = 1}^j n_i} j$ . I have a feeling that this generalized map from $\mathbb{N^t} \to  \mathbb{N} $ is also injective. But I don't know how to prove it. Geometrically it seems very difficult as compared to the proof for the case $t=2$ . I think there should be some algebraic proof. A rough sketch of the proof or any suitable reference book where I can read proof for this general case will be a great help.","['combinations', 'combinatorial-proofs', 'number-theory', 'elementary-number-theory', 'discrete-mathematics']"
4173544,When does downward closure commute with supremum?,"Let $A$ be a suplattices, and suppose we have a family $\{a_i\}_{i\in I}\subseteq A.$ Is $\bigcup_{i\in I}(\operatorname{\downarrow}a_i) = \operatorname{\downarrow} \sup_{i\in I}(a_i)$ in general? Here $\downarrow a$ means the principal downward closed sets (order ideal) generated by $a.$ I believe this assertion is wrong in general, and my counter example is $I=\{1, 2\}$ and $A=\{0\lt a_1\lt 1, 0\lt a_2\lt a\lt 1\}.$ Then $\operatorname{\downarrow} a_1\cup\operatorname{\downarrow} a_2=\{0, a_1, a_2\}$ while $\operatorname{\downarrow}(a_1\lor a_2)=A.$ Am I correct? Are there any obvious conditions on $A$ or $\{a_i\}_{i\in I}$ that would guaranteed the property in the above question? I am looking for a condition like $A$ being distributive. This sounds like a very vague question. But, hopefully more experienced people can tell me something useful.","['elementary-set-theory', 'order-theory', 'supremum-and-infimum', 'lattice-orders']"
4173588,How do we know when we have all solutions to a differential equation?,"My question is theoretical, but it really bothers me. The way I see differential equation's solutions is that someone observed that, for instance, $Ce^{Ax}$ solves first order equations, etc. The solutions that we know are valid, but how can we be sure that there are no other solutions that we are neglecting? Furthermore, could the existence of such solutions be a problem in the future, since we have incomplete answers for all the problems that involve differential equations?",['ordinary-differential-equations']
4173682,How to perform Gibbs sampling for this distribution?,"I tried to sample this equation by Gibbs sampling. $
P\{X=i,y \le Y \le y+dy,N=n\}\propto C^n_iy^{i+\alpha-1}(1-y)^{n-i+\beta-1}e^{-\lambda}\frac{\lambda^n}{n!}dy
$ I know I should generate X given $(y,n)$ , Y given $(x,n)$ and N given $(x,y)$ step by step.
But I don't know how to generate them because I don't know the $\lambda$ and what $dy$ does mean. Please help me!!","['statistics', 'computational-mathematics', 'sampling', 'algorithms', 'probability']"
4173696,Are the following statments on the support of a probability measure equivalent?,"Let $X\subset \mathbb{R}^d$ and $Y\subset \mathbb{R^k}$ be nonempty sets. Endow the product space $X\times Y$ with the product topology and let $\mathcal{B}_{X \times Y}$ be the corresponding Borel $\sigma$ -field. Let $\mu$ be a probability measure on $(X\times Y, \mathcal{B}_{X \times Y})$ and define the projection maps $$\pi_X:X\times Y \mapsto X: (x,y)\mapsto x,$$ $$\pi_Y:X\times Y \mapsto X: (x,y)\mapsto y.$$ Are the following statements equivalent? (A) The marginal probability measures $\mu_X$ on $X $ and $\mu_Y$ on $Y$ have compact supports. (B) The support of $\mu$ is a compact subset of $X \times Y$ . The fact that (A) implies (B) is proved in the answer to this question: Support of a probability measure vs support of its margins On the other hand, I would say that a simple reasoning by contradiction allows to prove that $\text{supp}(\mu_X) \subset \pi_X(\text{supp}(\mu))$ and $\text{supp}(\mu_Y) \subset \pi_Y(\text{supp}(\mu))$ . Thus, $\text{supp}(\mu_X)$ and $\text{supp}(\mu_Y)$ are closed (by definition of support) and bounded (as they're included in the coordinate projections of a compact set), therefore compact. Am I missing anything stupid?","['measure-theory', 'borel-measures', 'real-analysis']"
4173726,A question on a compound Poisson process: $P(|\xi(t)|\leqslant0.3)\underset{t\rightarrow\infty}{\rightarrow}0$?,"Let $\xi(t)$ be a compound Poisson point process such that the number of summands is a Poisson point process with parameter $\lambda$ and the summands are random variables: $P(\xi_k=\pm1)=0.5.$ Is it true that $P(|\xi(t)|\leqslant0.3)\underset{t\rightarrow\infty}{\rightarrow}0$ ? I know a central limit theorem: Theorem. Let $\{\mu_k\}_k$ be a sequence of independently equally distributed random variambles, $\mu_k>0$ , $N(t)=\max\{n|\sum\limits_{k=1}^n\leqslant t\}$ , $a=E\mu_1$ , $\sigma^2=D\mu_1$ ( $D$ denotes variance) then $P\Bigl(\cfrac{N(t)-\frac{t}{a}}{\sigma a^{-\frac{3}{2}}\sqrt{t}}<x\Bigl)\underset{t\rightarrow\infty}{\rightarrow}\Phi(x)$ where $\Phi(x)$ is the distribution function of $N(0,1).$ I suppose it must be the key but I am not good at probability theory at all. I don't really know how to apply this theorem (and, furthermore, if this is the right way). Can you please help me?","['poisson-distribution', 'probability-distributions', 'poisson-process', 'probability-theory', 'probability']"
4173745,Solving PDE with Laplace Transform method.,"can someone assist me in solving the following PDE with the Laplace Transform method: $ \qquad \qquad \qquad \qquad \qquad \quad u_t = u_{xx} - a^2 (u-T_0) \qquad 0 < x < 1, \qquad   t>0 $ Boundary conditions: $ \qquad u_x (0,t) = 0  \quad \text{and}
                     \quad u_x (1,t) = 0  \qquad \qquad t>0  $ Initial condition: $ \qquad \qquad  u(x,0) = 0  \qquad \qquad \qquad \quad 0 < x < 1 $ The answer given in the notes is: $ \qquad u(x,t) = T_0(1-e^{-a^2t}) $ I attempted to solve the problem as follows : The first thing I did was take the Laplace transform with respect to the variable t on both sides. (transformed variable os equal to s) Taking Laplace transform on both sides gives me the following: $ \qquad \qquad \qquad \qquad sU(x,s) - U(x,0) = U_{xx} - \frac 1s .[a^2.(u-T_0)] $ Substituting the initial condition and rearranging the equation I get: $ \qquad \qquad \qquad \qquad U_{xx} - sU(x,s) = \frac 1s .[a^2.(u-T_0)] $ From here I attempted to solve the equation using the d-operator method which gives me the following complementary function: $ \qquad \qquad \qquad \qquad  U(x,s) $ = $ A.\cosh(\sqrt {s} . x  ) $ $ + B.\sinh(\sqrt {s} . x  ) $ This is the part where I get stucked as I don't know how to obtain the particular integral of $ \frac 1s .[a^2.(u-T_0)] $ Can anyone please assist me in moving forward to solve this problem? Thanks a lot for your help!","['ordinary-differential-equations', 'laplace-transform', 'multivariable-calculus', 'calculus', 'partial-differential-equations']"
4173748,"A coin is tossed several times and the outcomes are being recorded in a string of H and T. How long - on average - will you have to wait for an ""TTH?"" [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. This question is not about mathematics, within the scope defined in the help center . Closed 3 years ago . Improve this question Problem. A coin is tossed several times and the outcomes are being recorded in a string of H (heads) and T (tails). For example, that is recorded as ""HHTTTHTH,"" so, how long - on average - will you have to wait for an ""TTH ?"" I need to a plan of solving by simulation via python. Here is the algorithm: First make a while loop for flipping coins. Then make booleans for each of the states $s_{0}, s_{1}, s_{2}, s_{3}:$ $s_{i}$ means that we have made $i$ progress on getting ""TTH."" For example, $s_{2}$ means that our last 2 flips were ""TT."" If $E_{i}$ is the expected number of flips until we get to $s_{3}$ given that we are on $s_{i},$ then we are looking for the value of $E_{0}.$ We have the following system using states $$E_{0}= 1+ \frac{1}{2}E_{1}+ \frac{1}{2}E_{0}$$ $$E_{1}= 1+ \frac{1}{2}E_{0}+\frac{1}{2}E_{2}$$ $$E_{2}= 1+ \frac{1}{2}E_{2}+ 0$$ This means $$E_{2}= 2$$ $$E_{0}- E_{1}= 2$$ $$2E_{1}- E_0= 4$$ $$E_{1}= 6$$ $$\boxed{E_{0}= 8}$$ Now just simulate the progress the flip makes toward the final state by changing the values of each of the booleans until it gets to the final state. Also you would have to repeat this process a sufficient number of trials and take the average number of flips of all trials. Edit . What is the probability of it takes 8 trials to wait for an ""TTH ?"" Hope can you help... thanks a real lot !","['python', 'simulation', 'expected-value', 'algorithms', 'probability']"
4173753,Use Stirling's approximation to evaluate the probability $\lim_{n\to \infty}\binom{2n}{n}\left(\frac{1}{4}\right)^n$,"As part of a some probability problem (probability of gettin $n$ heads and $n$ tails in $2n$ trials with a fair coin) I have derived the formula: $$p_n=\binom{2n}{n}\left(\frac{1}{4}\right)^n$$ I want to evaluate: $$\lim_{n\to \infty} p_n$$ for $n\in \mathbb N$ , using the following bound: $$e^{\frac{1}{12n+1}}<\frac{n!}{\sqrt{2\pi n}\left(\frac{n}{e}\right)^n}<e^{\frac{1}{12n}}$$ This is a ""special"" case of Stirling's approximation from Herbert Robbins that can be found here . I am stuck because I am not sure if my calculation is correct and the result makes no sense to me. When I calculate the limit I get zero . Does this not contradict the law of large numbers? Wouldn't I expect to get a distribution of $50 \%$ heads and $50\%$ tails if I toss a fair coin an infinite amount of times which then should imply $\lim_{n \to \infty} p_n=1$ ? What I have tried so far: $$\begin{equation*}\begin{split}\lim_{n\to \infty} p_n&=\lim_{n\to \infty} \binom{2n}{n} \left(\frac{1}{4}\right)^n \\[10pt] &=\lim_{n \to \infty} \frac{(2n)!}{(n!)^24^n} \end{split}\end{equation*}$$ Rewriting the approximation: $$ \begin{equation*}\begin{split} &\phantom{\iff} \, \, \, \,e^{\frac{1}{12n+1}}<\frac{n!}{\sqrt{2\pi n}\left(\frac{n}{e}\right)^n}<e^{\frac{1}{12n}} \\[10pt] & \iff e^{\frac{1}{12n+1}}  \sqrt{2\pi n}\left(\frac{n}{e}\right)^n < n!<e^{\frac{1}{12n}} \sqrt{2\pi n}\left(\frac{n}{e}\right)^n\end{split}\end{equation*}$$ Replacing $n!$ in $p_n$ $$\begin{equation*}\begin{split} &\phantom{iff}\frac{(2n)!}{\left(e^{\frac{1}{12n+1}}\sqrt{2\pi n}\left(\frac{n}{e}\right)^n\right)^2 4^n}<\frac{(2n)!}{(n!)^2 4^n}<\frac{(2n)!}{\left(e^{\frac{1}{12n}}\sqrt{2\pi n}\left(\frac{n}{e}\right)^n\right)^2 4^n} \\[10pt] &\iff\underbrace{\frac{1}{\left(e^{\frac{1}{12n+1}}\sqrt{2\pi n}\left(\frac{n}{e}\right)^n\right)^2 4^n}}_{:=g(n)}<\underbrace{\frac{1}{(n!)^2 4^n}}_{:=f(n)}<\underbrace{\frac{1}{\left(e^{\frac{1}{12n}}\sqrt{2\pi n}\left(\frac{n}{e}\right)^n\right)^2 4^n}}_{:=h(n)}\end{split}\end{equation*}$$ From the squeeze theorem : If $\lim_{n\to \infty} g(n)=\lim_{n \to \infty} h(n)=L$ and $g(n) < f(n) < h(n)$ then $\lim_{n \to \infty} f(n)=L$ $$\begin{equation*}\begin{split}\lim_{n \to \infty} g(n) &= \lim_{n \to \infty} \frac{1}{\left(e^{\frac{1}{12n+1}}\sqrt{2\pi n}\left(\frac{n}{e}\right)^n\right)^2 4^n} \\[10pt] &=\frac{1}{2 \pi}\lim_{n \to \infty} \frac{1}{e^{\frac{2}{12n+1}} e^{(-2n)} n^{(2n+1)}4^n} \\[10pt] &= \frac{1}{2\pi} \lim_{n \to \infty }\frac{e^{-\frac{24n}{12n+1}}}{n^{2n+1}4^n}=0\end{split}\end{equation*}$$ Analogous $\lim_{n \to \infty} h(n)=0 \implies \lim_{n \to \infty } f(n)=0$ . Therefore, $$\lim_{n \to \infty}p_n=0$$","['limits', 'probability']"
4173758,Using Monotonicity to find the value of a required variable,"Given $f(x) = \log_c\frac{x-2}{x+2}$ , is defined $\forall \; x \in [a,b]$ and the function is monotonically decreasing. We have to find the value (or range of values) of $c$ such that there exists $a$ and $b$ , where $(2 < a < b)$ , and the range of the function over $[a,b]$ is $[\log_cc(b-1), \log_cc(a-1)]$ . I have concluded the following: $c \in (0,1)$ Since the function is monotonically decreasing $$f(a) = \log_cc(a-1) \implies \frac{a-2}{a+2} = c(a-1)$$ and $$f(b) = \log_cc(b-1) \implies \frac{b-2}{b+2} = c(b-1)$$ I thought that subtracting the two equations or taking their ratio might help me find some helpful inequality, but unfortunately couldn't find anything. Your help is appreciated. Thanks UPDATE $1$ : We know that $c \in (0,1)$ and $\frac{x-2}{x+2} \in (0,1) \; \forall \; x \in (2, \infty)$ . Hence, the value attained by the function is positive. Thus, $$\log_cc(a-1) > 0 \implies c(a-1) < 1 \implies a < \frac{1}{c} + 1$$ and a similar inequality for $b$ .","['functions', 'derivatives', 'monotone-functions']"
4173768,Can this determinant ever vanish?,"Let $a_j=1 +2\cos\left(\frac{2\pi j}q\right)$ for $j=1,\dots,q$ . Then consider the Hermitian matrix: $$A_q = \begin{pmatrix} 
           a_1 &      1 &      0 &      0 & \ldots &       0 & 1 \\ 
             1 &    a_2 &      1 &      0 & \ldots &       0 & 0 \\ 
             0 &      1 &    a_3 &      1 & \ldots &       0 & 0 \\
             0 &      0 &      1 &    a_4 & \ldots &       0 & 0 \\ 
        \vdots & \vdots & \vdots & \vdots & \ddots &  \vdots & \vdots \\
             0 &      0 &      0 &      0 & \ldots & a_{q-1} & 1 \\ 
             1 &      0 &      0 &      0 & \ldots &       1 & a_q
        \end{pmatrix}$$ Using Mathematica, I find: $$\begin{align}
\det(A_2)&=-4\\
\det(A_3)&=-1\\
\det(A_4)&=-7\\
\det(A_5)&=-\frac52(-5+\sqrt5)
\end{align}$$ Is there any general formula that describes this determinant? And, more importantly, can the determinant ever be zero? The one answer I got so far, suggests no, but it is of course not a proof. This problem is motivated by a quantum mechanics problem, where the Hermitian matrix describes an observable in QM. In particular, it originates from the study of an electron on a lattice in a commensurable magnetic field.","['matrices', 'determinant', 'linear-algebra']"
4173807,Frechet derivative of $\delta_{x(t)}$ is $\delta_{x'(t)}$?,"I don't really know anything about the Fréchet derivative but I was wondering if the Fréchet derivative of $\delta_{x(t)}$ was $\delta_{x'(t)}$ . More precisely, if we consider the Banach space $(\mathcal{M}(\mathbb{R}^d), \|\cdot\|_{\text{TV}})$ of signed measures with total variation norm, $t\mapsto x(t)$ is a smooth curve in $\mathbb{R}^d$ , and $\delta_{x(t)}$ the Dirac measure in the point $x(t)$ and consider the map \begin{align}
\mathbb{R}\to&\mathcal{M}(\mathbb{R}^d)\\
t\mapsto& \delta_{x(t)}
\end{align} I was wondering if this is Frechet differentiable and if like intuition suggest we have that it's Frechet derivative at point $t$ is $\delta_{x'(t)}$ . I think that what I have to verify is (is it?) that $$\frac{\|\delta_{x(t+h)}-\delta_{x(t)}-h\delta_{x'(t)}\|_{\text{TV}}}{|h|}\to0\text{ when }h\to 0$$","['frechet-derivative', 'measure-theory']"
4173831,Notation of the partial derivative,What does in simple word this notation means: $$\left(\frac{\partial u}{\partial x} \right) dx $$ I understand it this way: the rate of change of $u$ with respect to $x$ . But what we achieve by multiplying partial derivative by $dx$ afterwards?,"['partial-derivative', 'derivatives']"
4173891,How to see $\lim_{x \to 0}\frac{1-\cos x}{x^2}=\frac12$ by looking at the graphs of $1-\cos x$ and $x^2$,"We know $$\lim_{x \to 0}\frac{\sin x}{x} = 1$$ because $\sin x$ behaves like $x$ locally. It can be seen from the following graph: We can see as $x$ approaches $0$ , $\sin x$ behaves more and more like $y = x$ which makes the limit $\lim_{x \to 0}\frac{\sin x}{x}$ equal to $1$ . Now, let's see another limit. This time, we have $$\lim_{x \to 0}\frac{1-\cos x}{x^2}$$ which is equal to $\frac12$ . Here is the graph of $(1 - \cos x)$ and $x^2$ : How is this limit approaching $\frac12$ ? How to see it approaching $\frac12$ by the graph as in the case of $\lim_{x \to 0}\frac{\sin x}{x}$ ?","['limits', 'graphing-functions']"
4173914,Typo in Spivak Calculus on Manifolds not found in various errata?,"Did I find an error on page 42 of my edition of Spivak's Calculus on Manifolds regarding computing the partial derivatives of the implicit function defined by the Implicit Function Theorem? I don't find this error listed in any errata online, but can't make sense of what is written. For convenience, Spivak states the Implicit Function Theorem as: Suppose $f: R^n \times R^m \to R^m$ is continuously differentiable in an open set containing $(a,b)$ and $f(a,b) = 0$ . Let $M$ be the $m \times m$ matrix $$ (D_{n+j}f^i(a,b)) \qquad 1\leq i,j \leq m.$$ If $\det{M} \neq 0$ , there is an open set $A \subset R^n$ containing $a$ and an open set $B \subset R^m$ containing $b$ , with the following property: for each $x \in A$ there is a unique $g(x) \in B$ such that $f(x,g(x)) = 0$ . The function $g$ is differentiable. Spivak's goes on to explain how to find the partial derivatives of $g$ by taking $D_j$ of both sides of $f(x,g(x)) = 0$ and he writes: $$0 = D_jf^i(x,g(x)) + \sum_{\alpha=1}^{m}D_{n+\alpha}f^i(x,g(x)) \cdot D_jg^\alpha(x) \\
i,j = 1, \ldots, m.$$ But shouldn't $j$ go from $1$ to $n$ , not from $1$ to $m$ ? If $g: R^n \to R^m$ , then each $g^\alpha$ has $n$ partial derivatives.","['manifolds', 'multivariable-calculus', 'solution-verification']"
4174002,Distribution of a centered gaussian conditional on its norm?,"Consider a multivariate, centered gaussian $X$ . Define $Y:= \|X\|$ . I am wondering how to describe the conditional distribution of $X\mid Y$ .
Intuitively, by $X$ being centered, one would expect that conditional on $Y=c$ , $X$ is uniformly distributed on the circle of radius $c$ .
That is, I suspect that we have $$\mathbb{E}[\mathbb{I}_A[X]\mid Y] = \int \mathbb{I}_A[Z(u) Y(\omega)] \, d\mathbb{P}(u)$$ where $Z$ is a random variable $Z: \Omega \to \mathbb{R}^n$ , independent of $X$ , having the property that $Z \sim \operatorname{Unif}(S^n)$ , where I don't know exactly how to define this uniformity on the circle correctly. (I guess we would want that $\phi(X) \sim \operatorname{Unif}([0,2\pi))$ for any $\phi: \mathbb{R}^n \to \mathbb{R}$ s.t. $\phi(S^n) = [0,2\pi)$ . ) Am I correct in my intuition? If so, how to correctly define $Z$ above? And is there some easy proof?","['conditional-probability', 'probability-distributions', 'gaussian', 'probability-theory']"
4174006,Why is there this connection between Euler's number and $1/x$?,I've seen plenty of easy to understand proofs showing that $\frac{dy}{dx}\ln(x)=\frac{1}{x}$ but what I'm looking for is a way to intuitively justify why $n=-1$ is an exception to the power rule for integration (besides the fact that it results in a $\frac{1}{0}$ ).  Why is there this connection between $e$ and $1/x$ ?,"['integration', 'calculus', 'derivatives', 'eulers-number-e']"
4174015,Numerical Computation of Chapman-Kolmogorov Condition for a Dataset,"Good day every one, I am trying to solve a particular problem relating to probabilities: I have a time series dataset, where the price at time $t_i$ can be given as $x(t_i)$ We can then define a returns time series where $r_i = \ln[x(t_{i+1})/x(t_i)]$ I now want to find some timescale $t_M$ for which the returns could be viewed as a Markov process. For this, we require the Chapman-Kolmogorov (CM) equation $$p(r_2, t_2|r_1, t_1) = \int dr' p(r_2, t_2|r', t')p(r', t'|r_1, t_1) $$ to hold where p represents the usual conditional probability which can be given as $$p(r_i, t_i|r_j, t_j) = \frac{p(r_i, t_i;r_j, t_j) }{p(r_j, t_j) } $$ We can  reformulate the CM equation as  the value $$S= |(p(r_2, t_2|r_1, t_1)- \int dr' p(r_2, t_2|r', t')p(r', t'|r_1, t_1) |$$ For some given $r_1$ and $r_2$ in terms of $t'-t_1$ for example. We then expect $t_M = t'-t_1$ for a value of $t'-t_1$ where S vanishes or reaches its minimum. From what I have read, this value S, the CM conditions and subsequently the conditional probabilities can be computed numerically. So much so, that all the papers I have read make it seem like it a trivial matter. But I cannot find a way to do it. Does anyone know how to compute such values numerically from a given dataset? Thank you for your help
.","['statistics', 'markov-chains', 'time-series', 'numerical-methods', 'probability']"
4174028,Density of compactly supported smooth functions in Lp,"This is an exercise in my Functional Analysis book; I tried to check my solution by referring to this site and elsewhere but nowhere have I found a similar argument to mine (which makes me skeptical about my solution; note that I have no access to an instructor and there's no available solutions to this book); the solutions that I have found seem to me more complicated than my following argument (these are just bullet points, not rigorous proof): First off if $K$ is a compact set (assume WLOG that $K$ is a ball of radius $r$ ), then note that given any $L^p$ function $f$ on $K$ we can arbitrarily approximate it (in the $L^p$ norm) with a continuous function $g$ . Next note that polynomials are uniformly dense in the set of continuous functions, hence there exists a polynomial $p$ which uniformly approximates $g$ on $K$ and hence it can arbitrarily approximate it in the norm (where the integral is taken over $K$ of course). Now if $f$ is in $L^p(R^n)$ then there exists a set of finite measure $K$ (which WLOG we assume is a ball of radius $r$ ) such that the integral of $f$ over $K$ is arbitrarily close to its integral over $R^n$ . Let us take the continuous function $g$ as above which vanishes outside of $K$ and let $\psi$ be a bump function which is $1$ on a ball of radius $r-\epsilon$ and is supported in $K$ , then clearly $p\psi$ can also arbitrarily approximate $g$ in the norm (just like $p$ can). Then by the triangle inequality we obtain the approximation of $f$ by $p\psi$ in the norm. Is there anything that I'm missing?","['banach-spaces', 'measure-theory', 'approximation-theory', 'lp-spaces', 'functional-analysis']"
4174073,Prove a limit with $\varepsilon$-$\delta$ definition:,"the limit we want to prove is: $$\lim_{(x,y)\to(0,0)}\frac{x^4}{x^2+y^2}=0$$ It is actually very simple: the denominator is the square of the norm of $(x,y)$ , thus it follows that, for every $\varepsilon>0$ we must find $\delta>0$ for which it holds: $$\frac{x^4}{\delta^{2}}<\varepsilon$$ but I do not see how to get rid of that $x^4$ in order to define a proper $\delta$ . I imagine one has to use some particular inequality based on squares I must have forgot.","['limits', 'multivariable-calculus', 'epsilon-delta']"
4174123,What is the difference between Commutative Algebra and Algebraic Geometry?,What is the difference between Commutative Algebra and Algebraic Geometry ? Many of the theorems in Commutative Algebra and Algebraic Geometry have a geometric interpretation. Why both  are not same ? Note: I'm new on these two topics,"['self-learning', 'algebraic-geometry', 'soft-question', 'commutative-algebra']"
4174143,Function on all sets,"Suppose we want to define function $c$ , such that it takes some set $A$ and returns it's cardinality, that is $c(A) = |A|$ . One would be tempted to denote it, for instance, as $c: \Omega \to C_d$ , where $\Omega$ is set of all sets and $C_d$ is set of cardinal numbers. But such $\Omega$ does not exist. Can therefore no function operate on any set? Another example of such function could be a function, which takes a set and returns it's intersection with $\mathbb{R}$ - $f: \Omega \to 2^\mathbb{R}$ . Could anyone elaborate on this? Thanks","['elementary-set-theory', 'functions']"
4174160,"What is the definition of moduli space, in math vs in physics?","It is easy to find that there are many questions regarding moduli space on MSE: https://math.stackexchange.com/search?q=what+is+moduli+space But it seems to me that this phrase, moduli space, may mean many different things. For example, according to Wikipedia , the moduli space is used in physics to refer specifically to the moduli space of vacuum expectation values of a set of scalar fields, or to the moduli space of possible string backgrounds. Moduli spaces also appear in physics in topological field theory, where one can use Feynman path integrals to compute the intersection numbers of various algebraic moduli spaces. Moduli space occurs in the context of in  algebraic geometry, as a geometric space (usually a scheme or an algebraic stack) whose points represent algebro-geometric objects of some fixed kind, or isomorphism classes of such objects. intersection theory of Riemann surface. moduli space of Calabi-Yau manifolds. Weil-Petersson metric of the moduli space of elliptic curves. So what is the definition of moduli space, in math vs in physics, after all these?","['moduli-space', 'riemannian-geometry', 'algebraic-geometry', 'mathematical-physics', 'differential-geometry']"
4174164,coordinate transformation of the Laplace Beltrami Operator,"My Laplace-Beltrami operator isn't transforming correctly under a change of coordinates. What am I doing wrong? The Laplace-Betrami operator has the following expressing in local coordinates of a Riemannian manifold $(M, g)$ , \begin{align}
\Delta f(x) = g^{ij}(x) \frac{\partial^2 f(x)}{\partial x_i \partial x_j} + g^{jk}\Gamma^i_{jk} \frac{\partial f(x)}{\partial x_i},
\end{align} where $\Gamma^i_{jk}$ are Christoffel symbols. Written in this way, it is clear that the Laplace-Beltrami operator is a second-order elliptic operator on the manifold. Many books such as Markov Processes by Dynkin (page 151) or Functional Analysis by Yosida (page 426) state that the coefficient functions of elliptic operators must transform in a prescribed way in order to give a consistent result on the manifold. Namely, consider an elliptic operator of the form (written in local coordinates $x$ ) \begin{align}
Af(x) = b^i(x) \frac{\partial f(x)}{\partial x_i} + a^{ij}(x) \frac{\partial^2 f(x)}{\partial x_i\partial x_j}.
\end{align} Then in another coordinate system $\tilde{x}$ the coefficient functions transform as \begin{align}
\tilde{b}^i(x) &= b^k(x) \frac{\partial \tilde{x}_i}{\partial x_k} + a^{kl}(x)\frac{\partial^2 \tilde{x}_i}{\partial x_k\partial x_l} \\\\
\tilde{a}^{ij}(x) &= a^{kl}(x) \frac{\partial \tilde{x}_i}{\partial x_k}\frac{\partial \tilde{x}_j}{\partial x_l}.
\end{align} The Laplace-Beltrami operator should then obey this transformation rule with $a^{ij} =g^{ij}$ and $b^i = g^{jk}\Gamma^i_{jk}$ . The fact that $g^{ij}$ obeys the correct transformation rule is apparent; however, I am having a hard time seeing that $g^{jk}\Gamma^i_{jk}$ obeys the correct transformation. What I want to show is that \begin{align}
\tilde{g}^{jk}\tilde{\Gamma}^i_{jk} = g^{pq}\Gamma^k_{pq} \frac{\partial \tilde{x}_i}{\partial x_k} + g^{pq}\frac{\partial^2 \tilde{x}_p}{\partial x_k\partial x_q}
\end{align} I know that the transformation rule for the Christoffel symbols is as follows: \begin{align}
    \tilde{\Gamma}^i_{jk} &= \frac{\partial x_p}{\partial\tilde{x_j}}\frac{\partial x_q}{\partial\tilde{x}_k} \Gamma_{pq}^r \frac{\tilde{x}_i}{\partial x_r} + \frac{\partial^2 x_r}{\partial \tilde{x}_j\partial \tilde{x}_k} \frac{\partial \tilde{x}_i}{\partial x_r} \\
    &= \frac{\partial x_p}{\partial\tilde{x_j}}\frac{\partial x_q}{\partial\tilde{x}_k} \Gamma_{pq}^r \frac{\tilde{x}_i}{\partial x_r} - \frac{\partial x_p}{\partial \tilde{x}_j} \frac{\partial^2 \tilde{x}_i}{\partial x_p\partial x_q} \frac{\partial x_q}{\partial \tilde{x}_k}
\end{align} If I multiply both sides by $\tilde{g}^{jk}$ and use the transformation law of the inverse metric in coordinates, I obtain, \begin{align}
    \tilde{g}^{jk} \tilde{\Gamma}^i_{jk} &=  \tilde{g}^{jk} \frac{\partial x_p}{\partial\tilde{x_j}}\frac{\partial x_q}{\partial\tilde{x}_k} \Gamma_{pq}^r \frac{\tilde{x}_i}{\partial x_r} - \tilde{g}^{jk}\frac{\partial x_p}{\partial \tilde{x}_j} \frac{\partial^2 \tilde{x}_i}{\partial x_p\partial x_q} \frac{\partial x_q}{\partial \tilde{x}_k} \\
    &= g^{pq} \Gamma_{pq}^r \frac{\tilde{x}_i}{\partial x_r} - g^{pq} \frac{\partial^2 \tilde{x}_i}{\partial x_p\partial x_q}.
\end{align} This is very nearly what I wanted to show, but differs from the expected result by a negative sign in the second term. What have I done wrong?","['elliptic-equations', 'analytic-geometry', 'riemannian-geometry', 'differential-geometry']"
4174225,Prove all $2\times2$ real matrices with eigenvalues $1$ and $-1$ can be represented as,"My exercise asks: Prove that all $2\times2$ real matrices with eigenvalues $\lambda_1=1$ and $\lambda_2=-1$ can be represented as \begin{equation}
\begin{bmatrix}
\cos\theta & a\sin\theta \\
\frac{1}{a}\sin\theta & -\cos\theta
\end{bmatrix}
\end{equation} Starting like \begin{equation}
\begin{bmatrix}
a & b \\
c & d
\end{bmatrix}
\end{equation} Using the fact that $\operatorname{Tr}(A) = a+d =\lambda_1+\lambda_2 = 0 \Rightarrow a=-d$ . And using the fact that $\det A = ad-bc=\lambda_1\lambda_2=-1 \Rightarrow-a^2-bc=-1$ \begin{equation}
a^2+bc=1
\end{equation} How can I complete the proof?","['matrices', 'linear-algebra', 'characteristic-polynomial']"
4174258,Compare volume of cylinder and sphere with same surface area.,"Given that, Volume of a  cylinder with surface area a = $V_1$ Volume of a  sphere  with surface area a = $V_2$ Compare $V_1$ and $V_2$ . The correct answer for this question is $V_2 > V_1$ . I'm not able to prove this. Can someone please help me here? My approach : Assume  that, $r_1$ = radius  of  cylinder $r_2$ = radius  of  sphere  and $h$ = height of  cylinder $$a =  4\pi r_2^2 = 2\pi r_1(r_1 + h)$$ $$\implies 2r_2^2 = r_1(r_1+h) ...........(1)$$ Now based on equation (1), we need to compare $$\frac{4}{3}\pi r_2^3 \ and \ \pi r_1^2h$$ I'm stuck at this point. I'm not sure how to deal with term $r_1(r_1 + h)$ . Some help would be appreciated.","['spheres', 'area', 'surfaces', 'volume', 'geometry']"
4174275,Independence of the spacing of order statistics characterizes exponential distribution?,"The question is:
Let $Y_1 < Y_2$ be the order statistics of a random sample of size $2$ from a distribution of the continuous type which has p.d.f $f(x)>0$ provided $x \geq 0$ , and $0$ elsewhere. Show that the independence of $Z_1 = Y_1$ and $Z_2=Y_2-Y_1$ characterizes the exponential distribution. This is as far as I went:
The joint distribution of the order statistics : $$f(y_1,y_2)=2f(y_1)f(y_2), 0 < y_1 < y_2$$ . The Jacobian of change of variable is $1$ , thus $$g(z_1,z_2)=f(z_1,z_1+z_2)=2f(z_1)f(z_1+z_2)$$ . $Z_1$ and $Z_2$ are independent if and only if $$g(z_1,z_2)=g(z_1)g(z_2)$$ Not sure how to continue, can anyone please help? Edit: I found a similar question: Independence of spacing of order statistics of exponential distribution My question is just the reverse of the problem.","['statistics', 'exponential-distribution', 'order-statistics', 'gamma-distribution', 'probability']"
4174317,Show that $x^x$ is differentiable,"Define $f\colon\mathbb R_{+} \to \mathbb R, x\mapsto x^x$ . Show that $x^x$ is differentiable. $x^x = e^{x\ln(x)}$ $\lim_{h \rightarrow 0} \frac{e^{(x+h)\ln(x+h)} - e^{x\ln(x)}}{h} = \dots$ I calculated the derivative, which should be $e^{x\ln(x)}(\ln(x)+1) = x^x\cdot(\ln(x)+1)$ . But how do I get here using the differential equation? Edit: The full question was: Show that $x^x$ is differentiable and calculate its derivative. I already calculated its derivative so I didn't mention it in the question. It's not required to use the limit. I tried using it since it was the definition of the derivative in the text book.Any other suggestions would be helpful.","['derivatives', 'ordinary-differential-equations', 'real-analysis']"
4174373,"Confusion : In a class there are 30 students. Is it possible that, 9 of them have 3 friends (in the class), 11 - have 4, and 10 - have 5 friends?","Question : In a class there are 30 students. Is it possible that, 9 of them have 3 friends (in the class), 11 - have 4, and 10 - have 5 friends? Solution : Let there be 30 vertices in the graph, 9 of which have degree 3, 11 - have degree 4, 10 - have degree 5. Meanwhile, in the graph, there are 19 odd vertices, which is against the ""Handshake-Theorem"", so it's not possible. I didn't understand where is the statement ""Meanwhile, in the graph, there are 19 odd vertices"" from and by what do we get that information? I'm confused, please help me.","['graph-theory', 'discrete-mathematics']"
4174379,Interpolation of $\Pi_\Sigma(N)$,"I am asking this question out of curiosity, there is not really a particular reason behind this question. $\Pi_\Sigma$ :- I created this function which I call the Factor-Sum function. I don't know if this function is a popular function used by mathematicians or not, so I am just calling it my own. So I defined, $\Pi_\Sigma(N)=
\begin{cases}\sum_{i=1}^{n}{a_i}{p_i}, & \text{if}N=\prod_{i=1}^{n}{p_i}^{a_i} \\N, & \text{if} N=0,1 \\-\Pi_\Sigma(|N|), & \text{if} N<0 \end{cases}$ So this is an odd function which gives the input back when given a prime or $0$ or $1$ and gives the sum of the prime factors when given a composite. For example:- ● $\Pi_\Sigma(13)=13$ ● $\Pi_\Sigma(18)=2+3+3=8$ ● $\Pi_\Sigma(-18)=-8$ Interpolation of $\Pi_\Sigma$ :- So $\operatorname{Dom}(\Pi_\Sigma)=\mathbb{Z}$ I want to extend the domain of $\Pi_\Sigma$ to $\mathbb{R}$ . I have estimated few non-integer values of the function using newton forward formula- $f(a+hu)=f(a)+\sum_{n=1}^{\infty}\frac{u!}{n!(u-n)!}\Delta^nf(a)$ But it doesn't give an accurate or an estimated general formula for $\Pi_\Sigma$ for any real $N$ . I don't want interpolations like Peicewise constant interpolation or Linear interpolation which gives sharp edges in the graph of the function. I want an interpolation of $\Pi_\Sigma$ such that it becomes differentiable everywhere.(Such as polynomial interpolation, spline interpolation) Any help would be appreciated. (I don't really know much about interpolation that's why I need help.)","['recreational-mathematics', 'functions', 'interpolation']"
4174386,Solve for withdrawal rate in Monte Carlo simulation of retirement,"I've been working with compound returns and distribution of wealth over time for quite some time now and I feel like I am hitting a wall. What am I trying to achieve? Imagine that you are about to retire and have saved $100 000. You are planning to withdraw your money monthly over the next 20 years. If we assume that returns are normally distributed with: $${\mu} = 7 \%$$ $${\sigma} = 15 \%$$ I can simulate $1000$ returns from the above distribution in month $1$ . Subtract $X$ from my initial pot, realise a return and calculate the new value of the pot at the end of that month. This gives me $1000$ values at the end of period 1 and I can take the median of all these. Next month the process is repeated. I simulate 1000 returns for month 2 now, subtract the same amount $X$ from the opening balance (end of period 1 values) and multiply by the returns. This gives me yet another 1000 values at the end of period 2 and I can take the median of those. I keep doing this for all the subsequent months and this gives me the path of all median values over $20$ years with withdrawals. There has to exist a way to calculate the amount X (which is constant in each period) that allows me to exhaust my retirement pot (terminal value of 0) at the end of the withdrawal period. From Farago, Adam and Hjalmarsson, Erik, Compound Returns we know that compound returns have the following properties: $${\psi} = \log\left(\frac{\mu^2}{\sqrt{\sigma^2+\mu^2}}\right)%$$ and $${\eta} = \sqrt{\log\left(\frac{\sigma^2}{\mu^2}+1\right)} %$$ and we can find the $\alpha$ -quantile of compound returns with: $$q_\alpha\left(X_T\right) = e^{T\psi+\sqrt{T}\eta\Phi^{-1}\left(\alpha\right)}$$ i.e. I can use this formula to get the 25th percentile of compound returns from the above distribution in period T = 10 Unfortunately, this formula does not hold when you introduce either monthly savings or monthly withdrawals to the picture, as the distribution of compound wealth is then changed. I'd appreciate if anyone can give me any pointers on solving for withdrawal amount X as per the above.","['statistics', 'monte-carlo', 'simulation', 'normal-distribution']"
4174393,Second derivative of mollification at local maximum,"Let $u:[-1,1] \mapsto \mathbf{R}$ be a continuous function with a local maximum at 0. That is, there is a ball $B_\delta(0)$ with $u(x) \leq u(0)$ for all $x \in B_\delta(0)$ . Let $\eta(x)$ be the standard mollifier defined by $$ \eta(x) = \begin{cases} C \exp\left(\frac{1}{|x|^2-1}\right) &\text{if } |x|< 1\\ 0 &\text{if } |x| \geq 1,\end{cases} $$ where $C$ is chosen so that $\int_{\mathbf{R}^n} \eta = 1$ . For $x \in (-1+\epsilon, 1 - \epsilon)$ define the mollified function $u_\epsilon$ by $$ u_\epsilon(x) = \int_{B(0,\epsilon)} \epsilon^{-n}\eta\left(\frac{y}{\epsilon}\right)u(x-y) \ dy. $$ Is it true that $$ \liminf_{\epsilon \rightarrow 0} u_\epsilon ''(0) \leq 0. $$ This would be true if the mollified function also had a local maximum at 0 — however this is not necessarily the case. As some further intuition it should be true that the mollification has a local max near 0, and this local max approaches the origin as $\epsilon \rightarrow 0$ . However without something resembling uniform convergence I've been unable to turn this into a solution. Note also the lim inf can not be replaced by a limit as we can construct a function for  for which $ \lim_{\epsilon \rightarrow 0} u_\epsilon ''(0)$ does not exist. The idea behind the construction is to take any positive function for which the limit of the mollifications don't exist at 0 then integrate twice. More precisely take $h \in L^\infty[0,1]$ with $h \geq 0$ for which $\lim_{\epsilon \rightarrow 0} h_{\epsilon}(0)$ does not exist. Set $g(x) = \int_0^x h(x)$ and $u(x) = \int_0^x g(x)$ . Note $u(0)=0$ and $u \leq 0$ . Then $h$ bounded implies $u,g$ are Lipschitz, and differentiable a.e with $u′=g$ and $g′=h$ . Since the derivative of the mollification is the mollification of the derivative we have $(f_\epsilon)'' = u_\epsilon$ which we recall was chosen to not have a limit at 0.","['calculus', 'partial-differential-equations', 'real-analysis']"
4174442,Definition of directional derivative: Why does it work?,"The definition of the directional derivative in my textbook is $$
\nabla_{\vec{v}} f = \lim\limits_{h\to 0}\frac{f(\vec{x} + h \vec{v} )-f(\vec{x})}{h}
$$ with $\vec{x} = (x_1, x_2)$ and $\vec{v} = (v_1, v_2)$ (I first want to consider the two variable case). However, before looking at this definition I tried to come up with it on my own: Say I'm given a function $f(x_1, x_2)$ and wanted to evaluate the directional derivative for a vector $\vec{v}$ for $x_1 = 0$ and $x_2 = 0$ . Similar to the one-variable case I would consider the slope of the secant $\Delta f$ $$
\Delta f = \frac{f(x_1 + v_1, x_2 + v_2) -f(x_1, x_2)}{\Vert \vec{v}\Vert}
$$ so when introducing some real number $h > 0$ which will allow us to make the change in $(x_1, x_2)$ arbitrary small we can  consider the limit $$
\nabla_{\vec{v}} f = \lim\limits_{h\to 0}\frac{f(\vec{x} + h \vec{v} )-f(\vec{x})}{h\Vert\vec{v}\Vert}
$$ whereby $\Vert\cdot\Vert$ denotes the standard $\mathbb{R}^2$ norm. Is the latter definition also correct? I doubt it, because if $$
\nabla_{\vec{v}} f = \lim\limits_{h\to 0}\frac{f(\vec{x} + h \vec{v} )-f(\vec{x})}{h} = L \neq  0 
$$ then $$
\nabla_{\vec{v}} f = \lim\limits_{h\to 0}\frac{f(\vec{x} + h \vec{v} )-f(\vec{x})}{h\Vert\vec{v}\Vert} = \frac{1}{\Vert \vec{v}\Vert} \lim\limits_{h\to 0}\frac{f(\vec{x} + h \vec{v} )-f(\vec{x})}{h} = \frac{1}{\Vert \vec{v}\Vert} L \neq L.
$$ I hope someone can clarify this for me. Edit: I know that the first definition is more general because  it doesn't require the existence of a  norm but I still don't see why it is correct. Also, in my attempt I don't assume that $\Vert\vec{v}\Vert = 1$ because I just think of it as the length of the vector. Why is this incorrect?","['multivariable-calculus', 'derivatives', 'multivalued-functions']"
4174481,"If $f,f_m$ are Lipschitz with $\lim_{m\to+\infty} d(f_m(x),f(x)) = 0 $, is it true that the fixed point of $f_m$ converges to the fixed point of $f$?","I'm going through a proof in which at one point, the authors make the following statement : Let $(X,d)$ be a complete metric space and $f:X\to X$ and $f_m:X\to X$ Lipschitz with $lip(f)<1$ and $lip(f_m)<1\; \forall m\in\mathbb{N}$ . Let $x^*_m$ the fixed point of $f_m$ and $x^*$ the fixed point of $f$ .
If for each $x\in X$ we have that $$\lim_{m\to+\infty} d(f_m(x),f(x)) = 0, $$ it follows that $$\lim_{m\to+\infty} d(x^*_m,x^*) = 0 .$$ I tried to figure out how they came up with this by an argument along the lines of \begin{align*}d(x^*_m,x^*) &= d(f_m(x^*_m),f(x^*)) \leq d(f_m(x^*_m),f(x_m^*))+ d(f(x_m^*),f(x^*))\\&\leq d(f_m(x^*_m),f(x_m^*))+lip(f)d(x_m^*,x^*).
\end{align*} Then $$0\leq (1-lip(f))d(f(x_m^*),f(x^*))\leq d(f_m(x^*_m),f(x_m^*)).$$ But now we can't apply the first limit because $x_m^*$ depends on $m$ . Also another thing I tried is by using the fact that $$\lim_{n
\to+\infty}d(f^{\circ n}(x),x^*)=0 \; \forall x\in X$$ Where $f^{\circ n} = \underbrace{f\circ f\circ \dots \circ f}_{\text {n times}}.$ Then for a fixed $x\in X$ \begin{equation*}d(x^*_m,x^*)\leq d(x^*_m,f^{\circ n}_m(x)) + d(f^{\circ n}_m(x),f^{\circ n}(x))+ d(f^{\circ n}(x),x^*),\; \forall n\in\mathbb{N}
\end{equation*} Now let $\varepsilon > 0$ and set $N$ big enough so that $d(f^{\circ N}(x),x^*)<\varepsilon/3$ and $d(f_m^{\circ N}(x),x_m^*)< \varepsilon/3$ . Then \begin{align*}
d(x^*_m,x^*) &\leq d(x^*_m,f^{\circ N}_m(x)) + d(f^{\circ N}_m(x),f^{\circ N}(x))+ d(f^{\circ N}(x),x^*)\\&<2\varepsilon/3 + d(f^{\circ N}_m(x),f^{\circ N}(x)).
\end{align*} Now it can be shown that $\lim\limits_{m\to+\infty} d(f^{\circ N}_m(x),f^{\circ N}(x)) =0$ , so there is some $M$ such that $d(f^{\circ N}_m(x),f^{\circ N}(x)) <\varepsilon/3\; \forall m>M$ , from which we get $$d(x^*_m,x^*)<\varepsilon.$$ But I feel like something is not right in my second attempt. Is something missing from the statement?","['fixed-points', 'metric-spaces', 'lipschitz-functions', 'real-analysis']"
4174548,Locally Euclidean topology - but not Hausdorff,"We consider the set $X=\mathbb{R}\cup \{\star\}$ , i.e. $X$ consists of $\mathbb{R}$ and an additional point $\star$ . We say that $U\subset X$ is open if: (a) For each point $x\in U\cap \mathbb{R}$ there exists an $\epsilon>0$ such that $(x-\epsilon, x+\epsilon)\subset U$ . (b) If $\star \in U$ then there is an $\epsilon>0$ such that $(-\epsilon , 0)\cup (0, \epsilon)\subset U$ . $$$$ Show that this defines a topology in $X$ . Show that $X$ with this topology is locally Euclidean but not Hausdorff. $$$$ For (1) we have to show that $X$ and $\emptyset$ are open, the union of two open sets is open and the intersection of two open sets is open. First we show that $X$ is open : (a) For each point $x\in X\cap \mathbb{R}=\mathbb{R}$ there exists an $\epsilon>0$ such that $(x-\epsilon, x+\epsilon)\subset X=\mathbb{R}\cup \{\star\}$ . This is true since every neighboorhood of $x$ is contained. (b) If $\star \in X$ then there is an $\epsilon>0$ such that $(-\epsilon , 0)\cup (0, \epsilon)\subset X=\mathbb{R}\cup \{\star\}$ . Thisis true since the union of the intervals is a subspace of the real line. Is that correct? The emptyset is per definition open, or not? We don’t have to apply the given definition, do we? Let $M_1$ and $M_2$ be two open sets. We consider the union $M_1\cup M_2$ . For each point $x\in M_1\cup M_2$ it is either $x\in M_1$ or $x\in M_2$ (or both) so statement (a) follows from the fact that $M_1$ and/or $M_2$ are open. The same holds also for statement (b). Let $M_1$ and $M_2$ be two open sets. We consider the intersection $M_1\cap M_2$ . For each point $x\in M_1\cap M_2$ it is $x\in M_1$ and $x\in M_2$ so statement (a) follows from the fact that $M_1$ and $M_2$ are open. The same holds also for statement (b). Therefore we get that the above defines a topology in $X$ . Is that correct and complete? Could you give a hint for (2) ?","['general-topology', 'analysis']"
4174549,Find the value of $\cos105^\circ+\sin75^\circ$,Find the value of $$\cos105^\circ+\sin75^\circ.$$ We can write the given trig expression as $$\cos(180^\circ-75^\circ)+\sin75^\circ=-\cos75^\circ+\sin75^\circ\\=\sin75^\circ-\cos75^\circ$$ I don't see what else I can do. Thank you!,"['algebra-precalculus', 'trigonometry']"
4174567,Reference to an explicit formula for the Hadamard product of two rational generating functions,"It is a theorem that if two sequences $\{f_n\}_{n=0}^\infty$ and $\{g_n\}_{n=0}^\infty$ have generating functions $f(x) = \sum_{n=0}^\infty f_n x^n$ and $g(x) = \sum_{n=0}^\infty g_n x^n$ that can be expressed as rational functions $f(x) = p_1(x)/q_1(x)$ and $g(x)=p_2(x)/q_2(x)$ , then the Hadamard product of these two sequences, i.e. the sequence $\{h_n\}_{n=0}^\infty$ with $h_n = f_n g_n$ for all $n \geq 0$ , has a generating function $h(x) = \sum_{n=0}^\infty h_n x^n$ that also can be expressed as a rational function $h(x) = p(x)/q(x)$ .  An existing thread here, ""Algorithm for computing Hadamard product of two rational generating functions"" outlines a explicit procedure to explicitly calculate the coefficients of the polynomials $p(x)$ and $q(x)$ from the coefficients of the polynomials $p_1(x)$ , $q_1(x)$ , $p_2(x)$ , and $q_2(x)$ . Does anyone know a citation to a paper or a textbook in which the procedure given in that thread (or any procedure like it) is given completely explicitly and also completely proven, as opposed to being just outlined?  I have not had any luck in finding such a citation, but I feel that there must be one out there.","['generating-functions', 'combinatorics', 'sequences-and-series']"
4174587,A Proof of a Theorem by Burgess,"Consider the following result by Burgess: Theorem: Let $E$ be an analytic equivalence relation on a Polish space $X$ . Then either $|X/E|\leq\aleph_1$ or there is a perfect set of pairwise $E$ inequivalent elements in $X$ . I want to prove it using the following result by Silver: Theorem: If $E$ is a coanalytic equivalence relation on a Polish space $X$ , then either $|X/E|\leq\aleph_0$ or there is a perfect set of pairwise $E$ inequivalent elements. I can show that every analytic equivalence relation $E$ on a Polish space $X$ is of the form $$ E=\bigcap_{\alpha<\omega_1}B_{\alpha}, $$ where $B_{\alpha}$ is a Borel equivalence relation on $X$ . My attempt is to show that if there are $\aleph_2$ many $E$ equivalence classes, then $B_{\alpha}$ must have uncountably many equivalence classes, for some $\alpha<\omega_1$ , and then use Silver's result. Is it possible construct a binary tree of equivalence classes in the following way: Let $(\alpha_n:n<\omega)$ be a strictly increasing sequence in $\omega_1$ and set $\gamma:=sup\{\alpha_n:n<\omega\}$ . For every $s\in2^{<\omega}$ with $k:=|s|$ , choose a $B_{\alpha_k}$ equivalence class $E_s$ such that $E_t\subseteq E_s$ , for $s\subseteq t$ , and if neither $s\subseteq t$ nor $t\subseteq s$ , then $E_s\cap E_t=\emptyset$ . The difficulty then is to show that for every $f\in2^{\omega}$ , $\bigcap_{n<\omega}E_{f\upharpoonright n}\neq\emptyset$ , which would yield uncountably many $B_{\gamma}$ classes. Any help, including other approaches, is appreciated.","['equivalence-relations', 'general-topology', 'logic', 'descriptive-set-theory']"
4174610,Textbook recommendations for the differential geometry of Yang-Mills fields,I was wondering if anyone could recommend text books or papers that could help me really understand the math behind Yang-Mills fields? Thanks!,"['gauge-theory', 'differential-geometry']"
4174646,"Smaller representations for the group satisfying $\{\sigma_i,\sigma_j \}=2$ and $\sigma_i^2=1$","In recent days after learning about the derivation of Dirac equation , I was wondering how the Dirac matrices would look like if one changes the commutation relation from anti-commute to 0 to anti-commute to 2 which is the regular coefficient in squared monomials. In other words, what would have being the solutions to the problem $$\{\sigma_i,\sigma_j\}=\sigma_i\sigma_j+\sigma_j\sigma_i=2$$ $$\sigma_i^2=1 \tag{2}$$ In this question the accepted answer shows that ""this algebra is generated as a vector space by the 8 elements $1, \sigma_1, \sigma_2, \sigma_3, \sigma_1\sigma_2, \sigma_1\sigma_3, \sigma_2\sigma_3, \sigma_1\sigma_2\sigma_3$ "". Element $\sigma_1$ being $$\sigma_1 = \begin{pmatrix}
0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\
1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\
0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\
\end{pmatrix}$$ And ""Concretely, what $\sigma_1$ does on the basis is $e_1\mapsto e_2, e_2\mapsto e_1, e_3\mapsto e_5, e_4\mapsto e_6, e_5\mapsto e_3, e_6\mapsto e_4, e_7\mapsto e_8, e_8\mapsto e_7$ "" However, these are $8 \times 8$ matrices and I'm now looking for the smallest possible representation of these matrices, for a better comparison with Pauli’s ( $3$ , $2 \times 2$ ) or Dirac’s ( $4$ , $4 \times 4$ ) matrices. I’d like to inform that this is not a question about physics. I’m looking for the pure mathematical solution to the minimal representation of the solutions to the posed problem only. Any help will be appreciated. PS: Quotes are text originally posted in the cited answer.","['group-theory', 'abstract-algebra', 'representation-theory']"
4174672,"Let $A$, $B$ and $C$ be sets such that $A\subseteq C$, $B\subseteq C$ and $(C\setminus A)$ $\subseteq$ $B$. Then $A$ $\cup$ $B$ $=$ $C$.","My attempt Claim: Let $A$ , $B$ and $C$ be sets such that $A$ $\subseteq$ $C$ , $B$ $\subseteq$ $C$ and $(C\setminus$$A$ ) $\subseteq$ $B$ . Then $A$ $\cup$ $B$ $=$ $C$ . Proof. ( $\subseteq$ ) Suppose $x$ $\in$ $A$ $\cup$ $B$ . Then $x$ $\in$ $A$ or $x$ $\in$ $B$ . $\cdot$ Case 1 ( $x$ $\in$ $A$ ): Because $A$ $\subseteq$ $C$ , it follows that $x$ $\in$ $C$ . $\cdot$ Case 2 ( $x$ $\notin$ $A$ ): Since $x$ $\in$ $A$ $\cup$ $B$ , we have $x$ $\in$ $B$ . As $B$ $\subseteq$ $C$ $\Rightarrow$ $x$ $\in$ $C$ . In either case, $x$ $\in$ $C$ . Because $x$ is an arbitrarily chosen element of $A$ $\cup$ $B$ , we have $A$ $\cup$ $B$ $\subseteq$ $C$ . ( $\supseteq$ ) Suppose $x$ $\in$ $C$ . Then either $x$ $\in$ $A$ , or $x$ $\notin$ $A$ . $\cdot$ Case 1 ( $x$ $\in$ $A$ ): If $x$ $\in$ $A$ , then $x$ $\in$ $A$ $\cup$ $B$ . $\cdot$ Case 2 ( $x$$\notin$ $A$ ): Since ( $C$$\setminus$$A$ ) $\subseteq$ $B$ , we have $x$ $\in$ $B$ $\Rightarrow$ $x$ $\in$ $A$ $\cup$ $B$ . In either case, $x$ $\in$ $A$ $\cup$ $B$ . Since $x$ is an arbitrarily chosen element of $C$ , we have $C$ $\subseteq$ $A$ $\cup$ $B$ . Therefore, $A$ $\cup$ $B$ $=$ $C$ , as claimed.","['elementary-set-theory', 'solution-verification']"
4174693,Convergence of the product of a convergent and absolutely convergent series' elements.,"Prove that the series $\sum_{n=1}^{\infty} a_n b_n$ converges if the following conditions are met: series $\sum_{n=1}^{\infty} b_n$ converges, series $\sum_{n=1}^{\infty} (a_n - a_{n+1})$ absolutely converges. I was thinking applying Abel's test, proving that if: $\sum_{n=1}^{\infty} b_n$ is a convergent series (given), { $a_n$ } is a monotone sequence, and { $a_n$ } is bounded. Then the $\sum_{n=1}^{\infty} a_n b_n$ converges. To prove the second one statement, we've to get following inequality: $a_{n+1} \leq a_n$ . I've no idea how do we do that. Third one, I think, is obtained by the fact, that the $\sum_{n=1}^{\infty} (a_n - a_{n+1})$ series converges, so $\lim_{n\to\infty} (a_n - a_{n+1}) = 0$ . Is it correct?","['analysis', 'calculus', 'absolute-convergence', 'sequences-and-series', 'convergence-divergence']"
4174708,Calculating this line integral (Finding the intersection curve and which parametrization to choose).,"Let $C$ be part of the intersection curve of the Paraboloid $z=x^2+y^2$ with the plane $2x+2y-z+2=0$ that starts from point $(3,1,10)$ and ends in $(1,3,10)$ . We define $f(x,y,z)=z-y^2-2x-1$ . Calculate $\int_{C}f dl$ . My work: Finding $C$ : from the plane equation: $z=2x+2y+2$ . Substituting that into the paraboloid equation: $2x+2y+2=x^2+y^2 \Longrightarrow x^2-2x+y^2-2y=2 \Longrightarrow (x-1)^2+(y-1)^2=4$ . I find this result of getting a circle very weird, because the plane isn't parallel to $z=0$ plane, so I can't see why I received a circle, I expected an ellipse or something. The only thing I can think about is that I received the ""Shadow"" of the ellipse on the $xy$ plane, but I would appreciate any help understanding what have happened here! Anyway, I also got stuck here on which parametrization should I choose, if it's $x=r\cos(t), y=r\sin(t),z=r^2$ OR $x=1+r\cos(t),y=1+r\sin(t),z=?$ Then if I substitute it in the circle's equation I can find $z$ . But I'm not sure if I can do that since $C$ isn't all the circle, it's just part of it. I would appreciate any help, thanks in advance! Edit After the help from answers: If I define $\vec r(t)=(1+2cos(t), 1+2sin(t), 4cos(t)+4sin(t)+6)$ to be the vector that draws the circle. Then $\vec r'(t) = (-2sin(t), -2cos(t), 4cos(t)-4sin(t))$ . Where $\frac{\pi}{2} \ge t \ge 0$ . $f(x,y,z)=z-y^2-2x-1=2x+2y+2-y^2-2x-1=-y^2+2y+1 = 2 - (y-1)^2$ And so my integral: $$
\begin{split}
\int_C f dl
 &= \int_0^{\pi/2}
         2\cos(2t)
         \sqrt{(2\sin(t))^2 + (2\cos(t))^2 + (4\cos(t)-4\sin(t))^2} dt \\
 &= \int_0^{\pi/2}
         2\cos(2t)
         \sqrt{8 + (16\cos(t)^2 - 16\sin(2t) + 16\sin(t)^2)} dt \\
 &= \int_0^{\pi/2} 2\cos(2t)\sqrt{24-16\sin(2t)} dt
\end{split}
$$ I'm having some difficult times deciding how to do this integral","['integration', 'multivariable-calculus', 'line-integrals']"
4174775,"How to calculate $ \intop_{\partial(B_{R}\left(0\right))}\frac{5z^{3}-12z}{|\left(\tau_{1},\tau_{2},\tau_{3}\right)-\left(x,y,z\right)|^{3}}dS_{2} $","Conside a ball with center at $ (0,0,0) $ and radius $ 2 $ in $ \mathbb{R}^3 $ . Now let $ \tau=\left(\tau_{1},\tau_{2},\tau_{3}\right)\in\mathbb{R}^{3} $ be a constant point in the space. How can I calculate $ \intop_{\partial(B_{2}\left(0\right))}\frac{5z^{3}-12z}{|\left(\tau_{1},\tau_{2},\tau_{3}\right)-\left(x,y,z\right)|^{3}}dS_{2} $ Where $ dS_{2} $ means integrate by the 2 dimesional surface area of the sphere. Background Im trying to solve the following Laplace equation: $ \begin{cases}
u_{xx}+u_{yy}+u_{zz}=0 & x^{2}+y^{2}+z^{2}<4\\
u\left(x,y,z\right)=5z^{3}-12z & x^{2}+y^{2}+z^{2}=4
\end{cases}$ Eearlier, I found a formula for homogenous Laplace equation's in a ball in $\mathbb{R}^n $ (using the right Green function), and it is given by: $ u\left(x\right)=\frac{1}{R|S^{N-1}|}\intop_{\partial\left(B_{R}\left(0\right)\right)}\frac{\left(R^{2}-|x|^{2}\right)}{|x-y|^{N}}\varphi\left(y\right)dS_{N-1}\left(y\right) $ Where $ x $ here in $ \mathbb{R}^N$ , $ S^{N-1}| $ is the $N-1 $ dimensional area of a unit sphere in $ \mathbb{R}^N$ , $ \varphi $ is the function for the boundary condition of the Laplace equation $$ \begin{cases}
\varDelta u\left(x\right)=0 & inside\thinspace\thinspace the\thinspace\thinspace ball\\
u\left(x\right)=\varphi\left(x\right) & for\thinspace\thinspace\thinspace x\thinspace\thinspace\thinspace in\thinspace\thinspace\thinspace the\thinspace\thinspace\thinspace boundary\thinspace\thinspace\thinspace of\thinspace\thinspace\thinspace the\thinspace\thinspace\thinspace\thinspace ball
\end{cases} $$ and $ dS_{N-1}(x) $ means integration by the $N-1$ dimesnional surface of the boudary. I cant see how to calculate this integral (I wrote it without the constatnts from the formula). I will highly appriciate any help. Thanks in advance.","['multivariable-calculus', 'partial-differential-equations']"
4174777,Coin tossing - what's more probable?,"I am solving the following probability exercise. The solution I have found is very counter intuitive and I feel It is wrong, but I can't seem to understand why. A fair coin is tossed twice, you have to decide wheter it is more likely that two heads
showed up given that: 1) at least one toss is head, 2) the second toss was head. Solution Let $A$ be the event ""the first toss is head"" and let $B$ be
the event ""the second toss is head"". For case 1,: $$ P(A \cap B \vert A \cup B) = \frac{P(A \cap B \cap (A \cup B))}{P(A \cup B)} = \frac{P(A\cap B)}{P(A) + P(B) - P(A \cap B)} = \frac{1/4}{3/4} = 1/3$$ For case 2: $$ P(A \cap B \vert B) = \frac{P(A\cap B)}{P(B)} = \frac{1/4}{1/2} = \frac{1}{2}$$ Is this right? I feel like case $1$ should be more probable, given that at least may mean there are already two heads? Can someone shed some light?",['probability']
4174786,Combinatorial interpretation of rational function on e,"Over the last few weeks I have become obsessed with expressions like $$
\frac{e+4 e^{2}+e^{3}}{(1-e)^{4}},
$$ $$
\frac{e+26 e^{2}+66 e^{3}+26 e^{4}+e^{5}}{(1-e)^{6}},
$$ or $$
\frac{e+120 e^{2}+1191 e^{3}+2416 e^{4}+1191 e^{5}+120 e^{6}+e^{7}}{(1-e)^{8}}.
$$ These expressions sparked interest in me because they approximate $3!,5!$ and $7!$ , respectively and are part of a larger family of decent approximations (these approximations are quite good till 16!). One reason why this is true is because the relation between this expressions and polylogarithm, and the later with the gamma function, but I would really like to know if there is another way to justify why they approach factorials. I have delved on analytic combinatorics, and $q$ -analogs that talk about evaluating at roots of unity, poles or saddle points, but none of them seem totally appropriate,  Although they study the idea of evaluating a generating function in transcendental or complex numbers, none of them seem to relate directly to this. PD: a Dual to this identities is the evaluation at $e^{-1}$ , $$\frac{e^{-1}+11 e^{-2}+11 e^{-3} +e^{-4 }}{\left(1-e^{-1}\right)^{5}}$$ these are the same but with a correcting minus sign, so with $e^{-1}$ we get $4!$ while with $e$ we get $-4!$ . I add these  as they make more sense when we convert back to the classic polylogarithms expression $$5! \approx \operatorname{Li}_{-5}(z) = \sum_{k=0}^ \infty k^{5}z^k$$ with $z=\frac{1}{e}$ that needs $|z|<1$ , but I guess the $e$ expressions coincide with the analytic continuation of these series Also Something that made me stick with this subject was that for example $$ \frac{z+26 z^{2}+66 z^{3}+26 z^{4}+z^{5}}{(1-z)^{6}} =\frac{1}{z-1}+\frac{31}{(z-1)^{2}}+\frac{180}{(z-1)^{3}}+\frac{390}{(z-1)^{4}}+\frac{360}{(z-1)^{5}}+\frac{120}{(z-1)^{6}} $$ where something notable is that the last coefficient is exactly 5!, this is because eulerian numbers sum to factorials, but this also seemed crazily connected with the Cauchy residue theorem, only that this one was about $(z-1)^{-n}$ and not about $(z-1)^{-1}$ EDIT: Someone edited out an oeis entry linking this to the eulerian polynomials, so just so you know I'm aware what they are, also I will add a comment that I think it's crucial to finding the connection ""This seems to be connected to this combinatorial problem math.stackexchange.com/questions/257890/simon-newcombs-problem stating the formula $$\sum_{d=0}^{\infty} \frac{A_{d}(t) x^{d}}{(1-t)^{d+1} d !}=\frac{1}{1-t e^{x}}$$ the wikipedia page has the case $x=1$ although it doesn't seem to provide any source, while Jair answers [Comment] is that formula with $t=1/e$ . This seems promising as, that formula is almost a composition of classical analytical combinatorics constructions, and the wikipedia case has a $1/e$ as pole. ""","['number-theory', 'analytic-combinatorics', 'complex-analysis', 'combinatorics', 'generating-functions']"
4174816,Double integral polar coordinates - boundaries problem,"I need to calculate the surface of the area between $$\frac{(x-2)^2}{9} + \frac{(y+1)^2}{4} \le 1$$ and $$y \ge 0$$ Let's introduce polar coordinates: $$x-2 = 3r\cos(\phi)$$ $$y+1 = 2r\sin(\phi)$$ $$|J| = 6r$$ Substituting this in the first inequality we get that $r^2 \le 1$ , which means $r \in [0,1]$ for now. Now here's the problem. In the second inequality we have: $$r\sin(\phi) \ge 0$$ As $r$ is already greater or equal to zero, we have that $\sin(\phi) \ge 0$ , and thus that $\phi \in [0, \pi]$ One can also see this by drawing a picture, the line $y=0$ is the x axis and we get that it's greater than zero above the x axis, which is from $0$ to $\pi$ Substituting this, I get the following double integral: $$ \int_{0}^{\pi}\int_{0}^{1} 6rdrd\phi$$ and when I solve it I get that the solution is $3\pi$ . However, my workbook states that the solution is $2\pi - \frac{3\sqrt{3}}{2}$ Can anyone help me understand where I might be wrong?","['integration', 'multivariable-calculus', 'multiple-integral']"
4174824,Joint asymptotic convergence/normality of partitioned sums,"Define $S = \{1,\dots, |S|\}$ , and for each $s \in S$ let $\{X_{i,s}\}_{i=1}^\infty \overset{iid}{\sim} P_s$ and assume that $E[X_{i,s}] = 0$ for each $s$ . Now, for each $n$ , define $n_s(n) \leq n$ with $n_s(n) \in \mathbb{N}$ and $\frac{n_s(n)}{n} \xrightarrow{P} \delta_s \in (0,1)$ with $\sum_{s\in S}n_s(n) = n$ and $\sum_{s\in S}\delta_s = 1$ . Let $n_s(n)$ be non-decreasing for each $n$ . Now, I want to know whether \begin{align*}
\frac{1}{\sqrt{n}}\begin{pmatrix}
\sum_{i=1}^{n_1(n)}X_{i,1}\\
\vdots\\
\sum_{i=1}^{n_{|S|}(n)}X_{i,|S|}
\end{pmatrix} \xrightarrow{d} N(0, \Sigma)~,
\end{align*} for some covariance matrix $\Sigma$ . Assume that $\{X_{i,s}\}_{i=1}^\infty$ independent of $\{X_{i,s'}\}_{i=1}^\infty$ for any $s'\neq s$ . I think I can show that each of the coordinate sums is asymptotically normal, as follows: Fix some $s$ and define $X_i = X_{i,s}$ . Now, let $Z_n = \frac{1}{\sqrt{n}}\sum_{i=1}^{n}X_{i}$ ,
and now the CLT gives that, for some $\sigma_s$ , $$Z_n \xrightarrow{d} N(0, \sigma_s)~,$$ and so $$E[I\{Z_n \leq x\}]=P(Z_n \leq x) \rightarrow \Phi_s(x)~,$$ where $\Phi_s(x)$ is the cdf of $N(0, \sigma_s)$ . Now, since $\frac{n_s(n)}{n} \xrightarrow{P} \delta_s$ , we get the necessary result (by continuous mapping thm) if we can show that $E[E[I\{Z_{n_s(n)}\leq x\}| n_s(n)]] = E[I\{Z_{n_s(n)}\leq x\}] \rightarrow \Phi(x)$ . So, by the Vitali convergence theorem, we are done if we can show that $E[I\{Z_{n_s(n)}\leq x\}| n_s(n)] \xrightarrow{P} \Phi(x)$ . Finally,let $\epsilon > 0$ be given and note that there exists $N$ such that $|P(Z_n \leq x) - \Phi(x)| < \frac{\epsilon}{2}$ for all $n > N$ . Now, we have that we can pick $n$ sufficiently large so that $P(n_s(n) \leq N) < \frac{\epsilon}{2}$ , and so, for sufficiently large $n$ , we have \begin{align*}
P(|E[I\{Z_{n_s(n)}\leq x\}| n_s(n)] - \Phi_s(x)| > \epsilon) =&\ P(|E[I\{Z_{n_s(n)}\leq x\}| n_s(n)] - \Phi_s(x)| > \epsilon| n_s(n) > N)P(n_s(n) > N) + P(|E[I\{Z_{n_s(n)}\leq x\}| n_s(n)] - \Phi_s(x)| > \epsilon| n_s(n) \leq N)P(n_s(n) \leq N)\\
\leq&\ P(|E[I\{Z_{n_s(n)}\leq x\}| n_s(n)] - \Phi_s(x)| > \epsilon| n_s(n) > N)+P(n_s(n) \leq N)\\
<&\ \frac{\epsilon}{2} + \frac{\epsilon}{2}~,
\end{align*} and so, $E[I\{Z_{n_s(n)}\leq x\}| n_s(n)] \xrightarrow{P} \Phi(x)$ , as required. I think this correct, but I am not sure how to to go from this to joint convergence. I think it should be possible to use the above result to say something like \begin{align*}
\frac{1}{\sqrt{n}}\begin{pmatrix}
\sum_{i=1}^{n_1(n)}X_{i,1}\\
\vdots\\
\sum_{i=1}^{n_{|S|}(n)}X_{i,|S|}
\end{pmatrix}|\{n_1(n), \dots, n_s(n)\} \xrightarrow{d} N(0, \Sigma_2)~,
\end{align*} where $\Sigma_2$ is the limit of some conditional covariance matrix? Or something like that? But I am not sure how to get there formally","['statistics', 'probability-limit-theorems', 'weak-convergence', 'conditional-probability', 'probability-theory']"
4174854,ODE: The Lyapunov stability of a set,"When talking about the Lyapunov stability of a dynamical system, we usually take some point in the domain to test its stability. For example, for the ODE $\dot{x} = -x$ , the origin $ x = 0 $ is asymptotically stable. But, I saw a paper about the stability of a dynamical system where the stability is defined for a set rather than a point. They defined the distance $$
{\rm{dist}}(x,A) = \inf_{y \in A}{\Vert x - y \Vert}
$$ and also defined that a closed set $ A $ is asymptotically stable if there exists a class $ \mathcal{KL} $ function $ \beta $ such that for the solution $ x(t) $ , $$
\forall t \ge t_{0}:~{\rm{dist}}(x(t),A) \le \beta({\rm{dist}}(x_{0},A), t - t_{0} )
$$ where $ t_{0} $ and $ x_{0} $ are the initial time and state, respectively. I think it is a quite reasonable generalization of stability. I wonder if there are good references to such a definition. Is this a common definition of stability of a dynamical system? If so, I want some representative references (textbook or paper) introducing it.","['stability-theory', 'ordinary-differential-equations', 'reference-request']"
4174944,"Prove that $x\mapsto \mu(V+x)$ is lower semicontinuous (Big Rudin, Problem $2.23$)","Problem $2.23$ : Suppose $V$ is open in $\mathbb R^k$ and $\mu$ is a finite positive Borel measure on $\mathbb R^k$ . Is the function $f(x)=\mu(V+x)$ continuous? lower semicontinuous? upper semicontinuous? The problem above already has an answer here , which I do not understand quite well. Moreover, I'm primarily looking for help to complete my work on the above problem, or get solutions along the lines of what I have thought. My work: I have already guessed that $f$ is lower semicontinuous. It is easy to see that $f$ need not be continuous or upper semicontinuous, by considering Dirac measures and appropriate open sets. Consider some $V$ and $\mu$ which satisfy the hypothesis. We want to show that $A = \{x: f(x) > \alpha\}$ is open for every real $\alpha$ . Consider $x\in A$ . It suffices to find $r_x > 0$ such that $B(x,r_x) \subset A$ , where $B(x,r_x)$ denotes the open ball of radius $r_x$ centered at $x$ . Since $x\in A$ , $\mu(V+x) > \alpha$ . Also, $V+x$ is open due to the openness of $V$ . We can write $V$ as a disjoint, at most countable union, of open cubes $\{Q_j\}$ in $\mathbb R^k$ , i.e. $$V + a = \bigcup_{j=1}^\infty Q_j$$ How do I find a required $r_x$ ? Thank you! Update: Thanks to the current answer, I have at least one solution that works - but I still need help in completing my attempt.","['alternative-proof', 'measure-theory', 'real-analysis']"
4174965,Infinite subgroups of SO(3),"The classification of finite subgroups of SO(3) is well-known: we have the cyclic groups, the dihedral groups, and the symmetries of the Platonic solids. Is there an analogous result for the infinite subgroups of SO(3)? I don't really need a full classification, I'm interested only in subgroups that are neither Abelian nor dense in SO(3). So far the only such subgroup I managed to find is the infinite analogue of the dihedral groups; pretty much anything you try is dense in SO(3).","['group-theory', 'infinite-groups', 'lie-groups', 'rotations']"
4174990,Iterated integral involving polylogarithms,"To establish notation the polylogarithm Li $_n(x)$ has the power series expansion $$ \text{Li}_n(x)= \sum_{k=1}^\infty \frac{x^k}{k^n} $$ and the Riemann zeta can be considered the special value $\zeta(n) =\text{Li}_n(1).$ Define $$F_1(r)=\text{Li}_1(r)=-\log(1-r)$$ $$F_2(r)=\int_0^r dt \big(\frac{1}{t} + \frac{2}{1-t} \big) F_1(t) = (\text{Li}_1(r))^2 + \text{Li}_2(r) $$ $$F_3(r)=\int_0^r dt \big(\frac{1}{t} + \frac{2}{1-t} \big) F_2(t) = $$ $$ =\frac{2}{3}(\text{Li}_1(r))^3 + \text{Li}_1(r)\big(\text{Li}_2(r)+ \text{Li}_2(1-r)+\zeta(2)\big) + \text{Li}_3(r)+ 2\text{Li}_3(1-r) - 2\zeta(3) $$ where the closed forms can be found with Mathematica, although manual simplification was carried out for the last expression.  In general, define $$F_n(r)=\int_0^r dt \big(\frac{1}{t} + \frac{2}{1-t} \big) F_{n-1}(t)$$ Question 1: Can explicit forms be found for $F_4$ or for larger $n$ ? Question 2: Can it be shown that $$ \int_0^1 F_n(-r) \frac{dr}{r} = -\frac{\zeta(n+1)}{2} \quad \text{ and } \quad \int_0^1 F_n(+r) \frac{dr}{r}
= \big(2^n-1)\zeta{(n+1)} $$ (In addition to the closed forms above, for $n=4$ I get numerical agreement. )","['integration', 'polylogarithm', 'closed-form']"
4174991,Central limit theorem problem verification,"Attempt: a. $\mu=(1/6)(1)+(1/6)(2)+(1/6)(3)+(1/6)(4)+(1/6)(5)+(1/6)(6)=3.5$ $\sigma=\sqrt{EX^2-(EX)^2}=\sqrt{2.9167}$ b. $\mu=(1/216)((1)(3)+(3)(4)+(6)(5)+(10)(6)+(15)(7)+(21)(8)+(25)(9)+(27)(10)+(27)(11)+(25)(12)+(21)(13)+(15)(14)+(10)(15)+(6)(16)+(3)(17)+(1)(18))=10.5$ $\sigma=\sqrt{EX^2-(EX)^2}=\sqrt{8.75}$ c.By the law of large numbers, $\mu_{\overline{X}}=10.5,\sigma_{\overline{X}}=(\sqrt{8.75})/(\sqrt{25})$ d. $P\{\overline{X}>10\}=P\{Z>-.845\}=.8$ e.In this case $P\{\overline{X}>10\}=P\{Z>-1.195\}=.88$ so the value increases. This is not a graded assignment, but an exercise I am practicing.","['statistics', 'solution-verification']"
4175022,Help with Arithmetic Progressions of Perfect Squares,"Recently, I needed to generate all arithmetic progressions of three distinct perfect squares without any repeats. Mapping $\left(x, y\right)$ to such an arithmetic progression centered at $\left(x^2+y^2\right)^2$ with difference $4xy\left(y^2-x^2\right)$ for all $\left(x,y\right)\in\mathbb{X}$ , where $\mathbb{X}:=\left\{\left(x,y\right)\in\mathbb{N}^2:0<x<y\right\}$ , should solve this problem, as Fibonacci famously derived in his solution to the Congruum Problem. This means that for such an arithmetic progression $\left(b^2-h, b^2, b^2+h\right)$ , there should a unique solution in $\mathbb{X}$ to the system of equations $x^2+y^2=b,4xy\left(y^2-x^2\right)=h$ . However, in the case of the progression $\left(205^2,425^2,565^2\right)$ , for which $h=138600$ , these equations have no solution in $\mathbb{X}$ , as can be seen in this Desmos plot. What mistake am I making?","['number-theory', 'elementary-number-theory', 'integers', 'square-numbers', 'parametrization']"
4175040,How many non-congruent triangles can be formed by the vertices of a regular polygon of $n$ sides,"On a circle there are $n$ evenly spaced points (i.e., they form a regular polygon). How many triangles can be formed when congruent triangles are considered the same? This question is closely related to How many triangles can be formed by the vertices of a regular polygon of $n$ sides? , but here congruent triangles are considered to be the same.","['combinatorics', 'geometry']"
4175056,Is it more likely to get $450-550$ or $379-479$ blue marbles in $1000$ draws?,"This is a follow up question to this: An urn contains $4$ blue and $4$ red marbles. What is $P(A\vert B)$? An urn contains $4$ blue and $4$ red marbles. At first a marble is drawn (without looking) and removed from the urn. Then, a marble is drawn from the urn, its color recorded and put back in the urn. This process is repeated $1000$ times. Let $D$ be the event that between $450$ and $550$ blue marbles are drawn and let $E$ be the event that between $379$ and $479$ blue marbles are drawn. Which event is more likely? Intuitively I would say that event $D$ is more likely. This is because on average I would expect around $500$ blue marbles drawn. Since the event $D$ is centered around this average it seems more likely to me than event $E$ that is centered around a value of $429$ . Is there a nice way to show this mathematically by maybe using some sort of approximation?","['statistics', 'combinatorics', 'probability']"
4175176,"The graph of function $f(x)=a+b\cos (\frac{\pi}2-hx)$ is given, what is the value of $abh$?","The graph of function $f(x)=a+b\cos (\frac{\pi}2-hx)$ at a period is as follow. What is the value of $abh$ ? $1)\frac43\qquad\qquad2)-\frac43\qquad\qquad3)\frac34\qquad\qquad4)-\frac34$ I'm not sure how it denotes a period of the function visually I see it is half of the period. anyway, I think period of function is $2\times(\frac{7\pi}2-\frac{-5\pi}2)=12\pi$ . Hence $h$ should be $\frac16$ or $\frac{-1}{6}$ (I'm not sure which one is correct). And because minimum of the function is $-4$ , and the concavity of $\cos x$ changed, we can conclude $b=-4$ . but I don't know what is the value of $a$ and I'm not sure about the sign of $h$ .","['algebra-precalculus', 'functions', 'trigonometry']"
4175182,Ordered pair - why so complicated?,"In wikipedia is written that Kuratowski definition of ordered pair is now-accepted (I use down-right index ""K"" to mark Kuratowski formula): $p_K = (a,b)_K := \{ \{a\}, \{a,b\} \}$ My question is why people not use below simpler definition instead: $p = (a,b) := \{ \{a\}, \{b, \varnothing \} \}$ ? UPDATE After discussion on comments we get following Advantages of $(a,b)$ : for paris $(a,\varnothing)$ the result of $(a,\varnothing) = \{ \{a\}, \{  \varnothing \} \}$ is simpler than $(a,\varnothing)_K = \{ \{a\}, \{ a, \varnothing \} \}$ (we don't need to duplicate $a$ ) for case when $a=b$ formula $(a,a)=\{ \{a\}, \{a,\varnothing \} \}$ save property that we have two elements(pairs) in set, which is loose by formula $(a,a)_K=\{\{a\}\}$ Disatvantages of $(a,b)$ : for case $(\{\varnothing\},\varnothing) = \{ \{\{\varnothing\}\}, \{ \varnothing \}  \}$ we loose property that when $a\neq b$ the first element of pair  cardinality is $=1$ and second element cardinality is $=2$ which is saved for Kuratowski formula: $(\{\varnothing\},\varnothing)_K = \{ \{\{\varnothing\}\}, \{ \{\varnothing\}, \varnothing \}  \}$ . In this case both elements has cardinality $=1$ . for case $a=b$ formula $(a,a)_K=\{\{a\}\}$ is simpler than $(a,a)=\{ \{a\}, \{a,\varnothing \} \}$ for Kuratowski formula is easy to extract pair elements using union/intersection (which is not possible/easy for my formulat): $\pi_1( p_K ) = \bigcap (a,b)_K = \{a\}\cap \{a,b\} = \{a\}$ $\pi_2( p_K ) = \bigcup (a,b)_K = \{a\}\cup \{a,b\} = \{a, b\}$ I also realized that my definition is similar (but not the same) to Winner's definition",['elementary-set-theory']
4175194,Behavior of $\sum_i^n (1-\frac{1}{i})^s$ as a function of $s$?,"I'm interested in behavior of the following sum as a function of $s$ $$\frac{1}{n}\sum_{i=1}^n \left(1-\frac{1}{i}\right)^s$$ For $n=1000$ and $s\in (1,10000)$ , this seems almost linear on a log-plot ( notebook ), any tips how to model this analytically?","['riemann-zeta', 'summation', 'sequences-and-series']"
4175221,Generalization of the identity $2(m^2+n^2)=(m+n)^2+(m-n)^2$ for cubic case,I am very exited to see the following beautiful identity: $2(m^2+n^2)=(m+n)^2+(m-n)^2$ I wonder if I can  generalize it for cubic case like the expression as follows: $a(n_{1}^3+n_{2}^3+n_{3}^3)=(\pm n_1\pm n_2 \pm n_3)^3+(\pm n_1\pm n_2 \pm n_3)^3+\cdot \cdot \cdot+(\pm n_1\pm n_2 \pm n_3)^3$ Where $a$ is some constant and $\pm$ means you are free to choose any sign. I tried it by caculating $(n_1+n_2+n_3)^3+(n_1-n_2+n_3)^3+(n_1+n_2-n_3)^3$ but could not able to get an expression like $a(n_{1}^3+n_{2}^3+n_{3}^3)$ . Any hint or an explicit equation will be a great help.,"['elementary-number-theory', 'combinations', 'combinatorics', 'discrete-mathematics']"
4175223,A functional equation problem that is related to tetrahedral numbers,"Find all functions $f:\mathbb{R}\rightarrow\mathbb{R}$ s.t. $f(x+1)-2f(x)+f(x-1)=x+1$ , $f(0)=0$ , and $f(1)=1$ . The problem is stated above. My attempt to solve this question is to plug in $x=0$ , and $x=1$ . That gives us $f(-1)=0$ and $f(2)=4$ . Plugging in $x=2$ can give us $f(3)=10$ . After that we can also get $f(4)=20$ , $f(5)=35$ ...etc. I observed the sequence $0,1,4,10,20,35,...$ and found that these numbers are tetrahedral numbers , so the function we want may look like this: $f(x)=\frac{x(x+1)(x+2)}{6}$ However, by plugging in different integer values, and using mathematical induction can only confirm that the function we want is valid within $\mathbb{Z}$ . I don't know if there's a way to expand the domain from $\mathbb{Z}$ to $\mathbb{R}$ .",['functions']
4175248,"Given $x= \left ( 6, 2, -3 \right ),$ how to find the coordinate $x$ up to the basis $V$","In the vector space $\mathbb{R}^{3},$ given two systems of vectors $$U= \left \{ u_{1}= \left ( 4, 2, 5 \right ), u_{2}= \left ( 2, 1, 3 \right ), u_{3}= \left ( 3, 1, 3 \right ) \right \}$$ $$V= \left \{ v_{1}= \left ( 5, 2, 1 \right ), v_{2}= \left ( 6, 2, 1 \right ), v_{3}= \left ( -1, 7, 4 \right ) \right \}$$ Proved that $U$ and $V$ are two bases of $\mathbb{R}^{3}.$ Source: StackMath/@haidangel_ in.edit In the edited part, I gave a bonus question: Given $x= \left ( 6, 2, -3 \right ).$ How to find the coordinate $x$ up to the basis $V.$ Now I have two approaches but I don't know which one is true ? I need to the help. First approach . Consider the linear combination $$\alpha_{1}v_{1}+ \alpha_{2}v_{2}+ \alpha_{3}v_{3}= x$$ This is equivalent to the matrix equation $$\begin{bmatrix} 5 & 6 & -1\\ 2 & 2 & 7\\ 1 & 1 & 4 \end{bmatrix}\begin{bmatrix} \alpha_{1}\\ \alpha_{2}\\ \alpha_{3} \end{bmatrix}= \begin{bmatrix} 8\\ 2\\ -3 \end{bmatrix}$$ To find the solution, consider the augmented matrix. Applying elementary row operations, we obtain $$\left [ \begin{array}{rrr|r} 5 & 6 & -1 & 8\\ 2 & 2 & 7 & 2\\ 1 & 1 & 4 & -3 \end{array} \right ]\xrightarrow{R_{3}\leftrightarrow R_{2}}\left [ \begin{array}{rrr|r} 5 & 6 & -1 & 8\\ 1 & 1 & 4 & -3\\ 2 & 2 & 7 & 2 \end{array} \right ]\xrightarrow{2R_{2}- R_{3}}\left [ \begin{array}{rrr|r} 5 & 6 & -1 & 8\\ 1 & 1 & 4 & -3\\ 0 & 0 & 1 & -8 \end{array} \right ]$$ $$\left [ \begin{array}{rrr|r} 5 & 6 & -1 & 8\\ 1 & 1 & 4 & -3\\ 0 & 0 & 1 & -8 \end{array} \right ]\xrightarrow{6R_{2}- 25R_{3}- R_{1}}\left [ \begin{array}{rrr|r} 1 & 0 & 0 & 174\\ 1 & 1 & 4 & -3\\ 0 & 0 & 1 & -8 \end{array} \right ]$$ It follows that the solution is $\alpha_{1}= 174, \alpha_{3}= -8, \alpha_{2}= -3- \alpha_{1}- 4\alpha_{3}= -145.$ We obtain $$\left [ x \right ]_{V}= \begin{bmatrix} 174\\ -145\\ -8 \end{bmatrix}$$ Second approach . By the coordinate transformation equation $$\left [ x \right ]_{V}= P_{V\rightarrow E}\cdot\left [ x \right ]_{E}= \left ( P_{E\rightarrow V} \right )^{-1}\cdot\left [ x \right ]_{E}= \begin{bmatrix} 5 & 6 & -1\\ 2 & 2 & 7\\ 1 & 1 & 4 \end{bmatrix}^{-1}\begin{bmatrix} 6\\ 2\\ -3 \end{bmatrix}= \begin{bmatrix} 176\\ -147\\ -8 \end{bmatrix}$$","['vector-spaces', 'matrices', 'change-of-basis', 'solution-verification', 'linear-algebra']"
4175280,Finding the bounds for $|e^z - 1|$ on unit circle.,"The sharp upper bound is relatively easy to find: $$|e^z - 1| = \left|\sum_{n = 1}^\infty \frac{z^n}{n!} \right| \leq \sum_{n = 1}^\infty \frac{|z|^n}{n!} = e^{|z|} - 1 = e - 1$$ and it is attained at $z = 1$ . I am wondering if there is a simple way to obtain a positive lower bound. I am suspecting a sharp lower bound is $(1 - 1/e)$ but I cannot prove it. I was told that $(3 - e)$ is a positive lower bound, but I could not prove it neither. Remark: One can do some horrible single variable calculus by writing $z = e^{it}$ , where $t \in [0, 2\pi]$ but I would like to know if there is another (possibly much simpler) way to find a nontrivial lower bound. Edit: It seems that I got many answer like the following but they are deleted by the author very soon. I think it is a good idea to show a wrong attempt so I put it here: Putting $z = e^{it}$ , then \begin{align*}|e^z - 1|^2 & = |e^{2 \cos t} - 2e^{\cos t} \cos (\sin t)) + 1| \\
& \geq |e^{\cos t} - 1|^2 \\
& \geq (1 - 1/e)^2
\end{align*} The last estimation is WRONG when $t = \pi/2$ . (End of edit)",['complex-analysis']
4175314,What does holonomy measure?,"I have difficulty understanding conceptually what holonomy measures.
it can return a phase shift of the vector transported parallel along the connection. If there is no phase shift, it means that the connection is flat, and if there is phase shift, then it should indicate that the space is curved.
But I have found examples where a flat space can have non-trivial holonomy, for example a cone has non-trivial holonomy (see On a flat surface, can a holonomy can be nontrivial around certain curves ).
So my question: what information does holonomy give us? anything about the curvature?","['connections', 'holonomy', 'riemannian-geometry', 'differential-geometry']"
4175355,Nuclearity of the free product of C* algebras,"Let $A, B$ be unital $C^*$ algebras and $A\star B$ their unital (universal) free product. Assume that $A$ and $B$ are nuclear. When can we say that $A\star B$ is nuclear? I know that it can happen, e.g. $\mathbb{C}^{2}\star \mathbb{C}^{2}=\mathrm{C}^*(\mathbb{Z}_2\star \mathbb{Z}_2)$ is nuclear as $\mathbb{Z}_2\star \mathbb{Z}_2$ is amenable, but on the other hand $\mathrm{C}^*(\mathbb{Z})\star \mathrm{C}^*( \mathbb{Z})=\mathrm{C}^*(F_2)$ is not nuclear. I would be also interested in an analogous question for the reduced free products.","['harmonic-analysis', 'functional-analysis', 'operator-algebras']"
4175365,How to show that the following sequence is convergent?,"I am trying to solve this question from a math book. Suppose $a_n$ is convergent, then show whether the following sequence is convergent or divergent: $$ \begin{pmatrix}\cfrac{a_n}{a_{n+1}} \end{pmatrix}_n$$ my initial thoughts were that the series should converge to $1$ . But then looking at the d'Alembert's ratio, where it's the reciprocal of  this series, I am starting to think that I am wrong with the limit being $1$ . What is ít that I am doing wrong here. Any suggestion would be appreciated.","['limits', 'convergence-divergence', 'real-analysis']"
4175380,"Let $X$ be an ordered set. If $Y$ is a proper subset of $X$ that is convex in $X$, then is $Y$ an interval or ray in $X$? [closed]","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 3 years ago . Improve this question The question is from Munkres and this has been answered a lot of time. However, the problems that I am facing are: How does a ray look like in $\mathbb{R}^3$ or $\mathbb{R}^2$ ? What is an interval in an arbitrary topological space $X$ ? How do I think and find out an example that does not satisfy the question ?(I don't want an answer to this question but a hint so that I can find my own answer.) An example: Consider the dictionary topology in $\mathbb{R}^2$ and consider the convex set $S=\{x^2+y^2<1\}$ .We see that this set $S$ is convex. I am not sure whether it is an interval or ray? What is it?","['general-topology', 'analysis']"
4175385,Splitting of Irreducible character when restricted to index $2$ subgroup over finite field,"In Exercise $15$ of chapter 2 of the book ""The symmetric group"" by B.E. Sagan, I can prove the following Let $G$ be finite group and $H$ be an index $2$ subgroup. If $\chi$ is an irreducible character of $G$ , then $\chi|_H$ is irreducible iff $\chi(g) \neq 0$ for some $g \not\in H$ . This is proved using character theory over $\mathbb{C}$ and the fact that a conjugacy class of  an element $h\in G$ in $H$ is as same as that of $G$ or splits in two conjugacy classes of same size. Can this be proved for a finite field of characteristic $p$ as well, when $p\nmid |G|$ ?","['group-theory', 'representation-theory']"
4175396,Count the number of unique $N \times N$ binary matrices where every two rows or columns can be swapped,"Suppose, two $n\times n$ binary matrices are $\it similar$ if one can be transformed to another by swapping any two rows or two columns any number of times. My problem is: how many unique $n\times n$ binary matrices with a given number of 1s are there ? That is, those that are not $\it similar$ to any other matrix using the definition above? For example, there are 7 unique $3\times 3$ matrices having 4 ones: $\begin{array}{|ccc|}\hline
1 & 1 & .\\
1 & 1 & .\\
. & . & .\\\hline\end{array}
\begin{array}{|ccc|}\hline
1 & 1 & 1\\
1 & . & .\\
. & . & .\\\hline\end{array} 
\begin{array}{|ccc|}\hline
1 & 1 & .\\
1 & . & 1\\
. & . & .\\\hline\end{array}$ $\begin{array}{|ccc|}\hline
1 & 1 & .\\
1 & . & .\\
1 & . & .\\\hline\end{array} 
\begin{array}{|ccc|}\hline
. & 1 & 1\\
1 & . & .\\
1 & . & .\\\hline\end{array}$ $\begin{array}{|ccc|}\hline
1 & 1 & .\\
1 & . & .\\
. & 1 & .\\\hline\end{array}
\begin{array}{|ccc|}\hline
1 & 1 & .\\
1 & . & .\\
. & . & 1\\\hline\end{array}$ What I came up with is that two $\it similar$ matrices would have the same
(sorted) column sums and row sums but, apparently, this is not enough.
From the example above, one can see that the three last matrices: $\begin{array}{|ccc|}\hline
. & 1 & 1\\
1 & . & .\\
1 & . & .\\\hline\end{array}  
\begin{array}{|ccc|}\hline
1 & 1 & .\\
1 & . & .\\
. & 1 & .\\\hline\end{array}
\begin{array}{|ccc|}\hline
1 & 1 & .\\
1 & . & .\\
. & . & 1\\\hline\end{array}$ would have $(2, 2, 1)$ rows sum and $(2, 2, 1)$ column sum. There is some similarity with Young diagrams and conjugate/self-conjugate integer partitions.. but the idea how to count these matrices I do not understand, any help would be appreciated.","['matrices', 'combinations', 'integer-partitions', 'combinatorics']"
4175407,$\partial \bar \partial$-lemma for $d$-exact differential form.,"This is the $\partial \bar \partial$ -lemma as stated in [1]: Proposition 6.17 Let $X$ be a Kähler manifold, and let $\omega$ be a form which is both $\partial$ and $\bar \partial$ -closed. Then if $\omega$ is $d$ or $\partial$ or $\bar \partial$ -exact, there exists a form $\chi$ such that $\omega = \partial \bar \partial \chi$ . Voisin only proves the case where $\omega$ is $\bar \partial$ -exact, and I'm stuck with the case where $\omega$ is $d$ -exact. I tried to follow the proof of Voisin, but there is a term that won't disappear. Here is the idea: Since $\omega$ is $d$ -exact, we can write $\omega = d \beta$ for a form $\beta$ . By Hodge theory, there is a harmonic form $\alpha$ and a form $\gamma$ such that $$\beta = \alpha + \Delta_d \gamma,$$ where $\Delta_d$ is the $d$ -Laplacian. Since harmonic forms are $d$ -closed, this implies $$ \omega = d \Delta_d \gamma,$$ and since $X$ is Kähler we also have $\Delta_d = 2\Delta_{\bar\partial} = 2 (\bar \partial \bar \partial^* + \bar \partial^* \bar \partial)$ . Hence \begin{align*}
\omega & = 2 (\partial + \bar \partial)(\bar \partial \bar \partial^* + \bar \partial^* \bar \partial)\gamma \\
& =  2 \partial \bar \partial \bar \partial^* \gamma + 2\partial \bar \partial^* \bar \partial \gamma + 2 \bar \partial \bar \partial^* \bar \partial\gamma.
\end{align*} Since $\partial \bar \partial = - \bar \partial \partial$ , we see that everything except $2\partial \bar \partial^* \bar \partial \gamma$ is $\bar \partial$ -closed, hence $2\partial \bar \partial^* \bar \partial \gamma$ is also $\bar \partial$ -closed. But as $\partial \bar \partial^* = - \bar \partial^* \partial$ (which is true since $X$ is Kähler), we see that $2\partial \bar \partial^* \bar \partial \gamma$ is in the image of $\bar \partial^*$ , hence it vanishes (consider the scalar product with itself, and use the adjointness of $\bar \partial$ and $\bar \partial^*$ ).
Thus $$ w = 2 \partial \bar \partial \bar \partial^* \gamma + 2 \bar \partial \bar \partial^* \bar \partial \gamma.$$ In the same way as above I can deduce that the second term $2\bar \partial \bar \partial^* \bar \partial \gamma$ is $\partial$ -closed, but I don't see why it should be zero. Am I missing something? Or do I have to do something different? I could also use $\Delta_d \gamma = 2 \Delta_{\partial} \gamma$ , but that won't really change much. [1] Voisin, Claire; Hodge Theory and Complex Algebraic Geometry, I","['hodge-theory', 'complex-geometry', 'algebraic-geometry']"
4175410,"Problem $2.18$, Rudin's RCA - Painfully Set Theoretic","Problem $2.18$ : This exercise requires more set-theoretic skill than the preceding ones. Let $X$ be a well-ordered uncountable set which has a last element $\omega_1$ such that every predecessor of $\omega_1$ has at most countably many predecessors. (""Construction"": Take any well-ordered set which has elements with uncountably many predecessors, and let $\omega_1$ be the first of these; $\omega_1$ is called the first uncountable ordinal.) For $\alpha\in X$ , let $P_\alpha[S_\alpha]$ be the set of all predecessors (successors) of $\alpha$ , and call a subset of $X$ open if it is a $P_\alpha$ or an $S_\beta$ or a $P_\alpha \cap S_\beta$ or a union of such sets. Prove that $X$ is then a compact Hausdorff space. (Hint: No well-ordered set contains an infinite decreasing sequence.) Prove that the complement of the point $\omega_1$ is an open set which is not $\sigma$ -compact. Prove that to every $f \in C(X)$ there corresponds an $\alpha\ne\omega_1$ such that $f$ is constant on $S_\alpha$ . Prove that the intersection of every countable collection $\{K_n\}$ of uncountable compact subsets of $X$ is uncountable. (Hint: Consider limits of increasing countable sequences in $X$ which intersect each $K_n$ in infinitely many points.) Let $\mathfrak M$ be the collection of all $E \subset X$ such that either $E \cup \{\omega_1\}$ or $E^c \cup \{\omega_1\}$ contains an uncountable compact set; in the first case, define $\lambda(E) = 1$ ; in the second case, define $\lambda(E) = O$ . Prove that $\mathfrak M$ is a $\sigma$ -algebra which contains all Borel sets in $X$ , that, $\lambda$ is a measure on $\mathfrak M$ which is not regular (every neighborhood of $\omega_1$ has measure $1$ ), and that $$f(\omega_1) = \int_X f\ d\lambda$$ for every $f \in C(X)$ . Describe the regular $\mu$ which Theorem 2.14 associates with this linear functional. The problem certainly demands more set-theoretic skill than what I possess. My goal is to solve the problem in full, and that would start by understanding what it's saying. I request you to kindly help me with explanations/hints, and I will keep updating this post with my progress on this problem as I'm able to understand and do more parts of it. Thoughts: First, they take $X$ to be a well-ordered (every non-empty subset has a least element) uncountable set with last element $\omega_1$ . What do they mean by last ? What is meant by ""let $\omega_1$ be the first of these""? They have defined exactly the open sets (i.e. the topology) in $X$ . We must prove that $X$ is compact and Hausdorff . Hausdorff-ness is clear from Oliver's answer. For compactness, note that the topology on $X$ is the order topology, and by Theorem 27.1 of Munkres, we are done. Update: For (1): Note that $P_{\omega_1} = X\setminus \{\omega_1\}$ , since $\omega_1$ is the last element. So the complement of $\omega_1$ is open. We want to show that it is not $\sigma$ -compact. How do I do that? For (2): Suppose $f\in C(X)$ , i.e. $f$ is continuous on $X$ . I'm not sure what the codomain of the function is, so I'm assuming $\mathbb C$ . It looks like we want to find $z\in\mathbb C$ so that $f^{-1}(\{z\})$ is an $S_\alpha$ set for $\alpha < \omega_1$ . For (3): I found this answer , which seems to work. Lastly, I could use hints on how to go about the final part of the problem about measures. Thanks!","['general-topology', 'measure-theory', 'real-analysis']"
4175424,Integral $\int^\infty_0 \frac{\cos(\omega x)}{\cosh(ax)-\cos\beta}\text{d}x$,"Maybe you can help me, understanding an arising ambiguity: Consider the integral, which is on page 30 integral (6) of the Bateman Project( see link below) $$\int^\infty_0 \frac{\cos(\omega x)}{\cosh(ax)+\cos(\beta)}\text{d}x=\frac{\pi}{a\sin(\beta)}\frac{\sinh(\frac{\beta \omega}{a})}{\sinh(\frac{\pi \omega}{a})}$$ which holds for $\text{Re}(a)\pi>\text{Im}(a^*\beta) $ . Say I want to calculate the integral with a minus in the denominatorfor real $a, \beta$ (hence the above restriction on the parameters is always satisfied), which I have naively done by $\int^\infty_0 \frac{\cos(\omega x)}{\cosh(ax)-\cos(\beta)}\text{d}x=\int^\infty_0 \frac{\cos(\omega x)}{\cosh(ax)+\cos(\beta\pm\pi)}\text{d}x=
\frac{\pi}{a\sin(\beta\pm \pi)}\frac{\sinh(\frac{(\beta\pm\pi) \omega}{a})}{\sinh(\frac{\pi \omega}{a})}=-\frac{\pi}{a\sin(\beta)}\frac{\sinh(\frac{(\beta\pm\pi) \omega}{a})}{\sinh(\frac{\pi \omega}{a})}$ , then I get the ambiguity of the choosen sign infront of the $\pi$ in the $\sinh(\frac{(\beta\pm\pi) \omega}{a})$ . Can anyone explain to me what it is the correct way (sign of $\pi$ ) to solve this integral with the minus in the denominator? Link for formula: https://authors.library.caltech.edu/43489/1/Volume%201.pdf","['integration', 'definite-integrals', 'fourier-transform']"
4175429,Geometry problem from RMO 2016 [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question The following problem is from RMO 2016. Initially it seems pretty trivial, but I am not able to find an easy or elegant solution. The official solution is not intuitive. I am looking for an alternate elegant proof, and also framed in a proper way like we do in contests, because in such problems showing the exact steps is very critical. Let $ABC$ be a right-angled triangle with $\angle B=90^{\circ}$ degree. Let $I$ be the incentre of $ABC$ . Let $AI$ extended intersect $BC$ in $F$ . Draw a line perpendicular to $AI$ at $I$ . Let it intersect $AC$ in $E$ . Prove that $IE = IF$ . So far I have tried taking a point $E'$ such that $IE'=IF$ and then proving that $E$ and $E'$ coincide.","['triangles', 'circles', 'geometry']"
4175440,Fourier series derivatives and convergence,"Let $f(x)=x\sin(x)$ , $x\in[-\pi,\pi$ Find the Fourier series of $g(x)=f'(x)=\sin(x)+x\cos(x)$ , $x\in(-\pi,\pi)$ and show that it converges pointwise to $g$ . Try I found the FS of the function $f(x)=x\sin(x)$ , $x\in[-\pi,\pi)$ (in the just previous problem) to $1-\frac{1}{4}\cos(x)+\sum_{n=2}^{\infty} \left (\frac{2(-1)^{n+1}}{n^2-1} \right) \cos(nx)$ and shown that it converges uniformly to $f$ . (or written as $$1-\frac{1}{2}\cos(x)-2\sum_{k=2}^{\infty}\frac{(-1)^k}{(k^2-1)}\cos(kx)$$ Is there a trick to finding the Fourier of the derivative of my function given that I have the Fourier for my function? How do I show pointwise convergence to $g$ ? *I know about convolutions as I suspect I need that in this problem.
I think pointwise convergence is true if it is continuous and periodic.","['fourier-analysis', 'analysis', 'real-analysis', 'fourier-series', 'pointwise-convergence']"
4175443,Example of complex multiplication for elliptic curve,"In Mathematics of Isogeny Based Cryptography by De Feo, he mentions the following example: It seems I haven't understood something important about complex multiplication. How does $ (x,y) \mapsto (-x,iy)$ make sense in the first place if $E$ is over $\mathbb Q$ , not $\mathbb C$ or $\mathbb Q(i)$ ? $(-x,iy)$ isn't a ( $\mathbb Q$ -rational) point in $E$ . If we grant that $(-x,iy)$ is a point, and so don't require it to be $\mathbb Q$ -rational, what's the problem with doing the same for $\mathbb F_p$ ? Why is the fact that $-1$ is not a square mod $p$ a problem? Given that $-1$ is a square in $\mathbb F_{p^2}$ , why does this mean End $(E(p))$ is not commutative? When he introduces the curve in example 38 on the previous page, he treats it as a curve over $\mathbb C$ . I'm clearly missing something basic. If you could point it out I would be grateful.","['complex-multiplication', 'elliptic-curves', 'number-theory', 'cryptography', 'algebraic-geometry']"
4175444,Conditions of uniform convergence of arithmetic mean,"Under what conditions on sequence $(a_i)_{i=1}^{\infty}$ , where $a_i \in \mathbb R^n$ can we have $$
m^{-1}\sum_{i=1}^{m} \|x_1-a_i\|\|x_2-a_i\|
$$ converges as $m \rightarrow \infty$ uniformly for all $x_1$ and $x_2$ in a compact set $\mathcal X$ . For example, if $m^{-1}\sum_{i=1}^{m} \|a_i\|^2$ and $m^{-1}\sum_{i=1}^{m} a_i$ converges as $m \rightarrow \infty$ , then $m^{-1}\sum_{i=1}^{m} \|x-a_i\|^2$ converges uniformly for all $x$ in $\mathcal X$ . But I cannot derive the similar conditions for the uniform convergence of $m^{-1}\sum_{i=1}^{m} \|x_1-a_i\|\|x_2-a_i\|$ . Can anyone give me some ideas. Thanks~","['sequences-and-series', 'cauchy-sequences', 'real-analysis']"
4175447,"By counting by 2 ways, show a cycle of four acquaintances exists","In a conference there were $35$ participants. There are $110$ couples who know each other. Prove that it is possible to choose 4 members to sit at a round table such that two people sitting close together know each other. This is the last problem in a workbook ""Solving combinatorial math by 'counting in two ways' "" by Nguyen Tang Vu (original here in Vietnamese, Problem 10 on page 62) ""published in the math journal Star Education."" I find it quite interesting because it can't be solved in the usual ways. Here's all I did: Suppose any $2$ people can't get along with $2$ other people.
Count the number $S$ of triples of the form $(A,B,C)$ where person $A$ and person $B$ are familiar with person $C$ . Method 1: Count by $A, B$ . We have $S \le \binom{35}{2}$ (according to the assumption) Method 2: Count by $C$ :
Let $a_i$ be the number of people who know the $i$ -th person. We have: $$ a_1 + a_2 + ... + a_{35} = 220 $$ So $\binom{a_1}{2} + \binom{a_2}{2} + \binom{a_3}{2} + \ldots + \binom{a_{35}}{2} \ge 585$ . I want to prove what I assume is wrong, but $\binom{35}{2} = 595$ is still greater than $585$ . I tried to tighten my inequality but I can't. Can anyone give me a hint, please?","['graph-theory', 'combinations', 'combinatorics', 'permutations']"
4175457,If $B\subset\mathbb{R}$ is a Borel set and $f:B\to\mathbb{R}$ is an increasing function then $f(B)$ is a Borel set,"I am trying to prove the following statement: ""If $B\subset\mathbb{R}$ is a Borel set and $f:B\to\mathbb{R}$ is an increasing function then $f(B)$ is a Borel set"" but I have only managed to prove the easier statement ""If $B\subset\mathbb{R}$ is a Borel set and $f:\mathbb{R}\to\mathbb{R}$ is a strictly increasing function then $f(B)$ is a Borel set"" My proof (of the easier statement): By Inverse function $f^{-1}:f(\mathbb{R})\to\mathbb{R}$ of a strictly increasing function $f:\mathbb{R}\to\mathbb{R}$ is continuous we have that $f^{-1}:f(\mathbb{R})\to\mathbb{R}$ is continuous so $(f^{-1})^{-1}(\mathbb{R})=f(\mathbb{R})$ is open hence Borel thus $f^{-1}$ is a continuous function defined on a Borel set so it is Borel measurable which implies that $(f^{-1})^{-1}(B)=f(B)$ is a Borel set, as desired. $\square$ I would like to prove the initial statement but I have been stuck for a while so I would appreciate an hint about how to tackle its proof, thanks.","['borel-sets', 'measure-theory', 'monotone-functions', 'real-analysis']"
4175474,Proving $\cot 20^\circ - \cot 40^\circ + \cot 80^\circ = \sqrt{3}$,"Prove that: $$\cot 20^\circ - \cot 40^\circ + \cot 80^\circ = \sqrt{3}$$ What I have learnt in trigonometry so far: Trigonometric ratios and their graphs, formulas of ratios for compound angles, sum and product formulas of ratios (eg. $2 \sin A \cos B = \sin (A+B) + \sin (A-B)$ ). An answer using the things I have learnt would be appreciated. I tried this multiple times by trying to simplify to tan and then using the expression for $\tan (A+B)$ , but it didn't work out. EDIT: My attempt in detail: $$\cot 20^\circ - \cot 40^\circ + \cot 80^\circ = [(\tan 20^\circ + \tan 80^\circ) / \tan 20^\circ \tan 80^\circ ] - 1 / \tan 40^\circ$$ After this I further tried to get it in some form of ratio with which I could get angles like $ 30^\circ$ or $ 60^\circ $ , but I was unable to do it. There were two other proofs prior to this one, which seemed to use the same strategy. Source: Challenge and Thrill of Pre-College Mathematics","['contest-math', 'trigonometry', 'problem-solving']"
4175520,Bounds for the $n^{th}$-prime number and the inverse logarithmic integral?,"Are there any bounds for the $n^{th}$ -prime number $p(n)$ and the inverse logarithmic integral $\text{ali}(n)=\text{li}^{-1}(n)$ under the Riemann Hypothesis? $$|p(n)-\text{ali}(n)|<?$$ here is my attempt,it does not require skills in analytic number theory. It is definitely not a formal approach, I hope it holds and I gladly accept advice :-) $\pi(x)$ is the prime counting function, which can be understood as the inverse of the function that returns the nth prime number $p(x)$ From the Riemann hypothesis we have for $x\geq 2657$ : $$|\pi(x)-\text{li}(x)|\le \frac{1}{8 \pi}\sqrt{x}\ln(x) \tag{1.0}$$ From which we get the following inequalities: $$p(\text{li}(x)-\frac{1}{8 \pi}\sqrt{x}\ln(x))\le p(\pi(x))\le x; \ \ \ \  x\le p(\pi(x)+1) \le p(\text{li}(x)+\frac{1}{8 \pi}\sqrt{x}\ln(x)+1)$$ lets define $I^{-}(x)=\text{li}(x)-\frac{1}{8 \pi}\sqrt{x}\ln(x)$ ; $I^{+}(x)=\text{li}(x)+\frac{1}{8 \pi}\sqrt{x}\ln(x)+1$ : $$ p(I^{-}(x))\le x; \ \ \ \
p(I^{+}(x)) \geq x$$ let $J^{-}(x)$ and $J^{+}(x)$ the inverses of $I^{-}(x)$ e $I^{+}(x)$ $$ p(I^{-}(J^{-}(x)))=p(x)\le J^{-}(x); \ \ \ \ p(I^{+}(J^{+}(x)))=p(x) \geq J^{+}(x).$$ Since the functions $ J ^ {-} $ and $ J ^ {+} $ thus defined are not easy to calculate, let's define the functions $ f ^ {-} $ and $ f ^ {+} $ such that $$f^{+}(x)\le J^{+}(x); \ \ \ \ J^{-}(x) \le f^{-}(x). \tag{1.1}$$ In order for $ f ^ {-} (x) $ and $ f ^ {+} (x) $ to satisfy $ (1.1) $ , we need to have $$ I ^ {-} \big (f ^ {-} (x) \big) \geq x; \ \ \ \ I ^ {+} \big (f ^ {+} (x) \big) \le x. \tag {1.2} $$ We choose arbitrarily $$ f^{-}(x):=\text{ali}(x) )\Big(1+\frac{1}{8 \pi \text{li}(x \ln x)} \sqrt{x \ln x} \ln(x \ln x )\Big)$$ $$ f^{+}(x):=\text{ali}(x) )\Big(1-\frac{1}{8 \pi \text{li}(x \ln x)} \sqrt{x \ln x} \ln(x \ln x)\Big).$$ Since the function $ \text {ali} (x) $ is not yet defined, we study $ (1.2) $ as $$I^{-}\big(f^{-}(\text{li} x)\big)\geq \text{li} x; \ \ \ \ I^{+}\big(f^{+}(\text{li} x)\big)\le \text{li} x \tag{1.3}$$ The inequalities $ (1.3) $ concern real analytic functions therefore it is easy to establish that $$ \lim_{x \to \infty} \text{sgn} [I^{-}\big(f^{-}(\text{li} x)\big)- \text{li} x]=1 $$ $$ \lim_{x \to \infty} \text{sgn} [I^{+}\big(f^{+}(\text{li} x)\big)- \text{li} x]=-1 $$ By means of numerical calculation it is possible to state the following theorem Let $ p (n) $ be the n-th prime number and $  \text{ali} (n) $ the inverse function of the logarithmic integral $ \text {li} (n) $ , for any natural number $ n \geq 484 $ we have: $$ |p(n)-\text{ali}(n)|\le \frac{1}{8 \pi} \sqrt{n \ln n} \ln\big(n\ln n \big) \frac{\text{ali}(n)}{\text{li}(n \ln n)}\tag{1.4}$$ For $ n \geq 484 $ we have $\frac{1}{8 \pi} \sqrt{n \ln n} \ln\big(n\ln n \big) \frac{\text{ali}(n)}{\text{li}(n \ln n)} < \frac{1}{5 \pi} \sqrt{n}\ln(n)^{\frac{5}{2}}$ $$ |p(n)-\text{ali}(n)|< \frac{1}{5 \pi}\sqrt{n} \ln(n)^{\frac{5}{2}}\tag{1.5}$$ There is a rather similar one in https://arxiv.org/pdf/1203.5413.pdf (Theorem 6.2).
The expression (1.4) in my attempt is more tight than theorem 6.2 especially for small $n$ . at infinity they are both $O(\sqrt{n}\ln(n)^{5/2})$ . the expression (1.5) it's even more explicit about the equivalence/tightness with Theorem 6.2. Note that $ 484 \ln 484 \approx 2657 $ lower bound of theorem (1.0). In fact, the arbitrary choice of $ f ^ + $ and $ f ^ - $ was made to show a certain symmetry between (1.0) and theorem (1.4) which allows us to write a single bound for $p(n)-\text{ali}(n)$ and $\pi(n)-\text{li}(n)$ : for $n\geq 465$ : $$ \Bigg|\frac{p(n)}{\text{ali}(n)}-1\Bigg|\sim \Bigg|\frac{\pi(n \ln n)}{\text{li}(n \ln n)} -1\Bigg|<\sqrt{\frac{\ln^3 n}{n \pi^5 }}\tag{1.6}$$","['number-theory', 'inverse-function', 'prime-numbers', 'riemann-hypothesis']"
4175527,Can $\sum_{k=1}^n \arctan(\cot(\frac{\pi n}{k}))$ be simplified?,"I found this relation about the floor function on some forum: $$⌊x⌋ = x -\frac{1}{2}+\frac{\arctan(\cot(\pi x))}{\pi}$$ I found it intriguing as this could be used in relating several non - continuous expressions with trigonometric ones. Hence, I tried to use it for an expression of the divisor function (i. e. $d(n)$ ) which just gives how many divisors the argument has. Now I find myself stuck, as apparently to progress further I need to find the partial sum of the following: $$\sum_{k=1}^n \arctan(\cot(\frac{\pi n}{k}))$$ I felt like I couldn't do it by myself so asked you guys. I'm not sure whether there is a neat solution for my problem or not but would be glad if you gave any insights or feedback.","['divisor-counting-function', 'trigonometry', 'summation']"
4175535,Show that this sequence is positive with probability approaching one,"Let $(X_n)$ be a sequence of square integrable real random variables on a probability space $(\Omega,\mathcal F,P)$ . Suppose that $$E[X_n\mid \mathcal A]\to 1_A \quad P\text{-a.s.}$$ $$V[X_n\mid \mathcal A]\to 0 \quad P\text{-a.s.}$$ as $n\to \infty$ , where $\mathcal A\subset \mathcal F$ is a sub $\sigma$ -algebra, and $A\in\mathcal A$ has positive $P$ -measure. Can I show then that $$P[X_n\geq 0]\to 1 \quad \text{as } n\to\infty \quad?$$ Any help is very appreciated.","['measure-theory', 'conditional-probability', 'conditional-expectation', 'probability-theory', 'probability']"
4175558,Finding the range of $a$ for which line $y=2x+a$ lies between circles $(x-1)^2+(y-1)^2=1$ and $(x-8)^2+(y-1)^2=4$ without intersecting either,"Find the range of parameter $a$ for which the variable line $y = 2x + a$ lies between the circles $(x-1)^2+(y-1)^2=1$ and $(x-8)^2+(y-1)^2=4$ without intersecting or touching either circle. Now, how I solved it was realising the line has a positive slope of $+2$ , and thus if it's a tangent to circle #1 then its intercept should be negative. And so, using the condition of tangency, $$a^2= m^2(r_1)^2+(r_1)^2= 4+1 $$ And thus, as $a$ can only be negative (otherwise a positive value of $a$ will make the line intersect the circle). Thus, making the lower bound of $a> - \sqrt 5$ . Similarly for the bigger circle $a<-\sqrt{20}=-\sqrt{(2^2)(2^2)+(2^2)}$ Hence I find that the solution should be $(-\sqrt5,-\sqrt{20})$ , but the actual solution is $\left(2\sqrt 5-15,-\sqrt 5-1\right)$ .","['euclidean-geometry', 'circles', 'geometry']"
4175640,Can a subgroup of the symmetric group $\mathfrak S_k$ be an elementary substructure?,"Let $\mathfrak A \subset \mathfrak B$ be two $\mathcal L$ -structures over the language $\mathcal L$ . $\mathfrak A$ is an elemetary substructure of $\mathfrak B$ if for all $\mathcal L$ -formulas and all assignments $\alpha: \mathcal V \to A$ we have $\mathfrak A \vDash \varphi[\alpha] \iff \mathfrak B \vDash \varphi[\alpha]$ , where $\mathcal V$ is the set of variables of $\mathcal L$ , $A\subset B$ are the constants sets of the two structures $\mathfrak A$ and $\mathfrak B$ . My question is about the symmetric group $\mathfrak S_k$ of premutations $\sigma: K \to K$ , where $K= \{1,...,k\} \subset \mathbb N$ . My idea is that any nontrivial subgroup $\mathfrak S'_r \subset \mathfrak S_k$ (which is a substructure) is not elementary, where $r<k$ . Because the formula $\varphi(x_1,\cdots,x_r) \equiv \forall v (v = x_1 \lor \cdots \lor v = x_r)$ which is valid in $\mathfrak A$ under any assignement $\alpha: \mathcal V \to A$ is not valid in $\mathfrak B$ . It seems that no substructure can be an elementary substructure because of the that formula. What is wrong ?","['predicate-logic', 'model-theory', 'logic', 'symmetric-groups', 'group-theory']"
4175667,Continuous function $f$ from Euclidean topology to discrete topology is constant.,"let the standard metric $d(x,y)=|y-x|$ and $\rho_{disc}$ be the discrete metric defined by $${\displaystyle \rho_{disc} (x,y)={\begin{cases}1&{\mbox{if}}\ x\neq y,\\0&{\mbox{if}}\ x=y\end{cases}}}$$ Let $V=(\mathbb{R}, \rho_{disc}$ ) and $W=(\mathbb{R},d)$ be two metric spaces (that has $\mathbb{R}$ as underlying sets, but given by two different metrices as written). Show that a function $f:W\rightarrow V$ is continuous if and only if  it is constant using the supremum property (directly/indirectly) So far Have tried for a lot of time now but I just do not see why I have to use the supremum property and how. It makes absolutely no sense to me.
The only thing that seems straight forward to me is that if $f$ is constant (but I do not even use  the supremum property here obviously) then it is continuous. The other implication does make sense to me using the supremum property.","['continuity', 'metric-spaces', 'analysis', 'real-analysis']"
4175682,Distance between two points in two different planes given the dihedral angle,"We have four points: $p_1, p_2, p_3$ and $p_4$ . The goal is to compute the distance between $p_1$ and $p_4$ . What we know: The distances between $p1$ and $p2$ ( $a$ ) , $p2$ and $p3$ ( $b$ ), $p3$ and $p4$ ( $c$ ) The angles $\alpha$ and $\beta$ between ( $p1$ , $p2$ , $p3$ ) and ( $p2$ , $p3$ , $p4$ ) respectively The dihedral (torsion) angle $\phi$ between the two planes of $p1$ and $p4$ We do not have any coordinates of any of these points. How do we use this information to compute the distance between $p1$ and $p4$ ? I tried doing something like projecting $p1$ onto the plane of $p4$ , but I ended up needing information that I do not have access to.","['trigonometry', '3d']"
4175691,Family of pairwise distinct elements,"Given a family $(x_i)_{i\in I}$ of (not necessarily pairwise distinct) elements, is it always possible to choose a subset $J\subset I$ such that $$ \{x_i: i\in I\} = \{x_j: j \in J\} $$ and such that the elements $x_j$ with $j\in J$ are pairwise distinct? Do we need the axiom of choice? Sorry if this should be obvious.","['elementary-set-theory', 'axiom-of-choice', 'logic']"
4175794,Does $HK = H'K$ imply $H \cong H'$ in this context?,"Let $G$ be a group and $p\in\mathbb{N}$ . Suppose there exists $g\in G$ of infinite order ( i.e. $\langle g\rangle :\!= \{g^n:n\in\mathbb{Z}\}$ is infinite) which commutes with all elements of $G$ . I will say that a normal subgroup $H \trianglelefteq G$ is a $p$ -complement of $g$ if $\langle g\rangle H :\!= \{g^nh: h\in H, n\in \mathbb{Z}\} = G$ , $\langle g\rangle \cap H = \langle g^p\rangle$ and $H/\langle g^n\rangle$ is finite. My question is: are any two $p$ -complements of $g$ isomorphic? My intuition says that they should be isomorphic. Indeed, if $H,H'$ are $p$ -complements of $g$ , then from the isomorphisms theorems we have $H/\langle g^n\rangle \cong G/\langle g\rangle \cong H'/\langle g^n\rangle$ .
Moreover, the theorem below gives an affirmative answer in a similar context. Theorem. Let $K$ be a finite group. Suppose that $K = LM = LM'$ , where $L,M,M'$ are normal groups in $G$ satisfying $L\cap M = L\cap M' = \{1\}$ . Then, $L\cong L'$ . Any comment is appreciated.","['group-theory', 'abstract-algebra', 'finite-groups']"
4175803,How to solve this limits question using the properties of modulus and exponents?,"Let $f(x)=|x|^{p-2}\sin(\frac{1}{x})+x|\tan x|^{q-3} ,x\neq0$ is differentiable at $x=0$ , given $f(0)=0$ , then what can be the values of $p$ and $q$ ? My attempt: As $x$ approaches $0$ , the $\sin(\frac{1}{x})$ term approaches infinity and so for the limit to be zero $x$ has to be zero. But here I can't understand the inter-relation between value of $p$ and $x$ . If I put the value of $p=3$ and $q=3$ , the overall limit becomes $0$ , but according to the solution given, $p>3$ and $q\ge3$ . But I can't understand how this ranges came. Even tried writing taylor series of sin( $\frac{1}{x}$ ), but that also didn't help. Can anyone please explain the underlying concept in this and how can we solve this question?","['limits', 'limits-without-lhopital']"
4175814,Hardy's Inequality: Problems $3.14$ and $3.15$ in Rudin's RCA,"In Problem $3.14$ , we prove (a) Hardy's inequality, (b) the condition for equality, and I shall talk about (c), (d) below. Problem $3.15$ is the discrete case of Hardy's inequality. I have asked three related questions in a single post itself, since all of them are related to Hardy's inequality , and none should be too involved. There are some existing posts on MSE related to these topics, so I shall link them right away and point out that my question is not a duplicate: Post 1 , Post 2 , Post 3 , Post 4 . For the sake of mentioning it, Hardy's inequality is: For $p\in (1,\infty)$ , $f\in L^p((0,\infty))$ relative to the Lebesgue measure, and $$F(x) = \frac{1}{x}\int_0^x f(t)\ dt\quad (0 < x < \infty)$$ we have $$\|F\|_p \le \frac{p}{p-1} \|f\|_p$$ Question 1: This is Problem $3.14(c)$ in Rudin's book. Prove that the constant $p/(p-1)$ cannot be replaced by a smaller one. In one of the linked posts, there is some discussion on how this is the best constant, but I was unable to follow it. My sense is that it suffices to find a counterexample, i.e. for every constant $\beta$ smaller than $p/(p-1)$ , we need a function $f_\beta\in L^p((0,\infty))$ which does not satisfy the required inequality. Why are we complicating things? If I'm thinking right, could someone help me find a counterexample ? Question 2: This appears as Problem $3.14(d)$ of Rudin's book. The author is trying to emphasize that the inequality is not for $p = 1$ . If $f > 0$ and $f\in L^1$ , prove that $F\notin L^1$ . I found an example, $f(x) = e^{-x}$ . Then $F(x) = \frac{1-e^{-x}}{x}$ . $F$ 's integral diverges, since the integral of $1/x$ diverges (use limit comparison test for integrals). However, as @David C. Ullrich pointed out, this is not enough. Question 3: This is Problem $3.15$ in the same book and is the discrete case of Hardy's inequality. Suppose $\{a_n\}$ is a sequence of positive numbers. Prove that $$\sum_{N=1}^\infty \left(\frac{1}{N} \sum_{n=1}^N a_n \right)^p \le \left(\frac{p}{p-1} \right)^p \sum_{n=1}^\infty a_n^p$$ if $1 < p < \infty$ . If $a_n\ge a_{n+1}$ , the result can be made to follow from Hardy's inequality. This special case implies the general one. I took $f = \sum_{n=1}^\infty a_n \mathbf{1}_{[n,n+1]}$ . Then $f\in L^p$ only if $\sum_{n=1}^\infty a^p_n < \infty$ . If $f\notin L^p$ , the inequality is trivial. So let's take $f\in L^p$ . Now using Hardy's inequality, we have $\|F\|_p \le \frac{p}{p-1} \|f\|_p$ . What is $F$ ? $$F(x) = \frac{1}{x}\int_0^x \sum_{n=1}^\infty a_n\mathbf{1}_{[n,n+1]}(t)\ dt = \frac{1}{x}\left(\sum_{n=1}^{\lfloor x\rfloor} a_n + (x - \lfloor x\rfloor)a_{\lfloor x\rfloor + 1} \right)$$ How do I proceed? P.S. I have already solved Problems $3.14(a)$ and $3.14(b)$ , i.e. proving Hardy's inequality and showing that equality holds iff $f = 0$ a.e.","['inequality', 'lp-spaces', 'functional-analysis', 'real-analysis']"
4175843,"Find the number of solutions for the equation $ 3x+2y + 3z = n $ where $ x,y,z \in \Bbb N$ and $n \equiv 1 \mod(6) $.","Problem : Find the number of solutions for the equation $ 3x+2y + 3z = n $ where $ x,y,z \in \Bbb N$ and $n \equiv 1 \mod(6) $ . Note: I'm supposed to use generating functions. Also, I found questions about the above equation but none of them talk about the modulo. Attempt : Notice that $ 3x \in \{ 3n | n \in \Bbb N \} , 3z \in \{ 3n | n \in \Bbb N \}, 2y \in \Bbb N_{even} $ . Denote $ t_1 \ = 3x , t_2 = 3z , t_3 = 2y $ . So we'll search for generating functions that correspond to the equation $ t_1 + t_2 +t_3 = n $ , hence we'll have $ ( x^0+ x^3 + x^6 + ...)( x^0+ x^3 + x^6 + ...)( x^0+ x^2 + x^4 + ...) = (\sum (x^3)^k)(\sum (x^3)^k)(\sum (x^2)^k) = \frac{1}{(1-x^3)^2} \frac{1}{1-x^2} $ [ Here I've stopped ]. Then I need to do partial fractions decomposition but the result is terribly long - I'm not sure if I need to even do the decomposition ( maybe there's a shorter way to reach the coefficient $ n $ ? moreover I'm not really sure what coefficient $ n $ they mean, are they seeking a specific $ n $ s.t. $ n ~mod~ 6 = 1 $ ? because If not there are infinitely many such n's. In any case, how would you solve the problem?. Thanks in advance!","['combinatorics', 'discrete-mathematics', 'generating-functions']"
4175861,Clarify on Birkhoff's theorem (in universal algebra),"In class we said that, as a consequence of Birkhoff's theorem, the theory of  fields  is not axiomatizable only by equations. In particular,  we saw  that the product of two fields in  general is just a ring. However I don't understand why if we use a language with $(+,\cdot,-,\frac {1}{}, 1,0)$ , where $+$ and $\cdot$ are the binary operations of sum and product, $-$ and $\frac 1 {} $ are the unary operations that give the inverses,  and $1,0$ are the  two usual constants. It seems to me that in this language the theory of  fields is axiomatizable adding to the axioms of a ring (that are all equations) the axiom $\frac 1  x \cdot x=1$ , that is an equation too. Probably I'm missing some hypothesis on the language in the Birkhoff's theorem, but I don't  see any of them.  Thaks for any clarify","['universal-algebra', 'model-theory', 'abstract-algebra', 'logic']"
