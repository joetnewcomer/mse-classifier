question_id,title,body,tags
266718,Quotient Group G/G = {identity}?,"I know this is a basic question, but I'm trying to convince myself of Wikipedia's statement. ""The quotient group $G / G$ is isomorphic to the trivial group."" I write the definition for left multiplication because left cosets = right cosets. $ G/G = \{g \in G : gG\} $ But how is this isomorphic to the trivial group, $ \{id_G\} $? $gG$ can't be simplified to $id_G$ ? Thank you.",['group-theory']
266744,This quotient space is homeomorphic to the Möbius strip?,"Let $G:\mathbb R \times [-1,1]\to \mathbb R \times [-1,1]$ be a map defined by $G(x,y)=(x+1,-y)$ This space $Q=\mathbb R\times [-1,1]/\sim$, where $(x_1,y_1)\sim (x_2,y_2)$ if and only if there is $n\in \mathbb Z$ such that $G^n(x_1,y_1)=(x_2,y_2)$ is homeomorphic to the Möbius strip? I'm trying to see this intuitively without success. Anyone has an idea why these spaces are ""equal""? Thanks EDIT Following the commentaries, The only map I can imagine from the Möbius strip is the one which send a point $(x,y)$ in the Möbius strip onto $(x,y)$ in $Q$. See the picture below:","['general-topology', 'intuition', 'algebraic-topology', 'visualization']"
266752,Number of elements of given order in a group,"Example 1: ""Calculate the number of elements of order 2 in the group $C_{20} \times C_{30}$"" To do this, I split the groups into their primary decompositions and got that the groups with elements of order 2 are $C_4$ and $C_2$. From here, to then work out the number of elements of order 2 I did: $\varphi(4) = 2$,
$\varphi(2) = 1$ So number of elements of order 2 will be $(2 + 1)^2 - 1 = 3$, which was the correct answer. However Example 2: ""Compute the number of elements of order 35 of the group $\mathrm{Aut}(C_{6125})$"" To do this, I can just check that 35 divides 6125 and then use the Euler totient function. Why do I not have to split 6125 into its primary decomposition and then use that little formula to work out the number of elements? Is it because this is a cyclic group and so I can just use the Euler function, however as the other one is a direct product, I need to use a different method?","['finite-groups', 'group-theory', 'abstract-algebra']"
266761,Grothendieck 's question - any update?,"I was reading Barry Mazur's biography and come across this part: Grothendieck was exceptionally patient with me, for when we first met I knew next to nothing about algebra. In one of his first conversations with me, he raised the question (asked of him by Washnitzer) of whether a smooth proper algebraic variety defined over a real quadratic field could yield topologically different differentiable manifolds realized by the two possible imbeddings of the number field into the reals. What a perfect question, at least for me! Not that I answered it. But it was surely one of the very few algebro-geometric questions that I then had the background to appreciate. ... the question provided quite an incentive for a topologist to look at algebraic geometry. I began to learn the elements of algebraic geometry working with Mike Artin. Is the problem still open? I am an algebraic topology student so it feels very surprising someone will come up with a question like this. But I am at a loss how to experimentally find some toy examples one can work by hand.","['algebraic-geometry', 'geometric-topology']"
266762,Multiplication operator and trace class,"Suppose we work in $H=l^2(\Bbb{N})$ and suppose the multiplication operator $T_f$ such that $T_f\psi=f\psi$ and $f:\Bbb{N}\rightarrow \Bbb{C}$. We denote by $B_1(H)$ the trace class of operators. Question: I want to find a sufficient and necessary condition for $f$, such that $T_f\in B_1(H)$. Can someone help me with this question? (This a question from a exam for Introduction to Functional analysis.)","['operator-theory', 'hilbert-spaces', 'functional-analysis', 'lp-spaces']"
266776,Dense subset of $C(X)$,"I am trying to prove the next proposition, but i need some help: Let $ (X,\rho)$ be compact metric space. Prove that there exist a compact subset $K$ of $C(X)$ whose linear span is dense in $C(X)$ Thanks.","['general-topology', 'functional-analysis']"
266783,Geometric argument as to why the cyclic quadrilateral has the maximal area,"I am looking for a purely geometric/intuitive argument as to why the cyclic quadrilateral has the maximal area among all quadrilaterals having the same side lengths. I am aware of couple of proofs, which resort to some sort of algebra/ calculus/ trigonometric argument. For instance, the Bretschneider's formula , gives the area of a quadrilateral as $$\sqrt{(s-a)(s-b)(s-c)(s-d) - abcd \cos^2(\theta/2)}$$ where $\theta$ is the sum of a pair of opposite angles of the quadrilateral. Hence, given $a,b,c,d$, the maximum is attained when $\theta = \pi$, which allows us to conclude that the quadrilateral has to be cyclic. Another very similar argument, using calculus and trigonometry, is mentioned in this article . However, I am not able to intuitively understand why among all quadrilateral with given sides $a,b,c,d$ the cyclic quadrilateral is the one that maximizes the area. I believe a geometric argument would provide me a good intuition in understand this non-trivial fact.","['geometry', 'circles']"
266792,Does the Least Squares Regression Method work for any line type?,"I recently learned how to apply the least squares method to do linear regression. I also understand that it can be used for quadratic regression, by minimizing the error for three variables, two coefficients and a constant, instead of two variables. Would the same method apply to most, or all, types of equations? Could I simply assume coefficients wherever possible, and a constant, then find the partial derivative with respect to each, then set them equal to zero and solve? For example, could I regress to *a*log(*b*x)+ c ? Could I use logarithms, sine waves, exponential function, etc? If not, what are the exceptions? Where is this method not possible? Why? Thanks in advance for all responses.","['statistics', 'regression', 'calculus']"
266794,How do I read this question? (subject: bijections),"Introduction In Basic Algebra I , I am struggling with fully understanding the following exercise: Show that $S\overset{\alpha}{\to}T$ is injective if and only if there is a map $T\overset{\beta}{\to}S$ such that $\beta\alpha=1_S$, surjective if and only if there is a map $T\overset{\beta}{\to}S$ such that $\alpha\beta=1_T$. In both cases, investigate the assertion: if $\beta$ is unique then $\alpha$ is bijective. My Problem I am struggling only with the bold portion. (I have written proofs by contradiction for the other aspects of the question.) What confuses me specifically is this: What is this question really asking? Is it saying, ""What happens when $\beta$ is unique when both $\beta\alpha=1_S$ and $\alpha\beta=1_T$?"" or is it saying, ""What happens when $\beta$ is unique and either $\beta\alpha=1_S$ or $\alpha\beta=1_T$ is true?"" Remarks As you can see, my real problem here is understanding precisely what is being asked. If it is asking, the first (both $\alpha\beta=1_T$ and $\beta\alpha=1_S$ are true), then we're simply constructing the very definition of a bijection. If it's asking the latter, I don't know what's going on . . . Are we somehow still constructing a bijection? Can you all give me help on reading questions such as this?","['elementary-set-theory', 'functions']"
266800,Convergence of a sequence,"Problem statement: Determine the limit of the following sequence: $\sqrt{a},\sqrt{1+\sqrt{a}}, \sqrt{1+\sqrt{1+\sqrt{a}}},... $ My progress: Let´s begin by introducing some notation. Let $a_{n}$ denote the nth term of the sequence. We have $a_{1}=\sqrt{a}$ and $a_{n}=\sqrt{1+a_{n-1}}$. My instinct tells me now to rewrite as $a_{n}^2-a_{n-1}-1=0$ which has a root $\frac{1+\sqrt{5}}{2}$ (neglect the negative root for obvious reasons). However: My friend told me this is only an eventually value of the sequence and not necessarily. I have to determine that this sequence converges before i can conclude this. How can I do this? And what does it actually mean when I solve the quadratic(because that is only an instinct of mine)?",['sequences-and-series']
266818,Base (topology) with closed intervals,"I am curious why it's a problem to define a base using closed sets? For example, my book uses the definition under ""Constructing Topologies from Bases"" as specified at http://en.wikibooks.org/wiki/Topology/Bases , as opposed to the ""definition"" listed on this page.  I don't see why closed intervals are a problem for example, the point ${1} \in [0,1], [1,2]$ so in particular $ {1}  \in [0,1]\cap[1,2]=[1,1]=\{1\}$ I realize that topologies consist of ""open sets"" but why can't closed sets be a base for (larger) open sets for a topology.... or more generaly, why can't topologies be constructed using closed sets.","['general-topology', 'definition']"
266832,"X and Y coordinates of circle giving a center, radius and angle","I have to find the necessary translations in X and Y to move a point 0n a circle to another one. I have a center (X and Y coordinates), a radius, and a current position in radians. And given a value in radians (the amount I want to translate), I have to find the amount of values in X and Y I have to move to get to that position. So, for example, if default values are (2, 3) for the center, the radius is 3 and the starting radian position is 0. The starting point will be (5, 3) and I if I want to move the position 0.2 radians, I want to know how many units of X and Y I have to make to go to that position. This is a simple drawing of what I want to do. Also, check out which one is the 0 radian starting position (rightmost part)","['trigonometry', 'circles', 'functions']"
266833,How to maximize this integral?,"Rudin asked me to maximize $$\int^{1}_{-1}x^{3}g(x)dx$$ under the restraint that $$\int^{1}_{-1}g(x)=\int^{1}_{-1}xg(x)dx=\int^{1}_{-1}x^{2}g(x)dx=0$$ This is clearly a Hilbert space problem need to use orthogonal relations. I computed $x^{3}$'s coefficients under the $L^{2}$ inner product and it turns out $x^{3}=\frac{3}{5}x^{2}+c$, with $c$ being orthogonal to $\{1,x,x^{2}\}$. But how does this help to find $g$? A related question I also do not know how to solve is to find the minimum of $$\int^{\infty}_{0}|x^{3}-a-bx-cx^{2}|^{2}e^{-x}dx$$And it is not clear to me what the linearly independent underlying set is - $\{1,x,x^{2},e^{-x/2}\}$?",['real-analysis']
266863,The law of absolute value of a standard Brownian motion,"How can we easily compute $\mathbb{E} [ \left|W_t\right|]$, where $W = (W_t)_{t \geq 0}$ is the one dimensional standard Brownian motion (or wiener process)?","['probability-theory', 'stochastic-processes', 'probability']"
266869,Combinatorial Proofs of Real Analysis Identity,"In this question , a proof using real analysis is given of the following identity: $$ \sum_{n=1}^{\infty} \frac{(n-1)!}{n \prod_{i=1}^{n} (a+i)} = \sum_{k=1}^{\infty} \frac{1}{(a+k)^2}$$ Is there a combinatorial proof of this identity? Is so, does the proof require that $a$ be a natural number? Also is there an easy way to verify if combinatorial proofs exist of particular identities?","['partial-fractions', 'sequences-and-series', 'real-analysis', 'combinatorics']"
266870,weak law of large numbers: proof using characteristic functions vs proof using truncation,"In Varadhan's lecture notes on Probability Theory (they are online here and on Amazon here ) in Exercise 3.6 he writes: The weak law may hold sometimes, even if the mean does not exist. If we dampen the tails of the Cauchy ever so slightly with a density $f(x) = \frac{c}{(1+x^2)\log(1+x^2)}$, show that the weak law of large numbers holds. I get that the characteristic function here is differentiable at 0, hence we can get $\phi(\frac{t}{n})$ through the Taylor expansion. Since the characteristic function $\psi_n(t)$ of $\frac{S_n}{n}$ is given by $\phi_n(t) = [\psi(\frac{t}{n})]^n$, following the rest of the proof using characteristic functions in Varadhan's lecture notes shows us that $\frac{S_n}{n}$ converges in probability to $0$. What I'm not sure about is how this translates to a truncation argument. I think my understanding of the various components of the truncation argument as they relate to properties of characteristic functions is very poor. Can someone elaborate as to the links between the two different proofs? What does it mean for a characteristic function to be differentiable at 0 in terms of what we can and cannot truncate? As a followup, is it true then that if a characteristic function for the distribution of a random variable is differentiable at 0, then the weak law of large numbers holds? Or are there also other conditions that need to hold? P.S. As a side question, is there a clean form (i.e. one without integrands) of the characteristic function for a r.v. with density $f(x) = \frac{c}{(1+x^2)\log(1+x^2)}$? I don't know any complex analysis, so the derivation of the characteristic function of the Cauchy distribution with density $\frac{1}{\pi(1+x^2)}$, $\phi(t) = e^{-|t|}$ flew over my head. I just want to know if the characteristic function for the density above could be derived through something like complex analysis as well, and if it would be in my interests to get a foundation in complex analysis for basic graduate probability theory.","['probability-theory', 'law-of-large-numbers']"
266871,Calculating prime sequences,"Let $\omega(k)$ be the prime omega function, it counts how many distinct prime factors k has. The dirichlet series for  $\omega(k)$ can be written as,$$\sum_{k=1}^\infty\frac{\omega(k)}{k^s}=\prod_{p}\frac{1}{1-p^{-s}}*\sum_{p}\frac{1}{p^s}=\zeta(s)*P(s)$$
I know I cant re-write $$\sum_{k=0}^\infty\frac{\omega(ak+b)}{(ak+b)^s}=\prod_{p\equiv\text{b  mod a} }\frac{1}{1-p^{-s}}*\sum_{p\equiv\text{b mod a}}\frac{1}{p^s}$$
But can I re-write it, as somthing similar?",['sequences-and-series']
266873,Derivation of $e$,"It's well-known that $$e = \lim_{n\rightarrow \infty} (1+1/n)^n$$ as defined by Bernoulli when considering infinitely-compounded interest.  I believe this is the earliest definition of $e$. But if we were in (say) the 17th century (before differentiation), how would we know that the limit exists and how could we calculate the value to arbitrarily many decimal places?  Equivalently, how can we prove that $$ e = \sum_{n=0} 1/n!$$ without using $\frac{d}{dx}e^x = e^x$?  (If we can prove $\lim_{h\rightarrow 0} \frac{e^h-1}{h} = 1$, that gives the derivative of $e^x$ and I'm fine with that approach too.)","['exponential-function', 'limits']"
266885,Inverse Laplace transform of $\frac{\log(s)}{1 + s}$,"Is it possible to find the inverse laplace transform $$\mathcal{L}^{-1}\frac{\log(s)}{1 + s}$$ using the Bromwich integral formula $$\mathcal{L}^{-1} \{F(s)\}(t) = f(t) = \frac{1}{2\pi i}\lim_{T\to\infty}\int_{\gamma-iT}^{\gamma+iT}e^{st}F(s)\,ds$$  I'm having trouble coming up with a suitable contour to use.  If the denominator were $1 - s$, then the pole would be in the right hand plane and the residue theorem would reduce the integral to the sum of the residues plus the integral around the branch cut.  But with this one, the pole is in the left hand plane where the branch cut should be.  Instead of setting $\gamma = 1$ as it must be in the case where the denominator is $1 - s$, can I set $\gamma = 0$, run the contour down the real axis and detour around the origin? I'm not sure if this is allowed, or will work.  Thanks for any advice.","['laplace-transform', 'complex-analysis', 'contour-integration']"
266888,On the structure of maximal parobolic subgroups of orthogonal groups over finite fields,"Let $q=p^f$ be an odd prime power and $P$ be a maximal parobolic subgroup of $GO^\varepsilon(n,q)$ stabilising a totally singular $k$-subspace. It is known that $P$ has shape $A{:}(B\times C)$, where $A$ is a special $p$-group of order $q^{k(k-1)/2+k(n-2k)}$ with center of order $q^{k(k-1)/2}$, $B=GL(k,q)$ and $C=GO^\varepsilon(n-2k,q)$. Then what is the conjugation action of $B$ and $C$ on $A$?","['finite-groups', 'group-theory']"
266890,An exercise about finite intersection property in $T_1$ space,"Let $X$ be a $T_1$ space. Let $\mathfrak {D}$ be a collection of subsets of $X$  that is maximal with respect to the finite intersection property. Show that there is at most one point belonging to $\bigcap_{D \in \mathfrak{D}} \bar D$ Here's my attempt. Suppose there're two points $x$, $y$ both belonging to $\bigcap_{D \in \mathfrak{D}} \bar D$. By $T_1$ axiom, there is one open set $A$, such that $x \in A$, while $y \notin A$. The maximality of $\mathfrak D$ implies every neighborhood of $x$ and $y$ belongs to $\mathfrak D$, and so is $A$. Thus every neighborhood of $y$ intersects with $A$, which shows that $y\in \bar A$. I don't know how to proceed. EDIT :This is an excercise from James Munkres' textbook Topology (2ed), page 235. However, I can't find a problem in K.Gosh's answer. Maybe something is wrong in this problem, or my paraphrasing of it.",['general-topology']
266892,local convexity of $L_p$ spaces,"wiki says The spaces $L_p([0, 1])$ for $0 < p < 1$ are equipped with the F-norm 
they are not locally convex, since the only convex neighborhood of zero is the whole space
Why is this so? http://en.wikipedia.org/wiki/Lp_space","['operator-theory', 'topological-vector-spaces', 'functional-analysis']"
266897,Structure of the group of arithmetic functions,"This question was originally posted in Elements of finite order in the group of arithmetic functions under Dirichlet convolution. and it goes as follows: Let G be the group consisting of all arithmetic functions (i.e. functions $f:\mathbb{N} \to \mathbb{C}$) under the ""convolution""operation  $\ast,$  defined as $$(f\ast g)(n):=\sum_{ab=n}f(a)g(b), n \in \mathbb{N}.$$
(Note that each function in the group assigns the value $1$ to $1.$) Alexander Gruber showed in the aforementioned post that G is a torsion-free abelian group. A few further facts can be easily proved: (1) G is not finitely generated and in particular is infinite. (2)If one lets H to denote the subgroup of G consisted of multiplicative functions, then $|G:H|=\infty.$ However my question is: What is known in the literature about the group structure of G ?","['abelian-groups', 'number-theory', 'abstract-algebra', 'analytic-number-theory', 'group-theory']"
266899,Why the Riemann hypothesis doesn't imply Goldbach?,"I'm interested in number theory, and everyone seems to be saying that ""It's all about the Riemann hypothesis (RH)"". I started to agree with this, but my question is: Why then doesn't RH imply the (asymptotic) Goldbach conjecture? By ""asymptotic"" here I mean that any $n\in\mathbb N$ big enough can be written as $p+q$, with $p,q$ primes. I already asked some experts, and they told me that ""RH is rather about the distribution of primes"". But look at this table, (number of ways to write an even number n as the sum of two primes, 4 ≤ n ≤ 1,000,000) isn't that saying that the asymptotic Goldbach conjecture is also about the distribution of primes? I don't understand. Any help would be very welcome.","['prime-numbers', 'analytic-number-theory', 'number-theory']"
266902,Integral of the positive part of a Brownian motion,"Let $X(t)$ be the standard Brownian motion, I need to find the distribution of $S=\int_{0}^T(X(t))^+dt$, where $(x)^+=\max\{0,x\}$. I want to use the distribution to get a concentration bound for $S$. So even if we can't find the distribution, still, bounding the variance of $S$ helps a lot. For example, if I can bound the variance by, say $T^3$, then I can use Chebyshev's inequality to get a good concentration bound: 
\begin{align*}
\Pr\{|S-E[S]|>k T^{3/2}\} < \frac{1}{k^2}
\end{align*} Any results on the same problem with $S=\int_{0}^T|X(t)|dt$ is also very much appreciated. Thank you!","['probability-theory', 'stochastic-processes', 'brownian-motion']"
266914,Compactness theorem and Tychonoff theorem,"This thread has it compactness theorem can be derived from Tychonoff theorem. I'm interested in how this can be done, but got stuck. Here's how far I understand: Following the version of campactness theorem in A Mathematical Introduction to Logic , Herbert B. Enderton（2ed): A set of wffs (well-formed formula) is satisfiable iff every finite
  subset is satisfiable. Let $\Sigma$ be a set of wffs, each of which is generated by a set of sentence $A$ whose elements can be indexed by $I$. Then the truth value of each finite subset $\Sigma_{\alpha}$ is determined by the truth assignment of $A$, which can be expressed as a function in the space $\{T, F\}^I$. For each finite subset $\Sigma_{\alpha}$, there is a non-empty subset $J_{\alpha}$ of $\{T, F\}^I$ which makes  $\Sigma_{\alpha}$ true. Suppose all finite subsets of $\Sigma$ can be indexed by $B$, then the compactness theorem says $\bigcap_{\alpha \in B}J_{\alpha} \neq \varnothing$ I got stuck on how to define the topology of $\{T, F\}^I$. It seems to me, since $\Sigma_{\alpha}$ is a finite set of wffs, its truth value should only depend on the truth values of a finite number of sentences in $A$. Supposedly, Tychonoff Theorem could serve as a hint, but I don't know how to proceed.","['general-topology', 'logic', 'compactness']"
266917,Teaching probability by using a deck of cards,"I plan to teach two sessions of probability to 11th grade students using a deck of cards. My classes will be next week. I have already taught them the basic notions of writing sample spaces, computing conditional probabilities and so on. The problem is that once students get 'trained' to use conditional probability, they use it all the time and do not go back to first principles. A typical example is the question: ""What is the probability that the third card drawn from a pack of cards is a queen?"". The interesting thing is that my untrained 9th grade cousin could answer immediately when I actually used a pack of cards to ask her the question. So that motivated me to teach a couple of classes on probability with a simple apparatus like a deck of cards. Presently I have the following ideas: Let us call the question 'What is the probability that the 4th card is a queen?' as THE question. Deal 5 cards face down and ask THE question. Now flip the third card open and ask THE question. Now flip the flipped card and shuffle the 5 cards and place them in some order
face down and ask THE question. Now add two extra black suit cards (tell them the cards are from a black suit) from the deck to the array of five cards and ask THE question. Now tell them that I might have lied about the suit of exactly one of the cards in the previous round and then ask THE question. Further, I plan to do the Monty Hall puzzle and Bertrand's box problem with the pack of cards. I wanted to do a basic gambler's ruin too. But I do not know how to go about it. My question, therefore, to the community is: 1) Would you kindly suggest interesting probability questions using a deck of cards? 2) Are there interesting questions which cannot be asked using a deck of cards? If so, what simple apparatus would I need? P.S: Buffon's needle problem would have been a good suggestion, but the students cannot appreciate continuous sample spaces as of now. That is, I would like examples from discrete sample spaces. Thank you :)","['education', 'probability']"
266942,Putnam type question: Invertible matrix,"Are the following matrices invertible? (1) $A= (a_{ij})_{2003 \times 2003}$, where $a_{ii}=2003, a_{ij}=1$ for $i \not=j$. (2) $B= (b_{ij})_{n \times n }$ with $b_{ii}= \pi$ and $b_{ij} \in \mathbb{Q}$ for $i \not= j$. Thank you so much.","['matrices', 'contest-math']"
266948,Riemann zeta function and modulus,"The functional equation for the zeta function $ζ(s)$ is given by $ζ(s)=f(s)ζ(1-s)$ (a) We know that if $Re(s)=1/2$, then $|f(s)|=1$. My question is about the case where $|f(s)|=1$ outside the critical line. Is this case possible, i.e., (b) Is this implication ""if $|f(s)|=1$ then $Re(s)=1/2$"" correct?","['zeta-functions', 'complex-analysis']"
266953,A simple series of set-theoretic operations (unions and intersections),"How can I evaluate the expression $$ (A_1 \cup \ldots \cup A_n) \cap (B_1\cup \ldots \cup B_m) \cap (C_1 \cup \ldots \cup C_o) ?$$ I know that for $(A_1 \cup \ldots \cup A_n) \cap B_1$ we get $((A_1\cap B_1) \cup \ldots \cup (A_n\cap B_1))$, but don't knw how the generalize this to the above.",['elementary-set-theory']
266957,"A interesting improper integral, $ \int_{0}^1\frac{\ln x}{x^2-x-1}\text{d}x$",$$\displaystyle \int_{0}^1\frac{\ln x}{x^2-x-1}\text{d}x$$ I think there should be a smart way to evaluate this. But I cant see..,"['improper-integrals', 'calculus', 'integration']"
266963,What is the rank of the cofactor matrix of a given matrix?,"Let $A = (a_{ij}) ∈M_n(\mathbb{R})$; $n≥3$. Let $B = (b_{ij})$ be the matrix of its co-
factors, i.e. $b_{ij}$ is the cofactor of the entry $a_{ij}$ in $A$. What is the rank of $B$
when a. the rank of $A$ is $n$? b. the rank of $A$ is less than, or equal to, $n ≥ 2$? I  am completely stuck on it.how can i solve this.",['linear-algebra']
266973,Linear functional and convergent series in $\ell^\infty$,"Let $\ell^\infty$ be the Banach space of bounded sequences with the usual norm and let $c,c_0$ be the subspaces of sequences that are convergent, resp. convergent to zero. Show that: The linear functional $\ell_0\colon c\rightarrow \mathbb{C}$ defined for $x = (x_n) \in c$ by
$$ \ell_0(x) = \lim_{n\rightarrow \infty} x_n$$
extends to a continuous functional on $\ell^\infty$ if $L$ denotes the set of all continuous extensions of the functional $\ell_0$ from (1), then a sequence $x = (x_n) \in  \ell^\infty$ belongs to $c_0$ iff
$$\ell(x) = 0 \;\; \forall \ell \in L$$ Describe $c$ in a similar way
My try: (1): This follows by Banach limits. (2): $(\Rightarrow)$ follows by extension $(\Leftarrow)$ Here Im a bit unsure, assume $x \not \in c_0$ if $x \in c$ we get an contradiction. But if $x\not \in c$ what happens then, can we use a subsequence? since we have bounded functionals? can we use $\ell x = \lim_{k \rightarrow \infty} x_{n_k}$ or something like that, would $\ell \in L$? (3): same as two I suppose, can we use subseqeunces? Please correct what I'm missed","['functional-analysis', 'banach-spaces']"
266977,Show $\lim\limits_{n\to\infty} \sqrt[n]{n^e+e^n}=e$,Why is $\lim\limits_{n\to\infty} \sqrt[n]{n^e+e^n}$ = $e$? I couldn't get this result.,['limits']
266998,How to compute the determinant of a tridiagonal Toeplitz matrix?,"How to show that the determinant of the following $(n\times n)$ matrix $$\begin{pmatrix}
5 & 2 & 0 & 0 & 0 & \cdots & 0 \\
2 & 5 & 2 & 0 & 0 & \cdots & 0 \\
0 & 2 & 5 & 2 & 0 & \cdots & 0 \\
\vdots & \vdots& \vdots& \vdots & \vdots & \vdots & \vdots \\
0 & \cdots & \cdots & 0 & 2 & 5 & 2 \\
0 & \cdots & \cdots & \cdots & \cdots & 2 & 5
\end{pmatrix}$$ is equal to $\frac13(4^{n+1}-1)$? More generally: How does one compute the determinant of the following tridiagonal matrix (where the three diagonals are constant)? $$M_n(a,b,c) = \begin{pmatrix}
a & b & 0 & 0 & 0 & \cdots & 0 \\
c & a & b & 0 & 0 & \cdots & 0 \\
0 & c & a & b & 0 & \cdots & 0 \\
\vdots & \vdots& \vdots& \vdots & \vdots& \vdots & \vdots \\
0 & \cdots & \cdots & 0 & c & a & b \\
0 & \cdots & \cdots & \cdots & \cdots & c & a
\end{pmatrix}$$ Here $a,b,c$ can be taken to be real numbers, or complex numbers. In other words, the matrix $M_n(a,b,c) = (m_{ij})_{1 \le i,j \le n}$ is such that
$$m_{ij} = \begin{cases}
a & i = j, \\
b & i = j - 1, \\
c & i = j + 1, \\
0 & \text{otherwise.}
\end{cases}$$ There does not seem to be an easy pattern to use induction: the matrix is not a diagonal block matrix of the type $M = \bigl(\begin{smallmatrix} A & C \\ 0 & B \end{smallmatrix}\bigr)$ (where we could use $\det(M) = \det(A) \det(B)$ for the induction step), and there are no lines or columns with only one nonzero entry, so Laplace expansion gets complicated quickly. Is there a general pattern that one could use? Or is the answer only known on a case-by-case basis? It's possible to compute the determinant by hand for small $n$: $$\begin{align}
\det(M_1(a,b,c)) & = \begin{vmatrix} a \end{vmatrix} = a  \\
\det(M_2(a,b,c)) & = \begin{vmatrix} a & b \\ c & a \end{vmatrix} = a^2 - bc \\
\det(M_3(a,b,c)) & = \begin{vmatrix} a & b & 0 \\ c & a & b \\ 0 & c & a \end{vmatrix} = a^3 - 2abc
\end{align}$$ But there is no readily apparent pattern and the computation becomes very difficult when $n$ gets large.","['matrices', 'linear-algebra', 'faq', 'toeplitz-matrices', 'determinant']"
267013,Is it possible to replace function by its concave envelope,"Let $f(x) \in C[-1,2]$. Consider an optimization problem
$$
    J[\mu] = \int\limits_{-1}^{2}f(x) \, \mu(dx) \to \max\limits_{\mu - \text{Borel probability measure}}
$$
with restriction
$$
   \int\limits_{-1}^{2}x \, \mu(dx) = 0.
$$
Is it true that solution of this problem (maximal value of $J$) will not change if we replace $f$ by its concave envelope? If the answer is positive, what about optimal measure? Will it change, if it exists?","['optimization', 'convex-analysis', 'measure-theory']"
267021,A small geometry puzzle out of curiosity,"Out of curiosity I've been thinking about the following ""puzzle"" for a while now and maybe someone here can help. Situation We take a rectangle and start off at one of the corners. In that corner, which is $90^\circ$, we start drawing a line at $45^\circ$, splitting the corner into two equal parts and staying inside the rectangle with our line. As soon as the line hits an edge of the rectangle, we take a $90^\circ$ ""turn"" so that we stay inside the rectangle and repeat this as often as we can. Question My hypothesis is that we then eventually always end up in a (nother) corner, where our problem stops as we can't take a $90^\circ$ turn there and stay inside the rectangle. I've tried this in my head with several sizes of rectangles and it always works out, but I can't prove that it's always true for all rectangles. (also with non-integer sized rectangles, for example) If there's anybody out there wanting to spend some time thinking about this, I would really be interested to find out the solution. :) Example cases If we take squares, the proof is easy. Take a square with edges size 5 and give the bottom left corner the co-ordinate (0, 0) . We start a line and end up immediately at (5, 5) . If we take a rectangle size 6 (x-axis) by 5 (y-axis), our line ""bounces"" at the following points: (0, 0);(5, 5); (6, 4); (2, 0); (0, 2); (3, 5); (6, 2); (4, 0); (0, 4); (1, 5); (6, 0) where (6, 0) is of course a corner point.","['geometry', 'puzzle']"
267029,Perfect Set and Compact Set,"I am having some difficulty in understanding the difference between Perfect and Compact sets. More specifically, my problem is rather understanding how Perfect sets are different from Compact sets , by that I mean, I understand Compact Sets more than Perfect Sets. I know that for any set, $S$, to be Compact, every sequence of  $S$ has a subsequence that converges to a point which also lies in $S$. This is basic definition but is not difference than saying it is Bounded and Closed or Heine Borel Theorem. Now, the definition of Perfect Set is $P$ is a Perfect Set if $P =P'$ where $P'$ is the set of Limit Points of $P$ (WolframAlpha). At other places, I also that a set is Perfect Set if $P$ is closed and accumulation point of $P$. Though, I do not understand this completely, it sounds similar to definition of Compact Sets. I would appreciate any explanation. Further, are there are any non-singleton sets that are Compact but Not Perfect ?
How about Perfect but Non Compact Sets ?","['general-topology', 'compactness', 'real-analysis', 'analysis']"
267063,Can a limit of a function that's defined only in one point exist?,The question is whether by definition there can exist a limit of a function that's defined only in one point ( or in several points but there's no interval in which the function is defined). This came up when thinking about $\lim_{x \to 0}{\sqrt{-|x|}}$,"['calculus', 'limits']"
267077,eigen value of the gradient operator,Eigen value of the following differential equation $$\nabla \phi (\vec r) = a  \vec {k} \phi(\vec{r})$$ is $$ \phi(\vec{r}) = e^{a \vec{k}.\vec{r}}$$ How can i derive this result?,"['vector-analysis', 'ordinary-differential-equations', 'eigenvalues-eigenvectors']"
267086,Weak limit and strong limit,"Let $X$ be a Banach space and let $x_n \overbrace{\rightarrow}^w x$ and $x_n \overbrace{\rightarrow}^s z$ can we then say that $x = z$?
My try: $$\| x- z\| = \sup_{\ell \leq 1} |\ell(x-z)| = \sup_{\ell \leq 1} |\ell x -\ell z| \leq \epsilon$$ Where $\ell$ is a continuous functional in $X'$
Is this correct? is there any easier way?
Thanks
Btw if this already is correct, should I delete the post or 
what do I do?","['operator-theory', 'functional-analysis', 'banach-spaces']"
267088,Compute the series,"Compute the series
$$1)\space\sum_{n=1}^{\infty}\left(1+\frac{1}{2}+\frac{1}{3}+\cdots+\frac{1}{n+1}\right)\frac{1}{n(n+1)}$$
$$2)\space\sum_{n=1}^{\infty}\left(1-\frac{1}{2}+\frac{1}{3}-\cdots(-1)^{n}\frac{1}{n+1}\right)\frac{1}{n(n+1)}$$","['sequences-and-series', 'calculus', 'real-analysis']"
267098,Prove this conjecture - is it even possible?,"Let $f(x)$ be continuous for all $\mathbb R$. $$\lim_{x\to\infty}f(x)=L_1$$ and $$\lim_{x\to-\infty}f(x)=L_2$$
Where $L_1,L_2$ belong to $\mathbb R$. Prove that $f(x)$ is bounded for all $\mathbb R$. My problem with this conjecture: Isn't $f(x)$=$1/x$ a counterexample? In this case, $L_1,L_2=0$ and the function is not bounded. Did I miss something? Thanks in advance.",['functions']
267112,A vector bundle admits a local covariantly constant section iff it is flat,"Let $p:E\rightarrow M$ be a vector bundle over a manifold $M$ and let $\nabla$ be a connection on $E$. I am trying to show that $E$ admits a covariantly constant section $s$ in a neighborhood of each point (i.e. $\nabla s = 0$), if and only if the curvature of $\nabla$ is 0. I think I can show that a parallel section implies 0 curvature using the various symmetries of the curvature tensor. I am unsure about the converse though. If we can show that parallel transport depends only on the homotopy class of the path, then we can produce a covariantly constant section by parallel transporting some fixed vector to each point. But, I am not sure how to get this as a consequence of 0 curvature. Any suggestions?","['riemannian-geometry', 'differential-geometry']"
267113,Question about Benford's law,"A set of numbers is said to satisfy Benford's law if the leading digit d (d ∈ {1, ..., 9}) occurs with probability, $$ P(d)=\log_{10}(d+1)-\log_{10}d$$ With Birkhoff's Ergodic Theorem  is possible to prove that the sequence $2^n$( for example) satisfies the Benford's law. The Fibonacci sequence satisfies Berford's law?","['ergodic-theory', 'probability']"
267116,Convergence of the series,"Im trying to resolve the next exercise:
$$\sum_{n=1}^\infty\ e^{an}n^2   \text{  ,  }a\in R $$
I dont know in which ranges I should separe the a value for resolving the limit and finding out the convergence.","['sequences-and-series', 'summation', 'calculus', 'limits']"
267143,"Prove that any two left cosets $aH, bH$ either coincide or are disjoint, and prove Lagrange's theorem","Consider a group $G$ and a subgroup $H \subset G$ . Prove that any two left cosets $aH$ and $bH$ either coincide or are disjoint. State and prove the Lagrange theorem. For the first part, the proof I have goes like this: Assume $aH \cap bH \ne \emptyset$ (so are not disjoint). Then for some elements $h_1, h_2 \in H$ , we get $$ah_1 = bh_2.$$ Multiply both sides on the right by $h_1^{-1}$ $$ah_1h_1^{-1} = bh_2h_1^{-1}$$ $$a = b(h_2h_1^{-1})$$ I get up to here, but then for some reason the next line says $$aH = \{ah_1\} = \{b(h_2h_1^{-1})h_1\} \in H$$ As all elements of $H$ here, this is equal to $aH$ and so the proof is complete. I don't get why the intersection giving the empty set shows its not disjoint. Secondly, to prove the Lagrange theorem. The theorem is that the order of the subgroup divides the order of the group, or: $$|G| = |H| \cdot (\mathrm{Number \, of \, left \, cosets\, of H)}$$ Then the proof says this: $G$ consists of the number of left cosets of $H$ , and each of them consist of $|H|$ elements, then the cosets are disjoint. How does this prove Lagrange's theorem?","['group-theory', 'abstract-algebra']"
267164,The prime numbers do not satisfies Benford's law,"A set of numbers is said to satisfy Benford's law if the leading digit d (d ∈ {1, ..., 9}) occurs with probability, $$ P(d)=\log_{10}(d+1)-\log_{10}d,$$ how do you prove that the prime numbers do not satisfies Benford's law?","['ergodic-theory', 'probability', 'number-theory']"
267185,Does differentiable function of bounded variation have bounded derivative?,"I learned that $f$ is a function of bounded variation, when function $f$ is differentiable on $[a,b]$ and has bounded derivative $f'$. What I want to know is converse part.
If $f$ is differentiable on $[a,b]$ and $f$ is a function of bounded variation, Is derivative of $f$ bounded? 
I guess it's false, but i cannot find a counterexample. If it's true, please show me proof.","['bounded-variation', 'real-analysis']"
267192,Is every square traceless matrix unitarily similar to a zero-diagonal matrix?,"This question asks for the symmetric case, but after consideration I believe that any complex square matrix with zero trace is unitarily similar to a matrix with zero diagonal. This answer to another related question has a demonstration of the not necessarily unitary affirmative. Is the unitary case known true or false already? For reference, this is what makes me think it is true: Consider the set of values from the diagonal one pair at a time, say $d_0$ and $d_1$. We have the principal submatrix 
$$\pmatrix{d_0 & x \\ y & d_1}$$
The general unitary transform (for any $c$ and $s$ such that $cc^* + ss^* = 1$) is
\begin{align}
  & \pmatrix{c & s \\ -s^* & c^*}\pmatrix{d_0 & x \\ y & d_1}\pmatrix{c^* & -s \\ s^* & c} \\
 = & \pmatrix{cd_0 + sy& cx+sd_1 \\ -d_0s^* + c^*y & -s^*x+c^*d_1}\pmatrix{c^* & -s \\ s^* & c} \\
 = & \pmatrix{\vert c \vert^2d_0 +\vert s\vert^2d_1 + cs^*x  + c^*sy & -csd_0 - s^2y + c^2x + csd_1\\ -c^*s^*d_0 +(c^*)^2y - (s^*)^2x + csd_1& \vert s \vert^2d_0 +\vert c\vert^2d_1 - c^*sy - cs^*x} \\
\end{align}
The question at this point is if for some $c$ and $s$ can we have zero in the bottom right:
$$\vert c \vert^2d_0 +\vert s\vert^2d_1 = (cs^*)x + (c^*s)y$$ From this point I visualize on the complex plane. The left side is in terms of only magnitudes. Parameterizing the magnitude ratio of $c$ and $s$ gives the value on a line between the points $d_0$ and $d_1$. The RHS (right hand side) is arbitrary in terms of complex angle. If $x$ and $y$ are large enough, then some angle for $c^*s$ (and opposite angle for $cs^*$) gives equality. The endpoints of the LHS line where $c=0$ or $s=0$ coincide with right hand side zero. At the middle points on the path between $d_0$ and $d_1$, the circle of angle possibilities for the right hand side grows, thus (if $x$ and $y$ are large enough) the possibility of equality exists with appropriate choice of angle for $c$ and $s$. For smaller values of $x$ and $y$, then a point closer to zero is attainable. For $x=0$ and $y=0$ a midpoint between $d_0$ and $d_1$ is closer to zero because the pair may be chosen as such due to the zero trace. Thus an iterative method converging to zero for all points is possible. As this argument is not terribly rigorous, I am wondering if the result is already known? Or would it be worth my time to formalize the argument?","['matrices', 'linear-algebra']"
267216,Tangent spaces of affine algebraic varieties at singular points,"Let $X$ be an affine algebraic over the algebraically closed field $k$ and let $\mathcal{O}(X)$ be the ring of its regular functions. Let us assume that $X$ is irreducible and let $x\in X$. There are different ways to define the tangent space $\operatorname{T}_x X$ of $X$ at $x$, one way being to let $\operatorname{T}_x X := \operatorname{Der}_k(\mathcal{O}(X),k_x)$, where $k_x$ is the field $k$, considered as an $\mathcal{O}(X)$-module via the map $f\mapsto f(x)$. Now, one says that $X$ is smooth at $x$ iff $\dim_k(\operatorname{T}_x X) = \dim X$, where the right hand side denotes the Krull-dimension of $X$ as a topological space. Questions: I was wondering what one could say about $\dim_k (\operatorname{T}_x X)$ in general, i.e. at non-smooth points. So let $y\in X$ be a singular point. 1) Can $\dim_k(\operatorname{T}_y X)$ be smaller than $\dim X$, or is it always larger? 2) And if $X\subset k^n$ is a subvariety of the affine $n$-space, is $\dim_k (\operatorname{T}_x X) \le n$ true for each $y\in X$? So you see that I'm just learning to play with tangent spaces. Thank you for your help!","['commutative-algebra', 'algebraic-geometry']"
267230,I don't understand holonomy well,"I'm just trying to understand how a vector can rotate around a smooth loop $\gamma$ on some manifold $M$. By Picard's theorem, the differential equation $\nabla_{\frac{\partial}{\partial t}} W =0$ with initial condition $W_{\gamma(t_0)} = v$ for this given connection just have one solution and ,since W is a vector field, $W_{\gamma(t_f)} = v$. I think it's very idiot, but I'm not getting it.
 Thanks in advance.",['differential-geometry']
267237,Why do the gaussian integers have only 2 congruence classes mod 1+i?,"If we consider $Z[i]$ modulo $1+i$, why are there only two congruence classes?","['modular-arithmetic', 'number-theory']"
267238,Is it that trivial to see that a sequence of random variables is mutually independent?,"Grinstead and Snells book, Introduction to Probability, page 144: Here is a number of short questions I have about this text: 0) The authors say that they consider ""special classes of random
variables"", one such classe being the class of indepedent trails. I think this is imprecise: They should have said ""classes of sequences of random variables"". What do you think ? 1) The $X_j$ are functions $X_j:R\times R\times \ldots \times R \rightarrow \mathbb{R}$, right ? 2) They should have specified that $R\subseteq \mathbb{R}$ since otherwise the $j$-th projection isn't well defined: $X_j(\Omega)\subseteq \mathbb{R}$, but it $R\ni \omega_j \not\in \mathbb{R}$. 3) On the second line from below shouldn't it say ""outcome $(\omega_1,\ldots,\omega_n)$, rather then $(r_1,\ldots,r_n)$ ? (The $r$'s are also already used to define $R=\{r_1,\ldots,r_s\}$) 4) Most important Is it that trivial to see (penultimate line) that the random variables $X_1,\ldots,X_n$ form an independent trials process ? It is indeed easy to see, that they have the same distribution, but proving that they are mutually independent does require some work!","['probability-theory', 'probability']"
267248,Infinite sum of floor functions,"I need to compute this (convergent) sum
$$\sum_{j=0}^\infty\left(j-2^k\left\lfloor\frac{j}{2^k}\right\rfloor\right)(1-\alpha)^j\alpha$$
But I have no idea how to get rid of the floor thing. I thought about some variable substitution, but it didn't take me anywhere.","['sequences-and-series', 'infinity', 'functions', 'summation', 'functional-analysis']"
267258,Easy but hard question regarding concave functions!,"I have a question about concave functions. Let $f:[0,T]\rightarrow \mathbb{R}^+$ is a concave function. Let $S=\int_0 ^ T f(x)dx$ and $R=\frac S T$ . Show that there is an interval $[a,b]$ , where $0\leq a \leq b \leq T$ and $b-a\geq \frac T 2$ such that for every $x\in [a,b]$ we have: $f(x) \geq R$ . If $f$ is non-decreasing function it is quite simple since by use of Jensen's inequality one can argue that $\frac 1 T \int_0 ^T f(x)dx \leq f(\frac T 2)$ . Also I could prove this for piecewise linear concave functions. My proof is by induction on the number of line segments in the piecewise linear concave function. It is messy and use lots of geometric stuff. I wonder if there are any nice and tidy proofs for general concave functions. Any comments is much appreciated!","['convex-analysis', 'real-analysis']"
267263,Intermediate value theorem is the key?,"Let $f(x)$ be a continues function for all $x$, and $|f(x)|\le7$ for all $x$. Prove the equation $2x+f(x)=3$ has one solution. I think the intermediate value theorem is key in this, but I'm not sure of the proper usage.",['functions']
267267,Intuitive proof of multivariable changing of variables formula (Jacobian) without using mapping and/or measure theory?,"What is an intuitive proof of the multivariable changing of variables formula (Jacobian) without using mapping and/or measure theory? I think that textbooks overcomplicate the proof. If possible, use linear algebra and calculus to solve it, since that would be the simplest for me to understand.","['multivariable-calculus', 'linear-algebra', 'intuition', 'change-of-variable']"
267272,Proof of three variable equation.,"The Question: Let a,b,c be complex numbers satisfying
$abc = 1$ and $a+b+c =$ $\frac1a + \frac1b + \frac 1c$
Show that at least one of $a,b,c$ must equal $1$. What I have tried: Rearranging the $RHS$ and subbing in the first equation we get $a+b+c = bc + ac+ab$ Now from Equation 1 we have $ a = \frac{1}{bc}$ and subbing this into the manipulation above we get $\frac{1}{bc} + b+c = bc + \frac 1b + \frac 1c$ Now multiplying out by $bc$ we get $1+b+c = (bc)^2 +c + b$ implying that $(bc)^2 = 1$
And from equation one we get $a^2b^2c^2 = 1^2 = 1$ and $b^2c^2 = 1$ therefore $a^2 = 1$ and $a = 1$. Is this correct/sufficient if not can you point me in the right direction and feel free to show other methods etc. Thanks.",['number-theory']
267274,Inverse of order preserving transformation,"Suppose $\left(A,\leq_{A}\right)$ and $\left(B,\leq_{B}\right)$ are posets and $f:A\to B$ is an order-preserving bijection. I'm trying to show that $f^{-1}:B\to A$ is also order preserving. That is, I want to show that, given $b_{1},b_{2}\in B$ , $$b_{1}\leq_{B}b_{2}\Longrightarrow f^{-1}\left(b_{1}\right)\leq_{A}f^{-1}\left(b_{2}\right)$$ Since $f$ is bijective, there are uniquely defined $a_{1},a_{2}\in A$ such that $$b_{1}=f\left(a_{1}\right)\Longrightarrow a_{1}=f^{-1}\left(b_{1}\right)$$ $$b_{2}=f\left(a_{2}\right)\Longrightarrow a_{2}=f^{-1}\left(b_{2}\right)$$ If $a_{1},a_{2}$ are comparable and I assume $a_{2}\leq_{A}a_{1}$ ,
I get a contradiction, since $f$ is order preserving: $$b_{2}=f\left(a_{2}\right)\leq_{B}\, f\left(a_{1}\right)=b_{1}$$ So I deduce that if $a_{1},a_{2}$ are comparable, then necessarily the required inequality holds. My question is whether it's possible that $a_{1},a_{2}$ are not comparable and the claim is actually false?","['elementary-set-theory', 'order-theory']"
267279,Proof of Lagrange theorem - Order of a subgroup divides order of the group,"The Lagrange theorem states: If $G$ is a finite group, and $H$ a subgroup of $G$ , then the order of $H$ will divide the order of $G$ . More precisely, $|G| = |H| \cdot (\text{number of left cosets of }H)$ : $$|G| = |H| \cdot (G:H)$$ The proof I have in my notes says: $G$ consists of $\{G:H\}$ cosets, each of them consists of $|H|$ elements, the cosets are disjoint. That's it. How does this prove the theorem?","['finite-groups', 'group-theory', 'abstract-algebra']"
267300,Positive definite matrix must be Hermitian,"Is there a simple way to show that a positive definite matrix must be Hermitian? I feel there is a long drawn out proof of this to be had by taking unit vectors and applying the positive definiteness property, and brute forcing it. But is there some simple clever proof why a positive definite matrix is necessarily Hermitian?","['positive-definite', 'matrices', 'linear-algebra', 'hermitian-matrices']"
267303,Show $\lim\limits_{n\to\infty} n \ln\left(1-\frac{1}n\right) = -1$,Could you help me show that $$\lim\limits_{n\to\infty} n \ln \left({1-\frac{1}n} \right) = -1 ?$$,['limits']
267315,Random Variable Probability Russian Roulette,"I am very confused on this one. Any help in how to solve it and what probability rule to use would be appreciated. Consider the situation in which a person played Russian roulette (one bullet, 6 chambers) until the bullet fires. Let X be the random variable that represents the number of shots until the game ends. Clearly, this number includes all shots, including the one in which bullet fires. a) What values can X take? 
b) Find the probability for each of the following: 
   X = 1, 3, 5, 7, 9","['statistics', 'probability', 'random']"
267331,What is the Laplace operator's representation in 3-sphere-coordinates?,"The three-dimensional Laplace operator in spherical coordinates can be expressed as $$\Delta_3 = \frac1{r^2}\partial_r(r^2\partial_r) + \frac1{r^2} L^2$$ where $L^2$ is the squared angular momentum operator $$L^2 = \frac1{\sin\theta}\partial_\theta(\sin\theta\partial_\theta)+\frac1{\sin^2\theta}\partial_\phi^2.$$ Is there a similarly simple representation in four-dimensional hyperspherical coordinates à la $$\Delta_4 = \frac1{r^3}\partial_r(r^3\partial_r) + \frac1{r^2}M^2$$ for some ""hyperangular"" momentum operator that does not depend on the hyper-radius? I know this is related to the Laplace-Beltrami Operator , but what's the explicit form?","['multivariable-calculus', 'partial-differential-equations', 'differential-geometry']"
267347,Relationship between automorphisms of finite etale covers and function fields,"Let $X$ and $Y$ be varieties over an algebraically closed field $K$, $\phi:Y \longrightarrow X$ be a finite etale cover , and let $K(X),K(Y)$ be the function fields of $X$ and $Y$ respectively. Then what is the relationship between $Gal(K(Y) / K(X))$ and $Aut(Y / X)$ where $Aut$ here means scheme automorphisms of $Y$ preserving $\phi$?","['galois-theory', 'algebraic-geometry']"
267350,A relation involving surface integral,"I am a little confused on how to apply a change of variables to a surface integral.  If I have 
$
\int_\Sigma F\cdot N dS 
$, and a nice map to another surface, say $f$, do I apply the change of variables as $\int_{f^{-1}(\Sigma)}F\cdot N \ |J(f^{-1})|\ dS$, with $J(f)$ the Jacobian? The particular problem is: $\Sigma = \{ (x,y,g(x,y))\in R^3 : x^2+y^2 \leq 1 \}$ where $g$ is $C^2 $ and the graph has the property that every ray from the origin in $R^3$ intersects $\Sigma$ at most once.  We are given that $\Sigma$ is contained in some ball of radius R centered at the origin, and need to relate the integral $\int_\Sigma \nabla f \cdot N dS$, where $f=\frac{1}{\|x\|}$, to a formula involving R and the area of the image of $\Sigma$ under the projection to the boundary of the R-ball. I notice that $\nabla f \cdot N$ becomes the constant $-\frac{1}{R^2}$, so can I say that the previous integral is equal to $-\frac{1}{R^2}Area(E)$, where $E$ is the area of the projection of $\Sigma$ to the surface of the ball?  I know this is not quite right, but I have to be on the right track.  Again, I am not confortable applying change of variables to a general surface integral, and any help would be appreciated.  Thanks!",['multivariable-calculus']
267363,Isosceles triangle,"Let $ \triangle ABC $ be an $C$-isosceles and $ P\in (AB) $ be a point so that $ m\left(\widehat{PCB}\right)=\phi $. Express $AP$ in terms of $C$, $c$ and $\tan\phi$. Edited problem statement(same as above but in different words): Let $ \triangle ABC $ be a isosceles triangle with right angle at $C$. Denote $\left | AB \right |=c$. Point $P$ lies on $AB(P\neq A,B)$ and angle $\angle PCB=\phi$. Express $\left | AP \right |$ in terms of $c$ and $\tan\phi$.","['geometry', 'trigonometry']"
267364,$S_4/V_4$ isomorphic to $S_3$ - Understanding Attached Tables,"I think I see $ S_4/V_4 \cong S_3 $ from the first table beneath marked in the green. I just ignore $ V_4 $ and think of it as mapped away by the bijection $ f^{-1} $ where $ f(s) = s V_4 \iff f^{-1}(\sigma V_4) = s \in S_3 $ But why do they compute only $\{S_3\}V_4 $ ? By definition, $ S_4/V_4 = \{sV_4 : s \in S_4\} $ . Where are the rest of the elements in $ S_4/V_4 $ like $(2, 1, 3, 4)V_4, (2, 1, 4, 3)V_4, (2, 3, 1, 4)V_4 $ etc...? I don't see ""The rows are the cosets of $V_4 $ in $S_4$ ."" Can someone show me this please? For instance, the third row of the table marked in the blue consists of $(1, 4, 3, 2), (1, 3, 2, 4) \notin V_4 $ . I can't see $ S_4/V_4 \cong S_3 $ from the second table. Can someone explain it please?  Thank you.","['abstract-algebra', 'normal-subgroups', 'finite-groups', 'symmetric-groups', 'group-theory']"
267371,I shouldn't be able to prove the power-set of union is equal to union of power-sets.,"And yet here I am, ""proving"" the impossible! My reasoning is as follow: $X \in P(A \cup B) \iff X \subset A \cup B \iff x \in X \to x \in A \cup B \iff x\in X \to x \in A \vee x \in B \iff  (x \in X \to x \in A) \vee (x \in X \to x \in B) \iff X \subset A \vee X \subset  B \iff X \in P(A) \vee X \in P(B) \iff X\in P(A) \cup P(B)$ I know that this breaks down at least as soon as $ (x \in X \to x \in A) \vee (x \in X \to x \in B)$ but since $P \to Q \vee R \iff (P \to Q) \vee (P \to R)$, I don't know how to avoid it. Hints or answer would welcomed.",['elementary-set-theory']
267399,"Finding functions extremes, convexity and up/downards intervals.","I know title sounds weird but i had to translate it and that was best i could put. Anyhow i have the following function: $$
f(x) = x\cdot e^{-x^{2}}
$$ I have to find the following: 1. Intervals where function is falling and rising ? 2. Convexity intervals 3. Local and global extreems 4. Graph the function I was sick and was not able to attend the last class so now I'm looking at the following function and questions not knowing where to find the following. To solve ( 1. ) i assumed i need to find the derivative of the function which I  did and I  got $ f'(x) = 1 \cdot e^{-x^{2}} + (-2x^2 \cdot e^{-x^{2}}) = e^{-x^{2}} \cdot (-2x^2 + 1) $ Now that i got the 1st derivative of the function i wanted to check following two rules:
Function is falling if $ x = f(x) ; x < x + 1 $ and rising $ x = f(x); x + 1 > x $ However I'm compleately lost here.","['calculus', 'derivatives', 'functions']"
267417,"Show that, for every $n$, $A_{n+2}$ has a subgroup isomorphic to $S_n$","Show that, for every $n$, $A_{n+2}$ has a subgroup isomorphic to $S_n$ Also, in general, when I construct an isomorphism, what's necessary to show that it's well-defined? Is showing it is a bijection and homomorphism enough? And are there any rules to follow when I try to construct a homomophism or isomorphism? I mean when I'm asked to show a certain group is isomorphic to another, it's always difficult for me to find the mapping.","['group-isomorphism', 'symmetric-groups', 'group-theory', 'abstract-algebra']"
267432,Simple Formula to Describe $\zeta$ in One Go,"I was looking around for a simple formula that can describe Riemann Zeta $\zeta$ in one go, at $\mathbb C-\{1\}$, but I couldn't really find one. Could someone help me find one? I know one way to do this, but it gives a ridiculously complicated formula: From analytic continuation of 
$$\Xi(s)=\frac1{s-1}-\frac1s+\int_1^\infty(u^{-s/2-1/2}+u^{s/2-1})\sum_{n=1}^\infty e^{-\pi n^2u}du$$ which holds for $s\in\mathbb{C}-\{0,1\}$, we can deduce a general formula of $\zeta$:
$$\begin{align}
  \zeta(s) &= \pi^{s/2}\frac{\Xi(s)}{\Gamma(s/2)}\\
           &= \pi^{s/2}\left(\frac1{s-1}-\frac1s+\int_1^\infty(u^{-s/2-1/2}+u^{s/2-1})\sum_{n=1}^\infty e^{-\pi n^2u}du\right)\left(e^{\gamma s/2}\frac s2 \prod_{n=1}^\infty (1+\frac s{2n})e^{-s/(2n)}\right)\\
           &=\frac12(\pi e^{\gamma})^{s/2}\left(\frac 1{s-1}+s\int_1^\infty(u^{-s/2-1/2}+u^{s/2-1})\sum_{n=1}^\infty e^{-\pi n^2u}du\right)\left(\prod_{n=1}^\infty \frac{1+\frac s{2n}}{e^{s/(2n)}}\right)
\end{align}$$
Thus we can write an explicit formula of $\zeta$ that should hold for $\mathbb C-\{1\}$ as following:
$$\zeta(s)=\frac12(\pi e^{\gamma})^{s/2}\left(\frac 1{s-1}+s\int_1^\infty(u^{-s/2-1/2}+u^{s/2-1})\sum_{n=1}^\infty e^{-\pi n^2u}du\right)\left(\prod_{n=1}^\infty \frac{1+\frac s{2n}}{e^{s/(2n)}}\right)$$ Note that infinite product of $\frac1{\Gamma(s/2)}$ was used to make the expression more direct.","['riemann-zeta', 'complex-analysis']"
267438,Pinsker $\sigma$-Algebra,"Let $(X,A,\nu)$ be a probability space and $T:X\to X$ a measure-preserving transformation. The Pinsker $\sigma$ -algebra is defined as the lower sigma algebra that contains all partition P of measurable sets such that $h(T,P)=0$ ( entropy of T with respect to P ). How can one calculate the Pinsker $\sigma$ -algebra of the Bernoulli shift $\left(\dfrac{1}{2},\dfrac{1}{2}\right)$ ? I think that the Pinsker $\sigma$ -algebra is the $\sigma$ -algebra of all measurable sets of measure $0$ or $1$ . And another question: Why is  the Pinsker $\sigma$ -algebra important in ergodic theory?","['ergodic-theory', 'probability', 'entropy']"
267473,Finding a conformal map of lunar domain to upper half disk,"Does there exist a conformal map from the region $\Omega = \{z :|z|<1\} \cap \{z: |z- \frac{1+i}{\sqrt2}|<1\}$ onto the region $\{z: |z|<1,  \operatorname{Im}z>0\}$? I think I need  to find  at least three intersection point of the two circles and mapped them  to real axis using the formula of fractional linear transformation. I even have difficulty finding the intersection points. I would really appreciate if someone do this rigorously. This is not a homework problem. This is from the collection of previous qual exams.",['complex-analysis']
267489,prove $\sqrt{a_n b_n}$ and $\frac{1}{2}(a_n+b_n)$ have same limit,"I am given this problem: let $a\ge0$,$b\ge0$, and the sequences $a_n$ and $b_n$ are defined in this way: $a_0:=a$, $b_0:=b$ and $a_{n+1}:= \sqrt{a_nb_n}$ and $b_{n+1}:=\frac{1}{2}(a_n+b_n)$ for all $n\in\Bbb{N}$ To prove is that both sequences converge and that they have the same limit. I don't know how to show this. I have spent 2 hours on this, no sign of success","['recurrence-relations', 'sequences-and-series', 'limits', 'proof-writing', 'problem-solving']"
267492,"for a $3 \times 3$ matrix A ,value of $ A^{50} $ is","I f
$$A= \begin{pmatrix}1& 0 & 0 \\ 
1 & 0 & 1\\
0 & 1 & 0 \end{pmatrix}$$
 then $ A^{50} $  is $$ \begin{pmatrix}1& 0 & 0 \\ 
50 & 1 & 0\\
50 & 0 & 1 \end{pmatrix}$$ $$\begin{pmatrix}1& 0 & 0 \\ 
48 & 1 & 0\\
48 & 0 & 1 \end{pmatrix}$$ $$\begin{pmatrix}1& 0 & 0 \\ 
25 & 1 & 0\\
25 & 0 & 1 \end{pmatrix}$$ $$\begin{pmatrix}1& 0 & 0 \\ 
24 & 1 & 0\\
24 & 0 & 1\end{pmatrix}$$ I am stuck on this problem. Can anyone help me please...............",['linear-algebra']
267497,"$f,g:\,(X,\mu)\to\mathbb{R}$, $f=g$ a.e then if $g$ is Lebesgue measurable then so if $f$?","I have an observation in my real analysis lecture notes that states
that if $f,g:\,(X,\mu)\to\mathbb{R}$ (with Borel's -$\sigma$ algebra
) and $f=g$ almost everywhere then if $g$ is Lebesgue measurable
then so if $f$. I don't understand why this is true, can someone please explain ? I tried looking at some Borel set and on it source, but I can't figure
why if we change $g$ in some measure $0$ of points then the source
is still in Lebesgue -$\sigma$ algebra","['measure-theory', 'real-analysis']"
267511,Does there exist an analytic function $f:D\to\mathbb{C}$ such that $f(1/n)=f(-1/n)=1/n^3$,"""Does there exist an analytic function $f:D\to\mathbb{C}$ such that $f(1/n)=f(-1/n)=1/n^3$?"" This is one of the past qualifying exam problems that I am working on and I found that 
$f(0)=0$, $f^{(n)}(0)=0,n=1,2$, $f^{(3)}(0)=1$ using the definition of derivative of a function. I am trying to use a Taylor expansion at z=0 since f is analytic in $D=\{z\in \mathbb{C}||z|=1\}$. However I do not know how to use $f(1/n)=f(-1/n)=1/n^3$ to prove or disprove the existence of such function $f$. Any help would be appreciated. Thank you in advance.",['complex-analysis']
267518,Is there a harmonic function in the whole plane that is positive everywhere?,"This is one of the past qualifying exam problems that I was working on. I know that, when we let $z=x+iy$, ${|z|}^2=x^2+y^2$ is not harmonic. I do not know where to start to prove that there is no harmonic function that is positive everywhere. Any help or ideas idea will be really appreciated. Thank you in advance.",['complex-analysis']
267520,Show $ a·b = |a| × |b| \cos(\theta)$ geometrically and by using no algebraic arguments at all,I want to know if there is a more natural way of deriving $ a·b = |a| × |b| \cos(\theta)$ without using algebraic identities and looking at a figure instead. I am familiar with the algebraic method.,"['geometry', 'inner-products', 'algebra-precalculus', 'vectors']"
267521,"Is there a characterization of groups with the property $\forall N\unlhd G,\:\exists H\leq G\text{ s.t. }H\cong G/N$?","A common mistake for beginning group theory students is the belief that a quotient of a group $G$ is necessarily isomorphic to a subgroup of $G$ .  Is there a characterization of the groups in which this property holds? If this question is too broad, I might ask if such a characterization exists for $p$ -groups. History : I originally posed the opposite question, regarding groups for which $\exists N\unlhd G\,:\, \not\exists H \unlhd G\, \text{  s.t. } H \cong G/N$ , and crossposted this to MO .  I received an answer there to the (now omitted) peripheral question about probability, which shows that most finite groups probably have this property.  After this, I changed the question to its current state, as this smaller collection of groups is more likely to be characterizable.","['group-cohomology', 'finite-groups', 'p-groups', 'group-theory', 'combinatorics']"
267534,calculate the limit of this sequence $\sqrt{1+\sqrt{1+\sqrt{1+\sqrt{1..}}}}$ [duplicate],"This question already has answers here : Closed 11 years ago . Possible Duplicate: $\sqrt{c+\sqrt{c+\sqrt{c+\cdots}}}$, or the limit of the sequence $x_{n+1} = \sqrt{c+x_n}$ i am trying to calculate the limit of $a_n:=\sqrt{1+\sqrt{1+\sqrt{1+\sqrt{1+}}}}..$ with $a_0:=1$ and $a_{n+1}:=\sqrt{1+a_n}$ i am badly stuck not knowing how to find the limit of this sequence and where to start the proof. i did some calculations but still cannot figure out the formal way of finding the limit of this sequence. what i tried is: $$(1+(1+(1+..)^\frac{1}{2})^\frac{1}{2})^\frac{1}{2}$$ but i am totally stuck here","['nested-radicals', 'sequences-and-series', 'problem-solving', 'limits']"
267557,The inverse of Lagrange's Theorem is true for finite supersolvable group.,"We have already known that the inverse of Lagrange's Theorem is a right fact about for example abelian or nilpotent finite groups. How can I show that: If $G$ be finite and supersolvable$^*$ and $n\mid|G|$, then $G$ has a subgroup of order $n$? $^*$ A group is supersolvable if there exists normal subgroups $N_i$ with $$1=N_0\subseteq N_1\subseteq ...\subseteq N_r=G$$ where each factor $\frac{N_i}{N_{i-1}}$ is cyclic for $1\leq i\leq r$. Thanks for any hint to start.","['finite-groups', 'group-theory']"
267563,Closed set in $\ell^1$,"Show that the set $$ B = \left\lbrace(x_n) \in \ell^1 : \sum_{n\geq 1} n|x_n|\leq 1\right\rbrace$$
  is compact in $\ell^1$.
  Hint: You can use without proof the diagonalization process to conclude that every bounded sequence $(x_n)\in \ell^\infty$ has a subsequence $(x_{n_k})$ that converges in each component, that is $\lim_{k\rightarrow\infty} (x_{n_k}^{(i)})$ exists for all i.
  Moreover, sequences in $\ell^1$ are obviously closed by the $\ell^1$-norm. My try: Every bounded sequence $(x_n) \in \ell^\infty$ has a subsequence $(x_{n_k})$
that converges in each component. That is $\lim_{k\rightarrow\infty} (x_{n_k}^{(i)})$ exists for all i.  .And all sequences in $\ell^1$ are bounded in $\ell^1$-norm.
I want to show that every sequence $(x_n) \in B$, has an Cauchy subsequence.
Choose an N and M such that for $l,k > M$ such that $|x_{n_k}^{(i)} - x_{n_l}^{(i)}| < \frac{1}{N^2}$ Then 
$$\sum_i^N |x_{n_k}^{(i)} - x_{n_l}^{(i)}| + \sum_{i = N+1} ^\infty |x_{n_k}^{(i)} - x_{n_l}^{(i)}| \leqslant \frac{1}{N} + \frac{1}{N+1}  \sum_{i = N+1} ^\infty i|x_{n_k}^{(i)} - x_{n_l}^{(i)}| \leqslant \frac{3}{N+1}$$ 
It feels wrong to compine $M,N$ like this, is it? what can I do instead?","['sequences-and-series', 'general-topology', 'lp-spaces', 'compactness', 'functional-analysis']"
267564,Recurrence relation: $T(n) = T(n-1) + 1/n$ [duplicate],"This question already has answers here : Recurrence telescoping $T(n) = T(n-1) + 1/n$ and $T(n) = T(n-1) + \log n$ (2 answers) Closed 9 years ago . \begin{align}
T(0) & = 0 \\
T(n) & = T(n-1) + \dfrac{1}{n}
\end{align} solve the recurrence relation My work so far: \begin{align}
T(1) & = 1 \\
T(2) & = 1 + \dfrac{1}{2} \\
T(3) & = 1 + \dfrac{1}{2} + \dfrac{1}{3} \\
&\vdots
\end{align} this is the harmonic series, which diverges. What is the solution to the recurrence relation?","['self-learning', 'discrete-mathematics']"
267566,Problem on a quotient group of a matrix,"Let $G=\left\{\begin{bmatrix}a & b \\ c & d\end{bmatrix}:a,b,c,d\in\mathbb{Z}\right\}$ be the group under matrix addition and $H$ be the subgroup of $G$ consisting of matrices with even entries. Find the order of the quotient group $G/H$. How should I solve this problem?",['abstract-algebra']
267568,Kolmogorov Extension Theorem vs. Caratheodory Extension Theorem,"I noticed that CET together with monotone-class arguments is commonly used in theory of discrete-time stochastic processes to construct a joint probability measure from finite-dimensional distributions. At the same time, I often see KET being used to construct a joint probability measure from finite-dimensional distributions in continuous time case. As it requires the state space to have some topological properties, it seem to have more restricted applications comparing to those of CET. Updated: more explicit question I decided to rephrase my questions in a more explicit way: is it true that KET holds without assumptions on the topology of the state space? I have not found the place, where they are used.","['probability-theory', 'stochastic-processes', 'measure-theory']"
267571,find recurrence relation $T(n)=2T(n/2) +\log_2(n)$,"$$\begin{align*}
&T(n) = 2T(n/2) + \log_2(n)\\
&T(1) = 0  
\end{align*}$$ $n$ is a power of $2$ solve the recurrence relation my work so far: unrolling this, we have $$\begin{align*}
T(n) &= 4T(n/4) + \log_2(n) -1\\
&= 8T(n/8) + 2\log_2(n) -2\\
&=\log_2(n-1) \log_2(n) - \log_2(n) + 1
\end{align*}$$ after substituting for base case. where is my mistake?","['recurrence-relations', 'discrete-mathematics', 'self-learning']"
267584,Is every sigma-algebra generated by some random variable?,Let $\mathcal{A}$ be a $\sigma$-algebra over $\Omega$. Is there a function $f:\Omega\rightarrow\mathbb{R}$ such that $\mathcal{A}=f^{-1}(\mathfrak{B(\mathbb{R})})$? ($\mathfrak{B(\mathbb{R})}$ being the Borel field on the real line),"['probability-theory', 'measure-theory']"
267589,Products in the category of normed linear spaces,"I have tried to formulate the notion of products myself and this is what I came up with: Let $(X_i, |*|_i), i\in I$ be a collection of normed linear spaces and $f_i:Y\to X_i$ a collection of bounded linear maps, all index by the set $I$. As long as $I$ is a finit set we can factor all maps in the following way: $Y\overset{\triangle}{\to}\prod_{I}Y\overset{\prod_{i\in I} f_i}{\to}\prod_{i\in I}X_i\overset{p_i}{\to}X_i$ where the norm on the products is given by: $|x|=\underset{i\in I}{sup}(|x_i|_i)$ As can be seen this is a close relative to $l^\infty$. We can formulate the notion of coproducts in the dual way and get something similiar to $l^1$, but only with finit sums. $|x|=\sum_{i\in I}|x_i|_i$ I originally choose the supremum norm (on the product) so that it would work with infinite products, I am, however, no longer sure. I wanted to use the definiton above to illuminate the difference between the weak topology and weak convergence. To start I imagine we are in the following position: $X\overset{\triangle}{\to}\prod_{X'}X\overset{\prod_{\lambda\in X'} \lambda}{\to}\prod_{X'}\mathbb{R}\overset{p_i}{\to}\mathbb{R}$ The weak topology on $Y$ can be obtained as the coarsest topology where $(\prod_{\lambda\in X'}\lambda)\triangle$ is continuous with respect to the product topology in $\prod_{X'}\mathbb{R}$ while weak convergence correspondes to the product norm defined above, which correspondes to the box topology. Now for the objects this seem to be working out fairly well but it occurs to me that $(\prod_{\lambda\in X'}\lambda)\triangle$ need not be bounded, infact as long as X' isn't uniformly bounded it won't. So now I'm hoping that I did something wrong. I really want the category of normed vectorspaces to have infinit products and it makes me a bit sad to think it might not. Alternatively this is why the ideas of uniform boundedness are so important and I need to incorporate these somehow. I read about them but I honestly didnt get thier significanse at the time and I can't really see thier place in the big picture. Any help in that regard would also be very appreaciated. I apologice if the question is to vague to be a proper StackExchange question.","['category-theory', 'functional-analysis']"
267593,Group containing no subgroup of index 2 [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question Prove that if a group is containing no subgroup of index 2 then any subgroup of index 3 is normal. Thank you.","['group-theory', 'normal-subgroups']"
267597,do Carmo: Second Variation Formula,"I have some trouble with the derivation of the second variation formula in do Carmo's famous ""Riemannian Geometry"" (p. 197f.). The proposition is the following: 2.8 Proposition Let $(M,\langle\cdot,\cdot\rangle)$ be a Riemannian manifold and let $\gamma:[0,a]\to M$ be a geodesic. Assume that $f:(-\epsilon,\epsilon)\times[0,a]\to M$ is a proper variation of $\gamma$. Let $E:(-\epsilon,\epsilon)\to\mathbb{R}$ be the energy function associated to $f$, i.e.:
$$E(s):=\int_{0}^{a}\left\langle\frac{\partial f}{\partial s}(s,t),\frac{\partial f}{\partial s}(s,t)\right\rangle\operatorname{d}\!t$$
Then:
$$\frac{1}{2}E''(0)=-\int_{0}^{a}\left\langle V(t),\frac{D^{2}V}{dt}+R\left(\dot{\gamma},V\right)\dot{\gamma}\right\rangle\operatorname{d}\!t-\sum_{i=1}^{k}\left\langle V(t_{i}),\frac{DV}{dt}(t_{i}^{+})-\frac{DV}{dt}(t_{i}^{-})\right\rangle$$
where $R$ is the curvature on $M$ and $V:[0,a]\to TM$ is the variational field given by $V(t):=\frac{\partial f}{\partial s}(0,t)$ - is this well-defined everywhere? - and:
$$\frac{DV}{dt}(t_{i}^{+}):=\lim_{t\downarrow t_{i}}\frac{DV}{dt}(t)\quad \frac{DV}{dt}(t_{i}^{-}):=\lim_{t\uparrow t_{i}}\frac{DV}{dt}(t)$$ I know that the proposition still is not well-defined as it is not clear what the $t_{i}$ stand for and so on. Let me start with a few comments on notation: $\frac{D}{dt}$ denotes the covariant derivative along a curve, or if $f:(-\epsilon,\epsilon)\times [0,a]\to M$ is a parametrized surface, then by convention $\frac{D}{\partial t}V(s_{0},t_{0})$ is the covariant derivative of the field $V:(-\epsilon,\epsilon)\times [0,a]\to TM$ along the curve defined by $t\mapsto f(s_{0},t)$ at the point $t_{0}$ and similarly for the operator $\frac{D}{\partial s}$. Now I give you the definition of a variation as it appears in do Carmo's book: Let $c:[0,a]\to M$ be a piecewise differentiable curve. A function $f:(-\epsilon,\epsilon)\times[0,a]\to M$ is a variation of $c$ iff: $f(0,t)=c(t)$ for all $t\in[0,a]$ There exists a partition $0=t_{0}<\cdots<t_{k+1}=a$ such that $f\big|_{(-\epsilon,\epsilon)\times[t_{i},t_{i+1}]}$ is differentiable for all $0\leq i\leq k$. $f$ is a proper variation of $c$ if $f(s,0)=c(0)$ and $f(s,a)=c(a)$ for all $s\in(-\epsilon,\epsilon)$. At the time it is already clear that:
$$\frac{1}{2}E'(s)=\sum_{i=0}^{k}\left.\left\langle\frac{\partial f}{\partial s},\frac{\partial f}{\partial t}\right\rangle\right|_{t_{i}}^{t_{i+1}}-\int_{0}^{a}\left\langle\frac{\partial f}{\partial s},\frac{D}{\partial t}\frac{\partial f}{\partial t}\right\rangle\operatorname{d}\!t$$
and hence differentiation with respect to $s$ yields:
$$\frac{1}{2}E''(s)=\sum_{i=0}^{k}\left.\frac{d}{ds}\left\langle\frac{\partial f}{\partial s},\frac{\partial f}{\partial t}\right\rangle\right|_{t_{i}}^{t_{i+1}}-\int_{0}^{a}\frac{d}{ds}\left\langle\frac{\partial f}{\partial s},\frac{D}{\partial t}\frac{\partial f}{\partial t}\right\rangle\operatorname{d}\!t$$
Using standard properties of the Levi-Civita connection, this yields:
$$\frac{1}{2}E''(s)=\sum_{i=0}^{k}\left.\left\langle\frac{D}{\partial s}\frac{\partial f}{\partial s},\frac{\partial f}{\partial t}\right\rangle\right|_{t_{i}}^{t_{i+1}}+\sum_{i=0}^{k}\left.\left\langle\frac{\partial f}{\partial s},\frac{D}{\partial s}\frac{\partial f}{\partial t}\right\rangle\right|_{t_{i}}^{t_{i+1}}-\int_{0}^{a}\left\langle\frac{D}{\partial s}\frac{\partial f}{\partial s},\frac{D}{\partial t}\frac{\partial f}{\partial t}\right\rangle\operatorname{d}\!t-\int_{0}^{a}\left\langle\frac{\partial f}{\partial s},\frac{D}{\partial s}\frac{D}{\partial t}\frac{\partial f}{\partial t}\right\rangle\operatorname{d}\!t$$
So far so good. The issue now is the following: ""Putting $s=0$ in the expression above, we obtain that the first [...] $<$term is$>$ zero, since $f$ is proper and $\gamma$ is a geodesic."" I do not see the reason for this. There are two obvious options: it clearly holds if for all $i$ the map $s\mapsto f(s,t_{i})$ is a geodesic or if $\frac{\partial f}{\partial t}(0,t)\equiv 0$. The latter is false by assumption (somewhere in the beginning of the book: geodesics are by definition non-trivial). The second is a rather strong assumptionand would be mentioned somewhere. A third possibility would be that the map $t\mapsto\frac{D}{\partial s}\frac{\partial f}{\partial s}(s,t)$ is continuous and indeed I assume that this is the case. I do not see why this follows from the definition of a variation. Does anybody have an idea?","['riemannian-geometry', 'differential-geometry']"
267612,Boundedness of an integral operator,"Let $K_n \in L^1([0,1]), n \geq 1$ and define a linear map $T$ from  $L^\infty([0,1]) $to sequences by 
$$ Tf = (x_n), \;\; x_n =\int_0^1 K_n(x)f(x)dx$$ 
Show that $T$ is a bounded linear operator from $L^\infty([0,1]) $to $\ell^\infty$ iff
$$\sup_{n\geq 1} \int_0^1|K_n(x)| dx \lt \infty$$ My try: 
$(\Leftarrow)$ 
$$\sup_n |x_n| = \sup_n  |\int_0^1 K_n(x)f(x) dx| \leq \sup_n\int_0^1 |K_n(x)f(x)| dx \leq \|f\|_\infty \sup_n\int_0^1 |K_n(x)|dx $$
 $(\Rightarrow)$
 I can't get the absolute value right. I was thinking uniformed boundedness and that every coordinate can be written with help of a linear functional. But then I end up with $\sup_{\|f\| = 1} |\int_0^1 K_n(x) f(x) dx | \leq \infty$. Can I choose my $f$ so that I get what I want?",['functional-analysis']
267627,"Is the ideal $I = \{f\mid f (0) = 0\}$ in the ring $C [0, 1]$ of all continuous real valued functions on $[0, 1]$ a maximal ideal?","Is the ideal $I = \{f \mid f (0) = 0\}$ in the ring $C [0, 1]$ of all continuous real valued functions on the interval $[0, 1]$ a maximal ideal?",['abstract-algebra']
267644,$n$ choose $k$ where $n$ is less than $k$,"I am working on parameter estimation and one of the estimators involves a summation of $_nC_k$ ($n$ choose $k$) expressions. For some iterations, I need to compute expressions like $_0C_1$, $_0C_2$, etc. In general how do we compute $_nC_k$ when $n$ is less than $k$? Do we still use the formula $\frac{n!}{(n-k)!k!}$ and use the gamma function to compute the negative factorial? Thanks!","['factorial', 'binomial-coefficients', 'combinatorics']"
267652,Find the limit of $(x_n)$ defined by $x_{n+1}=c_nu(x_n)$,"Find $\displaystyle \lim_{n\rightarrow \infty }x_n$ :
$$\left\{\begin{matrix}x_1=a>0\\ \\ x_{n+1}=\frac{2x_n\cdot \cos\left(\frac{\pi}{2^n+1}\right)}{x_n+1}\end{matrix}\right.$$ I have tried that :
Let $a_n=\dfrac{1}{x_n}$ . So :
$$a_{n+1}=\frac{1}{2\cos\left(\frac{\pi}{2^{n+1}}\right)}.a_n+\frac{1}{2\cos\left(\frac{\pi}{2^{n+1}}\right)}$$
So I tried to have geometric series: 
By let :
$$a_{n+1}+f(n+1)=\frac{1}{2\cos\left(\frac{\pi}{2^{n+1}}\right)}(a_n+f(n))$$
So we must find one $f(n)$:
$$\frac{f(n)}{2\cos\left(\frac{\pi}{2^{n+1}}\right)}-f(n+1)=\frac{1}{2\cos\left(\frac{\pi}{2^{n+1}}\right)}$$
As $$f(n)-f(n+1)\cdot 2\cos\frac{\pi}{2^{n+1}}=1$$ Can you give me the way to find one $f(n)$ sastisfied that ; or anyone has nice way to solve this problem",['limits']
267666,Prove that the set $\mathrm{Aut}(G)$ of all automorphisms of the group $G$ with the operation of taking the composition is a group,"Let $G$ be a group. Say what it means for a map $\varphi: G \rightarrow G$ to be an automorphism. Show that the set-theoretic composition $\varphi \psi = \varphi \circ \psi$ of any two automorphisms $\varphi, \psi$ is an automorphism. Prove that the set $\mathrm{Aut}(G)$ of all automorphisms of the group $G$ with the operation of taking the composition is a group. I have said: A map is an automorphism of a group $G$ if it is an isomorphism to itself. a) For the next bit, I want to show if $\varphi, \psi$ is bijective, then $\varphi \circ \psi$ is bijective: For two elements $a, b \in G$ we have $$\varphi \circ \psi (ab) = \varphi(\psi(ab)) = \varphi(\psi(a)\psi(b))$$ as $\psi$ is an isomorphism. Also, as $\varphi$ is an isomorphism, we have $$\varphi(\psi(a) \psi(b)) = \varphi \circ \psi(a) \varphi \circ \psi(b)$$ Showing $\varphi \circ \psi$ is an isomorphism iff $\varphi, \psi$ are isomorphisms. For the group bit, we want to prove the 3 group axioms. 1) Associativity: $\varphi \circ (\psi \circ \zeta) = (\varphi \circ \psi) \circ \zeta$. So for some $x \in G$, we get: $$\varphi \circ (\psi \circ \zeta)(x) = (\varphi \circ \psi) \zeta(x) = \varphi(\psi(\zeta(x))) $$ 2) Identity: If we let the identity automorphism, $e: G \rightarrow G$, be the map $e(x) = x$, then clearly we get that $e \circ \psi = \psi \circ e = \psi$. 3) Inverse: As the automorphisms are bijective (already proved) then we know that  by definition of a bijection, there is well defined inverse such that $\psi^{-1}: G \rightarrow G$ exists. (Second edit to correct proof for inverse): For any two elements $a,b \in G$, we want to see if $\psi^{-1}(ab) = \psi^{-1}(a)\psi^{-1}(b)$. Apply $\psi$ to both sides gives us $$\psi \circ \psi^{-1}(ab) = \psi(\psi^{-1}(ab)) = ab$$ Doing the same on RHS gives us $ab$ and so we have proved the inverse exists and is unique. Is this right and enough to prove this? EDIT: Actually, can I just say that by definition of two bijective maps, the composition is also bijective and this is enough?","['proof-writing', 'group-theory']"
267668,"Show that the sum of the largest odd divisors of $n+1, n+2, \ldots, 2n$ (where $n$ is a natural number) is a perfect square?","I've been given the solution but I don't understand it at all, could someone please explain?",['number-theory']
267669,convergence of weighted average,"It is well known that for any sequence $\{x_n\}$ of real or complex numbers which converges to a limit $x$, the sequence of averages of the first $n$ terms is also convergent to $x$.  That is, the sequence $\{a_n\}$ defined by $$a_n = \frac{x_1+x_2+\ldots + x_n}{n}$$ converges to $x$.  How ""severe"" of a weighting function $w(n)$ can we create that the sequence of weighted averages $\{b_n\}$ defined by $$b_n = \frac{w(1)x_1 + w(2)x_2 + \ldots + w(n)x_n}{w(1)+w(2)+\ldots+w(n)} $$ is convergent to $x$?  Is it possible to choose $w(n)$ such that $\{b_n\}$ is divergent?",['sequences-and-series']
