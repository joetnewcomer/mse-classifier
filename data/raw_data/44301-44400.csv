question_id,title,body,tags
441457,"$W^{1,p} $ and $W^{2,p}$ Estimates.","In the beginning of section 4 in here the author says that one can easily adapt the methods in the preceding section to obtain $W^{1,p}$ estimate. I'm trying to do this. I think the following: the lemma 7 is replaced by Lemma: There is a constant $N_1$ so that for any $\varepsilon >0, \exists \delta = \delta(\varepsilon)>0$  and if $u$ is a solution of
    $$ \Delta u = f \quad \mbox{in}\quad \Omega,$$
    in a domain $\Omega \supset B_4,$ with 
    $$\left \{\mathcal{M}(|f|^2) \le \delta^2\right \} \cap \left \{\mathcal{M}(|\nabla u|^2) \le 1 \right \} \cap B_1 \neq \emptyset$$
    then
    $$|\left \{ \mathcal{M}(|\nabla u|^2)>N_1^2 \right \} \cap B_1| < \varepsilon |B_1|.$$ Here $$\mathcal{M}v(x) = \sup_{r>0}\dfrac{1}{|B_r(x)|}\int_{B_r(x)}|v|$$
is the maximal function of $v.$
As in here there is a point $x_0 \in B_1$ so that
$$ \dfrac{1}{|B_r(x_0)|}\int_{B_r(x_0)} |\nabla u |^2 \le 1  \quad \mbox{and } \quad \dfrac{1}{|B_r(x_0)|}\int_{B_r(x_0)}|f|^2 \le \delta^2$$
and consequently $$ \int_{B_4} |\nabla u|^2 \le 2^n \quad \mbox{and} \quad \int_{B_4}|f|^2 \le 2^n \delta^2  \tag{1}$$
by Poincaré and the first inequality we have
\begin{equation}
\int_{B_4}|  u - \overline{u}_{B_4}|^2 \le C_1
\end{equation}
In lemma 7 in the same way we get
\begin{equation}
\int_{B_4}| \nabla u - \overline{\nabla u}_{B_4}|^2 \le C_1
\end{equation}
and considering $v$ the solution of the following equation
$$
\left \{
\begin{array}{rclcl}
\Delta v & = & 0 & \mbox{in} & B_4 \\
v&=& u - (\overline{\nabla u})_{B_4}\cdot x - \overline{u}_{B_4} & \mbox{on}&  \partial B_4
\end{array}
\right .
$$
Then by minimality of harmonic functions with respect to energy in $B_4.$
\begin{equation}
\int_{B_4} | \nabla v|^2 \le \int_{B_4}| \nabla u - \overline{\nabla u}_{B_4}|^2 \le C_1.
\end{equation}
So as $\nabla v$ is also harmonic by gradient estiamte (of the harmonic function $\nabla v$) we have
\begin{equation}
\|D^2 v\|_{L^\infty(B_3)}\le N_0^2.
\end{equation} Then my intention is also to obtain universal control as below
\begin{equation}
\| \nabla v \|_{L^\infty(B_3)} \le N_0^2.
\end{equation}
Am I right? What should I do? Thank you. I will be very grateful.","['partial-differential-equations', 'analysis']"
441470,How to calculate probability using multinomial distribution?,"So according to the multinomial distribution, the probability function $\Pr(X_1 = x_1, X_2 = x_2, \dots, X_k = x_k)$ is equal to $\dfrac{n!}{x_1! x_2! \cdots x_k!} \cdot p_1^{x_1}\cdot p_2^{x_2} \cdots p_k^{x_k}$ (See http://en.wikipedia.org/wiki/Multinomial_distribution ). And if we were to sum all of the probabilites for all possible values of $x_1, x_2, \dots x_k$, we would get one. The thing is that summing all of those probablities also includes the situations in which at least one $x_j = 0$. How would I go about computing the following probablity function?: $$\Pr(X_1=x_1>0, X_2=x_2>0, \ldots, X_k=x_k>0) = ?$$ So basically, the sum of all probabilities of the scenarios in which no $x_j = 0$ and the sum of all the probabilities of the scenarios in which at least one $x_j = 0$ is equal to $1$. I want to find the sum of all probabilities of the scenarios in which no $x_j = 0$","['parameter-estimation', 'multinomial-coefficients', 'probability', 'probability-distributions', 'statistical-inference']"
441471,"List all subsets of {a, b, c, d, e}, containing a but not containing b","I wonder...can I solve this by just getting A = {a, c, d, e} minus those subsets which do not contain a? So, let A be {a, c, d, e}. |A| is 2^4 = 16
And let B be {c, d, e}. |B| is 8
And let C be subset of subsets of {a, b, c, d, e}, containing a but not containing b Can I conclude that that |C| will be 8, that is, |A| - |B|? I could enumerate these: {a} {a, c} {a, d} {a, e} {a, c, d} {a,c, e} {a, d, c} {a, d, e} Which are 8, not including the empty set so I guess there is some mistake with my reasoning. Could you people point that out for me? P.S: this question is from the book Discrete Mathematics: Elementary and Beyond, by Lovász et al.",['elementary-set-theory']
441473,The value of $\sqrt{1-\sqrt{1+\sqrt{1-\sqrt{1+\cdots\sqrt{1-\sqrt{1+1}}}}}}$?,"How to find value of $\sqrt{1-\sqrt{1+\sqrt{1-\sqrt{1+\cdots\sqrt{1-\sqrt{1+1}}}}}}$ ? I've calculated it by MATLAB for some finite terms and I've got : $0.3001 - 0.4201i$, but I don't know how to find the value analytically! Would you mind helping me find it? Thanks","['calculus', 'algebra-precalculus', 'open-problem', 'problem-solving']"
441481,Why does $\sum_{n = 0}^\infty \frac{n}{2^n}$ converge to 2? [duplicate],"This question already has answers here : How can I evaluate $\sum_{n=0}^\infty(n+1)x^n$? (24 answers) Closed 10 years ago . Apparently, $$
\sum_{n = 0}^\infty \frac{n}{2^n}
$$ converges to 2. I'm trying to figure out why. I've tried viewing it as a geometric series, but it's not quite a geometric series since the numerator increases by 1 every term.",['sequences-and-series']
441496,Expression for the Maurer-Cartan form of a matrix group,"I understand the definition of the Maurer-Cartan form on a general Lie group $G$, defined as $\theta_g = (L_{g^{-1}})_*:T_gG \rightarrow T_eG=\mathfrak{g}$. What I don't understand is the expression $\theta_g=g^{-1}dg$ when $G$ is a matrix group. In particular, I'm not sure how I'm supposed to interpret $dg$. It seemed to me that, in this concrete case, I should take a matrix $A\in T_gG$ and a curve $\sigma$ such that $\dot{\sigma}(0)=A$, and compute $\theta_g(A)=(\frac{d}{dt}g^{-1}\sigma(t))\big|_{t=0}=g^{-1}A$ since $g$ is constant. So it looks like $\theta_g$ is just plain old left matrix multiplication by $g^{-1}$. Is this correct? If so, how does it connect to the expression above?","['lie-algebras', 'lie-groups', 'differential-geometry']"
441507,Simple spectrum and the spectral theorem for bounded symmetric operators,"I have a question regarding the spectral theorem for bounded self-adjoint operators. The book ""Functional Analysis, an Introduction"" by Eidelman, Milman, and Tsolomitis says that if an operator $T$ has a simple spectrum then it is unitarily equivalent to the operator $T\varphi(\lambda)=\lambda\cdot \varphi(\lambda)$ acting on $L^2$ equipped with the measure generated by the right-continuous function $\lambda\mapsto\langle E_\lambda x_0, x_0\rangle$. Here, $\{E_{\lambda}\}$ is our resolution of identity. Hence, is this unitary equivalence to the multiplication operator only possible when $T$ has a simple spectrum, or is it possible in the general self-adjoint case? Wikipedia says that it's always true, but my functional book along with the book ""Treastie on the Shift Operator"" say that it's only possible when $T$ has simple spectrum. Also, the definition of simple spectrum is when there exists an $x_0\in H$ such that $$\{ (E_{\lambda_1}-E_{\lambda_2})x_0\ : \ \lambda_2<\lambda_1\}$$ is a dense subset of our Hilbert Space. Can someone give me some intuition as to why this definition is natural.","['operator-theory', 'spectral-theory', 'functional-analysis', 'analysis']"
441522,General formula or a pattern for the $n$th derivatives of $e^{f(x)}$?,"I want to find the $nth$ derivatives of the function $e^{f(x)}$ with respect to $x$, the first derivative is $$e^{f(x)}f^{\prime}(x).$$
 The second derivative is $$\left( {\frac {d^{2}}{d{x}^{2}}}f \left( x \right)  \right) {{\rm e}^
{f \left( x \right) }}+ \left( {\frac {d}{dx}}f \left( x \right) 
 \right) ^{2}{{\rm e}^{f \left( x \right) }}
.$$ The third derivative is $$\left( {\frac {d^{3}}{d{x}^{3}}}f \left( x \right)  \right) {{\rm e}^
{f \left( x \right) }}+3\, \left( {\frac {d^{2}}{d{x}^{2}}}f \left( x
 \right)  \right)  \left( {\frac {d}{dx}}f \left( x \right)  \right) {
{\rm e}^{f \left( x \right) }}+ \left( {\frac {d}{dx}}f \left( x
 \right)  \right) ^{3}{{\rm e}^{f \left( x \right) }}
$$
 The fourth derivative is $$ \left( {\frac {d^{4}}{d{x}^{4}}}f \left( x \right)  \right) {{\rm e}^
{f \left( x \right) }}+4\, \left( {\frac {d^{3}}{d{x}^{3}}}f \left( x
 \right)  \right)  \left( {\frac {d}{dx}}f \left( x \right)  \right) {
{\rm e}^{f \left( x \right) }}+3\, \left( {\frac {d^{2}}{d{x}^{2}}}f
 \left( x \right)  \right) ^{2}{{\rm e}^{f \left( x \right) }}+6\,
 \left( {\frac {d^{2}}{d{x}^{2}}}f \left( x \right)  \right)  \left( {
\frac {d}{dx}}f \left( x \right)  \right) ^{2}{{\rm e}^{f \left( x
 \right) }}+ \left( {\frac {d}{dx}}f \left( x \right)  \right) ^{4}{
{\rm e}^{f \left( x \right) }}
$$ My question is: Is there a general formula or a pattern for the nth derivative of $e^{f(x)}$. You may use the maple command diff(exp(f(x)), x$5) to do some experiments. Thanks a lot ^^","['calculus', 'combinatorics']"
441525,Differentiating $y=x^{2}$,"I am reading in a book about differentiating, but I am confused with one of the steps he takes.  We start with: $$\begin{align}
y &= x^{2} \\
y + \mathrm{d}y &= (x + \mathrm{d}x)^2 \\
y + \mathrm{d}y &= x^2 + x\mathrm{d}x + x\mathrm{d}x + (\mathrm{d}x^2)
\end{align}$$ Now the author simplifies this to: $$y + dy = x^2 + 2x\mathrm{d}x + (\mathrm{d}x^2)$$ I dislike how the middle term is simplified to $2x\mathrm{d}x$ instead of $2(x\mathrm{d}x)$ , as I feel like it is more intuitive on what is going.  As in, $2$ of the term $x\mathrm{d}x$ , instead of $2x\mathrm{d}x$ .  But I fear writing it as $2(x\mathrm{d}x)$ may result in an incorrect distributive property. Next, he omits the $(\mathrm{d}x^2)$ : $y + \mathrm{d}y = x^2 + 2x \mathrm{d}x$ . Subtract the original $y = x^2.$ : $$\mathrm{d}y = 2x \mathrm{d}x.$$ Now here is where I get confused: $$\frac{\mathrm{d}y}{\mathrm{d}x} = 2x.$$ How can he just divide both sides by $\mathrm{d}x$ !?  If the original term was $2$ of $x\mathrm{d}x$ , wouldn't it have to be written out as $2x * 2\mathrm{d}x$ , and thus divide both sides by $2\mathrm{d}x$ instead? I think the root of my confusion is how to properly simplify: $x\mathrm{d}x + x\mathrm{d}x$ . I trust that he is right, but I am looking for an explanation of why his simplification can work, and why $2(x\mathrm{d}x)$ would be incorrect.","['calculus', 'derivatives']"
441527,"Answer-verification: Show that $f(x,y)=1+2x+3y$ for all $(x,y)\in \Bbb R^2$","Define the function $f: \Bbb R^2\to \Bbb R$ has first order partial derivatives and that $f(0,0)=1$ 
While $\frac{\partial f}{\partial x}(x,y)=2$ and $\frac{\partial f}{\partial y}(x,y)=3$ for all $(x,y)\in \Bbb R^2$ Prove that $f(x,y)=1+2x+3y$ for all $(x,y)\in \Bbb R^2$ $\bf{solution:}$ Let $\frac{\partial f}{\partial x}(x,y)=g(x,y)$ Then $\int g(x,y)dx=2x +c_1$ for $c_1 $ is constant Similarly, let $\frac{\partial f}{\partial y}=h(x,y)$ Then $\int h(x,y)=2y+c_2$ for $c_2$ constant Since $f(0,0)=1$ is constant so, $c:=(c_1,c_2)=1$ Thus, $f(x,y)=1+2x+3y$ for all $(x,y)\in \Bbb R^2$ Is this answer true? If there exist mistakes, please can somebody correct this?","['calculus', 'derivatives', 'real-analysis', 'solution-verification']"
441534,"If $V \subset H$ compact, is $L^2(0,T;V) \subset L^2(0,T;H)$ compact too?","As the question states, if we have the compact embedding of Hilbert spaces $V \subset H$, is $L^2(0,T;V) \subset  L^2(0,T;H)$ compact too? If not true in general, is it true for $V=H^1(\Omega)$ and $H=L^2(\Omega)$?","['hilbert-spaces', 'functional-analysis']"
441536,Is tensor product of Sobolev spaces dense?,"My question is: is $W_2^k(\mathbb{R})\otimes W_2^k(\mathbb{R})$ dense in $W_2^k(\mathbb{R}^2)$, and more generally is this true in $\mathbb{R}^d$? I found this post: Tensor products of functions generate dense subspace? which shows the above type of result for $C_c^\infty$.  So my guess is that the answer should be affirmative, maybe requiring the assumption that $k>d/2$?","['tensor-products', 'sobolev-spaces', 'functional-analysis', 'real-analysis']"
441550,Deformation of integration paths,"First of all: I'm more of an algebraic person. So happily differentials/integrals are not what I deal with a lot. However, I got this exercise to solve: Let $\Omega \subset \mathbb{R}^n$ open, $K: \Omega \rightarrow \mathbb{R}^n$ a $C^1$ vector field with $\partial_iK_j  = \partial_j K_i$ for $i, j= 1, ..., n$. Let $\gamma, \gamma ' \in C^1([0,1]; \Omega)$ be curves with $\gamma(0) = \gamma'(0)$ and $\gamma(1) = \gamma' (1)$. Let $\Phi \in C^2 ( [0,1] \times [0,1]; \mathbb{R}^n)$ be a homotopy between $\gamma$ and $\gamma'$. Then it is to show that $\int_{\gamma} K d x= \int_{\gamma '} K d x$. I know this holds for continous homotopies already, but I have to present the solution to a group of first years and the proof for general case seems a bit lengthy. But, here I have a $C^2$ homotopy, and I'd like to use it by showing $\frac{\partial}{\partial s} \int_{\Phi(s, -)} K dx = 0$ How can I do this?",['analysis']
441558,Finding a basis for a subspace in $\Bbb R^{2\times 2}$,"Find a basis for the space and determine its dimension. The space of all matrices $$A=\begin{pmatrix}a& b\\c& d\end{pmatrix}$$ in $\Bbb R^{2\times 2}$ such that $a + d = 0$ (in other words, the [sum of the] diagonal = 0). I'm not sure how to even begin this question.  Please help!","['matrices', 'linear-algebra']"
441564,Mean value theorem application for multivariable functions,"Define the function $f\colon \Bbb R^3\to \Bbb R$ by $$f(x,y,z)=xyz+x^2+y^2$$
  The Mean Value Theorem implies that there is a number $\theta$ with $0<\theta <1$ for which
  $$f(1,1,1)-f(0,0,0)=\frac{\partial f}{\partial x}(\theta, \theta, \theta)+\frac{\partial f}{\partial y}(\theta, \theta, \theta)+\frac{\partial f}{\partial z}(\theta, \theta, \theta)$$ This is the last question. I don't have any idea. Sorry for not writing any idea. How can we show MVT for this question?","['multivariable-calculus', 'calculus', 'real-analysis', 'analysis', 'derivatives']"
441571,Lights Out Variant: Flipping the whole row and column.,"So I found this puzzle similar to Lights Out, if any of you have ever played that.  Basically the puzzle works in a grid of lights like so: 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 When you selected a light (the X), it toggled itself and all the lights in its row and column: 1 0 1 0 1 1 X 1 0 1 1 0 0 0 0 0 This got me wondering how one could tell whether there was a solution for a given setup and grid size, and if so, what was it? I can't seem to get anywhere. Could anyone push me in the right direction?","['puzzle', 'algorithms', 'combinatorics']"
441574,"Characterization properties of number sets $\mathbb{N},\mathbb{ Z},\mathbb{Q},\mathbb{R},\mathbb{C}$","When people say that a structure is defined up to isomorphism means, accordingly, that they assume certain properties that make it completely determined under certain operations and relations. So, I'd like to know what the properties are that characterize the different systems of numbers ($\mathbb{N},\mathbb{Z},\mathbb{Q},\mathbb{R},\mathbb{C}$) up to isomorphism with the operations of $+,\cdot$, and $\leq$. To make my question clearer, for example I  guess the principle of induction would be part of characterizing $\mathbb{N}$, the least upper bound property would be part of characterizing $\mathbb{R}$, etc. The thing is that there are a lot of properties like these and it's not clear, at least for me, to decide what are the main ones and what of them can be deduced and are redundant, etc. In other words I'd like to ask which properties characterize each of the sets $\mathbb{N},\mathbb{ Z},\mathbb{Q},\mathbb{R},\mathbb{C}$ based on their operations and orderings.","['abstract-algebra', 'elementary-set-theory', 'real-analysis']"
441597,How to calculate what matrix will transform specified points to other specified points,"I want to transform an image. As far as I was able to find out, I can achieve this with a matrix, right? So here is my problem: how do I get this matrix if the only thing I know are the following starting and ending points? $$\begin{matrix}
\text{Starting Points} & \text{Target Points} \\
\mathrm{TL}(3,5)     &    \mathrm{TL}'(0,3) \\
\mathrm{TR}(5,5)     &    \mathrm{TR}'(3,3) \\
\mathrm{LL}(2,2)     &    \mathrm{LL}'(0,0) \\
\mathrm{LR}(6,1)     &    \mathrm{LR}'(3,0)
\end{matrix}$$",['matrices']
441604,Uniformly convergence in compact sets,"(Theorem 7.13 in Baby Rudin) Suppose $K$ is compact, and (a) $\{f_n\}$ is a sequence of continuous functions on $K$, (b) $\{f_n\}$ converges pointwise to a continuous function $f$ on $K$, (c) $f_n(x) \ge f_{n+1}(x)$ for all $x \in K, n = 1, 2, 3, \cdots$. Then $f_n \to f$ uniformly on $K$. I was reading this theorem in Baby Rudin, but the proof uses a trick that is not easy for me to come up with. What I had in mind was to work in the compact spaces (since $K$ compact and $f_n$ continuous) $f_1(K), f_2(K), \cdots$ directly, instead of in the domain $K$. I understand that (a) can give me a set of compact spaces $f_1(K), f_2(K), \cdots$; and (b) can help me construct a convergence sequence (but not sure in what space, since union of countably many compact sets is not necessarily compact); and (c) can give me a monotone function (again, not sure in what space). I got stuck at the point where a warning sign says: ""be careful about the union/intersection of countably many compact sets."" Any hint to proceed?",['real-analysis']
441631,Closure of a connected set is connected,"Let $(X,d)$ be  a metric space and let $E \subseteq X$ connected. I want to show that $\overline E$ is connected. How can I prove this in a nice way ?","['general-topology', 'connectedness', 'analysis']"
441638,"What is an example of a bounded, discontinuous linear operator between topological vector spaces?","I am thinking there might be an example between the space of compactly supported smooth functions on the real line (chosen because it is non-metrizable under the standard topology for this space of test functions) and $L^{1/2}[0,1]$ (chosen because it is not locally convex).",['functional-analysis']
441656,Are there Hausdorff spaces which are not locally compact and in which all infinite compact sets have nonempty interior?,"Here is the background material from which I am working: The Cantor set is an uncountable compact Hausdorff space with empty
interior. In a locally compact Hausdorff space, each countable set has empty interior. The rational numbers with the subspace topology is a non-locally compact Hausdorff space in which all compact sets have empty interior. I am trying to find a non-locally compact Hausdorff space in which all infinite compact sets have nonempty interior. I am guessing the example will be an exotic function space.","['general-topology', 'compactness']"
441672,Simplifying trig expression for Laplace transform,"I'm working on the following Laplace transform problem at the moment, and I'm a little stuck. $$\mathcal{L} \{\sin(2x)\cos(5x) \}$$ I don't recall any trig identity that would apply here. I know that $$\sin(2x) = 2\sin(x)\cos(x)$$ But I'm not sure if that applies in this situation. If you guys could point in the right direction I'd be most appreciative.","['trigonometry', 'laplace-transform']"
441685,Why are nonsquare matrices not invertible?,I have a theoretical question. Why are non-square matrices not invertible? I am running into a lot of doubts like this in my introductory study of linear algebra.,"['matrices', 'inverse']"
441691,Riemann-Stieltjes Integral computation (step function?),"Im trying to integrate this, using theorem 7.9 of apostol's book: $$\int^{10}_0 f(x)d\alpha(x) $$ $f(x) = x^2$ and $\alpha(x)= 3\chi(7,9](x)$
Where $\chi(x)$ is $0$ everywhere except $1$ in the interval $(7,9]$ So using this theorem, and knowing the steps are at 7, and 9, and everywhere else the sum and substraction of $\alpha$ is $0$ i get: $$f(7)[\alpha(7+)-\alpha(7-)] + f(9)[\alpha(9+)-\alpha(9-)] = $$
 $$= 7^2 (3*(1 - 0)) + 9^2 (3*(0-1)) = 3*7^2 - 3*9^2$$ Does this sound about right? In class we did a mostly theeoretical stuff with the R-S integral but not a single example so I'm i little lost.","['integration', 'real-analysis']"
441720,When does $a \cdot\sin(x) = \sin(a \cdot x)$?,I am examining the expression $a \cdot \sin(x) =\sin(a \cdot x)$ where $a$ is a rational constant. Is there a way to determine which values of $x$ would be valid? Does it only hold true for certain values of $a$?,"['trigonometry', 'number-theory']"
441721,The set of jumps of a càdlàg function is countable,"Let $f$ be defined on $[0, \infty)$ have all its left limits and be right continuous. Then is the set of discontinuity points of $f$ which are all jumps necessarily countable?","['real-analysis', 'analysis']"
441725,Partitions of a prime power into powers of the same prime,"Fix a prime $p$, and $k$ a natural number. The question is then: How many partitions of $p^k$ are there into powers of $p$? So, for instance, if $p = 2$ and $k = 2$, there are 4, namely (4), (2, 2), (2, 1, 1) and (1, 1, 1, 1). This seems like it could be a hard problem in number theory, but I don't really know much number theory (I'm a topologist), and so don't have a feel for such things.","['integer-partitions', 'number-theory']"
441732,Describing Functions on a Manifold,"Well, I have a pretty simple (probably silly and basic) doubt about how do we describe functions on a Manifold. Well, just to make clear which definitions I'm using, for now what I know is that: a topological manifold is a metric space $M$ such that for each $p\in M$ there's a integer $n$ with $n \geq 0$ such that we can find a neighborhood of $p$ homeomorphic to $\Bbb R^n$. A chart for a manifold $M$ is a pair $(x,U)$ with $U\subset M$ and $x : U \to \Bbb R^n$, if two charts overlap smoothly we say that they're $C^\infty$ related and a collection of $C^\infty$ related charts is an atlas for $M$. In that setting, a smooth manifold is a pair $(M,\mathcal{A})$ where $M$ is a topological manifold and $\mathcal{A}$ is one maximal atlas for $M$. So if I understood, providing a chart $(x,U)$ to a manifold $M$ is a way to introduce ""coordinates"" on $M$. Indeed, if $I : \Bbb R^n\to \Bbb R$ is the identity function we define $x^i = I^i \circ x$ to be the ""$i$-th coordinate function"" on $U$. In that case, for each $p \in U$ we have the coordinates $(x^1(p), \cdots, x^n(p))$ and if I understood correctly this is a way to allow us to bring to abstract spaces the usual notions of analysis over $\Bbb R^n$ (of course, in a refined manner, so that it fits the generality of the situation). Now the real question: this all led me to a doubt - how do we describe functions on a manifold? Well, this question might seem strange, but there's a point, if we work with $\Bbb R^n$, then each $a \in \Bbb R^n$ is an $n$-tuple of reals $a = (a^1,\dots, a^n)$ and so we can describe functions $f : \Bbb R^n \to \Bbb R$ by combining functions defined on $\Bbb R$ applied on each $a^i$. Indeed, we have the identity $I^i(a) = a^i$, and so we can easily define for instance $f : \Bbb R^2 \to \Bbb R$ by: $$f = \sin \circ I^1 - \sqrt{(I^1)^2 - (I^2)^2}$$ Now at a point $(a,b) \in \Bbb R^2$ we would have then: $$f(a,b)= \sin(I^1(a,b))-\sqrt{(I^1(a,b))^2-(I^2(a,b))^2}=\sin a-\sqrt{a^2+b^2}$$ So, to define the function $f(x,y)=\sin x - \sqrt{x^2+y^2}$ we can simply combine functions from $\Bbb R$ to $\Bbb R$ using the component functions of the identity function. My understanding is: we know how to build functions from $\Bbb R^n$ to $\Bbb R$ because we implicitly construct these combinations of functions constructed on $\Bbb R$ and the components of $I$. Now, on an arbitrary manifold, points are not necessarily $n$-tuples of numbers. The projective plane for instance is the set of all lines through the origin of $\Bbb R^n$, so although charts provide $n$-tuples for each point, each point is not itself one $n$-tuple, so the construction of functions from one arbitrary manifold to $\Bbb R$ would not be simply like that. But now here comes my understanding: we simply use the coordinate functions, exactly to work as we do in $\Bbb R^n$! For instance, let's suppose that $M$ is a smooth manifold of dimension $2$ and that $(x,U)$ is a chart, in that case $x : U \to \Bbb R^2$ and we have two coordinate functions $x^1 = I^1 \circ x$ and $x^2 = I^2 \circ x$, and with this we can express any function $f : U \to \Bbb R^2$ simply by combining $x^1$ and $x^2$ with usual functions defined on $\Bbb R$! For instance: $$f=\sin \circ x^1 - \cos \circ x^2$$ So that given $p \in U$ we would have $f(p) = \sin(x^1(p)) - \cos(x^2(p))$ which we would know how to compute. So is all of this correct? Is really this way that we usually set up functions on arbitrary manifolds? Is this the correct way to use charts on a manifold to work with it? Thanks very much in advance!","['manifolds', 'differential-geometry']"
441755,Finding the value of Pr(X<Y),"Consider the joint density $f_{X,Y}(x,y)=1/40$ inside the rectangle 0< x <5 and 0< y< 8. How do I calculate $Pr[X<Y]$ ?","['statistics', 'probability']"
441758,"What does ""isomorphic"" mean in linear algebra?","My professor keeps mentioning the word ""isomorphic"" in class, but has yet to define it... I've asked him and his response is that something that is isomorphic to something else means that they have the same vector structure. I'm not sure what that means, so I was hoping anyone could explain its meaning to me, using knowledge from elementary linear algebra only. He started discussing it in the current section of our textbook: General Vector Spaces. I've also heard that this is an abstract algebra term, so I'm not sure if isomorphic means the same thing in both subjects, but I know absolutely no abstract algebra, so in your definition if you keep either keep abstract algebra out completely, or use very basic abstract algebra knowledge, that would be appreciated.","['linear-algebra', 'terminology']"
441764,When does a solution to linear equations satisfy $|x_1|>\sum_{i=2}^n|x_i|$?,"Let $A\overline{X}=0$, where $A=(a_{i,j})\in M_{L, n}(\mathbb{C})$ is a given non-zero $L\times n$ matrix over the complex numbers $\mathbb{C}$, and $\overline{X}=(x_1, x_2, \cdots, x_n)^T $ is an $n$-column vector. Suppose $L< n$, then we know that the above equations have non-zero solutions.  My question is: What are the sufficient (and necessary) conditions on $A$ such that we can find one solution $\overline{X}$ satisfying: $$(P)\ \ \ \ \ \ \ \  |x_1|>\sum_{i=2}^n|x_i|$$ Here are some observations and remarks: We may assume $L>1$, since for $L=1$, $|a_{1,1}|<|a_{1,i}|$ for some $i>1$ is a sufficient condition. For $a_{i,1}\neq 0$, since $x_1=-\sum_{j=2}^n\frac{a_{i,j}x_j}{a_{i,1}}$, we know that a necessary condition for the property $(P)$ to be hold is that $\exists j>1$, s.t., $|a_{i,j}|>|a_{i,1}|$. My primary motivation to ask this question is that I want to consider equations in the general group algebras $\mathbb{Z}G$ for some countable discrete group $G$; see this problem: Find a special element in group algebra","['matrices', 'linear-algebra']"
441771,"Given $\mu$ the counting measure on an infinite set $\Omega$, $\lim \mu(A_n) \ne 0$","Problem: Let $\mu$ be the counting measure on an infinite set $\Omega$.  Prove that there is a sequence of sets $A_1 \supset A_2 \supset A_3 \dots$ such that $\bigcap A_n = \varnothing$, but $\lim_{n \to \infty} \mu(A_n) \ne 0$. Attempt :Choose a countably infinite set $\{x_i : i \in \mathbb{N} \}  = A_1 \subseteq \Omega$.   Define $A_n = \{x_i : i \ge n\}$  Then we have $A_1 \supseteq A_2 \dots$ with $\bigcap A_n = \varnothing$.
However, $\mu(A_n) = \infty$ for all $n$. Does my proof look correct?","['measure-theory', 'proof-verification', 'real-analysis']"
441788,What are zero divisors used for?,"This is the first time I hear this term. Specifically the assertion is that $\mathbb{Z}$ has no zero divisors. So, from my understanding this is because there are not two non-zero numbers $a,b\in \mathbb{Z}$ such that $ab=0$. Also I can see that this definition is related to the one I learnt in high school that $a$ divides $0$ if $\exists b\in\mathbb{Z}\ (ba=0)$, the difference being that we need to consider the restriction $a,b\neq 0$ when dealing with zero divisors. What is the motivation of zero divisors? what are they used for?",['abstract-algebra']
441791,The 10.4 Problem on Benassy's *Macroeconomic Theory*,"This a repost. In my first try at the problem here I was not very clear with my question and I was also troubled by my lack of knowledge of MathJax. And I probably lost the attention of you guys while trying to make things clearer. So here comes a second try: I'll post the problem: 10.4 A RBC model with generations We will study and solve analytically a simple model with generations where, as in reality, investment and consumption can react quite differently to productivity shocks. The model is adapted from Huffman (1995), who studies the more general case where agents have a positive probability of death. We assume that the population grows at the rate n, and the supply of
labor also grows at the rate n. Each generation of households lives forever, works only in the rst period of its life, and consumes in all periods by saving under the form of capital. The household of generation has a utility function: $$\sum_{t=\tau}^\infty\beta^t \log C_t $$ which it maximizes subject to the budget constraints: $$ C_t+K_{t+1}=L_t w_t, \qquad\text{for } t=\tau, $$
$$ C_t+K_{t+1}=R_t K_t, \qquad\text{for } t>\tau. $$ Finally the production function is Cobb-Douglas: $$ Y_t = A_t K_t^\alpha L_t^{1-\alpha}. $$ 10.4.1 Questions 1. Compute the values of consumption and investment as functions of
capital and output. 2. Show how consumption and investment respond to technology shocks. Now maximizing and manipulating the first order conditions you will get these answers for question 1 : $$C_{t}=(1-\beta)[Y_{t}+(1-\delta)K_{t}] \tag{1}$$ $$K_{t+1}=\beta[Y_{t}+(1-\delta)K_{t}]\tag{2}$$ $$I_{t}=\beta Y_{t}-(1-\beta +\delta\beta)K_{t} \tag{3}$$ Now here comes my puzzle with question 2 : I'm supposed to substitute the production function in every equation to show the interaction with the technology shocks  -- (1), (2) and (3). For instance, Equation (2) would become: $$K_{t+1}=\beta[A_tK^\alpha_{t}L^{1-\alpha}_t+(1-\delta)K_{t}]$$ Then I should try to solve the dynamics of capital in equation (2) and substitute the result in equations (1) and (3). But how can I do that? Log linearization does not seem give me a solution and it seems strange to assume $K_{t+1}$=$K_t$ (actually, can I do that?). I'll be glad if someone could point me the way. Observation : There is a solutions book of Benassy's Macroeconomic Theory available on the internet. You can google something like ""Benassy Solutions"" and you will find it. The solution for this problem is available at pages 83-84, but the book does not give the real answer for the second question of the problem. It says it would be ""tedious"" to derive the dynamics of capital and substitute in the equations of consumption and investment, so it just points the way (not with enough leads for me, at least) for the answer, as I described above.","['economics', 'ordinary-differential-equations', 'summation']"
441792,Points in unit square,"Let $n$ points be given in the unit square. How to prove or disprove: the points can be labeled $x_1,\ldots,x_n$ to satisfy the inequality $$\|x_1-x_2\|^2 +\|x_2-x_3\|^2+\cdots+\|x_n-x_1\| ^2 \le 4,$$ where $\|\cdot\| $ is the Euclidian distance ?","['geometry', 'inequality']"
441801,Help show angles at corner of a pyramid add up to more than $\pi$. (Picture included),"How can I prove that $\delta_i + \gamma_{i + 1} + \beta_{i + 1} \ge \pi$? Intuitively it seems clear because if you flatten the edge of the pyramid, you are going to have to make either $\delta_i$ or $\gamma_{i + 1}$ smaller. But my brain has not had any luck supplying a proof, although I know it must be more or less trivial. Can anyone help me out?",['geometry']
441805,Are there closed-form expressions for the real and imaginary functions?,"By ""real and imaginary functions"" I mean $\operatorname{Re}(z)$ and $\operatorname{Im}(z)$.",['complex-analysis']
441813,The sum of the residues of a meromorphic differential form on a compact Riemann surface is zero,"How can one see that the sum of the residues of a meromorphic function on a Riemann surface $
\Sigma_g$ of positive genus is always zero? This is not true for the Riemann sphere $\mathbb{CP}^1$.","['riemann-surfaces', 'complex-geometry', 'complex-analysis']"
441821,Inversion of a power series without a linear term,"Could someone explain me how to invert
$$
z = y e^{-y} = e^{-1} - \frac{1}{2e}(y - 1)^2 + \frac{1}{3e}(y - 1)^3 - \frac{1}{8e}(y - 1)^4 + \cdots
$$
around $y=1, z=e^{-1}$, so that $y$ is expressed as a series of $(1 - ez)$ ?
This is a part of example VI.8 in ""Analytic combinatorics"" by Flajolet and Sedgewick.
They skips the details of the inversion process.
Actually I am not so familiar with manipulating series expansions.
If someone could give some details of the method, I'll greatly appreciate for it.","['generating-functions', 'calculus', 'analysis']"
441888,$ \{x : P(x)\} $ vs. $ \{P(x) : x\} $ ---- When are these set-builder notations the same and different?,"I should clarify that I'm asking for intuition or informal explanations. I'm starting math and never took set theory so far, thence I'm not asking about formal set theory or an abstract hard answer. From Gary Chartrand page 216 Mathematical Proofs - $\begin{align} \text{ range of } f & = \{f(x) : x \in domf\} = \{b : (a, b) \in f \} \\ 
& = 
\{b ∈ B : b \text{ is an image under $f$ of some element of } A\} \end{align}$ Wikipedia - $\begin{align}\quad \{\text{odd numbers}\} & = \{n \in \mathbb{N} \; :  \; \exists k \in \mathbb{N} \; : \; n = 2k+1   \}     \\
& = \{2n + 1 :n \in \mathbb{Z}\} \end{align}$ But Why $G/G = \{gG : g \in G \} \quad ? \quad$ And not $\{g \in G : gG\} ?$ EDIT @Hurkyl 10/5. Lots of detail please. Question 1. Hurkyl wrote $\{\text{odd numbers}\}$ in two ways. But can you always rewrite $\color{green}{\{ \, x \in S: P(x) \,\}}$ with $x \in S$ on the right of the colon? How? $ \{ \, x \in S: P(x) \,\} =  \{ \, \color{red}{\text{ What has to go here}}  : x \in S \, \} $? Is $ \color{red}{\text{ What has to go here}} $ unique? Qusetion 2. Axiom of replacement --- Why $\{ f(x) \mid x \in S \}$ ? NOT $\color{green}{\{ \; x \in S \mid f(x) \;
 \}}$ ? @HTFB. Can you please simplify your answer? I don't know what are ZF, extensionality, Fraenkel's, many-one, class function, Cantor's arithmetic of infinities, and the like.","['intuition', 'elementary-set-theory']"
441902,Is this answer sufficient to prove? The question is related to second partial derivatives.,"Is this answer sufficient to prove ? Does there exist a notation mistake or else? Problem Suppose that the functions $\varphi: \mathbb R \rightarrow \mathbb R$ and $\psi: \mathbb R \rightarrow \mathbb R$ have continuous second partial derivatives. Define $f(x,y) = \varphi(x-y) + \psi (x + y), \quad \forall (x,y) \in \mathbb R^2.$ Prove that 
  $$
\frac {\partial^2f}{\partial x^2} - \frac {\partial^2f}{\partial y^2} = 0, \quad \forall (x,y) \in \mathbb R^2.
$$ Solution \begin{align}
\frac {\partial f}{\partial x} &= \varphi'(x-y) + \psi'(x+y) \\
\frac {\partial^2 f}{\partial x^2} &= \frac \partial{\partial x} \left( \frac {\partial f}{\partial x} \right ) = \varphi''(x-y) + \psi''(x+y)\\
\frac {\partial f}{\partial y} &= -\varphi'(x-y) + \psi'(x+y) \\
\frac {\partial^2 f}{\partial y^2} &= \frac \partial{\partial y} \left( \frac {\partial f}{\partial y} \right ) = \varphi''(x-y) + \psi''(x+y)
\end{align}
Then
$$
\frac {\partial^2 f}{\partial x^2} - \frac {\partial^2 f}{\partial y^2} = \varphi''(x-y) + \psi''(x+y) - \left [ \varphi''(x-y) + \psi''(x+y)\right ] = 0\quad \blacksquare
$$","['calculus', 'derivatives', 'real-analysis', 'solution-verification']"
441912,Proving that $\|A\|_{\infty}$ the largest row sum of absolute value of matrix $A$,"I am studying matrix norms. I have read that $\|A\|_{\infty}$ is  the largest row sum of absolute value and $\|A\|_{1}$ is the highest column sum of absolute values of the matrix $A$. However, I am not able to prove this. Are there any proof of these statements? Please help  and thanks for your time. Edit: Where $\|A\|_{\infty}$ is the matrix norm induced by the vector norm $\|x\|_{\infty}$.","['matrices', 'normed-spaces', 'linear-algebra']"
441917,Wald's second equation,"We have a random walk $S_N=\sum_{i=1}^{N}X_i$ where $X_i$ are i.i.d with $0<E(X_i)<\infty$ and $N$ is a stopping time.
What is the ""exact"" second equation of Wald ? I've seen different results and sometimes they are contradictory. Thank you","['probability-theory', 'stochastic-processes', 'probability']"
441919,What is the domain of the following function?,"Please tell me the domain of $y = \sin^{-1}(\sin(x))$ P.S. I think domain is $(-\infty, \infty)$ But my teacher says it is $(-\frac{\pi}{2}, \frac{\pi}{2})$. He says since $sine$ is a many one function, so its domain has to be confined in the interval of $(-\frac{\pi}{2}, \frac{\pi}{2})$ to make it an inverse function. Well I didn't quite understand. Please explain.","['trigonometry', 'functions']"
441936,Irreducible representation of dimension $5$ of $S_5$,"i am searching for a concrete as possible description of the (there are two but the are obtained from each other by tensoring with the signature representation) irreducible representation of dimension 5 of the symmetric group $S_5$ on 5 elements. [Fulton Harris] to my knowledge only computes the character. Wikipedia says it has something to do with an exceptional transitive embedding of
$S_5$ into $S_6$. Would love if someone could tell me a bit more about that.","['representation-theory', 'linear-algebra', 'finite-groups', 'symmetric-groups', 'group-theory']"
441968,Fourier transform using principal value,Can anyone help me  compute the Fourier transform of $ 1/|x|^{n-\alpha} $ in $\mathbb{R}^n $ where $ 0 < \alpha < n $ ? Somehow it becomes the principal value of $ 1/|x|^\alpha $ which I can't figure out.,"['distribution-theory', 'fourier-analysis', 'real-analysis', 'integral-transforms']"
441986,Distributions on manifolds,"Wikipedia entry on distributions contains a seemingly innocent sentence With minor modifications, one can also define complex-valued distributions, and one can replace $\mathbb{R}^n$ by any (paracompact) smooth manifold. without any reference cited. I went through Vladimirov, Demidov, Gel'fand & Shilov but could not find a single mention of the latter concept. Of course, I have an intuitive feeling of how to go about this, but I would need to use generalized functions on $S^1$ in my work and I don't want to inefficiently re-discover the whole theory if it exists anywhere already. Could anyone point me at a reference where I could learn more about distributions on smooth manifolds? NB this is not the same question as distributions supported , or concentrated , on a manifold embedded in $\mathbb{R}^n$. My space of test functions would also be defined on the same manifold so transverse derivatives are not defined.","['distribution-theory', 'functional-analysis']"
442017,Definitions of the usual order in $\mathbb{N}$,"I know of basically two ways of defining the usual order in $\mathbb{N}$: By using the relation ""$\in$"" on $\mathbb{N}$ so that $\forall m,n\in N(m<n\longleftrightarrow m\in n)$. By saying that $\forall m, n \in \mathbb{N}(m<n\longleftrightarrow \exists p\in \mathbb{N}(n=p+m))$. The first one seems to be more ""artificial"" and ""elemental"" in the sense that is more difficult to prove that it is indeed a linear order on $\mathbb{N}$. But such a definition is the one prefered by set theory books. 
So my question is why? since the second one is equivalent except that is much simpler and intuitive, at least I see it that way. Also what are the main advantages of using one over the other?, unless it's just a matter of taste. Edit: To make precise my question I'll add some extra context. First of all I'm starting the definition of $\mathbb{N}$ just as is made in set theory. It might be by taking the intersection of all inductive sets or else it might be by saying that a natural number is a transitive set with the relation $\in$ on it being a strict linear order...,etc.  The thing is essentially that I don't understand the fact of doing the defintion $(1)$ which is by far more elementary than just starting by proving the theorem of recursion and then making the definition of $+$ to get $(2)$, which, as I said, is simpler and more natural and intuitive. So I can't see the advantages of $(1)$ over $(2)$ and why set theory books prefer one over the other (This makes me think that I'm missing something). Also my observation is that having $(1)$ it's very easy to deduce $(2)$ by just defining $+$ by using the recursion theorem and then applying the principle of induction. At this point I don't know if its possible to deduce $(1)$ by having $(2)$. So I'm in doubt here because I'm assuming that both definition are equivalent, thought I don't now and if they aren't then there should be a reason why $(1)$ is the appropriate definition. But if they're equivalent, then I'd like to know the advantages or the reasons why $(1)$ is preferible over the other.","['natural-numbers', 'elementary-set-theory']"
442019,equivalent condition for moment generating function,"Consider a random variable $x$ with pdf $f(x)$, and have $x \ge 0$. The moment generating function is defined as $M(t)=\int^{\infty}_{-\infty}e^{-tx}f(x)dx$ (noted that we change the sign of $t$ compared with common case ). For convenient we consider only when $t>0$. The problem is: When would a function be the moment generating function of a distribution? There are some trivial conditions like $M(0)=1$ and $M(t)$ is strictly decreasing. But obviously these are not enough. An observation is that the $M(t)$ should lie in the convex hull of $e^{-tx}$. From inequality techniques we have $\log M(t)$ up convex. Is this condition sufficient? An related but a bit different problem is given $t_1,t_2,\dots,t_n$ and $M_1,M_2,\dots,M_n$ when there exist $M(t)$ such that $M(t_i)=M_i$? Add Jul 12: The reason that the up convex condition is not enough are as follows: Consider a function $\bar M(t)$ that it's logarithm is linear in an interval, using Cauchy inequality we can demonstrate that $\bar M(t)$ is composed of one $e^{-tx}$. But we can find other continuation.","['probability-theory', 'convex-analysis', 'analysis']"
442034,"Existence of solution of ODE $y^{\prime}=f(y,t)$ where $f(y,t)$ is not defined in initial value.","Consider a differential separable equation $$y^{\prime}=f(y,t)$$ with initial solution $y(t_0)=y_0$. Suppose that $f(y_0,t_0)$ is not defined. Is there a theorem which can be used to prove the existence and the uniqueness of the solution of this Differential Equation? The trouble is because $f(y_0,t_0)$ is not defined (much worse than discontinuous where we can still use Carathéodory's existence theorem) For example a separable differential equation $y^{\prime}=\frac{1}{y-1}+2$ with initial solution $y(0)=1$.","['ordinary-differential-equations', 'calculus', 'analysis']"
442043,Covering with most possible equal size subsets having pairwise singleton intersections,"Assume I have a non-empty finite set $S$ with $x=|S|$. I want to divide the set $S$ into subsets $S_1, S_2, .., S_n$ ( Edit: Yes, $S = \cup S_i$, and I'm embarrassed that I forgot to include that) such that: $ |S_i| = y, \forall 1 \le i \le n$  (The cardinality of each subset is fixed) $|S_i \cap S_j| = 1, \forall 1 \le i,j \le n, i \neq j$ (Each subset has exactly 1 element in common with any other subset) Edit: The second condition above excludes the possiblility of a pairwise disjoint division of subsets. Is there a way to determine the maximum value of $n$ (the number of possible subsets), given $x$ and $y$?",['combinatorics']
442061,How to compute $\int_{\mathbb{C}} \frac{|dz|^2}{|z-a_1| \cdot |z-a_2| \cdot |z-a_3|}$ explicitly?,"I have these integrals :
$$I_1= \int_{\mathbb{C}} \frac{|dz|^2}{|z-a_1| \cdot |z-a_2| \cdot |z-a_3|},$$
and
$$I_2= \int_{\mathbb{C}} \frac{|dz|^2}{|z-a_1| \cdot |z-a_2| \cdot |z-a_3| \cdot |z-a_4|}.$$
wherer $a_i \in \mathbb{C}$, and the $a_i$ are distincts. I can see that those integrals are well defined, but I need to evaluate them. Can they be computed explicitly ? Note : I would like an explicit value for these integrals, but failing that I am interested in the asymptotic value when $a_2 \rightarrow a_1$.","['definite-integrals', 'multivariable-calculus', 'closed-form']"
442062,To find the limit of three terms mean iteration,"We know that
the arithmetic-geometric mean  $AGM(a,b)$ of $a$ and $b$ defined as $$2a_1=a+b$$
$$b^2_1=ab$$ $$2a_n=a_{n-1}+b_{n-1}$$
$$b^2_n=a_{n-1}b_{n-1}$$ $AGM(a,b)=\lim\limits_{n\to \infty} a_{n}=\lim\limits_{n\to \infty} b_{n}$ $$AGM(a,b)=\frac{\pi}{4}\frac{a+b}{K(\frac{a-b}{a+b})}$$ where $K(m)$ is the complete elliptic integral of the first kind: $$\int _0^{\frac{\pi}{2}} \frac{1}{\sqrt{a^2 \cos^2(\theta) + b^2 \sin^2(\theta)}} \, d\theta = \int _0^{\frac{\pi}{2}}\frac{1}{\operatorname{AGM}(a,b)} \, d\theta = \frac{\pi}{2 \,\operatorname{AGM}(a,b)}$$ See Landen's_transformation I thought If we use three terms as shown below how it can be named? $$3a_1=a+b+c$$
$$3b^2_1=ab+ac+bc$$
$$c^3_1=abc$$ $$3a_n=a_{n-1}+b_{n-1}+c_{n-1}$$
$$3b^2_n=a_{n-1}b_{n-1}+a_{n-1}c_{n-1}+b_{n-1}c_{n-1}$$
$$c^3_n=a_{n-1}b_{n-1}c_{n-1}$$ Do they have the limit that all is equal and if yes how to find it? $x=F(a,b,c)=\lim\limits_{n\to \infty} a_{n}=\lim\limits_{n\to \infty} b_{n}=\lim\limits_{n\to \infty} c_{n} ?$ Does anybody know how to express such this kind of triple mean with known functions ?
Can we express $x$ as elliptic integrals? Thanks for answers EDIT: I tested for $a=1$ ,$b=2$,$c=3$ After just 2 iterations , I got
$a_2,b_2,c_2 \approx 1.92$ Seems that the results quickly go to a limit .","['special-functions', 'sequences-and-series', 'definite-integrals', 'elliptic-integrals', 'reference-request']"
442080,"What is the need for classifying numbers like integer, whole number etc?",what are the everyday life examples where we use the classification. I feel all the math behind the scenes(in computers weather etc ) is highly abstracted. I am looking for strong answers to tell the children when they ask me this question.,"['prime-numbers', 'linear-algebra', 'elementary-number-theory', 'number-theory']"
442081,Is a complex polynomial a regular covering? What is its group of deck tranformations?,"We know that a complex polynomial $P$ of degree $n$ is an $n$-sheeted covering from
$$\{\mathbb{C} - P^{-1}\{\text{critical values of }P\}\} \to \{\mathbb{C} - \{\text{critical values of }P\}\}. $$ 
So the question is how to determine whether such a cover is regular or not, and its group of deck transformations. The specific example I was trying was $P(Z)=Z^3 - 3Z$. The critical values are $\{2,-2\}$. So the group is $F_2$, i.e. the free group on 2 generators, and $$P^{-1}\{\text{critical values of }P\} = \underset{\text{corr. to }2}{\{2,-1\}} \cup \underset{\text{corr. to }-2}{\{-2,1\}}.$$ So here the group is $F_4$. I see the facts that a small simple loop around $2$ maps to a simple loop around $2$, and small simple loop around $-1$ maps to a double loop around $2$. And similar for preimage of $-2$. We know that if the image of the fundamental group of domain is normal in fundamental group of codomain, then the covering is regular. So can we fix a point and say that a simple loop just going around 2 will map to a simple loop going around 2 and similarly for other points? I guess not (because then the image would be whole group, which contradicts the fact that it is a $3$-sheeted cover). So how to proceed? Can anybody help?","['riemann-surfaces', 'algebraic-topology', 'complex-analysis']"
442109,geometric interpretation of a height inequality of prime ideals,"Theorem 15.1 in Matsumura's Commutative Ring Theory states that if $f:A\rightarrow B$ is a homomorphism of Noetherian rings, $P \in \operatorname{Spec}B, P \cap A=p$, then $ht (P) \le ht(p) + \dim B_P/pB_P$. He proceeds to say that we can replace $A$ by $A_p$ and $B$ by $B_P$ and then the inequality becomes $\dim B \le \dim A + \dim B/mB$, where $A,B$ are now local rings and $m$ is the maximal ideal of $A$. Indeed, i can see why this is true.
He then states: ""rewriting the original inequality in this form makes the geometrical content clear"". My question is: what is the geometrical content?","['commutative-algebra', 'algebraic-geometry']"
442129,Limiting value of functions - From Tao Analysis II,"Let $(X,d_X)$ and $(Y,d_Y)$ be metric spaces,$E \subseteq X$ and $f:E \rightarrow Y$ a function. If $x_0 \in \overline E$ we define
$$
 \lim_{x \rightarrow x_0;x \in E} f(x) = L 
$$ iff
$$
\exists L \in Y \forall \epsilon > 0 \exists \delta > 0 \forall x\in E: d_X(x,x_0) < \delta \rightarrow d_Y(f(x),L) < \epsilon \qquad (1)
$$ He then gives the following exercise: Let $x_0 \in E$. Then $\lim_{x \rightarrow x_0; x \in E} f(x)$ exists $\iff$ $\lim_{x \rightarrow x_0; x \in E \setminus \{x_0\}} f(x)$ exists. Further we have that if $\lim_{x \rightarrow x_0; x \in E} f(x)$ exists, then the limit equals $f(x_0)$. First the implications: From left to right is trivial. But what if $x \in E \setminus \{x_0\}$ ? Why does then (1) also hold for $x_0$ itself ? I got some edits: The implication $\Leftarrow )$ also requires that the limit equals $f(x_0)$. Sorry for that. Then the equivalence is true. Further I see that Tao doesn't intend that for example the function $f(x)= 1$ if $x = x_0$ and $f(x) = 0$ otherwise should have a limit where $E = \mathbb R$. First, if we consider $E \setminus \{x_0\}$ we have that the limit equals $0$. In fact if the limit exists and $x_0 \in E$ then the function must be continous.",['analysis']
442132,Finding Curvature,"A curve is described by the vector $f(t)=(3e^t, 4e^t)$.
I found that the curvature is equal to $0$.
I am confused on how to explain geometrically why the curvature is zero.","['multivariable-calculus', 'curvature', 'differential-geometry']"
442140,Isomorphisms of $\mathbb P^1$,"Prove that every iso morphism of $\mathbb P^1$ (over an algebrically closed field $\mathbb K$) is of the form 
  $$
\phi(x_0: x_1) = (ax_0+bx_1 : cx_0 + dx_1)
$$
  where $\begin{pmatrix} a & b \\c & d\end{pmatrix} \in GL(2, \mathbb K).$ There are some hints; I show you what I've done. 1 . Show that the action of $PGL(2, \mathbb K)$ on $\mathbb P^1$ is transitive. Well, I think this is quite intuitive, but I can't find a rigorous proof. Let us pick two distinct points $x=(x_0:x_1)$ and $y=(y_0 : y_1)$. I want to find an invertible matrix $A$ s.t. $Ax = y$. It is easy to see that this system (the unknowns are the entries of $A$) has always solutions (and maybe one can find one solution s.t. $ad-bc \ne 0$). My question is: is there an easier way to see that this action is transitive? Is it enough to say ""It's trivially true in the affine case so it must be true in the projective space as well""? 2 . Using the fact that every isomorphism of $\mathbb A^1$ is of the form $t \mapsto at+b$ (for some $a \ne 0$), prove the claim for morphisms s.t. $\phi(0:1)=(0:1)$. Suppose $\phi$ is a morphism s.t. $\phi(0:1)=(0:1)$. If we restrict $\phi\vert_{U_0}$ we obtain a morphism of $U_0 \simeq \mathbb A^1$, hence it must of the form 
$$
\phi(1:x) = (1:ax+b) 
$$
i.e. 
$$
\phi(x_0:x_1) = (x_0:ax_0+bx_1) 
$$ Is this correct? Why shall I assume that $(0:1) \mapsto (0:1)$? 3. Conclude. I don't see how to conclude at this point, I'm puzzled. Could you please help me? Thanks.","['algebraic-geometry', 'abstract-algebra', 'projective-geometry']"
442142,"Lebesgue density for other probability measures on $[0,1]$","Does the Lebesgue density theorem hold for arbitrary (Borel) probability measures on $[0,1]$? Following Downey & Hirschfeldt's proof leads me to believe that the answer is ""yes"". (Recall every probability measure on $[0,1]$ is regular , which is a key step in the proof.) But I feel that if this is true, it would be easy to find it stated somewhere, though I've not been able to. All proofs, statements, mentions, etc. that I've seen regard only the Lebesgue measure. (I've looked in Royden's, Folland's, and Billingsley's books in addition to Downey & Hirschfeldt's.) If it does hold, is there a good reason why it's received so little attention (if it indeed has)?","['probability-theory', 'measure-theory', 'reference-request']"
442153,Why is a section of a sheaf over closed set defined this way?,"Why is a section of a sheaf $F$ over closed set $S \subset X$ is defined as inductive limit $$ \varinjlim_{S\subset U} F(U)\; ?$$
From my point of view, we should define it as a function, which each point $x \in S$ maps to $F_x$, such that $S$ can be covered by open sets $U_i$, and there are sections $s_i \in F(U_i)$, which coincide in stalks. Is it equivalent? Maybe, for sufficiently good topological spaces?","['general-topology', 'sheaf-theory', 'algebraic-geometry', 'definition']"
442168,Fundamental group and Riemann surfaces,"Compact surfaces are classified up to homeomorphism by their fundamental group (defined up to isomorphism). However, 2 compact Riemann surfaces may well be homeomorphic but not conformally equivalent. Still, they are related to their fundamental groups by the fact that the universal cover map is holomorphic : so for say a compact hyperbolic Riemann surface $M$, it can be described as the quotient of the upper half plane under the action of a Fuchsian group which is isomorphic to the fundamental group. That Fuchsian group is not unique though. My question is this : what is the notion of equivalence needed for two Fuchsian groups to generate the same (hyperbolic) Riemann surface ? It needs a priori to be stronger than just isomorphism.","['riemann-surfaces', 'group-theory']"
442173,what does $|x-2| < 1$ mean?,"I am studying some inequality properties of absolute values and I bumped into some expressions like $|x-2| < 1$ that I just can't get the meaning of them. Lets say I have this expression $$ |x|<1.$$ This means that $x$ must be somewhere less than $1$ or greater than $-1$ which means that $$-1 < x < 1.$$ So basically $|x|<1$ and $-1 < x < 1$ are the same thing. $$|x|<1 \iff -1 < x < 1 \iff\text{""Somewhere less that $1$ or greater than $-1$"" or between $-1$ and $1$}$$ Now lets say I have $$ |x-2| < 1.$$ This means that the result of the expression $|x-2|$ must be less than $1$ or greater than $-1$? What does that also mean for $x$? Is it that $x$ must be a value that when we subtract $2$ the result has to stay withing the bound of $-1$ or $1$ or less than zero? If $x =5$ the statement fails because $3 <1$ is false. So it has to determine a boundary of $x$'s that satisfy this equation right? if $|x| = |-x|$ what can this mean for $|x-2| = |-x-2|$ or $|x+2|$ or $|-x+2|$ ? Thank you","['absolute-value', 'algebra-precalculus', 'intuition']"
442178,"Given a matrix with non-negative real entries, can you algebraically prove that it has a non-negative eigenvalue?","I am looking specifically for an algebraic proof, but if you can offer both algebraic and topological proofs, I will appreciate it even more.","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
442197,Weakly compact implies bounded in norm [duplicate],"This question already has an answer here : Does weak compactness imply boundedness in a normed vector space (not necessarily complete)? (1 answer) Closed 10 years ago . The weak topology on a normed vector space $X$ is the weakest topology making every bounded linear functionals $x^*\in X^*$ continuous. If a subset $C$ of $X$ is compact for the weak topology, then $C$ is bounded in norm. How does one prove this fact?","['functional-analysis', 'banach-spaces', 'general-topology', 'normed-spaces', 'compactness']"
442209,Prove that $\sin 10^\circ \sin 20^\circ \sin 30^\circ=\sin 10^\circ \sin 10^\circ \sin 100^\circ$?,"$\sin 10^\circ \sin 20^\circ \sin 30^\circ=\sin 10^\circ \sin 10^\circ \sin 100^\circ$ This is a competition problem which I got from the book ""Art of Problem Solving Volume 2"". I'm not sure how to solve it because there's just so many possibilities of using most of the trig identities that I don't know which path to take. One way I tried is canceling out the $\sin 10$ on both sides: $\sin 20^\circ \sin 30^\circ= \sin 10^\circ \sin 100^\circ$ $2 \sin 10^\circ \cos 10^\circ \sin 30^\circ=\sin 10^\circ \sin 100^\circ$ $2 \sin 80^\circ \sin 30^\circ= \sin 100^\circ$ $2 \sin 80^\circ \sin 30^\circ= \sin 30^\circ \cos 70^\circ+\sin 70^\circ \cos 30^\circ$ $2 \sin 80^\circ \sin 30^\circ=\sin 20^\circ \sin 30^\circ+\sin 70^\circ \sin 60^\circ$ $2 \sin 80^\circ \sin 30^\circ=\sin 20^\circ \sin 30^\circ + 2\sin 70^\circ \sin 30^\circ \cos 30^\circ$ $2 \sin 80^\circ \sin 30^\circ=\sin 20^\circ \sin 30^\circ + 2\sin 70^\circ \sin 30^\circ \sin 60^\circ$ $1=\large \frac {\sin 20^\circ}{2 \sin 80^\circ}+ \frac {\sin 70^\circ \sin 60^\circ}{\sin 80^\circ}$ Now I set $\sin^2 \theta=\large \frac {\sin 20^\circ}{2 \sin 80^\circ}$ and $\cos^2 \theta =\large \frac {\sin 70^\circ \sin 60^\circ}{\sin 80^\circ}$ I solves for $\sin \theta$ and $\cos \theta$ and set up a right triangle, which then led me to the equation $\sin 70^\circ \sin 60^\circ=\sin 80^\circ-\frac 12 \sin 20^\circ$ Another approach I tries is from the beginning having $\sin 10^\circ \sin 20^\circ \sin 30^\circ=\sin^2 10^\circ  \sin 100^\circ$ and the using the power-reducing formula, but that also got me nowhere. Any help is appreciated. Thanks.","['trigonometry', 'algebra-precalculus']"
442210,How to find the value of this integral,"Can someone please explain how $$\tfrac{1}{2\pi a^2} \int_0^{2\pi}e^{-(n-1)i\theta}[1+\tfrac{e^{2i \theta}}{a^2}+\tfrac{e^{4i \theta}}{a^4}+\cdots] \, d\theta =0 $$ when $n$ is even ?","['integration', 'complex-analysis']"
442221,"If $A$ is a $3\times 3$ complex matrix such that $A^3=-I$, then $A$ has distinct eigenvalues?",Let $A$ be a $3\times 3$ complex matrix such that $A^3=-I$ How to show that $A$ has distinct eigenvalues? What if i consider $A=-I?$ Isn't then -1 becoming the only eigen value?,['linear-algebra']
442934,Triangular numbers and the harmonic mean,"This morning somebody called my attention to the fact that $4T_n$ is the harmonic mean of $T_{2n}$ and $T_{2n+1}$, where $T_n=n(n+1)/2$ is the $n$th triangular number.  I verified this algebraically but - Do you know a conceptual reason why this is happening? It makes sense to me that $4T_n$ sits between $T_{2n}$ and $T_{2n+1}$ in some sort of nice way, since $T_{2n}=3T_n+T_{n-1}$ and $T_{2n+1}=3T_n + T_{n+1}$.  But why the harmonic mean?","['elementary-number-theory', 'algebra-precalculus']"
442949,Variance of minimum of N random variables,"Let $X_1,X_2,\dots,X_N$  be i.i.d. random variables with support $[0,M]$, and with density and distribution functions $f_X(x)$ and $F_X(x)$ respectively. 
Given 
$Y= \min_{i\in \{1,\dots,N\}} X_i$ , how does one obtain the variance of $Y$? My approach so far: $F_Y(y) = 1 - [1-F_X(y)]^N$, hence $f_Y(y) = Nf_X(y)[1-F_X(y)]^{N-1}$. So we have \begin{align} E[Y^2] &= \int_0^M y^2 Nf_X(y)[1-F_X(y)]^{N-1} dy\\ 
&=  \Big[-y^2 [1-F_X(y)]^{N}\Big]_0^M + \int_0^M 2y [1-F_X(y)]^{N} dy\\
&= 2\int_0^M y [1-F_X(y)]^{N} dy
\end{align} and similarly \begin{align}E[Y] &= \int_0^M y Nf_X(y)[1-F_X(y)]^{N-1} dy\\
& = \Big[-y [1-F_X(y)]^{N}\Big]_0^M + \int_0^M  [1-F_X(y)]^{N} dy\\
&= \int_0^M [1-F_X(y)]^{N} dy.
\end{align}
Hence, $$\text{var}(Y)  =  E[Y^2] - (E[Y])^2 =  2\int_0^M y [1-F_X(y)]^{N} dy - \Big[\int_0^M [1-F_X(y)]^{N} dy\Big]^2.$$ I feel something is wrong about the final expression I have obtained for $\text{var}(Y)$. The first term depends $2\int_0^M y [1-F_X(y)]^{N} dy $ on the magnitude of the values of $y$, while the second term $\int_0^M [1-F_X(y)]^{N} dy$ doesnt depend on the magnitude of the values of $y$ (it just integrates probabilities over the entire support of $y$). Hence, I feel that by scaling $Y$, the first term can be made arbitrarily small, while the second term remains constant. This could result in a negative variance, which is impossible! Could anyone tell me if I am going wrong, and if so, where I'm going wrong?","['probability-theory', 'probability-distributions']"
442950,Show that: $\lim\limits_{r\to\infty}\int\limits_{0}^{\pi/2}e^{-r\sin \theta}\text d\theta=0$,"I would like to show $\lim\limits_{r\to\infty}\int_{0}^{\pi/2}e^{-r\sin \theta}\text d\theta=0$ . Now, of course, the integrand does not converge uniformly to $0$ on $\theta\in [0, \pi/2]$ , since it has value $1$ at $\theta =0$ for all $r\in \mathbb{R}$ . If $F(r) = \int_{0}^{\pi/2}e^{-r\sin \theta}\text d\theta$ , we can find the $j$ th derivative $F^{(j)}(r) = (-1)^j\int_{0}^{\pi/2}\sin^{j}(\theta)e^{-r\sin\theta}\text d\theta$ , but I don't see how this is helping. The function is strictly decreasing on $[0,\pi/2]$ , since $\partial_{\theta}(e^{-r\sin\theta})=-r\cos\theta e^{-r\sin \theta}$ , which is strictly negative on $(0,\pi/2)$ . Any ideas?","['calculus', 'integration', 'real-analysis', 'complex-analysis', 'limits']"
442958,Commutant of bounded linear operators on a Hilbert space,"Given a Hilbert space $H$, denote by $\mathcal{A}=\mathcal{B}(H)$ the C*-algebra of bounded linear operators on $H$. Denote further by $$\mathcal{B}(H)' := \{A\in \mathcal{B}(H) : [A,B]=0 \;\forall B \in \mathcal{B}(H)\}$$ the commutant of $\mathcal{B}(H)$. I think $\mathcal{B}(H)' = \{\lambda \mathbb{1}:\lambda \in \mathbb{C}\}$, but how can proof this? Are the elements of $\mathcal{B}(H)'$ invertible in $\mathcal{B}(H)'$? (Then my claim would follow by the Gelfand-Mazur theorem...)","['operator-algebras', 'functional-analysis']"
442966,Bifurcation of integral curves,"Consider the following first order ODE:
$$\frac{\operatorname{d}\!y}{\operatorname{d}\!x} = x^2 - y^2$$
Despite the fact that this ODE has a very simple expression, it is not solvable in terms of elementary functions. (We need the so-called Bessel function $J_u(z)$, where $u \in \mathbb{R}$ and $z \in \mathbb{C}$.) I've used AutoGraph to plot the direction field and to plot several integral curves. There is a clear separation of the plane. Your eye will no-doubt pick out two very heavily coloured curve-like regions. The underlying curves form a bifurcation set: choosing points on either side give qualitatively different integral curves through those points. Is there a general way to find an equation or a parametrisation for the bifurcation set? Or do we have to be able to solve the ODE explicitly? If it isn't possible to find the bifurcation set explicitly, then is there any way to find other information, e.g. how many regions the bifurcation set separates the plane into? (In my example, the plane is separated into three regions.) Addendum: Here's a plot to show that the lines $y = \pm x$ ($x^2-y^2=0$) have no local significance to the integral curves. They lines $y=\pm x$ do seem to be asymptotes for some of the integral curves.","['bifurcation', 'ordinary-differential-equations']"
442979,Why does $\lim\limits_{x\to0}\sin\left(\left|\frac{1}{x}\right|\right)$ not exist?,"Can someone explain, in simple terms, why the following limit doesn't exist? $$\lim \limits_{x\to0}\sin\left(\left|\frac{1}{x}\right|\right)$$ The function is even, so the left hand limit must equal the right hand limit. Why does this limit not exist?","['trigonometry', 'limits']"
442987,"Can somebody correct my proof? : if f is continuously differentiable, then f is differentiable.","Theorem: Let $U\subseteq \Bbb R^n$ be open. If $f$ has continuous first partial derivatives in $U$ then $f$ is differentiable in $U$. Proof: Let's prove that if $f$ is differentiable at $a$ then $T(h)=Df(a).h$ ,where T(h) is total derivative. Let's set $T(h)= (\alpha_1.h+\alpha_2.h+...+\alpha_n.h)=(\alpha_1,...,\alpha_n).h $ Since $f$ has continuous derivatives, $$\lim_{h\to0}\frac{f(a+h)-f(a)-T(h)}{\Vert h\Vert}=0 \tag 1$$ by the first order approximation theorem. Set $h:=te_i$ for $t>0$ $$\begin{align}
\lim_{h\to0}\frac{f(a+h)-f(a)-T(h)}{\Vert h\Vert}&=\lim_{h\to0}\frac{f(a+te_i)-f(a)-\alpha_it}{t} \\
&=\frac{f(a+te_i)-f(a)}{t}-\alpha_i
\end{align}$$ $\lim_{t\to 0^+}\frac{f(a+te_i)-f(a)}{t}=\alpha_i$ by the equation (1) We also need to check this limit for $t<0$ Do I prove the theorem? Is this proof enough? Do I have mistakes ? Please can one correct my proof? Thank you:)","['calculus', 'real-analysis', 'analysis']"
442989,Posterior Distribution of a Prior Variable,"Let $X_{1},\dots,X_{n}$ be a random sample from an exponential distribution with density $f(x;\theta)=\theta e^{-\theta x}$, $x>0$ (having mean $1/\theta$). Assume a prior density for $\theta$ which is also exponential with mean $1/\beta$, where $\beta$ is known. Prove that the posterior distribution of $\beta$ is a gamma distribution. --In general, the posterior distribution would be $\pi(\beta\mid \mathbf{x})=f(\mathbf{x}\mid \beta)\pi(\beta)/m(\mathbf{x})$, where $m(\mathbf{x})$ is the marginal probability of $x$. The part that I am stuck at has to do with being given $f(\mathbf{x}\mid\theta)$, not $f(\mathbf{x}\mid\beta)$. Any help is appreciated!","['statistics', 'bayesian']"
443004,Logic/Intuition behind the Uniqueness Theorem,"So the uniqueness theorem is: 
Consider the following IVP.
$$y'=f(t, y)$$
$$y(t_o)=y_o$$
If $f(t,y)$ and $df\over dy$ are continuous functions in some rectangle $a < t < b$, $d < y < z$ containing the point $(t_o, y_o)$ then there is a unique solution to the IVP in some interval to $h < t < t_o + h$ that is contained in $a < t < b$. I cannot seem to wrap my head around why this must be true (the intuition), I'm sure it must be pretty obvious since there are not any other questions concerning this on stackexchange.",['ordinary-differential-equations']
443047,Show that every finite group of order n is isomorphic to a group of permutation matrices,"Show that every finite group of order n is isomorphic to a group consisting of n x n permutation matrices under matrix multiplication. (A permutation matrix is one that can be obtained from an identity matrix by reordering its rows) I can't even understand the question. I think a group of n x n permutation matrices is not isomorphic to finite group of order n.
I think it is isomorphic to Sn. Help me plz!","['finite-groups', 'group-theory', 'abstract-algebra']"
443056,Show that $\int_{0}^\infty \frac{1-\cos x}{x^2}dx=\pi/2$.,"I am trying to show that $$\int_{0}^\infty \frac{1-\cos x}{x^2}dx=\pi/2.$$The hint is ""try simple substitution"", and not incidentally, the previous problem has shown that $\int_0^\infty \frac{\sin^2(xu)}{u^2}du=\frac{\pi}{2}|x|$. This looks an awful lot like we'd like to reduce it to the earlier case, for $x=1$. What shall we try to substitute for? I think we'd have some problems subbing for cosine, since it does not approach a limit at infinity (correct me if there is a way to make this substitution). Subbing for $x^2$ hasn't gotten me anywhere. We might want to try to split it up, and see if anything better comes out of trying to integrate $\int_0^\infty \frac{\cos x}{x^2}dx$. No luck there so far. Any ideas?","['calculus', 'integration', 'real-analysis']"
443061,Convergence of Matrix Series,"I would just like a quick sanity check. If I have a matrix $ M $, then the series $ 1 + M + M^2 + M^3 \cdots $ converges to $ (1-M)^{-1} $ if the operator norm $ \lVert M \rVert_{\mathrm{op}} < 1$. Is it sufficient to show that each column vector $ v $ of $ M $ has norm $ \lVert v\rVert_{L^2} < 1 $?","['matrices', 'analysis']"
443068,"Every integer is congruent modulo $m$ to exactly one integer in $\{0, 1, ..., m-1\}$","Show that every integer is congruent modulo $m$ to exactly one of the numbers in the set $\{0, 1, ..., m-1\}$. I tried this: Apply the division algorithm - then $n = q \cdot m+r$ where $q, r$ are integers and $0 \le r < m$. In other words, $n$ is congruent (mod $m$) to $r$, and $r$ is in that set. Suppose there are two integers in the set, $r$ and $s$, both of which are congruent (mod $m$) to $n$. Then $r$ is congruent (mod $m$) to $s$, so either $r-s$ or $s-r$ is a non negative multiple of $m$, less than $m$, so it must be 0. $$r-s = 0 \qquad \text{ or }\qquad s-r = 0$$ Either way $s = r$. The problem is: We know that if $n \ge 0$, then $n$ is congruent mod $m$ to a number $r$ with $0 \le r < m$ by the division theorem. For an integer $a < 0$, find some multiple $k$ of $m$ so that $a + mk > 0$. Then by the division theorem, $a + mk = mq + r$ with $0 \le r < m$. Then $a = r \pmod m$.",['number-theory']
443079,Discrete Math Question: arithmetic progression [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question A lumberjack has $4n + 110$ logs in a pile consisting of n layers. Each layer has two more logs than the layer directly above it. If the top layer has six logs, how many layers are there? Write the steps to calculate the equation for the problem and state the number of layers. It's given that the top layer has 6 logs and each layer below that gains 2 logs per layer. 1st layer: 6 2nd layer: 6 + 1(2) = 6 + 2 = 8 3rd layer: 6 + 2(2) = 6 + 4 = 10 4th layer: 6 + 3(2) = 6 + 6 = 12 5th layer : 6 + 4(2) = 6 + 8 = 14 and so on the nth layer: $a_n = 6 + 2(n-1)$ 1st term 6 and common difference 2 with n terms 1st term: $a_n = 6$ last term: $a_n = 6 + 2n + 4$ $S_n = (n/2)(a_1 + a_n)$ $$4n + 110 = (n/2)(6 + 6 + 2(n-1))$$ Can anyone help break this equation down to solve for n?",['discrete-mathematics']
443084,Another doubt about real functions on manifolds,"Well, some days ago I've asked here how do we describe functions on manifolds. My idea was that it could be done using the coordinate functions of a chart: if $(x,U)$ is a chart for a manifold $M$ then we can define one function $f : U \to \Bbb R$ as a combination of the $x^i$ functions. Now I have one doubt that seems very silly (the answer is probably obvious, and I'm failing to see it). Now here comes my doubt: let $C^{\infty}(U\subset M,\Bbb R)$ be the set of all smooth functions defined in the subset $U$ of a manifold $M$ of dimension $n$. I've defined a $k$-combination to be a map $$c:\prod_{i=1}^k C^{\infty}(U,\Bbb R) \to C^{\infty}(U,\Bbb R)$$ so for instance, for $k=2$ the map $c(f,g)=\lambda f + \sin \circ g$ would be a $2$-combination of $f$ and $g$. Now, let $k = n$, then trivially by the definition we have that: $$c(x^1,\dots,x^n)\in C^\infty(U,\Bbb R)$$ My question is: do we have that for any $f \in C^\infty(U,\Bbb R)$ there exists a unique $n$-combination of the functions $x^i$ such that $f = c(x^1,\dots, x^n)$? In other words, do we have that any function defined on $U\subset M$ is a suitable combination of the coordinate functions? Thanks very much in advance!","['manifolds', 'differential-geometry']"
443094,Property of convex functions.,"I have seen the following argument: If $F: \mathbb{R}^n \to \mathbb{R}$ is a convex function, then there exist a Borel function $\lambda\colon\mathbb{R}^n \to \mathbb{R}^n$ bounded on compact subsets, and such that
  \begin{equation}
F(w) \ge F(z) + \langle \lambda(z), w-z\rangle
\end{equation}
  for every $z,w \in \mathbb{R}^n.$ Why is this true? Can you give one answer or a reference? if you know something similar, please tell me.
 Thank you.",['analysis']
443097,Primes and the Unit circle.,"Consider the ""prime spiral"" $f(z) = \sqrt{z}\exp(2\pi i \sqrt{z})$, for integer $z$. It has been shown that the intersections of $f$ with some quadratic curves contain a significantly disproportionate number of primes. Let $P = \{\exp(2\pi i \sqrt{p}) \;:\ p \;prime \}$, the set of unitized prime spiral coordinates. 1) Is $P$ equal to the circle group or is it a proper subset? (note that $P$ is countable) 2) What is the complement of $P$ in the circle group? 3) Is the complement a group? 4) Is the circle group equal to the closure of $P$?","['prime-numbers', 'complex-analysis', 'group-theory', 'real-analysis']"
443108,Bessel function values,"Given $$J_m(x)=\sum_{n=0}^{\infty}{{(-1)^n}\over{n!(n+m)!}}\left(\frac{x}{2}\right)^{m+2n},$$ where $m=0,1,2,\ldots$ and $x\ge0$. Need to show $$\left|J_m(x)\right|\le1.$$","['ordinary-differential-equations', 'special-functions']"
443132,Showing that $\Omega$ is of class $C^1$,"I have done a lot in this problem, but unfortunately it is not enough to solve it, answers or hints are very welcome. Let $B$ be a rectangle in $\mathbb R^2$ and consider $\varphi\colon B\to\mathbb{R}^3$ of class $C^1$. For any $y\in\mathbb{R}^3\setminus\varphi(B)$, define
$$\Omega(y) = \int_\varphi\frac{1}{|y-x|^3}(y-x)\,dS_x.$$
Show that $\Omega$ is of class $C^1$ as a function in variable $y$. At this point I could find that
$$\frac{\partial\Omega}{\partial y_1}(y)=\int_{\partial\varphi}\frac{1}{|y-x|^3}(0,x_3-y_3,x_2-y_2)$$
 $$\frac{\partial\Omega}{\partial y_2}(y)=\int_{\partial\varphi}\frac{1}{|y-x|^3}(x_3-y_3,0,x_1-y_1)$$
and $$\frac{\partial\Omega}{\partial y_3}(y)=\int_{\partial\varphi}\frac{1}{|y-x|^3}(x_2-y_2,x_1-y_1,0).$$
Now, all I have to do is show that any one of these is continuous as a function of $y$, and that is where things are getting hard. Thanks.","['continuity', 'integration', 'real-analysis', 'analysis']"
443136,Find the point where $3x-4y+25=0$ is a tangent to the circle $x^2+y^2=25$,Find the coordinates of the point where the line $3x-4y+25=0$ is a tangent to the circle $x^2+y^2=25$. Can someone please show me the first few steps of solving the simultaneous equation?,['algebra-precalculus']
443141,Green's Function Divergence,"Given a domain $ \Omega \in \mathbb{R}^2 $, and a PDE of the form $ L = a(x) \partial_x^2 + b(x) \partial_y ^2 $ for $ x \in \Omega $ , the green's function $ G(x,y) : \Omega \times \Omega \rightarrow R $ satisfies $ L G(p,q) = \delta(q-p) $ and $ G(p,q) = 0 $ for $ q \in \partial \Omega $. I would like to understand the divergences of the green's function near the diagonal. In particular, what sort of divergent terms will appear? My feeling is that there is only a  logarithmic divergences, and a dipole-like term. Reasoning is that roughly speaking, I should be able to take care of the $ \delta $ with a logarithm, and then correct with bounded functions. Precisely for $ x_0 \in \Omega $, split off the zeroth order term of the PDE. $$ L  = L_0 + L_r $$ where $$ L_0 =  a(x_0) \partial_x^2 + b(x_0) \partial_y ^2  + L_r  \\ L_r = ( da \cdot (x-x_0)\partial_x^2 +  db \cdot (x-x_0)\partial_x^2) + O((x-x_0)^2) $$ Now we know the Green's function for $ L_0 $, $ G_0(x,y) $, which will be a logarithm. Then one can correct for $ L_r $ by adding the term $$ L^{-1} \left( L_r G_0(x,y)  \right) $$ My intuition is that the linear part of $ L_r $ will produce a dipole term: $ L_r G_0(x,y) $ itself diverges, but in a small neighborhood $ B_\epsilon $, the ""total charge"" goes to zero. Apart from this, there will be no divergences. Is this true, and is there some source where this is studied?","['partial-differential-equations', 'analysis']"
443158,"For what $x\in[0,2\pi]$ is $\sin x < \cos 2x$","What's the set of all solutions to the inequality $\sin x < \cos 2x$ for $x \in [0, 2\pi]$? I know the answer is $[0, \frac{\pi}{6}) \cup (\frac{5\pi}{6}, \frac{3\pi}{2}) \cup (\frac{3\pi}{2}, 2\pi]$, but I'm not quite sure how to get there. This is what I have so far: $\\
\sin x - \cos 2x < 0\\
\sin x - \cos^2 x + \sin^2 x < 0\\
2\sin^2 x + \sin x - 1 < 0\\
-1 < \sin x < \frac{1}{2}$ Any help will be much appreciated.","['trigonometry', 'inequality', 'quadratics']"
443173,Relative density of images of diophantine polynomials,"My current research project involves sampling a sequence along non-constant polynomials with non-negative integer coefficients defined over the natural numbers, and I'd like to be able to say when two such polynomials are ""independent"". Say for two polynomials of this type $p$ and $q$, that $q$ is independent of $p$ if
\begin{equation*}
\limsup_{n \to \infty} \frac{p(\mathbb{N}) \bigcap q(\mathbb{N}) \bigcap \{1,2,\ldots,n\}}{p(\mathbb{N})\bigcap \{1,2,\ldots,n\}} = 0
\end{equation*} That is, $q$ is independent of $p$ if the relative upper asymptotic density of the image of $q$ in the image of $p$ is $0$. Say $q$ is dependent on $p$ if this property does not hold. It's pretty easy to show that if $\deg(q)>\deg(p)$ then $p$ is independent of $q$ (though $q$ is not necessarily independent of $p$). However, I'm stuck classifying when $p$ and $q$ are independent when they are of the same degree. If we define $g_{mr}(n) = mn+r$, it seems like if $\deg(q)=\deg(p)$, then $p$ and $q$ are dependent on each other if and only if there exist $m$, $m'$, $r$, $r'$ such that $q \circ g_{mr} = p \circ g_{m'r'}$. The forward direction is trivial, but I'm having a lot of trouble with the reverse direction. This problem can be viewed as a diophantine equation of the form $p(n)-q(m)=0$, and I'd like to know how these solutions are distributed. Unfortunately, all papers I've found that might be relevant have only classified whether there are finitely or infinitely many solutions. Even for quadratics it seems difficult. I know there exist recurrence relations that generate further solutions given one solution, but I don't know if these generate all solutions, and I haven't been able to find any results on the subject. Could you suggest any relevant papers or theorems that might shed some light on this problem in general, or even just for quadratics?","['algebraic-geometry', 'number-theory']"
443186,"Show that $\int_0^\infty e^{-(x-u/x)^2}(1-\frac{u}{x^2})dx$ converges uniformly on $u\in [\delta,L]$","I would like to show that $$\int_0^\infty e^{-(x-u/x)^2}\left(1-\frac{u}{x^2}\right)dx$$ converges uniformly on, say, $u\in [\delta,L]$, for arbitrarily small $\delta>0$ and arbitrarily large $L>0$. The important thing is that we can fit any $u>0$ into some interval on which the integral converges uniformly. If we can major the exponential by some appropriate exponential in terms of $x$, then the rest is taken care of. But I am having a hard time doing so. For instance, I may try $e^{-(x-u/x)^2}\leq e^{-x^2}$, but it is not clear that this is true for instance when both $u$ and $x$ are close to zero. Any ideas?","['calculus', 'integration', 'real-analysis', 'uniform-convergence']"
443188,Intuition of Empty Set in Ordered Pair,"This question is inspired by Exercise 1.44 Mathematical Proofs , 2nd Ed, by Gary Chartrand et al. Given that $A = \{\emptyset, \color{green}{\{{\emptyset}\}}\}$, I understand that 
$A \times \mathcal{P}(A) = \LARGE{\{} \normalsize{ (\emptyset, \emptyset), (\emptyset, \color{green}{\{{\emptyset}\}}), (\emptyset, \color{blue}{\{\{\emptyset\}\}}), (\emptyset, A), 
(\color{green}{\{{\emptyset}\}},\emptyset), ( \color{green}{\{{\emptyset}\}}, \color{green}{\{{\emptyset}\}}), ( \color{wgreen}{\{{\emptyset}\}}, \color{blue}{\{\{\emptyset\}\}} ), (\color{green}{\{{\emptyset}\}} ,A) } \LARGE{\}} $. I also understand that these 3 all differ: $\emptyset$ = an empty box, $\color{green}{\{{\emptyset}\} \text{= a box containing an empty box }}, \color{blue}{\{\{\emptyset\}\} \text{= a box containing a box containing an empty box} }.$ However, what is the meaning of an ordered pair containing any one of $\emptyset$, or $\color{green}{\{{\emptyset}\}}$ or $\color{blue}{\{\{\emptyset\}\}}$? As 3 examples, $(\emptyset, \emptyset), (\emptyset, \color{blue}{\{\{\emptyset\}\}}), ( \color{green}{\{{\emptyset}\}}, \color{blue}{\{\{\emptyset\}\}} )$ unhinge me because I only obtained them by the definition of Cartesian product; I am daunted and nescient about their true meaning. Could the 8 ordered pairs above be represented graphically? Or is there intuition or another interpretation? I have referenced Ordered pairs in a power set . $\large{\text{Supplement to Alex Mardikian and Professsor Scott's Answers :}}$ With many thanks to your answers, I now understand the ordered pairs can be bijected with natural numbers for simplicity. Nonetheless, without rewriting or paring them, is it possible to understand directly the meaning of an ordered pair containing any one of $\emptyset$, or $\color{green}{\{{\emptyset}\}}$ or $\color{blue}{\{\{\emptyset\}\}} ?$ The bijections have taken away some of my ""angst"", but I still feel fazed by ordered pairs like $(\emptyset, \emptyset), (\emptyset, \color{blue}{\{\{\emptyset\}\}}), ( \color{green}{\{{\emptyset}\}}, \color{blue}{\{\{\emptyset\}\}} )$.",['elementary-set-theory']
443202,Steady State Solution Non-Linear ODE,"I'm working through some problems studying for a numerical methods course, but I'm stuck on how to answer the following question analytically. It says to find the steady state solution of the following equation: $\frac{dy}{dx} = -ay + e^{-y}$ where $y(0)=0$. It says that the steady state solution is when $\frac{dy}{dx} = 0$. It's also claimed that the steady state solution is a fixed point of the system. I'm stuck on where to start with this. If I immediately try to solve $0 = -ay + e^{-y}$, I can't isolate y. Then I tried to start with the homogenous equation, but that devolved also. What am I missing?","['ordinary-differential-equations', 'numerical-methods']"
443208,Determining Convergence of Power Series,"Flip a fair coin until you get the first ""head"".  Let X represent the number of flips before the first head appears.  Calculate E[X]. So I solved this problem and you get a power series: $E[X] = 1*0.5 + 2*0.5^2 + 3*0.5^3+ ...$ This is basically of the form $\sum\limits_{i=0}^{\infty}x_i(0.5)^i.$ I flipped open my calculus book to review how to solve this series but I didn't find anything on how to calculate the limiting value for a power series, just the radius of convergence. I see for a sum of infinite geometric series, the value is: $S_n = a+ ax + ax^2 + ... + ax^n + ... = \cfrac{a}{1-x}$ for |x| < 1. Can someone please tell me the general approach if there is one for a power series? Thank you in advance.","['statistics', 'sequences-and-series', 'power-series', 'calculus']"
443209,Matrices with trace zero. [duplicate],"This question already has an answer here : If $\mathrm{Tr}(A)=0$ then $T=R^{-1}AR$ has all entries on its main diagonal equal to $0$ (1 answer) Closed 5 years ago . I would like to show that every trace zero square matrix is similar to one with zero diagonal elements. This question has been asked before, and has had an answer by Don Antonio . And my problem is that I cannot understand the cited paper. In the cited paper , (proof 4), one finds the sentence Since $\text{Tr}(K) = \text{Tr}(B^{–1}SB) = \text{Tr}(S) = 0$, this step can be 
  repeated to replace $K$ by a matrix whose every diagonal element is zero ( thereby changing $c$ and $r^T$ ) thus constructing $C$ so that every diagonal element of $C^{–1}SC$ is zero. Question I thought that, since $\text{Tr}(K)=0$, we can, by the induction hypothesis, find an invertible $D$, such that $D^{-1}KD$ has diagonal elements $=0$. But how does this enable us to replace $K$ by a matrix with zero diagonal elements, at the cost of changing $r^T$ and $c$? I tried to constuct some matrix $C$ from $D$ such that $C^{-1}\begin{bmatrix}0&r^T\\c&K\end{bmatrix}C=\begin{bmatrix}0&r'^T\\c'&K'\end{bmatrix}$ with $K'$ having zero diagonal elements, but to no avail. I have tried various choices of $C$, but the result of the multiplication refuses to be of the required form, so I wonder if I am missing something here? Any hint is well-appreciated.","['matrices', 'linear-algebra']"
443242,How to better understand where the circles and lines go under fractional linear transformations?,"Today I encountered the transformation $f(z) = \frac{z}{z-1}$. It has the following property: As the point $z$ makes a counter-clockwise revolution around the unit circle beginning at $1$, the point $f(z)$ parametrizes the line with real part $1/2$, travelling upward. This is not a difficult thing to verify with a bit of fiddling around. I used this fact to show that a certain operator had a gap in its spectrum. But, if I hadn't already expected this was going to happen for another reason, I would never have noticed the above property of this transformation. Another example: the Cayley transform $f(z) = \frac{z -i}{z+i}$. As $z$ travels the real line from left to right, $f(z)$ undergoes a counterclockwise revolution of the circle, beginning and ending at $1$. Again, this is easy to check. I'm aware of the phenomenon because the transform is relatively famous, but, if I had encountered this transformation ""in the wild"", I would never have expected the above property.  Which leads to my question: Is there some more systematic way to see where lines and circles go under fractional linear transformations $f(z) = \frac{az+b}{cz+d}$? I can verify expected facts by doing things like computing the norm, or real and imaginary parts of the right hand side, but I cannot help but feel like there is some gap in my knowledge that prevents me from really understanding what is going on.","['rational-functions', 'special-functions', 'complex-analysis']"
443246,"Can I write $(x^p)^{q} = x^{pq}$, where either of $p$ or $q$ are rational.","I am confused with a very basic algebra question about the following law of exponents. We know that $(x^n)^{m} = x^{nm}$, holds true for real $x$ and integer exponents $n, m$. I want to know whether this result holds for rational exponents aswell? For example can I write $(x^p)^{q} = x^{pq}$, where either of $p$ or $q$ are rational. Kindly pardon me for asking a very silly question. Thanks for the help.",['algebra-precalculus']
443252,What is the probability that the roots of $P(x) = \frac{1}{4} x^2 +Ux+V^2$ are real?,"Assume that $U$ and $V$  are independent normally distributed random variables, each with mean $0$ and variance $1$. Find the probability that the roots of the polynomial $P(x) = \frac{1}{4} x^2 +Ux+V^2$  are real. This is a question I had to work out on my intro probability midterm. It's clear to see by looking at the discriminant that 
$$\begin{align}
\Bbb P(\text{roots of }P(x)\text{ are real})
&=\Bbb P(U^2-V^2\ge0) \\
&=\Bbb P(U^2\ge  V^2) \\
&=\Bbb P(U\ge V\text{ or }-U\ge -V),
\end{align}$$
but what next? I appreciate any help. Thanks in advance!",['probability']
