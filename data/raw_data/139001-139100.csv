question_id,title,body,tags
2230509,Details in a proof of coarea formula in $\mathbb{R}^n$.,"Let $\Omega\subseteq\mathbb{R}^n$ be an open set, and let $u:\bar{\Omega}\rightarrow\mathbb{R}$ be a function of class $C^1(\bar{\Omega})$. Given $\lambda\in\mathbb{R}$, let $\Gamma_\lambda=\{x\in\Omega:\,u(x)=\lambda\}$. Coarea formula: Suppose $|\nabla u|>0$ on $\bar{\Omega}$, and let $f\in L^1(\Omega)$. Then $$\int_\Omega f\,dx=\int_\mathbb{R}\int_{\Gamma_\lambda} \frac{f}{|\nabla u|}\,d\sigma\,d\lambda.$$ I present a proof that I think would work, and I want to ask about a (very important) step inside the proof. I know that coarea formula can be proved in a more general setting, but I am interested on solving this particular proof. For each $p\in\Omega$, there is $i\in\{1,\ldots,n\}$ with $|u_{x_i}(p)|>0$. By continuity, there exists $r_p>0$ such that for all $x\in B(p,r_p)\subseteq\Omega$ we have $|u_{x_i}(x)|>0$. As $\Omega$ is Lindelöf, $\Omega=\cup_{j=1}^{\infty} B_j$, where $B_j$ is some of such balls. Partition of the unity: there exists $\psi_j\in C_c^{\infty}(B_j)$ with $0\leq\psi_j\leq 1$ and $\sum_{j=1}^{\infty}\psi_j(x)=1$ for all $x\in\Omega$. Define $f_j=f\,\psi_j$ on $\Omega$. From now on, fix one of the balls $B=B_j$ and for simplicity of notation assume that $|u_{x_n}|>0$ on $B$. By the implicit function theorem, $\Gamma_\lambda\cap B=\{x\in B:\,u(x)=\lambda\}=\{(x',\varphi(x',\lambda)):\,x'\in\tilde{B}\}$, where $\tilde{B}$ open in $\mathbb{R}^{n-1}$ and $\varphi(\cdot,\lambda)\in C^1(\tilde{B})$. Question: can I assume that $\tilde{B}$ is chosen independently of $\lambda$? Do we have $\varphi(x',\cdot)\in C^1$? On the one hand, $$\int_\mathbb{R}\int_{\Gamma_\lambda}f_j\,d\sigma\,d\lambda=\int_\mathbb{R}\int_{\Gamma_\lambda\cap B}f_j\,d\sigma\,d\lambda=\int_\mathbb{R}\int_{\tilde{B}}f_j(x',\varphi(x',\lambda))\sqrt{1+|\nabla_{x'}\varphi(x',\lambda)|^2}\,dx'\,d\lambda.$$ On the other hand, if the question has a positive answer, \begin{equation}
\begin{split}
\int_\Omega f_j\,|\nabla u|\,dx &=\int_B f_j\,|\nabla u|\,dx \\
&\stackrel{\substack{\text{change}\\\text{variable}}}{=}\int_\mathbb{R}\int_{\tilde{B}}f_j(x',\varphi(x',\lambda))|\nabla u(x',\varphi(x',\lambda))|\,|\varphi_\lambda (x',\lambda)|\,dx'\,d\lambda.
\end{split}
\end{equation} Finally use $u(x',\varphi(x',\lambda))=\lambda$ for all $x'\in \tilde{B}$, and derivating with respect to $x'$ and $\lambda$ (if the question has a positive answer), one arrives at the equality between the last two big expressions. If the answer to the question were negative, are there any alternatives to make this proof work? I don't know, something like changing the balls by rectangles...","['geometric-measure-theory', 'differential-geometry', 'vector-analysis']"
2230592,$L_p$ space inclusion for Riemann-Stieltjes integral,"The integral here is defined in the Riemann-Stieltjes sense, the interval $[a,b]$ contains $\psi$'s support, and $\alpha<1$. $X$ is $\alpha$-Hölder continuous. \begin{align*}  \left|\int_a^b \psi(v)\mathrm{d}X(v)\right|&\leq \|\psi\|_{\infty}\lim\limits_{\left|\mathcal{P}\subseteq{[a,b]}\right|\to 0}\sum\limits_{i=0}^{n-1}\left|X(v_{i+1})-X(v_i)\right|\\
&\leq \|\psi\|_{\infty}\mu([a,b])^{1-\frac{1}{\alpha}}\lim\limits_{\left|\mathcal{P}\subseteq [a,b]\right|\to 0}\left(\sum\limits_{i=0}^{n-1}\left|X(v_{i+1})-X(v_i)\right|^{\frac{1}{\alpha}}\right)^{\alpha},
\end{align*} where $\mu$ is the standard Lebesgue measure. Have I correctly used the result that, for $1\leq p<q\leq\infty$, where $A$ is a finite measure space and $f$ is measurable (with measure $\mu$),we have
$$\|f\|_p\leq \mu(A)^{\frac{1}{p}-\frac{1}{q}}\|f\|_q$$
?","['functional-analysis', 'real-analysis', 'analysis', 'proof-verification']"
2230596,Relationship Between Sine as a Series and Sine in Triangles,I'm taking a single variable calculus course and sine series is defined as $$ \sum_{k=0}^\infty (-1)^k \frac{x^{2k+1}}{(2k + 1)!}. $$ Sine is also defined as opposite length over hypotenuse length for a right angled triangle. So $$\frac{\text{opposite}}{\text{hypotenuse}} =  \sum_{k=0}^\infty (-1)^k \frac{x^{2k+1}}{(2k + 1)!}? $$ Is there a concept I'm not understanding here?,"['taylor-expansion', 'trigonometry', 'trigonometric-series', 'calculus']"
2230623,why are convex functions defined as functions who's epigraph is a convex set?,"A convex real-function is a function such that all points above the function's graph form a convex set. Why isn't it defined instead the opposite way: a function such that all points below it form a convex set? Is there a particular reason for this? edit : my question really is: Is there some kind of similarity that convex sets share with convex functions, but not with concave functions, which would explain why we use the same term for these different things?","['convex-analysis', 'functions', 'definition']"
2230635,Prove $\int_{0}^{\infty}{\ln x\ln\left(x\over 1+x\right)\over (1+x)^2}dx$ and $\int_{0}^{\infty}{\ln x\ln\left(x\over 1+x\right)\over 1+x}dx$,"Two well known constants $$\int_{0}^{\infty}{\ln x\ln\left(x\over 1+x\right)\over (1+x)^2}=\zeta(2)\tag1$$ $$\int_{0}^{\infty}{\ln x\ln\left(x\over 1+x\right)\over 1+x}=\zeta(3)\tag2$$ An attempt: Applying IBP: $$\int{\ln x\over x}\mathrm dx={1\over 2}\ln^2 x+C\tag3$$ Rewrite $(2)$ as $$\int{\ln^2 x\over 1+x}\mathrm dx-\int{\ln(x)\ln(1+x)\over 1+x}\mathrm dx=I_1-I_2\tag4$$ Let integrate $I_1$ , applying IBP $$I_1=\ln^2(x)\ln(1+x)-2\int{\ln(x)\ln(1+x)\over x}\mathrm dx\tag5$$ $$I_1=-\ln^2(x)\ln(1+x)+2\ln(x)\ln(1+x)-2\int{\ln(x)\ln(1+x)\over x}\mathrm dx\tag6$$ $I_1$ is not going down any further. Let try $I_2$ applying IBP $$I_2={1\over 2}\ln(x)\ln(1+x)+{1\over 2}\int{\ln^2(x)\over x}\mathrm dx\tag7$$ $$\int{\ln^2(x)\over x}\mathrm dx={1\over 3}\ln^3(x)+C\tag8$$ $$I_2={1\over 2}\ln(x)\ln(1+x)+{1\over 6}\ln^3(x)+C\tag9$$ This seem too complicate, what I am doing here How can we tackle $(1)$ and $(2)$ in a less cumbersome way?","['integration', 'definite-integrals', 'calculus']"
2230651,A conjectured continued fraction for $\phi^\phi$,"As I previously explained, I am a ""hobbyist"" mathematician (see here or here ); I enjoy discovering continued fractions by using various algorithms I have been creating for several years. This morning, I got some special cases for a rather heavy expression I was working on, finding the beautiful identities: $$
    \phi^\phi
    \;=\;
    2 +
    \displaystyle\frac{2\left(1-1/\phi\right)/\phi}
      {2\left(2-1/\phi\right) +
    \displaystyle\frac{3\left(1-2/\phi\right)/\phi}
      {3\left(2-1/\phi\right) +
    \displaystyle\frac{4\left(1-3/\phi\right)/\phi}
      {4\left(2-1/\phi\right) +
    \displaystyle\frac{5\left(1-4/\phi\right)/\phi}
      {5\left(2-1/\phi\right) + \;\ddots }}}}
$$ Equivalently $$
    \phi^\phi
    \;=\;
    2 +
    \displaystyle\frac{2/\phi\left(\phi-1\right)}
      {2\sqrt5 +
    \displaystyle\frac{3\left(\phi-2\right)}
      {3\sqrt5  +
    \displaystyle\frac{4\left(\phi-3\right)}
      {4\sqrt5  +
    \displaystyle\frac{5\left(\phi-4\right)}
      {5\sqrt5  + \;\ddots }}}}
$$ where $\phi$ is the golden ratio. I was very excited to have found this $\phi^\phi$ formula and my question is about how original it is : did someone already see it or could I be confident in assuming it is new?
Similarly $$
    \phi^{2/\phi}
    \;=\;
    2 +
    \displaystyle\frac{2\left(1-2/\phi\right)}
      {2\phi +
    \displaystyle\frac{3\left(1-3/\phi\right)}
      {3\phi +
    \displaystyle\frac{4\left(1-4/\phi\right)}
      {4\phi +
    \displaystyle\frac{5\left(1-5/\phi\right)}
      {5\phi + \;\ddots }}}}
$$ By using a more compact notation (see at the end of this message for an explanation about how to read it), other identities for $\sqrt{3}$ , $\sqrt[3]{4}$ , $\sqrt[4]{5}$ , etc. would be: $$
  \sqrt[a]{a+1}
\;=\;2+
\displaystyle\operatorname*{K}_{n=1}^{\infty}
    \frac
    {\left(n+1\right)\left(1-an\right)/\left(a+1\right)}
    {\left(n+1\right)\left(1+a/\left(a+1\right)\right)}
$$ These identities are special case of the following conjectured identity (of course, when asking whether the previous formulae are known or not, it also means the formula below should be new also): $$
  \left(\displaystyle\frac{x}{x-1}\right)^{x-1}
\;=\;2+
\displaystyle\operatorname*{K}_{n=1}^{\infty}
    \frac
    {\left(n+1\right)\left(x-n-1\right)/x}
    {\left(n+1\right)\left(x+1\right)/x}
\tag{1}\label{1}
$$ that I found from a more general conjecture being related to the following continued fraction: $$
    g\left(k,x\right) = 
\displaystyle\operatorname*{K}_{n=1}^{\infty}
    \frac
    {\left(n+1\right)\left(k-n-k/x\right)/x}
    {\left(n+1\right)\left(1+1/x\right)}
$$ for which I empirically noticed the relation (with $\textrm{B}$ the beta function): $$
    \begin{array}{l}
        2\;+\;
    g\left(\alpha,\xi\right) \;+\; g\left(\alpha,\displaystyle\frac{\xi}{\xi-1}\right)
        \\[8pt]
        \qquad\qquad =\;
        \alpha\left(\xi-1\right)^{\alpha/\xi-1}\left(\displaystyle\frac{\xi}{\xi-1}\right)^{\alpha-2} \textrm{B}\left(\alpha/\xi, \alpha-\alpha/\xi\right)
    \end{array}
\tag{2}\label{2}
$$ where it is easy to notice that the case $\alpha=\xi/\left(\xi-1\right)$ makes $g\left(\alpha,\xi\right)=0$ leading to an identity containing a single continued fraction (which can later be simplified as above). The previous notation is the one I use; I find it convenient and it can be found for instance in Continued Fractions with Applications by  Lorentzen & Waadeland, but I know that some people don't like it; it has to be read the following way: $$
a_0 + \operatorname*{K}_{n=1}^{\infty} \frac{b_n}{a_n} = a_0 + \cfrac{b_1}{a_1 + \cfrac{b_2}{a_2 + \cfrac{b_3}{a_3 + \ddots}}}
$$","['number-theory', 'conjectures', 'golden-ratio', 'continued-fractions']"
2230675,Are all values of the totient function for composite numbers between two consecutive primes smaller than the totient values of those primes?,"I've seen the graph for $\varphi(n)$ vs $n$ on Wolfram, and it seems like the $\varphi(n)$ values for primes follow a constant slope, but is there a proof that states that the totient values between two consecutive primes are always smaller than the totient values of those two primes? EDIT:
I got a satisfactory answer for the case where there is a strict inequality. But what is the condition for a relaxed inequality? Is there a proof that establishes $\varphi(n)\le\varphi(p_n)$ and $\varphi(n)\le\varphi(p_{n+1})$","['number-theory', 'prime-numbers', 'totient-function']"
2230684,Area of equilateral triangle inscribed in right triangle,"An Isosceles right triangle  $ABC$  , $AB=BC= 4 cm$ Point $p$ is a midpoint of $BC$ , points $q$, $s$  lies on $AC$,$AB$ respectively  , such that the triangle $pqs$ is  an equilateral triangle ; what is the area of triangle $pqs$",['geometry']
2230714,Differentiating a derivative with respect to another function of $x$,"I've been studying second order differentials, during which we were taught how to reduce second order differential equations to a simpler form using substitution. One trick we used was 
$$\frac{d}{dx}\bigg(\frac{dy}{dz}\bigg)=\frac{d}{dx}\frac{dy}{dz}\frac{dz}{dz}=\frac{d^2y}{dz^2}\frac{dz}{dx}$$
Where $y$ and $z$ are both functions of $x$ This was introduced by 'grouping' terms together to form $\frac{d^2y}{dz^2}$, which is not what is happening, just a useful trick that happens to work. My question is, what is really happening here? Why does this work?","['derivatives', 'ordinary-differential-equations', 'calculus']"
2230719,Maximum (or upper bound on the) weight of a topology on a set X.,"Let $X$ be a set and $\tau$ a topology on $X$. Let's define the weight of $\tau$, $w(\tau)$, as the minimum cardinality of a basis for $\tau$. 1) What is the supremum of the weights of all topologies on $X$? 2) Is this supremum a maximum? 3) Is this supremum greater than the cardinality of $X$? Let $s=\sup\{w(\tau) : \tau \text{ is a topology on } X\}$. This is what I deduced: Clearly $s\geq |X|$, since $w(\tau)=|X|$ when $\tau$ denotes the discrete topology. If $X$ is finite then $s=|X|$ is a maximum. So the answer to 3) in this case is no .",['general-topology']
2230727,Is $48^p-47^p$ ever prime?,"I was examining primes q that are $q=(n+1)^p-n^p$ with p also prime. 
There seems to be more than one  solution for most n. 
In the table below all the first solutions of p up to 2000 and for n up to 200:
\begin{array}{||r|r|||r|r|||r|r|||r|r||}
\hline \hline
n & p & n & p & n & p & n & p \\ \hline \hline
1 & 3 &51 & 29 &101 & 5 &151 & 59\\ \hline
2 & 3 &52 & 3 &102 & 13 &152 & 1583\\ \hline
3 & 3 &53 & 479 &103 & 7 &153 & 3\\ \hline
4 & 3 &54 & 5 &104 & 5 &154 & 43\\ \hline
5 & 5 &55 & 3 &105 & 3 &155 & 7\\ \hline
6 & 3 &56 & 19 &106 & - &156 & 3\\ \hline
7 & 7 &57 & 5 &107 & 59 &157 & 3\\ \hline
8 & 7 &58 & 3 &108 & 3 &158 & 3\\ \hline
9 & 3 &59 & - &109 & 5 &159 & 7\\ \hline
10 & 3 &60 & - &110 & 5 &160 & 13\\ \hline
11 & 3 &61 & 17 &111 & 113 &161 & 7\\ \hline
12 & 17 &62 & 3 &112 & 5 &162 & 389\\ \hline
13 & 3 &63 & 3 &113 & - &163 & 47\\ \hline
14 & 3 &64 & 5 &114 & 139 &164 & 3\\ \hline
15 & 43 &65 & 7 &115 & 269 &165 & 3\\ \hline
16 & 5 &66 & 3 &116 & - &166 & 13\\ \hline
17 & 3 &67 & 3 &117 & 7 &167 & 167\\ \hline
18 & 1607 &68 & 17 &118 & 13 &168 & 11\\ \hline
19 & 5 &69 & 11 &119 & 3 &169 & 17\\ \hline
20 & 19 &70 & 47 &120 & 5 &170 & 3\\ \hline
21 & 127 &71 & 61 &121 & 5 &171 & 3\\ \hline
22 & 229 &72 & 19 &122 & 7 &172 & 3\\ \hline
23 & 3 &73 & 23 &123 & 3 &173 & 19\\ \hline
24 & 3 &74 & 3 &124 & - &174 & 5\\ \hline
25 & 3 &75 & 5 &125 & 3 &175 & 3\\ \hline
26 & 13 &76 & 19 &126 & 41 &176 & 37\\ \hline
27 & 3 &77 & 7 &127 & 59 &177 & 269\\ \hline
28 & 3 &78 & 5 &128 & 3 &178 & 5\\ \hline
29 & 149 &79 & 7 &129 & 3 &179 & 3\\ \hline
30 & 3 &80 & 3 &130 & 1499 &180 & 19\\ \hline
31 & 5 &81 & 3 &131 & 101 &181 & 43\\ \hline
32 & 3 &82 & 331 &132 & 167 &182 & 43\\ \hline
33 & 23 &83 & 41 &133 & - &183 & 11\\ \hline
34 & 3 &84 & 179 &134 & 7 &184 & 3\\ \hline
35 & 5 &85 & 5 &135 & 7 &185 & 3\\ \hline
36 & 83 &86 & 3 &136 & 3 &186 & 3\\ \hline
37 & 3 &87 & 5 &137 & - &187 & -\\ \hline
38 & 3 &88 & 3 &138 & 113 &188 & 13\\ \hline
39 & 37 &89 & 109 &139 & - &189 & 41\\ \hline
40 & 7 &90 & 3 &140 & 3 &190 & 53\\ \hline
41 & 3 &91 & 3 &141 & 7 &191 & 3\\ \hline
42 & 3 &92 & 17 &142 & 3 &192 & 5\\ \hline
43 & 37 &93 & 3 &143 & - &193 & 3\\ \hline
44 & 5 &94 & 61 &144 & 5 &194 & -\\ \hline
45 & 3 &95 & 3 &145 & 7 &195 & 3\\ \hline
46 & 5 &96 & 1307 &146 & 13 &196 & 3\\ \hline
47 & - &97 & 7 &147 & 3 &197 & 5\\ \hline
48 & 3 &98 & 709 &148 & 5 &198 & -\\ \hline
49 & 3 &99 & 5 &149 & 271 &199 & 31\\ \hline
50 & 7 &100 & 43 &150 & 13 &200 & 59\\ \hline
\hline
\end{array}
47 is the first n that has no solution for $p<2000$.
I tried n=47 for higher p but still no solution for $p<10000$ Question: Is there a way to prove that $q=48^p-47^p$ is never prime?
After factoring $48^p-47^p$ for several p, I found the smallest prime factor is always $\equiv 1 \pmod {p}$ but I don't see how this helps.","['number-theory', 'prime-numbers']"
2230746,Does this statement represent a set?,"Does the following statement represent a set?
""The collection of all the stars in the universe?"". I think it represents a set. Please explain if someone agrees or disagrees.",['elementary-set-theory']
2230770,Triangling a triangle,"It is widely known that we can square a square , which is defined as follows: ""Squaring a square"" is tiling a square with integer side lengths with smaller squares with integer side lengths. In reality it is very simple; we can for example tile a $2\times2$ square with four unit squares. Thus, people've thought of the restriction that all tiles must have different sizes, which they've named perfect . This turns out to be possible, with the smallest perfectly squared square being a $112\times112$ square: My question is simple: can we do the same with equilateral triangles? Meaning, can we tile an equilateral triangle with integer side lengths with smaller equilateral triangles with integer (but all different) side lengths? If so, what would be the smallest perfectly triangled triangle? EDIT: So I've been doing some thinking and I think I'm getting closer. Let's have a look at the smallest triangle tile (we'll call it $\tau$). We'll split cases. Case 1: $\tau$ is in a vertex. If the little triangle is a tile in one of the three vertices of the parent triangle, then it has one edge left; only triangles smaller than or as small as $\tau$ can fill that edge, but $\tau$ was the smallest triangle. This is impossible. Case 2: $\tau$ is on the border. If $\tau$ is on the border of the parent triangle, but not in the corner, then either side of $\tau$ is touching that of a bigger triangle, which makes those two neighboring tiles overlap. This is also impossible. Assume now $\tau$ is not on the border of the parent triangle. Case 3: An edge of $\tau$ is touching a vertex. If an edge is touching a vertex, then since the neighboring tiles are bigger, we have the following (the orange tile being $\tau$, ignore that the blue triangle is the same size, it's beside the point): Which makes this case equivalent to case 2. And then the last case is when none of the above hold, but I'm quite stuck on that.","['puzzle', 'geometry']"
2230797,Regular map between quasiprojective varieties are continuous,"I am reading Shaferevich's Basic Algebraic Geometry Book 1. In page 50 it proved that regular maps between quasiprojective varieties are continuous. I do not understand the proof: Suppose $f:X\rightarrow Y$ is a regular map between quasiprojective varieties. $Z\subset Y$ is a closed subset of $Y$. Want to show that $f^{-1}(Z)$ is closed in $X$. Now for any point $x\in X$ there are neighbourhoods $U$ of $x$ and $V$ of $f(X)$ such that $f(U)\subset V\subset\mathbb A^m$ nad the map $f:U\rightarrow V$ is regular. Cover $X$ with such $U$'s. We can assume that $U$ is an affine variety. Since closedness is a local property it is enough to check that $f^{-1}(Z)\cap U=f^{-1}(Z\cap V)$ is closed in $U$. Since $Z\cap V$ is closed in $V$, it is defined by equations $g_1=\cdots=g_m=0$, where $g_i$ are regular functions on $V$. But then $f^{-1}(Z\cap V)$ is defined by the equation $f^*(g_1)=\cdots =f^*(g_m)=0$. I do not understatnd the following things: (i) Why $Z\cap V$ is closed in $V$ implies it is defined by equations $g_1=\cdots=g_m=0$, where $g_i$ are regular functions on $V$. (ii) Where do we use the fact that ""We can assume that $U$ is an affine variety"". Please help me. Thank you.","['affine-varieties', 'projective-space', 'algebraic-geometry', 'commutative-algebra']"
2230870,Find the value of $3+7+12+18+25+\ldots=$,"Now, this may be a very easy problem but I came across this in an examination and I could not solve it. Find the value of $$3+7+12+18+25+\ldots=$$ Now here is my try $$3+7+12+18+25+\ldots=\\3+(3+4)+(3+4+5)+(3+4+5+6)+(3+4+5+6+7)+\ldots=\\3n+4(n-1)+5(n-2)+\ldots$$ After that, I could not proceed.",['algebra-precalculus']
2230884,"Prove that for every prime number $p>3$, $4p^2+1$ can be written as the sum of three square numbers","Given that $p>3$ prove that $4p^2+1$ can be written as the sum of three distinct positive square numbers. Plugging in $5$ I get $101=49+36+16=7^2+6^2+4^2$ I also know that all primes greater than $3$ can be written in the form $3k+1$ and $3k+2$ but plugging those values in I get: $36k^2+24k+5$,  $36k^2+48k+17$ and the solution probably lies in arranging these numbers in such a way that we get the desired squares, but I can't come up with a combination ,or is my ""idea"" not even in the right direction?","['discrete-mathematics', 'elementary-number-theory']"
2230982,Help differentiating $\frac{(x-1)^2(x+2)^2}{(x+1)^2}$,"I need help differentiating this expression below. I know you can use a mix of the product rule and quotient rule, but that is tedious and long. Is there a shorter method? $$\dfrac{(x-1)^2(x+2)^2}{(x+1)^2}$$","['derivatives', 'calculus']"
2231000,Question about a 3rd order linear PDE,"Consider $f(x,y,t)$ whose spatial second order derivatives evolve over time based on the following pair of PDEs: $$\begin{align}
\frac{\partial^3}{\partial x^2 \partial t}f\,&=\,\frac{1}{2}\left(\frac{\partial^2}{\partial y^2}f-\frac{\partial^2}{\partial x^2}f\right)\\
\\
\frac{\partial^3}{\partial y^2 \partial t}f\,&=\,\frac{1}{2}\left(\frac{\partial^2}{\partial x^2}f-\frac{\partial^2}{\partial y^2}f\right)
\end{align}$$ The process is subject to initial condition $f(x,y,t=0)=f_0(x,y)$ for some given $f_0(x,y)$. Is there an analytical expression for the solution $f$ in terms of $f_0$? Help would be greatly appreciated. Golabi","['ordinary-differential-equations', 'partial-differential-equations']"
2231017,"$A\in M_{3\times3} $ has eigenvalues $\lambda=1,-1. \Rightarrow A^3=A$?","My first intuition was that the statement in the title is false, however I have failed to find a counterexample. Iv'e managed to show this is true if $A$ is diagonalizable but cannot see why this is necessarily true.
Thanks. Clarification: $\lambda=1,-1$ are the only eigenvalues","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra']"
2231031,Interpretation of eigenvectors of Hessian in context of local min/max/saddle?,"Say $f \in C^2$ so we can possibly use its Hessian $H$ to determine whether $f$ has a local max, min, or saddle at a critical point $x_0$. Since $H(x_0)$ is real and symmetric, it is diagonalizable, say with eigenvector-eigenvalue pairs $(v_1,\lambda_1),\ldots,(v_n,\lambda_n)$. The second derivative test asserts that if all the $\lambda_i$ are strictly positive, then $f$ has a local min, if they are all strictly negative, then $f$ has a local max, and if there are at least one strictly positive and one strictly negative, then $f$ has a saddle point. Is there some geometric interpretation to what the $v_i$ are? Are the $v_i$ somehow directions in which the function restricted to that direction has concavity $\lambda_i$?","['multivariable-calculus', 'stationary-point', 'optimization', 'calculus']"
2231051,"Covariance, inner product and independence","Let $X$ and $Y$ be two normally distributed random variables. I understand that if $\operatorname{cov}(X,Y)=0$ then they are stochastically independent (right?). Now, is it true that if  $X \cdot Y = 0$ they are independent?, are those two results equivalent?","['normal-distribution', 'independence', 'probability-theory', 'inner-products', 'random-variables']"
2231149,Are nearby simple closed geodesics ambient isotopic?,"Let $(M,g)$ be a closed Riemannian manifold. I want to show that there exists a sufficiently small $\delta > 0$ such that if $\gamma_1: S^1 \to M$ and $\gamma_2: S^1 \to M$ are simple closed geodesics with $d(\gamma_1, \gamma_2) = \sup\ \{d(\gamma_1(\theta), \gamma_2(\theta)) : \theta \in S^1\} < \delta$, then they are ambient isotopic. There are easy counterexamples if you drop the simple condition. I have attempted a proof as follows: Since $M$ is closed, there is some $\epsilon$ such that every point in $M$ has a totally normal neighborhood of radius $\epsilon$. As long as $\delta < \epsilon$, there is a unique shortest geodesic connecting $\gamma_1(\theta)$ to $\gamma_2(\theta)$ for each $\theta$. Geodesic flow along these connecting segments takes $\gamma_1$ to $\gamma_2$. But a priori, two of those connecting segments might intersect such that the flow is not an isotopy. I suspect that something about being geodesics prevents this, since in a neighborhood nearby geodesics should look something like parallel lines oriented in the same direction, but I haven't managed to come up with an argument. Can this proof be finished, possibly with much smaller $\delta$? Is this statement even true?","['general-topology', 'riemannian-geometry', 'differential-geometry', 'geodesic']"
2231189,What does the blow up along a locally principal look like?,"Let $\mathcal{I}$ be a locally principal ideal sheaf of a scheme $X$ (i.e. for all $x\in X$ exists an open neighborhood $U$ of $x$ and $f_U\in \mathcal{O}_X(U)$ with $\mathcal{I}|_U=(f_U)^\tilde{}$). Is the blow up $X'$ of $X$ with center $\mathcal{I}$ a closed subscheme of $X$? And if it is the case, which is the ideal sheaf defining $X'$ as a closed subscheme of $X$? I've founded positive answers for the affine case with $\mathcal{I}$ globally principal: Suppose $X=\mathrm{Spec}(A)$ and $\mathcal{I}$ being the sheaf associated to the ideal $(f)\subseteq A$ for a given $f\in A$. The ideal $J$, defining the closed subscheme $X'$ of $X$, is the extension and contraction of the zero ideal by the homomorphism $A\to A_f$. If the zero ideal of $A$ has a minimal primary decomposition $q_1\cap\dots\cap q_l$ (e.g. $A$ Noetherian), the ideal $J$ is the intersection of the $q_i$ such that $\{1,f,f^2,\dots\}\cap \sqrt{q_i}=\emptyset$, or, in any case, $J$ is $\bigcup_{n\ge 1} (0:f^n)$. The closed embedding $\mathrm{Spec}(A/J)\to \mathrm{Spec}(A)$ satisfies the required universal property: If $f$ is nilpotent then $V(f)=A$, $J=A$ and the blow up is the empty set. If it is not then the class of $f$ in $A/J$ is diferent from zero an not a zero divisor, so the pull back of $\mathcal{I}$ to $X'$ is a Cartier divisor. And given a morphism $W\to X$ with this last property, affine locally we have a ring homomorphism $\varphi:A\to B$ such that $\varphi(f)$ is not a zero divisor and diferent from zero, so given $j\in J$, exists $n$ such that $jf^n=0$, hence $\varphi(j)\varphi(f)^n=0$ and $\varphi(j)=0$ (i.e. $J\subseteq \ker(\varphi)$). Morally, for one side, we are erasing the irreducible components of $X$ inside the closed scheme $Z$ determined by $\mathcal{I}$ and, the other side, we are lifting the non-reduced structure of the embedded components of $X$ inside $Z$.","['algebraic-geometry', 'blowup']"
2231223,Why we have elementary operations on matrix?,"I just started with matrices, so this might be the stupidest question I ever asked. When we had to find the inverse of a matrix $A$, we write $A$ as $A = IA$ then we use elementary operations to convert $A$ on LHS to $I$. The elementary operations I have been taught is $R_i \to kR_j$, $R_i \to R_j$ and $R_i \to R_i + kR_j$. I want to know why we have only these operations and not something like $R_i \to R_i + 10$ ? How did somebody came up this 3 operations ? It would be nice if the answers are a little bit beginner friendly because I don't know much about linear algebra.","['matrices', 'linear-algebra']"
2231228,Normal Probability Plot: points oscillate around line of slope 1: polynomial?,"This is the Normal Probability Plot I've obtained for some data: As you can see the points seem to osciallate, as in a period, around the line of slope 1 and passing through the origin. I've obtained this plot by trying to fit a simple linear regression model. Can I deduce from this peculiar behaviour (just as an Anzat, or a guess, waiting for further tests) that this can indicate that there is a polynomial relationship? (for example the grade of the polynomial might be equal to the number of times the oscillation crosses the line) Or otherwise, what does this suggest? That there is a trigonometric relationship? Edit Basically Ive fitted a linear model data.lm <- lm(y~x, data=data) , then Ive created the standardized residuals data.lm$sr <- rstandard(data.lm) and finally plotted the qqplot qqnorm(data.lm$sr) and I've added abline(0,1)","['regression', 'statistics']"
2231243,Finding a line segment from two edges of a cube that intersects an arbitrary point within the cube volume,"To give some context for where this problem is originating, I am an artist whose work is primarily focused on illustrating concepts in math and physics through sculptural media. I am working on creating a series of sculptures that depict different constellations with their stars as they are actually arranged in space in 3D (well, almost, my z coordinates are the distances from earth in light years scaled down to fit within the confines of the cube, so not 100% true to life, but close enough for art reasons). From most angles, the sculptures just look like beads strung at random from wires anchored to a cube frame, but when viewed head-on from the front, they form the shape of the constellation as it appears here on earth. Here's an early version of the Big Dipper I finished last summer to give you an idea of what these will look like. big dipper So far, I've been brute forcing the x and y coordinates for the stars from pictures of constellations stuck in Adobe Illustrator, I grab my z coordinates from Wikipedia, and once I've scaled and centered my (x,y,z)'s for all of a constellation's stars in a spreadsheet, I plot them as points in Geogebra with a cube frame drawn around them, each dimension of the cube ranging over -100 to 100 with the origin in the center. I'll then resave that file under each individual star's name, turn off all the other stars, and then draw a line segment connecting different cube edges and then slide its end points along the edge until the line intersects the center of the star. These lines are what will ultimately become the wires connecting the star to the frame edges in the final sculpture, and I generally find 2-5 possible solutions for each star. Here's an example of my found brute-force'd solutions for a star in Aquarius to illustrate (the red point is my marker to keep myself oriented): sadachiba What I want to know is, how can I SOLVE for these lines, either algebraically or numerically? While the process can be pretty meditative and relaxing sometimes, I am getting pretty tired of brute forcing all these solutions by hand in Geogebra, especially since it is difficult to get the line segment precisely through the plotted point by scooting around its end points (not to mention this just propogates my errors in the final, physical form, so no bueno), and because I know that I'm probably missing some of the possible solutions sometimes (and I want all the solutions for each star so I can have some wire position options for aesthetic reasons and to make sure no wires pass in front of other stars when viewed head-on). I had talked out the problem with some of my most trusted physics classmates and one of my physics professors last summer, but if memory serves, none of us ever came up with a solution, or in the very least I never found anything that worked. (Which is weird, because this seemed like it should be pretty easy to me, and honestly it still does.) I think I had tried some failed way involving determinants as one of my attempts, but I don't remember what it was and Lord knows what sketchbook that was in. At no point was there an attempt by any party to try and solve the problem numerically, but I've taken numerical analysis since then, so that option is now comfortably on the table for me if need be. So, what I'm working with here, essentially: Seven knowns, and two unknowns. The known (x,y,z) coordinates for the star Two known coordinates (with values of either -100 or 100, depending on which cube edge) and one unknown coordinate (the position along the length of that cube edge) for the first wire anchor Two known coordinates and one unknown coordinate for the second wire anchor on another cube edge What I want: a straightforward formula (or algorithm) for computing those two unknowns. A comp sci friend of mine has volunteered to write a script to automate this whole line-finding process for me, and I imagine that it will probably check all possible combinations of cube edges for solutions for what it's worth. Anyway, thank you in advance! I'm really looking forward to having this mystery solved.","['linear-algebra', 'geometry']"
2231295,"Uniform continuity of $f(x) = \frac{x+1}{x+2}$ on $(-2,\infty)$","Is the function $f(x) = \frac{x+1}{x+2}$ uniformly continuous on $(-2,\infty)$?   I know how to prove this for the case when the domain is closed or is, say,  $[-1, \infty)$,  but I am not sure how to estimate the fraction from above when working with this domain.","['uniform-continuity', 'functions']"
2231317,Predicting if $n^2 + 1$ is prime,"I'm trying to write a program that can tell if $n^2+1$ is prime where n is in the natural numbers (sorry I don't know how to write this in proper math notation). Sure, I can take a brute force approach to check if the number is prime, but I want to check millions of values of n, so as n gets big, $n^2$ gets out of hand quickly and my computing slows down. Is there some more efficient approach to check if it's prime?","['number-theory', 'prime-numbers']"
2231325,A subspace of $\omega_1$ is metrizable iff it is nonstationary,"I want to prove the following statement: A subspace $X$ of $\omega_1$ is metrizable if and only if $X$ is nonstationary in $\omega_1$. I haven't really achieved much: If $X$ is stationary, then $X$ is uncountable and it is easy to see that $X$ is not compact (not even Lindelöf).
So it would suffice to show that $X$ is sequentially compact. This however need not be the case as seen by the set $X=\omega_1\setminus\{\omega\}$ and sequence $x_n=n$. For the other direction, the only metrization theorem I'm familiar with is not applicable since if $X$ is nonstationary it need not be second-countable. It is however clear if $X$ is bounded, since then it is a subspace of a countable ordinal, which is metrizable.","['general-topology', 'set-theory', 'ordinals']"
2231341,Arranging $10$ people in $2$ lanes. Each lane has to have at least $2$ people.,"How many ways can $10$ people be arranged in two lanes, if each lane has to have at least two people? What I did is use $\binom{n+r-1}{r}$ but that ignores the order in two lanes. Say one lane has $3$ people the other has $7$. This method fails to count the order in each lane.","['permutations', 'combinatorics', 'discrete-mathematics']"
2231343,Gradient of a homogenous function,"I am having trouble constructing a proof for this preposition. I am not sure if I am misunderstanding the meaning of a homogenous functions, but either way I get stuck in my proof. Let $k$ be an integer. A function $f : \mathbb{R^n} \to \mathbb{R}$ is called homogenous of degree $k$ if $f(\lambda x) = \lambda^k f(x)$ for all $\lambda \in \mathbb{R}$ and $x \in \mathbb{R^n}$. Prove that if $f$ is homogenous of degree $k$ then $x \cdot \nabla f(x) = kf(x)$. Here is my go at it. Proof. (=>) Suppose $x \cdot \nabla f(x)$. Then  $$x \cdot \nabla f(x)$$ 
$$= x \cdot [\frac{\partial f}{\partial x_1}, ..., \frac{\partial f}{ \partial x_n}]$$ $$ = [x_1, ..., x_n] \cdot [\frac{\partial f}{\partial x_1}, ..., \frac{\partial f}{\partial x_n}]$$ $$ = \frac{\partial f}{\partial x_1} x_1 +  ... + \frac{\partial f}{\partial x_n} x_n $$ But I feel I've gone off course now. Any ideas / hints? Thanks!","['multivariable-calculus', 'real-analysis']"
2231349,How to determine if $\ f(x)=|x-2| $ is differentiable at 2,I need to determine if $\ f(x)=|x-2| $ is differentiable at 2. I was thinking I could use the definition of a derivative $\ \frac{(f(x+h)-f(x))}{h} $ but am kind of at a loss.,"['derivatives', 'analysis']"
2231362,Solving Recurrence Relation $a_n=6a_{n-1} - 9a_{n-2}$ for $n\geqslant2$,"So the problem is to solve this recurrence relation with the initial conditions $a_0 = 2, a_1 = 21$. $a_n=6a_{n-1} - 9a_{n-2}$ for $n\geqslant2$ And also find the value of $a_{2016}.$ Here is my solution but I'm not entirely sure if it's correct. Was wondering if anyone can confirm what I did is valid or perhaps I made a mistake somewhere? Thanks in advance.","['recurrence-relations', 'discrete-mathematics']"
2231388,Derivations: $I/I^2$ is isomorphic to $I \otimes A$,"Consider a ring map $B \rightarrow A$. Consider the map $f:A \otimes_{B}A \rightarrow A$, where $x \otimes y$ goes to $xy$. Let $I$ be the kernel of $f$. Why is it true that $I/I^2$ is isomorphic to $I \otimes_{A \otimes_{B}A} A$? This is what I've been able to prove till now: Let $R=A \otimes_{B}A$. Now, consider the $R$-module homomorphism  $\phi$from $I$ to $I\otimes (R/I)$, $\phi(a)=a\otimes 1$. It is easy to see that the kernel of $\phi$ contains $I^2$. How do I prove it is exactly $I^2$?","['abstract-algebra', 'tensor-products', 'algebraic-geometry', 'commutative-algebra']"
2231441,"Show that $\nabla f \in C^{1,1}$ if the difference between $f$ and its linear interpolant has a quadratic bound","Let $f : \mathbb{R}^d \to \mathbb{R}$ be a differentiable function such that for every $x,y$ and every $\lambda \in [0,1]$: $$|\lambda f(x) + (1-\lambda) f(y) -f(\lambda x + (1-\lambda)y)| \leqslant |x-y|^2 $$ holds. How can one show that there is a constant $C>0$ such that we have : $$|\nabla f (x) - \nabla f (y)| \leqslant  C |x-y|,$$ for every $x,y$. I did not find a way to solve this.","['derivatives', 'real-analysis', 'convex-analysis', 'vector-analysis']"
2231466,metric on SE(3),"Let
$
SO(3) = \{ R  \mid RR^\top = I_3 \text{ and } \det(R) = 1 \}
$
and
$$
SE(3) = \left\{\begin{bmatrix} R & {\bf t} \\ {\bf 0}^\top & 1 \end{bmatrix}\mid R \in SO(3), {\bf t} \in \mathbb{R}^3\right\}.
$$
My question is, given two matrices $H_1, H_2 \in SE(3),$ can anyone provide a formula for the geodesic distance between them? My best guess is to add the magnitude of the rotation and the magnitude of the translation.
Then, the the distance between $H_1$ and $H_2$ is given by
$$
||H_1 - H_2|| 
= ||{\rm Rodrigues}(R_1R_2^\top)||_2 +\frac{1}{2} \left( ||{\bf t}_1 - R_2^\top {\bf t}_2||_2+ ||{\bf t}_2 - R_1^\top {\bf t}_1||_2\right),
$$
where I am using Rodrigues' formula to find the angle-axis representation for $SO(3)$ in order to easily find the magnitude of a rotation.
This is rather ad-hoc, but it at least it is zero when $H_1=H_2$, strictly positive otherwise, and symmetric.  Whether or not it obeys the triangle inequality I do not know for sure, but I think no. Calin Belta and Vijay Kumar's 2002 paper seems to be relevant, but they are talking about smooth rigid motions parameterized by points in $SE(3)$, and not necessarily just looking at the absolute difference that I am interested in.  Maybe its the same, but I don't know enough differential geometry to tell.","['rotations', 'metric-spaces', 'differential-geometry']"
2231497,"for $n\geq 3$ $C(n,k)$for the following mapping","Question : For a finite set $A$, let $|A|$ denote the number of elements in $A$. Let $F$ denote the set of all functions $f:\{1,2,3,4,\dot{}\dot{},n\}\rightarrow\{1,2,3,4,\dot{}\dot{},k\} (n\geq 3,k\geq 2)$ satisfying $f(i)\neq f(i+1) $ for every $i:1\leq i\leq n-1$ and $C(n,k)$ denote the number of functions in $F$ satisfying $f(n) \neq f(1)$. Then For $n \geq 3, C(n,k)$ is? Answer given is $(k-1)^n + (-1)^n(k-1)$ but I happen to have no idea How to get there. What i initially though was $f(1)$ can be chosen in $K$ ways and $f(r)$ for $r\neq 1$ in $(k-1)$ ways. So  number of maps of $f$ are $$|F|=k(k-1)^{n-1}$$And the number of maps for $f(n)=(f1)$ is same as the number of maps in $F$ for which $f(n-1) \neq f(n)$ But That's it. I'm lost on how to proceed. Please guide.","['combinatorics', 'functions', 'principal-ideal-domains']"
2231517,Motivation Of Correlation Coefficient Formula,"Definitions correlation coefficient $= r = \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum_{i=1}^{n}(x_i - \bar{x})^2\sum_{i=1}^{n}(y_i - \bar{y})^2}}$ My Question What is the motivation of this formula? It's supposed to measure linear relationships on bivariate data, but I don't understand why it would do that as defined. For example, Riemann integrals are said to measure area under a curve, and that makes sense because $\sum f(x_i)\Delta x$ is adding areas of rectangles under the curve $f(x)$ approximating its area more and more as we take more samples. Does such an intuition exist for the correlation coefficient? What is it? My background in statistics is nothing but a bit of discrete probability. I know histograms, data plots, mean, median, range, variance, standard deviation, box plots and scatter plots at this point (from reading the first weeks material on an introductory statistics class). My Research All of the ""Questions that may already have your answer"" seemed to either be asking about what the formula said mathematically or asked questions that were more advanced than my knowledge.",['statistics']
2231530,Derivative of matrix valued function $f(A)=AA^T$,"This is part of a larger proof on the orthonormal group viewed as a manifold. I have never done anything with matrix calculus and am trying to find $df$ where 
$$
f(A)=AA^T
$$
where 
$$
f:M_{n\times n}\to S(n)
$$
wehre $S(n)$ are the symmetric $n\times n$ matrices. So 
we should have 
$$
df:M_{n\times n}\to T_pS(n)
$$
where $p\in S(n)$.","['matrices', 'differential-topology', 'matrix-calculus', 'manifolds']"
2231535,show that if $f$ is uniformly differentiable then prove that $f'$ is continuous,"How would I go about showing that if $f$ is uniformly differentiable then $f'$ is continuous. my attempt:
A differentiable function $f:[a,b]\to \Bbb R$ is said to be uniformly differentiable on $[a,b]$ if $\forall \epsilon>0 \exists \delta>0:\forall x,y\in[a,b]$ we have $$0<|x-y|<\delta\implies |\frac{f(x)-f(y)}{x-y}-f'(y)|<\epsilon$$ I don't know where to go from here, any help would be highly appreciated.","['derivatives', 'real-analysis', 'continuity']"
2231642,Prove that $\pi$ is irrational help,"I am working through Cartwright's proof for $\pi$ being irrational; specifically, the problem states: Given $$A_n=\int_{-1}^{1}(1-x^2)^n\cos\left(\frac {\pi x}{2}\right)\,dx$$ Prove: $$A_n=\frac {8n(2n-1)A_{n-1}-16n(n-1)A_{n-2}}{\pi ^2}.$$ I must prove it using integration by parts and have gotten really close to the answer but I am stuck at this step: $$A_n=\frac{-16n(n-1)}{\pi^2}\int_{-1}^{1}x^2(1-x^2)^{n-2}\cos\left(\frac {\pi x}{2}\right)+\frac {8n}{\pi^2}A_{n-1}.$$ Specifically, I'm wondering how one could get rid of the $x^2$ term out of the integral to get $A_{n-2}.$ Thanks in advance!",['real-analysis']
2231689,Calculus - Infinite Series,"Decide whether the infinite series converges of diverges.
$$\sum_{n=1}^\infty \frac{2^n+3^n}{3^n+4^n}$$ My thought process: The nth term test doesn't seem viable after initial use. The comparison function I derived for DCT/LCT is: $\frac{3^n}{4^n}$.
   I cannot create an appropriate inequality between the given function and my comparison function I found, so I tried LCT. I am aware that 
$\sum_{i=1}^\infty \frac{3^n}{4^n}$ is geometric and because the common ratio (r) is $ \frac{3}{4}$, $-1<r<1$ the series converges, however I cannot compute the limit LCT requires. Application of the root test would seem unbeneficial because roots do not split over sums. As for the ratio test I was also unsuccessful in proceeding with the computation of the limit. The above are the only tests I have learned as of right now. My question is what test should I be looking to utilize to determine convergence or divergence?","['sequences-and-series', 'calculus']"
2231695,Why define $|x|$ by a piecewise function?,"So I was recently solving a question about the derivative of $|\sin(x)|$ and the answer above me used a piecewise function to solve the problem. I used the definition $|x|=\sqrt{x^2}$, and the problem became incredibly easy to solve. So, I guess what I am wondering, is why people define $|x|$ by a piecewise function like: $|x|= \begin{cases}
    x , & \text{if } x \geq 0\\
    -x, & \text{otherwise}
\end{cases}$ Because it is harder to differentiate and the only possible application is integration. Plus, my definition is easier to prove: Proof: The absolute value of a real number is defined as the magnitude of the real number. The magnitude of a complex number $a+bi$ is $\sqrt{a^2+b^2}$, and if $b$ is $0$ because the number is real, then $|a|=\sqrt{a^2}$. So, in conclusion, I want to know how this piecewise definition came about, and why I never see my definition. If possible, I would like to know the flaws with my definition.","['calculus', 'definition']"
2231737,Methods for finding $\cos(4x)$ given that $\sin(2x) = \frac{3}{5}$,If $\sin(2x) = \frac{3}{5}$ Find $\cos(4x)$.. I tried by : $\cos(4x)= \cos(2\cdot2x)$.. And $\cos (2\cdot2x) = 1-2\sin^2(2x)$ .. From it ---- $\cos(4x)=0.28$. Is there any other ways ?,['trigonometry']
2231738,"$X$ given $\Theta$ is $\operatorname{Poisson}(\Theta)$, $\Theta$ is distributed as $\operatorname{Gamma}(a,b)$. What are the Mean and Variance of $X$?","This is what I have so far: Joint Distribution (product of pmf of $X$ and pdf of $\Theta$)  $$f(x,\theta)=\frac{\theta ^xe^{-\theta}}{x!}\frac{b^a}{\Gamma (a)}\theta ^{a-1}e^{-b\theta}$$ and with a little algebra we can get $$f(x,\theta)=\frac{1}{x!}\frac{b^a}{(b+1)^{x+a}}\frac{\Gamma (x+a)}{\Gamma (a)}\cdot\frac{(b+1)^{x+a}}{\Gamma (x+a)} \theta ^{(x+a)-1}e^{-(b+1)\theta}$$ for easy derivation of the pdf of $X$: $$f(x)=\frac{1}{x!}\frac{b^a}{(b+1)^{x+a}}\frac{\Gamma (x+a)}{\Gamma (a)}\int_0^\infty\frac{(b+1)^{x+a}}{\Gamma (x+a)} \theta ^{(x+a)-1}e^{-(b+1)\theta}d\theta$$ leaving us with$$f(x)=\frac{1}{x!}\frac{b^a}{(b+1)^{x+a}}\frac{\Gamma (x+a)}{\Gamma (a)}$$
Which looks kind of similar to some kind of beta distribution?
What kind of distribution can this be identified as?
If it's not a standard distribution, how can I calculate the raw moments?
Is integration or summation appropriate (Changing $x!$ to $\Gamma (x+1)$)?
Thanks for your help!","['expectation', 'probability-distributions', 'statistics', 'probability', 'poisson-distribution']"
2231750,Is there a proof for this modified Collatz-like problem?,"The Collatz Conjecture is a famously unproven problem in mathematics, but I was thinking of a slight modification, and whether or not a proof of this different form is trivial. Here is a statement of the original problem; Take a starting integer n and apply the following operations; multiply by 3n + 1 if odd, divide by two if even. Take the resulting number and feed back into the algorithm. After a finite number of steps the algorithm will reach 1. Here is a modified statement; For any integer n you can always apply some combination of multiplying by 3n + 1 and dividing by 2 to get to 1. The difference is that you don't explicitly define what to do in the case when a number is even or odd. Of course, you can only divide by 2 when the number you are working with is even, but in this statement, taking an even number and multiplying by 3n+1 follows the rules so, in some ways, the Collatz conjecture is a special case of this form. Anyways, has anyone heard of a proof of something like this and if not, would a proof tell us anything interesting about the Collatz conjecture itself? Thanks!","['number-theory', 'algorithms', 'collatz-conjecture']"
2231778,Fredholm Alternative - what went wrong?,"So I found the general solution for this DE with these BCs:
$$\frac{d^2u}{dx^2}+u=1$$
$$u(0)=u(L)=0$$
by doing:
$$u(x)=Acos(x)+Bsin(x)+1$$
$$u(0)=0=A+1 \therefore A=-1$$
$$u(L)=0=-cos(L)+Bsin(L)+1 \therefore B=\frac{cos(L)-1}{sin(L)}$$
$$\implies u(x)=-cos(x)+1+sin(x)\frac{cos(L)-1}{sin(L)}=1-cos(x)-sin(x)tan(\frac{L}{2})$$ So then I wanted to check the Fredholm Alternative. So the homogeneous solution would be:
$$u_h(x)=Acos(x)+Bsin(x)$$
$$u_h(0)=0=A \therefore A=0$$
$$u_h(L)=0=Bsin(L) \implies L=n\pi \implies B=1$$
$$\implies u_h(x)=sin(x)$$
so checking Fredholm...
$$\int_{0}^{L} (1)sin(x) dx=-cos(x)\Big|_0^L=1-cos(L)\ne0$$ Could anyone give me insight what's going on here? Doesn't this mean that the Fredholm Alternative is telling me there's no solution? What's going on here? Any help in understanding this would be greatly appreciated. edit: The Fredholm alternative summarizes the results for nonhomogeneous problems:
$$L(u)=f(x)$$
subject to homogeneous BCs of the self-adjoint type. Either: $u=0$ is the only homogeneous solution (i.e. $\lambda \ne 0$) in which case the nonhomogeneous problem has a unqiue solutions, or there are nontrivial homogeneous solutions $\phi_h(x)$ (i.e. $\lambda = 0$ is an eigenvalue) in which case the nonhomogeneous problem has no solutions or an infinite number of solutions For the nonhomogeneous problem with homogeneous BCs, then, solutions exist only if the forcing function is orthogonal to all homogeneous solutions. The forcing function being orthogonal to the homogeneous solution (with weight 1) is represented by:
$$\int_{a}^{b}f(x) \phi_h(x) dx=0$$ The number of solutions of $L(u)=f(x)$ subject to homogeneous BCs is given by: if $\phi_h=0$ ($\lambda\ne0$) and $\int_{a}^{b}f(x) \phi_h(x) dx=0$ then the number of solutions is $=1$ if $\phi_h\ne0$ ($\lambda=0$) and $\int_{a}^{b}f(x) \phi_h(x) dx=0$ then the number of solutions is $=\infty$ if $\phi_h\ne0$ ($\lambda=0$) and $\int_{a}^{b}f(x) \phi_h(x) dx\ne0$ then the number of solutions is $=0$","['partial-differential-equations', 'homogeneous-equation', 'integration', 'orthogonality', 'ordinary-differential-equations']"
2231786,definite integral- how to solve. I know the substitution.,I know the substitution but how should I continue? $$\int_0^1 x\sqrt{\frac{1-\sqrt{x}}{1+\sqrt{x}}}dx$$,"['trigonometry', 'calculus', 'algebra-precalculus', 'integration', 'definite-integrals']"
2231806,About generator of a cyclic commutator subgroup,"The following problem appears in the book of I. Macdonald on Group Theory: Let G be a group such that (1) $[G,G]$ is infinite cyclic. (2) $[G,G]\subseteq Z(G)$ . Prove that $[G,G]$ is generated by a single commutator . I want to consider this question with a different face. Q. Is there a group $G$ satisfying only (1), but $[G,G]$ is not generated by a commutator?",['group-theory']
2231813,Proving limit of sin(1/x)cos(1/x) doesn't exist as x goes to 0,"Just a quick question, this may or may not be a duplicate by the way. I've seen the proof of the trig functions not existing separately but I couldn't seem to find them multiplied together like in this problem. My question is could I just separate the two functions, prove that both limits do not exist and say the overall limit doesn't exist or is that the completely wrong way of approaching the problem? EDIT: Here's my attempt with the use of $\frac{sin(\frac{2}{x})}{2}$ hint. Proof: Note that $\sin(\frac{1}{x})\cos(\frac{1}{x})$ =  $\frac{\sin(\frac{2}{x})}{2}$. Let f(x) =  $\frac{\sin(\frac{2}{x})}{2}$. $\sin \theta = 1$ when $\theta = \frac{4k+1 \pi}{2}$ for $k \in \mathbb{Z}$ $\sin \theta = -1$ when $\theta = \frac{4k+1 \pi}{2}$ for $k \in \mathbb{Z}$ so $\sin(2/x_n) = 1$ when $x_n = \frac{4}{(4n+1)\pi}$ which equals $0$ when $n$ goes to infinity and $f(x_n) = 1$ for all $n$ $\sin(2/y_n) = 1$ when $y_n = \frac{4}{(4n-1)\pi}$ which equals $0$ when $n$ goes to infinity and $f(y_n) = -1$ for all $n$ It then follows that: $\sin(2/x_n)/2 \implies f(x_n) = 1/2$ $\sin(2/y_n)/2 \implies f(y_n) = -1/2$ Since $\{x_n\}$ goes to zero $x_n \neq 0$ and $\{y_n\}$ goes to zero $y_n \neq 0$ but $\{f(x_n)\} \rightarrow 1/2 \neq -1/2 \leftarrow\{f(y_n)\}$ $\lim_{x \to 0} f(x)$ does not exist by the sequential criterion. Is this totally off?",['analysis']
2231827,Prove that $\det( M) \in \mathbb{Z}$,Let $\Gamma$ be a finite multiplicative group of matrices with complex entries. Let $M$ denote the sum of the matrices in $\Gamma$ . Prove that det $M$ is an integer. Hint: square $M$ and use the distributivity of multiplication with respect to the sum of matrices. I tried using the hint but I am not able to get to anything.,"['matrices', 'abstract-algebra', 'determinant', 'group-theory', 'linear-algebra']"
2231830,How do I find the real and imaginary part of $z+ e^z $,How can I find the imaginary and real part of $z + e^z$ ? I tried but I only get $$x + yi + e^x e^{yi}$$,"['algebra-precalculus', 'complex-analysis', 'complex-numbers', 'exponential-sum']"
2231859,"Finding the limit of the sequence with $a_1=a$, $a_2=b$, and $a_{n}=\sqrt{a_{n-1} a_{n-2}}$","Let there be a recursive sequence that begins with two terms, $a_1 = a$ and $a_2 = b$. The third term, $a_3$, is created by taking the geometric mean ($\sqrt{a \times b}$) of the previous two terms. The fourth term, $a_4$, is once again created by taking the geometric mean of the previous two terms. This process is repeated indefinitely. For example, if $a = 1$ and $b = 8$, $a_3 = \sqrt{1 \times 8}=  \sqrt8 =2.82843... $ $a_4 = 4.75683...$ $a_5 = 3.66802...$ $a_6 = 4.17710...$ ...and so on. If you'll notice, as the terms go on, they are slowly converging towards one number. In this case, it's 4. This number will (tentatively) be called the ""limit"" ($L$). My question is, what is the general rule for finding $L$ in terms of $a$ and $b$?","['algebra-precalculus', 'sequences-and-series']"
2231868,Proof of a proposition regarding recursive definitions (from Terence Tao's Analysis I),"I'm currently reading Terence Tao's book Analysis I , and I got stuck on his proposition 2.1.16 about recursive definitions ; actually, I don't understand his (informal) proof of it . First, here are the five Peano axioms he's using : Axiom 2.1. $0$ is a natural number. Axiom 2.2. If $n$ is a natural number, then $n{++}$ is also a natural number. Axiom 2.3. $0$ is not the successor of any natural number ; i.e., we have $n{++} \ne 0$ for every natural number $n$ . Axiom 2.4. Different natural numbers must have different successors ; i.e., if $n, m$ are natural numbers and $n \ne m$ , then $n{++} \ne m{++}$ . Equivalently, if $n{++} = m{++}$ , then we must have $n=m$ . Axiom 2.5. (Principle of mathematical induction). Let $P(n)$ be any property pertaining to a natural number $n$ . Suppose that $P(0)$ is true, and suppose that whenever $P(n)$ is true, $P(n{++})$ is also true. Then $P(n)$ is true for every natural number $n$ . And here is the proposition, and the proof I'm stuck on : Proposition 2.1.16 (Recursive definitions). Suppose for each natural number $n$ , we have some function $f_{n} : \mathbb{N} \rightarrow \mathbb{N}$ from the natural numbers to the natural numbers. Let $c$ be a natural number. Then we can assign a unique natural number $a_{n}$ to each natural number $n$ , such that $a_{0} = c$ and $a_{n{++}} = f_{n} (a_{n})$ for each natural number $n$ . Proof . (Informal) We use induction. We first observe that this procedure gives a single value to $a_0$ , namely $c$ . (None of the other definitions $a_{n{++}}:= f_{n} (a_n)$ will redefine the value of $a_0$ , because of Axiom 2.3.) Now suppose inductively that the procedure gives a single value to $a_n$ . Then it gives a single value to $a_{n{++}}$ , namely $a_{n{++}}:= f_{n} (a_n)$ . (None of the other definitions $a_{m{++}}:= f_{m} (a_{m})$ will redefine the value of $a_{n{++}}$ , because of Axiome 2.4.) This completes the induction, and so $a_n$ is defined for each natural number $n$ , with a single value assigned to each $a_n$ . I don't understand how does that prove anything. I feel like all he's saying is that « all natural numbers are different from each others » ; I don't understand why we couldn't have, for example, $a_0 = a_1 = c$ (for instance, if we consider the Fibonacci sequence : $0, 1, 1, 2, ...$ , we have $a_1 = a_2 = 1$ ). I actually found another proof of uniqueness on Wikipedia (regarding the Recursion theorem) and I think I understood it, but I really would like to understand Tao's point of view as well. Finally, shouldn't we prove that such a function exists as well, instead of just supposing it exists ? I found this document which gives a proof for the existence of such a function (at pages 2-3), but I'm a little bit confused about the way they do it: can we really ""imagine"" or ""create"" such sets as $S$ and $g$ , like they do, and draw conclusions from them? Another thing that disturbs me regarding their approach is that Tao doesn't talk about sets before chapter 3, and the proposition above comes from chapter 2... so the question here is: how could we prove the existence of such functions as the ones described in the recursion theorem without knowing anything about sets and set theory? So, as you can see... I'm pretty confused about a lot of things. Any help would be greatly appreciated!","['real-analysis', 'peano-axioms', 'proof-explanation']"
2231893,"Tangent Space of SL(n,R) at arbitrary point, e.g. not at $\mathbb{1}$","I am looking for the tangent space of $SL(n,\mathbb{R}) = \{A\in\mathbb{R}^{n\times n} | \det{A}=1 \}$ (actually $n=3$) at an arbitrary $M\in SL(n,\mathbb{R})$. From now on I will omit the $\mathbb{R}$ for convenience. It is well known and easy to prove that the tangent space at the identity matrix $\mathbb{1}$, $T_1SL(n)$, is the set of all traceless matrices of the same size. However I am not able to generalize this result. These are my thoughts: Let $\gamma:\mathbb{R}\to SL(n)$ be a curve with known $\gamma(0) = M$ and unknown $\gamma^\prime(0)=X$. Let's differentiate the $SL$-characteristic equation: $$\frac{d}{dt}|_{t=0}\det{\gamma}(t) = D(\det)|_{\gamma(0)}\,\cdot\,\gamma^\prime(0) = \frac{d}{dt}1 = 0$$ Here $A\cdot B = A_{ij}B_{ij}$. The trick for $M=\mathbb{1}$ is $$D(\det)|_1 = \mathbb{1},$$ so the above differentiation equation reads ${\rm tr}(\gamma^\prime(0))=0$. However in the general case $$D(\det)|_M = {\rm Cof}(M)$$ the cofactor matrix. As far as I see ${\rm Cof}(M) \cdot X = 0$ is of no use. Any ideas out there?
Thanks.","['matrix-equations', 'matrices', 'matrix-calculus', 'differential-geometry', 'lie-groups']"
2231926,"Tangent Space of SymSL(n,$\mathbb{R}$) at arbitrary point","I am looking for the tangent space of $SymSL(n,\mathbb{R}) = \{A\in\mathbb{R}^{n\times n} | \,A^{\rm T} = A,\; \det{A}=1 \}$ (actually $n=3$) at an arbitrary $M\in SymSL(n,\mathbb{R})$. (Actually I am interested in $SymSL^+(n,\mathbb{R}) = \{A\in\mathbb{R}^{n\times n} | \,A^{\rm T} = A,\; \det{A}=1,\; A \text{ is positive definite} \}$, but I have the feeling it boils down to the title of this question.) Related questions: Tangent Space of SL(n,ℝ) at arbitrary point, e.g. not at $\mathbb{1}$ Tangent space of Sym(n,ℝ) The first question's answer doesn't work here because $Sym(n)$ is not a group, the second question's answer is not applicable because $SL(n)$ is not a vector space. Hence $SymSL(n,\mathbb{R})$ is neither a group nor a vector space. I would very much appreciate any comments. edit #2: $SL(n,\mathbb{R})$ is connected and smooth. So $SymSL(n,\mathbb{R})$ is the intersection of a connected smooth manifold with a vector space. This makes me believe we can talk about a tangent space in this case. Some more possibly usefull facts: the set $SymSL^+(n,\mathbb{R})$ I am actually interested in is a connected, simply connected and complete Riemannian manifold.","['matrix-equations', 'matrices', 'matrix-calculus', 'differential-geometry', 'lie-groups']"
2231947,Do the mean and variance of a random variable define it completely?,"Do the mean and variance of a random variable define it completely? In particular, if $X$ is a random variable, such that $E(X) = \operatorname{Var}(X) = u$, does that imply that $X \sim \operatorname{Poisson}(u)$ ? If so, then a proof that a RV is Poisson would require only to show the above relationship which is very useful. Otherwise, what measures can uniquely define a random variable, or a Poisson Random Variable?","['statistics', 'probability', 'probability-distributions']"
2231965,"Count number of increasing functions, nondecreasing functions $f: \{1, 2, 3, \ldots, n\} \to \{1, 2, 3, \ldots, m\}$, with $m \geq n$.","I stumbled upon a question given like: Let $m$ and $n$ be two integers such that $m \geq n \geq 1$. Count the number of functions $$f: \{1, 2, · · · , n\} \to \{1, 2, · · · , m\}$$ of the following two types: (a) strictly increasing; i.e., whenever $x < y, f(x) < f(y)$, and (b) non-decreasing; i.e., whenever $x < y, f(x) \leq f(y)$. I tried in the following way. For (a). We can say $f(n)>f(n-1)$ AND $f(n)>f(n-2) \ldots f(n)>f(1)$ (total $n-1$ elements) Similarly for $f(n-1)>f(n-2), f(n-1)>f(n-3) \ldots f(n-1)>f(1)$ (total $n-2$ elements)... and $f(2)>1$ Like this $$(n-1) + (n-2) + \ldots + (1) = \frac{n(n-1)}{2}$$ Is this correct? For (b). Since there's equality, it will be $$n + (n-1) + ... (1) = \frac{n(n+1)}{2}$$ Is my approach correct? Any help is appreciated. Thanks in advance.","['combinatorics', 'functions']"
2232068,Is there an algorithm that can decide whether a polygon is self-intersecting using only its vertex coordinates?,"I'm trying to determine whether a polygon is self-intersecting or not by calculating the sum of the interior angles; i.e. if the sum is less than $(n-2)\pi$, then it is self-intersecting. The information that I have is the ordered set of vectors locating the vertices on the plane. I can calculate the angle between sides using dot and cross product, but my algorithm doesn't distinguish between internal and external angles. Also, I need the algorithm to work regardless of the polygon's regularity and convexity. Any suggestions will be much appreciated.","['polygons', 'optimization', 'trigonometry', 'algorithms', 'geometry']"
2232115,Explicit computation moment map complex projective space,"Consider the hamiltonian action of $T^2$ on $\mathbb{CP}^2$ : $$ \varphi: ((e^{i\theta_1},e^{i\theta_2}),[z_0:z_1:z_2]) \longmapsto [z_0:e^{i\theta_1}z_1,e^{i\theta_2}z_2].$$ I've read that its moment map is $$ \mu (z_0,z_1,z_2) = -\tfrac{1}{2} (\tfrac{|z_1|^2}{|z_0|^2+|z_1|^2+|z_2|^2},\tfrac{|z_2|^2}{|z_0|^2+|z_1|^2+|z_2|^2}).$$ How can I show this with a explicit calculation of $d\mu^X$ and $i_{X^\#}\omega $ 
 to show they are equal? I could do this with the same action but on $\mathbb{C}^2$, with polar coordinates. Would this work in this case, if yes what would be the equivalent of polar coordinates for projective space?","['complex-geometry', 'projective-geometry', 'symplectic-geometry', 'moment-map', 'differential-geometry']"
2232143,Large list of ordinary differential equations for practice,"I am looking for a large list of ordinary differential equations, as a practice resource. Preferably the list should be in order of ""difficulty"" and allow me to practice the different techniques (change of variables, etc). Do you have a suggestion for a good list like this?","['reference-request', 'ordinary-differential-equations', 'online-resources']"
2232145,Prove that a polynomial diverges to infinity.,"I would like to prove the following statement: Let $P$ be a polynomial of degree $n$ where $n$ is an odd natural number and $x$ $\in$ $\mathbb{R}$. $P(x)=a_{0}+a_{1}x+ ... + a_{n}x^{n}$ If $a_{n} > 0$, then $\lim_{x\to\infty}P(x)=\infty$ I am thinking of three ideas in order to prove the statement above. $1$. $\lim_{x\to\infty}P(x)=\infty$ if for every $M>0$, there exists $K \in \mathbb{R}$ such that if $x \in \mathbb{R}$ with $x>K$, then $P(x)>M$. $2$. $P$ is continuous on $\mathbb{R}$. $3$. Contradiction: $a_{n} > 0$ but $\lim_{x\to\infty}P(x)\neq\infty$ Although I'm thinking the ideas above might help me prove the statement, but I cannot prove it. Could anyone help me with this?","['real-analysis', 'polynomials', 'limits', 'functions', 'analysis']"
2232157,The most effective windshield-wiper setup. (Packing a square with sectors),"I was on the bus on the way to uni this morning and it was raining quite heavily. I was sitting right up near the front where I could see the window wipers doing their thing. It made me think ""what is the best configuration of window wipers for cleaning the maximum area of window?"" Rather than dealing with rectangles of arbitrary size, it is good to start by looking at the specific case of a square. To abstract the problem into a mathematical format, I'll restructure it like so: What is the maximum proportion of a square that can be packed with non-overlapping circle-sectors with origins on the edge of a square? However, $($while still sitting on the bus$)$ I realised that the answer is always ""the whole square"". This is because you can recursively define configurations of sectors that get closer to each other with a smaller angle, as shown below: The way to get around this ""solution"" is by adding another restriction: The sectors should be uniquely defined by their origin and radius. This is possible if ""every sector must have the maximum angle possible where the radius doesn't leave the square"". For example, even the first case for the sequence I gave is no longer allowed. The two sectors have angles of $\frac{\pi}{4}$, but with the new rule the arcs must both have angles of $\frac{\pi}{2}$ as their radii stay in the square for this angle. However, in this case the two sectors overlap, showing that it is an illegal configuration. Here are some examples of allowed configurations: Clearly various ""infinite"" things happen, as these all resemble apollonian gaskets. It seems like a calculus problem but I've spent too much time dealing with topology that I'm not really sure where to start! Once the square case is covered, it's natural to generalise to rectangles and parallelograms, and eventually to any polygon. Once all polygons are ""solved"", any two dimensional shape bounded by a closed curve may be solvable as well! Any thoughts and discussion will be appreciated. EDIT A number of people (mainly friends making fun of me at uni) have pointed out that real windshield wipers do overlap, and that's fundamental to their effectiveness. I realise this, but for the purpose of mathematical abstraction I felt that ""supposing there is no overlap"" creates an ideal level of complexity. Some more precision Let $P$ be a polygon with boundary $\partial P$. (First suppose $P$ is a square, but it will definitely be interesting to generalise.)
Let $o_i$ be points in $\partial P$, and $r_i \in \mathbb{R}$. Then each pair $o_i, r_i$ uniquely determines a circle $C_i$ centred at $o_i$. Label each of the points where $C_i$ intersects $\partial P$, and draw straight lines from these points to $o_i$. This splits the circle into sectors. Now remove every sector that encloses a point outside of $P$. The sector(s) you are left with depend only on the starting point, radius, and polygon. Given that you can have as many starting points as needed, what is the greatest proportion of the polygon (in terms of area) that can be packed by these sectors which do not overlap? Suggested variations What is the optimal solution where you try to maximise the area which is cleaned but minimise the number of wipers? It seems like the 4th diagram is probably the solution to the square. But what if only finitely many wipers can be used? What is the solution for each $n$? What if you do in fact let the sectors overlap? (This will completely change the nature of the problem as it isn't meaningful unless the dynamics of the wipers is considered.)","['packing-problem', 'plane-geometry', 'optimization', 'euclidean-geometry', 'geometry']"
2232167,"Since the $\omega$-limit is invariant, then it must contain only points with $\dot{V}(x)=0$","I am trying to understand the following proof: I do not fully get why he says: since $\Gamma^+$ (which I think is usually referred to as the $\omega$-limit) is an invariant set, then $\dot{V}(x)=0$ in $\Gamma^+$. Intuitively, it seems to me that, since $\omega$-limit is invariant, it must be composed of singularities or closed orbits (and I know that the $\omega$-limit is connected because the orbits for positive times are trapped inside a compact set). But closed orbits are impossible because $V$ is strictly decreasing, so $\omega(x)$ must only contain singularities. But even if this reasoning is correct, it seems to me that it is not rigorous as it is.","['ordinary-differential-equations', 'dynamical-systems', 'proof-explanation']"
2232188,why t-distribution and normal distribution?,Why do we use the t-distribution when the population standard deviation is not known? And similarly why the normal distribution when standard deviation is known?,"['statistics', 'probability', 'parameter-estimation']"
2232239,What is the difference between $x^{1/2}$ and $\sqrt{x}$?,"As far as I know, $x^{1/2} = \sqrt{x}$. On the other hand, $\sqrt{i^4} = \sqrt{1} = 1$ and $(i^4)^{1/2} = i ^ {4/2} = i^2 = -1$. Does this mean that $\sqrt{x} \neq x^{1/2}$?","['algebra-precalculus', 'complex-numbers']"
2232287,the 8 queens on the chessboard: variations,"i've heard of the 8 Queens problem: put 8 queens onto a standard chessboard without any of them able to capture any other queen. my question is: what is the smallest 2-D chessboard that can have queens? (as in the chessboard is $x^2$, with x queens on it. and what about cubic and hyper-cubic chessboards? A queen can move in any direction (up, down, left, right, diagonal, forward, backward, and the movement in any hyper-cubic space","['puzzle', 'chessboard', 'geometry']"
2232328,In Calculus of Variation: Problem applying variational principle theorem,"Let $f:\mathbb R^m \rightarrow [0,+\infty)\;$ be a smooth function
   that vanishes on a finite set $A\;$ where $\vert A \vert\; \ge 2$ and
   the maps $v:(l^{-},l^{+}) \rightarrow \mathbb R^m\;$ defined by $\mathcal M= \{\;v\in W^{1,2}_{loc} (l^{-},l^{+});\;-\infty \le  l^{-}
 \lt l^{+} \le +\infty\;,\;\lim_{x \to l^{-}}  v(x)=a_1 \in
 A\;,\;\lim_{x \to l^{+}} v(x)=a_2 \neq  a_1 \in
 A\;\;,\;v((l^{-},l^{+}))\subseteq \mathbb R \setminus A \}\;$. Show that a minimizer of the functional $\;I(v)=\int_{l^{-}}^{l^{+}}
\frac{{\dot v}^2}{2} + f(v) \;dx$ on $\;\mathcal M\;$ exists. I found after some research the following theorem: Let $\;X\;$ be reflexive, $\;M\subset  X\;$ nonempty and weakly sequentially closed,$\; F:M\rightarrow \mathbb R \;$ coercive and weakly sequentially lower semi-continuous. Then there exist $\;x_0 \in M\;$ such that ; $\;F(x_0)=\inf_{x \in M} F(x)\;$ I know $\;W^{1,2}\;$ is reflexive and for the coerciveness of $\;I\;$ there is a hint : ""Assume $\limsup_{\vert v \vert \to +\infty} f(v) \gt 0\;$"" which I don't completely understand why is needed. My question : How do I prove that $\; \mathcal M\;$ and $\;I\;$ satisfy the above theorem? I'm really new to Sobolev Spaces and I hadn't seen before the term ""weakly sequentially closed"". I would appreciate if somebody could help me through this. Furthermore, any suggestions about useful books related to this topic, would be valuable. Thanks in advance!!!","['functional-analysis', 'weak-convergence', 'coercive', 'calculus-of-variations', 'sobolev-spaces']"
2232338,Limit of a sum 1: $\lim _{n\to \infty }\sum _{k=1}^n\sqrt{n^4+k} \cdot \sin \frac{2k\pi }{n}$,"$$\lim _{n\to \infty }\sum _{k=1}^n\sqrt{n^4+k} \cdot \sin \frac{2k\pi }{n}$$ It looks like a Riemann sum, but I don't know how to approach it. Any hint would be appreciated. (Without Taylor expansion) EDIT: The answer is $- \frac{1}{4 \pi}$","['riemann-sum', 'limits']"
2232371,Characterization of finite morsphisms over $\operatorname{Spec }O_K$,"Let $K$ be a number field with ring of integers $O_K$. Now consider a finite  and dominant (this condition was added later) morphism of schemes: $$\pi:X\to \operatorname{Spec }O_K$$ Do we have some results which tell us what is the scheme $X$? For instance if $L$ is a finite extension of $K$, then one possibility is $X= \operatorname{Spec }O_L $. Then what else? Do we have some classification theorem for $X$? Edit: I'm trying to prove that when $X$ is integral then the unique possibility is 
$X=\operatorname{Spec }O_L$ for a finite extension $K\subset L$. Let $L$ be the function field of $X$, then by the valuative criterion of properness I get a morphism over $\operatorname{Spec }O_K$:
$$f: \operatorname{Spec }O_L\to X$$
The last step is to show that it is actually an isomorphism... Any suggestions?","['algebraic-number-theory', 'affine-schemes', 'field-theory', 'algebraic-geometry']"
2232377,How to interpret data given from statistical software question?,Hello I am trying to answer the following question. (Apologies for the image but it is perhaps clearer than me doing a table here). I am quite stuck on a few points and wanted some help. I think the distribution is a $t$ distribution with $6$ degrees of freedom. As we have $9$ countries recorded and $2$ things recorded so we get $9-(2+1)=6$. For b) I know the formula that $\text{Estimate} ~\div~\text{Standard Error}=\text{t-value}$ so for the second column we can figure out the standard error is $1.415$. Now for the top row I want to find the $t$ value corresponding to the $p$ value of $0.05$. So we want the number such that $95%$ of the distribution is less than the absolute value of that number. So I think this gives $P(>|t|)=0.05$ so we look in the tables to find the value of $t$ that gives $0.025$ in the upper tail (since by symmetry the lower tail will contribute the other $0.025$). This gives the value as $2.447$ and so the corresponding standard error is $6.0073$. This is the main thing I am not too sure about so if anyone could help me out and explain if I am wrong what I should be doing differently that would be great. Oh and for c) I said yes I would agree since $0.0003<0.01$.,"['statistics', 'probability']"
2232409,Applying stokes' theorem to evaluate the double integral for the hemisphere with radius 2 for $y \geq 0$ and oriented in the $+y$ direction.,"A question on my homework asks: Use Stokes' Theorem to evaluate $\int\int_{S} (curl\vec{F}) * {n} \space dS$
where S is defined as the hemisphere $x^2 + y^2 + z^2 = 4$ for $y \geq 0$ and oriented in the positive y direction. They've also given the vector field $\vec{F} = \space <ze^y, xcos(y), xzsin(y) > $ So I started by drawing the surface, which is pretty straightforward. I'm gonna be integrating over the xz plane, where the curve is defined by $x^2 + z^2 = 4$, i.e. a circle with radius of $2$. According to my book, the orientation of the curve is consistent with that of the surface if you imagine a person walking around the curve and 1) their head points in the same direction as the normal vector to the surface, and 2) the surface is to their left at each point along the curve. I parametrized the curve as follows: $\vec{r(t)} = \space <2cos(t), 0, 2sin(t)>$ I did everything else right--I plugged in the values for x, y, and z into the vector field and properly set up the integral. In the end, I got an answer of $-4\pi$, but this was wrong. I then tried entering $4\pi$, and that was apparently the correct answer. This seems to imply that while I did everything else right, I had to set up the limits as $t$ going from $2\pi$ to $0$ as opposed to $0$ to $2\pi$. But this doesn't make sense to me, since that forces the surface to be to the right of the imaginary person as he walks along the curve. What did I do wrong?","['multivariable-calculus', 'stokes-theorem']"
2232448,Product of squared sines: $\prod_{k=1}^{n-1}\prod_{j=1}^{n-1}\left[ \sin^2\left(\frac{k\pi}{2 n}\right) +\sin^2\left(\frac{j\pi}{2 n}\right)\right]$,"I have a double product $$a(n)=2^{2 (n-1)^2} \prod_{k=1}^{n-1} \prod_{j=1}^{n-1}
\left[
  \sin^2 \left(\frac{k\pi}{2 n}\right) +\sin^2 \left(\frac{j\pi}{2 n}\right)
\right]$$ which always gives integers. I would like to have a closed form for this or something more intuitive without sines/complex numbers. I have tried methods from similar questions but I can't seem to evaluate this expression. Every new insight is appreciated. Thank you in advance.","['algebra-precalculus', 'products', 'trigonometry', 'geometry']"
2232499,Minimum sum in quadrilateral,"Let $ABCD$ be a convex quadrilateral. Also, let $E$ be the midpoint of $AC$ and $F$ the midpoint of $BD$ and $M$ the midpoint of $EF$. The circle $\Gamma$ with center $M$ has radius $r$, such that all the points $A,B,C,D$ lie outside the circle. Prove that, for any point $P$ in the interior of $\Gamma$ $$PA+PB+PC+PD>4r$$ I tried using complex number. One can easily see that $m=\frac{a+b+c+d}{4}$ and $PA+PB+PC+PD=|p-a|+|p-b|+|p-c|+|p-d|$. I also suspect that the minimum is achieved when $P$ is at the intersection $O$ of the diagonals, or at the intersection of $MO$ and $\Gamma$ when $O$ is outside the circle, but didn't succeed in proving it.","['analytic-geometry', 'complex-numbers', 'geometry']"
2232520,What are chance of two randomly generated 4 digit strings being the same?,"I am building a website where an alphanumeric ID will be generated. As of now, I have it randomly grabbing a number or letter from this data set: ABCDEFGHIJKLMNOPQRSTUVWXYZ 0123456789 So there are 36 possibilities. If my math is right, if I make the ID 4 digits/characters long, the odds of a duplicate would be: 1/36 * 1/36 * 1/36 * 1/36 which equals 1/1,679,616. In a nutshell, I want to eliminate (within reason) the possibility of a duplicate ID being created, but the shorter the ID the better. If I went with 4 digits and ended up creating 15,000 IDs (like 4T6H, GF29, etc.), what are the chances that two of them will be the exact same? If I generated ONE, it's obviously 1 in 1,679,616 (i think).  But wondering how the odds are affected if I generate 15,000 of them. Any insight/corrections on my math would be greatly appreciated.",['probability']
2232560,Evaluate $\int_{x=0}^{2 \pi}\frac{dx}{(1+a \cos{x})^{b^2}}$,"Evaluate:
  $$\int_{0}^{2 \pi}\frac{dx}{(l^2+r^2+2 l r \cos{x})^{b^2}}$$
  where $b^2$ is a real number, $r>0$, and $l \geq 0$. I can just simplify it to 
$$c\int_{0}^{2 \pi}\frac{dx}{(1+a \cos{x})^{b^2}}$$
where $a>0$. Any ideas? simplifications? results?","['trigonometry', 'calculus', 'integration', 'definite-integrals', 'trigonometric-integrals']"
2232563,Knight shift on $3×3$ chess board,The chess table has $2$ Black and $2$ White knights marked with $C =$ $Black$ and $B =$ $White$.  Is it possible to move the pieces from their initial position to get the positions on $2$?,"['graph-theory', 'discrete-mathematics']"
2232604,Arrangements question.,"If I have a 5 by 6 matrix with 30 elements, $a_{i,j}$, in how many ways can I select 3 elements $a^1_{i,j}, a^2_{i,j}, a^3_{i,j}$ such that none of the $i$  are the same and none of the j are the same(none in the same column or row). I think the answer is $\frac{30*20*12}{3!} = 1200$, since their are 30 ways to pick for the first element, 20 for the second, 12 for the third and each arrangement is then counted 6 ways. But I'm not sure about this, and I have a tendency to get these kinds of problems horribly wrong.",['combinatorics']
2232636,Looking for intuition behind the Euler Product Formula and related Number Theory things,"I've been trying to dive into Number Theory to better understand prime numbers. I found Euler's Product Formula, $$\sum_{n\in\mathbb{N}}{\frac{1}{n^s}}=\prod_{\text{Prime }p}{\frac{1}{1-\frac{1}{p^s}}}$$ While looking into this, a number of things confused me. In one informal explanation, I don't get how they Add for n=1,2,3... on the very first page. In another book I have, I see them ""expand the factors"" by saying $$\frac{1}{1-\frac{1}{p^s}}=1+\frac{1}{p^s}+\frac{1}{(p^2)^s}+\frac{1}{(p^3)^s}+...$$ and I don't see where that comes from either. I'm also curious why we express the product as such an unwieldy fraction instead of simply writing $\frac{p^s}{p^s-1}$. I suppose my overarching question is... am I just blind and this isn't clicking with me, or am I in over my head and these steps involve other parts of number theory which aren't mentioned? I apologize if I've been too broad or not very specific, I'd be happy to clarify what I can or move this somewhere more appropriate.","['number-theory', 'prime-numbers']"
2232656,Why doesn't the limit of $\frac{e^{\frac1x}-1}{e^{\frac1x}+1}$ exist?,Consider $$\lim_{x \to 0}  \frac{e^{\frac1x}-1}{e^{\frac1x}+1}$$ Applying L'hospital's rule for the left hand limit and right hand limit gives the same answer. Why doesn't this limit exist?,"['real-analysis', 'limits', 'calculus', 'limits-without-lhopital', 'arithmetic']"
2232688,Number of observations needed to distinguish two known distributions with p-confidence,"I have a 1-length cube.   $N$ spots are located in the cube according to the one of known distributions: $f(x,y,z) = 1$ $g(r) = k\ exp(-2\ r^2)$ (where $k$ is a normalization constant and $r= \sqrt{x^2 +y^2+z^2 }$) Problem: How many points, $N$, do I need to distinguish these distributions with $p = 90\%$ confidence? Is it enough to consider not the whole cube, but just a quarter of sphere inside it? (Because it's difficult to transform $f$ to sphere coordinates in cube, but easy in sphere) What exactly is the probability here? Do I have to use statistical tests?","['statistics', 'probability-distributions']"
2232775,"The number of seven digit integers, with sum of the digits equal to 10 and formed by using the digits 1, 2 and 3 only, is","I solved it using the regular combination method taking the two cases as 1,1,1,1,1,2,3 and 1,1,1,1,2,2,2. But how do you solve it using multinomial theorem?","['combinatorics', 'multinomial-theorem']"
2232779,"What are the different types of ""averages"" and when to use each one?","So, the concept of an average truly is somewhat abstract. Most statisticians define it as a ""measure of central tendency."" Others say it is the ""center of gravity"" for a set of numbers. I personally prefer a slightly more concrete explanation: A statistic that describes the ""typical"", or better yet, ""representative"" value of a data set. We humans get to decide what ""representative"" actually means. Is it the most common number? The number that falls ""in the middle"" of a set of numbers? Etc. I am going to list a few types of averages and am wondering if someone could provide a data set where that particular average is the best choice for describing a ""typical"" or ""representative"" value for that data set. Types of averages: Arithmetic Mean: The number that you could use in place of each of the values of a data set, and still have the same sum. Formula: $$\overline{X}=\frac1N\sum\limits_{i=1}^{N} X_i$$ Mode: The most common value in a data set. No formula that I know of. Median: The literal middle number of a data set where the values are listed in ascending order. No formula that I know of. Root Mean Square: Don't really know how to describe this average in a physical sense. Maybe the average that gives larger numbers in the data set more ""weight"" or ""significance?"" Formula: $$X_{rms}=\sqrt{\frac1N\sum\limits_{i=1}^{N} X_i^2}$$ Mean Root Square: I just made this one up, but it seems to work well when I applied it to some random data sets. It seems to do the opposite of the RMS and gives smaller numbers in the data set more ""weight"" and ""significance."" Formula:
$$X_{mrs}=\frac1N\sqrt{\sum\limits_{i=1}^{N} X_i^2}$$ EDIT: Turns out this should not be considered an average because it fails to describe a data set that consists of only one number, unlike all the other averages. Geometric mean: The number that you could use in place of each of the values of a data set, and still have the same product . Formula:
$$GM=\sqrt[N]{\prod\limits_{i=1}^{N} X_i}$$ Feel free to add in any other popular or useful types of averages and when to use them!","['means', 'statistics', 'average']"
2232818,"If $p\mid (3^n+1)$, then $p\equiv 1\pmod{3}$","Show that if $p> 2$ is a prime, $n > 1$ is odd and $p\mid (3^n+1)$,
  then $p\equiv 1\pmod{3}$. Since $n$ is odd, we have $3^{n+1} \equiv -3 \pmod{p}$ is a quadratic residue. Then I thought about using Quadratic Reciprocity but didn't see how to apply it. We have $x^2 \equiv -3 \pmod{p}$ for some integer $x$. By Fermat's Little Theorem we have $$x^{p-1} \equiv x^2 \cdot x^{p-3} \equiv -3 \cdot x^{p-3} \equiv 1 \pmod{p}.$$ Thus, $x^{p-3} \equiv -3^{-1} \pmod{p}$. I didn't see how to get a contradiction if $p \equiv 2 \pmod{3}$.","['number-theory', 'quadratic-reciprocity', 'quadratic-residues']"
2232819,Prove using combinatorics $n \mid \binom{n}{m} \binom{n}{m-1}$,"Prove using combinatorics $$n ~\Bigg | \binom{n}{m} \binom{n}{m-1}.$$ We should find a problem whose answer is $\displaystyle\dfrac{\displaystyle\binom{n}{m} \binom{n}{m-1}}{n \times f(n,m)}$ but I can't find such problem. Any hints?","['combinatorics', 'combinatorial-proofs']"
2232854,"How do I Evaluate the Integral $\int_{-\infty }^{\infty } \frac{1}{e^{x^2}+1} \, dx$?","Like the question states, how do I evaluate the integral
$$\int_{-\infty }^{\infty } \frac{1}{e^{x^2}+1} \, dx$$
I know of no methods to evaluate this, but when I plug this into Mathematica and Wolfram Alpha , it returns 
$$\int_{-\infty }^{\infty } \frac{1}{e^{x^2}+1} \, dx=\left(1-\sqrt{2}\right) \sqrt{\pi } \zeta
   \left(\frac{1}{2}\right)$$
where $\zeta (x)$ is the Riemann Zeta Function.","['improper-integrals', 'integration', 'riemann-zeta', 'probability-distributions']"
2232869,"The group of $k$-automorphisms of $k[x_1,\ldots,x_{n},x_1^{-1},\ldots,x_n^{-1}]$","Let $k$ be a field (I do not mind to further assume that $k$ is of zero characteristic, if that will make things easier). For $k[x_1,\ldots,x_n]$ it is known that the affine and triangular automorphisms generate the group of automorphisms of $k[x_1,\ldots,x_n]$, call it $G_n$,
see, for example, van den Essen's book .
It is also known that $G_2$ is a free amalgamated group, see, for example, Dick's paper . My question: Is the group of $k$-automorphisms of $k[x,x^{-1}]$, call it $\hat{G_1}$, known?
of $k[x,y,x^{-1},y^{-1}]$?
or more generally, of $k[x_1,\ldots,x_n,x_1^{-1},\ldots,x_n^{-1}]$?
(call it $\hat{G_n}$).
By 'known' I mean if it is not difficult to find a set of generators similarly to the generators of $k[x_1,\ldots,x_n]$ (or perhaps, a free amalgamated structure of $\hat{G_2}$ similarly to the free amalgamated structure of $G_2$). Thanks for any hints and comments.","['abstract-algebra', 'group-theory', 'commutative-algebra']"
2232885,Stable local minimizers of functions on a Banach space,"Let $X$ be a Banach space and $f:X\rightarrow (-\infty,\infty]$ be a lower semicontinuous function. We are interested in  some conceptions of local minimizer: We say that $\bar{x}\in X$ is a stable strict local minimizer of $f$ if $f(\bar{x})$ is finite and there exists $\varepsilon>0$ such that the mapping $$
	M:x^*\mapsto\text{argmin}_{\|x-\bar{x}\|\leq\varepsilon}\{f(x)-\langle x^*,x\rangle\}
	$$ from $X^*$ to $X$ is single-valued on some neighborhood of $0$ with $M(0)=\bar{x}$ . We say that $\bar{x}\in X$ is a stable well posed local minimizer of $f$ if $f(\bar{x})$ is finite and there exists $\varepsilon>0$ such that for every vector $x^*\in X^*$ near the origin, there is a point $x_{x^*}$ in $U:=\overline{B}(\bar{x},\varepsilon)$ with $x_0=\bar{x}$ so that in terms of the perturbed functions $f_{x^*}(\cdot):=f(\cdot)-\langle x^*,\cdot\rangle$ we have $$
	f_{x^*}(x_{x^*})=\inf_{x\in U}f_{x^*}(x)
	$$ and every sequence $(x_n)\subset U$ along which $f_{x^*}(x_n)\rightarrow f_{x^*}(x_{x^*})$ obeys $\|x_n-x_{x^*}\|\rightarrow 0$ . We say that $\bar{x}\in X$ is a stable strong local minimizer of $f$ if $f(\bar{x})$ is finite and there exist $\varepsilon>0$ and $\kappa>0$ such that for every vector $x^*\in X^*$ near the origin, there is a point $x_{x^*}$ in $U:=\overline{B}(\bar{x},\varepsilon)$ with $x_0=\bar{x}$ so that in terms of the perturbed functions $f_{x^*}:=f(\cdot)-\langle x^*,\cdot\rangle$ the inequality $$
	f_{x^*}(x)\geq f_{x^*}(x_{x^*})+\kappa\|x-x_{x^*}\|^2
	$$ holds for every $x\in U$ . A point $\bar{x}\in X$ is called a stable Lipschitz local minimizer of the function $f$ if $f(\bar{x})$ is finite and there exists $\varepsilon>0$ such that the mapping $$
	M:x^*\mapsto\text{argmin}_{\|x-\bar{x}\|\leq\varepsilon}\{f(x)-\langle x^*,x\rangle\}
	$$ is single-valued and Lipschitz continuous on some neighborhood of $0$ with $M(0)=\bar{x}$ . We have observed that: stable strong local minimizer $\Rightarrow$ stable well posed local minimizer $\Rightarrow$ stable strict local minimizer. stable strong local minimizer $\Rightarrow$ stable Lipschitz local minimizer $\Rightarrow$ stable strict local minimizer. When $X$ is finite dimensional,  stable strict local minimizer $\Leftrightarrow$ stable well posed local minimizer. When $X$ is finite dimensional,  stable strong local minimizer $\Leftrightarrow$ stable Lipschitz local minimizer. We would like to construct: a stable well posed local minimizer of $f$ which is not a stable strong local minimizer of $f$ a stable strict local minimizer of $f$ which is not a stable well posed local minimizer of $f$ a stable Lipschitz local minimizer of $f$ which is not a stable strong local minimizer of $f$ a stable Lipschitz local minimizer of $f$ which is not a stable well posed local minimizer of $f$ a stable well posed local minimizer of $f$ which is not a stable Lipschitz local minimizer of $f$ Thank you for all kind help and comments.","['functional-analysis', 'lipschitz-functions', 'banach-spaces', 'optimization']"
2232899,Two questions on Graham's conjecture,"Graham's conjecture states that $$\pi(G\times H)\le\pi(G)\pi(H)$$ where $\pi(G)$ denotes the pebbling number of a graph $G$.  I have the following two questions: Are there examples of graphs $G$, $H$ with $\pi(G\times H)<\pi(G)\pi(H)$? Let $\pi_L(G,v)$ denote the minimum number $n$ such that for any distribution with $n$ pebbles on $G$ it is possible to move a pebble on $v$.  Is anything known about the following, 'localized' version of the conjecture? $$\pi_L(G\times H,(v,w))\le\pi_L(G,v)\pi_L(H,w)$$ Is it plausible?  Are there counterexamples?","['combinatorics', 'graph-theory', 'reference-request', 'discrete-mathematics']"
2232950,"What is the relation between the determinant of the adjoint representation, and volume or eigenvalues?","I'm relatively new to Lie Groups, and finding in a text the following statement, as it is supposed to be obvious. I would love some reference or context to either of these two (probably related) statements: The context is $G$ a connected lie group with lie algebra $\mathfrak{g}$, $H$ closed connected subgroup with sub-lie-algebra $\mathfrak{h}$ of dimention $d$. fixing $x\in \wedge^d \mathfrak h - \{0\}$, it is said that $\wedge^d Ad(g)x=x$ iff $g\in N(H)$ and $\det(Ad\:(g|_{\mathfrak h}))=1$ for some $\Gamma$ acting on $G$, if $\gamma(H\Gamma/\Gamma)=H\Gamma/\Gamma$ then $|\det(Ad\:(\gamma|_{\mathfrak h}))|=1$, and so $\wedge^d Ad(\gamma)x=\pm x$ the first one is somewhat related in my head to the formula of inner product of $e_1\wedge\ldots\wedge e_d$ with $\wedge^d Ad(g) e_1\wedge\ldots\wedge e_d$, and that it should be 1 if it's an eigenvector with eigenvalue $1$. I could not formulate it. the second one looked like some argument of $\gamma$ preserving the volume and therefore the absolute value of the determinant, which basically means volume, must be 1. I could not formulate this either. P.S: Just to mention: I think I do understand the part about being in the normalizer, as $g\in N(H)$ implies $\phi_g (g)\in H$ for all $h\in H$and therefore $Ad(g)(x)\in \mathfrak{h}$ for all $x\in\mathfrak{h}$. Still, the determinant part is unclear.","['exterior-algebra', 'smooth-manifolds', 'differential-geometry', 'lie-algebras', 'lie-groups']"
2232959,Witt algebra as infinitesimal symmetries of the diffeomorphism group of the circle?,"Let $\mathcal G$ be the diffeomorphism group of the unit circle in the complex plane. Since the unit circle is a compact smooth manifold, $\mathcal G$ can be given the structure of a Lie group such that its Lie algebra is the space of smooth vectors fields on the unit circle. Write $\mathcal G$ also for this Lie group. Let $\mathfrak g$ be the (abstract) Lie algebra over $\mathbb C$ generated by elements $\{L_n\}_{n\in\mathbb Z}$ satisfying
$$
[L_n,L_m]=(n-m)L_{n+m}.
$$
(This abstract Lie algebra is known as the Witt algebra. One way to realize the Witt algebra is by taking $L_n$ to be the operator $z^{1-n}\frac{d}{dz}$ acting on the Laurent polynomial ring $\mathbb C[z,z^{-1}]$.) My question is the following:
$$
\text{Does the Lie algebra of $\mathcal G$ contain a subalgebra isomorphic to $\mathfrak g$?}
$$ According to the discussion in Section 5.4 of Schottenloher's book ""A Mathematical Introduction to Conformal Field Theory"", the answer would seem to be ""no"". But according to the survey article ""Kac-Moody and Virasoro algebras in relation to quantum physics"" by Goddard and Olive, the answer seems to be ""yes"" (page 14). I suspect there is some subtle language difference between the mathematicians and the physicists. The question I have asked above is mathematically precise, and I am therefore looking for a mathematically precise answer.","['abstract-algebra', 'smooth-manifolds', 'mathematical-physics', 'lie-algebras', 'lie-groups']"
2232970,"Showing a function is a function of only a variable $\eta(x,t)$","Suppose I have a differential equation $$\frac{\partial\theta}{\partial t}=\frac{\partial^2\theta}{\partial x^2}$$ satisfied by $\theta(x,t)$ and I then had that $\theta(x,t)=k F(x,t)$, and I know $F(x,t)$ is dimensionless. What is a general method in this situation to answer the question ""Show  $F$ is a function of only the similarity variable $\eta=\eta(x,t)$""? I am not really sure how to approach this as I don't recall ever encountering a problem like this. Any help apprecieted.","['heat-equation', 'ordinary-differential-equations', 'dimensional-analysis']"
2232975,Solving first order linear pde,"$$xv_x-yv_y=(x-y)\sin(x+y)$$
I am trying to using characteristic method $\dfrac{dx}{x}=\dfrac{dy}{-y}=\dfrac{dv}{(x-y)(\sin(x+y))}$ From first equality (I mean equation $(1)$ and $(2)$) , we get $xy=c_1$ From $(2)$ and $(3)$ , we get $\dfrac{dx+dy}{x-y}=\dfrac{dv}{(x-y)(\sin(x+y))}$ and so get $v=-\cos(x+y)$ Where Am I Wrong? or How can we solve another method?","['ordinary-differential-equations', 'partial-differential-equations']"
2232987,"For $0\leq a,b \leq \pi$ if $\cos a = -\cos b$ then $\sin a = \sin b$","Problem: Is it it true that for $0\leq a,b \leq \pi$ if $\cos a = -\cos b$ then $\sin a = \sin b$. Thoughts:
When I draw a picture it makes sense but I am unsure what identity to use to show this is true. Any hints appreciated. What about this: First squaring both sides yields
$\cos^2(a) = \cos^2(b)$, then $1-\sin^2(a) = 1 - \sin^2(b)$ implies $\sin(a) = \sin(b)$",['trigonometry']
2233017,Evaluation of $\sum _{n=1}^{\infty} \tan^{-1} \frac{2}{n^2+n+4}$,Find the following sum $$S= \sum _{n=1}^{\infty} \tan^{-1} \frac{2}{n^2+n+4}$$ I am not able to make it telescopic series. Could someone help me with this?,['sequences-and-series']
2233106,"Is it possible when multiplying two polynomials that, after collecting similar terms, all terms vanish?","Algebra by Gelfand poses this question with the remarkably unhelpful answer of: No. Probably this problem seems silly; it is clear that it cannot happen. If you think so, please reconsider the problem several years from now. I'm sure the mathematical wit is just lost on me, but since you can lose some terms from multiplying, it doesn't seem too far fetched through some mathematical wizardry that there are cases where they all vanish. So why is this?","['algebra-precalculus', 'polynomials']"
2233109,What are the coordinates of red point?,"The function  $f (x)=-x^2+4$ ""in red"" is moving along the line $y=x+4$  "" in black ""  from green point  to  black point  and becomes in the place of blue graph  as shown in the following  graph What are the coordinates  of red point? I got the green point $(0,4)$ by using the equation  $y=x+4$ ,  and got the intersection  point of the two  parabolas $(2,0)$  and I stopped here.",['calculus']
2233121,Banach space of Type $p<1$?,"Let $X$ be a Banach space. We say that it has type $p$ if there exist $T>0$ such that for any $n\in\Bbb N$ and $x_1,\dots,x_n\in X$,
$$
\Bbb E_{\varepsilon}\left|\left|\sum_{i=1}^n\varepsilon_i x_i\right|\right|^p \le T \sum_{i=1}^n ||x_i||^p,
$$
where the expectation is taken over all $\varepsilon\in\{-1,1\}^n$. In all cases I've seen, the literatures only discuss the case where $p\ge 1$. What could be said about that case $0<p<1$?","['functional-analysis', 'normed-spaces', 'real-analysis', 'banach-spaces']"
2233193,"Graph theory, unique path of tree proof","Let $G = (V,E)$ be a tree with at least $2$ vertices. Show that for every $u,v$ $\epsilon V$, there exists a unique path from $u$ to $v$. My attempt: Suppose for contradiction, there are $2$ distinct paths from $u$ to $v$ $v = p_{1}, p_{2}, ......, p_{k} = v$ $v = q_{1}, q_{2}, ......, q_{k} = v$ How do I prove that there is a cycle formed through this contradiction?","['graph-theory', 'trees', 'discrete-mathematics']"
2233221,A Question on Borel Measurable Functions,"Define $A, B:[a,b] \to \mathbb R$ by
$$
A(x) = \lim_{\epsilon \to 0} \sup_{y\in [a,b]\\|x-y|<\epsilon} f(y), \quad B(x) = \lim_{\epsilon \to 0} \inf_{y\in [a,b]\\|x-y|<\epsilon} f(y),
$$
where $f:[a,b]\to\mathbb R$ is bounded function on $[a,b]$.
I want to show that (i) $A, B$ are borel measurable functions. (ii) If $f$ is continuous at $x_0$, then $A(x_0) = f(x_0) = B(x_0)$. (iii) If $A(x_0) = B(x_0)$ then $f$ is continuous at $x_0$. Actually I have no idea for (i) because I could not express $A,B$ as some limit of measurable functions. For (ii) I obtained that for any $x \in [a,b]$, $B(x) \le f(x) \le A(x)$. Please help me.","['borel-sets', 'real-analysis', 'measure-theory', 'analysis']"
