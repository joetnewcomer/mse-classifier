question_id,title,body,tags
1393976,Relationship between two integrals,"I'm reviewing for an intro calculus exam, and the following problem appears on a past final exam: If: $$\int^3_1 \frac{1}{x^4\sqrt{1+x}}\, dx = k$$ What is:
 $$\int^3_1 \frac{1}{x^5\sqrt{1+x}}\, dx $$ (I'm assuming the answer will be in terms of $k$) It seems that most basic integration techniques(substitution, integration by parts, trig sub, etc.) will not allow the solution of the integral, and I'm not sure how else to approach this problem at my level. I've run this by both my lecturers, and they cannot find a solution in a reasonable amount of time either. I'm curious because it seems the there would be a simple solution or rule I'm ignorant of (considering this is on an intro calc exam), but I'm stumped. Where am I going wrong? Thanks!","['calculus', 'integration']"
1393992,How many bitstrings of length 8 contain 5 consecutive 0's?,"I worked this problem using a recursive sequence, i.e. it can end in 
$1$, leaving $a_{n-1}$, or $10$, leaving $a_{n-2}$, $100$ leaving $a_{n-3}$, $1000$ leaving $a_{n-4}$, $10000$ leaving $a_{n-5}$, and finally $00000$ leaving $2^{n-5}$ possibilities. $a_{0}=a_{1}=a_{2}=a_{3}=a_{4}=0$
Then I worked it up to $n=8: a_{5}=1, a_{6}=1+2^{6-5}=3, a_{7}=3+1+2^{7-5}=8, a_{8}=8+3+1+2^{8-3}=20$. My question is, aside from counting each individual bit string (which I did, by the way), how else can this type of problem be worked? Thanks!",['discrete-mathematics']
1393993,Counting the size of the largest sets of independent strings,"This question derives from a PPCG coding challenge I posed previously. For a given positive integer $n$ , consider all binary strings of length $2n-1$ .  For a given string $S$ , let $L$ be an array of length $n$ which contains the count of the number of $1$ s in each substring of length $n$ of $S$ . For example, if $n=3$ and $S = 01010$ then $L=[1,2,1]$ . We call $L$ the counting array of $S$ . We say that two strings $S1$ and $S2$ of the same length match if their respective counting arrays $L1$ and $L2$ have the property that $L1[i] \leq 2*L2[i]$ and $L2[i] \leq 2*L1[i]$ for all $i$ . Problem For increasing $n$ starting at $n=1$ , we want to compute the size of the largest set of strings, each of length $2n-1$ so that no two strings match. Known answers For $n=1,2,3,4,5$ the optimal answers are $2,4,10,16,31$ . For $n=6,7,8,9,10$ , the best known values are $47, 76, 112, 168, 235$ from a combination of the answers of joriki and Peter Taylor. The question Plotting these values they appear to be subexponential but it is hard to say much more than that. This leads to the question: How do optimal solutions scale with $n$ ? Question now posed at https://mathoverflow.net/questions/215343/counting-the-size-of-the-largest-sets-of-independent-strings as well.","['asymptotics', 'combinatorics']"
1393994,Can one have a nontrivial 'resolution of singularities' of a smooth variety?,"Suppose $z_1,z_2$ are coordinates on $\mathbb{A}^2$ and $(w_1,w_2)$ homogeneous coordinates on $\mathbb{P}^1$. We can define a subvariety $X \subset \mathbb{A}^2 \times \mathbb{P}^1$ by $w_1z_2 - w_2z_1 = 0$. Then this is smooth (right?) and the projection $\pi:X \rightarrow \mathbb{A}^2$ is an isomorphism away from $(0,0)$, but $\pi^{-1}(0,0)$ is isomorphic to $\mathbb{P}^1$. So my question is: Is this a valid resolution of singularities, or am I misunderstanding the definition of a resolution of singularities. For reference: I thought that if $f:X' \rightarrow X$ is a proper map, $X'$ is smooth, and there is a dense open set $U$ of $X'$ such that $f\mid_U$ is an isomorphism, then $f$ is a resolution of singularities.",['algebraic-geometry']
1394016,Existence of fair parallel queues,"I just spent a few days at a major theme park.  The queue for one particular ride (involving pirates) bifurcated upon entry; the two sides wound independently through a maze and emerged next to each other at the other side.  Two people nearby were debating whether both sides had the same physical length, or whether one side was shorter.  I spent lots of time in queues that day mulling over the following problem: Define an $(m,n,k)$-queue to be an $m\times n$ grid, together with $k$ disjoint paths from one of the $m$-long sides to the other, such that each grid point is contained in one path; each of the paths has the same length; the entry points are contiguous, and the exit points are contiguous. Question: What are necessary and sufficient conditions on $m$, $n$ and $k$ such that there exists an $(m,n,k)$-queue? As examples, below are pictures of $(6,6,k)$-queues for $k=1,2,3,4,6$. There are some obvious necessary conditions.  First, $k$ must divide $mn$ (and the common path length is $l=mn/k$).  Second, $k\le m$.  However, these conditions are not sufficient; for example, it's not hard to show that there is no $(8,3,4)$-queue. Some special cases are straightforward.  An $(m,n,m)$-queue trivially exists; it consists of $m$ vertical paths of length $n$ (see the $(6,6,6)$-queue in the figure above.)  An $(m,n,1)$-queue always exists; the $(6,6,1)$-queue above illustrates a ubiquitous construction.  An $(m,n,n)$-queue always exists if $n\le m$; for example, here's the canonical construction of a $(6,4,4)$-queue: Constructing larger queues from smaller queues One easy way to extend a queue is to stack one queue on top of its reflection; thus the existence of an $(m,n,k)$-queue implies the existence of a $(m,cn,k)$-queue for any integer $c>0$. Here's a more interesting construction.  In an $(m,n,k)$-queue with $k|m$, there's a possibility that some horizontal line in the grid is crossed exactly $m/k$ times by each of the $k$ paths. (This happens, for example, in
the pictured $(6,6,2)$-queue; both paths intersect the line below the top line three times.)  In this case you can insert an extra row at this line, extending all $k$ paths vertically to get an $(m,n+1,k)$-queue: Iterating, this proves the existence of a $(6,n,2)$-queue for all $n\ge 6$.  (If you've been to the Haunted Mansion, this construction will look familiar!) You can also extend horizontally (if $k|n$ and every path intersects a vertical line $n/k$ times) to get an $(m+1,n,k)$-queue. Remarks The contiguousness requirement was motivated by observation of actual queues.  However, the problem seems trivial if that requirement is dropped; in that case, the necessary conditions $k|mn$ and $k\le m$ are also sufficient. Observe that there are some parity consequences of the bipartiteness of the grid.  If $l$ is odd, the paths connect points of the same color in a ""checkerboard"" coloring of the grid, otherwise paths connect points of opposite color.  If $mn$ is odd, then there's a ""majority color""; the line of entry points (and the line of exit points) must begin and end with that majority color. By connecting the first exit point to the second exit point, reversing direction and so on, the problem can be viewed as asking whether there is a Hamiltonian path in the grid with additional structure.  This led to some interesting references but no solution. There are plenty of related problems here, such as the problem of counting queues.  Some variant of the Gessel-Viennot lemma seems like it might be useful; this has been extended to graphs with cycles (e.g. here ) but the property that all paths have the same length is not preserved by tail-swapping, so there's room for innovation.","['combinatorial-geometry', 'hamiltonian-path', 'combinatorics']"
1394029,Infinite series of integrals of $L^2$ functions,"I'm hoping someone can help me with this integration problem I've been struggling with. Let $\{f_n\}$ be a sequence in $L^2(\mathbb{R})$ such that $\sum_{n=1}^\infty \lVert f_n\rVert^2_2<\infty$ and $\sum_{n=1}^\infty f_n (x)=0$ for a.e. $x\in\mathbb{R}$. I need to show that for every $g\in L^2(\mathbb{R})$,
$$\sum_{n=1}^\infty \int_\mathbb{R} f_ng\,d\mu$$
exists and is equal to zero, where $\mu$ is Lebesgue measure. The assumptions of the problem lead me to believe that some sort of Cauchy-Schwartz Inequality result can be used, maybe along with Dominated Convergence Theorem. However, every attempt I've made at using CSI has led to unwanted square roots. I was, however, able to prove with Fatou's Lemma that $\sum_{n=1}^\infty |f_n|^2$ is integrable. I'm not sure if it helps, but I thought I'd share it in case it does. I'd appreciate any help for this problem.","['analysis', 'real-analysis', 'functional-analysis', 'integration']"
1394032,$\sum X_n$ converges a.s.,"This one is from old qualifying exam. $\{X_n\}$ be non-negative, independent and $\{Y_n\}$ is another sequence (not necessarily independent) but $X_n \sim^{d} Y_n$. Then $\sum X_n$ converges a.s. $\Rightarrow$ $\sum Y_n$ will also converge a.s. (This part I am able to show using Kolmogorov 3-series and Khintchine Equivalence. But I am stuck at the following) Question : If non-negativity is dropped from $X_n$'s we can not conclude the convergence of $\sum Y_n$. Any kind of help/hint is appreciated. Thank you,","['probability-theory', 'probability', 'probability-distributions']"
1394059,What is the least possible value of $ùëì(999)?$ [duplicate],"This question already has an answer here : Functional Equation $f(mn)=f(m)f(n)$. (1 answer) Closed 8 years ago . Let $ùëì$ be a one-to-one function from the set of natural numbers to itself such that $ùëì(ùëöùëõ) = ùëì(ùëö)ùëì(ùëõ)$ for all natural numbers $ùëö$ and $ùëõ.$ What is the least possible value of $ùëì(999)?$ What I think is that I have a hunch for the answer and follow the intuitions, any help?","['algebra-precalculus', 'functions']"
1394089,Schubert calculus and number of lines satisfying some properties.,"I am reading the file . I have a question on pae 18. It is said that: Given a line in $\mathbb{R}^3$, the family of lines intersecting it can be interpreted in $G(2, 4)$ as the Schubert variety
$$
X_{\{2,4\}}=\overline{\left(\begin{matrix} 
* & 1 & 0 & 0 \\
* & 0 & * & 1
\end{matrix}\right)}
$$
with respect to a suitably chosen basis determined by the line. Why the family of lines is $X_{\{2,4\}}$? Thank you very much.","['schubert-calculus', 'algebraic-geometry', 'geometry', 'representation-theory']"
1394091,What is a permutation representation in regard to group actions,"I have read the definition of a permutation representation from Dummit and Foote, and Wiki, but I don't understand. Can I please have an example? I get the impression that we can write a group action normally as: $$G\times X\to X, (g,x)\mapsto g\cdot x$$ Or we can write it as a permutation representation, i.e. a group action does: $$\begin{pmatrix}1&2&3&4\\\sigma(1)&\sigma(2)&\sigma(3)&\sigma(4)\end{pmatrix}$$ Is that all a permutation representation refers to?","['abstract-algebra', 'group-theory', 'group-actions']"
1394100,How do you find an odd hole in a graph?,"Why is there no literature on finding odd holes in a general undirected graph? I found this paper that seems to enumerate ALL chordless cycles ( http://arxiv.org/pdf/1309.1051v4.pdf ) but apparently, I read somewhere else that finding odd holes in the graph is a more difficult problem (and possibly open?) Why can't we pull out the odd holes from the cycles found above? Furthermore, is it possible to find just ONE odd hole in a graph efficiently?","['graph-theory', 'discrete-mathematics', 'algebraic-graph-theory']"
1394112,The asymptotic of the number of integers that are sums of three nonnegative cubes,"Let $c(n) $ be the number of distinct integers between $0 $ and $n $ of the form $ a^3 + b^3 + c^3$, meaning the sum of $3$ nonnegative cubes. $C(n) = O( n \space \ln(n)^x ) $ Find and prove the optimal real value of $x$.","['asymptotics', 'polynomials', 'number-theory', 'cubics']"
1394113,What are some usual norms for matrices?,"I am familiar with norms on vectors and functions, but do there exist norms for spaces of matrices i.e. $A$ some $n \times m$ matrix? If so, that would that imply matrices also form some sort of vector space?","['vector-spaces', 'matrices', 'normed-spaces', 'linear-algebra', 'matrix-norms']"
1394117,Find a homogeneous system whose solution space is spanned by the given vectors,"find a homogeneous system whose solution space is spanned by the following set of 3 vectors: 
$$(1,-2,0,3,-1) , (2,-3,2,5,-3), (1,-2,1,2,-2)$$ Please help, I've only seen similar questions where there are 4 unknowns not 5",['linear-algebra']
1394123,Solve trigonometric equation $ \cot x + \cos x = 1 + \cot x \cos x $,"Solve trigonometric equation: $$ \cot (x) + \cos (x) = 1 + \cot (x) \cos (x) $$
I tried to multiply both sides with $\sin x$ (which I'm not sure if I can multiply with sin).",['trigonometry']
1394132,Examples of infinite dimensional normed vector spaces,"In my notes on functional analysis it mentions that $C([0,1]),\ell^p$ and, $\ell^\infty$ are normed vector spaces, and gives some examples of norms that we can define on them. However, it then simply states that these three spaces are infinite-dimensional normed vector spaces. The only thing mentioned in my notes so far is in relation to finite-dimensional vector spaces, namely, that a vector space is finite-dimensional if it has a finite basis. My question(s): how is it exactly that one understands these spaces to be infinite-dimensional; what does it mean to say that they are infinite-dimensional and how do they differ from an example of a finite-dimensional vector space, say, $\mathbb R^n$. Going on what I know about finite-dimensional spaces, is it simply then that an infinite-dimensional space has an infinite basis? How would one visualize this? Can anybody show me why the examples I gave above are indeed infinite-dimensional?","['vector-spaces', 'linear-algebra', 'functional-analysis', 'normed-spaces']"
1394137,"Given local smooth extensions, construct a global smooth extension","In Spivak's A Comprehensive Introduction to Differential Geometry, Vol. 1 , he defines a function from a half-space $H^n$ to be $C^\infty$ if there is an extension to a neighborhood of $H^n$ that is $C^\infty$. On page 54, exercise 10(b) asks If $f: H^n \to \mathbb{R}$ is locally $C^\infty$, then $f$ is
  $C^\infty$, i.e., $f$ can be extended to a $C^\infty$ function on a
  neighborhood of $H^n$. Perhaps an argument from connectedness would work? Given a point $x$ on the boundary, the condition on a point $y$ that there exists a smooth extension containing both $x$ and $y$ is certainly an open condition. I can't see why it should be a closed one.","['differential-geometry', 'smooth-manifolds', 'multivariable-calculus']"
1394149,Inverse of a product of real functions,"Given $F(x) = L(x)G(x)$, with $L$ and $G$ real function strictly greater than zero. Suppose that F and G are decreasing functions (so that $F^{-1}$ and $G^{-1}$ exists). What can we say about the inverse of $F$? $$F^{-1}(y)$$ Do some representations of this type
$$F^{-1} = H  G^{-1}$$
exist, for some $H$? (and which would be the link between $L$ and $H$?) Please report more results as you can, even with stronger assumptions on what you want. Thanks.
$$$$
And last but not least, numerically speaking, is it a difficult problem? Suppose I can invert numerically $F$ and $G$, so that I can find $H$. Do I have some info about $L$? What can I do?","['inverse', 'real-analysis', 'functions']"
1394178,"In a ring: If every non-zero and non-unit element factors into prime elements, is factorization over irreducible elements unique?",Why (not)? I came up with this question while trying to understand the definition of a UFD.,"['abstract-algebra', 'unique-factorization-domains', 'ring-theory']"
1394181,Solving the equation $\tan(x)=\cos(x+33.44)$,"Please show a method of solving the equation $\tan(x)=\cos(x+33.44)$. I tried several methods (half-angle, cosine of sum, multiply cosines,etc...), but nothing worked. How should one solve such equation or in general an equation of the form $\tan(x)=\sin(x+a)$ or $\tan(x)=\cos(x+a)$? Thanks!",['trigonometry']
1394191,Need help to understand Uniqueness of Lifts theorem's proof.,"Theorem: Let $p:E \to B$ be a covering map. Fix $b_0 \in B$ and $e_0 \in p^{-1}(b_0)$. Let $f: X \to B$ be a continuous map with $f(x_0)=b_0$ and $X$ is connected. Suppose $g_1,g_2: X \to E$ are two continuous maps such that $p \circ g_1= p \circ g_2 = f$ and $g_1(x_0)=g_2(x_0)=e_0$, Then $g_1=g_2$. For proving this theorem, my teacher first considered a set $S=\{x \in X |g_1(x)=g_2(x)\}$. The theme of proof was showing $S$ to be both open and closed in $X$ and then using connectedness of $X$ to show that $S=X$. Now, the part of proof I am not able to understand is proving that $S$ is open. It is as follows: Fix $x_1 \in X$ arbitrarily. Let $V_{f(x_1)}$ be any evenly covered neighbourhood of $f(x_1)$. Since $f$ is continuous, there exists a neighbourhood $W_1$ of $x_1$ such that $f(W_1) \subseteq V_{f(x_1)}$.
  Put $e_1=g_1(x_1)=g_2(x_1) \in E$. Let $U$ be the slice over $V_{f(x_1)}$ containing $e_1$.
  Since $g_1,g_2$ are continuous, there exist open neighbourhoods $W_2,W_3$ of $x_1$ in $X$ such that $g_1(W_2) \subseteq U$ & $g_2(W_3) \subseteq U$.
  Let $W_0=W_1 \cap W_2 \cap W_3$.
  Now, since $p \circ g_1 = p \circ g_2 = f$, therefore $f(x)=p(g_1(x))=p(g_2(x)) \forall x \in W_0$ where $g_1(x),g_2(x) \in U \forall x \in W_0$.
  But $p|U: U \to V_{f(x_1)}$ is a bijection $\Rightarrow g_1(x)=g_2(x) \forall x \in W_0$. Hence $W_0 \subseteq S \Rightarrow S$ is open. Last line of the proof i.e. getting $S$ to be open is clear to me. But how we get $g_1(x)=g_2(x) \forall x \in W_0$is not clear to me.","['algebraic-topology', 'general-topology', 'functions']"
1394200,Is the chance of a variable also a parameter for a probability distribution?,"I'm new to statistics and I'm a bit confused about the concepts of 'chance of a variable' and 'parameters of a probability distribition'.
Is chance also a parameter? And if so: can computing the chance of a variable be considered as an estimation for the parameters?","['statistics', 'probability-distributions', 'parameter-estimation']"
1394206,Prove that neither $A$ nor $B$ is divisible by $5$,"Let the sum $$ {1+ \frac12 + \frac13 + \frac 14+ \dots +\frac1{99} + \frac 1{100}}$$ be written as $\frac AB$, where $A$ and $B$ are positive integers with no common factors. Show that neither $A$ nor $B$ is divisible by $5$. Using Mathematica, I found the sum is $$\frac AB=\frac {14466636279520351160221518043104131447711}{278881500918849908658135235741249214‚Äå2272}$$","['number-theory', 'harmonic-numbers', 'divisibility', 'elementary-number-theory']"
1394212,Limit of a function involving a sequence.,"I have the following problem: Suppose that $\lim_{n \to \infty} a_n = 0$. Prove that for any $x$
  $$\lim_{n \to \infty} \left(1+a_n \frac{x}{n}\right)^n = 1.$$ I have tried replacing $a_n$ with a function $a(n)$ and applying L'Hopital's Rule but got no useful result. I also tried going directly to the definitions and showed that $\lim_{n \to \infty} (1+a_n \frac{x}{n}) = 1$, but I don't know how to deal with the $n$th power (that makes the limit $\lim_{n \to \infty} \exp(n(1+a_n \frac{x}{n}))$ indeterminate).","['sequences-and-series', 'calculus', 'limits', 'exponential-function']"
1394247,Help with Rudin's proof of Riesz Representation Theorem,"I am having difficulty understanding a step in the proof of Riesz Representation Theorem, in Rudin's 'Real and Complex Analysis' (P.40, Theorem 2.14): Let $X$ be a locally compact Hausdorff space, and let $\Lambda$ be a positive linear functional on $C_c(X)$ (the set of all continuous functions on X with compact support) Rudin defines $$\mu(V)=sup\{\Lambda f:f\prec V\}$$ for every open set $V$ in $X$, where $f\prec V$ means $f$ is continuous and has compact support and $0\le f\le \chi_V$ He goes on to assert that $\mu(E)=inf\{ \mu(V): E\subseteq V, V \:open\}$ for every open set $E$ in $X$ But I have difficulty understanding why the above equality holds. I can prove $\mu(E)\leq inf\{ \mu(V): E\subseteq V, V \:open\}$ immediately from the definition of $\mu$ but the other side of the inequality is giving me trouble. Any help in elaborating Rudin's statement is very much appreciated.","['riesz-representation-theorem', 'real-analysis', 'measure-theory']"
1394251,Calculating Elliptic Curve cofactor h,"An Elliptic Curve in short Weierstrass form over a finite field $F_p$ is given by the equation: $$y^2 = x^3 + ax + b \mod p$$ To use this curve for cryptographic purposes, in the domain parameters of the curve a point $G$ on the curve is defined. $n$ is the order of the subgroup generated by $G$ and is usually included in the domain parameters of the curve. The cofactor of such a curve is defined as: $$h = \frac{\#E(F_p)}{n}$$ where $\#E(F_p)$ is the number of all points that satisfy the curve equation and $n$ is the order of the curve. For most (well-chosen) domain parameters, $h$ can be approximated reasonably well by: $$h \approx \frac{p}{n}$$ But what's the approach to actually calculate $h$ when only $a, b, n, p$ are given that gets around explicit point counting algorithms like Schoof/Elkies?","['elliptic-curves', 'group-theory']"
1394254,Union of conjugacy classes of $O(n)$ is not a subgroup,"Let $O(n)$ be the standard orthogonal group of real matrices. I am trying to prove the following: $N = \bigcup_{g\in GL_n(\mathbb{R})}g\cdot O(n)\cdot g^{-1}$ is not a subgroup of $GL_n(\mathbb{R})$. I know that if it was a subgroup then it was equal to the normal closure of $O(n)$ but I do not know what that is... Motivation: It is proved here that a linear automorphism $T:V \rightarrow V$ preserves some inner product on $V$ if and only if the matrix of $T$ w.r.t an arbitrary basis is similar to an orthogonal matrix. I want to prove a composition of two transformation of this type is not necessarily also of that type. (Which amounts to proving $N$ is not a subgroup, since closure under taking inverses clearly holds).","['group-theory', 'linear-algebra', 'normal-subgroups']"
1394264,Construct a function that takes any value even number of times.,"I'm looking for a continous function $f: [0,1] \to \mathbb{R}$ such that it takes any value even (thus finite) number of times. I suppose that it exists in the class of Lipschitz functions. All my approaches have led to some value which is taken infinite number of times.",['real-analysis']
1394271,Reducing a higher order nonlinear ODE to a system of first order ODEs,"The ODE that I am trying to reduce is: $$
y''' + 4\,y'' + y' + 6\,y - 2y^{2} = 0
$$ I start by letting
$$
y = y_1
$$
$$
y' = y_2
$$
$$
y'' = y_3
$$
$$
y''' = y_4 = 2y_1^2 - 4y_3 - y_2 - 6y_1
$$ However, due to the term $2y_1^2$, I believe that this set of functions cannot be put into matrix form, and hence, I am stuck here. I would very much appreciate any guidance. :)",['ordinary-differential-equations']
1394275,"Prove that $\mathrm E\left({\max}\left\{X^2 , Y^2\right\} \right) \leq 1 + \sqrt{1 - \rho^2}$ where $\rho$ is their correlation.","I have 2 random variables $X,Y$ with mean 0 and variance 1, their correlation is $\rho$. I need to prove this inequality $$\mathrm E\left({\max}\left\{X^2 , Y^2\right\} \right) \leq 1 + \sqrt{1 - \rho^2}$$ I need some pointers as to how to solve this problem. Thanks!",['probability']
1394276,Intersection of topological manifolds.,"A condition for the intersection of two smooth manifolds to be a smooth manifold is that they intersect transversally. Is this only an obstruction because of the smooth structure? Question: Is the intersection of two topological manifolds always a topological manifold? If not, are there conditions which can be added to the manifold(Not the smooth+transversal intersection) so that it is true?","['manifolds', 'general-topology']"
1394294,At least one of $|f(x)|$ and $|g(x)|$ not less than $a+1$,"Let $a\in(0,1),f(x)=ax^3+(1-4a)x^2+(5a-1)x-5a+3$,$g(x)=(1-a)x^3-x^2+(2-a)x-3a-1 $.
Prove that: For any real number $x$ ,at least one of $|f(x)|$  and $|g(x)|$ not less than $a+1$ since
$$f(x)+g(x)=x^3-4ax^2+(1+4a)x-8a+2$$
if we can prove 
$$|f(x)+g(x)|\ge 2(a+1)$$?but can not find any other and can not prove whether there is any other solution or not.","['contest-math', 'functions']"
1394302,On the norm of a quotient of a Banach space.,"Let $E$ be a Banach space and $F$ a closed subspace. It is well known that the quotient space $E/F$ is also a Banach space with respect to the norm 
$$
\left\Vert x+F\right\Vert_{E/F}=\inf\{\left\Vert y\right\Vert_E\mid y\in x+F\}.
$$
Unfortunately in a set of lecture notes on (Lie) group representations (material for our study group) the author accidentally used here $\min$ instead of $\inf$. Probably a mostly harmless booboo, because at that point it was only needed to get a Banach space structure on the quotient, and we will probably be concentrating on Hilbert spaces anyway, where the problem does not arise. Namely from Rudin's Functional Analysis I could not find a proof that the minimum should always be attained. Except in the case of a Hilbert space, where an application of parallelogram law (the sum of the squared norms of the two diagonals of a parallelogram equals that of the four sides) allows us to find a Cauchy sequence among a sequence of vectors $(y_n)\subset x+F$ such that 
$$\lim_{n\to\infty}\left\Vert y_n\right\Vert_E=\left\Vert x+F\right\Vert_{E/F}.$$ But anyway, the suspicion was left that the infimum is there for a reason (other than conveniently allowing us to sweep this detail under the rug at that point of the development of theory), so in the interest of serving our study group I had to come up with a specific example, where the minimum is not achieved. It's been 25 years since I really had to exercise the Banach space gland in my brain, so it has shrunk to size of a raisin. Searching this site did help, because I found this question . There we have $E=C([0,1])$, the space of continuous real functions on $[0,1]$ equipped with the sup-norm. If we denote by $\Lambda$ the continuous functional
$$
\Lambda: E\to\mathbb{R},f\mapsto\int_0^{1/2}f-\int_{1/2}^1f
$$
and let $F=\ker\Lambda$, then the answer to the linked question proves that there is no minimum sup-norm function in the coset $\Lambda^{-1}(1)$. So I have a (counter)example, and the main question has evolved to: When can we use minimum in place of infimum in the definition of the quotient space norm? My thinking: It seems to me that the answer is affirmative, if $F$ has a complement, i.e. we can write $E=F\oplus F'$ as a direct sum of two closed subspaces such that the norm on $E$ is
equivalent to the sum of the norms on $F$ and $F'$-components. But the first point also raises the suspicion that the question may be a bit ill-defined (and uninteresting) in the sense that the answer might depend on the choice of the norm $\left\Vert\cdot\right\Vert_E$ among the set of equivalent norms. However, if we, for example, perturb the sup-norm of $C([0,1])$ in the above example by multiplying the functions with a fixed positive definite function before taking the sup-norm, the argument seems to survive, so may be replacing the norm with an equivalent one is irrelevant? So to satisfy my curiosity I also welcome ""your favorite example"" (one with a finite-dimensional $F$ would be nice to see), where we absolutely need the infimum here. Bits about any sufficient or necessary conditions for the minimum to be sufficient or (as a last resort :-) pointers to relevant literature are, of course, also appreciated.","['quotient-spaces', 'banach-spaces', 'functional-analysis', 'normed-spaces']"
1394315,"How many numbers between 4,000 and 7,000 can be chosen using the digits [0, 8]?","I have a homework problem in combinatorics, and I am struggling to solve it because I didn't understand our lesson well. Can you please help me to solve this problem? How many numbers between 4,000 and 7,000 can be chosen using the digits 0, 1, 2, 3, 4, 5, 6, 7, and 8 if each digit must not be repeated in any numbers? PS: I don't have the resources to solve this. I just don't understand what our professor taught us, but we have already made a make-up class to solve this conflict.",['combinatorics']
1394328,an integral equation in a function with two arguments,"Say we are given $C(s,t)=\min(s,t)+\zeta st$. How can we solve $$g(s,t)=C(s,t)+\lambda \int_0^1g(s,u)C(u,t)du.$$
Looking into some text books on integral equations I see that most of the kernels, $C$, that they exemplify are degenerate (separable) hence solving such an equation becomes easy. But how could one proceed in this case where the kernel is not separable?","['calculus', 'functional-analysis', 'functions']"
1394372,ricci tensor of 2-sphere $S^2$,Hi could someone show me explicitly how to compute the ricci tensor $g_{ij}$?,"['differential-geometry', 'riemannian-geometry', 'semi-riemannian-geometry']"
1394374,AP in Chessboard,"The natural numbers $1,2,...,n^2$ are arranged in a $nXn$ chessboard. In how many ways can we arrange the numbers such that the numbers on every row and every column are in arithmetic progression?
I know that $1$ has to be put in one of the corners. I have also observed that the given criteria is maintained if the numbers are arranged one after another like $1^{st}$ row- $1,2,...,n$. $2^{nd}$ row- $n+1....2n$ and so on. In this way I get $4$ different ways(by rotating the board). Trying to prove that these are the only possible ways. Am I on the right path? Please explain.","['sequences-and-series', 'combinatorics']"
1394396,Prove that $\measuredangle AQP+\measuredangle NAP=90^o$,"Let a triangle $ABC$ be right at $A$, $AH$ be the altitude to the side $BC$. Let $M$ be an arbitrary point located in $AH$. Draw circle $B$ with the radius $BA$, circle $C$ with the radius $CA$. The circle $B$ and the circle $C$ respectively cut $CM, BM$ at $P$ and $Q$. Circle $(HPQ)$ cut $BC$ at $N$. Prove that $$\measuredangle AQP+\measuredangle NAP=90^o$$ Here is the GeoGebra file of this image.","['geometry', 'triangles']"
1394400,Taking the limit $\lim_{p\rightarrow \infty} \left( \frac{\|f\|_\infty}{\|f\|_p}\right)^p$,"Taking the limit 
$$\lim_{p\rightarrow \infty} \left( \frac{\|f\|_\infty}{\|f\|_p}\right)^p$$ First I think the expression after taking the limit will depend on the function $f$. In my attempt, because it is in the form $``1^\infty""$, I tried to use L'Hopital's rule. And we can calculate the limit (assuming the integrals are defined and finite, I just want to see what the limit might look like). 
\begin{align*}
 \lim_{p\rightarrow \infty} \left(\frac{\|\nabla u \|_\infty}{\|\nabla u\|_p}\right)^{p} &=  \lim_{p\rightarrow \infty} \exp\left( p\log\left(\frac{\|\nabla u \|_\infty}{\|\nabla u\|_p}\right)\right)\\
&=\lim_{p\rightarrow \infty} \exp\left( \frac{\log\left(\frac{\|\nabla u \|_\infty}{\|\nabla u\|_p}\right)}{\frac{1}{p}}\right)\\
&=\lim_{p\rightarrow \infty} \exp\left( \frac{\frac{d}{dp} \left[-\log\left(\frac{\|\nabla u \|_p}{\|\nabla u\|_\infty}\right)\right]}{\frac{-1}{p^2}}\right)\\
&=\lim_{p\rightarrow \infty} \exp\left( \frac{\left(\frac{\|\nabla u \|_\infty}{\|\nabla u\|_p}\right)\frac{\frac{d}{dp}\left[\|\nabla u\|_p \right]}{\|\nabla u \|_\infty}\}}{\frac{1}{p^2}}\right)\\
\end{align*}
where 
\begin{align*}
\frac{d}{dp}\left[\|\nabla u\|_p \right]  &= \frac{d}{dp}\left[\left(\int_{\mathbb R^N} |\nabla u |^p dx \right)^{1/p} \right] \\
&=\frac{d}{dp}\left[\exp\left(\frac{1}{p} \log\left(\int_{\mathbb R^N} |\nabla u |^p dx \right)\right)\right] \\
&=\|\nabla u \|_p \left\{\frac{-1}{p^2}\log\left(\int_{\mathbb R^N} |\nabla u |^p dx \right) + \frac{1}{p} \frac{1}{\int_{\mathbb R^N} |\nabla u |^p dx }\int_{\mathbb R^N} |\nabla u|^p \log(|\nabla u |) dx  \right\}
\end{align*} Putting it back into the limit we get 
$$\lim_{p\rightarrow \infty} \exp \left(-\log\left(\int_{\mathbb R^N} |\nabla u |^p dx \right) + p \frac{1}{\int_{\mathbb R^N} |\nabla u |^p dx }\int_{\mathbb R^N} |\nabla u|^p \log(|\nabla u |) dx \right)$$
which simplifies to 
$$\lim_{p\rightarrow \infty} \frac{\exp \left(p\frac{\int_{\mathbb R^N} |\nabla u|^p \log(|\nabla u |) dx}{\int_{\mathbb R^N} |\nabla u |^p dx } \right)}{\int_{\mathbb R^N} |\nabla u |^p dx }$$ And I am stuck. Is this a correct approach? Thank you very much!","['lp-spaces', 'limits', 'real-analysis', 'normed-spaces']"
1394401,Injective function on the domain of natural numbers,"Find all injective functions $f:N \rightarrow N$ such that $$f(f(m)+f(n))=f(f(m))+f(n)$$ Where $m,n$ are natural numbers.",['functions']
1394422,Find two homeomorphic topological spaces and a bijective continuous map between them which is not homeomorphism.,"I'm aware that it is duplicate, but I'd like to know whether my example is appropriate or not. Let our function $f$ be on the set $\mathbb{Q}\cap\mathbb{Z}$ induced by standard topology of a line. I'm going to construct a bijection from $\mathbb{Q}\cap\left((0,1)\cup(1,2)\right)$ to $\mathbb{Q}\cap(0,1)$. The rest from $(2n,2n+1)\cup(2n+1,2n+2)$ to $(n,n+1)$ is similar. My idea is that if the restriction of $f$ on $(n,n+1)$ is monotonous then we are done, because $f$ becomes continuous but its inverse does not.
Let's denote elements from $(0,1)$ in domain as $\dfrac{a'}{b}$ and elements from $(1,2)$ in domain decrease by $1$ and denote as $\dfrac{a''}{b}$ .
$$f(\dfrac{1'}{2})=\dfrac{1}{2}\text{and}f(\dfrac{1''}{2})=\dfrac{1}{3}$$
$$f(\dfrac{1'}{3})=\dfrac{1}{4}\text{and}f(\dfrac{1''}{3})=\dfrac{1}{5}$$
$$f(\dfrac{2'}{3})=\dfrac{2}{3}\text{and}f(\dfrac{2''}{3})=\dfrac{3}{4}$$
$$f(\dfrac{1'}{4})=\dfrac{1}{6}\text{and}f(\dfrac{1''}{4})=\dfrac{1}{7}$$
$$...\text{so.on}...$$
So $f(x'')=y$ means $f(1+x)=y$ and $f(x')=f(x)$ The idea is next:
We start from the elements with smallest denominator and map them on element which satisfies the condition of monotone on the one hand, and has the smallest possible denominator on the other hand. I think that this idea will lead us to surjectivity, but still I doubt. P.S. There is an assumption that for $\dfrac{p}{q}$ we have $\gcd(p,q)=1$","['examples-counterexamples', 'proof-verification', 'general-topology', 'functions']"
1394423,Conjugacy in $S_n$ with composing permutations left to right vs. right to left,"I realize there are two conventions for composing permutations. Left to right: $(1\ 2)(1\ 3) = (1\ 2\ 3)$ Right to left: $(1\ 2)(1\ 3) = (1\ 3\ 2)$ Among others, Dummit and Foote and Contemporary Abstract Algebra (Gallian) use the right to left convention, while Handbook of Computational Group Theory (Holt), Sage, and GAP use the left to right convention. Now, given permutations $\sigma, \tau \in S_n$ , where $\sigma = (\sigma_1\ \sigma_2 \ldots\ \sigma_n) \ldots$ (in cycle notation), in the right to left convention we have the convenient fact that $\tau \sigma \tau^{-1} = (\tau(\sigma_1)\ \tau(\sigma_2)\  \ldots\ \tau(\sigma_n) ) \ldots$ . Proof: Observe that if $\sigma(i) = j$ , then $\tau \sigma \tau^{-1} (\tau(i)) = \tau(j)$ . Therefore if the ordered pair $i, j$ appears in the cycle decomposition of $\sigma$ , then the ordered pair $\tau(i), \tau(j)$ appears in the cycle decomposition of $\tau \sigma \tau^{-1}$ . Now if you believe that, you can use a similar proof to obtain the ugly fact that in the left to right notation $\tau \sigma \tau^{-1} = (\tau^{-1}(\sigma_1)\ \tau^{-1}(\sigma_2) \ldots\ \tau^{-1}(\sigma_n))\ldots$ To me this makes the left to right convention inferior, because conjugation follows a less natural rule. Am I missing something? Are there other reasons to compose permutations from left to right that result in simpler algebraic laws? And if not, I am curious why we don't exclusively use right to left notation.","['convention', 'permutations', 'abstract-algebra', 'group-theory', 'gap']"
1394432,"Angle of tangent line and line $y=0,z=x$ is constant","Show that the tangent lines to the regular parameterized curve $\alpha(t)=(3t,2t^2,2t^3)$ make a constant angle with the line $y=0,z=x$. 1) The tangent line at each point is given, I believe, by $\alpha'(t)=(3,4t,6t^2)$ 2) So the angle this makes with $(x,0,x)$ is given I believe by $\frac{\arccos(u\cdot v)}{|u||v|}$? $$\frac{\arccos(3tx+6t^2x)}{\sqrt{(2x^2)(9+16t^2+36t^4)}}$$ Two concerns, should $x$ in my line $y=0,z=x$ be parameterized by $t$? Clearly my dot product is wrong, since it won't give a constant angle?","['differential-geometry', 'angle']"
1394443,Using basic definition to derive duplication formula for Gamma function,"Baby Rudin chap 8, 8.21, some consequences of the gamma function, one of them is
$$\Gamma(x)=\frac{2^{x-1}}{\sqrt\pi}\Gamma(\frac{x}2)\Gamma(\frac{x+1}2)$$
Rudin noted that this identity ""followed directly from $\Gamma(1/2)=\sqrt\pi$ and from theorem 8.19"", in which the theorem 8.19 is in fact a definition of the gamma function (1). $\Gamma(x+1)=x\Gamma(x)$, for all $x>0$. (2). $\Gamma(1)=1$. (3).$\log\Gamma(x)$ is convex on $\Bbb R^+$. And then I was having quite a hard time fighting to derive the duplication formula from this definition. I have to say that for me, it is NOT trivial or direct at all. I wonder, is there really a simple, or as Rudin put it, direct way to do this?","['analysis', 'calculus', 'real-analysis']"
1394455,How do I compute the gradient vector of pixels in an image?,"I'm trying to find the curvature of the features in an image and I was advised to calculate the gradient vector of pixels. So if the matrix below are the values from a grayscale image, how would I go about calculating the gradient vector for the pixel with the value '99'? 21 20 22 24 18 11 23
21 20 22 24 18 11 23
21 20 22 24 18 11 23
21 20 22 99 18 11 23
21 20 22 24 18 11 23
21 20 22 24 18 11 23
21 20 22 24 18 11 23 Apologies for asking such an open ended question, I've never done much maths and am not sure how to start tackling this.","['image-processing', 'multivariable-calculus', 'gradient-flows']"
1394473,Differentiability and continuity of a multivariable function,"Let $f:\mathbb R^2\to \mathbb R$ be defined by $$f(x,y)=\begin{cases}\frac{x|y|}{\sqrt{x^2+y^2}},& (x,y)\ne(0,0)\\ 0,& (x,y)=(0,0).\end{cases}$$ For which non-zero vectors $u$ does the directional derivative exist at the point $(0,0)$? Do the partial derivatives exist? Is $f$ differentiable at $0$? Is $f$ continuous at $0$? According to my calculations, the directional derivative is zero for all non-zero vectors $u$ at $(0,0)$ which implies the partial derivatives are zero at $(0,0)$. I am not sure how to proceed with 3. and 4. I am not allowed to use the existence of partial derivatives and their continuity to check for differentiability since the author introduces this theorem in the next section. Thanks.","['continuity', 'calculus', 'multivariable-calculus', 'derivatives']"
1394536,Packing of discrete random variables with finite second moment,"I am considering a discrete random variable $X \in\mathbb{R}$ with $N$ points (where each point has non-zero probability) and $E[X^2]=1$ and $E[X]=0$. Let $d_l$ be the the smallest distance between $x_l \in X$ and its closest neighbor in the support of $X$ that is
\begin{align}
d_{l}=\min_{x_l, x_k: l \neq k} |x_l-x_k|
\end{align} Also, define
\begin{align}
d_{\max}&=\max_{l} d_l \\
d_{\min}&=\min_{l} d_l \\
\end{align} I know that amongst random variables with finite second moment uniformly spaced and uniformly described random variable gives the best packing that 
\begin{align}
d_{\min} \le d_{\min \text{Unif}}=\sqrt{\frac{12}{N^2-1}}
\end{align} Here some question that I was thinking about: Can we have also a lower bound on $d_{\min}$ in terms of $N$ other than $d_{\min} \ge 0$. I am thinking no. We can always find an $X$ with a smaller and small minimum distance. Can we find upper and lower bounds  $d_{\max}$?
I am thinking that  \begin{align*}
d_{\max}  \le N d_{\min} \le  \sqrt{\frac{12 N^2}{N^2-1}}
\end{align*} Can we find lower and upper bounds on $\frac{d_{\min}}{d_{\max}}$? If we know $d_{\min}$ can we say something about the second smallest distance or $d_{\max}$? Finally,  where I can find any reference on this subject? And what branch of math studies some thing like this? Also, it seems to me that we do not have to talk about random variables here and just talk about packing deterministic points. Please let me know how I can improve the question. 
Thank you for any help in advance.","['probability-theory', 'probability', 'packing-problem', 'random-variables']"
1394545,Irreducibility criteria for polynomials with several variables.,"Let $K$ be a field. Show that $x^2-yz$ is irreducible in $K[x,y,z]$. Deduce that $x^2-yz$ is prime. If it is $K[x]$, then there are several methods which can be used to check whether a given polynomial is irreducible. But how do we check that when we have a polynomial of several variables? No idea how to do it. Any theorems? Moreover, in general, it is not true that irreducible elements are prime. So, how can I deduce the last result? Any help is appreciated.","['abstract-algebra', 'irreducible-polynomials', 'polynomial-rings', 'ring-theory']"
1394560,Alternative area of a triangle formula,"The problem is as follows:
There is a triangle $ABC$ and I need to show that it's area is: $$\frac{1}{2} c^2 \frac{\sin A \sin B}{\sin (A+B)}$$
Since there is a half in front I decided that base*height is equivalent to $c^2 \frac{\sin A \sin B}{\sin (A+B)}$. So I made an assumption that base is $c$ and went on to prove that height is $c \frac{\sin A \sin B}{\sin (A+B)}$. But I end up expressing height in terms of itself.. i.e.  $h \equiv \frac{ch}{a\cos B + b \cos A}$. How do I prove this alternative area of triangle formula?","['geometry', 'area', 'triangles', 'trigonometry']"
1394599,Newton iteration on Riemannian manifolds,"Suppose $f:M \to N$ is a smooth map between complete Riemannian manifolds of the same dimension. Suppose $Df(m_0)$ is invertible, and $n$ is a point close to $f(m_0)$. Can we perform Newton iteration to find a point $m^*$ mapping to $n$ as we do in the proof of the Inverse Function Theorem, by taking $m_{i+1} = \exp_{m_i} \circ (Df_{m_i})^{-1} \circ \log_{f(m_i)}(n)$? Hopefully we would expect this to converge to a point mapping to $n$ if $n$ is chosen close enough to $f(m_0)$. My apologies if this is nonsense; I'm still learning about Riemannian manifolds, $\log$, $\exp$, etc.","['differential-geometry', 'smooth-manifolds', 'riemannian-geometry']"
1394623,Evaluating $\sum_{n \geq 1}\ln \!\left(1+\frac1{2n}\right) \!\ln\!\left(1+\frac1{2n+1}\right)$,"Is there a direct way to evaluate the following series? $$
\sum_{n=1}^{\infty}\ln \!\left(1+\frac1{2n}\right) \!\ln\!\left(1+\frac1{2n+1}\right)=\frac12\ln^2 2. \tag1
$$ I've tried telescoping sums unsuccessfully. The convergence is clear. Given the simplicity of the result, I'm inclined to think it might exist an elegant way to get $(1)$.","['calculus', 'closed-form', 'logarithms', 'sequences-and-series', 'integration']"
1394643,Symmetry of the second derivative,"For the purposes of this question, a function $f$ is differentiable at $x\in \mathbb{R}^d$ iff (i) the directional derivative $\mathrm{D}_vf(x)$ exists for all $v\in \mathrm{T}_x(\mathbb{R}^d)$ and (ii) the map $\mathrm{T}_x(\mathbb{R}^d)\ni v \mapsto \mathrm{D}_vf(x)\in \mathbb{R}$ is linear and continuous.  (You actually get continuity for free, but I include it because it belongs there if you replace $\mathbb{R}^d$ with something infinite dimensional.)  In this case, I write $v^a\nabla _af(x):=\mathrm{D}_vf(x)$.  A covariant tensor field $T_{a_1\ldots a_l}$ is differentiable at $x\in \mathbb{R}^d$ iff $[v_1]^{a_1}\cdots [v_l]^{a_l}T_{a_1\ldots a_l}$ is differentiable for all $[v_1]^a,\ldots ,[v_m]^a\in \mathbb{R}^d$, in which case the derivative is the tensor field of covariant rank $l+1$, $\nabla _aT_{a_1\ldots a_l}$ that sends $l+1$ vectors $v^a,[v_1]^a,\ldots ,[v_l]^a$ to $v^a\nabla _a\left( [v_1]^{a_1}\cdots [v_l]^{a_l}T_{a_1\ldots a_l}\right)$.  (Of course, you use essentially the same definition for arbitrary tensors, but math.stackexchange is not letting me stagger indices and I don't need to know how to differentiate contravariant tensors for the purposes of this question). The question is: If $f$ is twice differentiable at $x$, must we have that $\nabla _a\nabla _bf(x)=\nabla _b\nabla _af(x)$? The definition given above is strictly weaker than Fr√©chet differentiability , but strictly stronger than G√¢teaux differentiability (if you want the examples that show strictness, ask in the comments).  The result is true for the Fr√©chet derivative (see, e.g., Pugh pg. 281), but false for the G√¢teaux derivative (see, e.g., the standard example on Wikipedia).  This is not a counter-example for the definition above because the second derivative fails to be linear at the origin (and so it is not considered to be twice differentiable there).  Furthermore, it is true for all three definitions if we require continuity of $\nabla _a\nabla _bf(x)$ at $x$.  But can we remove this continuity hypothesis? For what it's worth, I think it is false.","['calculus', 'real-analysis', 'analysis', 'tensors', 'derivatives']"
1394696,A generalization of Jordan curve theorem involving Warsaw circle,"When I first looked at Jordan curve theorem my impression was: ""Wow, a complicated theorem telling us something obvious!"" Let me state the Theorem: Let $C \subset \Bbb{R}^2$ be a set homeomorphic to the circle $S^1$. Then $\Bbb{R}^2 \setminus C$ has two connected components: one of them is bounded, the other one is unbounded. What about changing hypothesis? What about if $C$ were (homeomorphic to) the Warsaw circle? Intuitively, I think that the answer would be the same: $C$ divides the plane in a space having two connected components, one bounded and the other one unbounded. But is this true? How can we prove this? Is it a corollary of Jordan's theorem?",['general-topology']
1394704,Eigenvalues of matrix sums,"Under what conditions are the eigenvalues of $A+B$ equal to the eigenvalues of $A$ plus the eigenvalues of $B$, where $A,B$ are square matrices? From searching, it seems that the condition is that $AB=BA$.  If that is indeed the case, why?","['eigenvalues-eigenvectors', 'linear-algebra', 'matrices']"
1394730,Counting integral solutions,"Suppose $a + b + c = 15$ Using stars and bars method, number of non-negative integral solutions for the above equation can be found out as $15+3-1\choose15$ $ =$ $17\choose15$ How to extend this principle for finding number of positive integral solutions of
$a + b + 3c = 15$? I tried to do it by substituting $3c$ with another variable $d$. But could not succeed.",['combinatorics']
1394738,How to understand the set of permutation representations of a group $G$?,"In Algebra by Michael Artin, Chapter 6, page 182 (second edition, Pearson),  Proposition 6.11.2 states that there exists a bijective correspondence between operations of a group $G$ on the indices set $S=\{1,\cdots,n\}$ and permutation representations $G\to S_n$, in which a permutation representation of a group $G$ is a homomorphism from the group to a symmetric group, say, $\phi:G\to S_n$. This is really driving me insane, because all I can imagine is that there is always solely one representation. My reasoning is straightforward, for each $g\in G$, it sends $1,\cdots,n$ to $g(1),\cdots,g(n)$, and thus corresponds to a $\sigma\in S_n$ such that $\sigma(1)=g(1),\cdots,\sigma(n)=g(n)$. So I think that the map $\phi:G\to S_n$ is completely determined by $G$ and there is thus but one representation.. Anything wrong?","['abstract-algebra', 'group-theory', 'permutations']"
1394769,Determining the MVUE of $\theta$ when $f(x;\theta) = \theta^x (1-\theta)$,"The Statement of the Problem: Let $X_1, X_2, ... , X_n$ be a random sample from $$ f(x;\theta) = \theta^x (1-\theta) \quad x = 0,1,2,... $$ (a) Find the ML estimator of $\theta$. (b) Show that $T = \sum_{i=1}^n X_i$ is a sufficient statistic for $\theta$. (c) Determine the MVUE of $\theta$. Where I Am: I've taken care of parts (a) and (b) but am a bit stuck on part (c). In order to find a MVUE, I have to find an unbiased estimator, which I can't seem to figure out. My MLE, which is the following: $$ \hat\theta_{\text{mle}} = \frac{\sum_{i=1}^n X_i}{n + \sum_{i=1}^n X_i} $$ seems to be biased (although, honestly, I got stuck trying to find its expectation). So, I've tried making an unbiased estimator from scratch... with no luck. Any tips here would be helpful. Thanks.","['expected-value', 'probability-distributions', 'statistical-inference', 'statistics', 'parameter-estimation']"
1394770,Set of infinite subsets. Is it a topology?,"Here is the question: Let $X = \mathbb{R}$ and let $\Omega$ consist of the empty set and all infinite subsets of $\mathbb{R}$. Is $\Omega$ a topological structure? My attempt : I think the answer is No; it is not a topology. 
Because we have $$ \Omega =  \lbrace \varnothing \rbrace \cup \lbrace U \subseteq \mathbb{R} \mid \text{$U$ is infinite} \rbrace $$ If we check the axiom for the finite intersection property then let $U_1, U_2 ..U_n$ be finite elements of $\Omega$ now $\cap_{i=1}^{n} U_i$ might be finite and thus doesn't belong to $\Omega$. Is this explanation correct? EDIT: Let $U_1$ be set of all positive even numbers and $U_2$ be the set of all primes. Now we know both $U_1$ and $U_2$ are elements of $\Omega$ as they are infinite sets but $ U_1 \cap U_2 = \lbrace 2 \rbrace $ which is finite.",['general-topology']
1394778,Elementary topology examples,"I'm preparing (to teach) my first class of undergraduate topology and I'm looking for some elementary, motivating applications of topology for the first day.  We'll be following Munkres, starting with point-set topology and then ending the semester with advanced topics such as knot theory or algebraic topology.  The students will not have had algebra and this might be the first course they take after introduction to proof. I'm looking for everyday facts that are easily stated and proved nicely with topology.  For instance, I can illustrate Brouwer's fixed point theorem with a map of campus: If I drop the map on the ground, there is some point on the map over the point it represents.  If I rip the map into pieces, I can put the map parts all over campus so that no map point is over the point it represents. Most ""applications"" that I can think of / are in Real Life Applications of Topology are too advanced for a first, introductory day.","['big-list', 'general-topology', 'soft-question']"
1394789,How to calculate probability with Z score not on table?,"According to this Z table in my book, anything with a $z$ of over $3.16$ is probability 1, but this is not right. The textbook also has an example where $\mathbb P(Z\geq3.9) = 0.000048$; can somone explain to me how this answer was achieved?","['statistics', 'probability-distributions', 'statistical-inference']"
1394803,Find the real root of $x^5+5x^3+5x-1$,"Find the real root of $$x^5+5x^3+5x-1$$ I have tried with squaring but the numbers that I got is not correct, any help ?",['algebra-precalculus']
1394843,Calculating $\sum_{n=1}^{\infty}\ln^2 \!\left(1+\frac1{2n}\right) \!\ln^2\!\left(1+\frac1{2n+1}\right)$,Based upon Oloa's question here Evaluating $\sum_{n \geq 1}\ln \!\left(1+\frac1{2n}\right) \!\ln\!\left(1+\frac1{2n+1}\right)$ I was thinking if we possibly can get a nice way to evaluate the series $$\sum_{n=1}^{\infty}\ln^2 \!\left(1+\frac1{2n}\right) \!\ln^2\!\left(1+\frac1{2n+1}\right).$$ Maybe using the same telescoping idea or it simply doesn't work? What then?,"['calculus', 'real-analysis', 'definite-integrals', 'sequences-and-series', 'integration']"
1394847,degree of an etale cover of the affine line,"Let $X\subset \mathbb{A}^N_k$ be an irreducible smooth variety over an algebraically closed field $k$. Suppose we have an etale map $\pi:X\to \mathbb{A}^1_k$. Are there any bounds on the degree of $\pi$? Here etale means flat with smooth, finite fibers. I'm interested mainly in the characteristic zero case.",['algebraic-geometry']
1394869,Question on the matrix of a Kaehler Metric in Normal Coordinates,"I am currently studying normal coordinates on a Kaehler manifolds: Let $h$ be a Kaehler metric on a complex manifold $M$ and let $p \in M$. Let $(z_1,..,z_n)$ be a coordinate chart such that $h$ is a metric in these coordinates. I know that due to the Kaehler condition, we have that $h_{i\bar j}(p)=\delta_{ij}$ after a constant linear change of coordinates $(z'_1, ...,z'_n)$. (In addition, I know that $dh_{i \bar j}=0$).  My question is: How does the matrix of $h$ look in the new coordinates $(z'_1, ...,z'_n)$ before I substitute $p$ in to get $h_{i\bar j}(p)=\delta_{ij}$? Is there any kind of change-of-coordinates formula to obtain the matrix $h$ in these new coordinates? The reason I am asking is because I need to compute the derivatives of the $h_{i\bar j}$ without plugging in $p$.","['complex-geometry', 'algebraic-geometry', 'differential-geometry', 'kahler-manifolds']"
1394882,Shorter proof of measurability of the set where two measurable functions differ,"Let $f,g$ be measurable functions from $\Omega$ into $[0,\infty]$. I want to show that the set where the two functions differ is measurable. i.e. the set $K = \{x\in \Omega: f(x) \neq g(x) \}$ is measurable. Since $f,g$ can take on $+\infty$, my approach is to consider the following cases: For $x \in \Omega$ such that $f(x) \neq g(x)$, $f(x) \in \mathbb{R}$, $g(x) \in \mathbb{R}$ $f(x) \in \mathbb{R}$, $g(x) = \infty$ $f(x)  = \infty $, $g(x) \in \mathbb{R}$ Since the cases 2 and 3 are symmetric, I essentially need to consider cases 1 and 2 (without loss of generality). But is there a shorter proof of the claim which handles all three cases all at once?",['measure-theory']
1394890,Echalon decomposition in binary shuffle (Hopf) algebras,"Consider a binary shuffle algebra $\mathcal{W}$ of two letters $a, b$. As usual the concatination of two words $u = u_1 \dots u_m$, $v = v_1 \dots v_n$ is defined as:
$$u \bullet v := u_1 \dots u_m v_1 \dots v_n$$
and the shuffle product is defined recursively as:
$$(k \bullet u) * (l \bullet v) := k \bullet (u * (l \bullet v) ) + l \bullet ( (k \bullet u) * v)$$
where $k,l \in \{a,b\}$ are some letters... If necessary, the coproduct of $w \in \mathcal{W}$ is:
$$\Delta (w) = \sum_{u \bullet v = w} u \otimes v.$$ An element $c \in \mathcal{W}$ is said to be in echalon form of weight $N$, if it is the concatination exponent of some linear combination of $a$ and $b$, i.e.:
$$c = (\alpha a + \beta b)^N = \sum_{k=0}^N \alpha^{N-k} \beta^{k} (a^{N-k} * b^{k}).$$ The problem I have is to prove (relatively easy) that any shuffle element $a^m * b^n$ can be represented as a combination of echalon elements of wieght $m+n$ and to find a formula (the hard part) for this, e.g. something like:
$$a^m * b^n = \sum_{k=1}^{m+n} \gamma_k^{(m,n)} (\alpha_k^{(m,n)} a + \beta_k^{(m,n)} b)^{m+n} \, ?$$
Examples:
$$a*b = ab + ba = \frac{1}{2} \left( (a+b)^2 - (a-b)^2 \right),$$
$$a^2 * b = a^2b + aba + ba^2 = \frac{1}{2} \left( (a+b)^3 - (a-b)^3 - 2 b^3 \right)...$$","['hopf-algebras', 'combinatorics']"
1394948,Prove using algebra of continuous functions that $f$ is continuous in $\mathbb{R}$,"Let us consider $f : \mathbb{R} \to \mathbb{R}$ defined by
  $$f(x) =\begin{cases} x^2 \sin \frac{1}{x},& x \neq 0\\ 0,& x = 0\end{cases}.$$ By using algebra of continuous functions (or algebra of limits) show that $f$ is continuous in $\mathbb{R}$. (You may assume without
  proving that $\sin y$ and polynomials are continuous at every point). Okay so I understand that $x^2$ and $\sin\frac{1}{x}$ are both continuous functions, and due to algebra of continuous functions proving $f(x)$ is continuous but I'm not sure how to prove this? Thanks.","['continuity', 'real-analysis', 'functions']"
1394977,L'H√¥pital's rule and Difference Quotients,"Consider the general difference quotient for a function $f(x)$ that is differentiable at $x = a$: $$f'(a) = \lim_{x \to a} \frac{f(x) - f(a)}{x - a}$$ Since both the numerator and denominator of the difference quotient are differentiable and approach 0, it seems like we should be able to apply l'Hospital's rule, differentiating with respect to $x$: \begin{align}
f'(a) & = \lim_{x \to a} \, \frac{f(x) - f(a)}{x - a} \\
& = \lim_{x \to a} \, f'(x), \text{ given we fix $a$ and have assumed $f$ is differentiable}
\end{align} But this seems to imply that $f'(x)$ is continuous or $f(x)$ is continuously differentiable at $x = a$. I don't understand where this additional condition comes from: I suspect the problem may be in applying l'Hospital's rule (perhaps it's circular?). But to use l'Hospital's and know the limit existed, it was sufficient to assume $f(x)$ was differentiable at $x = a$. Nowhere did we have to make the assumption that the function be continuously differentiable. I must be overlooking some small detail, but I just cannot put my finger on it. Any help would be appreciated.","['calculus', 'limits', 'derivatives']"
1394985,Advanced Algebra Manipulation/Inequality Proof: $\frac{4x^3(x^2+y^2)-2x(x^4+y^4)}{(x^2+y^2)^2} \leq 6|x|$,"I need to show that
$$\frac{4x^3(x^2+y^2)-2x(x^4+y^4)}{(x^2+y^2)^2} \leq 6|x|$$ by starting with the left side of the inequality and working from there. Hints from the textbook said to work from these inequality ""tricks,"" $$2|ab| \leq a^2 + b^2$$
$$|a| + |b| \leq \sqrt{2} \sqrt{a^2+b^2}$$ And the triangle inequality, $$|a+b| \leq |a| + |b|$$ Expanding the numerator gives us $$\frac{2x^5 + 4x^3y^2 - 2xy^4}{(x^2 + y^2)^2}$$ For starters, I use the triangle inequality theorem to make the numerator look like this: $$|2x^5 + 4x^3y^2 - 2xy^4| \leq |2x^5|+|4x^3y^2|+|2xy^4|$$ Also, in regard to the denominator, since it is even, it is always positive and thus equal to its absolute value. Then, I multiply both sides by the denominator, $(x^2+y^2)^2$. This gives us $$|2x^5|+|4x^3y^2|+|2xy^4| \leq 6|x||x^4 + 2x^2y^2+y^4|$$
$$|2x^5|+|4x^3y^2|+|2xy^4| \leq 6|x^5+2x^3y^2+xy^4|$$ My question is, since $|a+b| \leq |a|+|b|$, I feel as though I cannot violate that rule and am stuck. What trick(s) can I use from here? If there were no absolute value symbols, it would be as simple as simplifying the inequality since the orders match up. However, it would not be true for all (x,y) as the right side of the inequality is odd.","['absolute-value', 'real-analysis', 'algebra-precalculus', 'inequality']"
1395020,Index of zero of a gradient vector field at a critical point,"Let $M$ be a Riemannian manifold with a Morse function $f: M \to \mathbb{R}$. The zeroes of the gradient vector field of $f$ are the critical points of $f$. How do you show that a critical point of $f$ with Morse index $k$ is a zero of the gradient vector field with index $(-1)^k$? Update, 8/29: If somebody has something they want to add as an answer, there are 50 points are on the table that will otherwise go to waste. Notes: The latter index is the degree of the Gauss map $\partial B^n \to S^{n-1}$ defined by the vector field on the boundary of a small ball $B^n$ containing the zero, as in Poincar√©-Hopf. I'm looking for an argument that is intrinsic or at least preserves the Riemannian structure, maybe using the Hessian. (Here's a sketch of my unsatisfying argument: Any two Riemannian structures on $M$ define gradient vector fields for $f$ with the same critical points, and you can define a time-dependent flow connecting any two such vector fields to see that the index of every zero is preserved. Thus it suffices to invoke the Morse lemma and use a Morse chart to pull back to $\mathbb{R}^n$ with the standard Riemannian metric. From there, the claim is a simple, explicit calculation.)","['differential-topology', 'morse-theory', 'differential-geometry', 'riemannian-geometry']"
1395062,"Finding the number of permutations of $\{1,\cdots,6\}$ which do not contain 3 consecutive integers.","I tried to find the number of permutations of $\{1,\cdots,6\}$ which do not contain the strings 123, 234, 345, or 456 using the following method, and I would like to find out why this method does not give the right answer. (In particular, which permutations does it count incorrectly?) Take the total number of permutations and then subtract those with 3 consecutive integers, add back those with 4 consecutive integers, subtract the ones with 5 consecutive integers, and finally add the one permutation with all digits consecutive to get $6!-4\cdot4!+3\cdot3!-2\cdot2!+1\cdot1!=720-96+18-4+1=\color{blue}{639}$.","['discrete-mathematics', 'combinatorics']"
1395069,"Can I go from the LU factorization of a symmetric matrix to its Cholesky factorization, without starting over?","I mistakenly computed the LU factorization and then realized that the question is asking for a Cholesky factorization, i.e., finding a lower triangular matrix L such that the symmetric matrix A has factorization $LL^T$. Can I modify this factorization to achieve the Cholesky factorization? Thanks,","['matrices', 'lu-decomposition', 'matrix-decomposition', 'cholesky-decomposition', 'linear-algebra']"
1395083,$n$th roots of entire functions,"I am stuck on this complex analysis problem. Let $f$ be an entire function and $n$ a positive integer. Show that
  there exists an entire function $g$ such that $f=g^n$ if and only if
  the order of each zero of $f$ is divisible by $n$. I can see that locally around each $z_0$ we can write $f(z)=(z-z_0)^{nk}s(z)$ where $s(z)$ has no zeroes in a neighborhood of $z_0$ and so there exists a logarithm of $s(z)$, say $l(z)$, which means that $g(z)=(z-z_0)^ke^{l(z)/n}$ works, but I don't understand how to get an entire function from this. I know that it suffices to show that this construction gives functions that agree on the overlap of these neighborhoods, but I don't see why they would have to agree.",['complex-analysis']
1395084,"Measures, as a supreme, proof","Let $\Sigma$ be a $œÉ$-algebra over a set $X$, and $Œº_1$ and $Œº_2$ finite measures in it. It can be shown that the function $Œº:\Sigma \to [0,\infty ]$ defined by $$E\mapsto \sup_{F‚àà\Sigma}\{Œº_1(E‚à©F)+Œº_2(E\setminus F)\}$$ is a measure. could someone help me see is a measure I got stuck when i have to show $$\mu(\bigcup_{n=1}^\infty E_n) \geqslant \sum_{n=1}^\infty\sup_{F\in\Sigma} \left\{\mu_1(E_n\cap F) + \mu_2(E_n\setminus F) \right\} = \sum_{n=1}^\infty \nu(E_n).$$ $E_n $ a secuence of disjoints set Know you can also use Radon-Nicodym, since $\mu_1$ and $\mu_2$ finite, but i'm more interested in the general case, when you have two measures","['elementary-set-theory', 'measure-theory']"
1395093,Non-constant $L^1$ function has a non-zero integral over some interval,"Prove that if $f\in L^1([0,1],\lambda)$ is not constant almost
  everywhere then there exists an interval so that
  $\int_I\!f\,\mathrm{d}\lambda\neq 0$. Here $\lambda$ is the Lebesgue
  measure. Since this is obviously true for continuous functions, I've been trying to use the fact that continuous functions with compact support are dense in $L^1$, but I'm not sure how to set it up.","['lebesgue-measure', 'real-analysis', 'measure-theory']"
1395094,Prove that a sequence whose second difference is a nonzero constant is quadratic.,"For example, if {$a_0, a_1, a_2, a_3, ...$} is the sequence, 
the first difference is {$a_1-a_0, a_2-a_1, a_3-a_2, ...$}, 
and the second difference is {$(a_2-a_1)-(a_1-a_0), (a_3-a_2)-(a_2-a_1), ...$}. I think that using facts from up to Calculus, perhaps derivatives, should be enough. I find myself going in circles and don't know how to approach this.","['sequences-and-series', 'quadratics']"
1395095,Share the beer fairly in a finite number of pours,"A classical problem within measurements is that you have a $8\,\text{dl}$ mug of delicious expensive beer and need to share it evenly with your friend. However you only have two empty glasses of $5\,\text{dl}$ and $3\,\text{dl}$. Is it possible to divide the liquid in two using those two containers? With some light pondering one comes to the conclusion that yes, it is possible. 8 5 3 

8 0 0 - 0 
3 5 0 - 1 
3 2 3 - 2 
6 2 0 - 3 
6 0 2 - 4 
1 5 2 - 5 
1 4 3 - 6 
4 4 0 - 7 Assume that we have a mug containing $B\,\text{dl}$ delicious beer, and two empty mugs of sizes $p$ and $q$. What conditions must lie on $p$ and $q$ to ensure that there always exists a finite number of pours to split $B$ in half? (It is taken for given that $B$ always is even...)","['graph-theory', 'discrete-mathematics']"
1395112,Proving $Y$ such that $Y \cap B = \emptyset$,"I have been solving this problem from Velleman's How to prove book: Suppose $B \subseteq A$ and define a relation $R$ on $\mathcal{P}(A)$
   as follows: $R = \{(X,Y) \in \mathcal{P}(A) \times \mathcal{P}(A) \mid
 (X \Delta Y) \subseteq B\}$ a) Prove that $R$ is an equivalence relation on $\mathcal{P}(A)$. b) Prove that for every $X \in
 \mathcal{P}(A)$ there is exactly one $Y \in [X]_R$ such that $Y \cap B
 = \emptyset$ Now I have proved the first part of the question. But I'm stuck in the
second part. I cannot find any existential example for $Y$ for which
$Y \cap B = \emptyset$. Any pointers on how to solve it ?","['elementary-set-theory', 'equivalence-relations', 'relations', 'logic']"
1395131,Markov chains and conditioning on impossible events,"Consider a Markov chain $(X_0,X_1,\ldots)$ with a state space $S\equiv\{s_1,s_2\}$ and the following matrix of ‚Äútransition probabilities‚Äù (I will explain the use of quotation marks below):
\begin{align*}
\begin{array}{c|cc}
&s_1&s_2\\
\hline
s_1&1&0\\
s_2&1&0
\end{array}
\end{align*}
That is, no matter what initial state the system starts in, it will always end up in state¬†$s_1$ in one period and stay there forever. Rigorously speaking, these ‚Äútransition probabilities‚Äù are to be interpreted as follows:
\begin{align*}
\mathbb P\,(X_{n}=s_1\,|\,X_{n-1}=s_1)=&\,1,\\
\mathbb P\,(X_{n}=s_2\,|\,X_{n-1}=s_1)=&\,0,\\
\mathbb P\,(X_{n}=s_1\,|\,X_{n-1}=s_2)=&\,1,\\
\mathbb P\,(X_{n}=s_2\,|\,X_{n-1}=s_2)=&\,0
\end{align*}
for each $n\in\mathbb N$. My concern is that the last two probabilities are ill-defined (except possibly for $n=1$), because for any given initial probabilities, the condition events $\{X_{n-1}=s_2\}_{n=2}^{\infty}$ have zero probability! Strictly speaking, therefore, the above matrix cannot be interpreted as conditional probabilities because of the problem of conditioning on events that never occur. What is the standard resolution of this technical problem? Does one make the hand-waving assumption of defining conditional probabilities that depend on impossible events anyway, or is there a more sophisticated and rigorous way around this issue? Any input is appreciated.","['probability', 'markov-chains', 'stochastic-processes']"
1395136,"For $ A \in M_{m \times n}(\mathbb{R})$, does $\ker(A)$ relate to $\ker(A^T) $?","For $ A \in M_{m \times n}(\mathbb{R})$, does $\ker(A)$ relate to $\ker(A^T) $? And if so, what would be the connection? I wouldn't imagine there being any without additional conditions on $A$ (like symmetry or something), but I'm not sure. To provide some context, I'm trying to show that if $Ax = 0_m $ has a unique solution $x \in \mathbb{R^n}$, i.e. $\ker(A) = \{0_n\}$, then the matrix $A^TA$ is invertible. I reasoned that $Ax=0_m$ having a unique solution will not necessarily yield $\ker(A^TA) = \{0_n\}$ as $\ker(A^T)$ might not be $ \{0_m\}$. However, if $\ker(A) = \{0_n\}$ implies $\ker(A^T) = \{0_m\}$ then the solution should follow. Thanks in advance, Brandon","['linear-algebra', 'transpose']"
1395156,Closed plus finite dimensional in a TVS,"If $E$ is a topological vector space (TVS), $F_1$ a closed subspace of $E$, and $F_2$ a finite dimensional subspace of $E$, such that $F_1 \cap F_2=\{0\}$, is $F_1+F_2$ necessarily closed? If yes, are the projection from $F_1+F_2$ onto $F_1$ and $F_2$ respectively, continuous?","['functional-analysis', 'general-topology']"
1395177,"Is anyone talking about ""ball bundles"" of metric spaces?","In differential geometry: Each smooth manifold $M$ is equipped with a tangent bundle $TM,$ which is a manifold equipped with a projection back to $M$ Given a smooth map $f : M \rightarrow N$ between smooth manifolds, we get a corresponding pushforward $f_* : TM \rightarrow TN.$ Furthermore, the square involving $f_*,f$ and the two projections $TM \rightarrow M,TN \rightarrow N$ commutes. Something similar appears to occur in the study of metric spaces. Each metric space $X$ is equipped with a ball bundle $BX$, defined as $(\mathbb{R}_{\geq 0} \cup \{\infty\}) \times X.$ I'm not 100% sure how to make this into a metric space in its own right. Anyway, we get a projection $\pi_X : BX \rightarrow X$ given by $\pi_X(r,x) = x$. Given a function $f : X \rightarrow Y$ between metric spaces, we get a pushforward $f_* : BX \rightarrow BY$ that works as follows: we assert that $(s,y)$ equals $f_*(r,x)$ iff two conditions hold. Firstly, $y = f(x).$ Secondly, $s$ equals the least element of $\mathbb{R}_{\geq 0} \cup \{\infty\}$ such that closed the ball of radius $s$ centered at $y$ includes the image under $f$ of the closed ball of radius $r$ centered at $x$. I'm not sure if we need any conditions on $f$ to ensure that such an $s$ exists. So whereas the pushforward in differential geometry measures the directed sensitivity of the function to an infinitesimal directed change, the pushforward of a function between metric spaces (as defined above) measures the undirected sensitivity to an undirected error. Anyway, it seems to me that these ball bundles provide a sensible foundation for the basic numerical analysis we're learning in class at the moment. For example, this construction generalizes and improves upon the notion of interval arithmetic . Question. Is anyone talking about ""ball bundles"" of metric spaces? If so, what are they called in the literature, and where can I learn
  about them?","['metric-spaces', 'reference-request', 'general-topology', 'differential-geometry', 'numerical-methods']"
1395186,"Help proving generalized Jensen's inequality $\mathbf{E}[f(\cdot,X(\cdot))\mid \mathscr{G}] \geq f(\cdot,\mathbf{E}[X\mid\mathscr{G}](\cdot))$","I'm reading Meyer's seminal work Probability and Potentials (1966), in which he states the following ""borrowed"" theorem from Dubins ""Rises and Upcrossings of Nonnegative Martingales"" (1961). LEMMA. ( Generalized Jensen's inequality ) Let $(\Omega, \mathscr{F}, \mathbf{P})$ be a probability space, $X$ an integrable random variable on this space, and $\mathscr{G}$ a sub-$\sigma$-field of $\mathscr{F}$. We shall denote by $Y$ a version of $\mathbf{E}[X\mid \mathscr{G}]$. Let $f$ be a measurable mapping of $\Omega \times \mathbf{R}$ (with the natural product $\sigma$-field) into $\mathbf{R}$, such that (a) The mapping $\omega \mapsto f(\omega,t)$ is $\mathscr{G}$-measurable for each $t\in\mathbf{R}$. (b) The mapping $t\mapsto f(\omega,t)$ is convex for each $\omega \in \Omega$. Suppose that the random variable $\omega \mapsto f(\omega,X(\omega))$ is integrable. We then have the inequality
  $$\mathbf{E}[f(\cdot,X(\cdot))\mid \mathscr{G}] \geq f(\cdot,Y(\cdot))\ \text{a.s.}$$ He indicates that one could prove the theorem for simple $X$ and then pass to a limit ""which is a little more delicate than usual"" and then omits the proof. As a side note, I have searched Dubins' paper and find nothing even remotely similar in it. I don't see how assuming $X$ is simple would help, but here's what I've tried so far. Proof. By the convexity assumption, for all $x,x_0,\omega$ we have
$$
f(\omega,x) \geq \partial_2 f(\omega,x_0)(x-x_0) + f(\omega,x_0)
$$
where
$$
\partial_2 f(\omega,x_0) = \lim_{n\to\infty} \frac{f(\omega,x_0+1/n)-f(\omega,x_0)}{1/n}
$$
is the right-handed derivative in $f$'s second variable. Note that $\partial_2 f(\cdot,x_0)$ is a limit of $\mathscr{G}$-measurable functions and hence is as well, for each $x_0$. Now plug in $x=X(\omega)$, so we have
$$
f(\omega,X(\omega)) \geq \partial_2 f(\omega,x_0)(X(\omega)-x_0) + f(\omega,x_0)
$$
for all $x_0$. At this point I would like to condition both sides relative to $\mathscr{G}$ to get
$$
\mathbf{E}[f(\cdot,X(\cdot))\mid \mathscr{G}](\omega) \geq \partial_2 f(\omega,x_0)(Y(\omega)-x_0) + f(\omega,x_0)
$$
for almost all $\omega$ in $\Omega_{x_0}$ with $\mathbf{P}(\Omega_{x_0})=1$, and hence for all $\omega \in \Omega^*$ where $\Omega^* = \cap_{q \in \mathbf{Q}} \Omega_{x_0}$ has full measure. Then for all $\omega \in \Omega^*$ I can take a sequence $q_n \searrow Y(\omega)$ to obtain
$$
\mathbf{E}[f(\cdot,X(\cdot))\mid \mathscr{G}](\omega) \geq f(\omega,Y(\omega))
$$
where here we make use of the local boundedness of $x_0 \mapsto \partial_2 f(\omega,x_0)$ given to us by convexity, and the continuity of $x_0 \mapsto f(\omega,x_0)$ also given to us by convexity. I said like up in bold because I do not know that $\omega \mapsto \partial_2 f(\omega, x_0)X(\omega), \omega\mapsto \partial_2 f(\omega,x_0)$, and $\omega \mapsto f(\omega, x_0)$ are integrable, so I cannot just pull out the $\mathscr{G}$-measurable parts. Is there some way I can resolve this? EDIT: It may be useful to note that $f$ is actually $\mathscr{G}\otimes \mathscr{B}(\mathbf{R})$-measurable: define $f_n(\omega,x) := f(\omega, d_n(x))$ where $d_n(x) = \inf\{ \frac{k}{2^n} : \frac{k}{2^n} \geq x, k \in \mathbf{Z}\}$. Then $\{ f_n \in B \} = \cup_{\frac{k}{2^n}, k \in \mathbb{Z}}( \{\omega:f(\omega,\frac{k}{2^n}) \in B\} \times [\frac{k}{2^n},\frac{k+1}{2^n}))$. The $f_n$ are demonstrably $\mathscr{G} \otimes \mathscr{B}(\mathbf{R})$ measurable and $f_n \to f$ by continuity of $f$.","['probability-theory', 'measure-theory']"
1395215,Proof of the law of reflection without calculus,"I am working on some optimization problems, and I am aware of the method of proving that the "" angle of incidence equals the angle of reflection "" using Fermat's principle and calculus. However, my textbook suggests that there is a simple way to prove this without calculus, but I'm a little unsure about how to do this. I would appreciate any advice on how to proceed.","['physics', 'trigonometry']"
1395225,Show the locus of all points such that $x^2+y^2+z^2=1$ and $x^2-y^2-z=0$ is smooth (Implicit Function Theorem),"Let $\mathcal C$ be the locus of all point $(x,y,z) \in \mathbb R^3$ with 
  $$x^2+y^2+z^2=1 \text{ and } x^2-y^2-z=0.$$
  Show that $\mathcal C$ is a smooth curve in the following sense: For each point $p \in \mathcal C$, there exist open sets $U \subset \mathbb R$, $W \subset \mathbb R^3$ and a $\mathcal C^1$ map $f:U \to W$ such that $p \in W$ and $f(U)= \mathcal C \cap W$. My idea was to define a function $\Phi:\mathbb R^3 \to \mathbb R^2$ by $\Phi(x,y,z)=(x^2+y^2+z^2-1, x^2-y^2-z)$. Then $\Phi^{-1}(0)=\mathcal C$. Now I want to apply the Implicit Function Theorem but I run into a problem: Let $\phi_1$ and $\phi_2$ denote the coordinate functions of $\Phi$. Then $$\det \begin{bmatrix} \frac{\partial \phi_1}{\partial y} & \frac{\partial \phi_1}{\partial z} \\ \frac{\partial \phi_2}{\partial y} & \frac{\partial \phi_2}{\partial z} \end{bmatrix} = \det \begin{bmatrix} 2y & 2z \\ -2y & -1 \end{bmatrix} = 4yz-2y = 2y(2z-1). $$ So my determinant is zero when $y=0$ and when $z=\frac{1}{2}$ and I can't apply the Implicit Function Theorem at those points. I think there might be a way to use the Implicit Function Theorem twice to get two functions $g,h: \mathbb R \to \mathbb R$ such that $\Phi(x,g(x),h(x)) = 0$. Then I would be able to define $f:\mathbb R \to \mathbb R^3$ by $f(x) = (x, g(x), h(x))$. Is this possible? Or do I need to change my function $\Phi$?","['implicit-function-theorem', 'multivariable-calculus', 'real-analysis']"
1395251,"Proof of onto and one-to-one functions, composition","I want to prove this: Let $f: A \to B$ and $g: B \to C $ be functions. if $g \circ f$ is onto, and $g$ is one-to-one, then f is onto. Here is what I have done, can someone please verify my work: Let $y \in B$. And let $z = g(y) \in C$. Since $g \circ f$ is onto, there exists an $x \in A$ such that $g \circ f(x) = z$. So, we have, $g(f(x)) = z$. We also have, $g(y)=z$, hence $g(f(x)) = g(y)$. Since $g$ is one-to-one, we conclude that $f(x)=y$. Therefore, shown that for any $y \in B$, there is an $x \in A$ such that $f(x) = y$. Therefore, $f$ is onto.","['function-and-relation-composition', 'discrete-mathematics', 'functions']"
1395266,Show that $f$ is a decreasing function,It's given that $f(x)=\frac{1}{x^3}-x^3$ for $x>0$ show that $f$ is a decreasing function. My attempt $f'(x)=-3x^{-4}-3x^2$ $x^6=-1$ How to continue by my attempt ?,"['derivatives', 'calculus', 'functions']"
1395269,Average order of $\mathrm{rad}(n)$,"Let $\mathrm{rad}(n)$ denote the radical of an integer $n$, which is the product of the distinct prime numbers dividing n. Or equivalently, $$\mathrm{rad}(n)=\prod_{\scriptstyle p\mid n\atop p\text{ prime}}p.$$ Assume $\mathrm{rad}(1)=1$, so that $\mathrm{rad}(n)$ is multiplicative. I was wondering if one has a nice asymptotic formula for the sum $$\sum_{n\le x}\mathrm{rad}(n).$$
At first, I wanted to use the Wiener-Ikehara Theorem. Using Euler Product, we have 
\begin{align}
\begin{split}
R(s)&=\sum_{n\ge 1}\frac{\mathrm{rad}(n)}{n^s}=\prod_{p}(1+\frac{p}{p^s}+\frac{p}{p^{2s}}+\cdots)\\
&=\prod_{p}(1+\frac{p}{p^s}\frac{1}{1-p^{-s}})\\
&=\zeta(s)\prod_{p}(1+\frac{p-1}{p^s}).
\end{split}
\end{align}
However, the Wiener-Ikehara Theorem seems not to work here because the product part diverges when $s=1.$ Comparing term-wisely with the product and using $1<p-1<p$, we can get
$$\frac{\zeta(s)^2}{\zeta(2s)}<R(s)<\frac{\zeta(s)\zeta(s-1)}{\zeta(2s-2)}.$$ Moreover, if multiplicative function $\mathrm{core}(n)$ is defined to map positive integers ''n'' to square-free numbers by reducing the
exponents in the prime power representation modulo 2, or in formula 
: $$\mathrm{core}(p^e) = p^{e\mod 2}.$$ with $\mathrm{core}(1) =1 .$ Or equivalently, $$\mathrm{core}(p^{2k+1})=p,$$ $$\mathrm{core}(p^{2k})=1$$
Then we always have $$\mathrm{core}(n) \le \mathrm{rad}(n).$$
Since the Dirichlet generating function of $\mathrm{core}$ is
: 
\begin{align}
\begin{split}
C(s)&=\sum_{n\ge 1}\frac{\mathrm{core}(n)}{n^s}
=\prod_{p}(1+\frac{p}{p^s}+\frac{1}{p^{2s}}+\frac{p}{p^{3s}}+\frac{1}{p^{4s}}+\cdots)\\
&=\prod_{p}(1+\frac{\frac{p}{p^s}+\frac{1}{p^{2s}}}{1-\frac{1}{p^{2s}}})\\
&=\frac{\zeta(2s)\zeta(s-1)}{\zeta(2s-2)}.
\end{split}
\end{align} $$\frac{\zeta(2s)\zeta(s-1)}{\zeta(2s-2)}<R(s)<\frac{\zeta(s)\zeta(s-1)}{\zeta(2s-2)}$$
Here we may use the Wiener-Ikehara Theorem to derive asymptotic bounds. This was as far as I could work out.
Are there any results considering the average order of $\mathrm{rad}(n)$ or analytic expression of its Dirichlet series? Thanks.","['multiplicative-function', 'dirichlet-series', 'number-theory', 'analytic-number-theory', 'asymptotics']"
1395303,Intuition behind almost sure limit of $\frac{|S_n|}{n^{1/p}}$,"Suppose $X_i$'s are non-degenerate i.i.d. Then (1) If $E|X_1|^p=\infty$ we've $\limsup_{n\rightarrow \infty}  \frac{|S_n|}{n^{1/p}}=\infty$. And this is true $\forall p>0$ (2) However for $p=2$ we can say more. For every choice of centring constant $\{C_n\}$ we have $\limsup_{n\rightarrow \infty}  \frac{|S_n-C_n|}{\sqrt{n}}=\infty$. i.e. Does not matter whether $E(X_1^2)<\infty$ or not! I know the proof but whenever I look at them they does not stop surprising me as if something's wrong in there(in (2)). Is there any way to visualize what's going on here? Something related to laws of iterated logarithm (where we assumed finite $2^{nd}$ moments)? Would you please shed some light on it or/and suggest some reading materiel? Thank you,","['probability-theory', 'probability', 'law-of-large-numbers']"
1395306,"What is the probability of rolling a 6-sided die 5 times, and getting at least 3 in a row?","I had been working on this problem, and ran into trouble because I couldn't easily use the ""find the opposite probability and subtract from one"" trick. So for example I think I can find the probability of getting at least two in a row rolling a die 5 times, by finding the probability of getting no duplicates at all and then subtracting from one to find the opposite: ( 1 - (5/6)^4 ) But how to find the probability of a sequence of at least three? The extension of the problem is to write a formula generalizable to the number of trials, number of possible outcomes per trial, and the length of the repeated sequence. I like working on this on my own so if you can just give a little hint or guidance I'd appreciate it very much!","['probability', 'discrete-mathematics']"
1395358,Logic question requiring axiom of choice,"Predicting Real Numbers Regarding the above question, the solutions require creating classes of sequences with representative sequences. How are those sequences constructed? How is it possible to generate a ""list"" of the classes and representatives if the sequences are made of real numbers which implies the set of sequences is uncountable? Thanks in advance for any answers.","['infinity', 'elementary-set-theory', 'logic']"
1395359,Degree of a projective variety,"Let $X \subset \mathbb{P}^n$ be a projective variety of dimension $k <n$. By an equivalent definition of dimension, $k$ is the smallest integer such that there exists an open set of $G(n-k-1,n)$, i.e. an open set of $(n-k-1)$-planes of $\mathbb{P}^n$ that are disjoint from $X$. In other words, the general $(n-k-1)$-plane does not meet $X$. Question 1: How can we show that there exists an open set of $G(n-k,n)$, such that every $(n-k)$-plane in that open set meets $X$ in zero dimension? Question 2: Taking a step further, how can we show that the number of points that the general $(n-k)$-plane (of Question 1) meets $X$ is constant? This is known as the degree of $X$. PS: I am interested in arguments making use of basic principles rather than invoking results from intersection theory. I am aware that if we intersect $X$ with an $(n-1)$-plane that meets $X$ but does not contain it, then the dimension of the intersection is precisely $k-1$. Now, an $(n-k)$-plane is the intersection of $k$ $(n-1)$-planes and so i can intuitively see the existence of the required open set of Question 1. But how to establish this rigorously? Many thanks.",['algebraic-geometry']
1395387,Possible ways to induce norm from inner product,"Let $ S $ be a normed vector space (over $\mathbb{R}$, say, for simplicity) with norm $ \lVert\cdot\rVert$. Can this norm be induced from inner product only through $\lVert \cdot \rVert = \sqrt{\langle \cdot, \cdot \rangle}$ ? As to prove the if part of ""A norm is induced by inner product iff the norm satisfies parallelogram equality"", $\lVert \cdot \rVert = \sqrt{\langle \cdot, \cdot \rangle}$ is used.","['inner-products', 'functional-analysis', 'normed-spaces']"
1395413,Is it possible to construct a smooth curve with fractional Hausdorff dimension?,"It is known that fractal curves have fractional Hausdorff dimension. These curves are not smooth and have undefined length. However, is the converse true? If a curve has a fractional Hausdorff dimension, then must it be
  non-smooth/not differentiable?","['dimension-theory-analysis', 'differential-geometry', 'fractals', 'general-topology']"
1395420,"If $x,y,z>0$ and $xyz=32,$ Then the minimum of $x^2+4xy+4y^2+4z^2$ is","If $x,y,z$ are positive real no. and $xyz= 32\;,$ Then Minimum value of $$x^2+4xy+4y^2+4z^2$$ is $\bf{My\; Try::}$ Here I have Used $\bf{A.M\geq G.M}$ Inequality So $$\displaystyle \frac{x^2+4xy+4y^2+4z^2}{4}\geq \left(x^3\cdot y^3\cdot z^2\right)^{\frac{1}{4}}\;,$$ But I did not How can I solve it Help me, Thanks","['optimization', 'algebra-precalculus', 'inequality']"
1395461,"How to choose point and line thorough it, such that rotating and using points as pivots, it will touch all infinitely many times?","Suppose that you mark a finite collection of points on an infinite plane in such a way that you cannot draw a straight line through any three marked points. We define a windmill to be the following process: draw an infinite straight line on the plane through exactly one of the marked points. Then rotate the line clockwise using the chosen marked point as a pivot until the moving line hits another marked point. At that instant, the new marked point takes over as a pivot, and the line continues to rotate clockwise. This process continues, with new pivots taking over from time to time. Show that it is possible to select one of the marked points, and choose a starting line through that point at a particular angle, so that the resulting windmill uses every marked point as a pivot on infinitely many occasions.","['contest-math', 'geometry']"
1395473,Linear combination of i.i.d random variables,"We say that a random variable $X$ satisfies the $(\alpha,\beta)-$condition for some $\alpha>0$ and $\beta>0$ if
$$\mathbb{P}(|X|<t)<\alpha t\text{ and }\mathbb{P}(|X|>t)<e^{-\beta t}\quad\forall t>0$$ Assume $X_1,\dots,X_m$ are i.i.d random variables satisfying the $(\alpha,\beta)-$condition for some $\alpha>0$ and $\beta>0$. Let $X=(X_1,\dots,X_m)$ and $x_0\in\mathbb{R}^m$ with $\Vert x_0\Vert_2=1$. Consider the random variable $Y=\langle X,x_0\rangle$. I am interested whether $Y$ satisfies the $(\alpha',\beta')-$condition for some $\alpha'>0$ and $\beta'>0$, i.e. 
$$\mathbb{P}(|Y|<t)<\alpha' t\text{ and }\mathbb{P}(|Y|>t)<e^{-\beta' t}\quad\forall t>0$$ Intuitively I felt the answer should be positive, but I am having difficulty to prove (or disprove) the statement. Any help is appreciated.","['probability', 'statistics', 'random-variables', 'measure-theory']"
1395474,"reflexive, symmetric, and transitive relations proof","Let $A = \{1, 2, 3, ... , n\}$ where $n$ is a positive integer. Let $F$ be the set of all functions from $A$ to $A$. Let $R$ be the relation on $F$ defined by: for all $g, f \in F, fRg$ if and only if $f(i) \lt= g(i)$ for some $i \in A.$ Let $I$ A : $A \to A$ be the identity function on $A$ defined by $I$ A $(x)$ = $x$ for all $x \in A$. a) Is $R$ reflexive? symmetric? transitive? Prove your answers. b) How many elements $f \in F$ are there so that $I$ A $Rf$? Explain. c) How many elements $f \in F$ are there so that $fRI$ A ? Explain. d) How many elements of $f \in F$ are there so that $fRI$ A and $f$ is onto? Explain. My attempt to answer: a) We know a relation $R$ is reflexive iff for all $x\in A$, $xRx$ We know a relation $R$ is symmetric iff for all $x1, x2\in A$, if $x1Rx2$ then $x2Rx1$ We know a relation $R$ is transitive iff for all $x, y, z\in A$, if $xRy$ and $yRz$ then $xRz$ Now, using these definitions, we should be able to answer a). $R$ is reflexive: Let $f\in F$. Then $f(1)\leq f(1)$, so $fRf$. If $n=1$ then $F$ contains exactly one element and it is obvious that in that case $R$ is symmetric and transitive. This as a consequence of the fact that it is reflexive. So let us assume that $n>1$ from here. $R$ is not symmetric: Let $f\in F$ be prescribed by $i\mapsto1$ and $g\in F$ by $i\mapsto2$. Then $fRg$ but not $gRf$. $R$ is not transitive: Let $f,g,h\in F$ with $f(1)=f(2)=2$, $g(1)=2\wedge g(2)=1$ and $h(1)=h(2)=1$. Then $fRg\wedge gRh$ but not $fRh$. Now b) We know that Identity function returns the same values as its parameter, right? So, if you pass f(1) = 2, then identity function of f I A (2) = 1 so the question is how many elements $f \in F$ are there so that $fRI$ A ? Since, the I A is defined as: I A (x) = x, this means there are n number of elements?",['discrete-mathematics']
1395476,find $\lim_{n\to \infty}(\log(1+1/n))^{1/n}$,"Question is to find the limit of following as n tends to infinity : $\lim_\limits{n\to \infty}(\log(1+1/n))^{1/n}$ my attempt: took expansion of  $\log(1+x)$
so $\lim_{n\to \infty}(\frac{1}{n^{1/n}}(1-\frac{1}{2n}+\frac{1}{3n^2}....)^{1/n}) $ is of form $1^0$ which is not indeterminate and hence limit is 1. is it right?","['calculus', 'limits']"
1395512,Determine all functions satisfying $f\left ( f(x)^{2}y \right )=x^{3}f(xy)$,"Denote by $\mathbb{Q}^{+} $  the set of all positive rational numbers. Determine all functions $f:  \mathbb{Q}^{+} \rightarrow \mathbb{Q}^{+}$ which satisfy the following equation for all $x,y \in \mathbb{Q}^{+}:$ $$f\left ( f(x)^{2}y \right )=x^{3}f(xy).$$ What I have tried is ...
 By substituting $y=1$, we get $$f\left ( f(x)^{2} \right )=x^{3}f(x).$$ Then, whenever $f(x)=f(y)$, we have $$x^{3}= \frac{f\left ( f(x)^{2} \right )}{f(x)}= \frac{f\left ( f(y)^{2} \right )}{f(y)}=y^{3}$$ which implies $x=y$, so the function $f$ is injective. and I think I'm stuck here, any help will be appreciated, thanks. Note that it's an Olympiad question (IMO2010 SL, Problem A5).","['rational-numbers', 'contest-math', 'algebra-precalculus', 'functional-equations']"
