question_id,title,body,tags
4680350,Is the Gauss Divergence theorem applicable when the Divergence of a vector field is a dirac delta function?,"(This question is motivated by electrostatics) In electrostatics one comes across discontinuous vector fields all the time, for example, the vector field $ \vec E=\frac{\vec r}{r^3} $ which has a missing point discontinuity at $\vec r=0$ , whose divergence $\nabla\cdot \vec E$ is the dirac delta distribution (to be precise, $\vec \nabla \cdot \vec E=4\pi\delta(\vec r)$ , using test functions and so on). It is not clear to me how one can assert that the volume integral of this dirac delta distribution, $\vec \nabla \cdot \vec E$ , is equal to the surface integral of the field, which is discontinuous. Yet, physics textbooks still apply the Gauss Divergence theorem, to say that $\iiint_{V}\nabla\cdot\vec E d\tau=\iint_{S}\vec E\cdot\hat ndS$ , where V contains the singularity $\vec r =0$ , but don't explain why one is allowed to do this, when the vector field is clearly discontinuous in the domain in which the integral is being done. Alas, the integral $\iint_{S}\vec E \cdot \hat n dS= \iint_S\frac{\hat r \cdot \hat n dS}{r^2}$ comes out to be $4\pi$ , but my question still holds. Now, I am aware that the result for this case comes out to be exactly the same, $4\pi$ , through different calculations, but is this a coincicende? More precicely, given a vector field $\vec E$ which is defined , continuous and differentiable everywhere except at $\vec r=0$ , whose divergence $\vec \nabla \cdot \vec E$ comes out to be the dirac delta distribution, can we apply gauss divergence theorem in such a case (case where we include the origin)?","['divergence-theorem', 'physics', 'multivariable-calculus', 'dirac-delta']"
4680354,"Let $a_1 , a_2, a_3$ be a harmonic progression with $a_1 =5$ and $a_{20} =25$. Then the least positive integer for which $ a_n \lt 0$ is?","Let $a_1 , a_2, a_3$ be a harmonic progression with $a_1 =5$ and $a_{20} =25$ . Then the least positive integer for which $ a_n \lt 0$ is? My attempt:-
As This is a harmonic progression, so the denominator  of the first term  is $a=\frac{1}{5}$ and the denominator of $a_{20}=a+19d=\frac{1}{25}$ solving the above linear equations we find that $d=\frac{-4}{475}$ so finding when the denominator will be zero we get $n=23.75$ , as the closest integer is 24, the HP becomes negative when $n=24$ However, my book says that the answer is actually $25$ and I'm not sure I understand how. Where Have I gone wrong? Thanks in advance for the help! Source:- JEE Advance , Paper 2,2012","['contest-math', 'harmonic-numbers', 'algebra-precalculus', 'sequences-and-series']"
4680361,Solvable-by-finite groups,"I am trying to prove this:
Let $G$ be a finite-by-solvable group, i.e. $G$ has a normal subgroup $N$ that is finite with $G/N$ solvable. Prove that $G$ is solvable-by-finite, i.e., $G$ has a solvable normal subgroup $K$ such that $G/K$ is finite. My attempt: There exists a natural map $\psi$ from $G$ to Aut $N$ that takes $g\in G$ to the automorphism of $N$ that’s ‘conjugation by g’. Now, the kernel $K$ of this $\psi$ is $C_G(N)$ , the centralizer of $N \in G$ . What is $K\cap N$ then?
Considering $N$ is finite, we have $G/K$ is also finite. I want to show that $K$ is solvable but I  am stuck here.
Any help would be appreciated.","['finite-groups', 'quotient-group', 'normal-subgroups', 'group-theory', 'solvable-groups']"
4680367,"Wrong but fun and/or useful ""proofs"" in linear algebra","I wonder if anyone can share wrong but useful and/or fun proofs in linear algebra. It can not only be fun, but also useful for someone who learns the subject. You are welcome to add explanations but please hide them in order not to spoil the fun. Let me start from my own ""proof"" that every square matrix has zero determinant (I am sure that ""proof"" was discovered many many times). ""Theorem"". Every square matrix $A$ over any field $K$ has zero determinant. ""Proof"". If $A$ has two equal rows or columns we are done. Otherwise, we will construct them. First let add all the rows except the first row to the first row. Next let add all the rows except the last row to the last row. Clearly, now first and last row are equal since both or them are sum of every row in $A$ , so $\det(A) = 0$ . $\Box$ After we added rows to the first row of $A$ it changed, but the ""proof"" assumes that the first row is the same.",['linear-algebra']
4680383,"Recursive formula for $\int_0^1 x^n (x + a)^{-1} \,dx$",I'm stuck on a textbook exercise that asks me to define the integral $I_n$ in the title in terms of $I_{n-1}$ . The only technique I'm aware of for determining integral recurrence relations is integration by parts and that does not seem to work out here no matter how I pick $u$ and $v$ . Is there another technique I need to apply or am I missing something?,"['integration', 'analysis']"
4680500,Find the tangent between two points,"Let $f(x) = x^3$ . Show that for every point $P = (x_0, y_0) \in\mathbb R^2$ there is a tangent to the graph of $f(x)$ that passes through $P$ . I said in order for this to be true $f'(x)$ needs to be defined for all $f(x)$ and for all $x$ 's. If this is true then we will have a value for all $f'(x)$ . This means that $f(x)$ will be able to give us all types of straight lines that both grows and decreases. So I differentiated $f(x)$ to $3x^2$ and here we can see that $f'(x)$ is defined for all x's and thus there is a line for every $(x_0, y_0)$ that passes through the point $p$ . But in the answers they used mean value theorem etc, but I was wondering if my explanation was totally wrong because I got $0$ point on it.","['tangent-line', 'calculus', 'solution-verification', 'algebra-precalculus', 'derivatives']"
4680506,"What definition of ""nearly orthogonal"" would result in ""In a 10,000-dimensional space there are millions of nearly orthogonal vectors""?","Quanta Magazine's April 13, 2023 A New Approach to Computation Reimagines Artificial Intelligence starts with: By imbuing enormous vectors with semantic meaning, we can get machines to reason more abstractly — and efficiently — than before. Later on, during the explanation are the paragraphs: The vectors must be distinct. This distinctness can be quantified by a property called orthogonality, which means to be at right angles. In 3D space, there are three vectors that are orthogonal to each other: One in the x direction, another in the y and a third in the z. In 10,000-dimensional space, there are 10,000 such mutually orthogonal vectors. But if we allow vectors to be nearly orthogonal, the number of such distinct vectors in a high-dimensional space explodes. In a 10,000-dimensional space there are millions of nearly orthogonal vectors. I remember reading previous questions here with high dimensions and dot products are discussed and seeing comments about how easy it is to get very small or even zero dot products in high dimensions, but I've never worked outside of one, two and three dimensional problems. Question: What definition of ""nearly orthogonal"" would result in ""In a 10,000-dimensional space there are millions of nearly orthogonal vectors""? Would it be for example dot product 1 smaller than some number like 0.1? 1 of the presumably normalized vectors","['inner-products', 'linear-algebra', 'geometry']"
4680509,Proof for an ultrafilter [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last year . Improve this question The question is as follows: Let $A,B$ be sets and $f: A \to B$ be a function. Let $U$ be an ultrafilter on the set $A$ . Prove that the set ${\{C \subseteq B : f^{-1}C \in U}\}$ is an ultrafilter on $B$ . Recall that $f^{-1}C = {\{a \in A : f(a) \in C}\}$ . I have proven that the set is a filter but am stuck on proving the ""ultra""part.","['elementary-set-theory', 'filters', 'set-theory']"
4680560,Apostol: How to use Stokes's theorem to compute $\int_C ydx+zdy+xdz=\pi a^2\sqrt{3}$ by using a portion of a sphere as the surface?,"The following is a problem in Apostol's Calculus , Vol II, section 12.13 Consider the line integral $$\int_C ydx+zdy+xdz=\pi
 a^2\sqrt{3}\tag{1}$$ where $C$ is the curve of intersection of the sphere $$x^2+y^2+z^2=a^2\tag{2}$$ and the plane $$x+y+z=0\tag{3}$$ Use Stokes' theorem to show that the line integral (1) has the given
value and explain how to traverse $C$ to arrive at the given answer. Solving (3) for $z$ $$z=-x-y\tag{4}$$ and subbing into (2) $$x^2+y^2+(-x-y)^2=a^2\tag{5}$$ we obtain $$x^2+xy+y^2=\frac{a^2}{2}\tag{6}$$ This equation represents the values of $x$ and $y$ of points $(x,y,z)$ that are on the intersection $C$ . Here is a plot of these points This ellipse is the projection of $C$ onto the xy-plane. Because the problem statement says to use Stokes' theorem, at this point I tried to compute the surface integral $$\iint\limits_S (\text{curl}F\cdot \hat{n})dS\tag{7}$$ $$=\iint\limits_S \text{curl}F(r(u,v))\cdot N(u,v)dudv\tag{8}$$ where $$N(u,v)= \frac{\partial r(u,v)}{\partial u}\times \frac{\partial r(u,v)}{\partial v}\tag{9}$$ is the fundamental vector product for a parametrization $r(u,v)$ of the surface $S$ (which is defined on some region $T$ in the uv plane that is the interior of a Jordan curve, the image under $r(u,v)$ of which is $C$ ), and $$F(x,y,z)=y\hat{i}+z\hat{j}+x\hat{k}\tag{10}$$ My question is about a non-optimal choice of this surface. Ideally, to facilitate calculations, we would use the plane in between $C$ as our surface. But I would like to use the portion of the sphere that has $C$ as its boundary. The sphere can be parametrized by spherical coordinates $$r(\phi,\theta)=a^2(\cos{\theta}\sin{\phi}\hat{i}+\sin{\theta}\sin{\phi}\hat{j}+\cos{\phi}\hat{k})\tag{11}$$ which gives us $$N(\phi,\theta)=\frac{\partial r(\phi,\theta)}{\partial \phi}\times \frac{\partial r(\phi,\theta)}{\partial \theta}=a^2(\sin^2{\phi}\cos{\theta}\hat{i}+\sin{\theta}\sin^2{\phi}\hat{j}+\cos{\phi}\sin{\phi}\hat{k})\tag{10}$$ and since we are interested only in the values of $\theta$ and $\phi$ that correspond to values on the surface that is above the ellipse, we can sub in the parametrization in (11) into the ellipse which should give us $\phi$ as a function of $\theta$ so that we know the limits of integration in the surface integral $$x^2+xy+y^2=\frac{a^2}{2}\tag{11}$$ $$a^2\cos^2{\theta}\sin^2{\phi}+a^2\sin{\theta}\cos{\theta}\sin^2{\phi}+a^2\sin^2{\theta}\sin^2{\phi}=\frac{a^2}{2}\tag{12}$$ $$\sin^2{\phi}=\frac{1}{2(1+\sin{\theta}\cos{\theta}})\tag{13}$$ $$\sin{\phi}=\frac{1}{\sqrt{2(1+\sin{\theta}\cos{\theta}})}\tag{14}$$ $$\phi(\theta)=\sin^{-1}{\left (\frac{1}{\sqrt{2(1+\sin{\theta}\cos{\theta}})}\right )}\tag{15}$$ Finally, $$\text{curl}F(x,y,z)=-\hat{i}-\hat{j}-\hat{k}\tag{16}$$ and the surface integral becomes $$\iint\limits_S (\text{curl}F\cdot \hat{n})dS\tag{17}$$ $$=\int_0^{2\pi}\int_0^{\phi(\theta)} \langle -1,-1,-1\rangle\cdot \langle a^2\sin^2{\phi}\cos{\theta},a^2\sin{\theta}\sin^2{\phi}, a^2\cos{\phi}\sin{\phi}\hat{k} \rangle d\phi d\theta\tag{18}$$ Should we expect (18) to equal $\pi a^2\sqrt{3}$ ? When I try to compute this in Maple, I don't really obtain the correct result.","['multivariable-calculus', 'stokes-theorem']"
4680657,Positive integer matrices satisfying $A^3 + B^3 = C^3$,"From the 3rd edition of the book ""The Linear Algebra a Beginning Graduate Student Ought to Know"" by Jonathan S. Golan, we find the following exercise (number 475) under chapter 9: ""Find infinitely-many triples $(A, B, C$ ) of nonzero matrices in $M_{3×3}(\mathbb{Q})$ , the entries of which are nonnegative integers, satisfying the condition $A^3 + B^3 = C^3.$ "" Now we if understand ""non-negative integers"" to include $0$ , then easily we can take $A$ , $B$ and $C$ to be diagonal matrices such that: $$ A =
\begin{pmatrix}
a & 0 & 0 \\
0 & 0 & 0 \\
0 & 0 & 0 \\
\end{pmatrix}
, B = 
\begin{pmatrix}
0 & 0 & 0 \\
0 & b & 0 \\
0 & 0 & 0 \\
\end{pmatrix},
C = \begin{pmatrix}
a & 0 & 0 \\
0 & b & 0 \\
0 & 0 & 0 \\
\end{pmatrix}$$ However, if we interpret the term ""non-negative"" to mean ""strictly positive"" (s.t. a positive matrix is defined in the sense given in the entry: https://en.wikipedia.org/wiki/Nonnegative_matrix ), the question becomes harder... I suspect that the equation never holds, not only in the case of $n=3$ , but for all positive integers $n$ . I.e. we cannot find positive matrices $A,B,C$ in $M_{n×n}(\mathbb{Q})$ such that $A^k + B^k = C^k.$ where $k>2$ is an integer."" I conjecture this because a few constructions I tried for finding solutions all failed, and I imagine a way to prove that it is impossible would be by contradiction... i.e. show that any valid triplet would imply a rational/integer solution to the integer equation $a^k + b^k = c^k$ (where $a,b,c \in \mathbb{Q}$ ) which can't exist by Fermat's last theorem. However, I haven't found a promising trick yet and I wonder if the conjecture, if true, can be proven so easily, be it via contradiction or via other means...","['matrices', 'matrix-equations', 'linear-algebra']"
4680659,Complex conjugate by complex integration,"By Cauchy's Theorem we have $
f(a)=\frac{1}{2\pi i}\int_{\gamma}\frac{f(w)}{w-a}dw
$ where $\gamma$ is the path $\gamma(t)=b+re^{it},~t\in[0,2\pi],$ $a\in B_r(b)$ where $B_r(b)$ is the closed ball of radius $r$ with center $b,$ fully lying in the domain of $f.$ Now, in case of $f(z)=\bar{z},$ we can't apply Cauchy's Theorem as $f$ is not an analytic function. So my doubt is whether we can say $
   \bar{a}=\frac{1}{2\pi i}\int_{\gamma}\frac{\bar{z}}{z-a}dz
$ for the path $\gamma$ with center different from $a.$ Any counter example or suggestions or hints is fully appreciated. Thanks in advance. EDIT: There was a mistake in the question from my side. I have edited the question. This is what I tried so far. $\frac{1}{2\pi i}\int_{\gamma}\frac{\bar{z}}{z-a}dz\\
=\frac{1}{2\pi i}\int_{0}^{2\pi}\frac{(\bar{b}+re^{-i\theta})ire^{i\theta}d\theta}{(b-a)+re^{i\theta}}\\
=\frac{\bar{b}}{2\pi i}\int_0^{2\pi}\frac{ire^{i\theta}d\theta}{b-a+re^{i\theta}} +\frac{1}{2\pi}\int_0^{2\pi}\frac{r^2d\theta}{b-a+re^{i\theta}}\\
=\frac{\bar{b}}{2\pi i}\int_{\gamma}\frac{zdz}{z+b-a} +\frac{r^2}{2\pi}\int_0^{2\pi}\frac{d\theta}{b-a+re^{i\theta}}\\
=\bar{a}(b-a)+\frac{r^2}{2\pi}\int_0^{2\pi}\frac{d\theta}{b-a+re^{i\theta}}
$ How to proceed further?","['complex-analysis', 'complex-integration', 'cauchy-integral-formula', 'analysis']"
4680699,Proving $\lim_{x\to\infty}\left(\frac{\sin(e^{-x})}{x^{p-2}(x-1)^q}\right) = 0$,"How can I prove the following limit for every $p,q \in \mathbb R$ ? $$\lim_{x\to\infty}\left(\frac{\sin(e^{-x})}{x^{p-2}(x-1)^q}\right) = 0$$ For example, I tried using absolute value together with the squeeze theorem, while I believe it might work if $p-2+q > 0$ it would fail otherwise. Any suggestions, please?","['limits', 'calculus']"
4680744,A special point of a triangle related to the nine point circle,"Playing with the nine point circle in GeoGebra, I have ""discovered"" a special point. I assume it is a well known point, but I cannot find its name and properties. Description: Let $ABC$ be a triangle with sides $a,b,c$ , $M_a, M_b, M_c$ are the midpoints of $a,b,c$ , $H_a,H_b,H_c$ the feet of the altitudes, and $O$ the center of the nine point circle of $ABC$ . Let $N_a, N_b, N_c$ be the reflections of $H_a, H_b, H_c$ across $O$ (lying on the nine point circle). Then the three straight lines connecting $A,B,C$ and $N_a, N_b, N_c$ intersect at a point $N$ . Using online geometric tools it is easy to check the following properties of the point $N$ : $N$ exists if only $ABC$ is not a right triangle $N$ coincides with $O$ if only $ABC$ is an equilateral triangle $N$ coincides with one of $A$ , $B$ , or $C$ if only the corresponding angle is $45^\circ$ or $135^\circ$ $N$ belongs to either the area of $ABC$ , or one of the opposite angles of $A$ , $B$ , or $C$ $N$ never lies on a side of $ABC$ , except for the vertices $A$ , $B$ , and $C$ Questions: How to prove the three straight lines connecting $A,B,C$ and $N_a, N_b, N_c$ intersect at a single point? What is the name and what are the properties of the point $N$ ?","['euclidean-geometry', 'triangles', 'triangle-centres', 'geometry']"
4680750,"Is it possible when multiplying two polynomials that, after the collection of similar (like) terms, all terms except one vanish?","I am working with an 8th grader. In their book, Algebra , Chen and Gelfand ask this problem: Problem 97 . Is it possible when multiplying two polynomials that, after the collection of similar (like) terms, all terms except one vanish? (Do not count the case when each of the polynomials has only one monomial.) A similar question (also from the same book) was asked a while ago. I guess the answer to this one is similar to that one. I tried to explain it by considering two polynomials $A: a_0 + a_1x$ and $B: b_0 + b_1x$ and then considering the cases where the product has only one term (either $a_0b_0$ , $(a_0b_1 + a_1b_0)x$ , or $a_1b_1x^2$ ) without making both $A$ and $B$ monomials or either of them the zero polynomial (that is at least three of $a_0, a_1, b_0, b_1$ are nonzero). In each of the cases, we showed that it is impossible to do so. Is our answer correct? I guess the result can be generalized for polynomials in single variable (assuming that the answer is correct) using the standard form: $\displaystyle \sum_0^n a_ix^i \cdot \sum_0^m b_ix^i$ .","['algebra-precalculus', 'polynomials']"
4680760,What is the maximum value of the product of the length of a side and the opposite the angle of a triangle?,"WLOG, let $a$ be the side of a triangle inscribed in a unit circle and $A$ be the opposite angle. Experimental data shows that there is a constant $C \approx 3.6394$ such that $aA \le C$ . Question : What is the maximum value of $aA$ ? Progress : Trivially, $\max \left (aA\right) \ge \pi$ . This follows from the case when the triangle is a right triangle in a semi-circle so that $a = 2$ and $A = \frac{\pi}{2}$ . A slightly less trivial bound is $\max \left (aA\right) \ge \left( \frac{2\pi}{\sqrt{3}}\right) \approx 3.6276$ which very close to the experimentally observed maxima. This corresponds to the case when we have a triangle whose angles are $\left(\frac{2\pi}{3}, \frac{\pi}{6}, \frac{\pi}{6}\right)$ .","['euclidean-geometry', 'geometry', 'maxima-minima', 'triangles', 'inequality']"
4680796,Computing a Fourier transform and imaginary part dependence,"I would like to compute the following Fourier transform: $$\int_{-\infty}^\infty (1 + (x+it)^2)^{-s} e^{i x \xi} dx$$ and to explicitly see the dependence in $s$ , in particular the imaginary part. Since the variables are nonreal, I am not so sure what kind of change of variables can be done.","['integration', 'complex-analysis', 'fourier-analysis', 'analysis']"
4680798,"Find the presentation for the kernel of a map from $G=\langle a,b,c\mid aba=bab,bc=cb\rangle$ to $\mathbb{Z}$.","I want to compute the presentation for the kernel of $f:G\to(\mathbb{Z},+)$ given by $f(a)=f(b)=0$ and $f(c)=1$ , where $G=\langle a,b,c\mid aba=bab,bc=cb\rangle$ . It is easy to see that $a^{c^i}:=c^iac^{-i}\in\ker(f)~\forall~i\in\mathbb{Z}$ , so we can expect to have $\ker(f)$ generated by $\lbrace b,a^{c^i}\rbrace_{i\in\mathbb{Z}}$ . Hence, I claim that the kernel is: $$\langle b,a^{c^{i}},i\in\mathbb{Z}\mid a^{c^{i}}ba^{c^{i}}=ba^{c^{i}}b,i\in\mathbb{Z}\rangle$$ But I dont know whether this is right or not. It seems obvious that the kernel is generated by those elements, since every element $w\in\ker(f)$ I've tried can be obviously written as a product of those elements, however I can't prove it. Any help will be appreciated.","['group-homomorphism', 'geometric-group-theory', 'group-theory', 'combinatorial-group-theory']"
4680801,Two matrices $A$ and $B$ with $AB+BA=0$,"Question: There are two matrices $A$ and $B$ of order $3\times3$ with $AB+BA=0$ , then is it necessary that $AB=0$ ? I tried this problem but couldn't reach any conclusive answer. I didn't see any reason for $AB=0$ , then I tried to get some counterexample. I couldn't find it. Please give me some counterexample if it exists. Also, please tell me how you reached there? I suppose it is not just a matter to attempt with two matrices by trial only. There should be some thought process to find such matrices. In case if you find $AB=0$ , please prove it. Thank you.","['matrices', 'linear-algebra']"
4680861,Limit of quotient in the number of combinatorial sequences involving Fibonacci numbers,"Let's call $a_n$ the number of sequences of length $n$ of $\{0,1,2,3,4\}$ . Let $x_k$ denote the kth digit in the sequence ( $k\in\{1,2,...n\}$ ). We want this sequence to be 'alternating' which in this case means: $$
\begin{align}
\\x_k\in \{1,3\} \implies x_{k+1} \notin \{1,3\}
\\x_k\in \{2,4\} \implies x_{k+1} \notin \{2,4\}
\\x_k = 0 \implies x_{k+1} \neq 0
\end{align}
$$ i.e. A 0 cannot be followed by a zero, an even digit (greater than 0) cannot be followed by another even digit and an odd digit cannot be followed by another odd digit. I want to find $\lim_{n\to\infty}{\frac{a_{n+1}}{a_n}}$ If there are no zeros, $a_n = 2^{n+1}$ because we can choose 4 digits in the first position and then 2 in each subsequent position. If we add a zero in any position except the first or last the number of sequnces is the same, this is because we split the sequence into two independent ones of lengths $k$ and $n-k-1$ , giving us $2^{k+1}\cdot 2^{n-k}=2^{n+1}$ . Thus we need to count the number of ways to place 0 and deal with the edge cases. For $n$ available positions the number of ways to place zeros without any two being adjacent is equal $F_{n+2}$ , which is the n+2th Fibonacci number. Thus to find all sequences we split the problem into 4 cases: Sequences that don't start or end in 0 Sequences that start but don't end in a 0 Sequences that end but don't start in a 0 Sequences that both start and end in a zero For 1. for a sequence of length $n\geq 3$ we get $2^{n+1}F_n$ . Because we can place a zero in all but 2 positions, let's call this count of sequences $b_n$ . For 2. and 3. is the same as above but we append a 0 and the beginning or end, so we get $2b_{n-1}=2\cdot2^{n}F_{n-1}$ . For 4. we append a zero at both ends so we get $b_{n-2}=2^{n}F_{n-1}$ From this I concluded that: $$
\lim_{n\to\infty}{\frac{a_{n+1}}{a_n}}=\lim_{n\to\infty}{\frac{b_{n+1}+2b_n+b_{n-1}}{b_{n}+2b_{n-1}+b_{n-2}}}=\lim_{n\to\infty}{\frac{2^n(4F_{n+1}+4F_n+F_{n-1})}{2^{n-1}(4F_n+4F_{n-1}+F_{n-2})}=\lim_{n\to\infty}{\frac{8F_{n+1}+8F_n+2F_{n-1}}{4F_n+4F_{n-1}+F_{n-2}}}}
$$ Writing this out with the closed form formula for Fibonacci numbers leads me to believe that I either do not know of a technique to solve such a limit or that there is a mistake in the combinatorial argument.","['limits', 'combinatorics', 'discrete-mathematics']"
4680887,"Given the circumscribed circle diameter and the number of points of a regular polygon, what is its side length?","Is it possible to determine the side length of a regular polygon if you know only the number of points it has, and the ""width"" (or possibly more geometrically accurately, the circumscribed circle diameter) of the shape? The application is that I want to draw different shapes (i.e., with differing numbers of vertices) but I want each of them to have the same width, so I set constant the width of the shape, but new need to calculate the side length.","['trigonometry', 'geometry', 'polygons']"
4680889,Convergence in distribution of empirical cdf almost surely.,"Given i.i.d. random variables $\{X_n\}$ , define the empirical cdf $$ \hat{F}_n(\omega, x) = \frac{1}{n} \sum_{i = 1}^n \mathbf{1}_{X_i(\omega) \leq x}$$ where $\omega \in \Omega$ and $x \in \mathbb{R}$ . Show that $\hat{F}_n(\cdot, \cdot) \overset{d}{\to} F$ as $n \to \infty$ , i.e. $$ P\left(\left\{\omega : \lim_{n \to \infty} \hat{F}_n(\omega, x) = F(x)\text{ for every } x \in C(F)\right\}\right)=1$$ I know that each $\hat{F}_n(\cdot, x)$ is a random variable, and each $\hat{F}_n(\omega, \cdot)$ is a cdf. Furthermore, for fixed $x \in \mathbb{R}$ , we have $\hat{F}_n(\cdot, x) \overset{as}{\to} F$ by the Strong Law of Large Numbers; thus, each $$ P\left(\left\{\omega : \lim_{n \to \infty} \hat{F}_n(\omega, x) = F(x)\right\}\right) := P(A_x) = 1. $$ The problem is extending this to almost all $x$ . If I only had to deal with countably many $x$ , then I could just take a countable union of $A_x^c$ and obtain the result. It has been hinted that the problem can be reduced to this case, but I am still unable to figure out how.","['probability-limit-theorems', 'probability-distributions', 'probability-theory', 'probability', 'random-variables']"
4680917,Are the columns of a random Toeplitz Matrix linearly independent?,"Consider a Toeplitz matrix $T \in \mathbb{R}^{n \times p}$ with randomly independently generated entries and $n < p$ . The entries of the Toeplitz matrix are generated by a continuous random variable.
Now, let's take $n$ columns $T_1, \dots , T_n$ of $T$ . Are $T_1, \dots, T_n$ linearly independent with probability 1 for any such selection $T_1, \dots , T_n$ ?","['toeplitz-matrices', 'linear-algebra', 'probability-theory']"
4680919,The degree of a meromorphic form in a genus $g$ Riemann surface is equal to $2g-2$… is this in some way related to the Gauss-Bonnet theorem?,"I’m following an introductory course on Riemann surfaces. Today, the lecturer proved the fact that the degree of a meromorphic form in a genus $g$ Riemann surface is equal to $2g-2$ (we can deduce from this, for instance, that the sum of orders of zeros of a holomorphic nontrivial form is $2g-2$ as well). He then said as a side remark that this result is related to the Gauss-Bonnet theorem from differential geometry (he called this result “flat Gauss-Bonnet”), in the sense that (in some intuitive way, I reckon) “all the curvature would be concentrated in the singularities”, where “conical singularities act like Dirac masses” (or something along that lines… I can’t precisely recall his words since I didn’t totally grasp what his point was). I more or less could picture what he meant in a handwavy way, but I prefer trying to get a more solid understanding over things. Is there some precise sense in which the singularities of a meromorphic function on a Riemann surface are related to the (Gaussian…? Geodesic…?) curvature of that surface? Is the result about the degree of meromorphic functions actually related to the Gauss-Bonnet theorem? Would there be any other result generalizing both, or a more general framework in which this analogy could be made explicit? In general, how can I learn more about this subject? (I have some basic knowledge of differential geometry, if that helps. But in any case references on the subject would be welcome.)","['riemann-surfaces', 'riemannian-geometry', 'curvature', 'meromorphic-functions', 'differential-geometry']"
4680928,Related Rates: Shadow of Ball Problem,"A light is at the top of a pole $50$ ft high. A ball is dropped from the same height from a point $30$ ft away from the light. How fast is the shadow of the ball moving along the ground $1\over 2$ seconds later? (Assume the ball falls a distance $s = 16t^2$ ft in $t$ seconds.) The way I attempted at this is as so: The geometrical picture we are looking at is of two heights ( $= 50$ ft) $30$ ft horizontally away from each other. One of the heights decreases towards the horizontal at a rate $-16t^2$ . As this height decreases, connect the tips of both heights with a line and produce this line till it hits the horizontal. Call the length between the point at which the line hit the horizontal and the foot of the decreasing height $x$ . Then the tip of this length is the shadow of the ball, and it is required to find the rate at which this length decreases. The image below should provide a visual aid: Call the balls height from the horizontal $y$ (this is $50 - 16t^2$ on the picture), then by what is given, ${dy\over dt}=-32t$ (since $y = 16t^2$ ) An obvious relation between the variables and the constants is of the proportionality between the sides of the triangles. ${x\over y} = {x + 30 \over 50}$ Solving for $x$ , $x = {30y \over 50 - y}$ Implicitly differentiating, $x^\prime = 30y(50 - y)^{-2}y^\prime + (50 - y)^{-1}30y^\prime$ Substituting for $y^\prime = -32$ , we get $x^\prime = -1500$ . Is this result correct? I must ask for I do not consider myself yet experienced, hence I have to get constant affirmation from those more professional. Thank you in advance.","['related-rates', 'calculus', 'derivatives', 'algebra-precalculus']"
4680947,"Let $f:[0,1]\to \mathbb{R},f(x)=4x(1-x),f_n(x)=f(f_{n-1}(x))\;\forall n\geq 1$ and $f_0(x)=x$. Find number of solutions to the equation $f_n(x)=x$.","Let $f:[0,1]\to \mathbb{R},f(x)=4x(1-x),f_n(x)=f(f_{n-1}(x))\;\forall n\geq 1$ and $f_0(x)=x$ . Find number of solutions to the equation $f_n(x)=x$ . My Attempt I tried plotting graphs of $y=f(x)$ and $y=f(f(x))$ by focusing on the fact when $f(x)=0$ and when $f(x)=1$ because $f(f(x))=0$ at these points and also found the points when $f(f(x))=1$ . So I got that $f(f(x))=x$ has $3$ solutions. Can there be a recursive solution or some other approach here because this way I am not able to get any pattern.","['graphing-functions', 'function-and-relation-composition', 'maxima-minima', 'functions', 'algebra-precalculus']"
4680955,Existence of a TFA group which can be written as an extension in two different ways,"I'm looking for an example of an abelian, torsion-free group, say $E$ , which can be written on the
one hand as a trivial extension of two other groups $G$ and $H$ , necessarily abelian, and also as a non-trivial extension of the same groups (so $G$ and $H$ must be torsion free as well).
It seems to be that $E$ would have to be very large (certainly infinitely generated), but I'm not sure if it exists.","['group-theory', 'abelian-groups']"
4680971,Classifying divergent sequences in a metric space,"To my understanding, in $\mathbb{R}$ , we have the following ways in which a sequence can diverge: The sequence could diverge off into $\infty$ or $-\infty$ ( relevant generalization ) Divergence by oscillation: A sequence that neither converges to a finite number nor diverges to either $∞$ or $−∞$ is said to oscillate or
diverge by oscillation. 2.1.An oscillating sequence with finite amplitude is called
a finitely oscillating sequence. eg: $\{ (-1)^n \}$ 2.2.An oscillating sequence with infinite amplitude
is called an infinitely oscillating sequence.   Eg: $\{ n(-1)^n \}$ In contrast, for a general metric space, is there a way to classify the ways of divergence similar to the above? If so, what are some examples of ways which a sequence could diverge in a general metric space which can't happen in $\mathbb{R}$ ? Notes: On divergence by oscillation Source","['applications', 'metric-spaces', 'analysis', 'sequences-and-series']"
4680994,Problem Proof of matrix Invertibility,"Let 2 $v \times 1$ column matrices X and Y such that the $v \times v$ matrix $A = I +XY^{T}$ to be invertible.Show that $A^{-1}= I - \frac{1}{1+Y^{T}X}XY^{T}$ My effort: I have to show that $AA^{-1}=I$ . So: $$AA^{-1}=(I +XY^{T})\left(I - \frac{1}{1+Y^{T}X}XY^{T}\right)$$ \begin{align*}
AA^{-1}&=(I +XY^{T})\left(I - \frac{1}{1+Y^{T}X}XY^{T}\right)\\
&= I\left(I - \frac{1}{1+Y^{T}X}XY^{T}\right) + XY^{T}\left(I - \frac{1}{1+Y^{T}X}XY^{T}\right)\\
&= I - \frac{1}{1+Y^{T}X}XY^{T} + XY^{T} - \frac{1}{1+Y^{T}X}XY^{T}XY^{T}\\
\end{align*} How I proceed further ?","['matrices', 'linear-algebra', 'vectors']"
4681038,"Minimizing $\int_{0}^{1} (f'(x))^2 \, dx$ with constraints","Problem. Given that $f \in C^{(1)} [0,1]$ , $f(0) = a$ , $\int_{0}^{1} f(x) \, dx = 0$ , find minimum value of $\int_{0}^{1} (f'(x))^2 \, dx$ . I've tried applying Cauchy-Schwarz, but only got the lower bound of $a^2$ . I also could construct an example where the value is $4a^2$ , but couldn't make any progress after that. My Attempt. With Cauchy we have $$ \left| \int_{0}^{c} f(x) g(x) \, dx \right|^2
\leq \left( \int_{0}^{c} f^2(x) \, dx \right) \left( \int_{0}^{c} g^2(x) \, dx \right), $$ where we can substitute $f(x) = f'(x)$ , $g(x) = 1$ , so: $$ \left| \int_{0}^{c} f'(x) \, dx \right|^2 \leq \int_{0}^{c} f'^2(x) \, dx. $$ For some $c$ in $[0,1]$ we have $f(c) \leq 0$ , so we can choose $c$ such that left side is at least $(f(c) - f(0))^2 = a^2$ . The right part doesn't decrease while increasing $c$ , so that's why the lower bound is $a^2$ . $a^2$ can also be the answer, but I couldn't find such an example.","['integration', 'calculus', 'analysis']"
4681044,Can this non-linear boundary-value problem be solved analytically?,"I am trying to solve $$
[y^2(x)]''+\frac{x}{2} y'(x) = 0
$$ on $x\in\mathbb{R}$ , with the conditions $$
\lim_{x\rightarrow-\infty} y(x) = a,\qquad
\lim_{x\rightarrow\infty} y(x) = b.
$$ I am particularly interested in non-negative solutions, $y(x)\geq0$ , and the case where $a\neq b$ . This means I cannot integrate by parts on the second term, so I'm rather stuck. Searching the usual places (Google, Wolfram alpha) hasn't returned anything interesting.","['boundary-value-problem', 'nonlinear-analysis', 'ordinary-differential-equations']"
4681091,"Find the value of $S$, sum of some Harmonic Numbers","Find the value of $$S=\sum_{t=1}^{37}t\left(\frac1{t}+\frac1{t+1}+\frac1{t+2}+\cdots+\frac1{37}\right)$$ This question was asked in an exam which I took. I thought that converting it to a compact form will help me solve the summation. I tried converting it to a double summation but in vain. Which ever technique I used, nothing was of any help. Then I thought maybe Harmonic Numbers can help. I rewrote the problem as $$S=\sum_{t=1}^{37}t\left(H_{t-1}\right)$$ This looks like an Arithmetic Geometric Progression but it's not, rather it's a Arithmetic Harmonic Progression (if that's a thing). I'm stuck. Any help is greatly appreciated.","['number-theory', 'sequences-and-series']"
4681095,Riemann-Liouville integral of $f$ is zero implies $f =0$ a.e.,"The Riemann-Liouville integral is defined by $$
I^\alpha f(x)=\frac{1}{\Gamma(\alpha)} \int_a^x f(t)(x-t)^{\alpha-1} d t
$$ where $\Gamma$ is the gamma function and $a$ is an arbitrary but fixed base point. Take $a = 0$ and $\alpha = 1/2$ . Therefore we look at: $$
I^{\frac{1}{2}} f(x) := \frac{1}{\Gamma(1/2)} \int_0^x \frac{f(t)}{\sqrt{x-t}} d t
$$ Suppose $I^{\frac{1}{2}}f(x) = 0$ for all $x$ . Can we then conclude $f=0$ a.e.? My approach so far has been to take the Fourier transform and use the convolution theorem. I cannot conclude because I do not know if $f \in L^2(\mathbb{R})$ . Otherwise, I could conclude just by using the fact that the Fourier transform is an isometry between $L^2$ spaces. See here for the same question on MathOverflow.","['measure-theory', 'analysis', 'real-analysis', 'complex-analysis', 'riemann-integration']"
4681097,$\bmod p^a\!:\ x^2\equiv 1\iff x\equiv \pm 1\ \ $,"There is question For each of prime $p$, show that the congruence 
  $x^2 \equiv1 \pmod {p^a}$
  has precisely two solutions. Continue and show that the congruence
  $x^2 \equiv 1 \pmod {2^a} $
  has one solution if $a=1$, two solutions if $a=2$, and four solutions if $a \ge 3$. I don't know how to do. Help please?","['number-theory', 'elementary-number-theory']"
4681103,Deriving the power series for sine and cosine from geometry,"A few years ago, I saw an article that showed that it was possible to derive the power series for sine and cosine using a tail-to-tip chord approximation in the unit circle. Basically, one first create a chord of length $0 \leqslant \theta \leqslant 2$ starting from the origin point $(1,0)$ to a point $P_1$ on the unit circle. Now, if you divide the length $\theta$ by a given constant $n$ and create a sequence of multiple tail-to-tip chords, then you have $n$ points on the unit circle from $P_1$ to $P_n$ and the total length [of all chords] remains $\theta$ . You want to find the couple $(x_n,y_n)$ by solving the tail-to-tip recurrence system given by $$
\begin{cases}
  (x_k - x_{k-1})^2 + (y_k - y_{k-1})^2 = \left(\frac\theta n\right)^2 \\
  (x_k)^2 + (x_k)^2 = 1
\end{cases}
$$ Trying to first the first couple $(x_1,y_1)$ we have $$
\begin{cases}
  (x_1 - x_0)^2 + (y_1 - y_0)^2 = \left(\frac\theta n\right)^2 \\
  (x_1)^2 + (y_1)^2 = 1
\end{cases}
$$ And it's not hard to show that $$
x_0 \neq 0, y_0 = 0 \implies x_1 = \frac{(x_0)^2 - (\theta/n)^2 + 1}{2x_0}, y_1 = \sqrt{1 - (x_1)^2}
$$ We know that $P_0 = (1,0)$ so we can easily compute $P_1$ from the formula above. Further terms can be computed using iterative substitution, aka the ""plug and chug"" method. Indeed, we can show that $$
x_0 \neq 0, y_0 = 0 \implies x_k = \frac{(x_{k-1})^2 - (\theta/n)^2 + 1}{2x_{k-1}}, y_k = \sqrt{1 - (x_k)^2}
$$ Now, expanding this whole expression becomes very cumbersome for $k > 2$ and we want to find an explicit formula instead, that is, one which doesn't involve $x_{k-1}$ in the expression. I tried to do the substitution up to $k = 3$ but I failed to identify a recurring pattern. From the geometric intuition, though, we should have $$
x_n \sim \cos(\theta) \quad \text{and} \quad y_n \sim \sin(\theta) \quad \text{as} \ n \to \infty
$$ A lot of steps have been skipped in the original article, and somehow, the final result is as follows $$
x_n = \sum_{k=0}^{\lfloor n/2 \rfloor}(-1)^k \bigg({n \atop 2k}\bigg) \bigg(1 - \frac{(\theta/n)^2}{2}\bigg)^{n-2k} \bigg(\frac\theta n\bigg)^{2k} \bigg(1 - \frac{(\theta/n)^2}{4}\bigg)^k
$$ and $$
y_n = \sum_{k=0}^{\lfloor n/2 \rfloor}(-1)^k \bigg({n \atop 2k+1}\bigg) \bigg(1 - \frac{(\theta/n)^2}{2}\bigg)^{n-2k-1} \bigg(\frac\theta n\bigg)^{2k+1} \bigg(1 - \frac{(\theta/n)^2}{4}\bigg)^{k+(1/2)}
$$ In the limit as $n \to \infty$ and glossing over some convergence details, it can be shown that the two above expressions simplify to the power series of cosine and sine, respectively. To me, it seems not so trivial to derive those two expressions. I like the concept, and I would like some help or guidance on what steps could have been used to get those two results.","['geometry', 'recurrence-relations', 'generating-functions', 'power-series', 'trigonometry']"
4681116,Solving the laplacian over a square,"I am preparing for an upcoming exam, and I was solving the following boundary value problem $$\Delta u(x,y)=0,\ (x,y)\in [0,\pi]^2$$ $$u_y(x,0)=0,\ u_y(x,\pi)=0$$ $$u(0,y)=0$$ $$u(\pi,y)=\cos^2y$$ I tried separation of variables, asusming $u(x,y)=X(x)Y(y)$ and solved it, putting in the boundary conditions and got (assuming the solutions are not trivially zero) $$X(x)=A(e^{nx}-e^{-nx})$$ $$Y(y)=D\cos(ny)$$ for some constants $A,D$ . I then put them together and wrote $$u(x,y)=\sum_{n=1}^\infty A_n(e^{nx}-e^{-nx})\cos(ny)$$ where the $A_n$ are constants to be determined. Am I correct in writing this? Assuming it is correct, I put in the last boundary condition and using the orthogonality of the fourier basis, I get $$A_n=\frac{2/\pi}{e^{n\pi}-e^{-n\pi}}\int_0^\pi \cos^2y\cos(ny)\ \mathrm dy$$ which only survives when $n=2$ (for the rest, it is $0$ ). For $n=2$ , it gives $$A_2=\frac{1}{2(e^{2\pi}-e^{-2\pi})}$$ Then plugging in this in the solution, I have $$u(x,y)=\frac1{2(e^{2\pi}-e^{-2\pi})}(e^{2x}-e^{-2x})\cos(2y)$$ But here is the problem. The final solution doesn't seem to be satisfying the last boundary condition. It gives $$u(\pi,y)=\frac12\cos(2y)=\cos^2y-\frac12$$ where there is an extra factor of $1/2$ . I have been looking at it for hours but I can't find where the error creeps in. Any help is appreciated!","['solution-verification', 'harmonic-functions', 'ordinary-differential-equations', 'partial-differential-equations']"
4681163,How to compute the following definite integral?,"$$\int_{-\infty}^{+\infty} e^{-(ap - ibx)^2} dp$$ where $a$ , $p$ , $b$ , $x$ are real numbers and $a$ is greater than zero.
I think that I should declare a new variable $m = ap - ibx$ , then $dm = adp$ and the integral will just become: $$\frac{1}{a}\int_{}^{} e^{-m^2} dm$$ However, it is not quite a Gaussian since $m$ is complex and the borders of integration will be something like $(-\infty - ibx)$ and $(+\infty - ibx)$ . Therefore I do not know how to prove that the given integral should be equal to $\sqrt{\pi}/a$ .","['integration', 'complex-analysis', 'calculus', 'multivariable-calculus']"
4681180,Non-Markovian Basketball Player Puzzle,"I am trying to solve the following puzzle I recently heard: Suppose a basketball player is shooting ten free throws. He makes the first, and misses the second. For every subsequent shot, his probability of making that shot is the percentage of shots already made (i.e., probability of making the third is $1/2$ ). What is the probability that out of $10$ shots, he makes exactly $5$ of them? I have an idea of how to solve the problem, but I can't quite finish it. For the player to make 5 shots, at any point he must have exactly one shot made, two shots made... 4 shots made in no particular order. And at each stage he must have already taken a total of 2 shots, 3 shots... 9 shots. Therefore I have a fraction that looks something like this: $$
\frac{{\displaystyle\binom{8}{4}} \cdot 1 \cdot 2 \cdot 3 \cdot 4}{2 \cdot 3 \cdot 4 \cdot 5 \cdot 6 \cdot 7 \cdot 8 \cdot 9}
$$ where $4!$ is the total number of shots already made, $\binom{8}{4}$ is the number of ways of arranging those makes, and $9!$ is the total number of shots taken. I'm not sure if this is correct, but I don't feel like I've taken into account the fact that the five misses could be between any of the makes in any order.","['discrete-mathematics', 'probability']"
4681201,Application of Sobolev's inequality,"Given $K\subset \mathbb{R}$ compact, we consider a regular function $f:K^n\to \mathbb{R}$ whose mean value is $0$ . I was wondering if we can get the inequality $ n\|f\|_{L^q(K^n)}\leq C \sum_{i=1}^n\|\nabla_{x_i}f\|_{L^2(K^n)}$ for some $C$ that only depends on $K$ (not on $n$ ), where $q$ satisfies $1/q=1/2-1/n.$ I suppose that if this is true, it should be a consequence of applying Sobolev inequality . However, the constant here depends on $n$ .","['lebesgue-integral', 'real-analysis', 'multivariable-calculus', 'functional-analysis', 'partial-differential-equations']"
4681205,$n$-th root of a positive element in an ordered field,"In Rudin's real analysis, there is a statement that says that for every positive real number $x$ and for each positive integer $n$ , there is one and only one real number $y$ such that $y^{n} = x$ . My question is kind of similar but with a little variant. It is the following: Does there exist an ordered field $F$ other than $\mathbb{R}$ such that it satisfy the following two properties: (1) every positive element of $F$ has an $n$ -th root for all positive integers $n$ , (2) for any positive integer $n$ , the map $f: F^{+} \rightarrow F$ defined by $f(x) = y$ , where $y^{n} = x$ , is a continuous function under the order topology.","['continuity', 'general-topology', 'functions']"
4681286,How to solve circular permutation from its linear analogue?,"Suppose I know how to solve a linear permutation problem, is there any general strategy to solve its circular analogue? I apologise for putting multiple questions. The specific answers to these questions might be already available. I am not looking forward to the answers of these questions, rather , I want to know the common strategy (not manual counting) that all of these problems have. Circular permutation of $n$ distinct objects: We can break the circle from $n$ places, each yielding its own linear arrangement, so $k \times n = n! \implies k = (n-1)!$ Consider $n$ sided polygon. How many $r$ sided polygon can be formed so that no sides are common? : $x_1 + x_2 + \cdots + x_r = n-r$ and $x_i ≥ 1$ . Therefore, number of possible ways is ${{n-r-1} \choose {r-1}} \color{red}{\frac{n}{r}}$ The number of ways in which a necklace can be formed using 6 identical diamonds and 3 identical pearls is: Partition $6$ into $3$ unordered tuples, i.e., $(0,0,6),$ $(0,1,5),(0,2,4),(0,3,3),$ $(1,1,4),(1,2,3),(2,2,2)$ . So, there are $7$ possibilities. In problem (2) , I understood why ${{n-r-1} \choose {r-1}}$ is used, but I had a doubt on why $\color{red}{\frac{n}{r}}$ is used. We cannot apply the logic of problem (1) here since there is a lot of symmetry. Also, we cannot apply the logic of problem (2) to problem (3), as we get ${{6+3-1} \choose {3-1}} \times \frac{9}{3}$ which does not match with the correct answer $7$ . Is there any common strategy to all these problems?","['permutations', 'combinatorics']"
4681296,Is the ideal generated by coefficients of characteristic polynomial of a matrix prime?,"Consider the ring $R=\mathbb C[a_{ij}]$ which is the free polynomial ring of $n^2$ variables $a_{ij}$ over the field of complex numbers $\mathbb C$ . Set matrix $A=[a_{ij}]_{n\times n}$ and $f(\lambda):=\det(\lambda I-A)=\lambda^n+\sum_{k=0}^{n-1}f_k\lambda^k$ be its characteristic polynomial. Let the ideal $J=(f_0,\cdots,f_{n-1})\subset R$ . Is $J$ a prime ideal? What I have done is the following: Take a look at the algebraic set $Z=V_{\mathbb C^{n\times n}}\ (J)\subset M_n(\mathbb C)$ , the set of all nilpotent matrices, one can show that $Z$ is irreducible. Consider the Jordan block of size $n$ and eigenvalue $0$ , $B=J_n(0)$ . Check the map $\mathrm{GL}_n(\mathbb C)\to M_n(\mathbb C)$ given by $P\mapsto PBP^{-1}$ . The image of this map is nilpotent matrices with Jordan canonical form $B$ , since the set of these matrices is Zariski dense in $Z$ , so the closure of the image is $Z$ . By the fact that $\mathrm{GL}_n(\mathbb C)$ is irreducible, we know the image is irreducible, so $Z$ is irreducible too. It remains to show that $J$ is a radical ideal: by $I(Z)=\sqrt J$ if $J=\sqrt J$ then it is prime. For $n=2$ , this can be done by hand. When $n=3$ , By a SageMath check: sage: R.<a11, a12, a13, a21, a22, a23, a31, a32, a33> = PolynomialRing(QQ,9)
....: I = R * [a13*a22*a31 - a12*a23*a31- a13*a21*a32 + a11*a23*a32
      + a12*a21*a33 - a11*a22*a33, - a12*a21 + a11*a22 - a13*a31 - 
      a23*a32 + a11*a33 + a22*a33, -a11 - a22 - a33]
....: I.is_prime()
True","['maximal-and-prime-ideals', 'matrices', 'linear-algebra', 'characteristic-polynomial', 'commutative-algebra']"
4681307,Are there any non-real solutions of cot z = z?,"I am trying to locate the solutions of $\cot z = z$ . It is clear that there are an infinite number of solutions when $z$ is real just from looking at the graph, but how could I determine if there are any non-real complex roots? I tried letting $z=x+iy$ with $x,y $ both real and writing $$ x+iy = \cot(x+iy) = \frac{\cos(x+iy) \sin(x-iy)}{\sin(x+iy)\sin(x-iy)} = \frac{\sin(2x)-i\sinh(2y)}{\cosh(2y)-\cos(2x)} $$ Equating real and imaginary parts gives two equations which must be satisfied: $$ \frac{\sin(2x)}{\cosh(2y)-\cos(2x)}=x \;\; (1)\,, \hspace{1cm} \frac{\sinh(2y)}{\cosh(2y)-\cos(2x)} = -y \;\; (2)$$ If $y=0$ we recover the equation $\cot x = x$ and if $x=0$ we obtain $\coth y = -y$ which has no solutions (implying that there are no purely imaginary solutions) but I can't figure out how to deduce from these equations whether there are additional solutions for $x,y$ both non-zero. Any help is appreciated.","['trigonometry', 'complex-numbers']"
4681319,Question about divisors on a compact Riemann surface,"I am trying to prove the following question from here without relying on the Riemann-Roch theorem. Let $X$ be a compact Riemann surface, and let $D$ be a divisor on $X$ . (i) If $\mathrm{deg}(D) = 0$ , show that $\mathrm{dim}(L(D))$ is equal to $0$ or $1$ , with the latter occurring if and only if $D$ is principal. Furthermore, any non-zero element of $L(D)$ has divisor $-D$ . (ii) If $\mathrm{deg}(D) \geq 0$ , establish the bound $\mathrm{dim}(L(D)) \leq \mathrm{deg}(D) + 1$ . Here is my work so far: If $D = 0$ then we have that $L(0) = 0$ as $X$ is compact, with the opening mapping theorem, implies that $L(0)$ is the space of constant functions. However, I am not sure what to do even for the simple case where $D = (P) - (Q)$ . any $f \in L(D)$ must have at least a simple zero at $Q$ and at most a simple pole at $P$ . How can I get further information about $f$ ? Similarly, the only one that I could prove so far for (ii) is the case when $D$ is trivial. Thank you so much for your help.","['complex-analysis', 'riemann-surfaces', 'divisors-algebraic-geometry', 'meromorphic-functions']"
4681334,Construct a bijection given two injections,"I know that if there exists an injection $f: A \to B$ , then $|A| \leq |B|$ . Then trivially, $f: A \to B$ and $g: B \to A$ both being injections imply that $|A| = |B|$ . However, the definition of $|A| = |B|$ means that there exists a bijection between $A$ and $B$ . Is there any way to construct such a bijection from $f$ and $g$ or at least prove a bijection exists without using cardinality?","['elementary-set-theory', 'cardinals', 'functions']"
4681342,Why doesn't MVT hold when I take the limit as $x\to 0$?,"I'm considering $f(x) = x^2\sin(1/x)$ for $x\ne 0$ , and $f(0)=0$ . MVT gives me $(f(x)-f(0))/ x = x \sin(1/x) = f'(c) = 2c \sin(1/c) - \cos(1/c)$ for some $c$ between $x$ and $0$ . Taking the limit as $x$ goes to $0$ gives me $0 = \lim_{c\to 0} \cos(1/c)$ which doesn't make sense. What did I do wrong?","['analysis', 'real-analysis', 'calculus', 'solution-verification', 'derivatives']"
4681376,"If $x^2 + y^2 = 1$, then find the value of $(3x-4x^3)^2+(3y-4y^3)^2$ where $x,y\in \mathbb {R}$ .","If $x^2 + y^2 = 1$ , then find the value of $(3x-4x^3)^2+(3y-4y^3)^2$ where $x$ , $y \in \mathbb {R}$ . What I've tried : I thought $x$ , $y$ as $\sin \theta$ and $\cos \theta$ . But, it doesn't seems to work and I'm unable to see any particular pattern in it .",['algebra-precalculus']
4681383,The application of the open mapping theorem,"Let $V$ be a Hilbert space and $V_i \subset V(i=1, \ldots, J)$ a number of closed subspaces satisfying $V=\sum_{i=1}^J V_i$ , which, by a simple application of the Open Mapping Theorem, implies $$
\sup _{\|v\|=1} \inf _{\sum_i v_i=v} \sum_{i=1}^J\left\|v_i\right\|^2<\infty
$$ I don't know how to use the open mapping theorem. Edit: This claim is made in the paper The method of alternating projections and the method of subspace corrections in Hilbert space by Jinchao Xu and Ludmil Zikatanov. See here .",['functional-analysis']
4681403,A problem about a equivelant representation of a distance of measures.,"Problem : For two probability measures 𝜇 and 𝜈 on the real line 𝐑, the total variation distance is defined as $$
‖𝜇 − 𝜈‖_{TV} = \sup \{\mathit{\mu}(C) - \mathit{\nu}(C) \colon C \in \mathcal{B}(\mathbb{R})\} ,
$$ where $\mathcal{B}(\mathbb{R})$ is the $\sigma$ -algebra of Borel sets on $\mathbb{R}$ . Let $\mathcal{C}(\mathit{\mu}, \mathit{\nu})$ be the space of couplings of the probability measures $\mathit{\mu}$ and $\mathit{\nu}$ , i.e., the space of $\mathbb{R}^2$ valued random variables $(X, Y)$ defined on some (not necessarily same) probability space $(\Omega, \mathcal{F}, \mathbb{P})$ such that the marginal distributions of $X$ and $Y$ are $\mathit{\mu}$ and $\mathit{\nu}$ , respectively. It can be shown that \begin{equation*}
‖\mathit{\mu} − \mathit{\nu}‖_{{TV}} = \inf \{\mathbb{P}(X \neq Y) \colon (X, Y) \in \mathcal{C}(\mathit{\mu}, \mathit{\nu})\} .
\end{equation*} For simplicity, we may assume that $\mathit{\mu}$ and $\mathit{\nu}$ are absolutely continuous with respect to the Lebesgue measure on $\mathbb{R}$ . I figue out that $$
‖\mathit{\mu} − \mathit{\nu}‖_{{TV}} \leq \inf \{\mathbb{P}(X \neq Y) \colon (X, Y) \in \mathcal{C}(\mathit{\mu}, \mathit{\nu})\}.
$$ And the key to gain the other side is to construct a $\mathbb{P}$ s.t. $$
\mathit{\mu}(C) − \mathit{\nu}(C) = \mathbb{P}(X \neq Y).
$$ But how?",['probability-theory']
4681404,Breaking a rose up into distinct pieces,"The cartesian equation for a rose is: $x = rcos(k\theta)cos(\theta)$ $y = rcos(k\theta)sin(\theta)$ When $k=4$ the figure formed has 8 petals.  If I wish draw those 8 petals as polygons in a graphics system such as Processing, I can iterate over $\theta$ with steps small enough to smoothly draw the vertices of the polygons.  The first polygon's vertices will be drawn for $0<=\theta<\pi/4$ , for instance.  The next for $\pi/4<=\theta<\pi/2$ . When $k$ is not an integer we have more complex figures where the petals appear to ""overlap"".  For instance when $k=3/2$ we have the picture below, with 6 petals which overlap their neighbour.  When $k=5/2$ the situation is more complex. For any arbitrary rational value of $k$ , how do we calculate the ranges of $\theta$ which will break the rose down into distinct shapes?  Is there a better way to tackle this problem? To make my question clearer, I've added a further figure for $k=3/2$ .  The perimeter I can find is in red.  The perimeters of polygons I'd like to find are in blue and green for this value of k. . A rose with k=1.5 A rose with k=2.5",['geometry']
4681422,"Sequence function on $C[-2,2]$ is Cauchy Sequence","We consider the space $C[-2,2]$ and Euclidian norm $\left\| . \right\|_2$ . We observe the sequence of functions: $$ f_n(x)=\left\{\begin{matrix}0,
 & x \notin [0,1]\\ nx,
 & x \in [0,\frac{1}{n}]\\ 1,
 & x \in [\frac{1}{n},1- \frac{1}{n}] \\ n(1-x)
 & x \in [1-\frac{1}{n},1]
\end{matrix}\right. $$ Is $f_n(x)$ a Cauchy Sequence wrt $\left\| . \right\|_2$ ? I am struggile to show either of those things. I cannot find counter example and I don´t get far when I try to prove that it is. Any tip or help would be appriciate!","['cauchy-sequences', 'normed-spaces', 'functional-analysis']"
4681433,Deducing the Fermi sea is ground state for the kinetic energy operator $\sum_j(-\Delta_{x_j})$,"I am reading a paper and have no background in quantum mechanics. Any help/references would be appreciated. The ground state for a system of $N$ non-interacting fermions on the unit torus $\mathbb T^d$ has the following simple form. In frequency space, $$\Big(\psi_N,\sum_j(-\Delta_{x_j})\psi_N\Big)=\sum_{p_i\in\mathbb Z^d,\,i=1,...,N}\Big(\sum_{j=1}^N p_j^2\Big)|\widehat\psi_N(p_1,...,p_N)|^2.$$ (This follows from Plancherel on $\mathbb T^d$ .) My question is about the following conclusion from this result. The paper I am reading says, Therefore, it is easy to see that the lowest energy configuration is given by $\widehat\psi_N={\bigwedge}_{i\in F_n}\delta_i$ , where $F_N\subset\mathbb Z^d$ is the subset of $N$ distinct lattice points closest to the origin, and $\delta_i$ is the Kronecker delta at $i\in\mathbb Z^d$ . Clearly, the set $F_N$ is an approximate ball $B_{R_N}(0)\cap\mathbb Z^d$ of radius $R_N\sim N^{1/d}$ , and it is referred to as the Fermi sea. My questions are: How do I deduce from the equation that the lowest energy configuration is given by $\widehat\psi_N={\bigwedge}_{i\in F_n}\delta_i$ , where $F_N\subset\mathbb Z^d$ is the subset of $N$ distinct lattice points closest to the origin? Why is $F_N$ is an approximate ball $B_{R_N}(0)\cap\mathbb Z^d$ of radius $R_N\sim N^{1/d}$ ?","['analysis', 'functional-analysis', 'partial-differential-equations', 'quantum-mechanics', 'physics']"
4681447,Distribution of distinct objects into distinct groups,"I came across this question on the principle of distribution under combinatorics: ""Find the number of ways in which 6 different prizes can be
distributed among 3 children, each receiving at least 1 prize."" Assume that all the prizes have to be distributed.
So, basically I could solve this by dividing it into cases as $(1,1,4)$ for when A gets 1 prize, B gets 1, and C gets 4 prizes, $(1,2,3)$ and $(2,2,2)$ and then calculated distributions in each case as well as taking into account the unique arrangements, as $(1,1,4)$ and $(1,4,1)$ are 2 different cases. By adding all of them, I arrived at the answer 540, which is the correct answer according to the solution in the book.
However, I tried attempting to do this by taking the total number of ways to distribute 6 prizes among 3 children without any conditions, and then subtracting the cases where even any one of them got no prize, but failed to arrive at the solution. So, what I did was this: Total ways to distribute 6 prizes among 3 children without any conditions: $3^6$ This also includes the case $(0,0,0)$ . So, $3^6 -1$ Now let any one child get no prize and so 6 prizes can be distributed among 2 children in 2^6 ways. And we can select the child getting 0 prize in 3 ways. So, $$3^6-1-3(2^6)$$ However $3 * 2^6$ ways has 3 cases of $(0,0,0)$ which we had already excluded earlier, so we should add 3 now. $$3^6 -3(2^6) + 2$$ Also $3 * 2^6$ has 2 cases each of $(0,0,1)$ , $(1,0,0)$ , $(0,1,0)$ , so by following earlier reasoning we must add 3 to the expression as these cases are getting subtracted twice.
So, final expression becomes $$3^6 - 3(2^6) + 5$$ But this gives the answer 542. I can't point out exactly where I went wrong and I would really appreciate it if someone could.",['combinatorics']
4681486,Two different ways of constructing the convex combination of two sets,"Suppose $A$ and $B$ are both subsets of $\mathbb{R}^n$ and convex.
Let \begin{equation*}
C=\left\{z\in \mathbb{R}^n \vert z=\alpha x+\left(1-\alpha\right)y, x \in A, y\in B, \alpha \in \left[0,1\right]\right\}, 
\end{equation*} that is just the convex hull of $A \cup B$ . Suppose there is a one-to-one mapping between $A$ and $B$ , denoted by $f$ . Consider the following set where the convex combination is more restrictive: \begin{equation*}
D=\left\{z\in \mathbb{R}^n \vert z=\alpha x+\left(1-\alpha\right)y, x \in A, y\in B, y=f\left(x\right), \alpha \in \left[0,1\right]\right\}.
\end{equation*} Apparently $D\subseteq C$ . I was wondering whether $D=C$ . I tried to construct a counterexample by drawing graphs but failed.","['convex-analysis', 'geometry', 'real-analysis']"
4681590,Difference of prime powers as linear combination of jumping champions,"Reading the preprint Bounded gaps between
primes in short intervals by Ryan Alweiss and Sammy Luo ( https://arxiv.org/abs/1707.05437 ), I came up with the following question: Can the difference $\Delta$ between prime powers $p^a$ and $q^b$ not exceeding $x$ always be written as a finite linear combination $\sum_{i=1}^{k'} c_{i}J_{i}(x)$ with non negative integral coefficients $c_{i}$ of the jumping champions up to $x$ $J_{i}(x)$ with $i<j\Longrightarrow J_{i}(x)>J_{j}(x)$ and $\lVert\Delta\rVert:=\sum_{i=1}^{k'}c_{i}$ minimal? I'm especially interested in the case $ab\leq 2$ . Edit: assuming an affirmative answer to the previous question can one get $\lVert\Delta\rVert=O(\log^{O(1)}x)$ ? Here comes a vague idea: assuming the jumping champions are the primorials $P_{m}:=\prod_{i=1}^{m}p_{i}$ , from $P_{m}=m^{m(1+o(1))}$ and writing $w_{x}$ for the ""power square root"" of $x$ i.e. $w_{x}^{w_{x}}=x$ , from $\log^{\log x}x=(e^{\log\log x})^{\log x}=e^{\log x.\log\log x}=x^{\log\log x}$ one gets $w_{x}=o(\log x)$ . Now from Bertrand's postulate one has $P_{m+1}\leq 2p_{m}P_{m}\lesssim 2m\log m P_{m}$ so one should have $\lVert\Delta\rVert\leq 2k'w_{x}\log w_{x}$ . But $k'\leq w_{x}$ hence $\lVert\Delta\rVert\leq 2w_{x}^{2}\log w_{x}=o(\log^{2}(x)\log\log x)=O(\log^{O(1)}x)$ . Edit April 24th 2023: by the way, can one prove that $H_{m}:=\lim\inf_{n\to\infty}p_{n+m}-p_{n}$ is reached for $\lVert\Delta\rVert=m$ with the finite sequence $(c_{i})_{1\leq i\leq k'}$ non decreasing? This may lead to a combinatorial prediction of diameters of prime constellations.
Also we may make an analogy between $\lVert\Delta\rVert$ and the dimension of a vector space and between the number of non vanishing coefficients $c_{i}$ and the rank of some endomorphism defined thereon. Edit April 27th 2023: I've just seen that someone voted to close because this question ""needs details or clarity"", so I refer to https://mathoverflow.net/questions/61842/about-goldbachs-conjecture and especially to the definition of natural configuration therein so as to provide an insight of why primorials and thus conjecturally jumping champions are expected to preserve the primality of a number to which it's added or substracted (and thus why the difference of prime powers should be a linear combination with non negative integral coefficients of jumping champions provided they are primorials). From the point of view of configurations the sequence of primorials ""converges to $0$ "" as the configuration of order $u$ of both a primorial greater or equal to $p_{u}\sharp$ and of $0$ only consists of a sequence of $0$ .
Taking $J_{1}(x)$ as a value for $d$ in the preprint of Alweiss and Luo may allow to pass from $2n=p+q^2$ with $p$ and $q$ prime to $2n=p'+q'$ with $p'$ and $q'$ prime with $O(\log^{O(1)}n)$ shifts of the integer $r$ such that both $n-r$ and $n+r$ are prime powers. The general idea would be to first strengthen Chen's theorem to ""every large enough even integer is the sum of a prime and the square of a prime or the sum of two primes"" and then reduce the first case to the second one. Edit April 29th 2023: say an interval $I$ (respectively its length $g=\lambda(I)$ ) of the form $[P^{a},Q^{b}]$ with $P$ and $Q$ prime and $Q-P$ minimal is an $m$ -jumping prime power interval (respectively gap) of level $l=ab$ if $m$ is the infimum of the set of integers $t$ such that $g$ is the sum of $t$ jumping champions up to $Q^{b}$ . As an example $g_{30}=p_{31}-p_{30}=127-113=14=6+6+2$ is a $3$ -jumping prime power gap of level $1$ . Now denote by $\gamma_{m,l}(J)$ the number of $m$ -jumping prime powers intervals of level $l$ contained in $J$ such that the total number of jumping prime power intervals of level at most $l_{0}$ contained in $J$ is $N_{l_{0}}(J)=\sum_{m\geq 1,l\leq l_{0}}\gamma_{m,l}(J)$ . The idea is to express the lengths of the intervals $I_{1}:=[\min(p',q'),\max(p',q')]$ and $I_{2}:=[\min(p,q^{2}),\max(p,q^{2})]$ with $2n=p'+q'=p+q^{2}$ with $p, q, p'$ and $q'$ prime as sums of jumping prime power gaps of level at most $2$ , each being of the form $\Delta$ and show that the number of $m$ -jumping prime power intervals of level at most $2$ contained in $I_{j}$ with $m>1$ and $j\in\{1,2\}$ is an $o(N_{2}(I_{j}))$ . Are there results in the literature which may help to reach this goal? Note that this partly boils down to showing that most coefficients $c_{i}$ in a prime gap of the form $\Delta$ equal $0$ or $1$ . Also, assuming an affirmative answer to the first question, we may set $I_{j}$ with $j\in\{1,2\}$ such that $\Delta:=\lambda(I_{j})$ is a $\lVert\Delta\rVert$ -jumping prime power gap of level $j$ . Denoting by $r_{0}(n)$ the smallest non negative integer $r'$ such that $(n-r',n+r')\in\mathbb{P}^{2}$ and by $k_{0}(n):=\pi(n+r_{0}(n))-\pi(n-r_{0}(n))$ we get $2r_{0}(n)=:\Delta\Longrightarrow k_{0}(n)\leq\lVert\Delta\rVert$ and the conjecture in the current edit implies $k_{0}(n)\lesssim\lVert\Delta\rVert$ . Writing $2r_{0}(n)=k_{0}(n)\log^{1+\varepsilon_{k_{0}(n)}}n=\lVert\Delta\rVert\log^{1+\varepsilon'_{\lvert\Delta\rVert}}n$ this and the PNT imply that $\lim_{k_{0}(n)\to\infty}\varepsilon_{k_{0}(n)}=\lim_{k_{0}(n)\to\infty}\varepsilon'_{\lVert\Delta\rVert}=0$ . From the reasoning leading to $\lVert\Delta\rVert=o(\log^{2}n.\log\log n)$ we get $k_{0}(n)=o(\log^{2}n.\log\log n)$ and thus $2r_{0}(n)=o(\log^{3+h}n.\log\log n)$ where $h=\sup_{k_{0}(m),m\leq n}\varepsilon_{k_{0}(m)}$ , giving further evidence to the hypothesis that one may pass from $2n=p+q^{2}$ to $2n=p'+q'$ in $O(\log^{O(1)}n)$ shifts of the integer $r$ such that both $n-r$ and $n+r$ are prime powers. Edit April 30th 2023: a way to do so would be to use the rank reducing shift $S_{n}(r):=\frac{(\Omega(n+r)+\Omega(n-r)-2)+\vert\Omega(n+r)-\Omega(n-r)\vert}{2}g_{min}(n)$ with $g_{min}(n)=2.3^{1_{3\not\mid n}}$ iteratively to get a finite sequence $(r'_{l}(n))$ with $r'_{0}(n):=r$ and $r'_{l'+1}(n):=r'_{l'}(n)+S_{n}(r'_{l'}(n))$ to get a primality radius $r_{0}(n)$ , i.e get $(n-r_{0}(n),n+r_{0}(n))\in\mathbb{P}^{2}$ . As $\Omega(m)\leq\frac{\log m}{\log 2}$ for any positive integer $m$ , one may be able to prove that this algorithm with initial value $r'_{0}(n):=0$ terminates after $O(\log^{1+o(1)} n)$ steps and thus that $r_{0}(n)=O(\log^{2+o(1)}n)$ . Edited on May 5th 2023 to try to resolve conflict of notations. Edit May 7th 2023: in the special case $ab=1$ $\Delta_{1}=q-p$ is obviously a linear combination of prime gaps with positive integral coefficients. Now consider the case $\Delta_{2}=q^{2}-p=q^{2}-q+q-p=q(q-1)+q-p$ . As $q-1=q-3+2$ and $2$ being both a prime gap and a jumping champion, assuming $\Delta_{1}=\sum_{i}c_{i}J_{i}(x)$ one gets $\Delta_{2}=\Delta_{1}+q\Delta'_{1}$ where $\Delta'_{1}:=\sum_{i}c'_{i}J_{i}(x)$ hence $\Delta_{2}=\sum_{i}c''_{i}J_{i}(x)$ . Edit January 10th 2024: the dual question, namely viewing jumping champions as linear combinations with non negative coefficients of prime gaps, may help reduce the known upper bound of $246$ of Polymath8b to $30=5\times 6$ replacing thrice $6$ by $2+4$ to get an admissible $k$ -tuple with $k=9$ of diameter $30$ , hence a prime constellation. In that case one would get $\lVert\Delta\rVert=3+3+2=8=k-1$ . The fact that the $8$ -simplex is convex and self-dual may be useful in the variational method used in the aforementioned Polymath project.","['number-theory', 'prime-gaps', 'prime-numbers']"
4681614,Topologizing free abelian groups. Clarification,"The question Topologizing free abelian groups on Mathoverflow asks about the existence and uniqueness of a topology for the free abelian group on $X$ such that the natural inclusion is a homeomorphism onto its image and addition and inverse map are continuous. There are four different answers and some interesting discussions along the comments.
The final answer is affirmative if and only if the topological space is completely regular.
In the Abelian case (as in others) it can be regarded as $\mathbb Z[X]$ endowed with the weakest topology with respect to which all homomorphic extensions of continuous maps from $X$ to topological groups are continuous (Sipacheva, Free Boolean Topological Groups ). The topology on these spaces is important because their homotopy groups compute the homology with integer coefficients of the topological spaces they're the span of (Dold-Thom theorem). In this sense, McCord provided a systematic construction of abelian groups whose homotopy groups computed the homology of the space in question with coefficients in ''good'' groups (I think there are some technical conditions).
For a (pointed) space $(X,x_0)$ and a topological abelian group $G$ , $B(G,X)$ was the space of functions $f:X\to G$ with finite support with the extra convention that $f(x_0)=e$ for all $f$ . For each $n\geq 0$ $B_n(G,X)$ was the subspace of $B(G,X)$ consisting of functions whose support had at most cardinality $n$ , with the quotient topology with respect to the map $$
q_n:(X\times G)^n \to B_n(G,X);
$$ $q((g_1,x_1),\dots,(g_n,x_n))$ is the function $f:X\to G$ such that $f(x_i)=g_i$ and $f(x)=e$ for $x\in X\setminus \{x_1,\dots,x_n\}$ (with the convention that $q(g,x_0)=e$ for all $g\in G$ .
Then $$
B(G,X)= \bigcup_n B_n(G,X).
$$ For $G=\mathbb Z$ with the discrete topology, $B(\mathbb Z,X)$ is the group completion of the topological monoid $SP^\infty X$ , the infinite symmetric product of $X$ . Is $B(\mathbb Z,X)$ isomorphic to $\mathbb Z[X]$ as topological abelian groups? In the paper (Sipacheva, Free Boolean Topological Groups ), the author defines free Boolean topological groups are defined similarly: the abstract free Boolean group generated by the set $X$ endowed with the weakest topology with respect to which all homomorphic extensions of continuous maps from $X$ to topological Boolean groups are continuous.
Is this equivalent to $B(\mathbb Z_2,X)$ ? $\bullet$ M. C. McCord, Classifying spaces and infinite symmetric products . EDIT As @Tyrone points out in a comment, McCord considers compactly generated spaces. In the accepted answer to the original question, the space $X$ must be normal for the free abelian topological group $\mathbb Z[X]$ to exist. You can assume that all the spaces here are locally finite CW-complexes.","['homotopy-theory', 'linear-algebra', 'functional-analysis', 'general-topology', 'algebraic-topology']"
4681674,Clarification about weak topology in the space of probability measure,"In Jacod and Shiryaev book , page 347, we find the definition of weak convergence of probability measures. Definition . Let $E$ be a Polish space (completely metrizable space which is also separable) and let $\mathcal{E}$ be its Borel $\sigma$ -algebra (the $\sigma$ -algebra generated by the collection of all open subsets of $E$ ). We denote by $\mathcal{P}(E)$ the space of all probability measures on $(E,\mathcal{E})$ .
The weak topology on $\mathcal{P}(E)$ is defined as the coarsest topology for which the mappings $\mu\rightarrow \mu(f)$ are continuous for all bounded continuous functions $f$ on $E$ . I am not very familiar with the concept of ""coarsest topology for which a mapping"" is continuous, but this wikipedia page helps a bit. The idea is, among all those topologies that make the mapping $\mu\rightarrow \mu(f)$ continuous, to consider the smallest one. The problem is: does this topology exist? Furthermore, I see form this post that the weak topology is sometimes defined in this way. We have $\mu_n\longrightarrow\mu$ whenever $$
\int f d\mu_n \to \int f d\mu.
$$ for all bounded continuous functions $f$ on $E$ . Do the two definitions coincide? Any reference would help.","['weak-convergence', 'general-topology', 'measure-theory', 'polish-spaces']"
4681688,How do I determine that the function $f(x)=\sin3x+4\cos x-8x$ is decreasing on the entire real line?,"How do I determine (see) that the function $f(x)=\sin3x+4\cos x-8x$ is decreasing on the entire real line? Its graph obviously helps, but I am not searching for that. The only method I am familiar with is to find the solutions of the inequality $f'(x)<0$ . In these intervals the function is decreasing. For the first derivative we have $$f'(x)=3\cos3x-4\sin x-8$$ $$=3\left(4\cos^3x-3\cos x\right)-4\sin x-8$$ $$=12\cos^3x-9\cos x-4\sin x-8$$ I am not sure the formula for $\cos3x$ helps whatsoever. It's not obvious for me that $f'(x)<0$ for all $x$ . What's the idea?","['functions', 'derivatives', 'real-analysis']"
4681696,Computing a limit on the unit sphere: Riemann Lebesgue?,"Let $u\in L^1(\mathbb{S}^{d-1})$ . I want to show that \begin{align*}
\lim_{|\xi|\to \infty}
\int_{\mathbb{S}^{d-1}}(1-\cos(\xi\cdot w))u(w)d \sigma_{d-1}(w)
= \int_{\mathbb{S}^{d-1}}u(w)d \sigma_{d-1}(w). 
\end{align*} Basically, the question can be reduced into showing that \begin{align*}
\lim_{|\xi|\to \infty}
\int_{\mathbb{S}^{d-1}}\cos(\xi\cdot w)u(w)d \sigma_{d-1}(w)
= 0. 
\end{align*} This looks like a Riemann-Lebesgue lemma. But I don't know how to tackle it. I intuitively guessed this from the classical Riemann-Lebesgue Lemma which infers that \begin{align*}
\lim_{|\xi|\to \infty}
\int_{B_1(0)}(1-\cos(|\xi| z\cdot x))u(x)d x
= \int_{B_1(0)}u(x)dx\quad \text{for fixed $z\in \Bbb R^d$}. 
\end{align*} More generally, if $f$ is $T^d$ -periodic, then $f_\lambda(x)= f(\lambda x)$ weakly converge in $L^p$ to its mean value as $\lambda\to\infty$ that is $$f_\lambda \rightharpoonup \bar f,\quad \quad \bar f=\frac{1}{T^d}\int_{[0,T]^d}f(x) dx.$$ Is there any good reference for this type of limit?
Any help is welcome","['integration', 'fourier-analysis', 'harmonic-analysis', 'analysis', 'real-analysis']"
4681745,Do the $4$ Pythagorean means divide into two algebraic dualities?,"I’m looking to understand the relationship between rectangular product & mean square operations -- or, equivalently, between their root operations, the geometric & quadratic means.  Here’s the problem: Suppose we define an isomorphic mapping CR(a,b) to re-describe argument real pair a,b into their conjugate roots -- i.e., $$CR(a,b) = \left( \sqrt a+\sqrt b, \sqrt a-\sqrt b \right)$$ With the function arguments so ‘re-described’, subtraction becomes re-describable as a product, and addition as a mean square : $$
\begin{split}
\text{Diff}(a,b)
  = a - b
 &= \left(\sqrt a+\sqrt b\right)\left(\sqrt a-\sqrt b\right)
  = \text{Prod}(CR(a,b)) \\
\text{Sum}(a,b)
  = a + b
 &= \frac{\left(\sqrt a+\sqrt b\right)^2+\left(\sqrt a-\sqrt b\right)^2}{2}
  = \text{MeanSq}(CR(a,b))
\end{split}
$$ So subtracting a pair of real numbers is always just multiplying their conjugate square roots, and summing them likewise just mean-squaring those same conjugate square roots. 7 is thus not just the difference of 16 and 9 , but the product of their conjugate square roots (4+3)(4-3) ; likewise, 25 is not just their sum, but the mean-square of those conjugate square roots (49+1)/2 . But the sum & difference operations on the left-side of the above equations are inverse operations to one another -- by definition, even.  Can the corresponding right-sides of the above equations, multiplying & mean-squaring, be similarly understood as inverse operations of each other?? Since those latter operations, rectangular product & mean-square, are 2-degree area-functions, perhaps the question is best addressed to their 1-degree linear counterparts (i.e., their own square roots), in which case we ask then after the relationship between geometric mean & quadratic mean .  And this appears to offer some promise, since among the four Pythagorean means, the other two -- arithmetic & harmonic means -- are, obviously, multiplicative “duals” of one another: $$
\begin{split}
HM(a,b) &= {1 \over AM(\frac1a,\frac1b)} \\
AM(a,b) &= {1 \over HM(\frac1a,\frac1b)}
\end{split}
$$ …and in that sense they are in ""inverse"" relationship, with the geometric mean that falls between them being multiplicatively self- dual, $GM(a,b)= {1 \over GM(1/a,1/b)}$ . But can all four Pythagorean means then really be so neatly paired off that the quadratic mean QM be in some way “dual with” or ""inverse to"" GM ?  The following diagram in Wikipedia, which relates them as a “central secant” (my term for it) vs. a tangent, looks promising in this regard, but I myself am not quite seeing what the inversion would then be, conceptually: * Please feel free to suggest other tags appropriate to this question.  I am, frankly, not quite sure under what math subfields it falls. Image here: https://en.wikipedia.org/wiki/Root_mean_square#/media/File:QM_AM_GM_HM_inequality_visual_proof.svg ( The diagram is drawn from these larger articles: https://en.wikipedia.org/wiki/Pythagorean_means#Inequalities_among_means https://en.wikipedia.org/wiki/Root_mean_square#Relationship_to_other_statistics )","['analytic-geometry', 'algebra-precalculus', 'a.m.-g.m.-inequality', 'means']"
4681766,Cleaner form for transformation involving Stirling numbers,"I have a specific transformation involving treating the Stirling numbers of the first kind as a matrix, given by, for some positive $b$ $$
C^{(b)} = (S_1^{(b)})^{T} \left(J_b\ \left(\frac{1}{2^{i}}{{b}\choose{i}}\right) \right) S_1^{(b)}
$$ where $S_1^{(b)}$ is a $b+1 \times b+1$ matrix of Stirling numbers of the first kind, $J_b$ is the exchange matrix (matrix with 1s along the anti-diagonal), and the remaining matrix is simply a diagonal matrix with binomial coefficients divided by powers of two along the diagonal schematically, this looks like, for example for $b=2$ , $$
C^{(2)} = 
\begin{bmatrix}
 1 &  0 &  0 \\
 0 &  1 & -1 \\
 0 &  0 &  1 \\
\end{bmatrix}
\begin{bmatrix}
 0 & 0 & \frac{1}{2^{2}}{{2}\choose{2}} \\
 0 & \frac{1}{2^{1}}{{2}\choose{1}} & 0 \\
 \frac{1}{2^{0}}{{2}\choose{0}} & 0 & 0 \\
\end{bmatrix}
\begin{bmatrix}
 1 &  0 & 0 \\
 0 &  1 & 0 \\
 0 & -1 & 1 \\
\end{bmatrix}
$$ and the specific matrix elements are given by $$
c^{(b)}_{k l} = \begin{cases}
\frac{1}{2^b} s(b, l) & k = 0 \\
s(b, k) & l = 0 \\
\sum_{w=l}^{b-k} \frac{1}{2^w} {{b}\choose{w}} s(b-w, k) s(w, l)   & else
\end{cases}
$$ Given the connections between changes of basis to rising/falling factorials, Stirling numbers, and binomial coefficients this feels like it has some deeper meaning, but this is of course complicated by the fact that we can't read this as a plain change of basis since $S_1^{(b)}$ is not unitary For anyone who wants it, here's some Mathematica code to generate this matrix cMat[b_] :=
 With[
  {
   S = Table[StirlingS1[k, w], {k, 0, b}, {w, 0, b}],
   J = Array[KroneckerDelta[#, b - #2] &, {b, b} + 1, 0],
   W = DiagonalMatrix[Table[Binomial[b, w]/2^w, {w, 0, b}]]
   },
  Transpose[S] . (J . W) . S
  ]

cMat[3] // MatrixForm $$
\left(
\begin{array}{cccc}
 0 & \frac{1}{4} & -\frac{3}{8} & \frac{1}{8} \\
 2 & -\frac{9}{4} & \frac{3}{4} & 0 \\
 -3 & \frac{3}{2} & 0 & 0 \\
 1 & 0 & 0 & 0 \\
\end{array}
\right)
$$","['combinatorics', 'stirling-numbers']"
4681778,Prove that $(A \cup B)\backslash (C \backslash A)=A \cup (B \backslash C)$,"For all sets $A, B$ and $C$ , I need to prove that it holds $$(A \cup B)\backslash (C \backslash A)=A \cup (B \backslash C)$$ I tried to prove on this way: $$C\backslash A= X$$ $$(A \cup B) \backslash X = \\
=AX \cup BX = \\
=AX \cup B\backslash C\backslash A=\\
= A\cup (B\backslash C)$$ Is this correct? Could you please help me to prove this correctly if I'm wrong?","['elementary-set-theory', 'propositional-calculus', 'logic', 'discrete-mathematics']"
4681802,Geometric interpretation of vector and transpose?,"$v^Tv$ is the dot product of a vector with itself, which is just its norm squared, an intuitive geometric quantity. Is there something to be said about $vv^T$ ? Is there some kind of relationship between this matrix and some geometric object the way the cross product relates to the area of the parallelogram for example?","['vectors', 'matrices', 'linear-algebra', 'intuition', 'geometric-interpretation']"
4681806,Distribution of a sum of first and last order statistics,"I can't find anywhere on the internet a solution to the following exercise: Let $X = (X_1, \dots, X_n)$ be a sequence of i.i.d random variables from exponential distribution. Find the distribution of statistic $T = \frac{1}{2}(X_{(1)} + X_{(n)})$ where $X_{(1)}, X_{(n)}$ are first and last order statistics. Preparation : $$f_{X_i}(x_i) = \lambda e^{-\lambda x_i}\mathbb{1}_{(0,\infty)}(x_i)$$ $$F_{X_i}(x_i) = 1-e^{-\lambda x_i}$$ I know the general formula for the density function of vector $X_{(r)},X_{(s)}$ which is $$f_{X_{(r)},X_{(s)}}(u,v) = \frac{n!}{(r-1)!(s-r-1)!(n-s)!}F(u)^{r-1}f(u)(F(v)-F(u))^{s-r-1}f(v)(1-F(v))^{n-s}$$ So by using this formula for $X_{(1)}, X_{(n)}$ I have: $$f_{X_{(1)}, X_{(n)}}(x,y) = (n-1)n\lambda^2e^{-\lambda(x+y)}(e^{-\lambda x}-e^{-\lambda y})^{n-2}\mathbb{1}_{(0,\infty)}(x)\mathbb{1}_{(0,\infty)}(y)\mathbb{1}(x \leq y)$$ First approach : Here is the area of integration $$F_T(t) = P(T \leq t) = P(\frac{1}{2}X_{(1)} + \frac{1}{2}X_{(n)} \leq t) = P(X_{(n)} \leq -X_{(1)}+2t) = \iint_A f_{X_{(1)}, X_{(n)}}(x,y) \,dx\,dy = \\
=\int_{0}^{t}\int_{x}^{-x+2t} (n-1)n\lambda^2e^{-\lambda(x+y)}(e^{-\lambda x}-e^{-\lambda y})^{n-2} \,dy\,dx = \\
=(n-1)n\lambda^2\int_{0}^{t} e^{-\lambda x}\int_{x}^{-x+2t}e^{-\lambda y}(e^{-\lambda x}-e^{-\lambda y})^{n-2} \,dy\,dx$$ I don't know how to calculate this integral. Second approach : Here is the area of integration $$F_T(t) = P(T \leq t) = P(\frac{1}{2}X_{(1)} + \frac{1}{2}X_{(n)} \leq t) = \iint_B f_{X_{(1)}, X_{(n)}}(x,y) \,dx\,dy = \dots$$ Now using substitution: $u = x, v= \frac{1}{2}(x+y)$ so $x = u, y = 2v-u, |J| = \begin{bmatrix} 1 & 0\\ -1 & 2 \end{bmatrix} = 2$ $$\dots = \int_{-\infty}^{\infty}\int_{-\infty}^{t} 2f_{X_{(1)}, X_{(n)}}(u,v-u) \,dv\,du = \int_{-\infty}^{t}\int_{-\infty}^{\infty} 2f_{X_{(1)}, X_{(n)}}(u,v-u) \,du\,dv$$ So that means: $$f_T(v) = \int_{-\infty}^{\infty} 2f_{X_{(1)}, X_{(n)}}(u,v-u) \,du = \\
=\int_{-\infty}^{\infty} 2(n-1)n\lambda^2e^{-\lambda(u+2v-u)}(e^{-\lambda u}-e^{-\lambda (2v-u)})^{n-2}\mathbb{1}_{(0,\infty)}(u)\mathbb{1}_{(0,\infty)}(2v-u)\mathbb{1}(u \leq 2v-u)\,du =\\
= 2(n-1)n\lambda^2 e^{-2\lambda v} \int_{0}^{\infty}(e^{-\lambda u}-e^{-\lambda (2v-u)})^{n-2}\,du $$ Again similar integral. Third approach: Chat GPT gave me the following solution :) $X_{(1)}=\min(X_1,\dots,X_n), X_{(n)}=\max(X_1,\ldots,X_n)$ - I agree with this so far. $$F_T(t) = P(T \leq t) = P(\frac{1}{2}X_{(1)} + \frac{1}{2}X_{(n)} \leq t) = P(X_{(1)} \leq -X_{(n)}+2t) = \\
=1 - P(X_{(1)} > 2t - X_{(n)}) = \\
=1 - P(X_1>2t-X_n, X_2>2t-X_n, \dots, X_{n-1}>2t-X_n, X_n>2t-X_n)=\\
= 1 - \prod_{i=1}^{n}P(X_i>2t-X_n) = 1-[1-F_{X_i}(2t-X_n)]^n= 1-[1-\int_{2t}^{\infty} \lambda e^{\lambda(2t-x)}\,dx]^n = \\
= 1- [e^{-\lambda t}]^n = 1-e^{-n \lambda t}$$ $$f_T(t) = \frac{d}{dt}(1-F_T(t)) = \frac{d}{dt}(e^{-n\lambda t}) = n\lambda e^{-n \lambda t}$$ I do not understand why from $X_{(1)}>2t-X_{(n)}$ we go suddenly to $X_1>2t-X_n, \dots, X_n>2t-X_n$ Summary: My questions are: If my first and second approach is correct, how to solve integrals at the end? Is chat gpt correct? If none of this approaches are correct then I would be grateful for solution.","['integration', 'statistics', 'probability-distributions', 'order-statistics', 'probability']"
4681841,Find the product of the min and max value of the function $f(x)=\frac{\sin^4x+\cos^4x}{\sin^6x+\cos^6x}$,Find the product of the min and max value of the function $$f(x)=\dfrac{\sin^4x+\cos^4x}{\sin^6x+\cos^6x}$$ We can simplify the function as follows $$f(x)=\dfrac{(\sin^2x+\cos^2x)-2\sin^2x\cos^2x}{(\sin^2x+\cos^2x)(\sin^4x-\sin^2x\cos^2x+\cos^4x)}\\=\dfrac{1-2\sin^2x\cos^2x}{1-3\sin^2x\cos^2x}=\dfrac{1-\frac{(2\sin x\cos x)^2}{4}}{1-\frac{3(2\sin x\cos x)^2}{4}}\\=\dfrac{2-\sin^22x}{2}\cdot\dfrac{4}{4-3\sin^22x}=\dfrac{4-2\sin^22x}{4-3\sin^22x}=\dfrac{4-3\sin^22x+\sin^22x}{4-3\sin^22x}\\=1+\dfrac{\sin^22x}{4-3\sin^22x}$$ How do I continue from here?,['functions']
4681854,Calculate ranking (match value) in Swiss tennis,"The match value is a part of the ranking in Swiss tennis , it is calculated with the formula: $$
W=\frac{1}{2} \left( \ln\left( \sum_{i=1}^{s} e^{w_i}+e^{w_0} \right)-\ln\left( \sum_{j=1}^{N} e^{-w_j}+e^{-w_0} \right) \right)
$$ Original from the link above: $W$ = your match value $w_0$ = your previous match value $w_i$ = the match value of the player you defeated $w_j$ = the match value of the player you lost to $s$ = sum of the matches you won $N$ = sum of the matches you lost I would like to calculate how many times ( $s$ ) one has to defeat a player with a match value of $W_j=3.400$ to get the match value $W=3.2$ if you start with $w_0=2.354$ for the setting when you do not lose matches ( $N=0$ ). How could I write a function in $\mathbb{R}$ to calculate this? Update1: Because of the comments (the given formulas might not be unequivocal), I contacted Swiss Tennis for clarification. They sent me updated formulas (sorry for the quality, these are the originals): Where WA = W0 . Unfortunately, they did not provide an example of the formula in use.","['algebra-precalculus', 'statistics']"
4681972,Finding small square roots modulo P,"Let $P$ be a sufficiently large prime number. Let $x$ be a positive integer, we can write: $$
\begin{align*}
x^2 = kP + a
\end{align*}
$$ where $0 \leq a < P$ . Suppose furthermore that $\sqrt{P} < x < P^{2/3}$ , then this implies that $0 < k < P^{1/3}$ . Assuming that as $x$ runs through its range, $a = x^2 \bmod P$ takes on uniformly distributed values in $[0, P)$ (this isn't rigorous but given the quadratic residues are fairly uniformly distributed mod $P$ this is still a good heuristic), then the probability that there exists at least one $x$ such that $a < P^{1/3}$ is well approximated by $$
\begin{align*}
1 - \left ( 1 - P^{-2/3} \right )^{P^{2/3}} \to 1 - \frac{1}{e} \approx 0.63
\end{align*}
$$ which is independent of $P$ . In practice I've found this to be pretty reliable and I can find such $x$ for most choices of $P$ . My question is, given a prime $P$ , does there exist an efficient algorithm (say, polynomial in $\log P$ ) to find at least one $x$ , if one exists (which as seen above is likely), such that $0 < k < P^{1/3}$ and $0 < a < P^{1/3}$ ? Of course we can just try all possible values of either $k$ or $a$ , but this becomes prohibitively expensive as $P$ grows. I have tried to apply Coppersmith's method but it does not seem powerful enough for this problem. Lattices seem a natural fit for problems looking for ""small solutions"" of this kind, but perhaps the fact that $P$ is prime can be of help (since the above does not use the primality of $P$ in any way). Has this problem been studied?","['number-theory', 'integer-lattices', 'algorithms', 'reference-request']"
4682038,Finding matrix least square problem,"If you have a function of the form $$
f(x) = \frac{1}{2}\left\lVert Ax - y \right\rVert_2^2
$$ We know that if $A \in \mathbb{R}^{n \times m}, x \in \mathbb{R}^m$ and $y \in \mathbb{R}^n$ we can find the minimizer by differentiating $$
\nabla_x f = A^TAx - A^Ty
$$ setting this to $0$ leads to the linear system $$
A^TAx = A^Ty.
$$ Suppose now instead of $x$ being unknown the unknown is $A$ . In this case we have $$
f(A) = \frac{1}{2} \left\lVert Ax - y \right\rVert_2^2
$$ To calculate the gradient w.r.t. $A$ I proceed as follows (assuming as a norm for $A$ I am using the 2 norm). $$
\lim_{E \to 0} \frac{\left| f(A + E) - f(A) - T(A)E \right|}{\left\lVert E \right\rVert_2}
$$ With a little bit of calculation we can show that $$
f(A + E) - f(A) =  \left(x^TA^T - y^T\right)Ex +\left\lVert Ex \right\rVert_2^2
$$ Substituing this into the limit and using the squeeze theorem I get $$
0 \leq \lim_{E \to 0} \frac{\left| \left(x^TA^T - y^T\right)Ex +\left\lVert Ex \right\rVert_2^2 - T(A)E \right|}{\left\lVert E \right\rVert_2} \leq \lim_{E \to 0} \frac{\left| \left(x^TA^T - y^T\right)Ex  - T(A)E \right| +\left\lVert Ex \right\rVert_2^2 }{\left\lVert E \right\rVert_2} \leq \lim_{E \to 0} \frac{\left\lVert \left(x^TA^T - y^T\right)(\cdot)x  - T(A) \right\rVert_{{\mathbb{R}^{n \times m}}^*} \left\lVert E \right\rVert_2 +\left\lVert Ex \right\rVert_2^2 }{\left\lVert E \right\rVert_2} = \lim_{E \to 0} \left\lVert \left(x^TA^T - y^T\right)(\cdot)x  - T(A) \right\rVert_{{\mathbb{R}^{n \times m}}^*}
$$ The last limit is equal to 0 iff $$
T(A) = \left(x^TA^T - y^T\right)(\cdot)x
$$ Question 1: Is my calculation of the differential correct? Assuming it is I was trying to characterize $T(A)$ using a basis $E_{ij} = \delta_{ij}$ by doing this I get $$
T(A)E_{ij} = \left(x^TA^T - y^T\right)E_{ij}x = \left(x^TA^T - y^T\right)x_j e_i = x_j \left(x^TA^T - y^T\right) e_i = x_j \left(x^TA^T e_i  - y^T e_i \right) = x_j \left(x^TA^T  e_i  - y_i \right)
$$ Question 2 : Is this correct? This should give me a set of equations that I should be able to solve for $A$ ?","['derivatives', 'solution-verification', 'linear-algebra']"
4682101,Prove $27abc + 10(a^2+b^2+c^2)^{\frac{3}{2}} \geq 6(a+b+c)(a^2+b^2+c^2)$,"Let $a,b,c$ be real numbers. Prove that $$27abc + 10(a^2+b^2+c^2)^{\frac{3}{2}} \geq 6(a+b+c)(a^2+b^2+c^2).$$ My work: I started with some Cauchy-Schwarz on the $(a^2+b^2+c^2)^{3/2}$ to get similar to $(a+b+c)(a^2+b^2+c^2)$ but I don't know what to do next.","['algebra-precalculus', 'cauchy-schwarz-inequality', 'inequality']"
4682102,Is there any relationship between Gleason's theorem and Riesz representation theorem?,"Gleason's Theorem Section 2.3.3 states that if a mapping $p$ satisfies several conditions, $p$ can be written as $p(E)=\text{tr}(\rho E)$ which is the inner product with a given density matrix. The third condition if $E_1E_2=0$ , then $p(E_1+E_2)=p(E_1)+p(E_2)$ looks like linearity condition. So I think it is very similiar to Riesz representation theorem in functional analysis. Is there any further relationship between the two theorems?","['riesz-representation-theorem', 'functional-analysis', 'intuition', 'quantum-mechanics', 'quantum-information']"
4682114,A difficulty in the surface integral of $\frac{1}{\sqrt{1-y^4}}$ over a certain surface $S$,"Consider the following surface integral of the first kind: $\iint_{S}\frac{1}{\sqrt{1-y^4}}dS$ where $S=[(x,y,z)\in R^3:z=x+\frac{y^2}{\sqrt{2}},x\in[0,\frac{\pi}{2}],y\in[0,\frac{1}{\sqrt{2}}]]$ . I found this exercise on Youtube and the solver opted for a parametric approach to the surface $S$ obtainig the result $\frac{\sqrt{2}\pi^2}{8}$ . I opted for a cartesian approach to the surface $S: dS=\sqrt{1+||\nabla g||^2}dxdy$ where $z=g(x,y)=x+\frac{y^2}{\sqrt{2}}$ . By calculation, $dS=\sqrt{1+2y^2}dxdy$ as $\nabla g=(1,\sqrt{2}y)$ . Now, $\iint_{S}\frac{1}{\sqrt{1-y^4}}dS=\iint_{D}\frac{1}{\sqrt{1-y^4}}\sqrt{1+2y^2}dD=\int_{0}^{\pi/2}dx\int_{0}^{1/\sqrt{2}}\frac{\sqrt{1+2y^2}}{\sqrt{1-y^4}}dy=\frac{\pi}{2}\int_{0}^{1/\sqrt{2}}\frac{\sqrt{1+2y^2}}{\sqrt{1-y^4}}dy$ . To me it's not clear how to proceed except doing a simple $\sqrt{1-y^4}=\sqrt{1-y^2}\sqrt{1+y^2}$ but in the numerator I have a different quantity even after trying to factor a $2$ outside the square root. Is my approach even correct for this kind of problem or should I parametrize $S$ ?","['multivariable-calculus', 'solution-verification']"
4682132,"For an equation that gives function value at a point, how do I apply a differential operator?","(Note: Using Einstein summation convention throughout) I'm trying to understand Theorem 2.2.1 in Wald's General Relativity book. We have a smooth manifold $M$ , with $p\in M$ and $(O,\psi)$ an open chart containing it. Let $f\in C^{\infty}(M)$ and $X^i(f)\equiv\frac{\partial}{\partial x^i}(f\circ\psi^{-1})\big|_{\psi(p)}$ . There's a result that if $F:\mathbb{R}^n\to\mathbb{R}$ is smooth, then for each $a=(a^1,\ldots,a^n)\in\mathbb{R}^n$ , $$F(x)=F(a)+(x^i-a^i)H_i(x)\tag{1}$$ where $H_i(x)=\frac{\partial F}{\partial x^i}\big|_{x=a}$ . So now letting $F=f\circ\psi^{-1}$ and $a=\psi(p)$ , for all $q\in O$ , we get $$f(q)=f(p)+[x^i\circ\psi(q)-x^i\circ\psi(p)]H_i(\psi(q))\tag{2}$$ So far it's clear. The next step is what I don't understand: Let $v\in T_p(M). [...]\ $ we apply $v$ to $f$ . Using equation (2), the linearity and Leibnitz properties of $v$ , and the fact that $v$ applied to a constant (such as $f(p)$ ) vanishes, we obtain $$v(f)=v[f(p)]+[x^i\circ\psi(q)-x^i\circ\psi(p)]\ \bigg|_{q=p}v(H_i\circ\psi)+(H_i\circ\psi)\big|_pv[x^i\circ\psi-x^i\circ\psi(p)]\tag{3}
\\=\big(H_i\circ\psi(p)\big)\ v(x^i\circ\psi)$$ There's a lot I don't get - Why is the LHS not $v[f(q)]$ ? And in the very last bracket on RHS, why is it $[x^i\circ\psi-x^i\circ\psi(p)]$ and not $[x^i\circ\psi(q)-x^i\circ\psi(p)]$ ? Sorry if this seems like a naive question - I guess my multivariable calculus is rusty..","['calculus', 'tangent-spaces', 'differential-geometry']"
4682135,How many ways are there to select 3 red cards and 4 black cards so that there are 2 power cards [jack to ace] and 5 regular cards [2 to 10]?,"How many ways are there to select 3 red cards and 4 black cards from a deck of 52 playing cards so that there are 2 power cards [jack to ace] and 5 regular cards [2 to 10]? My attempt: There are $$\binom{26}{3}\times\binom{26}{4}$$ ways to pick 3 red cards and 4 black cards from a standard deck of 52 cards. Moreover, there are $$\binom{36}{5}\times\binom{16}{2}$$ ways to pick 5 regular cards and 2 power cards from a standard deck of 52 cards. Now, the required answer is an overlap between the two selections, so that among 7 cards there are 3 red cards and 4 black cards and there are 5 regular cards and 2 power cards. How do I get the desired answer?","['combinatorics', 'discrete-mathematics']"
4682142,Can this solution be generalised from $\ N=4\ $ to $\ N=2^r\ $?,"This question relates to a version of a problem that's already been discussed at least twice before on MSE, namely here , and here . The version of the problem I'm interested in is the following: Let $\ R_N\ $ be the right circular shift by one place of strings of bits of length $\ N=2^r\ $ : $$
(R_NS)_i=S_{(i-2)\pmod{N}+1}\ ,
$$ $\ S_0\ $ be a random string of bits of length $\ N\ $ , $\ X_1$$\,X_2,$$\,\dots,X_j,$$\,\dots\ $ a sequence of independent random integers distributed uniformly over the set $\ \{0,$$\,1,$$\,2,$$\,\dots,$$\,N-1\}\ $ and $\ C_1,C_2,\dots,C_j,\dots\ $ any sequence of strings of bits of length $\ N\ $ . Define the sequence $\ S_1$$\,S_2,$$\,\dots,S_j,$$\,\dots\ $ recursively by $$
S_j=R_N^{X_j}\big(S_{j-1}\oplus C_j\big)\ ,
$$ where $\ \oplus\ $ represents the operation of bitwise XOR between two strings of bits. The problem is to determine a finite sequence $\ C_1,C_2,\dots,C_M\ $ such that at least one of the strings $\ S_1$$\,S_2,$$\,\dots,S_M\ $ is guaranteed to be zero. The origin of the problem is a more general one appearing as question $7$ of the senior A-level Tournament of the Towns paper of autumn $2009$ . In the solution sheet for that paper it is proved by induction that such a finite sequence always exists. While preparing an answer to this question (now closed), I discovered the following solution for $\ N=4\ $ : \begin{align}
C_1&=0000\\C_2&=1111\\C_3&=0101\\C_4&=1111\\C_5&=0011\\C_6&=1111\\C_7&=0101\\C_8&=1111\\C_9&=0001\\C_{10}&=1111\\C_{11}&=0101\\C_{12}&=1111\\C_{13}&=0011\\C_{14}&=1111\\C_{15}&=0101\\C_{16}&=1111 
\end{align} My initial proof that this sequence works comprised an unenlightening collection of casework. As I was tidying it up, however, I noticed some relations between the order of the appearance of the terms in the solution and the lengths of their orbits under the action of the group of circular  shifts, and I eventually came up with the following proof: First note that length of the orbit of a string $\ S\ $ of bits of length $\ N\ $ is $\ \ell\ $ under the action of the group $\ G_N\ $ of circular shifts if and only if $\ \ell=2^k\ $ for some $\ k\in\{0,1,2,\dots,r\}\ $ ; and $S\ $ is periodic with period $\ \ell\ $ . If the string $\ C\ $ has an orbit of length $\ p<\ell\ $ (and is hence periodic with period $\ p=2^j\ $ for some $\ j<k\ $ ) then the length of the orbit of $\ C\oplus S\ $ is $\ \ell\ $ . If the length of $\ S_0$ 's orbit is $1$ , then either $\ S_0=0000\ $ or $\ S_0=1111\ $ , and so either $\ S_1=1111\ $ or $\ S_2=0000\ $ . If the length of $\ S_0$ 's orbit is $2$ then so are those of $\ S_1\ $ and $\ S_2\ $ . Therefore either $\ S_2=0101\ $ or $\ S_2=1010\ $ , the only $4$ -long bit strings with period $2$ . In the first case, $\ S_3=0000\ $ , while in the second, $\ S_3=1111\ $ and $\ S_4=0000\ $ . If the length of $\ S_0$ 's orbit is $4$ and it has even parity , then the length of the orbits of $\ S_1,S_2,S_3\ $ and $\ S_4\ $ will also be $4$ and they will also all have even parity.  Therefore $\ S_4\in\{0011,0110,1100,1001\}\ $ , the set of all $4$ -long bit strings of even parity with an orbit of length $4$ .  Therefore $\ S_5\in\{0000,$$\,0101,$$\,1111,$$\,1010\}\ $ and has an orbit of length $1$ or $2$ . If $\ S_5\ne0000\ $ and we repeat steps $2$ to $4$ as steps $6$ to $9$ , then at least one of $\ S_6, S_7\ $ or $\ S_8\ $ must be $\ 0000\ $ by the same argument as above. This shows that if $\ S_0\ $ has even parity, then at least one of $\ S_1\ $ to $\ S_8\ $ must be $\ 0000\ $ . If $\ S_0\ $ has odd parity, then so do $\ S_1\ $ to $\ S_8\ $ , and therefore $\ S_9\ $ must have even parity.  If $\ S_9\ne0000\ $ , we simply repeat steps $2$ to $8$ as steps $10$ to $16$ , and the same argument as above shows that at least one of $\ S_{10}\ $ to $\ S_{16}\ $ must be $\ 0000\ $ . This completes the proof. My question is ""Can this solution be generalised to a construction of one for any $\ N=2^r\ $ ?"" Progress Some of the progress I've made towards a solution for an arbitrary $\ N=2^r\ $ is included in the above proof for $\ N=4\ $ , in the form of statements that are more general than are actually needed for that special case. Yesterday, I made a key observation which I think will now allow me to generalise the above solution to one for any $\ N=2^r\ $ , and prove that it works. If nobody beats me to it, I'll post the solution in a few days.","['contest-math', 'recreational-mathematics', 'group-theory', 'group-actions', 'problem-solving']"
4682148,Counterexample to isomorphisms between tensor product of finite-dimensional vector spaces,"One of my homework problems required me to prove that If $V$ and $W$ are finite-dimensional vector spaces, then prove that \begin{equation*}
V^{\ast} \otimes W^{\ast} \cong \mathcal{L}(V, W; \mathbb{R}) \cong \mathcal{L}(V \otimes W; \mathbb{R})
\end{equation*} and \begin{equation*}
V^{\ast} \otimes W \cong \mathcal{L}(V; W),
\end{equation*} where $\mathcal{L}(V_1, \ldots, V_n; W)$ means all multilinear maps $f \colon V_{1} \times \ldots \times V_{n} \rightarrow W$ . I was able to prove the above and it required a dimension argument, i. e. used the fact that the vector spaces are finite-dimensional. But then I was trying to come up with an infinite-dimensional example such that the above isomorphisms would fail but I can't seem to find one. I would assume that an example where the dimension of the dual space is larger should do the trick. Is there an obvious straight forward counterexample to the above isomorphisms that I am simply missing?","['linear-algebra', 'vector-spaces', 'differential-geometry']"
4682149,Does every totally ordered set has an upper bound?,"I'm studying Set theory using Halmos's book. I'm wondering whether it is true to state that ""Every totally ordered set has an upper bound"" (no matter it is finite or infinite) ? My intuition is that since the set $S$ is totally ordered, then 2 arbitrary elements $x$ and $y$ are comparable, say $x \leq y$ , then we compare $x$ with $x_1$ , $y$ with $y_1$ , $x$ with $y_1$ , $y$ with $x_1$ to find the correct order of the extension. If we do it ad infinitum, we can eventually order the set $S$ , and find the upper bound of it. But I was not able to give a rigorous proof. Can you please tell me if the statement is correct ? If not can you please give me an example in case it fails ? or eventually a sketch of proof it is true. Many thanks!","['elementary-set-theory', 'set-theory']"
4682170,Find value of $x$ from $f'(x) + Cf(x) = 0$,"I have the following equation: $$
\sum_{i=1}^N \ln (d_i) d_i^{-x} = C \sum_{i=1}^N d_i^{-x}
$$ where $C$ and $d_i$ are constants (known variables). For $N=2$ the equation takes the form $$
\ln (d_1) d_1^{-x} + \ln (d_2) d_2^{-x} = C (d_1^{-x} + d_2^{-x})
$$ and it is possible to solve it analytically for $x$ . My question is whether it is possible to solve the first equation analytically for $N>2$ . In general, this type of equation can be written as: $$
\sum_{i=1}^N g(x_i) f(x_i) = C \sum_{i=1}^N f(x_i)
$$ Edit : from @ancient mathematician we can rewrite $d_i$ to $e^{\lambda_i}$ . Thus, the equation now is defined as $$
\sum_{i=1}^N \lambda_i  e^{-\lambda_i x} = C \sum_{i=1}^N   e^{-\lambda_i x}
$$ We can notice that the left part is the derivative of the right part, such as $$
-\frac{d}{dx} \sum_{i=1}^N  e^{-\lambda_i x} = C \sum_{i=1}^N   e^{-\lambda_i x}
$$ with $f(x) =  \sum_{i=1}^N  e^{-\lambda_i x}$ we have $$
f'(x) + Cf(x) = 0
$$ The task is to find the $x$ from this equation.","['derivatives', 'closed-form']"
4682285,How to solve the differential equation $y'=y/(y+a)+b$,"I am trying to determine the proportion of a quantity $y$ in a mixture of total quantity $y + a$ . I know that the quantity $y$ evolves according to two components: one which is constant $b$ and another one which is proportional to the concentration of $y$ in $y + a$ . I get a weird differential equation where $y'$ depends both on $y$ but also on $1/y$ , so it's not a differential equation per se. Does anyone know how to solve this differential equation or have a trick to make it linear? Thank you so much",['ordinary-differential-equations']
4682292,Does every triangle satisfy $\frac{abc}{R^3} \ln \left(\frac{a}{R}\right)\ln \left(\frac{b}{R}\right)\ln \left(\frac{c}{R}\right) > -\ln 2$?,"If $a,b,c$ are the sides of a triangle inscribed in a circle of radius $R$ . Is it true that $$
\frac{abc}{R^3} \ln \left(\frac{a}{R}\right)\ln\left(\frac{b}{R}\right)\ln \left(\frac{c}{R}\right) 
> - \ln 2 \tag 1
$$ I ran a Monte Carlo simulation for the expression on the LHS and obtained a minima of $- 0.6923259$ after a billion samples. This value is slightly greater than $\ln2 \approx 0.6931$ . Can this proved? Update 1 : Using the insight from the comment made by @Anon we can show the slightly weaker result that LHS $> - \frac{4\ln^2 2}{e} \approx -0.7069951$ . If one side of the triangle is less than $R$ and the other two sides are greater than $R$ then the LHS will be negative. Hence we need to minimize $x \ln x$ for one side and maximize it for the other two sides. The minimum value of $x\ln x$ occurs at $x = \frac{R}{e}$ and for the triangle of circum radius $R$ , since no side can exceed $2R$ hence $x\ln x < \frac{2R}{R} \ln \frac{2R}{R} = 2\ln 2$ . Hence the LHS of $(1)$ must be at least $> - \frac{4\ln^2 2}{e}$ . Update 2 : An improvement of the estimate in update 1 is as follows. If one side of a triangle is $a = \frac{1}{e}$ , what is the maximum possible length of the other sides. Simple algebraic manipulations give $b = c = \sqrt{2 + \sqrt{4 - \frac{1}{e^2}}}$ and substituting these in $(1)$ we get $$
LHS \ge -\frac{1}{e}\left(\sqrt{1 - \frac{1}{2e}} + \sqrt{1 + \frac{1}{2e}}\right)^2
\ln^2 \left(\sqrt{1 - \frac{1}{2e}} + \sqrt{1 + \frac{1}{2e}}\right)
\approx -0.692325
$$ But must be noted that this may not be the minima since the true minima may occur at $a \ne \frac{1}{e}$ . Update 3 : Under the assumption that the minima will occur when the triangle is isosceles, we can prove that the minima is $-0.62918$ as shown by K.defaoite. I have separate and proof which I have posted below.","['euclidean-geometry', 'inequality', 'geometry', 'real-analysis', 'trigonometry']"
4682340,"Suppose $f_1(x)=\sin(1+\sin(x))$, $f_2(x)=\sin(1+\sin(2+\sin(x)))$ and so on. Does $\lim_{n\to\infty}f_n(x)$ eventually become a constant function?","I came across this question on Quora . I'm rephrasing the question in the title. A sequence of functions $\{f_n(x)\}$ is recursively defined such that $f_{n}(x)=f_{n-1}(n+\sin x)$ and $f_0(x)=\sin(x)$ . The question is: Does $\lim\limits_{n\to\infty}{f_n(x)}$ eventually become a constant function? I intuitively thought that the answer is NO . This was my line of reasoning: Whatever be the value of $n$ , if we take a derivative of $f_n(x)$ , we get another function in terms of $x$ . But the derivative of a constant function is supposed to be zero, which is contradiction. However, to my surprise, when I took to Python terminal to code this sequence, I found that the limit converges somewhere around $0.9941666781206763$ irrespective of the value of $x$ (which indicates it's indeed a constant function). >>> from sys import setrecursionlimit
>>> setrecursionlimit(10**5)
>>> f = lambda n, x: f(n-1, n+sin(x)) if n>0 else sin(x)
>>> from math import sin
>>> f(1500, 10)
0.9941666781206763
>>> for x in range(0, 100):
...  print(f(1800, x))
... I believe $n=1800$ iterations is fairly high i.e, sufficient for computing $n\to\infty$ . Can anyone explain what was wrong with my intuition and/or if there's any bug in my code? I am not sure if the latter part of my query is in the scope of this site.","['limits', 'solution-verification', 'recurrence-relations', 'sequences-and-series']"
4682381,"Find center of ellipse provided coordinates of one focus, and point on ellipse with it's tangent","At a point $A(1,1)$ on ellipse, equation of tangent is $y=x$ . If one of the foci of ellipse is $(0,-2)$ and the coordinates of centre of ellipse are $(\alpha,\beta)$ then find the value of $\alpha+\beta$ . It is given that the length of major axis of the ellipse is $4\sqrt{10}$ units. Solution given Let $S(0,-2)$ and $S'$ be foci of ellipse. Then the slope of $AS'=\frac13$ and $AS'=3\sqrt{10}$ So the coordinates of $S'$ will be $(10,4)$ and centre is mid point of $S$ and $S'$ . I understand why the slope of $AS'$ is $\frac13$ but I cannot understand why $AS'$ has to be $3\sqrt{10}$ . If I can prove former, I can easily calculate the coordinates of $S'$ . Please help me. Any help is greatly appreciated.","['euclidean-geometry', 'conic-sections', 'geometry']"
4682382,Does weak convergence in $H^1_0(\Omega)$ imply weak convergence of the weak derivatives in $L^2(\Omega)$?,"Let $\Omega\subset\mathbb{R}^N$ be bounded and consider a sequence of functions $(u_n)_n\subset H^1_0(\Omega)$ such that $u_n\rightharpoonup u\in H^1_0(\Omega)$ . Can we then say that $\partial_i u_n \rightharpoonup \partial_iu$ in $L^2(\Omega)$ for $i=\overline{1,N}$ ? My progress: since the inclusion $H^1_0(\Omega)\subset L^2(\Omega)$ is compact, eventually passing to a subsequence we can assume that $u_n\to u$ in $L^2(\Omega)$ . This allows us to assume that $u_n(x)\to u(x)$ for a.e. $x\in \Omega$ by again eventually passing to a subsequence. I wasn't able to use any of these general facts, I only thought that maybe it is enough to write the definition of $u_n \rightharpoonup u$ in $H^1_0(\Omega)$ , i.e. $$\int_\Omega \nabla u_n\cdot \nabla v \to \int_\Omega \nabla u \cdot \nabla v$$ for all $v\in H^1_0(\Omega)$ . This implies that $$\int_\Omega \partial_i u \cdot \partial_iv\to \int_\Omega \partial_i u \cdot \partial_i v$$ for all $v\in H^1_0(\Omega)$ . Now if for any $w\in L^2(\Omega)$ there would be some $v\in H^1_0(\Omega)$ such that $w=\partial_i v$ , then we would be done. I am not sure if this is true however and I don't know how to proceed.","['sobolev-spaces', 'functional-analysis', 'weak-convergence', 'partial-differential-equations']"
4682386,How to properly define a stochastic process as a random variable valued in the Skorokhod space,"There are different ways to define a (cadlag) stochastic process (I add cadlag because I consider this a minimal requirement for all applications that are relevant to my personal interests). Starting from a probability space $(\Omega,\mathcal{F},\mathsf{P})$ one of the most classical is to consider the product space $\Omega\times[0,\infty)$ equipped with the product sigma-algebra $\mathcal{F}\otimes\mathcal{B}([0,\infty))$ and to define a stochastic process as an application $$
X:\Omega\times[0,\infty)\rightarrow \mathbb{R}
$$ measurable with respect to $\mathcal{B}(\mathbb{R})$ in arrival and $\mathcal{F}\otimes\mathcal{B}([0,\infty))$ in departure. Another possibility (useful for results on functional convergence) is to take the space $\mathbb{D}(\mathbb{R}_{+},\mathbb{R})$ of cadlag functions defined form $\mathbb{R}_{+}=[0,\infty)$ with values in $\mathbb{R}$ equipped with the Skorokhod metric. In this case we associate to each $\omega\in\Omega$ the ""entire trajectory"" and so a stochastic process is an application $$
X:\Omega\rightarrow\mathbb{D}(\mathbb{R}_{+},\mathbb{R})
$$ which is also a random variable once some measurability constraint is imposed. In order to do so: which sigma-algebra is implicitly considered on $\mathbb{D}(\mathbb{R}_{+},\mathbb{R})$ ? I assume that it is the Borel sigma algebra associated with the topology, but I might be mistaken since I did not find an explicit mention of it in the textbooks that I am reading, so any confirmation/disproof is greatly appreciated.","['stochastic-processes', 'measure-theory', 'skorohod-space', 'random-variables']"
4682405,Simplify $\frac{3}2\cos^{-1}\left(\sqrt{\frac{2}{2+\pi^2}}\right)+\frac{1}4 \sin^{-1} (\frac{2 \sqrt 2 \pi}{2+\pi^2}) +\tan^{-1}\frac{\sqrt 2}\pi$,"I have to simplify $$\frac{3}{2}\cos^{-1}\left(\sqrt{\frac{2}{2+{\pi}^2}}\right)+\frac{1}{4} \sin^{-1} \left(\frac{2 \sqrt 2 \pi}{2+{\pi}^2}\right) +\tan^{-1}{\frac{\sqrt2}{\pi}}$$ My attempt:-
Let $\sqrt{\frac{2}{2+{\pi}^2}} =\cos{\theta}$ so that implies: $\sin{\theta}=\frac{\pi}{\sqrt{2+{\pi^2}}}$ similarly $\tan{\theta}=\frac{\pi}{\sqrt2}$ so the original expression simplifies to $$\frac{3}{2} {\theta}+\frac{\theta}{2}+\left(\frac{\pi}{2}-{\theta}\right)$$ Which is $$ \theta +\frac{\pi}{2}$$ which gives $$\frac{\pi}{2} +\cos^{-1}\left(\frac{\sqrt{2}}{\sqrt{2+{\pi^2}}}\right)$$ however, the answer is supposed to be an integer, which this is clearly not. Where am I going wrong? Source:- JEE Advanced 2022, paper 1","['algebra-precalculus', 'trigonometry']"
4682516,Explosive number(s) from $x_{n+1}=\left(1+\frac{1}{x_n}\right)^n$,"I came accross a curiosity I don't fully understand. In an exam, the sequence $\left(x_n\right)$ is introduced such as for all $n \geq 1$ $$
x_{n+1}=\left(1+\frac{1}{x_n}\right)^n
$$ with $x_1 = \alpha \in \left]0;+\infty\right[$ .
It is argued that there exists one number $\alpha^{\ast}$ , and only one,  such that the sequence $\left(x_n\right)$ with $x_1 = \alpha^{\ast}$ diverges towards $+\infty$ . A proof is then proposed where it is shown that $\alpha^{\ast} \approx 1,1874$ . This result triggers my curiosity. I've written a small python script, and I've observed that as soon as $x_{N}$ is ""big"", then $x_{N+1} \approx 1$ . I guess all the mystery is there : how to have $x_{N}$ 'big' without having $x_{N+1} \approx 1$ . For $x_{N}$ big enough, we can write $$
x_{N+1} = e^{N\ln\left(1+\frac{1}{x_N}\right)} = e^{N\left(\frac{1}{x_{N}} - \frac{1}{2x_{N}^2} + o\left(\frac{1}{x_{N}^2}\right)\right)}
$$ So my guess is that $N/x_{N}$ needs to stay low. What I see for example is : \begin{array}
$x_1 & 5 & 1.1874\newline
x_2 & 1.20 & 1.84\newline
x_3 & 3.36 & 2.38\newline
x_4 & 2.18 & 2.86\newline
x_5 & 4.52 & 3.31\newline
x_6 & 2.72 & 3.74\newline
x_7 & 6.55 & 4.14\newline
x_8 & 2.70 & 4.54\newline
x_9 & 12.4 & 4.92\newline
x_{10} & 2.0 & 5.29\newline
\end{array} A pattern clearly emerges with $\alpha = 1.1874$ , where odd and even indexes find a kind of balance. But after some more iterations, the balance is broken : we find $x_{28} = 3.2 \cdot 10^{8}$ and $x_{29} \approx 1.0$ . Does it mean that it is not possible for a program to reproduce this pattern and just preserve it until a given rank ? Is there an equation that could be deduced for $\alpha^{\ast}$ ?",['sequences-and-series']
4682521,Is the number of classes countable in axiomatic set theory?,"I'm recently learning mathematical logic and axiomatic set theory. In Takeuti and Zaring's Introduction to Axiomatic Set Theory Chapter 4, it says For each wff (well formed formula) $\varphi(a, a_1, ... , a_n)$ we will introduce a class symbol $\{x| \varphi(x, a_1, ... , a_n)\}$ ... This seems to imply that a class is just another expression of a well-formed formula. This answer also says a class is a collection of ""all sets which have a property which we can describe in the given language"". My question is, since in the formal language we used to describe set theory there is only countable symbols (finite quantifiers, finite connectives, finite relationships, finite constants, and countable variables), it is obvious that the number of all well formed formulas can only be countable, and since each class is just another expression of wffs, does that mean there are only countable classes in axiomatic set theory? This seems strange to me because people say ""every set is a class"" and the number of sets is  uncountable. Is there an explaination of this apparent contradiction? My guess is my understanding of classes is wrong. If so, could anyone give me a precise definition of a class? update: To be more precise, consider these two questions: Is it true that for every class $A$ , there exists a well formed formula $\varphi(x)$ such that $A = \{x| \varphi(x)\}$ ? Is it true that every subset of natural number set $\mathbb N$ can be described with a finite string (since every wff is at least a finite string of symbols)? If the answers to both questions above are Yes, then it looks strange to me. I want to know which statement above is wrong.","['elementary-set-theory', 'first-order-logic', 'logic', 'set-theory']"
4682525,Prove a function defined on an open ball with radius $1$ is onto a open ball with radius $0.4$,"I use $B_{r}$ to denote an open ball centered at $0$ with radius $r$ . Consider Euclidean metric and a function $$\begin{align}
f:B_{1} \to \mathbb{R}^n
\end{align}$$ with $f(0)=0$ such that $$\begin{align}
\forall x,y\in B_{1}, x\ne y\implies|f(y)-f(x)-(y-x)|<0.1|y-x|  &&(*)
\end{align}$$ I want to show this function is onto ball $B_{0.4}$ . That is, for all $z\in B_{0.4}$ ,there exists an $x$ such that $z=f(x)$ I tried to use $|z|<0.4$ , $f(0)=0$ and $(*)$ . Let $y=0$ and $x\ne 0$ , and use $(*)$ I get $$\begin{align}
|f(x)-x|<0.1|x|<0.1
\end{align}$$ since $x\in B_{1}$ , $|x|<1$ . Since $|f(x)-x|<0.1$ , I can say that $f(x)-x\in B_{0.1}$ Also, I can see the function is injective. However, I can't relate all the things that I have to prove $f$ is onto $B_{0,4}$ , or maybe I miss some hidden information in the problem. Any help on this? Thanks.","['general-topology', 'analysis']"
4682556,"$10$ students, $16$ lessons, each lesson one student is chosen to be asked, probability that every student will be asked after $16$ lessons","$10$ students, $16$ lessons, each lesson one student is chosen to be asked, probability that every student will be asked after $16$ lessons. First solution: Our sample space is strings of length $16$ which takes values in { $1,...,10$ }.
Let $A_k$ be event such that $k$ -th student will be not asked after $16$ lessons. We can compute our desired probability $P(A)$ using inclusion-exclusion principle: $P(A)=1-P(\bigcup_{i=1}^{10}A_i)$ . Second solution: Stars and bars method, think of giving students lessons in which they are asked. To count every possibilities of $10$ students being asked in $16$ lessons it is equivalent to count how many solutions there are to equation $x_1+...+x_{10}=16$ where $x_i\geq0$ , ${16+10-1 \choose 10-1}$ possibilities. To count possibilities in which each student was asked it is equivalent to count how many solutions there are to equation $x_1+...+x_{10}=16$ where $x_i\geq1$ , ${15 \choose 9}$ possibilities, so our desired probability is $$\frac{{15 \choose 9}}{25 \choose 9}$$ I think first method is correct, I am not sure about second. It seems okay but someone told me to not to use stars and bars doing probability. If it is wrong explain why.","['stirling-numbers', 'combinatorics', 'probability-theory', 'probability']"
4682589,Interpreting exterior products as intersection of diagrams,"This paper provides an intuition of $k$ -forms. On page $4$ it reads: ""In order to represent the exterior product of two $n$ -forms you find the intersection of the diagrams representing the forms. For example if we draw $dx$ as vertical lines and $dy$ as horizontal lines then $dx ∧ dy$ is the set of intersection points which will form a uniform grid."" Why can the exterior product of two forms be interepreted as the intersection of the diagrams representing the forms? This is a follow-up to this post .","['analysis', 'multivariable-calculus', 'intuition', 'differential-forms', 'differential-geometry']"
4682623,"Is there a general formula for $ (x + y)^m$? where m is an nonnegative integer number , and x and y are non - commutative .","We know that if x and y are commutative, we get the following result $$
(x+y)^m = \sum\limits_{k=0}^m \binom{m}{k} x^k y^{m-k}
$$ for nonnegative integer number m. But is there a general formula for the above expression if x and y are non-commutative?","['number-theory', 'calculus', 'abstract-algebra', 'discrete-mathematics', 'algebra-precalculus']"
4682670,Why is the Eisenstein series $G_2$ a quasimodular form?,"For even $k \geq 4$ , the Eisenstein series \begin{align*}
G_k(\tau) &=  \sum_{(n, m)\in \mathbb{Z}^2} \frac{1}{(m + n\tau)^k}
\end{align*} (omitting the term $(n, m) = (0, 0)$ ) is a modular form of weight $k$ for $\Gamma = SL_2(\mathbb{Z})$ , and in fact the ring of modular forms of $\Gamma$ is just $\mathbb{C}[E_4, E_6]$ . The usual proof involving rearranging the double series over $n$ and $m$ , which fails to converge compactly for the case $k = 2$ . Still, $G_2$ is reasonably close to a modular form; it satisfies $G_2(-1/\tau) = \tau^2 G_2(\tau) + \alpha \tau$ for some constant $\alpha\not = 0$ , and the graded ring $M_* = \mathbb{C}[G_2, G_4, G_6]$ is closed under the operator $D \vert M_k = \frac{1}{2\pi i} \frac{d}{dq} + \beta k$ for some constant $\beta$ . All this is easy enough to prove directly, but is there some deeper reason why $G_2$ is a quasimodular form? That is, why is $G_2$ still very close to being a modular form despite the bad behavior of the series above for $k = 2$ ; or, conversely, why doesn't $\Gamma$ have any modular forms of weight $2$ despite having a reasonable candidate in $G_2$ ?","['complex-analysis', 'modular-forms', 'analytic-number-theory']"
4682713,Mathematical Paradox: How Can The Center of a Shape Be Located OUTSIDE This Shape?,"Recently I have been learning about Geospatial Analysis in which we are often interested in using computer software to analyze the mathematical properties and characteristics of polygons (e.g. calculating their centroids). For example, using the R programming language, I downloaded a geospatial file of Canada that is broken up into different ""polygons"" - I then attempted to calculate the centroids of each of these polygons and visualize the results. Here the Code : library(dplyr)
    library(sf)
    library(data.table)
    library(rvest)
    library(leaflet)
    library(ggplot2)
    library(urltools)
    library(leaflet.extras)
    library(stringr)
    library(magrittr)
    
    
    # Download zip files
    url_1 <- ""https://www12.statcan.gc.ca/census-recensement/alternative_alternatif.cfm?l=eng&dispext=zip&teng=lada000b21a_e.zip&k=%20%20%20151162&loc=//www12.statcan.gc.ca/census-recensement/2021/geo/sip-pis/boundary-limites/files-fichiers/lada000b21a_e.zip""
    
    
    download.file(url_1, destfile = ""lada000b21a_e.zip"")
    
    # Extract zip files
    unzip(""lada000b21a_e.zip"")
    
    # Read shapefiles
    ada <- st_read(""lada000b21a_e.shp"")
    
    shapefile_1 = ada %>% st_transform(32617)
    #sf_cent <- st_centroid(shapefile_1)
    
    sf_cent <- st_point_on_surface(shapefile_1)
    
    # Transform the centroids to the WGS84 CRS
    sf_cent_geo <- st_transform(sf_cent, crs = 4326)
    
    
    # Extract the longitude and latitude coordinates of the centroids
    lon <- st_coordinates(sf_cent_geo)[,1]
    lat <- st_coordinates(sf_cent_geo)[,2]
    
    ADAUID <- sf_cent_geo$ADAUID
    lon <- st_coordinates(sf_cent_geo)[,1]
    lat <- st_coordinates(sf_cent_geo)[,2]
    
    shapefile_1 = ada %>% st_transform(32617)
    sf_cent <- st_centroid(ada)
    
    ggplot() + 
        geom_sf(data = shapefile_1, fill = 'white') +
        geom_sf(data = sf_cent, color = 'red') The results look something like this: As we can see, some of these polygons appear to have multiple centroids (""red points"") - this means the centroids for some of these polygons are located outside of these polygons themselves! Based on these two references here ( https://en.wikipedia.org/wiki/Shoelace_formula , https://en.wikipedia.org/wiki/Centroid ), the formula for calculating the centroid of a polygon can be written as such (based on the area of the polygon): $$A = \frac{1}{2} | \sum_{i=1}^n (x_i y_{i+1} - x_{i+1} y_i) |$$ $$C_x = \frac{1}{6A} \sum_{i=0}^{n-1} ((x_i + x_{i+1}) (x_i y_{i+1} - x_{i+1} y_i))$$ $$C_y = \frac{1}{6A} \sum_{i=0}^{n-1} ((y_i + y_{i+1}) (x_i y_{i+1} - x_{i+1} y_i))$$ My Question: Is it possible to mathematically prove that sometimes $C_x$ and $C_y$ can be located outside the perimeter of the polygon that they belong to? Otherwise, how else is it possible that the centroid of a polygon can be located outside of the polygon itself? Thanks!","['centroid', 'geometry']"
4682720,Are there finite dimensional matrices for which $e^{A+B}=e^Ae^B$ when $A$ and $B$ do not commute?,"If we have square matrices $A$ and $B$ that commute (i.e. $AB=BA$ ), then we have $e^{A+B} = e^Ae^B$ . In general this isn't true without the condition that $A$ and $B$ commute. I would like to know if this is ""if and only if"", or whether $A$ commuting with $B$ is just a necessary condition. In other words, do there exist square matrices $A$ and $B$ such that $AB\ne BA$ but $e^{A+B} = e^A e^B$ ? Not that it really matters because this question already got a very good answer, but I don't think this should be considered a duplicate of Does $e^{a+b}=e^{a}e^{b}$ implies that $ab=ba$ for banach algebras? , because that question is about Banach algebras whereas mine is only about ordinary finite-dimensional matrices. Neither is it a duplicate of If $e^A$ and $e^B$ commute, do $A$ and $B$ commute for finite dimensional matrices? (of which Does $e^{a+b}=e^{a}e^{b}$ implies that $ab=ba$ for banach algebras? itself is closed as a duplicate), because that is clearly just a different question.","['matrices', 'matrix-exponential', 'linear-algebra']"
4682727,How do I approach mathematical proofs involving nested if-then statements?,"I'm new to proofs and trying to prove the following statement. I already have trouble writing the ""automatic parts"" of the proof at the beginning because I'm not sure what assumptions I can and should make given the nested if-then statements. I am finding that particularly confusing. Is there an algorithmic strategic approach to generally proving nested if-then-statements so that it's easier to see what should be defined and assumed in the beginning? Here is the statement: Let $A,B$ be sets and let $f: A \rightarrow B$ be a function. If, for all $W,X \subseteq A$ , if $f(W) \subseteq f(X)$ , then $W \subseteq X$ , then $f$ is injective. I try breaking this down to the general form $(P \Rightarrow Q)\Rightarrow R$ such that P: ""for all $W,X \subseteq A$ , $f(W) \subseteq f(X)$ "" Q: "" $W \subseteq X$ "" R: "" $f$ is injective"" My proof is then as follows (line-for-line): (1) Suppose for all $W,X \subseteq A$ , if $f(W) \subseteq f(X)$ , then $W \subseteq X$ . (2) Suppose $f(W) \subseteq f(X)$ . (3) Let $y \in f(W)$ . (4) Then, for all $y \in f(W)$ , there exists $w \in W$ such that $f(w) = y$ . (5) Since $f(W) \subseteq f(X)$ , it follows that $y \in f(X)$ as well. (6) So, there exists $x \in X$ such that $f(x) = y$ . (7) Hence, $f(w)=f(x)$ . (8) Based on the initial assumptions, from $f(W) \subseteq f(X)$ follows that $W \subseteq X$ . (9) So, $w \in X$ . So, I have $f(w)=f(x)$ and $x,w \in X$ . Since I'm trying to prove that $f$ is injective, I need to show that $x=w$ but I'm not seeing how to explicitly show this. My suspicion is that I might've already messed up at the very beginning because the nested if-then statements tend to give me trouble. Any help would be greatly appreciated. EDIT Thanks to everyone for suggestions and corrections. I believe that I now have a decent proof. Here again the statement: Let $A,B$ be sets and let $f: A \rightarrow B$ be a function. If, for all $W,X \subseteq A$ , if $f(W) \subseteq f(X)$ , then $W \subseteq X$ , then $f$ is injective. And the proof: (1) Suppose for all $W, X \subseteq A$ , if $f(W) \subseteq f(X)$ , then $W \subseteq X$ . (2) Let $x, w \in A$ and suppose $f(x) = f(w)$ . (3) Let $W = \{w\}$ and $X = \{x\}$ . (4) Note that $f(W)=f(\{w\})=\{f(w)\}$ and $f(X)=f(\{x\})=\{f(x)\}$ . (5) Since $f(w) = f(x)$ , it follows that $\{f(w)\} \subseteq \{f(x)\}$ , i.e., $f(W) \subseteq f(X)$ . (6) So, by the initial assumption, $W \subseteq X$ , i.e., $\{w\} \subseteq \{x\}$ . (7) Hence, $w = x$ and so $f$ is injective. $\square$","['proof-writing', 'logic', 'analysis']"
4682758,Bounding the variance.,"Let, $X_1, X_2, \dots, X_n$ be independent random variables, where $X_j$ is Bernoulli with parameter $p_j \in [0,1]$ .
Let, $g(x_1, x_2, \dots, x_n)$ be a function, satisfying the bounded difference condition with constants $c_1, c_2, \dots, c_n > 0$ . I am trying to show that $$Var(g(X_1, X_2, \dots, X_n)) \leq \sum_{j=1}^n c_j^2p_j(1-p_j)$$ where $X_1, X_2, \dots, X_n$ be independent random variables, $X_j$ is Bernoulli with parameter $p_j \in [0,1]$ . The function $g(x_1, x_2, \dots, x_n)$ satisfies bounded difference condition with constants $c_1, c_2, \dots, c_n > 0$ . I know that if the random variables satisfy Bounded Difference Condition; the following holds true $$|g(x_1,\dots, x_{j-1},x_j,x_{j+1}, \dots, x_n) - g(x_1,\dots, x_{j-1},x_j',x_{j+1}, \dots, x_n)| \leq c_j$$ where $x_j'$ is an independent copy of $x_j$ . Under this condition one can also show that $Var(g(x_1,\dots,x_n)) \leq \frac{1}{4} \sum_{j=1}^nc_j^2$ . Furthermore, by Efron-Stein inequality, $$Var(g(x_1,\dots,x_n)) \leq \frac{1}{2} \mathbb{E}\sum_{j=1}^n\bigg( g(x_1,\dots,x_j,\dots ,x_n) - g(x_1,\dots,x_j',\dots ,x_n)\bigg)^2$$ From the BDC above this inequality becomes; $$Var(g(x_1,\dots,x_n)) \leq \frac{1}{2} \mathbb{E}\sum_{j=1}^nc_j^2 = \frac{1}{2}\sum_{j=1}^n c_j^2$$ I am still missing the factor $p_j(1-p_j)$ which is basically $Var(X_j)$ . But I am not sure how to incorporate this term.
Can anyone please drop a hint on how to prove this?","['statistics', 'probability-distributions', 'probability-theory']"
4682801,History of the general formula for linearising $\cos^n(x)$,"I was wondering where the formula: $$\cos^n(x)=\sum_{k=0}^n\frac{n!}{k!(n-k)!}\cos(x(2k-n))$$ Was first originally published. I accidentally derived it a few days ago and was wondering where it was first established for historical context. I derived it in the following way: Using Euler's formulas, we can write $\cos^n(x)$ out as: $$\cos^n(x)=\frac{1}{2^n}(e^{ix}+e^{-ix})^n$$ Which, when expanded using Newton's binomial formula yields: $$\cos^n(x)=\frac{1}{2^n}\sum_{k=0}^n\frac{n!}{k!(n-k)!}e^{ikx}\cdot e^{-ix(n-k)}$$ Which simplifies down to: $$\cos^n(x)=\frac{1}{2^n}\left(\sum_{k=0}^n(\frac{n!}{k!(n-k)!}\cos(x(2k-n)))+i\sum_{k=0}^n(\frac{n!}{k!(n-k)!}\sin(x(2k-n)))\right)$$ $$=\frac{1}{2^n}C_n+\frac{i}{2^n}S_n$$ Because $S_n\in\mathbb{R}$ we can write that $\Im(\cos^n(x))=S_n=0$ And consequently we yield: $$\cos^n(x)=\frac{1}{2^n}\sum_{k=0}^n\frac{n!}{k!(n-k)!}\cos(x(2k-n))$$ Where does this originally come from? I'm sure it's been done before but I've looked everywhere and can't find it at all. This is as usual purely recreational.","['trigonometry', 'math-history', 'summation', 'complex-numbers']"
4682833,Suggestions on improving my proof of a basic equivalence class property?,"I am currently brushing up on some very basic set theory, as I've been away from proof writing and such for a few years.  The statement I wrote a proof for is: If $\sim$ is an equivalence relation on a set $X$ then $[x]\neq[y]\iff[x]\cap[y]=\emptyset$ . For context, I wrote this statement myself (another skillset I am rebuilding) and recognize that it comes off as a bit awkward (although I believe it is a true statement). In any case, here is the proof I wrote.  I am looking for general advice regarding clarity and conciseness, as well as any suggestions on what I may add or remove to make this proof stronger.  Of course, if there are any errors please point those out! Proof. ( $\Rightarrow$ )  Let $X$ be a set with equivalence relation $\sim$ .
For $x,y\in X$ assume that $$[x]\neq[y].$$ Suppose towards a
contradiction that $[x]\cap[y]\neq\emptyset$ .  If this intersection is
nonempty, then there is some $z$ such that $z\in[x]$ and $z\in[y]$ . By
definition of equivalence class, $z\in[x]$ implies that $z\sim x$ and,
similarly, $z\in[y]$ implies that $z\sim y$ .  Since $\sim$ is
transitive, this means that $x\sim y$ .  Therefore $x\sim a$ for all $a\in[y]$ and $y\sim b$ for all $b\in[x]$ .  Thus $[x]=[y]$ , a
contradiction. ( $\Leftarrow$ )  Suppose that $[x]\cap[y]=\emptyset$ .  Assume towards a
contradiction that $[x]=[y]$ . If $z\in[x]$ then $z\in[y]$ by definition of set equality.  Thus $z\in[x]\cap[y]$ , a contradiction. $\blacksquare$ Thank you for your time and assistance.","['elementary-set-theory', 'equivalence-relations', 'solution-verification']"
4682842,"The distance $d(\mu_1,\mu_2):=\int \left|\frac{d\mu_1}{d\nu}-\frac{d\mu_2}{d\nu}\right|d\nu$ doesn't depend on $\nu$. Why?","I have the following problem. Define the variation distance as $$d(\mu_1,\mu_2):=\int \left|\frac{d\mu_1}{d\nu}-\frac{d\mu_2}{d\nu}\right|d\nu,$$ where $\mu_1$ , $\mu_2$ e $\nu$ are probability measure on $(\Omega,\mathcal{F})$ , such that $\mu_1\ll \nu$ and $\mu_2\ll \nu$ . I want to show that the distance $d$ doesn't depend on $\nu$ .
My idea is to show that $$\int \left|\frac{d\mu_1}{d\nu}-\frac{d\mu_2}{d\nu}\right|d\nu=\sup \sum_{i}|\mu_1(E_i)-\mu_2(E_i)|,$$ where the supremum is taken over all $\mathcal{F}$ -measurable partitions $(E_i)_i$ of $\Omega$ . The $""\geq""$ is easy: $$\sup \sum_{i}|\mu_1(E_i)-\mu_2(E_i)|=\sup \sum_{i}\left|\int_{E_i}d\mu_1-\int_{E_i}d\mu_2\right|=\sup \sum_{i}\left|\int_{E_i}\frac{d\mu_1}{d\nu}-\frac{d\mu_2}{d\nu}d\nu\right|\leq$$ $$\leq \sup \sum_{i}\int_{E_i}\left|\frac{d\mu_1}{d\nu}-\frac{d\mu_2}{d\nu}\right|d\nu=\int \left|\frac{d\mu_1}{d\nu}-\frac{d\mu_2}{d\nu}\right|d\nu.$$ So we have $$\int \left|\frac{d\mu_1}{d\nu}-\frac{d\mu_2}{d\nu}\right|d\nu\geq\sup \sum_{i}|\mu_1(E_i)-\mu_2(E_i)|.$$ Now, I don't know how to show the other inequality.","['measure-theory', 'probability-distributions', 'probability-theory', 'probability']"
4682854,Boundedness of a simple differential equation's solution,"I have a simple problem that I encountered when I was trying to prove the boundedness of a function created from a smooth manifold. The problem is simplified to the next general statement:
Let $f:(-\infty,\infty)\to (-\infty,\infty)$ be a bounded, $C^{\infty}$ -class function.
Suppose $\frac{d^nf}{dt^n}<\infty$ for any $n=1,2,...$ . Then, is the function below bounded from above? $$
g(x)=\int_0^x\left(\frac{df}{dt}\right)^3dt,\quad x\in[0,\infty).
$$ If the function is monotonically increasing, the answer is ""yes"" since if we let $|f|<N_0$ and $\left|\frac{df}{dt}\right|<N_1$ , then $$
g(x)\le N_1^2\int_0^x\left|\frac{df}{dt}\right|dt=N_1^2\int_0^x\frac{df}{dt}dt=N_1^2(f(x)-f(0))\le 2N_1^2N_0.
$$ I can't figure out if the statement is true when $f$ is not monotonical. I am a student in the field of differential geometry so any advice would be great.","['integration', 'functions', 'derivatives', 'ordinary-differential-equations']"
4682867,Rigorous and purely geometric definition of sine and cosine,"I'd like to revisit a question that has been brought up a couple of times here on math.stackexchange, yet as far as I'm aware, nobody has come up with a final answer. The question is: Is it possible to give a rigorous definition of sine and cosine not using the power series approach? One of my beginners courses at the university for example did like that: They gave us the intuitive definition of sine and cosine using the unit circle. The explicitly mentioned that these definitions were dependent on arc length, whose definition they would omit here though but rather rely on intuition. Then they said, the following properties could (in theory) be proved but to avoid the above mentioned challenges, they'd rather introduce them as axioms: Sine and cosine are defined on the real domain and are continuous. Sine is an odd and cosine an even function. They would abide to the respective addition formulas. $\lim_{x \to 0} \frac{\sin(x)}{x} = 1$ . $\cos(0) = 1$ . They then state that these five axioms already uniquely define a pair of functions. In other words, if a pair of functions are subject to the five axioms, they are the sine and the cosine. Eventually, the introduce the well-known power series for both sine and cosine and show that they abide to the axioms and hence we know, they are the sine and the cosine. When you try to prove the five ""axioms"" then all difficulties are related to the arc length. The usual way to introduce the arc length would require me to know the derivate of sine and cosine but using that is prohibitive here as we have not yet defined sine and cosine. To cut a long story short: Can be done and has it been done by someone? A purely geometrical yet rigorous definition of sine and cosine or can it proved that it's doomed to fail as the circular dependencies can't be avoided? Looking forward to your feedback!","['trigonometry', 'geometry']"
4682907,Prove $\int_{0}^{1} \frac{k^{\frac34}}{(1-k^2)^\frac38} K(k)\text{d}k=\frac{\pi^2}{12}\sqrt{5+\frac{1}{\sqrt{2} } }$,"The paper mentioned a proposition: $$
\int_{0}^{1} \frac{k^{\frac34}}{(1-k^2)^\frac38}
K(k)\text{d}k=\frac{\pi^2}{12}\sqrt{5+\frac{1}{\sqrt{2} } }.
$$ Its equivalent is $$
\int_{0}^{\infty}\vartheta_2(q)^3\vartheta_4(q)^2
\sqrt{\vartheta_2(q)\vartheta_4(q)}\text{d}x
=\frac{1}{3} \sqrt{5+\frac{1}{\sqrt{2} } }.
$$ I think that there is a $L$ -series satisfying $$
\int_{0}^{\infty}x^{s-1}\vartheta_2(q)^3\vartheta_4(q)^2
\sqrt{\vartheta_2(q)\vartheta_4(q)}\text{d}x
=L_f(s)\Gamma(s)\times\text{other components}.
$$","['integration', 'definite-integrals', 'real-analysis', 'dirichlet-series', 'elliptic-integrals']"
