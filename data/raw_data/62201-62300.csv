question_id,title,body,tags
705270,Absolute inequality question.,"I'm stuck with this kind of absolute inequality: $$|x+1|>x+2.  \tag1$$ Firstly, when I solve this one: $$|x+1|=x+2, \tag2$$ I make sure the right side of the equation is greater than zero; 
Condition: $$x+2\ge0;\quad x\ge-2.$$ When I solve this by separating it in two cases and finding a solution, I get, in this example: $x=-1.5$, which belongs to the interval of $[-2,+\infty)$, so it's the right solution. However, when I solve the first inequality $(1)$, I get the solution: $$x<-1.5$$. $-1.5$ is in the interval of the condition for the equation $(1)$ (which is the same for the second one -- the inequality): $[-2,+\infty )$, therefore, the WHOLE interval of $(-∞, -1.5)$ is the solution. Is this the right way of solving this kind of inequality? Thanks in advance.",['algebra-precalculus']
705271,Open and connected in $R^n$ revised,"I am trying to understand the following: If we have an open and connected set in $R^n$ then it can be connected with line segments parallel to the axes. I managed to prove this:
 If a set $U$ is open and connected in $\mathbb{R}^n$ then we can prove it is polygonally connected(there is a path formed from line segments completely contained in $U$). My question now is how would I modify the path such that the line segments remain in $U$ and they are now parallel to the axes? I would very much appreciate some help.
Thank you!","['connectedness', 'multivariable-calculus', 'real-analysis', 'analysis']"
705282,"What is the convex-hull of the set $\{ (n,\varphi(n)) : n\in \mathbb N \} \subset \mathbb R^2$","I know that set
$$
E=\{ (n,\varphi(n)) : n\in \mathbb N \} \subset \mathbb R^2
$$
has infinitely many points on the line $y=x-1$, which suggests this line to be included in the upper part of the convex-hull. However I don't really see what's going on at the bottom. That is what is the convex-hull of $E$? Thanks.","['number-theory', 'analysis']"
705327,How many vertices does this tree have?,"Suppose that $T$ is a tree. It has $e$ edges and $n$ vertices, and
  $\overline{T}$ has $10e$ edges. What is n? I think $n = 1$ is a solution, because $T$ can have no edges then, so $0=10*0$. A tree with $n$ vertices has $n-1$ edges. So it's complimentary has $n(n-1) - (n-1) = (n-1)^2$ edges. Therefore, I think, solutions of
$$10(n-1)=(n-1)^2$$ are the $n$'s that fulfill the requirements. So $n=1$ comes this way as well. And there is another possible solution, $n=11$. Is this the right solution? If so, is there a better way to come to the same conclusion?","['graph-theory', 'discrete-mathematics', 'trees']"
705334,Spectrum of idempotent element,"Let $A$ be some unitary algebra over $\mathbb{C}$. If $a^2=a$ and $0\ne a\ne 1$ then $\{0,1\}\subset \sigma_A(a)$ ($\sigma_A(a)$ is the spectrum if $a$). I believe that also $\sigma_A(a)\subset \{0,1\}$. For examlpe, if $A=\mathbb{C}\times\mathbb{C}\times...\times\mathbb{C}$ with pointwise multiplication then each idempotent is $(\epsilon_1,\epsilon_2,...,\epsilon_n)$ where $\epsilon_i\in \{0,1\}$ and $(\epsilon_1-\lambda,\epsilon_2-\lambda,...,\epsilon_n-\lambda)$ is invertible iff $\epsilon_i\ne \lambda$ i.e. $\lambda\notin \{0,1\}$. Also, if $K\subset \mathbb{R}^2$ is a compact set then the space of continuous functions $A=C(K,\mathbb{C})$ is also a $\mathbb{C}$-algebra and $f$ is idempotent iff $f(K)\subset \{0,1\}$. But $\sigma_A(f)=f(K)$. First, I am stuck on to find some easy trick to prove that the spectrum of an idempotent element (not $0$ and not $1$) is $\{0,1\}$. Secondly, this statement is easy for $\mathbb{C}^S$ (this is the algebra of all functions and $\sigma(f)=f(S)$), perhaps there is a nice way to reduce our problem to the case of $\mathbb{C}^S$?","['banach-algebras', 'linear-algebra', 'spectral-theory', 'idempotents', 'functional-analysis']"
705371,When does $e^z + e^{-z} = 0$?,"Here's what I have so far: Let $e^z + e^{-z} = 0$.  Then $e^x\cos y + ie^x\sin y + e^{-x}\cos y - ie^{-x}\sin y = 0$. The simplification in the second term follows because I know $\cos(y) = \cos(-y)$ and $\sin(y) = -\sin(y)$. Am I going about this the right way? Not totally sure how to simplify from here... Thanks for the help,
Mariogs",['complex-analysis']
705379,Differentiable function with non-differentiable inverse,"Is it possible to define a bijective function $f: \mathbb{R} \to \mathbb{R}$ that is differentiable at a point $x_0$ such that $f'(x_0) \ne 0$ , but $f^{-1}$ is not differentiable at $f(x_0)$ ? I think it is possible and I was trying to split functions for rationals and irrationals but most of those functions fail to be bijective. Any ideas?","['calculus', 'derivatives', 'real-analysis']"
705393,How can I solve this equation $3x^5-x^2/2+x+1=0$,"Maybe I am just too tired, but I dont know how to solve this?? Can you point me in right direction. Thanks!!!",['functions']
705408,Geometry of the Cayley Transform,"I'm trying to understand the geometry of the Cayley transform. Suppose I have a $3 \times 3$ rotation matrix $R$ (i.e an orthogonal matrix with determinant equal to $1$ ). Let's ignore the corner case where $-1$ is an eigenvalue of $R$ (in other words, we assume that the rotation angle is not $\pi$ ). Then, according to a result of Cayley , I can find a skew symmetric matrix $S$ such that $$
R = (I - S)(I + S)^{-1}
$$ In other words, I can find two other transformations $A = I - S$ and $B= (I + S)^{-1}$ whose combined effect, when applied one after the other, is the same as the original rotation. My question is: Can we find some geometric interpretation of the transforms $S$ and $A$ and $B$ , so that we can see how they combine to produce a rotation. I know that a rotation can be written as a product of two reflections. Is that related to the Cayley decomposition $R = AB$ ? Are $A$ and $B$ reflections? The 3-dimensional case is the only one that's of interest to me. Edit: Some Progress I made some progress on the algebra, but not the geometry. Suppose our matrix $R$ corresponds to a rotation through an angle $\theta$ around the unit vector $\mathbf{n} = (u,v,w)$ . Let $t = \tan\tfrac12\theta$ . Then I managed to show that  the Cayley decomposition is given by $R = A \cdot B$ , where $$
S = 
\left[
\begin{matrix}
 0 & t w & -t v \\
 -t w & 0 & t u \\
 t v & -t u & 0  
\end{matrix}
\right]
$$ $$
A = I - S =
\left[
\begin{matrix}
 1 & -t w & t v \\
 t w & 1 & -t u \\
 -t v & t u & 1  
\end{matrix}
\right]
$$ $$
B = (I + S)^{-1} = \frac{1}{1+t^2}
\left[
\begin{matrix}
 t^2 u^2+1 & t (t u v-w) & t (v+t u w) \\
 t (t u v+w) & t^2 v^2+1 & t (t v w-u) \\
 t (t u w-v) & t (u+t v w) & t^2 w^2+1  
\end{matrix}
\right]
$$ We have $\det(A) = 1+ t^2$ and $\det(B) = 1/(1+t^2)$ , so neither $A$ nor $B$ is a rotation or a reflection. I still don't see the geometry of $A$ and $B$ , though. That's the puzzle.","['matrices', 'geometry', 'linear-algebra', 'rotations']"
705420,"A regularity result for a parabolic PDE? Want $u' \in L^\infty((0,T)\times \Omega)$","Let $f \in L^\infty((0,T)\times \Omega)$ and let $g \in L^\infty((0,T)\times \Omega)$ satisfy 
$$0 < a \leq g(x,t) \leq b\quad\text{for all $(x,t)$}$$
$$\frac{dg}{dt} \in L^\infty((0,T)\times \Omega).$$ We know that there exists a function $u \in L^2(0,T;H^1)\cap H^1(0,T;H^{-1}(\Omega))$ such that
$$\int_0^T \int_\Omega u'(t) \varphi(t) + \int_0^T \int_\Omega g(t)\nabla u(t) \nabla \varphi(t) = \int_0^T\int_\Omega f(t)\varphi(t)$$
for all $\varphi \in L^2(0,T;H^1(\Omega))$ and $u$ satisfies $u(0) = u_0$ for a given $u_0 \in L^2(\Omega)$. My question is, if we know that $u_0 \in L^\infty(\Omega)$, does it follow that $u' \in L^\infty((0,T) \times \Omega)$? I.e. do we have the expected regularity of $u$? We expect this because $f$ is appropriately regular and as is $u_0$ so we expect the same for $u'$. If so can anyone refer me to a citation for this result? Thank you. If not, what additional smoothness do I need? Let us assume $\Omega$ is as nice as required.","['sobolev-spaces', 'partial-differential-equations', 'reference-request', 'functional-analysis', 'bochner-spaces']"
705447,Inclusion and Exclusion Word Problem: Discrete Math,"I am having trouble understanding how to solve this question: Some five courses are offered in a semester. The group of students who take at least
one of these courses consists of 155 students. There are 80 students registered in each
course. For any two among these courses, there are precisely 40 students who take
each of them. For any three of these courses, there are precisely 20 students who take
each of them. For any four among these courses, there are precisely 10 students who
take each of them. How many students in this group take every one among the five
courses in this semester? What I came up with is using a diagram I created to try and figure the problem out. Course 1: has 40 people unaccounted for. Course 2: has 30 people unaccounted for. Courses 3 & 4 & 5: has 50 people unaccounted for. By this process, only 30 people can take all five classes, but that leaves out 10 people in course 1 and 20 people in courses 3, 4 and 5. This question comes from some inclusion/exclusion notes from my professor. The notes don't really explain inclusion/exclusion very well, or at least I don't understand it. What am I missing? Can someone help me understand how to solve this question?","['inclusion-exclusion', 'discrete-mathematics']"
705456,Consider $f(z)=e^{-z^{-4}}$ for $z≠0$ and $f(0)=0$. Show that the Cauchy Riemann equations are satisfied for $z=0$,"Consider $$f(z)=e^{-z^{-4}}$$ for $z≠0$ and $f(0)=0$. Show that the
  Cauchy Riemann equations are satisfied for $z=0$, and show that $f$ is
  not complex differentiable. Any smart ideas here ? I hope there is some nicer method than just exanpding $(x+iy)^{-4}$.",['complex-analysis']
705471,Continuity of Real Number line,"What is the property of real numbers that allows them to be seen as a continuous line, and how natural numbers, rational numbers lack this property?","['real-numbers', 'real-analysis']"
705473,Show simplicial complex is Hausdorff,"I have a simplicial complex $K$ and I need to show that its topological realisation $|K|$ is Hausdorff. And $K$ need not be finite. I have very little idea on how to get started on this. Only that if $x,y \in |K|$, I need to find disjoint open sets containing $x$ and $y$. I also know $|K|$ is a quotient space formed by ""glueing"" simplices together along their faces, so I have the quotient collapsing map, $p: K \to |K|$ and so my open sets $U, V$ are open iff their pre-images under this map are open. Any help on how to get started would be much appreciated.","['general-topology', 'simplicial-stuff', 'separation-axioms']"
705486,Does continuity imply existence of one sided derivatives?,"From what I understand a derivative may not exist at a given point if the function is not continuous or the right and left side derivatives are not equal.
Does that imply that if a function is continuous, the one sided derivatives exist at it's every point?","['calculus', 'derivatives', 'real-analysis']"
705490,Help in showing that $f:M\rightarrow \mathbb{R}$ has atleast two critical points,"Here is the question: Let M be a compact smooth manifold, $f:M\rightarrow\mathbb{R}$ be a smooth non-constant function. Show that $f$ has at least two critical points. I am trying to show by contradiction. Suppose $f$ has less than two critical points. First assume it has none. By Inverse Function Theorem, for $x\in M$, there is an open neighbourhood $U $ containing $x$ such that $f|_U$ is a diffeomorphism. This means $f$ is an open map. Thus, $f(M)$ is open. But this is contradiction to the fact that $f(M)$ is compact (since $f$ is cont's and $M$ is compact). Is this fine? Now I don't know how to show that there cannot be only one critical point. Only after proving this, I will be done. Some-where I should be using that $f$ is non-constant. I don't know how. I understand that if $f$ is a constant function, then every point in $M$ is trivially critical. Intuitively I don't understand why compactness is used. I am trying to find an example of non-compact smooth manifold $M$ and a smooth map $f:M\rightarrow \mathbb{R}$ that has no critical points. I will appreciate any hint for this too.","['general-topology', 'manifolds']"
705493,A theorem about conditional expectation in C*-algebra,"Definition 1. Let $B\subset A$ be C*-algebra. A projection from A onto B is a linear map $E: A \rightarrow B$ such that $E(b)=b$ for every $b\in B$. A conditional expectation from A onto B is a contractive completely positive projection $E$ from $A$ onto $B$ such that $E(bxb')=bE(x)b'$ for every $x\in A$ and $b, b'\in B$. Theorem 2 (Tomiyama). Let $B\subset A$ be C*-algebra and $E$ be a projection from $A$ onto $B$. Then, the following are equivalent: (1) $E$ is a conditional expectation; (2) $E$ is contractive completely positive; (3) $E$ is contractive. Proof. We only have to prove that the last condition implies the first, so assume $E$ is contractive. Passing to double duals, we may assume that $A$ and $B$ are von Neumann algebras. We first prove that $E$ satisfies $E(bxb')=bE(x)b'$ for every $x\in A$ and $b, b'\in B$.......... My question: I can not understand why we can regard a C*-algebra as a von Neumann algebra? Could someone explain to me in detail? Many thanks.","['c-star-algebras', 'operator-algebras', 'von-neumann-algebras', 'functional-analysis']"
705523,Prove that {$a ∈ ℤ : a ≤ k$} has a greatest element,"How can I prove that the set {$a ∈ ℤ : a ≤ k$}, where $k∈ℝ$, has a greatest element? I have tried using the Well-ordering theorem in order to get a contradiction but I'm having trouble with my approach. Thanks.",['elementary-set-theory']
705527,Jordan form example clarification,"I am practicing Jordan forms and came across the following example: $$A=\left(\begin{array}{rrr} 1&1&1\\-1&-1&-1\\1&1&1\end{array}\right).$$ 
Jordan canonical form is $J=\begin{pmatrix}0&0&0\\0&0&0\\0&0&1\end{pmatrix}$. My question is shouldn't $J=\begin{pmatrix}0&1&0\\0&0&0\\0&0&1\end{pmatrix}$ be the Jordan form? I computed the eigenvalues which are 0 (multiplicity 2) and 1 (multiplicity 1). Now because of multiplicity 1 the block containing eigenvalue 1 is $1\times1$ matrix. With 0 we find the eigenvectors to be $E_1=\{\begin{pmatrix}-1\\1\\0\end{pmatrix}, \begin{pmatrix}-1\\0\\1\end{pmatrix}\}$. Since the dimension is 2 my Jordan block will have $2\times2$ block with diagonal entries 0 and thus we get the second form. Where am I making a mistake?","['jordan-normal-form', 'matrices', 'linear-algebra']"
705567,"Help determining relations on the set {1, 2, 3}","I'm studying for a midterm and I just want to make sure that my understanding of these 2 problems that my teacher gave is logically sound. If you could take a look and give me some feedback I would really appreciate it. Problem 1 In the case below, a relation on the set {1,2,3} is given. Of the three properties, reflexivity, symmetry, and transitivity, determine which ones the relation has. Give reasons. a. R = {(1, 3), (3, 1), (2, 2)} 
I think it is not reflexive because for every x in the set {1,2,3} the (x,x) does not exisit in R. It is symmetric because for every element (x, y) there is a (y, x). Here is what I'm not so sure about. The no relation from x to y and from y to z exist. I think this case is similar to part C and therefore it is transitive. Though I'm not entirely sure if my reasoning is sound. b. R = {(1, 1), (2, 2), (3, 3), (1, 2)} I said reflexive because for every element x there was the pair (x,x). It is not symmetric because for the pair (1,2) the pair (2,1) does not exists. I said it is transitive but this goes off the logic I used in part A. c. R = ∅ I already know this one is right from the post of previous person here. My reasoning was that it is not reflexive because for x there does not exist the pair (x,x).  It is transitive based off of the logic in the previous post. Problem 2 In each case below, say whether the given statement is true for the
universe (0, 1) = {x ∈ R | 0 < x < 1}, and say whether it is true for the
universe [0, 1] = {x ∈ R | 0 ≤ x ≤ 1}. For each of the four cases, you
should therefore give two true-or-false answers.
a. ∀x(∃y(x > y))
b. ∀x(∃y(x ≥ y))
c. ∃y(∀x(x > y))
d. ∃y(∀x(x ≥ y)) Honestly on this one I'm not sure where to start. My first guess would be that for
A) 
Universe (0, 1) = false
Universe [0, 1] = false B) 
Universe (0, 1) = true
Universe [0, 1] = true C) 
Universe (0, 1) = false
Universe [0, 1] = false D) 
Universe (0, 1) = true
Universe [0, 1] = true Not entirely sure why","['relations', 'elementary-set-theory']"
705593,Check my answer - Finding the jacobi matrix of a function,"We are given $f: \mathbb R^n \to \mathbb R^n$ such that: $0 \neq x \in \mathbb R^n$, $f(x)=\frac{x}{|x|}$, where $|x| = \sqrt {x_1^2 +x_2^2+...+x_n^2}$ Find the jacobi matrix (the differential matrix) of $f$. My solution: I realized that if $x= \begin{pmatrix} x_1\\x_2\\ \vdots \\x_n \end{pmatrix}$ and $f_1(x_1)= \frac{x_1}{|x|}$ and $f_2(x_2)=\frac{x_2}{|x|}$ and so on then: where $i\neq j$ $$\frac{df_k(x_i)}{dx_j}=-\frac{x_ix_j}{|x|^3}$$ and  $$\frac{df_k(x_i)}{dx_i}=\frac{|x|^2-x_i^2}{|x|^3}$$ explanation: $$f_k(x_j)=\frac{x_j}{\sqrt{x_1^2+...+x_n^2}}$$, then if we derive by $x_i$ then we get $$\frac{-0.5*2x_i*|x|^{-1}*x_j}{|x|^2} = -\frac{x_ix_j}{|x|^3}$$ and if we derive by $x_j$ then the result will be $\frac{|x|^2-x_j^2}{|x|^3}$ So to sum up, in my opinion the jacobi matrix looks like this: in the diagonal, in entry $(i,i)$ we have: $$\frac{|x|^2-x_i^2}{|x|^3}$$ and not on the diagonal. in entry $(i,j)$ we have $$-\frac{x_ix_j}{|x|^3}$$ Is this correct?","['multivariable-calculus', 'normed-spaces', 'calculus', 'derivatives']"
705597,Proof: $ \lfloor \sqrt{ \lfloor x\rfloor } \rfloor = \lfloor\sqrt{x}\rfloor $.,I need some help with the following proof: $ \lfloor \sqrt{ \lfloor x\rfloor } \rfloor = \lfloor\sqrt{x}\rfloor $. I got: (1) $[ \sqrt{x} ] \le \sqrt{x} < [\sqrt{x}] + 1 $ (by definition?). (2) $[ \sqrt{x} ]^2 \le x < ([\sqrt{x}] + 1)^2 $. (3) $[ \sqrt{x} ]^2 \le [x] \le x < ([\sqrt{x}] + 1)^2$ ??,"['radicals', 'algebra-precalculus', 'ceiling-and-floor-functions']"
705611,Primes $p$ such that $p^2$ divides $x^2 + y^2 + 1$,"Call a prime $p$ awesome if there exist positive integers $x$ and $y$ such that $p^2$ divides $x^2+y^2+1$. Observation: $2$ is not awesome, because $x^2+y^2+1\not\equiv 0$ (mod $4$). But $3$ is awesome, because $9$ divides $27=5^{2}+1^{2}+1$. So my question is: Are there infinitely many awesome primes? Can we find all awesome primes? Motivation: It is true that for every prime $p$, there exists positive integer $x$ and $y$ such that $p$ divides $x^2+y^2+1$. The proof can be found here . (This is actually a nice result; for example, it is used in a proof of Lagrange's $4$-square theorem). If this is too trivial, what can we say if $p^2$ is replaced by $p^{k}$? :)","['divisibility', 'number-theory', 'elementary-number-theory', 'prime-numbers', 'problem-solving']"
705632,Effect of sigmas inequality on sequences,"We have two nets of complex numbers $\{z_\alpha\}_{\alpha\in I},\{w_\alpha\}_{\alpha\in I}$ for some set $I$ which might be uncountable, and we have
$$\sum_{\alpha\in I}|w_\alpha|\leq d<\sum_{\alpha\in I}|z_\alpha|\leq c$$ for some real numbers $c,d\in R$. Now can we find two nets of complex numbers$\{\tilde{z}_\alpha\}_{\alpha\in I},\{\tilde{w}_\alpha\}_{\alpha\in I}$ with
$$\sum_{\alpha\in I}|\tilde{w}_\alpha|=\sum_{\alpha\in I}|w_\alpha|,\qquad\sum_{\alpha\in I}|\tilde{z}_\alpha|=\sum_{\alpha\in I}|z_\alpha|,\qquad |\tilde{w}_\alpha|\leq|\tilde{z}_\alpha|,\ (\alpha\in I)$$ or at least 
$$\sum_{\alpha\in I}|w_\alpha|\leq\sum_{\alpha\in I}|\tilde{w}_\alpha|\leq d<\sum_{\alpha\in I}|z_\alpha|\leq\sum_{\alpha\in I}|\tilde{z}_\alpha|\leq c\qquad |\tilde{w}_\alpha|\leq|\tilde{z}_\alpha|,\ (\alpha\in I).$$","['sequences-and-series', 'real-analysis', 'analysis', 'complex-numbers', 'complex-analysis']"
705657,Nonsingular projective variety of degree $d$,For each $d>0$ and $p=0$ or $p$ prime find a nonsingular curve in $\mathbb{P}^{2}$ of degree $d$. I'm very close just stuck on one small case. If $p\nmid d$ then $x^{d}+y^{d}+z^{d}$ works. If $p\mid d$ then I have chosen the curve $zx^{d-1}+xy^{d-1}+yz^{d-1}$. After some work using the Jacobian criterion for nonsingularity I arrive at $3z=0$. As long as $p\neq 3$ this curve is nonsingular. But I haven't been able to deal with the $p=3$ case. Any ideas? Thanks in advance.,"['algebraic-geometry', 'algebraic-curves', 'abstract-algebra']"
705719,Find the center of a specific group,"The group $G$ is generated by the two elements $\sigma$ and $\tau$, of order $5$ and $4$ respectively. We assume that $\tau\sigma\tau^{-1}=\sigma^2$. I have shown the following: * $\tau\sigma^k\tau^{-1}=\sigma^{2k}$ and $\tau^k\sigma\tau^{-k}=\sigma^{2^k}$. * $\langle\sigma\rangle$ is a normal subgroup of $G$, and $\langle\sigma\rangle\cap\langle\tau\rangle=\{e\}$. * $G/\langle\sigma\rangle=\langle\tau\langle\sigma\rangle\rangle$. * $G$ is of order $20$ and every element $g$ in $G$ may be written uniquely in the form $g=\sigma^k\tau^m$, where $0\le k<5$ and $0\le m<4$. * The commutator subgroup $[G:G]=\langle\sigma\rangle$. What remains is to find the center $Z(G)$ of $G$. Any suggestions on how to proceed? Thank you.","['finite-groups', 'group-theory']"
705742,Geometric interpretation of Euler's identity for homogeneous functions,"A function $f: \mathbb{R}^n \rightarrow \mathbb{R}$ is called homogeneous of degree $d \geq 0$ if $$f(\lambda x_1, \ldots, \lambda x_n ) = \lambda^d f(x_1, \ldots, x_n)$$  Differentiating both sides with respect to $\lambda$ and then plugging in $\lambda=1$, we obtain the following equality:
$$ \sum_{i=1}^n x_i \frac{ \partial f}{\partial x_i}(x_1, \ldots, x_n) = d \cdot f(x_1, \ldots, x_n) $$ This equation is usually called ""Euler's identity."" It feels it should have a clean geometrical interpretation, but I'm blanking out on what it might be.","['geometry', 'analysis']"
705758,Power series for a matrix inverse,"Is there a power series expansion for a matrix inverse of the form
$$\left(\frac{1}{m}I+A\right)^{-1} \mbox{ where $m$ is a scalar?}$$ $A$ is not invertible but the expression above is defined. I don't want to embed $m$ into the $A$ matrix as I want the result to have $m$ in it explicitly. Thanks!","['matrices', 'matrix-calculus', 'linear-algebra', 'inverse']"
705783,Why are these two Poisson-processes independent?,"I have two poisson-processes, I have seen a mathematical proof that they are independent, and offcourse they must be independent since the proof is in several textbooks. But logically I can not understand why they are independent, for me, it is very logical that they are dependent. The processes are defined like this: First we have a Poisson-process $\{N(t), t \ge 0\}$ with parameter $\lambda$. And we defined two new processees like this: At every instance an event occur in the original process, we define this event as type 1, with probability p, and type 2 with probability 1-p. It can then be showed that: $\{N_1(t),t \ge 0\}$ and $\{N_2(t), t \ge 0\}$ are both poisson processes, and it can be showed that their parameters are $\lambda p$ and $\lambda (1-p)$. But now comes what I don't get, they are also independent! I mean, lets say you have p=0.5 and you are at point t* in time. Lets also say that you are given that $N_2(t*)=1000$, why does this value of 1000 not change the probability of $P(N_1(t*) \ge 500)$? Isn't it logical that the more type 2 events that happen, it is more likely that a lot of type 1 events have happened?","['probability-theory', 'stochastic-processes', 'probability']"
705806,$\mathbb Z[\sqrt {-5}]$ is Noetherian,I'm trying to prove that $\mathbb Z[\sqrt {-5}]$ is Noetherian. I already know that $\mathbb Z[X]$ is Noetherian and I'm trying to find a surjective map $$\varphi: \mathbb Z[X]\to \mathbb Z[\sqrt{-5}]$$ with $\ker\varphi=(X^2+5)$. If I could find this map I could prove that $\mathbb Z[\sqrt{-5}]\cong \mathbb Z[X]/(X^2+5)$ and then $\mathbb Z[\sqrt{-5}]$ is Noetherian. Thanks,"['abstract-algebra', 'noetherian']"
705835,Short exact sequence of sheaves and intersection of curves,"Let $C_1$ and $C_2$ be two (smooth rational) curves, $D=C_1+C_2$, $C_1\cap C_2=p$ (a single point). Then how can I show that there is a short exact sequence of sheaves $
0\rightarrow \mathcal{O}_{C_2}(-p)\rightarrow  \mathcal{O}_{D} \rightarrow \mathcal{O}_{C_1}\rightarrow 0 ?
$ Thanks!",['algebraic-geometry']
705840,Quotient Topology vs Subspace Topology.,"Let $X$ and $Y$ be topological space and let $\pi:X\to Y$ be a quotient map (it is surjective map and $Y$ has the quotient topology induced by $\pi$). A subset $U\subset X$ is said to be saturated if $U=\pi^{-1}(\pi(U))$. One easily can checks that the restriction of $\pi$ to any saturated open is a quotient map.
Let $U$ be a saturated open set. We can consider two topologies on $\pi(U)$: the subspace topology and the quotient topology $(\pi_{|_U}: U\to \pi(U))$. What is the relationship between these two topologies? I managed to prove that the topology quotient is finer than the subspace topology, but just it. I cannot proof that the topologies are the same and I cannot find a counterexample.","['general-topology', 'quotient-spaces']"
705847,Counterexample for the Chain rule for the Gateaux-derivative,"I'm reading the book of Drabek, Milota - Methods of Nonlinear Analysis , and at page 121, they state: but I can't manage to find such counterexample. For clarity the Gateaux derivative is defined in this way: I need some kind of hints about how to build such counterexample because I'm like going nowhere with my trials. According to me $f$ and $g$ can't be continuous, otherwise G-derivative would be Frechét-derivative and for this kind of derivative the chain rule holds. It is sufficient requiring that only one function is non-continuos?","['multivariable-calculus', 'gateaux-derivative', 'examples-counterexamples', 'calculus-of-variations', 'banach-spaces']"
705877,An exotic sequence,"Let $a=\frac{1+i\sqrt 7}{2}$ and $u_n=\Re(a^n)$
  show that  $(|u_n|)\to +\infty$ I think basics method does not works here. Any ideas ?","['sequences-and-series', 'real-analysis']"
705935,Find volume between two spheres using cylindrical & spherical coordinates,"I've got two spheres, one of which is the other sphere just shifted, and I'm trying to find the volume of the shared region. The spheres are $x^2 + y^2 +z^2 = 1$ and $x^2 + y^2 +(z-1)^2 = 1$ I know how to transform the variables into cylindrical and spherical coordinates but I'm having trouble figuring out the bounds. How do I do this? EDIT: Based on Kaladin's answer, which helped me realize the bounds for $r$, would it be correct to express the volume of the region as follows? (as cylindrical coordinates) $$V = 2\int_0^{2\pi} \int_{1/2}^1 \int_{-\sqrt{1-r^2}}^{\sqrt{1-r^2}} rdzdrd\theta$$ EDIT 2: Assuming I integrated the above integral properly, that equals $\frac{2\pi\sqrt{2}}{3}$, which is obviously not Kaladin's answer. What's the problem?","['multivariable-calculus', 'calculus', 'integration', 'spherical-coordinates']"
705959,Finite abelian p-group and an element of maximal order,"I'm studying for an exam and I'm having trouble understanding the proof given for the following statement: Suppose $G$ is a finite abelian $p$-group and $a \in G$ has maximum order, then there exists a subgroup $K \subseteq G$ such that: $<a>\ast$  $K$ $= G$ $<a> \cap$  $K$ $= \{e\}$ What I have written down seems disjoint, so I probably missed a few details from lecture.  Could anyone give me the proof, or a reference to one?  For reference, this particular proof started with choosing $b \in G/<a>$ of minimal order and showing that $<a> \cap <b> = \{e\}$ and $|b|=p$, but it already has lost me by that point. This was given near the beginning of the course: at that time, we only knew the Chinese Remainder theorem and that, given a finite abelian $G$ such that $\forall x \in G$, $x^{nm} = e$ with $\operatorname{gcd}(m,n) = 1$, if we define $G_n = \{x \in G : x^n = e\}$ and $G_m = \{x \in G : x^m = e\}$, we have that $G \cong G_n \times G_m$","['finite-groups', 'group-theory', 'abstract-algebra', 'abelian-groups']"
705960,Proof of $\sin^2(x) + \cos^2(x)=1$ using series,"I have to prove the following identity $\sin^2 (x) + \cos^2(x)=1$. I can easily prove this, but this exercise is given in the section introducing the series expansions for $\sin(x)$ and $\cos(x)$ and I should use these in the proof but am not quite sure how to do this.","['trigonometry', 'complex-numbers', 'sequences-and-series', 'combinatorics']"
705961,A function vanishing at infinity is uniformly continuous,"If $f\in C_0(\mathbb{R})$ (i.e. $f$ continuous and for all $\varepsilon>0$ there is $R>0$ such that $|f(x)|<\varepsilon$ whenever $|x|>R$), then why is $f$ uniformly continuous? I know that we should somehow use that $f$ is ""small"" outside a compact interval (on which it is uniformly continuous), how can we nicely write down the $\delta$?","['calculus', 'continuity', 'real-analysis', 'uniform-continuity']"
705969,Integral $\int_0^1\frac{1-x^2+\left(1+x^2\right)\ln x}{\left(x+x^2\right)\ln^3x}dx$,"I'm struggling with this integral
$$I=\int_0^1\frac{1-x^2+\left(1+x^2\right)\ln x}{\left(x+x^2\right)\ln^3x}dx.\tag1$$ Mathematica could not evaluate it in a closed form. Its numeric value is approximately $I\approx0.7804287418294087023386965471512328112...$ $^\text{[more]}$ , but I could not find a plausible closed form for this number using inverse symbolic calculators available online. Update : Based on Raymond Manzoni's comment below, there is actually a conjectural closed form, numerically matching up to at least $10^3$ decimal digits:
$$I\stackrel?=6\ln A-\frac{\ln4}3-\frac14,\tag2$$
where $A$ is the Glaisher-Kinkelin constant :
$$A=\exp\left(\frac1{12}-\zeta'(-1)\right).\tag3$$
Could you suggest a proof of the conjecture $(2)$?","['improper-integrals', 'closed-form', 'calculus', 'integration', 'definite-integrals']"
706006,Defining $\sigma$-algebra on a subset,"This is problem 2.6 from ""Probability Essentials"" by Jacod. Here's the question and my proof: Let $(\Omega, \mathbf{A})$ be a $\sigma$-algebra and let $B\in \mathbf{A}$. Show that
$\mathbf{B} = \{A\cap B: A \in \mathbf{A}\}$ is a $\sigma$-algebra on $B$. Is it still true when $B \notin \mathbf{A}$? Proof:$\varnothing = \varnothing \cap B$ and $B = \Omega \cap B$ are both are in $\mathbf{B}$.
If $(A\cap B) \in \mathbf{B}$, then 
$$B\backslash (A\cap B) = B\cap (A \cap B)^c =B\cap (A^c \cup B^c) = B \cap A^c \in \mathbf{B}. $$
So $\mathbf{B}$ is closed w/rspt to complements. Finally, let $(A_n \cap B) \subset \mathbf{B}$ for $n \in \mathbb{N}$. Then
$$\bigcup_n (A_n \cap B) = B\cap\left(\bigcup_n A_n\right) \in \mathbf{B}.$$
So $\mathbf{B}$ is closed w/rspt to countable unions and $\mathbf{B}$ is a $\sigma$-algebra. I'm pretty sure that this is correct. The only thing that's tripping me up is that the proof still holds when $B \notin \mathbf{A}$. I was SO CONVINCED that this theorem would not hold if $B\notin \mathbf{A}$, so I'm just wondering if I missed something here for the second question of the problem. Otherwise, why would the book even ask this question??? Thanks in advance.",['measure-theory']
706057,Open set in the image of a dominant morphism of affine spaces,"Let $k$ be an infinite field, $X=Y=\mathbb{A}^n_k$, and let $\varphi:X\longrightarrow Y$ be defined by $n$ algebraically independent polynomials. In particular, $\varphi$ is dominant (that is, $\varphi(X)$ is a dense subset of $Y$). Now, using Noether normalisation, one usually proves that there is a non-empty open subset $U\subseteq\varphi(X)$. I wonder how large $U$ could be. Note that in the proof, $U$ is a principal open set. Can we hope for a better bound than $\dim(Y\setminus U)\leq n-1$ in general? EDIT. The field $k$ should be algebraically closed; otherwise, the statement is not true at all.","['commutative-algebra', 'algebraic-geometry']"
706058,Formally smooth vs. smooth,"A (commutative) algebra $A$ is called formally smooth if for any (commutative) algebra $R$ and an ideal $I\subset R$ such that $I^2=0$, any morphism $A\to R/I$ lifts to a morphism $A\to R$. Suppose now that $X$ is a variety and $A$ is the algebra of regular functions on it. How are the definitions of formal smoothness of $A$ and smoothness of the variety $X$ related? Are the two notions equivalent? It doesn't seem to be the case, but I don't know how to prove it. I might be very silly here. In this case I would be glad if you explain that to me. Thank you very much!","['commutative-algebra', 'ring-theory', 'algebraic-geometry']"
706061,Topologies of test functions and distributions,"I'm wondering about some of the topological properties of $\mathcal D(\Omega)$ and $\mathcal D'(\Omega)$: I know $\mathcal D(\Omega)$ is not metrizable, so not first countable (right?). However, my question is: Is $\mathcal D(\Omega)$ sequential? When $\mathcal D'(\Omega)$ is endowed with the weak* topology, is it sequential? (I presume this one is clearly not first countable either). How about for $\mathcal S$ and $\mathcal S'$? One of the reasons I ask is that some authors seem to use the theorem: Given $X$ a sequential space, and $Y$ a topological space, $f:X \rightarrow Y$ is continuous if and only if $f$ is sequentially continuous, to state that operators of the form $T:\mathcal D'(\Omega)\rightarrow\mathcal D'(\Omega)$ are continuous (like differentiability). However, they never seem to prove or even mention whether $\mathcal D'(\Omega)$ is sequential or not. Are they indeed using the above theorem, some other result, or is this perhaps carelessness?","['general-topology', 'distribution-theory', 'schwartz-space', 'analysis', 'functional-analysis']"
706093,"Why is $\pi_1(X,x_0)$ a group?","I want to show that $\pi_1(X,x_0)$ is a group. I am told that $e(t) := x_0$ is the identity element. Now, I am struggling to show that it is an identity element, and also that the inverse of an element gives $e$. I feel like the obvious choice in defining a homotopy between $f\cdot e$ and $f$ (for some path $f : [0,1] \mapsto X$) would be, $F(s,t) := \begin{cases}
f(\frac{2}{1+s}t) , \space 0\leq t \leq \frac{1+s}{2}\\
x_0 ,\space  \frac{1+s}{2} \leq t \leq 1\\
\end{cases} $ And likewise the obvious choice for defining a homotopy between $e$ and $f\cdot f^{-1}$ would be, $G(s,t) := \begin{cases}
f(2ts) , \space 0\leq t \leq \frac{1}{2}\\
g((2-2t)s) ,\space  \frac{1}{2} \leq t \leq 1\\
\end{cases} $. But I can't prove that $F$ and $G$ are continuous. So firstly am I on the right line? I.e are these the right maps to be looking at. Secondly: If so, why is it that they are continuous? I hope you can shed some light! Thanks! Edit : If I can prove the following then I would be done. I want to show that any function $H : X\times Y \mapsto Z$ is continuous if $H_x(y) := H(x,y)$ is continuous for each $x \in X$ and $H_y(x) := H(x,y)$ is continuous for each $y \in Y$. But I can't prove this either. Neither do I even know whether it is true!","['general-topology', 'homotopy-theory', 'algebraic-topology']"
706112,Intuition for groups,"This is quite a non-standard question, certainly for mathematics, though I believe it is no less important (for me and my peers, i.e. grads). The course I am reading so far introduced us to Groups, rings, fields, etc. in the first year, progressing to characters, reps etc in the latter years. However, even with representation theory I still don't feel like I have a good intuition. How do you gain intuition in such an area. I know there will be a response of doing examples, but this doesn't really help - I've done lots already. Am I doomed.",['abstract-algebra']
706117,Minimal and Characteristic Polynomials of Matrix Multiplication Transformation,"Fix a matrix $A \in M_n(F)$ where $F$ is a field, and consider the following linear transformation $\phi_A: M_n(F) \to M_n(F)$ given by $\phi(B) = AB$. Prove that the minimal polynomials of $\phi$ and $A$ are equal. Are their characteristic polynomials equal?","['matrices', 'linear-algebra', 'polynomials']"
706190,Cousin of the Vandermonde binomial identity,"The Vandermonde binomial identity can be expressed as
\begin{align*}
\sum_{i+j=r} \binom{m}{i} \binom{n}{j} = \binom{m+n}{r} && r \leq m +n.
\end{align*}
While working on an algebra problem, I stumbled on a formally similar, but distinct identity:
\begin{align*}
\sum_{i+j=r} \binom{i}{m}\binom{j}{n} = \binom{r+1}{m+n+1}
 && m+n \leq r.
\end{align*}
This isn't hard to prove or anything. The left-hand side enumerates the subsets  $S \subseteq \{1,2,\ldots,r+1\}$ with $|S| = m+n+1$ according to the position of the $(m+1)$st largest element of $S$. But, I found the similarity striking enough to ask the following Question: Are the parallels between these two formulas just a coincidence? Or, is there something else going on here?","['binomial-coefficients', 'combinatorics']"
706194,Prove that the cardinality of $\Bbb N$ is less than the cardinality of $\Bbb R$,I understand there are different ways of showing this. One would be to use functions and mappings and another way is to express cardinality arithmetically? But if the sets are uncountable then it is not possible to express arithmetically?,['elementary-set-theory']
706195,Set up the limits and evaluate $\iiint ydv$,"Set up the limits and evaluate the integral. $$\displaystyle\iiint ydv$$
$$G$$ G is the region enclosed by the plane $z = y$, $xy-plane$ and the surface $y = 1 - x^2$ I need help finding the limits of integration. I have this so far, but I don't think it is correct. $$\displaystyle\int_{0}^{1}\int_{0}^{1 - x^2}\int_{0}^{y} y\;dz\;dy\;dx$$","['multivariable-calculus', 'volume', 'integration']"
706206,Sheafification - Construction of a Sheaf,"I tried different books and lecture notes to understand sheafification, but for instance in Hartshore or Shafarevich's book, but I found it hard to understand. The following is the approach my professor used. But also here I have some questions. But first here is what he wrote: Let $\mathscr{F}$ be a presheaf. $$\mathscr{F}^g(U):= \left\{\begin{array}{rl} \{f_P\}_{P\in U}| & f_P\in\mathscr{F}_P, \forall P\in U\textrm{ }\exists V\ni P, V\subset U\textrm{ and a }f\in\mathscr{F}(V) \\
         | & \textrm{ with }f\in\mathscr{F}(V)\to\mathscr{F}_Q, f\mapsto f_Q \end{array}\right\}$$ First see that $\mathscr{F}^g$ is a presheaf: Let $U'\subset U$. $f=\{f_P\}_{P\in U}\in\mathscr{F}^g(U)\mapsto \bar{f}:=\{f_P\}_{P\in U'}\in\mathscr{F}^g(U')$. So $\forall P\in U'$ $\exists V\subset U'$ such that $V'=V\cap U'$ and $\mathscr{F}(U)\to\mathscr{F}_Q$ with $f\mapsto f_Q$. $$\begin{array}{ccc} \mathscr{F}(V) & & \\ \downarrow{\varphi} & \searrow &  & \\ \mathscr{F}_Q & \xleftarrow{} & \mathscr{F}(V')& \end{array}$$
For all $Q\in V'$. and $\varphi(\bar{f})$ Let $U=\bigcup\limits_{i\in I}U_i$. $\mathscr{F}^g(U)\overset{\beta}{\to}\prod\limits_{i\in I}\mathscr{F}^g(U_i)$ $\prod\limits_{i\in I}\mathscr{F}^g(U_i)\overset{\alpha}{\to}\prod\limits_{i,j\in I}\mathscr{F}^g(U_{ij})$, ($U_{ij}=U_i\cap U_j$) with $\{f_i\}_{i\in I}\mapsto \{f_{ij}\}_{ij}$, and $f_{ij} = \rho_{U_i U_{ij}}f_i - \rho_{U_j U_{ij}}f_j$ and $f_i = \{f_{iP}\}_{P\in U_i}\in\mathscr{F}^g(U_i)$ $(*)$ $Im(\beta)=ker(\alpha)$. If $\beta(f)=0$ $\Rightarrow f_P=0$ $\forall P\in U$ $\Rightarrow f = \{f_P\}_{P\in U}=0$. $(**)$ If $P\in U_{ij}$, then $\{f_i\}_{i\in I}\in ker(\alpha)$. Show $f_{ip}=f_{jp}$: Let $U_i\supseteq V_i\ni f\in V_j\subseteq U_j$ $\mathscr{F}(V_i)\to \mathscr{F}_{iP}$ with $\tilde{f}_i\mapsto f_{iP}$ and $\mathscr{F}(V_j)\to \mathscr{F}_{jP}$ with $\tilde{f}_j\mapsto f_{jP}$. $(***)$ $\rho_{U_i U_{ij}}f_i = \rho_{U_j U_{ij}}f_j\Rightarrow f_{ip}=f_{jp}$ $\forall P\in U_{ij}$. $\tilde{f}=\{f_{P}\}_{P\in U}$. $f_P=f_{iP}$ for $i$ with $P\in U_i$. $\tilde{f}\in\mathscr{F}^g(U)$ fulfils the condition, and so $\mathscr{F}^g$ is a sheaf. Our definition for a sheaf: Let $\mathscr{F}: ouv(X)\to \textrm{(abelian groups)}$ be a presheaf. Then $\mathscr{F}$ is a sheaf if $\forall U\subset X$ open: $U=\bigcup\limits_{i\in I}U_i$ open couver $\Rightarrow \mathscr{F}(U)\overset{\beta}{\to}\prod\limits_{i\in I}\mathscr{F}(U_i)$ is injective and $Im(\beta)=\{(f_i)_{i\in I}|\rho_{U_i U_{ij}} f_i = \rho_{U_j U_{ij}} f_j\}$. Now my questions: To $(*)$: Here we want to show that  $Im(\beta)=ker(\alpha)$ holds right?  But how did he show it? I don't understand what he does to afterwards. To $(**)$: Why do we have ''If $P\in U_{ij}$, then $\{f_i\}_{i\in I}\in ker(\alpha)$.''? To $(***)$: I understand why ''$f_{ip}=f_{jp}$'' follows, but not that ''$\rho_{U_i U_{ij}}f_i = \rho_{U_j U_{ij}}f_j$'' holds. Thanks and all the best!","['sheaf-theory', 'algebraic-geometry']"
706227,Error In Proving Variance Of Sample Mean,"So the variance of the sample mean $\bar X$ is $\sigma^2/n$, and I understand how to prove it through the formula $Var(nX) = n^2Var(X)$. However, I was approaching it through another method, and seem to have proven that the variance of the sample mean is $\sigma^2$, and I can't seem to find the error in my proof: $ Var(\bar X) = E[\bar X^2] - E[\bar X]^2 
              = E[\bar X^2] - \mu^2 
              = E[(1/n\sum X_i)^2] - \mu^2 
              = 1/n^2 E[(\sum X_i)^2] - \mu^2 
              = 1/n^2 (n^2E[X^2]) - \mu^2
              = Var(X) $. I've been looking for a while, but I can't find what's wrong with this. If someone could help point out the error in this, that would be very helpful, thanks!","['statistics', 'probability', 'expectation']"
706247,help with showing completeness,"Let $\left\{H_n\right\}_{n=1}^\infty$ be a sequence of Hilbert spaces and let $H=\left\{\left\{x_n\right\}:x_n\in H_n, \sum ||x_n||^2<\infty \right\}$. Define the inner product as $(\left\{x_n\right\}, \left\{y_n\right\})=\sum (x_n,y_n)$ Then $H$ is complete with respect to the induced norm $\left\|x_n \right\|=(\left\{x_n\right\}, \left\{x_n\right\})^\frac{1}{2}$. I want to consider a Cauchy sequence $\left\{ \left\{x_{i,m}  \right\}_{i=1}^\infty \right\}_{m=1}^\infty$ and use the fact that $\sum ||x_n||^2<\infty$, but here is where I run into a problem: $\displaystyle \sum_{m=1}^\infty ( \left\{x_i  \right\}_m , \left\{x_i  \right\}_m)= \sum_{m=1}^\infty \sum_{i=1}^\infty (x_{i,m}, x_{i,m})$. The sum above may not be necessarily finite, right? I want to show that it is finite so that this way I know that $\left\{ \left\{x_i  \right\}_m \right\}_{m=1}^\infty$ has a limit. What am I doing wrong? Thanks for your help.","['measure-theory', 'hilbert-spaces', 'real-analysis', 'analysis']"
706275,Expected number of bridges,There are 10 islands in a row. Each island is linked to the successive one by 2 bridges. One of these two is the correct bridge i.e. it will take you to the other side. The other is a bad bridge i.e. if you take that one you will be taken back to the first island and will have to start over again. The probability of any of the two connecting bridges being good or bad is 0.5.What is the expected number of bridges that you need to cross before reaching the last island ? Also once you have crossed a bridge you remember it to be good or bad so that you are not crossing the bad bridges more than once. Any help is appreciated. Thank you.,"['statistics', 'probability']"
706278,Uses of integral calculus in discrete mathematics?,"I have to do a project in my integral calculus class. But all the topics are too mainstream (parabolic arc calculation,archimedean approzimation of circle are,obtaining $E=mc^2\dots$ However I'm really into discrete maths right now and I would like to use integral calculus for my project in discrete mathematics? Is this viable? What are some topics I could persue?(Things I am really into right now are combinatorial identities, graph theory,abstract algebra and category theory). Thank you very much in advance, forgive me if this question is innapropriate. Best Wishes.","['definite-integrals', 'indefinite-integrals', 'discrete-mathematics', 'soft-question']"
706283,Is there an algebraic invariant for complex curves that's mapped to injectively?,"Consider the functor $\pi_1: \text{Closed Surfaces} \rightarrow \textbf{Grp}$. This is homotopy invariant; every closed topological surface has a unique fundamental group. In the reverse direction, by classification, if two closed surfaces have isomorphic fundamental group, then the surfaces themselves are homeomorphic. This fails if we move up to $3$-manifolds, and fails spectacularly for dimension $\geq 4$. So I'll restrict my questions to small dimensions. Question: is there a functor $\text{Complex Curves} \rightarrow \textbf{Grp}$ that has the same properties as before? (In this case, it should be conformally invariant, but the preimages of a given group should be conformally equivalent.) I doubt it, if only because there are continuum many complex structures on a torus, and it seems unlikely that something which can be continuously varied like this will give me a nice algebraic invariant that can differentiate these structures. Bonus question: if this is provably false, is it provably false for rings as well? (Feel free to let rings have unity or not and morphisms take unity to unity or not.) Edit : Zhen Lin noted in the comments below that the Yoneda embedding to PreSheaf works fine. I've restricted now to groups and rings. I want there to be no algebraic invariant in the spirit of, say, homotopy groups or the cohomology ring or the group of line bundles that does the job for us.","['complex-analysis', 'category-theory', 'riemann-surfaces', 'abstract-algebra']"
706285,Discrete Math creating functions that map sets,"contruct a simple one-to-one function from
$Z^+ → P(Z^+)$ How would I approach this type of problem? I'm guessing from utilizing $F: Z^+ → P(Z^+)$ I'm guessing need to find some way to map all positive integers to the power set of all positive integers. Do I just define something like f(x) = the number of elements inside each subset of the Power set ? Thought I'm sure that wouldn't be 1-to-1 because multiple subsets are the same size in the power set.",['discrete-mathematics']
706293,What is the probability that $HH$ occurs before $TH$ in an infinte sequence of coin flips?,"This is one of the questions of a set of exam review questions that don't have solutions to them. I can't get my head around this but it seems so simple. By flipping a fair coin repeatedly and independently, we obtain a sequence of
  H's and T's. We stop flipping the coin as soon as the sequence contains either HH or TH.
  Two players play a game, in which Player 1 wins if the last two symbols in the sequence
  are HH. Otherwise, the last two symbols in the sequence are TH, in which case Player 2
  wins. A = ""Player 1 wins""
  and
  B = ""Player 2 wins."" Determine Pr(A) and Pr(B)",['probability']
706307,Differential Equations - Method of Undetermined Coefficients: Homework Question,"I am doing some studying regarding Differential Equations and using the Method of Undetermined Coefficients in order to solve second order, non-linear, non-homogeneous equations. While asking this question, I realized someone had already asked the same question regarding the same exact problem on stackexchange. Their question can be found here. The question that I have is asking us to solve: $y'' -2y' -3y = (-3t)(1/e^t)$     , (call this $\alpha$). The answer to $\alpha$ in the textbook is the same as what user32240 said, and then the coefficients are also listed in his/her answer. Thus far, I have looked at the following link (if you visit this link, page 15 is the area with the information regarding this problem), and I have made little progress to see why we are using: $(At^2)(1/e^t)+(Bt)(1/e^t)$, (call this $*$). My Question is : Why are we using $*$ to solve this equation? While I am attempting to solve $\alpha$, I am using $*/t$. Any help would be much appreciated! BOOK INFO TITLE:     Elementary Differential Equations and Boundary Value Problems
 EDITION:   Tenth
 Authors:   William E. Boyce / Richard C. DiPrima
 Question:  pg.184, question 5",['ordinary-differential-equations']
706389,Proof Strategy - Prove that each eigenvalue of $A^{2}$ is real and is less than or equal to zero - 2011 8C,"Remember that we've already proven the following, for  any real symmetric $n\times n$ matrix $M$:
(i) Each eigenvalue of $M$ is real.
(ii) Each eigenvector can be chosen to be real.
(iii) Eigenvectors with different eigenvalues are orthogonal. (b) Let $A$ be a real antisymmetric $n\times n$ matrix. Prove that each eigenvalue of $A^{2}$ is real and is less than or equal to zero. $(A^2)^T = (A^T)^2 = (-A)^2 = A^2$, so $A^2$ is real symmetric. By virtue of (i) above, the eigenvalues of $A^2$ must be real. $1$. How would you determine to prove that $A^2$ is symmetric, so that you can benefit from (i) ? Let $A^2v = \color{orangered}{ k \; \mathbf{ v } }$, where k is a scalar. By (ii) above, hypothesise that $\mathbf{ v }$ is real.
Then $\begin{align} k \mathbf{ v^Tv } & = v^T \; \color{orangered}{ k \; \mathbf{ v } }
=  v^T \; \color{forestgreen}{ A^2 }v = v^T \color{forestgreen}{ AA } v 
= v^T\color{forestgreen}{ (-A^T)A }v \\ & = -(Av)^T(Av) < 0 \end{align}$. $2.$ The question asks us to prove $k < 0$, but what's the proof strategy? The trick looks like to consider $k \mathbf{ v^Tv } $, but how would you determine/divine/previse this? I remember $\langle v,v \rangle := v^Tv \ge 0$. $3.$ I'm not asking about the algebra itself, but what's the strategy behind it here?    The last few steps feel too clever/guileful?","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors', 'proof-explanation']"
706417,Why are there cubics in a Calabi-Yau manifold?,"I heard from a recent talk that the ""number of $n$-degree curves"" in a Calabi-Yau manifold is an invariant of the space. But what does that mean? (Specifically I would like to ask the following.) Does the sequence of ""number of $n$-degree curves in a CY-manifold has a name? (i.e. the sequence for which Physics wins over Mathematics in calculating $n_3$.) So does it make sense to ask, for example, 'What's the number of quadratic rational curves on a torus?' Is this sequence related to something more familiar, like homology groups, Betti number, torsion, Euler characteristic (not its weighted version), etc.? Thank you very much for your attention.","['string-theory', 'algebraic-geometry', 'geometric-topology', 'algebraic-topology']"
706450,"If $A$ is normal such that $AB=BA$, then $A^*B=BA^*$","Please help me. Let $A,B\in M_n(\mathbb{C})$. Show that if $A$ is normal such that $AB=BA$, then $A^*B=BA^*$.","['matrix-equations', 'matrices', 'linear-algebra']"
706453,"Product topology on $X \times Y$ the smallest topology when $f(x, y) = x$ and $g(x, y) = y$ are continuous functions?","$X$ and $Y$ are topological spaces and let $f : X \times Y \to X$ and $g : X \times Y \to Y$ be maps such that $f(x, y) = x$ and $g(x, y) = y \ \forall (x, y) \in X \times Y$ . Show that the product topology on $X \times Y$ is the smallest topology on $X \times Y$ for which both the $f$ and $g$ are continuous. I think I understand what is going on here. Here is how I see it. As $f$ is continuous, take an open set $U \subset X$ and it's inverse image $(U, Y)$ will be open in $X \times Y$ for any topology on $X \times Y$. Similarly, as $g$ is continuous, take an open set $V \subset Y$ and it's inverse image $(X, V)$ will be open in $X \times Y$ for any topology on $X \times Y$. Hence $(U, Y) \bigcap (X, V) = (U, V)$ which will be open in $X \times Y$ for any topology on $X \times Y$. Now the set $\{(U, V): U \in X, V \in Y\}$ is the product topology hence we are saying that the product topology will be a subset of any other topology on $X \times Y$ when $f$ and $g$ are the continuous maps as defined above. Is my understanding correct? If so is my proof clear or is it messy?","['general-topology', 'product-space']"
706461,Calculating the limit $\lim((n!)^{1/n})$,"Find $\lim_{n\to\infty} ((n!)^{1/n})$. The question seemed rather simple at first, and then I realized I was not sure how to properly deal with this at all. My attempt: take the logarithm, 
$$\lim_{n\to\infty} \ln((n!)^{1/n}) =  \lim_{n\to\infty} (1/n)\ln(n!) =  \lim_{n\to\infty} (\ln(n!)/n)$$
Applying L'hopital's rule: 
$$\lim_{n\to\infty} [n! (-\gamma + \sum(1/k))]/n! = \lim_{n\to\infty} (-\gamma + \sum(1/k))=  \lim_{n\to\infty} (-(\lim(\sum(1/k) - \ln(n)) + \sum(1/k))
 = \lim_{n\to\infty} (\ln(n) + \sum(1/k)-\sum(1/k)
 = \lim_{n\to\infty} (\ln(n))$$
I proceeded to expand the $\ln(n)$ out into Maclaurin form
$$\lim_{n\to\infty} (n + (n^2/2)+...) = \infty$$
Since I $\ln$'ed in the beginning, I proceeded to e the infinity
 $$= e^\infty
 = \infty$$ So am I write in how I approached this or am I just not on the right track? I know it diverges, I was just wanted to try my best to explicitly show it.","['factorial', 'radicals', 'real-analysis', 'limits']"
706466,Do all Groups have a representation?,I know that many kind of groups can be represented by matrices; for example: rotation groups can be represented by matrices.  Especially all elements of rotation groups can be represented by orthogonal matrices with determinant positive one. Also Permutation group can be represented by matrices. But I need to know: are there any kind of group which can not be represented by matrices? Or is there any kind of group which does not have a representation? Can you show me sample?,"['representation-theory', 'group-theory', 'abstract-algebra']"
706467,Question on a derivative on a Hilbert space,"I have this functional $J(u)=\frac12 \|u\|^2+\int_0^1 F(t,Ku(t))dt$ where $F(t,u)=\int_0^u f(t,\xi) d\xi$ , $\displaystyle Ku(t)=\int_0^1 G(t,s)u(s) ds$ with $G(t,s)=\begin{cases} s(1-t),&0\leq s \leq t\leq 1\\t(1-s), &0\leq t\leq s \leq 1\end{cases}$ we define the Nemytskii operator $N_f : H\rightarrow H$ where $N_{f}u(t)=f(t,u(t)),\ t\in [0,1]$ and we have $J'(u)v=(u-KN_fK u,v)$ , For $\tau>0$ I'm trying to prove that $\frac{d}{d\tau} J(\tau u)=(J'(\tau u),u)$ it's written like that, and it gives the area that we applied the derivative of a composed function! But whene i used the definition (Gateaux) i found: $$\displaystyle\lim_{s\rightarrow 0} \frac{J(\tau u+sh)-J(\tau u)}{s}=(J'(\tau u),h)$$ for all $h\in H$ so $\nabla J(\tau u)=J'(\tau u)$ how to find that $\frac{d}{d\tau}J(\tau u)=(J'(\tau u),u)$ ?? Thank you.","['gateaux-derivative', 'hilbert-spaces', 'derivatives', 'analysis']"
706479,Solve $7\sin^2(x) - 9\cos(2x) = 0$,"I need to solve for x in the polynomial $$7\sin^2(x) - 9\cos(2x) = 0$$ I have tried approaching the problem in multiple ways. I am only looking for some hints, not the actual answer. Thanks :D",['trigonometry']
706513,Calculating the determinant gives $(a^2+b^2+c^2+d^2)^2$?,"I need to calculate the following determinant in order to prove the following equality: $$\det\begin{pmatrix} a & b & c & d \\ -b & a & -d & c \\ -c & d & a & -b \\ -d & -c & b & a \end{pmatrix} = (a^2+b^2+c^2+d^2)^2.$$ I tried using Gauss-algorithm to get an easier matrix, but I'm not sure if I did it correctly. Calling the $4$ lines $I$, $II$, $III$ and $IV$, I did: (1) $II \cdot a$ (2) $III \cdot a$ (3) $IV \cdot a$ After this I did: (4) $II' + I \cdot b$ (5) $III' + I \cdot c$ (6) $IV' + I \cdot d$ So finally I got the following matrix: $$\begin{pmatrix} a & b & c & d \\ 0 & a^2+b^2 & bc-ad & ac+bd \\ 0 & ad+bc & a^2+c^2 & cd-ab \\ 0 & bd-ac & ab-cd & a^2+d^2 \end{pmatrix}.$$ I thought this would make the determinant a bit easier, unfortunately I must have done something wrong. Is multiplication with single lines allowed as I have done it? Thank you very much.","['linear-algebra', 'determinant']"
706525,Positive compact operator has unique square root.,"Let H be a hilbert space and T be a compact positive operator so that by the spectral decomposition theorem,  $T=\sum_{n=1}^{\infty}{\lambda}_{n}\langle x,e_{n}\rangle e_{n}$
where the $e_{n}$ are the eigenvectors of T and form an orthonormal basis.
I have shown that T has a positive square root namely $S=\sum_{n=1}^{\infty}{\lambda}_{n}^{0.5}\langle x,e_{n}\rangle e_{n}$. I am trying to show S is unique. My attempt :
Suppose that $L$ is positive with $L^2=T$.Then since $L$ commutes with $T$ it is invariant on it's eigenspaces. So given $e_{n}$ there is an $m$ such that $e_{m}$ is associated to the same eigenvalue, ${\lambda}$ as $e_{n}$ and $L(e_{n})={\alpha}e_{m}$ for some ${\alpha}$. Note that since each eigenvalue may be associated to more than one eigenvector, we cannot assume $n=m$. From there I'm stuck Thanks","['operator-theory', 'linear-algebra', 'hilbert-spaces', 'functional-analysis']"
706547,A little bit of Intuition for Corepresentations from Representations,"Hi folks I am trying to prove what I think should be a straightforward enough result but I am having to make a somewhat unnatural definition to do it. This unnatural definition is hinted at in a paper by Franz & Gohm : If $G$ is a group, then $b:M\times G\rightarrow M$ is called a (left) action of $G$ on $M$, if it satisfies... ...as before we have the unital *-homomorphisms $\alpha_g:F(G)\rightarrow F(G)$ defined by $\alpha_g(f)(x):=f(b(x,g))$. Actually, in order to get a representation of $G$ on $F(G)$, i.e. $\alpha_g\alpha_h=\alpha_{gh}$, we must modify the definition and use $\alpha_g(f)(x):=f(b(x,g^{-1}))$. Otherwise we get an anti-representation . Let $G$ be a finite group and let $\rho:G\rightarrow GL(V)$ be a representation of $G$. I had wanted to prove that if we define a map by $$\chi(v)=\sum_{g\in G}u\otimes\mathbf{1}_{\{g\,:\,\rho(g)u=v\}}=\sum_{g\in G}\rho(g^{-1})v\otimes\mathbf{1}_{\{g\}},$$ that $\chi$ would be a corepresentation of the quantum group $F(G)$ on $V$. Something that will ultimately fix my problem, in line with Franz & Gohm's comments above, is if I define $$\chi_0(v)=\sum_{g\in G}u\otimes\mathbf{1}_{\{g\,:\,\rho(g^{-1})u=v\}}=\sum_{g\in G}\rho(g)v\otimes\mathbf{1}_{\{g\}}.$$ The reason I am uneasy about this is because it destroys a lot of the understanding I thought I had... briefly, if we consider the representation to be an action of $G$ on $V$ such that $u\overset{g}{\longrightarrow}v$ I wanted $\chi$ to encode all of this by saying look all of the things that bring you to $v$: something that looks or feels like $\coprod_i(u_i\overset{g_i}{\longrightarrow} v)$. To be a corepresentation we need $(I_V\otimes \varepsilon)\circ\chi=I_V$ where $\varepsilon$ is the counit. There is no problem showing this with either definition. The other property we need is $$(I_V\otimes \Delta)\circ \chi=(\chi\otimes I_A)\circ\chi,$$
which works fine for $\chi_0$ but for what I want the best I can do is 
$$\sum_{g,t\in G}\rho(gt)^{-1}\otimes \mathbf{1}_{\{gtg^{-1}\}}\otimes\mathbf{1}_{\{g\}}=\sum_{g,t\in G}\rho(gt)^{-1}\otimes \mathbf{1}_{\{t\}}\otimes\mathbf{1}_{\{g\}},$$
which only works if $G$ is abelian. The map $\Delta$ is the coproduct given by $\Delta: F(G)\rightarrow F(G)\otimes F(G)$ 
$$\Delta(\mathbf{1}_{\{g\}})=\sum_{t\in G}\mathbf{1}_{\{gt^{-1}\}}\otimes \mathbf{1}_{\{t\}}.$$ I suppose I am a little uneasy about letting go of the very little intuition that I have in the realm of quantum groups and I am wondering is there a better reason for using $\chi_0$ over $\chi$ apart from ""it works"". Thank you for your time.","['representation-theory', 'group-theory', 'quantum-groups']"
706565,Prove that $n^2+n+41$ is prime for $n<40$,"Here's a problem that showed up on an exam I took, I'm interested in seeing if there are other ways to approach it. Let $n\in\{0,1,...,39\}$. Prove that $n^2+n+41$ is prime. I shall provide my own solution, though I am curious does anyone know how to do this without using PIDs?","['prime-numbers', 'principal-ideal-domains', 'elementary-number-theory', 'abstract-algebra']"
706594,Understanding basic stochastic differential equations,"This is from a physics course in economics, the literature provides a bare minimum of mathematical explanations. I am trying to understand how to work with stochastic differential equations given in exercises. Any explanation of how to approach would be appreciated. I am assuming this is very easy, but since the given literature is unreadable for me, I have no idea. Assume that the time evolution of two stock prices $S_1$ and $S_2$ are
  described by the two following Wiener process, $$dS_1 = \sigma_1\epsilon\sqrt{dt}\\ dS_2  = \sigma_2\epsilon\sqrt{dt}
+ \sigma_0\epsilon_0\sqrt{dt},$$ where $\sigma_0, \sigma_1, \sigma_2$ are volatilities, $\epsilon_0$
  and $\epsilon$ are independent , normally distributed random numbers
  with variance one. Furthermore, assume that $S_1(0) = S_2(0) = 0$. 1. If $\sigma_2 = 0$, what is the correlation between S_1(t) and S_2(t)? 2. Calculate the variance and the correlation between the two following portfolios $$F_1 = S_1 \\ F_2 = \sigma_2S_1 - \sigma_1S_2 $$ Assuming $\sigma_2 = 0$ yields $dS_2 = \sigma_0\epsilon_0 \sqrt{dt}$. They provide no proper definition of the correlation, but from what I have seen in an example, it seems to be given by the moment $\langle S_1 S_2\rangle$. How is this integral derived from the given information? Do we compute $$\langle dS_1dS_2 \rangle = \sigma_0\sigma_1\langle\epsilon_0\epsilon dt\rangle = \sigma_0\sigma_1\langle\epsilon_0\rangle\langle\epsilon\rangle dt ?$$
Where would we go from here? 2.. Itôs formula seems to be the key. Again, they do not provide a proper definition, but I'm guessing the approach is the following. Let $f(x,t) = x$ and define $F_1 = f(S_1, t)$ and $F_2 = \sigma_2f(S_1,t) - \sigma_1f(S_2, t)$. We should get the following $$dF_1 = \sigma_1\epsilon\sqrt{dt} \\
dF_2 = \sigma_2dS_1 - \sigma_1dS_2 = -\sigma_0\sigma_1\epsilon_0\sqrt{dt}.$$ Any suggestions? As of writing I just got my hands on a copy of Oksendal's ""Stochastic differential equations"" which I hope will have an approach that I am more comfortable with.","['economics', 'stochastic-processes', 'finance', 'ordinary-differential-equations']"
706609,A conjecture on partitions,"While trying to prove a result in group theory I came up with the following conjecture on partitions: Let $b(i,j)$  be the number of partitions of $i$  with greatest part exactly equal to $j$ , for all $i,j\in\mathbb{N}$. Suppose for $m\in\mathbb{N}$,  $a(m)$  denotes the number of partitions of $m$  with each part at least $2$ . Then the following holds: 
$$\sum_{i+j=m} b(i,j)=a(m).$$ I need to prove or disprove the above conjecture. I checked first few cases where it holds true. I tried induction and some bijection arguments but did not succeed. Any idea will be appreciated.","['integer-partitions', 'elementary-number-theory', 'number-theory']"
706649,Prove the following sets equalities,"I'm really struggling with proofes, please tell me if I'm correct and if there is a better way to prove (or disprove) the following: i) $(A \setminus B) \setminus B = A \setminus B$ My answer: $x\in((A \setminus B)\setminus B) \Leftrightarrow x\in (A \setminus B)$ and $x\notin B \Leftrightarrow x\in A$ and $ x \notin B \Leftrightarrow x\in (A \setminus B)$ ii) $A - (B - A) = A$ My answer: $x\in (A \setminus (B \setminus A)) \Leftrightarrow x\in A$ and $x\notin (B \setminus A) \Leftrightarrow x\in A$ iii) $P(A \cup B) = P(A) \cup P(B)$ My answer: not true. The case where $A=\{3\}$ and $B=\{5\}$, $P(A\cup B) = \{\emptyset,\{3\},\{5\},\{3,5\}\}$ and $P(A) \cup P(B) = \{\emptyset,\{3\},\{5\}\}$ iv) $P(A\cap B) = P(A)\cap P(B)$ My answer: $x\in P(A\cap B) \Leftrightarrow x \subseteq (A\cap B) \Leftrightarrow x \subseteq A $ and $ x\subseteq B \Leftrightarrow x \in P(A)$ and $x\in P(B) \Leftrightarrow x \in (P(A) \cap P(B))$","['discrete-mathematics', 'elementary-set-theory', 'proof-verification']"
706671,Lower semicontinuity of indicator function,"For any set $\mathcal{S} \subseteq \mathbb{R}^{N}$, let us define the indicator function $$\delta_{\mathcal{S}}(\mathbf{x}) \triangleq \begin{cases}
0, & \quad \textrm{if } \mathbf{x} \in \mathcal{S} \\
\infty, & \quad \textrm{otherwise}.
\end{cases}$$ Is this function lower semicontinuous? I suppose it is if the set $\mathcal{S}$ is closed, but I'm not absolutely sure.","['optimization', 'functional-analysis']"
706709,The probability of a Brownian motion's tail event is unaffected by the starting point,"Consider the measurable space $\left(\mathbf{C}\left[0,\infty\right), \mathcal{B}\left(\mathbf{C}\left[0,\infty\right)\right)\right)$ and the stochastic process $\left(X_t\right)_{t \in \left[0,\infty\right)}$ defined over this space, where for every $t \in \left[0,\infty\right)$, $X_t$ is the projection on the $t^\textrm{th}$ coordinate, i.e. $\forall f \in \mathbf{C}\left[0,\infty\right),\ X_t\left(f\right) = f\left(t\right)$. Denote by $\mathcal{T}$ the associated tail $\sigma$-algebra. For every $x \in \mathbb{R}$, let $P_x : \mathcal{B}\left(\mathbf{C}\left[0,\infty\right)\right) \rightarrow \left[0,1\right]$ be a probability measure that renders $\left(X_t\right)_{t \in \left[0,\infty\right)}$ a Brownian motion with start at $x$. Let $A \in \mathcal{T}$. For any $x \in \mathbb{R}$, $P_x\left(A\right) \in \left\{0, 1\right\}$ (this can be derived using Blumenthal's $0$-$1$ law together with the time inversion invariance of Brownian motion). I'd like to show that for every $x, y \in \mathbb{R}$, $P_x\left(A\right) = P_y\left(A\right)$. In proving this fact, I'd like to avoid using the strong Markov property of Brownian motion, if possible (the simple Markov property is legit, though), but this is not a requirement, just an extra challenge.","['probability-theory', 'stochastic-processes', 'brownian-motion']"
706731,Example: Push-Forward Sheaf,"Let $f: X\to Y$ be a continuous map, $\mathscr{F}$ a sheaf on $X$. $f_*\mathscr{F}$ is the sheaf on $Y$ defined by $f_*\mathscr{F}(U)=\mathscr{F}(f^{-1}(U))$ Uand $\rho_{VU}=\rho_{f^{-1}(V)f^{-1}(U)}: f_*\mathscr{F}(V)\to f_*\mathscr{F}(U)$. Example: Let $X= \{P,Q\}$ with the discrete topology and $Y=\{R\}.$ $f:X\to Y$ and let $\underline{\mathbb{R}}$ be the sheaf of local constant real valued functions on $X$. Then $
     f_*(\underline{\mathbb{R}})=\left\{\begin{array}{ll} \mathbb{R}^2, & U=\{R\} \\
         0, & U=\emptyset\end{array}\right.$ Why do we have that $\underline{\mathbb{R}}(f^{-1}(R))= \mathbb{R}^2$? I don't see where this comes from.","['sheaf-theory', 'algebraic-geometry']"
706746,Prove or disprove - order types and constants,"Let $k$ and $l$ be natural numbers and let $\omega=[(\mathbb N, \le)], \ \eta=[(\mathbb Q, \le)]$ be order types (or ordinals). Prove or disprove the following: if $k+\eta=l+\eta$ then $k=l$ . if $k+\omega=l+\omega$ then $k=l$ . $2014\cdot\omega=2014+\omega$ For 1, I'm not sure, the only way for $k+\eta=l+\eta$ to be true is if the two constants are equal, because if they weren't then it wouldn't be true. That's obviously not formal enough. For 2, we know from ordinal arithmetic that $n\in\mathbb N+\omega=\omega$ so let's take two different natural numbers instead of $k$ and $l$ and we'll get that the first term is true but the second isn't. Is that enough to prove it ? For 3, this is the way I see it: $\{2014,2\cdot 2014,...n\cdot2014\}=2014\cdot\omega\neq2014+\omega=\omega$ , is it enough?","['ordinals', 'elementary-set-theory']"
706748,"What does ""weakly compact"" mean when applied to subsets $X \subset Y$?","Let $X$ be a subset of a Banach space $Y$. Please can you give me a definition of what ""$X$ is weakly compact"" means? I want one which is in terms of sequences and boundedness, as opposed to one with topology and stuff like that. Thank you. I have searched the internet for days to avail for such a nice definition. I did receive an answer in this thread , however the answer makes no reference to the set $Y$. Also a citation to a text would be nice.","['functional-analysis', 'definition', 'weak-convergence', 'reference-request', 'compactness']"
706749,$\prod_{k=0}^{\infty} \cos(x \cdot 2^{-k}).$ [duplicate],"This question already has answers here : Finding the limit $\lim \limits_{n \to \infty}\ (\cos \frac x 2 \cdot\cos \frac x 4\cdot \cos \frac x 8\cdots \cos \frac x {2^n}) $ (3 answers) Closed 6 years ago . Task is to find $$\prod_{k=0}^{\infty} \cos(x \cdot 2^{-k}).$$ 
I tried to make it with double-angle formula: $\prod_{k=0}^{\infty} \cos(x \cdot 2^{-k}) = \frac{\prod_{k=0}^\infty \sin(x2^{1-k})}{2^\infty \cdot \prod_{k=0}^\infty \sin(x \cdot 2^{-k})} $ I'm sad to admit, that I'm stuck with that one.
So I would appreciate any help, such as pointing the right direction.","['trigonometry', 'limits']"
706782,Computing the kernel of an isogeny between two elliptic curves,Consider the two rational elliptic curves - $ E_{1}: y^{2}+y=x^{3}+x^{2}-131x-650 $ $ [\text{Cremona}:35a2] $ $ E_{2}: y^{2}+y=x^{3}+x^{2}-x $ $ [\text{Cremona}:35a3] $ We know that there is an isogeny of degree 9 between the above two curves. My question is how to write down the isogeny and compute it's kernel $?$ EDIT - Is there any theoretical way of calculating the kernel since I don't know how to find out the kernel from the kernel polynomial $?$,"['algebraic-geometry', 'elliptic-curves', 'number-theory']"
706851,Weaker notion of first-countability for filters?,"While trying to understand the motivation behind the definition of a filter I've stumbled upon the following notion, let's call it ""almost first-countability"": Let $x$ be a point of a set $X$ and $\mathcal{F}$ be a filter on $X$ such that each $F\in\mathcal{F}$ contains $x$. We say $\mathcal{F}$ is almost first-countable if there is a countable collection $\mathcal{C}=\{C_1,C_2,\dots\}$ of nested subsets of $X$ (so $C_1\supset C_2\supset\cdots$) such that $\Sigma(\mathcal{C})=\Sigma(\mathcal{F})$, where for any $\mathcal{X}\in P(P(X))$ the symbol $\Sigma(\mathcal{X})$ denotes the set of sequences $\phi\colon\mathbb{N}\to X$ converging with respect to the collection $\mathcal{X}$, i.e. each element of $\mathcal{X}$ contains a tail of $\phi$. Clearly if $\mathcal{F}$ is first-countable, i.e. it can be generated by a countable filter base, then it is almost first-countable (just take $\mathcal{C}$ to be $\{C_1,C_1\cap C_2,C_1\cap C_2\cap C_3,\dots\}$ where $\{C_1,C_2,C_3,\dots\}$ is a countable filter base generating $\mathcal{F}$). Question: Is this notion strictly weaker than first-countability? In other words, are there a set $X$, a non-first-countable filter $\mathcal{F}$ at $x\in X$ and a countable collection $\mathcal{C}=\{C_1,C_2,\dots\}$ of nested subsets of $X$ such that $\Sigma(\mathcal{C})=\Sigma(\mathcal{F})$? Observation: Call $\mathcal{C}'$ the filter generated by the base $\mathcal{C}$ by adding all supersets of elements of $\mathcal{C}$. Then $\Sigma(\mathcal{C}')=\Sigma(\mathcal{C})$. It follows that the above question boils down to finding two filters at $x$ sharing the same set of convergent sequences and such that one is first-countable while the other is not (or proving they do not exist, of course). As an exercise for myself let me rewrite user126154's brilliant argument in a more detailed fashion. In order to fix the ideas, instead of letting $\alpha$ be any non-$\omega$-cofinal limit ordinal I decided to choose a concrete example by picking up the smallest limit ordinal which is not $\omega$-cofinal. If I'm not mistaken this should be the first uncountable ordinal $\omega_1$. Consider the first uncountable ordinal $\omega_1$ and the filter $\mathcal{F}_\infty$ on $\omega_1$ generated by the filter base $\mathcal{B}_\infty:=\{(a,\infty)\mid a\in \omega_1\}$ where $(a,\infty):=\{x\in \omega_1\mid x>a\}$. Observe that $\Sigma(\mathcal{F}_\infty)$ is empty: indeed, assume there is a sequence $\phi\colon\mathbb{N}\to \omega_1$ converging with respect to $\mathcal{F}_\infty$; by induction $\phi$ has a strictly increasing subsequence $\phi'$ also converging w.r.t. $\mathcal{F}_\infty$; the limit of this sequence is just $s:=\sup_{n\in\mathbb{N}}\{\phi'(n)\mid n\in\mathbb{N}\}$, i.e. a countable union of countable ordinals which is still countable, hence $s\in \omega_1$  and the interval $(s+1,\infty)$ does not contain any tail of $\phi'$, which is absurd. Further observe that $\mathcal{F}_\infty$ cannot be generated by a countable filter base, otherwise we could construct a sequence converging w.r.t. the base and hence also w.r.t. $\mathcal{F}$. Now consider the set $X:=(\sqcup_{n\in\mathbb{N}} (\omega_1)_n)\cup\{\infty\}$ consisting of the disjoint union of countably many copies of $\omega_1$ together with a new point $\infty$, and construct the filter $\mathcal{F}$ on $X$ consisting of all subsets $F\subset X$ satisfying all the three conditions below: $F\cap(\omega_1)_n\in\mathcal{F}_\infty$ for each $n\in\mathbb{N}$, there is $j\in\mathbb{N}$ such that $F\cap(\omega_1)_k=\omega_1$ for each $k\geq j$, $\infty\in F$. Notice that $\mathcal{F}$ cannot be generated by a countable filter base, otherwise by restricting each element of the base to one copy of $\omega_1$ we would obtain a countable filter base for $\mathcal{F}_\infty$. Now consider the collection $\mathcal{C}=\{C_n\mid n\in\mathbb{N}\}$ of subsets of $X$ where $C_n$ is defined by the next three conditions: $C_n\cap(\omega_1)_j=\emptyset$ for $j<n$, $C_n\cap(\omega_1)_j=\omega_1$ for each $j\geq n$, $\infty\in C_n$ for each $n\in\mathbb{N}$. Clearly $\mathcal{C}$ satisfies the axioms of a filter base, and the filter that it generates is obviously first-countable. Now we show that $\Sigma(\mathcal{F})=\Sigma(\mathcal{C})$. Let $x_n$ be a sequence in $X$ converging w.r.t. $\mathcal{C}$. Each $F\in\mathcal{F}$ contains some $C_n$ so $x_n$ converges w.r.t. $\mathcal{F}$ as well. Conversely, assume $x_n$ converges w.r.t. $\mathcal{F}$ and define $\sigma(n)$ to be the index of the copy of $\omega_1$ where $x_n$ lies (put $\sigma(n)=\star$ if $x_n=\infty$). If for each $n$ there is $j_n$ such that for each $k\geq j_n$ $\sigma(k)$ is either greater than $n$ or equal to $\star$ then $x_n$ obviously converges w.r.t. $\mathcal{C}$ and we are done. Otherwise $\sigma$ has a constant subsequence at some natural number, that is there is a subsequence $x_{n_k}$ staying in a single copy of $\omega_1$. Since $x_n$ converges w.r.t. $\mathcal{F}$ by assumption, then $x_{n_k}$ must converge w.r.t. $\mathcal{F}_\infty$ and this is impossible since $\Sigma(\mathcal{F}_\infty)=\emptyset$. Conclusion: we have found a set $X$, two filters at some point $x\in X$ one of which is first-countable while the other is not (the former being the filter generated by $\mathcal{C}$, the latter being $\mathcal{F}$) sharing the same set of converging sequences in $X$. In other words, $\mathcal{F}$ is ""almost first-countable"" but not first-countable, therefore the notion spelled out above of ""almost first-countability"" is really different than first-countability (in particular, it is strictly weaker). In order to avoid ambiguities I add the definitions used. A filter on $X$ is a nonvoid collection of subsets of $X$ such that: the empty set does not belong to the collection, any finite intersection of its elements is a superset of some element of the collection, any superset of any of its elements belongs to the collection. A filter base is like a filter but we drop the third assumption. By adding all supersets of all elements of a filter base $\mathcal{F}$ we obtain the filter $\mathcal{F}'$ generated by the base $\mathcal{F}$. It follows that a nonvoid collection $\mathcal{B}\in P(P(X))$ is a base of a given filter $\mathcal{F}$ if and only if $\mathcal{B}\subset\mathcal{F}$ and each $F\in\mathcal{F}$ contains some $B\in\mathcal{B}$.","['general-topology', 'filters']"
706892,Error bound of the Euler method,"I am self studying working through the book ""A First Course in the Numerical Analysis of Differential Equations"" and have come to a deadend on q 1.2. The linear system $y' = Ay, y(0) = y_0$, where $A$ is a symmetric matrix, is solved by the Euler method. Let  $e_n = y_n - y(nh)$ Where $y_n$ denotes the Euler approximation and $y(nh)$ the exact solution ($h$ is Euler step size). Prove that $ ||e_n ||_2 = ||y_0||_2 max|(1+h\lambda)^n - e^{nh\lambda}|$ Where $\lambda \in \sigma(A)$ where $\sigma(A)$ is the set of eigenvalues of A. I have tried various approaches such as writing $e_n$ as the error bound of the Euler method and taking the norm, but I can't seem to get $||y_0||_2$ in my answers.","['error-propagation', 'ordinary-differential-equations', 'systems-of-equations', 'numerical-methods']"
706913,Limits of Indeterminate Quotient: $\lim\limits_{x \to 0^+} \frac{\ln(e^x - 1)}{\ln(x)}$ and $\lim\limits_{x \to -1}(\frac1{x+1} - \frac3{x^3+1})$,I was preparing for my exam and found myself struggling with finding limits of indeterminate quotient. $$\lim\limits_{x \to 0^+} \dfrac{\ln(e^x - 1)}{\ln(x)}$$ I have tried using L'Hopital's Rule to reduce it to: $\lim\limits_{x \to 0^+} \dfrac{xe^x}{e^x-1}$ but still does not solve the problem. Another problem that I've faced: $$\lim\limits_{x \to -1}(\frac{1}{x+1} - \frac{3}{x^3+1})$$ I have tried to combine it into 1 term: $\lim\limits_{x \to -1}(\dfrac{x^3-3x-2}{x^4+x^3+x+1})$ and applied L'Hopital's Rule but still got an Indeterminate Quotient. Any advice on the 2 above qns is really much appreciated!,['limits']
706914,Calculating expected value and variance of a probability density function,"If I was given a probability density function: $$f(y) = \left\{\begin{array}{ll}\frac{3y^2(4-y)}{64} & \textrm{for }  0 \leq y \leq 4\\
           0 & \textrm{elsewhere} \end{array}\right.$$ for expected value would that just be the following integral? 
$$\int_{0}^{4} yf(y)\,\textrm{d}y$$ I do not know how I would calculate the variance though. Any tips? Thanks",['probability']
706934,Riemann Zeta Function Non-Vanishing on the Line $\mathrm{Re} \; z = 1$,"The result quoted in the title is usually a stepping stone in the proof of the prime number theorem and I am familiar with the usual argument for this result. The other day my professor was telling me, however, that the prime number theorem actually implies this result too. He suggested looking at the limit: $$\lim_{\sigma \to 1} (\sigma-1)\int_1^{\infty}\frac{\psi(x)-x}{x^{\sigma+i\tau + 1}} \mathrm{d}x$$ Apparently by assuming the prime number theorem one can show that this limit is zero and from there deduce that $\zeta(1+i\tau) \neq 0$, but I am having difficulty showing either of these. Can someone help fill in the missing details please?","['analytic-number-theory', 'riemann-zeta', 'number-theory']"
706943,What is the name of following formula?,"What is the name of following formula?
$$
S=\sqrt[]{(p-a)(p-b)(p-c)(p-d)}
$$
where
$$
a+b+c+d=2p
$$
$S$ is the surface of a quadrangle. $a, b, c, d$ are lengths of sides of a quadrangle that can be inscribed into a circle.",['geometry']
706970,Zorn's Lemma in noetherian modules,"For noetherian modules, we have in particular the equivalent definitions that the Ascending Chain Condition holds and that every nonempty subset of submodules has a maximal element. Now I can prove the ""ACC $\Rightarrow$ every nonempty set of submodules has a maximal element"" implication by the following argument: Let $S$ be a nonempty set of submodules, take $N_1 \in S$. If $N_1$ is not maximal, there exists a $N_2 \supsetneq N_1$ per definition. By induction we get a chain $N_1 \subsetneq N_2 \subsetneq \dotsb$ and by ACC this induction terminates after finitely many, say $n$, steps. Then $N_n$ is maximal. My question is: Did I miss the use of Zorn's Lemma somewhere? This proof doesn't seem to use it, and the other implications in the equivalence work fine without it too, yet I've seen some sources (e.g. Wikipedia, first answer here: Is every Noetherian module finitely generated? ) that require it. I'm fine with Zorn's Lemma by the way, just feeling a bit stupid right now.","['modules', 'set-theory', 'abstract-algebra']"
706994,Integral $\int_0^a \ln \left( \frac{b-\sqrt{a^2-x^2}}{b+\sqrt{a^2-x^2}} \right)dx$,"Hi I am trying to calculate, $$
\int_0^a \ln \left( \frac{b-\sqrt{a^2-x^2}}{b+\sqrt{a^2-x^2}}    \right)dx
$$
where $a,b$ are positive real constants.  I Know $\ln(xy)=\ln x +\ln y$, but I do not know how to evaluate this integral then.
I need to find a closed form for the indefinite integral 
$$
\int \ln \big(b\pm \sqrt{a^2-x^2}\big) dx
$$
so this is really the problem I am facing.  The closed form exists and is in terms of elementary functions.  Thanks!","['definite-integrals', 'calculus', 'integration', 'contour-integration']"
707008,prove $| \exp(x) - 1 - x - \frac{x^2}{2!} - \frac{x^3}{3!}| < \frac{e}{24}$,"prove $\displaystyle\left\lvert \exp(x) - 1 - x - \frac{x^2}{2!} - \frac{x^3}{3!}\right\rvert| < \frac{e}{24}$ $\forall x \in [-1,1]$ my attempt, we defined $\exp(x) = \displaystyle \sum_{n=0}^{\infty} \dfrac{x^n}{n!}$ using this: $| \exp(x) - 1 - x - \frac{x^2}{2!} - \frac{x^3}{3!}| = \left | \displaystyle \sum_{n=4}^\infty \dfrac{x^n}{n!} \right | \leq \displaystyle\sum_{n=4}^\infty \left |\dfrac{x^n}{n!} \right |  $ since $|x| \leq 1 $ and $e = 2.718...$ $\displaystyle\sum_{n=4}^\infty \left |\dfrac{x^n}{n!} \right | \leq \displaystyle\sum_{n=4}^\infty \left |\dfrac{e^n}{n!} \right | < e^4/24 < e/24$ Is this a valid proof? The reason I ask is because we have just started Taylor Series in my analysis class and I don't see how I'm exactly using this at all in the proof edit using maclaurin: $\exp(x) = 1 + x + x^2/2! + x^3/3! + e^\theta x^4/4!$ for some $\theta \in (0,1)$, since $|x| \leq 1$ $$\dfrac{e^\theta}{4!}|x^4| \leq e^\theta/24 < e/24$$ is this correct?","['exponential-function', 'inequality', 'analysis']"
707059,Confidence Interval and margin of error,I had the following question on a study guide and was wondering if I did it correctly. I was confused because of the way the question is worded. Here is the question: And here is how I attempted it: Is this correct?? I was confused because I think the problem asked for confidence interval when it actually meant margin of error. Thanks for the help!,['statistics']
707068,Proof with disjoint and sets.,"Prove that $A$ and $B$ are disjoint if and only if $A\subseteq B'$ What I know: If $S\cap T =\emptyset$ then $S$ and $T$ are said to be disjoint. The intersection of two sets $S$ and $T$ is the set $S\cap T$, consisting of all elements that are both in $S$ and $T$, hence $S\cap T =$ {$x | x\in S$ AND $x\in T$}.",['elementary-set-theory']
707069,Does the sequence $\sin(n!\pi^2)$ converge or diverge?,Does the sequence $\sin(n!\pi^2)$ converge or diverge?,['sequences-and-series']
707088,Derivative of exponential functions,"Can anyone present an intuitive reason for why the derivatives of exponential functions, lets say, as apposed to polynomials, grow more rapidly than the functions themselves? i.e.
$$
y = e^{x^2}\\
\frac{\mathrm{d}y}{\mathrm{d}x} = 2 x e^{x^2}
$$
I would appreciate an answer that does not simply go out and show algebraic manipulations (of limits etc.) which lead to the desired result. I am much more interested in a, at least partially, verbal explanation. Thank you! :)","['exponential-function', 'intuition', 'derivatives']"
707107,The cardinality of the function,"I'm reading a book about cardinality of functions and while I was solving some problems of the book I saw this: Prove that the cardinality of a general function $f:K \to K$ is $n^n$, where $n$ is the number of elements in $K$.
I think I do understand the logic behind this,for example let's say: $K=\{a,b,c,d,e\}$. Now the function $f$ has a cardinality of $5^5$ because the first element ($a$) has $5$ opportunities, the second element ($b$) has also $5$ opportunities,the third element ($c$) has also $5$ opportunities and so on. Now I'm trying to prove this as the task says,but I don't know how to do it,how to write it in a more mathematical way.","['functions', 'analysis']"
707115,Topology of weak convergence,"Edited: Thanks to etienne. I start with a compact metric space $(X,d)$. Then I consider the collection of finite measure $\mathcal{M}$ on $X$ and I equip $\mathcal{M}$ with the topology of weak convergence. This means that $\mu_n$ converges to $\mu$ if and only if for all $f \in C(X, \mathbb{R})$ (continuous functions from $X$ to $\mathbb{R}$),
$$
\int f d\mu_n \to \int f d\mu.  
$$
Now my question is what does a general continuous function from $\mathcal{M}$ to $\mathbb{R}$ look like? By definition for $f \in C(X, \mathbb{R})$,
$$
F(\mu) := \int f d\mu
$$
is continuous but is also linear so this cannot be all continuous functions. Can we describe the entire set in some way?","['probability-theory', 'weak-convergence', 'measure-theory', 'analysis']"
707139,"If $N\in \mathbb N$ is a palindrome in base $b$, can we say it is a palindrome in other bases?","I have noticed a pattern among palindromic numbers, and was curious if there is a general truth out there. My examples are limited to smaller bases so that numerals may be used. My conjecture is that if $N_b$ is a palindrome with $b=p^n$ for some prime $p$ and all digits of $N_b$ are less than $p$ then $N_p$ is also a palindrome. For example, $$10100101_8 = 1000001000000001000001_2$$
$$12022021_9 = 102000202000201_3$$ Using only divisibility as a criterion, the conjecture does not hold, since the first example above is equal to $20020001001_4$. My central question is pretty big I guess. If $N_b$ is a palindrome, for which $a$ is $N_a$ a palindrome? I'm interested in any subcases such as this one as well.","['palindrome', 'elementary-number-theory', 'number-theory']"
707167,Computing Normals from Metric Tensor,"I asked a similar question on the Physics Stack Exchange, but unfortunately I have had no reply. It may be more suited for the Math section, as it focuses on the mathematical interpretation of GR. Just to motivate the question, recall the boundary term in the Einstein-Hilbert action:
$$S = \frac{1}{8\pi G} \int_{\partial M} \mathrm{d}^3 x \sqrt{|h|}\, K$$ where the integration is over the boundary of a manifold, $K$ is the trace of the extrinsic curvature, and $h$ is the first fundamental form, 'physically' equivalent to the induced metric on the boundary of the manifold. To compute the extrinsic curvature, one requires the inward/outward normals. Is there a straightforward way to compute the normals directly from the metric tensor? In the end, I just want to plug the normals $n_{\alpha}$ into the expression $K_{\mu \nu} = (1/2)n_{\alpha}g^{\alpha \beta}\partial_{\beta}g_{\mu \nu}.$","['general-relativity', 'differential-geometry']"
707175,Level sets of holomorphic functions,"It is a somewhat well known fact that any closed set (say in the plane) can be realized as the level set of a smooth ($C^\infty$) function, so level sets of smooth functions are as general as they can possibly be. Question (very basic and probably well known, sorry) : what about level sets of holomorphic functions ? By the isolated zero principle, any non constant holomorphic function (in one variable) must be a submersion at all but a discrete set of points, so you get level sets which are fairly reasonnable. What is the most general scenario for such sets ? I would like to know this in those 3 levels of generality, if possible : 1) level sets of holomorphic maps from $\mathbb{C}^n$ to $\mathbb{C}^k$ 2) level sets of holomorphic maps from complex manifolds to complex manifolds (finite dimensional ; all local information should be the same as case 1). Feel free to add all relevant hypotheses I wouldn't know about (Kähler, Stein, I don't know...) 3) level sets of holomorphic maps from (possibily infinite dimensional) complex Banach manifold to complex Banach manifold.","['complex-geometry', 'several-complex-variables', 'complex-analysis']"
707183,"Why surjectivity is defined by ""for every $y$,there exist $x$ such that$ f(x)=y$"" instead of ""$x_1=x_2\Rightarrow f(x_1)=f(x_2)$""","I think injective and surjective is a dual concept.
Injective: $f(x_1)=f(x_2) \Rightarrow x_1=x_2$
But the definition of surjective is so different.
It's ""for every $y$,there exist $x$ such that $f(x)=y$"". so why we define surjective by ""for every $y$,there exist $x$ such that $f(x)=y$"" instead of ""$x_1=x_2 \Rightarrow f(x_1)=f(x_2)$""",['functions']
707209,Rank of sum of rank-$1$ matrices,If you sum a certain number of rank- $1$ matrices: $$X = u_1 u_1^T + u_2 u_2^T + \cdots + u_N u_N^T$$ Is the result guaranteed to be rank- $N$ assuming the individual $U$ vectors are linearly independent?,"['matrices', 'linear-algebra', 'rank-1-matrices', 'matrix-rank']"
