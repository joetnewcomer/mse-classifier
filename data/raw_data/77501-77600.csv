question_id,title,body,tags
984937,"Tedious undefined limit without L'Hospital $\mathop {\lim }\limits_{x \to \frac{\pi }{2}} \,\,\frac{{\tan \,(x)}}{{\ln \,(2x - \pi )}}$","When I try to calculate this limit: $$\mathop {\lim }\limits_{x \to \frac{\pi}{2}^+} \,\,\frac{{\tan \,(x)}}{{\ln \,(2x - \pi )}}$$ I find this: $$\begin{array}{l}
L = \mathop {\lim }\limits_{x \to \frac{\pi }{2}^+} \,\,\frac{{\tan \,(x)}}{{\ln \,(2x - \pi )}}\\
\text{variable changing}\\
y = 2x - \pi \\
x \to \frac{\pi }{2}\,\,\,\, \Rightarrow \,\,\,y \to 0\\
\text{so:}\\
L = \mathop {\lim }\limits_{y \to 0} \,\,\frac{{\tan \,\left( {\frac{{y + \pi }}{2}} \right)}}{{\ln \,(y)}} = \mathop {\lim }\limits_{y \to 0} \,\,\frac{{\tan \,\left( {\frac{y}{2} + \frac{\pi }{2}} \right)}}{{\ln \,(y)}}\\
 = \mathop {\lim }\limits_{y \to 0} \,\,\frac{{ - \cot\,\left( {\frac{y}{2}} \right)}}{{\ln \,(y)}} =  - \mathop {\lim }\limits_{y \to 0} \,\,\frac{{\csc (y) + \cot (y)}}{{\ln \,(y)}}\\
 = \frac{{ \pm \infty  \pm \infty }}{{ - \infty }} = ??
\end{array}$$ and in the latter part I get stuck, should be obtained using mathematical software $L= \pm \infty$ how I justify without L'Hospital?","['limits-without-lhopital', 'calculus', 'real-analysis', 'analysis', 'limits']"
984977,Can a Norm be Induced by two Different Complex Inner Products?,"Let $(X,\|\cdot\|)$ be a normed vector space over $\mathbb{C}$. If $\|x\|=\sqrt{\langle x,x\rangle}$ and $\|x\|=\sqrt{\langle x,x\rangle'}$ for all $x\in X$ where $\langle,\rangle$ and $\langle,\rangle'$ are complex inner products, then must we have $\langle,\rangle=\langle,\rangle'$ ? If $X$ is a vector space over $\mathbb{R}$, I think the answer is yes. Indeed, since
$$
\forall x\in X:\|x\|=\sqrt{\langle x,x\rangle}=\sqrt{\langle x,x\rangle'}\implies\forall x\in X:\langle x,x\rangle=\langle x,x\rangle'
$$
then for $x,y\in X$ we have $\langle x+y,x+y\rangle=\langle x+y,x+y\rangle'$ and expanding we see that $\langle x,y\rangle=\langle x,y\rangle'$. But, in the complex case, I can only get $\Re\langle x,y\rangle=\Re\langle x,y\rangle'$ with this argument.","['vector-spaces', 'normed-spaces', 'functional-analysis']"
985013,Prove a theorem in combinatorics,"I want to show that for $k=1,...,(n-1)$ we have : $\binom{n}{k}\leq \frac{n^n}{k^k(n-k)^{n-k}}$ I have used induction on $k$, but I have not deduced the above relation.","['binomial-coefficients', 'combinatorics']"
985058,Use the definition of derivative to prove $\lim_{x\to 0}\ln(x+1)/x =1$,"How would I use the definition of derivative to prove 
$$\lim_{x\to 0} \frac{\ln(1+x)}{x} = 1$$ I got to $$\frac{\frac{\ln(1+x+h)}{(x+h)} - \frac{\ln(1+x)}{x}}{h}$$ but have no idea where to go from here. On another site I found someones answer where they stated the following:
$$
\lim_{x\to 0} \frac{\ln(1+x) - \ln(1+0)}{x-0} 
= [\ln(1+x)]'\rvert_x = 0
$$
but I am unsure why the $x$ in the $x-0$ is removed. Can someone please explain?","['derivatives', 'limits']"
985085,attack on RSA (factoring when knowing e and d),"This is the problem, I have to explain how works the algorithm on the image with modular arithmetic for a discrete math class., I tried to explain it, but I couldn´t. In the class, I have seen this topics: Euclidean Algoritm, RSA, Bézout's identity, The Chinese remainder theorem, Euler's theorem, Euler φ function, Fermat's little theorem and other primality filters like Miller_Rabin. This problem is extra at the class, but I need to explain it, I´m the only one on the class who has to explain it. So please, I would be so, so, so grateful with the one who can explain me how the algorithm works (mathematically) , for example: why ed is congruent with? 1 mod phi?(N) (the first fact in the image) here is the link where I find it: https://www.cs.purdue.edu/homes/ninghui/courses/Fall04/lectures/lect14-c.pdf thanks in advance¡  :)","['modular-arithmetic', 'prime-factorization', 'discrete-mathematics', 'cryptography']"
985121,"Basic Math, exponents and algebra","I have the equation
$$\frac{x_1^{-\frac{1}{2}}}{{x_2^{-\frac{1}{2}}}} = p_l/p_2$$ How do I get $x_2$ on its own? I have
$$x_2^{-\frac{1}{2}} = \frac{p_2(x_1^{-\frac{1}{2}})}{p_1}$$
And if you have a useful link that reviews this info, it would be highly appreciated.",['algebra-precalculus']
985151,"Show that if $A,B$ are measurable, $A\subset E\subset B$, and $m(A)=m(B)$, then $E$ is measurable.","Here's the full problem: Suppose $A\subset E\subset B$, where $A,B$ are measurable with finite measure. Show that if $m(A)=m(B)$, then $E$ is measurable. Here, we are dealing with measure space $(\mathbb{R},\mathcal{M},m)$. I come here just to see if this is a valid proof. Here we go: Proof We have that $m(A),m(B)<\infty$. Supposing $m(A)=m(B)$, we have $$m(A)\leq m(E) \leq m(B)=m(A)$$
  $$\implies m(A)=m(E)$$ Since $A$ is measurable, it follows that $E$ must then be measruable. I know of another way to prove this, I was just wondering if this was a valid argument as well.","['lebesgue-measure', 'real-analysis']"
985212,Row reduction and the characteristic polynomial of a matrix,Can you row reduce the matrix before computing $\det(\lambda I-A)$? Will this still give an equivalent characteristic polynomial?,"['matrices', 'linear-algebra']"
985261,Determining number of solutions to equation (Discrete math),"How many solutions are there to the equation below, if $x_i$ is a positive integer > 1:
$$\sum_{1}^{6} x_i = 29$$ I also have to do this for x1<=5, however I imagine that's a similar process. So, my question is based on $x_i>1$. Where is a good starting point? Edit: I feel as though I should use bars and stars in some way. We have 6 bars and 17 stars, then multiply that by the possible number of ways that we can order the bars (i.e. $x_1,x_2,x_3,x_4,x_5,x_6 \space \text{vs} \space x_1,x_2,x_3,x_4,x_5,x_6$)? After realizing I can have a min of 2 and max of 19 what's a step in the right direction? Also, I just realized I've had the idea in my mind that 2 + 2 + 2 + 2 + 2 + 19 and 19 + 2 + 2 + 2 + 2 + 2 would be different solutions, but I now believe those would count as the same. Just as some clarification, plus to explain why I wanted to multiply by 6! in my previous attempt",['discrete-mathematics']
985293,Please help me with this set operation (Corrected question),"""$A$ and $C$ are disjoint sets, schematize $(A^c \cup B^c)\cap C$."" Please help me. My answer was ""$C$"". Thank you. (I can't comment, so I put the upgraded question...)",['elementary-set-theory']
985305,Find absolute maximum and minimum with domain,"Find absolute maximum and minimum of the function $f(x,y)=3-x^2+y^2$ on the region $R = \{(x,y):1≥x≥0, 2≥y≥0\}$ I found that the gradient is $∇f(x,y)=(2x,2y)$ and that the critical point inside the domain is (0,0) and it is a local minimum. I know I have to check the boundary, and I know how to do it for a fixed equation like $x^2+y^2=1$ but not for the domain I'm given. Can someone explain how this type of problem is to be solved? I don't seem to understand this problem logically or intuitively.","['optimization', 'multivariable-calculus', 'calculus']"
985319,The behavior of quotient groups under homomorphisms,"We're learning normal subgroups, kernels, homomorphisms and isomorphisms in abstract algebra right now. I'm trying to tie the ends together: I know that if $G$ is a group, $N$ a normal subgroup of $G$, and $\phi: G\to G′$ is a  homomorphism then $\phi(N)$  is a normal subgroup of $G′$. But can I say that quotient group $G/N$ is isomorphic to $G'/ \phi(N)$? Let's assume that $\phi$ is a surjective homomorphism.","['group-theory', 'normal-subgroups']"
985336,Clarification on proof that all groups of order $< 60$ are solvable,"I've manged to prove that all groups of order $< 60$ are solvable, using Burnside's theorem. However, I found an alternate proof here Question about solvable groups It states that: ""Note that $A_5$ is the smallest non-abelian simple group and its order is $60$. Therefore in any subnormal series of any group of order less than $60$, $A_5$ is not a composition factor. Hence all group of order less than $60$ are all solvable."" Could anyone explain why the fact that in any subnormal series of any group of order $< 60$, $A_5$ is not a composition factor implies that all groups of order less that $60$ are solvable? It's not clear to me why that follows immediately.","['solvable-groups', 'finite-groups', 'group-theory', 'abstract-algebra']"
985342,Theorem 3.29 in Baby Rudin,"Theorem 3.29 in Walter Rudin's Principles of Mathematical Analysis , 3rd ed., states that If $p>1$ , then the series $$\sum_{n=2}^\infty \frac{1}{n (\log n)^p} $$ converges; if $p \leq 1$ , the series diverges. Now in the proof, Rudin only seems to discuss the case when $p> 0$ , for it is only in this particular case that we can use the Cauchy Condensation Test. How to deal with the case of $p<0$ ? Of course, the case $p=0$ yields the divergent harmonic series.","['sequences-and-series', 'convergence-divergence', 'calculus', 'real-analysis', 'analysis']"
985345,Proving a palindromic integer with an even number of digits is divisible by 11,"I'm in an introductory course for discrete math so I'm a novice at English proofs. I'm not sure if my reasoning here is valid or if I'm using modular arithmetic correctly. Specifically the line I marked with $(**)$ . I would appreciate any feedback. Sorry if any part of the proof seems obvious we are generally expected to spell everything out. Objective: Prove every palindromic integer with an even number of digits is divisible by $11$ . Proof: Consider a palindromic integer $p$ in the form of $x_{1} x_{2} …. x_{n-1}x_{n}x_{n}x_{n-1}...x_{2}x_{1}$ where $p$ has $2n$ digits.
This can be expanded as: $$x_{1} + x_{2}\cdot10 + … + x_{n}\cdot10^{n} + x_{n}\cdot10^{n+1} + … + x_{2}\cdot10^{2n} + x_{1}\cdot10^{2n+1}$$ $(**)$ $10 \equiv -1 \pmod{11}$ so if we take $\pmod{11}$ of the expression we can replace $10\equiv -1$ . $$x_{1} + x_{2}\cdot(-1) + … + x_{n}\cdot(-1)^{n} + x_{n}\cdot(-1)^{n+1} + … + x_{2}\cdot(-1)_{2n} + x_{1}\cdot(-1)^{2n+1}$$ Since we know $2n$ is even (and therefore $2n + 1$ is odd), and $(-1)^{a} = 1$ when $a$ is even and $= -1$ when $a$ is odd we can rewrite the expression as: $$x_{1} - x_{2} + … + x_{n} - x_{n} + … + x_{2} - x_{1} = 0$$ Therefore since $p \equiv 0 \pmod{11}$ , we have that $11$ divides $p$ .","['solution-verification', 'number-theory', 'modular-arithmetic', 'palindrome', 'proof-writing']"
985346,Normalizer and centralizer are equivalent when $p$ is the smallest prime dividing $|G|$,"Let $p$ be the smallest prime dividing $|G|$, and suppose that some $P \in \mathsf{Syl}_p(G)$ is cyclic. Prove that $N_G(P) = C_G(P)$. So I let $G=p^\alpha m$ $p$ does not divide $m$. P is cyclic, hence is abelian, so I get that $P \leq C_G(P) \leq N_G(P)$. p is the smallest prime dividing the order of $G$, hence every prime divisor of $m$ is greater than $p$. I also carried out the normal computation of Sylow theorem where $n_p$ is congruent to 1 mod p, and $n_p$  divides $m$. I also tried looking at the index of $N_G(P), C_G(P)$ and tried to show that this equals to $1$ but got stuck there. Any suggestion are welcome!","['abstract-algebra', 'normal-subgroups', 'sylow-theory', 'prime-numbers', 'group-theory']"
985372,How can I have a copy of this old paper?,"How can I have a copy of this old paper and a translation of it? Frobenius, G. (1902). Uber primitive Gruppen des Grades n und der Klasse n - 1. S. B. Akad. Berlin 1902, 455-459.","['reference-request', 'group-theory']"
985375,The product of uniformly continuous functions is not necessarily uniformly continuous,"I was asked to show that given two functions $f:\mathbb{R}\rightarrow \mathbb{R}$ and $g:\mathbb{R}\rightarrow \mathbb{R}$ which are both uniformly continuous, to show that the product $fg:\mathbb{R}\rightarrow \mathbb{R}$ was not always necessarily uniformly continuous. Rather than just give a counter example, I wanted to try showing it directly assuming that it was always uniformly continuous and see where the proof gets hairy or where it seems to fail. Only problem is that I seemed to have accidentally shown myself that it is always true, so I wanted to show everyone so you could show me where I went wrong! Proof Let $\{u_n\}$ and $\{v_n\}$ be sequences in $\mathbb{R}$ such that $\lim_{n \rightarrow \infty } [u_{n} - v_{n}]=0$ If we apply the function to our sequences, then we have $\lim_{n \rightarrow \infty } [(fg)(u_{n}) - (fg)(v_{n})]$ $\lim_{n \rightarrow \infty } [f(u_{n})g(u_{n}) - f(v_{n})g(v_{n})]$ But since f and g were uniformly continuous, then limit of f(u) = f(v) and limit g(u) =g(v) So if we let the f's converge to a, and the g's converge to b, then it would seem that using the product rule for limits, we would wind up with ab - ab  which indeed equals zero, and would meet our criterion for uniform continuity. My guess is that I went wrong because I assumed that $fg(u_n) = f(u_n)g(u_n)$","['continuity', 'proof-verification', 'real-analysis', 'analysis', 'uniform-continuity']"
985387,Number of Symmetric Relations on a set A,"I'm having trouble understanding their explanation. I follow everything up to ""The Set $A_2$ contains $(1/2)(n^2 - n)$ subsets..."" could someone please help explain this to me? Source: Discrete and Combinatorial Mathematics, Ralph P. Grimaldi","['relations', 'discrete-mathematics']"
985392,derivative of $\ln((1+\beta)^x-1)$,How do I differentiate the term $\ln((1+\beta)^x-1)$ with respect to $x$? Is it possible to do it this way: $$\frac{1}{(1+\beta)^x-1}$$ But i get stuck if i do the normal differentiation.,"['calculus', 'derivatives']"
985447,$L^p$ norm of a gradient,"Suppose $f:\mathbb{R}^n\to \mathbb{R}$ and let $Df=(f_{x_1},f_{x_2},..., f_{x_n})$, the gradient of $f$. A special case of the Gagliardo-Nirenberg inequality says that $$||f||_{p^*}\leq C||Df||_{p}$$ But I can show that $$||f||_{p^*}\leq C\left(\sum_{i=1}^n||\frac{\partial}{\partial x_i}f||_{p}^p\right)^{1/p}$$ I am a bit confused about what the definition of $||Df||_{p}$ is. Is $$||Df||_{p}=\left(\sum_{i=1}^n||\frac{\partial}{\partial{x_i}}f||_{p}^p\right)^{1/p}$$ true? I had always thought that $$||Df||^p_{p}=\int{|Df|^p\,dx}=\int{\left((f_{x_1})^2+(f_{x_2})^2+...+(f_{x_n})^2\right)^{p/2}}$$ Thanks!","['sobolev-spaces', 'functional-analysis']"
985448,Proof: Minkowski sum polytope implies A and B polytopes,"Suppose $A$ and $B$ are convex sets and their Minkowski sum $A+B$ is a polytope. 
How do you prove that $A$ and $B$ are polytopes as well?","['geometry', 'polytopes', 'polyhedra', 'discrete-geometry']"
985456,How do I prove $[G:H\cap K]\leq [G:H][G:K]$?,"Reference: Infinite group with subgroups of finite index Let $G$ be a group. Let $H,K$ be subgroups of $G$ . How do I prove that $[G:H\cap K]\leq [G:H][G:K]$ ? Let's not assume any index is finite. Then, still the result holds? If so how do I prove it?",['abstract-algebra']
985506,"How to find the function $f$ that satisfies $f(x, y) = f(x^{-1}, y^{-1})^{-1}$ and $f(x, y)$ is $\approx$ $average(x, y)$?","Fist of all, I'm a programmer, not a mathematician, and I'm sorry for my non native English. And I'm sorry if the question is not appropriate, it is my first time here. Or if the question has no answer. I am writing a very complex program in the Scheme language and I'm stuck in a problem. I need a function that satisfies the following condition: First condition $$
f(x, y) = f(x^{-1}, y^{-1})^{-1} \tag{1}
$$ Well, I know that $f=\times$ or $f=\div$, e.g., can satisfies it. For example: if $f=\times$ and if $x = 5$ and $y = 8$ then: $$
f(x, y) = f(x^{-1}, y^{-1})^{-1} = 40
$$ But I have an extra condition, which makes it difficult: Second condition The result of $f(x, y)$ should be aprox. the simple average between them. I.e.: $$
f(x, y) \approx average(x, y) \tag{2}
$$ Example: if $x = 5$ and $y = 8$ then $f(x, y) \approx 6+\frac{1}{2}$ Or, at least something between $x$ and $y$, i.e.: $$
min(x, y) < f(x, y) < max(x, y) \tag{2}
$$ So, because of that second condition, I can now discard $f=\times$ and $f=\div$. $average$ itself does not work as well: For example: if $f=average$ and if $x = 5$ and $y = 8$ then: $$
average(x, y) = 6+\frac{1}{2}
$$
$$
average(x^{-1}, y^{-1})^{-1} = 6+\frac{2}{13}
$$
so
$$
average(x, y) \neq average(x^{-1}, y^{-1})^{-1}
$$ I have no idea how to solve it the right way, so I did some trial and error. The best I got was this: $$
f = average\left(average(x, y), average(x^{-1}, y^{-1})^{-1} \right)
$$ The distance between $f(x, y)$ and $f(x^{-1}, y^{-1})^{-1}$ is lower than if I use the $average$, but it is not zero yet. Also, it works fine to small numbers like $5$ and $8$, but if I try $x=123$ and $y=888$ e.g., it starts to get too far from the average, although satisfying the condition $min(x, y) < f(x, y) < max(x, y)$, what is fair for me in last case. In Scheme language (R5RS) this following function should return #t for any rational number $x > 0$ and $y > 0$ given the right fn I am looking for: (define satisfies (lambda (fn x y)
             (and (= (fn x y)
                     (/ 1 (fn (/ 1 x)
                              (/ 1 y))))
                  (= (fn x y) (fn y x))
                  (> (fn x y) (min x y))
                  (< (fn x y) (max x y))))) Is it possible to solve something like that? Is that too specific? Where should I start? Thank you. ** LATE EDIT ** Third condition $$
f(x, y) = f(y, x) \tag{3}
$$ Fourth condition (nice to have) $$
f(x, y) \in \mathbb{Q}  \tag{4}
$$ Known facts $x \approx y$ $x \in \mathbb{Q}$ $y \in \mathbb{Q}$ $x > 0$ $y > 0$ My final solution Thanks to @DanielV and @Macavity: $$
f(x, y) = \mathbb{R}\to\mathbb{Q}(\sqrt{xy}) \tag{a}
$$ $$
f(x, y) = \mathbb{R}\to\mathbb{Q}(\sqrt{x^{-1}y^{-1}})^{-1} \tag{b}
$$ if $min(x, y) < min(x^{-1}, y^{-1})$ then use $(a)$
else $(b)$ Assume in this solution: $\sqrt{n}$ is a grotesque approximation $\in \mathbb{R}$ of the real root. $\mathbb{R}\to\mathbb{Q}(x)$ is a function that converts a $\mathbb{R}$ number into $\mathbb{Q}$ number (losing precision, of course). Equivalent to inexact->exact function in Scheme language.","['average', 'functions', 'functional-equations']"
985548,"For a non-negative absolutely continuous random variable $X$, with distribution $F$. Why is $\lim_{t\rightarrow \infty}t(1-F(t))=0$?","So I am given a non-negative absolutely continuous random variable $X$ with distribution $F$, and density $p_X$. I am given the definition of expectation using simple functions and the survival function. Using those I need to prove that $$E(X)=\int_0^\infty xp_X(x)dx$$ So I am given that $$E(X)=\int_0^\infty 1- F(t)dt$$ After applying integration by parts I get $$E(X)=\lim_{t\rightarrow \infty}t(1-F(t)) +\int_0^\infty xp_X(x)dx.$$ I am having trouble justifying why the first term is 0. I have $$\lim_{t\rightarrow \infty}t(1-F(t))=\lim_{t\rightarrow\infty}t\int_t^\infty p_X(x)dx\leq\int_t^\infty xp_X(x)dx$$ But I dont know how to show the latter is 0.","['probability-theory', 'probability-distributions', 'probability']"
985560,Number of particles at time $t$,"A following problem appears in my text book under the section of induction: At time $0$, a particle resides at the point $0$ on the real line. Within $1$
second, it divides into $2$ particles that fly in opposite directions and
stop at distance $1$ from the original particle. Within the next second,
each of these particles again divides into $2$ particles flying in opposite
directions and stopping at distance $1$ from the point of division, and so
on. Whenever particles meet they annihilate (leaving nothing behind).
How many particles will there be at time $2^{11} + 1$? I checked the values up to time 16 and observed that each time we are dealing with the time point that corresponds to some power of 2 the distribution of particles is such that only the 2 ""outer"" particles (the left-most and right-most on the real line) remain, all of the ""inner particles"" are annihilated because they happen to ""collide"". So, I think the answer is that at time $2^{11} + 1$ the number of particles is exactly four, because at time $2^{11}$ only the outer particles remain (thus there are 2), and at the next time point ($2^{11}+1$) 2 more particles will be created from each (none are annihilated), so there must be two more, altogether 4. However, this hardly seems like a proof and lacks all mathematical rigour (although the problem does not ask for a proof). So, how would I come about proving this result?","['induction', 'discrete-mathematics']"
985596,Rank of a matrix and dimension of the image,"I'm teaching linear algebra to first year students, and I was recently asked why is the rank of a matrix, representing a linear application in a given basis, equal to the dimension of the image space of this application. If I think in terms of columns it is easy to see that applying it to the canonical basis vectors gives me a span of the image where every vector has for coordinates one column of the first matrix, thus the dimension of the image is the number of linearly independent columns. But is there an equivalent short argument for rows? I mean without using the fact that the rank is invariant by applying transposition, and possibly without introducing a dual space which could make things only more confusing for my students.","['vector-spaces', 'matrices', 'linear-algebra', 'matrix-rank']"
985611,Does every homogeneous space allow a group structure?,"Let $(X,\tau)$ be a homogeneous space , that is for all $x,y \in X$ there is a homeomorphism $\varphi:X\to X$ such that $\varphi(x) = y$. Is there a group operation $*:X\times X\to X$ such that $(X,*,\tau)$ is a topological group?","['general-topology', 'topological-groups', 'group-theory']"
985619,"Prove that $\int_{0}^{1}\sin{(\pi x)}x^x(1-x)^{1-x}\,dx =\frac{\pi e}{24} $","I've found here the following integral. $$I = \int_{0}^{1}\sin{(\pi (1-x))}x^x(1-x)^{1-x}\,dx=\int_{0}^{1}\sin{(\pi x)}x^x(1-x)^{1-x}\,dx=\frac{\pi e}{24}$$ I've never seen it before and I also didn't find the evaluation on math.se. How could we verify it? If it is a well-known integral, then could you give a reference?","['definite-integrals', 'closed-form', 'calculus', 'integration']"
985655,Optimized way to compute L1 distance matrix,"I'm computing distances between two groups of multi-dimensional points giving a matrix of distances pairwise between points. For the L2 (euclidean) distance I can use optimized matrix multiplication routines (blas etc.). X and Y which are matrices $ n\times k $, and $ m\times k $  comprised of the points $x_1..x_n $, and $y_1..y_m$ stacked as row vectors ($k$ is the dimension of the points), the final output D a matrix $ n\times m $ of pairwise distances, with elements: $ d_{ij} = ||x_i - y_j||^2  = ||x_i||^2 + ||y_j||^2 - 2x_i.y_j $ Where the last term $ 2x_i.y_i $ can be computed by matrix multiplication $2XY^T$ and the first two terms can be computed for each $ ||x_i||^2 = x_i . x_i $ and $ ||y_j||^2 = y_j . y_j  $ Better described in this paper: http://www.plosone.org/article/fetchObject.action?uri=info%3Adoi%2F10.1371%2Fjournal.pone.0092409&representation=PDF Is there any way to vectorize the L1 (Manhattan) distance similarly?","['algorithms', 'matrices', 'linear-algebra', 'numerical-methods', 'numerical-linear-algebra']"
985669,Calculating distance of camera in 3D environment,"I have a stage 840x840 px in size.
My viewport is 840x840 px and so is my cube. I want the face of my cube to fit exactly the space of the viewport and so the flash stage. How can I calculate the camera z distance to accomplish this? I've came up with something, but still it's not the solution of the problem.
I've analized the situation and came up with this graphic: According to this, what I'm looking for is a catethus of a right triangle and, since I've got the other one and the opposite angle degrees, I can use trigonometry to find it.
Still this doesn't work.
In my case the box side is 840 and so is the viewport width, while the camera FOV is 60. Through trial and error I found the right value for camera.z to be about -591 while using the formula in the image I get -1147.4613391789285
I really don't get what I'm missing. Hope someone can help me. Thank you!
Andrea","['trigonometry', 'computer-vision']"
985670,bibliography for weak solutions of ODE's,Could someone recommend to me some bibliography about weak solutions of ODE's and solutions of ODE's that are not Lipschitz or discontinuous??,"['nonlinear-system', 'ordinary-differential-equations', 'calculus']"
985686,"Evaluating $\int_0^{\frac{\pi}{2}}\ln\left(\frac{\ln^2\sin\theta}{\pi^2+\ln^2\sin\theta}\right)\,\frac{\ln\cos\theta}{\tan\theta}\,d\theta$","Prove $$\int_0^{\frac{\pi}{2}}\ln\left(\frac{\ln^2\sin\theta}{\pi^2+\ln^2\sin\theta}\right)\,\frac{\ln\cos\theta}{\tan\theta}\,d\theta = \frac{\pi^2}{4}$$","['calculus', 'integration', 'contest-math', 'definite-integrals', 'real-analysis']"
985687,Torsion-free module over a PID is flat,"Suppose a ring of integers $S$ is an extension of a ring of integers $R$ with $\mathfrak{q}$ a prime ideal in $S$ and $\mathfrak{p}=\mathfrak{q}^c$ in $R$. Is there a straightforward way of showing that $S_\mathfrak{q}$ is flat over $R_\mathfrak{p}$ from first principles? i.e. without just quoting a the theorem such as the one in the title (the proof of which in Bourbaki is somewhat obscure). I am happy that this then shows that $S$ is flat over $R$ which is the result I am actually after. A later thought (in the bath!): $S$ is f.g. over $R$ and $S-\mathfrak{q}\subset S-\mathfrak{p}$, so $S_\mathfrak{q}$ is f.g. over $R_\mathfrak{p}$. Moreover $S_\mathfrak{q}$ is torsion-free, hence free hence flat. Does this work?","['commutative-algebra', 'algebraic-number-theory', 'abstract-algebra']"
985701,"Connection between linear independence, non-/trivial and x solutions","I am having a hard time remembering which goes hand in hand with what. The math questions I get always include words like trivial etc. 1 solution no solution infinite amount of solutions And then we have the two types of set of vectors linearly independent linearly dependent A set of vectors is linearly independent iff the system of equations are satisfied when all vector scalars are = 0 (making all vectors zero vectors). This results in 1 solution , the solution is trivial ? A set of vectors is linearly dependent when there are an infinite amount of solutions to the system of equations. This is non-trivial ? Where does no solution come in? I understand that if there is no solution, then all of the vectors do not intersect at a specific coordinate(which is the solution to the system of equations). But does that mean the set of vectors is linearly independent or dependent?",['linear-algebra']
985722,$p$-summable series in a Banach space,"Let $E$ be a Banach space and denote its dual space by $E^*$. Let $p \in [1, \infty)$ and $x : \mathbb{N}\rightarrow E$ be such that for every $\phi \in E^*$,
$$\left( \sum_{n=1}^{\infty} \lvert \phi(x(n))\rvert^p \right)^{1/p}$$
is finite. Why is
$$\sup_{\phi \in E^*, \lVert \phi \rVert \leq 1} \left( \sum_{n=1}^{\infty} \lvert \phi(x(n))\rvert^p \right)^{1/p}$$
finite.","['functional-analysis', 'banach-spaces']"
985750,Solve $x^3 - x + 1 = 0$,"Solve $x^3 - x + 1 = 0$, this cannot be done through elementary methods. Although, this is way out of my capabilities, I would love to see a solution (closed form only). Thanks!","['cubics', 'algebra-precalculus']"
985778,Weighted sum of cosines,"Consider $$f(x) = \sum_{k=1}^\infty \cos(kx) k^\alpha.$$ The first question is: does this have a name (Mathematica gives it as a sum of polylogs of complex arguments, but this seems unnatural). Also, does the logarithmic derivative have a name and/or nice properties? (The exponent $\alpha$ in my applications is a negative real number, but I will take what I can get...)","['fourier-series', 'special-functions', 'analysis']"
985783,"How can I find the point where two algebraic equations, in the form $y=mx+b$, intersect without graphing?","Suppose I have these two algebraic equations in the format $y=mx+b$: $$
y=2x+4 \\
y=3x+5 \\
$$ Now, by graphing these two algebraic equations on a coordinate plane, I find that they intersect at the point $(-1,2)$. Now, I find it annoying sometimes when trying to find where two lines intersect, I have two pull out a sheet of graph paper and plot them, or make a table. How can I find the intersection point of two algebraic equations without doing either of these things?",['algebra-precalculus']
985802,Holder Inequality,"I have a problem with the demonstration of this inequality ('m following Royden) : If $p$ and $q$ are nonnegative numbers such that
$\frac{1}{p}+\frac{1}{q}$ and if $f \in L^p$ and $g \in L^q$, then $f\cdot g \in L^1$ and
$$\int |fg| \leqslant ||f||_p \cdot ||g||_q$$ 
Without loss of generality suppose $f,g \geqslant 0$ Set $h(x)=g(x)^{q-1}=g(x)^{p/q}$,since $q-1=q/p$ also $g(x)=h(x)^{q-1}=h(x)^{p/q}$ Thus for $t \in \bf{R}$:
$$ptf(x)g(x)= ptf(x)h(x)^{p-1} \leqslant (h(x)+tf(x))^p-h(x)$$ (because of lemma). Hence
$$pt \int fg \leqslant \int |h+tf|^p-\int h^p = ||h+tf||^p-||h||^p$$ and
$$pt \int fg \leqslant (||h||+t||f||)^p-||h||^p$$
Now is the passage that I do not understand: Differentiating both sides with respect to t at t=0, we get
$$p \int fg \leqslant p ||f|| \cdot ||h||_p^{p-1}=p||f|| \cdot ||g||$$ I do not see why I can derive from both sides of an INEQUALITY..","['inequality', 'lp-spaces', 'integral-inequality', 'analysis', 'banach-spaces']"
985807,Translation of an old paper by Frobenius,"I have an old paper: Frobenius, G. (1902). Uber primitive Gruppen des Grades $n$ und der Klasse $n - 1$ . S. B. Akad. Berlin 1902, 455-459. in the German language. Is there a way to access a translation of it? Or other proof in the English books or papers?","['reference-request', 'translation-request', 'group-theory', 'mathematical-german']"
985837,Find $\int_{ - \infty }^{ + \infty } {\frac{1} {1 + {x^4}}} \;{\mathrm{d}}x$,"How can we find the integral:
$$\int_{ - \infty }^{ + \infty } {\frac{1} {1 + {x^4}}} \;{\mathrm{d}}x$$
I tried to find and got it to be $\cfrac{\pi}{\sqrt2}$. Am I correct? Please help me with an appropriate method. I tried to use sum of residue.","['improper-integrals', 'calculus', 'integration', 'definite-integrals', 'contour-integration']"
985840,A dyadic decomposition of a random variable,"Let $X$ be a real-valued random variable with mean equal to zero. We consider $n$ identical copies $X_1,\ldots,X_n$ of $X$ and denote with $S_n=X_1+\cdots+X_n$ the sum of them.   We decompose the $X_j$ into a dyadic decomposition: $$X_j=X_{j,0}+\sum_{m=1}^\infty X_{j,m}$$where $X_{j,0}:=X_j I(X_j\leq 1)$ and $X_{j,m} := X_j I(2^{m-1}<X_j<2^m)$, $I$ denoting the indicator function. In a similar way we split
$$S_n=S_{n,0}+\sum_{m=1}^\infty S_{n,m}$$ with  $S_{n,m}=\sum_{j=1}^n X_{j,m}$. My question is: Why does the inequality $$P(|S_n|\geq C n)\leq \sum_{m=0}^\infty P \left(|S_{n,m}|\geq \dfrac{Cn}{100(m+1)^2}\right)$$ where $C$ denotes an arbitrary positive constant, hold ? I have a hint to use the pigeonhole principle and to apply the fact that the probability of the union of events is less then the sum of the probabilities of each of the events (i.e. rather elementary facts). Any help would be much appreciated.","['probability-theory', 'inequality', 'probability']"
985851,Compute $\sum_{k=0}^{n}\frac{1}{\binom{n}{k}}$ [duplicate],"This question already has answers here : Calculate the sum of inverse values of ${n\choose 0}, {n\choose 1}, ... {n\choose n}$ (2 answers) Closed 6 years ago . I want to calculate $\sum_{k=0}^{n}\frac{1}{\binom{n}{k}}$ . No idea in my mind. Any help? Context I want to calculate the expected value of bits per symbols in adaptive arithmetic coding when the number of symbols goes to infinity.","['summation', 'binomial-coefficients', 'combinatorics']"
985852,Determinant value of $2 \times 2$ matrices,"Let $a,b,c,d$ be integers such that $\dfrac ac \in \mathbb Q^+$\ $\mathbb Z^+ $ and $\dfrac bd \in \mathbb Q^- $ \ $ \mathbb Z^-$ ; then how many solutions does $|ad-bc|=1$ have ?",['number-theory']
985879,Relation between trace and rank for projection matrices,If $A $ is  an  $n \times n$  matrix  over $\mathbb C$ such that $A^2=A$ then is it true  that  $\operatorname{trace} A = \operatorname{rank} A$?,"['projection-matrices', 'trace', 'matrix-rank', 'matrices', 'linear-algebra']"
985911,Homeomorphism(topological spaces) version of Cantor–Bernstein–Schroeder theorem,"Let $A$ , $B$ be topological spaces such that there for some subset $D$ of $B$ there is a homeomorphism form $A$ to $D$ and for some subset $E$ of $A$ there is a homeomorphism form $B$ to $E$ ; then must there exist a homeomorphism from $A$ to $B$ ?","['general-topology', 'functions']"
985913,The tangent space of the boundary of a manifold with boundary is a subspace of the tangent space,I was trying to understand the following sentence in some notes I am reading: Let $M$ be a manifold with boundary. At any point $p \in {\partial}M$ there is a canonical subspace $T_{p}({\partial}M) \subset T_{p}(M)$; the quotient space is the a real line $\nu_{p}$. I know of $T_{p}(M)$ as the vector space consisting of operators or derivations $\nu: F(M) \rightarrow \mathbb{R}$ where $F(M)$ is the algebra of smooth functions from $M \rightarrow \mathbb{R}$. Does this natural subspace involve some sort of imbedding of a $F({\partial}M)$ into $F(M)$? I apologize if this question is obvious.,"['differential-topology', 'differential-geometry']"
985915,Prove whether a particular function is concave,"Given the following equation:
$$V(w) = - \frac{\alpha}{2} \left[ y_1(w) + y_2(w) + \int _{-\infty}^{+\infty} \vert y_1(w) - y_2(w) - x\vert f_{T1}(x)dx\right] \\- \beta \int _{w - y_1(w)} ^{+\infty} \left( y_1(w) + x - w\right) f_{T2}(x)dx$$ and the information that $\frac{\partial y_2(w)}{\partial w} \geq 0 $ and $\frac{\partial y_1(w)}{\partial w}=0$ $F_{k}(x)=\int\limits_{-\infty}^{x} f_{k}(t)dt$ is $k$'s cumulative distribution function which is continuous on a compact support where $k=\{T_1,T_2\}$ and $0 \leq f_k \leq 1 $ is $k$'s probability density function; and $\alpha, \beta > 0$ I would like to prove whether $V(w)$ is (strictly) concave, or if it is not concave, whether it is quasi-concave. Attempts :
I tried to see if the function has a second derivative that is negative. First, I derived: 
$$\frac{\partial V(w)}{\partial w} = -\alpha y_2^{\prime}(w)\left[1-F_{T_1}\left(y_1(w)-y_2(w)\right) \right] + \beta\left[1-F_{T_2}(w-y_1(w))\right]$$ and \begin{align}
\frac{\partial }{\partial w} \left(\frac{\partial V(w)}{\partial w}\right) &= -\alpha y_2^{\prime}(w)\left[1-F_{T_1}\left(y_1(w)-y_2(w)\right) \right] + \beta\left[1-F_{T_2}(w-y_1(w))\right] \\
&= -\alpha \left\{ y_2^{\prime \prime}(w)\left[1-F_{T_1}\left(y_1(w)-y_2(w)\right) \right] + (y_2^{\prime}(w))^2 f_{T_1}\left(y_1(w)-y_2(w)\right) \right\}  \\ 
 \quad \quad \quad  &- \beta f_{T_2} \left( w-y_1(w)\right) 
\end{align} However, I could not sign $y_2^{\prime \prime}(w)$ without additional information.","['multivariable-calculus', 'calculus', 'functions', 'probability', 'derivatives']"
985930,"There are 10 sticks of length 1,..,10. How many triangles can be formed","There are 10 distinct sticks of length 1,..,10. How many triangles can be formed? I do not know whether there are some counting tricks for this one.","['geometry', 'combinatorics']"
985958,On a linear $3\times 3$ system of differential equations with repeated eigenvalues.,I have the following system: $$\begin{cases} x'= 2x + 2y -3z \\ y' = 5x + 1y -5z \\ z' = -3x + 4y \end{cases} $$ $$\det(A - \lambda I)= -(\lambda - 1)^3$$ the eigenvector for my single eigenvalue is : $v_1 = \begin{pmatrix} 1 \\ 1 \\ 1 \end{pmatrix}$ I can't find any other linearly independent solutions. What can you do in this  $3\times 3$ case with only a single eigenvalue? If you wish you can provide a reference and then I will try my hand at solving it myself.,"['ordinary-differential-equations', 'systems-of-equations']"
985972,Would you accept this proof for $(A^c)^c = A$?,"In my exercises I had the following question: Prove that $(A^c)^c = A$. My solution: Let $A$ be a set where $A\subset X$. $A = \{x \in X, x \in A\}$ by definition. $A^c = \{x \in X, x \notin A\}$ Let $P(x)$ be the proposition that $x \in X$ and $Q(x)$ be the proposition that $x \in A$. Therefore: $A = P(x) \wedge  Q(x)$ $A^c = P(x) \wedge ¬Q(x)$ $(A^c)^c = P(x) \wedge ¬(P(x) \wedge ¬Q(x)) \iff P(x) \wedge (¬P(x) \vee Q(x)) \iff (P(x) \wedge ¬P(x)) \vee (P(x) \wedge Q(x)) \iff False \vee (P(x) \wedge Q(x)) \iff P(x) \wedge Q(x) = A$ Hence, $(A^c)^c = A$. Is this a solid enough proof, or should I do a different approach? Note: My actual written work contains references to De Morgan's Laws, and other propositions in the course that allow me to do the logical equivalences.","['elementary-set-theory', 'proof-verification']"
985988,"Find the limit of recursive sequence, if it exists: $a_{n+1}=\frac{7+3a_n}{3+a_n}$","My goal is to to test this recursive sequence if it's convergent and if yes, find the limit. $$a_1=3,\:a_{n+1}=\frac{7+3a_n}{3+a_n}$$ I know how to do this with normal sequences, but this is the first time we have to use a recursive sequence. If you calculate the first few parts you get: n | a(n) 1 | 3 2 | 2.66667 3 | 2.64706 4 | 2.64583 5 | 2.64576 6 | 2.64575 7 | 2.64575 8 | 2.64575 So I take it the sequence is convergent against 2.64575... But how do you prove that in a calculation?","['sequences-and-series', 'recurrence-relations', 'calculus', 'limits']"
986007,Find maximum number of nodes in a regular graph of degree 4 and diameter 2,"In $n$ nodes directed graph, every vertex has in-degree and out-degree equal to $4$.
If every vertex is reachable from every other vertex directed by a path of length at most $2$.
How can we find maximum value of $n$?","['graph-theory', 'discrete-mathematics']"
986029,T is not compact operator,"I want to show that if $T$ is a bounded operator between two Hilbert spaces and $T$ is not compact then there exists an orthonormal sequence $y_{n}$ and an $R>0$ such that $\forall n\in \mathbb{N}\,\,\,\|T(y_{n})\|\geq R$. I understand that there exists a sequence $y_{n}\in B[0,1]$ satisfying the above condition (because there exists a sequence doesn't contain any convergent subsequence), but i can't find an orthonormal one","['operator-theory', 'hilbert-spaces', 'functional-analysis', 'compact-operators']"
986030,Which integrals can be solved using Feynman's Technique?,How to check whether an integral can be easily solved using Feynman's approach. What are the main criteria needed to be taken into account?,['integration']
986034,Confusing algebra rule: why $\frac{7^{n+1}-1}{6} + 7^{n+1} = \frac{7^{n+2}-1}{6}$?,"Math rule I don't understand. My discrete math midterm is tomorrow and I'm studying proof styles. I came across a rule (algebra maybe?) I don't quite understand and I was hoping someone could explain it step by step for me. $$\frac{7^{n+1}-1}{6} + 7^{n+1} = \frac{7^{n+2}-1}{6}$$ I guess I can memorize it, but could someone show me how it works step by step? Thanks",['algebra-precalculus']
986049,What does the constant mean in Big O notation?,"I have a big issue in understanding the real meaning of Big O notation. Classical definition: $f(x) = O(g(x))$ as $x\rightarrow k$ if there exist $\delta, C > 0$ such that $f(x) \leq Cg(x)$ whenever $|x-k| < \delta$. I understand that the inequality holds when $|x-k| < \delta$ so we have an upper bound in that interval for $f(x)$ function. However, as there is a constant in the inequality I do not understand how it can help us to control the growth of the function. For example, if $C = 10^{100}$ then the bound would be quite different from $C = 1$ so I do not really know how big the bound of my function is. The problem is related to finite difference method with Taylor series, $f\in C^2$: $$\frac{f(x+h) - f(x)}{h} - f'(x) = O(h)$$ which means that as $h\rightarrow 0$ if there exist $\delta, C > 0$ such that $\frac{f(x+h) - f(x)}{h} - f'(x) \leq Cx$ whenever $h < \delta$. So, the error between the real derivative and approximation is bounded by $Cx$ but that bound is quite different if $C = 10^{100}$ or $1$. So, how Big O notation tells me the maximum error that I will have? That error could be as big as wanted making C big enough? Thanks a lot!","['finite-differences', 'discrete-mathematics', 'taylor-expansion']"
986053,What is known about$\sum\limits_{p\text{ prime}} \frac{1}{p^2-1}$?,Are there some known results for $\sum\limits_{p\text{ prime}} \dfrac{1}{p^2-1}$? I wasn't able to find anything about this sum in the internet or in my books!,"['reference-request', 'number-theory', 'analysis']"
986073,Trouble understanding algebra in induction proof,"I'm on hour 20 of studying for the discrete math midterm tomorrow, and I've got to be honest I'm a little panicked. In particular I'm having trouble with induction proofs, not because I don't understand the proofs but because of the algebra. Here is an example of a problem/solution my professor put up: 6. Give an induction proof to prove the quantified predicate, 
(All n, n >= 1, 1/2 + 1/2^2 + ... + 1/2^n = (2^n - 1)/2^n)

Sol:
Let P(n) be the predicate 
1/2 + 1/2^2 + ... + 1/2^n = (2^n - 1)/2^n

Base Case: n=1:
P(1) <=> 1/2 = (2-1)/2 <=> 1/2 = 1/2 <=> T

Induction Step:
(All n, n >= 1, P(n) => P(n+1))

  P(n)
=> {definition of P(n)}
  1/2 + 1/2^2 + ... + 1/2^n = (2^n - 1)/2^n
=> {add 1/2^(n+1) to both sides of ""=""}
  1/2 + 1/2^2 + ... + 1/2^(n+1) = (2^n - 1)/2^n + 1/2^(n+1)
=> {arithmetic}
  1/2 + 1/2^2 + ... + 1/2^(n+1) = (2*(2^n - 1) + 1)/2^(n+1)
=> {arithmetic}
  1/2 + 1/2^2 + ... + 1/2^(n+1) = (2^(n+1) - 1)/2^(n+1)
=> {definition of P(n+1)}
  P(n+1) After step two of the induction step I get confused about these transformations on the right hand side: $$(2^n - 1)/2^n + 1/2^{n+1}$$
$$(2\cdot(2^n - 1) + 1)/2^{n+1}$$
$$(2^{n+1} - 1)/2^{n+1}$$ I'll admit I'm not the best at math, but I really need to do well in this class. Could someone explain the logic of the transformations to me? I know the point is to replace the 'n' with 'n+1', but I don't see the logic of him multiplying by two in the second transformation. Thanks!","['logic', 'algebra-precalculus', 'predicate-logic', 'discrete-mathematics']"
986074,"Find this maximum of this $\frac{\int_{0}^{\pi}f(x) \, dx}{\int_{0}^{\pi} f(x)\sin x\,dx}$","Question: Assmue that $\int_0^\pi f(x)\,dx$ and $\int_0^\pi f(x)\sin x\,dx$ is convergence,and $f(x)>0,\forall x\in(0,\pi)$   Find this maximum as possible for all function $f$
  $$I=\dfrac{\int_0^\pi f(x)\,dx}{\int_0^\pi f(x)\sin{x}\,dx}$$ show that：
$$I\le\dfrac{4}{\pi}?$$ I think this problem is interesting,But I can't.",['analysis']
986089,Arctan(f(x)) is almost the same as Erf(f(x)) for many f(x). Is the just coincidence or is there a reason?,"For example: Arctan(x) is almost Erf(x) (subtle differences in absolute value and curve) Arctan(x^50) is almost Erf(x^50) (difference in absolute value) and many others, so we can conclude: Arctan(f(x)) ~ Erf(f(x)) (~ meaning Is a poor approximation of) Is there a reason for this or is this just a strange coincidence for the 10 equasion I tested (I listed only a few)?","['trigonometry', 'sequences-and-series', 'error-function', 'taylor-expansion']"
986103,Calculating a limit with infinitely many terms,"I've encountered this limit : $$\lim_{n\to\infty} \frac1n \left(\sin\left(\frac{\pi}{n}\right) + \sin\left(\frac{2\pi}{n}\right)+\cdots+\sin{\frac{(n-1)\pi}{n}}\right)$$ Wolfram gives the value: $2\over \pi$. We did something similar in class.
If I consider the function: $\sin(x\pi)$ and the equidistant partition: $j\over n$, I can somehow transform this problem into an integral. Could someone please give me some advices and\or guidance on how to proceed in this problem. Thanks for any suggestions in advance. edit: Thanks a lot guys.","['trigonometry', 'sequences-and-series', 'integration', 'limits']"
986186,How to prove that $\tan 55^\circ<\pi/2$,"How to prove that $\tan 55^\circ<\pi/2$? I checked it on a calculator, but how to prove it though? Is it some trigonometric substitution?","['geometry', 'trigonometry']"
986213,Is the sum of saturated ideals saturated?,"In a graded ring $S=\oplus_{k=0}^{\infty}S_k$, denote $m=\oplus_{k=1}^{\infty}S_k$, call an ideal $I$ to be saturated if $I=\cup_{n=1}^{\infty}(I\colon m^n)$. Is the sum of two saturated ideals still saturated? $$\cup_{n=0}^\infty((I+J)\colon m^n)=\cup_{n=0}^\infty(I\colon m^n)+\cup_{n=0}^\infty(J\colon m^n)$$ Is there a counterexample? Edit :
The question arises when I try to understand global complete intersection, Hartshorne Ex 8.4(a). We define a scheme of codimension $r$ to be complete intersection if the saturated homogeneous ideal us generated by $r$ elements. It is claimed that a subscheme is complete intersection iff it is the scheme intersection of $r$ hypersurfaces $H_i$. I am not clear how to show (1) A hypersurface is a complete intersection. That is for a subscheme of codimension $1$, its saturated homogeneous ideal is generated by one element. (2) Intersection of hypersurfaces is complete intersection. That is the saturated ideal of the sum of saturated principal ideals $(f_i)$ (assuming (1)) is saturated. As the question arises here, so would it be better to have an counterexample with $I,J$ saturated, the sum ideal $I+J$ define a nonempty subsceme of $\mathbb{P}^n$?","['commutative-algebra', 'algebraic-geometry']"
986231,Is a trigonometric function applied to a rational multiple of $\pi$ always algebraic? [duplicate],"This question already has answers here : Proof that a trigonometric function of a rational angle must be non-transcendental (4 answers) Closed 7 years ago . Specifically, just to talk about cosine, is it true that $\cos(\frac{a\pi}{b})$ is algebraic for integers $a$ and $b$? Looking at this post and the link to trigonometric constants in the comments, it seems likely that this is true. But most of the values calculated there are the result of sum/difference of angle formulas for existing algebraic values of sine and cosine. This came up when looking at $\cos(\frac{\pi}{7})$. If this is algebraic, how can we calculate it? If it is not, for which arguments will sine and cosine be algebraic and for which arguments will they be transcendental?","['trigonometry', 'transcendental-numbers']"
986248,Is there an infinite countable $\sigma$-algebra on an uncountable set,"Let $\Omega$ be a set. If $\Omega$ is finite, then any $\sigma$-algebra on $\Omega$ is finite. If $\Omega$ is infinite and countable, a $\sigma$-algebra on $\Omega$  cannot be infinite and countable. What about if $\Omega$ is not countable ? Is it possible to find an uncountable $\Omega$ with a $\sigma$-algebra that is infinite and countable ?","['measure-theory', 'cardinals', 'elementary-set-theory']"
986268,"Why ""$\lim\limits_{x\rightarrow \infty} \frac{x+\sin x}{x}$ does not exist"" is not an acceptable answer?","Find the limits: $\lim\limits_{x\rightarrow \infty}  \frac{x+\sin x}{x}$ Since the numerator and denominator tends to infinity as $x$ tends to infinity, then applying Lhopital's rule: $\lim\limits_{x\rightarrow \infty}  \frac{x+\sin x}{x} = \lim\limits_{x\rightarrow \infty}  \frac{1 + \cos x}{1}$ since $\cos x$ has no limit as $x$ tend to infinity ($\cos x$ oscillates between $-1$ and $1$), I conclude that the limit of $\frac{x + \sin x }{x}$ as $x$ tends to infinity does not exist too. Why is this answer wrong (the correct answer is 1) and at what point should I have realized that I made a mistake and abort this solution and try something else? Is $\frac{1 + \cos x}{1}$ considered an indeterminate form?","['trigonometry', 'calculus', 'limits']"
986343,Algorithm to compute whether a stabbing line exists for a set of line segments,Let $S$ be a set of $n$ segments in the plane. A line $L$ that intersects all segments of $S$ is called a traversal or stabber of $S$. Give a $\mathcal{O}(n^2)$ algorithm to decide if a stabber for $S$ exists using duality.,"['geometry', 'computer-science', 'computational-geometry', 'algorithms']"
986366,Tangent space to lie group at identity.,"I'm supposed to show that  for a Lie group G, $T_{(e,e)}G\times G \simeq T_eG\oplus T_eG$ and that $T_{(e,e)}m$ is given by $(X,Y)\mapsto X+Y$. I'm having trouble proving this. I'm not exactly clear what this means or how one would go about proving this.","['lie-groups', 'differential-geometry']"
986375,For which of the following functions the $\sum_{x\in S(f)}\frac{1}{x}$ converges?,"For real valued function $f$ define 
$$S(f)=\{x:x>0,f(x)=x\}$$
For which of the following functions the $\sum_{x\in S(f)}\frac{1}{x}$ converges? $\tan x,\tan^2x,\tan{\sqrt{x}},\sqrt{\tan x},\tan 2x$ I do not have any idea to solve this problem,I think all these have infinitely many fixed points.I need help. Thanks.","['convergence-divergence', 'functions']"
986377,$\int_{0}^\pi \frac{\sin(nx)}{\sin x} dx$,"How do I integrate :$\int_{0}^\pi \frac{\sin(n\theta)}{\sin \theta} d\theta $ I did the following:
$\int_{0}^\pi \frac{\sin(n \theta)}{\sin \theta}d\theta = \mbox{Im} \int_{0}^{\pi} \frac{e^{i n \theta}}{\sin \theta} d\theta = \mbox{Im} \int_{0}^{\pi} 2i \frac{e^{i n \theta}}{e^{i \theta}-e^{- i \theta}} d\theta$ Put $ z=e^{i \theta}$ then $ \mbox{Im} \int_{|z|=1} \frac{z^n}{(z^2-1)} dz$ Now I have problem , because the function $f(z)= \frac{z^n}{(z^2-1)}$ is not analytic on the boundary of the unit disk. Now I can not use the Cauchy Residue Theorem. The answer is $0$ if $n$ is even and $ \pi$ if $n$ is odd. I stuck: Any suggestions ?","['complex-analysis', 'contour-integration']"
986412,Function composition: $f^{653}(56)=?$,"Let $f(x) = \frac1{(1-x)}$. Define the function $f^r$ to be $f^r(x) = f(f(f(...f(f(x)))))$. Find $f^{653}(56)$. What I've done: I started with r=1,2,3 and noticed the following pattern:
$$f^r(x)= \left\{ 
\begin{array}{c}
\frac1{1-x}, when \  r\equiv 1\pmod 3 \\ 
\frac{x-1}x, when \  r\equiv 2\pmod 3 \\
x, \ when \  r\equiv 0\pmod 3
\end{array}
\right.  $$ As  $653\equiv 2\pmod 3$, $\\$ $f^{653}(56) = \frac{55}{56}$ BUT how can I prove that I'm right? By induction? I don't know what to do then, when I go from $r$ to $r+1$. Could you please share with me your reasoning by solving this problem? PS: This problem is from the book ""How to think like a mathematician"" by Kevin Houston.","['induction', 'calculus', 'algebra-precalculus', 'functions']"
986425,Trying to evaluate $\prod_{k=1}^{n-1}(1-e^{2k\pi i/n})$ for my complex analysis homework,"For my complex analysis homework, I am trying to show that the integral of the real function $1/(1+x^n)$, for integer $n\ge2$, along the positive real line is
$$\int_0^{\infty}\frac{dx}{1+x^n} = \frac{\pi}{n\sin(\pi/n)}.$$
The suggested approach is to consider the contour integral
$$\int_{\gamma}f(z)dz = \int_{\gamma}\frac{dz}{1+z^n},$$
where $\gamma$ is a contour construced such that it traverses all of the positive real line, but only a single simple pole is included. So I started out by factoring the polynomial in the denominator, which has (distinct) roots $\omega_k=\exp(i[\pi+2k\pi]/n)$, so that $1+z^n=(z-\omega_0)(z-\omega_1)\cdots(z-\omega_{n-1})$. Using this, I attempt to find the residue at $z=\omega_0$ (which is the single pole included in $\gamma$ by construction) by
$$\text{Res}_{\omega_0}f=\lim_{z\rightarrow\omega_0}\frac{1}{(z-\omega_0)\cdots(z-\omega_{n-1})}(z-\omega_0)= \frac{1}{(\omega_0-\omega_1)\cdots(\omega_0-\omega_{n-1})}.$$ I have found that for every $(\omega_0-\omega_k)=\exp(i\pi/n)-\exp(i\pi/n+2k\pi i/n)$, I can extract an $\omega_0$ from the $\omega_k$, yielding $(\omega_0-\omega_k)=\exp(i\pi/n)[1-\exp(2k\pi i/n)]$ such that we are left with
$$\text{Res}_{\omega_0}f=\frac{1}{\prod_{k=1}^{n-1} e^{i\pi/n}[1-e^{2k\pi i/n}]}=\frac{1}{e^{i\pi(n-1)/n}\prod_{k=1}^{n-1} \left(1 - e^{2k\pi i /n}\right)}.$$ Now, since I know the final answer, I strongly believe that 
$$\prod_{k=1}^{n-1}(1-e^{2k\pi i/n} )=n,$$
but I am having a very hard time trying to evaluate this product. Any pointers would be greatly appreciated.","['complex-numbers', 'complex-analysis']"
986460,Covariant derivative as a connection on a vector bundle,"In the Wikipedia article Connexion (vector bundle) , such a connection is defined as a function $\Gamma(E) \to \Gamma(E\otimes T^*M)$ . Then the definition of a covariant derivative is given as a function $\Gamma(E) \to \Gamma(E)$. But the article proceeds by saying that a covariant derivative is also a connection. How could a covariant derivative be a connection since the codomains
of those two kinds of objects appear to be different ? Are those two different definitions of a connection ? Some authors would use the $\Gamma(E) \to \Gamma(E\otimes T^*M)$ version, while others would use $\Gamma(E) \to \Gamma(E)$ ?","['connections', 'differential-geometry']"
986482,Different approaches to N balls and m boxes problem,"Suppose that you have N indistinguishable balls that are to be distributed in m boxes (the boxes are numbered from 1 to m). What is the probability of the i-th box being empty (where the i-th box is the box with the number i) given that the balls have equal chances of arriving at any box? I found two different approaches to solve this problem (which I post bellow). Since each of them leads to a different solution, I am having a hard time trying to find which one is incorrect. I am fairly sure that the first approach is correct since it follows the 'standard' way of solving problems involving indistinguishable balls, but I cannot find the error in the second one. I would greatly appreciate any help you could provide to solve this doubt. (1) First approach: (Bosons) The number of ways of distributing N indistinguishable balls into m boxes is equal to: $$\binom{N + m -1}{N}=\frac{(N + m - 1)!}{N!(m-1)!} $$ On the other hand, the number of ways to distribute the balls and leaving the i-th box empty can be obtained by leaving the i-th box empty and distributing the N balls into the remaining m - 1 boxes. This is equal to: $$\binom{N + m - 2}{N}=\frac{(N + m - 2)!}{N!(m-2)!}$$ Therefore the probability of the i-th box being empty is the quotient of the second number by the first: $$\frac{(N + m - 2)!}{N!(m-2)!}.\frac{N!(m-1)!}{(N + m - 1)!}=\frac{m-1}{N + m - 1}$$
(2) Second approach: (Counting functions) Suppose that before distributing the balls into the boxes we number them from 1 to N. Then for each ball, the number of ways of distributing that ball into the m boxes is m. So the number of ways to distribute N balls into m boxes is: $$m^N$$ If we want to distribute N numbered balls into m boxes leaving the i-th box empty, each ball can only go to the m-1 remaining boxes. Therefore the number of ways in which this can be done is: $$(m-1)^N$$ And the desired probability will be the quotient: $$\left(\frac{m-1}{m}\right)^N \neq \frac{m-1}{N + m - 1}$$ Thank you very much for your time.","['probability', 'combinatorics']"
986506,"Finding all the values of n, such that $ \varphi (n) = 12 $ [duplicate]","This question already has answers here : Using Euler's Totient Function, how do I find all values n such that $\phi(n)=12$? [duplicate] (3 answers) Closed 9 years ago . I have not broken this down very far.
I have come to the conclusion that there are infinitely many values for n where there exists  12 coprimes to n. Since there are infinitely many primes, and primes are coprimes to any number smaller than that prime, I reach that conclusion. Can anyone stop me and tell me where I'm going wrong or how to approach this. I've used the theorem: $ \varphi (n) = ((1-\frac{1}{p_{1}})...(1-\frac{1}{p_{k}})) $ But to compute these values would one not need to write a program to run which slots in all these primes?","['prime-numbers', 'totient-function', 'discrete-mathematics', 'number-theory']"
986508,Reference request regarding calculus exam,"I'm currently a first year computer science student and I'm deeply interested in calculus . That being said, what we studied so far consists of: Cantor sets, sequences and a brief introduction to series and convergence tests. Our final exam is going to be set sometime in February and I took the liberty of looking up exams from past years. Since the structure is mainly the same, I'll post the relevant content of a final: Find the Fourier series for $f(x) = x\left|x\right|$ on $[ - \pi ,\pi ]$ and the value of the series for $x = \pi$. Compute the integral  $\int\limits_0^1 {\frac{x}{{\sqrt[3]{{1 - x^3 }}}}}\,\mathrm dx $ using Beta integrals and study its convergence Compute $\int\int_D xy\,\mathrm dx\,\mathrm dy $ where $D = \left\{ (x,y)\mid 2x^2  + y^2  \le 2,x \ge 0,x \le y \le 3x\right\}$. Find the volume bounded by the following two surfaces: $x^2  + y^2  = 1,\,\,z = \sqrt {x^2  + y^2 } ,z \ge 0$ . Approximate the value of this integral to two decimal places: $\int\limits_0^{\frac{1}{4}}\mathrm e^{-x^2}\,\mathrm dx
$. Find the extrema of $f(x,y) = 4(x - y) - x^2  - y^2$. I know this might be a lot to ask for free, but I really like calculus and I want to learn on my own. I'm really eager to study but I need a bit of guidance.
So, to get to the question, can anyone suggest some reading materials that could cover these areas? EDIT : I posted this question almost a week ago hoping someone would answer,after seeing that my post didn't get much attention I placed a bounty on it, but still nobody comes forward with answers/comments. Since apparently no one can shed any useful insight on this matter, maybe it is because my post is poorly structured. If so, can you at least suggest an edit ?
Thanks.","['calculus', 'reference-request', 'soft-question']"
986518,Union of subgroups is a subgroup if and only if one subgroup is a subset of the other [duplicate],"This question already has answers here : If a group is the union of two subgroups, is one subgroup the group itself? (3 answers) Closed 9 years ago . Let $H$ and $K$ denote two subgroups of a group $G$.  Prove that the union $H \cup K$ is a subgroup of $G$ if and only if $H \subset K$ or $K \subset H$.",['group-theory']
986525,sheafification construction in Hartshorne,"In section II.1 of Hartshorne, the sheaf $\mathscr F^+$ associated to a presheaf $\mathscr F$ is constructed so that $\mathscr F^+(U)$ is the set of functions
$$
  s\colon U \to \bigcup_{p \in U} \mathscr F_p
$$
with $s(p) \in \mathscr F_p$ and satisfying some local condition. I am confused by the appearance of the union here.
First of all, I don't see any larger object containing the stalks $\mathscr F_P$ in which to take the union. 
So I will assume this is meant to be a disjoint union.
This doesn't really bother me. My real question is: If we want each $\mathscr F^+(U)$ to have the structure of an abelian group, shouldn't this union be a product?","['sheaf-theory', 'algebraic-geometry']"
986541,Find derivative of $f(x)=\frac{1}{\sqrt{x+2}}$ by definition,Use the definition of a derivative to find the derivative of: $$f(x)=\frac{1}{\sqrt{x+2}}+2x$$ my work: $$\lim_{h\to0}\frac{f(x+h)-f(x)}{h}$$ $$\lim_{h\to0}\frac{\frac{1}{\sqrt{x+h+2}}+2(x+h)-\frac{1}{\sqrt{x+2}}-2x}{h}$$ $$\lim_{h\to0}\frac{\frac{1}{\sqrt{x+h+2}}+2h-\frac{1}{\sqrt{x+2}}}{h}$$ $$\lim_{h\to0}\frac{\frac{1}{\sqrt{x+h+2}}-\frac{1}{\sqrt{x+2}}}{h}+2$$ $$\lim_{h\to 0}\frac{1}{h}\frac{\sqrt{x+2}-\sqrt{x+h+2}}{\sqrt{x+h+2}\sqrt{x+2}}+2$$ I don't know what to do from here.,"['radicals', 'calculus', 'derivatives', 'limits']"
986571,Integral involving hyperfactorial,"I'm trying to prove that:
$$
\int_0^1 \ln\left(K(x)\right)\space dx =-\zeta'(-1)=\ln(A)-\frac{1}{12}
$$
Where $A$ is Glaisher Kinkelin's constant and $K(x)$ is a generalization of the hyperfactorial given by:
$$
K(n+1)=\prod_{k=1}^{n} k^k
$$
$$
K(x)=\lim_{r\to\infty} \frac{e^{\frac{1}{2}x(x+1)}\cdot r^{xr+\frac{1}{2}x(x+1)}\cdot K(r+1)}{x^x\cdot (1+x)^{1+x}\cdots(r+x)^{r+x}}
$$
I arrived to show the following using the limit representation: $$
K(x)=x^{-x}\cdot(2\pi)^{-\frac{x}{2}}\cdot e^{\frac{1}{2}x(x+1)-\frac{\gamma}{2}x^2}\cdot\prod_{k=1}^\infty \left[\frac{e^{x+\frac{x^2}{2k}}}{\left(1+\frac{x}{k}\right)^{x+k}}\right]
$$ But I wasn't able to proceed further. So any help is highly appreciated.","['definite-integrals', 'gamma-function', 'calculus', 'zeta-functions']"
986588,Geometric interpretation of linear forms in the sum of four (or eight) squares identity,"There is a well-known sum-of-squares identity $$(a^2+b^2)(c^2+d^2)=(ac+bd)^2+(ad-bc)^2. \tag{1}$$ Moreover, letting $\vec{u}=[\begin{smallmatrix}a\\b\end{smallmatrix}]$, $\vec{v}=[\begin{smallmatrix}c\\d\end{smallmatrix}]$, and $\theta=\angle\vec{u}\vec{v}$, we have $$\begin{array}{llrl} ac+bd & = & \vec{u}\cdot\vec{v} & = & \|\vec{u}\|\|\vec{v}\|\cos\theta \\ ad-bc & = & \det[\vec{u}~\vec{v}] & = & \|\vec{u}\|\|\vec{v}\|\sin\theta \end{array} \tag{2}$$ So the bilinear forms $ac+bd$ and $ad-bc$ have a geometric interpretation in terms of $\vec{u},\vec{v}$. There is also a four-squares formula: $$(x_1^2+x_2^2+x_3^2+x_4^2)(y_1^2+y_2^2+y_3^2+y_4^2)=z_1^2+z_2^2+z_3^2+z_4^2 \tag{3}$$ where $$\begin{cases} z_1 = x_1y_1-x_2y_2-x_3y_3-x_4y_4 \\
z_2 = x_2y_1+x_1y_2-x_4y_3+x_3y_4 \\
z_3 = x_3y_1+x_4y_2+x_1y_3-x_2y_4 \\
z_4 = x_4y_1-x_3y_2+x_2y_3+x_1y_4  \end{cases} \tag{4}$$ Question: do the bilinear forms $z_{1,2,3,4}$ have a geometric interpretation in terms of $\vec{x},\vec{y}$? What about the forms in the sum-of-eight-squares identity? The form $z_1$ looks related to quaternions, which I have heard admit some kind of geometric interpretation. However the forms seem to privilege the first coordinate axis over the other three, and furthermore the quadratic forms in $(4)$ at a glance don't seem invariant under linear isometries of space, unlike the forms in $(2)$, and too sensitive of a coordinate-dependence seems to throw a wrench into the possibility of a pure geometric interpretation. There is additionally the question of ""what other pure geometric information is there concerning two vectors other than their sizes and the angle between them?"" Naively, I'd wager four different forms can't derive from one data point, unlike two (since there are precisely two basic trig functions: sine and cosine). So I am somewhat anxious that there may not be a good geometric interpretation.","['geometry', 'sums-of-squares']"
986684,How to solve the integral: $\int {\sqrt{1+\sqrt{x}}}/x dx$,"$$\int \frac{{\sqrt{1+\sqrt{x}}}}{x} dx$$ I tried with $u=\sqrt x $, but this did not work. I really don't know what to do...",['integration']
986690,$\int_{0}^{\infty} x \cdot \cos(x^3) dx$ convergence,"$$\int_{0}^{\infty} x \cdot \cos(x^3) dx$$ I only want to prove, that this integral converges, I don't need to calculate the exact value.
I don't know what to do with the cosinus, I can't get rid of it. I know that the integral is equal to $$\frac{1}{3} \cdot \int_{0}^{\infty} \frac{\sin(x^3)}{x^2} dx$$
but here is also the problem, that I can't get rid of the sinus... Any hints?",['real-analysis']
986695,Convergence of sequence of integrals.,"Let $(\mathcal{X}, \mathcal{A}, \mu)$ be a measure space, $f_n: \mathcal{X} \to \Bbb R$ a sequence of measurable functions, and $g_n:\mathcal{X} \to \Bbb R$ integrable functions such that $|f_n| \leq g_n$. Let $f$ and $g$ measurable functions, $g$ integrable, with $f_n(x) \to f(x)$ and $g_n(x) \to g(x)$. If $\int_{\mathcal{X}} g_n  \ \mathrm{d}\mu \to \int_{\mathcal{X}} g \ \mathrm{d}\mu $, then $\int_{\mathcal{X}} f_n \ \mathrm{d}\mu \to \int_{\mathcal{X}} f \ \mathrm{d}\mu $. I think that the idea is to dominate all those $f_n$ with some integrable function, and then by the Dominated Convergence Theorem, we're done. The problem is that each $f_n$ is dominated by $g_n$, it's not the same function dominating all of them. Ok, I know that: $$f_n \leq |f_n(x)| \leq g_n(x) \implies |f(x)| \leq g(x) \quad \mbox{and}\quad \int_{\mathcal{X}} f_n \ \mathrm{d}\mu \leq \int_{\mathcal{X}} g_n \ \mathrm{d}\mu.$$ Taking limits, we get:
$$\limsup \int_{\mathcal{X}} f_n \ \mathrm{d}\mu \leq \int_{\mathcal{X}} g \ \mathrm{d}\mu $$ But other than this, I don't know how to do it. Can someone give me some help (or hints of how to use this info)? Thanks.","['measure-theory', 'integration', 'real-analysis']"
986698,Zero divisors and invertible elements,"I have learned about $X_n = \mathbb{Z} / n\mathbb{Z}$. I understand that a zero divisor is an element $x\neq 0$ in $X_n$ such that $xy = 0$ for some $y\neq 0$. I understand that an element $x$ in $X_n$ is invertible if there is a $y$ in $X$ such that $xy=1$. My question is if it is true that $X_n$ is the disjoint union of the invertible elements and the zero divisors? I think this is true since for example in $X_5$ there are no zero divisors and all elements are invertible. In $X_6$ the invertible elements are $1, 5$ and the zero divisors are $2,3, 4$. And $X_6$ is exactly the union of those two sets and the two sets are disjoint. If I am right that this is correct, I would like a hint on how to prove it. (This is not homework, but I would like to try to proof myself if I can get help started.)","['modular-arithmetic', 'self-learning', 'discrete-mathematics', 'integers']"
986727,Confidence Interval has no relation to the probability?,"An Intro to Stats class has the following problem: Find and interpret the 90% confidence interval for the true mean The provided answer is this: The probability is either 1 or 0. 
Its either true or it isn't! No maybes. This answer confuses me. I thought the 90% confidence interval means there's a 90% probability that the mean is in that interval. Does the confidence interval really have no bearing on the probability? Can someone explain why the provided answer makes sense at an introductory level? I've looked at this question , but it doesn't seem to answer my question at all.","['statistics', 'probability']"
986734,Requesting deeper understanding of binomial coefficient,"I noticed that $\binom {52} 4$ * $\binom {48} 1$ is $5$ times that of $\binom {52} 5$. So for example, if we were to draw $4$ cards from a standard deck then draw $1$ more, we cannot just say there are $\binom {52} 4$ * $\binom {48} 1$ ways to do that because we counted $5$ times too high that way.  So my question is what is a more general formula for this type of thing? Suppose ""k"" is anywhere from $1$ to $4$ cards on the first ""group"" so we have $\binom {52} k$, so then the 2nd group would be $\binom {52-k} {5-k}$, but what would the ""correction factor"" be in the semi-general case?  For example, in the $\binom {52} 4$ * $\binom {48} 1$ case it was $5$x too high so we need to divide by $5$ to get it to equal $\binom {52} 5$.  What about if we only chose $3$ cards the first go round or only $2$...? Next suppose we didn't restrict ourselves to having $52$ cards to choose from but rather n cards and we choose k of them such that k is no more than half of n and n is at least $10$.  Then what can we say generically about ""busting"" up our draw into $2$ ""groups"" and then ""correcting"" them?","['probability-theory', 'probability']"
986763,No simple groups of order 9555: proof,"While reading through crazyproject, I came across the following proof that there were no simple groups of order $9555$. However, I do not understand the step that says: ""Moreover, since 7 does not divide 12 and 13 does not divide 48, $P_7P_{13}$ is abelian."" I don't quite follow this reasoning. If someone could explain this to me I'd be very grateful.","['finite-groups', 'group-theory']"
986776,"why $f$ is holomorphic if $f(z) = \frac{1}{2\pi i} \int_\gamma \frac{f(\zeta)\, d \zeta}{\zeta - z}$?","I'm reading Gong Sheng's Concise Complex Analysis to get some basic understanding. On $\S 2.4$ page 61 Theorem 2.15 (Hurwitz Theorem) it says Theorem 2.15 (Hurwitz Theorem) Let $\{f_j\}$ be a sequence of holomorphic functions on $U\subseteq \mathbb C$ that converges uniformly to a function $f$ on 
  every compact subset of $U$. If $f_j$ is never equal to zero on $U$ for all $j$, then 
  $f$ is either identically zero or never equal to zero on $U$. Proof: For an arbitrary point $z \in U \subseteq \mathbb C$, choose a simple closed curve $\gamma$ in $U$ such that the inside of $\gamma$ contains $z$. 
  Since $f_j$ is holomorphic on $U$, by Cauchy integral formula we have $$f_j(z)=\frac{1}{2\pi i}\int_\gamma \frac{f_j(\zeta)\,d \zeta}{\zeta-z}$$
  Since $\{f_j\}$ converges uniformly on every compact subset of $U$, we have 
  $$\lim\limits_{j\to \infty} f_j(z) = \lim\limits_{j\to \infty} \frac{1}{2\pi j} \int_\gamma \frac{f_j(\zeta)\,d \zeta}{\zeta-z}  = \frac{1}{2\pi j} \int_\gamma \lim\limits_{j\to \infty} \frac{f_j(\zeta)\,d \zeta}{\zeta-z} $$
  It follows that $$f(z) = \frac{1}{2\pi i} \int_\gamma \frac{f(\zeta) \, d \zeta}{\zeta - z}$$
  Hence, $f(z)$ is a holomorphic function. 
  Similarly, we can prove that $\{f_j'(z)\}$ converges uniformly to $f'(z)$ on every compact subset of $U$. If $f(z)$ is not identically zero, then by Theorem 2.13, the zeros of $f$ are  discrete. Let $\gamma$ be a curve that does not pass through these zeros. Then 
  $$\frac{1}{2\pi i} \int_\gamma \frac{f_j'(\zeta)}{f_j(\zeta)\, d \zeta} \to \frac{1}{2\pi i} \int_\gamma \frac{f'(\zeta)}{f(\zeta)\, d \zeta}$$
  as $j\to \infty$.
  By the assumption and Theorem 2.14, we have 
  $$\frac{1}{2\pi i} \int_\gamma \frac{f_j'(\zeta)}{f_j(\zeta)\, d \zeta} = 0$$
  Therefore  $$\frac{1}{2\pi i} \int_\gamma \frac{f'(\zeta)}{f(\zeta)\, d \zeta} = 0$$
  and $f(z)$ has no zero on $U$. I wonder why $f(z)$ is a holomorphic function once $f(z) = \frac{1}{2\pi i} \int_\gamma \frac{f(\zeta) \, d \zeta}{\zeta - z}$? So far from that book I only know such ways to determine a function is holomorphic By definition, that is $f(z)$ is holomorphic in $U$, iff $\forall z\in U$, $\lim_{h\to 0} \frac{f(z+h)-f(z)}{h}$ exists, here $h \in \mathbb C$. Cauchy-Riemann equation, that is, if $f(z) \in \mathscr L ^1 (U)$ and fulfills the Cauchy-Riemann equation $\frac{\partial f}{\partial x} = -i \frac{\partial f}{\partial y}$, then $f$ is holomorphic on $U$, here $z=x+iy$. Power series expansion (Taylor series): $f(z)$ is holomorphic in $U$ iff $f$ has a power series expansion $\forall z \in U$. Morera theorem:  If $f(z)$ is continuous on $U$ and 
the integral of $f$ along any rectifiable closed curve is zero, then $f(z)$ is 
holomorphic on $U$. It seems none of such 1-4 could get to the conclusion that $f(z)$ is a holomorphic function?",['complex-analysis']
986800,Prove that:$\int_{a}^{b} f(x) dx = b \cdot f(b) - a \cdot f(a) - \int_{f(a)}^{f(b)} f^{-1}(x) dx$ [duplicate],"This question already has answers here : Show rigorously that the sum of integrals of $f$ and of its inverse is $bf(b)-af(a)$ (6 answers) Closed 6 years ago . I just wanted to ask, if my proof is correct.
I haven't seen the equation before, but I think it's quite useful. Let $f$ be an bijective differentiable function. Then the inverse function $f^{-1}$ exists and the following equation holds: $$\int\limits_{a}^{b} f(x) dx = b \cdot f(b) - a \cdot f(a) - \int\limits_{f(a)}^{f(b)} f^{-1}(x) dx$$ Proof. $f$ is an bijective differentiable function and $F$ is an antiderivative of $f$. First we need to find an antiderivative of $f^{-1}$. $\int f^{-1}(x) dx$ with substitution $x = f(y)$ yields: $$\int y \cdot f'(y) dy = y \cdot f(y) - \int f(y) dy = y \cdot f(y) - F(y)$$ resubstitution yields: $$\int f^{-1}(x) dx = x \cdot f^{-1}(x) - F(f^{-1}(x))$$
hence $\int\limits_{f(a)}^{f(b)} f^{-1}(x) dx = \left[x \cdot f^{-1}(x) - F(f^{-1}(x)) \right ]_{f(a)}^{f(b)}$ $$=b \cdot f(b) - F(b) - (a \cdot f(a) - F(a)) = F(a) - F(b) + b \cdot f(b) - a \cdot f(a)$$
$$= \int\limits_{b}^{a} f(x)  dx + b \cdot f(b) - a \cdot f(a) = -\int\limits_{a}^{b} f(x)  dx + b \cdot f(b) - a \cdot f(a)$$ All in all: $$\int\limits_{f(a)}^{f(b)} f^{-1}(x) dx = -\int\limits_{a}^{b} f(x)  dx + b \cdot f(b) - a \cdot f(a)$$ which is equal to $$\int\limits_{a}^{b} f(x) dx = b \cdot f(b) - a \cdot f(a) - \int\limits_{f(a)}^{f(b)} f^{-1}(x) dx$$ q.e.d.","['calculus', 'integration', 'real-analysis', 'analysis', 'surfaces']"
986804,Why do we care about non-$T_0$ spaces?,"(Reminder: A $T_0$ topological space, also known as a Kolmogorov space , is a space where the topological structure ""recognizes"" that different points are different : No two points have exactly the same open sets around them.) For a space that is not $T_0$, we can uniquely form a $T_0$ space from it by taking the Kolmogorov quotient , which just means sending two points to the same point in the quotient iff they are, so to speak, a counterexample to $T_0$-ness. This induces an isomorphism (i.e. order-preserving, union-/finite intersection-compatible bijection) on the topologies of the old space and the new space , and the new space is homeomorphic to any other $T_0$ space with the same topology . Wikipedia seems to say that we can toggle $T_0$-ness on and off and get analogous theorems in many cases. But it also says, ""[...] it may also be easier to allow structures that aren't T0 to get a fuller picture."" In short, I'm wondering: What does point-set topology lose if we require topological spaces to always be $T_0$? (Probably nothing, in pure point-set topology.) What non-$T_0$ spaces in other fields have desirable properties that are lost on Kolmogorov quotient? (P.S.: I admit that I've been thinking about pointless topology. There's no tag for it?)","['general-topology', 'motivation']"
986805,Is the Square Root of an Inverse Matrix Equal to the Inverse of the Square Root Matrix?,"I know in general that if a matrix $A$ is positive definite, then there exists a (unique?) square root matrix $B$, which is also positive definite, such that $BB=A$. Therefore, suppose $A$ is positive definite. It is invertible, and its inverse is also positive definite. Therefore I know there exists $C$ (possibly unique?) so that $CC=A^{-1}$. For simplicity, I will call $C=A^{-1/2}$, so that in this notation $A^{-1/2}A^{-1/2}=A^{-1}$. My question is, is it also true that $A^{-1/2}AA^{-1/2}=I$? Or is this not necessarily true? I have posted an attempted solution below -- please let me know what you think. Thanks! Edit It occurs to me that at the essence of this question is whether or not $B=C^{-1}$; is this necessarily true? That is, is square root of the inverse of a matrix equal to the inverse of the square root of the matrix? (This also partly depends on whether or not $B$ and $C$ are themselves invertible; would this be true?) Edit 2 There's now a related topic which asks what kind of matrix decomposition we're using here (and the differences between these different approaches to matrix decomposition. That question can be found here .","['matrix-decomposition', 'least-squares', 'matrices', 'linear-algebra', 'regression']"
986826,Is there a classification for the generating sets of symmetric group?,"Is there a classification for the generating sets of symmetric group? Or, is there an algorithm for checking wheather a subset is a generating set? For example, can $S_7$ be generated by all its $4$-cycles? Can $S_7$ be generated by all its $4$-cycles whose entries are consecutive i.e. $\{(1 2 3 4), (2 3 4 5),\dots,(7 1 2 3)\}$?",['group-theory']
986829,"L'Hopital's Rule, Factorials, and Derivatives","I have the following limit $\displaystyle\lim_{n\to\infty}\frac{e^n}{n!}$. Now if I try to solve this using this using L'hopital's rule, I won't be able to since I can't take the derivative of $n!$. My question is why can't I take the derivative? Generally speaking, why can't I take the direct derivative of a factorial? I've seen other questions, but I just want a more simple answer (for someone at the Calculus 1 or 2 level). Thank you in advance","['factorial', 'sequences-and-series', 'calculus', 'derivatives']"
986835,Finding the sum of $\sin(0^\circ) + \sin(1^\circ) + \sin(2^\circ) + \cdots +\sin(180^\circ)$,I need help understanding the sum of $\sin(0^\circ) + \sin(1^\circ) + \sin(2^\circ) + \cdots +\sin(180^\circ)$ or $\displaystyle \sum_{i=0}^{180} \sin(i)$ This might be related to a formula to find the average voltage from a generator used to gauge waves: $V_\text{avg} = 0.637 \times V_\text{peak}$. I am currently learning about AC circuits in the military.,"['summation', 'algebra-precalculus']"
986861,"Derivative of $y=\tan(3)e^x$,","If, $y=\tan(3)e^x$, wouldn't the derivative be $y\;'=\sec^2(3)e^x \times e^x$? The outer function times the inner function, using the chain rule? The answer key gives the derivative as $y=e^x \tan 3$ and I don't understand this.","['calculus', 'derivatives']"
986888,"Selecting cells so that every $2\times 2$ square is odd, then even","Jacob selects some cells from a $12\times9$ table, so that every $2\times 2$ subsquare contains an odd number of selected cells. He then selects some more cells, so that every $2\times 2$ subsquare now contains an even number of selected cells. What is the minimum number of selected cells at the end? [Source: Russian competition problem]","['extremal-combinatorics', 'contest-math', 'combinatorics']"
986904,How to evaluate $\int_0^1\frac{\tanh ^{-1}(x)\log(x)}{(1-x) x (x+1)} \operatorname d \!x$?,"How to evaluate the following integral $$\int_0^1\frac{\tanh ^{-1}(x)\log(x)}{(1-x) x (x+1)} \operatorname d \!x $$ The numerical result is $= -1.38104$ and when I look at it, I have no idea how to work on it. Could you provide me hits to evaluate the integral above? Thank you.","['improper-integrals', 'closed-form', 'calculus', 'integration', 'definite-integrals']"
