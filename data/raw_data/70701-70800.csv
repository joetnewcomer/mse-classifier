question_id,title,body,tags
864039,How find this limit $I=\lim_{n\to\infty}\sum_{k=0}^{n}\frac{\cos{\sqrt{\frac{k}{n}}}}{2^k}$,"$$I=\lim_{n\to\infty}\sum_{k=0}^{n}\dfrac{\cos{\sqrt{\dfrac{k}{n}}}}{2^k}$$ my idea: since
$$\cos{\sqrt{\dfrac{k}{n}}}\le 1$$
so
$$I\le\lim_{n\to\infty}\sum_{k=0}^{n}\dfrac{1}{2^k}=2$$ But How show $I\ge 2?$ Thank you",['limits']
864055,p-norm of a function,"Let $f\in L^1(\mu)\cap L^\infty(\mu)$. I have proved for any $1<p<\infty$, $f\in L^p(\mu)$, $w(p)=||f||_p$ is continuous w.r.t. $p$, and  $\lim_{p\to \infty}||f||_p=||f||_\infty$. Is $w(p)$ differentiable? Will $w(p)$ be a concave or convex function w.r.t. $p$ when $p$ sufficiently large?","['integration', 'measure-theory', 'lp-spaces', 'real-analysis', 'functional-analysis']"
864076,"Expressing a quadratic form, $\mathbf{x}^TA\mathbf{x}$ in terms of $\lVert\mathbf{x}\rVert^2$, $A$","EDIT: This question is actually an attempt to solve this . Please take a look. Let $A$ be a symmetric postive-definite $n\times n$ matrix, i.e. $A\in\mathbb{S}_{++}^{n}$ Also, let $\mathbf{x}\in\mathbb{R}^n$. Let $Q\colon\mathbf{R}^n\to\mathbb{R}^{*}_{+}$ be the following quadratic form
$$
Q(\mathbf{x})=\mathbf{x}^TA\mathbf{x}.
$$ If we apply  SVD (Singular Value Decomposition) on $A$, we have
$$
A=P\Lambda P^T,
$$
where $P$ is an orthogonal matrix, and $\Lambda=\operatorname{diag}\{\lambda_1,\ldots,\lambda_n\}$ is the diagonal matrix of the (positive) eigenvalues of $A$, $\lambda_i>0$, $i=1,\ldots,n$. I would like to express the above quadratic form, $Q(\mathbf{x})$, in terms of the $2$-norm of $\mathbf{x}$, as well as the matrix $A$ (in some way, for instance in terms of the $2$-norm of $\Lambda$, or something else). What I have thought so far is as follows:
$$
Q(\mathbf{x})
=
\mathbf{x}^TA\mathbf{x}
=
\mathbf{x}^T P \Lambda P^T \mathbf{x}
=
\Big(\mathbf{x}^T P \Lambda^{\frac{1}{2}}\Big)\Big(\Lambda^{\frac{1}{2}} P^T \mathbf{x}\Big) =
\Big(\big(P \Lambda^{\frac{1}{2}}\big)^T\mathbf{x}\Big)^T
\Big(\Lambda^{\frac{1}{2}} P^T \mathbf{x}\Big).
$$ Now, if we set $\mathbf{x}_a=\big(P \Lambda^{\frac{1}{2}}\big)^T\mathbf{x}\in\mathbf{R}^n$, then the quadratic can be rewritten as
$$
Q(\mathbf{x}) = \mathbf{x}_a^T\mathbf{x}_a = \big\lVert \mathbf{x}_a \big\rVert^2_2
=
\Big\lVert \big(P \Lambda^{\frac{1}{2}}\big)^T\mathbf{x} \Big\rVert^2_2.
$$ As far as I know (thanks to @DanielFischer - if I do not misunderstand his words), the following holds true
$$
Q(\mathbf{x}) = \Big\lVert \big(P \Lambda^{\frac{1}{2}}\big)^T\mathbf{x} \Big\rVert^2_2
\leq
\Big\lVert \big(P \Lambda^{\frac{1}{2}}\big)^T \Big\rVert^2_2
\Big\lVert \mathbf{x} \Big\rVert^2_2.
$$ My question is: (a) Are all the above correct? (b) Is there any way of getting rid of the inequality, granted that $A$ is symmetric and positive-definite? Moreover, could we define a function $f\colon\mathbb{R}^n\times\mathbb{S}_{++}^{n}\to\mathbb{R}$, such that $f(\mathbf{x},A)=Q(\mathbf{x})$, where $f$ is expressed in terms of the $2$-norm of $\mathbf{x}$, as well as in terms of $A$ in some way (for instance, in terms of $\Lambda$, etc.)? (c) Any other suggestions? Thanks in advance!","['matrix-decomposition', 'quadratic-forms', 'linear-algebra']"
864085,Trigonometry sum of solutions question,"Problem: For which $a$ will the sum of solutions be equal to $100$, in $\sin(\sqrt{ax-x^2})=0$. The attempt at a solution: For $\sin(x)=0$, $x$ must be equal to $0$, so we get $$\sqrt{ax-x^2}=0\\ax-x^2=0\\x(a-x)=0\\x=0\\a-x=0$$last 2 are the solutions as I understand but I can't seem to finalize the solution, please help. Thank you in advance.","['trigonometry', 'algebra-precalculus']"
864105,E is bounded if and only if every countable subset of it is bounded,"I'm trying to do an exercise from Rudin's ""Functional analysis, 2nd edition"". It is question 6 from the first chapter: ""Prove that a set E in a topological vector space is bounded if and only if every countable subset of E is bounded"" My efforts so far: If $E$ is bounded, then if $U$ is any neighbourhood containing $0$, $E\subset tU$ for all $t$ large enough and positive. $A\subset E$, and so for any $U$ a neighbourhood of $0$, $A\subset tU$ for $t$ large enough. I'm having trouble with the ""only if"" part. I cannot see where the ""countability"" of $A$ comes in: If $A$ is a bounded countable subset of $E$, then $A\subset tU$ for $t$ large enough, and $U$ is as before. Now, somehow I need to argue that $A\subset E \subset tU$. Any hints would be appreciated, thanks!",['functional-analysis']
864116,How to count different card combinations with isomorphism?,"Let's consider a standard deck of cards and say that two sets of cards are isomorphic if there exists permutation of colors that makes one set into another. For example: A♡ K♡ K♧ is isomorphic with A♤ K♤ K♡ , but not than A♢ K♤ K♧ Now we can count that there are 1326 different pair of cards, but when considering the color isomorphisms there are only 169 of them. Is there a generic formula or approach to calculate it for any problem size (number of ranks(AKQ..), colors(♢♡♧♤...), and set size?",['combinatorics']
864119,Abstract algebraic geometry vs complex algebraic geometry,"Sorry in advance if my question is not precise enough. I'm currently trying to study algebraic geometry on my own. I've started by trying to read Harsthorne and Liu's book. And i found it very difficult, especially because every proof seemed ""clever"" and non intuitive. I'd say that i wouldn't have been able to find any of them, especially the ones of real theorems like the one on formal functions, for instance.
I felt a bit discouraged, and i told myself, well algebraic geometry is hard. The i ran into the book of griffith harris, principles of algebraic geometry... and it was simply incredible, the book felt really natural to read, and i felt like i was really doing geometry. So i'ma  bit perplexed because i've heard several times, that schemes make things simpler and more natural and that it is clearly the good way of seeing things. I remember something from Harris book, ""the geoemtry of shemes"", which went like ""The expert do know that schemes often make things simpler"". So i want to know if that's normal that i find scheme theory a lot more obscure than complex geometry, and that i feel that i'm really not able to prove anything in that setting, when i feel i'm a lot more at ease with complex algebraic geometry. And how to convince myself that really schemes are a simplification of classical material, and not an obscure and technical treatment. Thank you!","['algebraic-geometry', 'soft-question']"
864131,Packing circles in circle vs semicircle vs quarter of circle,"Consider $N$ disjoint circles with radius $1$ packed into a larger 
circle $C$. Let $R$ be the smallest possible radius of $C$, allowing 
the best packing density. Now take the $N$ unitary circles and try to pack them in two other ways, 
again searching the maximal packing density. First, let us pack them 
into two disjoint and equal semicircles; then, let us pack them into 
four disjoint and equal quarters of circle. Let $R_S$ be the smallest 
possible radius of the semicircles, and let $R_Q$ be the smallest 
possible radius of the quarters of circle, in both cases allowing the 
maximal packing density. 
Because halving a packed circle or semicircle alters the best packing disposition (hexagonal) along the division lines, we have $R_Q>R_S>R$. I calculated the differences $(R_S-R)$ and $(R_Q-R_S)$ using the best 
packing values available to date for $N\leq400$. The result is shown in 
the following figure: Prove or disprove that these differences converge to definite positive 
values when $N$ tends to $\infty$. Edit: the plot might suggest some convergence towards positive values. I tried to calculate these values by determining the effect of division lines on packing, and then by focusing on the region of the semicircles nearest to the diameter, and on the regions of the quarter of circles nearest to the radia. Then, I calculated the difference between the uncovered areas over these regions, considering the unitary circles first in the best packing hexagonal arrangement, and then in the ""squared"" arrangement (that could probably be expected at the level of diameter and radii). However, I obtained inconsistent results.","['geometry', 'circles', 'packing-problem', 'limits']"
864132,$\epsilon - \delta$ definition of continuity?,"trying to recall the $\epsilon, \delta$ definition of continuity, I came up with the following: A function is continuous at $x$ if $\forall \epsilon > 0 \; \exists \; \delta > 0: |f(x-\delta) - f(x+\delta)| < \epsilon$. This is very likely not equivalent to the Weierstrass' definition of continuity at $c$: $\forall \epsilon > 0 \; \exists \; \delta > 0: |x-c| < \delta \Rightarrow |f(x) - f(c)| < \epsilon $. Could you please point out where the first statement fails to be equivalent to Weierstrass'? Many thanks!",['calculus']
864135,An inequality about a sequence,"Let $(a_n)$ be a sequence such that  $a_0=1 , a_1=2 , a_{n+1}=a_n+\dfrac {a_{n-1}}{1+ a_{n-1}^2} , \forall n \ge1 $ , then is it true that $52 < a_{1371} < 65$ ? $ EDIT:-$  I am posing another question , so I'm not able to accept Oleg567 ' s very correct answer  : Let $(a_n)$ be a sequence such that  $a_0=1 , a_1=2 , a_{n+1}=a_n+\dfrac {a_{n-1}}{1+ (a_n-1)^2} , \forall n \ge1 $ , then is it true that $52 < a_{1371} < 65$ ?","['inequality', 'sequences-and-series']"
864140,Use a proof by cases to show that $\lfloor n/2 \rfloor$ * $\lceil n/2 \rceil$ = $\lfloor \frac{n^2}{4} \rfloor$ for all integers $n$.,"Question Use a proof by cases to show that $\lfloor n/2 \rfloor$ * $\lceil n/2 \rceil$ = $\lfloor \frac{n^2}{4} \rfloor$ for all integers $n$. My Attempt: I can only think of two cases, $n/2 \in \mathbb{Z}$ $n/2 \notin \mathbb{Z}$ First case is straightforward: $\lfloor n/2 \rfloor = \lceil n/2 \rceil = n/2$, $\frac{n}{2}*\frac{n}{2} = \frac{n^2}{4}$ Second case troubled me, $\lceil n/2 \rceil = \lfloor n/2 \rfloor + 1\\
\lceil n/2 \rceil = \lfloor n/2 + 1\rfloor$ $n/2 - 1 \leq \lfloor n/2 \rfloor < n/2\\
n/2 \leq \lfloor n/2 + 1 \rfloor < n/2 + 1$ I multiply both inequalities, $\frac {n^2 - 2n}{4} \leq \lfloor n/2 \rfloor * \lfloor n/2 + 1 \rfloor < \frac{n^2 + 2n}{4}$ I need to prove that $\lfloor n/2 \rfloor * \lfloor n/2 + 1 \rfloor$ should be at least $n^2 /4$ and less than $n^2 /4 + 1$, this ensures that if I floor that, it will be $n^2/4$, but I'm lost. My second attempt , (I didn't think the top have anywhere to go). This time I used some epsilon $\epsilon \in (0, 1)$, $\lfloor n/2 \rfloor = n/2 - \epsilon\\
\lceil n/2 \rceil = n/2 + 1 - \epsilon$ $\lfloor n/2 \rfloor * \lfloor n/2 + 1 \rfloor = (n/2 - \epsilon)*(n/2 + 1 - \epsilon)\\
= n^2/4 + n/2 - n*\epsilon/2 - n*\epsilon/2 - \epsilon + \epsilon ^ 2\\
= n^2/4 + n/2 - 2n\epsilon/2 + 2\epsilon^2/2\\
= n^2/4 + \frac{n-2n\epsilon - 2\epsilon + 2\epsilon^2}{2}$ The problem now is I need to prove that $\frac{n-2n\epsilon - 2\epsilon + 2\epsilon^2}{2}$ is between 0 and 1. I don't really think this one is the solution is either so I gave up.",['discrete-mathematics']
864149,Could it be that Goldbach conjecture is undecidable?,"The result closest to Goldbach conjecture is Chen's theorem [ Sci. Sinica 16 157–176], the proposition ``1+2''. It is natural to ask if it is likely that under our arithmetic axioms the Goldbach conjecture is an undecidable proposition.","['logic', 'incompleteness', 'goldbachs-conjecture', 'number-theory']"
864163,Proof on limit superior and limit inferior of a set,"I understand the result intuitively but how can I prove this? For a given integral $n \ge 1$, let $A_n  = \left\{\frac mn \mid m \in \mathbb Z\right\}$. Show that $\varlimsup_{n\to\infty} A_n = \mathbb Q$, the set of rational numbers and $\varliminf_{n\to\infty} A_n = \mathbb Z$, the set of integers.","['proof-writing', 'elementary-set-theory']"
864168,"Does $K_{15,15}$ decompose into $K_{5,5}-C_{10}$ and $K_{5,5}-(C_6 \cup C_4)$ subgraphs?","Following on from this question : Q : Does $K_{15,15}$ decompose into $K_{5,5}-C_{10}$ and $K_{5,5}-(C_6 \cup C_4)$ subgraphs? or equivalently Q : Does there exist a $15 \times 15$ matrix containing $15$ copies of each symbol in $\{1,2,\ldots,15\}$ such that each row and each column containing a copy of symbol $i$ contains exactly $3$ copies of $i$? The usual checks hold (a) the number edges in $K_{5,5}-C_{10}$ and $K_{5,5}-(C_6 \cup C_4)$ is $5^2-10=15$ which divides $15^2$, the number of edges in $K_{15,15}$, and (b) the degrees of the vertices in $K_{5,5}-C_{10}$ and $K_{5,5}-(C_6 \cup C_4)$ are $3$ which divides $15$, the degrees of the vertices in $K_{15,15}$. The answers to the earlier question do not seem usable here. I managed to fit $10$ in with the computer, but the computer seems woefully inadequate at solving this problem:","['graph-theory', 'discrete-mathematics', 'combinatorics']"
864188,"If $\lim\limits_{x \to \infty} f(x) = 1$, can we have function $f(x)$, such that $\int_0^{\infty}f(x)dx$ converges","I know the Initiative answer, can anyone give a neat answer based on solid reasoning EDIT : $f(x)$ is continuous","['calculus', 'integration', 'definite-integrals', 'summation', 'limits']"
864206,Characteristic function of Cantor set is Riemann integrable,"I want to prove that the characteristic function of the Cantor set is Riemann integrable on $[0,1]$ . Could somebody please tell me if my proof is correct? Let $f$ be the characteristic function of the Cantor set and let $L(f,P)$ denote the lower Riemann sum and $U(f,P)$ the upper Riemann sum with respect to partition $P$ . First note that in any subinterval of $[0,1]$ there are points that are not in $C$ , hence $L(f,P)=0$ for all partitions $P$ , and hence $L(f)=0$ . Let $\varepsilon > 0$ . If $C = \bigcap_n C_n$ then let $n$ be such that the length of $C_n$ is smaller than $\varepsilon$ : $|C_n|<\varepsilon$ . (Here $C_n$ is a union of $2^n$ closed intervals of length ${1 \over 3^n}$ .) Let $P$ be the partition consisting of the endpoints of the intervals in $C_n$ and let $I_k$ denote the intervals in $C_n$ . Then $$ U(f,P) = \sum_k |I_k| < \varepsilon$$ Hence $U(f) = 0$ and therefore $\int_0^1 f = 0$ . Please note that I am not looking for a proof. I am asking if somebody could please check my proof.","['real-analysis', 'solution-verification']"
864212,"Quotient of polynomials, PID but not Euclidean domain?","While trying to look up examples of PIDs that are not Euclidean domains, I found a statement (without reference) on the Euclidean domain page of Wikipedia that $$\mathbb{R}[X,Y]/(X^2+Y^2+1)$$ is such a ring. After a good deal of searching, I have not been able to find any other (online) reference to this ring. Can anyone confirm this result? Is there a reference for it (paper, textbook or website)?","['principal-ideal-domains', 'commutative-algebra', 'reference-request', 'abstract-algebra']"
864216,About matrix derivative,"Suppose $A$ is a matrix with order n*n. we have the following equity but I don't know why. $f(x)=\frac{1}{2}x^TAx-b^Tx$. then
$f'(x)=\frac{1}{2}A^Tx+\frac{1}{2}Ax-b$ Is there any rule like scalar function's derivative? thanks.","['linear-algebra', 'calculus', 'derivatives']"
864219,How many tagged partitions of an interval are there?,"A tagged partition of an interval $[a, b] \ (a, b ∈ ℝ, a < b)$ is a finite sequence $(x_i)_{i=0}^n$ in $ℝ$, where $a=x_0 < x_1 < … < x_n = b$. Consider the set of all tagged partitions of $[a, b]$, $M_{a,b} = \{T: T\text{ is a tagged partition of }[a, b]\}$. Now my question is, what is the cardinality of $M_{a,b}$? If it is smaller than the cardinality of $\mathcal{P}(ℝ)$, what is the cardinality of $∪_{a<b∈ℝ} M_{a,b}$? I have been able to derive that $|ℝ| ≤ |M_{a,b}| ≤ |\mathcal{P}(ℝ)|$, where $\mathcal{P}(ℝ)$ is the power set of $ℝ$: Proof that $|ℝ| ≤ |M_{a,b}|$: Consider the function $f: A = \{(a, x, b): a < x < b\} → (a, b), (a, x, b) \mapsto x$. $f$ is bijective, $A ⊂ M$, and $|(a,b)| = |ℝ|$. Proof that $|M_{a,b}| ≤ |\mathcal{P}(ℝ)|$: Consider the function $f: M → A = \{B ∈ \mathcal{P}(ℝ): B ⊂ [a, b], B\text{ is finite}, a, b ∈ B\}, (x_i)_{i=0}^n \mapsto \{x_0, …, x_n\}$. $f$ is bijective, and $A ⊂ \mathcal{P}(ℝ)$.","['elementary-set-theory', 'real-analysis']"
864227,Is there a finite non-solvable group which is $p$-solvable for every odd $p\in\pi(G)$?,Let $G$ be a finite non-solvable group and let $\pi(G)$ be the set of prime divisors of order of $G$. Can we say that there is $r \in \pi(G)-\{2\}$ such that $G$ is not a $r$-solvable group?,"['finite-groups', 'group-theory', 'abstract-algebra']"
864237,What is a short exact sequence telling me?,"Let's take a short exact sequence of groups
$$1\rightarrow A\rightarrow B\rightarrow C\rightarrow 1$$
I understand what it says: the image of each homomorphism is the kernel of the next one, so the one between $A$ and $B$ is injective and the one between $B$ and $C$ is surjective. I get it. But other than being a sort of curiosity, what is it really telling me?","['exact-sequence', 'group-theory']"
864261,Are there circles in $\mathbb{R}^d$ taking no rational values?,"I recently stepped over a little detail in a thesis I still wonder about. If one looks at $\mathbb{Q}$, then it is dense in $\mathbb{R}$, and we have no problem finding real numbers that don't belong to $\mathbb{Q}$. That's fine so far. No go to the $d$-dimensional case. Sure, we can find points in $\mathbb{R}^d$ that don't belong to $\mathbb{Q}^d$, but is it possible to find a whole disk (rectangle, triangle, (Borel-)measurable set, whatsoever) $A\subset\mathbb{R}^d$ s.t. $\partial A\in\mathbb{R}^d\setminus\mathbb{Q}^d$? Or better, even a dense set $T\subseteq[0,\infty)$ and disks (or similar) $A_t$ with radius $t$ and $t\in T$ having this property? In fact it doesn't even have to be $\mathbb{Q}^d$, one could just take any countable, dense set in $\mathbb{R}^d$ as well. (Sry for wrong tags, I just had no clue to which branches this question belongs to)","['geometry', 'elementary-set-theory']"
864280,Stable Marriage - set of preferences such that every arrangement is stable?,"This is a homework problem from the MIT OCW math for CS class, assignment 4, problem 5. Prove or disprove the following claim: for some n ≥ 3 (n boys and n girls, for a total of 2n people), there exists a set of boys’ and girls’ preferences such that every dating arrangement is stable. As I understand it, this is asking for a set of preferences such that any combination of matchings is stable. Informally, my thought was to show by contradiction this is not possible. I assume the theorem is true, then there must be some combination such that every male is paired with his least favorite partner. In this case, assuming the theory holds, then every female must prefer their partner the most. Otherwise, if any female prefered any other male more, they would form a rogue couple. This then would be true starting with the female set, that is there exists a combination such that each female is paired with her least favorite, so each male must like his partner the most. Given this, and that we are looking at every combination, there must exist a combination of two couples such that a male is with his least favorite and a female is with her least favorite (who are different people because of the idea above). This would create a non-stable matching, so there is a contradiction. I feel this is wrong somehow, and that I am missing something obvious. Would someone point me in the right direction? I am sorry if this is way off base or too informal, I do not have a background in math, and trying to teach myself has been fun but slow going without anyone to consult.","['graph-theory', 'discrete-mathematics']"
864283,Topology Book including specific aspects,I am looking for a basic book about Topology (maybe also a bit of Functional analysis but basically Topology) including the following points (in addition to the basic points): $\bullet$ Seminorms $\bullet$ Locally convex topological vector spaces $\bullet$ weak-$^{*}$ topology,"['book-recommendation', 'general-topology', 'locally-convex-spaces', 'reference-request', 'topological-vector-spaces']"
864286,Generalizing the Monotone Subsequence theorem,"In proving the Bolzaono-Weierstrass theorem, one proves the lemma that every infinite real sequence has a(n infinite) monotone subsequence. In all of the proofs I've seen so far, this is done by constructing the monotone sequence incrementally, either by taking the maximum of a the sequence starting from some point, or (if the maximum does not exist) by taking increasingly large values.
This made me curious about a more genral hypothesis, that cannot be proved using the same method: Hypothesis : Given linearily ordered sets, $I$ and $A$, such that $|I|\ge\aleph_0$, and a family $\{a_\alpha\}_{\alpha\in I}\in A^I$, then there exists a subset $J\subseteq I$, $|J|=|I|$, such that $\{a_\alpha\}_{\alpha\in J}$ is monotone, i.e. for all $\beta,\gamma\in J$, either $a_\beta \le a_\gamma$ whenever $\beta\lt\gamma$, or $a_\beta \ge a_\gamma$ whenever $\beta\lt\gamma$. Any ideas on how can I go about proving, or disproving, this hypothesis?","['sequences-and-series', 'elementary-set-theory', 'analysis']"
864325,What's the purpose of this formula?,Just found this image on the web: Can anyone explain what's the meaning (if any) of this formula? (I did a Google image search but found no answer),"['summation', 'integration']"
864369,Radius of Convergence for $f(z) = \dfrac{1}{1+z^2+z^4}$ at $\dfrac{1}{2}$,"I am practicing some qualifying problems, and I cannot compute the following: Find the radius of convergence $R$ of the Taylor series of $f(z) = \dfrac{1}{1+z^2+z^4}$ centered at $\dfrac{1}{2}$. I'm thinking I am having just a technical issue by not seeing the trick for finding the Taylor series for this function. I tried rewriting $f(z)$ and got to $f(z) = -\dfrac{4}{3} \dfrac{1}{1-\frac{4}{3}\left(\left(z-\frac{1}{2}\right)^2+z+\frac{1}{4}\right)^2}$ although I couldn't find the Taylor series from here.",['complex-analysis']
864370,Hochschild cohomology of skew polynomial rings,"Definition The skew polynomial algebra over $\mathbb{C}$ is defined as $\mathbb{C}\langle x,y\rangle/(xy-yx+x)$ or alternatively as $\mathbb{C}[x,y,\sigma]$, where $\sigma$ is the automorphism on $\mathbb{C}[x]$ sending $x$ to $x+1$. Question Does anyone know a reference where the Hochschild cohomology of $\mathbb{C}[x,y,\sigma]$ is calculated?","['noncommutative-algebra', 'noncommutative-geometry', 'ring-theory', 'algebraic-geometry', 'hochschild-cohomology']"
864381,Union and Intersection of sets,"I was reading Introduction to Topology by George L. Cain and found myself struggling with this definition mentioned in the book. Let $X$ be a set, and suppose $C$ is a collection of subsets of $X$.
Then if $C$ = Empty Set, Union of $C$ is an Empty Set too and Intersection of $C$ is the set $X$. Now my questions are: If $C$ is an Empty Set and also the collection of subsets of $X$ then isn't it true that $X$ is also essentially an empty set. For example, let $X = \{1,2\}$ then according to the definition $C = \{\emptyset, \{1\}, \{2\}, \{1,2\}\}$.
So, in the same manner $C$ can be an Empty Set only when the collection of subsets of $X$ is an Empty Set or $X = \emptyset$. Union of $C$ is the union of all the elements present in $C$. So if $C$ is an Empty Set, then the only set present in the collection of sets $C$ is the value of an Empty Set. 
Here lies my question: We know how to find the Union of $2$ or more sets but with respect to what should I find the Union of $1$ set? Also, at the back of my mind I know its an Empty set because there aren't any other sets present in $C$ but how do I know for sure? Intersection of $C$ is the intersection of all the elements present in $C$. So if $C$ is an empty set, again I present the same question, with respect to what should I take the intersection? Also, generally if $C$ was not an empty set and would be something like $C = \{\emptyset, \{1\}\}$, the intersection would be equal to an Empty Set as the set $\{1\}$ has subsets $\{1\}, \emptyset$.
So how exactly does the Intersection of $C$ when $C$ is an Empty Set return set $X$?",['elementary-set-theory']
864390,$\Gamma \subset \mathbb{R}^{+}$ is uncountable. Can we choose a sequence from $\Gamma$ of which the sum is $\infty$,"If $\Gamma$ is a set of uncountably many different positive real numbers, can we choose a sequence of pairwise different positive numbers from $\Gamma$, say $\{a_n\}$, such that $\sum a_n = \infty$ ? I am considering such problem and I think the answer should be yes . But what's the rigorous way to prove it? Please give me some hints and I will appreciate any help :-)","['elementary-set-theory', 'real-analysis']"
864393,Constant in Sobolev-Poincare inequality on compact manifold $M$; how does it depend on $M$?,"Let $M$ be a smooth compact Riemannian manifold of dimension $n$. Let $p$ and $q$ be related by $\frac 1p = \frac 1q - \frac 1n$. There is a constant $C$ such that for all $u \in W^{1,q}(M)$ 
$$\left(\int_M |u-\overline{u}|^p\right)^{\frac 1p} \leq C\left(\int_M |\nabla u|^q\right)^{\frac 1q}.$$
I'm not interested in the best constant $C$ but want to know how does $C$ depend on $M$? I am hoping for something like $C=C(|M|,n)$ where $|M|$ is the volume of $M$. Can someone refer me to this result? Thanks.","['sobolev-spaces', 'riemannian-geometry', 'functional-analysis', 'differential-geometry']"
864399,is knot type invariant under diffeomorphism?,"Is it possible to have a diffeomorphism of $R^3$ which changes the knot type, for instance the image of a trivial knot is a trefoil knot?","['knot-theory', 'differential-geometry']"
864430,"Solve the System of Equations in Real $x$,$y$ and $z$","Solve for $x$,$y$ and $z$ $\in $ $\mathbb{R}$ if $$\begin{align} x^2+x-1=y \\
                   y^2+y-1=z\\
z^2+z-1=x \end{align}$$ My Try: if  $x=y=z$ then the two triplets $(1,1,1)$ and $(-1,-1,-1)$ are the Solutions. if $x \ne y \ne z$ Then we have $$\begin{align} x(x+1)=y+1 \\
                   y(y+1)=z+1\\
z(z+1)=x+1 \end{align}$$ Multiplying all we get  $$xyz=1 \tag{1}$$ and adding all we get $$x^2+y^2+z^2=3 \tag{2}$$ Now from Original Equations $$\begin{align} x^2=y+1-x\\
                y^2=z+1-y\\
                z^2=x+1-z \end{align}$$ Multiplying all and Using $(1)$ we get $$(y+1-x)(z+1-y)(x+1-z)=1 $$    $\implies$ $$xy+yz+zx-3=(x-y)(y-z)(z-x) \tag{3}$$ I am unable to proceed further..","['linear-algebra', 'systems-of-equations', 'real-numbers']"
864456,How to calculate the length of a cubic hermite spline between two points,"I am using the following equation to create a cubic hermite spline: $$p_n(t) = a_nt^3+b_nt^2+c_nt+d_n$$
$$1\geq t\geq 0$$
$p_n(t)$ is the unit interval interpolation equation for dimension n. $t$ is the parametric variable. This was rearranged from Wikipedia and I simplified the equation as the implementation is unimportant here. I need to calculate the length of the interpolated spline and for that I am using the following equation to calculate the length:
$$
s = \int_0^1 \sqrt[2]{\dot{p}_x(t)^2+\dot{p}_y(t)^2+\dot{p}_z(t)^2} dt
$$ $$\dot{p}_n(t) = 3a_nt^2+2b_nt+c_n$$ $\dot{p}_n(t)$ is the first derivative of the interpolation equation with respect to $t$. After subbing in all the relevant equations I get the following:
$$s = \int_0^1 \sqrt[2]{9(\boldsymbol{A}\cdot\boldsymbol{A})t^4 + 12(\boldsymbol{A}\cdot\boldsymbol{B})t^3 + (6(\boldsymbol{A}\cdot\boldsymbol{C})+4(\boldsymbol{B}\cdot\boldsymbol{B}))t^2 + 4(\boldsymbol{B}\cdot\boldsymbol{C})t + \boldsymbol{C}\cdot\boldsymbol{C}} dt$$
$$\boldsymbol{A} = \begin{pmatrix}a_x\\a_y\\a_z\end{pmatrix}$$
I vectorised it for brevity and it also lets me do a sneaky trick (atleast I think its a sneak trick). I noticed that the polynomial inside the square root looked similar to $\dot{p}_n(t)^2$ and since $\boldsymbol{A}\cdot\boldsymbol{A}=|\boldsymbol{A}|^2$I figured the following is possible: $$s = \int_0^1 \sqrt[2]{(3\boldsymbol{|A|}t^2 + 2\boldsymbol{|B|}t + \boldsymbol{|C|})^2} dt$$ After integrating I get the following solution:
$$s=\boldsymbol{|A|}+\boldsymbol{|B|}+\boldsymbol{|C|}$$ However, on implementing this I find that the values it produces are wrong. In the image below the straight green line in the centre of the image has a length of approximately 6 units and the solution I derived gives a spline length of 15 units. If the spline did have a length of 15 units then it should follow a path similar to a semi-circle. I'm not entirely sure where I went wrong here, my best guess is that missed something when I vectorised the equation but I can't seem to figure out what I did wrong. I would appreciate any help. Note: The spline is described by the path of squares which go from one end of a line to another.","['interpolation', 'cubics', 'spline', 'integration']"
864460,"If $f$ has pole of order $m$, then $\text{res}\left(f,z_0\right)=\lim_{z\to z_0}\frac{1}{(m-1)!}\left\{(z-z_0)^mf(z)\right\}^{(m-1)}$","Statement : Let $$f(z):=\sum_{k=-\infty}^\infty a_kz^k$$ have a pole of order $m$ at $z_0$. Then $$\text{res}\left(f,z_0\right)=\lim_{z\to z_0}\frac{1}{(m-1)!}\left\{(z-z_0)^mf(z)\right\}^{(m-1)}$$ Since $f$ has a pole of order $m$ $$(*)\;\;\;f(z)=\sum_{k=0}^\infty a_kz_k+\sum_{k=1}^m a_{-k}z^{-k}$$ By the Residue theorem we've got $$\text{res}\left(f,z_0\right)\text{ind}_\gamma\text{ }z_0=\frac{1}{2\pi i}\int_\gamma f(z)\;dz$$ where $\gamma$ is a nullhomologous path such that $z_0\notin\gamma^*$. Now comes the point where I'm a little bit confused: Wouldn't Cauchy's Integral theorem yield $\int_\gamma f(z)\;dz=0$? [No, it would not - as stated in the comment of Squirtle and the answer of Daniel Fischer ]. However, how to proceed? I'm unsure whether $(*)$ does help here or not. Another fact that follows from the pole of order $m$ at $z_0$ is the existence of a holomorphic function $g$ with $$f(z)=\frac{1}{(z-z_0)^m}g(z)$$ But I still got problems to obtain the statement. Notes: $\text{ind}_\gamma\text{ }z_0$ denotes the Winding number $\gamma^*$ denotes the trace","['complex-integration', 'contour-integration', 'complex-analysis', 'analysis']"
864473,The variational formulation of entropy,"For $f:\mathbb Z_2^n \to [0, \infty)$, the entropy of $f$ is defined as
$$
{\rm Ent}(f) = \mathbb E[f(X) \log f(X)] - \mathbb E f(X) \log(\mathbb E f(X)),
$$
where $X$ is a random element of $\mathbb Z_2^n$. The variational formulation of entropy claims that
$$
{\rm Ent}(f) = \sup\{\mathbb E[f(X) \times g(X)]~:~ \mathbb E e^{g(X)} \le 1, g:\mathbb Z_2^n \to \mathbb R \}.
$$
How can we prove it? I know the hint is to define
$$
L(g, \lambda) = \mathbb E[f(X)g(X)] - \lambda (\mathbb E[g(X)] - 1).
$$
and then we just need to show that $\sup_g \inf_{\lambda \ge 0} L(g, \lambda) = {\rm Ent}(f)$. But I don't know what technique can be applied to find the extremal value of $L(g, \lambda)$.","['probability-theory', 'harmonic-analysis']"
864485,How to find know if function is onto?,How do you figue out whether this function is onto? $\mathbb{Z}_3\rightarrow \mathbb{Z}_6:f(x)=2x$ Onto is of course is for all the element b in the codomain there exist an element a in the domain such that $f(a)=b$ Here the co domain is mod 6 So let $k\in\mathbb{Z}_6$ But I am not sure how to see if it is onto.,['functions']
864508,Complete ONS and pure point spectrum,"In all that follows all operators are taken to be densely defined on a Hilbert space $H$.
Some textbooks state that an operator $A$ on $H$ has pure point spectrum if $H$ admits a complete ONS (Hilbert space basis) of eigenvectors of $A$. Naively the term ""pure point spectrum"" suggests a relation to the point spectrum $\sigma_p (A)$ of $A$. I searched in lots of books (e.g. Brezis, analyse fonctionelle; Reed/Simon, etc) and could not find anything. At last I found something along the lines that if $A$ is self-adjoint and has pure point spectrum then $\sigma_p (A)$ is dense in $\sigma(A)$. Could someone point me to a reference where this and related connections (is there a converse perhaps?) are proven? Remark: the mathematical physics tags is totally appropriate, this is obviously of importance in mathematical physics.","['operator-theory', 'hilbert-spaces', 'functional-analysis', 'mathematical-physics']"
864519,Density in $\mathbb{R}_{ +}$ of a subgroup of $\mathbb{Q}_{> 0}$?,"Let $\phi : \mathbb{Q}_{>0} \to \mathbb{Z}$ be the group morphism defined by $\phi(p) = p$ for $p$ a prime number. It follows that $\phi(1)=0$, $\phi(a.b) = \phi(a)+\phi(b)$, $\phi(a^{-1}) = -a$ and in general: $$\phi(\prod_i p_i^{n_i}) = \sum_i n_i p_i$$ with $p_i$ a prime number and $n_i \in \mathbb{Z}$. Let $\mathcal{K} = ker (\phi) $, a subgroup of $\mathbb{Q}_{>0}$. Then, $\mathcal{K}=  \{  r \in \mathbb{Q}_{>0}  \vert  r=\prod_i p_i^{n_i}   \text{ and }   \sum_i n_i p_i = 0 \}$ Question: Is $\mathcal{K}$ a dense subset of $\mathbb{R}_{ +}$ ?","['prime-numbers', 'group-theory', 'number-theory']"
864524,The Price is Right optimal play,"The following situation happened on the Price is Right and I was curious about the optimal response.
The rules are:
A contestant rolls a wheel with 5 cent increments from 5 - 100 (20 numbers total). A contestant can choose to spin the wheel once and accept the number the wheel landed on (stay) or spin again and have this new number added to the previous number. If the contestant has a number that is over 100 cents they automatically lose. The object of the game is to roll the highest number out of a set of contestants. GirlA rolled once and rolled 60 cents. GirlA knows GirlB will play afterwards. Should GirlA roll again? At what number is the expected value neutral / what range of numbers should GirlA stay on? If there is more than one player behind, what range of numbers is best to stay on?","['game-theory', 'probability', 'expectation']"
864529,Question on Inductive Proof of Implicit Function Theorem,"I am struggling with an inductive proof of the implicit function theorem, concretely with the final part of construction of a function, up to this final point everything is perfectly clear to me. First the following is known to be true: Theorem 1: Let $F : G \subseteq \mathbb R^{n+1} \to \mathbb R$, $G \ne \emptyset$, $F \in C^1(G)$, $G$ open. For $x^0 \in \mathbb R^n, y^0 \in \mathbb R$ let
$$
 F(x^0, y^0) = 0 \quad \mbox{ and } \quad
 F_y(x^0, y^0) \ne 0.
$$
Then there exists some neighborhood $U(x^0) \subseteq \mathbb R^n$ and a function $f : U(x^0) \to \mathbb R$ such that 
$$
 y = f(x_1, \ldots, x_n), \qquad
 y_0 = f(x_1^0, \ldots, x_n^0)
$$
and
$$
 F(x, f(x)) = 0
$$
and $f \in C^1(U(x^0))$. Now the Implicit Function Theorem reads as Theorem 2 (Implicit Function Theorem): Let $F : G \subseteq \mathbb R^{n+m} \to \mathbb R^m$, $G\ne \emptyset$,
$F \in C^1(G)$, $G$ open. Also $(x^0, y^0) \in G$ with $x^0 \in \mathbb R^n, y^0 \in \mathbb R^m, F(x^0,y^0) = 0$ and
$$
 \det\left( \frac{\partial F}{\partial y} \right)_{y=y_0} \ne 0.
$$
Then there exists neighborhoods $U(x^0) \subseteq \mathbb R^n, V(y^0) \subseteq \mathbb R^m$ and a function $g : U(x^0) \to V(x^0)$ such that $F(x, g(x)) = 0$ on $x \in U(x^0)$. Proof: The proof proceeds by induction on $m$, if $m = 1$ it is Theorem 1, so we assume $m > 1$ and suppose (by induction hypothesis) the statement holds for $m-1$. Let $F : G \subseteq \mathbb R^{n+m} \to \mathbb R^n$ be given, then because of
$$
 \det\left( \frac{\partial F}{\partial y} \right)_{y=y_0} \ne 0
 \quad \mbox{ or } \quad
\det \begin{pmatrix}
  \frac{\partial F_1}{\partial y_1} & \frac{\partial F_1}{\partial y_2} & \cdots & \frac{\partial F_1}{\partial y_m} \\
  \vdots \\
  \frac{\partial F_m}{\partial y_1} & \frac{\partial F_m}{\partial y_2} & \cdots & \frac{\partial F_m}{\partial y_m} 
 \end{pmatrix} \ne 0.
$$
So we can suppose that every row contains an entry $\ne 0$, suppose w.l.o.g. that 
$\frac{\partial F_m}{\partial y_m} \ne 0$. By Theorem 1 we can solve (locally) for $y_m$, that means there is some neighborhood $U$ of $(x, y_1, \ldots, y_{m-1})$ and a function
$$
 y_m = \varphi(x, y_1, \ldots, y_{m-1})
$$
and $\varphi$ is continously differentiable with ($x \in \mathbb R^n$)
$$
 F_m(x, y_1, \ldots, y_{m-1}, \varphi(x, y_1, \ldots, y_{m-1})) = 0
$$
for all $(x,y_1,\ldots,y_{m-1}) \in U$. Now set 
$$
 \Phi_i(x, y_1, \ldots, y_{m-1}) := F_i(x, y_1, \ldots, y_{m-1}, \varphi(x, y_1, \ldots, y_{m-1}))
$$
for $i = 1, \ldots, m-1$. Then $\Phi : U \subseteq \mathbb R^{n+m-1} \to \mathbb R^{m-1}$
and $\Phi$ fulfills als prerequisites to apply the induction hypothesis (here the proof shows this, but I omit it because it is quite long and does not apply to my question).
Then there exists neighborhoods $W \subseteq \mathbb R^n, V \subseteq \mathbb R^{m-1}$ and a function $g : W \to V$ with
$$
 \Phi(x, g(x)) = 0
$$
for all $x \in W$. Now set $h(x) = (g(x), \varphi(x,g(x))$, then we have
$$
 F(x, h(x)) = 0
$$
and the proof is finished. $\square$ My question is on the last part. Namely the construction of the function $h(x)$, 1) Because $h(x) = (g(x), \varphi(x, g(x))$ it must be the case that $(x, g(x) \in U$,
because $\varphi : U \to \mathbb R$, but I do not see that this must be the case? 2) The same issue if I want to show that $F(x, h(x)) = 0$, if $i \ne m$ it is
$$
 F_i(x, h(x)) = \Phi_i(x, g(x))
$$
by definition, but for
$$
 F_m(x, h(x)) = F_m(x, g(x), \varphi(x,g(x)) = F_m(x, g_1(x), \ldots, g_{m-1}(x), \varphi(x, g_1(x), \ldots, g_{m-1}(x))
$$
and to conclude that this equals $0$ it also must be that $(x, g(x)) \in U$, but I do not see that this must be the case?","['multivariable-calculus', 'differential-geometry', 'real-analysis', 'analysis', 'implicit-function-theorem']"
864538,Why did Michael Spivak pick $\frac{\epsilon}{2(|m|+1)}$? Why didn't he start with arbitrary $\epsilon$?,"On page 104 in Calculus (2008 4th edition), Michael Spivak proves that limits of two functions equals the limit of the product of the functions, as follows. If $\epsilon>0$ there are $\delta_1,\delta_2>0$ such that, for all $x$ , $$\text{if }0 <|x-a|<\delta_1,\text{ then }|f(x)-l|<\min\left(1,\frac{\epsilon}{2(|m|+1)}\right),$$ $$\text{ and if }0 <|x-a|<\delta_2,\text{ then }|g(x)-m|<\frac{\epsilon}{2(|l|+1)}.$$ This is supposedly due to the fact that $\lim_{x\to a}f(x)=l$ and $\lim_{x\to a}g(x)=m$ . There are two things I don't understand about this argument. First, shouldn't you start from $\epsilon$ when making such a proof, not $\frac{\epsilon}{2(|m|+1)}$ or something like that? Second, does the first row really hold? It merely tries (if I've understood it correctly) that $$\lim_{x\to a}f(x)=l.$$ In the definition of a limit it says that for any $\epsilon$ we can find a corresponding $\delta$ . But it seems like you can't in this case. What if $\frac{\epsilon}{2(|m|+1)}>1$ ? Then we can't really know for sure if the first statement holds, since for all we know, $|f(x)-l|$ could lie between $1$ and $\frac{\epsilon}{2(|m|+1)}>1$ . How am I understanding his proof wrong?","['real-analysis', 'limits']"
864604,Checking connectivity of adjacency matrix,"What do you think is the most efficient algorithm for checking whether a graph represented by an adjacency matrix is connected? In my case I'm also given the weights of each edge. There is another question very similar to mine: How to test if a graph is fully connected and finding isolated graphs from an adjacency matrix That answer seems to be good, except I don't really understand it. How does repeatedly squaring the matrix give information about its connectivity? There is another an answer that claims eigenvectors also give information about the connectivity of the graph, could anyone explain that as well? I'm asking this because I don't have the background to understand the answers given, I'm just solving a problem that has to do with these topics. Searching around on google didn't give me an answer either, so hopefully someone can clear it up.","['matrices', 'linear-algebra', 'graph-theory', 'algorithms']"
864609,What is the closed form for $\sum_{n=1}^\infty \frac1n - \frac1{n+1/p}$?,"A while ago, I started to look at expressions of the following form:
$$
S_p:=\sum_{n=1}^\infty \frac1n - \frac1{n+1/p},
$$
 where $p$ is prime, because otherwise things get too complicated for me at the moment. 
What I found so far is the following:
$$
S_p= p -\log(2p) - \frac12 \pi \cot\left(\frac\pi p\right) + T_p,
$$
where $T_p$ contains $\frac{p-1}2$ terms $t_{p,k}$ of the form: 
\begin{cases}
\pm 2 \sin\left(\frac{k\pi}{2p}\right) \log\left(\sin\left(\frac{k\pi}{2p}\right)\right) \\
\pm 2 \cos\left(\frac{k\pi}{2p}\right) \log\left(\sin\left(\frac{k\pi}{2p}\right)\right)\\
\pm 2 \sin\left(\frac{k\pi}{2p}\right) \log\left(\cos\left(\frac{k\pi}{2p}\right)\right) 
\\
\pm 2 \cos\left(\frac{k\pi}{2p}\right) \log\left(\cos\left(\frac{k\pi}{2p}\right)\right) 
\end{cases} An example can be found here . How does the closed form for $\sum_{n=1}^\infty \frac1n - \frac1{a+n}$ look like? (EDIT: where $a=1/p$)","['closed-form', 'sequences-and-series']"
864634,"Show $\iint xye^{-xy}\,dx\,dy$ is convergent or divergent","Determine convergence/divergence of $$\iint xye^{-xy}\,dx\,dy$$ for $x,y \geqslant 0$ i.e. in the first quadrant. I have managed to show that $xye^{-xy} \to 0$ in the first quadrant but other than that not gotten very much far unfortunately. One thought I had was to use polar coordinates and for some radius $r_0$ approximate $xye^{-xy} \thicksim e^{-xy} $. I would then want to investigate $$ \iint e^{-xy} \,dx\,dy$$
in the first quadrant from radius $r_0$ to infinity (the angle lies between zero and $\pi/2$). However that integral was no more easier than the previous one. Thoughts?","['multivariable-calculus', 'improper-integrals']"
864640,Constructing a vector space of dimension $\beth_\omega$,"I'm trying to solve Exercise I.13.34 of Kunen's Set Theory , which goes as follows (paraphrased): Let $F$ be a field with $|F| < \beth_\omega$, and $W_0$ a vector space over $F$ with $\aleph_0 \le \dim W_0 < \beth_\omega$.  Recursively let $W_{n+1} = W_n^{**}$ so that $W_n$ is naturally identified with a subspace of $W_{n+1}$.  Then let $W_\omega = \bigcup_n W_n$.  Show that $|W_\omega| = \dim W_{\omega} = \beth_\omega$. Some useful facts: If $W$ is a vector space over $F$ with basis $B$, there is an obvious bijection between $W^*$ and ${}^{B}F$ (i.e. the set of functions from $F$ to $B$, denoted this way to avoid ambiguity with cardinal exponentiation).  Hence $|W^*| = |F|^{\dim W}$. Asaf Karagila showed in this answer that $|W| = \max(\dim W, |F|)$. By the ""dual basis"" construction we have $\dim W^* \ge \dim W$.  (There's an assertion on Wikipedia that the inequality is strict whenever $\dim W$ is infinite, but I don't immediately see how to prove that.) One inequality is pretty easy.  Using Fact 1, we get $|W^*| = |F|^{\dim W} \le |F|^{|W|}$.  Now thanks to the simple fact that ${}^{\beth_n} \beth_m \subset \mathcal{P}(\mathcal{P}(\beth_m \times \beth_n))$ we have $\beth_m^{\beth_n} \le \beth_{\max(m,n)+2}$.  So by induction it follows that $|W_n| < \beth_\omega$ for each $n$, and hence (using Kunen's Theorem 1.12.14) we get  $|W_\omega| \le \beth_\omega$. For the other direction, if $\dim W \ge |F|$ then Fact 3 gives us $\dim W^* \ge |F|$ and hence by Facts 1 and 2 $$\dim W^* = \max(\dim W^*, |F|) = |W^*| = |F|^{\dim W} \ge 2^{\dim W}.$$ So if $\dim W_0 \ge |F|$ then by induction we get $\dim W_n \ge \beth_{2n}$ and therefore $\dim W_\omega \ge \beth_\omega$.  Since $|W_\omega| \ge \dim W_\omega$ we must have equality throughout. But I am stuck on the case $\aleph_0 \le \dim W_0 < |F|$.  Intuitively it still seems like $\dim W^*$ should be ""much larger"" than $\dim W$.  We shouldn't really need to go through the cardinalities of the spaces themselves, but I can't see what to do.  Any hints?","['set-theory', 'linear-algebra', 'cardinals']"
864657,can I get the correct average of a set of numbers from the averages of several subsets?,"Let's say I have this set of numbers: 565 212 812 895 443 73 468 900 299 993 252 740 291 112
(average 503.9285714286) I'd like to split them apart into 3 sets of unequal size: 565 212 812
(529.6666666667) 

443 73 468 900 299 895
(513) 


993 252 740 291 112
(477.6) Then take the average of each set and (somehow) get the average of the entire set from the 3 averages. Assume that the number of subsets is variable and the number of values in each set is also variable.",['statistics']
864674,Sheafification: Show that $\tilde{\mathscr{F}_x}=\mathscr{F}_x$.,"My today's question is about a proof of this book . More precisely we are talking about the proof of Prop. 2.24 on page 52. The book says that we have $\tilde{\mathscr{F}_x}=\mathscr{F}_x$ for all $x\in X$. I tried to verify that but unfolding the definition of elements of $\tilde{\mathscr{F}_x}$ is very technical. So I got stuck. Furthermore, it can't be meant literally because elements of $\tilde{\mathscr{F}_x}$ and $\mathscr{F}_x$ aren't of the same type so to speak. So what is meant by that equality? Here my approach to unfold the definition of elements of $\tilde{\mathscr{F}_x}$: An element of $\tilde{\mathscr{F}_x}$ is the equivalence class of a pair $(U,(s_y)_{y\in U})$ with $x\in U$. Each pair $(U',(s'_y)_{y\in U'})$ is equivalent to $(U,(s_y)_{y\in U})$ iff there is a $V\subseteq U\cap U'$ with $x\in V$ and $(s_y)_{y\in U}|_V=(s'_y)_{y\in U'}|_V$. By definition of the restriction that means for all $y\in V$ we have $s_y=s'_y$. Now the equality $s_y=s'_y$ could be itself unfold in a similar way since $s_y$ is again an equivalence class of pairs. Is it correct what I did so far and does it help me to show $\tilde{\mathscr{F}_x}=\mathscr{F}_x$?","['sheaf-theory', 'algebraic-geometry']"
864696,2D Integral of Bessel Function and Gaussians,"I've run into the following integral, and I'm not sure how to evaluate it. $$F(k)=\int d^{2}\mathbf{x}\left(e^{-\frac{\left(x-2a\right)^{2}}{4w^{2}}}+e^{-\frac{\left(x+2a\right)^{2}}{4w^{2}}}+2e^{-\frac{x^{2}}{4w^{2}}}\right)\left(e^{-\frac{\left(y-2b\right)^{2}}{4w^{2}}}+e^{-\frac{\left(y+2b\right)^{2}}{4w^{2}}}+2e^{-\frac{y^{2}}{4w^{2}}}\right)J_{0}(k\mid\mathbf{x}\mid)$$ Where I've written x to have components $x$ and $y$, and $a$, $b$ and $w$ are all positive constants.(Edit: the integral is over all space) The reason I believe this can be solved is because I have the following expression which should hopefully be the result of evaluating this integral. $$F(k)=16\pi e^{-w^{2}k^{2}}(1+J_{0}(2bk)+J_{0}(2ak)+J_{0}(2k\sqrt{a^{2}+b^{2}}))
 $$ I'm trying the verify the topmost method as a way to obtain this result, which is why I already have a tentative answer. I can see, for example, how to get the $1$ term in the tentative solution, so I have some hope this can be done. If I were to evaluate it in polar coordinates, a useful integral would be: $$\intop_{0}^{2\pi}d\theta e^{\alpha\cos(\theta)+\beta\sin(\theta)}$$ I know $\intop_{0}^{2\pi}d\theta e^{\alpha\cos(\theta)}=2\pi I_0(\alpha)$, which is both reassuring and worrying, as it makes me wonder if the top integral is missing  $i$. Does anyone have any idea of how to go about evaluating either of these integrals?","['definite-integrals', 'bessel-functions', 'special-functions', 'integration']"
864701,"If $B \subseteq A$, why is $\{ B \}$ not in the power set of $A$?","Define $B = \{1\}$ and $A=\{1, 2\}$.  Then the power set of $A$ is $\mathcal P(A)= \{ \emptyset, \{1\}, \{2\}, A \}$.  Let $C= \{ B \} = \{ \{1 \}\}$.  Why is $C \notin \mathcal P(A)$? I dont see why $C$ is not an element of $\mathcal P(A)$, because with the brackets around B you get the set of the set containing B. In the Power Set of A i see that we have a set containing the set with 1. Is it wrong because the one in the power set isnt the set containing the set with 1. I dont know how else to read the power set though. Its a set with the element set containing one.",['elementary-set-theory']
864733,Finding a specific sequence of digits in pi,"Looking at the pifs project on GitHub and this question on SO has made me curious as to how feasible it is to find a specific sequence of digits within Pi. Essentially, on average, how many digits of pi would you have to have to go through to find a specific sequence of a given length? Assuming the digits of pi to be normal and otherwise random, I would assume that the difficulty of finding a specific sequence increases exponentially(?) as the length of the sequence increases. For instance, just trying to find a short sequence like '12345' is fairly easy, occurring at position 49702. However, just one more digit, say, '123456', brings you up to position 2458885. Of course, it differs by specific sequence; '314159' is much easier to find in terms of the work you have to do (especially computationally, where runtimes and memory usage make a difference). There's probably still a way to find an average digit of pi on which any given sequence would start, but it's beyond the scope of my mathematical ability. Another interesting question is whether there's a specific formula for average position in pi for a sequence of a given length. For instance, if you took a specific 256 kb sequence, it would take an absurd number of digits of pi to find it, but how would that absurd number compare the the far more absurd number of digits you would need to find a specific 512 kb sequence in pi? I suppose one could also take information theory into account, because since pi is effectively random, at first glance it seems like it might take longer to identify a sequence that has a repeating pattern. Thinking more about it, I don't think that it would be any more difficult to find than any other specific sequence, but I'm not certain. As you can probably tell by the horribly imprecise language above and my complete lack of reputation on this site, I'm not that familiar with these types of math, so if the tags below are inappropriate, please help me out by editing them.","['pi', 'sequences-and-series', 'probability', 'entropy']"
864769,My data is not normally distributed: what can I do to estimate a tail probability?,"Continuing on from my earlier question , I'm attempting to analyse the data qualitatively. In the following plot, I make $10000$ samples where I count ""the number of clashes"".  I plot $n$ vs. the number of times $n$ clashes occurred. (The number of clashes is a measure of ""how wrong"" an attempted attack was [on the secret sharing scheme I'm looking at]). (Drawn using tikzDevice for R , then edited manually.) In R, it fails the shapiro.test , so it's not normally distributed: > shapiro.test(z[1:5000])

    Shapiro-Wilk normality test

data:  z[1:5000]
W = 0.9947, p-value = 1.597e-12 So: Q: How can I estimate the probability $p$ of $0$ clashes from the above distribution? It should be very small, around $10^{-14}$: I have a theoretical lower bound of $1.046 \times 10^{-14}$, and I expect it to be close to the actual value. I have made $10^{11}$ samples, and all had at least one clash. I attempted to fit an exponential curve to the left hand side (drawn above):  the curve is $$3.29 \times 10^{-12} \exp(0.56n)$$ which, when $n=0$ gives the estimate $\hat{p}=3.29 \times 10^{-16}$.  But I know that this estimate is off by around a factor of $100$, which makes me think this is not the best approach.  (Or maybe I should fit some other curve, or use more samples.  Or maybe this level of confidence is to be expected.) Addendum : I'm trying to show that $\mathrm{Pr}[0 \text{ clashes}]$ is small (say less than $10^{-8}$ or $10^{-9}$).  So the estimate doesn't need to be precise, but I need to have confidence in the estimate. The theoretical maximum number of clashes is $220$ (this number can be achieved). ""Do you know the statistical power of the Shapiro-Wilk test for such a large sample size?""  In short, no, I don't.  But we can compare the results to random data from a normal distribution: > shapiro.test(rnorm(5000, mean = mean(z), sd = sd(z)))

    Shapiro-Wilk normality test

data:  rnorm(5000, mean = mean(z), sd = sd(z))
W = 0.9996, p-value = 0.4053 While the results fluctuate between runs, they don't seem comparable to my data. I also tried with fewer samples included and it didn't seem to ""help"". > shapiro.test(z[1:100])

    Shapiro-Wilk normality test

data:  z[1:100]
W = 0.9757, p-value = 0.06116 compared to > shapiro.test(rnorm(100, mean = mean(z), sd = sd(z)))

    Shapiro-Wilk normality test

data:  rnorm(100, mean = mean(z), sd = sd(z))
W = 0.9845, p-value = 0.2932 (Here, it fluctuates quite a lot.) I'm capable of making around $10^{10}$ samples, if it would help.","['distribution-tails', 'statistics', 'estimation', 'experimental-mathematics', 'probability']"
864793,Munkres Topology Exercise 2.q,"I have another doubt regarding a question from Munkres' Topology (another one on cartesian products, sorry!). I have to determine if the following statement is true: $$(A\times B)-(C\times D)=(A-C)\times (B-D)$$ What I did was: If the ordered pair $(a,b)\in LHS$, then we must have that $$(a,b)\in (A\times B)\implies a\in A, b\in B$$
$$(a,b)\not\in (C\times D)\implies a\not\in C, b\not\in D$$ Now, this means that:
$$a\in(A-C)$$
$$b\in(B-D)$$ So that $(a,b)\in RHS$. Therefore $LHS\subseteq RHS$. Now, going the other way... If $(a,b)\in RHS$, then:
$$a\in (A-C)\implies a\in A, a\not\in C$$
$$b\in (B-D)\implies b\in B, b\not\in D$$ Which means that:
$$(a,b)\in (A\times B)$$
$$(a,b)\not\in (C\times D)$$ So $(a,b)\in LHS$, and $LHS\supseteq RHS\implies LHS=RHS$. According to the website that I'm checking my answers against, though, the correct solution should give $LHS\supset RHS$. This implies I did something wrong in the first part, where I show that $LHS\subseteq RHS$. What did I do wrong there? I'm really having trouble getting this, I think. Thanks, and sorry for the inconvenience. Usually I'm able to grasp math more easily :(",['elementary-set-theory']
864816,Functions $f$ such that $f(x)+f(-x)=f(x)f(-x)$,"I was looking for examples of real valued functions $f$ such that $f(x)+f(-x)=f(x)f(-x)$. Preferably, I'd like them to be continuous, differentiable, etc. Of course, there are the constant functions $f(x)=0$ and $f(x)=2$. I also showed that $1+b^x$, where $b>0$, is another solution. Are there any other nice ones?","['calculus', 'functional-equations']"
864820,extending the convergence of measures,"Let $F$ the real vector space of all applications $\phi: X \times Y \rightarrow \mathbb{R}$ where  $(X,\mathcal{B}_1, \mu)$, $(Y,\mathcal{B}_2 )$ measurable spaces with $X$ and $Y$ are compact metric space provided with the borel sigma algebra $\mathcal{B}_1$, $\mathcal{B}_2$ such that $\phi$ is measurable. for all $x \in X$, $\phi_x=\phi(x,-): Y \rightarrow \mathbb{R}$ is continuous i.e. $\phi_x \in C(Y)$ $x\in X \mapsto \Vert \phi_x\Vert_{C(Y)} \in L^1(\mu)$ identifying $\phi \backsim \psi \Leftrightarrow \phi_x =\psi_x$ for $\mu -a.e $  and endow $ F $ of a norm $$\Vert \phi\Vert_F=\int_X \Vert \phi_x\Vert_{C(Y)} d\mu$$
then $ (F, \Vert \phi\Vert_F) $ is a separable Banach space where the dense set is the set of continuous functions $\varphi: X \times Y \rightarrow \mathbb{R}$. With this definition now present my question: Let $P(X\times Y)$ is the space of probability. Know $\nu_n \rightarrow \nu$ in $P(X\times Y)$ sss $\int \varphi d\nu_n\rightarrow \int \varphi d\nu$ for all continuous functions  $\varphi: X \times Y \rightarrow \mathbb{R}$. Then $\int \phi d\nu_n\rightarrow \int \phi d\nu$ for all functions  $\phi \in F$ ? Appreciate any help on how to test this assertion.","['measure-theory', 'convergence-divergence', 'analysis']"
864830,Why is a random variable called so despite being a function?,"According to my knowledge, its a function $P(X)$ which includes all the possible outcomes a random event.","['terminology', 'probability']"
864851,All Sets have bijection with cartesian products of Subsets?,"I was doodling around with some math today, trying to find ""representations"" for sets as cartesian products of their proper subsets. For example: $\mathbb{N}\leftrightarrow 2\mathbb{N}\times\{0,1\}$ $\mathbb{Z}\leftrightarrow 2\mathbb{Z}\times\{0,1\}$ $\mathbb{R}\leftrightarrow \mathbb{Z}\times[0,1)$ I'm thinking most ways to do this have to do with abstract algebra, using quotient structures times the respective substructure. But I was wondering given an arbitrary non-empty set $A$ and ignoring trivial cases like $|A|=1$, does there always exist a bijection with some $B\times C$ where $B$ and $C$ are proper non-empty subsets of $A$?",['elementary-set-theory']
864863,Wheel of Fortune Problem,"The Summation formula is $$\sum_{i=1}^ni =\frac{n(n+1)}2$$ How is it that we know the integers $1,2,...36$ appear exactly $3$ times. And why do we multiply the sum by $3$ in the last part of the proof? Source of Question: Discrete and Combinatorial Mathematics: An Applied Introduction by Ralph P. Grimaldi, 5th Edition.","['discrete-mathematics', 'proof-writing', 'combinatorics']"
864886,Is it true that $\mathbb E[{\frac{X}{Y}]}={\frac{\mathbb E[X]}{\mathbb E[Y]}}$?,"If $X$ and $Y$ are both random variables, does it hold $$\mathbb E\left[\frac{X}{Y}\right]={\frac{\mathbb E[X]}{\mathbb E[Y]}}$$ ??","['statistics', 'sampling', 'probability', 'statistical-inference']"
864890,Closed subspace of a reflexive Banach space is reflexive,"I'm studying Conway's functional Analysis by myself. In page 132 of his book, for showing every Closed subspace M of a reflexive Banach space X is reflexive, he says $\sigma(X,X^*)_{|_{M}}=\sigma(M,M^*)$. But I can not understand how it is. Please regard me. 
Thanks in advance","['functional-analysis', 'banach-spaces']"
864894,All permutation matrices that convert one Hadamard matrix into another Hadamard matrix.,"Given a Hadamard matrix $H$, I know that applying row and column permutations, along with multiplying a row or a column with a -1 results in another Hadamard matrix $H^{'}$ equivalent to the first. 
Given $H$ and $H^{'}$, ( assume we know that they're equivalent) , is it possible to find all pairs of permutation matrices $(P,Q)$ that preserve Hadamard equivalence, such that,
\begin{equation}
H^{'}=PHQ
\end{equation}
? For example, take 2 Hadamard matrices of order 4, $H,H^{'}$. We know that there is only one equivalence class of Hadamard matrices of order 4, so the 2 matrices are equivalent. $H =
\left(
\begin{matrix}
1 & 1 & - & 1 \\
- & 1 & - & -\\
1 & 1 & 1 & -\\
- & 1 & 1 & 1 \\
\end{matrix}
\right)
$, 
$H^{'} =
\left(
\begin{matrix}
1 & 1 & 1 & - \\
- & 1 & 1 & 1\\
- & - & 1 & -\\
1 & - & 1 & 1 \\
\end{matrix}
\right)
$ Now, $
\left(
\begin{matrix}
1 & 1 & 1 & - \\
- & 1 & 1 & 1\\
- & - & 1 & -\\
1 & - & 1 & 1 \\
\end{matrix}
\right)
=$
$
\left(
\begin{matrix}
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0\\
0 & 0 & 1 & 0\\
0 & 0 & 0 & 1 \\
\end{matrix}
\right)
*$
$
\left(
\begin{matrix}
1 & 1 & - & 1 \\
- & 1 & - & -\\
1 & 1 & 1 & -\\
- & 1 & 1 & 1 \\
\end{matrix}
\right)
*$
$
\left(
\begin{matrix}
0 & 0 & 0 & - \\
0 & 0 & 1 & 0\\
0 & - & 0 & 0\\
1 & 0 & 0 & 0 \\
\end{matrix}
\right)
$ So here, $P =
\left(
\begin{matrix}
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0\\
0 & 0 & 1 & 0\\
0 & 0 & 0 & 1 \\
\end{matrix}
\right)
$
,
$Q =
\left(
\begin{matrix}
0 & 0 & 0 & - \\
0 & 0 & 1 & 0\\
0 & - & 0 & 0\\
1 & 0 & 0 & 0 \\
\end{matrix}
\right)
$ This is one example of a pair $(P,Q)$. How do you list all such pairs? (I'll make the question more specific and add that I'm looking for permutation matrices for 4x4 Hadamard matrices only)","['matrices', 'permutations', 'hadamard-product']"
864903,A measurable function equal to a countable sum of characteristic functions?,"A theorem in measure theory says that if $\mu$ is a measure on $X$ and $f : X
\rightarrow [ 0, \infty]$ is $\mu$-measurable, then there exists a sequence $(
A_k)_{k \in \mathbb{N}}$ of $\mu$-measurable sets in $X$ such that $$f =
\sum_{k = 1}^{\infty} \frac{1}{k} 1_{A_k}$$ where $1_{A_k} ( x) = 1$ if $x \in
A_k$ and 0 otherwise. I am trying to understand the intuition of this result. If $X =\mathbb{R}$
and $f$ is continuous, then $f$ takes an uncountable number of values in its
range. How could that be given a countable sum and values?","['measure-theory', 'real-analysis']"
864920,Pairs of $2\times 2$ matrices generating free groups.,"The matrices $\begin{pmatrix}1&2\\0&1\end{pmatrix}$ and $\begin{pmatrix}1&0\\2&1\end{pmatrix}$ are well-known to (freely) generate a free group.  Some years ago, I read a paper that, if memory serves, sort of summarised what was known about generalisations to pairs of the form $\begin{pmatrix}1&\lambda\\0&1\end{pmatrix}$ and $\begin{pmatrix}1&0\\\lambda&1\end{pmatrix}$.  (Or perhaps even more general such pairs.) I recall that there were results there describing regions in $\mathbb{C}$ from which $\lambda$ chould be chosen so that such a pair freely generated a free group, and there were plots of these regions (at least one, anyway).  Unfortunately, I cannot recall the title or author(s) of the paper, and Googling didn't turn up anything that looked familiar. Does anyone recall such a paper and be able to provide a reference. (I did find a 1967 paper by Lyndon and Ullman, but that wasn't it, and I think the one I'm after was later, and probably described further progress on the question, probably with its own new results.)","['reference-request', 'free-groups', 'group-theory', 'linear-groups']"
864928,How do you find this product?,Is there a way to find the exact value of the product $$P=\displaystyle\prod_{n=1}^{1007} \sin {\left(\dfrac{n\pi}{2015}\right)}$$,['trigonometry']
864999,Completing the following equation by the suitable method,"i got this linear equation two variable problems for my school.
I understand the basics of the normal linear equation but this seems different instead having a pure number after the ""="" they got a ration, here is the problem. $$X:2Y = 5:14$$
$$(X+4) : (3Y-21) = 2:3$$ What i've tried to do is just guess the X and Y and to solve it (took a long time and still dont find it) so as example if the X is 5 and the Y is 7, it fit the first equation but wont fit in the 2nd question. The "":"" sign is for ration, not ""divided by"" Please answer how you solve and not just give the answer, because as you see im trying to learn not trying to just solve my homework.",['algebra-precalculus']
865022,Properties about order of a general group,"For a group, $G$, is it true that $o(Z(G))\cdot o([G,G]) \leq o(G)$ where $Z(G)$ denotes the centre of $G$ and $[G,G]$ denotes the commutator subgroup of $G$?",['group-theory']
865028,Is it differentiable?,"Let us consider the function $$
f(x)=
\begin{cases}
x^2\sin {\dfrac{\pi}{x}} & x \neq 0\\
0                        & x=0
\end{cases}
$$ We want to check its differentiability at $x=0$. By the definition of $f'(x)$, the derivative of $f$ at $x=0$ would be $$f'(0)=\displaystyle\lim_{h \rightarrow 0}\dfrac{h^2\sin {\dfrac{\pi}{h}}}{h}$$ which would be $$f'(0)=\displaystyle\lim_{h \rightarrow 0} h\sin \frac{\pi}{h}$$ Using the squeeze theorem, we can prove that this limit is equal to $0$. So according to the above procedure, the function is differentiable at $x=0$. But, when we look at the graph of this function, it doesn't seem differentiable (below) In addition to this, when we find $f'(x)$ by using the $u.v$ rule and the chain rule, $f'(x)$ does not exist. So, is it differentiable or not?","['calculus', 'derivatives']"
865034,Perelman's F-functional and its analysis,"While going through the Kleiner and Lott notes ""Notes on Perelman's papers"" , I encountered an argument that seems wrong to me, or (more likely) I do not understand something. It is about the $F$-funtional. It is defined as follows:
$$F(g,f)=\int_{M}(R+\left | \bigtriangledown f \right |^2)e^{-f}dV,$$
where $g$ is Riemannian metric, $f$ is a smooth function over manifold $M$. It is stated, that first variation of the functional can be expressed as follows:
$$\delta F(v_{ij},h)=\int_{M}e^{-f}\left [ -v_{ij}(R_{ij}+\bigtriangledown_{i}\bigtriangledown _{j}f)+(\frac{v}{2}-h)(2\Delta f-\left | \bigtriangledown f \right |^2+R) \right ]dV,$$ where $v_{ij}=\delta g_{ij}$ is a symmetric covariant 2-tensor on $M$ (more specifically, it is an element of tangent space of infinite dimensional manifold of all smooth Riemannian metrics on $M$), $h=\delta f$ is a smooth function over $M$ (f is a smooth function as well), $v=g^{ij}v_{ij}$. Part of the proof is as follows:
$$\delta R=-\Delta v+\triangledown_{i}\triangledown_{j}v_{ij}-R_{ij}v_{ij}$$
$$\delta (e^{-f}dV)=(\frac{v}{2}-h)e^{-f}dV$$
$$\delta \left | \triangledown f \right |^2=-v^{ij}\triangledown_{i}f\triangledown_{j}f+2<\triangledown f,\triangledown h>$$
I understand these three lines very clearly - it is not very difficult.
Putting all together I get
$$\delta F=\int_{M}\left [-\Delta v +\triangledown_{i}\triangledown_{j}v_{ij}-R_{ij}v_{ij} +(R+\left | \triangledown f \right |^2)(\frac{v}{2}-h) +2<\triangledown f,\triangledown h>-v^{ij}\triangledown_{i}f\triangledown_{j}f \right ]e^{-f}dV$$. And that is were my results do not match Kleiners and Lotts result. The difference is that in their derivation they have $v_{ij}\triangledown_{i}f\triangledown_{j}f$ instead of $v^{ij}\triangledown_{i}f\triangledown_{j}f$. But this part is just direct plug-in of those three variation formulas above. And those are exactly the same in my derivation and in authors. So, what I am missing? What I'm not seeing?","['ricci-flow', 'differential-geometry']"
865042,Partial Differential Equation with a flux term,"Recall how we derived all our equations: Take an interval $[a,b]$ and consider $$\dfrac{\mathrm d}{\mathrm dt}\int_a^b(\text{quantity) d}x=\big[\text{Flux}\big]_a-\big[{\rm Flux}\big]_b.$$ For our example $$\dfrac{\partial u}{\partial t}+u\dfrac{\partial u}{\partial x}=0,$$
  we can write it as $$\dfrac{\partial u}{\partial t}+\dfrac{\partial}{\partial x}\left(\tfrac12u^2\right)=0.$$
  $$\text{i.e.}\qquad\dfrac{\partial u}{\partial t}+\dfrac{\partial \phi}{\partial x}=0\qquad\text{where }\quad\phi=\tfrac12u^2.$$ I don't understand why $\phi=\frac{1}{2}u^2$ is the flux in this case?","['fluid-dynamics', 'multivariable-calculus', 'partial-differential-equations']"
865047,Finding the limit without using L'Hôpital's rule or a Taylor/Maclaurin series.,"Can this limit be found without using L'Hôpital's rule or Taylor/Maclaurin series?--
$$L=\displaystyle\lim_{x \rightarrow 0} \dfrac{e^x-x-1}{x^2}$$ I came up to the right answer..just that the method is not foolproof. -- Let $L$ be the limit. So, $$L=\lim_{x \rightarrow 0}\dfrac{e^x-x-1}{x^2}$$ Now, let $x=2y$. So, $$L=\lim_{x \rightarrow 0} \dfrac{e^{2y}-2y-1}{4y^2}$$So, the limit can be rewritten as $$L=\lim_{y \rightarrow 0} \dfrac{e^{2y}-2e^y+1+2e^y-2y-2}{4y^2}$$ which is $$L=\dfrac{1}{4}\lim_{y \rightarrow 0} \left(\left(\dfrac{e^y-1}{y}\right)^2+2\dfrac{e^y-y-1}{y^2}\right)$$ Now comes what i was saying. What i did was i separated the limit across the two terms. We can do that only if the two limits exist individually and finitely. The first, i am sure, exists.But notice the second term is twice the limit we desire to find. So, this method is only applicable when the limit exists.If we do substitute the second term with 2L, we have $$L=\dfrac{1}{4} (1+2L)=L$$ Solving for $L$ we get $\boxed{L=\dfrac{1}{2}}$. But as I said this method is not foolproof. Is there any?",['limits']
865056,Why locally compact hausdorff space,"I may be missing something very trivial,but cannot figure it out.
To prove the fact that the space $C_0(X)$ is a Banach space under the usual sup norm when $X$ is locally compact and Hausdorff, where do we use the properties of $X$? Thanks for any help.",['functional-analysis']
865063,Minimal number of edges removed to make a graph triangle free,"I'm interested in finding an upper bound on the expected value of the minimal number of edges one needs to remove from a random graph $G_{n,p}$ (where each edge appears with probability $p$) in order to make it triangle free.
Particularly, I would really be happy if it was of size less than $\Theta(pn^2)$. 
Has anyone came across something like this?","['graph-theory', 'probability', 'random-graphs']"
865078,Length minimizing curves are geodesic segments,"I have a metric space $(X,d)$, a geodesic arc is defined to be a continuous function $\gamma : [a,b] \rightarrow X$, $a < b$, which is (globally) distance preserving and geodesic segments are defined to be images of geodesic arcs. Given any curve (continuity is assumed) $\gamma: [a,b] \rightarrow X$ and a partition $P$
$$a = t_0 < t_1 < \cdots < t_m = b$$
of $[a,b]$ define
$$\ell(\gamma,P) = \sum_{i=1}^m d(\gamma(t_{i-1}),\gamma(t_i))$$
and we define the length of $\gamma$, denoted by $|\gamma|$ and which may be infinite, to be the supremum of all these sums for partitions $P$. Because $a < b$ constitutes a partition of $[a,b]$, $|\gamma| \ge d(\gamma(a),\gamma(b))$. Finally what I want to prove is the following: Let $\gamma : [a,b] \rightarrow X$ be a curve from $x$ to $y$ in $X$ with $x \neq y$. Then $|\gamma| = d(x,y)$ if and only if $\gamma$ maps $[a,b]$ onto a geodesic segment joining $x$ to $y$ and $d(x,\gamma(t))$ is an increasing function of $t$. I don't have either direction fully, what I have, my thoughts in general and some notes are: For the forward direction, that $|\gamma| = d(x,y)$ is the same as saying that equality holds in the triangle inequality for any partition of $[a,b]$; I can show that the same holds for any restriction of $\gamma$ and then using this I can show that $d(x,\gamma(t))$ is increasing. I thought maybe I could consider the reparametrisation of $\gamma$ achieved by affinely mapping $[a,b]$ to $[0,d(x,y)]$ hoping that this may give me a geodesic arc but I have gotten nowhere with this. For the opposite direction I've spent much less time thinking about it and have nothing at the moment. A useful fact might be that if $[x,y]$ and $[y,z]$ are geodesic segments joining $x$ to $y$ and $y$ to $z$ respectively, $[x,y] \cup [y,z]$ is a geodesic segment joining $x$ to $z$ if and only if $$d(x,y)+d(y,z)=d(x,z).$$ This is from John G. Ratcliffe's Foundations of Hyperbolic Manifolds, Section 1.5. Thank you.","['geometry', 'metric-spaces', 'geodesic']"
865081,Greatest value of f,If $f'(x)=6-x$ then which of the following has the greatest value? $f(2.01)-f(2)$ $f(3.01)-f(3)$ $f(4.01)-f(4)$ $f(5.01)-f(5)$ $f(6.01)-f(6)$ I know the answer is $f(2.01)-f(2)$ but how to prove?,"['calculus', 'algebra-precalculus', 'functions']"
865092,Conjugate subgroups of $GL_n(K)$,"Let $ K \subset L$ two fields,  $G$ and $G'$ subgroups of $\mathrm{GL}_n(K)$. 
  Assume that $G$ and $G'$ are conjugate in $\mathrm{GL}_n(L)$. Are $G$ and  $G'$ conjugate in  $\mathrm{GL}_n(K)$? I have a solution for this one using a non trivial paper. I will add the source later because I would like to know if someone have a simpler proof in that case.",['group-theory']
865104,Linear w.r.t. any measure,"Let $X$ be a Banach space endowed with a Borel $\sigma$-algebra. How do we call a real-valued Borel function $f$ that satisfies for any Borel probability measure $\mu$ the following formula
$$
  \int_X f(x)\mu(dx) = f\left(\int_Xx \mu(dx)\right).
$$
If we focus only on discrete measures $\mu$ then $f$ is just any linear function, however I wonder whether there is a special term for $f$ that satisfies such linearity condition for all measures.","['functional-analysis', 'measure-theory', 'probability-theory', 'linear-algebra', 'terminology']"
865130,Proving that $\mathbb R^3$ cannot be made into a real division algebra (and that extending complex multiplication would not work),"I am trying to solve the following exercise: Prove that complex multiplication does not extend to a multiplication
  on $\mathbb R^3$ so as to make $\mathbb R^3$ into a real division
  algebra. I am aware of Frobenius' theorem that there are only three finite dimensional real associative division algebras. But the exercise would be pointless if the theorem was assumed. Let $x,y \in \mathbb R^3$. Since $x y$ has to extend the complex multiplication: $$xy = (x_1y_1-x_2y_2, x_1y_2 + x_2 y_1, ?)$$ I have no idea how I can proceed from here. Could someone tell me how to do this? It should be easy as the other exercises I did so far were also easy.","['quaternions', 'division-algebras', 'lie-groups', 'abstract-algebra']"
865142,Rankine Hugoniot Jump Condition Derivation,I follow the majority of this derivation I just do not understand where the two terms highlighted in green come from.,"['fluid-dynamics', 'multivariable-calculus', 'partial-differential-equations']"
865149,Solve The Triangle,"I am having a tough time trying to solve this problem. I have utilized the 30, 60, 90 triangle measures for the length of sides. However, I am stuck since the side that would be √3 has 100 as its length. How do I solve then? This is what I have done so far:","['trigonometry', 'algebra-precalculus']"
865178,Area of the field that the cow can graze.,"How do we find the area that the cow can graze? The question goes as follows-- There is a circular barn house surrounded by a huge grazing field. A cow is tied to the rope ($AB$) at the end $A$ as shown. The length of the rope is half the circumference of the barn. Find the area that the cow can graze. 
The left side of the area is obvious but i cannot get a hang of what is happening on the right side..all i can say is that the rope starts to wrap around the barn when the cow goes to the right. The length of the rope is $16\pi$ units.","['geometry', 'calculus', 'area']"
865199,Choose 100 numbers from 1~200 (one less than 16) - prove one is divisible by another!,"Prove that if 100 numbers are chosen from the first 200 natural
  numbers and include a number less than 16, then one of them is
  divisible by another. How to prove this? many thanks....",['pigeonhole-principle']
865216,Constructing a Banach space of cardinality $\beth_{\omega+1}$,"This is related to yesterday's question Constructing a vector space of dimension $\beth_\omega$ ; it's the next exercise (I.13.35 (a)) in Kunen's Set Theory . Let $B_0 = \ell^1$ and let $B_{n+1} = B_n^{**}$ be the continuous second dual of $B_n$, so that we can consider $B_n$ as a subset of $B_{n+1}$ in the usual way.  Let $B$ be the completion of $\bigcup_n B_n$.  Show that $|B| = \beth_{\omega+1}$. I have managed to solve part (b) of the exercise, which says that any Banach space $X$ with $|X| \ge \beth_\omega$ actually has $|X| \ge \beth_{\omega+1}$.  So it will be enough to show $|B| \ge \beth_\omega$ (though given the ordering of the parts of the exercise, this may not be what Kunen had in mind). Presumably we should try to show that $|B_{n+1}| \ge 2^{|B_n|}$ or something similar.  But when working with continuous duals, I don't see how to do that.  Additionally, each step of the induction is somehow going to have to use the fact that we started with $B_0 = \ell^1$, since if $B_0$ had been a reflexive space, this would never work.  We also have to rule out the possibility that one of the later $B_n$ turns out to be reflexive. Any suggestions are welcome.","['set-theory', 'cardinals', 'functional-analysis', 'banach-spaces']"
865231,Requirements for integration by parts/ Divergence theorem,"In order to use the integration by parts formula(or more generally the divergence theorem) for functions of several variables $$\int_{\Omega} \nabla u\cdot v d \Omega = \int_{\partial \Omega}(u(v \cdot \nu))d \Omega - \int_{\Omega}u\nabla \cdot v d\Omega$$ is it required that $\Omega$ is compact or at least just bounded subset of $\mathbb{R}^{n}$? Is it required that $\partial \Omega$ is at least Lipschitz continuous? If not, are there any restrictions on $\Omega$ and $\partial \Omega$? This question was inspired by the wiki entry 'integration by parts' and 'divergence theorem'. Thanks for any assistance.","['continuity', 'calculus', 'integration', 'proof-verification']"
865237,An injection from $\mathbb{N}$ to $\mathbb{N}^n$.,"I'm currently attempting to prove $\mathbb{N}^n \sim \mathbb{N}$ via Cantor-Schroeder-Berstein (because I found no other way). In my work so far I've managed to find an injective function $f$ from $\mathbb{N}^n$ to $\mathbb{N}$ where $(a_1, \cdots, a_n) \mapsto 2^{a_1}3^{a_3}\cdots\rho_n^{a_n}$ where $\rho_n$ is the n-th prime number. I believe this function $f$ to be injective thanks to the fundamental theorem of arithmetic . But I can't seem to find an injective function from $\mathbb{N}$ to $\mathbb{N}^n$. Resuming, I have three questions: Are my workings on $f$ correct?, that is, is $f$ really an injection? Do you have any hints on finding an injective function $g$ from $\mathbb{N}$ to $\mathbb{N}^n$? Is there another, easier way of proving $\mathbb{N}^n \sim \mathbb{N}$.","['cardinals', 'elementary-set-theory']"
865251,"If $x,y \in (0,\frac{\pi}{2})$ then expression $\sin x +\cos y +\tan^2y+\cot^2x+5>\ldots?$","Problem : If $x,y \in (0,\frac{\pi}{2})$ then expression $\sin x +\cos y +\tan^2y+\cot^2x+5$ is always greater than : (a)  $\ 7 $ (b)  $\ 8 $ (c)  $\ 9 $ (d)  $\ $none of these Solution : We can write the given expression $\sin x +\cos y +\tan^2y+\cot^2x+5$ as $\sin x +\cot^2x +\cos x +\tan^2y +5$ $\Rightarrow \sin x +\cot^2x +\cos y +\tan^2y +5  = \sin x + \csc^2x -1 +\cos x +\sec^2y-1+5$ $\Rightarrow \sin x + \csc^2x  +\cos x +\sec^2y+3$ Please guide me how to proceed further. Thanks.","['inequality', 'trigonometry', 'algebra-precalculus']"
865287,"Gaussian integral with offset, and other cases","Consider the Gaussian Integral $$ \int_{-\infty}^{\infty} e^{-x^2} \ dx = \sqrt{\pi}$$ Numerically, it seems that for any arbitrary imaginary offset, ki,
$$\int_{ki-\infty}^{ki+\infty} e^{-x^2} \ dx = \int_{-\infty}^{\infty} e^{-x^2} \ dx = \sqrt{\pi}$$ Why is this so edit and how would you prove it ?  $\exp(-(x+ki)^2)=\exp(k^2) \times \exp(-x^2 - 2kix)$ gets large very quickly, yet the overall integral does not change, no matter what the value of k is. I have another related question.  It appears that for f, an arbitrary polynomial with an even number of terms, that this might still hold, if f(x) gets arbitrarily large positive for real x as the absolute value of x gets arbitrarily large. $$\int_{ki-\infty}^{ki+\infty} e^{-f(x)} \ dx = \int_{\infty}^{\infty} e^{-f(x)} \ dx$$","['integration', 'complex-analysis']"
865293,Showing $\ln(\sin(x))$ is in $L_1$,"Prove $\ln[\sin(x)] \in L_1 [0,1].$ Since the problem does not require actually solving for the value, my strategy is to bound the integral somehow. I thought I was out of this one free since for $\epsilon > 0$ small enough, $$\lim_{\epsilon \to 0}\int_\epsilon^1 e^{\left|\ln(\sin(x))\right|}dx=\cos(\epsilon)-\cos(1) \to 1-\cos(1)<\infty$$ and so by Jensen's Inequality, $$e^{\int_0^1 \left| \ln(\sin(x))\right|\,dx}\le \int_0^1e^{\left|\ln(\sin(x))\right|}\,dx\le1-\cos(1)<\infty$$ so that $\int_0^1 \left|\ln(\sin(x))\right|\,dx<\infty$. The problem, of course, is that the argument begs the question, since Jensen's assumes the function in question is integrable to begin with, and that's what I'm trying to show. Any way to save my proof, or do I have to use a different method? I attempted integration by parts to no avail, so I am assuming there is some ""trick"" calculation I do not know that I should use here.",['real-analysis']
865296,In a PID every nonzero prime ideal is maximal,"In a principal ideal domain, prove that every non trivial prime ideal is a maximal ideal Attempt: Let $R$ be the principal ideal domain. A principal ideal domain $R$ is an integral domain in which every ideal $A$ is of the form $\langle a \rangle = \{ar~~ | ~~r \in R\}$ Let $ \langle a \rangle $ be a prime ideal $\implies R/A $ is an integral domain. A finite integral domain is a field . Hence, if we prove that $R/A$ is finite, then $R/A$ is a field $\implies A$ is a maximal ideal. Now, $\langle a \rangle = \{ar~~ | ~~r \in R\}$ Since, R is an integral domain, there are no zero divisors and cancellation is allowed $\implies ar_1 = ar_2 \implies r_1=r_2 \implies ar_i$ maps to a different member of $R$ for each different $r_i \implies \langle a \rangle$ represents the elements of $R$ in some random order. $\implies \langle a \rangle = R$ and hence, $R/A \approx {0}$ is finite and hence $A$ is maximal. Is my attempt correct?","['ring-theory', 'maximal-and-prime-ideals', 'abstract-algebra', 'principal-ideal-domains', 'ideals']"
865306,Finding if a function is onto?,"Is the following function onto? It is a piece-wise function. Let the function $f:\mathbb{R}\rightarrow \mathbb{R}$ be $f(x)= \begin{cases}
2-x &,   x\le 1 \\
\frac{1}{x} &, x>1
\end{cases}$ If we say $g(x)=2-x$ then it is one to one because make let $b\in \mathbb{R}$ then let $a=2-b$
$$f(a)=f(2-b)=2-(2-b)=b \qquad .$$ Thus it onto. However $\frac{1}{x}$ let $b\in \mathbb{R}$ then it is not one to one b/c the codomain is all real but the range does not include zero. Thus the function is not onto?",['functions']
865310,How to calculate $\int_{\partial B_2(0)}\frac{2z^2+7z+11}{z^3+4z^2-z-4}\;dz$?,"I want to calculate $$\displaystyle\int_{\partial B_2(0)}\underbrace{\frac{2z^2+7z+11}{z^3+4z^2-z-4}}_{=:f(z)}\;dz\tag{0}$$ Partial fraction decomposition yields $$f(z)=\underbrace{\frac{1}{z+4}}_{=:f_1(z)}-\underbrace{\frac{1}{z+1}}_{=:f_2(z)}+\underbrace{\frac{2}{z-1}}_{=:f_3(z)}\tag{1}$$ From this representation of $f$, it's easy to see that $-4$ and $\pm 1$ are poles of $f$. That means, that we can't take benefit from Cauchy's integral theorem , since $f$ is unbounded in a neighborhood of one of these poles. However, since $f$ is holomorphic on $\mathbb{C}\setminus\left\{-4,\pm 1\right\}$ we can apply the residue theorem which states here $$\int_{\partial B_2(0)}f(z)\;dz=2\pi i\sum_{z_0\in\left\{-4,\pm 1\right\}}\text{res}(f,z_0)\;\text{ind}_{\partial B_2(0)}\text{ }z_0$$ The winding number of $-4$ is obvious equal to $0$ while that ones of $\pm 1$ are equal to $1$. So, what would be smart to do now? Either we consider $f$ as a whole or as the sum of $f_1$, $f_2$ and $f_3$: In the first case, we would need to calculate the integrals $$\int_{\partial B_{\delta_\pm}(\pm 1)}f(z)\;dz$$ with $B_{\delta_\pm}(\pm 1)\subset B_2(0)$ In the second case, we would need to determine the Laurent series expansion of $f_1$, $f_2$ and $f_3$ at $\pm 1$. We can take advantage of the fact, that $f_1$, $f_2$ and $f_3$ in $(1)$ are in their Laurent series form at $-4$, $-1$ and $1$, respectively. What would be the easier way? Is there some rule of thumb in general? It seems like in this case, both options are too complicated and it would be easier to calculate $(0)$ from the definition without the residue theorem. Or is there something what prevents me from doing this? Notes: $B_r(z_0):=\left\{z\in\mathbb{C}:|z-z_0|<r\right\}$ $A_{r,R}(z_0):=\left\{z\in\mathbb{C}:r<|z-z_0|<R\right\}$ $\text{ind}_{\gamma}\text{ }z_0$ is the winding number of $z_0$ wrt $\gamma$","['complex-integration', 'integration', 'complex-analysis', 'analysis']"
865318,Example I.4.9.1 in Hartshorne (blowing-up),"Let $Y$ be the irreducible curve of $\mathbb{A}^2$ given by $y^2 = x^2(x+1)$. Let $t,u$ be homogeneous coordinates of $\mathbb{P}^1$. Then the total inverse image of $Y$ under the blowing-up $\phi: X \rightarrow \mathbb{A}^n$ of $\mathbb{A}^n$ at the origin $O=(0,0)$ is a subset of $\mathbb{A}^2 \times \mathbb{P}^1$ and given by the equations $y^2 = x^2(x+1), x u = y t$. Note that by definition the blowing-up of $Y$ at $O$ is the closure of $\phi^{-1}(Y-O)$ and is denoted by $\tilde{Y}$. Hartshorne, first considers the open set $t \neq 0$, sets $t=1$, treats $u$ as an affine parameter and arrives at the exceptional curve and the equations $y=ux, u^2=x+1$, and he states that the latter give precisely $\tilde{Y}$. Question 1: Why do the equations $y=ux, u^2=x+1$ define $\tilde{Y}$? My effort: Since $Y$ is irreducible, the set $Y-O$ is not closed and so $\phi^{-1}(Y-O)$ will not be closed. Now $\tilde{Y}$ is inside the total inverse image of $Y$, i.e. $\phi^{-1}(Y)$, and so any point in $\tilde{Y} - \phi^{-1}(Y-O)$ must be a point of $\phi^{-1}(O)$. Finally, note that $V(y-ux,u^2-x-1) = \phi^{-1}(Y-O) \cup \left\{(0,0,1),(0,0,-1)\right\}$. How can i complete the argument now? Question 2: Accepting that $\tilde{Y}=\phi^{-1}(Y-O) \cup \left\{(0,0,1,1),(0,0,-1,1)\right\}$, Hartshorne states that the points of $\tilde{Y}$ that intersect $\phi^{-1}(O)$, i.e. points $(0,0,1),(0,0,-1)$, (assuming that $t=1$), give the slopes of the branches of $Y$ through the origin $O$. How can we see that? What is a general proof of this statement? Question 3: By considering now the open set $u \neq 0$, we can set $u=1$ and the equations of $\phi^{-1}(Y)$ become $x = t y, y^2 = x^2(x+1)$ which give $y = 0$ and $1 = t^2(ty+1)$. What does the information given my these equations signify and why is Harsthorne now analyzing them?",['algebraic-geometry']
865371,Proving 7n+5 is never a cubic number?,"This is from a question that starts with: An arithmetic progression of integers an is one in which $a_n=a_0+nd$, where $a_0$ and $d$ are integers and n takes successive values $0, 1, 2, \cdots$ Prove that if one term in the progression is the cube of an integer there will be an infinite number of such terms. I have done this part (with help) but I am now stuck on proving that $7n+5$ can never be a cubic number (i.e. $x^3$ where $x$ is an integer) and $n$ is a positive integer. My first plan was proof by induction, trying this with both $x$ (from $x^3=7n+5$) and then $n$. Nether of these worked as I got formula that seemed impossible to solve. I have also tried manipulating $x^3=7n_1+5$ and $y^3=7n_2+5$ since if $x$ is an integer then there must also be a $y$ which this statement is also true. Any hints on where to start would be great thanks!",['sequences-and-series']
865384,Deducing an optimal gambling strategy (using martingales).,"Apologies in advance for the length, I tried being precise. Suppose a game where in each turn you can gamble a certain amount of money on the result of a fair coin toss. If the coin comes out tails you lose what you gambled and if it
comes out heads you gain double what you gambled, this goes on for $n$ turns. To formalize this let $X_{1},X_{2},...$ be i.i.d r.vs such that $\mathbb{P}\left(X_{i}=2\right)=\mathbb{P}\left(X_{i}=-1\right)=\frac{1}{2}$ and let $\mathcal{F}_{k}=\sigma\left(X_{1},...,X_{k}\right)$ be the natural filtration. A gambling strategy is a sequence of non-negative r.vs $C_{1},C_{2},...$ which are previsible relative to $\mathcal{F}$ (that is $C_{k}$ is $\mathcal{F}_{k-1}$-measurable). Your initial wealth is $Y_{0}=1$ and for each $1\leq k \leq n$ your accumulated wealth is $$Y_{k}=1+\sum_{j=1}^{k}C_{j}X_{j}$$
A gambling strategy is said to be: Legal if $C_{k}\leq Y_{k-1}$ for all $k$. Conservative if $C_{k}\leq 0.99Y_{k-1}$ for all $k$ Now for the actual question: Show that the legal strategy that maximizes $\mathbb{E}\left[\log Y_{n}\right]$ is always gambling a constant proportion $A$ of the current wealth and using this strategy there is a constant $B$ such that $\mathbb{E}\left[\log Y_{n}\right]=Bn$. Denote $M_{k}=\log\left(Y_{k}\right)-Bk$ ($B$ is an arbitrary constant), show that there is a $K<\infty$ such that under any conservative strategy $\left|M_{i}-M_{i-1}\right|<K$ almost surely. Attempted solution: For the first question I worked in a sort of recursive fashion. Suppose we are at time $n-1$ with $Y_{n-1}=x$ and we need to choose the ratio A. Define: $$V_{1}\left(x\right):=\mathbb{E}_{A}\left[\ln\left(Y_{n}\right)|Y_{n-1}=x\right]$$
By direct calculation we get: $$V_{1}\left(x,A\right)=\frac{1}{2}\mathbb{E}\left[\ln\left(\left(1+2A\right)x\right)\right]+\frac{1}{2}\mathbb{E}\left[\ln\left(\left(1-A\right)x\right)\right]
=\frac{1}{2}\ln\left(\left(1+2A\right)x\right)+\frac{1}{2}\ln\left(\left(1-A\right)x\right)=\frac{1}{2}\left(\ln\left(1+2A\right)+\ln\left(1-A\right)\right)+\ln\left(x\right)
 $$
Derivating twice gives: $$\frac{\partial}{\partial A}V_{1}\left(x,A\right)=\frac{4A-1}{2\left(A-1\right)\left(2A+1\right)}\qquad\frac{\partial^{2}}{\partial A^{2}}V_{1}\left(x,A\right)=\frac{-8A^{2}+4A-5}{2\left(A-1\right)^{2}\left(2A+1\right)^{2}}
 $$ 
Which shows that $A=\frac{1}{4} $ is unique maximum of $V_{1}$ for which: $$V_{1}\left(x,\frac{1}{4}\right)=\frac{1}{2}\left(\ln\left(1\frac{1}{2}\right)+\ln\left(\frac{3}{4}\right)\right)+\ln\left(x\right)=\frac{1}{2}\ln\left(\frac{9}{8}\right)+\ln\left(x\right)$$
Now by similar logic if we are at time $n-2$ and we got $Y_{n-2}=x$
  to invest: $$V_{2}\left(x,A\right):=\mathbb{E}_{A}\left[\ln\left(Y_{n}\right)|Y_{n-2}=x\right]=\frac{1}{2}\mathbb{E}_{A^{'}}\left[\ln\left(Y_{n}\right)|Y_{n-1}=\left(1+2A\right)x\right]+\frac{1}{2}\mathbb{E}_{A^{'}}\left[\ln\left(Y_{n}\right)|Y_{n-1}=\left(1-A\right)x\right]
=\frac{1}{2}V_{1}\left(\left(1+2A\right)x,A^{'}\right)+\frac{1}{2}V_{1}\left(\left(1-A\right)x,A^{'}\right)\overbrace{\leq}^{1}\frac{1}{2}\left(\frac{1}{2}\ln\left(\frac{9}{8}\right)+\ln\left(\left(1+2A\right)x\right)\right)+\frac{1}{2}\left(\frac{1}{2}\ln\left(\frac{9}{8}\right)+\ln\left(\left(1-A\right)x\right)\right)
=\frac{1}{2}\ln\left(\left(1+2A\right)x\right)+\frac{1}{2}\ln\left(\left(1-2A\right)x\right)+\frac{1}{2}\ln\left(\frac{9}{8}\right)=\underbrace{\frac{1}{2}\ln\left(1+2A\right)+\frac{1}{2}\ln\left(1-A\right)+\ln\left(x\right)+\frac{1}{2}\ln\left(\frac{9}{8}\right)}_{*}
 $$ Where the marked inequality is a result of $A^{'}=\frac{1}{4}$ being optimal for time $n-1$. Maximizing the new equaiton * is exactly the same as maximizing the equation we had at time $n-1$ and it is maximized again for $A=\frac{1}{4}$ for which we get $$V_{2}\left(x,\frac{1}{4}\right)=\frac{1}{2}\ln\left(\frac{9}{8}\right)+\ln\left(x\right)+\frac{1}{2}\ln\left(\frac{9}{8}\right)=2\cdot\left(\frac{1}{2}\ln\left(\frac{9}{8}\right)\right)+\ln\left(x\right)$$
Continuing this inductively we obtain: $$\mathbb{E}\left[\ln\left(Y_{n}\right)\right]=n\left(\frac{1}{2}\ln\left(\frac{9}{8}\right)\right)+\ln\left(Y_{0}\right)=n\left(\frac{1}{2}\ln\left(\frac{9}{8}\right)\right)
 $$ 
This is indeed of the form $\mathbb{E}\left[\ln\left(Y_{n}\right)\right]=Bn$
  for $B=\frac{1}{2}\ln\left(\frac{9}{8}\right)$. Additionally, I tried writing this ""solution path"" using conditioning on $\mathcal{\mathcal{F}}_{n-1}$, that is by doing a similar analysis for $\mathbb{E}_{A}\left[\ln\left(Y_{n}\right)|\mathcal{F}_{n-1}\right]$ which seems more formally accurate however I couldn't make it work out. As for the second question, I showed that $M_{k}$ is a supermartingale and I know that if it had bounded differences then relative to a well chosen stopping time the Optional Stopping Theorem could be applied. Is it possible to deduce that $M_{k}$ has bounded differences by way of contradiction by showing some contradiction to the Optional Stopping Theorem if the opposite was true? If so what stopping time should be used? Sorry for the lengthy read, help would be very appreciated.","['probability-theory', 'stochastic-processes', 'probability', 'martingales']"
865398,Combination of quadratic and arithmetic series,"Problem: Calculate $\dfrac{1^2+2^2+3^2+4^2+\cdots+23333330^2}{1+2+3+4+\cdots+23333330}$. Attempt: I know the denominator is arithmetic series and equals
$$\frac{n}{2}(T_1+T_n)=\frac{23333330}{2}(1+23333330)=272222156111115,$$
but how do I calculate the numerator without using a calculator?","['arithmetic', 'summation', 'sequences-and-series', 'exponentiation']"
865401,Simplify continued fraction with $\pi$,"I'm not even sure where to start on this: Simplify:  $$\pi+\dfrac{2}{\pi+\dfrac{2}{\pi +\dfrac{2}{\dots}}}$$ The second term is a rational expression with 2 in the numerator and the denominator is the entire expression again...over and over with no end. One thought I had was to let $x=\pi + 2/x$, then multiply both sides by x to get a quadratic.  However, I have turned an expression into an equation, so this doesn't seem right. $x^2-\pi x-2=0$ and solve using q.e.
This would give $x = (\pi \pm \sqrt{\pi^2+8} )/2$  However, the problem said to simplify not solve. Any thoughts?",['algebra-precalculus']
865403,Concerning Rules of Exponents & Absolute Value,"I understand that one of the accepted definitions of the absolute value function is $\left| x \right| = \sqrt{x^2}$. However, I do not understand why if I substitute $-5$ in for $x$ that I can't do the following using rules of exponents: $\left|-5\right| = \sqrt{(-5)^2} = \left[(-5)^2\right]^\frac 12 = (-5)^\frac 22 = (-5)^\frac 11 = -5$. Clearly we know that the end result isn't right, but I can't find any logical problems with my reasoning. Can someone shed some light onto the situation for me? Thanks!","['exponentiation', 'absolute-value', 'functions']"
865418,Faithful Representations of C*-algebras,"Can anyone give me an example of a represetation of the algebra $M_n(\mathbb{C})$ that is not faithul?
If it's not possible, could you explain me why it is not?","['operator-algebras', 'matrices', 'c-star-algebras']"
865422,Can any measure be made into a bounded measure?,"Is it possible to derive a bounded measure from any measure on a measure space?
For example can the Lebesgue measure be made into a probability measure?","['probability-theory', 'measure-theory', 'real-analysis', 'analysis']"
865430,What group is $\mathbb{R}/\mathbb{Z}$ isomorphic to?,"This is not so much a plea of ignorance, but rather me trying to see whether intuitively I actually understand what is going on in group theory. The question asks What group is $\mathbb{R}/\mathbb{Z}$ isomorphic to? Thinking about it like a real line which is periodic mod 1, I simply said. The real numbers mod 1 under addition. Is this correct? And am I really allowed to be asking such low level questions on MSE?","['infinite-groups', 'group-theory', 'abstract-algebra', 'abelian-groups']"
865442,Find expression for : $ S_n =\sum_{i=1}^{n} \frac{i}{i^4+i^2+1} $,"I want to find a formula for the sum of this series using its general term.
How to do it? Series $$
S_n = \underbrace{1/3 + 2/21 + 3/91 + 4/273 + \cdots}_{n \text{ terms}}
$$ General Term $$
S_n = \sum_{i=1}^{n} \frac{i}{i^4+i^2+1}
$$","['sequences-and-series', 'calculus', 'real-analysis', 'analysis']"
