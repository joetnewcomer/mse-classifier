question_id,title,body,tags
607588,zeros of a function holomorphic in the closed unit disc,"Let $f$ be a holomorphic function in a neighborhood of the closed unit disc $\{z \in \mathbb{C} : |z| \leq 1\}$, and suppose that $\Re{(\bar{z}f(z))} > 0 $ when $|z| = 1$. Prove that $f$ has exactly one zero in the open unit disc. Till now what I have tried is this: When $|z| = 1: \quad \Re{(\bar{z}f(z))} > 0 \implies |\bar{z} f(z)| > 0 \implies |f(z)| > 0 $. 
Since $|z|=1$ is compact, $|f(z)| \leq M $ on $|z|=1$. WLOG, we can assume $M=1$. This means that $f(z)$ is zero-free on the unit circle and thus has only finitely many zeros inside the unit disc. Thus $f(z)$ has the following Blaschke product representation - $f(z) = z^k \prod_{j=1}^{n} \dfrac{-a_j}{|a_j|} \dfrac{z-a_j}{1-\bar{a_j}z}F(z)$ where $f(a_j) = 0$ for all $j$ and $F(z)$ is a bounded, zero-free holomorphic function in the unit disc. I do not know how to proceed from here and if this is at all useful. Can somebody help please.","['maximum-principle', 'roots', 'complex-analysis']"
607629,meromorphic functions on the extended complex plane,"I'm highly confused by one theorem. Every meromorphic function on the extended complex plane is rational. But $e^z$ is analytic everywhere in the plane, and since it is analytic outside a bounded set, it has an isolated singularity at $\infty$. It seems to me that this singularity at $\infty$ is removable because the laurent expansion at $\infty$ has no positive terms. Therefore it is meromorphic on the extended complex plane. But $e^z$ cannot possibly be rational, it does not have any zero. What's wrong here?","['rational-functions', 'complex-analysis']"
607640,Normal curve after base change (p > 0),"Suppose that $C$ is a normal projective curve over some base field $k$, possibly of positive characteristic. I am wondering to what extent one can modify the base field $k$ while not braking the regularity of $C$. So in particular, is a separable (or maybe separably generated) extension allowed? My exact use case would be $k\subset K=K(C)$, so $K$ is the function field of the curve itself. Moreover, we can assume that $k$ is algebraically closed in $K$.","['algebraic-geometry', 'positive-characteristic', 'algebraic-curves', 'field-theory']"
607647,Characterization of differentiability via Lie derivatives,"Yesterday I asked this question in MathOverflow but did not receive an answer yet. I want to try my chance here too, since I am in kind of a hurry. Answers will be much appreciated. I intend to propose as a project the proof of the statement below, but I want to make sure that it is not already proved somewhere else before. Let $G$ be a Lie group, and $f$ a real-valued function on $G$. The expression $f \in \mathcal{C}^k(G)$ makes sense, and this would be the case even if $G$ were merely a smooth manifold. On the other hand, the Lie group structure on $G$ enables one to speak of directional derivatives of $f$. Indeed, the Lie algebra $\mathfrak{g}$ of $G$ is canonically isomorphic to the space of left-invariant derivations of $\mathcal{C}^\infty(G)$; under this isomorphism, each $X \in \mathfrak{g}$ is associated with the (left) Lie derivative operator $\mathcal{L}_X$ given by
$$(\mathcal{L}_X f)(y) := \left.\frac{\mathrm{d}}{\mathrm{d} t}\right|_{t=0} f(y e^{tX})$$
where $f \in \mathcal{C}^\infty(G)$ and $y \in G$. It is natural to call $\mathcal{L}_X f$ as the (left) directional derivative of $f$ along $X$ . Taking the above equality as a definition, one may expect as in elementary analysis that being in $\mathcal{C}^k$ is equivalent to having continuous directional derivatives of order $k$. This is what our statement says: Statement. Let $G$ be a Lie group, and $f$ a real-valued function on $G$. For each $k \in \mathbb{N}$, $f \in \mathcal{C}^k(G)$ if and only if $(\mathcal{L}_{X_1} \cdots \mathcal{L}_{X_k})f$ exists and is continuous for all $X_1,\ldots,X_k \in \mathfrak{g}$. I searched quite a while for this statement in the literature but could not find anything. (The proof is not so trivial as you might think at a first glance. Please have a look at this question and p. 15 of this essay also.) Have you ever seen it somewhere? If so, could you please give a reference?","['derivatives', 'reference-request', 'differential-geometry', 'lie-groups']"
607661,To calculate residue of the function $f(z) = \frac{z^2 + \sin z}{\cos z - 1}$.,"I was trying to find the residue of the function $$f(z) = \frac{z^2 + \sin z}{\cos z - 1}.$$ Here is the my attempt: The given function has a pole of order two at $z = 2n\pi$. So, we use the following formula to calculate residue of a function when it has a pole of order m at $z=z_0$. $$\mathrm{Res}(f(z))_{z=z_0}=\frac{1}{(m-1)!}\lim_{z\to z_0}\left[\frac{d^{m-1}}{dz^{m-1}}(z-z_0)^m f(z)\right]$$ But I am not able to apply this formula as I am getting zero in the denominator while I am taking limit $z\to 2n\pi$. Any help or suggestions will be very helpful for me. Thanks","['residue-calculus', 'complex-integration', 'complex-numbers', 'complex-analysis', 'limits']"
607684,Limit of the ratio of consecutive Fibonacci numbers [duplicate],"This question already has answers here : How to prove that $\lim \limits_{n\rightarrow \infty} \frac{F_{n+1}}{F_n}=\frac{\sqrt{5}+1}{2}$ (4 answers) Closed 10 years ago . I have read in a book that the limit of the ratio of consequent Fibonacci numbers is the golden ratio. However, it was just mentioned thus not justified. So, my question is how would you derive the following limit:
$$\lim_{x\to\infty}{\frac{F_n}{F_{n+1}}}=?$$
Where $F_n$ is the nth Fibonacci number?","['sequences-and-series', 'calculus', 'golden-ratio', 'fibonacci-numbers', 'limits']"
607695,How does a hyperplane in the projective space corresponds to the Twisting Sheaf of Serre,"Reference: Hartshorne,Chapter 2, Proposition 6.17 $X= \mathbb P ^n _k$ for some field k. Then the generator of the $Cl
(X)$ (which is the group of weil divisors modulo principal divisor) is generated by a hyperplane which corresponds to the invertible sheaf $\mathcal O(1)$. I don't understand how does a hyperplane corresponds to the invertible sheaf $\mathcal O(1)$ Can someone please help.",['algebraic-geometry']
607723,Dominated Convergence on risk measures,"This is a quite specific question and I am not able to provide the whole background (e.g. what a risk measure is). If someone knows that would be great. I am having difficulties understanding a certain point within a proof. We have the following: $\rho(X)=\inf\{ m \in \mathbb{R} | E[l(-m-X)] \leq x_{0} \}$ where $\rho$ is a convex measure of risk, $X \in \mathcal{X}$, where $\mathcal{X}$ is the class of all bounded
    measurable functions on some given probability space
    $(\Omega,\mathcal{F})$ $l$ is convex loss function (increasing
   and not identically constant) $x_{0}$ is an interior point of range of $l$. What I do not understand is why $\rho(X)$ is the solution of $E[l(-z-X)]=x_{0}$ (it is also the unique solution but that I understand). For those who recognize this point is part of the the proof of Prop. 4.59 on p.199 (eq. 4.54) from the book of H. Foellmer and A. Schied ""Stochastic Finance"". The authors state that $\rho(X)$ is a solution because of dominated convergence but I fail to recognize how and why. Thank you in advance.","['convex-analysis', 'measure-theory', 'convergence-divergence']"
607741,"Finding the basis, difference between row space and column space","I'm confused in Linear Algebra when finding the basis. In my textbook there are two methods: Row space and Casting out In the Row Space algorithm I form the Matrix whose rows are the given vectors, then I reduce it to echelon and my basis are the non zero rows: In the Casting out method, I basically form the matrix whose columns are the given vectors. 
Reduce to echelon and my entries with pivots form the basis. I would really appreciate if someone could tell me the difference between using the column and row interpretation (this part really blocks me in the subject), is it basically the same (the difference being how to interpret the echeloned matrix? If yes what is the point of having two distinct methods. And when do I know which one I need to use.",['linear-algebra']
607785,"Improper Integral $\int\limits_0^\frac{1}{2}x^n\cot(\pi x)\,dx$","What is the closed form of the following integral for every $n\in\mathbb{N}$?
$$\int_0^\frac{1}{2}x^n\cot(\pi x)\,dx$$
By Mathematica we see that
$$\int_0^\frac{1}{2}x\cot(\pi x)\,dx=\frac{\log(2)}{2\pi}$$
$$\int_0^\frac{1}{2}x^2\cot(\pi x)\,dx=\frac{\pi^2\log(4)-7\zeta(3)}{8\pi^3}.$$
If there not exist a closed form, how one can prove these two formulas?","['improper-integrals', 'closed-form', 'integration', 'real-analysis', 'complex-analysis']"
607794,Newton-Raphson for reciprocal square root,"I have a question about using Newton-Raphson to refine a guess of the reciprocal square root function. The reciprocal square root of $a$ is the number $x$ which satisfies the following equation: $$x^{-2} = a$$ So we are looking for the root of the following equation: $$x^{-2} - a = 0$$ Applying the Newton-Raphson method then leads to the following: $$x_{n+1} = x_n - {f(x_n) \over f'(x_n)} = x_n - {x_n^{-2} - a \over -2x_n^{-3}} = x_n(1.5 - 0.5ax_n^2)$$ Before looking up the above standard solution, I tried to come up with my own equation: $$x^2 = {1 \over a}$$ In this case, we are looking for the root of a different equation: $$x^2 - {1 \over a} = 0$$ And the Newton-Raphson method gives us: $$x_{n+1} = x_n - {f(x_n) \over f'(x_n)} = x_n - {x_n^2 - {1 \over a} \over 2x_n} = 0.5(x_n + {1 \over ax_n})$$ Is there anything wrong with this alternative approach, and why would I choose one over the other?","['approximation', 'convergence-divergence', 'real-analysis', 'numerical-methods']"
607815,Using argument principle to compute an integral,"Let $f(z)=z^4-2z^3+z^2-12z+20$. Then evaluate the integral by using the argument principle $$\oint_C \frac{zf'(z)}{f(z)} \,ds$$ Where $C$ is the circle $|z|=5$. What I've tried: I tried using the residue theorem but this is a cumbersome method and calculations get too long. Also the book wants us to solve it by the argument theorem and the problem is that the integral is not in the formal form described in the theorem. What's the correct way to solve this problem? The answer in the book is $4\pi i.$","['complex-integration', 'complex-analysis']"
607841,Terminology: How should we call $\mathbb{Z}[\sqrt{5}]$?,"I'm wondering, what shall we call the ring $\mathbb{Z}[\sqrt{5}]$? I know that $\mathbb{Z} \left[ \frac{1+\sqrt{5}}{2} \right]$ is called a quadratic integer ring . But do we have something similar for $\mathbb{Z}[\sqrt{5}]$? I'm sorry if the question seems a little bit dumb, but I haven't come across this term before. :( Thank you very much, And have a good day,","['terminology', 'abstract-algebra']"
607883,Properties of ideals preserved under extension of scalars,"The motivation for this question comes from a question in a book by a certain R.H dealing with geometrically reduced and irreducible schemes. Let $k \subset K$ be algebraically closed fields and let $I$ be a prime ideal in the polynomial ring $k [x_1 \ldots x_n]$, generated, say, by $f_1, \ldots f_m$. Suppose that $I$ is prime or that the radical of $I$ is prime. These properties, I think, should be preserved if we consider $I$ as an ideal in the larger polynomial ring of $K$. I have at least two arguments for that: 1) The first follows by translating those ideal theoretic to a system of polynomial equations and inequations in $K$ with coefficients in the small field $k$. By Hilbert's Nullstellensatz,  if there's a solution in the big field, then there's already a solution in the small one. 2) Use quantifier elimination. Every extension of algebraically closed fields is an elementary extension (in the sense of model theory). Translate the fact that I is not prime into a first order formula with parameters in the small field $k$. If there's a witness in the larger field, there is a witness in the small one already (Here one should be a little bit careful: each formula only handles polynomials of bounded degree. But compactness ensures that if an ideal is not prime, then there is a bound to the degree of the polynomials witnessing this fact as a function of the degrees of its generators). However, I am not sure how to make these notions precise and write them down elegantly. I will appreciate help","['commutative-algebra', 'algebraic-geometry']"
607895,Asymptotic formula for almost primes,"I have developed a formula for almost primes which is far more accurate asymptotically than Landau's well known $$\pi_k(n) \sim \left( \frac{n}{\log n} \right) \frac{(\log\log n)^{k-1}}{(k - 1)!}$$ (Landau's is not good for high $n$, whereas the one I have been working on actually gets more accurate the higher $n$ becomes - see here .) Is this of any significance? Just out of interest, I have included some plots up to $n=9$: where actual is green, Landau is blue, & mine is red. (Note: I have changed the scale in each one.)","['prime-numbers', 'asymptotics', 'number-theory']"
607924,"Alternative to Parthasarathy's ""Probability measures on metric spaces""","In the book ""Probability measures on metric spaces"" by K. R. Parthasarathy the fifth chapter is devoted to the Kolmogorov consistency theorem. Before coming to this result, however, he proves the following: Let $(X,\mathcal{B})$ be a Borel space and $\mathcal{B}_n\subseteq\mathcal{B}$ a $\sigma$-algebra such that (i) $\mathcal{B}_1\subseteq\mathcal{B}_2\subseteq ...$ and $\displaystyle\bigcup_{n}\mathcal{B}_n$ generates $\mathcal{B}$. (ii) $(X,\mathcal{B}_n)$ is a standard Borel space for each $n=1,2,...$ Then, in order that every consistent sequence of measures on $\mathcal{B_1},\mathcal{B}_2,...$ be extendable to a measure on $\mathcal{B}$ it is necessary and sufficient that $\displaystyle\bigcup_n A_n\neq\emptyset$ for each sequence $A_1,A_2,...$. If this is the case, then $(X,\mathcal{B})$ is also standard. I need this theorem in order to prove a different result, and I would like for my text to be somewhat self-contained. The problem is, however, that this would mean adding quite a large appendix if I were to follow the lines of the Parthasarathy book. Hence, my question is: Does anyone know of an alternative text containing a different proof of this (or a similar) result?","['probability-theory', 'probability']"
607934,Underlying set of the scheme theoretic fiber,"Categorical constructions in the category of schemes usually do not preserve the underlying sets. For example, the underlying topological space of the product of schemes is not the topological product of the underlying spaces. It is true that if $V,W$ are varieties then the closed points of the product is the same as the product of the closed points, but even then the topology is finer than the product topology. However, the scheme theoretic fiber over a point has the same underlying set and the same topology as the fiber in the category of toppological spaces. I know how to prove this result - but why should we expect this to be true?",['algebraic-geometry']
607938,Solution verification: $A\sim B\implies \mathscr P(A)\sim \mathscr P(B)$.,"Prove that if $A$~$B$ then $\mathscr{P}(A)$~$\mathscr{P}(B)$, where ~ shows equivalence between sets. Proof: Since $A$~$B$ we define a function $f:A\to B$ such that f is one-to-one and onto by the formula $f(a)=a+1$. Define  $g:\mathscr{P}(A)\to\mathscr{P}(B)$ for arbitrary $k,n\in\mathbb{Z^+}$ such that $n=|A|$, $g(\{a_1,...,a_k\})= 
\begin{cases} \{a_1 +1,...,a_k+1\}, &\text{$1\le k\le 2^{n-1}$}\\
\{a_k+1\}, &\text{$n=1$}\\
\end{cases}$ It's easy to check that $g$ is one-to-one and onto.","['elementary-set-theory', 'solution-verification']"
607956,How many of all cube's edges 3-colorings have exactly 4 edges for each color?,"I've found the number of different cube's edges  colorings with three colors available.
 (We say that the two colorings are the same if one can obtain a second by turning cube and permuting colors)
My resualts credit are given to the following solution : Edge coloring of the cube . [solution summery : First of all define a group G, a set X and group action of G on X. We want to find the number of different cube edges coloring while we know that if we can obtain some coloring by turning another one – it is the same coloring. So we actually need to find the number of orbits of X (the orbit of an element x in X is the set of elements of X to which x can be moved by the elements of G) and then use Burnside's lemma . ] So,  Now I want calculate how many of the 3-colorings I found have exactly 4 edges for each color ? this question asked in Combinatorics course as a bonus question. Thanks! 
Bar","['abstract-algebra', 'combinatorics']"
607988,Where is sum $\sum_{n=0}^\infty \left(\frac{1-z}{1+z}\right)^n$ analytic,"I'm trying to solve for the values of $z$ such that the function $$\sum_{n=0}^\infty \left(\dfrac{1-z}{1+z}\right)^n$$ converges, and also determine where the sum is analytic. Well, the series converges if and only if $\left|\dfrac{1-z}{1+z}\right|<1$, which means $|1-z|<|1+z|$. Viewing geometrically, $z$ is closer to the point $1$ than to the point $-1$, so we have $\Re{z}>0$. Where is the sum analytic? I don't know of any theorem to guarantee that.","['sequences-and-series', 'complex-analysis']"
608014,ODE with delta function,"Consider the following ODE
$$y''+a\delta (x)y+\lambda y=0$$
subject to the initial conditions
$$y(\pm\pi )=0$$
(1) Show that there is a set of eigenvalues
$$\tan (\pi \sqrt{\lambda })=\frac{2\sqrt{\lambda }}{a}$$
(2) Investigate if the condition $$\lambda =-u^{2}$$
where u is a positive number, is possible. I tried Laplace transform but noticed that the initial value is not satisfying.
Then I tried to separate cases where x is zero or non-zero, but it didn't lead to the answer. Keep trying:
So I noticed 
$$\int_{-\epsilon }^{\epsilon }[y''+a\delta (x)y+\lambda y]dx=\int_{-\epsilon }^{\epsilon }y''dx+\int_{-\epsilon }^{\epsilon }a\delta (x)ydx+\int_{-\epsilon }^{\epsilon }\lambda ydx$$
$$=y'(\epsilon )-y'(-\epsilon )+ay(0)+\lambda \int_{-\epsilon }^{\epsilon } ydx$$
Then I took $$\lim_{\epsilon \rightarrow 0^{+}}$$ and obtain the following equation $$y'(0^{+})-y'(0^{-})+ay(0)=0$$
Next I tried to solve the ODE on the interval $$(-\infty ,0)\cup (0,\infty )$$ (in this way the delta function is evaluated to be zero)
So the ODE becomes $$y''+\lambda y=0$$ which has the solution form$$y=c_{1}\sin \sqrt{\lambda }x+c_{2}\cos \sqrt{\lambda }x$$
But after I substitute the initial conditions $$y(\pm\pi )=0$$ I got $$c_{1}=c_{2}=0$$
I am wondering what went wrong here...",['ordinary-differential-equations']
608019,Limit of product series for convergent and increasing sequences,"Suppose $a_1,a_2,\ldots\in\mathbb{C}$ and $b_1,b_2,\ldots\in\mathbb{R}$. Suppose also that $\sum a_n$ converges, that $b_n\leq b_{n+1}$ for all $n\geq 1$, and that $\lim_{n\rightarrow\infty}b_n=\infty$. I want to show that $$\lim_{N\rightarrow\infty}\dfrac{1}{b_N}\sum_{n=1}^Na_nb_n=0.$$ My intuition is that: As $N$ gets large, $a_n$ is very small (since its series is convergent), while $b_n$ for $n\leq N$ is bounded by $b_N$, which appears in the denominator, so $\dfrac{a_nb_n}{b_N}$ is small. How can we actually make the argument?","['convergence-divergence', 'sequences-and-series', 'complex-analysis', 'limits']"
608027,Example of topological space where pseudo-component differ with intersection of clopen sets.,"It is well known fact that connected component $C_x$ of a point $x$ from some topological space $\tau$ is contained in every clopen set containing $x$ (so it's intersection $M$ also contains $C_x$). We know that when $\tau$ is compact then mentioned intersection $M$ equals to $C_x$, too. Hence my question: what is counterexample for non-compact $\tau$ where $C_x$ differs with $M$?","['general-topology', 'connectedness', 'compactness']"
608039,Keyhole integral and version of $\log$ in $\frac{\log t}{(t^2+1)^2}$,"I want to calculate $$\int_0^\infty \dfrac{\log t}{(t^2+1)^2}dt$$ It certainly looks like a contour integral. I'm thinking about the keyhole contour where the ""hole"" is around the origin and along the positive $x$-axis. Along the horizontal line above the $x$-axis, it is our desired integral. But what should it be along the horizontal line below the $x$-axis? I'm not so well-versed with versioning of $\log$ to say this.","['logarithms', 'integration', 'complex-analysis']"
608059,Closed form for $\sum_{n=-\infty}^\infty \frac{1}{(z+n)^2+a^2}$,I want to express $$\sum_{n=-\infty}^\infty \dfrac{1}{(z+n)^2+a^2}$$ in closed form. What comes to mind is the formula $$\pi\cot\pi z = \dfrac{1}{z}+\sum_{n\ne 0}\left(\dfrac{1}{z-n}+\dfrac1n\right)=\dfrac{1}{z}+\sum_{n=1}^\infty\dfrac{2z}{z^2-n^2}$$  and also $$\dfrac{\pi^2}{\sin^2\pi z}=\sum_{n=-\infty}^\infty \dfrac{1}{(z-n)^2}.$$ But neither of these gives the term $(z+n)^2+a^2$ that we want. Perhaps we can adjust somehow?,"['sequences-and-series', 'complex-analysis']"
608061,"Find partial derivative at point $(0,0)$ of $(xy)/(x^2+y^2)$","It's a bit wierd question but I have to ask it. $$ \text{Let }\space f(x, y) =
\begin{cases}
\dfrac{xy}{x^2 + y^2},  & \text{if $(x, y) \ne (0,0)$} \\
0, & \text{if $(x, y) = (0, 0)$}  \\
\end{cases}$$ The following question is: Do partial derivatives of $f(x, y)$ exist at $(0, 0)$? If so, find them. if not, prove. As I know it should be simple, Just derive $\dfrac{df}{\partial x} 0 = 0, \dfrac{df}{\partial y} 0 = 0$. But I must admit it seems wierd. where have I wrong? How should I solve such questions? thanks in advance!","['multivariable-calculus', 'partial-derivative']"
608066,A possible theorem,"So i was playing around with members of a random power set, and i came to a revelation(at least to me it was). Say $A=\{1,2,3\}$ then for arbitrary $k,n\in Z^+$, $n=|A|$ and $\mathscr{P}(A)=\{\varnothing,\{1\},\{2\},\{3\},\{1,2\},\{1,3\},\{2,3\},\{1,2,3\}\}$, $|\mathscr{P}(A)|=2^n.$ There are ${n\choose n-1}$ ways of choosing ($n-1$)- element sets in $\mathscr{P}(A)$  so that's ${3\choose1}+{3\choose2}+{3\choose3}=7$ so we're short by one, playing around once more and we have    $2{n\choose n}+{n\choose n-1}+{n\choose n-2}=2^n$ and by generalizing:
$2{n\choose n}+{n\choose k}+...+{n\choose k-(n-2)}=2^n$ for $1\le k\le n-1$. Pardon my ignorance, but is there a theorem for this(if the equation is correct), and is this how research in math is done(if it is, then it must be pretty darn exciting!!!)",['sequences-and-series']
608067,$\int_{-\pi/2}^{\pi/2} \frac{\sin^{2012}{x}}{\left(1+ \alpha^x\right)\left(\sin^{2012} {x}+\cos^{2012}{x}\right)}\;{dx} $,"For $\alpha\in\mathbb{R^+}$, evaluate $$\displaystyle \int_{-\pi/2}^{\pi/2} \frac{\sin^{2012}{x}}{\left(1+ \alpha^x\right)\left(\sin^{2012}  {x}+\cos^{2012}{x}\right)}\;{dx} $$ Can I have a hint on this? I tried substituting $x=-t$ but got nowhere.","['trigonometry', 'integration']"
608093,Proving $\int_a^b x^2dx = \frac{b^3 - a^3}{3}$,"Can anyone help me prove $\int_a^b x^2dx = \frac{b^3 - a^3}{3}$, the long way? I know exactly what to do, but the algebra involved is just too much for me and I keep making a mistake somewhere and getting a different result every time...
I need to prove it using the Riemann defintion of an integral, for a start it would be: $$\int_a^b x^2dx = \displaystyle \lim_{n \to\infty} \sum_{i = 1}^n\left[{a+\frac{bi - ai}{n}}\right]^2\left[\frac{b - a}{n}\right]$$ right? And I need to do so many steps to prove it..is there an easier way or will I just have to go through all the steps?","['riemann-sum', 'calculus', 'integration']"
608122,Help in this easy example in algebraic geometry,"It's a silly example, maybe I miss something. I will begin with a theorem in basic algebraic geometry that states: Let $f:X\to Y$ be a finite morphisms of affine varieties with $Y$
  normal. Thus, for each $y\in Y$, we have $|f^{-1}(y)|\le \deg(f)$. Notation: $\deg(f)=[K(X):K(Y)]$ $Y$ normal means every element of $K[Y]$ contains every element of $K(Y)$ which is integral over $K[X]$ $y\in Y$ is a ramification point if $|f^{-1}(y)|\lt \deg(f)$ Example $$f:\mathbb A^1\to \mathbb A^1$$ $$t\mapsto t^2$$ I didn't understand why: If $char(k)\neq 2$, then there is only one ramification point $(t=0)$. If $char(k)=2$, then every point of $\mathbb A^1$ is a ramification point. Thanks in advance",['algebraic-geometry']
608126,Knowing when to use Green/Stokes/Divergence theorem to evaluate line/surface integrals,"$\newcommand{\mbf}{\mathbf}$
Evaluate 
$$
\iint \limits_{S} \mbf{F} \cdot d \mbf{S}
$$
where $\mbf{F} = 3xy^2 \mbf{i} + 3x^2y \mbf{j} + z^3 \mbf{k}$ and $S$ is the surface of the unit sphere. I have written my solution below -- is it correct?  Also, how does one know when to use Green/Stokes/Divergence theorem to evaluate a surface/line integral? Note that evaluating this surface integral directly yields an ugly integral of $\int \sin^5(x)\, dx$.  We will resort to Gauss' Divergence Theorem to simplify matters. Indeed, by Gauss' Divergence Theorem, we have
$$
\iint \limits_{S} \mbf{F} \cdot d \mbf{S} = \iiint \limits_{S_{\text{int}}} (\nabla \cdot \mbf{F}) \, dV.
$$
where $S_{\text{int}}$ denotes the interior of the sphere.
Now, $\nabla \cdot \mathbf{F} = 3(x^2+y^2+z^2)$.  Now, we are just integrating
$$
\iiint \limits_{S_{\text{int}}} 3(x^2+y^2+z^2) \, dV.
$$
Let's transform this to spherical coordinates.  We obtain the equivalent integral
$$
\int_{0}^{2\pi} \int_{0}^{\pi} \int_{0}^{1} 3 \rho^4 \sin \phi \, d \rho \, d \phi \, d \theta.
$$
$$
= \frac{3}{5} \int_{0}^{2 \pi} \int_{0}^{\pi} \sin \phi \, d \phi \, d \theta
$$
$$
= \frac{12 \pi}{5}.
$$",['multivariable-calculus']
608163,Find angle inside of isosceles triangle,"The figure explains it best. We have $ABC$ isosceles triangle. We know a few angles as follows: $$\begin{align}
ACB &= 20°\\
PAB &= 50°\\
ABQ &= 60°
\end{align}$$ Find $\angle BQP$",['trigonometry']
608179,Proof of $\sum_{i=1}^{k}(2i-1) = k^2$ and some general questions,"My vocabulary in math is lacking quite a lot, so please forgive me if my question is not sufficiently accurate or needlessly verbose. I tried very hard to get the latex flowing, at least that's one thing I got going. In the syllabus from which I'm currently studying, the proof of this equation is something I have difficulty grasping (this is a quick example that's supposed to be self-explanatory *desperate face* ): $$\sum_{i=1}^{k}(2i-1) = k^2$$ Now, this is the proof in the syllabus: $$\sum_{i=1}^{k+1}(2i-1)  = \sum_{i=1}^k(2i-1) + 2k + 1$$ $$\sum_{i=1}^{k+1}(2i-1) = k^2 + 2k + 1$$ $$\sum_{i=1}^{k+1}(2i-1) = (k+1)^2$$ I understand the reasoning, 1 being the minimum value and valid allows for rewriting the equation for k+1, and if everything for the k+1 version is valid, along with the minimum of k being valid, everything is valid. However, why isn't the first step done like this? (subtraction, isn't valid but seems logical to me atm) $$\sum_{i=1}^k(2i-1) + 2k - 1$$ Also, could someone please point me in the right direction on how to accomplish this conversion: $$k^2+2k+1 = (k+1)^2$$ Thank you in advance for helping me find the sources on how to understand everything until page 18 (out of 180 ^_^)",['discrete-mathematics']
608186,General geodesics,"How to solve the following: Let $f : (M,\nabla)\rightarrow (\overline{M},\overline{\nabla})$ be a diffeomorphism of manifolds with torsion-free connections. a) For reparametrisation $\alpha$ of geodesic line on M holds $\nabla_{T_\alpha}T_{\alpha}=
\rho(t)T_\alpha$, and conversely, if tangent field of curve satisfies this condition, then exits its reparametrisation that is geodesic. Prove. (These curves we can call general geodesics.) b) Diffeomorfism $f$ is a geodesic map if image of general geodesic on manifold M is general geodesic on $\overline{M}$. By identifying $f$ connected vector-fields
$M$ and $\overline{M}$: $P(X,Y)=\overline{\nabla}_{X}Y-\nabla_{X}Y$. Prove that $P$ is symmetric and $F$-bilinear map. Conclude that $P(X,Y)= \psi(Y)X+\psi(X)Y$, where $\psi$ is a form. By using vector-fields of coordinate frame, find $\psi$. For a torsionless connection we have: $\nabla_{X}Y-\nabla_{Y}X=[X,Y]$. $P$ is a $F$-bilinear map, since it is $F$-linear by first coordinate:
\begin{align*}P(X,f_1 Y_1+f_2 Y_2)&=\nabla_{X}(f_1 Y_1+f_2 Y_2)-\overline\nabla_{X}(f_1 Y_1+f_2 Y_2)\\
&=\nabla_{X}f_1 Y_1+\nabla_{X} f_2 Y_2-\overline\nabla_{X}f_1 Y_1-\overline\nabla_{X}f_2 Y_2\\
&=X(f_1)Y_1+f_1\nabla_{X}Y_1+X(f_2)Y_2+f_2\nabla_{X}Y_2\\
  &\quad -X(f_1)Y_1-f_1\overline\nabla_{X} Y_1-X(f_2)Y_2-f_2\overline\nabla_{X} Y_2\\
&=f_1(\nabla_{X}Y_1-\overline\nabla_{X}Y_1)+f_2 (\nabla_{X}Y_2-\overline\nabla_{X}Y_2)\\
&=f_1 P(X,Y_1)+f_2 P(X,Y_2),\end{align*}
and similarly, it is $F$-linear by second coordinate. How to deduce what is $\psi$? Also, how to prove a statement for general geodesics? Detailed explanations are welcome. Thanks in advance.",['differential-geometry']
608196,"Limiting case of Binomial(n,p)/n?","Let the random variable $X$ have distribution $X \sim \text{Binomial}(n,p)$.  Let $Y = X/n$.  What is the limiting distribution of $Y$, as $n \to \infty$?  Does it have a simple distribution? Of course, when $n$ is large, $X$ has approximately the distribution $\text{Poisson}(np)$.  Thus, we could ask the question in the following alternative way: suppose $X^* \sim \text{Poisson}(np)$, and define $Y^* = X^*/n$; what is the limiting distribution of $Y^*$, as $n \to \infty$? I have not been able to find an existing result on this, though it sounds like the sort of thing that someone must have studied long ago.  When I search for limiting distribution and Poisson or limiting distribution and Binomial, I find many references to the fact that $\text{Binomial}(n,p) \to \text{Poisson}(np)$ as $n \to \infty$, which I already knew, so I'm not sure where to look to figure this out.","['convergence-divergence', 'probability-distributions', 'probability', 'limits']"
608210,sufficient condition for being an integral factor,Let $ f: \mathbb {R}^m \rightarrow \mathbb {R}-\{0\} $ function $C^{\infty}$ class and $w$ a one-form $C^{\infty}$ class in $\mathbb {R}^m $. If $\alpha=w-\dfrac{1}{f}dx_{m+1} $ satisfies $\alpha \wedge d\alpha= w \wedge dw$ then $d(fw)=0$ Note: $\mathbb {R}^m \subseteq \mathbb {R}^{m+1}$ with $x_{m+1}=0$. Thanks for any suggestions.,"['multivariable-calculus', 'differential-geometry', 'manifolds', 'analysis', 'multilinear-algebra']"
608236,Calculating $\log_7 125$,"So the problem asks to calculate $\log_7 125$. It's multiple choice and the options are $2.48$ $4.75$ $1.77$ $2.09$ Given that $7^2 = 49$ and $7^3 = 343$, the answer must be either option 1 or 4, not 2 or 3. So now what. I remembered there's a way to translate bases like so:
$$
\log_a x = (\log_a b)(\log_b x)
$$
which translates to
$$
\log_7 125 = (\log_7 5)(\log_5 125)
$$
which is 
$$
3\log_7 5
$$ But then what? I didn't know so I took an educated guess and went which option 1, which was right. But for next time, what should I do? What is the general strategy for solving problems like this when the base and the number have no obvious relationship?","['exponentiation', 'logarithms', 'algebra-precalculus']"
608257,"Evaluate the integral: $ \int x \tan^{-1}\ x \,\mathrm{d}x$","Evaluate the integral: $$\int x\tan^{-1}x\,\mathrm{d}x$$ What I have so far: $$u = \tan^{-1}x$$
$$\mathrm{d}u = \frac{1}{1+x^2}\,\mathrm{d}x$$
$$\mathrm{d}v = x\,\mathrm{d}x$$
$$v = \frac{x^2}2$$ $$(*) \int u\ \mathrm{d}v = uv - \int v \ \mathrm{d}u$$
$$\left(\tan^{-1}x\right)\frac{x^2}2 - \frac12\int x^2\cdot\frac{1}{1+x^2}\,\mathrm{d}x$$
$$\left(\tan^{-1}x\right)\frac{x^2}2 - \frac12\int \frac{x^2}{1+x^2}\,\mathrm{d}x$$ The problem I have now is how to integrate the integral $\displaystyle \int \dfrac{x^2}{1+x^2}\,\mathrm{d}x$. It doesn't look like a U-substitution will get me any further nor can I make a trig substitution.","['trigonometry', 'calculus', 'integration', 'indefinite-integrals']"
608266,Prove a cubic equation has at least one real root,"Show that the cubic eq: $$x^3+ax^2+bx+c = 0 \quad  a,b,c\in \mathbb{R}$$ has at least one real root. I know that the above equation can be broken down into $(x-a)(x-b)(x-c) = 0$ , but I have no idea what to do next. I can't use IVT to do this because I don't have a specified range. (edit): For others reading this, the equation CANNOT be broken down to $(x-a)(x-b)(x-c) = 0$","['multivariable-calculus', 'calculus']"
608269,Pullback distributes over wedge product,"I'm looking to prove that the pullback of a smooth function distributes over wedge product, i.e. $$\varphi^*(\omega \wedge \eta) = \varphi^* \omega \wedge \varphi^* \eta. $$ Here the question is answered. This is an excerpt from the answer: $f^*(\omega\wedge \theta)(v_1,\cdots ,v_p,w_1,\cdots ,w_q)=(\omega\wedge \theta)(f_*(v_1),\cdots ,f_*(v_p),f_*(w_1),\cdots ,f_*(w_q)).$ using the summation formula for wedge product. Which will be same as $\omega(f∗(v_1),⋯,f∗(v_p))\wedge \theta(f∗(w_1),⋯,f∗(w_q)).$ Which is (by definition) same as $f_*(\omega)\wedge f_*(\theta).$ The part I have trouble with is the third line. $\omega(f∗(v_1),⋯,f∗(v_p))$ and $\theta(f∗(w_1),⋯,f∗(w_q))$ are real numbers, so how can we wedge them? There might be some abuse of notation here I'm not familiar with. When I try to show $\varphi^*(\omega \wedge \eta) = \varphi^* \omega \wedge \varphi^* \eta $, my attempt breaks down when I try to simplify $(\varphi^*\omega \wedge \varphi^* \eta)(v_1, \dotsc, v_{p+q})$. Should I try to work with decomposable forms?","['differential-forms', 'differential-geometry']"
608280,Real life examples of commutative but non-associative operations,"I've been trying to find ways to explain to people why associativity is important.
Subtraction is a good example of something that isn't associative,  but it is not commutative. So the best I could come up with is paper-rock-scissors; the operation takes two inputs and puts out the winner (assuming they are different). So (paper rock) scissors= paper scissors = scissors, But paper (rock scissors)= paper rock = paper. This is a good example because it shows that associativity matters even outside of math. What other real-life examples are there of commutative but non-associative operations? Preferably those with as little necessary math background as possible.","['examples-counterexamples', 'abstract-algebra', 'soft-question', 'binary-operations', 'associativity']"
608290,Intersecting geodesics in a positive curvature manifold,"Suppose $M$ is a connected, compact orientable 2-dimensional Riemannian manifold, with positive Gaussian curvature. I'd like to show that two non-self-intersecting closed geodesics must intersect each other. I tried to use Gauss-Bonnet Theorem to prove this, but I wasn't successful.
Can somebody help me ?
Thank you.","['riemannian-geometry', 'differential-geometry']"
608296,Limit of $\sum_{i=1}^n \left(\frac{{n \choose i}}{2^{in}}\sum_{j=0}^i {i \choose j}^{n+1}\right)$,I'm trying to calculate the limit for the sum of binomial coefficients: $$S_{n}=\sum_{i=1}^n \left(\frac{{n \choose i}}{2^{in}}\sum_{j=0}^i {i \choose j}^{n+1} \right).$$,"['limits', 'sequences-and-series', 'binomial-coefficients', 'combinatorics']"
608305,Prove that $f \in C^k$ if $|\hat{f}(n)|\leq C/|n|^{k+a}$,"I'm looking at some problems related to Fourier series. This one stumped me a little. Suppose that $f$ is $2\pi$-periodic and piecewise smooth. Show that if
  there exist $k \in \mathbb{N}, a > 0,$ and $C > 0$ such that
  $$|\hat{f}(n)|\leq \frac{C}{|n|^{k+a}},$$ for $n \geq N_0$, then $f
 \in C^k$. Note that $\hat{f}(n)$ is the Fourier coefficients of $f$. I really seem to have no idea where to start with this one. I was thinking about using the expression for the Fourier coefficients $$\hat{f}(n) = \frac{1}{2\pi}\int_0^{2\pi} f(t) \mathrm{e}^{-int}\, \mathrm{d}t$$ and bound it by $|\hat{f}(n)| \leq 1/2\pi \int_0^{2\pi} |f(t)|\, \mathrm{d}t$. But this throws the $n$ out of the question. Any ideas?","['fourier-series', 'fourier-analysis', 'complex-analysis']"
608307,"If $A + B + C = \pi$, then show that $\sin(A) + \sin(B) + \sin(C) = 4\cos\frac{A}{2}\cos\frac{B}{2}\cos\frac{C}{2}$ [duplicate]","This question already has answers here : Prove that $\sin(2A)+\sin(2B)+\sin(2C)=4\sin(A)\sin(B)\sin(C)$ when $A,B,C$ are angles of a triangle (3 answers) Proving $\sin A + \sin B + \sin C = 4 \cos \frac{A}{2} \cos \frac{B}{2} \cos \frac{C}{2}$ [duplicate] (5 answers) Closed 10 years ago . So i have 
$A + B + C = \pi$ $$\frac{A}{2} + \frac {B}{2} + \frac{C}{2} = \frac{\pi}{2}$$ $$4\cos\left(\frac{-B-C + \pi}{2}\right)\cos\left(\frac{-A -C + \pi}{2}\right)\cdots$$
 And I doubt this leads to anywhere. So then I tried, 
$\sin\left(\frac{-B-C + \pi}{2}\right)\cdots$ and this didn't go anywhere either. 
I don't know what to try, and I've seen other people's solutions and they do something like:
$\sin(C) = \sin(A + B)$, $\cos(C/2) = \sin(\frac{A + B}{2})$ but i don't see where they got this part from. Other people use Euler's formula or whatever but I haven't learned that yet so I can't use it.",['trigonometry']
608361,Finding the limit of $\mathop {\lim }\limits_{x \to 0} \frac{x}{{\ln (5x + 1)}}$,"$$\lim_{x \to 0^+} \frac{x}{\ln (5x + 1)}  = {1 \over 5}$$ First, What I tried to do is dividing by $x$, but it didn't work out. By the way, It's a common approach to find a limit. Why is it failing here? Second, I played with the logarithm rules which only brought me to: $$\log _{5x + 1} e^x = x \log_{5x + 1} e$$ It might be a starter, but I don't know what to do from this point.","['calculus', 'functions', 'limits']"
608373,Why is shefication necessary in constructing the reduced scheme?,Let $X$ be a scheme. Hartshorne defines the reduced scheme associated to $X$ as the sheafication of the presheaf $U \mapsto \mathcal{O}_X(U)_{\text{red}}$. Is there any example that shows that this presheaf need not be a sheaf?,['algebraic-geometry']
608388,A real world problem I have encountered in my work (Not a book!) - opcode allocation,"""here's a word size, here is a list of data bits of an instruction, and their relative frequencies, allocate them as best you can"" Tags were a guess, sorry. I find this problem to be VERY interesting, I'm not sure what I expect as an answer but I want at the very least to share it. Terminology A bit is a binary digit , a 0 or a 1. A word is a collection of bits (for this application 8 of them, this may be called a byte or sometimes char ) An instruction is a number of words such that the first m bits unambiguously identify the instruction (there will be examples), the remaining bits may be data or ignored. A register is a number of words ""inside the machine"" that instructions can operate on and use data from. (there will always be at least 4 registers, due to the four colour theorem) A subregister is a continuous partition of a register and is a number of words in length. The memory is a strip of words starting at 0 to some finite limit. The size of a register is what subregister we wish to use A general purpose register is a register used for manipulating data, not the flow of the program or manipulating structures of the program (eg stack) Examples to understand terminology x86_64 registers This is a real world example, in the CPU of the computer you are reading this on is a register called ""a"", it is 64 bits (8 bytes) long. rax address the full 64 bits, eax addresses the lower 32 bits, ax the lower 16, al the lower 8 and ah the upper 8 of ax , as a diagram: register a (the numbers below are bytes)
|   7   |   6   |   5   |   4   |   3   |   2   |   1   |   0   |
|                          rax                                  |
                                |               eax             |
                                                |      ax       |
                                                |  ah   |  al   | So al is a subregister of ax . Instructions Suppose I want to move the contents of register X into register Y , we denote this by the assembly instruction: MOV X,Y , we move into X the value of Y. However using a and b registers from the _x86 example above: MOV a,b means copy the contents of b into a, but what parts of b and a? MOV rax,rbx makes sense, clearly this means copy the 64 bits of b into a. MOV eax,ebx means copy the lowest 32 bits of b into a. Clearly the sizes must be the same for the MOV instruction. Defining an instruction Suppose we have 4 registers, a , b , c and d . Suppose also we have 4 sizes, 64 bits, lower 32, lower 16 and lower 8. we may express a register as 2 bits, ( 00 01 10 and 11 respectively) We may also express a size as 2 bits (the same as above respectively) So MOV GP,GP where ""GP"" means ""general purpose register"" has 6 bits of data, target register, source register and size. Recall that an instruction is a number of words, this means (I will use word size as 8 in all examples) to fit in one word the first 2 bits must uniquely and unambiguously define MOV. If we can't do this then we must use 16 bits (2 words) and this means 8 bits are ignored. this is inefficient and what is to be minimised Worked example problem Suppose we have the following instruction set MOV GP,GP - Copy the contents of the second register into the first. MOV [GP],GP - Copy the value of the second register into the memory location given by the first. ( example MOV [rax],ebx sets the memory location rax to the first byte of of ebx , the memory location rax+1 to the second byte of ebx , all the way to rax+3 being the final byte of the 4 byte register ebx.) This requires 2 registers and a size (it must be [rax] for this machine in the example because a memory address is 64 bits, the amount of data to copy into memory is given purely by the right hand register) MOV GP,[GP] - Copy the value of the memory location given by the second register into the first register ( example MOV ax,[rdx] means copy the memory value at rdx to the lower byte of a and copy the memory value at rdx+1 to the second lowest byte of a ) HALT - this signals the end of the program and shuts down the machine (it doesn't execute any more instructions after this) NOP - short for no op, it literally means do nothing. This is what your processor does when idle. A naive attempt MOV GP,GP has 6 bits of data MOV [GP],GP has 6 bits of data MOV GP,[GP] has 6 bits of data HALT has 0 bits of data NOP has 0 bits of data Let us also consider an instruction frequency , higher indicates more frequent and lower indicates less frequent, is is simply a ranking (an integer value). Clearly the first 3 will be very common instructions and the last 2 will be very uncommon, it makes sense to allocate them like so: MOV a,b   -->  00aabbss (ss is size)
MOV [a],b -->  01aabbss 
MOV a,[b] -->  10aabbss
HALT      -->  1100xxxx (x = ignored)
NOP       -->  1101xxxx 
(unused)  -->  1110
(unused)  -->  111100
(unused)  -->  111101 You can see the pattern forming I hope, you'll also note this is unambiguous, if one were to allocate binary numbers for these you will note HALT would be 100vwxyz (4) (where HALT would ignore vwxyz) However this would be interpreted as MOV into register 0v the yz sized block of data starting at the location in memory given by register wx Hence my simple pattern. The above example was simple to solve regardless. Where it becomes complex Suppose we have some more instructions: ADD GP,GP - Add to the LHS register the contents of the RHS register (6 bits of data, a lower frequency than any MOV, 2 registers and a size) INC GP - increment register by 1 (4 bits of data, register and size) DEC GP - like INC but decreases a register's value by 1 (4 bits of data) SET GP,mask,value - mask and value are 8 bits each, for each 1 in the mask set the corresponding byte in GP to the 8 bits given in value. so SET GP,11111111,00000000 sets an entire register to 0 - 18 bits of data (2+8+8) MUL GP,GP - Another 6 data bit, same format as ADD NEG GP - negates the integer value of GP (4 data bits) PUSH GP - 4 data bits, register and size POP GP - 4 data bits, register and size You can see that the moment we have more than 3 things with the same amount of data something has to spill and it might displace something else. My question is, what is the best way to allocate a set of operations? This boils down (hopefully now you see how/why) ""How can I create a word length * n string of binary digits that uniquely defines an operation with n data bits where the least number of bits are ignored and equally eligible operations are ranked based on their relative frequency."" At first glance this appears VERY similar to box packing, and it almost is, the constraint of minimising the number of words for an instruction is important however. One of my earliest attempts was to put this in a spreadsheet and order by data bits, this works for instructions that want to share the same instruction length, but can unfairly place (for example) the SET instruction last, even though it'd nicely fit in a 24 bit (3 byte) instruction. There is more to this problem than meats the eye, I want to study this! I wont bother giving you a full instruction set because it doesn't matter to the problem it boils down to ""here's a word size, here is a list of data bits of an instruction, and their relative frequencies, allocate them as best you can"" - This question would have made little sense without the above.","['discrete-mathematics', 'combinatorics']"
608433,When can a manifold be curvature free?,"Recall that in a Riemannian manifold (or pseudo Riemannian) there is always the unique Levi-Civita connexion that annuls the torsion. There are also manifolds (not needfully Riemannian) which are curvature free, thus the deviation from Euclideanhood is encoded wholly in the torsion tensor. Question 1: Are there known sufficient, or necessary, or both necessary and sufficient conditions conditions for a curvature-free connexion (weaken assumptions to e.g. a Finsler manifold if need be) to be defined? Question 2: Are there known sufficient, or necessary, or both necessary and sufficient conditions conditions that rule out a curvature-free connexion? Question 3: Now, one thing that is bending my mind is: what happens to the holonomy group if we can have a curvature-free connexion? Obviously the holonomy group is trivial for a curvature free manifold. This seems to imply to me that somehow all connexions for that manifold must be curvature free, because there is no way to ""continuously deform"" a Lie group from the trivial group to a nontrivial one. Is this right? If not, how does the holonmy group ""jump"" from being trivial to something nontrivial?","['manifolds', 'differential-geometry']"
608445,Evaluate: $\int \frac{1}{x^7-x}\ \mathrm{d}x$,"Evaluate: $$\int \frac{1}{x^7-x}\ \mathrm{d}x$$ My approach to this question: $$\int \frac{1}{x^7-x}\ \mathrm{d}x = \int \frac{1}{x(x^6-1)}\ \mathrm{d}x$$
$$\int \frac{1}{x(x^6-1)}\ \mathrm{d}x = \int \frac{1}{x(x-1)(x+1)(x^2-x+1)(x^2+x+1)}\ \mathrm{d}x$$
$$\frac{1}{x(x-1)(x+1)(x^2-x+1)(x^2+x+1)} = \frac{A}{x} + \frac{B}{x-1} + \frac{C}{x+1} + \frac{Dx+E}{x^2-x+1} + \frac{Fx+G}{x^2+x+1}$$ At this point I realized how brutal this question if going to be. Is there an easier way to solve the integral?",['calculus']
608446,Fourier transform extended to $L^2$,"Let $f\in L^1(\mathbb{R})\cap L^2(\mathbb{R})$, and let $f_k$ be functions in the Schwartz class such that $\|f-f_k\|_1+\|f-f_k\|_2\rightarrow 0$ as $k\rightarrow\infty$. Define $$g_k(t)=\int_\mathbb{R}f_k(x)e^{-itx}dx \text{    and    } g(t)=\int_\mathbb{R}f(x)e^{-itx}dx$$ It can be shown that $\lim_{k\rightarrow\infty}g_k(t)=g(t)$ for all $t$. Let $T_1:L^2(\mathbb{R})\rightarrow L^2(\mathbb{R})$ be defined as the unique continuous mapping that extends the mapping $T:S\rightarrow L^2(\mathbb{R})$, where $S$ is the Schwartz class, and the Fourier transform of a function in the Schwartz class is defined using the $L^1$ definition (like $g$ and $g_k$ above.) How can I prove that $$\lim_{k\rightarrow\infty}\|g_k-T_1f\|_2=0$$ and also that $$g(t)=(T_1f)(t)$$ pointwise? EDIT : The first one is a consequence of Plancherel theorem, as Daniel Fischer mentioned in the comment. What about the second one?","['fourier-analysis', 'limits']"
608453,Eisenbud Unmixedness Example,"I am struggling with the following example in Chapter 18 of Eisenbud's Commutative Algebra with a View Toward Algebraic Geometry , in which the author uses the unmixedness theorem to show that a genus 1 degree 4 irreducible curve $C$ in $\mathbb{P}^3_k$ has a homogeneous ideal generated by two quadrics in $S = k[x_0,...,x_n]$. He shows first that there exist linearly independent irreducible quadrics $Q_1$, $Q_2$ such that $(Q_1,Q_2) \subset I$, where $I$ is the homogeneous ideal of $C$. Next he uses irreducibility to assert that $Q_1, Q_2$ form a regular sequence in $S$. I am okay with this part. Now he says that the curve cut out by $Q_1, Q_2$ has degree 4 by Bezout's theorem. I believe I understand this part. The degree of the scheme-theoretic intersection is equal to the product of the degrees (I believe this is what Bezout's theorem says, although I can't find it phrased in these terms), which is 2*2 since we deal with two quadric hypersurfaces. This does not depend on the fact that $Q_1, Q_2$ are a regular sequence. Please correct me if I'm mistaken anywhere here. Now, here is the part I do not understand. ""Since $(Q_1,Q_2)$ is contained in $I$, we must have $(Q_1,Q_2) = I \cap J$ where codim$J > 2$."" Where does this decomposition come from? Finally, he concludes that $J=\emptyset$ since by the Unmixedness Theorem every associated prime of $(Q_1,Q_2)$ has codimension 2. This part again I believe I understand. Can anyone explain the middle part to me? I do not get it at all. Disclaimer: I am not interested in the actual assertion, only the technique of his proof, so while an alternate approach may be edifying, it's not what I'm looking for.","['commutative-algebra', 'algebraic-geometry']"
608458,Hartshorne's definition of structure sheaf,"Hartshorne at page $70$ defines the structure sheaf on Spec $A$. The elements of $\mathcal O_{\textrm{Spec}A}(U)$ are particular functions $s:U\longrightarrow\coprod_{p\in U}A_p$. With the symbol  $\coprod_{p\in U}$ I think he means the coproduct in the category of commutative rings, but in can't figure out what precisely is $\coprod_{p\in U}A_p$ in this case. It is the direct sum of the rings $A_p$? Does the coproduct always exist in the category of commutative rings?","['sheaf-theory', 'commutative-algebra', 'algebraic-geometry', 'schemes']"
608460,Commutativity of a finite group,In a finite group a representative can be chosen from each conjugacy class such that they all commutate. Prove that the group is commutative. Does this still hold true if the group is infinite?,"['infinite-groups', 'finite-groups', 'group-theory', 'abelian-groups']"
608465,Is there a proof for this Fibonacci relationship?,"I was looking at the decomposition of Fibonacci numbers using the definition of $F_n = F_{n-1} + F_{n-2}$, and noted the pattern in the coefficients of the terms were Fibonacci numbers. It appears to hold, and I believe it's true, but I haven't seen a proof for it. Does one exist? $F_n = 1F_{n-1} + 1F_{n-2}$ $F_n = 2F_{n-2} + 1F_{n-3}$ $F_n = 3F_{n-3} + 2F_{n-4}$ $F_n = 5F_{n-4} + 3F_{n-5}$ etc This can be generalized to $F_n = F_xF_{n-(x-1)}+F_{x-1}F_{n-x}$","['fibonacci-numbers', 'sequences-and-series']"
608495,"An infinite $\sigma$-algebra contains an infinite sequence of nonempty, disjoint sets.","I am trying to solve Exercise 3 a) given here . The problem states: Let $\mathcal{M}$ be an infinite $\sigma$-algebra. Prove that
  $\mathcal{M}$ contains an infinite sequence of nonempty, disjoint
  sets. (Hint: if $\mathcal{M}$ contains an infinite sequence of
  strictly nested sets, then we’re done, so assume that no such sequence
  exists. Next, use this assumption to find a nonempty set in
  $\mathcal{M}$ with no nonempty proper subsets in $\mathcal{M}$.
  Finally, show that this can be done infinitely many times.) Here's my idea: Let's say $\mathcal{M}$ is $\sigma$-algebra on the set $X$. If $\mathcal{M}$ does not contain an infinite sequence of strictly nested sets, then given any $A\in\mathcal{M}$, every strict chain starting with $A$ must terminate after finite time: i.e. $A\subsetneq E_{1}\subsetneq E_{2}\subsetneq … \subsetneq E_{k}$ and there is no set $X\neq B\in\mathcal{M}$ such that $E_{k}\subsetneq B$. But then the complement $E_k^{c}$ has no nonempty proper subsets in $\mathcal{M}$. But I am having trouble showing that the process can repeated infinitely many times. I have been stuck with this for the whole day, and it is driving me crazy! Thanks for the help!","['measure-theory', 'real-analysis']"
608539,Smallest graph possessing a property,"I was studying about Almost self-centered graphs . http://link.springer.com/article/10.1007%2Fs10114-011-9628-3 My doubt is what would be the minimum number of vertices for such graphs. My idea: I think its 4 and the graph that satisfy this condition is $P_4$ where end vertices are not in the center of $P_4$. Is my solution correct? If not, then kindly give hints or suggestions, thanks. Definition : Almost self-centered (ASC) graphs are introduced as the graphs with exactly two non-central vertices. NOTE : there is another class of graphs known as almost peripheral graphs. Almost peripheral (AP) graphs are introduced as graphs G with |P(G)| = |V (G)|−1 (and |C(G)| = 1). I think $P_3$ is AP graph","['graph-theory', 'discrete-mathematics', 'combinatorics']"
608553,Help on basic set theory question.,"Prove or Disprove: For every two sets $A$ and $B$, $(A\cup B)-B=A$. I believed it was true, so first I showed that $(A\cup B)-B$ is a subset of $A$. My question is how do I prove that $A$ is a subset of $(A\cup B)-B$? What I have first is what follows: Suppose there exists an arbitrary element $x$ in $A$.
If $x$ is in $A$, then $x$ is not in $B$ From here, I'm stuck.",['elementary-set-theory']
608567,Geometric Series,"The first term in a geometric series is 4 and the sum of the first three terms is 64. Find the sum of the first eight terms of the series. I know the a value is 4, but I'm unsure of how to find the r value. This is what i have tried: $a+ ar+ ar^2 = 64$ $4r^2+4r-60=0$ This doesn't give an integer answer, so i doubt that it is the r value. Any hints as to where i went wrong?","['quadratics', 'sequences-and-series']"
608577,Branch cut problem,"I am looking at the text by G. K. Batchelor, An Introduction to Fluid Dynamics, pg. 428-9. I am looking at the inverse mapping of $z = \zeta + \frac{\lambda^2}{\zeta}$ given by $$\zeta=\frac{1}{2}\left(z+(z^2-4\lambda^2)^{\frac{1}{2}}\right),$$
as we wish $\zeta$ ~ $z$ as $|z|\rightarrow \infty$. Now assuming $|z|>\lambda$, this maps a circle into an ellipse. Batchelor says "".. the value of $(z^2-4\lambda^2)^{\frac{1}{2}}$ is made unique here by specifying that there is a 'cut' in the $z$-plane at $-2\lambda \leq x \leq 2\lambda$, $y=0$ and the relevant branch is that which it is positive at $x>2\lambda$, $y=0$ (the negative branch of $(z^2-4\lambda^2)^{\frac{1}{2}}$ being that needed for the mapping of the region of the $z$-plane outside the ellipse on to the region of the $\zeta$-plane inside the circle $|\zeta|=c$). "" I have not studied branch points and branch cuts before. I think I understand that the branch points occur at $z=-2\lambda$ and $z=2\lambda$, and the branch cut that joins those is chosen. However, I do not really understand what is meant in bold. Any insight or suggested reading would be appreciated. I have noticed when using this inverse mapping it is only valid in the positive real half-plane in the $z$-plane outside of the ellipse and I think this relates.","['branch-cuts', 'complex-analysis']"
608592,An interesting integral $I = \int\limits_{-1}^{1} \arctan(e^x)dx $,"I solved this interesting integral online:
$$I  = \int\limits_{-1}^{1} \arctan(e^x)dx $$
Now I tried the substitution $u=e^x$ but it lead me nowhere.  I was looking at the following post which was solved in a beautiful way Integrate $\int_0^{\pi/2} \frac{1}{1+\tan^\alpha{x}}\,\mathrm{d}x$ . From there I found this very interesting article http://www.maa.org/sites/default/files/pdf/mathdl/CMJ/Nelsen39-41.pdf which has the integral I posted at the end as a question to the reader. Looking at the graph of $\arctan(e^x)dx$ on the interval $-1 \leq x \leq 1$ I conjectured that $I=\frac{\pi}{2}$. I used the following method to prove it:
\begin{eqnarray}
-e^{-x}&=&\frac{-1}{e^x}\\&=& \frac{-1}{\tan\{   \arctan(e^x)  \} }\\&=&-\cot\{ \arctan(e^x) \}\\
&=& \tan \left\{\arctan(e^x)-\frac{\pi}{2} \right\}\\
\end{eqnarray}
For the last equality I used the fact that $\cot(\theta) =-\tan\left(\theta -\frac{\pi}{2}\right) $. Now we take the arctan of both sides to obtain:
$$\arctan(-e^{-x}) = \arctan(e^x)-\frac{\pi}{2}$$ Finally I use the fact that $\arctan(-\theta)=-\arctan(\theta)$ and add $\frac{\pi}{4}$ to both sides of the last equation to obtain:
$$-\arctan(e^{-x})   +\frac{\pi}{4}= \arctan(e^x)-\frac{\pi}{4} $$
So it is established that the function $f(x) = \arctan(e^x)-\frac{\pi}{4}$ is an odd function. Thus
$$I_2  = \int\limits_{-1}^{1}  \left[ \arctan(e^x)-\frac{\pi}{4} \right]dx = 0 $$
Now $$I =  \int\limits_{-1}^{1} \arctan(e^x)dx  = I_2 +  \int\limits_{-1}^{1} \frac{\pi}{4}dx =\frac{\pi}{2} $$
I thought this integral was really interesting and I was wondering if anyone else has any different ways of solving it, possibly with a clever substitution. I was especially amazed at how easily it could be solved because integrals with arctan usually give me a lot of trouble. Also, I think we can extend this to a broader result where we replace $x$ by any arbitrary odd function $g(x)$ and show that 
$$I  = \int\limits_{-a}^{a} \arctan(e^{g(x)})dx = \frac{a \pi}{2}$$
for any odd function $f(x): (-a,a) \to\Bbb R$. Essentially the proof for this would follow the exact same reason as above right? So if anyone has another method of computing the original integral I am definitely interested in reading your solutions! Thanks in advance for any input and ideas! Also thanks to Ron Gordon for his nice answer on the question I linked, the answer given there inspired me to look for different ways of trying to solve this integral that I normally would have given up on.","['definite-integrals', 'integration']"
608618,Limit composition,"If I am given the following graph, how do I compute the limit of x->2 of f(f(x))? I tried to "" compose "" the limits, but lim x->2 f(x) is 1, but then f is not continuous at 1, so the limit DNE? Is that right?",['calculus']
608625,How does $\sin(x-2\pi) = \sin(x)$?,How does $\sin(x-2\pi) = \sin(x)$? Is it so that you can split $\sin(x-2\pi)$ into $\sin(x) - \sin(2\pi)$ and that equals $\sin(x) - 0 = \sin(x)$? Please help. Thank you,"['trigonometry', 'algebra-precalculus']"
608636,Why do equations with two distinct variables with 2 distinct linear equations work?,"My question is about basic algebra. I am thinking about the ""why"" here and I'm looking for an intuitive answer. If you have the following equations: $$S + U = 90$$
    and
$$40S + 25U = 2625$$ you can then rewrite $S = 90 - U$ and then substitute. Now you have a single equation with one variable: $$\begin{align*}
40(90 - U) + 25& = 2625 \\
    3600 - 40U + 25U& = 2625 \\
                -15U& = -975 \\
                   U& = 65
\end{align*}$$ What's going on here? Ultimately, why does this always solve out? I realize single equations with one variable solve (there's gotta be some number that satisfies this equation), but why? What's going on? I guess by solving the equation, we're bypassing this iterative process of trial and error of plugging in numbers and seeing if it equals 2625? Is that what ""solving the equation"" really means?","['linear-algebra', 'algebra-precalculus']"
608637,Proof of solid angle theorem,"I have a homework problem to prove about the solid angle. The book says: Let S be a smooth parametric surface and let P be a point such
  that each line that starts at P intersects S at most once. The solid angle Ω(S) subteded by S at P is the set of lines starting at P and passing through S . Let S(a) be the
  intersection of Ω(S) with the surface of the sphere with center P and radius a . Then the measure of the solid angle (in steardians )
  is defined to be $$ |Ω(S)| = \frac{\text{area of }S(a)}{a^2}$$ Apply the Divergence Theorem to the part of Ω(S) between S(a) and S to show that $$ |Ω(S)| = \iint_S \frac{\mathbf r \cdot \mathbf n}{r^3} dS$$ where r is the radius vector from P to any point on S , r = r , and the unit normal vector n is directed away from P . First let me say that it is O.K. for me to ask for some help here according to my university rules. I try to do this problem but have some questions. First, problem says it is the set of lines starting at P but should this be rays ? It seems to me like in the case of a sphere there would be no lines that start at P and intersect the sphere at most once if the point is inside the circle, because each line can go in to directions. So I assume it is rays. After that I have some questions like, how am I supposed to calculate the area of S(a) ? I know that the area of S(a) is equal to $\iint_{S(a)} dS$ but I have to get that as an integral of S , not S(a) . I had the idea that because I know it intersects at most once I could map each point on S onto S(a) , but I don't know how to do that. I thought maybe could just divide by the radius of the sphere a but that clearly doesn't work. I think this is an interesting problem and could be fun to solve but I don't know where to start. Could you please give a hint -- NOT the whole answer? By the way this is Stewart's Calculus 7e on page 1163, the ""Problems Plus"" problem #1. Sorry for my bad English and thanks in advance! :) EDIT I have seen on Wikipedia ( http://en.wikipedia.org/wiki/Solid_angle ) that it says $$Ω = \iint_S \frac{\mathbf r \cdot \hat n}{r^3} dS$$ which means that this is correct, but it does not say how the proof works. It says ""can be calculated as the surface integral"" but does not explain how ""can be calculated"" is true. Could someone elaborate here?","['multivariable-calculus', 'solid-angle']"
608646,How many 6-letter words that have either exactly 2 vowels or 4 vowels are there? (all lower case),"I considered two cases. Case 1 (2 vowels): Pick 2 vowels $\binom{5 + 2 -1}{2}$, then pick 4 consonants $\binom{21 + 4 -1}{4}$, then order them $6!$. Case 2 (4 vowels): Pick 4 vowels $\binom{5 + 4 -1}{4}$, then pick 2 consonants $\binom{21 + 2 -1}{2}$, then order them $6!$. Total:  $\binom{5 + 2 -1}{2} \binom{21 + 4 -1}{4} 6! +\binom{5 + 4 -1}{4} \binom{21 + 2 -1}{2} 6!$ But then I realized I couldn't do the factorial step because I could have the same vowels/consonants appearing more than once so I would be over counting their order. How can I clear this up? Is there an alternative way I can go about this? Thanks!",['combinatorics']
608651,Prove $Y_n:=\sup|\hat{F}_n(x)-F(x)|$ is a reverse submartingale,"Suppose $\{X_j,j \ge 1\}$ are iid with common distribution $F$ and let $\hat{F}_n$ be the empirical distribution based on $X_1,\dots,X_n$. Show $$Y_n:=\sup|\hat{F}_n(x)-F(x)|$$ is a reverse submartingale. Hint: Consider first  $\{\hat{F_n}-F(x), n \ge 1\}$, then take absolute values, and then take the supremum over a countable set. Above is the problem. I think we should use $$\hat{F}_n(x)=\frac{1}{n}\sum 1_{\{X_i \le x \}}.$$ But I could not find a proper $B_n$ s.t. $E(\hat{F}_n(x)|B_{n+1})=\hat{F}_{n+1}(x)$.","['probability-theory', 'martingales']"
608652,How to find closed form formula for a sum,"I am a PhD student in electrical engineering. I need to find a closed form formula for the following series:
$$\sum_{k=1}^{\infty}\frac{1}{2}A_k^2e^{-k^2\sigma_m^2}(e^{k^2\sigma_m^2}-1)$$where $A_k= \frac{4\sin(\frac{\pi}{2}k)}{\pi k}$ and $\sigma_m^2$ is a constant.
This is a very important result if I can find it. Thanks a lot.","['residue-calculus', 'sequences-and-series', 'cauchy-sequences']"
608670,"Construct a complete metric on $(0,1)$","Can anyone construct a complete metric on $(0,1)$ which induces the usual subspace topology on $(0,1)$ ?","['general-topology', 'metric-spaces']"
608671,The $i$-th center $Z_{i}(G)$,"Let $H$ be a normal subgroup of a $p$-group $G$, $H$ is of order $p^i$. Prove that $H$ is contained in the $i$-th center $Z_{i}(G)$. Recall that we define $Z_{0}(G)=1$, and for $i>0$, $Z_{i}$ is the subgroup of $G$ corresponding to $Z(G/Z_{i-1})$ by the Correspondence Theorem: $Z_{i}/Z_{i-1}=Z(G/Z_{i-1})$ The sequence of subgroups $Z_{0}\subset Z_{1}\subset Z_{2}\subset\ldots$ is called the upper central series of $G$ I use induction on $i$ and consider $G/Z(G)$. The case $i=0$ is trivial ($H=1$ and $Z_{0}(G)=1$). How should I continue the proof? Thanks for any insight.","['p-groups', 'group-theory', 'abstract-algebra']"
608676,Question about the Irwin-Hall Distribution (Uniform Sum Distribution),"So I have been reading about the Irwin-Hall distribution online, it is a sum of uniform distributions on $[0,1]$, and it seems very interesting: http://en.wikipedia.org/wiki/Irwin%E2%80%93Hall_distribution On the Wikipedia article above they derive pdf for the special cases n = 1,2,3,4, and 5. 
n = 1 is trivial, for n = 2 we are drawing points from a square $U_1 \times U_2$. Then we compute the probability of picking points under a line in that square, take its derivative and then derive the triangular distribution. For n = 3, we are drawing points from the cube $U_1 \times U_2 \times U_3$ and compute the probability of picking points under a plane and can intuitively see the parabolic distribution (since the volume under the plane on the cube will be of third degree, then we takes its derivative to get pdf). In general we see the pdf will have n pieces with each piece of degree k-1. My question here is deriving the formulas for the n = 3,4,5 case don't seem easy as they are shown in the Wikipedia article, what would be the approach to get the equations? Secondly, intuitively we would think due to the central limit theorem that this distribution approaches the normal distribution, but they give a general version of the pdf in the Wikipedia article, and I don't see how that is going to converge to the normal distribution. For n = 3, I know how to get pdf when $x \in [0,1]$ and $x \in [2,3]$, but not sure about when $x \in [1,2]$.","['uniform-distribution', 'probability-theory', 'normal-distribution', 'probability-distributions', 'probability']"
608681,Hartshorne's t functor,"Hartshorne (II Prop 2.6) defines a functor $t$ from the category of topological spaces to itself as follows: If $X$ is a topological space, define $t(X)=\{Z\subseteq X:Z\text{ is irreducible and closed}\}$. Assign $t(X)$ the topology with closed sets given by $t(Y)$ where $Y$ is a closed subset of $X$. If $f\colon X_1\to X_2$ is continuous, define $t(f)\colon t(X_1)\to t(X_2)$ by $t(f)(Z)=\overline{f(Z)}$. (See the question Hartshorne proposition II(2.6) for more details). Finally, he defines a function $\alpha\colon X\to t(X)$ (which one can easily show is continuous) by $\alpha(P)=\overline{\{P\}}$. My question is concerning Abramo's answer to the above-linked question, namely that $\alpha(U)=t(X)-t(Y)$ for any open subset $U=X-Y$ of $X$. I seem to have produced a counterexample to this, and I was hoping that someone might point out where I messed up: Let $X$ be the nonnegative integers with closed subsets given by $[n]=\{0,1,\ldots,n-1\}$ for $n\geq0$ and of course $X$ itself. Notice that each of these closed sets is irreducible. In particular, $X$ is irreducible. Now, the closure of any $n\in X$ is the set $[n+1]$, so applying $\alpha$ to $X$, we get
$$ \alpha(X)=\{[1],[2],\ldots\}.$$
On the other hand, 
$$ t(X)-t(\emptyset) = t(X)=\{[1],[2],\ldots\}\cup \{X\}.$$
So, $t(X)-t(\emptyset)\neq \alpha(X)$. In fact, this shows that $\alpha(X)$ isn't even open, since  $t(X)-\alpha(X)=\{X\}$ isn't closed (if $t(Y)=\{X\}$ for some closed $Y\subseteq X$, then $X\subseteq Y\subseteq X$, i.e. $Y=X$, a contradiction).",['algebraic-geometry']
608693,Using $(1+x)^k \approx 1+kx$ to approximate?,"Use the approximation $(1+x)^k \approx 1+kx$ to estimate $(1.0003)^{26}$ and $\sqrt[4]{1.006}$. I know how to solve this step-by-step, but I don't understand what I'm doing exactly: why does $(1+x)^k \approx 1+kx$? $x^k$ is $x \times x \times x \times \dots x\;\;$ a certain $k$ number of times. Where do they get $kx$ from?","['approximation', 'calculus', 'functions', 'estimation']"
608702,Does there exist an analytic function $f$ such that $f(\overline{\mathbb{D}})=\overline{\mathbb{H}}$?,"Does there exist an analytic function $f$, defined in a neighborhood of $\overline{\mathbb{D}}$, such that $f(\overline{\mathbb{D}})=\overline{\mathbb{H}}$ ? where $ \overline{\mathbb{H}} = \{ z \in \mathbb{C} | \ Imz \geq 0\} $ and $\overline{\mathbb{D}} = \{ z \in \mathbb{C} | \ |z| \leq 1\}$. The first thing that comes to my mind is the linear fractional transformation $T(z)=\frac{i-iz}{1+z}$ (is not analytic in any neighborhood of $ \overline{\mathbb{D}}$, right? since we are not considering the Riemann sphere, or equivalently $f'(-1)=\infty \notin  \overline{\mathbb{H}}$). But using this or any other linear fractional transformation you have to map the unit circle onto the real line, hence one point , say $z_0$ on the unit circle gets mapped to $\infty$; therefore $ f(z_0) \notin  \overline{\mathbb{H}}$. Is it correct that no linear fractional transformation can do the job ?
How can we show that such a map does not exist ? Any hint or idea is appreciated.",['complex-analysis']
608705,"If $f$ and $g$ are Riemann integrable, are $f\cdot g$ and $f/g$ Riemann integrable?","I do not think they are, but I cannot seem to come up with a definitive answer. I have tried using the ""Cauchy criterion"" for integrability $$U(f,P)-L(f,P)<\varepsilon$$ Here, $U(f,P)$ is the upper Darboux sum and $L(f,P)$ is the lower Darboux sum. For $f\cdot g$ , I have tried using $$U(f,P)-L(f,P)<\sqrt\varepsilon$$ $$U(g,P)-L(g,P)<\sqrt\varepsilon$$ But I am not getting anywhere. I am not quite sure what to do for the $\frac{f}{g}$ . Edit: For $\frac{f}{g}$ , $g\neq0$","['integration', 'real-analysis']"
608707,Prove that $C = f^{-1}(f(C)) \iff f$ is injective and $f(f^{-1}(D)) = D \iff f$ is surjective,"Let $f:A\rightarrow B$ be a function, $C\subseteq A$, $D\subseteq B$ then prove: $C = f^{-1}(f(C)) \iff f$ is injective $f(f^{-1}(D) = D \iff f$ is surjective For both equivalences, I have difficulties proving the right implications (proving that $f$ is injective for the first equivalence and proving that $f$ is surjective for the second). I found a proof of the second right implication (proving that $f$ is surjective) that I can't understand. The proof is as follows: ""Let $y\in D$, consider the set $D=\{y\}$. Then $f(f^{-1}(\{y\}))=\{y\}$ wich implies $y\in f(f^{-1}(\{y\}))$, this is, $y=f(x)$ for an element $x\in f^{-1}(\{y\})\subseteq A$. This proves that $f$ is surjective."" Would appreciate an explanation of this last proof, helpful hints or proofs of these implications. Thank you beforehand. For the left implications I proved the equalitiess by proving that $P\subseteq Q$ and $Q\subseteq P$ (then $P=Q$). There are 2 inclusions that do not need $f$ to be injective or surjective where I have no difficulties proving: $C \subseteq f^{-1}(f(C))$ $f(f^{-1}(D) \subseteq D$ This means the other 2 inclusions must use the premise of $f$ being injective or surjective. I have proved successfully that $f(f^{-1}(D) \supseteq D$ using the that $f$ is surjective. But when proving $C \supseteq f^{-1}(f(C))$ I didn't use the $f$ is injective so something must be wrong. Proof is as follows: Let $a\in f^{-1}(f(C))$ $\implies f(a) \in f(C)$ $\implies \exists a\in C: f(a)=b$ Where must I use the premise of $f$ being injective?",['functions']
608721,How to show that $g$ attains maximum at $0$ or $1$,"Suppose $f:[0,1]\to\mathbb{R}$ is continuous，define $$g:[0,1]\to\mathbb{R},\quad g(x):=\int_0^1|f(t)-x|dt$$ Show that $g$ attains maximum at $0$ or $1$. I don't know how to approach, any hints?","['calculus', 'integration', 'real-analysis']"
608727,"Prove that $2^n\alpha-[2^n\alpha]$ is dense in [0,1]","Prove that $2^n\alpha-[2^n\alpha]$ is dense in $[0,1]$, if $\alpha$ is a positive irrational number. $[x]$ represents the largest integer smaller than $x$. I only know how to prove $n\alpha-[n\alpha]$ is dense in $[0,1]$, using pigeon hole principle. I am looking for similar method to solve this problem.",['real-analysis']
608750,An inequality with infinite sum,"If $p>1$, and $k$ is a positive integer more than $1$, show that $$\sum_{n=2}^{\infty}\frac{(\ln n)^k}{n^p} \le \frac{k!}{(p-1)^{k-1}}$$ At first, I thought many ideas such as Cauchy-Schwarz inequality, Taylor expansion, Induction on k, etc.. But they does not work efficiently.....","['sequences-and-series', 'calculus']"
608763,Volume of the first octant under a surface,"Find the volume of the first octant region under the surface $\sqrt{x}+\sqrt{y}+\sqrt{z}=1$ I think that the integral should be: $$\int_{0}^1\int_{0}^{\left(1-\sqrt x\right)^2}\int_{0}^{\left(1-\sqrt x -\sqrt y\right)^2}\,dz\,dy\,dx$$ Could someone tell me if this is correct?",['multivariable-calculus']
608799,Arzela-Ascoli net question,"Let $X$ be a compact metric space. Let $C(X)$ denote the space of real-valued continuous functions on $X$ . A commonly given corollary to the Arzela-Ascoli theorem is: Proposition: If $f_n$ is an equicontinuous sequence in $C(X)$ converging pointwise to $f \in C(X)$ , then actually $f_n \to f$ uniformly. In order to prove this, I first proved a simple lemma Lemma: Suppose $x$ is a point and $S$ is a sequence in a compact metric space $M$ .  If every convergent subsequence of $S$ converges to $x$ , then $S$ converges to $x$ . Proof: Suppose for contradiction that $S$ does not converge to $x$ . Then, there is a subsequence $S'$ of $S$ whose terms are bounded away from $x$ .  Being a sequence in a compact metric space, $S'$ has a convergent subsequence $S''$ . Since $S''$ is a convergent subsequence of $S$ , it converges to $x$ by hypothesis. But, this is impossible since the terms of $S'$ should be bounded away from $x$ . which is applied as follows. Proof of proposition: Let $M$ be the uniform closure of $\{f_n : n \in \mathbb{N} \} \cup \{f\}$ . By the Arzela-Ascoli, $M$ is compact for the uniform norm. Consider now $f_n$ as a sequence in $M$ . Any subsequence of $f_n$ which converges uniformly must converge to $f$ (since $f_n \to f$ pointwise). So, by the lemma, $f_n \to f$ uniformly. What I am slightly unsure of is whether these arguments carry over, mutatis mutandis, for nets? Question: If $X$ is a compact metric space, $C(X)$ is the space of real-valued continuous functions on $X$ , and $f_i$ is an equicontinuous net in $C(X)$ converging pointwise to $f \in C(X)$ , does $f_i \to f$ uniformly? I think the answer is yes, but I am not totally comfortable with the concept of a subnet, so it is difficult to be certain. Edit : Thinking about it more, it seems the point requiring clarification is the following one. Claim: If a net $(x_i)_{i \in I}$ in a metric space $M$ does not converge to a point $x \in M$ , then there is a subnet that is bounded away from $x$ . That is, there is an $\epsilon > 0$ and a cofinal, increasing function $\varphi : J \to I$ out of a directed set $J$ such that $d( x_{\varphi(j)}, x) \geq \epsilon$ for all $j \in J$ . Since $(x_i)$ does not converge to $x$ above, we know there exists an $\epsilon >0$ such that, for all $i_0 \in I$ , there exists $i \geq i_0$ with $d(x_i,x) \geq \epsilon$ . To find a subnet, it seems the obvious thing to do is try $J = \{ i \in I : d(x_i,x) \geq \epsilon\}$ and $\varphi$ the inclusion. Now, the above condition says exactly that $J$ is cofinal in $I$ . And, obviously the inclusion map is increasing... so I guess that settles things? Edit 2: I guess in my first edit I forgot to verify that $J$ was, itself, a directed set. But it seems a cofinal set $J$ in a directed set $I$ is automatically a directed set. Any finite subset of $J$ has an upper bound in $I$ , which has then an upper bound in $J$ .","['nets', 'compactness', 'functional-analysis', 'real-analysis']"
608828,Prove $1 + \cot^2\theta = \csc^2\theta$,"Prove the following identity:
$$1 + \cot^2\theta = \csc^2\theta$$ This question is asked because I am curious to know the different ways of proving this identity depending on different characterizations of cotangent and cosecant.","['trigonometry', 'alternative-proof']"
608832,Showing a sequence convergence,"Let $a_1,a_2>0$ and $a_{n+1}=\cfrac{2}{a_{n-1}+a_{n}}(n\ge2)$, How to prove $a_n$ is convergent?","['calculus', 'real-analysis', 'limits']"
608834,Vector representation of a line,"I was reading through a geometry book for computer vision and it presented that the homogeneous representation of lines is $$ax+by+c =0 \Leftrightarrow (a,b) \neq 0$$ But then they introduced an example that says Consider the two lines $x=1$ and $x=2$. Here the two lines are parallel and consequently intersect ""at infinity"". In homogeneous notation the lines are $l=(-1,0,1),\ l'=(-1,0,2)$. how do they get the values of $a$, $b$, and $c$ given the equations $x=1$ and $x=2$ ?",['geometry']
608837,Laplace's Equation with Neumann BC,"Hi fellow math enthusiasts, I am currently working on some research to do with the electric field induced within the
brain via magnetic stimulation. I am trying to solve the partial differential equation in 2D cartesian co-ordinates \begin{equation}
\nabla \cdot \underline{\sigma} \vec{\nabla}\phi = - \nabla \cdot  \left(\underline{\sigma} \frac{\partial \vec{A}}{\partial t}\right)
\end{equation} For a magnetic vector potential of $\vec{A}=-\frac y2 \hat{i}+\frac x2\hat{j}$ and the magnetic vector potential can be separated so the function of time does not need to be known. From above this can be written as $$
\sigma_x\frac{\partial^2\phi}{\partial x^2}+\sigma_y\frac{\partial^2\phi}{\partial y^2}=0
$$
and after a change of variables $\gamma=\left(\frac{\sigma_x}{\sigma_y}\right)^{\frac12}y$ revels Laplace's equation
$$
\frac{\partial^2\phi}{\partial x^2}+\frac{\partial^2\phi}{\partial \gamma^2}=0
$$
The surface to which Laplace's equation is to be solved in is the rectangle bounded by the lines $x=a,\ x=-a$ and $y=b,\ y=-b$ subject to Neumann boundary conditions 
\begin{align}
\left.\frac{\partial\phi}{\partial x}\right|_{x=a}&=\frac y2 \quad &\left.\frac{\partial\phi}{\partial x}\right|_{x=-a}&=\frac y2\\
\left.\frac{\partial\phi}{\partial y}\right|_{y=b}&=-\frac x2 \quad &\left.\frac{\partial\phi}{\partial y}\right|_{y=-b}&=-\frac x2  \\
\end{align}
Which cannot be solved although my math prof. said that since it is a linear PDE, each boundary condition can be solved independently with the other three Neumann BC set to zero and the final answer is a linear combination of the four solutions. Which I have tried to no avail. Any thoughts? Thank you","['multivariable-calculus', 'differential-geometry', 'partial-differential-equations', 'boundary-value-problem', 'harmonic-functions']"
608857,Relation between linear maps and matrices,"I've been reading Axler's ""Linear Algebra Done Right"", and have learned more about linear operators/ maps, but I'd like to make sure that I understand how to properly relate this information to matrices. First, any $m \times n$ matrix with entries in a field $F$ uniquely determines a linear transformation $T: F^n\to F^m$ by $(x_1,...,x_n)\mapsto (\sum_{j=1}^{n}a_{1j}x_j,...,\sum_{j=1}^{n}a_{mj}x_j)$, and if $T:V\to W$ is a linear map between finite dimensional vector space $V$ and $W$ over field $F$ and we fix a basis $B_1$ in $V$ and $B_2$ in $W$, with $dim(V)=n$ and $dim(W)=m$, then $M(T)$ (function that maps $T$ to its matrix with respect to $B_1$ and $B_2$ by the procedure outlined above) is an isomorphism between $L(V,W)$ (vector space of linear maps between $V$ and $W$) and $M$ at $(m,n,F)$ (vector space of $m \times n$ matrices with entries in $F$). QUESTIONS 1.) If I'm given a matrix with entries in $F$, how exactly would I go about determining information about it from linear maps? For example, suppose that i'm given an $n \times n$ matrix $A$ where $n$ is odd. I know that if $T$ is an operator on an odd-dimensional vector space $V$, then $T$ has an eigenvalue. Since $T$ can be any operator on any odd-dimensional vector space, can I just pick $V=F^n$? Then I could say that $A$ represents a unique linear transformation $T:F^n\to F^n$ by the assignment above, and since $T$ has an eigenvalue, $A$ must also have (the same) eigenvalue (since $T$ and $A$ are the same transformation on $F^n$)? Furthermore, if I assume the standard basis for $F^n$, then there is no other such matrix ($m \times n$ and entries in $F$) that represents the particular operator that $A$ does, and every possible operator on $F^n$ is represented by a matrix in $M$ at $(n,n,F)$. Is this all correct? Would similar arguments apply to invertibility, similarity, etc. ? 2.) Since an $m \times n$ matrix $A$ with entries in $F$ represents a unique linear map $T: F^n\to F^m$, and since finite dimensional vector spaces with the same dimension are isomorphic, can't I also interpret $A$ as representing a unique linear map $T: V\to W$, where $V$ and $W$ are any vector spaces over $F$ s.t. $dim(V)=n$ and $dim(W)=m$?","['matrices', 'linear-algebra']"
608863,Find asymptotics for solution $x$ of $(x+1)^{\frac{n+1}{n}}-x^{\frac{n+1}{n}}=5$,"It is easy to see that for any $n\geq 1$, the equation
$(x+1)^{\frac{n+1}{n}}-x^{\frac{n+1}{n}}=5$ has a unique positive
solution ; call it $x_n$. Is there a simple asymptotic formula for $x_n$ ? I tried unsuccessfully
  to find one, and computed that $$
 \lfloor x_3 \rfloor=53, \
  \lfloor x_4 \rfloor=256, \
   \lfloor x_5 \rfloor=1256, \
   \lfloor x_6 \rfloor=6195, \
   \lfloor x_7 \rfloor=30678, \
   \lfloor x_8 \rfloor=152243, \ 
 $$ It seems that the sequence $(\frac{x_{n+1}}{x_n})$ is increasing
and converges to $5$.","['asymptotics', 'sequences-and-series', 'real-analysis']"
608875,How find this equation,"solve this equation
$$\sqrt{\sqrt{3}-\sqrt{\sqrt{3}+x}}=x$$ My try: since
$$\sqrt{3}-x^2=\sqrt{\sqrt{3}+x}$$
then
$$(x^2-\sqrt{3})^2=x+\sqrt{3}$$",['algebra-precalculus']
608885,$X\in \mathfrak{g}$ means flow commutes with left-translation,"Suppose $X\in \mathfrak{g}$ is a left invariant vector field on a Lie group G. In this article it mentions that The fact that our vector fields satisfy $L^*_gX = X$ implies that the
  flow commutes with left-translation: $\Phi_t\circ L_g = L_g \circ
 \Phi_t$. It makes intuitive sense to me why this would be true, but I can't seem to formulate it.  Let $h\in G$, then we want to show $\Phi_X^t(L_g(h)) = g\cdot \Phi^t_X(h)$. We have $X_{h} = X_{L_{g^{-1}}(gh)}= L_{g^{-1}}^*(X_{gh})$, but now I am getting lost again...","['lie-groups', 'differential-geometry', 'vector-fields']"
608889,The Helmholtz equation: How prove this $T\psi{(x)}\in\Omega$.,"Let $\Omega\subset  R^2$  be a simply connected
bounded domain with inﬁnitely diﬀerentiable boundary  $\partial\Omega$and unit normal
vector $v$ directed into the exterior of $\Omega$
$$\Phi{(x,y)}=\dfrac{i}{4}H^{(1)}_{0}(k|x-y|),x\neq y$$
we denote the fundamental solution to the two-dimensional Helmholtz equation in terms of the ﬁrst kind Hankel function of order zero where
the  Helmholtz equation
$$\Delta u+k^2u=0, \mbox{in}   R^2\overline{\Omega}$$
and 
$$(T\psi)(x):=\dfrac{\partial}{\partial v(x)}\int_{\partial\Omega}\dfrac{\partial\Phi{(x,y)}}{\partial v(y)}\psi{(y)}ds(y),x\in\partial\Omega.$$ show that:
  $$(T\psi)(x)=\dfrac{\partial}{\partial s(x)}\int_{\partial\Omega}\Phi{(x,y)}\dfrac{\partial \psi}{\partial s}(y)ds(y)+k^2v(x)\cdot\int_{\partial \Omega}\Phi{(x,y)}v(y)\psi{(y)}ds(y),x\in\partial\Omega $$ This relusut is from this paper: http://num.math.uni-goettingen.de/kress/kress2013.pdf The author say can in [12], http://link.springer.com/article/10.1007%2FBF02941090#page-1 Now I find this paper,because I don't know french,so  I'm not sure  this is the proof, if someone understand this proof, can you  explain it  to me.
 thank you very much. Thank you This follow  picture is from [12]","['partial-differential-equations', 'analysis']"
608898,A light beam enters a closed room. What is the maximal number of reflections?,"I have the following problem: a light beam enters a mirror room with integer coordinates in the plane (consider it as a polygon). One of the walls of the room is removed and the light beam enters the room. The initial (not reflected) beam is defined by two points with integer coordinates. It enters the rooms, reflects a number of times and exits the room. 
The goal is to maximize the ratio $$\dfrac{\text {number of reflections}}{\text {number of sides of the room}}$$ All coordinates should be in the range $[0, 50]$. Can you give me any hints or references to previous work on this problem.
Thanks in advance!","['geometry', 'reflection', 'open-problem', 'physics']"
608908,Prove homotopic attaching maps give homotopy equivalent spaces by attaching a cell,"Prove: If $f,g:S^{n-1} \to X$ are homotopic maps, then $X\sqcup_fD^n$ and $X\sqcup_gD^n$ are homotopy equivalent. I think it can be proved by showing they are both deformation retracts of $X\sqcup_H(D^n\times I)$ where $H$ is the homotopy between $f$ and $g$. However, I have difficult in proving that the deformation retracts are continuous map. In fact, I have difficulty in representing a map in quotient spaces like $X\sqcup_fD^n$. I think a map from $X\sqcup_fD^n$ to $W$ can be represented by two maps: $m_1: X\to W$, $m_2: D^n\to W$, where for $x\in S^{n-1}$, $m_1\circ f(x)=m_2\circ i(x)$. Then I construct the deformation retract this way: $m_1: X\to X$. For $x\in H(S^{n-1},t)$, $m_1(x)=H(S^{n-1},0)$, otherwise $m_1(x)=x$. $m_2: D^n\times I\to D^n\times {0}$: $m_2((D^n,t))=(D^n,0)$. It is easy to verify that $m_1$ and $m_2$ define a map from $X\sqcup_H(D^n\times I)$ to $X\sqcup_fD^n$. As long as this is a continous map, obvioulsy then we find a deformation retract. But it seems such a map is not continous?","['general-topology', 'homotopy-theory', 'algebraic-topology']"
608909,Solution of the equation $\left(x+\frac{1}{x}\right)^{\frac{1}{x}}=A$,"Is it possible to solve analytically the following equation?
$$\left(x+\frac{1}{x}\right)^{\frac{1}{x}}=A$$
with $A\gt 1$? I tried to transform it in the following:
$\frac{1}{x}\ln\left(x+\frac{1}{x}\right)=B$ with $B=\ln(A)$, but it seems to be still unsolvable. Is there some trick to solve it? Thanks.",['algebra-precalculus']
608919,"Is it true that if $f(x)$ has a linear factor over $\mathbb{F}_p$ for every prime $p$, then $f(x)$ is reducible over $\mathbb{Q}$?","We know that $f(x)=x^4+1$ is a polynomial irreducible over $\mathbb{Q}$ but reducible over $\mathbb{F}_p$ for every prime $p$ . My question is: Is it true that if $f(x)$ has a linear factor over $\mathbb{F}_p$ for every prime $p$, then $f(x)$ has a linear factor over $\mathbb{Q}$? Edit: Thanks for @Jyrki Lahtonen's answer, I want to do some modifications: Is it true that if $f(x)$ has a linear factor over $\mathbb{F}_p$ for every prime $p$, then $f(x)$ is reducible over $\mathbb{Q}$? Thanks in advance!","['irreducible-polynomials', 'number-theory', 'abstract-algebra', 'polynomials', 'algebraic-number-theory']"
608920,Hahn–Banach Theorem for Normed Spaces: not unique extension,"Let $\ell^{\infty}$ be the set of bounded sequences in $\mathbb{F}$, with the supremum norm. $c \subset \ell^{\infty}$ the sequences whose limit exists. Then there exists a $f \in (\ell^{\infty})'$, the dual, such that $f(x) = \lim_{n \to \infty} x(n)$ for all $x \in c$. Because we can define it on $c$ and then extend it with the Hahn-Banach theorem for Normed Spaces. My question is if there is another $g \in (\ell^{\infty})'$, $g \not = f$, with $g(x) = f(x) = \lim_{n \to \infty} x(n)$ for all $x \in c$. I tried using two different one-dimensional extensions first but I couldn't finish that proof.
Any ideas? Thanks.",['functional-analysis']
608921,"For sphere $S^2$, the conjugate locus of each any point in $S^2$ reduces to a single point.","The problem is: For sphere $S^2\subset\Bbb{R}^3$, the conjugate locus of each point in $S^2\subset\Bbb{R}^3$ reduces to a single point. I can prove that any point is conjugate to it's antipodal point. But I can't prove that other points aren't conjugate with with each other. Any reference or sketch of proof will be interesting. Thanks in advance. My tries: There's a proposition in my book ( Differential Geometry of Curves and Surfaces Manfredo P. do carmo ) which says: PROPOSITION 5 . Let $p, q \in S$ be two points of $S$ and let $\gamma ':[0,1] \to S$ be a geodesic joining $p = \gamma '(0)$ to $q = \exp_p(l\gamma '(0))$. Then $q$ is conjugate to $p$ relative to $\gamma$ if and only if $v = l\gamma '(0)$ is a critical point of $\exp_p:T_p(S) \to S$. In this way I need calculate $(d \exp_p)_v(w)$ to observe for which $v,w$ we have $(d \exp_p)_v(w)=0$.","['reference-request', 'differential-geometry']"
608924,"For this morphism of integral schemes $X\to Y$, if $X$ is geometrically reduced (irreducible) then is $Y$ also geometrically reduced (irreducible)?","Let $k$ be an arbitrary field. Suppose that $C/k$ is an integral curve which is birationally equivalent to a projective line. Is it true that $C$ is geometrically reduced and irreducible? This is of course true if $C$ is a normal, since then $C$ is just isomorphic to some open subset of the projective line. So I guess the above question can be generalized to the following one: Let $X$ and $Y$ be two integral (so both reduced and irreducible)
  schemes of finite type over $\text{Spec }k$ and
  let $X\longrightarrow Y$ be a finite, birational $k$-morphism.
  Suppose that $X$ is
  geometrically reduced (irreducible). Is then $Y$ also geometrically reduced
  (irreducible)?","['algebraic-geometry', 'schemes', 'algebraic-curves', 'commutative-algebra', 'birational-geometry']"
608949,a question about compact tangent bundle,"I have a question about tangent bundles. Is there a compact tangent bundle?
Or what conditions do we need to be sure that tangent bundle of a manifold be compact?","['manifolds', 'vector-bundles', 'differential-geometry']"
608957,Monty hall problem extended.,"I just learned about the Monty Hall problem and found it quite amazing. So I thought about extending the problem a bit to understand more about it. In this modification of the Monty Hall Problem, instead of three doors, we have four (or maybe $n$) doors, one with a car and the other three (or $n-1$) with a goat each (I want the car). We need to choose any one of the doors. After we have chosen the door, Monty deliberately reveals one of the doors that has a goat and asks us if we wish to change our choice. So should we switch the door we have chosen, or does it not matter if we switch or stay with our choice? It would be even better if we knew the probability of winning upon switching given that Monty opens $k$ doors.","['monty-hall', 'probability']"
609012,"How prove this $g(x)=\sup{\{f(x,y)|0\le y\le 1\}}$ is continuous on $[0,1]$","let $f(x,y):[0,1]\times[0,1]\to R$ is continuous real function. show that
$$g(x)=\sup{\{f(x,y)|0\le y\le 1\}}$$ is continuous on $[0,1]$ My try: since $f(x,y)$ is continuous on $D=[0,1]\times [0,1]$, so $f(x,y)$ is Uniformly continuous on $D$,so
$\forall\varepsilon>0$,then exist $\delta>0$,such $|x_{1}-x_{2}|<\delta,|y_{1}-y_{2}<\delta$,then we have
$$|f(x_{1},y_{1})-f(x_{2},y_{2})|<\varepsilon$$
so
$$g(x_{1})-g(x_{2})=|\sup f(x_{1},y)-\sup f(x_{2},y)|<\sup|f(x_{1},y)-f(x_{2},y)|$$ Now maybe follow is not true? $$|\sup f(x_{1},y)-\sup f(x_{2},y)|<\sup|f(x_{1},y)-f(x_{2},y)|$$",['analysis']
