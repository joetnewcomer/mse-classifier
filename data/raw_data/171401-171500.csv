question_id,title,body,tags
3038472,"If $x_1,x_2,\ldots,x_n$ are the roots for $1+x+x^2+\ldots+x^n=0$, find the value of $\frac{1}{x_1-1}+\frac{1}{x_2-1}+\ldots+\frac{1}{x_n-1}$","Let $x_1,x_2,\ldots,x_n$ be the roots for $1+x+x^2+\ldots+x^n=0$ . Find the value of $$P(1)=\frac{1}{x_1-1}+\frac{1}{x_2-1}+\ldots+\frac{1}{x_n-1}$$ Source: IME entrance exam (Military Institute of Engineering, Brazil), date not provided (possibly from the 1950s) My attempt: Developing expression $P(1)$ , replacing the 1 by $x$ , follows $$P(x)=\frac{(x_2-x)\cdots (x_n-x)+\ldots+(x_1-x)\cdots (x_{n-1}-x)}{(x_1-x)(x_2-x)\cdots (x_n-x)}$$ As $x_1,x_2,\ldots,x_n$ are the roots, it must be true that $$Q(x)=(x-x_1)\cdots(x-x_n)=1+x+x^2+\ldots+x^n$$ and $$Q(1)=(1-x_1)\cdots(1-x_n)=n+1$$ Therefore the denominator of $P(1)$ is $$(-1)^{n} (n+1).$$ But I could not find a way to simplify the numerator. Another fact that is probably useful is that $$1+x^{n+1}=(1-x)(x^n+x^{n-1}+\ldots+x+1)$$ with roots that are 1 in addition of the given roots $x_1,x_2,\ldots,x_n$ for the original equation, that is $$x_k=\text{cis}(\frac{2k\pi}{n+1}),\ \ k=1,\ldots,n.$$ This is as far as I could go... Hints and full answers are welcomed.","['contest-math', 'algebra-precalculus', 'complex-numbers']"
3038490,A space obtained by $S^3$ by removing a Hopf link,"If we remove a Hopf link from $3$ -dimensional sphere $S^3$ , can we obtain a space homotopy equivalent to (or deformation retract to) an annulus ? If the answer yes, can we write it explicitly? EDIT: Let $H^+$ denote the positive Hopf link. If we remove $H^+$ from $S^3$ , we obtain a Milnor fibration $\pi_+: S^3-H^+ \to S^1$ given by the rule $(r_1,\theta_1,r_2,\theta_2) \to \theta_1+\theta_2$ , see Etnyre 's note. This gives an open book decomposition of $S^3$ with a page annulus.","['geometric-topology', 'general-topology', 'algebraic-topology']"
3038503,Proving fraction is irreducible,"Example: The fraction $\frac{4n+7}{3n+5}$ is irreducible for all $n \in \mathbb{N}$ , because $3(4n+7) - 4(3n+5) = 1$ and if $d$ is divisor of $4n+7$ and $3n+5$ , it divides $1$ , so $d=1$ . I want to know if there is some general method of finding $x, y \in \mathbb{Z}$ , 
so that $$x(an+b) + y(cn+d) = 1$$ when $(an+b, cn+d) = 1$ , instead of trial and error, or some quicker and easier way (for not so pretty fractions) for determining whether it is irreducible.","['number-theory', 'gcd-and-lcm', 'elementary-number-theory', 'fractions', 'rational-numbers']"
3038516,When a manifold is isometric to a product manifold?,"Let $M$ be a Riemannian smooth manifold of dimension p and $\phi$ a smooth submersion from $M$ to some other smooth manifold $N$ of dimension q. Denote by $\mathcal{F}$ the foliation of leaves $\phi^{-1}(z)$ for $z\in \phi(M)$ . When can we say that $M$ is isomorphic to a product manifold of the form $L\times S$ where $L$ is a leave of $\mathcal{F}$ passing through a point $x_0$ and $S$ is a transversal leave passing through the same point $x_0$ . A classical condition in ([1], Theorem 4.4 section 4.4) says that if $M$ is complete simply connected and if $\mathcal{F}$ is parallel then $M$ is isomorphic to such product manifold. But I don't know what condition $\phi$ should satisfy to ensure that $\mathcal{F}$ is parallel? Are there more general conditions on $\phi$ to ensure that $M$ can be seen as a product manifold? [1] A. Bejancu and H. R. Farran. Foliations and Geometric Structures. Springer Science & Business Media, Jan. 2006. Google-Books-ID: NtqEFj4nYecC.","['foliations', 'riemannian-geometry', 'differential-geometry']"
3038518,Evaluating the integral $\int_0^{\pi/4}\sqrt{1-16\sin^2(x)}\mathop{}\!\mathrm dx$,"How can we evaluate this integral? $$\int_\limits{0}^{\pi/4}\sqrt{1-16\sin^2(x)}\mathop{}\!\mathrm dx$$ I tried a substitution $$u=4\sin x,\quad \mathrm dx=\frac{\mathrm du}{\sqrt{16-u^2}}$$ hence the integration will be $$\int_\limits{u=0}^{u=2\sqrt{2}}\frac{\sqrt{1-u^2}}{\sqrt{16-u^2}}\mathop{}\!\mathrm du$$ But I could not complete the solution using this substitution.","['integration', 'definite-integrals', 'calculus', 'trigonometry', 'elliptic-integrals']"
3038582,"Prove that the polar decomposition of normal matrices, $A=SU$, is such that $SU=US$","Assume $A$ is a normal matrix. Suppose $A=SU$ is a polar decomposition of $A$ . Prove that $SU=US$ . I have no idea to prove this. $A$ is normal then $AA^*=A^*A$ . And then we have $$
SS^*=U^*S^*SU.
$$ But I don't know how to continue.","['matrices', 'linear-algebra', 'matrix-decomposition']"
3038644,Representation of an algebra is absolutely irreducible if and only the representation map is surjective,"This should be well known but I can't seem to locate a reference: Let $k$ be a field, $V$ a $n$ -dimensional vector space over $k$ with an action of a $k$ -algebra $A$ . We say that $V$ is an absolutely irreducible $A$ -module if for any field extension $L/k$ , $V\otimes_k L$ is irreducible as an $A\otimes_{k}L$ module. In this situation, we also have a representation map $r: A \to M_n(k) = End_k(V)$ . Why is it true that $V$ is absolutely irreducible if and only if $r$ is surjective? It is at least easy to show that if $r$ is surjective, then $V$ is absolutely irreducible. This is simply equivalent to showing that $M_n(k)$ (even $GL_n(k)$ ) acts transitively on non zero vectors in $k^n$ (plus the fact that tensor products preserve surjectivity). What about the other direction?","['matrices', 'representation-theory', 'noncommutative-algebra']"
3038651,Taylor series expansion of $\frac{1}{\sqrt{1-\beta x(x+1)}}$,"I am trying to find the taylor series expansion about $0$ (maclaurin series) of $$x \rightarrow \frac{1}{\sqrt{1-\beta x(x+1)}} \text{ with } \beta \in \mathbb{R}^{+*}$$ I've tried using the taylor series expansion of $$\frac{1}{\sqrt{1-X}} = \sum_{n=0}^{\infty}4^{-n}{2n \choose n}X^n \text{ }\text{ }\text{ }\text{ with } \text{ } X=\beta x(x+1)$$ But I can't turn it into a power series because of the $(x+1)^n$ ... I've also tried to derive $$\frac{1}{n!}\cdot\frac{\text{d}^n}{\text{d}x^n}\left(\frac{1}{\sqrt{1-\beta x(x+1)}}\right)_{x=0}$$ But no results so far... Edit : with a more powerful method, I found that, if we call $\left(a_n\right)_{n\in\mathbb{N}}$ the coefficients of the taylor series expansion $\left(\frac{1}{\sqrt{1-\beta x(x+1)}}=\sum_{n=0}^{\infty}a_nx^n\right)$ , the sequence $\left(a_n\right)_{n\in\mathbb{N}}$ is then defined by : $$\forall n\geq3, \text{} na_n=\beta\left(n-\frac{1}{2}\right)a_{n-1}+\beta\left(n-1\right)a_{n-2}$$ $$\text{with }\text{ }a_1 = \frac{\beta}{2} \text{ , } a_2 = \frac{3}{8}\beta^2+\frac{1}{2}\beta$$ It's definitely a step forward, but I don't know how to proceed from there. Is there a way to handle sequences that are defined by such a way ?","['real-analysis', 'calculus', 'taylor-expansion', 'sequences-and-series', 'power-series']"
3038661,Closed form of an improper integral to solve the period of a dynamical system,"This improper integral comes from a problem of periodic orbit . The integral evaluates one half of the period. In a special case, the integral is $$I=\int_{r_1}^{r_2}\frac{dr}{r\sqrt{\Phi^2(r,r_1)-1}}$$ where $$\Phi(u,v)=\frac{u\exp{(-u)}}{v\exp{(-v)}}$$ The interval follows $\Phi(r_1,r_2)=1$ , $r_1<r_2$ . I have found a solution to a special case (by applying perturbation method to the original ODE), which is $$\lim_{r_1\rightarrow r_2} I =\pi$$ When $r_1 \rightarrow r_2$ , we have $r_1, r_2 \rightarrow r_0$ , where $r_0$ is the peak position of $g(r)=r\exp{(-r)}$ . The numerical verification is shown below: $\uparrow$ The interval of the integral and the integrand $\uparrow$ The integral as a function of $r_2$ My problem is to derive a closed form for $I(r_1)$ , or even just a Taylor expansion about $r_0$ . I appreciate any hint. Thanks! If you are interested, here is the general form of the integral: $$I=\int_{r_1}^{r_2}\frac{dr}{r\sqrt{\Phi^2(r,r_1)-1}}$$ where $$\Phi(u,v)=\frac{u\exp{(k(u))}}{v\exp{(k(v))}}$$ and $k$ is a decreasing function.
The interval follows $\Phi(r_1,r_2)=1$ , $r_1<r_2$ . By solving the original ODE using perturbation method, the solution to a special case is $$\lim_{r_1\rightarrow r_2} I =\frac{\pi}{\sqrt{1+r_0 k''(r_0)/k'(r_0)}}$$ When $k(r)=-r$ , it reduces to $\pi$ . In fact, $\lim_{r_1 \rightarrow r_2} I (k(r)=-C\cdot r^n) = \pi/\sqrt{n}$ . Thanks to Fabian, the second derivative at $r=1$ matches $I=\pi-\frac{\pi}{12}\epsilon^2+O(\epsilon^3)$ : $\uparrow$ The above is the numerical second order derivative of figure 2.","['integration', 'improper-integrals', 'special-functions', 'lambert-w', 'elliptic-integrals']"
3038681,"Integration Representation of Bounded Bilinear Functional on $L_2([0,1])$","Suppose $B(f,g)$ is a bilinear functional on $L_2([0,1])$ , satisfying $|B(f,g)|\leq M \|f\|_2\|g\|_2$ for some $M>0$ . My question is whether there always exists a function $\xi_B(x,y)$ (Maybe essentially bounded?) such that $$B(f,g) = \int_{[0,1]^{\otimes2}}\xi_B(x,y)f(x)g(y)dxdy.$$ One possible idea to prove it is to use Riesz Representation theorem first and have $B(f,g) = <\tau_B f,g>$ , where $\tau_B$ is a bounded linear operator from $L_2([0,1])$ to $L_2([0,1])$ and then there might be some results for an integration representation of $\tau_B$ . But I am not sure where can I find results about it. P.S.: In my research, $B(f,g)$ is also symmetric, i.e. $B(f,g)=B(g,f)$ , or, as a result, $\tau_B$ is self-adjoint. It will also be good if you can help me proving integration representation with this extra condition. I don't think it will be very useful though.","['operator-theory', 'functional-analysis', 'real-analysis']"
3038712,What proportion of positive integers have two factors that differ by 1?,"What proportion of positive integers have two factors that differ by 1? This question occurred to me
while trying to figure out
why there are 7 days in a week. I looked at 364,
the number of days closest to a year
(there are about 364.2422
days in a year, iirc).
Since $364 = 2\cdot 2 \cdot 7 \cdot 13$ ,
the number of possible
number that evenly divide a year
are
2, 4, 7, 13, 14, 26, 28,
and larger. Given this,
7 looks reasonable -
2 and 4 are too short
and 13 is too long. Anyway,
I noticed that
13 and 14 are there,
and wondered how often
this happens. I wasn't able to figure out
a nice way to specify the
probability
(as in a Hardy-Littlewood
product),
and wasn't able to 
do it from the inverse direction
(i.e., sort of a sieve
with n(n+1) going into
the array of integers). Ideally, I would like
an asymptotic function
f(x) such that $\lim_{n \to \infty} \dfrac{\text{number of such integers } \ge 2 \le nx}{n}
=f(x)
$ or find $c$ such that $\lim_{n \to \infty} \dfrac{\text{number of such integers } \ge 2 \le n}{n}
=c
$ . My guess is that,
in the latter case, $c = 0$ or 1,
but I have no idea which is true.
Maybe its $1-\frac1{e}$ . Note: I have modified this
to not allow 1 as a divisor.","['number-theory', 'asymptotics']"
3038737,Number of strings of length 8 using ABCDEF that contain ABC?,"Here is my attempt to calculate the number of strings of length $8$ using $6$ characters (ABCDEF) which contain 'ABC'. Basically I wanted to see if my approach is correct or if there is a better way to calculate this. Basically we consider ABC like an element by itself, and it can go: ABC X X X X X X ABC X X X X X X ABC X X X X X X ABC X X X X X X ABC X X X X X X ABC Where the X represents another character. So we have $6$ rows and in each row there are $6^5$ possibilities (can choose between $6$ chars. and have $5$ spots), therefore we have $6^6$ combinations. However there are repetitions, which are the following cases: ABC ABC X X ABC X ABC X ABC X X ABC X ABC ABC X X ABC X ABC X X ABC ABC So we subtract these possibilities which are $6^3$ ( $6 \cdot 6^2$ because there are $6$ rows and $2$ spots for $6$ chars in each row) So we end up with $6^6 - 6^3$ . Thank you in advance.",['combinatorics']
3038781,Minimal sufficient statistic criterion,"(Note: This is not about Bayesian inference, but about classical inference) Let $\{P_\theta\}_{\theta\in \Theta}$ be a family of probability measures on $\mathbb{R}^n$ with density functions $f_\theta$ . Let $T:\mathbb{R}^n \rightarrow \mathscr{T}$ be a statistic. Define $$D(x):=\{y\in \mathbb{R}^n: \text{ There exists a positive function } h \text{ such that } f_{\theta}(x)=f_{\theta}(y)h(x,y) \text{ for all } \theta \}$$ . (Note that $D(x)$ forms a partition of $\mathbb{R}^n$ ) Assume that $T(x)=T(y)$ if and only if $x\in D(y)$ . Many textbooks and even wikipedia asserts that, with the above assumption, one can show that $T$ is minimal sufficient. However, I do not get this Here is a proof that textbooks I have seen have: Let $\alpha:range(T)\rightarrow \mathbb{R}^n$ be a representative function for $T$ . (That is, $T(\alpha(t))=t$ ) If we pick $x\in\mathbb{R}^n$ , from our assumption, $f_\theta(x)=f_\theta(\alpha(T(x)))h(x,\alpha(T(x))$ holds for all $\theta$ for some positive function $h>0$ . If we take $g_\theta:=f_\theta\circ \alpha$ , then by Fisher-Neymann theorem, $T$ is sufficient. However , since $\alpha$ need not be measurable, $g_\theta$ need not be measurable. So we cannot apply Fisher-Neymann theorem. (As you can see here , $\alpha$ need mot be measurable) Is $g_\theta$ measurable in anyways? Or is there a correct proof for this? Thank you in advance.","['statistical-inference', 'statistics']"
3038840,Finding $p$ such that $\sum\limits_{n=1}^\infty n(1+n^2)^p$ converges. Check my work.,"Given series $$
\sum\limits_{n=1}^\infty n(1+n^2)^p
$$ Find the values of $p$ , such that the series is convergent. To find $p$ , I use integral test,
assume $f(x)=x(1+x^2)^p$ , \begin{eqnarray}
\int\limits_1^\infty x(1+x^2)^pdx &=& \lim\limits_{b\to\infty} \int\limits_1^b x(1+x^2)^pdx\\
&=& \lim\limits_{b\to\infty} \left[\dfrac{1}{2(p+1)}\left((1+b^2)^{p+1}-2^{p+1}\right)\right]
\end{eqnarray} If $p=1$ , the integral is divergent, If $p>-1$ , the integral is divergent, If $p<-1$ , the integral is convergent to $-\dfrac{1}{p+1}2^p$ , So, I conclude the series is convergent while $p<-1$ . This answer is correct or incorrect?","['convergence-divergence', 'sequences-and-series']"
3038847,"Given $f(x)$ is integrable on $[0, 1]$ and $0 < f(x) < 1$, prove that $\int_{0}^{1} (f(x))^{n} \mathop{dx}$ converges to $0$.","Given $f(x)$ is integrable on $[0, 1]$ and $0 < f(x) < 1$ , prove that $\int_{0}^{1} (f(x))^{n} \mathop{dx}$ converges to $0$ . I understand why the statement is true intuitively because as $n \to \infty$ , since $f$ lies between $0$ and $1$ , it will be like a fractional value, which converges to $0$ since the fractions get smaller and smaller. However, I am not sure about how to prove this rigorously.","['integration', 'real-analysis', 'limits', 'convergence-divergence', 'riemann-integration']"
3038892,"Cevians $AD$, $BE$, $CF$ are concurrent, as are cevians $DP$, $EQ$, $FR$; show that $AP$, $BQ$, $CR$ are concurrent","The following is one version of the Cevian Nest Theorem : In $\triangle ABC$ , $D$ , $E$ , and $F$ are points on $BC$ , $CA$ , and $AB$ , respectively, such that $AD$ , $BE$ , and $CF$ are concurrent lines. Points $P$ , $Q$ , and $R$ respectively on $EF$ , $FD$ , and $DE$ are such that $DP$ , $EQ$ , and $FR$ are concurrent. Prove that $AP$ , $BQ$ , and $CR$ are also concurrent. I am really not getting how to proceed at all. I know I'm supposed to use Ceva's theorem but where do I apply it.","['contest-math', 'euclidean-geometry', 'geometry', 'triangles', 'plane-geometry']"
3038913,"Finding the harmonic conjugate of $T(x,y)= e^{-y} \sin x$?","I try the following two method on finding the harmonic conjugate of $T(x,y)= e^{-y} \sin x$ : Method 1 : by a method of the book Complex Variables and Applications by Brown and Churchill, Chapter 9 Section 104, $$v(x,y) = \int_{(0,0)}^{(x,y)} -u_t(s, t)\ ds + u_s(s, t)\ dt = \int_{(0,0)}^{(x,y)} e^{-y} \sin x \ dx + e^{-y} \cos x \ dy = -e^{-y} \cos x - e^{-y} \cos x +C = -2e^{-y} \cos x +C$$ which $C$ can be chosen to be zero. Method 1 : Since $T(x,y)= e^{-y} \sin x$ and its harmonic conjugate must be the real and imaginary parts of an analytic function, respectively, so it can be $f(z)=-ie^{iz} =e^{-y} \sin x - ie^{-y} \cos x.$ So why there is an extra $2$ coefficient in Method 1? Where did I do wrong? Added. Probably the Method 1 is wrong. It comes from if $F_x(x,y) = P(x,y), \  F_y(x,y) = Q(x,y)$ holds in here . For example the method gives the correct answer for $u=xy$ but again it give a wrong answer for $u=x^3-3xy^2:$ that is $v=6x^2y-y^3$ ; but the correct one is $v=3x^2y-y^3$ . But it looks impossible such a famous book to make a mistake. (???)","['complex-analysis', 'solution-verification', 'harmonic-functions', 'line-integrals']"
3038918,"What is the convex hull of $\text{conv}(u_1,u_2,\cdots,u_p)+\text{conv}(v_1,v_2,\cdots,v_s)$?","Let $u_i, i= 1,\cdots,p$ and $v_j, j= 1,\cdots,s$ be finitely many vectors in $\mathbb{R}^n$ . Show that $$
\text{conv}(u_1,u_2,\cdots,u_p)+\text{conv}(v_1,v_2,\cdots,v_s)=\text{conv}\{u_i+v_j \mid i= 1,\cdots,p, \,\, j= 1,\cdots,s\}
$$ We need to show $$
x+y \in \text{conv}\{u_i+v_j \mid i= 1,\cdots,p, \,\, j= 1,\cdots,s\}
$$ where $x \in \text{conv}(u_1,u_2,\cdots,u_p)$ and $y \in \text{conv}(v_1,v_2,\cdots,v_s)$ . Also, we need to show $$
z \in \text{conv}(u_1,u_2,\cdots,u_p)+\text{conv}(v_1,v_2,\cdots,v_s)
$$ where $z \in \text{conv}\{u_i+v_j \mid i= 1,\cdots,p, \,\, j= 1,\cdots,s\}$ . I have tried the following for the first one: Let $x \in \text{conv}(u_1,u_2,\cdots,u_p)$ so $x=\sum_{i=1}^p\lambda_iu_i$ where $\sum_{i=1}^p\lambda_i=1$ . Also, Let $y \in \text{conv}(v_1,v_2,\cdots,v_s)$ so $x=\sum_{j=1}^s\mu_jv_j$ where $\sum_{j=1}^s\mu_j=1$ . Summing them $$x+y=\lambda_1u_1+\lambda_2u_2+\cdots+\lambda_pu_p+\mu_1v_1+\mu_2v_2+\cdots+\mu_sv_s.$$ Now the question is how we can get something in the form of $\text{conv}\{u_i+v_j \mid i= 1,\cdots,p, \,\, j= 1,\cdots,s\}$ ?","['vectors', 'convex-hulls', 'convex-geometry', 'geometry', 'convex-analysis']"
3038931,"$AB_1$, $AB_2$, $AB_3$ are the altitude, angle bisector, median from vertex $A$ of $\triangle ABC$; arrange lengths $BB_i$ in ascending order","Consider an acute angled triangle $\triangle ABC$ such that $AB\lt AC$ . If from $A$ altitude $AB_1$ is drawn, internal angle bisector $AB_2$ is drawn, and median $AB_3$ is drawn. Arrange the lengths $BB_1$ , $BB_2$ and $BB_3$ in ascending order. My try: I started with an Isosceles Triangle $\triangle ABD$ with $AB=AD$ . Now, for $\triangle ABD$ , $AB_1$ is altitude, angle bisector, and median. In figure $2$ Let $\angle BAB_1=\theta=\angle B_1AD$ let $\angle DAC=2 \beta$ So $\angle BAC=2(\theta+\beta)$ If we construct $AB_2$ asinternal angle bisector of $\angle BAC$ , Then each half angle is : $$\angle BAB_2=B_2AC=\theta+\beta \gt \theta$$ $\implies$ $$\angle BAB_2 \gt \angle BAB_1$$ hence the point $B_2$ should be to right side of the point $B_1$ Hence $$BB_1 \lt BB_2$$ But can I have a clue to compare $BB_2$ and $BB_3$ ?","['triangles', 'inequality', 'angle', 'geometry']"
3038946,Proving a set to be countable,"A set $S = \left\lbrace \left( x, y \right) \vert x^2 + y^2 = \dfrac{1}{n^2}, \text{ where } n \in \mathbb{N} \text{ and either } x \in \mathbb{Q} \text{ or } y \in \mathbb{Q} \right\rbrace$ is given. I need to prove that this is countable. I have tried looking for a bijection $f: \mathbb{Q} \rightarrow S$ as $f \left( x \right) = \left( x, y \right)$ where $y$ is a fixed real number such that the property of the set is satisfied. Clearly, this function is not even a surjection. How should we define our bijection so that we prove $S$ is countable?","['elementary-set-theory', 'real-analysis']"
3039017,Second order ODE problem with a series solution,"I'm trying to obtain an analytical solution to the following ODE: $$-\epsilon x y+\left(\epsilon R-x-\epsilon x^2\right)y'+\left(R-x^2\right)y''=0$$ The only method that would make sense for me is the series method where I define $$y=\sum_{n=0}^\infty a_n x^n$$ and try to obtain a recurrence relation. If each part of the ODE is written separately we obtain: $$-\epsilon xy = \epsilon \sum_{n=0}^{\infty}a_nx^{n+1}$$ $$\left(\epsilon R-x-\epsilon x^2\right)y'=\sum_{n=1}^{\infty}n a_n x^{n-1}-\sum_{n=1}^{\infty}na_nx^n-\epsilon \sum_{n=1}^{\infty}na_nx^{n+1}$$ $$\left(R-x^2\right)y''=R\sum_{n=2}^{\infty}n(n-1)a_nx^{n-2}-\sum_{n=2}^{\infty}n(n-1)a_nx^n$$ Each time I'm trying to work out the equation I reach a dead end in terms of the indexes. Is it possible to reduce this problem to a recurrence relation problem? If not, is this equation solvable analytically?","['recurrence-relations', 'ordinary-differential-equations']"
3039029,"prove $\lim \limits_{n \to \infty}{\frac{W_n\sqrt{n}}{(n-1)\sqrt{2}}} \sim N_{(0,1)}$","I searched the internet alot . The only relevant clue is in Wikipedia: F-distribution Beside that I didn't find any proof for this theory. If $Y$ has $B\left(\frac{d_1}{2}, \frac{d_2}{2}\right)$ distribution, then show that $X$ with given formula has $F\left(d_1,d_2\right)$ distribution. $$X = \frac{d_2Y}{d_1\left(1-Y\right)}$$ I tried this but I can't do anything because of $\Gamma{}$ integral: $$Y = \frac{\Gamma\left({\frac{d_1 + d_2}{2}}\right)}{\Gamma\left(\frac{d_1}{2}\right)\Gamma\left(\frac{d_2}{2}\right)}x^{\frac{d_1}{2} - 1}\left(1-x\right)^{\frac{d_2}{2}-1}$$ so: $$X = \frac{d_2Y}{d_1\left(1-Y\right)}$$ $$X = \frac{d_2\frac{\Gamma\left({\frac{d_1 + d_2}{2}}\right)}{\Gamma\left(\frac{d_1}{2}\right)\Gamma\left(\frac{d_2}{2}\right)}x^{\frac{d_1}{2} - 1}\left(1-x\right)^{\frac{d_2}{2}-1}}{d_1\left(1-\frac{\Gamma\left({\frac{d_1 + d_2}{2}}\right)}{\Gamma\left(\frac{d_1}{2}\right)\Gamma\left(\frac{d_2}{2}\right)}x^{\frac{d_1}{2} - 1}\left(1-x\right)^{\frac{d_2}{2}-1}\right)}$$ $$X = x^{\frac{d_1}{2} - 1}\frac{\Gamma\left({\frac{d_1 + d_2}{2}}\right)}{\Gamma\left(\frac{d_1}{2}\right)\Gamma\left(\frac{d_2}{2}\right)}\left(\frac{d_2\Gamma\left(\frac{d_1}{2}\right)\Gamma\left(\frac{d_2}{2}\right)\left(1-x\right)^{\frac{d_2}{2}-1}}{d_1\Gamma\left(\frac{d_1}{2}\right)\Gamma\left(\frac{d_2}{2}\right) - \Gamma\left({\frac{d_1 + d_2}{2}}\right)x^{\frac{d_1}{2} - 1}\left(1-x\right)^{\frac{d_2}{2}-1}}\right)$$ compare it to $F\left(d_1,d_2\right)$ : $$F\left(d_1,d_2\right)=x^{\frac{d_1}{2} - 1}\frac{\Gamma\left({\frac{d_1 + d_2}{2}}\right)}{\Gamma\left(\frac{d_1}{2}\right)\Gamma\left(\frac{d_2}{2}\right)}\left(\frac{d_1}{d_2}\right)^{\frac{d_1}{2}-1}\frac{1}{\left(1+\frac{d_1}{d_2}x\right)^{\frac{d_1+d_2}{2}}}$$ so: $$\left(\frac{d_1}{d_2}\right)^{\frac{d_1}{2}-1}\frac{1}{\left(1+\frac{d_1}{d_2}x\right)^{\frac{d_1+d_2}{2}}} = \left(\frac{d_2\Gamma\left(\frac{d_1}{2}\right)\Gamma\left(\frac{d_2}{2}\right)\left(1-x\right)^{\frac{d_2}{2}-1}}{d_1\Gamma\left(\frac{d_1}{2}\right)\Gamma\left(\frac{d_2}{2}\right) - \Gamma\left({\frac{d_1 + d_2}{2}}\right)x^{\frac{d_1}{2} - 1}\left(1-x\right)^{\frac{d_2}{2}-1}}\right)$$ I can't go on anymore because of $\Gamma$ integral! If possible, give me a hint to prove this. Any help will be appreciated.",['statistics']
3039030,A question about union of non-overlapping intervals and its relation to Arzelà's theorem,"While trying to answer this question I initially tried to argue via contradiction and was led to the following result: Unproved Theorem : For each positive integer $n$ let $J_n$ be a union of finite number of non-overlapping (closed) sub-intervals of $[a, b] $ . And further let the combined length of sub-intervals in $J_n$ be greater than or equal to $\delta>0$ for all $n$ . Then there is at least one point $c\in[a, b] $ which lies in infinitely many $J_n$ . Two intervals are non-overlapping if their interiors are disjoint. Unfortunately I was unable to prove the theorem and I need some help here. Also approaches without the use of measure theory are desired as I was able to answer the linked question using measure theory. The relation between the above theorem and the linked question is based on the fact that if a Riemann integral is positive then the function being integrated is positive on some union like $J_n$ . More formally Apostol proves the following theorem in an exercise (see Exercise 7.35, page 180, Mathematical Analysis ): Theorem : Let $f:[a, b] \to\mathbb {R} $ be a non-negative Riemann integrable function such that $I=\int_{a} ^{b} f(x) \, dx>0$ . Let $M$ be a positive bound for $f$ and $\delta=\dfrac{I} {2(M+b-a)}$ . Then the set $A=\{x\mid f(x) \geq \delta\} $ contains a finite number of non-overlapping intervals whose combined length is at least $\delta$ . Here is one approach which sounds promising but there are certain doubts. Let's assume on the contrary that no such point $c$ exists. Then for each $x\in[a, b] $ there is a positive integer $n_x$ such that $x\notin J_n$ for all $n\geq n_x$ . Since $J_n$ is closed it follows that there is a neighborhood $I_x$ such that $I_x\cap J_n=\emptyset $ for all $n\geq n_x$ . By Heine Borel we can choose a finite number of such neighborhoods say $I_{x_1},\dots,I_{x_p}$ which cover $[a, b] $ . Let $N$ be the maximum of $n_{x_1},\dots,n_{x_p}$ . Then $[a, b] \cap J_n=\emptyset $ for $n\geq N$ and this is a contradiction. The problem with above proof is that the value $\delta$ is used nowhere. That part of hypotheses seems crucial. The problem with the above proof is found and the wrong inference is striked out. I will let the above wrong proof be there so that readers can avoid it. Update : On further investigation as well as looking at this answer of the linked question, it appears that the unproved theorem mentioned above is equivalent to the theorem of Arzelà: Arzelà's Theorem : Let $\{f_n\} $ be a sequence of functions $f_n:[a, b] \to\mathbb {R} $ such that each $f_n$ is Riemann integrable on $[a, b] $ and let $|f_n(x)|\leq M$ for all positive integers $n$ and all $x\in[a, b] $ . Further let $f_n$ converge point wise to a Riemann integrable function $f$ on $[a, b] $ . Then $\int_{a} ^{b} f_n(x) \, dx\to\int_{a} ^{b} f(x) \, dx$ . By considering the functions $f_n-f$ the above theorem is reduced to the special case when $f(x) =0$ for all $x\in[a, b] $ . Thus let $f_n(x) \to 0$ for all $x\in[a, b] $ and $|f_n(x)| \leq M$ for all $x\in[a, b] $ and all $n\in\mathbb {N} $ . Also since $|\int_{a} ^{b} f_n(x) \, dx|\leq \int_{a} ^{b} |f_n(x) |\, dx$ the theorem is reduced to the case when each $f_n$ is non-negative. Thus Arzelà's theorem is reduced to the equivalent simpler formulation: Arzelà's Theorem (Simplified) : Let $\{f_n\} $ be a sequence of non-negative Riemann integrable functions $f_n:[a, b] \to\mathbb{R} $ which converges to $0$ point wise on $[a, b] $ and let $f_n(x) \leq M$ for all $x\in[a, b] $ and all $n\in\mathbb {N} $ . Then $\int_{a} ^{b} f_n(x) \, dx$ converges to $0$ . Arguing by contradiction let us suppose that $\int_{a} ^{b} f_n(x) \, dx$ does not converge to $0$ . Then there is an $\epsilon>0$ and a subsequence $f_{n_k} $ such that $\int_{a} ^{b} f_{n_k} (x) \, dx\geq \epsilon$ . Without any loss of generality we can assume the subsequence $f_{n_k} $ to be the entire sequence $f_n$ . Thus we have $\int_{a} ^{b} f_n(x) \, dx\geq \epsilon $ . And by the theorem from Apostol's exercise this means that if $\delta=\dfrac{\epsilon} {2(M+b-a)}$ then the set $A_n=\{x\mid f_n(x) \geq\delta\} $ contains a union $J_n$ of non-overlapping subintervals of $[a, b] $ whose combined length is not less than $\delta$ . By the theorem stated at the beginning of this post there is a point $c\in[a, b] $ which lies in infinitely many $J_n$ and hence $f_n(c) \geq \delta$ for infinitely many $n$ . This contradicts the hypotheses that $f_n$ converges to $0$ point wise on $[a, b] $ . This completes the proof of Arzelà's theorem. Assuming the truth of Arzelà's theorem one can prove the theorem mentioned in the beginning of this post. Let's just take $f_n$ to be the indicator function of $J_n$ . If every $x\in[a, b] $ lies only in a finite number of $J_n$ then $f_n$ converges point wise to $0$ on $[a, b] $ . It can be checked that all hypotheses of Arzelà's theorem are satisfied and hence the integrals $\int_{a} ^{b} f_n(x) \, dx$ converge to $0$ . But these integrals represent the length of $J_n$ which is at least $\delta$ and thus we reach a contradiction. In this manner we see that the theorem mentioned in beginning of the post is equivalent to the theorem of Arzelà.","['integration', 'real-analysis']"
3039053,logic question : about the set equality $f(A)=B$,"I argued with a friend about whether the equivalence : $$x\in A \iff f(x)\in B$$ (where $f:E \to F$ is some function and $A \subset E$ , $B \subset F$ )
is enough to say that the set-equality $f(A) = B$ holds. If we take the map $$ \begin{aligned}[t]
f \colon \mathbb{R}^* &\longrightarrow \mathbb{R} \\
x &\longmapsto \dfrac 1x \end{aligned} $$ If we take $A:=(0,+\infty)$ and $B=(0,+\infty)\cup \{0\}$ the equivalence sounds correct yet $f(A) \neq B$ . Thanks for any clarifications.","['elementary-set-theory', 'logic']"
3039058,An inequality about linear PDE,"I am trying to solve the following problem: Let $\Omega$ be a bounded smooth domain in $\mathbb{R}^n, \ n\geq 2$ . Let $u\in C^2(\overline{\Omega})$ be a solution of $$\left\{\begin{array}{ll}u_t-\Delta u=f(x)& \text{in } \Omega\times(0,\infty)\\ u=0&\text{on }\partial \Omega\times (0,\infty) \\ u=g(x) & \text{on } \Omega\times\{0\}\end{array}\right.$$ Show that $$\max_{0\leq t\leq T} \int_\Omega u^2(x,t)dx+\int_0^T\int_\Omega|\nabla u(x,t)|^2dx\, dt\leq C\left(\int_\Omega g^2(x)dx+\int_0^T|f(x)|^2 dx\,dt\right)$$ for some constant $C$ independent of $f,\ g$ and $u$ . My attempt: Multiplying the first equation by $u$ and taking integration on $\Omega$ , we have $$\frac{1}{2}\frac{d}{dt}||u||^2_{L^2}+\int_\Omega \nabla u\cdot \nabla u=\int_\Omega fu.$$ (Here we also use the Green's identity and the boundary condition of $u$ ) Taking integration on $[0,s]$ where $s\leq T$ . Then we have $$\frac{1}{2}||u(x,s)||^2_{L^2}+\int_0^s\int_\Omega|\nabla u(x,t)|^2dx\, dt= \frac{1}{2} \int_\Omega g^2(x)dx+\int_0^s\int_\Omega fu\ dt$$ where $$\int_\Omega fu\leq ||f||_{L^2} ||u||_{L^2}\leq \epsilon ||u||_{L^2}^2 + C(\epsilon ) ||f||_{L^2}$$ Then we have $$(\frac{1}{2}-s\epsilon )||u(x,s)||^2_{L^2}+\int_0^s\int_\Omega|\nabla u(x,t)|^2dx\, dt
\leq \frac{1}{2} \int_\Omega g^2(x)dx+\int_0^s C(\epsilon ) ||f||_{L^2} dt$$ Then I was stuck here. I don't know where can I derive the part $$\max_{0\leq t\leq T}||u(x,t)||.$$ Also, I am struggling how to make the two coefficients before the two terms on the left the same so that we can get the desired inequality.","['inequality', 'partial-differential-equations', 'real-analysis']"
3039085,Existence nontrivial Killing vector field $\iff$ existence nontrivial $\Bbb S^1$-action,Where can I find proof of the following classical fact? The existence of a nontrivial Killing vector field on a compact Riemannian manifold $M$ is equivalent to the existence of a nontrivial $\Bbb S^1$ -action on $M$ . Is there any counterexample in non-compact case?,"['riemannian-geometry', 'reference-request', 'differential-topology', 'group-actions', 'differential-geometry']"
3039105,Formalizing an observation,"I just rewatched some old math books for the fun of it and was able to
  observe the following which I want to formalize (could you help me
  with it): Choose 2 numbers with distance 1 for each pair. Proceed with... First Example $(i)$ (3,4) and (6,7) $3\cdot 6+4\cdot 7=46$ and $3\cdot 7 + 4\cdot 6 = 45$ EDIT: Second example $(ii)$ (distance between pairs don't need to be the same distance) (5,6) and (9,10) $5 \cdot 9 + 6 \cdot 10 = 105$ and $5\cdot 10 + 6\cdot 9 = 104$ Therefore, the outcome of both equations in $(i)$ and $(ii)$ have a distance of $1^2$ . Observation If you try this for different examples and for distances $n\in \mathbb{N}_0$ , you'll most likely notice, that the observation is satisfied for all pairs $(a,b),(c,d)\mid a,b,c,d\in\mathbb{N}\setminus \{0\}$ with a specific distance $n\geq 0$ . I want to formalize this fact, but I'm not really sure, if my following thoughts are correct. Informal, we have: For all pairs $(a,b),(c,d) \in  \mathbb{N}\setminus 0:$ exists one $n$ in $\mathbb{N}_0$ with $b$ is the successor of $a$ with distance $n$ and $d$ is the successor of $c$ with distance $n$ for which we obtain equivalent that the outcome of $(ac+bd)$ has distance $n^2$ to the outcome $(ad+bc)$ . I would formalize this as the following: $$\forall a,b,c,d \in \mathbb{N}\setminus 0 : \exists n \in \mathbb{N}_0:(b=a+n) \land (d=c+n) \iff \underbrace{(ac+bd)}_{=x+n^2}- \underbrace{(ad+bc)}_{=x}=n^2$$ Do you think this is correct? If not, could you share your thoughts about it? Could we use group-theory to discribe these equations easier?","['number-theory', 'proof-writing', 'proof-verification', 'discrete-mathematics']"
3039113,Why are algebraic structures preserved under intersection but not union?,"In general, the intersection of subgroups/subrings/subfields/sub(vector)spaces will still be subgroups/subrings/subfields/sub(vector)spaces. However, the union will (generally) not be. Is there a ""deep"" reason for this?","['abstract-algebra', 'big-picture', 'category-theory']"
3039173,Is every matrix conjugate to its transpose in a continuous way?,"It is well-known that every square matrix is conjugate to its transpose . This means (in the case of real matrices) that, for each $n\times n$ matrix $M$ with real entries, there is a matrix $S_M\in GL(n,\mathbb{R})$ such that ${S_M}^{-1}MS_M=M^T$ . My question is: can you choose $S_M$ in such a way that it depends continuously on $M$ ? In other words: Is there a continuous map $\psi\colon M_{n,n}(\mathbb{R})\longrightarrow GL(n,\mathbb{R})$ such that $$\bigl(\forall M\in M_{n\times n}(\mathbb{R})\bigr):\psi(M)^{-1}.M.\psi(M)=M^T?$$ My guess is that the answer is negative even for $n=2$ . Note that, for each individual matrix $M$ , there are plenty of choices for $S_M$ . For instance, if $n=2$ and $$M=\begin{bmatrix}x&y\\z&t\end{bmatrix},$$ then you can take $$S_M=\begin{bmatrix}az&bz\\bz&bt-bx+ay\end{bmatrix},$$ with $a$ and $b$ chosen such that $\det(S_M)\neq0$ but, of course, this will only work if $z\neq0$ . What if $z=0$ ? Then you can take $$S_M=\begin{bmatrix}-at+ax&ay\\ay&by\end{bmatrix}$$ and, again, $a$ and $b$ should be chosen such that $\det(S_M)\neq0$ ; the problem now is that, of course, this will only work if $y\neq0$ . And so on. This looks like the problem of finding a logarithm for each $z\in\mathbb{C}\setminus\{0\}$ : there are plenty of choices for each individual $z$ , but there is no continuous way of picking one.","['matrices', 'continuity', 'transpose', 'linear-algebra', 'similar-matrices']"
3039181,Upper bound of expected maximum of weighted sub-gaussian r.v.s,"Let $X_1, X_2, \ldots$ be an infinite sequence of sub-Gaussian random variables which are not necessarily independent. My question is how to prove \begin{eqnarray}
\mathbb{E}\max_i \frac{|X_i|}{\sqrt{1+\log i}} \leq C K,
\end{eqnarray} where $K=\max_i \|X_i\|_{\psi_2}$ . Note that $\|\cdot\|_{\psi_2}$ is the Orlicz norm for sub-Gaussian random variable. Here is my thought that confuses me.... Consider the finite case with $i\leq N$ , we have \begin{eqnarray}
\mathbb{E}\max_{i\leq N} \frac{|X_i|}{\sqrt{1+\log i}} &=& \int_0^\infty \mathbb{P}\left(\max_{i\leq N} \frac{|X_i|}{\sqrt{1+\log i}} > t \right) dt \\
&\leq& \int_0^\infty \sum_{i=1}^N\mathbb{P}\left( \frac{|X_i|}{\sqrt{1+\log i}} > t \right) dt \\
&\leq& \sum_{i=1}^N \frac{2}{\sqrt{1+\log i}} \int_0^\infty e^{-cs^2/K^2}ds \\
&=&  K\sqrt{\frac{\pi}{c}} \sum_{i=1}^N \frac{1}{\sqrt{1+\log i}}
\end{eqnarray} where the first inequality holds by a simple union bound and the second inequality holds by sub-Gaussianity of $X_i$ (i.e. we have $\mathbb{P}\{|X_i|\geq t\} \leq 2 e^{-ct^2/\|X_i\|_{\psi_2}^2}$ and $c$ is an absolute constant) and a simple trick of change-of-variable (i.e. let $s := t\sqrt{1+\log i}$ ). However, the problem of my proof above is that the sum $\sum_{i=1}^N \frac{1}{\sqrt{1+\log i}}\to\infty$ as $N\to\infty$ . Intuitively, I think the inequalities I used here are not very sharp. But what is the right inequality to use in this case??? This question comes from Exercise 2.5.10 of Prof. Roman Vershynin's book titled as ""High-Dimensional Probability"". The electric version of this book is downloadable from his personal webpage.","['probability-distributions', 'order-statistics', 'probability']"
3039184,Extreme values of ${x^3 + y^3 + z^3 - 3xyz}$ subject to ${ax + by + cz =1}$ using Lagrange Multipliers,"If ${ax + by + cz =1}$ , then show that in general ${x^3 + y^3 + z^3 - 3xyz}$ has two stationary values ${0}$ and $\frac{1}{(a^3+b^3+c^3-3abc)}$ , of which first is max or min according as ${a+b+c>0}$ or ${< 0}$ but second is not an extreme value. Comment on particular cases when (i) ${a+b+c=0}$ , (ii) ${a=b=c}$ . My Attempt: $${F=f+\lambda \phi =x^3 + y^3 + z^3 - 3xyz + 3\lambda(ax + by + cz-1)}$$ $${\frac13F_x = x^2-yz+\lambda a = 0}{\text{ ...(1)}}$$ $${\frac13F_y = y^2-xz+\lambda b = 0}{\text{ ...(2)}}$$ $${\frac13F_z = z^2-xy+\lambda c = 0{\text{ ...(3)}}}$$ $${(1)x+(2)y+(3)z \implies f+\lambda (1) = 0 \implies \lambda = -f}$$ $${(1)+(2)+(3) \implies}{x^2+y^2+z^2-xy-yz-zx=(a+b+c)f}$$ $${\implies f/(x+y+z)=(a+b+c)f}\,,$$ then ${f=0}$ or ${x+y+z=1/(a+b+c)}$ . Also, ${(1)-(2) \implies x^2-y^2-z(x-y)=f(a-b) \implies \frac{x-y}{a-b}=f\frac{a+b+c}{x+y+z}}$ Similarly ${(2)-(3)}$ and ${(3)-(1)}$ , then we get ${\frac{x-y}{a-b}=\frac{y-z}{b-c}=\frac{z-x}{c-a}=f\frac{a+b+c}{x+y+z}}$ I don't know how to proceed further. I couldn't get the other stationary value of ${f}$ . I need help in proceeding further to calculate stationary points and/or stationary values, if at all, my method is correct.","['nonlinear-optimization', 'lagrange-multiplier', 'maxima-minima', 'multivariable-calculus', 'optimization']"
3039193,"Proving $1 - \frac{2 \vartheta}{\pi} \sin \vartheta \leq \cos \vartheta$, for $\vartheta \in [0, \frac{\pi}{2}]$","For my thesis I need the inequality $1 - \frac{2 \vartheta}{\pi} \sin \vartheta \leq 2 \cos \vartheta$ for $\vartheta \in [0, \frac{\pi}{2}]$ which can be proved by exploiting the fact that $\cos \vartheta$ is concave on $[0, \frac{\pi}{2}]$ . When I plotted the graph of $1 - \frac{2\vartheta}{\pi} \sin \vartheta$ and the graph of $\cos \vartheta$ I noticed that indeed the stronger inequality $$1 - \frac{2 \vartheta}{\pi} \sin \vartheta \leq \cos \vartheta$$ seems to hold. Actually I do not need this stronger version but I would be interested in a proof anyway. What I have tried: Trying to find the zeros of $h(\vartheta)=\cos \vartheta - 1 + \frac{2 \vartheta}{\pi} \sin \vartheta$ . Writing down the Taylor-expansion of $h(\vartheta)$ and comparing the positive and the negative terms. Both approaches ended up in a mess. Does anyone  have an idea on how to prove this?","['trigonometry', 'inequality']"
3039230,How would you prove $\int^8_0\frac1{\sqrt{x+\frac1{\sqrt{x}}}}dx<4-\frac1{2019}$?,"We would like to prove the following inequality. $$\int^{8}_{0}\frac{1}{\sqrt{x+\frac{1}{\sqrt{x}}}}\,dx<4-\frac{1}{2019}\tag{1}$$ What I've tried is using the AM-GM inequality, $$x+\frac{1}{\sqrt{x}}\ge 2\,\sqrt{x \times\frac{1}{\sqrt{x}}}=2x^{\frac14} $$ then $$\int^{8}_{0}\frac{1}{\sqrt{x+\frac{1}{\sqrt{x}}}}\,dx\le\frac{1}{\sqrt{2}}\int^{8}_{0}\frac{1}{\sqrt[8]{x}}\, dx=4.98\cdots<\color{red}{5}-\frac{1}{2019}.\tag{2}$$ How would you prove $(1)$ ? It is tempting to upper-bound the integrand by an easier function. $\color{white}{11110811197115115116117100101110116}$","['integration', 'nested-radicals', 'definite-integrals', 'calculus', 'inequality']"
3039281,Question about the proof of Stone-Weierstrass theorem (Weierstrass approximation theorem) in Rudin,"In Rudin's Principles of Mathematical Analysis , a proof of the Stone-Weierstrass theorem in its original statement is included (3ed, p159): My question is about the step after (51), $P_n(x)=\int_{-1}^1f(x+t)Q_n(t)\operatorname{d}t$ .
How does one proceed from this, by a change of variable, to the next step, namely $P_n(x)=\int_{-x}^{1-x}f(x+t)Q_n(t)\operatorname{d}t$ ? And another question is why $P_n(x)=\int_0^1f(t)Q_n(t-x)\operatorname{d}t$ is a polynomial.","['complex-analysis', 'proof-explanation', 'real-analysis']"
3039363,"Is $[ \sqrt 2, \sqrt 3] \cap \mathbb{Q}$ an open subset of $\mathbb{Q}$?","Consider  the  set  of rational number $\mathbb{Q}$ as a subset  of $\mathbb{R}$ with  the usual metric. Let $K  = [ \sqrt 2, \sqrt 3] \cap \mathbb{Q}$ . I  have  some  confusion in  my mind that is Is $K$ is an open subset  of $\mathbb{Q}$ ? My attempt :  my answer  is No, $K=[\sqrt 2, \sqrt 3]\cap \Bbb{Q}=\{q \in \Bbb{Q}|\sqrt 2< q< \sqrt 3\}$ where $[\sqrt 2, \sqrt 3]$ is closed in $\Bbb{R}$ . From this  I can conclude  that  K  is not  open  subset  of $\mathbb{Q}$ Is  it True  ?","['general-topology', 'proof-verification', 'compactness']"
3039387,Continuity for a two-variable function from baby Rudin,"While I'm studying Baby Rudin's Exercise, I got some problems. The Exercise $9.28$ says I need to check the continuity of the function $$\varphi(x,t)=\begin{cases}x&0\leq x\leq \sqrt{t} \\ -x+2\sqrt{t}& \sqrt{t}\leq x\leq 2\sqrt{t}\\ 0&\text{otherwise}\end{cases}$$ and $\varphi(x,-t)=-\varphi(x,t)$ for $t\geq0$ . Intuitively, I know the function is continuous on $\mathbb{R}^2$ , but I can't show it easily. Even I tried to show the continuity by $\varepsilon$ - $\delta$ argument, but the formula got complicated; there are too many cases. Is there any simple way to show its continuity? I heard that by using pasting lemma it can be proved easily, but it is out of the scope of the class.","['multivariable-calculus', 'vector-analysis', 'analysis']"
3039393,How to solve $ \frac{dy}{dx} = \frac{x^3 -y^3}{x-y}$ which is a seemingly homogenous equation.,"How to solve $$ \frac{dy}{dx} = \frac{x^3 -y^3}{x-y}?$$ I can show $\frac{dy}{dx} = x^2 +y^2 +xy,$ which may be converted into an exact differential or any other process might be helpful ?","['differential-forms', 'ordinary-differential-equations']"
3039397,Apply Rolle's theorem to find real roots,"Suppose the function $f$ is continuous on $[a,b]$ and differentiable on $(a,b)$ such that $f(a)=f(b)=0$ . Prove that there exist a point $c\in(a,b)$ such that $$f(c)-f'(c)=0$$ From the question above, or otherwise, show that the equation $$1+x+\frac{x^2}{2!}+\cdots+\frac{x^{2n+1}}{(2n+1)!}=0$$ has real roots on $\mathbb{R}$ but not more than two.
  Additionally, show that the equation $$e^x-x^n=0$$ has at most three real roots on $\mathbb{R}$ , where $n
\in \mathbb{N}$ . My attempt: Suppose the function $$h(x)=e^{-x}f(x)$$ Then $$h'(x)=e^{-x}[f(x)-f'(x)]$$ Since $h(a)=h(b)=0$ and $e^{-x}>0$ for all real $x$ , then there exist a point $c\in(a,b)$ such that $h'(c)=0$ i.e. $f(c)-f'(c)=0$ . Then I get stuck on the following question. Should I start it with construct a function $$h(x)=e^{-x}[1+x+\frac{x^2}{2!}+\cdots+\frac{x^{2n+1}}{(2n+1)!}]$$ and follow my previous procedure?","['rolles-theorem', 'proof-verification', 'derivatives', 'analysis']"
3039403,"$T(X)$ be the set of all function $f :X \rightarrow \{0,1\}$.Then which of the following statement is True?","For a  set $X$ , let $\mathcal{P}(X)$ be the set of all  subsets of $X$ and $T(X)$ be  the  set of all function $f: X \to \{0,1\}$ .
Then which  of the  following statement is True ? If $X$ is  finite ,then $P(X)$ is  finite There is one-one correspondence between $X$ and $\mathcal{P}(X)$ My Approach I  take $X = N$ then  I get $\mathcal{P}(X) = 2^N$ which is uncountable so option a) is  discarded  i mean  option $a)$ is not correct im doubt in option  2.",['elementary-set-theory']
3039428,"Prove that if $a,b,c \in \mathbb{R^+}\text{ and } abc=8\text{ then } {ab+4\over a+2}+{bc+4\over b+2}+{ca+4\over c+2}\ge6$","Question: Prove that if $a,b,c \in \mathbb{R^+}\text{ and } abc=8\text{ then } {ab+4\over a+2}+{bc+4\over b+2}+{ca+4\over c+2}\ge6$ My Approach: Now we have: $${ab+4\over a+2}={2\times (ab+4)\over2\times (a+2)}={2ab+8\over2(a+2)}={2ab+abc\over2(a+2)}={ab(2+c)\over2(a+2)}$$ Now similarly we can acheive: $${bc+4\over b+2}={bc(2+a)\over2(b+2)};{ca+4\over c+2}={ca(2+b)\over2(c+2)}$$ Using AM-GM we get: $${ab+4\over a+2}+{bc+4\over b+2}+{ca+4\over c+2}$$ $$={ab(2+c)\over2(a+2)}+{bc(2+a)\over2(b+2)}+{ca(2+b)\over2(c+2)}$$ $$\ge\sqrt[3]{{ab(2+c)\over2(a+2)}\times{bc(2+a)\over2(b+2)}\times{ca(2+b)\over2(c+2)}}$$ $$=\sqrt[3]{(abc)^2\over2^3}$$ $$=\sqrt[3]{8^2\over8}=2$$ Therefore, we get: $${ab+4\over a+2}+{bc+4\over b+2}+{ca+4\over c+2}\ge2$$ However, the question wants me to prove that its greater than or equal to $6$ and when I try to plug in I always get a value larger than or equal to $6$ . So where did I go wrong and how can I fix my mistake. Thank you in advance.","['algebra-precalculus', 'inequality']"
3039460,Trying to Solve Math Problem for Real World Use - Combinatorics,"I'm trying to solve a math problem that hasn't been solved - to anyone's knowledge - in the community it's being used in. I am sure it is not difficult, but I am not smart enough to figure it out. In England, when on a country shoot (part of Britain's heritage) there are 8 ""pegs"" (shooting position in a straight line numbered 1-8) and shoot four ""drives"" (45 minute period of shooting). People draw pegs blind and then there are several ways that people change pegs across the 4 drives. Move two up: 1 goes to 3 goes to 5 goes to 7. Move up three: 1 goes to 4 goes to 7 goes to 2. Odds up 3, evens down 3, etc. 4 and 5 are considered the best ""pegs"" and 1 and 8 are considered the worst. The questions is this: How would you solve this problem trying to solve for two different parameters: 1) Everyone get an equal distribution of being at 4/5 and 1/8 or at least close to them such that no one is advantaged over the course of the four ""drives"" and everyone is equally in the center or on the ends. 2) People get to stand next to different people across the course of the day and not always next to the same people (the reason odds up and evens down was invented). No one particularly likes the current numbering system and many are looking for an alternative where you draw a number sequence as opposed to a number. (IE, you draw a card that has the ""peg"" order pre-determined for the 8 people - eg 3,1,5,7) Thanks for your help! :) Rand PS Someone tried to solve this problem previously and could only make it work with 9 ""pegs"" and not 8. See link - https://www.gunsonpegs.com/articles/shooting-talk/alternatives-to-moving-up-2-the-durnford-wheel","['combinatorial-designs', 'combinatorics']"
3039462,Example of norm on $\mathbb{R}^2$ that's NOT absolutely monotonic.,"We call a norm $\|\cdot\|$ on $\mathbb{R}^n$ absolutely monotonic if $$
|a_i| \leq |b_i|, i=1,\cdots,n \implies \|a\| \leq \|b\|.
$$ What's an example of norm on $\mathbb{R}^2$ that's not absolutely monotonic? This is an exercise left to the reader -- so presumably not too difficult. But it's giving me some trouble. The usual suspects that come to mind, i.e. the $\ell^p$ norms, $p \in [1,\infty]$ , are all absolutely monotonic.","['normed-spaces', 'real-analysis']"
3039466,How to sketch this Domain of triple integral,"i am having hard time sketching the domain of this : $$
\ \int_0^1\int_0^{1-x^2}\int_0^y f(x,y,z){dz}{dy}{dx} $$ is there an easy way to do that ? i got like cylinder and planes and its hard to see the Volume domain The question asking to sketch this "" simple "" domain","['integration', 'multivariable-calculus', 'real-analysis']"
3039528,"Proof verification for $\lim \inf x_n + \lim \sup y_n \le \lim \sup(x_n + y_n)$ for bounded $x_n, y_n$","Let $\{x_n\}$ and $\{y_n\}$ denote two bounded sequences. Prove that: $$
\lim \inf x_n + \lim \sup y_n \le \lim \sup(x_n + y_n) \\
$$ We know that both $x_n$ and $y_n$ are bounded hence is their sum: $$
m \le x_n + y_n < M
$$ Using that fact we may choose a subsequence in order to satisfy the following: $$
\lim(x_{n_k} + y_{n_k}) = \lim\sup(x_n + y_n) \tag1
$$ Since $x_{n_k}$ is bounded (as far as $x_n$ is) lets choose a convergent subsequence with indices $n^\prime_k \ge n_k$ such that: $$
\exists \lim x_{n^\prime_k}
$$ Now consider a sequence $y_{n^\prime_k}$ (note the index is $n^\prime_k$ ), since it is bounded we may choose a convergent subsequence from $y_{n^\prime_k}$ with indices $n^{\prime\prime}_k \ge n^\prime_k$ such that: $$
\exists\lim y_{n^{\prime\prime}_k}
$$ Since $\{x_{n^{\prime\prime}_k}\}$ is a subsequence of $\{x_{n^\prime_k}\}$ it is convergent to the same limit. Also $\{y_{n^{\prime\prime}_k}\}$ is a subsequence of $\{y_{n^\prime_k}\}$ and we've chosen $\{y_{n^{\prime\prime}_k}\}$ to be convergent. Based on that and on $(1)$ we may write: $$
\lim(x_{n^{\prime\prime}_k} + y_{n^{\prime\prime}_k}) = \lim(x_{n_k} + y_{n_k}) = \lim\sup (x_n + y_n)  \tag 2
$$ By definition of limsup and liminf: $$
\lim x_{n^{\prime\prime}_k} \ge \lim\inf x_n \\
\lim y_{n^{\prime\prime}_k} \le \lim\sup y_n
$$ Or (multiply second inequality by $-1$ ): $$
\lim x_{n^{\prime\prime}_k} \ge \lim\inf x_n \\
-\lim y_{n^{\prime\prime}_k} \ge -\lim\sup y_n
$$ Subtract the inequalities: $$
\lim x_{n^{\prime\prime}_k} + \lim y_{n^{\prime\prime}_k} \ge \lim\inf x_n + \lim\sup y_n \tag3
$$ Limit of sum is just a sum of limits so: $$
\lim(x_{n^{\prime\prime}_k} + y_{n^{\prime\prime}_k}) =\lim x_{n^{\prime\prime}_k} + \lim y_{n^{\prime\prime}_k}
$$ So now using $(2)$ and $(3)$ we conclude that: $$
\lim \sup(x_n + y_n) \ge \lim\inf x_n + \lim\sup y_n
$$ Is this argument enough to consider the proof complete?","['limsup-and-liminf', 'proof-verification', 'calculus', 'sequences-and-series', 'limits']"
3039554,Is not full rank matrix invertible?,Problem $A$ is a $4 \times 4$ matrix. It is known that $\text{rank}(A)=3$ . Is matrix A invertible ? Attempt to solve $\text{rank(A)}=3 \implies \det(A)=0$ which implies matrix is $\textbf{not}$ invertible. One dimension is lost during linear transformation if matrix is not full rank by definition. This implies determinant will be $0$ and that some information is lost in this linear transformation. Is my intuition behind this correct ?,"['matrix-rank', 'determinant', 'matrices', 'linear-algebra', 'linear-transformations']"
3039578,"Let $M$ be a smooth manifold. Can we say that $M - M = \{ n - m : n,m \in M\}$ is also a smooth manifold?","I was thinking about this for a while. The definition I use for the smooth manifold is the same as per Wikipedia . Let $\{(U_k,\phi_k)\}$ is a smooth atlas of $M$ . Then the natural atlas which was coming in my mind for $M-M$ was $\{(U_i - U_j, \phi_i - \phi_j)\}$ where $(\phi_i - \phi_j)(u)=\phi_i(u) - \phi_j(u) \; \forall u \; \in U_i - U_j$ . Is my approach correct? By $M - M$ I just mean formal difference of two sets where an element $x$ of $M-M$ can be written as $n-m$ for some $n,m \in M$ . Note that ""difference"" in $M-M$ has no meaning but I am seeking a suitable atlas for this set so that when I am in some $\Bbb R^n$ , I will do subtraction as per the addition is done in the group $\Bbb R^n$ . As a beginner in learning the subject, I am not confident in writing down the details. Thank you. EDIT: After a recent comment by @MikeMiller, I realized that I was actually working in $M \times M$ . So I thought to change my definition of $M - M$ . I see now $M - M$ as a set of equivalence classes where the equivalence relation is such that any to pairs $(m,n)$ and $(p,q)$ (or $m-n$ and $p-q$ ) are equivalent if we have a suitable atlas for $M-M$ such that in local coordinates, $m-n=p-q \in \Bbb R^n$ . The problem is I want to know whether such an atlas exists.","['manifolds', 'differential-topology', 'smooth-manifolds', 'differential-geometry']"
3039599,"What is $\int_{-\infty}^{\infty}\exp(\mathrm{i} n \cosh{x}) \, \mathrm{d}x$?","I'm hoping to determine the value of the following integral: $$\int_{-\infty}^{\infty}\exp(\mathrm{i} n \cosh{x}) \, \mathrm{d}x$$ Here is a plot of the integrand as a function of $x$ with parameter $n$ varying from 0 to 10. The integral appears to not converge. However, it is known that $$\int_{-\infty}^{\infty}\exp(\mathrm{i} n x) \, \mathrm{d}x = 2\pi \delta(n)$$ where $\delta(x)$ is the Dirac delta function. Is it possible for the first integral to be expressed similarly using Dirac delta notation?","['integration', 'definite-integrals', 'dirac-delta']"
3039664,"Prove tht $f(x) = x^{2}$ is uniformly continuous on $\bigcup_{n = 1}^{\infty} [n, n + 1/n^{3}]$.","How can I show that the function $f(x) = x^{2}$ is uniformly continuous on $\bigcup_{n = 1}^{\infty} [n, n + \frac{1}{n^{3}}]$ ? As $n \to \infty$ , I know that we get only all of the integers; however, the result doesn't make sense to me. I'm aware of both the sequential and $\epsilon-\delta$ definitions of continuity, but I didn't get anywhere with them.","['uniform-continuity', 'epsilon-delta', 'analysis', 'real-analysis', 'continuity']"
3039677,Free vs. bound variables in first order logic,"I am a little unclear about why the whole concept of free and bound variables. Shouldn't we be trying to bound every variable that appears in any statement of a formal proof? Otherwise what stops us from doing something like $k = \text{donut}$ or $k=\text{1/0}$ or $k=(\text{picture of a flower})$ if $k$ is not bound to some universe of discourse such as the set of natural numbers, or a specific set or range, etc? Under what circumstances would we ever use a free variable? To me it's like defining a useless concept such as ""Well when we use the addition operator + we usually put two numbers on either side, but if we don't, we consider it a 'free operator' because it's not adding anything."" Like if it's a useless concept, why have it? Why isn't it a requirement to just bind every variable whenever it's used or introduced? Do proof generally do this in practice where all variables are bound to some universe of discourse (which I assume means ""some defined set from which the variable belongs"").","['first-order-logic', 'proof-writing', 'logic', 'definition', 'elementary-set-theory']"
3039700,Stability of $y = \cos(2t)$ for the ode $y'' + 4y = 0$,"I want to examine the stability of the solution $\phi = \cos(2t)$ of the ode $y'' + 4y = 0$ . I know the general solution of this ode is $y = c_1 \cos(2t) + c_2 \sin(2t)$ . So to examine the stability of my solution, I need to see if other solutions stay close to it starting at $t = 0$ . It'll be asymptotically stable if other solutions converge to it. So, when $t = 0$ , $\phi(0) = \cos(0) = 1$ . and $\phi'(0) = -\sin(0) =0$ . But.. how do I pick $y(t)$ so that $y(0)$ starts out close to $1$ and $y'(0)$ is close to $0$ ? Then what? Well, $y(t) = 1$ when $t = 0$ and when $t = 0$ , $y'(0) = 1$ . I'm not sure how to proceed.",['ordinary-differential-equations']
3039715,Why are transformations always on the left side of the object?,"I'm doing some philosophy involving time evolution operators.  Thus I might have two operators $A$ and $B$ which operate in order on the state of the world, $x$ .  This might be written mathematically as $B(A(x))$ or in the multiplicative notation for groups and semigroups, $BAx$ . For time evolution, it is intuitive to write $xAB$ , as time evolves from left to right.  This is intuitive purely because of culture.  Obviously both are equally valid.  I merely need to define the operators with reversed multiplication tables. Why do we choose to define our transformation operators to always appear on the left side of the multiplication?  Is it merely because that's the order they appear in function composition, or is there something deeper?","['convention', 'functions']"
3039716,On an exercise in section 4 of Chapter I from Hartshorne's Algebraic Geometry,"It is about exercise 4.9: Let $X$ be a projective variety of dimension $r$ in $\mathbb{P}^n$ with $n\geq r+2$ . Show that for suitable choice of $P \notin X$ and a linear $\mathbb{P}^{n-1}\subseteq \mathbb{P}^n$ , the projection from $P$ to $\mathbb{P}^{n-1}$ induces birational morphism of $X$ onto its image $X' \subseteq \mathbb{P}^{n-1}$ . You will need (4.8A), (4.7A) and (4.6A). Here is my thinking: WLOG we can suppose that $X$ is an affine variety. The idea is that after a suitible change of coordinates, we can choose the hyperplane $H$ defined by $\lbrace x_n=0 \rbrace$ and take $P=(0,\dots,0,1)$ so that the projection is defined by $(x_1,\dots,x_n) \mapsto (x_1,\dots,x_{n-1},0)$ . We want to prove that the $k$ -algebra homomorphism \begin{align}
\frac{k[x_1,\dots,x_{n-1}]}{\mathcal{I}(X)\cap k[x_1,\dots,x_{n-1}]} & \hookrightarrow 
\frac{k[x_1,\dots,x_n]}{\mathcal{I}(X)} \\
x_i & \mapsto x_i
\end{align} induces an isomorphism of extensions of $k$ \begin{equation}
\phi:\text{Frac} \left( \frac{k[x_1,\dots,x_n]}{\mathcal{I}(X)\cap k[x_1,\dots,x_{n-1}]} \right) \rightarrow 
\text{Frac} \left( \frac{k[x_1,\dots,x_n]}{\mathcal{I}(X)} \right)
\end{equation} Now let $K$ be the field of rational fuctions of X. Reasoning as in Proposition 4.9 , it is possible to find a trascendence base such that, after changing coordinates, it is formed by rational functions $x_1,\dots,x_r \in K$ so that $K$ is a finite separable extension of $k(x_1,\dots,x_n)$ . Consider the following extensions: \begin{equation}
k \subseteq k(x_1,\dots,x_r,x_{r+1},\dots,x_{n-2}) \subseteq k(x_1,\dots,x_r,x_{r+1},\dots,x_{n-2})[x_{n-1},x_n]=K
\end{equation} the second one is a finite separable extension, so by (4.6A) there is a rational fuction $\alpha$ which generates K as an extension of $k(x_1,\dots,x_r,x_{r+1},\dots,x_{n-2})$ . Furthermore, there exist $f_1,f_2,g_1,g_2 \in k[x_1,\dots,x_n]$ such that \begin{equation}
\alpha = \frac{f_1(x_1,\dots,x_{n-2})}{g_1(x_1,\dots,x_{n-2})}x_{n-1} + \frac{f_2(x_1,\dots,x_{n-2})}{g_2(x_1,\dots,x_{n-2})}x_n
\end{equation} At this point, I would like to ask if there is some continuation in order to prove that $\phi$ is surjective. Thank you very much for your answers.","['extension-field', 'algebraic-geometry', 'projective-geometry']"
3039750,About the definition of coinduction of a module,"If $G$ is a group, $H$ a subgroup, and $N$ a left $\mathbb{Z}[H]-$ module, I've learned the following construction: $$\mathrm{coInd}_H^G(N) = \mathrm{Hom}_{\mathbb{Z}[H]}(\mathbb{Z}[G], N)$$ where $\mathbb{Z}[G]$ is given the structure of a left $\mathbb{Z}[H]$ -module setting $$h\cdot x = xh^{-1}$$ for every $x\in G$ and $h\in H$ .
Then one makes $\mathrm{coInd}_H^G(N)$ a left $\mathbb{Z}[G]$ -module declaring that for every $g\in G$ and $\varphi\in\mathrm{coInd}_H^G(N)$ $$(g\cdot\varphi)(x) = \varphi(g^{-1}x).$$ Is there some reason why we are taking all those inverses instead of just defining, in a way that looks more natural to me, the $H$ -structure on $\mathbb{Z}[G]$ setting $h\cdot x = hx$ and then the $G-$ structure on $\mathrm{coInd}_H^G(N)$ setting $(g\cdot\varphi)(x) = \varphi(xg)$ ? I think the two definitions are equivalent: if $\varphi\in\mathrm{coInd}_H^G(N)$ one can define $\psi:\mathbb{Z}[G]\to N$ such that $\psi(x) = \varphi(x^{-1})$ for every $x\in G$ . Now $\psi$ is an element of the coinduced module constructed following the second definition, and the map sending every $\varphi$ to the corresponding $\psi$ gives an isomorphism. Am I wrong? If not, why is the first definition preferred over the second?","['definition', 'abstract-algebra', 'representation-theory', 'modules']"
3039753,"Any two of the subsequences $\{a_{2k}\}, \{a_{2k+1}\}, \{a_{3k}\}$ converge do not imply $\{a_k\}$ converges?","If $\{a_k\}$ is a sequence, I have shown if the three subsequences $\{a_{2k}\}, \{a_{2k+1}\}, \{a_{3k}\}$ all converge, then the sequence converges. I am asked whether the sequence converges if only two of them converge. Any help will be appreciated. I first show the limits are the same. Let us assume $\lim a_{2k} = a, \lim a_{2k+1}=b, \lim a_{3k}=c$ . Then $\lim_{6k} = a = c$ and $\lim_{6k +3} = b = c$ . Now pick any $\varepsilon > 0$ , there are $N_1, N_2$ such that \begin{align*}
&|a_{2k} -a | < \varepsilon, \text{ if }2k \ge N_1, \\
&|a_{2k+1} -a | < \varepsilon, \text{ if }2k+1 \ge N_2.
\end{align*} So if $n \ge \max(N_1, N_2)$ , we get $|a_n -a| < \varepsilon$ .","['convergence-divergence', 'sequences-and-series']"
3039802,Coloured partitions,"I have $2n$ elements, $n$ of which are blue and the other $n$ are orange. Other than sharing a colour, they are distinct, i.e. each of those $2n$ objects is different and recognizable from any other. How many partitions are there such that in each subset there’s at least one blue element and there are at least two elements total? So, for example, a good partition would be {blue_1, blue_2} or {blue_1, orange_1} or {blue_5, orange_1, orange_3, orange_7} and a bad (i.e. the one I don’t want counted) one {blue_1} (because there’s only one element), or {orange_3, orange_11} (because there’s no blue one). I tried to approach this first by starting with Bell number and subtracting, but that lead me nowhere. Then I started anew, trying to get a recurrence relation. Obviously, $X_2 = 1$ , because the only partition one can get is {blue_1, orange_1}. Then, if I already had $X_{2n - 2}$ partitioned, I could: Keep things as-is and add a new pair as another subset—one option for each previous partition. Add {blue_n, orange_n}, as a pair, to any pre-existing subset—the number of subsets for each partition; but I don’t know how many those are . Add {blue_n} to one subset and {orange_n} to another—and again, while I know it’s $\binom{x}{2}$ for each partition with $x$ subset, I don’t know how to write that in a useful way. Some other solutions, created by taking blue_n and adding pre-existing oranges to it (because now it can create a valid partition)—but here I am not even sure how much that would be, maybe somewhere around $B_{2n - 2}$ ? I have created a small Python script to calculate a few first values. It shows $X_2 = 1, X_4 = 3, X_6 = 28, X_8 = 433, X_5 = 9461$ . Unfortunatelly, there’s no such sequence on OEIS.","['set-partition', 'combinatorics', 'discrete-mathematics', 'recreational-mathematics', 'problem-solving']"
3039839,Number of subgraphs of a triangle,"I'm having difficulty finding the number of subgraphs of a triangle... the solutions of the textbook I'm using says the answer is $18$ , but I am counting $17$ in the following way: $$\binom{3}{1}\cdot 2^{\binom{0}{2}} + \binom{3}{2}\cdot 2^\binom{2}{2} + \binom{3}{3}\cdot 2^\binom{3}{2} = 17\,,$$ since there are $\binom{0}{2}=0$ edges total one can place in a graph with $1$ vertex, etc. I am not sure if I am using the right method to count, since I am counting one less than what the answer is supposed to be. Any help would be appreciated!","['graph-theory', 'proof-verification', 'combinatorics', 'discrete-mathematics']"
3039847,"Is $\sum _{n=1} ^ \infty \frac{1}{(x+\pi)^2 \cdot n^2 }$ uniformly convergent on $(-\pi , \pi)$?","Is this series uniformly convergent on $(-\pi , \pi)$ : $$\sum _{n=1} ^ \infty \frac{1}{(x+\pi)^2 \cdot n^2 }\,?$$ My Attempt: If the series were convergent we would have got a natural number $k$ for a fixed $\epsilon>0$ such that $\sum _{n=k} ^ \infty \frac{1}{(x+\pi)^2 \cdot n^2 } < \epsilon$ for all $x \in (-\pi , \pi)$ .  But for this case we will get the term $f_n$ in the summation greater than $1$ for $-\pi + 1/n$ .
 So for every $n$ we will get a $x\in (-\pi , \pi) $ such that summation at $x$ is greater than $1$ . That's why the series is not uniformly convergent on $(-\pi , \pi)$ . Can somebody please tell me if I have gone wrong anywhere?","['analysis', 'real-analysis', 'uniform-convergence', 'sequences-and-series', 'convergence-divergence']"
3039866,Show that the $L^{p}$ norm $\|f\|_{L^{p}} := \big( \int^{b}_{a} |f(x)|^p\big)^{1/p}$ is not induced by a scalar product for $p \neq 2$.,"On $X = C^0\big([a,b]\big)$ , for any $p \in \mathbb{R}$ , $p>1$ , we define the $L^p$ norm by, $$\|f\|_{L^{p}}:=\big(\int^{b}_{a}|f(x)|^{p}dx \big)^{1/p}.$$ Show that for $p\neq 2$ , this norm is not induced by a scalar product. My method of trying to prove this was to prove a contradiction to the parallelogram rule, $$  \|f+g\|^{2}_{p} + \|f-g\|^{2}_{p} = 2\|f\|^{2}_{p} + 2\|g\|^{2}_{p}, \tag{$1$}$$ where $f,g \in C^{0}([a,b])$ . So I defined the following functions; $$f(x):=\frac{a+b}{2}-x$$ $$g(x) := \begin{cases}\frac{a+b}{2}-x, \ \ for \ \ a \leq x \le \frac{a+b}{2}. \\
x-\frac{a+b}{2}, \ \ for \ \ \frac{a+b}{2} < x \le b \end{cases}$$ which gives $$f(x)+g(x) = \begin{cases} a+b-2x, \ \ & for \ \ a\le x \le \frac{a+b}{2}. \\ 0, & for \ \ \frac{a+b}{2} < x \le b\end{cases}$$ $$f(x)-g(x) = \begin{cases} 0, & for \ \ a \le x \le \frac{a+b}{2}. \\
2x - (a+b), \ \ & for \ \ \frac{a+b}{2} < x \le b \end{cases}$$ Then I proceeded to calculate each term of the parallelogram rule, $$\|f+g\|^{2}_{p} = \bigg( \int^{\frac{a+b}{2}}_{a}|a+b-2x|^{p}\bigg)^{2/p} = \frac{(b-a)^{\frac{2(p+1)}{p}}}{(2(p+1))^{2/p}} $$ $$ \|f-g\|^{2}_{p} = \bigg( \int_{\frac{a+b}{2}}^{b}|2x- (a+b)|^{p}\bigg)^{2/p} = \frac{(b-a)^{\frac{2(p+1)}{p}}}{(2(p+1))^{2/p}}$$ $$2\|f\|^{2}_{p} = 2 \bigg( \int^{b}_{a}| \frac{a+b}{2}-x|^{p} dx \bigg)^{2/p} = 2 \cdot \frac{2^{2/p}(\frac{b-a}{2})^{\frac{2(p+1)}{p}}}{(p+1)^{2/p}} $$ $$\begin{align}2 \|g\|^{2}_{p}  & = 2 \bigg(\int^{\frac{a+b}{2}}_{a} |\frac{a+b}{2} - x|^{p} dx \ + \ \int^{b}_{\frac{a+b}{2}}|x- \frac{a+b}{2}|^{p} dx\bigg)^{2/p} \\  & =2 \cdot \frac{2^{2/p}(\frac{b-a}{2})^{\frac{2(p+1)}{p}}}{(p+1)^{2/p}} \end{align}$$ Plugging into $(1)$ we then get $$2 \cdot \frac{(b-a)^{\frac{2(p+1)}{p}}}{(2(p+1))^{2/p}} = 4 \cdot \frac{2^{2/p}(\frac{b-a}{2})^{\frac{2(p+1)}{p}}}{(p+1)^{2/p}}$$ which simplifies quite nicely to $$2^{p} = 4.$$ So the equality only holds for $p = 2$ . Is what i've done correct? is there another way of proving the question which is better?","['inner-products', 'proof-verification', 'normed-spaces', 'lp-spaces', 'functional-analysis']"
3039874,Evaluate$\int\limits_0^1 [\log(x)\log(1-x)+\operatorname{Li}_2(x)]\left[\frac{\operatorname{Li}_2(x)}{x(1-x)}-\frac{\zeta(2)}{1-x}\right]\mathrm dx$,"The following is from Mathematical Analysis $-$ A collection of Problems by Tolaso J. Kos $($ Page $27$ , Problem $282$$)$ $$\mathfrak{I}=\int\limits_0^1 \left[\log(x)\log(1-x)+\operatorname{Li}_2(x)\right]\left[\frac{\operatorname{Li}_2(x)}{x(1-x)}-\frac{\zeta(2)}{1-x}\right]\mathrm dx=4\zeta(2)\zeta(3)-9\zeta(5)\tag1$$ Today I came across this question asking for the evaluation of the integral $$\mathfrak{J}=\int\limits_0^{\pi/2}\frac{\log^2(\sin x)\log^2(\cos x)}{\sin x\cos x}\mathrm dx=\frac12\zeta(5)-\frac14\zeta(2)\zeta(3)\tag2$$ Which can done be ""rather simple"" by invoking the fourth derivative of the Beta Function. The final structure of the result reminded me of the logarithmic integral $(1)$ I was not able to evaluate. It might turn out that this relation is by pure chance but nevertheless it motivated me to look at $(1)$ again. It is hardly probable that $(1)$ can be done in a similar way like $(2)$ in xpaul 's answer to the linked question due the involved Dilogarithms $-$ but anyway you can prove me wrong. I have not got that far with $(1)$ but, however, I noticed two, I would say quite interesting, facts about the integral. First, consider the following, well-known functional relation of the Dilogarithm $$\operatorname{Li}_2(x)+\operatorname{Li}_2(1-x)=\zeta(2)-\log(x)\log(1-x)$$ which can be used in order to get rid of the $\log(x)\log(1-x)$ -term within $(1)$ and leading to $$\small\int\limits_0^1 \left[\log(x)\log(1-x)+\operatorname{Li}_2(x)\right]\left[\frac{\operatorname{Li}_2(x)}{x(1-x)}-\frac{\zeta(2)}{1-x}\right]\mathrm dx=\int\limits_0^1 \left[\zeta(2)-\operatorname{Li}_2(1-x)\right]\left[\frac{\operatorname{Li}_2(x)}{x(1-x)}-\frac{\zeta(2)}{1-x}\right]\mathrm dx$$ Second, applying the substitution $x=1-x$ after a minor reshape yields to $$\small\begin{align}
\int\limits_0^1 \left[\zeta(2)-\operatorname{Li}_2(1-x)\right]\left[\frac{\operatorname{Li}_2(x)}{x(1-x)}-\frac{\zeta(2)}{1-x}\right]\mathrm dx&=\int\limits_0^1 \left[\frac{\zeta(2)}{1-x}-\frac{\operatorname{Li}_2(1-x)}{1-x}\right]\left[\frac{\operatorname{Li}_2(x)}x-\zeta(2)\right]\mathrm dx\\
&=\int\limits_0^1 \left[\zeta(2)-\operatorname{Li}_2(1-x)\right]\left[\frac{\operatorname{Li}_2(x)}x-\zeta(2)\right]\frac{\mathrm dx}{1-x}\\
&=\int\limits_0^1 \left[\zeta(2)-\operatorname{Li}_2(x)\right]\left[\frac{\operatorname{Li}_2(1-x)}{1-x}-\zeta(2)\right]\frac{\mathrm dx}x\\
&=\int\limits_0^1 \left[\frac{\zeta(2)}x-\frac{\operatorname{Li}_2(x)}x\right]\left[\frac{\operatorname{Li}_2(1-x)}{1-x}-\zeta(2)\right]\mathrm dx
\end{align}$$ I want to point out the quite interesting one could say ""almost""-symmetry of the two integrals $$\begin{align}
\mathfrak{I}_1&=\int\limits_0^1 \left[\frac{\zeta(2)}{1-x}-\frac{\operatorname{Li}_2(1-x)}{1-x}\right]\left[\frac{\operatorname{Li}_2(x)}x-\zeta(2)\right]\mathrm dx\\
\mathfrak{I}_2&=\int\limits_0^1 \left[\frac{\zeta(2)}x-\frac{\operatorname{Li}_2(x)}x\right]\left[\frac{\operatorname{Li}_2(1-x)}{1-x}-\zeta(2)\right]\mathrm dx
\end{align}$$ which might be helpful for the actual evaluation. But from hereon I have no clue how to continue. Just expanding the brackets out does not seem like a good idea to me. Since one the one hand it is not elegant at all and on the other hand it would lead to to the term $\operatorname{Li}_2(x)\operatorname{Li}_2(1-x)$ for which I have no idea how to deal with (I am not that confident using double series). I also tried various ways of IBP but this seems to be pointless since all variations ended up in producing a divergent term $-$ unless I have missed a special choice of $u$ and $\mathrm v$ . I have not figured out a suitable substitution nor an appropriate newly introduced parameter (for the application of Feynman's Trick) and the I do not know whether a series expansion would be helpful or not (connected with this issue is the possibility of a double summation with which I cannot really deal). Thus, I am asking for the closed-form evaluation of $(1)$ hopefully equal to the given value (which works out numerically according to WolframAlpha). Even though I have troubles with double series I would accept an answer invoking these but I would appreciate a solution without involving them. As this integral appeared within a collection of Analysis Problems I am quite sure that it has been already evaluated somewhere (maybe even here on MSE where I was not able to find it!). Thanks in advance!","['integration', 'definite-integrals', 'polylogarithm', 'closed-form', 'riemann-zeta']"
3039888,Example of a non-trace class operator,"Let $H$ be a complex Hilbert space.
For an operator $T: H \rightarrow H$ fix an orthonormal basis and define the ""absolute value"" of $T$ as $$|T| = (TT^{*})^{\frac{1}{2}}$$ We say that the operator is a trace-class operator, if $\text{tr}(|A|) < \infty$ , i.e. $$\sum{\langle |A|e_{i}, e_{i} \rangle}  < \infty$$ for some $\{ e_{i} \}$ (and thus any) basis in $H$ Here $\langle \cdot, \cdot \rangle$ stands for the inner product on $H$ ). What i know is that there exists a chain of inclusions: $$ \{ \text{finite rank operators} \} \subset \{ \text{trace class} \} \subset \{ \text{compact} \}$$ Is there is an example of an operator $S: H \rightarrow H$ such that for some basis $\{ e_{i} \}$ in $H$ the following sum $$ \sum{\langle Se_{i}, e_{i} \rangle} < \infty$$ converges, but the operator is not a trace-class? I can provide the following ""counterexample"":
Let $H = L^{2}([0, 1])$ with basis $ \{ e^{i n x} \} $ and consider the operator $T$ that maps $$ e^{i n x} \mapsto \frac{1}{n^{3}} \frac{d}{dx}(e^{i n x})$$ In fact it is a composition of operators $L^{2} \rightarrow l^{2} \rightarrow l^{2}$ , where the first arrow stands for the derivative operator and the second one multiply each element $a_{n}$ of the sequence by $\frac{1}{n^{3}}$ . One can show that this operator is not compact (is it true? it should, since the derivative operator is not compact and the second arrow does not help to make the image of a non precompact set precompact). I claim that $\sum{\langle T (e^{inx}), e^{inx} \rangle} < \infty$ , since the series $\sum{\frac{1}{n^{2}}} < \infty$ , but the operator is not trace-class, since otherwise it would be compact. Do the mentioned reasoning fail to be correct? If yes, how one can fix the details in order to provide a correct counterexample? Are there any others examples that met the requirements?","['operator-theory', 'fourier-analysis', 'functional-analysis', 'compact-operators']"
3039910,Find all matrices which satisfy $M^2-3M+3I = 0$,"I am trying to find all matrices which solve the matrix equation $$M^2 -3M +3I=0$$ Since this doesn't factor I tried expanding this in terms of the coordinates of the matrix.  It also occurs to me to put it into ""vertex"" form: $$M^2 - 3M + \frac{9}{4}I+\frac{3}{4}I=0$$ $$(M-\frac{3}{2}I)^2 = -\frac{3}{4}I$$ but this doesn't look much better. What I found from expanding by coordinates was, if $M=\pmatrix{a & b \\ c & d}$ then $$\pmatrix{a^2+bc -3a + 3& ab + bd - 3b \\ ac+cd-3c & bc+d^2-3d+3} = \pmatrix{0&0\\0&0}$$ From the off-diagonal entries I get that either $$a+d-3=0$$ or $$b=c=0$$ If $a+d-3\not=0$ then $a^2-3a+3=0$ and likewise for $d$ .  Then we get more cases for $a$ and $d$ . If $a+d-3=0$ the upper-left is unchanged and the lower-right is $$bc + (3-a)^2-3(3-a)+3 = 0$$ which simplifies to the same thing from the upper-left and so is redundant.  In the off-diagonals $$ac+c(a-3)-3c = 0 \Rightarrow $$ $$2ac-6c = 0$$ We again get cases, and I suppose after chasing cases enough you get the solution set. However, it just feels like this can't be the intended solution given how tedious and uninformative all of this case-chasing is.  Is there some bigger idea I'm missing?","['examples-counterexamples', 'matrices', 'minimal-polynomials', 'linear-algebra', 'matrix-equations']"
3039913,"What is a ""linear function"" in the context of multivariable calculus?","On Wikipedia , it says When $f$ is a function from an open subset of $\mathbb{R}^n$ to $\mathbb{R}^m$ , then the directional derivative of $f$ in a chosen direction is the best linear approximation to f at that point and in that direction. I just want to check that linear functions from $\mathbb{R}^n$ to $\mathbb{R}^m$ , are defined as functions of the form $f(x) = ax+b$ where $a$ is a scalar and $b$ is a vector? Also, it seems like functions of the form above just enlarge/shrink and shift. Is this correct? I thought that if anything was going to be a counterexample, it was going to be an off center circle; under the transformation x $\mapsto$ 2x , I thought an off-center circle might map to an ellipse; but this doesn't seem to be the case. For example, if $(x, y)$ satisfies $(x-2)^2 + (y-2)^2 = 1$ , then multiplying both sides by $2^2$ gives $(2x-4)^2 + (2y-4)^2 = 4$ ; so $(2x, 2y)$ satisfies $(X^2-4)^2 + (Y-4)^2 = 4$ , which is still a circle with center at $(4, 4)$ , as expected.","['multivariable-calculus', 'analysis', 'real-analysis']"
3039914,Finding approximation to stable manifold of saddle point,"I am stuck on the following exercise from Strogatz' book on dynamical systems (exercise 6.1.14). Consider the system $\dot{x} = x+e^{-y}, \dot{y} = -y$ . This system
  has a single fixed point, $(-1, 0)$ . This is a saddle point. The
  unstable manifold is $y=0$ , but the stable manifold is some non-linear
  curve. Let $(x, y)$ be a point on the stable manifold close to $(-1,
> 0)$ and define $u = x + 1$ . Write the stable manifold as $y=a_1u +a_2u^2 + O(u^3)$ . To determine the coefficients, derive two
  expressions for $dy/du$ and equate them. I have, as a first try for an equation, simply differentiated $y$ wrt $u$ : $\frac{dy}{du} = a_1 + 2a_2u + O(u^2)$ , where I'm a bit uncertain about the $O(u^2)$ , but I suspect we can leave that out anyway, since we're approximating. I'm not sure how we'd find a second equation. I've found a post that answers the same question , but it ends up with a line, rather than the non-linear curve that is pictured in the book: Furthermore, I don't see why they have $\frac{dy}{du} = \frac{\dot{y}}{\dot{u}}$ or how they calculated the Taylor approximation for $\dot{u}$ . Basically, I'm a bit lost, could someone perhaps give me some hints?","['taylor-expansion', 'ordinary-differential-equations', 'dynamical-systems']"
3039922,Linear Discriminant Analysis: Meaning of Negative Eigenvalues?,"In Linear Discriminant Analysis (LDA) we compute two matrices from the data: the between scatter matrix $\boldsymbol{S}_b$ and within scatter matrix $\boldsymbol{S}_w$ . A direction $\boldsymbol{w}$ is then considered more discriminative if $(\boldsymbol{w}^T \boldsymbol{S}_b \boldsymbol{w})/(\boldsymbol{w}^T \boldsymbol{S}_w \boldsymbol{w})$ is larger. Therefore, the most $k$ discriminative directions correspond to the top $k$ eigenvectors of the matrix $\boldsymbol{S}_b \boldsymbol{S}_w^{-1}$ . While the two scatter matrices $\boldsymbol{S}_b$ and $\boldsymbol{S}_w$ are positive semi-definite, the matrix $\boldsymbol{S}_b \boldsymbol{S}_w^{-1}$ does not have to be. So I wonder what is the meaning/intuition of negative eigenvalues in this case? This question arose when I wanted to choose the number $k$ based on what percentage of discriminative information is preserved by the top $k$ eigenvectors. For example, in case of PCA, I could say I want to pick the top $k$ eigenvectors that maintain $90\%$ of the variance, i.e. $(\sum_{j=1}^k \lambda_j)/(\sum_{j=1}^n \lambda_j) \approx 0.9$ ( $n$ being the total number of eigenvalues). However, if negative eigenvalues can exist in LDA, how should I modify the PCA idea to achieve similar goal? Should I use $(\sum_{j=1}^k \lambda_j)/(\sum_{j=1}^n \lambda_j) \approx 0.9$ , or $(\sum_{j=1}^k \lambda_j)/(\sum_{j=1}^{n^+} \lambda_j) \approx 0.9$ ( $n^+$ meaning sum over nonnegative eigenvalues only), or $(\sum_{j=1}^k \lambda_j)/(\sum_{j=1}^{n} |\lambda_j|) \approx 0.9$ , or none of these? Thanks Golabi","['machine-learning', 'statistics']"
3039931,Gradient of Square of Quadratic Inner-Product,"\begin{equation}
\begin{aligned}
f(x) :=&   {\langle}x,Ax{\rangle}^2\\
=& x^{T}Axx^{T} Ax\\
& x \in \mathbb{R}^n,\\
& A \in \mathbb{R}^{n \times n}, \;A = A^T.
\end{aligned}
\end{equation} The 2nd answer is the generalization + example code to validate.","['derivatives', 'linear-algebra']"
3039973,How is the eccentricity of a circle equal to zero?,"According to many websites, including Wikipedia, the eccentricity of a conic section is defined as the ratio of (the distance from a fixed point called the focus) to (the distance from a fixed line called the directrix). How is this definition applicable to circles? What are the focus and directrix? Are they the center and a tangent line to the circle? In that case, the eccentricity should not be zero, it should be undefined, as far as my intuition goes.","['analytic-geometry', 'circles', 'geometry']"
3040003,Newtonian potential expansion identity,"Preliminaries Consider the Newtonian potential $$\frac{1}{|\vec x - \vec y|}$$ with $\vec{x}, \vec{y} \in \mathbb{R}^3$ and $|\vec{x}| = x > y = |\vec{y}|$ . Its Taylor expansion is given by $$\frac{1}{|\vec x - \vec y|} = \sum_{n=0}^\infty \frac{(-1)^n}{n!} (\vec{y} \cdot\vec{\nabla}_\vec{x})^n \frac{1}{x},$$ which can also be written in terms of Legendre polynomials as $$\frac{1}{|\vec x - \vec y|} = \sum_{n = 0}^\infty P_n (\hat{x} \cdot \hat{y}) \frac{y^n}{x^{n+1}}.$$ The key identity here is $$\frac{(-1)^n}{n!} (\vec{y} \cdot\vec{\nabla}_\vec{x})^n \frac{1}{x} = P_n (\hat{x} \cdot \hat{y}) \frac{y^n}{x^{n+1}}$$ Using the key identity twice, we have $$\frac{(-1)^n}{n!} (\vec{y} \cdot\vec{\nabla}_\vec{x})^n \frac{1}{x} = P_n (\hat{x} \cdot \hat{y}) \frac{y^n}{x^{n+1}} = \left(\frac{y}{x}\right)^{2n+1}  P_n (\hat{x} \cdot \hat{y}) \frac{x^n}{y^{n+1}} = \left(\frac{y}{x}\right)^{2n+1} \frac{(-1)^n}{n!} (\vec{x} \cdot\vec{\nabla}_\vec{y})^n \frac{1}{y}.$$ The Question Is there a way to prove the identity $$\boxed{(\vec{y} \cdot\vec{\nabla}_\vec{x})^n \frac{1}{x} = \left(\frac{y}{x}\right)^{2n+1} (\vec{x} \cdot\vec{\nabla}_\vec{y})^n \frac{1}{y}}$$ directly, i.e., without resorting to Legendre polynomials?","['legendre-polynomials', 'alternative-proof', 'multivariable-calculus', 'taylor-expansion', 'potential-theory']"
3040015,Estimate number of cards needed to be drawn from deck before full house,"Imagine we have a well-shuffled deck of cards and we keep drawing cards until there is at least one full house in the drawn cards. How many cards will we draw on average? I would be interested in both the exact solution (which is something around 12) but, more importantly, in a good quick way of estimating this value.","['puzzle', 'card-games', 'probability']"
3040068,"What is the probability $X + Y > 100$? $X,Y \sim U[40,80]$","I'm struggling to write out the integral for this. Both $x$ and $y$ are i.i.d. distributed uniformly over $[40,80]$ . I think it should be of the form $\int_{40}^{80} \int_{100-x}^{80} \frac{1}{40\times40}dy~dx$ but this evaluates to $1$ ? Thanks for your help!","['probability-distributions', 'uniform-distribution', 'probability-theory', 'probability']"
3040105,Understanding the structure of a group through its decomposition in normal subgroups,"I am confused with a basic fact in group theory. ''Given a finite group $G,$ one can find a sequence of subgroups $$G=H_0\lhd H_1\lhd H_2 \cdot \cdot  \cdot \cdot \lhd H_r = \{e\}$$ and such that $H_{k+1}/H_k$ is simple.''
Since one talks about a group in general terms, then the statement must hold also for a simple group,whereby the sequence will be trivial. But in the case $G$ is not simple, by definition it must be solvable and the statement must hold again. But then we read another statement in algebra books: ''Given the finite group $G,$ it is solvable if one can find a sequence of subgroups $$G=H_0\lhd H_1\lhd H_2 \cdot \cdot  \cdot \cdot \lhd H_r = \{e\}$$ and such that $H_{k+1}/H_k$ is abelian.'' To my understanding, since the second statement is more specific than the first one, one would conclude that the abelian groups $H_{k+1}/H_k$ as stated in the second statement are simple (in which case they will be isomorphic to cyclic groups of prime order), something that is not stated in books. At the other hand, since the first statement must be true also for solvable groups, we must conclude that the simple group $H_{k+1}/H_k$ must be abelian in the case of a solvable group. Can somebody comment on my conclusions and say what is wrong or true. Which statement implies which one, or, are they equivalent in the case of solvable groups ? One also reads in algebra books (I quote here Lang's book) the following: ''such a sequence already gives information about $G$ . To get a full knowledge of $G$ , one would have to know how these factor groups are pieced together.'' Can somebody explain through an example, what knowledge of $G$ we get through such a sequence and how to proceed to piece the factor groups together. Many thanks.","['group-theory', 'abstract-algebra']"
3040128,Probability of Winning Coin Tosses - Variable Number of Games,"Hillary and Trump play a game of coin toss. The coin is fair such that $\mathrm{Pr}(x=H) = \mathrm{Pr}(x=T) = 0.5$ . If it gets a Head (H), Hillary wins, otherwise, Trump wins. They agree in advance that the first player who has won $3$ rounds will collect the entire prize. Coin flipping, however, is interrupted for some reason after $3$ rounds and they got $1$ Head and $2$ Tails. Suppose that they continue to toss the coin afterwards, what is the probability that Henry Hillary will win the entire prize? I saw this question also on Chegg and I got the correct answer, but I drew a tree of the rest of the remaining outcomes. We get: 3T, 3HT, and 3HH. Hillary winning would be HH, so $\mathrm{Pr}(HH) = 3/9 = 1/3$ . But I want to know the proper way to do this problem. For example, what formula is used? The second the coin changed to be biased, I have no idea what to do. In addition, how would you derive the solution is the coin is biased? Ex: Pr(x=H)=0.75? I believe this is an Expected Value problem...looked through some other questions and I couldn't quite figure out the solution. Any solutions or links to duplicate questions (with solutions) would be great. Thank you in advance! P.S. I saw this question but it didn't quite help me... Fair and Unfair coin Probability","['expected-value', 'statistics', 'probability']"
3040138,What is rule for when solving algebraic equations?,"I'm a high school student trying to get critical intuition when learning algebraic equation solving. For $x$ any complex number and $c$ constant, simple polynomial such as $x^n -c=0$ are easily solvable for $x$ . Then if we know how to solve polynomial $g(x)=k$ for any constant $k$ we can now solve more complex polynomial $[g(x)]^n -c=0$ . Hence we say Quadratic polynomial is solved when we deform it into $a(x-p)^2 -q=0$ since linear polynomial is solvable. The reason for doing this when solving polynomials is because our intuition can only do linear calculations and fails to do calulations of ""higher complexity"" directly. (I cant find sufficient word to describe this) e.g. $ab=1$ implies $a=b^{-1}$ and $a+b=0$ implies $a=-b$ but $a^2 + b^2 +ab=0$ is whole new stuff. Further from polynomials, I think algebra is all about deforming equations into reasonably simpler form and deciding if such progress is doable. Am I making things right?",['algebra-precalculus']
3040185,$\int_{-\infty}^{\infty}\frac{\mathrm{d}x}{ax^2+bx+c}=\pi$ similar identities,"I recently found that $$\int_{-\infty}^{\infty}\frac{\mathrm{d}x}{ax^2+bx+c}=\pi$$ iff $$b^2-4ac=-4.$$ I found it by integrating $$I=\int_{-\infty}^{\infty}\frac{\mathrm{d}x}{ax^2+bx+c}.$$ If the reciprocal of the function is to be integrated over the entire real line, then the function must not have any real zeros. This implies that $$b^2-4ac<0$$ With this in mind, we complete the square: $$I=\int_{-\infty}^{\infty}\frac{\mathrm{d}x}{a(x+\frac{b}{2a})^2+c-\frac{b^2}{4a}}.$$ Then setting $g=c-\frac{b^2}{4a}$ , and $x+\frac{b}{2a}=\sqrt{\frac{g}{a}}\tan u$ , $$I=\sqrt{\frac{g}{a}}\int_{-\pi/2}^{\pi/2}\frac{\sec^2u\ \mathrm{d}u}{g\tan^2u+g}=\frac{\pi}{\sqrt{ag}}.$$ So our identity holds for $$ag=1.$$ And with a little algebra, $$b^2-4ac=-4.$$ So my question is, are there any other similar identities involving other famous constants? Cheers!","['integration', 'big-list', 'improper-integrals', 'real-analysis']"
3040191,Flat but not very flat families,"I'm doing an exercise in Hartshorne's Algebraic Geometry , Ex 9.5 in Chapter III,  whose part (a) states the following: Given an example to show that if $\{X_t\}$ is a flat family of closed subschemes of $\mathbb{P}^n$ , then the projective cone $\{C(X_t)\}$ need not be a flat family in $\mathbb{P}^n$ . Since we can determine flatness by Hilbert polynomials. I want to use the dimension  formula $dim((S_t/I_t)[x])_d = \sum_{i = 0}^{d}dim(S_t/I_t)_i$ , to construct a family with same Hilbert polynomial but have different dimension in lower degrees. This turned out to be some special example of flat but not very flat families related to the remaining part of this exercise, but I failed in finding such counter examples.",['algebraic-geometry']
3040201,Let $g(k)$ be the greatest odd divisor of $k$ show that $ 0< \sum_{k=1}^n \frac {g(k)}{k} - \frac {2n}{3} \lt \frac 23$,"Prove that for all positive intergers $n$ , $$ 0< \sum_{k=1}^n  \frac {g(k)}{k} - \frac {2n}{3} < \frac {2}{3}$$ Where $g(k)$ denotes the greatest odd divisor of $k$ . Here's my try: All numbers $k$ can be written as $k= 2^ts$ , for nonnegative $t$ and odd $s$ , therefore if $k= 2^ts$ , then $\frac {g(k)}{k} = \frac {1}{2^k}$ i.e $\frac {g(k)}{k}$ is equal to $1$ divided by the highest power of $2$ dividing $k$ . I first thought of proving the inequality for $k= 2^n (n>1)$ . Let $Q= \sum_{k=1}^{2^n}  \frac {g(k)}{k}$ , then: $$Q = \frac {1}{2}q_1 +\frac {1}{2^2}q_2 + \cdots + \frac {1}{2^{n -1}} q_{2^{n -1}}+  \frac {1}{2^n} q_{2^n}+ 2^{n-1} $$ . $q_i$ is the number of times $\frac {1}{2^i}$ is added in the summation. It's easy to notice that $q_{2^n} =1$ . $q_i$ for $0< i < 2^n$ would be equal to $2^{n-1-i}$ (comes from this $(2^i)(2(2^{n-1-i})-1)$ ). Then: $$Q= 2^{n-1}+ \frac {1}{2^n} + \sum_{i=1}^{n-1}  \frac{1}{2^i} \cdot 2^{n-1-i}  $$ $$Q = 2^{n-1}+ \frac {1}{2^n} + 2^{n-1} \sum_{i=1}^{n-1}  (\frac{1}{4})^i  $$ EDITED With some algebra we get that: $$Q - \frac {2}{3} \cdot 2^n= - \frac {4}{3} \cdot 2^{n-1} + 2^{n-1}+ \frac {1}{2^n} + 2^{n-1} \cdot \frac {4^{n-1}-1}{4^{n-1}} \cdot \frac {1}{3} <  \frac {1}{2^n} < \frac {2}{3} $$ Also: $$ Q - \frac {2}{3} \cdot 2^n = \frac {1}{2^n} - \frac {2^{n-1}}{4^{n-1}} \cdot \frac {1}{3}= \frac {1}{2^n} - \frac {1}{2^{n-1}} \cdot \frac {1}{3}> \frac {1}{2^n} - \frac {1}{2^{n-1}} \cdot \frac {1}{2}= 0$$ Then I would get: $$ 0< Q - \frac {2}{3} \cdot 2^n < \frac {2}{3}$$ Well, I thought proving the inequality for $k=2^n$ because I had some idea about how many times the powers of $2$ appeared. I then thought that I could go backwards with induction but I'm stuck. I would like to see some other approaches but I would also like to know if it's possible to solve the problem from the point where I am. I'll appreciate any hints or help, thanks in advance.","['divisibility', 'number-theory', 'analytic-number-theory', 'sequences-and-series', 'inequality']"
3040258,Is there any two variable function which has no representation of the form $\sum\limits_{n=1}^{\infty} f_n(x)g_n(y)$?,"Is there any function $f:\Bbb R^2\to\Bbb R$ which has no representation of the form below? $$f(x,y)=\sum_{n=1}^{\infty} g_n(x)h_n(y)\quad(x,y\in \Bbb R).$$ Editor's note: A possible source of motivation for this question lies in a trick used to find solutions to linear partial diferential equations, in particular Laplace's equation in two dimensions. As a first step, a solution of the form $f(x,y)=g(x)h(y)$ is sought; and then more-general solutions of the form displayed above can be generated. While it is far from obvious that all solutions to the 2-D Laplace equation must be of this form, it is also hard to find a counterexample, namely a solution that cannot be thus structured. (Indeed, is such a solution known at all?) If we relax the conditions so as not to require even continuity of $f$ (let alone its being a solution of Laplace's equation), then there is in principle more room to find a counterexample. Thus it seems that the question posed above may be answerable. In fact, while this editor is unable to come up with a counterexample, his (admittedly unreliable) intuition says that there probably is one and that the answer is yes.",['real-analysis']
3040278,Value of $\lim_{n \to \infty}\frac{\sqrt{1}+\sqrt{2}+\sqrt{3}+\cdots+\sqrt{n-1}}{n\sqrt{n}}$,"Evaluate $$\lim_{n \to \infty}\dfrac{\sqrt{1}+\sqrt{2}+\sqrt{3}+\cdots+\sqrt{n-1}}{n\sqrt{n}}.$$ I am trying to use the Sandwich principle here.. $\lim_{n \to \infty}\dfrac{\sqrt{1}+\sqrt{2}+\sqrt{3}+\cdots+\sqrt{n-1}}{n\sqrt{n}}=\lim_{n \to \infty}\dfrac{\sqrt{\dfrac{1}{n}}+\sqrt{\dfrac{2}{n}}+\sqrt{\dfrac{3}{n}}+\cdots+\sqrt{\dfrac{n-1}{n}}}{n}\ge \lim_{n \to \infty}\bigg(\sqrt{\dfrac{1}{n}}.\sqrt{\dfrac{2}{n}}.\sqrt{\dfrac{3}{n}}\cdots\sqrt{\dfrac{n-1}{n}}\bigg )^\dfrac{1}{n-1}=\lim_{n \to \infty}\bigg(\dfrac{(n-1)!}{n^n}\bigg )^\dfrac{1}{2(n-1)}$ But after this I am a little in doubt.
This link may provide some light Evaluation of the limit $\lim\limits_{n \to \infty } \frac1{\sqrt n}\left(1 + \frac1{\sqrt 2 }+\frac1{\sqrt 3 }+\cdots+\frac1{\sqrt n } \right)$ but I do not understand how it would help my problem.. In continuation of @Rebello's answer here, I would like to provide an answer for the problem given in the link $\lim\limits_{n \to \infty } \frac1{\sqrt n}\left(1 + \frac1{\sqrt 2 }+\frac1{\sqrt 3 }+\cdots+\frac1{\sqrt n } \right)=\lim\limits_{n \to \infty }\sum_{k=1}^{n}{\dfrac{1}{\sqrt{kn}}}=\int_{0}^{1}\dfrac{1}{\sqrt{x}}dx+\lim\limits_{n \to \infty }\dfrac{1}{n}=2$","['limits', 'calculus']"
3040289,Boundary and initial conditions in quasi linear first order pde,"I cannot understand what we are looking to find in such a problem... For example consider the pde $u_t+u_x=u$ , with $x,t>0$ (1) and initial and boundary conditions: $u(x,0)=1$ , for $x\ge0$ (2) $u(0,t)=1$ , for $t\ge0$ (3) Are we looking for a solution of (1) which can be extended (continously?)in order to take values implemented by (2), (3)? Remark: I do not need a solution of the above problem, just a proper defintion or refference. Thanks in advance.","['ordinary-differential-equations', 'partial-differential-equations']"
3040296,How to use the chain rule for change of variable,"I have asked this questions: Change of variables in differential equation? ...but after thinking about it, I am still a little confused of how to rigorously use the chain rule to calculate the derivative(s) of a function for a change of variable. I have the following derivative: $f(x) = \frac{dw(x)}{dx}$ Now I introduce the change of variable: $\hat{x}=\frac{x}{L}$ and I apply the chain rule: I write: $g(\hat{x}) = L \hat{x} = x$ I substitute: $f(g(\hat{x})) = \frac{dw(g(\hat{x}))}{d(g(\hat{x}))}$ ...but this does not help me... I am confusing something. I would be glad, if someone could show me in detail and step by step how to do this rigorously. Thanks a lot.","['derivatives', 'chain-rule']"
3040319,Every open subset $U\subseteq\mathbb{R}$ is countable union of disjoint open intervals.,"Theorem. Every open subset $U\subseteq\mathbb{R}$ is countable union of disjoint open intervals. I was looking for proofs for this result and I came to this interesting post: Any open subset of $\Bbb R$ is a at most countable union of disjoint open intervals. [Collecting Proofs] . Among all the proofs I started from the simplest one: the one written by G.T. https://math.stackexchange.com/a/1949873/554978 . However, I am not convinced of the proof that $I_x$ is an interval. I do not know if I did not understand correctly or the proof in question is not valid, so I propose one myself and I would like you to tell me which one is valid. Definition. An interval is a subset $I\subseteq\mathbb{R}$ such that, for all $a<c<b$ in $\mathbb{R}$ , if $a,b\in I$ then $c\in I$ . Let $x\in U$ and we suppose that $x\in\mathbb{Q}$ , then define \begin{align} I_x = \bigcup\limits_{\substack{I\text{ an open interval} \\ x~\in~I~\subseteq~U}} I,\end{align} we must prove that $I_x$ is an interval. About that let $a,b\in I_x$ such that $a<c<b$ , then we must prove that $c\in I_x$ . Since $a,b\in I_x$ , then $a,b\in I$ for same open interval $I$ which contains $x$ . If $a$ and $b$ belong to the same $I$ , since $a<c<b$ and $I$ is an interval, $c\in I$ , therefore $c\in I_x$ . Now, we denote with $I_a$ the open interval of $I_x$ which contains $a$ , but not $b$ and we denote with $I_b$ the open interval of $I_x$ which contains $b$ , but not $a$ . First case: $[c=x]$ . If $c=x$ , then $c\in I_x$ by definition of $I_x$ ; Second case: $[c<x]$ . If $c<x$ , then either $a<c<x<b$ or $a<c<b<x$ . $(i)$ If $a<c<x<b$ , since $a\in I_a$ and $x\in I_a$ and $I_a$ is an interval, then $c\in I_a$ , therefore $c\in I_x$ . $(ii)$ If $a<c<b<x$ , since $x\in I_a$ and $a\in I_a$ , and $I_a$ is an interval we have that $b\in I_a$ , absurd. Third case $[c>x]$ . If $c>x$ , then either $a<c<x<b$ or $x<a<c<b$ . $(i)$ If $a<c<x<b$ , since $a\in I_a$ , $x\in I_a$ and $I_a$ is an interval we have that $c\in I_a$ therefore $c\in I_x$ . $(ii)$ If $x<a<c<b$ , since $x\in I_b$ and $b\in I_b$ , we have that $a\in I_b$ absurd. Then in general $c\in I_x$ , this prove that $I_x$ is an interval. Thanks!","['proof-verification', 'analysis', 'real-analysis']"
3040322,"Derangements $p$ of $1,2,\dots,n,n+1$ such that $n+1$ doesn't go to $n$","Recall that the number or Derangements of $1,2,\dots,n$ is a permutation $p$ such that $p(i) \neq i$ for all $i$ . We can express it with the recurrence $D_n=(n-1)(D_{n-1}+D_{n-2})$ or by the closed formula $$D_n =\sum_{i=0}^n (-1)^i \frac{n!}{i!}$$ Now we consider the number of permutations of $1,2,\dots, n,n+1$ such that for all $1\leq i \leq n$ (not $n+1$ ), $p(i)\neq i$ , but also $p(n+1) \neq n$ . We need to express this number using $D_n$ s. I was thinking of first counting the number of permutations without the additional condition $p(n+1) \neq n$ and received using inclusion-exclusion $$\sum_{r=0}^n (-1)^r \binom{n}{r}(n+1-r)! = \sum_{r=0}^n (-1)^r \frac{n!}{r!}(n+1-r) =$$ $$\sum_{r=0}^n (-1)^r \frac{(n+1)!}{r!}- \sum_{r=1}^n (-1)^r \frac{n!}{(r-1)!}=$$ $$\sum_{r=0}^n (-1)^r \frac{(n+1)!}{r!}- n\sum_{r=0}^{n-1} (-1)^{r+1} \frac{(n-1)!}{r!}=$$ $$=D_{n+1}+nD_{n-1}$$ Now we need to subtract from this the number of permutations when $p(n+1)=n$ , which I wasn't able to count. Thanks in advance","['permutations', 'inclusion-exclusion', 'combinatorics']"
3040330,Generalize exterior algebra: vectors are nilcube instead of nilsquare,"The exterior product on a ( $d$ -dimensional) vector space $V$ is defined to be associative and bilinear, and to make any vector square to $0$ , and is otherwise unrestricted. Formally, the exterior algebra $\Lambda V$ is a quotient of the tensor algebra. What happens if, instead, the $n$ th power of any vector is $0$ ? Let's call this the $n$ th nilpotent algebra, $N_nV$ . The $0$ th nilpotent algebra is trivial, with only one element $1=a^0=0$ , so $N_0V=\{0\}$ , which is $0$ -dimensional. The $1$ st nilpotent algebra is the scalar field, because any vector is $a^1=0$ ; thus $N_1V=\mathbb F$ , which is $1$ -dimensional. The $2$ nd nilpotent algebra, with $a^2=a\wedge a=0$ , is the exterior algebra $N_2V=\Lambda V$ , which is $2^d$ -dimensional. What is the $3$ rd nilpotent algebra? Would $N_3V$ be $3^d$ -dimensional? Would $N_nV$ be $n^d$ -dimensional? If $d=1$ , so $V$ has a basis $\{a\}$ , then $N_nV$ has a basis $\{1,a,a^2,\cdots,a^{n-1}\}$ , so it is indeed $n^1$ -dimensional. If $d=2$ , so $V$ has a basis $\{a,b\}$ , then $N_0V$ has basis $\{\}$ , and $N_1V$ has basis $\{1\}$ , and $N_2V$ has basis $\{1,a,b,ab\}$ . What is a basis for $N_3V$ ? Since any vector cubes to $0$ , we have $$0=(a+b)^3=a^3+aab+aba+abb+baa+bab+bba+b^3$$ and $$0=(a-b)^3=a^3-aab-aba+abb-baa+bab+bba-b^3.$$ Subtract these and divide by $2$ to get $$0=aab+aba+baa.$$ Are there any other relations like this, not immediately obvious from the definition? Naively using only $a^3=b^3=0$ , we would expect this to be a basis: $$\{1,a,b,a^2,ab,ba,b^2,a^2b,aba,ab^2,ba^2,bab,b^2a,$$ $$a^2ba,a^2b^2,aba^2,abab,ab^2a,ba^2b,baba,bab^2,b^2a^2,b^2ab,\cdots\}$$ which would contain an infinite number of terms like $a^2ba^2ba^2b$ ; but some terms must be removed, being linearly dependent: $$ba^2=-a^2b-aba$$ $$b^2a=-ab^2-bab$$ $$a(ba^2)=0-a^2ba$$ $$a(b^2a)=-a^2b^2-abab$$ $$(ba^2)b=-a^2b^2-abab$$ $$b^2a^2=a^2b^2+abab-baba$$ $$(b^2a)b=0-bab^2$$ $$\vdots$$ Will there be only finitely many independent terms left?","['vector-spaces', 'nilpotence', 'abstract-algebra', 'tensor-products', 'quotient-spaces']"
3040366,"Why is my proof for “if $0 \leqslant x \leqslant 2$, then $-x^3 + 4x + 1 > 0$” is false?","$$\text{if $0 \leqslant x \leqslant 2$, then $-x^3 + 4x + 1 > 0$}$$ $$x(4-x^2)>-1$$ $$x>\dfrac{1}{x^2-4}$$ if the last statement is smaller than $x$ then it is also smaller than $2$ because of first statement ( $0 \leqslant x \leqslant 2$ ): $$\dfrac{1}{x^2-4}<2$$ $$1<2x^2-8$$ $$4.5<x^2$$ $$-2.121<x<2.121$$ Which contradicts the first statement because $x$ cannot be greater than $2$ . My proof is wrong but why? (I took that question from Math for Computer Science book p. 12)","['proof-verification', 'discrete-mathematics']"
3040367,Integral $\int_0^1 \frac{dx}{\prod_{n=1}^\infty (1+x^n)}$,"The following integral appeared this summer on AoPS . However it received no answer until today. $$I=\lim_{n\to \infty } \int_0^1\frac{dx}{(1+x)(1+x^2)\dots(1+x^n)}=\int_0^1 \frac{dx}{\prod_{n=1}^\infty (1+x^n)}$$ I have learnt recently from here that: $$\frac{1}{\prod_{n=1}^\infty (1+x^n)}=\prod_{n=1}^\infty\left(1-x^{2n-1}\right)\Rightarrow I=\int_0^1\prod_{n=1}^\infty\left(1-x^{2n-1}\right)dx$$ I suspect this has a closed form since a similar integral to the last equality appeared here on MSE before; however this one is a bit different since the product goes only on odd powers and I don't see how to make a connection between the two of them, so I will appreciate some help with that.","['integration', 'definite-integrals', 'closed-form', 'infinite-product']"
3040385,Solving an equation that contains a variable which brings 0=0 issue,"So I encountered this question: Given that the relationship between distance (m) and velocity (v) of an object is $$v^2 = 1 - m^3$$ Find the acceleration of the object when $m=1$ By taking the derivative of each side with respect to $t$ $2v \frac{dv}{dt} = -3m^2 \frac{dm}{dt} $ and we know that $\frac{dv}{dt}$ = acceleration, $\frac{dm}{dt}$ is equal to $v$ , then: $2v  a = -3m^2 v$ and by solving for $a$ without dividing by $v$ since $v$ can be zero, $a = -3/2$ But hold on... we've just substituted $m$ with 1, this means that we have to substitute $v$ with zero, but if we do this we would turn out with 0 = 0, without solving for $a$ That's how our teacher solved it. My questions are: is it permissible to substitute the value for a variable and keep the other, even if i know its value? And why did we treat $v$ here as any other number other than zero?","['derivatives', 'chain-rule']"
3040459,Does an endpoint of a function have a slope?,"Say I have the following function which is defined for $0 \leq x \leq 1$ : If you would derive this function and substitute $y = 0$ , you would get $x = 0.5$ and $x = 0.75$ for the respective as the maximum and minimum point respectively. Now, what if I ask for which range of $x$ does this function rise? Well, I know that it's: $$0 < x < 0.5$$ $$0.75 < x < 1$$ What confuses me is: why don't we include the endpoints and make the inequality inclusive? The explanation I have been given is that a slope is determined between two points, but then why is it when you substitute the $x$ coordinate of the endpoints in the derivative, you get a value?","['calculus', 'derivatives', 'slope', 'real-analysis']"
3040463,Bet on the sum of two dice,"There are two players, and each one has a die with six sides from $1$ to $6$ . The probability of each side landing is equal. Now, the two players roll their dice, and they only know the number of their own die. They will propose prices in turn, until one of them doesn't provide a higher price. The winner will get the money equal to the sum of these two dice minus the price they provided. What is the optimal strategy for playing this game?","['game-theory', 'dice', 'probability']"
3040482,"Limit $\lim_{(x, y) \to (\infty, \infty)} \frac{x+\sqrt{y}}{x^2+y}$","Show whether the limit exists and find it, or prove that it does not. $$\lim_{(x, y) \to(\infty,\infty)}\frac{x+\sqrt{y}}{x^2+y}$$ WolframAlpha shows that limit does not exist, however, I do fail to conclude so. $$\lim_{(x, y) \to(\infty,\infty)}\frac{x+\sqrt{y}}{x^2+y} = [x=r\cos\theta, y = r\sin\theta] = \lim_{r\to\infty}\frac{r\cos\theta+\sqrt{r\sin\theta}}{r^2\cos^2\theta+r\sin\theta} = \lim_{r\to\infty}\frac{\cos\theta\frac{\sqrt{\sin\theta}}{\sqrt{r}}}{r\cos^2\theta+\sin\theta} = 0.$$ Having gotten the exact results for whatever the substitution is made (such as $y = x, y = x^2, [x = t^2, y = t])$ , my conclusion is that limit does exist and equals $0.$ Did I miss something?","['limits', 'multivariable-calculus']"
3040494,Are all verbal automorphisms inner power automorphisms?,"Suppose $G$ is a group. $\DeclareMathOperator{\Wa}{Wa}\DeclareMathOperator{\Tame}{Tame}\DeclareMathOperator{\Aut}{Aut}$ Lets call $\phi \in \Aut(G)$ verbal automorphism iff $\exists n \in \mathbb{N}, \{a_i\}_{i=0}^n \subset G, \{e_i\}_{i=0}^n \subset \{-1; 1\}$ such that $\forall t \in G$ $(\phi(t) = a_0t^{e_1}a_1…t^{e_n}a_n)$ . 
One can easily see, that all the verbal automorphisms form a normal subgroup in $\Aut(G)$ . Lets denote this subgroup as $Va(G)$ . One can see, that sometimes $Va(G)$ is a proper subgroup: for example, $C_2 \times C_2$ has no nontrivial verbal automorphisms, but $\Aut(C_2 \times C_2)$ is isomorphic to $S_3$ . Also one can see that a subgroup is invariant under verbal automorphisms iff it is normal. Lets call $\phi \in \Aut(G)$ inner power automorphism iff it is a composition of an inner automorphism and a universal power automorphism. It is easy to see, that all inner power automorphisms form a normal subgroup in $\Aut(G)$ . Lets denote this subgroup as $Ip(G)$ . One can also see that $Ip(G) \leq Va(G)$ (as $\forall \phi \in Ip(G) \exists a \in G, n \in \mathbb{Z}$ such that $\forall t \in G (\phi(t) = a^{-1}t^na$ )) and that $Ip(G)$ is always isomorphic to a homomorphic image of $\frac{G}{Z(G)} \times C_{\exp(G)}$ , where $\exp(G)$ is the exponent of $G$ . Is the statement $Va(G) = Ip(G)$ always true? If $G$ is abelian, then it definitely is, as all verbal automorphisms of any abelian group are universal power automorphisms. If $G$ is complete then the statement is also true, as all automorphisms of a complete group are inner. However, I failed to find out anything other than that. Any help will be appreciated.","['automorphism-group', 'power-automorphism', 'normal-subgroups', 'abstract-algebra', 'group-theory']"
3041517,JEMC 2016/2: Proof that a certain line is orthogonal to the radical axis of two circles,"Two circles C1 and C2 intersect at points A and B. Let P, Q be points on circles C1, C2 respectively,
  such that |AP| = |AQ|. The segment P Q intersects circles C1 and C2 in points M, N respectively. Let C be
  the center of the arc BP of C1 which does not contain point A and let D be the center of arc BQ of C2 which
  does not contain point A. Let E be the intersection of CM and DN. Prove that AE is perpendicular to CD. --- European Mathematical Cup 2016: Junior category question 2: http://emc.mnm.hr/wp-content/uploads/2016/12/EMC_2016_Juniors_ENG.pdf When I tried to solve this problem, I managed to prove that $$ E \in AB, $$ which reduces the question to proving that $$ CD \perp AE = AB \perp O_1O_2 \Rightarrow CD\parallel O_1O_2 \\ \text{ (with } O_1 \text{ and } O_2 \text{ the centers of } C_1 \text{ and } C_2 \text{ respectively).} $$ How can I do this?","['contest-math', 'circles', 'geometry']"
3041546,When are quotients of homeomorphic spaces homeomorphic?,"Let $X$ and $Y$ be homeomorphic topological spaces, connected by the homeomorphism $f : X \rightarrow Y$ . Let $\sim$ be an equivalence relation on $X$ and $\approx$ be an equivalence relation on $Y$ . I would think that there would be some structure that I could place on the equivalence relations $\sim$ and $\approx$ that would allow me to construct, using the homeomorphism $f$ , a homeomorphism $\bar{f}$ from $X/\sim$ to $Y/\approx$ . I suspect that that relationship is $a \sim b \leftrightarrow f(a) \approx f(b), \forall a, b \in X$ . That is, I suspect that ""equivalent"" quotients of homeomorphic spaces are homeomorphic, but I don't know exactly how to formulate this or prove it. (This result, by the way, to me, seems to hinge on the existence of a ""reverse"" universal quotient property: juts as functions $f : X/\sim \rightarrow Y$ correspond uniquely to a subset of functions $f : X \rightarrow Y$ , I suspect that functions $f : X \rightarrow Y/\approx$ correspond uniquely to some subset of functions $f : X \rightarrow Y$ , but I don't know how this works either.)","['general-topology', 'category-theory']"
3041551,Find optimal number of videoclips to watch (depending on length) to get Maximum points.,"Problem: How to find optimal number of video clips to watch (depending on length) to get Maximum points. Description: I request video clip, then I have two options: to watch it (spend time) and receive points or to skip it and not to receive points (not to spend time). Timeout between new video is 5s. (This is statistical histogram where (Y-axis is number of videos, X-axis is video length) Limitations && Assumptions: - We don't know videos in advance (that's why I've gathered data to build a statistical histogram to know their probabilities. ) - When we skip video clip we don't lose points. - We do know video length before watching it. - We receive points for watching video completely. - We receive the same amount of points for every video. So basically we need to skip those videos which are long and watch those videos with an optimal length. (aka to find how to maximize points per unit time)","['optimization', 'statistics']"
3041567,Permutation probability,"Let $S = \{1,2,3,4,5,...,n\}$ . Let $\Omega$ be set of permutation maps of $S$ . Let $\Phi : \mathbb{R} \to \mathbb{R}$ be strictly positive and strictly increasing map. Consider positive function $P: \Omega \to \mathbb{R}$ defined by $$P(\tau) = \prod_{j=1}^{n} \frac{\Phi(\tau(j))}{\sum_{k=j}^n \Phi(\tau(k))}.$$ I want to show that $P$ is probability function on $\Omega$ . For that , I should show that $$\sum_{\tau \in \Omega} P(\tau)=1.$$ I tried to calculate $$\sum_{l=1}^n\sum_{\tau(l)=1} P(\tau).$$ But it is difficult. Is anyone want to help me?","['permutations', 'probability-distributions', 'combinatorics', 'discrete-mathematics', 'probability']"
3041599,Subspace basis of $\mathbb{R}^n$ only with positive values,"It seems obvious but I didn't find a proof yet:
 Let $U$ be an arbitrary subspace of $\mathbb{R}^n$ . Set $m:=\dim{U}$ . Can $U$ be written as $U=\mathrm{span}\{b_1,\dotsc,b_m\}$ , $b_j=\begin{pmatrix}b_{i,1}\\\vdots\\b_{i,n}\end{pmatrix}$ with $b_{i,j}\ge0\;\forall i\in\{1,\dotsc,m\}\;\forall j\in\{1,\dotsc,n\}$ ? An equivalent formulation for this question: $\exists B=\begin{pmatrix}b_{1,1}&\cdots &b_{1,n}\\\vdots&&\vdots\\b_{m,1}&\cdots &b_{m,n}\end{pmatrix}\in\mathbb{R}^{m\times n}: U=\mathrm{img}(B)$ with $b_{i,j}\ge0\;\forall i\in\{1,\dotsc,m\}\;\forall j\in\{1,\dotsc,n\}$ ? If yes, can you please give a construction algorithm for a given base $\{u_1,\dotsc,u_m\}$ of $U$ ?","['matrices', 'vector-spaces']"
3041656,Sum of two co-prime integers,"I need some help in a proof:
Prove that for any integer $n>6$ can be written as a sum of two co-prime integers $a,b$ s.t. $\gcd(a,b)=1$ . I tried to go around with ""Dirichlet's theorem on arithmetic progressions"" but didn't had any luck to come to an actual proof.
I mainly used arithmetic progression of $4$ , $(4n,4n+1,4n+2,4n+3)$ , but got not much, only to the extent of specific examples and even than sometimes $a,b$ weren't always co-prime (and $n$ was also playing a role so it wasn't $a+b$ it was $an+b$ ). I would appriciate it a lot if someone could give a hand here.","['number-theory', 'elementary-number-theory']"
3041701,Is a product nowhere dense?,"I'm reading Haworth1977, Baire spaces . On page 7 the authors say ...the finite product of subsets is nowhere dense iff at least one of the subsets is itself nowhere dense. However, this is not necessarily true for infinite product and they give an example of countable product that is nowhere dense but every component is somewhere dense. Later they state the following proposition For each $\alpha \in A$ let $N_\alpha$ be a subset of the space $X_\alpha$ . Then, $\prod_{\alpha\in A}N_\alpha$ is nowhere dense in $\prod_{\alpha\in A}X_\alpha$ iff for some $\beta\in A$ , $N_\beta$ is nowhere dense in $X_\beta$ or $\text{cl}N_\alpha\ne X_\alpha$ for infinitely many $\alpha\in A$ . I must miss something because to me the proposition says exactly the contrary of the previous comment. If someone has the book Kuratowski Topologie I (1958, 4th ed., I assume written in French) the proposition above corresponds to some proposition on page 154 of the given edition of Kuratowski, and it would be interesting to have the proposition of that book, French is also fine. (Haworth1977 refers to Kuratowski)",['general-topology']
3041775,Arranging 3 girls and 9 boys,"Three girls A, B and C, and nine boys are lined up in a row. In how many ways this can be done if B must lie between A and C, and A, B must be separated by exactly 4 boys. I have used the following approach. First select 4 boys ${9 \choose 4}$ and then combine them in between A and B. After that, partition the remaining 5 boys into 3 (similar to r balls into n boxes, here n is $(3-1)$ ) with ${ 5 + 2 -1\choose 2 - 1} $ . Hence, the answer should be: ${9 \choose 4}{ 5 + 2 -1\choose 2 - 1} 4! 5! $ . Can anybody tell me if this is correct or not?","['permutations', 'combinatorics', 'discrete-mathematics']"
3041796,"If $1\le a_1<\cdots<a_n\le 2n$ satisfy $\operatorname{lcm}(a_i,a_j)>2n$ for $i\ne j$, is $a_i>\frac{2n}{3}$ for all $i$?","If integers $1\le a_1<\cdots<a_n\le 2n$ satisfy $\operatorname{lcm}(a_i,a_j)>2n$ for $i\ne j$ , is it true that $a_i>\frac{2n}{3}$ for all $i$ ? My attempt:
Suppose that $i<j$ , then $\operatorname{lcm}(a_i,a_j)>a_j$ since if $\operatorname{lcm}(a_i,a_j)=a_j\le 2n$ we have a contradiction. If $\operatorname{lcm}(a_i,a_j)=2a_j$ then $2a_j\ge 3a_i$ , and i don't know what to do next.","['number-theory', 'gcd-and-lcm', 'least-common-multiple', 'elementary-number-theory']"
3041798,Are There Functions Where $(f\cdot g)^\prime$ is equal to $f^\prime \cdot g^\prime$? [duplicate],"This question already has answers here : When does product of derivatives equals derivative of products? (2 answers) Closed 5 years ago . My math teacher recently asked my class to find if there are any functions that comply to the rule $$(f\cdot g)^\prime = f^\prime \cdot g^\prime$$ I have searched the web for an answer but I couldn't find it, could anyone help me with that? or at least point me to the right direction?","['functional-equations', 'calculus', 'derivatives', 'ordinary-differential-equations']"
3041812,How to think about decimal exponents,"I don't know if this is the right place to ask a question about middle school-level math, but I'll give it a shot. I don't have the background to fully understand related questions (like How to calculate a decimal power of a number ), but my son, who's currently taking Algebra I, has been asking me how logs affect other functions. I don't have much of an answer, but in exploring, we found something kind of weird. The graphing calculator at GeoGebra plots $\log_2(x^{2/5})$ with curves on both sides of the y axis but $\log_2(x^{0.4})$ only shows up on the right side. (We used $\log_2$ instead of $\ln$ because it was easier for us to think about.) We get that fractional exponents work like this: $$
   x^{\frac{a}{b}} = \sqrt[b]{x^a}
$$ And exponents with even numerators have positive y values for positive and negative values of x, so log of them is defined. My guess about why $\log_2(x^{0.4})$ is only on the right side is that if you were going to vary the exponent continuously, the evenness of the numerator would oscillate extremely. And expressing the exponent as a decimal implies that kind of continuous variation rather than clearly distinguishing the numerator and denominator. Is that kind of the right explanation (for me and a 7th grader, that is)? Thanks in advance to anyone who's willing to talk about this at our level.","['algebra-precalculus', 'education']"
