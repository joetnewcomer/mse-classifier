question_id,title,body,tags
1974134,Periodic points and dense orbits,"I am reading a proof (theorems about shifts) in an introductory dynamical systems book which uses the following fact: Definitions: Let $A$ be an $m\times m$ adjacency matrix $(a_{ij})$ and $\Sigma_m=\mathcal{A}_m^\mathbb{Z}$ be the set of infinite two-sided sequences of symbols in $\mathcal{A}_m:=\{1,\dots,m\}$. Now, we let $\Sigma_m^+=\mathcal{A}_m^\mathbb{N}$ be the infinite one-sided sequences. We say that a word or infinite sequence $x$ in the alphabet $\mathcal{A}_m$ is allowed if $a_{x_i,x_{i+1}}>0$. Hence we let $\Sigma_A\subset\Sigma_m$ be the set of allowed two-sided sequences and $\Sigma_A^+\subset\Sigma_m^+$ the set of allowed one-sided sequences. Now, they say that if all entries of some power of $A$ is positive, then in the product topology $\Sigma_A^+$ and $\Sigma_A$, periodic points are dense and there are dense orbits. They don't explain why this is true and since I failed proving this by myself, I was wondering whether someone can help me. Any hints are appreciated.","['ordinary-differential-equations', 'dynamical-systems', 'discrete-mathematics']"
1974159,Algebraic expansion of $(1+x)^{1/x}$ is?,"i have to solve 
$ \lim_{x\to 0} \frac{{(1+x})^{1/x}-e+ex/2}{x^2}$ and in the hint it is advised to use the algebraic expansion of $(1+x)^{1/x}$. Also i know that the algebraic expansion of $(1+x)^{m} = 1+mx+m(m-1){x^2}/2+...$ but this is in the case where m is an integer.
So please help me here with the limit.","['algebra-precalculus', 'calculus', 'limits']"
1974178,Transcendental numbers and irrationality measure,"Is it possible to generate transcendental numbers of arbitrary irrationality measure ? I am thinking of something like an infinite series which depends on a parameter fixing the irrationality measure. All I have found so far is bounds on the irrationality measure of famous numbers, I have not been able to find something going the other way around.",['number-theory']
1974187,smooth embedding between manifolds,"I'm sightly confused about the definition of an embedding between manifolds. (There seems to be several formulations and apparently they are meant to be equivalent.) From what I gather a smooth map $f: M \to N$ between manifolds is an embedding if it is (1) an immersion (smooth and derivative is injective), and (2) it is a topological embedding (homeomorphism onto image) With this definition, the image of an embedding is a manifold (a submanifold of $N$) and $f$ is a diffeomorphism onto its image. To fully understand this definition, can someone give me an example of (a) an injective immersion that is not an embedding (for example if the image is not a manifold), and (b) the necessity of the requirement of it being an immersion (for example a smooth injection whose image is not a manifold). PS. I have seen an example of (a) that is the injective immersion from $\mathbb{R}$ to the figure 8 in $\mathbb{R}^2$ by taking $\pm \infty$ to the intersection of the figure 8 from top right/ bottom left. But I'm having trouble confirming why it's not a homeo onto image (it's clearly bijective but why is it not continuous wrt to the subspace topology of the figure 8 in $\mathbb{R}^2$?)","['manifolds', 'general-topology', 'differential-geometry']"
1974309,Summation or Integral representation ${e^{2}\above 1.5pt \ln(2)}=10.66015459\ldots$,How can I construct a summation or integral representation of $${e^2\above 1.5pt \ln(2)}.$$  Naively I would write $$\Bigg(\sum_{n=0}^{\infty}{2^n \above 1.5pt n!} \Bigg)\Bigg(\sum_{n=1}^\infty {(-1)^{(n+1)} \above 1.5pt n}\Bigg)^{-1}$$ but I suspect we can further reduce that and I am not sure how to get there.  Numerically $${e^{2}\above 1.5pt \ln(2)}=10.66015459\ldots={7.38905609\ldots \above 1.5pt 0.693147181\ldots} $$,"['logarithms', 'exponential-function', 'algebra-precalculus', 'summation', 'elementary-number-theory']"
1974310,"Discrete mathematics, divisibility [closed]",Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 7 years ago . Improve this question How can I prove that for all $n\in\mathbf{N}$ that $6 | n^5 + 5n$? I tested for $n = 2$ and got $6 | 32 + 10 = 42$.,"['divisibility', 'discrete-mathematics']"
1974338,$m+n\sqrt{2}$ is a dense in R. Another approach,"In order to prove, that $m+n\sqrt{2}$ is a dense, can we just argue(and prove), that between a pair of real numbers always exists the rational number. If so, we can show that there are infinitely many limit points in set $m+n\sqrt{2}$. Because i can't understand, why do we need to show, that $(\sqrt2-1)^n\to 0 $ How will it help?","['general-topology', 'real-analysis', 'elementary-set-theory']"
1974363,The logarithm of a symmetric positive definite matrix as a function,"Can the logarithm of a symmetric,positive definite matrix always be expressed locally as a power series? That is: Is the logarithm function analytic on the space of symmetric, positive definite matrices?","['matrices', 'linear-algebra']"
1974366,"Prove that if $B$ is an antisymmetric matrix, then $\det(B+I) \neq 0$ [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Prove that if $B$ is an antisymmetric matrix with real entries, then $\det(B+I) \neq 0$.","['matrices', 'linear-algebra', 'determinant']"
1974386,Convergent nets and closed sets in a proof of Schechter's book,"In my current obsession to learn equivalences of the Ultrafilter Lemma, I found the Handbook of Analysis and its Foundations, by Eric Schechter - by the way, a marvelous book in my opinion. In this book (section 28.29), the proof that Banach-Alaoglu Theorem implies (in ZF) the Ultrafilter Lemma goes like this: we fix a set $\Omega$ and a proper filter $\mathcal{F}$ on $\Omega$; we set $X=\{f\colon \Omega\to\mathbb{R}|f$ is bounded$\}$ equipped with the sup norm; by Banach-Alaoglu, the closed unit ball on $X^*$ is $w^*$-compact (compact in the weak$^*$ topology), call it $V$; the map $\varphi\colon \Omega\to V$ defined as $\varphi_\omega(x)=x(\omega)$ for $\omega\in \Omega$ and $x\in X$ is an injection, so we may suppose that $\Omega\subset V$; the set $\mathcal{K}=\{w^*\text{-cl}(F): F\in\mathcal{F}\}$ is a family of $w^*$-closed subsets of $V$ with the finite intersection property, hence there exists $v\in \bigcap\mathcal{K}$; we define $\mu\colon \wp(\Omega)\to\mathbb{R}$ by setting $\mu(S)=v(1_S)$, where $1_S\colon \Omega\to \{0,1\}$ is the characteristic function of $S$; in order to see that $\mathfrak{u}=\{G\subset\Omega:\mu(G)=1\}$ is an ultrafilter that contains $\mathcal{F}$, the author uses the following fact for any fixed $F\in\mathcal{F}$, since $v\in w^*\text{-cl}(F)$, there is some net $(\omega(\alpha):\alpha\in A)$ in $F$ such that $\varphi_{\omega(\alpha)}\stackrel{w^*}{\longrightarrow}v$. My problem concerns this last step. I know that in any topological space $Y$, $y\in Y$ and $A\subset Y$, $(\dagger)$ $\quad$ $y\in\overline{A}$ if and only if there exists a net of elements in $A$ converging to $y$. However, the only proof I know about this fact uses the Axiom of Choice. Finally, my questions : There is a way to prove $(\dagger)$ without the Axiom of Choice? If not, what am I missing in order to prove the 8th step? Thank you. I am aware of this post , but my question concerns specifically about the proof in Schechter's book.","['functional-analysis', 'general-topology', 'nets', 'axiom-of-choice']"
1974448,Prove for Arbitrary Point $O$ inside $\triangle ABC$ we have $OA + OB + OC < AB + AC + BC$,Prove for Arbitrary Point $O$ inside $\triangle ABC$ we have $OA + OB + OC < AB + AC + BC$. I know $\frac{1}{2} (AB+AC+BC)<OA+OB+OC$ but don't know how to prove $OA + OB + OC < AB + AC + BC$.,"['euclidean-geometry', 'triangles', 'geometry']"
1974506,Any other cases similar to $\sqrt[4]{\frac {3+2\sqrt[4]{5}}{3-2\sqrt[4]{5}}}=\frac 12 (3+\sqrt[4]{5}+\sqrt{5}+\sqrt[4]{125})$,"Ramanujan gave many curious identities, one of which was $$\sqrt[4]{\frac {3+2\sqrt[4]{5}}{3-2\sqrt[4]{5}}}=\frac {\sqrt[4]{5}+1}{\sqrt[4]{5}-1}=\frac 12(3+\sqrt[4]5+\sqrt5+\sqrt[4]{125})\tag1$$
And another one:$$\sqrt[3]{\sqrt[5]{\frac {32}5}-\sqrt[5]{\frac {27}5}}=\sqrt[5]{\frac 1{25}}+\sqrt[5]{\frac {3}{25}}-\sqrt[5]{\frac {9}{25}}\tag2$$ Question: Is there some algebraic method to prove $(1)$ and $(2)$, and can that method be generalized? And more specifically, can both $(1)$ and $(2)$ be represented as a sum of radicals of the same degree? Such as $\sqrt[4]{A+B\sqrt[4]{C}}=\sqrt[4]{X}+\sqrt[4]{Y}+\sqrt[4]{Z}$. Also, I do realize that for $(1)$, you can raise everything to the fourth power and simplify to get an identity (such as $1=1$), but it doesn't provide insight on why or how the equation holds.","['algebra-precalculus', 'radicals', 'nested-radicals']"
1974522,y'' + y = -sin(x),"$y'' + y = -\sin(x)$ $y(0) = 0 $ $y'(0) = 0$ I first solved for the homogeneous solution to get: $y(x) = c_1 \sin(x) + c_2 \cos(x)$ then took the derivative of that: $y'(x) = c_1 \cos (x) - c_2 \sin(x)$ This is where I am not sure where to go... $y(0) = c_1 \sin(0) + c_2 \cos(0) 
     =  0 + c_2 $ so would c2 equal zero? y'(0) = c1 cos(0) - c2 sin(0)
      =  c1 - 0 then c2 is zero too? I don't think that's right, but I'm not sure what else to do. 
And where to go from there.",['ordinary-differential-equations']
1974534,The PDF of the area of a random triangle in a square,"Three points are chosen uniformly and independently at random on the unit rectangle $(0,1)\times(0,1)$. What is the probability distribution (in the form of a cumulative distribution function and/or a probability density function supported on $[0,1/2]$) of the area of the triangle whose vertices are so chosen?  What are the moments of this distribution? The area might be expressed as the norm of the sum of three three-dimensional vector cross products,  as $$\frac12\|p_1\times p_2+p_2\times p_3+p_3\times p_1\|.$$ Closely related: Probability of lies a point in a random triangle . See also http://mathworld.wolfram.com/SquareTrianglePicking.html and http://www.diva-portal.org/smash/get/diva2:644463/FULLTEXT01.pdf","['probability', 'geometry']"
1974557,What are some natural arithmetical statements independent of ZFC?,"GÃ¶del's first incompleteness theorem produces a statement in the language of arithmetic that's independent of a given theory. The second theorem says that a consistient theory can not prove its own consistency, which is also a arithmetical statement (since you phrase it in terms of a Turing machine that looks for contradictions, for example). Are there any ""natural"" statements in arithmetic that are independent of ZFC (besides consistency of ZFC, which is arguably pretty natural)? The wikipedia article only lists the consistency of ZFC.","['number-theory', 'meta-math', 'set-theory']"
1974593,Why tensor product of two sheaves of modules is a sheaf of modules?,"Let $(X, \mathcal O_X)$ be  a ringed topological space. Consider two $\mathcal O_X$ modules, $\mathcal F$ and $\mathcal G$. First we define the tensor product presheaf $\mathcal F \otimes_{p,\mathcal O_X} \mathcal G$, which assigns every open set $U$ in $X$ the $\mathcal O_X(U)$-module $\mathcal F(U) \otimes_{\mathcal O_X(U)} \mathcal G(U)$. Now, $\mathcal F \otimes_{p,\mathcal O_X} \mathcal G$ is a presheaf of abelian groups . We take the the sheafication of the $\mathcal F \otimes_{p,\mathcal O_X} \mathcal G$ to obtain a sheaf of abelian groups , $\mathcal F \otimes_{\mathcal O_X} \mathcal G$. My question is for any open set $U$ in $X$ what is the $\mathcal O_X(U)$-module on   $(\mathcal F \otimes_{\mathcal O_X} \mathcal G)(U)$?","['abstract-algebra', 'sheaf-theory', 'algebraic-geometry', 'commutative-algebra']"
1974619,Closed form of $\sum _{n=0}^{\infty} \frac{\left(-\pi ^2\right)^n \cos \left(2^nb\right)}{(2 n)!}$,"Is it possible to calculate the sum
  $$
\sum _{n=0}^{\infty} \frac{\left(-\pi ^2\right)^n \cos \left(2^nb\right)}{(2 n)!}
$$
  in closed form? Formal naive argument gives 
$$
\sum _{n=0}^{\infty} \frac{\left(-\pi ^2\right)^n}{(2 n)!}\sum _{m=0}^{\infty} \frac{\left(-b ^2\right)^m}{(2 m)!}2^{2mn}=\sum _{m=0}^{\infty} \frac{\left(-b ^2\right)^m\cos\left(2^m\pi\right)}{(2 m)!}=\cos b-2.
$$
However, numerical calculation shows that this is wrong. For example, for $b=1/3$ http://www.wolframalpha.com/input/?i=N%5B1%2F(Cos%5B1%2F++++3%5D+-2)Sum%5B(-%5C%5BPi%5D%5E2)%5En%2FFactorial%5B2+n%5D+Cos%5B1%2F3+2%5En%5D,+%7Bn,+0,+150%7D%5D,+35%5D","['real-analysis', 'calculus', 'closed-form', 'complex-analysis', 'sequences-and-series']"
1974624,Is there an entire function with $f(\mathbb{Q}) \subset \mathbb{Q}$ and a non-finite power series representation having only rational Coeffitients,"I'm trying to answer the following question: Is there an entire function $f(z) := \sum \limits_{n=0}^\infty c_nz^n$ such that $f(\mathbb{Q}) \subset \mathbb{Q}$ $\forall n: c_n \in \mathbb{Q}$ $f$ is not a polynomial ? I'm trying to show that no such function exists. Here's why I think so: Assuming such a function existed. We would get $f(10^k) \in \mathbb{Q}$ for all $k \in \mathbb{Z}$. So the decimal representation of $f(10^k)$ either cuts at some digit or consists of repeating digits.
Now my gut is telling me that if this is true for $f(10^n)$ with $n \in \mathbb{N}$, it won't be for $f(10^{-n}).$ (e.g. for $c_n$ with a finite digit representation: that's because the number of zeroes between each non-zero digit would increase indefinitely) But, is this correct at all? And if so, how do I show it rigorously?","['complex-analysis', 'entire-functions', 'power-series', 'transcendental-functions']"
1974631,"Prove that if $\kappa$ is an uncountable regular cardinal that is also a limit cardinal, then $\kappa = \aleph_{\kappa}$","A cardinal $\kappa$ is regular if whenever $X \subseteq \kappa$ with $|X|<\kappa$ then $supX<\kappa$. And a cardinal is a limit cardinal if it is of the form $\aleph_{\beta}$ where $\beta$ is a limit ordinal. So I know that $\kappa=\aleph_{\beta}$ for some limit ordinal $\beta$, and I know that $\kappa\leq\aleph_\kappa$. I'm thinking that the right way to proceed on with this is to assume $\kappa<\aleph_\kappa$ and prove by contradiction. \begin{equation}
\begin{aligned}
\kappa&<\aleph_\kappa\\
\kappa = \aleph_\beta&<\aleph_\kappa\\
\beta &< \kappa
\end{aligned}
\end{equation} Im not sure how to proceed on from here! More importantly, I don't know how to make use of the fact that $\kappa$ is regular.. Some hints would be appreciated!",['elementary-set-theory']
1974632,Find the operator norm.,"Let $A$ be an operator on the Hilbert space $L^2([0, \pi])$ defined by
$$ A(f)(x) = \int_0^\pi \cos(x-y)f(y) \ dy ,$$ where $0 \leq x \leq \pi$. Find the operator norm of $A$. By definition $\| A \| = \sup_{\| f \| = 1} \| Af \|$. We also have 
\begin{align*}
\| Af \| &= \left( \int_0^\pi \left| \int_0^\pi \cos(x-y)f(y) \ dy \ \right| ^2  \ dx \right)^{1/2} \\
&\leq \| f \| \left( \int_0^\pi \int_0^\pi \left| \cos(x-y) \right|^2 \ dy  \  dx \right)^{1/2} \\
&=\| f \| \left( \int_0^\pi \int_0^\pi \cos^2(x-y)  \ dy  \  dx \right)^{1/2} \\
&= \|f\| \pi/\sqrt{2}
\end{align*} Thus $\| A\| \leq \pi/\sqrt{2}$. But it is hard to find a function $f$ such that $\| Af \|$ equals $\| f \| \pi/\sqrt{2}$. May be I made a mistake or I need to use some other approach. Could you give me some tips please.","['functional-analysis', 'normed-spaces', 'hilbert-spaces']"
1974650,Proof of Dobinski's formula for Bell numbers,"The Bell number $B(n)$ is defined as $\sum_{k=1}^n S(n,k)$ where $S(n,k)={n\brace k}$ is a Stirling number of the second kind. I would like to learn how to prove the following identity (Dobinski's formula):
$$B(n)=\frac{1}{e}\sum_{j=0}^{\infty}\frac{j^n}{j!}.$$","['stirling-numbers', 'combinatorics']"
1974697,Power set cardinality confusion,"I am reading a book that claims that if $|A|=2$, $|C|=3$ then 
$$
|P(P(A)\times P(C))|=32
$$
How is this computed? I would think the cardinality of the above should be $2^{2^{|A|}*2^{|C|}}=2^{4*8}=2^{32}$. What am I missing? As I am trying to compute these quickly, I would like to avoid enumerating things mechanically.","['combinatorics', 'elementary-set-theory']"
1974710,"What does $[A,B]=0$ mean in matrix theory?","This is probably very simple but I can't seem to find an answer anywhere. I'm being asked to prove $e^{tA}e^{tB} = e^{t(A+B)}$ for all $t \in \mathbb{R}$ iff $[A,B]=0$ However, I am unsure what $[A,B]=0$ even means! Any help?","['matrices', 'notation', 'matrix-exponential', 'linear-algebra']"
1974766,Confused about the concept of distributions and functions,"I just learned the concept of distributions, but I'm confused about the concept, so my question is simple and may looks a bit strange (sorry about that..) Firstly, I know that a distribution is a continuous linear functional, mapping from $D(\Omega)$ to a complex number. So if $f\in D'(\Omega)$, then the parameter for $f$ should be a function, right? (which I mean $f$ should be like $f(g)$ or $f(\varphi)$, ($g$ and $\varphi$ are functions), but not $f(x)$ where $x$ is a real number) And is this the main difference between a function and a functional? But I also see examples like ""let $f\in D'(\Omega)$ be a distribution defined by $f(x)=2x$ when $x>0$ and $f(x)=0$ when $x\leq 0$)"". What does this mean? Is $f$ here a distribution or a function after all? Secondly, a distribution $f$ operating on a function $\varphi$ should be defined by $<f,\varphi>$ equals something, but why both in my note and some textbooks, when discussing the multiplication by $C^{\infty}$ functions and differentiation, they all began with $<af,\varphi>=\int_\Omega af\varphi dx=<f,a\varphi> \forall \varphi \in D(\Omega)$. Here suppose $f\in C$ (or $f\in L_{loc}^{1}(\Omega)$) and $a\in C^{\infty}(\Omega)$ and $<\partial^\alpha f,\varphi>=\int_{\mathbb R^N}(\partial ^\alpha f)\varphi dx=...$ Why here the distributions are set as integral automatically? Or shall we think of distribution as integral like above when doing operations on distributions? Thanks so much!","['functional-analysis', 'distribution-theory', 'functions', 'partial-differential-equations']"
1974771,How to find the variance of $U= X-2Y+4Z$? & The Co-variance of $U=X-2Y+4Z$ and $V = 3X-Y-Z$,"EDIT If the random variables $X,Y, Z$ have the expected, $$\text{ means: }\mu_{x}=2 \qquad \qquad \mu_{y}=-3 \qquad \qquad \mu_{z} = 4$$ $$ \text{variances: }\sigma_{x}^{2}=3 \qquad \qquad \sigma_{y}^{2}=2 \qquad \qquad \sigma^{2}_{z}=8$$ $$\text{covariances: }\text{cov}(X,Y) =1 \quad \quad \text{cov}(X,Z) = -2 \quad \quad \text{Cov}(Y,Z) = 3$$ find the variance of $U = X-2Y+4Z$ . The co-variance of $U$ and $V = 3X-Y-Z$ One must use these formulas in order to solve this problem. From what I have deduced from the formulas above in order to find the variance one must use this formula $v(U)= \text{var}(a_x+b_y+c_z) =a^2\cdot \text{var}(x) +b^2\cdot \text{var}(Y)+c^2 \cdot \text{var}(z) + 2ab \cdot cov(x,y) +2ac\cdot \text{cov}(x,z)+2abc \cdot \text{cov}(Y,Z)$ To find the co-variance one must use this formula $\text{cov}(u,v) = \text{cov}(a_1+b_1+c_1,a_2+b_2+c_2)=(a_{1})(a_{2})\text{var}(x)+(b_{1})(b_{2})\text{var}(Y)+(c_{1})(c_{2})\text{var}(Z)+\left[ (a_{1})(b_{2})+(b_{1})(a_{2}) \right] \cdot \text{cov}(X,Y)+\left[ (a_{1})(c_{2})+(c_{1})(a_{2}) \right] \cdot \text{cov}(X,Z)+ \left[ (b_{1})(c_{2})+(c_{1})(b_{2}) \right] \cdot \text{cov}(Y,Z)$ Is the formula that I used above a correct interpretation of what is alluded by in the formulas above? Lastly, I do not want to make duplicates so the questions I have asked above is different from what I asked before in the previous questions, mainly because am asking  about the interpretations of the formulas...... not just the answer.I hope this is enough information so that this question can be its own independent entity.","['statistics', 'covariance', 'variance']"
1974821,"Haar measure scalars, what am I doing wrong here?","Let $\mu$ be a Borel measure on a topological space $X$, and let $E \subseteq X$ be Borel.  Let $\phi$ be a homeomorphism of $X$, and let $\lambda$ be the measure given by $\lambda(A) = \mu(\phi(A))$.  If $f: E \rightarrow \mathbb{C}$ is measurable and integrable, then so is $f \circ \phi: \phi^{-1}E \rightarrow \mathbb{C}$, and $$\int\limits_E f \space d \mu= \int\limits_{\phi^{-1}E} f \circ \phi \space d\lambda$$ For example, if $f$ is a simple function, say $f = \sum\limits_{i=1}^m c_i \chi_{E_i}$ for $E_i \subseteq E$ disjoint and Borel, then $f \circ \phi: \phi^{-1}E \rightarrow \mathbb{C}$ is the function $\sum\limits_{i=1}^m c_i \chi_{\phi^{-1}E_i}$, and $$\int\limits_{\phi^{-1}E} f \circ \phi \space d \lambda = \sum\limits_{i=1}^m c_i \lambda(\phi^{-1}E_i) = \sum\limits_{i=1}^m c_i\mu(E_i) = \int\limits_E f \space d \mu$$ Now let $G$ be a locally compact topological group, $\mu$ a left Haar measure on $G$, and $\phi$ the topological group isomorphism $x \mapsto x_0xx_0^{-1}$ for a fixed $x_0 \in G$.  Define $\lambda = \mu \circ \phi$.  It is easy to see that $\lambda(E) = \mu(x_0Ex_0^{-1}) = \mu(Ex_0^{-1})$ for all Borel sets $E$, and that $\lambda$ is also a left Haar measure.  Therefore, there exists a constant $\Delta(x_0) = \Delta > 0$ such that $\lambda = \Delta \mu$, or in other words $$\mu(Ex_0^{-1}) = \Delta \mu(E)$$ for all $E$ Borel.  Now, for $f: G \rightarrow \mathbb{C}$ integrable, we should have $$\int\limits_G f d \mu = \int\limits_{\phi^{-1}G} f \circ \phi \space d \lambda = \int\limits_G f \circ \phi  \space d\lambda = \Delta \int\limits_G f \circ \phi \space d\mu$$ Or in other words, $$\int\limits_G f(x)dx = \Delta(x_0) \int\limits_G f(x_0xx_0^{-1}) dx$$ However, the notes I'm reading here ( http://www.math.toronto.edu/murnaghan/courses/mat1196/rnotes.pdf ) page 19, have $\Delta(x_0)$ on the other side of the equation.  Am I making a mistake somewhere?","['topological-groups', 'harmonic-analysis', 'integration', 'measure-theory']"
1974883,Elementary Set Theory Cardinality of this Set?,"i have been struggling with the following problem: Prove if this * set has cardinality $\mathbb N, \mathcal P(\mathbb N) $ or  $\mathcal P(\mathcal P(\mathbb N)) $ . *$\mathrm X:=$ The set of all strictly increasing functions $\mathcal f:\mathbb N \to \mathbb N$, such that $\mathcal f(0)=0$, and $\mathcal f(n) \le 2n.$ So here is my attempt: We define a function $\phi: \mathrm X\to  \mathcal P(\mathbb N)$ like this:
Let $y$ be a member of X. $\phi(y) = \{y(1),y(2),...,y(n),...\}$ So $\phi$ is an injection, and we can conclude that $Card (\mathrm X)\le Card( P(\mathbb N))$. I tried using the diagonal argument to show that $X$ is not countable, but im not sure if it follows. I would be really glad if someone could help me with this, this is not any kind of homework, im just honestly studying for my test.",['elementary-set-theory']
1974919,Algebra of Differential Operators,"Let $A$ be a finitely generated commutative $k$-algebra, where $k$ is a field.  I have seen two definitions of the algebra of differential operators on $A$, which I will write as $D(A)$, and my question is: when are they equivalent, and why? Even just providing a reference would be great. One definition I've seen is: Let $\mathrm{Der}(A)$ be the $k$-linear derivations on $A$, and let $A$ act on itself by left multiplication. Then $D(A)$ is the subalgebra of $\mathrm{End}_k(A)$ generated by $A$ and $\mathrm{Der}(A)$. The other definition I've seen is saying: An element $T\in\mathrm{End}_k(A)$ is a differential operator of order $\leq n$ on $A$ if $[\cdots[[T,a_0],a_1]\cdots,a_n]=0$ for all $a_0,\dots,a_n\in A$, where the bracket is computed in $\mathrm{End}_k(A)$.  Then we define $D(A)$ as the set of differential operators of some finite order on $A$. I believe that the first definition, which I'll call $D'(A)$ is contained in the second definition, which I'll call $D(A)$.  But it's not clear to me when the opposite inclusion holds. My second big question, which you can feel free happily ignore if you know the answer to the first, is: what is the 'right' definition of $D(A)$ when $A$ is a non-commutative algebra over $k$?  How do the above two definitions agree in this situation?","['ring-theory', 'noncommutative-algebra', 'algebraic-geometry', 'commutative-algebra']"
1974920,"Can the topology $\tau = \{\emptyset, \{a\}, \{a,b\}\}$ be induced by some metric?","I'm just beginning to learn about topological spaces, and in my notes a few examples of topological spaces are given. One of them is $\tau = \{\emptyset, \{a\}, \{a,b\}\}$ on the set $X = \{a,b\}$. I can clearly see how this meets my definition of a topology, namely that $\emptyset, X \in T$; $\bigcup_{\lambda \in \Lambda} T_{\lambda} \in \tau$ whenever $\{T_{\lambda}\}_{\lambda \in \Lambda} \subseteq \tau$; $\bigcap_{k=1}^{n} T_{k} \in \tau$ whenever $\{T_{k}\}_{k=1}^{n} \subseteq \tau$. My question: I was wondering if this could be a topology induced by some metric $d$ on $X$, however. Or more generally, how one could determine whether a particular topology is possibly induced by a metric. I have seen that the discrete topology on any $X \neq \emptyset$ given by $\tau = \mathcal{P}(X)$ is induced by the discrete metric $\mu$, for instance, which has motivated my question as to whether some of the other topologies introduced may be metric-induced as well. I attempted to think of some metric which would induce my above topology, but have thus far been unsuccessful - but also not sure how I might prove that one cannot exist.","['general-topology', 'real-analysis', 'metric-spaces']"
1974938,$4$ dogs have been born in the same week. What is the probability that they were born on different days?,"$4$ dogs have been born at a dog kennel in the same week. What is the probability that
  they were born on different days? I did:
$$\frac{^7C_4}{7^4}$$ But my book says the solution is:
$\frac{120}{7^3}$ What did I do wrong? EDIT: I copied the problem exactly as it is in my book. If it is missing information, poorly thought or doesn't make any sense, that's not my fault. Typos, mistakes and low quality abound in these schoolbooks.","['combinatorics', 'probability']"
1974941,"How do I find a mean and variance of ratio of two random variables for given mean, variance, and co-variance?","Given two random variables $X$ and $Y$ with mean of $\mu_X$ and $\mu_Y$, variances of $\sigma_X^2$ and $\sigma_Y^2$, and covariance of $C_{XY}$, how to find the approximation of the mean and variance of $Z = \frac{Y}{X}$ in terms of  $\mu_X$,  $\mu_Y$, $\sigma_X^2$, $\sigma_Y^2$, and $C_{XY}$?","['means', 'probability', 'random-variables', 'probability-distributions']"
1974945,"Tangent Line, and Derivative","I was given the function $f(x)=k\sqrt{x}$ , and a line $y=x+4$ .  I need to find a value for k such that the line is tangent to the graph.  I have attempted the problem by taking the derivative of the given function. Derivative $$f'(x)=\frac{k}{2\sqrt{x}}$$ Since the slope of the tangent line is $1$ , I set the derivative equal to $1$ and get: $$1=\frac{k}{2\sqrt{x}}$$ and then I get: $$2\sqrt{x}=k$$ I feel like I am on the right track, but I am clueless on how to find an x to ensure I find the right k.  What other process would be necessary to find k, assuming I am on the right track?","['derivatives', 'calculus']"
1974962,Example of discrete subgroup of $\mathbb{R}^2$ where image of $X$ under 1st projection isn't discrete subset of $\mathbb{R}$?,"What is an example of a discrete subgroup $X$ of $(\mathbb{R}^2, +)$ where the image of $X$ under the 1st projection $\mathbb{R}^2 \to \mathbb{R}$ isn't a discrete subset of $\mathbb{R}$?","['abstract-algebra', 'group-theory']"
1974972,A few questions on Taylor's inequality.,"Taylor's Inequality. If $|f^{n + 1}(x)| \le M$ for $|x - a|\le d$, then the remainder $R_n(x)$ of the Taylor series satisfies the inequality$$|R_n(x)| \le {M\over{(n + 1)!}}|x - a|^{n + 1} \text{ for }|x - a| \le d.$$ I have a few questions surrounding Taylor's inequality. What is the intuition behind the proof? Why should I care about it, i.e. how does one apply it?","['derivatives', 'real-analysis', 'taylor-expansion', 'calculus', 'sequences-and-series']"
1975001,Meaning of the antipode in Hopf algebras?,"What I understand so far is that Hopf algebra is a vector space which is both algebra and coalgebra. In addition to this, there is a linear operation $S$, which for each element gives a so-called 'anitpode'. Can anyone give an intuitive explanation of what is the 'antiopde' element? Why is it essential for the representation theory? What is the meaning of the axiom related to it (#3 on wiki)? (looks like without that axiom the product and co-product would be unrelated to each other) Thanks.","['abstract-algebra', 'representation-theory', 'hopf-algebras', 'coalgebras']"
1975043,Determine a stability region?,"The question I'm trying to solve is the following: The implicit midpoint method is defined as: $y_{n+1} = y_n + hf(t_{n+1/2},(y_n + y_{n+1}/2),$ where $t_{n+1/2} = t_n + {h/2}$ What is the stability region for the equation $y' = \lambda y$? In other words, for what values $\bar{h} = h \lambda \space \in \space \mathbb{C}$ is the method stable? I really have no idea on where to even begin with this. What I tried to do was plug in $\lambda y_n$ into the trapezoid method so I can obtain $y_n$ as a function of it and $\bar{h}$, but I wasn't really getting any where. Honestly, I'm not even sure if there's supposed to be an explicit way of getting the answer here. Does anybody have any idea on how to do this? I'd really appreciate any help.","['stability-theory', 'computational-mathematics', 'stability-in-odes', 'numerical-methods', 'ordinary-differential-equations']"
1975078,Defining the factorial of a real number,"I'm curious, how is the factorial of a real number defined?  Intuitively, it should be: $x! = 0$ if $x \leq 1$ $x! = \infty$ if $x >1$ Since it would be the product of all real numbers preceding it, however, when I plug $\pi!$ into my calculator, I get an actual value: $7.18808272898$ How is that value determined?",['real-analysis']
1975080,Prove existence of multiplicative inverse modulo p when p is prime,"The question is Suppose p is a prime number and p does not divide a. Prove that the congruence $ax \equiv 1 \mod p$ has a solution (Without using Fermat's Theorem), I can intuitively tell this is true because since $p$ is prime, every $x < p$ is co-prime to it, thus
$$x \mod p$$ 
Will produce a unique integer for each $x \in \{0, 1, 2, .... p-1\}$, before it cycles over again at $p$. Clearly, some $x$ must have that $x \mod p = 1$. However, I don't know how to prove this for $ax$, mainly because I can't prove the ramifications it can have on the mod cycle. What I do know is that if for some $x$, we have:
$$ax \equiv ay \mod p$$
Then since $p$ doesn't divide $a$ (by question assumption), it must divides $x - y$, implying that the solution for $ax \equiv 1 \mod p$ only depends on $x$, however, I don't know how to show this rigorously. Could anyone enlighten me?","['number-theory', 'modular-arithmetic', 'elementary-number-theory']"
1975167,Two Circles Can Have At Most One Common Chord? (IMO),"I am currently working to understand a combinatorics problem. Within the proof they state that "" Two circles can have at most one common chord ..."" and I do not understand why this is true. I've included a screenshot from my textbook. The book then goes on to finish the proof. Now I can follow everything before the last paragraph, but have no idea why two circles can have at most one common chord (last full sentence of last paragraph). Question: Can you please provide some explanation for why two circles can have at most one common chord?","['combinatorics', 'geometry']"
1975187,Proving area of triangle formed at parallelogram midpoint is 1/4 of the parallelogram?,"ABCD is a parallelogram . X is the midpoint of AD & Y is the midpoint of BC. Show that the area of $\triangle {ABX}$ is $\frac{1}{4}$ the area of ABCD Can you help me with this proof? Where should I start? I think It should be by proving $\triangle{DBC} \cong \triangle{DBA} $ using SAS as DB is a common side DC= AB as ABCD is a parallelogram, $\angle {BDC} = \angle{DBA} $ alternate angles And I can also predict that the use of the midpoint theorem here. Many thanks!","['proof-writing', 'geometry']"
1975194,"Debate about Cardinality of Reals vs. Cardinality of $[0,2\pi)$","My teacher claimed that the cardinality of the points on the unit circle (i.e. $[0,2\pi))$ was strictly greater than the cardinality of $\mathbb{R}$. I suspect he was mistaking the necessity of the existence of a bijection with the existence of a continuous bijection (which obviously wouldn't exist here). Am I right or am I missing something? The whole crux of his argument rested on a vague geometric argument and intuitively I could see why he'd think that but there is nothing intuitive about cardinals from what I've seen so far. Someone please put this to rest so I can finally sleep.",['elementary-set-theory']
1975201,Is a connected set union limit point a connected set?,"Good night, I'm trying this exercise: Let $C\subset\mathbb{R}^n$ connected and let $x$ be an accumulation point of $C$. Prove that $C\cup\{x\}$ is connected. I understand the exercise, geometrically at least, it makes a lot of sense but no luck trying to prove it, by previous examples, I get that, the idea of working with contentedness is by contradiction using the disjoint sets that their union are the disconnected set, but I can't get to use the definition of accumulation point in my proof, any hints or ideas would be appreciated, thanks.","['general-topology', 'metric-spaces', 'connectedness']"
1975317,"Does there exist a $G$-invariant polynomial $f \in \mathbb{C}[x_1, \ldots, x_n]^G$ such that $f(u_1, \ldots, u_n) = 0$ and $f(v_1, \ldots, v_n) = 1$?","Let $G$ be a finite subgroup of $\text{GL}(\mathbb{C}^n)$ and let $u = (u_1, \ldots, u_n)$, $v = (v_1, \ldots, v_n) \in \mathbb{C}^n$ be two points which do not belong to the same $G$-orbit in $\mathbb{C}^n$. Question. Does there exist a $G$-invariant polynomial $f \in \mathbb{C}[x_1, \ldots, x_n]^G$ such that $f(u_1, \ldots, u_n) = 0$ and $f(v_1, \ldots, v_n) = 1$?","['polynomials', 'abstract-algebra', 'group-actions', 'group-theory', 'linear-algebra']"
1975339,Let $f$ be a real uniformly continuous function on the bounded set $E$ in $\mathbb{R^1}$. Prove that $f$ is bounded on $E$,"Let $f$ be a real uniformly continuous function on the bounded set $E$ in $\mathbb{R^1}$. Prove that $f$ is bounded on $E$ My (Attempted) Proof Since $E$ is bounded, put $\alpha = \sup E$, $\beta = \inf E$. Now since $f$ is uniformly continuous on $E$, we only have to prove convergence of $f$ as $x \in E \to \alpha$ and $x \in E \to \beta$. So let $\{x_n\}$ be a  Cauchy sequence and fix $\epsilon > 0$. Let $\delta$ be such that $d(f(p), f(q)) < \epsilon$. Now take $N$ so large such that $m, n > N \implies d(x_n, x_m) < \delta$. We then have $d(f(x_n), f(x_m)) <  \epsilon$ (By uniform continuity of $f$) Thus $\{f(x_n)\}$ is a Cauchy sequence, and thus converges to some point $L \in \mathbb{R^1}$ $$\begin{aligned}\therefore \text{As} \ \ x_n \to \beta \ , \  \ f(x_n) \to L_1\\
\ \ x_n \to \alpha \ , \  \ f(x_n) \to L_2\\\end{aligned}$$ ( Comment: Since we let $\{x_n\}$ be an arbitrary Cauchy sequence, we can pick two different Cauchy sequences, one that converges to $\beta$, and one that converges to $\alpha$, and thus the above statement holds) Now put $\gamma = \max\{L_1, L_2, f(x)\  | \  x \in E\}$ and $\eta = \min\{L_1, L_2, f(x)\  | \  x \in E\}$. Then we have $\gamma = \sup f[E]$, and $\eta = \inf f[E]$, and thus $f[E]$ is bounded. $\ \square$ First of all if my proof rigorously correct? Secondly, if you have any criticism on my proof-writing skills, please let me know, as I'm always looking to improve. Finally, I proved that $f$ is bounded on $E$ by proving that the sequence $\{f(x_n)\}$ was Cauchy, and would thus converge, but are there other cleaner/more efficient ways of proving that $f$ is bounded on $E$?","['real-analysis', 'alternative-proof', 'proof-verification', 'proof-writing', 'metric-spaces']"
1975360,Find values of $a$ such that $\frac{x^2-x}{1-ax}$ attains all real values,"Find values of $a$ such that
  $$\frac{x^2-x}{1-ax}$$
  attains all real values. I first tried to find the range of the above by equating the above to some $y$. Solving I get $x^2+x(ay-1)-y=0$. How do I proceed?","['algebra-precalculus', 'functions']"
1975363,Solving recurrence $a_n = (1 + a_{n - 1})/a_{n - 2}$,"I have the following problem: Solve the recurrence relation $a_n = (1 + a_{n - 1})/a_{n - 2}$ for $a_0 = \alpha$ and $a_1 = \beta$. I don't have idea how to do it. I belive the problem is that it's not a linear recurrence equation (my problem is equivalent to $a_na_{n-2} = 1 + a_{n-1}$). Could you give me some tips about the problem or solving such equations in general, please?","['recurrence-relations', 'sequences-and-series']"
1975485,Prove using an inequality that $e$ is irrational,"I have to prove that $e$ is irrational using this inequality $$0<e-\sum_{k=0}^n\frac1{k!}<\frac1{n\cdot n!}$$ The exercise leave the hint ""prove by contradiction"". I know too that $2<e\le 3$. What I tried is set $e=p/q$ for $p,q\in\Bbb N$, and $\sum 1/k!=A/n!$ where $A\in\Bbb N$. Then I written $$0<\frac{p}{q}-\frac{A}{n!}<\frac1{nn!}$$ but I dont get any idea from here. Indeed I dont know exactly what to do here, I never used a inequality to prove the irrationality of a number. Can you give me some hint (or solution)? Thank you. P.S.: I dont know exactly what kind of tags I have to use for this question.","['proof-writing', 'irrational-numbers', 'analysis']"
1975506,Find the perimeter of a triangle.,"Let $ABC$ be an acute-angled triangle in which $D,E,F$ are points on $BC,CA,AB$ respectively such that $AD$ is perpendicular to $BC,AE=EC,CF$ is bisects angle C internally. Suppose $CF$ meets $AD$ and $DE$ in $M,N$ respectively . If $FM=2,MN=1,NC=3$, find the perimeter of triangle $ABC$.
It is the problem. Somebody help me.I can't proceed it.",['geometry']
1975608,Why won't a series converge if the limit of the sequence is 0?,"Just thinking about it in terms of logic, shouldn't the series of a sequence whose limit as $n$ approaches infinity is 0 converge? I know that the $n$th term test for divergence says that if a series is convergent, then the limit of its sequence is 0 and I also know there are some sequences for which it has been ""proven"" that their series does not converge even though the sequence converges to 0, but I just don't believe these tests. If we stretch $n$ out to infinity and the terms are approaching 0, then how is it possible for the sum of the terms to ""overflow"" and diverge if the terms are becoming negligibly small?","['divergent-series', 'convergence-divergence', 'limits']"
1975613,What does $\mathbb P\{X\geq 1\}$ mean in probability theory?,"Let $(\Omega ,F,\mathbb P)$ a probability space and $X$ a random variable.  I have a doubt on a definition. Does $\mathbb P\{X>1\}=0$
means that $X(\omega )\leq 1$ for all $\omega \in \Omega $ ? Or it can have an $\omega \in \Omega $ s.t. $X(\omega )>1$ ? For example, I know that in a measurable space $(\mathbb R,\mathcal B,m)$, we have for example for $f=\mathbb 1_\mathbb N$ that $$m\{x\mid f(x)=1\}=0,$$ but $f(1)=1$ anyway (i.e. that there exist very few but some $x$ s.t. $f(x)=1$). Does for probability it's the same or to say that $$\mathbb P\{X\in A\}=0$$
tell us that there is no $\omega \in \Omega $ s.t. $X(\omega )\in A$ ?","['probability-theory', 'random-variables']"
1975656,Second order evolution ODE,"I'm studying an article about the decay of solutions to some evolution equations of second order and i'm trying to understand the simple ODE case : $y'' +  y' + f(y) = 0 $ with $f(y)=y^2$ or $y^3$ or more generally $f(y)=c|y|^{a-1}y$, $c \in \mathbb{R}, a>1$ I would love to understand just the case $y'' +  y' + y^2 = 0$. Any help please ? I thought about using Cauchy-Lipschitz for the existence and uniqueness of the solution.",['ordinary-differential-equations']
1975680,5 number summary vs mean and standard deviation,"Hello i have a few numbers and i want to describe them using the best tool for this case: Either the 5-number summary or the mean and the standard deviation .But since i am statistics newbie i dont know when 5NS is better than mean and SD.In this specific case we have the following numbers: 130 125 107 97 96 94 86 83 82 81 58 55 54 52 48 47 45 45 42 41 39 39 39 38 36 35 34 5NS give us : Minimum.   1st Quartile.   Median.     3rd Quartile.      Maximum. 
     34.0      40.0          52.0          84.5            130.0 and mean with standard deviaton give us: mean=64 and standard devation = 26.19 Which one is better to describe our data in this case and when is 5NS better to use than Mean and SD??","['means', 'statistics', 'standard-deviation']"
1975729,topology on rings of quotients e.g. meromorphic functions,"Suppose that we have a noetherian domain $R$. Then we can construct the ring of fractions by the method described in Goodearl & Warfield. Now suppose that $R$ has a topology. What sort of sensible topologies can we get on the ring of fractions? For a concrete (even commutative) case, consider the polynomials on $\mathbb{C}$, with quotient ring the meromorphic functions. What topologies do we have here? I assume we have a topology of uniform convergence on compact sets where the denominator does not vanish. However one problem is the creation of what might be called `pole-antipole pairs', where we take (z-1)/(z-a) for a constant $a$ and then vary $a$ near $a=1$ (depending on application, a topology allowing such pair creation might be useful or it might be very bad). This means that a topology on meromorphic functions might not be so obvious as it seems (to me at least). There is always the topology of the set of functions into the compact Riemann sphere. Apologies for the question which doubtless has some well known solution. I would be very happy if someone could give me some references to look up, especially for the general noncommutative case.","['abstract-algebra', 'general-topology', 'reference-request', 'algebraic-geometry']"
1975747,Random walk with centered increments,"Let $X_1, X_2,\cdots$ be a sequence of independent, identically distributed random variables and $\displaystyle S_n=\sum_{i=1}^{n}X_i$. Then  $EX_{1} <0$ if, and only if , $\displaystyle\lim_{n \rightarrow \infty } S_{n} = -\infty \quad\text{a.s.}$ If  $EX_{1} < 0$ then $\displaystyle\lim_{n \rightarrow \infty } S_{n} = -\infty \quad\text{a.s.}$   using the strong law of large numbers. This shows one of the  implications. Now, suppose that  $EX_{1} \geq 0$. If $EX_{1} > 0$ then $\displaystyle\lim_{n \rightarrow \infty } S_{n} = \infty \quad\text{a.s.}$ using the strong law of large numbers, contradiction. But I can not show the case where $EX_{1} = 0$. Help?","['random-walk', 'law-of-large-numbers', 'probability-theory', 'random-variables']"
1975751,Understanding the slope of a line as a rate of change,"I thought I was confident about what is meant by the slope of a line and how it relates to a rate of change , but I'm having doubts and I'm hoping that someone will be able to help me clear them up. As I understand it, intuitively the slope of a line is a number $m$ that quantifies the amount it inclines from the horizontal, and its direction. Now, if $y$ is a function of $x$, such that $y=mx+c$, then one can quantify the rate of change in $y$ as one changes $x$ via the the ratio of their coordinate differences, such that $$m=\frac{\Delta y}{\Delta x}$$ Heuristically, can one (hopefully correctly) understand this quantity as follows: The value of the function $y$ changes by an amount of $\Delta y$ units for every $\Delta x$ units change in $x$. Therefore, the value of $y$ changes by an amount $\frac{\Delta y}{\Delta x}$ units per unit change in x , which is exactly the rate of change in $y$ with respect to $x$ , since it quantifies the amount the value of $y$ changes per unit change in $x$. Would this be a correct understanding at all?","['algebra-precalculus', 'slope', 'intuition']"
1975753,Integrating factor formula derivation plus-minus problem,"I'm trying to derive the formula for the solution of a first order ODE, $y = e^{-\mu(x)}\int e^{\mu(x)}q(x)dx$ with $\mu(x) = \int p(x)dx$ for the form $y'+p(x)y = q(x)$. Here's what I did: Rewriting the general form $y'+py = q$, we get
\begin{equation}
\left[q(x)-p(x)y\right]dx = dy.\label{eqn:int-fact2}
\end{equation}
Now state $M = q(x) - p(x) y$, $N=1$ and assume left and right hand side to be a constant:
\begin{equation}
\frac{dM}{dy} = \frac{dN}{dx} = C\label{eqn:int-fact-MN}
\end{equation}
Use integrating factor $\mu(x)$ to ensure exactness:
\begin{equation}
\frac{d[\mu(x) \cdot M]}{dy} = \frac{d[\mu (x) \cdot N]}{dx} \Rightarrow \mu(x) \frac{dM}{dy} = \mu(x) \frac{dN}{dx} + \frac{d\mu(x)}{dx} N.
\end{equation}
\begin{equation}
\mu(x)\left[-p(x)\right] = \frac{d\mu(x)}{dx} \Rightarrow -p(x)dx = \frac{d\mu(x)}{\mu(x)}.
\end{equation}
\begin{equation}
\ln \mu(x) = -\int p(x)dx \Rightarrow \boxed{\mu(x) = e^{-\int p(x)dx}}
\end{equation}
\begin{equation}
\int \left[q(x)-p(x)y\right]dx =\int dy,
\end{equation}
\begin{equation}
\int e^{-\int p(x)dx}dy = e^{-\int p(x)dx}y + C(x) 
\end{equation}
\begin{equation}
p(x)ye^{-\int p(x)dx} + C'(x)= q(x)e^{-\int p(x)dx} + p(x) y e^{-\int p(x)dx}
\end{equation}
\begin{equation}
C'(x)= q(x)e^{-\int p(x)dx} \Rightarrow C(x) = \int q(x)e^{-\int p(x)dx}dx + C.
\end{equation}
Choose $C=0$ to get:
\begin{equation}
e^{-\int p(x)dx}y + \int q(x)e^{-\int p(x)dx}dx = 0 
\end{equation}
\begin{equation}
e^{-\int p(x)dx}y  = - \int q(x)e^{-\int p(x)dx}dx \Rightarrow \boxed{y = - e^{\int p(x)dx}\int q(x)e^{-\int p(x)dx}dx}
\end{equation} So why am I ending up with ye olde $+\mapsto-$ and $-\mapsto+$? Where is the error?",['ordinary-differential-equations']
1975786,Vanishing terms in Leray spectral sequence,"Let $f:X\to Y$ be a continuous map of complex manifolds. Consider $H^p(Y;R^qf_*V)$, where $V$ is a vector bundle on $X$, and $R^qf_*V$ are the higher direct images. (This is the $E_2^{p,q}$ term in the Leray spectral sequence associated to $f$ for the vector bundle $V$.) Is it the case that $H^p(Y;R^qf_*V)=0$ for $q>\text{dim}_{\mathbb{C}}\,X-\text{dim}_{\mathbb{C}}\,Y$? I recall seeing this stated somewhere, but I have been unable to find this again, and I haven't been able to prove this statement to myself.","['derived-functors', 'algebraic-geometry', 'sheaf-cohomology', 'spectral-sequences', 'vector-bundles']"
1975789,Limit of $\left\{ \int_{0}^{1} [bx + a(1 - x) ]^{\frac1n} dx \right\}^n$ as $n \to \infty$,"Evaluate the limit for $0 < a < b$ , $$\lim_{n \to \infty} \left\{ \int_{0}^{1} [bx + a(1 - x) ]^{\frac1n} dx \right\}^n$$ Note that the exponent $~1/n~$ is inside the integration on the entire integrand $~a + (b-a)x,~$ and the exponent $n$ is outside on the definite integral. One solution is available given this particular definition of the logarithm function as a limit: $$\log x = \lim_{h \to 0} \frac{x^h - 1}h  \quad \text{, or equivalently} \quad\log x = \lim_{n \to \infty} n(x^{\frac1n} - 1)$$ This solution is an algebraic maneuver that involves terms like $~e^{b\log b},~$ where one first obtains $~\log b~$ as a limit, and then only after another limit can one arrive at $~b^b~$ eventually. My question is this: how does one evaluate the limit more directly without this seemingly redundant path of log on the exponent? In short, there's an approach at hand that is unsatisfactory, and I believe there are better ones. As a reference, below is the detailed steps of the circuitous solution outlined above: The definite integral evaluates to $$\frac1{b - a} \frac1{ 1 + \frac1n } \left[ a + (b-a)x \right]^{ 1 + \frac1n } \Bigg|_{0}^{1} = \frac{ b^{1 + \frac1n} - a^{1 + \frac1n} }{b - a} \frac1{ 1 + \frac1n }$$ Thus the whole expression becomes $$
\begin{align}
&\lim_{n \to \infty} \left\{ \frac{ b^{1 + \frac1n} - a^{1 + \frac1n} }{b - a} \frac1{ 1 + \frac1n } \right\}^{n} \\
&= \frac1e \lim_{n \to \infty}  \left\{ 1 +  \frac{ b^{1 + \frac1n} - a^{1 + \frac1n}  - (b - a) }{b - a} \right\}^{n} \\
&= \frac1e \lim_{n \to \infty}  \left\{  1 +  \frac{ n \left( b^{1 + \frac1n} - b \right) - n \left( 
	a^{1 + \frac1n} - a \right) }{ n (b - a) } \right\}^{n}
\end{align}
$$ all the limits exist so I'm just gonna keep writing in this non-rigorous way $$
\begin{align}
&= \frac1e \lim_{n \to \infty}  \left\{  1 +  \frac1n \frac{ b \log b - a \log a }{ b - a } \right\}^{n} 	\\
&= \frac1e	\cdot e^{ \frac1{b-a} \left( b \log b - a \log a \right)} \\
&= \frac1e	\left( \frac{ b^b }{ a^a } \right)^{ \frac1{b-a}}
\end{align}$$","['alternative-proof', 'limits', 'logarithms', 'calculus', 'exponentiation']"
1975795,An improbable Euchre game -- A 9$\spadesuit$ kind of evening,"Setup During a game of cutthroat euchre (3 players instead of 4), my girlfriend won the game by playing as her last card, the 9$\spadesuit$.  Given that euchre is played with a deck consisting of 9s, 10s, Js, Qs, Ks, and Aces, and trump was a different suit, this was one of the 3 lowest cards in the deck. That's a pretty awesome way to win the game, but it gets better.  In addition to playing the 9$\spadesuit$, she also took all 5 tricks in that hand and therefore got two points to win the game instead of the standard one point you get for only making your bid. Adding on to the improbable nature of this game, the 9$\spadesuit$ was turned up five times as the bid card -- she turned it up three times, her father turned it up once, and I turned it up once. The game ended with scores of 10, 8, and 3, which meant, since hers was the only two point hand, we played 19 hands. I refer those who are unfamiliar with Euchre to the rule set here . Goal I'd love to figure out the probability of the 9$\spadesuit$ turning up 5 times as the bid card and then extend that probability to include the fact that the the 9$\spadesuit$ was also the card used to win the game by taking all tricks in the final hand. Start of a Solution Because you shuffle between each hand, I believe the probability of any one 9 (since we would have been just as flabbergasted with any 9) coming up 5 times as the bid card in a game of 19 hands is: $$ P_{\text{particular card coming up 5 times}} = \frac{4}{24} \cdot \left(\frac{1}{24}\right)^{4} = \frac{1}{1,990,656} $$ But here is where my stats fail me.  How do I model the probabilities of the hand being played? If I want to model the probability of the 9$\spadesuit$ being the card to win the last hand, do I have to include the probability of the 9$\spadesuit$ not being the last card during the other hands?  I'm thinking something like this pseudo equation: $$ P_{\text{dealt the right 9}} \cdot P_{\text{playing the 9 last}} \cdot P_{\text{taking all tricks}} \cdot P_{\text{something about winning the game?}} \cdot P_{\text{something else?}} $$ I believe we can calculate the first probability via: $$ P_{\text{dealt the right 9}} = 1 - (P_{\text{not being dealt the right 9}}) = 1 - (\frac{23}{24} \cdot \frac{22}{23} \cdot \frac{21}{22} \cdot \frac{20}{21} \cdot \frac{19}{20}) = \frac{5}{24} $$ Can I calculate the second probability via this?  This result is non-intuitive to me. $$ P_{\text{playing the 9 last}} = 1 - P_{\text{not playing the 9 last}} = 1 - (\frac{4}{5} \cdot \frac{3}{4} \cdot \frac{2}{3} \cdot \frac{1}{2}) = \frac{4}{5} $$ Could I use a pre-calculated probability for the fact that she took all 5 of the tricks on the last hand?  If I found a resource online that gave the probability of taking all 5 tricks in a Euchre hand, how would I integrate that?","['probability', 'card-games']"
1975799,solve x for a cubic congruence equation with large prime mod.,"For $x^3 = 123456789 \pmod{1000000007}$ given $1000000007$ is a prime. Find $x$. My school only teach us about linear congruence equation, and it is an extra credit question. Therefore, I think the question can solve by using the concept only in linear congruence equation. Original, for $ax = b \pmod{k}$, i usually would do an extended euclid algorithm. However, in this case, seem the algorithm cannot be apply. Can anyone give me some helps??","['congruences', 'polynomial-congruences', 'prime-numbers', 'modular-arithmetic', 'discrete-mathematics']"
1975805,Limit involving $(1+x)^x$ term,"I don't know how to solve the following limit without using series expansion. $$\lim_{x\to 0} \frac{(1+x)^x -1 -x^2}{x^3} $$ I have tried use L'Hopital's rule and finding bounds to use squeeze theorem but to no avail. Please give me hints on how to compute the limit, instead of posting full answers. Thanks in advance :) Edit: I have just found an answer, though it is not elegant at all. It is done simply by applying L'Hopital's rule three times and there is not much to say about it. Still, other answers are welcome.","['real-analysis', 'calculus', 'limits']"
1975821,"Looking for more ""exotic"" classes of polyhedra","I am aware of the Platonic Solids, the Archimedean Solids, the Catalan Solids, the Johnson solids, Goldberg polyhedra, deltahedra and some zonohedra. I am interested in more names of polyhedra, specifically 3D polyhedra with iscosehedral symmetry and unit edge lengths. I do not require regular faces (as something like the rectified truncated icosahedron and the snub rhombic triacontahedron are the sort of polyhedra I am interested in). I am also interested in links to images.","['polyhedra', 'big-list', 'soft-question', 'geometry']"
1975954,Solving the logistic equation $dx/dt=x(1-x)$,"In Arnold's Ordinary Differential Equations, Arnold asks the reader to work out the solution to
$$ \dot{x} = x(1-x) $$
and Arnold gives the derivation
$$ t= \int {dx \over x(1-x)} = \ln(x/1-x), \hbox{ or } x={e^t \over 1+e^t} $$
Trying this out on my own, I take a partial fractions approach: If we assume
$$ {1 \over x(1-x)} = {A \over x} + {B \over 1-x} $$
then
$$ 1 = A(1-x) + Bx = (B-A)x+A $$
so $A=1$ and $B=1$. Hence
$$ {1 \over x(1-x)} = {1 \over x} + {1 \over 1-x} $$
implying that
$$ t=\int {dx \over x(1-x)} = \int {dx \over x} + \int {dx \over 1-x}
                          = \ln(x(1-x)) $$
contrary to Arnold's claim. Additionally, if seems to me that if we then solve for x in terms of $t$, we do not obtain
$$ x={e^t \over 1+e^t} $$
as we should for the ``known solution'' to the logistic curve. Can someone please explain what is going on, and where my or Arnold's solution goes wrong?","['integration', 'ordinary-differential-equations', 'calculus']"
1975966,Subgroup of free group on two elements free of rank $6$.,"Let $F$ be the free group on two elements $x$, $y$. To make our lives easier, we denote $x^{-1}$ by $X$ and $y^{-1}$ by $Y$. Let $g_i$ for $i = 1, \ldots, 6$ be the following elements:$$g_1 = xyxY,$$$$g_2 = XYXyxYxyXyxYXYXyxYxyxyXYY,$$$$g_3 = XYXyx,$$$$g_4 = YxyXyxYXYXyyx,$$$$g_5 = YxyXYxyxyX,$$$$g_6 = xxYXXy.$$Let $G$ be the subgroup of $F$ generated by the $g_i$. Question. How do I see that $G$ is free of rank $6$?","['abstract-algebra', 'free-groups', 'algebraic-topology', 'geometric-topology', 'group-theory']"
1975969,Interesting mathematical artifact: Equality sign wrong for exponential function.,"I found an interesting case where it seems like an equality sign works wrong. Let's consider the following construction: $\frac{1+\Lambda}{2} e^{i\Lambda \phi}$ where $\Lambda = \pm1$, so $\Lambda^2=1$. Then I apply Euler formula: $\frac{1+\Lambda}{2} e^{i\Lambda \phi} = \frac{1+\Lambda}{2} (\cos \phi + i\Lambda \sin \phi)= \frac{1}{2} \cos \phi + \frac{\Lambda}{2} \cos \phi + \frac{i\Lambda}{2} \sin \phi + \frac{i}{2} \sin \phi = \frac{1+\Lambda}{2} e^{i\phi}$ where I have used $\sin(\Lambda \phi) = \Lambda \sin \phi$ and $\cos (\Lambda \phi) = \cos \phi$. However, this is just wrong! $e^{i\Lambda \phi}\neq e^{i \phi}$ even though the equality sign was not broken anywhere in between (at least it doesn't seem to be broken to me). What am I doing wrong?",['trigonometry']
1976129,"What does Differential Geometry lack in order to ""become Relativity"" - References","Given a regular curve $\gamma \colon I \to \mathbb{R}^n$, if we consider the variable $t \in I \subset \mathbb{R}$ as the time, then we have the usual interpretation of $\gamma'(t)$ as the (instantaneous) velocity vector at the position $\gamma(t)$ and $\lvert\gamma'(t)\rvert$ as the speed (or scalar velocity). From this point of view, we know from differential geometry (very classical examples, indeed) that there are curves that ""go through infinite length in a bounded amount of time"". Of course, at these examples, the speed of these curves increase infinitely (""goes to infinity""). I have very rough ideas concerning Relativity Theory (I'm a mathematician, not a physicist) but I know that, for example, the speed a object can reach is bounded by the speed of light, and that mass, lengths and even the time are distorted at very high speed (near the speed of light). As I said, I'm not an expert on this subject, so maybe my question even make sense, but what axioms do I insert to my models in order to get such results, from a purely mathematical/axiomatic point of view? Is the answer to this ""the Einstein postulates""? I want to know also if there is an area which study this kind of ""differential geometry + relativity"" (or even a ""Riemannian geometry + relativity""). Would the answer to this question be simply ""Relativity""? (as I said, I don't have a deep knowledge on that). (Is there) Do you recommend any references at this subject?","['reference-request', 'differential-geometry', 'general-relativity']"
1976163,"If a field extension is separable, then $[E:F]=[E:F]_s$?","Lang's definition Let $E/F$ be an algebraic field extension and $\bar{F}$ be an algebraic closure of $F$ . Define $[E:F]_s$ as the cardinal of field monomorphisms $\sigma:E\rightarrow \bar{F}$ fixing $F$ . Let $E/F$ be a separable extension. I know that if the extension is finite, $[E:F]=[E:F]_s$ . I'm curious about the case extension is infinite. Is it still $[E:F]=[E:F]_s$ ? There is an example that a separable extension possessing uncountable degree, so it does not seem easy to prove this.","['abstract-algebra', 'field-theory']"
1976222,Can an unbounded sequence have a convergent cesaro mean?,"I was wondering if an unbounded sequence may have a convergent cesaro mean ($\frac{1}{n}\sum_{k=1}^n a_n$). I was maybe thinking of $$a_n = (-n)^n$$
as a sequence having a convergent mean, but I might be wrong. Anyways, how would you proceed to prove such an intuition?","['cesaro-summable', 'sequences-and-series', 'limits']"
1976264,How to show that $E \left[ ( V-E[V|V+U])^2VU \right] =-2E \left[ \left( \text{Var}(V|V+U) \right)^2 \right]$,"Let $V$ and $U$ be independent random variables (but not identical) and let 
  \begin{align*}
W=V+U,
\end{align*}
  Is it true that 
  \begin{align}
E \left[ ( V-E[V|W])^2 \frac{VU}{2} \right] &= - E \left[ \left(E\left[ ( V-E[V|W])^2 |W \right] \right)^2 \right]\\
&=-E \left[ \left( Var(V|W) \right)^2 \right],
\end{align}
  where  $E\left[ ( V-E[V|W])^2 |W \right]= Var(V|W)$? We can verify that this is true if $V$ and $U$ are standard normal. Since $E[V|W]= \frac{W}{2}$, on the one hand, we have 
\begin{align}
E \left[ ( V-E[V|W])^2 \frac{VU}{2} \right] = E \left[ ( V-\frac{W}{2})^2 \frac{VU}{2} \right] \\
= E \left[ ( \frac{V}{2}-\frac{U}{2})^2 \frac{VU}{2} \right] =-\frac{1}{4}.
\end{align} On the other hand, using that $Var(V|W)= E[V^2|W]-(E[V|W])^2$ it is not difficult to show that $Var(V|W)=1/2$  and we have 
\begin{align}
-E \left[ \left( Var(V|W) \right)^2 \right]=-\frac{1}{4}.
\end{align} There is a possibility that I am missing a constant factor. So, lets assume that both $U$ and $V$ are zero mean and unit variance (but not identically distributed). Also, what other good examples can we use to see if it is a valid identity? Thank you.","['probability-theory', 'conditional-expectation', 'expectation']"
1976303,Cross product with curl,"I'm trying to compute $u \times(\nabla \times v)$. My solution so far is below: \begin{align*}
[u \times (\nabla \times v)]_i& = \epsilon_{ijk}u_j\epsilon_{klm}\partial_lv_m \\
& =\epsilon_{kij}\epsilon_{klm}u_j\partial_lv_m \\ 
&=u_j\partial_lv_m(\delta_{il}\delta_{jm}-\delta_{im}\delta_{jl}) \\ & =u_j\partial_iv_j-u_j\partial_jv_i \\
\end{align*} I can see that the second term will give me $(u\cdot\nabla)v$, but I'm not sure what to do with the first term.","['cross-product', 'calculus']"
1976319,Lie Bracket of Lie Algebra Associated with Given Lie Group,"Let $G$ be a Lie group. Its Lie algebra, when considered as a vector space, is given by $T_e G$, the tangent space of $G$ at the identity element $e$. However, in order to fully describe the Lie algebra associated with $G$ we must also describe the commutator $\left[\cdot,\,\cdot\right]:T_eG^2\to T_eG$ and show that it obeys the three axions: bilinearity, alternativity and the Jacobi identity. Following Wikipedia, one defines first for any $g\in G$ left multiplication on $G$ by $g$ as $$ l_g:G\to G$$ given by $$ x\mapsto gx$$and a left-multiplication invariant vector field $X\in TG$ is one which obeys for every $\left(g,\,h\right)\in G^2$ $$ \left(d l_g\right)_h X_h = X_{gh} $$ where $\left(d l_g\right)_h:T_hG\to T_{gh}G$ is the differential of $l_g$ at $h$. We define $Lie\left(G\right)$ as the vector space of left-multiplication invariant vector fields. Apparently $G\times Lie\left(G\right)$ is isomorphic to $TG$ via $$\left(g,X\right)\mapsto\left(g,X_g\right)$$ so that we get a $\natural$ isomorphism $Lie\left(G\right)$ with $T_eG$ given by $$Lie\left(G\right)\ni X \mapsto X_e\in T_eG$$This last isomorphism we call $\phi$. Now apparently there is a Lie bracket structure on $TG$ which induces a Lie bracket structure on $Lie\left(G\right)$: for any $X$ and $Y$ in $TG$ we have $$ \left[X,\,Y\right]_{TG}= X\left(Y\left(\cdot\right)\right)-Y\left(X\left(\cdot\right)\right)$$ This in turn can be pushed forward to a define our desired Lie bracket on $T_e G \equiv \frak{g} $ via: If $X$ and $Y$ are any tangent vectors in $T_eG$ then $$\left[X,\, Y\right]_{T_eG}=\phi\left[\phi^{-1}\left(X\right),\,\phi^{-1}\left(Y\right)\right]_{TG}$$ My question is: is there now any easier way to describe $\left[\cdot,\,\cdot\right]:T_eG^2\to T_eG$? I tried for example to write it in coordinates and it was a mess. How do you ""easily"" see how $\left[X,\, Y\right]_{T_eG}$ acts on any scalar function $f$ given some $X$ and $Y$ in $T_eG$?","['vector-fields', 'definition', 'differential-geometry', 'lie-algebras', 'lie-groups']"
1976328,The join of disjoint varieties in disjoint linear spaces has dimension $\dim X +\dim Y+1$,"Let $X, Y \subset \Bbb P^n$ be disjoint projective varieties. Their join $J(X,Y)$ is the set of all points on lines joining a point of $X$ to a point of $Y$. It is a projective variety. The dimension of the join is always $\dim X +\dim Y+1$. Harris (page 148) writes that in the case where $X$ and $Y$ lie in disjoint linear subspaces of $\Bbb P^n$ this is "" Immediate, since no two lines joining points of X and Y can meet, so every point of the join lies on a unique line joining X and Y "". I would like help on understanding this: Why two lines joining points on two disjoint linear varieties $L_1, L_2$ can never meet? Why does the set $L$ of lines joining points of $X$ to points of $Y$ have dimension $\dim X + \dim Y$? Assuming these two I know how to finish: looking at the set $$T=\{(l,z) : z\in l, l \text{ intersects both X and }Y\}$$ we see that $J(X,Y)$ is the image of the second projection $\pi_2$, so $\dim J = \dim T $ by (1), and moreover $\dim T = \dim L+1$ since all the fibers of $\pi_1$ have the same dimension 1. Alternatively, I'd like any approach to showing the following: Assume $X \subset H_1 \subset \Bbb P^n$ and $Y \subset H_2 \subset \Bbb P^n$ are two projective varieties, where $H_1 \simeq \Bbb P^k$ is the intersection of $n-k$ homogeneous linear polynomials, and likewise $H_2 \simeq \Bbb P^t$, and $H_1 \cap H_2 = \emptyset.$ Why $\dim J(X,Y)=\dim X+\dim Y+1$? I do know an inequality on one side: $\dim J(X,Y) \leq \dim X+\dim Y+1$ since $J(X,Y)=\pi_3(S)$, where $S=\{(p,q,z): z \in (pq)\} \subset X \times Y \times \Bbb P^n$.",['algebraic-geometry']
1976347,combinatorics: sum of product of integer compositions,"I am trying to solve a problem from Stanley's book, it says: Fix $k,n \in \mathbb{P}$ . Show that: \begin{align}
\sum a_1 a_2 \cdots a_k = \binom{n+k-1}{2k-1}
\end{align} where the sum ranges over all compositions $(a_1 , a_2 , \ldots , a_k)$ of $n$ into $k$ parts. I am trying to reason like this: we need to find the coefficient $c_n = \sum a_1 a_2 \cdots a_k$ from this generating function -- \begin{align}
\sum_n c_n x^n &= \sum_n \sum a_1 a_2 \cdots a_k x^n \\ 
&= \sum_n \sum a_1 a_2 \cdots a_k x^{a_1 + a_2 + \cdots + a_k}\\
&= \sum_n \sum a_1x^{a_1} a_2x^{a_2} \cdots a_kx^{a_k}
\end{align} after that, I have no clue, how do I solve this ? moreover, what is the range in the inner sum ? If we consider Mark Riedel's answer, and assume $n=4$ , $k=2$ ; then the sum will be \begin{align}
\sum (z + 2z^2)^2 = z^2 + 4z^3 + 4z^4
\end{align} On the other hand the compositions will be $(1,3), (2,2), (3,1)$ , therefore the above sum will be counted as: \begin{align}
(1.3)z^{1+3} + (2.2)z^{2+2} + (3.1)z^{3+1} &= 1z^1.3z^3 + 2z^2.2z^2 + 3z^3.1z^1\\ 
&= 3z^4 + 4z^4 + 3z^4 = 10z^4
\end{align} what's going on? what am I missing?","['generating-functions', 'combinatorics', 'integer-partitions']"
1976417,A community project: prove (or disprove) that $\sum_{n\geq 1}\frac{\sin(2^n)}{n}$ is convergent,"As the title says, I would like to launch a community project for
  proving that the series $$\sum_{n\geq 1}\frac{\sin(2^n)}{n}$$ is
  convergent. An extensive list of considerations follows. The first fact is that the inequality
$$ \sum_{n=1}^{N}\sin(2^n)\ll N^{1-\varepsilon}\qquad\text{or}\qquad\sum_{n=1}^{N}e^{2^n i}\ll \frac{N}{\log(N)^{1+\varepsilon}} \tag{1}$$
for some $\varepsilon>0$ is enough to prove the claim by Abel summation. In the same spirit, it is quite common to employ Weyl's inequality / Van der Corput's trick to prove the convergence of $\sum_{n\geq 1}\frac{\sin(n^p)}{n}$. In our case, however, we do not have an additive base of $\mathbb{N}$ made by perfect powers associated with some exponent, hence an additive base of finite order, so the estimation of the exponential sums appearing in the right side of $(1)$ is more difficult. Assuming that for an infinite number of primes $p$ the element $2$ is a generator of $\mathbb{Z}/(p\mathbb{Z})^*$ (Legendre's conjecture), we may probably regard $[1,N]$ as a subset of $\mathbb{Z}/(p\mathbb{Z})$ (for a huge $p$) and prove there is enough cancellation to grant $(1)$. However, Legendre's conjecture seems quite out-of-reach at the moment. Integral extimations techniques, that turned out to be pretty effective in other contexts , are almost ineffective here, since $\sin(2^x)$ oscillates too fast, so that there is no reason for expecting that
$$ \sum_{n=M+1}^{M+N}\sin(2^n)\approx \int_{M}^{N+M}\sin(2^x)\,dx, $$
so, even if $\lim_{N\to +\infty}\int_{1}^{N}\sin(2^x)\,dx$ is convergent by Dirichlet's test, there is little use of that. However, the series $g(\xi)=\sum_{n\geq 1}\frac{\sin(2^n\xi)}{n}$ is convergent for almost every $\xi$, since $g\in L^2\left(-\pi,\pi\right)$. Additionally, the statement there is enough cancellation to ensure $(1)$ appears to be equivalent to (or, at least, a consequence of) the statement the digits $0$ and $1$ in the binary representation of $\pi$ are equidistributed . It is hard to believe that is not the case, and the Bailey-Borwein-Plouffe formula $$\pi=\sum_{k\geq 0}\frac{1}{16^k}\left(\frac{4}{8k+1}-\frac{2}{8k+4}-\frac{1}{8k+5}-\frac{1}{8k+6}\right)\tag{2}$$
may provide a way to prove it.","['equidistribution', 'sequences-and-series', 'summation-by-parts']"
1976475,Two groups of numbers with close sums,"Let $n$ be a positive integer, and independently randomize numbers $x_1,\dots,x_n,y_1,\dots,y_n$ from $(0,1)$ uniformly. Fix a real number $r>0$. Let $p_n$ be the probability that the indices $\{1,\dots,n\}$ can be divided into two groups $A,B$ so that $$\left|\sum_{i\in A}x_i-\sum_{i\in B} x_i\right|<r \text{ and } \left|\sum_{i\in A}y_i-\sum_{i\in B} y_i\right|<r.$$ Is it true that $p_n$ approaches $1$ as $n\rightarrow\infty$? If we only have the $x_i$'s, then this is true by the following method. We can let $n$ be large enough so that there are likely more than $2/r$ numbers that are in $I=[r/2, r]$. We put the numbers one by one into the two groups, starting with those outside $I$, keeping the difference between the two groups less than $1$. Then we put in the numbers in $I$ so that the difference between the two groups is less than $r$.",['probability']
1976510,"Conjecture regarding integrals of the form $\int_0^\infty \frac{(\log{x})^n}{1+x^2}\,\mathrm{d}x$.","I have been playing around a bit with integrals of the form $$I(n)=\int_0^\infty \frac{(\log{x})^n}{1+x^2}\,\mathrm{d}x,\,\,n\in\mathbb{Z}^+,$$ and I am trying to obtain a closed form solution for $I(n).$ I believe the special cases $I(1)$ and $I(2)$ are somewhat well-known, but I will go over them. When $n=1,$ we have $$I(1)=\int_0^\infty \frac{\log{x}}{1+x^2}\,\mathrm{d}x=\int_0^1 \frac{\log{x}}{1+x^2}\,\mathrm{d}x+\int_1^\infty \frac{\log{x}}{1+x^2}\,\mathrm{d}x.$$ This can be easily shown to be zero by performing the substitution $x=1/y,$ which will yield $$\int_0^1 \frac{\log{x}}{1+x^2}\,\mathrm{d}x=-\int_1^\infty \frac{\log{x}}{1+x^2}\,\mathrm{d}x.$$ Thus, $I(1)=0.$ Clearly, this can be generalized to all odd integers, and $I(2n+1)=0.$ In the case of $n=2$, first observe through the same substitution as above that $$\int_0^1 \frac{(\log{x})^2}{1+x^2}\,\mathrm{d}x=\int_1^\infty \frac{(\log{x})^2}{1+x^2}\,\mathrm{d}x.$$ This implies that $$I(2)=2\int_0^1 \frac{(\log{x})^2}{1+x^2}\,\mathrm{d}x,$$ which is an easier integral to work with. Performing the substitution $x=e^{-y}$ yields $$I(2)=2\int_0^\infty y^2\left(e^{-y}-e^{-3y}+e^{-5y}-\cdot\cdot\cdot\right)\,\mathrm{d}y.$$ Using the identity $$\int_0^\infty x^2 e^{-ax}=\frac{2}{a^3},$$ we obtain $$I(2)=4\left(\frac{1}{1^3}-\frac{1}{3^3}+\frac{1}{5^3}-\cdot\cdot\cdot\right)=4\cdot\frac{\pi^3}{32}=\frac{\pi^3}{8}.$$
I'm not sure how this infinite series is evaluated, but I found this result in a book. I used Mathematica to check a few more values, and I found that $I(4)=5\pi/32,\,I(6)=61\pi/128,\,$ and $I(8)=1385\pi/512.$ Clearly the pattern is $$I(2n)=A_{2n}\left(\frac{\pi}{2}\right)^{2n+1},$$ where $A_{2n}$ is some constant. It turns out that these constants are the Euler numbers, which are the coefficients $E_k$ corresponding to the series $$\operatorname{sech}x=\sum_{k=0}^\infty\frac{E_k}{k!}x^k.$$
All Euler numbers corresponding to odd $n$ are zero, and the first few even Euler numbers are $E_0=1,\, E_2=-1,\, E_4=5, \,E_6=-61,\,$ and $E_8=1385.$ Thus, I have conjectured that $$I(2n)=(-1)^n E_{2n} \left(\frac{\pi}{2}\right)^{2n+1}$$ for all $n\in\mathbb{Z}^+.$ I suppose this could be extended to $n\in\mathbb{Z}_{\geq 0}$ thusly:
$$I(n)=i^n E_n \left(\frac{\pi}{2}\right)^{n+1},$$ since $E_n=0$ for odd $n.$ So the question, of course, is how to prove this. I tried generalizing the method I used for $I(2),$ and I found that $$\int_0^\infty x^n e^{-ax}=\frac{n!}{a^{n+1}},\,\,n\in\mathbb{Z}_{\geq 0}.$$ Using this, I obtained $$I(2n)=n!\left(\frac{1}{1^{n+1}}-\frac{1}{3^{n+1}}+\frac{1}{5^{n+1}}-\cdot\cdot\cdot\right)=n!\sum_{k=0}^\infty\frac{(-1)^k}{(2k+1)^{n+1}}.$$ Mathematica wasn't able to evaluate this sum, even for the case of $n=2.$ It gives some expression involving multiple zeta functions, with which I have no experience. Even if we can't prove this, I would be interested to know why the Euler numbers might appear here. Any help would be greatly appreciated. Edit : As Claude Leibovici helped point out, there final series expression should be $$I(2n)=2(2n)!\sum_{k=0}^\infty \frac{(-1)^k}{(2k+1)^{2n+1}}=\frac{(2n)!}{2^{4n+1}}\left[\zeta\left(2n+1, \frac{1}{4}\right)-\zeta\left(2n+1, \frac{3}{4}\right)\right].$$","['integration', 'definite-integrals', 'sequences-and-series']"
1976521,Reason why $P(X = k) = 0$ but $P( k_1 \leq X \leq k_2) \neq 0$ for continous random variable $X$,"This might be too easy (or almost trivial) for many out here, but i am having troubles with this. 
I know for any continous random variable $X$, $P(X = k) = 0$, however the probability that $X$ falls in $[k_1,k_2]$ is not necessarily zero, where $k_1 < k_2$. I've been using this notion since high school and collage, but I never seem to grasp the idea. Am i being too superficial or is it okay to pause and wonder a bit here? Thanks for your time.","['statistics', 'probability']"
1976577,When will a parametric solution exist for a Diophantine equation?,"Many Diophantine equations with infinite solutions I've seen have parametric solution. Example:
$$a=m^2-n^2$$
$$b=2mn$$
$$c=m^2+n^2$$
Implies: $$a^2+b^2=c^2$$
So pythagorean triples can be generated with arbitrary $$m>n>0$$
I specifically have in mind this equation:
$$ab(a+b)(a-b)=cd(c+d)(c-d)$$
So does there exist some f such that:
$$f(r, s, t)=(a,b,c,d)$$","['number-theory', 'diophantine-equations']"
1976613,Showing product of normal varieties is normal,"let $X, Y$ be two affine normal varieties, over an algebraically closed field $k$, I want to show that $X\times Y$ is still a normal affine variety. There is an answer for "" Does the fiber product of two normal varieties remain normal? "", but I haven't learned scheme theory, so I am looking for a proof I am able to deal with. So far, I can prove the result assuming $Y$ is affine space $Y=\mathbb A^n_k$. I list out sketch of my proof below. The strategy is that use the fact that the affine variety over a over an extended field $\mathbb A^n_{k(X)}$ is normal, (or equivalently affine space is geometrically normal ). Using this fact, if we have an element in $k(X\times \mathbb A^n_k)$ integral over $k[X\times \mathbb A^n_k]$, we can make the denumerator very simple (only relies on variables in $X$). However, this method cannot be generalized, so I have no idea to prove the general case $X\times Y$ is normal. Any suggestion or reference would be thankful. proposition Let $k$ be an algebraically closed field, $X\subset \mathbb A^m_k$ a normal affine variety, then the product variety $X\times \mathbb A^n_k$ is affine normal. sketch of proof : First $k[X\times \mathbb A^n_k]=k[X][y_1,y_2,...,y_n]$,  $k(X\times \mathbb A^n_k)=k(X)(y_1,y_2,...,y_n)$. We want to prove that the coordinate ring $k[X][y_1,y_2,...,y_n]$ of $X\times \mathbb A^n_k$ is integrally closed in its fraction field $k(X)(y_1,y_2,...,y_n)$. Let $f\in k(X)(y_1,...,y_n)$ be an element which is integral over $k[X][y_1,y_2,...,y_n]$. We break up the proof into two steps: Step 1 : Show $f\in k(X)[y_1,y_2,...,y_n]$ This is easy because polynomial ring over a field is always a normal domain. Step 2 : Show $f\in k[X][y_1,y_2,...,y_n]$ Since step 1 is down, now $f=\sum_{i=1}^l u_i v_i$ for $u_i\in k(X)$, and $v_i\in k[y_1,...,y_n]$, also $v_i$'s are linearly independent over $k$. Note that if we restrict the integral relation $$f^k+a_{k-1}f^{k-1}+...+a_1f+a_0, \ \ \ \  a_i\in k[X][y_1,...,y_n]$$ to a fixed point $p$ in $\mathbb A^n_k$, then it gives a integral relation of $f(p)=\sum_{i=1}^l u_iv_i(p)\in k(X)$ with coefficients $a_i(p)\in k[X]$:$$f(p)^k+a_{k-1}(p)f(p)^{k-1}+...+a_1(p)f(p)+a_0(p), \ \ \ \  a_i(p)\in k[X]$$ By normality assumption of the variety $X$, $f(p)\in k[X]$. Now, we claim that we can always pick $l$  points $p_1,...,p_l$ in $\mathbb A^n_k$ such that the vectors $(v_1(p_i),...,v_l(p_i)), 1\le i\le l$ are linearly independent (this is an easy argument since $k$ is infinite), therefore $u_i$'s are linear combination of $f(p_i)$'s, thus $u_i\in k[X], \forall i$. Thus $f=\sum_{i=1}^l u_i v_i\in k[X][y_1,y_2,...,y_n]$, as desired. $\tag*{$\blacksquare$}$",['algebraic-geometry']
1976614,"Is there a mathematical term, practical application, or area of math that covers a function raised to itself?","Some abstract examples would be: $f(x)^{f(x)}$ or $f(x)^{f(x)^{f(x)...}}$
Actual equations I've attempted to look at can be viewed here on desmos.com There seems to be a pattern of common convergence, and a relation to the functions raised to a constant power, but in my searches I have yet to find any meaning or usage.","['functions', 'terminology', 'recursion', 'hyperoperation', 'tetration']"
1976633,Solving an implicit differential equation?,"Consider solving the differential equation $y' = f(t,y)$ at time points $t_i$ with the respective solutions $y_i$. The following multi-step method is based on the integral relation: $y(t_{i+1}) = y(t_{i-1}) + \int^{t_{i+1}}_{t_{i-1}}f(t,y)dt$ Derive an implicit multi-step method by approximating the integrand $f(t,y)$ with the polynomial interpolant using function values at $t_{i-2}, t_{i-1}, t_{i}, t_{i+1}$. OK, so I know this multi-step method is called the Nystrom method. I also know that the method I come up with needs to have the following form: $y_{i+1} = y_{i-1} + h(\alpha f_{i-2} + \beta f_{i-1} + \gamma f_{i} + \phi f_{i+1})$ Here $\alpha, \beta, \gamma$, and $\phi$ are constants I have to find. $h$ is just the timestep interval size, and $f_p = f(t_p,y_p)$ for some arbitrary $p$. Beyond this, I'm completely stuck, and don't know how to even get started. Through only a few examples I found online, it seems what sometimes works is to use Taylor series to expand about the point $t_{i-1}$ and then somehow construct a system of equations for the constants to solve for them. Unfortunately the examples I've found haven't been really illustrative though. So when I tried this I got nowhere helpful pretty fast. I'd really appreciate any help I can get with this.","['taylor-expansion', 'computational-mathematics', 'numerical-methods', 'ordinary-differential-equations', 'implicit-differentiation']"
1976654,General form of a matrix that is both centrosymmetric and orthogonal,"A centrosymmetric matrix is of the form $JAJ=A$ where $J$ is the counter identity matrix, i.e. $$J=
        \begin{bmatrix}
        0 & 0 & 1 \\
        0 & 1 & 0 \\
        1 & 0 & 0 \\
        \end{bmatrix}
$$And an orthogonal matrix is $A$ such that $A^{-1}=A^T$ The only such matrix I could think of having these property is the identity matrix $$I=
        \begin{bmatrix}
        1 & 0 & 0 \\
        0 & 1 & 0 \\
        0 & 0 & 1 \\
        \end{bmatrix}
$$Is there a general form that A takes that has these properties?","['matrices', 'linear-algebra']"
1976669,A question on the proof of Thm 1.4 in Algebraic Geometry A First Course,"Thm 1.4 States that If $\Gamma\subset P^n$ is any collection of $d\leq 2n$ points in general position, then $\Gamma$ can be described by quadratic polynomials $\{f_i\}$. The proof intends to show that for any $q$ such that if for all i, $f_i(\Gamma)=f(q)=0$, then $q\in\Gamma$ and it turns out that $q$ lies in a set of cardinality $|n|$. And then it wants to show that $q$ is an element of that set. So one took advantage of redundant information of 2n points in general position and $q$ lies in a set of cardinality $|n|$ to finish the proof. What is the geometrical picture that forces $q$ to be an element of that special set?","['projective-space', 'projective-geometry', 'algebraic-geometry']"
1976693,How can I mathematically model a pringle as a function?,I need to translate the dimensions of a pringle chip into a mathematical function to calculate the surface area of hyperbolic paraboloids. How can I do this?,"['multivariable-calculus', 'quadrics']"
1976711,Difficult limit problem involving sine and tangent,"I encountered the following problem: $$\lim_{x\to 0} \left(\frac 1{\sin^2 x} + \frac 1{\tan^2x} -\frac 2{x^2} \right)$$ I have tried to separate it into two limits (one with sine and the other with tangent) and applied L'HÃ´pital's rule, but even third derivative doesn't work. I also tried to simplify the expression a bit: $$\frac 1{\sin^2 x} + \frac 1{\tan^2 x} = \frac{1+\cos^2 x}{\sin^2 x} = \frac{ 1}{1-\cos x} + \frac 1{1+\cos x} -1$$ But I cannot make it work either. I would like answers with series expansion. Thanks in advance.","['real-analysis', 'calculus', 'limits']"
1976747,Prove that $R^{2}$ cannot decrease when adding a variable,"I know that in general this is true because the smaller model is nested within the larger model, so the larger model must have SSE at least as low as the smaller one, but I'm having a hard time proving this mathematically. I know that $$R^{2} = \frac{\mathbf{{\hat{\boldsymbol\beta '} X ' y}} - n \bar{\mathbf{y}}^{2}}{\mathbf{y'y} - n\bar{\mathbf{y}}^{2}}$$ So my idea was to show that $\mathbf{{\hat{\boldsymbol\beta '} X ' y}}$ is increasing with $p$ (assuming $\mathbf{X}$ is $n$ x $p$) since the rest of the equation is constant wrt $\mathbf{X}$.  I've gotten as far as $$\sum\limits_{i=1}^{n}\sum\limits_{j=1}^{p} \hat{\boldsymbol\beta}_j \ x_{ij} \ y_{i}$$That is where I'm stuck.","['regression', 'linear-regression', 'linear-algebra']"
1976792,prove that any finite set in a metric space is compact,Prove that any finite set in a metric space is compact It is obvious that any finite set is bounded. I don't understand if any finite set is closed? And is it ok to say any finite set is compact because they are bounded and closed?,"['general-topology', 'real-analysis', 'metric-spaces', 'compactness']"
1976815,Can we show that all $2 \times 2$ matrices are sums of matrices with determinant 1?,"I came across a paper on the Sums of 2-by-2 Matrices with Determinant One . In the paper, which I have conveniently indicated here for reference, the author claims, but without proof, that a $2 \times 2$ is a sum of elements of the special linear group, $SL_2(\mathbb{F})$, whose elements, $U$, are also $2 \times 2$ matrices, such that $|U|=1$. I was thinking of proving this by either technique. Let $A= \begin{bmatrix}a & b\\c & d\end{bmatrix}$, and $a, b, c, d \in \mathbb{F}$. Technique 1. Consider the following 4 matrices with determinant 1: $M_1= \begin{bmatrix}e & 0\\0 & 1/e\end{bmatrix}$, $M_2 = \begin{bmatrix}0 & -f\\1/f & 0\end{bmatrix}$, $M_3 = \begin{bmatrix}1/h & 0\\0 & h\end{bmatrix}$, and $M_4 = \begin{bmatrix}0 & 1/g\\-g & 0\end{bmatrix}$. We show that that $\sum\limits_{i=1}^4 M_i = A$. Thus, we have $e + 1/h = a$, $1/e + h = d$, $-f + 1/g = b$, $1/f - g = c$. Technique 2. Consider $\{U_i\}_{i=1} ^\infty \in SL_2(\mathbb{F})$. Show that the sum of a countable number of $U_i$s is $A$. The problem I have here is that I don't know how to proceed from here. I don't know if either of these will be considered correct, though. I hope someone could help me out here. Thanks.","['matrices', 'linear-algebra']"
1976830,Exponential decay of Fourier coefficients correspond to analytic functions,"I am looking for a proof of the Payley-Wiener theorem saying that an analytic function on $\mathbb{T}$ (the torus) has exponentially decaying Fourier coefficients. I also found a proof of this fact in this book , but I do not get what they are doing there, i.e. how they apply Cauchy's formula. If somebody could elaborate or prove this from scratch, I would be very grateful.","['complex-analysis', 'fourier-series', 'fourier-analysis', 'analysis']"
1976842,How is the distance of two random points in a unit hypercube distributed?,"Let $p_1, p_2 \sim U([0, 1]^n)$ with $n \in \mathbb{N}$ be two points in the $n$-dimensional unit hypercube which are uniform randomly independently sampled. How is the distance $d(p_1, p_2) = \sqrt{\sum_{i=1}^n { \left (p_1^{(i)} - p_2^{(i)} \right )}^2}$ distributed? Similar questions There are questions on math.SE which cover the average distance question for $n=1$ and $n =2$ (the one for $n=2$ also explains how to ) One dimension : $\frac{1}{3}$ Two dimensions : about $0.521...$ (this makes me guess that the distribution is noting ""standard"", because then the average distance question should be easy to answer. Can one make a statement like ""the distribution of the distance of two points is 'almost' ...""?)","['probability-distributions', 'probability', 'geometry']"
1976857,Jacobian Criteria for Power series,"Prof. T.T. Moh, on his page on the Jacobian Conjecture, mentions that ""the classical Jacobian criteria for power series, implies that $k[[f(x,y),g(x,y) ]]=k[[x,y]]$. Thus we have
$$x=F(f,g), y=G(f,g)$$
as power series. "" What is meant by the Jacobian Criteria for Power Series? Is there a good exposition of this?","['abstract-algebra', 'power-series', 'reference-request', 'algebraic-geometry']"
1976877,Is there a Bezout's theorem for holomorphic functions of two variables?,"Is there an analogue of the Bezout's Theorem which pertains to holomorphic functions of two variables defined on a fixed domain or germs of analytic functions of more than one variable at $0$? I have never seen a proof nor have I seen a counter-example. Edit: More concretely, if we consider the ring of germs of analytic functions in several variables at $0$, is it true that for two such germs having no common factors, the set of their common zeros is discrete?","['reference-request', 'algebraic-geometry']"
1976922,Two ways of defining tangent space,"Question states: ""Let $f:\Bbb R^n \to \Bbb R$ be a differentiable map and let $f:\Bbb R^{n+1} \to \Bbb R$ be given by $(x,z) \mapsto f(x) -z$ where $x \in \Bbb R^n$ and $z \in \Bbb R$. Let $M \subset \Bbb R^{n+1}$ be the graph of $f$ and $M' = F^{-1}(\{0\})$, i.e. the preimage of zero. Part 1: Let $a \in \Bbb R^n$. Describe the tangent space on $M=M'$ at $(a,f(a)) \in \Bbb R^{n+1}$ using $f$ and using $F$. Part 2: Show that these two descriptions agree."" I have proven that $M=M'$. Part 1 requires me to use the gradient of $f$ at some point and the fact that the normal vector is tangent to $M'$. For part 1, I tried expressing the tangent space $M$ as
$$
(a,f(a)) + \sum_{i=1}^n (e_i, \partial_if(a))r_i
$$
where $e_i \in \Bbb R^n$ is $i$th unit vector and $r_i \in \Bbb R$. Also, I expressed the tangent space $M'$ as 
$$
\{x \in \Bbb R^{n+1} : \nabla F(a) \cdot x = 0\}.
$$
But I couldn't really show they they are equal (for part 2). Am I doing something wrong here? I do feel like my first expression is overly complicated. Please don't include any linear algebra and express everything in terms of (advanced) calculus. I only know very few concepts in linear algebra.","['multivariable-calculus', 'calculus']"
1976942,How often is $\sin(a^n) $ positive or negative?,"Let $a > 1$. Define $$
f(x,a) = \#\{n:\sin(a^n) \ge 0, n \in N, 1 \le n \le x\},
$$ $$
g(x,a) = \#\{n:\sin(a^n) < 0, n \in N, 1 \le n \le x\}.
$$ Questions What is known about the growth rate of $f(x,a)$ and $g(x,a)$? Can the quantity $\Delta(x,a) = f(x,a) - g(x,a)$ it be bounded in terms of $x$ and $a$? My thoughts : Since $\sin(\theta)$ is a circular function, I would look at the distribution of the remainder when $a^n$ is divided by $2\pi$. If the remainder is uniformly distributed in $(0,2\pi)$ then $\sin(a^n)$ is equally likely to be positive or negative hence I would expect $f(x,a) \sim g(x,a) \sim x/2$.","['real-analysis', 'trigonometry', 'analysis']"
1976958,Variance of probability distribution,"I have continuous distribution, $X$,  with probability density function
$$f_X(x) = \frac{\alpha{\beta}^\alpha}{(x+\beta)^{\alpha+1}}$$
where $\alpha > 1, \beta > 0, x \ge 0$. I have also found the expected value to be
$$E(X) = \alpha\beta\left(\frac{1}{\alpha-1}-\frac{1}{\alpha}\right)$$ I am required to obtain the variance of the distribution and I am very stuck on doing this? I know that
$$Var(X) = E(X^2)-E^2(X)$$
but got stuck funding $E(X^2)$.","['statistics', 'probability', 'probability-distributions']"
1976973,How to prove the expanding Ricci soliton is Einstein metric?,"As picture below ,I want to prove the expanding Ricci soliton is Einstein metric. I can get $R+\Delta f-n\lambda=0$ . Besides ,I want to prove $R+|\nabla f|^2= C$ for some constant $C$ . But fail. I just get $R+|\nabla f|^2-2\lambda f=C'$ . So, how to do it ? Just give a little hint is enough . Thanks. Picture below is from the 176 page of paper . And, the definition of expanding Ricci soliton can be found in here .","['riemannian-geometry', 'partial-differential-equations', 'ricci-flow', 'soliton-theory', 'differential-geometry']"
1977013,Particular solution of $y''+4y=x\cos x$,"Find both the general solution $y_h$ and a particular solution $y_p$ for
  $$y''+4y=x\cos x$$ So far I've got $y_h$ from factoring the characteristic polynomial:
$$y_h=C_1\sin2x+C_2\cos2x$$
But the $y_p$ part troubles me, any help?","['ordinary-differential-equations', 'calculus']"
1977020,How to give a consistent mathematical explanation to a paradoxical divergent/convergent phenomena. [duplicate],"This question already has answers here : Why does the tangent of numbers very close to $\frac{\pi}{2}$ resemble the number of degrees in a radian? (4 answers) Closed 7 years ago . How can be explained, in a ""clean"" mathematical way, the ""stabilization"" of the different digits in the following divergent sequence? $$\tan(89Â°)=57.28996163...$$ $$\tan(89.9Â°)=572.9572134...$$ $$\tan(89.99Â°)=5729.577893...$$ $$\tan(89.999Â°)=57295.77951...$$ $$\tan(89.9999Â°)=572957.7951...$$ etc...","['trigonometry', 'sequences-and-series']"
1977064,Hypothesis in the Radon-Nikodym theorem.,"I have a question concerning a proof of Radon-Nikodym theorem here . Why is the hypothesis ""$\nu$ is finite"" necessary? The author uses it to have the measure $\sigma=\mu+\nu$ finite and then, from $|Tu|\leq \Vert u\Vert_{L^2(X,\mathcal{F},\sigma)}\sqrt{\sigma(X)}$, conclude that $T$ is bounded. By I think that it is also true that $|Tu|\leq\Vert u\Vert_{L^2(X,\mathcal{F},\sigma)} \sqrt{\mu(X)}$ (applying first HÃ¶lder's inequality and then the fact that $\mu\leq\sigma$), so $T$ is bounded in any case . So for me, $\mu$ has to be finite, but $\nu$ not. However, this would contradict the example posted here . Any ideas?","['self-learning', 'probability-theory', 'functional-analysis', 'lebesgue-integral', 'measure-theory']"
1977081,When to stop rolling a die in a game where 6 loses everything,"You play a game using a standard six-sided die. You start with 0 points. Before every roll, you decide whether you want to continue the game or end it and keep your points. After each roll, if you rolled 6, then you lose everything and the game ends. Otherwise, add the score from the die to your total points and continue/stop the game. When should one stop playing this game? Obviously, one wants to maximize total score. As I was asked to show my preliminary results on this one, here they are: If we simplify the game to getting 0 on 6 and 3 otherwise, we get the following: $$\begin{align}
EV &= \frac{5}{6}3+\frac{25}{36}6+\frac{125}{216}9+\ldots\\[5pt]
&= \sum_{n=1}^{\infty}\left(\frac{5}{6}\right)^n3n
\end{align}$$ which is divergent, so it would make sense to play forever, which makes this similar to the St. Petersburg paradox. Yet I can sense that I'm wrong somewhere!","['probability', 'gambling', 'dice']"
