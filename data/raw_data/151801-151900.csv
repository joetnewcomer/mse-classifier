question_id,title,body,tags
2538082,AM>HM Problem $\frac{1}{n+1}+...+\frac{1}{3n+1}>1$,"I am having difficulty solving one of the problems from ""Problems in Mathematical Analysis I"" -  W. J. Kaczor;M. T. Nowak . It's a problem 1.2.5 b), and it goes like this: 1.2.5. For $n \in \mathbb{N}$, verify the following claims: $$\tag{b} \qquad \dfrac{1}{n + 1} + \dfrac{1}{n + 2} + \dfrac{1}{n + 3} + \ldots + \dfrac{1}{3n + 1} \, > \, 1$$ In solutions it says: ""Use the arithmetic-harmonic mean inequality!"" I tried to apply it on whole inequality but got: \begin{align}
& \dfrac{\frac{1}{n+1}+\ldots+\frac{1}{3n+1}}{2n}\, >\, \dfrac{2n}{n+1+\ldots+3n+1} \\ 
\implies & \frac{1}{n+1}+\ldots+\frac{1}{3n+1}>\frac{8n^2}{2n(n+1+3n+1)} \\
\implies & \frac{1}{n+1}+\ldots+\frac{1}{3n+1}>\frac{2n}{2n+1}
\end{align}","['inequality', 'cauchy-schwarz-inequality', 'analysis']"
2538085,Confusion over one-sided curly bracket notation for which limits must be computed,"For the function $f$, given by$$f(x) = \begin{cases} a & (x=0) \\ \frac {\sinh(x)}{\sinh(2x)} & (x\neq0)\end{cases}$$ Provided the limits exist, I need to determine,  $$\lim_{x \to 0}f(x)$$ I know that $f(x)$ is undefined at $x=0$. Furthermore, I've determined that $\lim_{x \to 0} \frac {\sinh(x)}{\sinh(2x)} = \frac{1}{2}$. Now, as far as my confusion is concerned. If the question only asked for $\lim_{x \to 0} \frac {\sinh(x)}{\sinh(2x)}$, I would simply show how I computed $\frac{1}{2}$. However, with the additional case where $f(x) = a$, alongside the one-sided curly bracket notation, I'm not sure how to approach this problem. I cannot find any literature to enlighten me on how to use this notation in the context of limits, so I apologise if this is a duplicate. Perhaps this is because I don't know what name to give this one-sided curly bracket notation. I do however have one idea on how to approach this: Which is to show that $$\lim_{x \to 0} \frac {\sinh(x)}{\sinh(2x)} = \frac{1}{2} =a$$ Am I correct in my interpretation on how to handle this notation in the context of computing limits? Or am I missing something? Either way, how can this notation be explained in precise terms in this context? At the moment, it is fairly vague in my mind.","['hyperbolic-functions', 'notation', 'functions', 'limits']"
2538096,Galois group of $x^4-2x^2+2$. Apparent contradiction!!,"I'm trying to compute de Galois group of $p(x) = x^4-2x^2+2$, and I seem to have arrived to a contradiction, which of course means that there is some mistake that I'm not able to find. The first thing I did was to compute the roots: $\alpha_1 = \sqrt[4]2 \space e^{\pi i/8}$ $\alpha_2 = -\sqrt[4]2 \space e^{\pi i/8}$ $\alpha_3 = \sqrt[4]2 \space e^{-\pi i/8}$ $\alpha_4 = -\sqrt[4]2 \space e^{-\pi i/8}$ From the expressions, one can see that: $\alpha_3 = \alpha_1^{15} \space \frac{\sqrt 2}{16}$ So that $\sqrt 2$ is in the splitting field, and with $\sqrt 2$ and $\alpha_1$ it's possible to generate the other roots. Therefore, the splitting field must be: $\mathbb{Q}(\sqrt 2,\alpha_1)$ We need to see if the degree is equal to 4 or 8. If the degree of $\alpha_1$ over $\mathbb{Q}(\sqrt 2)$ is 4, the total degree will be 8. And this is the case, because $p(x)$ splits in $\mathbb{Q}(\sqrt 2)[x]$ if and only if there are $\alpha_i$ and $\alpha_j$ so that $(x-\alpha_i)(x-\alpha_j)$ have coefficients in $\mathbb{Q}(\sqrt 2)$, which applying Cardano's formulas requires $\alpha_i + \alpha_j \in \mathbb{Q}(\sqrt 2)$ and $\alpha_i  \alpha_j \in \mathbb{Q}(\sqrt 2)$. It's easy to rule out all combinations of $\alpha_i$ and $\alpha_j$ (perhaps easier if one considers the expression $\alpha_i = \pm\sqrt[4]{2} (\frac{1}{2}\sqrt{2+\sqrt2} \pm \frac{i}{2}\sqrt{2-\sqrt2})$), and to prove that it's not possible, so that the degree of the extension is 8. In this point, the Galois group $G$ can be seen as a subgroup of $S_4$ (because the group acts permuting the four roots) of order 8, so that, according to the structure of subgroups of $S_4$ (see https://groupprops.subwiki.org/wiki/Symmetric_group:S4 ), the Galois group is isomorphic to $D_8$. However, I wanted a more direct proof, using the expression of the splitting field, which allows us to consider the group as acting on $\alpha_1$ (sending it to either $\alpha_1$, $\alpha_2$, $\alpha_3$ or $\alpha_4$) and $\sqrt 2$ (sending it to $\sqrt 2$ or $-\sqrt 2$). Using this, the Galois automorphisms have to be: \begin{array}{|c|c|c|}
\hline
& \sigma(\alpha_1) & \sigma(\sqrt 2) \\ \hline
\sigma_1 & \alpha_1 & \sqrt 2\\ \hline
\sigma_2 &  \alpha_2 &\sqrt 2\\ \hline
\sigma_3 & \alpha_3 &\sqrt 2\\ \hline
\sigma_4 & \alpha_4 &\sqrt 2\\ \hline
\sigma_5 & \alpha_1 &-\sqrt 2\\ \hline
\sigma_6 & \alpha_2 &-\sqrt 2\\ \hline
\sigma_7 & \alpha_3 &-\sqrt 2\\ \hline
\sigma_8 & \alpha_4 &-\sqrt 2\\ \hline
\end{array} Moreover, we can consider these two subgroups: $N = Gal(\mathbb{Q}(\sqrt 2,\alpha_1)/\mathbb{Q}(\sqrt 2)) = \{\sigma_1,\sigma_2,\sigma_3,\sigma_4\}$ $H = Gal(\mathbb{Q}(\sqrt 2,\alpha_1)/\mathbb{Q}(\alpha_1)) = \{\sigma_1,\sigma_5\}$ $N$ is normal, because the field extension $\mathbb{Q}(\sqrt 2)/\mathbb{Q}$ is a normal extension. And $N\cap H = \{\sigma_1\}$, so that $N H= G$ and $G = N \rtimes H$ It seems that we are arriving to the same conclusion, but we need to prove that $N \simeq \mathbb{Z}_4$ in order to end. And this is the point that fails, because all elements of $N$ are of order $1$ or $2$: $\sigma_2^2(\alpha_1) = \sigma_2(\alpha_2) = \sigma_2(-\alpha_1) = -\alpha_2 = \alpha_1$ $\sigma_3^2(\alpha_1) = \sigma_3(\alpha_3) = \sigma_3(\alpha_1^{15} \space \frac{\sqrt 2}{16}) = \alpha_3^{15} \space \frac{\sqrt 2}{16} = \alpha_1$ $\sigma_4^2(\alpha_1) = \sigma_4(\alpha_4) = \sigma_4(-\alpha_1^{15} \space \frac{\sqrt 2}{16}) = -\alpha_4^{15} \space \frac{\sqrt 2}{16} = \alpha_1$ So that $N \simeq \mathbb{Z}_2 \times \mathbb{Z}_2$, and $G \simeq (\mathbb{Z}_2 \times \mathbb{Z}_2)\rtimes \mathbb{Z}_2$ Please, can you tell me where is the mistake?? Thanks a lot in advance!","['abstract-algebra', 'galois-theory', 'group-theory']"
2538105,Why shouldn't this prove the prime number theorem?,"Someone deduced without using complex analysis that $$ \int \frac{\pi(t)}{t^2} \mathrm{d}t \sim \log\log t $$
where $\pi$ is the prime counting function. By differentiating the above, he then arrives at $$\frac{\pi(t)}{t^2} \sim \frac{1}{t\log t} $$ which is exactly the Prime Number Theorem. However, he feels that something should be wrong with this approach, but not sure exactly what ?","['number-theory', 'analytic-number-theory', 'asymptotics']"
2538155,"If a = b (mod m) and gcd(a,b) = 1, then gcd(a,m) = 1","I can't figure out how to prove this. I know m | (a-b) and I know that there is some integers x and y such that ax + by = 1, however I do not know how to connect these two things to prove the result that the gcd(a,m) = 1. Please help!","['gcd-and-lcm', 'discrete-mathematics', 'modular-arithmetic', 'elementary-number-theory']"
2538164,Maximum likelihood estimator of $\operatorname{Poisson}(\lambda)$ with restricted $\lambda$,"Consider $X_1, X_2, \ldots,X_n$ iid $\operatorname{Poisson}(\lambda)$ random variables, where $\lambda \in [a,b]$, $0<a<b$. How do you find the maximum likelihood estimator of the restricted $\lambda$? I know that the maximum likelihood estimator of the unrestricted $\lambda$, $(\lambda \in [0, \infty])$, is $$\widehat{\lambda}_\text{MLE}=\bar{X}_n = \dfrac{X_1+X_2+\cdots+X_n}{n}.$$ I was thinking of finding the behavior as the maximum likelihood estimator at as it moves between $0$ and $\infty$ and substituting $a$ and $b$ respectively, but I am unsure if that is correct. Thank you in advanced.","['maximum-likelihood', 'statistics', 'estimation', 'poisson-distribution']"
2538184,Proof of golden rectangle inside an Icosahedron,"This is an regular Icosahedron with three golden rectangles inscribed in it. I realize that they are clearly rectangles, I was wondering if someone could prove that they are a golden rectangles, assuming all edges are length $s$. (I know that it's true from a result and from google but I'm not sure how to show it.) I am completely fine with a proof from its dual, the dodecahedron.","['golden-ratio', 'geometry']"
2538297,Can I calculate limits in 3 dimensions with a substitution of the type $z=xy$?,"This is my first question here so I hope I'm doing it right :) sorry otherwise! As in the title, I was wondering if and when it is OK to calculate a limit i three dimensions through a substitution that ""brings it down to two dimensions"". Let me explain what I mean in a clearer way through an example. I was calculating this limit: $$\lim_{(x,y) \to (0,0)} \frac{\ln (1+\sin^2(xy))}{x^2+y^2} =\lim_{(x,y) \to (0,0)} \frac{\ln (1+\sin(xy)\cdot \sin(xy))}{x^2+y^2}$$
$$=\lim_{(x,y) \to (0,0)} \frac{\ln (1+xy\cdot xy)}{x^2+y^2} =\lim_{(x,y) \to (0,0)} \frac{\ln (1+x^2y^2)}{x^2+y^2}=\lim_{(x,y) \to (0,0)} \frac{x^2y^2}{x^2+y^2}$$
$$=\lim_{(x,y) \to (0,0)}\frac{1}{\frac{1}{y^2}+\frac{1}{x^2}}=""\frac{1}{\infty}""=0.$$
Where I have used:
$$ \lim_{(x,y) \to (0,0)} \frac{\sin(xy)}{xy}=[z=xy]=\lim_{z\to 0}\frac{\sin z}{z}=1$$
and 
$$ \lim_{(x,y) \to (0,0)} \frac{\ln(1+xy)}{xy}=[z=xy]=\lim_{z\to 0}\frac{\ln(1+z)}{z}=1.$$
Is the way I calculated the limits for $(x,y)\to (0,0)$ by substituting with $z=xy$ legit? 
Also, if it is... am I allowed to substitute an expression with its limit inside a limit, as in while calculating the limit, or can I only take the limits in one last step (I'm a bit confused by this exercise in general, I have solved it with Taylor series but I'm curious to know whether this works too)? Thank you so much in advance!","['multivariable-calculus', 'substitution', 'calculus', 'limits']"
2538298,"Tangent plane of the surface: $z-g(x,y)=0$ in $(x_0, y_0, z_0)$","How can I determine the equation of tangent plane of the surface: $$z-g(x,y)=0$$ in the point: $$(x_0, y_0, z_0)$$ in terms of implicit derivatives?","['derivatives', 'implicit-function-theorem', 'integration']"
2538299,Strong law of large numbers implies weak law,"I'm reading Achim Klenke's textbook on probability theory, and I've hit a road block in his proof that the strong law of large numbers (SLLN) implies the weak law of large numbers (WLLN). Let $(X_n)_{n \in \mathbb N}$ be a sequence of real integrable random variables, and let $\widetilde S_n = \sum_{i=1}^n (X_i - \mathbb E[X_i])$, where $\mathbb E[X]$ is the expectation of the random variable $X$. The weak and strong laws of large numbers are: WLLN: $\displaystyle \lim_{n \to \infty} \mathbb P\left[ \left| \frac 1 n \widetilde S_n\right| > \epsilon\right]=0$. SLLN: $\displaystyle \mathbb P\left[ \limsup_{n \to \infty} \left| \frac 1 n \widetilde S_n\right|=0\right] = 1$. For $\epsilon > 0$, Klenke defines the sets $A_n^\epsilon = \left\{ \left| \frac 1 n \widetilde S_n \right| > \epsilon\right\}$ and $A = \left\{ \limsup_{n \to \infty} \left| \frac 1 n \widetilde S_n \right| > 0 \right\}$, and states that $$A = \mathop\bigcup_{m \in \mathbb N} \limsup_{n \to \infty} A_n^{1/m},$$ and thus $\mathbb P\left[ \limsup_{n \to \infty} A_n^\epsilon\right] = 0$ for $\epsilon>0$. Then, by Fatou's lemma, 
\begin{align}
\limsup_{n \to \infty} \mathbb P\left[A_n^\epsilon\right] &= 1-\liminf_{n \to \infty} \mathbb E\left[ \mathbb 1_{\left(A_n^\epsilon\right)^c}\right] \leq 1 - \mathbb E\left[\liminf_{n \to \infty} \mathbb 1_{\left(A_n^\epsilon\right)^c}\right] = \mathbb E\left[ \limsup_{n \to \infty} \mathbb 1_{A_n^\epsilon}\right] = 0.
\end{align} My question: I understand this entire argument, except for the first equality in the above equation. Equivalently, what I'm trying to figure out is, why is $\limsup \mathbb P\left[A_n^\epsilon\right] = 1-\liminf \mathbb P\left[ \left(A_n^\epsilon\right)^c\right]$? Is this some general measure theory result that I'm not seeing?","['probability-theory', 'probability', 'measure-theory']"
2538331,Odd function composition,Let $f: \Bbb R \to \Bbb R$ be an odd function. Is the compositon of $ \underbrace{f \circ f \circ f \circ \cdots \circ f}_{\text{$n$ times}}$ odd or even? Do I need to prove it with separate cases for $n$ even and $n$ odd?,"['function-and-relation-composition', 'functions']"
2538354,Any bounded sequence in $L^4$ has a convergent subsequence in $L^2$?(True or False),"Is this true that ""Any bounded sequence in $L^4[0,1]$ has a convergent sbsequence in $L^2[0,1]$?"" Of course I tried so much for this but I could not get any solution till now. Any  hints. is appreciated. Thank you",['functional-analysis']
2538369,The matrix identity $\nabla_A \text{tr}AB = B^T$ when A is symmetric,"Suppose $A,B \in \mathbb{R}^{n \times n}$, $f: \mathbb{R}^{n \times n} \to \mathbb{R}$. Define $\nabla_A f(A)) \in \mathbb{R}^{n \times n}$,  where $(\nabla_A f(A))_{ij} = \frac{\partial{f(A)}}{\partial{A_{ij}}} $. Consider the equation $\nabla_A \text{tr}AB = B^T$, according to this note . This can be proved as 
$$ \begin{align}
f(A) = \text{tr}AB 
&=\sum_{i=1}^nA_{1i}B_{i1} +\sum_{i=1}^nA_{2i}B_{i2} + \cdots + \sum_{i=1}^nA_{ni}B_{in} \\
&= \sum_{j=1}^{n}\sum_{i=1}^{n} A_{ji}B_{ij}\\
\end{align} $$ If we assume A is symmetric matrix, I'm confused whether the following is right because it contradicts with $\nabla_A \text{tr}AB = B^T$. $\nabla_A \text{tr}AB = B + B^T$ because $A_{ij} = A_{ji}$ and $\frac{\partial{f(A)}}{\partial{A_{ij}}} = B_{ij} + B_{ji}$","['multivariable-calculus', 'matrix-calculus', 'linear-algebra', 'vector-analysis']"
2538376,Calculating variance of an Ornstein Uhlenbeck process,"I have the following process $$dX_t = (b-aX_t)dt + dW_t$$
$$X_0 = x_0$$
with $a,b,x_0$ constants, and I wish to calculate the variance. (I have already solved for the process and for the expected value). To find $E(X^2)$, my idea was to use to set $Z_t = X_t^2$, apply Itos lemma and take expectations on each side. That is
$$dZ_t = 2X_tdX + 2(dX)^2$$
$$= 2X_t(b-aX_t)dt +2X_tdW_t+2dt$$
Integrating from $0$ to $t$ and taking expectations
$$E(Z_t) = x_0^2 +2b\int_0^tE(X_s)ds-2a\int_0^tZ_sds + 2t$$
where $E(X_t) = e^{-at}(x_0 - \frac{b}{a})+\frac{b}{a}$. I have no idea how to solve the above equation. Is there another way to calculate this variance that I am missing?","['stochastic-processes', 'brownian-motion', 'probability-theory', 'stochastic-calculus']"
2538390,Circle Inversion,"I don't understand the concept of circle inversion. $OP \cdot OP' = k^2$ For example, in a circle $x^2+y^2=k^2$.
If I set a general point $P(x,y)$, why is its image $P'(\frac{xk^2}{x^2+y^2}, \frac{yk^2}{x^2+y^2})$? Also, why does a line become a circle through O? Sorry for my English, I'm not a native English speaker.","['circles', 'inversive-geometry', 'geometry']"
2538424,partial sums of the sequences $(X_n)$ and $(Y_n)$,"Let $(X_n : n = 1,2, \ldots )$ be a sequence of identically distributed random variables having finite mean. For $n=1,2,\ldots$ , let $Y_n = X_nI_{\{w:|X_n(w)|\leq n\}}$ , let $(S_n : n = 1,2, \ldots)$ and $(T_n : n = 1,2, \ldots)$ denote the sequences of partial sums of the sequences $(X_n)$ and $(Y_n)$ , respectively. Then $$\lim_{n \rightarrow \infty}(\frac{T_n}{n}-\frac{S_n}{n})=0 \ $$ The hint for this problem said proving first this result: Let $(X_n : n = 1,2, ... )$ be a sequence of identically distributed
random variables having finite mean. Then $$ P(\limsup_{n \rightarrow \infty }\{w: |X_n(w)|> n \}) = 0$$ My attempt for this is: Let $F$ denote the common distribution function of the random variables $|Xn|$ . Using the expression for the mean of a nonnegative random variable, we obtain $$\infty > \int_0^{\infty} [1-F(x)]dx \geq \sum_{n=1}^{\infty}[1-F(x)] = \sum_{n=1}^{\infty} P(\{w: |X_n(w)|> n \})$$ and then appealing to the Borel Lemma we have the probability is zero. Is it correct? but How can I apply this result to solve this problem? Could someone help me pls. Thanks for your time and help.","['law-of-large-numbers', 'probability-theory', 'probability']"
2538439,"Using only logical symbols and $\in$, and $=$ translate into first-order logic: ""$A$ is the power set of $B$""","Using only logical symbols and $\in$, and $=$ translate into first-order logic: ""$A$ is the power set of $B$"" I've attempted to solve this, but I am not sure whether my solution contains no errors. I'd be glad if you gave me some kind of feedback. $$(\forall x)(x\in A \Rightarrow ((\forall y)(y \in x \Rightarrow y \in B))$$ My reasoning: If $A$ is the power set of $B$ then every element $x$ of $A$ will be a subset of $B$, and so any object in $x$ will also be in $B$.","['propositional-calculus', 'logic', 'elementary-set-theory', 'logic-translation']"
2538458,"Do all integrable functions on $[0,1]$ form a vector space?","Does the set of all functions integrable over $[0,1]$ form a vector space? 
(Here we are assuming ""standard"" definitions of addition and multiplication). Here is what I have tried: Define $\mathcal{F}=\lbrace f(x) | \int\limits_{0}^1f(x)dx\in\mathbb{R}\rbrace$. 
For $f,g,h\in\mathcal{F}$ the following hold: I proved several of the properties (commutativity of addition, associativity of addition, additive identity with $z(x)=0$).  I am stuck as to how to prove that there is an additive inverse and multiplicative inverse for all $f\in\mathcal{F}$.","['functions', 'vector-spaces']"
2538490,Submartingale inequality,"Let $X_n$ be a $F_n$ sub martingale. Suppose it exists an integrable random variable $X'$ such that $X_n \le \mathbb E(X' \mid F_n) \,\text{}a.s. \quad \forall n\in \mathbb N_0$. First I want to show that $\sup_{n \in \mathbb N_0} \mathbb E(X_n^+) < \infty$. $$\sup_n \mathbb E( X_n^+)\overset{\text{assumption}}{\underset{\text{}}{\le}}\sup_n \mathbb E\big(\vert\mathbb E(X' \mid F_n)\vert \big) \le \sup_n \mathbb E\big(\mathbb E(\vert X'\vert \mid F_n) \big)\overset{\text{tower}}{\underset{\text{}}{=}}\sup_n \mathbb E( \vert X' \vert)=\mathbb E(\vert X' \vert)$$ Since $ X'$  is integrable we have $\mathbb E(\vert X' \vert)< \infty$. Therefore $\sup_{n \in \mathbb N_0}E(X_n^+) < \infty $. Furhermore I want to show that for the a.s. limit $ X_\infty \in L^1$ holds. $$\mathbb E(\vert X_\infty \vert )=\mathbb E( \vert \lim_{n \to \infty}X_n \vert )=\mathbb E( \lim_{n \to \infty} \vert X_n \vert )\le \mathbb E(\lim_{n \to \infty}\vert \mathbb E(X' \mid F_n)\vert)=\mathbb E(\liminf_{n \to \infty}\vert\mathbb E(X' \mid F_n)\vert)\overset{\text{Fatou}}{\underset{\text{}}{\le}}\liminf_{n \to \infty}\mathbb E(\vert \mathbb E(X'\mid F_n)\vert) \le \liminf_{n\to\infty}\mathbb E(\mathbb E(\vert X' \vert \mid F_n))=\liminf_{n\to\infty}E(\vert X' \vert)=\mathbb E(\vert X' \vert)$$Again $\mathbb E(\vert X' \vert) < \infty$ by assumption. EDIT: This only holds if $ X_n$ non negative If $X_n$ is negative we get $$E(\vert X_\infty \vert )=E(\lim_{n\to\infty}X_n^-)=E(\liminf_{n\to\infty}X_n^-)\le \liminf_{n\to\infty} E(X_n^-)\le \liminf_{n\to\infty}E(X_n^+)- \liminf_{n\to\infty}E(X_0)=\liminf_{n\to\infty}E(\vert X_0 \vert )< \infty$$ second last line because of $\liminf E(X_n^+)=0$ Now I have trouble to show $X_n \le \mathbb E(X_\infty \mid F_n) \forall n\in \mathbb N_0$ An idea is to split $X_n$ in negative and positive parts and show that they are uniformly integrable. I am not able to continue here. Help is much appreciated and a comment about the attempt above is also welcome. Edit2 Still one has to consider cases where $ X_n$  is negative an positive","['probability-theory', 'martingales', 'uniform-integrability']"
2538499,Tangent Space and Vector field in Euclidean Space in view of Smooth Manifold,"I have just learned tangent space in smooth Manifold.It is defined in this manner....Let $M$ be a smooth Manifold,let $\Gamma$$(p)$ be the collection of all smooth curve on $M$ to the point $p$$\in$$M$ such that $d$($\gamma$$(t)$)$/dt$ $=$$d$($\tau$(t))/$dt$, at $t=0$.$\gamma$,$\tau$$\in$$\Gamma$$(p)$.Under these  condition we define a relation $\sim$.It is easy to verify that $\sim$ is an equivalence relation and each of the  equivalence classes are called tangent vector at $p$.But If I focus in particularly Euclidean Space how can I relate it with the Tangent space in Euclidean space,By Tangent Space on Euclidean Space I know the vector space that is generated by the partial derivaties w.r.t $x_1$,$x_2$,..,$x_n$ where $x_1,x_2,...,x_n$ are coordinates in $R^n$.How can I compare these two tangent space in similar way?Does the tangent space at $p$$\in$ $M$ represents a plane of  dimension $n$ in $n$ dimensional Manifold $M$? I have similar problem in understanding vector field.By Vector Field we mean a section of vector Bundle on a smooth Manifold.But in Euclidean Space by Vector field we mean a mapping $X(p)->(p,x(p))$$p$$\in$$R^n$,,I think there need to be a similarity in the definition of Vector field Euclidean Space and manifold as smooth Manifolds are the general form of Euclidean Spaces,But I can't view that similarity! How does these two definition in Manifold are generalized from their definition in Euclidean space?","['multivariable-calculus', 'differential-geometry']"
2538518,"Extrema of $f(x,y)=\sqrt{x^2+y^2} \cdot e^{-(x^{2}+y^{2})}$","i have problems solving this task here: We have a function $f:\mathbb{R}^2\rightarrow\mathbb{R}$,
$$ f(x,y)=\sqrt{x^2+y^2} \cdot e^{-(x^{2}+y^{2})} $$ Calculate the local extrema of $f$.
Decide for all whether it is a strict local minimum or strict local maximum.
Find the global maximum and minimum of $f$. My main problem is to calculate the local extrema of $f$. Normally i would calculate the partial derivatives and set them 0.
Like: $\frac{\partial f}{\partial x} = \frac{xe^{-x^{2}-y^{2}}}{\sqrt{x^{2}+y^{2}}}-2xe^{-x^{2}-y^{2}}\sqrt{x^{2}+y^{2}}$ $\frac{\partial f}{\partial x} = \frac{e^{-x^{2}-y^{2}}(-2x^{2}y-2y^{3}+y)}{\sqrt{x^{2}+y^{2}}}$ If you just help me finding the points of the local extrema i would be very happy. Sitting now since a few days on this task.","['functional-analysis', 'partial-derivative', 'calculus']"
2538521,First-order linear differential inequality [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Let $x$ be a function of  $C^1(I,R)$ where $I\subset \mathbb{R}$ , such that  $$x'(t)\leq a(t) x(t)+b(t),$$ where $a$ and $b$ are continuous functions on  $I$ in $R$ then 
  $$ x(t)\leq x(t_0) \exp\left(\int_{t_0}^{t}a(s)ds\right)+\int_{t_0}^{t}\exp\left(\int_{s}^t a(\sigma)d\sigma\right)b(s)ds$$ How to prove this proposition please ? Thank you","['real-analysis', 'ordinary-differential-equations']"
2538522,"If $T$ is an upper triangular matrix, and $TT^{H}=T^{H}T$ , show that $T$ has to be a diagonal matrix","Problem If $T \in \mathbb{C}^{n \times n}$ is an upper triangular matrix, and $TT^{H}=T^{H}T$, where $T^H$ means the Hermitian transpose of $T$, show that $T$ has to be a diagonal matrix. What I Have Done This seems to be obvious, but writing $T = [t_1, t_2, \cdots, t_n]$ does not help. I also tried to write $TT^{H}$ in an element-wise form, but I got stuck halfway. Could anyone help me, thank you in advance.",['linear-algebra']
2538553,What is the difference between statistical mean and calculus mean?,"For example in statistics we learn that mean = E(x) of a function which is defined as $$\mu = \int_a^b xf(x) \,dx$$ however in calculus we learn that $$\mu = \frac {1}{b-a}\int_a^b f(x) \,dx $$ What is the difference between the means in statistics and calculus and why don't they give the same answer? thank you","['average', 'statistics', 'calculus']"
2538567,Prove Riemann Integral is Zero,"$\mathbf{Theorem}: \ $ If $S\subset\mathbb{R}^N$ is a non-empty measurable set, with Jordan measure (content) zero, and $f:S\mapsto \mathbb{R}^M$ is a bounded function, then the Riemann integral, $\int_Sf=0$ $\mathbf{Lemma \ 1}:$ A set $S\subset \mathbb{R}^N$ has Jordan measure zero, if for each $\epsilon>0$ , there are compact intervals $I_1,...,I_n\subset \mathbb{R}^N$ with, $$S\subset \bigcup_{i=1}^nI_i \ \ and \ \ \sum_{i=1}^n\mu(I_j)<\epsilon_0$$ Where $\mu(I)$ denotes the Jordan measure of the set $I$ . $\mathbf{Proof:}$ Suppose $S\subset \mathbb{R}^N$ is a non-empty measurable set, with Jordan measure zero, and $f:S\mapsto \mathbb{R}^M$ is a bounded function. By $\mathbf{Lemma \ 1}$ , a set $S\subset \mathbb{R}^N$ has Jordan measure zero, if for each $\epsilon>0$ , there exists compact intervals $\{I_i\}_{I=1}^N$ , such that $S\subset \bigcup_{I=1}^NI_i$ and $\sum_{I=1}^N\mu(I_i)<\epsilon_0$ . Then for $\epsilon_0=\frac {\epsilon}{sup(f)}$ , clearly, $$\bigg|\int_Sf\bigg|\leq\bigg|\int_{\bigcup_{I=1}^NI_i}f \bigg|\leq|sup(f)|\sum_{i=1}^N\mu(I_i)<\epsilon$$ That is, $\int_Sf=0$ . Is this a sufficient proof for the above theorem, or am I doing something wrong? Can anyone provide any feedback, or a proper proof if this isn't right? Thanks in advance!","['multivariable-calculus', 'measure-theory', 'analysis', 'riemann-integration']"
2538597,Is the open mapping theorem true for all complete metrizable topological vector spaces?,"Recall that the open mapping theorem is true for Banach spaces. Furthermore, it is also true for Frechet spaces, which are complete metric spaces(with extra properties). It makes me wonder whether we can say that open mapping theorem applies to all complete metrizable topological vector spaces, since the key ingredient Baire category theorem certainly applies to all complete metric spaces and the norm in the proof of Banach spaces can be adapted to metric hopefully.",['functional-analysis']
2538598,How would I solve $x^2-4x=y^2-4y$ without knowing the answer beforehand?,"The equation is $x^2-4x=y^2-4y$ in the case where $x\ne y$. The answer is $x+y=4$. I can start from $x+y=4$ and create the equation very easily, and I can substitute $x+4=y$ into the equation and show both sides are equal easily. I just don't get how I would find the answer if I didn't know it before hand, and all I had was the equation? Any advice?",['algebra-precalculus']
2538604,The sequence of polynomials that generates $\sqrt{ x}$,"Let $A$ be a unital C*-algebra, and $x\in A^+$. We know $\sqrt{x}$ is a unique square root of $x$, is limit of polynomials generated by $x$. My question: What is the representation of these polynomials? I think about using Functional calculus, and find the polynomials that generated the function $\sqrt{x}$. Thought about Maclaurin series, but I could not find anything. Please advise me. Thanks a lot.","['functional-analysis', 'c-star-algebras', 'operator-theory']"
2538608,Question Regarding the Coordinate Independent Form of the Exterior Derivative,"The coordinate version of the exterior derivative $d:\Omega^k(M)\to \Omega^{k+1}(M)$ of differential forms of a $C^\infty$ manifold $M$ can be expressed on a form 
$$ \omega=fdx^1\wedge\cdots\wedge dx^k$$
as 
$$ d\omega=\sum_{i=1}^n\frac{\partial f}{\partial x^i}dx^i\wedge dx^1\wedge\cdots \wedge dx^k$$
(for example). Alternatively, one can express this in a coordinate invariant form as
$$ d\omega(X_1,\ldots, X_{k+1})=\sum_{i=1}^{k+1}(-1)^{i+1}X_i(\omega(X_1,\ldots, \widehat{X_i},\ldots, X_{k+1}))$$
$$+\sum_{1\le i<j\le k+1}(-1)^{i+j}\omega([X_i,X_j],X_1,\ldots, \widehat{X_i},\ldots, \widehat{X_j},\ldots,X_{k+1}).$$
Here the $X_i\in \mathfrak{X}(M)$. I can show that these two operators are actually the same. That's not a problem. My confusion is in showing that the coordinate invariant form $d\omega$ is independent of extension $X_1,\ldots, X_{k+1}\in \mathfrak{X}(M)$. Indeed, the idea is that we define $d\omega_p$ on a $(k+1)-$tuple 
$$(v_1,\ldots, v_{k+1})\in \overbrace{T_pM\times\cdots\times T_pM}^{k+1\:\text{times}}$$
by extending this tuple to a $(k+1)-$tuple of smooth vector fields $X_1,\ldots, X_{k+1}$ so that $X_i(p)=v_i$. I can see that this is independent of extension, because of the corresponding fact for the coordinate definition. On the other hand, I would like to show that this formula is well-defined in this sense intrinisically , based only on the coordinate independent formula. EDIT: As an addendum, I want to understand why the coordinate independent definition is independent of extension $(X_1,\ldots, X_{k+1})$ chosen without appealing to the coordinate definition. EDIT 2: Please note this question is not a duplicate of the other, because I am interested in showing the corresponding fact for the coordinate-independent version of the formula, without appealing to the coordinate expression.","['differential-forms', 'de-rham-cohomology', 'differential-geometry']"
2538656,Proving $y=\tan(x)$ is of the form $P_{n+1}(\tan(x))$,"So as the title states I have to prove using induction that the nth derivative of $y=\tan(x)$ is of the form $P_{n+1}(\tan(x))$, where $P_{n+1}$ is a polynomial of  degree $n+1$ So what's the intuition behind this? Usually I would like to find a general formula for the derivative of $\tan(x)$ and then following the steps of mathematical induction. Which would get me: $n = k+1$ for all n. How do I approach this problem? Thank you in advance","['derivatives', 'induction', 'polynomials']"
2538705,Joint probability density function and limits of integration,"Suppose we have $f(x,y) = 2$ when $x>0$, $y>0$, $x+y <1$ and $0$ elsewhere. 
I want to find the $\Pr(Y>X)$ and I'm struggling with finding the correct limits of integration generally but especially when we want to find $\Pr(Y>X)$ or similar. Can anyone explain the general method please, would be very grateful.",['statistics']
2538764,Do units in $\mathbb{Z} [(1+\sqrt{d})/2] $ have norm $\pm1$?,Do units in $\mathbb{Z} [(1+\sqrt{d})/2] $ have norm $\pm1$? As I understood the norm of units of integer rings of $\mathbb{Q} (\sqrt{d} ) $ have norm $\pm 1$ and at the same time $N( \frac{a + b \sqrt{d}}{2} ) = \frac{1}{4} (a^2 - d b^2)$ in my understanding. Is that right?,"['number-theory', 'algebraic-number-theory']"
2538811,application of Kolmogorov 0-1 Law,"Any random variable measurable with respect to the tail $\sigma$-field
of an infinite independent sequence of $\sigma$-fields is equal to some constant a.s. My attempt: Since $\alpha_n \rightarrow \infty$, we have $\limsup \frac{S_n}{\alpha_n} = \limsup \frac{X_j,\ldots,X_n}{\alpha_n}$, thus the variable $\limsup \frac{S_n}{\alpha_n}$ is measurable with respect to the tail σ-algebra of (X_n) and since the (Xn) are all
independent, by the 0 − 1 law, this random variable is almost-surely constant. Is it correct the attempt ? Could someone help me pls? Thanks for your time and help","['probability-theory', 'probability']"
2538838,formula for $E$($X^{2}$),Let $X$ be a random variable ( values in $\mathbb{N_0}$ ) Show that: $$ E(X^{2})= \sum_{k=1}^{\infty} (2k-1)P(X \ge k) $$ I already know that: $$E(X^{2}) = E(X(X-1)) + E(X) $$ $$ E(X) = \sum_{k=1}^{\infty} P(X \ge k)  $$ Maybe this could help?,"['probability-theory', 'probability']"
2538871,"if $\frac{m}{n},\frac{m+1}{n+2},\frac{m+2}{n+4},\frac{m+3}{n+6}$be positive integers, find the minimum of the m [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question let $m$ be a positive integer,and $n$ be an  positive integers,such $$\dfrac{m}{n},\dfrac{m+1}{n+2},\dfrac{m+2}{n+4},\dfrac{m+3}{n+6}$$be positive integers,find the minimum of the $m$. It seem use CRT to solve it? But I can't find it so far",['number-theory']
2538873,Doubly periodic entire function with periods that are linearly independent over $\mathbb{Q}$ is constant.,"Question Let $f$ be entire and suppose there exists $\lambda_1,\lambda_2 \in \mathbb{C}$ linearly independent over $\mathbb{Q}$ such that $f(z+\lambda_1)=f(z)=f(z+\lambda_2)$. Then $f$ is constant. Attempt A similar question was asked here but I don't think the answer is satisfactory. I want to (hopefully) show that for any $\epsilon>0$ I can find integers $m_1,m_2$ such that $|m_1\lambda_1+m_2\lambda_2|<\epsilon$. Then I will be able prove the result as follows: Let $z_0\in \mathbb{C}$. Then $g(z)=f(z)-z_0$ has a zero at $z_0$ and this zero must be isolated. Consequently we can find an $\epsilon>0$ such that the epsilon ball about $z_0$ contains only one zero ($z_0$) of $g(z)$. However, by the above, we can find $m_1,m_2$ so that $|m_1\lambda_1+m_2\lambda_2|<\epsilon$ and by assumption $g(z_0+m_1\lambda_1+m_2\lambda_2)=g(z_0)=0$ which is only possible if $f$ had been constant.",['complex-analysis']
2538879,Borel Zero-One Law for a sequence of constants,"I'm working on a problem and need some intuition to get unstuck, thanks in advance. So, we are given a sequence of iid random variables $ \{X_n, n \geq 1\}$. Then we have $\{a_n\}$ is a sequence of constants. We need to show: $$P \{ [X_n > a_n] \text{ i.o.}  \} = 
\begin{cases} 
      0 & \text{iff } \sum_n P[X_1 >a_n] < \infty \\
      1 & \text{iff } \sum_n P[X_1 >a_n] = \infty
   \end{cases}
$$ My intuition: It is clear that this problem is related to Borel Zero-One Law. So, I think of defining the event $A_n = X_1 > a_n$ and then, claim that by the one-zero law: $$P \{ [A_n] \text{ i.o.}  \} = 
\begin{cases} 
      0 & \text{iff } \sum_n P(A_n) < \infty \\
      1 & \text{iff } \sum_n P(A_n) = \infty
\end{cases}
$$
However, I think I'm missing something or ignoring something by not considering that what I'm asked to show involves the sum of terms having $X_1$ only: i.e. $\sum_n P[X_1 > a_n]$. Any thought you may have about it? Thanks.","['borel-cantelli-lemmas', 'probability-theory', 'measure-theory']"
2538928,Weak convergence and convergence in measure implies convergence in L^1?,"This is a problem from S.J.Taylor Introduction to Measure and Integration p.182 Problem Let $(\Omega, \mathcal F, \mu)$ be a measure space.
Let $f_n$ be a sequence of functions in $L^1(\mu)$ such that $f_n$  converge in measure to $f$ and $ \left(\int_E f_n \right)$  is a Cauchy sequence for every measurable set $E$, then we must prove that $f_n$ converge to $f$ in $L^1$. What I was trying to do is to proof that the measures $\nu_n $ induced by $f_n$ are equicontinous at $\emptyset$, this is, for all $\epsilon > 0$ and all decreasing sequence of sets $(B_k) \downarrow \emptyset$ there exists a $k_0$ such that $k\geq k_0$ implies $|\nu_n(B_k)|< \epsilon $. Because there is a result that convergence in measure and equicontinuity at $\emptyset$ implies $L^1$ convergence but the problem is that I don't know how to use effectively the condition that the measures converge for every set. One option was first consider the case where all the functions are positive or use contradiction and suppose that the sequence is not equicontinous.","['weak-convergence', 'measure-theory']"
2538937,Inverse of matrix with nonnegative entries,"I am interested in matrices with the property that both $A$ and $A^{-1}$ have nonnegative entries.  The only such matrices I could construct were diagonal matrices, and my question is whether these are the only such examples. What I can say about such matrices is that they must preserve the quadrant
$$
Q^+ = \{x\in\mathbb{R}^n \mid x_i \geq 0 \}.
$$
That is, $x\in Q^+$ if and only if $Ax\in Q^+$.  This seems rather unlikely unless $A$ preserves the axes, that is, unless $A$ is diagonal.  But I can't seem to turn this into a proof. EDIT Cameron Buie made the nice observation that permutation matrices also work. So I wonder: are there any examples with more than $n$ nonzero entries?  What about 2x2 examples with at least 3 nonzero entries?","['matrices', 'linear-algebra']"
2538963,Combinatorial justification for $C_{11}-C_{10}=\binom{12+9}9-2\binom{12+9-1}{9-1}$,"TL;DR: How is $2\binom{9+12-1}{9-1}$ the number of paths from $(3,0)$ to $(12,12)$ touching or crossing above the diagonal $y=x$? Full version: I'm an undergraduate teaching assistant, tutoring discrete maths this year, but I have to admit, I'm struggling to find an explanation for an expression one of my students has come up with in a homework problem (without any logical reasoning)... I hope you can help me see the combinatorial argument! The exercise in question is: How many monotonic paths [i.e. the allowed moves from $(x,y)$ are $(x+1,y)$ and $(x,y+1)$] are there from $(3,0)$ to $(12,12)$ that do not touch the diagonal (except for the final move?) The students know that the number of monotonic paths from $(0,0)$ to $(n,n)$ that do not cross above (but may touch ) the diagonal is given by the Catalan number $C_n$. The most obvious solution is the following: Introducing an auxiliary subdiagonal $1$ unit length below turns the question into ""how many monotonic paths are there from $(1,0)$ to $(12,11)$ that are allowed to touch the diagonal and go through $(3,0)$?"" From $(1,0)$ we can only reach $(2,0)$, from where we can reach $(3,0)$ or $(2,1)$. There are $C_{11}$ monotonic paths to $(12,11)$ starting from $(1,0)$, and $C_{10}$ starting from $(2,1)$, so the answer is $C_{11}-C_{10}$. Another valid approach I saw in one submission: The number of monotonic paths from $(3,0)$ to $(12,11)$ is $\binom{20}{11}$, the number of bad paths (that touch / cross above the diagonal) is $\binom{20}{12}$, so the answer is $\binom{20}{11}-\binom{20}{12}$. There was no explanation given by the student, but I figured that this expression was most probably derived from André's reflection method , i.e. the number of monotonic paths is $\binom{9+11}{11}$, and if we substitute all $\to$ moves for $\uparrow$ moves and vice versa from the point a path goes bad, we end up at $(11,12)$ instead, which gives us a bijection from the bad paths to all monotonic paths from $(3,0)$ to $(11,12)$, of which there are $\binom{8+12}{12}$. (Fair enough, I would've liked for the student to write down their reasoning, but at least some valid reasoning was not too hard to come up with.) Now the third approach is the one that I can't wrap my head around, but it leads to the correct answer: The expression for all monotonic paths from $(3,0)$ to $(12,12)$ is $\binom{9+12}{9}$, the number of bad paths is $2\binom{9+12-1}{9-1}$, so the answer is $\binom{21}{9}-2\binom{20}8$. No logical reasoning provided at all, so now I'm trying to figure out how the student arrived at this conclusion. I totally see where $\binom{9+12}{9}$ comes from, and at least one of the two occurrences of $\binom{9+12-1}{9-1}$ could be interpreted as the number of monotonic paths from $(3,0)$ to $(11,12)$, all of which are bad paths, but I can't seem to figure out how the remaining bad paths correspond to the expression $\binom{9+12-1}{9-1}$.","['combinatorics', 'integer-lattices', 'catalan-numbers', 'discrete-mathematics']"
2538964,Which part of the train stays for the longest time in the station?,"A train with length $L$ is moving towards a train station of length $S$ with speed $v$. The train starts to decelerate with acceleration $-a$ as soon as head reaches the station until completely stops. Right after the train completely stops, it starts to accelerate with acceleration $a$ until its tail leaves the station with speed $v$. Which part of the train stays for the longest time in the station? The correct answer is the mid-part of the train. If the head stays in the station for $t$ and the mid-part of the train stays for $\sqrt{2}t$. Could anyone give me some clue on how to get this?","['algebra-precalculus', 'physics', 'calculus']"
2539022,How do I obtain the first fundamental form in terms of the arclength and unit normal of an arbitrary ray in the real plane?,"My question is based on the 1981 paper ""Computation of wave fields in inhomogenous media"" by Cerveny et.al. (I will add any appropriately needed information to this posted question, so there is no need to obtain the paper). They search for solutions to the wave equation $$\frac{\partial^2u}{\partial{x^2}} + \frac{\partial^2u}{\partial{z^2}} = \frac{1}{V(x,z)^2}\frac{\partial^2u}{\partial{t^2}}$$ where $V(x,z)$ is known. The $\mathbb{R}^2$ Cartesian coordinates $(x,z)$ are used. An arbitrary ray $\Omega \subset \mathbb{R}^2$ is taken, and parameterized by arclength $s$ increasing from an initial point $s = 0$ at $t = 0$. The real plane is parameterized based on $\Omega$ by the arclength $s$ and the unit normal $n$ off the ray (see figure, reproduced from reference). For non-straight rays $\Omega$ there are irregular regions (where different pairs $(s,n)$ that describe the same point in $\mathbb{R}^2$), and the complement in $\mathbb{R}^2$ is called the regularity region. They then obtain the first fundamental form in terms of a small segment $dr$ of arclength as $$dr^2 = h^2 ds^2 + dn^2$$ where $$h = 1 + \frac{n}{v}v_n$$ for $v(s) = V(s,0)$ and $$v_n = \left[\frac{\partial V(s,n)}{\partial n}\right]_{n=0}.$$ My question: How did they obtain the first fundamental form? I know that $$dr^2 = F_{ss} ds^2 + 2F_sF_n ds dn + F_{nn} dn^2$$ where $F(s,n) = (x,z)$ is the coordinate transformation and $F_s$ is the first derivative of $F$ wrt $s$, $F_{ss}$ the second, $F_{sn}$ the mixed derivative. However, they obtain the first fundamental form with arbitrary array $\Omega$. Let me know if you need more information. Reference: Červený, Vlastislav, Mikhail M. Popov, and Ivan Pšenčík. ""Computation of wave fields in inhomogeneous media—Gaussian beam approach."" Geophysical Journal International 70 .1 (1982): 109-128.","['coordinate-systems', 'multivariable-calculus', 'wave-equation', 'ordinary-differential-equations', 'differential-geometry']"
2539040,What's the Cartesian Product of $\{x\}$ and $\{x\}$?,"The exercise I'm working on is ""Show that $\{x\} \times \{x\} = \{\{\{x\}\}\}$"". The solution I'm seeing says that this is equal to $\{\{\{x\}\}\}$, but I don't get this yet. Here's what I do understand: $\{x\}\times\{x\}$ should be the set of ordered pairs whose first coordinate is in $\{x\}$ and whose second coordinate is also in $\{x\}$. The only thing in $\{x\}$ is $x$. The cartesian product is a set. An ordered pair is a set. So if $x$ is the only thing in $\{x\}$, then the only ordered pair of $\{x\} \times \{x\}$ should be $\{x\}$, and the cartesian product should be the set of all of those ordered pairs, i.e. $\{\{x\}\}$. Any hints as to what I'm missing?",['elementary-set-theory']
2539062,Find this maximum of the $\frac{\sqrt{3}}{4}x^2+\frac{\sqrt{(9-x^2)(x^2-1)}}{4}$,"Let $x\in \mathbb{R}$, find the function maximum of the value
$$f(x)=\dfrac{\sqrt{3}}{4}x^2+\dfrac{\sqrt{(9-x^2)(x^2-1)}}{4}$$ my attemp
$$x^2=5+4\sin{t},t\in\left[-\frac{\pi}{2},\frac{\pi}{2}\right]$$
then
$$f=\dfrac{5\sqrt{3}}{4}+2\sin{\left(t+\frac{\pi}{6}\right)}\le 2+\dfrac{5}{4}\sqrt{3}$$ My Question:this function have other methods to find this maximum? such as AM-GM,Cauchy-Schwarz inequality and so on?","['algebra-precalculus', 'real-analysis', 'inequality', 'maxima-minima']"
2539116,Conformal mappings of $\mathbb{D}$ onto $\mathbb{D}$ which is not one-to-one?,"A holomorphic (analytic) function $f:\Omega\to\mathbb{C}$ is called a conformal mapping if $f'$ is nonvanishing. Every one-to-one holomorphic function is conformal, but the converse is not true. (e.g. $\exp$.) My question is: Is there any conformal mapping of $\mathbb{D}$ onto $\mathbb{D}$ which is not one-to-one? (or If $f:\mathbb{D}\to\mathbb{D}$ is conformal and onto, then does it follow that $f$ is one-to-one?) Find all conformal mapping of $\mathbb{D}$ onto $\mathbb{D}$ such that $f(0)=0$.","['complex-analysis', 'conformal-geometry']"
2539122,Determine set of subsequential limits,"Suppose you are given a sequence $\{s_n\}$, where the odd terms $\{s_{2m+1}\}$ and the even terms $\{s_{2m}\}$ form two converging subsequences: $$s_{2m+1} \to \alpha,$$ $$s_{2m} \to \beta.$$
My intuition is that the set of subsequential limits $E$ of $\{s_n\}$ equals $\{\alpha, \beta\}$, but I’m struggling with a proof. Is there a way to pick another subsequence of $\{s_n\}$ that converges to some $\gamma \neq \alpha, \gamma \neq \beta$? @David
If a subsequence contains finitely many odd or finitely many even terms, then in the tail it converges to either $\alpha$ or $\beta$. If a subsequence contains infinitely many odd terms and infinitely many even terms, then for no $N$ does the tail $\{s_n: n \geq N\}$ get arbitrarily close to either $\alpha$ or $\beta$. Is that the right reasoning?","['real-analysis', 'sequences-and-series', 'convergence-divergence']"
2539135,How to solve $\int(\cos(x)^{\cos(x)+1}\tan(x) (1+\log(\cos(x)))dx$? (2017 MIT Integration Bee Qualifier Problem #20),"I'm working my way through the qualifier, trying to learn some new techniques as I go. I am pretty stymied by this one. Solve: $$\int(\cos(x)^{\cos(x)+1}\tan(x)
(1+\log(\cos(x)))dx$$ My steps so far have been to let $u=\cos(x)$ and $\,du=-\sin(x)\,dx$ which yields: $$-\int u^u(1+\log(u))du$$ From here I am not so sure where to go. I would prefer a hint rather than a full solution, please. Thanks!",['integration']
2539141,Contradiction of gradient between direction of steepest increase and local minimum,"I can understand the proof that at a local minimum, the gradient of that function must be zero. But I can't understand it together with the fact that gradient points the steepest increase, since if it is at local minimum, then moving at any direction will give the function some increment. So what does gradient being zero at this point means? If any direction increases this function, then why don't we just choose the direction with the greatest increment but choose zero which means not to move at all?","['multivariable-calculus', 'gradient-descent', 'vector-analysis']"
2539181,Meaning of inverse temperature,"I am not familiar with statistics, so when I read a book which covers statistical learning, I have a question. Here, a posteriori probability density function is defined as follows; $D_n=\{X_1,X_2,\cdots, X_n \}$ be a set of random variables and $\varphi(w)$ be a priori probability density function. Then for given statistical model $p(x|w)$,
The ""a posteriori probability density function $p(w|D_n)$ with the inverse temperature $\beta>0$"" is defined by
$$p(w|D_n)={1\over {Z_n}} \varphi(w) \prod_{i=1}^n p(X_i|w)^\beta,$$
where $Z_n$ is the normalizing factor. My question is what is the meaning of ""inverse temperature""? I want to know its meaning or role in this definition.
Any reference would be helpful, thanks!",['statistics']
2539233,"If $\phi : M = \mathbb{R}^n \setminus \{0\} \to \mathbb{R}^n$ is defined by $\phi(x) = x + \frac{x}{|x|}$, find $\phi^{-1}$","If $\phi : M = \mathbb{R}^n \setminus \{0\} \to \phi[M] \subseteq \mathbb{R}^n$ is defined by $\phi(x) = x + \frac{x}{|x|}$, find $\phi^{-1}$ I'm not sure how to go about finding $\phi^{-1}$ here. $\phi$ is clearly injective, and bijective on $M$, so $\phi^{-1}$ must exist, but I'm not entirely sure how to go about algebraically finding the inverse $\phi^{-1}(x)$. How can I go about doing so? If it helps the boundary of $\phi[M]$ is $S^{n-1}$.","['multivariable-calculus', 'inverse-function', 'functions']"
2539271,Expected area of a random $n$-gon,"Choose $n$ points $\{z_1, \ldots, z_n\}$ from the unit circle $\partial \mathbb{D} = \{z \in \mathbb{C}: |z| = 1\}$ uniformly at random, and let $P_n$ be the convex hull of the $z_i$'s. Let $X_n = area(P_n)$. What can be said about $X_n$? Can $\mathbb{E}X_n$ be computed? It's easy to see that $P_n$ converges to $\mathbb{D}$ pointwise almost surely, so $X_n \to \pi$ a.s. as $n \to \infty$. What is the rate of convergence? It is 'easy' to get a direct computation for $\mathbb{E}X_3$, by writing down a formula for the area of the triangle and integrating directly: for example, you can assume $z_1 = 1$, and that $z_2 = e^{i \theta}, z_3 = e^{i \phi}$ with $\theta < \phi$, and integrate directly. But this is a bit tedious, and especially so for large $n$! Is there an easier way to do this computation? One idea is to rely on order statistics: write $z_k = \exp(i \theta_k)$ for iid uniform variables $\theta_k \in [0,2\pi)$, and let $\{\phi_k\}_{k=1}^n$ be the ordered sequence of the $\theta_k$, i.e. $\phi_1 = \min\{\theta_1, \ldots, \theta_n\}$, $\phi_2 = $ 2nd largest element of $\{\theta_1, \ldots, \theta_n\}$, ... $\phi_n = \max\{\theta_1, \ldots, \theta_n\}$. The distributions of the $\phi$'s can be written down explicitly - though it's a bit messy - and $P_n$ can be divided into $n$ triangles, yielding $X_n = \frac{1}{2} \sum_{k=1}^n \sin(\phi_k - \phi_{k-1})$, with the convention $\phi_0 = \phi_n - 2\pi$. I haven't tried writing down this integral out of fear, but it may be do-able. ( I suspect there is a clever symmetry argument to avoid needing the order statistics. ) Heuristically, if the $z_n$ are 'well-distributed,' the angle distance between adjacent $z_i$'s is roughly $\frac{2\pi}{n}$, so the error between the areas of the disk and $P$ is roughly $n(\frac{\pi}{n} - \frac{1}{2} \sin(\frac{2\pi}{n})) = \frac{4\pi^3}{3} n^{-2} + O(n^{-4})$. Thus we should have $n^2(\pi - \mathbb{E}X_n) \to L \in (0,\infty)$ $\hspace{.5cm} (\star)$ Perhaps this argument can be formalized, and the constant $L$ can be determined. After that, the usual next step is to hope for something like $n^2(\pi - X_n) \to_d Z$ for some random variable $Z$, or a CLT like $\gamma_n (X_n - \mathbb{E}X_n) \to_d N(0,1)$ for some constants $\gamma_n$. Also: what if the $z_k$ are selected uniformly from the unit sphere in $d$-dimensions? I haven't thought much about this, but maybe a statement analogous to $\star$ can be proved. Edit 1: A quick google search revealed this site, which has some additional interesting calculations. In particular, it claims to compute $L$ via the method I suggested, which would answer $\star$.","['area', 'probability', 'geometric-probability', 'random-variables']"
2539306,Sum of Independent Half-Normal Distributions with unequal variance,"$\DeclareMathOperator{\erf}{erf}$ I want to find the cumulative distribution function (CDF) of the random variable $Z = |X| + |Y|$ where $X$ and $Y$ are two independent random variables which are normally distributed with mean 0 but different variance $\sigma_X^2$ and $\sigma^2_{Y}$ . $|X|$ and $|Y|$ follow the so-called Half-Normal distribution, which is a special case of the Folded-Normal distribution, when $\mu = 0$ . The probability density functions (PDF) of $|X|$ and $|Y|$ for $x > 0$ are defined as follows ( wikipedia ): \begin{align}
\label{pdf}
f_{|X|}(x, \sigma_{X}) =  \frac{\sqrt{2}}{\sigma_{X}  \sqrt{\pi}}  \exp \left(- \frac{x^2}{2\sigma_{X}^2}\right) && f_{|Y|}(y, \sigma_{Y}) =  \frac{\sqrt{2}}{\sigma_{Y}  \sqrt{\pi}} \exp\left(- \frac{y^2}{2\sigma_{Y}^2}\right)
\end{align} And their CDF: \begin{align}
\label{cdf}
F_{|X|}(x, \sigma_{X}) = \erf\left(\frac{x}{\sigma_{X} \sqrt{2}}\right) && F_{|Y|}(y, \sigma_{Y}) = \erf\left(\frac{y}{\sigma_{Y} \sqrt{2}}\right)
\end{align} @DilipSarwate gave a very elegant solution for the case $\sigma_{Y} = \sigma_{X}$ here , but I am interested in the general case when this is not true, i.e. one of the variable has a higher weight in the final value (bigger scale). So far, I have determined the PDF of $Z$ by doing the convolution of $f_{|X|}$ and $f_{|Y|}$ . Since $f_{|X|}$ and $f_{|Y|}$ are defined only for $x > 0$ , we can truncate the convolution to the interval $[0,z]$ : \begin{align}
f_Z(z) &= \int_0^z f_{|Y|}(z-x) f_{|X|}(x) \, dx \\
f_Z(z) &= \frac{2}{\sigma_X \sigma_Y \pi} \int_0^z \exp\left(\frac{-(z-x)^2}{2\sigma_Y^2}\right) \exp\left(\frac{-x^2}{2\sigma_X^2}\right) \, dx \\
f_Z(z) &= \frac{2}{\sigma_X \sigma_Y \pi} \int_0^z 
\exp\left(\frac{-(x^2 - 2xz + z^2)}{2\sigma_Y^2}\right) \exp\left(\frac{-x^2}{2\sigma_X^2}\right) \, dx \\
f_Z(z) &= \frac{2}{\sigma_X \sigma_Y \pi} \exp\left(\frac{-z^2}{2\sigma_Y^2}\right) \int_0^z \exp\left(\frac{-x^2+2xz}{2\sigma_Y^2}\right) \exp\left(\frac{-x^2}{2\sigma_X^2}\right) \, dx \\
f_Z(z) &= \frac{2}{\sigma_X \sigma_Y \pi} \exp\left(\frac{-z^2}{2\sigma_Y^2}\right) \int_0^z \exp\left(\frac{-(\sigma_X^2 + \sigma_Y^2)x^2 + 2z\sigma_X^2 x}{2 \sigma_X^2 \sigma_Y^2}\right) \, dx 
\end{align} We define $\sigma_Z = \sqrt{\left(\sigma_X^2 + \sigma_Y^2\right)}$ : \begin{align}
f_{Z}(z) &= \frac{2}{\sigma_X \sigma_Y \pi} \exp\left(\frac{-z^2}{2\sigma_Y^2}\right) \int_{0}^{z} \exp\left(\frac{-\sigma_Z^2 x^2 + 2z\sigma_X^2 x}{2 \sigma_X^2 \sigma_Y^2}\right) dx 
\end{align} We complete the square $ax^2 + bx$ to the form $a(x-h)^2 + k$ with $h = -\frac{b}{2a}$ and $k = - \frac{b^2}{4a}$ , i.e., $h = \frac{z\sigma_X^2}{\sigma_Z^2}$ and $k = \frac{(z \sigma_X^2)^2}{\sigma_Z^2}$ . This results in: \begin{align}
f_{Z}(z) &= \frac{2}{\sigma_X \sigma_Y \pi}
\exp\left(\frac{-z^2}{2\sigma_Y^2}\right) 
\int_{0}^{z} 
\exp\left(\frac{-\sigma_Z^2\left(x - \frac{z \sigma_X^2}{\sigma_Z^2}\right)^2 
	+ \frac{(z \sigma_X^2)^2}{\sigma_Z^2}}{2\sigma_X^2 \sigma_Y^2}\right) dx \\
f_{Z}(z) &= \frac{2}{\sigma_X \sigma_Y \pi}
\exp\left(\frac{-z^2}{2\sigma_Y^2}\right)
\exp\left(\frac{(z\sigma_X^2)^2}{2\sigma_X^2 \sigma_Y^2 \sigma_Z^2}\right) \int_{0}^{z} 
\exp\left(\frac{-\sigma_Z^2 \left(x - \frac{z \sigma_X^2}{\sigma_Z^2}\right)^2}{2\sigma_X^2 \sigma_Y^2}\right) dx \\
f_{Z}(z) &= \frac{2}{\sigma_X \sigma_Y \pi} \exp\left(\frac{-z^2(\sigma_Z^2 - \sigma_X^2)}{2\sigma_Y^2 \sigma_Z^2}\right) \int_{0}^{z} \exp\left(\frac{-\sigma_Z^2 \left(x - \frac{z \sigma_X^2}{\sigma_Z^2}\right)^2}{2\sigma_X^2 \sigma_Y^2}\right) dx \\
f_{Z}(z) &= \frac{2}{\sigma_X \sigma_Y \pi} \exp\left(\frac{-z^2}{2 \sigma_Z^2}\right) \int_{0}^{z} \exp\left(\frac{-\sigma_Z^2 \left(x - \frac{z \sigma_X^2}{\sigma_Z^2} \right)^2}{2\sigma_X^2 \sigma_Y^2}\right) dx 
\end{align} \begin{align}
f_{Z}(z) &= \frac{2}{\sigma_X \sigma_Y \pi} \exp\left(\frac{-z^2}{2 \sigma_Z^2}\right) \int_{0}^{z} \exp\left(\frac{-\left(x - \frac{z \sigma_X^2}{\sigma_Z^2}\right)^2}{2\frac{\sigma_X^2 \sigma_Y^2}{\sigma_Z^2}}\right) dx \\
\end{align} We add the term $\frac{\sqrt{2 \pi (\frac{\sigma_X \sigma_Y}{\sigma_Z})^2}}{\sqrt{2 \pi (\frac{\sigma_X \sigma_Y}{\sigma_Z})^2}}$ : \begin{align}
f_{Z}(z) &= \frac{2}{\sigma_X \sigma_Y \pi} 
\exp\left(\frac{-z^2}{2 \sigma_Z^2}\right) 
\sqrt{2 \pi \left(\frac{\sigma_X \sigma_Y}{\sigma_Z}\right)^2} 
\int_{0}^{z} 
\frac{1}{\sqrt{2 \pi \left(\frac{\sigma_X \sigma_Y}{\sigma_Z}\right)^2}}
\exp\left(\frac{-\left(x - \frac{z \sigma_X^2}{\sigma_Z^2}\right)^2}{2\left(\frac{\sigma_X \sigma_Y}{\sigma_Z}\right)^2}\right) dx \\
f_{Z}(z) &= \frac{2 \sqrt{2}}{\sigma_Z \sqrt{\pi}} 
\exp\left(\frac{-z^2}{2 \sigma_Z^2}\right) 
\int_{0}^{z} 
\frac{1}{\sqrt{2 \pi \left(\frac{\sigma_X \sigma_Y}{\sigma_Z}\right)^2}} 
\exp\left(\frac{-\left(x - \frac{z \sigma_X^2}{\sigma_Z^2}\right)^2}{2\left(\frac{\sigma_X \sigma_Y}{\sigma_Z}\right)^2}\right) dx 
\end{align} As we can see, the expression in the integral represents the density of a Gaussian distribution with mean $\frac{z \sigma_X^2}{\sigma_Z^2}$ and standard deviation $\frac{\sigma_X \sigma_Y}{\sigma_Z}$ . As a results we can evaluate it as follows: \begin{align}
f_{Z}(z) &= \frac{2 \sqrt{2}}{\sigma_Z \sqrt{\pi}} \exp\left(\frac{-z^2}{2 \sigma_Z^2}\right) \left[\Phi\left(z, \frac{z \sigma_X^2}{\sigma_Z^2}, \frac{\sigma_X \sigma_Y}{\sigma_Z}\right) - \Phi\left(0, \frac{z \sigma_X^2}{\sigma_Z^2}, \frac{\sigma_X \sigma_Y}{\sigma_Z}\right)\right]
\end{align} where $\Phi(x,m,s)$ is the value of the cumulative distribution function at $x$ of a Gaussian distribution with mean $m$ and standard deviation $s$ . Now we can compute the cumulative distribution function $F_Z$ : \begin{align}
F_{Z}(z) &= \int_{0}^{z} f_{Z}(x) dx \\
F_{Z}(z) &=  \frac{2 \sqrt{2}}{\sigma_Z \sqrt{\pi}}  \int_{0}^{z} \exp\left(\frac{-x^2}{2 \sigma_Z^2}\right) \left[\Phi\left(x, \frac{x \sigma_X^2}{\sigma_Z^2}, \frac{\sigma_X \sigma_Y}{\sigma_Z}\right) - \Phi\left(0, \frac{x \sigma_X^2}{\sigma_Z^2}, \frac{\sigma_X \sigma_Y}{\sigma_Z}\right)\right] dx \\
F_{Z}(z) &=  \frac{2 \sqrt{2}}{\sigma_Z \sqrt{\pi}}  \int_{0}^{z} \exp\left(\frac{-x^2}{2 \sigma_Z^2}\right) \left[
\frac{1}{2} \left( 1 + \erf \left(\frac{x-\frac{x \sigma_X^2}{\sigma_Z^2}}{\frac{\sigma_X \sigma_Y}{\sigma_Z} \sqrt{2}} \right) \right) - 
\frac{1}{2} \left( 1 + \erf \left( \frac{-\frac{x \sigma_X^2}{\sigma_Z^2}}{\frac{\sigma_X \sigma_Y}{\sigma_Z} \sqrt{2}} \right) \right)
\right] dx 
\\
F_{Z}(z) &=  \frac{\sqrt{2}}{\sigma_Z \sqrt{\pi}}  \int_{0}^{z} \exp\left(\frac{-x^2}{2 \sigma_Z^2}\right) \left[
\erf \left( \frac{x-\frac{x \sigma_X^2}{\sigma_Z^2}}{\frac{\sigma_X \sigma_Y}{\sigma_Z} \sqrt{2}} \right)  - 
\erf \left( \frac{-\frac{x \sigma_X^2}{\sigma_Z^2}}{\frac{\sigma_X \sigma_Y}{\sigma_Z} \sqrt{2}} \right)
\right] dx 
\end{align} Since the integral of the sum is equal to the sum of the integrals: \begin{align}
F_{Z}(z) &=  \frac{\sqrt{2}}{\sigma_Z \sqrt{\pi}} \left[ 
\int_{0}^{z} 
\exp\left(\frac{-x^2}{2 \sigma_Z^2}\right) 
\erf \left( \frac{x-\frac{x \sigma_X^2}{\sigma_Z^2}}{\frac{\sigma_X \sigma_Y}{\sigma_Z} \sqrt{2}} \right) dx  - 
\int_{0}^{z} 
\exp\left(\frac{-x^2}{2 \sigma_Z^2}\right) 
\erf \left( \frac{-\frac{x \sigma_X^2}{\sigma_Z^2}}{\frac{\sigma_X \sigma_Y}{\sigma_Z} \sqrt{2}} \right)
 dx \right] \\
F_{Z}(z) &=  \frac{\sqrt{2}}{\sigma_Z \sqrt{\pi}} \left[ 
 \int_{0}^{z} 
 \exp\left(\frac{-x^2}{2 \sigma_Z^2}\right) 
 \erf \left( \frac{x \left(1-\frac{\sigma_X^2}{\sigma_Z^2} \right)}{\frac{\sigma_X \sigma_Y}{\sigma_Z} \sqrt{2}} \right) dx  - 
 \int_{0}^{z} 
 \exp\left(\frac{-x^2}{2 \sigma_Z^2}\right) 
 \erf \left( \frac{-\frac{x \sigma_X^2}{\sigma_Z^2}}{\frac{\sigma_X \sigma_Y}{\sigma_Z} \sqrt{2}} \right)
 dx \right] \\
 F_{Z}(z) &=  \frac{\sqrt{2}}{\sigma_Z \sqrt{\pi}} \left[ 
 \int_{0}^{z} 
 \exp\left(\frac{-x^2}{2 \sigma_Z^2}\right) 
 \erf \left( x \frac{\sigma_Y}{\sqrt{2} \sigma_Z \sigma_X } \right) dx  - 
 \int_{0}^{z} 
 \exp\left(\frac{-x^2}{2 \sigma_Z^2}\right) 
 \erf \left(- x \frac{\sigma_X}{\sqrt{2} \sigma_Z \sigma_Y } \right)
 dx \right]
\end{align} We know that $\erf(x)$ is an odd function and that $\exp(x)$ is an even function, as a result, their product is odd, and thus: \begin{align}
F_{Z}(z) &=  \frac{\sqrt{2}}{\sigma_Z \sqrt{\pi}} \left[ 
\int_{0}^{z} 
\exp\left(\frac{-x^2}{2 \sigma_Z^2}\right) 
\erf \left( x \frac{\sigma_Y}{\sqrt{2} \sigma_Z \sigma_X } \right) dx  +
\int_{0}^{z} 
\exp\left(\frac{-x^2}{2 \sigma_Z^2}\right) 
\erf \left(x \frac{\sigma_X}{\sqrt{2} \sigma_Z \sigma_Y } \right)
dx \right]
\end{align} This is where I am stuck. It seems that the integrals are not elementary. What can I do? Just to verify my results in the case of equal variance, I am going to assume that $\sigma_X = \sigma_Y$ . From 3.3 (41) in this paper , We know that: $$
\int \exp \left( -a^2 x^2 \right) \left[ \erf(ax)\right]^n \, dx = \frac{\sqrt{\pi}}{2a(n+1)} \left[\erf(ax)\right]^{n+1}
$$ Thus: \begin{align}
F^{\sigma_X = \sigma_Y}_{Z}(z) &=  \frac{2 \sqrt{2}}{\sigma_Z \sqrt{\pi}}  
\int_{0}^{z} 
\exp\left(\frac{-x^2}{2 \sigma_Z^2}\right) 
\erf \left( \frac{x}{\sqrt{2} \sigma_Z } \right) dx \\
F^{\sigma_X = \sigma_Y}_{Z}(z) &=  \frac{2 \sqrt{2}}{\sigma_Z \sqrt{\pi}}  
\frac{\sqrt{\pi}}{4 \frac{1}{\sqrt{2} \sigma_Z}} \erf(\frac{z}{\sqrt{2} \sigma_Z})^2 \\
F^{\sigma_X = \sigma_Y}_{Z}(z) &=  \erf(\frac{z}{\sqrt{2} \sigma_Z})^2
\end{align} Which is consistent with the solution from here . However, as I said, I don't know how to solve the problem when $\sigma_X \neq \sigma_Y$ . Any suggestions? I think I have no choice but to use a numerical approximation method, such as Simpson's rule.","['normal-distribution', 'convolution', 'calculus', 'probability-distributions', 'random-variables']"
2539310,Let $\log x=\log 2+\log y$ and $2^x+8^y=4$ then find the $x$,Let $\log x=\log 2+\log y$ and $2^x+8^y=4$ then find the $x$ My Try : $$\log x=\log 2+\log y \\ \log x=\log 2y \\x=2y $$ So we have : $$2^x+8^y=4\\2^{2y}+2^{3y}=4 \\t=2^y \\t^2+t^3=4$$ now what ?,['algebra-precalculus']
2539319,Relation of the category of $k$-schemes and the category of $k$-varieties,"For an algebraically closed field $k$, there exists a fully faithful functor from the category of $k$-varieties to $k$-schemes. (A $k$-variety is an affine, quasi-affine, projective, or quasi-projective variety. And an affine (resp. projective) variety is an irreducible closed subset of $\mathbb{A}_k$ (resp. $\mathbb{P}_k$), and a quasi-affine (resp. quasi-projective) variety is an open subset of an affine (resp. projective) variety, with respect to the Zariski topology, where $\mathbb{A}^n_k = \{ (a_i)_{i=1, \cdots n} | a_i \in k \}, \mathbb{P}^n_k = \{ (a_0 : \cdots : a_n) | a_i \in k, $ for some $i, a_i \neq 0 \}.$) I think this is the very motivation to study schemes in order to understand varieties. Now, but, it is natural desires to understand varieties over non-algebraically closed field, and also I want to, because I want to study diophantine geometry. But the functor only works over algebraically closed fields. Is there such a functor over non-algebraically closed fields? And if not, is there a reasonable reason to study schemes for people who want to study diophantine geometry?","['schemes', 'algebraic-geometry']"
2539338,minimal sets in a subset of a $\sigma$-algebra,"Given a measurable space $(X,\mathcal{X})$ and a set $A\in \wp(X)$ does there exist  a least set $B\in \mathcal{X}$ such that $A \subseteq B$ ? def. a measurable space $(X,\mathcal{X})$ consists of a set $X$ and a $\sigma$-algebra, i.e. a non-empty set $\mathcal{X}\subseteq \wp(X)$ which is closed under countable union and complements.","['measure-theory', 'elementary-set-theory']"
2539367,Ordinality of empty set,I search about why ordinality of an empty set is zero. there are some articles said this is convention. but i wondered the proof of this. Why ordinality of an empty set is zero?,['elementary-set-theory']
2539378,Trigonometric series convergent to $0$ a.e.?,"I was wondering whether there exist $(c_k)_{k\in\mathbb{Z}}$ in $\mathbb{C},$ not all $0,$ so that $\lim_{K \to \infty} \sum_{|k| \le K} c_ke^{2\pi i kx} = 0$ for a.e. $x \in [0,1]$ . Of course the answer is ""no"" provided that $\sum_k |c_k|^2 < \infty$ . This is all I got.","['real-analysis', 'fourier-series', 'analysis']"
2539404,"Why in distributive lattices, if an element has complement, it is unique?","I know in some lattice like Diamond, a given element can have more than one complement, but when we have a distributive lattice, an element has at most one complement.
I’m looking for prove of this Theorem, please help me. Logically in Lattice L (Inf is Infimum and Sup is Supremum): ∃x,y: (Inf(a,x)=0 ^ sup(a,x)=1) ^ (inf(a,y)=0 ^ Sup(a,y)=1) If L is distributive we can prove x=y. (Am i right?) P.S. It’s very helpful if you describe Line Of Reasoning of The prove too. Thanks,
Omid Yaghoubi","['lattice-orders', 'logic', 'order-theory', 'discrete-mathematics']"
2539421,Definition: Basis of a topology,"I have a question regarding the basis of a topology, or actually 2 different definitions I encountered.
Munkres:
If $X$ is a set, a basis for a topology on $X$ is a collection $\mathscr{B} \subset P(X)$ such that: i) For each $x \in X$, there is at least one basis element $B \in \mathscr{B}$ containing $x$. ii) If x belongs to the intersection of two basis elements $B_1$ and $B_2$, then there is a basis element $B_3$ containing $x$ such that $B_3 \subset B_1 \cap B_2$ And then he defines the generated topology as
$ \{ U \subset X \ | \ \forall x \in U \ : \exists B\in \mathscr{B} \ \ \text{s.t.} \ \ x \in B \subset U  \}$. So this is basically a way to start with a collection of subsets of $X$ that fulfill those two properties and this collection will always be a basis for one topology on this set $X$. In my class we started from the other direction, namely given a topological space $(X,\tau)$, $\mathscr{B} \subset P(X)$ is called a basis if every open set $U \in \tau$ can be written as an arbitrary union of basis elements. On my latest exercise sheet, I have to proof that $\mathscr{B} \subset P(X)$ is the basis of a topology $\tau$ on $X$ (in the sense of the second definition) if and only if the two defining properties from Munkres definition hold.
The one direction of this is pretty easy by giving a constructive proof using the generated topology. In the other direction, I have to show that if one of those properties does not hold, there can not be a topology $\tau$ on $X$ such that $\mathscr{B} \subset P(X)$ is a basis of $\tau$. If the first property is violated, then $X$ cannot be written as a union of basis elements so this one is clear. However, in my understanding, I have a counterexample for the second one: Let $X = \{1,2,3\}$ and $\tau = \{ \emptyset, X\}$ be the trivial topology. Now let $\mathscr{B}$ be such that it contains $B_1 = \{1,2\}$ and $B_2 = \{2,3\}$. To see that $\mathscr{B}$  is a basis, we have to check that we can generate $X$ as the union of basis elements which is clearly the case. However $B_1 \cap B_2 = \{ 2\}$ so property ii) is violated. Now I obviously got something mixed up at some point but I am really not sure where so could somebody please clarify this for me? Thanks,
Max","['self-learning', 'general-topology']"
2539440,Help Showing that the Adjoint Operator $T^*$ is Surjective if and only if $T$ is Injective,"Let $T\in L(V,W)$,where $L(V,W)$ denotes a linear map from a vector space $V$ to vector space $W$. I want to prove that $T$ is injective iff $T^*$ is surjective, where $T^*$ is the adjoint of $T$. I start with the definition of adjoint: $\langle w,Tv \rangle= \langle T^*w,v \rangle$ for all $w \in W $, $v\in V$. What should I do next? Take $v=0$?","['linear-algebra', 'adjoint-operators']"
2539475,How to derive the characteristic function $\phi_X(t) = \mathbb{E}\left(e^{it^T X}\right) = e^{it^T \mu} e^{-\frac{1}{2}t^T\Sigma t}$?,"My attempt to calculate the characteristic function $\mathbb{E}\left(e^{it^T X}\right)$ of multivariate normal distributed $X \sim \mathcal{N}_d(\mu,\Sigma)$, finding a lecture note that writes as follows, but I am confused about the $\overset{?}{=}$ step. \begin{align*}
\phi_X(t) &= \mathbb{E}\left(e^{it^T X}\right) \\
&= \int_{-\infty}^{\infty} e^{it^T X} f_X(x) dx \\
&= \int_{-\infty}^{\infty} e^{it^T X} \frac{1}{(2\pi)^{d/2}|\Sigma|^{1/2}} e^{-\frac{1}{2}(x-\mu)^T \Sigma^{-1} (x-\mu)} dx \\
&= \int_{-\infty}^{\infty} \frac{1}{(2\pi)^{d/2}|\Sigma|^{1/2}} \exp{\left(-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu)+it^T x\right)} dx \\
&\overset{?}{=} \exp{\left(it^T \mu - \frac{1}{2} t^T \Sigma t\right)} \\
&= e^{it^T \mu} e^{-\frac{1}{2}t^T\Sigma t}
\end{align*} Can you show me more details about that step?","['characteristic-functions', 'statistics', 'probability', 'normal-distribution']"
2539488,Trigonometric equation result differs from given,"i've got an equation: $$\sin^6(x) + \cos^6(x) = 0.25$$ and i'm trying to solve it using the sum of cubes formula, like this: $$ (\sin^2(x))^3 + (\cos^2(x))^3 = 0.25 $$
$$ (\sin^2(x) + \cos^2(x))^2 (\sin^4(x) - \sin^2(x)\cos^2(x) + \cos^4(x)) = 0.25 $$
$$ 1 - 3\sin^2(x)\cos^2(x) = 0.25 $$
$$ -3 \sin^2(x)\cos^2(x) = -\frac{3}{4} $$
$$ \sin^2(2x) = 1 $$
$$ \sin^2(2x) = \sin^2(2x) + \cos^2(2x) $$
$$ \cos^2(2x) = 0 $$ and here it must be $x = \frac{\pi n}{2} \pm \frac{\pi}{4} $ but solution is $ x = \pi n \pm \frac{\pi}{4}$ What's wrong?",['trigonometry']
2539509,Is $\mathbb{C}^m\times\mathbb{C}^n=\mathbb{C}^{m+n}$ true?,"In real analysis we have
$\mathbb{R}^{m} \times \mathbb{R}^{n} = \mathbb{R}^{m+n}$, e.g.
$$
\mathbb{R}\times\mathbb{R}=\mathbb{R}^2=\big \{
(x,y): x\in \mathbb{R}, y\in\mathbb{R}
\big\}
$$ Is this also true for complex numbers, i.e. $\mathbb{C}^m\times\mathbb{C}^n=\mathbb{C}^{m+n}$?","['complex-numbers', 'elementary-set-theory']"
2539520,Power series representation of arctangent: fails to converge everywhere,"My understanding of power series turns out to be less-well-formed than I thought.  To confess, I took my two courses in analysis in grad school (one real, one complex) and got out. Since this is my Calc II class, let's keep everything in real variables, please.  It's not hard to derive the power series for $\arctan(x)$ as
$$
\arctan(x) = \sum_{n=0}^\infty \frac{(-1)^n}{2n+1} x^{2n+1}, \ -1 \leq x \leq 1.
$$
Also not hard to work out the interval of convergence for the right-hand side.  So far, so good. Here's my question and why I suddenly see how naive I am.  I tend to think of $\arctan$ as an incredibly nice function, so I expect its power/Taylor series to converge everywhere.  In short, I view $\arctan$ as being just as nice as $f(x) = e^x$, whose power series representation converges everywhere (domain of the power series matches the domain of the function).  Same story for $\sin(x)$ and $\cos(x)$.  They're ""nice"" so their power series converge on their entire domain. When the power series for something like $\ln (x)$ or $\frac{1}{x}$ has finite radius, I'm completely fine with that as there is an obvious discontinuity that you bump into as you work your way out from the center.  But why does the power series for $\arctan(x)$ have a finite radius?  I know that something goes wrong with Taylor's remainder and this is what prevents the series from representing $\arctan(x)$ everywhere, but I would appreciate an explanation from the point of view of properties of $\arctan(x)$ and not its power series:  what is it about $\arctan(x)$ that prevents its power series from being optimally ""nice""?","['power-series', 'calculus']"
2539522,"Prob. 4, Chap. 7, in Baby Rudin: On what intervals does the series converge uniformly?","Here is Prob. 4, Chap. 7, in the book Principles of Mathematical Analysis by Walter Rudin, 3rd edition: Consider 
  $$ f(x) = \sum_{n=1}^\infty \frac{1}{1+n^2 x }. $$
  For what values of $x$ does the series converge absolutely? On what intervals does it converge uniformly? On what intervals does it fail to converge uniformly? Is $f$ continuous wherever the series converges? Is $f$ bounded? My Attempt: Fix a real number $\delta > 0$. If $x \in [ \delta, +\infty)$, then we see that 
  $$ 0 < \frac{1}{1+n^2 x} < \frac{1}{n^2 x } \leq \frac{1}{n^2 \delta } = \frac{1}{\delta} \frac{1}{n^2}, $$
  and the series $\sum \frac{1}{n^2} $ converges. So, by Theorem 7.10 in Rudin, our series converges uniformly on $[ \delta , +\infty)$. And, if $$x \in (- \infty, - \delta ]\setminus \left\{ \ -1, -\frac{1}{2^2}, -\frac{1}{3^2}, - \frac{1}{4^2}, \ldots \ \right\},$$
   then $x < 0$, and, for all large enough $n$, we also have $1 + n^2 x < 0$, and for those $n$, we have $$ \left\lvert \frac{1}{1+n^2 x} \right\rvert = \frac{1}{ \left\lvert 1+n^2 x \right\rvert} =  \frac{1}{ -1 - n^2 x} < \frac{ 1}{ \frac{n^2 x}{2} - n^2 x} = -\frac{2}{x} \frac{1}{n^2} = \frac{2}{\delta} \frac{1}{n^2}.      $$
  Here we have used the fact that, as $x < 0$, so as $n$ gets larger and larger, we eventually have  $1 + n^2 x < -1$, so $n^2 x < -2$, which implies that $\frac{n^2 x}{2} < -1$ and hence $\frac{n^2 x}{2} - n^2 x < -1 - n^2 x$; also from $1 + n^2 x < -1$, we obtain $1 < -1 - n^2 x$ and hence $0 < 1 < -1 - n^2 x$. And, we have also used the fact that, as $x \leq - \delta$, so $-x \geq \delta > 0$, and hence $$ 0 < -\frac{1}{x} \leq \frac{1}{\delta}.$$ As the series $\sum \frac{1}{n^2}$ converges, so it follows from Theorem 7.10 in Baby Rudin that our series converges uniformly on the following subset of $\mathbb{R}$: $$ (-\infty, -\delta ] \setminus \left\{ \ -1, -\frac{1}{2^2}, - \frac{1}{3^2}, - \frac{1}{4^2}, \ldots \ \right\}.$$ Is what I have done so far correct? If not, then where have I erred? What if $x \in (- \delta, \delta)$? And, what about the (uniform) convergence of this series for complex values of  $x$?","['real-analysis', 'uniform-convergence', 'sequences-and-series', 'convergence-divergence', 'analysis']"
2539532,Does there exist a closed form for the sinc function series $\sum_{n=1}^\infty \frac{\sin\sqrt{n^2+1}}{\sqrt{n^2+1}}$?,"Here I want to get the closed form solution of the following summation $$
\sum_{n=1}^\infty \frac{\sin\sqrt{n^2+1}}{\sqrt{n^2+1}} \qquad(1)
$$ Or the more general form ($x$ be an arbitrary real number, and $a\geq0$ is a constant): $$
f_a(x) = \sum_{n=1}^\infty \frac{\sin\left(x\sqrt{n^2+a^2}\right)}{\sqrt{n^2+a^2}}\qquad(2)
$$ I tried the numeircal simulations before I post the question. I truncated the first $1,000,000$ terms of equation (1) and it turned $0.781233190560320$. Anyone can help me? In fact, I made it the reduced case when $a=0$. It can be proved by Fourier series:
$$
f_0(x)=\sum_{n=1}^\infty \frac{\sin nx}{n} = \left\{ \matrix{\dfrac{\pi-x}{2}, 0<x<2\pi\\0, x=0,2\pi} \right. 
$$
And the function is periodical:
$$
f_0(x) = f_0(x+2\pi)
$$ Edit : How about this one?
$$
g_a(x) = \sum_{n=1}^\infty \frac{\cos\left(x\sqrt{n^2+a^2}\right)}{\sqrt{n^2+a^2}}\qquad(3)
$$ We get the ""diverging wave solution"" in physics when we combine the equation (2) and (3):
$$
h_a(x)=g_a(x)+\text{i}f_a(x)=\sum_{n=1}^\infty \frac{\exp\left(\text{i}x\sqrt{n^2+a^2}\right)}{\sqrt{n^2+a^2}}\qquad(4)
$$ Edit #2 :
I tested the solution solved by Random Variable (see the most ranked answer and thousands thanks to it!) compared with the truncating results: $$
\sum_{n=1}^N\frac{\sin \left(x\sqrt{n^2+a^2}\right)}{\sqrt{n^2+a^2}}, N = 1,000,000, a=1
$$ Here is the solution by @Random Variable :
the solution of equation (2) as the following: $$
\sum_{n={1}}^\infty \frac{\sin\left(x\sqrt{n^2+a^2}\right)}{\sqrt{n^2+a^2}} 
=
\frac{\pi}{2} J_0(ax) -\frac{\sin(ax)}{2a}, a>0, 0<x<2\pi\qquad(2*)
$$
  where $J_0(ax)$ is the Bessel function of the first kind of order zero. Here is the comparison: It can be found that the both agree well when $0 <x<2\pi$,but differ in other domain. So, how about the solution beyond $(0,2\pi)$? Edit #3 : Inspired by Random Variable 's answer, I found the solution of equation (3) as the following: $$
\sum_{n={1}}^\infty \frac{\cos\left(x\sqrt{n^2+a^2}\right)}{\sqrt{n^2+a^2}} 
=
-\frac{\pi}{2} Y_0(ax) -\frac{\cos(ax)}{2a}, a>0, 0<x<2\pi\qquad(3*)
$$
  where $Y_0(ax)$ is the Bessel function of the second kind of order zero. Here is the comparison: Note that equation (3) is divergent when $x=0$ . Possible relating QUESTIONS: Does there exist a closed form for the non-integer shifted sinc-function series: $\frac{\sin(n+a)x}{(n+a)x}$?","['sequences-and-series', 'closed-form']"
2539598,Show that the subset of strictly monotonic functions in $C(I)$ is nowhere dense,"Show that the subset of strictly monotonic functions in $C(I)$ is nowhere dense in $C(I)$ My idea is proving that the closure of the subset is the subset of weakly monotonous functions, and then it will be easy to prove that the interior of this subset is empty. It's the first part that I'm having trouble with. I can't seem to easily show that a weakly monotonous function has a strictly monotonous in each environment. I have a vague idea for showing that when the number of constant intervals is finite, but not in the general case. Also showing that every element of the closure is weakly monotonous seems hard. I don't know how to approach it.","['general-topology', 'functions']"
2539621,Does the Intersection of Images imply an Injective Function?,"I've read that $f(A \cap B) = f(A) \cap f(B)$ is true iff $f$ is an injective function' (and thus the statement is biconditional), and I've been trying to understand why this is true, but struggling. I understand from the proofs the implication that if $f$ is injective $\implies f(A \cap B) = f(A) \cap f(B)$ . But it's the reverse implication I'm struggling with, as I seem to be finding counter examples; where am I going wrong? Let $f$ be a function s.t. $f(A \cap B) = f(A) \cap f(B)$ . Clearly, if $x\in (A \cap B)\implies f(x) \in  ( f(A) \cap f(B) )$ . But for some functions, couldn't there also be a set $C \neq (A \cup B)$ such that $f(C) = f(A) \cap f(B)$ ? And hence, $f$ would be a many-one function, despite $f(A \cap B) = f(A) \cap f(B)$ ? Example: Consider the domain $D = \{1, 2, 3, 4, 5, 6, 7\}$ and the codomain $E = \{a, b\}$ and a function $f$ that maps $D$ to $E$ s.t. odd numbers in $D$ map to a and even numbers map to b. Now, let the sets $A$ , $B$ , $C$ $\subset$ $D$ equal $\{1, 2\}$ and $\{1, 2, 3\}$ and $\{5, 6\}$ respectively. Then, $(A \cap B) = \{1, 2\}$ and $f(A) \cap f(B) = \{a, b\} = f(A \cap B)$ . But clearly now, $f(C) = \{a, b\} = f(A) \cap f(B)$ - the equality holds, but $f$ is many-one, not injective. I must be wrong in my logic somewhere/not understood some basic facts about sets and their equality, but can't see what? Any thoughts? Thanks very much, indeed.","['elementary-set-theory', 'functions']"
2539622,How many $6$-sided and $8$-sided standard dice exist? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question Standard means that the sum of the opposite sides is $7$ for $6$-sided die and $9$ for $8$-sided die.","['combinations', 'platonic-solids', 'dice', 'permutations', 'combinatorics']"
2539632,Applying the chain rule to a function mapping matrices to matrices,"Given a function $F:\text{Mat}(n,n)\rightarrow\text{Mat}(n,n)$, I'd like to get $\frac{d}{dM_{ij}}F(M)^2$ using matrix calculus. I already derived it by simply writing it out explicitly for my choice of $F$, but this doesn't seem to generalize well if I want to take second derivatives of higher powers of $F(M)$ so I wanted to finally get my head around matrix calculus. To get it in matrix notation I noted that $$\frac{d}{dM_{ij}}F(M)^2 = \left(\frac{d}{dM} F(M)^2\right)[e^{ij}]$$ for $e^{ij}\in\text{Mat}(n,n)$ such that $(e^{ij})_{xy} = \delta_{i=x}\delta_{j=y}$. Now if $F$ were the identity, then I'd get $Me^{ij}+e^{ij}M$ (or more generally $\sum_{l=0}^{p-1}M^le^{ij}M^{p-l-1}$ for $F(M)^p$ instead of $F(M)^2$). Using the chain rule, would I get $$\left(F(M)e^{ij}+e^{ij}F(M)\right)\left(\frac{d}{dM}F(M)[e^{ij}]\right) ?$$ Optional information : It seems weird since I multiply(/pass as an argument) with $e^{ij}$ twice, which doesn't really make a lot of sense in the scalar case (e.g. $n=1$), but I don't know how to make use of the $(\frac{d}{dX} X^2)[Y]=XY+YX$ otherwise for symmetric $M$ and my choice of $F$ (which maps positive $M$ to positive $F(M)$) the trace of this object coincides with my direct computation (not sure if that's just a coincidence caused by some of the involved symmetries though). What I looked up so far: Most of the notes I could find online only dealt with scalar valued functions of matrices or vectors. http://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf (p15, eq 136) seems to be one exception, but they go back to pretty direct computations which is basically what I did so far.
Instead I was thinking about getting something along the lines of Matrix chain rule question: what is $\frac{d}{dX} f(S)$ where $S = (A+X)^{-1}$ (just set $f=(F(M)^2)_{xy}$), but this doesn't seem to work if I don't know how to invert $F$.","['matrices', 'chain-rule', 'matrix-calculus']"
2539668,Are all connected and locally integral affine schemes globally integral?,"In these notes, on p. 2 Section 4, Kedlaya claims an affine scheme is integral if and only if it is connected and every local ring is an integral domain. But elsewhere I have seen that this requires a Noetherian condition on the affine scheme, e.g. problem 19 here , problem 56D in this . What is wrong with Kedlaya's proof? Or is the result actually true without assuming Noetherian?","['noetherian', 'algebraic-geometry', 'schemes', 'affine-schemes', 'commutative-algebra']"
2539678,Prove that $\lim\limits_{x\to\infty}\frac1x=0$,"So I had to explain to someone about limits and I got asked: how do you prove that $\lim\limits_{x\to\infty}\frac1x=0$ without intuition. After a while I answered: Let's construct a sequence $(a_n)$ where $a_n=\frac1n$(the sequence starts from $n=1$) now, $\left[\frac1x\right]'=-\frac1{x^2}$ thus $a_n>a_{n+1}$. Now let's assume that there is a value, say $k$, such that $a_n>k>0,\forall n\in\Bbb Z^+$. If $k$ is a rational number then $k=\frac qp\ge\frac1p=a_p>a_{p+1}$ which is contradiction If $k$ is irrational then: $k=\cdots +b_2+b_1+b_0+b_{-1}+b_{-2}+\cdots$ where $b_i=c\times 10^i, c\in\{0,1,2,3,4,5,6,7,8,9\}$. Now I can construct a number $k'=\max\{\,b_i\ne0\}$. $k'$ is rational, hence $k>k'=\frac qp\ge\frac1p=a_p>a_{p+1}$ which is contradiction. This implies that there is no $k$ such that $a_n>k>0,\forall n\in\Bbb Z^+$ which implies that $\inf\{a_n\}=0$ and because $a_n>a_{n+1}$ I also know that  $\inf\{a_n\}=\lim\limits_{x\to\infty}\frac1x$ hence $\lim\limits_{x\to\infty}\frac1x=0$. My question is, is my proof okay? I don't think that I have any problems but I am not completely sure. And if yes. Is there a easier way to prove that for any positive irrational number there is always smaller positive rational number?","['proof-verification', 'calculus', 'limits']"
2539699,$\int \frac{x^2+4x+4}{(x^2+5x+7)\sqrt{x+2} } dx$,The question is to evaluate $$\int \frac{x^2+4x+4}{(x^2+5x+7)\sqrt{x+2} } dx$$ I tried rewriting the integral as $$\int \frac{dx}{\sqrt{x+2}} - \int\frac{x+3}{(x^2+5x+7)\sqrt{x+2}} dx$$ the first integral is simply $2\sqrt{x+2}$.I tried using Integration by parts on second integral but it got complicated.Any ideas?,"['integration', 'calculus']"
2539742,Rank of upper triangular block with Identity matrix,"Quick question I was hoping I could get some insight on. If I have a block matrix of the following form $$A = \begin{pmatrix} I & A_{12} \\
0 & A_{22} \end{pmatrix}$$ Where $A_{12}, A_{22}$ are arbitrary block matrices that need not be square (in fact in my case they are not square). Is it correct to say that $$\text{rank} A = \text{rank}I + \text{rank}A_{22}$$ Because the identity matrix ensures that $A$ has the rank of $I$ and then the rank of $A$ should be determined by the rank of $A_{22}$, no?","['matrices', 'matrix-rank', 'linear-algebra']"
2539767,Is this proof of indepencence of two events circular?,"Task (I freely admit it is from a former test): We choose a random person $X$ and it turns out that this person has three siblings, with at least one older sister among them. A) What is the probability that $X$ is a girl? B) What is the probability that the second oldest child of this familily is a girl? C) What is the probability that $X$ is the youngest child of this family? D) Let $A$, $B$, $C$ denote the above events. Which pairs are independent: $(A, B)$, $(A, C)$, $(B, C)$? Validate each answer. Note: Assume that, regarding each birth, the events: a boy is born and a girl is born have the same probability $p=\frac12$ (we do not take into account the possibility of twins being born, etc), and these events are independent from any former births. My solution attempt: A) $\frac12$, from the independence of birhts. Before we go to B), C), D), let's list all legal combinations: If $X$ is the second oldest kid: $b/g\quad b/g\quad X_{b/g}\quad g$ - this gives $8$ combinations If $X$ is the third oldest kid: $b/g \quad X_{b/g}\quad b/g \quad b/g$ - this would be $4\cdot 4$ combinations, but we must exclude the illegal combination that two oldest kids are all boys, so it's $4\cdot 3 = 12$ combinations If $X$ is the youngest kid: $X_{b/g} \quad b/g \quad b/g \quad b/g$ - Excluding the illegal combination that all older kids are all boys this gives us $2\cdot7=14$ combinations So we have a total of $34$ legal combinations. B) Let's list legal combinations: $b/g\quad b/g\quad X_g \quad g$ - $4$ combinations $b/g \quad X_{b/g} \quad g \quad b/g$ - $8$ combinations $X_{b/g} \quad b/g \quad g \quad b/g$ - $8$ combinations Thus the probability is $\frac{4+8+8}{34}=\frac{10}{17}$ C) Above we showed that there are $14$ legal combinations in such a case, so the answer is $\frac{14}{34}=\frac{7}{17}$ D) And here be dragons, I guess. This is how I'd tackle this: $(A, B)$: All legal combinations for the event $A\cap B$ are: $b/g\quad b/g \quad X_g \quad g$ - $4$ combinations $b/g \quad X_g \quad g \quad b/g$ - $4$ combinations $X_g\quad b/g\quad g\quad b/g$ - $4$ combinations $12$ combinations total, so $P(A\cap B) = \frac {12}{34} \neq \frac12\cdot \frac{20}{34} = P(A)\cdot P(B)$, so by definition $A$ and $B$ are not independent. $(A,C)$: There are $7$ legal combinations for the event $A\cap C$: $X_g\quad b/g \quad b/g \quad b/g$, this would be $8$ but we must exclude the illegal combination $X_g \quad b \quad b \quad b$ Therefore $P(A\cap C) = \frac7{34} = \frac12 \cdot \frac {14}{34} = P(A)\cdot P(B)$, so by definition these events are independent $(B, C)$: THere are $8$ legal combinations: $X_{b/g} \quad b/g \quad g \quad b/g$ So we have $P(B\cap C) = \frac8{34} = \frac 4{17}$
But $P(B)\cdot P(C) = \frac7{17}\cdot \frac{10}{17} \neq \frac 4{17}$ So by definition these events are not independent. My worry is: I used the classical definition of probability for each part of the task. But I can only use the classical definition if the permutation of children in this famility is independent of their sex; so, essentialy, I can only use the classical definition if $(A, C)$ are independent. However, it was my task to prove that $A$ and $C$ are really independent, and I used the classical definition to prove it... So, in the end, am I not guilty of circular reasoning here?","['probability', 'proof-verification']"
2539799,Computing the second Chern character on Kähler manifold,"Let $(X, \omega)$  be a compact Kähler manifold and $E$ a vector bundle on $X$ with hermitian metric $h$. Let also $F_h$ be the curvature of Chern connection on $(E, h)$. It is a $(1,1)$-form with coefficients in $\operatorname{End}(E)$. In Simpson's paper ""Higgs bundles and local systems"" the following formula plays important role:
$$
\int_X \operatorname{Tr}(F_h \wedge F_h) \wedge \omega^{n-2} = C_1||F_h||_{L^2} - C_2||\Lambda F_h||_{L^2}
$$
for certain constants $C_1$ and $C_2$ (here $\Lambda$, as usual, is the hermitian-adjoint to the Lefschetz operator $L \colon \eta \mapsto \omega \wedge \eta$) Indeed in Simpson's paper this equation is used not for a curvature of a unitary connection, but for a pseudocurvature of a hermitian metric on vector bundle endowed with flat connection . However, I believe it is not really important and the proves must be similar. It seems that this relation holds in a general situation and follows from some standard Hodge theory. Although I don't understand how to prove it. Simpson claims that this fact follows from ""Riemann bilinear relations"", but I don't understand what he really means.","['riemannian-geometry', 'complex-geometry', 'kahler-manifolds', 'hodge-theory', 'differential-geometry']"
2539803,Determinant of a matrix with integer power entries,"Define $$D(n,k)=\begin{vmatrix} 1^k & 2^k&\cdots& n^k\\2^k&3^k&\cdots &(n+1)^k\\ \vdots&\vdots&\ddots&\vdots\\ n^k&(n+1)^k&\cdots&(2n-1)^k 
\end{vmatrix}.$$ I'm asking: Calculate $D(1,1), D(2,1), D(3,1), D(4,1)$. Show that $D(n,2)=0$ for $n>3$. Show that $D(n,k)=0$ for $n>k+1$ First one is not difficult. I thought that maybe this calculation could help me to attack the second and third question. Is not the case. For $n=4$ one can verify that this determinant is truly zero by making zeros on the first row an then calculating a $3\times 3$ determinant. However, it doesn't help for found a generalized method for demonstrate the assertion. It's pretty clear (I think) that induction is the ideal method but I'm not sure on how to proceed. I try to use the fact that the matrix is symmetric, but again without success. Thanks in advance!","['matrices', 'linear-algebra', 'determinant']"
2539855,"Find a bijection from $[0,1]$ to $[0,1]$ that is not strictly monotone. is this possible?","I'm not convinced this is possible, as soon as you have $2$ distinct elements mapping to the same number, the function is no longer $1$-$1$ and therefore not a bijection.",['analysis']
2539866,Geometric/trigonometric origin of a surprising algebraic identity?,"Let $f(x,y,z)=(x+y+z-1)^2-4xyz$. One can verify by inspection that for all $x,y,z$ $$f(x^2,y^2,z^2)=16 f\left(\frac{1+x}{2},\frac{1+y}{2},\frac{1+z}{2}\right)\cdot f\left(\frac{1-x}{2},\frac{1-y}{2},\frac{1-z}{2}\right).$$ I came to the above in the process of playing around with the formula $$\cos^2 t+\cos^2u+\cos^2v =1+2\cos t\cos u\cos v,$$ valid when $u+v+t=0$. (This in turn is a special case of the identity discussed in another recent question of mine.) This relation implies that $f(\cos^2 t,\cos^2 u,\cos^2v)=0$ when $u+v+t=0$. To connect this further with the desirerd relation, if we substitute $(x,y,z)=(\cos 2t,\cos 2u,\cos 2v)$, then the identity of interest may be shown to take the form
$$f(\cos^2 2t,\cos^2 2u,\cos^2 2v)=16f(\cos^2 t,\cos^2 u,\cos^2 v)f(\sin^2 t,\sin^2 u,\sin^2 v).$$
From this we see that if $t+u+v=0$ iff $2t+2u+2v=0$ as well and therefore $f(\cos^2 t,\cos^2 u,\cos^2 v)=0$ iff $f(\cos^2 2t,\cos^2 2u,\cos^2 2v)=0$. This verifies the desired identity in the case corresponding to $u+v+t=0$. What I want to know: Is there a geometric/trigonometric account of the general result?","['algebra-precalculus', 'trigonometry', 'alternative-proof', 'geometry']"
2539884,Show that there exists a non-constant periodic trajectory for the system of ODEs,I am having a hard time finding information online about how to show that there exists a non-constant periodic trajectory for the system of ODEs. For example if the system is $$x'=1-4x+x^2y$$ $$y'=3x-x^2y$$ Does anyone know where I can read about this type of problem or what steps to take to find the trajectories? Thanks.,['ordinary-differential-equations']
2539902,Solve over integers $\frac{xy}{z} + \frac{yz}{x} + \frac{zx}{y} = 3$,"I am trying to solve $\frac{xy}{z} + \frac{yz}{x} + \frac{zx}{y} = 3$ over integers, but I have no idea what's the best way to do it. I have tried multiplying both sides by $xyz$ and then figuring out that $z$ divides $xy$, $x$ divides $yz$, etc, but with no effect.","['diophantine-equations', 'inequality', 'polynomials', 'number-theory', 'elementary-number-theory']"
2539925,Where to find a proof of the Julia-Fatou theorem for the connectedness of Julia sets?,"There's a theorem that if all the orbits of the critical points of a complex polynomial map are bounded, the corresponding Julia set is connected. Also, if all the critical orbits escape to infinity, the Julia set is a cantor set. Where can I find a proof of this theorem? I have tried to find it but I cannot.","['complex-analysis', 'complex-dynamics']"
2539942,Proof of the unbounded-ness of $\sum_{n\geq 1}\frac{1}{n}\sin\frac{x}{n}$,"For any $x\in\mathbb{R}$, the series
$$ \sum_{n\geq 1}\tfrac{1}{n}\,\sin\left(\tfrac{x}{n}\right) $$
is trivially absolutely convergent. It defines a function $f(x)$ and I would like to show that $f(x)$ is unbounded over $\mathbb{R}$ . Here there are my thoughts/attempts: $$(\mathcal{L} f)(s) = \sum_{n\geq 1}\frac{1}{1+n^2 s^2} = \frac{-s+\pi\coth\frac{\pi}{s}}{2s}=\sum_{m\geq 1}\frac{(-1)^{m+1}\,\zeta(2m)}{s^{2m}}$$
is a function with no secrets. It behaves like $\frac{\pi}{2s}$ in a right neighbourhood of the origin, like $\frac{\pi^2}{6s^2}$ in a left neighbourhood of $+\infty$. The origin is an essential singularity and there are simple poles at each $s$ of the form $\pm\frac{i}{m}$ with $m\in\mathbb{N}^+$. These facts do not seem to rule out the possibility that $f$ is bounded; For any $N\in\mathbb{N}^+$ there clearly is some $x\ll e^N$ such that $\sin(x),\sin\left(\frac{x}{2}\right),\ldots,\sin\left(\frac{x}{N}\right)$ are all positive and large enough, making a partial sum of $ \sum_{n\geq 1}\tfrac{1}{n}\,\sin\left(\tfrac{x}{n}\right) $ pretty close to $C\log N$. On the other hand I do not see an effective way for controlling  $ \sum_{n>N}\tfrac{1}{n}\,\sin\left(\tfrac{x}{n}\right) $ - maybe by summation by parts, by exploiting the bounded-ness of the sine integral function? Some probabilistic argument might be effective. For any $n\geq 3$ we may define $E_n$ as the set of $x\in\mathbb{R}^+$ such that $\sin\left(\frac{x}{n}\right)\geq \frac{1}{\log n}$. The density of any $E_n$ in $\mathbb{R}^+$ is close to $\frac{1}{2}$, so by a Borel-Cantellish argument it looks reasonable that the set of points such that $|f(x)|\geq \frac{\log x}{100}$ is unbounded, but how to make it really rigorous? To compute $\lim_{x\to x_0}f(x)$ through convolutions with approximate identities seems doable but not really appealing.","['inequality', 'fourier-analysis', 'laplace-transform', 'trigonometry', 'sequences-and-series']"
2539960,The elliptic regularity theorem for differential operators with variable coefficients,"I'm following the book ""Introduction to the theory of distributions"" by Friedlander and Joshi. There is the following result p. 109 $Theorem (8.6.1)$. Let $X \subset \mathbb{R}^n$ be an open set, and let $P$ be an elliptic operator with constant coefficients. Then $$\mathrm{singsupp}(u)=\mathrm{singsupp}(Pu)$$ As an observation after the demonstration says: ""This principle, applied to Schwartz kernels and backed by an apropriate construction, gives the elliptic regularity theorem for differential operators with variable coefficients."" Would you give me references for this more general case? Is necessary the theory of pseudo-differential operators? Thank you for any reply.","['partial-differential-equations', 'reference-request', 'regularity-theory-of-pdes', 'distribution-theory', 'functional-analysis']"
2539976,Prove that:$f(f(x)) = x^2 \implies \int_{0}^{1}{(f(x))^2dx} \geq \frac{3}{13}$,"Let $f: [0,\infty) \to [0,\infty)$ be a continuous function such that $f(f(x)) = x^2, \forall x \in [0,\infty)$. Prove that $\displaystyle{\int_{0}^{1}{(f(x))^2dx} \geq \frac{3}{13}}$. All I know about this function is that $f$ is bijective, it is strictly increasing*, $f(0) = 0, f(1) = 1, f(x^2) = (f(x))^2, \forall x \in [0, \infty)$ and $f(x) \leq x, \forall x \in [0, 1]$**. With all these, I am not able to show that  $\displaystyle{\int_{0}^{1}{(f(x))^2dx} \geq \frac{3}{13}}$. *Suppose that $f$ is strictly decreasing. Then, $\forall x \in (0,1), x^2 < x \implies f(x^2) > f(x) \iff (f(x))^2 > f(x) \iff f(x) > 1$, which is false because, if we substitute $x$ with $0$ and with $1$ in $f(x^2) = (f(x))^2$ we get that $f(0) \in \{0,1\}$ and $f(1) \in \{0,1\}$. So $f$ is strictly increasing. **Suppose that there exists $x_0 \in [0, 1]$ such that $f(x_0) > x_0$. Then, $x_0^2 = f(f(x_0)) > f(x_0) > x_0$, which is false. Then $f(x) \leq x, \forall x \in [0,1]$. Edit: I have come up with an idea to use Riemann sums, but I reach a point where I cannot continue. Let $\epsilon < 1$. Then $f(\epsilon) = x_1$ and $f(x_1) = \epsilon^2$. And now $(f(\epsilon))^2 = f(\epsilon^2) = x_2$ and so on. Now we will use the Riemann sum: We will take the partition $\Delta = (1 > \epsilon > \epsilon ^2 > ... \epsilon ^{2^n} >0 ) $and the intermediate points will be the left margin of each interval. Then we have: $\displaystyle{\int_{0}^{1}{(f(x))^2 dx}}  = \displaystyle{ \lim_{\epsilon \to 1}{\lim_{n \to \infty}{\sum_{k = 0}^{n}{(\epsilon^{2^k} - \epsilon^{2^{k+1}})\epsilon^{2^{k+1}}}}}}$ I do not know how to compute this.","['real-analysis', 'inequality', 'definite-integrals', 'integral-inequality']"
2539980,"If graph of $f(x) \cdot f'(x)$ is given, answer the following","If $f(x)$ is a continuous and differentiable function. Given that $f(x)$ takes values of the type $\pm \sqrt{W}$ for $x=a$ and $x=b$ (where $W$ denotes set of whole numbers). For all other $x$, $f(x)$ can take any real value. Also $f(c)=-\frac{3}{2}$ and $|f(a)| \leq |f(b)|$ and graph of $f(x) \cdot f'(x)$ is given below: Answer the following questions: Ques: Find number of rational values $f(a)+f(b)+f(c)$ can take? Ques: Find number of values $(f(a))^2+(f(b))^2+(f(c))^2$ can take? It is clear from given data that $f'(c)=0$ . I thought of taking  $g(x)=(f(x))^2/2$ Hence from given graph, $g(x)$ increases from $x=a$ to $x=c$ and then decreases Also $g(c)=9/8$ but I am not able to proceed from here. Could someone please help me in this?","['derivatives', 'calculus']"
2539983,Integrate Product of Matrix Exponentials,"I'm trying to compute $$I(t) = \int_0^t e^{ A \tau} e^{A^T \tau} \ d \tau $$ where $A$ is a real matrix, and $A^T$ its transpose. I know that if $A$ was symmetric and $B = A + A^T$  nonsingular, I could use 
the rule for the Integral of matrix exponential and the result would be $$ I(t) = B^{-1} \left( e^{t B } - I \right) $$ What if $A$ is not symmetric, though?","['matrix-equations', 'matrix-calculus', 'multivariable-calculus', 'definite-integrals', 'matrix-exponential']"
2540018,"If two graphs are subgraphs of each other, are they isomorphic?","I was curious to know whether, when two graphs are subgraphs of each other, they are isomorphic. Is there a proof for this? I was using the idea from set theory that if two sets are subsets of each other, then they are equal. Thanks","['graph-theory', 'discrete-mathematics']"
2540041,$\sin3x-\sin2x-\sin x=0$,"I have issue solving this equation.
So I wrote $$\sin3x= 3\sin x-4\sin^3x$$ and $$\sin2x = 2\sin x\cos x$$
So we have $$3\sin x-4\sin^3x-(2\sin x\cos x)-\sin x = 0$$
But now I have $$\sin x$$ and $$\cos x$$ as unknown, and I don't know how to finish this.",['trigonometry']
2540042,$\lim _{n\to \infty }\left[\sum _{k=1}^{n-1}\left(1+\frac{k}{n}\right)\sin \left(\frac{k\pi }{n^2}\right)\right]$,"I have to calculate this limit using Riemann sums:
$$\lim _{n\to \infty }\left[\left(1+\frac{1}{n}\right)\sin \left(\frac{\pi }{n^2}\right)+\left(1+\frac{2}{n}\right)\sin \:\left(\frac{2\pi \:}{n^2}\right)+...+\left(1+\frac{n-1}{n}\right)\sin \:\left(\frac{\left(n-1\right)\pi \:}{n^2}\right)\right]$$
and
$$\lim _{n\to \infty }\left[\sum _{k=1}^{n-1}\left(1+\frac{k}{n}\right)\sin \left(\frac{k\pi }{n^2}\right)\right]$$ I've done quite a few of this type of limits, but I haven't yet figured out what function $f$ to use with the Riemann sum for this particular one. Could I have some hints on how to find that function? Thank you.","['definite-integrals', 'calculus', 'limits']"
2540063,"Without using a calculator and logarithm, which of $100^{101} , 101^{100}$ is greater?","Which of the following numbers is greater? Without using a calculator and logarithm. $$100^{101} , 101^{100}$$ My try :  $$100=10^2\\101=(100+1)=(10^2+1)$$ So  : $$100^{101}=10^{2(101)}\\101^{100}=(10^2+1)^{100}=10^{2(100)}+N$$ Now what ?","['inequality', 'number-comparison', 'algebra-precalculus', 'upper-lower-bounds', 'approximation']"
2540082,Intersection of the Union of Infinite Sets,"So, I'm trying to make sense of this question: ""Suppose we have an $A_n$ for each n $\in$ N (i.e. the Naturals). Fill in the blanks with two words to get a true statement. Justify your answer. x $\in$ $\bigcap_{k=1}^{infinity}\bigcup_{n=k}^{infinity}$ $A_n$ iff x $\in$ $A_n$ for [ blank ] [ blank ] n $\in$ N "" I'm very new unfortunately to set theory and families of sets so I'm very stuck, but here's what I've got so far: When k=1, $\bigcup_{n=1}^{infinity}A_n$ = {1,2,3...} When k=2, $\bigcup_{n=2}^{infinity}A_n$ = {2,3,4...} So on, so forth. Hence the total function is $\bigcap_{k=1}^{infinity}$ { {1,2,3...}, {2,3,4...}, {3,4,5...},....} Let { {1,2,3...}, {2,3,4...}, {3,4,5...},....} = I This is where I become unsure: I don't know much about infinity, but it seems like this total intersection of I has no fixed list of elements? The intersection of the first element to the n'th is the n'th element. But I has an infinite number of sets as its elements, so the intersection of all its elements is its infinite'th element. And the infinite'th element of I itself has an infinite number of elements. Hence, $\bigcap_{k=1}^{infinity}$ { {1,2,3...}, {2,3,4...}, {3,4,5...},....} = { $\infty$, $\infty$+1, $\infty$+2,$\infty$+3...., $\infty$} I'm new to this type of maths, but I know that $\infty$ isn't a number, so I doubt I've understood at all what the $\bigcap_{k=1}^{infinity} I$ equals? Let alone how to advance from this understanding to answering the question. My only idea goes as follows: instead of thinking about $\bigcap_{k=1}^{infinity} I$ in total, and then thinking about an element from that completed intersection, you can only consider individual elements from the intersection as you 'calculate' it whilst iterating through k? Hence, as you iterate through k=1 to k=infinity, x $\in$ $\bigcap_{k=1}^{infinity}\bigcup_{n=k}^{infinity}$ $A_n$ iff x $\in$ $A_n$ for x > n $\in$ N Apologies for likely explaining this poorly. Has anyone got any insight on the solution, and how to understand the concept of the question? Many thanks, indeed.","['real-analysis', 'elementary-set-theory']"
2540087,Pattern in Isomorphisms between $\mathbb Z_m \times \mathbb Z_n$ and $\mathbb Z_{mn}$,"In general, the group $\mathbb Z_{mn}$ under addition $\bmod mn$ is isomorphic to the direct product $\mathbb Z_m \times \mathbb Z_n$ if and only if $\gcd(m,n)=1.$ This is easy to see since $\mathbb Z_{mn}$ is generated by the element $(1,1)$, and if $\gcd(m,n)=1$, then this will only be zero if it is multiplied by itself $mn$ times (resulting in the cyclic group). However I'm interested in constructing an isomorphism between the two groups as an explicit expression. I've been playing around a bit with some examples, one of which is the function $\phi : \mathbb Z_2 \times \mathbb Z_3 \to \mathbb Z_6$ where $\phi(a,b) = 3a + 4b \pmod 6$, which gives us the desired isomorphism. I'm interested here in the relationship between the integers $2$, $3$, and the coefficients $3, 4$ of $a$ and $b$. After playing around in Wolfram|Mathematica, I managed to obtain the following isomorphisms $\phi_{m,n} : \mathbb Z_m \times \mathbb Z_n \to \mathbb Z_{mn}$ for coprime $m,n$ in $\{1, 2, \dots, 10\}$. First of all, the following results seem to hold in general. $$\phi_{1, n}(a, b) = a + b \qquad \text{for all $n$}$$ 
$$\phi_{m, 1}(a, b) = a + b \qquad \text{for all $m$}$$ 
$$\phi_{2, n}(a, b) = na + (n + 1)b \qquad \text{for all $n$}$$
$$\phi_{m, n}(a, b) = K a + L b \iff \phi_{n,m}(a, b) = L a + K b \qquad \text{for all $m, n$}$$ Beyond this point, I could not spot a general pattern. The isomorphisms I obtained are: $$\phi_{3, 4}(a, b) = 4a + 9b$$
$$\phi_{3, 5}(a, b) = 10a + 6b$$
$$\phi_{3, 7}(a, b) = 7a + 15b$$
$$\phi_{3, 8}(a, b) = 16a + 9b$$
$$\phi_{3, 10}(a, b) = 10a + 21b$$
$$\phi_{4, 5}(a, b) = 5a + 16b$$
$$\phi_{4, 7}(a, b) = 21a + 8b$$
$$\phi_{4, 9}(a, b) = 9a + 28b$$
$$\phi_{5, 6}(a, b) = 6a + 25b$$
$$\phi_{5, 7}(a, b) = 21a + 15b$$
$$\phi_{5, 8}(a, b) = 16a + 25b$$
$$\phi_{5, 9}(a, b) = 36a + 10b$$
$$\phi_{6, 7}(a, b) = 7a + 36b$$
$$\phi_{7, 8}(a, b) = 8a + 49b$$
$$\phi_{7, 9}(a, b) = 36a + 28b$$
$$\phi_{7, 10}(a, b) = 50a + 21b$$
$$\phi_{8, 9}(a, b) = 9a + 64b$$
$$\phi_{9, 10}(a, b) = 10a + 81b$$
If you want to try and generate a few yourself, here is the Mathematica function I implemented. I'm sure it can be optimised, but for the first 10 coprime integers it sufficed. isomorphism[{m_, n_}] := 
     Module[{x = Null}, 
     For[i = 1, i < m*n, 
         i++, (If[#[[2]] == Table[i, {i, 0, m*n - 1}], 
         x = ToString[#[[1]][[1]]] <> ""a+"" <> ToString[#[[1]][[2]]] <> 
        ""b""; Break[]] &) /@ 
     Table[{{i, j}, 
     Mod[i #[[1]] + j #[[2]], m*n] & /@ 
     Table[{Mod[i, m], Mod[i, n]}, {i, 0, m*n - 1}]}, {i, 1, 
    m*n}, {j, 1, m*n}][[i]]]; x]; I'd appreciate if anyone can help me find the pattern to determine $\phi_{m, n}$ in general.","['direct-product', 'prime-numbers', 'group-theory']"
2540099,What is the 1000th decimal of the square root of 1998 ones?,"I'm new to this, forgive my formatting. The task Find the $1000$ th decimal of $\sqrt{11...11}$ , where there are $1998$ $1$ s. Proof I tried a smaller amount of $1$ s: $\sqrt{11} = 3.3166247903... =: \sqrt{a_1}$ $\sqrt{1111} = 33.3316666249... =: \sqrt{a_2}$ $\sqrt{111111} = 333.3331666666... =: \sqrt{a_3}$ There's a pattern, for an even amount of $1$ s. For $n$ $1$ s, there will be $\frac{n}{2}  3$ s before the decimal point and $\frac{n}{2}  3$ s after it. Therefore when there are $1998$ $1$ s, there will be: $999$ $3$ s . $999$ $3$ s $1$ . In other words: $33...33.33....331$ Where the $1$ is the $1000$ th decimal. [ EDIT ] Forgot to mention that $i = \frac{n}{2}$ . So we will get $1998$ $ 1$ s if $i=999$ . Looking at the numbers that come after the chain of $3$ s . I would want to prove that it will always be one. $a_i = \sum_{k=0}^{2i-1} 10^k$ where $i\in\Bbb{N^+}$ $\sqrt{a_1}-3.3=0.0166247903...$ $\sqrt{a_2}-33.33=0.0016666249...$ $\sqrt{a_3}-333.333=0.0001666666...$ To formulate this $\sqrt{a_i} - \frac{3a_i}{10^i}$ Get the first number to the left of the decimal point, by multiplying it with $10$ s. $\biggl(\sqrt{a_i} - \frac{3a_i}{10^i}\biggl)10^{i+1}=: b_i$ $b_1=1.66247903..., b_2=1.6666249..., b_3=1.666666...,$ etc. To prove that $1<b_i<2$ , in other words, show that the series $b_i$ isn't decreasing. For $<2:$ $\lim_{i\to \infty}b_i=\lim_{i\to \infty}\biggl(\sqrt{a_i} - \frac{3a_i}{10^i}\biggl)10^{i+1}=\frac{5}{3}=1.6666666666666666666666....$ The limit was calculated by Maple 2015. The limit being $1.66666...$ means that $b_i$ will be getting closer to that value. This proves the $<2$ part. Missing What I think I'm missing is proving that $b_i$ isn't decreasing. Just because $b_1$ starts at $1.6624...$ and eventually $b_i$ will end up close to $1.666666666666...$ doesn't mean that it hasn't decreased somewhere along the way. I tried showing that $b_i<b_{i+1}$ but got stuck at: $\sqrt{a_i}<10\sqrt{a_{i+1}} -3 \cdot 10^i \cdot 11$ Maple is giving me a FAIL on the verify and evalb functions, which means that I don't know how to use Maple properly. Maybe the fact that $a_i$ is rising can help somehow? [ EDIT ] I may found a way, it's not nice. We know that the first couple of values of $b_i$ are increasing, therefore I tried to show that $b_i$ is not increasing by finding the derivative of the function $b_i$ (thank you Maple). Then having the derivative be equaled to zero, there is no such case, therefore there are no critical points, so the sequence doesn't change between increasing or decreasing, and since the first few values of $b_i$ were increasing, the entire sequence cannot be decreasing, making it non-decreasing. Is this proof rock solid in general, or are there still some gaps to improve upon?","['discrete-mathematics', 'sequences-and-series', 'proof-verification', 'limits']"
2540136,If $X$ is connected then there're not $F$ and $G$ such that $F\cap G=\emptyset$ and $X=F\cup G$,"Theorem: Let $(X,\tau)$ be a topological space. If there is no nonempty closed subsets $F$ and $G$ in $X$ such that $F\cap G=\emptyset$ and $X=F\cup G,$ then $X$ is connected. Proof Let's suppose X is no connected and let's see that there exist nonempty closed subsets $F$ and $G$ in $X$ such that $F\cap G=\emptyset$ and $X=F\cup G$ . As X is no connected, there exists open sets $U,V\in\tau$ such that $U\cap V=\emptyset$ , $X=U\cup V$ and both are nonempty sets...(1) Notice that $U^c=V,V^c=U.$ Therefore $U$ and $V$ are closed. And by (1) the proof is done. I did this proof and I don't know if it's correct.
Could you check it and tell me please?","['general-topology', 'connectedness', 'elementary-set-theory', 'proof-verification']"
2540195,Finding a limit converging into $\ln(x)$,"As we know, $\int\dfrac{1}{x}dx = \ln (x) + c$ Also, $\int x^a dx = \dfrac{x^{a+1}}{a+1} + c$ for any $a \neq -1$ But since $x^{-1} = \dfrac{1}{x}$, I suspected that $\ln x = \int\dfrac{1}{x}dx = \int x^{-1} dx = \lim_{a\to -1} \dfrac{x^{a+1}}{a+1}$ However this is false but I then realised this is pretty close from the real equality $\ln x = \lim_{a\to 0} \dfrac{x^a - 1}{a}$ But I don't manage to understand where does this $-1$ come from.
I know what I did was everything but rigourous, but is there a way to get this equality with a similar method to what I've done? Thank you for reading!","['logarithms', 'integration', 'limits']"
2540224,Find a primitive root of $71$.,"In my Number Theory Class we found that $7$ was a primitive root of 41 by first finding two integers who have order $5$ and $8$  $modulo 41$ respectively, these being $16$ and $3$. Since $16(3)=7(mod41)$ 7 is a primitive root. I'm trying to do this for $71$ and so far have that $5$ has order $5(mod71)$. I'm struggling to find integers whose order $modulo71$ are $2$ and $7$.","['number-theory', 'primitive-roots']"
2540276,Help with $ \lim\limits_{t \to 0} \int_{-1}^1 \frac{t}{t^2+x^2} f(x)\ dx$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question Show that if $f$ is continuous on $[-1,1]$, then
$$
\lim_{t \to 0} \int_{-1}^{1}\frac{t}{t^2+x^2}f(x)\,dx=\pi f(0)
$$
Any hints?",['real-analysis']
2540283,Proof of Miquel's six circle theorem,"Theorem Miquel's six circle theorem states that if in the following all cocircularities except the last one are satisfied, then the last one is implied. In words: if $ABCD$ lie on a circle, and $ABYZ,BCXY,CDWX,DAZW$ likewise, then $XYZW$ lie on a circle (or a line) as well. Motivation The Wikipedia section on this is really short and does reference some books, but no online resources. So I think it would be nice to have various proofs for this theorem available here. I'll provide one (moved to an answer so it can be vote-sorted, too), but I want to know how other people with a different background would tackle this. So I make this an alternative-proof question.","['circles', 'inversive-geometry', 'alternative-proof', 'geometry']"
2540287,Kolmogorov–Smirnov 2-sample test with large sample sizes always significant,"I'm aware that the probability of a traditional statistical test such as student's t or mann-whitney u being deemed significant approaches 1.0 as sample size increases (i.e. >10,000) but I'm getting the same issue with a Kolmogorov–Smirnov 2-sample test which I'm having trouble understanding. Doesn't it always evaluate the difference between two sets of 100 cumulative probability values? I don't understand how sample size affects the result.",['statistics']
