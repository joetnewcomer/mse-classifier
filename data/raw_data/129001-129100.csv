question_id,title,body,tags
1988420,Ant is on a vertex of a triangle. What is the expected number of seconds to get back to the original vertex?,"An Ant is on a vertex of a triangle. Each second, it moves randomly to an adjacent vertex. What is the expected number of seconds before it arrives back at the original vertex? My solution: I dont know how to use markov chains yet, but Im guessing that could be a way to do this. I was wondering if there was an intuitive way to solve this problem. I would have guessed 3 seconds as an answer. I'm assuming that if it is at Vertex A, there is a 1/2 chance of going to Vertex B or C. So minimum number of seconds is 2 seconds. Max number could be infinite if it keeps bouncing back between B and C without returning to A. I'm still not sure how to do this puzzle.","['markov-chains', 'statistics', 'probability']"
1988455,Open superset of $\mathbb{Q}$,"Let $S$ be an open set such that $\mathbb{Q}\subset S$. We can also define a set $T=\mathbb{R}\setminus S$. I have been trying to prove or disprove whether $T$ could be uncountable. I suspect $T$ has to be at most countable, is my intuition correct?","['general-topology', 'elementary-set-theory']"
1988472,Empty set isomorphism,"Two sets are isomorphic if there is a bijection between them. But there is no bijection between two empty sets. Are two empty sets ""indistinguishable""? If so, what formal meaning this ""indistinguishable"" has? It may be a silly question, however I cannot find any answer on my own.",['elementary-set-theory']
1988483,"If $X = \bigcup_{n=1}^{\infty} F_n$ and each $F_n$ is a closed set, then $\bigcup_{n=1}^{\infty} F_n^{\circ}$ is dense in $X$.","Show that for a metric space $X$, the following statements are equivalent: a) X is a Baire Space. b) Every nonempty open set in $X$ is a set of the second category. c) If $X = \bigcup_{n=1}^{\infty} F_n$ and each $F_n$ is a closed set, then $\bigcup_{n=1}^{\infty} F_n^{\circ}$ is dense in $X$. I am able to prove that a) implies b). But Unable to prove the other directions b) implies c) and c) implies a). Help Needed. Thank You.","['general-topology', 'real-analysis', 'metric-spaces', 'baire-category']"
1988490,Necessity of Axiom of Choice in Functional Analysis given ZF + Dependent Choice,"What do we get with the Axiom of Choice (AC) in Functional Analysis that cannot be accomplished with Zermelo-Fraenkel (ZF) plus the Axiom of Dependent Choice (DC)? So, for instance, just dusted off and opened my old class notes and saw Hahn-Banach (see note below) Baire Category (see note below) Open Mapping / Closed Graph thrms Uniform Boundedness Principle Projection Lemma (Hilbert Space) Unit Ball is weak-* compact (Banach-Algaoglu) Riesz Representation Theorem (see note below) Spectral Theorem Separation of Convex sets by Hyperplanes Basic theorems about distribution functions/L^P spaces ... and any other theorems you can think of that fit in this theme of being well known to anyone who took a basic course in functional analysis, and useful to people who use analysis in their work. Please add to list b/c I am sure I forgot some theorems. (note on Hahn-Banach: In the spirit of the question, the most concrete form that is still abstract enough to use in the proofs of the other theorems is fine here. For instance, in my notes I have $p$ sublinear on a N.V.S. $X$ and $V$ a subspace of $X$, $f\in V^*$ and $|f|\le p$ on $V$ as the assumptions. note on Baire Category: The version that every complete metric space (or Banach space) is a Baire space would likely be sufficient here since I believe that the second one that locally compact Hausdorff spaces are Baire might not be standard material for a basic course in Functional Analysis. Please correct me if I'm wrong!) So, which require AC if one already accepts ZF+DC? Edit This is intended to be more a question about the internal logical dependencies of Functional Analysis than about logic and set theory. A good answer does not need to prove each of the theorems separately. In particular, One might show theorems $n_1$ and $n_2$ can be proven with DC by citing good links. Then say ""a standard proof for $n_3$ uses $n_1$ and some epsilon delta stuff. A standard proof $n_4$ uses $n_2$ and $n_3$ plus image of compact sets is compact, so also doesn't need full AC."" For the ones that do need AC, maybe a good link for one and then a link showing that others are equivalent under ZF. In other words, what I am looking for is for someone to take the few theorems about DC vs. AC that have already been proven, and flesh this out to the rest of (basic) functional analysis by discussing logical dependencies within the field of functional analysis. Please only assume a background in functional analysis, not in Foundations (sets/logic/etc. beyond everyday use). References to other questions where the details have been worked out in more rigour are quite sufficient.","['functional-analysis', 'axioms', 'foundations', 'axiom-of-choice']"
1988565,Find the solution of the Cauchy problem $u_t-uu_x=0$.,"For the Cauchy problem $u_t-uu_x=0, ~x\in \mathbb{R}, t>0$ with $u(x,0)=x,~x\in \mathbb{R} $, which of the following statements is true? the solution $u$ exists for all $t>0$. the solution $u$ exists for $t<\frac{1}{2}$ and breaks down at $t=\frac{1}{2}$. the solution $u$ exists for $t<1$ and breaks down at $t=1$ the solution $u$ exists for $t<2$ and breaks down at $t=2$. My work I used the method of characteristics to find out the solution. Given equation is $u_t-uu_x=0$, then 
$$\frac{du}{ds}=\frac{\partial u }{\partial x}\frac{dx}{ds}+\frac{\partial u }{\partial t}\frac{dt}{ds}$$. 
$\dfrac{dt}{ds}=1$ , letting $t(0)=0$ , we have $t=s$ $\dfrac{du}{ds}=0$ , letting $u(0)=f(x_0)$ , we have $u(x,t)=f(x_0)$ $\dfrac{dx}{ds}=-u$ , letting $x(0)=x_0$ , we have $x=-us+x_0$ , Therefore $u(x,t)=f(x_0)=f(x+ut)$. Now applying the initial condition $u(x,0)=f(x)=x$ we get $u(x,t)=x+ut$. Now the problem is from the solution I am unable to conclude anything from the option given precisely. It seems the option 1 is true but I don't know for sure. How can I solve this? Please help.Thanks.","['cauchy-problem', 'ordinary-differential-equations', 'partial-differential-equations']"
1988569,Can it be shown that $A*B/\langle\langle A \rangle\rangle \cong B$ without referencing a specific construction of A*B?,"Let $A$ and $B$ be groups and $A*B$ the free product. Let $N=\langle\langle A \rangle\rangle$ be the smallest normal subgroup of $A*B$ containing $A$. Show that $A*B/N \cong B$ without utilizing a specific construction of the free product. That is, formulate a proof without explicitly examining the elements of $A*B$. For a homework assignment I turned in last week, I was asked to show that $A*B/N \cong B$, which I did by showing that every element $Na_1b_1\cdots a_nb_n \in A*B/N$ is of the form $Nb$ for some $b\in B$ and then by defining $\phi:A*B/N \to B$ as $\phi(Na_1b_1\cdots a_nb_n)=\phi(Nb)=b$, which can fairly easily be shown to be an isomorphism. While this sufficed for the assignment, I don't particularly like this proof. I'm interested in knowing if it can be shown that $A*B/N \cong B$ without reference to the elements or specific construction of $A*B$. That is, does $A*B/N \cong B$ follow from the universal property of the free product or related theorems? All of my attempts so far have been fruitless.","['category-theory', 'abstract-algebra', 'group-theory', 'group-isomorphism']"
1988608,"Is the relation {(1,1),(1,2)} transitive? [duplicate]","This question already has answers here : Can a relation with less than 3 elements be considered transitive? (4 answers) Closed 7 years ago . For it to be transitive (1,2) would need to exist in the relation.
And it does, because a and b happen to be the same number.
But sets don't contain duplicates, so it either is transitive, or it cant be transitive if a and b are the same value.","['relations', 'elementary-set-theory']"
1988633,An isomorphism concerned about any finitely generated projective module,"This is the problem I want to solve : Show that for any finitely generated projective module $P$ over a ring $R $,
  $\mathrm{Hom}(P,M)$ is isomorphic with  $\mathrm{Hom}(P,R)\otimes M $. This is what I've done: I define a map : $Hom (P,R) × M \rightarrow Hom (P,M) $, with the law: $(\phi,m)\rightarrow \phi_m $, $\phi_m (x):=\phi(x) m $. This map is obviously bilinear, so we have a map $Hom (P,R) \otimes M \rightarrow Hom (P,M) $,  with the law $\phi\otimes m \rightarrow \phi_m $, $\phi_m (x):=\phi(x) m $. Now I have to construct the inverse homomorphism to end the proof. Because  $P $ is finitely generated, we can assume  $P=R^n $. I define a map: $Hom (P,M) \rightarrow Hom (P,R)\otimes M $ that sends $f $ to $f'\otimes f (1) $, when  $1$ is the identity element of $ P=R^n $. I don't know how to define $f'$. Is there any hint? If you don't agree with these, do you have another idea? Thanks.","['abstract-algebra', 'modules', 'noncommutative-algebra', 'projective-module']"
1988639,total number of mapping,"How many maps $\phi\, $ are there from $ N\, \cup\, {{0}}$  to $ N\, \cup\, {{0}}$, such that the property $ \phi(ab) \, = \, \phi(a)\,+\,\phi(b)\,$ is satisfied for all $a\, b \,\in N\, \cup\, {{0}}$? I came up with only one, mapping all numbers to zero.","['group-homomorphism', 'functions']"
1988659,Cayley-Bacharach for higher degree curves,"The Cayley-Bacharach theorem (also known as the 9 point theorem or the $8 \rightarrow 9$ theorem states that if two cubic curves intersect in 9 points, and C is any curve through 8 of those points, then C also passes through the 9th point. Suppose we replaced the word cubic with quartic or quintic? Suppose I have two curves of order $d$ that meet in $d^2$ points (by Bezouts), how many of these points does another degree $d$ curve C have to pass through before we an say it passes through all points? My intuition tells me that the answer would be ${d+2} \choose 2$$ -2$ - but is this accurate? I derive this from the dimension of the vector space = number of linear conditions imposed by points + 2 (our two curves which we want to span the vector space of vanishing polynomials). I am new to this area, so forgive any faux pas made with notation, convention, etc.","['projective-geometry', 'algebraic-geometry']"
1988678,Integral with 4 branch points,"Inspired by Ron Gordon's answer here I attempted to integrate
$$
g(w)=h(w)\ln w=\frac{\ln w}{(w+p)\sqrt{(w+x)(w+y)(w+z)}}, \quad (x,y,z,-p>0)
$$
over the contour $\gamma$ shown below. Description of the contour Line segment joining $P_{k},P_{j}$ is denoted by $L_{k,j}$. Each line segment is parallel to and at a distance $\delta$ from the real line. Small circle centered at $-\alpha$ is denoted by $C_\alpha$ and has radius $r_\alpha$. The large circle centered at $0$ has radius $R$ and is denoted by $C_R$. We shall consider the limiting case where
      $$\begin{align}&r_\alpha\to0,\quad \alpha=0,x,y,z,p\\
  &R\to+\infty\\&\delta\to0\end{align}$$ Question Integrals over $C_\alpha(\alpha=x,y,z,0), C_R$ vanish. Integral over $C_p$ can be computed using residue but how can the branch cuts be defined so that $g$ remains continuous inside the contour?","['complex-analysis', 'contour-integration', 'branch-points', 'branch-cuts']"
1988710,Preimage of a compact set,"If $f : \mathbb{R}^n \to \mathbb{R}$ is continuous, is the preimage $f^{-1}([0,1])$ also compact? I'm trying to check the two conditions that it's closed and bounded. I know how to show it's closed, but I don't know how to show that it's bounded. Can I just say the domain is unbounded because it's $\mathbb{R}^n$?","['multivariable-calculus', 'general-topology']"
1988753,"Suppose A,B and C are sets. Prove that if A ⊆ B, then A-C ⊆ B-C","I understand this intuitively. Let's say there's $x \in A$ and $x \in B$. Then $A - C$ means we're taking away every element in set $C$ from set $A$ and similarly the same for $B - C$. I understand that even if $C$ and $A$ had the same elements, even then $A-C \subseteq B-C$ holds true (the empty set). But I can't seem to write a formal proof out for it. Thanks!",['elementary-set-theory']
1988766,Hard exercise William Feller characteristic function,"This is an exercise of Feller Probability vol.2 that I'm trying to prove it without much progress. Suppose that $c_k>0$, $\sum c_k=1$ but $\sum c_k2^k=\infty.$ Let $u$ be an even continuous density concentrated on $(-1,1)$ and let $w$ be its characteristic function. Then $$f(x)=\sum c_k2^ku(2^kx)$$
defines a density that is continuous except at the origin and has the characteristic function 
$$\phi(\zeta)=\sum c_{k}2^kw(2^{-k}\zeta)$$
Show that $|\phi|^n$ is not integrable for any $n.$ As a hint that gives the book is if $x\neq 0$ the serie determinated by $f$ is finite. Consider the inequality $(\sum c_kp_k)^n\geq\sum c_k^np_k^n$ valid for $p_k\geq 0.$ Any kind of idea or help is welcome.","['characteristic-functions', 'probability-theory', 'probability-distributions']"
1988771,Showing an analytic function on the unit disk is nonzero in a certain neighborhood,"Suppose $f(z)$ is analytic for $|z|\le 1$ and $f(0) = a_0 \ne 0$. If $M = \max_{|z|=1} |f(z)|$, then show $f(z)\ne 0$ for all $z$ with $|z| < \frac{|a_0|}{|a_0|+M} =:r$. I know we can write $f(z) = a_0 + z^kg(z)$, some $k\ge 1$ and $g$ analytic and $g(0)\ne 0$. From here, I've tried various techniques, like contradiction by assuming $f$ has a root in the disk $\{|z| < r\}$, or trying to use Rouche's Theorem on the disk by examining $|f(z)-a_0|$, but I haven't really gotten anywhere. Any hints would be greatly appreciated.",['complex-analysis']
1988782,Where to start learning Differential Geometry/Differential Topology?,"I realize that this may be a very general question, perhaps even an unclear one (if it is I apologize), but as someone looking for the best way to start learning about these topics, I find that there is no clear path to learning Differential Geometry / Differential Topology, as there is with Analysis or General Topology, or even Abstract Algebra For example in Analysis, most agree that Principles of Mathematical Analysis by Walter Rudin is the place to begin, for Topology, Munkres book is the standard reference, and for Algebra, most tend to use either Dummit and Foote, Artin, Fraleigh or Lang. For Differential Geometry/Differential Topology, I find that there are no standard texts, the only one I know of is Lee's Introduction to Smooth Manifolds , however I feel I currently lack the prerequisites to tackle that book properly. Now I understand that to recommend a book to someone, you would need some gauge of their mathematical ability/maturity, but it is next to impossible to demonstrate that, so instead I can give a list of books that I'm currently reading through, and plan to read through in the next 3-6 months. What I'm currently reading Principles by Mathematical Analysis (Baby Rudin) Linear Algebra Done Right (by Sheldon Axler) Vector Calculus, Linear Algebra, and Differential Forms: A Unified Approach (by Hubbard and Hubbard) What I plan on reading soon Calculus on Manifolds by Spivak Topology by Munkres Complex Analysis by Alfhors Abstract Algebra by Dummit and Foote But after that I'm lost as to where to go further. I'm lost between Analysis on Manifolds by Munkres , A Comprehensive Introduction to Differential Geometry by Spivak , and do Carmo's Differential Geometry of Curves and Surfaces . Or should I just skip all those intermediate books and go straight to Lee's Introduction to Smooth Manifolds ? A Side note I find that the more challenging a book I read is, and the more I struggle through a book, I develop a deeper understanding of the topics in the book, and a greater appreciation of the subject I'm studying as a whole. Based on the books I've read/plan to read, please recommend books that are not easy, but difficult and challenging.","['differential-topology', 'reference-request', 'book-recommendation', 'soft-question', 'differential-geometry']"
1988842,"Find all functions $f:R \to R$, that for each $x, y ∈ R$ satisfy $f(x\cdot f(y)) = x \cdot y$","Two such functions would be $f(x) = x$ and $f(x) = -x$, but how would I know I've found all satisfactory functions?",['functions']
1988851,Time for the tank to be empty,"A hemispherical tank of radius 2 metres is initially full of water and has an outlet of 12 cm$^2$ cross-sectional are at the bottom. The outlet is opened at some instant. The flow through the outlet is according to the law 
$v(t) = 0.6 \sqrt{2gh(t)}$, where $v(t)$ and $h(t)$ are respectively the velocity of the flow through the outlet and the height of water level above the outlet at time $t$, and $g$ is the acceleration due to gravity. Find the time it takes to empty the tank. I know to write a differential equation by relating the decrease of water level to the outflow in order to solve. But don't know how and as we are not not given the initial height how can we solve it.","['physics', 'integration', 'ordinary-differential-equations', 'calculus']"
1988872,4-digit password with unique digits not in ascending or descending order,"I need to calculate how many possible passwords there are if each password is 4 digits long, using the digits 0-9. All digits in the password must be unique, and cannot all be neither increasing nor decreasing. For example “3569” is not allowed, because the digits are in increasing order, while “1374” is allowed I know that a four digit password could be anything between 0000 to 9999, hence there are 10,000 combinations. But I am now stuck figuring out how to calculate the number of all possible passwords that are unique, neither increasing nor decreasing. 
I have tried to calculate the possible number of passwords if every digit only may be used once:
$$P(n,r)=\frac{10!}{(10−4)!}=\frac{10⋅9⋅8⋅7⋅6⋅5⋅4⋅3⋅2⋅1}{6⋅5⋅4⋅3⋅2⋅1}=5040$$
But I am now quite sure if this is the answer to the question? If not how should I calculate such a question?","['permutations', 'combinatorics', 'discrete-mathematics']"
1988881,Proving $\frac{1}{\sqrt x} $is discontinuous at 0,"The function at hand is $f(x) = \frac{1}{\sqrt x} $ I know that is order to prove discontinuity, I have to show the following: $\forall \delta \gt 0, \exists \varepsilon \gt 0 ~~\text{and} ~~ \exists x ~~ \text{such} ~\text{that} ~~|x - 0| \lt \delta ~~ \text{implies} ~~ |f(x) - f(0)| \geq \varepsilon$ but the function is not defined at $x = 0$, so I can't develop $f(0)$. I also tried finding a sequence that converges to $0$ but it's image does not converge to the image of $0$, but I'm faced with the same problem there as well. grateful for any help.","['continuity', 'real-analysis', 'functions']"
1988909,Equivalent definitions for normal maps between von-Neumann algebras,"There are many different definitions for ""normal"" in literature, and I could not see the equivalence between the two following definitions: Let $M , N$ be von-Neumann algebra, and let $\varphi: M\to N$ be a map. We say that $\varphi$ is normal if: $\varphi(\sup x_{\alpha})=\sup \varphi (x_{\alpha})$ for all norm-bounded monotone increasing nets of self adjoint elements $\{x_{\alpha}\} \subseteq M_{sa}$. $\varphi$ is $\sigma$-weakly continuous (when identifying $M$ with its predual and recall that the weak$^*$-topology on the predual coincides with the relative ultra-weak ($\sigma$-weak) topology on $M\subseteq B(H)$). The direction $(2)\Rightarrow (1)$: If we let $(x_{\alpha})\subseteq M_{sa}$ be a norm-bounded increasing net, by Vigier lemma, $x_{\alpha}$ converges in SOT to some $x\in M_{sa}$ and actually $x=\sup_{\alpha} x_{\alpha}$. We know that on bounded subsets the ultra-weak topology coincides with the weak$^*$ topology, so by $\sigma-weak$ continuity of $\varphi$ we get $\varphi(x_\alpha)\to \varphi(x)$ (in norm). However, I'm not sure why $\lim \varphi(x_\alpha)=\sup \varphi (x_{\alpha})$. Maybe if we add an assumption that $\varphi$ is positive we could get it, again by applying Vigier's lemma. I don't know also how to show the converse direction. Maybe I also should mention that I'm not sure the above definitions I gave are equivalent, there is an option I did some ""mix"", or this is true for states? Thank you for your time.","['functional-analysis', 'c-star-algebras', 'conditional-expectation', 'operator-algebras']"
1988948,Geometric interpretation of non-square matrices,I realize that a $n\times{n}$ matrix can be interpreted as linear transformation of a vector in n-dimensional coordinate system. But I am not able to interpret any $m\times{n}$ matrix same way since $m\times{n}$ doesn't mention all the coordinates. How  can this type of transformation be visualized?,"['matrices', 'linear-algebra', 'linear-transformations']"
1988978,What's so discrete about discrete topology?,"I am a beginner at topology. I recently learned about discrete topology. But the definition of discrete topology doesn't convey anything 'discrete' to me. Is it just whimsically named like top, bottom quarks in physics or does discreteness has anything to do with discrete topology? P.S As I've not found anything like  this on this site I hops this is not duplicate.",['general-topology']
1988994,Is $f(x)/x$ differentiable at $x=0$?,"Let $\varepsilon> 0$, $I:=(-\varepsilon,\varepsilon)$ and $f\in C^\infty(I,\mathbb R)$ with $f(0)=0$. By the definition of the derivative we know that
$$h:I\setminus\{0\}\to \mathbb R, \qquad x \mapsto \frac{f(x)}{x}$$
can be continuously extended to $I$ with $h(0):=f'(0)$. But what do we know about differentiability of $h$ at $0$? Is $h\in C^\infty(I,\mathbb R)$? EDIT: For analytic functions this is clearly the case. But what do we have in general?","['derivatives', 'real-analysis', 'continuity']"
1989007,Advanced book on partial differential equations,"I am looking for an advanced book on partial differential equations that makes use of functional analysis as much as possible. All the books I have looked in so far either shy away from functional analysis and try to avoid even basic concepts, or present results from functional analysis I know anyway just to discuss some very basic applications to partial differential equations (say, semigroup theory applied to the heat equation). The book I am looking for should use functional analysis instead of hard analysis whenever possible (I am well aware of the fact that the theory of partial differential equations is not merely an application of functional analysis), go into some advanced topics that are relevant for research, and not spend too much space on covering the results of functional analysis itself - I have my references for that. The background is that I am interested in operator equations that are not partial differential equations, yet methods from pde are often helpful. If it is relevant, I am mostly interested in elliptic and parabolic equations, although I don't want to limit the focus.","['functional-analysis', 'book-recommendation', 'partial-differential-equations']"
1989034,What common developments are there to solve $1+x=x^a$?,"I am facing the trinominal equation $1+x=x^a$ where $a$ is not necessarely an integer, but some positive real. Are there some common series developments of functions $x=V(a)$ that one can solve the equatios via $1+V(a)=V(a)^a$.","['functional-analysis', 'sequences-and-series']"
1989041,Understanding the definition of ergodicity through examples,"I am taking a course on Communication Systems (from an engineering point of view). While I'm usually very interested in the formal mathematics, this time I would like to avoid it, since I don't have a good background on probability theory; also, many of my colleagues have little to no interest in formal mathematics at all, and I would like to understand this concept in a way that would be easy to propagate to them. So, apparently to understand the meaning of ergodicity, one needs to know what is the ensemble average and what is the time average of a random process. After reading this answer on Math.SE , and three related entries on Wikipedia ( Ergodic Process , Ergodicity , Stationary ergodic process ), this is what I understand: A random process is like a random variable, but it's outcomes are ""waveforms"" (a.k.a. functions) instead of numbers. The ensemble average is the average of the outcomes of the random process, and therefore is another function (waveform) by itself. A given random variable will have one ensemble average (one function). As opposed to the ensemble average, a random process can have many (possibly infinitely many) time averages, since every outcome of the random process (i.e., every waveform) has its own time average, which is the average value of the waveform. That is, given an outcome $x(t)$, it's time average will be given by $$\lim_{T \to \infty} \dfrac{1}{T} \int_{-\frac{T}{2}}^{\frac{T}{2}}x(t)dt$$ After reading those wikipedia pages, it seems that an ergodic process is a process that satisfies ""the time average is equal to the ensemble average"". But, which time average? To my understanding there are many time averages. Which one? All of them? Their mean? At least one of them? Or what? Also, I would like to take a better look on the following examples, found in the linked wikipedia pages: Example 1. Suppose that we have two coins: one coin is fair and the other has two heads. We choose (at random) one of the coins, and then perform a sequence of independent tosses of our selected coin. Let X[n] denote the outcome of the nth toss, with 1 for heads and 0 for tails. Then the ensemble average is ½  (½ +  1) = ¾; yet the long-term average is ½ for the fair coin and 1 for the two-headed coin. Hence, this random process is not ergodic in mean. Is this correct? (of course my doubt here is a consequence of the fact that I don't know the answer for my bold question above). Example 2. Ergodicity is where the ensemble average equals the time average. Each resistor has thermal noise associated with it and it depends on the temperature. Take N resistors (N should be very large) and plot the voltage across those resistors for a long period. For each resistor you will have a waveform. Calculate the average value of that waveform. This gives you the time average. You should also note that you have N waveforms as we have N resistors. These N plots are known as an ensemble. Now take a particular instant of time in all those plots and find the average value of the voltage. That gives you the ensemble average for each plot. If both ensemble average and time average are the same then it is ergodic. It says ""take a particular instant of time in all those plots"". Does any instant works? Or rather, do I have to take ""all of them"" (one at a time)? Taking only one instant of time doesn't seem right... Rather, shouldn't I be taking some sort of limit to infinity? Also, it refers to ""the time average"" as if it was only one, but to my understanding there are N different time averages here, since there are N waveforms.","['stochastic-processes', 'average', 'probability-theory', 'statistics']"
1989065,Exercises where multivariable calculus and differential equations are mixed,"I have a course where multivariable calculus and differential equations are mixed, as an application of what you did in class, Hadamard's theorem: Let $f\in \mathcal{C}^2(\Bbb{R}^n,\Bbb{R}^n)$ If $f(0)=0$ and that for all $x\in \Bbb{R}^n$ the derivative is invertible and satisfies $$\Vert (df_x)^{-1}\Vert\le A\Vert x\Vert+B$$ where $A,B$ are two fixed constant. Then $f$ is a diffeomorphism. It was very interesting, we use Cauchy-Lipschitz's Theorem, explosion in finite time and local inversion theorem. Unfortunately , I didn't find a suitable reference in my library for these kind of exercises. I am not sure where I am suppose to search, I am looking for exercises, any ideas?","['multivariable-calculus', 'reference-request', 'ordinary-differential-equations']"
1989095,A question about proving that there is no greatest cardinal [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . The community reviewed whether to reopen this question 2 years ago and left it closed: Original close reason(s) were not resolved Locked . This question and its answers are locked because the question is off-topic but has historical significance. It is not currently accepting new answers or interactions. I would like to know if it is possible to prove that there is no greatest cardinal without axiom of choice","['cardinals', 'elementary-set-theory']"
1989112,Partitioning $\mathbb Q^+_0$ in 2-element sets,"I'm having trouble solving the following exercise: Find a partitioning of the set $\{x\in \mathbb Q | x \geq 0\}$ in disjoint subsets, each containing two elements. Now at first I thought about pairs $(a,b) := \{\{a\}, \{a,b\}\}$ whith whom you could identify $\frac{a}{b}$, but they are rather subsets of $\mathcal P(\mathbb N)$, right? Maybe there is an easy solution, but neither I nor my friends couldn't come up with one yet.","['rational-numbers', 'set-partition', 'elementary-set-theory']"
1989117,Subdifferential of a convex differentiable function,"Let us consider $f:\, \mathbb{R}^n \rightarrow \mathbb{R}$ be a convex function and differentiable at a point $x_0$. If $\partial f(x_0)$ denotes the subdifferential of $f$ I would like to prove that the only element in it is given by the gradient of f in $x_0$, i.e. $$
\partial f(x_0)=\left\lbrace\nabla f(x_0)\right\rbrace
$$ I know that it should be trivial but i can't prove the inclusion: $\subset$ ...any suggestion?","['derivatives', 'subgradient', 'real-analysis', 'convex-analysis']"
1989144,Discrete proof?,"So we're doing proofs regarding numbers in discrete and I'm unsure of form. Is there anyone who could help me through this? Prove $n^2 + 2n +1$ is odd for all even integers, then prove that it is odd for all integers.","['proof-writing', 'discrete-mathematics']"
1989182,Why is the solution to a nonhomogeneous differential equation the complementary solution + a particular solution? [closed],Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 7 years ago . Improve this question Why does only one particular solution allow enough degrees of freedom for the general solution?,['ordinary-differential-equations']
1989217,Prove if $|f|$ is differentiable at $a$ and $f$ is continuous at $a$ then $f$ is differentiable at $a$,"I have a problem
Prove if $|f|$ is differentiable at $a$ and $f$ is continuous at $a$ then $f$ is differentiable at $a$ Hint: I need prove $|\lim_{x\rightarrow a}\frac{f(x)-f(a)}{x-a}|=\lim_{x\rightarrow a}|\frac{f(x)-f(a)}{x-a}|$ I try use this fact: $\lim_{x\rightarrow a}\frac{|f(x)|-|f(a)|}{x-a}$ Exist and $\lim_{x\rightarrow a}|f(x)|-|f(a)|=0$ But I'm stuck, please someone help me?","['derivatives', 'real-analysis']"
1989279,Is it possible to make any abelian group homomorphism into a linear map?,"Let $G$
  and $H$
  be abelian groups and let $\varphi:G\rightarrow H$
  be a group homomorphism. Can we define a nontrivial scalar multiplication on $G$
  (from some field $F$
 ) and another nontrivial scalar multiplication on $H$
  (from $F$
 ), thereby making them vector spaces, such that $\varphi$
  becomes a linear map? If the answer is yes, then would this also work if we made $G$ and $H$ into modules over some ring $R$?","['category-theory', 'modules', 'group-theory']"
1989327,Cauchy-Schwarz Inequality and series proof,Let { $a_n$ } and { $b_n$ } be sequences such that $\sum_{n=1}^\infty a_n^2$ and $\sum_{n=1}^\infty b_n^2$ are convergent Prove that $\sum_{n=1}^\infty a_nb_n \le (\sum_{n=1}^\infty a_n^2)^{\frac{1}{2}} (\sum_{n=1}^\infty b_n^2)^{\frac{1}{2}}$ I can see I have to use the Cauchy-Schwarz inequality. But not really sure how to start. Also I know $\sum_{n=1}^\infty a_nb_n$ converges absolutely from a previous part of the question.,"['inequality', 'cauchy-schwarz-inequality', 'sequences-and-series']"
1989341,On the evaluation of the integral $\int_{-\frac{b}{a}}^{\frac{1-b}{a}}\log\left(ax+b\right)\exp\left(-\frac{1}{2}x^2\right)\mathrm{d}x$.,"Let $x\in(0,1)$ be a random variable that follows a truncated normal distribution with density 
$$
f(x)=
\begin{cases} 
      \frac{1}{\sqrt{2\pi\sigma^2}D}\exp\left(-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2\right)                 & \text{, if}\:\:0<x<1           \\
      0 & \text{, otherwise}
\end{cases}
$$
where $D=\Phi\left(\frac{1-\mu}{\sigma}\right)-\Phi\left(-\frac{\mu}{\sigma}\right)$ (let $\Phi$ denote the cdf of the standard normal distribution). I am interested in evaluating the integral
$$
I = \int_{0}^{1}g(x)f(x)\mathrm{d}x,
$$
where $g(x)=\log(x)$, $x>0$, is the neperian logarithm, i.e. the integral
$$
I = \frac{1}{\sqrt{2\pi\sigma^2}D}\int_{0}^{1}\log(x)\exp\left(-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2\right)\mathrm{d}x,
$$
which, using the substitution $u=\frac{x-\mu}{\sigma}$, is rewritten as follows
$$
I = \frac{1}{\sqrt{2\pi}D}\int_{-\frac{\mu}{\sigma}}^{\frac{1-\mu}{\sigma}}\log\left(\sigma u+\mu\right)\exp\left(-\frac{1}{2}u^2\right)\mathrm{d}u.
$$ I know that this couldn't be given in a closed form. If this makes any difference, I want to use this for a practical application, so if there could be a numerical approximation with some given accuracy, that would suit me, but I would like to avoid it.","['integration', 'definite-integrals', 'normal-distribution']"
1989345,Motivation for Mobius Transformation,"Let $S$ denote the Riemann Sphere. Recall that a Mobius transformation is a function $f:S \to S$ defines as $z \to \frac {az+b}{cz+d}$ where $a,b,c,d \in \mathbb C$ with $ad-bc=1$. What is the motivation to study Mobius Transformation? Why should one look at the map defined in the above way?","['riemann-surfaces', 'complex-analysis', 'mobius-transformation']"
1989359,Is there an easy way to determine a point from its barycentric coordinates geometrically?,"For example if I have a point $(\alpha_1,\alpha_2,\alpha_3,\alpha_4)$ and a polygon with vertices $v_1,v_2,v_3,v_4$, can I determine the actual location without calculating the result with the formula ($\sum_i\alpha_i\times v_i$) but just using a ruler and line intersections? I was thinking of a step by step approach like how the center of mass of a triangle can be determined by taking the midpoint of each side and drawing a line to the opposite vertex, but I can't seem to generalize it properly to work with an arbitrary number of vertices and different weights per vertex. The only way that I could think of is to measure the segment on each side and ""shift"" each segment so it lies one after another, essentially doing vector addition, but the errors add up due to inaccuracies. Thanks in advance! Edit: After rereading a few times and trying out some things I can see why it might be ambiguous, so let me try to clarify:
I have an equation $\alpha_0 \times v_0 + \alpha_1 \times v_1 + ... + \alpha_n \times v_n$ with $\sum_i \alpha_i = 1$.
I can rewrite that as $\alpha_1 \times (v_1-v_0) + \alpha_2 \times (v_2-v_0) + ... + \alpha_n \times (v_n - v_0) + 1 \times v_0$ with the coefficient of $v_0$ equal to 1 because it's corresponds to the sum of all $\alpha$. Now if I draw each term as a vector starting from $v_0$ for a random polygon and semi random weights I get the following image: https://i.sstatic.net/wYCSy.png (can't embed image due to not enough reputation, sorry) [ Maybe not, but I have so I will lend you a hand (HdB) ] To get the corresponding point from the barycentric coordinates $(\alpha_0, ..., \alpha_n)$ I now just need to do vector addition, as shown in green. With a lot of vertices this gets quite inaccurate due to having to shift a ruler to determine the next point until the entire sum is done, so my question was if there was any way to determine the same point without adding up all those inaccuracies?","['barycentric-coordinates', 'geometry']"
1989367,A question regarding the vector bundle associated to the frame bundle,"Let $E\to M$ be a smooth real vector bundle of rank $n$ and $\mathcal{F}E\to M$ be the associated frame bundle. The frame bundle is a principal $GL(n,\mathbb{R})$-bundle and $GL(n,\mathbb{R})$ has a natural action on $\mathbb{R}^n$. Thus we can construct the associated vector bundle $\mathcal{F}E \times_{GL(n,\mathbb{R})} \mathbb{R}^n \to M$. This is again a vector bundle of rank $n$. A natural question is that : Is there a relation between the two bundles $\mathcal{F}E \times_{GL(n,\mathbb{R})} \mathbb{R}^n \to M$ and $E \to M$ ? I guess that they would be isomorphic, but I am unable to see if there is a natural isomorphism between them.","['manifolds', 'vector-bundles', 'differential-geometry']"
1989375,Representation of integers by Fibonacci numbers,"Denote by $F$ the set of all Fibonacci numbers.
It is our conjecture that: (a) For every integer $n$ there exist a number $k=2^q$ (for some positive integer $q$) and  numbers $a_1,\cdots,a_k\in F$ such that 
$$
n=a_1+\cdots+a_{\frac{k}{2}}-(a_{\frac{k}{2}+1}+\cdots+a_k).
$$
Now, denote by $k(n)$ the least $k$ obtained from (a). (b) The set of all $k(n)$, where $n$ runs over all integers, is unbounded above. (the second part is very important for me)","['number-theory', 'fibonacci-numbers', 'additive-combinatorics', 'elementary-number-theory']"
1989389,Why can't linear maps map to higher dimensions?,"I've been trying to wrap my head around this for a while now. Apparently, a map is a linear map if it preserves scalar multiplication and addition. So let's say I have the mapping: $$f(x) = (x,x)$$ This is not a mapping to a lower or equal dimension, but to a higher one. Yet it seems to preserve scalar multiplication and addition:
$$f(ax) = (ax,ax) = a(x,x) = af(x)$$
$$f(x+y) = (x+y,x+y) = (x,x) + (y,y) = f(x) + f(y)$$ I must have made an error in my logic somewhere, but I can't seem to find it. Or are linear maps simply defined this way? I would really appreciate to know this.","['linear-algebra', 'linear-transformations']"
1989412,Decision Tree Probability - With Back Step,"For the below decision tree, I can see how the probabilities of each end state are calculated... simply multiply the previous decisions: But for this one below, I'm totally stumped. It seems in my head the chance at resetting back to the first decision is completely negated because essentially the whole decision restarts like the first decision was never made. But based on the end probabilities this gives s3 a larger chance at being chosen. What does the math behind this look like? How are those final probabilities calculated given the reset in the decision tree?","['statistics', 'probability']"
1989472,Reference on these two affirmations on Differential Geometry,"I'm reading the paper ""A gap theorem for free boundary minimal surfaces in the three-ball"" . In what follows $\Sigma$ is a minimal compact free boundary surface in the unit three-ball $B^3$ contained in $\mathbb{R}^3$. On page 5 we have two affirmations, here they are: 1 - ""In particular, $\partial \Sigma$ is strictly convex in $\Sigma$. This implies that for all $p,q \in \Sigma$ there exists a minimising geodesic in $\Sigma$ joining $p$ to $q$."" 2 - ""Given $[\alpha] \in \pi_1(\Sigma,p)$, let us assume that $[\alpha]$ is a non trivial homotopy class. Since $\partial \Sigma$ is strictly convex we can find a geodesic loop $\gamma:[0,1] \to \Sigma$, $\gamma(0)=\gamma(1) = p$, such that $\gamma \in [\alpha]$."" I've finished studying the whole paper and these are the only two things I don't understand and don't know how to prove. Where can I find reference for these two facts? I already tried looking into some of the references but didn't find anything helpful. Thank you.","['riemannian-geometry', 'differential-geometry']"
1989492,How to evaluate $ \int_0^n \cos(2\pi \lfloor x\rfloor\{x\})dx$?,"For a real number $ x$ , let $\lfloor x\rfloor$ denote the largest integer less than or equal to $x$ and $ \{x\}=x-\lfloor x\rfloor$ (floor and fractional part, resepectively). Let $n$ be a positive integer. I want to evaluate $$ \int_0^n \cos(2\pi \lfloor x\rfloor\{x\})dx$$ I broke down the integral as $$\int_0^1\cos(2\pi \cdot 0 \cdot x)dx+\int_1^2\cos(2\pi \cdot 1 \cdot x)dx +\cdots+ \int_{n-1}^{n}\cos(2\pi \cdot (n-1)\cdot x)dx$$ However I got the wrong answer and I couldn’t understand where I went wrong.","['fractional-part', 'integration', 'definite-integrals', 'ceiling-and-floor-functions']"
1989514,Dance competition,Twenty boys and twenty girls were invited to a prom. During the dance competition $99$ pairs (consisting of a boy and a girl) made a dance performance. All pairs were unique. Prove that there exist such two boys and such two girls that each boy danced with both girls. What I managed to do myself: I found the number of pairs consisting of $2$ girls: it's $\frac{20!}{18!\cdot 2!}=190$,"['combinations', 'combinatorics', 'graph-theory']"
1989520,The empty and full sets need to be in the topology of a set?,"Let for example the set be $X=$ {a,b,c}, where a,b,c are of undeterminated nature, the following topology: $T=$ {{a},{a,b}}, is a topology in the definition proposed by F. S. George in the book Introduction to topology and modern analysis, the definition is: A topology $T$ of a set $X$ is a collection of subsets of $X$ satisfying the following: 1) The union of a subclass os sets in T is a set in T
2) The finite intersection of sets in T is a set in T and in the following pages he propose that the empty set and the set  X are always in any topology, and the justificative is because one is the union of an empty subclass and the other is a intersection of an empty subclass of $T$, it is not right is it? How do you guarantee that the empty set is always a subclass of a topology? Is because of this that usualy we require that a topological space must have the empty set and the full set instead of only these 2 previous statements, or not?",['general-topology']
1989525,"For a convex function, does having a unique minimizer imply that it is coercive?","I am looking for a simple proof that if a functional is convex and it has a unique minimizer, then it must be coercive. To be specific, let ${\cal H}$ is a Hilbert space and $G$ is a functional on it. If $G$ has a unique minimizer on ${\cal H}$, i.e. $\exists f_0 \in {\cal H}$ such that $G(f_0) < G(f), \quad \forall f \in {\cal H}, f \neq f_0$. How can we prove that $G(f) \rightarrow \infty$ when $\|f\| \rightarrow \infty$.","['functional-analysis', 'convex-analysis', 'analysis']"
1989530,Cofiltered limit of $T_0$ and quasi compact spaces is again quasi compact.,"Let $\mathscr{I}$ be a cofiltered category and consider a cofiltered diagram of topological spaces $X_i$ with each space being quasi compact and $T_0$. For every $X_{i} \xrightarrow{f_{i,j}} X_j$ morphism in the diagram we have that $f_{i,j}$ is a quasi compact map. That is, if $U \subset X_j$ is open and quasi compact then its preimage is also open and quasi compact. I would like to prove that the limit of diagram, let's called it $X$ is quasi compact. For the moment I am not getting very far. I am not even able to prove that $X$ is non empty. I don't know if it is useful but every $X_i \cong \operatorname{Spec} R_i $ for some commutative ring.","['category-theory', 'general-topology', 'algebraic-geometry']"
1989552,Number of different possibilities including repeats,"so in one of my math classes, we're learning about counting and using this operation called ""n choose k"" $\binom{n}{k}=\frac{n!}{k!(n-k)!}$, however this operation does not account for the possibilities of repeats, and answers with repeating variables. An analogy would be that you want to buy a pizza with the following conditions: up to 3 toppings on each pizza 7 toppings to choose from The pizza toppings must be unique—double or triple toppings are not allowed. The arrangement of the toppings on each pizza does not matter; e.g., tomatoes on top of
pepperoni is the same as pepperoni on top of tomatoes.
What is the total number of possibilities for a pizza order in this deal? And we learned that the answer would be $x=\binom{7}{0} + \binom{7}{1} + \binom{7}{2}+\binom{7}{3}=64$. However, how would you find how many pizzas you could order with double or triple toppings.  So pretty much using this ""choose"" function, but allowing for those doubles and triples to come up in the count.  I tried this manually, by writing down all the possibilities and I found that the ""choose"" did not account for a pretty significant amount of doubles and triples. Ex: $\binom{7}{3}=35$, and when I drew out all the possibilities for lets say the 3 toppings were A, B, C, D, E, F, G.  I found there to be an extra 49 pizzas which could be accounted for (if there are repeated toppings, like AA, BB etc...). Another Ex: For $\binom{7}{2}=21$, if we draw the two by two table you can see that the diagonal is the only place where two of the same variables meet, and this ""choose"" function does not account for them. So essentially my question is, how do you account for these without doing what I did, by manually drawing out all the tables, and physically finding all the possibilities which can have 2 or 3 repeated values? Like is there a mathematical way of finding this? And to conclude from what I found then there would be a total of $64+49+7+7=127
$ ways to get a pizza with the 2nd condition.  The extra 7 I added in there is intuitively there can only be 7 pizzas which have the same toppings, like AAA, BBB, CCC, DDD, EEE, FFF, GGG.","['combinatorics', 'statistics', 'probability']"
1989608,Product Space constructed from cylinder set,"I am studying the book ""Probability Theory"" from Achim Klenke. In this book the Measure extension Theoremis constructed in the following way: Consider an infinitely often repeated random experiment with finitely many possible outcomes. Let $E$ be the set of possible outcomes. Let $\omega_{1},\omega_{2},....\in E$ be the observed outcomes. Hence the space of all possible outcomes of the repeated experiment is $\Omega=E^\mathbb{N}$. Then they defined the set of all sequences whose first n values are $\omega_{1},....\omega_{n}$ as $\mathcal{A}_{n}:= \{[\omega_{1},....\omega_{n}]:\omega_{1},....\omega_{n} \in E\}$
Then $\mathcal{A}:=\bigcup_{n=0}^{\infty}\mathcal{A}_{n}$ forms a semi-ring. Now they defined a probability measure on the semi-ring $\mathcal{A}$ and want extend it to $\sigma(\mathcal{A})$. For that purpose they want to prove first the existence of $\sigma(\mathcal{A})$ in the following way: Define the (ultra-)metric $d$ on $\Omega$ by $d(\omega,\omega^{'})= \left\{\begin{array}{@{}lr@{}}
        2^{-inf\{n\in\mathbb{N}:\omega_{n}\ne\omega_{n}^{'}\}} & \text{if }\omega\ne\omega^{'}
\\
        0                       & \text{if}\omega=\omega^{'}
        \end{array}\right\}$ They claim $(\Omega,d)$ is a compact metric space and $[\omega_{1},....\omega_{n}]=B_{2^{-n}}(\omega)=\{\omega^{'}\in\Omega:d(\omega, \omega_{'}) <2^{-n}\}$. The complement of $[\omega_{1},....\omega_{n}]$ is an open set, as it is the union of $(\#E)^{n}-1$ open balls
$[\omega_{1},....\omega_{n}]^{c}=\bigcup_{(\omega_{1}^{'},....\omega_{n}^{'})\ne(\omega_{1},....\omega_{n})}[\omega_{1}^{'},....\omega_{n}^{'}]$.
Since $\Omega$ is compact, the closed subset $[\omega_{1},....\omega_{n}]$ is compact. Therefore $\sigma(\mathcal{A})=\mathcal{B}(\Omega,d)$, which guaranteed the existence. Applying Caratheodory Theorem, we obtain an extension on the Sigma-Algebra. Now the following Point I couldn't follow: $[\omega_{1},....\omega_{n}]$ is defined as an open-ball, why it is
closed? Why is $(\Omega,d)$ compact? I cannot see why $\sigma(\mathcal{A})=\mathcal{B}(\Omega,d)$.
The Borel-Sigma-Algebra is defined as the sigma-algebra generated by Open-sets. I know it is equivalent to the sigma-algebra generated by closed sets and compact sets. However, the set $\mathcal{A}$, as a countable union of $[\omega_{1},....\omega_{n}]$, which is closed and compact, can still not be classified as open, close or compact.","['product-space', 'probability-theory', 'measure-theory']"
1989648,Hahn-Banach Theorem and Elliptic PDEs,"Suppose $A$ is positive-definite and bounded.  For a fixed $u\in W^{1,2}(U)$, define $$
\ell_u(v)=\int_{U}A\nabla u\nabla v
$$ for $v\in W^{1,2}(U)$.  Also suppose $\ell_u$ is bounded on some linear subspace $X$ of $W^{1,2}(U)$ (e.g., maybe $W^{1,2}_0(U)$).  Is there any conclusion I can draw regarding $\|u\|_{W^{1,2}(U)}$? By Hahn-Banach, I can extend $\ell_u$ uniquely to a bounded linear functional $\tilde{\ell}_u$ on $W^{1,2}(U)$ with $\|\ell_u\|=\|\tilde{\ell}_u\|$, but I don't think I'm guaranteed anymore information about $\tilde{\ell}_u$.  I can say $|\tilde{\ell}_u(u)|\leq \|\ell\|\|u\|_{W^{1,2}(U)}$, but is there anymore?","['functional-analysis', 'partial-differential-equations']"
1989748,Accurate $\zeta(s)$ integral identities for $\sum_\limits{n=2}^{\infty}\frac{1}{n^{s}\sqrt{\ln{n}}}$,"Some time ago while doing formal symbolic manipulations for fun (without worrying about convergence or getting into analysis ) to see where I would get, I did the following manipulation: Starting with the following formula (which I think is quite well known and follows from 3.325 in this book by substitution changing the variable of integration to $\sqrt{x}$): $$\int_{0}^{\infty}x^{-\frac{1}{2}}e^{-ax-\frac{ab}{x}}dx=\sqrt{\frac{\pi}{a}}e^{-2\sqrt{ab}}$$ I let $a=\ln{n}$ and took a sum from $n=2$ to $\infty$ and then interchanged integration and summation on the left and used the definition of the zeta function to get: $$\int_{0}^{\infty}x^{-\frac{1}{2}}\left[\zeta\left(x+\frac{b}{x}\right)-1\right]dx=\sqrt{\pi}\sum_{n=2}^{\infty}\frac{1}{n^{2\sqrt{b}}\sqrt{\ln{n}}}$$ I then let $s=2\sqrt{b}$ and performed the substitution $x\rightarrow u^2$ in the integral to arrive at the following interesting formula: $$\sum_{n=2}^{\infty}\frac{1}{n^{s}\sqrt{\ln{n}}}=\frac{2}{\sqrt{\pi}}\int_{0}^{\infty}\zeta\left(x^{2}+\frac{s^2}{4 x^2}\right)-1 \;dx \tag{1}$$ At a different time, I took $\int_{0}^{\infty}g(t)\sum_\limits{n=2}^{\infty}\frac{1}{n^{st}}dt$ for arbitrary $g(t)$ and rearranged the summation and integration and used the definition of the Laplace transform to turn this into $\sum_\limits{n=2}^{\infty}L[g(t)](s\ln{n})$. I then substituted in $g(t)=H(t-a)f(t-a)$ where $H(t)$ is the Heaviside function and $f(t)$ is arbitrary and used some Laplace transform identities and the definition of the zeta function to get: $$\int_{0}^{\infty}\left(\zeta(st)-1\right)H(t-a)f(t-a)dt=\sum_{n=2}^{\infty}e^{-as\ln{n}}L[f(t)](s\ln{n})$$ $$=\int_{a}^{\infty}\left(\zeta(st)-1\right) f(t-a)dt$$ Then I set $f(t)=\frac{1}{\pi\sqrt{t}}$ and evaluated the Laplace transform to get: $$\sum_{n=2}^{\infty}\frac{1}{n^{as}\sqrt{s\ln{n}}}=\int_{a}^{\infty}\frac{\zeta(st)-1}{\sqrt{\pi(t-a)}}dt$$ I then made the substitution $t\rightarrow a+\frac{x^2}{s}$ and set $a=1$ to finally get: $$\sum_{n=2}^{\infty}\frac{1}{n^{s}\sqrt{\ln{n}}}=\frac{2}{\sqrt{\pi}}\int_{0}^{\infty}\zeta(x^{2}+s)-1 \; dx \tag{2}$$ I think that equations $(1)$ and $(2)$ are quite beautiful, but I do not know whether they are true or not because of the formal kind of way I derived them which can give spurious results as I've found . Although the 2 integrals look similar, I am not sure if they are actually directly related (since I cannot think of a substitution that would turn one into the other) or if the apparent similarity is just a coincidence. When I tested a few special values of $s$ with Wolfram Alpha, e.g. with $s=\pi$ here , here and here I got that the difference between the two integrals was on the order of $10^{-14}$ and the error in each of the two identities was around $10^{-12}$. Not being familiar with the error in Wolfram Alpha infinite calculations, I am not sure whether that implies that my representations are wrong or not, and I know there can be some very accurate near identities . Other very accurate but not exact approximations I have derived have had errors on the order of $10^{-16}$, which makes me inclined to doubt the expressions' accuracy. I have not been able to find either of these purported identities anywhere. My question : does anyone know whether identities $(1)$ and $(2)$ are actually true or not, and if they are not does anyone know what the error terms are through a more accurate approach?","['real-analysis', 'laplace-transform', 'calculus', 'riemann-zeta', 'sequences-and-series']"
1989772,"If $a$ and $n$ are relatively prime, there is a unique natural number $b < n$ such that $ab \equiv_n 1$","I really don't know how to tackle this proof because it has mod in it. There's 3 parts to the question. You don't have to answer all three parts (would be cool to check answer with though), I just need a starting point so get this proof rolling. Question: Relatively Prime: Means if two numbers' greatest common divisor is $1$.
Let $a$ and $n$ be two natural numbers. Prove that if $a$ and $n$ are relatively prime, there exists a unique natural number $b < n$ such that $ab \equiv_n 1$ by doing the following: a) Prove that 
$$\exists b \in \mathbb N, b < n \land ab\equiv_n 1. \tag1$$ b) Add to equation ($1$) in part (a) to express that $b$ is unique. c) Now prove $b$ is unique. (If you need a picture of the question Question picture",['discrete-mathematics']
1989786,Infinite network of resistors,"In Physic, I have to find a way to prove, with equations, that the sum of an infinite network of resistors of 1 $\Omega$ has a limit value. This question is based on the resistor's rules: In a parallel circuit: $R_E = (R_1^{-1}+R_2^{-1}...)^{-1}$ In a series circuit: $R_E = R_1+R_2...$ Here is my scheme: Click to see the image! I begin my mathematical reasoning by using Excel to calculate the most precise value. I discovered that Excel does not compute more that 15 digits... but I still got an overview of the possible answer: 2.73205080756888. I also understood the principle of adding the previous number calculated and just add the new loop to the answer, but my teacher told me that using  series was difficult... So, I decided to search online to find a solution and I found that:
$$R_{eq} = R \cdot (1+\sqrt{3})$$,
but it don't understand how to get up to there. They added a short reasoning: Click to see . Does anyone could add more steps in the reasoning or give me a hint to use series in this particular case? Edits In my excel file, I found that my function to compile the value was :
$$(\text{ANS}^{-1}+1)^{-1}+2$$
Where ANS is the result of the calculation of the third or more loop based on the third loop. The result of my first loop is 3 (sum of the three resistors in serie), the sum of my second loop is calculated based on: 
$$({3}^{-1}+1)^{-1}+2$$, then you realize when calculating that you are adding the previous numbers, so I have used the previous cell number (ANS)","['physics', 'limits']"
1989799,Find the number of onto functions [k] $\to$ [4],"I wish to count the number of onto functions from a $[k]$ set to $[4]$ through considering the complement. Here is what I have in mind, subtract the total number of functions from $[k]$ to $[4],$ $4^k$ with the number of functions that fail to map to all of the $4$ elements in $[4],$ i.e. 
$4^k - [4 + 6(2^k - 2) + 4(3^k - 10)]$ corresponds to the total - [functions mapping to a single element + $2$ elements of $4$ + $3$ elements of $4$] only would be the number of onto functions from $[k]$ to $[4].$ Is this reasoning and formula correct? As of now I am unsure if the $3$ element missed formula is correct, $4(3^k - 10).$ Any thoughts or hints would be appreciated.","['combinatorics', 'functions']"
1989869,"When we speak of a group, must we explicitly specify a certain binary operation?","I was wondering about the ways we say something is a group. For example, the set $$G = \{z \in \mathbb{C} \mid z^n = 1 \text{ for some }n \in \mathbb{Z}^+\}$$ is a group under multiplication. But if I were to just say ""Assume that $G = \{1,a,b,c\}$ is a group of order $4$,"" how can we not specify the binary operation? Is this just saying there exists a binary operation for which it is a group? Edit: Here is a definition of a group that seems to show what I am saying:",['group-theory']
1989878,Radius of a cyclic quadrilateral given diagonals,"I noticed something curious about intersecting chords in a circle. Suppose two chords have lengths $p$ and $q$ and intersect at right angles at point $O$. The intersection $O$ divides the two chords into four total segments of lengths $a,b,c,d$ (say $a+c=p$ and $b+d=q$). The radius of the circle turns out magically to be the root-mean-square $$R=\sqrt{\frac{a^2+b^2+c^2+d^2}{4}}$$ I think it's fascinating, because for other pairs of intersecting chords, the radius is just as much an ""average"" as excenters of triangles are ""centers."" I came up with a more general formula involving more than just right angles, but it's not satisfying. Does anyone have some good insight into why the right angle case is particularly nice? Maybe there isn't anything deep and it strikes me more only because I am a functional analyst. My favorite proof so far is saying $a^2+b^2+c^2+d^2=(AB)^2+(CD)^2$, then rearranging the arcs to make another right triangle with the diameter as hypotenuse: The diameter is the ""third diagonal"" among the three different cyclic quadrilaterals you can make with those four lengths. Turns out, you can generalize to angles other than $90^\circ$ $$R=\frac{\text{third diag.}}{\sin\theta}$$ It's more symmetry than I would have hoped - you just have to think about all three quadrilaterals at once. But, it doesn't deal much with the root-mean-square bit.","['quadrilateral', 'geometry']"
1989879,Define $A^{-1}$ (in some cases) even if $A$ is not an invertible matrix,"$\def\r{\Bbb R}$ 
$\def\q{\Bbb Q}$
As the title suggest, I am trying to do something that I know cannot be done, so my question is confused, and I am trying to make sense of it. Generally: (1) How does one make sense of what I describe below, and (2) are there known results and known terminology applicable, related to my comments? (I am tempted to think of some generalizations of rings, monoids, but I can't make sense of it without using a unit.) So, I was reading about irreducible matrices (and relations to strongly connected graphs, online), after starting with the book Dynamical Systems and Ergodic Theory by Pollicott and Yuri. As an example of an irreducible matrix they give 
$A=\begin{pmatrix} 0 & 1 & 1 \\ 0 & 1 & 1 \\ 1 & 0 & 0 \end{pmatrix}$. Since the first two rows coincide, clearly $\det(A)=0$ and $A$ is not invertible. Nevertheless one may look at powers $A^n$ of $A$, as well as at $A^n-A^{n-1}$. 
Certainly this is possible for $n\ge2$, and my computer (using computer algebra Reduce) happily evaluates the case $n=1$ too, as $A^1-A^{1-1}=\begin{pmatrix} -1 & 1 & 1 \\ 0 & 0 & 1 \\ 1 & 0 & -1 \end{pmatrix}$ (obviously using $A^{1-1}=I=\begin{pmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \end{pmatrix}$), but the case $n=0$, 
that is $A^0-A^{-1}$ generates an error message ``Singular matrix'' (of course, as $A^{-1}$ does not exist). But, it turns out $A^{n+1}-A^n= A^{n-1}$ for $n\ge2$. For example, $n=2$, then $A^3=\begin{pmatrix} 1 & 2 & 2 \\ 1 & 2 & 2 \\ 1 & 1 & 1 \end{pmatrix}$, and $A^3-A^2=\begin{pmatrix} 0 & 1 & 1 \\ 0 & 1 & 1 \\ 1 & 0 & 0 \end{pmatrix}= A^1$. $n=3$, then $A^4=\begin{pmatrix} 2 & 3 & 3 \\ 2 & 3 & 3 \\ 1 & 2 & 2 \end{pmatrix}$, and $A^4-A^3=\begin{pmatrix} 1 & 1 & 1 \\ 1 & 1 & 1 \\ 0 & 1 & 1 \end{pmatrix}= A^2$. $n=4$, then $A^5=\begin{pmatrix} 3 & 5 & 5 \\ 3 & 5 & 5 \\ 2 & 3 & 3 \end{pmatrix}$, and $A^5-A^4=\begin{pmatrix} 1 & 2 & 2 \\ 1 & 2 & 2 \\ 1 & 1 & 1 \end{pmatrix}= A^3$. $n=5$, then $A^6=\begin{pmatrix} 5 & 8 & 8 \\ 5 & 8 & 8 \\ 3 & 5 & 5 \end{pmatrix}$, and $A^6-A^5=\begin{pmatrix} 2 & 3 & 3 \\ 2 & 3 & 3 \\ 1 & 2 & 2 \end{pmatrix}= A^4$. (As seen the Fibonacci numbers are involved too.) From the above, one if tempted to (recursively) define $A^{n-1}=A^{n+1}-A^n$ for all $n\le1$. For example, $A^0=A^2-A^1 = \begin{pmatrix} 1 & 0 & 0 \\ 1 & 0 & 0 \\ -1 & 1 & 1 \end{pmatrix} \not= I$. Even though $A^0$, defined this way, is different from $I$, it acts like $I$ when multiplied to $A^n$, $n\ge1$. For example, $A^0\cdot A=A\cdot A^0=A$, $A^0\cdot A^7=A^7\cdot A^0=A^7$, etc. Also, $(A^0)^2=A^0$, and $(A^0)^n=A^0$ for $n\ge1$. Similarly, one may define $A^{-1}=A^1-A^0 = \begin{pmatrix} -1 & 1 & 1 \\ -1 & 1 & 1 \\ 2 & -1 & -1 \end{pmatrix}$. (And, one may define $A^{-n}$ for all $n\ge1$.) Even though $A$ is not invertible, the $A^{-1}$ as defined above behaves like an inverse of $A$, namely $A^{-1}\cdot A=A\cdot A^{-1}=A^0 = 
\begin{pmatrix} 1 & 0 & 0 \\ 1 & 0 & 0 \\ -1 & 1 & 1 \end{pmatrix}$. So, my (confused) question (in addition to (1) and (2) at the beginning) is: 
(3) What am I observing (assuming it has already observed and is well-known)? Edit. I think I understand better what I was asking (or what had confused me) and will post my comments here. This is essentially an answer, but I will leave the option open for someone else to post their answer, as they find appropriate, as the question was a bit open ended, and may get different types of answers. 
(Also, after typing this edit, I feel there are more details to be verified.) QiaochuYuan left a comment which I initially did not understand, but now I think he meant something along what is illustrated by the following example. Let $F=\{\begin{pmatrix} x & 0  \\ 0 & 0 \end{pmatrix}: x\in\r\}$. Then $F$ is a field isomorphic to $\r$, with additive identity $O=\begin{pmatrix} 0 & 0  \\ 0 & 0 \end{pmatrix}$ and multiplicative identity $U=\begin{pmatrix} 1 & 0  \\ 0 & 0 \end{pmatrix}$, and if $X=\begin{pmatrix} x & 0  \\ 0 & 0 \end{pmatrix}\not=O$ then $X^{-1}=\begin{pmatrix} x^{-1} & 0  \\ 0 & 0 \end{pmatrix}$. The latter does not contradict the fact that $\begin{pmatrix} x & 0  \\ 0 & 0 \end{pmatrix}$, as a matrix, is not invertible. If $Id=\begin{pmatrix} 1 & 0  \\ 0 & 1 \end{pmatrix}$ is the identity matrix, this looks like a contradiction, having two different multiplicative identities, namely $U$ and $Id$, but there is no contradiction as simply $Id$ does not belong to $F$. It didn't seem that QiaochuYuan addressed the identity $A^{n+1}-A^n= A^{n-1}$ for $n\ge2$ (and the latter seemed special to me). Let $E= \begin{pmatrix} 1 & 0 & 0 \\ 1 & 0 & 0 \\ -1 & 1 & 1 \end{pmatrix}$ (which I had denoted by $A^0$ above, but I prefer $E$ now). $E$ is the multiplicative identity of the structure described in my question, and I was puzzled as it looked like there were two different multiplicative identities, namely $E$, and $I= \begin{pmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \end{pmatrix}$. It seemed to me that if we use the usual matrix multiplication, then there was only one choice for the multiplicative identity, namely $I$. The matrix $E$ isn't even a diagonal matrix, and it looked strange it would be a multiplicative identity 
(and I must have forgotten that matrices have normal forms). Well, I verified the details later, and $E$ is indeed the multiplicative identity, while $I$ simply does not belong to this structure. Call the structure hinted at in my question $K$. So $K$ contains 
$A=\begin{pmatrix} 0 & 1 & 1 \\ 0 & 1 & 1 \\ 1 & 0 & 0 \end{pmatrix}$ as well as 
all $A^n$, $n\ge1$ (usual matrix multiplication). We have that $A^{n-1}=A^{n+1}-A^n$ for all $n\ge2$, and this suggest that $E=A^2-A= \begin{pmatrix} 1 & 0 & 0 \\ 1 & 0 & 0 \\ -1 & 1 & 1 \end{pmatrix}$ would play the role of the multiplicative identity. Once this is done, we could define the inverse of $A$, as $A-E$ (where $E$ plays the role of $A^0$). I had used the notation $A^{-1}$ in my question, but I confuse myself with that as I think in this context it should be reserved for matrix inverse (which for $A$ does not exist). So, if $n\ge1$, I will denote the multiplicative inverse of $A^n$ (in $K$) by $A^{[-n]}$. In particular, $A^{[-1]}=A-E=\begin{pmatrix} -1 & 1 & 1 \\ -1 & 1 & 1 \\ 2 & -1 & -1 \end{pmatrix}$, then $A^{[-2]}=E-A^{[-1]}=\begin{pmatrix} 2 & -1 & -1 \\ 2 & -1 & -1 \\ -3 & 2 & 2 \end{pmatrix}$, next $A^{[-3]}=A^{[-1]}-A^{[-2]}$, etc. (using the identity $A^{n-1}=A^{n+1}-A^n$ as a model). Let $S=\{A^{[-n]}:n\ge1\}\cup\{E\}\cup\{A^n:n\ge1\}$. Then $S$ is a commutative ring under usual matrix multiplication, with identity element $E$. Since of course we could add and subtract the elements of $S$ (as matrices), I was confused that $S$ is a field, and I knew that couldn't be, as the multiplicative group should contain a copy of the rationals $\q$, whereas $S$ seems isomorphic as a group to $(\Bbb Z,+)$. (But it was getting late.) I had simply forgotten that $S$ is not closed under addition (and subtraction). 
So $S$ is not a field, but it generates a field. Let $K$ be the field that is generated by $S$. I will present a couple of more specific descriptions of $K$ below. First, every element of $S$ is of the form $\begin{pmatrix} q & r & r \\ q & r & r \\ p & q & q \end{pmatrix}$, with $p+q=r$ (so obviously such an element is completely determined by $p$ and $q$). Every element of $K$ is of this form too, where $p,q,r\in\q$ and $p+q=r$. The operations are usual matrix addition and multiplication, with the usual zero matrix, but with $E$ for the multiplicative identity. Suppose that there is a field isomorphism $h:K\to L \subset \r$. (There is one, indeed, described below.) Let $a=h(A)$, then $1+a=a^2$ since $E+A=A^2$. The solutions for $a$ are the golden section $\varphi=\frac{1+\sqrt{5}}2\approx1.618$ and $\psi=\frac{1-\sqrt{5}}2\approx-0.618$. Thus, $K$ is isomorphic to the field extension $\q(\sqrt{5})$ (hmm, I didn't verify if matrix multiplication goes into usual multiplication in $\r$, so I may be wrong, but will keep writing). Let $(p,q)$ abbreviate the matrix $\begin{pmatrix} q & r & r \\ q & r & r \\ p & q & q \end{pmatrix}$, where $p+q=r$. Then $h(E)=h(-1,1)=1$, $h(A)=h(1,0)=a$, and 
$h(A^2)=h(0,1)=a^2$. Thus $h(p,q)=pa+qa^2$. Note also that $\pm\sqrt{5}=3a-a^2$. There are two possibilities for $h$. Either (1), $a=\varphi$ and then $h(p,q)=\frac{p+3q}2+\frac{p+q}2\sqrt{5}$, or (2), $a=\psi$ and then $h(p,q)=\frac{p+3q}2-\frac{p+q}2\sqrt{5}$. I feel I didn't verify all details, but it is getting late again. If what I wrote in this edit is incorrect, then the question remains as to explain what the above example is or does.","['recurrence-relations', 'dynamical-systems', 'matrices', 'abstract-algebra', 'algebraic-graph-theory']"
1989900,6 fair coin flips: probability of exactly 3 heads,"When a certain coin is flipped, the probability of heads is $0.5$. If the coin is flipped $6$ times, what is the probability that there are exactly $3$ heads? The answer is $\frac5{16}$. I wonder why it isn't $\frac12$. Since a fair coin flip results in equally likely outcomes, any sequence is equally likely… I know why it is $\frac5{16}$. We divide the number of possible outcomes with exactly 3 heads by the total possible outcomes. What bothers me is how I should think about it so I won't make a mistake anymore. Why is $\frac12$ not right? I need to get intuition.",['probability']
1989935,Evaluating the improper integral $\int_0^\infty \frac{x\cos x-\sin x}{x^3} \cos(\frac{x}{2}) \mathrm dx $,"I've been working through the following integral and am stumped: $$\int_0^\infty \frac{x\cos x-\sin x}{x^3}\cos\left(\frac{x}{2}\right)\mathrm dx$$ Given the questions in my class that have proceeded and followed this integral, I believe that this is some form of Fourier transform/integral. However, it doesn't look like any of the content surrounding it. That is, there is no $e^{-ikx}$ or $g(k)$ or anything else that I'm familiar with. I know that it's an even function, but that's about as far as I can get. If I try to split it over the subtraction, I get two non-converging integrals, so that wasn't much help either. I've been throwing lots of trig identities at it but nothing familiar has appeared yet. Any help would be greatly appreciated.
Thank you.","['fourier-analysis', 'calculus', 'improper-integrals', 'integration', 'fourier-transform']"
1989950,Problem in proof of open mapping theorem?,"I was doing proof of open mapping theorem from the book Walter Rudin real and complex analysis book and struck at one point. Given if $X$ and $Y$ are Banach spaces and $T$ is a bounded linear operator between them which is $\textbf{onto}$. Then to prove $$T(U) \supset \delta V$$ where $U$ is open unit ball in $X$ and $\delta V = \{ y \in Y : \|y\| < \delta\}$. Proof- For any $y \in Y$ since map is onto, there exist an $x \in X$ such that $Tx = y$. It is also clear that if $\|x\| < k$, then $y \in T(kU)$ for any $k$. Clearly $$Y = \underset{k \in \mathbb{N}}{\cup}  T(kU) $$ But as $Y$ is complete, by Baire category theorem it can't be written as countable union of nowhere dense sets. So there exist atleast one $k$ such that $ T(kU)$ is not nowhere dense.  Thus this means $$(\overline{T(kU)})^0 \ne \emptyset$$ i.e. $ T(kU)$ closure has non empty interior. Let $W$ be open set contained in closure of  $T(kU)$. Now for any $w \in W \implies w \in \overline{T(kU})$, so every point of $W$ is the limit of the sequence $\{Tx_i\}$, where $x_i \in kU$, Let us now fix $W$ and $k$. Now choose $y_0 \in W$ and choose $\eta > 0$, so that $y_0+y \in W$ if $\|y\| < \eta$. This can be done as $W$ is open set, so every point of it has some neighborhood also there. Now as $y_0 , y_0+y \in W$ from above paragraph  there exist sequences $\{x_i'\}$ and $\{x_i''\}$ in $kU$ such that $$T(x_i') \to y_0 \qquad T(x_i'') \to y_0+y \quad as \ i \to \infty$$ Set $x_i = x_i'-x_i''$. Then clearly $$\|x_i\| \leq \|x_i'\| + \|x_i''\| < 2k$$ and $T(x_i) \to y$. Since this holds for every $y$ with $\|y\|< \eta$. Now it is written that, the linearity of $T$ shows that following is true for $\delta = \dfrac{\eta}{2k}$ To each $y \in Y$ and to each $\epsilon > 0$ there corresponds an $x \in X$ such that $$\|x\| \leq \delta^{-1}\|y\| \quad \text{and} \quad \|Tx-y\| < \epsilon \quad (1)$$ How does this follows? This proof is given in Walter rudin 3rd edition on page 112","['functional-analysis', 'banach-spaces', 'analysis']"
1989954,Elementary proof for a generalized version of Pascal's hexagon theorem?,"I saw a generalization version of Pascal's theorem on a book, which is actually proved by deep algebraic geometry theorems (e.g., Cayley-Bacharach-Chasles theorem, or Bézout's theorem). I just wonder whether we can prove it by elementary/synthetic methods (e.g., perspective points, or invariance of cross-ratios and properties of second order point-rows)? Given six points $A,B,C,D,E,F$ on a conic, we take another point $G$ and draw two conics, one (denoted as $a$) constructed from $A,B,G,E,F$ and another (denoted as $b$) from $B,C,D,G,E$. Two conics $a$ and $b$ intersect on four points $B,G,E,H$. Suppose $AF\cap CD=O$. Prove: $G$, $O$ and $H$ are co-linear.","['projective-geometry', 'alternative-proof', 'algebraic-geometry', 'geometry']"
1989957,Does the Laplace Transform have any practical use or provide any mathematical insight?,"Mathematics essentially is the study of the transformation of symbols according to specific rules (inference rules/axioms).  However we don't just study any arbitrary system of mathematics; we carefully pick ones that make it easier to understand and create solutions for the real world. What exactly has the Laplace Transform helped simplify or understand better (in addition to the various simpler tools we already have, Fourier Transforms and Linear Algebra)? In control systems analysis, I've seen the Laplace transform being used to create $s$-domain transfer functions that represent linear time-invariant systems.  However, when various graphs for analysis are created (Nyquist, Nichols, Bode) we substitute $\mathbb{j}\omega$ into the $s$-domain functions.  This would make it equivalent to a Fourier transform. The poles of the $s$-domain function are used to help understand the stability of a system.  It can be shown that these poles are the same as the eigenvalues of the linear operator; however the eigenvalues of the linear operator can be clearly associated with their time-domain modes and gives a direct understanding of why an LTI-system is stable if the eigenvalues are all less than 0. Is there any particular application of the Laplace transform that clearly makes something easier to understand or do?  Why is the Laplace transform so heavily taught in schools?","['control-theory', 'ordinary-differential-equations', 'laplace-transform']"
1989980,"If $\int_1^ \infty \frac {x^3+3}{x^6(x^2+1)} \, \mathrm d x=\frac{a+b\pi}{c}$, then find $a,b,c$.","If $$\int_1^ \infty \frac {x^3+3}{x^6(x^2+1)} \, \mathrm d x=\frac{a+b\pi}{c} $$ then find $a, b, c$ . Now, using partial fractions I calculated $$a = 62-10\ln (2) \qquad\qquad b = -15 \qquad\qquad c = 20$$ but it took me more than 45 minutes to do all the work. The question was asked in an MCQ exam where only 4-5 minutes are available. I am probably missing something which can help to solve it. Thanks! Note it was asked in an exam for students of grade 12 so I basically don't know very complex integrations thus I am searching for integration via elementary functions only.","['integration', 'definite-integrals']"
1989999,Classify groups of order $pq^2$ using semidirect product,"I am struggling with semidirect products and how they can be used to classify groups of a certain order. In particular, I need help with the nonabelian case. This is the problem I am working with.. Classify all groups of order $pq^2$ with $p$,$q$ primes, $p<q$,
  $p\nmid(q-1)$, and $p^2\nmid(q+1)$. Use can use the fact that $GL_2(\mathbb{Z}_q)$ has $(q^2-1)(q^2-q)$ elements. Ok. So here's my thought process. I first considered when $G$ was abelian and applied the Fundamental Theorem of Finitely Generated Abelian Groups (FTFGAG) to obtain all abelian groups of this order. My results were: $\mathbb{Z}_{pq^2}$ and $\mathbb{Z}_{pq}\times\mathbb{Z}_q$. Next considered when $G$ was nonabelian and applied Sylow's Theorem to determine how many Sylow $p$ and $q$ subgroups there were in $G$. I found the Sylow $q$-subgroups to be unique, and hence normal. I let the Sylow $q$-subgroup be called $H$. I let $K$ be any Sylow $p$-subgroup in $G$. Then by Lagrange, $H\cap K=1$. Next I showed that $G=HK$ and let $\varphi: K\rightarrow \text{Aut}(H)$ be a homomorphism. Then by applying theorem 12 from Dummit and Foote (sorry it didn't have a name :/), I got $G\cong H\rtimes_\varphi K$. Now I just need to consider all isomorphisms of $H$. They are $\mathbb{Z_{q^2}}$ and $\mathbb{Z}_q\times\mathbb{Z}_q$. Suppose $H=\mathbb{Z_{q^2}}$. Then $|\text{Aut}(H)|=q(q-1)$. Since $p\nmid q$ and $p\nmid q-1$, there does not exist an element of order $p$ in $\text{Aut}(H)$ by Lagrange. This means the only homomorphism is trivial. Therefore $H\rtimes_\varphi K\cong \mathbb{Z}_{q^2}\times \mathbb{Z}_p$. But this is abelian and contradicts my assumption that $G$ is nonabelian. Plus FTFGAG, already classified all abelian groups. Therefore $H=\mathbb{Z}_{q^2}$ does not result in a new group. And here is where I start to get lost... Suppose $H=\mathbb{Z_q}\times\mathbb{Z_q}$. Then $|\text{Aut}(H)|=(q^2-1)(q^2-q)$. I do not see how $p$ divides this... Help with this last part would be much appreciated. Thanks. Also here are some resources I have looked at: https://crazyproject.wordpress.com/2010/06/25/classify-the-groups-of-order-75/ http://www.math.purdue.edu/~lipman/5532011/order-p%5E2q.pdf","['abstract-algebra', 'semidirect-product']"
1990048,Example appliction of Nash-Moser inverse function theorem,"I have basic knowledge of PDE and know how to use the standard (Banach space) inverse function theorem to solve
$$
-\Delta u+ g(u)=f
$$
when $g(0)=g'(0)=0$ and $f$ is small: Define $A(u):=-\Delta u+g\circ u$. Then $A(0)=0$ $A'(0)v=-\Delta v$ is invertible for example if we consider $A\colon C^{2,\alpha}\to C^{0,\alpha}$ and $A'(0)\colon C^{2,\alpha}\to C^{0,\alpha}$. Therefore, for small enough $\|f\|_{C^{0,\alpha}}$, there is a solution $u\in C^{2,\alpha}$ of $A(u)=f$. Is there a similarly simple example for the application of the Nash-Moser inverse function theorem? A side question that is easier to answer than the main question: According to Wikipedia, the Nash-Moser theorem is helpful when the inverse of the derivative loses derivatives. Does this mean that the inverse is for example a map $C^{0,\beta}\to C^{2,\alpha}$ with $\beta>\alpha$ or does it actually mean that derivatives are lost in the sense that the inverse is for example a map $C^{2,\beta}\to C^{2,\alpha}$ with $\beta>\alpha$? In any case, why would this preclude application of the standard inverse function theorem (on smaller spaces)?","['functional-analysis', 'nonlinear-analysis', 'inverse-function-theorem', 'partial-differential-equations']"
1990066,How does $(Ax -b)^T(Ax -b)$ reduce to $x^TA^TAx − 2b^TAx + b^Tb$?,"I am not sure if I can write $(Ax -b)^T$ as $(A^Tx^T -b^T)$. If I can, I can't reproduce the above result. Please help. Also refer to any sources that will give me a good insight in matrix derivatives.","['matrices', 'partial-derivative', 'derivatives']"
1990080,Sequence of triangles with exponentiated sides,"Let $a,b,c\in\Bbb R^+$. For any given $n\in\Bbb N$ there exists a triangle with sides $a^n,b^n,c^n$. Show that at least two of $a,b,c$ are equal. I know that you can create inequalities for $a^n,b^n,c^n$, but what's next?","['real-analysis', 'triangles', 'geometry']"
1990118,minkowski distance at the infinity,"Given that the Minkowski distance between points $X = (x_1,\dots,x_n)$ and $Y = (y_1,\dots ,y_n)$ is
$$
d(X, Y)
  = \left(\sum_{i=1}^n|x_i−y_i|^p\right)^{1/p},
$$
I want to show that
$$
\lim_{p\to\infty}d(X, Y) = \max_{i=1, \dots, n} |x_i-y_i|.
$$ How can I prove that as $p$ approaches infinity, the Minkowski distance approaches maximum difference of coordinates?","['normed-spaces', 'limits', 'geometry']"
1990127,"Why $\lim\limits_{(x,y)\to(0,0)}\frac{\sin(x^2+y^2)}{x^2+y^2}=\lim\limits_{t\to 0}\frac{\sin t}{t}$?","Why $\displaystyle\lim_{(x,y)\to(0,0)}\frac{\sin(x^2+y^2)}{x^2+y^2}=\lim_{t\to 0}\frac{\sin t}{t}$( and hence equals to $1$)? Any rigorous reason? (i.e. not just say by letting $t=x^2+y^2$.)",['analysis']
1990145,How can mathematical induction prove something?,"I am learning mathematical induction, and the concept still does not fit in my mind. I just cannot understand how I can prove something just by: 1) basis: calculating whether it fits for the minimal $n$, where $n$ belongs to $N$. 2) inductive step: I JUST assume that the statement that I set at the start works for any $n\leq m$, then it also works for $(m+1)$ On what basis can I say that the statement is proven? Based on the fact that I have found the formula from the first part of the inductive step in the formula of the second part of the inductive step , substituting the first one for the second and getting the same result as I assumed in the inductive step ? I cannot get it. Maybe I am misunderstanding the whole concept of mathematical induction. If that is the truth, then I am sorry. Can anyone explain to me in human language why I can say that a statement is proven when I perform mathematical induction on that statement?","['induction', 'discrete-mathematics']"
1990167,How to prove the following properties of infimum and supremum involving the union and intersection of the sets $A_k$,"I am reading a book on probability theory and I have troubles understanding why the following holds $$
   \sup_{k \ge n} A_k = \bigcup_{k\ge n} A_k
$$ $$
\inf_{k \ge n} A_k = \bigcap_{k\ge n} A_k
$$ I know how to define infimum and supremum, but I have troubles proving the above expressions. Unfortunately, the book states those expressions as a definition without proving them. A graphical explanation in terms of a Venn diagram will be very helpful. 
Thank you in advance","['probability-theory', 'supremum-and-infimum']"
1990212,Can I solve x on this way? or is there a mistake I made or is the question wrong?,"$$\cos3x\sin2x=\cos3x$$
Can I just pull $\cos3x$ out of both sides and continue with $\sin2x=0$ which leaves us with $2x=0$?",['trigonometry']
1990320,"How do I simplify $\sum_{k=1}^n \gcd(k,n)$? [duplicate]","This question already has an answer here : Sum of GCD(k,n) (1 answer) Closed 7 years ago . For a given positive integer $n$, how do I simplify $$\sum_{k=1}^n \gcd(k,n)?$$ By simplification I mean is there any formula which makes it easier to compute it (rather than just compute each term and sum up)?","['number-theory', 'elementary-number-theory']"
1990396,"Prob. 11, Chap. 3, in Baby Rudin: If $a_n > 0$ and $\sum a_n$ diverges, then how do we show that $\sum \frac{a_n}{1+a_n}$ too diverges?","Here's Prob. 11, Chap. 3, in the book Principles of Mathematical Analysis by Walter Rudin, 3rd edition: Suppose $a_n > 0$ , $s_n = a_1 + \cdots + a_n$ , and $\sum a_n$ diverges. (a) Prove that $\sum \frac{a_n}{1+ a_n}$ diverges. [ I have no clue of how to prove this!] (b) Prove that $$ \frac{a_{N+1}}{s_{N+1}} + \cdots + \frac{a_{N+k}}{s_{N+k}} \geq 1- \frac{s_N}{s_{N+k}}$$ [I can show this.] and deduce that $\sum \frac{a_n}{s_n}$ diverges. [How to?] (c) Prove that $$ \frac{a_n}{s_n^2} \leq \frac{1}{s_{n-1}} - \frac{1}{s_n}$$ and deduce that $\sum \frac{a_n}{s_n^2}$ converges. [This I can show, I think.] (d) What can be said about (the convergence or divergence of) $$\sum \frac{a_n}{1+ n a_n} \ \ \ \mbox{ and } \ \ \ \sum \frac{a_n}{1+ n^2 a_n}?$$ [ How to answer this?] I would prefer those answers that use only the machinary developed by Rudin himself upto this point in the book. Here's what I can show: Since $a_n > 0$ , we have $0 < s_{N+1} < \cdots < s_{N+k}$ and so $$ \frac{a_{N+1}}{s_{N+1}} + \cdots + \frac{a_{N+k}}{s_{N+k}} \geq \frac{a_{N+1} + \cdots + a_{N+k}}{s_{N+k}} =  1- \frac{s_N}{s_{N+k}}.$$ As $a_n > 0$ , so, for all $n = 2, 3, 4, \ldots$ , we have $0 < s_{n-1} < s_n$ and therefore $$ \frac{a_n}{s_n^2} = \frac{s_n - s_{n-1}}{s_n^2} \leq \frac{s_n - s_{n-1}}{s_n s_{n-1}} = \frac{1}{s_{n-1}} - \frac{1}{s_n},$$ and hence $$ 0 \leq \sum_{k=1}^n \frac{a_k}{s_k^2} = \frac{1}{a_1} + \sum_{k=2}^n \frac{a_k}{s_k^2} \leq \frac{1}{a_1} + \sum_{k=2}^n \left( \frac{1}{s_{k-1}} - \frac{1}{s_k} \right) = \frac{1}{a_1} + \frac{1}{s_1} - \frac{1}{s_n} \to \frac{2}{a_1} + 0 $$ as $n \to \infty$ because $a_n > 0$ and $\sum a_n$ diverges and hence $s_n = a_1 + \cdots + a_n \to \infty$ as $n \to \infty$ . So if $\lim_{n\to\infty} \sum_{k=1}^n \frac{a_k}{s_k^2} $ exists [ but how to show this?}, then we must have $$ 0 \leq \lim_{n\to\infty} \sum_{k=1}^n \frac{a_k}{s_k^2} \leq \frac{2}{a_1}.$$ Am I right?","['real-analysis', 'convergence-divergence', 'sequences-and-series', 'analysis']"
1990442,Integrate $I=\int_0^1\frac{\arcsin{(x)}\arcsin{(x\sqrt\frac{1}{2})}}{\sqrt{2-x^2}}dx$,"How to prove 
\begin{align}
 I &= \int_0^1\frac{\arcsin{(x)}\arcsin{(x\sqrt\frac{1}{2})}}{\sqrt{2-x^2}}dx \\
   &= \frac{\pi}{256}\left[ \frac{11\pi^4}{120}+2{\pi^2}\ln^2{2}-2\ln^4{2}-12\zeta{(3)}\ln{2} \right]
\end{align}
 By asking  $$x=\sqrt{2}y$$ then using integration by parts, we have
 $$I=\frac{\pi^5}{2048}-\frac{1}{4}\int_0^1{\arcsin^4\left( \frac{z}{\sqrt{2}}\right) }\frac{dz}{\sqrt{1-x^2}}$$ But how to calculate this integral? I would appreciate your help","['integration', 'definite-integrals', 'calculus']"
1990504,How to find the coordinates of the vertices of a pentagon centered at the origin,"I am attempting to follow this tutorial here: http://www.mathopenref.com/polygonradius.html My goal is to find the coordinates of vertices of a pentagon, given some radius. For example, if I know that the center is at $(0,0)$, and my radius is $8.1$, what formula can I use to get the coordinates of points A, E, B, D, C, if I know the center point between D, C (i.e $(0,5)$",['geometry']
1990517,How do I do this proof? $(A \cup B) - C = (A - C) \cup B \iff B \cap C = \emptyset$,"$(A \cup B) - C = (A - C) \cup B \iff B \cap C = \emptyset$ I know that for this problem, $C$ is removed from $A \cup B$ I also know that $(A - C) \cup B$ can be rewritten as $(A \cup B) - (C \cup B)$, but not sure what exactly that means. My assumption is that $A \cup B$ remains after removing $C \cup B$ leaving me with just $A \cup B$, but that doesn't seem to make sense if $C \cup B$ was removed. Am I just left with $A$ in this part? I'm also a bit confused on how $B \cap C = \emptyset$ Would the proof then go as follows? 1) $(A \cup B) - C \subseteq (A - C) \cup B$ 2) $(A - C) \cup B \subseteq (A \cup B) - C$ 3) $B \cap C \subseteq \emptyset$ 4) $\emptyset \subseteq B \cap C$ Would I then show that: 5) $(A \cup B) - C = (A - C) \cup B \Rightarrow B \cap C = \emptyset$ 6) $B \cap C = \emptyset \Rightarrow (A \cup B) - C = (A - C) \cup B$ Am I on the right path? If so, how do I go about formulating each step? Seems like 6 different proofs in one is a bit much.","['proof-writing', 'elementary-set-theory', 'proof-explanation']"
1990525,How to account for stretching in graph transformation of $y = \sqrt{x}$?,"Hi guys, I got this question as an assignment from my university and have been trying to solve it for a whole day now but can't get the correct answer. Well, I know how to shift Graph towards left, right, upwards and downwards $C$ points. Well for example current Graph's equation is $y = x^2$ and if we have to move graph to left $C$ points. We will add $C$ to the function and it will become $y = (x+C)^2$ and if we have to shift Graph to right side $C$ points, then we will subtract $C$ from function, and the equation will become $y = (x-C)^2$, and similarly add $C$ to the $f(x)$ and subtract $C$ from $f(x)$ if we want to shift graph upwards $C$ points and downwards $C$ points respectively, and if we want to reflect it about $x$-axis, we will multiply $f(x)$ with minus ""-"" sign and if we want to reflect it about $y$-axis we will multiply the function with minus""-"" sign thats makes it like $y = f(-x)$. Well now you now that I know these things. But I have been trying to solve this question and its been a day but I am not able to solve it correctly. Kindly help me, I want to submit my Assignment and I really do not want to lose even a single marks from Mathematics. And yeah I forgot to tell that I have already figured out that the graph in second picture is reflected about $x$-axis and then moved $1$ unit/point toward left side and moved $1$ unit/point downwards, but if you look carefully the graph in second picture is little stretched as well and thats where I am getting problem because I am not figuring out that is it stretched towards x-direction or y-direction and also can't figure out that how many points/units it have stretched.","['transformation', 'functions']"
1990567,Pointwise convergence vs norm convergence in $X^*$,"Let $X$ be a normed space, $X^*$ its dual space and $\left\|{T}\right\|=\sup\{|T(x)|:\left\|x\right\|=1\}$, the usual norm in $X^*$. Let $(T_n)\subseteq X^*$. It is true that if $T_n\to 0$ in $X^*$ then $T_n$ converges pointwise to zero, because for every $x\in X$ we have $|T_n(x)|\le \left\|{T_n}\right\|\left\|{x}\right\|$. The converse is not true. However, in all counterexamples I've seen we have $\dim X=\infty$. Could it be true if $\dim X<\infty$? If not, could anyone help me to find a counterexample even in this case? Thank you.","['functional-analysis', 'normed-spaces']"
1990635,Finding a minimal polynomial over $\mathbb{Q}(\sqrt5)$,"The question is to find the minimal polynomial of $\sqrt{2}+\sqrt{7}$ over $\mathbb{Q}(\sqrt{5})$ . First, I found its minimal polynomial over $\mathbb{Q}$ which is equal to $X^4 - 18X^2 + 25$ . I suppose this could already be a candidate for a minimal polynomial over $\mathbb{Q}(\sqrt{5})$ so I tried proving that using the tower property, but I don't think that's the right approach.","['irreducible-polynomials', 'abstract-algebra', 'field-theory', 'minimal-polynomials']"
1990638,Affine twisted cubic realized as intersection of quadratic surfaces?,"This is a purely affine variety. Define $F_1=y-x^2, F_2=z-xy, F_3=xz-y^2$. It is clear that $(x,x^2,x^3)$ is a solution to $F_1=F_2=F_3=0$. Since projective twisted cubic is not intersection of two quadractics which contains an extra line, I would not expect this to be the case in affine as well. However, $F_1\cap F_2$ seems to be exactly twisted cubic curve and I could not see any extra information on the other line. The other two intersections(i.e. $F_2\cap F_3$ and $F_1\cap F_3$ do yield two extra lines. What have I done wrong here?","['affine-geometry', 'algebraic-geometry']"
1990662,Completeness of Measure spaces,"A metric space X is called complete if every Cauchy sequence of points in X has a limit that is also in X. It's perfectly clear to me. A measure space $(X, \chi, \mu)$ is complete if the $\sigma$-algebra contains all subsets of sets of measure zero. That is, $(X, \chi, \mu)$ is complete if $N \in \chi$, $\mu (N) = 0$ and $A \subseteq N$ imply $A \in \chi$. Technically, I could understand the definition, but can't get the logic behind it. Questions: 1) Why do we care only about subsets of sets of measure zero to determine completeness? 2) How does the completeness of measure spaces relate to a completeness of metric spaces? 3) Could you suggest a concrete elementary example of a measure space (preferably, with simple sets) that isn't initially complete and then is completed?","['functional-analysis', 'measure-theory']"
1990675,Vector space of $m\times n$ matrix $\Bbb R^{m\times n}$ vs vector space of a vector of size $mn$ $\Bbb R^{mn}$?,"I have a very basic question in linear algebra. Every vector of size $n$ with each entry from $\Bbb R$ lies in the space $\Bbb R^n$ , where $\Bbb R^n$ is the cartesian product of $n$ copies of the set $\Bbb R$ . But how is it different from the vector space of matrices? It is written in my books that the vector space of matrices is $\Bbb R^{m\times n}$ , but what does that mean? What is $\Bbb R^{m\times n}$ ? Because if it is the same as $\Bbb R^{mn}$ , then how is an $m\times n$ matrix different from an $mn$ dimensional vector?","['matrices', 'linear-algebra', 'vector-spaces']"
1990679,"Approximation on partitions in $L^2([0,1]\times \Omega)$","I’m working on Nualart’s book “The Malliavin calculus and related topics” and in the proof of lemma 1.1.3 he mentions that the operators $P_n$ have their operator norm bounded by 1. I fail to see why, can you help me? Using Jensen’s inequality I get a norm more akin to $2^n$, so I guess Jensen is too weak to prove that? Quoting the proof: Let $u$ be a process in $L^2_a([0,1]\times\Omega)$ ($L^2_a$ are the adapted processes w.r.t Brownian motion) and consider the sequence of processes defined by
$\tilde u^n(t)=\sum_{i=1}^{2^n-1}2^n\left(\int_{(i-1)2^{-n}}^{i2^{-n}}u(s)ds\right)1_{]i2^{-n},(i+1)2^{-n}]}(t)$. We claim that the sequence converges to $u$ in $L^2([0,1]\times\Omega)$. In fact define $P_n(u)=\tilde u^n$. Then $P_n$ is a linear operator in $L^2([0,1]\times\Omega)$ with norm bounded by one.","['stochastic-processes', 'malliavin-calculus', 'probability-theory', 'functional-analysis', 'measure-theory']"
1990691,Prove that a homomorphism $\phi$ must be trivial.,"Let $G,H$ be finite groups where $|G|$ and $|H|$ are coprime. Prove that any homomorphism $\phi :G\rightarrow H$ must be trivial $($ie. $\phi (x)=e_H, $ the identity element of $H, \forall x\in G)$. We know that $Ker(\phi )$ and $Im(\phi )$ are subgroups of $G$ and $H$, respectively. Then, the Lagrange Theorem asserts that $|Ker(\phi )|$ divides $|G|$ while $|Im(\phi )|$ divides $|H|$. I am trying to show that $|Im(\phi )|=1 \implies |Ker(\phi )|=|G| \implies \phi$ is trivial. I can show this last series of implications and the first part separately. How do I make the leap from where I left off to $|Im(\phi )|=1$? Side note: I am using the Range-Kernel Theorem as well: $|Im(\phi )|\times |Ker(\phi )|=|G|$.","['finite-groups', 'abstract-algebra', 'group-theory', 'group-homomorphism']"
1990704,Find the power series of $f(x)=\frac{1}{x^2+x+1}$,"I want to find the power series of $$f(x)=\frac{1}{x^2+x+1}$$
How can I prove the following?
$$f(x)=\frac{2}{\sqrt{3}} \sum_{n=0}^{\infty} \mathrm{sin}\frac{2\pi(n+1)}{3} x^n  \,\,\,\, |x|<1$$ In particular I would like to know how to proceed in this case. The polinomial $x^2+x+1$ has no roots so here I cannot use partial fraction decomposition: what method should I use?","['power-series', 'taylor-expansion', 'sequences-and-series', 'calculus']"
1990743,The smooth atlas of a manifold,"Suppose that $M$ is a smooth manifold with an atlas $A$, and $p$ is a point of $M$. pick a smooth chart $(U,\phi)$ such that $p \in U$, then a trick we often use is that we can always let $\phi(p) = 0$. The reason is that if $\phi(p) \neq 0$, we can simply compose it with a translation map. My question is, if we do compose it with a translation map, how am I able to guarantee that this composition is still in the original atlas $A$? If it is not in $A$, then how am I able to conclude that this change of charts will not have any impact on the structure of $M$?","['smooth-manifolds', 'differential-geometry', 'differential-topology']"
1990852,Arzela-Ascoli compact-open topology,"If we consider the following theorem we note that $\mathcal{F}$ is compact and $f_n\in\mathcal{F}$ , my question is why the sequence $f_n$ admits a convergent subsequence. note : If $\mathcal{F}$ is compact, that does not imply that $\mathcal{F}$ is sequentially compact. Any hint would be appreciated.","['functional-analysis', 'general-topology', 'metric-spaces']"
1990854,Differential equation $f''(x)+2 x f(x)f'(x) = 0$,"I am trying to solve, $ f''(x)+2 x f(x)f'(x) = 0$ with boundary conditions $f(-\infty)=1$ and $f(\infty)=0$. I have found that for instance $f(x) = 3/2 x^{-2}$ but obviously it does not satisfy the proper boundary conditions. Any ideas for a solution?","['ordinary-differential-equations', 'nonlinear-system']"
1990899,Connection between linearly independent vectors and projective points in general position,"I'm trying to understand the connection between the notions of linear independence and general position . I have no background in geometry, so first I'll start with what I know and then I'll pose specific questions, please bear with me and correct me at any point. Let $q$ be a prime power, $d$ be a nonnegative integer, and $V$ be a $(d+1)$-dimensional vector space over the finite field $F_q$ with $q$ elements. For $v \in V$ denote 
$$[v] = \left\{ cv \mid c \in F_q, c\neq 0 \right\}.$$
Then the collection of symbols $[v]$ can be seen as the points of 
the $d$-dimensional projective space PG(d,q). 
Furthermore, for a $(k+1)$-dimensional subspace $S$ of $V$, the set 
$$\left\{ [s] \mid s \in S \right\}$$
is a $k$-flat of $PG(d,q)$ . From what I read in pg. 19 of these notes I assume that this definition of the notion of ""general position"" is correct: We say that $m$ points in $PG(d,q)$ are in general position if they
  are not contained in any $(m-2)$-flat. So, to my understanding, the following statement is correct: The points $[v_1], \ldots, [v_m]$ of  $PG(d,q)$ are in general position
  if and only if the vectors $v_1, \ldots, v_m$ are linearly
  independent. My proof. The points $[v_1], \ldots, [v_m]$ are in general position iff they are not contained in any $(m-2)$-flat, which is true iff $v_1, \ldots, v_m$ are not contained in any $(m-1)$-dimensional subspace in $V$. This is the same as linear independence of $v_1, \ldots , v_m$. My questions are: Is the above statement correct? Are the preceding definitions accurate? PS. The reason for my confusion is that I've read different definitions for ""general position"" that I don't understand well, as well as discussions were people explain that general position is not equivalent to linear independence (which I thought my statement above implies). While I'm trying to understand and digest things, it would be very helpful to know if I got the above correctly.","['finite-fields', 'finite-geometry', 'linear-algebra', 'geometry']"
1990948,"If two topological spaces have the same topological properties, are they homeomorphic?","Topological properties are investigated because we can show that two spaces are not homeomorphic by finding one property that holds in one space but not the other. But what if no topological property can distinguish two topological spaces? So I ask: If two topological spaces have the same topological properties, must they be homeomorphic? Edit: I don't really have any particular class of topological properties in mind, because what I am thinking is really every single topological property, whenever it is well-defined for a topological space. I just didn't know that the class of topological properties is so large, that even ""homeomorphic to a space $X$"" is itself a topological property, making my question trivial.",['general-topology']
1990950,Solving $(\cos{x}+3)(\cos{x}-1)=0$,"I started with this equation
$$2\cos{x}-2=\sin^2{x} \tag{1}$$ and took the following steps to solve it (for radians): $$\begin{align}
2\cos{x}-2=1-\cos^2{x} \tag{2} \\    
2\cos{x}-2+\cos^2{x}-1=0 \tag{3} \\    
\cos^2{x}+2\cos{x}-3=0 \tag{4} \\    
(\cos{x}+3)(\cos{x}-1)=0 \tag{5}
\end{align}$$ I get these two factors in $(5)$, but the $(\cos{x}+3)$ factor is undefined, so I don't know how to solve this for real. I know the answer is either $0$ or $2\pi$, but I only found that out through trial-and-error, not algebraically.",['trigonometry']
1990955,Derivative of multivariate Gaussian PDF with respect to covariance,"While trying to derive the M-step of the EM-algorithm for a mixture of Gaussians, I came across this derivative, which I have no idea how to deal with: $$
\frac{\partial}{\partial \mathbf{\Sigma_k}} \left ( (2\pi)^{-d/2}|\mathbf{\Sigma_k}|^{-1/2}e^{-\frac{1}{2}(x-\mathbf{\mu_k})^T\mathbf{\Sigma_k}^{-1}(x-\mathbf{\mu_k})}\right )
$$ Basically, this the derivative of the multivariate Gaussian PDF with respect to the covariance matrix. My matrix calculus is not very good - how do I approach this? I've computed the derivative of the logarithm of this PDF before and that was a bit easier because the $|\mathbf{\Sigma_k}|$ and $\mathbf{\Sigma_k}^{-1}$ were in two separate terms that were added/subtracted. But here they are in two terms that are multiplied together.","['derivatives', 'statistics', 'partial-derivative']"
1991016,$L_p$ norm of linear function,"Is there a nice formula for the $L_p$ norm of $f(\vec{x}) = \sum_{i=1}^n x_i$ on the domain $[-1,1]^n$, where $\vec{x} = (x_1, \dots, x_n)$? i.e. a nice expression for $\left(\int_{\vec{x} \in [-1,1]^n}  \left|\sum_{i=1}^n x_i\right|^p dx_1 \dots dx_n\right)^\frac{1}{p}$","['functional-analysis', 'multivariable-calculus', 'calculus', 'analysis']"
1991029,"Singapore math olympiad Trigonometry question: If $\sqrt{9-8\sin 50^\circ} = a+b\csc 50^\circ$, then $ab=$?","$$\text{If}\; \sqrt{9-8\sin 50^\circ} = a+b\csc 50^\circ\text{, then}\; ab=\text{?}$$ $\bf{My\; Try::}$ We can write above question as $$\sin 50^\circ\sqrt{9-8\sin 50^\circ} = a\sin 50^\circ+b$$ Now for Left side, $$\sin 50^\circ\sqrt{9-8\sin 50^\circ} = \sqrt{9\sin^250^\circ-8\sin^350^{\circ}}$$ Now How can i solve it after that , Help required, Thanks",['trigonometry']
1991088,"Problem 6.10, I. Martin Isaacs' Character Theory","Let $N \triangleleft G$ with $(|G : N|, |N|) = 1$ . Suppose that every subgroup of $G/N$ is an $M$ -group. Show that $G$ is a relative $M$ -group with respect to $N$ . Here are definitions of $M$ -group and relative $M$ -group in the book: Let $\chi$ be a character of $G$ . Then $\chi$ is monomial if $\chi = \lambda^G$ , where $\lambda$ is a linear character of some (not necessarily proper) subgroup of $G$ . The group $G$ is an $M$ -group if every $\chi \in \operatorname{Irr}(G)$ is monomial. Let $N \triangleleft G$ and let $\chi \in \operatorname{Irr}(G)$ . Then $\chi$ is a relative $M$ -character with respect to $N$ if there exists $H$ with $N \subseteq H \subseteq G$ and $\psi \in \operatorname{Irr}(H)$ such that $\psi^G = \chi$ and $\psi_N \in \operatorname{Irr}(N)$ . Iff every $\chi \operatorname{Irr}(G)$ is a relative $M$ -character with respect to $N$ , then $G$ is a relative $M$ -group with respect to $N$ . Since $G/N$ is an $M$ -group, it is solvable. I want to use Theorem 6.22, but I don't know how to prove that every chief factor of every subgroup of $G/N$ has nonsquare order. And I don't know how to use the fact that $(|G : N|, |N|) = 1$ . Can anyone help me?","['finite-groups', 'representation-theory', 'group-theory']"
1991165,Why is the change-to-polar-coordinate method valid in computing limits?,"For example, when we compute $\displaystyle\lim_{(x,y)\to(0,0)}\frac{x^2y}{x^2+y^2}$, we can use the change to polar coordinates method below: Let $\begin{cases}x=r\cos\theta\\y=r\sin\theta \end{cases}$, then
  $\displaystyle\lim_{(x,y)\to(0,0)}\frac{x^2y}{x^2+y^2}=\lim_{r\to0}\frac{r^3\cos^3\theta\sin\theta}{r^2}(=\lim_{r\to0}r\cos^2\theta\sin\theta=0)$. However, why is this method valid? What is the actual reason behind this substitution? Is this related to the limit law of composition functions of continuous function? But what are those two functions that applying behind here? I think it makes use of this change-of-coordinate continuous and one-to-one function $\Psi$: $$\begin{alignat*}{3}\Psi:\ &\mathbb{R}^+\times[0,2\pi)&&\to\mathbb{R}^2\\
&(r,\theta)&&\mapsto(r\cos\theta,r\sin\theta)\end{alignat*}$$ But I can't figure out how to ""chain"" this function with others and get the eager result.","['continuity', 'real-analysis', 'polar-coordinates', 'analysis']"
