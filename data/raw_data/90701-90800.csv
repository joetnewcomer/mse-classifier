question_id,title,body,tags
1222331,"If $f+f'<\varepsilon$, then $f'<\varepsilon$","Let $f$ be continuous on $[a,b]$ and differentiable on $(a,b)$ and there exstis $\varepsilon>0$ such that $f(x)+f'(x)<\varepsilon$ for all $x\in (a,b)$. Prove that $f'(x)<\varepsilon$ for all $x\in (a,b)$. These are my efforts: $\bullet$ If $f(x)\ge 0$ then $f'(x)<\varepsilon$, so we just need to consider those $x$ such that $f(x)<0$. $\bullet$ Consider $g(x)=f(x)\cdot e^x-\varepsilon\cdot e^x$ then $g$ decreases on $(a,b)$. If $f(c)<\varepsilon$, then $f(x)<\varepsilon$ for all $x\in [c,b]$. $\bullet$ If $f(x_0)\ge \varepsilon$ for some $x_0$ then $f$ increases in some neighborhood of $x$. I cannot completely solve it. Thanks so much for any help.","['real-analysis', 'derivatives']"
1222336,Show that an open subset $U \subset \mathbb{H^n}$ is open in $\mathbb{R^n}$ iff $U \cap \partial\mathbb{H^n}=\phi$,"Consider the $n-$dimensional closed half-space $\mathbb{H^n}=\{x \in \mathbb{R^n}|x_1 \le 0 \}$ and let $\partial \mathbb{H^n}=\{x \in \mathbb{H}|x_1=0\}$ be its boundary. Show that an open subset $U \subset \mathbb{H^n}$ is open in $\mathbb{R^n}$ iff $U \cap \partial\mathbb{H^n}=\phi$ My try: Suppose that an open subset $U \subset \mathbb{H^n}$ is open in $\mathbb{R^n}$. Then let's assume that $\vec{x} \in U \cap \partial\mathbb{H^n}$.Since $U$ is open in $\mathbb{R^n}$, there exists $r \gt 0$ such that $B_{d}(\vec{x},r) \subset U$.  Let $\vec{y}=(y_1,y')\in \mathbb{H^n} \cap B_{d}(\vec{x},r) $ such that $y_1 \lt 0$.   $z=(-y_1,y') \in B_{d}(\vec{x},r) $ but $z \not \in B_d(\vec{x},r) \cap \mathbb{H^n}$.  I believe this should lead to a contradiction at the point $x$. For some reason I am unable to see it. For the other side since $ U$ is open in $\mathbb{H^n}$, $U$ can be written as some $V \cap \mathbb{H^n}$, where $V$ is open in $\mathbb{R^n}$. Since  $U \cap \partial\mathbb{H^n}=\phi$  , we  have $V \cap \partial\mathbb{H^n}=\phi$.Thus $V \subset \mathbb{H^n}$. Thus $U=V$. Is this part alright?
Thanks for the help!!","['analysis', 'multivariable-calculus', 'general-topology']"
1222337,A difficult trigonometric integral involving absolute value,"$$
\int_{0}^{2\pi}\lvert\sin(x)\rvert\cos(nx)\,dx=
-\frac{4\cos^2\bigl(\frac{\pi n}{2}\bigr)\cos(\pi n)}{n^2-1}
$$ I'm not actually trying to solve this myself. The answer appears in my lecture notes without any explanation whatsoever. Apparently it depends on whether or not $n$ is odd or even, since the answer is $0$ when $n$ is odd, but I really don't understand how they've gotten the answer at all. Please help me to figure out what the heck is going on!","['definite-integrals', 'fourier-series', 'absolute-value', 'trigonometry', 'integration']"
1222346,"""Direct sums of injective modules over Noetherian ring is injective"" and its analogue",I have a commutative algebra class and I heard the theorem from the professor: Let $R$ be a Noetherian ring and $\{E_i : i\in I\}$ be a collection of injective $R$-modules then $\bigoplus_{i\in I} E_i$ is also injective. My questions are: How to prove that? My professor does not talk about the proof of it (just states the theorem.) I asked to professor where I can find the proof and she asks that I might find the proof of it in some homological algebra textbook. However I can't find that. Does the following analogue of above theorem hold? Let $R$ be an Artinian ring and $\{P_i : i\in I\}$ be a collection of projective $R$-modules then $\prod_{i\in I} P_i$ is also projective. If $R$ is domain then $R$ is field so the theorem holds trivially. I wonder above statement holds for general (Artinian) ring.,"['abstract-algebra', 'injective-module', 'projective-module', 'commutative-algebra']"
1222359,Is there anything special about this matrix?,"I've just encountered a matrix which seems to display nothing special to me:
$$B=\begin{pmatrix}1&4&2\\0 &-3 &-2\\ 0 &4 &3 \end{pmatrix}$$
But further observation reveals something stunning:
$$B^n=\cases{{I}&n is even\\{B}&n is odd}$$
So it leads me to wonder if there is indeed some special properties of this matrix $B$, or more probably, $B$ belongs to a whole special class of matrices whose name I don't know? Could you drop me a hint? Thanks in advance. EDIT I think I was being a bit stupid... It suddenly hit me that any matrix $B$ such that $B^2=I$ will have this property.","['terminology', 'linear-algebra', 'matrices']"
1222382,"What is a group action, and how can we apply it to Sylow theory","I am studying Sylow theorems at the moment, more specifically trying to solve the following problem that I recently posted: Let G be a finite group which has exactly eight Sylow 7 subgroups. Show that there exits a normal subgroup N of G such that the index [G:N] is divisible by 56 but not by 49 The link is here: If we have exactly 1 eight Sylow 7 subgroups, Show that there exits a normal subgroup $N$ of $G$ s.t. the index $[G:N]$ is divisible by 56 but not 49. My initial response was to use Sylow's theorems to understand the order of the group. Though I am still very new at this. I was then told to look at this problem through group actions, which I know considerably less in. After taking a look at group actions again, I know just a few more things. Considering that I am just beginning at understanding this theory, I was wondering if someone can explain to me in laymen terms, the application of group actions and how to use them to solve problems. Of course, I know that I could just look up book definition, but I would like a little more insight than that. 
How would you explain group actions to someone with just calculus level knowledge maybe? What is the meaning of group actions, using language that is easy for a beginner to understand? The definition of group action that I have found comes from Hungerford's Algebra. An action of a group $G$ on a set $S$ is a function $GxS \to S$ such that for all $x \in S$ and $g_1, g_2 \in G$: $ex=x$ and $(g_1g_2)x=g_1(g_2x)$","['abstract-algebra', 'sylow-theory', 'group-theory', 'group-actions']"
1222395,Stuck on crucial step while computing $\int_{- \infty}^{\infty} e^{-t^2}dt$,"This is a not mandatory exercise I am struggling with from my Analysis II Class, at the very end of it I am supposed to compute $$\int_{-\infty}^\infty e^{-t^2}dt \tag{*}$$
The most famous way to do that is switch to polar coordinates but I am not supposed to do it that way, one of my tutors even called it a 'dirty trick'. Instead the exercise gives us the following two Integrals to work with: $$F(x)= \int_0^1 \frac{e^{-x^2(1+t^2)}}{1+t^2}dt \text{ and } G(x)= \left( \int_0^x e^{-t^2}dt\right)^2, \Â \forall x \in \mathbb{R} $$ I yet fail to see how these two integrals relate to (*) but I can naively follow the instructions given by exercise sheet and hope that the result will follow: Problem : Show that $F,G$ are of Class $C^1(\mathbb{R})$, compute $F',G'$ for all $x \in \mathbb{R}$ and show that $F+G$ is constant My approach : There isn't much to do really rather than to quote some Lemmas, clearly the parametric integral $F$ is of class $C^1$ because $f(x,t): \mathbb{R} \times [0,1] \to \mathbb{R}$ given by $f(x,t)=e^{-x^2(1+t^2)}/(1+t^2)$ is of class $C^1$, I can therefore switch the partial derivative with the integral and obtain that  $$F'(x) =-2 x \int_0^1e^{-x^2(1+t^2)}dt$$ I doubt that I can further simplify this integral. With a little help of the fundamental theorem of Calculus one obtains that $$G'(x)= 2 \left( \int_0^x e^{-t^2}dt\right)e^{-x^2} $$ At this point I hope that the exercise (or my computation) is flawed, at least the limit points of the integrals because I wouldn't know how to show that $F'+G'=0$ for all $x\in \mathbb{R}$ to conclude that $F+G$ is constant. The only sense I could make out of $F'$ would be if I integrated it with respect to $x$ rather to $t$. Are there any further simplifications I can do?","['analysis', 'real-analysis', 'integration']"
1222415,Finding a combinatorial argument for an interesting identity: $\sum_k \binom nk \binom{m+k}n = \sum_i \binom ni \binom mi 2^i$,"Consider the following identity $${{n}\choose{0} }{m\choose n} + {n\choose 1}{{m+1} \choose n}+ \cdots +{n\choose n}{{m+n} \choose n} =\sum_{i=0}^{\min (m ,n)} {n\choose i}{m\choose i}2^i$$ The right hand side looks really neat to me but I can't find any combinatorial argument to this.I'm totally stuck on how to approach. I'd like hints and not full solutions. EDIT I guess asking for a hint was a bit too much for this question. Apologies.","['summation', 'binomial-coefficients', 'combinatorics']"
1222443,How to factorize $x^4+2x^2-x+2$?,"look at this:
$$x^4+2x^2-x+2$$
How to factorize it? It should be changed to be in the form of standard factorization formulas.","['factoring', 'algebra-precalculus']"
1222445,"functions compositions, three sets, counting compositions","Given three sets $P, Q, R$ such that $|P|=p, |Q|=q, |R|=r,$ and $p,q,r > 1$ let $f(x): P\rightarrow Q$, and $g(x):Q\rightarrow R$ be two functions. Find the number of functions which can be composed using $g(x)$, and $f(x)$ respectively (find the functions in the form $h(x)=g(f(x))$) I don't even know where to start with this one, is there a formula for counting compositions that i'm not aware of, or should i just create random cases and see if there is a general number of compositions.","['discrete-mathematics', 'function-and-relation-composition', 'combinatorics']"
1222474,"A noncommutative counterexample to the following property: If $I,J$ are comaximal ideals, then $IJ=I\cap J$.","Let $R$ be a commutative ring with $1$ . If $I+J=R$ , then $IJ = I \cap J$ . The post below has already given a solution. However, I am wondering what happens if $R$ is not commutative? Can anyone provide me with a counterexample? If I am not wrong, the counterexample given in the post is the case when $R$ is commutative and does not have unity. Which part of the proof uses commutativity of the ring? Thank you. If $I+J=R$, where $R$ is a commutative rng, prove that $IJ=I\cap J$.","['abstract-algebra', 'ideals']"
1222484,Prove $ \sum \frac{\cos n} { \sqrt n}$ converges,How to Prove $ \sum \frac{\cos n} { \sqrt n}$ converges Using Abelâs theorem ? I think it can be done using $\cos n = Re(e^{in})$ { Real Part of Complex Number } How to proceed ?,"['real-analysis', 'sequences-and-series', 'trigonometry', 'radicals', 'convergence-divergence']"
1222594,"Expectation of an increasing, bounded concave function of a non-negative random variable","Let $h:[0,\infty)\to [0,1)$ be a strictly increasing and strictly concave function. Let the argument of this function be a random variable $C$ with probability density function (pdf) $f_{C}(c)$ with support on some subset of $[0,\infty)$. By an application of Jensen's inequality, we have $$\mathrm{E}(h(C)) = \int_{0}^{\infty}h(c)f_{C}(c)dc < h\left(\int_{0}^{\infty}cf_{C}(c)dc\right) = h(\mathrm{E}(C))$$
where the expectations are assumed to exist. I wonder if this can be generalized as outlined below when the function $h$ is defined as above. Assume that we have two random variables $C_{1}$ and $C_{2}$ for which $\mathrm{E}(C_{1}) = \mathrm{E}(C_{2})$, but the higher moments of their distributions $f_{C_{1}}$ and $f_{C_{2}}$ differ in general. In particular, we may take $\mathrm{Var}(C_{2})>\mathrm{Var}(C_{1})$. Can anything be said about which quantity is larger in this case, $\mathrm{E}(h(C_{1}))$ or $\mathrm{E}(h(C_{2}))$? Intuitively, since $h$ is concave and increasing, I expect $\mathrm{E}(h(C_{2})) < \mathrm{E}(h(C_{1}))$ (the variable with the largest variance produces the smallest expectation), and certainly if $f_{C_{1}}$ and $f_{C_{2}}$ are both symmetric. But does this hold in general? I would be a little surprised if it does, but I haven't been able to find a simple counterexample.","['probability', 'convex-analysis']"
1222596,Probability of turning a 3x3 Rubik's Cube 50 random turns and solving,"So I am working with my secondary Algebra II class on permutations, combinations, and probability and had an idea for an interesting problem that I hope can work for their skill level.  We have been able to establish that the total number of permutations for a 3x3 Rubik's Cube is $$4.3252 \cdot 10^{19}$$ which they are good with and seem to understand the reasoning behind.  Now, I would like to give them a problem something like ""What is the probability of solving a 3x3 Rubik's Cube by making 50 random turns?  Assume that it is fully scrambled prior to your first turn.""  The problem is...I don't know how to solve the question I just asked!  I'm trained in Computer Science so I am familiar with combinatorics/probability but I'm not really sure how to tackle this problem. Part of me feels like it is way more advanced than I am anticipating but, again, I really am stuck on how to go about solving it and even if the solution is more advanced than is appropriate for a high school Algebra II class I am hoping to be able to glean atleast some of the reasoning out to show them an interesting application of what we have been learning. inb4 this should be on MESE.  The question is not about how to teach this problem but literally how to actually solve the problem","['probability', 'combinatorics']"
1222652,New characteristic functions from old,"I am doing an exercise which says: If $f$ is a characteristic function, then show that  $$ F(t):=  \int_0^{\infty} f(ut)e^{-u}du $$ is again a characteristic function. Is this answer correct? Let $Z$ be an exponentially distributed random variable with parameter $1$. Let $X$ be a random variable with characteristic function $f$. Then \begin{align}
F(t) &= \mathbb{E} \left[ \left( \mathbb{E} e^{itsX} \right) \Bigg{\vert}_{s=Z}\right] \\
&= \mathbb{E} \left[ \mathbb{E}(e^{itZX} \big{\vert} Z ) \right]\\
&=\mathbb{E}(e^{itZX})
\end{align} where it is the second equality that uses the independence. This shows that $F$ is the characteristic function of the random variable $ZX$. Many thanks for your help.","['probability-theory', 'characteristic-functions', 'probability-distributions']"
1222677,Proving completeness of $L^p$,"I want to make sure my understanding of the proof is correct. For a Cauchy sequence $\{f_n\}$ in $L^p$, we want to find a $f\in L^p$ such that $f_n\stackrel{L^p}\to f$ Now, skipping the technicalities of the proof, if we manage find some $f$, for which $$\forall \epsilon>0\;\exists n_0,\; m\geq n_0 \;\;\|f-f_m\|_{L^p}\leq\epsilon$$
Are we done? I'd say yes, as, $f=\underbrace{(f-f_m)}_{\in L^p}+f_m \in L^p$ and $$\epsilon \geq \|f-f_m\|\geq \Big|\|f\|-\|f_m\| \Big|$$
Implies $\|f_m\|\stackrel{L^p}\to \|f\|$ Am I correct in my reasoning? Thank you.","['sequences-and-series', 'banach-spaces', 'functional-analysis', 'measure-theory']"
1222689,Limit of a certain quotient,$$ \lim_{n\to \infty} {\sum_{k=1}^n {1\over\sqrt{k}}\over\sqrt{n}} $$ I understand that the summation is divergent and this is $\infty\over\infty$ form. But how to proceed further??,"['calculus', 'limits']"
1222700,Showing $s^2=\frac{1}{n-1}\sum_{i=1}^n(x_i-\bar{x})^2=\frac{1}{n-1}\left [\sum_{i=1}^n x_i^2-\frac{1}{n}\left ( \sum_1^nx_i\right )^2 \right ]$ [duplicate],This question already has answers here : Sample variance derivation (2 answers) Closed 9 years ago . I've got as far as this  $$s^2=\frac{1}{n-1}\sum_{i=1}^n(x_i-\bar{x})^2=\frac{1}{n-1}\sum_{i=1}^n\left ( x_i^2-2x_i\bar{x}+\bar{x}^2\right )$$ $$=\frac{1}{n-1}\left [\sum_{i=1}^nx_i^2+\bar{x}^2-2\bar{x}\sum_{i=1}^n x_i \right ]$$ $$\frac{1}{n-1}\left [\sum_{i=1}^nx_i^2 +\left ( \bar{x}-\sum_{i=1}^n x_i\right )^2 -\left (\sum_{i=1}^n x_i \right  )^2\right ]$$ And now I'm stuck. I can use $$\sum_{i=1}^n\frac{x_i}{n}=\bar{x}$$ However can't get the result. If someone could point me in the right direction I'd be grateful.,"['statistics', 'standard-deviation']"
1222712,How to find the limit properly?,I would like to find or solve the limit of: $$\lim_{n \to \infty} \frac{80^{(n+1)/4}}{37^{(2n+3)/4}}$$ My idea was somehow non-intuitive: $$\lim_{n \to \infty} \frac{80^{(n+1)/4}}{37^{(2n+3)/4}} \leq  \lim_{n \to \infty} \frac{3^{4(n+1)/4}} {6^{2(2n+3)/4}}= \lim_{n \to \infty}(\frac{3^{4n+4}}{6^{4n+6}})^{1/4} = \lim_{n \to \infty}(\frac{1^{4n+4}}{3^{4n+6}})^{1/4}=0$$ But it seems wrong somehow...,['analysis']
1222722,"$z^n=(z+1)^n=1$, show that $n$ is divisible by $6$. [duplicate]","This question already has answers here : Complex numbers - Exponential numbers - Proof (5 answers) Closed 7 years ago . we are given $z^n=(z+1)^n=1$, $z$ complex number. we want to prove that $n$ is divisible by $6$. I showed that $|z|=|z+1|=1$. Hence $z$ is on the intersection of two unit circles, one centered at $(0,0)$ and the other one centered at $(-1,0)$. Then $z$ can take two values $z=\operatorname{cis}(2 \pi /3)$ or $z=\operatorname{cis}(4 \pi/3)$. Then from $z^n=1=\operatorname{cis}(2 \pi k)$, $k$ integer I showed that $n$ should be divisible by $3$. I am left to show that $n$ should be divisible by $2$. I think if I figure out a way to show that $\operatorname{arg}(z+1)=\pi/3$ or $-\pi/3$ then I would be done, by using $(z+1)^n=\operatorname{cis}(2\pi k)$. but how can I do this? Any ideas are welcome! Thanks in advance!","['complex-numbers', 'algebra-precalculus']"
1222732,Prove that $ (\mathbb{Q}\times\mathbb{R})\cup (\mathbb{R}\times\mathbb{Q})$ is a locally connected and connected subspace of $\mathbb{R}^2$,"The book I am using for my Introduction of Topology course is Principles of Topology by Fred H. Croom. Prove that $A = (\mathbb{Q}\times\mathbb{R})\cup (\mathbb{R}\times\mathbb{Q})$ is a locally connected and connected subspace of $\mathbb{R}^2$ This is what I understand: A space $X$ is connected provided that it cannot be written as the disjoint union of specifically two open sets. A space $X$ is locally connected at a point $a$ in $X$ if every open set containing $a$ contains a connected open set which contains $a$. The space $X$ is locally connected provided that it is locally connected at each point. I'm aware that neither connected nor locally connected implies the other, nor do their negations. Meaning I would have to prove each. Now the set of rationals is disconnected (in fact totally disconnected). $\mathbb{R}^2$ is connected and locally connected. $A \subseteq \mathbb{R}^2$ I'm a little stuck on how to approach this question; however, I do have a rough idea. To prove $A$ is connected, I can claim that $A$ is disconnected. Then there exists two nonempty set $U$ and $V$ such that $U\cup V=A$ and $U \cap V = \emptyset$. Thus $U$ and $V$ are clopen. Eventually, I should arrive at a contradiction because $\emptyset$ and $A$ are the only subsets of $A$ that are clopen, proving $A$ is connected. However I am not sure how to properly execute the approach. To prove $A$ is locally connected. I can claim the space $A$ has a local basis $\mathscr{B}_a$. I would need to prove that $\mathscr{B}_a$ consist of connected open sets, proving $A$ is locally connected. Am I on the right track? Any suggestions oh how I can proceed with my ideas? Sorry for the long read. If there are any mistakes in what I stated above, please let me know so I can correct it. I sincerely thank you for taking the time to read this question. I greatly appreciate any assistance you may provide.","['connectedness', 'general-topology']"
1222743,Degree of freedom,"I have learnt from solving different statistical problems that if we have a sample of size $n$ picked from the population with normal distribution, the degree of freedom for, say, Student distribution or Chi-square distribution distribution will be always $n-1$. Recently i have discovered the following problem: Let ${X_1},{X_2}, \cdots ,{X_{10}}$ be independent
  $N(0,1)$-distributed (standard normal distribution) random variables.
  Define $$X = X_1^2 + X_2^2 +  \cdots  + X_{10}^2$$ What is the
  distribution, expectation and variance of $X$? I understand that this is a Chi-square distribution. What i don't get is why the degree of freedom is $10$ instead of $9$? If $X$ is a sum of $10$ squared $RV$ shouldn't we treat it as a sample with size $n=10$ and hence $X \sim {\chi}^2(n - 1)$?",['statistics']
1222768,Why are vector valued functions 'well-defined' when multivalued functions aren't?,"I'm looking for an 'intuitive' answer here, because I have no formal mathematical training but find myself in a comparatively math-heavy PhD (visual perception; lots of neuroscientists on the one side and CS folk on the other). Only functions which map some number of inputs to a single output are considered 'true' or 'well-defined' functions. I've seen squaring (and presumably other exponents) given as an example: [any number] squared produces a single 'output', though some outputs for different inputs may be the same: e.g. -2 and 2 squared both equal 4. By contrast, I've seen square-root given as an example of a NON -'well-defined' function, because sqrt(4) can equal both 2 and -2. A single input maps to multiple outputs, violating the definition of a 'true' function. (EDIT: As @Eff says in the comments, this is an incorrect example because sqrt(4) is in fact defined to equal 2 alone. But I hope my broader point is still clear) Presumably, the benefits of 'true' functions as defined by this constraint come in terms of assumptions one can make, and guarantees one can rely on when reasoning about the function. Vector-valued functions return multiple scalar values (organised within a tuple) and considering my programmer background I can't see how this differs, except in terminology, from a multivalued function. Yet I have never read anybody suggesting vector-valued functions aren't true functions. As it stands, if I were faced with the task of inverting a function which takes multiple inputs, I'd simply define the inverse as vector-valued, to sidestep the constraint. My sqrt(4) would be the tuple (2,-2). From a software engineering perspective, even in C where functions may return no more than one argument, that argument could be an array or a struct. It feels like either both or neither of multivalued and vector-valued functions meet the definition of being 'well-defined' / 'true' functions. What am I misunderstanding?","['multivalued-functions', 'functions']"
1222828,Affine variety and dimension,"I'm working on a paper about representation of quivers and Gabriel's theorems. See this .pdf if you're interested ; but I guess you can answer my question without knowing anything about quivers, or at least I'll try to simplify it so that quivers are not involved. Let $n \in \mathbb{N}$ and $\alpha = (\alpha_{1}, \dots, \alpha_{n}) \in \mathbb{N}^{n}$. I'm asked to prove that $\prod\limits_{i = 1}^{i= n-1} \text{Hom}(\mathbb{C}^{\alpha_{i}}, \mathbb{C}^{\alpha_{i+1}})$ is an affine variety which is isomorphic to $\prod\limits_{i = 1}^{i= n-1} \mathbb{C}^{\alpha_{i}}\times \mathbb{C}^{\alpha_{i+1}}$ , and thus it is irreducible and its dimension is $\sum\limits_{i=1}^{i=n-1} \alpha_{i}\alpha_{i+1}$. Problem is I know nothing about algebraic geometry, and so I really find it hard to understand truely the words I put in bold. Then, assume there is a group action of a given group $G$ on $\prod\limits_{i = 1}^{i= n-1} \text{Hom}(\mathbb{C}^{\alpha_{i}}, \mathbb{C}^{\alpha_{i+1}})$. I'm told two things which, I guess, are close to each other : if the codimension of every orbit is $\geq 1$, then there is an infinity of orbits . if there is a finite number of orbits, then one of those orbits must be a dense open set. How would you justify that ? Thanks for any help or reference.","['algebraic-geometry', 'reference-request', 'quiver']"
1222832,How to integrate $ \int_0^\infty \sin x \cdot x ^{-1/3} dx$ (using Gamma function),"How can I calculate the following integral: $$\int_0^\infty x ^{-\frac{1}{3}}\sin x \, dx$$ WolframAlpha gives me $$ \frac{\pi}{\Gamma\Big(\frac{1}{3}\Big)}$$ How does WolframAlpha get this? I don't understand how we can rearrange the formula in order to apply the gamma-function here. Any helpful and detailed hint/answer is appreciated.","['gamma-function', 'complex-analysis', 'integration']"
1222840,"Group theory, geodesic words.","I'm not sure if I understand term ""geodesic words"" correctly. Need this to translate chapter about braid groups to polish, so if any of You know polish equivalent, please share it.
Using wikipedia's definition for ""Word (group theory)"" i have: For example, if x, y and z are elements of a group G, then xy, zâ1xzz
  and yâ1zxxâ1yzâ1 are words in the set {x, y, z}. I know that geodesic line is the shortest line between two given points. Adding both informations i think that ""geodesic word"" means the shortest word, one in which all possible cancellation was done. Example: $xz$ - geodesic, $xyy^{-1}z$ - not geodesic.
Am I right? If not, please help me out.","['group-theory', 'geodesic']"
1222868,how to factorize $x^2+10yz-2xz-2xy-3y^2-3z^2$?,"How to factorize 
$$x^2+10yz-2xz-2xy-3y^2-3z^2$$ It is expanded and we should make them into parts and factorize each part individually. the last answer is $$(x+y-3z)(x-3y+z)$$ but how to get it ?","['factoring', 'algebra-precalculus']"
1222918,Pointwise convergence and L1 convergence in bounded mass case,"I have a question regarding convergence modes and their relationships, my problem is actually an application to probability, How to prove that : ${f_n}$ and $g$ are probability density functions such that for all $x \in R$ ${f_n}(x) \rightarrow g(x)$ as $n \rightarrow \infty$, then ${f_n}$ converges to $g$ in $L^{1}$ I don't see how to prove this, my first thought was to use the bounded convergence theorem but I don't see how (similarly with Fatou's lemma), I think it is more subtle. I found this theorem however which is more general, but I can't find its proof : Suppose that ${f_n: X \rightarrow [0,+\infty)}$ are measurable, are such that ${\sup_n \int_X f_n\ d\mu < \infty}$, and converge pointwise almost everywhere to some measurable limit ${f: X \rightarrow [0,+\infty)}$. Show that ${f_n}$ converges in ${L^1}$ norm to ${f}$ if and only if ${\int_X f_n\ d\mu}$ converges to ${\int_X f\ d\mu}$. Informally, we see that in the unsigned, bounded mass case, pointwise convergence implies ${L^1}$ norm convergence if and only if there is no loss of mass. Do you see how ? Thanks","['probability-theory', 'convergence-divergence', 'real-analysis', 'probability-distributions']"
1222928,"How to reason about the combinatorial term ""$n$ choose $k$"" (i.e., $\binom{n}{k}=\frac{n!}{k!(n-k)!}$)","The combinatorial number is the number of picking $k$ unordered outcomes out of $n$ possible choices. In that setting, we have a set $A$ with $|A|=n$ and the combinatorial numbers is just really the number of subsets $S\subset A$ with $|S| = k$. This number is $$\binom{n}{k} = \dfrac{n!}{k!(n-k)!},$$ but how can we reason about this? How can we derive this formula? I've seem some people reasoning about this in the following way: the number of ways to choose permutations with size $k$ among $n$ objects is $$n(n-1)\cdots (n-k-1) = \dfrac{n(n-1)\cdots (n-k+1)(n-k)\cdots 1}{(n-k)(n-k-1)\cdots 1} = \dfrac{n!}{(n-k)!},$$ then we have to divide by $k!$ to disconsider the order. Why is that? Why dividing by $k!$ we get the number of subsets of $A$ with size $k$?",['combinatorics']
1222933,"Limit of the integral $\int_0^1\frac{n\cos x}{1+x^2n^{3/2}}\,dx$","Prove that $\displaystyle\int_0^1\frac{n\cos x}{1+x^2n^{\frac32}}dx\rightarrow0$ as $n\rightarrow\infty$. $f_n(x)=\frac{n\cos x}{1+x^2n\sqrt{n}}$ tends to zero function pointwise. It just converges uniformly on every compact interval $[\epsilon,1]$, but$f_n(0)=n$ tends to $+\infty$ and we can not use replacement of limit and integral with this reasoning. So, the other useful method to handle limit of integrals, is Lebesgue Dominated Convergence Theorem .
But I can't still find the proper dominating nonnegative and measureble function over $[0,1]$ for the sequence $\{f_n\}$. First it seems the term $\cos x$ doesn't have impact on the result. Then for each $p<1$, there's natural $m$ that $f_m(x)$ is not dominated by $g(x)=\frac{1}{x^p}$ on the whole interval. (I observed it via plotting). I think in the process of finding a good inequality, we must generate $n$ in denominator and use $n>1$.","['lebesgue-integral', 'real-analysis', 'improper-integrals', 'integration']"
1222963,"If $\lim_{n\to\infty}a_n=L$ and $f$ is continuous at $L$, then $\lim_{n\to\infty}f(a_n)=f(L)$. Is this true?","Theorem: Prove or disprove the following: If $\lim_{n\to\infty}a_n=L$ and the function is continuous at $L$, then $\lim_{n\to\infty}f(a_n)=f(L)$. I'm trying to study for my upcoming exam and I'm struggling to prove the above theorem. I believe you need to use the $\epsilon$-$\delta$ proof method to prove it, but I cannot find a way to do it. I'm not very comfortable with those kinds of proofs just yet. A proof with explanation or some guidance would be greatly appreciated.","['limits', 'real-analysis', 'epsilon-delta']"
1222968,What is reverse inclusion?,"I'm learning about posets for the first time. What does it mean for a collection of sets to be ""ordered by reverse inclusion""? Thank you.","['discrete-mathematics', 'lattice-orders', 'order-theory', 'combinatorics']"
1222975,Set of pairwise sum is the same,"Let $X=\{x_1,\ldots,x_n\},Y=\{y_1,\ldots,y_n\}$ be sets of pairwise distinct integers with $X\neq Y$. For which $n$ is it possible that $\{x_i+x_j\mid i<j\}=\{y_i+y_j\mid i<j\}$? For example, $n=2$ is possible because of $\{1,4\},\{2,3\}$, $n=4$ is possible because of $\{1,4,6,7\},\{2,3,5,8\}$, and similarly any $n$ power of $2$ is possible.","['algebra-precalculus', 'combinatorics']"
1222986,Computing $\lim_{n\to\infty}\sqrt{\frac{2n}{n+1}}$,"We are asked to find the limit of the recursively defined sequence, and to assume that the sequence converges. $a_1$=0 and $a_{n+1}$= $\sqrt{8+2a_n}$ I then solved for $a_n$ using algebra. $a_n$=${(a_{n+1})^2 - 8\over 2}$ I set the limits of each term equal to eachother. $\lim \limits_{n \to \infty}$$a_n$ = $\lim \limits_{n \to \infty}$${(a_{n+1})^2 - 8\over 2}$ So, from what I understand $\lim \limits_{n \to \infty}$$a_n$ = L And you can just set L = ${L^2 - 8\over 2}$ which after algebraic simplification equals: $L^2$ -2L -8 = 0 (L-4)(L+2) = 0 L = -2, 4 So I do not understand how there are two limits, if these are even correct? And why $(a_{n+1})^2$ can be substituted for $L^2$. I came to these answers after watching a video on a similar problem which is why I'm not really understanding the basic concepts of it. Thanks.","['sequences-and-series', 'limits', 'recursion']"
1223054,What would be the join and meet of this lattice?,"I'm working on the following problem: Let $W$ be a subspace of the vector space $\mathbb{K}^n$, where $\mathbb{K}$ is a field of characteristic $0$. Let $L$ denote the set of supports of all vectors in $W$, ordered by reverse inclusion. Show that $L$ is a geometric lattice. **I will mention that for any $v=(v_1, \ldots , v_n)$, $\,$ $\text{supp}(v)=\left\{i: v_i\neq 0 \right\}$. First I need to show that $L$ is semimodular, so I will show that if $\text{supp}(v)$ and $\text{supp}(u)$ both cover $\,$ $\text{supp}(v) \wedge \text{supp}(u)$ $\,$ then $\,$ $\text{supp}(v) \vee \text{supp}(u)$ $\,$ cover both $\,$ $\text{supp}(v)$ $\,$ and $\,$ $\text{supp}(u)$. Here is my issue: I want to safely say that since $\text{supp}(v) \subseteq [n]$ that $\,$ $\text{supp}(v) \vee \text{supp}(u)= \text{supp}(v) \cup \text{supp}(u)$ $\,$ and $\,$ $\text{supp}(v) \wedge \text{supp}(u)= \text{supp}(v) \cap \text{supp}(u)$. However, how do I know that $L$ is closed under unions and intersections to begin with? Perhaps I'm wrong and the join and meet of any two elements in $L$ is some other set. Help me, please! Thank you!","['discrete-mathematics', 'lattice-orders', 'order-theory', 'combinatorics']"
1223071,Lagrange Multipliers Dilemma,"In the problem $f(x,y) = xy$ and $g(x, y) = x^2 + 9y^2 = 18$ I get $y = 2Î»x$, $x = 18Î»y$ and $x^2 + 9y^2 = 18$ (the constraint). All is fine, but I feel like I'll get two different answers depending on what my first step is. I could do $y = 2Î»(18Î»y) $
or I could do $x = 18Î»(2Î»x)$ Almost identical. But... $y = 36Î»^2y$, $y - 36Î»^2y = 0$, $y(1-36Î»^2) y = 0$ or $Î» = \pm1/6$. or $x = 36Î»^2x$, $x - 36Î»^2x = 0$, $x(1-36Î»^2) = 0$ where $x = 0$ or $Î» =\pm 1/6$. Which component is zero flips! What am I doing wrong?","['lagrange-multiplier', 'multivariable-calculus']"
1223075,Which number is bigger: $\sqrt[10]{2}$ or $1.2$?,What is the general method for finding such inequalities? I have some more problems of this kind in the text I am using.,"['algebra-precalculus', 'inequality']"
1223076,The path of the shock,"Here I am using the shock speed to work out the path the shock takes. I don't understand why we cannot take the value of $u_{-}$ at $t=1/u_0$ 
i.e $u_{-}=u_0$. and calculate the speed of the shock there ($\frac{ds}{dt}$) and hence work out the shock path $x=s(t)$. Why do we need the value of $u_-$ in its more general form?","['multivariable-calculus', 'partial-differential-equations']"
1223087,Extension of isometries on submanifolds of a riemannian manifold,"Let $S$ be a submanifold of a Riemannian manifold $M$ . Suppose that the closure of $S$ is equal $M$ , i.e, $\bar{S}=M$ . When can we extend an isometry (as Riemannian manifold) $f:S\to S$ to an isometry $\tilde{f}:M\to M$ ?","['geometry', 'riemannian-geometry', 'differential-geometry']"
1223108,Compute $\sqrt[7]{0.999}$ to three decimal places.(From Gelfand's Algebra text.),"After a brief introduction to roots(imaginary numbers were not introduced yet), this question is asked. I am apparently expected to find the answer using elementary algebraic manipulation. I have tried playing around with the problem and observed $\sqrt[7]{0.999} = {(1-\frac{1}{1000}})^\frac{1}{7} = (\frac{(3)^3(37)}{10^3})^\frac{1}{7}$ But do not get how to solve the problem.Any helpful ideas will be appreciated. PS: Inequalities and binomial series were not yet introduced in the text.I have only a rudimentary knowledge of maths, so keep the answers simple and within the scope of elementary algebra. I have edited this problem,adding context. Do not penalize previous answers which used calculus. :)","['algebra-precalculus', 'inequality']"
1223124,What is $\tan(8^\circ51'12'')$?,"I have a copy of a ""ten place natural trigonometric tables"" by Hans Hof. For fun I tried to check that the numbers are accurate. But I don't seem to be able to get exactly the same numbers as in the table. The difference is just on the last digit. And it isn't just one number that is off, most seem to be off. I tried to check the table against various online calculators. For example, according to the table, $$\tan(8^\circ51'12'') \approx 0.155761467\color{red}3.$$ I understand that $$8^\circ 51'12'' = \bigg (8 + \frac{51}{60} + \frac{12}{3600}\bigg)^\circ.$$ When I use Google to Calculate tan((8 + 51/60 + 12/3600) degrees) I get $$0.155761467\color{red}{19}^\circ$$ If I use another online calculator I get $$0.155761467\color{red}{199}^\circ$$ My table seem to be the one off, but my question is: what is $\tan(8^\circ51'12'')$ ? Is my table just off on the last digitor maybe Google isn't rounding correctly?",['trigonometry']
1223145,Hartshorne notation in section III.12,"I am reading section III.12 in Hartshorne, the one about the Semicontinuity Theorem. For $f:X \rightarrow Y$, where $Y=\mathrm{Spec}A$ and $\mathcal{F}$ a coherent sheaf on $X$, he writes $H^i(X,\mathcal{F}\otimes_A M)$, where $M$ is an $A$-module. This notation confuses me. Does he mean $H^i(X,\mathcal{F}\otimes_{\mathcal{O}_X}f^*\tilde{M}$)? It is the only way I can make sense of what we have there, since we want some sheaf on $X$ (we take cohomology there, and in general the cohomology of the pushforward on $Y$ is different). Also, $\mathcal{F}$ does not have a structure of $\mathcal{O}_Y$ module. Is my interpretation correct? Otherwise, what is the right one? Thank you!","['sheaf-cohomology', 'algebraic-geometry', 'schemes', 'sheaf-theory', 'coherent-sheaves']"
1223149,Why can't three unit regular triangles cover a unit square?,"A square with edge length $1$ has area $1$.
An equilateral triangle with edge length $1$ has area $\sqrt{3}/4 \approx 0.433$.
So three such triangles have area $\approx 1.3$, but 
it requires four such triangles to cover the unit square, e.g.: Q . How can it be proved that three unit triangles cannot cover a unit square? I am not seeing a straightforward route to proving this.","['euclidean-geometry', 'geometry', 'discrete-geometry', 'packing-problem']"
1223160,What's the supremum of the following set $\{ n + \frac{(-1)^n}{n} : n \in \mathbb{N}\}$,"What's the supremum of the following set $\{ n + \frac{(-1)^n}{n} : n \in \mathbb{N}\}$? I know that the infimum is $0$, but what about the supremum? I have calculated with Maxima the first $1000$ terms, and it seems that the numerator grows faster than the denominator (because we are adding or removing always a smaller fraction), could it be $\infty$?","['elementary-set-theory', 'calculus']"
1223166,Determine the expected value of $X$ using indicator random variables,"Let $n\geq 1$ be an integer. Consider a uniformly random permutation $a_1, a_2, \ldots , a_n$ of the set $\{1, 2, \ldots , n\}$. Define random variable $X$ to be the number of indices $i$ for which $1 \leq i \lt n$ and $a_i < a_{i+1}$. Determine the expected value $E(X)$ of $X$. (Hint: Use indicator random variables.) I know that $X_i = 1$, if $a_i \lt a_{i+1}$ and $0$, otherwise So I have determined that $E(X) = P(X_i=1)$ but I am not sure how to figure out what the $P(X_i=1)$ is.","['probability', 'discrete-mathematics']"
1223193,"How ""big"" can the center of a finite perfect group be?","A perfect group is a group where the derived (commutator) subgroup $G'$ of $G$ equals $G$. $G'$ measures the ""non-abelian-ness"" of $G$, in a sense. This suggests that ""many"" elements of perfect $G$ don't commute, though ""many"" others must commute in any finite group, given that any element of a finite group generates a cyclic subgroup. It occurred to me that the center $Z(G)$ of $G$ might provide some guidance: e.g. the center (elements that commute with everything) of a perfect group must be ""small"", perhaps as small as trivial (e.g. the center of perfect $A_5$ is trivial). But some Googling suggests that the center of a perfect group need not be trivial ( Gr$\ddot{u}$n's lemma : $G/Z(G)$ is centerless, but $Z(G)$ may be nontrivial). I think I'm interpreting this correctly, but I could be wrong! Question: Does $G$ being a finite perfect group say anything about the structure of $Z(G)$? In particular, is there a lower bound on its index $[G:Z(G)]$ in terms of $|G|$?","['group-theory', 'finite-groups']"
1223244,Are there any irrational numbers that have a difference of a rational number?,"Are there any irrational numbers that have a difference of a rational number? For example, if you take $\pi - e$, it looks like it will be irrational ($0.423310\ldots$) - however, are there any irrational numbers where this won't be the case? Edit to keep up with the answers: Cases where it won't be the case: $yX - y(X + n)$, where $X$ is irrational, or equivalent have been covered $e^{\pi  i} = -1$ has been covered the golden ratio ($\phi$) has been covered Are there any other cases? $e^\pi - \pi$ comes close, but not quite - are there any cases such as this where the result is a (proper) rational number?","['transcendental-numbers', 'number-theory', 'irrational-numbers', 'rationality-testing']"
1223274,Can Three Equilateral Triangles with Sidelength $s$ Cover A Unit Square?,"A previous question on the site asked for a short proof of the fact that three equilateral triangles with unit side length cannot be arranged to cover a square with unit side lengths. Given the truth of that assertion, I began to wonder: What is the minimum side-length $s$ such that three equilateral triangles with side-length $s$ cover a square with unit side length? The existence of such an $s$ follows from a simple compactness argument. It is clear, from the previous question, that $1<s$ and it is easy to construct a cover of a square with equilateral triangles of sidelength $\frac{2\sqrt{3}}3$ as: It would not surprise me too much if $s=\frac{2\sqrt{3}}3$ - that is, if the altitude of the triangle had to be of unit length - but I cannot think of any reason to believe this. (I would be particularly interested in a proof akin to the proof I gave to the other question - i.e. defining something akin to a measure $\mu$ and showing that $3\mu(\text{triangle})<\mu(\text{square})$, but any proof is good with me). It has been pointed out in comments that the following configuration is better: The sidelength is $\frac{1}2\left[\frac{2\sqrt{3}}3+1\right]$.","['optimization', 'combinatorial-geometry', 'geometry', 'triangles']"
1223275,"Complete example of haar measure on compact groups like $GL(n,R)$","I am currently reading the proof of existence of haar measure, but I learn better mostly by examples so I would like examples of explicit computation of haar measure mainly on any $Gl(n,R)$ or any lie groups and please also explain the details as I didn't take a course in harmonic analysis I want to understand more what is going on explicitly since I understand stuff more with examples. For example given some matrix in Gl(n,R) I want to see computation done on it.","['lebesgue-measure', 'measure-theory', 'harmonic-analysis', 'self-learning', 'examples-counterexamples']"
1223280,"Why is $\frac{d}{dt}|\xi(t)|^2=2<\xi, \nabla \xi>$, when $\nabla$ is the covariant derivative?","I understand that: $(1) \frac{d}{dt}|\xi(t)|^2=2<\xi, \nabla \xi>$ if this is happening in $\mathbb{R}^n$. But my question is in the following setting: $\nabla \xi:=K_{c^*\pi} \circ T \xi.\partial t$, where $K_{c^*\pi} $ is the connection induced by the induced bundle of a function $c:S \rightarrow M$, where $S$ is the sphere and $M$ is the manifold (which I'm supposing has a connection on a bundle $\pi : E \rightarrow M$, and $\partial t$ is the canonical tangent vector of the sphere - This is according to Klingenberg's Lectures on Closed Geodesics). I'm having trouble understanding why $(1)$ holds in this case.","['differential-geometry', 'riemannian-geometry']"
1223305,Distributor? Distributive analog of commutator and associator?,"Motivation: ""the commutator gives an indication of the extent to which a certain binary operation fails to be commutative"" ( http://en.wikipedia.org/wiki/Commutator ). For example (courtesy of wikipedia), in a group, $G$, for each $g,h \in G$, the commutator of $g$ and $h$, $[g,h]$ is defined by,
$$[g,h] = g^{-1}h^{-1}gh$$ ""the term associator is used in different ways as a measure of the nonassociativity of an algebraic structure"" ( http://en.wikipedia.org/wiki/Associator ). For example (thanks wikipedia!), for a nonassociative ring or algebra $R$, the associator is the multilinear map $[\cdot,\cdot,\cdot] : R \times R \times R \to R$ given by,
$$[x,y,z] = (xy)z-x(yz)$$ Comment: I was expecting to find an analog to the associator and commutator for the property of distributivity. I've failed to find such an analog on wikipedia and via google searches. This lack of information gives me a sad face. Question: My question is, does an established analog to the (concept of the) associator and commutator exist for the property of distributivity? If so are there any good sources of information on it and its use? In certain situations we can define an operator that measures the degree to which one binary operation fails to be (left/right) distributive over another and call it the (left/right) distributor. For example suppose $(S,+,\times)$ is an algebraic structure such that $(S,+)$ is an abelian group and $(S,\times)$ is a semigroup. Then we can define the left distributor, $\mathrm{Ldis} : S \times S \times S \to S$, by
$$\mathrm{Ldis}(x,y,z) = xy+xz - x(y+z)$$
Similarly we can define the right distributor, $\mathrm{Rdis} : S \times S \times S \to S$, by
$$\mathrm{Rdis}(x,y,z) = yx+zx-(y+z)x$$
where, as per usual, $-$ is used to denote additive inverse, juxtaposition is used in place of $\times$, and $\times$ has higher precedence than $+$. In the case that $\times$ is commutative, $\mathrm{Ldis} = \mathrm{Rdis}$, and we can define the distributor, $\mathrm{dis}$, by setting it equal to the left or right distributor. Example: In any ring we have,
$$\mathrm{dis}(x,y,z) = 0$$ Example: In any wheel algebra we have,
$$\mathrm{dis}(x,y,z) = 0x$$ Side question: Can anyone think of any other structures with a distributor-like operator satisfying an identity which does not force said structure to be trivial? Any help or information on the subject is very much appreciated. Thank you for your time and consideration. I hope you have a great day. Sincerely, DAS","['abstract-algebra', 'universal-algebra', 'category-theory']"
1223318,Why is it true that every set in $\mathbb R^n$ can be covered by a countable union of open balls?,Why is it true that every set in $\mathbb R^n(n\geq 2$ can be covered by a countable union of open balls? This is the fact we are using in the definition of measure theory where outer measure of a set is defined to be the infimum of all countable open coverings of open balls covering that given set How to be sure that one such covering exists?,['measure-theory']
1223320,Distributing r identical obejcts into n distinct containers.,"So, lets say I have $4$ burglars, and I have a custom pistol with $10$ bullets in it. How many possible ways can I put $10$ bullets into EXACTLY $2$ burglars and let the other $2$ get away? Note that I am NOT looking for an ANSWER, I am only asking if it is possible for someone to help me understand why my initial conditions are incorrect. In particular, can someone confirm if what I am doing below is correct? *My technique is to use the inclusion exclusion formula where it is $$E_2 = S_2 - \binom{3}{1}S_3 + \binom{4}{2}S_4$$ where $S_i$ stands for the possibilities where $i$ burglars get a bullet in them. Now, lets say I want to find $S_2$, which is the number of ways to distribute $10$ bullets amongst $2$ burglars. Would the answer to this perhaps be $$\binom{4}{2}(10^2 - 2)$$ where we first choose $2$ burglars out of the $4$ and then with the $2$ burglars each can have $10$ bullets so $10^2$ and then I minus $2$ because each has to have at least $1$. Can someone please confirm if I did $S_2$ correctly? The answer is $6132$ just in case anyone is wondering...",['discrete-mathematics']
1223409,"How to find the derivative of an integral where both, the limit and the integrand, are functions of x?","I found a good expository paper by Keith Conrad, which explains by examples the technique of derivative under the integral sign. Here's the link: http://www.math.uconn.edu/~kconrad/blurbs/analysis/diffunderint.pdf In these examples, the integrand is a function of both $x$ (the variable on which the differentiation is intended) and the parameter $t$. However, in most of the examples given in the paper, the limits of integration are constants. Then, there're these following links from mathmistakes.info, which have examples where the limit of the integral is a function of $x$ but the integrand itself is independent of $x$ (i.e. the integrand is solely a function of $t$). http://www.mathmistakes.info/facts/CalculusFacts/learn/doi/doi.html http://www.mathmistakes.info/facts/CalculusFacts/learn/doi/doif.html I was looking for techniques for differentiating integrals of the following kind
$$\int_0^{g(x)} h(x,t) dt$$
where both the limit and the integrand are functions of $x$. I would prefer to have some examples of course, but any insight is appreciated.","['derivatives', 'definite-integrals', 'integration']"
1223417,Is it necessary for one to understand analysis?,"Is it necessary for one to understand analysis in order to pursue a career in mathematics? Basically, I am very weak at analysis. But the problem is that most of the topics listed in the syllabus include analysis: Real analysis Complex analysis Topology Functional analysis Measure theory Manifold theory All require a good understanding of analysis. Is there any scope for me to survive in the mathematical world? I am only interested in Group Theory and Ring Theory (i.e, Abstract Algebra). Is it possible for me to just carry on, or will I also have to develop a liking for the topics listed above? Is it possible to pursue a career without them? Sorry if the question is very personal, but I donât have other options.","['analysis', 'learning', 'soft-question']"
1223425,Total number of unordered pairs of disjoint subsets of S,"Let $S = \{1, 2, 3, 4\}$. Find the total number of unordered pairs of
  disjoint subsets of $S$. I know the answer is $41$ since it's solved in the book as the expression $$\frac{3^4 -1}{2!} +1 \ .$$ I couldn't get through the solution above, I have solved it by making pair of sets. Please help me to understand the way by which the question has been solved in the book.","['elementary-set-theory', 'combinatorics']"
1223439,Solution of Second Order Differential Equation with non-constant coeffecient,"How do we solve the differential equation $y''-2(\sin x)y'-(\cos x-\sin^2x)y=0$ IVP: $y\left(\dfrac{\pi}{2}\right)=0$ , $ y'\left(\dfrac{\pi}{2}\right)=1$ ?
Its neither constant coeffecient, nor $Cauchy-Euler$. I really don't know how to proceed. We need to find the value of $y(0)$",['ordinary-differential-equations']
1223464,A second opinion on a proof in topology,"My friend and I were looking over some homework questions for an upcoming test in introductory topology, and one of the questions on the homework was to show that a metric space is normal. What we came up with on the spot was this: Set $(X, d)$ a metric space. Let $A, B$ be closed and disjoint subsets of $X$. Then let \begin{align*}
U = \{x : d(x, A) < d(x, B) \}, \\
V = \{x : d(x, A) > d(x, B) \}
\end{align*} Clearly $U$ contains $A$, and $V$ contains $B$. Furthermore, $U$ and $V$ are each disjoint. The one thing left is to demonstrate openness, and this is where I want to be sure I have it. Let $f : x \mapsto d(x, A) + d(x, B) i $ be a map from $X$ to $\mathbb{C}$. It's clearly continuous. Now, $U$ is the pre-image of $\{ a + bi : b > a \}$, an open set, so $U$ is open, and likewise for $V$. I came up with this on the fly. I just want to be sure this method is sound. Edit: It also just occurred to me that a simpler map to have used might have been $g : x \mapsto d(x, A) - d(x, B)$, and then look at the pre-images of positives and negatives.","['separation-axioms', 'proof-verification', 'general-topology']"
1223486,Smallest number of points on plane that guarantees existence of a small angle,"What is the smallest number $n$, that in any arrangement of $n$ points on the plane, there are three of them making an angle of at most $18^\circ$? It is clear that $n>9$, since the vertices of a regular 9-gon is a counterexample. One can prove using pigeonhole principle that $n\le 11$. Take a edge of the convex hull of points. All the points lie to one side of this line. cut the half-plane into 10 slices of $18^\circ$ each. There can't be any points in the first and last slice. Thus, by pigeonhole principle some slice contains more than one point. So we have an angle of size at most $18^\circ$. Now, for $n=10$, I can not come up with a counterexample nor a proof of correctness. Any ideas?","['pigeonhole-principle', 'geometry']"
1223528,Motivation behind Quasitriangular Hopf algebra,I would like to know why it is interesting to define the quasi-triangular structure on a Hop algebra. I understand that the pseudo-co-commutative (the existence of an intertwining operator between the co-product and the opposite co-product) together with the quasi-triangular property implies the Yang-Baxter equation. What does the quasi-triangular property means? In physics I the YBE leads to the notion of integrable systems. However what role does in play in mathematics?,"['abstract-algebra', 'hopf-algebras', 'quantum-groups']"
1223538,How to prove every partition of same cardinality sets has same cardinality?,"Assume $A$ is a set, and $A$ is partitioned into two ways, $\{A_i\}$ and $\{B_i$} where any $A_1,A_2 \in \{A_i\}$ and $B_1,B_2 \in \{B_i\}$ we have $|A_1|=|A_2|=|B_1|=|B_2|$. Then is that true $|\{A_i\}|=|\{B_i\}|$? Intuitively, $|\{A_i\}|=|\{B_i\}|=|A|/|A_1|$ where $A_1 \in \{A_i\}$. However it makes sense when it's only in finite case. I can't construct bijection between those two partitions. Help me.",['elementary-set-theory']
1223630,Concerning series of positive real numbers whose terms are decreasing and tending to $0$,"Let $\{a_n\}$ be a decreasing sequence of positive real numbers such that $\lim_{n \to \infty} a_n=0$ and $\sum_{n=1}^{\infty}a_n= \infty$ ( for eaxmple , like $a_n:=\dfrac 1n$ ), then is it true that for every $r>0$ , there exists a subsequence  $\{a_{r_n} \}$ of $\{a_n\}$ such that $\sum_{n=1}^{\infty} a_{r_n}=r$ ? For example , for $\sum\dfrac 1n =\infty$ and  $e>0$ , we have subsequence $\{\dfrac 1{n!}\}$ of $\{\dfrac 1n\}$ such that $\sum \dfrac 1{n!}=e$ , but even for this sequence $\{\dfrac1 n \}$ , I am not able to prove my  claim for general $r>0$ . Please help . Thanks in advance","['analysis', 'sequences-and-series', 'limits', 'real-analysis']"
1223651,$\int_a^b |f(x)||g(x)| dx \leq \left(\int_a^b |f(x)|^p dx\right)^{\frac1p}\left(\int_a^b |g(x)|^q dx\right)^{\frac{1}{q}}$,"Let $p\gt 1,q\gt 1$ be the dual indices, $\frac1p + \frac1q = 1$ and let $X$ be the space of all continuous functions on $[a,b]$ with two real numbers $a\lt b$. $f(x)$ and $g(x)$ are continuous functions on $[a,b]$ I want to prove that: $$\int_a^b |f(x)||g(x)| dx \leq \left(\int_a^b |f(x)|^p dx\right)^{\frac1p}\left(\int_a^b |g(x)|^q dx\right)^{\frac{1}{q}}$$ I have been suggested to use young's inequality, but I can't find the relevant thing to use. It seems on wiki to be very relevant to use 'Young's inequality for convolutions', but I have never dealt with any $L^p$ spaces, should I just learn these, or is this not what they were referring?",['functional-analysis']
1223664,"Show that $Y^2-X^3\mid f$ if $f$ vanishes on the curve $C: (t^2,t^3)$, and determine what property of a field $k$ will ensure that the result holds.","Let $\phi: \mathbb{R^1}\rightarrow \mathbb{R^2}$ be the map given by $t \mapsto (t^2,t^3)$; prove directly that any polynomial $f\in \mathbb{R}[X,Y]$ vanishing on the image $C=\phi(\mathbb{R^1})$ is divisible by $Y^2-X^3$. Determine that property of a field $k$ will ensure that the result holds for $\phi: k\rightarrow k^2$ given by the same formula. Here is how I did the first part: By division algorithm, I can write $$f(X,Y)=(Y^2-X^3)f_1(X,Y)+Yf_2(X)+f_3(X)$$ Since $f(t^2,t^3)=0$ for all $t\in \mathbb{R}$, we have, for all $t$, $$t^3f_2(t^2)+f_3(t^2)=0$$ Comparing the odd and even power terms of $t$ gives $$f_2(X)=f_3(X)=0$$ This shows $f$ is divisible by $Y^2-X^3$. I am not sure how to do the second part though. It seems to me the argument could work for all fields, unless the division algorithm fails. But when does it fail? Or will the odd and even power argument fail at some point? Thank you for your help!","['elliptic-curves', 'algebraic-geometry', 'parametric']"
1223712,Range of $f(x) =\frac {x -1}{x^2 -2x + 3} $?,"Is my solution for finding the range of 
$$f(x) = \frac{x-1}{x^2 -2x + 3} $$
correct?
Since its Domain is $ \mathbb{R} $, so transforming this equation into $x$ in terms of $y$ , we get $$ yx^2 - (2y +1)x + (3y+1) = 0 $$
Now, since $ x \in \mathbb {R} $ , so its discriminant $\mathbb{D}$ must be $ \ge 0 $, so we have, $$ (2y + 1)^2 - 4y(3y + 1) \ge 0 $$ Solving it, we get
$$ y \in \left[-{1 \over {2 \sqrt2}}, {1 \over {2 \sqrt2}}\right] $$
Kindly solve my problem.","['calculus', 'functions']"
1223718,linear approximation with respect to L1 norm,"I am trying to solve this problem:
Find the best $L^1$ linear approximation of $e^x$ on [0,1] i.e. minimize 
$\int_0^1|e^x-\alpha-\beta x| dx$ any hints how to proceed","['convex-optimization', 'optimization', 'linear-algebra']"
1223719,reciprocal vectors,"I don't understand some of the terminology in this  question. I googled reciprocal vectors and got an article on reciprocal lattices, but I'm not sure if that is what they are talking about in this question. Also, when they say that ${\bf A}$, ${\bf B}$, and ${\bf C}$ are defined by ... plus cyclic permutations, again I looked at the wikipedia article on the subject, but I still do not understand the concept. Does anyone have a link for a clear explanation? The vectors ${\bf a}$, ${\bf b}$, and ${\bf c}$ are non-coplanar, and
  form a non-orthogonal vector base. The vectors ${\bf A}$, ${\bf B}$,
  and ${\bf C}$, defined by $$ {\bf A} = \frac{{\bf b}\times {\bf c}}{{\bf a}\cdot{\bf b}\times
 {\bf c}}, $$ plus cyclic permutations, are said to be reciprocal vectors. Show that $$ {\bf a} = \frac{{\bf B}\times {\bf C}}{{\bf A}\cdot{\bf B}\times {\bf
 C}}, $$ plus cyclic permutations. thanks","['vectors', 'linear-algebra']"
1223725,"For each irrational number $b$, does there exist an irrational number $a$ such that $a^b$ is rational?","It is well known that there exist two irrational numbers $a$ and $b$ such that $a^b$ is rational. By the way, I've been interested in the following two propositions. Proposition 1 : For each irrational number $a\gt 0$ , there exists an irrational number $b$ such that $a^b$ is rational. Proposition 2 : For each irrational number $b$ , there exists an irrational number $a$ such that $a^b$ is rational. I got the following : Proposition 1 is true. Suppose that both $\frac{\ln 2}{\ln a}$ and $\frac{\ln 3}{\ln a}$ are rational. There exists a set of four non-zero integers $(m_1,m_2,n_1,n_2)$ such that $\frac{\ln 2}{\ln a}=\frac{n_1}{m_1}$ and $\frac{\ln 3}{\ln a}=\frac{n_2}{m_2}$ . Since one has $a=2^{m_1/n_1}=3^{m_2/n_2}$ , one has $2^{m_1n_2}=3^{m_2n_1}$ . This is a contradiction. It follows that either $\frac{\ln 2}{\ln a}$ or $\frac{\ln 3}{\ln a}$ is irrational. Hence, either setting $b=\frac{\ln 2}{\ln a}$ or setting $b=\frac{\ln 3}{\ln a}$ works. Then, I began to consider if proposition 2 is true. To prove that proposition 2 is true, it is sufficient to show that for each irrational number $b$ , there exists a rational number $c$ such that $c^{1/b}$ is irrational. This seems true, but I have not been able to prove that. So, my question is the following : Question : Is proposition 2 true? If yes , how can we show that? If no , what is a counterexample? Proposition 2 : For each irrational number $b$ , there exists an irrational number $a$ such that $a^b$ is rational.","['rational-numbers', 'number-theory', 'irrational-numbers', 'exponentiation']"
1223727,How to differentiate $y=\sqrt{\frac{1+x}{1-x}}$?,"I'm trying to solve this problem but I think I'm missing something. Here's what I've done so far: $$g(x) = \frac{1+x}{1-x}$$ $$u = 1+x$$
$$u' = 1$$ $$v = 1-x$$
$$v' = -1$$ $$g'(x) = \frac{(1-x) -(-1)(1+x)}{(1-x)^2}$$
$$g'(x) = \frac{1-x+1+x}{(1-x)^2}$$
$$g'(x) = \frac{2}{(1-x)^2}$$ $$y' = \frac{1}{2}(\frac{1+x}{1-x})^{-\frac{1}{2}}(\frac{2}{(1-x)^2})
$$","['calculus', 'derivatives']"
1223743,Gradient in local coordinates on a manifold with Riemannian metric,"Let $M$ be a smooth manifold with a Riemannian metric g : $TM\otimes TM$ -> R If f is a smooth function from M to R , the gradient of f with respect to g is the vector field $\nabla f$ defined by $df$=$g(\nabla f, *)$ (1) In local coordinates {$x^i$}, compute $\nabla f $ in terms of local coordinates. (2) Now consider $p \in M$. Show that if $V \in T_p M$ satisfies $df_p(V)>0$, then there exists a Riemannian metric $g$ on $M$ with $\nabla f(p)$=$V$ I'm having trouble with how to represent $g(\nabla f, *)$ in terms of local coordinates. Any help would be appreciated. Thanks.","['coordinate-systems', 'differential-geometry', 'manifolds', 'riemannian-geometry']"
1223809,"Finding the area of the 4th triangle, given the areas of the other 3, and all the 4 form a rectangle","In one of my tutorial classes, when I was studdying in 9th class (I am in 10th now), our tutor gave us a problem saying itâs a difficult one, and to him, it was incomplete . This is that problem: In a rectangle ABCD , point B is joined to the points P and Q on the sides AD and DC respectively. And P and Q are joined to form three distinct triangle; namely PDQ or x , QCB or y , BAP or z and BPQ or f . Given the area of x = 3m^2 , y = 4m^2 and z = 5m^2 , find the area of f . Note: all the information regarding this problem has been provided. The dimensions of any of the line segments are not known . This also means that the exact positions of P and Q on their respective line segments are also not known . Because of the lack of information (See Note ), my tutor declared it as an incomplete problem (he is just a high-school Science and Mathematics teacher, please donât expect him to think beyond the limits of a typical high-school student, that is, in case he is wrong). After a few hours of brainstorming, I came up with what I called an ingenious method . But then I felt that my method actually was not accurate. So, can anybody tell me if this problem is complete and solvable, if yes, is my method correct (see below), if no, what is the best/better method to solve it. MY METHOD: As all the triangles with their areas given are on the edge of the rectangle, we know that they all are right triangles . So we can say that one of the arms of the right angle is the altitude and the other is the base . Now, we can use the formula (1/2) * base * altitude to calculate their areas. Lets take a as altitude and b as base . (Hereâs the first part of the trick ) We now try all possible _a_s and _b_s for the three triangles, where a and b are natural numbers only . (This is also where the major weakness of my method is. More numbers, i.e., any real numbers should have been tried, but that is infeasible). Note that all possible values are those values that form a triangle of that specified area. For triangle x , we have the following dimensions: - a = 1 , b = 6 - a = 2 , b = 3 - a = 3 , b = 2 - a = 6 , b = 1 # For triangle y , we have the following dimensions: - a = 1 , b = 8 - a = 2 , b = 4 - a = 4 , b = 2 #
  - a = 8 , b = 1 For triangle z , we have the following dimensions: - a = 1 , b = 10 - a = 2 , b = 5 - a = 5 , b = 2 - a = 10 , b = 1 # (Hereâs the other part of the trick) Then, we select those specific dimensions of triangles, which when placed together form a rectangle. The condition we require: When the triangles are placed together to form a quadrilateral the opposite sides of it must be equal. If this quadrilateralâs opposite sides are equal, we know that it is a parallelogram . And as all of the triangles that form the edges are right angled , we have at least one of the angles of the parallelogram right angled_, so we know that this parallelogram is a rectangle . The correct set of dimensions (that we will be using here) are high-lighted in bold, while the once suffixed with a â#â can also be used. So, in triangle x we take PD as altitude and DQ as base.
  In triangle y we take BC as altitude and CQ as base.
  In triangle z we take PA as altitude and AB as base. Henceforth, we now have: (PA + PD) = BC (DQ + CQ) = AB Therefore, the condition is matched. WE NOW HAVE THE CORRECT DIMENSIONS OF THE THREE TRIANGLES Now we can either find the area of f by finding the area of the rectangle and subtracting it by the areas of the three triangles, or by finding the three triangleâs hypotenuse using the Pythagorean formula and then apply the _Herronâs formula _on the hypotenuses. I prefer the former. > After calculating, we have, _f = 8m^2_ Thank you =)","['area', 'geometry', 'triangles', 'rectangles', 'packing-problem']"
1223852,Coin weighting problem,"There are n coins, among which there may or may not be one counterfeit coin. If there is a counterfeit coin, it may be either heavier or lighter than the other coins. The coins are to be weighed by a balance. What is the coin-weighing strategy for 3 weighings and 12 coins(find the counterfeit coin if it is there and tell me whether it is too lighter or heavier)? I think I can find the counterfeit coin between two(4-2-1). But I cannot determine which one of the two and whether it is too lighter or heavier. I'm not sure what tags the problem belongs to. I put it in probability,everyone can help me retag it.","['probability-theory', 'probability']"
1223865,"Computing bases for direct, wedge, tensor products, etc., of given vector spaces","I am filled with all kinds of vector space and I want to make sure I understand the basis for each kind of vector space. Suppose $\{v_i\}_{i=1}^n$ is the basis for vector space $V$, $\{w_j\}_{j=1}^m$ is the basis for vector space $W$. $V+W$: all linear combo of $\{v_i\}$, $\{w_j\}$, basis is $\{v_i,w_j\}$, dimension is $\dim(V)+\dim(W)-\text{number of overlap}$ $V\oplus W$: Same as $V\times W$? $V\times W$: all $(v,w)$ with $v\in V$ and $w\in W$, basis $(v_i,w_j)$, dimension is $\dim(V)\dim(W)$ $V\otimes W$: all linear combo of $v_i\otimes w_j$, basis $v_i\otimes w_j$, dimension is $\dim(V)\dim(W)$. By universal property of tensor, $V\times W$ is isomorphism to $V\otimes W$? $V\bigwedge V$ or $\bigwedge^rV$: all linear combo of $v_i\wedge v_j$, basis $v_i\wedge v_j$ and $i\neq j$, dimension is ${\dim V}\choose r$ $V^{`}\cdot V$ or $S_rV$:(symmetric power) all linear combo of $v_i^{`}\cdot v_j$, basis $v_i^{`}\cdot v_j$ and $i\neq j$, dimension is ${\dim V +r-1} \choose r$. So eventually, I want to understand what are the basis for the two vector spaces $\bigwedge^2(V\oplus W)$ and $ \bigwedge^2V\oplus(V\otimes W)\oplus\bigwedge^2W$(and finally I need to find an isomorphism between these two spaces, which need to prove it maps basis to basis, and that is why I need to make sure I know the basis). Let $\{(v_i,w_j)\}=\{e_k\}$, where $i=1,\cdots,n$, $j=1,\cdots,m$, $k=1,\cdots,nm$. Is $\{e_i\wedge e_j\}_{i,j=1}^{nm}$ with $i\neq j$ the basis for $\bigwedge^2(V\oplus W)$? OMG, I am so confused. BTW, it seems that these two spaces are not isomorphism, is the problem wrong?","['vector-spaces', 'linear-algebra', 'tensor-products']"
1223872,How to prove that $\mathbb{R}$ and $\mathbb{R}^2$ are not homeomorphic?,"I'm asked to prove that $\mathbb{R}$ and $\mathbb{R}^2$ are not homeomorphic. So far, I've been able to prove that $\mathbb{R}\backslash\{a\}$ and $\mathbb{R}^2\backslash\{b\}$ are not homeomorphic, for $a\in \mathbb{R}$ and $b\in \mathbb{R}^2$ . But I don't know how to go on from here. Can anyone give me a hint?",['general-topology']
1223900,"joint distribution, discrete and continuous random variables","This may be trivial, but if X is a random variable uniformly distributed over $[0,1]$ and Y is a discrete random variable such that $\mathbb{P} (Y=y_1) = \lambda \in (0,1]$ and $\mathbb{P} (Y=y_2) = 1 - \lambda$. Now I am seeking to compute the expectation of (a linear function) of the random variable X conditional on Y. Is this possible? Can we think of a ""joint distribution"" of two random variables where one random variable has a continuous density function and the other is discrete? Thank you","['uniform-distribution', 'probability', 'probability-distributions']"
1223910,Divergence of a vector tensor product/outer product: $ u \bullet \nabla u = \nabla \bullet (u \otimes u) $,"I'm currently studying the derivation of the RANS (Reynolds Averaged Navier Stokes) equations, used in the study of turbulence, and I've stumbled upon a step wich I don't understand very well. The problem is on the following identity (one of the steps of the formal derivation of the RANS equations, present in many online texts): $$ u \bullet \nabla u = \nabla \bullet (u \otimes u) $$ , where $ u = \{ u \; v \; w \} $ is a 3D vector and $ u \otimes u $ is the tensor dot product / outer product of vector $u$ by itself: $$ u \otimes u = 
        \begin{pmatrix}
        u^2 & uv & uw \\
        vu & v^2 & vw \\
        wu & wv & w^2 \\
        \end{pmatrix}
$$ My question is: where can I find a proof of the previous equality? When I try to derive it by hand I don't end up with the result above (I'm probably commiting an error somewhere). Can someone derive it (in a simple way) here by hand? I've searched online, but I haven't found anything this specific.","['tensor-products', 'multivariable-calculus']"
1223993,Marginals of (not necessarily finite) measures,"Consider a product of two measurable spaces, $(X,\mathcal{A})$ and $(Y,\mathcal{B})$, and a (not necessarily finite) measure, $\varrho$ on the product space $(X \times Y, \mathcal{A} \otimes \mathcal{B})$. I wonder, if there is any general notion for the ""marginals"" of $\varrho$, so if there is a way to find (or at least prove the existence of) a measure $\mu$ on $(X, \mathcal{A})$ and a measure $\nu$ on $(Y, \mathcal{B})$, for which $\varrho$ equals the product measure $\mu \times \nu$. I need it the case when $\varrho$ is atom-less and $\sigma$-finite, although I would be interested in the general case as well. (By the way, I just realised, that if there are such marginals, they can't be unique: actually, if I multiply $\mu$ with a positive constant $c$, and divide $\nu$ with the same $c$ constant, the results will still be marginals of $\varrho$. Although, I guess, they are uniqe, up to this manipulation.)",['measure-theory']
1224021,Is there error in proof of lemma on Riemann-Roch space of divisor $D$?,"I'm reading Steven Galbraith ""Mathematics of Public Key Cryptography"" and can't understand lemma 8.4.2 on page 154 that necessary for proof of Riemann-Roch theorem. Suppose $C$ $-$ curve over $\mathbb k$. We want to prove that if $D' \ge D$ then $dim_{\mathbb k} (\mathscr L_{\mathbb k} (D')/\mathscr L_{\mathbb k}(D)) \le \deg(D') - \deg(D)$. Where $L_{\mathbb k}(D)$ $-$ Riemann-Roch space of $D$, i.e. $\mathscr L_{\mathbb k} (D) = \{f \in \mathbb k(C)^â : v_P(f) \ge -n_P\ for\ all\ P \in C(\mathbb k)\} \cup \{0\}$. In order to prove that we are trying to prove following fact: Let $P_0 \in C(\overline{\mathbb k})$. Then $dim_{\mathbb k}(\mathscr L_{\mathbb k} (D + P_0)/\mathscr L_{\mathbb k} (D)) \le 1$. Proof is following: Write $D = \sum_{P \in C(\overline{\mathbb k})} n_P(P)$. Note that
  $\mathscr L_{\mathbb k} (D)$ is a $\mathbb k$-vector subspace of
  $\mathscr L_{\mathbb k} (D + P_0)$. Let $t \in k(C)^â$ be a function
  such that $v_{P_0} (f) = n_{P_0} + 1$ (e.g., take $t$ to be a power of
  a uniformizer at $P_0$). If $f \in \mathscr L_{\mathbb k} (D + P_0)$
  then $ft \in O_{P,k}(C)$. We therefore have a $\mathbb k$-linear map
  $\psi : \mathscr L_{\mathbb k} (D + P_0) â \mathbb k$ given by
  $\psi(f) = (ft)(P_0)$. The kernel of $\psi$ is $\mathscr L_{\mathbb k} (D)$ and
  the first part of the statement follows. Let consider following example
$$C(\mathbb Q) = V(y=0),\ f = \frac{x^2-xz}{x^2-2},\ t = \frac{x^2-2}{z^2},\ P_0 = (\sqrt{2}:0:1) \in C(\overline{\mathbb Q}).$$ Hence $ft = \frac{x^2-xz}{z^2}$ and $ft(P_0) = 2 - \sqrt{2} \notin \mathbb Q$. And we cannot say that $\psi : \mathscr L_{\mathbb Q} (D + P_0) â \mathbb Q$. Is that error in book or I don't understand something?",['algebraic-geometry']
1224030,Spectrum of periodic schrÃ¶dinger operators,"In many articles it's stated, as if it's common knowledge, that any SchrÃ¶dinger operator with periodic potenial has purely absolutely continuous spectrum. I've tried to actually find a theorem stateting this with no luck. I've looking in Reed and simon, Teschl and googled endlessly. I can't seem to find any theorem which states this is true in the case of a one dimensional periodic potential? Can you help me out?","['operator-theory', 'functional-analysis']"
1224044,Determining the rate of change of a radius as a sphere loses volume,"Problem: A spherical balloon leaks $0.2\mathrm m^3 / \mathrm{min}$. How fast does the radius of the balloon decrease the moment the radius is $0.5\mathrm m$? My progress: Since we're dealing with the rate of change of the volume, I set up a function for volume wrt. the radius, which would be $$V(r) = \frac43\pi r^3$$ Then I differentiated it, and got $$V'(r) = 4\pi r^2$$ Now, I don't know quite how to use the first piece of information in the problem. Am I going to need to find a $V(t)$ here? As far as I can tell, we can say that $$V'(t) = -0.2$$ but how do I piece all this together? (Assuming I'm right so far.) Any help appreciated!","['volume', 'calculus', 'derivatives']"
1224054,Any idea how to evaluate this equation?,"I'm trying to evaluate(approximate) the following integral $$ F(x,t;q) =  \int_{-\infty}^{\infty}\frac{q}{q+2ik} e^{i(kx +8k^3 t)}\; dk $$
It's similar to the Airy function but I can't get rid of the $\frac{1}{k}$ in front of the exponential. $q>0 $ is a parameter that I can vary. $x \in (-\infty,\infty)$ is my spatial variable $t > 0$ is my time dependence Any ideas? An approximate solution in the large or small $q$ limit would also be fine.","['complex-analysis', 'complex-integration', 'integration']"
1224060,Spivak Calculus Chapter II Exercise 22 :: Arithmetic mean and geometric mean,"the exercise says: If $a_1,\ldots,a_n\ge0$ then the A-M is $A_n=\frac{a_1+\cdots+a_n}{n}$ and G-M is $G_n=\sqrt[n]{a_1a_2\cdots a_n}$ we would like to show that $G_n\le A_n$ (1) suppose that $a_1<A_n$ then some $a_i>A_n$, for convenience say $a_2>A_n$ Let $\overline{a}_1=A_n$ and $\overline{a}_2=a_1+a_2-\overline{a}_1$ show that $$\overline{a}_1\overline{a}_2\ge a_1a_2$$ I can't understand how he concludes $G_n\le \overline{G}_n$, maybe he says suppose that $a_3<A_n$ then  for convenience say $a_4>A_n$, and so $$\overline{a}_1\overline{a}_2\ge a_1a_2\\ \overline{a}_3\overline{a}_4\ge a_3a_4\\ \vdots \\ \overline{a}_{n-1}\overline{a}_n\ge a_{n-1}a_n$$ and multiply each to get the result but what if $a_3=A_n$? is there a  more rigorous proof? also i can't understand the rest of what he says if anyone can clarify it thanks in advance","['calculus', 'inequality']"
1224074,Identity Operator can be uniformly approximated by orthonormal basis,"Let $H$ be a separable Hilbert space with orthonormal basis $e_1, e_2, ...$.  I know that for any $x \in H$, we have $$\|x\|^2 = \sum\limits_n \|\langle x, e_n \rangle\|^2$$ and in fact $x = \lim\limits_{N \to \infty} \sum\limits_{n=1}^N \langle x, e_n \rangle e_n$ in the norm topology in $H$.  I was wonderdering whether this approximation is in any sense uniform.  In particular, whether it is true that $$\|1_H - T_N\| \to 0$$ where $T_N = \sum\limits_{n=1}^N \langle -,e_n \rangle e_n$.  I don't expect this to be true, but it would make my life a lot easier right now if it was.","['hilbert-spaces', 'functional-analysis']"
1224083,"Are $X$ and $X+Y$ independent, if $X$ and $Y$ are independent? [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question As asked in the title? Does the independence of two random variables $X$ and $Y$ imply the independence of $X$ and $X+Y$? If so, what's the easiest way to prove that?","['probability-theory', 'independence', 'random-variables']"
1224085,When are two series the same?,"A series is an expression of the form
$$
\sum_{n=k}^{\infty} a_n
$$
where the $a_n$ are real numbers and they depend on $n$. If $a_n = b_n$ for all $n\geq k$, then I would assume that one would say that the two series
$$
\sum_{n=k}^{\infty} a_n\quad\text{and}\quad \sum_{n=k}^{\infty} b_n
$$
are the same series. Is it true that if two series
$$
\sum_{n=k}^{\infty} a_n\quad\text{and}\quad \sum_{n=k}^{\infty} b_n
$$
are the same, then $a_n = b_n$ are the same for all $n$? The reason that I am asking is because I would think that the two series
$$
0 + 1 + 2 + 3 + \dots \quad\text{and}\quad 1 + 2 + 3 + 4 + \dots
$$
are the same, but $0\neq 1, 1\neq 2, \dots $. So, when exactly are two series the same when considered as elements in the set of all series? Edit: Given the comment and answer below, maybe what I need to know is if it makes sense to talk about the set of all series. If this does make sense, what does it mean that two elements of this set are the same.","['sequences-and-series', 'calculus']"
1224130,Existence of bijection that reorders elements?,"Suppose I have some function $f:\mathbb{R}\to[0,1]$. Does there necessarily exist a bijective mapping $g:\mathbb{R}\to\mathbb{R}$ such that $g(x)\leq g(y)$ implies $f(x)â¤f(y)$? If not, does it help if I restrict the domain to $\mathbb{R}_+$ or a closed interval? Edit: I guess if I take a very ugly function such as the indicator function that is $1$ if and only if $x$ is rational, this may not hold. (In that case, let $x$ be any rational number. Whatever $g(x)$, the set $[g(x),\infty)$ has positive Lebesgue measure, but its pre-image wrt $g$ is countable.) But what about if I only need the properties to hold almost everywhere? Specifically, if the order condition holds except on a set of measure zero, if $\textsf{Im}(g)=\mathbb{R}$ up to a set of measure zero and $g^{-1}(z)$ has measure zero for all $z\in[0,1]$? Proof idea: Here's my original intuition for what could work, but I'm not confident all arguments are sound.
Let $h$ correspond to some probability measure over $\mathbb{R}$ that has full support (by which I mean, if $h(A)=0$, then the set $A$ has Lebesgue measure zero - should I rather call this absolutely continuous?) and admits a distribution function $H$. Then let 
$$g(x)=H^{-1}(1-h(f^{-1}((f(x),\infty)))-h(f^{-1}(\{f(x)\})\cap(x,\infty)).$$ Furthermore, let $$A=\bigcup_{n=1}^\infty\left\{\left(\frac{m}{n},\frac{m+1}{n}\right)\mid 0\leq m<n\text{ and }h\left(f^{-1}\left(\frac{m}{n},\frac{m+1}{n}\right)\right)=0\right\}.$$ Since $f^{-1}(A)$ can be written as a countable union of inverse images with zero measure each, it follows that $h(f^{-1}(A))=0$. In that case, $f(x)<f(y)$ with $x,y\notin f^{-1}(A)$ implies $(f(x),\infty)\supseteq(f(y),\infty)\cup (\{f(y)\}\cap(x,\infty))\cup (f(x),f(y))$ and the inverse image of the last part of this disjoint union has nonzero measure by definition of $A$. This implies $g(x)<g(y)$, establishing the desired order condition. As for bijectivity, let $z\in \mathbb{R}$. I want to show $h(g^{-1}(z))=0$. By the above, all points in $g^{-1}(z)\setminus A$ share a common function value $f(z)$. Let $(a,b)$ be the infimum and the maximum of $g^{-1}(z)$ respectively. By the definition of $g(\cdot)$, it must hold that $h(g^{-1}(z))\leq h(f^{-1}({f(z)})\cap(a,b))=0$. This establishes my notion of ""almost everywhere injective"". Lastly, for surjectivity, let $k=H^{-1}(y)$ for any $y\in\mathbb{R}$. Set $z=\inf\{f(x)\mid h(f^{-1}((f(x),\infty)))<k\}$. Either $h(f^{-1}((z,\infty)))=k$ and $h(f^{-1}(\{z\}))=0$, or $h(f^{-1}((z,\infty)))>k$. Either way, there exists $x\in f^{-1}(\{z\})$ such that $g(x)=H^{-1}(k)$. Does this sound plausible? Shouldn't there be a much more simple approach to prove this intuitive result?","['lebesgue-measure', 'proof-verification', 'real-analysis', 'general-topology', 'reference-request']"
1224134,Stuggling to understand ideal powers,"In my current algebraic number theory course we have defined the multiplication of 2 ideals as the smallest ideal containing all products of elements of both, [i.e: let I and J be ideals of a ring R, then
IJ:={$\sum_1^k a_ib_i : a_i\in I , b_i\in J$} where k depends on R ] we haven't however, formally defined ideal powers, by which I mean ideals of the form $I^x$ where x is an integer. However, using the first, informal definition, it seems to me that all products of elements from I will just again form I i.e. using the formal definition, and taking x = 2 I find that $I^2$ = II = {$\sum_i^k a_ib_i : a_i\in I , b_i\in I$} = {$\sum_1^k c_i : c_i\in I$} = {$d : d\in I$} = I and clearly extending this definition to higher powers results in the same thing? Thanks for any clarification!","['abstract-algebra', 'ideals', 'algebraic-number-theory']"
1224146,Showing that poset of set of supports of a vector space is semimodular,"Let $W$ be a subspace of the vector space $\mathbb{K}^n$, where $\mathbb{K}$ is a field of characteristic $0$. The support of a vector $v = (v_1,\ldots, v_n) \in \mathbb{K}^n$ is given by $\text{supp}(v) = \left\{i : v_i\neq 0\right\}$. Let $L$ denote the set of supports of all vectors in $W$, ordered by reverse inclusion. I want to show that $L$ is a semimodular lattice. By Proposition 3.3.2 in Stanley's Enumerative Combinatorics, vol. 1, we can either show that $L$ is graded (every maximal chain has the same length) and that its rank functions $\rho:L\rightarrow \left\{0,1,\ldots, n \right\}$ satisfies
$$ \rho(s)+\rho(t) \geq \rho(s\wedge t)+\rho(s\vee t)$$ for any $s,t \in L$ or we can show that if $s$ and $t$ both cover $s\wedge t$, then $s\vee t$ covers both $s$ and $t$. Here's the problem...I know that the meet of any $s,t \in L$ is $s\cup t$, but I don't know what the join is. Ultimately what I'm trying to show is the $L$ is a geometric lattice, which requires showing that $L$ is semimodular. Perhaps there is a better way of proving this.","['field-theory', 'order-theory', 'discrete-mathematics', 'lattice-orders', 'combinatorics']"
1224150,Isomorphism from $\mathbb{C}[G]$ to $\prod_{i=1}^h M_{n_i}(\mathbb{C})$.,"What I want to ask is the proof of the Proposition 10. in ""Linear Representations of Finite Groups"" by Jean-Pierre Serre. Let $\rho_i : G \rightarrow GL(W_i)$ be the distinct irreducible representations of $G$.$(1 \le i \le h)$
We can extend $\rho_i$ to $\widetilde{\rho_i} : \mathbb{C}[G] \rightarrow \text{End}(W_i)$ by $\widetilde{\rho_i}(\sum_{g \in G} a_g g) = a_g \sum_{g \in G} \rho_i(g)$. Then $\widetilde{\rho} = (\widetilde{\rho_i}) : \mathbb{C}[G] \rightarrow \prod_{i=1}^{h} \text{End}(W_i) \cong \prod_{i=1}^h M_{n_i}(\mathbb{C})$ is a homomorphism. Then Proposition 10 states that it is an isomorphism. 
Since dimensions of domain and codomain are same, it suffices to show that $\widetilde{\rho}$ is surjective. In the proof of the book, If $\widetilde{\rho}$ is not surjective, then there exists a nonzero linear form on $\prod M_{n_i}(\mathbb{C})$ vanishing on the image of $\widetilde{\rho}$.
This gives a nontrivial relation on the coefficients of the representations $\rho_i$ which is impossible because of the orthogonality formulas of 2.2. But I can not follow the above three lines in the proof. I will appreciate it if you give an explanation for the proof. Thank you.","['abstract-algebra', 'group-theory', 'representation-theory']"
1224163,differentiation of a matrix function,"In statistics, the residual sum of squares is given by the formula $$ \operatorname{RSS}(\beta) = (\mathbf{y} - \mathbf{X}\beta)^T(\mathbf{y} - \mathbf{X}\beta)$$ I know differentiation of scalar functions, but how to I perform derivatives on this wrt $\beta$? By the way, I am trying to take the minimum of RSS wrt to $\beta$, so I am setting the derivative equal to 0. I know somehow product rule has to hold. So here I have the first step $$-\mathbf{X}^T(\mathbf{y}-\mathbf{X}\beta) + (\mathbf{y}-\mathbf{X}\beta)^T(-\mathbf{X})= 0$$","['matrix-calculus', 'derivatives']"
1224168,Is fibonacci sequence a member of more broad family of sequences?,"Yesterday, I was pondering on the Fibonacci sequence and  I started to discover some features of it that were previously unknown to me.
Such as, 1, 1, 2, 3, 5, 8, 13, 21, 34 .... 1 ) The nth element of the sequence is the sum-1 of first n-2 elements.
2) If you multiply the first number with one and the second one with the two and sum them, you would get the fibonacci number, after the next element of the sequence.
For example, 1x1 + 1x2 =  3.
3x1 + 5x2 = 13.
5x1 + 8x2 = 21.
and so on.
What is more, if I do this for another subsequent (5, 8 or 2, 3) fibonacci numbers I would get another Fibonacci number but in this case, I would not skip one element, instead, I would skip 'x' times where 'x' is equal to the index of the first occurence of the subsequent numbers. For example,
3x5 + 5x8 = 55, normally we would get the next element, if the second operands would be one but in this case we get the 4th element after the next fibonacci number. It amazed me and I asked to myself, if there was any other such sequence. Then I realized that, any sequence generated by random two number has the same property.
For example,
suppose that the first two numbers in my sequence are 3 and 4.
I will generate the next element of the sequence by multiplying the previous one with 3, the current one with 4 and summing those two results. Following happens, 3, 4, 25, 112, 523 ... And this series also satisfies the second property mentioned above. So, my question is, Do all this sort of sequences have another name which refers to that abstraction? 
OR is this property trivial?","['sequences-and-series', 'number-theory', 'elementary-number-theory', 'fibonacci-numbers']"
1224192,What is the greatest value of b for which and real valued function f that satisfies the following properties must also satisfy f(1)<5,"The properties listed are: 1) f is infinitely differentiable on the real numbers 2) $f(0) = 1, f'(0) = 1$, and $f''(0) = 2$ 3) $|f'''(x)| < b$ for all x in $[0,1]$ This is question 42 from the GRE math subject test 9367. My idea was to integrate both sides of the inequality in property three, and plug in the info from property 2 for the value of c (post integration). Is this a valid approach? I get the correct answer for b, which is 12, but I don't know if this is mathematically valid to integrate a magnitude, and integrate both sides of an inequality. Please help! Thank you.","['derivatives', 'gre-exam', 'calculus', 'integration']"
1224201,Derive the equation of first variation for a flow of a vector field.,"This is a problem from Susan Colley's Vector Calculus. I have trouble understanding the solution to it. Problem: Derive the equation of first variation for a flow of a vector field. That is, if $\mathbf{F}$ is a vector field of class $C^1$ with flow $\phi$ of class $C^2$, show that $$\frac{\partial}{\partial t}D_{\mathbf{x}}\phi(\mathbf{x},t)=D\mathbf{F}(\phi(\mathbf{x},t))D_{\mathbf{x}}\phi(\mathbf{x},t).$$ Here the expression ""$D_{\mathbf{x}}\phi(\mathbf{x},t)$"" means to differentiate $\phi$ with respect to the variables $x_1,x_2,\ldots ,x_n,$ that is, by holding $t$ fixed. Solution: By definition of a flow of $\mathbf{F}$, we know that $\frac{\partial}{\partial t}\phi(\mathbf{x},t)=\mathbf{F}(\phi(\mathbf{x},t))$. So 
$$\frac{\partial}{\partial t}D_{\mathbf{x}}\phi(\mathbf{x},t)=D_\mathbf{x}(\frac{\partial}{\partial t}\phi(\mathbf{x},t))=D_{\mathbf{x}}\mathbf{F}(\phi(\mathbf{x},t)).$$ Now by the Chain Rule, 
$$D_{\mathbf{x}}\mathbf{F}(\phi(\mathbf{x},t))=D\mathbf{F}(\phi(\mathbf{x},t))D_{\mathbf{x}}\phi(\mathbf{x},t).$$ I don't understand the two equations shown in the solution. First, how can we interchange $\frac{\partial}{\partial t}$ and $D_{\mathbf{x}}$ in the first equation? Also, I don't understand how the Chain Rule leads to the second equation, since we're trying to get $D_\mathbf{x}\mathbf{F}$, not $D\mathbf{F}$. This seems to suggest that $D_\mathbf{x}\mathbf{F}$ is just the matrix of $D\mathbf{F}$ with the first $n$ columns. That is, the partials with respect to the variables $x_1,x_2,\ldots,x_n$. This result confuses me. How does this result make sense starting from the definition of the expression $D_{\mathbf{x}}$ given in the problem? I would greatly appreciate it if anyone could explain the above questions to me.","['vectors', 'vector-analysis', 'multivariable-calculus']"
1224207,Intuition about $v\otimes w$,"In Physics and Differential Geometry usually tensors of type $(k,l)$ on a vector space $V$ over $\mathbb{F}$ are defined as multilinear functions $$f : \underbrace{V\times\cdots\times V}_{k \ \mathrm{terms}}\times\underbrace{V^\ast\times\cdots\times V^\ast}_{l \ \mathrm{terms}}\to\mathbb{F}$$ this makes it quite simple to gather some understanding of $(k,0)$ tensors from one intuitive point of view. They are just $k$-linear functions of vectors and can be used like linear functions of vectors or like inner products and so on. Also it is not hard to see why one would care about these. Now, on the other hand, tensors of type $(0,l)$ also appear in Physics quite frequently. Indeed Maxwell's Stress Tensor is: $$\mathcal T
=
\epsilon_0\left[
\mathbf{E}\otimes\mathbf{E}+c^2\mathbf{B}\otimes\mathbf{B}
-\frac12\sum_i\mathbf{e}_i\otimes\mathbf{e}_i\left(E^2+c^2 B^2\right)
\right].$$ Those objects are not much intuitive IMHO. First, a tensor of type $(0,l)$ is a function of linear functionals in this approach, and this makes it a little bit harder to make sense from a physical and geometrical point of view. The other possible approach to tensors is the one based on the universal property. As far as I understand, the basic idea of this approach is that in the end the construction (with quotient spaces and so on) shows that there exists a way to make sense of the product $v_1\otimes\cdots \otimes v_k$ and that it has all the nice properties we would want. In that case, a tensor of type $(0,l)$ as defined above is an element of $V\otimes\cdots\otimes V$. Of course to understand those objects, it suffices to understand for $v,w\in V$ how $v\otimes w$ can be understood. So my question is: I know the constructions are isomorphic and I know from a rigorous point of view what $v\otimes w$ is, now how can one intuitively make sense of $v\otimes w$? Again, thinking of it as a function of linear functionals doesn't seem much intuitive. So, just regarding it as an element of $V\otimes V$ how can we give to it some geometric and physical intuition? The object $v\wedge w \in V\wedge V$ has one nice way to be understood: it can be thought of as the paralelogram generated by $v$ and $w$, that is one oriented area in the same way as $v$ and $w$ are oriented segments. Now, is there a nice way to understand $v\otimes w$ too?","['vector-spaces', 'tensor-products', 'intuition', 'linear-algebra', 'tensors']"
1224273,An isomorphism theorem for sheaves.,Let $\varphi: \cal{F} \longrightarrow \cal{G}$ a morphism of sheaves. My goal is to prove that $im\varphi \simeq \cal{F} / Ker \varphi$. My thoughts about this problem: 1) $im \varphi(U) \simeq \cal{F}(U) / Ker \varphi(U)$ (a classic result for abelian groups). 2) We have an isomorphism between sheaves iff we have an isomorphism between their stalks.,"['algebraic-geometry', 'sheaf-theory']"
1224283,"Cauchy problem $y' = y + 10\sin y, y(0) = a$","I have a Cauchy problem:
 $y' = y + 10\sin y, y(0) = a$ It is need to find $\frac{\partial y}{\partial a} \Big|_a$ where $a = 0$. I don't know what to do here. Could you help me please?
Thank you.",['ordinary-differential-equations']
1224365,An alternative way to integrate derivatives of inverse trigonometric functions?,"I'm getting through my book for calculus and I tried to evaluate $$A = \int_{-1}^{+1} {x^2 - {2 \over {x^2 + 1}}} \space dx \tag1$$ on my own, as I forgot that $\int{1 \over x^2 + 1} = \tan^{-1}(x) + c$. I wonder, however, why didn't I get the same result when going the other way (using substitution for $x^2 + 1$). $$A = \int_{-1}^{+1} {x^2} dx - 2\int_{-1}^{+1}{1 \over {x^2 + 1}} dx \tag2$$
Choosing $u = x^2 +1$ and $du = 2x\space dx$, I turned the above into
$$A = \Bigg[\space {x^3 \over 3} \space\Bigg]_{-1}^{+1}  - 2\int_{2}^{2}{1 \over u} {1 \over {2x}}du \tag3$$
and because $2 = 2$, $A$ becomes 
$$A = {2 \over 3}\tag4$$ If I do 
$$A = {2 \over 3} + -2\Bigg[\space \tan^{-1}(x) \space\Bigg]_{-1}^{+1} = {2 \over 3} -\pi/2 - \pi/2 = {2 \over 3} - \pi\tag5$$ The answer in my book is ${2\over3} - \pi$ too. I must have $M$essed something up, but I don't know what and where. Would there be some ideas?","['trigonometry', 'calculus', 'definite-integrals', 'integration']"
1224375,How to visualize permutations?,"I'm getting a warning that this is a subjective question, and it very well probably is. But nevertheless, it is still a valid question that helps in the studying of mathematics from my point of view. Visualizing math is very important. I'm studying abstract algebra, reading about permutations, and I'm having a hard time visualizing the group of permutations. For instance, a permutation is defined as a function on a set, $f:A\to  A$, that is 1-1 and onto. The binary operation on this set is composition of functions, which is associative, has an identity and has an inverse. Usually, when I hear of functions, I picture $x^2 + 2x + 1$ or $2x + 2$. Is this what I should be thinking of when I think of a collection of permutations? Because I can't help but confuse my mind by just thinking of all the different ways you can arrange the set. How do y'all picture this set?","['abstract-algebra', 'group-theory', 'intuition', 'permutations']"
1224398,Taylor expansion of a power function,"I was wondering about Taylor expansions of functions of the form $x^p$, where p is a real number, about $x = 0$. It seems clear how to do it about any other point, but what happens to the series as I approach 0? What specifically does ""break down"" in the expansion? As a simple example, I was looking at $y(x) = (1-x^3)^{1/3}$, where the cube root has the usual property that $(-x)^{1/3} = -x$. When I look at the point $x=1$ and the first derivative there, I get division by zero. The function for $x = 1+\epsilon$ looks like $-3^{1/3} \epsilon^{1/3}$, hence I get $-3^{-2/3} \epsilon^{-2/3}$ for the derivative. How to deal with that? Thanks for your help.
SSF","['taylor-expansion', 'polynomials', 'limits', 'derivatives']"
1224415,"How do I prove that $\arccos(x) + \arccos(-x)=\pi$ when $x \in [-1,1]$? [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Prove that $\arccos x + \arccos(-x) = \pi$ when $x \in [-1,1]$. How do I prove this? Where should I begin and what should I consider?","['trigonometry', 'functions']"
