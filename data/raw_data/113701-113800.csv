question_id,title,body,tags
1656348,Method of determining symmetries in an irregular polygon (2D or 3D)?,"Thank you in advance for helping. Given a polygon with $n$ vertices, $$P = \begin{bmatrix} x_{1} & x_{2} & ... & x_{n} \\ y_{1} & y_{2} & ... & y_{n} \end{bmatrix}$$ how does one determine: 1) The axes of symmetry, if there are any 2) Radial (rotational) symmetry, if it exists 3) Any other type of symmetry (or something $close$ to a symmetry, if such a thing exists) Methods involving linear algebra and/or group theory are more than welcome. And if you can suggest, any thoughts for finding symmetries in three-dimensional polygons? (Not sure what they're called...) $$P = \begin{bmatrix} x_{1} & x_{2} & ... & x_{n} \\ y_{1} & y_{2} & ... & y_{n} \\ z_{1} & z_{2} & ... & z_{n} \end{bmatrix}$$","['matrices', 'reflection', 'symmetry', 'group-theory', 'linear-algebra']"
1656369,"For which values $a, b \in \mathbb{R}$ the function $u(x,y) = ax^2+2xy+by^2$ is it the real part of a holomorphic function in $\mathbb{C}$","For which values $a, b \in \mathbb{R}$ the function $$u(x,y) =
 ax^2+2xy+by^2$$ is  the real part of a holomorphic function in
  $\mathbb{C}$. I think we have to take Cauchy-Riemann theorem , but I don't know how to find these two constant from a certain function $f(x,y) = u(x,y)+i v(x,y)$. Is anyone could help me?","['derivatives', 'complex-analysis']"
1656381,Nontrivial subring with identity of a ring without identity [duplicate],"This question already has answers here : Example of a ring without unity that has a subring with unity? [duplicate] (2 answers) Closed 8 years ago . I'm looking for an example a ring and a subring with $R \subset S$ such that $R$ has 1 but $S$ does not. Its easy to choose R to be the trivial ring with $0=1$, but are there any more exotic examples of this phenomenon?","['abstract-algebra', 'ring-theory', 'rngs']"
1656398,Prove that if the altitude and median of a triangle form equal angles with sides then the triangle is right.,"Problem statement: Prove that if the altitude and median drawn from the same vertex of a nonisosceles triangle lie inside the triangle and form equal angles with its sides, then this is a right triangle. After many attempts, I came up with this: let $ABC$ be the triangle where $CH$ is the altitude, $CM$ is the median, and name the angles $ACH = MCB = \theta$, $CAH = \alpha$, $CBM = \beta$ and $HCM = \gamma$. Using the sine theorem in the triangle $CMB$ we get $$\frac{MB}{\sin(\theta)} = \frac{MC}{\sin(\beta)},$$ while using the sine theorem in the triangle $ACM$ we get $$\frac{MC}{\sin(\alpha)} = \frac{MA}{\sin(\theta + \gamma)}.$$ Combining these equations I found $$\sin(\alpha) \sin(\theta) = \sin(\beta) \sin(\theta + \gamma).$$ Applying the identity $$\sin(a)\sin(b) = \frac{\cos(a-b) - \cos(a+b)}{2}$$ I concluded $$\cos(\alpha - \theta) = \cos(\theta + \gamma - \beta).$$ Since all angles are within $[0, \pi]$ range I concluded $$\alpha - \theta = \theta + \gamma - \beta,$$ thus $2 \theta + \gamma = \alpha + \beta$. From the original triangle we know $$2 \theta + \gamma + \alpha + \beta = \pi,$$ and combining the equations proves the triangle is right. Is this correct? Is there a synthetic way to do it?","['euclidean-geometry', 'triangles', 'proof-verification', 'geometry']"
1656405,"How many numbers between $0$ and $999,999$ are there whose digits sum to $r$","How many numbers between $0$ and $999,999$ are there whose digits sum to $r$ In generating a function for the answer, here is what I came to. We have a maximum of 6 number slots to use to sum to r. Then $e_1 + e_2 + e_3 + e_4 + e_5 + e_6 = r$ And since each slot has the capacity to be a number between $0$ and $9$, then $e_i = (1 + x^1 + x^2 + x^3 + x^4 + x^5 + x^6 + x^7 + x^8 + x^9) $, and the generating function is therefore $(1 + x^1 + x^2 + x^3 + x^4 + x^5 + x^6 + x^7 + x^8 + x^9)^6$. Do I have this generating function correct?","['generating-functions', 'combinatorics']"
1656407,Is there a formula for $\sin(xy)$,Can we express a trigonometric function for the product of two angles as a function of trigonometric functions of its factors? For example: Is there a formula for $\sin(xy)$ as a function of $\sin x$ and $\sin y$ or other trigonometric functions of $x$ and $y$.,"['trigonometry', 'calculus']"
1656408,Derivative of Nested Matrix Quadratic Form,"I have two real matrices: $\mathbf{A} \in \mathbb{R}^{k \times d}$, $\mathbf{B} \in \mathbb{R}^{d \times d}$, where $k \leq d$. Further $\mathbf{B}$ is symmetric. I also have two vectors $\mathbf{c},\mathbf{d} \in \mathbb{R}^d$. My question is, what is gradient of the following expression with respect to $\mathbf{A}$:
$$
(\mathbf{A} \mathbf{c})^\top (\mathbf{A} \mathbf{B} \mathbf{A}^\top)^{-1} (\mathbf{A} \mathbf{d})
$$ An observation: I know from the Matrix Cookbook that, if I replace the matrix $(\mathbf{A}^\top \mathbf{B} \mathbf{A})^{-1}$ with a matrix $\mathbf{E} \in \mathbb{R}^{d \times d}$ (that does not depend on $\mathbf{A}$) we have that:
$$
\nabla_\mathbf{A} (\mathbf{A} \mathbf{c})^\top \mathbf{E} (\mathbf{A} \mathbf{d}) = \mathbf{E}^\top \mathbf{A} \mathbf{c} \mathbf{d}^\top + \mathbf{E} \mathbf{A} \mathbf{d} \mathbf{c}^\top
$$ where $\nabla_\mathbf{A}$ signifies the gradient with respect to $\mathbf{A}$. So it seems I'm just missing a chain-rule step. Thank you very much for any insights about this.","['matrices', 'inverse', 'linear-algebra', 'derivatives']"
1656409,How to prove that the increments are independent?,"I shall prove that if two independent processes have each independent increments, then the sum have independent increments. What I have tried is this: Assume we have a probability space $(\Omega, \mathcal{F},P)$, and two stochastic processes $X_t$, $Y_t$.  Let $\sigma(X_{t^*})=\{X_{t^*}^{-1}(B)\}$, the sigma-algebra generated by the variable. And let $\sigma(X_{t_1},X_{t_2})=\sigma(\sigma(X_{t_1}),\sigma(X_{t_2}))$ the sigma algebra generated by the two sigma algebras etc. Let us assume that $s _1\le s_2 \le t_1 \le t_2$. What I need to show is that : $\sigma(X_{t_2}+Y_{t_2}-X_{t_1}-Y_{t_1})$ is independent of $\sigma(X_{s_2}+Y_{s_2}-X_{s_1}-Y_{s_1})$. What I know already is that $\sigma(X_{t_2}-X_{t_1})$ is independent of $\sigma(X_{s_2}-X_{s_1})$ and $\sigma(Y_{t_2}-Y_{t_1})$ is indepent of $\sigma(Y_{s_2}-Y_{s_1})$. And lastly since the two processes are independent i know that $\sigma(X_{t_2},X_{t_1},X_{s_2},X_{s_1})$ is independent of $\sigma(Y_{t_2},Y_{t_1},Y_{s_2},Y_{s_1})$. What I need to end up with is that: $P(X_{t_2}+Y_{t_2}-X_{t_1}-Y_{t_1}\in A, X_{s_2}+Y_{s_2}-X_{s_1}-Y_{s_1} \in B)=P(X_{t_2}+Y_{t_2}-X_{t_1}-Y_{t_1}\in A)\cdot P(X_{s_2}+Y_{s_2}-X_{s_1}-Y_{s_1} \in B)$. But I do get stuck here. My only idea is to work with some kind of reduction, where I look at the variables $X_{t_2}-X_{t_1}=Z_1,Y_{t_2}-Y_{t_1}=Z_2,X_{s_2}-X_{s_1}=Z_3,Y_{s_2}-Y_{s_1}=Z_4$.  The the LHS of what is above is $P(Z_1+Z_2 \in A, Z_3+Z_4 \in B)$. Uintil this point I haven't really gotten anywhere it seems I just have rewritten the problem, maybe the next step is showing that $Z_1, Z_2$, but I am not sure how that follows either(if variables are independent, are their differences also independent.?). Any hints or help on how to solve this?",['probability-theory']
1656426,"Prob. 2, Sec. 20, in Munkres' TOPOLOGY, 2nd ed: The dictionary order topology on $\mathbb{R} \times \mathbb{R}$ is metrizable.","Here's Prob. 2, Sec. 20 in the book Topology by James R. Munkres, 2nd edition: Show that $\mathbb{R}\times \mathbb{R}$ in the dictionary order topology is metrizable. The dictionary order on the set $\mathbb{R} \times \mathbb{R}$ is defined as follows: For any two points $x_1\times y_1$, $x_2 \times y_2$ $\in \mathbb{R} \times \mathbb{R}$, we define $$x_1 \times y_1 \prec x_2 \times y_2$$
  if and only if either $x_1 < x_2$, or if $x_1 = x_2$ and $y_1 < y_2$. Now the dictionary order topology on $\mathbb{R} \times \mathbb{R}$ is the one having as a basis all sets of the fomm 
$$\left( a \times b, a \times c \right) \colon= \left\{ \ x \times y \in \mathbb{R} \times \mathbb{R} \ \colon \ a \times b \prec x \times y \prec a \times c \ \right\},$$ 
where $a, b, c \in \mathbb{R}$ such that $b < c$. Now if we define the funtion $d \colon \left(\mathbb{R} \times \mathbb{R} \right) \times \left( \mathbb{R} \times \mathbb{R} \right) \to \mathbb{R}$ as 
$$d\left( x_1 \times y_1, x_2 \times y_2 \right) \colon = \begin{cases} 1 \ \mbox{ if } \ x_1 \neq x_2; \\ \min \left(\  \vert y_1 - y_2 \vert, \ 1 \ \right) \ \mbox{ otherwise }, \end{cases} $$
then is this function $d$ a metric? How to verify the triangle inequality? Does this function give the dictionary order topology on $\mathbb{R} \times \mathbb{R}$? If $x_1 = x_2 = x_3$, then we have 
$$
\begin{align}
& \ d\left(x_1 \times y_1, x_3 \times y_3 \right) \\
&= \min\left( \vert y_1 - y_3 \vert, \ 1 \right) \\
&\leq \min\left( \vert y_1 - y_2 \vert, \ 1 \right)  + \min\left( \vert y_2 - y_3 \vert, \ 1 \right) \\
& \ \ \mbox{ [using the fact that this minimum is the same as the standard bounded metric on $\mathbb{R}$]} \\ 
&= d\left(x_1 \times y_1, x_2 \times y_2 \right) + d\left(x_2 \times y_2, x_3 \times y_3 \right).
\end{align}
$$
If $x_1 \neq x_2$ and $x_2 \neq x_3$, then we have 
$$
\begin{align}
d\left(x_1 \times y_1, x_3 \times y_3 \right) &\leq 1 < 1 + 1 =  d\left(x_1 \times y_1, x_2 \times y_2 \right) + d\left(x_2 \times y_2, x_3 \times y_3 \right).
\end{align}
$$
If $x_1 = x_2$ and $x_2 \neq x_3$, then $x_1 \neq x_3$ either, and so 
$$
\begin{align}
d\left(x_1 \times y_1, x_3 \times y_3 \right) &= 1 \\
&\leq d\left(x_1 \times y_1, x_2 \times y_2 \right) + 1 \\
&= d\left(x_1 \times y_1, x_2 \times y_2 \right) + d\left(x_2 \times y_2, x_3 \times y_3 \right). \end{align}$$
And, similarly for the case when $x_1 \neq x_2$ and $x_2 = x_3$. Is this demonstration of the triangle inequality complete and correct? PS: Assuming that the above $d$ is a metric, here is my attempt at showing that the dictionary order topology on $\mathbb{R} \times \mathbb{R}$ is indeed the one induced by the metric $d$ above. Let
  $$B \colon= \{ a \} \times (b, c)  = \{ \ a \times t \in \mathbb{R} \times \mathbb{R} \ \colon \ b < t < c \ \} = ( a \times b, a \times c) $$ 
  be a basis element for the dictionary order topology on $\mathbb{R} \times \mathbb{R}$, and let $x \times y \in B$. Then of course $x = a$ and $b < y < c$. Let us put 
  $$ \epsilon \colon= \min \{ \ y-b, c-y, 1 \}.  $$
  Then if $s \times t \in B_d ( x \times y, \epsilon)$, then $s \times t \in \mathbb{R} \times \mathbb{R}$, and 
  $$ d( s \times t, x \times y ) < \epsilon. \tag{1}$$
  and, as $\epsilon \leq 1$, so 
  $$ d( s \times t, x \times y ) < 1, $$
  which implies that $s = x$, that is, $s = a$, and also from (0) we can conclude that 
  $$ d( s \times t, x \times y ) = \min \{ \  \lvert t-y \rvert, 1 \ \}. $$
  Then (1) implies that 
  $$
d( s \times t, x \times y ) = \min \{ \  \lvert t-y \rvert, 1 \ \} < \epsilon = \min \{\  y - b, c - y , 1 \ \}. $$
  So 
  $$ d( s \times t, x \times y ) = \lvert t-y \rvert < \min \{ \ y-a, b-y \} , $$ 
  The last relation implies that $b < t < c$. So $s \times t \in B$. Thus for any basis set $B$ for the dictionary order topology and for any element $x \times y \in B$, we have a basis element $B_d ( x \times y, \epsilon)$ for the $d$-metric topology such that 
  $$ x \times y \in B_d ( x \times y, \epsilon ) \subset B. $$
  So the $d$-metric topology is finer than the dictionary order topology on $\mathbb{R} \times \mathbb{R}$. Now let us consider an open ball $B_d( a \times b, \epsilon )$, where $a \times b \in \mathbb{R} \times \mathbb{R}$ and $\epsilon > 0$ are arbitrary. Let $x \times y \in B_d ( a \times b, \epsilon )$. Then if we choose a real number $\delta$ such that 
  $$ 0 < \delta < \min \{ \ \epsilon - d( a \times b, x \times y), \ 1 \ \}, $$
  then we note that $\delta < 1$ and also that 
  $$ B_d ( x \times y, \delta ) \subset B_d ( a \times b, \epsilon ). \tag{2} $$ Now let us put 
  $$ B \colon= \{ \ x \ \} \times ( y-\delta, y + \delta) = \big( \ x \times (y-\delta), \ x \times (y+ \delta) \ \big). $$
  Then this $B$ is a basis element for the dictionary order topology on $\mathbb{R} \times \mathbb{R}$ such that $x \times y \in B$. Moreover, if $s \times t \in B$, then 
  $s = x$ and $y-\delta < t < y+\delta$ and hence $\lvert t-y \rvert < \delta$. But $\delta < 1$. 
  So 
  $$ d( s \times t, x \times y ) = \min \{ \lvert t-y \rvert, 1 \} = \lvert t-y \rvert < \delta,  $$
  which implies that $ s \times t \in B_d( x \times y, \delta )$ and hence also that $s \times t \in B_d( a \times b, \epsilon)$ by virtue of (2) above. Therefore $B \subset B_d( a \times b, \epsilon)$. Thus we have shown that for any basis element $B_d( a \times b, \epsilon)$ for the $d$-metric topology and for any element $x \times y \in B_d( a \times b, \epsilon)$, there is a basis element $B$ for the dictionary order topology on $\mathbb{R} \times \mathbb{R}$ such that 
  $$ x \times y \in B \subset B_d( a \times b, \epsilon). $$
  Thus the dictionary order topology is finer than the $d$-metric topology. The preceding few paragraphs show that the $d$- metric topology is the same as the dictionary order topology on $\mathbb{R} \times \mathbb{R}$. Is this proof correct? Is each and every step of it correct in its logic and presentation? If not, then where lies the problem?",['general-topology']
1656431,How can I show that a function is non-decreasing,"I have the following function: $$F(x)=\begin{cases} \dfrac{x}{x+1},& \text{if }x\ge 0,\\ 0,& \text{otherwise}\end{cases}$$ I want to prove that it is right-continuous and non-decreasing. To show it's right continuous, I had to show that 
$$\lim_{x\to 0^+} F(x)=F(0). $$
$$\lim_{x\to 0^+} F(x)= \frac{0}{1+0} = 0 \quad\mbox{ and }\quad F(0)=0.$$
Since they are both equal, that proves the right continuity. (correct me if I'm wrong plz) For non-decreasing, I know that I must show that $x\le y$ implies $F(x)\le F(y)$, but I don't know how to do that. I can't find anything online to help.","['real-analysis', 'functions']"
1656500,"If $f:[0,\infty)\to [0,\infty)$ and $f(x+y)=f(x)+f(y)$ then prove that $f(x)=ax$","Let $\,f:[0,\infty)\to [0,\infty)$ be a function such that $\,f(x+y)=f(x)+f(y),\,$ for all $\,x,y\ge 0$. Prove that $\,f(x)=ax,\,$ for some constant $a$. My proof : We have , $\,f(0)=0$. Then , 
$$\displaystyle f'(x)=\lim_{h\to 0}\frac{f(x+h)-f(x)}{h}=\lim_{h\to 0}\frac{f(h)}{h}=\lim_{h\to 0}\frac{f(h)-f(0)}{h}=f'(0)=a\text{(constant)}.$$ Then, $\,f(x)=ax+b$. As, $\,f(0)=0$ so $b=0$ and $f(x)=ax.$ Is my proof correct?","['functional-equations', 'calculus', 'analysis']"
1656525,Kantorovich distance: discrete distributions,"Let $\mu,\nu$ be two discrete distributions on $\Bbb R$, and for simplicity assume that each takes only a finite number of values. For example, $\mu$ gives probabilities $p_i$ to points $x_i$ and $\nu$ gives probabilities $q_j$ to points $x_j$. The Kantorovich distance between them can be computed as 
$$
  \int_{-\infty}^\infty |F_\mu(t) - F_\nu(t)|\mathrm dt.
$$
Is there a way to simplify this expression in my setting?","['probability-theory', 'optimal-transport', 'measure-theory']"
1656526,"An ellipse is drawn with the major and minor axes of lengths of $10$ and $8$, Then radius of circle which touches that ellipse.","An ellipse is drawn with the major and minor axes of lengths of $10$ and $8$ respectively Using one focus as center is drawn such that it is tangent to the ellipse. The radius of the circle is $\bf{My\; Try::}$ Here I have assume Center of ellipse is at origin. So equation of ellipse is $\displaystyle \frac{x^2}{25}+\frac{y^2}{16}=1$ Using Some calculation $\displaystyle e = \frac{3}{5}$ and So focus is $\displaystyle (\pm 3,0)$ Now equation of Circle whose one center is at one focus $(3,0)$ So equation of Circle is $(x-3)^2+y^2=r^2\;,$ Where radius is $=r$ Now eliminating $y$ from these two equation, We get $\displaystyle \frac{x^2}{25}+\frac{r^2-(x-3)^2}{16} = 1$ So we get $\displaystyle 16x^2+25r^2-25(x-3)^2=400\Rightarrow 16x^2+25r^2-25x^2-225+150x=400$ So $\displaystyle -9x^2+150x+25r^2-625=0\Rightarrow 9x^2-150x-25(r^2-25)=0$ Now given Ellipse and Circle are Tangent. So we will put $\bf{Discriminant =0}$ So $\displaystyle (150)^2-+4\cdot 25 \cdot 9 (r^2-25) =0\Rightarrow  r^2=0\Rightarrow r=0$ But When I solved Using Parametric Coordinate I get $r=2$ I did not understand Why I am not getting Same answer , plz explain me Thanks",['geometry']
1656584,Summation of this huge series,"The value of $\dfrac{2^2+1}{2^2-1}+\dfrac{3^2+1}{3^2-1}...+\dfrac{2011^2+1}{2011^2-1}$ is: In the interval $(2010,2010\frac{1}{2})$ In the interval $(2011-1/2011,2011-1/2012)$ In the interval $(2011,2011\frac{1}{2})$ In the interval $(2012,2012\frac{1}{2})$ I'm staring at it but can't see any trick to solve it. I think there is some trick as its of the form $a^2+b^2/(a-b)(a+b)$.",['sequences-and-series']
1656628,Limit involving a recursively-defined sequence,"$$A_{n+1}=A_n+\frac{1}{\sum_{i=1}^n A_i}$$ with $$A_1=1$$ Find out the value of $$\lim_{n→∞}A_n/\sqrt{\log(n)}$$ I used Stolz Theorem, but it seems to be useless.","['sequences-and-series', 'calculus', 'analysis']"
1656645,Proving equality - a sum including binomial coefficient $\sum_{k=1}^{n}k{n \choose k}2^{n-k}=n3^{n-1}$,"I want to prove the following equality: $$\displaystyle\sum_{k=1}^{n}k{n \choose k}2^{n-k}=n3^{n-1}$$ So I had an idea to use $((1+x)^n)'=n(1+x)^{n-1}$ So I could just use the binomial theorem and let $$x=2 \implies (n3^{n-1})$$ and then modify the sum into that one on the left side. So I need to prove that :
$$\displaystyle\sum_{k=1}^{n}k{n \choose k}2^{n-k}=n(1+x)^{n-1}$$ if$$x=2$$
Any help would be appreciated.","['combinatorics', 'binomial-theorem', 'summation', 'binomial-coefficients']"
1656682,Surjectivity (onto) for isomorphism definition,"I have two books on algebra where one makes the definition of isomorphism to be a bijective homomorphism, while the other makes it as an injective homomorphism. I am doing the exercises from one book and learning from the other (not optimal I know), and so I am wondering what definition is considered the convention. If both are conventionally okay, is something lost by removing the surjective part of the bijection and if so what? I realise it's a rather uninteresting question, but if someone has the time I would appreciate the answer. Thank you!","['finite-groups', 'abstract-algebra', 'group-homomorphism', 'group-isomorphism', 'group-theory']"
1656716,proving convergence and calculating sum of a series,So I have this series: $$\displaystyle\sum_{n=1}^{\infty}\frac{3n^2+15n+9}{n^4+6n^3+9n^2}$$ I noticed: $$\displaystyle\sum_{n=1}^{\infty}\frac{1}{n^2}(\frac{3n^2+15n+9}{n^2+6n+9})$$ So can I say that it's convergent already or should I use a critera on the second fraction in the sum? Also for sum I could use partial fractions or am I mistaken? Any help would be appreciated.,"['sequences-and-series', 'convergence-divergence']"
1656737,Estimation of a sequence related to the Stirling's formula,"I need to show that $$n!=\left(\frac{n}{e}\right)^n\sqrt{2\pi n}e^{\lambda_n}$$
where $$\frac{1}{12(n+1)}<\lambda_n$$ I calculated that $$\lambda_n=\ln n!+n-n\ln n -\frac{1}{2}\ln(2\pi n)$$ On Wikipedia I found that $$(*)\quad\ln \Gamma (x+1)+x-x\ln x -\frac{1}{2}\ln(2\pi x)=\int_0^{\infty}\frac{2\arctan\left(\frac{t}{x}\right)}{e^{2\pi t}-1}dt=\sum_{n=1}^{\infty}\frac{c_n}{(x+1)^\overline{{n}}}$$ where $$c_n=\frac{1}{n}\int_0^1x^{\overline{n}}\left(x-\frac{1}{2}\right)dx$$
and $$x^{\overline{n}}=x(x+1)(x+2)\cdot\ldots\cdot(x+n-1)$$
From all this I get $$\lambda_n=\ln n!+n-n\ln n -\frac{1}{2}\ln(2\pi n)=\sum_{k=1}^{\infty}\frac{c_k}{(n+1)^{\overline{k}}}>\frac{c_1}{n+1}=\frac{1}{12(n+1)}$$ The only problem I have is that I don't know how to prove (*) equalities which I found on Wikipedia. Here's the link to Wikipedia Stirling's approximation EDIT. I made a mistake because I missed a line over n in formulas. I changes some things because now you can't compute exact formula for $c_n$.","['real-analysis', 'sequences-and-series']"
1656762,The 2-norm of the integral vs the integral of the 2-norm,"I`m currently having some issues with a seemingly innocent problem. I would like to show that $$\Bigg\|\int_\mathbb{R}\begin{pmatrix}A(x)\\B(x)\end{pmatrix}dx\Bigg\|_2 \leq \int_{\mathbb{R}}\Bigg\|\begin{pmatrix}A(x)\\B(x)\end{pmatrix}\Bigg\|_2dx$$ Where $A(x),B(x) \in L^2(\mathbb{R})$ and the two norm is defined as $$\Bigg\|\begin{pmatrix}A(x)\\B(x)\end{pmatrix}\Bigg\|_2=\sqrt{|A(x)|^2+|B(x)|^2}$$ I've asked around and people have tended to say ""that's very simple"" and then spent half an hour staring at it. I've tried plugging stuff in and it seems to hold but I do need a proof. Any help would be much appreciated! Thanks in advance","['normed-spaces', 'analysis']"
1656769,"If the degree of $(f(x)+f(−x))$ is $10$, then the degree of $(g(x)−g(−x))$ is?","Let $f(x)$ be a polynomial and $g(x) = f'(x)$ be its derivative. If the degree of $(f(x)+f(−x))$ is $10$, then the degree of $(g(x)−g(−x))$ is______? My attempt : Somewhere the answer is given as $9$. IMO, when we derivative a polynomial function, it reduces the degree by one. The same function is added, which cannot increase the degree of the resulting function, but it can reduce the degree when we subtract it. So, it should be maximum $9$. Can you explain in formal way, please?","['derivatives', 'polynomials', 'calculus', 'functions']"
1656772,Almost sure convergence along a subsequence implies convergence in probability over the whole sequence,"Consider a sequence of real-valued random variables $\{X_n\}_n$ almost surely converging to a real-valued random variable $X$ along a subsequence $\{n_k\}_k \subseteq \mathbb{N}$: $X_{n_k} \rightarrow_{a.s.}X$ as $k \rightarrow \infty$. Does this imply convergence in probability along the whole sequence, i.e. $X_n \rightarrow _p X$  as $n \rightarrow \infty$? Hint for the proof?","['almost-everywhere', 'probability-theory', 'asymptotics', 'probability', 'convergence-divergence']"
1656776,Trace of matrix that is a product of 2 others.,"We consider that $A,B$ are two square matrices. 
I would like to know if there is a proof that 
$$tr(AB)=tr(BA)$$ I seek for special kind of proof without using sigma notation and matrices multiplication definition because it is obvious then. Is there a more deep meaning for this trace property.? Thanks!!","['matrices', 'trace', 'eigenvalues-eigenvectors', 'linear-algebra']"
1656778,Triangle angles.,"For $\vartriangle$ABC it is given that $$\frac1{b+c}+\frac1{a+c}=\frac3{a+b+c}$$ Find the measure of angle $C$. This is a ""challenge problem"" in my precalculus book that I was assigned. How do I find an angle from side lengths like this? I have tried everything I can. I think I may need to employ the law of cosines or sines. Thanks.","['algebra-precalculus', 'geometry']"
1656795,What does the condition number of an adjacency matrix tells us,"Assume a directed graph, what does the condition number of its adjacency matrix mean?","['graph-theory', 'numerical-methods', 'linear-algebra']"
1656800,4 is an element in the following set:,"A) $\{x \in  \mathbb{Z} \mid 4 < x < 10\}$ B) $\{x \in  \mathbb{Z}  \mid x \text{ is the square of an integer}\}$ C) $\{4, \{4\}\}$ D) $\{\{4\},\{\{4\}\}\}$ E) $\{\{\{4\}\}\}$ Here are the answers I came up with. I am pretty confident about A-C, but I'm not sure about D and E. A: $4$ is not an element because $x < 4$ . False B: This can be true, only if the integer being squared is $2$ . True C: This contained $4$ and the subset $\{4\}$ , so True. D: Both of these are subsets, so False. E: This is only a subset, which is not the same as $4$ . False. Could someone confirm my logic on this is correct?","['elementary-set-theory', 'discrete-mathematics']"
1656814,How to prove $dxdy = r dr d \theta$?,"$x = r \cos \theta$, $y = r \sin \theta$ I got $dx = \cos \theta dr - r \sin \theta d \theta $ $ dy = \sin \theta dr + r \cos \theta d \theta$ How to get $dx dy = r dr d \theta$?? I saw the same question Rigorous proof that $dx dy=r\ dr\ d\theta$ . But I am not getting where vectors are coming in to the picture thanks.","['multivariable-calculus', 'integration']"
1656818,"How to prove $5^n − 1$ is divisible by 4, for each integer n ≥ 0 by mathematical induction?","Definition of Divisibility 
  Let n and d be integers and d≠0 then d|n ⇔ $\exists$ an integer k such that n=dk"" Source: Discrete Mathematics with Applications, Susanna S. Epp Prove the following statement by mathematical induction.
$5^n − 1$ is divisible by 4, for each integer n ≥ 0. My attempt: Let the given statement p(n). (1) $5^0 − 1=1-1=0$ is divisible by 4. So p(0) is true. (2) Suppose that for all integers $k \ge 0$, p(k) is true, so $5^k − 1$ is divisible by 4 by inductive hypothesis. Then we must show that p(k+1) is true. $5^{k+1} − 1$ = $5\cdot 5^k − 1$ I can't further develop the step. I'm stuck on this step. It should be something like $5\cdot(5^k − 1)$ so that p(k+1) be true to apply inductive hypothesis.","['discrete-mathematics', 'divisibility', 'induction', 'elementary-number-theory']"
1656855,Is the self-adjoint condition required in the definition of a positive operator?,"I'm reading Linear Algebra Done Right and it defines a positive operator $T$ as one which is self adjoint and has the property
$$\langle Tv,v \rangle \geq 0$$
for all $v\in V$. I am confused as to why the self adjoint condition must be included. Here is what I came up with: Suppose $T$ is an operator such that $\langle Tv, v\rangle \geq 0$ for all $v$. This implies that $\langle Tv, v\rangle$ is a real number, since the greater than sign doesn't make sense for complex numbers. Then, using the definition of adjoint,
$$\langle Tv, v\rangle = \langle v, T^*v\rangle = \overline{\langle T^*v,v\rangle} = \langle T^*v, v\rangle$$
for all $v\in V$. Therefore, $Tv=T^*v$ for all $v$ and $T$ is self adjoint. Where did I go wrong?","['positive-semidefinite', 'self-adjoint-operators', 'linear-algebra']"
1656857,Is a real logarithm of a special orthogonal matrix necessarily skew-symmetric?,"The exponential map from the Lie algebra of skew-symmetric matrices $\mathfrak{so}(n)$ to the Lie group $\operatorname{SO}(n)$ is surjective and so I know that given any special orthogonal matrix there exists a skew-symmetric real logarithm. However, must all real logarithms of a special orthogonal matrix be skew-symmetric?","['matrices', 'exponentiation', 'lie-algebras', 'lie-groups']"
1656862,"Conditional expectation of $E(\max(X,a)\mid\min(X,a))$ when $X$ is exponentially distributed","I am trying to compute the conditional expectation $$E\left[\max{(X,a)} \mid \min{(X,a)}\right]$$ where $X\sim \exp(a)$ and $a$ is a constant. I set $U=\min{(X,a)},W=\max{(X,a)}$, and computed the joint distribution as 
$$F_{UW}(u,w)=\begin{cases}P(X\le u,a\le w)+P(X\le w,a\le u)-P(X\le u,a\le u)& u<w\\P(X\le w,a\le w) &w<u\end{cases}$$ Then I don't know how to proceed. Can I differentiate $F_{UW}$ to find the joint density? Also, is there any easy way to compute without finding the joint density? These is a similar question here , but it involves two continuous r.v.","['probability-theory', 'probability', 'probability-distributions']"
1656915,Finite Double Sum $\sum_{j=0}^n\sum_{i=0}^j \binom {n+1}{j+1}\binom ni =2^{2n}$,"The problem is given in a combinatorics class study sheet. I cannot prove, and actually I am not sure if there was a mistake in the question or not. I tried for a few small n's e.g. 1, 2 and it holds. $\\$ I need to show that $\\$ $\mathop{\sum_{j=0}^{n}\sum_{i=0}^{j}}$ $n+1 \choose j+1$ $n \choose i $ = $2^{2n}$  $\forall n$ $\in$ $\mathbb{Z}^{+}$","['combinations', 'combinatorics', 'summation', 'binomial-coefficients']"
1656941,$p$-adic étale sheaf,"Here is the context : I'm trying to understand Katz-Deligne theory of false modular forms as exposed in the third appendix of the Katz's paper Higher Congruences between modular forms : https://web.math.princeton.edu/~nmk/old/highercong.pdf I haven't gone very far yet in fact I'm still trying to understand the first paragraph, and my question is just a question of algebraic geometry. So here is the setup $(W,\pi,k)$ is mixed characteristic DVR of residue chararcteristic $p$. For all $m \geq 1$ we write $W_m$ for $W/\pi^mW$. Let $S_m$ be a compatible sequence of affine flat affine $W_m$-schemes (i.e. $S_m = S_{m+1} \otimes_{W_{m+1}} W_m$). Let $P$ be a rank one $p$-adic étale sheaf on the $S_m$ which, according to the paper, means the following : 1) $P$ on $S_m$ is the unique $p$-adic étale sheaf on $S_m$ which induces $P$ on $S_1$ and $P$ 2) $P$ is and inverse of system $(P_n)$ of étale sheaves which are twisted form of the constant étale sheaf $\mathbf{Z}/p^n\mathbf{Z}$ My question : They say that $ \omega_m := P \otimes_{\mathbf{Z}_p} \mathcal{O}_{S_m}$ is an invertible sheaf on $S_m$. I understand that an étale sheaf is a zariski sheaf but I don't see how $P$ is a $\mathbf{Z}_p$ sheaf (since it is only étale locally isomorphic to $\mathbf{Z}_p$) and especially I don't understand why it gives you an invertible sheaf ?",['algebraic-geometry']
1656945,Approximating $x=\sqrt{2}+1$,"Suppose $y>1$ is some approximation to $x=\sqrt{2}+1$. Give a brief reason (not a proof) why one should expect $(1/y)+2$ to be a closer approximation to $x$ than $y$ is. After testing this out for a bit, it looks like we can let $y_{n+1}=\frac{1}{y_n}+2$ and $\lim_{n\to\infty}y_n=\sqrt{2}+1$, but this does not give me any intuitive idea as to why $y_{n+1}$ should be a better approximation to $x$ than $y_n$ is. Can anyone give a brief reason for this improvement in aproximation, especially a more ""intuitive"" one than simple numerical data?","['intuition', 'real-analysis', 'limits', 'calculus', 'approximation']"
1656952,Limit of $\frac{n^2}{n!}$,"Show $$\lim_{n\to \infty} \frac{n^2}{n!}=0$$ $$\frac{n^2}{n!}-0 = \frac{n^2}{n!} \le \frac{n^2}{n} = n < \epsilon$$ So if I let $\epsilon > 0$, then as long as I choose $1/N < \epsilon$, I have an appropriate $N$?","['real-analysis', 'proof-writing', 'sequences-and-series', 'limits']"
1656989,"Ordered set with a smallest element with element having a successor and and predecessor, not similar to the natural numbers","I'm looking to give an ordered set that is not similar to $\mathbb N$ with a smallest element in which every element has a successor and a predecessor, which wouldn't apply to the least (that is the predecessor). $\displaystyle \left\{\frac{-1}{n}, \frac{1}{n}, 1-\frac{1}{n} : n=1,2,3,...\right\}$ In this set, the least would be infinitesimally small as $n \rightarrow \infty$. Is this logic correct?",['elementary-set-theory']
1657010,Integration of $\int\frac{\sin^4x+\cos^4x}{\sin^3x+\cos^3x}dx$,"How can we integrate: $$
\int\frac{\sin^4x+\cos^4x}{\sin^3x+\cos^3x}dx
$$ Using simple algebraic identities I deduced it to $$
\int\frac{1-2\sin^2x\cdot\cos^2x}{(\sin x+\cos x)(1-\sin x\cdot\cos x)}dx
$$ but can't proceed further. Please provide some directions?","['indefinite-integrals', 'integration', 'calculus']"
1657028,Axiomatizability of some classes of groups,"I want to check which of the following classes are axiomatizable and which are even finitely axiomatizable. the class of finite groups the class of infinite groups the class of groups of order $n$ for some fixed $n$ the class of torsion groups the class of torsion-free groups Attempts: Not axiomatizable due to compactness . I think the group axioms plus the sequence of formulae (""there are $n$ distinct elements"") should give an axiomatization. If it was finitely axiomatizable then so was the complement (ie all structures that don't describe infinite groups), which seems wrong but I'm not sure how to argue this. The group axioms plus ""there are $n$ distinct elements"" plus ""there are not $n+1$ distinct elements"" should give a finite axiomatization? / 5. I'm not sure how to tackle the torsion thing.","['first-order-logic', 'torsion-groups', 'group-theory']"
1657030,Fit plane to 3D data using least squares,"I have some samples of data of the form $x,y$ and $z=f(x,y)$ . I wish to fit a plane (i.e. $z = Ax + By + C$ ) to the data with the smallest mean square errors. I have found an ""answer"" in section 3 of this document, and several other locations too but the answers always end with variations of ""now solve these equations and you can find $A$ , $B$ and $C$ "" I just about have the ability to solve these equations, but the process gets so messy that the likelihood of me making a mistake is quite high (and I need a guaranteed-correct answer). Surely someone has written out the full solution longhand somewhere - i.e. in the form $A=\dots$ , $B=\dots$ and $C=\dots$ anyone know where this has been done? EDIT: I see two answers already which leave out the last step as being trivial... and indeed they don't require any advanced maths... but you do need quite a big whiteboard to work it all out and the scope for making a mistake along the way is quite large. Indeed I noticed that assorted tutorials going through worked examples always have rather neat whole numbers. I find it hard to believe that there is nowhere online where someone has worked out the general case. I.e. find $A$ , $B$ and $C$ in the following set of equations... $$Ad+Be+Cf=g$$ $$Ah+Bi+Cj=j$$ $$Al+Bm+Cn=p$$ ...where $d$ to $p$ are all constants.","['statistics', 'linear-regression']"
1657050,In measure theory $\emptyset$ and $\{a\}$ are considered as intervals . Why?,"I recently started self learning measure theory.
While reading a note , I came across this , In measure theory $\emptyset$ (empty set) and $\{a\}$ (singleton set) are considered as intervals . Why are they considered as intervals ?","['measure-theory', 'soft-question', 'definition']"
1657066,northmost latitude,"From the book Astronomy, principles and practice. I cannot solve the second part. Assuming the Earth to be a sphere of radius 6378 km calculate the great circle distance in kilometers between
London (51◦ 30 N, 0◦) and New York (40◦ 45 N, 74◦ W).
Find also the most northerly latitude reached on the great circle arc. the great circle distance is given by $\Delta\sigma=\arccos(\sin51.5\sin40.75 + \cos51.5 \cos40.75\cos74)$ Then I converted the result to radians and used  $d=r\Delta\sigma$ to get 5786km. Then I tried to use the departure equation but logically it does not seem to correspond to the problem.","['celestial-mechanics', 'trigonometry']"
1657073,Covariant derivative identity,"I am trying to prove the following identity for contravariant vectors $X$ and $Y$ (this appears in exercise 6.7 of D'Inverno): $\nabla_{X}(fY) = (Xf)Y + f \nabla_X Y$. I have a way of proving it but it assumes linearity of the function $f$, whereas the proof is supposed to hold if $f$ is any smooth function. Here's my proof: \begin{eqnarray*}
\nabla_{X}(fY) &=& X^b \nabla_b(fY^a)\\
 &=& X^b(\partial_b (fY^a) + fY^c\Gamma^{a}_{cb})\\ 
&=& X^b(\partial_bf(Y^a) + f\partial_b Y^a + fY^c \Gamma^{a}_{cb})\\
&=&(X^b \partial_b f)Y^a + X^bf(\partial_bY^a + Y^c\Gamma^{a}_{cb})\\
&=& (Xf)Y + f(X^b\nabla_bY^a)\\
&=& (Xf)Y + f \nabla_X Y
\end{eqnarray*} Is there a better way to prove this without assuming linearity of $f$? I have searched around for a proof of this to no avail.","['tensors', 'differential-geometry', 'general-relativity']"
1657075,If $X$ is a finite set and $Y \subset X$. Prove that $Y$ is finite.,"I am having trouble solving a question of section 3.6 (cardinality of sets) from Tao's Analysis I book. 
I have to prove the following statement : My attempt (the boldline's refers to the points where I need help): Since $X$ is a finite set, let $\#X=n$ and let 
$N_n:=\{i \in N:\forall 1\leq i \leq n\}$. Since $\#X=n$, $\exists$ a bijection $f:X \mapsto N_n $. Now, let $G:=\{f(x):x \in Y\} $. Since $G \subset N_n$ $  \exists g_1 \in G$ s.t $g_1=min(G)$ ( I am not bothering with proving this). Now, consider $G_2:=G-\{g_1\}$, if $G_2\ne \emptyset $, there exists $g_2 \in G_2 $ s.t $g_2=min(G_2)$. And now I need help: Going on like this I will get to a point where $G_m=\emptyset $ .
I don't know how to 
technically write this argument, can someone help me? Carrying on... Now, let the set $G':=\{g_i: \forall 1\leq i \leq n'\}$. Note that $n'=m-1$. So ( maybe I have to write some other steps here, please help ), $\exists$ a bijection $g:Y \mapsto N_n' $, then Y is finite and $\#Y=n'$. And now, I have to proof that $n' \leq n$. Did I already prove this? If don't, I can prove this by contradiction, right? So, that's it. I appreciate any help.","['real-analysis', 'elementary-set-theory']"
1657080,Planarity on $10$ vertices,"Is there a planar graph on $10$ vertices such that its complement is planar as well? I have troubles deciding if this is an elementary or deep question. By some other thread, the answer is an easy No for $11$ or more vertices.","['graph-theory', 'discrete-mathematics']"
1657086,Global minimum over open and convex domain,"Consider a function $f:\Theta \subset \mathbb{R}\rightarrow \mathbb{R}$. Let $\Theta$ be a convex and open set and $f$ a strictly convex function. If the function has a global minimum, is it unique? I'm confused by the fact that $\Theta$ is not assumed to be compact. Is this a problem for guaranteeing uniqueness?","['general-topology', 'optimization', 'elementary-set-theory']"
1657094,Show that $\mathbb{R}^2$ can't be written as the union of disjoint topolocial circles,"My attempt was to think about cohomology. But I think that there is some failure on my thought. Suppose that the claim holds. Then $\mathbb{R}^2 = \cup_i S^1_i$. We know that $\mathbb{R}^2$ minus a circle has the comology isomorphic to $\mathbb{R}$. But does not make any difference take off a circle of such union, then the cohomology of $\mathbb{R}^2$ is not the trivial. What is a contradiction.","['algebraic-topology', 'general-topology', 'proof-verification']"
1657112,"MST, Cut in Graph, Some Claims?","I ready for taking a P.hD Entrance Exam. one of old-solution problem of Data Structure is as follows: Which of the following Claims is True about MST of Simple, Undirected, Weighted and Connected Graph G ? (edge weights is not necessarily different.) 1) if lightest edge between any cut in G, be unique, then MST is unique. 2)If all edges weights be different, MST is unique. 3) if the weights of e=(u, v) be equal to maximum lightest edge in all paths between u and v then e be in the MST . Answer: one of them is Correct. Who can explain more, which is true? why? there is any proof or we must take an example or provide counterexample?","['graph-theory', 'trees', 'computer-science', 'algebraic-graph-theory', 'discrete-mathematics']"
1657124,Limit of sum of terms containing binomial coefficients,"$$\lim_{n \to \infty} \sum_{k=0}^n \frac{n \choose k}{k2^n+n}$$
The result is $0$. The $n$ from the denominator can be ignored. If not for the $k$ at the denominator, the result would be $1$, but I can not find the right inequality.","['summation', 'binomial-coefficients', 'limits']"
1657134,How many cube roots does an $n\times n$ identity matrix have over $\mathbb C$?,"I thought there are infinite solutions, because if $A$ is a solution, then $Q^TAQ$  is also a solution, where $Q$ is an orthogonal matrix. But I used MATLAB to symbolically solve for the cube root of a $2\times 2$ identity matrix, I got 16 solutions. Every entry of the solutions is either $0$ or a cube root of $1$.
MATLAB is unable to solve for higher $n$. So how many cube roots does an $n\times n$ identity matrix have? $n^4$?","['matrices', 'linear-algebra']"
1657137,L2 Norm of Pseudo-Inverse Relation with Minimum Singular Value,"Consider a matrix $A \in\mathbb R^{n\times m}$ with $n>m$. It has full column rank, i.e. $\operatorname{rank}(A)=m$. Its left pseudo-inverse is given by; $$A^{-1}_\text{left}=(A^TA)^{-1}A^T $$ From two different results during my studies, I have realized the following:
$$ \|A^{-1}_\text{left}\|_2 = \frac{1}{\sigma_{\min}(A)} $$
just like the case as if $A$ is square invertible matrix. I have seen a similar question , however I couldn't relate the answer with the equality given above. My question is: How can we show that the L2 norm of left pseudo-inverse of $A$ is related to its minimum singular value? Thank you in advance for your help.","['matrices', 'normed-spaces', 'pseudoinverse', 'linear-algebra']"
1657148,"Given a linear Hilbert-Schmidt embedding $ι$ between Hilbert spaces, prove that $ιι^*$ is a bounded, linear operator with finite trace","Let $(U,\langle\;\cdot\;,\;\cdot\;\rangle)$ be a separable Hilbert space $Q$ be a bounded, linear, nonnegative and symmetric operator on $U$ $U_0:=Q^{\frac 12}(U)$, $$\langle u,v\rangle_0:=\langle Q^{-\frac 12}u,Q^{-\frac 12}v\rangle\;\;\;\text{for }u,v\in U_0$$ where $Q^{-\frac 12}$ is the pseudo inverse of $Q^{\frac 12}$ and $(e_n)_{n\in\mathbb N}$ be an orthonormal basis of $U_0$ $(U_1,\langle\;\cdot\;,\;\cdot\;\rangle_1)$ be a separable Hilbert space and $$\iota:(U_0,\langle\;\cdot\;,\;\cdot\;\rangle_0)\to(U,\langle\;\cdot\;,\;\cdot\;\rangle)$$ be a linear Hilbert-Schmidt embedding How can we show that $$Q_1:=\iota\iota^\ast$$ is a bounded, linear, symmetric and nonnegative operator on $U_1$ with finite trace? Clearly, $$\langle Q_1u,v\rangle_1\stackrel{\text{def}}=\langle\iota\color{blue}(\iota^\ast u\color{blue}),v\rangle_1\stackrel{\text{def}}=\langle\iota^\ast u,\iota^\ast v\rangle_0\;\;\;\text{for all }u,v\in U_1\tag 1\;.$$ Thus, $\iota$ is nonnegative (since $\langle\iota^\ast u,\iota^\ast u\rangle_0\ge 0$ for all $u\in U_1$) and symmetric, since $$\langle u,Q_1v\rangle_1\stackrel{\text{Hermitian symmetry}}=\overline{\langle Q_1v,u\rangle_1}\stackrel{\text{(1)}}=\overline{\langle\iota^\ast v,\iota^\ast u\rangle_0}\stackrel{\text{Hermitian symmetry}+(1)}=\langle Q_1u,v\rangle_1\;.$$ However, I fail to prove that $Q_1$ has finite trace, i.e. $$\operatorname{tr}Q_1:=\sum_{n\in\mathbb N}\langle Q_1e_n,e_n\rangle_1<\infty\tag 2$$ for any orthonormal basis $(e_n)_{n\in\mathbb N}$ of $U_1$. How can we show $(2)$ and that $\iota$ is bounded and linear?","['functional-analysis', 'hilbert-spaces', 'operator-theory', 'analysis']"
1657151,Differentiability of a scalar function of two variables --- problems with Stewart’s definition.,"I’m feeling uncomfortable about how Stewart’s Calculus makes the transition from differentiability of functions of one variable to differentiability of functions of two variables. Namely, Stewart gives the following definition: Definition. A function $ f $ of two variables is said to be differentiable at $ (a,b) $ if the first-order partial derivatives of $ f $ at $ (a,b) $ exist and
  \begin{align}
  & ~ f(a + \Delta x,b + \Delta y) - f(a,b) \\
= & ~ {f_{\operatorname{x}}}(a,b) \Delta x +
      {f_{\operatorname{y}}}(a,b) \Delta y +
      {\epsilon_{1}}(\Delta x,\Delta y) \Delta x +
      {\epsilon_{2}}(\Delta x,\Delta y) \Delta y,
\end{align}
  where $ \displaystyle \lim_{(\Delta x,\Delta y) \to (0,0)} {\epsilon_{1}}(\Delta x,\Delta y) = \lim_{(\Delta x,\Delta y) \to (0,0)} {\epsilon_{2}}(\Delta x,\Delta y) = 0 $. Note. Later on, he shows that this will follow if the partial derivatives exist and are continuous near $ (a,b) $, and I am fine with this. What first irked me is that I didn’t remember learning this definition, so I spent a while trying to understand it. Moreover, the only functions that I’ve found to motivate the need for such a definition are those that are not continuous at the point in question. For example, consider the function $ f: \mathbb{R}^{2} \to \mathbb{R} $ defined by
$$
\forall (x,y) \in \mathbb{R}^{2}: \qquad
f(x,y) \stackrel{\text{df}}{=}
\begin{cases}
\dfrac{x y}{x^{2} + y^{2}} & \text{if $ (x,y) \neq (0,0) $}; \\
0                          & \text{if $ (x,y) = (0,0) $}.
\end{cases}
$$
Then $ f_{\operatorname{x}} $ and $ f_{\operatorname{y}} $ are defined at $ (0,0) $, but $ f $ is not continuous there. Here’s my quarrel. I don’t think that this is a natural extension from the one-dimensional case. In one dimension, differentiability at a point implies continuity at that point, but two dimensions, the existence of $ f_{\operatorname{x}} $ and $ f_{\operatorname{y}} $ at a point don’t imply the continuity of $ f $ at that point. My intuition, then, is that to extend the definition of differentiability to two dimensions, we should say that $ f_{\operatorname{x}} $ and $ f_{\operatorname{y}} $ exist and that $ f $ is continuous at the relevant point. This seems nice and simple, so I can’t imagine why Stewart would go with the awkward definition given at the beginning of this post, if this was indeed the case. It therefore seems that I should be wrong. If I am, can you give me an example of a function $ f $ that is continuous at $ (a,b) $, and $ f_{\operatorname{x}} $ and $ f_{\operatorname{y}} $ are defined at $ (a,b) $, but it isn’t differentiable there? Additionally, I have a rough outline of a proof in my head of why it should be true. The definition of a directional derivative gives
$$
  {D_{\mathbf{u}} f}(a,b)
= \lim_{h \to 0} \frac{f(a + h \Delta x,b + h \Delta y) - f(a,b)}{h},
$$
but expressing it as a gradient implies that
$$
  \lim_{h \to 0} \frac{f(a + h \Delta x,b + h \Delta y) - f(a,b)}{h}
= {f_{\operatorname{x}}}(a,b) \Delta x + {f_{\operatorname{y}}}(a,b) \Delta y.
$$
However, for this limit to be true, it seems like the original awkward definition must follow, i.e.,
$$
  \frac{f(a + h \Delta x,b + h \Delta y) - f(a,b)}{h}
= {f_{\operatorname{x}}}(a,b)\Delta x + {f_{\operatorname{y}}}(a,b) \Delta y,
$$
which implies that
$$
  f(a + h \Delta x,b + h \Delta y) - f(a,b)
= {f_{\operatorname{x}}}(a,b)h \Delta x + {f_{\operatorname{y}}}(a,b)h \Delta y
$$
without even the need for the functions $ \epsilon_{1} $ and $ \epsilon_{2} $. Edit 1 zhw. has given a nice counter example below. However, I’d now like to alter my questions. Would an alternative definition be that all the directional derivatives of $ f $ exist and that $ f $ is continuous at a given point? What if I now extend my original approach to say that $ f $ is continuous on a neighborhood of $ (a,b) $ and that $ {f_{\operatorname{x}}}(a,b) $ and $ {f_{\operatorname{y}}}(a,b)$ exist? Could you give me a counterexample now? Edit 2 zhw. has knocked down Question 2 of Edit 1 in his response to my comment to his original answer, so now I’m just wondering if Would an alternative definition be that all the directional derivatives of $ f $ exist and that $ f $ is continuous at a given point? I’m motivated to ask because (a) zhw.’s counter examples all have some directional derivatives that don’t work and (b) my attempted proof relied on the existence of directional derivatives.","['multivariable-calculus', 'partial-derivative', 'derivatives']"
1657187,Is it possible for local maximum value to be smaller than local minimum? I got such a solution.,"In the following function:
$f(x) = (x^2-x+1)/(1-x)$ I got that minimum $f(0) = 1$
and maximum $f(2) = -3$ Wolfram also says so... but why is it?","['calculus', 'functions']"
1657210,Find all ideals of ${\mathbb{Z}_n}$,"The task is to find all ideals of ${\mathbb{Z}_n}$, where $n$ is
  positive integer, greater than one. My effort Let $I$ be an ideal of ${\mathbb{Z}_n}$. It is obvious that $I$ is an additive subgroup of ${\mathbb{Z}_n}$. Consider $G$ as an additive subgroup of ${\mathbb{Z}_n}$. Then $G$ is a cyclic additive subgroup generated by $\left\langle d \right\rangle $, where $d \mid n$. We know that for a finite cyclic group of order $k$, every subgroup's order is a divisor of $k$, and there is exactly one subgroup for each divisor. It follows that all ideals of ${\mathbb{Z}_n}$ are of form $\left\langle {{d_1}} \right\rangle ,\left\langle {{d_2}} \right\rangle , \ldots \left\langle {{d_i}} \right\rangle $, where ${d_1},{d_2}, \ldots ,{d_i}$ are positive divisors or $n$. Questions Is my proof correct?","['abstract-algebra', 'proof-verification']"
1657230,"If $S = A_1 \cup A_2 \cup \cdots \cup A_6 = B_1 \cup \cdots \cup B_n$, find $n$","Suppose $A_1, \ldots , A_6$ are six sets each with four elements and $B_1, \ldots, B_n$ are $n$ sets each with two elements. Let $S = A_1 \cup A_2 \cup \cdots \cup A_6 = B_1 \cup \cdots \cup B_n$. Given that each of the elements of $S$ belongs to exactly four of the $A$’s and to exactly three of the $B$’s, find n. The first thing I tried is looking at cardinality because we are trying to prove equality by the axiom of extension. We have $\left | A_1 \cup A_2 \cup \cdots \cup A_6 \right| \leq 24$ and $\left |B_1 \cup \cdots \cup B_n \right | \leq 2n$. So let's suppose $\left |S \right| = m$ where $m \leq 2n$ and $m \leq 12$. I am trying to figure out how to utilize the last sentence . It seems if we can find $m$ we will be able to find $n$.","['combinatorics', 'elementary-set-theory']"
1657276,State space for 8-queen problem,"While reading Artificial Intelligence a Modern Approach I came across the following formulation for the 8-queen problem : Initial state : No queens on the board. States : Arrangements of n queens (0 <= n <= 8), one per column in the leftmost n columns, with no queen attacking another are states. Successor function : Add a queen to any square in the leftmost empty
colum such that it is not attacked by any other queen. I have been trying to find some pattern that would allow me to sort out the number of states for each n given the constraints above but I have not been succeeded for n > 2. So, for: n=1 => 8 states n=2 => 42 states ... Even though I could generate all the possible combinations for each n and then filter out all those that do not represent a valid state, I would rather not go that way because it would be really time and space consuming for n, say, greater or equal than 10. To sum up, is there any sort of formula to find the number of states given n and at the same time taking into account the following constrains?","['combinatorics', 'artificial-intelligence', 'probability']"
1657349,How do we formally distinguish between zero probability events that may and may not actually occur?,"Consider a random variable $X$ with pdf 
\begin{equation}
f(x)=
\begin{cases}
3/2 &\text{ if } x\in[0,1/3]\cup[2/3,1] \\
0 & \text{ otherwise}
\end{cases}
\end{equation}
Here, $P(X=1/6)=P(X=1/2)=0$, but $1/6$ and $1/2$ are somehow different, because the event $X=1/6$ can actually happen , but $X=1/2$ can't. How do you differentiate between values like $1/2$ that can't happen, and $1/6$ that can, and what do I need to know about a random variable in order to know whether a value is zero probability of one type or the other?",['probability']
1657351,Intersection of the corners of a hypercube and a hyperplane,"Consider the corners $c$ of a unit hypercube in $\mathbb{R}^n$ (for example in $\mathbb{R}^2$, $c = \{\{0,0\},\{1,0\},\{0,1\},\{1,1\}\}$) and a hyperplane $p \subseteq \mathbb{R}^{n-1}$ (for example in $\mathbb{R}^{2-1},$ $ p $ is a line). How do I prove that the hyperplane $p$ intersects at most half of the corners of the hypercube? Geometrically it seems obvious, but I'm not sure how to show this rigorously.","['vector-spaces', 'linear-algebra', 'polytopes', 'geometry']"
1657377,obtaining Bernoulli numbers from determinant,"I am reading a paper entitled Bernoulli Numbers Via Determinants by Hongwei Chen and I'm confused about a particular step.  The author sets up a system of equations via the following: first let $B_n$ represent the $n$-th Bernoulli number.  Then $$x=(e^x-1)\sum_{n=0}^\infty B_n\frac{x^n}{n!}$$ Letting $b_n=B_n/n!$ and expanding we get $$x=\left(x+\frac{x^2}{2!}+\frac{x^3}{3!}+...\right)\left(b_0+b_1x+b_2x^2+...\right)$$ Immediately we can see that $b_0=1$.  Using Cauchy Products, we then obtain an infinite sequence of equations which are coefficients of the powers of $x$. But we don't need infinite, we can look at the system for coefficients up to $x^n$.   Therefore \begin{cases}
b_1=-\frac{1}{2!} \\[2ex]
\frac{b_1}{2!}+b_2=-\frac{1}{3!} \\[2ex]
\frac{b_1}{3!}+\frac{b_2}{2!}+b_3=-\frac{1}{4!} \\[2ex]
\vdots \\[2ex]
\frac{b_1}{n!}+\frac{b_2}{(n-1)!}+...+b_n=-\frac{1}{(n+1)!} \\[2ex]
\end{cases} Then the author goes on to state that applying Cramers rule produces
$$b_n=
\begin{vmatrix}
1 & 0 & 0 & \cdots & -\frac{1}{2!} \\
\frac{1}{2!} & 1 & 0 & \cdots & -\frac{1}{3!} \\
\frac{1}{3!} & \frac{1}{2!} & 1 & \cdots & -\frac{1}{4!} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
\frac{1}{n!} & \frac{1}{(n-1)!} & \frac{1}{(n-2)!} & \cdots & -\frac{1}{(n+1)!} \\
\end{vmatrix}
$$ Then $$B_n=n!
\begin{vmatrix}
1 & 0 & 0 & \cdots & -\frac{1}{2!} \\
\frac{1}{2!} & 1 & 0 & \cdots & -\frac{1}{3!} \\
\frac{1}{3!} & \frac{1}{2!} & 1 & \cdots & -\frac{1}{4!} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
\frac{1}{n!} & \frac{1}{(n-1)!} & \frac{1}{(n-2)!} & \cdots & -\frac{1}{(n+1)!} \\
\end{vmatrix}
$$ And finally, $$B_n=(-1)^n n!
\begin{vmatrix}
\frac{1}{2!} & 1 & 0 & \cdots & 0 \\
\frac{1}{3!} & \frac{1}{2!} & 1 & \cdots & 0 \\
\frac{1}{4!} & \frac{1}{3!} & \frac{1}{2!} & \cdots & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
\frac{1}{(n+1)!} &\frac{1}{n!} & \frac{1}{(n-1)!} &  \cdots & \frac{1}{2!} \\
\end{vmatrix}
$$ Can someone please explain the last step?  I just don't see how that last step comes from the previous.  I figure it has something to do with properties of determinants, and i do know that $|cA|=c^n|A|$, but I don't see where that is coming from here.","['matrices', 'determinant', 'linear-algebra', 'systems-of-equations']"
1657399,Prove that $|\mathbb{N} \times \mathbb{N}| \leq |\mathbb{N}|$,"Claim: $|\mathbb{N} \times \mathbb{N}| \leq |\mathbb{N}|$ Proof: For all  $ x \in \mathbb{N}, y \in \mathbb{N}$, we can define a function $f(x,y) = x + \frac{(x+y-1)(x+y-2)}{2}$ We now prove that $f$ is an injection. We will show that if $f(x,y) = f(u,v)$ then $x+y$ = $u+v$ Suppose $f(x,y) = f(u,v)$ but $x+y \neq u+v$. Then either $x+y > u+v$ or $u+v > x+y$. Case 1: $x+y > u+v$ Then $x+y = u+v + \delta$ for some $\delta > 0$. $$x + \frac{(x+y -1)(x+y-2)}{2} = u + \frac{(u+v -1)(u+v-2)}{2} + \delta$$ Now, I don't know what to do.","['elementary-set-theory', 'discrete-mathematics']"
1657429,Convergence of complex series $\sum \frac{z^n}{\sin(n)}$,"I started studying complex analysis out of interest recently, and there is a problem I just cannot figure out as much as I try. This is about the radius of convergence of the following series : $$\sum_{n>0}\frac{z^n}{\sin n}$$ Now, what I have established is that clearly, the series diverges in absolute value for $|z|>1$ by bounding downwards with $\sum_{n>0}{|z|^n}$ My intuition tells me this series should CONVERGE for $|z|<1$. However, I am not able to prove it. I tried using the definition of the radius of convergence, : $$\frac{1}{R} = \lim_{n\to\infty} \sup \left|\frac{1}{\sin n}  \right|^{1/n}.$$ However, I cannot prove that limit as $n\to\infty$ of $\sin(n)^{1/n}$ is indeed $1$. I know that the problem is that the adherence of set $\sin(n), n \in \mathbb{N}$ is $[-1;1]$ and I don't know how to deal with the subsequence $\sin(n_k)$ that tends to $0$. I have also considered tried bounding the series, but to no avail. Is there any method I missed or do I have to find a way to compute the aforementioned limit ?","['complex-analysis', 'sequences-and-series', 'convergence-divergence']"
1657439,Show $x^2 + 2\cos(x) \geq 2$,"How do I show that $x^2 + 2\cos(x) - 2$ is always nonnegative (x is measured in radians)? If $x \geq 2$ or $x \leq -2$ then obviously, $x^2 \geq 4$, and so it must be true. But otherwise, $2\cos(x)$ can be as small as $-2$ and it is quite surprising that something that could potentially be as small as $x^2 - 4$ is never actually negative. I'm not sure how to go about solving this, especially since there is an $x^2$ term which is annoying. Edit: Preferably without calculus, although the existing calculus answers are fine.","['algebra-precalculus', 'inequality', 'trigonometry']"
1657461,Prove that Proclus' axiom is equivalent to Playfair's axiom,"I'm attempting to prove that Proclus' axiom: ""If a straight line intersects one of two parallel lines, it will intersect
  the other also."" is equivalent to Playfair's axiom: ""In a plane, given a line and a point not on it, at most one line parallel to the given line can be drawn through the point."" However, before coming to this problem, we've proved Euclid's first $28$ postulates where lines intersected by ""magic."" Does anyone have an idea/solution to then do this: You should show that your axiom is equivalent to Playfair's
  Axiom (so if one holds, so does the other, and vice-versa).",['geometry']
1657473,Prove $\int_0^\infty \frac{x^{k-1} + x^{-k-1}}{x^a + x^{-a}}dx = \frac{\pi}{a \cos(\frac{\pi k}{2a})}$.,"I need help in proving this identity $$\int_0^\infty \frac{x^{k-1} + x^{-k-1}}{x^a + x^{-a}}dx = \frac{\pi}{a \cos(\frac{\pi k}{2a})}$$ for $0<k<a.$ It might be done using residues, but I don't know which contour to choose.","['integration', 'definite-integrals', 'calculus', 'closed-form']"
1657477,Is there a closed-form of $\frac{1}{1}+\frac{1}{1+2^2}+\frac{1}{1+2^2+3^2}+.....$,"How can I find the closed-form of?
$$\frac{1}{1}+\frac{1}{1+2^2}+\frac{1}{1+2^2+3^2}+.....$$
Any help thanks",['sequences-and-series']
1657483,Complex Analysis with differential forms,"I'm studying a little of Complex Analysis and I have seen that I can use the integrals of complex functions as integrals of differential forms in $\mathbb{R}^n.$ For example: Cauchy Theorem for complex analytic functions is a consequence of the fact that a closed differential form on a simply connected set is exact. My question is :
Are there other famous theorem of Complex Analysis that I can prove with the theory of differential forms in Euclidean space?","['big-list', 'reference-request', 'de-rham-cohomology', 'differential-forms', 'complex-analysis']"
1657488,Is $f(x)=\frac{\sin x}{x}$ for all $x\neq 0$ differentiable?,"The function $f(x)$ is defined by $$f(x)=\frac{\sin x}{x}$$ for any $x≠0$. For $x=0$, $f(x)=1$. My work: Determine if the function is continuous, differentiable and if the latter, find its derivative at $0$. $$f(x) =\begin{cases}\dfrac{\sin x}{x}, & x \ne 0 \\
      1 & x = 0 \end{cases}$$ I proved the continuous condition using L'Hopital's rule on the following \begin{equation} f(0) = \lim_{x\to 0} \frac{\sin x}x = 1 \end{equation} For the defferentiable condition I think I proved it \begin{align*}
\lim_{x\to0} \frac{f(x) - f(0)}{x-0} &= \lim_{x\to0} \frac{\frac{\sin x}x - 1}{x-0} \\
&= \lim_{x\to0} \frac{\sin x - x}{x^2} \\
&= \lim_{x\to0} \frac{\cos x-1}{2x} \\
&= \lim_{x\to0} \frac{-\sin x}{2} \\
&= 0 
\end{align*} Now the derivative of $f(x)$ is
\begin{equation} \frac{x\cos x - \sin x}{x^2} \end{equation} But what does it mean ""find its derivative at $0$"" ? The only thing that came to my mind is to find its limit as $x\to 0$ \begin{equation} \lim_{x\to0}\frac{x\cos x - \sin x}{x^2} = 0 \end{equation} Did I understand and do everything correctly?","['derivatives', 'continuity', 'calculus']"
1657495,"How to solve $ \sqrt{x^2 +\sqrt{4x^2 +\sqrt{16x^2+ \sqrt{64x^2+\dotsb} } } } =5\,$?","How to find $x$ in:
$$
\sqrt{x^2 +\sqrt{4x^2 +\sqrt{16x^2+ \sqrt{64x^2+\dotsb} } }  } =5
$$","['radicals', 'recurrence-relations', 'nested-radicals', 'sequences-and-series']"
1657498,Geometric interpretation of Leibniz formula for $\pi$,"We know $\pi=4(\frac{1}{1}-\frac{1}{3}+\frac{1}{5}-\frac{1}{7}....)$. I'm wondering, is there a geometric interpretation of this identity. Can we prove this identity by finding a different way to determine the area of the unit circle for example?","['circles', 'euclidean-geometry', 'sequences-and-series', 'pi']"
1657507,Presentation of $S_4$ with $3$ generators and easier relators,"The presentation $$< x^4,y^3,z^2,yxzx^2,zxzy^2x^3,zyzy >$$ for $S_4$ is quite complicated. $S_4$ could be easily generated by $2$ elements, but
I prefer $3$ generators with orders $2,3$ and $4$ because then the elements $x^j\cdot y^k\cdot z^l$ with $0\le j\le 3\ ,\ 0\le k\le 2\ ,\ 0\le l\le 1$ are the group elements. This is impossible with $2$ generators because the maximum order of an element in $S_4$ is $4$. In general, $n-1$ generators are sufficient for $S_n$ , if the above property
is required (maybe, less relators suffice for larger $n$, does anyone know the actual minimum ? ) Is there a presentation of $S_4$ with $3$ generators and easier relators ?
  The relators must determine $S_4$ uniquely. It would be best, if the presentation could be generalized for $S_n$ and $n-1$ generators.","['finite-groups', 'abstract-algebra', 'group-theory', 'symmetric-groups']"
1657561,Solving Euler-Lagrange Equation with delta function,"I am trying to understand a physical system and have arrived at the following equation: $$\mathcal{S} = \int_{z = -\infty}^{z = \infty} dz \left\lbrace f_\rho[\rho] + \dfrac{m}{2} \bigg| \dfrac{\partial \rho}{\partial z} \bigg| ^2 + \dfrac{\rho ^2 (z) \delta(z-z_0)}{2}\right\rbrace$$ where I seek the $ \rho (z) $ that minimizes the value of $\mathcal{S}$ . $ \rho (z) $ is a function of $ z $ , with $ \rho ' = d\rho / dz$ . $ f [\rho] = a \rho ^2 + b \rho ^3 + c \rho ^4$ is a functional of $ \rho (z) $ , and $ f_\rho[\rho] = \frac{df}{d\rho} $ . I thus write an Euler-Lagrange equation: $$ \dfrac{\partial \mathcal{S}}{\partial \rho} = \dfrac{\partial}{\partial z} \left( \dfrac{\partial \mathcal{S}}{\partial \rho '}\right)$$ I have been unable to solve this equation for $ {\rho(z)} $ , and was wondering how to do so. I have managed to simplify the EL equation to: $$ \dfrac{\partial f_\rho [\rho]}{\partial \rho} + \rho \delta(z-z_0) = m \dfrac{\partial ^2 \rho}{\partial z^2} $$ but I don't know where to go from here. Any help would be much appreciated.","['euler-lagrange-equation', 'calculus-of-variations', 'ordinary-differential-equations']"
1657619,How to define $x^a$ for arbitrary real numbers $x$ and $a$,"Questions like this , which asks to solve $$x^{\frac43} = \frac{16}{81}$$ confuse me. The solution for real $x$ is $\pm \frac8{27}$. The question would presumably be a bit different to solve $$x^{\frac42} = \frac{16}{81}$$ Because on the one hand $\frac42 = 2$ so the answer is $\pm\sqrt{\frac{16}{81}} = \pm\frac49$. But on the other hand $x^{\frac{4}{2}} = x^{{\frac12}\cdot{4}}$ which, as a function of $x$, is not equal to $(x^{\frac12})^4$. This is fine, but it raises the question, what is the proper way to define $x^{\frac{4}{3}}$? We have seen we cannot just arbitrarily factor the exponent and apply the multiplication rule. But that's the only way I can think to define $x^{4/3}$ without first defining $x^a$ for all real numbers probably by way of $\ln$. This tends to come up for algebra-precalculus and similar questions on the site. It might be harder than first appears. More precisely I am asking how to define $x^a$ for as general real $x$ and $a$ as possible, in the context of precalculus, or how to define it at any level of mathematics and adapt it to a precalculus or at least $\mathbb R$ concept.","['algebra-precalculus', 'exponentiation', 'definition']"
1657627,Probability with pigeon hole principle,"A gambler buys at least one lottery ticket everyday, maybe more.
   During the whole year he buys at most $400$ tickets. Show that during
   the year there exists a sequence of consecutive days for which the
   total number of tickets bought is exactly $330$. Hint: if $v_i$ is the
   number of tickets bought up to and including the $i^{th}$ day of the
   year, then we want to prove that there exists $j$ and $i$, with $j>i$,
   such that $v_j = v_{i-1} + 330$. I'm not totally sure how to do this. However, I think that it involves the pigeon hole principle. thanks.",['discrete-mathematics']
1657664,"Discrete Math - ""No computer science students are engineering students""","Struggling with a homework problem here and can't understand logically which one would be correct (each has different truth tables). I need to express the following statement using quantifiers, variables, and the predicates M(s), C(s), and E(s) ""No computer science students are engineering students"" D = set of all students C(s) = ""s is a computer science major"" E(s) = ""s is an engineering student"" So I'm stuck between, $\forall s \in D, C(s) \implies \lnot E(s)$ -OR- $\forall s \in D, \lnot C(s) \land E(s)$","['logic', 'discrete-mathematics']"
1657716,Any number coprime with 10 dividing at leat one number of the form 111...111 [duplicate],This question already has an answer here : Repunit Divisibility [duplicate] (1 answer) Closed 8 years ago . How can I prove that any number coprime with 10 (either prime or not) can divide at least one number of the form 111...111?,"['number-theory', 'discrete-mathematics']"
1657823,How many possible combinations in $7$ character password?,"The password must be $7$ characters long and it can include the combination: $10$ digits $(0-9)$ and uppercase letters $(26)$. My Solution: Thus in total there are $7$ slots, each slot could be either $0-9$ or $26$ letters $= 36$ possibilities for each slot, therefore, $36^7$ would be the number of password combinations? Am I correct?","['permutations', 'combinatorics', 'combinations']"
1657846,Function is bounded on plane,"Let $f(x,y)=-\dfrac{2x^3y}{(x^2+y^2)^2}$ for $(x,y)\neq (0,0)$ and $f(0,0)=0.$ Prove that $f$ is bounded on $\mathbb{R}^2$.","['multivariable-calculus', 'inequality', 'functions']"
1657849,Proving a modified version of Jordan's lemma?,"I want to prove the version of Jordan's lemma which say's that: Around a contour as shown below: The integral:
$$\int_{\Gamma} e^{az}f(z)dz$$
will go to $0$ if $$|f(z)|\le \frac{M}{R^\alpha}$$ for some positive $M$ and $\alpha$. Does anyone know how this can be proved?","['complex-analysis', 'contour-integration']"
1657878,"Proof of for all integer $n \ge 2$, $n^3-n$ is divisible by 6 by mathematical induction.","Prove the following statement by mathematical induction: For all integer $n \ge 2$, $n^3-n$ is divisible by 6 My attempt: [Proof]
 Let the given sentence p(n) (1) $2^3-2$=6 is divisible by 6. p(2) is true. (2) Suppose for all integer $k \ge 2$, p(k) is true. 
That is, mathematical hypothesis is $k^3-k$ is divisible by 6. Then we must show that p(k+1) is true. $(k+1)^3-(k+1) = (k^3 +3k^2+3k+1)-(k+1)$=$(k^3 -k)+(3k^2+3k)$ I have to get some multiple of 6 from $(3k^2+3k)$ to reach p(k+1) is true. How can I complete this proof?","['discrete-mathematics', 'elementary-set-theory', 'elementary-number-theory']"
1657900,A white noise process which does not consist of independent random variables?,"I know the definition of a white noise $\{u_t\}$ (see below), but I cannot see how to find an example of a white noise which is serially dependent, e.g. where $u_t$ depends on the value of $u_{t-1}$. Can someone provide an example of a dependent white noise process? Definition of a white noise process. The stochastic process $\{u_t\}$ is white noise if and only if (1) $E(u_t)=0$ and (2) $E(u_tu_{t+k})=\sigma^2\textbf{1}\{k=0\}$, where $\textbf{1}\{k=0\} =1$ if $k=0$ and $0$ otherwise,  and where $\sigma>0$ is finite.","['independence', 'statistics', 'random-variables']"
1657972,Does the axiom of choice have any use for finite sets?,It is well known that certain properties of infinite sets can only be shown using (some form of) the axiom of choice. I'm reading some introductory lectures about ZFC and I was wondering if there are any properties of finite sets that only hold under AC.,"['elementary-set-theory', 'axiom-of-choice']"
1657981,lim inf version of sequential criterion,"I know that if $f$ is a continuous function, then $\lim f(x_n)=f(\lim x_n)$, provided $\lim x_n$ exists. Can the same thing work for $\lim\inf$? i.e. is it true that $\lim\inf f(x_n)=f(\lim\inf x_n)$, provided $\lim\inf x_n$ exists (which it always does).? Thanks for any help.
I am trying to see if I can use this property in another proof.","['functional-analysis', 'real-analysis']"
1657992,Gambling device: What's my probability to win at 5 dollars before going bankrupt?,"I'm going gambling and I have ten dollars. I have a gambling device that costs 1 dollar per game to play. I win with a probability of $\frac{1}{5}$ and each win gives me back four dollars (to a net profit of three) while lost games give nothing back for a net loss of one dollar. I'm going to play the game until I go bankrupt (net wins and net losses sum up to $-10$ or less) or I make a profit of five dollars (net wins and net losses sum up to $5$ or more). I want to know the probability of the game ending in me winning. At first I tried analyzing this using the binomial distribution but I'd need to know the total number of games in advance, but it is unbounded. Ideas on how to approach this are warmly welcome.",['probability']
1658002,Multi-variable Limit,"Question : Does the following limit exist, if so what does it equal? 
$$\lim_{(x, y) \to (0,0)} \frac{x^2 y^5}{2x^4 +3y^{10}}$$ - Solution 1 : The limit DOES NOT exist. Let $ x=y^{5/2}$
$$\lim_{y \to 0} \frac{(y^{5/2})^2 y^5}{2(y^{5/2})^4 +3y^{10}} = \lim_{y \to 0} \frac{y^{10}}{2y^{10} +3y^{10}} = \lim_{y \to 0} \frac{1}{2 +3} = \frac{1}{5} $$ Let $ x=0$
$$\lim_{y \to 0} \frac{(0)^2 y^5}{2(0)^4 +3y^{10}} = \lim_{y \to 0} \frac{0}{0 +3y^{10}} = \lim_{y \to 0} 0 = 0 $$ Thus the limit does not exist Solution 2 : The limit DOES exist. Change to polar coordinates and find limit as $r \to 0$
$$\lim_{r \to 0} \frac{(r^2cos^2{\theta}) (r^5sin^5\theta)}{2(r^4cos^4{\theta}) +3(r^{10}cos^{10}{\theta})} =\lim_{r \to 0}\frac{r^4}{r^4} \times\frac{r^3cos^2{\theta} sin^5\theta}{2cos^4{\theta} +3r^{6}cos^{10}{\theta}} =\frac{0}{2cos^4{\theta} +0}= 0  $$ Thus the limit does exist and is $0$ - Problem Can someone please tell me which solution is correct (if any) and why the other is wrong?",['multivariable-calculus']
1658036,SVD for augmented matrix,"I'm doing the following problem to prepare for my exam tomorrow: Suppose that $A$ is a $n \times m$ matrix with $n \geq m$ and that the singular values of $A$ are $\sigma_1, \sigma_2, \dots, \sigma_m$ . Now consider the augmented matrix $$B = \left[ \begin{array}{cc} A \\ I \end{array} \right],$$ where $I$ is the $m \times m$ identity matrix. We want to show that the singular values of $B$ are $\tilde{\sigma}_i = \sqrt{1 + \sigma_i^2}$ for each $i$ . I'm currently lost on where to begin. I know that $A = U\Sigma V^T$ for orthogonal matrices $U$ and $V$ with $\Sigma$ containing the singular values on the diagonal, by definition. However, I'm not seeing how to extend this to show the desired result for $B$ . Can someone lend a hand?","['matrices', 'svd', 'linear-algebra']"
1658049,Prove that $\phi$ is class preserving automorphism,"Let $G$ be a finite group and $\phi:G\to G$ be an automorphism of $G$ such that $\phi|_P=conj(g)|_P$ (restriction of some inner automorphism of $G$) where $P$ is any sylow $p$-subgroup of $G$, then is it true that $\phi$ preserves conjugacy classes of $G$? If the group is nilpotent this is clearly true, but is it true always?","['finite-groups', 'abstract-algebra', 'group-theory']"
1658054,Proof of $n(n^2+5)$ is divisible by 6 for all integer $n \ge 1$ by mathematical induction,"Prove the following statement by mathematical induction: $n(n^2+5)$ is divisible by 6 for all integer $n \ge 1$ My attempt: Let the given statement be p(n). (1) $1(1^2+5)$=6 Hence, p(1) is true. (2) Suppose for all integer $k \ge 1$, p(k) is true. That is, $k(k^2+5)$ is divisible by 6 We must show that p(k+1) is true. $(k+1)((k+1)^2+5)$=$k^3+3k^2+3k+1+5(k+1)$ =$k^3+3k^2+8k+6$ =$k(k^2+5)+3k^2+3k+6$ I'm stuck on this step. I feel I have to show $3k^2+3k+6$ is divisible by 6. But, how can I show $3k^2+3k+6$ is divisible by 6?","['discrete-mathematics', 'elementary-set-theory', 'elementary-number-theory']"
1658058,"Are all compact subgroups of $GL(n,\Bbb C)$ in $U(n)$?","If $G$ is a compact subgroup of the multiplicative group $\Bbb C-\{0\}$, then it is easy to show that $G\subseteq S^1$. I wonder if this generalizes as follows: Question: If $G$ is a compact subgroup of $GL(n,\Bbb C)$, do we have $G\subseteq U(n)$? I am more interested in Lie groups, but I don't know if assuming $G$ is a Lie group can help. If it does make a difference, then yes I am assuming $G$ is a Lie group. Proof in case of $n=1$: Suppose $g\in G$ and $g\notin S^1$. Then, $g=re^{i\theta}$ for $r\neq 1$. By taking $g^{-1}$ if necessary we may assume $r>1$. Then, $g^n\in G$ for all $n\geq 0$ but $|g^n|=r^n\to\infty$ as $n\to\infty$ so $G$ is unbounded and hence not compact.","['general-topology', 'topological-groups', 'group-theory', 'lie-groups']"
1658059,Finding limit of a 2 variable function (or show a lack of),"$$ \lim_{x,y\to -1,0} \frac{πx^4 - 3xy^3}{ln(x^4+y^4)} $$ How do i find the following limit, or explain that it does not exist?","['multivariable-calculus', 'limits']"
1658066,General formula for the higher order derivatives of composition with exponential function,"Suppose I have a function $x:\mathbb{R} \to \mathbb{R}$ and consider:
$$g(t) = e^{x(t)}$$
When I start differentiating with respect to $t$ I obtain:
\begin{align}
g'&=e^xx'\\
g''&=e^x((x')^2+x'')\\
g'''&=e^x((x')^3+3x'x''+x''')\\
&...
\end{align} My question is whether there is a reasonable expression for higher derivatives of $g$ as a function of $x$. I'm pretty sure this kind of a thing has its own name, but I cannot find anything... Thank you in advance!","['derivatives', 'exponential-function', 'closed-form']"
1658073,Value of the product: $ \sqrt{2} \sqrt{2 - \sqrt{2}} \sqrt{2 - \sqrt{2 - \sqrt{2}}} \sqrt{2 - \sqrt{2 - \sqrt{2-\sqrt{2}}}} \cdots $ =?,"Let the recursive sequence $$ a_0 = 0, \qquad a_{n+1} = \sqrt{2-a_n},\,\,n\in\mathbb N.
$$ T
Can we find the value of the product $$
\prod_{n=1}^{\infty}{a_n}?
$$ Well, from here I don't seem to follow. I can understand that there would be some good simplification and the product will hopefully telescope but I'm lacking the right algebra. I also thought of finding a recurrence solution probably from the corresponding DE but that didn't follow as well.","['infinite-product', 'limits', 'convergence-divergence', 'nested-radicals', 'sequences-and-series']"
1658103,A basic query on sylow subgroup,"Let $G$ be a  group of odd order then $2 \not\mid\ \lvert G \rvert$, so can we say that $G$ has a sylow $2$- subgroup which is $\{e\}$ or a sylow $p$-subgroup of $G$ is only defined if $p \mid \lvert G \rvert$?","['sylow-theory', 'group-theory']"
1658106,Determining a matrix from its characteristic polynomial,"Let $A\in\mathcal{M}_{n}(K)$ , where $K$ is a field. Then, we can obtain the characteristic polynomial of $A$ by simply taking $p(\lambda)=\det(A-\lambda I_n)$ , which give us something like $$p(\lambda) = (-1)^n\lambda^n + (-1)^{n-1}(\text{tr } A)\lambda^{n-1} +  \cdots + \det A$$ Now, how can we obtain the matrix $A$ knowing the characteristic polynomial?","['galois-theory', 'systems-of-equations', 'matrices', 'characteristic-polynomial', 'linear-algebra']"
1658113,"Exercise from ""Moduli of Curves""","I am struggling with Exercise 1.5 from the book ""Moduli of Curves"" by Harris and Morrison. Namely, I want to show that $\mathbb{P}^1_{\mathbb{C}}$ is a fine moduli space of lines through the origin in $\mathbb{C}^2$. Edit: I want to phrase the question differently and more detailed. Here are my thoughts. First of all, by $\mathbb{C}^2$ I mean the affine space $\textrm{Spec} (\mathbb{C}[x,y])$. And a line through the origin is a subscheme corresponding to an ideal generated by $\lambda x+\mu y$ where $\lambda, \mu \in \mathbb{C}$ are not both zero. Now consider the functor $F$ from the category of schemes over $\mathbb{C}$ to the category of sets that sends a scheme $X$ to the set of subschemes $W \subseteq \mathbb{C}^2 \times X$ (together with the projection on $X$) that have the property that the fiber over every $\mathbb{C}$-point of $X$ is a line through the origin (the fiber is embedded to $\mathbb{C}^2$ via the projection). I want to show that $F$ is isomorphic to $\textrm{Mor}_{\mathbb{C}}(-,\mathbb{P}^1_{\mathbb{C}})$. So I want to find two natural transformations $F\to \textrm{Mor}_{\mathbb{C}}(-,\mathbb{P}^1_{\mathbb{C}})$ and $\textrm{Mor}_{\mathbb{C}}(-,\mathbb{P}^1_{\mathbb{C}})\to F$ that are inverse to each other. For the second one there is a natural candidate coming from the tautological bundle over $\mathbb{P}^1_{\mathbb{C}}$. But my problem is to show that this has an inverse: So I have a subscheme $W \subseteq \mathbb{C}^2 \times X$ that has the property that the fiber over every $\mathbb{C}$-point of $X$ is a line through the origin and I have to find a corresponding morphism $X \to \mathbb{P}^1_{\mathbb{C}}$. This means that I have to associate a line bundle to $W$ that is generated by two global sections. I guess to do that, one takes sections of the projection map $W \to X$. This gives a sheaf on $X$, but why is it coherent and locally free of rank one?","['deformation-theory', 'algebraic-geometry']"
1658165,Showing there is no local isometry between spheres of different radii,"I wish to show there is no is no local isometry between 2-dim spheres of different radii, without the use of curvature, as it is not in my knowledge yet. Could you provide directions? If such isometries preserves area, the contradiction can be reached by considering an equilateral triangle and its image. Though I doubt it's the case.","['spherical-trigonometry', 'spherical-geometry', 'geometry']"
1658174,Geometric proof for irrationality of $\pi$,Is there a geometric proof for irrationality of $\pi$? That would be neat.,"['number-theory', 'euclidean-geometry', 'irrational-numbers']"
1658176,"The function $\mathrm{Li}_2(x)=\int_2^x\frac{dt}{\log^2t}$, its inverse and summation","I am reading the more understandable mathematics in the section Preliminary Results of a paper in which the authors give a explanation of facts for the logarithmic integral and its inverse. In this post I ask about similar equations but now for a different logarithmic integral function, now I consider $\mathrm{Li}_2(x)=\int_2^x\frac{dt}{\log^2t}$, and its inverse $\mathrm{Li}_2^{-1}(x)$. My goal is understand more these facts (the genuine computations from the authors), and refresh basics about analysis. I know the relation between a function that has inverse, its graph, the function $x$ and the inverse function (I write this because could be useful to find the asyptotic that I ask in my question, I don't know how deduce it now). I can write and know that
$$\mathrm{Li}_2(x)\sim\frac{(1+o(1))x}{\log^2x}\quad\text{  as }x\to\infty,$$ but, Question 1. Can you give the correspoding and similar asymptotic for $\mathrm{Li}_2^{-1}(x)$, as $x\to\infty$? Here, as I've said $\mathrm{Li}_2^{-1}(x)$ is the inverse function of the logarithmic integral $\int_2^x\frac{dt}{\log^2t}$. I know that by differentiation of a inverse function and by the Fundamental Theorem of Calculus I can write my explanation for a similar equation for $\mathrm{Li}_2(x)$ (following the equation that the authors write for the logarithmic integral) $$\left(\mathrm{Li}_2^{-1}\right)'\left(\mathrm{Li}_2(x)\right)=\frac{1}{\frac{d}{dx}\left(\int_2^x\frac{dt}{\log^2t}\right)}=\log^2x,$$ and combining this last with the composition with $\mathrm{Li}^{-1}_2(x)$ one has the coresponding equation and compute $\left(\mathrm{Li}_2^{-1}\right)'(x)$ as 
$$\left(\mathrm{Li}^{-1}_2\right)'\left(\mathrm{Li}_2\left(\mathrm{Li}_2^{-1}(x)\right)\right)=\log^2\left(\mathrm{Li}_2^{-1}(x)\right).$$ Question 2. Can you use the asymptotic that you've computed as answer of Question 1 , to get an asymptotic as $x\to\infty$ for $\log^2\left(\mathrm{Li}_2^{-1}(x)\right)$? I believe, following similar computations that authors give for their logarithmic integral function, that now I with $\mathrm{Li}_2(x)$ can write $$\sum_{1<m<n}\mathrm{Li}^{-1}_2(x)=\int_2^{\mathrm{Li}_2^{-1}(n)}\frac{tdt}{\log^2t}+O\left(\sum_{1\leq m\leq n}\log^2 m\right).$$ Question 3 (Now this question is optional, thus 
  it is not necessary to answer). I say that I've asked to me if previous identity is right when I write the similar statement for which I believe that holds. Can you refute previous statement? Can you prove it using previous answers to my questions (I believe that with these the authors can prove their identity), or at least give a reasonable approximation for other methods (I say perhaps partial summation)?","['derivatives', 'polylogarithm', 'asymptotics', 'inverse-function']"
1658186,I've found two different definitions of a cylindrical Brownian motion and don't understand why they are consistent,"Let $(\Omega,\mathcal A,\operatorname P)$ be a probability space $(\mathcal F_t)_{t\ge 0}$ be a filtration of $\mathcal A$ $(U,\langle\;\cdot\;,\;\cdot\;\rangle)$ be a separable Hilbert space $\left(B^{(n)}\right)_{n\in\mathbb N}$ be independent real-valued Brownian motions with respect to $\mathcal F$ on $(\Omega,\mathcal A,\operatorname P)$ $\mathfrak L(X)$ be the set of bounded, linear operators on a normed vector space $X$ I've found two different definitions of a cylindrical Brownian motion and don't understand why they are consistent: Definition 1 : Let $Q\in\mathfrak L(U)$ be nonnegative and symmetric $U_0:=Q^{\frac 12}(U)$, $$\langle u,v\rangle_0:=\langle Q^{-\frac 12}u,Q^{-\frac 12}v\rangle\;\;\;\text{for }u,v\in U_0$$ where $Q^{-\frac 12}$ is the pseudo inverse of $Q^{\frac 12}$ and $(e_n)_{n\in\mathbb N}$ be an orthonormal basis of $U_0$ $(U_1,\langle\;\cdot\;,\;\cdot\;\rangle_1)$ be a separable Hilbert space and $$\iota:(U_0,\langle\;\cdot\;,\;\cdot\;\rangle_0)\to(U_1,\langle\;\cdot\;,\;\cdot\;\rangle_1)$$ be a Hilbert-Schmidt embedding, e.g. $(U_1,\langle\;\cdot\;,\;\cdot\;\rangle_1):=(U,\langle\;\cdot\;,\;\cdot\;\rangle)$ and $$\iota u:=\sum_{n\in\mathbb N}\alpha_n\langle u,e_n\rangle_0e_n\;\;\;\text{for }u\in U_0\tag 1$$ for some $(\alpha_n)_{n\in\mathbb N}\subseteq(0,\infty)$ with $\sum_{n\in\mathbb N}\alpha_n^2<\infty$ Then $$W_t:=\sum_{n\in\mathbb N}B_t^{(n)}\iota e_n\;\;\;\text{for }n\in\mathbb N\text{ and }t\ge 0\tag 2$$ is called a cylindrical $Q$-Brownian motion with respect to $\mathcal F$ on $(\Omega,\mathcal A,\operatorname P)$. [Note that (2) is convergent in $L^2(\Omega; U_1)$.] Definition 2 : Let $(\tilde e_n)_{n\in\mathbb N}$ be an orthonormal basis of $U$ Then $$W_t:=\sum_{n\in\mathbb N}B_t^{(n)}\tilde e_n\;\;\;\text{for }n\in\mathbb N\text{ and }t\ge 0\tag 3$$ is called a cylindrical Brownian motion or space-time white noise with respect to $\mathcal F$ on $(\Omega,\mathcal A,\operatorname P)$. [Note that (3) is convergent in $L^2(\Omega;\tilde U_1)$ if $U_1\supseteq U$ is a separable Hilbert space and there is a Hilbert-Schmidt inclusion $\tilde\iota:U\to\tilde U_1$.] Definition 2 seems to be a special case of Definition 1, but how do we obtain it? If we choose $Q:=\operatorname{id}_U$, then $(U_0,\langle\;\cdot\;,\;\cdot\;\rangle_0)=(U,\langle\;\cdot\;,\;\cdot\;\rangle)$). Now, we could choose $(U_1,\langle\;\cdot\;,\;\cdot\;\rangle_1):=(U,\langle\;\cdot\;,\;\cdot\;\rangle)$ and $\iota$ to be $(1)$ (with $\langle\;\cdot\;,\;\cdot\;\rangle_0$ replaced by $\langle\;\cdot\;,\;\cdot\;\rangle$). However, that doesn't yield that $(2)$ and $(3)$ are equal (does it?). So, how do we obtain a space-time white noise $(3)$ from $(2)$?","['stochastic-processes', 'probability-theory', 'mathematical-physics', 'functional-analysis', 'brownian-motion']"
1658199,A conjecture on Schatten 1-norm,"I have a conjecture on Schatten 1-norm. Before presenting the conjecture, let us first  specify the notions used here. A matrix $A$ is said to be a density operator if $A$ is positive semidefinite with $\textrm{tr}(A)=1$. The Schatten 1-norm of a matrix $A$ is $\|A\|_1:=\textrm{tr}\sqrt{A^{*}A}$. My conjecture is: if $\|\rho_1\otimes\sigma_1-\rho_2\otimes\sigma_2\|_1=\|\rho_1-\rho_2\|_1$ and $\rho_1\rho_2\neq0$, i.e., the supports of $\rho_1$ and $\rho_2$ are not orthogonal, then $\sigma_1=\sigma_2$, where $\rho_i$, $\sigma_i$, $i=1,2$ are density operators. I know this conjecture holds for some special cases, but I do not know how to prove it in general. So can anyone help me?","['tensor-products', 'matrices', 'mathematical-physics', 'functional-analysis', 'linear-algebra']"
1658224,Find all square numbers $n$ such that $f(n)$ is a square number,Find all the square numbers $n$ such that $ f(n)=n^3+2n^2+2n+4$ is also a perfect square. I have tried but I don't know how to proceed after factoring $f(n)$ into $(n+2)(n^2+2)$. Please help me. Thanks.,"['number-theory', 'square-numbers', 'elementary-number-theory']"
