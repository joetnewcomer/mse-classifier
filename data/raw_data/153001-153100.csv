question_id,title,body,tags
2569899,Geometric Proof of Irrationality of non-square $k$,"I was reading an interesting proof (published by Apostol I believe) of irrationality of $\sqrt{2}$ that aimed to use purely geometric methods to prove the result. Although the proof is interesting on its own, I was wondering if it is possible to use a similar technique for a general argument that the square root of any non-square $k$ is irrational. I know the Apostol paper claims this can be done for $\sqrt{n^2 + 1}$ and $\sqrt{n^2 - 1}$ but the paper I read this proof in claims it can be generalised to any non-square $k$: This proof is a prime example of the cooperation of two different fields of mathematics. We just translated a purely number-theoretical problem into a problem about triangle similarity, and used our result there to solve our original problem. This technique is widely used all over higher-level mathematics, even between things as seemingly unrelated as topological curves and groups. Finally, we leave it as an exercise to the reader to extend this proof to a proof that whenever $k$ is not a perfect square, then $\sqrt{k}$ is irrational. The proof is quite similar, but strays from nice isosceles right triangles Is this possible? If so, I would love to see how!","['irrational-numbers', 'geometry']"
2569920,"Continuous $f:[0,1]\to\mathbb{R}$ such that $f(0)=f(1)$ and $\forall\alpha\in(0,1)\exists c\in[0,1-\alpha]|f(c)=f(c+\alpha)$?","Let $f:[0,1]\to\mathbb{R}$ continuous such that $f(0)=f(1)$. Is it true that $\forall\alpha\in(0,1)\exists c\in[0,1-\alpha]|f(c)=f(c+\alpha)$? At first I tried to find a counterexample but my intuition says it's true.
Then I've got the idea of applying Bolzano's Theorem to $g(x)=f(x)-f(x+\alpha)$ defined on $[0,1-\alpha]$  but I didn't get anything. What can I do?",['real-analysis']
2569938,How to Find the Area of This Composite Figure,"In my assignment, I have this problem that I must find the exact value for: I'm not sure, but I think I should first draw another triangle above the 35 cm, making a rectangle. I could find the area of the rectangle (49 * 23). Then, I can do the Pythagorean Theorem for that other triangle (35^2+b^2=49^2 ---> b=sqrt 1176), subtracting the total from the rectangle area. But, to me, this method is not correct because there is a small triangle-shaped space near the 23 cm, so I'm not sure my finding of the area will work. Step by step, could you explain how you would find the area of this composite?","['area', 'triangles', 'geometry']"
2569960,Behavior of a variety under base change,"I am looking for an example of an irreducible variety $X$ say over a field $K$ such that the base change $X_\overline K$ to an algebraic closure is no longer irreducible, and has irreducible components of many different dimensions. For example the curve $x^2+y^2=0$ is irreducible 1 dimensional (in the sense of Krull dimension of the co-ordinate ring) over $\mathbb R$ but splits into two lines $(x+iy)(x-iy)=0$ over $\mathbb C$. But in this case, the components are of all of same dimension 1. In general, how wild can $X$ be after base change? Is it wilder if we allow $X$ to be an integral scheme? Is there a theory to control it? e.g. if we impose $X$ is affine, projective (scheme), characteristic $0$ etc? EDIT: The question was resolved in the case of varieties, and I decided to drop the case for schemes, because base change locally corresponds to tensoring with an arbitrary ring, whence it is no longer reasonable to continue without adding many more qualifiers.","['schemes', 'affine-varieties', 'projective-schemes', 'algebraic-geometry']"
2569962,Principal directions of parallel (offset) surfaces,"Suppose $\mathbf{F}(u,v)$ is a parametric surface. We can define another surface $\mathbf{G}(u,v)$ by $$
\mathbf{G}(u,v) = \mathbf{F}(u,v) + r\mathbf{N}(u,v)
$$ where $r \ge 0$ and $\mathbf{N}(u,v)$ is the unit normal of $\mathbf{F}(u,v)$ given by $$
\mathbf{N}(u,v) = \frac {\mathbf{F}_u(u,v) \times \mathbf{F}_v(u,v) }
                   {  \| \mathbf{F}_u(u,v) \times \mathbf{F}_v(u,v) \| }
$$ The surface $\mathbf{G}(u,v)$ is called an offset surface in my field (CAGD), or a parallel surface in traditional differential geometry. I'm trying to relate the curvature properties of $\mathbf{G}$ to those of $\mathbf{F}$ . Specifically, I'm wondering about the principal directions at corresponding points of $\mathbf{F}$ and $\mathbf{G}$ . My intuition says that these ought to be related in some simple way, maybe even parallel. Can anyone throw any light on this? The application is in design/manufacturing, so we can restrict our attention to ""nice"" surfaces like roofs of cars or wings of airplanes. For example, we can assume that $r$ is small, so that no unpleasant cusps or self-intersections occur on $\mathbf{G}$ .","['differential-geometry', 'surfaces']"
2570012,"For two random variables $X_1 + X_2$ and $\min(X_1,X_2)$ find the joint-distribution and the covariance","Let $X_1,X_2$ be independent random variables. Moreover $X_1,X_2$ are discrete uniform distributed({$1,...,N$}) We define: $A:=  X_1+X_2$ $B:= \min(X_1,X_2)$ Find joint-distribution of $A$ and $B$  and calculate covariance of $A$ and $B$. I don't really have a clue how to find the joint-distribution of $A$ and $B$. So for this task I really need some help. Maybe you can give me a hint and I try to solve it then. I would edit this question with my attempt until I find the joint-distribution. Edit : Let us start with the joint distribution. $P(A=a,B=b) =P(B=b|A=a)\cdot P(A=a)$. In the answers below I saw that: $ P(A=a)=\frac{1}{N^2}\left\{ \begin{array}{lr}a-1& 2\leq a \leq N+1 \\
2N+1-a & N+2\leq a \leq 2N \end{array} \right. $ I understand why this formula holds for $P(A=a)$ but only with the example. I don't know how we can show it. Moreover We have to find $P(B=b|A=a)$. I think a) is clear now. Will try to edit my attempt in a few days. Edit for the second part : I will write $Cov$ for covariance.
So we have to calculate $Cov(A,B)$. We already know that: $Cov(A,B) = E(AB) - E(A)E(B) $ (expected value) All we have to compute is the expected value for $AB,A,B$. Thanks to the user ""mathemagical"". I already know the value of $E(A), E(B)$. I even understand the rest of the answer except how we can calculate $E(Z)$.","['covariance', 'probability', 'random-variables', 'probability-distributions']"
2570022,"Exponential Generating Function for the number of sequences in A,B,C","I am trying to study exponential generating functions and I am having a difficult time understanding. I am tasked with writing an exponential generating function for the number of sequences in A,B,C of length n such that there is at least one A and two C's. In general, an EGF is of the form $\sum_{n=0}^{\infty} a_{n} \frac{x^n}{n!}$ where $a_{n}$ counts the number of ways to impose a certain structure on a set. The number of sequences of length n that will contain at least one A is I believe $n 3^{n-1}$ because we will place an A in the sequence, for which we have $n$ choices, and then for the remaining $n-1$ spots, we have 3 choices. Choosing two C's will probably be similar, ${n \choose 2}\cdot 3^{n-2}$ since we will place two C's in our sequence, and then have 3 choices for the other $n-2$ spots. Thank you.","['permutations', 'combinatorics', 'generating-functions']"
2570033,Application Radon - Nikodym,"I just learned about Radon-Nikodym theorem. However, I do not seem to have any intuition on how to apply it... For example : Let $(X,\mathscr{M},\lambda)$ be a $\sigma-$finite measure. Let $f$ be $\mathscr{M}$ measurable. Let
$\mathscr{N} \subset \mathscr{M}$ be a $\sigma-$algebra. Prove that there exists an $\mathscr{N}$ measurable function $g$ such that 
$$ \int_B f d\lambda = \int_B g d\lambda $$
for every $B\in \mathscr{N}$ Clearly this question feels like an application for the Radon-Nikodym theorem. However how can I find all the ingredients ? I have to find some signed measure $\mu$ which is absolutely continuous with respect to $\lambda$.
Maybe $\mu(B) = \int_B f d\lambda$ is simply the answer.","['radon-nikodym', 'measure-theory']"
2570034,Injection from dual space into double dual space,"I know for a vector space $V$ over the real or complex numbers, there exists a canonical embedding into its double dual $V^{**}$, and if $V$ is given an inner product, then there is a canonical embedding from $V$ into $V^*$. However, I was not sure if there is any canonical embedding from $V^*$ into $V^{**}$ that is compatible with the above emebeddings, i.e. if
$$\sigma:V \rightarrow V^{**}, \sigma(v)(f)=f(v)$$
$$\iota:V \rightarrow V^*, \iota(v)(w)=\langle w,v \rangle$$
are injective linear map. So my question is: Is there a canonical (does not depend on basis) injective linear map  $\mu: V^* \rightarrow V^{**}$ such that
$$\sigma = \mu \circ \iota$$
I try to build an inner product on $V^*$ based on the inner product on $V$ but to no avail.","['canonical-transformation', 'linear-algebra', 'linear-transformations', 'dual-spaces']"
2570054,How to calculate a matrix $M$ by dividing 2 vectors?,"Let $u = \begin{bmatrix}a\\b\\c\end{bmatrix}$ Let $v = \begin{bmatrix}d\\e\\f\end{bmatrix}$ There exists a $3\times3$ matrix, $M$, such that: $Mu = v$ so $M = vu^{-1}$ But how do I go about calculating $vu^{-1}$? My guess is that $u^{-1}$ will be a row vector in order to make the multiplication work... But apparently you can't do inverses on non-square matrices.","['matrices', 'linear-algebra']"
2570065,Derivative of a rotated vector with respect to the quaternion,"Let us say we have a right-handed unit quaternion, describing the rotation from frame $a$ to frame $b$ : $q_a^b$ .  The rotation matrix formed from this quaternion is $R\left( q_a^b \right)$ and describes a passive rotation.  That is, $R\left( q_a^b \right)v$ describes the same object $v$ in the new frame $b$ . The following expression is given in Michael Andre Bloesh's dissertation without explanation link - (unfortunately embargoed until April 2018) $$\frac{d}{dq_a^b} R\left( q_a^b \right)v = -\left( R\left( q_a^b \right)v  \right)^\times $$ where the $\left( \cdot \right)^\times $ notation is the skew-symmetric matrix. I played with these expressions numerically to confirm the above and 
 also discovered that the derivative of the active rotation is $$\frac{d}{dq_a^b} R\left( q_a^b \right)^\top v = R \left( q_a^b \right)^\top \left( v \right)^\times $$ which I guess makes some intuitive sense as well. While these expressions seem to work, how do I approach this problem in a principled way (i.e. not guessing and checking with numerical differentiation)?","['derivatives', 'rotations', 'quaternions', 'differential-geometry']"
2570067,Can a product of a number and its reverse consist of only $1$'s?,"Problem: Let $n \gt 1$. If you write the digits of $n$ in reverse, then multiply by original $n$, is it possible for the product to consist only of $1$'s? This came from a competition I recently did, and I found this question quite interesting. Below is the proof I submitted. It's a little tedious in the middle, so feel free to correct any errors. Proof: Let $\bullet n$ denote reversed $n$. Assume $n$ has $k$-digits. Then $$n = 10^{k-1}a_1+10^{k-2}a_2 + \dots + 10a_{k-1}+a_k$$ where $0 \le a \le 9$, $a \in \mathbb Z$, and $a$ is the digit. $\bullet n$ multiplied by $n$: \begin{align}
& \bullet n \cdot n \\
& = (10^{k-1}a_k + 10^{k-2}a_{k-1} + \dots)(10^{k-1}a_1+10^{k-2}a_2 + \dots) \\
& = 10^{2k-2}a_ka_1 + 10^{2k-3}a_ka_2 + 10^{2k-3}a_{k-1}a_1+\dots+10^{2k-k}a_1^2+10^{2k-k}a_2^2+\dots \\
& = 10^{2k-2}(a_ka_1) + 10^{2k-3}(a_ka_2 + a_{k-1}a_1)+\dots + 10^{k}(a_1^2 + a_2^2 + \dots ) + \dots \\
\end{align} We now have the digits of the product of $\bullet n$ and $n$. Equate all digits to $1$: \begin{align}
1 & = a_ka_1 \tag{1} \\
1 & = a_ka_2 + a_{k-1}a_1 \tag{2} \\
1 & = a_1^2 + a_2^2 + \dots + a_{k-1}^2 + a_k^2 \tag{3} \\
\end{align} Observe $(1)$. $a_ka_1 = 1 \implies a_k = a_1 = 1$. Now observe $(3)$. We have: \begin{align}
a_1^2 + a_2^2 + \dots + a_{k-1}^2 + a_k^2 & = 1 \tag{3} \\
1^2 + a_2^2 + \dots + a_{k-1}^2 + 1^2 & = 1 \\
a_2^2 + a_3^2 + \dots + a_{k-2}^2 + a_{k-1}^2 & = -1 \\
\end{align} The sum of the squares of real, positive integers cannot be a negative number. Hence, we have a contradiction. By reductio ad absurdum , we have proved that the product of $n$ and $\bullet n$ cannot consist only of $1$'s. $\Box$","['algebra-precalculus', 'proof-writing', 'proof-verification']"
2570098,Prove that $\sum_{i=0}^d {n\choose i}\leq n^d +1$,"Prove that $\sum_{i=0}^d {n\choose i}\leq n^d +1$ I tried doing it by induction. For $d=0$ the inequality says $1\leq 2$, so it's true. For the induction step we assume $\sum_{i=0}^d {n\choose i}\leq n^d +1$ 
so we have
$$\sum_{i=0}^{d+1} {n\choose i}\leq n^d +1 \leq n^d+1+ {n\choose {d+1}}$$
and this is where I am stuck. Why is $n^d+{n\choose {d+1}} \leq n^{d+1}$?","['real-analysis', 'number-theory', 'induction', 'combinatorics', 'analysis']"
2570138,Proof of Holder's Inequality using Jensen's Inequality - Integrability,"I did not find any posts regarding this: So I was reading the Alternate proof of Holder's inequality . What I am confused is the this bolden part: From Jensen's inequality, $$ \int h \, d \nu = \Big( \int h^p \, d\nu\Big)^{\frac{1}{p}}$$ where $\nu$ is a probability measure, and $h$ is any $\nu$ -measurable function . The proof I know of requires $h$ to be integrable, or at least $\int h \,d \nu < \infty$ . Supposing this condition is required. If we proceed the proof, we need to first show $$ \int hg \, d\nu < \infty$$ without invoking the inequality. But this seems to be what we are proving. I believe I am interpreting something wrong. What am I missing?","['inequality', 'probability-theory', 'measure-theory', 'jensen-inequality', 'holder-inequality']"
2570175,What does it mean intuitively for a random variable to be a continuous function from its sample space?,"Let's say we have a probability space $(\Omega, \sigma, P)$. and a random variable $Y:\Omega\to \mathbb R$ $P$ is of course a mapping $P:\Omega\to \mathbb R$. Now, Omega is not necessarily a topology, but we can simply make the additional assumption that $\Omega$ also has a topology $T$ defined on it. This means that we can talk about whether $Y$ is a continuous function from $\Omega \to \mathbb R$. The thing is, I usually think of the sample space $\Omega$ as something that ""exists in the background"", but that is not necessarily what we care about. We really care about the random variables, and when we define probability density functions on them for example, then the sample space is not in view at all (we only see the space of values that the random variable can take (usually $\mathbb R^n$), and the space that the probability density can take (which is $\mathbb R^+$). So that's why I'm wondering, is there an intuitive interpretation of the random variable being a continuous map from $\Omega$ to $\mathbb R$? Bonus : If the topology is a differentiable topological space, is there an interpretation of the random variable being a differentiable function? EDIT : Obviously this will depend on the topology. My question implicitly asks whether there is a topology such that there is such a meaningful interpretation. That is, the interpretation doesn't have to be generally applicable to all topologies and all probability spaces in the same way.","['probability-theory', 'measure-theory', 'geometric-interpretation', 'random-variables']"
2570235,Calculate $\int_{\Omega}f d\lambda$.,"Let $\Omega=[0,1]\times[0,1]$, $\lambda$ the restriction of the Lebesgue measure $\lambda^2$ on $\mathbb{R}$ to $\Omega$. Define $$\begin{array}{rccc} f\colon& \Omega&\longrightarrow&\mathbb{R}\\& (x,y)&\mapsto&
  \begin{cases}
    (1-xy)^{-1} & \text{ if } xy\neq 1,\\
    0 & \text{ if } xy=1.
  \end{cases}\end{array}$$ I have already proven that $f$ is jointly measurable. Now I have to compute $\int_{\Omega}f\,\mathrm d\lambda$. There is a hint that I might need to apply Fubini's theorem twice, and that I can use $\sum_{n=1}^{\infty}\dfrac{1}{n^2}=\dfrac{\pi^2}{6}$ without proof. I really don't know where to start, can somebody help me?","['multivariable-calculus', 'lebesgue-integral', 'definite-integrals', 'measure-theory']"
2570252,Properties of infimum and supremum of sets ( $ A_n \subset B_n \implies \liminf A_n \subset \liminf B_n$),"Prove if $A_n \subset B_n$ for all $n$, then $\liminf A_n \subset \liminf B_n $ and $\limsup A_n \subset \limsup B_n$. Attempt of proof: $\liminf A_n = \bigcup_{n\ge1}\bigl(\bigcap_{k\ge n} A_k\bigr)$ $x \in \liminf A_n \implies \exists n: x \in \bigcap_{k \ge n} A_k \implies x \in A_k, \ \ k\ge n \implies x \in B_k, \ k \ge n \implies x\in \bigcap_{k \ge n}B_k$ and I am not sure what do now 2.$\limsup A_n=\bigcap_{n\ge1}\bigl(\bigcup_{k\ge =n}A_k\bigr)$ $x \in \limsup A_n \implies \forall n \ge 1: \ x\in \bigcup_{k \ge n} A_k \implies x \in \bigcup_{k \ge n}B_k$ and I am not sure what do now",['elementary-set-theory']
2570265,Does $f'(x)>0$ a.e. imply that $f$ is strictly monotone?,"Let us assume that $f:\mathbb{R}\to \mathbb{R}$ is differentiable and $f'(x)>0$ almost everywhere. If $f'\in L^1_{loc}$, then FTC implies that for any $x,a\in \mathbb{R}$,
$$
f(x)-f(a)=\int_a^x f'(t)dt.
$$
Therefore, we have $f(x)\geq f(a)$, because $\int_a^x f'(t)dt\geq \frac{1}{n} m(\{x;f'(x)>\frac 1 n\})$ for any $n\in \mathbb{N}$. Then we know that $f$ has to be strictly monotone. Otherwise, there exits an interval $(c,d)\subset [a,b]$ such that $f(x)$ is constant over $(c,d)$, which is impossibe because $f'(x)=0$ is zero over this interval and hence $f'(x)>0$ a.e. fails. How about removing the assumption that $f'\in L^1_{loc}$? Does $f'(x)>0$ almost everywhere imply that $f$ is strictly monotone",['real-analysis']
2570282,Evaluating an infinite series using contour integral,"This is a problem from Ph.D qualifying exam of complex analysis. Determine the value of $\sum_{n=1}^{\infty} \frac{(-1)^n}{n^2}$ by integrating $f(z) = \frac{\pi \csc \pi z }{z^2} $ on an appropriante domain of the complex plane. My attempt: I already found that for any positive integer $n$, $f$ has a simple pole on $z=n$ and the residue of $f$ on $z=n$ is $\frac{(-1)^n}{n^2}$. Therefore, I think that setting an appropriate contour containing the poles from $z=1$ to $z=n$ and evaluating the contour integral will be helpful. However, I have trouble finding such contour. Does anyone have ideas? Any advice or hint will be helpful! Thanks!","['complex-analysis', 'contour-integration']"
2570298,Prove the function cannot be injective,"Let $f: \{x \in \mathbb{Q}, x \gt 0 \} \rightarrow \mathbb{Q}$ such
  that $f(xy)=f(x) + f(y), \forall x,y$.Prove: $f$ cannot be injective Can $f$ be surjective? For $x=y=1$ I get $f(1)=0$. Also it's easy to prove 
$$f(x^n)=n\,f(x),\quad \forall n \in \mathbb{Z}$$ I could not get further, any help is appreciated UPDATE I've found the proof for 1).
Let $p, q$ be distinct primes, and $a,b \in \mathbb{Z}$ such that $\frac {f(p)}{f(q)}=\frac{b}{a}$. Then $f(p^a)=af(p)=bf(q)=f(q^b)$.",['functions']
2570309,Parallel tangent vector field on torus,"Let's say we have a torus $T$ parametrized by $\varphi(\theta,\phi)=((a + b \cos \phi)\cos\theta, (a + b \cos \phi )\sin\theta, b \sin\phi)$ and $a>b>0$. We construct a smooth tangent unit vector field $X$ on $T$ by differentiating $\varphi$ with respect to $\theta$ and normalizing it to obtain $X(\theta,\phi)=(-\sin(\theta),\cos(\theta),0)$. Now $X$ looks pretty much like $(-y,x,0)$, but then normalized, so $\mathbf Y(x,y,z)=\left((x,y,z),\frac{1}{\sqrt{x^2+y^2}}(-y,x,0)\right)$ would be the non-parametrized version (which we will not use, but maybe it's relevant for the answer). Question : Find a parallel tangent vector field $Z$ along the curve $\alpha : [0, 2\pi] \to T$ given by $\alpha(t) = \varphi(2t, 3t)$, non-zero and distinct from $X$. Now I don't know how to tackle this type of problem, as I don't know how to construct parallel vector fields along any curve. The book I'm using only names a parallel vector field for the sphere (and just spontaneously names one, without explaining how it can be found). So just to make a start, it wouldn't surpise me for some reason if I needed to use
\begin{align*}
\alpha'(t)=(-&3b\sin(3t)\cos(2t)-2(a+b\cos(3t))\sin(2t),\\
-&3b\sin(3t)\sin(2t)+2(a+b\cos(3t))\cos(2t),\\
&3b\cos(3t))
\end{align*} Any help would be appreciated!","['manifolds', 'differential-geometry', 'surfaces']"
2570316,Intersection of two Lie subgroup is Lie subgroup ?,"This question is already asked in here but i can't find a satisfactory answer. The question (in the title) arise from the following definition (i'm using Lee's smooth manifold p.156) : If $G$ is a Lie group and $S \subseteq G$, the $\textbf{subgroup generated by } S$ is the smallest subgroup containing $S$ (i.e., the intersection of all subgroup containing $S$). The definition above implicitly assume that the intersection of any two Lie subgroup $S_1,S_2 \subset G$ is again Lie subgroup. I find it difficult to prove this. I can see that the intersection has the group property but i have no idea how to show that $S_1 \cap S_2$ is an immersed submanifold of $G$. The answer by @Moishe Cohen in the given link above is using argument involving Lie algebra. But since the definition in Lee's book is given before he define Lie algebra, i assume that this problem can be solved without it (probably). Can anyone help me with this ? Thank you.","['smooth-manifolds', 'submanifold', 'differential-geometry', 'lie-algebras', 'lie-groups']"
2570327,"Calculate probability $P(\min\left\{X,Y\right\} \leq x)$ and $P(\max\left\{X,Y\right\} \leq x)$","$X,Y$ are independent, identical distributed with $$P(X=k) =
P(Y=k)=\frac{1}{2^k} \,\,\,\,\,\,\,\,\,\,\,\, (k=1,2,...,n,...)$$ Calculate the probabilities $P(\min\left\{X,Y\right\} \leq x)$ and
  $P(\max\left\{X,Y\right\} \leq x)$ For the minimum I do like this: $$\begin{split}F_M(x) &= P(\min\left\{X,Y\right\} \leq x) \\ &= 1-P(x<\min\left\{X,Y\right\} ) \\ &= 1-P(x<X, x<Y) \\ & = 1-P(X>x)\,P(Y>x)\\ & = 1-(1-P(X \leq x))\,(1-P(Y \leq x))\\ & = 1-(1-F_X(x))\,(1-F_Y(x))\end{split}$$ Is this correct for minimum? I'm not sure how do it for $\max$? Maybe I do it too complicated because they are equal these $P(X=k)=P(Y=k)$ maybe you can do it more elegant? But I don't know how?","['probability', 'probability-distributions']"
2570328,derivative of $\frac 2x \sin(x^3)$ by definition,"The function: $$\frac 2x \sin(x^3)$$ when $x\neq0$, and $0$ while $x=0$. I need to find if the function is derivation at $x=1$. First step was to check if the function is continuous. there is just 1 side of limit to check (since its the same function around $x=1$, so I compared the limit of the function with $f(1)$:
$$\lim_{x\to 1}\space \frac{2}{x}\sin(x^3) = 2\sin(1) = f(1)$$ first question: was this step necessary? next:
$$f'(1) =\lim_{h\to 0}\space \frac{ \frac2{h+1}\sin((h+1)^3)-2\sin(1)}h$$ $$=\lim_{h\to 0}\space \frac{ \frac{2\sin((h+1)^3)}{h+1}-2\sin(1)}h$$ and I know about $\lim_{x\to 0}\frac {\sin(x)}x = 1$, so: $$=\lim_{h\to 0}\space \frac{ \frac{2\sin((h+1)^3) \cdot (h+1)^2}{(h+1)^3}-2\sin(1)}h$$
and then: $$=\lim_{h\to 0}\space \frac{ 2(h+1)^2-2\sin(1)}h$$ and now I don't know how to get rid of the $h$ denominator",['derivatives']
2570334,Biggest Circle you can fit in a Hypercube,"In a unit square the biggest circle is of diameter 1. In a unit cube I have reasoned that the biggest circle is $\sqrt{\frac{6}{5}}$ (EDIT: (Full solution: $r = \sqrt{\frac{n}{8}}$) This reasoning is wrong; there are larger circles, only read this section if you enjoy seeing me work out the radius of a specific non-maximal class of circles in hypercubes. See below for my working after seeing people's answers.) In higher dimensions, I only speculate that the biggest circle has diameter $\sqrt{\frac{2n}{n+2}}$ My reasoning is as follows: To find the plane on which the biggest circle would lie, it seems reasonable to pick the farthest two corners $(0,0,0), (1,1,1)$, and then pick the midpoint of the vertical edges $(1, 0, \frac{1}{2}), (0, 1, \frac{1}{2})$. This gives a rhombus with diagonals $\sqrt{3}$ and $\sqrt{2}$ (the diagonals of the cube and the square at height $\frac{1}{2}$, respectively), and side lengths all $\sqrt{1^2 + \frac{1}{2}^2} = \frac{\sqrt{5}}{2}$ Now, $(1, 0, \frac{1}{2}).(0, 1, \frac{1}{2}) = \frac{1}{4}$ so the cosine of the acute angle of the rhombus is $\frac{1}{4}/(\frac{\sqrt{5}}{2})^2 = \frac{1}{5}$, so the acute angle is $\cos^{-1}\left(\frac{1}{5}\right)$. The smallest distance between opposite sides (the height) of this rhombus is: $$\begin{aligned}
\frac{\sqrt{5}}{2}\cos\left(\frac{\pi}{2} - \cos^{-1}\left(\frac{1}{5}\right)\right) &= \frac{\sqrt{5}}{2}\left[\sin\left(\cos^{-1}(\frac{1}{5})\right)\right]\\
&=\frac{\sqrt{5}}{2}\sqrt{1 -\frac{1}{5^2}} \\
&=\sqrt{\frac{6}{5}}\end{aligned} $$ The circle centred at the centre of the rhombus has at most this diameter, since it will then meet the rhombus tangentially. My reasoning is not rigorous, but here's how it extends to higher dimensions: I presume the plane the circle lies on would include (wlog.) the diagonal of length $2$, $(0,0,0,0),(1,1,1,1)$ I also guess that the vectors $(1,0,\frac{1}{2},\frac{1}{2}),(0,1,\frac{1}{2},\frac{1}{2})$ define the plane. These have length $\frac{\sqrt{6}}{2}$, dot product $\frac{2}{4}$ and hence angle $\cos^{-1}(\frac{2}{6})$. The height would then be: $$\begin{aligned}
\frac{\sqrt{6}}{2}\left[\sin\left(\cos^{-1}\left(\frac{2}{6}\right)\right)\right]
&=\frac{\sqrt{6}}{2}\sqrt{1 - (\frac{2}{6})^2}\\
&=\sqrt{\frac{8}{6}}\end{aligned}$$ And if this guess of a plane holds in dimension n:
$$\begin{aligned}
\left(1,0,\frac{1}{2},\frac{1}{2},\frac{1}{2},...\right)\cdot\left(0,1,\frac{1}{2},\frac{1}{2},\frac{1}{2},...\right) &= \frac{n-2}{4}\\
&= \left|\left(1,0,\frac{1}{2},\frac{1}{2},\frac{1}{2},...\right)\right|\\
&= \sqrt{\frac{n+2}{4}}\end{aligned}$$ gives angle $\cos^{-1}(\frac{n-2}{n+2})$ and height $\sqrt{\frac{n+2}{4}} \sqrt{1 - \frac{(n-2)^2}{(n+2)^2}}$ $= \sqrt{\frac{2n}{n+2}}$ So, on the assumption that this is a plane holding a circle of maximal diameter, the diameter would be $= \sqrt{\frac{2n}{n+2}}$, radius $= \sqrt{\frac{n}{4n+4}}$ so I could never fit a circle radius $\frac{1}{\sqrt{2}}$ in any hyper-cube. I'm asking for either justification or correction of this method. Is it right to assume that the plane cuts out a rhombus in higher dimensions? End of original question As was pointed out by Mark Bennet, a maximal circle in a cube $[-1,1]^3$ lies in the plane through the origin normal to $(1,1,1)$ and has radius $\frac{\sqrt{6}}{2}$ Here, I try to generalise Mark Bennet's example: (Please read with a critical eye) This plane intersects the cube at the six points whose coordinates have one $1$, one $-1$ and one $0$. These are the furthest points the plane reaches in the cube. The shortest lines between these points lie on the surface of the cube and can be expressed, symmetrically in the 3 coordinates, as $\pm(-1,t,1-t)$ with $ t \in [0,1]$ these lines make a hexagon with minimal distance $\sqrt{1+\frac{1}{2}^2 +\frac{1}{2}^2} = \frac{\sqrt{6}}{2}$ I've done this methodically so that I can generalise to higher dimensions. In higher dimension n there are two cases: n even: In this case, the hyperplane through the origin normal to $(1,1,..)$ reaches all corners of the hypercube that have $\frac{n}{2} 1$'s and $\frac{n}{2} -1$'s. Now we must pick a basis for the plane in this hyperplane that contains the largest circle. We can recover the circles given by @celtschk by using the basis vectors:
$$\underbrace{(1,-1,1,-1\ldots,1,-1)}_{n}$$, and $$
\underbrace{(1,-1,1,-1\ldots}_{\frac{n}{2}} \underbrace{\ldots,-1,1,-1,1)}_{\frac{n}{2}}$$ That is, switching sign half way through so that they add to cancel the second half and subtract to cancel the first. Then the circle is given by: $$\{(\underbrace{\cos\phi,-\cos\phi,\ldots}_{\frac{n}{2}},
\underbrace{\sin\phi,-\sin\phi,,\ldots}_{\frac{n}{2}})|0\le\phi\le 2\pi\}$$ (since $(\underbrace{1,-1,\ldots}_{\frac{n}{2}}0,0,\ldots)$ and 
$(0,0,\ldots\underbrace{-1,1,\ldots}_{\frac{n}{2}})$ are orthogonal, and $\phi = 0$ gives us their scaling.(largest scaling that fits in the cube)) which has radius $\sqrt{\frac{n}{2}}$ But can we pick a basis that gives a bigger circle? n odd:",['geometry']
2570359,"If $(f ∘ f)$ is differentiable, is $f$ also differentiable?","Question: If $(f \circ f)$ is differentiable on $\mathbb R$, then $f$ is differentiable on $\mathbb R$. Is this statement true or false and why? I have had a look at this question and really can't get my head around it. I have thought that it is False, because if we let $f(x) = 2$, $(f\circ f)$ can't be defined as $(f(f(2))$ doesn't exist.  So the statement would be false as we can't define $(f\circ f)$ so it can't be differentiable on $\mathbb R$. Is this way of looking at it right or not?","['derivatives', 'function-and-relation-composition', 'calculus', 'functions']"
2570365,"If $f(x)+g(x)$ is strictly concave, then is $x+(g \circ f^{-1})(x)$ also strictly concave?","Suppose I have continuous, single variable functions $f$ and $g$ : $\mathbb{R\rightarrow}\mathbb{R}$ (both are twice continuously differentiable). Define $H$ as follows $$H(x)=f(x)+g(x)$$ I know that $H(x)$ is strictly concave. Now suppose that $f$ is invertible and its inverse $f^{-1}$ is twice cont. differentiable everywhere. Define a new $\hat{H}$ as follows $$\hat{H}(x)=x+(g \circ f^{-1})(x)$$ Is $\hat{H}$ concave in $x$? Since both $g$ and $f^{-1}$ are twice continuously differentiable, so too then is $(g \circ f^{-1})(x)$. Hence we may inspect the sign of $\hat{H}''$. $\hat{H}''$ is  given by $$\hat{H}''=\frac{g'' \circ f^{-1}}{f'(f^{-1}(x))}-\bigg(\frac{(g' \circ f^{-1})(f''(x))}{\big(f'(f^{-1}(x))\big)^3}\bigg)$$ which is concave if $$\frac{g'' \circ f^{-1}}{g' \circ f^{-1}}<\frac{f''(x)}{\big[f'(f^{-1}(x))\big]^2}$$ Is there some insight that would simplify the checking of the sign, or is the answer only accessible through laborious computing?","['functional-analysis', 'real-analysis', 'functions', 'derivatives']"
2570384,Finding the general equation of a cross section of a roof and the position of each joist that makes up its surface,"Doing some revision and came across this question. Would rather step along my thought process first rather than just type down the questions at the start if that's okay. A roof is given by the function $z = f(x, y) = \frac{5}{2} + \frac{1}{200}
(9x^2-4y^2)$ and is on the domain $[-6, 6] × [-6, 6]$ Nine
timber joists will be cut, and positioned such that they lie on cross sections of the
surface. Shadecloth will be laid on top of the joists to produce a curved roof effect. So I can see we have a hyperbola here and can understand where the 9 joists would be positioned. Here is what I think this function is looking like, I can see where each joint would go in this picture: Our vertical plane for cross sections is going to take the form $ax+by=c$ I think and taking x or y as constants give the cross sections. $z = f(x, y) = \frac{5}{2} + \frac{1}{200}
(9x^2-4c^2)$ and $z = f(x, y) = \frac{5}{2} + \frac{1}{200}
(9c^2-4y^2)$ These are parabolas so I don't really know what to do with these, seems kind of useless with the problem. I'm first asked this by the book Which values of $a, b, c$ can be chosen in my general equation such that the cross sections of our original equation are straight lines in three-dimenstional space? Okay, I'd think I'd have to determine the positions of the joists to answer this. That's why I'm scratching my head. I'll continue here with more info. Each joist $J_{k}$, $k = 1, ..., 9$ is to have one end attached to the
position $P_{k}$ and the other end attached to the position $Q_{k}$ in three-dimensional space. $P_{k}$ is specified in the question. Determine the other endpoints $Q_{k}$, such that each joist $J_{k}$ lies on the surface $f(x, y)$ and the $x$ and $y$ coordinates of each $Q_{k}$ lie on the boundary of the domain $[−6, 6] × [−6, 6].$ I'm not going to list all 9 points because I'd eventually like to solve this myself but I'll give 4 $P_{k}$ as an example here. $P_{1} = (-6, 3, f(-6, 3))$ $P_{3} = (-6, -3, f(-6, -3))$ $P_{5} = (-4, -6, f(-4, -6))$ $P_{7} = (0, -6, f(0, -6))$ So once I find the general equation. Which I'll probably do through some sort of simultaneous method maybe? Then I have to find the point on a plane from a vector at each $P_{k}$ 9 different times? I think that's how I go about solving it but it seems so inefficient and I'm also not sure. Any help appreciated, I'll keep working with mucking with the general equation to find a b and c values in the meantime.","['multivariable-calculus', 'linear-algebra', 'calculus']"
2570411,"Calculate expected value of random variable $Z=\min\left\{X,Y\right\}$ [duplicate]","This question already has answers here : Calculate probability $P(\min\left\{X,Y\right\} \leq x)$ and $P(\max\left\{X,Y\right\} \leq x)$ (2 answers) Closed 6 years ago . Hi math people in my last question I  asked the question $X,Y$ are independent, identical distributed with $$P(X=k) =
P(Y=k)=\frac{1}{2^k} \,\,\,\,\,\,\,\,\,\,\,\, (k=1,2,...,n,...)$$ Calculate the probabilities $P(\min\left\{X,Y\right\} \leq x)$ I calculate it correct, here is calculation: $$\begin{split}F_M(x) &= P(\min\left\{X,Y\right\} \leq x) \\ &= 1-P(x<\min\left\{X,Y\right\} ) \\ &= 1-P(x<X, x<Y) \\ & = 1-P(X>x)\,P(Y>x)\\ & = 1-(1-P(X \leq x))\,(1-P(Y \leq x))\\ & = 1-(1-F_X(x))\,(1-F_Y(x))\end{split}$$ But now how calculate expected value of random variable $Z=\min\left\{X,Y\right\}$ So we have $Z = 1-(1-F_X(x))\,(1-F_Y(x))$ Then $$E(Z) = \int_{0}^{\infty}\left(1-(1-F_X(x))\,(1-F_Y(x))\right) \,\,dx$$ Is it good like this?","['probability-theory', 'probability-distributions', 'probability', 'discrete-mathematics']"
2570419,Ways to find the orthogonal projection matrix,"I'm a bit lost trying to find the projection matrix for an orthogonal projection onto a plane defined by the normal vector $n = (1, 1, 1)^T$. Then I can find the basis C of the plain $C = ( (-1,0,1)^T (0,-1,1)^T)$. Now i should be able to find the projection Matrix with $A(A^TA)^{-1}A^T$
Where $A:=\begin{bmatrix} 
-1 & 0\\
0 & -1\\
1 & 1\end{bmatrix}$. Then my the projection matrix will look like this?
$A:=\begin{bmatrix}
2/3 & -1/3 & -1/3\\
-1/3 & 2/3 & -1/3\\
-1/3 & -1/3 & 2/3\end{bmatrix}$ Is this correct? To which basis is this projection matrix? How can I change the matrix to a different basis? There should be another way to find the matrix. Something like add to my basis $C$ a vector from my basis $B$ (which should not be the standard basis) in $\mathbb{R^3}$, find the projection of the basis ( I only need to do this for the added basis vector from $B$ since the rest is already on the plane). But how can I find the projection of the added basis vector? After that what would be the matrix from basis B to B? The coefficients of the linear combinations $c_1,c_2,P(b_i)$ in B?","['projection-matrices', 'linear-algebra']"
2570427,"Laplace method for $\int_0^1 e^{a(x-1)}\ln(-\ln(x)) \, dx$","The following integral $$ \int_0^1 e^{a(x-1)}\ln(-\ln(x)) \, dx$$ looks like the one for which the Laplace method is applicable. The function under the integral looks like this: ( $a$ increases from red to black), so the leading contribution to the integral should be at the points 1 and 0. I can split this into two integrals from functions having maximum at 0, however direct application of the Laplace method is problematic since the maxima are infinite. Can it be fixed with some variable change, or do I need something beyond the Laplace method (steepest descents or anything else)?","['integration', 'asymptotics', 'laplace-method']"
2570437,$\int \frac{du}{u-2}=-\int dx $ where's my stupid mistake?,"I'm struggling with this very simple ode since it gives me 2 different solutions depending on where I put the minus. from 
$$\int \frac{du}{u-2}=-\int dx $$
follows
$$ln|u-2|=-x +ln|C|$$ which yields
$$u=2+Ce^{-x}$$ Now if I rewerite the 1st equation to $$\int \frac{du}{2-u}=\int dx$$
then
$$ln|2-u|=x+ln|C|$$
which gives
$$u=2-Ce^x$$ I know, there's probably a pretty stupid mistake, but I just can't see it.
any hints?",['ordinary-differential-equations']
2570439,Showing a counterexample of $\cap\left(\cup A_{ij}\right)\subset \cup\left(\cap A_{ij}\right)$,"Prove, or disprove with a counterexample, the equality:
  $$
\bigcup^{\infty}_{j = 1}\left(\bigcap^{\infty}_{i = 1}A_{ij}\right) =\bigcap^{\infty}_{i = 1}\left(\bigcup^{\infty}_{j = 1}A_{ij}\right)
$$ Let's call the left set $A$ and $B$ the right one. I gave a proof for $A\subset B$ and (if it's correct) it sugests that $B\subset A$ is not always valid. It's as follows: Let $x\in A$, then there exists $j$ such that $x\in\cap_{i=1}^{\infty} A_{ij}$ $\Rightarrow$ $\exists j\in \mathbb{N}:\forall i\in\mathbb{N}, x\in A_{ij} \Longrightarrow \forall i\in\mathbb{N},\exists j\in\mathbb{N}: x\in A_{ij} \Rightarrow \forall i\in\mathbb{N}, x\in \cup_{j=1}^{\infty}A_{ij} \Rightarrow x\in B$ I think the crucial step to why we don't always have $B\subset A$ is the implication marked above with a longer arrow. However I'm stuck in trying to get a counterexample. Any help would be appreciated.",['elementary-set-theory']
2570485,"Closed form solution for $\int_0^{\infty } \frac{\sin ({n}/{x})}{e^{2 \pi x}-1} \, dx$","Is there a closed form solution for the following  integral $$\int_0^{\infty } \frac{\sin \left(\frac{n}{x}\right)}{e^{2 \pi  x}-1} \, dx$$ for $n>0$","['calculus', 'closed-form', 'complex-analysis', 'improper-integrals', 'integration']"
2570535,Stability of nonlinear 2nd order ODE,"Determine the stability for the point critical point $(0,0)$ to a solution $u(t)$ to the equation $$u''+u^5=0$$ Apparently, this cannot be determined using linearization. What other options do I have?",['ordinary-differential-equations']
2570573,Distribution of infinite sum of Bernoulli,"Let $(X_n)$ be a sequence of independent Bernoulli random variables of parameter $1/2.$
Let $Y_n=\sum_{k=1}^n\frac{X_k}{2^k}.$ We have $Y_n\overset{n\to\infty}\to\sum_{k=1}^{+\infty}\frac{X_k}{2^k},$ I would like to compute the distribution and to prove that $\vert F_n(x)-x\vert\le 1/2^n$ for all $x\in [0,1].$ We have $P_{Y_n}=\sum_{x\in Y_n(\Omega)}P(Y_n=x)\delta_x.$ If I am not mistaken we have $Y_n(\Omega):=\{\frac{k}{2^n}: k=0,1,\ldots,2^{n-1}\}.$ Now I just have to compute $P(Y_n=\frac{k}{2^n});$ if I write $Y_n=0.X_1X_2\ldots X_n$ I imagine we have $P(Y_n=\frac{k}{2^n})=P(X_1=a_1)P(X_2=a_2)\cdots P(X_n=a_n)=\frac{1}{2^n}.$ Therefore, $$P_{Y_n}=\frac{1}{2^n}\sum_{k=1}^{2^n-1}\delta_{k/2^n}.$$ I have no idea to prove that $\vert F_n(x)-x\vert\le 1/2^n,$ I tried wrting $x=\sum_k a_k/2^k$ but... Question: How can I prove formally that $$P(Y_n=\frac{k}{2^n})=\frac{1}{2^n}\; \mbox{and}\; \vert F_n(x)-x\vert\le 1/2^n ?$$","['probability-theory', 'probability', 'probability-distributions']"
2570581,Example of a symmetric BBID that is not isomorphic to its dual,"Let $(v, k, \lambda)$ be a design $\mathcal{D}$. We say it's symmetric if $b=v$ where $b$ is the number of blocks in $\mathcal{D}$. A design also can be realized also by constructing the incidence matrix of dimensions $b \times v$. I am puzzled by the claim that follows corollary 2.4 in "" Combinatorial designs. Constructions and analysis"", Douglas Stinson . Corollary 2.4. Suppose M is the incidence matrix of a symmetric (v, k, λ)-BIBD.
  Then $M^T$ is also the incidence matrix of a (symmetric) (v, k, λ)-BIBD Corollary 2.4 says that the dual of a symmetric BIBD is again a symmetric BIBD. We note that these two BIBDs need not be identical or even isomorphic I found examples of $M \not = M^T$ but I could not find any example where $M \not \cong M^T$. What I've tried: Search for small examples of symmetric design Construct the incidence matrix and its transpose Create a graph in which there is an edge between $(i,j)$ iff the element $i$ belongs to the block $j$ for $M$ and $M^T$ (Let's call them $G, G_T$ Check if $G \cong G_T$ using sage Based on the experimental results I'm inclined to believe $M \cong M^T$ but could not prove that as well. Another update: Morgan Rodgers suggested checking projective planes of order 9. Since taking transpose turns every point into a line and every line into a point. According to Wikipedia there are non-daul projective planes i.e. turning every line into a point and vice versa does not result in an isomorphic projective plane. According to wikipedia Hugh's planes , so the dual construction is not isomorphic to the original one. One also, can use sagemath to construct such example using the command sage.combinat.designs.block_design.HughesPlane(q2, check=True) See here","['combinatorial-designs', 'combinatorics', 'graph-isomorphism', 'discrete-mathematics']"
2570596,Does this uniquely define a conditional expectation?,"I know how we define conditional expectations in  probability theory without measure theory (i.e. with density functions on R). My question is about defining it on general probability spaces using measure theory. Assume a probability space $(\Omega, \sigma, P)$
If we want to define a conditional expectation $E(X|G)$ where G is a subset of Omega (i.e. Y is in sigma), then there is no problem whatsoever. But What if instead we want to find $E(X|Y=y)$ where y is a single value of the random variable Y, so that it will have measure zero? then we cant calculate the conditional expectation the standard way. So I came up with the following formula: $$\lim_{\epsilon\to 0}\int x dP(x|Y_\epsilon)$$ where $Y_\epsilon=\{\omega : |Y(\omega)-y|<\epsilon\}$. Does this correctly and uniquely define the conditional expectation of X given a measure zero realization of Y?","['probability-limit-theorems', 'probability-theory', 'probability', 'measure-theory']"
2570605,Riemann manifolds and Levi-Civita connection,"Let $(M, \langle.,.\rangle )$ be a 2-dimensional Riemannian manifold, $\nabla$ its Levi-Civita connection. How can I show that there is a function $K \in \mathscr C^{\infty}(M)$ such that $$R^{\nabla}(X,Y)Z=K(\langle Y,Z\rangle X-\langle X,Z \rangle Y) $$ for all $X,Y,Z \in \Gamma (TM)$? Would appreciate some help or approach to solve this, thanks in advance.","['manifolds', 'riemannian-geometry', 'differential-geometry']"
2570639,Cauchy's Integral Formula and Delta Functions,"As we know from complex analysis, Cauchy's integral formula states: $f(z_o)=\frac{1}{2\pi i}\int_\gamma{\frac{f(z)}{z-z_o}dz}$ for a closed contour $\gamma$. However there is also the result from other areas of maths that states: $f(x_o)=\int_R{f(x)\delta(x-x_o)dx}$ for some region $R$ Given the similarity in the results, is there any significance in comparing $\delta(x-x_o)$ to $\frac{1}{2 \pi i (x-x_o)}$ since basically integrating a function over them always gives the function's value at $x_o$ (Apologies in advance if this question may seem silly but I haven't found any satisfactory answers in my search so I thought I'd ask)","['cauchy-integral-formula', 'complex-analysis', 'dirac-delta', 'contour-integration']"
2570656,How to prove that $\sqrt{2+\sqrt3}-\sqrt{2-\sqrt3}=\sqrt2$ without squaring both sides,"I have been asked to prove: $$\sqrt{2+\sqrt3}-\sqrt{2-\sqrt3}=\sqrt2$$ Which I can easily do by converting the LHS to index form, then squaring it and simplifying it down to get 2, which is equal to the RHS squared, hence proved. However I know you can't square a side during proof because it generates an extraneous solution. So: how do you go about this proof without squaring both sides? Or can my method be made valid if I do this: $$\sqrt{2+\sqrt3}-\sqrt{2-\sqrt3}=\sqrt2$$ $$...=...$$ $$2=2$$ $$\lvert\sqrt2\rvert=\lvert\sqrt2\rvert$$ $$\sqrt2=\sqrt2\text{ hence proved.}$$ Cheers in advance :)","['radicals', 'proof-verification', 'algebra-precalculus', 'proof-writing', 'proof-explanation']"
2570658,Cardinal Arithmetic - Right or Wrong?,"${\,}| {\Bbb{R}} {\rightarrow} {\Bbb{N}} {\,}| = {\,}| {\Bbb{N}}^{\Bbb{R}} {\,}| = \aleph_0^{\aleph} = \aleph_0{^2}^{\aleph_0}$ ${\,} | {\Bbb{R}} {\times} ({\Bbb{R}} \rightarrow \{0,1\}) {\,}| = |{\Bbb{R}}| \cdot|{\Bbb{R}}\rightarrow\{0,1\}| = \aleph \cdot 2^{\aleph} = 2^{\aleph_0} \cdot 2^{\aleph} = 2^{\aleph_0 + \aleph} = 2^{\aleph}$ $\aleph_0^{\aleph_0} = \aleph \, \,$ ? Any more ways to simplify the expressions ? are they right ? Any references for more complex cardinal arithmetic ? Thank you.","['cardinals', 'discrete-mathematics']"
2570732,How irregular can $f'$ be beyond Darboux's Theorem?,"By Darboux's theorem if $f:D\to\mathbb R$ is differentiable then $f'$ satisfies the intermediate value property $-$ even if it is discontinuous. In particular I am interested in the following: Assume $f'(a)<f'(b)$ for some $a<b$. We know that then $f'$ assumes every value in the interval $I=[f'(a),f'(b)]$ within $[a,b]$. Does this imply that $(f')^{-1}\big(I\big)$ has postive measure? Intuitively it seems like it must be true; but how to prove it? This question is related to a comment I made on this thread . Note that if $g:D\to\mathbb R$ has the intermediate value property, but is not the derivative of a differentiable function, then it can be quite volatile $-$ see for instance Conways base 13 function . Here, the pre-image of $I$ could only be described as a mess. Some related stuff: https://math.stackexchange.com/a/292380/99220 Volterra's function as an example of a very badly behaved derivative (set of discontinuities of $V'$ has positive measure). Cantors function (or rather its integral) is not a counter-example since the intersection of the complement of the cantor set with any (open) interval contains an (open) interval.","['derivatives', 'real-analysis', 'lebesgue-measure']"
2570773,bijective function over $\mathbb{N}$ that isn't $f(X) = (X)$ [duplicate],"This question already has answers here : Is there a bijective function mapping Natural numbers to Natural numbers, other than $f(n) = n$? (2 answers) Closed 6 years ago . I'm struggling to come up with a good example for a bijective function over $\Bbb N$. I've come up with: $f(n) =\begin{cases}   
       1,& n=0\\  
       0, &n=1  \\
       n, &\text{otherwise}\\ \end{cases} $ Firstly, can you confirm this is acceptable, and secondly, does anyone have any other examples? (Perhaps a more beautiful one!)","['elementary-set-theory', 'functions']"
2570782,Find floor of sum $\sum_{k=1}^{80} k^{-1/2}$,"We have to find the floor $\lfloor S \rfloor$ of the following sum: $$S = \sum_{k=1}^{80}\frac{1}{\sqrt k}$$ What I  did was to find a approximate series that this series is near to. Let that series have general term $T_k$ and original series may have general term $a_k$. We construct the following series of $T_k$ $$T_k = \frac{1}{ \sqrt{k+1}+\sqrt{k}} = \sqrt{k+1}-\sqrt{k}\\$$ Then we have the following inequality: $$\frac{a_k}{2} = \frac{1}{\sqrt{k}+\sqrt{k}} > T_k \\
\sum a_k > 2 \sum_{1}^{80} T_k \\
S > 2 (\sqrt{81}-1)$$ Where the last result is due to telescoping property of $T_k$. So we have a lower limit $ S_k >\color{indigo}{ 16}$ However still we cannot say $\lfloor S \rfloor = 16$ because $S$ may exceed $17$.","['algebra-precalculus', 'summation', 'sequences-and-series']"
2570804,Prove that $\mathcal{P}(\mathbb{N})\setminus\{\emptyset\}$ has a choice function.,"Prove that $\mathcal{P}(\mathbb{N})\setminus\{\emptyset\}$ has a
  choice function. (Remark: you are not allowed to use the Axiom of Choice in this part of the question) Pf :  We can define the choice function $f$ for $\mathcal{P}(\mathbb{N})\setminus\{\emptyset\}$ by $f(S)=\text{the least element of $S$}.$ According to Wikipedia , A choice function (selector, selection) is a mathematical function f
  that is defined on some collection X of nonempty sets and assigns to
  each set S in that collection some element f(S) of S. In other words,
  f is a choice function for X if and only if it belongs to the direct
  product of X. Can someone explain the intuition behind this proof? Thank you.","['axiom-of-choice', 'elementary-set-theory', 'proof-explanation']"
2570824,Second digit of square numbers in binary yields $\sqrt2$,"Why do ratios of terms in sequences based on $2$ nd binary digit of $2$ nd power, converge to $\sqrt2$? Update: Added at the bottom of the post a generalization for all other bases,powers, and digits. Start with $k=1$, generate the sequences $a_d(n)$ by: increase $k$ by $1$, look at the binary representation of $k^2$, take the second digit keep repeating step one  until the taken digit is $\ne$ compared to the previously taken digit then the number of digits you took is the new element in the sequence $a_d$, where $d$ is the value of the digit that was being taken
  (either $a_0$ or $a_1$) repeat the process for next term, but with the new digit, continuing with the $k$ you left with The ratio of two consecutive terms in both sequences $a_0,a_1$ seems
  to converge to $\sqrt2$. Why is this the case? Can we show it truly converges to $\sqrt2$ ? How can we express this algorithm/sequences in mathematical expressions? In other words , $a_0$ is the number of consecutive $0$'s appearing as the second digit in binary representations of squares of natural numbers, and $a_1$ is the same thing for $1$'s. The computed terms are below: ( python code on repl.it) a_1 = 1, 1, 2, 2, 3, 4, 6, 8, 12, 17, 25, 34, 49, 68, 97, 137, 194, 274, 388, 548, 776, 1097, 1552, 2195, 3104, 4390, 6208, 8780, 12417, 17560, 24834, 35120, 49668, 70241, 99336, 140482, 198672, 280965, 397344, 561930, 794689, 1123860, 1589379, 2247720, 3178757, 4495441, 6357514, 8990882, 12715028, 17981765, 25430057, 35963531, 50860114, 71927063,...
a_0 = 3, 1, 2, 2, 4, 5, 8, 10, 15, 20, 29, 40, 58, 81, 116, 162, 231, 325, 461, 651, 921, 1302, 1842, 2603, 3683, 5207, 7365, 10415, 14729, 20830, 29458, 41660, 58916, 83319, 117832, 166638, 235663, 333276, 471325, 666553, 942649, 1333106, 1885297, 2666212, 3770594, 5332424, 7541187, 10664849, 15082374, 21329697, 30164747, 42659393, 60329493, 85318786,... Last computed terms from above: $$ \frac{a_1(54)}{a_1(53)}=\frac{71927063}{50860114}=1.414213562321\dots\approx\sqrt2=1.414213562373\dots$$ $$ \frac{a_0(54)}{a_0(53)}=\frac{85318786}{60329493}=1.414213542288\dots\approx\sqrt2=1.414213562373\dots$$ The first one seems to converge a bit faster. ($10$ decimal places vs $7$ decimal places for $n=54$) How good are these fraction approximations? Is there a closed form for these sequences? Trying to find a recurrence relation: One thing I've noticed in the successive ratios of the terms is that if we denote one as $\frac{a}{b}$, then the next one would always be $\frac{2b}{a}+c_n$, where $c_n$ is $\frac{-1}{a},\frac{1}{a}$ or $0$. For $a_1$ I've observed values for $c_n$ in ratios in order: $c_n=$ 0,0,-,0,0,0,0,+,+,0,-,0,+,+,0,0,0,0,0,0,+,+,0,0,0,0,+,0,0,0,0,+,0,0,... You can see the ratios between successive terms in $a_1$ below: Where the left side is the ratio of $a_1(n)/a_1({n-1})$, and the right side are operations to reach the next term in the sequence, where c=1/a , if we represent the ratios as a/b ; 1,       ^-1,*2
2/1,     ^-1,*2
2/2,     ^-1,*2-c
3/2,     ^-1,*2
4/3,     ^-1,*2
6/4,     ^-1,*2
8/6,     ^-1,*2
12/8,    ^-1,*2+c
17/12,   ^-1,*2+c
25/17,   ^-1,*2
34/25,   ^-1,*2-c
49/34,   ^-1,*2
68/49,   ^-1,*2+c
97/68,   ^-1,*2+c
137/97,  ^-1,*2
194/137, ^-1,*2
274/194, ^-1,*2
388/274, ^-1,*2
548/388, ^-1,*2
776/548, ^-1,*2
1097/776, ^-1,*2+c
1552/1097, ^-1,*2+c
2195/1552, ^-1,*2
3104/2195, ^-1,*2
4390/3104, ^-1,*2
6208/4390, ^-1,*2
8780/6208, ^-1,*2+c
12417/8780, ^-1,*2
17560/12417, ^-1,*2
24834/17560, ^-1,*2
35120/24834, ^-1,*2
49668/35120, ^-1,*2+c
70241/49668, ^-1,*2
99336/70241, ^-1,*2
etc. If we can somehow find the pattern for which terms we add or subtract $c$, we could define the ratio sequences with reversal of the fractions, multiplying by $2$, and adding $c$. With the numerators/denominators of these ratio sequences, we could define $a_1$. A similar $c_n\in\{-c,0,c\}$ sequence exist for $a_0$. Generalization Consider the algorithm above that generates sequences $a_d$. Above, we were looking at the second digit, $D=2$. Lets consider any $D\ge2$ digit. Looking at powers $P\in\mathbb N$, lets observe the numbers $k^P$ Also, consider bases $b\ge2$ Generate $a_d$ as explained above, observing the $D$ digit in $k^P$ in
  base $b$: Then, the ratios of terms seem to converge for all sequences $d$ : $$ \frac{a_d(n)}{a_d(n-(b-1)\cdot b^{D-2})}=\sqrt[P]{b}$$ As $n\to\infty$, for all $d$ sequences, and all variables considered above. How can this observation be explained/proved ? Note that $P=1$ is trivial as the sequences are of form $a_d=b^m$, where $m$ changes periodically. For example, base $b=3$ sequences for $P=1$, when $D=2$ look like: a_0 = 1, 1, 3, 3, 9, 9, 27, 27, 81, 81, 243, 243, 729, 729, 2187, 2187, 6561, 6561,...
a_1 = 1, 1, 3, 3, 9, 9, 27, 27, 81, 81, 243, 243, 729, 729, 2187, 2187, 6561, 6561,...
a_2 = 1, 1, 3, 3, 9, 9, 27, 27, 81, 81, 243, 243, 729, 729, 2187, 2187, 6561, 6561,... Note that the period is $(b-1)\cdot b^{D-2}$, which is found in the term ratio above. How can we calculate sequences $a_d$ when $P\ge2$ for some $D\ge2$ in some $b\ge2$?","['square-numbers', 'binary', 'number-systems', 'sequences-and-series', 'elementary-number-theory']"
2570913,"$\mu,\nu$ ergodic implies $\mu\perp\nu$ [duplicate]","This question already has an answer here : Show $A \in \cal F$ exists, such that $\mathbb P(A)=1$ and $\mathbb Q(A)=0$. (1 answer) Closed 6 years ago . Let $T:\Omega\to\Omega$ a measurable function and $\mu,\nu$ $T$-ergodic measures on $\Omega$. I am trying to prove that $\mu\perp\nu$ (this is, they concentrate in disjoint sets). My attempt was define $w=\mu+\nu$ and use Radon-Nikodým to obtain $f,g\in L^1(\Omega)$ such that $\mu\sim fdw,\ \nu\sim gdw$. Then I only have to show that $w(\{f,g>0\})=0$, but I couldn't progress much. Note: for $\mu$ being ergodic I mean ""$\mu$ is $T$-invariant and, for every measurable $A$, $\mu(A\triangle T^{-1}A)=0$ implies $\mu(A)\in\{0,1\}$. Note2: I am not able to use the ergodic theorem.","['ergodic-theory', 'measure-theory']"
2571061,Defining integration on analytic subvarieties,"Let $X$ be a compact complex manifold, and let $V$ be an analytic subvariety. In books like Griffiths-Harris: Principles of algebraic geometry , they authors freely integrate differential forms on $V$, without caring about whether it is well-defined. For example, in page 140, it says ""Recall also that for any analytic subvariety $V$ of dimension $k$, we have defined the fundamental class $(V)\in H_{2k}(X,\mathbb{R})$ to be given by the linear functional $\varphi\mapsto\int_{V}\varphi$ on $H_{DR}^{2k}(X)$..."" 1) It's not clear to me how the integration is defined; as far as I know, integration can be defined on manifolds or chains, but I'm not sure how to define it on a closed subset, since pullback on a closed subset doesn't make sense (I guess, right?). Does one do it by covering the closed subset by charts, and then taking partition of unity subordinate to an open cover containing the charts? Or is there some other way of defining it? Can one define it in general for any closed bounded subset, or are analytic subvarieties special? 2) Also, at least for $\mathbb {R}^n$ by a theorem due to Lebesgue, a bounded continuous function on a bounded subset $A$ is integrable as long as boundary of $A$ has measure zero; but I'm not sure whether the same is true for an analytic subvariety. (Sorry for this vague question; here I'm just trying to find a connection between the theory on $\mathbb{R}^n$ and manifolds in general). Any help would be appreciated.","['complex-geometry', 'differential-geometry']"
2571120,"stein's complex analysis, functions of finite order.","An entire function $f$ is said to be of finite order if there exists $\rho > 0$ and constants $A, B>0$ such that 
    \begin{equation}\label{eq:growth order}
		\lvert f(z)\rvert \leq Ae^{B\lvert z\rvert^\rho} \qquad \forall z\in\mathbb{C}
	\end{equation}
    The growth order of $f$ is $\rho_f = \inf \rho$ where the infimum is taken over all $\rho > 0$ for which there exists constants $A, B$ such that the above equation holds. Let $n(r)$ denote the number of zeroes of a function $f$ in the disk of radius $r$ about the origin. Stein's theorem 2.1 states that if $f$ is entire and $\rho_f \leq \rho$, then there exists a constant $C>0$ such that $n(r) \leq Cr^\rho$ for all sufficiently large $r$. Here, $n(r)$ denotes the number of zeroes in a disk about the origin of radius $r$. PROOF.Suppose first that $f(0) \neq 0$ and note that since $n(r)$ is an increasing function, 
    $$
		n(r) = \frac{n(r)}{\log(2)}\int_r^{2r}\frac{1}{x}\,\mathrm{d}{x} \leq \frac{1}{\log(2)}\int_r^{2r}\frac{n(x)}{x}\,\mathrm{d}{x}
	$$
    By the previous lemma,
    $$
		\int_r^{2r}\frac{n(x)}{x}\,\mathrm{d}{x} \leq \frac{1}{2\pi}\int_0^{2\pi}\log\lvert f\left(2re^{it}\right)\rvert\,\mathrm{d}{t} - \lvert f(0)\rvert 
	$$
Then for all sufficiently large $r$;
$$
\int_0^{2\pi}\log\lvert f(2re^{it})\rvert dt\leq \int_0^{2\pi}\log\lvert A\exp\{B(2r)^\rho\} \rvert \,\mathrm{d}t \leq C r^\rho
$$
for some constant $C$. Why do we need $r$ to be large? I am wondering if the assumption can be removed.","['complex-analysis', 'inequality', 'analysis']"
2571132,"Wrong Wolfram Alpha result for $\lim_{(x,y)\to(0,0)}\frac{xy^4}{x^4+x^2+y^4}$?","I'm trying to solve this limit:
  $$
\lim_{(x,y)\to(0,0)}\frac{xy^4}{x^4+x^2+y^4}
$$ Here's my attempt: $$0 \le |\frac{xy^4}{x^4+x^2+y^4} - 0| = \frac{|x|y^4}{x^4+x^2+y^4},$$ and since $x^4+x^2 \ge0$ then $\frac{y^4}{x^4+x^2+y^4} \le 1$ so 
$$
\frac{|x|y^4}{x^4+x^2+y^4} \le |x|,$$ so 
$$
0 \le \lim_{(x,y)\to(0,0)}|\frac{xy^4}{x^4+x^2+y^4} - 0| \le \lim_{(x,y)\to(0,0)} |x| = 0,
$$ and using the squeeze theorem the limit is $0$. But if I input the limit in wolfram alpha, it says that the limit doesn't exist. Here is the link to the limit in Wolfram Alpha.","['multivariable-calculus', 'wolfram-alpha', 'limits']"
2571158,Is this continuity proof valid?,"$g:\mathbb{R}^2 \rightarrow \mathbb{R}$ differentiable and: $$g(x, 1) = 4$$ $$g(0, y) = 4$$ $$g(x, x + 1) = x^2 + 4.$$ $f:\mathbb{R}^2 \rightarrow \mathbb{R}$ such that: $$f(x, y) = \begin{cases} 
      \frac{g(x, y) - 4}{\sqrt{x^{2} + (y - 1)^{2}}} & (x, y) \neq (0, 1) \\
      0 & (x, y) = (0, 1)
   \end{cases}
$$ I have to prove $f$ is continuous. Now, I know that if $g$ is differentiable then it is continuous, then:
$$\lim_{(x,y)\to(0,1)} g(x, y) = g(0,1) = 4$$
So in $$\lim_{(x,y)\to(0,1)} \frac{g(x, y) - 4}{\sqrt{x^2 + (y - 1)^2}}$$
Is it valid to say that as I distribute the limit I get 0 because:
$$ \frac{0}{\lim_{(x,y)\to(0,1)} \sqrt{x^2 + (y - 1)^2}}$$ is $0$? Thanks in advance! PS: Sorry for my English.","['multivariable-calculus', 'continuity', 'limits']"
2571159,Lines that pass through a cube,I have to make a program in which I have a cube (centered at origin) and random lines that pass through the cube. I don't know what condition could be sufficient that assures me that the lines are going to pass through there.,"['3d', 'geometry']"
2571165,Arzela Ascoli counterexamples,"I am looking for some examples that show that the Arzela Ascoli theorem is ""tight"".
i.e. is there a sequence of functions that is uniformly bounded and equicontinuous on a noncompact set that would not have a uniformly convergent subsequence. Also is there an example of a uniformly bounded non-equicontinuous sequence on a compact set that does not have a convergent subsequence, and similarly by removing the uniformly bounded condition",['real-analysis']
2571171,Limit problem: $\lim_{t\to1} \frac {\sqrt {2t^2-1}\sqrt[3]{4t^3-3t}-1}{t^2-1}$,"Update: $$\lim_{t\to1} \frac {\sqrt {2t^2-1}\sqrt[3]{4t^3-3t}-1}{t^2-1}$$ First of all, I am grateful to you for all the answers you have given me. I want to ask MSE to confirm the correctness of the alternate solution and its mistake. I worked so hard for solve this limit without L'Hôpital. I tried to solve this limit myself. Because, I like it.
And I trust MSE. Because, MSE is always the real teacher for me.
Please, teach me., my mistakes. $$\begin{align}&\lim_{t \to 1}\frac {\sqrt{2t^2-1}×\sqrt[3]{4t^3-3t}-1}{t^2-1}\\\\&=\lim_{t \to 1} \frac {\sqrt[3]{4t^3-3t}-\frac{1}{\sqrt{2t^2-1}}}{\frac{t^2-1}{\sqrt{2t^2-1}}}\\\\&=\lim_{t \to 1}\frac{4t(t^2-1)+t-\frac{1}{(2t^2-1)×\sqrt{2t^2-1}}}{(t^2-1)×\left[ \frac{\sqrt[3]{(4t^3-3t)^2}}{\sqrt{2t^2-1}}+\frac{\sqrt[3]{4t^3-3t}}{2t^2-1}+\frac{1}{(2t^2-1)×\sqrt{2t^2-1}}\right]}\\\\&=\lim_{t \to 1}\frac{4t+\frac{t(2t^2-1)×\sqrt{2t^2-1}-1}{(2t^2-1)×\sqrt{2t^2-1}×(t^2-1)}}{\left[ \frac{\sqrt[3]{(4t^3-3t)^2}}{\sqrt{2t^2-1}}+\frac{\sqrt[3]{4t^3-3t}}{2t^2-1}+\frac{1}{(2t^2-1)×\sqrt{2t^2-1}}\right]}\\\\&=\lim_{t \to 1}\frac{4t}{\left[ \frac{\sqrt[3]{(4t^3-3t)^2}}{\sqrt{2t^2-1}}+\frac{\sqrt[3]{4t^3-3t}}{2t^2-1}+\frac{1}{(2t^2-1)×\sqrt{2t^2-1}}\right]
}\\\\&\qquad\qquad+\lim_{t \to 1}\frac{\frac{t(2t^2-1)×\sqrt{2t^2-1}-1}{(2t^2-1)×\sqrt{2t^2-1}×(t^2-1)}}{\left[ \frac{\sqrt[3]{(4t^3-3t)^2}}{\sqrt{2t^2-1}}+\frac{\sqrt[3]{4t^3-3t}}{2t^2-1}+\frac{1}{(2t^2-1)×\sqrt{2t^2-1}}\right]
}\\\\&= \frac{4}{3}+\frac{1}{3}\lim_{t \to 1}\frac{t(2t^2-2)×\sqrt{2t^2-1}+t×\sqrt{2t^2-1}-1}{(t^2-1)×(2t^2-1)×\sqrt{2t^2-1}}\\\\&=\frac{4}{3}+\frac 13\lim_{t \to 1}\frac{2t}{2t^2-1}+\frac 13\lim_{t \to 1}\frac{t×\sqrt{2t^2-1}-1}{(t^2-1)(2t^2-1)\sqrt{2t^2-1}}\\\\&=\frac{4}{3}+\frac 23+\frac 13\lim_{t \to 1}\frac{2t^4-t^2-1}{(t^2-1)(2t^2-1)\sqrt{2t^2-1}×(\sqrt{2t^4-t^2}+1)}\\\\&=2+\frac 13 \lim_{t \to 1}\frac{(t^2-1)(2t^2+1)}{(t^2-1)(2t^2-1)\sqrt{2t^2-1}×(\sqrt{2t^4-t^2}+1)}\\\\&=2+\frac 13 \lim_{t \to 1}\frac{(2t^2+1)}{(2t^2-1)\sqrt{2t^2-1}×(\sqrt{2t^4-t^2}+1)}\\\\&=2+\frac 13×\frac{3}{2}=2+\frac 12=\frac 52.\end{align}$$ I doubt that I have correctly applied the limit rules. Did I apply all the limit rules correctly  and is the solution correct..? Thank you!","['radicals', 'limits', 'proof-verification', 'calculus', 'limits-without-lhopital']"
2571191,"Proving $ \int_0^{+\infty} \frac{\sin(t)^{^{2n+1}}}{t} \, dt= \frac{\pi (2n)!}{2^{2n+1}(n!)^2} $ with elementary calculus?","Time ago I asked how to integrate this, but people answered me with advanced topics, so I have this doubt, is it possible to integrate this with elementary calculus? $$ \int_0^{+\infty} \frac{\sin(t)^{^{2n+1}}}{t} \, dt= \frac{\pi (2n)!}{2^{2n+1}(n!)^2} $$","['real-analysis', 'integration', 'definite-integrals', 'calculus']"
2571197,A problem on rank of a matrix over two fields,"This is a problem from Berkeley problems in mathematics. If $F$ is a subfield of $K$, and $M$ has entries in $F$, how is the row rank of $M$ over $F$ related to the row rank of $M$ over $K$? where $M$ is a n by n matrix The solution says ""If a set of rows of $M$ is linearly independent over $F$, then clearly it is also independent over K, so the rank of $M$ over $F$ is, at most, the rank of $M$ over $K$."" I have some trouble understanding this, what I thought was that if they are linearly independent over the bigger field K, they are linearly independent over F. (Because all linear combinations with scalars from F are subsumed when you are talking about linear combinations in K) However here it is the other way around","['matrices', 'linear-algebra']"
2571204,The unit ball in $L^{\infty}$ is not weakly sequentially compact.,"I would like to show that $\overline{B_1(0)} = \{x \in L^{\infty} : \|x \|_{L^{\infty}} \leq 1\}$ is NOT weakly sequentially compact (so that $L^{\infty}$ is NOT reflexive). Does this follow from the fact that $\overline{B_1(0)}$ is not strictly convex ? One way to prove this would be to explicitly construct a sequence $\{f_n\}$ in $\overline{B_1(o)}$ which has no weakly convergent subsequences, but I have not been able to think of anything.","['general-topology', 'real-analysis', 'functional-analysis', 'analysis']"
2571222,"What is wrong with my ""disproof"" of Cantor's Theorem?","I cannot figure out what is wrong: We will attempt to show that $\mathcal{P} (\mathbb{N})$ is countable. We use the following corollary from Rudin's Principles of Mathematical Analysis , p. 29: Suppose $A$ is at most countable, and, for every $\alpha\in A$ , $B_{\alpha}$ is at most countable. Put $$T=\bigcup_{\alpha \in A}B_{\alpha}$$ Then $T$ is at most countable. ""Proof"" 1: Let $A = \mathbb{N}$ and for every $\alpha \in A$ let $B_{\alpha}=\{S \in \mathcal{P} (\mathbb{N})| \text{the sum of the elements of } S \text{ is } \alpha \}$ . $A$ is countable and for every $\alpha \in A$ , $B_{\alpha}$ is finite. Therefore $$\bigcup_{\alpha \in A}B_{\alpha}$$ is countable. But $\displaystyle \bigcup_{\alpha \in A}B_{\alpha}=\mathcal{P} (\mathbb{N})$ , so $\mathcal{P} (\mathbb{N})$ is countable. ""Proof"" 2: Let $A= \mathbb{N}$ and for every $\alpha \in A$ let $B_{\alpha}=\{ S \in \mathcal{P} (\mathbb{N}): |S| = \alpha \}$ . I think that I can show by induction (if requested) that for each $\alpha \in A$ , $B_{\alpha}$ is countable. Thus $$\bigcup_{\alpha \in A}B_{\alpha}$$ is countable. But again, $\bigcup_{\alpha \in A}B_{\alpha} = \mathcal{P} (\mathbb{N})$","['fake-proofs', 'elementary-set-theory', 'proof-verification']"
2571260,Derivative of trace distance,"If we have two time-dependent density matrices $\rho(t)$ and $\sigma(t)$.
The trace distance is
$$
D(\rho(t),\sigma(t))=\frac{1}{2} \operatorname{Tr} \vert \rho(t)-\sigma(t) \vert.
$$
Does an explicit formula for
$$\frac{d D(\rho(t),\sigma(t))}{dt}$$
exist? Only the domain where $\rho \neq \sigma$ is asked for.","['derivatives', 'matrix-equations', 'matrices', 'matrix-calculus', 'linear-algebra']"
2571267,Is there any proof that there doesn't exist a circulant Hadamard matrix of size $8 \times 8$?,"Is there any proof that there doesn't exist an $8 \times 8$ circulant Hadamard matrix? A matrix $H \in \{\pm 1\}^{n \times n}$ is Hadamard if $H H^T = n I$, where $I$ is the $n \times n$ identity matrix. Then, a Hadamard matrix $H$ such that $h_{i,~j}=h_{(i+1)~mod~n,~(j+1)~mod~n}$ is a circulant Hadamard matrix. For example, let $\pi$ be a $4$-size matrix $[1, -1, -1, -1]$. Let $$A = \text{circulant}(\pi)=\left[\begin{array}{rrrr}1&-1&-1&-1\\-1&1&-1&-1\\-1&-1&1&-1\\-1&-1&-1&1\end{array}\right]$$ Since $$AA^T=4I=\text{circulant}(1,0,0,0)=\left[\begin{array}{rrrr}1&0&0&0\\0&1&0&0\\0&0&1&0\\0&0&0&1\end{array}\right]$$ where $A$ is the $4 \times 4$ Hadamard matrix. Now, my question is how to prove that there does not exist an $8 \times 8$ circulant Hadamard matrix. I can check all possible $8 \times 8$ circulant matrices using MATLAB. There are just $2^8$ possible cases; $\text{circulant}(\pm1, \pm1, \pm1, \pm1, \pm1, \pm1, \pm1, \pm1)$. However, I want to know mathematical proof not a proof via simulation.","['matrices', 'combinatorics', 'circulant-matrices', 'hadamard-matrices']"
2571338,Strange inequality about $e^{-x}$,"Consider $\displaystyle e^{-x}-\left(1-\frac{x}{n} \right)^{n}$ (x>0). Can we say that this difference less than $\displaystyle \frac{x^{2}e^{-x}}{n}$? 
I've tried to use Taylor formula and estimating $\displaystyle \frac{1}{m!} - \frac{1}{n^{m}}\binom{n}{m}$. But don't have any result. Any idea?","['real-analysis', 'sequences-and-series']"
2571401,How would I go about proving the following statement?,"For all $x \in \mathbb{N}$ and $y \in \mathbb{N}$, $$ Q= \frac{2^x-3^x}{3^x-2^{x+y}}$$ the only time Q is a natural number and odd is when $(x,y)=(1,1)$. I've been trying to solve this for a while as this equation came out of a simplified case of a problem I am working on but I don't know how to consider all the cases. I have plotted this in Matlab before and I know that when $x \gg y$ it produces very large negative numbers and when $y \gg x$ the limit goes toward zero. But, there is a ""line"" when $x$ is slightly greater than $y$ that causes the values become weird and sporadic. The last thing I know is that it is easy to see that the only time Q is positive is when $ y > x \log_2 (3/2)$. What methods and/or ideas would help prove this? Thanks in advance. Edit: I forgot to mention in the orignal post but I already know that the cases of $x=y$, $x \gg y$ and,$y \gg x$ back up this statement, I was asking about how I could go about proving the cases where x and y aren't drastically different, thus causing positive numbers close to natural numbers.","['number-theory', 'proof-writing', 'collatz-conjecture', 'proof-explanation']"
2571447,Understanding a notation chain rule for multivariable functions,"I can't understand the meaning of partial derivative times differential. I was reading wikipedia and poped to Total derivative article, Where I saw this: The total derivative of $ {\displaystyle f(t,x(t),y(t))}$ with respect to ${\displaystyle t}$ is $\frac{df}{dt} = \frac{\partial f}{\partial t}\frac{dt}{dt} + \frac{\partial f}{\partial x}\frac{dx}{dt} + \frac{\partial f}{\partial y}\frac{dy}{dt}$ which can be simplefied to: ${\displaystyle \operatorname {d} f={\frac {\partial f}{\partial t}}\operatorname {d} t+{\frac {\partial f}{\partial x}}\operatorname {d} x+{\frac {\partial f}{\partial y}}\operatorname {d} y}$ What does it mean to take a partial derivative ${\frac {\partial f}{\partial t}}$ (which is a new function by itself) and multiply it by a differential $\operatorname {d}t$. I'm in high school currently and I read what interests me. I don't have an comprehensive knowledge, therefore it might have been taught in topics which I have'nt learned. So any question will be welcomed :)","['multivariable-calculus', 'chain-rule', 'calculus']"
2571459,"Intuitive understanding of the formula $\frac{(m+n+p)!}{m!n!p!}$ for dividing $m+n+p$ things into three groups of sizes $m,n$ and $p$","The number of ways in which $m+n+p$ things can be divided into three unequal groups containing $m,n$ and $p$ things is $\dfrac{(m+n+p)!}{m!n!p!}$ I need help understanding this formula intuitively and its proof. Moreover, I don't get why this formula has no multiplication by $3!$ since there are $3!$ permutations of those 3 groups possible.","['permutations', 'combinatorics', 'intuition', 'combinations']"
2571619,Representing $\sin(xy)$ as a finite sum of functions of the form $f(x)g(y)$,"Call a function $h: \Bbb R^2 \to \Bbb R$ simple if there are functions $f,g: \Bbb R \to \Bbb R $ such that $h(x,y) = f(x)g(y)$. In fancy words, $h$ factors under the tensor product. Is the function $h(x,y) = \sin(xy)$ equal to a finite sum of simple functions? The Taylor expansion of $h$ gives an infinite sum of simple functions equal to $h$. Testing for simplicity can be done by diving by the partial derivatives and checking if the result is independent of one variable.","['calculus', 'functions']"
2571629,"Is $f(m,n)=2^m\cdot(2n+1)$ a bijection between $\Bbb{Z_{\geq0}\times Z\to Z}$?","Let $\mathbb Z$  denote the set of integers and $\mathbb Z_{\ge 0}$
  denote the set $\{0,1,2,3,...\}$. Consider the map $f:\mathbb Z_{\ge
 0}\times \mathbb Z \to \mathbb Z$ given by $f(m,n)=2^m\cdot(2n+1)$. Then
  the map $f$ is (A)injective but not surjective. (B)surjective but not injective. (C)injective and surjective. (D)neither injective nor surjective. For injectivity, $$2^{m_1-m_2}(2n_1+1)=(1)(2n_2+1)$$
$$2^{m_1-m_2}(2n_1+1)=2^0(2n_2+1)$$ 
$$m_1=m_2 \land n_1=n_2   $$ For surjectivity, $m=0$, $f$ maps to odd integers.Similarly, I am getting pre-image for even integers also. So, (C) is the correct answer. Am I correct? But, solution manual gives (A) as the correct one. Who is correct? Please help me.","['algebra-precalculus', 'functions', 'proof-verification']"
2571670,Evaluate $\int_0^\infty \frac {(\log x)^4dx}{(1+x)(1+x^2)}$,Evaluate $$\displaystyle\int_0^\infty \frac {(\log x)^4dx}{(1+x)(1+x^2)}$$ This is a past final term exam problem of a complex analysis course at my university. I am studying for this year’s exam and I found this problem. The examiner assumes us to use residue calculus. Could you please give your valuable suggestions on how to proceed ?,"['complex-analysis', 'improper-integrals']"
2571725,"Continuous linear operator, $T: (C[0,1],\|\cdot\|_p)\to (C[0,1],\|\cdot\|_p)$ continuous for some $p$","Observe $C[0,1]$ and for $1\leq p<\infty$ the norm $\|f\|_p=\left(\int_0^1 |f(t)|^p\, dt\right)^{1/p}$. Let $T: C[0,1]\to C[0,1]$ be an arbitrary linear operator. Show, that when it exists a $1\leq p<\infty$ such that $T: (C[0,1],\|\cdot\|_p)\to (C[0,1],\|\cdot\|_p)$ is continuous, then is $T: (C[0,1],\|\cdot\|_\infty)\to (C[0,1],\|\cdot\|_\infty)$ continuous. I do not really know how to start here.
Thanks in advance for any help.",['functional-analysis']
2571729,How to show that $\lim_{n\to \infty } \left(\frac{(1 + \frac{1}{n^2})^{n^2}}{e}\right)^n = 1$?,"I need to find the limit: 
$$\lim_{n\to \infty } \left(\frac{(1 + \frac{1}{n^2})^{n^2}}{e}\right)^n$$
So I know that the limit is $1$. Using Squeeze theorem
$$? \leq \left(\frac{(1 + \frac{1}{n^2})^{n^2}}{e}\right)^n \leq \left(\frac{e}{e}\right)^n \rightarrow\ 1 $$
What should be instead $?$ ? Is it possible to solve in another way? Unfortunately, I can't use L'Hôpital Rule or Series Expansion in this task.","['calculus', 'limits']"
2571817,How did Euler disprove Mersenne's conjecture?,"In 1644, Mersenne made the following conjecture: The Mersenne numbers, $M_n=2^n−1$, are prime for $n = 2, 3, 5, 7, 13, 17, 19, 31, 67, 127, 257$, and no others. Euler found that the Mersenne number $M_{61}$ is prime, refuting the conjecture. For context, $M_{61} = 2 305 843 009 213 693 951$. I imagine that this would be incredibly large for most 18th-century number theorists. Thus, a natural question is: Do we know how Euler proved this? From what I've read, he wasn't Ramanujan-like in his results. Indeed, he tended to have proofs for such things, even if he never published/mentioned them (unless to show colleagues that he had already derived their published results years before them). Yet, I also doubt that he checked primes up to $\sqrt{M_{61}}$. (And if it was indeed a case of mathematical mysticism, how could one use non-Eulerian cleverness to offer an alternative disproof? ) Edit: As Daniel Fischer commented, it actually wasn't Euler! ""$M_{61}$ was determined to be prime in 1883 by Ivan Mikheevich Pervushin, though Mersenne claimed it was composite, and for this reason it is sometimes called Pervushin's number,"" according to Wikipedia. It was disproven a century later, but I suppose it would still be useful to know how it was disproved.","['math-history', 'mersenne-numbers', 'big-numbers', 'number-theory', 'prime-numbers']"
2571834,Example of a distribution that is ergodic but not $\phi$-mixing?,"The book ""asymptotic theory for econometricians"" ststes the theory that if a stationary sequence is alpha or phi mixing, it is also ergodic, but not the other way around. However, when I look at the definitions they seem intuititely to me to capture the same idea. I cannot think of an example of a probability distribution over a stationary time series of random variables that is ergodic but not alpha or phi mixing.","['time-series', 'mixing-variables', 'probability-theory', 'ergodic-theory']"
2571882,How to show it is a rhombus,I am trying to solve question 2 (figure 2). I have shown that the diagonals are interesting each other in right angle but I cannot show that AB||GH. Please help.,['geometry']
2571895,Monotone function $f(x)$ for which $|f(x)-f(y)| \leq |x-y|$.,"Let $f:[0,1]\to\mathbb R$ such that $|f(x)-f(y)|\leq |x-y|$ for any $x,y\in[0,1]$. Assume that for any $x\leq y$ in $[0,1]$ then $f(x)\leq f\left(\frac{x+y}2\right)\leq f(y)$ or $f(x)\ge f\left(\frac{x+y}2\right)\geq f(y)$. Then $f$ must be monotone. I have no idea to prove this, how to prove this?","['real-analysis', 'calculus', 'functions']"
2571906,Proof that the evolute of an ellipse is an astroid,"I need to prove that the evolute of the ellipse $\gamma (t)  = (a\cos t, b\sin t)$  with $ a, b > 0 $ is the astroid: $\rho (t) = (\frac{(a^2-b^2)\cos^3 t}{a},\frac{(b^2-a^2)\sin^3 t}{b} )$ I am little bit insecure if this is right. Did I make any mistake? \begin{align*}
\text{Curvature of $\rho$:} \\
\kappa&=\frac{ab}{(a^2\sin^2t+b^2\cos^2t)^{\frac{3}{2}}}\neq0 \\
\text{ Normal:} \\ 
n(t)&=\frac{(-b\cos t,-a\sin t)}{(a^2\sin^2t+b^2\cos^2t)^{\frac{1}{2}}} \\
\text{Hence,  } \beta(t)  \\
\beta(t)&=(a\cos t,b\sin t)+\frac{a^2\sin^2t+b^2\cos^2t}{ab}(-b\cos t,-a\sin t) \\
\beta(t)&= (\frac{(a^2-b^2)\cos^3 t}{a},\frac{(b^2-a^2)\sin^3 t}{b} ) \\
\text{Evolute's trace is described by the astroid:} \\
(ax)^\frac{2}{3}+(by)^\frac{2}{3}&=(a^2-b^2)^\frac{2}{3} \\
\beta(t) \text{ is not regular for the following values of t} \\
t&=0=\frac{\pi}{2}=\frac{3\pi}{2}
\end{align*}","['parametric', 'differential-geometry', 'curvature']"
2571920,Develop the the following Recurrence Relation,"I am attempting to solve the following relation of recurrence: Knowing that $S_n$ is the number of binary strings of length $n$ that
  does not contain the pattern $111$. Develop the relation of recurrence
  for $S_1, S_2, ..., S_n$ and the initial conditions that defines the
  succession of $S$. I know that if $n$ is the length of the string and every character could only have two possible values then the number of combinations is $2^n$. But these types of worded questions are not my strong points. Where do I begin and how do I proceed?","['recurrence-relations', 'discrete-mathematics']"
2571938,Limit of average of decimal digits: $\lim\frac{1}{n} (x_1 + \dots +x_n) = constant$,"I have a problem to solve in Ergodic Theory, but I am stuck and have no idea how to procedure. The problem is the following. Prove that there exists a constant α such that for Lebesgue a.e. x∈[0,1]
$\lim_{n\to\infty} \frac{1}{n} (x_1 + \dots + x_n) = \alpha$
where
$x_1
,...,x_n$
are digits of the decimal expansion of x meaning $x_i \in $ {0,...,9}. I have, that if $x \in Q$,  $\alpha$ is obviously 0. So if $x \in $ R\Q we can bound the limit by above by 9 and below by 1 e.g.
 $\lim_{n\to\infty} \frac{1}{n} (x_1 + \dots + x_n) \leq \lim_{n\to\infty} \frac{9n}{n} = 9$. Right? But now I still have to prove it exists, how can I do that? Thanks a lot already.","['decimal-expansion', 'lebesgue-measure', 'ergodic-theory', 'limits']"
2571957,Orientation preserving/reversing homeomorphisms of torus,I know that every matrix $A$ in $GL_2(\mathbb{Z})$ gives raise to a homeomorphism of the torus which induces a linear map $H_1(\mathbb{T}) \longrightarrow H_1(\mathbb{T})$ whose associated matrix is precisely $A$. My problem is that I need to determine if the homeomorphism $f_A$ associated to $A$ is orientation preserving (i.e. $\textrm{deg }f = 1$) or orientation reversing (i.e. $\textrm{deg }f=-1$). Is there any easy approach (e.g. using smoothnes) to decide so in terms of the entries of $A$?.,"['algebraic-topology', 'homology-cohomology', 'differential-geometry']"
2571971,Steiner inellipse,"Hello it's related to my answer for Prove the inequality $\frac{b+c}{a(y+z)}+\frac{c+a}{b(z+x)}+\frac{a+b}{c(x+y)}\geq 3\frac{a+b+c}{ax+by+cz}$ My answer fails but I don't know why ... So I was thinking a generalization of the following formula: $$\frac{IA^2}{CA\cdot AB}+\frac{IB^2}{BC\cdot AB}+\frac{IC^2}{CA\cdot BC}=1$$ I know that it's related to the Steiner inellipse and we have for a triangle ABC and the ellipse of foci $P$ and $Q$: $$\frac{PA\cdot QA}{BA\cdot CA}+
  \frac{PB\cdot QB}{CB\cdot AB}+
  \frac{PC\cdot QC}{BC\cdot AC}=1$$ But in my proof I have also use the following formula: \begin{align}
  \frac{1}{IA^2}+\frac{1}{IB^2}+\frac{1}{IC^2} &=
  \frac{1}{r^2}-\frac{1}{2rR} \\
  IA^2+IB^2+IC^2 &= s^2+r^2+8rR \\
  CA\cdot AB+BC\cdot AB+CA\cdot BC &= s^2+(4R+r)r \\
  \frac{1}{CA\cdot AB}+\frac{1}{BC\cdot AB}+\frac{1}{CA\cdot BC} &=
  \frac{1}{2rR}
\end{align} So what's the new expression of: \begin{align}
  \frac{1}{BA\cdot CA}+\frac{1}{CB\cdot AB}+\frac{1}{BC\cdot AC} &= ? \\
  \frac{1}{PA\cdot QA}+\frac{1}{PB\cdot QB}+\frac{1}{PC\cdot QC} &= ?  \\
  PA\cdot QA+PB\cdot QB+PC\cdot QC &= ?  \\
  BA\cdot CA+CB\cdot AB+BC\cdot AC &= ?
\end{align} In function of the parameters of the inellipse and the triangle $ABC$ like the area and the side of the triangle or the semi major semi minor axes of the ellipse? Edit: I have a good news The centroid $M$ of the triangle $ABC$ correspond to the centre of the inellipse  and we have the following relation for $P$ any interior point  related to the triangle $ABC$: $$PA^2+PB^2+PC^2=MA^2+MB^2+MC^2+3MP^2$$ Thanks a lot.","['euclidean-geometry', 'trigonometry']"
2572000,Why is function domain of fractions inside radicals not defined for lower values than those found by searching for domain of denominator in fraction?,"Consider function $y = \sqrt{\frac{1-2x}{2x+3}}$. To find the domain of this function we first find the domain of denominator in fraction: $2x+3 \neq 0$ $2x \neq -3$ $x \neq - \frac{3}{2}$ So, the domain of $x$ (for fraction to be valid) is $x \in \left(- \infty, - \frac{3}{2}\right) \cup \left(- \frac{3}{2}, + \infty\right)$. Then we find the domain for whole fraction: $\frac{1-2x}{2x+3} \ge 0$ $1-2x \ge 0$ $-2x \ge -1$ $x \le \frac{1}{2}$ My textbook says that the (real) domain of the whole $y$ function is $x \in \left(- \frac{3}{2}, \frac{1}{2}\right]$. I understand why the function is not defined in values larger than $\frac{1}{2}$ (because condition is $x \le \frac{1}{2}$), but I don't understand why it can't be have values less than $- \frac{3}{2}$ (because condition says only $x \neq - \frac{3}{2}$). I checked the domain of this function and the domain given in the textbook is correct. Function has imaginary values for $x$ values less than $- \frac{3}{2}$ or bigger than $\frac{1}{2}$. It is undefined in $- \frac{3}{2}$.
Real values only in $\left(- \frac{3}{2}, \frac{1}{2}\right]$ domain.","['algebra-precalculus', 'functions']"
2572030,Translating between two different definitions of exterior derivative,"If $\Omega^k(M)$ is the space of differential $1$-forms on a manifold $M$, one may define the operator $\mathop{}\!\mathrm{d} : \Omega^k(M) \to \Omega^{k+1}(M)$ in a coordinate-independent way as follows:
$$\begin{split}
\mathop{}\!\mathrm{d}\omega(X_0,\dots,X_k) = &\sum_{i=0}^k (-1)^i X_i\left(\omega(\dots,\hat X_i,\dots)\right) \\ &+ \sum_{0\leq i < j \leq k} (-1)^{i+j}\omega([X_i,X_j],\dots,\hat X_i, \dots, \hat X_j,\dots)
\end{split}\tag{1}$$
I am trying to see if I can recover the usual definition in terms of local coordinates $x$:
$$\mathop{}\!\mathrm{d}\omega(X_0,\dots,X_k) = \frac{\partial \omega_{i_1\cdots i_k}}{\partial x^{i_0}}(\mathop{}\!\mathrm{d}x^{i_0} \wedge \mathop{}\!\mathrm{d}x^{i_1} \wedge \cdots \wedge \mathop{}\!\mathrm{d}x^{i_k}) (X_0,\cdots,X_k)\tag{2}$$
In the case $k = 1$, equations $(1)$ and $(2)$ become
$$\begin{split}
d\omega(X_0,X_1) &= X_0(\omega(X_1)) - X_1(\omega(X_0)) -\omega([X_0,X_1]) = \square \\
d\omega(X_0,X_1) &= \dfrac{\partial \omega_a}{\partial x^k} (\mathop{}\!\mathrm{d}x^k \wedge \mathop{}\!\mathrm{d}x^a)(X_0,X_1) = \triangle
\end{split}$$
Setting $\omega = \omega_a \mathop{}\!\mathrm{d}x^a$, $X_0 = X_0^i \dfrac{\partial}{\partial x^i}$, $X_1= X_1^j \dfrac{\partial}{\partial x^j}$, we see that the first equation becomes
$$\begin{split}
\square &= X_0^i \dfrac{\partial}{\partial x^i}\left(\omega_a \mathop{}\!\mathrm{d}x^a \left(X_1^j \dfrac{\partial}{\partial x^j}\right)\right) - X_1^j \dfrac{\partial}{\partial x^j}\left(\omega_a \mathop{}\!\mathrm{d}x^a \left(X_0^i \dfrac{\partial}{\partial x^i}\right)\right) \\ &\quad - \omega_a \mathop{}\!\mathrm{d}x^a\left(\left(X_0^i \dfrac{\partial X_1^j}{\partial x^i} - X_1^j \dfrac{\partial X_0^i}{\partial x^j}\right)\dfrac{\partial}{\partial x^m}\right) \\
&= X_0^iX_1^j \dfrac{\partial \omega_j}{\partial x^i} - X_0^i X_1^j \dfrac{\partial \omega_i}{\partial x^j} - X_0^i \dfrac{\partial X_1^j}{\partial x^i} \omega_j + \dfrac{\partial X_0^i}{\partial x^j} X_1^j \omega_i \\ &= X_0^iX_1^j \left(\dfrac{\partial \omega_j}{\partial x^i} -  \dfrac{\partial \omega_i}{\partial x^j}\right) - X_0^i \dfrac{\partial X_1^j}{\partial x^i} \omega_j + \dfrac{\partial X_0^i}{\partial x^j} X_1^j \omega_i
\end{split}$$
On the other hand, the second equation becomes
$$\begin{split}
\triangle &= \dfrac{\partial \omega_a}{\partial x^k} X_0^i X_1^j \delta^{ka}_{ij} = \dfrac{\partial \omega_a}{\partial x^k} X_0^i X_1^j \det \begin{pmatrix} \delta^k_i & \delta^k_j \\ \delta^a_i & \delta^a_j\end{pmatrix}\\ &= \dfrac{\partial \omega_a}{\partial x^k} X_0^i X_1^j (\delta^k_i\delta^a_j - \delta^k_j\delta^a_i) = \left(\dfrac{\partial \omega_j}{\partial x^i} - \dfrac{\partial \omega_i}{\partial x^j}\right) X_0^i X_1^j
\end{split} $$
This means that if $\square = \triangle$ then
$$- X_0^i \dfrac{\partial X_1^j}{\partial x^i} \omega_j + \dfrac{\partial X_0^i}{\partial x^j} X_1^j \omega_i = 0 $$
Yet if this is so (and I still can't see why) then I'm at a loss at understanding the need for the second summation in equation $(1)$. Would someone care to elucidate and/or point out errors in my calculations?","['differential-forms', 'differential-geometry', 'exterior-algebra']"
2572067,Worldwide Center of Mathematics - Problem of the Week (u-sub),"The problem is to integrate $\displaystyle \int_0^1 \frac 1 {\sqrt{x} + \sqrt[3]{x}} \, dx$ and is solved by using the substitution $x = u^6$. The way I learned u-sub one has to find an expression for $u$ (i.e. $u =$ [expression in terms of $x$]) and not for $x$. The explanation in the solution is short and I do not quite understand this type of u-sub. Also, should this integral not be a limit, since the original function is undefined for $x = 0$?","['integration', 'definite-integrals', 'calculus']"
2572087,Are Parabolas With Two x-Intercepts More Numerous Than Parabolas With No x-Intercepts?,"Suppose we randomly assign values to a , b and c in the equation $y=ax^2 + bx + c$. Whenever the discriminant $(b^2-4ac)$ is positive, the parabola will have two x-intercepts. This will happen whenever $4ac<b^2$, or more explicitly, whenever: $4ac<0$, $4ac=0$ & $0<b^2$, or $0<4ac<b^2$ Let’s distinguish the question of whether $4ac=0$. If our discussion is limited to quadratic equations (in which a cannot equal $0$), $4ac=0$ only when $c=0$. I don’t know what probability to assign to that case, but I don’t think that the question of probability will be important. If $4ac=0$, a parabola usually has two x-intercepts: When $b=0$, $b^2=0$, discriminant=$0$, and the parabola has 1 x-intercept When b is not $0$, $b^2>0$ and the parabola has 2 x-intercepts If 4ac does not equal $0$, a parabola usually has two x-intercepts: 4ac < 0             4ac > 0
|4ac|< b2   Two x-intercepts    Two x-intercepts
|4ac|= b2   Two x-intercepts    One x-intercept
|4ac|> b2   Two x-intercepts    No x-intercept (I'm assuming that these columns are equally likely, not that the rows are. There are two x-intercepts whenever $4ac<0$ (50% of the time) and sometimes even if $4ac>0$ (some positive percent of the time). So that seems to be a greater-than-50% chance.) So regardless of whether $4ac=0$, parabolas usually have two x-intercepts. But that must be wrong. A randomly selected parabola must have the same probability of two x-intercepts as of no x-intercepts. Parabolas can open up or down (with equal probability), with vertex above or below the x-axis (with equal probability). Vertex is above x-axis  Vertex is below x-axis
Parabola opens up   No x-intercepts         Two x-intercepts
Parabola opens down Two x-intercepts        No x-intercept No? SOME REFLECTIONS ON THE RESPONSE SO FAR As happens with painful regularity, the response is a bit too sophisticated for me to understand totally. But I believe there are two major lines of analysis going: (1) doubt that randomly selected values of a , b and c create an equal likelihood that the parabola's vertex lies above or below the x -axis; and (2) doubt about the concept of selection ""at random."" Let's consider that first question first. In an equation in the form $y=ax^2 + bx + c$, the axis of symmetry is the line $x=-b/2a$, and the y-coordinate of the vertex is the y-value associated with that x-value: $y = a(x)^2 + b(x) + c$ $y = a(-b/2a)^2 + b(-b/2a) + c$ $y = ab^2/4a^2 – b^2/2a + c$ $y = b^2/4a – b^2/2a + c$ $y = b^2/4a – 2b^2/4a + 4ac/4a$ $y = (b^2 – 2b^2 + 4ac)/4a$ $y = (– 1b^2 + 4ac)/4a$ When will y be positive? What seems fairly clear to me is that those four alternatives should be equally numerous. I admit to some confusion about the sign of y in those cases where a and c are either both positive or both negative, but it does seem to me that the top-left case should supply some number of positive- y results, the bottom-right case should supply an equal number of negative- y results, and as a whole the table suggests an equal probability that y is positive or negative. But in any event, even if this analysis is wrong, and a random selection of a , b and c DOES NOT allow an equal likelihood of the vertex above or below the x -axis, doesn't it remain the case that the parabola is equally likely to open up or down, so that half of all parabolas (whether vertex-above or vertex-below) will open towards the x -axis and create two x -intercepts? As to the second concern, about random selection, I just don't understand the issue. I read the referenced page about probability distributions, and the only thing that strikes me is the paucity of examples with neither greatest nor least possible value, cases like mine in which a , b and c can be any number. Would it improve the question to consider the random selection of an integer, instead of all real numbers? Do I need to constrain the question to values within a certain interval? What is to be done?","['conic-sections', 'probability', 'algebraic-geometry']"
2572111,Magnitude of $f_3(n)$ compared to power towers of tens,"In the fast growing hierarchy , the sequence $f_2(n)$ is defined as $$f_2(n)=n\cdot 2^n$$ The number $f_3(n)$ is defined by $$f_3(n)=f_2^{\ n}(n)$$ For example, to calculate $f_3(5)$, we have to apply the operator $n\cdot 2^n$ five times with start value $5$. Denote $$T(n):=10\uparrow 10 \uparrow \cdots \uparrow 10 \uparrow 10$$ with $n$ tens, so a power tower of tens with height $n$. With the help of the computer, I found out that $f_{30}<T(31)$ , but $f_{31}>T(32)$, so $31$ is the smallest number $n$ with $f_3(n)>T(n+1)$ Can this value also be found without electronic help by bounding the function $f_3(n)$ ? Can I also find the smallest number $n$ with $f_3(n)>T(n+k)$ for $k=2,3,4,\cdots$ without brute force ?","['number-theory', 'big-numbers', 'tetration', 'power-towers']"
2572114,"One of the terms in the open form of $(3x^2+2x+y+4z)^{10}$ is randomly chosen, what is the probability that the chosen term contains $x^7$?","today I've encountered a problem like the following: One of the terms in the open form of $(3x^2+2x+y+4z)^{10}$ is randomly chosen, what is the probability that the chosen term contains $x^7$? My Attempts I've reduced the question to two pieces, -calculating the number of terms with $x^7$ and the number of all terms. I've opened the brackets using multinomials: $$\sum_{k_1,k_2,k_3,k_4=1\\k_1+k_2+k_3+k_4=10}^{10} \dbinom{10}{k_1,k_2,k_3,k_4} (3x^2)^{k_1}\cdot(2x)^{k_2}\cdot y^{k_3}\cdot(4z)^{k_4}$$ 
To calculate the number of terms with $x^7$ I've used that $2k_1+k_2=7$ easily I got $(0,7),(1,5),(2,3),(3,1)$ as the number of solutions for this, thus $4$ terms with $x^7$. However when it got to calculating the number of all terms It got a little more complicated, As an initial thought $x^2$ allows us to get $x^{20}$ for the max degree and $x^{10}$ for the minimum, I assumed that they can take all the values between firstly and what I got was $\{10,11,12,13,14,15,16,17,18,19,20\}$ thus I said the answer might be $\dfrac{4}{11}$. Though I think that my solution has technical errors, and the answer I gave isn't in the options. What are your suggestions?","['multinomial-coefficients', 'binomial-coefficients', 'probability', 'combinatorics', 'contest-math']"
2572116,Integration of a Heaviside function,"I stumbled upon this issue while solving a integration step in a problem as follows: I  have a discontinuous function $F_X(x)$ given by $$F_X(x)=\begin{cases} 
      1 &, 0\leq x< 3 \\\\
      \exp(-\mu x)&, 3\leq x<\infty 
 \end{cases}$$ I could integrate $F_X(x)$ by a piecewise integration. However, if I were to represent this function as $$\displaystyle1-(1-\exp(-\mu x))H(x-3),$$ then I should be able to  integrate as $$\displaystyle \int_0^{\infty} [1-\{1-\exp(-\mu x)\}H(x-3)] dx.$$ Yet,  I couldn't solve it. Further, I want to integrate rectangular function decomposed as Heaviside functions as follows: $$\int_0^{\infty} \left(H(t-2)-H(t-3)\right) \,dt$$ I know that that the answer is 1; however, I am unable separate the integral using the linearity of integration and find the answer. Obviously, I am missing some fundamentals here. Please any advice will be helpful. Is there some silly mistake I am making in the whole question?","['continuity', 'integration', 'functions']"
2572137,$v \otimes v' = v' \otimes v$ implies $v = av'$,"In Dummit and Foote problem 12 of section 10.4, I need to show that if $V$ is some vector space over a field $F$ and $v,v'$ are nonzero elements of $V$, supposing we have that $v \otimes v' = v' \otimes v$ then this implies that $v = av'$ for some $a \in F$. I was trying to consider some basis $\mathcal{B} = \{e_i\}_{i\in I}$ for the vector space $V$, show that we can write $v$ and $v'$ as linear combinations of this basis elements and then argue that since we have $v \otimes v' = \sum_{i \in I}r_i e_i \otimes \sum_{i\in I} s_i e_i = \sum_{i\in I} s_i e_i \otimes \sum_{i \in I}r_i e_i = v' \otimes v$ then if we look at a particular element of the sum on LHS and RHS, namely $r_ie_i \otimes s_je_j = s_je_j\otimes r_i e_i$ then we can send the $r_i$ to the other side or do some manipulation of that sort and obtain the desired result. I know this argument is not rigorous at all, so I am having a hard time doing it more rigorous (if this is a good approach) or actually attack this problem efficiently. I was wondering if this would be the right approach, like working with basis elements and so on or if there is some better way to look at this problem. Perhaps some use of universal property for modules would be helpful? Any help or suggestion with this problem is highly appreciated! Thanks so much!","['abstract-algebra', 'modules', 'tensor-products']"
2572148,Prove that if $\varphi(1_R) \ne 1_s$ then $\varphi(1_R)$ is a zero divisor in $S$.,"Let $R$ and $S$ be nonzero rings with identity and denote their
  respective identities by $1_R$ and $1_S$. Let $\varphi: R \to S$ be a
  nonzero homomorphism of rings. Prove that if $\varphi(1_R) \ne 1_s$ then $\varphi(1_R)$ is a zero
  divisor in $S$. I've seen many variations of this problem elsewhere on MSE, but none in this particular form. I've got the following: Since $\varphi$ is a homomorphism, it follows that $\varphi(1_R) = \varphi(1_R) \varphi(1_R)$; and so $$\varphi(1_R)1_S = \varphi(1_R) \varphi(1_R) \implies \varphi(1_R)[1_S - \varphi(1_R)] = 0.  $$ Since $\varphi(1_R) \ne 1_S$ by assumption, either $\varphi(1_R)$ is a zero divisor (in which case, we're done), or $\varphi(1_R) = 0$. Here's where I'm stuck because I don't see why $\varphi(1_R)$ can't be equal to $0$. Indeed, the statement of the problem says that $\varphi$ is a nonzero homomorphism of rings, but is there some reason why just $1_R$ can't be in ker$(\varphi)$?","['abstract-algebra', 'ring-theory']"
2572215,Help with proving Schröder Bernstein theorem,"I am trying to prove Schröder–Bernstein theorem myself but I am stuck. Here is my try. Let $f:A \rightarrow B$ and $g:B \rightarrow A$ be injective functions for sets $A$ and $B$. Define $h: A \rightarrow B$ as follows: $$ h\left(x\right) = 
     \begin{cases}
       f(x) & \nexists b : g(b)=x \\
       g^{-1}(x) & \text{otherwise}
     \end{cases}
   $$ $h$ is a well defined function because $g$ is injective and it is onto as well. I am stuck at this point because $h$ can be surjective. However for each $x \in B$, there can be at most $2$ distinct elements of $A$ which map to $x$. I think this observation can be used to make use of an argument similar to Hilbert's paradox but I am not able to come up with it. I don't need a complete solution, a hint in the right direction would be much appreciated.",['elementary-set-theory']
2572263,How to find the absolute value of the difference of two variables?,"The problem is as follows: Let $x$ and $y$ integers which satisfy the following equations:
  $$x+y-\sqrt{xy}=7$$
  $$x^2+y^2+xy=133$$
  Find the value of  $\;|x-y|.$ I'm stuck on this problem due the fact that there appears a square root of $xy$ and the squares of both $x$ and $y$, hence the system cannot be solved using the regular methods. Moreover I don't know how to approach the absolute value. The answer which would help me the most is one which addresses some theoretical basis about absolute value and steps which would led me to find $x$ and $y$.",['algebra-precalculus']
2572266,double integral over unbounded region?,"I've looked through a few calculus textbooks and I'm not finding much about how to reduce double integrals over unbounded regions to iterated integrals. Usually double integrals over bounded regions are discussed and categorized as either ""type 1"" or ""type 2"", and from there we have some version of Fubini's Theorem which lets us do iterated integration. Here is an example appearing in a book on statistics: $f_{X,Y}(x,y)
=
\begin{cases}
2e^{-x-y} & 0<x<y\\
0 & \text{otherwise} 
\end{cases}$ I have to find $P(Y<3X)$. I believe this is just the double integral over the region between the lines $y=x$ and $y=3x$ in the first quadrant. Is there a definition or theorem that lets me make the reduction to iterated integration?","['multivariable-calculus', 'statistics', 'probability']"
2572349,Cohomology of Product of Spheres,"I am trying to compute the De Rahm cohomology of $M = S^2 \times S^2$. I was able to compute $H^0(M), H^1(M),$ and $H^4(M)$, but am having trouble computing $H^2(M)$ and $H^3(M)$. I am using the Mayer Vietoris sequence, and I took $U = S^2 \times (S^2 \setminus \{p\})$ and $V  = S^2 \times (S^2 \setminus \{q\})$, so $U \cap V = S^2 \times S^1$. But I haven't been able to find any of the maps needed to compute $H^2$ or $H^3$. How can compute these groups?","['algebraic-topology', 'homology-cohomology', 'differential-geometry']"
2572373,Quick question about a picture - area under a normal distribution is always 1,"Check out the picture below. It's from this site: http://mathworld.wolfram.com/Convolution.html All 3 curves (red, blue, green) are normal distributions [Edit and solution to my question (thanks Hyperplane): Turns out they are not the curves of a normal distribution. I learned ""Gaussian"" does not necessarily mean a probability density function] . Green is the convolution of blue and red. My question I know the area under all normal curves is one (axiom of probability). But it seems like the red curve has the biggest area. I know the convolution of two normals has a variance equal to the sum of the variance of $f$ and $g$... I feel this is a bad picture, but I know I'm wrong to accuse wolfram of that. Can you fix my intuiton? Is it really just all in the tails? Sorry if this is the dumbest question ever.","['statistics', 'probability']"
2572375,Prove $kf(x)+f'(x)=0 $ when conditions of Rolle's theorem are satisfied .,"Prove that if $f$ is differentiable on $ [a,b]$ and if $ f(a)=f(b)=0$ then for any real $k$ there is an $ x \in (a,b) $such that $$kf(x)+f'(x)=0 $$ 
As all the conditions of Rolle's theorem are satisfied one can say that there is at least one  $c \in (a,b) $ such that $f'(c) =0$ How should I proceed furthur ? How can I use this to get to the required equation ?","['derivatives', 'real-analysis', 'calculus', 'functions']"
2572383,Is a set with no limit points closed?,"For example, consider the set: $$\{2,\ 3,\ 5\} \subset \mathbb R.$$ This set has no limit points. A closed set (also this ) is a set which contains all of its limit points. The set described above contains all of its $0$ limit points, therefore it is closed. Is this reasoning correct? Can it be made rigorous more other than just re-writing it with quantifiers? Thank you.","['general-topology', 'real-analysis']"
2572424,How can I show that every derivation of $C^\infty(M)$ on a smooth manifold can be represented by a vector field?,"How can I show that every derivation of $C^\infty(M)$ on a smooth manifold can be represented by a vector field? I want to show that the space of vector fields is isomorphic to the space of derivations of $C^\infty(M)$. I know the proof when $M = \mathbb{R^n}$, but would like to do it for a general smooth manifold.","['manifolds', 'vector-fields', 'smooth-manifolds', 'differential-geometry']"
2572470,"A root of $z^n + f(z)$ within $B_1(0)$, $f$ entire","Suppose we're given an entire function $f$, with the property that $|z| < 1 \implies |f(z)| < 1$. We're asked to show that for any $n \geq 1$, $f(z) + z^n$ has a root within $B_1(0)$. Further I cannot use Rouche's theorem, or the argument principle or the residue theorem :). We can use Cauchy's theorems, or the dog walking theorem: If $\gamma_1, \gamma_2$ are closed curves s.t $|\gamma_1(t) -
 \gamma_2(t)| < |\gamma_1(t)|$ for any $t \in [a,b]$ then
  $n(\gamma_1,0) = n(\gamma_2,0)$. I've spent some times with this: tried by contradiction (it is hinted to try something along these lines) which yields that for any $r \in [0,1)$, $\gamma_1(t) := (re^{\pi it})^n + f(re^{\pi it})$, $0 \notin Image(\gamma_1)$. This gives, through a homotopy to the constant function $f(0)$, that $n(\gamma_1, 0) = 0$. Then from here I've been trying to define a meaningful $\gamma_2$ either by simply $\gamma_2(t) = (re^{\pi it})^n$, or by a using the entirety of $f$ to define it as a finite combination of parts of its power series. None of these yielded successful estimates. I'd like a hint please, first. Edit 1 : By the above discussion if we can find $r \in [0,1)$ s.t $|f(re^{\pi it})| < r^n$ we would be done. Tried this by contradiction, which yields a sequence within the ball whose values under $f$ converge to a point in $S^1$. From here I don't see much more to do. Btw the above condition would be required to use Rouche's theorem as well, no? Edit 2 Ok so we've been given a correction; we have the above question with the following now: $|z| \leq 1 \implies |f(z)| < 1$. I will post my suggested answer as well, alongside Daniel's great answer.","['derivatives', 'complex-analysis', 'roots', 'entire-functions']"
2572490,Can one determine where $\vert z^2-x \vert \le \vert z\vert$?,"Please look at the nice attempt in the answer below, too before you answer: Let $z \in \mathbb C$ have positive real part and $x>0$ a positive number. I am trying to find the smallest real part of $z$ such that $$\vert z^2-x \vert \le \vert z\vert.$$ Does anyone know how to solve this? The problem is that over $\mathbb C$ such inequalities become multi-valued since $z=a+ib$ . I should add that wolframalpha also gets some expressions but it is not completely transparent what the minimum possible real part is after all. click me Any comments are highly appreciated.","['complex-analysis', 'real-analysis', 'calculus', 'analysis']"
2572491,Power series solution : can we have a unique series solution(around $x=0$) for an IVP having $x=0$ a singular point?,"Studying power series and Frobenius method , I found a theorem stating that there is a unique Maclaurin series $y(x)$ satisfying the IVP 
$$y''+a(x)y'+b(x)y=0 ,\ \ y(0)=\alpha \ \ ,y'(0)=\beta$$
provided $a(x)$ and $b(x)$ are analytic at $x=0$ . So does this mean that if we have $x=0$ is a regular singular point , we do not have always a unique solution for the IVP ? or not always , we may have a unique solution or not and we just do not guarantee the unique solution ? For example , the problem
$$xy''-xy'+y=e^{x}\ \ \ ,y(0)=1\ \ \ ,y'(0)=2$$
The general solution ( particular and homogeneous solutions) is 
$$y(x)=(e^x-x)+c_1x+c_2(-1+x\ln(x)+\frac{x^2}{2}+\frac{x^3}{12}+...)$$
(Note : the details of the solution is here Solving this non homogeneous IVP using power series )
Applying initial conditions , we find that $c_1=2$ , $c_2=0$ (unique values for the constants although $x=0$ is singular point!) However , another problem 
$$x^2y''-3xy'+3y=0,\ \ y(0)=0\ \ ,y'(0)=1$$
has $x=0$ a regular singular point , and has solution
$$y=c_1x+c_2x^3$$
Applying intial conditions , we find that $c_1=1$ but $c_2$ has infinite values.","['ordinary-differential-equations', 'power-series']"
2572593,Least cost to guess a number between 0~100,"Here is the problem. There is a number randomly chosen between 1~100. The player tries to guess that. If the guess is larger than true value, the player is punished by 'a' dollar. If the guess is smaller than true value, the player is punished by 'b' dollar. How much money the play should prepare in order to hit the number in the worst case?
1) a = 1, b = 1;
2) a = 2, b = 1;
3) a = 1.5, b = 1; Here is where I am so far. 
For the first sub-question, the player would use binary tree and the worst case would be 7 guessing times (6 wrong and 1 right). Hence, the punish money would be 6*1 = 6 dollars. 
For the second sub-question, instead of separating the range by half, the player will separate the range according to the weight given by a and b, i.e. in this case the player would choose 33 for the first guess instead of 50. In this strategy, the worst case would cost the player 11 dollars(according to my calculation), while the binary method would cost the player 12 dollars.
For the third question, the methodology is the same as second one. My doubt is: is there another method which is better? The doubt comes from this fact: my method applied same to sub-question 2 and sub-question 3, which means the existence of sub-question 3 is meaningless. Clearly an author of a problem would not put that kind of sub-question. appendix: I am not sure the problem in the link below would provide some hint, but they have something in common. http://datagenetics.com/blog/july22012/index.html","['binary', 'probability']"
