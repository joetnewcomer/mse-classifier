question_id,title,body,tags
437861,Is this recursion relation proof correct?,"Recurrence relation:$$a_0 = 1$$ $$a_{n+1} = 2a_n$$ I'm trying to prove that for any n âˆˆ N, $a_n = 2^n$.  I want to use induction. What I have is, assume that $a_n = 2^n$ is true for $P(n)$. Then $P(n+1)$ would be: $$a_{n+1} = 2^{n+1}$$ $$a_{n+1}=2\cdot(2^n)$$ Because $a_n = 2^n$, then we can substitute, so $a_{n+1} = 2a_n$.","['discrete-mathematics', 'number-theory']"
437862,"Prove that if $\langle x,z\rangle = 0$ for all $z,$ then $x=0.$","I just wanted to check if my reasoning in this proof was correct.
The question is as follows. Let $\beta$ be a basis for a finite dimensional inner product space $V.$ a) Prove that if $\langle x,z \rangle = 0$ for all $z \in \beta,$ then $x=0.$ OK, I reasoned it this way: from the definition of inner products, we have that $\langle x,0 \rangle = \langle 0,x \rangle = 0.$ Further, since $z$ is a basis element and linearly independent, then $x_1z_1+x_2z_2+\dots+x_nz_n = 0$ only if either all the $z_i$ s are zero or all the $x_i$ s are zero. Therefore, $x=0$ since in the initial construction, we defined $z$ as a basis for $V,$ and it doesn't have to be zero. b) Prove that if $\langle x, z \rangle = \langle y,z \rangle$ for all $z \in \beta,$ then $x=y.$ Again, we can go to the fact that $z$ is a basis and linearly independent. We have that $x_1z_1+x_2z_2+\dots+x_nz_n = y_1z_1+y_2z_2+\dots+y_nz_n,$ so if $z$ is linearly independent, then it can only be zero if all the $z$ s are zero or all the $x$ s and $y$ s are zero. In which case, $x$ would be equal to $y$ if $z$ isn't zero. For other cases, we just divide the left side of the equation by the $z$ s on the right, and we get $x_1+x_2+\dots+x_n = y_1+y_2+\dots+y_n$ Is this correct? Did I miss something important? I know this is a simple exercise, but I want to be sure.","['vector-spaces', 'linear-algebra']"
437883,What is the analytic continuation of the Riemann Zeta Function,I am told that when computing the zeroes one does not use the normal definition of the rieman zeta function but an altogether different one that obeys the same functional relation. What is this other function that they use explicitly given? Also if I were to take one of these non trivial zeroes and plug it into the original definition would my answer tend towards zero as I evaluate the series?,"['riemann-hypothesis', 'analytic-number-theory', 'riemann-zeta', 'complex-analysis']"
437900,A problem from Spivak's Calculus on Manifolds,"Notation As Spivak suggests, given $A\subset\mathbb R^n$, boundary $A$ denotes the topological boundary of $A$, i.e. $\overline A\cap\overline{A^c}$. Problem 5-3(a): Let $A\subset\mathbb R^n$ be an open set such that boundary $A$ is an $n-1$ dimensional manifold. Show that $N=A\cup$ boundary $A$ is an $n$ dimensional manifold-with-boundary. Thoughts It seems that we only need to show that there's a neighborhood $V_x$ of $x\in$ boundary $A$ such that $V_x\cap N$ is diffeomorphic to $\mathbb R^n$ or $[0,\infty)\times \mathbb R^{n-1}$. The first situation is met when $A=\{x:0<\lVert x\rVert<1\}$. The condition of boundary $A$ is indispensable, but I don't know how to make use of it. At first, I found a counterexample , eventually pointed out by somebody that it is against the condition of boundary $A$:
$$A=\bigcup_{n=1}^\infty\left(\frac1{2^{n+1}},\frac1{2^n}\right)\times\mathbb R$$
It seems that, the material of manifolds is not that manageable.","['manifolds', 'calculus', 'real-analysis']"
437904,Confused with proof that all Cauchy sequences of real numbers converge.,"First the textbook proves that all Cauchy sequences are bounded, and so have a convergent subsequence, $\{a_{n_{k}}\}$ that converges to a limit, say $L$. Now we use this to prove that all Cauchy sequences are convergent. So an $N_1$ exists such that $$\left|a_{n_{k}}-L\right|<\frac{\epsilon}{2}$$ for all $ k > N_1$,
and an $N_2$ exists such that $$\left|a_m-a_n\right|<\frac{\epsilon}{2}$$ for all $n,m > N_2 $. Pick any $k > N_1$ such that $n_k > N_2$. Then for every $n > N_2$, $$\left| a_n - L \right | \leq \left| a_n - a_{n_{k}} \right| + \left| a_{n_{k}} - L \right| < \epsilon/2 + \epsilon/2 = \epsilon$$. So $$\lim_{n \rightarrow \infty}a_n = L$$ I'm fine with this proof until the last part - I'm confused as to why we can pick an abitrary $k$ like we do? Should the limit not depend only on $n$? Now it appears like it also depends on $k$ and if we pick a $k < N_1$, the inequality isn't true. Can someone clarify this for me please?","['proof-explanation', 'sequences-and-series', 'real-analysis', 'cauchy-sequences']"
437908,The Product Rule of Square Roots with Negative Numbers,"In the statement $\forall a, b \geq0, \sqrt{a} \cdot \sqrt{b} = \sqrt{ab}$, why is it necessary to restrict $a$ and $b$ to being $\geq 0$? It seems that one should be able to say, for example, $(-3)^{1/2} \cdot (-3)^{1/2} = (-3 \cdot -3)^{1/2} = 9^{1/2} = 3$, so where is the flaw in this statement, since it just seems to be using laws of exponents. Edit: I don't think people are understanding what I'm asking. To reemphasize, my question is: why do we say $\forall a, b \geq 0, \sqrt{a} \cdot \sqrt{b} = \sqrt{ab}$, instead of just $\forall a, b \in \mathbb{R}, \sqrt{a} \cdot \sqrt{b} = \sqrt{ab}$",['algebra-precalculus']
437919,"Sum of one, two, and three squares","If a square $n^2$ can be written as the sum of two nonzero squares as well as the sum of three nonzero squares, then can we conclude that it can be written as the sum of any number of nonzero squares up to $n^2 - 14$ nonzero squares? Example: $13^2 = 12^2 + 5^2 = 12^2 + 4^2 + 3^2$. But also $13^2 = 11^2 + 4^2 + 4^2 + 4^2$ and $13^2 = 12^2 + 4^2 + 2^2 + 2^2 + 1^2$ etc up to $13^2 = 3^2 + 2^2 + 2^2 + 1^2 + .. + 1^2$.",['number-theory']
437926,A limit problem $\lim\limits_{x \to 0}\frac{x\sin(\sin x) - \sin^{2}x}{x^{6}}$,"This is a problem from ""A Course of Pure Mathematics"" by G H Hardy. Find the limit $$\lim_{x \to 0}\frac{x\sin(\sin x) - \sin^{2}x}{x^{6}}$$ I had solved it long back (solution presented in my blog here ) but I had to use the L'Hospital's Rule (another alternative is Taylor's series). This problem is given in an introductory chapter on limits and the concept of Taylor series or L'Hospital's rule is provided in a later chapter in the same book. So I am damn sure that there is a mechanism to evaluate this limit by simpler methods involving basic algebraic and trigonometric manipulations and use of limit $$\lim_{x \to 0}\frac{\sin x}{x} = 1$$ but I have not been able to find such a solution till now. If someone has any ideas in this direction please help me out. PS: The answer is $1/18$ and can be easily verified by a calculator by putting $x = 0.01$","['alternative-proof', 'calculus', 'limits']"
437940,What does it mean by piecewise smooth boundary?,I will be highly obliged if anyone can give me any reference where i can get the definition of domain (in $\mathbb{R^n}$) with piecewise smooth boundary. My question is when a domain in $\mathbb{R^n}$ is said to have a piecewise smooth boundary? I tried a lot to find in Google but i didn't get.Please help me out.,"['multivariable-calculus', 'reference-request']"
437944,"$f$ integrable, $g$ measurable, $f = g$ almost everywhere implies $g$ integrable","If $f\in L(X,\mathcal{x},\mu)$, that is: $f\colon X\to R$ is measurable; $\int f^+\,d\mu<+\infty$ and $\int f^-\,d\mu<+\infty$; $\int f\,d\mu=\int f^+\,d\mu-\int f^-\,d\mu$. If $g\colon X\to R$ is measurable and $f=g$ $\mu$-almost everywhere,
I need to show that $\int g^+\,d\mu<+\infty$. Any thoughts? Note: The integral of a non-negative measurable function $h$ is defined as $$\int h\,d\mu=\text{sup}\left\{\int\phi\,d\mu: 0\le\phi\le h\right\},$$ where $\phi$ is a simple measurable function.","['lebesgue-integral', 'measure-theory', 'real-analysis', 'analysis']"
437946,Motivation behind introduction of measure theory,"Is the motivation behind the introduction of measure theory the Lebesgue integral? In order to evaluate such an integral we need the length of each of the horizontal strip of width $h$. I have a question here. Why do we need such a general concept of measure? Length is a kind of measure, but why did Lebesgue think of so general a concept of ""measure"" when he just needed the length to evaluate his integrals? Is there any other motivation behind this ?","['lebesgue-integral', 'measure-theory', 'intuition']"
437950,"A question about bounds, least and minimal elements, and partial vs strict ordered sets","It's not very clear to me if the concepts of bounds , least elements and minimal elements (also, greatest elements and maximal elements, etc. ) apply only to partial orders or if the definition applies to general ordered sets. If I try to make an analogy between sets in general and the real numbers I would say that those definitions are explicitly made for partial orders, though I'm not sure and I don't know whether there are some sets with strict order to which the definitions apply. For example, there is a theorem that says that ""if $b$ is the least element of $B$ in some order on $A$ and $B\subseteq A$, then $b$ is the infimum of $B$"". In this case I can think of the set $A=\{1,2,3\}$ with the usual strict order $<$ on $\mathbb{R}$ and $B=\{2,3\}$. Then $\inf(B)=1$ and $\min(B)=2$. But if I take the usual partial order $\leq$ then $\min(B)=\inf(B)=2$. Here I'm using the next definition: Let $R$ be an ordering on $A$, and let $B\subseteq A$. Then, 1.- $a\in A$ is a lower bound of $B$ iff $\forall x\in B(a R x)$. 2.- $a\in B$ is a greatest element of $B$ iff $\forall x\in B(x R a)$. 3.- $a\in A$ is called an infimum of $B$ iff it is the greates element of the set of all lower bounds of $B$. Note: For the example I'm assuming as proved that the greatest element an the infimum are unique. Edit: Esentially what I'd like to know is to what kind of orders the definitions of bounds, least and greatest elements, minimal and maximal elements, etc. apply.",['elementary-set-theory']
437956,"Prove that the series $\sum_{n=1}^\infty \left[f(n)-\int_n^{n+1}\!f(x)\,\text{d}x\right]$ converges","Let $f$ be a non-negative decreasing function on $[1,+\infty)$. Prove that the series 
$$\sum_{n=1}^\infty \left[f(n)-\int_n^{n+1}\!f(x)\,\text{d}x\right]$$
converges.","['convergence-divergence', 'sequences-and-series', 'analysis']"
437980,For what kind of a subset its sums equal $\mathbb{R}^4$,"For short, suppose $a,b$ are real numbers. Let $A=\{(\cos(at), \cos(bt), \sin(at), \sin(bt))\mid t\in \mathbb{R}\}$. Let $B=\sum A=\{\sum_{i=1}^n x_i\mid x_i\in A, n \geq 1\}$. For what values $a,b$, $B$ equals $\mathbb{R}^4$? In general, what conditions can we impose to a subset $A$  of $\mathbb{R}^n$, 
such that the sums of $A$ is the whole space? Any references, suggestions are appreciated. Thanks!",['analysis']
437996,Minimal geodesics in $S^{n+1}$,"Let $\Omega^d(M)$ the space of minimal geodesics on a smooth manifold $M$. How can I prove that if $M= S^{n+1}$, $\Omega^d(S^{n+1}) \simeq S^n$?","['differential-topology', 'geometry']"
438028,Prove that $m^{2013}-m^{20}+m^{13}-2013$ has at least $N$ prime divisors,"for positive integer $N>1$,There always exists $m$ such that
$$m^{2013}-m^{20}+m^{13}-2013$$
has at least $N$ prime divisors Thank you all, this is good problem, but I don't know how to solve it.","['prime-numbers', 'prime-factorization', 'number-theory']"
438055,Non-trivial Topology,"I can't understand the differences between a non-trivial topology and a trivial one.
Whuat's the meaning of ""non-trivial"" topology?
Is there a link with connection's properties? For example, could we say that a moebius strip has a ""non-trivial"" topology while an ordinary strip has a trivial one?",['general-topology']
438069,Does every countable subset of the set of all countable limit ordinals have the least upper bound in it?,"I'm sorry if the question is that kind of trivial, I just feel uncertain about these ordinals all the time. Is the answer to the following question ""yes"": Denote by A the set of all countable limit ordinals. Does every countable subset of A have the least uper bound in A?","['ordinals', 'elementary-set-theory']"
438078,Mutual Information for clustering,"I'm working on a document clustering application and decided to use Normalized Mutual Information as one of the measures of effectivenes. But I don't really understand how to implement this in that situation. In http://nlp.stanford.edu/IR-book/html/htmledition/evaluation-of-clustering-1.html the the formula is transformed to (185), and in this publication (www.shi-zhong.com/papers/comptext2.pdfâ€Ž, page 8, formula 17) it looks slightly different, n(h,l) is not divided by total number of documents N. So, which formula is correct? I would be very grateful for possibly simple explantation.","['clustering', 'statistics', 'data-mining', 'data-analysis', 'pattern-recognition']"
438079,The Analog of the Cube in The Fourth Dimension,"I was just wondering how a ""cube"" would look in 4-D. I know that in 1-D it is a line, in 2-D it is a square, in 3-D it is a cube. Is it possible to envision it? If it is, how would the axes be defined? (i.e: 3-D as the x,y, and z axes) P.S.: Not sure what tag this would go under. Geometry maybe?",['geometry']
438081,Canonical sheaf not globally generated for a certain surface.,"Me and a friend tried the following problem, but with no luck. Anything would be appreciated: Let $X \rightarrow S$ be an arithmetic surface such that for some $s \in S$, $X_s$ is the union of two elliptic curves meeting transversally at a point rational over $k(s)$. Show that $\omega_{X/S}$ is not generated by its global sections, and find the smallest $n$ such that $\omega^n_{X/S}$ is. I have only noted some trivial things, the fibers are of genus two seems relevant. But apart from that, nothing.",['algebraic-geometry']
438089,Real valued analytic function defined on a connected set is constant,"Let $G$ be a connected set and $f : G \rightarrow \mathbb{C}$ a real valued analytic function. Prove that $f$ is constant. My idea to prove the result is to prove a subset $A \neq \varnothing$ of the connected set $G$ is both open and closed. So $G=A$
Take $f(w) = a$
$$A = \{z\colon z \in G, f(z) = a\}$$
Now I want to show that $A$ is infinite. How to do it?
After that it is easy to prove $A=G$.",['complex-analysis']
438108,Show: $f'=0\Rightarrow f=\mbox{const}$,"Let $G\subseteq\mathbb{C}$ be a domain and $f\colon G\to\mathbb{C}$ holomorphic. Show:
    $$
f'=0\mbox{ in }G\Rightarrow f\mbox{ is constant}
$$ Cauchy-Riemann:
$$
f'(z)=f_x(z)=u_x(x,y)+i v_x(x,y), z=x+iy=0\\ \Leftrightarrow u_x(x,y)=0~\wedge v_x(x,y)=0
$$ and
$$
f'(z)=-if_y(z)=-iu_y(x,y)+v_y(x,y)=0\\\Leftrightarrow u_y(x,y)=0~\wedge~v_y(x,y)=0
$$ That means: If one derivates u and v to x, one gets 0, and therfore the x-part of these functions must be constant. The ssame for the y-part of u and v. So u and v are constant and so is then f. Is that okay?",['complex-analysis']
438118,Prove that $\limsup_{n\to\infty} |X_n|/n \le1 $ almost surely,"Suppose $\{X_n\}$ a sequence of random variables.
If $\sum_{n=1}^\infty P(|X_n|>n)< \infty$ Prove that $$\limsup_{n\to\infty}\frac{ |X_n|}{n} \le1 $$ almost surely What i have done so far: I thought using the Borel-Cantelli lemma could lead me somewhere, but i didn't have any luck. From Borel-Cantelli lemma we know that if $\sum_{n=1}^\infty P(|X_n|>n)< \infty$ then $P(|X_n|>n)=0$ How could I proceed?
I would appreciate any help, advice. Thank you all very much in advance for your time and concern.","['probability-theory', 'borel-cantelli-lemmas', 'sequences-and-series', 'limsup-and-liminf']"
438140,Series involving Marcum Q function,"I would like to have a better form of this series: $$\sum_{k=0}^{\infty}\,\frac{1}{k!}\,\left(\frac{ab\sin(c)}{\sqrt{2}}\right)^{2k}\,Q_{k+\frac{3}{2}}\left(ab\cos(c),bx\right)$$ where $Q_m(\alpha,\beta)$ is the generalized Marcum Q-function .
Does anyone an idea on how to proceed, if possible to make it better (e.g. getting rid of the series)?
Thanks! EDIT:
could the result be just proportional to $Q_{\frac{3}{2}}\left(ab,bx\right)$???","['statistics', 'sequences-and-series', 'special-functions']"
438146,Can't see how this function is differentiable Spivak's Calculus on Manifolds Exercise 2-4,"The problem is as follows: Let $g$ be a continuous real-valued function on the unit circle $\{x \in \mathbb{R}^2 : \lvert x \rvert = 1\}$ such that $g(0,1) = g(1,0) = 0$ and $g(-x) = -g(x)$. Define $f: \mathbb{R}^2 \to \mathbb{R}$ by $$f(x) =
          \begin{cases}
           \lvert x \rvert \cdot g\left(\frac{x}{\lvert x \rvert}\right) & : x \neq 0\\
            0 & : x = 0
           \end{cases}$$ The question is: If $x \in \mathbb{R}^2$ and $h: \mathbb{R} \to \mathbb{R}$ is defined by $h(t) = f(tx)$, show that $h$ is differentiable. I'm not sure which definition of differentiation I should useâ€“the usual single variable one or the general one defined in the chapter? I went with the single variable definition since $h$ is a single variable function and I get: $$\lim_{k \to 0} \frac{h(t+k) -h(t)}{k} = \lim_{k \to 0} \frac{f((t+k)x) - f(tx)}{k} = \lim_{k \to 0} \frac{\lvert tx-kx \rvert \cdot g\left( \frac{tx-kx}{\lvert tx-kx \rvert} \right) - \lvert tx \rvert \cdot g\left( \frac{tx}{\lvert tx \rvert} \right)}{k}$$ I don't know what to do after this. We don't know if g is differentiable. If I use the other limit definition, I run into the same problem. If the information given for $g$ is supposed to somehow imply that $g$ is differentiable, I don't see it. Any hints?","['multivariable-calculus', 'real-analysis']"
438152,extension of analytic functions of several variables,"Suppose that we have two functions of several complex variables that are holomorphic on the whole euclidean space. If these two functions are equal on an open and connected subset of the REAL euclidean space, can we say that they are equal everywhere?
This is true for holomorphic functions of one complex variable, but does it hold for several variables holomorphic functions?",['complex-analysis']
438154,A reason for writing $\mathfrak{c}=2^{\aleph_{0}}$,"In the book Measures, Integrals and Martingales the author asks to show that $\# \{1,2\}^{\Bbb{N}} \le \# (0,1) \le \# \{0,1\}^{\Bbb{N}}$ and to conclude that $\# (0,1)= \# \{0,1\}^{\Bbb{N}}$ . He also remarks that this is a reason for writing $\mathfrak{c}=2^{\aleph_{0}}$. I am stuck on two parts showing $\# \{1,2\}^{\Bbb{N}} \le \# (0,1) \le \# \{0,1\}^{\Bbb{N}}$ the hint given is to ""interpret $\{0,1\}^{\Bbb{N}}$ as base-$2$ expansions of all numbers in $(0,1)$ while $ \{1,2\}^{\Bbb{N}}$are all infinite base-$3$ expansions lacking the digit $0$"" but I've never worked with base expansions or dyadic fractions so I'm trying to find another way(I wouldn't mind if someone could guide me through this, all I know is that a dyadic fraction is rational of the form $\displaystyle\frac{a}{2^q}$.) For the second part I'm trying to show that $f: \{0,1\}^{\Bbb{N}} \to \{1,2\}^{\Bbb{N}}$ defined by $f((a_i)_{i \in N})=(b_1, b_2,\ldots)$ where $b_i =1$ if $a_i=0$ and $2$ otherwise, is a bijection and the result follows by the Cantor-Bernestein theorem. Concerning the remark it seems that $\{0,1\}^\Bbb{N}=2^{\aleph_0}$ but I haven't been able to prove that. Notation: $\{0,1\}^{\Bbb{N}}$ is the set of sequences $(x_j)_{j \in \Bbb{N}}$ such that $x_j \in\{ 0,1\}$ Edit: Is the reason for $\{0,1\}^\Bbb{N}=2^{\aleph_0}$ the following? If we want to chose a sequence whose terms are $0$ or $1$ for each $n \in \Bbb{N}$ then each $(x_j)_{j \in \Bbb{N}}$ has a value for each $j$ that is it has $\aleph_0$ entries each of which have two choices then we have $2 \times 2 \times 2 \times  \ldots$ choices $= 2^{\aleph_0}$ choices.","['cardinals', 'elementary-set-theory']"
438164,diagonalize quadratic form,"I have this quadratic form $Q= x^2 + 4y^2 + 9z^2 + 4xy + 6xz+ 12yz$ And they ask me: for which values of $x,y$ and $z$ is $Q=0$? and I have to diagonalize also the quadratic form. I calculated the eigenvalues: $k_{1}=0=k_{2}, k_{3}=14$, and the eigenvector $v_{1}=(-2,1,0), v_{2}=(1,2,3), v_{3}=(3,6,-5)$ I don't know if this is usefull in order to diagonalize or to see when is $Q=0$","['matrices', 'quadratic-forms', 'linear-algebra', 'diagonalization']"
438165,Taking the derivative of an Integral,"I would like to express the derivative of an integral in as elegant a form as possible. However, I am struggling at the moment. I would like to find the derivative $f'(y)$ of the function $f(y) = \int_{h(y)}^{g(y)}u(x,y)\,\mathrm{d}x$ in terms of only the functions $g$, $h$ and $u$ which can be assumed to be sufficiently well behaved.","['multivariable-calculus', 'calculus', 'integration', 'definite-integrals', 'derivatives']"
438166,Core for the Laplace operator in a bounded domain,Let $X$ be a bounded connected open subset of the $n$-dimensional real Euclidean space. Consider the Laplace operator defined on the space of infinitely differentiable functions with compact support in $X$. Does the closure of this operator generate a strongly continuous semigroup on $C_0(X)$ endowed with the supremum norm? I think it is equivalent to the following question: Is the space of infinitely differentiable functions with compact support in $X$ a core for the Dirichlet Laplacian on $X$?,"['operator-theory', 'partial-derivative', 'functional-analysis', 'partial-differential-equations']"
438169,Prove that $\frac{100!}{50!\cdot2^{50}} \in \Bbb{Z}$,I'm trying to prove that : $$\frac{100!}{50!\cdot2^{50}}$$ is an integer . For the moment I did the following : $$\frac{100!}{50!\cdot2^{50}} = \frac{51 \cdot 52 \cdots 99 \cdot 100}{2^{50}}$$ But it still doesn't quite work out . Hints anyone ? Thanks,['combinatorics']
438190,Going from the Poisson distribution to the Gaussian.,"In this lecture, at about the $37$ minute mark, the professor explains how the binomial distribution, under certain circumstances, transforms into the Poisson distribution, then how as the mean value of the Poisson distr. increases, the devation from the mean behaves like a Gaussian. I'm having trouble with calculating this. The pmf of the Poisson distr. is $$p(n)=\frac{e^{-\lambda}\lambda^n}{n!}$$ If we define $x=\lambda-n$ to be the deviation from the mean and substitute into the pmf, we get $$p(x)=\frac{e^{-\lambda}\lambda^{\lambda-x}}{(\lambda -x)!}$$ Using the Stirling formula, this becomes approximately $$p(x) \approx \frac{e^{-\lambda}\lambda^{\lambda-x}}{(\lambda -x)^{\lambda -x} e^{-(\lambda -x)} \sqrt{2\pi (\lambda -x)} } = \frac{e^{-x}}{\sqrt{2\pi}} \frac{\lambda^{\lambda-x}}{(\lambda -x)^{\lambda -x}} (\lambda -x)^{-\frac{1}{2}}$$ $$=\frac{e^{-x}}{\sqrt{2\pi}} (\lambda -x)^{-\frac{1}{2}} (1-\frac{1}{\lambda /x})^{x-\lambda} = \frac{e^{-x}}{\sqrt{2\pi}} (\lambda -x)^{-\frac{1}{2}} ((1-\frac{1}{\lambda /x})^{\lambda /x})^{\frac{x^2-\lambda x}{\lambda}}$$ Now the rightmost term tends to $$e^{-\frac{x^2}{\lambda}}e^x$$ as $\lambda \to \infty$ , which cancels the $e^{-x}$ in front. So this would be looking fairly Gaussian if not for the uncomfortable factor of $(\lambda -x)^{-\frac{1}{2}}$ which tends to zero, killing the whole thing! Where am I making a mistake? Clearly, in the Stirling approximation, the square root factor isn't too relevant (order-wise), and if it's omitted then the problem goes away (or does it? the result isn't normalised!)... but surely this can be fixed?","['probability-theory', 'normal-distribution', 'probability-distributions']"
438210,"Show that $\int_{\alpha}\frac{1}{z}\, dz=\int_{\beta}\frac{1}{z}\, dz$.","Let $a$ and $b$ be positive real numbers. Define ways $\alpha,\beta\colon [0,1]\to\mathbb{C}$ via
  $$
\alpha(t):=a\cos(2\pi t)+ia\sin(2\pi t),~~~~~\beta(t):=a\cos(2\pi t)+ib\sin(2\pi t).
$$
  Show that
  $$
\int_{\alpha}\frac{1}{z}\, dz=\int_{\beta}\frac{1}{z}\, dz.
$$ $1/z$ is holomorphic on $\mathbb{C}\setminus\left\{0\right\}$.
Both ways are closed ways with start- and endpoint $a$. So to my opinion all conditions of the Cauchy integral theorem are fullfilled clearly except that both ways are homotopic. I am thinking of
$$
H\colon [0,1]\times [0,1]\to\mathbb{C}, H(x,y):=a\cos(2\pi x)+i(1-y)a\sin(2\pi x)+iyb\sin(2\pi x)
$$
as an appropriate homotopic function. Anyhow it is
$$
H(x,0)=\alpha(x),~~~~~H(x,1)=\beta(x).
$$","['integration', 'complex-analysis', 'contour-integration']"
438231,General solution for trigonometry equation,"How should I state the general solution for the equation $\sin(4\phi)=\cos(2\phi)$.
The angles are $15$, $45$, $75$ and $135$ if I restrict myself within the range $[0,360]$",['trigonometry']
438242,Mix-problem with percentage,"A can is containing coffee and another can is containing exactly the same amount of milk. We take a spoon of coffee and mix it in the milk can. Then we take a spoon from the mix we obtained and mix it in the coffee. Now we have obtain two different mixes, one with some coffee in the milk, and one with some milk in the coffee. Is it more milk in the coffee than it's coffee in the milk or is it the same? I thought like this: We name the amount in the cans x. Then it lasts x-1 in the coffee-can and the milk-can contains x+1 after the first mix. And then we take $\frac{1}{x+1}$ of this mixture in the coffee-can.",['algebra-precalculus']
438252,Why $\sum_{k=1}^n \frac{1}{2k+1}$ is not an integer?,"Let $S=\sum_{k=1}^n \frac{1}{2k+1}$, how can we prove with elementary math reasoning that $S$ is not an integer?
Can somebody help?","['elementary-number-theory', 'algebra-precalculus']"
438304,Applications of companion matrices,I'm looking for interesting applications of companion matrices. I can also use the Frobenius Normal Form. I already covered the Cayley-Hamilton Theorem and the application to linearly recursive sequences and high-order scalar linear differential equations.,"['matrices', 'linear-algebra', 'companion-matrices', 'applications']"
438310,Show that an entire function is a polynomial,"There is a question in the book that asks me to show that if f is an entire function such that $|f(z)| \le L|z|^m$ where $|z| \ge R$ , then $f$ is a polynomial of degree of at most $m$ . The problem gives me a hint that I should use the Cauchy estimates for n>m and $r \to \infty$ The below is from a post https://math.stackexchange.com/a/143881/64742 Since $f$ is entire, it is equal to a power series centered at zero with radius of convergence $\infty$ , which must match its Taylor series there. $$f(z)=\sum_{n=0}^\infty \frac{f^{(n)}(0)}{n!}z^n$$ Since $|f(z)|\leq k|z|^m$ , Cauchy's estimate gives us $$|f^{(n)}(0)|\leq \frac{n!k|z|^m}{R^n}$$ for all $|z|=R$ . For $n>m$ , letting $R\rightarrow\infty$ , we see that $|f^{(n)}|=0$ . It follows that $f$ is a polynomial of degree $\leq m$ . Now, I follow what the above answer says except where ""It follows that f is a polynomial of degree $ \le m$ . Why do we arrive at that conclusion? The preceding statement merely says that $ |f^{(n)}|=0 $",['complex-analysis']
438311,discretize a function using $z$-transform,"I would like to discretize the following continuous function using $z$-transform: $$G(s)=\frac{s+1}{s^2+s+1}$$ The process I am using is to take the inverse Laplace transform of $\frac{G(s)}{s}$ and then take the z-transform of it. Finally I multiply it the result for $1-z^{1}$ to simulate a zero order hold. The results I am obtaining are the following ones: $$\mathcal{L} \{\frac{G(s)}{s}\}= F(t)=e^{-0.5}[\cos{\frac{\sqrt{3}t}{2}}+\frac{1}{{\sqrt{3}}} \sin{ \frac{\sqrt{3t}}{2}}]$$ $$Z\{F(t)\} = \frac{1-e^{-0.5t}z^{-1}\cos{\frac{\sqrt{3}T}{2}}}{1-2e^{-0.5t}z^{-1}\cos{\frac{\sqrt{3}T}{2}}+e^{-T}z^{-2}} + \frac{1-e^{-0.5t}z^{-1}\sin{\frac{\sqrt{3}T}{2}}}{1-2e^{-0.5t}z^{-1}\cos{\frac{\sqrt{3}T}{2}}+e^{-T}z^{-2}} $$ Definig $\alpha=e^{-0.5T}\cos \frac{\sqrt{3}T}{2}$, $\beta=\frac{e^{-0.5T}}{\sqrt{3}}e^{-0.5T}\cos \frac{\sqrt{3}T}{2}$ and by writing it in function of $z$ instead of $z^{-1}$ we have: $$Z\{F(t)\} =\frac{ z^2+z(\alpha+\beta)}{z^2-2 \alpha z + e^{-T}}$$ Multiplying it by $ 1-z^{-1} $ we finally get: $$\frac{z^2+z(1-\alpha- \beta)+ \alpha - \beta}{z^2-2 \alpha z + e^{-T}}$$ I already redone the calculation a number of times and I couldn't find any errors. However I know it is wrong because it is not matching the correct response to an impulse when I plot it in MATLAB. I hope that it was clear enough. Sorry if I made any theoretical mistakes trying to explain the process, I am just a beginner at this subject. EDIT: After taking the correct Laplace Transform presented below, the answer takes the form of:
$$\frac{z(\beta - \alpha + 1)-\alpha - \beta + e^{-T}}{z^2-2 \alpha z + e^{-T}}$$ If anyone is interesd here are the plots I got from MATLAB corroborating the analysis: The line is the step response of the continuous function, the dotted one is obtained via the c2d function in MATLAB and it is my benchmark. The points are the ones I get via my analysis showed at the top. As you can see everything fits perfectly. Thank you again for your support.","['laplace-transform', 'discrete-mathematics']"
438341,"Calculate the volume of $T = \{(x,y,z) \in \mathbb R^3 : 0 \leq z \leq x^2 + y^2, (x-1)^2 + y^2 \leq 1, y \geq 0\}$","Calculate the volume of $T = \{(x,y,z) \in \mathbb R^3 : 0 \leq z \leq x^2 + y^2, (x-1)^2 + y^2 \leq 1, y \geq 0\}$ so I said that the integral we need is $\iint_{D} {x^2 + y^2 dxdy}$.
But when I drew $D$ I got this: Now I said I want to move the circle to the middle so I would have its' center at $(0,0)$ so I did a change of variables where : $$\begin{array}{11} x=u+1 \\ v = y\\ J(u,v) = 1 \\ u=r\cos\theta\\v=r\sin\theta\\0 \leq r \leq 1 \\ 0 \leq \theta \leq \pi  \end{array}$$ And we need $\iint_{D} {u^2 + 2u + 1 + v dudv}$ And the integral we finally need to calculate is: $$\int_{0}^{\pi} {d\theta {\int_{0}^{1} r^2\cos\theta + 2r\cos\theta + 1 + r\sin\theta du dv}} = 1 + \pi$$ but wolfram does not agree with my answer.
What went wrong?","['multivariable-calculus', 'calculus', 'integration', 'proof-verification']"
438344,"What does ""homomorphism"" require that ""morphism"" doesn't?","I'm starting to learn category theory, but there's one thing I don't get: all morphisms seem to be homomorphisms; the definition seems to be the same. What's the difference between these two? Can you give me an example of a non-homomorphic morphism? Thank you for your patience,","['category-theory', 'abstract-algebra', 'definition']"
438347,Why is the Jacobi symbol in this setting a unique homomorphism?,"If $D \equiv 0,1$ mod $4$ a nonzero integer, why is the map given by $\chi: (\mathbb Z / D\mathbb Z)^* \rightarrow \{-1,+1\}, \chi([p]) = (D/p)$ for odd primes $p$ not dividing $D$, a unique homomorhpism? And why is $\chi([-1]) = 1$ if $D > 0$, and $\chi([-1]) = -1$ if $D < 0$? Why is it unique? And why is it only defined for odd primes $p$ not dividing $D$? (This has been answered) Can anybody explain in details why it's a homomorphism? I though i had it... but i'm not sure. For the Legendre symbol it seems evident Should this not follow from $(ab/p) = (a/p)(b/p)$? How can i show that this homomorphism is well-defined? I'm pretty sure i need this: Why is the Jacobi symbol $(D/m) = (D/n)$ for certain $m,n,D$?",['number-theory']
438362,Evaluate $\cos 18^\circ$ without using the calculator,"I only know $30^\circ$, $45^\circ$, $60^\circ$, $90^\circ$, $180^\circ$, $270^\circ$, and $360^\circ$ as standard angles but how can I prove that
$$\cos 18^\circ=\frac{1}{4}\sqrt{10+2\sqrt{5}}$$",['trigonometry']
438364,What is the difference between exponential symbol $a^x$ and $e^x$ in mathematics symbols?,I want to know the difference between the exponential symbol $a^x$ and $e^x$ in mathematics symbols and please give me some examples for both of them. I asked this question because of the derivative rules table below contain both exponential symbol $a^x$ and $e^x$ and I don't know when should I use one of them and when should I use the another one. Derivative rules table: [ Derivative rules table source ],['derivatives']
438387,How to calculate $\cos(6^\circ)$? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question Do you know any method to calculate $\cos(6^\circ)$ ? I tried lots of trigonometric equations, but not found any suitable one for this problem.",['trigonometry']
438391,Are two matrices of the same rank similar?,"I know that if two matrices $A$ and $B$ are similar implies that they have the same rank. However, if they have the same rank are they similar?","['matrices', 'linear-algebra']"
438398,Why is matrix multiplication defined a certain way? [duplicate],"This question already has answers here : Intuition behind Matrix Multiplication (14 answers) Closed 10 years ago . Why is it that when multiplying a (1x3) by (3x1) matrix, you get a (1x1) matrix, but when multiplying a (3x1) matrix by a (1x3) matrix, you get a (3x3) matrix? Why is matrix multiplication defined this way? Why can't a (1x3) by (3x1) yield a (3x3), or a (3x1) by (1x3) yield a (1x1)? I really would like to get to the root of this problem or 'axiomatization'. Thanks.","['matrices', 'axioms']"
438422,Is there a simple way to state continuity for $I$-adic topology?,"Let $R$ be a commutative ring with the $I$-adic topology defined by an ideal $I$, and let $S$ be a commutative ring with the $J$-adic topology for an ideal $J$. How would you translate saying that a homomorphism $f:R\to S$ is continuous? I am guessing it might be enough to say that for all $n>0$, there is an $m>0$ such that $f^{-1}(J^n)$ contains $I^m$. Is this right?","['general-topology', 'commutative-algebra', 'continuity']"
438436,Inverting the modular $J$ function,"Klein's modular function $J(z)$ is defined and studied 
in e.g. Apostol's book Modular functions and Dirichlet
series in number theory. Certain specific evaluations are available, for example, $$J(i) = 1$$ Additionally, it is known that $J(z)$ takes on all complex
values. Question: Can one solve for that $z$ in the fundamental domain (either explicitly or numerically) which satisfies $J(z) = \mathrm{i}$?","['modular-forms', 'number-theory']"
438440,Is determinant uniformly continuous?,The determinant map $\det$ sending an $n\times n$ real matrix to its determiant is continuous since it's a polynomial in the coefficients. Is it also uniformly continuous?,"['matrices', 'uniform-continuity', 'linear-algebra', 'determinant']"
438444,"What is the integral of $\int e^x\,\sin x\,\,dx$?","I'm trying to solve the integral of $\left(\int e^x\,\sin x\,\,dx\right)$ (My solution): $\int e^x\sin\left(x\right)\,\,dx=$ $\int \sin\left(x\right) \,e^x\,\,dx=$ $\left(\sin(x)\,\int e^x\right)-\left(\int\sin^{'}(x)\,\left(\int e^x\right)\right)$ $\left(\sin(x)\,e^x\right)-\left(\int\cos(x)\,e^x\right)$ $\left(\sin(x)\,e^x\right)-\left(\cos(x)\,e^x-\left(\int-\sin\left(x\right)\,e^x\right)\right)$ $\left(\sin(x)\,e^x\right)-\left(\cos(x)\,e^x-\left(-\sin\left(x\right)\,e^x-\int-\cos\left(x\right)\,e^x\right)\right)$ I don't know how to complete because the solution gonna be very complicated.",['integration']
438452,Find all real numbers such that $\sqrt{x-\frac{1}{x}} + \sqrt{1 - \frac{1}{x}} = x$,Find all real numbers such that $$\sqrt{x-\frac{1}{x}} + \sqrt{1 - \frac{1}{x}} = x$$ My attempt to the solution : I tried to square both sides and tried to remove the root but the equation became of 6th degree.Is there an easier method to solve this?,"['radicals', 'quadratics', 'algebra-precalculus']"
438456,For All Unique Combinations of 60 A's and 20 B's Number of Combinations that have BB,Here is my question. I have 60 A's and 20 B's and need to find out the number of unique combinations of those where B shows up consecutively at least once. For example (6 A's and 2 B's): AAAAAABB = 1 AAAAABAB = 0 AAAABBAA = 1,"['statistics', 'combinatorics']"
438477,Discrete Mathematics: $x\leq y+\epsilon \implies x\leq y$,"Let $x$ and $y$ be real numbers. Prove that if $x\leq y + \epsilon$ for every positive real number $\epsilon$, then $x\leq y$. I would like a hint as to how to prove this. Thank you. Pictorial proof would be nice too. So this is how I word-smithed the answer given by the author of my accepted answer: We will proceed by showing the contrapositve. We are given that
$$x\leq y+\epsilon \implies x\leq y,$$
so the contrapositive is resolved as
$$x > y \implies x>y+\epsilon,$$
or by substituting $x-y = \omega$ simply
$$\omega > 0 \implies \omega > \epsilon,$$
but if $\omega >0$, then $\epsilon = \frac{\omega}{2} > 0$; however, $\omega \leq \frac{\omega}{2}$ is false. Therefore, we can assert that for all $\epsilon > 0$
$$\omega\leq\epsilon \implies \omega \leq 0;$$ quod erat demonstrandum . Here is my pictorial representation:","['calculus', 'proof-writing']"
438485,Proving that $\sum\limits_{n = 0}^{2013} a_n z^n \neq 0$ if $a_0 > a_1 > \dots > a_{2013} > 0$ and $|z| \leq 1$,"I'm going to teach a preparation course for the complex analysis qualifying exam from my university (which basically consists of me doing some problems from past exams) and I'm trying to solve some questions from previous exams. One of the questions is the following: Prove that $\displaystyle{\sum_{n = 0}^{2013} a_n z^n \neq 0}$ if the coefficients  satisfy $a_0 > a_1 > \dots > a_{2013} > 0$ and $|z| \leq 1$. I tried to approach the problem by using the reverse triangle inequality to try to isolate the leading term, which I thought should be the constant coefficient, as follows: \begin{array}
. \left|  \sum_{n = 0}^{2013} a_n z^n \right| &= \left| a_0 +  \sum_{n = 1}^{2013} a_n z^n \right| \\
&\geq |a_0| - \left|  \sum_{n = 1}^{2013} a_n z^n \right|\\
&\geq |a_0| -  \sum_{n = 1}^{2013} |a_n z^n|\\
&\geq a_0 -  \sum_{n = 1}^{2013} a_n |z^n|\\
&\geq a_0 -  \sum_{n = 1}^{2013} a_0 |z^n|\\
&= a_0\left( 1  -  \sum_{n = 1}^{2013} |z^n| \right)
\end{array} Then for $|z| < 1$, we have that this last expression is equal to $$
a_0\left( 1  -  |z| \frac{|z|^{2013} - 1}{|z| - 1} \right)
$$ and my hope was to prove that this was always positive, nevertheless, after failing to prove it, I plotted the expression inside the parenthesis as a function of $|z|$, and found out that it changes sign in the interval $(0, 1)$. Question Can my approach somehow be made to work? And if not, how can I prove that the sum $\displaystyle{\sum_{n = 0}^{2013} a_n z^n \neq 0}$ under the given conditions? Thank you very much for any help.","['complex-numbers', 'sequences-and-series', 'roots', 'complex-analysis']"
438493,Using Calculus to find total and maximum revenue and profit,"I'm grappling with understanding how to use calculus to find rates of profit, revenue, and cost.  I have the following problem: $x = \text{ quantity }$, $12 < x < 48$ Total Cost: $C(x) = \dfrac 92x^2 -17x + 2700$ Price per item: $p(x) = -\dfrac{x^2}3 +\dfrac{23}2x + 78 + \dfrac{20000}x$ To find the total revenue $R(x)$, I believe that I have to multiply the quantity x by the price/item.  Thus, $$\begin{align} R(x) &= x\cdot p(x)\\ 
         &= x\left( -\dfrac{x^2}3 +\dfrac{23}2x + 78 + \dfrac{20000}x\right) \\
         &=  -\dfrac{x^3}3 +\dfrac{23}2x^2 + 78 + 20000\end{align}$$ To find total profit $P(x)$, I believe that I have to subtract cost from revenue. Thus, $$\begin{align} P(x) &= R(x) - C(x) \\
         &= -\frac{x^3}3 +\frac{23}2x^2 + 78x + 20000 - \left(\frac 92x^2 -17x + 2700\right) \\
         &= --\frac{x^3}3 +\frac{17}2 x^2 + 61x + 17300\end{align}$$ To find $x$ for maximum revenue, I believe I need to find the derivative of $R(x)$, so that $$\begin{align} R'(x) = -x^2 + 23x + 78 &= 0\\
              -(x-26)(x+3) &= 0\\
              x = 26  \text{ or }x &= -3\end{align}$$ Since $x = -3$ is not in the domain, this means that the quantity of $x$ that will generate the maximum revenue is $26$. To find $x$ for maximum profit, I need to first find the derivative of $P(x)$, set it equal to zero, and solve for $x$.  Thus, $$P'(x) = -x^2 + 17x + 61 = 0$$ And here's where I run into trouble.  I'm not sure if I'm doing my math correctly or if this is just not an easy polynomial to factor.  If I can't factor the polynomial to find x, I'm not sure how to proceed. Essentially, I'm hoping someone can tell me if my math and logic are correct as I take the derivatives and find the maxima; if I'm not doing it correctly, how so; and what I might be doing wrong when it comes to finding the total profit.  My apologies if there is a better way to format exponents.  I checked the formatting help page and didn't see any help specific to that.  If you have a suggestion for that as well, I'm happy to go in and edit the post to make it more readable.  Thanks in advance.","['optimization', 'calculus', 'derivatives']"
438519,"Using complete induction, prove that if $a_1=2$, $a_2=4$, and $a_{n+2}=5a_{n+1}-6a_n$, then $a_n=2^n$","Could anyone please explain to me how to do this problem by using the principle of complete induction? Thanks. :) Let $a_1=2$, $a_2=4$, and $a_{n+2}=5a_{n+1}-6a_n$ for all $n\geq 1$. Prove that $a_n=2^n$ for all natural numbers $n$.","['induction', 'recurrence-relations', 'elementary-number-theory', 'discrete-mathematics']"
438539,Proof by Contradiction: $100$ Balls & $9$ Boxes,"Show, by giving a proof by contradiction, that if $100$ balls are placed in nine boxes, some box contains 12 or more balls. I would like to ask for a hint for this quesiton. Thank you.","['optimization', 'discrete-optimization', 'inequality', 'discrete-mathematics']"
438555,"Do there exist complex algebraic $Î±,Î²$ such that $Î±^Î²=Ï€$ or $Î±^Î²=e$?","Given the algebraic operations and complex exponentiation $(a+bi)^{c+di}$ and logarithm, is it possible to derive $\pi$ and $e$? If one is derivable then so should be the other, as $e^\pi = (-1)^{-i}$. I however don't think either are. I'd be interested to be proved wrong though. An elaboration of the rules: no trigonometry, solution must be expressible using a finite number of terms, and $Î±$ and $Î²$ are complex, algebraic numbers.","['pi', 'complex-numbers', 'exponential-function', 'number-theory']"
438567,Whats the formula for the amount to scale up an image during rotation to not see the edges,"I'm trying to figure out a formula... for how much a picture (rectangle) would have to be scaled up during a rotation (at any rotation amount) so that you don't see the edge of the picture in the square of the bounding box. If the bounding box is square it might be a simpler formula. But when the box is rectangle it seems like it gets harder to figure out.  Although it might be a different formula if the width>height, than if the height>width. The graphic above shows 30 degrees which took 170%. I would think 45 degrees would be the worst case scenario then from there to 90 it would go down again. To clarify, I am looking for a formula to calculate a scale factor to use given an angle a height and a width. We can assume the size and aspect of the bounding box to be equal to the size and aspect of the photo.  So the input is Angle, Height, and Width.. the output is Scale Factor. Or actually, maybe it can be figured out using the Angle and an Aspect Ratio..  where aspect ratio is width/height. In practice this will be done in code.. so it doesn't have to be a single formula.  It can be different formulas for different scenarios.. such as if the w>h or w=h or w",['trigonometry']
438572,Path Connectedness in Van Kampen Theorem,"On page 17 of this pdf, http://www.math.uchicago.edu/~may/CONCISE/ConciseRevised.pdf , the Van Kampen Theorem is proven. That is it is shown that for any covering of a space $X$ by a family of open path connected subsets $\lbrace U_i\rbrace$ closed under finite intersections, then the fundamental groupoid $\pi(X) =$ colim ${\pi(U_i)}$ Where the the category on $U$ is has the ${\pi(U_i)}$ as objects and inclusions $U_i \subset U_j$ as arrows. Now the theorem is proven by showing that the required universal property is satisfied, that is that given any groupoid $G$ with family of maps $f_{U_i}:\pi(U_i) \to G$ such that the associated diagram commutes (that is that if $U_i \subset U_j$ we have $f_{U_j}|_{U_i} = f_{U_i}$) we can find a unique family of maps $f^*: \pi(X) \to G$ such that $f^*|_{\pi(U_I)} = f_{U_i}$. For $a\in U_j$ we can define $f^*(a) = f_{U_j}(a)$.  This is obviously unique and is well defined because if $a \in U_j, U_k$ we have $a \in {U_j \cap U_k}$ and $f_{U_j}|_{U_j \cap U_k} = f_{U_k}|_{U_j \cap U_k}$. For a path $\phi: x \to y$ with $x, y \in X$, $f$ is covered by U and thus has a finite subcovering $\lbrace U_i\rbrace$. Now denote the restriction of our path to some path in $U_i$  $\phi_i$. It seems celar that we can find proper endpoints to do this.  We can then define $f([\phi])$ to be the composite of all such $\phi_i$. I think I can understand why the actual steps in the proof are valid, but the theorem seems to require that the sets involved be path connected despite that at no point the actual proof employs this.  Can somebody please try to explain what part of that proof is invalid if the $\lbrace U_i\rbrace$ involved are not path connected?  Why doesn't the map constructed still work?","['general-topology', 'connectedness', 'homotopy-theory', 'algebraic-topology']"
438585,Axiom of Regularity and infinite sequences,"I'm wrestling with the elementary implications of the Axiom of Regularity. The axiom: $âˆ€A(Aâ‰ âˆ…â†’(âˆƒxâˆˆA)(Aâˆ©x=âˆ…))$ implies that every set A either has $âˆ…âˆˆA$, or it has some element $x$ such that $xâˆ©A=âˆ…$. My questions:
(1) If $xâˆˆA$, and $x$ is not a subset (or, x is a subset that consists of only one element, i.e. {1}), then does $xâˆ©A=âˆ…$? I'm trying to understand how $xâˆ©\{1,2,3\}=âˆ…$ (2)How does this guarantee no infinitely descending sequences? Thank you for your time.",['elementary-set-theory']
438597,Question about the proof that a countable union of countable sets is countable,"Can One explain me a bit about  the Hence 2.12 Theorem Let $\{E_n\}$ , where $n=1,2,3,...$ , be a sequence of countable sets, and put $S=\underset{n=1}{\overset{\infty }{\cup }}E_n$ . Then $S$ is countable. Proof Let every set $E_n$ be arranged in a sequence $\left\{x_{\text{nk}}\right\},k=1,2,3,\text{...},$ and consider the infinite array (16) in which the elements of $E_n$ form the nth row. The array contains all elements of $S$ . As indicated by the arrows, these elements can be arranged in a sequence (17) $x_{11};x_{21},x_{12};x_{31},x_{22},x_{13};x_{41},x_{32},x_{23},x_{14};\text{...}$ Sentence 1 If any two of the sets $E_n$ have elements in common, these will appear more than once in (17). Sentence 2 Hence there is a subset $T$ of the set of all positive integers such that $S\sim T$ , which shows that $S$ is at most countable. Since $E_1\subset S$ , and $E_1$ is infinite, $S$ is infinite, and thus countable. Problem :
What's the relation between sentence 1 and sentence 2?",['elementary-set-theory']
438608,A sequence raised to a sequence,"I was wondering if the following is true... If $(a_{n})$ is a sequence of positive terms converging to $a$ and $(b_{n})$ is a real sequence converging to $b$, then the sequence $(a_{n}^{b_{n}})$ converges to $a^{b}$. This is what I did $$ a_{n}^{b_{n}} = e^{b_{n}\ln{a_{n}}}$$ Now as the logarithm function is continuous, we have, for a fixed $m$ $$ \lim\limits_{n\to \infty}a_{n}^{b_{m}} = e^{b_{m}\ln{a}} $$ Now as exponential is continuous, we have our result. Is every step here correct? I am skeptical because this is an important result and the proof is easy (if it is correct) and yet it is not found in real analysis books. EDIT: We have $(1 + 1/n) \to 1$ and $n\to \infty$ and $(1 + 1/n)^{n} \to e$. Does this qualify as a counterexample? Is the result only true for finite $a$ and $b$?","['sequences-and-series', 'real-analysis']"
438623,The union of a countable set of countable sets?,"Let $A$ be an countable set, and let $B_n$ be the set of all $n$ -tuples $\left(a_1,\ldots,a_n\right)$ $B_n$ is the union of a countable set of countable sets. This question maybe about the English. Is my rephrase right? $B_n$ is a countable set as the union of countable sets. I think the quoted sentece has some problems in grammar or others? Of course, that's only my judge, I'm not a native speaker and not so confident in the judge, so I asked this.","['terminology', 'elementary-set-theory']"
438633,Unbiased family of estimators and variance.,"Given $X_1, \dots, X_n$ simple random sample with distribution $F_X$ -unknown-, i have to estimate $\mu = \mathrm{E}(X)$. Now, given the famility of estimators $\tilde{T} = \bigg\{\displaystyle\sum_{i=1}^n \alpha_iX_i : \ \displaystyle\sum_{i=1}^n \alpha_i = 1\bigg\}$. I have to (1) Prove that if $\hat{\mu} \in \tilde{T},$ then $\hat{\mu}$ it's unbiased; and (2) Show that for every estimator $\beta \in \tilde{T}$, $\mathrm{Var}(\bar{X_n})<\mathrm{Var}\{\beta\}$. Here's my attempt: (1) $\hat{\mu} \in \tilde{T} \implies \hat{\mu} = \displaystyle\sum_{i=1}^n \alpha_iX_i \implies \mathrm{E}(\hat{\mu}) = \mathrm{E}\bigg(\displaystyle\sum_{i=1}^n \alpha_iX_i\bigg) = \displaystyle\sum_{i=1}^n \alpha_i\mathrm{E}(X_i)$. Now, since $X_1,\dots, X_n$ it's a sample mean, then all of them have the same distribution, let's say $X$. Follows $\mathrm{E}(\hat{\mu}) = \displaystyle\sum_{i=1}^n \alpha_i\mathrm{E}(X_i) = \displaystyle\sum_{i=1}^n \alpha_i\mathrm{E}(X) = \mathrm{E}(X)\displaystyle\sum_{i=1}^n \alpha_i = \mathrm{E}(X)$ and then follows $ \hat{\mu}$ unbiased ? (2) I know that $\mathrm{V}(\bar{X}) = \displaystyle\frac{\sigma^2}{n}$, if $\mathrm{V}(\beta) < \displaystyle\frac{\sigma^2}{n}$ and since $\beta \in \tilde{T}$ we have $\beta = \displaystyle\sum_{i=1}^n \beta_iX_i$ for $\beta_i$ scalars, then $\mathrm{V}(\beta) =\mathrm{V}\bigg(\displaystyle\sum_{i=1}^n \beta_iX_i\bigg) = \displaystyle\sum_{i=1}^n \beta_i^2\mathrm{V}(X_i) > \displaystyle\sum_{i=1}^n \mathrm{V}(X_i) = n\sigma ^2$ and should be $n\sigma ^2 < \displaystyle\frac{\sigma^2}{n}$. And follows that the assumption was wrong.",['statistics']
438647,Tricky detail in the proof of Haar's theorem,"I'm trying to dig in the details of the proof of Haar's theorem, and at some point I need to use Fubini's theorem, which requires that if we want to change the order of integration over the product space $X  \times Y$, the spaces $X$ and $Y$ must be complete measure spaces. (In my case, they are topological measure spaces and my measure is also defined over the completion of their $\sigma$-algebras, but in order to have a topological measure space, I restrict the measure to the Borel $\sigma$-algebra). However, I am working with a continuous function (the one I am integrating). I am wondering if the following holds : given a continuous function $h : X \times X \to \mathbb C$ where $(X, \mathcal T)$ is a topological space, $(X, \Sigma, \mu)$ is a complete measure space and $\sigma(\mathcal T) \subseteq \Sigma$ (the Borel sets are measurable), is it possible to show that $h$ is measurable with respect to $\overline{\sigma}(T) \times \overline{\sigma}(\mathcal T)$? (Here $\overline{\sigma}$ denotes the completion of the $\sigma$-algebra generated by $\mathcal T$.) This will imply I can use Fubini. Note that my measure $\mu$ comes from Haar's theorem, so if it helps, it is non-zero and inner/outer regular. Perhaps the following could be easier to prove : if $f : (X, \mathcal T_X) \to (Y, \mathcal T_Y)$ is a continuous function, is $f$ measurable with respect to $\overline{\sigma}(\mathcal T_X)$ and $\overline{\sigma}(\mathcal T_Y)$? I guess it's false if you put the zero measure on $Y$ because then the completion is just the trivial $\sigma$-algebra, but in my case I am working with $\mathbb C$ and the Lebesgue measure, so perhaps I can find my way around it. All the proofs I've read seem to hide this tricky detail that the assumptions of Fubini must be satisfied...","['topological-groups', 'measure-theory']"
438648,Trigonometry Equations.,"Solve for $0 \leq X \leq 360$, giving solutions correct to the nearest minute where necessary,
a) $\cos^2 A -8\sin A \cos A +3=0$ Can someone please explain how to solve this, ive tried myself and no luck. Thanks!",['trigonometry']
438684,"Polar decompostion should be a diffeomorphism, right?","I seem to have gotten stuck in the mud verifying what I thought was going to be a completely straightforward fact. I would appreciate if somebody could help dig me out. Inside the $n \times n$ complex matrices $M_n(\mathbb{C})$, let $U, GL, GL_+$ denote, respectively, the unitary matrices, invertible matrices and positive invertible matrices. I was trying to check: The multiplication map $F : U \times GL_+ \to GL$ sending $(u,p) \mapsto up$ is a diffeomorphism. Everything here is being viewed as a submanifold of the $2n^2$-dimensional Euclidean space $M_n(\mathbb{C})$. Even though all the scalars here are complex, the objects are being viewed as real manifolds. Some relevant facts: I calculated the tangent spaces to $U$ and got $T_u(U) = \{ a \in M_n(\mathbb{C}) : u^*a + a^*u = 0 \}.$ That is, $a$ is tangent to $U$ at $u$ if and only if $u^*a$ is anti-self-adjoint.  In particular, $T_1(U)$ is the anti-self-adjoint matrices. $GL_+$ is an open subset of the vector space $SA \subset M_n(\mathbb{C})$ of self-adjoint matrices. So, $T_p(GL_+) = SA$ for all $p \in GL_+$. $GL$ is an open subset of $M_n(\mathbb{C})$ so $T_a(GL) = M_n(\mathbb{C})$ for all $a \in GL$. Since $F$ is a bijection (polar decomposition), we will be done if we can show that $F$ has invertible derivative everywhere. The derivatives are given by $DF_{(u,p)} (a,b) = ap + ub$. I figured the easiest thing to do would be to check that this linear map always has zero kernel (since the domain and codomain are manifolds of the same dimension). Look how well this works at the point $(1,1) \in  U \times GL_+$! If $DF_{(1,1)}(a,b) = a+b = 0$ (where $a$ is anti-self-adjoint and $b$ is self-adjoint) then, taking adjoints, we also have $-a + b = 0$. Combining these equations gives $a = b = 0$. But, I get stuck checking injectivity at other points. Even, say, at $(1,p)$ where $p \in GL_+$. Then, if we take $(a,b) \in T_{(1,p)}(U \times GL_+)$ (i.e. $a^* = -a, b^* = b$) and assume that $DF_{(1,p)}(a,b) = b + ap = 0$, I get stuck doing all sorts of crazy algebra trying to deduce $a=b=0$.","['multivariable-calculus', 'linear-algebra', 'manifolds']"
438686,Reference for relation between class number of $\Bbb Q[\sqrt{-p}]$ and partial quotients of $\sqrt p$,"So in Ireland and Rosen's, ""Classical Introduction to Modern Number Theory"", they mention the following incredible fact at the end of Chapter 13, section 1. Suppose $p \neq 3$ and $p \equiv 3 \pmod 4$ and $\mathbb Q[\sqrt{p}]$ has class number one. Let $\sqrt{p}=[a_{0}, \overline{a_1 ,\ldots a_{n}}]$ be its continued fraction expansion. Then $\frac{1}{3}(a_n - a_{n-1} + \ldots \pm a_1)$ is the class number of $\mathbb Q[\sqrt{-p}]$. The fact is attributed to Hirzebruch, and I have no clue how it is proven, and am unable to find a proof. Talking to a professor and a little research revealed that this has something to do with the Hilbert modular surface. I would appreciate some help in understanding this incredible fact!","['continued-fractions', 'complex-geometry', 'number-theory', 'algebraic-number-theory', 'reference-request']"
438688,Why is $\sin^2x + \cos^2x = 1$ important?,"To start off, I understand the proof behind this identity, and I can visualize it in my head with the unit circle. But I read this quote: They only need to remember three facts â€“ that $\sin 30^\circ = Â½$ , that $\tan 45^\circ =1$, and that $\sin^2x + \cos^2x =1$ .  Just about everything else they need to know about trigonometry can be derived from these. and I realized I don't have a complete understanding on practical use of the identity.  Therefore I am looking for an explanation and some practical examples on why it is so important. Thanks for your help!","['trigonometry', 'calculus']"
438691,How does knowing a function as even or odd help in integration ??,"So, I am learning Fourier Series and it involves integration. I am not too good at integration. Now, the resource I use is videos by Dr. Chris Tisdell . In the opening video he says that knowing whether the function as even or odd will greatly simplify the integration process. So, I have two questions: 1. What is even/odd function? 2. How will that simplify integration ?","['fourier-series', 'integration']"
438710,Proof for the total derivative of a function,"I'd be interested to understand why is the total derivative of a function $f(t,x,y)$, where $x = x(t)$ and $y=y(t)$ defined as: $$\frac{df}{dt} = \frac{\partial f}{\partial t}\frac{dt}{dt} + \frac{\partial f}{\partial x}\frac{dx}{dt} + \frac{\partial f}{\partial y}\frac{dy}{dt}$$ This formula seems intuitive to me, but if I would need to prove the general case analytically, how would I do it? :) Thank you for any help! :)","['multivariable-calculus', 'partial-derivative', 'calculus', 'derivatives']"
438715,Meaning of fractional Fourier transform with imaginary iteration count?,"As one may know, the Fourier Transform $$F[f](\nu) = \int_{-\infty}^{\infty} f(t) e^{-2\pi i \nu t} dt$$ can be iterated, and this iteration generalized to fractional iteration count via $$F^h[f](\nu) = \sqrt{1 - i \cot\left(\frac{\pi h}{2}\right)} e^{i\pi \cot\left(\frac{\pi h}{2}\right) \nu^2} \int_{-\infty}^{\infty} e^{-i 2\pi \left( \csc\left(\frac{\pi h}{2}\right) \nu t - \frac{\cot\left(\frac{\pi h}{2}\right)}{2} t^2\right)} f(t) dt$$. This can be interpreted, in a sense, as ""rotating"" $f$ between the time and frequency domain. In particular, $h = 1/2$ corresponds to a half-way rotation -- half-way between time and frequency. $h = -1$ is the inverse Fourier transform. $h = 2$ (i.e. $F \circ F$) is the ""mirror-image"" transform, that is, the time reversal of $f$, or $f(-t)$. The above formula may be written without the $\frac{\pi}{2}$ factors, which parameterizes it more directly in terms of the angle as an actual radian angle, with $\frac{\pi}{2}$ radians, i.e. a right angle, being the angle at which the frequency domain lies to the time one. But what is the interpretation and meaning of the above when $h = i$, that is, a single imaginary iteration of the transform? What does the ""spectrum"" given by $F^i[f]$ mean? More generally, what happens with $h = 2i$, $h = 3i$, etc.? EDIT: I note that for such positive-imaginary $h$, the kernel in the integrand grows quickly because the exponent becomes real (note that $\csc(ix) = -i\ \mathrm{csch}(x)$ and $\cot(ix) = -i \coth(x)$ and these get multiplied by $-i 2\pi$, turning them real), suggesting a strong decay of $f$ is required to get convergence, unless perhaps we can abuse analytic continuation from the real iteration counts in other cases somehow, though I think that might not yield a unique result. However it does seem to work better for negative -imaginary $h$, i.e. $h = -i$, $h = -2i$, etc. . Perhaps exploring those would be better? EDIT 2: Perhaps an example would be in order. Let $$f(t) = \begin{cases} 1, \mbox{if } |t| \le 1 \\ 0, \mbox{otherwise} \end{cases}$$, i.e. the ""boxcar"" function, or a fixed-width pulse in the time domain. Since the support is compact, the integral will converge. If we take the usual Fourier transform, $F^1[f] = F[f]$, we get a sinc function as the result. We can interpret this as a frequency spectrum of the original $f$, and it contains mostly low-frequency content, with little ripples of higher frequencies. But, suppose we take the imaginary Fourier transform -- one imaginary iteration of $F$, or $F^i$. What we get cannot be expressed in elementary terms, however we can use the ""imaginary error function"" to get a ""closed form"" of sorts: $$F^i[f](\nu) = \frac{\sqrt{1 â€“ \coth\left(\frac{\pi}{2}\right)}}{2 \sqrt{\coth\left(\frac{\pi}{2}\right)}} e^{\pi \left(\coth\left(\frac{\pi}{2}\right) â€“ \mathrm{csch}\left(\frac{\pi}{2}\right) \mathrm{sech}\left(\frac{\pi}{2}\right)\right) \nu^2} \\ \left(\mathrm{erfi}\left(\frac{2\pi \coth\left(\frac{\pi}{2}\right) â€“ 2\pi \mathrm{csch}\left(\frac{\pi}{2}\right) \nu}{2 \sqrt{\pi \coth\left(\frac{\pi}{2}\right)}}\right) â€“ \mathrm{erfi}\left(\frac{-2\pi \coth\left(\frac{\pi}{2}\right) â€“ 2\pi \mathrm{csch}\left(\frac{\pi}{2}\right) \nu}{2 \sqrt{\pi \coth\left(\frac{\pi}{2}\right)}}\right)\right)$$ Now the $1 - \coth\left(\frac{\pi}{2}\right)$ under the one square root sign is negative, so $F^i[f]$ is purely imaginary at each $\nu$. At $0$, it is about $3.338i$, and grows very quickly as we move toward the positive and negative $\nu$ directions. What kind of ""spectrum"" is this ? What is it telling us about the boxcar function?","['fourier-analysis', 'analysis']"
438743,Quadratic Bezier curves representation as implicit quadratic equation,"A quadratic bezier curve from points P1=(x1, y1) to P3=(x3, y3) with control point P2=(x2, y2) can be represented as parametric quadratic curve P(t) where t is in [0, 1] . $$P(t) = (P_1t + P_2(1 - t))t + (P_2t + P_3(1 - t))(1 - t)
         = P_1t^2 + P_2(1 - t)t + P_3(1 - t)^2$$ We can extend the range of t to be all real numbers, from minus infinity to plus infinity, and then we will get a nice curve dividing the plane in two. I read somewhere, that this infinete curve is either a straight line (if P1 , P2 and P3 are colinear) or a parabola. Could you please confirm that? Since division of plane by a parabola or a line can be expressed by quadratic equation of form: Point P=(x, y) is 
  on one side  if F(P) > 0
  on the other if F(P) < 0
  on the curve if F(P) == 0
where F(P) = A * x^2 + B * y^2 + C * x * y + D * x + E * y + F How can we, starting from points P1, P2, P3 calculate the numbers A, B, C,D, E, F ? I think something similar is done in this wolfram demostration http://demonstrations.wolfram.com/FocusAndDirectrixInAQuadraticBezierCurve/ Thank you","['geometry', 'linear-algebra', 'algebraic-geometry']"
438744,Is it always true that $\det(A^2+B^2)\geq0$?,"Let $A$ and $B$ be real square matrices of the same size. Is it true that
$$\det(A^2+B^2)\geq0\,?$$ If $AB=BA$ then the answer is positive:
$$\det(A^2+B^2)=\det(A+iB)\det(A-iB)=\det(A+iB)\overline{\det(A+iB)}\geq0.$$","['matrices', 'linear-algebra', 'determinant']"
438764,Closed form for $a_{n+1} = (a_n)^2+\frac{1}{4}$,"I've been given the following sequence:
\begin{align*}
&a_0 = 0; \\
&a_{n+1} = (a_n)^2+\frac{1}{4}.
\end{align*} I also have to prove that whatever I come up with is correct, but that will likely be the easy part. Here are the first few values: \begin{align}
&a_0 = 0 \\
&a_1 = \frac{1}{4}\\
&a_2 = \frac{5}{16}\\
&a_3 = \frac{89}{256} \\
&a_4 = \frac{24305}{65536}
\end{align} I've managed to to determine that the denominators are of the form $2^{2^n}$. I've tested up to one million terms of this sequence and it appears that $\lim_{n\rightarrow\infty}a_n = \frac{1}{2}$. I spent a while trying to find something of the form $a_n = \frac{P(n)}{Q(n)}$. I haven't had any luck with this, so I started looking into some sums. I've found that 
\begin{align*}
a_2 = \frac{1}{4} + \frac{1}{16} = \frac{5}{16}
\end{align*}
and, 
\begin{align*}
a_3 = \frac{1}{4} + \frac{1}{16} + \frac{1}{32} + \frac{1}{256} = \frac{89}{256}
\end{align*} But now, 
\begin{align*}
a_4 = \frac{1}{4} + \frac{1}{16} + \frac{1}{32} + \frac{1}{64} + \frac{1}{128} + \frac{1}{512} + \frac{1}{1024} + \frac{1}{2048} + \frac{1}{4096} + \frac{1}{65536}= \frac{24305}{65536}.
\end{align*} So it seems that there is some type of sum involving negative powers of 2 going on, but it isn't clear to me that there is even a pattern here. Any hints/help would be appreciated!","['recurrence-relations', 'sequences-and-series']"
438766,Volume of irregular solid,"I need to calculate volume of irregular solid which is having fix $200 \times 200$ width and breadth but all four points varies in depth. I have table which gives depth at each point. How to calculate volume of such solid? Hi, I am giving here my main problem definition.
I have a grid with size  $200 \times 200$  and the depth at each point is given in array.
For  $2 \times 4$ grid, below is the depth level. And i need to find volume of such solid. 537.52,    707.52,    742.52,    719.52,    654.52 631.52,    783.52,    795.52,    764.52,    727.52 597.52,    868.52,    846.52,    793.52,    707.52 In Image i have tried to plot first grid cell. Any help/pointer/suggestion would be real help. I found some post related to this. But not sure which will give best result. http://tutorial.math.lamar.edu/Classes/CalcI/MoreVolume.aspx (Example 2) and link 2 answers.yahoo.com/question/index?qid=20080804220134AA8skGw Please comment your views.
Thanks a lot in advance.","['geometry', 'volume']"
438771,Solutions of Elliptic PDEs: scaling and ellipticity,"Suppose we have a weak solution of the uniformly elliptic equation $$\sum_{i,j=1}^n D_i(a_{i,j}(x)D_j u(x)) = 0$$ in all of $\mathbb{R}^n$ Where $a_{i,j}$ are bounded and measurable and $D_i$ represents the partial derivative with respect to $x_i$. Consider the scaling $y=\frac{x}{r}$ for some $r>0$ Can I say that for all $r>0$,  $u(rx)$  is a (weak) solution of another elliptic equation with the same ellipticity constant, in the unit ball $B(0,1)$  ?? Thank you.","['multivariable-calculus', 'partial-differential-equations', 'real-analysis']"
438779,Get the number of digits from a number,"I'm looking for a function $f$ that would give me the following results : For any $x$ such as  $ x \in \mathbb {N^*}, x>0 $ $f(x) = 1 $ when  $1\leq x < 10$ $f(x) = 2 $ when  $10\leq x < 100$ $f(x) = 3 $ when  $100\leq x < 1000$ and so on ... So far , I have tried the floor function with no success.","['functions', 'real-analysis']"
438788,Trigonometric problem : Eliminate $\theta$ and $\phi$ from the relation and find relation between p and q,"Question : Eliminate $\theta$ and $\phi$ from the relation $$\begin{align}
p \cot^2\theta + q \cot^2\phi &= 1 &(1)\\
p \cos^2\theta + q \cos^2\phi &= 1 &(2)\\ 
p \sin\theta  &= q\sin\phi &(3)
\end{align}$$ Also find relation between $p$ and $q$. I have tried different ways but unable to eliminate $\theta$ and $\phi$. One method: If I subtract equations $(1)$ and $(2)$  then I got: $$p\frac{\cos^4\theta}{\sin^2\theta} +q \frac{\cos^4\phi}{\sin^2\phi}=0$$ Please guide how to solve this.. thanks..",['trigonometry']
438802,Why does $\int\limits_0^1 {\dfrac{{x - 1}}{{\ln x}}} \;\text{d}x=\ln2$? [duplicate],"This question already has answers here : Showing that $ \int_{0}^{1} \frac{x-1}{\ln(x)} \mathrm dx=\ln2 $ (3 answers) Closed 10 years ago . I have found that $$\int\limits_0^1 {\dfrac{{x - 1}}{{\ln x}}} \;\text{d}x=\ln2$$ but I can't prove it.
Any hint? Thank you in advance","['improper-integrals', 'calculus']"
438840,Find the method of moments estimator of theta,"Let $Y_1, Y_2, \dots, Y_n$ be i.i.d RVs from the following distribution: $$f(y) = \theta y ^{\theta -1} \qquad  0 < y < 1, \quad\theta > 0$$ Show the method of moment estimator of theta is: $\bar Y/(1-\bar Y)$ I must only be seeing solutions that skip steps, because I cannot come to this answer. I can get up to this part (which I believe is in the right track): $$E(y) = \int_0^1 y \theta y^{\theta -1}\,dy,$$ which leads to $E(y) = \theta/(\theta + 1)$ But I do not know how to proceed from there....",['statistics']
438853,Prove that the maximum number of edges in a graph with no even cycles is floor(3(n-1)/2),"The question is in the title. I can see why the bound is sharp (for example, a lot of triangles sharing one common vertex if n is odd, or the same but with one spare edge hanging out if n is even). But I can't prove why the bound is the best possible. I know that each edge must belong to at most one cycle. I was thinking that you could take any path or odd big odd cycle and turn it into bunch of triangles wherever possible, but I think that might not be valid because a lot of greedy local optimums isn't necessarily the global optimum. So what do I do? I tried looking online for an answer before posting this and all I could find is this: Link Is the reasoning faulty there? I couldnâ€™t make sense of it after it talked about decomposing into cycles. Thanks for any help","['extremal-combinatorics', 'graph-theory', 'discrete-mathematics', 'combinatorics']"
438905,Solving a system of non-linear (trig) equations:,I am having trouble trying to solve the following equations: $\sin(\alpha)+\sin(\beta)=\dfrac {1000} A$ $\sin(\alpha)+\sin(\gamma)=\dfrac {800} A$ $\dfrac {20(1+\cos(\alpha-\beta))} {\cos(\beta)} -\dfrac {20(1+\cos(\alpha-\gamma))} {\cos(\gamma)}-.225=0$ I tried plugging into MatLab using fsolve() and it gave me values that do not solve the all three of the equations.  Trying to expand in a taylor series gets really ugly really fast.  So does anyone have any advice on how to solve these.  Thanks,"['nonlinear-optimization', 'trigonometry', 'nonlinear-system']"
438933,Finite group is abelian if the representatives of its conjugacy classes commute,"Let $G$ be a finite group and let $g_1 , g_2 ,...,g_r$ be the representatives of its conjugacy classes. If $g_i g_k=g_k g_i$ for every $i,k \in$ {$1,2,...,r$}, then prove that $G$ is abelian. My original trial was to prove this in arbitrary subgroup of $S_n$
and using Cayley's theorem we can prove this easily, and the reason is we can take advantage of the fact that 
if $\tau , \sigma \in S_n$, $$\sigma = (a_{11} ... a_{1 n_{1}})(a_{21} ... a_{2 n_{2}}) ... (a_{r1} ... a_{r  n_{r}})$$ then $$\tau \sigma \tau ^{-1} = (\tau(a_{11}) ... \tau(a_{1 n_{1}}))(\tau(a_{21}) ... \tau(a_{2 n_{2}})) ... (\tau(a_{r1}) ... \tau(a_{r  n_{r}}))$$ But this didn't give me any valuable results, so any hints which can be useful ? I found a proof of this exercise here , but I want to construct my own proof. Any hints ?","['finite-groups', 'group-theory', 'abstract-algebra']"
438940,distribution of $\cos(\omega_0 n)$ where n are integers?,"Assume we have the sequence $\,x[n]=\cos(\omega_0 n),$ where $n$ are integers. If we suppose these are realizations of a random variable, what would be the p.d.f. of that random variable?","['probability-theory', 'sequences-and-series', 'probability']"
438955,Prove that f(x)=g(x),"Show that if $f,g:\mathbb{R}\to \mathbb{R}$ are continuous and periodic and $\lim_{x\to \infty}[f(x)-g(x)]=0$,
  then $f=g$","['continuity', 'real-analysis', 'periodic-functions']"
438956,Coefficients of this Taylor series are bounded,"Let $f(z)$ be a function that's analytic in the open unit disk, and also in a region containing the closed unit disk with the exception of a few simple poles (i.e. the poles have degree 1) that lie outside the open unit disk. Show that the coefficients of the Taylor expansion of f(z) at 0 (we know its radius is at least the unit disk) are bounded. I could use help with this. What I've tried: we can multiply $f(z)$ by $(z-c_1)(z-c_2)...$ where $c_1,...$ are the singularities to get an analytic function, and then express the series of $(z-c_1)(z-c_2)...f(z)$ in terms of $f(z)$'s series to get a constraint on the coefficients (since the analytic function's coefficients will go to 0). But this is tedious and the constraint doesn't seem good enough to show boundedness. Update: Sorry, it looks like I confused a few people (as seen by the hints below). To clarify, $f$ is analytic in the open unit disk. We're not given analyticity in the closed unit disk. I should also emphasize that the poles are of degree 1 at the most. This isn't a homework question (just an exercise from a textbook), so feel free to post either hints or whole answers.","['power-series', 'complex-analysis']"
438958,double coset question,"Let $G$ be a group and $H$ a subgroup. Consider $H/G\backslash H$ the set of double cosets of $H$ in $G$. Show $H$ is normal in $G$ if and only if the mapping $f$ from $G/H$ into $H/G\backslash H$ defined by
$f(aH) = HaH$ for all $a$ in $G$ is a bijection. The part of $H$ normal in $G$ implies a mapping $f$ is a bijection is easy. (It was a comment in Bourbaki Algebra).",['group-theory']
438976,Show that the matrix $A+E$ is invertible.,"Let $A$ be an invertible matrix, and let $E$ be an upper triangular matrix with zeros on the diagonal. Assume that $AE=EA$. Show that the matrix $A+E$ is invertible. WLOG, we can assume $E$ is Jordan form. If $A$ is Jordan form, it's trivial. If $A$ is not Jordan form, how to use $AE=EA$ to transform $A$ to a Jordan form? Any suggestion? Thanks.","['matrices', 'linear-algebra']"
438979,Taking a convex hull does not increase a supremum of a linear function,"Let $X$ be a topological vector space, let $f:X\to\Bbb R$ be a continuous linear function and let $P(X)$ denote the set of all Borel probability measures on $X$. For any $M\subseteq X$ we define the strong convex hull as
$$
  \operatorname{sco}(M) = \left\{\int y\;\mathrm d\nu: \nu\in P(X) \text{ and } \nu^*(M)  =1\right\}.
$$
Is that true that for any non-empty $M$ it holds that $\sup_M f = \sup_{\operatorname{sco(M)}}f$? In case the latter fact is true, I would be happy if someone can provide a reference to this. I am not sure whether the integral is always defined over topological vector spaces, so the motivation was the case $X=P(A)$ where $A$ is a Borel space, and $P(A)$ is endowed with the topology of weak convergence. In the latter situation the integration is well-defined, but I guess that a similar result shall hold for a more general case as well. Feel free to correct me.","['convex-analysis', 'measure-theory', 'probability-theory', 'reference-request', 'topological-vector-spaces']"
439001,How can I find the value of this limit,$$\lim _{ { x }\to { 0 } }{ \frac { \sin x-\arctan x }{  {x }^{ 2 }\log(1+x) } }$$ this log is natural logarithm,"['calculus', 'limits']"
439005,"What ""is"" a matrix in the context of a vector space?","I'm familiar with the definition of a vector space $V$ over a field $F$ I'm also comfortable with the notion that a matrix ""represents"" a linear map from one vector space $V$ to another vector space $W$. The Wiki article on Vector Spaces says this: Matrices are a useful notion to encode linear maps. But this conflicts with what I think a matrix is. Is a matrix a ""thing"" or ""element"" that we can write down and multiply by other matricies/vectors? Or is it simply a ""representation"" of a linear map between spaces? Does it depend on the context? If it is a ""thing"" - then how do we define the multiplication of objects from the vector space with objects of a different kind that do not belong to the vector space? We can write a meaningful equation such as: $M \cdot \textbf{x} = \textbf{y}$ Where x and y are vectors, and M is a matrix. I know how to perform the multiplication, but it seems wrong to me that $M$ is of a different ""species"" (apologies - I'm not familiar enough with abstract algebra to know the correct classification - set/group/etc.) than the thing we are multiplying it with. Sorry if this is vague, I'm just hoping someone might be able to clear up this slight confusion. Thanks!","['vector-spaces', 'matrices', 'linear-algebra', 'abstract-algebra']"
439014,Presentation of abelian group,"How one can find the abelian group which has a presentation $$\langle x,y,z,w\mid6x+8y+10z+14w, 4x+4y+4z+4w\rangle$$ 
Is there any way indicates the steps to find such a group? Or just by guesswork and experience? Edit: Can one proves directly whether it is the group $\mathbb Z_2 \times \mathbb Z \times \mathbb Z \times \mathbb Z$ or not?","['group-presentation', 'group-theory', 'abelian-groups']"
439023,how to prove this equality,"There are two equalities, $\sinh({\cosh }^{-1}x)=\sqrt { {x }^2-1 }\quad (x>1)$ $\cosh({\sinh}^{-1}y)=\sqrt{1+{y}^2}$ prove this equality please.. how to prove it? i cannot try it.. also, $x={\cosh}^{-1}y=\ln(y+\sqrt{y^2-1})$ is it true?","['inverse', 'functions']"
439030,"If $\tan\alpha$, $\tan\beta$ are roots of $x^2+px+q=0$, evaluate: $\sin^2(\alpha+\beta)+p\sin(\alpha+\beta)\cos(\alpha+\beta)+q\cos^2(\alpha+\beta)$","Question : Knowing that $\tan\alpha$ , $\tan\beta$ are roots of the quadratic equation $x^2+px+q=0$ ; Compute the expression $\sin^2(\alpha +\beta) +p\sin(\alpha +\beta) \cos(\alpha +\beta)+q\cos^2(\alpha +\beta$ ) My Working : Sum of the roots are : $\tan\alpha +\tan\beta = -p; $ product of the roots $\tan\alpha \tan\beta = q; $ After putting these values of roots in the given equation I got : $x^2-(\tan\alpha + \tan\beta) x + ( \tan\alpha \tan\beta) =0$ Please suggest whether is it correct method of approaching this or some other better method. Thanks..",['trigonometry']
439034,Solving Bessel integration,"What would be the solution of the bessels equation,
$$b=k A(t)\int_0^{\infty} J_0 (k \rho) e^ \frac{-\rho^2}{R^2} \rho d \rho$$ Can I sove that by using this formulation?
$$c= \int_0^{\infty}j_0(t) e^{-pt} dt= \frac{1}{\sqrt{1+p^2}}$$","['algebra-precalculus', 'bessel-functions', 'calculus', 'integration']"
439054,Algebraic Groups Problem [duplicate],This question already has answers here : A closed subset of an algebraic group which contains $e$ and is closed under taking products is a subgroup of $G$ (2 answers) Closed 10 years ago . I am currently trying to go through Humphrey's Linear Algebraic Groups and am stuck on a problem that sounds deceivingly simple but can not seem to figure out (Problem 5 from Section 7). I have spent a fair amount of time on it and expect it to be something silly that I just am not seeing. The problem is: A closed subset of an algebraic group which contains e and is closed under multiplication is a subgroup,['algebraic-geometry']
