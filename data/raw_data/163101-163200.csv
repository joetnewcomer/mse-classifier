question_id,title,body,tags
2835149,How to show that $|\nabla f|\ge \sqrt 2$?,"Let $[0,1]^2\subset U\subset \mathbb R^2$ where $U$ is open, and let $f: U\to \mathbb R$ be a differentiable function with $f(0,0)=3$ and $f(1,1)=1$. Prove that $|\nabla f|\ge \sqrt 2$ somewhere in $U$. The only idea I had is to apply Taylor's formula but it only gives something like $-2=f(1,1)-f(0,0)=f_x(1,1)+f_y(1,1)$, which holds at a point, and I guess ""somewhere"" means ""on a subset"". Moreover, I don't know how to get hold of $f_x^2+f_y^2=||\nabla f|| ^2$. Any hints please? (If I only use hints as opposed to reading a solution I hope I will learn more.)","['multivariable-calculus', 'real-analysis', 'calculus', 'derivatives']"
2835168,Doubt in passing in the demonstration of Carathéodory's theorem,"someone can help with the passage marked in red. I've tried in many ways using the definition, but to no avail. This theorem is found in Bartle's book The Elements of Integration and Lebesgue measure on page 142. Definition 13.3 that is needed at this beginning of the demonstration and the condition of Carathéodory $m^*(A)= m^*(A \cap E)+m^*(A \cap E^c)$.",['measure-theory']
2835226,Prove that a function is affine,"Let $f,g:\mathbb R\to \mathbb R$ be functions such that 
  $$f(x+h)=f(x)+g(x)h+\alpha(x,h)$$ for all $x,h\in \mathbb R$, where
  $|\alpha(x,h)|\le Ch^3$. Show that $f(x)=ax+b$ for some $a,b\in
 \mathbb R$. I think the way I'm supposed to prove this is by showing that $f'(x)$ is identically constant. The derivative of $f$ at $x$ is $\lim_{h\to 0}\frac{f(x+h)-f(x)}{h}$. I can write the given condition as $$\left|\frac{f(x+h)-f(x)}{h}\right|\le |g(x)| + Ch^2,$$and as $h\to 0$, we get $|f'(x)|\le |g(x)|$. Am I on the right track? Any further hints?","['derivatives', 'real-analysis', 'calculus', 'limits']"
2835240,What does the Lindelöf hypothesis imply?,"I recently read this article ( https://viterbischool.usc.edu/news/2018/06/mathematician-m-d-solves-one-of-the-greatest-open-problems-in-the-history-of-mathematics/ ) about someone who may have proven the Lindelöf hypothesis which states that the Riemann zeta-function behaves on the critical line as
$$\zeta(1/2 + it)=O(t^\varepsilon)$$
for any $\varepsilon > 0$. The article is very vague, so what implications a proof of the Lindelöf hypothesis would have? For example on the distribution of prime numbers or the Riemann hypothesis?","['number-theory', 'riemann-hypothesis', 'prime-numbers']"
2835269,Prove by induction that $2^n\le (n+1)!$ for all $n\in\Bbb N$. [duplicate],"This question already has answers here : Prove by induction: $n! \ge 2^{(n-1)}$ for any $n \ge 1$ [duplicate] (4 answers) Closed 5 years ago . Prove by induction that $2^n\le (n+1)!$ for all $n\in\Bbb N$ . What I've done so far is prove for $n=1$ : $$2^1 \le (1+1)!,$$ $$2 \le 2,$$ which is correct Then I tried to prove for $n+1$ , in other words, I want to get here: $$2^{n+1}\le(n+2)!.$$ So, I multiplied everything with $2$ : $$2\cdot 2^n \le2\cdot (n+1)!,$$ $$2^{n+1} \le2(n+1)n!.$$ So I already have what I wanted in the left part of the inequality, but I'm stuck for the right part. Can someone help me?
Thanks!","['inequality', 'algebra-precalculus', 'induction', 'sequences-and-series', 'discrete-mathematics']"
2835271,Problem defining a function via Step function and Dirac's Delta,"First: I know Dirac's Delta isn't a function and hence shouldn't be treated like one. But this arose in a physics textbook so I'm looking for an answer that oversees that. Consider the following function:
$$f(x) = \begin{cases} \cos x , \quad \textrm{if} \quad  -\pi/2 < x < \pi/2 \\
0, \quad \textrm{otherwise} \end{cases}$$
And I want $f''(x)$. So I can just differentiate two times directly, to obtain:
$$f(x) = \begin{cases} -\cos x , \quad \textrm{if} \quad  -\pi/2 < x < \pi/2 \\
0, \quad \textrm{otherwise} \end{cases}$$
However, if I decide to write:
$$f(x) = H(-\pi/2)\cos x - H(\pi/2)\cos x$$
($H(x)$ stands for Heaviside's step function). 
I can't differentiate twice. Moreover, if I decide to write:
$$f'(x) = - H(-\pi/2)\sin x + H(\pi/2)\sin x$$
I'll obtain:
$$f''(x) = -\delta(-\pi/2)\cos x + \delta(\pi/2)\cos x$$ 
However
$$\int f''(x) dx = - \cos(-\pi/2) + \cos (\pi/2) = 0$$
Which also doesn't make sense. Now, for another problem (where the discotinuity at the first derivative occured in a point where $f(x) \neq 0$) the author used Dirac's Delta and Heaviside to obtain the derivative. But here he just claims that since $f(x) = f''(x)  = 0$ at the end points, we shouldn't worry about the deltas and just differentiate directly (as I did) to obtain the correct expression. My question comes from the fact that I can seemingly define the function and it's first derivative in the three ways I did, and the three ways give me different expressions for the second derivative. Why?","['derivatives', 'dirac-delta', 'calculus']"
2835289,Showing a sequence/process is a positive martingale,"For $(M_t)_{t\geq0}$ to be a martingale w.r.t a filtration $\mathcal{F}_t$, we require $M_t \in L^1$ $E[M_t \mid \mathcal{F}_s] = M_s$, $t\geq s$ If it is known that $M_t \geq 0$, does one have to prove condition 1? Or does it fall out of condition 2 since
$$E[M_t] = E[E[M_t \mid \mathcal{F}_0]] = E[M_0] < \infty?$$
My concern is whether the law of iterated expectations holds if we don't know apriori that $M_t \in L^1$. Relatedly, are there examples of stochastic processes where $M_t \notin L^1$ but $E[M_t \mid \mathcal{F}_s] = M_s$?","['stochastic-processes', 'probability-theory', 'martingales']"
2835290,Moment generating function of the average of two variables,"I am given two variables $Y_1$ and $Y_2$ obeying an exponential distribution with mean $\beta= 1$ We are asked what the distribution of their average is and the solution must be found using moment generating functions. The solution to this exercise says: Well first, the solution already has a typo since it should be $E[e^{t((1/2)Y_1+(1/2)Y_2)}]$ but moreover, I don't agree that $E[e^{t((1/2)Y_1+(1/2)Y_2)}]=M_{Y_1}(t)M_{Y_2}(t)$ Since $M_{Y_1}(t)M_{Y_2}(t)=E[e^{t(Y_1+Y_2)}]$, from my understanding. So what is the actual solution to this problem?","['calculus', 'probability-distributions', 'statistics', 'probability', 'moment-generating-functions']"
2835297,"A direct proof for $\int_0^x \frac{- x \ln(1-u^2)}{u \sqrt{x^2-u^2}} \, \mathrm{d} u = \arcsin^2(x)$","I have been trying to evaluate
$$ f(x) \equiv \int \limits_0^\infty - \ln\left(1 - \frac{x^2}{\cosh^2 (t)}\right) \, \mathrm{d} t $$
for $x \in [0,1]$ and similar integrals recently. I know that
$$ \int \limits_0^\infty \frac{\mathrm{d} t}{\cosh^z (t)} = \frac{2^{z-2} \Gamma^2 (\frac{z}{2})}{\Gamma(z)} $$
holds for $\operatorname{Re} (z) > 0$, so by expanding the logarithm I found that
$$ f(x) = \frac{1}{2} \sum \limits_{n=1}^\infty \frac{(2n)!!}{n^2 (2n-1)!!} x^{2n} \, .$$
But the right-hand side is the power series of the arcsine squared, so $f(x) = \arcsin^2 (x)$. On the other hand, the substitution $u = \frac{x}{\cosh(t)}$ in the original integral leads to the representation
$$ f(x) = \int \limits_0^x \frac{- x \ln(1-u^2)}{u \sqrt{x^2-u^2}} \, \mathrm{d} u \, ,$$
for which Mathematica (or WolframAlpha if you're lucky) gives the correct result. I would like to compute this integral without resorting to the above power series and thereby find an alternative proof for the expansion. I have tried to transform the integral into the usual form
$$ \arcsin^2 (x) = \int \limits_0^x \frac{2 \arcsin(y)}{\sqrt{1-y^2}} \, \mathrm{d} u $$
and thought about using the relations
$$ \arcsin(x) = \arctan\left(\frac{x}{\sqrt{1-x^2}}\right) = 2 \arctan\left(\frac{x}{1+\sqrt{1-x^2}}\right) \, , $$
but to no avail. Maybe the solution is trivial and I just cannot see it at the moment, maybe it is not. Anyway, I would be grateful for any ideas or hints.","['integration', 'definite-integrals', 'power-series']"
2835298,Determination of the unitary irreps of $\mathbb{R}$ using Stone's theorem,"I've tried to find the unitary irreducible representations of the additive group $(\mathbb{R},+)$ and came up with a pair of results, which I want to verify if are correct. They are: Theorem: Let the additive group $G=(\mathbb{R},+)$ be given. Then any unitary representation $U : G\to \mathfrak{U}(\mathscr{H})$ acting on the Hilbert space $\mathscr{H}$ is isomorphic to a unitary representation $U^\diamond : G\to \mathfrak{U}(L^2(X,d\mu))$ for some measure space $(X,\mu)$ given by $[U^\diamond(t)\Psi](x)=e^{-ita(x)}\Psi(x)$ for a real $a\in L^2(X,d\mu)$. Proof: Since a unitary representation is given by a continuous homomorphism $U$ on the strong topology, this means that $U$ is actually a strongly continuous $1$-parameter group of unitary operators, after all, $U(t+s)=U(t)U(s)$. Hence Stone's theorem guarantees that there is one hermitian operator $A$ in $\mathscr{H}$ such that $U(t) = e^{-itA}$. This in turn can be rigorously characterized by the spectral theorem. Since $A$ is hermitian, there is a measure space $(X,\mu)$ and a unitary isomorphism $\chi : \mathscr{H}\to L^2(X,d\mu)$ such that if we define $A^\diamond = \chi A\chi^\dagger$ then $A^\diamond$ is a multiplication operator in the sense that there is $a\in L^2(X,d\mu)$ which is actualy real, satisfying $$[A^\diamond\Psi](x)=a(x)\Psi(x),\quad \forall x\in X.$$ In that case we can perfectly define $e^{-itA^\diamond}$ as $$[e^{-itA^\diamond}\Psi](x)=e^{-ita(x)}\Psi(x),\quad \forall x\in X.$$ Hence we may as well define $$e^{-itA}=\chi^\dagger e^{-itA^\diamond}\chi.$$ But here $U^\diamond(t)=e^{-itA^\diamond}$ provides a unitary representation of $G$ on $L^2(X,d\mu)$ and so the last equation shows that $\chi$ becomes a representation isomorphism between it and the original one, completing the proof. Corolary: Let the additive group $G = (\mathbb{R},+)$ be given. Then the irreducible representations are parametrized by $\lambda \in \mathbb{R}$ and given by $U^\diamond : G\to \mathfrak{U}(L^2(X,d\mu))$ given by $U^\diamond(t)=e^{-i\lambda t}\mathbf{1}$ where $\mathbf{1}$ is the identity operator and $(X,\mu)$ is a measure space. Proof : Let an irreducible representation $U : G\to \mathfrak{U}(\mathscr{H})$ be given. By the previous theorem it is isomorphic to a representation $U^\diamond : G\to \mathfrak{U}(L^2(X,d\mu))$ characterized by a real function $a\in L^2(X,d\mu)$ so that $U^\diamond(t)= e^{-itA^\diamond}$ for the associate multiplication operator $A^\diamond$. It should be obvious that $A^\diamond$ commutes with $U^\diamond(t)$ for every $t$. Hence this means $$[U^\diamond(t),A^\diamond]=U^\diamond(t)\circ A^\diamond - A^\diamond \circ U^\diamond(t) = 0.$$ Hence by Schur's lemma, since the representation is irreducible, $A^\diamond$ acts by a multiple of the identity. Thus $a(x) = \lambda$ for some $\lambda \in \mathbb{R}$ and for all $x\in X$. In turn $U^\diamond(t) = e^{-i\lambda t}\mathbf{1}$ completing the proof. Now I'm unsure if this is correct (I'm actually a bit new to functional analysis). Is the result correct, or have I made some remarkably wrong mistake? Finaly, I feel strange that one arbitrary measure space $(X,\mu)$ is left lurking around. Wasn't it required to have a fully determined $(X,\mu)$ in the irreducible representations?","['proof-verification', 'functional-analysis', 'representation-theory', 'spectral-theory', 'group-theory']"
2835313,Find smallest set of natural numbers whose pairwise sums include 0..n,"Given a positive integer $n$, how do you find the smallest set of nonnegative integers $S$ such that for each integer $m$, where $0\leq m<n$, there exist two (not necessarily distinct) members of set $S$, say $x$ and $y$ such that $x+y=m$. For example, consider the case $n=50$. Suppose the length of $S$ is $L$. 
For a lower bound, if the elements of $S$ have pairwise distinct sums, then there are $\dbinom{L+1}{2}$ sums (the plus 1 is because numbers can be added to themselves). Thus, $$\binom{L+1}{2}\geq50\implies L\geq10$$. I can acheive $L=12$ with the set {0, 1, 2, 3, 7, 10, 15, 18, 22, 23, 24, 25} (done with very inefficient program which searches randomly among all sets). For $L=10$, I feel like it should be impossible; we only have to show that more than 5 numbers can be expressed as a sum in more than 1 way, which should be able to be done through some casework. However, is $L=11$ possible? I think so. Similarly, for $n=100$, I have $L=17$ from my program: {0, 1, 3, 4, 9, 11, 16, 20, 25, 30, 34, 39, 41, 46, 47, 49, 50}. But the lower bound only gives $L\geq 14$, so at least $L=15$ or $L=16$ should be possible. In general, how do you do it efficiently for any given $n$?","['combinatorics', 'discrete-optimization']"
2835319,Ratio limit of volumes,"Let $f:U\to \mathbb{R}^{m}$ be a $C^{1}$ function defined on an open subset $U\subset \mathbb{R}^{m}$. Prove that if $f'(a)$ is not an isomorphism then 
$$\lim_{r\to 0} \frac{\mathrm{vol}~ f(\bar{B}_{r}(a))}{\mathrm{vol}~\bar{B}_{r}(a)}=0.$$ It seems to be necessary to use Sard theorem, but I was not able to do it. I appreciate any help. Edit: Since $f'(a)$ is a linear transformation which is not an isomorphism, $f'(\bar{B}_{r}(a))$ is contained in $\mathrm{Im}~ f'(a)$, which is an hipersurface of $\mathbb{R}^{m}$ such it dimension is smaller than $m$.   Therefore, $f'(\bar{B}_{r}(a))$ has empty interior and thus, $\mathrm{vol}~ f'(\bar{B}_{r}(a))= 0$. Does this imply the thesis?","['multivariable-calculus', 'measure-theory']"
2835326,How can we convert double sums to single sums?,"Let's say that $n\to A(n),B(n)$ is a bijection from $\mathbb{N} \to \mathbb{N^2}$. This would be the inverse of a pairing function . The canonical example would be $B(n)= n-\frac{1}{2}\lfloor \frac{\sqrt{8n+1}-1}{2}\rfloor \lfloor \frac{\sqrt{8n+1}+1}{2} \rfloor $ $A(n) = \lfloor \frac{\sqrt{8n+1}-1}{2}\rfloor-B\left(n\right)$ Then is it the case that $$\sum_{b=0}^\infty \sum_{a=0}^\infty{f(a,b)}=\sum_{n=0}^\infty f(A(n),B(n))?$$ I assume that if I am given that LHS is absolutely convergent the equality holds for any pairing function. I would guess that this is overkill however. If $\sum_{b=0}^\infty \sum_{a=0}^\infty{f(a,b)}$ is conditionally convergent we still may be able to find a suitable $A(n),B(n)$. Questions 1) What conditions are required for this equality to hold? 2) I don't know a whole lot about double sums. Is this a standard technique? Where can I learn more? 3) Where can I find more pairing functions? I can't imagine that the one above is the most convenient to work with... Example Let's say $f(a,b)=\frac{1}{(a+1)^2(b+1)^2}$ Then it's easy enough (Given we know the solution of the Basel problem ) to find the left hand side is $\pi^4/36$. But to find what the righthand side looks like is going to be tricky. We have a new series of rationals that approaches $\pi^4/36$. It's $\frac{1}{4}+\frac{1}{4}+\frac{1}{9}+\frac{1}{25}+\dots$ it doesn't have such a nice pattern to it because of our selection of the functions $A,B$.","['functional-analysis', 'special-functions', 'sequences-and-series', 'analysis']"
2835330,Show that $2^{ax}\frac{\Gamma((a+1)x)}{\Gamma(x)}$ is an increasing function,"I would like to show that the following function 
\begin{align}
f_a(x)=2^{ax}\frac{\Gamma((a+1)x)}{\Gamma(x)}
\end{align}
is an increasing function in $x$ for $x \ge 0$  for any fixed $a>0$. I did some simulations but not sure how to show a proof for this. I wanted to point out that, from simulation, it seems that $\frac{\Gamma((a+1)x)}{\Gamma(x)}$ can be decreasing for values  $x=0$. We can attempt this by showing that the derivative  of a logarithm of $f_a(x)$ is positive. Let \begin{align}
g_a(x)= \log (f_a(x))
\end{align} (here log is base e) and the derivative of $g_a(x)$ is given by
\begin{align}
\frac{d}{dx}  g_a(x)&=  \frac{d}{dx} \left( ax \log(2)+  \log (\Gamma( (a+1)x))- \log (\Gamma( x)) \right)\\
&=a \log(2) + (a+1)\psi((a+1)x)-\psi(x)
\end{align} 
where $\psi(x)$ is a digamma function. Now it remains to show the following inequality for the difference of digamma functions
\begin{align}
 (a+1)\psi((a+1)x)-\psi(x) \ge - a \log(2) .
\end{align}","['gamma-function', 'calculus']"
2835344,Solving $u = xu_x + u_t$ by method of characteristics,"I'm learning the method of characteristics. Suppose we want to find $$u(t,x)$$ such that $$u = xu_x + u_t$$ $$u(0,x) = f(x)$$ By the multivariable chain rule, and putting the PDE again below to compare: $$\frac{du}{dt} = \frac{\partial u}{\partial x}\frac{dx}{dt} + \frac{\partial u}{\partial t}\frac{dt}{dt}$$ $$u = xu_x + u_t$$ By comparsion we get: $$\frac{du}{dt} = u \rightarrow u = K_1e^t$$ $$\frac{dx}{dt} = x \rightarrow x = K_2e^t$$ So, at the path $(t,K_2e^t)$ we have that $u$ is $K_1e^t$. But there is a family of paths $(t,K_2e^t)$ because $K_2$ is undetermined. Let's see the graph for one possible $K_2$: If I knew $K_2$ then I'd have this path in the graph, and then I'd know that on this path, $u(0,K_2) = f(K_2) = K_1$ so the solution for $u$ on the path $(t,K_2e^t)$ should be $u = K_1e^t = f(K_2)e^t$. However this solution is not for every $x$ and every $t$, it's just in the path, that is: $$u(t, K_2e^t) = f(K_2)e^t$$ there's still work needed to generalize it for $u(t,x)$ in general. So the two questions are: how to find $K_2$ first, and how to transform $u(t, K_2e^t) = f(K_2)e^t$ into a solution dependent of $t$ and $x$, that is, $u(x,t)$?","['derivatives', 'partial-derivative', 'calculus', 'partial-differential-equations']"
2835352,Proof that $\sigma$-algebra is closed under intersection,"I want to show in this proof that a $\sigma$-algebra is closed under intersection. But I am not sure if my second to last implication is true? Let $\mathcal{F}$ be a subset of the sample space $\Omega$ with the three properties of a $\sigma$-algebra. Prove that an event $A_k\in\mathcal{F}$ is also closed under countable intersection for all $k\in\mathbb{N}$. Properties 1) $\emptyset\in\mathcal{F}$ 2) $A\in\mathcal{F}\implies A^C\in\mathcal{F} \quad \text{(closed under complementation)}$ 3) $A_k\in\mathcal{F}\implies \bigcup_{k\in I} A_k\in\mathcal{F}$ for all $k\in I \quad\text{(closed under countable union)}$ My Solution If $\mathcal{F}$ is modeled as a $\sigma$-algebra, using the second property and third property yields $$
\begin{align}
A_k\in\mathcal{F}&\implies\bigcup_{k\in\mathbb{N}}A_k\in\mathcal{F} &&\text{(closed under union)}\\
&\implies\left(\bigcup_{k\in\mathbb{N}}A_k\right)^C\in\mathcal{F} && \text{(closed under complementation)}\\
&\implies\bigcap_{k\in\mathbb{N}}A_k^C\in\mathcal{F} && \text{(de Morgan's Law)}\\
&\implies\bigcap_{k\in\mathbb{N}}(A_k^C)^C\in\mathcal{F} && (A_k^C\in\mathcal{F} \text{ closed under complementation) }\\
&\implies \bigcap_{k\in\mathbb{N}}A_k\in\mathcal{F}\\
&\implies \mathcal{F}\;\textit{is closed under intersection.}
\end{align}
$$ New Solution Taking @AnyAD's advice into consideration:
$$
\begin{align}
A_k\in\mathcal{F}&\implies A_k^C\in\mathcal{F} && \text{(closed under complementation)}\\
&\implies\left(\bigcup_{k\in I} A_k^C\right)\in\mathcal{F} && \text{(closed under union)}\\
&\implies\left(\bigcup_{k\in I} A_k^C\right)^C\in\mathcal{F} && \text{(closed under complementation)}\\
&\implies\left(\bigcap_{k\in I} (A_k^C)^C\right)\in\mathcal{F} && \text{(de Morgan's Law)}\\
&\implies\bigcap_{k\in I}A_k\in\mathcal{F}\\
&\implies \mathcal{F}\;\textit{is closed under intersection.}
\end{align}
$$","['probability', 'proof-verification']"
2835353,Domains for which the divergence theorem holds,"In the book Elliptic partial differential equations of second order written by Gilbarg and Trudinger, I saw the following sentence on page 17 in section 2.4 Green’s Representation: As a prelude to existence considerations we derive now some further consequences of the divergence theorem, namely, Green identities. Let
  $\Omega$ be a domain for which the divergence theorem holds and let $u$ and $v$ be $C^2(\bar\Omega)$ functions. It is well known that the divergence theorem holds when $\Omega$ is a bounded domain with $C^1$ boundary. Are there any other domain than a bounded one with $C^1$ boundary for which the theorem holds? I would be grateful if you could give any comment for this question.","['multivariable-calculus', 'geometric-measure-theory', 'real-analysis', 'vector-analysis']"
2835367,Integral curves to a non-vanishing vector field on the unit square,"Let $X$ be a non-vanishing vector field on the unit square $I^2$ in $\mathbb{R}^2$. I would like to show that every integral curve to $X$ exits the unit square in finite time. This fact is used in a paper I am reading, in which the author says ""(assume there is an integral curve that does not exit the unit square,) it would approach asymptotically some simple closed curve in $I^2$. In the interior of this curve the vector field would have to have a singularity."" This does seem reasonable, since integral curves cannot cross themselves (unless they are simply closed curves, but as the author has noted this would result in a contradiction in the interior of the closed curve) so they should have no place to go except wrapping around. However I cannot make this idea rigorous at all. Any help is appreciated!","['ordinary-differential-equations', 'analysis', 'vector-analysis']"
2835377,Combination notation vs. Binomial Coefficient Formula,"I'm studying probability and statistics and had a question regarding notation. I noticed that combinations and the binomial coefficient are essentially the same thing, that is: $$\binom{n}{k}\ =\ _nC_k\ =\ \frac{n!}{(n-k)!k!}$$ But I was wondering, is there a particular difference between the two that people should be aware of? For example, are there certain use cases where one is preferred over the other? Thank you.","['combinations', 'statistics', 'binomial-coefficients', 'probability']"
2835378,Is completeness necessary? X separable iff weak* topology on closed unit ball of dual is metrizable.,"First some references: [M] Megginson - An Introduction to Banach Space Theory [D] Denkowski, Migórski, Papageorgiou, Socrates - An Introduction to Nonlinear Analysis [B] Brezis - Functional Analysis, Sobolev Spaces and Partial Differential Equations [DS] Dunford and Schwartz - Linear Operators Part I: General Theory The following theorem appears in [M, p.231], [D, p.305], [B, p.74], [DS, p.426].  I'm sure it appears elsewhere too. Theorem. Let $X$ be a Banach space. Then $X$ is separable iff the closed unit ball of $X^*$ is metrizable in the weak* topology (inherited from X*). However, [M] only assumes $X$ is a normed space, not a Banach space. I've been through the proofs, and I can't see where completeness is being used. Question 1. Is completeness of $X$ really necessary? There is also a closely related theorem that appears in [D, p.305], [B, p.74], [DS, p.426]: Theorem. Let $X$ be a Banach space. Then $X^{*}$ is separable iff the closed unit ball of $X$ is metrizable in the weak topology (inherited from X). Question 2. Is completeness of $X$ really necessary?","['functional-analysis', 'real-analysis']"
2835385,"Solve $(ST-\lambda I)x=b$ in $O(n^2)$ for upper triangular $S,T$","Let $S,T\in\mathbb{R}^{n\times n}$ be 2 upper triangular matrixes, and $ST-\lambda I$ be nonsingular where $I$ denotes the identity matrix of order $n$. Solve the system of linear equations in complexity $O(n^2)$ for $b\in\mathbb{R}^n$:
  $$(ST-\lambda I)x=b$$ It's known that equations like $Uy=b$ for upper triangular $U$ can be solved in complexity $O(n^2)$ by back substitution method. I tried to rewrite $ST-\lambda I$ as the product of 2 matrixes, but it failed. Now I get stuck on this puzzling problem. Appreciated for any suggestions.","['numerical-methods', 'numerical-linear-algebra', 'linear-algebra']"
2835404,Why is the Indefinite Integral of a Step Function and continuous?,"As I posted before, say I have:\begin{equation}
  S(X)=\left\{
  \begin{array}{@{}ll@{}}
    c_0, & \text{if}\ t_0 \leq x <t_1 \\
    c_1, & \text{if}\ t_1 \leq x <t_2 \\ 
    c_2, & \text{if}\ t_2 \leq x <t_3 \\ 
. & \ . \  \\ 
. & \ . \  \\
. & \ . \  \\
. & \ . \  \\
c_{n-1}, & \text{if}\ t_{n-1} \leq x \leq t_n \\\end{array}\right.
\end{equation} . Why is the indefinite integral of S(x) piecewise linear and continuous? I think I understand why it it is piecewise linear (hopefully as I was trying to do in my last post) but why is the indefinite integral of a step function necessarily continuous? It is not clear to me why the integral of $S(x)$, or an arbitrary step function for that matter cannot have jump discontinuities.  Thanks for the help. Here is a picture stating that it must necessarily be continuous: Perhaps it would help me if someone could help me understand how they calculated the indefinite integral of this step function: Essentially they have in this picture: $T(X) =1$ for $0 \leq x < 2$ $T(X) =-1$ for $2 \leq x \leq 4$.
They get the indefinite integral to be: $x$ for $0 \leq x < 2$ $4-x$ for $2 \leq x \leq 4$. How did they compute this?","['real-analysis', 'limits', 'calculus', 'continuity', 'integration']"
2835406,"In a field extension, if each element's degree is bounded uniformly by $n$, is the extension finite?","Given a field extension $F\subset E$, if there exists a $n$ such that for each $\alpha\in E$ we have $|F[\alpha]: F| \leq n$, can we conclude that $|E:F|<\infty$? This is the question here , but I would like to drop the char $0$ assumption on $F$.","['abstract-algebra', 'extension-field', 'field-theory']"
2835429,Complex Analysis Book: Conway vs Lang,"I want to start stuyding complex analysis on a graduate level on my own (self study). I'm having trouble with diciding which one of the following books to use: Serge Lang's Complex Analysis
or John. B. Conway's Functions of One Complex Variable. Here's the first part of the contents of both books: As you can see, Conway has a chapter on Metric Spaces and the Topology of $\Bbb C$, and starts with power series in the third chapter, while Lang does it directly in the second chapter. Which of these two books do you guys recommend me and why?","['complex-analysis', 'book-recommendation']"
2835521,Limit of function as $x \to\infty $ when $f'(x)$ is given,"Let $f:[1,\infty)\rightarrow \mathbb R $ is a differentiable function which satisfies $$f'(x)=\frac {1}{x^2+(f (x))^2}  \text{ and } f(1)=1$$ then find the limit of $f $ as $x \to\infty $ My attempt : So I first thought of making a differential equation and then calculate the limit. But the differential equation formed $y'(y^2+x^2)=1$ is a non standard equation and it cannot be solved. Even calculators on the internet show that ""no solution found"". However, Wolfram Alpha does provide a graph but not the solution. Also $f^{\prime\prime}(x)<0$. Can this fact be used in some way? Next I thought of using Rolle's theorem but I am unable to figure out some way to use it. Can anyone provide me some idea on how to approach this problem?","['derivatives', 'ordinary-differential-equations']"
2835530,Explain eigenvalues of a distance/cost matrix,"Assume there are N countries. The cost of making a phone call from country $i$ to country $j$ is $C_{ij}$ . We know that all costs are non-negative. (Q1) Can you think of a verbal interpretation of eigenvalues of the matrix $C_{ij}$ ? (Q2) Does anything change, if we allow weights to be negative? I am aware that an eigendecomposition of a transformation $T$ is given by $T = R^{-1}DR$ , which means that, if a matrix were to be used as a transformation, it could be interpreted as rotation, scaling, and rotation back to the original basis. However, I'm not necessarily using my matrix to transform anything, so my intuition does not quite help","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra']"
2835538,Converse of Taylor's Theorem,"Let $n$ be a nonnegative integer and $a,b\in\mathbb{R}$ such that $a<b$ .  From Taylor's Theorem, we know that any $n$ -time differentiable function $f:(a,b)\to \mathbb{R}$ satisfies the condition that $$f(x+h)=\sum_{k=0}^n\,\frac{f_k(x)}{k!}\,h^k+R_n(x,h)\text{ for all $x\in(a,b)$ and $h\in(a-x,b-x)$}\,,\tag{*}$$ where $f_k:(a,b)\to\mathbb{R}$ is the $k$ -th derivative of $f$ for each $k=0,1,2,\ldots,n$ (in particular, $f_0=f$ ), and the $n$ -th remainder term $R_n(x,h)$ satisfies $$R_n(x,h)\in o\left(h^n\right)\text{ for each $x\in(a,b)$ and for every small $h\in\mathbb{R}$}\,.\tag{**}$$ (In other words, $\lim\limits_{h\to 0}\,\dfrac{R_n(x,h)}{h^n}=0$ for all $x\in (a,b)$ .) I have a question whether the converse of Taylor's Theorem is true.  In other words, is the following conjecture correct? Conjecture. Suppose that functions $f,f_0,f_1,f_2,\ldots,f_n:(a,b)\to\mathbb{R}$ satisfy (*) and (**).  Then, $f$ is $n$ -time differentiable, with $k$ -th derivative $f_k$ for each $k=0,1,2,\ldots,n$ (in particular, $f_0=f$ ). From this link , some continuity or boundedness constraints on the $f_k$ 's or on the remainder term $R_n$ are assumed for the converse to hold.  If the converse does not hold in general (i.e., without these continuity or boundedness constraints), could anybody give a counterexample?  If it is true, then can you please give me a proof or a reference?  What I know is that the converse holds for $n=0$ (trivially) and $n=1$ (with a small amount of work).","['real-analysis', 'taylor-expansion', 'functional-equations', 'approximation-theory', 'numerical-methods']"
2835550,"How to answer matrices problems involving ""meet"" and ""join""?","Problem: Given the matrix below find the meet and join of A and B. \begin{bmatrix}
    1    & 0  & 1 \\
    1    & 1  & 0 \\  
    0    & 0  & 1 \\
\end{bmatrix} \begin{bmatrix}
    0    & 1  & 1 \\
    1    & 0  & 1 \\  
    1    & 0  & 1 \\
\end{bmatrix} How to answer this kind of questions? I have learned the basics to advance math and know how to answer matrices involving problems, but I am new to this ""meet"" and ""join"" type of questions. Any help would be appreciated.","['matrices', 'matrix-equations']"
2835557,Can we always find a continuous a.e. probability density function?,"Given an absolutely continuous cumulative distribution function, we know the corresponding probability density function is not unique, but it is determined almost everywhere. My question is: For any absolutely continuous cumulative distribution function, can we always find a continuous almost everywhere probability density function? For example, $f(x)*1\{x\in\mathbb{R} - \mathbb{Q}\}$ is nowhere continuous, where $f(x)$ is a continuous probability density function. But $f(x)=f(x)*1\{x\in\mathbb{R} - \mathbb{Q}\}$ a.e. So $f(x)$ is a desired probability density function.","['probability-theory', 'measure-theory']"
2835558,What does consistency mean in Mathematics?,"What does consistency mean in Mathematics? Does the meaning vary as per the context? If yes, than can you give some examples? PS: I'm not sure what is the correct tag for this question, please someone edit it. Thank you so much :)",['discrete-mathematics']
2835590,"Inequivalence of Compactness and Sequential Compactness, Especially for the Weak* Topology?","I know that for topological spaces, compactness and sequential compactness are generally not equivalent. From wikipedia: ""there exist sequentially compact spaces that are not compact (such as the first uncountable ordinal with the order topology), and compact spaces that are not sequentially compact (such as the product of ${\displaystyle 2^{\aleph _{0}}={\mathfrak {c}}}$ copies of the closed unit interval [e.g., the space of functions $f:\mathbb{R} \to [0,1]$ with pointwise convergence])."" For the weak topology on a normed space, compactness and sequential compactness are equivalent: Theorem (Eberlein-Smulian) Let $X$ be a normed space and let $A$ be a subset of $X$. Then $A$ is weakly compact if and only $A$ is weakly sequentially compact. I'm interested in examples where compactness and sequential compactness are not equivalent in the weak* topology. Example. The closed unit ball $B_{*}$ of $X^{*} = (\ell^{\infty})^{*}$ is weak* compact (by Banach-Alaoglu) but is not weak* sequentially compact (the sequence of functionals $f_n(x_1,x_2,\ldots,)=x_n$ has no weak* convergent subsequence). Question 1. What is an example of a normed space $X$ and an $A \subseteq X^{*}$ that is weak* sequentially compact but not weak* compact? Question 2. Is there a normed space $X$ such that (i) there is a set $A \subseteq X^{*}$ that is weak* sequentially compact but not weak* compact and (ii) the closed unit ball $B_{*} \subseteq X^{*}$ is weak* compact but not weak* sequentially compact. Question 3. (Easier than Question 2). Is there a topological space $X$ such that (i) there is a set $A \subseteq X$ that is sequentially compact but not compact and (ii) there is a set $B \subseteq X$ that is compact but not sequentially compact. Edit: Question 3 turned out to be much easier than I thought (see Henno Brandsma's answer below).","['general-topology', 'real-analysis', 'functional-analysis']"
2835693,How Gelfond find his limit for $\exp(\pi) $? [duplicate],"This question already has an answer here : Origin of rapidly converging sequence for $e^\pi$ (1 answer) Closed 6 years ago . $$ a_0 = \frac{1}{\sqrt 2} $$ $$ a_{n+1} = \frac{( \sqrt {1 - a_n^2} -1)^2}{a_n^2} $$ $$ \lim_{n \to \infty} \frac{4^{\frac{1}{2^n}}}{a_{n+1}^{\frac{1}{2^n}}} = \exp(\pi) $$ How did Gelfond find this nice result ?
And how to prove it ? 
The 4 is trivial , but the rest is not.
Is this related to trigonometry ?
Is this related to continued fractions ? Are there analogues known for cube roots ? Notice a proof alone might not explain how he found the result.","['fixed-point-theorems', 'roots', 'pi', 'limits']"
2835716,Question about Euler equation: $at^2\ddot x(t)+bt\dot x(t)+cx(t)=0$,"Let's consider the differential equation $$at^2\ddot x(t)+bt\dot x(t)+cx(t)=0$$ where $a\neq 0$ and $a,b,c\in\mathbb R$. Now it says in my book that if $\varphi: (0,\infty)\to\mathbb R$ is a solution, then so is $\tilde\varphi: (-\infty,0)\to\mathbb R, \tilde\varphi(t)=\varphi(-t)$ and I don't understand that. Don't we have $\frac{d}{dt}\varphi(-t)=-\dot\varphi(t)$? And then $\frac{d^2}{dt^2}\varphi(-t)=\frac{d}{dt}(-\dot\varphi(t))=-\ddot\varphi(t)$? No matter what I do, if I plug in the derivatives of $\tilde\varphi$, I don't see how it solves the equation above but I'm sure there is a very simple error in my train of thought.",['ordinary-differential-equations']
2835732,Fubini's theorem and the Gaussian Integral,"I have been reading K. Conrad's very useful monograph on the Gaussian Integral ( http://www.math.uconn.edu/~kconrad/blurbs/analysis/gaussianintegral.pdf ) but I have a couple of questions which I am having trouble fully justifying to myself: Let $J=\int^\infty_0 e^{-x^2}dx$ where obviously $2J=\int^\infty_{-\infty} e^{-x^2}dx$ is the more traditional Gaussian integral. In Solution 1, Conrad solves $J$ using polar coordinates, while in Solution 2, he uses the substitution $x=yt$ in the double integral $J^2=\int^\infty_0 e^{-x^2}dx\int^\infty_0 e^{-y^2}dy=\int^\infty_0(\int^\infty_0 e^{-(x^2+y^2)}dx)dy$. I don't really have a problem with either solution (except for one point which I will outline below), except that he says his Solution 2 uses only single variable calculus, while Solution 1 uses multivariable calculus. Perhaps it is my own ignorance showing, but why does Solution 2 not use multivariable calculus? Is it because $y$ is a dummy variable? My other issue comes from the implicit use of Fubini's theorem. Above, where I have written $J^2=...$ I presume it is Fubini that allows me to change the order of integration. However, how does this work when we are working with improper integrals? Further, what would I need to check to make sure Fubini holds? It is easy to show $J$ exists (as a limit), and $e^{-x^2}$ is everywhere non-negative, but is that enough?","['real-analysis', 'calculus', 'multivariable-calculus', 'integration', 'improper-integrals']"
2835736,Prove the completeness of the following metric space,"We know that if $(X,d)$ is a metric space then $\sigma=\frac{d}{1+d}$ is also a metric on $X$. If $(X,d)$ is a complete metric space then how to prove that $(X,\sigma)$ is also a complete metric space ?","['functional-analysis', 'general-topology', 'metric-spaces']"
2835744,Approximating Sobolev functions on unbounded domains of class $C^1$ by compactly supported smooth functions,"In the lecture we saw the following statement Corollary : Let $\Omega$ be open and of class $C^1$, $1 \leq p < \infty$ and $u \in W^{1,p}(\Omega)$. Then there exists a sequence $(u_k)_{k \in \mathbb{N}} \subset C^{\infty}_c(\mathbb{R}^n)$ with $||u_k|_{\Omega}-u||_{W^{1,p}(\Omega)} \rightarrow 0, k \rightarrow \infty$ The proof went as follows: First we set $\delta>0$ and constructed a $\overline{u} \in W^{1,p}(\Omega)$ with $supp(\overline{u}) \subset\subset \mathbb{R}^n$, i.e. compact support in $\mathbb{R}^n$, with $||\overline{u}-u||_{W^{1,p}(\Omega)} < \delta$. Then the proof said to use a extension operator for Sobolev functions, which can be constructed, since for the boundary $\Gamma$ of $\Omega$ it holds that $\Gamma \cap supp(\overline{u})$ is compact. This was the part I did not understand . For reference our lecturer used the following notes . The above stated corollary is Korollar 8.4.2. Unfortunatly the notes are written in german, but since the notes are mainly based on Brezi's book on functional analysis, the same statement can be found in Corollary 9.8 in Brezi's book. Thanks a lot in advance!","['functional-analysis', 'real-analysis', 'sobolev-spaces', 'partial-differential-equations']"
2835767,Sequence of subspaces is dense. Limit of Operator norm,"Let $V \subset L^2(\Omega)$ be a Hilbertspace and $\{V_n\}$ a sequence of subspaces such that
\begin{align*}
V_1 \subset V_2 \subset \dots \quad \text{and} \quad \overline{\bigcup_{n \in \mathbb{N}} V_n} = V \, (\text{w.r.t. } V\text{-norm} ).
\end{align*}
For some $f\in L^2(\Omega)$ we define $\phi_n = \sup_{\| v_n\| = 1, v_n \in V_n} \int_\Omega f(x) v_n(x)\, dx$. How can I prove that
\begin{align*}
\lim_{n\to\infty} \phi_n = \sup_{\| v\| = 1, v \in V} \int_\Omega f(x) v(x)\, dx
\end{align*} 
holds? Is this convergence uniform?","['functional-analysis', 'normed-spaces', 'sobolev-spaces', 'sequences-and-series']"
2835773,Differential equation from an exam,"Hello there yesterday in my exam I had the following problem: Knowing that $y_1=x$ is a solution, solve: $$(x^2 - 1)y''+2xy'-2y=0$$ My try was to use Liouville-Ostrogradski formula (see: https://www.encyclopediaofmath.org/index.php/Liouville-Ostrogradski_formula ) So bassically what I have is (I will denote with C the second Wronskian since is just a constant): $$y_1y_2'-y_1'y_2=Ce^{-\int{\frac{2x}{x^2-1}}dx}$$ $$xy_2'-y_2=\frac{C}{x^2-1}\rightarrow \frac{y_2'}{x}-\frac{y_2}{x^2}=\frac{C}{x^2(x^2-1)}$$  $$\left(\frac{y_2}{x}\right)'=\frac{C}{(x^2-1)x^2}=\frac{C}{(x^2-1)}-\frac{C}{x^2}$$ By integrating : $$\frac{y_2}{x}=\left(\frac{C}{2}\ln\left|\frac{x-1}{x+1}\right|+\frac{C}{x}+C_2\right)$$$$y_2=c_1x\ln\left|\frac{x-1}{x+1}\right|+c_2x +c_3$$ Was my solution correct and complete? I am wondering if  I must prove that this differential equation has only those two solutions, but I have no ideea how.",['ordinary-differential-equations']
2835806,Hartshorne-Eisenbud cross reference?,"Is there a page online that lists where exactly all the algebraic theorems in Hartshorne appear in Eisenbud?  I know that Eisenbud uses the term ""codimension"" instead of ""height"", but just Flipping through the chapters on dimension theory, I'm not finding it very easy to locate the particular theorems referenced by Hartshorne. I'm trying to find the proofs for the dimension theory in the first section, specifically: Theorem 1.8A (M, Ch. $5$, $\S14$) Theorem 1.11A (A-M, p. $122$) Theorem 1.12A (M, p. $141$) Here ""M"" refers to Matsumura's Commutative Algebra and ""A-M"" to Atiyah and MacDonald's Introduction To Commutative Algebra , which are the references given in Hartshorne.","['abstract-algebra', 'reference-request', 'algebraic-geometry']"
2835807,Real power series absolutely converges. Does complex series converge too?,"Consider a function $f: (0,1) \to \mathbb R$ defined as the following power series:
$$
f(x) = \sum_{k=0}^\infty a_k (1-x)^k.
$$
This series has $a_k > 0$ and is assumed to converge point-wise for all $x \in (0,1)$. My question is: If $x$ in the above expression is replaced by a complex variable $z$, can it be assured that $\sum_{k=0}^\infty a_k (1-z)^k$ converges for all $z$ with $|z-1|<1$? Here is my attempt at a proof , but I'm not sure it is correct. The series for $x \in (0,1)$ is absolutely convergent in $(0,1)$ by the assumptions. That is, $\sum_{k=0}^\infty a_k (1-x)^k = \sum_{k=0}^\infty a_k |1-x|^k$ is finite for all such $x$. Replacing $x$ by any complex $z$ such that $|1-z| = |1-x|$, the resulting $\sum_{k=0}^\infty a_k |1-z|^k$ converges to the same value. This implies that the complex series $\sum_{k=0}^\infty a_k (1-z)^k$ (absolutely) converges. Since this holds for any $x \in (0,1)$, the complex series converges for any $z$ in the disk $|z-1|<1$. Are all my steps correct ? If so, is there any shorter proof ? If not, is there a counterexample ?","['real-analysis', 'calculus', 'complex-analysis', 'convergence-divergence', 'power-series']"
2835809,One tailed confidence interval $1 - 2\alpha $ rationale,"In my statistics textbook, I’ve noticed a pattern that is clear but the rationale for which isn’t explained: When constructing a one tailed confidence interval, the confidence level is equal to $ 1 - 2\alpha $. I can apply this idea, but can someone please explain to me the rationale? Why is $ 1 - 2\alpha $ the confidence level for a one tailed test when a two tailed test is $1 - \alpha $? I should add that my understanding is that a one tailed confidence interval should have confidence level equal to $1 - \alpha $ because each tail in a two tailed confidence interval has area $1 - \alpha/2 $. This is what I cannot reconcile. Edit: This table is referenced repeatedly in the book but no justification I can find is given. The book is “Essentials of Statistics,” 5th edition, Triola, Mario F. Edit: I’ve included some reference photos from two sections of the book. The first two photos below are from a general section on confidence intervals where only two tailed intervals are discussed. The following two photos are from a section on chi-squares tests. I can not reconcile the statements regarding confidence level in the next photo from the statement about alpha in the final photo:","['statistics', 'confidence-interval']"
2835858,Check the proof that $f(x) = \cos({x})\cdot\cos({\sqrt{3}x})$ is not periodic,"I have to prove that $f(x) = \cos({x})\cdot\cos({\sqrt{3}x})$ is not periodic If the function is periodic then: $$
f(x) = f(x+T)\\
\cos(x)\cdot\cos(\sqrt{3}x) = \cos(x+T)\cdot\cos(\sqrt{3}(x+T))
$$ Consider the function at $0$: $$
\cos(T)\cdot\cos(\sqrt{3}T) = 1
$$
But this equation has only one solution at $T=0$ which contradicts the initial assumption that there exists a positive period. Or the other way: $$
\cos(T)\cdot\cos(\sqrt{3}T) = 1
$$
Let $\cos(T) = 1$ and $\cos(\sqrt{3}T) = 1$, hence $$
T = 2 \pi m \\
\sqrt{3}T=2\pi n
$$ Substituting $T$ in the second equation gives: $$
2\pi m\sqrt{3} = 2\pi n \\
\sqrt{3} = \frac{n}{m}
$$
But $m,n \in \mathbb N$ and $\sqrt{3} \in \{\mathbb R \setminus \mathbb Q\}$ which gives a contradiction. Is the prove above valid? Update: For $\cos{T} = -1$ and $\cos\sqrt{3}T = -1$: $$
T = \pi+ 2 \pi m \\
\sqrt{3}T=\pi + 2\pi n \\
\sqrt{3} = \frac{2n + 1}{2m+1}
$$ Which is a contradiction.","['periodic-functions', 'trigonometry', 'proof-verification', 'algebra-precalculus', 'proof-writing']"
2835877,"Why is this function not differentiable at $ (1,1)$?","I have spent over two hours trying to understand why this function is not differentiable at $(1,1)$! 
$$f(x,y)=\begin{cases}x+y & x\ne y\\x+1 &x=y \end{cases}$$
Supposedly we ought to prove it through using the following equation: $$\lim_{(h,k)\to(0,0)} \frac{[f(1+h,1+k)-f(1,1)-h(\partial_xf(1,1))-k(\partial_yf (1,1))]}{\sqrt{h^2+k^2}} $$ with: $$\frac{\partial f}{\partial x}(1,1) = 1, \quad \frac{\partial f}{\partial y}(1,1) = 1$$ the limit is $0$ when $h \neq k$ But supposedly when $h = k$ the limit is different from $0$ which proves it is not differentiable at $(1,1)$ but no matter what I do I can't seem to get a result different from $0$ when $h = k$ Any help would be much appreciated!","['multivariable-calculus', 'partial-derivative']"
2835881,Cayley–Hamilton And Invertible Matrix,"In my lecture notes, it was mentioned that if the Cayley–Hamilton polynomial has a free element then it is invertible. Namely, $P_A(x) = a_n x^n + \dots + a_1 x + a_0$ there $a_0 \neq 0$. Why is it correct?","['matrices', 'cayley-hamilton', 'linear-algebra', 'inverse']"
2835882,"Is there a nice way to evaluate $\iiint_{E}\, \frac{dx\,dy \,dz}{\sqrt{x^2+y^2+(z-b)^2}}$ where $E:x^2+y^2+z^2\leq a^2$","Is there a nice way to evaluate $$\displaystyle\iiint_{E}\, \dfrac{dx\,dy\,dz}{\sqrt{x^2+y^2+(z-b)^2}}$$ where   $E:x^2+y^2+z^2\leq a^2$ with
    $0<a<b$ If I use the standard spherical coordinates (Is there a better transformation?) $$x=p\sin(\phi)\cos(\theta) $$ $$y=p\sin(\phi)\sin(\theta)$$ $$z=p\cos(\phi)$$ $$|J|=p^2\sin(\phi)$$ $$\iiint_{E}\, \frac{dx\,dy \,dz}{\sqrt{x^2+y^2+(z-b)^2}} $$ $$=\int_{\phi=0}^{\pi}\,\int_{\theta=0}^{2\pi}\,\int_{p=0}^{a}\, \frac{p^2\sin(\phi)\,dp\,d\theta \,d\phi}{\sqrt{p^2\sin^2(\phi) + (p\cos(\phi)-b)^2}}$$ $$=\int_{\phi=0}^{\pi}\,\int_{\theta=0}^{2\pi}\,\int_{p=0}^{a}\, \frac{p^2\sin(\phi)\,dp\,d\theta \,d\phi}{\sqrt{(p-b\cos(\phi))^2 + b^2\sin^2(\phi)}}$$ Which I'm finding bit difficult.","['multivariable-calculus', 'multiple-integral', 'calculus']"
2835899,Isomorphically comparing normal subgroups and their quotient groups,"1 . Find a finite group G and two normal subgroups A and B such that $A \cong B$ but $G/A \ncong G/B$. Let $G=\mathbb{Z}_4 \times \mathbb{Z}_2$ (which is abelian), $A= \langle(2,0)\rangle$ and $B=\langle(0,1)\rangle$. Then $(1,0)+B$ has order 4, hence $G/B$ is cyclic; whereas $G/A = \{A, (1,0)+A, (0,1)+A, (1,1)+A \}$ is not cyclic because every non-zero element has order $2$. Therefore $G/A \ncong G/B$. 2 . Find a finite group G and two normal subgroups A and B such that $A \ncong B$ but $G/A \cong G/B$. Let $G=D_4$ the dihedral group with $8$ elements, then both $A=\langle \rho_{\pi/2} \rangle$ and $B=\langle\rho_\pi, \iota, \iota_{\pi}\rangle$ have order $4$, hence they have index $2$ which implies that they are normal and that their quotient groups are isomorphic, but $B$ is not cyclic so $A\ncong B$. Note that $\rho_\theta$ indicates the rotation of an angle $\theta$ counterclockwise, while $\iota_\theta$ is the reflection through the line that form an angle $\theta/2$ with the x-axis. Do you think these solutions are correct?","['finite-groups', 'abstract-algebra', 'examples-counterexamples', 'group-theory']"
2835903,"$X\times\hat A$ homeomorphic to $\widehat{C(X,A)}$ for unital $C^*$-algebras $A$","Let $X$ be a compact Hausdorff space and $A$ a unital $C^*$-algebra, then
I know that
\begin{align*}
\Psi:X\times\hat A &\to \widehat{C(X,A)} \\
(x,[\pi]) &\mapsto [\pi\circ\epsilon_x]
\end{align*}
is a bijection where $\epsilon_x:C(X,A)\to A$ is the point evaluation $\epsilon_x(f):=f(x)$ (see J. Dixmier ""$C^*$-Algebras"" , Corollary 10.4.4). I want to show that $\Psi$ is a homeomorphism with respect to the Hull-Kernel-Topology on the irreducible representations $\hat A$ and $\widehat{C(X,A)}$. I was able to show that $\Psi^{-1}$ is continuous, so I only need the continuity of $\Psi$. $\newcommand\Hull{\operatorname{Hull}}$
$\newcommand\Ker{\operatorname{Ker}}$ So far I am starting with a net $(x_\lambda,[\pi_\lambda])$ that converges to some $(x,[\pi])$ and want to show that
$$\Psi(x,[\pi])\in\overline{\Psi(\{(x_\lambda,[\pi_\lambda]\}_\lambda)}=\Hull\Ker\{[\pi_\lambda\circ\epsilon_{x_\lambda}]\}_\lambda$$
To this end let $f\in\Ker\{[\pi_\lambda\circ\epsilon_{x_\lambda}]\}_\lambda$, then we have to show that $\pi(f(x))\equiv\pi\circ\epsilon_x(f)=0$. Since $f\in\ker(\pi_\lambda\circ\epsilon_{x_\lambda})$ for all $\lambda$, we know that $\pi_\lambda(f(x_\lambda))\equiv\pi\circ\epsilon_x(f)=0$ for all $\lambda$. So the continuity of $\Psi$ follows when we can show that
$$ [\forall \lambda:\pi_\lambda(f(x_\lambda))=0,\; \pi_\lambda\to\pi,\;x_\lambda\to x] \quad\Rightarrow\quad \pi(f(x))=0 $$
I think it's safe to reduce this to the simpler statement
$$ [\forall \lambda:\pi_\lambda(a_\lambda)=0,\; \pi_\lambda\to\pi,\;a_\lambda\to a\in A] \quad\Rightarrow\quad \pi(a)=0 $$
This certainly looks like it should be true, but I'm not able to show this. For the interested reader: One can show the continuity of $\Psi^{-1}$ using nets: if $[\pi_\lambda\circ\epsilon_{x_\lambda}]\to[\pi\circ\epsilon_x]$, then one can proof separately that $[\pi_\lambda]\to[\pi]$ and $x_\lambda\to x$ by contradiction, which shows $(x_\lambda,[\pi_\lambda])\to(x,[\pi])$ . Alternatively one can show for all subsets $X_0\subset X$, $A_0\subset\hat A$, that
$$\Ker(\Psi(X_0\times A_0))=I_{X_0,A_0}:=\{f\in C(X,A)\,|\,f(X_0)\subset\ker A_0\}$$
This can be used to show for closed $X_0,A_0$, that $\Psi(X_0\times A_0)$ is also closed, which shows that $\Psi$ is closed, therefore $\Psi^{-1}$ must be continuous.","['functional-analysis', 'c-star-algebras']"
2835913,Why Rolle's theorem is giving two roots here?,"I am trying to find Number of distinct roots of $$f(x)=x+5\cos x=0$$ in $\left[0, \pi \right]$ we have $f(0)=5 \gt 0$ and $f(\pi)=\pi-5 \lt 0$ so by IVT we have at least one root in $\left[0,  \pi \right]$ Now IVT does not give information on number of roots, So I assumed let $p$ and $q$ are two distinct roots of $f(x)$ in $\left[0, \pi \right]$ Now $$f(p)=f(q)=0$$ Now applying Rolle's Theorem we get $$f'(c)=0$$ that is $$1-5 \sin c=0$$ so $$c =\arcsin(0.2)$$ which  $\in$ $\left[0,\pi \right]$ hence My assumption that there are two roots $p$ and $q$ is correct. But Graph shows there is only one root in $\left[0,\pi \right]$ Where I went wrong?","['derivatives', 'trigonometry', 'rolles-theorem', 'algebra-precalculus', 'continuity']"
2835944,The number of subsets of a set of cardinality $n$,"Please help with this question. Show that for a finite set $A$ of cardinality $n$ , the cardinality of $P(A)$ is $2^n$ , where $P(A)$ is the power set of $A$ . Thank you in advance for any help that is given.","['combinatorics', 'elementary-set-theory']"
2835971,Curve of Intersection between a Surface and a Plane,"The following terms are defined as in the book Differential Geometry by Do Carmo. Let $S$ be a regular surface, $p \in S,$ $N$ be a normal vector at $p$ and $v \in T_pS$ . Let $P$ be the plane parallel to the plane spanned by $v$ and $N$ and passes through $p$ . Now, I want to show that $P$ intersects with $S$ at a regular curve. I first tried to work on projections but that does not bring me to the conclusion. After that, I used the fact that a regular surface is locally a graph. Without loss of generality, I assumed that $S$ is a graph of a function of the form $z=f(x,y)$ . The equation of the plane $P$ is $(\vec{x}-p)\bullet(N \times v)=0$ , so I put in $\vec{x}=(x,y,f(x,y))$ and get $((x,y,f(x,y))\bullet(u\times v)=0$ . I try to use Implicit Function Theorem on this equation but I have no idea to proceed. Can anyone give me the idea of solving such problem? Thank you.","['implicit-function-theorem', 'curves', 'multivariable-calculus', 'differential-geometry', 'surfaces']"
2835994,Why is this morphism of vector bundles given by a matrix of linear forms,"Let $X$ be a smooth hypersurface in Projective space $\mathbb{P}^n$ of degree $ d$ defined by the equation $f=0$. Given that we have a vector bundle $E$ of rank $r\geq1$ on $X$ such that we have the following exact sequence on $\mathbb{P}^n$: $$0\rightarrow O(-1)^{rd}\rightarrow O^{rd}\rightarrow E\rightarrow 0.$$
My question is as follows. What is the morphism from $O(-1)^{rd}\rightarrow O^{rd}$? A paper indicated that it is given by a $rd\times rd$ matrix of linear forms. Why is this? I am not able to see it. If this is so, can we say where in $\mathbb{P}^n$ the determinant of that matrix vanishes?",['algebraic-geometry']
2836019,"Is there a ""largest function""?","In one of my classes, the professor asked about what we think the largest function was. Many thought perhaps ${e^x}^{e^x}$, but I thought about $n!$ When I talk about a ""largest function"", I mean the function that increases the quickest. The professor asked about a function larger than $n!$ to which I responded, $2n!$ Although snarky in nature, it is technically true. So my question is this: What is the ""largest function"" if we define ""largest"" as being ""increases the quickest"". A parent function is what we need, as it prevents someone like myself from putting a larger coefficient before the function.",['functions']
2836020,Can someone help me do this limit? $ \lim_{n\to\infty} \frac{n!\times(2n)!}{(3n)!}$,"can someone help me with this limit? I don't know how to expand that factorial multiplication, so what I've done so far is substitute what given: $$ \lim_{n\to\infty} \frac{n!\times(2n)!}{(3n)!}$$
  $$ \lim_{n\to\infty} \frac{\infty\times\infty}{\infty}$$ And with this I can apply the Cauchy or L'Hôpital's theorem by deriving both sides of the fraction independently, but my problem also stars here because, I don't how to derive a factorial term. Can someone help me please?
Thanks","['factorial', 'calculus', 'limits']"
2836028,Solve the equation $X^2+X=\text{a given matrix}$,I want to solve the quadratic matrix equation $$X^2+X=\begin{pmatrix}1&1\\1&1\end{pmatrix}$$ If I put $X$ in the form $$X=\begin{pmatrix}a&b\\c&d\end{pmatrix}$$ then I find complicated equations. Is there a simple way to tackle the problem without using diagonalization?,"['matrix-equations', 'systems-of-equations', 'matrices', 'linear-algebra', 'quadratics']"
2836055,"Find all $f:\mathbb{R}_+\to\mathbb{R}_+$ such that $(x+y) \, f\big(f(x) \, y\big)=x^2 f\big(f(x)+f(y)\big)$ for all $x,y>0$.","Find all functions $f\colon\Bbb R_+\to\Bbb R_+$ that satisfy the functional equation $$(x+y)\, f\bigl(f(x)\, y\bigr)=x^2 \,f\bigl(f(x)+f(y)\bigr)$$ for all $x,y\in\mathbb{R}_+$ .  Here, $\mathbb{R}_+$ is the set of positive real numbers. Attempt: There is no continuous solution $f$ such that $\lim_{x\to 0^+}f(x)$ exists.  If such a solution exists, then let $L=\lim_{x\to 0^+}f(x)$ .  If $L>0$ , then by taking $x\to 0^+$ , we get $$y\,f(Ly)=0.$$ Therefore $f(Ly)=0$ for all $y>0$ .  This is a contradiction because the codomain of $f$ is $\mathbb{R}_+$ .  Therefore, $L=0$ . Now, taking $y\to 0^+$ , we get $$0=x^2\,f\big(f(x)\big)$$ for all $x>0$ .  This means $f\big(f(x)\big)=0$ .  This is again a contradiction. How do we solve the functional equation if the continuity and limit assumptions are dropped?","['contest-math', 'functions', 'functional-equations']"
2836060,Flatten 3D triangle while maintaining edge lengths,"I currently try to flatten a triangle in 3d space while maintaining the edge lengths. The triangle consists of 3 vertices, all with x,y,z coordinates and is drawn clockwise. The second vertex yields 1 for the z value, the other two vertices are aligned to the x-axis and yield 0 for z.
Directly setting the z value would violate the edge length constraint. The target is to transform the 3d triangle so it could be completely projected in 2d. I tried to calculate the angle between a vector lying on the ground and an edge vector to get a rotation matrix. To flatten the triangle I would have to rotate the triangle with exactly this angle. 
This however is error-prone under real life conditions. I'm currently looking for a way to transform the triangle directly without the need of a rotation.","['rotations', '3d', 'triangles', 'geometry']"
2836083,Derivative of the variance wrt $x_i$,"As the title states, I want to find the derivative of $$\frac{1}{N}\sum_i (x_i - \mu)^2$$
w.r.t $x_i$ (note that $\mu$ is also another function of $x_i$, of course). I've tried solving it and got the following result $$\frac{2(N - 1)}{N^2}\sum_i (x_i - \mu)$$ Is this right? Am I doing something wrong?",['derivatives']
2836121,"How to find distance between a point and 3D surface, solution to general quadric equation, and visualizing such a surface?","Goal: I am writing software to visualize 3-D objects in Python, using libraries such as sympy , numpy , and matplotlib.pyplot .  I would like to fit the best surface to a small number of points.  This is why I want to find the smallest distance between a point and a quadric surface ==============================================================================
$$Ax^2 + By^2 + Cz^2 + Dxy + Exz + Fyz + Gx + Hy + Iz + J = 0$$ ============================================================================== Questions: 1)  How can I find a solution to this equation, given particular coefficients $A, B, ..., J$ ?  This is for the purpose of solving question 2, which is the key question: 2)  How can I find the smallest Euclidean distance between that surface and a point?  I have access to a computer; I'm using python2 and sympy at the moment. 3)  Is there software I can use to visualize such a surface? 4)  Are these surfaces known as ""manifolds"" in proper mathematical terms?  From brief reading, it sounds like a manifold is a more general mathematical object than the object the word ""surface"" I'm using denotes I've looked here , here , here , here , and here .","['differential-geometry', 'quadrics']"
2836183,minimum possible penalty of an arbitrary classifier?,"I'm self-studying some ML over the summer and ran into a question that I don't really understand. I don't really understand what (i) is asking. Is the minimum possible penalty not the trivial case in which you correctly predict the test example for a total penalty of 0? They mention multiple cases so it seems like they're asking for something else, but I guess I don't understand what the question is even asking. Would they not phrase the question as expected or average penalty if they were looking for something more? Any one know what I'm missing?","['machine-learning', 'statistics', 'probability']"
2836197,Computing the electric flux [duplicate],"This question already has an answer here : Using Divergence Theorem (1 answer) Closed 5 years ago . Let $B_r=\{x\in \mathbb R^3 : |x|\le r\}$ and let $dS_r$ denote the area element on $\partial B_r$. Set $$E(x)=C\int_{\partial B_R}\nabla_x |x-y|^{-1} dS_y$$ Show that for $|x|< R$, $E$ is zero and for $r<R$, the flux $\int_{\partial B_r} E(x)\cdot \nu \ dS_x$ is zero. First of all, what does $\nabla_x$ stand for? The $\nabla$ without subscripts usually stands for the gradient, but I'm not sure about $\nabla_x$. For the flux integral, is it better to use the divergence theorem or use the definition? In the former case, how do I find the divergence (i.e., how to differentiate a line integral)?","['multivariable-calculus', 'real-analysis', 'integration', 'calculus']"
2836204,Quick evaluation of the Gamma function?,"I am given an exercise about the beta distribution, with a solution: EXAMPLE 4.11 A gasoline wholesale distributor has bulk storage tanks that hold fixed supplies and are filled every Monday. Of interest to the wholesaler is the proportion of this supply that is sold during the week. Over many weeks of observation, the distributor found that this proportion could be modeled by a beta distribution with $\alpha = 4$ and $\beta = 2$. Find the probability that the wholesaler will sell at least $90\%$ of her stock in a given week. Solution If $Y$ denotes the proportion sold during the week, then
  $$f(y) =
\begin{cases}
\frac{\Gamma(4 + 2)}{\Gamma(4)\Gamma(2)}y^3 (1 - y), & 0 \le y \le 1, \\
0, & \text{elsewhere,}
\end{cases}$$
  and
  $$P(Y \lt .9) = \int_.9^\infty f(y) dy = \int_.9^1 20(y^3 - y^4)dy \\
= 20 \left\{ \left. \frac{y^4}4 \right]_.9^1 - \left. \frac{y^5}5 \right]_.9^1 \right\} = 20(.004) = .08.$$
  It is not very likely that $90\%$ of the stock will be sold in a given week. In this exercise they claim that $$\frac{\Gamma(4+2)}{\Gamma(4)\Gamma(2)}=20$$ without any explicit calculations of the integral. Moreover, it seems that the result is simply $(4+2-1)(4-1 + 2-1)=5*4=20$. What shortcut did they use to compute the gamma distribution without the need for explicit computation?","['calculus', 'statistics', 'probability', 'gamma-function', 'beta-function']"
2836220,"If $X \times Y$ is Separable, are $X, Y$ Separable?","I would suspect the question in the title is false, but I could not think of a counterexample.  The reason I am interested in this question concerns the various definitions of 'generalized manifolds.'  For some definitions, I know that generalized manifolds in dimension 1 and 2 are actual manifolds, but I think this is only when we assume the spaces are separable/metrizable.","['manifolds', 'general-topology', 'separable-spaces']"
2836255,Finding the absolute maximum,"You are in charge of manufacturing the snazzy new mobile tablets that everyone wants to own.  The revenue function, in dollars, is given by $R(s,t) = 8s+6t-s^2-2t^2+2st$  , s denotes ""steel"" model and t denotes ""titanium"" model, both in units of million (assume that you make positive but a finite number of products). I have to determine the quantity of both products for maximum revenue. My understanding: So, I think the question is asking for the global maximum point. I found the critical point and it has only one, (11,7). Now, I think we need to assume that the lowest boundary for s and t is 0 and the upper boundary is also something (I don't know what to assume). And I'm stuck here.",['multivariable-calculus']
2836261,Find the volume common to sphere $x^2+y^2+z^2$ and the cylinder $x^2+y^2<ax$,"Find the volume common to sphere $x^2+y^2+z^2<1$ and the cylinder $x^2+y^2<ax$ I set up the following integral : $$I=2\cdot \iiint_{z=0}^{\sqrt{a^2-x^2-y^2}} dz\,dy\,dz = 2\cdot\iint_E\sqrt{a^2-x^2-y^2} \, dy\,dx$$ where $E:x^2+y^2=ax$ Now under polar coordinates 
$E:r=a\cos(\theta)$ and so $0\leq r \leq a\cos(\theta)$ and $-\pi/2\leq \theta \leq \pi/2$ $$I= 2\cdot\int_{\theta=-\pi/2}^{\pi/2}\,\int_{r=0}^{a\cos(\theta)} \sqrt{a^2-r^2}\,r\,dr\,d\theta=2\cdot (1/2)\cdot(2/3)\int_{\theta=-\pi/2}^{\pi/2}a^3\cdot(1-\sin^3(\theta))d\theta = \frac{2a^3}{3}\cdot\{\int_{\theta=-\pi/2}^{\pi/2} d\theta - \int_{\theta=-\pi/2}^{\pi/2}\sin^3(\theta)d\theta\} = \frac{2\pi a^3}{3}$$ However answer given to me is $$\frac{2a^3}{3}\cdot(\pi - \frac43)$$ Where am I making the mistake? Or is it the case that the answer given to me is incorrect?","['multivariable-calculus', 'multiple-integral', 'calculus']"
2836268,Show that the quotient $X/Y$ has the Cauchy distribution.,"I have a problem with which I'm struggling for a while. Suppose that the random variables $X$ and $Y$ are independent
  and that each has the standard normal distribution.
  Show that the quotient $X/Y$ has the Cauchy distribution. I know how to solve it by Jacobian and multivariable transformation but I tried to do this a different way and I can't spot a mistake but my answer gives a contradiction. My solution: Let $G$ be the cdf of $X/Y $, then \begin{align*}
G(c)
&= \mathbb{P}(X/Y \leq c) \\
&= \mathbb{P}(X/Y \leq c \mid Y > 0)\mathbb{P}(Y > 0) + \mathbb{P}(X/Y \leq c \mid Y < 0)\mathbb{P}(Y < 0) \\
&= \frac{1}{2} \big[ \mathbb{P}(X/Y \leq c \mid Y > 0) + \mathbb{P}(X/Y \leq c \mid Y < 0) \big] \\
&= \frac{1}{2} \big[ \mathbb{P}(X \leq cY) + \mathbb{P}(X \geq cY) \big] \\
&= \frac{1}{2}.
\end{align*} Where is the mistake?","['statistics', 'probability']"
2836281,Show $x^{p^n}-x$ has distinct roots over a field of characteristic $p$.,"This problem comes from Question 14 of Chapter 5, Section 6 in I.N. Herstein's Abstract Algebra , second ed. Given a field $F$ with characteristic $p\neq 0$, show that all roots of $x^m-x$ within this field are distinct (no root has multiplicity greater than 1), where $m = p^n$ for some $n$. I know that if $F$ is a finite field of order $p$ that $$x^p-x=\prod_{a\in F}(x-a)$$ and this result should lead to having $$x^p-x=x(x-1)(x-2)(x-3)\cdots(x-(p-1))$$ as I believe I can form a finite subfield of $F$ out of these elements $\{1,2,3,\ldots,p-1,0\}$, but I'm not sure of this claim. If I can do that then I do know that $$(x^{p^k}-x)(1+x^{p^k-1}+x^{2p^k-2}+\ldots+x^{p^k\cdot p-p})=x^{p^{k+1}}-x$$ so I only need to show that $1+x^{p^k-1}+x^{2p^k-2}+\ldots+x^{p^{k+1}-p}$ is irreducible or at least is not divisible by $x-a$ for any $a\in F$. I realized that if I let $p(x) = 1+x^{p^k-1}+x^{2p^k-2}+\ldots+x^{p^{k+1}-p}$ and assumed that it was divisible by some $x-a$ we would have $$p(x)=q(x)(x-a)=xq(x)-aq(x)$$ and therefore if $$q(x) = \sum_{i=0}^{\deg q(x)}(q_ix^i)$$ we would have $p_i=q_{i-1}-aq_i$ for all $i$ (where $p_i$ is the $i^\text{th}$ coefficient in $p(x)$). From this I got that $q_0a=1$ so $q_0 = a^{-1}$ and then $q_1=a^{-2}$ and I could work my way up but I had issues figuring out how to extrapolate when I git $q_{p-1}$ and $q_{2p-2}$.","['abstract-algebra', 'polynomials', 'field-theory']"
2836304,Another variant of cops and robber.,"I am considering the following variant of the cops and robber problem, apologies if this is well-known and references are welcomed. The set up. Let $G=(V,E)$ be a simple finite undirected graph. A robber function on $G$ is some $R:\mathbb Z_{\ge 0}\to V$ such that $R(t)$ and $R(t+1)$ are adjacent vertices in $G$ , in particular $R(t)\neq R(t+1)$ for all $t$ (there are no loops in $G$ , and the robber is always ""on the move""). A cop strategy on $G$ is any function $C:\mathbb Z_{\ge 0}\to V$ , with no restriction whatsoever. We say the cop strategy $C$ captures robber $R$ if there exists some $t\in \mathbb Z_{\ge 0}$ such that $C(t)=R(t)$ . Denote $T(C,R)$ to be smallest such $t$ if exist, otherwise set it to $\infty$ . If $T(C,R) = \infty$ , then we say $R$ avoids or evades capture by $C$ . Finally, we say the graph $G$ has a sure-capture strategy if there exists a cop strategy $C$ such that for all robber function $R$ , we have $T(C,R)$ finite. Examples. If $G$ is a path graph, then $G$ has a sure-capture strategy. If $G$ is a claw with three branches, each branch with two edges, then $G$ has a sure-capture strategy. Both of above can be analyzed by looking at the parity of the possible starting positions of the robber, as these are bipartite graphs. In fact, If $G$ is a star-like graph with $n\ge 3$ branches, and each branch having two edges, then $G$ has a sure-capture strategy. (Here $G$ has $2n+1$ vertices.) Sketch. Denote the center point of $G$ as $c$ , and branch $i$ consists of vertices $a_i$ and $b_i$ , where $a_i$ is connected to both $c$ and $b_i$ . If $n$ is odd, consider the cop strategy $C$ given by $a_1,c,a_1,c,a_2,c,\ldots,a_n,a_1,c,a_1,c,a_2,c,\ldots,a_n$ . The first half ensures robber is captured if robber starts at any $a_i$ position. Now if we haven't captured the robber in the first half, then the robber must started at a $b_i$ position, which after the first half now lands in an $a_i$ position, so we repeat the strategy again. We can adapt it similarly when $n$ is even. Some questions. What simple finite graph has a sure-capture strategy? [We can easily show that if $G$ has any cycle, then $G$ does not have any sure-capture strategy. Indeed, if to the contrary that cop strategy $C$ is a sure-capture strategy on $G$ with some cycle, we can use $C$ to produce a robber function $R$ that always avoid capture, as each vertex on said cycle has degree $\ge 2$ .] So they must be forests. Consider then $G$ to be connected. Then $G$ has a sure-capture strategy implies $G$ is a tree. Do all trees have a sure-capture strategy? I am not so sure here, for a claw with three branches, but each branch with 3 or more edges in it, is there a sure-capture strategy? If $G$ has a sure-capture strategy $C$ , then for all robber function $R$ , $T(C,R)$ is finite. But is $T(C,R)$ bounded over all possible $R$ ? I am aware of the pursuit-evasion variant where both cop and robber alternate turn, both with perfect information of where each other are, both may skip go, and both must move along the edge. In such case, we analyze positions called corners (a vertex $v$ whose closed neighborhood $N[v]$ are all covered by a single vertex), and look at removal/addition of these corners. Could this be adapted here as well?","['puzzle', 'combinatorics', 'graph-theory', 'recreational-mathematics']"
2836318,Find absolute maximum and minimum values by parametrizing the boundaries,"$f(x,y) = 2\cos x + 3\sin y$  $; R= {(x , y): 0 \leq x \leq 2\pi \\\mbox{and}\\ 0 \leq y \leq \pi} $ I need to find the absolute maximum value and absolute minimum value in the region $R$, and I do have to parametrize the boundary pieces of $R$ to find critical points there. I tried taking $(x,y) = (r\cos(\theta),r\sin(\theta))$ for $\theta \in [0,2\pi]$
and then I got $h(\theta) = 2\cos(r\cos(\theta))+3\sin(r\sin(\theta))$ After that $h'(\theta)=2r\sin(\theta)\cdot\sin(r\cos(\theta))+3r\cos(\theta)\cdot(\cos(r\sin(\theta))$. I can't find values of $\theta$ for which $h'(\theta)=0$. How should I proceed from here?",['multivariable-calculus']
2836351,is this correct? $\lim\limits_{x\to a}f(x)^{g(x)} = [\lim\limits_{x\to a}f(x)]^{\lim\limits_{x\to a}g(x)}$,"I met a question, let me compute
$$ \lim\limits_{x\to 0}(\cos x)^{-x^2}$$ the answer is 1 this is not a primary function,  its structure is like $$\lim\limits_{x\to 0}f(x)^{g(x)}$$ is it a theorem, which I don't find it on my math book? probably write as 
$$\lim\limits_{x\to a}f(x)^{g(x)} = [\lim\limits_{x\to a}f(x)]^{\lim\limits_{x\to a}g(x)}$$",['limits']
2836366,"Why does dividing both sides of this system of equations to each other yields infinite ""incorrect solutions""?","This might be basic, but I'm really bad at basic math. I'm trying to solve the following system of equations:
$$\sqrt{x^2+y^2}\cdot \left(x-5\right)=6x+y \tag{1},$$$$\\\sqrt{x^2+y^2}\cdot \left(y-1\right)=6y-x-2 \tag{2}$$
I put them in Wolfram Alpha to test the result, and it yields 3 solutions, which I assume is true. All nice and dandy. But then I couldn't find out how to move forward. So I decide to divide $(2)$ by $(1)$. which gives:
$$\frac{y-1}{x-5}=\frac{6y-x-2}{6x+y} \tag{3}$$ After a few calculations, I figured that this is an equation for a circle. $$y^2+29y=-x^2+9x+10 \tag{4}$$ which implies that there's an infinite number of solutions. Which means that I'm wrong. So can anybody tell me what I did wrong? And if possible teach me how to solve the system of equations please? Thank you! :D","['algebra-precalculus', 'systems-of-equations']"
2836381,"$f_n \rightharpoonup f$, $g_n \to g$ in measure, $\|g_n\|_{L^\infty} \leq M$, then $f_n g_n \rightharpoonup fg$,","Let $f_n$, $f \in L^2(0, 1)$ be such that $f_n$ converges to $f$ weakly in $L^2(0, 1)$. Let $g_n, g : (0, 1) \to \mathbb{R}$ be measurable functions such that $g_n$ converges to $g$ in measure and $\|g_n\|_{L^\infty} \leq M$ for every $n$.
Prove that a) $g\in L^\infty(0,1)$ b) $f_ng_n$ converges to $fg$ weakly in $L^2(0, 1)$. My attempt: I think that point a) it's ok but i don't know how to finish point b). a) Since $g_n$ converges to $g$ in measure for all $\varepsilon>0$ we have
$$\lim_{n\to\infty} \mu(\{|g-g_n|<\varepsilon\})=1$$
We define $A^\varepsilon_n:=\{|g-g_n|<\varepsilon\}$ and $A^\varepsilon:=\bigcup_n  A^\varepsilon_n$. By definition $A^\varepsilon_n \subset A^\varepsilon$ for every $n$, then $\mu(A^\varepsilon_n) \leq \mu(A^\varepsilon)$ and, taking the limit for $n\to +\infty$, we get $\mu(A^\varepsilon)=1$. 
Defined $$A:=\{\,x\in (0,1)\,|\,|g_n(x)|\leq M\,\},$$ it follows $\mu(A)=1$ (and so $\mu(A^\varepsilon \cap A)=1$). I claim that there exists $C>0$ such that $|g(x)|\leq C$ for every $x\in A^\varepsilon \cap A$. Indeed for every $x\in A^\varepsilon \cap A$, there exists $\overline n=\overline n_x$ s.t. $x\in A^\varepsilon_{\overline n_x}$ and so
$$|g(x)|\leq |g(x)-g_{\overline n_x}(x)|+|g_{\overline n_x}(x)|< \varepsilon + M.$$
In conclusion, we have proved $|g(x)|< \varepsilon + M$ a.e., that is $||g||_{L^\infty}\leq M+\varepsilon.$ b) Let $h$ be an arbitrary function in $L^2$, then
$$ \bigg|\int (f_n g_n - f g) h \, dx \bigg| \leq \bigg| \int (f_n g_n - f_n g)h \, dx\bigg| + \bigg|\int (f_ng - fg) h \, dx\bigg| =$$
$$= \bigg|\int f_n(g_n - g)h \, dx \bigg| + \bigg|\int (f_n - f)g h \, dx\bigg| $$
$$\leq (2M +\varepsilon)\bigg|\int f_n h \, dx \bigg| + \bigg|\int (f_n - f)g h \, dx\bigg| $$
And now ? The second integral goes to zero (since $gh\in L^2$ and $f_n \rightharpoonup f$), but what about the first one ? I know that convergence in measure implies other modes of convergence, but this only applies to subsequences. Thanks in advance.","['alternative-proof', 'lebesgue-measure', 'proof-verification', 'weak-convergence', 'measure-theory']"
2836389,Sacred Geometry of Chance,"This problem is dedicated to Leon the professional . This question came to my mind when I was contemplating on the numbers 1-20 arranged interestingly around a regular dartboard: QUESTION: Can we divide a circle with radius of $\sqrt{3}\sigma$ on a plain into 3 optimal pieces with equal areas assigned by $1,2,3$ as score ,which an ambitious dart player with density
probability function of $f(r;\sigma )={\frac {r}{\sigma^{2}}}e^{-r^{2}/(2\sigma ^{2})}$ (Rayleigh distribution) as
probability of dart hitting in distance of $r$ from his aim point,
achieves least score from the designed dartboard plane in his
throw (guaranty getting minimum equal score from each point on the
board he may aim to shoot)? Are the shapes of these pieces unique? what are they look like? Note1: if dart goes out of the board player will get $0$ score. $\sigma$ is standard deviation in Rayleigh distribution and dart hits
in circle of radius $\sigma$ around player's aim point by probability
of about $0.39$ . Note2: At first I proposed a generalized form of this problem stating to find $n$ connected regions on a plane which they totally shape a connected closed board without any hole, assigned by $n$ natural numbers as score and the goal was to find optimal shape of each number ,But I found this simpler state of the problem as hard as enough to contemplate. ---Another Generalization can be considered: Setting a desired predefined probability score function over the dartboard plane domain(a function that you give a point of dartboard to it as input and it gives you the probable score achieves by a player who aim to hit that point as the output) and the challenge is to design a dartboard which gives us that predefined function as score probability in each point, like to design a deceiving dartboard which the score probability be least for points of region assigned by score $3$ and be highest for points of region assigned by score $1$ . for easing the problem I have considered a constant probability score function with minimum value, which still finding its minimum value is challenging. Note3: there can be other variants and generalizations of this problem which are more applied and even I think they maybe discussed earlier but it is great to discuss here too, for example in a combinatorics way a question arises where there are quantitative numbers of valuable sources in each country and a comet threaten the planet Earth with the same hitting probability for each of its points, the question here is how to divide these sources among different countries which we loose least number of sources when the comet hits (all of the sources become inaccessible in the whole country which has been hit).
However I hope this does not happen until we become advance enough in technology and facilities to eliminate such kind of threats by solving such these problems and also we human being be wise and united enough to use and benefit solutions in order to truly share our valuable sources. Ultimate Note: the song ""shape of my heart"" from the film leon the professional performed by Sting, which I like a lot, have also a very nice lyric. it says: ... He deals the cards to find the answer The sacred geometry of chance The hidden law of a probable outcome The numbers lead a dance ... I am listening and singing the song while I'm still thinking about the problem: Is this life designed by God in a way which its ""sacred geometry of chance"" ,""the hidden law of its probable outcome"",shapes our fate? what are the shapes look like? would it be shape of my heart?...","['probability', 'optimization', 'geometry']"
2836393,Hard to understand hypothesis test problem.,"In some university were collected 10 data from females and males. Something similar to M F Verify the hypothesis $\mu_M-\mu_F=360g$ knowing that $\mu_M-\mu_F>360$ with $\alpha=.01$ This was an exam problem (I don't recall the exact statement but it was something very similar to this one, the image that I put here is not the one that was in the exam I mean I don't recall the  given data). My solution This problem is about hypothesis test (I think). Data: We have this data coming from some university. Our study parameter is $\mu_M-\mu_F$. And we have $\alpha=.01$ Supposition. We don't know the distribution of our data but w.l.o.g. let's suppose it follows a normal distribution. (I think I'm wrong here because the sample is small n=10). We also know the variance of $M$ and $F$ (was asked to calculate in  before question) Hypothesis $H_A=\mu_M-\mu_F>360$ $H_0=\mu_M-\mu_F\le 360$ (Note that here we must have $\le$ althoug was given in the text $\mu_M-\mu_F=360$) then the test statistic, the region, value of test statistic, conclusion,p value, etc. I concluded that we should not deny null hypothesis. Can someone check if what I did is correct? Am I very wrong? Thanks in advance for your time","['normal-distribution', 'hypothesis-testing', 'statistics', 'probability', 'descriptive-statistics']"
2836402,Which group of order 96 is this group?,"I have a group of order 96, and I am wondering which combination of familiar groups it might be. I have tried and failed to identify it with a semidirect product of cyclic groups. $$G_1 = \langle a, b \mid a^8 = b^3 = (ab) ^2 = (a^2b^2)^3 = (a^4b^2)^3 = 1 \rangle$$ Thank you for your help.","['finite-groups', 'abstract-algebra', 'group-theory']"
2836419,Proving injectivity of a certain polynomial function,"So I have to find the second derivative of the inverse function of: $$f_{(x)}=3x^4+2x^3-8x^2-20x-160 ;  x\ge 2$$ which I already have done, but I still need to prove the function is injective over the given domain. I've tried the classic $f_{(x_1)}=f_{(x_2)}~$, but I end up with a factor I'm unable to simplify by using elementary methods. $$f_{(x_1)}=f_{(x_2)}~$$
$$3x_1^4+2x_1^3-8x_1^2-20x_1-160=3x_2^4+2x_2^3-8x_2^2-20x_2-160$$
$$3(x_1^4-x_2^4)+2(x_1^3-x_2^3)-8(x_1^2-x_2^2)-20(x_1-x_2)=0$$
$$3(x_1^2+x_2^2)(x_1+x_2)(x_1-x_2)+2(x_1-x_2)(x_1^2+x_1x_2+x_2^2)-8(x_1+x_2)(x_1-x_2)-20(x_1-x_2)=0$$
$$(x_1-x_2)(3(x_1^2+x_2^2)(x_1+x_2)+2(x_1^2+x_1x_2+x_2^2)-8(x_1+x_2)-20)=0$$ so I found the $(x_1-x_2)$ factor I needed, but I can't find a way to simplify or to factor the second expression, or a way to prove it can't be equal to 0 over the function's domain. How would one do it? Or is another way of proving the function's injectivity, other than graphing, recommended? If someone could prove it and tell me the procedure they used, it would be much appreciated.","['derivatives', 'polynomials', 'factoring', 'functions']"
2836421,Finding the shaded area in a triangle,Here is the diagram: I only know that the middle segment is a median of the big triangle. But nothing else.,"['triangles', 'geometry']"
2836425,Ants moving from vertex to vertex on a polyhedron,"On a regular polyhedron, there is one ant on each vertex. In one round, every ant walks to an adjacent vertex, each adjacent vertex with equal probability. Let $P(r)$ be probability that after r rounds, each vertex still has exactly one ant. Does $P(r)$ converge as r tends to infinity? How does the function behave? Is it monotonic? For example, $P(1)$ of tetrahedron is $\frac{1}{9}$ ; $P(1)$ of octahedron is $\frac{5}{256}$ .","['recreational-mathematics', 'probability']"
2836441,understanding an inequality with the p-th moment,"I am trying to understand how bound of the p-th moment is coming from the concentration inequality. In general, we would have, say, $S=\sum_{i=1}^na_ix_i$, where $x_i$ are random variables and $a_i$ are in $R$. Then, the concentration inequality can be written: $$
E(S-ES)^p\leq Cp^p\|a\|_2.
$$ In order to bound the $p$-th moment, one would write:
$$
E(|S|^p)^{1/p}\leq E|S| +Cp^p\|a\|_2.
$$ I cannot understand which inequality used here to get this last line? Would it be Minkovsky?","['statistics', 'probability', 'expectation']"
2836469,How would the condition for linearity for function with multiple variable be given?,"I know that a function is called linear if it satisfies the conditions
$$f(x+y)=f(x)+f(y)$$
and
$$f(ax)=af(x)$$
(i.e. it preserves the properties or operation). How is the condition for linearity given when there are multiple variable in the funciton?
for ex
$$f(x+y,z)$$ and 
$$f(ax,z)$$
I know
$$f(x+y,z)=f(x,z)+f(y,z)$$ 
is a condition for multilinear function, but can there be multivariable function which is linear and not multilinear,ie linear in all the variables at once and not seperately (like in multilinear function). How to make sense of multivariable function that is linear and that is multilinear? 
Edit: Extra details. A function $f(x,y)$ is called multlinear(bilinear to be specific) if $$f(x+a,y)=f(x,y)+f(a,y)$$
$$f(x,y+b)=f(x,y)+f(x,b)$$
and also $$f(nx,y)=nf(x,y)=f(x,ny)$$. So is 
$$f(x+a,y+b)=f(x,y+b)+f(a,y+b)+f(x+a,y)+f(x+a,b)+f(x,y)+f(a,b)+f(x,b)+f(a,y)$$ when $f(x,y)$ is multilinear and
$$f(x+a,y+b)=f(x,y)+f(a,b)$$ 
when $f(x,y)$ is linear?","['linear-algebra', 'multilinear-algebra']"
2836482,Set equivalence - Zorich's real analysis,"I am doing my BS Mathematics second year through an open university IGNOU . I am taking a first course in real analysis . I am using the text by Bartle and Shebert and the one by Zorich to supplement it. I would like to have my proof on elementary set equivalence verified. This is a naive attempt. Verify the relation $$(A \subset C)\wedge(B \subset C)\iff((A \cup B) \subset C)$$ Proof. (1) Consider arbitrary elements $x_{1}\in A,x_{2} \in B$ . We are given $(A \subset C) \wedge (B \subset C)$ . It follows - $x_{1} \in A \implies x_{1} \in C$ . $x_{2} \in B \implies x_{2} \in C$ . $x_{1},x_{2} \in (A \cup B) \implies x_{1},x_{2} \in C$ Consequently, $(A \cup B) \subset C$ . $(A \subset C) \wedge (B \subset C) \implies (A \cup B) \subset C$ . (2) In the other direction, consider arbitary elements $x_{1},x_{2} \in (A \cup B)$ . Given $(A \cup B) \subset C$ , we must have $x_{1},x_{2} \in C$ . But, $x_{1},x_{2} \in (A \cup B)$ implies (a) $x_{1} \in A, x_{2} \in B$ or (b) $x_{1},x_{2} \in (A \cap B)$ or (c) $x_{1},x_{2} \in A, B = \phi$ or (d) $A = \phi, x_{1},x_{2} \in B$ Each of these implies the left hand side $(A \subset C)\wedge(B \subset C)$ holds. $((A \cup B) \subset C) \implies (A \subset C)\wedge(B \subset C)$ From (1) and (2) we have : $((A \cup B) \subset C) \iff (A \subset C)\wedge(B \subset C)$","['elementary-set-theory', 'proof-verification']"
2836525,Are $\mathbb{R}[X] / (X^2 +1)$ and $\mathbb{C}$ homeomorphic?,"The fields $\mathbb{R}[x] / (x^2 +1)$ and $\mathbb{C}$ are isomorphic as fields , but I am trying to see if they are homeomorphic as well. $\mathbb{C}$ is given its standard topology, and we can define a metric on $\mathbb{R}[x]$ by $$
d 
\left( 
\sum_{j = 0}^a a_j x^j ~, \sum_{j = 0}^b b_j x^j 
\right)
:= 
\left( 
\sum_{j = 0}^{\max\{a,b\}} (a_j - b_j)^2
\right)^{1/2}
$$ which induces a topology. $\mathbb{R}[x] / (x^2 +1)$ is then given the quotient topology. Any polynomial $[f] \in \mathbb{R}[x] / (x^2 +1)$ can be written as $[f] = a [1] + b [x]$ with $a,b \in\mathbb{R}$ . A field isomorphism can then be given by the map $\psi : \mathbb{R}[x] / (x^2 +1) \rightarrow \mathbb{C}$ with $$
\psi([1]) = 1 ~~~,~~~ \psi([x]) = i
$$ We then have that $\psi$ combined with the quotient map $\pi: \mathbb{R}[x] \rightarrow \mathbb{R}[x] / (x^2 +1)$ gives $$
\psi \circ \pi \left( \sum_{k = 0}^a a_j x^k \right)
=
\psi \left( \sum_{k = 0}^a a_k [x]^k \right)
=
\sum_{k = 0}^a a_k i^k
=
\operatorname{eval}_i  \left( \sum_{k = 0}^a a_j x^k \right)
$$ I checked that for any convergent sequence $f_n \rightarrow f$ we have $\lim_{n \rightarrow \infty} \operatorname{eval}_i(f_n) = \operatorname{eval}_i(f) $ and since $\mathbb{R}[x]$ and $\mathbb{C}$ are metric spaces, this shows that $\operatorname{eval}_i = \psi \circ \pi$ is contiuous. By the universal property of quotient maps , this also shows that $\psi$ is continuous. But I am kind of stuck on proving the continuity of $\psi^{-1}$ and would be glad for any ideas. Another thing I am questioning is, whether the topology I chose on $\mathbb{R}[x]$ is the most natural one you could choose. The second possibility I could think of is to look at $\mathcal{C}(\mathbb{C},\mathbb{C})$ with the compact-open topology and consider $\mathbb{R}[x]$ as a subspace if this (continuity of $\operatorname{eval}_i$ would easily follow in this case). It would be interesting to know if they are homeomorphic or not. Update As Paul Frost poited out (and showed), $\psi$ is not continuous with the assumptions I made. I also went back to check my calculations on the continuity of $\operatorname{eval}_i$ and indeed found a mistake there. He also showed that $\mathbb{R}[x]$ equipped with the topology induced by the $\Vert \cdot \Vert_1$ norm does make $\psi$ continuous. Since the proof by paul blart math cop for the continuity of $\psi^{-1}$ remains correct under these circumstances, $\psi$ is shown to be a homeomorphism in this case. So this anwsers the first part of my question.","['general-topology', 'field-theory', 'complex-numbers', 'quotient-spaces']"
2836539,"On the integral $\int_{0}^{\pi/2} \frac{x \log \left ( 1-\sin x \right )}{\sin x} \, \mathrm{d}x$","Recently I run into this integral $$\mathcal{J} = \int_{0}^{\pi/2} \frac{x \log \left ( 1-\sin x \right )}{\sin x} \, \mathrm{d}x$$ I don't know to what it evaluates. I tried several approaches. 1st: Differentiation under the integral sign Consider the function $\displaystyle f(\alpha)= \int_{0}^{\pi/2} \frac{x \log \left ( 1-\alpha\sin x \right )}{\sin x} \, \mathrm{d}x$. Hence \begin{align*}
\frac{\mathrm{d} }{\mathrm{d} \alpha} f(\alpha) &= \frac{\mathrm{d} }{\mathrm{d} \alpha} \int_{0}^{\pi/2} \frac{x \log \left ( 1-\alpha\sin x \right )}{\sin x} \, \mathrm{d}x \\ 
 &= \int_{0}^{\pi/2} \frac{\partial }{\partial \alpha}  \frac{x \log \left ( 1-\alpha\sin x \right )}{\sin x} \, \mathrm{d}x  \\ 
 &= -\int_{0}^{\pi/2} \frac{x \sin x}{\sin x \left ( 1- \alpha \sin x \right )} \, \mathrm{d}x\\ 
 &=- \int_{0}^{\pi/2} \frac{x}{1- \alpha \sin x} \, \mathrm{d}x
\end{align*} And the last integral equals? 2nd: Taylor series expansion Lemma: It holds that $$x \sin^n x = \left\{\begin{matrix}
2^{1-n}\displaystyle\mathop{\sum}\limits_{k=0}^{\frac{n-1}{2}}(-1)^{\frac{n-1}{2}-k}\binom{n}{k}\,x\sin\big((n-2k)x\big) & , & n \;\; \text{odd} \\\\ 
2^{-n}\displaystyle\binom{n}{\frac{n}{2}}\,x+2^{1-n}\mathop{\sum}\limits_{k=0}^{\frac{n}{2}-1}(-1)^{\frac{n}{2}-k}\binom{n}{k}\,x\cos\big((n-2k)x\big) &  , & n \;\; \text{even}
\end{matrix}\right.$$ Hence, \begin{align*}
\int_{0}^{\pi/2} \frac{x \log \left ( 1-\sin x \right )}{\sin x} \, \mathrm{d}x &=  -\int_{0}^{\pi/2} \frac{x}{\sin x} \sum_{n=1}^{\infty} \frac{\sin^n x}{n} \, \mathrm{d}x \\ 
 &=-\sum_{n=1}^{\infty} \frac{1}{n} \int_{0}^{\pi/2} x \sin^{n-1} x \, \mathrm{d}x
\end{align*} However the lemma does not help at all. In fact, if someone substitutes the RHS what it seems to be in there is an $\arcsin $ Taylor expansion. The series that remains to be evaluated is very daunting. To sum up, I don't know to what this integral evaluates. I don't even know if a nice closed form exists neither do I expect one. But , I still hope.","['real-analysis', 'integration']"
2836685,"Distinguishing Two Compactifications of $[0,1)$","Pictured below are two subsets of the plane, each a compactification of the closed half-line with remainder a closed arc.  I am really frustrated by my inability to prove that the space pictured on the right, an arc with a ray seesawing back and forth toward it, is not homeomorphic to the closed topologist's sine curve.  How does one show this? As well, in Nadler he refers to this object as the 'M-Continuum'.  I have seen the left figure also referred to as the M-Continuum by another author, where there are 'half-length dips' between each dip of the typical sine curve.  Are these two spaces homeomorphic? I really have trouble figuring out how to compare these spaces.  Can anyone help? Here is a better image of this other 'M-Continuum': http://hyperspacewiki.org/index.php/M_continuum","['plane-curves', 'compactification', 'continuum-theory', 'general-topology', 'metric-spaces']"
2836702,Inequality with complex number,"I have the following homework question for a course in complex analysis: Determine all the $z\in\mathbb{C}$ with $|\sin z| ≤ 1$, and find an $n\in \mathbb{N}$ such that $|\sin(in)| > 10 000$. I have however no clue how to do this, also because during the lecture the teacher said that is no ordering in the complex numbers. I tried substituting $\sin(z)=\frac{1}{2i}(e^{iz}$ - $e^{-iz})$ but this didn't bring my any further.",['complex-analysis']
2836720,"How to prove that $x^2+y^2+z^2=14^n$ holds for distinct integers $x,y,z$ for every natural $n$?","Prove that for all natural numbers $n$, there exist distinct integers $x, y, z$ for which, $x^2+y^2+z^2=14^n$ How to prove this using mathematical induction? Some context: A related question asks for solutions of $x^2 + y^2 + z^2 = 3^{10}$ where the asker first tries to express $3^1$ and $3^2$ as sums of three squares and then combine these to construct a representation of $3^3$, and so on. However, none of the answers seem to use this approach. Legendre's three square theorem states that $n \in \mathbb{N}$ can be expressed as a sum of three squares if and only if $n$ is not of the form $4^a(8b+7)$, and $14^k$ clearly isn't. However, it does not guarantee that  $x,y,z$ are distinct and applying it  is not (at least not directly) a proof by induction.","['discrete-mathematics', 'induction', 'elementary-number-theory']"
2836737,"What is the least and greatest element in symmetric but not reflexive relation over $\{1,2,3\}$?","Let $S=\{1,2,3\}$ and $R$ be a symmetric but not reflexive relation over $S$. Because $R$ is a set of all relations (under the given conditions) over $S$ then $\subseteq$ is a partial order over $R$. Prove that there's the least element in $R$ and prove that $R$ doesn't have the greatest element. I think that the empty set is the least element in $R$ because for empty set is in any subset of $R$ by definition of empty set. Therefore the empty set is in relation with every element of $R$. I'm confused why $R$ doesn't have the greatest element. Isn't it:
$$
X=\{(1,2),(2,1),(1,3),(3,1),(2,3),(3,2)\}
$$
? $X$ contains all the symmetric pairs in $R$ and it contains every other element of $R$.","['relations', 'elementary-set-theory']"
2836777,Cauchy's principal part equation,"In the book Many-Body Physics by Coleman, on page 110 there is the following statement: Using Cauchy's principal part equation, $1/(x-i \delta) = P(1/x) + i \pi \delta(x)$ , where $P$ is the principal part. Here $\delta$ is a number and $\delta(x)$ I presume to be the Dirac delta.
I am not sure what this means. I assume it is related to the principal part of a function but, otherwise, I don't know how to obtain this. Help would be appreciated.",['complex-analysis']
2836780,Understanding the range of $f(x) = \frac{x}{\sqrt{1-x^2}}$,"Let's take the function $$f(x)=\frac{x}{\sqrt{1-x^{2}}}.$$ My question is, why is the range of the function is all real numbers? Because doesn't the fact that the denominator must be $f(x)=\sqrt{1-x^{2}}$ and that the numerator must be $x$ limit the amount of values the function can produce? Because for every $x$, only one denominator value is possible. Doesn't this limit the output of this function, therefore preventing it from producing all real numbers? And furthermore, can you prove to me that the $x$ inputs needed to produce every single real number are ordered from smallest to largest? Basically, why is it the case here that the larger the $x$-value you put in, the larger the $y$-value? Can someone please explain to me, as simply as possible and without calculus, why the range of the function is all real numbers? And furthermore, can you prove to me that the $x$ inputs needed to produce every single real number are ordered from smallest to largest? Basically, why is it the case here that the larger the $x$-value you put in, the larger the $y$-value?","['algebra-precalculus', 'functions', 'rational-functions']"
2836813,Question on the proof $\int_0^\infty \frac{\sin(at)}{t}dt=\frac{\pi}{2} \operatorname{sgn}(a)$.,"In my solution, for the proof of $$\int_0^\infty \frac{\sin(ax)}{x}dx=\frac{\pi}{2} \operatorname{sgn}(a),$$ they do as under. The only important thing is where the red square is (the rest is as usual). The says that $\sin(t)\geq \frac{t}{2}$ when $[0,\pi/6]$ and $\sin(t)\geq \frac{1}{2}$ when $t\in [\pi/6,\pi/2]$. But why don't the simply use the fact that $\sin(t)\geq \frac{t}{2}$ on $[0,\pi/2]$, what gives $$\int_0^{\pi/6}e^{-R\sin(t)}dt\leq \int_0^{\pi/2}e^{-Rt/2}dt=\frac{-2}{R}\left[e^{-Rt/2}\right]_{0}^{\pi/2}=\frac{-2}{R}(e^{-R\pi/4}-1)\underset{R\to \infty }{\longrightarrow }0.$$ Is there something I didn't get ? Because taking $\sin(t)\geq t/2$ for all $t\in [0,\pi/2]$ instead of taking $\sin(t)\geq t/2$ on $[0,\pi/6]$ and $\sin(t)\geq 1/2$ on $[\pi/6,\pi/2]$ looks to work great, no ?",['complex-analysis']
2836814,Dependence of spinor bundle on choice of metric,"For an oriented Riemannian manifold $(M^n,g)$ with spin structure, one can define the spinor bundle $\pi_g:\mathbf{S}_g\to M$. The space of metrics is convex. So if $g_t=(1-t)g_0+tg_1$ is a family of metrics, I think all spinor bundles $\pi_{g_t}:\mathbf{S}_{g_t}\to M$ are isomorphic as smooth vector bundles over $M$. So what exactly is the dependence of the spinor bundle on the choice of metric?","['spin-geometry', 'differential-geometry']"
2836827,Projecting a surface on another surface,"I would like to know if there is a method, and what is called the area of mathematics that studies this kind of things, for projecting surfaces on other surfaces. Example : suppose to have a half-sphere (3d) centered in $(1,1,1)$. I want to find its projection on the plane $z=0$  as seen from the direction defined by the vector $(1,0,1)$ (the line $z=x$ on the $y=0$). How is then given the parametric formula of the surface ""projected""? Basically this is how to find the shape of the shadow of an umbrella, and I would like to generalize it.","['projection', 'geometry']"
2836862,The ordinary generating function for the square-free kernel: reference request about singularities and its phase plot,"Let $n\geq 1$ an integer, in this post I denote the product of distinct prime numbers dividing dividing $n$ as $$\operatorname{rad}(n)=\prod_{\substack{p\mid n\\p\text{ prime}}}p,$$
is the famous arithmetic function that appears in the abc conjecture.
See it you want the Wikipedia Radical of an integer Claim. It's easy to prove that the ordinary generating function
$$f(z)=\sum_{n=1}^\infty \operatorname{rad}(n)z^n\tag{1}$$ for the square-free kernel or radica of $n$ has radius de convergence $1$. Proof. It's obvious the inequality $1\leq \operatorname{rad}(n)\leq n$ thus $1\leq (\operatorname{rad}(n))^{1/n}\leq n^{1/n}$, and from here squeeze theorem implies $(\operatorname{rad}(n))^{1/n}\to 1$. And the Cauchy–Hadamard theorem that $R=1$.$\square$ Question 1. I'm curious about what standard claims/questions, if any, can be stated about the singularities of a the generating function $f(z)$ over $|z|=1$. That is, imagine that we want to study the singularities of $f(z)$ over $|z|=1$, what questions can be studied? Many thanks. Thus I'm asking what standard questions should can be studied being those potentially interesting. Aren't required deduction, only are required some details about what topics/issues can be studied about the set of singularities of $f(z)$ on the set of complex numbers $|z|=1$. If you know it, or more advanced questions from the literature refer it answering this Question 1 as a reference request, and I try to find and read the theory about previous generating function and its singularities from the literature. I wondered previous and next question searching information about the generating function of the greatest prime factor (that is a different arithmetic function) 
 in Internet that I found [1]. Question 2 (Optional). I would like to know* the phase plot for previous ordinary generating function $$f(z)=\sum_{n=1}^\infty \operatorname{rad}(n)z^n$$ in the same spirit that is showed in the first plot of the section Greatest Prime Factor from Linas' Mathematical Art Gallery [1]. Can you provide us, or do you know it from the literature, the phase plot for $(1)$ over $|z|\leq 1$? Many thanks. I would like to see the plot (feel free if you want to add some mathematical details about how calculate it) with the purpose to know it. References: [1] Greatest Prime Factor , from Linas' Mathematical Art Gallery, home page of Lina Vepstas (2016).","['analytic-number-theory', 'reference-request', 'generating-functions', 'complex-analysis', 'singularity']"
2836874,"Derivatives 101: what does ""with respect to"" mean?","I'm studying derivatives 101 and I can't get my head around the phrasing ""with respect to"" something. Eg in chain rule we calculate the derivative of outer function with respect to inner + derivative of inner with respect to x. But what does it actually mean (in human language) to say a derivative is ""with respect to"" anything at all? Thanks a ton.",['derivatives']
2836900,Prove that $| \operatorname{Aut}(D_n)|= n\phi(n)$,"Prove that for $n\gt 2$ , $| \operatorname{Aut}(D_n)|\le n\,\phi(n)$ where $D_n$ is the dihedral group with $2n$ elements and $\phi$ is Euler phi function. Let $\rho$ be a rotation such that $o(\rho)=n$ , that is $R_n = \langle\rho\rangle$ , and $\psi$ an automorphism of $D_n$ ; then $\psi(\rho)$ must have order $n$ and there are only $\phi(n)$ such elements in $D_n$ and they are all rotations, therefore $\psi(R_n)=R_n$ . Now let $\iota$ be the reflection through the $x$ -axis, we have to send it in one of the $n$ reflection and since $D_n = \langle\rho, \iota \rangle$ , $\psi$ is univocally determined.
In conclusion we have at most $n\phi(n)$ choices for $\psi$ . I could have also considered all the sets with two elements that generate $D_n$ which are of the form $\{\rho, \iota\}$ with $\rho$ a rotation of order $n$ and $\iota$ a reflection (there are $n\phi(n)$ of them); since an automorphism sends a set of generators into a set of generators we have again at most $n\phi(n)$ automorphisms (a rotation will be sent in a rotation) obtained by extending to a homomorphism the various choices (which give us bijective functions). Moreover there are exactly $n\phi(n)$ of them because every choice give us a different automorphism. Are both solutions, and my remark, correct? Thanks in advance Edit: I was wrong saying that the only sets of two elements generating $D_n$ are of the form $\{\rho, \iota\}$ , because there are also sets formed by two reflections, but since a rotation must be sent in a rotation my second proof should be correct.","['automorphism-group', 'finite-groups', 'proof-writing', 'dihedral-groups', 'group-theory']"
2836911,How interpret convergence in probability?,"Q1) We say that $X_n\to X$ in probability if $$\forall \varepsilon>0, \lim_{n\to \infty }\mathbb P\{|X_n-X|>\varepsilon\}=0.$$ What does it mean concretely ? What could be the interpretation behind ? Q2) What would be the difference between 1) $$\forall \varepsilon>0, \lim_{n\to \infty }\mathbb P\{|X_n-X|\leq \varepsilon\}=1$$ 2) $$\forall \varepsilon>0, \mathbb P\{\lim_{n\to \infty }|X_n-X|\leq \varepsilon\}=1$$ 3) $$\mathbb P\{\forall \varepsilon>0, \lim_{n\to \infty }|X_n-X|\leq \varepsilon\}=1$$ 4) $$\lim_{n\to \infty }\mathbb P\{\forall \varepsilon>0, |X_n-X|\leq \varepsilon\}=1.$$ I'm not really sure how to interpret all these four limits since they look almost the same for me. I can see that 1) is nothing more than the convergence in probability. If someone could explain me the difference between all these limit, it would help me very much to understand better those concept of convergence.","['probability-theory', 'probability', 'measure-theory']"
2836915,Calculus of variation with discontinuous solutions,"I'm thinking of the following question: Consider a function $f: U\rightarrow\mathbb{R}$ where $U=[0,L_1)\cup(L_1,L]$ , and an energy functional $$F=\int_{U}\Big (\frac{\mathrm{d}f}{\mathrm{d}x}\Big)^2\mathrm{d}x.$$ The boundary condition is $f(0)=f(L)=0$ . Also, assume $f$ has a jump discontinuity at $x=L_1$ , i.e., $f(L_1^-)=-f(L_1^+)=-a$ , where $a$ is a constant, and $L_1$ is a variable. The question is: what is the minimum energy? Simple answer: the Euler-Lagrange equation on $[0,L_1)$ and $(L_1,L]$ is $$\frac{\mathrm{d}^2 f}{\mathrm{d}x^2}=0,$$ Therefore we have the following solution: $$f(x) =
\begin{cases}
 -\frac{a}{L_1}x,  & \text{x$\in [0,L_1)$} \\
 -\frac{a}{L-L_1}x+\frac{L}{L-L_1}a, & \text{x$\in (L_1,L]$}
\end{cases}$$ Then the energy function $F(L_1)=\frac{a^2}{L_1}+\frac{a^2}{L-L_1}$ . Therefore we have the minimum energy $4a^2/L$ when $L_1=L/2$ . Then I tried Fourier series. The Fourier series for the discontinuous solutions are $$  f(x)=\sum_{k=1}^{\infty}\Big[\frac{4a}{k\pi}\cos\frac{k\pi L_1}{L}+\frac{2aL}{(k\pi)^2}\Big(\frac{1}{L-L_1}-\frac{1}{L_1}\Big)\sin\frac{k\pi L_1}{L}\Big]\sin\Big(\frac{k\pi x}{L}\Big),$$ When we substitute this representation into the energy functional, we get infinite energy. In particular, \begin{align}
F(L_1=L/2) &  =\sum_{k=1}^{\infty}\Big(4a\cos\Big(\frac{k\pi}{2}\Big)\Big)^2\cdot\frac{1}{2L}\\
 & =\sum_{k=1}^{\infty}\frac{4a^2}{L}(1+\cos k\pi)~\mathrm{e}^{-\lambda_1 k} & \text{$\lambda_1\to0^+$}\\ 
 & \to\frac{4a^2}{L}\cdot\frac{1}{\lambda_1}\\
\end{align} \begin{align}
F(L_1=L/4) & =\sum_{k=1}^{\infty}\Big(4a\cos\Big(\frac{k\pi}{4}\Big)-\frac{16}{3}\frac{a}{k\pi}\sin\Big(\frac{k\pi}{4}\Big)\Big)^2\cdot\frac{1}{2L}\\
 & =\sum_{k=1}^{\infty}\frac{4a^2}{L}\Big(1+\cos \Big(\frac{k\pi}{2}\Big)\Big)~\mathrm{e}^{-\lambda_2 k}\\& +\sum_{k=1}^{\infty}\Big(\frac{128a^2}{9L}\frac{1}{(k\pi)^2}\sin^2\Big(\frac{k\pi}{4}\Big)-\frac{64a^2}{3L}\frac{1}{k\pi}\sin\Big(\frac{k\pi}{4}\Big)\cos\Big(\frac{k\pi}{4}\Big)\Big)& \text{$\lambda_2\to0^+$}\\ 
 & \to\frac{4a^2}{L}\cdot\frac{1}{\lambda_2}-\frac{4}{3}\cdot\frac{a^2}{L}\\
\end{align} It is not surprising that the energies are infinite due to the Gibbs phenomenon. However, it is surprising when we take a look at the energy difference: $$F(L_1=L/4)-F(L_1=L/2)=\Big(\frac{4a^2}{L}\cdot\frac{1}{\lambda_2}-\frac{4a^2}{L}\cdot\frac{1}{\lambda_1}\Big)-\frac{4}{3}\cdot\frac{a^2}{L}$$ While when we use $F(L_1)=\frac{a^2}{L_1}+\frac{a^2}{L-L_1}$ , we get $F(L_1=L/4)-F(L_1=L/2)=\frac{4}{3}\cdot\frac{a^2}{L}$ . My observation is that when we ""ignore"" the divergent term, the Fourier series give us the correct absolute value for the energy difference but wrong sign (I have checked for all values of $L_1$ ). I don't feel like it is a coincidence. To get the correct value of energy difference, I'm guessing that maybe when we use Fourier series, we introduce a vanishing length scale for the jump discontinuity, and this length scale should be the same whatever the value of $L_1$ is, and somehow $\lambda_1$ , $\lambda_2$ are related to it so that $\frac{4a^2}{L}\cdot\frac{1}{\lambda_2}-\frac{4a^2}{L}\cdot\frac{1}{\lambda_1}$ may be some finite number. My question is whether we can use Fourier series to get the correct value of energy difference.","['divergent-series', 'calculus-of-variations', 'fourier-series', 'sequences-and-series']"
2836916,What are the abelian extensions of $\Bbb C(X)$?,"I would like to have a precise description of the finite abelian extensions of the field $ K = \Bbb C(X)$. Typically, can we describe the abelianization of its absolute Galois group $G_K$? Thoughts: It is known for instance that the abelianization of the absolute Galois group of $\Bbb Q$ is $\widehat{\Bbb Z}^{\times}$. 
Maybe there is a geometric approach to my problem, via compact Riemann surfaces (equivalently, via smooth projective algebraic curves over $\Bbb C$). As mentioned in this question, the finite abelian extensions of $K$ correspond to ""abelian covers"" of $\Bbb P^1_{\Bbb C}$. I don't know if this is could be related to geometric class field theory, somehow? My idea was to use Kummer theory , since all the roots of unity belong to $K$ and $K$ has characteristic $0$.
The map $L \mapsto L^{\times, n} \cap K^{\times}$ is a bijection between the set of abelian extensions $L/K$ of exponent $n$ and the subgroups $K^{\times, n} \leq H \leq K^{\times}$.
Under this bijection, if $L/K$ is finite , then its Galois group is isomorphic to $H / K^{\times, n}$.
Since $K$ is the fraction field of the UFD $\Bbb C[X]$, whose units are well-known, I think that we have
$$K^{\times} \cong \Bbb C^{\times} \oplus \Bbb Z^{(\Bbb C)}$$
where$^{(1)}$ $u \prod\limits_{\alpha \in \Bbb C} (X - \alpha)^{n_{\alpha}}$ is sent to $(u, (n_\alpha))$.
But then there are too many subgroups... and I don't know how to relate it to $\varprojlim\limits_{L/K \text{abelian finite}} \mathrm{Gal}(L/K)$.
It is mentioned here that the maximal pro-$p$ quotient of $G_K^{\mathrm{ab}}$ is 
$\Bbb Z_p^{(\Bbb C)}$. Some other notes:
the absolute Galois group of $K$ is the profinite completion of the free group of rank $2^{\aleph_0}$, according to the paper cited here .
The algebraic closure of $K$ is difficult to describe, actually.
If we are interested in the $X$-adic completion of $K$, then  we get $\Bbb C((X))$, which is a quasi-finite field (i.e. its absolute Galois group is the pro-cyclic group $\widehat{\Bbb Z}$). Thank you for your help! $^{(1)}$
For instance the subgroup 
$$H = \left\{
u (X-a)^{k_a} \prod_{b \neq a} (X-b)^{n k_b} \mid u \in \Bbb C^{\times}, k_b = 0 \text{ for almost all } b
\right\} \leq K^{\times}$$
corresponds to the abelian extension 
$L = K(\sqrt[n]{H}) =  \Bbb C\left( \sqrt[n]{X-a} \right)/K$.","['galois-theory', 'class-field-theory', 'abstract-algebra', 'algebraic-number-theory', 'field-theory']"
2836927,Closed form for solution of ODE?,"Suppose that $g$ is defined over $\mathbb R$ and $$f'(x) = g(x) \, (g'(x))^2.$$ Is it possible to find a closed form for the indefinite integral $f$ as a function of $g$?","['indefinite-integrals', 'ordinary-differential-equations']"
2836935,Question regarding central limit theorem proof using Lyapunov's condition,"Let $X_n\sim \operatorname{independent} \operatorname{Uniform} (0,n^2)$. I need to find $a_n$ and $b_n$ such that $$\frac{\sum_{k=1}^n (X_k -a_n)}{b_n}$$ converges in distribution to a non-degenerate limit. My apporach is to use Lindeberg condition (Lyapunov's condition) to this and prove this converges to standard normal distribution. This is my work so far: $X_k= n^2 Z_k$ where $Z_k$ ~ $U[0,1]$ . Under  Lyapounov's condition i use $\delta =2$ . So $$E|X_k|^{2+\delta} = E|X_k|^4 = n^8E|Z_k|^4.$$ $$D_n =\sum_1^n \sigma^n_k = \sum_1^n \frac {n^4}{12}.$$ Using Lyapounov's condition $$\frac{E|X_k|^{4}}{D^2_n} = \frac{E|X_k|^4\sum_n^8}{(\sum\frac {n^4}{12})^2}.$$ if my work is correct , then this seems to be a divergent series so this as a results of that lindeberg condition will not satisfy. Can anyone help me figure out what did i do incorrectly ? Maybe there is an easy way to prove this rather than this way.","['probability-theory', 'convergence-divergence', 'central-limit-theorem']"
2836952,Find the volume common to the surfaces $y^2+z^2=4ax$ and $x^2+y^2=2ax$,"Find the volume common to the surfaces $y^2+z^2=4ax$ and $x^2+y^2=2ax$ I set up the following integral : $$\iiint_{z=-\sqrt{4ax-y^2}}^{\sqrt{4ax-y^2}}\,dz\,dy\,dx = 2\cdot \int_{x=0}^{2a} \int_{y=-\sqrt{2ax-x^2}}^{\sqrt{2ax-x^2}} \sqrt{4ax-y^2}\,dy\,dx$$ Which is not easy to integrate. If I use polar coordinates the integration becomes $$2\cdot \int_{\theta=-\pi/2}^{\pi/2} \int_{r=0}^{2a\cos(\theta)} \sqrt{4ar\cos(\theta)-r^2\sin^2(\theta)} \cdot r\,dr\,d\theta$$ Which is again difficult","['multivariable-calculus', 'multiple-integral', 'calculus']"
