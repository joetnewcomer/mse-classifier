question_id,title,body,tags
2443294,Doob's Maximal Inequality and Doob's L^p Inequality for Sub Martingales,"Let $X:\Omega\times[0,T]\longrightarrow \mathbb{R}$ be a non-negative submartingale with cadlag sample paths, $p>1$ and $C>0$. Then I understand that Doob's Maximal Inequality is given by:
\begin{equation*}
\mathbb{P}\left( \sup_{t\in [0,T]} X_t \ge C\right) \le \frac{\mathbb{E}\left[ X_T\right]}{C}
\end{equation*}
And Doob's $\mathcal{L}^p$ Inequality is given by:
\begin{equation*}
\left\Vert \sup_{t\in [0,T]} X_t\right\Vert_p \le \frac{p}{p-1}\left\Vert X_T\right\Vert_p
\end{equation*} My questions are: 1)What happens when I take $T\rightarrow\infty$ and could you please provide a careful proof of why it is the case (of whatever happens as we take $T\rightarrow\infty$)? I would suspect that the following inequalities hold:
\begin{equation*}
\mathbb{P}\left( \sup_{t\in \mathbb{R}^+} X_t \ge C\right) \le \frac{\sup_{T\in \mathbb{R}^+}\mathbb{E}\left[ X_T\right]}{C}
\end{equation*}
And:
\begin{equation*}
\left\Vert \sup_{t\in \mathbb{R}^+} X_t\right\Vert_p \le \frac{p}{p-1}\sup_{t\in \mathbb{R}^+}\left\Vert X_T\right\Vert_p
\end{equation*} Basically because $\mathbb{E}\left[X_T\right] \le \mathbb{E}\left[ X_{T+1}\right]$ $\forall T\in \mathbb{R}^+$ and the sets event/random variables on the LHS of the inequalities are also increasing. (I think I actually kind of proved this to myself...but I am extremely in-confident about my own abilities and hence am asking for a) a sanity check b) it would be nice to see how someone else would prove this as I may learn a new trick/technique/insight from their proof!) 2) Intuitively why is the assumption of cadlag sample paths so crucial? 3) (This really is more of a sanity check) do these inequalities hold (both for $T\in \mathbb{R}$ and as $T\rightarrow\infty$) if we remove the assumption that $X$ is a non-negative martingale and subsequently write the Doobs Maximal Inequality with absolute values? I.e. \begin{equation*}
\mathbb{P}\left( \sup_{t\in [0,T]}\left\vert X_t\right\vert \ge C\right) \le \frac{\mathbb{E}\left[\left\vert X_T\right\vert\right]}{C}
\end{equation*} (and Doobs $\mathcal{L}^p$-Inequality does not change, because the absolute values are automatically already built in) Thanks in advanced.","['inequality', 'probability', 'martingales']"
2443302,Uniqueness of characteristic polynomial of linear transformation in finite fields,"Let $T : V \to V$ be a linear transformation of the $F$-vector space $V$. Then using the (abstract) determinant function $\det : \operatorname{Hom}(V, V) \to K$ we can define a function
$$
  \lambda \mapsto \det(\lambda \cdot \operatorname{id} - T)
$$
from $F$ to $F$. Now if we represent $T$ by a matrix $A$ we then have $\det(\lambda \cdot \operatorname{id} - T) = \det(\lambda \cdot I - A)$ where on the RHS the determinant function is an expression in the entries of the matrix. Now if we change the basis, i.e. represent $T$ by a different matrix $B = S^{-1}AS$, then a simple calculation shows that
$\det(\lambda \cdot I - B) = \det(S^{-1}(\lambda I - A)S) = \det(\lambda \cdot I - A)$ and hence the value of of the matrix expression does not depend on the basis. But this is often used as a justification that the characteristic polynomial (i.e. the polynomial $\det(\lambda \cdot I - A)$) is independent of the of the choosen basis. But all I can derive from the above arguments is that the values of the determinant are the same, i.e. if $p(x) := \det(x\cdot I - A)$
and $q(x) := \det(x \cdot I - A)$, then $q(x) = p(x)$ for all $x \in F$ if $B = S^{-1}AS$. If $F$ is infinite, this gives that the polynomials are equal (i.e. have the same sequence of coefficients, and hence the coefficients represent also invariants of the transformation). But the equality that for $p(x) = a_n x^n + \ldots + a_1 x + a_0$, $q(x) = b_m x^m + \ldots + b_1 x + b_0$ we have
$$
 p(x) = q(x) \quad \mbox{ iff } \quad m = n, ~ a_i = b_i, ~ i = 0,\ldots, n
$$
does not need to hold in finite fields, for example $p(x) = x^2 + x$ and $q(x) = 0$ in $\mathbb Z/2\mathbb Z$. So then, is the characteristic polynomial (as a formal polynomial, i.e. determined by its coefficients) still unique in the case of finite fields? And if not, do you know an example?","['matrices', 'abstract-algebra', 'finite-fields', 'linear-algebra']"
2443305,"Show that $\lim_{(x, y)\to(0,0)}\frac{x^4y^4}{(x^2+y^4)^3}$ D.N.E","Show that $$\lim_{(x,y)\to(0,0)}\frac{x^4y^4}{(x^2+y^4)^3}$$ D.N.E In order to do this I should consider two paths and show that they do not reach the same limit. Consider when $x=0$. Then we have $\lim_{y\to 0}\dfrac{y^4}{y^{12}}=\dfrac{1}{y^8}=\infty$ Similarly if we choose $y=0$, then we have Then we have $\lim_{x\to 0}\dfrac{x^4}{x^{6}}=\dfrac{1}{x^2}=\infty$ Since both of these limits approach an asympote, can I even use them to show that the limit does not exist? Or must they approach a finite number?","['multivariable-calculus', 'calculus', 'limits']"
2443341,No. of isosceles triangles possible of integer sides with sides $\leq n$,"Prove that the no. of isosceles triangles with integer sides, no sides exceeding $n$ is $\frac{1}{4}(3n^2+1)$ or $\frac{3}{4}(n^2)$ according as n is odd or even, n is any integer. How to do it? I found that under these conditions no. of triangles possible may be
${n\choose 2}$","['combinatorics', 'combinatorial-geometry']"
2443371,How does synthetic division work?,"I've read that we can divide any polynomial by a linear polynomial by synthetic division considerably faster than that by long division method. Now, I've learnt the steps to do so but I don't quite understand how it works. Because here rather than dividing by the factor we are dividing by the zero ( i.e.* root*) and apparently these two cases are quite different. But, in a way, the steps involved in this method seem to be equivalent to that in the long division but I haven't been to fully grasp how and why that is so. Bonus Question:- Also, is there a similar relatively easy method for dividing by higher degrees polynomials too?","['algebra-precalculus', 'polynomials']"
2443424,functional equation $f(f(x))=af(x)+bx$ [duplicate],"This question already has an answer here : Continuous functions $f: \mathbb{R} \to \mathbb{R}$ such that $f\big(f(x)\big)=rf(x)+sx$ and $r,s \in (0, 1/2).$ (1 answer) Closed 1 year ago . Let $0<a,b<\frac{1}{2}$. Find all continuous functions $f$ satisfying $f(f(x))=af(x)+bx$. I proved $f$ is monotonic, but stucked at this point. How to use the bounds for $a,b$, why is it important to have $a,b\in(0,\frac{1}{2})$?",['functions']
2443439,$\alpha\in\mathbb{C}$ algebraic over $\mathbb{Q}$ iff $\alpha^n$ algebraic over $\mathbb{Q}$,"Let $\alpha\in\mathbb{C}$ and $n\in\mathbb{N}$. Show, that $\alpha$ is algebraic over $\mathbb{Q}$, iff $\alpha^n$ is algebraic over $\mathbb{Q}$. Hello, I want to proof this, but get stuck really quick...
I might need some help. ""$\Rightarrow$"" Suppose $\alpha$ is algebraic over $\mathbb{Q}$. Then there is $0\neq f\in\mathbb{Q}[X]$ with $f(\alpha)=0$. I have to show, that there is a $0\neq g\in\mathbb{Q}[X]$ with $g(\alpha^n)=0$ I tried severel things, but nothing of them should work. I want to construct $g$ by using $f$. 
First i thought about division with remainder. 
Then I tried to write $f(\alpha^n+\alpha-\alpha^n)$ and conclute something from there using the binomial theorem. I also thought about using the degree of the expansion $[\mathbb{Q}(\alpha):\mathbb{Q}]=\deg(f)$, where we can suppose that $f$ is the minimal polynomial of $\alpha$. Do you have a hint to get me started?
Thanks in advance.","['abstract-algebra', 'polynomials']"
2443513,Why square the term $X - \mu$ in the definiton of the variance?,"Why is is the variance $\operatorname{Var}(X)$  of a random variable $X$ definied to be $\operatorname{E}[(X-\mu)^2]$? My professor said that you want the variance to be positive, but why not go for  $\operatorname{E}[|X-\mu|]$ then? (Just starting on this subject so maybe a stupid question).","['statistics', 'probability', 'variance', 'definition']"
2443538,Find the solutions to $\left\lfloor\left(\frac{5}{3} \right)^n\right\rfloor = 3^m$,"Find all positive integer solutions to $\left\lfloor\left(\dfrac{5}{3}
\right)^n\right\rfloor = 3^m$. Let $a_n = \left\lfloor\left(\dfrac{5}{3}
\right)^n\right\rfloor$. Then $$a_n = 1,2,4,7,12,21,35,59,99,165,275,459,765,1276,2126,3544,5907,9846,16410,\ldots.$$ Since a power of $3$ is odd, we only need to look at the odd terms of $a_n$: let these be $b_n$. Then $b_n = 1,7,21,35,59,99,165,275,459,765,5907,\ldots$. There don't seem to be powers of $3$ with a positive exponent in $b_n$ in the first few terms. Using the Binomial Theorem, we have $$\left(\dfrac{5}{3}
\right)^n = \left(1+\dfrac{2}{3}\right)^n = 1+\dfrac{2}{3} \binom{n}{1}+\left(\dfrac{2}{3}\right)^2 \binom{n}{2}+\cdots+\left(\dfrac{2}{3}\right)^n\binom{n}{n}.$$ How can we continue from here?","['number-theory', 'diophantine-approximation']"
2443553,Inverse of continuous bijective linear operator is continuous.,"If $T: X \to Y$ is a continuous bijective linear operator where $X$ and $Y$ are Banach spaces, show that $T^{-1}$ is continuous. Attempt: Suppose that $T^{-1}$ is not continuous. Then, $T^{-1}$ is not bounded, so we have that $$||T^{-1}y_0||_X \geq C||y_0||_Y$$ for all $C \in \mathbb{R}$. However, since $y_0 \in Y$ and $T$ is surjective, we have that $T(x_0) = y_0$ for some $x_0 \in X.$ Then,
$$||T^{-1}(Tx_0)||_X \geq C||T(x_0)||_Y$$
$$||x_0||_X \geq C||T(x_0)||_Y$$
$$||Tx_0||_Y \leq \frac{1}{C}||x_0||_X.$$
Since this is true for all $C \in \mathbb{R}$, we have that 
$$||Tx_0||_Y = 0.$$
Since we can repeat this process for every $y \in Y$, we get that 
$$||Tx||_Y = 0, \ \forall x \in X.$$
Then, we must have that $Tx = 0$ for all $x$, because in general, $||x|| = 0$ iff $x=0$. So, this $T$ isn't injective, a contradiction. Thus, $T^{-1}$ must be bounded, and hence continuous. Could someone please verify if I'm doing this properly? Linear operators are very new to me, and slightly uncomfortable. In particular, when we say a linear operator is bounded, I'm not sure if that means at a single $x_0$, or for all $x \in X$. We've also never discussed the composition of linear operators, so I'm not 100% sure that $T^{-1}T(x_0) = x_0$, although I assume it should work just like function composition. Thanks for any help in advance.","['functional-analysis', 'real-analysis', 'proof-verification']"
2443566,Rotate a line around a point in space.,"I'm trying to figure this equation out before I code it. If I have a line that starts at $(x_1,y_1)$, and ends at $(x_2,y_2)$. I have a point not on the line, $(c_1,c_2)$ that I would like to rotate this line around to a certain angle. Is there an equation for handling this or could you please suggest an equation to use? Thanks,
B",['geometry']
2443597,"an ""algebraic relation"" by any other name...?","I am confronted with this definition which is unfamiliar to me: Suppose $F\subset \mathbb C\times \mathbb C$ is a relation. $F$ is said to be algebraic if there exists a matrix $A\in M_{n+1}(\mathbb C)$ such that no row of $A$ is the zero vector, and $$(x,y)\in F\iff \sum_{p=1}^{n+1}\sum_{q=1}^{n+1}A_{pq}y^{p-1}x^{q-1}=0$$ I'd like to find out more about it. I've been trying to find this in other texts without much luck, and hampered by the obvious problem of only having ""algebraic relation"" as a search term. This appeared in the context of a text on analytic functions, at the end of a chapter about analytic relations, analytic continuation, and branch-points. It might be useful to provide the remaining context provided by the book (there isn't much!) The definition above is only used for three following exercises, and the book does not go any further into this thing. The exercises are: If $F$ is an algebraic relation, show $F^{-1}$ is algebraic also. If $g$ is an analytic function and $g\subseteq F$ , then $F$ contains every analytic relation extending $g$ . If $G$ is an analytic relation contained in an algebraic relation, then $G'$ (the derivative of $G$ ) is also contained in an algebraic relation. That's it... I think that's all that is mentioned. Can someone point me to other texts where this idea appears and/or give other terminology that might lead me to see more about this?","['terminology', 'complex-analysis', 'relations']"
2443603,Getting rid of absolute value after integration,"I have this differential equation in an exercise: $$y' = \frac{y}{\sqrt{1-x^2}}$$ I solved it like this: $$\frac{dy}{dx} = \frac{y}{\sqrt{1-x^2}}$$ $$\frac{1}{y}dy = \frac{1}{\sqrt{1-x^2}}dx$$ $$\int \frac{1}{y} \,dy = \int \frac{1}{\sqrt{1-x^2}} \,dx$$ $$\ln \,\lvert\,y\,\lvert + C_1 = \arcsin\,x + C_2$$ $$\lvert\,y\,\lvert\,= {e}^{\arcsin\,x + C_3}$$ $$\lvert\,y\,\lvert\,=C{e}^{\arcsin\,x}$$ $$y=±C{e}^{\arcsin\,x}$$ However, the solution given in my textbook is $$y=C{e}^{\arcsin\,x}$$ How to get rid of the absolute value? Did I do something wrong? Some of the other exercises indicates when $y > 0$ but this one has no such indication. I guess it can be deducted?","['indefinite-integrals', 'ordinary-differential-equations', 'absolute-value']"
2443637,Equivalence of definitions of a multivariate normal distribution,"Fix a probability space $(\Omega,\mathcal{F},\mathbb{P})$. I have seen at various times the following definitions of a multivariate Gaussian distribution: A random vector $$X=(X_1,\ldots,X_d):\Omega\to\mathbb{R}^d$$ is a multivariate Gaussian if $\sum_{i=0}^d c_i X_i$ is normally distributed for all $c_i\in\mathbb{R}$. A random vector $$X=(X_1,\ldots,X_d):\Omega\to\mathbb{R}^d$$ is a multivariate Gaussian if there exist independent standard normal random variables $Y_1,\ldots,Y_d:\Omega\to\mathbb{R}$, a matrix $A\in\mathrm{M}_d(\mathbb{R})$, and a vector $v\in\mathbb{R}^d$ such that $$X=AY+v.$$ Now, it is clear that definition 2 implies definition 1, but I don't see why the converse should hold true. I suspect this might simply be an elementary linear algebra trick (such as Gaussian elimination), but I don't know for sure. My main difficulty is somehow obtaining independent random variables from $X_1,\ldots,X_d$ which may be dependent.","['probability-theory', 'probability', 'linear-algebra', 'normal-distribution']"
2443642,How to prove that $e^{\gamma}={e^{H_{x-1}}\over x}\prod_{n=0}^{\infty}\cdots?$,"How do we show that $$e^{\gamma}={e^{H_{x-1}}\over x}\prod_{n=0}^{\infty}\left(\prod_{k=0}^{n}\left({k+x+1\over k+x}\right)^{(-1)^{k}{{n\choose k}}}\right)^{1\over n+2}?\tag1$$ Where $\gamma$ is the Euler-Mascheroni constant $H_0=0$, $H_n$ is the harmonic number. $x\ge1$ Take the log of $(1)$ $$\gamma-H_{x-1}+\ln(x)=\sum_{n=0}^{\infty}{1\over n+2}\sum_{k=0}^{n}(-1)^k{n\choose k}\ln\left({k+x+1\over k+x}\right)\tag2$$ Probably take $(2)$ into an integral and take it from there...?","['infinite-product', 'sequences-and-series', 'euler-mascheroni-constant']"
2443661,What is my method of rendering the Mandelbrot set called?,"Recently I've dived into studying complex analysis on my own and it led me to find an interesting way of displaying the Mandelbrot set: Consider $$f(f(f(f(...x))))$$
Then, 
$$ \frac{d}{dx} (f(f(f(f(...x))))) = f'(f(f(f(...x))))\cdot f'(f(f(...x)))...$$
Assuming that this function converges for $x$, 
$$\frac{d}{dx}(f(f(...x))) =  \prod_{p=1}^{\infty} f'(f^{p}(x))$$
Since all non-edge-points in a Julia set always diverge or converge to the same cycle, this gave me an idea. Even though this product is always equal to $0$ or $\infty$, I wondered if it was possible to still compare the derivatives by how quickly they converge to $0$. I thought about the best way to do this for a while and came up with the following expression to color the points in the Mandelbrot set:
$$ 1-4\sqrt[p]{ \prod_{i=1}^{p} d(v_{i}) }$$
where $p$ is the length of the cycle the point converges to, $v_i$ is the $i$th point of the cycle, and $d(x)$ is a function which returns the squared distance of $x$ from the origin. The radical normalizes the value of the product based on the length of the cycle, in effect determining the ""average"" value of $f'(f^p(x))$. Finding the cycle and its values can be done efficiently using pre-existing algorithms. When I made a program to implement this algorithm, I got the following really cool image: If this has been done before, what is this method of displaying the set called?","['complex-analysis', 'fractals']"
2443668,Minimizing the Schatten 1-norm over symmetric matrices.,"Let $X$ be an $n \times n$ Hermitian matrix, it follows that we can write $X=A+iB$ where $A$ is symmetric and $B$ is skew-symmetric. Let $S$ be the set of $n \times n$ symmetric matrices and define the Schatten $1$-norm (also known as trace norm) as $\lVert M \rVert_1=\sum_j \sigma_j(M)$, where $
\sigma_j(M)$ are the singular values of $M$. To measure how close $X$ is to the subspace of symmetric the matrices, we can define the distance measure
$$ D(X) = \min_{Y\in S} \lVert X-Y \rVert_1 .$$
Expanding $X$ into symmetric and skew-symmetric parts, we get that
$$D(X)= \min_{Y\in S} \lVert (A-Y)+iB \rVert_1$$
From this it seems intuitively that the minimum occurs when $Y=A$, in which case $D(X)=\lVert B\rVert_1$ is simply the $1$-norm of the imaginary part of $X$. How would one show that this quantity is minimized for $A=Y$?","['matrices', 'normed-spaces', 'functional-analysis', 'spectral-theory', 'linear-algebra']"
2443677,The $n$-th derivative has $n$ zeros. Can such a function be unbounded?,"Question : Given a $C^\infty$-function $f:\Bbb R\to\Bbb R$ for which the $n$-th derivative has exactly $n$ zeros (counted with multiplicity) for all $n\in \Bbb N_0$. Can such a function be unbounded ? The motivation comes from another question of mine. I conjectured that functions with such zero-patterns look ""bell-shaped"". Examples might be $$\exp(-x^2)\quad\text{and}\quad \frac1{1+x^2}.$$ To construct an unbounded example, I had the following idea: take an intuitively bell-shaped function (like one of the above) which vanishes at infinity. Now, replace the converging tails with something that does diverge to $-\infty$ instead. The divergence must be sufficiently slow so that the zero pattern is preserved. I was not successful so far. For another idea, take once more a function with the desired zero-pattern. Then, add an unbounded function but pay attention to not destroy the zero pattern. This too turned out to be very tricky.","['derivatives', 'examples-counterexamples', 'functions']"
2443696,Unstable solutions when numerically integrating a system of ODE's with increasing step size,"Given is the following system of linear ordinary differential equations: $$ a'(t)= -a(t)+0.1b(t)+0.5c(t)+0.1d(t) $$
$$ b'(t)=0.1a(t)-b(t)+0.2c(t)+0.4d(t)$$
$$ c'(t)=0.5a(t)+0.2b(t)-c(t)+0.3d(t)$$
$$ d'(t)=0.1a(t)+0.4b(t)+0.3c(t)-d(t)$$ with initial conditions $$ a(0)=1, b(0)=c(0)=d(0)=0 $$ I numerically solved this system with the explicit Euler method at a step size of 0.1 and then increased the step size. Here is the solution at step size 0.1: However, with increasing step size, the solution becomes more and more unstable and eventually ""explodes"". Here is a graph with step size 1.25: And here with step size 1.35: Can somebody explain to me why the increase in step size results in such a behavior?","['numerical-methods', 'ordinary-differential-equations', 'systems-of-equations']"
2443765,Evaluate the infinite product $\prod_{n=1}^{\infty} \left(1-\frac{2}{(2n+1)^2}\right)$,$$\prod_{n=1}^{\infty} \left(1-\frac{2}{(2n+1)^2}\right)$$ I've seen some similar questions asked. But this one is different from all these. Euler product does not apply. One cannot simply factorize $\left(1-\frac{2}{(2n+1)^2}\right)$ since the $\sqrt{2}$ on top will prevent terms from cancelling. Any help will be appreciated! Note: we are expected to solve this in 2 mins.,"['combinatorics', 'infinite-product', 'calculus']"
2443783,Fractional part summation and asymptotic expansion error,"Let us consider the sum  $$\displaystyle T_K=\sum_{n \geq \sqrt{K}}^{{K}} \left\{ \sqrt {n^2-K} \right\}  $$ where $K$ is a positive integer and where $\{ \}$ indicates the fractional part. Its asymptotic expansion for $K \rightarrow \infty$ is $$T_K=c  K + O(\sqrt{K})$$ where $$c= \frac{  1+\gamma -\log(2) }{2}$$ and  $\gamma$ is the Euler-Mascheroni constant. A nice demostration of this expansion is given here . Now let us set $$A_K= c K- \frac{1}{2} \,\sqrt{K} -\frac{1}{8} \log(K)$$ where the last two terms of this quantity reflect the behaviour of the error term of the asymptotic expansion above. If we calculate the average value of the difference between $T_K$ and $A_K$ over all positive integers $K \leq N$, we have $$\frac{1}{N} \sum_{K=1}^{N} (T_K- A_K) \approx 0.126....$$ for $N \rightarrow \infty \,\,$. I am interested in this constant term, for which there seems to be a rather slow convergence (the value above was calculated for $N=10^6\,$). In particular, I wonder whether this bias may have a closed-form expression. After some calculations, I found the quantity $$\gamma - \frac{1}{8} -  \frac{\log(2)}{2}+\frac{1}{48}=0.1264754...\,$$ but I would like to have a formal confirmation of this.","['number-theory', 'fractional-part', 'summation', 'asymptotics']"
2443881,Self intersections of a smooth closed curve being deformed,"Let $\gamma_0$ be a smooth closed curve in $\mathbb{R}^2$, such that it has no self intersection. You can smoothly deform it in order to create a (still smooth) curve $\gamma_1$ that have some self intersections. It looks like that at some point during the deformation you get at least one self intersection such that the two parts of the curve intersecting are tangent, for example as a limiting case between having $0$ and $2$ self intersections (see the image below). However, despite the problem looking quite simple I was unable to find a proof of this claim, either in a book or by myself. Therefore I am searching a reference to a proof of this claim, if it exists (which seems likely to me as the problem looks kind of standard).","['transversality', 'differential-geometry', 'differential-topology']"
2443998,Is it possible to have two triangles with equal sides but with different angles?,"Can there be two triangles, for example $ \triangle ABC $ and $ \triangle DEF$ so that the measure of their sides is the same but their angles are different? Thanks.","['triangles', 'geometry']"
2444020,Conditions Weaker than Locally Euclidean,"This is a very general question, but hopefully some people find it interesting.  I'm working in the setting of compact metric spaces, so most of the basic topological properties will be satisfied. When the space $X$ is also connected, then I know that being locally connected is sufficient to be locally path connected, and is also sufficient for the metric on $X$ to be equivalent to a convex metric.  Thus for compact, connected, metric spaces being locally connected is very strong. But there are also locally connected spaces like dendrites that look very far from manifolds.  There are a lot of characterizations of the arc and the circle, and I know that there are a few characterizations in dimension two, since there are the Moore and Bing characterizations of the 2-sphere.  But I am wondering if there are general local conditions that are strong enough to imply that a point is contained in a neighborhood that looks like some $\mathbb{R}^n$ or $\mathbb{R}^\omega$, the Hilbert Cube? Basically, I am looking for some local condition that a point $x \in X$ can satisfy so that, assuming $X$ is a compact, connected, locally connected metric space, it follows that $X$ is locally Euclidean at $x$ - or has a neighborhood homeomorphic to the closed upper half-plane, i.e. looks like a boundary point of a manifold with boundary.  I am wondering if any of the following three (plus something) are good enough, or if anyone knows some helpful counterexamples: 1) $X$ is locally contractible (not enough by itself, e.g. dendrite or simple triod) 2) $X$ is locally homogeneous (every point has a local basis of homogeneous open neighborhoods) 3) $X$ is strongly locally homogeneous (every $x$ has a local basis $U_i$ of open neighborhoods such that for every $y \in U_i$ there is a homotopy on $U$ sending $x$ to $y$ composed of homeomorphisms) 3a) $X$ is strongly locally homogeneous on every $n$-point set for every $n$ (i.e. the homotopy can be chosen to send any $n$ distinct points to any other $n$ distinct points). We could also add homogeneity conditions to the boundaries, or conditions on the extensibility of the local homeomorphisms to boundaries. Especially curious if there has been progress since the annulus theorem was extended to all dimensions by Moise/Kirby/Quinn, or since the theory of Cantor Manifolds was fully developed.  In particular, are any of the above strong enough if the $U_i$ are assumed to be Cantor Manifolds?  I think maybe for dimension 2 it might be relevant, at least, but probably the Cantor Manifold property would have to be replaced with some ($n-2$)-dimensional non-separating sets in higher dimensions. To be honest, besides some classification theorems for surfaces, I really haven't come across much stuff on this local topological aspect.  Maybe an algebraic topologist has an explanation for why it's so much harder in high dimensions?  This is a paper I found that seems relevant, but the results aren't very satisfying except for surfaces. https://www.jstor.org/stable/1969469 Anyone spent much time thinking about this issue?","['manifolds', 'continuum-theory', 'algebraic-topology', 'geometric-topology', 'general-topology']"
2444031,Neumann boundary condition problem,"Say I have a long hallway in an office building. If I assume that any cigarette smoke, mixes across the width of the hallway and vertically through the depth of the hallway much faster than it mixes along the hallway, I wrote the diﬀusion of cigarette smoke as an equation
$$\frac{\partial S}{\partial t}= κ \frac{\partial^2 S}{\partial x^2} -γS +α(x)$$ where $S$ is the concentration of smoke, $κ$ is the rate of diﬀusion of smoke, $γ$ is the rate at which the smoke sticks to the walls or otherwise leaves the system, $α(x)$ is the sources of smoke, t is the time and x is distance along the hallway. How can I discretize the hall into N segments and write the equation for the steady state as a matrix equation? How do I find the condition number of the matrix? Any help will be appreciated!","['finite-differences', 'ordinary-differential-equations', 'linear-algebra']"
2444037,How to represent Hadamard product in terms of matrix multiplication?,"In the case of two vectors $u, v$ with dimensions $n\times 1$, their Hadamard product can be represented by the following matrix multiplication:
$$\mathrm{diag}(u)v = \left[\begin{array}{ccc}
u_{1} &  & 0\\
 & \ddots\\
0 &  & u_{n}
\end{array}\right]\left[\begin{array}{c}
v_{1}\\
\vdots\\
v_{n}
\end{array}\right]=\left[\begin{array}{c}
u_{1}v_{1}\\
\vdots\\
u_{n}v_{n}
\end{array}\right]\equiv u\circ v$$ Is there a way to generalize this for Hadamard products of matrices?","['matrices', 'products']"
2444099,Condition for eigenvalues to have negative real parts (Hurwitz) for specific matrix structure,"Let $$ A=\begin{bmatrix} P & \alpha x\\ -y^\top & 0\end{bmatrix}$$ where $P \in \mathbb{R}^{n \times n}$ is Hurwitz (the eigenvalues of $P$ have strictly negative real parts), $x, y \in \mathbb{R}^{n}$ , and $\alpha$ is a real positive scalar. Find the condition for $A$ to be Hurwitz for sufficiently small $\alpha > 0$ . I have analyzed that this is true whenever $y^\top P^{-1} x < 0$ holds. However, I am not able to prove this fact. Help in this regard would be appreciated.","['eigenvalues-eigenvectors', 'matrices', 'hurwitz-matrices', 'control-theory', 'linear-algebra']"
2444136,"$(\Bbb Q,+)$ is not isomorphic to any of its proper subgroups.","Show that 
   $(\Bbb Q,+)$ is not isomorphic to any of its proper subgroups. Let $H$ be  a proper subgroup of $\Bbb Q$ such that $H\cong \Bbb Q$ such that $\exists h\in \Bbb Q$ but $h\notin H$. Let $f:H\to \Bbb Q$ be the isomorphism then $f(a)=h$ for some $a\in H$. But how to proceed from here?","['abstract-algebra', 'group-theory', 'proof-explanation']"
2444142,"Why does my method for computing roots with multiplicity give the wrong answer at infinity, and can it be repaired?","To solve equations in a way that tells you not just the solutions, but the multiplicities, I had the following idea: Use the metaphor of ""integer-valued logic."" Replace ""and"" with multiplication and ""or"" with addition. Replace $=$ with some other symbol like $\#$ to mean that the result is integer valued, as opposed to boolean valued. For instance, whereas the equation $(x-1)^5 = 0$ has value False for $x \neq 1$ and True for $x=1$, the expression $(x-1)^5 \,\#\, 0$ has value $0$ for $x \neq 1$ and $5$ for $x=1$. For example, the null-factor law reads $$(ab \,\#\, 0) = (a \,\#\, 0)+(b\,\#\,0)$$ This seems to work pretty well in the affine plane. For example, suppose we to study the example on p.28 of Silverman's ""The Arithmetic of Elliptic Curves."" In particular, we wish to find the zeroes of $$x-a$$ on the curve $$y^2 = (x-a)(x-b)(x-c).$$ We compute: $(x-a\,\#\,0) \cdot (y^2 \,\#\, (x-a)(x-b)(x-c))$ $=(x\,\#\,a) \cdot (y^2 \,\#\, (x-a)(x-b)(x-c))$ $=(x\,\#\,a) \cdot (y^2 \,\#\, (a-a)(a-b)(a-c))$ $=(x\,\#\,a) \cdot (y^2 \,\#\, 0)$ $=(x\,\#\,a) \cdot 2(y \,\#\, 0)$ $=2(x\,\#\,a)(y \,\#\, 0)$ Ergo $x-a$ has exactly one zero on the curve of interest, it occurs at $x=a,y=0$, and it has multiplicity $2$. This agrees with Silverman's answer, so it seems to work. However, according to Silverman, $x-a$ also has a zero on the  ""at infinity"" with multiplicity $-2$. To find it, the obvious thing to do is to homogenize everything in sight and do the same computation again. In particular: $(x-az\,\#\,0) \cdot (y^2z \,\#\, (x-az)(x-bz)(x-cz))$ $=(x\,\#\,az) \cdot (y^2z \,\#\, 0)$ $=(x\,\#\,az) \cdot (2(y \,\#\, 0)+(z\,\#\,0))$ $=2(x\,\#\,az)(y \,\#\, 0)+(x\,\#\,az)(z \,\#\, 0)$ $=2(x\,\#\,az)(y \,\#\, 0)+(x\,\#\,0)(z \,\#\, 0)$ We surmise that there's a root at $(a:0:1)$ with multiplicity $2$ and and another at $(0:1:0)$ with multiplicity $1$. But this contradicts Silverman's answer, which is that the point at infinity has multiplicity $-2$. Question. Why does my method for computing roots with multiplicity give the wrong answer at infinity, and can it be repaired?","['polynomials', 'algebraic-geometry', 'complex-analysis', 'projective-space', 'meromorphic-functions']"
2444156,Prove $\rm AB = BA = 0$ if the set of nonzero eigenvalues of $\rm A + B$ is union of set of nonzero eigenvalues of $\rm A$ and $\rm B$.,"$A$ and $B$ are $n×n$ symmetric matrices, their non-zero eigenvalues are $(\lambda_{1},\ldots,\lambda_{r} )$，$( \mu_{1},\ldots,\mu_{s} )$.  If the nonzero eigenvalues of $A + B$ are  $(\lambda_{1},\ldots,\lambda_{r}，\mu_{1},\ldots,\mu_{s} )$,  show that $AB = BA = 0$ $\bf{Note}$ that the (non-zero) eigenvalues of a matrix form a multiset, so the above is a union of multisets.","['eigenvalues-eigenvectors', 'matrix-decomposition', 'linear-algebra']"
2444165,What is the rate of change of the height of water in a conical frustum bucket after one minute if it is being filled at a constant rate?,"I have an embarrassing question to ask. Embarrassing in the sense that I should be able to confirm or refute the solutions I got but I just can't seem to rationalise the results I worked out. I am working on a tutorial for some of my students and I want to know if I have the Mathematics right because the numbers I end up with seem a bit small. And before people start telling me, I know there are better ways to do this problem but it is more about showing the students how similar triangles can be used in these related rates type problems that they will get in their exam. Don't shoot the messenger - I don't write the curriculum. The problem is set out in this PowerPoint (or see below because apparently PPT is the tool of the devil) as a number of tutors will deliver this to the different classes. I greatly appreciate any help I may get. Pete [edited here - lucky I do LateX] The volume of a conical frustum bucket is given by $$V=\frac{\pi h}{3}(R^2+Rr+r^2)$$ given $r=15$ cm, $R=22$ cm & $h=56$ cm what is the rate of change of the height of water in the bucket after one minute if it is being filled at a constant rate $\frac{dV}{dt}=0.3$ L/s, from empty. Eliminating $R$ from the equation above using similar triangles and letting $R=15+\frac{h}{8}$ we get $$V=225\pi h + \tfrac{15\pi h^2}{8}+\tfrac{\,\pi h^3}{192}$$
$$\Rightarrow \tfrac{dV}{dt}=(225\pi+\tfrac{15\pi h}{4}+\tfrac{\pi h^2}{64})\tfrac{dh}{dt}$$ After 1 minute $V=18$ litres $=18000$ cm$^3 \Rightarrow h\approx 21.4$ cm. Solving for $\frac{dh}{dt}$ gives $$\tfrac{dh}{dt} =\frac{0.3}{225\pi+\tfrac{15\pi h}{4}+\tfrac{\pi h^2}{64}}$$
 and hence $\frac{dh}{dt}\approx0.0031$cm/s This is what seems a bit 'low' to me - I am looking at the horse bucket in my mind as I fill it ans it goes faster than that - doesn't it?",['calculus']
2444174,"Prove $ |A \cup B| = |[0,1]| \Rightarrow |A|=|[0,1]| \bigvee |B|=|[0,1]| $","I've tried the argument by contradiction, but did not succeed. Intuitively I understand that union of less-than-continuum sets cannot equal to $|\mathbb{R}|$. I'm curious what a formal proof could be.","['cardinals', 'elementary-set-theory']"
2444196,"Show that if $\vert G\vert = pq$, then either $G$ is abelian or $Z(G) = \{ e\}$.","The center of a group $G$ is defined as $Z(G):=\{ z\in G : gz = zg, \; \forall g \in G\}$. The goal is to show that if $\vert G\vert = pq$, where $p$ and $q$ are not necessarily distinct primes then either $G$ is abelian or $Z(G) = \{ e\}$. I want to suppose that $Z(G) \neq \{ e\}$ and then use the fact that $G/Z(G)$ is cyclic to imply that $G$ is abelian, which is something I have already proven. But how do I show that $G/Z(G)$ is cyclic when I am not certain what exactly $Z(G)$ looks like. I only know that it has at least one non-identity element in it, which will be of order $p$ WLOG, (the case where it is of order $pq$ is trivial). Any help is appreciated. Thank you.","['finite-groups', 'abstract-algebra', 'abelian-groups', 'group-theory']"
2444197,"Given function $f:\Bbb R\to\Bbb R:f(x)=\cos x$, check which properties it has","Given function $f:\mathbb{R}\to \mathbb{R}:f(x)=\cos x$, check whether it is surjective injective increasing decreasing strictly increasing strictly decreasing My Idea: $f(0)=f(2\pi)$ but $0 \neq 2\pi$ this f is not one one consider $y=2 \in \mathbb{R}$ There does not exist any $x\in \mathbb{R}$ such that $f(x)=\cos x=y=2$ then $f$ is not onto what about other options",['functions']
2444235,"Counting ways of seating couples, keeping men apart, women apart, and couples apart","There are $n$ man-woman couples sitting around a table, with seat number $1,2,\dots,2n$. How many ways of sitting that keeps men apart, women apart, and simultaneously couples apart? I intend to tackle the problem invoking the Inclusion-Exclusion Principle . Set ground set 
$$X= \{ \text{sittings that keep men apart and women apart}\}$$ Label the couples with number $1$, $2$, $\dots$, $n$. Define 
$$A_i = \{ \text{sittings that keeps men apart and women apart, but keep the $i$-th couple together} \}$$ 
for each $i\in[n]$. Then the number of sitting we set out to find is equal to:
$$\biggl|X-\bigcup_{i=1}^nA_i\biggr|=\biggl|\bigcap_{i=1}^nA_i^c\biggr|$$ The only problem left is how to determine size of $A_I$, where $I$ is a subset of $[n]$. But I have no idea how to enumerate this. Anybody got any ideas?",['combinatorics']
2444302,Example of non-nilpotent element contained in infinitely many prime ideals of a one dimensional noetherian ring.,"I am looking for an example of the following situation: $R$ is a noetherian one-dimensional ring. $x \in R$ is a non-nilpotent element contained in infinitely many primes of $R$. Obviously, nilpotent elements behave in such a way and I was asking myself if other elements can behave in a similar fashion. If there is a reference that no such elements exist, please tell me or post a proof if you like to. Thanks a lot in advance!","['abstract-algebra', 'algebraic-geometry', 'commutative-algebra']"
2444327,"Use the Inclusion-exclusion principle in order to count the number of positive integers $\le 1000$ that can't be divided by $7, 11$ and $13$.","Use the Inclusion-exclusion principle in order to count the number of positive integers $\le 1000$ that can't be divided by $7, 11$ and   $13$. This excercise was given to us, but I feel like it doesn't make much sense. In the past, we had similar excercises that would, for example, ask for the number of positive integers $\le 1000$ that can't be divided by $7, 11$ or $13$. This kind of question can be directly answered with the Inclusion-exclusion principle, but the excercise above actually has two variables in it, which are $|A_7 \cup A_{11} \cup A_{13}|$ (number of positive integers that can't be divided by $7, 11$ or $13$) and $|A_7 \cap A_{11} \cap A_{13}|$ (number of positive integers that can't be divided by $7, 11$ and $13$), and in order to get the first one, I would have to calculate the second one, and this would already be the answer to the question above, without applying the Inclusion-exclusion principle at all. Is there another way to do this that I am missing here?","['combinatorics', 'discrete-mathematics']"
2444370,Condition on the cardinality of $\Omega$ for a countably generated sigma-algebra,"I am trying to work out the following question. Any hints are very much appreciated. Let $\mathcal{F}$ consist of all $A \subseteq \Omega $ such that either $A$ is a countable set or $A^{\complement}$ is a countable set Verify that $\mathcal{F}$ is a $\sigma$-algebra . Show that $\mathcal{F}$ is countably generated if and only if $\Omega$ is a countable set . My attempt is as follows (please point out if there are any inconsistencies in arguments). Proof: $\mathcal{F}$ is a $\sigma$-algebra $\varnothing$ is a countable set. Hence $\varnothing\in \mathcal{F}$. Since $\Omega^{\complement} = \varnothing$, hence $\Omega \in \mathcal{F}$ For any set $A \in \mathcal{F}$, $A^{\complement} \in \mathcal{F}$ (this is by definition of $\mathcal{F}$, since either $A$ or $A^{\complement}$ is countable) Consider any countable collection of sets $A_1, A_2, A_3, \cdots \in \mathcal{F}$. If $A_i$ 's are all countable then $\bigcup_{i=1}^{\infty} A_i \in \mathcal{F}$ (since countable union of countable sets is countable). If for any $j$, $A_j$ is such that $A_j^{\complement}$ is countable then consider the set $B = \bigcap_{i=1}^{\infty} A_i^{\complement}$. Since $A_j^{\complement}$ is countable hence $B$ is atmost countable. Therefore $B \in \mathcal{F}$ and so $B^{\complement} \in \mathcal{F}$. Which implies $\bigcup_{i=1}^{\infty} A_i \in \mathcal{F}$. Hence $\mathcal{F}$ is closed under countable unions. Proof: $\mathcal{F}$ is countably generated if and only if $\Omega$ is a countable set If $\Omega$ is a countable set i.e. $\Omega = \{\omega_1, \omega_2, \omega_3, \cdots \}$, then as suggested by the above construction $\mathcal{F} = 2^{\Omega}$. And since $2^{\Omega}$ is the $\sigma$-algebra generated by the collection of singletons $\{\omega_i\}$, which is a countable collection, hence $\mathcal{F}$ is countably generated. However I am unable to prove the only-if statement. Thanks for your suggestions.",['measure-theory']
2444392,Positive definite matrix over a non-Archimedean field,"Suppose $K$ is a non-Archimedean ordered field, and $A$ is an $n\times n$ square matrix over $K$ such that (1) all diagonal entries of $A$ are $1$, and (2) all off-diagonal entries of $A$ are infinitesimal (i.e. between $-\frac1k$ and $\frac1k$ for all nonzero natural numbers $k$).  For instance, if $K=\mathbb{R}(x)$ is the field of rational functions, ordered with $x$ infinitesimal, then the off-diagonal entries of $A$ could be polynomials in $x$ with zero constant term. Does it follow that $A$ is positive definite, i.e. that $V^{T} A V > 0$ (in the ordering of $K$) for all nonzero $V\in K^n$?  This seems intuitive to me because it is an ""infinitesimal deformation of the identity matrix"", but I don't immediately see how to prove it.","['matrices', 'infinitesimals', 'positive-definite', 'field-theory']"
2444436,"If $f:\mathbb{R}\to\mathbb{R}$ is continuous, then is the pseudo-inverse $f^+$ measurable?","Assume that $\sigma$-algebra contains Borel sets and let $f:\mathbb{R}\to \mathbb{R}$ be a continuous function. Define $g=f^+:\mathbb{R}\to \mathbb{R}$ as $g(x) = 0$ if $f(x) = 0$ and $g(x) = 1/f(x)$ if $f(x)\neq0$. I am trying to prove that $g$ is measurable but not confident in my trial. Would you check the proof below? Since $f$ is continuous and $f(x) = 0 \Leftrightarrow g(x) = 0$, $f^{-1}(0) = g^{-1}(0)$ is closed, so measurable. Let $A = \{x\in \mathbb{R}\mid f(x) = 0\}$ and $B = \mathbb{R}\setminus A$. The restriction of $g$ into $B$, $g|_B$, is continuous in $B$. Let $V\in \mathbb{R}$ be an arbitrary open set. Then, $W = V\setminus\{0\}$ is open and $g^{-1}(W) = g|_B^{-1}(W) \subset B$ is open, so measurable. Since $g^{-1}(0)$ and $g^{-1}(W)$ are measurable, $g^{-1}(V)$ is measurable. Therefore, $g$ is measurable.","['real-analysis', 'analysis']"
2444463,An explanation for undergraduated students about why the Jacobian conjecture is hard,"I remember from multivariable calculus that the implicit function theorem and the inverse theorem are important theorems. Maybe for the students seem an understandable theory when the students known good examples and counterexamples,  and the proofs. Also the definition of characteristic of a field is easy. I know that $\mathbb{R}$ and $\mathbb{C}$ have characteristic $0$. I would like to study from the aficionado point of view the Jacobian conjecture, I am saying this statement from the Wikipedia . Question. Is feasible an explanation with examples and reasonings at undergraduate level tell us why the Jacobian conjecture is a very difficult problem? Thanks you in advance. I don't know if the background in algebra of students is enough to know why this problem is hard to solve. If a student believes it to be easy, can you provide evidence that his/her belief is wrong with the mathematics that he/she know ? If you need to refer to some relevant literature on it, I try find and read it.","['intuition', 'conjectures', 'abstract-algebra', 'multivariable-calculus', 'jacobian']"
2444480,Image of $A^\frac{1}{2}$ equal to image of $A$,"Let $A\in B(H)$ be a closed range positive operator, and $A^\frac{1}{2}$ its square root. Clearly image of $A$ is a subset of image of $A^\frac{1}{2}~~$($R(A)\subset R(A^\frac{1}{2})$). How do we prove $R(A)= R(A^\frac{1}{2})$? 
I edite the question",['functional-analysis']
2444481,What does uniformly perturbed mean?,"I've been reading through a paper (N.E.A.T) and came across the sentence : the value had a 90% chance of being uniformly perturbed Now I don't know what it means. I have started a web search and all I found was singular perturbation, nothing about uniform.
Then I started to read through the topic and it seems very complicated. My question is if someone can explain me what it is in relatively simple terms and a formula would also be helpful if possible (or existing). 
Alternatively a learning resource would also be nice.","['perturbation-theory', 'functions']"
2444528,Matrix Derivative of $ {L}_{1} $ Norm,"I'm with problems to find step-by-step resolution for a matrix differentiation. My main problem is to solve the L1 norm into this derivative: $\nabla K = \frac{\partial }{\partial x}\left | BCx - Nk + Fk \right |_{1}^{1} $ where B, C, N and F are matrix and x are a vector. Can anyone help with this? Thanks for the help!","['matrices', 'linear-algebra', 'derivatives']"
2444533,Finding coefficient of $j^2k^3lm^3$ in $(j + k + l + m)^9$,"I'm trying to find the coefficient of: $$j^2k^3lm^3$$ in: $$(j + k + l + m)^9$$ According to the Book of Proof (which is our material), it seems for: $$x^ay^b, \{a,b\} \in \mathbb{N}$$ in: $$(x+y)^c, c \in \mathbb{N}, c \geq \{a,b\}$$ we can use the binomial theorem: $$(x + y)^n = \binom{n}{0}x^n + \binom{n}{1}x^{n-1}y + \binom{n}{2}x^{n-2}y^2 + ... + \binom{n}{n-1}xy^{n-1} + \binom{n}{n}y^n$$ However, I'm lost on the other one. Please help?","['binomial-coefficients', 'polynomials', 'functions', 'combinatorics', 'exponentiation']"
2444570,"A finite-type, generically finite, dominant morphism of integral schemes induces finite field extension?","So I am doing an exercise of Hartshorne - II (3.7). I am given a finite-type, generically finite, dominant morphism $f: X \longrightarrow Y$ of integral schemes. I am asked to show that there is a dense open subset $U \subseteq Y$ such that the induced morphism $f^{-1}(U) \longrightarrow U$ is finite. I am given a hint that I should first show that the function field of $X$ is a finite extension of the function field of $Y$. I am having trouble showing this part to begin with. Here is my attempt so far: Let $\epsilon$ and $\eta$ be the generic points of $X$ and $Y$ respectively. These are unique since $X$ and $Y$ are integral. Also by integrality, we have that ever open set in $Y$ is dense, and so any affine $\text{Spec } B \subseteq Y$ contains the generic point $\eta$. Since $f$ is finite-type, we have
$$
f^{-1}({\text{Spec } B}) = \bigcup_{i} \text{Spec } A_{i}
$$
where each $A_{i}$ is a finitely generated $B$-algebra. Again, each of these $A_{i}$ are integral domains and must all contain the generic point of $X$, $\epsilon$. Choosing one of these $A_{i}$, which we will just call $A$, we have an exact sequence (since it is a finitely generated $B$-algebra):
$$
B[t_{1}, t_{2}, \ldots , t_{m}] \rightarrow A \rightarrow 0.
$$
Denote the residue field of the generic point $\eta \in Y$ by $\kappa_{\eta}$. By right exactness of the tensor product, we have
$$
\kappa_{\eta}[t_{1}, t_{2}, \ldots , t_{m}] \rightarrow A \otimes_{B}\kappa_{\eta} \rightarrow 0.
$$
That is, we have that $A \otimes_{B} \kappa_{\eta}$ is a finitely-generated $\kappa_{\eta}$-algebra. By Noether's Normalization, we then have a finite collection $\{ y_{1}, y_{2}, \ldots , y_{d} \}$ of algebraically independent elements of $A \otimes_{B}\kappa_{\eta} $ such that 
$$
\kappa_{\eta}[y_{1}, y_{2}, \ldots , y_{d}] \rightarrow A \otimes_{B} \kappa_{\eta}
$$
makes $A \otimes_{B} \kappa_{\eta}$ into a finitely generated module over $\kappa_{\eta}[y_{1}, y_{2}, \ldots , y_{d}]$. Then we can consider the induced morphism of affine schemes
$$
\phi: \text{Spec} \left( A \otimes_{B} \kappa_{\eta}  \right) \rightarrow   \text{Spec}\left( \kappa_{\eta}[y_{1}, y_{2}, \ldots , y_{d}] \right).
$$
Since the morphism $f$ is generically finite, we have that $\text{Spec} \left( A \otimes_{B} \kappa_{\eta}  \right)$ has only finitely many points. So if I could somehow show that the above map is surjective, I would be done (since the only way $\kappa_{\eta}[y_{1}, y_{2}, \ldots , y_{d}]$ could have only finitely many primes is if $d=0$ ). However, the best I have is that it is surjective onto a closed subset of 
$$
\text{Spec}\left( \kappa_{\eta}[y_{1}, y_{2}, \ldots , y_{d}] \right),
$$
which (as far as I can tell) might be finite. That is, $\ker \phi$ might contain all but finitely many primes, and hence I would not be able to deduce that $d=0$. I would like to make some kind of Going-Up argument, but I required that quotienting by $\ker \phi$ doesn't kill all but finitely many primes. Is anyone able to point me in the right direction on this? Is my approach up to this point ok? How am I able to conclude the argument from here?","['finitely-generated', 'modules', 'algebraic-geometry']"
2444616,"Proving that $F(x)=\int_{a}^{x}f(x,y)dy$ is continuously differentiable","I know that $f:\mathbb{R}^2\rightarrow\mathbb{R}$ is continuous, $f$ is differentiable in $x$ with $D_{1}f:\mathbb{R}^{2}\rightarrow \mathbb{R}$ continuous and I know that:    $F(x)=\int_{a}^{x}f(x,y)dy, x\in \mathbb{R}$ . I now want to prove that $F$ is continously differentiable (thus that $F$ is differentiable and that $F'(x)$ is continuous) I also need to show that:
$$F'(x)=f(x,x)+\int_{a}^{x}\frac{\partial f(x,y)}{\partial x}dy, x \in \mathbb{R}$$. I know that there exists a $G$ such that: $\int_{a}^{x}f(x,y)dy=G(x)-G(a)$ with $G'(x)=f(x,y)$,  and that $\frac{d}{dx}\int_{a}^{b}f(x,y)dy=\int_{a}^{b}\frac{\partial f(x,y)}{\partial x}dy$, that's the furthest I got with this problem can anyone help me solve this?","['integration', 'ordinary-differential-equations']"
2444618,Try to generalize First Mean Value Theorem For Integrals,"1. Suppose  that $f(x)$ is (Riemann) integrable on $[a,b]$ and $F^{'}(x)=f(x)$ for all $x\in[a,b]$,then there is a number $\color{red}{\xi\in(a,b)}$ such that 
$$\int_{a}^{b}f(x)dx=f(\xi)(b-a)$$ 2. I generalize the above statement which is ture to the following version: Suppose  that $f(x)$ and $g(x)$ are (Riemann)integrable on $[a,b]$ with $g(x)\geq 0$ for all $x\in[a,b]$ and $F$is  a primitive function of $f$ on $[a,b]$ ,then there is a number $\color{red}{\xi\in(a,b)}$ such that 
$$\int_{a}^{b}f(x)g(x)dx=f(\xi)\int_{a}^{b}g(x)dx$$ 3. I need to proof the generalisation is ture,or give some counterexamples to disprove it . From the First mean value theorem for definite integrals ,we have 
 $$\int_{a}^{b}f(x)g(x)dx=\mu\int_{a}^{b}g(x)dx,\quad \inf_{x\in[a,b]}\{f(x)\}\leq \mu\leq \sup_{x\in[a,b]}\{f(x)\}.$$
If $$\inf_{x\in[a,b]}\{f(x)\}< \mu <\sup_{x\in[a,b]}\{f(x)\},$$ Darboux's theorem tells us there is a $\xi\in(a,b)$ such that $f(\xi)=\mu.$ If $$\mu=\inf_{x\in[a,b]}\{f(x)\}\quad  \text{or}\quad  \mu=\sup_{x\in[a,b]}\{f(x)\},$$ is there also  a  $\xi\in(a,b)$ such that $f(\xi)=\mu ?$","['real-analysis', 'integration', 'definite-integrals', 'riemann-integration']"
2444634,A proof question using mathematical Induction,I'm having difficulty as to understanding what the questions is expecting us to prove. I understand how the mathematical induction works and how to go about doing the same. It would help if someone could in simpler words explain what the question means.,"['algebra-precalculus', 'induction', 'discrete-mathematics']"
2444641,On the converse of the $n$th term test,"A student asked a very insightful question in my Calculus class this morning.  I did not know how to answer him.  (Admittedly, I am not an analyst by trade:  once I passed my qualifiers I never looked back.)  I would like to know if anyone here can give a precise answer, and if that can be massaged into an answer understandable by someone in Calculus II. The topic of the lecture was the $n$th term test (or ""divergence test"") for infinite series.  I presented it as: Theorem: If $\sum_n a_n$ converges then $\lim_{n \to \infty} a_n=0$. I proved this, then had them state the contrapositive: Divergence Test :  If $\lim_{n \to \infty} a_n \neq 0$ then $\sum_n a_n$ diverges. I then gave a litany of examples. To their credit, they never fell into the false-converse trap.  I have been harping on dogs/mammals/horses all semester so they are very good about avoiding that (if you are a dog then you are a mammal but the converse is false if you can find a horse). My second example was the harmonic series, which of course has $\lim_{n \to \infty} a_n=0$ yet fails to converge.  Hence we definitely have horses in my theorem above (and they all spotted this). Enter the sharp student.  He asked if there was an improvement on my first theorem so that the converse becomes true.  I had said earlier in my example that although $\lim_{n \to \infty} \frac{1}{n}=0$, it doesn't converge ""fast enough"" to $0$ to make the harmonic series converge.  The student asked for a measure of ""fast enough"" or at least a precise statement of this.  What he is fishing for is something like: Improved Theorem: If $\sum_n a_n$ converges then $\lim_{n \to \infty} a_n=0$ and (extra-nice condition on the speed of the convergence to $0$). My instinct is there is no answer in terms of the terms $a_n$.  The only answer is that the terms must vanish quickly enough to make the sequence of partial sums convergent (which is an unsatisfying answer to his question).  If he only cared about $p$-series then I can be precise ($p > 1$), but he is asking about generic series whose terms vanish in the limit. I hope my question is clear.  Am I correct that all this is much too subtle to have a nice, clean answer on the ""rate"" of convergence of the terms to $0$?","['sequences-and-series', 'calculus']"
2444643,"How do I find time continuous A, B matrices from a discrete state space model?","The easiest way to compute a discrete state space model from time continuous state space model is by this method. $$
\begin{bmatrix}
A_d & B_d \\
0 & I
\end{bmatrix} = \exp\left(
\begin{bmatrix}
A & B \\
0 & 0
\end{bmatrix} h\right),
$$ But how would it be if I have the discrete state space model and I want to find the time continuous state space model? Edit: I'm just guessing now. Is this the right method? $$\frac {1}{h}\ln \left(\begin{bmatrix}
A_d & B_d \\
0 & I
\end{bmatrix}\right) = \begin{bmatrix}
A & B \\
0 & 0
\end{bmatrix}$$","['control-theory', 'linear-control', 'optimal-control', 'discrete-mathematics']"
2444656,Asymmetry for Carmichael 'twins',"Using a table of Carmichael numbers up to $10^{16}$, there are
$34971$ pairs $(c-2,c)$ where $c$ is a Carmichael number and $c-2$ is prime but only $204$ pairs $(c,c+2)$ with $c+2$ prime. Is there some theoretically reason for this striking asymmetry ($99.42\%$ vs. $0.58\%$)? The MSE question Why are Carmichael Numbers less common with an arithmetic progression seems somehow related, but I cannot see a direct connection.","['number-theory', 'carmichael-numbers', 'elementary-number-theory']"
2444673,Is it possible to drill a square hole using drill of special pattern?,"I have known one of the solutions which uses Reuleaux triangle as the drill, however the hole actually is a ""square"" with four round corner ( brief info about this solution ). However, in another post, someone claims to improve the approach and gives a pattern which, as he claims, can make a ""square"" without round corner( the pattern ). But he didn't give any further explaination, and barely the picture can't get me across. I am now confused whether it is possible to make a ""square"" without round corner using drills.Or is it impossible theoretically?","['rotations', 'geometry']"
2444707,Proofs involving multiple quantifiers?,"I'll just give this simple example to illustrate my point: There exists a real number $x$ such that for every real number $y$, we have $xy=y$. If I wish to prove this statement in a non-constructive way, that is to say, without explicitly assigning to $x$ the value $1$ and thereby proving the statement, I don't know how to do it. My first problem arises in translating the sentence into logical connectives. I could say: $$(\exists x )[x \in \mathbb{R} \, \land \forall y(y \in \mathbb{R} \implies xy=y)  ]$$ But then, how could I take - for example - something like the contrapositive of the implication when it's all embedded in these quantifiers, not to mention the conjunction? Surely I can't just take the contrapositive of the embedded implication as if it were a standalone implication, considering all the intertwined connectives and quantifiers surrounding it? Edit: Allow me to add in this quick edit. My problem is in part that I have no clue how I would go about deriving a contradiction from the negated statement above. If I wish to do a proof by contradiction, I first negate the above expression to the shorthand $\forall x \in \mathbb{R}, \exists y \in \mathbb{R}, xy \neq y$. However, what's next? I presume it would start off like: Let $x$ be an arbitrary real number. Then... But I don't quite understand what I would do in this particular case.","['proof-writing', 'predicate-logic', 'elementary-set-theory', 'quantifiers']"
2444744,Probability of winning tic tac toe game.,"You and your friend like to play tic tac toe, but are not very good at it. On each turn, the player picks a random empty square to place their mark. The game ends when the first person gets three in a row, as usual. If you make the first move, what is the probability that you win the game?  If you make the first move, what is the probability that you win the game? If the answer can be expressed as $\frac{a}{b}$, a and b are coprime, find a+b. My attempt: No of probable ways of arranging tic tac toe symbols so as to win the game =3horizontal ways+3 vertical ways+2 criss-cross ways=8 The total number of ways in which 3 spaces can be filled out of 9 spaces=9C3. Therefore, Total number of outcomes=The total number of ways in which 3 spaces can be filled out of 9 spaces (and) One extra space where either of the two tic tac toe symbols can be filled up=9C3*2 Probability=8/(2*(9C3))=1/21",['probability']
2444764,Combinatorial game with stones,"Two players play the following game. There are 2 piles of stones. One pile consists of 4 stones and the other one consists of 6 stones. Players take turns one by one. The amount of stones is unlimited. During the turn a player can add 4 stones into one pile or multiply a number of stones by 2 in one pile. The player wins if there are more than 26 stones in either pile after his turn. Who will win in this game - the first player or the second player? What choices should the winning player make to secure the win? It's like that -> 4,6 -> 4,12 -> 4,24 -> 4,28 (win) or 4,6 -> 8,6 -> 16,6 -> 32,6 (win). I need a table that shows all the winning combinations. (I'm actually bad at maths, it's just that our school teachers thinks that we should be able to solve complex advanced problems, but I can't solve this one no matter how much I try.) The answer must look like this (the captions are in Russian, so don't mind them): https://i.sstatic.net/rrC9d.jpg","['combinatorics', 'probability-theory', 'combinatorial-game-theory']"
2444769,Measure Preserving Diffeomorphism of $\mathbf R^n$,"A homeomorphism $h:\mathbf R^n\to \mathbf R^n$ will be called measure preserving if $\mu(h(A))=\mu(A)$ for all Lebesgue measurable sets $A$ in $\mathbf R^n$, where $\mu$ is the Lebesgue measure. It is well-known that the linear isomorphisms $T:\mathbf R^n\to \mathbf R^n$ which are measure preserving are precisely those with determinant $\pm 1$. I am wondering if the converse is true: Question. Are all measure preserving homeomorphisms $h:\mathbf R^n\to \mathbf R^n$   which fix the origin are necessarily linear? I was getting nowhere. So I replaced ""homeomorphism"" with ""diffeomorphism"" in the above. And for simplicity let's assume we are only interested in orientation preserving diffeomorphisms. Then the question becomes: Question. Let $f:\mathbf R^n\to \mathbf R^n$ be an origin fixing diffeomorphism such that its Jacobian has constant determinant $1$.
  Then is $f$ necessarily linear? Can somebody help me with the above? Thanks. EDIT. The answer to the above question is ""no"". For consider $f:\mathbf R^2\to \mathbf R^2$ defined as $f(x, y)=(x, y+g(x))$ where $g:\mathbf R\to \mathbf R$ is any smooth map taking $0$ to $0$.
This example was provided by a professor at my insititute.","['real-analysis', 'measure-theory']"
2444854,Proving that a complex function with constant module at boundary has a zero. (EDITED),"Let $f$ be a holomrphic non-constant function in $\Omega$, and a disc $C$, such that $\overline{C} \subset \Omega$. I want to proove that if $|f|$ is constant at $\partial C$, then $f$ has at least a zero in $C$. Really do not know where to start. Appreciate any help. (From here I edited it) So, this is what I thought. Lets suppose that $f$ has no zeros in $\overline{C}$, then $1/f$ is holomorphic at $\overline{C}$. Since $|f|=M$ is constant at $\partial C$ and we know that a holomorphic function in a close bounded set takes its maximum in the boundary, we know that for every $z\in \overline{C}$ we have $|f(z) \leq M$ and $|1/f(z)| \leq 1/M$ so we know that for every $z \in \overline{C}$ $f(z)=M$. Then $f$ its constant in $C$. Using maximum modulus principle we have that f must be constant in $\Omega$ (absurd). Then $f$ must have zeros in $\overline{C}$, if they are in the boundary then using that its maximum must be in the boundary, we have that $f=0$ in $C$, and then we have the same reasoning. Finally, $f$ must have zeros at $C$.",['complex-analysis']
2444868,Find limit of trigonometric function,"$$\lim_{x\rightarrow0} \frac{\tan^3(3x)-\sin^3(3x)}{x^5}$$
I think it should be decomposed with $$\lim_{x\to0} \frac{\sin x}{x}=1$$ but I'm always getting indefinity $\frac{0}{0}$.","['real-analysis', 'limits']"
2444884,Which string can't be accessed?,We start from the string $abcdef$ and We can edit it with the following rules: 1.$abcdef \Rightarrow adbecf$ 2.$abcdef \Rightarrow daebfc$ Which string can't be accessed? 1.dbafec 2.fcbeda 3.cabefd 4.efdcab 5.fedcba In these kind of problems we usually look for a common thing in every change of the the string.Which I can't do here.Also the answer in the book is string $5$. Puzzling SE copy : https://puzzling.stackexchange.com/questions/55399/which-string-cant-accessed,['combinatorics']
2444903,Help Finishing Archimedean Property Proof,"Prove ${\bigcap}_{n=1}^\infty$ $(0, \displaystyle\frac{1}{n})$ $= \emptyset$. In order to show that this intersection is equal to $\emptyset$, we need to show there is no element, $x$, in the intersection. Suppose there does exist such an $x\in (0, \displaystyle\frac{1}{n})$. Then $0<x<\frac{1}{n}$. Archimediean Property states that for any $x\in \mathbb{R}, \exists n \in \mathbb{N}$, such that $n>x$. This gives us that $\frac{1}{n}<\frac{1}{x}$. Let A represent the intersection and $x_0 \in A, x_0 >0$. Then $0<x_0<\frac{1}{n}$. If we set $x=\frac{1}{x_0}$, then $\frac{1}{n} < x_0$. This is a contrradiction since $x_0 < \frac{1}{n}$","['proof-explanation', 'elementary-set-theory', 'proof-verification']"
2445015,$ \bigcap\limits_{n=1}^N I_n \neq \emptyset$ for all $ N \in \mathbb{N}$ implies that $ \bigcap\limits_{n=1}^\infty I_n \neq \emptyset $?,"How can I show that a sequence of closed bounded (Not necessarily nested) intervals $ I_1, I_2, I_3 ,\ldots$ with the property that $ \bigcap\limits_{n=1}^N I_n \neq \emptyset$  for all $ N \in \mathbb{N}$ implies that $ \bigcap\limits_{n=1}^\infty I_n \neq \emptyset $ ? I'm being asked to determine if this is true.  I think that it is, because no matter how large $N$ is, we can always find an element in  $ \bigcap\limits_{n=1}^N I_n$.  So, we could simple let $N$ grow and there will always be an element in the intersection.  I was thinking about using induction, but this doesn't seem like an induction problem.  I am new to Real Analysis (self-study).  Someone tried to explain this to me using the bolzano weierstrass theorem, but I have not learned that. Any guidance will be appreciated.","['real-analysis', 'sequences-and-series']"
2445016,Stokes theorem and Cauchy integral formula,"Let first state the version of Stokes theorem I am looking at For any smooth $(n-1)$-form $\omega$ with compact support on the oriented $n$-dimensional manifold $M,$ $\int_M d\omega = \int_{\partial M} \omega$. I never learn to know how to use this properly. One specific problem I have at hand is the following: $f$ is a smooth function defined on the unit disk $\Delta,$
$$
\eta = \frac{1}{2 \pi i} \frac{f(w)\,dw}{w-z},
$$
$$
d\eta = - \frac{1}{2\pi i} \frac{\partial f(w)}{\partial\bar w} \frac{d \omega \wedge d \bar \omega}{w-z},
$$
let $\Delta_{\varepsilon}$ be the disc of radius $\varepsilon$ around $z$. Then by stokes theorem: $$
\frac{1}{2\pi i}\int_{\partial \Delta_{\varepsilon}} \frac{f(w) \, dw}{w-z} = \frac{1}{2\pi i} \int_{\partial \Delta}\frac{f(w) \, dw}{w-z} + \frac{1}{2\pi i} \int_{ \Delta - \Delta_{\varepsilon}} \frac{\partial f(w)}{\partial\bar w} \frac{d \omega \wedge d \bar \omega}{w-z}.$$ Can someone explain to me in detail how does the Stokes theorem apply here? The orientation is important in the proof of the stokes theorem since we want to choose a set of oriented atlas. But I do not see how do we see the orientation in real applications.","['complex-analysis', 'differential-topology']"
2445035,Symmetric determinant,"So, basically i want to prove that the value of $$\begin{vmatrix}
ax-by-cz & ay+bx & cx+az\\
ay+bx & by-cz-ax & bz+cy\\
cx+az & bz+cy & cz-ax-by\\
\end{vmatrix}$$
is equal to $$(x^2+y^2+z^2)(a^2+b^2+c^2)(ax+by+cz)$$ $\mathbf {What}$ $\mathbf {I} $ $\mathbf{have} $ $\mathbf{tried}$
: I have noticed it is a symmetric matrix but cannot proceed on that thought further. Next, I have tried multiplying row $1,2,3$ with $yz, xz, xy$ respectively with no luck. I also did some transformations but they were of no use again. Thanks in advance.","['matrices', 'determinant']"
2445077,Intuition regarding the $\sigma$ algebra of the past (stopping times),"Let $(\mathcal F_n)$ be a filtration and  $\tau$ be a stopping time with values in $\mathbb N \cup \{\infty\}$. Let $\mathcal F_\infty$ be the sigma-algebra generated by $\cup_n \mathcal F_n$. Define $$\begin{align}\mathcal F_\tau &=\{A\in \mathcal F_\infty, \forall n\in \mathbb N,\; A\cap (\tau =n)\in \mathcal F_n  \}\\
&=\{A\in \mathcal F_\infty, \forall n\in \mathbb N,\; A\cap (\tau \leq n)\in \mathcal F_n  \}
\end{align}
$$ $\mathcal F_\tau$ is referred to in Klenke as the ""$\sigma$-algebra of $\tau$-past"", and in Gut as the ""pre-$\tau-\sigma$-algebra"". What's the intuition behind $\mathcal F_\tau$ ? Why does it have the names I just mentionned ?","['stochastic-processes', 'probability-theory', 'measure-theory', 'stopping-times']"
2445098,Partitioning $\mathbb{R}$ given a sequence summing to $1$.,"Let $f$ be Lebesgue integrable on $\mathbb{R}$, and suppose we have a sequence $(a_n)$ of positive numbers such that $\Sigma a_n = 1$. Does there exist a partition of $\mathbb{R}$ into measurable sets $D_n$ such that $\int_{\mathbb{R}} f \chi_{D_n} = a_n \int_{\mathbb{R}} f$? My intuition is that this is true, but I'm unsure how to go about proving this.","['real-analysis', 'measure-theory']"
2445119,MSEs of Estimators of Variance in Normal Distribution,"$\newcommand{\MSE}{\operatorname{MSE}}$ Consider the mean squared error (MSE) of the following estimators of variance, where $X_i$ is given by the normal distribution: $$\MSE(S^2)=\MSE\left(\frac{1}{n-1}\sum_{i=1}^n (X_i - \bar{X})^2\right) = \frac{2}{n-1} \sigma^4$$ $$\MSE(S_1^2)=\MSE\left(\frac{1}{n}\sum_{i=1}^{n}(X_i - \bar{X})^2\right) = \frac{2(n-1)}{n^2}\sigma^4$$ (first one is an unbiased estimator of variance, and second one is a biased estimator) And, in the case where $\mu$ is known: $$\MSE(S_0^2)=\MSE(\frac{1} n \sum_{i=1}^n (X_i - \mu)^2) = \frac{2}{n}\sigma^4$$ In considering the MSE of these three estimators, I have two questions: Why do we often use $S^2$ instead of $S_1^2$ as an estimator for $\sigma$ , even though the latter has a lower MSE? If it is due to the fact that $S^2$ has a lower bias, then why do we define MSE the way we do at all? If minimizing bias is more important than minimizing variance, couldn't we set the MSE to be equal to twice the bias squared plus the variance, or something like that? Intuitively, how is $\MSE(S_1^2) > \MSE(S_0^2)$ ? This doesn't really make sense to me, as in cases where we know $\mu$ our MSE should really only decrease. The only explanation I can think of is that if we were to have an entire sample that was biased, the deviations from the population mean would clearly be greater than the deviations from the sample mean. But, on average, this shouldn't be the case. Thanks in advance!","['mean-square-error', 'normal-distribution', 'statistics', 'probability', 'chi-squared']"
2445141,Probability of guessing incorrect infinite number of times,"Suppose I have an event with probability p , what is the probability of this event never occurring infinite number of times. For example; what is the probability of someone rolling a dice and guessing the number wrong infinite number of times.","['law-of-large-numbers', 'probability-theory', 'probability', 'statistics']"
2445213,"Draw level curves for $f(x,y)=\frac{x^2+y^2}{xy}$","Draw level curves for $f(x,y)=\dfrac{x^2+y^2}{xy}$ Let $z=\dfrac{x^2+y^2}{xy}$ $z=0\to x^2+y^2 = 0$, which is a circle of radius $0$, or nothing. $z=1\to x^2+y^2=xy\to \color{red}{x^2-xy+y^2=0}$ How do I even graph this? How do I know what it looks like. I tried plotting on Wolfram Alpha but the result is literally nothing.","['multivariable-calculus', 'curves']"
2445230,"How to show that $(1+\frac1x)^x$ is increasing on $[0,+\infty)$","I am trying to show that the function $f(x)=(1+\frac1x)^x$ on $[0,+\infty)$ . I have found that $f'(x)=f(x) \left[\ln\left(\frac{x+1}x\right)- \frac1{x+1}\right]$ . Since $f(x)$ is always positive, I only have to show that $$\ln\left(\frac{x+1}x\right)>\frac1{x+1}\text{ when }x>0.$$ Is there an easy way to do this?","['real-analysis', 'calculus']"
2445236,"Is there a closed form for this ""flowery"" integral?","I'm curious about shapes like this: I think of this as the trajectory of a particle where the acceleration is perpendicular to the velocity and oscillates sinusoidally in time. The functions I'm investigating, in the generic case, are of the form: $$f(x) = \int e^{ai(x + b\,sin\,x)}\ dx$$ The above image is generated with $a=0.75, b=-1$. I'm especially interested the relationship of $a$ and $b$ in the specific case: $$0 = \int_0^{2\pi} e^{ai(x + b\,sin\,x)}\ dx$$ This corresponds to shapes like this, where the ""lobes"" touch at the origin: This is generated with $a=0.75, b \approx -0.7364$. In trying to figure out $b = g(a)$ I've tried my usual method of graphing approximate values of $b$ against $a$ and comparing it with some common functions, but I couldn't find anything that matched. I also tried entering some values of $b$ into WolframAlpha to see if it could find a closed form, but no dice. Is there a closed form for the generic case? What is the equation relating $a$ and $b$ in the specific case, and does it have a closed form? To me, the numbers seem magically pulled out of thin air, with no relation to any known constants.","['closed-form', 'indefinite-integrals', 'integration', 'definite-integrals', 'graphing-functions']"
2445240,"Evaluate $\lim_{(x,y)\to(0,0)}\frac{\cos(xy)-1}{x^2y^2}$","Evaluate $\lim_\limits{(x,y)\to(0,0)}\dfrac{\cos(xy)-1}{x^2y^2}$ The limit does exist. The only thing I can think of is let $t=xy$. Then our limit becomes $$\lim_{t\to 0}\dfrac{\cos(t)-1}{t^2}=\lim_{t\to 0}\dfrac{\cos(t)-1}{t^2}\dfrac{(\cos(t)+1)}{(\cos(t)+1)}=\lim_{t\to 0}\dfrac{-\sin^{2}t}{t^2(\cos(t)+1)}$$ This is how far I got and then I don't know. Not even sure if this is the best method to find the limit. Any hints would help. Thank you.","['multivariable-calculus', 'trigonometry', 'calculus', 'limits']"
2445264,All analytic functions are constant?,"While reading a book around complex analysis I came across a small theorem: If $f(z)$ is a real valued, complex variabled, analytic function then it is constant. My ""Proof"" I started thinking that if this is true then given any complex variabled, complex valued, analytic function $f$ we can see that $$\Re(f), \Im(f)$$ are both real valued, complex variabled, analytic functions thus must be constant and thus $f$ is constant. Now I know that in reality not all complex valued, complex variabled, analytic functions are constant. But I want to know what is wrong with the ""proof"" .",['complex-analysis']
2445268,Probabilistic Interpretation of Linear Regression: Why is the hypothesis function considered the mean of random variable y?,"In his machine learning notes (Chapter 3) http://cs229.stanford.edu/notes/cs229-notes1.pdf , 
Andrew Ng glosses over some math. In quantifying the random variable y :  $$y^{(i)}=\theta ^{T}x^{(i)}+e^{(i)}$$ e is conjured to represent random noise/factors not accounted by the hypothesis model. If this is the case why must x also be counted a random variable?
Also, why is e assumed to have mean 0? Would not a more general case assume a mean of μ ? Furthermore, I understand the mathematical form of the gaussian distribution, $$\frac{1}{\sqrt{2\pi \sigma }}e^{-\frac{(q-\mu)^{2}}{2\sigma ^{2}}}$$
but I do not understand how one can conclude that the hypothesis function, $$\theta ^{T}x^{(i)}$$ constiutes the mean of the random variable y , therefore implying:
$$p(y^{(i)}|x^{(i)};\theta )=\frac{1}{\sqrt{2\pi \sigma }}e^{-\frac{[y^{(i)}-\theta ^{T}x^{(i)}]^{2}}{2\sigma ^{2}}}$$
Thank you for your help in understanding these subtleties.","['machine-learning', 'statistics', 'linear-regression']"
2445308,"Calculate $\lim_{(x,y)\to(0,0)}\tan(x)\sin(\frac1{|x|+|y|})$","Calculate $\lim_\limits{(x,y)\to(0,0)}\tan(x)\sin\left(\dfrac1{|x|+|y|}\right)$ We know that $$-1\leq \sin\left(\dfrac{1}{|x|+|y|}\right)\leq 1$$ $$-\tan(x)\leq \tan(x)\sin\left(\dfrac{1}{|x|+|y|}\right)\leq \tan(x)$$ Taking the limit on both sides gives us $0$ , therefore the limit is $0$ . Does this work? I am doubtful of the fact that $\sin\left(\dfrac{1}{|x|+|y|}\right)$ is undefined, so I am not sure.","['multivariable-calculus', 'real-analysis', 'trigonometry', 'limits']"
2445326,"Let $n\in \mathbb{Z}_+$ and suppose that $n \geq 4$. Then there exists non-negative integers $x, y$ such that $n = 2x + 5y$","Base cases: If $n = 4$, then we set $x = 2, y = 0$ and get $n = 2(2) + 5(0)$, as desired. If $n = 5$, then we set $x = 0, y = 1$ and get $n = 2(0) + 5(1)$, as desired. General case: Now assume that $n \geq 6$.
  Note that $(n − 2) \in \mathbb{Z}_+$ with $n − 2 \geq 4$ (since $n \geq 6, n\in \mathbb{Z}_+$), so we may apply
  induction to $n − 2$. Hence there exists non-negative integers $x', y'$ such that: $n − 2 = 2x' + 5y'$
  $\iff n = 2x' + 2 + 5y'$
  $\iff n = 2(x' + 1) + 5y'$. Let $x = x' + 1$ and $y = y'$. 
  Then $x, y$ are non-negative integers with $n = 2x + 5y$. Solving previous induction proofs I have been able to apply induction to $n-1$.  In the solution for this example induction is applied to $n-2$.  Are there certain cases where induction should be applied to one over the other or is this just a more efficient method?","['induction', 'proof-explanation', 'discrete-mathematics']"
2445333,"Let $G$ be a group and $a,b \in G$ show that $|b| = 5$","Show that if $|a|=2$, $ab^2a^{-1}=b^3$ and $b\ne e$, then $|b|=5$. My attempt $$a^2 = e \implies a * a = e \implies a = a^{-1}$$
$$ab^2a=b^3$$
$$(ab^2a)^2=(b^3)^2$$ I) $$ab^2aab^2a = b^5$$
$$ab^2a=b^3$$
$$ab^2ab^2=b^3b^2$$ II) $$ab^2ab^2 = b^5$$ I and II $\implies$$b^4 = b^5 \implies b = e \implies b^5 = e$ Of course it is wrong, I've been trying to solve this problem for over 2 hours but I can't find a way to show $b^5=e$ through the given properties.","['abstract-algebra', 'group-theory']"
2445380,Markov inequality on tossing a fair die n times,"I am tossing a fair die $n$ times. What is the the probability that the sum of the numbers is at most $2n$.
I am doing this in the following way:
I found $\mathbb E[X] = 3.5n$
So 
$$\Pr[X\leq 2n] = 1 - P[X > 2n]$$
According to Markov inequality:
$$P[X>2n] \leq E[X]/2n = 3.5n/2n = 3.5/2 =1.75$$
So $P[X \leq 2n] > 1 - 1.75 = -0.75$.
I am not sure where I am going wrong? How a probability can be negative?","['inequality', 'probability', 'random-variables']"
2445388,Clarification on Lemma 68.5 of Munkres,"In James R. Munkres's ""Topology"" he has the lemma "" Lemma 68.5. Let $\{G_{\alpha}\}_{\alpha \in J}$ be a family of groups; let $G$ be a group; let $i_{\alpha}: G_{\alpha} \to G$ be a family of homomorphisms. If the extension condition of Lemma $68.3$ holds, then each $i_{\alpha}$ is a monomorphism and $G$ is the free product of the groups $i_{\alpha}(G_{\alpha})$."" "" Lemma 68.3. Let $\{G_{\alpha}\}_{\alpha \in J}$ be a family of groups; let $G$ be a group; let $i_{\alpha}: G_{\alpha} \to G$ be a family of homomorphisms.  If each $i_{\alpha}$ is a monomorphism and $G$ is the free product of the groups $i_{\alpha}(G_{\alpha})$, then $G$ satisfies the following condition: Given a group $H$ and family of homomorphisms $h_{\alpha}: G_{\alpha} \to H$, there exists a homomorphism $h: G\to H$ such that $h \circ i_{\alpha}=h_{\alpha}$ for each $\alpha$. Furthermore h is unique."" The proof of Lemma 68.5. uses the following lemma "" Lemma 68.4. Let $\{G_{\alpha}\}_{\alpha \in J}$ be a family of groups. Suppose $G$ and $G'$ are groups and $i_{\alpha}: G_{\alpha} \to G$ and $i_{\alpha}': G_{\alpha} \to G'$ are families of monomorphisms such that the families $\{i_{\alpha}(G_{\alpha})\}$ and $\{i_{\alpha}(G_{\alpha}')\}$ generate $G$ and $G'$, respectively. If both $G$ and $G'$ have the extension property stated in the preceding lemma, then there is a unique isomorphism $\phi: G\to G'$ such that $\phi \circ i_{\alpha} = i_{\alpha}'$ for all $\alpha$."" My question is whether the statement of Lemma 68.5. is missing the additional assumption that the family $\{i_{\alpha}(G_{\alpha})\}$ generates $G$? Or is that implicitly implied by the condition in Lemma 68.3. ?","['group-homomorphism', 'free-product', 'group-theory']"
2445437,Real continuous function with attractive fixed point has range subset of domain,"Let $f:\mathbb{R}\to \mathbb{R}$ be $C^1$ with fixed point $p$, such that $|f'(p)|< 1$. Then there exists an interval $I$ containing $p$ such that $f:I\to I$. I'm trying to prove this rigorously, but there's a roadblock. My best attempt is as follows: Let $\varepsilon > 0$, such that $\varepsilon$ is small, and consider $f(p+\varepsilon)=f(p)+f'(p)\varepsilon+\mathcal{O}(\varepsilon^2)$ and $f(p-\varepsilon)=f(p)-f'(p)\varepsilon+\mathcal{O}(\varepsilon^2)$. Then $$|f(p+\varepsilon)-f(p-\varepsilon)|=|\varepsilon(2f'(p))+O(\varepsilon^2)|$$$$\le 2\varepsilon|f'(p)|+|\mathcal{O}(\varepsilon^2)|<2\varepsilon+|\mathcal{O}(\varepsilon^2)|$$ Everything would be as desired if not for the $|\mathcal{O}(\varepsilon^2)|$ term. How does one get rid of it? I could argue that since $\varepsilon$ is small, we can neglect the term, but that is not very rigorous. Would appreciate your insight.","['real-analysis', 'fixed-points', 'proof-verification', 'functions', 'analysis']"
2445441,The nature of quotient spaces,"There's the following example from Introduction to Topological Manifolds by John Lee , the sphere $\mathbb{S}^2$ is homeomorphic to the closed disk $\bar{\mathbb{B}}^2 \subseteq \mathbb{R}^2$ modulo the equivalence relation generated by $(x, y) \sim (-x, y) \in \partial \bar{\mathbb{B}}^2$. (The claim is thus $\mathbb{S}^2 \cong \mathbb{\bar{B}}^2/ {\sim}$) Now my intuition failed me here, because the Torus, $\mathbb{T}^2$, which is used as the prototypical example to demonstrate the power and simplicity of quotient spaces, where ""gluing"" ends of a square to form first a cylinder, and then finally a torus make sense. That ""gluing"" intuition didn't work for me in this case, if anything by that argument the quotient space we'd end up with above would be a semi-circle sitting in $\mathbb{R}^2$. But to prove this claim the book explicitly constructs a quotient map $f : \mathbb{\bar{B}}^2 \to \mathbb{S}^2$ where $f$ is a rather involved function, and since $f$ makes the same identitifcations, namely being that on the boundary of the disk we have $f(x, y) = f(-x, y)$, and by the uniqueness of quotient space we prove our claim. It seems most of the quotient spaces I've come across are of this nature. Which is for any quotient space $X /{\sim}$ there is a quotient map say $f$ (which is not the canonical mapping $q : X \to X / {\sim}$ defined by $q(x) = [x]$, sending an element to its equivalence class), which makes the same identifications as the equivalence relation. We then then appeal to the uniqueness of quotient spaces, and because $f$ makes the same identifications as $q$, we have $f[X] = X /{\sim}$. But since $X / {\sim}$ is easier to state and work with we use that instead. Am I correct in this observation? Are all quotient spaces of this nature? If so, what can we do in the case of the Klein bottle, $K$, obtained by identifying the edges of the square $I \times I$ according to $(0, t) \sim (1, t)$ and $(t, 0) \sim (1-t, 1)$ for $t \in [0, 1]$. $K$ is certainly a quotient space, but it is seemingly not of the nature of the above examples, mainly because I don't know a quotient map $f$ (as used above), that makes the same identifications as $\sim$. What stops me from simply defining $K$ (or any quotient space like $\mathbb{S}^2$ above) as the quotient space generated by the relation instead of having to do the laborious calculations to find a quotient map $f$ that makes the same identifications as the relation?","['algebraic-topology', 'general-topology', 'equivalence-relations', 'quotient-spaces']"
2445462,"The probability that A hits a target is $\frac14$ and that of B is $\frac13$. If they fire at once and one hits the target, find $P(\text{A hits})$","The probability that A hits a target is 1/4 and the probability that B hits a target 1/3. They each fire once at the target. If the target is hit by only one of them, what is the probability that A hits the target? I know that this is an independent event.
If I do P(A hitting) * P(B not hitting) then (1/4)(2/3) = 1/6
But when I look at the back of my book the answer is 2/5? 
My book is known to give wrong answers because it is quite old; therefore, I am left with self doubt. Can anyone tell me if I have the correct answer or if I am actually making a mistake?",['probability']
2445479,"True or false : $\gcd(a_m, a_n) = a_{\gcd(m, n)}$?","Define a sequence $\left(a_0, a_1, a_2, \ldots\right)$ of integers by $a_0= 0, a_{n+1}=P(a_n)$, where $P$ is a polynomial with POSITIVE integer coefficients. I guess that $\gcd(a_m, a_n) = a_{\gcd(m, n)} $.","['number-theory', 'polynomials', 'gcd-and-lcm']"
2445562,Is the unit group of any finitely generated reduced $\Bbb Z$ algebra finitely generated?,"If $A$ is  finitely generated commutative reduced $\Bbb Z$ algebra, must the unit group $A^{\times}$ be finitely generated? The question is motivated by the Dirichlet unit theorem which says the unit group of the algebraic integer ring of any number field is finitely generated. And for other $\Bbb Z$ algebras such as finite fields, their unit groups are even finite.","['number-theory', 'group-theory', 'commutative-algebra']"
2445633,Do these conditions imply function is continuous?,"I have two separate conditions: a)
$\lim\limits_{h\to 0}|f(x+h)-f(x-h)|=0$ for every $x \in \Bbb R$ and b) $\lim_\limits{h\to 0}|f(x+h)+f(x-h)-2f(x)|=0$  for every $x \in \Bbb R$. My question is do the each of them imply $f$ is continuous?  $f(x)$ is said to be continuous at $x_0$ if $\lim_\limits{x\to x_0} f(x) = f(x_0) = c$ For a) it seems correct but I don't know how to prove it. For b), it seems wrong but I can't think of a counterexample.","['real-analysis', 'calculus']"
2445646,"What kind of ""measure"" is $dB_{t}(\omega)$","In stochastic integration one considers integrals as $L^2(P)$ limits of simple functions w.r.t  $dB_{t}(\omega)$ where $B$ is standard brownian motion. It is not clear to me what kind of object this $ dB_{t}(\omega)$ is, it is certaintly not a measure in the usual sense. How should one think about this object? And is there a name for it in general?","['stochastic-processes', 'probability-theory', 'stochastic-calculus', 'measure-theory']"
2445675,Show that neither $\frac{p^p-1}{p-1}$ nor $\frac{p^p+1}{p+1}$ can be a prime power,"Let $p\ge 5$ be a prime number,show that neither of the two numbers 
$$\dfrac{p^p-1}{p-1}; \dfrac{p^p+1}{p+1}$$ can be a prime power I know that $(p-1)|p^p-1$ and $(p+1)|p^p+1$ I have read some similar problems: Prove that $\frac{a^n-1}{b^n-1}$ and $\frac{a^{n+1}-1}{b^{n+1}-1}$ can't both be prime. Choosing $a$ s.t. $\frac{a^k - 1}{a-1}$ is not a prime power","['number-theory', 'prime-numbers']"
2445679,Urns: solving a differential system,"I'm working on an urn model where two urns, say A and B, are interacting in that at each step, a ball is drawn from each of them and then replaced adding a ball of the color drawn from the other urn. So if my draw vector at time $t$ is $X_t=(X_t^a,X_t^b)=(W,B)$, I'll add a black ball to urn A and a white to urn B. Now, if $Z$ represents the proportion of black balls, I end up having the following dynamics: \begin{cases} \mathbb{E}\left[\Delta Z_a^t|\mathcal{F}_t\right]=\cfrac{1}{S_a^t+1}\left[Z_b^t-\cfrac{1}{S_a^t}\right]\\ \mathbb{E}\left[\Delta Z_b^t|\mathcal{F}_t\right] =\cfrac{1}{S_b^t+1}\left[Z_a^t-\cfrac{1}{S_b^t}\right] \end{cases} with S being the total number of balls in the considered urn. Quite naively, I tried to solve the following differential system: $$
\begin{cases} x'(t)=\frac{1}{t+1}\left[y(t)-\frac{1}{t}\right] \\ y'(t)=\frac{1}{t+1}\left[x(t)-\frac{1}{t}\right] \end{cases}
$$ assuming that each urn is randomly initialized with one ball. The problem is: if I solve this system I end up having functions that are not probabilities at all. I'm not proficient in stochastic calculus so I don't know whether my method is good but I need to add a constraint to my system or if I should solve SDEs rather than ODEs. Do you know how I can get around this? EDIT: actually a mistake was hidden in the computation of the dynamics. The right system is: $$
\begin{cases} \mathbb{E}\left[\Delta Z_a^t|\mathcal{F}_t\right]=\cfrac{1}{S_a^t+1}\left[Z_b^t-Z_a^t\right]\\ \mathbb{E}\left[\Delta Z_b^t|\mathcal{F}_t\right] =\cfrac{1}{S_b^t+1}\left[Z_a^t-Z_b^t\right] \end{cases}
$$ So the ordinary differential system associated is $$
\begin{cases} x'(t)=\frac{1}{t+1}\left[y(t)-x(t)\right] \\ y'(t)=\frac{1}{t+1}\left[x(t)-y(t)\right] \end{cases}
$$ Which makes much more sense but seems tougher to solve.","['recurrence-relations', 'markov-chains', 'probability', 'ordinary-differential-equations', 'polya-urn-model']"
2445703,Has $f'(x)=f(x+1/2)$ non-oscillating solutions?,"Question : Is there a non-oscillating solution of $f'(x)=f(x+1/2)$ ? With oscillating I mean ""having infinitely many zeros"". 
This question builds on this other question which discusses the differential equations $$(*)\quad f'(x)=f(x+\lambda)$$ for general $\lambda\in\Bbb R$. It was found that if $z=a+bi$ is a solution of $z=\exp(\lambda z)$, then $$f(x)=e^{ax}\cos(bx)$$ is a solution of $(*)$. For $\lambda\le1/e$ the value $z$ can be chosen real, so the corresponding solution is not oscillating. For $\lambda>1/e$ however, no real valued solution $z$ exists, so this examplary solution contains $\cos(bx)$, therefore oscillates. For the interested reader Why I am asking for $\lambda=1/2$? It is just an example. I am actually interested in a general argument for $\lambda\in(1/e,1)$. For $\lambda\ge 1$ I already know that there must be infinitely many zeros. The argument is pretty straight forward and uses the mean value theorem . Proof . Let $\lambda> 0$. If there are only finitely many zeros, then $f$ finally becomes positive/negative. With every solution $f$ there is another solution $-f$, hence we can say $f$ becomes positive in the end. So we have $f(x)>0$ for all $x\ge x_0$. Note that this implies $f^{(n)}(x_0)=f(x_0+n\lambda)>0$. So the function is not only increasing, but increasing with an increasing rate and so on. The mean value theorem states $$f'(\xi)=\frac{f(x_0+\lambda)-f(x_0)}\lambda$$ for some $\xi\in[x_0,x_0+\lambda]$. Because $f''(x_0)>0$ we have $$f(x_0+\lambda)=f'(x_0)\le f'(\xi)=\frac{f(x_0+\lambda)-f(x_0)}\lambda$$ which rearranges to $(1-\lambda)f(x_0+\lambda)\ge f(x_0)$. Assuming $\lambda > 1\Rightarrow1-\lambda<0$ gives the immediate contradiction $$f(x_0+\lambda)\le \frac{f(x_0)}{1-\lambda}<0.$$ The case $\lambda =1$ gives a similar contradiction. $\square$ This proof yields absolutely no hint on any magical barrier for non-oscillating solutions at $\lambda=1/e$. For $\lambda < 1$ we find $f(x_0+\lambda)\ge f(x_0)/(1-\lambda)$ which is no problem for at least exponentially growing functions.","['examples-counterexamples', 'ordinary-differential-equations', 'functional-equations']"
2445809,Derivative of an integral of a two-variable function,"I want to calculate the derivative of an integral of a two-variable function, so $\frac{d}{dy}\int_{0}^1f(x,y)\,dx$. I am sorry if this is a basic question but a google search yields unusable results. I am 90% sure that the derivative can simply go under the integral, but I would like to be sure. Thank you.","['derivatives', 'integration']"
2445883,Is a continuous bijective map with same domain and range a homeomorphism?,"For a continuous bijective function from $\Bbb R$ to $\Bbb R$ is a homeomorphism, can we generalise it?","['continuity', 'general-topology']"
2445907,Is $\sum_{n=1}^\infty \frac{(-1)^n}{n}i^{n(n+1)}$ convergent?,"How to analyse the convergence of the series $$\sum_{n=1}^\infty \frac{(-1)^n}{n}i^{n(n+1)}=1-\frac{1}{2}-\frac{1}{3}+\frac{1}{4}+\frac{1}{5}-\frac{1}{6}-\frac{1}{7}+\frac{1}{8}+\frac{1}{9}-\frac{1}{10}-\frac{1}{11}+\dots?$$ I've thought about using results about alternating series but this one is not exactly of one those.  I've also tried to show that the sequence of partial sums is a Cauchy sequence and then to find a convergent subsequence of them, but I wasn't successful either. Remark: I even know this series is really convergent...","['power-series', 'sequences-and-series', 'convergence-divergence']"
2445926,Complex quintic equation,"Given the equation $x^5=i$, I need to show by both algebraic and trigonometrical approaches that
$$\cos18^{\circ}=\frac{\sqrt{5+2\sqrt5}}{\sqrt[5]{176+80\sqrt5}}$$
$$\sin18^{\circ}=\dfrac1{\sqrt[5]{176+80\sqrt5}}$$
Trying by trigonometric approach, 
$x^5$ = i     $\;\;\;\;$ -- eqn. (a) => x = $i\sin(\dfrac{\pi}{2} +2k\pi)$ => $i\sin(\pi\dfrac{4k + 1}{2}) $ Taking the value of k=0, for getting the principal root of 18$^{\circ}$, have x = $i\sin(\dfrac{\pi}{10}) $ Solving algebraically, the solution approach is : $(a+bi)^5$ = i $\;\;\;\;$ -- eqn. (b) => $a^5 + 5ia^4b -10a^3b^2 -10ia^2b^3 +5ab^4 +ib^5$ Separating the real & imaginary parts: $a^5 -10a^3b^2 +5ab^4=0$$\;\;\;$ -- eqn. (c); $\;\;\;\;$$5a^4b -10ia^2b^3+b^5=1$$\;\;\;$ -- eqn. (d) Solving (c), we have : $a(a^4 -10a^2b^2 +5b^4)=0$$\;\;\;$ -- eqn. (c); Either $a$ = $0$, or $(a^4 -10a^2b^2 +5b^4)=0$$\;\;$ -- eqn. (c'), dividing both sides by $b^4$, and having c = a/b,  $(c^4 -10c^2 +5)=0$$\;\;$ -- eqn. (c''), having d = $c^2$, get : $(d^2 -10d +5)=0$$\;\;$ -- eqn. (c'''), with factors as : d =$5\pm 2\sqrt5$ finding value of c for the two values, get square roots of the two values for d. //Unable to proceed any further with (c'''). Only root of significance, from eqn. (c) is $a = 0$. Taking eqn.(d), and substituting $a = 0$, we get:$\;\;\;b^5$=1 => $b =1$ //Unable to prove any of the two values for $\sin18^{\circ}$, or $\cos18^{\circ}$","['roots', 'trigonometry', 'complex-numbers']"
2445955,Show that a set is complete in a generic Hilbert space $H$,"Let $\{e_n\}$, $n\geq1$ be an orthonormal base of an hilbert space $H$. Let 
$$
f_1=e_1-e_2+e_3,\quad f_2=e_2-e_3+e_4,\quad \ldots\quad f_n=e_n-e_{n+1}+e_{n+2}.
$$
Show that $\{f_n\}$, $n\geq1$ is complete. I think I have to use the definition, that is
$$
(f_n, x)=0,\ \forall n\ \ \Rightarrow \ \ x = 0
$$
but I cannot understand how. Some help?","['functional-analysis', 'hilbert-spaces']"
2445956,Product $\left(\frac31\right)^{1/2}\cdot\left(\frac75\right)^{1/6}\cdot \left(\frac{11}9\right)^{1/10}\cdot \left(\frac{15}{13}\right)^{1/14}\cdots$,"Recently I rediscovered by a new method a family of infinite products I obtained years ago, and one of the examples you may find below, $$\left(\frac{3}{1}\right)^{1/2}\cdot\left(\frac{7}{5}\right)^{1/6}\cdot \left(\frac{11}{9}\right)^{1/10}\cdot \left(\frac{15}{13}\right)^{1/14}\cdots=\exp\bigg(\frac{\pi}{4}\int_0^{\pi/4}\frac{\tan(x)}{x}\textrm{d}{x}\biggr).$$ I wonder if such results are known in the mathematical literature, or anything similar to the example stated above. If yes, I'd be glad to receive information about the related literature. Supplementary question: Find the infinite product representations of 
$$\exp\bigg(\frac{\pi}{4}\int_0^{\pi/4}\frac{\tan^2(x)}{x}\textrm{d}{x}\biggr), \ \exp\bigg(\frac{\pi}{4}\int_0^{\pi/4}\frac{\tan^3(x)}{x}\textrm{d}{x}\biggr), \ \exp\bigg(\frac{\pi}{4}\int_0^{\pi/4}\frac{\tan^4(x)}{x}\textrm{d}{x}\biggr)$$","['real-analysis', 'calculus', 'integration', 'special-functions', 'sequences-and-series']"
2445982,Does a differentiable clustering algorithm exist?,"I have some vectors $x_0, x_1, x_2, ... x_n$ for a fixed $n$ (the vector dimension is about 2-20). I know there are $m$ clusters for these $n$ vectors (where $1\leq m \leq n$). For every input vector $x_i$ I should get a probability for each cluster (e.g. generated by $\mathrm{softmax}$). This algorithm should contain as few parameters as possible. I tried to implement a differentiable k-means, but the result was not that great, especially it seems to be hard to select good initial cluster centers. Maybe there already exists such an algorithm or it is easy to port one? Thank you","['derivatives', 'clustering']"
2445994,Discrete Laplacian of Gaussian (LoG),"In Image processing, one often uses the discrete Laplacian of Gaussian (LoG) to do edge detection with $LoG(x,y) = -\frac{1}{\pi \sigma^4}[1-\frac{x^2+y^2}{2\sigma^2}]\cdot e^{-\frac{x^2+y^2}{2\sigma^2}}$ Various sources here , here or here give discrete Kernels of the LoG to be convoluted with the input image to yield the filtered version. However, I do not understand the derivation of this Kernel from the function. One possible Kernel for $\sigma = 1.4$ is $K = \begin{bmatrix}0.0& 1.0& 1.0& 2.0&   2.0&   2.0&   1.0& 1.0& 0.0\\
           1.0& 2.0& 4.0& 5.0&   5.0&   5.0&   4.0& 2.0& 1.0\\
           1.0& 4.0& 5.0& 3.0&   0.0&   3.0&   5.0& 4.0& 1.0\\
           2.0& 5.0& 3.0& -12.0& -24.0& -12.0& 3.0& 5.0& 2.0\\
           2.0& 5.0& 0.0& -24.0& -40.0& -24.0& 0.0& 5.0& 2.0\\
           2.0& 5.0& 3.0& -12.0& -24.0& -12.0& 3.0& 5.0& 2.0\\
           1.0& 4.0& 5.0& 3.0&   0.0&   3.0&   5.0& 4.0& 1.0\\
           1.0& 2.0& 4.0& 5.0&   5.0&   5.0&   4.0& 2.0& 1.0\\
           0.0& 1.0& 1.0& 2.0&   2.0&   2.0&   1.0& 1.0& 0.0\end{bmatrix}$ My question is, how these discrete Kernels are derived from the $LoG(x,y)$ function. Is there any scaling factor involved? Is it an integration over the discrete pixel area? My calculated values for the central point (-40.0) are: $LoG(0,0) \approx -0.1624$ and $\iint\limits_{-0.5}^{0.5}{LoG(x,y)} dx dy \approx -0.0761$","['derivatives', 'image-processing', 'laplacian', 'convolution']"
2446000,Solve the equation $2x^2-[x]-1=0$ where $[x]$ is biggest integer not greater than $x$.,I' ve tried with $x^2 = {[x]+1\over 2}$ so $x$ is a square root of half integer. And know? What to do with that?,"['algebra-precalculus', 'quadratics']"
2446078,Is skateboard vibration model correct?,"My friend and I rode a skateboard yesterday. After a certain speed the board began to wobble and I fell down.
In order to avoid a similar outcome in the future, I want to model the ""vibration"" that occurred mathematically so that I can analyze the effect of different wheels, suspensions or even foot placement. I have created the following model, which is a variation of the harmonic oscillator: Model of vertical wheel displacement: Variable declarations: $w_n(t):=$Position of the nth wheel $m_n(t):=$Weight of the nth wheel in kg $F_n(t):=$Surface irregularity force on the nth wheel in newton $k_n,v_n\in \mathbb{R}^+:=$Coefficient of nth wheel The vertical displacement of the wheels is then modelled by: $m_n\ddot{w}_n=-k_n\cdot w_n-v_n\cdot \dot{w}+F_n$ Picture (orange part is modelled by the above equation): Model of board vibration I simulate the wobbling as rotation of the board in radian. It is
dependent on the displacement of the wheels: The larger the displacement of two adjacent wheels (front view) $w_1,w_2$, the larger the wobbling of the board.
Because the rider can counteract this wobbling by exerting a force himself, we have to include him in the model as well.
This counterforce is not random but depends on the previous vibration of the board (vibration) at an earlier time $t-\alpha$, so we add the function $\lambda(b(t-\alpha)$.
Since the rotation is centered around a pivot which is also dampened, we add the dampening term $v_b\cdot \dot{b}$. To simplify calculations, it is possible to set $\lambda(b(t-\alpha)$=$b(t-\alpha)$. Additional Variable declarations: $\lambda(b(t-\alpha):=$ Counterforce of the rider in newtons.
$b(t):=$ Position of the board in radian.
$\mu,\alpha\in \mathbb{R}^+:=$Coefficients The rotation of the board is then modelled by: $m_b\ddot{b}(t)=\lambda(b(t-\alpha)\cdot sin(b)+\mu (w_1-w_2)-v_b\cdot \dot{b}$ I have drawn a picture again, so you can see what I mean: Question:
Do you think this is a valid model to model high speed ""board wobble""?
Perhaps, you can come up with a better approach to solve the problem? I can tape my phone under the board (so I have an accelerometer, a gyroscope, a magnetometer, a gravity sensor, a linear acceleration sensor, a rotation sensor and a pressure sensor at my disposal). Thank you for your help.",['ordinary-differential-equations']
2446084,distance from the centre of a $n$-cube as $n \rightarrow \infty$,"I've figured out the pattern for calculating the average distance from the centre of an n-cube; but I don't have a formula for the answer. Is there an easy way to figure this out? Average distance of points from the centre of a unit 0-cube (point) $$A_0 = 0$$ Average distance of points from the centre of a unit 1-cube (line) $$A_1 = \int_{x=-\frac{1}{2}}^{x=\frac{1}{2}}{x}\; dx = 0.250000$$ Average distance of points from the centre of a unit 2-cube (square) $$A_2 = \int_{x=-\frac{1}{2}}^{x=\frac{1}{2}}{\int_{y=-\frac{1}{2}}^{y=\frac{1}{2}}\sqrt{x^2+y^2}}\;dy \; dx \approx 0.382598$$ Average distance of points from the centre of a unit 3-cube (cube) $$A_3 = \int_{x=-\frac{1}{2}}^{x=\frac{1}{2}}{\int_{y=-\frac{1}{2}}^{y=\frac{1}{2}}\int_{z=-\frac{1}{2}}^{z=\frac{1}{2}}{\sqrt{x^2+y^2+z^2}}}\;dz\;dy \; dx \approx 0.480296$$ Average distance of points from the centre of a unit 4-cube (tesseract) $$A_4 \approx 0.560950$$ My gut instinct is that $A_n \rightarrow \infty$ as $n \rightarrow \infty$ as in my head higher dimensional cubes become more spiky and I expect the mass to become concentrated in the corners. I feel justified in saying this because the number of ""corners"" is $2^n$ with a potential distance of $\frac{\sqrt{n}}{2}$ If somehow it were to approach some limit, that would be cool (to me at least) Thanks in advance for any help, advice or answers","['multivariable-calculus', 'integration', 'calculus', 'limits']"
