question_id,title,body,tags
4140321,"The inclusion of $W^{1,p}$, $p\geq1$ into $C[0,1]$ with sup norm is bounded.","Fix $p \geq 1$ , let $W([0,1])$ be the space of absolutely continuous functions such that for all $f \in W$ we have $\|f'\|_p^p <\infty$ . Then this is a Banach Space with the norm; $\|f\|_W=\left(\|f\|_p^p+\|f'\|_p^p\right)^{1/p}$ . I want to show that $\iota:W \hookrightarrow C[0,1]$ , the inclusion into the space of all continous functions with infinity norm, is bounded. So I have to write; $$\|f\|_{\sup}\leq c\|f\|_W$$ for some constant $c$ yeah? But I can't seem to summon the technical skill to relate these norms... The only thing I tried with any promise was; $$\|f\|_{\sup}=\sup_{x\in [0,1]}|f(x)-f(0)+f(0)|\leq \sup_{x\in [0,1]}\left|\int_0^xf'(t)dt\right|^{p/p}+|f(0)|$$ $$\leq \sup_{x\in [0,1]}\left(\int_0^x|f'(t)|^pdt\right)^{1/p}+|f(0)|\leq \|f'\|_p+|f(0)|$$ The question is in a chapter regarding compact operators (and the next question is to show $\iota$ is compact for p>1) but I can't see how any of the material can be relevant here?","['lp-spaces', 'sobolev-spaces', 'functional-analysis']"
4140395,Smallest value for the number of edges in a non-planar graph?,"Let $G=(V,E)$ an undirected simple graph. $G$ is non-planar. What's the lowest value can $|E|$ take? I've thought about this inequality: ""If a graph $G=(V,E)$ is planar, let $|V|=v$ , $|E|=e$ , $r$ the number of regions. Then, the inequailities $3r\leq 2e$ and $e\leq 3v-6$ holds."" From this result, we can conclude that $|E|>3v-6$ . How can I guarantee this value is minimum?","['graph-theory', 'inequality', 'discrete-mathematics']"
4140426,"Suppose $X\sim N(\mu,1)$, show that $|\mu|$ has no unbiased estimate","Suppose $X\sim N(\mu,1)$ , show that $|\mu|$ has no unbiased estimator. Hint:use the fact that $|\mu|$ is not differentiable at $\mu=0$ . There are my ideas: Suppose $X_1,\cdots,X_n$ are simple random samples from $N(\mu,1)$ , and $g(X_1,\cdots,X_n)$ is an unbiased estimator for $|\mu|$ , which means $\mathbb{E}_{\mu}(g(X_1,\cdots,X_n))=|\mu|$ , i.e. $$\int g(x_1,\cdots,x_n)e^{-\frac{(x_1-\mu)^2}{2}}\cdots e^{-\frac{(x_n-\mu)^2}{2}}\,\mathrm{d}x_1\cdots\mathrm{d}x_n=|\mu|.$$ I want to prove that $\mathbb{E}_{\mu}(g(X_1,\cdots,X_n))$ is differentiable at $\mu=0$ . For this, I want to exchange integral and derivative by Leibniz integral rule on measure theory statement. I am going to find a function $h(x_1,\cdots,x_n)$ that satisfies $\left|\dfrac{\partial G(x_1,\cdots,x_n,\mu)}{\partial \mu}\right|\le h(x_1,\cdots,x_n)$ on $|\mu|\le\epsilon$ ( $\epsilon$ is a positive number) and $h(x_1,\cdots,x_n)$ is integrable, where $$G=g(x_1,\cdots,x_n)e^{-\frac{(x_1-\mu)^2}{2}}\cdots e^{-\frac{(x_n-\mu)^2}{2}}.$$ But I am stuck.","['statistics', 'probability', 'real-analysis']"
4140489,Is $\prod_{n=0}^\infty \left(1-\frac{1}{\cosh ^2((n+1/2)\pi)}\right)=\frac{1}{\sqrt[4]{2}}$ true?,"The infinite product $$\prod_{n=0}^\infty \left(1-\frac{1}{\cosh  ^2((n+1/2)\pi)}\right)$$ agrees with $\frac{1}{\sqrt[4]{2}}$ to at least 100 decimal places. The ""identity"" is reminiscent of $$\sqrt[4]{1-\lambda (i)}=\frac{1}{\sqrt[4]{2}}$$ where $\lambda$ is the modular lambda function. I tried to use $$\theta_3(z|\tau)=\theta_3(0,\tau)\prod_{n=0}^\infty \frac{\cos ((n+1/2)\pi\tau+z)\cos ((n+1/2)\pi\tau -z)}{\cos^2 ((n+1/2)\pi \tau)}$$ where $z,\tau\in\mathbb{C}$ and $\operatorname{Im}\tau\gt 0$ . $\theta_3(\pi/2|i)$ leads to $$\prod_{n=0}^\infty \tanh^2 \left(\left(n+\frac{1}{2}\right)\pi\right)$$ and $\theta_3(i|i)$ leads to $$\prod_{n=0}^\infty \cosh \left(1-\left(n+\frac{1}{2}\right)\pi\right)\cosh\left(1+\left(n+\frac{1}{2}\right)\pi\right)\operatorname{sech}^2\left(\left(n+\frac{1}{2}\right)\pi\right)$$ but these products don't seem to give the answer.","['modular-function', 'complex-analysis', 'closed-form', 'sequences-and-series', 'theta-functions']"
4140565,What is the height of the tower given following information?,"Point C is due East of B and 300 m distance apart. A tower not in line in B and C was observed at B and C having vertical angles of 45 deg and 60 deg respectively. The same tower was observed at point D 500 m west of B. The vertical angle of the same tower as observed from D is 30 deg. The height of the tower is. Below is my initial figure and equation. tan 30 = H/LD;
tan 45 = H/LB;
tan 60 = H/LC After that, i'm not sure how to proceed.","['trigonometry', 'geometry', 'plane-geometry']"
4140582,What fraction of the hexagon is shaded?,The shaded part is formed by joining two vertices with the midpoints of the opposite sides. The triangle is formed by joining the adjacent vertices to the midpoint of the opposite side. source: cuemath.com,"['puzzle', 'area', 'geometry']"
4140598,"If $f(x) \leq f(a)$ for all $x$ in an open ball $B(a)$ , then prove that $\nabla f(a) = 0$","Question statement : Assume $f$ is a scalar field function differentiable at each point of an n-ball $B(a)$ . If $f(x) \leq f(a) \ \ \forall \ x $ in an open ball $B(a)$ , then prove that $\nabla f(a) = 0$ My try : $f(a+he_i)-f(a)\leq0$ where $e_i$ is a unit coordinate vector. Now I divide both sides by $h>0$ and take limit $\lim_{h\to 0} \frac{f(a+he_i)-f(a)}{h}\leq0$ which gives $\frac{\partial f}{\partial x_i}\leq0$ at $a$ . Doing the same thing, but now dividing both sides by $h<0$ and take limit $\lim_{h\to 0} \frac{f(a+he_i)-f(a)}{h}\geq0$ which gives $\frac{\partial f}{\partial x_i}\geq0$ at $a$ . Thus $\frac{\partial f}{\partial x_i}=0$ at $a$ for all $x_i, \ i \in {1,2,...n}$ . Thus $\nabla f(a) = 0$ . I have no clue as to whether this ""weird"" method of mine is correct or not. Someone please guide.","['scalar-fields', 'multivariable-calculus', 'derivatives', 'real-analysis']"
4140618,A Fibonacci conjecture: $\frac{n-1}{n}<\log_{F_{n+1}}{F_n}<\frac{n}{n+1}$.,"Given the Fibonacci sequence $F_n$ , that is $$
F_0=F_1=1,F_{n+2}=F_{n+1}+F_n.
$$ Then we have the sequence $\{\log_{F_{n+1}}{F_n}\}$ is increasing. for any $n\geqslant2$ , $$
\frac{n-1}{n}<\log_{F_{n+1}}{F_n}<\frac{n}{n+1}.
$$ In fact, I have tried to prove $(1)$ in a simple way, but failed. (See this previous question .) Because when $n$ is odd, the inequality $\frac{\ln F_n}{\ln F_{n+1}}<\frac{\ln F_{n+1}}{\ln F_{n+2}}\ $ is easy to get by using AM-GM inequality and Cassini's identity; when $n$ is even, things will be very different. As for $(2)$ , I have no idea how to prove it, except for using Binet's formula.","['inequality', 'fibonacci-numbers', 'sequences-and-series']"
4140652,period of the curvature and the period of the corresponding curve $\frac1{2\pi}\int_0^{\rho_k}k(s)\mathrm ds\in\Bbb Z$,"The paper "" When Is a Periodic Function the Curvature of a Closed Plane Curve?"", May 2008 The American Mathematical Monthly 115(5):405-414 The paper says: A Closed Plane Curve, when the (minimum) period of the (signed) curvature and the period of the corresponding curve do not coincide, if and only if $$\frac1{2\pi}\int_0^{\rho_k}k(s)\mathrm ds\in\Bbb Q-\Bbb Z$$ where $\rho_k$ is the (minimum) period of the signed curvature. Please refer to Proposition 2.1 and   the beginning of part 4 of the paper：if $\frac1{2\pi}\int_0^{\rho_k}k(s)\mathrm ds\in Z$ , then in this case the (minimum) period of the curvature and the period of the corresponding curve would coincide if the latter eventually closes up. But the paper dones't prove this. How to show the claim is correct? Thanks the paper : Wherher take a look at it, doesn't affect the topic here When Is a Periodic Function the Curvature of a Closed Plane Curve?","['plane-curves', 'curvature', 'differential-geometry']"
4140678,How to perform mathematically valid steps while finding a solution? [closed],"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 3 years ago . Improve this question Before having deeper understanding of Domain, I took many  mathematical steps as granted.
For e.g. $i) \frac{1}{\frac{1}{cos(x)}}=cos(x)$ $ii)\frac{1}{cosec(x)}=sin(x)$ $iii) \sqrt{x-2}*\sqrt{x+2}=\sqrt{x^2-4}$ But after learning Domains pretty nicely, I can see the equations the new way, in more mathematically stricter sense.
Say, $\frac{1}{\frac{1}{cos(x)}}$ has domain $x=R-(2n+1)\frac{\pi}{2}$ whereas $cos(x)$ has domain $R$ . Also, $\frac{1}{cosec(x)}$ has domain $(R-n\pi)$ and $sin(x)$ has domain $R$ . $\sqrt{x-2}*\sqrt{x+2}$ has domain $[2,\infty)$ whereas $\sqrt{x^2-4}$ has domain $(-\infty,-2]\cup[2,\infty)$ . Clearly, $i),ii),iii)$ are not always True. In everyday life, checking and verifying every possible operation while calculating a solution makes the entire process slow and tiresome (as of my present situation). So, what approach would be correct to follow while solving a problem? Checking and verifying every step?","['calculus', 'functions']"
4140703,Different approaches of find $P(X+Y>1/2)$ yielding different results,"I have the following question: Let X denote the diameter of an armored electric cable and Y denote
the diameter of the ceramic mold that makes the cable. Both X and Y
are scaled so that they range between 0 and 1. Suppose that X and Y
have the joint density $f(x,y)= (1/y), 0<x<y<1$ $=0,$ elsewhere. Find $P(X+Y >1/2)$ . Approach by the solution manual: $P(X+Y >1/2)=1-P(X+Y<1/2)$ then they continued accordingly and got $0.6534$ I have no issues with this approach, my problem is that I am following the more ""direct"" approach of directly computing $P(X+Y>1/2)$ and getting $0.5$ instead. My solution: First, I have the following graph: For a more interactive view, you can check the Desmos link here The orange area is my region of integration, I decided to integrate from the $y$ direction first while dividing my region into 2 parts to have 2 parts with one single entry and exit each, I divided it using a vertical line passing through the tip of the triangular shape at the bottom, this yields two double integrals: $\int_0^{1/4}\int_{1/2-x}^1 (1/y)dydx$ and $\int_{1/4}^{1}\int_{x}^1 (1/y)dydx$ Each of these integrals is equal to $1/4$ (done on WolframAlpha, so there should be no error in this part) which makes them sum to $1/2$ Before posting this I reviewed the given, the graph, and my integral set-up multiple times and couldn't find a mistake, any help would be appreciated.","['integration', 'multivariable-calculus', 'probability']"
4140727,Evaluating limits using Taylor expansions,The limits are $$\lim_{x\to 0}(\frac{\cos{x}-e^{-x^2/2}}{x^4})$$ $$\lim_{x\to 0}\frac{e^x\cdot\!\sin{x}-x(1+x)}{x^3}$$ Probably wrong things that I've tried $\lim_{x\to 0}\frac{\cos{x}-e^{-x^2/2}}{x^4}=\lim_{x\to 0}(\frac{1-\frac{x^2}{2!}+\frac{x^4}{4!}+o(x^5)-1+\frac{x^2}{2}+\frac{x^4}{4}+o(x^4)}{x^4})$ $\lim_{x\to 0}\frac{e^x\cdot\!\sin{x}-x(1+x)}{x^3}=\lim_{x\to 0}\frac{(1+x+\frac{x^2}{2}+o(x^2))(x+o(x^2))-x-x^2)}{x^3}=\lim_{x\to 0}\frac{\frac{x^3}{2}+o(x^2)}{x^3}=1/2$ Could you please help me understand how these kinds of limits can be computed I keep getting all of them wrong and if this goes on for a little bit longer I may have a panic attack.,"['analysis', 'real-analysis', 'calculus', 'taylor-expansion', 'limits']"
4140737,false proof of $\root \of 4$ is irrational.,"There is a proof in my math textbook about the fact that $\root \of 2$ is irrational. Proof : Lets assume that $\root \of 2$ is rational.Then there will exist $2$ coprime natural numbers $p$ , $q > 1$ such that , $$ \root \of 2 = \frac{p}{q} \to 2 = \frac{p^2}{q^2} \to 2q = \frac{p^2}{q}$$ Obviously , $2q$ is an integer but $\frac{p^2}{q}$ is not a integer , because $p$ and $q$ are natural numbers , coprime and $q > 1$ . So, $$2q \neq \frac{p^2}{q} \to \root \of 2 \neq \frac{p}{q}$$ So , $\root \of 2$ is an irrational number. $\square$ But the confusion to me is , it seems like I can use this argument to show that $\root \of 4$ is an irrational number. Proof : Lets assume that $\root \of 4$ is rational.Then there will exist $2$ coprime natural numbers $p$ , $q > 1$ such that , $$ \root \of 4 = \frac{p}{q} \to 4 = \frac{p^2}{q^2} \to 4q = \frac{p^2}{q}$$ Obviously , $4q$ is an integer but $\frac{p^2}{q}$ is not a integer , because $p$ and $q$ are natural numbers , coprime and $q > 1$ . So, $$4q \neq \frac{p^2}{q} \to \root \of 4 \neq \frac{p}{q}$$ So , $\root \of 4$ is an irrational number. $\square$ Can someone tell me what is wrong with this proof?","['algebra-precalculus', 'irrational-numbers', 'fake-proofs']"
4140758,To show countable sub-additivity of the Hausdorff measure on $\mathbb R^n$,"For all $F\subset \mathbb R^n$ , we define $$\mathcal H_\delta^s(F) = \inf\left\{\sum_{i=1}^\infty |U_i|^s : F \subset \bigcup_{i=1}^\infty U_i, 0 \le |U_i| \le \delta \right\}$$ where $|U_i|$ is the diameter of the set $U_i$ , defined in the usual way. We also define $$\mathcal H^s(F) = \lim_{\delta\to 0} \mathcal H_\delta^s(F)$$ for every $F\subset\mathbb R^n$ . To show that $\mathcal H^s(F)$ is a measure, it is enough to prove that the following three properties are satisfied: (a) $\mathcal H^s(\varnothing) = 0$ , (b) $A \subset B \implies \mathcal H^s(A) \le \mathcal H^s(B)$ , (c) $\mathcal H^s\left(\bigcup_{i=1}^\infty A_i\right) \le \sum_{i=1}^\infty \mathcal H^s(A_i)$ with equality if $A_i$ 's are disjoint Borel sets. I need help with (c). (c) Following the ideas of the previous two parts, I would first like to show that $\mathcal H^s_\delta\left(\bigcup_{i=1}^\infty A_i\right) \le \sum_{i=1}^\infty \mathcal H^s_\delta(A_i)$ and then take limits as $\delta\to 0$ . Consider $A_i$ for some $i$ . Let $\{U_{ij}\}_{j=1}^\infty$ be a $\delta$ -cover of $A_i$ , i.e. $A_i \subset \bigcup_{j=1}^\infty U_{ij}$ . Then, $$\bigcup_{i=1}^\infty A_i \subset \bigcup_{i=1}^\infty \bigcup_{j=1}^\infty U_{ij}$$ i.e. the union of all covers is a cover for the union of $A_i$ . How do I proceed from here? I also need to show that equality holds if $A_i$ 's are disjoint Borel sets. Thanks for your help!","['measure-theory', 'hausdorff-measure', 'real-analysis']"
4140763,"Is there an isometry between the direct sum of $L^1(\mu_i)$ and $L^1(\nu)$, i.e. $\bigoplus_{i} L^1(\mu_i)\cong L^1(\nu)$?","In https://math.stackexchange.com/a/74877/653080 it is mentioned that $\mathcal{M}(K)\cong L^1(\nu)$ for some measure $\nu$ , whereas $\mathcal M(K)$ is an $\mathcal{l}_1-$sum of $L_1(\mu)$ spaces is it mentioned that $\mathcal{M}(K)\cong \bigoplus_{i\in I} L^1(\mu_i)$ for some mutually singular probability measures $\mu_i$ . This hints at that $\bigoplus_{i\in I} L^1(\mu_i)\cong L^1(\nu)$ . Does this mean that in general there exists a (probability) measure $\nu$ such that $\bigoplus_{i\in I} L^1(\mu_i)\cong L^1(\nu)$ , when $\mu_i$ are mutually singular probability measures $\mu_i$ ? If so, can we choose $\nu$ to be any probability measure $\nu$ with full support on $K$ ? The spaces $\bigoplus_{i\in I} L^1(\mu_i)$ and $L^1(\nu)$ are defined as $$
   L^1(\nu) = \{f:K\to\mathbb{R}^d \;|\; \int_K|f(x)|d\nu(x) < \infty \} \\
   \bigoplus_{i\in I} L^1(\mu_i) = \{ (f_1,f_2...) \;|\; f_i\in L^1(\mu_i)\}
$$ with norms $$
    ||f||_{L^1(\nu)} = \int_K|f(x)|d\nu(x) \\
    ||f||_{\bigoplus_{i\in I} L^1(\mu_i)} = \sum_{i\in I}||f_i||_{L^1(\mu_i)}
$$","['banach-spaces', 'measure-theory', 'direct-sum', 'functional-analysis', 'isometry']"
4140798,The equation $yy''=-1$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Is the equation $$yy''=-1$$ well-known in literature, i.e., are there any references where it has been studied?
It came up in the context of my research and, due to its simple appearance, I thought that the behaviour of its solutions might be known already.","['ordinary-differential-equations', 'reference-request']"
4140846,"Calculating $\int_{\mathbb{R}^5}\frac{e^{-x^2-y^2-z^2}}{1+w^2+s^2}\,dx\,dy\,dz\,dw\,ds$","Calculate the following: $$\int_{\mathbb{R}^5}\frac{e^{-x^2-y^2-z^2}}{1+w^2+s^2}\,\mathrm{d}x\,\mathrm{d}y\,\mathrm{d}z\,\mathrm{d}w\,\mathrm{d}s$$ I tried to do the following (based on the suggestion below): \begin{align}
\int_{\mathbb{R}^5}\frac{e^{-x^2-y^2-z^2}}{1+w^2+s^2}\,\mathrm{d}x\,\mathrm{d}y\,\mathrm{d}z\,\mathrm{d}w\,\mathrm{d}s &= \int_{\mathbb{R}^3}{e^{-x^2-y^2-z^2}}\mathrm{d}x\,\mathrm{d}y\,\mathrm{d}z\int_{\mathbb{R}^2}\frac{1}{1+w^2+s^2}\,\mathrm{d}w\,\mathrm{d}s
\\&=\pi^{3/2}\int_{0}^{2\pi}\int_{0}^{\infty}\frac{1}{1+r^2}r\,\mathrm{d}r\,\mathrm{d}\theta
\\&=\pi^{3/2}\cdot2\pi\left(\frac{1}{2}\ln(1+r^2)\right)\bigg|_{0}^{\infty}
\\&=\infty
\end{align} but I'm not sure about it, would appreciate your help:)","['multivariable-calculus', 'multiple-integral']"
4140859,How many possible combinations are there for a password with 10 characters?,"The password must have 10 characters, each of which can be a number, or an uppercase or lowercase letter, so there are 68 possibilities for any character. (I'm using the Finnish alphabet which has 29 letters) The password must contain each of the following: at least one number, one lowercase letter and one uppercase letter. How many possibilities are there for such a password? I have tried to solve it as per the following but I am not sure about the answer. My logic is that first I calculate the possibilities for the number and the amount of places it can be, and then do the same for the mandatory uppercase and lowercase letters and then for the remaining seven characters, just multiply the amount of character possibilities (68) seven times. $$10\cdot\binom{10}{1}\cdot29\cdot\binom{9}{1}\cdot29\cdot\binom{8}{1}\cdot68^7=40709041893369446400\approx4{,}071\cdot10^{19}$$",['combinatorics']
4140936,Structure of the Brainball group,"This is a Brainball : It consists of $13$ numbered pieces arranged in a ring and a core; each piece has one side white and one side yellow. Part of the core, the blue caps in the picture above, can flip two groups of $3$ and $4$ pieces at once like pancakes, on opposite sides of the ring; the solved position has the white faces of $1$ to $13$ running clockwise on the same side. Scherphuis's website gives the number of positions as $2^{12}\cdot12!$ by noting a parity restriction (parity of piece permutation equals parity of number of yellow tiles you see) and treating positions differing by a ring twist as equal. We can effectively ""quotient out"" both restrictions by fixing piece $13$ and not turning the whole puzzle over (only twist the ring and the blue caps). The form of the puzzle and the form of the number of positions strongly suggests that the structure of the group $G$ of Brainball positions after quotienting out is the wreath product $C_2\wr S_{12}$ – my question here is on how to prove (or disprove) this. $G$ has $13$ generators corresponding to the positions of piece $13$ relative to the blue caps when doing a flip. Interpret Brainball positions as permutations on $24$ elements, where piece $n$ 's white side ( $1\le n\le12$ ) is associated with permuted element $n$ and the same piece's yellow side is associated with permuted element $12+n$ . I wrote a little Python script to print the $13$ generating permutations: #!/usr/bin/env python3
import numpy as np

def flip(n):
    A = np.roll(np.arange(13), n)
    A[:3] = -A[2::-1]
    A[6:10] = -A[9:5:-1]
    k = (A == 0).nonzero()[0][0]
    return np.roll(A, -k)

for n in range(13):
    B = flip(n)
    A = [0] * 25
    for i in range(1, 13):
        j = B[i]
        if j < 0:
            j = -j
            A[j] = 12+i
            A[12+j] = i
        else:
            A[j] = i
            A[12+j] = 12+i
    print(f""p{n} := PermList({A[1:]});"")
print(""G := Group([p0, p1, p2, p3, p4, p5, p6, p7, p8, p9, p10, p11, p12]);"") This produces the following output: p0 := PermList([24, 23, 1, 2, 3, 19, 18, 17, 16, 8, 9, 10, 12, 11, 13, 14, 15, 7, 6, 5, 4, 20, 21, 22]);
p1 := PermList([24, 2, 3, 4, 20, 19, 18, 17, 9, 10, 11, 13, 12, 14, 15, 16, 8, 7, 6, 5, 21, 22, 23, 1]);
p2 := PermList([3, 4, 5, 21, 20, 19, 18, 10, 11, 12, 14, 13, 15, 16, 17, 9, 8, 7, 6, 22, 23, 24, 2, 1]);
p3 := PermList([1, 2, 18, 17, 16, 15, 7, 8, 9, 24, 23, 22, 13, 14, 6, 5, 4, 3, 19, 20, 21, 12, 11, 10]);
p4 := PermList([1, 17, 16, 15, 14, 6, 7, 8, 23, 22, 21, 12, 13, 5, 4, 3, 2, 18, 19, 20, 11, 10, 9, 24]);
p5 := PermList([16, 15, 14, 13, 5, 6, 7, 22, 21, 20, 11, 12, 4, 3, 2, 1, 17, 18, 19, 10, 9, 8, 23, 24]);
p6 := PermList([24, 23, 22, 1, 2, 3, 18, 17, 16, 7, 8, 9, 12, 11, 10, 13, 14, 15, 6, 5, 4, 19, 20, 21]);
p7 := PermList([24, 23, 2, 3, 4, 19, 18, 17, 8, 9, 10, 13, 12, 11, 14, 15, 16, 7, 6, 5, 20, 21, 22, 1]);
p8 := PermList([24, 3, 4, 5, 20, 19, 18, 9, 10, 11, 14, 13, 12, 15, 16, 17, 8, 7, 6, 21, 22, 23, 2, 1]);
p9 := PermList([4, 5, 6, 21, 20, 19, 10, 11, 12, 15, 14, 13, 16, 17, 18, 9, 8, 7, 22, 23, 24, 3, 2, 1]);
p10 := PermList([1, 2, 17, 16, 15, 6, 7, 8, 24, 23, 22, 21, 13, 14, 5, 4, 3, 18, 19, 20, 12, 11, 10, 9]);
p11 := PermList([1, 16, 15, 14, 5, 6, 7, 23, 22, 21, 20, 12, 13, 4, 3, 2, 17, 18, 19, 11, 10, 9, 8, 24]);
p12 := PermList([15, 14, 13, 4, 5, 6, 22, 21, 20, 19, 11, 12, 3, 2, 1, 16, 17, 18, 10, 9, 8, 7, 23, 24]);
G := Group([p0, p1, p2, p3, p4, p5, p6, p7, p8, p9, p10, p11, p12]); It turns out that $p_0$ and $p_3$ can generate all of $G$ , so set G := Group([p0, p3]) . Trying to show isomorphism by H := WreathProduct(Group([(1,2)]), SymmetricGroup(12)); IsomorphismGroups(G,H); takes too long, however, so I tried the following. gap> N := First(NormalSubgroups(G), x -> Order(x) = 4096);
<permutation group of size 4096 with 12 generators>
gap> MinimalGeneratingSet(N);
[ (11,23), (12,24), (1,13), (2,14), (3,15), (4,16), (5,17), (6,18), (7,19), (8,20), (9,21), (10,22) ]
gap> H := FactorGroup(G, N);
Group([ (1,12,10,8,5,3)(2,11,9,4)(6,7), (3,6)(4,5)(10,12) ])
gap> StructureDescription(H);
""S12"" $N\cong C_2^{12}$ is the only normal subgroup of order $2^{12}$ in $G$ ; the above commands show that the quotient $H$ is isomorphic to $S_{12}$ . Combined with a comparison between the normal subgroup orders and conjugacy class counts ( $1165$ ) of $G$ and $C_2\wr S_{12}$ , this seems like very strong evidence for $G\cong C_2\wr S_{12}$ , but I'm not convinced. Are the above computations enough to show $G\cong C_2\wr S_{12}$ ? If not, what else do I need to do?","['gap', 'group-theory', 'puzzle', 'wreath-product']"
4140940,The shortest distance (not duplicated),"This is not the same question as this Consider the ellipse defined by $$x^2+4y^2=4$$ and the line $$x+y=4$$ find the shortest distance from a point on the ellipse to the line. In other words, we want to find a function $D(x,y)$ , you plug into it a point on the ellipse and it will tell you what is the closest point to this point on the line. This last line wasn't in the original question, so you may try to parametrize the ellipse and the line and try to find some connection, but this method didn't work for me ( $E$ is the ellipse and $L$ is the line): $$E(t)=\langle2\cos t,\sin t\rangle,  \text{  }L(t)=\langle t, 4-t \rangle$$ $$\implies D(t)=\langle t-2\cos t, 4-t-\sin t\rangle$$ but this curve doesn't work, it just tells you what is the path between two points on the ellipse and the line.","['curves', 'multivariable-calculus', 'vectors']"
4140956,Evaluate the order of the pole in $1/(1-\cos(z))^2$,"I'm trying to determine the order of the pole in the complex expression $$f(z)=\frac{1}{(1-\cos(z))^2}$$ I have determined the pole to be $z=2\pi n, n\in \mathbb{Z}$ . However, when I use the equation $\lim\limits_{z\rightarrow 2\pi n}[(z-2\pi n)^k f(z)]$ with $k=1$ , it equals $\frac{0}{1}=0$ or that the function is analytical in the neighborhood. I have used L'Hôpital's rule repeatedly to obtain this result. I checked my answer with Wolfram Alpha, and it's supposed to have a pole of order $4$ and $z=2\pi n$ . Where am I going wrong?","['complex-analysis', 'singularity']"
4140971,If $P(Y=y\mid X=x)=\chi_{\{c(x)=y\}}$ why is $E[Y\mid X]=Y$,"Let $X$ be a random variable on $\mathcal{X}$ while $Y$ is a random variable on $\mathcal{Y}$ . Further $c$ is a map: $c:\mathcal{X}\to \mathcal{Y}$ If $P(Y=y\mid X=x)=\chi_{\{c(x)=y\}} \; \; (*)$ where $\chi$ is the characteristic/indicator function, why is $E[Y\lvert X]=Y$ ? My idea: For any $x\in \mathcal{X}$ , we have on the event $\{X=x\}$ that $Y=c(x)\; \; (**)$ For me it seems clear that then $c(X)=Y$ , and if I were to be able to assume that $c$ is measurable I could simply state: $E[Y\mid X]=E[c(X)\mid X]=c(X)=Y$ . Is there more rigourous reasoning why $(**)$ would imply that $c(X)=Y$ ?","['expected-value', 'statistics', 'conditional-expectation', 'probability']"
4140973,"Nature of convergence of the sequence of functions $(f_1(x))^{1/2^n}$ where $f_1$ is continuous $f_1:[0,\infty)\rightarrow[1,\infty)$","Given a continuous function $f_1:[0,\infty)\rightarrow[1,\infty)$ Define a sequence of functions recursively by $n\geq1$ , $f_{n+1}(x)=\sqrt{f_n(x)}$ Is this sequence of functions pointwise convergent? uniformly convergent? If Yes, find the limit function Attempt: First, we want to see the pattern of the recursive $f_1,f_2,f_3\dots$ $$n=1, f_2(x)=\sqrt{f_1(x)}$$ $$n=2, f_3(x)=\sqrt{\sqrt{f_1(x)}}$$ $$n=3, f_4(x)=\sqrt{\sqrt{\sqrt{f_1(x)}}}$$ $$\vdots$$ $$n\in\mathbb{N},f_{n+1}(x)=\sqrt[2n]{f_1(x)}$$ $$n\in\mathbb{N},f_{n}(x)=\sqrt[2(n-1)]{f_1(x)}$$ $$\sum^{\infty}_{n=1}a_n(x)=\lim_{n\rightarrow\infty}f_n(x)-f_1(x)$$ $$\lim_{n\rightarrow\infty}f_n(x)-f_1(x)=\lim_{n\rightarrow\infty}\sqrt[2(n-1)]{f_1(x)}-f_1(x)$$ I had to stop here because I think there is a mistake, I will appreciate that if anyone enlights me.","['limits', 'calculus', 'functions']"
4141004,Show $\frac{\sin20^\circ\sin30^\circ\tan40^\circ}{\sin20^\circ\sin30^\circ+\tan40^\circ\sin50^\circ} =\tan10^\circ$,"The question arose in finding $\alpha$ in this diagram: (source: mei.org.uk ) With a bit of work with the sine rule it can be shown that: $$\tan(\alpha) = \frac{\sin(20^\circ)\sin(30^\circ)\tan(40^\circ)}{\sin(20^\circ)\sin(30^\circ)+\tan(40^\circ)\sin(50^\circ)}$$ ... and this can be evaluated on a calculator to find $\alpha = 10^\circ$ . But I'm not satisfied in using a calculator. I want to know if there's a neat way of manipulating the expression on the RHS so that it simplifies out to $\tan(10^\circ)$ . I've had a good go at it - using double/triple/quadruple angle formulae to re-write everything in terms of $\sin(10^\circ)$ , $\cos(10^\circ)$ and $\tan(10^\circ)$ and trying to simplify - but just seem to make things more complicated. Can you find a nice way of doing it?","['trigonometry', 'angle', 'geometry']"
4141013,How many integers 1 to 1000 are multiples of 3 or 9?,"I'm stumped about how to solve this, because every multiple of 9 is already a multiple of 3. Here's what I have so far: A = 999/3 = 333
B = 999/9 = 111 (A ∩ B) = multiples of 9 from 1 to 1,000, which equals 111 (A ∪ B) = A + B − (A ∩ B)
= 333 + 111 − 111
= 333","['inclusion-exclusion', 'discrete-mathematics']"
4141014,Injection into double dual is isomorphism away from codimension $\geq 2$ subscheme,"Let $X$ be a quasi-projective integral scheme and let $F$ be a torsion-free coherent sheaf over $X$ . Then there is an injective map $$\phi\colon F\hookrightarrow F^{\vee\vee}.$$ Moreover, in my situation it is known that $F^{\vee\vee}$ is locally free. Is it true that $\phi$ is an isomorphism away from a closed subscheme of codimension $\geq 2$ ? Of course, this holds true if $X$ is normal, but is it also true for non-normal $X$ ?","['algebraic-geometry', 'projective-schemes', 'schemes']"
4141040,$\int_{0}^{\pi/2}\arctan(\sin(x))dx=\frac{\pi^2}{8}-\frac{\ln^2(\sqrt{2}-1)}{2}$,"I am trying to evaluate the following integral, so far I tried 2 different ways, but could not finish the proof. Through the second method, it seems that I got closer $$\int_{0}^{\pi/2}\arctan(\sin(x))dx=\frac{\pi^2}{8}-\frac{\ln^2(\sqrt{2}-1)}{2}$$ First Method Consider the more general version with parameter k $$I(k)=\int_{0}^{\pi/2}\arctan(k\sin(x))dx$$ $$I^{\prime}(k)=\int_{0}^{\pi/2}\frac{\sin(x)}{1+k^2\sin^2(x)}dx$$ $$I^{\prime}(k)=\int_{0}^{\pi/2}\frac{\sin(x)}{\cos^2(x)+\sin^2(x)+k^2\sin^2(x)}dx$$ $$I^{\prime}(k)=\int_{0}^{\pi/2}\frac{\sin(x)}{\cos^2(x)+(1+k^2)\sin^2(x)}\frac{1}{\frac{\sin^2(x)}{\sin^2(x)}}dx$$ $$I^{\prime}(k)=\int_{0}^{\pi/2}\frac{\csc(x)}{\cot^2(x)+(1+k^2)}dx$$ substitution $\cot^2(x)=t$ does not seem very helpful. Second Method let $\sin(x)\longrightarrow x$ $$\int_{0}^{\pi/2}\arctan(\sin(x))dx=\int_{0}^{1}\frac{\arctan(x)}{\sqrt{1-x^2}}dx$$ integrating by parts $$\int_{0}^{1}\frac{\arctan(x)}{\sqrt{1-x^2}}dx=\arctan(x)\cdot\arcsin(x)|_{0}^{1}-\int_{0}^{1}\frac{\arcsin(x)}{1+x^2}dx$$ $$=\frac{\pi^2}{8}-\underbrace{\int_{0}^{1}\frac{\arcsin(x)}{1+x^2}dx}_{J}$$ using the expansion of $\arcsin(x)$ $$J=\int_{0}^{1}\frac{\arcsin(x)}{1+x^2}dx=\sum_{n=0}^{\infty}\frac{(2n)!}{2^{2n}(n!)^2}\frac{1}{2n+1}\int_{0}^{1}\frac{x^{2n+1}}{1+x^2}dx$$ Can someone indicate a method to help me finish at least one of the two methods?
Thank you","['integration', 'definite-integrals', 'sequences-and-series']"
4141049,Radon-Nikodym derivative of functions defined on graphs.,"I have been wondering for a bit what is the actual utility of a Radon-Nikodym derivative.
One thing I've observed is that it provides a general notion of derivative given a measure space (under further assumptions). As application of this is a classic one is the derivative of standard functions of real variable (so they generalize the riemann integral on the real line) but another one was derivitives w.r.t. counting measures. To some extent, and correct me if I am wrong, they unify for example the notion of derivative of real function of real variables with finite differences for example. I wonder if there's another application in graph theory for example, given a graph $G = (V,E)$ we can define a function $f : V \to \mathbb{C}$ as $f(v_i) = x_i$ I am familiar with the notion of Combinatorial Laplacian however I was wondering if it is possible to associate to a graph $G$ some measure space so that the definition of derivative would follow quite naturally from the use of Radon-Nikodym derivative. I am no expert in graph theory, but this sounds one of those things that someone surely must have tried or thought about, but I don't even know what keywords should I look for.","['measure-theory', 'graph-theory', 'derivatives', 'soft-question', 'radon-nikodym']"
4141057,limit superior of real value function (Exercise 9.3.4 in Tao Analysis I),"Here is the exercise: Propose a definition for limit superior $\lim\sup_{x \to x_0 ; x \in E} f(x)$ and limit inferior $\lim\inf_{x \to x_0 ; x \in E} f(x)$ , and then propose an analogue of Proposition 9.3.9 for your definition.
(For an additional challenge: prove that analogue.) Here is Proposition 9.3.9: Let $X$ be a subset of $\mathbf{R}$ , let $f : X \to \mathbf{R}$ be a function, let $E$ be a subset of $X$ , let $x_0$ be an adherent point of $E$ , and let $L$ be a real number.
Then the following two statements are logically equivalent: (a). $f$ converges to $L$ at $x_0$ in $E$ . (b). For every sequence $(a_n)_{n = 0}^\infty$ which consists entirely of elements of $E$ and converges to $x_0$ , the sequence $(f(a_n))_{n = 0}^\infty$ converges to $L$ . Here is my attemped: Let $X$ be a subset of $\mathbf{R}$ , let $f : X \to \mathbf{R}$ be a function, let $E$ be a subset of $X$ , and let $x_0$ be an adherent point of $E$ .
We define limit superior at $x_0$ in $E$ as $$
    \limsup_{x \to x_0 ; x \in E} f(x) = \inf\Big\{\sup\big\{f(x) : x \in E \land |x - x_0| < \delta\big\} : \delta \in \mathbf{R}^+\Big\}
$$ Let $L \in \mathbf{R} \cup \{-\infty, +\infty\}$ .
We claim that the following statements are equivalent: (a). $\limsup_{x \to x_0 ; x \in E} f(x) = L$ (b). For every sequence $(a_n)_{n = 1}^\infty$ which consists entirely of elements of $E$ and converges to $x_0$ , the sequence $(f(a_n))_{n = 1}^\infty$ has limit superior $\limsup_{n \to \infty} f(a_n) \leq L$ There exists a sequence $(b_n)_{n = 1}^\infty$ which consists entirely of elements of $E$ and converges to $x_0$ , and $\limsup_{n \to \infty} f(b_n) = L$ I managed to prove (a) implies (b).
But I don't know how to prove (b) implies (a).
(Note that $L$ can be $-\infty$ or $+\infty$ )
Any helps are appreciated.","['limits', 'limsup-and-liminf', 'real-analysis']"
4141105,"Given a $k^2$-membered set $S$ of points with coordinates $(x,y)\in \{ 1,2,...,k \}$, prove that some $4$ points in $S'$ lie on a circle.","We are given a $k^2$ -membered set $S$ of points on a plane. The points' coordinates are integers between $1$ and $k$ . We then construct another set $S'$ which contains at least $\frac{5}{2} k-1$ points from S. We should prove that there are always at least $4$ points in $S'$ that lie on a common circle. The situation amounts to a $k$ by $k$ square with an integer grid, the members of $S$ being all the vertices of the grid. A certain portion of the points, $k^{2}-\frac{5}{2}k+1$ of them, is then removed. For $4$ points to be on a circle, it is sufficient that they lie in the vertices of an isosceles trapezium. It is thus sufficient to prove that taking away $k^{2}-\frac{5}{2}k+1$ points is never enough to eliminate all possible sub-sections that form an isosceles trapezium from the square grid. This problem is rather interesting because the visually rephrased statement seems very intuitive but I am not sure how to proceed to rigorously prove this, especially concerning the specific quanitity $k^{2}-\frac{5}{2}n+1$ . I'd be grateful for any help.","['euclidean-geometry', 'combinatorics', 'plane-geometry']"
4141122,$\sum_{n=2}^\infty a^{-\ln(\ln(n))}$ for every $a>1$,"I want to determine if this sum is convergent or divergent: $\sum_{n=2}^\infty a^{-\ln(\ln(n))}$ for every $a>1$ . Define $f(x)=a^{-\ln(\ln(x))}$ for every $x \ge 2$ . $f$ is decreasing (since $a^{\ln(\ln(x))}$ is increasing), so we can use the Integral test, But I find it hard to calculate $\int_2^\infty a^{-\ln(\ln(n))}$ . Any hints to solve this integral (hints only please)? Thanks a lot!","['integration', 'improper-integrals', 'calculus', 'functions', 'sequences-and-series']"
4141129,What does this image represent and how to sketch it?,"I saw this question on a mathematics telegram channel: What does this image represent and how we can sketch it with
mathematical functions or mathematical equations? I'm not sure what this image is about and not sure what different colors mean here. I see a square divided into for equal squares. and there are lots of shapes like circle but most of them aren't really a circle.
Maybe it is about some advanced fields in mathematics?","['functions', 'geometry', 'graphing-functions']"
4141143,$\lim_{n \to +\infty} E[ \vert X_n \vert] = 0 \implies \lim_{n \to +\infty} E[ (X_n)^2] = 0$? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Suppose $(X_n)_{n \in \mathbb{N}}$ is a sequence real random variables which are uniformly bounded $P$ -a.s. If $$
\lim_{n \to +\infty} E[ \vert X_n \vert] = 0
$$ does this imply $$
\lim_{n \to +\infty} E[ (X_n)^2] = 0
$$ as well? It would if the variables were bounded by 1. But what if that's not case? I've looked at Jensen's Inequality but it seems to be the wrong way around",['probability-theory']
4141149,Prove Borel $\sigma-$algebras generated by two topologies of $L^1_{loc}(\mathbb{R}^d)$ are equivalent,"Let $L^1_{loc}(\mathbb{R}^d)$ be equipped with the following topologies: Strong topology, i.e., the base includes \begin{align}
U_{\Omega,f,\epsilon} 
= \left\{ g \in L^1_{loc} \colon \int_{\Omega} \vert f(x) - g(x)\vert d x < \epsilon 
\right\}
\end{align} where $\Omega \subset \mathbb{R}^d$ is compact, $f \in L^1(\Omega),~\epsilon > 0$ . Distributional topology, i.e., the base includes \begin{align}
W_{\phi, a, b} =
\left\{
g \in L^1_{loc} \colon \int_{\mathbb{R}^d} g(x) \phi(x) dx \in (a,b)
\right\}
\end{align} where $\phi \in C^{\infty}_c(\mathbb{R}^d),~a < b.$ Let $\mathcal{B}_s,~\mathcal{B}_d$ be the $\sigma-$ algebras generated by the strong topology and the distributional topology, respectively. I want to show $\mathcal{B}_s=\mathcal{B}_d$ . Since the weak-* open set is also (strongly) open, we deduce $\mathcal{B}_s \supset \mathcal{B}_d$ . I'm stuck at the other direction. I try to connect the two sets by using the fact: Given $\Omega \subset \mathbb{R}^d$ compact and $h \in L^1_{loc}(\mathbb{R}^d)$ , there exists $\eta_n \in C_c^{\infty}(\mathbb{R}^d)$ such that \begin{align}
\int_\Omega \vert h(x) \vert d x =\sup_{n \in \mathbb{N}} \int_{\mathbb{R}^d} h(x) \eta_n (x) dx.
\end{align} However, I'm not able to proceed further. Any ideas? Thank you.","['measure-theory', 'analysis', 'real-analysis', 'functional-analysis', 'general-topology']"
4141178,Is $\textbf{A}^m=\textbf{I}$ diagonalizable? [duplicate],"This question already has answers here : Let $A$ be a complex matrix such that $A^n = I$, show that $A$ is diagonalisable. (2 answers) Closed 3 years ago . Let $\textbf{A} \in M_{n\times n}(\mathbb{C})$ be a Matrix and $\textbf{A}^m=\textbf{I}$ where $m\neq \infty$ . Show (with Jordan normal form) that $\textbf{A}$ is diagonalizable. I have no clue how to do that...","['matrices', 'diagonalization', 'linear-algebra']"
4141186,"""Reverse"" Chebyshev Inequality that gives lower bound of being far from mean [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Chebyshev's inequality gives an upper bound on $P(|X - \mu| \geq k\sigma)$ but I was wondering if there was a way to find a lower bound for this probability or, equivalently an upper bound on $P(|X - \mu| < k\sigma)$ . What about with added assumptions? For example, is there any way to get a lower bound for the probability that a $\textrm{Binomial}(n, p)$ variable takes a value more than a constant $K$ away from the mean?","['variance', 'binomial-distribution', 'probability']"
4141212,Compute the expected number of dice that have been rolled at least once.,"I have been stuck forever on a homework problem. I thought I found the solution to the problem, but a friend simulated the setup with code and got a different final answer. I'm pretty sure his code is correct, but I also don't understand what could be wrong about my answer, so I was hoping you could enlighten me! Problem Definition: You have in total 5 dice. You select one of them at random and roll it. Then, you repeat this procedure 8 more times. Compute the expected number of dice that have been rolled at least once. My Solution: We can ignore the order of how we threw the dice. The total number of possibilities is \begin{equation}
  N={9+5-1 \choose 9}={13 \choose 9}=715.
\end{equation} For exactly $x$ different dice thrown at least once, we know that there are ${5 \choose x}$ amount of ways we can choose which dice to throw at least once. For each possible choice we for sure throw all $x$ dice once, after that we are free to do $9-x$ more throws. Every throw we get to choose any of the $x$ dice, thus \begin{equation}
  n(x)={5 \choose x}{(9-x)+x-1 \choose 9-x}={5 \choose x}{8 \choose 9-x},
\end{equation} where $n(x)$ is the amount of ways we could have thrown exactly $x$ dice at least once. For the last step we just use a calculator, giving: \begin{equation}
  \mathbb{E}(X)=\sum_{x=1}^5x\, \frac{n(x)}{N}=\frac{45}{13}.
\end{equation}","['statistics', 'probability-theory', 'probability']"
4141239,Can we say that $\lambda (A) = 0\ $?,"Let $(X, \mathcal A, \mu)$ be a $\sigma$ -finite measure space and let $f : X \longrightarrow [0,\infty]$ be a non-negative $\mu$ -measurable function on $X.$ Consider the set $$\begin{align*} A & := \left \{t \in [0,\infty]\ \bigg |\ \mu \left (\left \{x \in X\ \bigg |\ f(x) = t \right \} \right ) \gt 0 \right \}. \end{align*}$$ Can we say that $\lambda (A) = 0\ $ ? where $\lambda$ denotes the Lebesgue measure on $\Bbb R.$ I think it is the case but can't able to prove it. Do anybody have any idea about that?","['measure-theory', 'measurable-functions']"
4141257,A textbook with a proof of the Rank Theorem using only Banach's Fixed Point Theorem.,"It is well known that the Rank Theorem for $C^1$ maps can be obtained as a consequence of the Implicit Mapping Theorem and the Inverse Mapping Theorem for $C^1$ maps. See for example Zorich vol 1 . It is also well known that the Implicit and Inverse Mapping theorems are a consequence of the Banach's Fixed Point Theorem. See Pugh for a proof of Implicit Mapping Theorem directly from Banach's Fixed Point Theorem. See Rudin for a proof of the Inverse Mapping Theorem directly from Banach's Fixed Point Theorem. Obviously, for what was exposed in the previous paragraph, a proof (or several proofs) of Rank Theorem for $C^1$ mapping by means of the Banach Fixed Point Theorem exists. In other words, the affirmations of the Banach fixed point theorem and Rank Theorem for $C^1$ mapping  are not independent. In view of these considerations, my question is as follows. Is there any textbook with a proof of the rank theorem using Banach's Fixed Point Theorem? In the absence of a textbook, I would be very grateful for articles and lecture notes.","['fixed-point-theorems', 'reference-request', 'alternative-proof', 'analysis', 'real-analysis']"
4141261,"If $G$ has an $\Omega$-composition series, prove that every $\Omega$-subgroup [of $G$ has] a composition series.","This is part of Exercise 3.1.4 of Robinson's ""A Course in the Theory of Groups (Second Edition)"" . According to Approach0 , it is new to MSE. The Details: Since definitions vary, on page 15, ibid. , paraphrased, it states that A subgroup $N$ of $G$ is normal in $G$ if one of the following equivalent statements is satisfied: (i) $xN=Nx$ for all $x\in G$ . (ii) $x^{-1}Nx=N$ for all $x\in G$ . (iii) $x^{-1}nx\in N$ for all $x\in G, n\in N$ . On page 28, ibid. , A right operator group is a triple $(G, \Omega, \alpha)$ consisting of a group $G$ , a set $\Omega$ called the operator domain and a function $\alpha:G\times \Omega\to G$ such that $g\mapsto (g,\omega)\alpha$ is an endomorphism of $G$ for each $\omega\in\Omega$ . We shall write $g^\omega$ for $(g,\omega)\alpha$ and speak of the $\Omega$ -group if the function $\alpha$ is understood. [. . .] If $G$ is an $\Omega$ -group, an $\Omega$ -subgroup of $G$ is a subgroup $H$ which is $\Omega$ -admissible , that is, such that $h^\omega\in H$ whenever $h\in H$ and $\omega\in\Omega$ . On page 63, ibid. , Let $G$ be an operator group with operator domain $\Omega$ . An $\Omega$ -series (of finite length) in $G$ is a finite sequence of $\Omega$ -subgroups including $1$ and $G$ such that each member of the sequence is a normal subgroup of its successor: thus a series can be written $$1=G_0\lhd G_1\lhd\dots\lhd G_l=G.$$ The [. . .] quotient groups $G_{i+1}/G_i$ are the factors of the series. On page 64, ibid. , If $\mathbf{S}$ and $\mathbf{T}$ are $\Omega$ -series of [an $\Omega$ -group] $G$ , call $\mathbf{S}$ a refinement of $\mathbf{T}$ if every term of $\mathbf{T}$ is also a term of $\mathbf{S}$ . If there is at least one term of $\mathbf{S}$ which is not a term of $\mathbf{T}$ , then $\mathbf{S}$ is a proper refinement of $\mathbf{T}$ . On page 65, ibid. , An $\Omega$ -series which has no proper refinements is called an $\Omega$ -composition series . [. . .] If $\Omega$ is empty, we speak of a composition series . The Question: If $G$ has an $\Omega$ -composition series, prove that every $\Omega$ -subgroup [of $G$ has] a composition series. Thoughts: I'm somewhat confused: if $H$ is an $\Omega$ -subgroup of $G$ , then, in particular, it is a group, so . . . Yeah, I think that some refinement of $$1\lhd H$$ would be a composition series of $H$ , which would, I suppose, be guaranteed to exist since $G$ has an $\Omega$ -composition series, itself a refinement of $$1\lhd_\Omega G,$$ where $\lhd_\Omega$ means ""is a normal $\Omega$ -subgroup of"". I don't think I am expressing my thoughts clearly enough. For lack of a better term, perhaps there is some ""forgetful functor"" to go from $\lhd_\Omega$ to $\lhd$ . I don't know . . . I first encountered $\Omega$ -groups in Roman's ""Fundamentals of Group Theory: An Advanced Approach"" , page 274, a few months ago. They made sense then. Here is my previous question: Abelian and nonabelian groups with the same composition factors. Working through an example might help. Consider $\Omega=\{x\}$ , $G=S_3$ , and $$\begin{align}
\alpha:S_3\times \Omega &\to S_3\\
(\sigma,x)&\mapsto \sigma.
\end{align}$$ The series $$1\lhd_\Omega \Bbb Z_3\lhd_\Omega S_3$$ is an $\Omega$ -composition series by inspection. The subgroup $H=(\{e, (123), (321)\}, \circ)$ is an $\Omega$ -subgroup, since $\tau^x=\tau\in H$ for all $\tau\in H$ . Perhaps this example is not particularly illustrative, because $H$ so clearly has the composition series $$1\lhd H$$ without recourse to $G$ and its $\Omega$ -composition series. Please help :)","['group-theory', 'normal-subgroups']"
4141263,Rudin Theorem 2.30: relative openness,"I do not fully understand Rudin's Theorem 2.30. The context, which is not immediately clear from the problem,  is a metric space $(X,d)$ and a subset $Y \subset X$ . The theorem states: Suppose $Y \subset X$ . A subset $E$ of $Y$ is open relative to $Y$ if and only if $E = Y \cap G$ for some open subset $G$ of $X$ . I've replicated Rudin's proof's verbatim below, and will add my questions after. Suppose $E$ is open relative to $Y$ . To each $p \in E$ there is a positive number $r_p$ such that that the conditions $d(p,q) < r_p$ , $q \in Y$ imply that $q \in E$ . Let $V_p$ be the set of all $q \in X$ such that $d(p,q) < r_p$ , and define $G = \bigcup\limits_{p \in E} V_p$ . Then $G$ is an open subset of $X$ , by Theorems 2.19 and 2.24. Since $p \in V_p$ for all $p \in E$ , it is clear that $E \subset G \cap Y$ . By our choice of $V_p$ , we have $V_p \cap Y \subset E$ for every $p \in E$ , so that $G \cap Y \subset E$ . Thus $E = G \cap Y$ , and one half of the theorem is proved. Conversely, if $G$ is open in $X$ and $E = G \cap Y$ , every $p \in E$ has a neighborhood $V_p \subset G$ . Then $V_p \cap Y \subset E$ , so that $E$ is open relative to $Y$ . First, I'm not sure that I understand fully what 'open relative to $Y$ ' means. The definition of open is: $W \subset X$ ( $X$ a metric space) is open if for every $u \in W$ , there exists $\epsilon > 0$ such that $N_{\epsilon} (u) \subset W$ . My understanding of 'relative openness' is as follows. If we have $W \subset U \subset X$ , and for every $u \in W$ , there exists $\epsilon > 0$ such that $N_{\epsilon} (u) \subset W \subset U$ , so we s ay $N_{\epsilon} (u)$ is ""open relative to $W$ "" or open in $W$ , which I believe are equivalent notions. Is that correct? (If not, what I'm about to say almost will be f alse.) The first assumption is that $E$ is open relative to $Y$ , so given $p \in E$ , there is $r_p > 0$ so that $N_{r_p} (p) \subset Y \subset X$ . We call $V_p = N_{r_p} (p)$ , which is a neighborhood and, by Theorem 2.19, open. The problem is: the theorem only says open, but open relative to what? I assume we say open relative to $Y$ since $V_p \subset W$ . Then $G$ is a union of open sets and therefore open by Theorem 2.24, but relative to what? I would assume $Y$ again, but Rudin asserts that $G$ is an open subset of $X$ . This isa. problem, because Rudin warns right before stating this theorem that we may have a set that is open relative to $Y$ but not an open subset of $X$ . So this leads me to believe that I'm misinterpreting this, and perhaps $V_p$ is open in $X$ only. I think I can follow the remainder of the theorem, provided that I can get this fact straight, as much of it depends on understanding the concept of relative openness.","['proof-explanation', 'general-topology', 'real-analysis']"
4141277,Are there any interesting theorems of first-order group theory,"I've heard that theoremhood in first-order group theory is uncomputable, so there should be some theorems that are difficult to prove. However the few theorems of group theory I know are about subgroups, exponents and such, so they don't seem to be formalizable in first-order logic (for each $n\in\mathbb{N}$ we can write $\forall_x x^n=e$ for ""the group has exponent $n$ "" but this doesn't seem to help much). Are there any cool theorems or conjectures that are naturally stated in the first-order language of group theory?","['group-theory', 'logic', 'first-order-logic']"
4141364,Rank of a matrix over a ring?,"In his book Module Theory (1977), Blyth defines the column rank of an $m\times n$ matrix $A$ over a commutative unitary ring $R$ to be the dimension of the subspace of $\mathrm{Mat}_{m\times 1}(R)$ generated by the column...matrices of $A$ and dually for row rank (p. 153). However, he only defines dimension for free modules over commutative unitary rings (p. 105), so I don't think this definition will work as stated in general (even after changing ""subspace"" to ""submodule"") because a submodule of even a finitely generated free module over a commutative unitary ring need not be free. I'm trying to determine how to interpret an exercise which asks to show that the matrix $$A=\begin{bmatrix}1&2&3\\0&3&2\end{bmatrix}$$ over the ring $\mathbb{Z}/30\mathbb{Z}$ has a row rank of 2 and a column rank of 1 (p. 170). Should I just interpret this to be referring to the maximal numbers of linearly independent rows/columns? Note in the latest edition of his book (2018), it seems he has stated the definitions of rank for matrices over arbitrary unitary rings $R$ (p. 111), and generalized the definition of dimension to include also free modules over division rings (p. 78). The same exercise still appears (p. 121).","['matrix-rank', 'modules', 'matrices', 'abstract-algebra', 'linear-algebra']"
4141422,Prove by definition that $\lim\limits_{z \to i} \dfrac{4z+i}{z+1} = \dfrac{5i}{i+1}$,"I'm having trouble to prove this limit using $\epsilon - \delta$ . I know that, for every $\epsilon > 0$ , exists $\delta > 0$ , such that $0 < |z-i|<\delta \implies \left|\dfrac{4z+i}{z+1} - \dfrac{5i}{1+i}\right| < \epsilon$ we have $\left|\dfrac{4z+i}{z+1} - \dfrac{5i}{1+i}\right| = \left|\dfrac{4(z-i)-iz-1}{(z+1)(1+i)} \right|$ Now we can multiply by $i/i$ $\hspace{3.5cm} = \left|\dfrac{4i(z-i)+z-i}{i(z+1)(1+i)} \right|$ $\hspace{3.5cm} = \left|\dfrac{(z-i)(4i+1)}{i(z+1)(1+i)} \right| $ and I don't know what to do from here, I was trying to make appear the term $(z-i)$ to find $\delta$ in terms of $\epsilon$ , but I got stuck. Is this the right way to solve this problem? any tips will be helpful.","['complex-analysis', 'limits']"
4141444,"If a normal subgroup $N$ of $A_n$ contains any $3$-cycle, then $N = A_n$","Let $n\geq 3$ , if a normal subgroup $N$ of $A_n$ contains any $3$ -cycle, then $N = A_n$ . What I have done If $n\geq 5$ the result follows by these lemmas: (1) Let $n\geq3$ , then every element of $A_n$ is a product of $3$ -cycles and; (2) if $n\geq 5 $ , then any $3$ -cycle are conjugate in $A_n$ . Now for $n=3$ , we have that $A_3$ is a cyclic group generated by $(1 2 3)$ or $(1 3 2)$ . Thus, if $(1 2 3)$ or $(1 3 2)\in N$ , then $N=A_3$ My problem is when $n=4$ . I know that $M=\{(1),(12)(34),(13)(24),(14)(23)\}\cong \mathbb{Z}_2\times \mathbb{Z}_2$ is a normal subgroup of $A_4$ , but $M$ does't contain a $3$ -cycle. How can I go on to show that if $N$ contains a $3$ -cycle then $N=A_4$ ?","['permutation-cycles', 'finite-groups', 'abstract-algebra', 'symmetric-groups', 'group-theory']"
4141455,Union of closed convex sets,"Let $(K_n)_{n=1}^\infty$ be a sequence of convex, compact sets in the space $\mathbb{R}^k$ such that $$K_1\subsetneqq K_2\cdots \subsetneqq K_n\cdots.$$ Put $K=\bigcup_{n=1}^\infty K_n$ . Assume that $K$ is bounded. Can we deduce that $K$ is always not closed ? This is true for $k=1$ . It is also true if the sequence is such that $K_n$ is contained in the interior of $K_{n+1}$ . Is it possible to prove this in the general case or is there a counterexample?","['general-topology', 'convex-analysis', 'functional-analysis']"
4141460,Example where the associated sheaf does not exist,"What is a simple example of a topological space $X$ and a complete category $\mathcal{C}$ such that the inclusion $\mathbf{Sh}(X,\mathcal{C}) \hookrightarrow \mathbf{PSh}(X,\mathcal{C})$ has no left adjoint, i.e. there is a $\mathcal{C}$ -valued presheaf on $X$ which does not have an associated sheaf ? A sufficient condition for the existence of the associated sheaf is explained in Section 17.4 in Categories and sheaves by Kashiwara-Schapira: here the category $\mathcal{C}$ is assumed be be complete, cocomplete, filtered colimits are exact, and the IPC property holds. So for a counterexample one of these properties must fail.","['examples-counterexamples', 'category-theory', 'algebraic-geometry', 'sheaf-theory', 'adjoint-functors']"
4141477,Proving the existence/non-existence of $\lim_{x\rightarrow0} x\tan\frac1x$,"Find $$\lim_{x\rightarrow0} x\tan\frac1x$$ Now I tried to find the form of the limit ( $0/0$ or $0\cdot \infty$ or $\infty/\infty$ ), but as $x\rightarrow 0$ , $\tan(1/x)$ tends to $\tan \infty$ , and since $\tan x$ is unbounded unlike $\sin x$ or $\cos x$ , no particular value or range can be assumed for $\tan(1/x)$ . Then I tried to find LHL and RHL. Let $\lim_{x\rightarrow0^+} x\tan{(1/x)}=L$ . Then $\lim_{x\rightarrow0^-} x\tan{(1/x)}=-L$ , since $x$ is approaching from the negative side, the input $1/x$ of $\tan$ is the negative of the input in RHL, and $\tan (-x)=-\tan x$ Now if the limit exists, then $LHL=RHL$ , thus $L=0$ . Thus I got that if the limit exists, then it must be equal to $0$ . But this doesn't confirm that the limit exists (and it doesn't). Please help me in proving that the limit doesn't exist, and also please point out the mistakes (if any) in the argument I presented above (sorry for I might be weak in limits and the basics of it) EDIT: As pointed out by Shubham in the comments, I forgot to take the sign of $x$ too in the $LHL$ , thus rendering the argument which proved $L=0$ moot. THANK YOU","['limits', 'calculus', 'real-analysis']"
4141499,"To what extent it is necessary to assume ""complete regularity"" on $X$ to induce this locally convex topology on $C(X)$?","I found the following example in Conway's Functional Analysis Book: Suppose $X$ is a completely regular space and let $C(X)=$ all continuous functions from $X$ into $\Bbb{C}$ . If $K$ is a compact subset of $X$ , define $p_K(f)=\sup \{|f(x)|: x \in K\}$ . Then $\{p_K: K \text{ compact in }X \}$ is a family of seminorms that makes $C(X)$ into a LCS. Now for any space $X$ (not necessarily completely regular), $C(X)$ is a vector space. So, once we prove that family $\{p_K: K \text{ compact in }X \}$ of seminorms separates points on $C(X)$ then it would induce a locally convex topology on $C(X)$ . Now for $f\in C(X)\setminus \{0\}$ there is $x_0\in X$ so that $f(x_0)\ne 0$ . But then $p_{\{x_0\}}(f)=|f(x_0)| \ne 0$ . This implies that family of seminorms separates points on $C(X)$ ( we didn't use ""complete regularity"" !) and hence define a locally convex topology on $C(X)$ . My question: Isn't the case that  the space $C(X)$ for any topological space $X$ , not necessarily completely regular, satisfies the assertion of that example with the same family of seminorms? If so then is there any specific reason for restricting our attention to ""completely regular"" spaces $X$ ?? I mean, I know that ""completely regular"" spaces are ""nicer"" than general topological spaces, but can anyone mention some important property/result (related to this locally convex topology) on $C(X)$ that wouldn't hold without the ""complete regularity"" on $X$ . I want to realize the importance of assuming ""complete regularity"" condition in this case. Thanks","['topological-vector-spaces', 'vector-spaces', 'functional-analysis', 'locally-convex-spaces', 'general-topology']"
4141500,How to define an angular form with bounded support?,"In my smooth manifold course, I am asked to define a differential $1$ -form $\tau$ on $M = \mathbb{R}^{3} \setminus S^{1}$ with support bounded in $\mathbb{R}^3$ such that $\int_{\gamma} \tau$ can represent the signed crossing number of any closed curve $\gamma : S^{1} \to M$ about the disc $D^{2}$ . I believe that $\tau$ must be related to $\omega = \mathrm{d}(\arctan\frac{z}{\sqrt{x^{2}+y^{2}}-1})$ , but how can we modify $\omega$ to obtain a globally smooth $1$ -form with bounded support? It seems that $\int_{\gamma} \tau$ gives rise to linking numbers (see this post and this post ).","['algebraic-topology', 'smooth-manifolds', 'knot-theory', 'differential-forms', 'differential-geometry']"
4141517,Kernel and image of matrix,We have the matrix \begin{equation*}M=\begin{pmatrix} \cos (\alpha )-1& \sin (\alpha ) \\ \sin (\alpha) & -\cos(\alpha)-1\end{pmatrix}\end{equation*} I want to calculate the kernel and  the image of the matrix. For the kernel we have to solve the system $(s_{\alpha}-u_2)x=0_{\mathbb{R}^2}$ . Using Gauss elimination algorithmwe get \begin{equation*}\begin{pmatrix} \cos (\alpha )-1& \sin (\alpha ) \\ \sin (\alpha) & -\cos(\alpha)-1\end{pmatrix} \rightarrow \begin{pmatrix} \cos (\alpha )-1& \sin (\alpha ) \\ 0 & 0\end{pmatrix}\end{equation*} or not? Is the kernel $\left \{\lambda \begin{pmatrix}\cos (\alpha)-1\\ \sin (\alpha)\end{pmatrix}\right \}$ ? Can  we write this vector in respect of $\frac{\alpha}{2}$ instad of $\alpha$ ? The solution must be $\left \{\lambda \begin{pmatrix}\cos \left (\frac{\alpha}{2}\right )\\ \sin \left (\frac{\alpha}{2}\right )\end{pmatrix}\right \}$,"['matrices', 'trigonometry', 'linear-algebra', 'linear-transformations']"
4141568,Let $h$ be the function defined by $h(x)=\int_{0}^{x^2}e^{x+t}dt$ for all real numbers $x$. Then $h'(1)=\dots$,"This question appeared in the GRE MATH SUBJECT TEST (GR $0568$ ) - Question# $24$ : Let $h$ be the function defined by $h(x)=\int_{0}^{x^2}e^{x+t}dt$ for all real numbers $x$ . Then $h'(1)=$ (A) $e-1$ (B) $e^2$ (C) $e^2-e$ (D) $2e^2$ (E) $3e^2-e$ Now I have two approaches; FIRST APPROACH: (TRUE and I understand it very well): $h(x)=\int_{0}^{x^2}e^{x+t}dt=e^{x+t}|_{t=0}^{t=x^2}=e^{x+x^2}-e^x$ Differentiating, we get $h'(x)=(1+2x)e^{x+x^2}-e^x$ So $h'(1)=(1+2(1))e^{1+1^2}-e^1=3e^2-e$ Hence E is the correct answer. SECOND APPROACH: (FALSE and I do not know where is the mistake): Note that $$A(x)=\int_{B(x)}^{C(x)}a(t)dt \implies A'(x)=a(C(x))C'(x)-a(B(x))B'(x)$$ So, $h'(x)=(e^{x+x^2})(2x)$ Therefore $h'(1)=(e^{1+1^2})(2(1))=2e^2$ (which is the incorrect option D). Please clarify my mistake in the second approach. Your help would be appreciated. THANKS.","['integration', 'calculus', 'gre-exam', 'derivatives', 'exponential-function']"
4141610,How can I prove that set T is countably infinite? Countable and uncountable sets; rational numbers,"Let S be the collection of all non-vertical lines in the 2-dimensional plane $R^2$ passing through the origin. We can index the collection $S$ using $R$ as the index set, as follows. For each $i∈R$ , define $$L_i={\{(x,y) ∈ R^2 | y = ix}\}$$ Note that $i$ is simply the slope of the line $L_i$ . We can then write $$S={\{L_i | i∈R}\}$$ What is $⋃_{i∈R} L_i$ ? Explain why $S$ is uncountable. We shall call a line $L_i∈_S$ special if at least one point on the line $L_i$ other than the origin has rational numbers for both coordinates (i.e., there is at least one point $(x,y)≠(0,0)$ on $L_i$ such that $x∈Q$ and $y∈Q$ ). Let $T=\{L_i\in S\ |\ L_i\text{ is special}\}$ . Prove that $T$ is countably infinite. $R$ denotes set of real numbers and $Q$ denotes set of rational numbers. my answers: $⋃_{i∈R} L_i$ is the union of all the lines with slope $i \in R$ . $S$ is uncountable because the set $R$ of real numbers is uncountable since $S$ is indexed using $R$ as the index set. I am not sure how to prove this. What i have in mind is, since $T$ is a special set with a special line that has at least one point with rational numbers for both its coordinates, should I show that $T$ is countable because the set of rational numbers $Q$ is countable? Please help. Also are my answers to 1 and 2 correct? I somewhat feel they are but would love to hear from you all.","['elementary-set-theory', 'discrete-mathematics', 'rational-numbers']"
4141667,$\int_{0}^{1} \frac{\sin {xt}}{1+t} \ dt $ Lebesgue Integral,"could you please help me.
And let me notice how bad I am please. Problem: Calculate the derivative $F^\prime(x)$ of the function $F$ defined by the Lebesgue integral $$F(X) = \int_{0}^{1} \dfrac{\sin {xt}}{1+t} \ dt , x\in [0,1]$$ My attempt: Since the function $\dfrac{\sin {xt}}{1 + t}$ is a bounded function on $[0, 1]$ , then the integral (Riemann usual) $\int_{0}^{1} \dfrac{\sin {xt}}{1+t} \ dt $ converges, which implies that the integral of Lebesgue $\int_{0}^{1} \dfrac{\sin {xt}}{1 + t} \ dt $ exists, so $f$ is summable. Then using Theorem 9.6 which tells us that whatever the summable function $f$ in the segment $[a, b] \subset \mathbb{R}$ , in almost all points the equality $$\dfrac{\mathrm{d} }{\mathrm{d} x}\int_{a}^{x}f(t) \ dt = f(x)$$ Then the $F^\prime (x)$ is equal to. $$F^\prime(x) = \dfrac{\mathrm{d} }{\mathrm{d} x}\int_{0}^{1}\frac{\sin {xt}}{1+t} \ dt = \dfrac{\sin {x(1)}}{1+(1)} = \dfrac{\sin {x}}{2}$$ Many thanks","['lebesgue-measure', 'definite-integrals', 'lebesgue-integral', 'analysis', 'riemann-integration']"
4141694,Proving $\delta \notin C_c$,"Prove there is no $\delta \in C_c(\mathbb{R})$ such that for all $f \in C_c(\mathbb{R}) \ f= \delta \ast f$ . I think I have a solution to this problem, but am a bit unsure about it, as the author of this problem offers a more complicated solution.
So I'd be grateful if anyone could check my work. Consider $f_n(t)= 1-nt$ when $0 \leq t \leq \frac{1}{n}$ , $f_n(t)= 1+nt$ when $-\frac{1}{n} \leq t \leq 0$ and $f_n(t)=0$ otherwise. Clearly this defines a sequence of compactly supported continuous functions. This sequence is uniformly bounded by $1$ and for each $n \in \mathbb{N}$ $supp(f_n)= [-\frac{1}{n}, \frac{1}{n}]$ . Hence $1= f_n(0)= \int_{-\frac{1}{n}}^{\frac{1}{n}} \delta(-y) f_n(y) dy \leq \frac{2}{n} ||\delta||_{\infty}$ . So any such $\delta$ has to be unbounded, so can't belong to $C_c$ . ( In case it is of interest: The author considers the same sequence but with spike $(0,n)$ rather than spike $(0,1)$ .)","['integration', 'fourier-analysis', 'analysis', 'distribution-theory', 'solution-verification']"
4141763,Convergence of sequences $\sum_{k=1}^n \frac{1}{k}\sin\frac{n}{k}$ as $n\to\infty$.,"My question is to prove the limit $$\lim_{n\to\infty}\sum_{k=1}^n \frac{1}{k}\sin\frac{n}{k}$$ does not exist! $\textbf{Background:}$ Generally, we have the following result: If $f$ is monotone on $(0,1]$ , then $$\int_0^1 f(x) \,dx\ \mbox{exists} \iff \lim_{n\to\infty} \frac1{n}\sum_{k=1}^nf\left(\frac{k}{n}\right)\ \mbox{exists}.$$ And in both case, we have $$\int_0^1 f(x) \,dx=\lim_{n\to\infty} \frac1{n}\sum_{k=1}^nf\left(\frac{k}{n}\right).$$ If $f$ has no monotonicity, the above result may not be right.For example, let $$f(x)=\frac{1}{x}\sin\frac{1}{x},\ x\in(0,1].$$ It easy to see that $$\int_{0}^{1}\frac{1}{x}\sin\frac{1}{x}dx
=\int_{1}^{\infty}\frac{\sin u}{u}du=0.624713\cdots.$$ But the limit $$\lim_{n\to\infty}\frac{1}{n}\sum_{k=1}^n \frac{n}{k}\sin\frac{n}{k}=\lim_{n\to\infty}\sum_{k=1}^n \frac{1}{k}\sin\frac{n}{k}$$ doesn't seem to exist by numerical calculation using wolfram mathematica:For $n=1,2,\cdots,200$ Can someone provide a method to prove above limit does not exist.
Any help and hints will welcome!","['improper-integrals', 'sequences-and-series']"
4141764,Mean value theorem for sums,"I need to prove that if $f$ is continuous in $[x_1,x_2]$ and $a_1$ and $a_2$ are both greater than $0$ then there exists one $y \in [x_1,x_2]$ s.t. $$a_1\cdot f(x_1) + a_2\cdot f(x_2) = (a_1+a_2)f(y)$$ I have tried using the MVT but I got nowhere. Note that there are no derivatives or integrations in the equation.","['calculus', 'derivatives', 'real-analysis']"
4141798,"Considering the surface $f(x,y)=x^2y$. We know that a parametrization it can be $X(u,v)=(u,v,u^2v)$.","QUESTION: Considering the surface $f(x,y)=x^2y$ . We know that a parametrization it can be $X(u,v)=(u,v,u^2v)$ . Find the asymptotic lines in $S$ . MY ATTEMPT: Let $\alpha:I\subset \mathbb{R}\rightarrow S$ be a curve in this surface, such that $\alpha(t)=X(u(t), v(t))$ and $\alpha '(t)=u'X_u+v'X_v$ . Thus, $\alpha $ is asymptotic if, and only if, $$e(u')^2+2fu'v'+ g(v')^2=0. \qquad (*)$$ Where $e=\frac{2v}{\sqrt{1+u^4+4u^2v 2}}$ , $f=\frac{2u}{\sqrt{1+u^4+ 4u^2v^2}}$ and $g=0$ . Replacing this in $(*)$ we can find that $e(u')^2+2fu'v'+ g(v')^2=0\iff u'=0 \; \text{or} \; u'v+2uv'=0$ . In the first case $u=\text{constant}$ . However I'm struggling to resolve the ODE $u'v+2uv'=0$ . Would you help me with this?","['partial-differential-equations', 'asymptotics', 'ordinary-differential-equations', 'differential-geometry']"
4141849,Geodesics in a connected surface S parametrized by arc length with constant binormal vector implies that S are open of planes and spheres?,"Question: Geodesics in a connected surface S parametrized by arc length  with constant binormal vector implies that S are open of planes and spheres? My idea: I know that binormal vector is defined by $b=t\times n=\alpha '\times\frac{\alpha ''}{k}$ . On the other hand, it is true that if all geodesics in a connected surface are plane curves, then this surface is a subset of a plane or a sphere. I know how to prove this too. Thus, I'm trying to find a way to connect the question above with this result. However I'm not so sure if this is the best idea. I even do not know if the question above is true because I didn't find any counterexample. Would you help me with this?","['geodesic', 'geometry', 'differential-geometry']"
4141883,If the rat starts at room 2 what is the probability of eventually ending up in room 5?,I have a following doubt on a question of Markov chain. I have done the parts (a) to (d). I am facing problem with the last part. I am attaching what I have done so far.,"['matrices', 'calculus', 'markov-chains', 'probability']"
4141890,Why does $\nabla_{X}Y$ depend only on $X_{p}$? Lee's book on Riemannian geometry,"I am trying to understand the following theorem from Lee's book about Riemannian geometry. I had a look at several books but unfortunaletly I am still not quite sure if I get it. Question 1: Why does he assume w.l.o.g. that $X_{p}=0$ . I would say that the proof applied to $X(p)-\tilde{X}(p)=0$ gives the disered result, but why can't it be done ""directly"" as in the following excerpt. I would have done it this way too. Question 2: I had a look at Boothby's book and what I dont't understand is why he constructs a vector field that agrees with $X$ in a nhd. Is it just supposed to be a proof of existence in the sense that we can actually find such a vector field? Furthermore could it be that there are some typos? For example in the the equation above the last paragraph. I know it is quite a long question bit I would really appreciate some help. Many thanks in advance.","['connections', 'riemannian-geometry', 'differential-geometry']"
4141897,Caratheodory continuation theorem: existence of the sequence for the definition of the extended measure,"I was trying to understand the proof for the Caratheodory's continuation theorem: any measure on an algebra $R$ has a unique continuation to a measure on $\sigma(R)$ . The proof suggested an extension of a measure $\mu$ defined on $R$ as $\lambda(A) = \inf \left( \sum_{n \in \mathbb{N}} \mu(A_n)\right)$ defined on $P(\Omega)$ , which is the power set of $\Omega$ , the set of outcomes, and $A_n$ is a sequence in $R$ satisfying $A \subset (\cup A_n)$ . I failed to understand why such sequence of $A_n$ exists, because $A_n$ is supposed to be elements of $R$ while $P(\Omega)$ is the power set of $\Omega$ . For example, if $\Omega$ is the outcome of dice roll: $\Omega = {1,2,3,4,5,6}$ , and I take $R = \{ \emptyset, \{1, 3,5\}, \{2,4,6\}, \Omega \}$ , then $A = \{1,3\}$ is a valid subset of $P(\Omega)$ but $A$ cannot be constructed by taking unions of sets in $R$ . Maybe I have misunderstood something but it is unclear for me why most proofs work with power sets, not with e.g., $\sigma(R)$ . Grateful for your input.","['probability-theory', 'probability', 'real-analysis']"
4141936,Examples of bijective polynomials $\mathbb C^n\to\mathbb C^n$ that aren't linear.,"I'm trying to construct a polynomial automorphism $P:\mathbb C^n\to\mathbb C^n$ that isn't just a linear function like $P=(x,2y)$ . I know that such a mapping must have constant non-zero Jacobian determinant, so for $n=1$ linearity is a must, however for $n\ge2$ I don't see why we couldn't have something more interesting. I can construct some ""not quite linear"" maps like $(x,y+x^2)$ or $(x,y+z,x(y+z)+y)$ , but they are still ""essentially linear"" since we can more or less ignore the non-linear parts. (I can formalize this, but hopefully, it makes intuitive sense from the examples.) I have read some surveys on the Jacobian conjecture, and I don't think it rules out non-trivial bijective polynomial mappings even if it is true. Am I missing any obvious functions? Or is it unknown whether such functions exist?","['algebraic-geometry', 'ring-theory', 'abstract-algebra', 'commutative-algebra']"
4141953,Solving a Riccati equation - doesn't fit into any category I tried until now,"I have this ODE: $$p = xp' - x(p^2 + x^2)$$ after dividing by $x \neq 0$ we get $$ p' = \frac{p}{x} + p^2 + x^2 $$ Which I recognized as a Riccati equation, and also confirmed this on WolframAlpha. However, here's the problem. We always dealt with three subtypes of the Riccati equation: a) For any Riccati equation $y' = P(x)y^2 + Q(x)y + R(x)$ , if P(x), Q(x) and R(x) are constants, then it is a separable equation b) If $y' = Ay^2 + \frac{B}{x}y + \frac{C}{x^2}$ , A,B,C are constants, we let $z=yx, z=z(x)$ c) If a particular solution $y_1$ is known, we let $y(x) = y_1(x) + \frac{1}{z(x)}$ However, my equation does not fall into any of the three categories I mentioned and I don't know how to proceed. Any help would be appreciated!",['ordinary-differential-equations']
4142026,Second order non linear ODE - hard to solve integral makes me think I need a different substitution,"I have this here ODE: $$xy'' = y' + x((y')^2 + x^2)$$ Naturally, I'd try this substitution first: $$y' = p, p=p(x)$$ The equation then transforms into $$xp' = p+x(p^2+x^2)$$ Dividing it by $x$ , I get $$p' = \frac{p}{x} + p^2 + x^2$$ Which is a Riccati equation with the solution: $$p = x \cdot \tan{(\frac{x^2}{2}+C_1)}$$ The thing is, if I substitute back $y'=p$ , the integral on the right side is not an easy one to solve, and even if I do solve it with WolframAlpha the solutions are not the same as if I plug in the second-order equation directly. It makes me wonder if I should have tried another substitution/method. Any help will be appreciated!",['ordinary-differential-equations']
4142035,Geometry problem involving orthocenter and collinearity,"Let $X$ , $Y$ on line $BC$ from triangle $ABC$ such that $\angle XAY = 90^\circ$ . Suppose that $H$ is the orthocenter of $ABC$ . If $AX$ intersects $BH$ at $X'$ and $AY$ intersects $CH$ at $Y'$ , prove that intersection of circumcircle of $BXX'$ and circumcircle of $CYY'$ lay on $X'Y'$ I showed that $\angle BEX' + \angle CEY'= 90$ so showing $\angle BEC = 90^\circ$ would do the trick so we can do something like showing $BFCE$ cyclic or $BFGE$ cyclic. Am I going in the right direction or is there something else we need to do or some theorem we need to use? Please give any hint you can.","['contest-math', 'euclidean-geometry', 'geometry']"
4142050,Effects of variables' change on total change in a product function,"Prelude My topic is related to existing posts found here and here ; although, my questions are different. My post explains my objective and what has and has not worked for me. I have met my objective and provided my solution. My questions pertain to why the solution works in the hopes that I may apply my one-off solution here more readily to other instances. Background I am comparing two numbers that are products of multiple variables. My objective is to determine how much of the total change is attributable to each variable's change. As a simple example, consider: x1 = a1 * b1 = 10 * 10 = 100 
x2 = a2 * b2 = 11 * 10 = 110 How much of the total difference (110 - 100 = 10) is attributable to the change in a and b? My first approach was to use a binary (on/off) approach to determine what happens if each variables' change were the only change to occur. $$\Delta = \Delta a * b_1 + \Delta b * a_1$$ $$\Delta = (11 - 10) * 10 + (10 - 10) * 10$$ $$10 = 10 + 0$$ As shown, the change in ""a"" is responsible for 10 (100%) of the total change. However, as additional variables are added and/or change, this appears to stop working. Consider a more complicated example. Year A B C D Total (A * B * C * D) Y1 32 200 25 365 58,400,000 Y2 33 215 28 360 71,517,600 $\Delta$ 1 15 3 -5 13,117,600 If I use the previously described approach ( $\Delta = \Delta A * B_1 * C_1 * D_1 + ...$ ), the sum of the individual effects does not equal the total change. A B C D Total Change (A+B+C+D) 1,825,000 4,380,000 7,008,000 -800,000 12,413,000 As shown, if A were the only variable to change, it would increase the value by 1.8 million, and so on.  The sum total of isolated challenges in this method is approximately 12.4 million, which is less than the observed total of 13.1 million. My next attempt tried the reverse.  What would happen if each individual variable were the only variable not to change ( $\Delta = \Delta A * B_2 * C_2 * D_2 + ...$ )? A B C D Total Change (A+B+C+D) 2,167,200 4,989,600 7,662,600 -993,300 13,826,100 The sum total for this approach (approximately 13.8 million) is too great. The true answer exists somewhere between these two methods.  And through trial and error, I found a solution. Solution Let T be the total product for a given year, and $\Delta$ T be the total difference between T year 1 and T year 2 . Objective: Total change is equal to the change caused by each variable. $\Delta T = \Delta_A(T) + \Delta_B(T) + \Delta_C(T) + \Delta_D(T)$ Solution: $\Delta_A(T) = (A_2 - A_1) * B_1 * C_2 * D_1$ $\Delta_B(T) = (B_2 - B_1) * A_2 * C_2 * D_1$ $\Delta_C(T) = (C_2 - C_1) * A_1 * B_1 * D_1$ $\Delta_D(T) = (D_2 - D_1) * A_2 * B_2 * C_2$ Check: A B C D Total Change (A+B+C+D) 2,044,000 5,058,900 7,008,000 -993,300 13,117,600 As shown, the sum total of effects for the variables is equal to $\Delta$ T. Objective [presumably]  met. The Questions Notice in the solution that function differs for each variable. The effect of $\Delta$ A is $\Delta$ A * the year 1 value for B and D, but year 2 value for C. The effect of $\Delta$ B is $\Delta$ B * the year 1 value for D, but year 2 value for A and C. The effect of $\Delta$ C is $\Delta$ C * the year 1 value for A, B and D. The effect of $\Delta$ D is $\Delta$ D * the year 2 value for A, B and C. The functions are specific to the variable. Year 1 variables are applied to $\Delta$ C, and year 2 variables are applied to $\Delta$ D, these are not interchangeable functions. If year 2 variables are applied to $\Delta$ C, and year 1 variables are applied to $\Delta$ D, the sum total no longer equals the observed change ( $\Delta$ T). Q1: Why does this work? Why do we reference different years for different variables? Q2: Is there a way (other than trial and error) to determine the appropriate function (i.e., what would the function be for an added variable ""E""?) Q3: Does this solution actually isolate variables if they do not use a consistent approach? Is this really an accurate depiction of variables' effect on total change or just a coincidental / convenient distribution? Thanks, Andrew",['derivatives']
4142063,Prove that $f$ is a convex function if $f(x) \leq \int \limits_0^1 f(x + \alpha \cos(2 \pi y))dy $,"Let $f$ be a continuous $\mathbb{R}$ -valued function defined on $\mathbb{R}$ such that $$f(x) \leq \int \limits_0^1 f(x + \alpha \cos(2 \pi y))dy~~~~\forall x,\alpha \in \mathbb{R}$$ Prove that $f$ is a convex function. My attempt: $\sum \limits_{k=1}^n \cos\left( \frac{2 \pi k}{n} \right) =0$ , so $f(x) =
f \left(\sum \limits_{k=1}^n \left(x +\alpha \cos\left( \frac{2 \pi k}{n} \right)\right)\frac{1}{n} \right) $ $\int \limits_0^1 f(x + \alpha \cos(2 \pi y))dy = \sum \limits_{k=1}^n
\frac{1}{n} f\left(x + \alpha \cos\left( \frac{2 \pi k}{n} \right) \right) + o(1)$ And now the inequality in the condition is similar to Jensen's inequality,
but it is not a definition of a convex function. Also, $\int \limits_0^1 \cos(2 \pi y) dy = 0$ , so my question is a variation of this .","['integration', 'functions', 'convex-analysis', 'lebesgue-integral']"
4142071,Difference between Modules and Vector Spaces,"I have a curiosity question on a fundamental difference between vector spaces and general modules over rings. Some of the fundamental facts of linear algebra: (1) A finitely generated vector space has a basis. (2) Minimal generating (spanning) sets of a vector space are linearly independent and therefore form a basis. I recently took a course on modules. One basic example discussed: Let $R = K[x,y]$ , where $K$ is a field, and let $I = \langle x,y \rangle $ . We consider $I$ as a module over $R$ . $I$ is a finitely generated module, however it is not free (does not contain a basis). This is because the smallest generating set has size $2$ , and no matter what generating set you choose, you can write a non-trivial $R-$ linear combination of the elements of that set that equals $0$ . If $S = \{ f(x,y), g(x,y) \} $ so that $I = \langle S \rangle $ , then $g(x,y)f(x,y) + (-f(x,y))g(x,y) = 0 $ . A similar argument can be made for any finite generating set for $I$ . This example shows that those fundamental facts of vector spaces are not necessarily true for modules over general rings. My question is what is it about the scalars coming from a field that makes these facts true but not so when the scalars come from a general ring? I never got a chance to ask my professor during the class. I tried reading proofs from linear algebra texts but I cannot see where the underlying scalar FIELD makes the difference. Any clarification would be very helpful.","['finitely-generated', 'free-modules', 'linear-algebra', 'modules']"
4142106,Well-posedness of non-local equations. Deterministic. Singular. Reference request.,"Any references would be much appreciated. I'm looking for some well-posedness results for flow problems of the following type (note my issue is that I'm considering a singular non-local term). Let $\mathcal{P}(\mathbb{R}^d)$ be the space of probability measures on $\mathbb{R}^d$ . Let $\mu_0$ be some absolutely continuous (w.r.t Lebesgue) that is in $\mathcal{P}(\mathbb{R}^d)$ , lets $\textit{also}$ denote its density by $\mu_0$ . Consider the following flow $X:\mathbb{R}^+\times \mathbb{R}^d\to\mathbb{R}^d$ of the vector field $b$ \begin{equation}
\begin{cases}
&\partial_t X = b[\mu_0]\circ X,
\\
& X(0,\cdot)=\text{id}.
\end{cases}
\end{equation} where $b:\mathcal{P}(\mathbb{R}^d)\times \mathbb{R}^d \to \mathbb{R}^d$ is a non-local  vector field $b[\mu](x)=\int B(x-y)\mu(dy) $ , in the form of a convolution. At least formally the push-forward measure $\mu(t,\cdot)=\big(X(t,\cdot)\big)_{\#}\mu_0$ solves the continuity equation \begin{equation}
    \begin{cases}
    \partial_t \mu(t,\cdot) + \text{div} \big( \mu(t,\cdot) b[\mu_0]\big)=0
    \\
    \mu(t,\cdot)|_{t=0}=\mu_0.
    \end{cases}
\end{equation} I'm interested well-posedness of the above two equations and their relation via the push-forward. DiPerna-Lions theory (""Ordinary differential equations, transport theory and
Sobolev spaces"") has some stuff but im interested in the case of singular kernals $B$ , for example \begin{equation*}
B(r):= 
   C \begin{cases}
   {\|r\|^{-(d-2)}} & \text{for}~d>2
\\
 \log\|r\|  &\text{for}~d=2
\end{cases},
\end{equation*} for some $C\in \mathbb{R}$ .","['ordinary-differential-equations', 'singularity', 'real-analysis', 'partial-differential-equations', 'fluid-dynamics']"
4142148,How to calculate which primes have good reduction?,"I'm trying to find for which primes the elliptic curve over $\mathbb{Q}$ defined by $y^2z+yz^2=x^3-xz^2$ , for example, has good reduction. I think the way to go would be to find the minimal Weierstrass model but I have no idea about how to do it except asking PARI. Is there a simple algorithm (doable by hand) which works at least most of the time?","['arithmetic-geometry', 'algebraic-geometry', 'elliptic-curves']"
4142166,How densely can the :...: polyomino fill the plane?,"This is a follow-up to the question How good can a ""near-miss"" polyomino packing be? . Let $P$ be the heptomino shown below: I am interested in the packing density of $P$ on the square grid. (Unlike all polyominoes on $6$ or fewer cells, $P$ does not tile the plane, so by a compactness argument this density must be strictly less than $1$ .) The following packing, due to user nickgard here , attains a density of $14/15$ : On the other hand, $P$ cannot cover every cell on the following $65$ -cell region, as can be verified by a computer search: This means that the packing density of $P$ must be at most $64/65$ . ( Edit: To make this clearer, I've sketched out a more formal argument for why this is the case here .) How much can we tighten these bounds? There may be smaller regions that $P$ does not cover, but I do not think there will be any size- $15$ ones, so I expect that new techniques will be needed to get an exact answer here.","['polyomino', 'geometry', 'tiling', 'packing-problem']"
4142170,Connections on Hermitian subbundles,"I am following Kobayashi's book Differential geometry of complex vector bundles , which is proving a challenge to follow in detail, as many of the proofs leave up to the reader to fill in the gaps. Preliminaries My question is related to Section I.6 Subbundles and quotient bundles : here we have a rank $r$ holomorphic vector bundle $E\rightarrow M$ endowed with a Hermitian structure $h$ and a rank $p$ holomorphic subbundle $S \subset E$ . We can define the quotient bundle $Q = E/S$ fitting in the short exact sequence $$ 0 \rightarrow S \rightarrow E \rightarrow Q \rightarrow 0$$ and $Q$ being $C^\infty$ isomorphic to the orthogonal complemente $S^\perp$ . Consider the canonical Hermitian connection D (metric compatible and $D^{0,1} = \bar{\partial}$ ). We can decompose, taking sections with values in the subbundle $$D \xi = D_S \xi + A \xi~~~~~~~~\forall \xi\in\Omega^0(S)$$ $$D \eta = D_{S^\perp} \eta + B \xi~~~~~~~~\forall \eta\in\Omega^0(S^\perp)$$ and it is easy to see that $D_S$ is the Hermitian connection in $S$ , $A$ is a $Hom(S,S^\perp)$ -valued (1,0)-form, $B$ is a $Hom(S^\perp,S)$ -valued (0,1)-form, and furthermore, for $\xi \in\Omega^0(S),\eta\in\Omega^0(S^\perp)$ we have $$ h(A\xi,\eta) = - h(\xi,B\eta)$$ My problem I want to deduce the analogues of Gauss-Codazzi equations for Hermitian vector bundles, i.e. that the curvature act like $$
R = \left(\begin{array}{cc}
R_S - B\wedge B^* & D^{(1,0)}B\\
-D^{(0,1)}B^* & R_{S^\perp} - B^*\wedge B
\end{array}\right)
$$ Using frames for the $C^\infty$ decomposition $E = S\oplus S^\perp$ greatly helps. If we use the notational convention $1\leq a,b,c \leq p$ , $p+1\leq \lambda,\mu,\nu \leq r$ it is very simple to split the indices (summing over repeated indices everywhere) and see that $$DDe_a = (d\omega^b_a + \omega^b_c \wedge \omega^c_a + \omega ^b_\lambda \wedge \omega^\lambda_a)e_b
+ (d\omega^\lambda_a + \omega^\lambda_c \wedge \omega^c_a + \omega ^\lambda_\mu \wedge\omega^\mu_a)e_\lambda
 $$ $$
DDe_\lambda = (d\omega^a_\lambda + \omega^a_c \wedge \omega^c_\lambda + \omega ^a_\mu \wedge \omega^\mu_\lambda)e_a
+ (d\omega^\mu_\lambda + \omega^\mu_c \wedge \omega^c_\lambda + \omega ^\mu_\nu \wedge \omega^\nu_\lambda)e_\mu
 $$ Here one can easily identify the $S$ and $S^\perp$ curvatures: $$ R_Se_a = (d\omega^b_a + \omega^b_c \wedge \omega^c_a)e_b$$ $$ R_{S^\perp} e_\lambda = (d\omega^\mu_\lambda + \omega^\mu_c \wedge)e_\mu$$ and here the book states \begin{align*}
R e_a = (R_S + B\wedge A + DA)e_a\\
R e_\lambda = (R_{S^\perp} + A\wedge B + DB)e_\lambda
\end{align*} but I am certainly confused about how to calculate the action of either $A\wedge B$ , $DA$ or $DB$ since I don't know which version of the Leibnitz rule to implement, namely: $$ (A\wedge B) e_a = A^\lambda_b \wedge B^c _\mu e_a$$ or inverting the order of the wedges. Clarification : for the $A,B$ operators one can see that their matrix expression in the chosen split frame is $$Ae_a = \omega^\lambda_b e_\lambda~~ B e_\lambda = \omega^a_\lambda e_a$$","['complex-geometry', 'vector-bundles', 'differential-geometry']"
4142171,sinusoidal equations,"I was doing some maths & encountered that $$16\cos(8x) -2 = 6$$ and I looked for the answer and It's says "" If we isolate the cosine function, we can use the inverse cosine function to find one value of 8x (the one between 0 degree and 180 degree)."" and my question why exactly 0° to 180°? couldn't that be between 0° to 360°?",['trigonometry']
4142176,Why is CDF the only way to randomly select from samples?,"I am confused with the concept of cumulative distribution function (CDF). I see it helps in algorithms related to sampling of data. So for instance if we have a list of values, and we randomly want to pick up some elements with probability dependent on their value, CDF helps us with that in an efficient manner. What I am confused is why for this particular case an algorithm such as the following is not correct but we have to use CDF. Algorithm: Sum all elements of the array/stream of elements $w_n$ we want to sample and get the total sum. Keep a mapping of individual elements with their positions in the array/stream. This is required for duplicate entries Pick a random number in the range of $[0, total Sum)$ Scan linearly the array and check for each element if the random number selected is less than or equal to $\frac{w_i}{total Sum}*100$ . If yes then 4.a if there is only 1 occurence of the element $w_i$ in the list return $i$ 4.b if there are $k$ occurences of the element $w_i$ in the list select a random number in the range of $[0, k)$ and return the corresponding index in the original array $w$ It seems to me that this algorithm takes into account each element's ""weight"" in the array, it takes into account duplicates and is random. But I have verified via testing that it is wrong. What is the error in reasoning that makes it impossible to use this and CDF is the only correct approach? Update: To be clear the expectation is that for e.g. the input array $[5,15,20,30,30]$ then index $0$ is picked $5\%$ of the time, index $1$ is picked $15\%$ of the time, $2$ is picked $20\%$ of the time, $3$ is picked $30\%$ of the time and $4$ is picked $30\%$ of the time. CDF solves this, I am trying to understand why the algorithm I suggested does not if it essentially takes the percentages into account in the linear scan","['cumulative-distribution-functions', 'probability-distributions', 'probability-theory', 'probability']"
4142189,J. J. Rotman's proof that two free groups are isomorphic iff they have the same rank,"Rotman's ""An Introduction to the Theory of Groups"" contains the above result as Theorem 11.3. However, I failed to pickup a step of the proof. It goes something like this: ( $F \simeq G \implies \operatorname{rank}(F) = \operatorname{rank}(G)$ ) Let $X$ be a basis of $F$ and let $Y$ be a basis of $G$ . Since $F \simeq G$ , then $F/F' \simeq G/G'$ , where $F'$ denotes the commutator subgroup. By a previous result, $F/F'$ is a free abelian group of basis $\overline{X} = \{xF'\mid x \in X\}$ , and, by a previous result on free abelian groups, $|\overline{X}| = |\overline{Y}|$ . As $\mathbf{|X| = |\overline{X}|}$ , we have the result. The part in bold is where I couldn't understand. In principle, based on Rotman's definition of a free group with basis $X$ , I couldn't see a reason why, if $xF' = \tilde{x}F'$ , then $x = \tilde{x}$ . In fact, even if I could, at this point, use that $F$ is generated by $X$ , I don't think I'd be able to prove this tiny part of the result... Could anyone give me any hints as per how to procede? Thanks in advance! PS: Rotman's definition of a free group Def: A group $F$ is called free with basis $\mathbf{X}$ $\iff$ for every group $G$ and for every function $f: X \to G$ , there exists one, and only one, homomorphism $\phi: F \to G$ that extends $f$ .","['combinatorial-group-theory', 'group-theory', 'free-groups']"
4142204,Differential equation for ethanol concentration in nth tank,"I have the following problem to solve. At first, I write the differential equation for the 0th tank as: I go ahead and solve it and get: Now, for the second tank, the differential equation becomes: Solving it gives me that: However, according to a later statement in the same excercise: This means that I'm missing a factor of 1/2 for the equation of x1, which we can see if we substitute n = 1 in the given equation. Can anyone help me where it goes wrong in my differential equations? Thank you!","['derivatives', 'ordinary-differential-equations']"
4142212,Ordering on $R[\sqrt{n}]$ for an ordered ring $R$,"I'm interested in showing that if $R$ is an ordered ring (with ordering $\leq$ ), and $n \geq 0$ , then $R[\sqrt{n}]$ is also an ordered ring. In the reals, $0 \leq a_1 + a_n\sqrt n$ iff either (1) $0 \leq a_1$ and $na_n^2 \leq a_1^2$ , or (2) $0 \leq a_n$ and $a_1^2 \leq na_n^2$ .  So it seems natural to define the set $P$ of nonnegative elements of $R[\sqrt{n}]$ by the rule $a_1 + a_n\sqrt{n} \in P$ iff (1) or (2) above hold However, I'm having trouble proving that $x \in P$ and $y \in P$ implies $x + y \in P$ .  It seems like it should be elementary, but I'm finding myself running around in circles. I've been trying to split the proof into cases, depending on whether $x$ and $y$ satisfy rules (1) or (2).  The cases where they both satisfy (1) or both satisfy (2) are easy, but the casework is getting overwhelming when $x$ satisfies (1) and $y$ satisfies (2). I wonder if anyone can suggest something I'm missing, or maybe point me to a more general theorem that would help (although I'd like to avoid getting too esoteric since my eventual goal is to formulate the proof in coq). Thanks! Update: I’ve made progress but am still stuck.  Unless I’m mistaken, the only case I need is to show that $0 \leq (x_1 + x_n\sqrt{n}) + (y_1 + y_n\sqrt{n})$ when the following conditions all hold: $0 \leq x_1$ $0 \leq -x_n$ $nx_n^2 \leq x_1^2$ $0 \leq -y_1$ $0 \leq y_n$ $y_1^2 \leq ny_n^2$ $0 \leq x_1 + y_1$ $0 \leq -x_n - y_n$ Combining these assumptions gives $0 \leq y_1^2 \leq ny_n^2 \leq n x_n^2 \leq x_1^2$ . In this case I need to show that $n(x_n + y_n)^2 \leq (x_1 + y_1)^2$ . I’ve tried playing with fractions, derivatives, absolute values, and just can’t solve this case.  Any help would be appreciated.","['abstract-algebra', 'ordered-rings']"
4142214,"If the eigenfunctions of $T_{\phi}f:=f\circ\phi$ span $C(X)$, then $\overline{\{\phi^{n}:n\in\mathbb{Z}\}}^{\text{unif}}$ is compact","Let $X$ be a compact Hausdorff space. We endow $C(X,X)$ with the topology of uniform convergence . Let $\phi\colon X\to X$ be a homeomorphism and consider the linear isomorphism $T_{\phi}\colon C(X)\to C(X)$ defined by $T_{\phi}(f):=f\circ\phi$ . Suppose that the eigenfunctions of $T_{\phi}$ span $C(X)$ , that is, $$C(X)=\overline{\text{span}\bigcup_{\lambda\in\mathbb{C}}\ker(T-\lambda I)}.$$ I want to show that $\overline{\{\phi^{n}:n\in\mathbb{Z}\}}^{\text{unif}}$ is a compact group. I think there are versions of Arzela-Ascoli that may help, but I am not sure about this. Any suggestions would be greatly appreciated. EDIT: Apparently, according to this article , there may be a proof in theorem 1 of the following article: K. Sakai and S. Horinouchi: On compact transformation groups with discrete
spectrum. Sci. Rep. Kagoshima Univ., 33, 1-5 (1984). Unfortunately, I could not find this article online.","['arzela-ascoli', 'uniform-spaces', 'functional-analysis', 'general-topology', 'compactness']"
4142223,How to correctly use an integral to model the density?,"I have a density function $p_X(x)$ of an image $X \in \mathbb{R}^2$ over a set of points $x_i \in X$ . If two points $x_i$ and $x_j$ are within a fixed distance of $\epsilon$ from each other, I want to connect them with an edge. We can find the euclidean distance of every two values BUT this is too slow so i want to create a continuous model to speed it up. Firstly, define the density as $$\rho_0 = \frac{1}{N} \sum_{i=1}^N\delta(X - x_i).$$ Convolve it with a scaled Gaussian Kernel, to get $$\rho_X = \psi \circledast \rho_0 = \frac{1}{2N\epsilon^2 \pi} \sum_{i=1}^N e^{-\frac{(X-x_i)^2}{2\epsilon^2}}$$ My idea is then to integrate $p_X$ over a ball of size $\epsilon$ and centered at the point $x_i$ , i.e. the probability $x_j$ is a distance of $\epsilon$ from $x_i$ : $$ \int_{D(\epsilon,x_i)} p_X dX=  \frac{1}{2N\pi \epsilon^2} \int_{D(\epsilon,x_i)} \sum_{i=1}^N e^{-\frac{(x_1 - x_i)^2 + (x_2 - x_i)^2}{2\epsilon^2}} dx_1dx_2 \approx 0.39$$ If, $ \int_D p_X \ge C\epsilon^2$ , then we join an edge between $x_i$ and any $x_j$ in this ball, since the probability they are close is high enough. However, the result gives a constant so it would always be the same and hence useless to model. Should I integrate a different region and include $x_j$ somehow? But, say if I integrate each $x_i$ at a ball of size $x_j$ , I do NOT want to compute the distance between every $x_i$ and $x_j$ as it defeats the purpose of why I'm doing this!","['integration', 'statistics', 'mathematical-modeling', 'density-function']"
4142225,Proof with Double Integral with two variables,"I need to prove that the following statement is true: $$\iint_D e^{-x^2-y^2}dxdy=4\left(\int_0^Re^{-t^2}dt\right)^2$$ where $ D = \{|x| \leq R, |y| \leq R\} $ and $ 0 \leq R.$ I've tried exchanging the variables to polar coordinates: $$x = t\cos\theta, \quad y = t\sin\theta$$ so $$t^2 = x^2 +y^2.$$ but I was unable to find the new integration limits for $t$ and $\theta$ . Any help with advancing the proof would be greatly appreciated!","['multivariable-calculus', 'multiple-integral', 'definite-integrals']"
4142250,Which ODEs have solutions in terms of elementary functions?,I'm wondering what the most general results are on determining which ODEs have solutions which are expressible in terms of elementary functions and which do not. Is there some kind of ODE equivalent of the Risch algorithm?,"['elementary-functions', 'calculus', 'ordinary-differential-equations', 'real-analysis']"
4142367,Show the class number of $\mathbb{Q}[x]/(x^2 - x + 18)$ is $7$.,"Computer calculations show that the class group of $F = \mathbb{Q}[x]/(x^2 - x + 18) \simeq \mathbb{Q}(\sqrt{-71})$ is $C_F = \mathbb{Z}/7\mathbb{Z}$ .   Here is the table . The ideal class group is defined as the fractional ideals modulo the principal (fractional) ideals .  It measures the extent to which unique factorization fails.  It would be instructive to see the prime ideals which factor in this manner. In the article on fractional ideals there's an exact sequence: $$ 0 \to \mathcal{O}_K^\times \to F^\times \to I_F \to C_F \to 0 $$ so if I enter the values that I know so far: $$ 0 \to \Big[\mathbb{Z}[\sqrt{-71}]^\times \simeq \{ +1, -1\}^\times \Big] \to \mathbb{Q}(\sqrt{-71})^\times \to I_F \to \mathbb{Z}/7\mathbb{Z} \to 0 $$ From the abstract algebra point of view, I don't know how a cycle group emerges here. $\mathbb{Q}(\sqrt{-71})^\times$ is an infinitely generated abelian group under the operation (and also $\mathbb{Q}^\times$ ).  I'd really like to see how to use the exact sequence. The word ""ideal"" is used here differently: a fractional ideal of $\mathcal{O}_F$ is an $\mathcal{O}_F$ -module $I \subseteq F$ (of ""fractions"") with $rI \subseteq \mathcal{O}_F$ for some $r \in F$ . Another question about the ""ring theory"" involved here.  Using different example: Class group and localization in number fields Motivation behind the definition of ideal class group","['number-theory', 'arithmetic', 'algebraic-number-theory']"
4142417,"Modern, Clear Mathematics books with a similar style to Sheldon Axler's books [closed]","Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 3 years ago . The community reviewed whether to reopen this question 7 months ago and left it closed: Original close reason(s) were not resolved Improve this question This list ""is All You Need"" I graduated in Mathematics a couple of years ago but I know feel that I am forgetting quite a few things so I would like to go over most of the mathematical syllabus on my own. I would like to build a physical library ( meaning I want to buy books, not read them online ). I am looking to fill the areas shown below. Importantly, I would like to have books that are clear, fairly modern (I struggle to read 100-year-old manuscripts but if there is no alternative, I'll go for an old book) and allow me to cover the areas below without many gaps. Can you please suggest books following a similar style to Sheldon Axler 's ""Linear Algebra Done Right"" and ""Measure, Integration & Real Analysis""? By similar style I mean that they take the reader by hand and reinforce topics by using different colors, repetition of concepts and, importantly, building a lot of intuition with diagrams, figures or examples. They also shouldn't be huge 1000-page-long bricks. Here are the areas I am trying to cover. Striken over text means I have already bought them and happy with them. Texts in parenthesis are books I heard are good but possibly not quite similar to Sheldon Axler's style. Area Found Book Calculus No C - Spivak or VCLADF - Hubbard Linear Algebra Yes LADR - Axler Analysis Maybe A1- Tao or UA - Abbot Metric Spaces Maybe A2 - Tao or PMA - Rudin Differential Geometry No Functional Analysis Maybe FAFA - Sasane or IFAA - Kreyszig or FA - Stein Measure Theory Yes MIRA - Axler Probability Maybe PI - Grimmett or PT - Klenke or PM - Billingsley ODEs No DEDSLA - Hirsch Dynamical Systems Maybe NDC - Strogatz Stochastic Differential Equations No Optimization No Differential Calculus Maybe DCNS - Cartan or VCLADF - Hubbard Statistics Maybe NSLT - Vapnik or SLT - Vapnik","['self-learning', 'book-recommendation', 'reference-request', 'real-analysis', 'calculus']"
4142452,Need help determining the order of books for mathematics self study (names in description).,"I have recently started getting back into mathematics as a consequence of trying to get a better grasp on machine learning. I started studying from a machine learning book but found the language extremely convoluted and abstruse. Fortunately, the book referenced Gilbert Strang's book on linear algebra. Now, I wish to get back into mathematics, gain a better understanding and possibly a degree somewhere down the line. So, I am trying to relearn linear algebra and calculus (for now). I was trying to find some books for study and a lot of people recommended Micheal Spivak's Calculus which I managed to get a copy. Now, here's my dilemma. From what I can recollect about studying calculus in school is that there were a lot of topics (general equations for circles, parabolas, hyperbola; limits and continuity, trigonometry, arithmetic geometric harmonic progression, complex numbers etc),  that were taught before starting calculus. Spivak's book does have limits and continuity (about 50 pages) as a topic but I was skeptical about how much it could actually cover so I found Introduction to Real Analysis as a sort of precursor book to read before reading Spivk's Calculus.
The first 6 chapters and chapter 9 (infinite series) of this book are familiar to me based on previous coursework. Now my main question is should I first study limits and functions from this book before moving onto Spivak's calculus or will Spivak's calculus suffice ?
I am trying to rebuild a string foundation so I am looking for books with in-depth explanations (I like how Prof. Strang's book discusses concepts with the reader) I would also appreciate advice regarding purchase of a single pre-calculus book that covers all topics or different pre-calculus books for each separate topic. I think rigorously practicing each topic would be best. Thank you.","['book-recommendation', 'calculus', 'limits', 'algebra-precalculus', 'soft-question']"
4142461,How to use a character table,"This is quite an open-ended question. I have learned representation theory of finite groups and have an understanding of how to obtain the character table of a finite group. I see how the character table is useful from a representation-theoretical point of view as it can easily help me understand how an arbitrary representation can decompose as a product of irreducibles. At some point I even recall having learned how to extract information about the centre of the group using the character table.
However, it still seems very mysterious to me how people used character tables to understand large groups like the Monster. And what seems even more intriguing is how the character tables were obtained before the groups were constructed! Every book on representation theory that I have read seems to just concern itself with building the theory of representations of groups or algebras, but I have yet to find one that shows the full potential of these techniques. Here are a couple of concrete questions I am interested in having an answer to: (1) What would be a good reference to learn what the character table can tell me about the group, the limits of what it can tell me, and the techniques that people use to read interesting information from the table. The best would be if such a reference would include a good deal of exercises so that I can test my knowledge of the techniques. (2) How can one build a character table for a hypothetical group without having a construction for it?","['characters', 'representation-theory', 'reference-request', 'group-theory', 'soft-question']"
4142470,Prove $\int_{0}^{\infty} \frac{\left(\frac{\pi x}{2}-\log x\right)^3}{\left(x^2+1\right)^2 (\log^2x+\frac{\pi ^2}{4})} dx= \pi$,"@integralsbot at twitter posted interesting integral and complicated integrals that gives $\pi$ as a result. Some of the problems are really difficult to prove, such as $$\int_{0}^{\infty} \frac{\left(\frac{\pi x}{2}-\log x\right)^3}{\left(x^2+1\right)^2 (\log^2x+\frac{\pi ^2}{4})} dx =\pi\tag{1}\label{eq1}$$ I've tried to calculate this and it appeared very difficult. The plot of the integrand doesn't look very extraordinary. Using partial fraction decomposition, the integral can be transformed to the following form: $$\int_{0}^{\infty} \left( \frac{3 \pi  x}{2 \left(x^2+1\right)^2}-\frac{\log (x)}{\left(x^2+1\right)^2}+\frac{\pi^3 x^3-6 \pi ^2 x^2 \log (x)-3 \pi ^3 x+2 \pi ^2 \log (x)}{2 \left(x^2+1\right)^2 \left(4\log ^2(x)+\pi ^2\right)} \right)$$ The first two integrals can be more or less solved $$ \int_{0}^{\infty} \frac{3 \pi x}{2 \left(x^2+1\right)^2} = \frac{3 \pi}{4}, \>\>\>\>\>
\int_{0}^{\infty} -\frac{\log (x)}{\left(x^2+1\right)^2} = \frac{\pi}{4} $$ to yield: $$ \int_{0}^{\infty}  \frac{3 \pi  x}{2 \left(x^2+1\right)^2} - \frac{\log (x)}{\left(x^2+1\right)^2} \ dx= \pi \tag{2}\label{eq2} $$ This is interesting by itself, since the integrand displays interesting shape with two inflection points of the first derivative. I wouldn't expect it to be equal to $\pi$ (yet the algebra clearly shows that it is). What is even more interesting is $$ \int_{0}^{\infty} \frac{\pi^3 x^3-6 \pi ^2 x^2 \log (x)-3 \pi ^3 x+2 \pi ^2 \log (x)}{2 \left(x^2+1\right)^2 \left(4\log ^2(x)+\pi ^2\right)} = 0 \tag{3}\label{eq3}$$ which follows from \eqref{eq1} and \eqref{eq2}. This is correct (I've checked numerically with relatively high precision of ~100 decimals). It seems very hard to prove though. The plot of the integrand doesn't appear to suggest any trivial solution: An  obvious way to transform integral \eqref{eq3} is to expand the numerator: $$ 
\int_{0}^{\infty} \left( -\frac{3 \pi ^2 x^2 \log (x)}{\left(x^2+1\right)^2 \left(4 \log ^2(x)+\pi ^2\right)}-\frac{3
   \pi ^3 x}{2 \left(x^2+1\right)^2 \left(4 \log ^2(x)+\pi ^2\right)}+\frac{\pi ^2 \log
   (x)}{\left(x^2+1\right)^2 \left(4 \log ^2(x)+\pi ^2\right)}+\frac{\pi ^3 x^3}{2
   \left(x^2+1\right)^2 \left(4 \log ^2(x)+\pi ^2\right)} \right), $$ But the resulting integrals are also difficult. (I've tried to solve the second one, since it seems to have the simplest numerator, but didn't managed to get any result). Neither their numerical values (-1.93789..., 3.229820..., -0.322982..., -0.968946...) nor the plots indicate any obvious cancellations. Maybe there is some indirect way to show the integral \eqref{eq3} vanishes without solving it at all. I don't know where \eqref{eq1} comes from but it seems to be true and interesting. I believe some solution of this integral exists. I post it as an challenge/puzzle. Maybe someone knows it, sees clever substitution, or provides any insight into. So, the question is: how to prove either \eqref{eq1} or \eqref{eq3}?","['integration', 'calculus', 'definite-integrals']"
4142472,Looking for: $\lim_{n \to \infty}\frac{n!}{B_n}\sum_{i=0}^{n}\frac{B_{n-i}B_{i}}{(n-i)!i!}x^{1-i}=F(x)$,"Let $n=2k,k=1,2,3,,$ Proposed: $$\lim_{n \to \infty}\frac{n!}{B_n}\sum_{i=0}^{n}\frac{B_{n-i}B_{i}}{(n-i)!i!}x^{1-i}=F(x)\tag1$$ Where $B_n$ is Bernoulli numbers $\phi=\frac{1+\sqrt{5}}{2}$ I am looking for $F(x)$ , I was able to evaluate for some values of $F(x)$ , such as $$F(3)=\frac{\pi}{\sqrt{3}}$$ $$F(4)=\pi$$ $$F(5)=\frac{\pi\phi^2}{\sqrt{\phi^2+1}}$$ $$F(6)=\pi\sqrt{3}$$ $$F(8)=\pi(1+\sqrt{2})$$ $$F(10)=\pi\sqrt{\phi^3\sqrt{5}}$$ $$F(12)=\pi(2+\sqrt{3})$$","['limits', 'sequences-and-series']"
4142487,Why the mapping $1/\bar{z}$ look like the field lines of an electric dipole?,"While I was studying Mobius Transformation in  complex analysis, the complex function $\frac{1}{\bar{z}}$ caught my attention. suppose there are $n$ lines equally spaced all intersecting at $(1,0)$ as shown in red. If I apply the complex function then why does it resemble the field lines of a dipole(as shown in blue)? I know the lines are reflected by the circle centered at $(0,0)$ and having a radius of $1$ . The images of lines are circles passing through the center.
So far i have tried deriving the field line equation of a dipole but got no success. Here is my work: Dipoles are situated at $(1,0)$ and $(0,0)$ . The force acting on a unit charge at a point $(h,k)$ is equal to $\frac{1-h}{((h-1)^2+k^2)^{3/2}} + \frac{h}{((h)^2+k^2)^{3/2}} \hat{i} + \frac{-k}{((h-1)^2+k^2)^{3/2}} + \frac{k}{((h)^2+k^2)^{3/2}}\hat{j}$ . I don't know how to proceed from here. My idea is that if the field equation turns out to be a that of a circle then i will be sure. Also, why does it resemble the shape of the dipole in the first place? How can I get a feel for it. I can't see any connection between the two at all.","['complex-analysis', 'vector-fields', 'graphing-functions']"
4142501,How to find Rate and Order of Convergence of Fixed Point Method,"Given the function $f(x) = (e^x - 1)^2$ , we can use a fixed-point iteration to approximate the root. $$x_{n+1} = x_n - \frac{(e^{x_n} - 1)^2}{2e^{x_n}(e^{x_n}-1)}$$ This gives the following iterations after an initial guess $x_0 = 1$ : $$x_1 = 0.6839$$ $$x_2 = 0.4363$$ $$x_3 = 0.2595$$ $$x_4=0.1452$$ And so on. The error $E$ for each iteration is just the value of the iteration itself, given that the exact solution is $0$ . My question is: How does one find both the rate and order of convergence, given these iterations? Is there a specific formula or does one try to find a pattern from the ratio of consecutive errors? Then, can you prove these claims using Taylor series about the root? Any explanations would be brilliant.","['numerical-methods', 'functions', 'roots', 'approximation']"
4142518,Haar measure of the orthogonal group and Lie algebra,"I am looking to find the expression of the Haar measure of the $SO(3)$ group as a function of the Lie algebra basis $$
R(x,y,z) = \text{exp}\left( x L_x + yL_y + zL_z \right)
$$ where $L_x, L_y, L_z$ is the usual basis of antisymmetric matrices. In other words, what is the function $f(x,y,z)$ such that $d\mu(R) = f(x,y,z)dxdydz$ ?","['measure-theory', 'haar-measure', 'group-theory', 'probability', 'differential-geometry']"
4142535,"Proof verification: if $\int_a^b \sqrt{f(x)+g(x)}\,dx=0$, $f$ and $g$ are both non-negative, and $f$ is continuous, then $f\equiv 0$.","As a math-for-fun exercise, and also to supply my problem-solving toolbox with new inequalities, I challenged myself to attack this problem: If $\int_a^b \sqrt{f(x)+g(x)}\,dx=0$ , $f$ and $g$ are both non-negative on $[a,b]$ , and $f$ is continuous on $[a,b]$ , is $f$ identically $0$ on $[a,b]$ ? I think I've produced an argument that proves the answer is yes. Here it is: Suppose, for the sake of finding a contradiction, that $\int_a^b \sqrt{f(x)+g(x)}\,dx=0$ , $f$ and $g$ are both non-negative on $[a,b]$ , and $f$ is continuous on $[a,b]$ , but $f$ is not identically $0$ . Then for some $x_0\in[a,b]$ , we have $f(x_0)\neq 0$ . Since $f$ is non-negative, this reduces to $f(x_0)>0$ . Clearly either $x_0\in(a,b)$ , $x_0=a$ , or $x_0=b$ . If $x_0\in(a,b)$ , then the continuity of $f$ implies that for every $\varepsilon >0$ , there is a $\delta>0$ such that for every $x\in[a,b]$ , $x\in[x_0-\delta,x_0+\delta]$ implies $|f(x)-f(x_0)|<\varepsilon$ . In particular, this is true for $f(x_0)$ , since $f(x_0)>0$ . Thus, for some $\delta>0$ , $$|f(x)-f(x_0)|<f(x_0)\text{ for every }x\in[x_0-\delta,x_0+\delta]$$ $$\iff 0<f(x)<2f(x_0)\text{ for every }x\in[x_0-\delta,x_0+\delta]$$ This shows that $f$ is strictly positive on $[x_0-\delta,x_0+\delta]$ . Since $g$ is non-negative, we have that $g(x)\geq 0$ on $[a,b]$ , so $$f(x)+g(x)\geq f(x)>0\text{ for every }x\in[x_0-\delta,x_0+\delta]$$ $$\implies\sqrt{f(x)+g(x)}\geq\sqrt{f(x)}>0\text{ for every }x\in[x_0-\delta,x_0+\delta]$$ $$\implies\int_{x_0-\delta}^{x_0+\delta}\sqrt{f(x)+g(x)}\text{ }dx>0$$ Noting that $\int_{a}^{x_0-\delta}\sqrt{f(x)+g(x)}\text{ }dx\geq 0$ and $\int_{x_0+\delta}^{b}\sqrt{f(x)+g(x)}\text{ }dx\geq 0$ , we deduce that their sum is at least zero. This gives the contradiction \begin{align*}
\color{blue}{0} &= \int_{a}^{b}\sqrt{f(x)+g(x)}\text{ }dx\\
&= \int_{a}^{x_0-\delta}\sqrt{f(x)+g(x)}\text{ }dx+\int_{x_0-\delta}^{x_0+\delta}\sqrt{f(x)+g(x)}\text{ }dx+\int_{x_0+\delta}^{b}\sqrt{f(x)+g(x)}\text{ }dx\\
&\color{red}{>} \int_{a}^{x_0-\delta}\sqrt{f(x)+g(x)}\text{ }dx+\int_{x_0+\delta}^{b}\sqrt{f(x)+g(x)}\text{ }dx\\
&\geq \color{green}{0}
\end{align*} If $x_0=a$ or $x_0=b$ , a similar argument applies, the only difference being that we use $[x_0,x_0+\delta]$ and $[x_0-\delta,x_0]$ for $x_0=a$ and $x_0=b$ , respectively. We conclude that the stated assumptions necessitate $f$ being identically $0$ on $[a,b]$ . $\blacksquare$ I greatly appreciate any and all feedback.","['integration', 'calculus', 'solution-verification']"
4142572,Finite Abelian subgroups of $Aut(\mathbb{P}_{\mathbb{C}}^2)$,"I'm reading an article https://webusers.imj-prg.fr/~julie.deserti/biblio/Blanc_linearisationoffiniteabeliansubgroupsoftheCremonagroupoftheplane.pdf and I have problems with understanding the proof of Proposition 2.2. One of the statements of the proof is that (here we denote a morphism $[x:y:z]\to [ax:by:cz]$ by $[a:b:c]$ ): ""A simple calculation shows that every finite abelian subgroup of $Aut(\mathbb{P}_{\mathbb{C}}^2)=PGL(3,\mathbb{C})$ is either diagonalizable or conjugate to the group $V_9$ (here $V_9\cong \mathbb{Z}/3\mathbb{Z}\times \mathbb{Z}/3\mathbb{Z}$ and is generated by $[1:\xi_3:\xi_3^2]$ and $[x:y:z]\to [y:z:x]$ where $\xi_3=e^{2i\pi/3}$ )"" I tried my best to prove it with the direct calculation, but I'm afraid that I'm doing something wrong. I will appreciate any help! Edit: (details of my attempt): First, I took a matrix $g\in PGL(3,\mathbb{C})$ and assumed that it is diagnosable. We can assume $a_{11}$ so it will be of the form $$g=\begin{pmatrix}
1 &0 & 0\\
0 & \alpha &0 \\
0 & 0 & \beta
\end{pmatrix} $$ Then since the group is finite (so for any $g\in G$ we have that $g^{m+1}=g$ fo some $g$ ) we get that $\alpha=\xi_m^a$ , $\beta=\xi_m^b$ (where $\xi_{m}=e^{2\pi i/m}$ ). Then if $a\ne b$ the we can take any other element $h\in G$ of the form: $$h=\begin{pmatrix}
1 & h_{12} & h_{13}\\
h_{21} & h_{22} & h_{23} \\
h_{31} & h_{32} & h_{33}
\end{pmatrix} $$ and from the fact that $gh=hg$ (looking at the explicit expansions) we obtain that $h_{12}=h_{13}=h_{23}=h_{21}=h_{31}=h_{32}=0$ so the matrix is diagonisable: $$\begin{pmatrix}
1 & 0 & 0\\
0 & h_{22} & 0 \\
0 & 0 & h_{33}
\end{pmatrix} $$ and similarly to the above since the group is finite  we get that $h_{22}=\xi_n^c$ , $h_{33}=\xi_n^d$ (where $\xi_{n}=e^{2\pi i/n}$ ). In case $a=b$ (or $a=0$ or $b=0$ it seems that they lead to the similar cases) other elements $h$ are of the form: $$\begin{pmatrix}
1 & 0 & 0\\
0 & A & B \\
0 & C & D
\end{pmatrix} $$ and I couldn't get more information for this case. Moreover, I do not see at all how to get $V_9$ (and how to get ""not diagonalizable element"" $[x:y:z]\to [y:z:x]$ ) from the direct calculations + I cannot just assume that any element I take will be diagonalizable. I also tried multiplying 3x3 matrixes directly but got lost in these calculations. I really tried, but I failed and it seems that my way does not work. I will appreciate any help!","['algebraic-geometry', 'birational-geometry']"
4142583,Expectation and Variance of Branching Process,"Let $X_n, n \in \mathbb Z_+$ , be the branching process generated by $\xi$ , $\mathbb E \xi = a$ $\mathbb Var \xi = \sigma^2$ . Find the $E X_{n} $ and $Var X_n$ My Attempt: By the Galton-Walton process, $$X_n = \sum_{i=1}^{X_n -1} \xi_{i}^{n}$$ The Expectation is defined as: $$ EX_n = E(E \left( X_n|X_{n-1} \right) )$$ $$E \left( X_n|X_{n-1} =k \right) = E \left( \sum_{i=1}^{X_n -1} \xi_{i}^{n}|X_{n-1} =k\right)=ka $$ $$\implies EX_n = E(E \left( X_n|X_{n-1} \right) ) = a EX_{n-1}$$ Since, $EX_1 =E\xi =a \implies EX_n =a^n$ Please I am stuck here. Is my approach correct? Also any help or hint on how to find the Variances is appreciated. Thanks!","['stochastic-processes', 'conditional-expectation', 'probability']"
4142610,"Why is it that $1+(1+2+3+4+5+6+\ldots+n)$, basically a triangular number plus $1$, doesn't divide by $3$ or $5$?","As a self learner I am currently learning about triangular numbers, for which the formula is: $$T(n)=\frac{n(n+1)}{2}$$ While playing with my calculator, I added 1 to each resulted number, and I noticed that none of the results divides by $3$ or $5$ I am assuming that I am correct about this observation, other wise please let me know. So I have multiplied both sides of the original formula by $2$ , and now I have: $2(T(n))=n(n+1) = n^2+n$ Now my question still remains still wide open: why is it that $(n(n+1)+1) \bmod 3 \neq 0$ and $(n(n+1)+1) \bmod 5 \neq 0$ ? Or you can see it as  why $(n^2+n+1) \bmod 3 \neq 0$ and $(n^2+n+1) \bmod 5 \neq 0$ ? Or you can see it as why $(1+2+3+4+5+6+\ldots+n)+1$ , Basically why a triangular number plus $1$ does not dividing by $3$ nor $5$ ? I have tried Google and also tried searching over here, but either I don't know what I am searching for or I simply can't find an answer. I am trying to pull my head for a possible answer, but I just don't have a clue where to begin with. Any answers or hints are appreciated. Also if this is a duplicated, I honestly couldn't find it, so please just close and refer me to it.","['proof-explanation', 'algebra-precalculus', 'triangular-numbers', 'modular-arithmetic']"
4142617,Filling in details for calculation of the limit $\lim _{x\rightarrow \infty } x^{2}\left(\sqrt[7]{\frac{x^{3} +x}{1+x^{3}}} -\cos\frac{1}{x}\right)$,"I want to evaluate the following limit using asymptotics \begin{equation}
\lim _{x\rightarrow \infty } x^{2}\left(\sqrt[7]{\frac{x^{3} +x}{1+x^{3}}} -\cos\frac{1}{x}\right) \tag{1}
\end{equation} This is an example problem and this was the solution: \begin{gather}
\frac{x^{3} +x}{1+x^{3}} =\left( 1+\frac{1}{x^{2}}\right)\left( 1+\frac{1}{x^{3}}\right)^{-1} =\left( 1+\frac{1}{x^{2}}\right)\left( 1-\frac{1}{x^{3}} +\mathcal{O}\left(\frac{1}{x^{6}}\right)\right) \tag{2}\\
=1+\frac{1}{x^{2}} +\mathcal{O}\left(\frac{1}{x^{3}}\right) \tag{3}
\end{gather} And then \begin{gather}
\sqrt[7]{\frac{x^{3} +x}{1+x^{3}}} =\left( 1+\frac{1}{x^{2}} +\mathcal{O}\left(\frac{1}{x^{3}}\right)\right)^{\frac{1}{7}} \tag{4}\\
=1+\frac{1}{7} .\frac{1}{x^{2}} +\mathcal{O}\left(\frac{1}{x^{3}}\right) \tag{5}
\end{gather} \begin{equation}
\cos\frac{1}{x} =1-\frac{1}{2x^{2}} +\mathcal{O}\left(\frac{1}{x^{4}}\right) \tag{6}
\end{equation} From above, we obtain: \begin{equation}
\left(\sqrt[7]{\frac{x^{3} +x}{1+x^{3}}} -\cos\frac{1}{x}\right) =\frac{9}{14x^{2}} +\mathcal{O}\left(\frac{1}{x^{3}}\right) \tag{7}
\end{equation} Hence the required limit is: \begin{equation}
\lim _{x\rightarrow \infty }\left(\frac{9}{14x^{2}} +\mathcal{O}\left(\frac{1}{x^{3}}\right)\right) =\frac{9}{14} \tag{8}
\end{equation} I tried to fill in the details for the steps involved in the above steps. I supplied the details for $\displaystyle ( 3)$ as below: \begin{gather}
\left( 1+\frac{1}{x^{2}}\right)\left( 1-\frac{1}{x^{3}} +\mathcal{O}\left(\frac{1}{x^{6}}\right)\right) =1+\frac{1}{x^{2}} +\frac{1}{x^{3}}\left( -1-\frac{1}{x^{2}} +\left( x^{3} +x\right)\mathcal{O}\left(\frac{1}{x^{6}}\right)\right) \tag{9}\\
=1+\frac{1}{x^{2}} +\frac{1}{x^{3}}\left( -1-\frac{1}{x^{2}} +\frac{\left( x^{3} +x\right)}{x^{6}}\mathcal{O}( 1)\right) =1+\frac{1}{x^{2}} +\mathcal{O}\left(\frac{1}{x^{3}}\right) \tag{10}
\end{gather} where in (9) and (10), I have used the standard result: $\displaystyle \frac{\mathcal{O}( f( x))}{g( x)} =\mathcal{O}\left(\frac{f( x)}{g( x)}\right)$ , if $\displaystyle g( x) \neq 0$ . I tried to get (5) from (4) but failed. Then I supplied details for $\displaystyle ( 7)$ as below: \begin{gather*}
\left(\sqrt[7]{\frac{x^{3} +x}{1+x^{3}}} -\cos\frac{1}{x}\right) =\frac{9}{14x^{2}} +\mathcal{O}\left(\frac{1}{x^{3}}\right) -\mathcal{O}\left(\frac{1}{x^{4}}\right) =\frac{9}{14x^{2}} +\frac{1}{x^{3}}\left(\mathcal{O}( 1) -\mathcal{O}\left(\frac{1}{x}\right)\right)\\
=\frac{9}{14x^{2}} +\mathcal{O}\left(\frac{1}{x^{3}}\right)\\
\Longrightarrow \lim _{x\rightarrow \infty } x^{2}\left(\sqrt[7]{\frac{x^{3} +x}{1+x^{3}}} -\cos\frac{1}{x}\right) =\lim _{x\rightarrow \infty }\left(\frac{9}{14} +\mathcal{O}\left(\frac{1}{x}\right)\right) =\frac{9}{14}
\end{gather*} Any help in getting (5) from (4) is much appreciated. Thanks. \begin{equation*}
\end{equation*} \begin{equation*}
\end{equation*}","['limits', 'asymptotics', 'real-analysis']"
4142693,differential equation $y' = \frac{a}{(b+xy)^2}$,"Solve the differential equation $$y' = \frac{a}{(b+xy)^2}$$ My attempt: Substitution $$y = \frac{z}{x} \implies y' =  \frac{xz' - z}{x^2} \\ 
\frac{xz'-z}{x^2} = \frac{a}{(b+z)^2}$$ But this doesn't seem to help much. Wolfram Alpha says $$-\frac{\sqrt a \tanh^{-1}\left(\frac{\sqrt b y}{\sqrt a}\right)}{b^{3/2}} + \frac{\sqrt a \tanh^{-1}\left(\frac{ b y(b+y)-ax}{\sqrt a b^{3/2}}\right)}{b^{3/2}} + \frac{y}{b} = c_1$$",['ordinary-differential-equations']
4142700,"Show that $f(x)$ is a constant function if $\lim\limits_{h\to 0}\frac{1}{h^3}\int_{-h}^{h}f(x+t)\cdot t\,dt=0$ for all $x$","Let $f(x)$ be a continuous function on $\mathbb{R}$ , such that for any real number $x$ we have: $$\lim_{h\to 0}\dfrac{1}{h^3}\int_{-h}^{h}f(x+t)\cdot t\,dt=0.$$ Show that $f(x)$ is a constant function. Maybe we can use the following lemma? Lemma . If $g$ is a continuous function, then $$\lim_{h\to0}\frac{1}{2\,h}\int_{x-h}^{x+h}g(s)\,ds=g(x).$$ Proof . We may assume $h>0$ . $$
\left|g(x)-\frac{1}{2\,h}\int_{x-h}^{x+h}g(s)\,ds\right|=\frac{1}{2\,h}\left|\int_{x-h}^{x+h}(g(x)-g(s))\,ds\right|\le\frac{1}{2\,h}\int_{x-h}^{x+h}\left|g(x)-g(s)\right|\,ds.$$ Use that $g$ is continuous at $x$ to show that the last expression converges to $0$ as $h\to0$ .","['integration', 'limits', 'continuity', 'real-analysis']"
4142703,Integration on a subset,"Definition: Let $(X, \mathcal{A}, μ)$ be a measure space.
Let $f:X\rightarrow \mathbb{R}$ be a measurable function. Let $E\in \mathcal{A}$ . Then $$\int_E fdμ:=\int_X (f\chi_E)dμ.$$ Let $(X, \mathcal{A}, μ)$ be a measure space.
Let $f:X\rightarrow \mathbb{R}$ be a measurable function. Let $E\in \mathcal{A}$ . Assume that $\exists M>0$ s.t $$|f(x)|\le M,  \forall x\in E.$$ Then prove that $$|\int_E f dμ| \le Mμ(E).$$ Please help me in this proof. Definition is given above the proof of the statement. My try: $$|\int_E f dμ|=|\int_X (f \chi_E) dμ|$$ $$ \le \int_X |(f \chi_E)| dμ$$ $$= \int_X |f| |\chi_E| dμ$$ $$ \le  \int_X  M |\chi_E| dμ $$ $$= M \int_X |\chi_E| dμ$$ $$= M μ(E) $$","['integration', 'measure-theory', 'lebesgue-measure', 'lebesgue-integral', 'measurable-functions']"
4142705,Determining if a given function is a closed loop,"Is there any method/way to determine if a given maths function in $x$ and $y$ , when plotted with the help of coordinate-axes, forms a closed-loop ? In other words, does it, all by itself, enclose some area? For example, $x^2+y^2=5$ forms a closed loop (a circle). But $y = x^2$ does not form a closed loop (as it is a parabola, and is open from above).","['graphing-functions', 'area', 'geometry']"
