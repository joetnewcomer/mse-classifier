question_id,title,body,tags
4860522,Can we think of matrices as functions of sorts?,"Can we think of matrices as surjective functions where; $i,j$ (the indices) represent the inputs and $z$ (the element at that particular position)? Further, ( $i,j,z$ ) as an ordered triplet... The reason why I ask, is because, then that could possibly allow us to think of matrix multiplication as a composition of sorts, right? I think that this approach works, but I'm new to the matrices, so I wanted to check here. I've heard of linear maps, but I don't think that they're what I'm aiming for. Are they?","['matrices', 'soft-question', 'linear-algebra']"
4860564,Defining a multivariable function to make it continuous at a point,"I am working with the function $f(x,y) = \frac{\sin(x)\sin^3(y)}{1-\cos(x^2+y^2)}$ and am asked to make it continuous at $(0,0)$ . My approach was to take the limit along the line $x = 0$ and I got the limit to be $0$ and concluded that the function must be defined as $0$ at $(0,0)$ to make it continuous. The question that I have now is whether it is right to do so or if there is any other curve along which the limit is not zero and in general what is the best way to work out such a problem where I need to find the continuity for a function with several variables.","['limits', 'multivariable-calculus', 'real-analysis']"
4860591,"Confusion on ""almost everywhere defined"" function in $L^1$ space.","The following are excerpt from folland This proposition shows that for the purposes of integration it makes no difference if we alter functions on null sets. Indeed, one can integrate functions $f$ that are only defined on a measurable set $E$ whose complement is null simply by defining $f$ to be zero (or anything else) on $E^c$ . In this fashion we can treat $\bar{\mathbb{R}}$ -valued functions that are finite a.e. as real-valued functions for the purposes of integration.
With this in mind, we shall find it more convenient to redefine $L^1(\mu)$ to be the set of equivalence classes of a.e.-defined integrable functions on $X$ , where $f$ and $g$ are considered equivalent iff $f = g$ a.e . This new $L^1(\mu)$ is still a complex vector space (under pointwise a.e. addition and scalar multiplication). Although we shall henceforth view $L^1(\mu)$ as a space of equivalence classes, we shall still employ the notation "" $f \in L^1(\mu)$ "" to mean that $f$ is an a.e.-defined integrable function. This minor abuse of notation is commonly accepted and rarely causes any confusion. I have the following questions: What does it mean to be a.e. integrable? In other words, how do we know whether a.e defined functions are measurable and integrable? It is just whether the extension of this function with $0$ s is integrable? Also Folland first said that ""one can integrate functions defined on a measurable set $E$ whose complement is null by..."". Functions defined a.e is not necessarily defined on a measurable set if the measure is not complete. If two functions do not have the same domain, what does it mean by $f=g$ a.e? Is it whether the extension of $f$ and $g$ with $0$ s are equal almost everywhere? Precisely how do we treat $\bar{\mathbb{R}}$ functions that are finite a.e as real functions? Do we choose an arbitrary null set that contains all the infinities of the function and make them to be $0$ ? And since alter functions on null set does not makes no difference, it doesn't matter which null set we choose?","['integration', 'measure-theory', 'lebesgue-integral', 'real-analysis', 'almost-everywhere']"
4860643,"How to calculate $\int _0^1 \int _0^1\left(\frac{1}{1-xy} \ln (1-x)\ln (1-y)\right) \,dxdy$","Let us calculate the sum $$
\displaystyle{\sum_{n=1}^{+\infty}\left(\frac{H_{n}}{n}\right)^2},
$$ where $\displaystyle{H_{n}=1+\frac{1}{2}+\cdots+\frac{1}{n}}$ the $n$ -th harmonic number. My try The main idea because the actions are many. However, we go directly to the sum without the individual decays. $$
\begin{split}
{\left(\frac{H_{n}}{n}\right)^2} =\left(\frac{H_{n}}{n}\right) \left(\frac{H_{n}}{n}\right) & = \left(-\int _0^1 x^{n-1}\ln (1-x) dx\right) \left(-\int _0^1 y^{n-1} \ln (1-y)dy\right)\\
& =\int _0^1 \int _0^1 x^{n-1}y^{n-1} \ln (1-x)\ln (1-y) dxdy
\end{split}$$ So the sum sought, with transfer within the integral, is $$
\begin{split}
\int _0^1 \int _0^1 &\left( \sum_{n=1}^{\infty}x^{n-1}y^{n-1} \ln (1-x)\ln (1-y)\right) \,dxdy \\
&= 
\int _0^1 \int _0^1 \left(\frac{1}{1-xy} \ln (1-x)\ln (1-y)\right) \,dxdy
\end{split}
$$ My main question is how to evaluate the final integral, not the main question (sum).","['integration', 'summation', 'definite-integrals', 'multivariable-calculus', 'calculus']"
4860658,étale $\ell$-adic cohomology is a Weil cohomology theory,"I was reading https://mathoverflow.net/questions/85078/ell-adic-weil-cohomology-theory and in the first paragraph it is said that $\ell$ -adic cohomology is a Weil cohomology theory over separably closed fields. I have been looking for a reference for that everywhere, but I haven't found any precise statement. Could someone help me? For Weil cohomology theory I stick to the definition given in Stacks Project https://stacks.math.columbia.edu/tag/0FHY . In general, I would like to know the precise hypotheses on the base field for $\ell$ -adic cohomology to be a Weil cohomology theory: For example: is $\ell$ -adic cohomology a Weil cohomology theory on the category of smooth projective schemes over $k$ , when $k$ is a separably closed field a finite field a characteristic zero field (not necessarily algebraically closed) an algebraically closed field My guesses are: should be true is false, and a counterexample is in Remark 17.9 in Milne's Lecures on étale cohomology. is flase, in the third row of https://link.springer.com/article/10.1007/BF01456052 it is said that over number fields the cohomology groups need not be finite dimensional. But again, I couldn't find any reference with a proof. should be true I would like to find some official references, with proofs. Thanks in advance to those who can answer me.","['etale-cohomology', 'algebraic-geometry', 'sheaf-cohomology']"
4860719,Question where sum of terms of an AP is a trignometric function,"The question is as such If the sum of the first $n$ terms of an arithmetic progression is denoted by $S_n$ and $$S_n = 6n\sec^2 \theta + n(n-1)(\sin^2 \theta(4 + \tan^2 \theta) + \cos^2 \theta(4 + \cot^2 \theta))$$ where $\theta \in (0, \frac{\pi}{2})$ . Then the minimum value of the common difference of the arithmetic progression is (a) 10, (b) 12, (c) 14, or (d) 16, could not find a similar question on google, I tried to break up the $4 + \tan^2 \theta$ and $4 + \cot^2 \theta$ in the brackets into $\sec^2 \theta + 3$ and $\csc^2 \theta + 3$ and then get somewhere however could not Any help would be appreciated","['trigonometry', 'arithmetic-progressions']"
4860759,using $\epsilon-\delta$ to prove the continuity of a multivariable function,"How can I prove $f(x,y)=x^y$ is continuous on $U=\{(x,y)\in\mathbb{R}^2|x>0\}$ by using $\epsilon-\delta$ ? For $(x_0,y_0)\in U$ , I tried to do something with $y\ln x$ : $$y\ln x-y_0\ln x_0=(y-y_0)\ln x+y_0\ln\frac{x}{x_0}.$$ I want $x-x_0$ to occur in the equality, so that I can choose $\delta$ from $\sqrt{(x-x_0)^2+(y-y_0)^2}<\delta$ . But I don't know how to do it :( . Could someone help me?","['epsilon-delta', 'real-analysis', 'multivariable-calculus', 'calculus', 'limits']"
4860781,Why does “propositional calculus” have the word “calculus” in it?,"We define “calculus” like this: “ Calculus is the mathematical study of continuous change. ” But if that’s the case, then why is the study of (true or false) propositions and their relations called: “ Propositional calculus ”? These are some example statements from both fields: This is something from calculus: $\int_{0}^{3} x^2 dx = 3$ This is something from propositional calculus: $((A \rightarrow B)\land A) \rightarrow B$ What I know from a historical standpoint is that “calculus” was originally a word for “small pebble” and then evolved into a word for “calculation”. However, I also know that propositional calculus was developed somewhere in the 19th century, which is way after calculus was used for “calculation”. Why are both of these using the term “calculus”? Is its meaning as “calculation” related?","['propositional-calculus', 'analysis', 'calculus', 'math-history', 'terminology']"
4860808,Probability of Streaks of length $\lg n - 2 \lg \lg n$ in a Fair Coin [CLRS],"I'm trying to solve Exercise 5.4-8 in the fourth edition of CLRS: $\star$ 5.4-8 Sharpen the lower bound on streak length by showing that in $n$ flips of a fair coin, the probability is at least $1 - 1/n$ that a streak of length $\lg n- 2\lg \lg n$ consecutive heads occurs. While there is a closed form solution for the probability of a streak , I found it difficult to use for getting the bound needed here. I also found a supposed solution (listed as 5.4-7 there), using a similar approach to the text, where the sequence is partitioned into $\lfloor{n/s} \rfloor$ subsequences of length $s$ each. However, I think there are some issues with this solution. For starters, I believe a streak of length $s=\lg n - 2 \lg \lg n$ actually means $s = \lceil\lg n - 2 \lg \lg n \rceil$ . Also the floor at the exponent $n/s$ appears to be missing. I tried bounding the floors and ceilings more carefully and ended up with the inequality $$\left(1-\frac{\log _2^2(n)}{2 n}\right){}^{\frac{n}{\log _2(n)-2 \log _2\left(\log _2(n)\right)}-1} \leq \frac{1}{n} $$ which unfortunately fails around $n=2 \times 10^{11}$ . I cannot see how to remedy the proof in the link, nor how to get this bound in any other way. I still believe the statement in the exercise is true, and would greatly appreciate help proving it. Thanks.","['inequality', 'probability-theory', 'probability']"
4860819,Why is $(I+A)/(I-A)$ unambiguous?,"The following question is from Roger W. Brockett, Finite Dimensional Linear Systems ( Image of source ): Ordinarily one does not use division notation when dealing with matrices because $A/B$ might be interpreted as $AB^{-1}$ or $B^{-1}A$ and these are not necessarily the same. Why is the notation $(I+A)/(I-A)$ unambiguous? I do not know what (I+A)/(I-A) is supposed mean, let alone proving it is unambiguous. So the question is what that notation mean, and preferably why is unambigous?","['matrices', 'linear-algebra', 'inverse']"
4860840,Circle rolling between two functions,"Consider a circle of radius $r_s$ that is tangent to two curves $r(\theta)$ and $R(\theta)$ at points $E_1, E_2$ respectively, defined in polar coordinates.
Knowing the function $r(\theta)$ , find the function $R(\theta)$ , so that when rotating both function in opposite directions by some angle $d\phi$ around the center of the coordinate system, the circle remains on the line OS (where O is the center of the coordinate system and S being the center of the circle) and is tangent to both curves at one point respectively.
Can be thought of as if the circle rolls on both surfaces without slipping. In case where curve $r(\theta)$ is a circle with radius $r$ , the other curve $R(\theta)$ is also a circle with the radius $R = r+2r_s$ . I can generate the points of function $R(\theta)$ numerically, but I am struggling to find a way to get an analytic solution for the curve $R(\theta)$ . Any thoughts? A drawing for (maybe) better understanding of the problem: problem","['classical-mechanics', 'polar-coordinates', 'functions', 'geometry']"
4860856,Is covariant derivative of the connection one-form defined?,"This is in regards to the definition of curvature two-form $\Omega$ defined in Nakahara (Sec. 10.3.2, Def. 10.5, Pg. 386) as the covariant derivative of the connection one-form $\omega$ $$\Omega \equiv D\omega$$ This is actually in stark contrast to what we have been taught in physics that the covariant derivative of the connection is not defined. Can anyone please explain which understanding is the correct one?","['connections', 'differential-geometry']"
4860870,Solving two equations for $(a-b)$,"Let $a$ and $b$ be real numbers such that $a^{1/3}-b^{1/3}=12$ and $216ab=(a+b+8)^3$ . Find the value of $a-b$ . My attempt: Rationalizing the first equation, $a-b=12(a^{2/3}+b^{2/3}+(ab)^{1/3})$ . Using the second equation, $a-b=2(6a^{2/3}+6b^{2/3}+a+b+8)=2((a^{1/3}+2)^3+(b^{1/3}+2)^3-4(3a^{1/3}+3b^{1/3}+2))=2(a^{1/3}+b^{1/3}+4)([(a^{1/3}+b^{1/3}+2)^2-(2a^{1/3}+2b^{1/3}+3)])-4(3a^{1/3}+3b^{1/3}+2)$ And it keeps getting more complicated as I tried finding the value of $a^{1/3}+b^{1/3}$ using the given expression, I get $a^{1/3}+b^{1/3}=448+2a+2b$ and substituting this in does not help regenerate any term I know the value of. Any ideas as to how to solve this problem?","['rationalising-denominator', 'algebra-precalculus']"
4860921,On which sets can a function have zero derivatives?,"Let $f:\mathbb{R}\rightarrow\mathbb{R}$ be infinitely differentiable not identically zero. Let $S_f=\{ x : f^{(n)}(x)=0 \ \forall n\in\mathbb{N} \}$ . $S_f$ can be non empty e.g. $e^{-1/x^2}$ -like examples. In fact, $S_f$ can contain an interval (integrate the previous example). Clearly $S$ is closed. Is there an example of a closed proper subset $K$ of $\mathbb{R}$ such that $K$ is not $S_f$ for any $f$ ? We can combine my two examples to make a lot of closed sets, but its not so obvious how to make sure a function with $S_f$ equal to the cantor set. If such a $K$ exists, is there another way to characterise which sets $S_f$ can be?","['reference-request', 'functional-analysis', 'analysis', 'real-analysis']"
4860938,Solve the equation $\arcsin\bigg(\dfrac{x+1}{\sqrt{x^2+2x+2}}\bigg)-\arcsin\bigg(\dfrac{x}{\sqrt{x^2+1}}\bigg)=\dfrac{\pi}{4}$,"Solve the equation $$\arcsin\bigg(\dfrac{x+1}{\sqrt{x^2+2x+2}}\bigg)-\arcsin\bigg(\dfrac{x}{\sqrt{x^2+1}}\bigg)=\dfrac{\pi}{4}$$ My solution: I converted this equation in terms of $\arctan$ and applied tangent to both sides, and I got my answer as $x=-1,0$ . But then one of my friends said that $x=2$ satisfies too the above equation, and the reason he gave is as follows: $$\arcsin\bigg(\dfrac{3}{\sqrt{10}}\bigg)=\dfrac{\pi}{4}+\arcsin\bigg(\dfrac{2}{\sqrt{5}}\bigg)$$ and he applied sinus to both sides to obtain $\dfrac{3}{\sqrt{10}}=\dfrac{3}{\sqrt{10}}\:$ . Now I don't have any explanation for him. Can anyone here explain the reason behind this situation? I plotted it in desmos, and I am getting $x=-1,0$ only. Link to desmos","['inverse-trigonometric-functions', 'algebra-precalculus', 'inverse-function', 'trigonometry']"
4860957,AN EXAMPLE OF EXTREMUM VALUES OF FUNCTION FROM Thomas Calculus,"The picture is from Thomas Calculus 12th Ed. In the answers it says that the point $(2,1)$ is a local maximum point of the function $f$ which is correct to me because $f(2)\geq f(x)$ for some open interval containing $2$ . But when we check the sign of the first derivative, it does not change at $2$ , it is positive either side of the point $2$ and the book says ""if the derivative's sign does not change, then the point itself fails to be a local extremum"" consequently, $x=2$ is local maximum point as the definition of local maximum point and is not since derivative's sign does not change at $x=2$ . I am so confused, any hint or help will greatly be aprreciated.  Should we assume that x=2
is an end-point of the left function?  the book says ""A function ƒ has a local maximum value at a point c within its
domain D if $ƒ(x)\leqƒ(c)$ for all $x\in D$ lying in some open interval containing c."" so $x=2$ is an end-point for the left function","['calculus', 'analysis']"
4861007,Strange behaviour of $x^2+5x+7$ under iteration,"If any of the following exposition is unclear, please write a comment. In essence, I am looking at the graph $G$ that is generated by the polynomial $q(x) = x^2+ax+b$ ( $a,b \in \mathbb{Z}$ ) via the edge set $$\{(n, q(n) \text{ mod } p) : n =0,\ldots,p-1\}$$ for some prime $p \in \mathbb{P}$ . After some thought, it should be clear that the statements $$``\text{Iterating } q \text{ for any input will always eventually lead to divisibility by some prime at least once.} ``$$ and $$``G \text{ has a path from any node to 0.}``$$ are equivalent. Furthermore, ""at least once"" can be replaced by ""periodically infinitely many times"" and ""every node has a path to $0$ "" can be characterized by "" $G$ is weakly connected and has exactly one loop containing $0$ "". With that out of the way, let's get to the question: The natural question now is to know for which polynomials $q$ we have this nice property of ""eventual divisibility"" by some prime no matter what number we input, i.e. finding connected $G$ with a single loop containing $0$ . This is not rare, see for example $q(x) = x^2+3$ for $p=7$ : To get a feeling for how rare this is, let's look at the following plot: This image displays, for $a = -10, \ldots, 10$ on the vertical axis and $b = -10, \ldots, 10$ on the horizontal axis, if $G$ has the aforementioned property for some $p < 113$ in black and otherwise white. There are some obvious cases like $a = b+2$ and $a = -b$ where this eventual divisibility will never occur since they have the one-cycles $(-1,-1)$ and $(1,1)$ respectively. Modulo careful checking, we can eliminate quite a lot more trivial cases (i.e. explain white squares) in the diagram by searching for trivial one- and two-cycles, i.e. eventual divisibility seems to be the norm rather than the exception . In some other cases, eventual divisibility is found with a somewhat higher prime, such as $p=719$ for $x^2+5x+9$ . Sparing you the details, we are left with the cases below, in which either eventual divisibility does not exist or it requires an especially large prime. The discriminant $\Delta$ is included if it helps: $x^2-10x-10$ (EDIT) is ""eventually divisible"" for every residue with $p = 11701$ $x^2-10x-6$ (EDIT) is ""eventually divisible"" for every residue with $p = 31237$ $x^2-10x+4$ (EDIT) is ""eventually divisible"" for every residue with $p = 6337$ $x^2-10x+8$ (EDIT) is ""eventually divisible"" for every residue with $p = 13037$ $x^2-7x-7$ checked for $p \leq 4\cdot10^6$ by Mike Daas ( $\Delta = 77$ ) $x^2-7x+5$ checked for $p \leq 6881261$ by Mike Daas ( $\Delta = 29$ ) $x^2+5x+7$ is provably never ""eventually divisible"" as shown by Oscar Lanzi Five of the seven cases above have been solved as indicated, but for the remaining two I cannot rule in or rule out this property. I know that this is a question about (pretty much hopelessly) chaotic behaviour, but perchance somebody has a thought or two on the following: Since eventual divisibility seems to be occuring by pure chance every time, why do these exceptions stick out so much? Is there some anti-""strong law of small numbers"" at work here? If so, are the heuristics that might suggest non-existence of such $G$ for given $q$ ?","['graph-theory', 'number-theory', 'polynomials', 'recreational-mathematics', 'prime-numbers']"
4861048,Hard time grasping Dedekind cuts and real numbers [duplicate],"This question already has answers here : Why does the Dedekind Cut work well enough to define the Reals? (8 answers) Closed 5 months ago . The community reviewed whether to reopen this question 5 months ago and left it closed: Original close reason(s) were not resolved I have been trying to understand some elementary set theory recently, and am trying to understand how the real number line can be defined using the set of rational numbers. In particular, I am trying to understand Dedekind cuts. I understand the definition of a Dedekind cut, and I have no trouble identifying if a cut is Dedekind or not. But I have troubles understanding how this definition is useful. In a video I saw by Dr. Peyam , he claimed that $\displaystyle \sqrt[3]{2}$ can be defined the following way: $\displaystyle \sqrt[3]{2}=\{ r\in\mathbb{Q}:r^{3}<2 \}$ I understand that this set is in fact a Dedekind cut because it has (i) no maximum, (ii) contains all rationals less than $\sqrt[3]{2}$ and (iii) is a real, nonempty subset of $\mathbb{Q}$ . But I do not understand how we can define a singular number as a set containg infinitely many numbers.","['real-numbers', 'irrational-numbers', 'calculus', 'elementary-set-theory', 'general-topology']"
4861077,How to calculate this sum $\sum_{n=1}^{\infty} \frac{H_n \cdot H_{n+1}}{(n+1)(n+2)}$,How to calculate this sum $$\sum_{n=1}^{\infty} \frac{H_n \cdot H_{n+1}}{(n+1)(n+2)}$$ Attempt The series telescopes. We have $$=\frac{H_n \cdot H_{n+1}}{(n+1)(n+2)} = \frac{H_n \cdot H_{n+1}}{n+1} - \frac{H_n \cdot H_{n+1}}{n+2}$$ $$=\frac{H_n(H_n + \frac{1}{n+1})}{n+1} - \frac{(H_{n+1} - \frac{1}{n+1}) \cdot H_{n+1}}{n+2}$$ $$=\frac{H_n^2}{n + 1} - \frac{H_{n+1}^2}{n + 2} + \frac{H_n}{(n + 1)^2}+ \frac{H_{n+1}}{(n + 1)(n + 2)}$$ $$=\frac{H_n^2}{n + 1} - \frac{H_{n+1}^2}{n + 2} + \frac{H_{n+1} - \frac{1}{n+1}}{(n+1)^2} + - \frac{H_{n+1}}{n+1} - \frac{H_{n+1}}{n+2}$$ $$=\frac{H_n^2}{n + 1} - \frac{H_{n+1}^2}{n + 2} + \frac{H_{n+1}}{(n+1)^2} - \frac{1}{(n+1)^3} + \frac{H_{n + 1}}{n + 1} - \frac{H_{n + 2}}{n + 2} + \frac{1}{{(n + 2)^2}}$$ It follows that $$\sum_{n=1}^{\infty} \frac{H_n \cdot H_{n+1}}{(n+1)(n+2)} = \sum_{n=1}^{\infty} \left(\frac{H_{n}^2}{n + 1} - \frac{H_{n+1}^2}{(n+2)^2}\right) + \sum_{n=1}^{\infty} \frac{H_{n+1}}{(n+1)^2} - \sum_{n=1}^{\infty} \frac{1}{(n+1)^3}$$,"['summation', 'euler-sums', 'harmonic-numbers', 'closed-form', 'sequences-and-series']"
4861085,How would you explain a tensor to a computer scientist?,"How would you explain a tensor to a computer scientist? My friend, who studies computer science, recently asked me what a tensor was. I study physics, and I tried my best to explain what a tensor is, and I said something along the lines of ""a mathematical object that is described in between the mappings of vector spaces"", and he wasn't quite about that definition. I understood why, since it is a pretty wordy definition I gave, so I decided to give a more, down to earth, definition, describing a tensor as some array, with n-dimensions. However, he was still kind of confused by this. Can anyone synthesise a decent definition, tailored to a computer scientist's understanding?","['tensors', 'linear-algebra', 'vector-analysis']"
4861108,"The sequence $a_{n+2}=\frac{a_{n+1}+a_n}{\gcd\left(a_{n+1,}a_n\right)}$ is bounded","Let a sequence of natural numbers be $a_{n+2}=\frac{a_{n+1}+a_n}{\gcd\left(a_{n+1,}a_n\right)}$ where $a_1=a,a_2=b$ . Find all such pairs of $a,b$ such that the sequence is bounded. Denote $\gcd(a,b)=(a,b)$ . First of all, I notice if $(a,b)=1$ then the sequence would grow like $a+b,a+2b,....$ , so $(a,b)=d>1$ . Now let $a=dx,b=dy$ and $(x,y)=1$ . Then we get $a_3= x+y$ so, $a_4=\frac{x+y+b}{(x+y,b)}$ . How do I proceed?","['elementary-number-theory', 'recurrence-relations', 'sequences-and-series']"
4861129,"Integrating $\int_{0}^{1} \left(\frac{\arctan(x) - x}{x^2}\right)^2 \,dx$","how to integrate $$\int_{0}^{1} \left(\frac{\arctan(x) - x}{x^2}\right)^2 \,dx$$ Attempt $$=\int_{0}^{1} \left(\frac{\arctan(x) - x}{x^2}\right)^2 \,dx = \int_{0}^{1} \frac{1}{x^4} \cdot (\arctan(x) - x)^2 \,dx$$ Integrating by parts $$I = -\frac{1}{3} \left(\frac{\pi}{4} - 1\right)^2 + \frac{2}{3} \int_{0}^{1} \frac{x - \arctan(x)}{x(x^2 + 1)} \,dx$$ $$= -\frac{1}{3} \left(\frac{\pi}{4} - 1\right)^2 + \frac{2}{3} \int_{0}^{1} \frac{1}{x^2 + 1} \,dx - \frac{2}{3} \int_{0}^{1} \frac{\arctan(x)}{x(x^2 + 1)} \,dx$$","['integration', 'improper-integrals', 'definite-integrals', 'calculus', 'closed-form']"
4861160,One variable inequality problem $\frac{x\sqrt{|x^2 - 4|}}{x^2 - 4} - 1 > 0$,"Hi I'm having problem with inequality $\frac{x\sqrt{|x^2 - 4|}}{x^2 - 4} - 1 > 0$ I rearranged the equation a bit and I did this $\frac{x\sqrt{|x^2 - 4|}-x^2+4}{x^2 - 4}  > 0$ holds if $(x-2) \cdot(x+2)\cdot (x\sqrt{|x^2 - 4|}-x^2+4)>0$ This part is the most difficult for me $(x\sqrt{|x^2 - 4|}-x^2+4) = 0$ I am unable to find solution of this equation  and I think this is crucial to solving it.
I also tried other ways to solve this equation, such as moving 1 to the other side of the equation. And then I multiply both sides by $(x-2)^2 \cdot (x+2)^2$ But I also failed because I probably at some point illegally raised both sides to the second power. I also have answer for that inequality: $x\in(-2,\sqrt{2})\cup(2, \infty)$ I also tried to calculating this equation using programs such as wolfram alpha but only gives me a result and I would like to know how I could solve it.
Thank you in advance for your help.","['inequality', 'linear-algebra', 'analysis']"
4861179,Topology on the set of all separable Hausdorff topological spaces,"It is well-known ( 1 , 2 ) that the cardinality of a separable Hausdorff topological space is at most $2^{2^{\aleph_0}}$ . Therefore, the collection $\mathcal{A}$ of all (homeomorphism classes of) separable Hausdorff topological spaces is a set. Can the set $\mathcal{A}$ be equipped with a natural topology?","['general-topology', 'hyperspace']"
4861262,Generating consecutive numbers from matrix multiplication.,"I'm new to matrix multiplication and was trying to generate a sequence of consecutive numbers from the product of two $2 \times 2$ matrices and noticed this pattern. Let $$
A = \begin{pmatrix} n & n+1 \\ n+2 & n-1 \end{pmatrix}, \quad B = \begin{pmatrix} m & m-1 \\ m-1 & m \end{pmatrix},  \quad C = AB
$$ Compute \begin{align*}
C &= \begin{pmatrix} n & n+1 \\ n+2 & n-1 \end{pmatrix} \begin{pmatrix} m & m-1 \\ m-1 & m \end{pmatrix} \\
&= \begin{pmatrix} nm + (n+1)(m-1) & n(m-1) + (n+1)m \\ (n+2)m + (n-1)(m-1) & (n+2)(m-1) + (n-1)m \end{pmatrix} \\
&= \begin{pmatrix} 2nm - n + m - 1 & 2nm + m - n \\ 2nm + m - n + 1 & 2nm + m - n - 2 \end{pmatrix}
\end{align*} Let $k = 2nm + m - n$ , then $$
C = \begin{pmatrix} k - 1 & k \\ k + 1 & k - 2 \end{pmatrix}
$$ which yields consecutive numbers $k-2,k-1,k,k+1$ . Example Let $n=150, m=16$ . Then multiplying $$
\begin{pmatrix}
150 & 151 \\
152 & 149 \\
\end{pmatrix}
\cdot
\begin{pmatrix}
16 & 15 \\
15 & 16 \\
\end{pmatrix}
=
\begin{pmatrix}
4665 & 4666 \\
4667 & 4664 \\
\end{pmatrix}
$$ gives $k=4666$ with consecutive numbers $4664, 4665, 4666, 4667$ . WolframAlpha Questions Can that method be generalized to two $n \times n$ matrix products, resulting in $n^2$ consecutive numbers? Aside, is there a way to ensure the $n^2$ consecutive numbers are always composite?",['matrices']
4861312,"Is there an opposite of a dirac delta function, a function that is infinitely wide and infinitesimally high?","Is there an opposite of a dirac delta function, a function that is infinitely wide and infinitesimally high? The dirac delta function is defined as: $$
\delta(x) =
\begin{cases}
0, & \text{if } x \neq 0\\
\infty, & \text{if } x = 0
\end{cases}
$$ where $$
\int_{-\infty}^{\infty} \delta(x) \, dx = 1
\\
\int_{-\infty}^{\infty} f(x) \delta(x - a) \, dx = f(a)
$$ Is there a function: $$
\epsilon(x) = \lim_{\epsilon \to 0} \epsilon
$$ where $$
\int_{-\infty}^{\infty} \epsilon(x) \, dx = 1
$$ The dirac delta function $\delta(x)$ is infinitely high but infinitesimally wide, this new function $\epsilon(x)$ is infinitesimally high but infinitely wide. Im guessing theres no such function/distribution given how limits work and it probably would not be useful if it did, but is there any credence to this idea?","['limits', 'functions', 'dirac-delta', 'real-analysis']"
4861319,"A nice property of a triangle With side 1,2,2","About a year ago, while using GeoGebra, I discovered a beautiful property of a triangle with sides 1,2,2. It is that many of the important centers of this triangle are located at equal distances in a row, so much so that I called this triangle the “numbers line triangle.” You can consider the following two images: $G$ is the point of intersection of the heights of $∆XYZ$ $C$ is the point of intersection of the bisectors of $∆X^{'}Y^{'}Z^{'}$ $F$ is the intersection of the bisectors of $∆XYZ$ $B$ is the center of the circle $XMPDQN$ $E$ is the point of convergence of the averages of $∆XYZ$ $A$ is the point of convergence of the heights of $∆X^{'}Y^{'}Z^{'}$ $D$ is the point of convergence of the $∆XYZ$ axes $XA=AB=BC=CD=DE=EF=FG$ My question consists of two parts: Is this feature already discovered? How do we prove that anyway?","['euclidean-geometry', 'geometry']"
4861346,If $Y_n \rightarrow Y$ in distribution then $P(Y \geq M) \geq \liminf_{n\rightarrow \infty} P(Y_n \geq M)$ for $M \in \mathbb{R}$,Let $Y_n$ be a sequence of real random variables converging in distribution to a random variable $Y$ and let $M \in \mathbb{R}$ be a fixed real number. I would like to prove that $P(Y \geq M) \geq \liminf_{n\rightarrow \infty} P(Y_n \geq M)$ . This seems like it should be very easy to prove since if $x_n \rightarrow x$ then $x \geq \liminf_{n\rightarrow \infty} x_n$ for any convergent sequence of real numbers. But since we only have convergence in distribution and the limit is outside the measure $P$ I am having some trouble formalizing everything. How can one prove this?,"['measure-theory', 'real-analysis', 'convergence-divergence', 'probability-theory', 'probability']"
4861401,Constructing a function from a function of its inverse,"Let $f$ be a continuous strictly-increasing function that maps $\mathbb{R}_+$ to $\mathbb{R}_+$ . Define a function $g$ on $\mathbb{R}_+$ as follows: $$g(x) := f^{-1}(f(x)+1).$$ For example, if $f(x) = x^2$ , then $g(x) = \sqrt{x^2+1}$ . In words, $g(x)$ describes to what value you should increase $x$ , so that $f(x)$ increases by $1$ . The function $g$ clearly satisfies two properties: $g(x)>x$ for all $x$ ; $g(x)$ is strictly increasing. QUESTION: Given a function $g$ that satisfies these two properties, does there always exist a corresponding function $f$ ? If not, what other conditions are required?","['functions', 'inverse-function']"
4861405,"How to integrate $\int_{0}^{1} \int_{0}^{1} \int_{0}^{1}\frac{x^{4a - 1} \ln(x)}{\sqrt{yz} \cdot (1 + x^{2a}z + yzx^{4a} + yx^{2a})} \,dx \,dy\,dz$","how to integrate $$\int_{0}^{1} \int_{0}^{1}\int_0^1 \frac{x^{4a - 1} \ln(x)}{\sqrt{yz} \cdot (1 + x^{2a}z + yzx^{4a} + yx^{2a})} \,dx \,dy\,dz$$ My attempt $x^{2a} \rightarrow x$ $$=\frac{1}{4a^2} \int_0^1 \int_0^1 \int_0^1 \frac{x \ln(x)}{\sqrt{yz} \cdot (1 + yx)(1 + zx)} \,dx \,dy \,dz$$ $$=\frac{1}{4a^2} \int_0^1 \int_0^1 \int_0^1 \sum_{n, m \geq 0} (-1)^{n+m} y^{n-\frac{1}{2}} z^{m-\frac{1}{2}} x^{n+m+1} \ln(x) \,dx$$ $$= \int_0^1 \sum_{n \geq 0} \frac{(-1)^n x^{n + \frac{1}{2}}}{2n + 1} \cdot \sum_{m \geq 0} \frac{(-1)^m x^{m + \frac{1}{2}} \cdot \ln(x)}{2m + 1} \, dx$$ $$= \frac{1}{a^2} \int_{0}^{1} [\arctan(\sqrt{x})]^2 \ln(x) \,dx$$ $\sqrt{x} = x$ $$=\frac{4}{a^2}\int_{0}^{1} x \ln(x) \arctan^2(x) \,dx$$","['integration', 'multivariable-calculus', 'definite-integrals', 'closed-form']"
4861406,Do matrices really rotate and stretch vectors or is that definition incorrect?,"I come from the applied math and statistics world, but I was talking to my friend who comes from the pure math and number theory world—in particular Galois representation theory. I mentioned something about the confusing definition of ""matrices"" in textbooks. Many textbooks talk about a matrix as the solution to a linear system of equations, or other abstract descriptions. The definition that I have always found useful, was the sense that matrices rotate and scale vectors through linear transformations. Now, coming from the pure math side, my friend said that this definition was not accurate. I am trying to paraphrase some of his comments, but he said that in higher dimensions, matrices can stretch and rotate vectors only locally . He also said that it depends on what vectors the matrix acts upon. His response threw me for a loop and I was trying to understand how to resolve his statements. First, is my understanding of matrices incorrect? It is fine if this idea of rotating and stretching a vector is incorrect, but I am not sure what the alternative definition of a matrix would be. Like when my friend says that a matrix may only stretch/rotate a vector locally, I am trying to think of a practical example of this kind of phenomena. I will follow up with my friend on what he means, but I was hoping someone could set me straight on how I should think of a matrix, or the definition of a matrix.","['matrices', 'representation-theory', 'abstract-algebra', 'linear-algebra']"
4861427,How many possible pairs in a random 5-card poker hand?,"This question is from Introduction to Probability, question 32b. I've seen the solution and I understand it clearly. $$\frac{\binom{13}{2}\times \binom{4}{2}\times \binom{4}{2} \times 44}{\binom{52}{5}}$$ The $\binom{13}{2}$ is from the different pairs of values I can have.
The two $\binom{4}{2}$ is for the two same values from the possible four cards.
The 44 is the fifth card I can have which is different from the previous four. I came up with my own answer (which is obviously wrong) but I can't understand why it doesn't equal to the above.
My own answer is $$\frac{\frac{52}{2!} \times \frac{(52-4)}{2!} \times 44} {3!}$$ $\frac{52}{2!}$ is for the first possible card I can choose. Therefore, the second one must be the same. The 2! is because order doesn't matter. $\frac{52-4}{2!}$ is for the third possible card I can choose. Therefore, the fourth one must be the same. 44 is the rest of the card that I can choose. 3! is for the order of the two pairs and the last card doesn't matter. It seems like I undercount it but I can't understand why. Please show me what I am missing. Thank you very much.","['combinations', 'combinatorics', 'card-games', 'probability']"
4861439,Shortest distance between vertex of a circular cone and a quarter of its conical helix,"I was given with the question below: A circular cone with vertex C has a point A on the circumference of its base and
point B on the segment AC, as shown in the diagram below. The shortest
possible rope is wrapped once around the cone such that it starts at point A and
ends at point B. Assume that the base diameter and the slant height of this cone
are 6 cm and 12 cm, respectively. If AB = 3 cm and D is the point on the rope
that is closest to C, what is the length, in cm, of CD? Instinctively, by just looking at the diagram, I believe that B is the point on the rope that is closest to C. Therefore D is the same as B, and CD = 12 - 3 = 9. However, this looks to simple to be true, and it doesn't make much sense to have two points overlap. Furthermore, I found this question from this website , where the 15th question of EMIC is exactly the question I was tasked with, and the solution claims that it is 7.2. The value of 7.2 makes no sense to me, so I tried to attempt the question again, by modelling the rope as a helix with parametric equation $$
x(t) = 3(1-t)\cos(8\pi t)\\
y(t) = 3(1-t)\sin(8\pi t)\\
z(t) = 3\sqrt{15}t\\
0<t\leq\frac{1}{4}\\
$$ which, when plotted in desmos, seems to be exactly the rope I was given with in the question. I then attempted to use the distance formula to calculate the distance between a point on the parametric equation above, and the point $(0, 0, 3\sqrt{15})$ (which is the vertex of the cone, calculated by the Pythagorean theorem). The result was that, for $t=t$ , the distance between the rope and the vertex is $$
12|1-t|
$$ Obviously, to minimise $12|1-t|$ for $0<t\leq\frac{1}{4}$ , $t=\frac{1}{4}$ when the distance becomes 9, validating my initial guess. My answer should be wrong, but I just can't spot any mistake that I have made. I would appreciate if you could find my mistake and provide some hints to the correct solution.","['parametric', 'geometry', '3d']"
4861463,"If a sequence $ \{ a_n \} $ is contained in a finite union of sets, then there is a subsequence of $ \{ a_n \} $ contained in only one of the sets.","Edit : It has been pointed out that the title is stated ambiguously, please refer to the post by @Prem as to why. The title should actually be: If a sequence $ \{ a_n \} $ is contained in a finite union of sets, then there is a subsequence of $ \{ a_n \} $ contained entirely in one of the sets. In other words, if $ \{a_{n_i} \}$ is the desired subsequence, then there is some $ 1 \leq k \leq m $ such that $ a_{n_i} \in E_k $ for all $ i $ where $ \{n_i\} $ is the index selection sequence. I'm working on a proof in which I would like to use the following result: Suppose that a sequence $ \{ a_n \} $ is contained in a finite union of sets $ E_1 \cup \dots \cup E_m $ , then there exists a subsequence $ \{ a_{n_i} \} $ of $ \{ a_n \} $ contained entirely in one of the $ E_k $ where $ 1 \leq k \leq m $ . Here $ \{n_i\} $ is the index selection sequence. However, I have trouble finding a proof of this result in any of my textbooks. I've looked around the internet as well but haven't found anything. Intuitively, I'm certain that this is true, so I tried cooking up a proof of my own but I'm worried it might not be correct/rigorous: Since the sequence $ \{ a_{n} \} $ is infinite, we must have that it occurs infinitely often in at least one of the sets $ E_1, \dots, E_m $ . But this implies that there is some subsequence $ \{ a_{n_i} \} $ contained entirely in one of the sets $ E_1, \dots, E_m $ .","['general-topology', 'solution-verification', 'sequences-and-series', 'real-analysis']"
4861488,"$m$ people choosing $l$ elements out of $n$ independently, what is the probability of each element being chosen at least $k$ times?","We have $m$ people and a set of $n$ elements. Each person chooses $l$ elements out of $n$ , independently from each other. What is the probability that each element is chosen at least $k$ times? Let $X_1, \dots X_n$ be the random variables counting how many times each element is chosen. I want to determine the density $\mathbb{P}(X_1=k_1, \dots X_n=k_n)$ , then I can sum over all values greater than $k$ to determine the probability. I am having a hard time trying to compute the combinations. The denominator of the probability is easy, because it's all possible combinations of $l$ elements out of $n$ , repeated $m$ times, due to independence: $$\binom{n}{l}^m$$ But how can I determine only those combinations, such that the elements are chosen exactly $k_1, \dots k_n$ times? I don't know if a simple formula exists for this. Example: Let's say we have $m=10$ people voting for $n=5$ parties. Each person is expressing $l=2$ votes (more precisely, they randomly choose $2$ different parties). What is the probability that each party gets at least $k=1$ vote? Addendum: I am not sure if it helps, but I also thought of formalizing this problem in a different way. Basically it's a random $m \times n$ binary matrix, with each row summing to $l$ and each column summing to a number $\geq k$ . I need to count all the possible matrices.","['combinatorics', 'probability']"
4861511,"How to integrate $\int_{0}^{1} \int_{0}^{1} \ln\left(\frac{1}{\sinh^2(x) + \cosh^2(y)}\right) \,dx\,dy$","How to integrate $$\int_{0}^{1} \int_{0}^{1} \ln\left(\frac{1}{\sinh^2(x) + \cosh^2(y)}\right) \,dx\,dy$$ My attempt $$\int_{0}^{1} \int_{0}^{1} \ln\left(\frac{1}{\sinh^2(x) + \cosh^2(y)}\right) \,dx\,dy = - \int_{0}^{1} \int_{0}^{1} \ln(\sinh^2(x) + \cosh^2(y)) \,dx\,dy$$ $$= - \int_{0}^{1} \int_{0}^{1} \ln\left(\frac{e^{2x} + e^{-2x} + e^{2y} + e^{-2y}}{4}\right) \,dx\,dy$$ $$ =- \int_{0}^{1} \int_{0}^{1} \ln\left(e^{2x} + \frac{1}{e^{2y}} + e^{2y} + \frac{1}{e^{2x}}\right) \,dx\,dy + 2\ln(2)$$ $$= - \int_{0}^{1} \int_{0}^{1} \ln\left(\frac{e^{2x+2y} + 1}{e^{2y}} + \frac{e^{2x+2y} + 1}{e^{2x}}\right) \,dx\,dy + 2\ln(2)$$ $$=- \int_{0}^{1} \int_{0}^{1} \ln(e^{2(x+y)} + 1) \,dx\,dy +\int_{0}^{1} \int_{0}^{1} \ln(e^{2(x+y)}) \,dx\,dy - \int_{0}^{1} \int_{0}^{1} \ln(e^{2x} + e^{2y}) \,dx\,dy + 2\ln(2)$$ $$= - \int_{0}^{1} \int_{0}^{1} \ln(e^{2x} + e^{2y}) \,dx\,dy - \int_{0}^{1} \int_{0}^{1} \ln\left(1 + e^{2(x+y)}\right) \,dx\,dy + 2\ln(2) + 2$$ I need help with the last two integrals . Any help is appreciated. Edit Here is my second attempt $$I = 2 \ln(2) \int_{0}^{1} \int_{0}^{1} \,dx\,dy + \int_{0}^{1} \int_{0}^{1} \ln\left(\frac{1}{e^{-2x} + e^{2x} + e^{-2y} + e^{2y}}\right) \,dx\,dy$$ $x \rightarrow e^{-2x}, \quad y \rightarrow e^{-2y}$ $$=2\ln(2) - \frac{1}{4} \int_{e^{-2}}^{1} \int_{e^{-2}}^{1} \frac{\ln(y(x^2 + 1) + x(y^2 + 1)) - \ln(xy)}{xy} \,dx\,dy$$ $$=2\ln(2) - \frac{1}{4} \int_{e^{-2}}^{1} \int_{e^{-2}}^{1} \frac{\ln(y(x^2 + 1) + x(y^2 + 1))}{xy} \,dx\,dy + \frac{1}{2} \int_{e^{-2}}^{1} \frac{\ln(x)}{x} \,dx \cdot \int_{e^{-2}}^{1} \frac{1}{y} \,dy$$","['integration', 'definite-integrals', 'multivariable-calculus', 'calculus', 'closed-form']"
4861513,$L^1- L^\infty$ estimate for the semi group of wave equations,"I am looking for a proof of the following lemma for the case where: $y= (y_1,\cdots, y_n)\mapsto  P(y) = \|y\|_2= \sqrt{y_1^2+ \cdots + y_n^2}.$ In this case the rank of the mentioned matrix is $n-1$ for $y\neq 0$ ${\rm supp}(v)= \{y \in \mathbb{R}^n , 1<\|y\|_2 <2 \}$ The author referred to the following paper for the proof in the general case as stated above where It was done in the frame of Fourier transform of surface carried measures and its behaviour at the infinity. I wonder if there is another (more direct) proof which uses the usual techniques of functional analysis ( $L^p$ estimates, interpolation estimates ...etc.) Thank you for any hint.
EDIT: Here is what I found in the literature for the general proof:
In the following paper (see picture below): the Lemma 2.1 seems to have a result of the same nature where the author referred again the this paper from which I took a screenshot of the main result I wonder what the role of the assumption on the Hessian and the parameter $t$ is.","['lp-spaces', 'fourier-analysis', 'functional-analysis', 'differential-geometry']"
4861555,What are the conditions to compose limits to infinity?,"I've recently become a little obsessed with all the ways limits can be composed - and the preconditions for this to take place. I took $A,B_{1},B_{2},C \subseteq \mathbb{R}$ and $f:A\to B_{1},\ g:B_{2} \to C$ and further assumed $f[A] \subseteq B_{2}$ . And then I listed out all the ways to compose $f$ and $g$ with limits: \begin{align}
1.&&\lim_{x\to a}f(x)=b,\lim_{x\to b}g(x)=c&&\implies&&\lim_{x\to a}g(f(x))=c \\\\ 2.&&\lim_{x\to a}f(x)=b,\lim_{x\to b}g(x)=\infty&&\implies&&\lim_{x\to a}g(f(x))=\infty \\\\ 3.&&\lim_{x\to a}f(x)=\infty,\lim_{x\to\infty}g(x)=c&&\implies&&\lim_{x\to a}g(f(x))=c \\\\ 4.&&\lim_{x\to a}f(x)=\infty,\lim_{x\to\infty}g(x)=\infty&&\implies&&\lim_{x\to a}g(f(x))=\infty \\\\ 5.&&\lim_{x\to\infty}f(x)=b,\lim_{x\to b}g(x)=c&&\implies&&\lim_{x\to\infty}g(f(x))=c \\\\ 6.&&\lim_{x\to\infty}f(x)=b,\lim_{x\to b}g(x)=\infty&&\implies&&\lim_{x\to\infty}g(f(x))=\infty \\\\ 7.&&\lim_{x\to\infty}f(x)=\infty,\lim_{x\to\infty}g(x)=c&&\implies&&\lim_{x\to\infty}g(f(x))=c \\\\ 8.&&\lim_{x\to\infty}f(x)=\infty,\lim_{x\to\infty}g(x)=\infty&&\implies&&\lim_{x\to\infty}g(f(x))=\infty
\end{align} and I got the proofs (and preconditions) for $1$ through $5$ . For example, for $1.$ we need either : $A\ $ : $g(b)=c$ , or $B\ $ : $\exists \delta>0,\forall x \in A: \ \ 0<|x-a|<\delta \implies |f(x)-b|>0$ For $2.$ we need $B$ For $3.$ no additional requirements are needed For $4.$ no additional requirements are needed For $5.$ we need $A$ But now I am stuck on $6$ . So far I have the following: I expand the definitions of what I have, and am trying to prove. \begin{align}
1: &&& \lim_{ x \to \infty } f(x) = b &&\iff&& \forall \varepsilon>0, \exists c \in \mathbb{R}, \forall x \in A: \ \ x>c \implies |f(x)-b| < \varepsilon \\\\
2: &&& \lim_{ x \to b } g(x) = \infty &&\iff&& \forall r \in \mathbb{R}, \exists\delta>0,\forall x \in B_{2}: \ \ 0<|x-b| < \delta \implies g(x) > r \\\\
\text{Aim for:} &&& \lim_{ x \to \infty } g(f(x)) = \infty &&\iff&& \forall r \in \mathbb{R}, \exists c \in \mathbb{R},\forall x \in A: \ \ x>c \implies g(f(x)) > r
\end{align} Then take arbitrary $R \in \mathbb{R}$ . Therefore, $\exists\delta>0,\forall x \in B_{2}: \ \ 0<|x-b| < \delta \implies g(x) > R$ . Take particular $D>0$ for which that is true. Therefore, $\forall x \in B_{2}: \ \ 0<|x-b| < D \implies g(x) > R$ . Since $D>0$ , we also have $\exists c \in \mathbb{R}, \forall x \in A: \ \ x>c \implies |f(x)-b| < D$ . Take particular $C \in \mathbb{R}$ for which this is true. Therefore, $\forall x \in A: \ \ x>C \implies |f(x)-b| < D$ . Take arbitrary $X \in A$ . Therefore, $X>C \implies |f(X)-b| < D$ . Since $f(X) \in B_{2}$ , we get $0<|f(X)-b| < D \implies g(f(X)) > R$ .
Assume $X>C$ , therefore $|f(X)-b| < D$ . Assume precondition $b \not\in f[A]$ . Therefore $|f(X)-b| > 0$ . Therefore $0<|f(X)-b| < D$ , which implies $g(f(X)) > R$ . Hence we have the implication $X>C \implies g(f(X)) > R$ . $X$ is arbitrary, $C$ is particular, $R$ is arbitrary, therefore we have $\forall r \in \mathbb{R}, \exists c \in \mathbb{R},\forall x \in A: \ \ x>c \implies g(f(x)) > r$ . That proof works if I assume $b \not\in f[A]$ , which seems to make sense as a precondition. If I take an example of $f(x)=\frac{1}{x}$ and $g(x)=-\ln(x)$ , then indeed $0 \notin f[A]$ , and it looks like $g(f(x)) \to \infty$ as $x\to \infty$ : But then that got me thinking, is there any preconditions weaker than this? Surely if I can find examples that fail this condition, then it its stronger than it needs to be. So what if $f(x)=\frac{1}{x}\sin(x)$ ? Then not only $f(x)\to 0$ as $x\to \infty$ , but also $0 \in f[A]$ . And then what if $g(x)=\frac{1}{x^2}$ ? Then $g(x)\to \infty$ as $x\to 0$ . And it looks like $g(f(x)) \to \infty$ as $x\to \infty$ : But if I think about it, $g(0)$ is undefined, so $0 \not\in B_{2}$ . If we still maintain that $0 \in f[A]$ , then $f[A] \not\subseteq B_{2}$ . The only way to maintain that $f[A] \subseteq B_{2}$ is to say $0 \not\in f[A]$ , so the precondition I came up with seems to apply to this example too. Is $b \not\in f[A]$ the minimal precondition for composition $6.$ to take place? EDIT: Thanks to Karl for pointing out that a precondition weaker than $f(x) \neq c$ is: $B\ '\ $ : $\exists c \in\mathbb{R}, \forall x \in A: x>c \implies |f(x)-c|>0$ And thanks to David K for showing me that $B\ '$ is also a sufficient condition for $5.$ :)","['limits', 'proof-writing', 'real-analysis']"
4861562,Solving $(2n)^{\log 2}=(5n)^{\log 5}$,"I have seen this equation from a link named Asisten and German Academy , (it is a  video of Facebook) where there is a complicate solution (I invite to watch it) for $$(2n)^{\log 2}=(5n)^{\log 5}$$ I have adopted, instead, this approach: $$(2)^{\log 2}(n)^{\log 2}=(5)^{\log 5}(n)^{\log 5} \iff 2n^{\log 2}=5n^{\log 5}$$ After $$\frac{n^{\log 2}}{n^{\log 5}}=\frac 52 \iff n^{(\log 2-\log 5)}=\frac 52$$ $$\log(n^{(\log 2-\log 5)})= \log 5-\log 2 $$ $$(\log 2-\log 5)\log n=\log 5-\log 2  \iff \log n =-1$$ Hence $$e^{\log n}=e^{-1}\implies n=\frac 1e$$ Now I have seen the solution is $n=1/10$ . Is it different my solution why my base is $e$ and not $10$ ? Generally I have seen that $\log=\log_{10}$ . In Italy we used often $\log=\log_e$ . I yet thought with the old notation that $\operatorname{Log}=\log_{10}.$ I not adopted often $\ln$ where the base is neperian.","['algebra-precalculus', 'logarithms']"
4861649,"Discrete Math Question with ""all"" and ""except""","I came across this question on an exam and am not sure why I am wrong. The question: Using the following predicates over the domain of people: $$A(x) = \text{x is an American.}$$ $$B(x) = \text{x likes Burgers.}$$ $$H(x) = \text{x likes Hot Dogs.}$$ Correctly represent the statement, ""All Americans like Burgers except those who like Hot Dogs."" So my answer was: $$\forall x,[A(x)\longrightarrow (B(x)\iff \neg H(x))]$$ The correct answer was: $$\forall x,[A(x) \land B(x) \longrightarrow \neg H(x)]$$ My logic for my answer is that the statement essentially says all Americans either like burgers or hot dogs. My professor justifies his answer by saying that the statement is still true even if the left hand side is false. Now, where I'm confused is I think both statements are true, and mine gives more information. I think that the 'correct' answer misrepresents the statement in the case where $A(x)$ is true, $B(x)$ is false, and $H(x)$ is false. This results in F -> T, which makes the conditional true. However, by the provided statement, this should never happen. Because, assume $H(x)$ is empty. Then we have all Americans like burgers. So $B(x)$ must be true. Then, if $H(x)$ gains people, $B(x)$ is only false when $H(x)$ is true, so this is a contradiction for the 'correct' statement. However, my answer correctly accounts for this. If someone could clarify, that would be much appreciated, thank you.",['discrete-mathematics']
4861672,Necklace with 4p beads (Burnside's lemma),"Let $p \geq 3$ be a prime number. We consider $2p$ black beads and $2p$ blue beads (both indistinguishable). How many unique necklaces of size $4p$ , created from these beads, are there? (Consider only rotations.) I need help with the Burnside's lemma. (I have not found a similar question with a satisfactory answer). The first approach (by the formula): We will use the well-known formula. The color multi-set is $B = \{1^{2p}, 2^{2p}\}$ . The number of such necklaces is: $$ 
\begin{align} 
N(B) &= \frac{1}{|B|} \sum_{d\mid\gcd(n_1 \dots  n_k)} \binom{|B|/d}{n_1/d \dots n_k/d} \phi(d) \\
&= \frac{1}{4p} \sum_{d\mid\gcd(2p, 2p)} \binom{4p/d}{2p/d \; 2p/d} \phi(d) \\
&= \frac{1}{4p} \biggl( \binom{2}{1 \; 1}\phi(2p) + \binom{2p}{p \; p}\phi(2) + \binom{4}{2 \; 2}\phi(p) \biggr) \\
&= \frac{1}{4p} \biggl( 2(p-1) + \frac{(2p)!}{(p!)^2} + 6(p-1) \biggr) \\
&= \frac{8(p-1)(p!)^2+(2p)!}{4p(p!)^2} 
\end{align}
$$ The second approach (by the Burnside's lemma): The group size is $4p$ . The Id fixes $\binom{4p}{2p}$ elements. The first rotation fixes $0$ elements. The second fixes $2$ elements. What's the pattern for $p$ ? We have to know how many beads we can color in a given rotation, then we can check whether it is even possible.","['combinatorics', 'necklace-and-bracelets', 'discrete-mathematics', 'group-theory', 'group-actions']"
4861686,Existence of a Subset $S$ of $\mathbb{N}$ Where All but Finitely Many Natural Numbers Are Sums of Consecutive Elements of $S$,"I am pondering a question in number theory that touches upon the representation of natural numbers as sums of consecutive elements from a subset S of $\mathbb{N}$ . Specifically, the question is: Does there exist a subset $S$ of $\mathbb{N}$ such that all but finitely many natural numbers are the sum of multiple consecutive elements (see addendum) in $S$ ? Considering the case where $S = \mathbb{N}$ , the natural numbers that cannot be represented as a sum of multiple consecutive elements in $S$ are precisely the powers of 2, indicating that there are infinitely many such numbers. However, does this observation extend to every possible subset $S$ of $\mathbb{N}$ ? Intuitively, I believe this might be the case for any subset $S$ , but I'm at a loss for how to approach proving or disproving this conjecture. I'm eager to see if anyone can provide insights, suggest methods for proof, or offer counterexamples. Your expertise and thoughts on this matter would be greatly appreciated. By sum of multiple consecutive elements , I mean that if you write $S = \{s_1, s_2, \dotsc\}$ with $s_1 < s_2 < \dotsb$ , then we're considering sums of the form $s_i + \dotsc + s_{i + n}$ for $n \ge 1$ .","['number-theory', 'summation', 'combinatorics', 'natural-numbers']"
4861703,Combinatorics: number of ways students can sign up to courses,"There are $n$ distinguishable students. In how many ways can they sign up to courses $A, B, C$ if each of the students can choose either $0$ , $1$ , $2$ or $3$ courses and also (*) none of the $7$ parts of Venn Diagram visualizing the problem are empty. My solution: I assumed that (*) is equivalent to simply having to subtract the number of possibilities where students didn't choose certain courses and I'll use that fact later in the solution. Let's first count the total number of ways students can sign up to the courses.
Let's consider a single student. If they choose to sign up to $0$ courses, they have $1$ possibility $=$ choosing $0$ courses. If they choose to sign up to $1$ course, they have $3$ posibilites $=$ $A$ or $B$ or $C$ . If they choose to sign up to $2$ courses, they have $3$ possibilities $=$ not choosing $A$ or $B$ or $C$ . If they choose to sign up to $3$ courses, they have $1$ possibility $=$ choosing $A$ and $B$ and $C$ . So there are $8$ options in total and since there are $n$ students, there are $8^n$ total possibilities. Next step: we have to subtract the number of possibilities where students leave parts of the Venn Diagram empty. We're gonna use the inclusion-exclusion principle to calculate them. More precisely, we need to calculate $$|A'\cup B'\cup C'| = |A'| + |B'| + |C'| - |A'\cap B'| - |A'\cap C'| - |B'\cap C'| + |A'\cap B'\cap C'|$$ where $|A'\cup B'\cup C'|$ represents the total number of ways in which we can achieve an empty part in the Venn Diagramm and for example $|A'|$ is the total number of ways in which no student chose the course $A$ . Let's do something similar as in the beginning: what is the total number of ways $|A'|$ in which no student chose course $A$ ? Let's consider a single student. If they choose to sign up to $0$ courses, they have $1$ possibility. If they choose to sign up to $1$ course, they have $2$ posibilites $=$ choosing $B$ or $C$ . If they choose to sign up to $2$ courses, they have $1$ possibility $=$ choosing $B$ and $C$ . If they choose to sign up to $3$ courses, they have $0$ possibilities. So in total, a single student has $4$ ways not to choose course $A$ and since there are $n$ students, there are $4^n$ ways to do so. This number is obviously the same for courses $B$ and $C$ . So $|A'| = |B'| = |C'| = 4^n$ . Calculating the number of possibilities where no student chooses courses $A \cup B$ is very similar. The result I got is $2^n$ and $|A' \cup B'| = |A' \cup C'| = |B' \cup C'| = 2^n$ The number of ways in which every student can choose $0$ courses is just $1$ . Now, plugging in the numbers $|A'\cup B'\cup C'| = 3*4^n - 3*2^n + 1$ , leaving the total answer equal to $$8^n - 3*4^n + 3*2^n - 1$$ I was told that my solution is far off. Any idea where I made a mistake? EDIT: Alright, so to clarify there are $7$ Venn Diagram regions and students are distinguishable (I think it makes more sense after giving it some thought). My alternate solution: Let's choose $7$ students first and place them into those $7$ Venn Diagram regions. Since they can be swapped around, let's multiply them by $7!$ to get $7!$ * $\binom{n}{7}$ total ways to place them into those $7$ regions. We're left with $n-7$ students and from what I've counted in the first solution, it'd follow that there are $8^{n-7}$ ways for them to choose courses, leaving the final answer to be $$7! * \binom{n}{7} * 8^{n-7}$$ I've done it really fast and I'm not sure how correct it is, I'd appreciate any help from there.","['solution-verification', 'combinatorics']"
4861721,Klenke's proof of Slutzky's Theorem,"In Klenke's book on probability he states Slutzky's theorem as: Let $X, X_1, X_2, \ldots$ and $Y_1, Y_2\ldots$ be random varaibles with values in $E$ . Assume $X_n \xrightarrow{\mathcal{D}} X$ and $d(X_n, Y_n) \xrightarrow{n\rightarrow \infty} 0$ in probability. Then $Y_n \xrightarrow{\mathcal{D}} X$ . Here $E$ is a metric space with metric $d$ , and $\xrightarrow{\mathcal{D}}$ means convergence in disribution, i.e. $X_n \xrightarrow{\mathcal{D}} X$ if the distributions $\mu_{X_n}$ of the $X_n$ converge weakly to the distribution $\mu_X$ of $X$ . By weak convergence he means $$\int f \mu_{X_n} \rightarrow \int f \mu_X$$ for all continuous and bounded functions $f$ . His proof is as follows: Let $f: E \rightarrow \mathbb{R}$ be bounded and Lipschitz continuous with constant $K$ . Then $$|f(x) - f(y)| \leq Kd(x,y) \wedge 2\|f\|_{\infty} \quad \text{for all } x, y \in E.$$ Dominated convergence yields $\limsup_{n \rightarrow \infty} \mathbf{E}[|f(X_n) - f(Y_n)|] = 0.$ Hence we have $$\limsup_{n\rightarrow \infty} |\mathbf{E}[f(Y_n)] - \mathbf{E}[f(X)]| \\ \leq \limsup_{n\rightarrow \infty} |\mathbf{E}[f(X)] - \mathbf{E}[f(X_n)]| + \limsup_{n\rightarrow \infty} |\mathbf{E}[f(X_n)] - \mathbf{E}[f(Y_n)]| = 0.$$ I have a few questions about this proof: Why are we only considering Lipschitz continuous functions? By the definition of weak convergence shouldn't we consider continuous and bounded functions instead? What is the point of showing $|f(x) - f(y)| \leq Kd(x,y) \wedge 2\|f\|_{\infty}$ ? It appears we do not use it in the inequalities beneath it. Why is he using $\limsup$ and not $\lim$ for the dominated convergence theorem? I thought this theorem only applies to $\lim$ . The above proof suggests there is a relationship between $X_n \xrightarrow{\mathcal{D}} X$ and $\limsup_{n\rightarrow \infty} |\mathbf{E}[f(X)] - \mathbf{E}[f(X_n)]| = 0$ . What is this relationship?","['measure-theory', 'probability-limit-theorems', 'real-analysis', 'convergence-divergence', 'probability-theory']"
4861762,Texas Hold'em Poker odds - calculating opponent's odds,"Scenario: we have reached River, i.e. there are 5 cards on the table, and three of them are hearts. I have no heart on my hand, and there are 6 remaining players other than me. What is the probability, that (at least) one of them will have (any) two hearts on hand? Now if there was just one player other than me, the computation for him I believe would be this: $$\frac{\binom{10}2}{\binom{45}2}=\frac{1}{22} \approx 4.55 \%$$ because there are $10$ remaining hearts in the unseen cards and there are $45$ unseen cards together. Is this correct so far? Now the probability for $6$ remaining players is as simple as multiplying that previous number by $6$ ? One could argue it is, because from the combination point it doesn't matter whether unknown card is in deck or in hand. But then I get this: $$22\frac{\binom{10}2}{\binom{45}2} = 100 \%$$ , exactly. But $45$ unseen cards is $22$ and a half players. So it seems the simplified calculation is not entirely correct, though close. What matters to me is, if that simplified calculation will be always close, or are there scenarios where it will be way off?","['poker', 'combinatorics', 'probability']"
4861783,"From the Central-Limit Theorem, what does a sum of IID random variables converge in distribution to?","From [1], we have the well known Lindeberg–Levy Central-Limit Theorem: [Lindeberg–Levy Central-Limit Theorem]
Suppose $X_1, X_2, \ldots, X_n$ is a sequence of  independent and identically distributed  random variables with $E[X_i] = \mu$ and $\operatorname{Var}[X_i] = \sigma^2 < \infty.$ Then, as $n$ approaches infinity, the random variable $\sqrt{n}(\bar{X}_n - \mu)$ converges in distribution  to a  normal distribution $\mathcal{N}(0, \sigma^2)$ : $$
\sqrt{n}\left(\bar{X}_n - \mu\right)\ \xrightarrow{d}\ \mathcal{N}\left(0,\sigma^2\right) .$$ I am able to go through the proof of this found in [1] without issue. What I am curious about is how to manipulate the equation $$
\sqrt{n}\left(\bar{X}_n - \mu\right)\ \xrightarrow{d}\ \mathcal{N}\left(0,\sigma^2\right)  
$$ to determine, for example, what $$
 \sum_{i=1}^n  X_i  \ \xrightarrow{d}\ ? 
$$ Imitating Alecos Papadopoulos from [2], I write that ""by abusing notation and asymptotics [2]"", I have that $$
\sum_{i=1}^n X_i  \ \approx\ 
\mathcal{N}\left(n\mu,
\left(\sqrt{n}
\sigma\right)^2
\right).
$$ Ok, I have a solution. Yet, I do not know if its correct; nor do I know how to obtain the result on my own. That's not where I would like to be. Question Can you show---without abusing notation or asymptotics---that  I can infer $$
\sum_{i=1}^n X_i  \ \xrightarrow{d}\ 
\mathcal{N}\left(n\mu,
\left(\sqrt{n}
\sigma\right)^2
\right) 
$$ from $$
\sqrt{n}\left(\bar{X}_n - \mu\right)\ \xrightarrow{d}\ \mathcal{N}\left(0,\sigma^2\right)  ?
$$ Bibliography [1] https://en.wikipedia.org/wiki/Central_limit_theorem# [2] Alecos Papadopoulos ( https://math.stackexchange.com/users/87400/alecos-papadopoulos ), Why does the central limit theorem imply that the standard deviation approaches $\frac{\sigma}{\sqrt{n}}$ ?, URL (version: 2018-07-14): https://math.stackexchange.com/q/515040","['statistics', 'probability-distributions', 'central-limit-theorem']"
4861789,How to find the coefficient of $x^k$ in the expression $\prod_{p=1}^n (x^p+1)^p$?,"This Question asked on math over flow I tried to find the indefinite integral $$ f_n(x)=\int \prod_{k=1}^n \cos^k(kx)dx$$ by using Euler's formula and put $x=\frac{\ln y}{2i}$ I got $$ f_n(x)=-i2^{-\frac{n(n+1)}{2}-1}\int y^{-\frac{n(n+1)(2n+1)}{12}-1} \prod_{k=1}^n (y^k+1)^k dy$$ now lets define $a(n,k)$ as the coefficient of $x^k$ in the expression $\prod_{p=1}^n (x^p+1)^p$ then $$ \prod_{k=1}^n (y^k+1)^k =\sum_{k=0}^{\frac{n(n+1)(2n+1)}{6}} a(n,k) y^k$$ So $$ f_n(x)=2^{-\frac{n(n+1)}{2}-1}\sum_{k=0}^{\frac{n(n+1)(2n+1)}{6}} \frac{a(n,k)}{k-\frac{n(n+1)(2n+1)}{12}} (-i)\exp\left(-2x\left(k-\frac{n(n+1)(2n+1)}{12}\right) i\right)+c $$ and where $f_n(x)$ is real So we will take the real part of the result and get $$ f_n(x)=2^{-\frac{n(n+1)}{2}-1}\sum_{k=0}^{\frac{n(n+1)(2n+1)}{6}} \frac{a(n,k)}{k-\frac{n(n+1)(2n+1)}{12}}\sin\left(2x\left(k-\frac{n(n+1)(2n+1)}{12}\right)\right)+c $$ and if $k=\frac{n(n+1)(2n+1)}{12}$ then take limit to get $\frac{\sin(2ax)}{a}=2x , a\to0$ finally if we know $$ a(n,k)=a\left(n,\frac{n(n+1)(2n+1)}{6}-k\right)$$ then $$ f_n(x)=2^{-\frac{n(n+1)}{2}} a\left(n,\frac{N}{2}\right) x+2^{-\frac{n(n+1)}{2}-1}\sum_{k=1}^{\frac{N}{2}} \frac{a\left(n,\frac{N}{2}-k\right)}{k} \sin\left(2kx\right)+c ,\text{if  } N \text{   is even}$$ and $$ f_n(x)=2^{-\frac{n(n+1)}{2}+1}a\left(n,\frac{N-1}{2}\right)\sin\left(x\right)+2^{-\frac{n(n+1)}{2}}\sum_{k=1}^{\frac{N-1}{2}} \frac{a\left(n,\frac{N-1}{2}-k\right)}{2k+1} \sin\left((2k+1)x\right)+c   ,\text{if  } N \text{   is odd}$$ where $N=\frac{n(n+1)(2n+1)}{6} $ now my QUESTIONS How to calculate $a(n,k)$ or even what is the recurrence relation? also How to prove that $a(n,k)=a\left(n,\frac{n(n+1)(2n+1)}{6}-k\right)$ ? and when we took the real part if we took the imaginary part it will be zero So How to prove $$\sum_{k=0}^{\frac{n(n+1)(2n+1)}{6}} \frac{a(n,k)}{k-\frac{n(n+1)(2n+1)}{12}}\cos\left(2x\left(k-\frac{n(n+1)(2n+1)}{12}\right)\right)=c $$","['integration', 'recurrence-relations', 'calculus', 'products', 'indefinite-integrals']"
4861859,Calculating pretty difficult limit that invloves Riemann sums,"Let $S_n = \sum_{k=1}^n\frac{1}{\sqrt{n^2+k^2}}$ . Calculate the following limit $$\lim_{n \to \infty} n\left(n\Big(\ln(1+\sqrt{2})-S_n\Big)-\frac{1}{2\sqrt{2}\,(1+\sqrt{2})}\right).$$ My intuition says that every from of $n$ times a parentheses in a form of $0 \cdot \infty$ otherwise the problem would be trivial. So let's first calculate the inner most bracket, $\ln(1+\sqrt{2})-S_n$ .
Firstly, we notice that $S_n$ is a Riemann sum. Take $f(x)=\frac{1}{\sqrt{1+x^2}}$ . Now $S_n = \sum_{k=0}^n\frac{1}{\sqrt{n^2+k^2}}=\sum_{k=0}^n\frac{1}{n}f(\frac{k}{n})$ which is the Riemann sum for $\int_0^1f(x)dx=\text{arcsinh}(x) \vert_0^1=\ln(1+\sqrt{2})$ . Now $\ln(1+\sqrt{2})-S_n$ is the difference between the area under the curve and the riemann sum. Now trying to calculate $n(\ln(1+\sqrt{2})-S_n)=\frac{\ln(1+\sqrt{2})-S_n}{\frac{1}{n}}=^{\text{Stolz-Cesaro}}=n(n+1)(S_n-S_{n+1})$ . But I am stuck here. How should I continue? $S_n-S_{n+1}$ does not look like a nice Riemann sum, and I have no idea how to actually compute it. Any tips would be gladly appreciated.","['integration', 'riemann-sum', 'analysis', 'real-analysis', 'limits']"
4861871,Die rolling contest problem,"I got this problem as part of an interview... Problem Statment: You have two players, Frank and Jane, that take turns
in rolling a fair k-sided die. Whoever rolls a k first wins the game.
The Python program should output the probability that Frank wins the
game for k=6 thru 99. That is, the output will be an array of probabilities where index 0
is the probability when k = 6; index 1 when k = 7; etc. Note that it doesn't state who goes first or put any limit on the number of rolls. I asked for clarification because it sure seems to me the probability of Frank winning is always 50%, regardless of the value of k. I believe there is a slight advantage if Frank rolls first, but that's not in the problem statement. The person responded insisting that the probability of Frank winning does depend on k. I don't see it. Very similar probably is covered here: Probability of winning a game by rolling the die first but I think that solution depends on knowing who rolls first correct?",['probability-theory']
4861876,Action of exponential of multiplication operator on $L^2$,"Let $X: L^2(\mathbb{R}) \rightarrow L^2(\mathbb{R})$ be a multiplication operator, i.e. $f(x) \mapsto xf(x)$ for $f \in L^2$ . Multiplication operators are known to be self-adjoint on some dense subset of $L^2$ , and so by Stone's theorem on one-parameter unitary groups $X$ is the infinitesimal generator of some one-parameter group of operators $U(t)$ such that $U(t) = e^{itX}$ . I am interested in explicitly finding the action of $e^{itX}$ on an $L^2$ function $f$ . In an analogy with the heat semigroup, I think this can be determined by thinking of $e^{itX}$ as the solution to the differential equation $$\partial_t f = ixf$$ but I don't think this would make sense since $f$ is only assumed to be a function of $x$ . How can one find and/or describe how $e^{itX}$ acts on $L^2$ functions? Can anything be said about $e^{tx}$ ?","['semigroup-of-operators', 'operator-theory', 'functional-analysis']"
4861895,Can $x\sin(x)$ be algebraic when it is not $0$?,"It's easy to show (using the Lindemann-Weierstrass theorem ) that, for $x\ne 0$ , at least one of $x$ and $\sin(x)$ must be transcendental. But what about $x\sin(x)$ ? After all, the product of two transcendental numbers could be algebraic. Hence: Can the product $x\sin(x)$ be non-zero and algebraic? Might it even be rational? (The requirement that $x\sin(x)\ne 0$ is meant to rule out the trivial case of $x=k\pi$ .)","['irrational-numbers', 'examples-counterexamples', 'algebraic-numbers', 'transcendental-numbers', 'trigonometry']"
4861922,How many natural numbers are needed to generate 14 distinct subsets under complement and multiplicative closure?,"Let the multiplicative closure operator $h$ be defined on $\mathcal{P}(\mathbb{N})$ by setting $hA$ equal to the smallest set containing $A$ that is closed under multiplication.
In L. F. Meyers' solution to Problem E $1941$ on pp. $408$ - $9$ of the April $1968$ American Mathematical Monthly ( https://www.jstor.org/stable/2313449 ) it is shown that the set $A=\{2,3,14,15,25\}$ generates $14$ distinct subsets under $h$ and the complement operator $c$ on $\mathbb{N}.$ An editorial comment at the end then asks: What is the size of the smallest set having the desired property? I've never seen this problem mentioned anywhere else, so would guess it is still unsolved. The ""Answer added Nov. 18"" section of this answer proves that no Kuratowski 14-set has cardinality $1$ or $2$ in a topological space $X{:}$ https://math.stackexchange.com/a/186428/32209 The proof also works for a general closure operator (any operator that is extensive, idempotent, and isotonic) not just a topological one, so the answer to the question above is $3$ , $4$ , or $5.$ * Given the power of modern computers, maybe someone can find a tripleton of natural numbers that generates the maximum possible number of $14$ distinct subsets under $h$ and $c$ ? * $h$ is clearly extensive $(A\subseteq hA$ for all $A)$ , idempotent $(hh=h)$ , and isotonic $(A_1\subseteq A_2\implies hA_1\subseteq hA_2).$ It is not a topological closure operator though because, for example, $6\in h\{2,3\}\setminus(h\{2\}\cup h\{3\}).$ ---------------- update added 15 Feb 2024, edited 28 Feb 2024 ---------------- 1. It is noteworthy that the set $A$ in the Monthly equals $\{p_1,p_2,p_1p_4,p_2p_3,p_3^2\}$ where $p_1,p_2,p_3,p_4$ are the first four primes. We could obviously substitute any four distinct primes and get the same result. 2. In light of the proof above, it may have been necessary for Meyers to use all four primes to distinguish $hjhA$ from $jhA.$ 3. Before taking a close look at this question, I thought the answer would turn out to be $3.$ Now I suspect it is $5.$ 4. The problem editors were slightly off target when they wrote ""Another proof [that $14$ is the maximum number of sets obtainable under $h$ and $c$ ] is given in J. L. Kelley, General Topology , p. $57.$ "" because it ignores the distinction between the (topological) closure operator in Kelley and the more general one here.","['elementary-set-theory', 'elementary-number-theory', 'general-topology', 'optimization']"
4861925,"Why is this differential equation's interval not (-$\infty$, $\infty$)","I am currently using A First Course in Differential Equations with Modeling Applications, 10th Edition, by Dennis G. Zill. Section 2.3 Question #9. Find the general solution of the given differential equation. Give the largest interval $I$ over which the general solution is defined. Determine whether there are any transient terms in the general solution. The differential equation given was: $$
x\frac{dy}{dx} - y = x^2 \sin(x)
$$ Here is my work: Divide by $x$ to get the standard form: $$
\frac{dy}{dx} - \frac{1}{x} y = x \sin(x)
$$ Implement integrating factor: $$
\mu = \exp\biggl(\int{-\frac{1}{x}}\,dx\biggr) 
= e^{-\ln(x)} = e^{\ln(x^{-1})} = \frac{1}{x}
$$ Multiply both sides by the integrating factor: $$
\frac{dy}{dx}\frac{1}{x} - \frac{1}{x^2}y = \sin(x)
$$ Notice the derivative of a product: $$
\frac{dy}{dx} \biggl[ y \, \frac{1}{x} \biggr] = \sin(x)
$$ Take the integral of both sides: $$
\int \frac{dy}{dx} \biggl[ \frac{y}{x} \biggr] \, dx 
= \int \sin(x) \, dx 
\quad\implies\quad 
\frac{y}{x} = -\cos(x) + C
$$ Multiply both sides by $x$ : $$
y = -x\cos(x) + Cx 
\quad\text{or}\quad 
y = Cx - x\cos(x)
$$ My answer and the book's answer matched but the back of the book had $(0, \infty)$ as the interval. My question is why the interval is not $(-\infty, \infty)$ when $y$ is defined and continuous for all $x$ .","['continuity', 'analysis', 'ordinary-differential-equations', 'real-analysis']"
4861927,Proof $\pi$ is transcendental without symmetric function theory,"Recently for a bonus homework assignment in my algebra class, I was asked to review the literature and write up a proof that $\pi$ is transcendental. Essentially every source I found (""The Transcendence of $\pi$ "" by Steve Mayer for example) presents the classic proof of Lindemann, which heavily relies on symmetric function theory and in particular the fundamental theorem of elementary symmetric functions. Before this assignment, I did not know symmetric function theory, and by far the biggest difficulty in my solution and write up was understanding this theory and the argument used in the proof (which in my opinion, was not spelled out enough for a beginner to the theory to easily understand the argument in the sources I consulted). Now, symmetric function theory was useful to learn, and I am aware it is very useful in the proof of the Lindemann-Weierstrass theorem, but it begs the question: Is there any proof (preferably understandable to approximately a beginning graduate student) that $\pi$ is transcendental, without using symmetric function theory, and if not, is there a theoretical explanation for why? Edit: Crossposted to MO after 2.5 weeks https://mathoverflow.net/questions/466288/proof-pi-is-transcendental-without-symmetric-function-theory","['number-theory', 'abstract-algebra', 'pi', 'transcendental-numbers']"
4861960,Postive definiteness of block matrix,"I'm going to write a lower-size version of my question. The Solution or hint for this one might be sufficient as well. Let $G=\begin{bmatrix} A & B\\
C&D
\end{bmatrix}
$ where $$A_{11}=2C_{1}^{\frac{1}{2}}(\langle\eta_1,\eta_1\rangle)=2$$ $$A_{12}=2C_{1}^{\frac{1}{2}}(\langle\eta_1,\eta_2\rangle) +i(\eta_{11}\eta_{22}-\eta_{12}\eta_{21})C_{0}^{\frac{3}{2}}(\langle\eta_1,\eta_2\rangle)$$ $$A_{21}=\overline{A_{12}}$$ $$A_{22}=2C_{1}^{\frac{1}{2}}(\langle\eta_2,\eta_2\rangle)=2$$ So $A$ is a hermitian matrix. $$B_{11}=0$$ $$B_{12}=(\eta_{11}\eta_{23}-\eta_{13}\eta_{21})C_{0}^{\frac{3}{2}}(\langle\eta_1,\eta_2\rangle) +i(\eta_{12}\eta_{23}-\eta_{13}\eta_{22})C_{0}^{\frac{3}{2}}(\langle\eta_1,\eta_2\rangle)$$ $$B_{21}=-B_{12}$$ $$B_{22}=0$$ $$C=-\overline{B}$$ i.e., $C_{11}=C_{22}=0, $ $C_{12}=-\overline{B_{12}}, $ and $C_{21}=\overline{B_{12}}$ ,
and $$D=\overline{A}$$ i.e., $D_{11}=D_{22}=2, $ $D_{12}=\overline{A_{12}}, $ and $D_{21}=A_{12}$ . where $\eta_{i}=(\eta_{i1},\eta_{i2},\eta_{i3})$ (we have only two points) are the points on the unit sphere. And $\langle\cdot,\cdot\rangle$ is the inner product. Prove that $G$ is positive definite for almost every random choice of points. Edit after a comment \begin{align*}
	\det(G)&=16+\vert A_{12}\vert^{4}-\vert B_{12}\vert^{4}-8(\vert A_{12}\vert^{2}+\vert B_{12}\vert^{2})\\
           &\;\;\; +2\vert A_{12}\vert^{2}\vert B_{12}\vert^{2}+(\vert A_{12}\vert^{2}S+\vert B_{12}\vert^{2}T)i-TS
\end{align*} where \begin{align*}
	\vert A_{12}\vert^{2}&=4 \big(C_{1}^{\frac{1}{2}}(\langle \eta_{1},\eta_{2} \rangle)\big)^{2}+(\eta_{11}\eta_{22}-\eta_{12}\eta_{21})^{2} \big( C_{0}^{\frac{3}{2}}(\langle \eta_{1},\eta_{2} \rangle)\big)^{2}\\
	\vert B_{12}\vert^{2}&=(\eta_{11}\eta_{23}-\eta_{13}\eta_{21})^{2} \big( C_{0}^{\frac{3}{2}}(\langle\eta_1,\eta_2\rangle)\big)^{2} +(\eta_{12}\eta_{23}-\eta_{13}\eta_{22})^{2} \big( C_{0}^{\frac{3}{2}}(\langle\eta_1,\eta_2\rangle)\big)^{2}\\
	T&=4\, C_{1}^{\frac{1}{2}}(\langle \eta_{1},\eta_{2} \rangle)\, C_{0}^{\frac{3}{2}}(\langle \eta_{1},\eta_{2} \rangle)\, (\eta_{11}\eta_{22}-\eta_{12}\eta_{21})\\
	S&=2\,\big(C_{0}^{\frac{3}{2}}(\langle \eta_{1},\eta_{2} \rangle)\big)^{2}\, (\eta_{11}\eta_{23}-\eta_{13}\eta_{21})\, (\eta_{12}\eta_{23}-\eta_{13}\eta_{22})\\
\end{align*} I understand that $C_{1}^{\frac{1}{2}}(\langle \eta_{1},\eta_{2} \rangle)=\langle \eta_{1},\eta_{2} \rangle=\cos(\theta)$ and $C_{0}^{\frac{3}{2}}(\langle \eta_{1},\eta_{2} \rangle)=1$ . But even after this it's not obvious that the determinant is nonzero.","['matrices', 'positive-definite', 'block-matrices']"
4861963,Eigenvalues of a weighted mean where the weights are positive definite matrices,"Suppose I have some positive definite matrices $A_1, A_2, \dots A_k \in \mathbb{R}^{n \times n}$ and some values $s_1 \leq s_2\dots \leq s_k \in \mathbb{R}$ . Consider the matrix $A = (\sum_{k=1}A_k s_k)(\sum_{k=1} A_k)^{-1}$ . For $n=1$ (the scalar case), $A$ becomes a weighted mean of the $s_i$ 's, and thus necessarily satisfies $s_1 \leq A \leq s_k$ . For higher $n$ , can we say that the eigenvalues of $A$ must lie between $s_1$ and $s_k$ ? I'm particularly interested if this can be shown (or disproven) in the special case where each $A_k$ is of the form $A_k = x_k x_k^\top$ .","['matrices', 'linear-algebra', 'positive-definite', 'eigenvalues-eigenvectors']"
4862066,Prove that $\mathbb{E}\exp{\lambda\xi} \le \exp\left(\lambda^2 \Vert\xi\Vert_{\psi_2}^2\right)$,"Problem: Let $\xi$ be a real random variable. We say that $\xi$ is $\psi_2$ when $\exists \lambda >0$ such that $\mathbb{E}\exp(\xi^2/\lambda^2) \le e$ . We denote by $\Vert \xi \Vert_{\psi_2}$ the infimum of such $\lambda$ , that is \begin{align*}
    \Vert \xi \Vert_{\psi_2} = \inf\left\{\lambda > 0: \mathbb{E}\exp(\xi^2/\lambda^2) \le e\right\}.
\end{align*} Suppose that $\xi$ is $\psi_2$ and that $\mathbb{E}\xi = 0$ . Prove that $\forall \lambda >0$ $$\mathbb{E}\exp(\lambda \xi) \le \exp\left(\lambda^2 \Vert \xi\Vert_{\psi_2}^2\right).$$ My attempt: By using the inequality $e^{y} \le y+ e^{y^2}$ , we have \begin{align*}
    \mathbb{E}\exp(\lambda \xi) &= \int_{-\infty}^{+\infty}\exp(\lambda t) f_{\xi}(t) dt\\
    & \le \int_{\infty}^{+\infty}(\lambda t + e^{\lambda^2 t^2})f_\xi(t) dt\\
    & \le \lambda \int_{-\infty}^{+\infty}t f_\xi(t)dt + \int_{-\infty}^{+\infty}e^{\lambda^2 t^2}f_\xi(t)dt \\
    & = \lambda \mathbb{E}\xi + \int_{-\infty}^{+\infty}e^{\lambda^2 t^2}f_\xi(t)dt = \int_{-\infty}^{+\infty}e^{\lambda^2 t^2}f_\xi(t)dt  \tag{since $\mathbb{E}\xi = 0$}\\
& = \mathbb{E}[\exp(\lambda^2 \xi^2)]\\
& = \mathbb{E}\left[\left(\exp(\xi^2/\Vert \xi\Vert_{\psi_2}^2)\right)^{\lambda^2\Vert \xi \Vert_{\psi_2}^2}\right]
\end{align*} Now I am stuck here. I intended to use Jensen's inequality but the function in the exponential is not concave. Hints: I have just got a hint as follows Consider two cases are $\lambda \in ]0,1]$ and $\lambda > 1$ . When $\lambda \in ]0,1]$ use the inequality $e^y \le y + e^{y^2}$ , while for $\lambda >1$ , use the fact that $\lambda \xi \le \dfrac{1}{2}\lambda^2 + \dfrac{1}{2}\xi^2$ .","['inequality', 'probability-distributions', 'probability', 'random-variables']"
4862100,Prove that triangles $VAC$ and $VBD$ have equal areas and equal perimeters....,"The question Let $VABCD$ be a quadrilateral pyramid with a rectangular base. $\angle AVC =\angle BVD$ prove that triangles $VAC$ and $VBD$ have equal areas and equal perimeters. The idea Because the base ABCD is rectangular we get that $DB=AC$ . We also know the congruences of the angles, so I was thinking of showing that VDB is congruent with VDC this will make the perimeters and the areas equal. I don't know how to show this. I hope one of you can help me! Thank you!","['rectangles', 'angle', 'area', 'geometry']"
4862205,Probability that one random number among many has a unique prime factor,"If I sample $N+1$ integers $x, x_1, \ldots, x_N$ uniformly and independently from $\{1, \ldots, M=2^k\}$ , what is the probability that $x$ contains a prime divisor that does not divide any of the $\{x_i\}$ ? Upper/lower bounds and/or asymptotic approximations would also be of interest. For prime $p$ and $x, x_1, \ldots, x_N$ as above, say $x$ is $p$ -unique if $p | x$ and $p \nmid x_1, \ldots, p \nmid x_N$ . For any fixed and sufficiently small prime $p$ (say, $p \leq \sqrt{M}$ ), the probability that $x$ is $p$ -unique is $\frac{1}{p} \cdot \left(1-\frac{1}{p}\right)^N$ . One can try to lower bound $\Pr[\vee_p \hspace{2pt} \mbox{$x$ is $p$-unique}]$ using the inclusion-exclusion principle and treating the events that $x$ is $p_1$ -unique and $p_2$ -unique as independent when $p_1, p_2$ are both sufficiently small (and distinct). Doing so gives a lower bound of $\sum_{p} \frac{1}{p} \left(1-\frac{1}{p}\right)^N - \sum_{p_1 \neq p_2} \frac{1}{p_1p_2} \left(1-\frac{1}{p_1}\right)^N \left(1-\frac{1}{p_2}\right)^N$ (where the sums are over sufficiently small primes). But I didn't know where to go from there. This seems like a problem that would have been studied before in the context of multiplicative number theory but I have not managed to find any references.","['prime-numbers', 'number-theory', 'analytic-number-theory', 'multiplicative-function', 'probability']"
4862213,Understanding a measurabiliy statement from Section 6.3 in Lehmann and Romano,"This paragraph is at the end of Section 6.3 in the book Testing Statistical Hypotheses by Lehmann and Romano: In most applications, $M(x)$ is a measurable function taking on values in a
Euclidean space and it is convenient to take $\mathcal B$ as the class of Borel sets. If $\phi(x) = \psi[M(x)]$ is then an arbitrary measurable function depending only on $M(x)$ , it
is not clear that $\psi(m)$ is necessarily $\mathcal B$ -measurable. This measurability can be
concluded if $\mathcal X$ is also Euclidean with $\mathcal A$ the class of Borel sets, and if the range of $M$ is a Borel set. We shall prove it here only under the additional assumption
(which in applications is usually obvious, and which will not be verified explicitly
in each case) that there exists a vector-valued Borel-measurable function $Y(x)$ such that $[M(x), Y (x)]$ maps $\mathcal X$ onto a Borel subset of the product space $\mathcal M\times \mathcal Y$ , that this mapping is $1 : 1$ , and that the inverse mapping is also Borel-measurable. Given any measurable function $\phi(x)$ of $x$ , there exists then a measurable function $\phi'$ of $(m, y)$ such that $\phi(x) ≡ \phi' [M(x), Y (x)]$ . If $\phi$ depends only on $M(x)$ , then $\phi'$ depends only on $m$ , so that $\phi'$ $(m, y) = \psi(m)$ say, and $\psi$ is a measurable function of $m$ . I don't understand how to formalize the argument: How to choose $\phi'$ ? Why $\phi'$ depends only on $m$ if $\phi$ depends only on $M(x)$ ? Where do we need $Y(x)$ to be 1:1 with measurable inverse and measurable range? Can someone clarify the argument? Edit: Why is $\psi(m)$ a measurable function of $m$ ?","['measure-theory', 'statistical-inference', 'statistics', 'proof-explanation', 'measurable-functions']"
4862216,"Determine the real numbers $a, b, c, d \in [1,3]$, knowing that the relation $(a + b + c + d)^2 = 3(a^2 + b^2 +c^2 + d^2)$.","the question Determine the real numbers $a, b, c, d \in [1,3]$ , knowing that the relation $(a + b + c + d)^2 = 3(a^2 + b^2 +c^2  + d^2)$ . my idea $(a+b+c+d)^2=a^2+b^2+c^2+d^2+2(ab+ac+ad+bc+bd+cd)$ $=> 2(ab+ac+ad+bc+bd+cd)=2(a^2 + b^2 +c^2  + d^2)=> ab+ac+ad+bc+bd+cd=a^2 + b^2 +c^2  + d^2$ From here I've been trying to get it to a form where 0 will equal the product of some numbers but I didn't get to anything helpful. I hope one of you can help me! Thank you!","['algebra-precalculus', 'square-numbers']"
4862238,"If $\sum \|f_i\|$ converges and $\sum_{i=1}^\infty f_i$ exists in a normed function space, do we get for free that $\|\sum_{i=1}^n f_i - f\| \to 0$?","Let $(V,\|-\|)$ be a normed function space, and suppose that $(f_i)_i$ is a sequence of elements of $V$ so that $\sum \|f_i\| < \infty$ . Further suppose that this data implies that $f = \sum f_i$ , where $\sum_{i=1}^n f_i \to f$ pointwise , is an element of $V$ . Then I would think that we can show immediately that $\sum_{i=1}^n f_i \to f$ in norm, as: $$\left\|\sum_{i=1}^n f_i - f \right\| = \left\|\sum_{i=1}^n f_i- \sum_{i=1}^\infty f_i\right\| = \left\|\sum_{i=n+1}^\infty f_i\right\| \leq \sum_{i=n+1}^\infty \|f_i\|$$ which is sensible, as we can show that any tail of $\sum f_i$ is in $V$ as well. However, as $\sum \|f_i\| < \infty$ , it follows that the right-hand-side goes to zero as $n \to \infty$ , thus proving that $\sum_{i=1}^n f_i \to f$ in norm. Here is my question: Have I made a mistake in the above reasoning? The reason I am suspicious is because whenever I have seen an example of this situation in books (e.g., showing $L^p$ is a Banach space), the author shows convergence in norm using some other method dependent on the properties of the norm being considered. However, I cannot determine where the reasoning could break down.","['convergence-divergence', 'normed-spaces', 'functional-analysis']"
4862256,How many ways can a cube fit into a sphere through its vertices?,"I mean, we know that every cube has 8 vertices. Now imagine a sphere with a fixed radius. Cubes can have arbitrary sides, one way is this.  that there are no vertices on the sphere and the entire cube is inside the sphere, the other case is that the cube has only one vertex on the points of the sphere and the other 7 are inside the sphere.
Now comment on the rest of the states, i.e. 2, 3, 4, 5, 6, 7, and 8 vertices on the points of the sphere.
Comment which ones are impossible?
My idea is that states 3, 5, 6, and 7 are impossible
Of course, it is difficult to explain because each of them has different states, for example, three vertices is impossible because either all three must be in the same plane, in which case a rectangular sphere will not be formed in the circular cross-section, or with two vertices in the same plane.  be in another plane, which is also impossible because if two vertices are in the plane, it will eventually lead to 4 vertices on the points of the sphere.","['spheres', 'geometry', 'spherical-geometry']"
4862277,Proving $3^{100} > 5\cdot10^{47}$ with integral representation,"I want to prove that $3^{100} > 5\cdot10^{47}$ without using calculator or any approximation of the logarithm.
I tought about finding an integral representation of $(3^{100} - 5\cdot10^{47})$ with the integrand non negative in the chosen integration interval (something like this ), but I don't know how to chose the integrand. Do you have any ideas?
Or even any elegant way to prove the inequality?","['integration', 'inequality', 'number-comparison']"
4862303,Definition of hypergraph homomorphism,"W.Dörfler and D.A.Waller's paper ""A category-theoretical approach to hypergraphs"" gives the following definitions: A hypergraph is a triple $H = (V,E,f)$ where $V$ is the set of vertices, $E$ is the set of (hyper)edges and $f \colon E \to \mathcal{P}(V) \smallsetminus \{\emptyset\}$ is the function associating with every edges its edges. A hypergraph homomorphism from $H_1 = (V_1, E_1, f_1)$ to $H_2 = (V_2, E_2, f_2)$ is a pair of functions $h = (h_V \colon V_1 \to V_2, \ h_E \colon E_1 \to E_2)$ such that $h_V(f_1(e)) = f_2(h_E(e))$ for all $e \in E_1$ (by abuse of notation, if $f\colon X \to Y$ and $X' \subseteq X$ , then I set $f(X') = \{f(x) \mid x \in X'\}$ ). Note that this definition of hypergraphs allows loops (an edge connecting only a vertex with itself) and multiple edges (the same set of vertices can be connected by several edges). My questions are the following. What happens if we relax the definition of hypergraph homomorphism by requiring only that $h_V(f_1(e)) \subseteq f_2(h_E(e))$ for all $e \in E_1$ ? Which is the intuitive reason why we do not have a hypergraph homomorphism if $h_V(f_1(e)) \not\supseteq f_2(h_E(e))$ for some $e \in E_1$ ? Has the relaxed definition any pathological consequence? The authors say that In the case of hypergraphs which are graphs [that is, the cardinality of $f(e)$ is $1$ or $2$ for all $e \in E$ ], we note that the above definition
reduces to the usual one of graph homomorphism: $h$ sends vertices to vertices and
edges to edges, thus preserving adjacency of vertices. Does it hold even in the more relaxed definition of hypergraph homomorphism? I can't visualize any bad or paradoxical consequence of the relaxed definition of hypergraph homomorphism. On the contrary, it seems to me that only with the relaxed definition it holds that the trivial injection of a sub-hypergraph is always a hypergraph morphism (I assume that a hypergraph $H_1 = (V_1, E_1, f_1)$ is a sub-hypergraph of a hypergraph $H_2 = (V_2, E_2, f_2)$ if $V_1 \subseteq V_2$ and $E_1 \subseteq E_2$ and $f_1(e) = f_2(e) \cap V_1$ for all $e \in E_1$ ).
Moreover, it seems to me that the answer to question 2 is positive.","['graph-theory', 'category-theory', 'hypergraphs', 'definition', 'discrete-mathematics']"
4862329,A small lemma on cache resets (Bloom filters in particular),"Assume a fixed set of message $D$ and an associated distribution for selecting each message $d_i$ such that the total probability $\sum_{i \in D} d_i = 1$ . We create a cache with $M$ bits and $k$ hashes, where each message from $D$ gets mapped to $k$ unique entries between $[1,M]$ (i.e., a Bloom Filter). More formally, a Bloom filter is an array of $M$ bits initially set to 0. It employs $k$ hashes, each of which maps or hashes some set element to one of the $m$ array positions with a random distribution. These functions are denoted by $h_1,h_2, \cdots, h_k$ . To add an element $x$ to the Bloom Filter, we compute $k$ hash functions to determine the $k$ positions in the bit array and set the bits to these positions to 1. In other words, $h_i(x) = 1$ for the $i$ selected. We introduce a random variable $Y_j$ to represent the count of occupied slots in the Bloom Filter at the $j$ -th iteration. Furthermore, we assume that once $Y_j$ reaches or exceeds a threshold $\sigma$ , the Bloom Filter is reset such that the $M$ bits are set to 0 and the process concludes. I am interested in proving the following lemma: Let $X_{j} = \mathbb{1}_{Y_j \geq \sigma\; | \; Y_{j-1} < \sigma}$ (i.e. the $j+1$ -st draw to result in a reset given that it did not in the $j$ -th draw), then $P(X_j = 1) \leq P(X_{j+1} = 1)$ . I am finding it challenging to prove this lemma. I have verified its validity via simulations and it seems to hold. I can also brute force the computation for very simple cases and it also works. Please note that this situation differs from demonstrating that for $X'_{j} = \mathbb{1}_{Y_j \geq \sigma}$ , the property $P(X'_j = 1) \leq P(X'_{j+1} = 1)$ is relatively simple to establish using a sample path argument. I mention this because I originally thought that the proof would be trivial using this argument. The main difficulty arises because, for any specified number of set bits, it's possible to construct sequences of messages of any length that have resulted in that filter being filled. I would appreciate any help. A counter-example would also do the trick. Thanks!","['computer-science', 'statistics', 'probability', 'algorithms']"
4862362,Finding the expectation of the smallest value when $k$ numbers is taken from $1$ to $n$,"Let X be the smallest value obtained when k numbers are randomly chosen from the set 1,...,n. Find E[X] by interpreting X as a negative hypergeometric random variable. This is Self Test Exercise 7.7 of Sheldon's A First Course in Probability. The way I approached this is to first consider (for example) P(X = 1). Using the suggestion to take X as a negative hypergeometric random variable, we have $$P(X = 1) = \frac{\binom{1}{1}\binom{n - 1}{k - 1}}{\binom{n}{k}}$$ My idea was that we have one element 1 and the rest $k - 1$ elements from ... the remaining $n - 1$ elements. Similarly, for $P(X = 2)$ , we have one way of getting the minimum element $2$ , and $\binom{n - 2}{k - 1}$ ways of getting the other elements (well, except 1). Similarly, we can deduce that $$P(X = i) = \frac{\binom{n - i}{k - 1}}{\binom{n}{k}}$$ As a result, I got $$E(X) = \sum_{i = 1}^n i \times \frac{\binom{n - i}{k - 1}}{\binom{n}{k}}$$ The answer in the book is $\frac{n + 1}{k + 1}$ , which is just so much more elegant than what I came up with, and I'm not seeing how my answer reduces to theirs. My questions are: Is my approach correct? If not, what mistake(s) did I make in my analysis? If my answer is correct, how do I get to the expected result?","['expected-value', 'probability']"
4862378,Why does replacing $\cosh$ by $\cos$ in this biquadratic integral not change anything?,"TLDR; can I do the second integral with the method I used for the first integral? I was reading about some integrals when I saw the following: $$\int_{0}^{\infty}\frac{dx}{x^4+2x^2\cosh(2t)+1} = \frac{\pi}{4\cosh(t)}$$ The way to do this is to write the denominator as $(x^2+e^{2t})(x^2+e^{-2t})$ and then this is simple $\arctan$ integral after partial fraction decomposition. Then I saw another integral where cosh is replaced by cos, ie. $$\int_{0}^{\infty} \frac{dx}{x^4+2x^2\cos(2t)+1}= \frac{\pi}{4\cos(t)}$$ but the way to do this integral is quite different, and in fact quite difficult (you need to do a $1/x$ sub, then add the two resulting things, then write it as half of $-\infty$ to $+\infty$ integral, then add $2x\sin(t)$ to numerator, and then you get arctan). Basically there is no way I could have thought of this... However, even before seeing the solution to the second problem, I guessed the correct answer, and basically my reasoning was that $\cosh(2it)=\cos(2t)$ or basically in cos we just have an $i$ in the exponent and the rest of the 'form' is basically the same, so the answer should not make a difference... (so basically I thought I could do this the same way as I did the cosh integral, factorise denominator as $(x^2+e^{2it})(x^2+e^{-2it})$ and then do partial fraction stuff, but the thing is I am not familiar with using complex numbers in integrals yet, like I don't know if this type of thinking is valid or if this is mathematically possible to do integration with complex numbers...
So that is my question essentially; I want to see if it is possible to do the second integral in the way we did the first integral, and if so how? Also I would really appreciate any books/handouts/resources for learning how to do this if possible...","['integration', 'complex-analysis', 'definite-integrals']"
4862410,Show that $\frac {S_n} {n} \xrightarrow {p} 0.$,"Let $\{X_n\}_{n \geq 1}$ be a sequence of iid random variables with pdf $$f(x) = \begin{cases} \frac {c} {x^2 \log |x|}, & |x| \gt 2, \\ 0, & \text {otherwise}, \end{cases}$$ where $c$ is a normalizing constant. Let $S_n = \sum\limits_{k=1}^{n} X_k.$ Show that $\frac {S_n} {n} \xrightarrow {p} 0.$ Let us take $\varepsilon \gt 0.$ We need to show that $\mathbb P \left [\left \lvert \frac {S_n} {n} \right \rvert \gt \varepsilon \right ] \to 0$ as $n \to \infty.$ It is clear that $X_n$ 's have infinite mean and hence we cannot apply WLLN to conclude the result. By rough estimates we get $$\mathbb P \left [\left \lvert \frac {S_n} {n} \right \rvert \gt \varepsilon \right ] \leq n\ \mathbb P [|X_1| \gt \varepsilon]$$ which also does not seem to help much. Any idea?","['convergence-divergence', 'probability-theory']"
4862423,Definition of the Krull dimension of a topological space,"Let $X$ be a topological space. It is irreducible if it can not be written as a union of $U$ and $V$ where $U,V$ are proper closed subsets of $X$ . A chain of irreducible closed subsets of $X$ is a sequence $$
Z_0\subsetneq Z_1\subsetneq\cdots \subsetneq Z_n\subset X
$$ where each $Z_i$ is an irreducible closed subset of $X$ . For each of the chain, its length is either $\infty$ or the integer $n$ , and we define the Krull dimension $\dim(X)$ to be the supremum of lengths of chains of irreducible closed subsets of $X$ . I am a little bit confused about the definition. For each chain, do we allow $Z_n$ to be $X$ (say, $X$ is an irreducible closed subset)? If the only irreducible subsets of $X$ are the one-point sets and itself, is its dimension $0$ or $1$ ? Thank you!","['general-topology', 'algebraic-geometry']"
4862439,Does the existence of a continuous function on a topological space imply that that space is Hausdorff?,"It makes sense to me that this would be true but I am not sure. My understanding of (at least one of the definitions of) a continuous function is that for every point $p$ in the functions, domain, there exsits a neighborhood $N$ around that point There is a neighborhood $f(N)$ in the function's image that corresponds to $N$ As the width of $N$ shrinks to $0$ , so does the width of $f(N)$ This seems to imply that the topological space the function is defined on is Hausdorff, since for any two points $p_1$ and $p_2$ in the space, we can always find a neighborhood around $p_1$ that does not include $p_2$ and vice versa. Otherwise, our function could not be continuous at $p_1$ or $p_2$ . If this is not true, are there any other conditions on the function or the space that could make this true?","['continuity', 'general-topology']"
4862474,Ask a question on adjoint operator?,"Let $H_1,H_2$ be Hilbert spaces with inner products $\langle \cdot, \cdot \rangle_1$ and $\langle \cdot, \cdot \rangle_2$ . Corresponding to every $T \in \mathcal B(H_1,H_2)$ , there is a unique element $T^*$ of $B(H_2,H_1)$ determined by the relation $$\langle T x_1,  x_2 \rangle_2=\langle x_1, T^* x_2 \rangle_1$$ for all $x_1 \in H_1, x_2 \in H_2$ . Proof: Consider $\langle T x_1,  x_2 \rangle_2$ as a function of $x_1$ for fixed $x_2$ . It is bounded and linear so that the Riesz representation theorem may be applied to see that there exists a unique $y \in H_1$ such that $\langle T x_1,  x_2 \rangle_2=\langle x_1, y \rangle_1$ . Thus, we take $T^* x_2=y$ . This definition gives us a linear mapping. To see that it bounded first note that $T$ is necessarily the adjoint of $T^*$ . Then $$|| T^* x_2 ||^2_1=   |       \langle      x_2，T  T^*    x_2 \rangle_2  |$$ $$\leq ||T||   || T^* x_2 ||_1   ||x_2||_2$$ Question: Why $|| T^* x_2 ||^2_1=   |       \langle      x_2，T  T^*    x_2 \rangle_2  |$ ?","['proof-explanation', 'adjoint-operators', 'functional-analysis']"
4862475,Expected path length in a ladder-like graph if edges can be randomly removed.,"Question from an old exam: The King of Squares sets out to patrol the City of Squares. The City of Squares is an infinite ladder, i.e., a graph $(V, E)$ where $V = \mathbb{N} \times \{0,1\}$ and the vertex $(x, y)$ is connected to $(x-1, y)$ for $x>0,(x+1, y)$ and $(x, 1-y)$ . Unfortunately, due to the revolt, some parts of the streets are blocked. Each edge independently becomes blocked with probability $\frac{1}{2}$ . The king leaves his palace at the point $(0,0)$ . Let $X$ be the largest value of the coordinate $x$ that the King can reach without passing through the blocked streets. The king can look ahead, so he will choose the best route before he sets off. In the situation in the image below $X=5$ . (a) Find EX. (b) Find the probability that both points $(X, 0)$ and $(X, 1)$ are reachable. My attempt at (a): Let $$
X_i = \begin{cases}
    i, & \text{if it's possible to reach $(i, 0)$ or $(i,1)$} \\
    0, & \text{otherwise}.
\end{cases}
$$ Now we need to find the probability $p(i)$ that it is possible to reach the point $(i, 0)$ or $(i,1)$ . I have calculated that $p(i) = \frac{5}{8} p(i-1)$ , where $p(1) = \frac{5}{8}$ . This is derived from the idea that the probability of going from coordinate $ (x, 0)$ , to $(x+1, 0)$ or $(x+1, 1)$ is $\frac{5}{8}$ . Then $E[X]=\sum_{i=1}^{\infty}E[X_i]=\sum_{i=1}^{\infty}i\cdot(\frac{5}{8})^i = \frac{40}{9} 	\approx 4.44$ . Is this correct? How to do (b), because I don't know where to start?","['expected-value', 'probability']"
4862493,Evaluate $\int^{\infty}_{-\infty}\sin(xe^x)dx$,I recently learned $\int^{\infty}_{-\infty}\sin(e^x)dx$ can be solved like this: $$\int_{-\infty}^{\infty}\sin(e^x)dx$$ $$\int^{\infty}_{-\infty}\frac{\sin(e^x)}{e^x}e^xdx$$ $$\int^{\infty}_{0}\frac{\sin(u)}{u}du$$ $$\operatorname{Si}(e^x)|^\infty_{0}=\frac{\pi}{2}$$ It inspired me to come up with this integral which wolfram alpha approximates to $-0.98771815$ . I employed a similar strategy on my integral: $$\int_{-\infty}^{\infty}\sin(xe^x)dx=\int_{-\infty}^{\infty}\frac{\sin(xe^x)}{xe^x+e^x}(xe^x+e^x)dx=\int_{0}^{\infty}\frac{\sin(u)}{u+e^{W(u)}}du\\=\int_{0}^{\infty}\frac{\sin(u)}{u+\frac{u}{W(u)}}du=\int_{0}^{\infty}\frac{\sin(u)W(u)}{u(1+W(u))}du$$ I don't know how to solve this so I tried a different substitution: $$\int_{-\infty}^{\infty}\sin(xe^x)dx=\int_{-\infty}^{\infty}\frac{\sin(xe^x)}{e^x}e^xdx=\int_{0}^{\infty}\frac{\sin(\ln(u)u)}{u}du$$ I feel like I am close here but I don't know how to progress.,"['integration', 'improper-integrals', 'definite-integrals']"
4862499,Question about theorem 9.21 in Rudin's PMA,"The theorem in question is: Now, the part that I have a problem is the following highlighted text: Theorem (5.10) is I don't understand what function plays the role of $f$ at (5.10). What i've tried is the function $$g(t)=f(x+v_{j-1}+th_je_j)$$ But its derivative depends on the deriative of $f$ which I don't know it exists yet.","['mean-value-theorem', 'derivatives']"
4862503,Proving $\sum_{i=m+1}^\infty \frac{m!^{i/m}}{i!}<1$.,"One of this days, the user @AspiringMat was trying to prove that, for any integer $m\ge 1$ , $$\sum_{i=m+1}^\infty \frac{m!^{i/m}}{i!}<1.$$ and asked for help here on MSE. I've spent too much of my time attempting to solve this. However when I finally got to it, I realized he deleted the question ! I really don't want all my effort to be wasted, so... I'm asking and answering his question once again here. My solution is really messed up, so feel free to post your own as well.","['sequences-and-series', 'taylor-expansion', 'real-analysis']"
4862532,"Why are there different definitions of admissibility in the literature, and why do we need admissibility?","Wikipedia essentially defines an admissible trading strategy as a stochastic process $H = (H_t)_{t\geq 0}$ such that the associated value process $\int H(u) d S(u)$ is lower bounded. As I understand it, this rules out doubling strategies, since the value process is then not allowed to take arbitrary values in $(-\infty,0)$ . Other books, e.g. ""Martingale Methods in Financial Modelling"" by Rutkowski and Musiela, define a trading strategy $\phi$ as being admissible (wrt a measure $P^\ast$ ) if the associated discounted value process is a martingale (wrt $P^\ast$ ), see for example Definition 3.1.4 on page 91. First of all, I am a little confused at the different definitions of admissibility and how they are connected, but my understanding is that the concept of admissibility is used, generally, to avoid arbitrage in a financial model. But isn't the Wikipedia definition of admissibility superfluous? I mean, it rules out doubling strategies, but so does the existence of an equivalent martingale measure, which we need anyway, right? So why include the lower bound on the value process if we avoid doubling strategies using the first fundamental theorem of asset pricing? For the second definition of admissibility: As far as I understand, we have that (under some conditions on the model) there exists an equivalent martingale measure $Q$ if and only if the discounted value process is a martingale under $Q$ . I suppose this is a consequence of the discounted price process being a martingale under $Q$ . Why then do we need to define the admissible strategies as those strategies $\phi$ under which the discounted value process is a martingale? Again, can we not just show that there is an equivalent martingale measure, and since this rules out arbitrage, we can consider any self-financing trading strategy we want? Even doubling strategies? But if we can consider doubling strategies, how can the model be arbitrage free?","['stochastic-analysis', 'finance', 'stochastic-processes', 'martingales', 'probability-theory']"
4862541,Volume of cylindrical wedge of intersecting cylindrical shells,"Two cylindical shells of equal radius are inserted one into the other at various angle between the axes (I tried to give an example with the pic attached).
What is the maximum volume for the cylindrical wedge of the upper cylinder into the bottom one? For which angle between the axes it is reached?","['integration', 'maxima-minima', 'calculus', 'cylindrical-coordinates']"
4862551,"Permutations in ""PERSNICKETINESS"" with Constraints on Letter Placement","I'm tackling a combinatorial challenge with the word ""PERSNICKETINESS"". The task is to determine the number of permutations where the second ""S"" appears after the last vowel, considering letter frequencies of E (3x), S (3x), N (2x), I (2x), and each of P, R, C, K, T appearing once. I've developed two methods to approach the problem but arrived at two different expressions for the solution. I'm seeking insights on which method (if either) is correct. Approach 1: Vowels and the second S placement: Considering a block of 6 characters (3 Es, 2 Is, and the second S), I calculated the ways to place this block in the 15 available positions as $$\binom{15}{6}$$ . Internal arrangement of the block: For the internal arrangement of this block, ensuring the second S follows all vowels, I used $$\frac{6!}{3!2!}$$ to account for repetitions. Remaining letters arrangement: With 9 positions left, the arrangement of the remaining letters (including repetitions of S and N) is calculated by $$\frac{9!}{2!2!}$$ . Expression 1: Combining these steps, the expression for the total arrangements is derived from multiplying the outcomes of each step. Approach 2: Treating the sequence as a block: Here, I considered the vowels and the second ""S"" as a single block (6 elements total), effectively reducing the problem to arranging this block with the other letters. Calculating total permutations: This approach calculates the total permutations by treating the block as a single entity, then multiplying by the internal permutations of the block (accounting for E and I repetitions). Expression 2: The final expression for this method combines the permutations of treating the block as a single entity with the internal arrangements of the block. Both approaches aim to ensure the second ""S"" follows the last vowel, but they lead to different final expressions and numerical outcomes. I would appreciate any clarification on the correct approach or any errors in my reasoning.","['permutations', 'combinations', 'combinatorics']"
4862569,Contour Integrating,"$$ I = \int_{0}^{\infty} \frac{\sqrt{2} \left( e^{-2vz - 2b\sinh(z)}\cos\left(\pi\left(\frac{1}{4} + v\right)\right) + e^{2vz - 2b\sinh(z)}\sin\left(\pi\left(\frac{1}{4} + v\right)\right) \right)}{\sqrt{e^z - e^{-z}}} \, \mathrm{d}z $$ Going through Desmos, the function does converge. $f(z)$ , the integrand, is holomorphic in its domain, and the limits at $+\infty$ and $-\infty$ give me zero as long as $v \in \mathbb{R}$ and $\text{Re}(b) > 0$ . Edit :
As FShrike had mentioned, there's a branch cut at $0$ . This is the reason for the keyhole contour. For further context, see the comments.
I wanted to also first show the Proof of Convergence from Desmos and two interesting cases of the integral. $$\\$$ Case 1:
If I have $I(b)$ equal to the integral and vary $v$ , I get close similarities to the Modified Bessel Function of the Second Kind. $$\\$$ Case 2: If I have $I(v)$ equal to the integral, and vary $b$ , the graph and its properites can be seen below. $\\$ I also wanted to provide an alternative contour that might work as well. After realization, there's a branch cut at $z=i\pi$ as well. Also, as I tested equivalencies for the bounds of the integral, I got these odd results: Note :
This might not be necessary but may aid in a solution, here's how the integral behaves under various values of $v$ and $b$ Question: If stated correctly, the contour integral evaluates to 0 due to Cauchy's Integral Theorem. However, the path integrals of the contour would have to be evaluated. How would you evaluate the path integrals and evaluate the integral with the given notes above? $$
\oint_{c} \frac{{\sqrt{2} \times (e^{-2vz - 2b\sinh(z)}\cos(\pi(1/4 + v)) + e^{2vz - 2b\sinh(z)}\sin(\pi(1/4 + v)))}}{{\sqrt{e^z - e^{-z}}}} \, dz
$$ Using the contour $$
\oint_c = \lim_{{R \to \infty, \epsilon \to 0}} \left( \int_{\Gamma} + \int_{-R}^{-\epsilon} + \int_{\psi} + \int_{\epsilon}^{R} \right) $$ And with what I had stated: $$ 0 =\lim_{{R \to \infty, \epsilon \to 0}} \left( \int_{\Gamma} + \int_{-R}^{-\epsilon} + \int_{\psi} + \int_{\epsilon}^{R} \right) $$ Please excuse my drawing as I am not an artist,
Keyhole Contour: Choosen Contour Alternative Contour Progress Made $$
\lim_{{R \to \infty \atop \epsilon \to 0}} \left(\int_{-R}^{-\epsilon} + \int_{\epsilon}^{R}\right)$$ $\\$ Which is equal to: $\int_{-\infty}^{0} + I$ . And in connection to my notes: $I=-\int_{-\infty}^{0} f(z) dz$ .
Now, things get messy, so I'll keep it concise. $\\$ Evaluating: $\int_{-\infty}^{0} f(z) \, dz$ $\\$ First I made the substitution $ w = e^{z},dw = e^{z} \, dz $ . $$\int_{-\infty}^{\infty} \frac{e^{b(1/w-w)}w^{-1-2v}\left(\cos \left(\pi \left(\frac{1}{4}+v\right)\right)+w^{4v}\sin \left(\pi \left(\frac{1}{4}+v\right)\right) \right)}{\sqrt{-\frac{1}{w}+w}} dw $$ Distribute the $\pi$ , use the sum and difference formulas for $\cos$ and $\sin$ , and distribute throughout.
Next I factor out $\frac{\sqrt{2}}{2}$ which cancels out
At this point, the integral is: $$
\int_{-\infty}^{\infty} \frac{\left(e^{-bw + \frac{b}{w}} w^{(-1 - 2v)}\cos(\pi v) - e^{-bw + \frac{b}{w}} w^{(2v - 1)}\cos(\pi v)\right) + \left(-e^{-bw + \frac{b}{w}} w^{(-1 - 2v)}\sin(\pi v) + e^{-bw + \frac{b}{w}} w^{(2v - 1)}\sin(\pi v)\right)}{\sqrt{w - w^{-1}}} \, dw$$ Split into two fractions, $$I_{1} = \int_{-\infty}^{\infty} \frac{\cos(\pi v) e^{-bw + \frac{b}{w}} (w^{-1 - 2v} - w^{2v - 1})}{\sqrt{w - w^{-1}}} dw$$ And, $$I_{2}=\int_{-\infty}^{\infty}\frac{\sin\left(\pi v\right)e^{-bw+\frac{b}{w}}\left(w^{\left(-1-2v\right)}+w^{\left(2v-1\right)}\right)}{\sqrt{w-w^{-1}}}dw$$ Therefore, $I=-(I_1+I_2)$ I have also assumed both path integrals evaluate to zero. However, I'm uncertain.","['integration', 'complex-analysis', 'calculus', 'contour-integration']"
4862702,Prove that $\mathbb{P}\left(\Vert A \Vert \ge cK(\sqrt{N} + \sqrt{K} + t)\right) \le 2\exp(-t^2)$,"Problem: Let $A = (a_{ij}): l_2^k \to l_2^N$ be a random matrix whose coefficients $a_{ij}$ are independent, centered, $\psi_2$ (the definition is in this post) and satisfy. \begin{align*}
        \exists K>0, \forall i,j: \Vert a_{ij}\Vert_{\psi_2} \le K.
\end{align*} Prove that $\exists c >0$ (independent of everything) such that $\forall t>0$ \begin{align*}
   \mathbb{P}\left(\Vert A \Vert \ge cK(\sqrt{N} + \sqrt{K} + t)\right) \le 2\exp(-t^2).
\end{align*} My attempt: There is two closely related inequality that I have proved but I have not thought how to combine it to tackle with the problem $\forall x \in S^{k-1}$ , $\forall y \in S^{N-1}$ , $\forall t >0$ \begin{align*}
        \mathbb{P}\left(\sum_{i,j}a_{ij}x_jy_i > t\right) \le \exp\left(-\dfrac{t^2}{4K^2}\right).
    \end{align*} Let $\mathcal{N}$ be an $\varepsilon$ -net of $S^{k-1}$ and $\mathcal{M}$ be an $\varepsilon$ -net of $S^{N-1}$ \begin{align*}
        \sup_{x \in \mathcal{N},\ y \in \mathcal{M}} \langle Ax,y\rangle  \le \Vert A \Vert \le \dfrac{1}{1-2\varepsilon} \sup_{x \in \mathcal{N}, y \in \mathcal{M}} \langle Ax,y \rangle. \tag{*}
    \end{align*} I wonder is there any relation between $\mathbb{P}(\Vert A\Vert>\text{constant})$ with $\mathbb{P}\left(\sum_{i,j}a_{ij}x_jy_i > \text{constant}\right)$","['inner-products', 'metric-spaces', 'functional-analysis', 'inequality', 'probability']"
4862720,Does the exponential of a function converge? What can we do with it?,"I’m in middle school (6th grade) and I have a question related to the exponential function (the teacher couldn’t help me): We define the exponential as follows: $$ \exp(t) = \sum_{n = 0}^{\infty} \frac{t^n}{n!}$$ For whole number inputs of $t$ , this corresponds to raising $e$ to that power. I think $\exp(t)$ converges for every possible input of $t$ , but I haven’t found a proof yet. If anyone can provide a proof or disproof then that would be helpful. I would also like to know if for some $\exp(t)$ where $t \in U$ , $\exp(t)$ will also be $\in U$ . However, these are secondary questions and you can ignore them (but do answer if you want). We also define $\exp(t)$ for complex numbers , and matrices . Today I thought about the exponential of a function: $\exp(f(t))$ . For example, let’s take $\exp(t^2)$ . This would result in something like: $\exp(t^2) = \sum_{n = 0}^{\infty} \frac{(t^2)^n}{n!} = 1 + t^2 + \frac{t^4}{2!} + \frac{t^6}{3!} + \cdots$ Which we could write as a regular polynomial as $1 + t^2 + \frac{1}{2}t^4 + \frac{1}{6}t^6 + \frac{1}{24}t^8 + \cdots$ Another example: $\exp\left(\sin(t)\right)$ : $1 + \sin(t) + \frac{1}{2}\sin^2 (t) + \frac{1}{6}\sin^3 (t) + \cdots$ Actually, this is the same thing as raising $e$ to the power of a function. If we took $\exp(e^x)$ it would be the same as $e^{(e^x)}$ : $1 + \frac{1}{2}e^x + \frac{1}{6}e^{2x} + \cdots$ Question : Does the exponential “converge” for function inputs? Also, is there anything useful you can take away from taking the exponential of a function?","['convergence-divergence', 'functions', 'exponential-function', 'real-analysis']"
4862729,"About the integral $\int_{0}^{2\pi} \ln(s^2x^2 + 1) \, ds $","I've encountered an integral that has piqued my interest and am seeking insights or methods for its evaluation. The integral in question is: $$
\int_{0}^{2\pi} \ln(s^2x^2 + 1) \, ds
$$ where ( $x$ ) is treated as a constant parameter. This integral arises in a specific context I'm studying, and I'm particularly interested in understanding how its value changes with different values of ( $x$ ). Despite my efforts, I've found that this integral does not yield easily to standard techniques or elementary functions for its antiderivative. Numerical methods and special functions seem to be viable paths, but I'm curious about any analytic approaches or insights the community might have. Figure Description Attached is a plot showing how the value of the integral changes as a function of ( $x$ ) over the range from -2 to 2. The plot illustrates the integral's sensitivity to changes in ( $x$ ) and provides a visual representation of the problem at hand. I'm looking for any of the following: Analytic approaches to tackle this integral. Insights into the behavior of this integral with respect to ( $x$ ). References to similar integrals or relevant mathematical literature. Thank you in advance for your time and assistance!","['integration', 'definite-integrals', 'logarithms']"
4862811,Indpendence inequality over interval: $\mathbb{P}[a<X<b]\leq\mathbb{P}[a<X]\mathbb{P}[X<b]$,"I am trying to show the following: $$\mathbb{P}[a<X<b]\leq\mathbb{P}[a<X]\mathbb{P}[X<b]$$ where $X$ is any random variable and $a,b$ are constants. I feel I am missing the obvious here, but does the below proof hold? $$\mathbb{P}[a<X<b]=\mathbb{P}[a<X|X < b]\mathbb{P}[X<b]\leq \mathbb{P}[a<X]\mathbb{P}[X<b]$$ I used the inequality $\mathbb{P}[a<X|X < b]\leq \mathbb{P}[a<X]$ which I am fairly sure holds but am struggling to show. Is my reasoning correct?","['solution-verification', 'probability-theory', 'probability']"
4862824,"If for any $\epsilon >0$, there exists a $\delta >0$, such that for any $|x-x_0| < \delta,~ (L-\epsilon)^k \leq f(x) \leq (L+\epsilon)^k,$ [closed]","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 4 months ago . Improve this question Claim: If for any $\epsilon >0$ , there exists a $\delta >0$ , such that for any $|x-x_0| < \delta$ , it holds $(L-\epsilon)^k \leq f(x) \leq (L+\epsilon)^k,$ where $k$ and $L$ are positive constants. Then we have $\lim_{x \rightarrow x_0} f(x) =L^k.$ The following is my proof. Since $\lim_{\xi \rightarrow 0} (L+ \xi)^k = L^k,$ for any $\epsilon >0$ , there exists a $\delta' >0$ , such that for any $0 < \xi < \delta'$ , it holds $(L+\xi)^k - L^k < \epsilon.$ Then for $\delta'/2>0$ , there exists $\delta >0$ , such that when $|x-x_0| < \delta$ , it holds $ f(x) \leq (L+ \delta'/2)^k,$ and therefore, $f(x) - L^k \leq (L+ \delta'/2)^k - L^k < \epsilon.$ . The other direction can use the same method. Is my proof correct?","['analysis', 'real-analysis']"
4862831,Are there any other functions which satisfy $\frac d{dx}f^2(x)=f(2x)$ other than $f(x)=\sin(x)$ and $f(x)=x$?,"I have been practicing functional equations recently and decided to do a functional equation that involves derivatives: $$\text{Find all functions }\mathbb R\to\mathbb R\text{ such that }\dfrac d{dx}f^2(x)=f(2x)$$ Now a solution that can be found right away is the identity function $I(x)=x$ , and the other solution I was able to find was $\sin(x)$ (which is done through the sine addition formula): $$\dfrac d{dx}\sin^2(x)=\dfrac d{dx}\sin(x)\sin(x)\\=\sin(x)\cos(x)+\sin(x)\cos(x)\\=2\sin(x)\cos(x)=\sin(2x)$$ however I have been unable to find other solutions, so my question is: Are there other solutions to the functional equation $\dfrac d{dx}f^2(x)$ , or are $f(x)=x$ and $f(x)=\sin(x)$ the only solutions?","['functional-equations', 'calculus', 'derivatives']"
4862857,Limit as $x\to \infty$ of a function given in integral form,"Consider $F(x) = \int_0^{x^2} \frac{t^2+1}{t^4+2t^2+4}dt$ . I want to study $$
\lim_{x\to\infty} F(x), \quad \lim_{x\to\infty} \frac{F(x)}{x}
$$ Ideas: First, we can observe than $f(t) = \frac{t^2+1}{t^4+2t^2+4}$ is a continuous function over $\mathbb{R}$ , so $G(x) = \int_0^{x} \frac{t^2+1}{t^4+2t^2+4}dt $ is well defined, is continuous, differentiable and $F'=f$ . Is clear that $F = G \circ g$ , being $g(x) = x^2$ , so $F'$ is also differentiable and we can easily compute its derivative using the Chain Rule. If I find that $\lim_{x\to\infty} F(x) = \infty$ , then I could apply L'Hôpital Rule and study the limit of $F'(x)$ , which is $0$ . Can you help me with $\lim_{x\to\infty} F(x)$ ? I'm stuck with this part.","['calculus', 'definite-integrals', 'analysis', 'real-analysis']"
4862886,On the walk-generating function,"While I was reading Norman Biggs' Algebraic Graph Theory I came across the following (Page 12 2g ) exercise/additional result: Let $g_{ij}(r)$ denote the number of walks of length $r$ in $\Gamma$ from $v_i$ to $v_j$ . If we write $\mathbf{G}(z)$ for the matrix $$
\mathbf{G}(z)_{ij}=\sum_{r=1}^{\infty} g_{ij}(r)z^r,
$$ then $\mathbf{G}(z)=(\mathbf{I}-z \mathbf{A})^{-1}$ , where $\mathbf{A}$ is the adjacency matrix of $\Gamma$ . This may be regarded as a matrix over the ring of formal power series in $z$ , or as a real matrix defined whenever $z^{-1} \notin \text{Spec}(\Gamma)$ . From the formula for the inverse matrix and 2e , we obtain $$
\mathbf{G}(z)_{ii}=\frac{\chi(\Gamma_i;z^{-1})}{z\chi(\Gamma;z^{-1})}, \hspace{1cm}\text{tr}(\mathbf{G}(z))=\frac{\chi'(\Gamma;z^{-1})}{z \chi(\Gamma,z^{-1})}.
$$ I was able to prove everything except the part where the matrix is real if $z^{-1} \notin \text{Spec}(\Gamma)$ . The book has a typo, where instead of $z^{-1}$ it's written $z$ , but according to the following paper it must be $z^{-1}$ . Paper: Walk generating functions and spectral measures of infinite graphs Can someone give me some hints of why this happens? Note: $\chi(\Gamma;\lambda)$ means the characteristic polynomial of $\Gamma$ and $\chi(\Gamma_i;\lambda)$ is the characteristic polynomial of the induced subgraph obtained from $\Gamma$ by removing the vertex $v_i$ .","['matrices', 'graph-theory', 'algebraic-graph-theory', 'linear-algebra']"
4862895,Prove that it exists $i \neq j$ s.t. $P(A_i \cap A_j) \geq \frac{nc^2-c}{n-1}$ with $P(A_i) \geq c $,"Question: Let $A_1,A_2,...,A_n \subset \Omega $ a sequence of outcome such that $P(A_i) \geq c $ for all $i$ . Prove that it exists $i \neq j$ s.t. $P(A_i \cap A_j) \geq \frac{nc^2-c}{n-1}$ I have tried different ways including the following one but I did not succeed to conclude. 1-First note that: $\int (\sum_{1 \leq i \leq n} I_{A_i})^2dP= \sum_{i \neq j} \int I_{A_i}I_{A_j}dP + \sum_{i = j} \int I_{A_i}^2dP= \sum_{i \neq j} P(A_i \cap A_j) + \sum_{i = j}P(A_i)$ 2-Now we know that $\sum_{i = j}P(A_i)$ is the sum of $n$ element, thus $\sum_{i = j}P(A_i) \geq nc$ 3-We know too that $\sum_{i \neq j} P(A_i \cap A_j)$ is the sum of $n(n-1)$ elements. More over $\forall i \neq j$ by absurd let suppose that $P(A_i \cap A_j) < \frac{nc^2-c}{n-1}$ . But after I don't succeed to continue. Can someone help me please? Thank for your help.","['measure-theory', 'probability-theory', 'probability', 'inequality']"
4862926,Is the Axiom of Choice inconsistent with Countable Additivity?,"Consider a fair lottery among a countably infinite number of people. The Axiom of Countable Additivity says this is impossible to construct: If all people have a positive (and equal) probability of winning, the sum of their probabilities of winning would diverge, while if all people have a $0$ probability of winning, the sum of their probabilities would be $0 \neq 1$ . However, I feel like the Axiom of Choice can be used to construct such a lottery: Have each person select an element from $[0, 1)$ . This is possible even with the Axiom of Countable Additivity. Lemma: With probability $1$ everyone will have different numbers. Proof: Let $X_i$ be the number selected by $i$ . Let $Y_{ij} = X_i - X_j \mod 1$ . In order for two numbers to be equal with nonzero probability, there must be a nonzero probability that at least one $Y_{ij}$ equals $0$ . But for all $i$ and $j$ , $Y_{ij}$ is distributed uniformly and at random on $[0, 1)$ . This means that there is this same nonzero probability that at least one of the $Y_{ij}$ equals $x$ for every $x \in [0, 1)$ . Countable additivity would then lead to a divergent sum when considering the probabilities at least one of $Y_{ij} = 1/2$ , $Y_{ij} = 1/3$ , $Y_{ij} = 1/4$ , and so on. Choose a well-order on $[0, 1)$ using the Axiom of Choice. Declare the person with the least number according to this well-order the winner. What goes wrong with this reasoning? Or is it actually the case that these two axioms are inconsistent with each other?","['axiom-of-choice', 'probability-theory', 'axioms']"
4862990,Find the domain of a function for different values of $g$,"Find the domain of: $$f(x) = \frac{1}{(g+1)x^2 + 2(g-1)x + g-3}$$ for the various values of $g\in \mathbb{R}$ I am trying to solve this. First of all, I take the $g$ value equal to $-1$ so the domain is $\mathbb{R}$ . The next thing that I need to do is to take the g value not equal to $-1$ . The discriminant must be greater than zero. After many calculations, the result I have is this: $$-3g^2+6g+13>0$$ but I think that is not correct. This is an exercise from a Greek book and it gives me the solution, but not step by step : Domain of $f = R - \left[{\dfrac{3-g}{g+1}, -1 }\right]$ Any ideas? Thanks!","['algebra-precalculus', 'functions', 'problem-solving']"
4862997,Morphism of varieties is determined by morphism on $k^{\text{alg}}$-points,"This question is a bit related to the question To what extent is a scheme morphism determined by its topological map? . Let $X, Y$ be separated geometrically reduced schemes over a field $k$ . Whenever I have a morphism $X \to Y$ , I get a morphism $X(k^{\text{alg}}) \to Y(k^{\text{alg}})$ between the $k^{\text{alg}}$ -points, where $k^{\text{alg}}$ is the algebraic closure. Is the morphism $X \to Y$ uniquely determined by this map? I'm asking because in the language of varieties, the map $X(k^{\text{alg}}) \to Y(k^{\text{alg}})$ is all the data you need to define a morphism (since then the $k^{\text{alg}}$ -points are the whole underlying topological space), so I expect the same to be true in my case. I have problems like this more often, by which I mean I do not really know what holds in the ordinary language of varieties versus in the language of varieties as schemes, or how to express something in one language versus the other language. This can be frustrating when the texts I am reading sometimes use the language of varieties and other times the language of schemes. So, as a second question, I'd like to ask if there are textbooks (or any other kind of reference) that compare the two languages and make precise statements about how they relate. For example it'd be nice if you could prove that the category of varieties over $k$ (with $k$ not necessarily algebraically closed) is equivalent to a suitable full subcategory of the category of schemes over $k$ . This question turned out a bit long so thanks for reading, any help is appreciated.","['algebraic-geometry', 'schemes', 'reference-request']"
4863020,Solving a coupled system of ordinary differential equations,"I want to find two functions $f_1(t)$ and $f_2(t)$ such that $$
\log f_1=A_{11} \log\left(-\dot{f_1}+a_1 f_1\right) +A_{12} \log\left(-\dot{f_2}+a_2 f_2\right) \\
\log f_2=A_{21} \log\left(-\dot{f_1}+a_1 f_1\right) +A_{22} \log\left(-\dot{f_2}+a_2 f_2\right)
$$ where $A_{ij}$ and $a_i$ are known constants. The one-dimensional version of this system is $$
\log f=A \log\left(-\dot{f}+a f\right)
$$ and its solution is $$
f=\left(\frac{1-e^{a\frac{A-1}{A}t}}{a} \right)^{\frac{A}{A-1}}
$$ I'm hoping that a similar solution exists for the two-dimensional case but all my guesses so far have been wrong.","['nonlinear-system', 'systems-of-equations', 'ordinary-differential-equations', 'dynamical-systems']"
4863021,Finding a bound for existential quantification,"Let $\Sigma$ be an arbitrary alphabet, $\mathcal{P}$ denote the set of all prime numbers, and $\omega := \mathbb{N} \cup \{0\}$ Take the following set. $$
L = \left\{ (x, \alpha, \beta) \in \omega \times \Sigma^{*2} : \left( \exists t \in \mathcal{P} \right) ~ \alpha^{(x-2)(|\alpha| - 1)} = \beta^t  \right\} 
$$ I was requested to prove that the set is computable in the following way: $a.$ Prove that the predicate being quantified is primitive recursive, $b.$ Prove that the set being quantified over (the primes) is primitive recursive, $c.$ Find a bound for the quantification. Points $a$ and $b$ are simple, but I am having trouble with $c.$ For ""a bound for the quantification"" I mean some function $f(x, \alpha, \beta)$ s.t. $t \leq f(x, \alpha, \beta)$ whenever $\alpha^{(x-2)(|\alpha|-1)} = \beta^t$ holds for $t \in \mathcal{P}$ . The general case is tricky so I thought of dividing in the following cases. Given fixed elements $(x, \alpha, \beta) \in \omega \times \Sigma^{*2}, t \in \mathcal{P}$ , and assuming $\alpha^{(x-2)(|\alpha|-1)}=\beta^t$ holds: If $|\alpha| \leq |\beta|$ then $ t \leq (x-2)(|\alpha| - 1)$ and this is a bound. If $|\alpha| > |\beta|$ however it must follow that $t >(x-2)(|\alpha| - 1)$ It seems impossible to find a bound for $t$ in the second case. Assuming $|\alpha| > |\beta|$ , how could we find any quantity $\varphi$ dependent on $x, \alpha, \beta$ s.t. $t \leq \varphi$ whenever $\alpha^{(x-2)(|\alpha|-1)}=\beta^t, t \in \mathcal{P}$ ?","['computer-science', 'logic', 'discrete-mathematics', 'formal-languages', 'computability']"
4863065,"Easy proof that $n=5$ is the only solution of $n^n \equiv n^{n^n} \pmod {10^{n-1}}$ if $n \in \mathbb{N}-\{0,1\}$ is not a multiple of $10$","Let $n > 1$ be an integer not a multiple of $10$ .
Is there a short proof that $n = 5$ is the only solution to $n^n \equiv n^{n^n} \pmod {10^{n-1}}$ , given the fact that $5^{5^5} \equiv 3125 \pmod{10^4}$ (and even $3125 \equiv 5^{5^5} \pmod{10^5}$ )? P.S.
This question is related to my research on the congruence speed of tetration and arose in the discussion of the OEIS sequence $A369826$ before it was finally approved. Moreover, I am planning to submit another sequence concerning the number of frozen rightmost digits of some tetration bases at a given height (as my pending sequences are processed), and I would like to add also a short explanation in the comments that does not invoke the congruence speed of $n$ (i.e., for any integer $n>5$ that is not a multiple of $10$ , the number of frozen digits at height $2$ cannot exceed three times the constant congruence speed of the base, which is given by Equation (16) of Number of stable digits of any integer tetration , and then the stated result trivially follows).","['exponentiation', 'modular-arithmetic', 'power-towers', 'discrete-mathematics', 'hyperoperation']"
4863115,Are convex objects determined by their silhouettes?,"Informally, the silhouette of a 3D shape is a viewpoint-dependent 2D projection of it. You might imagine looking at several silhouettes and attempting to construct the overall shape.  My question is theoretical: if you have access to the set of all silhouettes of a convex figure —unordered, that is to say, you know only the silhouettes, not the viewing angles associated with each one—is that always sufficient to uniquely reconstruct the shape? Or are there convex shapes that are not related via any rigid transformation that have indistinguishable silhouette profiles? I have been working on this problem, and I'm stumped.  So far, I've tried generating asymmetric (chiral) shapes, and attempting to answer the question in two dimensions instead of three. Here's one attempt to formalize these terms: if $P$ is a (bounded) convex subset of $\mathbb{R}^3$ , let $u\in S^2$ be a viewing direction. The silhouette of $P$ in the $u$ direction is the set of all vectors $v\perp u$ such that the line through $v+u$ and parallel to $u$ intersects the object. Two convex subsets $P, Q\in\mathbb{R}^3$ have the same silhouette profile if there is a rigid transformation $f:\mathbb{R}^3\rightarrow \mathbb{R}^3$ such that the set of all silhouettes of $f(P)$ is equal to the set of all silhouettes of $Q$ . The question is whether there are convex subsets $P,Q\subseteq \mathbb{R}^3$ that are not the same shape (not related by a rigid transformation), but have the same silhouette profile. (These definitions carry over to other dimensions with $\mathbb{R}^3$ replaced with $\mathbb{R}^n$ , and $S^2$ replaced with $S^{n-1}$ .) Edit: In order to entirely erase the viewing direction from the silhouette, I should quotient these silhouettes by the relation that considers silhouettes equivalent if they can be transformed into one another by a rigid transformation.","['geometry', 'computer-vision', 'convex-hulls']"
4863144,Second Borel-Cantelli lemma via the moment method,"Let ${E_1,E_2,\dots}$ be a sequence of jointly independent events. If ${\sum_{n=1}^\infty {\bf P}(E_n) = \infty}$ , show that almost surely an infinite number of the ${E_n}$ hold simultaneously. (Hint: compute the mean and variance of ${S_n= \sum_{i=1}^n 1_{E_i}}$ . One can also compute the fourth moment if desired, but it is not necessary to do so for this result.) Question : From the hint, we want ${\bf P}(\lim_n S_n = \infty) = 1$ . i.e., $S_n$ diverges almost surely, yet I didn’t see immediately how the mean ${\bf E}(S_n) = \sum_{i=1}^n {\bf P}(E_i)$ and the variance ${\bf Var}(S_n) = \sum_{i=1}^n {\bf P}(E_i)(1 - {\bf P}(E_i))$ is applicable here, the Chebyshev’s inequality does not seem to convey too much information.","['borel-cantelli-lemmas', 'probability-theory']"
4863146,Probability of two specific cards to be in your hand in a game of bridge,"Assume that a 52-card deck is distributed among 4 players, each with 13. What is the probability that two specific cards, say the Ace of Hearts and Ace of Diamonds to be in my hand? I have two approach in solving this, each giving a different answer. The first approach to consider the sample space to be the position of the two aces among the four players. There is a 1/4 chance that the Ace of hearts to be in your hand and a 1/4 chance that the Ace of diamonds to be in your hand, so the chance that both Aces to be in your hand is 1/16 The second approach is using a combination approach, the sample size being all possibilites of a 13 card hand from 52 cards.
Then, we can calculate as follows: $\frac{{50}\choose{11}}{{52}\choose{13}} = \frac{1}{17} $ Which one is the correct answer and where did one of the working went wrong?","['conditional-probability', 'statistics', 'combinatorics', 'probability']"
4863185,Prove $1< \frac a{\sqrt{a^2+b^2}} + \frac b{\sqrt{b^2+c^2}} + \frac c{\sqrt{c^2+a^2}} \le \frac{3\sqrt2}2$,"Suppose that a, b, c are positive real numbers, prove that : $$1 < \frac a{\sqrt{a^2+b^2}} + \frac b{\sqrt{b^2+c^2}} + \frac c{\sqrt{c^2+a^2}} \le \frac{3\sqrt2}2.$$ This is a question from 100 inequalities by Vasc and Arqady. Link For the Right Hand Side inequality , I have tried applying AM-GM inequality and Cauchy–Schwarz inequality to solve the inequality but the issue is I am unable to arrange the terms for the $\le$ sign. The terms I want on the left side seem to end up on the right and vice versa. Even if I try to solve using the flipped sign of inequality, I am getting stuck midway unable to simplify the terms. Terms used in AM-GM inequalty : $A : \frac a{\sqrt{a^2+b^2}}$ $B  : \frac b{\sqrt{b^2+c^2}}$ $C : \frac c{\sqrt{c^2+a^2}}$ and then continuing with $\frac {A+B+C}3 \ge \sqrt[3] {ABC}$ . For the Cauchy–Schwarz inequality, I am using : $a_1 : \frac a{\sqrt{a^2+b^2}}, \ \ a_2  : \frac b{\sqrt{b^2+c^2}}, \ \ a_3 : \frac c{\sqrt{c^2+a^2}}$ and $b_1 : \frac{\sqrt{a^2+b^2}}a, \ \ b_2  : \frac{\sqrt{b^2+c^2}}b, \ \ b_3 : \frac{\sqrt{c^2+a^2}}c$ and then continuing with $(a_1^2+a_2^2+a_3^2)*(b_1^2+b_2^2+b_3^2) \ge (a_1b_1 + a_2b_2 + a_3b_3)^2$ For the Left Hand Side Inequality , I have the intuition that the inequality holds true but I cannot seem to find a method to prove it. Any ideas, hints and approaches are welcome. Thank you very much.","['algebra-precalculus', 'inequality']"
4863208,Finite group where all the elements are commutators,"Is there a finite group of order greater than $1$ , where all the elements are commutators? I thought about this question once, but I couldn't think of a single example. Obviously, such a group must be perfect. Perhaps the following fact can be used somehow: $g \in G$ is commutator iff $$\sum\limits_{\chi \in Irr(G)} \frac{\chi(g)}{\chi(1)} \neq 0$$",['group-theory']
