question_id,title,body,tags
331033,Duplicate quadratic Bézier curve with new start point?,"I have Bézier curve as shown by the wikipedia gif here: I would like to create a new curve that is a segment of the old one. For example, in this gif (from the same article): .. if I wanted B to be the starting point of the new curve, but for the curve to follow the same path, how could I find the new control point? I can see that the answer is very straightforward and easily solvable, but my mind still hasn't caught up with the logic behind the equation for the quadratic Bézier curve: so I'm having trouble thinking it out. I would greatly appreciate any hints/advice that would help push me in the right direction.","['vector-spaces', 'geometry', 'bezier-curve', 'trigonometry', 'linear-algebra']"
331034,Closed Convex sets of $\mathbb{R^2}$,Can some one please list the closed convex sets in $\mathbb{R^2}$ up to homeomorphism. How many of them are compact,"['general-topology', 'geometry', 'analysis']"
331038,Continuous open surjection on Reals,"If $f:\mathbb{R}\rightarrow \mathbb{R}$ is a continuous, open surjection, must it be a homeomorphism?","['general-topology', 'analysis']"
331048,Solve for $X$ in a simple $2\times2$ equation system.,I posted a similar question recently but I still have problem with this problem and would appreciate any help! $$\left[ \begin{array}{cc} 9 & -3\\ 5 & -5\end{array} \right] - X \left[ \begin{array}{cc} -9 & -2\\ 8 & 5\end{array} \right] = E$$ With $E$ i pressume they mean the identity matrix $\left[ \begin{array}{cc} 1 & 0\\ 0 & 1\end{array} \right]$. How should I go on and solve this for the $2\times2$ matrix $X$? a full development so I can follow your solution would be very much appreciated! Thank you kindly for you help!,"['matrices', 'linear-algebra']"
331058,"Generating function for the sequence $1,1,3,3,5,5,7,7,9,9,\ldots$","The generating function for the sequence $\left\{1,1,1,1,...\right\}$ is $$1 + x + x^2 + x^3 ... = \frac{1}{1-x}$$
What is the generating function for the sequence $\left\{1,1,3,3,5,5,7,7,9,9,\dots \right\}$? This is my attempt: what we want to do is after the initial  $\left\{1,1,1,1,...\right\}$ function we want to add two more functions shifted two to the right such as $\left\{0,0,1,1,1,...\right\}$ and keep adding such function 2 at a time and each new two are shifted 2 more to the right then the previous one. so first would be $\left\{1,1,1,1,\dots \right\}$ then add 2 of $\left\{0,0,1,1,1,1,\dots\right\}$ then add 2 more of $\left\{0,0,0,0,1,1,1,1,\dots\right\}$ and keep doing that. this gives us the function $$\frac{1}{1-x}+\frac{2x^2}{1-x}+\frac{2x^4}{1-x}+...$$ or $$\frac{1}{1-x}+\frac{2x^{2k}}{1-x}$$ however $i$ do not know where to go from here, how do $i$ finish this problem?","['generating-functions', 'discrete-mathematics']"
331091,"How to see that $\ker\left((X,Y)\otimes_R(X,Y)\to(X,Y)^2\right)\simeq k$ in $R=k[X,Y]$?","Let $k$ be a field, $R=k[X,Y]$ and $I=(X,Y)$, so that $R/I\simeq k$. I proved, using a projective resolution of $k$, that $\text{Tor}^R_2(k,k)= k$. I also proved that in general
$$
\text{Tor}^A_2(A/I,A/J)=\ker(I\otimes_AJ\to IJ)
$$
where $I,J$ are ideals in a commutative ring $A$. When trying to see this by computing $\ker(I\otimes_AJ\to IJ)$ for $A=R$ and $I=J=(X,Y)$, though, I get to an impasse. Since $X,Y$ generate $I$, then $\{X\otimes X,X\otimes Y,Y\otimes X,Y\otimes Y\}$ is a system of generators of $I\otimes_R I$. In particular $\alpha=X\otimes Y - Y\otimes X \in \ker(I\otimes_RI\to I^2)$ since $\alpha \mapsto XY-YX=0$. But then $\forall f\in R$ we have $I\otimes_R I \ni f\alpha \mapsto f\cdot(XY-YX)=0$, so $R\alpha\subseteq\ker(I\otimes_RI\to I^2)$.
What am I missing here? Edit: @GeorgesElencwajg cleared my doubt, though I still don't see how to prove that $\ker(I\otimes_RI\to I^2) = k$ without using homological algebra.","['homological-algebra', 'commutative-algebra', 'abstract-algebra']"
331113,Proving that a complex number $z$ is real.,"A problem I have in my book is to prove that $z$ is real if and only if $\bar{z} = z$. So far I have got that for $z = x + iy$, if $z$ is real, $y = 0$ and thus $z = x = \bar{z}$ as  $\bar{z} = x - iy$ where $y = 0$ (if I'm right). Now my book mentions something like converse of this, i.e, if $\bar{z} = z$ then $x+iy = x-iy$, where the last equality implies $y = -y$ and thus $y = 0$ (I don't get what equality it's talking about). Also later it's explained that, therefore, $z = x$ and thus is real. (I don't get the second part at all). Can someone please help me to understand this?","['complex-numbers', 'complex-analysis']"
331115,Find the smallest integer $n > 0$ such that $2012$ divides $9^n-1$.,"Find the smallest integer $n > 0$ such that $2012$ divides $9^n-1$. my thoughts: $$2012=2 \cdot 2 \cdot 503$$
$503$ is prime. so by fermats little theorem $9^{502} \equiv 1$(mod $503$). again $9^n \equiv 1$ (mod $4$). hence for $n=502$ equality holds but is it the smallest?",['number-theory']
331116,Missing term in series expansion,"I asked a similar question before, but now I can formulate it more concretely. I am trying to perform an expansion of the function $$f(x) = \sum_{n=1}^{\infty} \frac{K_2(nx)}{n^2 x^2},$$ for $x \ll 1$. Here, $K_2(x)$ is the modified Bessel function of the second kind. This series is a result of solving the integral $$f(x) = \frac{1}{3}\int_1^\infty \frac{(t^2-1)^{3/2}}{\mathrm{e}^{xt}-1}\mathrm{d}t.$$ The stated result is $$f(x) \approx \frac{\pi^4}{45 x^4} - \frac{\pi^2}{12 x^2}+\frac{\pi}{6x}-\frac{1}{32}\left(  \frac{3}{2}-2\gamma+2\ln4\pi-\ln x^2\right)+\mathcal{O}(x^2),$$ where $\gamma$ is the Euler-Mascheroni constant. It agrees numerically with $f(x)$ for small $x$. However, by using the series expansion of the Bessel function $$K_2(nx) = \frac{2}{n^2x^2}-\frac{1}{2}+\frac{1}{2}\sum_{k=0}^\infty \left[\psi(k+1)+\psi(k+3)-\ln\frac{n^2x^2}{4}\right]\frac{\left(\frac{n^2 x^2}{4}\right)^{k+1}}{k!(k+2)!},$$ with $\psi(x)$ being the digamma function and using the zeta regularization for summation over $n$, I am able to reproduce all the terms except $\frac{\pi}{6x}$. I.e., my result is $$f(x) = \frac{2\zeta(4)}{x^4} - \frac{\zeta(2)}{2x^2} + \frac{1}{8}\sum_{k=0}^\infty \left[\left(\psi(k+1)+\psi(k+3)-\ln\frac{x^2}{4}\right)\zeta(-2k) + 2 \zeta'(-2k)\right]\frac{\left(\frac{x^2}{4}\right)^{k}}{k!(k+2)!}.$$ It seems very strange that the $\frac{\pi}{6x}$ term should appear in the expansion since only even powers of $x$ appear in $K_2(nx)$. But, numerically, it is certainly there. How did I miss it? Edit #1: I just got an idea where the $\frac{\pi}{6x}$ term might come from! Approximating the integral representation of $f(x)$ for $xt \ll 1$ and using the UV regulator $\Lambda$, we have $$f(x) \approx \frac{1}{3} \int_1^\Lambda \frac{(t^2-1)^{3/2}}{xt}\mathrm{d}t \approx \frac{\Lambda^3}{9x} - \frac{\Lambda}{2x} + \frac{\pi}{6x}.$$ OK, so now the question is why doesn't the Bessel series see this term and what to do about it? Edit #2: The missing term might indicate that the zeta regularization isn't used properly. The term $\frac{\pi}{6x}$ appears right in the middle, separating the convergent sums $\zeta(4)$ and $\zeta(2)$ from the (regularized) divergent sums $\zeta(-2k)$ and $\zeta'(-2k)$. So, the missing term may be the price to pay for using the zeta regularization. Unfortunately, I don't know enough math to come to any decisive conclusion. Edit #3: In edit #1 I argued that the missing term $\frac{\pi}{6x}$ comes from expansion of the exponential in the denominator. When I expand the numerator in the binomial series $$f(x) = \frac{1}{3} \int_1^\infty \frac{t^3}{\mathrm{e}^{xt}-1}\sum_{k=0}^\infty \binom{3/2}{k}(-t^{-2})^k\mathrm{d}t$$ and perform the integration, I again obtain my original result without $\frac{\pi}{6x}$. So, depending on what I choose to expand, I obtain different (incomplete) results??","['special-functions', 'sequences-and-series', 'regularization', 'asymptotics', 'divergent-series']"
331121,Number of prime ideals of a ring,"Could anyone tell me how to find the number of distinct prime ideals of the ring $$\mathbb{Q}[x]/\langle x^m-1\rangle,$$ where $m$ is a positive integer say $4$, or $5$? What result/results I need to apply to solve this problem? Thank you for your help.","['ring-theory', 'maximal-and-prime-ideals', 'abstract-algebra', 'commutative-algebra', 'ideals']"
331148,Interesting Integral $\int_{-\infty}^{\infty}\frac{e^{i nx}}{\Gamma(\alpha+x) \Gamma(\beta -x)}dx$,I am asking this question out of curiosity. $$\int_{-\infty}^{\infty}\frac{e^{i nx}}{\Gamma(\alpha+x) \Gamma(\beta -x)}dx = \frac{ \left(2\cos \frac{n}{2} \right)^{\alpha +\beta-2}}{\Gamma(\alpha+\beta-1)}e^{\frac{in}{2}(\beta - \alpha)} \quad |n|<\pi \quad \text{and} \quad \Re(\alpha+\beta)>1$$ How did Ramanujan derive this formula? I have noticed that Ramanujan has discovered many integrals involving gamma function. Is there a general method to deal with such integrals?,"['gamma-function', 'improper-integrals', 'special-functions', 'integration']"
331152,The intuition behind the definition of geodesics on a Riemannian manifold. (A non-technical question),"In the text I'm studying, the idea behind the definition of a geodesic on a Riemannian manifold was sketched via paths in $\mathbb{R}^n$. I have trouble understanding some aspects of it. Let $\gamma: I \to \mathbb{R}^n$ be a path. It is a geodesic if $$ \ddot{\gamma}_T \equiv 0, $$ where $\ddot{\gamma}_T$ denotes the tangential component of the total acceleration $\ddot{\gamma}$. A geodesic is a ""straight as possible"" path on a manifold. Clearly, a line $$\gamma(t) = vt+p, \quad v,p \in \mathbb{R}^n$$ satisfies the given characterisation by acceleration in $\mathbb{R}^n$. But wouldn't a perfectly circular path also do? Have I misunderstood something or is this some property of the geodesics that the heuristic description fails to convey.","['analytic-geometry', 'multivariable-calculus', 'riemannian-geometry', 'differential-geometry']"
331153,Proving that $\lim_{h\to 0 } \frac{b^{h}-1}{h} = \ln{b}$,"Is there a formal proof of this fact without using L'Hôpital's rule? I was thinking about using a proof
of this fact:
$$
\left.\frac{d(e^{x})}{dx}\right|_{x=x_0} = e^{x_0}\lim_{h\to 0} \frac{e^{h}-1}{h} = e^{x_0}\cdot 1=e^{x_0}  
$$
that I have to help prove:
$$
\lim_{h\to 0} \frac{b^{h}-1}{h} = \ln{b}
$$
Is there a succinct proof of this limit? How does one prove this rigorously?","['calculus', 'limits']"
331169,A question concerning measurability of a function,"Let $\Omega\subset \mathbb{R}^n$ be bounded and let $X:=H^1(\Omega)$. Let $a:\Omega\times \mathbb{R} \to \mathbb{R}, (x,z)\mapsto a(x,z)$ be a bounded function such that $a(x,.)$ is continuous on $\mathbb{R}$ for every $x$ and $a(.,z)$ is measurable on $\Omega$ for every $z$. For $v,\phi\in H^1$ one finds in pde the integral
$$\int_\Omega a(x,v(x))\nabla v(x) \cdot \nabla\phi(x) dx$$
All measures should be the Lebesgue measure
My question is: Why is $a(x,v(x))$ a measurable function, why is $a(x,z)$ measurable on $\Omega\times \mathbb{R}$ or why is the integral defined? Usually one can not conclude from measurability of each compontent to measurability on the product space. Somehow i feel I need more measure theory than i know yet :)","['measure-theory', 'partial-differential-equations', 'functional-analysis', 'functions']"
331175,Probability that a normal distribution is greater than two others,"Given 3 independent variables with normal distributions, how can I calculate the probability that one of them will be greater than the other two simultaneously? So, how to calculate $P ((A>B) \bigcap (A>C))$ with $A=N(\mu_A,\sigma_A)$ $B=N(\mu_B,\sigma_B)$ $C=N(\mu_C,\sigma_C)$ I know how to calculate $P(A>B)$, since $P(A>B) = P(A-B>0)$, where $A-B$ has a normal distribution with $\mu = \mu_A - \mu_B$ and $\sigma^2= (\sigma_A)^2 + (\sigma_A)^2$ I'm also aware of the formula for conditional probability
$P ((A>B) \bigcap (A>C)) = P (A>B) P(A>C|A>B)$ But I'm lost as to how to calculate $P(A>C|A>B)$ (or any other way to solve this).","['statistics', 'probability-distributions', 'probability']"
331177,Pointwise limit of integrable function,"Question: Show that the pointwise limit of integrable functions is not necessarily integrable. I am stuck on this question. Here is what I know. Let $(f_n)^{\infty}_{n=1}$ be a series of integrable functions, and let $$\lim_{n \to \infty} f_n(x)=Z$$ I need to show that $Z$ is not necessarily integrable. Should I be looking for a specific example? A function that is integrable, but as $n \to \infty $ the function is no longer integrable.",['real-analysis']
331198,Consequence of Invariance of Domain,"The Invariance of Domain theorem states that Given a continuous injection $f : U \to \mathbb{R}^n$, where $U$ is a nonempty open subset of $\mathbb{R}^n$, $f$ is an open map. These slides (see last slide) state that as a consequence, Given a continuous injection $f : \mathbb{R}^n \to \mathbb{R}^m$, $n \leq m$. However, is the following statement true? Given a continuous injection $f : U \to \mathbb{R}^m$, where $U$ is a nonempty open subset of $\mathbb{R}^n$, $n \leq m$. It looks like a combination of the above statements. It naturally holds if $U$ is homeomorphic to $\mathbb{R}^n$.","['general-topology', 'metric-spaces', 'continuity']"
331207,A doubt in the proof of Frucht's theorem,"I am trying to understand the proof of Frucht's theorem which is: Every finite group is isomorphic to the automorphism group of some
  simple graph. The proof (which I am reading from this book) begins as follows: Let $\Gamma=\{g_1,\cdots, g_n\}$ be a group. Consider a directed graph $\hat{G_0}$ with $V(\hat{G_0})=\Gamma$ and a directed edge between $g_i$ and $g_j$ colored $k$ where $g_ig_j^{-1}=g_k$. Next it goes on to show that $Aut(\hat{G_0})\approx\Gamma$. Next, a graph $G$ is constructed: Whenever $g_i$ has a directed edge leading into $g_j$ of color $k$, then that edge is replaced by a (non-directed) path of length $k+2$. In this $k+2$-path there are paths of length $1$ attached to each inner point except for the inner point next to $g_j$ where we attach a path of length $2$. Then the following is established: Each automorphism of $\hat{G_0}$ induces a unique automorphism of $G$. If $\alpha$ is an automorphism of $G$, then $\alpha$ is induced by some automorphism of $\hat{G_0}$. This finishes the proof. What I don't understand is as the last two points presumably only establish that $Aut(\hat{G_0})$ and $Aut(G)$ have the same cardinality. It doesn't establish that they are isomorphic as groups which is essential for the final conclusion that $Aut(G)\approx \Gamma$. Update: There is no proof of (1) provided in the book. Instead it just says that the proof is clear! I assume what is meant is this: For any automorphism $f$ of $\hat{G_0}$, we construct an automorphism of $G$ by first permuting $V(G_0)$ as per $f$, then rearranging the paths appropriately (the path joining $g_i$ and $g_j$ is send to the path joining $f(g_i)$ and $f(g_j)$. The structure of the paths is such that there is no permutation possible within a particular path.).","['graph-theory', 'finite-groups', 'abstract-algebra']"
331210,Find the principal argument of a complex number,I have a text book question to find the principal argument of $$ z = {i \over -2-2i}. $$ I know formulas where we find using $$ \tan^{-1} {y \over x}$$ but I am kinda stuck here can somebody please help.,"['complex-numbers', 'complex-analysis']"
331228,Triviality of vector bundles,"Let $X$ be a proper curve, not necessarily smooth nor reduced, and $E$ a vector bundle on $X$ of rank $r$. Assume we know that $H^0(X,E)\geq r$ and $H^0(X,E^{\vee})\geq r$, can we conclude that $E$ is trivial? Is there a cohomological criterion to decide whenever a vector bundle is trivial?",['algebraic-geometry']
331230,A function of two variables question,"Consider a function of two variables $h(x,y)$. If it's linear for $y$. Can I express it as $a(x)y + b(x)$ ?   If positive, why ?",['functions']
331231,What quantifies as a rigorous proof?,"Okay I have been thinking about this common combinatorial identity. $$\sum_{r=0}^{n} \binom{n}{r} = 2^n.$$ It is simple to prove this by induction, but it requires some annoying algebraic manipulation which involves other combinatorial identities. What about if we took an approach that takes into factor a specific rephrase of the problem? My approach is this. Consider a combination lock with n number of on-off switches. To open it require turning on the correct switches. How many combinations are there? clearly, the first switch can be on or off, second on and off etc. so the combintions are $2^n$ We look at it from a different angle. How many ways are there to pick one on switch. $\dbinom{n}{1}$. what about picking 2 switches? $\dbinom{n}{2}$... and so on. Since the number of combinations are supposed to be the same,it gives us the identity. Now i know this explanation is not rigorous, but can someone point out exactly to me exactly which part of it it fails to be so? I have also encountered this problem in man other areas of mathematics when I try to prove something, I used a specific problem to do so and thus I doubt the validity of the proof. I can give more examples if needed",['combinatorics']
331239,"How to calculate $x_t$ from $ARIMA(1,2,0)$ (second difference $AR(1)$ process)?","It sounds so simple but I'v struggled with this problem for a quite long time now. I have come to this:
$$X_t = \phi(x_{t-1} - 2x_{t-2} + x_{t-3}) + 2x_{t-1} - x_{t-2} + \epsilon_t$$ it just doesn't give the right values..","['statistics', 'stochastic-processes', 'probability']"
331243,"If$f(z)$ is analytic , then what about $f'(z)?? $","If$f(z)$ is analytic ,  then what about $f'(z)$? can we conclude that $f^{(k)}(z)$ is analytic for any k$\in $$ \mathbb{N} $","['derivatives', 'complex-analysis', 'analyticity']"
331248,"What is the image of the map $\hom(V,V) \to \hom(\wedge^k V,\wedge^k V)$?","The title says it all. For the uninitiated: Any map $f:V \to W$ induces a map $\wedge^k V \to \wedge^k W$ by $v_1 \wedge \cdots \wedge v_k \mapsto f(v_1)\wedge \cdots \wedge f(v_k)$, so $\wedge^k(-)$ is a functor from vector spaces to itself. I have a map $\varphi:\wedge^k V\to \wedge^kV$ and I have reason to suspect that this map does not come fram a map $\psi:V \to V$. I'm not sure how to prove this. It seems that any map in the image of $\wedge^k(-)$ must satisfy some kind of Plücker relations (similar to those of the Grassmannian), since if $\varphi \in \hom(V,V)$ is represented by the matrix $(x_{ij})$, then its image in $\hom(\wedge^k V,\wedge^k V)$ has matrix $(\det_{IJ}(x_{ij}))$, where $\det_{IJ}$ means take the determinant of the submatrix with indices $I$ and $J$. I tried asking Macaulay2 to compute the ideal of relations, but even in the case $\dim V=4$ and $k=2$, it does not seem to be a feasible computation: R = QQ[x_1..x_16]
M = genericMatrix(R,4,4)
I = minors(2,M)
numgens I
>> 36
S = QQ[y_1..y_36]
f = map(R,S,gens I)
ker f
>> ......???? <- to much for M2! Is there some strategy to determine if my map comes from $\hom(V,V)$ other than computing these relations? If not, are the relations between the $k\times k$-minors of a $n\times n$-matrix known? Thanks.","['commutative-algebra', 'algebraic-geometry', 'exterior-algebra']"
331271,The prime number theorem and the nth prime,"This is a much clearer restatement of an earlier question . In section 1.8 of Hardy & Wright, An Introduction to the Theory of Numbers , it is proved that the function inverse to $ x ⁄ \log⁡ x$  is asymptotic to 
$x \log⁡ x$. “From this remark we infer,” they say, that: (*) The prime number theorem, $\pi(x)\sim x⁄ \log ⁡x$ , is equivalent to the theorem $p_n \sim n \log ⁡n$, where $p_n$ denotes the $n^{\text{th}}$ prime. That the theorems are equivalent is easy to prove by a different method, as in Apostol's Introduction to Analytic Number Theory , Theorem 4.5. But how does the equivalence follow from H & W’s “remark”? As they say in section 1.5, since $\pi(p_n ) = n$, “$\pi(x)$, as function of $x$, and $p_n$, as function of $n$, are inverse functions”; but the inverses of asymptotic functions are not usually themselves asymptotic to one another. Would someone please explain how H & W mean for us to deduce (*)?","['prime-numbers', 'number-theory']"
331275,Softmax function and modelling probability distributions,"Hinton in his neural network course on Coursera says that ""Any probability distribution P over discrete states (P(x) > 0 for all x) can be represented as the output of a softmax unit for some inputs."" I was trying to prove it but didn't manage. Do you know of a proof of this?","['pattern-recognition', 'probability-distributions', 'probability']"
331276,Convergence radius of power series,"I am trying to solve an exercise, but i am not sure that the result i get at the end is correct...Can I kindly ask you for a little help or a remark? Find the radius of convergence of the following power series: $\sum_{n=0}^{\infty }(n^{2}+a^{n})z^{n}$ for any $z,a\in \mathbb{C}$ I use the quotient ratio: $\lim_{n\rightarrow \infty }\left | \frac{a_{n+1}}{a_n} \right |=\lim_{n\rightarrow \infty } \left | \frac{n^{2}+2n+1+aa^{n}}{n^{2}+a^{n}} \right |=\lim_{n\rightarrow \infty }\left | \frac{1+\frac{2}{n}+\frac{1}{n^{2}}+ \frac{aa^{n}}{n^{2}}}{1+\frac{a^{n}}{n^{2}}} \right | = 1 $ and then i get radius of convergence $1$ . With Cauchy-Hadamard I get $\limsup_{n\rightarrow \infty }\sqrt{n^{2}+a^{n}}=\limsup_{n\rightarrow \infty }\sqrt{n^{2}(1+\frac{a^{n}}{n^{2}})}=\limsup_{n\rightarrow \infty }n\sqrt{1+\frac{a^{n}}{n^{2}}}=\infty $ and a radius of convergence $0$ . I am not sure which result is correct if any of them is correct... Thank you in advance!","['power-series', 'convergence-divergence', 'sequences-and-series', 'complex-analysis']"
331280,Probability distribution of tossing a coin until obtaining $k$ heads,"My question is the following. We toss a coin, for which probability of obtaining heads is $p \in (0,1]$, until we obtain $k$ heads, not necessarily in a row (generally $k$ heads). Let $X$ be a number of executed tosses. I need to find a probability distribution of $X$. So of course for $t <k$ we have $F_x(t) =0$. And for greater $t$? Firstly I thought that it would be $p\cdot \sum_{n=k}^t $${n-1}\choose {k-1} $$p^{k-1} (1-p)^{n-k-1} $, because we want to have head in the last toss and $k-1$ in all previous ones, but later I realised that things like $100 $ heads in $105$ tosses and $100$ heads in $106$ tosses are not disjoint. Then can somebody help me with finding the probability distribution for $X$? I don't know how to compute probability of tossing $k-1$ heads in $t$ tosses or LESS?","['probability-distributions', 'probability']"
331300,Cyclic subgroups and generators,"Sorry for posting a second question on this topic, abstract algebra is taking a bit longer to get my head around. I'm trying to work out if this is cyclic or not, and find all generators or show no generator exists. $\langle(12)(34)(56),(145)(236)\rangle \leq S_6$ Just in case there's differences in notation, that's just the subgroup generated by the elements $(12)(13)(56)$ and $(145)(236)$ of $S_6$. The problem is, my notes only show one example like this, but both permutations were even, and it was in $S_4$ so they just showed that you could generate $A_4$ (by literally showing you could make every even permutation) using the two elements. Given how one of the elements here is odd, and we're dealing with $S_6$ it doesn't look like a good method. So far, I've noted that, letting $\sigma = (12)(34)(56)$ and $\tau = (145)(236)$ we get that $o(\sigma) = 2$ and $o(\tau) = 3$ Also, that $\sigma \tau = (135246) = \tau \sigma$, $(\sigma \tau)^2 = (\tau \sigma)^2 = (154)(326) = \tau^{-1}$ Lastly that $(\sigma \tau)^3 = (\tau \sigma)^3 = (12)(34)(56) = \sigma = \sigma^{-1}$ I get a bit stuck as to where to go at this point, although I can't see how it's even possible this is cyclic. Thanks again, this place has already been a massive help!","['cyclic-groups', 'group-theory', 'abstract-algebra']"
331307,What is $\int\frac{dx}{\sin x}$?,I'm looking for the antiderivatives of $1/\sin x$. Is there even a closed form of the antiderivatives? Thanks in advance.,"['calculus', 'integration', 'indefinite-integrals']"
331314,How does one visualize a function with a discontinuous second derivative?,"Let us assume that all functions are continuous. I was teaching my calculus students the other day. We were talking about what points of non-differentiability look like. Two ways a function can fail to be differentiable at a point is if it looks like $y=|x|$ or like a Brownian motion (think of $x\sin x$ for instance), where the derivative oscillates too much. However, I do not have an intuition about $C^1$ functions and how they differ from $C^i$ functions for higher $i$. An example that I know is the function $$f(x)=x^2,x\geq 0\mbox{ and }f(x)=-x^2,x\leq 0.$$ The graph of this actually looks smooth to me. So the question rephrased may be: how can one visually tell the difference between $C^1$ functions and $C^2$ functions in a straight forward way. Although this is for undergrads, I wouldn't mind a more advanced answer.","['education', 'calculus', 'real-analysis']"
331321,How to find the value of positive integers $a$-through-$h$,"If the equation $(x-a)(x-b)(x-c)(x-d)(x-e)(x-f)(x-g) = hx$ has seven positive integer roots, and $a,b,c,d,e,f,g,h$ are positive integers too, how can we find them?","['algorithms', 'number-theory']"
331328,"Prove or disprove: If $x^T A x = 0 $ for all $x$, then $ A = 0 $.","Let $A$ be a square matrix and $x$ be a vector. Now consider the statement: If $x^T A x = 0 $ for any $x$, then $A = 0$. Is the above statement true or false?
How would you prove it?",['linear-algebra']
331337,Multivariate Taylor Expansion,"I am in confidence with Taylor expansion of function $f\colon R \to R$, but I when my professor started to use higher order derivatives and multivariate Taylor expansion of $f\colon R^n \to R$ and $f\colon R^n \to R^m$ I felt lost. Can somean explain to me from scratch multivariate Taylor? In particular I don't understand the notation
$$
f(x+h) = \sum_{k=0}^p \frac{1}{k!} f^{(k)}(x)[h,...,h] + O(h^{p+1})
$$
Why we need the k-linear form $ \frac{1}{k!} f^{(k)}(x)[h,...,h]$? This k-linear form is the derivative or the derivative is only $f^{(k)}(x)$? I'm quite lost. Thank you.","['multilinear-algebra', 'real-analysis', 'taylor-expansion']"
331361,"An ""Itzykson-Zuber""-like integral","I been told that there exists an integration formula, which states (or something of this sort)
$$
\int_{U(N)} dU \det[(\mathbb I+XUYU^{-1})^{-r}\propto \frac{\det(1+x_iy_j)^{N-r-1}]_{i,j}}{\Delta_N(x)\Delta_N(y)},
$$
where $dU$ is the Haar-measure, $X=\text{diag}(x_1,\ldots,x_N)$ is a positive definite diagonal matrix with $x_i\neq x_j$ for $i\neq j$ (similar for $Y$), and
$$
\Delta_N(x)=\prod_{1\leq i<j\leq N}(x_i-x_j)
$$
is a Vandermonde determinant. This is somewhat similar to a Harish-Chandra-Itzykson-Zuber integral , but I haven't seen this specific kind before. Are anyone familiar with this kind of integrals, and how to solve them? I would be particular interested in references to the literature.","['matrices', 'reference-request', 'integration']"
331365,"Arrange $n$ men and $n$ women in a row, alternating women and men.","A group contains n men and n women. How many ways are there to arrange these people in a row if the men and women alternate? I got as far as: There are $n$ [MW] blocks. So there are $n!$ ways to arrange these blocks.
There are $n$ [WM] blocks. So there are $n!$ ways to arrange these blocks. Which makes the total ways to arrange the men and women in alternating blocks $2(n!)$ The correct answer is $2(n!)^2$ Where does the second power come from?",['combinatorics']
331383,Number of straight line segments determined by $n$ points in the plane is $\frac{n^2 - n}{2}$,"How can we prove by mathematical induction that for all $n$, the number of straight line segments determined by $n$ points in the plane, no three of which lie on the same straight line, is $\frac{n^2 - n}{2}$? (The line segment determined by two points is the line segment connecting
them.) I know we start with the base case, where, if we call the above equation $P(n)$, $P(0)$, for $0$ lines would be $0$. But I really have no idea how to begin the inductive step. How do we know what $k+1$ we're supposed to arrive at?","['induction', 'discrete-mathematics', 'proof-writing']"
331404,How to prove this identity $\pi=\sum\limits_{k=-\infty}^{\infty}\left(\frac{\sin(k)}{k}\right)^{2}\;$?,"How to prove this identity? $$\pi=\sum_{k=-\infty}^{\infty}\left(\dfrac{\sin(k)}{k}\right)^{2}\;$$
I found the above interesting identity in the book $\bf \pi$ Unleashed . Does anyone knows how to prove it? Thanks.","['pi', 'trigonometry', 'sequences-and-series']"
331410,Why is stopping time defined as a random variable?,"I've been given a crash course in stochastic processes and martingales for the purposes of a semester project on them. The guy I'm working with has been, I feel, a little vague in the definition of stopping times, and I can't seem to find anything on Wikipedia or Google that clarifies the issue for me. My problem is that stopping times are defined as random variables. But given the motivation for the concept of stopping times (aren't they basically meant to represent betting strategies?), that doesn't at all seem like how I would personally define stopping times. I would define a stopping time as a, in some sense, predicate , or a two valued function, that maps sequences of values to either STOP or NOT STOP. So given a sequence of values (representing the values of the stochastic process up to the present), the function tells you whether or not to stop. But instead, a stopping time is given by Wikipedia as: A stopping time with respect to a sequence of random variables $X_1, X_2, X_3,\ldots$ is a random variable $\tau$ with the property that for each $t$, the occurrence or non-occurrence of the event $\{\tau = t\}$ depends only on the values of $X_1, X_2, X_3, \ldots, X_t$. I can't see at all how to relate that to the notion of stopping times as betting strategies. If stopping time is a random variable with respect to a given sequence of values, doesn't that mean it's not a ""determined"" strategy? That sounds like you look at how much money you've made/lost so far, and then based on both that and the result of a coin flip (or something), decide whether or not to stop playing. I'm sure I'm wildly misunderstanding either the definition, the motivation, or both. Please avoid dipping too deeply into measure theory or filtrations, if possible.","['stochastic-processes', 'stopping-times', 'probability', 'martingales']"
331445,The epsilon-delta definition of continuity,As we know the epsilon-delta definition of continuity is: For given $$\varepsilon > 0\  \exists \delta > 0\ \text{s.t. } 0 < |x - x_0| < \delta \implies |f(x) - f(x_0)| < \varepsilon $$ My question: Why wouldn't this work if the implication would be: For given $$\varepsilon > 0\ \exists \delta > 0\ \text{s.t. } |f(x) - f(x_0)| < \varepsilon  \implies  0 < |x - x_0| < \delta ?$$,"['epsilon-delta', 'real-analysis']"
331455,"$X_n - X_{n-1}$ is i.i.d. mean 1. Is $\frac{1}{n}X_n$ ""nearly"" decreasing a.s.?","Let $0=X_0 \leq X_1 \leq X_2 \leq \cdots $ be an increasing sequence of random variables with $X_n - X_{n-1}$ i.i.d. and $\mathbb{E}(X_n - X_{n-1}) = 1$ for all integers $n > 0$. I want to show that almost surely for each $m$, there is an $M>m$ such that
$$
\frac{1}{M}X_M \leq \frac{1}{m}X_m.
$$ I've computed
$$
\mathbb{E}\left(\frac{T_{n}}{n} - \frac{T_{n-1}}{n-1} \right) = \frac{1}{n} - 1.
$$
and 
$$
\mathbb{E}\left(\frac{T_{M}}{M} - \frac{T_{m}}{m} \right) = (M-m)\sum_{n=m+1}^{M} \left(\frac{1}{n} - 1\right).
$$ I feel like I should be able to use this to show that
$$
\mathbb{P}\left(\text{there exists $m$ such that for all $M > m$: } \frac{1}{M}X_M > \frac{1}{m}X_m  \right) = 0
$$
by using independence and forming an infinite product. I'm not sure how to make this work. I would appreciate any help.","['probability-theory', 'probability', 'random-variables']"
331460,Concept of Linearity,"I hear so many terms involving the word ""linear"". Linear function, linear equation, linear system, linear operator, linear transformation, linear mapping, linear space, linear algebra, linear electrical circuits, linear filters, linear electrical elements, linear approximation, linear optimization. I'm getting crazy trying to understand the application of the ""linear concept"" to all this aspects (function, equation, mapping, system, operator, transformation, algebra, etc.) and I wish to know the one essence that is to be linear. What something has to be to be linear? If I say something is linear, what do I know for sure about that something (no matter what the something is)? I heard a definition of linearity is by homogeinity (scaling the input results in a scaled output) and addition (summing the inputs results in summing the outputs). Can I apply this simple definition to all the branches (operator, mapping, system, transformation, algebra, ...) I mentioned ? Do they all behave like a line ? y = ax + b, for example, is a line but doesn't behave like a line because y is not linear.","['linear-algebra', 'functions']"
331469,Open morphisms are dominant?,"This seems very elementary but I haven't been able to prove it: If $f : X \to Y$ is an open map of irreducible topological spaces, then it is dominant (maps generic points to generic points). It might hold for only schemes, but I'm not sure.","['general-topology', 'algebraic-geometry']"
331477,Computing the divisors of a meromorphic function defined by a hyperelliptic curve.,"Let $X$ be a hyperelliptic curve defined by $y^2=h(x).$ Let $\pi : X\to \mathbb{P}^1$ be the double covering map sending $(x,y)$ to $x$. Let $\omega=\pi^{*}(dx/h(x)).$ Compute div$(\omega)$. I know that div$(\omega)=\sum_{p\in X} Ord_p(\omega)p$. I think I have to use the following lemma but not sure how to handle the hyperelliptic curve. Lemma 2.6. Suppose that $F : X —>Y$ is a holomorphic map between Riemann 
  surfaces, and $\omega$ is a meromorphic 1-form on $Y.$ Fix a point $p\in X.$ Then 
  $ord_p(F^{*}\omega) = (1 + ord_{F(p)}(\omega)) mult_p(F) - 1.$ Edit: The following is from the book ""Algebraic curves and Riemann surfaces"" by R.Miranda. Hyperelliptic Riemann Surfaces:Let $h(x)$ be a polynomial of degree $2g+ 
1 + e,$ where $e$ is either 0 or 1, and assume that $h(x)$ has distinct roots. Form 
  the smooth affine plane curve $X$ by the equation $y^2 = h(x).$ Note that any hyperelliptic surface $Z$ defined by $y^2 = h(x)$ has an automor- 
automorphism $\sigma : Z —> Z,$ namely $\sigma(x,y) = (x,-y).$ Note that $\sigma$ is an involution, that is, $\sigma\circ\sigma = id.$ This involution is called the hyperelliptic involution on X. It commutes with the projection map $\pi: X —> C_{\infty}$ in the sense that $\pi \circ \sigma=\pi.$ Meromorphic Functions on Hyperelliptic Riemann Surfaces: Using 
the hyperelliptic involution $\sigma$, we can describe all meromorphic functions on a 
hyperelliptic Riemann surface $X,$ defined by an equation $y^2 = h(x).$ 
For any meromorphic function $f$ on X, the pullback function $\sigma*f = f\circ \sigma$
also meromorphic on $X,$ since $\sigma$ is a holomorphic map. Since $\sigma^2= id,$ the sum 
$f+ \sigma^{*}f$is $\sigma^*$-invariant: $\sigma^*(f + \sigma^*f) = f + \sigma^*f. $
Now the basic example of a $\sigma^*$-invariant function is one which is pulled back 
from $\mathbb{C}_{\infty}$. This is a function $g$ of the form $g = \pi^*r = r\circ \pi$ for some meromorphic function $r$ on $\mathbb{C}_{\infty}.$ Any suggestions? Thanks.","['riemann-surfaces', 'algebraic-geometry', 'elliptic-curves', 'algebraic-curves']"
331499,Integral $\int\frac{6^x}{9^x-4^x}dx $,How to solve this integral: $$\int\frac{6^x}{9^x-4^x}dx $$ (I notice that $\frac{6^x}{9^x-4^x}=\frac{2^x3^x}{(3^x-2^x)(3^x+2^x)}$) Thank you!,['integration']
331504,Number of permutations of a specific cycle decomposition,"Let $X(n)$ denote number of all permutations of $\left\{1,\ldots,n \right\}$ that have only cycles of even length. Let $Y(n)$ denote number of all permutations of the same set that have only cycles of odd length. Count $X(2n)-Y(2n)$. I don't know even how to start. I counted this sum for $n=1,2,3$ and it seems that it is always equal to $0$, but it doesn't help with calculating it in general.",['discrete-mathematics']
331535,How to prove that every infinite cardinal $Z$ is equal the countable sum of sets of size $Z$?,"Any infinite cardinal $Z$ can be expressed as a countable union of disjoint sets, each of them has the same size $Z$. Any help will be appreciated.","['cardinals', 'elementary-set-theory']"
331537,How do I find the maximum and minimum values of $1−4\cos(2\theta)+3\sin(2\theta)$?,"To find the maximum of $$1 - 4\cos(2\theta) + 3\sin(2\theta) $$I tried:
$$1-4(1)+3(1)=0.$$
To find the minimum I tried to substitute with the minimum values of sin and cos:
$$1-4(-1)+3(-1)=2$$ I know I'm wrong, could someone explain why? And how I should go around obtaining the correct answer? Thanks","['trigonometry', 'maxima-minima', 'algebra-precalculus', 'solution-verification']"
331571,Left-Invariant Vector Field of a Lie Group,"How do I tell if a vector field on a Lie Group is left-invariant?  I have the technical definition.  But, I want to understand given a specific vector field what should I do to test if it is left-invariant?  For instance, here is a vector field in $\mathbb R^2$: $V(x, y)=y\partial/\partial x-x\partial/\partial y$ If this vector field (is/is not) left-invariant, can you provide me an example worked out as well of a vector field that (is not/is).","['multivariable-calculus', 'lie-groups', 'differential-geometry']"
331575,How to solve $4^x - 2^{x + 1} = 3 $ for x?,"We figured that this can be changed to $2^{2x} - 2^x \cdot 2 = 3$, but couldn't solve from there.  Perhaps we are not on the right path?",['algebra-precalculus']
331585,Divisibility - Math Olympiad: $x|(y^2+m)$ and $y|(x^2+m) $,"Show that for any positive integer $m$, there is an infinite number of pairs of integers $(x,y)$ satisfying the conditions: i) $\gcd(x,y)=1 $; ii) $y \mid x^2+m$; iii) $x \mid y^2+m$.","['divisibility', 'contest-math', 'number-theory', 'elementary-number-theory', 'vieta-jumping']"
331588,Reference to self-study Abstract Algebra and Category Theory,"I'm very interested in learning abstract algebra and category theory on my own. It seems a very powerful tool in math and it seems worthwile to take a time and learn about it. I just don't know even where to begin. Can someone point out for me what are good references to self-study those topics ? I'm really beginner, the only thing connected to algebra that I'm familiar with is linear algebra. Thanks very much in advance. Edit: Until now I've studied analytic geometry, single variable calculus, multivariable calculus, linear algebra, ordinary differential equations and I'm currently studying differential geometry and multilinear algebra.","['category-theory', 'reference-request', 'abstract-algebra']"
331626,How to get from $1 + (-1)^{n+1}$ to $1 + [((−1)^{n }) − 1] (−1)$,"I need some help with the algebra here. I have the following explanation, and I really can't follow the algebra. Could you also maybe give me some tips on how to think about such problems. $a_n = 1 + (−1)^n$ Basis Step: Specify $a_1$ by $a_1 = 1 + (−1)^1 = 0$. Recursive Step: Give a rule for ﬁnding $a_{n+1}$ from $a_n$, for $n ≥ 1$: $a_{n+1} = 1 + (−1)^{n+1}$ $= 1 + (−1)^n(−1)$ $= 1 + [((−1)^n + 1) − 1] (−1)$ $= 1 + (a_n − 1)(−1)$ $= 2 − a_n$ Thank you!","['algebra-precalculus', 'recursion']"
331631,What does it mean to have no proper non-trivial subgroup,"I am reading a first course in abstract algebra and there is a claim that says a group $G$ with no proper non trivial subgroups is cyclic. But I don't understand what does it mean to have no proper non trivial subgroup. I know that the identity element is trivial subgroup, all other subgroups are nontrivial and $G$ is the improper subgroup of $G$, and all others are proper subgroups. But what is proper non trivial subgroup? Thanks","['cyclic-groups', 'group-theory', 'abstract-algebra', 'definition']"
331649,How to sample point from triangle where vertex is not in origin,"This link http://mathworld.wolfram.com/TrianglePointPicking.html gives an overview of how to sample points from either a quadrilateral or triangle given one vertex is at the origin.  The standard formula is:  $x=a_{1}v_{1}+a_{2}v_{2}$ where $a_1$ and $a_2$ are from the distribution $U(0,1)$. Also, I am not sure of the intuition behind this formula as to why this yields random samples. EDIT: I know you simply add the offset vertex if the vertex is not in the origin. But the point is then contained in the quadrilateral. If I only want the points formed by a particular triangle in the quadrilateral, do I simply reject points that are not inside the vertices of the triangle?","['statistics', 'optimization']"
331654,Imposing the topology of open rays in $\Bbb R$,"After having received Brian M. Scott's permission (see comments in the selected answer) I am integrating his suggestions with my own solutions to form a complete answer to the questions apperaing below. Let $\mathscr{T}$ be the collection of subsets of $\Bbb R$ consisting
  of $\emptyset, \Bbb R$ and the rays of the form $(r, \infty)$,
  where $r \in \Bbb R$. $(a)$ Exhibit that this, indeed, is a topology on $\Bbb R$. Proof : Given any finite number of open sets of the form above, $\exists$ a maximal $r_n$. The set $(r_n, \infty)$ is the intersection of these finite sets. Let $\{U_i\}_{i \in I}$ be an arbitrary family of open sets. Let $r_{\min} = \inf\{r_i\}$. Then $(r_{\min}, \infty)$ is the union of the $U_i$ and clearly it is of the desired form to be an element of the topology. If $r_{\min} = -\infty$ then the union of the $U_i$ is the entire $\Bbb R$. $(b)$ Show that it fails to be a topology if $r \in \Bbb Q$. I don't have the full answer to this. I think that there should be a problem in the union of arbitrarily many open sets. Any help with a counterexample will be very helpful. Answer the following questions. Is $(\Bbb R, \mathscr{T})$: $(c)$ $T_1$? No. Let $x_1 \neq x_2 \in \Bbb R$ and assume without loss of generality that $x_1 < x_2$. Then any open set containing $x_1$ will be of the form $x_1 - \epsilon, \infty$ for some $\epsilon > 0$ and will encessarily contain $x_2$. $(d)$ Hausdorff No. Being Hausdorff (or $T_2$) would imply that it is $T_1$, a contradiction to (a). $(e)$ metrizable No. If there was a metric, the metric space would have to be Hausdorff, contradicting (b). $(f)$ second - countable I have no idea on how to go about this one. $(g)$ compact No. There exists no finite cover of this space. Suppose we are given a finite cover of this space. Then there exists a minimal $r$ such that $(r_{\min}, \infty)$ covers the entire space. Of ,course, this is only possible if $(r_{\min}, \infty) = \Bbb R$. $(h)$ locally compact Yes. We need to exhibit that any point has a compact neighbourhood. To this end, fix $x \in \Bbb R$. Let $(r, \infty)$ be a neighbourhood of $x$ and let $\{U_i\}_{i \in I}$ be an open cover. Then, there must exist $q \in \Bbb R$ such that $q \ge r$ so that $(q, \infty)$ is a set of the open cover. Clearly, taking $(q, \infty)$ as the subcover completes the proof. $(i)$ connected In part $(j)$ we prove that $(\Bbb R, \mathcal{T})$ is path-wise connected, hence connected. $(j)$ path-wise connected $\Bbb R$ is convex. Given $x, y \in \Bbb R$, the path $f: [0,1] \to \Bbb R$ given by $f(t) = (1-t)x + ty$ is continuous and $f(0) = x$ and $f(1) = y$. Since path-wise connected implies connected we also answered $(i)$. What is the closure of $\{1\}$ in $(\Bbb R, \mathcal{T})$? Proof : Since the closure is the smallest closed set containing $\{1\}$, it is clear that it is $(-\infty, 1]$ Any suggestions, corrections, hints and any help, in general, will be tremendously appreciated! Any stylistic improvements in the formatting of the question are also greatly encouraged!","['general-topology', 'connectedness', 'metric-spaces', 'compactness']"
331656,Runge-Kutta 4 - solving system of 6 differential equations (BVP),"I'm facing a tricky problem. I need to solve a system of 6 differential equations numerically, but I don't have 6 IVP (initial value problem) conditions, instead I have 6 BVP (boundary valye problem) conditions (3 conditions at $x=0$ and 3 conditions at $x=l$, being $l$ the last point to compute, thus $0<x<l$). So I need to convert the 3 boundary conditions at $x=l$ into 3 at $x=0$ (through the shooting method for example) so I have all 6 IVPs to solve my problem numerically through RK4. So far so good. I have two problems to solve. The first has the following form: \begin{cases}
    \frac{dT}{dx}&=f_1(g)  &(1)\\
    \frac{dV}{dx}&=f_2(e)   &(2)\\
    \frac{dM}{dx}&=f_3(V,g)  &(3)\\
    \frac{dK}{dx}&=f_4(x,M,T)  &(4)\\
    \frac{dg}{dx}&=f_5(x,T)  &(5)\\
    \frac{de}{dx}&=f_6(K)  &(6)\\
\end{cases} With the following BVPs: \begin{cases}
    T(0)&=c_1  \\
    T(l)&=0  \\
    V(0)&=c_2  \\
    V(l)&=0  \\
    M(0)&=c_3  \\
    M(l)&=0  \\
\end{cases} Through the shooting method I need to find $K(0)$, $g(0)$ and $e(0)$. 
In this case I can trivially find $g(0)$ because (1) and (5) are linearly dependent. To find $K(0)$ and $e(0)$ I shoot, for example: \begin{cases}
K(0)=+1 \text{ and } e(0)=+1 \\
K(0)=+1 \text{ and } e(0)=-1 \\
K(0)=-1 \text{ and } e(0)=-1 \\
K(0)=-1 \text{ and } e(0)=+1 \\
\end{cases} Then I record the final values for $V(l)$ and $M(l)$ for each case, make an approximating polynomial for each ($f_V=f(K,e)$ and $f_M=f(K,e)$ respectively), and solve the resulting system for $K$ and $e$: \begin{cases}
	f_V(K,e)=0 \\
	f_M(K,e)=0
\end{cases} The resulting $K(0)$ and $e(0)$ give me fairly good values (if I use approximating polynomials of order 1 I have an error of $10^-8$, more than acceptable for what I need).
Thus, my first problem is solved. The second problem is the real issue. The system is now: \begin{cases}
    \frac{dT}{dx}&=f_1(e,g)\\
    \frac{dV}{dx}&=f_2(e,g)  \\
    \frac{dM}{dx}&=f_3(V,e,g) \\
    \frac{dK}{dx}&=f_4(x,M,T) \\
    \frac{dg}{dx}&=f_5(x,T) \\
    \frac{de}{dx}&=f_6(K) \\
\end{cases} Also, there are now hyperbolic tangents involved (I have $g(x)$ inside $tanh()$ for example). I can't find any of $K(0)$, $g(0)$ or $e(0)$ trivially because now all equations depend on the others. So, my initial idea was to use the same shooting methodology but creating polynomials with 3 variables ($K$, $g$ and $e$) instead of just $K$ and $e$ like I used before. This isn't producing viable results, even if I use higher orders of polynomials. My question is: what can I do ? I don't mind changing methodologies or solving using other methods, I just need some directions so I can correctly solve this. I wholeheartedly welcome different perspectives on this.  I'm using maxima, for what it's worth. Also, I can determine the correct $K(0)$, $g(0)$ and $e(0)$ (through an external Maple file), and if I input those into my program I get correct results, so I know all the equations are correctly inputted. Thank you ! EDIT2: The system I'm aiming to solve is the following: \begin{cases}
    \frac{dT(x)}{dx}&={{3339\,{\it g(x)}\,\tanh \left({{50000\,\sqrt{8427\,{\it g(x)}^2+30036
 \,{\it e(x)}^2}}\over{163611}}\right)}\over{\sqrt{8427\,{\it g(x)}^2+
 30036\,{\it e(x)}^2}}}\\
    \frac{dV(x)}{dx}&={{12600\,{\it e(x)}\,\tanh \left({{50000\,\sqrt{8427\,{\it g(x)}^2+
 30036\,{\it e(x)}^2}}\over{163611}}\right)}\over{\sqrt{8427\,{\it g(x)}^
 2+30036\,{\it e(x)}^2}}}  \\
    \frac{dM(x)}{dx}&={{5\,\sqrt{8427\,{\it g(x)}^2+30036\,{\it e(x)}^2}\,{\it V(x)}-10017\,
 {\it g(x)}\,\tanh \left({{50000\,\sqrt{8427\,{\it g(x)}^2+30036\,
 {\it e(x)}^2}}\over{163611}}\right)}\over{5\,\sqrt{8427\,{\it g(x)}^2+
 30036\,{\it e(x)}^2}}} \\
    \frac{dK(x)}{dx}&=-{{60092431565\,x+15000000000\,{\it T(x)}+25000000000\,{\it M(x)}-
 2410745228515}\over{48076923076923}} \\
    \frac{dg(x)}{dx}&={{3281046763449\,x+1069000000000\,{\it T(x)}-156626689476919}\over{
 5250000000000000}} \\
    \frac{de(x)}{dx}&={\it K(x)} \\
\end{cases} Boundary conditions are: \begin{cases}
	T(0)=200 \\
	V(0)=-4.8073945252 \\
	M(0)=-47.1403817188 \\
	T(l)=0 \\
	V(l)=0 \\
	M(l)=0 \\
\end{cases} Where $l=25mm.$","['ordinary-differential-equations', 'maxima-software', 'numerical-methods', 'polynomials']"
331694,Cantor set on the circle,Draw a Cantor set C on the circle and consider the set A of all the chords between points of C. Prove that A is compact.,"['general-topology', 'analysis']"
331710,"Area of a parallelogram, vertices $(-1,-1), (4,1), (5,3), (10,5)$.","I need to find the area of a parallelogram with vertices $(-1,-1), (4,1), (5,3), (10,5)$. If I denote $A=(-1,-1)$, $B=(4,1)$, $C=(5,3)$, $D=(10,5)$, then I see that $\overrightarrow{AB}=(5,2)=\overrightarrow{CD}$. Similarly $\overrightarrow{AC}=\overrightarrow{BD}$. So I see that these points indeed form a parallelogram. It is assignment from linear algebra class. I wasn't sure if I had to like use a matrix or something.","['geometry', 'cross-product', 'linear-algebra', 'area', 'determinant']"
331712,"A sequence of random variables which converges in distributon converges ""to"" some random variable","Let $(X_n)$ be a sequence of random variables on a probability space $\Omega$, with distribution functions $F_n$. Suppose $F_n \rightarrow F$ in distribution for some distribution function $F$. Must there be a random variable $X$ on $\Omega$ with $X_n \rightarrow X$ in distribution? This seems like the sort of result one would want to be true, but I couldn't think of a way to prove it. To do so, one would need to somehow define $X$ ""backwards"" given its distribution $F$. Does anyone have any ideas?",['probability-theory']
331715,Artinian topological space are compact,Call a topological space $X$ Artinian if every nested sequence of closed sets $$C_1 \supset C_2 \supset C_3 \supset \cdots$$ is eventually constant. Prove that if $X$ is Artinian then it is also compact. I don't have a concrete strategy for attacking this. I am assuming (maybe wrongly so) that appealing to the finite intersection property might be of some help. Is this the case? Should I employ a different strategy? Thank you very much in advance!,"['general-topology', 'compactness']"
331733,Is Induction Independent of the Other Axioms of PA?,"I am trying to come up with a model of first order Peano Arithmetic (PA) where induction fails. Let $PA^{-IND}$ have the same axioms as PA except the first order induction axiom schema is replaced with its negation. I need to show there exists a predicate, $P$, that makes first order induction false. $P$ must satisfy $P(0) \land \forall x(P(x) \rightarrow P(Sx))$, yet $\forall x(P(x))$ is false. We can prove multiplication is commutative using double induction on $P(x,y)= (xy=yx)$. Why Does Induction Prove Multiplication is Commutative? Consider the 2x2 matrices $M_2(N)$ with the standard definitions for matrix addition and multiplication. Let the zero matrix be $0$ and the identity matrix be $S0$. $\forall x(Sx=x+S0)$ is a theorem of $PA^{-IND}$. Matrix multiplication is not commutative, yet we can prove multiplication is commutative for all the successors of $0$. Would $M_2(N)$ be a model of $PA^{-IND}$? The negation of first order induction says there exists a predicate:
$P(0) \land \forall x(P(x) \rightarrow P(Sx)) \land Ex( Not(Px))$ This looks like quantification over predicates but it isn't. The induction schema requires us to add an infinite number of axioms to the language. The negation of induction only requires the addition of a single axiom. Unlike PA, $PA^{-IND}$ has a finite number of axioms. I have simply added a new predicate to the language. I am using the axioms of PA given by Wikipedia for First Order Arithmetic . These axioms use induction to prove commutativity. Without induction, these axioms are very weak. They don't even require addition to be commutative. I would be interested in any model of $PA^{-IND}$.","['matrices', 'induction', 'peano-axioms', 'model-theory']"
331736,Continuity of a function to the integers,"I am trying to prove that in $\mathbb{Z}$ with co-finite topology the only path-connected components are the singletons. 
(I reckon that) showing that ""if a function $\gamma : [0,1] \to \mathbb{Z}$, where $\mathbb{Z}$ has
  co-finite topology, is continuous then it is constant"" should do the trick. However I am not sure this is true, let alone if this is a good approach to the problem. Any thoughts about it? Edit : I was thinking: suppose $x,y \in \mathbb{Z}$ and $\gamma : [0,1] \to \mathbb{Z}$, where $\mathbb{Z}$ has co-finite topology. Further suppose $x \neq y$, then $f^{1}(\mathbb{Z}\setminus \{x\})=(0,1]$ which is not open in $[0,1]$, contradicting continuity. Hence $x=y$. Does it seem right? Edit 2 :  Forget the (stupid) edit above!",['general-topology']
331768,"First countable, ccc, Hausdorff space","How to prove that every first countable, ccc, Hausdorff space has cardinality at most $2^\omega$ by use the Erdős-Rado theorem? Erdős-Rado theorem: Let $\kappa$ be an infinite cardinal. Let $E$ be a set with $|E|>2^\kappa$, and suppose $[E]^2=\bigcup_{\alpha<\kappa}P_\alpha$. Then there exists $\alpha<\kappa$ and a subset $A$ of $E$ with $|A|>\kappa$ such that $[A]^2\subset P_\alpha$. Thanks ahead:)","['general-topology', 'set-theory']"
331770,Radius of convergence and ratio test,"My book says that given a power series $\sum_{n = 1}^\infty c_nz^n$ where the $c_n$ are complex the radius of convergence of the series is $\dfrac{1}{L}$ where $L = \lim \sup \sqrt[n]{|c_n|}$.  So the radius of convergence is defined using the root test.  Since we can also apply the ratio test, is it fair to say, that the radius of convergence is $\dfrac{1}{L}$ where $L = \lim \sup \bigg|\dfrac{c_{n+1}}{c_n}\bigg|$?",['complex-analysis']
331784,$ n $ lines intersections,"As we all know, $ n $ lines which are not coincident may have some intersection points in an Euclid plane. And we define the set of the number of intersection points $ n $ lines can form is $ \mathbb{I} $, and we also define the complementary set $ \mathbb{B} = \{k \; | \; 0 \leq k \leq C_{n}^{2}\} - \mathbb{I} $. The question is, how can we find the maximum value in the set $ \mathbb{B} $, which we called $ L(n) $. If can't, could you prove that $$ \lim_{n \to \infty} \frac{L(n)}{n^{2}} = 0 $$ PS. For example, 5 lines may have 0, 1, 4, 5, 6, 7, 8, 9 intersection points, so set $ \mathbb{I} = \{0, 1, 4, 5, 6, 7, 8, 9\} $
ans set $ \mathbb{B} = \{2, 3\} $, so the $ L(5) = 3 $","['recurrence-relations', 'limits', 'number-theory']"
331788,Does $n^2+1\nmid n!$ hold for infinitely many $n\in\mathbb N$?,How many positive integers $ n $ satisfy that $ n^2+1 \nmid n! $; are there infinitely many?,['number-theory']
331790,Do the conjugacy classes of a group form a quotient group?,"Do the conjugacy classes of a group form a quotient group, $G / \sim$ ? Thanks",['group-theory']
331801,Embedding of free $R$-algebras,"Let $R$ be any nontrivial commutative unital ring and $I$ and $J$ any sets with $|I|>|J|$. Does there exist an embedding of $R$-algebras $R[x_i; i\in I]\longrightarrow R[y_j;j\in J]$? When $R$ is a domain, the question has been answered negatively here , via transcendence degrees.","['commutative-algebra', 'ring-theory', 'abstract-algebra']"
331815,Construct disjoint sequence of infinite subsets of $\mathbb{N}$ whose union is not $\mathbb{N}$ [duplicate],This question already has answers here : Expressing $\Bbb N$ as an infinite union of disjoint infinite subsets. (4 answers) Closed 8 years ago . Possible to construct a disjoint sequence of infinite subsets of $\mathbb{N}$ whose union is not $\mathbb{N}$? I am thinking this must be possible. I've considered trying to define each sequence as the range of some function. I have to find a way to hop over natural numbers in some way to leave infinitely many left for each subsequent subset of $\mathbb{N}$. Thinking about just leaving out $1$ so then the union isn't $\mathbb{N}$. I haven't tried to do anything like this before. Any possible hints on how this can be done and I can think a little more to see if I can come up with something? If not I may just ask for an answer heh. Thanks much for your time and input I appreciate it very much.,['elementary-set-theory']
331826,Expressing a matrix as an expansion of its eigenvalues,"This shouldn't be too difficult but I can't find a satisfactory proof. Show that a real, symmetric matrix $A$ with dimensions $D \times D$ satisfying the eigenvector
  equation $Au_{i} = \lambda u_{i}$ can be expressed as an expansion of
  its eigenvalues in the following way: $$A = \sum_{i=1}^{D}\lambda_{i}u_{i}u_{i}^{T}$$ and similarly, the
  inverse $A^{-1}$ can be expressed as $$A^{-1} = \sum_{i=1}^{D}\frac{1}{\lambda_{i}}u_{i}u_{i}^{T}$$ I suppose this is an alternative form of eigendecomposition. I know this can be proved using $AU = U\Lambda$ where $\Lambda$ is a diagonal matrix and $U$ an orthogonal matrix, but it's a somewhat tedious procedure. An additional question: Do I need to assume a real, symmetric matrix? Thanks a lot","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
331829,"Finding the sum $\sum\limits_{n=1,n\neq m^2}^{1000}\left[\frac{1}{\{\sqrt{n}\}}\right]$,","Find the value 
$\displaystyle\sum_{n=2,n\neq m^2}^{1000}\left[\dfrac{1}{\{\sqrt{n}\}}\right]$, by $\{x\}=x-[x]$,
$[x]$was bracket function,for example:$[5.4]=5, [2.9]=2,[-1.1]=-2 $and so on.",['sequences-and-series']
331830,Power Rule for group,"Is it true that, for $x$ integer
$$(ab)^x=b^xa^x?$$
I believe the fact $$(ab)^x=(a^xb^x)$$ is not true in general, right?","['group-theory', 'abstract-algebra']"
331833,Limit involving a hypergeometric function,"I am new to hypergeometric function and am interested in evaluating the following limit: $$L(m,n,r)=\lim_{x\rightarrow 0^+} x^m\times {}_2F_1\left(-m,-n,-(m+n);1-\frac{r}{x}\right)$$ where $n$ and $m$ are non-negative integers, and $r$ is a positive real constant. However, I don't know where to start.  I did have Wolfram Mathematica symbolically evaluate this limit for various values of $m$, and the patters seems to suggest the following expression for $L(m,n,r)$: $$L(m,n,r)=r^m\prod_{i=1}^m\frac{n-i+1}{n+i}$$ which one can re-write using the Pochhammer symbol notation as follows: $$L(m,n,r)=r^mn\frac{(n)_m}{n^{(m)}}$$ If the above is in fact correct, I am interested in learning how to derive it using ""first principles"" as opposed to the black box that is Wolfram Mathematica.  I am really confused by the definition of hypergeometric function ${}_2F_1(a,b,c;z)$, as the defition that uses the Pochhammer symbol in the wikipedia page excludes the case that I have where $c$ is a non-positive integer.  Any help would be appreciated.","['special-functions', 'limits']"
331844,Bias of Estimator with square root of a sum of squared random variables,"Got a distribution of
$f_X(x;\theta) = (x/\theta^2) \exp(-x^2/2\theta^2)$ for $x \ge 0$ where the MLE is calculated as
$\theta_{MLE} = \sqrt{(\sum_{i=1}^{n}x^2_i)/2n}$ So now need to find if it's unbiased by taking the expected value of the beast.
How would this be approached?",['statistics']
331853,$(x-a)(x-b)(x-c)(x-d)=ex$,"We can verify that $x=125,162,343$ are the roots of equation $(x-105)(x-210)(x-315)=2584x$.
My question is,Could you find five positive integers $a,b,c,d,e$, which $(x-a)(x-b)(x-c)(x-d)=ex$ has four positive integer roots?
Thanks in advance.","['elementary-number-theory', 'diophantine-equations', 'number-theory']"
331859,Finding the antiderivative of $\sin^6x\cos^2x$,"I need to find the antiderivative of 
$$\int\sin^6x\cos^2x \mathrm{d}x.$$ I tried symbolizing $u$ as squared $\sin$ or $\cos$ but that doesn't work. Also I tried using the identity of $1-\cos^2 x = \sin^2 x$ and again if I symbolize $t = \sin^2 x$ I'm stuck with its derivative in the $dt$. Can I be given a hint?","['calculus', 'integration']"
331866,Measure theory questions,"i. If $1 < p < \infty$ and $E = \{f_a, a \in A\}$ set of measurable functions of $\mathbb{R}$ and $\sup_{a \in A} ||f_a||_p < \infty$, I want to show that for $ 0 < q < p$, $\lim \limits_{x \rightarrow \infty} \sup \limits_{a \in A} \int_{|f_a| > x} |f_a|^q = 0$. ii. For bounded Borel $f$ on $\mathbb{R}$ where $\int fg = 0$ for all $g \in C_c(\mathbb{R})$, I want to show $ f=0$ a.e. iii. I want to show that $\forall \epsilon\gt0, \exists \delta\gt0$ s.t. $m(E \subseteq \mathbb{R}) < \delta \Rightarrow \int_E |f_a|^q < \epsilon$ My thoughts were for one to use Hölder's inequality to  use Borel-Cantelli, but that didn't get me anywhere. For two, it seems obviously if $g \in C_c(\mathbb{R})$ then set of discontinuities are countable so then $f$ must be zero a.e.","['lebesgue-integral', 'measure-theory', 'uniform-integrability']"
331876,Do the pictures in Hartshorne Ex. 1.5.1 make sense?,"I have done exercise 1 of section 1.5 of Hartshorne and am able to determine that the curves (a),(b),(c) and (d) are respectively those with a tacnode, node, cusp and triple point. Now when I did this exercise in the back of my mind these were curves in $\Bbb{A}^2_k$ with $k = \Bbb{R}$. My question is: If $k$ is any arbitrary field of characteristic not equal to $2$ then do these pictures make sense? It seems to me that even to begin to label an $X$ - axis and $Y$ - axis assumes that we have an ordering on the field $k$. What happens if $k = \Bbb{C}$? Surely the pictures will not be accurate anymore. Here is the relevant picture from Hartshorne.",['algebraic-geometry']
331877,Non trivial solution over $\mathbb{Z}_p$,Suppose p is an odd prime. Prove that $a_1x_1^2 + a_2x_2^2 + a_3x_3^2 + a_4x_4^2 + a_5x_5^2 = 0$ always have non-trivial solution over $\mathbb{Z}_p$ for any choice of $a_i$ in $\mathbb{Z}$. where $\mathbb{Z}_p$ is the p-adic integers,['number-theory']
331881,On the set of the sub-sums of a given series,"Choose a sequence $(x_n)_{n\in\mathbb N}$  of nonnegative real numbers with finite sum $x=\sum\limits_{n\in\mathbb N}x_n$ and consider the set $X=\{x_I\mid I\subseteq \mathbb N\}$ where, for every $I\subseteq \mathbb N$,  $x_I=\sum\limits_{n\in I}x_n$. Thus, $X\subseteq[0,x]$. Question: Can the set $X$ fail to be closed? A motivation from probability theory is explained there . Note that $X=[0,x]$ if $x_n=1/2^n$ and that $X\neq [0,x]$ if $x_n=a^n$ for some $a$ in $(0,1/2)$ (yielding measure zero Cantor sets), but that in all these cases $X$ is closed.","['probability-theory', 'sequences-and-series']"
331887,Books on locally convex topological vector spaces,My friend asked me for a good book about locally convex topological vector space. I'm  not familar with this. Could you give me some good references on it?,"['book-recommendation', 'general-topology', 'locally-convex-spaces', 'reference-request', 'topological-vector-spaces']"
331888,$\cos{(A-2B)}+\cos{(B-2C)}+\cos{(C-2A)}=\cos{(2A-B)}+\cos{(2B-C)}+\cos{(2C-A)}$,"Let $A,B,C\in \mathbb{R}$ with $\sin{A}+\sin{B}+\sin{C}=0$. Prove that $$\cos{(A-2B)}+\cos{(B-2C)}+\cos{(C-2A)}=\cos{(2A-B)}+\cos{(2B-C)}+\cos{(2C-A)}$$",['trigonometry']
331906,"Maximum likelihood for $(\mu,\sigma)$ and other related questions","$$f(x)=\frac{1}{2\sigma}\exp\left(\frac{-|x-\mu|}{\sigma}\right)$$ $$\mu\in,\sigma>0$$ When trying to calculate the maximum likelihood for $(\mu,\sigma)$, I got as far as:
$\log L(\mu,\sigma)=-n \log(2\sigma)-\frac{-\sum|x_i-\mu|}{\sigma}$
and I'm not really sure how am I supposed to calculate the derivative according to $\mu$ and according to $\sigma$. I also got stuck in the calculation of $E(x)$ and $E(x^2)$ and would really appreciate any assistance. I think I should recognize a PDF in the integral, but since the limits do not span the entire range (because of the abs..) I'm not sure how to do it. Thanks!!","['statistics', 'probability', 'calculus-of-variations', 'probability-theory']"
331908,Proof: $A \neq \emptyset \implies A \nsubseteq \emptyset $,"I proof that, let $A$ a set and $A \neq \emptyset$, then $A \nsubseteq \emptyset$; Proof by contradiction: if $A \subseteq \emptyset$ then by property I have an absurd , in fact by hypothesis $A \neq \emptyset$, therefore $A \nsubseteq \emptyset$. Or, direct proof: by hypothesis $A \neq \emptyset$, then ""$A \nsubseteq \emptyset$ or $ \emptyset \nsubseteq A$"", but by property I have only case that $ A \nsubseteq \emptyset$...
Is it correct?
Thank you all in advance","['proof-writing', 'elementary-set-theory']"
331913,"If $f_n(x_n) \to f(x)$ whenever $x_n \to x$, show that $f$ is continuous","From Pugh's analysis book, prelim problem 57 from Chapter 4: Let $f$ and $f_n$ be functions from $\Bbb R$ to $\Bbb R$. Assume that $f_n(x_n)\to f(x)$ as $n\to\infty$ whenever $x_n\to x$. Prove that $f$ is continuous. (Note: the functions $f_n$ are not assumed to be continuous.) here's my attempt: assume $x_n \to x$. we want to show that $f(x_n) \to f(x)$. so $|f(x_n) - f(x)| \leq |f(x_n)-f_n(x_n)| + |f_n(x_n)-f(x)|$. The second term can be made to be less than any $\varepsilon > 0$ for $n$ sufficiently large. i'm having trouble with the first term. can anyone help? thank you!",['real-analysis']
331922,A question on countably compact,"Here is a Lemma from this paper , which maybe helpful for the answering my question. A topological space $X$ is said to be star compact if whenever $\mathscr{U}$ is an open cover of $X$, there is a compact subspace $K$ of $X$ such that $X = \operatorname{St}(K,\mathscr{U})$. Let $\mathscr{U}$ be an open cover of $X$ and $\mathscr{V}\;$ be a finite subset of $\mathscr{U}$ covering $K$; if $\operatorname{St}(\cup\mathscr{V},\mathscr{U})=X$. Then we called $X$ is $1$-starcompact. Clearly, every star compact space implies  $1$-starcompact. My question is this: If $X$ is a regular star-compact, first countable, has the cardinality of $\aleph_1$, then is $X$ countably compact? Thanks ahead:) One direction: If 1-starcompact in this space is closed hereditarily, I think, the question will be solved.","['general-topology', 'compactness']"
331930,How to approach solving this indices example?,I am having problems working out how to approach solving this problem : $$\left(\frac{81}{16}\right)^n = \frac{32}{243}$$ How do I go about working out $^n$? Please step by step if possible.,['algebra-precalculus']
331948,How to draw the subgroup diagram of $\Bbb{Z}_n$ for specific n?,"I know how to find all the subgroups of $n$ for a specific values of $n$, for example for $n=18$, the subgroups of $\Bbb{Z}_{18}$ are: <1>={0,1, ... ,17}
<2>={0,2, ... ,16}
<3>={0,3, ... ,15}
<6>={0,6,12}
<9>={0,9}
<18>={0} But,  how do we draw the subgroup diagram of this? What are the steps? Here is the subgroup diagram that is given: Can anyone explain how to draw this? Thanks","['group-theory', 'abstract-algebra']"
331950,Pushforward measure integral property,"Let $\mu$ be a Borel measure on $X$ and $T: X \rightarrow Y$ a Borel map ($Y$ topological space). I define $$ T _* \mu(E) = \mu(T^{-1}(E))  \qquad \forall E \subset Y \quad \text{Borel} $$
It is easy to prove that $T_* \mu$ is a measure on $Y$. But why, if $f : Y \rightarrow \mathbb{R}$ is $L^1(T_* \mu)$,
$$ \int_Y f \ d T_* \mu = \int_X f \circ T \ d \mu$$","['measure-theory', 'analysis']"
331951,Natural way to define a free action of a finite abelian group,"Let $G$ be a finite abelian group. Then $G \simeq \mathbb{Z}_{u_1} \oplus \cdots \oplus \mathbb{Z}_{u_m}$, where $u_{i}$ is a power of some prime number. Without loss of generality I will consider $G = \mathbb{Z}_{u_1} \oplus \cdots \oplus \mathbb{Z}_{u_m}$. Let $Y$ be an infinite set. I introduce a set
$$
  \mathcal{Y} = Y^{u_1 \times\cdots \times u_m} \setminus \mathcal{Y}_0,
$$
where $\mathcal{Y}_0$ is the diagonal of $Y^{u_1 \times \ldots \times u_m}$:
$$
\mathcal{Y}_0 = \left\{ \left\{ y_{i_1,\ldots,i_m} \right\} \in Y^{u_1 \times \cdots \times u_m} \mid y_{k_1,\ldots,k_m}=y_{j_1,\ldots,j_m} \, \forall k_1,\ldots,k_m, j_1,\ldots,j_m   \right\}.
$$
I define an action of $G$ on $\mathcal{Y}$ by the rule
$$
   (l_1,\ldots,l_m) \cdot \left\{ y_{i_1,\ldots,i_m} \right\} = \left\{y_{i_1 + l_1\pmod{u_1}, \ldots, i_m + l_m\pmod{u_m}} \right\}.
$$
It is just a circular shift of multidimensional matrix $\left\{ y_{i_1,\ldots,i_m} \right\}$ in each dimension by appropriate number of positions. If $m=1$ then this action is free if and only if $u_1$ is prime. For $m>1$ this action is never free. For example for $G = \mathbb{Z}_2 \oplus \mathbb{Z}_2$ we have
$$
    (1,0) \cdot \begin{bmatrix} 1  & 2 \\ 1 & 2   \end{bmatrix} = \begin{bmatrix} 1  & 2 \\ 1 & 2   \end{bmatrix}.
$$
My question is if there is a natural way to generalize the above construction $\mathcal{Y}$ so that an analogous (in some sense) action of $G$ will be free for a more general class of finite groups? For example for $\mathbb{Z}_{p^k}$ or $\mathbb{Z}_{p} \oplus \mathbb{Z}_{q}$?","['finite-groups', 'group-actions', 'abstract-algebra']"
331962,Linear ODE question,"We have an first order ODE : Equation1 :   $y' + y = x$  ? 
We can view the left-hand side as an operator acting on $y$. In that case $L=(d/dx + 1)$ $L(y_1) = x$ $L(y_2)=x$ $L(y_1+y_2)=x$ So, clearly $L(y_1+y_2) = x \neq L(y_1)+L(y_2) = 2x$ So why is $y'+y=x$ is a linear ODE ?",['ordinary-differential-equations']
331966,References on Constrained Least Squares Problems?,"I have met some constrained least square problems, for example, my last post . I found that there are various methods for slightly different constraints, and still I often had little clue about how to solve such problems that I have met. I have learned some nonlinear optimization and had some good references.
I wish to learn more about constrained least square problems, such as what cases admit analytical solutions, and when a case has no analyitical solution, whether the case belongs to convex optimization, and if yes or no, what numerical methods can apply to it the best? So could someone recommend some references on this topic?
Thank you very much!","['optimization', 'linear-algebra', 'reference-request', 'real-analysis', 'numerical-methods']"
331967,Drawing subgroup diagram of Dihedral group $D4$,"I am reading Fraleigh p. 80 in A First 
Course in Abstract Algebra, and in the book i see the elements and subgroup diagram of the dihedral group $D_4$. Here are they: Here is how i try to draw the subgroup diagram: p 0 must be included in every subgroup since it is identity element. Then i look at p 1 , and try to find the subgroups including p 1 , since p 1 is included, the inverse of it must be included also, and p 1 op 1 must be included also, and so on . I need to check whether the result of these computations make it closed. But this lookslike a very long process. Is there an easy way to do that? For example, by looking at u 1 can we immediately say that it is included or not in a subgrouo without checking all compositions of u 1 with u 1 ? Or by looking at p 1 can we find < p 1 > easily? Thanks","['group-theory', 'abstract-algebra']"
331982,How to prove the topological space is not metrizable？,"Let $Z$ be the set of positive integers. For each positive integer n, let $O_{n}=\{ n,n+1,n+2,\dots \}$.Let $λ=\{\emptyset,O_{1},O_{2}, \dots, O_{n}.\dots\}$. Then $(Z,λ)$ is a topological space but not metrizable. My proof is: Let $d(1,2)=\varepsilon_{1，2}$ , if $\forall x \in Z$, $d(1,2) \leq d(1,x)$ then choose $\delta < \varepsilon_{1，2}$, $B(1,\delta)$ only contains 1, and there does not exist a subset $\{1\}$ in λ, if $\exists x\in Z$ ，st $d(1,x)<d(1,2)$ then $B(1,\delta)$ does not contain 2 and 1 is in the set, and there is not a such set. so $(Z,λ)$ is not metrizable. Is this proof correct？Is the metrizable topological space arise from the metric space  have the same open set？ I read a book about topology but it does not explain it and I got confused",['general-topology']
331985,Is there a quick trick to write permutations of $S_n$ as products of transpositions?,"If I want to write $(123)$ as product of transpositions, I get $(13)(12)$.
For $(132)$ I get $(12)(13)$. For $(1234)$, I get $(14)(13)(12)$. Seems like I can write $(abcd)$ as $(ad)(ac)(ab)$. Is this is a  general trick that also works for larger $n$? Edit: As usernull suggested, would this be a correct prove by induction? Suppose that $(a_1 ... a_n)=(a_1 a_n)...(a_1 a_2)$. Then 
\begin{align}
(a_1 ... a_n a_{n+1})=&(a_1 a_{n+1})(a_1 ... a_n) \\
   \overset{\text{IH}}{=}& (a_1 a_{n+1})(a_1 a_n)...(a_1 a_2)
\end{align}","['permutations', 'finite-groups', 'abstract-algebra']"
331987,Finding x and y for continuous onto function,"$f:[0,1]\rightarrow [0,1]$ continuous onto function such that $f(0)=0=f(1)$. Then show that there exists distinct values $x,y$ belongs to $[0,1]$ such that $f(x)=\frac{1}{2}=f(y)$.
could you please tell some hint?",['analysis']
332000,Complex integral Q,"I have this question: Let C be an open (upper) semicircle of radius R with its centre at the origin, and consider $\int_C f(z) \, dz$ where $f(z)=\frac 1{z^2 + a^2}$ for real $a > 0$. 
Show that 
$$ \left|f(z)\right| \ \le \ \ \frac 1{R^2-a^2} \qquad\textrm{and} \qquad
\left|\int_C f(z) \, dz\right| \le \frac {\pi R}{R^2 - a^2} \, .$$ I'm not sure how to work out $\left|f(z)\right|$ - any help appreciated!","['inequality', 'complex-analysis']"
332007,Uspenskij-Tkachenko Theorem,"Theorem : For a Moscow space $X$, every 
  $G_\delta$-dense subset $Y$ of $X$ is C-embedded in $X$. Proof $^{1}$: Assume that $Y$ is not C-embedded in $X$. Then, as it is easy to see, there
are open subsets $V_1$ and $V_2$ of $Y$ such that their closures in $Y$ are disjoint, while
the intersection of the closures of $V_1$ and $V_2$ in $X$ is not empty. Fix a point $x$ in
$\overline{V_1}\cap \overline{V_2}$, and let $U_i$ be the interior of the closure of $V_i$ in $X$, $i = 1, 2$. Obviously,
$V_i\subset U_i$; therefore, $U_i$ is not empty.
Since $X$ is a Moscow space, we can find $G_\delta$-sets $P_i$ in $X$ such that $x\in P_i\subset \overline{U_i}$,
$i = 1, 2$. Then $P = P_1\cap P_2$ is a $G_\delta$-subset of $X$ and $x\in P$; therefore, $P\cap Y$ is
not empty. Clearly, every point of $P\cap Y$ belongs to the intersection of closures
of the sets $V_1$ and $V_2$ in $Y$ , which is impossible, since this intersection is empty,
by the choice of $V_1$ and $V_2$. A.V. Arhangel'skii, On a theorem of W.W. Comfort and K.A. Ross , Comment.Math.Univ.Carolin. 40,1 (1999)133–151; dml.cz . In Topological Groups and Related Structures , Theorem 6.1.7. p348 , he wrote more details for this theorem. Since $Y$ is not C-embedded in $X$ then $Y$ is not $C^{*}$- embedded in $X$, and Urysohn extension theorem implies that $Y$ contains two completely separated 
subsets $A$ and $B$ whose closures in $X$ intersect. Take open subsets $V_1$ and $V_2$ in $Y$ such that 
$A\subset V_1$, $B\subset V_2$ and the closures of $V_1$ and $V_2$ in $Y$ are disjoint. Clearly, the intersection 
of the closures of $V_1$ and $V_2$ in $X$ is not empty. How can we take open subset open subsets $V_1$ and $V_2$ of $Y$ such that their closures in $Y$ are disjoint? Thanks.",['general-topology']
