question_id,title,body,tags
3638863,Description of inverse image ideal sheaf as kernel of a morphism,"Let $Y \rightarrow \mathbb{P}^n$ be a finite scheme and let $Z \rightarrow \mathbb{P}^n$ be a closed subscheme. I read that there is an exact sequence $0 \rightarrow \mathcal{I}_Z \cdot \mathcal{O}_Y \rightarrow \mathcal{O}_Y \rightarrow \mathcal{O}_{Z \cap Y}\rightarrow 0$ . I can't figure out why this is the case. The description of the inverse image ideal sheaf in Hartshorne is pretty abstract, so I don't how to prove this by working over affine sets.",['algebraic-geometry']
3639079,"Minimal structure imposed on sets to define ""dimension""","How do you formally define dimension of a set without using metrics, charts, an atlas, or a vector space structure? $\mathbb{R}$ and $\mathbb{R}^2$ are equinumerous, but $\dim \mathbb{R} = 1 \neq 2 = \dim \mathbb{R}^2$ . Is there no way to formally talk about this without using span or basis vectors? Really, I'm looking for the minimal structure imposed on sets to talk about dimensionality of a set.","['general-topology', 'linear-algebra', 'dimension-theory-analysis']"
3639182,"$\varphi$ monotone,continuous on $[0,1]$. Show $\varphi$ is AC, iff for any borel $f_n\to f$ in $L^1$,$\{\varphi(f_n)\}$ converges in measure.","Let $\varphi$ be monotonic and continuous on $[0,1]$ . Show it is AC, iff for any borel sequence $f_n$ that converges in $L^1$ the sequences $\varphi(f_n)$ converges in measure. The forward direction follows from the fact that $f_n \to f$ in $L^1$ implies convergence in measure and continuity preserves convergence in measure on finite measures. The backwards direction is the one that is giving me a little more trouble. Since $\varphi$ is monotonic (WLOG its increasing) all we have to show is that $\nexists x$ s. t. $\int_{0}^{x}\varphi'\lt\varphi(x)-\varphi(0)$ . However I do not really know how to do that. Any hints would be highly appreciated.","['measure-theory', 'lebesgue-integral', 'real-analysis']"
3639186,Proving finite group is commutative if there are representatives of its conjugacy classes that commute pairwise,"Aluffi IV.1.11 suggests proving that if a group $G$ is finite and there exist $g_1, \dots, g_r$ — representatives of all the $r$ conjugacy classes such that they commute pairwise, then the group is commutative. He also gives a hint to think about the sizes of the classes. Working backwards, $G$ is commutative if $Z(G) = G$ , that is, if each conjugacy class is trivial, that is, its size is $1$ and $[g_i] = \{ g_i \}$ . But how do I prove this? I know this problem is solvable by resorting to the fact that for any $H$ a proper subgroup of $G$ , $G$ is never the union of conjugates of $H$ , but this fact is given as an exercise that follows this one, so I guess the author intended a different proof.","['group-theory', 'abstract-algebra', 'finite-groups']"
3639237,Solving $y''=\lambda y$,"""Show that all solutions of $y''(x)=\lambda y(x)$ on $0\leqslant x \leqslant L$ with $y(0)=y(L)=0$ are of the form $c\sin\left(\frac{k\pi}{L}\right)x.$ (Hint: write down all solutions of the o.d.e and impose boundary conditions.)"" Here is an image from the textbook I'm using describing this problem. I'm not sure what the hint means; what entails ""writing down all solutions""? I'm not sure what method I should use to begin approaching this problem.","['sturm-liouville', 'ordinary-differential-equations', 'real-analysis']"
3639253,Ahlfors' lemma of winding number,"On page 115 of Ahlfors Complex Analysis, he defines $$h(t) = \int_\alpha^t \frac{z'(t)}{z(t)-a} dt$$ Later on the page he states that $e^{h(t)} = \frac{z(t) - a}{z(\alpha)-a}$ , but I don't see how to arrive at that. Is there a result outside of complex analysis this relies on or am I just not seeing the algebra of it?",['complex-analysis']
3639342,Compute $ \oint_{C_{o}} \frac{1}{\sin \left(\frac{1}{z}\right)} d z-\oint_{C_{i}} \frac{1}{\sin \left(\frac{1}{z}\right)} \mathrm d z $,"Compute the integral $$
\oint_{C_{o}} \frac{1}{\sin \left(\frac{1}{z}\right)} d z-\oint_{C_{i}} \frac{1}{\sin \left(\frac{1}{z}\right)} \mathrm d z
$$ where the outer circle, $C_{o},$ is the unit circle and the inner circle, $C_{i},$ is the circle of radius $1 / 10$ centered at the origin. (HINT: What region is enclosed by these two curves?) I've adapted the power series of the given function from the Maclaurin series for the sine: $\left(\frac{1}{x} - \frac{1}{x^3} \frac{1}{3!} + \frac{1}{x^5} \frac{1}{5!} - \right)^{-1}$ . If I were to sketch this region I would find that this is the annular region less than radius R=1 and greater than radius r= $\frac{1}{10}$ , making the region $\frac{1}{10}<|z|<1$ . I believe the outer circle would be the Maclaurin series of the function given $|z|<1$ minus the inner circle which would be a Laurent series since $|z|>\frac{1}{10}$ . Are there any flaws in my thinking of which I should be aware? I feel as if I'm missing a small piece in order to correctly arrange these steps. Clarification: I'm aware I take the residues of each and multiply them by $2\pi i$ . I omitted these steps for clarity.","['complex-analysis', 'trigonometry', 'residue-calculus']"
3639358,Ramanujan's rational elementary results on $A^3+B^3=C^2$.,"In the bottom of one of the pages of Ramanujan's notebooks (see below), he writes down the following equations: $$\left(11\frac 12\right)^3+\left(\frac 12\right)^3=39^2$$ $$\left(3\frac 17\right)^3-\left(\frac 17\right)^3=\left(5\frac 47\right)^2$$ $$\left(3-\frac 1{105}\right)^3+\left(\frac 1{105}\right)^3=\left(5\frac 6{35}\right)^2$$ $$\left(3\frac 1{104}\right)^3-\left(\frac 1{104}\right)^3=\left(5\frac{23}{104}\right)^2$$ It is clear he was studying the equation $A^3+B^3=C^2$ just like how Euler did, but he also took it one step further and extended the solutions to the set of rational numbers. Now Ramanujan was particularly fond of finding remarkable general identities, but often his most curious ones was he going to remember the most. So he never really wrote them down, and predominantly wrote special cases of them. From the elegant form of the equations above, I presume he had a general identity. Empirically I have found a near solution (my best one). $$\left(14+\frac 13\right)^3+\left(\frac 13\right)^3\simeq \left(54+\frac{442}{1665}\right)^2$$ And some solutions with irrationals. $$\left(6-\frac 4{3\pm \sqrt 5}\right)^3+\left(\frac 4{3\pm \sqrt 5}\right)^3=12^2$$ $$\left(1\pm\frac 2{\sqrt 5-1}\right)^3\mp\left(\frac 2{\sqrt 5-1}\right)^3=2^2$$ Anybody know how Ramanujan got these results? I just factored out $(a+b)^3-b^3$ since the $b^3$ terms cancelled out, leaving me with quadratics, which is fairly simple. I think if Ramanujan had a general identity for this, it would do the same. Note that $(-1\frac 12)^3+(\frac 12)^3=0^2$ which is another solution to his first equation, and both solutions can be written as $\frac{10\pm 12}{2}$ and $\frac{39\pm 39}{2}$ which looks quadratic. Any thoughts? Thanks.","['number-theory', 'elementary-number-theory', 'fractions', 'algebra-precalculus', 'quadratics']"
3639371,What would be a good way to understand (A x A) - (B x C) = (A - B) x (A - C)?,"I'm studying Cartesian Products and am tasked with proving or disproving (A x A) - (B x C) = (A-B)x(A-C). However, I'm having difficulties understanding what, exactly, is being stated, and hence that prevents me from starting any type of proof. I think that what looms over my lack of understanding in this is how to work with the Cartesian product and the complement set, especially how those two concepts overlap in the problem. Could someone please provide some clarity?",['elementary-set-theory']
3639384,"If the columns of $A$ generate the subgroup $G$ of $X$, then $\vert\text{det}\;A\vert = X:G$.","I was recently reading a paper by Cantor and Mills , when I came across the following lemma. Let $m$ and $t$ be positive integers. Let $X$ be the additive group of all $m$ -dimensional column vectors with integer elements, let $Y$ be a finite set of t-dimensional column vectors with integer elements, and let c be the cardinality of $Y$ . Suppose that $A$ is an $m$ by $m$ matrix of integers and that $B$ is an $m$ by $t$ matrix of integers. If, for $x\in X$ and $y \in Y$ , the column vector $Ax + By$ determines $x$ and $y$ uniquely, then $\vert\text{det}\;A\vert \geq c$ . Proof. Let $G$ be the subgroup of $X$ generated by the columns of $A$ . Thus $G$ is the set of all vectors $Ax$ with $x \in X$ . By hypothesis, the column vectors of the form $Ax + By$ , with $x \in X$ and $y \in Y$ , are all distinct. Therefore as $y$ ranges over the $c$ elements of $Y$ , By ranges over $c$ distinct cosets of $G$ in $X$ . Hence the index $X:G$ of $G$ in $X$ is at least $c$ . On the other hand $X: G$ is equal to the absolute value of the determinant of $A$ . Thus, $$\vert\text{det}\;A\vert = X:G \geq c$$ and the proof is complete. I don't understand how the authors get $\vert\det A\vert = X:G$ and I wasn't able to prove it myself. Here's what I tried:
We want to find the number of sets $S$ of $m$ -dimensional column vectors with integer entries such that for all $c,c' \in S$ , there exists $x,x' \in X$ that satisfy $Ax + c = Ax' + c'$ . Note that $$Ax + c = Ax' + c' \implies x + \frac{\text{adj}(A) \cdot c}{\det A}= x' +  \frac{\text{adj}(A) \cdot c'}{\det A},$$ thus there exists a solution $x,x' \in X$ if each entry of $\text{adj}(A) \cdot c$ and $\text{adj}(A) \cdot c'$ is the same modulo $\det A$ . At first, I thought that we could get $\det A$ sets just by assigning one set to each integer from $1, \dots, \det A$ . However, not every entry of $\text{adj}(A) \cdot c$ can take on all values $1, \dots, \det A$ , and there are plenty of examples of $c,c'$ for which are congruent modulo $\det A$ in one entry but not in another. I can't seem to make any progress beyond this. I've looked for a proof of the above statement to no avail. Could anyone explain how to prove this statement? Thanks in advance.","['group-theory', 'abstract-algebra', 'linear-algebra']"
3639388,Prove it is a matrix group.,"Let $K$ be a field and let $X ∈ K^{n×n}$ be a matrix. Show
  that the set $$U := \{A \in GL_n(K) | A^
TXA = X\}$$ is a group with respect to matrix multiplication. For this exercise, 
associativity is pretty self explanatory since by nature matrices are associative.
I'm confused about how to show that it has an inverse .
For Identity, I think I would go about $A^
TXAI = XI=X$ but I'm not sure if it is correct.","['proof-explanation', 'matrices', 'solution-verification', 'linear-algebra', 'group-theory']"
3639397,Proving $\lim\limits_{N\to\infty}\mu\Bigl(\bigcup\limits_{n=N}^\infty(E\setminus E_n)\Bigr)=0$,"Let $E$ be a measurable set of $\mathbb{R}$ , and the characteristic function of a subset $A$ of $E$ is a function $$\mathbf1_A:X\to\{0,1\}$$ defined as $$\mathbf1_A(x):=\begin{cases}1&\text{ if }x\in A\\0&\text{ if }x\notin A\end{cases}.$$ Now let $\{E_{n}: n \in \mathbb{N}^+\} \subseteq E$ be a collection of subset of $E$ . Show that 1. The sequence $\{\mathbf{1}_{E_n}(x)\}$ uniformly converges to $\mathbf{1}_{E}(x)$ if and only if $\exists N \in \mathbb{N}^+$ , $\forall n \geq N$ such that $E=E_n$ . $\{\mathbf{1}_{E_n}(x)\}$ converges almost uniformly to $\mathbf{1}_{E}(x)$ if and only if $$\lim _{N \rightarrow \infty}\mu\left(\bigcup_{n=N}^\infty \left(E \backslash E_{n}\right)\right)=0,$$ where $\mu (⋅)$ denotes the Lebesgue measure. 3.The sequence $\{\mathbf{1}_{E_n}(x)\}$ converges to $\mathbf{1}_{E}(x)$ a.e.  iff $$\mu\left(\bigcap_{N=1}^\infty \bigcup_{n=N}^\infty \left(E \backslash E_{n}\right)\right)=0.$$ My attempt: 1: $\Longleftarrow$ it is quite obvious. $\Longrightarrow$ there exists a natural number $N$ such that $|\mathbf{1}_{E_n}(x)-\mathbf{1}_{E}(x)|<\epsilon$ for all $n \geq N$ and $x \in E$ , namely $|\mathbf{1}_{E_n}(x)-\mathbf{1}_{E}(x)|=0$ . Thus we obtain $E=E_n$ for all $n \geq N$ and $x \in E$ . 2: $\Longrightarrow$ By definition of almost uniformly, we have for every $\delta>0$ there exists a measurable set $E_{\delta}$ with measure less than $\delta$ such that $\{E_{n}: n \in \mathbb{N}^+\} $ converges to $\mathbf{1}_{E}(x)$ uniformly on $E \backslash E_{\delta}$ . I'm completely stuck on how to  proceed. Any help and comments  will be appreciated.","['measure-theory', 'real-analysis']"
3639484,"Is the topological space $ (X^{*},\sigma (X ^ {*}, X)) $ metrizable?","Definition 1: Let $X$ be a normed space. The operator \begin{align*}
    J_{X}\colon X&\to X^{**}\\
    x&\mapsto J_{X}(x)(x^{*})=x^{*}(x)
\end{align*} is called canonical lace (or canonical immersion ) of $X$ into $X^{**}. $ Lemma 1: Let $X$ be a normed space. Then the canonical immersion $J_{X}$ of $X$ into $X^{∗∗}$ is an isometric isomorphism. Definition 2: Let $ (X, \Vert \cdot \Vert) $ be a normed space. The weak- topology*, denoted by $ \sigma (X ^{*}, X), $ is the smallest topology at $ X ^{*} $ that makes every element of $ \{J_ {X} (x) \mid x \in X \} \subseteq {X ^{**}}$ continuous. Let \begin{equation*}
    X=c_{00}=\{x=(x_{n})_{n\in\mathbb{N}}\in\mathbb{K}^{\mathbb{N}}\mid \exists N\in\mathbb{N}, x_{n}=0, \forall n\geq N\}.
\end{equation*} Question: Is the topological space $ (X^{*},\sigma (X ^ {*}, X)) $ metrizable? Attempt: We know that $(c_{00},\Vert\cdot\Vert_{\infty})$ is a normed space, which is not Banach. A completion of $(c_{00},\Vert\cdot\Vert_{\infty})$ is \begin{equation*}
    c_{0}=\left\{y=(y_{n})_{n\in\mathbb{N}}\in\mathbb{K}^{\mathbb{N}}\ \middle|\ \lim_{n\rightarrow{\infty}}{x_{n}}=0\right\}
\end{equation*} that is, there is $J\colon c_{00}\to c_{0}$ linear such that $\Vert J(x)\Vert=\Vert x\Vert,\forall x\in c_{00}$ and $\overline{J(c_{00})}=c_{0}.$ Furthermore, we know that \begin{equation*}
    X^{*}=c_{0}^{*}=l_{1}=\left\{z=(z_{n})_{n\in\mathbb{N}}\in\mathbb{K}^{\mathbb{N}}\ \middle|\ \sum_{n\in\mathbb{N}}{z_{n}}<\infty\right\}.
\end{equation*} and \begin{equation*}
    l_{1}^{*}=l^{\infty}=\left\{w=(w_{n})\in\mathbb{K}^{\mathbb{N}} \ \middle|\ \sup_{n\in\mathbb{N}}\{|w_{n}|\}<\infty \right\}.
\end{equation*} I don't know if I can conclude what I want with the above.","['banach-spaces', 'isometry', 'functional-analysis', 'dual-spaces']"
3639552,Solution of the differential equation $\sin(x\frac{dy}{dx})\cos(y)=\frac{dy}{dx}+\sin(y)\cos(x\frac{dy} {dx})$,"Find the solution of the differential equation $\sin(x\frac{dy}{dx})\cos(y)=\frac{dy}{dx}+\sin(y)\cos(x\frac{dy}
{dx})$ My approach is as follow $A=x\frac{dy}{dx}$ $\sin(A)\cos(y)-\cos(A)\sin(y)=\frac{dy}{dx}$ $\sin(A-y)=\frac{dy}{dx}$ $\sin(x\frac{dy}{dx}-y)=\frac{dy}{dx}$ After this step I am not able to solve it,","['derivatives', 'ordinary-differential-equations']"
3639625,"Is $C^1[0,1]$ a measurable subset of $C[0,1]$?","I am wondering whether $C^1([0,1],\mathbb{R})$ , the set of continuously differentiable functions, is an element of the Borel $\sigma$ -algebra of $(C[0,1],\|\cdot \|_\infty)$ . As far as I know, it is neither open nor closed, but I feel like it would be natural for this to be true. If this is not the case, what about the set of (not necessarily continuously) differentiable functions?","['borel-sets', 'continuity', 'measure-theory', 'derivatives']"
3639637,How do Fourier-Mukai equivalences not contradict reconstruction theorems?,"Apparently there is a thing called Fourier-Mukai equivalence in which the derived categories of coherent sheaves of two distinct schemes (e.g. an abelian variety and its dual) can be equivalent. On the other hand there are lots of reconstruction theorems whose gist tend to be that a scheme is determined by its (derived) category of sheaves, e.g. Tannaka dualities and the Gabriel-Rosenberg reconstruction theorem. How do these not contradict each other?","['derived-categories', 'algebraic-geometry', 'abelian-varieties', 'sheaf-theory']"
3639680,Prove that every minor in a matrix is invertible.,"Let $\zeta_p=e^{\frac{2\pi i}{p}}$ where $p$ is a prime. Let $C=
\begin{pmatrix}
\zeta_p^{0 \times 0} & \zeta_p^{0 \times 1} & \dots & \zeta_p^{0 \times (p-1)} \\
\zeta_p^{1 \times 0} & \zeta_p^{1 \times 1} & \dots & \zeta_p^{1 \times (p-1)} \\
\vdots  &      \vdots &  & \vdots \\
\zeta_p^{(p-1) \times 0} & \zeta_p^{(p-1) \times 1} & \dots & \zeta_p^{(p-1) \times (p-1)}
\end{pmatrix}.$ Prove that every minor in this matrix is invertible. This matrix can be viewed as the character table of $\mathbb{Z}_p$ , which may be helpful.","['group-theory', 'linear-algebra']"
3639734,Possible Converse to a Corollary to the Artin-Wedderburn Theorem,"Let $\mathsf{K}$ be a field, and $A$ a finite dimensional associative $\mathsf{K}$ -algebra, and suppose that $\mathcal{L}$ is a complete collection of representatives of the isomorphism classes of irreducible left $A$ -modules. If $A$ is semisimple, then a corollary to the Artin-Wedderburn theorem states that $$
\dim_{\mathsf{K}} A = \sum_{L \in \mathcal{L}} (\dim_{\mathsf{K}}L)^{2}.
$$ I am interested in whether this corollary has a converse. That is, if this equality holds can we say that $A$ is semisimple? If the answer is yes is there a simple (semisimple?) argument that I'm missing here, or if it is false can you provide a counter-example? If it is false, are there extra suppositions that we can apply to $A$ or $\mathsf{K}$ to make the statement hold? (Perhaps characteristic zero or algebraically closed?)","['ring-theory', 'abstract-algebra', 'representation-theory', 'modules']"
3639748,"Calculating the volume limited by $y=z^2$, $z=x^2$, $x=y^2$, $2y=z^2$, $2z=x^2$, $2x=y^2$","I've tried calculating the volume limited by the surfaces $y=z^2$ , $z=x^2$ , $x=y^2$ , $2y=z^2$ , $2z=x^2$ , $2x=y^2$ . I didn't know how to begin so instead I tried solving for $y=z^2$ , $z=x^2$ , $x=y^2$ . So I checked where they intersect and they can only have values from $0$ to $1$ .
I projected over the $xy$ -plane and got: $$\iint_D\left(\int_0^{x^2}\mathrm dz\right)\,\mathrm dx\mathrm dy=\int_0^1\left(\int_0^{\sqrt x}x^2\,\mathrm dy\right)\,\mathrm dx=\frac25.$$ I don't think that I got this right, not really confident in what I did. If what I did is correct, how should I proceed to resolve the original problem now?",['multivariable-calculus']
3639820,Simpler proof of the Hardy-Littlewood-Sobolev inequality in the inhomogeneous case,"The Hardy-Littlewood-Sobolev inequality is the statement that there is a $C>0$ such that $$
\tag{HLS} 
\lVert f\ast \lvert\cdot\rvert^{-\alpha}\rVert_p\le C\lVert f\rVert_q, $$ for all $f\in L^q(\mathbb R^d)$ , where the convolution is defined as $$(f\ast \lvert\cdot\rvert^{-\alpha} )(x)= \int_{\mathbb R^d} \frac{f(y)}{\lvert x-y\rvert^{\alpha}}\, dy, $$ and the parameters satisfy the conditions $$\tag{1} 0<\alpha<d, \quad \frac1p-\frac1 q+1=\frac\alpha d.$$ Now let us define the Japanese bracket $$\langle x \rangle:= \sqrt{1+ \lvert x\rvert^2},\qquad x\in\mathbb R^d,$$ which is a non-homogeneous version of $\lvert\cdot\rvert$ . The function $\langle x\rangle^{-\alpha}$ has the exact same decay at $\lvert x \rvert \to \infty$ of its homogeneous counterpart $\lvert x \rvert^{-\alpha}$ , but $\langle x \rangle^{-\alpha}$ is not singular at $x=0$ . By the obvious estimate $\langle x\rangle^{-\alpha}\le \lvert x\rvert^{-\alpha}$ , (HLS) immediately implies its non-homogeneous version $$\tag{n-HLS} 
\lVert f\ast \langle\cdot\rangle^{-\alpha}\rVert_p\le C\lVert f\rVert_q, $$ under the assumptions (1). Question . Is there a direct proof of (n-HLS) that is simpler than a proof of (HLS)? Remark 1 . The inequality (n-HLS) actually holds for $\frac1 p - \frac1q +1 \le \frac{\alpha}{d}$ . However, the non-endpoint case $\frac1 p - \frac1q +1 < \frac{\alpha}{d}$ can be immediately proved by an application of the Young inequality for convolutions. Thus, the present question is concerned solely with the endpoint case (1). In the following, the letter $C$ will always denote an irrelevant positive constant, whose value may change from line to line. Remark 2 . There are many proofs of (HLS). One that I know uses the Hardy-Littlewood maximal function. By decomposing the ball $B(x, r)$ into dyadic annuli, we obtain the local estimate $$\tag{2}\left\lvert \int_{B(x, r)}\frac{f(y)}{\lvert x-y \rvert^\alpha}dy\right\rvert \le r^{d-\alpha}\sum_{j=0}^\infty 2^{\alpha j - dj} Mf(x)= C_{d, \alpha}r^{d-\alpha}Mf(x).$$ This constant $C_{d,\alpha}$ equals $\sum 2^{(\alpha  - d)j}$ , which is finite because $\alpha<d$ . Here $Mf$ denotes the Hardy-Littlewood maximal function $$
Mf(x):=\sup \frac1{\lvert B\rvert} \int_B \lvert f(y)\rvert\, dy,$$ where the sup is taken over all balls $B$ containing $x$ . We then estimate the tail of the convolution via the Hölder inequality; $$\tag{3}
\left\lvert \int_{\mathbb R^d\setminus B(x, r)}\frac{f(y)}{\lvert x-y \rvert^\alpha}dy\right\rvert\le C r^{\frac{d}{q'}-\alpha} \lVert f\rVert_q.$$ Combining (2) and (3) gives the pointwise bound $$
\tag{4} \lvert f\ast \lvert\cdot\rvert^{-\alpha}(x)\rvert \le C\left( r^{d-\alpha} Mf(x) + r^{\frac{d}{q'}-\alpha} \lVert f\rVert_q\right).$$ Choosing the $r$ that minimises the right-hand side, then integrating and applying the Hardy-Littewood maximal estimate $\lVert Mf\rVert_q\le C\lVert f \rVert_q$ , we obtain (HLS). This procedure will of course work if $\lvert\cdot\rvert^{-\alpha}$ is replaced by $\langle\cdot\rangle^{-\alpha}$ . However, I think that there shouldn't be the need for the careful dyadic analysis of equation (2). Indeed, $\langle x-y\rangle^{-\alpha}$ is not singular at $y=x$ . This is why I am asking for a simpler proof.",['real-analysis']
3639879,Does $C_{c}(\mathbb{R})$ have a countable Hamel basis?,I was wondering if $C_{c}(\mathbb{R})=\text { continuous functions with compact support }$ have countable Hamel basis. My intuition  tells me try to use Baire Category Theorem and I found one corollary saying that for an infinite-dimensional Banach space every Hamel basis is uncountable. However $C_c(\mathbb{R})$ s not even complete. Any help or hint? Thanks in advance.,['functional-analysis']
3639887,"Determine $f^{(22)}(0)$, when $f(x)=x^{19}\ln(1+2x)$","""Determine $f^{(22)}(0)$ , when $f(x)=x^{19}\ln(1+2x)$ ."" Here is my attempt. First, I wrote $f=gh$ , where $g=x^{19}$ and $h=\ln(1+2x)$ . The derivatives of both of these functions behave predictably at $x=0$ . For example, $g^{19} = 19!$ , taking further derivatives simply yields zero, and previous derivatives at $x=0$ are also zero, since they contain $x$ as a multiplier. The derivatives of $h$ behave according to this sequence $$\frac{{x_n}}{(1+2x)^n}$$ where ${x_n}=\{2,-4,16,-96,768,...\}.$ The denominator is $(1+2x)^n=(1+2 \cdot 0)^n=1^n =1$ , so the value of $h'$ is simply the value of the sequence at $n\in \Bbb{N}.$ Next I tried to find a pattern in the application of the product rule with $f=gh$ . Multiple applications yields $$f^1=g^1h+gh^1$$ $$f^2=g^2h+g^1h^1+g^1h^1+gh^2$$ $$f^3 = g^3h+g^2h^1+g^2h^1+g^1h^2+g^2h^1+g^1h^2+g^1h^2+gh^3$$ $$...$$ The idea was to find a way to connect $g^{19}$ with the correct values of $h'$ , then compute the value of $f^{22}$ with the help of these simple derivatives. I haven't found one yet, but I think it might be possible to find a pattern in repeated applications of the product rule, but before that I wanted to ask whether there is some flaw in my work. Also, I'm not entirely sure about this but might this https://en.wikipedia.org/wiki/General_Leibniz_rule help here?","['derivatives', 'real-analysis']"
3639983,Bound for the Fourier transform,"Can someone come up with a proof for this bound of the Fourier transformation? Let $f$ be $s$ times continuously differentiable, with compact support, then there exists a real constant $c$ such that: $$\vert F(k)\vert\leq \frac{c}{(1+\vert k\vert)^s},$$ where $F$ is the Fourier transform of $f$ . Since there is a compact support, the maximum of the function exists and the Fourier transformation is bounded, but where does the factor $(1 +\vert k\vert)^{-s}$ come from? Thanks","['mathematical-physics', 'fourier-transform', 'analysis']"
3640026,Why does rotating the function $-e^x$ 270 degrees seem to equal $\ln(x)$?,"I saw an illustration in my text book of common functions plotted on cartesian coordinate system, when I noticed a relationship between $e^x$ and $ln(x)$ . I noticed that $e^x$ looked awfully similar to $ln(x)$ , and in fact if you rotate $-1 \times e^x $ 270 degrees, the functions seem identical, and I can't put my finger on why that is. I know the two functions are closely related, but I have never been able see the relationship visually before. Why is this this the case? Are there any ways to prove this?","['proof-writing', 'functions']"
3640045,$7$ th derivative of function at $x=0$,If $\displaystyle y=\frac{\sin(x^2)-x^2}{x^3}$ . Then value of $\displaystyle \frac{d^7y}{dx^7}\bigg|_{x=0}=$ What i try $$\sin x=\sum^{\infty}_{n=0}(-1)^n\frac{x^{2n+1}}{(2n+1)!}$$ Replace $x\rightarrow x^2$ Then $$\sin (x^2)=\sum^{\infty}_{n=0}(-1)^n\frac{x^{4n+2}}{(2n+1)!}$$ $$\frac{\sin(x^2)-x^2}{x^3}=\sum^{\infty}_{n=1}(-1)^n\frac{x^{4n-1}}{(2n+1)!}$$ How do i find its $7$ th derivative. Although i have calculate $1$ st or $2$ nd derivative. But $7$ th derivative is very conplex. Please help me How to solve it. Thanks,['derivatives']
3640087,What measure of distance does the harmonic mean minimize?,"The arithmetic mean of a set of numbers minimizes the squared error. The geometric mean minimizes the squared log difference $\left[\log(x)-\log(\overline{x})\right]^2.$ The median minimizes the mean absolute error. 
What does the harmonic mean minimize?",['statistics']
3640155,The resolvent of an operator commutes with it.,"Let $X$ be a Banach space and $\Phi : X \rightarrow X$ a bounded operator.
Let also $R(\cdot,\Phi) : \rho(\Phi) \rightarrow B(X)$ the resolvent operator of $\Phi$ defined in the usual way as $R(\lambda,\Phi) := (\lambda I -\Phi)^{-1}$ for $\lambda \in \rho(\Phi)$ . Is it always true, or under which assumptions, does $\Phi$ commute with its resolvent?
And if yes, how to show it? I think that maybe the Neumann series plays a role in an eventual proof.","['banach-spaces', 'operator-theory', 'functional-analysis']"
3640176,"Are there ""simple"" functions whose asymptotic behaviour is impossible to know?","My question is Does exist a simple function $f \colon A \subseteq \mathbb R \to \mathbb R$ such that it is impossible to know $\lim_{x \to \infty} f(x)$ ? Of course there are a lot of function whose behaviour is not known; but what happens if we use only elementary functions (the rigourous definition of elementary function involves differential algebra, so let's just imagine a elementary function as a composition of exponentials, logarithms, rational functions and trigonometric functions)?.
More clearly the problem is: Is it possible to create some function (or sequence) ""easy to define"" for which is not possible to evaluate his asymptotic behaviour? Edit : with ""not possible to evaluate"" I mean that the problem to evaluate $$\lim_{x \to +\infty} f(x)$$ is not decidible.","['functions', 'decidability', 'real-analysis']"
3640221,"Prokhorov's Theorem : The Statement. Precompact, Sequentially Compact, Relatively Compact : Definitions.","Let $S$ be a Polish space (a complete separable metric space), Let $\mathcal{P}(S)$ be the space of Borel probability measures on $S$ (the Borel sets are induced by the metric on the space $S$ ). Next I give the statement of Prokhorov's Theorem as I know it. $\textbf{Prokhorov's Theorem :}$ $\textbf{ (Bilingsley Convergence of Probability Measures page 37)  }$ A subset $\mathcal{M}\subset \mathcal{P}(S)$ is tight if and only if it is relatively compact. Now some definitions : $\textbf{Definition 1. : (Bilingsley page 35)} $ A subset $\mathcal{M}\subset\mathcal{P}(S)$ is $\textit{relatively compact}$ if every sequence has a weakly convergent sub-sequence. That is for $\{\mu_k\}\subset \mathcal{M}$ , there exists $\{\mu_{k_{m}}\}\subset \mathcal{M}$ such that $\mu_{k_{m}}\overset{weakly}{\longrightarrow}\mu \in \mathcal{P}(S)$ . $\textbf{Definition 2. : (Wikipedia Webpage Sequentially Compact) } $ A topological space $X$ is $\textit{Sequentially Compact}$ if every sequence in $X$ has a subsequence converging in $X$ . (Notice the convergence is w.r.t the topology, not necessarily the weak topology. $\textbf{Definition 3. : (Wikipedia Webpage Precompact) } $ A subset $Y$ of a topological space $X$ is precompact (relatively compact) if its closure is compact. $\textbf{Question 1:}$ The definitions 1. and 3. both use the term 'relatively compact' to mean different things, are either of them 'correct'?. $\textbf{Question 2:}$ I have seen Prokhorov's Theorem stated slightly differently in some places : for example if a subset $\mathcal{M}\subset \mathcal{P}(S)$ is tight : Wikipedia says $\mathcal{M}$ is sequentially compact. In other places I have seen it said that $\mathcal{M}$ is precompact. Or we have that $\mathcal{M}$ is relatively compact, as I stated before. Which of these is correct, are they in fact the same?","['metric-spaces', 'general-topology', 'probability-theory', 'probability', 'compactness']"
3640242,"how to find positive integer $m,n , (m^2 + n^2 )(n^2-m)= 2mn(m+n^2) $","how to find positive integer $m,n $ $(m^2 + n^2 )(n^2-m)= 2mn(m+n^2) $ answer is $(36,18), (36, 12) $ $n$ -th try........ $ gcd (m,n)= p$ ,   then $m=ap, n= bp$ $(a^2 p^2 + b^2 p^2 )(b^2p^2 -ap)= abcp^2(ap+ b^2p^2)$ $(a^2+ b^2 )(b^2p-a) = 2ab (a+ b^2p ) $ $ gcd(a^2+ b^2,b)=1$ , $ gcd(b^2p-a,b)=1$ so, $b=1$ $(a^2+1)(p-a)= 2a (a+p)$ $ p= a (\frac{a+1}{a-1} )^2 $ $p$ is integer, so, $a=2,3$ , $p=n=18,12$ is this possible? and is there some relationship with pythagorean triple?","['number-theory', 'integers']"
3640279,Dividing an angle into five equal parts by ruler and Compass Construction,Things I know: 1. We can divide any angle into two 2. We can prove that $\pi/3$ can not be trisected. Thus trisection is not true in general. 3. A regular $n$ -gon  can only be constructed if and only if $\phi(n)=2^t$ for some integer $t$ . Where $\phi(n)$ is the number of relatively prime numbers less than $n$ (Euler totient function) I also went over this problem. But the thing that I don't understand is in those cases they talk about constructing a regular $n$ -gon. That is we divide $360^{\circ}$ into $n$ equal parts. Which in my case will be $n=5$ . But what I need is different. I need to check whether any angle $\theta$ can be divided into $5$ equal parts. Appreciate your help,"['field-theory', 'galois-theory', 'geometry']"
3640324,Expected Value for the Number of Parts of a Random Partition (Considering Only a Portion of the Partition Spectrum),"Let $n$ be a positive integer. If we take the set of all partitions of $n$ and choose a random partition from it (uniformly), then the expected value of the number of parts of this partition is a known result. The highest order term of the expected value is $\sqrt{n}\operatorname{Log}(n)$ (Kessler & Livingston, 1976). Instead of the set of all partitions of $n$ , I only want to consider $k \%$ of the total spectrum of partitions. Let $P^k(n)$ denote the set which contains $k \%$ of the total partitions of $n$ . The partitions in $P^k(n)$ are chosen as follows. We begin with the empty set and add partitions one by one. At every step we choose to add a partition that has the smallest number of parts. We stop adding partitions once the set $P^k(n)$ contains the required $k \%$ of the total number of partitions. I am interested in the partition in $P^k(n)$ that has the highest number of parts, call this $max\left(P^k(n)\right)$ . Numerical experiment has shown that for large $n$ , $\operatorname{max}\left(P^k(n)\right) \approx k \sqrt{n}\operatorname{Log}(nk)$ . So for fixed $k$ and increasing $n$ we get $\operatorname{max}\left(P^k(n)\right) = \mathcal{O}(\sqrt{n}\operatorname{Log}(n))$ . Is there a way to apply Kessler and Livingston's result to the set $P^k(n)$ , so that we get the expected value for the number of parts of partitions in that set? This would be incredibly helpful as it would be a lower bound for $\operatorname{max}\left(P^k(n)\right)$ .","['integer-partitions', 'number-theory', 'combinatorics', 'discrete-mathematics', 'probability-theory']"
3640413,What is the difference between a set and a group?,"I'm new here probably  I wouldn't have a suitable way for asking suitable questions for this website really. In group theory , I mixed between set and group in Algebra;  however, I checked both of them definition. My question here is: Is set=group? I think there are a large difference since we have set theory and group theory ? Can we say for example ""set is finitely generated "" like group ?","['elementary-set-theory', 'group-theory', 'definition', 'terminology']"
3640450,"Reconciling Donsker-Varadhan definition of KL divergence with the ""usual"" definition","Let $\mu$ and $\lambda$ be probability measures on a measurable space $(X, \Sigma)$ .
In my experience, the usual definition of the Kullback-Liebler divergence of $\mu$ with respect to $\lambda$ is $$
\tag{1}
\label{kl def}
\operatorname{KL}(\mu \| \lambda)
= \begin{cases}
\int_X \log\left(\frac{d\mu}{d\lambda}\right) \, d\mu, & \text{if $\mu \ll \lambda$ and $\log\left(\frac{d\mu}{d\lambda}\right) \in L^1(\mu)$,} \\
\infty, & \text{otherwise.}
\end{cases}
$$ While reading some machine learning theory literature, I encountered the following inequality, attributed to Donsker and Varadhan, which is valid at least for bounded, $\Sigma$ -measurable functions $\Phi : X \to \mathbb{R}$ : $$
\tag{2}
\label{kl ineq}
\int_X \Phi \, d\mu \leq \operatorname{KL}(\mu \| \lambda) + \log\int_X \exp(\Phi) \, d\lambda.
$$ This led me to a 1983 paper by Donsker and Varadhan (see References below), in which they define the entropy of $\mu$ with respect to $\lambda$ by $$
\tag{3}
\label{dv def}
h(\lambda : \mu)
= \inf\left\{c \in \mathbb{R} : \int_X \Phi \, d\mu \leq c + \log\int_X \exp(\Phi) \, d\lambda
\quad\text{for all $\Phi \in \mathscr{B}(\Sigma)$}
\right\},
$$ where $\mathscr{B}(\Sigma)$ is the space of all bounded, $\Sigma$ -measurable functions from $X$ to $\mathbb{R}$ . The paper makes several assertions about this definition.
For instance, If $X$ is a separable, completely metrizable space and $\Sigma$ is its Borel $\sigma$ -algebra, then $\mathscr{B}(\Sigma)$ can be replaced by $C(X)$ in \eqref{dv def}, yielding the same infimum.
(Presumably $C(X)$ here is the space of continuous functions on $X$ , but not all such functions are necessarily $\mu$ -integrable, so maybe the space of compactly supported continuous functions is intended?) If $X$ is a separable, completely metrizable space and $\Sigma$ is its Borel $\sigma$ -algebra, then $h(\lambda : \mu)$ is lower semicontinuous in $\mu$ in the weak topology. (Theorem 2.1) $h(\lambda : \mu) = \operatorname{KL}(\mu \| \lambda)$ (i.e., \eqref{kl def} and \eqref{dv def} define the same quantity). I'm most interested in the first and last items above, whose proofs can be apparently found in an earlier 1976 paper by Donsker and Varadhan (see References below).
However, I was unable to find anything resembling these results in that paper. Questions How can I prove the assertions about $h(\lambda : \mu)$ made in the 1983 Donsker-Varadhan paper? In particular, why is $h(\lambda : \mu) = \operatorname{KL}(\mu \| \lambda)$ ? For which functions $\Phi$ does \eqref{kl ineq} hold? It certainly holds for all bounded, $\Sigma$ -measurable functions by the definition of $h(\lambda:\mu)$ , and it holds for non-negative, $\Sigma$ -measurable functions by the monotone convergence theorem. Does it hold for all $\mu$ -integrable functions? The machine learning literature also uses the following representation of Kullback-Liebler divergence, which is also attributed to Donsker and Varadhan: $$
\operatorname{KL}(\mu \| \lambda)
= \sup_{\Phi \in \mathcal{C}} \left(\int_X \Phi \, d\mu - \log\int_X \exp(\Phi) \, d\lambda\right),
$$ where $\mathcal{C}$ is a usually unspecified class of functions (presumably $\mathcal{C} = \mathscr{B}(\Sigma)$ works). This looks like a dual formulation of \eqref{dv def}, but I would appreciate a proof of this as well (in particular, the $\infty - \infty$ case may need to be addressed). References Donsker, M.D. and Varadhan, S.R.S. (1976), Asymptotic evaluation of certain Markov process expectations for large time—III. Comm. Pure Appl. Math., 29: 389-461. DOI Donsker, M.D. and Varadhan, S.R.S. (1983), Asymptotic evaluation of certain markov process expectations for large time. IV. Comm. Pure Appl. Math., 36: 183-212. DOI","['machine-learning', 'measure-theory', 'probability-theory', 'information-theory']"
3640553,Dyadic Decomposition For Oscillatory Integral,"In Terence Tao's notes on oscillatory integrals, Tao mentions that if $a(x)$ is a smooth, compactly supported phase, with $a(x) = 1$ in a neighborhood of the origin, then for any $N$ , $$ \int a(x) e^{\lambda i x^2}\; dx = e^{i\pi/4} \sqrt{\pi/\lambda} + O_{N,a}(\lambda^{-N}) $$ He mentions that this bound can be proven by 'a dyadic decomposition'. I've tried to come up with a dyadic decomposition strategy that yields this bound but something appears to be alluding me. What dyadic decomposition strategy might yield this bound? Below is the approach my intuition suggests, which might guide your answer, but if there is an obvious approach that I am missing, there is no need to read the approach below: If we define $\beta_0(x)$ to be a smooth function equal to $1$ on $[-1,1]$ and vanishing outside of $[-2,2]$ , and then define $\beta_n(x) = \beta_0(x/2^n) - \beta_0(x/2^{n-1})$ , then for each $x \in \mathbf{R}$ , $\sum_{n = 0}^\infty \beta_n(x) = 1$ . Thus $\{ \beta_n \}$ is a partition of unity, with $\beta_n$ supported on $|x| \sim 2^n$ for each $n$ . I want to isolate the behaviour of the integral when $|x| \lesssim \lambda^{-1/2}$ , where the phase is stationary, so I might want to decompose the integral as $$ \int a(x) e^{\lambda i x^2} = \sum_{n = 0}^\infty \int a(x) \beta_n(x \cdot \lambda^{1/2}) e^{\lambda i x^2}. $$ However, for $n \geq 1$ , I am unable to obtain any better bound than $$ \left| \sum_{n = 1}^\infty \int \beta_n(x \cdot \lambda^{1/2}) e^{\lambda i x^2} \right| \lesssim \lambda^{-1/2}. $$ Even if I was able to obtain a bound $O(\lambda^{-N})$ for this term, it seems unclear how we might reintroduce the amplitude $a$ to obtain a bound on $$ \left| \sum_{n = 1}^\infty \int a(x) \beta_n(x \cdot \lambda^{1/2}) e^{\lambda i x^2} \right|. $$ We can certainly sum up to $n \lesssim \log(\lambda^{1/2})$ , where $\beta_n(x \cdot \lambda^{1/2}) a(x) = \beta_n(x \cdot \lambda^{1/2})$ , but for $n \gtrsim \log(\lambda^{1/2})$ we obtain problems because $a$ modifies the behaviour of $\beta_n$ .","['integration', 'harmonic-analysis', 'oscillatory-integral']"
3640587,how do i find the solution of this trigonometry problem?,"How do I find the $\angle BCA$ ? I tried to find the formula of the parabola, and I got $y=-0.25(x-4)^2+9$ . Then, with the formula I found the coordinates of point $B$ and $C$ and then the measure between the point $B$ and $C$ . Now I am stuck.","['algebra-precalculus', 'trigonometry']"
3640591,Help with the Euler-type integral $\int_{0}^{m}\frac{1-e^{2\pi i x}}{x-j}\frac{x^{s-1}}{(1+x)^{z}}dx$,"Consider the integral : $$I=\int_{0}^{m}\frac{1-e^{2\pi i x}}{x-j}\frac{x^{s-1}}{(1+x)^{z}}dx\;\;\;\;s,z\in\mathbb{C}\;\;\;\;j,m \in \mathbb{N}\;\;0\leq j\leq m$$ i have tried using the Mellin integral representation of $\frac{1}{(1+x)^{z}}$ , which is given in terms of the beta function, but that didn't get me anywhere. I have tried using the generalized binomial theorem, and split the integral at $1$ , but that didn't get me anywhere either. Any help is highly appreciated. EDIT Using the Taylor expansion : $$\frac{1-e^{2\pi i x}}{x-j}=-\sum_{n=0}^{\infty}\frac{(2\pi  i)^{n+1}}{(n+1)!}(x-j)^{n}$$ And substituting $x=my$ , we have : $$I=-m^{s}\sum_{n=0}^{\infty}\frac{(2\pi  i)^{n+1}}{(n+1)!}\int_{0}^{1}(my-j)^{n}\frac{y^{s-1}}{(1+my)^{z}}dy$$ Using the integral representation of the Appell's hypergeometric function : $$F_{1}(a,b_{1},b_{2},c,x,y)=\frac{\Gamma(c)}{\Gamma(a)\Gamma(c-a)}\int_{0}^{1}t^{a-1}(1-t)^{c-a-1}(1-xt)^{-b_{1}}(1-yt)^{-b_{2}}dt$$ we have : $$I=\frac{m^{s}}{sj}\sum_{n=0}^{\infty}\frac{(-2\pi i j)^{n+1}}{(n+1)!}F_{1}\left(s,z,-n,s+1,-m,\frac{m}{j}\right)$$ Now, is there any way to simplify this, say, using the exponential generating function of $F_{1}(\cdot)$ ? i have looked for one, but could find any !","['definite-integrals', 'complex-analysis', 'beta-function', 'mellin-transform', 'hypergeometric-function']"
3640619,Show that $A$ is countable iff $\mathcal{P}_{fin}(A)$ is countable,"I need to show that $A$ is countable iff $\mathcal{P}_{fin}(A)$ is countable. where $\mathcal{P}_{fin}(A) = \left \{ x\subseteq A\mid x\;is\;finite \right \} $ I know that if $A$ is countable, I can build an infinite amount of such $x$ 's, but its obviously not enough. I am missing the main direction of the proof. I would appreciate help on this proof",['elementary-set-theory']
3640623,Understanding little $o$ and big $O$ notation,"I'm trying to figure out big $O$ notation (as $x\to\infty$ for $f(x) =\ln x$ ,  and little $o$ notation (as $x \to 0$ ) for $f(x) =\ln x$ . Similarly, I am trying to find out little o notation (as $x\to 0$ and as $x\to\infty$ ) for $f(x) = x^2 + x$ . What I know (for $\ln x$ ): I know we have that $\ln x < x$ for all $x > 0$ . I tried to look at the Taylor Series expansion for $x > 0$ (since I know we don't have one centered at $0$ ), but had no luck. What I know (for $x^2 + x$ ): I know that $x = o(x^2)$ for all $x$ I also know that $x^2 \in o(x^3)$ I struggle with asymptotic notation (especially little $o$ ); any tips to help guide me in the right direction would be much appreciated.","['asymptotics', 'real-analysis', 'calculus', 'discrete-mathematics', 'limits']"
3640651,How do you prove $S_{XYZT} \leq \dfrac{1}{5} S_{ABCD} $?,"In the given figure, $ABCD$ is a convex quadrilateral. Suppose that $M, N, P, Q$ are mid-points of $AB, BC, CD, DA$ , respectively. Prove that $S_{XYZT} \leq \dfrac{1}{5} S_{ABCD} $ where $S_{ABCD}$ (resp. $S_{XYZT}$ ) is the area of $ABCD$ (resp. $XYZT$ )? Could you please give a key hint to solve this exercise? Thank you so much for your discussions!","['quadrilateral', 'euclidean-geometry', 'area', 'geometry']"
3640694,Question of Hartshorne II8.15,"The theorem $8.15$ (p.177) from the Hartshorne's book ""Algebraic Geometry"" says: "" Let $X$ be an irreducible separated scheme of finite type over an algebraically closed field $k$ . Then $\Omega_{X/k}$ is a locally free sheaf of rank $n= \dim \ X$ iff $X$ is nonsingular variety over $k$ ."" Proof: If $x\in X$ is a closed point, then the local ring $B =\mathcal{O}_{x,X}$ has dimension $n$ , residue field $k$ , and is a localization of a $k$ -algebra of finite type. Furthermore, the module $\Omega_{B/k}$ of differentials of $B$ over $k$ is equal to the stalk $(\Omega_{X/k})_x$ of
the sheaf $\Omega_{X/k}$ · Thus we can apply (8.8) and we see that $(\Omega_{X/k})_x$ is free of
rank $n$ if and only if $B$ is a regular local ring. Now the theorem follows in
view of (8.14A), which says any localization of a regular local ring at a prime ideal is
again a regular local ring. and (Ex. 5.7), which says that $\Omega_{X/k}$ is locally free iff $(\Omega_{X/k})_y$ is free for all $y\in X$ . My confusion lies in the last sentence, I can see if $\Omega_{X/k}$ is a locally free sheaf of rank $n= \dim \ X$ , then by (Ex. 5.7), $(\Omega_{X/k})_x$ is free of rank $n$ for any closed point, thus $\mathcal{O}_{X,x}$ is a regular local ring at each closed point. Now apply (8.14A), we know $\mathcal{O}_{X,x}$ is a regular local ring at non-closed points, thus $X$ is nonsingular. However, I feel confused with the other direction: Suppose $X$ is smooth, then by (8.8), we know $(\Omega_{X/k})_x$ is free of rank $n$ for any closed point $x$ . But how do we show $(\Omega_{X/k})_x$ is free of rank $n$ for any nonclosed point? Here to apply (8.8), it requires $k(x)=k$ , but which is true for closed points. I don't think we can use (8.8) for non-closed points.",['algebraic-geometry']
3640750,how do i find the angle in this trigonometry problem?,"How do I find the ∠FAB?(knowing that the segment EF is the height of the triangle AFD) I tried several attempts to resolve it but none of them were succesful.I managed to find the angles ACB(=51,39) and CAB(=38,68) but i didn't know what to do with that information.I am stuck.","['algebra-precalculus', 'trigonometry']"
3640770,Is it impossible to perfectly fit a polynomial to a trigonometric function on a closed interval?,"On a closed interval (e.g. $[-\pi, \pi]$ ), $\cos{x}$ has finitely many zeros. Thus I wonder if we could fit a finite degree polynomial $p:\mathbb{R} \to \mathbb{R}$ perfectly to $\cos{x}$ on a closed interval such as $[-\pi, \pi]$ . The Taylor series is $$\cos{x} = \sum_{i=0}^{\infty} (-1)^i\frac{x^{2i}}{(2i)!} = 1 - \frac{x^2}{2} + \frac{x^4}{4!} - \frac{x^6}{6!} + \frac{x^8}{8!}-\dots$$ Using Desmos to graph $\cos{x}$ and $1-\frac{x^2}{2}$ yields: which is clearly imperfect on $[-\pi,\pi]$ . Using a degree 8 polynomial (the first 5 terms of the Taylor series above) looks more promising: But upon zooming in very closely, the approximation is still imperfect: There is no finite degree polynomial that equals $\cos{x}$ on all of $\mathbb{R}$ (although I do not know how to prove this either), but can we prove that no finite degree polynomial can perfectly equal $\cos{x}$ on any closed interval $[a,b]\subseteq \mathbb{R}$ ? Would it be as simple as proving that the remainder term in Taylor's Theorem cannot equal 0? But this would only prove that no Taylor polynomial can perfectly fit $\cos{x}$ on a closed interval...","['taylor-expansion', 'trigonometry', 'interpolation', 'polynomials']"
3640785,What is $\frac{a b \sin x}{2\sqrt{(a^2 + b^2 + 2 ab \cos x ) \cdot (a+b - \sqrt{a^2+b^2+ 2 ab \cos x})}}$ for $x \rightarrow 0$?,"I am trying to find the limit $\lim_{x \rightarrow0} \frac{a b \sin x}{2\sqrt{(a^2 + b^2 + 2 ab \cos x ) \cdot (a+b - \sqrt{a^2+b^2+ 2 ab \cos x})}}$ for $a,b \in \rm{I\!R}_{+}$ .  Applying L'Hospital's rule leads to $\lim_{x \rightarrow0}\frac{\cos x \cdot \sqrt{(a^2 + b^2 + 2 ab \cos x ) \cdot (a+b - \sqrt{a^2+b^2+ 2 ab \cos x})}}{-2 \sin x \cdot (a+b - \sqrt{a^2+b^2+ 2 ab \cos x}) + \frac{\sin x \cdot (a^2 + b^2 + 2 ab \cos x )}{\sqrt{a^2+b^2+ 2 ab \cos x}} }$ . However, this remains with both, cosine and sine.  Maybe one could use a trigonometric identity, which I cannot find.","['limits', 'trigonometry', 'real-analysis']"
3640833,$C^\infty(M)$-linear maps are local,"Very often in mathematical physics literature I've heard a fact that probably (if I've understood it correctly) translates as follows. Let $M$ be a differentiable manifold, and denote by $C^\infty(M)$ the
  ring of smooth real functions $M\to\Bbb{R}$ . Let now $E$ and $F$ be
  vector bundles on $M$ , and notice that the spaces of smooth sections $\Gamma(E)$ and $\Gamma(F)$ are modules over $C^\infty(M)$ .  Let now $f:\Gamma(E)\to\Gamma(F)$ be a smooth, $\Bbb{R}$ -linear function. The following are
  equivalent. $f$ is $C^\infty(M)$ -linear; $f$ is ""local"", meaning that given sections $\phi,\psi$ which agree at the point $p\in M$ ,
  then $f(\phi)$ and $f(\psi)$ agree at $p$ too. First of all, is the above correct? If not, what is the correct statement? Also, where can I find a reference and a proof?","['reference-request', 'vector-bundles', 'algebraic-geometry', 'commutative-algebra', 'differential-geometry']"
3640899,Reduced scheme $X_{red}$ out of a scheme $X$,"If $X$ is a scheme, we define the sheaf $(\mathcal{O}_X)_{red}$ as the sheafification of the pre-sheaf defined by $U\mapsto \mathcal{O}_X(U)/\sqrt{0}$ , where $\sqrt{0}$ is the nilradical of the ring $\mathcal{O}_X(U)$ . I'm trying to show that $(Y,\mathcal{O}_Y):=(X,(\mathcal{O}_X)_{red})$ is a reduced scheme. I was able to prove that $\mathcal{O}_{Y,x}\simeq \mathcal{O}_{X,x}/\mathfrak{N}_x$ , where $\mathfrak{N}_x$ is the nil radical of $\mathcal{O}_{X,x}$ , so that $\mathcal{O}_{Y,x}$ is a local reduced ring. But I'm having difficulty making the scheme structure of $Y$ explicit. If $X=\bigcup_iU_i$ is a cover with $(U_i,\mathcal{O}_X\big|_{U_i})$ affine, I guess the natural thing is to show $\mathcal{O}_Y\big|_{U_i}\simeq \mathcal{O}_{\text{Spec}(\mathcal{O}_Y(U_i))}$ . But I don't know how to do that. The sheaf $\mathcal{O}_Y$ seems so abstract, I don't know how to handle it. What's the best way to do this?","['algebraic-geometry', 'schemes', 'sheaf-theory']"
3640981,Functions that link to divisor function,"I am interested in the following problem: Do there exist a function $f:\mathbb{N}\to\mathbb{N}$ such that $$f(f(n))=\sigma_0(n)$$ My progress was the following (for sake of simplicity, we denote $\sigma_0(n)$ by $d(n)$ ): I proved $f(1)=1, f(2)=2$ $f(d(n))=d(f(n))$ $f$ is surjective $f(f(ab))=f(f(a))\cdot f(f(b))$ whenever $\gcd(a,b)=1$ However, I am not able to get any good idea to solve the main problem. Any help will be highly appreciated. EDIT: To prove $f(2)=2,$ we note that $$f(f(2))=d(2)=2\implies f(f(f(2)))=f(2)\implies d(f(2))=f(2)$$ Now we know that $d(N)=N\iff N=1,2$ ...Its easy to check that $f(2)\neq 1\implies f(2)=2$ .","['number-theory', 'divisor-counting-function', 'functions', 'arithmetic-functions']"
3640984,Proving interesting identity with partial sums of Pascal's triangle rows,"As part of another problem I'm working on, I find myself needing to prove the following: $$\sum_{k=0}^n\binom{2k+1}{k}\binom{m-(2k+1)}{n-k} = \sum_{k=0}^{n}\binom{m+1}{k}$$ where $n\leq m$ . I've checked it computationally for all $n\leq m\leq 16$ . A few thoughts: this looks like a binomial convolution, but the $k$ 's show up in the top of the binomial coefficients which disqualifies it from Vandermonde-esque identities I've found. Further, it uses weird binomial coefficients where the top is less than the bottom and the top can be negative - seems strange to me. Some references I've found (for example) have similar looking sums of products, but the $2k$ instead of $k$ seems to hurt. Another (""Some Generalizations of Vandermonde's Convolution"" by H. W. Gould) reveals to me that $$\sum_{k=0}^n\binom{2k+1}{k}\binom{m-(2k+1)}{n-k} = 
\sum_{k=0}^n\binom{2k+1+j}{k}\binom{m-(2k+1)-j}{n-k} $$ where $j$ can be any integer. Not sure if this can help. I see from this question and elsewhere that partial sums of Pascal triangle rows don't really have closed forms. I can't think of how to use a generating function here (I'm trying to show a sum is equal to a sum), and the terms in each sum seem completely different. I'm not really sure how to proceed, any help/advice would be much appreciated!","['factorial', 'convolution', 'binomial-coefficients', 'combinatorics', 'binomial-theorem']"
3641036,Does this limit converge on e?,"Playing around with some math in python today I came across what appears to be an interesting pattern: Starting at n=1 as n approaches positive infinity, take (n+1)^(n+2)/n^(n+1) and get a list of ratios of exponential expressions. At first glance the ratios between the numbers appeared to be converging to something so... Next, I took the difference between consecutive ratios, e.g. (n+2)^(n+3)/(n+1)^(n+2)-(n+1)^(n+2)/n^(n+1). The differences appear to be approaching e (2.718...) as n gets larger. The first few ratios rounded to the third decimal place are... 2^3/1^2 = 8 3^4/2^3 = 10.125 4^5/3^4 = 12.642 5^6/4^5 = 15.259 6^7/5^6 = 17.916 ... With their differences being... 10.125 - 8 = 2.125 12.642 - 10.125 = 2.517 15.259 - 12.642 = 2.617 17.916 - 15.259 = 2.657 ... After the 13th iteration you get 2.711, and it looks like the series will converge on e as it gets arbitrarily large. That or likely positive infinity and my hunch is off! Can anyone with better knowledge of limits tell me if I've stumbled across a novel way of calculating e or not? Here's the python code for those curious (first loop stops at 15 because that's all my cheap phone could handle): import numpy as np

ratios = []
i = 1
while i < 15:
    a = np.power(i,i+1)
    b = np.power(i+1,i+2)
    print(a)
    ratios.append(b/a)
    i+=1
print(ratios)

x=0
diffs = []
while x < len(ratios) - 1:
    temp = ratios[x+1] - ratios[x]
    diffs.append(temp)
    x+=1

print(diffs) This reminds of the time I thought I discovered a novel formula for exponents about the golden ratio. I didn't, it was already known and I think this may be the case too but my brief search hasn't turned up anything yet. Thanks!","['limits', 'convergence-divergence', 'python', 'exponential-function']"
3641051,"An empty set is always a subset of another set, but can it also be an element of a set too? [duplicate]","This question already has answers here : Is ""empty set"" an element of a set? (3 answers) Closed 4 years ago . I know an empty set ∅ is defined as a set that has no elements and is also a subset of every set, but can you say that it is an element of another set? I think not, but I'm not comepletly sure. For example, consider the statements below: $∅ ∈ P(Z)$ $∅ ⊆ Z$ $∅ ⊆ P(Z)$ $∅ ∈ Z$ I think only the second and third are correct since an empty set is always a subset of another set, but the first and last I'm not sure about. Would they be true statements or no? Also how do power sets affect this?",['elementary-set-theory']
3641101,Can a connected finite etale cover of a curve over a DVR have a disconnected special fiber?,"Let $R$ be a discrete valuation ring. Let $X\rightarrow\text{Spec }R$ be a smooth morphism with geometrically connected fibers of dimension 1. I'm happy to assume that $X$ is the complement of a normal crossings divisor inside a smooth projective $R$ -curve. Let $Y\rightarrow X$ be a finite etale map with $Y$ connected. Let's further assume the generic fiber of $Y$ is geometrically connected. Could $Y$ have a disconnected special fiber? Surely not right? For some reason I'm blanking on how to argue this. This came up when considering Galois closures. I want to say that if $Z\rightarrow X$ is a finite etale cover of curves over $R$ (both having geometrically connected special fibers), then the generic (resp. special) fiber of its Galois closure should be the Galois closure of its generic (resp. special) fiber.",['algebraic-geometry']
3641112,Possibility of ants not being able to cross a grid shaped bridge,"The problem is really simple, but I have absolutely no idea on how to solve it. So there is an ant who really wants to get to the other side of a grid shaped bridge. However, a person decides to stop the ant from crossing over, so he gets a coin and starts throwing it for each of the 28 black line segments. If the coin that he threw is a tail, he cuts out that line segment, and if the coin that he threw is a head, he leaves the line segment alone. After he does this for every 28 black line segment, what is the possibility that the ant still can cross the bridge?","['combinations', 'combinatorics', 'combinatorial-game-theory', 'game-theory', 'probability']"
3641118,Can eigenvectors be found without finding eigenvalues?,"Given a matrix $A$ and the set of all of its eigenvectors, it is possible to find all of the matrix’s eigenvalues by solving $A\vec v = \lambda\vec v$ .  Given the set of all eigenvalues, it is possible to find the corresponding eigenspaces by finding $\mathrm N(A-\lambda I)$ . It is also possible to find all of the eigenvalues independently of the eigenvectors by finding the zeroes of the characteristic polynomial $\lvert A – \lambda I\rvert$ . This makes me wonder, is it possible to find all of the eigenvectors or eigenspaces independently of the eigenvalues? If so, how? My linear algebra instructor’s assistant directed me to this video, which I found unhelpful.","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
3641128,Expressing continued fractions through $e$,"The following are some conjectures of mine that I have discovered empirically. The last three conjectures are true if the first four are true, and vice versa. i. $$e=3-\cfrac{1}{4-\cfrac{2}{5-\cfrac{3}{6-\ddots}}}$$ ii. $$\cfrac{e}{e-2}=4-\cfrac{1}{5-\cfrac{2}{6-\cfrac{3}{7-\ddots}}}$$ iii. $$\cfrac{e}{2(3-e)}=5-\cfrac{1}{6-\cfrac{2}{7-\cfrac{3}{8-\ddots}}}$$ iv. $$\cfrac{e}{3(3e-8)}=6-\cfrac{1}{7-\cfrac{2}{8-\cfrac{3}{9-\ddots}}}$$ v. Let $c_1(x)=5-\cfrac{1}{6-\cfrac{2}{7-\ddots}}$ and $c_2(x)=4-\cfrac{2}{5-\cfrac{3}{6-\ddots}}$ . Then, $$\cfrac{c_1(x)}{c_2(x)}=\cfrac e2$$ vi. Let $c_3(x)=6-\cfrac{1}{7-\cfrac{2}{8-\ddots}}$ and $c_4(x)=5-\cfrac{2}{6-\cfrac{3}{7-\ddots}}$ . Then, $$\cfrac{c_3(x)}{c_4(x)}=\cfrac e{3(e-2)}$$ vii. $$\cfrac{c_1(x)c_4(x)}{c_2(x)c_3(x)}=3\bigg(\cfrac e2-1\bigg)$$ Can these conjectures be proven/disproven, particularly either the first four or last three? If they are true, it appears the function $$f(n)=n-\cfrac{1}{n+1-\cfrac{2}{n+2-\cfrac{3}{n+3-\ddots}}}$$ is expressed through $e$ , at least seemingly for natural $n\geq 3$ .","['elementary-number-theory', 'continued-fractions', 'sequences-and-series']"
3641169,Proof that $A_1=\bigcap_{i=1}^{\infty}A_i \cup \bigcup_{i=1}^{\infty}(A_i\backslash A_{i+1})$,"Let $A_{i+1} \subseteq A_i$ , $F_{i}=A_i\backslash A_{i+1}$ which implies $A_i=A_{i+1}\cup F_i$ with $A_{i+1} \cap F_i = \varnothing$ .
Proof that $$A_1=\bigcap_{i=1}^{\infty}A_i \cup \bigcup_{i=1}^{\infty}(A_i\backslash A_{i+1}) \cdots (*)$$ . I have tried some ways.
First, I tried this way \begin{align*}
\bigcap_{i=1}^{\infty}A_i \cup \bigcup_{i=1}^{\infty}(A_i\backslash A_{i+1})
&=(A_1 \cap A_2 \cap A_3 \cap \cdots) \cup ((A_1\backslash A_2)\cup (A_2\backslash A_3)\cup (A_3\backslash A_4) \cup \cdots)\\
&=(A_1 \cap A_2 \cap A_3 \cap \cdots) \cup ((A_1\cap {A_2}^c)\cup (A_2\cap {A_3}^c)\cup (A_3\cap {A_4}^c) \cup \cdots)\\
&=(A_1 \cap A_1 \cap {A_2}^c) \cup (A_2 \cap A_2 \cap {A_3}^c) \cup (A_3 \cap A_3 \cap {A_4}^c) \cup \cdots
\end{align*} then I didn't know what must i do next and I tried the second way, I tried to expand each terms like this \begin{align*}
\bigcap_{i=1}^{\infty}A_i&=A_1 \cap A_2 \cap A_3 \cap \cdots\\
\bigcup_{i=1}^{\infty}(A_{i}\cap (A_{i+1})^c)&=(A_1 \cap {A_2}^c) \cup(A_2 \cap {A_3}^c) \cup (A_3 \cap {A_4}^c) \cup \cdots\\
&=A_1 \cap ({A_2}^c \cup A_2) \cap ({A_3}^c \cup A_3) \cap ({A_4}^c \cup A_4) \cap \cdots\\
&=A_1 \cap \cdots \text{(i didn't know what's the next step)}
\end{align*} Is it right if I think ${A_i}^c \cup A_i=A_1$ for $i=2,3,4,\cdots$ ? If it is right, I get this result from my second way: \begin{align*}
\bigcup_{i=1}^{\infty}(A_{i}\cap (A_{i+1})^c)&=(A_1 \cap {A_2}^c) \cup(A_2 \cap {A_3}^c) \cup (A_3 \cap {A_4}^c) \cup \cdots\\
&=A_1 \cap ({A_2}^c \cup A_2) \cap ({A_3}^c \cup A_3) \cap ({A_4}^c \cup A_4) \cap \cdots\\
&=A_1 \cap A_1 \cap A_1 \cap \cdots\\
&=A_1
\end{align*} then \begin{align*}
\bigcap_{i=1}^{\infty}A_i \cup \bigcup_{i=1}^{\infty}(A_{i}\cap (A_{i+1})^c) &= (A_1 \cap A_2 \cap A_3 \cap \cdots) \cup A_1\\
&= (A_1 \cap A_1) \cup (A_2 \cap A_1) \cup (A_3 \cap A_1) \cup \cdots\\
&= A_1 \cup \varnothing \cup \varnothing \cup \cdots\\
&= A_1
\end{align*} But, i was not sure about that way. So, how to proof equation  (*)? Thanks for any help.",['elementary-set-theory']
3641170,How to not find a Hamiltonian Cycle,"Consider the following naive algorithm for finding Hamiltonian cycles on a simple undirected graph G with n vertices: Choose an arbitrary vertex and mark it as vertex 1 Choose an arbitrary unmarked neighbor of vertex 1, move to it, and mark it as vertex 2 Repeat step (2) while the current iteration i < n and vertex i has unmarked neighbors If vertex n is adjacent to vertex 1 , move to vertex 1 and terminate It seems pretty intuitive to me that this algorithm fails to find Hamiltonian cycles most of the time on most graphs. However, there are some graphs for which this algorithm will always produce a Hamiltonian cycle, no matter where it starts or which subsequent vertices it chooses. As far as I'm aware, these graphs are: (1) a cycle on n vertices, (2) a complete bipartite graph on n vertices where the partite sets have the same magnitude, and (3) the complete graph on n vertices. I could be overlooking something, but I think it's trivial to show this. But for every graph other than these three types of graphs, I'm pretty sure there is at least one instance where the algorithm fails. The thing is I'm having a lot of trouble explicitly showing this. I tried breaking the cases up into non-regular and regular graphs (not including the 3 mentioned above), but I'm struggling to show the non-regular case, let alone the regular case. My general approach is to consider a graph G that has at least one Hamiltonian cycle, but isn't one of those three graphs and then somehow manipulate that cycle to construct a ""failed attempt"" for the algorithm. Needless to say, it isn't working out. I think there might be some form of combinatorial argument, but I don't really know how to start going about finding it, since G can be almost any simple undirected graph. All of the theorems I looked at aren't of much help because they are about the existence of a hamiltonian cycle, but I'm looking for (vaguely) for the lack of one. So at this point, I'm stuck. So to summarize my question: how can one explicitly show that for any graph that isn't one of the three graphs listed above, the algorithm has a non zero probability of failure?","['graph-theory', 'hamiltonian-path', 'combinatorics', 'reference-request']"
3641195,Using the implicit function theorem to prove that a function attains a certain value,"Here' how I tried to do it but failed: I don't see what the implicit function theorem has to do with this (this exercise is after the section on the implicit function theorem), but anyway, this is what I got out of thinking about the problem. Since the matrix $Df(a)$ has rank $n$ , some $n$ by $n$ matrix formed of a collection of $n$ of its column vectors has nonzero determinant. The determinant of this matrix is a continuous function of its entries and since it is non-zero at $a$ , there is some neighborhood of $a$ on which it is non-zero, but I still don't know how I can use this. Suppose $c$ is in an $\varepsilon$ neighborhood of $0$ , since $f(a)=0$ , we have $\left|f\left(x\right)\right|< \varepsilon$ whenever $\left|x-a\right|\ <\delta$ for some $\delta$ and I should prove that $f$ actually attains the value $c$ for some point in this neighborhood but I don't see how I can do this.","['multivariable-calculus', 'implicit-differentiation', 'implicit-function-theorem', 'real-analysis']"
3641273,Computing challenging determinant,"Seeking advice on how to tackle the below determinant $$
\begin{vmatrix} a_1b_1 & a_1b_2 & a_1b_3 & \ldots & a_1b_n \\ a_1b_2 & a_2b_2 & a_2b_3 & \ldots & a_2b_n \\ a_1b_3 & a_2b_3 & a_3b_3 & \ldots & a_3b_n \\ \ldots & \ldots & \ldots & \ddots & \vdots\\ a_1b_n & a_2b_n & a_3b_n & \ldots & a_nb_n\end{vmatrix}
$$ I have tried countless techniques, including cofactor expansion as well as row/column swapping. I also tried to exploit the symmetricness of the matrix. I have looked elsewhere for guidance however this is apparently quite rare. Any help or advice would be appreciated.","['determinant', 'linear-algebra']"
3641299,Two different answers for limit at zero,"The following problem arises when calculating the result of Theorem 2 (part (4)) in Takács (1962) Introduction to the Theory of Queues (page 211). Calculate $$\lim_{s\to 0^{+}} \left[
    \frac{ 2\bigl( \Pi_0'(s) \bigr)^2 }{ \bigl( \Pi_0(s) \bigr)^3 }
    -
    \frac{ \Pi_0''(s)}{ \bigl( \Pi_0(s) \bigr)^2 }
\right]
$$ given $$\lim_{s \to 0^{+}} s^{n+1} \Pi_0^{(n)}(s) = (-1)^n n!\,\mathrm e^{-\lambda\alpha}$$ for all non-negative integers $n$ . Remark : The function $\Pi_0(s)$ is the Laplace transform of $$P_0(t) = \exp\left( -\lambda\int_{0}^{t}[1-H(x)]\,\mathrm dx \right)$$ for a cumulative distribution function $H(x)$ on the non-negative reals, and $\alpha$ is the mean of $H(x)$ . My question : I can obtain two different answers for the limit, the second being the negative of the first. What did I do wrong? Solution 1 (obtains the same result as Takács, 1962) \begin{align*}
    \frac{ 2\bigl( \Pi_0'(s) \bigr)^2 }{ \bigl( \Pi_0(s) \bigr)^3 }
    -
    \frac{ \Pi_0''(s) }{ \bigl( \Pi_0(s) \bigr)^2 }
=
    \frac{ 2 \Pi_0(s) \bigl( s^2 \Pi_0'(s) \bigr)^2 }{ \bigl( s \Pi_0(s) \bigr)^4 }
    -
    \frac{ s^3 \Pi_0''(s) }{ s \bigl( s \Pi_0(s) \bigr)^2 }
\end{align*} so \begin{align*}
\lim_{s\to 0^{+}} \left[
    \frac{ 2\bigl( \Pi_0'(s) \bigr)^2 }{ \bigl( \Pi_0(s) \bigr)^3 }
    -
    \frac{ \Pi_0''(s) }{ \bigl( \Pi_0(s) \bigr)^2 }
\right]
&=
\lim_{s\to 0^{+}} \left[
    \frac{ 2 \Pi_0(s) \bigl( -e^{-\lambda\alpha} \bigr)^2 }{ \bigl( e^{-\lambda\alpha} \bigr)^4 }
    -
    \frac{ 2e^{-\lambda\alpha} }{ s \bigl( e^{-\lambda\alpha} \bigr)^2 }
\right]
\\ &=
\lim_{s\to 0^{+}} 2e^{2\lambda\alpha} \left[
    \Pi_0(s)
    -
    \frac{ e^{-\lambda\alpha} }{ s }
\right]
\end{align*} Solution 2 \begin{align*}
    \frac{ 2\bigl( \Pi_0'(s) \bigr)^2 }{ \bigl( \Pi_0(s) \bigr)^3 }
    -
    \frac{ \Pi_0''(s) }{ \bigl( \Pi_0(s) \bigr)^2 }
=
    \frac{ 2\bigl( s^2 \Pi_0'(s) \bigr)^2 }{ s \bigl( s \Pi_0(s) \bigr)^3 }
    -
    \frac{ \Pi_0(s) s^3 \Pi_0''(s) }{ \bigl( s \Pi_0(s) \bigr)^3 }
\end{align*} so \begin{align*}
\lim_{s\to 0^{+}} \left[
    \frac{ 2\bigl( \Pi_0'(s) \bigr)^2 }{ \bigl( \Pi_0(s) \bigr)^3 }
    -
    \frac{ \Pi_0''(s) }{ \bigl( \Pi_0(s) \bigr)^2 }
\right]
&=
\lim_{s\to 0^{+}} \left[
    \frac{ 2\bigl( -e^{-\lambda\alpha} \bigr)^2 }{ s \bigl( e^{-\lambda\alpha} \bigr)^3 }
    -
    \frac{ 2 \Pi_0(s) e^{-\lambda\alpha} }{ \bigl( e^{-\lambda\alpha} \bigr)^3 }
\right]
\\ &=
\lim_{s\to 0^{+}} 2e^{2\lambda\alpha} \left[
    \frac{ e^{-\lambda\alpha} }{ s }
    -
    \Pi_0(s)
\right]
\end{align*} Assuming that I haven't done something silly with the algebra, my guess is that has to do with even versus odd powers of $s$ vis-a-vis $-s$ . In the first answer, after multiplying by powers of $s$ , the denominators are even powers ( $4$ and $2$ ). But in the second answer the denominators are odd powers ( $3$ and $3$ ). So in some sense, in the first answer I could replace $s$ with $-s$ and everything is the same, but in the second answer I have a "" $-$ "" left over. Many thanks in advance.","['limits', 'real-analysis']"
3641315,How to prove $\sum_{n=0}^\infty(-1)^ne^{-xa^n}\ne \sum_{n=0}^\infty\frac{(-x)^n}{n!(1+a^n)}$?,"Assume that for $x>0$ and $a>1$ , $$f(x)=\sum_{n=0}^\infty(-1)^ne^{-xa^n},\quad g(x)=\sum_{n=0}^\infty\frac{(-x)^n}{n!(1+a^n)}$$ Regardless of validity, I use Taylor expansion for $e^{-xa^n}$ with respect to $x$ , and then exchange the order of both series to get $g(x)$ . However, $f(x)\ne g(x)$ . For example, when $a=2$ , $$f(1)-g(1)=0.0001579\cdots.$$ So why does this kind of circumstance appear ? In other words, why does $f(x)\ne g(x)$ ?","['sequences-and-series', 'real-analysis']"
3641317,Continuity of the supremum of a continuous function over a closed interval,"Proposition: let $F:R\times [0,1]\rightarrow R$ , be a countinuous function. If $g(x):= Sup\{F(x,t):t\in [0,1]\}$ , then $g(x)$ is continuous at all points. My Idea: 
Assume $g$ is not continuous at $x_0$ . Then there exists $\epsilon >0$ such that there exists a sequence $\{y_n\}$ which is converges to $x_0$ and $|g(y_n)-g(x_0)|>\epsilon$ and $y_n\ne x_0$ for all $n$ . $g(y_n)=F(y_n,t_n)$ for some $t_n\in [0,1]$ as $[0,1]$ is compact and $F$ is continuous. Thus we have the sequence $\{(y_n,t_n)\}$ . Now since the sequence lies in a closed interval by the Bolzano–Weierstrass theorem there is a sub-sequence $\{(y_m,t_m)\}$ which converges. It is easy to note $\{(y_m,t_m)\}$ converges to $(x_0,t_0)$ where $t_0$ is some real number between 0 and 1 . Hence $F(y_m,t_m)>g(x_0)+\epsilon$ or $F(y_m,t_m)<g(x_0)-\epsilon$ as $g(y_m)>g(x_0)+\epsilon$ or $g(y_m)<g(x_0)-\epsilon$ , which implies $F(x_0,t_0)\ge g(x_0)+\epsilon$ or $F(x_0,t_0)\le g(x_0)-\epsilon$ If it were only for the first inequality we would be done, alas it is not the case. I would appreciate if someone helped me prove/disprove the proposition.","['continuity', 'multivariable-calculus', 'analysis', 'real-analysis']"
3641350,Is the Ratio of Associative Binary Operations to All Binary Operations on a Set of $n$ Elements Generally Small?,"I started thinking about the number of associative (binary) operations on a set with $n$ elements today.  Looking online I found this paper which indicates only $113$ of the possible $19,683$ operations on a three-element set satisfy association.  So, $50\%$ of binary operations on a two-element set satisfy association, and less than $0.6\%$ of all binary operations on a three element set satisfy association.  For an $n$-element set, where $n$ denotes a natural number, is the ratio $R_{n}=A_{n}/B_{n}$, of the number of associative binary operations $A_{n}$ to the number of all binary operations $B_{n}$, in general small?  I don't mean the following questions as equivalent, but since they seem more concretely answerable in principle, does $$
\lim_{n \to +\infty} \frac{A_{n}}{B_{n}} = 0 ?
$$ Also, is $F : n \to R_{n}$ a monotonically decreasing function? Some Background of the Question: In his Linear Algebra Problem Book 1995 on p. 6 Paul Halmos writes ""The commonly accepted attitudes toward the commutative law and the associative law are different.  Many real life operations fail to commute; the mathematical community has learned to live with that fact and even to enjoy it.  Violations of the associative law, on the other hand, are usually considered by specialists only.""  For all I know, Halmos might only have written that to motivate the study of Linear Algebra and doesn't quite literally mean what he appears to say.  But, if he means what he appears to say, and if $F : n \to R_{n}$ is monotonically decreasing, or $R_{n}$ is generally small, I think there's something amiss with what Halmos says, since non-associative operations seem so common that one may as well enjoy them.","['abstract-algebra', 'combinatorics', 'analysis']"
3641410,Fourier transform difficulty 2D,"I have solved easily the (1) but I am really struggling with (2) and (3) . Do i need to use change of order of integration, because of so many parameters... i am confused a little bit. My work: $$\hat{Xf}(\xi,\theta)=\int\limits_{-\infty}^{\infty}\left(\int\limits_{-\infty}^{\infty}f(t\cos\theta+s\sin\theta,t\sin\theta - s\cos\theta) ds\right)e^{-2\pi i \xi t} dt = ??$$ How do I achieve $d\theta$ , any hints please? I got Jacobian as $t$ So, $$dxdy=t dt d\theta$$ I guess I am very close, I have also obtained $$\hat{f}(\xi\cos\theta,\xi\sin\theta)=\int\limits_{-\infty}^{\infty}\int\limits_{-\pi}^{\pi}f(t\cos\theta+s\sin\theta,t\sin\theta - s\cos\theta)e^{-2\pi i \xi t}  t d\theta dt$$","['integration', 'fourier-analysis', 'fourier-transform', 'multivariable-calculus', 'calculus']"
3641457,Technique for solving $\frac{ax+b}{cx+d}=\frac{px+q}{rx+s}$ where the sum of numerators equals the sum of denominators,"I was looking up some shortcuts to solve quadratic equations. I got a technique that applies when the sum of the numerators and denominators are equal, but I am unable to understand the reasoning behind it. Here I'm showing an example: $$ \frac{3x + 4}{6x + 7} = \frac{5x + 6}{2x + 3} $$ The solution goes as follows: ""Minute observation of the question helps us to identify that this question falls in a special category of quadratic equations, where the sum of the numerators (N) and the sum of the denominators (D) are found to be equal to 8x + 10.'' For the first root, $ N_1 + N_2 = D_1 + D_2 = 0$ or, $ 8x + 10 = 0 $ or, $ x = -5/4 $ For the second root $ N_1 - D_1 = N_2 - D_2 = 0 $ or, $ 3x + 3 = 0 $ or, $ x = -1 $ Can someone explain the reasoning/proof behind this?","['algebra-precalculus', 'quadratics']"
3641467,Trouble understanding the proof of Schröder-Bernstein theorem in Zorich's book?,"I've seen this exercise on Zorich's Mathematical Analysis 1: Doubts: It seems that from $\text{card }X = \text{card }Z$ , it follows that $(\text{card }X\leq \text{card }Y)$ and $(\text{card }Y\leq \text{card }X)$ and then $(\text{card }X\ = \text{card }Y)$ , It's not clear how. I know I'd have to prove that $g$ is a bijection, probably showing that $g$ is injective and surjective? How do I do that? I lack the tools to deal with that function and prove that.",['elementary-set-theory']
3641567,"Show that $E(X\mid Y)=E(X\mid A_1)1_{A_1}+\cdots +E(X\mid A_n)1_{A_n}$ when $\sigma(Y)=\sigma(\{A_1,\cdots A_n\})$","Lets $\sigma(Y)=\sigma(\{A_1,\cdots A_n\})$ where $A_1,\cdots , A_n$ is a partition on $\Omega$ . Show $$E(X\mid Y)=E(X\mid A_1)1_{A_1}+\cdots E(X\mid A_n)1_{A_n}$$ . My try: By definition $Y$ is a simple function, that is $Y=\sum c_i 1_{A_i}$ . $E(X\mid Y)$ is a function of $Y$ so \begin{eqnarray}
E(X|Y)=\left\{
\begin{array}{cccc}
a_1   &     \omega \in A_1   \\
a_2    &    \omega \in A_1     \\
.    &     .  \\
a_n   &    \omega \in A_n   
\end{array}
\right.
\end{eqnarray} and it is enough to calculate $a_i$ . By definition of conditional expectation $$E(X1_B)=E(E(X\mid Y)1_B), \text{for all} B\in \sigma(Y)$$ so $$E(X 1_{A_i})=E(E(X\mid Y)1_{A_i})=E(a_i 1_{A_i})=a_i E(1_{A_i})$$ so $a_i=\frac{E(X 1_{A_i})}{ E(1_{A_i})}= E(X\mid A_i).$ Q_1) Is this  proof valid? Q_2) Is this valid for a countable partition on $\Omega$ . It means , If $\{A_n , n\geq 1\}$ be a countable partition on $\Omega$ and $\sigma(Y)=\sigma(A_1,A_2,\cdots )$ $E(X\mid Y)=\sum_{n\geq 1} E(X\mid A_n)$ ,that is, (countable case). Q_2) Is this valid for an uncountable case. For $\{A_i , i\in I\}$ be a uncountable partition on $\Omega$ , where $I$ is an uncountable index set, if $E(X\mid Y)=\sum_{i\in I} E(X\mid A_n)$ ?
For example $\Omega=[0,1]$ , $\{A_x=\{ x\} ,x\in [0,1]\}$ Thanks in advance for any help you are able to provide or any clarification.","['conditional-expectation', 'measure-theory', 'probability-theory', 'real-analysis']"
3641586,Minimum area of an art gallery?,"I've adapted this problem from a TedEd riddle that I solved yesterday. It asks, what is the minimum number of rooms required such that every room except one room is connected to exactly three other rooms, except for one ""special"" room that is only connected to one other room. You can think of this like you're designing an art gallery to meet these conditions, and your ""special"" room contains a very rare painting which has to sit behind a vault door of which you only have one. I won't state the answer in this thread so as to not spoil the puzzle. Anyway, I thought of an interesting extension of this puzzle. Suppose your building company is rather cheap, and can only build walls in integer multiples of one meter and walls can only intersect at right angles, i.e, they can only build on ""gridlines"". Note that non rectangular rooms are allowed, as long as any vertex has an interior angle of $90$ or $270$ degrees. Furthermore, a door takes up an entire one meter segment, and for ease of navigation, 2 rooms may not be touching without a door between them. My question is, what is the minimum area, in multiples of $1\text{m}^2$ boxes, of such a gallery design? How might I work this out?","['analytic-geometry', 'graph-theory', 'geometry', 'geometric-topology', 'discrete-mathematics']"
3641608,Showing a subspace is not closed,"I have been asked the following problem which I have so far failed to solve rigourosly. Let $M=\{ (a_n)_{n=1}^\infty\in l^2\vert \sum_{n=1}^\infty \frac{a_n}{\sqrt{n}}=0 \}$ . Determine whether $M$ is a closed subspace of $l^2$ . My attempt: I think that the answer is no because this seems like the kernel of a functional $$ \phi(a):= \Big \langle a,\big(\frac{1}{\sqrt{n}}\big) \Big \rangle $$ . And since $(l^2)^*=l^2$ , and $\Big( n^{-1/2} \Big)_{n=1}^\infty\notin l^2$ , we should know that $\phi$ is not continuous and its kernel is dense, i.e., not closed. However it is not clear that $\phi$ is defined and hence not even necessarily a functional. My question is whether this argument is salvagable, and if not whether someone knows of a solution to this question?","['hilbert-spaces', 'functional-analysis', 'sequences-and-series']"
3641658,Prove that $(\frac{\pi}{3})^{\frac{3}{\pi}}+(\frac{3}{\pi})<2$,"Prove that : $$\left(\frac{\pi}{3}\right)^{\frac{3}{\pi}}+\frac{3}{\pi}<2$$ Straightforward proof : Since the function $f(x)=(x)^{\frac{1}{x}}+\frac{1}{x}$ is decreasing on $\left[1,\frac{\pi}{3}\right]$ We get : $$f\left(\frac{\pi}{3}\right)=\left(\frac{\pi}{3}\right)^{\frac{3}{\pi}}+\frac{3}{\pi}<f(1)=2$$ So we get an almost integer easily . My questions : Have you an alternative proof ? Can we find other almost integer with this way? Thanks a lot for all your contributions .","['alternative-proof', 'inequality', 'pi', 'derivatives']"
3641720,Prove combinatorically that $\sum_{i=1}^{n}2^{i-1}3^{n-i}=3^n-2^n$.,"Prove combinatorically that $$\sum_{i=1}^{n}2^{i-1}3^{n-i}=3^n-2^n\,.$$ For the right expression I was thinking about the problem ""amount of $n$ -long ternary vectors with at least one ' $2$ '"", but I can't seem to solve it with the left side so idk. Looking for a hint.","['summation', 'combinatorics', 'combinatorial-proofs', 'discrete-mathematics']"
3641764,Coproduct of free monoids.,"Consider the following diagram, where $A,B$ are sets, $A+B$ is their disjoint union, and $M(X)$ is the free monoid on $X$ for $X=A, B, A+B$ . I want to prove that $M(A+B)$ is the coproduct of $M(A)$ and $M(B)$ , just using universal properties. How does the universal properties of $A+B, M(A), M(B)$ and $M(A+B)$ induce the existence (and uniquiness) of the dotted vertical arrow to $N$ ? In other words, how can I prove that $M(A+B)$ has the universal property of the coproduct $M(A)+M(B)$ of $M(A)$ and $M(B)$ , without invoking any concrete presentation of the objects involved, such as the free monoid of words,...?","['monoid', 'abstract-algebra', 'category-theory']"
3641811,There is no total order on $\mathbb{C}$ with the algebraic property $0\leq z_1\land0\leq z_2\Rightarrow0\leq z_1+z_2\land0\leq z_1z_2$,"This question is about the proof of Example 62 (d) on Page 27 of these notes . The statement is that there is no total order $\leq$ on $\mathbb{C}$ with the algebraic property $0\leq z_1\land0\leq z_2\Rightarrow0\leq z_1+z_2\land0\leq z_1z_2$ . The statement is wrong; Thomas Andrews's answer below shows that there
  is a total order on $\mathbb{C}$ such that $0\leq z_1\land0\leq
> z_2\Rightarrow0\leq z_1+z_2\land0\leq z_1z_2$ . My attempt goes as follows: Any total order $\leq$ has the following properties: $\forall _{z_1\in \mathbb{C}}(z_1\leq z_1)$ (reflexive) $\forall _{z_1,z_2\in \mathbb{C}}\left(z_1\leq z_2\land z_2\leq z_1\Rightarrow z_1=z_2\right)$ (anti-symmetric) $\forall_{z_1,z_2,z_3\in \mathbb{C}}\left(z_1\leq z_2\land z_2\leq z_3\Rightarrow z_1\leq z_3\right)$ (transitive) $\forall _{z_1,z_2\in \mathbb{C}}\left(z_1\leq \
z_2\lor z_2\leq z_1\right)$ (total order) The question proposes a further algebraic property: $\forall _{z_1,z_2\in \mathbb{C}}\left(0\leq z_1\land \
0\leq z_2\Rightarrow 0\leq z_1+z_2\land 0\leq z_1 z_2\right)$ We need to prove that there is no relation with all five properties. The partial order $z_1\leq z_2\Leftrightarrow\left(z_1=z_2\lor\left|z_1\right|<\left| z_2\right|\right)$ has properties 1, 2, 3 and 5. Hence, the most straightforward possible proofs are $4\Rightarrow\neg 5$ or $5\Rightarrow\neg4$ . An attempt at $4\Rightarrow\neg 5$ : Either $0\leq i$ or $i\leq 0$ but not both as $i\neq 0$ (due to anti-symmetry). If $0\leq i$ , then using $z_1=z_2=i$ in property 5 gives $0\leq 2i$ and $0\leq -1$ . Using $z_1=2i$ and $z_2=-1$ in property 5 gives $0\leq -1+2i$ and $0\leq -2i$ Alternatively, using $z_1=z_2=-1$ in property 5 gives $0\leq -2$ and $0\leq 1$ In general, we generate $0\leq a+bi$ for various integer $a$ and $b$ . If $i\leq 0$ , then property 5 gives no results. Regardless of the initial $0\leq z$ , property 5 only gives $0\leq P(z)$ , where $P(z)$ are integer coefficient polynomials in $z$ . How does this provide a contradiction? Furthermore, the $z\leq 0$ case seems entirely intractable. An attempt at $5\Rightarrow\neg 4$ : Any violation of 4 requires $\neg 0\leq z\land \neg z\leq 0$ The contrapositive of 5 only generates $\neg 0\leq P(z)$ starting with $\neg 0\leq z$ and hence does not violate 4. Starting with $\neg z\leq 0$ ends with nothing further and thus does not negate 4. It seems that the two most straightforward approaches are not going to work. I have no idea how to proceed with the more complicated options.","['elementary-set-theory', 'relations']"
3641858,Can a composite number $3\cdot 2^n + 1$ divide a Fermat number $2^{2^m}+1$?,"In OEIS entry A204620 , there is a question (by Arkadiusz Wesolowski) about whether composite numbers of the form: $$3\cdot 2^n + 1$$ can be divisors of a Fermat number, i.e. of a number of the form $2^{2^m}+1$ . The question is ""answered"" by a comment by myself where I quote Morehead's 1906 paper (see Links section on OEIS entry). In it, he states: It is easy to show that composite numbers of the forms $2^\kappa \cdot 3 + 1,\  2^\kappa \cdot 5 + 1$ can not
  be factors of Fermat's numbers. However, to be sure, is that really easy to see? Or can it be proved in a ""hard"" way?","['elementary-number-theory', 'fermat-numbers', 'divisibility', 'sequences-and-series']"
3641917,Synthetic Proof for a Geometry problem,"A while back, this question was asked on MSE: Find the length of $CE$ In fact, allow me to phrase the problem in a slightly different manner: In quadrilateral $ABCD$ , $AB=6$ , $\angle{ABC}=90°$ , $\angle{BCD}=45°$ and $\angle{CAD}=2\angle{ACB}$ . If $DE$ is perpendicular to $AC$ with $E$ on side $BC$ , prove that the length of $CE=12$ . I have managed to prove the above result, but was unable to avoid the use of some trigonometry and algebraic manipulations. My solution is as follows: Let $M$ be the point of intersection of line segments $AC$ and $DE$ , and let $H$ be the foot of the perpendicular from $M$ to line segment $EC$ . Also, let $BC=x$ , $CE=a$ . Finally, let $\angle ACB =\theta, \angle CAD = 2\theta, \angle ACD=45^{\circ}-\theta$ . By Pythagoras' Theorem, $AC=\sqrt{AB^2+BC^2}=\sqrt{36+x^2}$ . Clearly, $\triangle{CME} \sim \triangle{CBA} \Rightarrow \frac{CM}{CE}=\frac{BC}{AC} \Rightarrow CM=CE \cdot \frac{BC}{AC}=\frac{ax}{\sqrt{36+x^2}}$ . Thus $AM=AC-MC=\sqrt{36+x^2}- \frac{ax}{\sqrt{36+x^2}}=\frac{36+x^2-ax}{\sqrt{36+x^2}} \Rightarrow \frac{CM}{AM} = \frac{ax}{36+x^2-ax}$ . Now, $\tan(2\theta)=\frac{MD}{MA}, \tan(45^{\circ}-\theta)=\frac{MD}{MC} \Rightarrow \frac{\tan(2\theta)}{\tan(45^{\circ}-\theta)}=\frac{MC}{MA}=\frac{ax}{36+x^2-ax}$ . On the other hand, $\tan(\theta)=\frac{AB}{BC}=\frac{6}{x} \Rightarrow \tan(2\theta)=\frac{2\tan(\theta)}{1-\tan^2(\theta)}=\frac{2 \cdot \frac{6}{x}}{1-\frac{36}{x^2}}=\frac{12x}{x^2-36} $ . Also, $\tan(45^{\circ}-\theta)=\frac{\tan(45^{\circ})-\tan(\theta)}{1+\tan(45^{\circ})\tan(\theta)}=\frac{1-\tan(\theta)}{1+\tan(\theta)}=\frac{1-\frac{6}{x}}{1+\frac{6}{x}}=\frac{x-6}{x+6} \Rightarrow \frac{\tan(2\theta)}{\tan(45^{\circ}-\theta)} = \frac{12x}{(x-6)^2}$ . Thus, we have $\frac{12x}{(x-6)^2}=\frac{ax}{36+x^2-ax} \Rightarrow a= (36+x^2-ax) \cdot \frac{12}{(x-6)^2} \Rightarrow a[1+\frac{12x}{(x-6)^2}]= 12 \cdot \frac{36+x^2}{(x-6)^2} \Rightarrow a \cdot \frac{x^2+36}{(x-6)^2} = 12 \cdot \frac{36+x^2}{(x-6)^2} \Rightarrow a=12$ . But this solution is, admittedly, rather tedious. Thus, I wonder if there exists a synthetic solution by any chance?","['alternative-proof', 'euclidean-geometry', 'geometry']"
3641927,"Why is $E[XY, X = i] = iE[Y, X = i]$?","So i am working on a problem in probability theory and i came across the following equation $$E[XY\mid \mathcal{F}]  = \sum_{i \in [6]}E[XY\mid X = i]1_{\{X=i\}} = \sum_{i \in [6]}\frac{E[XY, X = i]}{P[X=i]}1_{\{X=i\}} = \sum_{i \in [6]}\frac{iE[Y, X = i]}{P[X=i]}1_{\{X=i\}} = \sum_{i \in [6]}\frac{iE[Y]P[X = i]}{P[X=i]}1_{\{X=i\}}$$ For context: $[6]$ describes the set $\{1,...,6\}$ and $X,Y$ are the projections $X,Y: [6]^2 \to [6]$ and $\mathcal{F} = \sigma(X)$ the $\sigma$ -algebra generated by the projection $X$ . Unfortunately, I dont know why the 3rd ""="" and the last ""="" hold. Can someone help me understanding these 2 equations?","['conditional-expectation', 'expected-value', 'independence', 'probability-theory']"
3641959,How does the topology of a space describe the closeness of the open subsets of a given set $X$?,"I've been trying to learn about topology recently and there is a thing that I couldn't understand. I know that given the topological space $(X,\tau)$ , the $\tau$ contains open subsets of $X$ . To my understanding, the $\tau$ exists to describe the closeness of the subsets of $X$ without using any 
kind of distance function (like in metric spaces). But how can we make these statements using the information given for a $\tau$ . E.g. let $(X,\tau_1)$ be a topological space with $X=\{a,b,c\}$ and $\tau_1=\{\emptyset,\{a,b,c\},\{a\},\{b\},\{a,b\}\}$ .
What kind of statements can we make about the closeness of the subsets $\{a\},\{b\}$ and $\{a,b\}$ (and about the element $c$ )? Now let $(X,\tau_2)$ be another topological space with the same $X$ but with the $\tau_2=\{\emptyset,\{a,b,c\},\{a\}\}$ . What would be difference between $(X,\tau_1)$ and $(X,\tau_2)$ ? Also another question: why do the elements of $\tau$ always have to be open sets? Why can't they be just closed? Or is it just the definition of the topolology which makes the subsets open?","['elementary-set-theory', 'general-topology']"
3642041,What is the function fsolve in python doing mathematically?,"In the Python documentation for fsolve it says ""Return the roots of the (non-linear) equations defined by func(x) = 0 given a starting estimate"" f(x, *args). I wondered if anyone knew the mathematical mechanics behind what fsolve is actually doing? 
Thanks.","['python', 'roots', 'linear-algebra', 'numerical-linear-algebra', 'nonlinear-system']"
3642049,Proving $\sum_{r=0}^{n-1} (-1)^r \cos^n{\left(\frac{r\pi}{n}\right)}=\frac{n}{2^{n-1}}$,"Prove that $$\sum_{r=0}^{n-1} (-1)^r \cos^n{\left(\dfrac{r\pi}{n}\right)}=\dfrac{n}{2^{n-1}}$$ I proved the result using induction, however am more interested in finding the sum using complex numbers. Any hint?","['trigonometry', 'summation', 'complex-numbers']"
3642101,"O. Gabber, Non-negativity of Serre’s intersection multiplicities","This article is cited here and there, but I cannot find it anywhere. Gabber, O. (1995), Non-negativity of Serre’s intersection multiplicities, Expos ́e `a L’IHES I checked author's publications, and there are none in 1995.","['article-writing', 'algebraic-geometry', 'reference-request']"
3642105,"Evaluate $\int_0^1 \frac{x \operatorname{Li}_2(x) \log (1+x)}{x^2+1} \, dx$","$$\int_0^1 \frac{x \operatorname{Li}_2(x) \log (1+x)}{x^2+1} \, dx=-\frac{3\pi }{4}  \Im(\operatorname{Li}_3(1+i))+\frac{189}{128} \zeta (3) \log (2)+\frac{C^2}{2}-\frac{1}{4} \pi  C \log (2)+\frac{ \operatorname{Li}_4\left(\frac{1}{2}\right)}{8}+\frac{89 \pi ^4}{5760}+\frac{ \log ^4(2)}{192}+\frac{7}{96} \pi ^2 \log ^2(2)+\frac{1}{4}\int_0^1\frac{\ln(1-x)\operatorname{Li}_2(-x^2)}{1+x}dx$$ I was inspired by the method used by Ali Shather (see here ) to calculate this integral. But here, without going into the details of the long and tedious calculations, I could only deduce this relation. I believe that the last integral has never been calculated, is therefore a closed form for the proposed integral? $$$$","['integration', 'polylogarithm', 'definite-integrals', 'closed-form']"
3642137,Exercise on the implicit function theorem.,"Prove that the equation $x^2+y^2+\sin y=0$ defines a unique function $y=f(x)$ in a neighbourhood of $(0,0)$ . Prove also that in $x=0$ there's a maxima for $f$ . I tried to do this exercise in two different ways and I'm asking you to tell me if I did something wrong, if the procedure is correct and if I could have done something better. To prove that the equation defines a unique function $y=f(x)$ I want to use the implicit function theorem with the function $F(x,y)=x^2+y^2+\sin y$ . We have that $F(0,0)=0$ and $F$ is clearly $C^{\infty}$ so we don't have regularity problems. It's easy to verify that $F_y(x,y)=2y+\cos y$ and so $F_y(0,0)=1 \neq 0$ . For the implicit function theorem we have that there exists a unique function $f \colon \mathbb{R} \to \mathbb{R}$ at least defined in a neighbourhood of $0$ such that $y=f(x)$ . We also remind that as $F$ is $C^{\infty}$ even $f$ is $C^{\infty}$ . Now we have the two different solutions for the second question, proving that in $x=0$ there is a maxima. We know from the implicit function theorem that $$f'(x)=-\frac{F_x(x,f(x))}{F_y(x,f(x))}$$ and so $$f'(x)=0$$ which tells us that $x=0$ is a stationary point for $f$ . We can now use the chain rule to say that $$f''(x)=-\frac{[F_{xx}(x,f(x))+F_{xy}(x,f(x))f'(x)]F_y(x,f(x))-F_x(x,f(x))[F_{yx}(x,f(x))+F_{yy}(x,f(x))}{F_y(x,f(x))^2}$$ from which $f''(0)<0$ and so $f$ has a maxima in $0$ . We know that $f$ is $C^{\infty}$ so we have that $$f(x)=f(0)+f'(0)x+\frac{f''(0)}{2}x^2+o(x^2)$$ and for what we observed in the first part we have $f(0)=f'(0)=0$ . We know also that $F(x,f(x))=0$ and so, by plugging in the last equation the expression we found for $f(x)$ we have that $$x^2+\frac{f''(0)}{2}x^2+o(x^2)=0 \implies f''(0)=-2$$ and so the thesis. Is it alright? Suggestions?","['real-analysis', 'calculus', 'inverse', 'implicit-function-theorem', 'derivatives']"
3642150,Let $G$ be an $n$-vertex graph with at most $100n$ triangles. Prove that $G$ has a triangle-free...,"Let $G$ be an $n$ -vertex graph with at most $100n$ triangles. Prove that $G$ has a triangle-free induced subgraph with at least $\frac{n}{15 \sqrt{3}}$ vertices. My solution: We pick each vertex independently with probability $p \in[0,1]$ (we choose it later). Let $X$ be a number of chosen vertices and $Y$ a number of chosen triangles. Then the number of good vertices is at least $X-Y$ (we throw out from each chosen triangle at least one (bad) vertex). Calculate the expectation of it. $$E(X-Y) = E(X) -E(Y) \geq np-100n\cdot p^3$$ Now, the function $f(p) = p-100p^3$ has maximum at $p={\sqrt{3}\over 30}$ which give us $$E(X-Y) \geq {n\over 15\sqrt{3}}$$ So there must exists a subgraph with at least ${n\over 15\sqrt{3}}$ vertices with no triangle. Now I have 2 questions: Is there a non probabilistic solution? Is there a better bound?","['discrete-optimization', 'probabilistic-method', 'combinatorics', 'extremal-combinatorics']"
3642200,Hypersurface-orthogonality and static spacetimes,"I am currently learning about general relativity using these notes and I am confused by the notion of hypersurface orthogonality of a vector field. We define a spacetime to be stationary if there exists a timelike Killing vector field K. In this case we construct a system of coordinates $(t, x^i)$ where $x^i$ are coords on a hypersurface which is nowhere tangent to $K^a$ , $K = \frac{\partial}{\partial t}$ and the metric takes the form $$ ds^2 = g_{00}(x^k)dt^2 + 2g_{0i}(x^k)dtdx^i + g_{ij}(x^k). \label{eq:metric}$$ If in addition the Killing vector $K^a$ is hypersurface-orthogonal then we say the spacetime is static. We can choose the hypersurface in the construction of the above coords to be orthogonal to $K^a$ , and so the metric has $g_{0i} = 0$ in these coordinates. My issue here is that in my head I picture that for any smooth covector field there should be some hypersurface which is orthogonal to it. This would mean that any vector field is hypersurface orthogonal and hence any stationary spacetime is automatically static, but this is clearly false. Why is it that some vector fields are not hypersurface-orthogonal? The standard example of a stationary but not static spacetime is the Kerr metric. In Boyer-Lindquist coordinates, the metric is in the above form with $g_{0i} \neq 0$ (to be precise there is a $dtd\varphi$ cross term). This means that when lowering the index on $K^a = \left(\frac{\partial}{\partial t}\right)^a$ we get a $d\varphi$ component, ensuring that $K_a$ is not orthogonal to the constant $t$ surfaces. But why does this mean that Kerr is not static, since surely there could be a different foliation by hypersurfaces which are orthogonal to $K$ ?","['general-relativity', 'mathematical-physics', 'differential-geometry']"
3642210,"Given $U_1, U_2, \ldots, U_n$ i.i.d $\sim \text{Unif}(-1, 1)$, what's the probability that $U_1^2 + U_2^2 + \ldots + U_n^2 \le 1$?","Given $U_1, U_2, \ldots, U_n$ i.i.d $\sim \text{Unif}(-1, 1)$ , what's the probability that $U_1^2 + U_2^2 + \ldots + U_n^2 \le 1$ ? I tried to reduce it to $U_1^2 + U_2^2 \le 1$ and interpret the result geometrically but I'm not able to reason about it properly. $U_1^2 + U_2^2 \le 1$ represents the circle with radius $1$ centred in $0$ , but how can you interpret $|U_1| + |U_2|$ ? If $-1 \le U_1 \le 1$ and $-1 \le U_2 \le 1$ then $0 \le |U_1| + |U_2| \le 2$ .
If my reasoning is correct: $$P(U_1^2 + U_2^2 \le 1) = \frac{\textrm{Area of circle}}{\textrm{Area of } |U_1| + |U_2|} = \frac{\pi}{\textrm{Area of } |U_1| + |U_2|}$$ After that the same principle can be applied in a higher dimension, in 3 dimensions could be the volume of sphere divided the volume of the shape defined by $|U_1| + |U_2| + |U_3|$ , etc. I'd appreciate some guidance on this.","['statistics', 'uniform-distribution', 'probability-distributions', 'probability', 'random-variables']"
3642257,Derive an upper bound for the total variation of quadratic covariation [Exercise 1.5.7 in Karatzas and Shreve].,"Recall that given two continuous integrable martingale $X$ and $Y$ , we can define the quardatic covariation as $$\langle X,Y\rangle=\dfrac{\langle X+Y\rangle-\langle X-Y\rangle}{4},$$ where $\langle \cdot\rangle$ is the quadratic variation defined from  the unique increasing natural martingale in Doob's decomposition theorem. In the book by Karatzas and Shreve, they gave an exercise as follows: $\langle \cdot,\cdot\rangle$ on the set of square integrable martingales $\mathcal{M}_{2}$ satisfies the following properties: for any members $X,Y,Z$ of $\mathcal{M}_{2}$ and real numbers $\alpha,\beta$ , we have: $(1)$ $\langle \alpha X+\beta Y, Z\rangle=\alpha\langle X,Z\rangle+\beta\langle Y,Z\rangle$ ; $(2)$ $\langle X,Y\rangle=\langle Y,X\rangle;$ $(3)$ $|\langle X,Y\rangle|^{2}\leq\langle X\rangle \langle Y\rangle;$ $(4)$ For almost every $\omega\in\Omega$ , $$\xi_{t}(\omega)-\xi_{s}(\omega)\leq\dfrac{1}{2}\Big[\langle X\rangle_{t}(\omega)-\langle X\rangle_{s}(\omega)+\langle Y\rangle_{t}(\omega)-\langle Y\rangle_{s}(\omega)\Big]$$ for $0\leq s<t<\infty$ , where $\xi_{t}$ denotes the total variation of $\xi:=\langle X,Y\rangle$ on $[0,t]$ . I have proved $(1)-(3)$ . The proof of $(1)$ can be read here: Prove that the quadratic covariation is a bilinear form . $(2)$ is immediate. $(3)$ follows from Cauchy-Schwarz since we have proved in $(1)$ and $(2)$ that $\langle \cdot,\cdot\rangle$ is a bilinear symmetric form, and it is clear that it is positive semi-definite. However, I got stuck in $(4)$ . By definition the total variation can be written as $$\xi_{t}(\omega)=\sup_{\mathcal{P}}\sum_{i=0}^{n(p)-1}|\langle X,Y\rangle_{t_{i+1}}-\langle X,Y\rangle_{t_{i}}|$$ where the sup is taken over the collection $\mathcal{P}$ of all partitions $(t_{0},\cdots, t_{n})$ of $[0,t]$ . So, if $\mathcal{P}$ is the partition of $[0,t]$ and $\mathcal{G}$ is the partition of $[0,s]$ for $s<t$ , then we have \begin{align*}
\xi_{t}(\omega)-\xi_{s}(\omega)&=\sup_{\mathcal{P}}\sum_{i=0}^{n(p)-1}|\langle X,Y\rangle_{t_{i+1}}-\langle X,Y\rangle_{t_{i}}|-\sup_{\mathcal{G}}\sum_{j=0}^{m(g)-1}|\langle X,Y\rangle_{s_{i+1}}-\langle X,Y\rangle_{s_{i}}|\\
&\leq \sup_{\mathcal{P}}\sum_{i=0}^{n(p)-1}|\langle X,Y\rangle_{t_{i+1}}-\langle X,Y\rangle_{t_{i}}|-\sum_{j=0}^{m(g)-1}|\langle X,Y\rangle_{s_{i+1}}-\langle X,Y\rangle_{s_{i}}|\\
&\leq \sup_{\mathcal{P}}\sum_{i=0}^{n(p)-1}|\langle X,Y\rangle_{t_{i+1}}|+|\langle X,Y\rangle_{t_{i}}|-\sum_{j=0}^{m(g)-1}|\langle X,Y\rangle_{s_{i+1}}-\langle X,Y\rangle_{s_{i}}|.
\end{align*} But then I got stuck. What should I do? Thank you!","['analysis', 'real-analysis', 'stochastic-processes', 'quadratic-variation', 'probability-theory']"
3642259,Deciding if subset and element statements involving sets are true or false,"I'm trying to figure out if these statements are true or false: (1) {∅} ∈ P(A) (2) {A} ⊆ A (3) A ⊆ {A} This is what I think they are: (1) false reasoning : ∅ is a set with no elements, but {∅} is a set with one element (∅). Since ∅ is a subset of every set, ∅ is a subset of A. By definition a power set of a set, in this case A, is a set whose elements are subsets of the set A. So since ∅ is a subset of A, $∅ ∈ P(A)$ is true but not {∅} ∈ P(A) (2) false reasoning : A is contained in {A}, but {A} is not contained in A, so A ⊆ {A} is true, but {A} ⊆ A is false. (3) true reasoning: see previous explaination Is what I said correct (both the true/false answer and my reasoning)?","['elementary-set-theory', 'solution-verification']"
3642282,Normal cone to the union of sets,"For a set $A \subseteq \Bbb R^n$ and a point $\bar{x} \in A,$ the limiting (Mordukhovich) normal cone of $A$ at $\bar{x}$ is defined as $$N(\bar{x},A):= \limsup_{x\to \bar{x}} \widehat{N}(x,A),$$ where $$\widehat{N}(x, A):= \left\{u \in \Bbb R^n \mid \limsup_{x'\to x,\; x'\in A}\frac{u^\top (x'-x)}{\|x'-x\|}\leq 0\right\} $$ is the so-called Frechet normal cone and the limit is understood in the sense of Painleve-Kuratowski. Furthermore, for a functional $f: \Bbb R^n \to \Bbb R$ , the limiting subdifferential of $f$ at $\bar{x}$ is defined as $$\partial f(\bar{x}):= {u \in \Bbb R^n \mid (u,-1) \in N((\bar{x},f(\bar{x}), epi f) },$$ where $epi f$ is the epigraph of $f.$ All of these definitions and more are from the book ""Variational Analysis and Generalized Differentiation"" by Boris Mordukhovich. Now, consider two closed sets $A,B \subseteq \Bbb R^n$ and a point $\bar{x} \in A\cap B.$ My question is: does the inclusion $$N(\bar{x}, A\cup B) \subseteq N(\bar{x}, A) \cup N(\bar{x},B)$$ holds? If so, does there exists a reference for the result or a tighter upper bound? This question seems to be very natural, given the normal cone intersection formula, see Theorem 3.4 in Mordukhovich's book. However, I am not able to find such a result in the literature, and I need to cite it. My attempt at a proof is the following: Consider $\delta_A$ and $\delta_B,$ the indicator functions of $A$ and $B$ respectively. Then, it is easy to verify that $\delta_{A\cup B}= \min\{\delta_A, \delta_B\}.$ By Proposition 1.79 in Mordukhovich's book, we have $\partial \delta_A(\bar{x}) = N(\bar{x},A).$ Therefore, $$N(\bar{x}, A\cup B) = \partial (\min\{\delta_A, \delta_B\})(\bar{x}).$$ Moreover, by Proposition 1.113 (Mordukhovich's book) we have $$\partial (\min\{\delta_A, \delta_B\})(\bar{x}) \subseteq \partial \delta_A(\bar{x}) \cup \partial \delta_B(\bar{x}) =  N(\bar{x}, A) \cup N(\bar{x},B),$$ and hence the upper bound follows. Is this correct? A direct reference would be more beneficial in any case.","['variational-analysis', 'nonlinear-optimization', 'functional-analysis', 'non-convex-optimization', 'convex-analysis']"
3642301,Can continuous functions be made smooth by changing the smooth structure on the domain?,"Suppose $M$ is a smooth manifold and $f : M \to \mathbb R$ is a continuous function.
The function $f$ may not be smooth, but does there exist another smooth structure $M'$ (on the same topological manifold $M$ ) such that $f : M' \to \mathbb R$ is a smooth function? For example, if $M = \mathbb R$ and $f (x) = x^{\frac 13}$ then $f$ is not smooth w.r.t. the usual smooth structure on $\mathbb R$ . However if we take the smooth structure provided by the chart $\varphi (x) = x^{\frac 13}$ then in these coordinates $f \circ \varphi^{-1} (t) = t$ , so $f : (\mathbb R, \varphi) \to \mathbb R$ is a smooth function.
As another example, $g (x) = \lvert x \rvert$ is not smooth, but if we take the chart $\psi (x) = \operatorname{sign} (x) \sqrt{\lvert x \rvert}$ then $\psi^{-1} (t) = t \lvert t \rvert $ , so $g \circ \psi^{-1} (t) = t^2$ , which means $g$ is a smooth function on $(\mathbb R, \psi)$ .","['smooth-functions', 'smooth-manifolds', 'calculus', 'differential-topology', 'differential-geometry']"
3642326,Integrated brownian motion is not a Markov process,"Let $B = \{B_t\}_{t\geq 0}$ be a standard brownian motion. I'm trying to show that the process $X = \{X_t\}_{t\geq 0}$ , where $$
X_t := \int_0^t B_s \,\mathrm{d}s, \tag{1}
$$ is not a Markov process with respect to the natural filtration $\{\mathscr{F}_t^B\}_{t\geq 0}$ of $B$ . I understand that, by definition, $X$ is a Markov process if for every Borel mesurable set $A \subset \mathbb{R}$ and for every $s, t > 0$ , $$
\mathbb{P}[X_{t+s} \in A \mid \mathscr{F}_s^B] = \mathbb{P}[X_{t+s} \in A \mid X_s].
$$ However, I'm having trouble to figure out how to work with this definition, especially to prove that the process is not a Markov process. I found similar questions about this process, such as this one . However, the proof given there that it is not a Markov process relies on other results about gaussian processes, which I don't know about. Is there a way to prove that the process $X$ defined by $(1)$ is not a Markov process, directly from the definition?","['markov-process', 'brownian-motion', 'probability-theory']"
3642328,Lagrange multipliers for functionals,"I am attempting to prove that the multivariate distribution with maximum entropy for a given covariance is a Gaussian. (PRML, Bishop, problem 2.14). Bishop suggests the use of Lagrange multipliers - concretely, that should maximize $$
\text{H}[x] = -\int p(x)\log(x)dx
$$ subject to the constraints \begin{align*}
\int p(x)\,dx &= 1\\
\int xp(x)\,dx &= \mu\\
\int p(x)(x - \mu)(x - \mu)^T\,dx &= \Sigma.
\end{align*} Applying Lagrange multipliers to the maximization of a functional (as opposed to the maximization of a function on $\mathbb{R}^N$ ) is alien to me. If someone could direct me to a reference describing why Lagrange multipliers continue to ""work"" in infinite dimensional function spaces, I would appreciate it.","['entropy', 'lagrange-multiplier', 'reference-request', 'functional-analysis', 'probability-theory']"
3642483,Proving $1\times 1! + 2\times 2! + 3\times 3! +\cdots.+n\times n! = (n+1)! -1 $,Prove that: $$1\times 1! + 2\times 2! + 3\times 3! +\cdots+n\times n! = (n+1)! -1 $$ My attempt :- Let S= $1\times 1! + 2\times 2! + 3\times 3! + ...+n\times n! = (n+1)! -1 $ = $1\times 1! + 4\times 1! + 9\times 2! + 16\times 3! + ...+ n^2 \times (n-1)!$ Now i wanna relate this sum with the original sum to get it but i do not know how can i do it ?,['algebra-precalculus']
3642495,"Example of a bounded linear functional $T:L^ \infty \to \mathbb{R}$ which cannot be expressed by an integral $\int_{[a,b]}fg$ for an integrable $f$","Let $m$ be the Lebesgue measure on $[a,b]$ . What would be an example of a bounded linear functional $T:L^ \infty \to \mathbb{R}$ which cannot be expressed by an integral $\int_{[a,b]}fg$ for an integrable $f$ ? I know that, if $1 \leq p < \infty$ , then any bounded linear functional $T:L^p \to \mathbb{R}$ can be expressed by an integral $\int_{[a,b]}fg$ for an $f \in L^q$ . (Where $q$ is the conjugate of $p$ .) But the proof I am familiar with relies on the fact that $p$ is finite.","['measure-theory', 'lebesgue-measure', 'lebesgue-integral', 'real-analysis']"
3642539,"limit of multivariable function $f\left(x,y,z\right)=\left(x+y+z\right)\sin\left(\frac{1}{x}\right)\sin\left(\frac{1}{y}\right)$","this is a question from my calculus homework: Check if the following function has a limit in $(0,0,0)$ and if it has, find the value: $$f\left(x,y,z\right)=\left(x+y+z\right)\sin\left(\frac{1}{x}\right)\sin\left(\frac{1}{y}\right)$$ I tried to use different approaches in order to show that the limits are not equal so the function doesn't have a limit, but obviously I always got to $0$ for example: $$x=y=z: \lim _{\left(z,z,z\right)\to \left(0,0,0\right)}\left(z+z+z\right)\sin\left(\frac{1}{z}\right)\sin\left(\frac{1}{z}\right)=\lim_{\left(z,z,z\right)\to \:\left(0,0,0\right)}3z\:\sin^2\left(\frac{1}{z}\right)$$ since $\lim _{z\to 0}3z=0$ and $\sin(\frac{1}{z})$ is a bounded function: $$\lim_{\left(z,z,z\right)\to \:\left(0,0,0\right)}3z\:\sin^2\left(\frac{1}{z}\right)=0$$ $$ $$ as well, I think converting coordinates won't help m I have no more idea then... $$ $$ sorry about my weak grammar so thankful for any help or hint","['limits', 'multivariable-calculus']"
3642545,Estimating the arc length of a sine wave using this polynomial formula?,"I need to calculate the arc length of a half period of a sine wave with a given frequency and amplitude. I found this article which summarizes a polynomial method for getting a very close approximation: http://edspi31415.blogspot.com/2012/05/arc-length-of-sinx-curve-approximation.html He states: We have been looking to find the arc length of the curve $y = a sin x$ from $x = 0$ to $x = π$ . The exact value is: $π ∫ √ (1 + a^2 cos^2 x ) dx$ $0$ However, a good estimate can be found (to 2-3 decimal places) with the polynomial: $y = .0081196317102889 x^4 - .11577326164517 x^3 + .63914882375794 x^2 + .2071162669684 x + 3.0881429428239$ I'm having trouble understanding how that polynomial works though.  Arc length of the sine wave will vary both with amplitude and frequency of the sine wave, right? I don't see a way to accommodate for that. Let's say I have a simple equation of: $y = a * sin (\frac{π x}{c})$ As shown here: https://www.desmos.com/calculator/gshaw6pqar Could this polynomial give me the arc length say from $x=0$ to $x=c$ on that graph? If so, how do I implement it? Alternatively, are there any good or easy to implement other polynomial solutions for this problem?","['trigonometry', 'arc-length', 'polynomials']"
3642557,"If $x+y^3,x^2+y^2,x^3+y$ are all integers, are $x,y$ both integers?","Let $x,y$ be both real numbers. If $x+y^3,x^2+y^2,x^3+y$ are integers, are $x,y$ both integers? This question begins with two real numbers while usual number theory tricks are based on the precondition that the variables are integers. Showing $x,y$ are algebraic numbers is easy by observing $x+((x^3+y)−x^3)^3$ is an integer, but how can algebraic numbers help?","['number-theory', 'algebraic-number-theory', 'polynomials', 'elementary-number-theory']"
3642599,"If a matrix is positive-semidefinite, is Hermitian, and has a trace of 1, is it idempotent?","I have a matrix $A^{n\times n}$ that is positive semi-def. and Hermitian. Also, $Tr(A) = 1$ . I want to show that $A$ is idempotent. Are these properties enough? If so, how would one show this? If not, what else might I need? Thanks!","['positive-semidefinite', 'idempotents', 'matrices', 'hermitian-matrices', 'linear-algebra']"
3642650,"How many isosceles, right-angled, INSCRIBED triangles exist in an ellipse?","Are there more than four isosceles, right-angled, INSCRIBED triangles in an ellipse? 
By inscribed, I mean all three vertexes should lie ON the ellipse. I am attaching a simplified picture that shows my count of four such triangle. 
Two of them form the only inscribed square of an ellipse in the middle. 
The other two would exist at each end. Are there any proof or studies showing that these are the only four, or are there more? *Edit: As Deepak pointed, when I said four, I was not careful. If you draw the diagonal line in the inscribed square the other way, you can also have two others. To give you a better idea, I'm specifically wondering whether there are isosceles right angled inscribed triangles at different locations entirely, as is shown in my supplementary diagram that has a question mark. Note that in that diagram, I'm using a FAKE isosceles triangle (the two sides are not actually of same lengths), as I cannot find a true isosceles triangle. But I'm wondering whether a real one exists that looks similar to what is drawn.","['euclidean-geometry', 'triangles', 'geometry']"
3642655,"Evaluate $\iiint_V \sqrt{x^2+y^2+z^2}\, dV$ where $V: x^2 + y^2 + z^2 \leq 2z$","Evaluate $$I=\iiint_V \sqrt{x^2+y^2+z^2}\, dV\,,$$ where $V: x^2 + y^2 +
z^2 \leq 2z$ . I tried using the cylindrical coordinates to arrive at: $$I = \int\int_R\int_{z=1-\sqrt{1-r^2}}^{1+\sqrt{1-r^2}}r\cdot\sqrt{r^2+z^2}\,dz\,dr\,d\theta$$ where $R = r \leq 1$ But this is very tough to evaluate. Is there a better way to do this?","['multivariable-calculus', 'multiple-integral', 'stokes-theorem']"
3642671,Question about Euler's Method and the SIR epidemic model using a spreadsheet,"I am creating a spreadsheet to figure out how to correctly use Euler's Method with the SIR Model for Spread of Disease. I took a random question from the text Calculus in Context by Callahan and Hoffman. Given that $S(t)$ is the number of susceptible individuals, $I(t)$ is the number of infected individuals, and $R(t)$ is the number of recovered individuals, I am using the following differential equations: $\frac{dS}{dt} = -bSI$ $\frac{dI}{dt} = bSI-kI$ $\frac{dR}{dt} = kI$ So, with Euler's method, I used the following idea to get each successive iteration: $S_{new}=S-(bSI)\Delta t$ $I_{new}=I+(bSI-kI)\Delta t$ $R_{new}=R+(kI)\Delta t$ The particular problem I am working with has the following initial condition: $S(0)=35,400$ $I(0)=13,500$ $R(0)=22,100$ Also, the text set $b = 0.00001$ and $k=0.08$ . I made $\Delta t = 1$ to calculate $S$ , $I$ , and $R$ each day. Here is a screenshot of the spreadsheet showing my results for the first 10 days: Screenshot of the first 10 days Here is what I have entered in the cells Note that $b$ is stored as 0.00001, $k$ is stored as 0.08, and $t$ is the $\Delta t$ , which is stored as 1. In cell B3 I have entered: =B2-b*B2*C2*t In cell C3, I have entered: =C2+(b*B2*C2-k*C2)*t In cell D3, I have entered: D2+k*C2*t For the rest of the cells up to 40 days, I just dragged down the same formulas. So, for B4, C4, and D4, for example, it would be the identical formulas I listed above except with B3, C3 and D3 inside. I am first making sure I have the right idea and am not totally missing something crucial. I am also very interested in relating this to the COVID-19. Correct me if I'm wrong, but I believe $k$ is 1/(average period of infectiousness). I am still confused about how to estimate a $b$ value. I'd like to relate this to the US population, but, if that is too big, maybe another specific state or city. If someone could help me a bit with this piece, that would be great!","['calculus', 'ordinary-differential-equations']"
3642725,Geometry Problem on $\triangle ABC$ and Angle Chasing,"$\triangle ABC$ is an isosceles triangle with $AB=BC$ and $\angle ABD=60^{\circ}$ , $\angle DBC=20^{\circ}$ and $\angle DCB=10^{\circ}$ . Find $\angle BDA$ . My approach: Let $\angle BDA=x$ . Let $AB=BC=p$ . Applying sine law in $\triangle ADB$ , $\dfrac{p}{\sin x}=\dfrac{BD}{\sin (60+x)}$ . Applying sine law in $\triangle BDC$ , $\dfrac{p}{\sin150^{\circ}}=\dfrac{BD}{\sin 10^{\circ}}$ . Using the two equations, we get $\dfrac{1}{2\sin 10^\circ}=\dfrac{\sin x}{\sin (60^\circ +x)} \implies 2\sin 10^\circ=\dfrac{\sqrt{3}}{2}\cot x + \dfrac{1}{2} \\ \implies x = \text{arccot} \left(\dfrac{4\sin 10^\circ-1}{\sqrt{3}}\right)$ . Now I am stuck. I know that the answer is $100^\circ$ but no matter how hard I try I cannot seem to simplify it any further. Please help. If anybody has a better solution (involving simple Euclidean Geometry), I would be grateful if you provide it too. Edit: I am extremely sorry. The original problem was when $AB=BC$ . Sorry for the inconvenience caused. I have rectified my mistake. Also, I have changed the answer to $100 ^\circ$ .","['euclidean-geometry', 'trigonometry', 'triangles']"
