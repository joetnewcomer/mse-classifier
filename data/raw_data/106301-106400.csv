question_id,title,body,tags
1510767,$T$ is surjective if and only if the adjoint $T^*$ is an isomorphism (onto its image),"I am trying to prove the following statements: 
Let $X$ and $Y$ be normed spaces (not necessarily complete)
Let $T\in L(X,Y)$  (meaning $T:X\to Y$ is a bounded linear map). Let $T^*:Y^*\to X^*$ denote the adjoint operator. Then: $T^*$ is sujective if and only if $T$ is an isomorphism; $T$ is surjective if and only of $T^*$ is an isomorphism. Here an ""isomorphism"" $X\to Y$ is an injective linear operator $T:X\to Y$ such that there exists $c_1,c_2>0$ with $$c_1\|x\|\leq \|Tx\|\leq c_2\|x\| \text{ for all } x\in X.$$
In particular we do not require $T$ to be surjective. Discussion I have proved statement 1. and I have also proved that if $T^*$ is an isomorphism then $T$ is surjective, and that if $T$ is surjective then $T^*$ is injective. An ideal next step would be to show that $Image(T^*)$ is closed in $X^*$, at which point I could apply the open mapping theorem to conclude that $T^*$ is an isomorphism (since I already know $T^*$ is a bounded operator). However, I am struggling to show that the image of $T^*$ is closed. Any ideas would be appreciated.","['adjoint-operators', 'functional-analysis', 'normed-spaces']"
1510769,"Difference between epimorphism, isomorphism, endomorphism and automorphism (with examples)","Can somebody please explain me the difference between linear transformations such as epimorphism, isomorphism, endomorphism or automorphism? I would appreciate if somebody can explain the idea with examples or guide to some good source to clear the concept.",['linear-algebra']
1510782,Every $\sigma$ finite measure is absolutely continuous with respect to a finite measure.,"Let $\mu$ be a $\sigma$- finite measure on $(X,M)$. Prove that there exists a finite measure $\lambda$ on $M$ such that $\lambda\ll\mu$ and $\mu\ll\lambda$. Can anyone give me a hint on how to start on this problem?","['real-analysis', 'measure-theory']"
1510786,How to show that $x_{n+1} = \frac{1}{3}(2 x_n + \frac{a}{x_n^2})$ has an upper bound?,Let $x_n>0$ and $x_{n+1} = \frac{1}{3}(2 x_n + \frac{a}{x_n^2})$. We need to compute the $\lim_{n \to \infty} x_n $. My solution: suppose that the limit exists. Then we have $\lim_{n \to \infty} x_n = a^{1/3}$ by taking limits in both sides of $x_{n+1} = \frac{1}{3}(2 x_n + \frac{a}{x_n^2})$. Now we need to show that the limit exists. We have $x_{n+1} - x_n = \frac{1}{3}(-x_n + \frac{a}{x_n^2}) \geq 0$ if  $0 < x_n \leq a^{1/3}$. Therefore we only need to show that $0 < x_n \leq a^{1/3}$. But I have some difficulty in showing that $0 < x_n \leq a^{1/3}$. How to show that $0 < x_n \leq a^{1/3}$? Thank you very much.,"['calculus', 'limits']"
1510793,"Is the set $\big\{(x,y) : x^2 + y^2 \leq 1\big\}$ compact in $\left(\mathbb{R}^2,\sigma\right)$?","Define $\sigma$ by $$\sigma \big( \left( x_1,y_1\right) ,\left( x_2,y_2\right) \big) =
  \begin{cases} 
      \hfill \big|{y_1 - y_2}\big|  \hfill & \text{ if $x_1 = x_2$} \\
      \hfill \big|{x_1 - x_2}\big| + \big|y_1\big|+\big|y_2\big| \hfill & \text{ if $x_1 \neq x_2$} \\
  \end{cases}
$$ I've already proved that $\sigma$ is a metric.  I've played around trying to sketch $B_\sigma \big(\left(0,0\right),1\big)$ and have come to the conclusion that it is a square rotated 45 degrees and not containing the edges.  It's vertices are at $(0,1), (0,-1), (-1,0), (1,0)$ and it is fully contained within the unit circle. e.g. $\big<\big>$ if the ""lines"" were dotted. Unfortunately, this has yet to produce an epiphany.","['real-analysis', 'general-topology']"
1510802,Prove that if $n$ is composite then there are integers $a$ and $b$ s.t. $n \mid ab$ but $n \nmid a$ or $n \nmid b$,"I tried proving the above statement, but I am not sure if it is completely right - especially towards the end. Proof : Let $n$ be composite, then by definition we have $n=ab$ for some non-zero integers $a$ and $b$ with $a,b \neq \pm 1,\pm n$. Clearly, $n \mid ab$. Let if possible, $n \mid a$. Then $\exists$ a non-zero $k \in \mathbb{Z}$ s.t. $a=kn$. Then, $n=ab=knb \implies 1=kb$, which is a contradiction since the product of two non-zero integers $k, b$ s.t. $b \neq \pm 1$ cannot be equal to $1$. Hence, $n \nmid a$. Similarly, $n \nmid b$. Hence proved. I have assumed $a,b \neq 0$ because $n=ab$ is composite. Please, let me know if it fine. Thanks.","['number-theory', 'integers']"
1510844,"If $X$ is separable, then $\mathcal{F}(X)$ is also separable, where $\mathcal{F}(X) = \overline{span \{ \delta_x : x \in X \}}$","Suppose $X$ is a Banach space. For any $x \in X$, define the set $\mathcal{F}(X) = \overline{span \{ \delta_x : x \in X \}}$ where $\delta_x(f)=f(x)$ for all $f \in$ Lip$_0(X)$. The set Lip$_0(X)$ is the set of all real-valued Lipschitz functions which vanish at $0$. Note that $\delta_x$ is an evaluation functional on Lip$_0(X)$. I am wondering whether the following statement is true or not. If $X$ is separable, then $\mathcal{F}(X)$ is also separable. The statement above is taken from here , so I believe the statement is true. But I have no idea on how to prove it. UPDATE: The following is my attempt: Take the set $\{ \delta_x : x \in X \}$ with the norm $\| \delta_x \| = \| x \|$. Note that $\{ \delta_x : x \in X \}$ is isometric to $X$. Hence, $\mathcal{F}(X)$ is separable. Is it correct?","['banach-spaces', 'functional-analysis']"
1510851,"Directed graph, partition","Let $D=(V,E)$ be a finite directed graph with no isolated nodes(from every node there is at least one edge entering and one exiting, i.e there are no sources or sinks). For $v \in V$ define the following sets: $$v^+= \left\{w \in V|(v,w)\in E \right\}, v^-= \left\{w \in V|(w,v)\in E \right\}$$ For some $S \subseteq V, S^+= \bigcup_{v \in S} v^+, S^-= \bigcup_{v \in S} v^-$ Now define two related graphs, $G_{cp}=(V,E_{cp}),G_{ce}=(V,E_{ce})$ such that for two distinct nodes $v,w \in V$ we have $vw \in E_{cp}$ iff $v^+ \cap w^+ \neq \emptyset$  and $vw \in E_{ce}$ iff  $v^- \cap w^- \neq \emptyset$ Let $B_1,B_2,...,B_p$ be the sets of nodes of the connected components of $G_{cp}$ and $A_1,A_2,...,A_k$ be the set of connected components of $G_{ce}$. Obviously those sets are two partitions of $V$ Prove that $(B^+_1,B^+_2,...,B^+_p)$ and $(A^-_1,A^-_2,...,A^-_k)$ represent partitions of $V$. Also prove that $p=k$ (that is both graphs have the same number of connected components). To prove the first part I thought about taking some arbitrary $v \in V$ and than proving that $v$ is in $(B^+_1,B^+_2,...,B^+_p)$. Then a proof by contradiction may be required to complete the first part, but I can't quite seem to make the connection. I don't even know how to start proving $p=k$ Additional note The notation cp and ce comes from ""common prey"" and ""common enemy"" Update I managed to sketch a proof for the first part along the lines I talked about. Proof by contradiction works. I still need help in proving $p=k$","['graph-theory', 'discrete-mathematics']"
1510877,What does this 'L' and upside down 'L' symbol mean?,I need help finding out what the following symbols are called and what they do. I searched up math symbols but couldn't find them anywhere near there. $$\lceil{-3.14}\rceil=$$ $$\lfloor{-3.14}\rfloor=$$,"['ceiling-and-floor-functions', 'notation', 'discrete-mathematics']"
1510961,What is the Mathematics behind the folding an A4 sheet in 3 equal parts?? [duplicate],"This question already has answers here : How can a piece of A4 paper be folded in exactly three equal parts? (13 answers) Closed 8 years ago . This is an extension question of this question . They have given a plenty nice way to fold a A4 sheet in 3 equal parts. What is the Mathematics behind the foldings? Can we use the same way for $A5,A6,\ldots$?","['geometry', 'recreational-mathematics']"
1510983,Does a small perturbation of an orthonormal basis create strongly linearly independent vectors?,"Let $e_1, e_2, \ldots$ be an orthonormal base in the separable Hilbert space $\mathcal{H}.$ Let $\psi_1^n, \psi_2^n, \ldots \in \mathcal{H}, n\in \mathbb{N}$ be vectors such that $\sup_{i} \| \psi_i^{n}-e_i \|\to 0$ when $n\to \infty.$ My question: Is there exists $N$ such that for any $n>N$ vectors $\psi_1^n, \psi_2^n, \ldots$ are strongly linearly independent (i. e. $\sum_{i=1}^{\infty} a_i \psi_i^n=0, n>N$ only if $a_i=0, i=1,2,\ldots$) and span $\mathcal{H}$ (i. e. $\overline{Lin}\{ \psi_1^n, \psi_2^n, \ldots \}=\mathcal{H}$ for $n>N$). Comment: This is true for finite dimension but I don't know what happens in infinite dimension.","['orthonormal', 'hilbert-spaces', 'functional-analysis']"
1510987,Calculus mapping and proof,"Not sure where to go with this question, any help would be appreciated. QUESTION Let X:={1,2}. Find a map f:X→X and subsets A and B of X such that f(A∩B)≠ f(A)∩f(B). ATTEMPT I've proven that f(AnB)= f(A)nf(B) if f is injective, but I'm not sure if this helps.","['calculus', 'functions']"
1510993,Proof of Equicontinuous,"I have a question about equicontinuous Let $k(x,y)$ be a fixed function of two variables, and continuous on the square $[0,1] \times [0,1]$ , and let $T$ be a bounded linear operator from $L^2[0,1]$ into itself, defined by $$ Tf(x)  = \int_0^1 k(x,y)f(y)dy.$$ How to prove that if $(f_n)$ satisfies $\left( \int_0^1 \lvert f \rvert^2 \right)^\frac12 \leq 1$ for all $n = 1,2,\dots$ then the set $(Tf_n)$ is equicontinuos. This is my idea Let $\varepsilon$ be given. Choose $\delta=...~~~~~~~~~$. Let $x,y\in [0,1]$ such that $|x-y|\leq\delta$. Then
  \begin{align*}
|Tf_n(x)-Tf_n(y)|&=\left|\int_0^1 k(x,t)f(t)dt-\int_0^1 k(y,t)f(t)dt\right|\\
&\leq \int_0^1 |k(x,t)-k(y,t)||f(t)| dt
\end{align*} I have no idea to estimate $ |Tf_n(x)-Tf_n(y)| $. Please give me some suggestions.","['analysis', 'real-analysis', 'functional-analysis', 'functions']"
1510999,How to write down proof that if $\lim_{x\to \infty}f(x)=\alpha$ then $\lim_{x\to \infty}f'(x)=0$?,"Let $a, \alpha \in \Bbb{R}$; let $f: (a,+\infty)\to \mathbb{R}$ be differentiable; let $\lim_{x\to \infty}f(x)=\alpha$; let $\beta := \lim_{x\to \infty}f'(x)$. I want to show that $\beta = 0$. Now, the idea is quite clear to me. If $\lim_{x\to \infty}f(x)=\alpha$ then there is one horizontal assymptote and thus $f$ will get closer to it as $x$ grows. In that case, since it is horizontal, the derivative of $f$ should vanish. Although the idea is clear I'm not being able to write down this proof. I've tried by contradiction: suppose $\beta > 0$ first. Then since $\lim_{x\to \infty}f(x)=\alpha$, given $\epsilon > 0$ we have $|f(x)-\alpha|<\epsilon$ as long as $x > M$ for some suitable $M\in \mathbb{R}$, $M > 0$. Now, if we pick $x > M$ and focus on the interval $(M,x)$ there should be $c$, by the mean value theorem, such that $$f'(c) = \dfrac{f(x)-f(M)}{x-M}.$$ In this way I can introduce the derivative there, but it is computed at a fixed point. Of course if I vary $x$ the $c$ would vary and I believe I could get a contradiction from this, but I'm not finding how to do this properly. So how can I write down this idea for this proof? How can I get one contradiction from this?","['infinity', 'limits', 'real-analysis', 'proof-writing', 'derivatives']"
1511008,Find all twice-differentiable functions,"Find all twice- differentiable functions $f$ such that the
average value of $f$ on each closed subinterval of $[a,b],$ $a < b,$ is the
mean of $f$ at the endpoints of the subinterval. Please give me a hint how to start.","['calculus', 'derivatives']"
1511021,Finding angle in a given triangle.,"In the picture above: $\overset{\Delta}{ACD}$ is a triangle. $B$ is a point on $[CD]$. $m(\widehat{ABC})=140^\circ$ $|AB|=|BC|$. $|AC|=|BD|$. What is $\color{red}{m(\widehat{ADB})}$? There is probably a short answer, but i can't find it. [Answer is $\color{red}{30^\circ}$.]","['geometry', 'triangles']"
1511031,Why do we consider Borel sets instead of (Lebesgue) measurable sets?,"Dumb/ Challenging conventional wisdom question possibly related to my previous question . Why do we sometimes consider a measure space $(S, \Sigma, \mu) = (\mathbb{R}, \mathscr{B}(\mathbb{R}), \lambda)$ where $\lambda$ is Lebesgue measure rather than $(S, \Sigma, \mu) = (\mathbb{R}, \mathscr{M}(\mathbb{R}), \lambda)$ where $\mathscr{M}(\mathbb{R})$ is the set of $\lambda$ -measurable subsets of $\mathbb{R}$ ? I mean, there are subsets of $\mathbb{R}$ that are not Borel sets but $\lambda$ -measurable right ? If there are none, I guess that answers the first question. Possibly answered by above but why, in my previous question , is it 'natural' to consider $\mathscr{F}$ ? I'm guessing it's like why it's 'natural' to consider $\mathscr{B}(\mathbb{R})$ . Possibly related: Why do probabilists take random variables to be Borel (and not Lebesgue) measurable?","['probability-theory', 'lebesgue-measure', 'measure-theory', 'real-analysis', 'borel-sets']"
1511051,Confused about fair coins?,"Bob and Alice play with a coin.
Together they have thrown $30$ heads and $70$ tails. Bob says the coin is not fair.
Alice disagrees and proposes to keep tossing.
They toss another $100$ times and end Up with $100$ heads and $100$ tails. Bob admits he is surprised but argues about the fairness anyway.
He says there are $2^{200}$ possible outcomes and $\binom {200}{100} $ of them are $100$ heads and $100$ tails.
So the probability that you are correct in claiming it has a probability of heads over tails between $\frac {99}{200}$ and $\frac {101}{200}$ is very close to $A = 1 - \frac{\binom {200}{100}}{2^{200}}$. Cindy comes along , draws a Pascal triangle and points out that with a fair coin you have a probability of getting 100 heads equal to $A$.
Danny joins and claims that - because of what Cindy Said - it works in reverse too , if your probability is $A$ then your coin must be fair. Emmet joins the discussion and says Danny is wrong , because he does not take into account the unfair coins. Who is right , who is wrong ?
What is the truth ? 
What are the probabilities ?
How certain are we that the coin is fair ?","['probability', 'combinatorics']"
1511056,Affine transformations - the meaning of contractivity,"An affine transformation $\omega \colon \mathbb{R}^2 \to \mathbb{R}^2$ is a linear mapping followed by a translation, in other words
$$
\omega(x) = Ax+t = 
\begin{pmatrix}
a & b \\ c & d
\end{pmatrix}
\begin{pmatrix}
x_1 \\ x_2
\end{pmatrix}
+
\begin{pmatrix}
e \\ f
\end{pmatrix}.
$$ In general case, it is contractive (in terms of Euclidean metric) when the following is satisfied for some fixed $0 \le s < 1$
$$
\forall x,y \in \mathbb{R}^2 \quad d(\omega(x),\omega(y)) \le s \cdot d(x,y). 
$$ Now according to ""Fractals everywhere"" by M.F.Barnsley (exercise III.6.4) apparently under the assumption $\det(A-I) \neq 0$ all this holds if the operator norm $|A| \le s <1$. Why is this assumption needed? Can't we have a contractive mapping whose fixed point $x_f = (I-A)^{-1}t$ is, like, at infinity? Another source provides the following conditions
$$
a^2+c^2 < 1; \\ 
b^2+d^2 < 1; \\ 
a^2+b^2+c^2+d^2 - (ad-bc)(ad-bc) < 1;
$$
but what's the meaning of these conditions? And is the inequality $\det(A-I) \neq 0$ automatically enforced in this case?","['geometry', 'linear-algebra', 'affine-geometry', 'matrices']"
1511074,Is $x_k=\sin(k)$ eventually/periodic?,A sequence is eventually periodic if we can drop a finite number of terms from the beginning and make it periodic. $$x_k=\sin(k)$$ I think this is periodic since the function is periodic and it seems to converge to 0 by iterations. The thing that confused me is that there are infinite numbers in the domain in the period of $\sin(k)$ since it's continuous. So I can't really assume that if a function is periodic -> sequence is periodic?,"['analysis', 'sequences-and-series', 'periodic-functions', 'trigonometry']"
1511090,$E(X_n)=E(X_{n-1})=\ldots=E(X_0)\nRightarrow (X_n)_n$ is Martingale,I am searching for an example of an adapted process $(X_n)_n$ with constant expected value which is not an martingale (I know that the reverse direction holds),"['probability-theory', 'martingales', 'examples-counterexamples', 'expectation']"
1511096,"""Nested"" Binomial Distribution","I am currently working with a statistical distribution, and I'm wondering if any exploration has been done on this. The distribution is denoted $\xi$. To construct $\xi$ we use auxillary random variables $X_1,X_2, \ldots, X_k$ For indexing purposes we let the random variable $X_1 = 1$ $X_2 \sim \mathrm{Bin}(4, \frac{1}{2})$ $X_3 \sim \mathrm{Bin}(4X_2, \frac{1}{2})$ and in general $X_k \sim \mathrm{Bin}(4X_{k-1}, \frac{1}{2})$ So that the number of trials of the binomial distribution is itself a random variable. One can show that the sum of $P(X_k = 0)$ over all $k$ is about $0.08737$. The distribution $\xi$ is given by $P(\xi=k) := \dfrac{P(X_{k+1} = 0) - P(X_k = 0)}{0.08737}$ (we divide because probabilities have to add up to $1$).","['statistics', 'probability-distributions']"
1511112,Test if point is in convex hull of $n$ points,"I have $n$ points $x_1,\dots,x_n\in\Bbb R^d$, and I would like to check that some other point $y$ lies in their convex hull. How can I do this in some efficient way? I think that there was an algorithm based on checking the signs of pairwise inner products $x_i\cdot y$, however I was not able to find it.","['convex-hulls', 'geometry', 'convex-analysis', 'computational-geometry']"
1511123,How to integrate this ODE?,"How to solve the following ODE:
$$ y'(x)=\sqrt{\dfrac{1-x+y}{2x+y}}. $$ I tried to transform it to a homogeneous differential equation, I found
$$ s'(x)=\sqrt{\dfrac{s-1}{s+2}}-s$$ where $$ s(x) = \frac{2y(x)+3}{2x-1}.$$
Next? I don't know.","['real-analysis', 'ordinary-differential-equations']"
1511153,Condition for ramification points of a projection $\pi : X \to \mathbb{P}^1 $,Let $X = \{F=0\} \subset \mathbb{P}^2$ be a projective plane curve and let $\pi : X \to \mathbb{P}^1$ be defined by $\pi [x:y:z] \to [x:y]$. I'm trying to understand why the following is true: The holomorphic map $\pi$ is ramified at $p \in X$ Iff $\frac{\partial F}{\partial z} (p)=0.$ So far I understand the case where $X$ is an affine curve in $\mathbb{C}^2$ and the map $\pi$ projects to $\mathbb{C}$. Here the same condition condition applies as i've been able to prove. A projective plane curve $X$ is locally just an affine curve so the same condition must apply but the projection here is confusing since there are two coordinates. Could someone carefully outline the argument needed here to conclude the projective case from the affine case?,"['projective-geometry', 'algebraic-geometry', 'riemann-surfaces']"
1511181,Why can't $\int_{-1}^1{\frac{dx}{x}}$ be evaluated?,"So I just saw this question on brilliant.org and found that many people argued over whether this could be evaluated. My answer was 0 because it is an odd function, but others argued that because of the vertical asymptote it can't properly be evaluated. I understand the general concept of there being 'different' infinities because functions have different rates of change. However, I find this one especially baffling because this function fits the criteria $$1)\frac{d^{2n-1}}{dx^{2n-1}}f(x)=\frac{d^{2n-1}}{dx^{2n-1}}f(-x)$$
$$2)\frac{d^{2n}}{dx^{2n}}-f(x)=\frac{d^{2n}}{dx^{2n}}f(-x)$$
 $$3) -f(x)=f(-x)$$ I know that all odd functions fit this criteria, but I'm writing this explicitly because this means that they shouldn't be different infinities at all; they start at opposite points, and go at the same rates at all times. If this integral were expressed as a series representing $\int_{-1}^0{\frac{dx}{x}}$ and $\int_{0}^1{\frac{dx}{x}}$, there would always be a pair of points that cancel out, despite both integrals approaching infinity as they get closer to 0. This makes it even more baffling, because I remember the sum of all whole numbers being -1/12 - the derivation of which required the canceling of many pairs of numbers representing the series. My question is:
How can we justify that $\int_{-1}^1{\frac{dx}{x}}$ is not integrable because of the vertical asymptote if the infinities we're dealing with are the 'same infinities' although with opposite signs?","['infinity', 'calculus', 'definite-integrals', 'sequences-and-series', 'integration']"
1511226,Show the equivalence of these definitions of independence of random variables,"Let $(\Omega, \mathscr{F}, \mathbb{P})$ be a probability space. There are two different definitions of the independence of random variables $X_1, X_2, ...$ on $(\Omega, \mathscr{F}, \mathbb{P})$: The $\sigma$-algebras $\sigma(X_1), \sigma(X_2), ...$ are independent, i.e. for distinct indices $k_1, k_2, ..., k_m$, $\sigma(X_{k_1}), \sigma(X_{k_2}), ..., \sigma(X_{k_m})$ are independent. Given Borel sets $B_1,  B_2, ... $ and distinct indices $j_1, j_2, ..., j_p$, $$\prod_{j=j_1}^{j_p} P(X_j \in B_j) = P(\bigcap_{j=j_1}^{j_p} (X_j \in B_j))$$ Why are these two definitions equivalent? What I tried: For distinct indices $k_1, k_2, ..., k_m$, $\sigma(X_{k_1}), \sigma(X_{k_2}), ..., \sigma(X_{k_m})$ are independent. $$\iff P(\bigcap_{k=k_1}^{k_m} A_k) = \prod_{k=k_1}^{k_m} P(A_k)$$ where $$A_k \in \sigma(X_k) = \{ X_k^{-1}(B_k) | B_k \in \mathscr{B} \}$$ It looks like $$P(\bigcap_{k=k_1}^{k_m} A_k) = \prod_{k=k_1}^{k_m} P(A_k)$$ is the same as $$\prod_{j=j_1}^{j_p} P(X_j \in B_j) = P(\bigcap_{j=j_1}^{j_p} (X_j \in B_j))$$ Does that end the proof? Doesn't seem very rigorous. Can I somehow let or conclude that $m = p$ and $(k_1, ..., k_m) = (j_1, ..., j_p)$?","['probability-theory', 'independence', 'proof-verification']"
1511240,Eigenvalues of reflection,"Why are the eigenvalues of a reflection $Rx=\rho x$ in a $n$ -dimensional vector space just $\lambda=-1,1$ ? I can't seem to convince myself of this.","['linear-algebra', 'linear-transformations']"
1511242,Where does $(a^2+2ab\cos(\theta)+b^2)^{p/2}+(a^2-2ab\cos(\theta)+b^2)^{p/2}$ have a Maximum?,"Consider the real-valued function $$
\phi : [0,2 \pi) \rightarrow \mathbb{R} \\
\phi (\theta)=(a^2+2ab\cos(\theta)+b^2)^{p/2}+(a^2-2ab\cos(\theta)+b^2)^{p/2}$$ for $1<p$ and $a,b \in \mathbb{R}$. Where does this function attain its maximum/minimum? Does this depend on the choice of $a,b$ and $p$? If we compute the derivative we get: $$ \phi ' (\theta) = -abp \sin(\theta)((a^2+2ab\cos(\theta)+b^2)^{p/2-1}-(a^2-2ab\cos(\theta)+b^2)^{p/2-1})$$ The derivative vanishes at $0, \frac{\pi}{2}, \pi$ and $\frac{3 \pi}{2}$. So we have to inspect: $$ \phi(0)=\phi(\pi)=(a^2+2ab+b^2)^{p/2}+(a^2-2ab+b^2)^{p/2} = ((a+b)^2)^{p/2}+((a^2-b^2)^2)^{p/2}$$ and $$ \phi(\pi /2)=\phi(3\pi /2)=(a^2+b^2)^{p/2}+(a^2+b^2)^{p/2}$$ I can't really see which of the two is the max/min. How can we see which is?","['calculus', 'derivatives']"
1511293,Must a comeager set be dense?,"Say, on a complete separable metric space.  Separable probably doesn't matter. It's easy to see the opposite; if $D$ is a dense $G_\delta$ set, it's a countable intersection of open sets which contain $D$, so must also be dense.  Consequently the complements of those sets are closed sets with no interior, so must be nowhere dense.  And so their union (the complement of $D$) must be meager, so $D$ is comeager.  Great. It's not hard to extend this logic a bit more; if $C$ is any comeager set, then there is a $C'\subset C$ where $C'$ is comeager and $G_\delta$.  But must $C'$ be dense?  Must $C$ be dense? I suppose the real question then is this: if $C\subset X$ is comeager, must $C$ be dense? (the converse definitely does not hold, see $\mathbb Q\subset\mathbb R$).  By the reduction in the previous paragraph, it's enough to consider $C$ to be $G_\delta$, but that doesn't obviously lead to density.  Does it?","['real-analysis', 'general-topology']"
1511312,A curve that will be perpendicular to all $c \sin x$,"I want to find a parametric curve that would be perpendicular to all curves $y=c \sin x$ I can see that these curves will be straight lines when $x=\frac{2n+1}2\pi$ and they should become tiny circles as $x\rightarrow n\pi$, but I do not see how I would do this mathematically or what the answer would look like. The only thing that came to my mind so far is to think of a function $F$ and equate its derivative to be $-\frac{1}{c \cos x}$ $$-\frac{\frac{\partial F}{\partial x}}{\frac{\partial F}{\partial y}}=-\frac{1}{c \cos x}$$ $$c\cos x\frac{\partial F}{\partial x}=\frac{\partial F}{\partial y}$$ A separable solution to this would be $$\exp \bigg(\frac{2 k \tanh ^{-1}\left(\tan \left(\frac{x}{2}\right)\right)}{c}+ky\bigg)$$ I want the parametric curves to be perpendicular for all $c$. But I do not know if this makes sense and how I would continue. Intuitively, I am expecting to see concentric ellipses centered at $x=n\pi$","['curves', 'multivariable-calculus']"
1511331,"$f \in C(\mathbb R^n)$ be such that for some positive integer $m$ , $\Delta^m_{i,h}f=0 $ ; then $f$ is a polynomial in $n$ variables ?","Let $f \in C(\mathbb R^n)$ be such that for some positive integer $m$ , $\Delta^m_{i,h}f=0 , \forall h \in \mathbb R , i=1,2,...,n$ ; then how to show that $f$ is a polynomial in $n$ variables ? Here $\Delta_{i,h}f(x)=f(x+he_i)-f(x),\forall x \in \mathbb R^n$ , where $e_i$ is the $i$-th standard basis vector","['polynomials', 'continuity', 'multivariable-calculus']"
1511347,"Every complete orthonormal set in a Hilbert space $H$ is an orthonormal basis, if and only if $H$ is finite dimensional.","Show that any orthonormal set in a Hilbert space $H$ is linearly independent, and use this to show that $H$ is finite dimensional if and only if every complete orthonormal set is an orthonormal basis. Attempt: Trying to show that every orthonormal set is linearly independent is easy if the set is countable, but if it weren't, I'm uncomfortable about considering uncountable sums ($\sum_{\alpha \in I} c_{\alpha}e_{\alpha} = 0$). Anyway around this? Once I show linear independence, how do prove the claim using it?","['orthonormal', 'hilbert-spaces', 'functional-analysis']"
1511375,Show how $\lim\limits_{n\to\infty}\left(\frac{n-1}{n+1}\right)^n = \frac{1}{e^2}$,"How does one evaluate this limit?
$$\lim\limits_{n\to\infty}\left(\frac{n-1}{n+1}\right)^n$$ I got to $$\lim_{n\to\infty}\exp\left(n\cdot\ln\left(\frac{n-1}{n+1}\right)\right)$$ but I'm not sure where to go from there.","['calculus', 'limits', 'exponential-function']"
1511419,Does this seemingly elementary question require König's theorem?,"Question Let $f:\;\mathbb{R}\to\mathbb{N}$ and let $X_n$ be the set of reals mapped to the integer $n$. Show that for some $n,\;X_n$ has cardinality of the continuum. This is straightforward if we use König's theorem: assuming the contrary, i.e. $\left|X_n\right|<2^{\aleph_0}$ for all $n$: $$2^{\aleph_0}=\left|\bigcup_{\mathbb{N}} X_n\right|=\sum_{\mathbb{N}}\big|X_n\big|\overset{\text{K.T.}}<\prod_{\mathbb{N}}2^{\aleph_0}=\big(2^{\aleph_0}\big)^{\aleph_0}=2^{\aleph_0}$$
a contradiction. This feels overkill, but perhaps it is not. Am I missing a more elementary solution to this problem?","['elementary-set-theory', 'cardinals']"
1511434,Why are these two definitions of differentiability identical?,"Recently, I have learned the following as the  definition of multivariable differentiability. Assume that one can express $f(x, y)$ in the following form: $$f\left(x, y\right) = f\left(x_0, y_0\right) + \frac{\partial f}{\partial x} \Delta x + \frac{\partial f}{\partial y} \Delta y + \xi \left(x, y\right) $$ Where $\xi$ can be viewed as the ""error"" function between the surface and the tangent plane. Then for $f$ to be differentiable at $\left(x_0, y_0\right)$, the following must hold true for all $\epsilon > 0$: For any $\epsilon > 0$, there exists a $\delta > 0$ such that whenever $r < \delta$, $\xi < \epsilon r$ where $r = \sqrt{\left(x - x_0 \right)^2 + \left(y - y_0\right)^2}$. In more intuitive terms, as we approach the point, $\xi$ needs to ""disappear"" faster than any linear multiple of $r$. If $\xi$ is linear in $r$, then we can say that $f$ is not differentiable (sort of analogous to a cusp in single variable calculus). This can also be stated as (I think): $$\lim_{r \rightarrow 0} \frac{\xi(x, y)}{r} = 0$$ Intuitively, this makes sense to be, because when we get ""infinitesimally"" close to the point in question, we can utilize the tangent plane to obtain the differential expression: $$\mathrm{d}f = \frac{\partial f}{\partial x} \mathrm{d}x + \frac{\partial f}{\partial y} \mathrm{d}y$$ But in the textbook I am using, differentiability is defined as follows: $f(x, y)$ is differentiable at $(x_0, y_0)$ if we can express $\Delta f$ in the following manner: $$\Delta f = \frac{\partial f}{\partial x} \Delta x + \frac{\partial f}{\partial y} \Delta y + \epsilon_1 \Delta x + \epsilon_2 \Delta y$$ where as $\Delta x \rightarrow 0$ and $\Delta y \rightarrow 0$, $\epsilon_1 \rightarrow 0$ and $\epsilon_2 \rightarrow 0$. You can view $\epsilon_1 \Delta x + \epsilon_2 \Delta y$ as the $\xi$ function mentioned in the first definition of differentiability. But I don't see how the two definitions are identical. It seems that in both of them, the ""error"" from the tangent plane is required to approach $0$ ""quickly enough,"" but I don't quite see how the two are identical.","['calculus', 'multivariable-calculus', 'definition', 'derivatives']"
1511457,Congruence and similarity of matrices/ geometry,"Given two matrices $A$ and $B$ we can tell if those two matrices are congruent, similar, or neither.  Similarly given two figures in Euclidean geometry we can tell if they are congruent, similar, or neither. Is there a relationship between these two ideas (congruence/ similarity for matrices and congruence/ similarity for geometric figures) that justifies the use of the same names?","['geometry', 'linear-algebra', 'matrices']"
1511512,Let µ be counting measure on $B_{\mathbb{R}}$. Then prove there exists no finite measure $\lambda$ on $B_{\mathbb{R}}$ such that $\mu \ll \lambda$,"My question statement is:  If we have that $\mu$ is a counting measure on $B_{\mathbb{R}}$, then prove there is no finite measure $\lambda$ on $B_{\mathbb{R}}$ such that $\mu \ll \lambda.$ We know that the measure of any finite set is the number of elements in the set, and the measure of any infinite set is then infinity.  So this measure is not $\sigma-$finite.  I'm not sure how else to proceed and am curious if someone could provide me with assistance.","['real-analysis', 'measure-theory']"
1511532,Finite open covers of a complex $C^{(1)}$ curve.,"Consider a complex curve $\gamma \subset \mathbb{C}$, parametrized by $\alpha: [a,b]\to \mathbb{C}$, with $\alpha \in C^{(1)}$. Further, consider an finite open cover $\Phi$ of $\gamma=\alpha([a,b])$. Such cover exists by compactness and continuity. I want to show that we can find a $\textbf{finite}$ partition $a=t_0<t_1<\dots<t_n=b$ such that, for each $k\in\{1,\dots,n\}$, there exists $V\in \Phi$ with $\alpha \left ( [t_{k-1},t_k]\right ) \subset V$. Intuitively, this seems obvious, but I can't seem to come up with a rigorous proof (or a counterexample). My best effort is as follows: Since $\Phi$ is a cover of $\gamma$, $\alpha(a)$ belongs to some member of $\Phi$, call it $V_1$. If $\gamma \subset V_1$, then we are done. Suppose then that: $$\{ t\in [a,b] : \alpha(t)\not \in V_1 \}\neq \emptyset$$ Since $\alpha$ is continuous and $V$ is open, the LHS is closed  (and bounded), hence compact, and thus contains a minimum element, say $t_1$, with $a<t_1$. Again, since $\Phi$ is a cover of $\gamma$, $\alpha(t_1)$ belongs to some member of $\Phi$ (different from $V_1$), say $V_2$. We repeat the argument to find $t_2 = \min\{ t\in [t_1,b] : \alpha(t)\not \in V_2 \}$, with $t_2 > t_1$. At each step, if the sets so far considered are already a cover for $\gamma$, we are done (alternatively, to avoid this we could suppose that $\Phi$ a minimal cover, which exists by finiteness). We can obviously continue this way to find $t_1<t_2<t_3,\dots$, but does the process end in a finite number of steps, where the final $t_n$ found is $b$? My objection to the past construction is that the relative lengths of the intervals $[t_{k-1},t_k]$ could become arbitrarily small, and hence we might never ""reach"" the endpoint $b$, ala Zeno's paradox. I imagine that I'm missing something related to the compactness of the sets which are involved. Further, the fact that the curve is of class $C^{(1)}$ has not been used yet, merely the continuity of the curve, so its natural to ask whether this also holds for a curve which is simply continuous, or whether I need this additional hypothesis to complete the curve. If anyone could either help me finish with my method, or provide me with an alternative argument for the existence of the desired partition, I would be extremely grateful. Also, would anything changed if we restricted the members of $\Phi$ to be open disks? Note : I realize the title is rather vague, but I couldn't come up with something more specific (and short), so I'm open for suggestions.","['plane-curves', 'complex-analysis']"
1511560,Contraction operator,"In a proof of Picard's theorem using the contraction mapping theorem, we define an operator $T$ which is applied to a function $y$. I don't really see below how $Ty$ is any different from $y$ as the RHS for both are the same. Could someone please explain how they are different?","['metric-spaces', 'integral-operators', 'operator-theory', 'ordinary-differential-equations']"
1511567,Solve the differential equation $\frac{dy}{dx}=\frac{2x+y}{y}$,"Solve
$$\frac{dy}{dx}=\frac{2x+y}{y}$$ Let
$$\frac{dx}{dt}=y \\ \frac{dy}{dt}=2x+y$$ Plugin $\frac{dx}{dt}=y$ into $\frac{dy}{dt}=2x+y$ I get $$2x+\frac{dx}{dt}=\frac{dy}{dt}$$
Using the fact that $\frac{d^2x}{dt^2}=\frac{dy}{dt}$ I get the 2nd order system: $$\frac{d^2x}{dt^2}-\frac{dx}{dt}-2x=0$$ Solving this I get:
$(r-2)(r+1)=0$ , so $r=2,=1$ $$x(t)=Ae^{2t}+Be^{-1t}$$ How do I get my solution in terms of $y,x$? I can't seem to integrate $\frac{dy}{dx}$ by separating variables directly.",['ordinary-differential-equations']
1511568,If this a typo in my book: Radius of convergence of $\sum \frac{n! z^n}{n^n} $?,"Im trying to find the radius of convergence of $$\sum \frac{n! z^n}{n^n} $$ Let $a_n = \frac{n!}{n^n}$ so I know the radius of convergence $R$ is the limit of  $\lvert a_n/a_{n+1}\rvert$ which I get to be $1$. However, book says $R$ should be $e$.","['power-series', 'sequences-and-series', 'calculus']"
1511591,Statistical method to prove that variations are not important?,"I'm checking the effect a specific substance has in the elongation of the root of variousplants of the Solanum genus. I had my plants grow in soil with different concentration of hormones. My results are quite obscure from what I expected, so I'm guessing that at very low concentrations the substance doesn't have any effect. However, I did noticed a small difference in length from  those samples that grew up without the substance. Is there any statistical method to prove that the variations I observe are not important?",['statistics']
1511596,Define a relation and find its equivalence classes.,"Define a relation $\sim$ on $\Bbb{N}$ as follows. For any $a,b∈\Bbb N$, $a\sim b$ if and only if $ab$ is a perfect square. Show that $\sim$ is an equivalence relation. What are the equivalence classes? So far I have $a\sim a$ so $\sim$ is reflexive, $ab\sim ba$ $\sim$ is symmetric, $ab=x^2$ and $bc=y^2$ prove $ac$ is a perfect square so $$ac =\frac{ab\cdot bc}{b\cdot b} = \frac{x^2\cdot y^2}{b^2} = \left(\frac{xy}{b}\right)^2$$ Therefore ac is square, ~ is transitive and an equivalence relation.  I think you use the equation $a=b^2a'$ to find the equivalence classes but I don't know how.","['elementary-set-theory', 'equivalence-relations', 'relations']"
1511622,"What does it mean to ""marginalise out"" something?","Especially in machine learning one often reads the phrase ""to marginalise out"" something, and while I understand that this means to integrate over a property, I cannot quite grasp the larger significance. For example $z$ is unobserved, so its needs to be ""marginalised out"" to compute the likelihood of the parameters. I.e. $p_{\theta}(y) = \int p_{\theta}(y,z)dz$. Where $y$ is an observed variable, and $\theta$ parametrised the joint distribution. I suppose I am simply wondering why we need to marginalise out something at all, and why we call it marginalisation? Are we trying to change the dependency of the problem on as few variables as possible?","['statistics', 'markov-chains', 'machine-learning']"
1511626,Examples of geometric structures on real manifold that lead to almost complex structure,"I have a $M^{2n}$ real manifold. I am interested, if there are any well known geometric structures on manifold that lead in some natural manner to almost complex structure on $M.$ I read on wiki about compatible triples and I think one example would be triple $(M,\omega,g)$ consisting of symplectic form $\omega$ and metric tensor $g,$ such that $$g(X,Y)=\omega(X,(i_Y\omega)^\sharp)$$ for all vector fields $X,Y.$ We can define then an almost complex structure $J$ as follows:
$$J(X)=(i_X\omega)^\sharp.$$ I am looking for this type of examples. Btw. I am aware that there is an almost complex structure derived from complex manifold. Edit. After Jack's comment I added compatibility condition $g(X,Y)=\omega(X,(i_Y\omega)^\sharp).$ Edit. Almost cosympletic structure from Olszak's paper looks promising, but it is odd dimensional, so no chance. Maybe someone is familiar with similar structures, but on even dimensional mfd. Remark As tessellation pointed out: ""To get a global almost complex structure the only obstruction is the gluing condition which is a purely algebraic topological obstruction."" The idea however is to define almost complex structure in some natural manner to skip the middle part in below diagram $$\text{geometric structure}\implies\text{algebraic topological obstructions vanish}\implies \text{there is an almost complex structure}$$","['differential-geometry', 'smooth-manifolds', 'tensors']"
1511635,Is it known whether the possible number of prime factors of a Carmichael-number is bounded?,"Let $n(C)$ be the number of prime factors of the Carmichael-number $C$ . I Conjecture $\lim sup_{C\rightarrow \infty} n(C)=\infty$ In other words, the sequence $n(C)$ , $C$ running over the Carmichael-numbers, is unbounded. I learnt that Dickson's conjecture implies that this is the case. There are
arbitary long strictly increasing vectors $v_1,...,v_n$ ( $n\ge 3$ ) with $\sum_{j=1}^n \frac{1}{v_j}=1$ .
If $L\ :=\ lcm(v_1,...,v_n)$ , then $\prod_{j=1}^n (\frac{L^2}{x_j}\times m+1)$ is a Carmichael-number if $\frac{L^2}{x_j}\times m+1$ is prime for $j=1,...,n$ , and Dickson's conjecture implies that such a number $m$ always exists. I also learnt that it is not known, whether there are infinite many Carmichael
numbers with $k$ prime factors for any fixed number $k\ge 3$ . But maybe my conjecture can be proven (or disproven).","['prime-numbers', 'number-theory', 'pseudoprimes']"
1511636,term-by-term differentiation of function series $\frac{d}{dx}( \sum_{k=0}^{+\infty} f_{k}(x))=\sum_{k=0}^{+\infty}( \frac{d}{dx}f_{k}(x) ) $,"I wonder How do I write that equality legally? $$\frac{d}{dx}\left( \sum_{k=0}^{+\infty} f_{k}(x)\right)=\sum_{k=0}^{+\infty}\left(  \dfrac{d}{dx}f_{k}(x)  \right)  $$ indeed, In case of $f_{k}$ are power series we can under these conditions : Power Series In case of sum is finit and $f_{k}$ are différentiable we can write : $$\frac{d}{dx}\left( \sum_{k=0}^{n} f_{k}(x)\right)=\sum_{k=0}^{n}\left(  \dfrac{d}{dx}f_{k}(x)  \right)$$
In other words, the derivative of any finite sum of functions is the sum of the derivatives of those functions. Reference What is the condition which let us to write that : $$\frac{d}{dx}\left( \sum_{k=0}^{+\infty} f_{k}(x)\right)=\sum_{k=0}^{+\infty}\left(  \dfrac{d}{dx}f_{k}(x)  \right)  $$ could we use that theorem to write it also friend of mine told me that's why we were built the first continuous functions but nowhere differentiable but i didn't understand it, here is link : continuous functions but nowhere differentiable","['power-series', 'calculus', 'functions', 'sequences-and-series', 'derivatives']"
1511679,What's the probability of a future polling result falling in a given range?,"Question Each day, Gallup polls U.S. Employee Engagement. You can see 7-day rolling averages of the daily numbers here . Assume you have a set of historical daily numbers (ie, [0.354827, 0.352648, 0.34943, …] ). What would be the best technique to estimate the probability of a future number falling in a given range? As an example, I may want to say ""the probability of the number three days from now falling in the range 0.45…1 is ____%."" Initial Attempt My initial attempt counted the # of times this range condition had been met in the last 90 days, but this has a number of flaws. Most notably, the ranges 0…0.01 and 0…0.15 were equally unlikely, but obviously the former should be less likely than the latter. That is, my initial attempt didn't consider that the results tend to hover around 0.30…0.33 . Related Questions I read Continuously sampled event: Estimating the value of a future data point, based on past measurements and their tendency . The question seemed related, but not identical, and the answer was over my head. I started reading about ARIMA models , but I didn't want to get too far into the weeds without knowing if that's the right approach here.",['statistics']
1511704,Q: Find all functions that are analytic and satisfy $(\operatorname{Re}(f(z)))^2 = \operatorname{Im}(f(z))$,"I've been trying to find all functions $f(z):\Bbb{C}\longrightarrow\Bbb{C}$ that are analytic and satisfy $$(\operatorname{Re}(f(z)))^2 = \operatorname{Im}(f(z))$$ After plugging in $f(z)=x+iy$, I got $f(z)=x+ix^2$. These kind of functions never satisfy Cauchy-Riemann equations, since $\mathcal u_x=1 \neq 0=v_y$. Does it follow from this argumentation that no such analytic $f(z)$ exists?",['complex-analysis']
1511706,Using the inclusion-exclusion principle to calculate the proportion of numbers divisible by factors,"Let $m_1, ..., m_r$ be pairwise coprime numbers and $N=\prod\limits_{i=1}^r m_i$ . 
So I'm trying to calculate the proportion of the numbers 1 to N that are not divisible by any of the $m_i$, so I've used the Inclusion-Exclusion Principle,  but I have a really long expression of sums and was wondering how I can simplify it? So for the size of the set of all numbers between 1 and n not divisible by any of the $m_i$ is :
$$N-\sum_{i} N/m_i + \sum_{i<j} N/m_im_j - \sum_{i<j<k} N/m_im_jm_k \quad + ...$$
Then for the proportion just dividing through by N I got:
$$1-\sum_{i} 1/m_i + \sum_{i<j} 1/m_im_j - \sum_{i<j<k} 1/m_im_jm_k \quad + ...$$","['inclusion-exclusion', 'combinatorics']"
1511766,Inverse function of $f(x) = \frac{x+5}{x-2}$,Find the inverse of the function $f(x) = \frac{x+5}{x-2}$ Here's what I have so far: $y = \frac{x+5}{x-2}$ $x = \frac{y+5}{y-2}$ $(x)(y-2) = (y+5)$ but this seems to be a dead end. How should I approach this? Thank you!,"['polynomials', 'inverse', 'functions']"
1511779,"Eilenberg-Maclane space, when can $K(\pi, 1)$ be constructed as a compact manifold?","See here . Let $\pi$ be any group. Construct a connected CW complex $K(\pi, 1)$ such that $\pi_1(K(\pi, 1)) = \pi$ and $\pi_q(K(\pi, 1)) = 0$ for $q \neq 1$. It is rarely the case that $K(\pi, 1)$ can be constructed as a compact manifold. What is a necessary condition on $\pi$ for this to happen?","['homology-cohomology', 'abstract-algebra', 'manifolds', 'general-topology', 'algebraic-topology']"
1511790,"Power set of a finite set is finite proof, no cardinality of power set","Prove that $\mathcal{P}(A)$ of a finite set $A$ is finite. I need to prove this without using the cardinality of $\mathcal{P}(A)$. This is my attempt, which is by induction:
$\newcommand{\lbrac}[1]{\left(#1\right)}$
$\newcommand{\sett}[1]{\left\{#1\right\}}$
$\newcommand{\pset}[1]{\mathcal{P}\lbrac{#1}}$
Proof by induction over cardinality. If $A = \varnothing$, then $\pset{A} = \sett{\varnothing}$, which is finite. Suppose that for a set $A$ of cardinality $n$, $\pset{A}$ is finite. Let $A$ be a set of cardinality $n+1$. $A$ is not empty, since it is of cardinality $n+1 > 0$, and therefore pick some $x\in A$. It follows that $A = \lbrac{A-\sett{x}}\cup\sett{x}$. We claim that
$$
\pset{A} = \pset{\lbrac{A - \sett{x}}\cup\sett{x}} = \pset{A - \sett{x}}\cup\sett{C | C\in\pset{A}\wedge x\in C}
$$
Suppose $B\in\pset{A} = \pset{\lbrac{A-\sett{x}}\cup{x}}$. Then either $x\in B$ or $x\not\in B$. If $x\in B$, then $x\in B \wedge B\in\pset{A}\Rightarrow B\in C$. If $x\not\in B$ then $B\subseteq A - \sett{x}$. 
\newline
Either way, $B\in \pset{A - \sett{x}}\cup\sett{C | C\in\pset{A}\wedge x\in C}\Rightarrow \pset{A}\subseteq\pset{A - \sett{x}}\cup\sett{C | C\in\pset{A}\wedge x\in C}$. Suppose $B\in\pset{A - \sett{x}}\cup\sett{C | C\in\pset{A}\wedge x\in C}$. Then either $B\in\pset{A-\sett{x}}$ or $B\in\sett{C | C\in\pset{A}\wedge x\in C}$ (or both). If $B\in\pset{A-\sett{x}}$, then $B\subseteq(A-\sett{x})\cup\sett{x} = A$, and if $B\in\sett{C | C\in\pset{A}\wedge x\in C}$, then by definition, $B\subseteq A$. Either way, we get that $B\in\pset{A} \Rightarrow \pset{A - \sett{x}}\cup\sett{C | C\in\pset{A}\wedge x\in C} \subseteq \pset{A}$. Since we have shown both sets are contained in each other, they are equal. My goal is to now prove that $\sett{C|C\in\pset{A} \wedge x\in C}$ is finite. I didn't manage to do so without non rigorous claims that could also ""prove"" the main question. If this set is finite, and by induction hypothesis $\pset{A - \sett{x}}$ is finite, I'll be done. Any ideas on how to prove $\sett{C|C\in\pset{A} \wedge x\in C}$ is finite?",['elementary-set-theory']
1511832,When does the limit of derivatives coincide with the derivative of the limit function?,"Thinking about the (probably) well-known fallacy about approaching a unit square diagonal with staircase functions and thus concluding the diagonal length be $2$ instead of $\sqrt 2$ led me to an interesting question: Given a sequence $(f_k)_{k\in\mathbb N}$ of differentiable functions converging towards a differentiable limit function $f$, when does the limit of derivatives coincide with the derivative of the limit function, that is, when do we have $f'(x)=\lim_{k\to\infty}f_k'(x)$ for all $x$ in the function's domain? And what about second or $n$-th derivatives, supposing all the functions $f_k$ as well as $f$ are twice or $n$ times differentiable? No need to tell me staircase functions aren't differentiable - this is supposed to be a more general question about necessary and sufficient conditions for the limit of $n$-th derivatives to coincide with the $n$-th derivative of the limit.","['real-analysis', 'uniform-convergence', 'analysis', 'convergence-divergence', 'derivatives']"
1511875,How to evaluate $1234^{1234} \pmod{5379}$?,"Note: $5379 = 3 \times 11 \times 163$. I tried Chinese Remainder Theorem and Fermat's Little Theorem, got as far as:
$$
1234^{1234} = 1 \pmod{3} \\
1234^{1234} = 5 \pmod{11}
$$
With a bit more work:
$$1234^{1234} = 93^{100} \pmod{163}$$ But $93^{100}$ doesn't really help? WolframAlpha tells me that $\phi(5379)=3240>1234$
So I can't use Euler's Theorem? N.B This appeared on a 1st year undergrad problem sheet. So presumably, not too much technology is required.","['number-theory', 'modular-arithmetic']"
1511886,Likelihood ratio as Radon-Nikodym derivative,"I have a question regarding Exercise 6.11, displayed above. We assume that $\mathbb{P}^{X}(E):=\mathbb{P}(X \in E)$ for $E\in\mathcal{B}^n$. I wanted to prove that last assertion and, by doing the computations backwards, I arrive at
\begin{align*}
\frac{f(X(\omega))}{g(X(\omega))}
&=\left(\frac{f}{g}\right)(X(\omega)) \\
&=\frac{\text{d}\mathbb{P}^X}{\text{d}\mathbb{Q}^X}(X(\omega)) &\text{by 6.10, as $g>0$}\\
&\overset{?}{=}\frac{\text{d}\mathbb{P}}{\text{d}\mathbb{Q}}(\omega).
\end{align*}
But I am not sure about the last step; it seems a little shaky. For every Borel-set $E$, we have that
$$
\mathbb{P}^X(E) = \mathbb{P}(X \in E) = \mathbb{P}\left(X^{-1}(E)\right),
$$
so, when $X$ is invertible, we have that
$$
\mathbb{P}^X = \mathbb{P} \circ X^{-1},
$$
and hence, by associativity of composition, we have 
$$
\mathbb{P}^X \circ X= \left(\mathbb{P} \circ X^{-1}\right) \circ X= \mathbb{P} \circ \left(X^{-1} \circ X\right)=\mathbb{P},
$$
so I believe the 'shaky step' is justified for invertible $X$ (as the same goes for $\mathbb{Q}$), but I do not see why it should hold for every measurable $X$. Can anyone help me with that? Many thanks in advance!",['measure-theory']
1511897,Does the Fourier transform of a smooth $L^2$ function decay rapidly at infinity,"For $L^1$ functions, there is a correspondence through the Fourier Transform between functions which are smooth and functions which decay rapidly at infinity. More precisely, if $f$ is a smooth $L^1$ function, $\hat{f}$ is an $L^\infty$ function which decays faster than any polynomial at infinity, and conversely, if $g$ is an $L^\infty$ function which decays faster than any polynomial at infinity, then the inverse fourier transform of $g$ is $L^1$ and smooth. For $L^2$ functions, there is a difficulty. The Fourier transform formula is no longer valid on individual functions. It only is defined on the $L^2$ classes of functions. I have two questions: Is there a standard way to extend ""decays rapidly at infinity"" to $L^2$ classes of functions? Assuming (1), is there a 1-1 correspondence between classes of $L^2$ functions with a smooth representative and classes of $L^2$ functions which decay rapidly at infinity?","['fourier-analysis', 'real-analysis', 'functional-analysis']"
1511969,to prove $(R\circ S)^*\circ R = R\circ (S\circ R)^*$,"For 2 relations $R$ and $S$, need to prove is (1) $(R \circ S)^n \circ R = R\circ (S\circ R)^n$ for all $n \ge 0$ (2) $(R\circ S)^*\circ R = R\circ (S\circ R)^*$ My Work: I was able to prove (1) using Induction. Tried (2) as below:- As $(R\circ S)^*\circ R =   \bigcup\limits_{n=0}^\infty (R \circ S)^n \circ R$ So proof reduces to $(R \circ S)^n \circ R= R\circ (S\circ R)^*$ Now using the (1) $R\circ (S\circ R)^n$ From here how do I conclude that it is $= R\circ (S\circ R)^*$","['relations', 'discrete-mathematics']"
1511972,$f(x)=x^2$ is not Lipschitz?,"Consider the function $\ f:\mathbb{R}\to\mathbb{R}$ defined by $\ f(x)=x^2$ for all $x\in \mathbb{R}$. I think that $f$ is NOT Lipschitz (meaning, there exists no constant $c\in[0,\infty)$ such that $|f(x)-f(y)|\leq c |x-y|$ for all $x,y\in\mathbb{R}$). Here is my proof: Suppose that it IS Lipschitz. There there exists some constant $c\in[0,\infty)$ such that $|f(x)-f(y)|\leq c |x-y|$ for all $x,y\in\mathbb{R}$. Then: $\implies\ \ \ \ |x^2-y^2|\leq c |x-y|$ for all $x,y\in\mathbb{R}$ $\implies\ \ \ \ |x-y| \cdot |x+y|\leq c |x-y|$ for all $x,y\in\mathbb{R}$ $\implies\ \ \ \ |x+y|\leq c$ for all $x,y\in\mathbb{R}$ But there is no real number $c$ with the property that $|x+y|\leq c$ for all $x,y\in\mathbb{R}$. This is a contradiction. $f$ is not Lipschitz. Is this proof correct?","['uniform-continuity', 'lipschitz-functions', 'calculus', 'real-analysis']"
1512063,How to compute this gross limit.,"How do I compute this limit?
  $$
  \lim_{n \to \infty} 
  \frac{\left(1 + \frac{1}{n} + \frac{1}{n^2}\right)^n - 
        \left(1 + \frac{1}{n} - \frac{1}{n^2}\right)^n
  }{
       2 \left(1 + \frac{1}{n} + \frac{1}{n^2}\right)^n - 
        \left(1 + \frac{1}{n} - \frac{1}{n^2 + 1}\right)^n - 
        \left(1 + \frac{1}{n} - \frac{1}{n^2 (n^2 +1)}\right)^n
  }
$$ I think I got the correct limit by using fast converging limits to $e$.
In particular I used truncated Taylor series for the sqrt and 4th root.
Or squares and bisquares. Example $(1+1/2n)^{2n}$
 Becomes 
$(1 + 1/n + 1/4n^2)^n.$ In combination with l'hopital it gives me the answer. But I guess that is not a very good (fast) method.",['limits']
1512070,"Decide whether a relation is reflexive, symmetric, and transitive?","I have a problem to do that is similar to this: 
$R_1$  is over the set of real numbers (a) $(x, y) \in R_1$ if and only if $xy = 5$ decide whether it is reflexive, anti-reflexive, symmetric,
anti-symmetric and transitive. I'm confused, I know that reflexive means x=x and symmetric means that x,y implies y,x. I think it's the format of the question that is throwing me off. Help is very much appreciated.","['relations', 'discrete-mathematics']"
1512074,Prove $\frac{a+b}{\sqrt{c}}+\frac{a+c}{\sqrt{b}}+ \frac{b+c}{\sqrt{a}} \geq 2(\sqrt{a} + \sqrt{b} +\sqrt{c})$,"Could anyone advise me on how to prove this inequality: $$\dfrac{a+b}{\sqrt{c}}+\dfrac{a+c}{\sqrt{b}}+ \dfrac{b+c}{\sqrt{a}} \geq 2(\sqrt{a} + \sqrt{b} +\sqrt{c}),$$ where  $a,b,c $ are any positive real numbers. Do I use the AM-GM inequality somewhere? Thank you.","['algebra-precalculus', 'inequality']"
1512163,Integral of rationals,"Define $f(x)$ as
$$f(x)=\begin{cases}0,&\text{if }x\in \mathbb{Q}\\
1,&\text{if }x\notin \mathbb{Q}\;.
\end{cases}$$
Considering the fact that there is a countable infinity of rationals yet an uncountable infinity of irrationals between $0$ and $1$, can the following statement be made? If yes, why? if not, why not?
$$\int_0^1f(t) dt=1$$","['rational-numbers', 'irrational-numbers', 'integration']"
1512164,How to make a function periodic?,"I have a nice little equation here, $f\left(x\right)=\frac{4}{\pi ^2}\left(x+\frac{\pi }{2}\right)^2-1$, which ever so nicely approximates (with somewhat good accuracy), a period of the sine function, and then goes to nothingness (because it's a parabola). Using the inverse of the function I can get the other period of the sine function. How do I ""combine"" these two equations (the equation and it's inverse) to make one periodic function representing $\sin\left(x\right)$? This desmos graph may help.","['periodic-functions', 'polynomials', 'trigonometry']"
1512204,"Prove that $f$ is a group isomorphism, where $f$ interchanges the primes.","Let $G = \mathbb{Q}^{\times}$ be the multiplicative group of nonzero rational numbers. If $\alpha = p/q \in G$ where $(p,q) = 1$, let $f: G → G$ be the map which interchanges the primes $2$ and $3$ in the prime power factorization of $p$ and $q$ (so, for example, $f(2^43^57^113^2) = 3^42^57^113^2$ and $f(3/16) = f(3/2^4) = 2/3^4 = 2/81$), and $f$ is the identity on all rational numbers with numerators and denominators relatively prime to $2$ and to $3 $. a) Prove that $f$ is a group isomorphism. Attempt: let $x,y \in G$ and $x = 2^{a_1}3^{b_1}k_1j_1, y = 2^{a_2}3^{b_2}k_2j_2$. Then we need to show it is a group homomorphism. Then $f(xy) = f((2^{a_1}3^{b_1}k_1j_1)(2^{a_2}3^{b_2}k_2j_2)) = f(2^{a_1 + a_2}3^{b_1 + b_2}k_1k_2j_1j_2) = 3^{a_1 + a_2}2^{b_1 + b_2}k_1k_2j_1j_2 = 3^{a_1}2^{b_1}k_1j_1(3^{a_2}2^{b_2}k_2j_2) = f(2^{a_1}3^{b_1}k_1j_1)f(2^{a_2}3^{b_2}k_2j_2) = f(x)f(y)$ So $f$ is a group homomorphism. Now we need to show that it is a onto and injective function. onto: it is onto since for every $ y = 2^{a_2}3^{b_2}k_2j_2 \in G$, there exists $x = 2^{a_1}3^{b_1}k_1j_1 \in G$ such that $y = f(x)$ injective : let $x_1 = 2^{a_1}3^{b_1}k_1s_1$ and $x_2 = 2^{a_2}3^{b_2}k_2s_2$. Then $f(x_1) = f(x_2) $ $\Leftrightarrow$ $ f(2^{a_1}3^{b_1}k_1s_1) = f(2^{a_2}3^{b_2}k_2s_2)$ $\Leftrightarrow$ $ 3^{a_1}2^{b_1}k_1j_1 = 3^{a_2}2^{b_2}k_2j_2 $. I am kind of confused about proving it's a bijective function. Can someone please help me? b) Prove that there are infinitely many isomorphisms of the group $G$ to itself. Attempt: Generalize $f$ by $f(p^{a}q^{b}ks) = p^bq^aks$, where $p,q$ are any primes, that $f$ can interchanges them in the prime power factorizations. Can someone please verify I am on the right track? Any suggestion or better approach would really help. Thank you!","['abstract-algebra', 'group-theory', 'ring-theory']"
1512218,Extension of a linear map,"For any $x \in X$, define the set $\mathcal{F}(X) = \overline{span \{ \delta_x : x \in X \}}$ where $\delta_x(f)=f(x)$ for all $f \in$ $Lip_0(X)$. The set Lip$_0(X)$ is the set of all real-valued Lipschitz functions which vanish at $0$. Note that $\delta_x$ is an evaluation functional on Lip$_0(X)$. Suppose $X$ and $Y$ are Banach spaces. Let $L:X \rightarrow Y$ be a
  Lipschitz map such that $L(0)=0$. Then there exists a unique linear
  map $\hat{L}: \mathcal{F}(X) \rightarrow \mathcal{F}(Y)$ such that
  $\hat{L}\delta_X = \delta_YL$ The statement above is Lemma $2.2$ . The following is its proof: The linear map $L^\# : Lip_0(Y) \rightarrow Lip_0(X)$ defined by $L^\#(F) = F \circ L$ is pointwise-to-pointwise continuous, hence there is a linear map $\hat{L}$ between the preduals such that $\hat{L^*} = L^\#$. It is clear that $\| L^\# \| = Lip(L)$, and $\| \hat{L} \| = \| \hat{L^*} \| = \| L^\# \|$. The other assertions are clear. Question: $(1)$ To show the map $L^\#$ is pointwise-to-pointwise continuous, do I show that if $\lim_{n \rightarrow \infty}{F_n}=F$, then $ \lim_{n \rightarrow \infty}{L^\#F_n}= L^\#F$? $(2)$ Why there exists a linear map $\hat{L}$ after showing that $L^\#$ is point-to-pointwise continuous? $(3)$ Is that a typo in $\| L^\# \| = Lip(L)$? I think it should be $\| L^\# \| = \| L \|_{Lip}$. After that, how to show that $\| L^\# \| = \| L \|_{Lip}$? $(4)$ How to show that the map $\hat{L}$ is unique?","['lipschitz-functions', 'proof-verification', 'banach-spaces', 'functional-analysis']"
1512241,Proof that disjoint cycles commute,"I'm trying to prove that in a symmetric group two disjoint cycles commute. But I suspect that something is not right about my proof (a sense of vagueness). Some hints would be appreciated. Here's my proof: Let $\sigma=(s_1 s_2 ... s_n)$, $\tau=(t_1 t_2 ... t_m)$ for some integers $m, n$. That is, $s_i \neq t_j$ for any $i \in [1, n]$, $j \in [1, m]$. Now, $\sigma\tau=(s_1 ... s_n)(t_1 ... t_m)$ is a cycle of disjoint permutations, which cannot be represented by any other disjoint permutations. Thus $\sigma\tau=\tau\sigma$.","['group-theory', 'proof-verification', 'symmetric-groups', 'permutations']"
1512313,primes of the forms $...54321012345...$ and $...543212345...$,"I'm looking for primes formed from concatenating the first $n$ natural numbers in these following manners: $(n)(n-1)(n-2)\cdots54321012345\cdots(n-2)(n-1)(n)$ $(n)(n-1)(n-2)\cdots543212345\cdots(n-2)(n-1)(n)$ I have checked both of them for n up to $600$ , but the only primes I've found are $101$ and $131211109876543212345678910111213$ , which is n= $1$ , and n= $13$ respectively. Are there anymore primes of these forms besides those two (n= $1$ , n= $13$ )?","['prime-numbers', 'number-theory']"
1512327,$n$ fold convolution tends to zero a.e. if $\|f\|_{L^1}<\infty$.,"Let $f\geq 0$ satisfy $\int_\mathbb{R} f < 1$. Let $f_n$ be the $n$ time convolution of $f$ by itself. 
Then I want to show  $f_n \rightarrow 0$ a.e. as $n\rightarrow \infty$. We can clearly obtain that $f_n \rightarrow 0$ in $L^1(\mathbb{R})$. But how to prove a.e. convergence?","['lebesgue-measure', 'real-analysis', 'convolution', 'measure-theory']"
1512353,"In congruency tests, must the matching angle be the one in between the two sides?","When proving congruency, one of the classic tests is SAS, where the angle is between the two matching sides. Usually, it is taught that the angle must be between the two sides for this to work. Is it really true that the angle absolutely must be between the two sides to work? For example, if I have the following triangle (drawn to scale, so the double dashed line is longer than the single dashed line), then what other kind of triangle can be drawn that is not congruent to this, yet has two matching sides and this angle? I understand how the counter example can be made if the double dashed line is longer than the single dashed line (as in the diagram below), but not for the above case.",['geometry']
1512365,Prove $|a|=\sqrt{a^2}$,"I am having difficulty showing that the last case holds and I also just wanted to make sure I am proving this correctly. Case (i): If $a=0$ then we have $|a|=0=\sqrt{0^2}$ so trivially this is true. Case (ii): If $a>0$ then we have $|a|=a=\sqrt{a^2}$ Case (iii): This is where I get stuck since if $a<0$ then we have that $|a|=-a$, so if I start from $\sqrt{a^2}=\sqrt{(-a)^2}$ I'm not really sure what to do since I need this being equal to $|a|=-a$, I would like to say $\sqrt{(-a)^2}=-a$ but this seems to be a problem since it could also be written as $\sqrt{(-a)^2}=\sqrt{a^2}=a$",['real-analysis']
1512393,Meaning of $\int_E {f(x) \mu(dx)}?$,"Suppose $f$ is a measurable real-valued function defined on a measure space $(E, X , \mu)$. What is the meaning of the RHS of the following integral $$\int_E{f d\mu} = \int_E {f(x) \mu(dx)}?$$ I understand that LHS means 'integrate $f$ with respect to the measure $\mu$'. However, I fail to understand RHS. Remark: The integral above is taken from here , under 'Construction - Integration'.","['lebesgue-integral', 'definition', 'measure-theory']"
1512398,Prove that discontinuity set is countable union of closed sets,"For any function $f: [a,b] \rightarrow \mathbb{R}$, we can define the $\kappa$-oscillation set as follows: $D_\kappa = \{x \in [a,b]: $osc$_x(f) \geq \kappa \}$, where osc$_x(f) = \lim\limits_{r \rightarrow 0} \mathsf{diam}\,f([x-r,x+r])$. How can I use the fact that $D_\kappa$ is closed in order to prove that the discontinuity set of $f$ is a countable union of closed sets? And after I show that, how would I prove that the set of continuity points is a countable intersection of open sets?","['real-analysis', 'functions']"
1512468,Logistic curve through three points,"I need to find a logistic curve that passes through three points exactly. This means I cannot do a best fit but rather must use simultaneous equations. Essentially this is used to model population growth. The equation that I need to fit my data to is: $$ P=\frac{M}{be^{-kt}+1} $$ This was derived from the differential equation: $\frac{dP}{dt}=kP(M-P)$ When I attempt to find constants M (maximum population), b and k I end up getting a negative value for b and a value for M which is less than the original data set. This ends up creating some sort of weird hyperbola that does exactly fit my data though is not the necessary equation. From what I gather b, M and k must be positive to form a logistic equation. Here is the data: t=0 -> P=3766124
t=1 -> P=4000687
t=2 -> P=4500789 This is what I end up getting: M -> 3311478946607640967/945032999867
k -> -Log[(1883446144648/1055718570207)
b -> -(247632514983464541/3559111461591105508) Please show how this logistic function can be fitted exactly since these values are wrong. Thanks!","['algebraic-curves', 'logistic-regression', 'ordinary-differential-equations', 'functions']"
1512483,Why can we substitute the exponential function while deriving the characteristic equation,"I'm studying the way characteristic equation works. The derivation, according to Wikipedia, follows: We have a function $y(x)$ and an equation
$$a_n y^{(n)} + \cdots + a_1 y' + a_0 y = 0.$$ Then we substitute $$y = e^{rx}.$$ Why can we make such a substitution? I suspect we can't represent any function as $e^{rx}$. Besides it is said that $\forall z: e^{z} \neq 0$ (can you point me to a proof too), so if $\exists x_0: y(x_0) = 0$ then we can't represent this value in this substitution.","['calculus', 'ordinary-differential-equations']"
1512502,Closed form for integral of integer powers of Sinc function,"( Edit: Thank you Vladimir for providing the references for the closed form value of the integrals. My revised question is then to how to derive this closed form.) For all $n\in\mathbb{N}^+$, define $\mathcal{I}_n$ by the definite integral,
  $$\mathcal{I}_n:=\int_{0}^{\infty}\frac{\sin^n{(x)}}{x^n}\mathrm{d}x.$$
  Prove that $\mathcal{I}_n$ has the following closed form:
  $$\mathcal{I}_n\stackrel{?}=\pi\,2^{-n}\left(n\sum_{k=0}^{\lfloor\frac{n-1}{2}\rfloor}\frac{(-2)^k(n-2k)^{n-1}}{k!(n-k)!}\right),~~\forall n\in\mathbb{N}^+.$$ Integrals of small positive integer powers of the $\operatorname{sinc}$ function come up on a regular basis here, but it occurred to me that while I probably know the derivations for the $1\le n\le 4$ cases like the back of my hand, I can't recall ever working the integrals wfor any value of $n$ higher than that. The values of the first four integrals are, $$\mathcal{I}_1=\frac{\pi}{2},\\
\mathcal{I}_2=\frac{\pi}{2},\\
\mathcal{I}_3=\frac{3\pi}{8},\\
\mathcal{I}_4=\frac{\pi}{3}.$$ So I set out to first calculate $\mathcal{I}_5$ to see if any obvious pattern jumped out (and see if the trend of being equal to rational multiples of $\pi$ continued). I wound up getting frustrated and asking WolframAlpha instead. It turns that while the first four cases hinted very much at the possibility of a simple pattern relating the values of $\mathcal{I}_n$ for different positive integers $n$ (or possibly two separate patterns for even and odd $n$), the next few values most definitely did not: $$\mathcal{I}_5=\frac{115\pi}{384},\\
\mathcal{I}_6=\frac{11\pi}{40},\\
\mathcal{I}_7=\frac{5887\pi}{23040}\\
\mathcal{I}_8=\frac{151\pi}{630}.$$ So my questions are, 1) is there a systematic way to compute these integrals for all $n$?; and 2) is there an elegant way to represent these values in closed form for general $n$?","['special-functions', 'closed-form', 'improper-integrals', 'definite-integrals', 'integration']"
1512516,Dual of a Banach space is isometric to a subspace of a Lipschitz dual,"Suppose $E$ is a Banach space. Denote $E^*$ as a dual space of $E$ and $Lip(E)$ as the Lipschitz dual of $E$. In other words, $Lip(E) = \{ f:E \rightarrow \mathbb{R} | f(0)=0 \}$ and all $f$ is Lipschitz. In the book Geometric Nonlinear Functional Analysis, volume $1$, page $173$, there is this sentence before Proposition $7.5$: $E^*$ is naturally isometric to a subspace of $Lip(E)$. Question: How to show the statement above? Can give any hint?","['lipschitz-functions', 'functional-analysis']"
1512530,Probability of a result when spinning a disk,"A circular disk is divided into $5$ equal segments. On spinning the disk a pointer always points to one segment. The segments contain pictures of $2$ bananas, $2$ lemons and one kiwi fruit. The disk is spun $4$ times. The probability of not getting a kiwi is $\frac45 \times \frac45 \times \frac45 \times \frac45  = 0.410$. The probability of getting one kiwi is $(\frac15 \times \frac45 \times \frac45 \times \frac45)  + (\frac15 \times \frac45 \times \frac45 \times \frac45) + (\frac15 \times \frac45 \times \frac45 \times \frac45) + (\frac15 \times \frac45 \times \frac45 \times \frac45) = 0.410$ What is wrong here? the probability of no kiwi or one kiwi cannot be the same?",['probability']
1512557,How to prove there exist two elements in a positive integer sequence with bounded differences such that one is a multiple of the other?,"We are given an infinite positive integer sequence $a_1,a_2,\ldots$ such that $0<a_{n+1}-a_n\le 2013$ . How can I show that there exist infinite pairs $(p,q)$ such that $a_p\mid a_q$ ? In fact, it suffices to prove that one such pair exists, since we can use this conclusion on $a_{q+1},a_{q+2},\ldots$ to get another pair. But how can I prove such pair exists?","['sequences-and-series', 'elementary-number-theory']"
1512571,A intersection (A union B),"I'm trying to prove $A \cap (A \cup B) = A$. I'm stuck on the last part of my proof, not sure how to show next: $$x \in A \cap (A \cup B)$$
$$\iff x \in A \;\;\text{and}\;\; x \in A \cup B$$
$$\iff x \in A \;\;\text{and}\;\; (\text{either}\;\; x \in A \;\;\text{or}\;\; x \in B).$$",['elementary-set-theory']
1512577,Probability that none of 3 tennis balls chosen at random have been used before,"There are 15 tennis balls in a box, of which 9 have not previously been used. 3 of these balls are randomly chosen, played with and then returned to the box. later, another 3 balls are randomly chosen from the box. Find the probability that none of these balls has ever been used. I have decided to go simpler way and I have solved this problem another way:
$$ (9/15)*(8/14)*(7/13)*(6/15)*(5/14)*(4/13)$$ and I got the answer 0.008114962 But book gives another answer - $0.083$. Did I solve the problem right? If not, tell me please where I have made a mistake.","['probability', 'balls-in-bins']"
1512593,How to prove that these lines are concurrent?,"Point $D$ is chosen on side $BC$ of $\Delta ABC$ such that the incircles of $\Delta ACD$ and $\Delta ABD $ are tangent at $G$.
 Let line $l$ be the angle bisector of $\angle ABC$ ,line $m$ be the angle bisector of $\angle ACB$,and line $n$ be the perpendicular to $BC$ at point $D$. Prove that lines $l,m$ and $n$ are concurrent. My attempt: I let $ CR$ (angle bisector of $C$) and $DX$ ( line perpendicular to $BC$ at $D$) meet at $I$ ,then ,considering $\Delta CRA$ ,i have to prove that points $B,I,Q$ (where $BQ$ is the angle bisector of $B$) are collinear. For that  i've considered $\Delta CRA$ from which i have by Menelaus's Theorem (given that $I,Q,B$ are points that lie on the sides of this triangle)that: $$\cfrac{AB \cdot CQ \cdot RI}{RB \cdot AQ \cdot CI}=1  $$ Applying the Angle Bisector Theorem to $BQ$ i have that $$\frac {CQ}{AQ}=\cfrac{BC}{AB} \tag 1$$ ,doing the same for angle bisector $CR$ i have : $$ BR \cdot AC = AR \cdot BC $$ Multiplying this relation with $(1)$, i have that $\cfrac {AB}{RB}=\cfrac {AB \cdot AC}{BC \cdot AR}$ ,so to prove that the lines are concurrent  i have to prove that $\cfrac {RI}{CI}=\cfrac {AR}{AC}$ I am having some trouble proving this,can you give me some hints ?","['euclidean-geometry', 'geometry', 'triangles']"
1512602,continuous function: preimage of closure of a set is closure of preimage,"i am struggeling with the following problem: let $f:X\to Y$ be a continuous mapping bet ween two metric spaces. Does it hold that $f^{-1}(\overline{A})=\overline{f^{-1}(A)}$ and $f^{-1}(int(A))=int(f^{-1}(A))$, where the overline denotes the closure of a set and $int()$ the interior of a set. One direction is obvious: $f^{-1}(A)\subset f^{-1}(\overline{A})$ and by continuity of $f$ the set$f^{-1}(\overline{A})$ is closed. So we proved $\overline{f^{-1}(A)}\subset f^{-1}(\overline{A}$. Any idea or reference where I can find the proof or an counter example?","['metric-spaces', 'continuity', 'general-topology']"
1512652,Distribution of the sum of two Poisson random variables,"Let $X_1$ be a random variable with poisson distribution $\text{Poisson}(\lambda_1)$ (i.e. $f(x)=\frac{\lambda^x}{x!}e^{-\lambda}$ if $x \in \{ 0,1,2,3,\ldots\}$ and $0$ otherwise) and let $X_2$ be a random variable with poisson distribution $\text{Poisson}(\lambda_2)$. What is the distribution of $Y = X_1 + X_2$? I tried using the convolution formula: $$f_y(Y) = \Sigma_{x=1}^{\infty} f_2(y-x)f_1(x) = \lambda_2^ye^{-(\lambda_1+\lambda_2)}\Sigma_{x=1}^{\infty}\frac{\left(\frac{\lambda_1}{\lambda_2}\right)^x}{x!(y-x)!}$$ But I am kind of stuck here.. Any ideas? Thanks!","['probability-theory', 'poisson-distribution', 'probability-distributions']"
1512677,Determine the Type and the General Solution of an ODE,"Not sure where to start with this question. It's got me very confused. Help would be very appreciated, thanks Question Identify the type of first order ode and hence find the general solution: $$t \dot x = x+2te^{- {x\over t}}$$",['ordinary-differential-equations']
1512682,Why the combinatorial second Stiefel-Whitney class is a cocycle?,"From the book ""Spin geometry"" by Lawson&Michaelson Appendix A or this literature we know that there is a nice combinatorial way to interpret the second SW class by the transition functions of a principal bundle.
The basic idea is, we firstly take a good covering, where the principal bundle is trivial on each open sets. Then on each two-fold intersection we have the transition functions $$g_{\alpha\beta}: U_\alpha\bigcap U_\beta\rightarrow \mathrm{SO}(n)$$
Lifting each map to $\overline{g}_{\alpha\beta}:U_\alpha\bigcap U_{\beta}\rightarrow \mathrm{Spin}(n)$ gives a cochain on each three-fold intersection
$$w_{\alpha\beta\gamma}=\overline{g}_{\alpha\beta}\overline{g}_{\beta\gamma}\overline{g}_{\gamma\alpha}:U_{\alpha}\bigcap U_{\beta} \bigcap U_{\gamma}\rightarrow \mathbb{Z}_2$$
On both references above they just claim that $w$ is a cocycle. But I just wonder is the argument really so trivial?","['spin-geometry', 'differential-geometry', 'algebraic-topology', 'characteristic-classes']"
1512693,"Exponential distribution, how to apply in this task?","We have a restaurant, where glasses brake every $6$ month with exponential distribution. What is the probability, that From $5$ glasses, at most $3$ will break in $12$ month? From $500$ glasses, at most $300$ will break in $12$ month? I understand the task, but I have no idea how to applay the definition of exponential distribution. We have $\lambda = 1/6$ month? What is $X$?
Any help or hint appreciated. Or we have $E(X) = 1/6$ if $X=1$?","['probability', 'statistics']"
1512698,Uniqueness of Asymptotic Matching,"I'm studying the basics of Boundary Layer theory in which one makes a number of asymptotic expansions of the solution in various regions separated by a number of layers and then matches them to have an uniform approximation to the whole soultuion. Basically one finds an asymptotic expansion of the solution $y(x;\epsilon)$ inside the boundary and outside and matches them if there is an overlap region (and then repeat the process if there are many layers). Provided this is correct (?), my question is: how i can be sure that the matching procedure produces an unique approximated solution and what is the meaning of matching two solutions in a whole region? I couldn't find any piece of literature that addresses this problem or even mention it so does it even makes sense and if so is there an obvious explanation of why?","['asymptotics', 'ordinary-differential-equations', 'perturbation-theory']"
1512709,Intuition about construction of measures and outer measures,"I understand that a measure on a set is basically a way to assign a number to each suitable subset of that set and this number may be interpreted as ""size"". Intuitively, what is the outer measure?",['measure-theory']
1512730,A collection of sequences that cannot all be made to converge,"I am trying, mostly out of curiosity, to exhibit an infinite countable set $X$ of real, null sequences, such that given a sequence of signs $(s_n)\in\{-1,1\}^{\mathbb{N}},$ at least one of $(x_n)\in X$ will lead $\sum s_nx_n$ to diverge. Every construction I have tried has failed, yet I am convinced such an $X$ should exist. Would appreciate any clever ideas, or a proof of the contrary. Source: my question is inspired by this one , which treats the case $X$ finite: in that particular case there is no such set because it is possible to construct $(s_n)$ so that every $(x_n)\in X$ leads to $\sum s_nx_n$ convergent. The case where $X$ has cardinality $|\mathbb{R}|$ is almost trivial, so I am wondering what happens when $X$ is merely countable.","['sequences-and-series', 'convergence-divergence', 'real-analysis']"
1512738,Limit of $\frac{(n+1)^{2n}}{(n^2+1)^n}$ as $n\to \infty$,"So it is given to find $$\lim_{n\to \infty}\dfrac{(n+1)^{2n}}{(n^2+1)^n}$$ So what I did is $$\lim_{n\to \infty}\dfrac{(n+1)^{2n}}{(n^2+1)^n}=\lim_{n\to \infty}\dfrac{(n^2+2n+1)^{n}}{(n^2+1)^n}=\lim_{n\to \infty}\left(1+\frac{2n}{n^2+1}\right)^n$$ Now the rightmost form, is it $e^2$? I mean I am unable convince myself that it is some form of exponential function. Help me out.","['limits', 'real-analysis', 'exponential-function']"
1512743,An identity for the factorial function,"A friend of mine was doodling with numbers arranged somewhat reminiscent of Pascal's Triangle, where the first row was $ 1^{n-1} \ \  2^{n-1} \ \cdots \ n^{n-1} $ and subsequent rows were computed by taking the difference of adjacent terms. He conjectured that the number we get at the end is $ n! $ but I've not been able to prove or disprove this. The first few computations are given below:
$$ 
    \begin{pmatrix}
    1 \\
    \end{pmatrix}
$$ $$
    \begin{pmatrix}
    1   &     & 2   \\
        & 1   &     \\
    \end{pmatrix}
$$ $$
        \begin{pmatrix}
        1   &     & 4   &     & 9   \\
            & 3   &     & 5   &     \\
            &     & 2   &     &     \\
        \end{pmatrix}
$$ $$
        \begin{pmatrix}
        1   &     & 8   &     & 27  &     & 64  \\
            & 7   &     & 19  &     & 37  &     \\
            &     & 12  &     & 18  &     &     \\
            &     &     & 6   &     &     &     \\
        \end{pmatrix}
$$ $$
\newcommand\pad[1]{\rlap{#1}\phantom{625}}
        \begin{pmatrix}
        1   &     & 16  &     & 81  &     & 256 &     & 625 \\
            & 15  &     & 65  &     & 175 &     & 369 &     \\
            &     & 50  &     & 110 &     & 194 &     &     \\
            &     &     & 60  &     & 84  &     &     &     \\
            &     &     &     & 24  &     &     &     &     \\
        \end{pmatrix}
$$ I attempted to write down the general term and tried to reduce that to the required form. The general term worked out as
$$
       \sum_{i=0}^n (-1)^{n-i} \binom{n}{i} (i+1)^{n}.
$$
I tried applying various identities of the binomial coefficients but I'm barely making any progress. Any help would be appreciated. Small note : If I instead start with the first row as $ 0^{n} \ \  1^{n} \ \cdots \ n^{n} $ then I still get $n!$ at the end of the computation, and the general formula in this case works out as
$$
       \sum_{i=0}^n (-1)^{n-i} \binom{n}{i} i^{n}.
$$
In fact, we can start with any $n$ consecutive natural numbers, each raised to the $(n-1)$th power, and we still get $n!$ at the end of the computation.","['number-theory', 'binomial-coefficients', 'combinatorics']"
1512756,What is the distribution of the sqrt of a random variable with exponential distribution,"Let $X$ be a random variable with an exponential distribution where: 
  $f(x) = e^{-x}$ for all $x \geq 0$ (i.e. $X \sim \textrm{Exp}(\lambda = 1)$). Calculate >the distribution of $Y = X^{\frac{1}{2}}$. I tried to do the following thing:
$P(X=k)=\int_0^k e^{-x}dx=-e^{-x}|_0^k=1-e^{-k}$. So, $P(X^{\frac{1}{2}}=k)=P(X=k^2)=\int_0^{k^2} e^{-x}dx=-e^{-x}|_0^{k^2}=1-e^{-k^2}$. I think that if I differentiate this function by $k$, I should get the distribution (am I right?). So, I get: $(1-e^{-k^2})'_k = 2ke^{-k^2}$. I get that for $Y=X^{\frac{1}{2}}$, 
$f(y)=2ye^{-y^2}$. But I don't think this is the expected answer since it is not any known distribution. Where was I wrong? Thanks","['probability-theory', 'probability', 'probability-distributions']"
1512780,Computing a double integral,"Consider the double integral $$\int dp \int dp' \exp[-\frac{1}{2}p^2 + Kpq] \exp[-\frac{1}{2}p'^2 + Kpp' + Kp'q'],$$ where $q$ and $q'$ are constants. How should one solve such an integral? I tried completing the square on various terms, e.g $$\exp[-\frac{1}{2}p^2 + Kpq] = \exp[-\frac{1}{2}(p-Kq)^2 + \frac{K^2}{2}q^2].$$ Then can take the $q^2$ term outside and work with $$\exp[-\frac{1}{2}(p-Kq)^2 + Kpp'] \exp[-\frac{1}{2}p'^2 + Kp'q']$$ $$ = \exp[-\frac{1}{2}((p-Kq) - Kp')^2 + \frac{K^2}{2}p'^2] \exp[-\frac{1}{2}p'^2 + Kp'q']$$ but I still haven't managed to separate the $p'$ and $p$ terms. Many thanks for any tips!","['completing-the-square', 'multivariable-calculus', 'integration']"
1512830,Understanding the connection between the projective space and the affine plane,"Suppose we have a point $P=[x,y,z]\in \mathbb P^2$. Then at least one of the coordinates is not zero. Suppose $z\neq 0$. So we have write $P$ as $[x/z,y/z,1]$ and this point belongs to $(x/z,y/z)$ in the affine plane. But the every point on the line at infinity is of the form $[x,y,0]$, right? What are the images of this points? Vice versa a point $Q=(a,b)$ in the affine plane belongs to the projective point $[a,b,1]$. Which points will be send to points on the line at infinity ?","['abstract-algebra', 'algebraic-geometry', 'algebraic-curves']"
1512860,Why must the outside limits of an iterated be constant?,"My book claims that in an iterated integral $$\int_a^b \int_{g(x)}^{h(x)} f(x, y) \, dy \, dx$$ $h$ and $j$ are allowed to be any functions of $x$ not containing $y$, but $a$ and $b$ must be constant with respect to both $x$ and $y$. I don't really see why $a$ and $b$ have to be constants.","['calculus', '3d', 'definite-integrals', 'integration', 'multivariable-calculus']"
1512861,"Why is $|\cos\theta d\omega|$ the projection of the differential solid angle $d\omega$ onto the $(x,y)$-plane?","Let $B\subseteq\mathbb R^3$ be the ball with radius $r>0$ around $0$ and $S_{\partial B}$ be the surface measure of the boundary $\partial B$. Given a piece of the surface $A\subseteq\partial B$, its solid angle is defined to be $$\omega=\frac{S_{\partial B}(A)}{r^2}\;.$$ By definition, $$S_{\partial B}(A)=r^2\int_{T^{-1}(A)}\sin\theta\;d\lambda^2(\theta,\phi)\;,$$ where $$T:(0,\pi)\times(0,2\pi)\to\mathbb R^3\;,\;\;\;(\theta,\phi)\mapsto\left(\begin{matrix}r\sin\theta\cos\phi\\ r\sin\theta\sin\phi\\ r\cos\theta\end{matrix}\right)$$ and $\lambda^2$ denotes the $2$-dimensional Lebesgue measure. This leads people to talk about the differential solid angle $$d\omega=\sin\theta\;d\theta\;d\phi\;.$$ We can think about $d\omega$ as being the surface area of an infinitesimal small surface element. However, since this is relatively vague, I don't understand why $\left|\cos\theta d\omega\right|$ is the projection of $d\omega$ onto the $(x,y)$-plane. How can we verify this mathematically? $\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;$","['differential-geometry', 'geometry', 'mathematical-physics', 'physics', 'solid-angle']"
1512881,"linear, non-surjective isometry $T:\ell^p(\mathbb{Z})\to \ell^p(\mathbb{Z})$","I need help to find a linear, non-surjective isometry $T:\ell^p(\mathbb{Z})\to \ell^p(\mathbb{Z})$ for $1\le p\le\infty$. I tried different things, for example if $f:\mathbb{Z}\to\mathbb{Z}, z\mapsto 2z$, then I considered $T(x)=x\circ f$. But $T(x)(z)=x_{f(z)}=x_{2z}$, i.e.
$$T((\ldots,x_{-1},x_0,x_1,x_2,\ldots))=(\ldots,x_{-2},x_0,x_2,\ldots)$$and then $T$ need not to be injective. I tried other ideas but I don't have a suitable idea. Could you help me?","['sequences-and-series', 'isometry', 'functional-analysis']"
1512949,Universal cover of boundary,Let $M$ be a compact manifold-with-boundary and $B$ a component of $\partial M$. Let $\tilde{M}$ be the univeral cover of $M$ with infinite-sheeted covering map $p:\tilde{M} \to M$. I wonder about the following: Is it true that each component of $p^{-1}(B)$ is a universal covering space of $B$ ?,"['covering-spaces', 'manifolds-with-boundary', 'general-topology', 'geometric-topology']"
