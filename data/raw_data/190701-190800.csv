question_id,title,body,tags
3598343,Prove if an injective map $f:A\longrightarrow B$ exists there is also a surjective map from $A$ to a subset of $B$.,"Prove if an injective map $f:A\longrightarrow B$ exists there is also a surjective map from $A$ to a subset of $B$ . Say we are given an injective map $f: S \longrightarrow N$ . It is easy to see that $f$ is surjective to some subset of $N$ . Does it even need proving, or it enough to say, 'it simply follows'?",['functions']
3598409,exp(log + log) for positive semidefinite matrices,"Let $A$ and $B$ be positive definite matrices.  What is known about $f(A,B)=\exp(\log A + \log B)$ ?  Does this function have a name?  This is interesting because $f(A,B) = AB$ for commuting matrices and $f(A,B)=f(B,A)$ even for non-commuting matrices.","['logarithms', 'matrices', 'linear-algebra', 'matrix-equations', 'terminology']"
3598418,Please check my work! Question about cubic polynomials,"I need some help with this problem. Here is the link. Can you please tell me if there is an easier way to show that cubic polynomials have a real root? The question is in an analysis book from the continuity section so it has to use that. Here is the latex: Show that a cubic equation (i.e. one of the form $ax^3 + bx^2 + cx + d = 0$ where $a\neq 0)$ has at least one real root. Solution:
The equation has at least one root if for some $x_1<x_2$ , $\enspace f(x_1) < 0$ and $f(x_2) > 0$ . Then by the intermediate value theorem $f(c) = 0$ for some $x_1 < c < x_2$ . $x^3$ outgrows smaller powers of $x$ so the function is negative for some large negative number and positive for some large positive number.
If $(x_n)$ is a sequence of positive terms that tends to infinity, then $$f(x_n) = ax_n^3 + bx_n^2 + cx_n + d = x_n^3(a+ \frac{b}{x_n} + \frac{c}{x_n^2} + \frac{d}{x_n^3})$$ Now $\frac{b}{x_n}, \frac{c}{x_n^2}, \frac{d}{x_n^3}$ are sequences that tend to zero, so for any $\epsilon$ there is an $N$ such that $$|\frac{b}{x_n}| < \epsilon/3, \quad |\frac{c}{x_n^2}| < \epsilon/3, \quad |\frac{d}{x_n^3}| < \epsilon/3$$ and for $\epsilon = a$ , we have $$|\frac{b}{x_n}| + |\frac{c}{x_n^2}| + |\frac{d}{x_n^3}| < a$$ so that, by the triangle inequality $$|\frac{b}{x_n} + \frac{c}{x_n^2} + \frac{d}{x_n^3}| \leq |\frac{b}{x_n}| + |\frac{c}{x_n^2}| + |\frac{d}{x_n^3}| < a$$ which means $$-a <\frac{b}{x_n} + \frac{c}{x_n^2} + \frac{d}{x_n^3} < a$$ Then for some $|k|<1$ , it can be written $$a+ \frac{b}{x_n} + \frac{c}{x_n^2} + \frac{d}{x_n^3} = a+ ka = (1+k)a$$ and $$f(x_n) = x_n^3(1+k)a$$ for $n\geq N$ . Since $x_n$ is a sequence of positive terms, $f(x_n) = k_na$ for $n\geq N$ where $k_n>0$ . If $x_n$ is instead chosen as a sequence of negative terms that tends to $-\infty$ , then $f(x_n) = (k_n')a$ for $n\geq N$ where $k_n'<0$ . Therefore regardless of the sign of $a$ the function $f$ takes on both positive and negative values. It seems redundant and too many steps. Is there a more simple way to solve this problem? Any feedback is appreciated. Thank you!","['roots', 'analysis', 'alternative-proof', 'solution-verification', 'polynomials']"
3598429,Proof that you can win at least half the money.,"Suppose you play a game in which $n$ stacks of money each of different values, $a_1, ..., a_n$ are in a sequence on a table.  You get to choose either the left-most or right-most stack, then your opponent can do the same, and so on, until all stacks are gone. I need to prove that player 1 can always win at least half the money available when $n$ is even.  I initially tried induction but the inductive step wasn't clear. Suppose that you know the claim is true for $n=2k$ and consider a sequence of $2k+2$ stacks.  Picking the maximum of the two end stacks will not always result in an optimal choice.  If for instance the stacks are 1, 2, 100, 3 then as player 1 you might greedily choose 3 but then player 2 can choose 100.  If you instead selected 1 then player 2 would be forced to select a sub-optimal stack and you get the grab the 100. But I'm not sure how to prove this in general.  Certainly if the stacks are $a_1, ..., a_{2k+2}$ and if $a_1$ is maximal then it's optimal to pick that, and likewise for $a_{2k+2}$ .  But there are also examples where $a_2$ is maximal and yet it's not optimal to pick $a_{2k+2}$ .  For instance 3, 4, 3, 1.  The optimal selections go Player 1: 3 Player 2: 4 Player 1: 3 Player 2: 1 Then player 1 has done better than trying to force player 2 to reveal the 4 stack. Player 1: 1 Player 2: 3 Player 1: 4 Player 2: 3 One could theorize that if the max is $a_2$ or $a_{2k+1}$ and if that plus $\min\{a_1,a_{2k+2}\}$ is bigger than $\max \{a_1,a_{2k+2}\}+\min\{a_2,a_{2k+1}\}$ then you play the ""defensive"" strategy.  But after playing it, there's no guarantee that player 2 will reveal the max on the next move.  So I'm getting lost in the proof.","['game-theory', 'discrete-mathematics']"
3598480,Definite integral $\int_{0}^{\pi/2}\ 1/ (1+(\tan x)^{1/2})\ dx$,"$$\int_{0}^{\pi/2}\ \frac{1}{ 1+(\tan x)^{1/2}}\ dx$$ I have no idea how to evaluate this. I have tried many substitutions, but they just didn’t result in the answer. Update: As a remainder, if one wants to integrate a similar question, $\int_{0}^{\pi/2}\ 1/ (1+(tanx)^{\sqrt2})\ dx$ , refer to this Evaluate $\int_0^\pi\frac{1}{1+(\tan x)^\sqrt2}\ dx$ . Both of them were what I want to ask. I have tried many ways to find their anti-derivatives; however, in cases of this type (definite integral with a complicated integrand), their indefinite integral could not even be expressed in basic functions, let alone use Fundamental theorem of calculus II to evaluate them. Suitably using the brilliant method given below can directly lead to the answer. Thank you very much.","['integration', 'definite-integrals']"
3598536,Mismatching results using Fundamental Theorem of Calculus.,"First time poster here, thanks in advance! To get right to my question, it concerns solving for x in the following equation: $$\int_{0}^{x}(t^2+1) dt=x^2$$ Where the ""standard"" approach would be to apply the fundamental theorem of calculus like this: $$\frac{\mathrm{d} }{\mathrm{d} x} \int_{0}^{x}(t^2+1) dt= \frac{\mathrm{d} }{\mathrm{d} x} 
 x^2$$ $$x^2+1=2x$$ Then solving for x would return x=1 However, why do you get a different result by first computing the definite integral with respect to t, then putting the bounds (x and 0) and getting this: $$\frac{x^3}{3}+x=x^2$$ And clearly, here x must equal 0. Furthermore evaluating x=1 on the first equation does not hold true while evaluating x=0 does.
Perhaps it is wrong to evaluate integrals with variable bounds like that? Then how come double and triple integrals regularly use variable bounds that way?.
Is there something fundamentally wrong with taking the derivative of both sides? Again, any help and explanation is very much appreciated! EDIT: Thanks for the very clear answers everyone, makes complete sense now.","['calculus', 'definite-integrals']"
3598587,"Group congruences: If the operation is preserved, do we get $a\sim b$ $\Rightarrow$ $a^{-1}\sim b^{-1}$?","Let $(G,*)$ be a group. Let $\sim$ be an equivalence relation such that $$(\forall a,a',b,b'\in G)a\sim a', b\sim b' \Rightarrow a*b\sim a'*b'. \tag{*}$$ I.e., the equivalence relation $\sim$ respects the group operation. Question. Does the condition $(*)$ necessarily imply that $$(\forall a,b\in G) a\sim b \Rightarrow a^{-1}\sim b^{-1}, \tag{**}$$ i.e., the relation $\sim$ behaves well w.r.t. the inverses?
(If yes, how can we prove this? If it is not true, what are some counterexamples?) This can be expressed also using the corresponding partition. The condition $(*)$ means that $$[a]=[a'], [b]=[b'] \Rightarrow [a*b]=[a'*b'].$$ In the other words, we get a well-defined binary operation on the corresponding partition $G/\sim$ . It is easy to see that in this way we get a monoid. The condition $(**)$ says that the assignment $[a]\mapsto [a^{-1}]$ is also well-defined (=does not depend on the choice of the representative). So if $(**)$ is true, we have also inverses in $G/\sim$ and we get a group. In several places I have seen mentioned in passing that if an equivalence relation fulfills $(*)$ , the condition $(**)$ is true as well. For example, this is mentioned in the Wikipedia article Congruence relation ( current revision ). The definition there includes this condition, but the article mentions that ""this can actually be proven from the other four, so is strictly redundant"". Similarly, if I checked Hungerford's Algebra (proof of Theorem 1.5 on page 27 ) or Jacobson's Basic Algebra I (Definition 1.4 on page 54 and the comments following this definition), they both define congruence only using $(*)$ , but in the proof that we get a group they implicitly use that inverse is well-defined. (To make the question self-contained, I have copied the relevant parts from Jacobson's book below.) This is how this is presented in Jacobson's book: Definition 1.4. Let $(M,\cdot,1)$ be a monoid. A congruence (or congruence relation) $\equiv$ in $M$ is an equivalence relation in $M$ such that for any $a$ , $a'$ , $b$ , $b'$ such that $a\equiv a'$ and $b\equiv b'$ on has $ab\equiv a'b'$ . (In other words, congruences are equivalence relations which can be multiplied.) After this definition, there is the definition of quotient monoid and an explanation why it actually is a monoid. For groups, the author mentions: We can say a good deal more if $M=G$ is a group and $\equiv$ is a congruence on $G$ . In the first place, in this case the quotient monoid $(\overline G,\cdot,\overline 1)$ is a group, since $\overline a\overline{a^{-1}}=\overline 1=\overline{a^{-1}}\overline a$ . Hence every $\overline a$ is invertible and its inverse is $\overline{a^{-1}}$ . After this, the author proceeds to explain relationship between group congruences and normal subgroups.","['monoid', 'group-theory', 'congruence-relations']"
3598625,"If following actions allowed, Find $F(2002,2020,2200)?$","If following actions allowed,Find $F(2002,2020,2200)?$ $$ F(x+t,y+t,z+t)=t+F(x,y,z);$$ $$ F(xt,yt,zt)=tF(x,y,z);$$ $$ F(x,y,z)=F(y,x,z)=F(x,z,y)$$ where x,y,z,t are real numbers. My attempt: $F(0,0,0)=0$ from second action, then $F(x,x,x)=x$ for any x. And $F(x,y,z)=F(x,z,y)=F(y,x,z)=F(y,z,x)=F(z,x,y)=F(z,y,x)$ from third action. 
And I've found $$F(2x,2y,x+y)=2x+F(0,2y-2x,y-x)=2x+(y-x)F(0,2,1)=2y+F(2x-2y,0,x-y)=2y+(x-y)F(2,0,1)$$ Then $2x+(y-x)F(0,1,2)=2y+(x-y)F(0,1,2)$ , $F(0,1,2)=1.$ And I'm trying to find $F(0,1,11)$ I need some hint, I can't do more. In my opinion $F(x,y,z)=(x+y+z)/3$","['real-numbers', 'functions', 'real-analysis']"
3598820,Combinatorics counting problem,"There are $3n$ male students and $3n$ female students.
  How many ways can they be divided into two groups of three, in such way that in each group has at least one male student and one female student. I'd like to know if the following is correct:
First I organize them in lines of $2n$ , so: $2n!\cdot 2n!$ . then, I create a third line with the rest, so in total: $(2n!)^3$ . But now, I have created order inside the triplets, so to remove it I divide by $(3!)^{2n}$ . The final solution should be: $$\frac{(2n!)^3}{(3!)^{2n}}.$$ Is the solution above correct? Is the way of thinking correct?","['solution-verification', 'combinatorics']"
3598866,MLE of Geometric distribution - consistency and variance of inverse arithmetic sum,"I want to calculate the MLE and its consistency of Geometric distribution: $$\mathbb{P}(X=x)=p(1-p)^{x-1}$$ $$
l(p) = p(1-p)^{x_1-1}\cdot p(1-p)^{x_2-1} \cdot \cdots \cdot p(1-p)^{x_n-1} \\
L(p)=n\ln p + (x_1 + \cdots +x_n -n)\ln(1-p) \\
(L(p))'= \frac{n}{p} - \frac{x_1 + \cdots + x_n - n}{1-p} \\
\hat{p} = \frac{n}{x_1 + \cdots + x_n} = \frac{1}{\overline{X}}
$$ Now, to check the consistency I would use Markov's Inequality: $$
\mathbb{P}(|\hat{p_n} - \mathbb{E}(\hat{p_n})| \geq \epsilon) \leq \frac{\operatorname{Var}(\hat{p_n})}{\epsilon^2}
$$ I am stuck on calculating Variance though. Variance of arithmetic sum would be a breeze - here though it is an inverse of it. How can i proceed? Is it just the inverse of $\operatorname{Var}(\overline{X})$ = $\frac{\operatorname{Var}(X)}{n}$ which would equal $\frac{n}{\operatorname{Var}(X)}$ ? What is the $\mathbb{E}(\hat{p_n})$ ?","['statistical-inference', 'statistics', 'maximum-likelihood', 'probability-theory', 'probability']"
3598920,Define $I_n=\int_0^1\frac{x^n}{\sqrt{x^2+1}}dx$ for every $n\in\mathbb{N}$. Prove that $\lim_{n\to\infty}nI_n=\frac{1}{\sqrt 2}$.,"Question: Define $I_n=\int_0^1\frac{x^n}{\sqrt{x^2+1}}dx$ for every $n\in\mathbb{N}$ . Prove that $$\lim_{n\to\infty}nI_n=\frac{1}{\sqrt 2}$$ . My approach: Given that $I_n=\int_0^1\frac{x^n}{\sqrt{x^2+1}}dx, \forall n\in\mathbb{N}.$ Let us make the substitution $x^n=t$ , then $$nI_n=\int_0^1\frac{dt}{\sqrt{1+t^{-2/n}}}.$$ Now since $0\le t\le 1\implies \frac{1}{t}\ge 1\implies \left(\frac{1}{t}\right)^{2/n}\ge 1 \implies 1+\left(\frac{1}{t}\right)^{2/n}\ge 2\implies \sqrt{1+\left(\frac{1}{t}\right)^{2/n}}\ge \sqrt 2.$ This implies that $$\frac{1}{\sqrt{1+\left(\frac{1}{t}\right)^{2/n}}}\le\frac{1}{\sqrt 2}\\ \implies \int_0^1 \frac{dt}{\sqrt{1+\left(\frac{1}{t}\right)^{2/n}}}\le \int_0^1\frac{dt}{\sqrt 2}=\frac{1}{\sqrt 2}.$$ So, as you can see, I am trying to solve the question using Sandwich theorem. Can someone help me to proceed after this? Also, in $$\lim_{n\to\infty}nI_n=\lim_{n\to\infty}\int_0^1\frac{dt}{\sqrt{1+t^{-2/n}}},$$ the limit and integral interchangeable?","['integration', 'definite-integrals', 'real-analysis']"
3598954,Various variants of modular forms,"There are many different generalizations of modular forms. One has Hilbert modular forms, Siegel modular forms, Maass wave forms, Jacobi forms, and then there are various generalities of automorphic forms. There are level structures and weights, there are adelic forms and cusp forms, and all sorts of algebraic groups and subgroups. I'm having much trouble grasping all these different notions. Could someone perhaps give an overview of the various versions of modular and automorphic forms, along with their respective relevance? Specifically, I am interested in the Langlands conjecture, and its connection with homotopy theory (in which I have a reasonable background).","['algebraic-number-theory', 'number-theory', 'analytic-number-theory', 'algebraic-geometry', 'modular-forms']"
3598972,What is $\lim_{n\to \infty }\left(\sqrt[\leftroot{-2}\uproot{2}n+1]{(n+1)!}-\sqrt[\leftroot{-2}\uproot{2}n]{n!}\right)$?,So recently a friend asked me to compute this limit: $$\lim_{n\to \infty }\left(\sqrt[\leftroot{-2}\uproot{2}n+1]{(n+1)!}-\sqrt[\leftroot{-2}\uproot{2}n]{n!}\right)$$ Question : Does the limit exist? If yes is it finite and if yes what is its value? How do we solve this? Edit: Note: I am only familiar with only basics of limit solving(upto  L'Hôpital's rule) and have reasons to believe that this limit can be solved using these methods. If you could keep your answer simple that should help. Update Here is where I have gotten so far $$ \lim_{n\to \infty} (n+1)! ^{1\over n+1} - (n)! ^{1\over n}$$ Can be written as $$ \lim_{n\to \infty}[1*2*3*...(n+1)]^{1\over n+1}  - [1*2*3*...n] ^{1\over n}$$ $$\implies \lim_{n\to \infty} [(n+1)[{1 \over n+1}* {2 \over n+1}  * {3\over n+1}...* {n+1 \over n+1}]^{1 \over n+1} - (n)[{1 \over n}* {2 \over n}  * {3\over n}...* {n\over n}]^{1 \over n} ]$$ (Factoring n+1 out of first expression and n from second.) $$\implies  \lim_{n\to \infty} [(n+1) e^{{1 \over n+1} (\sum_{r=1}^{n+1}ln({r\over n+1}))} - (n) e^{{1 \over n} (\sum_{r=1}^{n}ln({r\over n}))}  ]$$ From here I think second limit can be solved as a integral(limit of a sum) but I cannot solve first. How can I proceed further? Thanks!,"['integration', 'definite-integrals', 'factorial', 'calculus', 'limits']"
3599094,Finding a coefficient of $x^{57}$ in a polynomial $(x^2+x^7+x^9)^{20}$,"So the task is to find a coefficient of $x^{57}$ in a polynomial $(x^2+x^7+x^9)^{20}$ I was wondering if there is a more intelligible and less exhausting strategy in finding the coefficient, other than saying that $(x^2+x^7+x^9)^{20}=((x^2+x^7)+x^9)^{20}$ and then working with binomial expansion.","['binomial-coefficients', 'multinomial-coefficients', 'polynomials', 'discrete-mathematics']"
3599117,Are all almost virtually free groups word hyperbolic?,"Suppose $G$ is a finitely generated group with a finite symmetric generating set $A$ . Lets define Cayley ball $B_A^n := (A \cup \{e\})^n$ as the set of all elements with Cayley length (in respect to $A$ ) $n$ or less. Suppose $R_1, … , R_k$ are $k$ random elements chosen uniformly from $B_A^n$ . Then we can define a random $k$ -generated subgroup of $G$ as $H(G, A, k, n) = \langle \{R_1, … , R_k\} \rangle$ . Now, suppose, $\mathfrak{X}$ is some group property closed under finitely-generated subgroups. We say, that  a finitely generated group $G := \langle A \rangle$ is almost $\mathfrak{X}$ iff $\forall k \in \mathbb{N} \lim_{n \to \infty} P(H(G, A, k, n)) = 1$ . The following facts are not hard to see: The definition does not depend on the choice of $A$ The property of being almost $\mathfrak{X}$ is closed under finitely-generated subgroups A group is almost almost $\mathfrak{X}$ iff it is almost $\mathfrak{X}$ Moreover, a following fact was proved by Gilman, Miasnikov and Osin in «Exponentially generic subsets of groups»: Any word hyperbolic group is either almost free or virtually cyclic An easy corollary of this statement is: All word hyperbolic groups are almost virtually free My question is whether the converse is also true: Are all almost virtually free groups word hyperbolic?","['combinatorial-group-theory', 'gromov-hyperbolic-spaces', 'geometric-group-theory', 'group-theory', 'probability']"
3599155,How to find range $a_{75}$ of the term of the series $a_n=a_{n-1}+ {1 \over {a_{n-1}}} $ [duplicate],"This question already has an answer here : Let us define a series $\{a(n)\}$ such that $a(n)= a(n-1) + \frac{1}{a(n-1)}$ (1 answer) Closed 4 years ago . If $a_1=1$ and for n>1 $$a_n=a_{n-1}+ {1 \over {a_{n-1}}} $$ $a_{75}$ lies between (a) (12,15) (b) (11,12) (c) (15,18) Now , in this question, I rewrote, $a_n-a_{n-1} = {1 \over {a_{n-1}}}$ , to make a telescopic type and summed the terms to get $$a_n-a_{1}= {1 \over {a_{n-1}}}+ {1 \over {a_{n-2}}}...{1 \over {a_{1}}}$$ And as ${1 \over {a_{r}}} <1$ for all r ,
I got $a_{75} <76$ , but it's of no help as , the upper bound is much higher. I got no further ideas , on how to solve it, please help.","['summation', 'inequality', 'approximation', 'sequences-and-series', 'algebra-precalculus']"
3599197,"Prove that the number of beautiful positive integers in the set $\{ 2^{20},\; 2^{20}+1,\; 2^{20}+2, \; ..., \; 2^{21}-1 \}$ is divisible by 17","Definition . Let a positive integer $n$ be written in binary numeral system. We shall say that a some digit of the $n$ is interesting if this digit is not equal to the adjacent digit to the right of it and if this digit is not equal adjacent digit to the left of it (The first digit is interesting if it is not equal to the second digit. The last digit is interesting if it is not equal to the penultimate digit). Let $f(n)$ be the number of interesting digits of $n$ . If $f(n)=16$ then we shall say that the positive integer $n$ is beautiful. Let $k$ be the number of beautiful positive integers in the set $\{ 2^{20},\; 2^{20}+1,\; 2^{20}+2, \; ..., \; 2^{21}-1 \}$ . Prove that $k$ is divisible by $17$ . My work . Using a computer program, I found that $k=323$ . Below I wrote all the beautiful positive integers in binary numeral system. But I need to have a mathematical solution of the problem. 111110101010101010101,
111011010101010101010,
111010110101010101010,
111010101101010101010,
111010101011010101010,
111010101010110101010,
111010101010101101010,
111010101010101011010,
111010101010101010110,
111010101010101010100,
111010101010101010010,
111010101010101001010,
111010101010100101010,
111010101010010101010,
111010101001010101010,
111010100101010101010,
111010010101010101010,
111001010101010101010,
110111010101010101010,
110101110101010101010,
110101011101010101010,
110101010111010101010,
110101010101110101010,
110101010101011101010,
110101010101010111010,
110101010101010101110,
110101010101010101000,
110101010101010100010,
110101010101010001010,
110101010101000101010,
110101010100010101010,
110101010001010101010,
110101000101010101010,
110100010101010101010,
110001010101010101010,
101111101010101010101,
101110110101010101010,
101110101101010101010,
101110101011010101010,
101110101010110101010,
101110101010101101010,
101110101010101011010,
101110101010101010110,
101110101010101010100,
101110101010101010010,
101110101010101001010,
101110101010100101010,
101110101010010101010,
101110101001010101010,
101110100101010101010,
101110010101010101010,
101101110101010101010,
101101011101010101010,
101101010111010101010,
101101010101110101010,
101101010101011101010,
101101010101010111010,
101101010101010101110,
101101010101010101000,
101101010101010100010,
101101010101010001010,
101101010101000101010,
101101010100010101010,
101101010001010101010,
101101000101010101010,
101100010101010101010,
101011111010101010101,
101011101101010101010,
101011101011010101010,
101011101010110101010,
101011101010101101010,
101011101010101011010,
101011101010101010110,
101011101010101010100,
101011101010101010010
101011101010101001010,
101011101010100101010,
101011101010010101010,
101011101001010101010,
101011100101010101010,
101011011101010101010,
101011010111010101010,
101011010101110101010,
101011010101011101010,
101011010101010111010,
101011010101010101110,
101011010101010101000,
101011010101010100010,
101011010101010001010,
101011010101000101010,
101011010100010101010,
101011010001010101010,
101011000101010101010,
101010111110101010101,
101010111011010101010,
101010111010110101010,
101010111010101101010,
101010111010101011010,
101010111010101010110,
101010111010101010100,
101010111010101010010,
101010111010101001010,
101010111010100101010,
101010111010010101010,
101010111001010101010,
101010110111010101010,
101010110101110101010,
101010110101011101010,
101010110101010111010,
101010110101010101110,
101010110101010101000,
101010110101010100010,
101010110101010001010,
101010110101000101010,
101010110100010101010,
101010110001010101010,
101010101111101010101,
101010101110110101010,
101010101110101101010,
101010101110101011010,
101010101110101010110,
101010101110101010100,
101010101110101010010,
101010101110101001010,
101010101110100101010,
101010101110010101010,
101010101101110101010,
101010101101011101010,
101010101101010111010,
101010101101010101110,
101010101101010101000,
101010101101010100010,
101010101101010001010,
101010101101000101010,
101010101100010101010,
101010101011111010101,
101010101011101101010,
101010101011101011010,
101010101011101010110,
101010101011101010100,
101010101011101010010,
101010101011101001010,
101010101011100101010,
101010101011011101010,
101010101011010111010,
101010101011010101110,
101010101011010101000,
101010101011010100010,
101010101011010001010,
101010101011000101010,
101010101010111110101,
101010101010111011010,
101010101010111010110,
101010101010111010100,
101010101010111010010,
101010101010111001010,
101010101010110111010,
101010101010110101110,
101010101010110101000,
101010101010110100010,
101010101010110001010,
101010101010101111101,
101010101010101110110,
101010101010101110100,
101010101010101110010,
101010101010101101110,
101010101010101101000,
101010101010101100010,
101010101010101011111,
101010101010101011100,
101010101010101011000,
101010101010101001110,
101010101010101001000,
101010101010101000110,
101010101010101000100,
101010101010101000001,
101010101010100111010,
101010101010100101110,
101010101010100101000,
101010101010100100010,
101010101010100011010,
101010101010100010110,
101010101010100010100,
101010101010100010010,
101010101010100000101,
101010101010011101010,
101010101010010111010,
101010101010010101110,
101010101010010101000,
101010101010010100010,
101010101010010001010,
101010101010001101010,
101010101010001011010,
101010101010001010110,
101010101010001010100,
101010101010001010010,
101010101010001001010,
101010101010000010101,
101010101001110101010,
101010101001011101010,
101010101001010111010,
101010101001010101110,
101010101001010101000,
101010101001010100010,
101010101001010001010,
101010101001000101010,
101010101000110101010,
101010101000101101010,
101010101000101011010,
101010101000101010110,
101010101000101010100,
101010101000101010010,
101010101000101001010,
101010101000100101010,
101010101000001010101,
101010100111010101010,
101010100101110101010,
101010100101011101010,
101010100101010111010,
101010100101010101110,
101010100101010101000,
101010100101010100010,
101010100101010001010,
101010100101000101010,
101010100100010101010,
101010100011010101010,
101010100010110101010,
101010100010101101010,
101010100010101011010,
101010100010101010110,
101010100010101010100,
101010100010101010010,
101010100010101001010,
101010100010100101010,
101010100010010101010,
101010100000101010101,
101010011101010101010,
101010010111010101010,
101010010101110101010,
101010010101011101010,
101010010101010111010,
101010010101010101110,
101010010101010101000,
101010010101010100010,
101010010101010001010,
101010010101000101010,
101010010100010101010,
101010010001010101010,
101010001101010101010,
101010001011010101010,
101010001010110101010,
101010001010101101010,
101010001010101011010,
101010001010101010110,
101010001010101010100,
101010001010101010010,
101010001010101001010,
101010001010100101010,
101010001010010101010,
101010001001010101010,
101010000010101010101,
101001110101010101010,
101001011101010101010,
101001010111010101010,
101001010101110101010,
101001010101011101010,
101001010101010111010,
101001010101010101110,
101001010101010101000,
101001010101010100010,
101001010101010001010,
101001010101000101010,
101001010100010101010,
101001010001010101010,
101001000101010101010,
101000110101010101010,
101000101101010101010,
101000101011010101010,
101000101010110101010,
101000101010101101010,
101000101010101011010,
101000101010101010110,
101000101010101010100,
101000101010101010010,
101000101010101001010,
101000101010100101010,
101000101010010101010,
101000101001010101010,
101000100101010101010,
101000001010101010101,
100111010101010101010,
100101110101010101010,
100101011101010101010,
100101010111010101010,
100101010101110101010,
100101010101011101010,
100101010101010111010,
100101010101010101110,
100101010101010101000,
100101010101010100010,
100101010101010001010,
100101010101000101010,
100101010100010101010,
100101010001010101010,
100101000101010101010,
100100010101010101010,
100011010101010101010,
100010110101010101010,
100010101101010101010,
100010101011010101010,
100010101010110101010,
100010101010101101010,
100010101010101011010,
100010101010101010110,
100010101010101010100,
100010101010101010010,
100010101010101001010,
100010101010100101010,
100010101010010101010,
100010101001010101010,
100010100101010101010,
100010010101010101010,
100000101010101010101,","['contest-math', 'number-theory', 'combinatorics']"
3599219,"For acute $\triangle ABC$, prove $(\cos A+\cos B)^2+(\cos A+\cos C)^2+(\cos B+\cos C)^2\leq3$","Prove that, in an acute $\triangle ABC$ , $$(\cos A+\cos B)^2+(\cos A+\cos C)^2+(\cos B+\cos C)^2\leq3$$ I tried this, but I can't to this. I used $AM\geq GM$ and got $$3\geq\cos(A-B)+\cos(A-C)+\cos(B-C)$$ But I can't see how to do this question.","['inequality', 'proof-explanation', 'geometric-inequalities', 'triangles', 'trigonometry']"
3599242,"Direct product of groups has inclusions, but it's still not the free product (coproduct)?","Conceptually, I get the difference between products and coproducts: the first has projections, the second has inclusions. There are all sorts of circumstances in which you can be convinced that these two notions are different. But now I'm thinking about groups, and it seems to me that (direct) products of groups actually do come with inclusions as per the universal property: The product $\prod G_\alpha$ of groups has projections $\{\pi_{\alpha_0}:\prod G_\alpha \to G_\alpha\}$ to each of its factors. Then for each $\alpha_0$ , every collection of maps $\{f_\alpha:G_{\alpha_0} \to G_\alpha\}$ , by $f_{\alpha_0} = \mathrm{id}$ and $f_\alpha \equiv e$ else, factors through a unique map $$ G_{\alpha_0} \xrightarrow{\exists!\ i_{\alpha_0}} \prod G_\alpha \xrightarrow{\pi_{\alpha_0}} G_{\alpha_0}.$$ Clearly the map $i_{\alpha_0}$ is an embedding, so I'd like to think of it as an inclusion. And this is all very natural, basically because groups are special in that they all have a distinguished element (the identity). So is there some nice conceptual reason why the collection $\{i_{\alpha_0}:G_{\alpha_0} \to \prod G_\alpha\}$ does not make $\prod G_\alpha$ into the coproduct, aside from the fact that of course the direct product and free product of groups are not isomorphic? Remark: I suppose you can also do a similar sort of thing to show that the coproduct also has projections, by basically dualizing this argument.","['universal-property', 'group-theory', 'category-theory']"
3599290,Countable subfield of $\mathbb{R}$,"Let $f:\mathbb{R}→\mathbb{R}$ be a function.  Prove that there is a countable subfield $K⊂\mathbb{R}$ such that $f(K)⊂K$ . What I've tried: start with any $x$ , look at the set ${x, f(x), f(f(x)), ...}$ Clearly it satisfies $f(K)⊂K$ , but I can't prove it's a subfield. Probably it's a false start. Then I thought maybe looking at $\mathbb{Q}$ , but don't know how to continue. Would appreciate if someone can give me a hint first, instead of a full solution.","['functions', 'real-analysis']"
3599301,Prove: Viviani’s theorem,"This problem is in Kiselev's Planitmetry, to prove that: In an equilateral triangle, the sum of the distances from an
interior point to the sides of this triangle does not depend on the
point, and is congruent to the altitude of the triangle. After searching google for a while, I discovered that it has a name, Viviani's theorem.
Anyways, the standard proof uses the concept of area, and the known formula for calculating the area of a triangle.
But I don't believe that was Kiselev's intention, since, he placed the problem after the section on the midline theorems (In triangles and trapezoids), So does anybody know a way to do this? I only need a hint. Attempt : I only found that each of these distances will be parallel to each altitude of the triangle, but couldn't use this fact in proving the theorem. In addition to that, I proved a case of the theorem, If the point lies on one of the altitudes, the proof follows from the picture.","['euclidean-geometry', 'geometry']"
3599333,$ Ax\cdot x>0$ and $Ay\cdot y>0$ implies $(Ax\cdot x)(Ay\cdot y)\geq (Ax\cdot y)^2$?,"Let $A$ be a $n\times n$ symmetric real matrix. Assume that $x,y\in\mathbb{R}^n$ are such that $Ax\cdot x>0$ and $Ay\cdot y>0.$ Does this imply that $(Ax\cdot x)(Ay\cdot y)\geq (Ax\cdot y)^2$ ? The inequality clearly looks like a Cauchy-Schwarz (C-S) type inequality but applying C-S I couldn't arrive to the desired inequality. Besides, I am not even sure if it is even true. Does anyone have any thoughts?","['matrices', 'cauchy-schwarz-inequality', 'linear-algebra', 'symmetric-matrices']"
3599343,Proving $\prod\limits_{k=1}^{n-1}\left(1-\frac{\sin^2(x/2n)}{\sin^2(k\pi/2n)}\right)=\frac{\sin{x}}{n\sin(x/n)}$ and related tangent formula,"Let $ n\geq 2 $ , and $ x\in\left]0,\pi\right[ $ , prove the following formulas : $$\begin{align}
\prod_{k=1}^{n-1}{\left(1-\frac{\sin^{2}{\left(\frac{x}{2n}\right)}}{\sin^{2}{\left(\frac{k\pi}{2n}\right)}}\right)}&=\frac{\sin{x}}{n\sin{\left(\frac{x}{n}\right)}} \\[8pt]
\prod_{k=1}^{n-1}{\left(1-\frac{\tan^{2}{\left(\frac{x}{2n}\right)}}{\tan^{2}{\left(\frac{k\pi}{2n}\right)}}\right)}&=\frac{\sin{x}}{n\sin{\left(\frac{x}{n}\right)}\cos^{2n-2}{\left(\frac{x}{2n}\right)}}
\end{align}$$ These beautiful formulas have served me to build a rigourous proof (Using squeezing theorem and the fact that if $ 0< x\leq y<\frac{\pi}{2} $ then $ \frac{\tan{x}}{\tan{y}}\leq\frac{x}{y}\leq\frac{\sin{x}}{\sin{y}} $ ) for Euler's well-known formula : $$ \left(\forall x\in\left]-\pi,\pi\right[\right),\ \sin{x}=x\prod_{n=1}^{+\infty}{\left(1-\frac{x^{2}}{n^{2}\pi^{2}}\right)} $$","['products', 'trigonometry', 'sequences-and-series']"
3599348,Subgroups of the general linear group over the adele ring,"Let $\mathbb{A}_\mathbb{Q}^f$ be the subring of the adeles ring with $x_\infty=0$ , is every open compact subgroup of $GL_2(\mathbb{A}_\mathbb{Q}^f)$ included in a conjugacy class of $GL_2(\widehat{\mathbb{Z}})$ ?
Thanks in advance","['algebraic-number-theory', 'number-theory', 'adeles', 'field-theory', 'group-theory']"
3599376,"Nondiscrete topology making $(Z,+)$ a topological group.","In Fourier Analysis on Number Fields , D. Ramakrishnan and R. J. Valenza propose the following exercise : While the (a) is quite clear, I had a lot more trouble with the (b). My idea for it was the following: Following the hint, we'll use the fact that the orbit of a rotation on the circle is either periodic or dense to find another element of $U\cap G$ . Let $p_1,\dotsc,p_k:\mathscr{G}\to S^1$ be the projections which satisfy $p_i(U)\neq S^1$ and consider the sequence $(j(1)^n)_{n\in\mathbf{Z}}$ . We start with $M=\mathbf{Z}$ and, for each $i$ , if $p_i(j(1)^n)$ is periodic in $n$ , we remove all the $n\in M$ such that $p_i(j(1)^n)\neq p_i(j(1))$ ; if $p_i(j(1)^n)$ is dense in $S^1$ , we remove all the $n\in M$ such that $p_i(j(1)^n)\notin p_i(U)$ . In the end $M$ is still an infinite set. Then, if $n\in M-\{1\}$ , $j(1)^n$ is another element of $U\cap G$ other than $j(1)$ . This contradicts the fact that $U\cap G$ is a singleton. I believe the bold sentence is true but I'm not so confident about it. Of course $M$ is infinite after the first stage but I haven't found an argument to justify it being infinite after the second stage. I would appreciate some clarification and would also find it interesting if someone had another solution for this exercise. (In the first stage, each one of the $p_i(j(1)^n)$ is of the form $e^{2\pi i q_in}$ , where $q_i$ is a rational number. If $m$ is the lcm of the denominators of the $q_i$ , then $M=m\mathbf{Z}$ after this stage.)","['general-topology', 'abstract-algebra', 'topological-groups']"
3599388,'Completing' incomplete vector fields,"Suppose $M$ is a smooth manifold with a smooth vector field $X$ on it. If $X$ is not a complete vector field (a complete vector field is one for which all integral curves exist for all time) is it possible to embed it in another smooth manifold and extend $X$ to a complete vector field on the new manifold?
More precisely, can one find a smooth manifold $N$ , a complete vector field $Y$ on $N$ , and a smooth embedding $F : M \to N$ such that $F_*X = Y$ , i.e. for all $p \in M$ , we have $dF_p (X_p) = Y_{F (p)}$ ? For example, if $M = (0, 1) \subset \mathbb R$ and $X = \partial_x$ then clearly $X$ is not complete, but $M$ embeds inside $N = \mathbb R$ with the extension $Y = \partial_x$ , which is complete.","['ordinary-differential-equations', 'vector-fields', 'smooth-manifolds', 'differential-topology', 'differential-geometry']"
3599439,$f\in\mathcal{O}_X(X)$ is a unit $\Leftrightarrow f_x\neq 0$ for all $x\in X$,"Let $X$ be a scheme. I'm trying to prove the following: $f\in\mathcal{O}_X(X)$ is a unit $\Leftrightarrow f_x\neq 0$ for all $x\in X$ [here $f_x$ is the germ of $f$ in the stalk $\mathcal{O}_{X,x}$ ] EDIT : the correct statement should have "" $f(x)\neq 0$ "" instead of "" $f_x\neq 0$ "", where $f(x)$ is the equivalent class of $f_x\in\mathcal{O}_{X,x}$ in the quotient $\mathcal{O}_{X,x}/\mathfrak{m}_{X,x}$ (residue field of the local ring $\mathcal{O}_{X,x}$ ). This is precisely the reason why I got stuck. Based on other problems involving local objects, it's probably a good idea to consider the affine case first. So let $X=\text{Spec}(A)$ . I've already proven $(\Rightarrow)$ , but I'm stuck at $(\Leftarrow)$ . The condition $f_x\neq 0$ for all $x$ is equivalent to $f\big|_{X_g}\neq 0\in\mathcal{O}_X(X_g)=A_g$ for all $g\in A$ with $X_g\neq \emptyset$ . The condition $f\big|_{X_g}\neq 0$ amounts to $fg^n\neq 0$ for all $n\geq 1$ . All this can be restated as $X_f\cap X_g\neq \emptyset$ for all $X_g\neq \emptyset$ , i.e., $X_f$ is dense in $X$ . But in order to prove $f$ is a unit, I need $X_f=X$ , which I can't see how to prove. Any suggestions?","['algebraic-geometry', 'schemes', 'sheaf-theory']"
3599459,What's the limit of the string?,"Find $$\lim_{n\to\infty} (x_n\sqrt{n})^{\sqrt{n^2-1}},$$ where $ x_{n+1} = \frac{x_n}{\sqrt{1+x_n^2}}$ and $x_1 = 2$ . I showed $x_n \to 0$ , $x_n\sqrt{n} \to 1$ , but i don't know how to solve limit properly.","['limits', 'calculus', 'limits-without-lhopital', 'sequences-and-series']"
3599500,Show that $3 \!\uparrow\uparrow\! 2$ is equal to the number of sets of rank at most $2$ with a $3$-valued notion of set membership,"This question is with regard to the answer of an older post . Please see the original post's answer for context. The following answer was given to a question about what the tetration $k \!\uparrow\uparrow\! n$ is actually counting, where $$‎k \!\uparrow\uparrow\! n := \underbrace{k^{k^{k^{.^{.^{.}}}}}}_{n - times}.$$ $k \!\uparrow\uparrow\! n$ is equal to the number of sets of rank at most $n$ when we adopt a $k$ -valued notion of set membership. For example, this view still gives us one set of rank $0$ , namely the empty set $\{\}$ , but now we have $k$ sets of rank $0$ or $1$ , namely the sets containing only $\{\}$ , with value between $0$ and $k-1$ (of course, the set containing $\{\}$ with value $0$ is identified with $\{\}$ , so that we only get $k-1$ new sets of rank $1$ , for a total of $k$ with rank $0$ or $1$ ). It is easy to check that we get $k^k$ ""sets"" of rank at most $2$ , $k^{k^k}$ of rank at most $3$ , and $k \!\uparrow\uparrow\! n$ sets of rank at most $n$ . My problem: It is easy to write out the sets for $3 \!\uparrow\uparrow\! 0$ and $3 \!\uparrow\uparrow\! 1$ , as they are simply \begin{align}
3 \!\uparrow\uparrow\! 0 \ \ &: \ \ \{ \} \\ 
3 \!\uparrow\uparrow\! 1 \ \ &: \ \ \{ \}, \big\{ \{ \}_{1}\big\}, \big\{ \{ \}_{2}\big\} 
\end{align} where each subscript indicates the intrinsic value of the member; however, I struggle to follow the described pattern for the 27 members that should be associated with $‎3 \!\uparrow\uparrow\! 2$ . Points will be awarded to the first answer that can correctly list all 27 members of $3 \!\uparrow\uparrow\! 2$ , as described in the OP.","['cardinals', 'logic', 'combinatorics', 'set-theory']"
3599533,Holomorphic functions on an open set but not a domain,"Let me lay out a definition first. Definition: A non-empty open connected subset of $\mathbb{C}$ is called a domain . I am currently self-studying Complex Analysis and have been referring to multiple books. Right now, I am at the point of trying to understand the definition of holomorphic functions. What got me confused is that in some books, they define holomorphic functions on a domain (cf. Lecture Notes by Ivan F. Wilde) while on some books, they define holomorphic functions on open subsets of $\mathbb{C}$ (cf. Stein-Shakarchi Complex Analysis, Priestley's Intro to Complex Analysis, Lang's Complex Analysis). So, my question is, why is this so? Would there be major consequences from this slight difference of definition? Thanks in advance.","['complex-analysis', 'connectedness', 'analysis']"
3599614,What are the processes whose second moment equal their quadratic variation (like the Brownian motion)?,"If $B_t$ is a standard Brownian motion, we know that $$[B]_t=t=E[B_t^2]$$ where $[.]_t$ is the quadratic variation at time $t$ . Can we characterize all processes such that $$ [X]_t=E[X_t^2]$$ If not, what are large classes of processes that have this property ?","['stochastic-analysis', 'stochastic-processes', 'quadratic-variation', 'probability-theory', 'stochastic-calculus']"
3599619,Solve this ODE: $y' = \frac{(y-4x)}{(x-y)}$,"My goal, as stated in the title, is to solve this ODE: $$\frac{dy}{dx} = \frac{y-4x}{x-y}$$ I thought I had solved it by following a particular strategy that I learned, as follows: Let $u = \frac{y}{x}$ and rearrange so that $$\frac{dy}{dx} = \frac{u-4}{1-u}$$ By the product rule, $$\frac{du}{dx} = \frac{1}{x}\frac{dy}{dx} - \frac{y}{x^2}$$ and we can again rearrange to get $$u + x\frac{du}{dx} = \frac{dy}{dx}$$ Substituting this into our expression for $\frac{dy}{dx}$ above yields $$x\frac{du}{dx} = \frac{u^2 - 4}{1 - u}$$ and this is now a separable ODE. Separate: $$\frac{1-u}{u^2 - 4}du = \frac{1}{x}dx$$ and solve (the left hand side is a little more trouble than the right, but they are both easily integrable): $$-\frac{1}{4}ln|u-2|-\frac{3}{4}ln|u+2| = ln|x| + C$$ $$\therefore \space \space e^{-\frac{1}{4}ln|u-2|-\frac{3}{4}ln|u+2|} = e^{ln|x| + C}$$ $$\therefore \space \space |u+2||u-2| = c|x|$$ where I have just made a new constant $c = e^{C+1}$ . Now, if I have done everything right, I should just be able to substitute back in for $u$ , getting the implicit solution: $$|\frac{y^2}{x^3}-\frac{4}{x}| = c$$ Except that I have an answer key that tells me I should get this instead: $$|y+2x|^3|y-2x| = c$$ Am I just bad at algebra? How are these two implicit equations the same? If they aren't, where have I gone wrong?","['integration', 'change-of-variable', 'ordinary-differential-equations']"
3599635,"How to show the ""naive"" Weierstrass elliptic function does not converge absolutely","Several resources (e.g., Stein and Shakarchi, Complex Analysis) begin a discussion of the Weierstrass $\wp$ function by saying that, in order to construct a doubly periodic meromorphic function with lattice $L$ , a good first guess is the function $$ f(z) = \sum_{\omega \in L}\frac{1}{(z-\omega)^2}$$ however, the series fails to converge absolutely, which is why the $\wp$ function is defined the way it is.  I cannot, however, find any resource that actually goes about showing why the series fails to converge.  Maybe it is a trivial calculation and I am just not seeing the answer, but could someone please rigorously show that this series fails to converge absolutely?  Part of the problem I am having in understanding this series is that it is indexed over a set that is not the positive integers, so I'm not sure what a partial sum would even look like exactly. Any help is greatly appreciated, thanks!","['complex-analysis', 'elliptic-functions']"
3599661,Must large (infinite) groups have large automorphism groups?,"For every cardinal $\kappa$ , is there a cardinal $\lambda$ such that for all groups $G$ with $|G| > \lambda$ , we have $|\mathrm{Aut}(G)| > \kappa$ ? I believe a similar result holds for finite groups (see Groups with given automorphism groups ), but I'm wondering about the infinite case. If this fails, how badly does it fail? Are there arbitrarily large groups with finite automorphism group?","['automorphism-group', 'group-theory', 'abstract-algebra', 'cardinals']"
3599689,Probability: Random variable dice problem,"I'm not sure how to approach the below problem using random variable. Can I consider this as distinct events and calculate the average of each and then add them together? Can I use a binomial distribution? I'm very lost... You have 1 dice. Each face has a probability of 1/6. You roll the dice and if you get a 6, you win 50\$ otherwise you roll again. This time, if you get a 6, you get 10\$ otherwise you get nothing. The initial cost to play is 10\$. What is the average if you play 5 times?","['probability', 'random-variables']"
3599734,Differential Equation $dy/dx=y^{1/3}$ and condition $y(x_0)=y_0$ has infinite solutions,"Prove that the differential equation $$\frac{dy}{dx}= y^{1/3}$$ with the initial value of $y(x_0)=y_0$ has infinite solutions. I don't really understand the problem if I have to show that there are infinite solutions depending on the initial conditions or if it is something like if I proposed $(x_0,y_0)=(0,0)$ and prove that for that case the equation has infinite solutions. if you think is the first one could you explain how to do it.","['calculus', 'ordinary-differential-equations', 'real-analysis']"
3599739,$ \frac{X_n}{n}$ does not converge to $0$ almost surely,"Suppose that $\sigma_{n}^{2} \geq 0, n \geq 1,$ satisfy $\sum_{n=1}^{\infty} \frac{\sigma_{n}^{2}}{n^{2}}=\infty$ and without loss of generality that $\sigma_{n}^{2} \leq n^{2}$ for all $n \geq 1 .$ Show that there are independent random variables $X_{n}, n \geq 1$ with $E\left[X_{n}\right]=0$ and $\operatorname{Var}\left(X_{n}\right) \leq \sigma_{n}^{2}$ for which $X_{n} / n$ does not converge to 0 a.s., and hence $n^{-1} \sum_{i=1}^{n} X_{i}$ does not converge to 0 a.s. If we set $P(X_n=n) = P(X_n = -n) = \frac{{\sigma_n}^2}{2n^{2}}$ and $P(X_n=0)= 1 - \frac{{\sigma_n}^2}{2n^{2}}$ $\sum\limits_{n=1}^{\infty} \frac{{\sigma_n}^2}{2n^{2}} =\infty$ so we get $\sum\limits_{n=1}^{\infty} P(X_n=n) =\sum\limits_{n=1}^{\infty} P(X_n=-n) =\infty$ After this point, I believe I have to use Borel Cantelli  Divergence lemma. but I am getting confused, we get $P(X_n = n $ i.o. $)=1$ why is the above the same as 
 implies $P(X_n \geq n $ i.o. $)=1$ and how do we complete and show the remaining of the proof in detail? Should I use Cesaro's averages theorem?","['borel-cantelli-lemmas', 'self-learning', 'convergence-divergence', 'probability-theory']"
3599791,$a+b \mid ab$ from CMO 1996,"The question is from the 1996 Chinese Mathematical Olympiad. I can't find the solutions anywhere online. Find the smallest value of $K$ such that any $K$ -element subset of $\{1,2,\ldots,50\}$ contains two elements $(a,b)$ such that $a+b \mid ab$ . My first inclination was to find the conditions under which $a+b \mid ab$ . $ a+b \mid ab+b^2$ and $a+b \mid ab+a^2$ for all $(a,b)$ . If $a+b \mid ab$ , then $a+b \mid a^2$ and $a+b \mid b^2$ , which is not possible if $\gcd(a,b)=1$ . Therefore $\gcd(a,b)>1$ . Let $d = \gcd(a,b)$ , $a=kd$ , and $b=jd$ . Then $\gcd(k,j)=1$ . Then $a+b \mid ab \implies (k+j)d \mid kjd^2 \implies (k+j) \mid kjd$ . $\gcd(k,j)=1$ , so any prime divisor $f \mid kj \implies (f \mid k$ and $f \nmid j$ ) or ( $f \mid j$ and $f \nmid k$ ), so $f\nmid(k+j)$ . Thus $\gcd((kj),(k+j))=1$ , so $k+j \mid d$ . If $d>=25$ , then either $kd$ or $jd$ must exceed $50$ , so we need only consider the possibilities for $0<d<25$ . $d=1,2\implies\emptyset$ $d=3\implies(3,6)$ $d=4\implies (4,12)$ $d=5\implies(5,20),(10,15)$ $d=6\implies(6,12),(6,30)$ $d=7\implies(7,42),(14,35),(21,28)$ $d=8\implies(8,24),(24,40)$ $d=9\implies(9,18),(36,45)$ $d=10\implies(20,30),(10,40)$ $d=11\implies\emptyset$ $d=12\implies(12,24)$ $d=13,14\implies\emptyset$ $d=15\implies(15,30)$ $d=16\implies(16,48)$ $d=17\implies\emptyset$ $d=18\implies(18,36)$ $d=19,20\implies\emptyset$ $d=21\implies(21,42)$ $d=22,23\implies\emptyset$ $d=24\implies(24,48)$ Now, to solve the problem, we need to create the largest possible set containing no $2$ elements from a single set. This would be equivalent to eliminating as few elements as possible such that no two elements are chosen from the same pair. Now, from the eleven pairs $(3,6),(4,12),(5,20),(10,15),(7,42),(14,35),(21,28),(8,24),(9,18),(36,45),(16,48)$ there are no elements common to two pairs. Thus, at least $11$ elements must be eliminated. If ${6,12,20,15,42,35,28,24,18,45,48}$ are eliminated, then every pair has had at least one element eliminated. Thus, the largest possible subset $S$ such that there are no $a,b\in S : (a+b) \mid ab$ has $50-11=39$ elements. Thus, the answer is $40$ . Can someone verify if this is a valid method? I am a bit confused if there are any exceptions I have missed.","['contest-math', 'divisibility', 'elementary-number-theory', 'solution-verification', 'algebra-precalculus']"
3599797,A Gronwall-type inequality for $L^p$ norms,"Here is a problem from my homework, which asks me to show a Gronwall-type inequality. Let $1\leq\beta<\gamma\leq\infty, 0<T\leq\infty$ and let $f\in L^\rho(0,T)$ , where $1\leq\rho<\infty$ is defined by $\frac1\rho=\frac1\beta-\frac1\gamma$ . If $\eta\geq0$ and $\varphi\in L_{\text{loc}}^\gamma([0,T))$ satisfy $$\|\varphi\|_{L^\gamma(0,t)}\leq\eta+\|f\varphi\|_{L^\beta(0,t)},$$ for all $0<t<T$ . Prove that $$\|\varphi\|_{L^\gamma(0,t)}\leq\eta\Phi(\|f\|_{L^\rho(0,t)}),$$ for all $0<t<T$ , where $\Phi(s)=2\Gamma(3+2s)$ and $\Gamma$ is the Gamma function. I cannot see why the Gamma function appears here. Applying Hölder's inequality to the assumption gives that $$\|\varphi\|_{L^\gamma(0,t)}\leq\eta+\|f\|_{L^\rho(0,t)}\|\varphi\|_{L^\gamma(0,t)}.$$ Now we can do the iteration, but this process fails to give the desired result. Any help would be appreciated.","['inequality', 'partial-differential-equations', 'analysis', 'real-analysis']"
3599800,Show that a sequence is convergent,"I found this problem in real analysis and I have no idea how to start, I just need a hint let $x_n$ be a bounded sequence of real numbers, that satisfies: 1- $\lim_{n\to \infty} x_{n+1} - x_n = 0 $ 2- if $ A = \{x_n: \forall n\in \mathbb{N}\} $ then $A'$ is finite (This defines A as the range of $x_n$ and A' is the set of limit points of A) prove that $x_n$ is convergent for $x_n$ to converge it's enough to show that A' has only one element, that if $x \in A' $ and $y \in A'$ then $x = y$ I tried to deduce that from the definition of the set of limit points and no luck there. and since $x_n$ is bounded then it has a convergent subsequence, which converges to a point in A'. I don't know what to do next","['sequences-and-series', 'cauchy-sequences', 'real-analysis']"
3599818,Construct a subspace of a complete normed $K$-vector space with $(y_\mu)_{\mu \in M}$ as its orthonormal basis,"I've been reading Bosch's book ""Lectures on Formal and Rigid Geometry"". In the proof of Theorem 6 on page 26, which I will show below, he claimed that there is a subspace $V'$ of a complete normed $K$ -vector space $V$ with $(y_{\mu})_{\mu \in M}$ as its orthonormal basis. However, I wonder how to construct this subspace explicitly. Theorem 6. Let $K$ be a field with a complete valuation, and $V$ a complete normed $K$ -vector space with an orthonormal basis $(x_{\nu})_{\nu \in N}$ . Write $R$ for the valuation ring of $K$ , and consider a system of elements $$y_{\mu}=\sum_{\mu \in M}c_{\mu\nu}x_{\nu} \in V^{o}, \mu \in M$$ where the smallest subring of $R$ containing all coefficients $c_{\mu\nu}$ is bald. Then, if the residue classes $\tilde{y}_\mu \in \tilde{V}$ form a $k$ -basis of $\tilde{V}$ , the elements $y_\mu$ form an orthonormal basis of $V$ . Proof: The systems $(x_{\nu})_{\nu \in N}$ and $y_{\mu}=\sum_{\mu \in M}$ form a $k$ -basis of $\tilde{V}$ . So $M$ and $N$ have the same cardinality, and $M$ is at most countable. In particular, $y_{\mu}=\sum_{\mu \in M}$ is an orthonormal basis of a subspace $V' \subset V$ . ... Also perhaps I should give the definition of $\tilde{V}$ , which is $$\tilde{V}=\{x\in V:|x|\leq 1\}/ \{x\in V:|x| < 1\}$$ And the definition of an orthonormal basis:  Let $V$ be a $K$ -vector space. A system $(x_{\nu})_{\nu \in N}$ of elements in $V$ , where $N$ is finite or at most countable, is called a (topological) orthonormal basis of $V$ if the following hold: $|x_\mu|=1$ for all $\mu \in N$ . Each $x\in V$ can be written as convergent series $x=\sum_{\mu \in N}c_{\mu}x_{\mu}$ with coefficients $c_{\mu} \in K$ . For each equation $x=\sum_{\mu \in N}c_{\mu}x_{\mu}$ as in (2) we have $|x|=$ max $_{\mu \in N}|c_{\mu}|$ . In particular, the coefficients $c_{\mu}$ in (2) are unique. Thanks for reminding me. I should add the definition of ""bald"" as well: A ring $R$ with a multiplicative ring norm $|\cdot|$ such that $|a|\leq 1$ for all $a\in R$ is called bald if $$\text{sup}\{|a|:a\in R, |a|<1\}<1$$ A ring norm on R is a map $|\cdot|:R\rightarrow \mathbb{R}_{\geq0}$ satisfying: $|a|=0 \Leftrightarrow a=0$ $|ab|\leq |a||b|$ $|1|\leq 1$ $|a+b|\leq \text{max}\{|a|,|b|\}$ (and the norm is called multiplicative if instead of (2) we have $|ab|=|a||b|$ )","['rigid-analytic-spaces', 'algebraic-geometry']"
3599874,Properties of injective modules,"I am reading A course in Homological Algebra by Hilton and Stammbach. In the first chapter they showed that a $\Lambda$ -module is projective iff it is a direct summand of a free module. They then defined the categorical dual of projective modules, which are injective modules as follows: A $\Lambda$ -module is injective if for every homomorphism $\alpha:A\to I$ and every monomorphism $\mu:A \to B$ there exists a homomorphism $\beta: B \to I$ such that $\beta \mu = \alpha$ . Then proceed to show the following characterization for when $\Lambda$ is a PID: Let $\Lambda$ be a PID. A $\Lambda$ -module is injective iff it is divisible. Now this seems quite concerning to me because the characterization doesn't seem very ""dual-like"" to projective modules. Two questions natually arise: Does being a divisible module have any categorical relations to being free or being a direct summand? The characterization for injective modules is proved only for PIDs whereas the characterization for projective modules is true for all rings. Is there a generalization to all rings for the injective case, or is there a big-picture reason to why this fails? Because of my interest in K-theory, I have also two more questions: A special case of projective module is stably free module. Is there a categorical dual to stably-freeness and if so what's its relation to injectivity? Projective modules are used in the construction of the $K_0$ group for rings, I'd like to know if injective modules have any significance in the K-theories of rings? Update: Apparently I was too hasty in asking this question, as the next section of the book provides a better characterization, and that is A $\Lambda$ -module $I$ is injective iff it is a direct factor (coincides with direct summand in this case) of a cofree module. This is the kind of result that I was looking for, but the definition of cofree seems even more enigmatic, it is defined to be direct products of $\Lambda^* = \text{Hom}_\mathbb Z(\Lambda, \mathbb Q / \mathbb Z)$ , where $\Lambda ^*$ has the left module structure induced by the right module structure of $\Lambda$ . I am very puzzled by this $\mathbb Q / \mathbb Z$ . I found a thread on MO about cofree modules. Todd explains that free modules does not have a formal dual notion. The definition of cofree with $\mathbb Q/ \mathbb Z$ involved is somewhat ad hoc and imprecise. Considering Captain Lama's comment, I will accept that duality in modules aren't perfect.","['algebraic-k-theory', 'homological-algebra', 'injective-module', 'category-theory', 'abstract-algebra']"
3599893,Can you make a sphere out of a plane?,"I had this idea to build a model of Earth in Minecraft. In this game, everything is built on a 2D plane of infinite length and width. But, I wanted to make a world such that someone exploring it could think that they could possibly be walking on a very large sphere. (Stretching or shrinking of different places is OK.) What I first thought about doing was building a finite rectangular model of the world as like a mercator projection, and tessellating this model infinitely throughout the plane. Someone starting in the US could swim eastwards in a straight line across the Atlantic, walk across Africa and Asia, continue through the Pacific and return to the US. This would certainly create a sense of 3D-ness. However, if you travel north from the North Pole, you would wind up immediately at the South Pole. That wouldn't be right. After thinking about it, I hypothesized that an explorer of this model might conclude that they were walking on a donut-shaped world, since that would be the shape of a map where the left was looped around to the right (making a cylinder), and then the top was looped to the bottom. For some reason, by simply tessellating the map, I was creating a hole in the world. Anyway, to solve this issue, I thought about where one ends up after travelling north from various parts of the world. Going north from Canada, and continuing to go in that direction, you end up in Russia and you face south. The opposite is true as well: going north from Russia, you end up in Canada pointing south. Thus, I started to modify the tessellation to properly connect opposing parts of Earth at the poles. When going north of a map of Earth, the next (duplicate) map would have to be rotated 180 degrees to reflect the fact that one facing south after traversing the north pole. This was OK. However, to properly connect everything, the map also had to be flipped about the vertical axis. On a globe, if Alice starts east of Bob and they together walk North and cross the North Pole, Alice still remains east of Bob. So, going north from a map, the next map must be flipped to preserve the east/west directions that would have been otherwise rotated into the wrong direction. Now the situation is hopeless. After an explorer walks across the North Pole in this Minecraft world, he finds himself in a mirrored world. If the world were completely flat, it would feel as if walking North will take you from the outside of a 3D object to its inside. Although I now think that it is impossible to trick an explorer walking on infinite plane into thinking he is on a sphere-like world, a part of me remains unconvinced. Is it really impossible? Also, how come a naive tessellation introduces a hole? And finally, if an explorer were to roam the world where crossing a pole flips everything, what would he conclude the shape of the world to be?","['spheres', 'geometry']"
3600016,Two different roots for $P(x) = x^4+ax^2+bx+c$,"Let $a, b, c \in \mathbb{R}$ and $a > 0$ . Also let $P: \mathbb{R} \to \mathbb{R}$ , $P(x) = x^4+ax^2+bx+c$ . Show that the function has at most two different roots. My assumption was to use Bolzano's theorem, but I couldn't figure out how to use it here. Also I'm curious if we could use something like Vieta's formula here? Any help would be appreciated.","['calculus', 'analysis', 'real-analysis']"
3600103,1999 USAMO submission by Titu Andreescu,"[USAMO 1999 submission, Titu Andreescu] Let $n$ be an odd integer greater than $1$ . Find the number of permutations $p$ of the set $\{ 1, 2, …, n\}$ for which $$\def\x#1{\lvert p(#1)-#1\rvert} \x1+\x2+\cdots+\x n = \frac{n^2-1}2.$$ The solution is the following: My problem is that I can’t understand anything from line 4 of the solution (the line that starts with “The maximum...”) and on. Please help me understand!","['permutations', 'contest-math', 'proof-explanation', 'combinatorics', 'discrete-mathematics']"
3600131,Application of Cauchy's integral formula.,"Let $f$ be an entire fundtion satisfying $|f^{\prime}(z)|\le 2|z|$ for any $z \in \Bbb C$ . Then show that $f(z)=a+bz^2$ for some $a,b\in \Bbb C $ with $|b| \le 1$ . My trial : I tried to show that $f^{\prime\prime}(z)$ is bounded on $\Bbb C$ .So, I tried to find relation between $f^{\prime}$ and $f^{\prime\prime}$ . I mean, $|f^{\prime\prime}(z)|$ $\le$ {something with $f^{\prime}(z)$ product |z|} $\le R $ by using generalized Cauchy's integral formula. But, I failed... 
Further, I just thought it has to do with utilizing maximum modulus Theorem. But I had no idea of how to apply it.. Could anyone just give a few hints. it would be great help. Thansk!","['complex-analysis', 'cauchy-integral-formula']"
3600182,Least $n \in \mathbb{N}$ such that $2^{|n|} = \aleph_0$? [duplicate],"This question already has answers here : Does a countably infinite power set exist? (1 answer) Existence in ZF of a set with countable power set (2 answers) cardinality proof: prove that for any set $A, \ 2^{|A|} \neq |\mathbb{N}|$ [duplicate] (2 answers) How do I prove that there doesn't exist a set whose power set is countable? [duplicate] (2 answers) Closed 4 years ago . It is well known that $2^{\aleph_0}>\aleph_0$ . This seems to imply that there is an $n \in \mathbb{N}$ such that $2^{|n|} = \aleph_0$ . If so, what is known about the least permitted value of $n$ such that this statement is true?","['elementary-set-theory', 'cardinals']"
3600194,"Find the number of rational numbers $m/n$, where $m,n$ are relatively prime positive integers satisfying $m<n$ and $mn=25!$.","Question: Find the number of rational numbers $\frac{m}{n}$ s.t. $\gcd(m,n)=1\;\land\; m,n\in\mathbb N\;\land m<n\;\land\;mn=25!
$ My approach: Instead of taking $25$ in particular, let us take any $n\in\mathbb{N}$ and $n>1$ . Let $a_i$ be the highest power of the $i^{th}$ prime $p_i$ s. t. $p_i^{a_i}|n!$ . Now consider the multiset $$S_n=\{\underbrace{2,2,2,\cdots,2}_{a_1},\underbrace{3,3,3,\cdots,3}_{a_2},\cdots,\underbrace{p_k,p_k,p_k,\cdots,p_k}_{a_k}\}$$ where $p_k$ is the greatest prime that divides $n$ . Let us choose any block of primes from $S_n$ or a combination of them and multiply all of them together (let us call this product to be $P$ ) and take the remaining block of primes in $S_n$ and multiply them together (let us call this product to be $p$ ). Now observe that $\forall P,p$ , we have, $P\neq p$ . $\implies P<p\;\underline{\lor}\;P>p$ . Also, we have $\gcd(P,p)=1$ . Now suppose WLOG that $P>p$ , then setting $m=p$ and $n=P$ , yields one of our required rational number $\frac{m}{n}=\frac{p}{P}$ . And moving on like this we can find all of our required rational numbers. Now let us move on to find the number of such rational numbers for our given $n$ . Now consider the set $$S_n^{'}=\{2,3,\ldots,p_k\}.$$ Observe that selecting any subset of $S_n^{'}$ corresponds to one of our required rational number. Therefore, counting the total number of subsets would yield the total number of our required rational numbers. But, while doing this, observe that we count each solution twice. Therefore, taking the half of the total number of subsets of $S_n^{'}$ would yield our answer. Thus if the total number of primes that divides $n!$ is $p$ then the total number elements in $S_n^{'}$ is $p$ , and hence the total number of subsets of $S_n^{'}$ is equal to $2^p$ . Hence the total number of required solutions would be $2^{p-1}$ . Now let us consider the special case where $n=25$ . Since, there $9$ primes less than or equal to $25$ , implies $9$ primes divides $25$ , which in turn $\implies p=9$ . Therefore, the total number of required solutions= $2^{9-1}=2^8=256.$ Is my solution correct and rigorous enough and is there a shorter and better solution?","['number-theory', 'solution-verification']"
3600219,Does there exist a two-generated simple non-abelian group with specific properties?,"Does there exist a simple non-abelian 2-generated group $G$ and two elements $a, b \in G$ , such that $\langle \{a, b\} \rangle = G$ , $a^2 =1$ and $\forall c, d \in G$ $\langle \{c^{-1}bc, d^{-1}bd \} \rangle \neq G$ ? We know that every group $G$ is isomorphic to a subgroup of the symmetric group acting on $G$ by Cayley's theorem . So, if our example is finite then we can use the fact that if $G$ is a non-abelian finite, simple group of order $>2$ and $G$ is a subgroup of $S_n$ , then $G$ must be a subgroup of $A_n$ . However, the group in question is not necessarily finite.","['examples-counterexamples', 'finitely-generated', 'simple-groups', 'abstract-algebra', 'group-theory']"
3600220,Can any one recommend a statistics book?,"I am currently a second-year graduate student in statistics. I have taken the course with the textbook Statistical inference by George Casella and Roger L. Berger. I have learned some basic concepts such as sufficient statistics,  complete sufficient statistics,  UMVUE and etc. Though I found all these concepts are in one-dimensional case in this book.  Can anyone recommend a book that covers these concepts in a multivariate or high dimensional case?  Especially, a textbook with practice questions and a solution manual is preferred.","['statistical-inference', 'statistics', 'book-recommendation', 'reference-request', 'probability']"
3600243,Can I translate this problem from $L_2(\Omega)$ to $\mathbb{R}^{n}$?,"I would like to ask whether or not, my reasoning is correct. This is probably a dumb question, but I haven't done any functional analysis course, and am kind of worried if the following reasoning (which seems to me as intuitive) is all right. I am trying to solve a problem about some particular set of random variables $\ \mathcal{S}, \ $ $$\mathcal{S}\subset L_{2}(\Omega):= \{X: \mathbb{E}X^{2}<\infty\}.$$ I have proved that $S$ is a subset of $$\hat{\mathcal{S}}=\{X\in L_{2}(\Omega): \mathbb{E}|X-X_{0}|^{2}=1\},$$ for some r.v. $\ X_{0}\in L_2(\Omega). \ $ I want to find a bound/calculate $$\sup_{X_1,X_2,\cdots,X_n \in \mathcal{S}}\sum_{i,j}\mathbb{E}|X_i-X_j|^2.$$ And now, what i would like to say is: $X_1,X_2,\cdots,X_n \ $ are $\ n \ $ points in Hilbert space $\ L_{2}(\Omega), \ $ so they must lie on some $\ n-1 \ $ dimensional subspace $\ H \ $ . This subspace is (I believe) isometric to the space $\ \mathbb{R}^{n-1} \ $ . Let $\ x_{1},\cdots, x_{n} \ $ be corresponding set of points in $\mathbb{R}^{n-1}$ . Then $\ x_1,\cdots, x_n$ still lies on some sphere $\hat{\mathcal{S}}'$ with radius $1$ . Finally $$\sum_{i,j}\mathbb{E}|X_i-X_j|^2=\sum_{i,j}||x_i-x_j||^2,$$ so $$\sup_{X_1,X_2,\cdots,X_n \in \mathcal{S}}\sum_{i,j}\mathbb{E}|X_i-X_j|^2\le
\sup_{x_1,x_2,\cdots,x_n \in \hat{\mathcal{S}}'}\sum_{i,j}||x_i-x_j||^2$$ which is now an euclidean geometry problem (already solved). Is this reasoning correct? I will be glad for any help.","['hilbert-spaces', 'probability-theory', 'isometry', 'functional-analysis']"
3600258,Evaluate $\int_{-\frac{\pi}{4}}^{\frac{\pi}{4}} \frac{\cos x+1-x^2}{(1+x\sin x)\sqrt{1-x^2}}dx$,"$$\int_{-\frac{\pi}{4}}^{\frac{\pi}{4}} \frac{\cos x+1-x^2}{(1+x\sin x)\sqrt{1-x^2}}dx$$ which is W3,  Jozsef Wildt International Mathematical Competition 2019.","['integration', 'calculus', 'definite-integrals', 'contest-math']"
3600329,Finding a hypersurface whose intersection of Veronese surface is the given curve?,"I'm working on Hartshorne's Algebraic geometry exercise I.2.12. It says: Let $Y$ be the image of the 2-uple embedding $\rho:\mathbb{P}^2\rightarrow\mathbb{P}^5$ . If $C\subset Y$ is a closed curve (a curve is a variety of dimension 1), show that there exists a hypersurface (projective variety with dimension $n-1$ where $n=\dim \mathbb{P}^n$ . This is equivalent to zero set of a single irreducible homogeneous polynomial) $V\subseteq\mathbb{P}^5$ such that $V\cap Y=C$ In here, $\rho$ is a map for $x=(x_0,x_1,x_2)$ , $\rho(x)=(M_0(x),\cdots,M_5(x))=(x_0^2,x_1^2,x_2^2,x_0x_1,x_1x_2,x_0x_2)$ Since curve is a hypersurface in $\mathbb{P}^2$ , there is a homogeneous irreducible polynomial $f\in k[x_0,x_1,x_2]$ ( $k$ is a field) such that $C=\rho(\mathcal{Z}(f))$ (zeros of $f$ ). Some website ( here and question of here ) says like this:
Take $g=f^2\in k[M_0,\cdots M_5]$ in detail $f(x)^2=f(x_0,x_1,x_2)^2=g(M_0(x),\cdots M_5(x))$ and factorize $g=g_1\cdots g_r$ where each $g_i\in k[M_0,\cdots,M_5]$ is irreducible. (By here , each $g_i$ is homogeneous) Then there is one $g_i$ , let's say $g_1=h$ , such that $V=\mathcal{Z}(h)$ satisfies $V\cap Y=C$ . Showing $V\cap Y\subset C$ is clear: if $z\in V\cap Y$ , there is $y\in\mathbb{P}^2$ such that $z=\rho(y)$ (by $z\in Y$ ) and $0=g_1(z)\cdots g_r(z)=g(z)$ (note $g_1(z)=h(z)=0$ by $z\in V$ ). So we get $0=g(z)=g(M_0(y),\cdots M_5(y))=f(y)^2$ which implies $f(y)=0$ and $y\in \mathcal{Z}(f)$ . So $z=\rho(y)\in\rho(\mathcal{Z}(f))=C$ . My question starts from here: But $C\subset V\cap Y$ is unclear to me. If there is $z\in C$ , we have for some $y\in \mathbb{P}^2$ such that $z=\rho(y)$ and $f(y)=0$ . We get $g(z)=g(M_0(y),\cdots M_5(y))=f(y)^2=0$ . But we cannot say $g_1(z)=0$ (because there may be other $g_i\neq g_1$ such that $g_i(z)=0$ .) So we cannot say $z\in V$ . How can I pick specific irreducible $g_i$ (like in given pages) such that $\mathcal{Z}(g_i)= V$ ? Although this shows an answer, I want to check the claim in the above pages. ( Another thought: I think following is true: With the above setting, there are finite hypersurfaces $V_i\subset\mathbb{P}^5$ such that $(\bigcup_{i=1}^n V_i)\cap Y=C$ instead of the original problem.)",['algebraic-geometry']
3600470,Minimum value of $(\cos\theta_1+\cos\theta_2+\cos\theta_3)$,"If $\hat{x}$ , $\hat{y}$ and $\hat{z}$ are three unit vectors in three-dimensional space, then the minimum value of\ $|\hat{x}+\hat{y}|^2+|\hat{y}+\hat{z}|^2+|\hat{z}+\hat{x}|^2$ is: My Attempt : Let $\theta_1$ be angle between $\hat{x}$ and $\hat{y}$ , $\theta_2$ be angle between $\hat{y}$ and $\hat{z}$ and $\theta_3$ be angle between $\hat{z}$ and $\hat{x}$ . $\therefore \theta_1,\theta_2$ and $\theta_3$ are the angles between any 2 edges of a tetrahedron from a single vertex. $\therefore |\hat{x}+\hat{y}|^2+|\hat{y}+\hat{z}|^2+|\hat{z}+\hat{x}|^2=(2+2\cos\theta_1)+(2+2\cos\theta_2)+(2+2\cos\theta_3)$ . $=6+2(\cos\theta_1+\cos\theta_2+\cos\theta_3)$ Can anyone please tell me what to do next?","['maxima-minima', 'trigonometry', 'vectors']"
3600591,Equality in trace duality,"For $A,B\in\mathbb{R}^{n\times m}$ we have the trace duality property $$|\langle A, B \rangle|\leq \|A\|_1 \|B\|_{\infty}$$ where $\|A\|_p$ is the Schatten $p$ -norm (i.e. $\|\cdot \|_1$ is the nuclear norm equal to the sum of singular values, and $\|\cdot\|_{\infty}$ is the operator norm equal to the largest singular value) and the inner product is $\langle A, B \rangle = \text{tr}(A^{\top}B)$ . There are at least two methods to prove this inequality. One is using the Fischer-Courant min-max principle (see for example this question ), and the other is by the aid of symmetric gauge functions (see Chapter 4 of Matrix Analysis (1997) form Bathia). None of these proofs establish sufficient (or necessary) conditions to get an equality. Do anyone know a way to get equality?","['real-analysis', 'matrices', 'linear-algebra', 'matrix-analysis', 'duality-theorems']"
3600613,Knowing the limit of $f'(x)$ find the limit of $f(x)$,"We have that $f$ is differentiable on $(a, +\infty)$ with $a>0$ . I want to show that if $\displaystyle{\lim_{x\rightarrow +\infty}f'(x)=\ell}$ , then there are the following cases: If $\ell>0$ then $$\lim_{x\rightarrow +\infty}f(x)=+\infty\ \text{ and } \ \lim_{x\rightarrow +\infty}\frac{f(x)}{x}=\ell$$ If $\ell<0$ then $$\lim_{x\rightarrow +\infty}f(x)=-\infty\ \text{ and } \ \lim_{x\rightarrow +\infty}\frac{f(x)}{x}=\ell$$ If $\ell=0$ then $$\lim_{x\rightarrow +\infty}f(x)=? \ \text{ and } \ \lim_{x\rightarrow +\infty}\frac{f(x)}{x}=\ell$$ $$$$ Do we use the fact that $$f(x+1)-f(x)=\int_x^{x+1}f'(u)\,du$$ to find the limits of the function $f$ ?","['limits', 'functions', 'analysis']"
3600625,Higher covariant derivatives and the exterior derivative,"Let me start with the following tl;dr version of my question What is a higher-order derivative, in general? How does it relate to the exterior
  derivative and to differential forms? Suppose we have a bundle and a section $E \overset{\sigma}{\underset{\pi}{\leftrightarrows}} M$ . Assume we have a connection on $E$ . (One of the links assumes we   also have a connection on $\tau^*M$ ; assume that also, if you like.) It seems The $k$ th order derivative should be a bundle map $\bigoplus_{i=0}^k \otimes^i \tau M \to E$ over M. Perhaps it always will satisfy some condition (such as symmetry) that will allow us to pass to a quotient of $\bigoplus_{i=0}^k \otimes^i \tau M$ . The covariant derivative should take us from $k$ th order derivatives to $k+1$ st order derivatives. It should be multilinear in the entries. Regarding the last bullet, I could believe that the higher-order derivative might not always be found by an iterated derivative . Like in calculus where we have to recognize that a multidimensional integral isn't the same as an iterated integral, and under nice circumstances, they are equivalent. One suggestion is that a higher covariant derivative of a section $\sigma: M \to E$ is the prolongation $E \to J^k E$ induced by $\sigma$ . This answer gives an outline of what I'm looking for, but it does so in quite a vague way. This answer seems to be addressing the issue head-on, but I haven't a clue what he's doing with his notation. See also this question about higher covariant derivatives. This is maybe how an explanation could proceed: A higher-order covariant derivative $\nabla^k s$ of a section of a vector bundle $E \to M$ should be the prolongation $E \to J^k E$ of the $k$ th jet bundle $J^kE \to E$ . Sections of $J^kE \to E$ are elements of $\Gamma \left( \left( \bigoplus\limits_{i=0}^k\operatorname{Sym}^i \tau^* M \right) \otimes E \right)$ . So we can think of them like ""polynomials of degree $\leq k$ where we plug in tangent vectors and get out elements of $E$ ."" This maps nicely onto Taylor polynomials and $k$ th order approximations of a function. The anti-symmetry of the exterior derivative (alternately, the anti-symmetry of the wedge product) kills all but the first-order derivatives. (Becoming a little vague. This is what the first link above says, but does not explain.) (How can we make the last bullet rigorous? One relevant fact is that if $V$ is a vector space, and we view the symmetric and anti-symmetric tensors of order $k$ as subgroups of $\otimes ^kV$ (really they are quotients), then $\operatorname{Alt}^kV \cap \operatorname{Sym}^k V = 0$ except when $k=1$ .) We'd like to say something like The usual exterior derivative $d: \wedge^k \tau^*M \to \wedge^{k+1} \tau^*M$ or $d: \wedge^k \tau^*M \otimes E \to \wedge^{k+1} \tau^*M \otimes E$ somehow only captures one level at a time(?) of what the higher derivatives do? We also like anti-symmetry for modeling a ""volume of a parallelipiped""-type function which is multilinear and vanishes when there are collinear entries (like the determinant). And we like the exterior derivative for being dual to the boundary in Stokes' theorem. Hence we extract this information in differential geometry. This morning I've been boring through the ""Natural Operations..."" book by Kolar et al, but boy...it's encyclopedic, and has quite esoteric notation to boot. Kolar claims he's outlined what a higher-order derivative should be in generality, in an article called "" On the Absolute Differentiation of 
Geometric Object Fields "" from 1973. As the title suggests, that article is pretty obscure, and some of the math therein is, also, at least to me.","['connections', 'fiber-bundles', 'lie-derivative', 'differential-geometry']"
3600693,Find sum of given binomial series for $n>3$,We are given that $n>3$ and we have to find the sum of the series given by: $$S=xyz\binom{n}{0}-(x-1)(y-1)(z-1)\binom{n}{1}+...+(-1)^n(x-n)(y-n)(z-n)\binom{n}{n}$$ I figured out that the general term is $$t(r)=(-1)^r(x-r)(y-r)(z-r)\binom{n}{r}$$ but I see no obvious manipulations between the terms nor does any particular series strike my mind. Can someone provide an approach? Any help would be appreciated.,"['binomial-coefficients', 'combinatorics', 'sequences-and-series']"
3600695,Show that $\sqrt{1+x}<1+\frac{x}{2}$ for all $x>0$,"I am a little stuck on this question and would appreciate some help. The question asks me to prove that $\sqrt{1+x}<1+\frac{x}{2}$ for all $x>0$ . I squared both sides of the question to get $1+x<\frac{x^2}{4}+x+1$ for all $x>0$ . Then, I multiplied both sides by $4$ to get $4+4x<x^2+4x+4$ for all $x>0$ . I am a little stuck and was wondering what to do after this step and how to actually provide sufficient proof to say that this statement is true.","['proof-explanation', 'proof-writing', 'real-analysis']"
3600766,Proof verification: Possibly false argument in the proof of $\int_{I}g(x)dF(u)=\int_{I}g(u)F'(u)du$ (Riemann-Stieltjes),"In this paper, I am questioning the proof of the following lemma (Lemma 2, page 5): Assume $F$ is differentiable with $F'=f$ continuous. Then if $g$ is integrable, $$\int_{I}g(x)dF(u)=\int_{I}g(u)F'(u)du.$$ Here is the proof they give: ""We derive the result via Riemann-Stieltjes sums: In the sum $$\sum_{i=1}^{n}g(\xi_{i})(F(x_{i})-F(x_{i-1}))$$ the factor $(F(x_{i})-F(x_{i-1}))=f(\eta_{i})(x_{i}x_{i-1})$ for some $\eta_{i}\in(x_{i-1},x_{i})$ , by the Mean Value Theorem. Therefore $$\sum_{i=1}^{n}g(\xi_{i})(F(x_{i})-F(x_{i-1}))=\sum_{i=1}^{n}g(\xi_{i})f(\eta_{i})(x_{i}-x_{i-1}),$$ which we recognize as a Riemann sum for the integral $\int gfdu$ and the result is proven."" I dont think his final argument need to be true. Since I encountered a similar argument yesterday in another paper (page 25), I asked a similar question on Stack Exchange yesterday (notation differs a little). One of the comments convinced me even more that this argument may be false. The problem (in the proof that I copied above) is that the variable $\xi_{i}$ in $g$ and $\eta_{i}$ in $f$ may differ. Can someone please explain his last argument? I.e. the Riemann integral estimation. I am so confused. Any help is greatly appreciated.","['measure-theory', 'stieltjes-integral', 'proof-explanation', 'real-analysis', 'riemann-integration']"
3600932,Showing $\frac{y-x}{\cos{x}}(2+\sin{x}\frac{\cos{x}+\cos{y}+\cos{x}\cos{y}}{\sin{(y-x)}})\leq \pi $,"I was playing around a bit with trigonometric inequalities and found this: $$\frac{y-x}{\cos{x}}(2+\sin{x}\frac{\cos{x}+\cos{y}+\cos{x}\cos{y}}{\sin{(y-x)}})\leq \pi
$$ for $0\leq x<y \leq\pi/2$ . This can be checked on Matlab for example. I know it's not the prettiest of inequalities but I found it interesting that the value $\pi$ is achieved for the pair $(x,y)= (0,\pi/2)$ and thought there could be some elegant way to show it. I have tried various approaches with no luck. I think one promising approach is to show that the function is increasing with respect to $y$ when we fix $x$ but I found the calculations to be quite messy. I would appreciate any ideas on proving this.","['trigonometry', 'inequality']"
3600953,Proving a closed form for an integral with nested radicals,"Is there a simple way to prove the following identity? $$\int_0^1\sqrt{\frac{u^2-2-2 \sqrt{u^4-u^2+1}}{4 u^6-8 u^4+8 u^2-4}}\mathrm du=\frac{\sqrt{3+2 \sqrt{3}}}{2^{10/3}\pi}\Gamma\left(\frac13\right)^3$$ Context : This integral came up in trying to evaluate the complete elliptic integral of the first kind $K(m)$ ( $m$ is the parameter ), $$K\left(\exp\left(\frac{i\pi}{3}\right)\right)$$ in terms of simpler functions. In particular, $$K\left(\exp\left(\frac{i\pi}{3}\right)\right)=C\left(1+i \left(2-\sqrt{3}\right)\right)$$ and $C$ is the integral mentioned in the first part. I was able to show this through an indirect route, but I am hoping my messy method can be easily outdone.","['calculus', 'definite-integrals', 'special-functions']"
3600968,A term for a unimodal function similar to $\exp(-x^2)$,"Is there a term for a smooth $\mathbb R\to\mathbb R^+$ function that is unimodal (has one local maximum), and whose $n^{\text{th}}$ derivative has $(n+1)$ local extrema? An example of such a function is the Gaussian function $f(x)=\exp(-x^2)$ . A negative example of a unimodal function that does not fit these criteria is $f(x)=1/(10+x^4)$ . Its derivatives have too many extrema. Another negative example that shows that the number of extrema can grow exponentially (with respect to the order of a derivative) is the Rvachev function $f(x)=\operatorname{up}\left(x/4\right)$ .","['real-analysis', 'maxima-minima', 'definition', 'derivatives', 'terminology']"
3601030,Suppose you have functions $f$ and $g$ such that $f: Y \rightarrow T$ and $g: X \rightarrow Y$.,"I having a tough time understanding this?  I've learned about onto and 1 to 1 functions from a basic perspective, but I'm having a hart time understanding where to even start with this. (a) Suppose (f o g) is onto.  Claim g is onto. Prove or Disprove. (b) Suppose (f o g) is onto.  Claim f is onto. Prove or Disprove. (c) Suppose (f o g) is one to one.  Claim g is one to one.  Prove or Disprove (c) Suppose (f o g) is one to one.  Claim f is one to one.  Prove or Disprove We've been given a hint of one is true for onto, and one is true for one to one.",['functions']
3601056,Computing $\lim_{n \to \infty} \left[\left(\prod_{i=1}^{n}i!\right)^{1\over n^{2}} (n^{x})\right] $ if exists for certain $x\in\mathbb R$,"I came across this problem on my exam and even after three hours of trying I am not able to get through the problem. I think it can be expressed as the limit of a sum but I am not sure and all my attempts to do the same have failed. Question: If the limit $$\lim_{n \to \infty} \left[\left(\prod_{i=1}^{n}i!\right)^{\frac{1}{n^2}} (n^{x})\right]$$ exists and is finite what are the possible values of $x$ and the corresponding values of limit? I got something like $$e^{\ln{1\over n}\displaystyle\sum_{r=1}^n\left[1-{r-1\over n}\ln\left({r\over n}\right)\right]}$$ but I am having trouble with that r-1 over there. Can this be expressed as a Riemann sum? (So recently all the answers I have got seem to be skipping steps I get that all these people are professional in their own fields but can you please try to write answers for someone who has considerably low IQ than yourself, thanks for the same)","['limits', 'calculus', 'factorial']"
3601062,Find minima for the KL divergence,"The task is exercise 33.7 from the book Information Theory, Inference, and Learning Algorithms . The question is related to finding three distinc minima by minimizing the reversed KL divergence $KL(q||p)$ . The gist of the questions is as follows. Given the joint distribution $p(x,y)$ where rows represent $y$ and the columns $x$ . $$
\begin{array}{l|llll} 
& 1 & 2 & 3 & 4 \\
\hline 1 & 1 / 8 & 1 / 8 & 0 & 0 \\
2 & 1 / 8 & 1 / 8 & 0 & 0 \\
3 & 0 & 0 & 1 / 4 & 0 \\
4 & 0 & 0 & 0 & 1 / 4
\end{array}
$$ If we approximate p with q by minimizing $KL(q||p)$ 1) show that there are three distinct minima 2) what is the value of $KL(q||p)$ if we set $q(x,y) = p(x)p(y)$ ? We may use that $q(x,y) = q(x)q(y)$ . My progress so far: $$
\begin{array}{l}
\mathrm{KL}(q(x, y) \| p(x, y))=\sum_{x, y} q(x, y) \log \frac{q(x, y)}{p(x, y)}=\sum_{x, y} q(x) q(y) \log \frac{q(x) q(y)}{p(x, y)} \\
=\sum_{x} q(x) \log q(x)+\sum_{y} q(y) \log q(y)-\sum_{x, y} q(x) q(y) \log p(x, y)
\end{array}
$$ Setting derivative wrt $q(x)$ to zero: $$
\begin{array}{l}
\frac{\partial}{\partial q(x)} \operatorname{KL}(q(x, y) \| p(x, y))=0  \iff \\
\frac{\partial}{\partial q(x)} \sum_{x} q(x) \log q(x)+\frac{\partial}{\partial q(x)} \sum_{y} q(y) \log q(y)=\frac{\partial}{\partial q(x)}\sum_{x} q(x) \sum_{y} q(y) \log p(x, y)
\end{array}
$$ However i am not sure how to do these derivatives, that i suspect needs to be solved to proceed. And then solve wrt. $q(y)$ after. I am not very familiar with variational calculus. Any help is appreciated.","['statistics', 'information-theory', 'real-analysis', 'coding-theory', 'probability']"
3601070,What is the domain and range of $x^{\cos(x)}$?,"By all accounts (Wolfram, Desmos and my TI-nspire CAS calculator) the domain is apparently all $x>0$ , but subbing in things like $\frac{-\pi}{2}$ or $-\pi$ yields a real answer, despite their being negative and thus ostensibly outside the domain. Likewise, WolframAlpha was ""unable to determine range"" and has left me very confused about the whole thing. Similar story with $x^{\sin(x)}$ . Any help would be greatly appreciated!",['functions']
3601095,Can the Borel sets be recovered from the Lebesgue sets and the null sets?,"Suppose that one is given a set $X$ equipped with a pair of $\sigma$ -algebras $\mathcal{L}$ and $\mathcal{N}$ . Suppose that $\mathcal{L}$ and $\mathcal{N}$ came from putting a nice topology on $X$ , then putting a nice measure on the Borel sets $\mathcal{B}$ of $X$ , then letting $\mathcal{L}$ be the completion of $\mathcal{B}$ , then letting $\mathcal{N}$ be the measure-zero sets in $\mathcal{L}$ , then forgetting the measure, then forgetting the topology. Is there any hope that one could recover $\mathcal{B}$ from $\mathcal{L}$ and $\mathcal{N}$ ? If the topology is not assumed to be nice, then the answer is no, because for example the set of all usual Lebesgue subsets of $\mathbb{R}$ is the set of all Borel subsets of $\mathbb{R}$ when $\mathbb{R}$ is equipped with the weird topology referenced here .",['measure-theory']
3601102,Law of the Unconscious Statistician Notation,"The LOTUS as stated is something like this (for continuous case):
Let $X$ be a continuous real-valued random variable that follows some density function $f(x)$ . Let $g(X)$ be some real-valued measurable function. Then we have $$\mathbb{E}[g(X)] = \int_\mathbb{R}g(x)f(x)\ \mathrm{d}x.$$ My question is in the domain that $g$ is defined on. When we have $g(X)$ as a function of a random variable, what is its domain? My intuition is $\mathbb{R}$ because (implicitly perhaps) $X$ as a random variable is some measurable function from $\Omega \to\mathbb{R}$ . So in a sense, $g:\mathbb{R}\to\mathbb{R}$ and law is essentially show that $$\int_\Omega g(X(\omega))\ \mathrm{d}\mathbb{P} = \int_\mathbb{R} g(x)f(x)\ \mathrm{d}m$$ where $m$ is the Lebesgue measure on $\mathbb{R}$ . Is that a correct interpretation? If the above interpretation is correct, then would the following also be for LOTUS of two random variables. Suppose $X,Y$ are independent real-valued continuous random variables (real valued measurable functions from the same $\Omega$ ) with $f_X(x),\ f_Y(y)$ as their densities. Let $h(X,Y)$ be some real-valued measurable function. By the LOTUS, we must then have $$\mathbb{E}[h(X,Y)] = \int_{\mathbb{R}^2} h(x,y) f_X(x) f_Y(y) \mathrm{d}m_2$$ where $m_2$ is the Lebesgue measure on $\mathbb{R}^2$ . If my interpretation in the previous part is correct, then the domain of $h$ should be $h:\mathbb{R}^2\to\mathbb{R}$ and the law shows that $$\int_\Omega h(X(\omega),Y(\omega)) \mathrm{d}\mathbb{P} = \int_{\mathbb{R}^2} h(x,y) f_X(x) f_Y(y) \mathrm{d}m_2.$$ Is this a correct understanding / extension? Lastly, I'm looking to find a measure-theoretic proof of this law so I can better grasp its derivation (in contrast to a lot of the proofs that assume some monotonic behavior of $g$ ). Does anybody have a reference / could provide one? Thanks!","['expected-value', 'measure-theory', 'probability-theory']"
3601104,What is area of circle given areas of $4$ squares,"I can't find a way to solve this, I know that by using power of the point the other square area is 64cm^2 and that its side length is 8, but for the area of the circle I'm not too sure where to start, can someone help?","['area', 'circles', 'geometry']"
3601223,"The minimum constant that increases the number sequence, which has fixed start number and end number. [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. This question is not about mathematics, within the scope defined in the help center . Closed 4 years ago . Improve this question This is the original problem: Suppose there is a sequence of 20 cells, the first cell contains number 1 and the last cell contains 50. We would like to fill all cells with integer numbers in such a way that numbers in the neighbouring cells differ by at most k. For which minimal k this is possible? To my understanding, I figure we can just find the available k to increase from 1 and the number that after the addition and so on to the final number 50. So I wrote a program to find this k. I assume the k is 2, and the result is following: let nums = [];
let k = 2;

for (let i = 1; nums.length < 20; i += k) {
    nums.push(i);
}

console.log(nums);
// [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39] Since the last number is way smaller than 50, then I tried k = 3, here’s what I got: let nums = [];
let k = 3;

for (let i = 1; nums.length < 20; i += k) {
    nums.push(i);
}

console.log(nums);
// [1, 4, 7, 10, 13, 16, 19, 22, 25, 28, 31, 34, 37, 40, 43, 46, 49, 52, 55, 58] It’s obvious that when k = 3, the last number has outnumbered than 50… so it’s not 3. Then I tried the number within the range 2 to 3, and I got 2.5 is the closest one to make the whole sequence reach at 50. But the question asks for an integer… so 2.5 is incorrect… But 2 is incorrect either... Did I comprehend the question in a wrong way? Thanks in advance!","['discrete-mathematics', 'sequences-and-series']"
3601272,"Proving $\sin(\tanh x) \ge \tanh(\sin x)$, for $x \in [0,\pi/2]$","Earlier, a very interesting proof of an inequality has been proposed at MSE: How prove this inequality $\tan{(\sin{x})}>\sin{(\tan{x})}$ Here the question is: How to prove that $$\sin(\tanh x) \ge \tanh(\sin x), ~~ \text{for}~~ x \in [0,\pi/2]$$ Interestingly, the first three terms of the Mclaurin series are identical for both the functions.","['calculus', 'inequality', 'sequences-and-series']"
3601299,If $A$ and $B$ have non-negative eigen values then can we conclude that $A+B$ has non-negative eigen values?,Let $A$ and $B$ be $n\times n$ matrices whose all eigen values are non-negative real numbers. What can I say about the signs of the eigen values of $A+B$ ? First of all is it possible that the eigen values of $A+B$ may not be real? Of course if $A$ and $B$ are symmetric and have non-negative eigen values then it is easy to see that $A+B$ will also have non-negative eigen values (this is just equivalent to positive semidefiniteness). So I am only interested in the non-symmetric case. Thank you.,"['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
3601308,Topology of Uniform Convergence and Compact-Open Topology,"Let $\mathbb{R}^i$ be equipped with their Euclidean topologies (for $i=n,m$ ) and consider the following topologies on $C(\mathbb{R}^n,\mathbb{R}^m)$ : Topology of Pointwise convergence In Nagata's book, it is shown that the topology of pointwise convergence is equivalent to the point-open topology, which is generated by the sub-basic sets $$
\left\{f \in C(\mathbb R^n, \mathbb R^m) : f(x) \subseteq O \right\}, \quad x \in \mathbb R^n,\ O\subseteq \mathbb{R}^m \text{ open}.
$$ Topology of Compact Convergence Similarly, in the same book, it is shown that the topology of compact-convergence (a.k.a. uniform convergence on compacts) is well-known to be equivalent to the compact-open topology on $C(\mathbb{R}^n,\mathbb{R}^m)$ which can be described by the sub-basic sets $$
\left\{f \in C(\mathbb R^n, \mathbb R^m) : f(K) \subseteq O \right\}, \quad K \subseteq \mathbb R^n \text{ compact, } O\subseteq \mathbb{R}^m \text{ open}.
$$ Topology of Uniform Convergence From these equivalences one immediately has that compact convergence refines pointwise convergence.  Now, it is also clear that uniform convergence refines compact convergence.  Is there a sub-base of the topology of uniform convergence of the form $$
\left\{
f \in C(\mathbb{R}^n,\mathbb{R}^m):\, 
f(A) \subseteq O
\right\}, \quad A \in \mathcal{A}, \ O\subseteq \mathbb{R}^m\mbox{ open},
$$ where $\emptyset \neq \mathcal{A}\subseteq 2^{\mathbb{R}^n}$ is a collection of non-empty subsets of $\mathbb{R}^n$ ?","['general-topology', 'definition', 'functional-analysis', 'uniform-convergence']"
3601317,Measure Induced by Integral is Regular if Original Measure Regular,"I am trying to prove the following question: Let $(E,\mathcal{A},\mu)$ be measure space, $g$ positive measurable function. Then we have that $\nu := \int_{A}gd\mu$ is a positive measure on $\mathcal{A}$ . Suppose $E$ is now locally compact and Hausdorff and that open sets of $E$ are $\sigma$ - compact. Suppose also that $\mathcal{A}$ is the Borel $\sigma$ -algebra, $\mu$ is a regular measure, and $g\in L^p(\mu)$ for some $p\in [1,\infty]$ . Then show that $\nu$ is regular. As for this question, my attempt is as follows, and yet I am not sure if it is correct. Let $V$ be an open set, $V = \cup_{n\ge 1} H_n$ , where $H_n$ are compact set. Then, let $H_1\prec f_1\prec V$ . Denote $K_i$ as the support for $f_i$ and define $H_1\cup \dots\cup H_n \cup K_1 \cup\dots \cup H_n \prec f_{n+1}\prec V$ . Then $(f_n)$ is increasing sequence and its limit is $\mathbb{1}_{V}$ . Now, by monotone convergence, if q is the conjugate component of $p$ $$\nu(V) = \lim_{n\to \infty} \int f_n d\nu = \lim \int f_ng\ d\mu = \int g \mathbb{1}_V \ d\mu \leq \|g\|_p \left(\int \mathbb{1}_V \ d\mu\right)^{1/q} = \|g\|_p (\nu(V))^{1/q}$$ Now let $A\in \mathcal{A}$ be a Borel set, $\epsilon >0$ , then by regularity of $\mu$ , $\exists K$ compact, $V$ open s.t. $K\subset A \subset V$ and $\nu(V\setminus K) < \epsilon$ . Note that compact sets are closed, so $V\setminus K$ is open, then $\nu(V\setminus K) \leq \|g\|_p (\nu(V\setminus K))^{1/q} < \|g\|_p \epsilon ^{1/q}$ , and this gives the regularity of $\nu$ . I do realize that there may be flaws in this proof and I would really appreciate it if someone could help. Thanks!","['measure-theory', 'lebesgue-integral']"
3601332,Conditional expectation of i.i.d random variables,"consider the sum of random variables $Q_k=\sum_k R_k $ , $R_k$ are i.i.d.
Now I want to calculate: $$E(Q_j| Y_{k+j}=n) =j \frac{k}{k+j}$$","['expected-value', 'probability-theory', 'probability']"
3601351,Gradient of $A \mapsto \sigma_i (A)$,"Let $ A $ be an $m \times n$ matrix of rank $ k \le \min(m,n) $ . Then we decompose $ A = USV^T $ , where: $U$ is $m \times k$ is a semi-orthogonal matrix. $S$ is $k \times k$ diagonal matrix , of which its diagonal entries are called singular values
of $ A $ . we denote them by $ \sigma _i = S_{ii} $ . $V$ is $n \times k$ semi-orthogonal matrix. Definition: a semi-orthogonal matrix $ Q $ is a non-square matrix where $ Q^{T}Q=I $ . This is the singular value decomposition (SVD) of matrix $ A $ . We define a function $ f_i: \mathbb R^{ m \times n} \to \mathbb R $ by $ f_i (A) = \sigma_i (A) $ . I am interested in finding the gradient of $ f_i $ in order to practice matrix defferentiation. I hope you can help me starting with the first steps. Here are the hints that I have been given in order to find the solution, and feel free to use them: Use the product rule of differentials to calculate $ dA $ where A is considered as function of $ U $ , $ S $ and $ V $ . The entries of the diagonal of anti-symmetric matrix are all zeros. The Hadamard product of two matrices $ A,B $ of the same size , is denoted by $$ (A \circ B )_{ij} = A_{ij} \cdot B_{ij} $$ Use the cyclic property of the trace operator. That is: $$\mbox{Tr}(ABC) = \mbox{Tr}(CAB) = \mbox{Tr}(BCA)$$ The trace of a scalar is a scalar. That is, given $ a \in \mathbb R $ : $$ \mbox{Tr}(a) = a $$ I stuck right at the beginning, I found that the product rule is: $$ dA = dUSV^{T} +  UdSV^{T}  +  USdV^{T}  $$ Also, I have tried to calculate $ A^{T}A $ as trying to find a useful manipulation where I can use it for the solution, and I got that it is equal to: $ VS^{T} SV^{T} $ .
First of all, is this what they meant by the product rule? And, second, how do I continue from here?","['non-smooth-analysis', 'matrices', 'matrix-calculus', 'derivatives', 'singular-values']"
3601356,"A function which is continuous everywhere, but not differentiable at any point","Let $f: \mathbb{R} \to \mathbb{R}$ be the function $$f(x) : = \sum_{n=1}^\infty 4^{-n} \cos (32^n \pi x).$$ (a) Show that this series is uniformly convergent, and that $f$ is continuous. (b) Show that for every integer $j$ and every integer $m \ge 1$ , we have $$\left|f\left(\frac{j+1}{32^m}\right) - f\left(\frac{j}{32^m}\right)\right| \ge 4^{-m}.$$ (Hint: use the identity $$\sum_{n=1}^\infty a_n = \left(\sum_{n=1}^{m-1} a_n\right) + a_m + \sum_{n=m+1}^\infty a_n$$ for certain sequences $a_n$ . Also use the fact that the cosine function is periodic with period $2 \pi$ , as well as the geometric series formula. Finally you will need the inequality $|\cos(x) - \cos(y)| \le |x -y|$ for any real number $x$ and $y$ . (c) Using (b), show that for every real number $x_0$ , the function $f$ is not differentiable at $x_0$ . (Hint: for every $x_0$ and every $m\ge 1$ , there exists an integer $j$ such that $j \le 32^mx_0 \le j+1$ .) (a) can be shown using the Weierstrass M test. $4^{-n} \cos(32^n \pi x) \le 4^{-n}$ for all $x$ , and $\sum_{n=1}^\infty 4^{-n} < \sum_{n=1}^\infty 2^{-n} =1$ . For (b), I first expand the equation out as the hint suggests $$\sum_{n=1}^{m-1} 4^{-n} [\cos (32^n \pi \frac{j+1}{32^m})) -\cos (32^n \pi \frac{j}{32^m})]  + 4^{-m} [\cos (\pi (j+1)) -\cos (\pi (j))] + \sum_{n=m+1}^\infty 4^{-n} [\cos (32^n \pi \frac{j+1}{32^m})-\cos (32^n \pi \frac{j}{32^m}) ].$$ It turns out that the middle term is either $4^{-m}2$ if $j$ is odd or $4^{-m}(-2)$ if $j$ is even. The last term is cancelled out due to $2\pi$ periodicity. However, I am not sure how to deal with the first term, and why we need the inequality $|\cos(x) - \cos(y)| \le |x -y|$ . I also appreciate if you give some hint for (c). Thanks in advance.","['trigonometry', 'real-analysis']"
3601358,Integral of function over its derivative,"I am looking for a solution to the following integral:
For a function $f(x)$ , $$ \int \frac{f}{f'}dx, $$ where $f'$ is the derivative of $f$ with respect to $x$ . It is clear that $\int \frac{f'}{f} dx = \log(f)$ , but I have no idea how to solve the above one. Any help would be greatly appreciated!! Cheers, Marc","['integration', 'fractions', 'derivatives']"
3601388,"In prime characteristic, is being $N$-1 a local property?","A Noetherian domain $R$ with fraction field $K$ is said to satisfy $N$ -1 if the integral closure of $R$ in $K$ is module finite over $R$ . My question is: Let $R$ be a Noetherian domain of finite Krull dimension such that $R$ has prime characteristic. If for every prime ideal $P$ of $R$ , the domain $R_P$ satisfies $N$ -1, then does $R$ itself necessarily satisfy $N$ -1 ? I know the answer is yes if we moreover assumed $R_f$ is normal for some $0\ne f \in R$ . ( https://stacks.math.columbia.edu/tag/0333 ). Also, the reason I required prime characteristic is because in characteristic zero, $N$ -1 is equivalent to $N$ -2  ( https://stacks.math.columbia.edu/tag/032M ) and it is known that $N$ -2 is not a local property , counterexample exists in any equicharacteristic ( https://mathoverflow.net/questions/40935/on-noetherian-and-japanese-rings ) . Please help.","['integral-extensions', 'algebraic-geometry', 'commutative-algebra']"
3601427,Compute $\lim \limits_{n\to \infty} \int_3^4 (-x^2+6x-8)^\frac{n}{2} dx$,"Compute $$\lim \limits_{n\to \infty} \int_3^4 (-x^2+6x-8)^\frac{n}{2}dx.$$ I am interested in a method to compute this as simply as possible. I know that by DCT this is $0$ , but I am not allowed to use it. With the substitution $t=x-3$ I got that this is $\int\limits_0^1 (1-t^2)^\frac{n}{2}dt$ and by using that $e^x\ge x+1, \forall x\in \mathbb{R}$ I could show that the limit is $0$ . This is anyway pretty complicated for the level of the exam where this was given, I would be interested in something even easier. Is it possible to write a recurrence relation for instance? EDIT: Based on Ian's answer I came up with the following solution and I would like to know whether it works: Let $\epsilon \in (0,1)$ and $I_n=\int_0^1 (1-t^2)^\frac{n}{2} dt$ . $$I_n=\int_0^{\epsilon}(1-t^2)^{\frac{n}{2}}dt+\int_{\epsilon}^{1}(1-t^2)^{\frac{n}{2}}dt\le \epsilon + (1-\epsilon^2)^\frac{n}{2}, \forall n\in \mathbb{N}$$ After we take the limit as $n\to \infty$ we get that $\lim\limits_{n\to\infty} I_n \le \epsilon, \forall \epsilon \in (0,1)$ and if we now let $\epsilon \searrow 0$ it follows that $\lim\limits_{n\to\infty} I_n \le0$ and since $I_n\ge 0$ we get that the limit is $0$ . I think this is basically what Ian did, but I would like to know whether it is correct to write it like this.","['limits', 'calculus', 'definite-integrals', 'real-analysis']"
3601442,Finding the value of k in the following limit,"Let $f :\mathbb{R}\to \mathbb{R}$ be a continuous function with period $1$ and $$\lim_{n\to\infty}\int_0^1\sin^2(\pi x)f(nx)dx= \frac{1}{k}\int_0^1f(x)dx.$$ Find $k$ . My approach till now: Applying half angle formula $2\sin^2(x) = 1-\cos(2x)$ I got : $$\frac{1}{2}\int_0^1f(nx)dx-
\frac{1}{2}\int_0^1\cos(2\pi x)f(nx)dx.$$ I can't think of a way forward from here without applying integration by parts but i don't know if its right to apply it as we don't know about the differentiability of the function $f$ . Please help me with this problem.","['definite-integrals', 'calculus', 'functions', 'limits', 'trigonometry']"
3601493,An inequality involving homogeneous polynomials,"Let $x_1, x_2, \dots x_k \ge 0$ be non-negative real numbers. Does it follow that $$k \left( \sum_{i=1}^k x_i^3 \right)^2 \ge \left( \sum_{i=1}^k x_i^2 \right)^3 ? $$ This seems like something that might easily follow from standard inequalities like Jensen's inequality? (Now I am embarrassed that I hadn't really carefully tried Jensen before asking. As a penance, I will post a solution using Jensen's inequality.)","['jensen-inequality', 'multivariable-calculus', 'symmetric-polynomials', 'inequality', 'holder-inequality']"
3601496,Amount of possible distributions of 7 different coins among 3 different pockets.,"So the exercise states the following: ""There are 7 different coins and 3 different pockets. How many different ways to distribute those coins among the pockets do we have, considering that none of the pockets should be left empty"" I calculated all the cases possible $3^7=2187$ in the previous exercise. So I calculated all the cases that don't suit me, which are the cases when at least one of the pockets is empty, which gave me $3*2^7=384$ . So in the end, the result is $2187-384=1803$ . Is that a correct approach?","['combinatorics', 'discrete-mathematics']"
3601525,Lowest upper bound on matrix norm,"Let $A \in \mathbb{R}^{d \times d}$ be an invertible real matrix and $A'$ the matrix obtained from $A$ by setting all diagonal elements to $0$ , namely $$A'_{ij} = \begin{cases} A_{ij} & \text{if } i \neq j \\
0 & \text{otherwise.}
\end{cases}$$ I can prove that $\lVert A' \rVert_2 \leq \min(2, \sqrt{d})\lVert A \rVert_2$ where $\lVert \cdot \rVert_2$ is the $2$ -norm (operator norm), but I don't think the bound is tight. I ran $20$ million samples with entries of $A$ generated both uniformly across integers from $-10$ to $10$ and from a standard normal distribution, and got $$\lVert A' \rVert_2 \leq \begin{cases} \lVert A \rVert_2 & \text{for } d=2 \\
\approx 1.29 \lVert A \rVert_2 & \text{for } d=3 \\
\approx 1.339 \lVert A \rVert_2 & \text{for } d=4 \\
\approx 1.346 \lVert A \rVert_2 & \text{for } d=5 \\
\approx 1.28 \lVert A \rVert_2 & \text{for } d=6.
\end{cases} $$ Any ideas on what the lowest upper bound would be as a function of $d$ ?","['matrices', 'matrix-norms', 'upper-lower-bounds', 'spectral-norm']"
3601577,Conditions for Fubini's theorem in simple terms,"Could someone explain the conditions required to satisfy Fubini's theorem in layman's terms, without going into measure theory? I'm a high school student trying to gain a simple understanding of when Fubini's theorem doesn't apply, but everything I've found online is in terms of measure spaces. Would it be possible to explain the conditions in terms of continuity and boundedness over the region of integration?","['integration', 'multivariable-calculus', 'multiple-integral', 'fubini-tonelli-theorems']"
3601605,Unfriendly function to study,"Good morning/afternoon, Our professor gave us this function to be studied: $$y = f(x) = x + 2 - 3\arcsin\left(\frac{x^2-1}{x^2+1}\right)$$ But I am having many troubles with this. Here is what I did: Domain This was rather easy for I needed to set the argument of the arcsine between $-1$ and $1$ and solve: $D: \mathbb{R}$ . Axis intersections For $x = 0$ , $f(0) = 2 + \frac{3}{2}\pi$ and that was ok. But here comes the pain: how can I solve the other intersection? $y = 0$ means some $x$ to be found... how? Sign of the function How to manage $f(x) > 0$ ? Limits and asymptotes That was easy (I hope): there are no vertical or horizontal asymptotes, but there is an obliquitous one: indeed $$m = \lim_{x\to +\infty} \frac{f(x)}{x} = 1$$ $$q = \lim_{x\to +\infty} f(x) - mx = 2 + \frac{3}{2}\pi$$ Hence I have a line! Max and min Another trouble: Computing the derivative I got, explicitly $$f'(x) = 1 - \frac{6x}{|x|(x^2+1)}$$ Which shows me that $x = 0$ is a non derivability point. Plotting the function made me to see that $x = 0$ seems line a cusp point. But I did not understand why. I tried to read the definition of a cusp (limits are infinite and of different signs, like in $\sqrt{|x|}$ ) but I cannot get why then $1/x$ has no cusp. Limits at $0^+$ and $0^-$ are infinite and of different signs! Anyway: this put me on hold for I cannot go on with maxima and minima. I tried to solve it anyway, getting $f'(x) = 0$ with $x = \pm\sqrt{5}$ but it seems really wrong.. Any help? Thank you so much!","['calculus', 'functions', 'derivatives']"
3601607,"Finding roots of $\sum\limits_{n = - \infty }^ \infty n z^n q^{n^2} =0 $ , $z_k=u_k(q)$","The Jacobi triple product identity is: $$F(z,q)=\prod\limits_{n=1}^{ \infty }(1-q^{2n})(1+zq^{2n-1})(1+z^{-1}q^{2n-1})=\sum\limits_{n = - \infty }^ \infty z^n q^{n^2}  $$ where $|q|<1$ All roots of $F(z,q)=0$ for z can be expressed as: $$z_k=-q^{2k-1}$$ where $k$ is an integer I would like to find similar expansion for $\sum\limits_{n = - \infty }^ \infty n z^n q^{n^2} $ like The Jacobi triple product identity. $$Q(z,q)=\sum\limits_{n = - \infty }^ \infty n z^n q^{n^2} $$ where $|q|<1$ . It is obvious that $z=1$ and $z=-1$ $$Q(1,q)=Q(-1,q)=0$$ $z=1$ and $z=-1$ are trivial roots for $Q(z,q)=0$ Can we express roots ( $z_k=u_k(q)$ ) as known functions such as Theta functions , etc? I would like to share my attempt to find $z_k=u_k(q)$ : $$Q(z,q)=\sum\limits_{n = - \infty }^ \infty n z^n q^{n^2} $$ $$Q(z,q)=(z-z^{-1})q+2(z^2-z^{-2})q^4+3(z^3-z^{-3})q^9+4(z^4-z^{-4})q^{16}+5(z^5-z^{-5})q^{25}+.......$$ $$Q(z,q)=(z-z^{-1})q+2[(z-z^{-1})(z+z^{-1})]q^4+3[(z-z^{-1})(z^2+1+z^{-2})]q^9+4[(z-z^{-1})(z^3+z+z^{-1}+z^{-3})]q^{16}+5[(z-z^{-1})(z^4+z^2+1+z^{-2}+z^{-4})]q^{25}+.......$$ $$Q(z,q)=(z-z^{-1}) \big[ q+2(z+z^{-1})q^4+3[(z+z^{-1})^2-1)]q^9+4[(z+z^{-1})^3-2(z+z^{-1})]q^{16}+5[(z+z^{-1})^4-3(z+z^{-1})^2+1]q^{25}+.......\big]$$ We can easily see that trivial roots $z=1,-1$ can be gotten from $z-z^{-1}=0$ Other roots can be gotten from $$Q(z,q)=(z-z^{-1})\big[(q-3q^9+5q^{25}+....)+(z+z^{-1})(2q^4-8q^{16}+...)+(z+z^{-1})^2(3q^9-15q^{25}+....)+(z+z^{-1})^3(4q^{16}+....)+(z+z^{-1})^4(5q^{25}+....)+...\big]$$ We can write that $$Q(z,q)=(z-z^{-1})\big(a_0(q)+a_1(q)(z+z^{-1})+a_2(q)(z+z^{-1})^2+a_3(q)(z+z^{-1})^3+a_4(q)(z+z^{-1})^4+.....\big)$$ $$z+z^{-1}=T(q)$$ If $T(q)$ is root of $a_0(q)+a_1(q)T(q)+a_2(q)T(q)^2+a_3(q)T(q)^3+.....=0$ 2 roots have a relationship  : $u_1=\frac{T(q)+\sqrt{T(q)^2-4}}{2}$ ; $u_{-1}=\frac{T(q)-\sqrt{T(q)^2-4}}{2}$ $u_1=\frac{1}{u_{-1}}$ Some relations for $ Q(z,q) $ may also be helpful $$Q(zq^2,q)=\sum\limits_{n = - \infty }^ \infty n z^n q^{n^2+2n} $$ $$zqQ(zq^2,q)=zq\sum\limits_{n = - \infty }^ \infty n z^n q^{n^2+2n} $$ $$zqQ(zq^2,q)=\sum\limits_{n = - \infty }^ \infty n z^{n+1} q^{n^2+2n+1} $$ $$zqQ(zq^2,q)=\sum\limits_{n = - \infty }^ \infty (n-1) z^{n} q^{n^2} $$ $$zqQ(zq^2,q)=\sum\limits_{n = - \infty }^ \infty n z^{n} q^{n^2}  -\sum\limits_{n = - \infty }^ \infty z^{n} q^{n^2}$$ $$Q(z,q)-zqQ(zq^2,q)= \sum\limits_{n = - \infty }^ \infty z^{n} q^{n^2}$$ $$Q(zq^2,q)-zq^3Q(zq^4,q)= \sum\limits_{n = - \infty }^ \infty z^{n} q^{n^2+2n}$$ $$zqQ(zq^2,q)-z^2q^4Q(zq^4,q)= \sum\limits_{n = - \infty }^ \infty z^{n+1} q^{n^2+2n+1}$$ $$zqQ(zq^2,q)-z^2q^4Q(zq^4,q)=\sum\limits_{n = - \infty }^ \infty z^{n} q^{n^2}$$ $$Q(z,q)-zqQ(zq^2,q)=zqQ(zq^2,q)-z^2q^4Q(zq^4,q)$$ $$Q(z,q)+z^2q^4Q(zq^4,q)=2zqQ(zq^2,q)   \tag{1}$$ Other relation can be written as: $$\frac{\partial F(z,q)}{\partial z}=\sum\limits_{n = - \infty }^ \infty n z^{n-1} q^{n^2}$$ $$Q(z,q)=z\frac{\partial F(z,q)}{\partial z}  \tag{2}$$ Thank you for answers and comments I wish Healthy days for all people in the world. EDIT:31/03/2020 Because $u_1, u_{-1}$ roots have relation  : $$u_1=\frac{1}{u_{-1}}$$ and if roots are $u_k(q)$ :  where $k$ positive integer We can write the expansion of $Q(z,q)$ as: $$Q(z,q)=A(q) (z-z^{-1})\prod\limits_{k=1}^{ \infty }(1-\frac{z}{u_k(q)})(1-\frac{z^{-1}}{u_k(q)})  \tag{3}$$ The relation (3) satisfies $Q(z^{-1},q)=-Q(z,q)$ $A(q),u_k(q)$ only depend on $q$ . I haven't found them yet . I have been looking for methods to find them. Thanks for any helps to find them. EDIT:  7th April 2020 I would like to add another relation . That can be helpful to find $A(q),u_k(q)$ $$F(z,q)=\prod\limits_{n=1}^{ \infty }(1-q^{2n})(1+zq^{2n-1})(1+z^{-1}q^{2n-1})$$ $$\ln F(z,q)=\ln \prod\limits_{n=1}^{ \infty }(1-q^{2n})+  \ln \prod\limits_{n=1}^{ \infty } (1+zq^{2n-1}) + \ln \prod\limits_{n=1}^{ \infty }(1+z^{-1}q^{2n-1})$$ $$\ln F(z,q)=\ln \prod\limits_{n=1}^{ \infty }(1-q^{2n})+   \sum\limits_{n = 1}^ \infty \ln(1+zq^{2n-1}) +  \sum\limits_{n = 1}^ \infty \ln(1+z^{-1}q^{2n-1})$$ If we derivate both side for $z$ ; $$\cfrac{\frac{\partial F(z,q)}{\partial z} }{F(z,q)}=\sum\limits_{n = 1}^ \infty \frac{q^{2n-1}}{1+zq^{2n-1}}-\sum\limits_{n = 1}^ \infty \frac{z^{-2}q^{2n-1}}{1+z^{-1}q^{2n-1}}$$ $$\cfrac{z\frac{\partial F(z,q)}{\partial z} }{F(z,q)}=\sum\limits_{n = 1}^ \infty \frac{zq^{2n-1}}{1+zq^{2n-1}}-\sum\limits_{n = 1}^ \infty \frac{z^{-1}q^{2n-1}}{1+z^{-1}q^{2n-1}}$$ $$\cfrac{Q(z,q)}{F(z,q)}=\sum\limits_{n = 1}^ \infty \frac{zq^{2n-1}}{1+zq^{2n-1}}-\sum\limits_{n = 1}^ \infty \frac{z^{-1}q^{2n-1}}{1+z^{-1}q^{2n-1}}$$ $$\cfrac{Q(z,q)}{F(z,q)}=\sum\limits_{n = 1}^ \infty \frac{zq^{2n-1}}{1+zq^{2n-1}}- \frac{z^{-1}q^{2n-1}}{1+z^{-1}q^{2n-1}}$$ $$\cfrac{Q(z,q)}{F(z,q)}=\sum\limits_{n = 1}^ \infty \frac{(z-z^{-1})q^{2n-1}}{1+q^{2(2n-1)}+q^{2n-1}(z+z^{-1})}$$ $$Q(z,q)=(z-z^{-1})F(z,q)\sum\limits_{n = 1}^ \infty \frac{q^{2n-1}}{1+q^{2(2n-1)}(1+\frac{q^{2n-1}}{1+q^{2(2n-1)}}(z+z^{-1}))}$$ $$Q(z,q)=(z-z^{-1})F(z,q)\sum\limits_{n = 1}^ \infty \frac{q^{2n-1}}{1+q^{2(2n-1)}}\big(1-\frac{q^{2n-1}}{1+q^{2(2n-1)}}(z+z^{-1})+\frac{q^{2(2n-1)}}{(1+q^{2(2n-1)})^2}(z+z^{-1})^2+.....\big]$$ $$Q(z,q)=(z-z^{-1})F(z,q)\sum\limits_{n = 1}^ \infty \frac{q^{2n-1}}{1+q^{2(2n-1)}}-\frac{q^{2(2n-1)}}{(1+q^{2(2n-1)})^2}(z+z^{-1})+\frac{q^{3(2n-1)}}{(1+q^{2(2n-1)})^3}(z+z^{-1})^2-.....\big)$$ $$Q(z,q)=(z-z^{-1})F(z,q)\sum\limits_{n = 1}^ \infty \sum\limits_{k = 0}^ \infty (-1)^k\frac{q^{(k+1)(2n-1)}}{(1+q^{2(2n-1)})^{k+1}}(z+z^{-1})^{k}$$","['theta-functions', 'functions', 'roots', 'sequences-and-series']"
3601626,How does an isosceles triangle minimize distance?,"I thought of this while solving another problem which I hacked using calculus but seems much easier than it is. Let me make a general case of it, or at least an example. Construct a segment $AB=6\text{cm}$ and the locus of all points $C$ such that $\triangle ABC$ has an area of $12\text{cm}^2$ . What you would do is draw a perpendicular $AC$ from any point on $AB$ that is $4\text{cm}$ long and then draw a line parallel to $AB$ at $C$ . That line is the locus of points. Now extend the question. What point $C$ on that line minimizes the sum of length of segments $AC$ and $BC$ ? In the question I deduced it differently since it was a question in coordinate geometry and I found an isosceles triangle. So how is it that $AC+BC$ is minimum when $AC=BC$ . I feel like there's a Euclid style proof of this but I can't really get one at the moment. Here's the picture of the situation.","['alternative-proof', 'euclidean-geometry', 'triangles', 'geometry']"
3601641,Various definitions for a branch of logarithm,"I am confused by the definitions put up for a branch of logarithm . I have two questions in mind. Why do some books define a branch on just an open subset whereas some books define it on an open connected subset? Why some texts define a branch to be continuous but then some texts take the extra leap and define the branch to be a holomorphic function? Here are some examples. In Sarason's Complex Function Theory, it states the definition: Let $G$ be an open connected subset of $\mathbb{C}-\{0\}$ . A branch of $\log z$ in $G$ is a continuous function $\ell$ in $G$ such that for each $z \in G$ , $\ell(z)$ is a logarithm of $z$ . In Ivan Wilde's Lecture Notes on Complex Analysis, we have: A branch of the logarithm is a pair $(D, f)$ , where $D$ is a domain (an open connected subset of $\mathbb{C}$ ) such that $0 \notin D$ and $f: D \to \mathbb{C}$ is continuous and satisfies $e^{f(z)} = z$ for all $z \in D$ . In Stein-Shakarchi's Complex Analysis, we have: Suppose that $\Omega$ is simply connected with $1 \in \Omega$ , and $0 \notin \Omega$ . Then, in $\Omega$ there is a branch of logarithm $F(z) = \log_\Omega z$ so that $F$ is holomorphic in $\Omega$ and $e^{F(z)} = z$ for all $z \in \Omega$ . In lecture notes I found online: Let $\Omega \subset \mathbb{C} - \{0 \}$ be open . Then, a branch of $\log z$ on $\Omega$ is a holomorphic function $L: \Omega \to \mathbb{C}$ such that $e^{L(z)} = z$ for every $z \in \Omega$ . A lot of the definitions assume that the logarithm is defined on a domain/region/open-connected subset of $\mathbb{C}$ . Why is this so? Moreover, what do we lose if we define it on just an open, not necessarily connected subset of $\mathbb{C}$ ? Would this be the same case to as why we sometimes define holomorphic functions just on an open set rather than on a domain? The only thing that I could think why assuming connectedness is important is to be more careful in the sense that the branch wouldn't take two different values on different subsets whose union is the subset where the branch is defined. Similarly, what do we lose if we define the branch to be just a continuous function rather than a holomorphic one?","['complex-analysis', 'connectedness', 'definition', 'logarithms']"
3601722,Derivative of a matrix-vector multiplication with respect to the matrix,"Let's assume that we have $\textbf{x} \in \mathbb{R}^n$ and $A \in \mathbb{R}^{m \times n}$ .
I want to show that $\frac{\partial(\textbf{Ax})}{\partial\textbf{A}} = \textbf{x}^T$ , e.g. in [0], where we have: $$\frac{\partial\textbf{W}_3\textbf{x}_2}{\partial\textbf{W}_3} = \textbf{x}_2^T$$ for $\frac{\partial E}{\partial\textbf{W}_3}$ . As far as I understand, we have $\textbf{Ax} \in \mathbb{R}^{m}$ , so in reality we differentiate the vector with respect to the matrix, what gives us a tensor with its 3D representation. I'm not sure how this can be equal to $\textbf{x}^T$ . [0] Sudeep Raja, A derivation of backpropagation in matrix form , August 17, 2016.","['matrices', 'tensors', 'derivatives', 'vectors']"
3601774,Integrating $x^{x^x}$,"Although one cannot find an elementary antiderivative of $f(x)=x^x$ , we can still give a series representation for $\int_0^1 x^x dx$ , namely: $$I_1=\sum_{n=1}^\infty \frac{(-1)^{n+1}}{n^n}=0.78343\ldots$$ One can even find an expression for the complete antiderivative in terms of infinite sums and the incomplete gamma function $\Gamma(a,x)$ : $$\int x^x dx =\sum_{n=1}^\infty \left(\frac{(-1)^{n+1}\Gamma(-n\ln(x),n)}{n^n \Gamma(n)}\right)+C$$ Considering special, non-elementary function, series, infinite products, etc. , is this also possible for $\int_0^1 x^{x^x} dx$ ? Thank you in advance!","['integration', 'definite-integrals', 'gamma-function', 'calculus', 'tetration']"
3601863,"Prove that $\log(z_1z_2) = \log(z_1)+\log(z_2)$ for $z_1$, $z_2$ in the right half plane","What is $\log(z_1z_2)−\log(z_1)−\log(z_2)$ for $z_1$ , $z_2$ in the second quadrant? For the first part of the question $\log(z_1z_2) = \log(z1)+\log(z_2)$ , I think I solved it correctly. By using principle branch, $\log z = \ln z + i\text{Arg}z , (-pi ,pi)$ . $\log(z_1z_2)= \log (z_1z_2) + i( \theta_1 + \theta _2)  \dots = \log z_1 + \log z_2 $","['complex-analysis', 'solution-verification', 'logarithms']"
3601881,Writing an algorithm solving the word-problem in hyperbolic groups,"I am reading in the “Metric Spaces of Non-Positive Curvature Book by André Haefliger and Martin Bridson”, on Dehn's Algorithm (Chapter III.Γ, p.449). Let $\mathcal{A}$ be a finite generating set of a group $\Gamma$ . A list of pairs of words $(u_{1},v_{1}),...,(u_{n},v_{n})\in\Gamma\times\Gamma$ is called “satisfies the conditions of Dehn's Algorithm” if the following hold: 1) $u_{i}=v_{i}$ in $\Gamma$ ; 2) $\forall i=1,...,n$ , $|u_{i}|>|v_{i}|$ , where $|u|$ denotes the length of $u$ as a word in the free group $F(\mathcal{A})$ ; 3) $\forall w\in\Gamma$ , $[w=1$ in $\Gamma$ implies that at least one of the $u_{i}$ 's is a subword of $w]$ . A finite presentation $\langle\mathcal{A}\mid\mathcal{R}\rangle$ of a group $\Gamma$ is called Dehn presentation if $\mathcal{R}=\{u_{1}v_{1}^{-1},...,u_{n}v_{n}^{-1}\}$ , where $(u_{1},v_{1}),...,(u_{n},v_{n})\in\Gamma\times\Gamma$ satisfy the conditions of Dehn's Algorithm. Given such a presentation it is obvious that the word problem is solvable $\Gamma$ . Assume now that the Cayley graph $C_{\mathcal{A}}(\Gamma)$ is $\delta$ -hyperbolic, where $\delta\geq0$ . I want to understand is it possible to construct an algorithm which solves the word-problem in $\Gamma$ . In the book above, Thm. 2.6, p.450, the authors proved that $\Gamma$ admits Dehn presentation. Namely, They proved that if $k>8\delta$ is a fixed integer, $u_{1},...,u_{n}$ are all the words in $F(\mathcal{A}) $ with $|u_{i}|\leq k$ , and $v_{i}$ , $i=1,...,n$ , is a word of minimal length in $F(\mathcal{A})$ such that $v_{i}=u_{i}$ in $\Gamma$ , then $\langle\mathcal{A}\mid u_{1}v_{1}^{-1},...,u_{n}v_{n}^{-1}\rangle$ is a Dehn presentation of $\Gamma$ . My question is to know if there exists an algorithm, which given (as variables) $\delta>0$ , and a finite presentation $\langle\mathcal{A}\mid\mathcal{D}\rangle$ of $\delta$ -hyperbolic group $\Gamma$ , the algorithm plots a list $(u_{1},v_{1}),...,(u_{n},v_{n})\in\Gamma\times\Gamma$ which satisfy the conditions of Dehn's Algorithm (that is, finds a geodesic word for every word of length $\leq8\delta+1$ )? If no, then why do “they” say that the word problem is solvable in hyperbolic groups?","['gromov-hyperbolic-spaces', 'group-theory', 'hyperbolic-geometry', 'geometry']"
3601934,A man tests for HIV. What is the predictive probability that his second test is negative?,"Can anyone help with this question ? In a population, it is estimated HIV prevalence to be $\lambda$ .
For a new test for HIV: $\theta$ is the probability of an HIV positive person to test positive $\eta$ is the probability an HIV negative person tests positive in this test. A person takes the test to check whether they have HIV, he tests positive. What is the predictive probability he tests negative on the second test? Assumption: Repeat tests on the same person are conditionally independent. From my notes predictive probability is given as: $P(\tilde{Y} = \tilde{y} | Y = y) = \int p(\tilde{y}|\tau) p(\theta|\tau)$ here $\tilde{Y}$ is the unknown observable, $y$ is the observed data and $\eta$ the unknown. I am interested in the probability of the second test is negative, given that the first test is positive,without knowing if the man really has HIV or not. To facilitate this I define: $y_1$ as the event of the first test being positive and $\tilde{y_{2}}$ as the second test being negative Would this adaption to the formula given above be the correct/best approach to this problem ? $p(\tilde{y_{2}}, y_{1}|\tau) = p(\tilde{y_{2}}|\tau) p(y_{1}|\tau)p(\tau) $ and this is really $\propto p(\tilde{y_{2}}|\tau) p(\tau|y_{1})$ I've gotten for the $p(\tau|y_{1})$ from Bayes' theorem: $$p(\tau|y_{1}) = \frac{p(\tau)p(y_1|\tau)}{p(y_1)} \\
= \frac{\lambda \theta}{ \lambda \theta + \eta (1 - \lambda) }$$ How could I then find $p(\tilde{y_{2}}|\tau)$ ? Is this the correct approach ? Any hints are welcomed.","['statistics', 'conditional-probability', 'bayesian', 'bayes-theorem', 'probability']"
3601937,Verifying $P(\lim_{n \to \infty}\inf A_n) \leq \lim_{n \to \infty}\inf P(A_n) \leq \lim_{n \to \infty}\sup P(A_n) \leq P(\lim_{n \to \infty}\sup A_n)$,"From Probability Through Problems By Marek Capinski,Tomasz Jerzy Zastawnaik Verify that $P(\lim_{n \to \infty}\inf A_n) \leq \lim_{n \to \infty}\inf P(A_n) \leq  \lim_{n \to \infty}\sup P(A_n) \leq P(\lim_{n \to \infty}\sup A_n)$ Solution as given : Consider $B_n=\cap_{k=n}^{\infty}A_k$ then \begin{eqnarray*}P(\lim_{n \to \infty}\inf A_n) &=& P(\cup_{n=1}^{\infty}B_n)...since \space \lim_{n \to \infty}\inf A_n =\cup_{n=1}^{\infty}\cap_{k=n}^{\infty}A_k \\ &=& \lim_{n \to \infty}P(B_n)...since \space B_1\subset B_2\subset...\\  &=& \lim_{n \to \infty} \inf P(B_n) ..since \space  P(B_1)\leq P(B_2) \leq...\\ &\leq& \lim_{n \to \infty}\inf P(A_n)...since\space B_n\subset A_n \\ \end{eqnarray*} What I am not getting is the $3^{rd}$ step,I mean how $\lim_{n \to \infty}P(B_n)=\lim_{n \to \infty} \inf P(B_n)$ ?Please explain.. Thanks in advance..","['limsup-and-liminf', 'measure-theory', 'probability-theory']"
3601966,Averaging Datasets with Inconsistent Time Points,"I am trying to find the equivalent of a ""mean"" and ""standard deviation"" of some time-dependent datasets, with the added complication that not all datasets were taken at consistent time points. Say, for example, you set 3 separate ovens to 350 degrees and measure the temperature response. All the ovens follow a similar temperature profile, but each timepoint is distinct. Additionally, most of the datapoints were taken at inconsistent times (e.g. only oven 1 has data at 6 min, only oven 2 has data at 5 min, and only oven 3 has data at 5.5 min). I want to know the ""average"" temperature profile as the ovens approach 350, and the spread in these profiles. It would be excellent if I could construct an average curve with time-dependent error bars. I'm not sure how to do this, but there must be some procedure. I thought about picking some easy time points (e.g. 1,2,3...), interpolating the curves that don't have data at these times, and averaging like normal from these calculated values, but that seems to lack rigor. Is there a better option? Sorry for the somewhat contrived example and the excel graph, but I think it's demonstrative of the kind of dataset I'm thinking about.","['data-analysis', 'statistics', 'standard-deviation']"
3602011,The stalk of the image sheaf on a normalization curve,"My question is based on exercise II.6.9 in  Hartshorne's Algebraic Geometry . Suppose that $X$ is a projective curve over $k$ (an algebraically closed field). Let $\tilde{X}$ be its normalization and $\pi: \tilde{X}\rightarrow X$ be the projection map. For each point $P\in X$ , let $\mathscr{O}_P$ be its local ring and $\tilde{\mathscr{O}_P}$ be the integral closure of $\mathscr{O}_P$ . Then my question is: Is there a relationship between the stalk of $\pi_*\mathscr{O}_\tilde{X}$ at $P$ and the local ring $\tilde{\mathscr{O}_P}$ ? Are they equal? If it's true, how to prove it? My attempt. In the affine case, suppose $X=\operatorname{Spec}A$ for some domain $A$ . I know that $\pi$ is just the ring extension $A\hookrightarrow\tilde{A}$ , where $\tilde{A}$ is the integral closure of $A$ in its field of fractions. And $P$ corresponds to a prime ideal $\mathfrak{p}$ of $A$ . Then $\tilde{\mathscr{O}_P}$ is the integral closure of $A_\mathfrak{p}$ . The stalk of $\pi_*\mathscr{O}_\tilde{X}$ at $P$ can be finally expressed as a direct limit of local rings $\{\tilde{A}_f\}$ , where $f$ is taken over all elements in $A\setminus\mathfrak{p}$ . So the question is translated into a problem of commutative algebra. That is, is it true for $\tilde{A_\mathfrak{p}}=\varinjlim\tilde{A}_f$ ? Maybe we need something given by the assumption on $X$ , i.e. $A$ is noetherian and of dimension $1$ . But I still have no strategy to deal with it. Could anyone help me? Thanks in advance!","['integral-extensions', 'algebraic-geometry', 'commutative-algebra']"
3602045,Trace of a Matrix Product.,"Let $A \in \mathbb{R}^{n\times m}$ , and $B\in \mathbb{R}^{m\times m}$ . Let $A'$ denote the transpose of $A$ . From this we know that : $A'\in \mathbb{R}^{m\times n}$ and $AB\in \mathbb{R}^{n\times m}$ and hence $ABA' \in \mathbb{R}^{n\times n}$ . The Trace of a matrix is defined as the sum of its diagonal entries. $\textbf{My Question :}$ Does anyone know bounds (using any usual matrix norm) for $\text{Trace}(ABA')$ Or more generally $\text{Trace}(AB)$","['vectors', 'trace', 'analysis', 'matrices', 'linear-algebra']"
3602067,Is the exponential function semi-algebraic?,"Recall the following definitions: We say a set $E\subseteq\mathbb{R}^n$ is semi-algebraic if there exist real polynomials $g_{ij},h_{ij}:\mathbb{R}^n\rightarrow\mathbb{R}$ such that $$E=\bigcup_{j=1}^p\bigcap_{i=1}^q\{x\in\mathbb{
R}^n:g_{ij}(x)=0\text{ and }h_{ij}(x)<0\}.$$ A function $f:\mathbb{R}^n\rightarrow(-\infty,\infty]$ is called semi-algebraic , if its graph \begin{equation*}
\{(x,y)\in\mathbb{R}^{n+1}:f(x)=y\}
\end{equation*} is semi-algebraic. Literature says real polynomials are semi-algebraic, which to me is a natural result. To further understand this concept, I am wondering the following: Is the exponential function $x\mapsto e^x$ semi-algebraic? Unfortunately I have no idea of how to prove or disprove it, so any hint or comment will be appreciated. Thanks a billion! Update: I am an optimizer and optimization people care about this concept because semi-algebraic functions enjoy Kurdyka-\L{}ojasiewicz property, a key assumption in many convex/non-convex optimization problems.","['semialgebraic-geometry', 'convex-optimization', 'algebraic-geometry', 'real-algebraic-geometry', 'exponential-function']"
