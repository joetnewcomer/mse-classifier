question_id,title,body,tags
2633861,Conditional Number growth of Hilbert Matrix: Theoretical vs MatLab.,"I need to investigate how the condition number of the Hilbert matrix grows with the size N. The Matlab command is: ""cond(hilb(N),2)"" Compute the condition number of the Hilbert matrices Hn ∈ R, N×N, for all N = 1, . . . , 50. Using Matlab to calculate the log of condition number of Hn versus N. (The blue 'x') Compare this with the anticipated theoretical growth (The red line) of $$O\left(\frac{(1+\sqrt{2})^{4N}}{\sqrt{N}}\right) $$ I got a plot like this: When N = 13, the Condition Number reaches the maximum. The Condition Number does not continue to grow when N>13. Why does the Condition Number stop growing after N=13? % generate Hilbert matrices and compute cond number with 2-norm

N=50; % maximum size of a matrix
condofH = []; % conditional number of Hilbert Matrix
N_it= zeros(1,N); 


% compute the cond number of Hn
for n = 1:N
    Hn = hilb(n);
    N_it(n)=n;
    condofH = [condofH cond(Hn,2)];
end

% at this point we have a vector condofH that contains the condition
% number of the Hilber matrices from 1x1 to 50x50.
% plot on the same graph the theoretical growth line. 


% Theoretical growth of condofH
x = 1:50;
y = (1+sqrt(2)).^(4*x)./(sqrt(x));

% plot
plot(N_it, log(y));
plot(N_it, log(condofH),'x', N_it,log(y));


% plot labels
plot(N_it, log(condofH),'x', N_it,log(y))
title('Conditional Number growth of Hilbert Matrix: Theoretical vs Matlab')
xlabel('N', 'fontsize', 16)
ylabel('log(cond(Hn))','fontsize', 16)
lgd = legend ('Location', 'northwest')
legend('MatLab', 'Theoretical')
legend('show')","['matrices', 'matlab', 'hilbert-matrices']"
2633906,Cauchy criteria at infinity,"i couldn't find the definition for Cauchy for functions as $x$ approaches infinity. I wrote it myself and i wanted to know if someone can correct me. Let $f(x)$ be a function defined on all the real numbers. for every $ε>0$ there is an $M$ such that if $x,y>M$ so $|f(x)-f(y)|<ε$ thank you for your help!","['definition', 'functions', 'limits']"
2633927,How to prove sin(nx) has no pointwise convergent subsequence without prior knowledge of Lebesgue's Theory?,"In Baby Rudin 7.20 example, the author mentions to prove that the function sequence
$$f_n(x):=\sin(nx) \qquad0(\leq x\leq 2\pi)$$has no pointwise convergent subsequence would be troublesome without Lebesgue's Theorem. Is there a proof that doesn't refer to Lebesgue's Theorem , and only requires the knowledge introduced in the first 7 chapter in Rudin?",['real-analysis']
2633949,Construction of random variables,A proof for the existence of a Wiener process is based on using Gaussian random variables to construct such a process with the properties we need from it. That got me thinking that I never actually learned how a random variable with a certain distribution is constructed. How does one prove that there exists $X:\Omega\rightarrow\mathbb{R}$ with $\mathbb{P}\{X\leq x\}=F(x)$ for a given $F$ ? More importantly what would $\Omega$ be in the case of usual R.V (e.g normal) and what would $X(\omega)$ represent ?,"['probability-theory', 'probability', 'probability-distributions']"
2634012,"Difference between ""undefined variance"" and ""infinite variance"" (and likewise moments)","I'm trying to get my head around the concept of ""stable distribution"" but there is a concept which is not clear to me. The thing that I would like to understand is whether ""Undefined variance"" is equivalent to ""infinite variance"" At the beginning, I thought that the two concepts where equivalent statements but then I looked on wikipedia the page about levy distribution ( https://en.wikipedia.org/wiki/Lévy_distribution ) and I saw that For the Lèvy distribution: Variance = $\infty \qquad$ Kurtosis=Undefined Hence, I would like to understand the difference between an undefined moment and an infinite one","['probability-theory', 'probability', 'statistics', 'probability-distributions']"
2634043,Basket with Lilies and Roses. Find the number of roses.,"Ques: A covered basket of flowers has some lilies and roses. In search of rose, Sweety and Shweta alternately pick
up a flower from the basket but put it back if it is not a rose. Sweety is 3 times more likely to be the first one
to pick a rose. If sweety begin this 'rose hunt' and if there are 60 lilies in the basket, find the number of roses
in the basket. Let the roses be x and lilies be y. Since they find all of the x roses finally
$$ x!/(x+y)! + y/(x+y) * x!/(x+y)! \cdots = 1  $$
So to be straight forward, I do not have any good idea how to deal with this.","['probability', 'elementary-probability']"
2634046,Asymptotic equivalent of $\sum_{n\ge0} q^{n^2}{x^n}$ as $x\to+\infty$,"Let $q\in\Bbb C^*$ with $|q|<1$, define
$$f:x\mapsto\sum_{n\ge0} q^{n^2}{x^n}$$
I want to find an asymptotic equivalent of $f$ as $x\to+\infty$. I found that $$a\le|f(x)|\cdot\exp\left(\frac{\ln^2|x|}{4\ln |q|}\right)\le b$$
  where
  $$a=\min\left( \left|\sum_{n\in\Bbb Z} q^{(n+\frac12)^2}\right|, \left|\sum_{n\in\Bbb Z} q^{n^2}\right|\right)$$
  $$b=\max\left( \left|\sum_{n\in\Bbb Z} q^{(n+\frac12)^2}\right|, \left|\sum_{n\in\Bbb Z} q^{n^2}\right|\right)$$ Here is what I did: Let $x=q^{-2k}$ with $k\in\Bbb R_+$, let $k=K+d$ such that $K\in\Bbb N$ and $d\in(-\frac12,\frac12]$, then
\begin{align}
f(q^{-2k})&=\sum_{n\ge0} q^{n^2-2kn}\\
&=q^{-k^2}\sum_{n\ge0} q^{(n-k)^2}\\
&=q^{-k^2}\sum_{n\ge-K} q^{(n-d)^2}\\
&=q^{-k^2}\left(\sum_{n\in\Bbb Z} q^{(n-d)^2}-\sum_{n>K} q^{(n+d)^2}\right)\\
\end{align}
Thus,
$$
|f(q^{-2k})\cdot q^{k^2}|=_{k\to+\infty}l(d)+o(1)
$$
where
$$
l:d\mapsto\left|\sum_{n\in\Bbb Z} q^{(n-d)^2}\right|
$$
and below is the graph of $l(d)$ with $q=\frac12$ and $-\frac12$. Since $\lim_{k\to+\infty}|q^{-2k}|=+\infty$, the results are shown by replacing $k$ with $-\frac{\ln |x|}{2\ln|q|}$. I expect any further studies of this problem.","['theta-functions', 'asymptotics', 'sequences-and-series', 'power-series', 'analysis']"
2634056,Studying the differentiability of $f(P) = P(0)P'(1)$,"Let $E= \mathbb{R}_n[X]$ and $f: E \rightarrow \mathbb{R}$ such that $f(P) = P(0)P'(1)$. Show that it is differentiable at every $P \in E$ My teacher proposed a solution without giving full justification, which doesn't allow me to fully understand why it works. And also, I am unsure which norm to use. He states that if we study for $P, H \in E$, we have: $$f(P+H) = (P+H)(0)(P+H)'(1) = P(0)P'(1) + P(0)H'(1) + H(0)P'(1) + H(0)H'(1) $$ Thus we can put $df(P)(H) = P(0)H'(1) + H(0)P'(1)$ (which is linear) and as $H(0)H'(1)$, we get the differentiability. Yet, if I study (with the condition that $H \not = 0$), we have: $$\frac{||f(P+H)-f(P) - df(P)(H)||}{||H||} = \frac{||H(0)H'(1)||}{||H||} $$ it doesn't seem that this would have a limit equal to $0$ when $||H|| \rightarrow 0$","['derivatives', 'differential-topology']"
2634076,Difference of cohomologous Kähler forms,"Let $X$ be a compact Kähler manifold. Show that if two Kähler forms $\omega, \omega'$ satisfy $[\omega]= [\omega'] \in H^2(X,\mathbb R)$, then there exists a real function $f$ such that $\omega = \omega' + i \partial \bar \partial f$. My idea was to use that locally we can find such a function, i.e. $\omega-\omega'= i \partial \bar \partial f$. But why does the right side extend globally?","['complex-geometry', 'kahler-manifolds', 'differential-geometry']"
2634085,"Prove that $\int_E \log fd\mu \leqslant \mu(E) \, \log \left[\frac{1}{\mu(E)} \right]$ for strictly positive measure $\mu$","Let $(X, \Sigma, \mu)$ be a measurable space, with strictly positive measure $\mu$. Let $f: X \rightarrow (0, \infty)$ be a function such that $\int_X fd\mu=1$. Show that for every $\mu$-measurable set $E \in \Sigma$ with $0 < \mu(E)<\infty$ the following inequality holds: $$\int_E \log fd\mu \leqslant \mu(E) \, \log \left[\frac{1}{\mu(E)} \right]$$ I'm dealing with this quiestion quite a bit and can't seems to find a solution.
My approach: We define new measure $\nu = f \cdot \mu$. Since $f>0$ and $\mu$ strictly positive, then $\nu$ is strictly positive. Moreover, $\nu(X) \equiv \int_Xdv = \int_Xd(f\cdot\mu) =\int_Xfd\mu = 1$. Therefore, by the Jansen inequality (concaved version): For every integrable function $g$ (according to $\mu$ ) such that $g:X \rightarrow (0,\infty)$ and concave function $F:(0, \infty) \rightarrow$ R (R for the real numbers): $$\int_X F\circ g d\nu \leq F \biggl(\int_X g d\nu \biggl)$$ I thought about taking $F(x) = \log(x)$ but I can't seem to find the right $g$ and how to conclude it to the integral overall given set $E$. Does anyone have a solution for this?
Thanks. Edit:
I got it. Take $g=f$ and for every set E above define $\nu_E = \frac{1}{\mu(E)} \cdot \mu$. Clearly, $\nu(E)=1$ there fore by the Jensen inequality we get: $$\int_E \frac{1}{\mu(E)} \cdot \log f d\mu  \leq \log \biggl(\int_E f \frac{1}{\mu(E)} \cdot d\mu \biggl)$$ Now we play with the last inequality and we get an equivalent one:
$$\int_E \log fd\mu \leqslant \mu(E) \, \log \left[\frac{1}{\mu(E)} \right]$$","['real-analysis', 'inequality', 'integration', 'measure-theory', 'jensen-inequality']"
2634141,How to think about proofs of inequalities (precalculus)?,"I know that
$a\leq \lvert a \rvert$ and $\lvert a \rvert =\sqrt{a^2}$, so I can write
$$
a\leq \sqrt{a^2}
$$
But say something like
$$
a\leq \sqrt{a^2+b^2}
$$
Intuitively it's true. But can we really prove this or is it just intuition? I think: ""we just added $b^2$ on the right side but nothing on the left side. Therefore the right side must be larger (of equal)"". Is this the right way to think about it?","['algebra-precalculus', 'inequality']"
2634154,Calculate the expected value for this markov chain,"Harry's restaurant changes year after year between the states $0$
  (bankrupt), $1$ (almost bankrupt) and $2$ (solvent). The transition matrix is 
  $P= \begin{pmatrix} 
1    &  0    &  0   \\ 
1/2  &  1/4  &  1/4 \\  
1/2  &  1/4  &  1/4 
\end{pmatrix}$ Calculate the expected value for the amount of years till state $0$ is
  reached, if we started from state $2$. I took this question from an exam and try to solve it but I'm not sure how to do this correct? I'm a bit confused we need to work with expected value to calculate the required steps / years to get from state $2$ to state $0$. At least that's how I understood this so far. It all sounds like I need to solve some recursive relations. Let $h(k)$ be the expected number of steps / years in this example until we reach the state $0$ when you are in state $2$. So we have that 
$$h(2)=0$$ because when you are in state $2$, you need $0$ steps / years to reach $2$. Then for $k=1$ $$h(1) = 1+0.25h(1)+0.25h(2)+0.5h(0)$$ because when you are in state $1$ you will need a step ($+1$) so you will reach with probability $0.25$ state $1$ again and with probability $0.25$ state $2$ and with probability $0.5$ state $0$. Similarly we do this for $h(0):$ $$h(0) = 1+1h(0)$$ But from here I don't really know how to continue to get the system and calculate the expected number pf steps with that? : /","['matrices', 'probability-theory', 'probability', 'statistics']"
2634193,From the given information I have to find $f'(0)$,"It is given that a function $f$ is differentiable everywhere, and $f(0)=5$. If $f(x)<5$ for all nonzero $x$ then what is the value of $f'(0)$?. Now I see that $0$ is a point of maximum of the function, which is differentiable at $0$, which means that $f'(0)$ must be zero. Is this the correct answer? I am conflicted because the book says it's not. There is a chance of a misprint though.",['derivatives']
2634233,Dimension of scheme of finite type over a field under base change (Hartshorne Ex. II.3.20),"Consider an integral scheme $X$ of finite type over a field $k$ . If $k\subseteq k'$ is a field extension, then the scheme $X' = X\otimes_k k'$ is not necessarily integral. For instance, take $X = \operatorname{Spec} \mathbb{R}[x,y]/(x^2+y^2)$ over $\mathbb R$ and $k' = \mathbb C$ . Then $$X' = \operatorname{Spec}\mathbb C[x,y]/(x^2+y^2) = \operatorname{Spec} \mathbb C[x,y]/(x+iy) \cup \operatorname{Spec} \mathbb C[x,y]/(x-iy)$$ has two irreducible components. Nonetheless, the dimension of each irreducible component of $X'$ is equal to the dimension of $X$ . Why? (This is Ex. II.3.20(f) in Hartshorne's book ""Algebraic Geometry"".)","['schemes', 'transcendence-degree', 'algebraic-geometry']"
2634254,"$|f(x)-f(y)|≤(x-y)^2$ for all real $x,y$. What can we say about $f$?","I can see that the absolute value of the difference quotient (for $y≠x$) is always less than $|x-y|$. From this I conclude that the limit of the difference quotient at $y$ i.e., the derivative at any point $y$ is $0$. So the function $f$ is a constant function. Is my math correct?",['derivatives']
2634273,Is there a $4\times4$ matrix $A$ such that $\det(A) = a^4+b^4+c^4+d^4$?,"There is a $2\times2$ matrix $A$ composed of reals $a$ and $b$ such that $\det(A) = a^2 + b^2$, namely $$A=\begin{bmatrix} a & -b \\ b & a \\ \end{bmatrix}.$$ It would seem there is not an analogy for $3\times3$ matrices.  That is, I don't think there is a matrix $A$ composed of three reals $a$, $b$, and $c$ such that $\det(A) = a^3 + b^3 + c^3$. However, matrices with even dimensions give an opportunity for cross-terms to cancel.  Is there then, for example, a $4\times4$ matrix $A$ composed of reals $a$, $b$, $c$ and $d$, such that $$\det(A) = a^4+b^4+c^4+d^4$$ Formalized statement : For all reals $a$, $b$, $c$ and $d$, I am looking for a $4\times4$ matrix $A$ such that $A_{ij} = \{\pm a,\pm b,\pm c,\pm d\}$ and $\det(A) = a^4+b^4+c^4+d^4$.  Is there such a matrix?","['matrices', 'determinant']"
2634277,How to prove this definite integral does not depend on the parameter?,"I am working on some development formulas for surfaces and as a byproduct of abstract theory i get that:
$$\int_{-\frac{\pi}{2}}^\frac{\pi}{2}\frac{1+\sin^2\theta}{(\cos^4\theta+(\gamma\cos^2\theta-\sin\theta)^2)^\frac{3}{4}}d\theta$$
is independent on the parameter $\gamma\in\mathbb{R}$. I thought that there was something wrong with my calculations but actually turns out that using Mathematica that the value is somewhat near $5,24412$ independently on the $\gamma$ I plug in the calculation of the integral. Is there any way to verify that actually this is a constant by direct computations, complex analysis, or at least is this kind of integrals studied? Edit:obviously differentiating in the integral does not help much","['complex-analysis', 'integration', 'definite-integrals', 'calculus']"
2634292,"If $\sin^{-1} (x) + \sin^{-1} (y)+ \sin^{-1} (z)=\dfrac {\pi}{2}$, prove that $x^2+y^2+z^2+2xyz=1$","If $\sin^{-1} (x) + \sin^{-1} (y)+ \sin^{-1} (z)=\dfrac {\pi}{2}$ , prove that: $$x^2+y^2+z^2+2xyz=1$$ My Attempt: $$\sin^{-1} (x) + \sin^{-1} (y) + \sin^{-1} (z)=\dfrac {\pi}{2}$$ $$\sin^{-1} (x\sqrt {1-y^2}+y\sqrt {1-x^2})+\sin^{-1} (z)=\dfrac {\pi}{2}$$ $$\sin^{-1} (x\sqrt {1-y^2} + y\sqrt {1-x^2})=\dfrac {\pi}{2} - \sin^{-1} (z)$$","['algebra-precalculus', 'trigonometry', 'inverse-function']"
2634304,Solving the inequality $|2-x|>1$,"I am trying to figure out the following inequality with absolute value, $$\begin{split} |2-x| &>1\\
x^2-4x +3 &> 0 \\
x>3&,\  x<1
\end{split}$$ Am I correct with this process?","['algebra-precalculus', 'inequality']"
2634317,Why the characteristic function is measurable?,"On page 11 of Rudin's real and complex analysis, Let $X$ be a measurable space. If $E$ is measurable set in $X$ and if \begin{equation}   \chi_{E}(x)=\begin{cases}
                  1, & x\in E \\
                  \\
                  0, & x\notin E.
 \end{cases} \end{equation} 
  then $\chi_E$ is a measurable function. Do we prove $\chi_E^{-1}(V)$ is a measurable set in $X$ for every open set $V$ in $\{0,1\}$? But $\{0\}$ is an open set in $\{0,1\}$，isn't it? So $\chi_E^{-1}(\{0\})$ is not a measurable set in $X$?","['measurable-functions', 'measure-theory']"
2634379,"Chain rule problem: given $f(x)=\sqrt{4x+7}$ and $g(x)=e^{x+4}$, compute $f(g(x))'$.","Question: Given the functions $f(x)=\sqrt{4x+7}$ and $g(x)=e^{x+4}$, compute $f(g(x))'$. My Approach: I have found that found that $f(g(x))=\sqrt{4e^{x+4}+7}$. Should I now just differentiate it to get my answer or is there any simpler method to solve this problem. Any helpful suggestions or answers.","['derivatives', 'chain-rule', 'calculus', 'algebra-precalculus', 'implicit-differentiation']"
2634408,countability of set of well-formed formulas,"Here is the question: Define the set WFF as follows-- a) Every element in set $A = \{s_1, s_2, ...\}$ is in WFF. $A$ is countably infinite. b) If $a$ is in WFF, so is $(\neg a)$. If $n$ and $m$ are in WFF, so is $(n \lor m)$. c) No other elements are in WFF. Show that WFF is countable. Attempt at a solution:
I was thinking it might be possible to show by induction that $S_i$, the set of all expressions with $i$ symbols, is countable, and then show that the union of all such countable $S_i$'s is also countable (which I know how to do). However, I'm unsure of how to proceed for the first part -- would it even be necessary to show that the set of all expressions with $i$ symbols is countable, as per the parentheses in the rules, it isn't possible to have an expression with, say, $i = 3$ symbols, or am I confused? Another thing I am having trouble with is that there doesn't seem to be any restriction from the criteria against infinitely long strings/logical sequences (that would make WFF, to my knowledge, not countable). I believe this is the right approach, but I am unable to justify that to myself.","['predicate-logic', 'first-order-logic', 'logic', 'elementary-set-theory']"
2634416,Tangent plane when gradient is zero,"I'm attempting to find the tangent plane of the function $f(x,y,z)=xz+2y^2z^2$ at $(x,y,z)=(-1,1,0).$ The partial derivatives are $z, 4yz^2$, and $4zy^2$ when done in respect to $x, y$ and $z$ respectively. But they're all zero at $(-1,1,0)$ (i.e the gradient is zero). Does this mean that a tangent plane doesn't exist at this point?","['multivariable-calculus', 'partial-derivative', 'plane-curves']"
2634477,Integral of $\int{\frac{\cos^4x + \sin^4x}{\sqrt{1 + \cos 4x}}dx}$,"How do we integrate the following? $\int{\frac{\cos^4x + \sin^4x}{\sqrt{1 + \cos 4x}}dx}$ given that $\cos 2x \gt 0$ I tried to simplify this, but I cannot seem to proceed further than the below form: $\int{\frac{\sec2x}{\sqrt{2}}dx + \sqrt{2}\int{\frac{\sin^2x\cos^2x}{\cos2x}dx}}$ $\implies \frac{1}{2\sqrt2}\log |\sec 2x + \tan 2x| + \sqrt{2}\int{\frac{\sin^2x\cos^2x}{\cos^2x-\sin^2x}dx} + C$ The answer that I'm supposed to get is: $\frac{x}{\sqrt2}+C$ Please help, thanks!","['indefinite-integrals', 'integration', 'trigonometry', 'calculus']"
2634478,"Let $f: [-1, 1] \longrightarrow [-1, 1]$ such that $f\in C^{1}$. Prove that there's exist $x_{0} \in [-1, 1]$ such that $|f'(x_{0})| \leq 1$","Let $f: [-1, 1] \longrightarrow [-1, 1]$ such that $f$ is a class $C^{1}$ function. Prove that there's exist $x_{0} \in [-1, 1]$ such that $|f'(x_{0})| \leq 1$. I know that $f'([- 1,1])$ is compact, since $f'$ is continuous. Therefore, it is closed and limited. To prove the result, I tried to use the continuity of $f'$ in some sequence and tried to use the Weierstrass theorem, but I could not conclude anything. I would like some suggestion.","['derivatives', 'real-analysis']"
2634479,A lower bound for the sum of probabilities of independent events.,"I'm trying to prove the following: If $A_1,A_2,\cdots, A_n $ are independent events, then the probability that non of the $ A_i$ occurs is less than $e^{-\sum^{n}_{i=1}P(A_i)} $. I was exploring different alternatives. The first was writing $P\left(\left( \bigcup A_i \right)^c \right)$ as the probability of the intersection of the complements, but I'm not sure if this will works because I cannot use the hypothesis of independence since the $A_i^c$ are not independent. Then, looking for an option in which the probability of the intersection shows, I was trying to prove that $ P\left(\left( \bigcup^{n}_{i=1}A_{i} \right)  \right) \geq 1-e^{-\sum^{n} P(A_i)}$, which allows me to use induction and the independence hypothesis. To my regret, I wasn't able to get to any place with this idea too. I have been trying but now I feel stuck. 
Any ideas?","['independence', 'probability-theory', 'inequality', 'borel-cantelli-lemmas']"
2634486,Prove that primes of the form $2n^2+10n+15$ are also of the form $36k+7$,"QUESTION: Find all primes $p$ of the form $2n^2+10n+15$, where $n$ is a positive integer. attempt: So, I know that we have to have $n\equiv 2\pmod 3$, because, if $n\equiv 1\pmod 3$ then $2n^2+10n+15\equiv 2*1^2+10*1+15\equiv 2+10+15 \equiv 27\equiv 0 \pmod 3$, which is impossible since $p$ can only be divisible by itself and $1$ which would mean that $p=3$, but $p$ is obviously larger than $3$. If $n\equiv 0\pmod 3$, then $2n^2+10n+15\equiv 2*0+10*0+15\equiv15\equiv0\pmod3$, so again we have that a prime number not equal to 3 is divisible by 3, which is impossible, so our only case left is $n\equiv 2\pmod 3$. But I'm stuck here, and I don't think it's that helpful. EDIT Okay, so, I've read the answers, and did some research. I now noticed a pattern in some of the prime numbers of the form $2n^2+10n+15$, that they all satisfy $p\equiv7\pmod{36}$, and I think it is true for all of the primes that take this form, and am interested in proving or disproving this new problem, and I think that the previous attempt is somewhat useful.","['number-theory', 'prime-numbers', 'modular-arithmetic', 'elementary-number-theory']"
2634517,"What's an intuitive explanation behind cross products being vectors, when dot products are not?","As someone currently taking Multivariable Calculus but hasn't taken Linear Algebra, I've been trying to catch up on LA and build an intuition; simply knowing equations isn't really satisfying or useful. My understanding of dot product and cross product (in $\mathbb{R}^3$) is that they generalize multiplication; whereas one becomes multiplication of the norms when vectors are parallel, the other (or rather, its magnitude) becomes multiplication of the norms when vectors are orthogonal. Dot product is maximized via similarity in the direction of vectors, whereas the magnitude of cross product is maximized by differences in the directions. This answer did a nice job at explaining that concept. However, I'm still struggling to understand why cross products are vectors when dot products are scalars. The magnitude of cross product seems intuitive as an opposite to dot product, but I don't see how that is conceptually related to a vector being orthogonal to two others. I've read answers like this to try and understand it, but I still don't see the relationship between measuring the directional difference between two vectors, and creating a new one perpendicular to the two vectors. How can I intuitively grasp that?","['intuition', 'cross-product', 'linear-algebra', 'vectors']"
2634559,Scaling of Lebesgue measure under a linear transformation and the volume of a parallelepiped.,"$\def\vect{\mathbf}
\def\diag{{\rm{diag}}}
\def\R{\mathbb R}
\def\vol{{\rm vol}}
\def\sign{{\rm sign}}$ This post intentionally duplicates two other threads of questions from MSE.  The intention is to point out how they are connected and to give a succinct explanation. One thread asks why the Lebesgue measure of the parallelepiped $P$  in $\R^n$ determined by vectors $v_1, \dots, v_n$ is 
$$ \lambda(P) = |\det(v_1, \dots, v_n)|$$ and hence the signed volume is 
$$\vol(v_1, \dots, v_n) = \det(v_1, \dots, v_n).$$ The second thread asks why Lebesgue measure scales as it does under a linear transformation, namely, given a linear transformation $T$ of $\R^n$,  for all Borel sets $S$,
$$
\lambda(T(S)) = |\det(T)|  \lambda(S).
$$ For the first question, see here and here . For the second question, see here and here .","['volume', 'measure-theory', 'linear-algebra', 'determinant']"
2634573,How to use a stabilizer chain (Schreier-Sims) to prune a centralizer search?,"I've implemented the Schreier-Sims algorithm. My sources indicate that a next useful step is to use this structure to prune a backtracking search of group elements, which should yield an improvement on exhaustively searching the group. I think I can see how to approach the problem of finding a (nontrivial) graph automorphism via a search of the full group $S_n$, though I haven't done it yet. My question is how to use the stabilizer chain structure to prune a centralizer search and/or a conjugacy test. For the sake of discussion, all group elements below are permutations of $n$ points and permutations compose right-to-left, the usual convention in mathematical contexts. A stabilizer chain for a group $G$ is a subgroup series $$ S_n \ge G = G^{(0)} > G^{(1)} > \dots > G^{(m)} = \langle 1 \rangle $$ where for $i=1 \ldots m$, $G^{(i)}$ is the largest subgroup of $G^{(i-1)}$ stabilizing some point $\beta_i$ (distinct for distinct $i$). So every permutation in $G^{(i)}$ has $\beta_i$ as a fixed point, hence it also fixes $\beta_1, \beta_2, \ldots \beta_{i-1}$. As a consequence of this structure, every element of $G$ can be written inductively $g = h_1 h_2 \dots h_m $ where $h_i$ is a coset representatives of $G^{(i)}$ in $G^{(i-1)}$. These coset representatives are readily available because they are elements of a transversal for the orbit of $\beta_i$ under the permutation action of $G^{(i-1)}$, which was computed during Schreier-Sims. The general idea of backtracking search is to conditionally eliminate the entire coset $\left( h_1 h_2 \ldots h_i \right) G^{(i)}$ from consideration by inspecting the partial product $h_1 h_2 \dots h_i$ for some task-specific property. The partial product fully determines the image of points $\beta_1, \beta_2, \ldots, \beta_i$ under the entire coset because those points are fixed by $G^{(i)}$. In the case of graph automorphism search, the coset may be skipped if $h_{i}$ permutes the $\beta_{i}$-labeled vertex in a way that violates the graph structure: if there is (or is not) an edge between vertices labeled by $\beta_i$ and $\beta_j$, there should (or should not) be an edge between vertices labeled by their image under $h_1 h_2 \ldots h_i$. I can't really see the corresponding test for a centralizer search, but it must be fairly obvious because I haven't found an explicit description of it. Sympy has an implementation in sympy.combinatorics.perm_groups.PermutationGroup , but I haven't deciphered what exactly it's doing. Something like GAP must also have an implementation, but I'm even less familiar with that language and haven't located it in the source code.","['algorithms', 'computational-algebra', 'group-theory']"
2634606,Holomorphic function satisfying $f^{-1}(\Bbb R)=\Bbb R$ is of the form $f(z)=az+b$,"Let $f$ be a holomorphic function defined on $\Bbb C$ such that $f^{-1}(\Bbb R)=\Bbb R$. Prove that there exists $a,b \in \Bbb R, \; a \neq 0 \;$ such that $f(z)=az+b \;$ for every $z \in \Bbb C$. I was given a hint: define the function $g(z)=\frac{f(z)-f(0)}{z}$. such $g$ is also holomorphic in $\Bbb C$ since the only singularity is in $0$, and it is a removable singularity since we can define $g(0)=f'(0)$. Next I thought about proving $g$ is bounded, and thus constant (using Liouville's theorem), but pretty much out of ideas. How can I finish the proof/solve in another way?","['complex-analysis', 'holomorphic-functions']"
2634616,How would I Write $n!$ in Product Notation,"I have been having a difficult time writing $n!$ in capital $\prod$ notation. Most of it is pretty easy but I can't seem to include $0!$ as a possible input since if I start the index $i$ at $0$, then the whole thing will be zero. I have tried multiple other combinations of $i$ and $n$ but none of them have worked out. Any suggestions?","['products', 'notation', 'discrete-mathematics']"
2634680,Does $A\sim B$ implies $B\sim A$?,"In my class we defined a set $A$ to be equivalent to set $B$ (noted $A \sim B$) if and only if there exists a function $f \colon A \to B$ that is bijective. Does that imply that $B$ is equivalent to $A$ (noted $B \sim A$)? Here is my attempt of proof: Lets define $g \colon B \to A$
Let $b_1$ and $b_2$ be elements of $B$, then we have to show that $g(b_1)=g(b_2)$ if and only if $b_1=b_2$. By hypothesis $g(b_1)$ and $g(b_2)$ are elements of $A$, and lets define $a_1=g(b_1)$ and $a_2=g(b_2)$. We know that $f(a_1)=f(a_2)$ if and only if $a_1=a_2$, which means $g(b_1)=g(b_2)$. But we know that $f(g(b_1))=b_1$, which is to say that $f(a_1)=b_1$ (This is the step I am not sure about). So $g(b_1)=g(b_2)$ if and only if $b_1=b_2$ and so $g$ is injective. Now about $g$ being surjective: We want to show that for every $a_1\in A$ there exists a $b_1\in B$ such that $g(b_1)=a_1$. By hypothesis if we have an element of $B$ called $b_1$, we know that there exists one element of $A$ called $a_1$ such that $f(a_1)=b_1$ and by substitution we get $f(g(b_1))=b_1$ and I am stucked here.","['elementary-set-theory', 'functions']"
2634733,How can skew-symmetric matrices be thought of as infinitesimal rotations?,"I've recently stumbled upon the fact that skew-symmetric matrices represent somehow infinitesimal rotations. Having never encountered them, I looked them up and learnt they have to do with Lie algebras and groups, but this is beyond what I've studied so far. Is it possible to have a more intuitive understanding of this? Also, from Wikipedia: skew-symmetric matrices are derivatives, while an actual infinitesimal rotation matrix has the form $I+Ad\theta$ where $d\theta$ is vanishingly small and $A ∈ so(3)$. Having read this is about derivatives and has applications in physics, that ""lonely"" $d\theta$ is actually a bit suspicious. What about it?","['intuition', 'geometry', 'infinitesimals', 'linear-algebra', 'lie-groups']"
2634743,Why is squaring an absolute value legitimate for algebraic manipulation?,"I was reading a math SE post following inequality with absolute value and found that it seemed to be common knowledge that you may square both sides of an absolute value function and it maintain correctness. 
For example:
$$
|x-5| = 1\\
(x-5)^2 = 1 \\
x^2-10x+24=0\\
(x-6)(x-4)=0\\
x=6 , x=4
$$
would be perfectly acceptable. Why does it work? Can someone provide intuition?","['algebra-precalculus', 'absolute-value']"
2634801,What is the difference between a trace and a contour in calculus?,"As far as I can tell they're exactly the same thing, but the notes here discuss them as if they are separate: The final topic in this section is that of traces.  In some ways these are similar to contours.  As noted above we can think of contours as the intersection of the surface given by $z=f(x,y)$ and the plane $z=k$.  Traces of surfaces are curves that represent the intersection of the surface and the plane given by $x=a$ or $y=b$. Is the only difference whether we're holding an ""input"" to the function constant as opposed to the ""output""? Generally the functions are defined by equations where any of the variables could be considered a function of the other two, so the distinction seems arbitrary? If there isn't a difference in denotation is there one of connotation?","['multivariable-calculus', 'visualization', 'calculus']"
2634817,Distribution problem with balloons and people,"Prompt: We have unlimited number of balloons in n colors . How many ways are there to give 2 differently colored balloons to each of k people if: no 2 people can get the same pair of colors. no 2 people get same color. For part 1, First we choose a pair of 2 distinct balloons = $n\choose2$ Then, we find he number of ways to choose these pairs = ${{n\choose 2}\choose{k}}$ The ways to give one of k different pairs to each of k different people = k! Final answer : $${{{n}\choose{2}}\choose{k}}k!$$ For part 2, Since no 2 people get the same color, we have to give each person a pair of different colors So first person gets $n\choose2$ balloons Second person gets $(n-2)\choose2$ Third person gets $(n-4)\choose2$ ... and so on till the last balloon, but I'm not sure how to find the last person. Also I'm not sure about the method I used.","['combinatorics', 'discrete-mathematics']"
2634851,Set Theory question about equalities of sets,"Consider the following sets: $A=\{3,4\},$     $B=\{4,3\}\bigcup \emptyset, C=\{4,3\}\bigcup\{\emptyset\}$ Which pairs of sets are equal? My attempt: We obviously have $C=\{4,3,\emptyset\}$ We also have(?) $B=\{4,3\}$ as by the Null set Axiom, the empty set is the unique set having no elements. Now by the extensionality axiom, $A$ and $B$ are equal since they have the same elements. However, they are not equal to $C$ as they don't contain the empty set as an element. Is that true? I'm still unsure about the bit where I look at the empty set as an element of $C$ since technically, no element of $C$ is not an element of $A$ or vice versa, hence we can use ZF1 again to conclude that they are equal?? Thanks in advance",['elementary-set-theory']
2634875,"Joint differential entropy of sum of random variables: $h(X,X+Y)=h(X,Y)$?","I see the following simplification used frequently in the literature, but I have not been able to verify it. Let $X$ and $Y$ be absolutely continuous (i.e. they have pdfs)
  $\mathbb{R}^d$-valued random variables. Assume the joint variable
  $(X,X+Y)$ is absolutely continuous on $\mathbb{R}^{2d}$. Then 
  $$h(X,X+Y)=h(X,Y).$$ Here $h$ signifies differential entropy, defined by 
$$h(W)=-\int_{\mathbb{R}^{d_W}}f_W(w)\log(f_W(w))\ dw$$
whenever $W$ is an $\mathbb{R}^{d_W}$-valued random variable with pdf $f_W$. Note1: $X$ and $Y$ are not assumed to be independent. Note2: Examples where the lhs is finite but the rhs is not defined would be accepted as a counterexample. I am also wondering, if the statement can be proved, then is it more generally true that
$$h(X,g(X,Y))=h(X,Y)$$
where $g$ is a deterministic function of its arguments? This question is similar, but seems to concern Shannon entropy (i.e. discrete variables). Shannon Entropy and Differential Entropy have different sets of properties as discussed in these links answer1 , answer2 , question1 ,and question2 .","['probability-distributions', 'statistics', 'entropy', 'probability', 'random-variables']"
2634895,"If $f\in L^{1}((0,1))$, does it hold that $\lim\limits_{n\to+\infty}\int_{0}^{\frac{1}{n}}f(x)\mathrm{d}x=0$?","I have met this problem while studying some functional and real analysis. I can't use Holder's inequality, since it seems useless. Any idea?","['real-analysis', 'lp-spaces', 'measure-theory']"
2634932,Integration of $\int_{-1}^{1}\frac{dx}{(x-a)\sqrt{1-x^2}}$ using Residue Calculus,"I would like to use residue calculus to prove that $\int_{-1}^{1}\frac{dx}{(x-a)\sqrt{1-x^2}} = \frac{\pi}{\sqrt{a^2-1}}$ , where $a$ is a complex constant outside of the real interval $[-1, 1]$. My idea for a strategy is to use a contour shaped like a dog-bone. It consists of two small circles (of radius $\varepsilon$) around $-1$ and $1$, that are connected by two segments near the real axis (one slightly above, and one slightly below). We know that the poles at $1$ and $-1$ are contained in the contour, and the pole at $z=a$ is not (for small enough $\varepsilon$). I would like to show integral goes to zero on the circle segments but I am having trouble doing this. Since the integrand is odd, we know that the segments along the axis will give us twice the required integral . By the residue theorem, we know that the integral over the contour equals $2\pi i$ times the sum of the residues of the poles contained within the contour. However, I am also having trouble calculating these two residues. I don't think any other contour would work because we do not 
know where $a$ is on the complex plane. Any help would be greatly appreciated. - Progress Update: I have figured out how to show that the integral goes to zero on the circle segments. However, I have also realized that the integrand is actually not odd (it was silly of me to make such a mistake). So now I am stuck trying to find a relationship between the integral along the top segment and the integral along the bottom segment. One of these is the desired integral, depending on the direction of the contour. But I do not know how to handle the other segment.","['complex-analysis', 'residue-calculus', 'complex-integration']"
2635008,Symplectic form on the n-torus,"I am trying to show that the n-torus, $\mathbb{R}^{2n}/ \mathbb{Z}^{2n}$ always has a symplectic form. By the Quotient Manifold Theorem, we have a smooth structure on the n-torus and a covering map $\pi \colon \mathbb{R}^{2n}\longrightarrow \mathbb{R}^{2n}/ \mathbb{Z}^{2n}$. Then, we have an open covering of the n-torus and in each open we can define a symplectic form by passing the symplectic form of an open of $\mathbb{R}^{2n}$ by a diffeomorphism. However, I am having troubles to understand why the symplectic form is defined globally; i.e, why it varies smoothly. Thanks in advance.","['symplectic-geometry', 'differential-geometry']"
2635064,When is the structure sheaf not coherent over itself?,"In the higher direct image sheaves section of Vakil (18.8), he makes the assumptions that $\mathscr{O}_Y$ is coherent over itself several times. How could $\mathscr{O}_Y$ not be Noetherian over itself? Over each affine open $U_i = $Spec $A_i$, isn't $\mathscr{O}_Y|_{U_i} = \widetilde{A_i}$, which is generated by 1?","['sheaf-theory', 'algebraic-geometry']"
2635120,How to Count Homomorphism from any finite group G to infinite cyclic group?,Question How to Count Homomorphism from any finite group G to infinite cyclic group MY Approach I Know I also know that a homomorphism is completely determined by its action on unit  element (like 1),"['abstract-algebra', 'group-theory', 'group-isomorphism', 'group-homomorphism']"
2635122,Eigenvalues without any calculations,"Question is from Intro to Linear Algebra (5th Ed) by Gilbert Strang, Chapter 6-39. Without writing down any calculations, can you find the eigenvalues of this matrix?  Also find $A^{2017}$. $$	A = \begin{Bmatrix}
		110 & 55 & -164\\
		42 & 21 & -62\\
		88 & 44 & -131
	\end{Bmatrix} $$ Obviously one of the eigenvalues is $0$.  Not sure how to find the rest without calculation.","['eigenvalues-eigenvectors', 'linear-algebra']"
2635175,Proving that this function converges uniformly.,"I was wondering if there is an easier way to show that this sequence of functions converges uniformly. Also I am almost $100 \% $ sure that my reasoning is not a proof, so yeah, help me please (there must be other way). $$ f_{n}(z)=\frac{e^{-n|z| }}{n} $$ 
With $z\in \mathbb{C} $ I thought that since this sequence tends to zero no matter what is the absolute value of $z$ . Being this limit the zero function in $\mathbb{C}$. The only way that maybe break the apparent uniform convergence is by choosing $$f(z^*)$$ such that $$|z^*| = \ln\frac{1}{n^{\frac{1}{n}}}$$ so that $$f(z^*)=\frac{1}{1} $$ but in order to get this i would have to choose a natural $n$ such that the absolute value of $z^*$ is of course positive, and this would be a $n$ such that 
$$ 0<n^{\frac{1}{n}}< 1$$ so there is no $n$ that satisfies this condition.","['sequence-of-function', 'sequences-and-series', 'uniform-convergence']"
2635188,Prove that a degree-$6$ polynomial has exactly $2$ real roots,"I have the function $f(x)={7x^6+8x+2}$ and I'm trying to prove that $f$ has exactly 2 real roots. What I've done: The only kind of solution I have come up with is essentially guessing pairs of values for $x$ that give $f$ a different sign and then make use of Bolzano's Theorem. More specifically: $f(-1)=1>0$ and $f(-{1\over 2})=-{121\over 64}<0$, so according to Bolzano's Theorem, there is some $x \in (-1, -{1 \over 2})$ such that $f(x)=0$. $f(-{1\over 2})=-{121\over 64}<0$ and $f(0)=2$, so according to Bolzano's Theorem, there is some $x \in (-{1 \over 2}, 0)$ such that $f(x)=0$. Question: The above solution looks kind of meh to me and I don't think it proves there are exactly 2 real roots, but rather that only 2 were found. Is there a better, more convincing way to prove the existence of exactly 2 roots?","['real-analysis', 'polynomials', 'roots', 'rolles-theorem', 'calculus']"
2635206,Problem relating to primes and sequences,"Prove/Disprove that there exist positive integers $a$ and $N$ such that the sequence $\overline{N}, \overline{aN}, \overline{aaN}, \overline{aaaN}, \ldots$ contains infinitely many primes. ($\overline{xy}$ refers to concatenating the digits of $x$ and $y$) This problem was thrown around a maths chat. We ran some computer programs use Miller-Rabin primality test on Python and we got some sequences which seemed to keep having primes (such as $a=2$, $N=3$), and others which we could easily mod-bash to see only have finitely many primes (such as $a=5$, $N=37$). We couldn't determine whether it would always be the case that there are finitely many primes, or whether $a=5$, $N=37$ was an exception. EDIT: After a bit more thought, we started considering what sort of conditions would be sufficient for such a sequence to only contain finitely many primes. There are some obvious ones like $N$ even or divisible by $5$, as well as $p \mid a, N$ for odd primes $p$. However, these don't cover the example of $a=5$, $N=37$. Are there any more sufficient conditions?","['number-theory', 'prime-numbers']"
2635227,Bounding $|\cos (2n+1)\theta |$,I am trying to find a bound for $|\cos (2n+1)\theta |$ by something of the form $c(n)|\cos \theta|$. I am suspecting that we can bound it by $(2n+1)|\cos \theta|$ but I'm not sure how to show that this is true.,['trigonometry']
2635261,Kullback-Leibler divergence is equivalent to L2 norm in some cases?,"This is a question similar to 1 and 2 . I wan to find out what the relationship between Kullback-Leibler divergence and L2 norm. Finally, I get the answer in  one book named ""Smoothing of Multivariate Data: Density Estimation and Visualization"". But I can not prove the Lemma in this book. Does anyone can help me to prove the Lemma together. And my probability density function is a GMM. Thanks in advance. For the sake of completeness I quote the Lemma 11.6: Let $D_k$ be the Kullback-Leibler distance defined in (11.8). We have $$D_k^2(f,f_0)\le\int_{\{x\in \mathbb{R}^d:f_0(x)\gt0\}}\frac{(f-f_0)^2}{f_0}.$$ The upper bound is called the $\chi^2$-divergence between $f$ and $f_0$. In particular if $\inf_{x\in \mathbb{R}^d}$$f_0(x)\gt0$, then $$D_k^2(f,f_0)\le\frac{\lVert f-f_0\rVert_2^2}{\inf_{x\in \mathbb{R}^d}f_0(x)}.$$ Also, if $f$ and $f_0$ are both bounded and bounded away from zero, then $$D_k^2(f,f_0)\ge\int_{\{x\in \mathbb{R}^d:f_0(x)\gt0\}}(f-f_0)+C\lVert f-f_0\rVert_2^2,$$ for a positive constant C. Some other formulas maybe used are given as follows:$$D_k^2(f,g)=\int_{\mathbb{R}^d\cap\{x:g(x)\gt0\}}f\log_e(\frac{f}{g})\quad\quad(11.8)$$ $$\lVert f-\hat f\rVert_P^P=\int_{R^d}\lvert f-\hat f\rvert^P$$","['probability-theory', 'probability', 'measure-theory', 'statistics']"
2635277,Using induction to prove sum of certain number-theoretic function.,"For any positive integer $ n > 1$, let $P(n)$ denote the largest prime not exceeding $n$.
Let $N(n)$ denote the next prime larger than $P(n)$. (For example $P(10) = 7$ and
$N(10) = 11$, while $P(11) = 11$ and $N(11) = 13$.) If $n + 1$ is a prime number, prove
that the value of the sum $$ \frac{1}{P(2)N(2)} + \frac{1}{P(3)N(3)} + \cdot\cdot\cdot + \frac{1}{P(n)N(n)} = \frac{n-1}{2n+2}$$ Can I use induction on two consecutive primes $k+1$ and $k+q+1$? If so, then here is my proof: Since the result holds true for $n=2$ and $n=4$, suppose that it holds true for $n=k$ with $k+1$ being prime. Then, $$\sum_{2}^{k}{\frac{1}{P(n)N(n)}} = \frac{k-1}{2(k+1)}$$ Then suppose that $k+q+1$ is the next prime greater than $k+1$, then $\forall m$ such that $ k+1 \leq m < k+q+1$, $P(m) = k+1$ and $N(m) = k+q+1$. Therefore, $$\sum_{2}^{k+q}{\frac{1}{P(n)N(n)}} = \sum_{2}^{k}{\frac{1}{P(n)N(n)}} + \sum_{k+1}^{k+q}{\frac{1}{P(n)N(n)}} = \frac{k-1}{2(k+1)} +\frac{q}{(k+1)(k+q+1)}$$ Which, on manupulation yields $$\sum_{2}^{k+q}{\frac{1}{P(n)N(n)}}=\frac{k+q-1}{2(k+q+1)}$$ Hence completes the proof. Is this correct or am I missing something?","['number-theory', 'contest-math', 'problem-solving', 'elementary-number-theory']"
2635313,Regular polygon areas in ratio 3:2,"Two regular polygons are inscribed in the same circle of radius $r$. First one has $k$ sides and second has $p$ sides. We are given that their areas have a ratio of $1.5$.
Calculate the area of a regular polygon inscribed in the same circle, having number of sides the sum of the other two numbers. Area of the first polygon: 
$$A_k = \frac{1}{2}\cdot k \cdot r^2 \cdot \sin\bigg(\dfrac{2\pi}{k}\bigg)$$
and area of the second:
$$A_p = \frac{1}{2} \cdot p \cdot r^2 \cdot \sin\bigg(\dfrac{2\pi}{p}\bigg)$$
Also $\frac{A_k}{A_p} = 1.5$ (assuming $k>p$ WLOG)
So $$\frac{A_k}{A_p} = \frac{k}{p} \cdot \frac{\sin\bigg(\dfrac{2\pi}{k}\bigg)}{\sin\bigg(\dfrac{2\pi}{p}\bigg)} = 1.5$$ Now obviously:
$$A_{k+p} = \frac{1}{2} \cdot (k+p) \cdot r^2 \cdot \sin\bigg(\dfrac{2\pi}{k+p}\bigg)$$
But I don't know how to continue, i.e. how to find a relation between the sins.",['geometry']
2635331,Inverse normalization function,"As far as I know the the normalization function is capable of normalize values between 0 and 1: $$\frac{X - \min}{\max - \min}.$$ With this the highest value will be mapped as $1$ and the lowest as $0$.
My question is the following: is there a way to map those values in an opposite way? Briefly speaking I want to map the highest value to $0$ and the lowest to $1$. Is there a function to do this?",['algebra-precalculus']
2635345,Doubts about homogeneous coordinates and points at infinity,"I've known about homogeneous coordinates and points at infinity for a very long time, but never had much reason to use them. I've used homogeneous coordinates to represent translations using transform matrices, but nothing else. I had an idea a couple of days ago (relating to optimization) which seems to require points at infinity. But I immediately ran into problems. As soon as I sat down and thought through what points of infinity actually are, I found what seemed like a fundamental problem with my understanding - it contradicts Euclid's axioms. I knew I had an old book that covers the subject, so I went back to that and checked. That didn't resolve the issue, it just allowed me to state the contradiction (hopefully) more clearly. So - the book is Applied Geometry for Computer Graphics and CAD, by Duncan Marsh, ISBN 1-85233-080-5, first edition, published by Springer-Verlag in 1999. Chapter 2 is 'Homogeneous Coordinates and Transformations of the Plane'. The almost complete first paragraph of section 2.2 'Points at Infinity' is... Homogeneous coordinates of the form $(x, y, 0)$ do not correspond to a
  point in the Cartesian plane, but represent the unique point at
  infinity in the direction $(x \; y)$. To justify this remark, consider
  the line $(x(t),y(t)) = (tx + a,ty + b)$ through the point $(a, b)$
  with direction $(x \; y)$. The point $(tx + a, ty + b)$ has
  homogeneous coordinates $(tx + a,ty + b, 1)$ and multiplying through
  by $1/t$ (for $t \neq 0$) gives alternative homogeneous coordinates
  $(x + a/t,y + b/t, 1/t)$. Points on the line an infinite distance away
  from the origin in the Cartesian plane may be obtained by letting $t$
  tend to infinity. The limiting point of $(x + a/t,y + b/t, 1/t)$ as $t
> \to \infty$ is $(x, y, 0)$. Therefore, it is natural to interpret the
  homogeneous coordinates $(x, y, 0)$ as the point at infinity in the
  direction $(x, y)$. Limits sometimes worry me. The limit of a function that approximates another
function at a given point is often taken as the value of the function being
approximated at that given point, but that can lead to non-unique values and to contradictions. An example is the tangent of 90 degrees - take the limit of an approximation and you get either $+\infty$ or $-\infty$ depending on which side you build your approximation function to approach from. Here, Marsh takes a formula along one particular line, takes a limit, and declares that the result is the ""point at infinity"", in doing so implying that the homogeneous coordinates resulting from that limit represent that ""point at infinity"" uniquely. I don't believe that's true. I believe that even though that formula describes the points along a line, the limit isn't a point at all - it's a direction. Which doesn't mean it's not a useful concept, but it does seem important to have the right intuitions. But first, I claimed a contradiction with Euclid's axioms... The relevant axioms are usually listed as the first two... A unique line segment can be drawn between any two distinct points. Any finite straight line segment can be extended indefinitely, to form a
unique infinite line. The point is that although Marsh only discusses taking $t \to +\infty$, it's just as valid to take $t \to -\infty$. Obviously if an unbounded line has any points at infinity, it has two. And two points are exactly what you need by Euclid's axioms to define a unique line. I list Euclid's second axiom only to assert that those lines drawn from distinct finite points aren't somehow distinct from those drawn between distinct points at infinity (presumably the justification for evaluating points at infinity from that limit). However, any two parallel lines - with emphasis on distinct parallel lines - have the same two points at infinity. By Euclid's axioms, that apparently means they're all the same line after all - any straight line is a space-filling curve. That's clearly absurd. The claim that the result from the limit uniquely identifies a point at infinity is then almost immediately used to justify the claim that any pair of parallel lines has a unique intersection at infinity. As far as I'm aware this is a standard use for points at infinity using homogeneous coordinates. But if distinct parallel lines really are distinct, I believe I've just proven that the homogeneous coordinates of a point at infinity do not uniquely identify a point at infinity. Distinct parallel lines share the same two ""point at infinity"" homogeneous vectors but aren't the same line. Those two opposite ""point at infinity"" vectors are not sufficient information to uniquely identify one line. If a line is to be drawn between two ""point at infinity"" homogeneous vectors, those vectors don't contain sufficient information to identify which particular line. An alternative argument is basically to forget Marshes limit and look at the the parallel lines themselves. The distance between them is constant, no matter how far along them you travel. Even at infinity, the distance between them is unchanged. Therefore, they don't intersect. So in short, I'm claiming that... Homogeneous coordinate vectors in which the ""extra"" ordinate is zero represent directions, not (absolute or relative) positions, in the underlying non-homogeneous space. I think of the extra ordinate as representing sensitivity to translation - the idea that directions (without magnitude) are insensitive to translation seems very reasonable, and this fits with that limit ""forgetting"" which particular parallel line it approaches infinity along. A point and a direction is sufficient to uniquely define a line. Two precisely opposite directions (the two directions along the same line) give no more information than just one direction, and are not sufficient to uniquely identify a line. With no reason to ""miss"" the origin, it might be tempting to draw the line through the origin, but all the parallel lines have equal claim to be ""the"" line with that direction. Rather than being able to drawn lines between any two arbitrary ""points at infinity"", lines with two distinct non-opposite directions are self-contradictions. Parallel lines don't intersect, not even at either or both of their respective infinities. If points at infinity exist as actual points, they cannot be uniquely identified purely by homogeneous coordinates that describe translation-insensitive directions. Have I made some stupid error in this? (I don't think so, but then I never do at the time). Has Marsh misled me? When points at infinity are used correctly , do Euclids axioms need to be worded slightly differently than I have them? Is the name ""points at infinity"" just a name that shouldn't be taken too literally for something that's really just a direction? BTW - I don't think this breaks my idea - a direction as a ""point at infinity"" should be fine just so long as I'm clear what I can do with that direction - what makes geometric sense and what doesn't. The idea itself is far too obvious to be original, but I want to work it out for myself. I've held back from adding extra tags (e.s.p. homogeneous-spaces) because I'm not sure they're appropriate.",['geometry']
2635356,Solve truth table task,"I am solving next task:
$$\left(x \vee y\right) \rightarrow \bar{x}$$ I assume that line above $\bar{x}$ makes it opposite of $x$ and my solving is this:
$$\begin{array}{|cc|c|c|c|}
\hline
x &y & x\lor y &x & \left(x \vee y\right) \rightarrow \bar{x}  \\  \hline
\text{T} & \text{T} & \text{T} & \text{T} & \text{F} \\
\text{T} & \text{F} & \text{T} & \text{F} & \text{F} \\
\text{F} & \text{T} & \text{T} & \text{T} & \text{T} \\
\text{F} & \text{F} & \text{F} & \text{T} & \text{T} \\ \hline
\end{array}$$
Does my calculations correct? If not why? EDITED","['propositional-calculus', 'logic', 'discrete-mathematics']"
2635362,Does $\lim a_n$ exist?,"Let $(a_n)_n$ and $(b_n)_n$ be two positive real sequences. If $0\leq a_n \leq b_n$ and $\lim b_n$ exists. Is $\lim a_n$ exists? I ask this question because now I'm reading a paper and I think the authors used the above properties, but I think it's not in general true.","['real-analysis', 'sequences-and-series', 'limits']"
2635376,"Let $f$ a function with bounded partial derivatives. Find the greatest value that $f$ can achieve at point $(1, 2)$","Let $f: \mathbb{R}^2 \rightarrow \mathbb{R}$ a function partial differentiable with \begin{align*}
 \left| \frac{\partial f}{\partial x} \,  (x, y) \right| \leq 10 \, \, \, \,  \text{and} \, \, \, \left| \frac{\partial f}{\partial y} \, (x, y) \right| \leq 20
\end{align*}
for all $(x, y) \in \mathbb{R}^2$ and with $f(0, 0) = 0$. Find the greatest value that $f$ can achieve at the point $(1, 2)$.
Give an example of a function $f$ satisfying these assumptions and such that $f(1, 2)$ achieve this value. I have really no idea to solve this problem (maybe with Taylor's theorem but I don't know how). I only know that a function $f$ satisfying these assumptions is continuous and $L$-lipschitz with $L:=10 \sqrt5$ but I don't see anything else. Can someone help me please?
Thanks in advance!","['real-analysis', 'taylor-expansion', 'partial-derivative', 'multivariable-calculus', 'analysis']"
2635388,Is there an entire function satisfying $|f(z)|=|z|+1$ for every $|z|\geq2017$? [duplicate],"This question already has an answer here : Does there exists an entire function such that for each $|z|>C$ for some constant $C$, $|f(z)|=|z|+1$? (1 answer) Closed 6 years ago . Is there a holomorphic function $f \in Hol(\Bbb C)$ such that $|f(z)|=|z|+1$ for every $|z|\geq2017$ ? I tried defining $g(z)=\frac{1}{f(z)}$. Such $g$ is clearly holomorphic and bounded for $|z| \geq 2017$. I want to show that $g$ is holomorphic in $|z| \leq 2017$ and then conclude that $g$ is constant. For that I want to show that $f$ has no zeros in $|z| \leq 2017$. I tried to prove it by Rouche theorem, but didn't succeed. Any ideas? Edit: the post similar to mine doesn't solve my problem, because the ending of the proof is not clear. Where is the contradiction?","['complex-analysis', 'holomorphic-functions', 'entire-functions']"
2635400,References for sufficiency of tangential criteria for formally smooth/unramified/étale morphisms,"In this MO question the author asks about the sufficiency of tangential criteria for determining formal smoothness/unramifiedness/étaleness, at least for varieties. This comment states: For varieties over $k$, tangential criteria OK in smooth case at $k$-points (as the complete local ring is power series ring over $k$). As a complete novice in algebraic geometry seeking a good understanding of formally smooth/unramified/étale morphisms, I am not able to fill the gaps in the linked comment(s). What are some references for sufficiency of tangential criteria for smooth varieties? Why are tangential criteria not always sufficient? Particularly what are some examples where they are satisfied but the morphism in question is not formally smooth/unramified/étale? I think my second question is related to this one , asking for examples of non-split square-zero extensions (in characteristic zero).","['schemes', 'affine-schemes', 'algebraic-geometry', 'commutative-algebra']"
2635449,Finite dimensional distributions of brownian motion changed at a random point,"In the book on Brownian Motion by Yuval Peres, he makes the following claim: Suppose that $\{ B(t); \ t \geq 0 \}$ is a Brownian Motion and $U$ is an independent random variable, uniformly distributed on $[0, 1]$. Then the process $\{ \tilde{B} (t); \ t \geq 0 \}$ defined as,
  $$\tilde{B}(t) = \begin{cases} B(t)  & \mbox{ if $t \neq U$} \\ 0  & \mbox{ if $t = U$} \end{cases}$$ has the same finite-dimensional distributions as a Brownian motion, but is discontinuous if $B(U) \neq 0$, i.e. with probability one, and hence this process is not a Brownian motion. I'm having difficulty in proving that the finite dimensional joint distribution ( basically the joint distribution of $( \ \tilde{B}(t_1), \ \tilde{B}(t_2), \tilde{B}(t_3), \dots \tilde{B}(t_n) \ )$ ) is the same as the finite dimensional distribution of $B(t)$. Can you please give me some clues.","['probability-theory', 'brownian-motion', 'probability-distributions']"
2635455,Prove that $f(ax + (1-a)y) = \frac{1}{y-x}\int_x^y f(t)dt$ implies $a = \frac{1}{2}$,"Let $f: \mathbb{R} \to \mathbb{R}$ be a non-constant function, integrable on every interval $[x,y] \subset \mathbb{R}$ and $a \in \mathbb{R}$ such that $$f(ax + (1-a)y) = \frac{1}{y-x}\int_x^y{f(t)dt}, \quad \forall x<y$$
  Prove that $\displaystyle a = \frac{1}{2}$. This is a small part from another problem. If I can prove that $\displaystyle{a = \frac{1}{2}}$ then the whole problem is solved, but I don't know how. Edit : If $f$ is integrable, then the function $F : \mathbb{R} \to \mathbb{R}, F(x) = \displaystyle{\int_m^x{f(t)dt}}, m \in \mathbb{R}$ is continuous. Since we have that $\displaystyle{f(ax + (1-a)y) = \frac{1}{y-x}\int_x^y{f(t)dt}, \forall x<y}$, then $f$ is continuous and $F$ is differentiable. This implies that $f \in C^{\infty}(\mathbb{R})$. If $\displaystyle{a = \frac{1}{2}}$, then $\displaystyle{f\left(\frac{x+y}{2}\right) = \frac{1}{y-x}\int_x^y{f(t)dt}, \forall x < y}$. So we have equality in the Hermite-Hadamard inequality, which is achieved when $f$ is linear on that interval.","['real-analysis', 'integration', 'definite-integrals']"
2635460,What is the average value of the determinant of matrices in this set? [duplicate],"This question already has an answer here : The average determinant of all integer matrices with coefficients $0,1,2$ [closed] (1 answer) Closed 6 years ago . State true or false. Let $n \geq 2$ be a natural number. Let $S$ be
  the set of all $n \times n$ real matrices whose entries are only $0,
1$ or $2$. Then the average of determinants of matrices in $S$ is greater than or equal to $1$. This is how I think the answer should go, but I am not fully convinced. False. The average value is zero. There are only finitely many matrices in $S$, and we can exhibit a one-to-one correspondence between the matrices with non-zero determinants as follows: given $A \in S$ with positive determinant, interchanging the first two columns of $A$ gives us a matrix in $S$ with negative determinant. As this function has an inverse (itself) it is bijective. Thus, the average value of the determinant of matrices in $S$ is zero.","['matrices', 'linear-algebra', 'proof-verification', 'determinant']"
2635465,Why is the symmetry group $S_3$ not the direct product of two nontrivial groups?,"I know that $S_3$ is the semi direct product of $\bigl\langle(1\ \ 2\ \ 3)\bigr\rangle \rtimes\bigl\langle(1\ \ 2)\bigr\rangle$, and I'm not sure where exactly the direct product property fails. Is it only because $\bigl\langle(1\ \ 2)\bigr\rangle$ is not normal in $S_3$?","['abstract-algebra', 'group-theory', 'permutations', 'semidirect-product', 'symmetric-groups']"
2635516,"A conjecture about numbers of the form $10^{m}(2^{k}−1)+2^{k-1}−1$, where $m$ is the number of decimal digits of $ 2^{k-1}$.","Question Numbers $n$ of the form $10^{m}(2^{k}−1)+2^{k-1}−1$ , where $m$ is the number of decimal digits of $ 2^{k-1}$ . For example: $k=1$ then $n=10$ . $k=2$ then $n=31$ . $k=3$ then $n=73$ . $k=4$ then $n=157.$ Conjecture: the number $(2^k-1)\cdot 10^m+2^{k-1}-1$ where $m$ is the number of decimal digits of $2^{k-1}$ is never prime when it is of the form $7s+6$ , that is when it is congruent to $6$ $\pmod 7$ . Examples: $n=1023511$ ( $k=10$ ) $\equiv 6 \pmod 7$ and thus it is composite $(1023511=19\times103\times523)$ , $n=20471023$ ( $k=11$ ) $\equiv 6 \pmod 7$ and thus it is composite ( $20471023=479\times42737)$ . With PFGW we arrived to $k=565000$ and all the $n's$ congruent to $6 \pmod 7$ are composite. According to Giovanni Resta's calculations in a post which has been canceled, there should be no probable prime congruent to 6 $\pmod 7$ upto k=800.000. The residue $6$ $\pmod 7$ occurs when either $m=6t+3$ and $k=3l+1$ or $m=6t+4$ and $k=3l+2$ with $k$ and $l$ some non-negative integers, but amazingly when it occurs the number is not prime. Can you find a counter-example or give a proof for the conjecture? Here a link to other interesting questions: Is there a number of the form $f(n)=7k+6=5p$ with prime  p? and Why do all residues occur in this similar sequence? For primes of this form see: The on-line Encyclopedia of integer sequences The following vector contains all the exponents k<=366800 leading to a prime $[2, 3, 4, 7, 8, 12, 19, 22, 36, 46, 51, 67, 79, 215, 359, 394, 451, 1323, 2131, 3336, 3371, 6231, 19179, 39699, 51456, 56238, 69660, 75894, 79798, 92020, 174968, 176006, 181015, 285019, 331259, 360787, 366770]$ Exponent $541456$ leads to another probable prime with residue 5 mod 7 and 325990 digits, but it need not be the next in increasing order. Remark: we found five-in-a-row probable primes with res 5 mod 7. Probable primes with residue 5 are now twice frequent than expected.
Exponents of these primes seem to be NOT random at all. Another thing I noticed, i don't know if it has some importance: the exponents leading to a probable prime $215, 69660, 92020, 541456$ are multiples of $43$ . I noticed that $\frac{215}{41}, \frac{69660}{41}, \frac{92020}{41}, \frac{541456}{41}$ all have a periodic decimal expansion equal to $\overline{24390}=29^3+1$ . This is equivalent to say that when k is a multiple of 43 and the number $10^{m}(2^{k}−1)+2^{k-1}−1$ is prime, then k is of the form $41s+r$ where r is a number in the set (1,10,16,18,37). Is there some mathematical reason for that?","['number-theory', 'integers']"
2635600,"Computing $\int \sqrt{x\sqrt[3]{x\sqrt[4]{x\sqrt[5]{x\cdots}}}} \,\mathrm{d}x$","I've just read a post that has been put on hold.  The question was about computing
$$
\int_{ }^{ }\sqrt{x\sqrt[3]{x\sqrt[4]{x\sqrt[5]{x \cdots}}}}\, \mathrm{d}x
$$
My attempt was to find explicitely the integrand hence I introduced the sequence
$$
a_1=1\ \text{ and }\ a_{n+1}=\left(xa_n\right)^{1/(n+1)}
$$
hence
$$
a_2=\sqrt{xa_1}=\sqrt{x}, \ a_3=\sqrt[3]{xa_2}=\sqrt[3]{x\sqrt{x}} \ \dots
$$
But the power is reversed, how can I ffind the corresponding $(a_n)_{n\in \mathbb{N}}$ ?","['definite-integrals', 'sequences-and-series']"
2635608,"How to evaluate $\frac{1}{2\pi}\int \frac{1}{(1-\alpha \cos \omega)^2 +\alpha^2\sin^2 \omega } \, d\omega$","May I please get help to solve the following expression,
$$\frac 1 {2\pi}\int \frac 1 {(1-\alpha \cos \omega)^2 +\alpha^2\sin^2 \omega} \, d\omega$$ I have tried several ways, but couldn't get through. Thanks in advance.","['derivatives', 'integration', 'definite-integrals', 'trigonometric-integrals']"
2635635,Stars and bars with constraints,"I have searched a lot and don't really understand the answers I've come across. So apologies in advance if I'm repeating a common question. The problem is as follows: Distribute $69$ identical items across 
$4$ groups where each groups needs to contain at least $5$ items. The way I see the problem: $x_1 + x_2 + x_3 + x_4 = 69$,  $x_i \geq 5$ Could this then be the same as: $x_1 + x_2 + x_3 + x_4 = 49$,   $x_i \geq 0$, and therefore be solved using ${n + k -1} \choose {k - 1}$ = ${52}\choose{3}$ = $\frac{52!}{3!(52 - 3)!}$ = $\frac{52!}{3!49!}$ Or am I thinking completely wrong here?","['combinations', 'combinatorics']"
2635658,"In a hand of 13 cards, what is the probability that all cards have different values","I'm going to go through my thoughts, tell me if I'm right.
There are $52\choose 13$ different hands with 13 cards. Each value has to appear once with 4 suits for each so there are $ 4^{13}$ different hands with each number once.
So i conclude that the probability is $\frac{4^{13}}{52\choose13} \approx 1.1\times 10^{-4}$. I am really bad a probability so any help and/or tips on approaching problems at first year university level with would be appreciated (I can only find very basic or high level probability stuff with no intermediate level)",['probability']
2635704,What is the expected length of the diameter of a special random graph?,"Let $G=(n,p)$ be a random graph . For example, consider that $G$ is the following graph. Initially, the edges of $G$ is undirected. A random $id\in R$ is assigned to each vertex of $G$. The $id$ of vertex $v$ is denoted by $id_{v}$. For each edge $e=(v,u)$, if $id_{v}>id_{u}$, $e$ is converted to a directed edge from $u$ to $v$, and if $id_{v}<id_{u}$, $e$ is converted to a directed edge from $v$ to $u$. A root is a vertex which all incident edges are outgoing edges. In the example, $V_{1}$ is a root. Let $r$ be a root and $v$ be a none-root vertex which has the longest directed distance ($d_{r,v}$) from $r$. What is the expected value of $d_{r,v}$? In the example, $d_{V_{1},V_{2}} = 1, d_{V_{1},V_{3}} = 1,d_{V_{1},V_{4}} = 1,d_{V_{1},V_{5}} = 2$, so $V_{5}$ is a non-root vetex which has the longest directed distance from the root. The following solution is my solution. But I can't compute some parts of it. Is there another solution? There are $P(n,d_{r,v}-1)$ potential different paths with length $d_{r,v}$ from $r$ to $v$. The paths are labeled with numbers $1,...,P(n,d_{r,v}-1)$. The vertices of $i$th path are donoted by $r=\sigma^{i}_{1},\sigma^{i}_{2},...,\sigma^{i}_{d_{r,v}},\sigma^{i}_{d_{r,v}+1}=v$. $X_{i}\text{ }(1\leq i\leq P(n,d_{r,v}-1))$ is a random variable such that 
\begin{align}
X_{i}=\begin{cases}
1 \quad\text{$i$th potential path, $\sigma^{i}$, is a valid path from $r$ to $v$.}\\
0 \quad\text{o.w.}
\end{cases}
\end{align} Thus, $E[d_{r,v}]$ is as follows
$$E[d_{r,v}] = \sum_{i=1}^{P(n,d_{r,v}-1)}E[X_{i}]$$
What remains is computing $\Pr(X_{i}=1)$. $X_{i}=1$ when There is a path from $r$ to $v$. The probability of it is $p^{d_{r,v}}$. The $id$s of the path's vertices are monotonically increasing. The probability of it is $\frac{1}{(d_{r,v}+1)!}$. There is no edge from $\sigma^{i}_{j}$ to $\sigma^{i}_{j+2}$ ($1\leq j\leq d_{r,v}-1$), for if there is an edge $(\sigma^{i}_{j},\sigma^{i}_{j+2})$, then the length of the longest directed path from $r$ to $v$ is not $d_{r,v}$ and is $d_{r,v}-1$. The probability of it is $(1-p)^{\frac{(d_{r,v}-1)(d_{r,v}-2)}{2}}$. There is no path with length one from $\sigma^{i}_{j}$ to $\sigma^{i}_{j+3}$ ($1\leq j\leq d_{r,v}-2$). I can't compute it's probability! There is no path with length two from $\sigma^{i}_{j}$ to $\sigma^{i}_{j+4}$ ($1\leq j\leq d_{r,v}-3$). I can't compute it's probability! ...","['expectation', 'random-graphs', 'algorithms', 'probability', 'random-variables']"
2635731,Let $X$ and $Y$ be independent and identically distributed random variables with moment generating function then $E(\dfrac{e^{tX}}{e^{tY}})$,"Let $X$ and $Y$ be independent and identically distributed random variables with moment generating function $M(t)=E(e^{tX});\ \ -\infty<t<\infty$ 
then $E(\dfrac{e^{tX}}{e^{tY}})$ equals ? $(A)=M(t)M(-t)$ $(B)=1$ $(C)=(M(t))^2$ $(D)=\frac{M(t)}{M(-t)}$ My input: Since its given that random variables are i.i.d so  $E(\dfrac{\require{\cancel}\cancel{e^{tX}}}{\cancel{e^{tY}}})=E(1)=1 $ can I do that?","['statistics', 'probability', 'moment-generating-functions']"
2635747,Bounded sequence in probability admits converging subsequence in probability?,"Let $X_n$ be a random variable (say in $\mathbb{R}^p$), and consider this statement: Claim: ""For any sequence of random variables $X_n$ being bounded in probability , there exists a subsequence $X_{n_k}$, and some $X$, such that $X_{n_k}$ converges in probability to $X$."" I wonder if it is true, or if a counter-example can be found? Here is what I found so far on the topic: Fact 1 : Prokhorov's theorem states that bounded sequences in probability admit a subsequence converging in law . But convergence in law is weaker than convergence in probability. Since this theorem is presented as being very important, I can guess it is sharp. Fact 2: A sequence converging in probability admits a subsequence converging almost surely (see this other post ), which is a stronger mode of convergence than in probability. If my claim is true, we could deduce that any stochastically bounded sequence admits an almost surely converging subsequence. This would make the conclusion of Prokhorov's theorem even weaker.","['weak-convergence', 'probability-theory', 'compactness', 'convergence-divergence']"
2635763,The derivative of complex quadratic form,"Is there any way to represent the derivative of this complex quadratic statement into a compact matrix form? $${x^{{*^T}}}Ax = \left[ {\begin{array}{*{20}{c}}
  {{a_1}{e^{ - j{\theta _1}}}}& \cdots &{{a_n}{e^{ - j{\theta _n}}}} 
\end{array}} \right]A\left[ {\begin{array}{*{20}{c}}
  {{a_1}{e^{j{\theta _1}}}} \\ 
   \vdots  \\ 
  {{a_n}{e^{j{\theta _n}}}} 
\end{array}} \right]$$","['matrices', 'quadratic-forms', 'multivariable-calculus', 'derivatives']"
2635839,Number of Subsets that Satisfies a Divisibility Condition,"Here is an interesting question that I thought of: We call a subset $S$ of the positive integers good if for all $n \in S$, we have that $d \in S$ for all $d | n$. 
  Find the number of good subsets of $\{1, 2, ..., n\}$. If we let $f(n)$ be this number, we get $f(p) = 2f(p-1) - 1$ for primes $p$. But for non-prime $n$, it seems to difficult to connect it to earlier values of $n$. Any solutions, suggestions, or comments would be appreciated",['combinatorics']
2635840,Evaluate $\lim_{ n \to \infty} \sum_{r=2n+1}^{3n} \frac{n}{r^2-n^2}$,Evaluate $$S=\lim_{ n \to \infty} \sum_{r=2n+1}^{3n} \frac{n}{r^2-n^2}$$ I have used change of variable $k=r-(2n+1)$ Then $$S=\frac{1}{n} \times \lim_{ n \to \infty} \sum_{k=0}^{n-1} \frac{n^2}{(2n+1+k)^2-n^2}$$ Then how can we continue?,"['algebra-precalculus', 'integration', 'definite-integrals', 'summation', 'sequences-and-series']"
2635903,A book on statistics similar to Michael Spivak's Calculus,"I'm looking for an book on statistics that's similar to Michael Spivak's Calculus . It should be rigorous, starting with some fundamental axioms and build layers of theorems on top of it, and it should be concise.","['reference-request', 'statistics', 'book-recommendation']"
2635953,Is the gradiant a column or a row? [duplicate],This question already has answers here : The gradient as a row versus column vector (2 answers) Closed 6 years ago . Suppose we have $f:\mathbb{R^2}\rightarrow \mathbb{R}$. Vectors which $f$ act on are column vectors i.e a $2 \times 1$ matrix. Is the gradiant $\nabla f$ then a row vector? And why is this logical?,['multivariable-calculus']
2635967,Relative Hitchin-Kobayashi correspondence and relative Hermitian Yang-Mills connections,"Let $\mathcal E\to X$ be a stable vector bundle over a polarized projective manifold $(X,\omega)$.We know, that in this case $\mathcal E$ admits Hermitian-Einstein metric, i.e., a metric $h$, such that (may be up to some constants) $$
{\rm tr}_\omega F(\mathcal E, h)=\lambda \rm Id,
$$
where $F(\mathcal E, h)\in \Lambda^{1,1}(T^*M)\otimes \rm End(\mathcal E)$ is the curvature of Chern connection on $(\mathcal E, h)$ ${\rm tr}_\omega\colon \Lambda^{1,1}(T^*M)\otimes \rm End(\mathcal E)\to \rm End(\mathcal E)$ is a contraction with $\omega$ $\lambda=\int_X c_1(\mathcal E)\wedge\omega^{n-1}/\int_X \omega^n$. Let $\pi : X\to\Delta$ be a degeneration of  Hermitian-Einstein metrics $(X_s,\mathcal E_s) $ , then $$
{\rm tr}_{\omega_s} F(\mathcal E_s, h_s)=\lambda(s) \rm Id,
$$
where here $\lambda (s) $ is the fiberwise constant. Then under which condition the relative vector bundle $\mathcal E_{X/\Delta}$ admits relative Hermitian-Einstein metric? When can we get uniqueness on it? since in general $h_s=h_s'+f (s)$ and $f (s) $ is a test function . $$\frac{\partial^2 h_t(s')}{\partial s'\partial t}=-2h_t(s')(\Lambda F_{h_t(s')}-\lambda (s')Id)$$ In fact we are facing with Hyperbolic PDE instead parabolic PDE :) In this case $s'=\frac {1}{s}$ where $s'\to \infty$ since $s\to 0$
. In fact we have two times $t, s'$ for this deformation. In Donaldson flow we can get the canonical metric by deforming the metric by one time $t $ while in this case we have two times. In fact the relative vector bundle is not a vector bundle near central fiber. My conjecture is that when central fiber is Kahler manifold, then we can get a stability on relative vector bundle. In fact in general the central fiber is Moishezon when general fibers are projective. Moreover  the singular Hermitian metric is not well defined on the central fiber $(X_0, \mathcal E_0)$. So we need to impose some condition such that $h_0$ to be well defined. See this question In general, I think after possible semi stable reduction , on the disc $\Delta $, the central fiber admits Hermitian-Yang Mills connection. Hassan Jolany","['complex-geometry', 'algebraic-geometry', 'kahler-manifolds', 'vector-bundles', 'differential-geometry']"
2635972,Matrix polynomial,"Let $p \in \mathbb{N}, p \geq 2$ even. Prove that $$\det(X^{p}+X^{p-1}+\dots+X+I)\geq 0$$
  for all invertible matrices $X$ with real entries. The solution I found simply uses the fact that the polynomial $x^p+x^{p-1}+\dots+x+1$ doesn't have any real roots. Why is that enough?","['matrices', 'polynomials', 'linear-algebra', 'determinant']"
2635973,"If $f(x)$ is strictly increasing in an interval $[a,b]$ then what can we say about another function $g(x)=(f(x))^2$ in the same interval?","I want to know whether $g(x)$ will be increasing, decreasing or whether it's nature cannot be predicted in $[a,b]$. My attempt: If $f(x)$ is strictly increasing in $[a,b]$ then we can say that $f'(x)>0$ in the interval $[a,b]$. Now, $g'(x) = 2*f'(x$) which will also be greater than $0$ in the interval $[a,b]$ as $f(x)$ is greater than zero in that interval. So, $g(x)$ should be strictly increasing too in the interval $[a,b]$. But in the textbook, it is given that the nature of $g(x)$ cannot be predicted in the interval $[a,b]$ and I don't see any way to conclude that. Any help would be appreciated.","['derivatives', 'functions']"
2635980,Is the converse of Cayley-Hamilton Theorem true?,"The question is motivated from the following problem: Let $I\neq A\neq -I$, where $I$ is the identity matrix and $A$ is a real $2\times 2$ matrix. If $A=A^{-1}$, then the trace of $A$ is $$ (A) 2 \quad(B)1 \quad(C)0 \quad (D)-1 \quad (E)-2$$ Since $A=A^{-1}$, $A^2=I$. If the converse of Cayley-Hamilton Theorem is true, then $\lambda^2=1$ and thus $\lambda=\pm1$. And then $\rm{trace}(A)=1+(-1)=0$. Here are my questions: Is  $C$ the answer to the quoted problem? Is the converse of Cayley-Hamilton Theorem, i.e.,""for the square real matrix $A$, if $p(A)=0$, then $p(\lambda)$ is the characteristic polynomial of the matrix $A$"" true? If it is not, then what's the right method to solve the problem above?","['matrices', 'cayley-hamilton', 'linear-algebra']"
2635994,Why isn't the area of a square always greater than the length of one of its sides?,"Intuitively, it seems like the area of a square should always be greater than the length of one of its sides because you can ""fit"" one of its sides in the space of its area, and still have room left over. However when the length of a side, $s$ , is less than $1$ , then the area $s^2 < s$ , which doesn't make sense to me for the reason above.",['geometry']
2636016,Finding domain of $\sqrt{x^{12} - x^9 + x^4 - x + 1}$,"How to find the domain of this function $\sqrt{x^{12} - x^9 + x^4 - x + 1}$? Its really hard to find all 12 roots and plot them or use tricks like ""wavy curve"" to check where the expression in the square root is positive . But I thought (i'm not sure) if we can prove that the function is positive for all value then the job would be done, although i haven't been able to do it. It would be helpful if someone can solve this .",['elementary-set-theory']
2636024,Statistics: Why are school grades qualitative variable?,"I am struggling to understand, why in descriptive statistics we say that school grades are a qualitative and not quantitative variable? I can understand why color of the hair is qualitative, but grades are numerical...","['descriptive-statistics', 'statistics']"
2636071,Find the cardinality of the set of all equivalence relations in $\mathbb{R}$.,"Find the cardinality of the set of all equivalence relations in $\mathbb{R}$. Hello all. My attempt:
Let $B=\{X\subseteq \mathbb{R}\times\mathbb{R}|Id_\mathbb{R}\subseteq X \land X\circ X \subseteq X \land X^{-1}=X\}$ be the set of all equivalence relations in $\mathbb{R}$. ( is this correct? ) We'll claim $|B|=2^{\aleph}$. First, it is trivial that $|B|\le |P(\mathbb{R\times R})|=2^\aleph$ since $B\subseteq P(\mathbb{R\times R}) $ Now, I had already proved that the cardinality of $A$= {The set of all reflexive relations in $\mathbb{R}$} is $2^{\aleph}$ so I want to use the set A in this current proof.
We'll show an injective map $\psi:A\rightarrow B$ and by that we'll prove $|A|\le |B| \Rightarrow 2^{\aleph}\le |B|\le 2^{\aleph} \Rightarrow |B|=2^{\aleph}$ according to CSBT. Let $\psi:A\rightarrow B$ be the function 
$\psi(X)=  X\cup X^{-1} \cup X\circ X \cup (X\circ X)^{-1} $. Yes, this is indeed inelegant and possibly not even correct. I would love to get your help on that question. Thanks in advance.","['equivalence-relations', 'elementary-set-theory', 'discrete-mathematics']"
2636074,Evaluate $\int_0^1 \frac{\mathrm{d}x}{\sqrt{1-x^2}}\frac{x }{1-k^2x^2}\log\left(\frac{1-x}{1+x}\right)$,"I am trying to evaluate the following integral
$$I(k) = \int_0^1 \frac{\mathrm{d}x}{\sqrt{1-x^2}}\frac{x }{1-k^2x^2}\log\left(\frac{1-x}{1+x}\right)$$
with $0< k < 1$. My attempt By performing the substitution 
$$y=\frac{1-x}{1+x} \Longleftrightarrow x=\frac{1-y}{1+y}$$ we have
$$ I(k) = \int_0^1 \mathrm{d}y \frac{\log y}{\sqrt{y}}\frac{y-1}{(k^2-1)y^2-2y(k^2+1)+(k^2-1)}$$ Now we can decompose
$$\frac{y-1}{(k^2-1)y^2-2y(k^2+1)+(k^2-1)}= \frac{1}{2k(1+k)}\frac{1}{y+a}- \frac{1}{2k(1-k)}\frac{1}{y+a^{-1}}$$ with $a=\frac{1-k}{1+k}$ runs from $0$ to $1$.
Therefore we can write
$$I(k) = \frac{1}{2k(1+k)}\color{blue}{\int_0^1 \mathrm{d}y \frac{\log y}{\sqrt{y}}\frac{1}{y+a}} - \frac{1}{2k(1-k)}\color{red}{\int_0^1 \mathrm{d}y \frac{\log y}{\sqrt{y}}\frac{1}{y+a^{-1}}}$$ So we have only to evaluate $\color{blue}{I_1}$ and $\color{red}{I_2}$. Now we consider the following integral
$$ J(\sigma) = \int_0^1 \mathrm{d}x \frac{\log x}{\sqrt{x}}\frac{1}{x-\sigma^2}$$
so that $\color{blue}{I_1}=J(i\sqrt{a})$ and $\color{red}{I_2}=J(i/\sqrt{a})$. By considering the map $x\mapsto x^2$ we can write
$$ J(\sigma)=4\int_0^1\mathrm{d}x \frac{\log x}{x^2-\sigma^2}= \frac{2}{\sigma}\left[\color{green}{\int_0^1 \frac{\log x}{x-\sigma}}-\color{green}{\int_0^1 \frac{\log x}{x+\sigma}}\right]$$ The problem then reduces to evaluate the $\color{green}{\text{green}}$ integrals. At this point I'm stuck. I think that it needs to be solved by using polylogarithms, but I don't really know how to use these functions. Mathematica 11.0 says $$J(\sigma)=4 \left(\frac{\Phi \left(\frac{1}{\sigma ^2},2,\frac{3}{2}\right)}{4 \sigma ^4}+\frac{1}{\sigma ^2}\right)$$ where $\Phi$ is the  Lerch transcendent. I don't know if this result is true (numerical integration is somewhat problematic). However, if it is true, I don't know what to do next. Any hint on how to proceed with the evaluation? Thanks in advance!","['logarithms', 'polylogarithm', 'integration', 'definite-integrals']"
2636077,Flat bundle and constant transition functions,"Let $E$ be a vector bundle over connected manifold $M$ and let $\nabla$ be a connection on $E$ i.e. a map $\nabla: \Gamma^{\infty}(M,E) \to \Omega^1(M) \otimes \Gamma^{\infty}(M,E)$. It can be extended to act on whole $\Omega(M,E):=\Omega^{\bullet}(M) \otimes \Gamma^{\infty}(M,E)$. Although $\nabla$ is not $C^{\infty}(M)$ linear its square $\nabla^2$ (understood as a composition of original connection with the extended one: $\nabla \circ \nabla$) is $C^{\infty}(M)$ linear. A bundle $E$ is called flat if $\nabla^2=0$. I would like to understand why Flatness is equivalent to the condition that the transition functions of $E$ are constant. I know that this was discussed already, e.g. here however the explanation there is rather sketchy and I would like to see some more detailed argument (and also understand the converse implication).","['connections', 'vector-bundles', 'differential-geometry']"
2636083,Reciprocal sum with 2017,"Find 2017 distinct postive integers ($a_1, a_2, \dots, a_{2017}$) such that
$$\sum_{i=1}^{2017}\dfrac{1}{a_i}=\dfrac{2017}{1000}$$ That is what I know: $1=1/2+1/3+1/6$. From that we can find infinity many ways to reach 1 as sum of reciprocals of distinct positive integers.","['algebra-precalculus', 'summation']"
2636089,Understanding weak convergence of probability measures,"Weak convergence of a sequence probability measures, denoted $P_n \Rightarrow P$, is typically defined as, $$ \int\limits_{\mathbb{R}}fdP_n \xrightarrow{n\rightarrow\infty} \int\limits_{\mathbb{R}}fdP \;\;\;\; (*)$$ for all $f \in C_b(\mathbb{R})$, the space of continuous and bounded functions. However I read here that if $(*)$ holds for all $f \in C_c^\infty(\mathbb{R})$, the space of smooth compactly supported functions, then weak convergence also holds. The proof in the link is as follows: Fix $\epsilon > 0$ and choose a smooth compactly supported function $g$ with $0 \leq g \leq 1$ and $\int gdP \geq 1−ϵ$. Let $K$ be the support of $g$. Then by assumption, $$\int gdP_n\rightarrow\int gdP \geq 1 - \epsilon$$ 
  so we see that, $P_n(K)\geq 1−\epsilon$. In other words, $\{P_n\}$ is tight. Hence after passing to a subsequence, $\{P_{n_k}\}$ converges weakly to some measure $P^*$. Now we notice that $\int fdP =\int fdP^*$ for all $f\in C_c^\infty(\mathbb{R})$, and it follows from a monotone class type argument that $P = P^*$. Finally use the ""double subsequence"" trick to conclude that the original sequence $\{P_n\}$ also converges weakly to $P$. I think I am able to follow the above until the last sentence. How we can conclude weak convergence of the original sequence? All we've shown is that for all $f \in C_b(\mathbb{R})$, $$ \int f dP_{n_k} \xrightarrow{k\rightarrow\infty} \int f dP $$ for this particular subsequence $\{P_{n_k}\}$. I'm not sure what the ""double subsequence"" trick is. Is it some sort of diagonal argument? How can we use it to conclude that, $$  \int\limits_{\mathbb{R}}fdP_n \xrightarrow{n\rightarrow\infty} \int\limits_{\mathbb{R}}fdP $$ for all $f \in C_b(\mathbb{R})$?","['functional-analysis', 'probability-theory', 'weak-convergence']"
2636094,"Are there infinite many positive integers $n$ such that $n^2+n+41$ is composite, but not divisible by $41$?","Let $S=n^2+n+41$. If you try with $n=1, 2, 3, \dots, 39$, $S$ is always prime. But if $n=40, 41$, $S$ is composite. Hence, there are infinite many positive integers $n$, such that $S$ is composite. My question is: Are there infinite many positive integer $n$, such that $S$ is composite, but not divisible by 41?","['number-theory', 'prime-numbers']"
2636103,Conditional Moment Generating Function and Iterated Rule,"Let $N$ by the number of claims made by a person.  Assume that the Number of claims varies with the type of person.  Measure the type of person by a  second random variable $\Lambda$, which is nonnegative and follows some distribution $F$.  Further, assume $N$ conditioned on $\Lambda =\lambda$ follows a Poisson with mean $\lambda$. Find the distribution of $N$ using the MGF technique; that is, express it as a function of the MGF of $\Lambda$.
Find the exact expression of the MGF of $N$ if $\Lambda$~$GAMMA(\alpha, \beta)$, and conclude the distribution of $N$ using the uniqueness theorem. So here's where I've made it so far: $$M_N(t)=E(e^{tN})=E(E(e^{tN}|\Lambda))=E(e^{\Lambda(e^t-1)})=M_\Lambda(e^t-1)$$
So if if $\Lambda$~$GAMMA(\alpha, \beta)$, we have that $$M_N(t)=\frac{1}{(1-\beta e^t+\beta)^\alpha}$$
But I do not recognize this MGF, which suggests that I didn't do something correctly somewhere.  Do you recognize this MGF?  If not, what is my mistake?","['probability-theory', 'probability-distributions', 'probability', 'moment-generating-functions', 'random-variables']"
2636110,De Rham cohomology groups of projective real space,"I would like to calculate the de De Rham cohomology groups of projective real space $\mathbb{RP}^{n}$. Well, i know all groups of De Rham cohomology os $n$-sphere $\mathbb{S}^{n}$ and that the map $\pi:\mathbb{S}^{n}\to \mathbb{RP}^{n}$ (the restriction to the projection map on $\mathbb{S}^{n}$) is a smooth submersion. With these tools, can I compute the cohomology groups of real projective space? How can I do this?","['de-rham-cohomology', 'smooth-manifolds', 'projective-space', 'algebraic-topology', 'differential-geometry']"
2636130,Why are bilinear maps represented as members of the tensor space $V^*\otimes V^*$ opposed to just members of the tensor space $V\otimes V$?,"Is this convention? If we let $B$ be the space of bilinear maps, it seems to me that there is an isomorphism $i_1 : B \to V^* \otimes V^*$ and an isomorphism $i_2 : B \to V \otimes V$. So is it just convention to think about bilinear maps as the tensor product of the dual space, or are there reasons using $i_2$ doesn't make sense? The spirit of this question is a possible duplicate of this question https://physics.stackexchange.com/questions/105347/is-it-foolish-to-distinguish-between-covariant-and-contravariant-vectors . But the answers there seem to be somewhat intertwined with concepts relating to general relativity. Is this a concept that only makes sense to understand in the context of differential geometry? If not, I am looking for answers that are more abstract.","['tensor-products', 'tensors', 'differential-geometry', 'multilinear-algebra']"
2636131,Hint for problem on $4 \times 7$-chessboard problem related to pigeonhole principle,"Suppose that each square of a $4 \times 7$ chessboard is colored either black or white. Prove that with any such coloring, the board must contain a rectangle (formed by the horizontal and vertical lines of the board) whose four distinct unit corner squares are all of the same color? Any hints on this problem, I guess it could be solved with a clever application of the pigeonhole principle, but I have some difficulty seeing what the objects and what the bags are in which to put the objects to apply the pigeonhole principle, and then argue that such an coloring must exist. It is taken from a textbook on discrete mathematics, and in the text a version of the Monotone Subsequence Theorem by Erdös/Szekeres is proven (using the pigeonhole principle). Hence, I guess it is somehow related to this.","['puzzle', 'combinatorics', 'pigeonhole-principle', 'discrete-mathematics']"
2636134,What is $\lim_{x\to 2} \frac{\sqrt{x+2}-2}{x-2}$?,"I tried multiplying by the conjugate which gave: $$\frac{x-2}{(x-2)\sqrt{x+2}+2x-4}$$ But i'm still gettting $\frac{0}{0}$. According to my textbook the answer should be $\frac{1}{4}$, but how do I get there?",['limits']
2636146,"Finding the mistake in $f(t) = (\cos (t), \sin (t)), f'(t) = if(t)$","I need to undertsand what is my mistake here. $ f(t) = (\cos(t),\sin (t))$ $ f'(t) = (-\sin(t),\cos (t))$ The tangent of a circle is orthogonal to the radius.
Since orthogonality in $\mathbb{C}$ is multiplication by $i$, then: $f'(t) = if(t)$ $ (-\sin(t),\cos (t)) = (i\cos(t),i\sin (t))$ But then $\displaystyle i=-\frac{\sin(t)}{\cos(t)} = \frac{\cos(t)}{\sin(t)} \Rightarrow 1=0$, which is absurd.","['complex-analysis', 'complex-numbers', 'functions']"
2636163,Which one is correct $\sum_{n=1}^{k} 2^{n}× n^2$ or $\sum_{n=1}^{k} (2^{n}× n^2)$?,"I have $2$ questions about notation. Question 1. Suppose, numbers are as follows. $\left\{3\right\}\longrightarrow7$ $\left\{3,6\right\}\longrightarrow9$ $\left\{3,6,7\right\}\longrightarrow11$ $\left\{3,6,7,5\right\}\longrightarrow15$ $...............$ $\left\{p_1,p_2,p_3,...p_n\right\}\longrightarrow q_n$ And $p_1,p_2,...,p_{n}$ are arbitrary natural numbers.But, the value $q_n$ depend on the values of ${p_1,p_2,...,p_n}.$ I want to write a notation. I think, I can write, for example, $$f(p_1,p_2,...p_n)=q_n$$ like a function.Is it correct or ıs there an other notation? Question 2. Which notation is correct? $\sum_{n=1}^{k} 2^{n}× n^2$ or $\sum_{n=1}^{k} (2^{n}× n^2)$ and $\sum_{n=1}^{k} 2^{n}+n^2$ or $\sum_{n=1}^{k} (2^{n}+n^2)$","['algebra-precalculus', 'summation', 'notation', 'functions']"
2636224,"if $df_x$ is an isomorphism, why is $f$ locally equivalent to the identity?","Early on in Guillemin and Pollack, after introducing the Inverse Function Theorem, the authors state: ""If $df_x$ is an isomorphism, then one can choose local coordinates around $x$ and $y$ so that $f$ appears to be the identity, $f(x_1,...,x_k)=(x_1,...,x_k)$."" They state this without any reasoning, so perhaps it should be obvious and I'm missing something critical. I suppose it makes sense why it would be true. If $df_x$ is an isomorphism of the tangent spaces $T_xX$ and $T_yY$, then by the Inverse Function Theorem, $f$ is a local diffeomorphism, and so the two spaces should look identical locally. But I would like to know why precisely this is the case. Why can we ""choose local coordinates"" so that this works? How do we choose these coordinates? I know that we'd have to start with parametrizations, say $\phi:U\rightarrow X$ and $\psi:U\rightarrow Y$, where $U\subset \mathbb{R}^k$, but I'm not sure where to go from there. I'm a little confused about what exactly ""local coordinates"" even are.","['general-topology', 'differential-topology']"
2636239,Do isomorphic graphs have same values for adjacency matrices and spectrum?,"There are two isomorphic graphs for which I want to find their spectrum(their eigenvalues). I am confused that the spectrum will be same for both the graphs since they are isomorphic, but I am not sure. I first wrote the adjacency matrix for both and they are also same, unless I did something wrong. The graphs have color coded nodes so when I did the adjacency matrices for both, I wrote the nodes in the color-coded manner (like mapping the nodes from first graph to another graph for row and column of adjacency matrix, and hence, the values had to be the same). But I also did the adjacency matrix for second graph according to the number-labels given to nodes, and then the answer had to be different because now the alignment is different. I mean if they are isomorphic then their adjacency matrices will be same or not? If yes, which sounds obvious because of their property of isomorphism, then why is the question asking for solving adjacency and spectrum for both graphs? (I watched youtube videos and read pages online but I still have doubts if I am solving this correctly.) These concepts are new to me, so maybe I am missing on something important here.  Please if someone can simplify this or point where I am doing wrong in this problem, that would be much appreciated. For reference, here is an image of graphs-> isomorphic graphs Adjacency matrices for the graphs. solution","['graph-theory', 'adjacency-matrix', 'spectral-graph-theory', 'discrete-mathematics']"
2636241,Is there another proof about irrationality of $\sqrt{2}$ without using a contradiction?,A well known proof to show the irrationality of $\sqrt{2}$ is by contradiction. Is there another method to show the irrationality of $\sqrt{2}$  better than by contradiction?,"['number-theory', 'alternative-proof', 'irrational-numbers']"
2636432,"How does Mean Value Theorem guarantee there can't be exactly 3 fixed points, all stable?","I need to find an equation $\dot x = f(x)$ (where $\dot x$ denotes $\frac{dx}{dt}$) where there are precisely three fixed points, and all of them are stable, or explain why such a situation is not possible. I have seen a solution to this problem where it says that the situation is not possible because ""the mean value theorem guarantees that between any two fixed points of the same type (stable, unstable), there must be a fixed point of the other type"". What I don't understand is why that should be true, or how you could go about proving that. My attempt thus far is: suppose $x=a$, $x=b$ are fixed points (I.e., $f(a)=f(b)=0$), then by the mean value theorem, there exists a point $x=c$ such that $c\in (a,b)$ and $f^{\prime}(c)=\frac{f(b)-f(a)}{b-a}=\frac{0}{b-a}=0$, but all this tells us is that the function goes from increasing to decreasing (or vice versa) on this interval. How does it tell us that if, say, $a$ and $b$ are both stable, that there cannot be another fixed point between them that is also stable? Thank you.","['dynamical-systems', 'calculus', 'fixed-point-theorems', 'stability-in-odes', 'ordinary-differential-equations']"
