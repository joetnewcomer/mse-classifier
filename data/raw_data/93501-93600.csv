question_id,title,body,tags
1276973,How to show $c_n=\frac11 + \frac12 + \cdots + \frac1n - \ln n$ is a sequence of positive numbers? [duplicate],"This question already has answers here : Showing that $\sum_{i=1}^n \frac{1}{i} \geq \log{n}$ (2 answers) Closed 9 years ago . For  $n \in \mathbb{N}$ let  $c_{n}$ be defined by $$c_{n}=\frac{1}{1}  + \frac{1}{2} + \cdots + \frac{1}{n} - \ln n$$     We have to prove that $c_{n}$ is a decreasing sequence of positive numbers. I've already shown the first part, that it is a decreasing sequence by considering the difference of 
 $$c_{n+1}-c_{n} = \ln \left(1- \frac{1}{n+1} \right) +\frac{1}{n+1} $$ and then using the expansion of $\ln (1-x)$ for $-1\leq x \leq 1$. But I'm having some trouble in showing the second part that all terms in the sequence are positive. I tried using first form of induction but but stuck in the inductive step, can somebody please suggest explain that to me? or better suggest some other way to prove that part? Any sort of welcome as log as it leads to the solution, thanks in advance.","['harmonic-numbers', 'summation', 'real-analysis', 'sequences-and-series', 'inequality']"
1276990,How many ways 5 different books be distributed among 5 students,"I've seen this question in a book and can't figure it out correctly. Let 5 different books be distributed among 5 students. Suppose the
  books are returned and distributed to the students again later on. In
  how many ways the books be distributed so that no student will get the
  same book twice? Answer for that question is : 5280 My answer :
At first,the 5 books can be distributed to 5 students in 5! ways.Then after returning,the books can be distributed in $4^5$ ways so that no student will get the same book twice.So the answer will be 5!x$4^5$ ways. Can anyone please explain?","['combinatorics', 'permutations']"
1277011,"Asymptotic behavior of $\int_0^1 \text{min}\{1,x^{-d}(1-x^d)^n\} dx$ as $n\to\infty$","I am trying to find bounds on \begin{equation*}
\int_0^1 \text{min}\{1,x^{-d}(1-x^d)^n\} dx~\text{as}~n\to\infty,~d\in\mathbb{N}. 
\end{equation*} I found this integral trying to bound some probability, therefore, I have no hope for a closed form and I am only interested in the behavior as $n\to\infty$, for fixed $d\in\mathbb{N}$. Unfortunately, I can't even get rid of the minimum myself.","['calculus', 'real-analysis']"
1277012,Is the empty set Lebesgue measurable?,"I have a quite dumb question. Is the empty set measurable? say with respect to the standard measure. I totally acknowledge intuitive explanations. Thanks,","['lebesgue-measure', 'measure-theory']"
1277032,Modulus differentiation,"For a Java project, I need to find a way to compute the derivate of a modulus function like
$$f(x) = g(x) \pmod{h(x)}$$
for any value of $x$. I know that the modulus function is discontinuous. If there is no way to compute that, do you have any suggestion to obtain a coherent result?","['modular-arithmetic', 'derivatives']"
1277037,Limit of an expression,"$$\lim\limits_{n\to\infty}\frac{1}{e^n\sqrt{n}}\sum\limits_{k=0}^{\infty}\frac{n^k}{k!}|n-k|=\sqrt{2/\pi}$$
Is this limit true? I should show limit is true. It is allowed to use computer programs to find this limit.
Thanks for your helps...","['summation', 'sequences-and-series', 'calculus', 'limits']"
1277038,Why is $1/i$ equal to $-i$?,"When I entered the value $$\frac{1}{i}$$ in my calculator, I received the answer as $-i$ whereas I was expecting the answer as $i^{-1}$. Even google calculator shows the same answer (Click here to check it out). Is there a fault in my calculator or $\frac{1}{i}$ really equals $-i$? If it does then how?","['complex-numbers', 'algebra-precalculus']"
1277055,Factorising polynomials over $\mathbb{Z}_2$,Is there some fast way to determine whether a polynomial divides another in $\mathbb{Z}_2$? Is there some fast way to factor polynomials in $\mathbb{Z}_2$ into irreducible polynomials? Is there a fast way to find $n$ such that a given polynomial in $\mathbb{Z}_2$ divides $x^n-1$? Could there be a strategy/checklist to check this as fast as possible? Please help me.,"['polynomials', 'factoring', 'algebra-precalculus']"
1277062,Eigenvalues of Group Elements and Quaternions,"The quaternion algebra is given by $\mathbb{H}$ = $\{a+bi+cj+dk \mid a, b, c, d \in \mathbb{R}, i^2 = j^2 = k^2 = -1, ij = k = -ji\} := \{z_1+z_2j \mid z_1, z_2 \in \mathbb{C}\}.$ I consider the 3-sphere as the set of unit quaternions (the quaternions of length 1) as follows:
$\mathbb{S}^3 = \{a + bi + cj + dk \mid a^2 + b^2 + c^2 + d^2 = 1\} = \{z_1 + z_2j \mid |z_1|^2 + |z_2|^2 = 1\}$ The product in $\mathbb{H}$ induces a group structure on $\mathbb{S}^3$. For each pair $(p, q)$ of elements of $\mathbb{S}^3$, the function 
$\Phi_{p,q} : \mathbb{H} \rightarrow \mathbb{H}$ 
with $\Phi_{p,q}(h) = phq^{-1}$ leaves invariant the length of quaternions. We can, therefore, define a homomorphism of groups:
$\Phi : \mathbb{S}^3 \times \mathbb{S}^3 \rightarrow \mathrm{SO}(4)$ such that $\Phi(p, q) = \Phi_{p,q}$. I am looking at subgroup $C_4 \times D^*_{24}$ of  $\mathbb{S}^3 \times \mathbb{S}^3$, where $C_4$ is the cyclic group of order 4 and $D^*_{12}$ is the binary dihedral group of order 12. I have looked at 3 different ways of representing this group and in each case I get resulting matrices in $\mathrm{SO}(4)$ with different eigenvalues. Here are the 3 ways: $C_4 = \{\langle g \rangle$, where $g^4 = 1\}$, $D^*_{12} = \{\langle A, B \rangle$, where $A^{6} = 1, B^4 = 1$ and $BAB^{-1} = A^{-1}\}$. I represent $g$ as the matrix \begin{pmatrix}
 i & 0 \\
 0 & -i 
\end{pmatrix} I represent $A$ as the matrix 
\begin{pmatrix} 
 e^{i\pi/3} & 0 \\                   
 0 & e^{-i\pi/3} \end{pmatrix}. I represent $B$ as the matrix \begin{pmatrix} 
 0 & i \\                 
 i & 0 \end{pmatrix}. With this, $BA$ is the matrix 
\begin{pmatrix} 
0 & e^{i\pi/6} \\                    
-e^{-i\pi/6} & 0 \end{pmatrix}. Then $\Phi(g, BA)(h)$ is the $4 \times 4$ matrix \begin{pmatrix} 
0 & 0 & \sin \frac{\pi}{6} & \cos \frac{\pi}{6} \\\\                    
0 & 0 & -\cos \frac{\pi}{6} & \sin \frac{\pi}{6} \\\\
\sin \frac{\pi}{6} & \cos \frac{\pi}{6} & 0 & 0 \\\\                    
-\cos \frac{\pi}{6} & \sin \frac{\pi}{6} & 0 & 0 \end{pmatrix}. This has eigenvalues $\pm e^{\pm i\pi/3}$ I  can also view $D^*_{12} = C_{6} \cup C_{6}j$ With $g$ and $A$ as before, I represent $j$ as the matrix 
\begin{pmatrix} 
 0 & 1 \\                    
-1 & 0 \end{pmatrix}. With this, $Aj$ is the matrix \begin{pmatrix} 
\ 0 & e^{i\pi/3} \\                   
-e^{-i\pi/3} & 0 \end{pmatrix}. Now, $\Phi(g, Aj)(h)$ is the $4 \times 4$ matrix \begin{pmatrix} 
0 & 0 & \sin \frac{\pi}{3} & \cos \frac{\pi}{3} \\\\                    
0 & 0 & -\cos \frac{\pi}{3} & \sin \frac{\pi}{3} \\\\
\sin \frac{\pi}{3} & \cos \frac{\pi}{3} & 0 & 0 \\\\                    
-\cos \frac{\pi}{3} & \sin \frac{\pi}{3} & 0 & 0 \end{pmatrix}. This has eigenvalues $\pm e^{\pm i\pi/6}$ I represent $g = i$, $A = e^{i\pi/3}$ and $j = j$. With this 
$\Phi(i, Aj)(h)$ = $i (a + bi + cj + dk) (-jcos(\pi/3) - ksin(\pi/3))$
= $c\sin(\pi/3)-d\cos(\pi/3) + i(c\cos(\pi/3) + d\sin(\pi/3)) + j(a\sin(\pi/3)+ b\cos(\pi/3)) + k(-a\cos(\pi/3) + b\sin(\pi/3))$ which gives the $4 \times 4$ matrix for $\Phi(i, Aj)$ to be \begin{pmatrix} 
0 & 0 & \sin \frac{\pi}{3} & -\cos \frac{\pi}{3} \\\\                    
0 & 0 & \cos \frac{\pi}{3} & \sin \frac{\pi}{3} \\\\
\sin \frac{\pi}{3} & \cos \frac{\pi}{3} & 0 & 0 \\\\                    
-\cos \frac{\pi}{3} & \sin \frac{\pi}{3} & 0 & 0 \end{pmatrix}. This has eigenvalues $\pm 1, \pm 1$ So I have 3 different ways to do this and in each case, I get a different matrix in $\mathrm{SO}(4)$ with different eigenvalues. I thought that if the three matrices represent the same element in $\mathrm{SO}(4)$, their eigenvalues should have been the same. What mistake am I making here?","['eigenvalues-eigenvectors', 'quaternions', 'group-theory', 'linear-algebra']"
1277067,What automorphisms exist on the abelian group of positive rationals under multiplication?,"Consider the abelian group $(\mathbb{Q}_{>0}, \times)$.
What automorphisms exist for this group?
I can only think of the trivial one and of $\phi(q) = \frac{1}{q}$. If we relax the problem to injective homomophisms from $(\mathbb{Q}_{>0}, \times)$ to itself, do we get additional results?","['rational-numbers', 'group-isomorphism', 'abelian-groups', 'group-homomorphism', 'group-theory']"
1277073,How to show the following vector bundles are equivalent?,"Given a smooth sub-manifold $X$ of $\mathbb{R^n}$ and define the diagonal in $X \times X$ to be $$\triangle = \{(x,x) \mid x \in X \} \subset \mathbb{R^n}\times \mathbb{R^n}$$ and normal bundle to $\triangle$ is defined to be $$N(\triangle)=\{(y,w) \mid y\in \triangle, w\in T_y(X\times X) \text{ such that } w \cdot v =0 \text{ for all } v \in T_y(\triangle)\}$$ with projection $\pi : N(\triangle) \to \triangle$ given by $(y,w)\mapsto y$ Then we want to show that $N(\triangle)$ is equivalent to the tangent bundle $TX$. I know (by definition of equivalent) that two vector bundles said to be equivalent if there are diffeomorphisms $$f:TX \to N(\triangle) \text{ and }\tilde{f}:X \to \triangle$$ such that $f$ takes each fibre $TX_x$ to $N(\triangle)_{\tilde{f}(x)}$ by a vector space isomorphism. What do I really need to do? Should I try to write down $f$ and $\tilde{f}$ and show that $f$ is an isomorphism on fibres? Any help would be thankful.",['differential-geometry']
1277087,Does the proof of Bolzano-Weierstrass theorem require axiom of choice?,"When selecting the terms of subsequence from each bisections, I thought axiom of choice might be required. But I'm not so sure whether or not, so please tell me. [edited] I'm sorry for the lack of explanation.
I want to prove this statement: Let $a_1, a_2, \ldots \in \mathbf{R}$, and $(a_n)_{n\in\mathbf{N}}$ is bounded, then $(a_n)$ has some convergent subsequence. The proof is as follows. Since $(a_n)$ is bounded, for all $n\in\mathbf{N}$, 
 $a_n \in I = [b, c]$. Now, let $I_0 = I$ and if $I_n = [b_n, c_n]$, 
we define $d_n = (b_n+c_n)/2$ and 
if infinite terms of $(a_n)$ is included in $[b_n, d_n]$(resp. $[d_n, c_n]$), we will define
 $I_{n+1} = [b_n, d_n]$(resp. $[d_n, c_n]$).If both intervals contain infinite terms, let $I_{n+1}$ be $[d_n, c_n]$. For all $n\in \mathbf{N}$, infinite numbers of $m \in \mathbf{N}$ exist such that $a_m \in I_n$ suffices. We take the sequence of natural numbers $(n(k))_{k\in\mathbf{N}}$which suffices $n(0) < n(1) < \cdots < n(k) < \cdots$ following this procedure: Now we have already selected $a_{n(1)}, \ldots, a_{n(k)}$, there are infinite numbers of $m\in \mathbf{N}$ which suffices $n(k)<m, a_m \in I_{k+1}$, so let's take the minimum m out of it. Applying this process recursively, we obtain a infinite convergent subsequence(?). I think intuitively, by only repeating this process we can't obtain countable infinite terms of subsequence because we have to repeat infinite times.","['analysis', 'real-analysis', 'axiom-of-choice']"
1277115,"I don't get the relationship between differentials, differential forms, and exterior derivatives.","I don't get the relationship between differentials, differential forms, and exterior derivatives. (Too many $d$'s getting me down!) Here are the relevant (partial) definitions from Wikipedia; essentially the same definitions/terminology/notations are to be found in my notes. Pushforward . Let $\varphi : M → N$ be a smooth map of smooth manifolds. Given some $x \in M$, the differential of $\varphi$ at $x$ is a linear map $d\varphi_x : T_x M \rightarrow T_{f(x)}N$... Differential form . Let $M$ be a smooth manifold. A differential form of degree $k$ is a smooth section of the $k$th exterior power of the cotangent bundle of $M$. At any point $p \in M$, a $k$-form $\beta$ defines an alternating multilinear map $\beta_p : T_p M \times \cdots \times T_p M \rightarrow \mathbb{R}$... Exterior derivative . The exterior derivative is defined to be the unique $\mathbb{R}$-linear mapping $f \mapsto df$ from $k$- forms to $(k + 1)$- forms satisfying the following properties... What I understand: You apply $d$ to differential $k$-forms to get differential $(k+1)$-forms. Implicitly, this means ""exterior derivative."" What I don't understand: If $\varphi : M \rightarrow N$ is a smooth map of smooth manifolds, in what sense, if at all, is the differential of $\varphi$ a differential form? Is there any reason not to just call this the pushforward and consistently denote it $\varphi_*$? If $f : M \rightarrow \mathbb{R}$ is a smooth map, does $df$ mean the differential of $f$, or does it mean the exterior derivative? Are these somehow miraculously the same? If so, why? It seems possible that they're the same, by identifying $T_x\mathbb{R}$ with $\mathbb{R}$. I don't understand the details. What, if anything, is the connection between the differential of a smooth mapping and the exterior derivative of a differential form?",['differential-geometry']
1277118,Extremal problem with infinite cardinals,"Made up, but somewhat interesting: Let $\lambda\leq\kappa$ be infinite cardinals. Let $X$ be a set of cardinality $\kappa$. Let $F\subseteq [X]^\kappa$ be a family of $2^\kappa$ subsets, which is closed under taking intersections of $\lambda$-many members. Let $E\subseteq F$ have the property that for each $f\in F$ there is $e\in E$ with $e\subseteq f$. How small can $E$ be in general?","['combinatorics', 'infinitary-combinatorics']"
1277132,"Three planes in general position, one point in each, construct sections","I have three planes in general position, and in each plane an
arbitrary point is selected : this gives us three points $R,S,T$.
Is it possible to construct the intersection lines of the $(RST)$
plane with each of the original planes using only a straightedge 
(so, we can only draw parallels and locate intersection points of two
secant lines)? One could formalize the problem as follows : we have a set $\cal S$ of lines and points, defined as the smallest set containing $R,S,T$ and the three intersection lines of the original planes, and closed with respect to line intersection (if two secant lines $D,D' \in {\cal S}$, then the intersection point $D\cap D'$ is in $\cal S$) and parallel straight lines (if $D\in S$ and $p\in S$ then the parallel to $D$ passing by $p$ is in $\cal S$). The question can then be restated as, does $\cal S$ contain the intersection lines of $(RST)$ with the original planes.","['geometric-construction', 'geometry']"
1277151,How to do it by Dominated Conversgence Theorem?,"I'm trying to find the limit
$$ I = \lim_{n\to\infty} \int_{\mathbb R^d} \frac1{n} |f(x)|^2 x\cdot\nabla\chi (x/n)dx, $$
where $f \in H^1 (\mathbb R^d, \mathbb C)$, $f \in H^2_{loc}(\mathbb R^d, \mathbb C)$ and $f \in L^\infty (\mathbb R^d, \mathbb C)$, the test function $\chi \in \mathrm C_c^\infty (\mathbb R^d, \mathbb R) $ such that $0\le \chi\le 1$ on $\mathbb R^d$, $\chi = 1$ on $B(0,1)$ and $\chi=0$ outside $B(0,2)$. I hope to prove that $I=0$ by Dominated Convergence Theorem, but I don't know how to determine a dominator. Could someone give me a hint? Edit: Thank to Nate Eldredge's comment, it seems not true without the assumptions $f \in L^\infty (\mathbb R^d, \mathbb C)$ and $f \in H^1 (\mathbb R^d, \mathbb C)$.","['functional-analysis', 'integration']"
1277164,Proving that $A\subset B$ if given $A=A\cap B$,"Let $A = A \cap B$. Prove $A \subseteq B$ I go about like this : Let $x \in (A \cup B)$ $\implies x\in A ~~\text{and} ~~ x\in B$ Question 1 : Is this true? Will and come here? Ideally or should come, as it is a union. Question 2 : How should we prove this ideally? Is there any better beginning? Our teacher said to use Venn diagrams, but I want to prove it in writing.",['elementary-set-theory']
1277186,"Showing this function is continuous $ f:(x,y)\mapsto x^2+y^2$","I have the following function: $$f:\Bbb R^2 \to \Bbb R,\quad f:(x,y)\mapsto x^2+y^2$$
I want to show that this function is continuous by showing that $f^{-1}((a,b))$ is an open set. How do I approach this? I have proved that the function is a metric already. But I can't think of how elements are mapped for some reason - an thus I can't see where a segment $(a,b)\subset \Bbb R$ would go to in the preimage.","['functional-analysis', 'continuity', 'general-topology', 'functions']"
1277197,Need a counter example for cycle in a graph,"Could anyone give a counter example for that theorem : A graph G has exactly one vertex of degree $1$, then it contains a cycle. I am so confused. I wonder that may I give a counter example which considers trees.","['graph-theory', 'discrete-mathematics', 'trees']"
1277214,"What is the maximum value of the sum $\sum_{i=1}^L(\bar{x}-x_i)$, in this specific case.","Let $x_i$ be a positive real variable, with $i=1,2,...,K$.
We denote by $\bar{x}$ the average value of the values $x_1, x_2,...,x_K$. Let $a=\min_i x_i$ and $b=\max_i x_i$, then $x_i \in [a,b]$. My question: what is the maximum value of the sum \begin{equation*}
\sum_{i=1}^L (\bar{x}-x_i), 
\end{equation*} for $L\le K$.","['average', 'summation', 'statistics', 'standard-deviation', 'optimization']"
1277224,Where to find interesting integrals for a Calc III student?,"I apologize in advance if this is a very soft question. I won't be surprised or offended if I can't get a good answer. One of my favorite things to do in my spare time, when I'm feeling analytical of course, is to evaluate integrals, both definite and indefinite. However, I've had little success here on Math.SE trying to find integrals that meet my criteria. Either the integral in question will be way beyond the methods that I understand to evaluate it (typically using contour integration), or is so mind-numbingly trivial that I can't be bothered writing it down. I've scoured the internet for some interesting integrals, and I found the MIT Integration Bee, but those aren't really that hard either. There are some decent ones in my multivariable calculus textbook, but I'm starting to run out of those too. Is there any specific place I should be looking for interesting, tough but doable without complex analysis? Specifically ones where we can evaluate through tricks like clever substitutions or exploitation of symmetry or changing coordinates, etc.","['calculus', 'soft-question', 'integration']"
1277242,Proving function is $C^k$,"This question is from an exercise in Way of Analysis (section 10.2.4 problem 20). If $f: \mathbb{R} \rightarrow \mathbb{R}$ is $C^k$ and $f$ is even, then show $F: \mathbb{R}^n \rightarrow \mathbb{R}$ given by $F(x) = f(|x|)$ is also $C^k$. $C^k$ just means the function has $k$ continuous derivatives, and $|x|$ is referring to the regular Euclidean norm. I am not sure how to use the fact $f$ is even in the proof and having trouble for a general $k$. Any hints, even on a particular case like $k=2$, are welcome. My workings: As a comment suggests $f(x) = F(x)$ for $n = 1$. For $n = 2$, $F(x) = f(\sqrt {x_1^2 + x_2^2}).$ I'm stuck on where to proceed from here. Is there some form of induction here that I am not seeing?",['real-analysis']
1277246,Coefficients of (generating) function,"If I have the generating function 
\begin{equation*}
A(x)= \frac{1}{(1-x^{10})\cdot(1-x^5)\cdot(1-x) }\,, 
\end{equation*}
what is a clean way to find the coefficients of $x^{n}$. This coefficient would tell me, in how many ways I can combine an element of the first, the second and the third to get $x^n$.
I am pretty new to generating functions and I only now how to set them up from a series, but not how to get the series from a function :-( Thanks in advance.","['generating-functions', 'combinatorics']"
1277263,weak compositions of $n$ with $2m$ parts and extra conditions,"A weak composition of $n$ into $k$ parts is a sum 
$$\displaystyle \sum_{i=0}^k x_i=n$$ 
such that $x_i\in \mathbb{Z}$ and $x_i\geq 0$ for each $i$. I am trying to figure out the number of weak compositions of $n$ into $2m$ parts such that $x_i\in \left\{0,1 \right\}$ for each $i\in \left\{1, 2, \ldots, m \right\}$ and $x_i$ is even for each $i\in \left\{m+1, m+2, \ldots, 2m \right\}$. I have decided to break my argument into two cases: 1) n is even; 2) n is odd. 1) When $n$ is even, there must be an even number of $x_i$s for $i\in \left\{1, \ldots, m \right\}$. 2) When $n$ is odd, there must be an odd number of $x_i$s for $i\in \left\{1, \ldots, m \right\}$. What I am considering is basing my argument on the number of terms $x_i$ for $i\in \left\{1, \ldots, m \right\}$ that are equal to $1$. I can subtract them from both sides and consider the number of weak compositions of $n-x$ ($x$ is the number of $x_i$s that are equal to 1). I just can't figure out how many such compositions there are. Help me! Thank you!!","['discrete-mathematics', 'number-theory', 'combinatorics']"
1277274,"Is $\mathbb{Q}[\sqrt{2},\sqrt{3}]$ the same as $\mathbb{Q}(\sqrt{2},\sqrt{3})$?","Is $\mathbb{Q}[\sqrt{2},\sqrt{3}]$ the same as $\mathbb{Q}(\sqrt{2},\sqrt{3})$? I mean, $\mathbb{Q}[\sqrt{2},\sqrt{3}]$ can be viewed as: $\mathbb{Q}[\sqrt{2}][\sqrt{3}]$, as polynomials of $\sqrt{3}$ having coefficients of $\mathbb{Q}[\sqrt{2}]$?, and $\mathbb{Q}(\sqrt{2},\sqrt{3})$ is the smallest field containing $\mathbb{Q}, \sqrt{2}\,\sqrt{3}$. Since $\mathbb{Q}[\sqrt{2},\sqrt{3}]$ is a field we must have that $\mathbb{Q}(\sqrt{2},\sqrt{3}) \subseteq \mathbb{Q}[\sqrt{2},\sqrt{3}]$?, but since all the terms in $\mathbb{Q}[\sqrt{2},\sqrt{3}]$ are made with sums and multiplications of $\mathbb{Q},\sqrt{2},\sqrt{3}$, we must have that $\mathbb{Q}[\sqrt{2},\sqrt{3}] \subseteq \mathbb{Q}(\sqrt{2},\sqrt{3})$? Can someone confirm that this is correct? But do we then also have that: $F[\alpha]=F(\alpha)$, always?
and $F[\alpha_1,\alpha_2]=F(\alpha_1,\alpha_2)$?","['extension-field', 'abstract-algebra', 'field-theory']"
1277294,"Matrices over $\mathbb{Q}[x,y,z]$ which are not equivalent","I have some problems solving the following task: Let $R = \mathbb{Q}[x,y,z]$ and:
  $$A = \begin{pmatrix} x & y \\ 0 & z
\end{pmatrix} \in M_{2,2}(R) \qquad B = \begin{pmatrix} x & 0 \\ y & z
\end{pmatrix} \in M_{2,2}(R).$$
  Show that $A$ is not equivalent to $B$, that is, there are no invertible matrices $C,D \in M_{2,2}(R)$ such that $B=CAD$. I've already tried substituting $C = \begin{pmatrix} a & b \\ c & d \end{pmatrix}$ and the same for $D$ and then drawing conclusions from the products of the matrices. But I wasn't able to find something helpful.","['abstract-algebra', 'linear-algebra', 'matrices']"
1277314,Trigonometric Functions Limit: $\lim_{x \to 0} \frac{1-\cos x}{x\sin x}$,"In my assignment I have to solve the following question. I know the answer, but I keep getting it wrong, and I don't know how to solve it. $$\lim_{x \to 0} \frac{1-\cos x}{x\sin x}$$ I have tried several things, but first I tried to multiply by $(1+\cos x)$, both numerator and denumerator, to get $$\lim_{x \to 0} \frac{1-\cos^2x}{(x\sin x)(1+\cos x)}$$  I keep getting that the limit is equal to $0$, by calculating (for example) $$\lim_{x \to 0} \frac{\frac{1}{\cos^2x}-\frac{\cos^2x}{\cos^2x}}{\frac{(x\sin x)}{\cos^2x}\frac{(1+\cos x)}{\cos^2x}},$$ which equals $$\frac{1-1}{1-1}$$ However, I know the answer is $\frac{1}{2}$. Any ideas? Thanks","['calculus', 'limits', 'trigonometry']"
1277325,How can I evaluate the following limit-integral combination?,"Can you give me some hint on how to show that
$$\lim_{y\to0^+}\frac{\int_0^\infty \exp(-y\cosh (x))\text dx}{\log y}=-1?$$ I tried to delimit from above and from below the function $x\mapsto−y\cosh(x)$ with some simple functions (simple means for which I can explicitly evaluate the integral by anti-differentiation) whose integrals from 0 to ∞ are asymptotic to $-\log y$ as $y$ approaches $0+$. But I failed in finding them.","['bessel-functions', 'limits', 'improper-integrals']"
1277332,a hyperbolic summation,Find the value of $$\lim_{n\to\infty} \sum_{k=1}^{n}\frac{1}{\sinh 2^k}$$ Numerical approximations gives me a value of $\frac{2}{e^2-1}$. I tried to write the sum as $$\sum_{k=1}^{\infty}\frac{1}{\sinh 2^k}=2\sum_{k=1}^{\infty}\sum_{n=0}^{\infty}2e^{-2^k(1+2n)}$$ I don't see how to calculate this expression.,"['sequences-and-series', 'calculus', 'hyperbolic-functions']"
1277392,No. of linearly independent bounded solutions,Let $V$ be the set of all bounded  solutions of the ODE $u''(t)-4u(t)=0$ $ where$ $t \epsilon \Bbb R$ . Then $V$ is a)real vector space of dimension 2 b)real vector space of dimension 1 c)contains only trivial solution $u=0$ Here I've got the solution as $y=$ ${ae^{-2x}}$ $+$ ${be^{2x}}$ .If we take $V$ as the set of all solutions of the given ODE then option a) will be true.But here $V$ is defined as the set of bounded solutions .So what is the no. of linearly independent bounded solutions?Also u=0 is a solution of the given ODE.,['ordinary-differential-equations']
1277412,$\int_0^1 \frac{dx}{(1+x)e^x} $,"How to integrate the folllowing: $$\int_0^1 \frac{1}{(1+x)e^x} \, dx $$ The major problem that I am facing is eliminating the exponential, I am unable to convert it into something else by substitution means.","['definite-integrals', 'integration']"
1277419,"Show that: $\int_{0}^{\infty} \frac{\sin{x^{q}}}{x^{q}} dx = \frac{\Gamma{\frac{1}{q}}}{q-1}\cos{\frac{\pi}{2q}} \mbox{, q > 1}$","How do you show that:
  $$
\int_{0}^{\infty} \frac{\sin{x^{q}}}{x^{q}} dx = \frac{\Gamma{\frac{1}{q}}}{q-1}\cos{\frac{\pi}{2q}} \mbox{, q > 1}
$$
  Without using Gamma function?","['analysis', 'gamma-function', 'calculus', 'integration']"
1277438,Limit of square root where x approaches infinity,"I have to calculate the following limit, and I wondered if my solution to the question was true. Here it is: $$\lim _{x \to -\infty} (\sqrt{(1+x+x^2)}-\sqrt{1-x+x^2})$$ Now I divide by $x^2$ and get: $$\lim _{x \to -\infty} (\sqrt{\frac{1}{x^2}+\frac{x}{x^2}+\frac{x^2}{x^2}}-\sqrt{\frac{1}{x^2}-\frac{x}{x^2}+\frac{x^2}{x^2}})$$ I know that $$\lim_{x \to -\infty}\frac{1}{x}=0$$ so I get the following: $$\lim _{x \to -\infty} (\sqrt{0+0+1}-\sqrt{0-0+1})$$
So we get the following: $$\lim _{x \to -\infty} (\sqrt{1}-\sqrt{1})=0$$ Is my solution correct? Thanks.","['calculus', 'limits']"
1277441,Discrete-time derivative of the sign function,"How does one calculate the time derivative of $$
x_{k+1} = C_1\, \text{sign}(x_k-y_k)\sqrt{2\vert x_k-y_k\vert},
$$ with respect to $x_k$ ? I know that the right part of the equation should yield
$$
\frac{\partial}{\partial\,x_k} \sqrt{2\vert x_k-y_k\vert} = \frac{x_k-y_k}{\vert x_k -y_k\vert^{\frac{3}{2}}}.
$$ Yet, I don't know to get the final result. How can one differentiate the sign function?","['discrete-optimization', 'partial-derivative', 'discrete-mathematics', 'derivatives']"
1277445,Separated scheme stable under base extension.,"Given a separated scheme morphism $X\to Y$, and a morphism $Z \to Y$, Hartshorne proves that the extension $X\times_YZ \to Z$ is also separated, as long as the schemes involved are Noetherian. The valuative criterion he uses to prove it depends on this assumption. Is it true for general $X, Y, Z$? $X\to Y$ separated means that the diagonal map $X\to X\times_YX$ is a closed immersion. I have to use this somehow to prove that
$$
\Delta:X\times_YZ \to (X\times_YZ)\times_Z(X\times_YZ)
$$
is a closed immersion. Can that product be simplified in any way? Is there an obvious way to see this that I'm missing?","['algebraic-geometry', 'schemes']"
1277450,Is the set of probability measures on a compact metric space (weak*-)closed?,"Let $(S,\mathcal B)$ be a compact metric space with the Borel-$\sigma$-Algebra. Let $\mathcal M$ be the space of signed Borel measures and $\mathcal P \subset \mathcal M$ the set of probability measures on $(S,\mathcal B)$. Now we say a sequence of measures $(\mu_n)_{n\in\mathbb N}$ with $\mu_n\in \mathcal M$ for each $n$ converges in the weak*-topology to a measure $\mu \in \mathcal M$ if (I) $\int fd\mu_n\overset{n\rightarrow\infty}{\rightarrow}\int f d\mu$ for each countinuous and bounded function $f$ from $S$ to $\mathbb R$ that vanishes at infinity (since $S$ is compact there aren't unbounded continuous $f$ anyways, and also ""vanishing at infinity"" has no meaning, hence this convergence coincides with the weak convergence of measures). I know that for non-locally-compact sets $S$ the $\mathcal P$ is not closed in this topology. But several times I stumbled over the restriction non-locally-compact which makes me wonder how to show closedness of $\mathcal P$ in the compact case, i.e. Question: Why can't there be a $\mu \in \mathcal M\setminus\mathcal P$ and a sequence of probability measures $(\mu_n)_{n\in\mathbb N}$ such that (I) holds? What I have tried: If $\mu\not\in\mathcal P$ then either $\mu(S)\neq1$ or there is a set $A\in\mathcal B$ such that $\mu(A)<0$. In the former case choose $f\equiv1$ and see that (I) cannot be true. In the latter case I think there has to be some open set $U$ such that $\mu(U)<0$ and then I can take a function $f$ that is strictly positive on $U$ and zero elsewhere, then (I) wouldn't hold either (left side would be zero or greater and right side negative). But I don't know if there really has to be such a set $U$. I already asked a different question regarding the existence of such a set ( Obtaining the measure of a set from a limit of measures of open sets ), but my approach there doesn't work.","['probability-theory', 'general-topology']"
1277464,Prove this Complicated Inequality,"Let $a$, $b$, $c$ be positive real numbers such that $a^2 + b^2 + c^2 + (a + b + c)^2 \le 4$. Prove that $$\frac{ab + 1}{(a + b)^2} + \frac{bc + 1}{(b + c)^2} + \frac{ca + 1}{(c + a)^2} \ge 3.$$ Let $x = a + b, y = b + c, t = a + c$ Then the INEQ becomes, $$\frac{ab + 1}{(x)^2} + \frac{bc + 1}{(y)^2} + \frac{ca + 1}{(t)^2} \ge 3.$$ Any further hints?","['contest-math', 'algebra-precalculus', 'inequality']"
1277490,"Determining matrix for relationship: reflexive, symmetric, transitive.","I have two matrices below and need to determine if R is (a) reflexive, (b) symmetric, and (c) transitive. $M_R = \begin{pmatrix} 1 & 0 & 1 & 0\\ 1 & 1 & 0 & 1 \\ 1 & 1 & 1 & 0\\ 1 & 1 & 1 & 1\end{pmatrix}$  ; $M_R = \begin{pmatrix} 1 & 1 & 1 & 1\\ 0 & 1 & 1 & 1 \\ 0 & 0 & 1 & 1\\ 0 & 0 & 0 & 1\end{pmatrix}$ So, far I was able to figure out that for both it is reflexive because there is 1 diagonally, and not symmetric because $M_{21} \neq M_{12}$ and also $M_R \neq (M_R)^T$. Can anyone please verify what I did is correct? And also how do I determine if it is transitive?",['discrete-mathematics']
1277501,Ambiguous integration,I had come across the following question: If we know $\int_0^9 f(u)du = 10$ and $\int_0^3 f(u)du = 14$ then what must the value of $\int_0^3 xf(x^2)dx$ be? I reason that this value would be $30$ because if $\int_0^3 f(u)du = \int_0^3 f(x)dx$ then $\int_0^3 f(x^2) dx$ then evaluating for $x$ would be the same as evaluating from $0$ to $9$. Therefore $\int_0^3 f(x^2)dx = \int_0^9 f(u)du = 10$. Then all we do is multiply the value of $f(x^2)$ by 3 when we are evaluating the entire integral. Thus we end up with the answer $30$. Would this reasoning be correct?,"['calculus', 'integration']"
1277512,Prove $R\times S$ is not an integral domain,"Let $R$ and $S$ be two commutative rings with unity. Prove that $R\times S$ is NOT an integral domain. This is the best I could think of so far, please give me a push in the right direction and correct me. It suffices to show that $R\times S$ has zero-divisors Therefore, let $a$ be an element of $R$ and $b$ be an element of $S$ , thus $R\times S$ has elements of the form $(a,b)$ . Consider the elements $A=(a,0)$ and $B=(0,b)$ , such that $a$ does not equal zero and $b$ does not equal zero. Then $AB = 0$ . Therefore $R\times S$ has zero divisors.","['abstract-algebra', 'integral-domain', 'proof-verification', 'ring-theory']"
1277530,System of equations involving sin and cos,"I'm trying to solve the following system: $$
\sin(x) + \cos(y) = 0.6\\
\cos(x) - \sin(y) = 0.2\\
$$ Solving for y in terms of x: $$
y=\arccos(0.6-\sin(x))=\arcsin(\cos(x) -0.2)
$$ Therefore:
$$
\frac{\pi}{2} - \arcsin(0.6-\sin(x)) = \arcsin(\cos(x) - 0.2)
$$
Forgot to add:
$$
\frac{-\pi}{2}\le x,y \le \frac{\pi}{2}
$$
Not too sure how to proceed from here, any hints?","['systems-of-equations', 'trigonometry']"
1277546,Decay of amplitude integral,"Consider the function $$
f(\vec{x}) = 
\int_{\Bbb R^3} {\frac{ e^{-i\,\vec{x}\cdot\vec{k}}}{\sqrt{\vec{k}^2 + m^2}}} d^3 k
$$ from Zee's Quantum Field Theory in a Nutshell . He argues like this: “the square root cut starting at $±im$ tells us that the characteristic value of $|\vec{k}|$ in the integral is of order $m$, leading to an exponential decay $\sim e^{−m|\vec{x}|}$”. I cannot understand what he means. It would be nice if someone can expand or suggest a reference for me. Thanks.","['fourier-analysis', 'quantum-field-theory', 'integration', 'asymptotics', 'complex-analysis']"
1277560,"Curious relation between parabola, circumcircle and circumellipse","When playing around with conics in GeoGebra, I have found out that the following relation seems to hold: Let parabola $p$ be tangent to sides/extensions of sides $BC,CA,AB$ of triangle $ABC$ at points $P,Q,R$. Call $F$ the focus of this parabola. Let $T$ be intersection point of lines $AP,BQ,CR$ (they are concurrent as a corollary to Brianchon theorem) and let $S$ be the intersection point of circumcircle and Steiner's circumellipse other than $A,B,C$ (a.k.a. Steiner point ). Then $F,T,S$ are collinear. My question is: can anyone provide a proof of this relation? I imagine this would be quite a complex result to show, but maybe it already exists somewhere in literature (in which case I'd be thankful for a reference). Thanks in advance. Illustration:","['geometry', 'conic-sections']"
1277561,"What is the strongest possible statement of the idea that ""the tangent line is the best linear approximation""?","For instance, I've just checked that that if you take the best linear approximation (in the $L^2$ sense) to a sufficiently nice function $f$ on the interval $[-\varepsilon, \varepsilon]$, and then let $\varepsilon \to 0$, you get $f(0) + x f'(0)$. Surely we could make this stronger -- I imagine the analogous statements should hold for, say, the $L^1$ norm as well, or for most reasonable norms.  Can we go farther, though? Question: What is the strongest precise definition we can give the word ""best"" so that we have a statement of the form ""the tangent line is the best linear approximation to a differentiable function""?  (Feel free to replace ""differentiable"" with, say, $C^2$ or something if it makes for a more interesting answer.) (Note: I'm aware of similar-sounding questions here, such as In what sense is the derivative the ""best"" linear approximation? , but the answers there don't answer my question.)","['calculus', 'real-analysis', 'functional-analysis']"
1277569,finding a bijective function from the real plane to the real line,"As part of a HW assignment in the course elementary set theory, I was given the following question: Prove explicitly (don't use any theorems or known facts, but find a bijective function) that $\vert\mathbb R\vert=\vert \mathbb R\times \mathbb R\vert$ I've already encountered with the following suggestion: for any $(x,y)\in \mathbb R$ with the decimal expansion $x=n_1+0.a_1 a_2 a_3 \ldots$ for some $n_1\in \mathbb Z$ and $0\leq a_i \leq 9$ and $y=n_2+0.b_1 b_2 b_3 \ldots$ for some $n_2\in \mathbb Z$ and $0\leq b_i \leq 9$. if $x$ or $y$ have two different decimal expansions then take the one that ends with an infinite string of 9's.
then define $f : \mathbb R\times \mathbb R\longrightarrow \mathbb R$ by: $f((x,y))=n_1 +n_2 +0.a_1 b_1 a_2 b_2 a_3 b_3 \ldots$ $f$ is injective (I know that it is not accurate because I can choose $n_1$ and $n_2$ as I wish as long as their sum remains the same but the following was the more important part)  but it is not onto $\mathbb R$ because for example: $0.12020202\ldots \in \mathbb R$ but there is no $(x,y)\in \mathbb R\times \mathbb R$ such that $f((x,y))=0.12020202\ldots$
because the only ""candidates"" are $x=0.10000\ldots$ and $y=0.2222\ldots$ but the number $0.10000\ldots $ does not belong to the representation that we agreed upon. I feel that it can be fixed somehow but I can't manage to do it.
I would really appreciate if anyone can give me a bijective function that fits. (also how can I fix $f$ to be injective).","['elementary-set-theory', 'cardinals']"
1277573,Convergence of the series $\sum_{1}^\infty \left(1-n\sin(\frac{1}{n})\right)$,I have to study the convergence of the series $$\sum_{n=1}^\infty \left(1-n\sin\left(\frac{1}{n}\right)\right).$$ I know I should study the limit $$\lim_{n \to \infty}n^\alpha\left( 1-n\sin\left(\frac{1}{n}\right)\right).$$ But I have some troubles with this limit (and so the convergence of the series). Any ideas?,"['sequences-and-series', 'calculus', 'limits']"
1277577,proof that $\frac{x^p - 1}{x-1} = 1 + x + \dots + x^{p-1}$ is irreducible,"I am reading the group theory text of Eugene Dickson . Theorem 33 shows this polynomial is irreducible $$ \frac{x^p - 1}{x-1} = 1 + x + \dots + x^{p-1} \in \mathbb{Z}[x]$$ He shows this polynomial is irreducible in $\mathbb{F}_q[x]$ whenever $p$ is a primitive root mod $q$. By Dirichlet's theorem there are infinitely many primes $q = a + ke$, so this polynomial is ""algebraiclly irreducible"", I guess in $\mathbb{Q}[x]$. Do you really need a strong result such as the infinitude of primes in arithmetic sequences in order to prove this result?  Alternative ways of demonstrating this is irreducible for $p$ prime? COMMENTS Dirichlet's theorem comes straight out of Dickson's book.  I am trying to understand why he did it.  Perhaps he did not know Eisenstein's criterion.  It's always good to have a few proofs on hand. Another thing is that Eisenstein's criterion is no free lunch since it relays on Gauss lemma and ultimately on extending unique factorization from $\mathbb{Z}$ to $\mathbb{Z}[x]$.","['irreducible-polynomials', 'abstract-algebra', 'polynomials', 'factoring', 'cyclotomic-polynomials']"
1277586,Is it possible to systematize the method behind Zagier's proof that $p = 4k+1$ is the sum of two squares?,"Zagier's proof (or perhaps the main idea should be attributed to Heath-Brown) works as follows: Consider the set $S := \{(x, y, z) \in \mathbb{N}^3 \; | \; x^2 + 4 y z = p \}$ . $S$ has an involution $\sigma(x, y, z) = (x, z, y)$ . A fixed point of $\sigma$ is a representation $p = x^2 + 4y^2$ , so it suffices to show that $\sigma$ has a fixed point. An involution on a set of odd cardinality has a fixed point. If a set admits an involution with an odd number of fixed points, it has odd cardinality. Finally, Zagier exhibits an involution $\tau$ of $S$ with exactly one fixed point. This method seems to have a great deal of potential, since, given an arbitrary diophantine equation, there are lots of ways we could see it as a specialization of another one.  Moreover, we can ignore trivial solutions easily by just changing the conditions on $S$ . Questions: Is there a systematic way of exploiting this idea to prove that a diophantine equation has a solution? Are there any obvious limits to the situations where such a technique could be applicable?",['number-theory']
1277594,Equivalence of Solutions to Wave Equation,"The differential equation $$\ddot x = -\omega^2 x$$ apparently has solutions of $$x = Ae^{i\omega t} + Be^{-i\omega t} \tag{1}$$
AND
$$x = A\sin(\omega t) + B\cos(\omega t) \tag{2}$$
AND
$$x = A\sin(\omega t + \phi) \tag{3}$$ How are all of these equivalent?  Isn't $(1)$ a complex number where $(2)$ and $(3)$ are real?  And how is the sum of a sine wave and a cosine wave just a sine wave?","['ordinary-differential-equations', 'trigonometry']"
1277601,Is this proof involving complete metric spaces correct?,"Show that if every closed ball of a metric space $(X, d)$ is complete then $ X$ is complete. I thought the following: given $(x_n)$ a Cauchy sequence in $X$, we have that the set $A= \{x_{1}, x_{2},..., x_{n},...\} $ is bounded, that is, $ diam(A) < M $ for some $ M \in \mathbb {R}$ Therefore for any $ n_{0}\in \mathbb {N}$, $ A \subset B [x_{n_{0}}, M]$ From the hypothesis we know that every closed ball is complete and therefore $ x_{n} \rightarrow x \in B [x_{n_{0}}, M] \subset X $ And so $ X $ is complete. For some reason I am not completely sure my proof is correct, could anyone tell me what you think?","['metric-spaces', 'cauchy-sequences', 'general-topology']"
1277604,What is the topology of the hyperreal line?,"Denote by $\Bbb R$ the real line and by $\Bbb R^*$ the hyperreal line. For any real numbers $x < y < z$ and infinitesimal $\epsilon$ the following holds:
\begin{equation}
\forall a,b,c \in \Bbb R:~~~x + a\cdot \epsilon<y+b\cdot \epsilon<z +c\cdot \epsilon
\end{equation}
This, together with the ordering of $\Bbb R$ being a subset of the ordering of $\Bbb R^*$, makes me think that there is an analogy between the hyperreal line and the open long line, understood as an ordered countable infinity of real lines. However, the hyperreal line contains at least an uncountable infinity of real lines, one for each real number. Then there are the infinite hyperreals. So the topology is not the same. What is the topology of the hyperreal line?","['nonstandard-analysis', 'infinitesimals', 'general-topology']"
1277609,Differential forms in Physics,"In the context of physics, I just read about the the symplectic 2-form $\omega$ on a symplectic manifold $M$ of dimension $2n$.  Unfortunately, I could not follow a few arguments. I.e. it was said that since $\omega$ is non-degenerate, the $n$-fold wedge-sum $\omega \wedge \cdots \wedge \omega$ is a volume form and if $M$ would be a closed manifold $M$, then $\int_M \omega \wedge \cdots \wedge \omega \neq 0.$ Could anybody explain to me where these two conclusion actually come from, i.e. I see that the wedge sum is a top-degree volume form, but I don't see why this means that it is nowhere vanishing and especially why the integral is non-zero.","['differential-forms', 'real-analysis', 'differential-topology', 'analysis', 'differential-geometry']"
1277615,Characterization of closed map by sequences/nets,"I'm interested in characterizing closed maps in terms of nets. Since a map is closed iff $\overline{f(V)} \subseteq f(\overline{V})$ for all subsets $V$, I believe one possible such characterization is $f$ is closed iff for each net $x_\alpha$ such that $f(x_\alpha) \to
 y$, we have that $x_\alpha$ converges to the set $f^{-1}({y})$. By convergence to a set I mean that for any neighborhood $V$ of $f^{-1}({y})$, $x_\alpha$ is eventually in $V$. In case anyone's interested, I came to this question trying to show that $X$ is compact $\iff$ the map $X \to \{*\}$ is universally closed. I know a proof, but I thought a proof in terms of nets could be more elucidatory.","['general-topology', 'nets']"
1277617,limit with two variable,"How to calculate: $$
\lim_{(x,y) \to (0,0)}        \frac{5x^6 + y^2}{x^3 + 2y}
$$ I think the result should be $0$, but how do I prove it? I tried by the definition, but I could not resolve that. I cannot use the different paths to prove that, because there are an infinity of paths and I would have to calculate them all, and that's impossible. 
I believe the only way is by definition.",['limits']
1277628,"Lower boundary for $ |f(z) - 1/z| $, where $ f(z) $ is holomorphic","I've been trying to prove the following statement: Let $ f:U \rightarrow \mathbb{C} $ be holomorphic with $ \overline{B(0, R)} \subset U$. Suppose $ r < R $. Prove that 
$$ \sup\limits_{r \leq |z| \leq R}\left(\left|f(z) - \frac{1}{z}\right| \right) \geq \frac{1}{R}$$ It's a way of proving that $ \frac{1}{z} $ is not a uniform limit of a sequence of polynomials on a ,,ring'' $ r \leq |z| \leq R $. I tried to use Cauchy's integral theorem to evaluate $ f(z) $, however it didn't lead me anywhere close to the solution. I would appreciate some help with this exercise",['complex-analysis']
1277663,Determining a measure through a class of measure preserving functions,"Let $\mu$ and $\mu^\prime$ be probability measures over the sigma algebra $\Sigma$ consisting of the Lebesgue measurable subsets of $[0,1]$. Suppose also that $\mu$ and $\mu^\prime$ assign measure $0$ to all and only null sets. (Notation: if $X$ is measurable, let $\mu_X$ denote the renormalized measure over measurable subsets of $X$: $\mu_X(Y)=\mu(Y)/\mu(X)$ (and similarly for $\mu^\prime$).) Now suppose that we have a collection of functions: $$\{f_X:X\rightarrow \overline{X} \mid X\in \Sigma, 0<\lambda(X)<1\}$$ such that for every way of partitioning $[0,1]$ into two sets, $X$ and $\overline{X}$, $f_X$ preserves the measure both between $\mu_X$ and $\mu_{\overline{X}}$ and between $\mu^\prime_X$ and $\mu^\prime_{\overline{X}}$. (In other words $\mu_X(f^{-1}(Y)) = \mu_{\overline{X}}(Y)$, and similarly for $\mu^\prime$.) Does it follow that $\mu=\mu^\prime$?","['lebesgue-measure', 'real-analysis', 'measure-theory']"
1277665,"RSA, cipher, Cryptosystem","I genuinely have no idea how to go about solving this, any hints would be helpful","['cryptography', 'discrete-mathematics']"
1277675,Random walk on natural number,"Problem: You are standing at the position $0$ on the line of natural numbers $0, 1, 2, ..., n$. From this position you go to $1$ with probability $1$,
but from any other position $i$ you go to $i+1$ with probability $p$ and respectively to $i-1$ with probability $1-p$. What is the expected number of steps to go from 0 to n? Just to be clear. There is no way you can end up on the negative number. And once you reach $n$ the game stops, so you can not end up on any number bigger than $n$. Here is my approach to tackle this problem: Let $N_i$ is the expected number of steps to reach $n$ from a position $i$.
It is obvious that $N_n = 0$. Also $N_0 = 1 + N_1$. And if we select any number $i$ from $1$ to $n-1$, then $N_i = (1 - p) \cdot N_{i-1} + p \cdot N_{i+1} = 1 + (1-p) \cdot N_{i-1} + p \cdot N_{i+1}$. Now I am trying to simplify things having these three equations: $$N_0 = 1 + N_1\\
N_i = 1 + (1-p) \cdot N_{i-1} + p \cdot N_{i+1}\\
N_n = 0$$ Approach 1 Putting $i = 1$ in equation (2) I found that $N_1 = 2/p - 1 + N_2$, which I later put in (1) to get $N_0 = 2/p + N_2$ Doing the same with $i = 2$ I got $N_2 = 1 - 2/p + 2/p^2 + N_3$ and $N_0 = 1 + 2/p^2 + N_3$. Just one more step with $i = 3$ gives me $N_3 = N_4 + 4/p - 4/p^2 + 2/p^3 - 1$ and $N_0 = 4/p - 2/p^2 + 2/p^3 + N_4$ I was doing all this in hope of finding some relationship which would allow me to guess what will be the relationship for the last or one before last step. But I fail to see any and therefore I gave up. Approach 2 I noticed that:
$N_0 - N_1 = 1$ and $N_{i-1} - N_i = 1 + (1 - p) \cdot (N_{i-2} - N_i)$ Here if I will sum the left side, I will get $N_0 - N_n = N_0$ and this gave me hope that I can get some closed form expression if I will add the right side. But when I add them up I got $n + (1 - p)(N_0 + N_1 - N_{n-1} - N_{n})$. This gave me $N_0 = \frac{n + (N_1 - N_{n-1})(1-p)}{p}$ which leads me nowhere because of $N_1$ and $N_{n-1}$. Approach 3 (similar to approach 2, but I expand the first element, not the second). I will not write it completely, not because I have not thought about, but because I value your time and I think that
the post is already too long. So $N_0 - N_1 = 1$ and $N_i - N_{i+1} = -1 + p (N_i - N_{i+2})$. After the same summation idea as in approach 2 I ended up with $N_1$, $N_2$ and $N_{n-1}$ elements. After this I gave up completely. Here I am not really sure that my starting idea Let $N_i$ is the expected number of steps to reach $n$ from a position
  $i$. is correct or whether the close formula for expected value exist. So how should I approach this problem? P.S. I know that for $p = 0.5$ (go left and right with equal probability) the close formula exists and expected number of steps one need to take from $0$ to $n$ is $n^2$.","['probability', 'random-walk']"
1277742,Prove that a martingale bounded in $L_2$ converges almost surely [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Hi as the topic states prove that a martingale bounded in $L_2$ converges almost surely.",['probability']
1277748,Decay of Fourier Transform,"I encountered the following statement, and I cannot see why it is true(if it is). Suppose $f$ is a nonnegative, bounded, compactly supported and measurable function with the following properties: $||f||_1=1$, $|\widehat f(y)|<1$ for $y\neq 0$, $|\widehat f(0)|=1$ and $\frac{d}{dy}|\widehat f(y)|^2<0$. Then, the claim which I don't quite see how it follows is the following: For small $K$ and some $r>0$ we have $$\sup_{|y|\geq K}|\widehat f(y)|^2\leq e^{-r|K|^2}.$$ From the Riemann-Lebesgue lemma all we would get is decay of the order $1/K^2.$ Thanks","['asymptotics', 'fourier-analysis', 'real-analysis', 'measure-theory']"
1277753,How to prove that algebraic numbers form a field? [duplicate],"This question already has answers here : How to prove that the sum and product of two algebraic numbers is algebraic? [duplicate] (5 answers) Closed 3 years ago . I'd like to know how to prove that algebraic numbers form a field by using Kronecker Product, but not sure exactly how to do it. Edit: This question is different from the suggested duplicated one in that this question asks for an answer to prove that algebraic numbers form a field in unconventional ways such as using Kronecker Product. As the result, answers are very different from the one suggested duplicated. So this question deserves to remain open.","['abstract-algebra', 'field-theory', 'splitting-field']"
1277765,Are the sum and/or product of two increasing functions also increasing?,"Question : Let $f(x)$ and $g(x)$ be two increasing functions. a) Show that their sum is also increasing. b) Investigate the corresponding claim for the product of two increasing functions. Attempted solution: a) If $f(x)$ and $g(x)$ are increasing functions, that means that: If $x_{1} < x_{2}$, then $f(x_{1}) < f(x_{2})$ $g(x_{1}) < g(x_{2})$ Adding the two inequalities gives: $f(x_{1}) + g(x_{1}) < f(x_{2}) + g(x_{2})$ This shows that the sum is also increasing. b) Multiplying the original inequalities gives: $f(x_{1})g(x_{1}) < f(x_{2})g(x_{2})$ This seems false. Even if both are increasing, one of them can be negative, and so the inequality cannot hold for all functions f and g? Is there a way to formalize this rough intuition-based argument? Or is a counterexample the most obvious way forward? However, a counterexample seems to miss out on the more general argument about why the inequality does not hold for negative functions. What are some productive ways to finish this question off?","['algebra-precalculus', 'functions']"
1277767,An elementary property of tensor products.,"I'm studying representations theory to start my Masters thesis. I'm using the book of J. P. Serre, Linear Representations of Finite Groups and in the pg. 55 He affirm: If $V$ is induced by $W$ and if $E$ is a $C[G]$-module, we have a canonical isomorphism 
  $$Hom^H(W,E)\simeq Hom^G(V,E)$$ 
  where $Hom^H(V,E)$ denotes the vector space of $C[G]$-homomorphisms of $V$ into $E$, and  $Hom^G(W,E)$ is defined similarly. This follows from an elementary property of tensor products. Here, $G$ is a finite group, $V$ is a $C[G]$-module and $W$ a sub-$C[H]$-module of $V$. I'm trying to prove this but without success. Can someone explain how to proceed here? What is this property and how to use it? [EDIT] In the book, He said to see also the following lemma: Lemma: Suppose that $(V,\rho)$ is induced by $(W,\theta)$. Let $\rho':G\rightarrow GL(V')$ be a linear representation of $G$, and let $f:W\rightarrow V'$ be a linear maps such that $f(\theta_tw)=\rho'_tf(w)$ for all $t\in H$ and $w\in W$. Then there exists a unique linear map $F:V\rightarrow V'$ which extends $f$ and satisfies $F\circ \rho_s=\rho_s'\circ F$ for all $s\in G$","['abstract-algebra', 'representation-theory']"
1277769,Growth of Tychonov's Counterexample for Heat Equation Uniqueness,"Define a function $\varphi$ on $\mathbb{R}_{+}$ by
$$\varphi(t):=\begin{cases}e^{-1/t^{2}}, & {t>0}\\ 0, & {t\leq 0}\end{cases}\tag{1}$$ It is well-known that $\varphi$ is $C^{\infty}(\overline{\mathbb{R}}_{+})$ and $\varphi^{(k)}(0)=0$ for all integers $k\geq 0$. Tychonoff famously showed that the function $u:\mathbb{R}_{+}\times\mathbb{R}\rightarrow\mathbb{R}$ defined by $$u(t,x):=\sum_{k=0}^{\infty}\dfrac{\varphi^{(k)}(t)}{(2k)!}x^{2k}, \qquad (t,x)\in\mathbb{R}_{+}\times\mathbb{R}\tag{2}$$ belongs to $C^{\infty}(\mathbb{R}_{+}\times\mathbb{R})$ and satisfies the Cauchy problem $$\begin{cases}\partial_{t}u-\Delta u=0 & {(t,x)\in\mathbb{R}_{+}\times\mathbb{R}},\\ u(0,\cdot)=0 & {}\end{cases}\tag{3}$$ Question. Motivated by this question , I am trying to show that for $t>0$ fixed,
  $u(t,\cdot)$ does not define a tempered distribution. I am looking for
  a ""lower bound"" on the growth of $u$ for $t>0$ fixed which I can use
  to construct a sequence of test functions
  $\varphi_{m}\in\mathcal{S}(\mathbb{R}^{n})$ which tend to zero in the
  Schwartz topology but $$\left|\langle{u(t,\cdot),\varphi_{m}}\rangle\right|=\left|\int_{\mathbb{R}^{n}}u(t,x)\varphi_{m}(x)dx\right|\geq c,\quad\forall m\in\mathbb{N}\tag{4}$$ for some $c>0$. I know that the function $u$ does not satisfy the growth condition $$\sup_{0\leq t\leq T}\left|u(x,t)\right|\leq Ae^{c\left|x\right|^{2}},\quad\forall x\in\mathbb{R}^{n}\tag{5}$$ where $T>0$ is fixed and $A,c>0$ are constants depending on $T$; however, I fail to see how this helps in the task described above. Edit: Einar Rødland has presented some graphical evidence to suggest that for fixed $t>0$, $u(t,\cdot)$ is ""well-behaved"" and defines a tempered distribution. I am seeking a proof of disproof of this conjecture. Note that a ""wild solution"" can be ""well-behaved"" for $t>0$ fixed. For example, in this paper , the authors present an example of nonuniqueness for the Cauchy problem which is continuous on $\mathbb{R}\times [0,\infty)$ and satisfies $$\left|u(x,t)\right|\leq C e^{\epsilon/t},\qquad (x,t)\in\mathbb{R}\times\mathbb{R}_{+}$$ where $C=C(\epsilon)$, for any $\epsilon>0$. Also, at the end of the paper the authors remark that all other (i.e. besides theirs) nonuniqueness solutions are unbounded in $x$, which would seem to contradict Einar's suggestion.","['fourier-analysis', 'distribution-theory', 'functional-analysis', 'partial-differential-equations']"
1277775,Intuition of Wronskian determinant and linear independence,"I am wondering the intuition in regard to the following; (let $w$ represent the wronskian function). Please correct me If I am mistaken, but I will write what I do know and what I am confused about. Suppose we consider a set of $n$ differentiable functions, say,  $\{f_1,…f_n\}$ on some open interval $I=(\alpha,\beta)$ Then why is it that if $$w(f_1,…,f_n)(x) \neq 0$$ for $\mathbf{some}$ $x \in I$, then they are linearly independent on the interval. But, if $$w(f_1,…,f_n)(x)=0$$ for even one $x \in I$, then they are linearly dependent in I? Is this because if it is zero for one x that we can find, this implies that it will be zero for all $x \in I$? how can we conclude this? in regard to its relationship with differential equations, ( which is why I am currently learning this), I understand that we would require $w \neq 0$ to have a unique solution, and I also understand why have a row that is a multiple of another would gives $w=0$ from simple determinant rules. But I am having trouble tying it all together. Thank you","['determinant', 'linear-algebra']"
1277800,Expected value of a function of a random variable [duplicate],"This question already has an answer here : What is the name of this theorem, and are there any caveats? (1 answer) Closed 9 years ago . Let X be a random variable whose PDF is $f(x)$, and $g$ a function of random variable X. I want to prove that $$E[g(X)] = \int{g(x)f(x)dx} $$ I've perfectly understood it in discrete case and I managed to prove also for continous case when $g$ is an increasing function. What is a formal proof for this formula? And what is a good intuition for it?","['probability-theory', 'probability', 'probability-distributions']"
1277823,"Tautological line bundle over $\mathbb{RP}^n$ isomorphic to normal bundle? Also ""splitting"" of transition functions","Hallo fellow mathematicians.
I try to understand why the normal bundle of $\mathbb{PR}^n$ is isomorphic (in the category of vector bundles) to the tautological line Bundle. More aptly, why $\nu_{\mathbb{RP}^{n+1}}^{\beta} \mathbb{RP}^n \cong L, \text{ where } L$ denotes the tautological line bundle over $\mathbb{RP}^n$ and $ \beta \colon \mathbb{RP}^n \rightarrow \mathbb{RP}^{n+1} $ the inclusion induced by the inclusion $\mathbb{R}^{n+1} \subset \mathbb{R}^{n+2}$.
I followed a few loose ends until now. 
One of them: (1) In this script (pdf) I found a proof (p.8). I just don't understand, how that is supposed to be suffice as proof. Afaik under trivialisations I could identify every vector bundle of the same dimension, so what seals the proof here? Another idea I came up with: (2) On $\mathbb{PR}^{n+1}$ we have a riemannian metric, i.e. the tangent bundle allows a presentation as the whitney-sum: $\nu_{\mathbb{RP}^{n+1}}^{\beta} \mathbb{RP}^n \oplus T \mathbb{PR}^n  \cong T\mathbb{RP}^{n+1}|_{\mathbb{PR}^n} $. According to Husemoller (Fibre Bundles, Theorem 2.7) we now ( analogous to this ) that two vector bundles - in order to be isomorphic - have to have cohomologous transition functions, i.e. they are related in a certain way to each other. Afaik we can split the transition functions of $T\mathbb{PR}^{n+1}$ into the direct sum (in the sense that $\phi_{ij}(p)=\begin{matrix}
\phi_{ij}^1(p)	& 0  \\ 
0	& \phi_{ij}^2(p)
\end{matrix} $ is the transition function of $T\mathbb{PR}^{n+1}$, where $ \phi_{ij}^1$ is the trans. function of $T\mathbb{PR}^{n}$ and $ \phi_{ij}^2 $ the is trans. function of the normal bundle). As soon as I try to compute all this I encounter problems. So I took the transition functions of the ""standard"" atlas of $\mathbb{RP}^n$, i.e. with $U_i:=\{[x_1:\dots x_n]|x_i \neq 0 \}$ the transition function is $\phi_j \circ \phi_i^{-1} (y^1, \dots y^n)=(\frac{y^1}{y^j}, \dots \frac{y^{i-1}}{y^{j}}, \frac{1}{y^j}, \frac{y^{i+1}}{y^j}, \dots,\frac{y^n}{y^j})$. When I pass this to the Jacobian (which is the transition function of the tangent bundle, right?) things get ugly. (3) Another idea I had (which is... regressing I suppose) is to use the orientiability of $\mathbb{RP}^{2n}$ and $\mathbb{RP}^{2n+1}$ and their stiefel whitney classes, which inplies in every case, that the normal bundle is not trivial. But now I would have to show that a line bundle is either trivial or isomorphic to the tautological bundle over $\mathbb{RP}^n$. Is that even true?
I'm very greatful for any help you may be able to provide. If I made a mistake, you are more than welcome to correct me.","['manifolds', 'general-topology', 'differential-topology', 'differential-geometry', 'algebraic-topology']"
1277829,Can the integers be made into a vector space over any Finite Field? [duplicate],"This question already has an answer here : Prove $\mathbb{Z}$ is not a vector space over a field (1 answer) Closed 5 years ago . Given a Finite Field $F$, can the the abelian group $\mathbb Z$ be made into a vector space over $F$ without changing the additive structure of $\mathbb Z$? This seems like it shouldn't be complicated, but having trouble on this one, any hints would be appreciated. I already know that $F\cong \mathbb F_{p^n}$ for some prime $p$ and some $n\in \mathbb N$. I have been trying to make a map $F\times \mathbb Z\rightarrow \mathbb Z$ by $(\overline n,m)\mapsto n\cdot m$ but this really seems like the wrong approach since the axioms aren't really met, maybe its not even possible. REPLY: Thanks so much for your replies, I am now fairly convinced that there is no such Vector Space. Thank you again, I am very appreciative of your assistance ^_^","['abstract-algebra', 'vector-spaces', 'integers', 'finite-fields']"
1277852,Upper bound of Frobenius norm of product of matrices.,I'm trying to prove that $||AB||_F\leq||A||_2||B||_F$. As far as I know it isn't a hard problem but I was stuck. Any ideas?,"['normed-spaces', 'linear-algebra', 'matrices']"
1277876,"Show $ \langle Tx,x \rangle \in \Bbb R\ \forall x \in H\ \implies T$ is self-adjoint","Show that a linear operator $T: H \to H$ is self adjoint if and only if $\langle Tx, x \rangle \in \Bbb R\ \forall x \in H$ . You may use that the equality that for all $x,y \in H$ $4\langle T(x),y \rangle = \langle T(x+y),x+y \rangle - \langle T(x-y),x-y \rangle + i\langle T(x+iy), x+iy \rangle -i\langle T(x-iy),x-iy \rangle$ without proof. I can show the forward implication quite easily: If $T$ is self adjoint, then $T = T^*$ so $ \langle Tx,x \rangle = \langle x,Tx \rangle = \overline{\langle Tx,x \rangle}$ Only real values are equal to their conjugate so this show $ \langle Tx,x \rangle \in \mathbb R$ for all $x \in H$ . However, I am having trouble showing the other direction holds. I've tried using the parallelogram identity and then equating real parts but to little avail. I am wondering how to go about this.","['adjoint-operators', 'inner-products', 'hilbert-spaces', 'functional-analysis']"
1277914,Solving exercise 1.10 in Silverman's AEC,"Please note that although there is a very similarly titled question Exercise 1.10 from Silverman ""The Arithmetic of Elliptic Curves"" this question received no answers. Let $p$ be an odd prime and $V_p\subseteq \mathbb P^2$ the variety $$V_p : X^2 + Y^2 = p Z^2 $$ I'm trying to show that $V_p \cong \mathbb P^1$ over $\mathbb Q$ if and only if $p\equiv 1\pmod 4$ . The forward direction is easy: suppose $p\cong 3\pmod 4$ . If $V_p$ is isomorphic to $\mathbb P^1$ over $\mathbb Q$ then $V_p (\mathbb Q) \cong \mathbb P^1 (\mathbb Q)$ . But $X^2 + Y^2 = p Z^2$ has no solutions in integers and thus $V_p (\mathbb Q)=\varnothing$ , and we know $\mathbb P^1 (\mathbb Q)\neq\varnothing$ . However I'm struggling to do the other direction because I can't cook up a good isomorphism $V_p \cong \mathbb P^1$ defined over $\mathbb Q$ when $p\equiv 1\pmod 4$ . Can anyone help me out with this? Thank you!","['elliptic-curves', 'algebraic-geometry', 'number-theory']"
1277916,Proving $\int_\mathbb R\frac{\sin(x)}{x}dx = \pi$ using the residue theorem [duplicate],"This question already has answers here : Evaluating the integral $\int_0^\infty \frac{\sin x} x \,\mathrm dx = \frac \pi 2$? (32 answers) Closed 6 years ago . I've been searching the web for a way to prove that $\int^{\infty}_{-\infty}{\sin(x)/x} = \pi$ with complex analysis, because I have a problem of consistency. I found two, carried in the following link : Computing $\int_{-\infty}^\infty \frac{\sin x}{x} \mathrm{d}x$ with residue calculus . But then I wanted to find it by using the fact that : $\sin(x)/x = \text{Im}(e^{ix}/x)$ To do so, I shifted the integration by $-i$ in the complex plane, showing that the integral on $[-\infty , \infty]$ is equal to the one on $[-\infty -i, \infty -i]$, since the integrand vanish on the vertical borders of the rectangle when we tend to infinity. I did this to get rid of the pole on the contour of integration. Then, by using the residues theorem on the contour $C_1 : z = y-i, y \in [-R,R]$ and $C_2 : z = Re^{it}-i, t \in [0,\pi]$. Given the integral on $C_2$ vanishes, we have then that : $\int^{\infty}_{-\infty}{\sin(x)/x} = \text{Im}(\int^{\infty}_{-\infty}{e^{ix}/x}) = \text{Im}(2\pi i\,\text{Res}(e^{iz}/z, 0)) = 2 \pi$ Which gives me the answer with a factor of $2$. I don't understand were did I go wrong ? I think it has something to do with the fact that I take the imaginary part of the integral, but I don't really know... Can someone spot my mistake ? If needed, I can provide further detail on my calculations.","['improper-integrals', 'definite-integrals', 'residue-calculus', 'integration', 'complex-analysis']"
1277920,Primes that divide $2^{\frac{p-1}2}+1$,"$p$ is a prime and $p\equiv 3,5 \pmod8$. Prove that $p\ | \ 2^{\frac{p-1}2} +1$. How should I approach this problem?",['number-theory']
1277925,How do you understand renaming of summation variables?,"As a part of a Knuth example , I struggle to understand how you flip the index so easily: $$\sum_{0 < j < k}(k-j) = \sum_{0 < k-j < k} j.$$ Why doesn't Knuth exchange the summand with the summation variable $k$ in $$\sum_{j < k < n}(k-j) = \sum_{j < k+j < n} k?$$ OK, the latter is easy to understand: no matter which variable/expression you have between $j$ and $n$, the summand is $j$ less than that. But which picture should I imagine to understand the variable change in the first summation?","['summation', 'discrete-mathematics']"
1277933,Closed form $\int_{-1}^{1} \frac{\ln (\sqrt{3} x +2)}{\sqrt{1-x^{2}} (\sqrt{3} x + 2)^{n}}\ dx$,"Does the following integral 
$$\int_{-1}^{1} \frac{\ln (\sqrt{3} x +2)}{\sqrt{1-x^{2}} (\sqrt{3} x + 2)^{n}}\ dx, \; \; n \in \mathbb{N}$$ have a nice closed form? Basically I cannot tackle it in any direction. Symmetry is useless . Applyig parts , well , gets things worse than they actually are. Could complex analysis help us here? That is, integrating around a dog bone contour ... I highly doubt it but it is just a thought. Any help on this one?","['closed-form', 'complex-analysis', 'real-analysis', 'improper-integrals']"
1277942,Find the union of of the following family or indexed collection,"this question was posted but I did not understand the solution.
For each natural number n, let An = {5n, 5n+1, 5n+2,...,6n}. And let A = {An: n is an element of the natural numbers}. Here is where I am: An = {5, 6, 7, 8, 9, 10,...} So U An = {5, 6, 7, 8, 9, ....} I saw the solution and it said that A1 = {5, 6} my question is if An = {5n, 5n+1, 5n+2, ..., 6n} then wouldn't A1 go on from 5 until infinity  because n = 1) 5(n)= 5, 5(n)+1 = 6, 5(n)+2 = 7,... Any explanation would be really helpful! The solution is U An = {5, 6, 10, 11, 12, 15, 16, 17, 18} U { n is an element of the natural numbers: n >= 20}",['discrete-mathematics']
1277955,Convergence on Norm vector space.,"I am not sure if this question make sense mathematically, so please bear with my ignorance. This is an extension to the question in the link: Is complete metric space is required? It seems in many engineering problem when we look for an optimal solution we work on normed vector space and it is complete under Lp norm. My question is how to improve convergence with less or limited data?
It appears to me that since our metric space is complete the convergence issue is related to the structure of space. What I mean is, we may not able to get faster convergence with limited data if we work on linear vector space. Is it possible that the problem may have a better solution in some function space which is not linear?","['linear-algebra', 'functional-analysis']"
1277974,Trapezoidal Rule in Stirling's Approximation,"https://en.wikipedia.org/wiki/Stirling's_approximation Here $$\sum \limits_{i=1}^n \log(i) $$ is approximated as $$\int^n_1\log(x) dx\ +\ 1/2\ \log(n)$$ but I would approximate it as $$\int^{n+1/2}_{0.5}\log(x)dx$$ clearly my method gives the wrong answer. Can someone explain to me how 1/2 logn term is decided? ADDITION: For example, if I wanted to approximate $$\sum \limits_{i=1}^{100} i^{-2} $$ I would actually sum the first 10 terms, and then add a correction term using integration. What I would do is, I would add the integral of 1/x^2 from 10.5 to 100.5 (sort of like a midpoint rule). What this rule suggests I do is to integrate from 11 to 100 and then add 1/2(1/11^2 + 1/100^2). I actually did this and my term is accurate within 7.1677e-05 and the trapezoid is accurate within -1.2485e-04. Final Edit: https://i.sstatic.net/kdPu2.png My approximation actually provides a better approximation anyway.","['asymptotics', 'approximation', 'factorial', 'integration']"
1277997,Determining if $\mathbb{Z}[a]$ is a discrete subring of $\mathbb{C}$.,"Let $a \in \mathbb{C}$ and consider the ring $\mathbb{Z}[a]$ . Is there some nice criterion which will tell me whether $\mathbb{Z}[a]$ is discrete in the sense that there is some $\delta >0$ such that, whenever $x \in \mathbb{Z}[a] \setminus \{0\}$ , one has $|x| \geq  \delta$ ?  It follows, then, that there is a smallest possible distance between any two points. I have been able to show some pretty easy things, such as: Fact 1 : A subring $R \subset \mathbb{C}$ is discrete if and only if $\{ |x| : x \in R\} \subset [0,\infty)$ is order isomorphic to $\mathbb{N}$ . Fact 2: The only discrete (unital) subring of $\mathbb{R}$ is $\mathbb{Z}$ . Fact 2 makes the case $a \in \mathbb{R}$ pretty easy: we get $\mathbb{Z}[a]$ discrete if and only if $a \in \mathbb{Z}$ . The case where $a \in \mathbb{C}$ is pure imaginary is also pretty easy. You need $\mathbb{Z}[a^2] \subset \mathbb{Z}[a]$ to be discrete, so you need $a^2$ an integer, i.e. $a = \pm \sqrt{n}i$ for some positive integer $n$ .  It's not hard to show that, for such $a$ , the ring $\mathbb{Z}[a]$ is also discrete. The next case I tried was the case where $a$ is a root of unity. If $a \neq 1$ is a third root of unity, things work out quite nicely: it turns out that $\mathbb{Z}[a]$ is a hexagonal lattice. However, if $a \neq 1$ is a  fifth root of unity, it gets difficult to compute by bare hands, and I am not too sure what happens.","['integer-lattices', 'abstract-algebra', 'ring-theory']"
1278063,"Evaluate $\int_0^2 \sqrt[3]{x^2 + 2x - 1} \, dx$","Calculate the value of the integral
  $$
\int_0^2 \sqrt[3]{x^2 + 2x - 1} \,dx
$$
  with measurement uncertainty not larger than $10^{-3}$. I know we can evaluate integration using the ""trapezoidal rule"" or ""Simpson's rule"". But if we want to calculate the uncertainty, using the first rule, we have to calculate $\max_{x \in [0, 2]} |f''(x)|$, which does not exist ($|f''(x)| = {2 \over 9}|{x^2 + 2x + 7 \over (x^2 + 2x - 1)^{5/3}}| $, which has limit $+\infty$ when $x \rightarrow \sqrt{2} - 1$). Using the second rule, we need to calculate $\max_{x \in [0, 2]} |f''''(x)|$, which doesn't exist either. So, how can we evaluate this integral? Can someone give me a suggestion? Thanks.","['numerical-methods', 'integration']"
1278075,"Let $(X, \mathfrak T)$ be a topological space and suppose that $A$ and $B$ are subsets of X. If $A\subseteq B$ then $A' \subseteq B'$","Let $(X, \mathfrak T)$ be a topological space and suppose that $A$ and $B$ are subsets of X.
If $A\subseteq B$ then $Bd(A) \subseteq Bd(B)$ If $A\subseteq B$ then $A' \subseteq B'$  ($A'$ is the set of limit points) Let $( X, \mathfrak T_U)$ be the topological space. Let $A = [0,1) \cup (1,2)$ Let $B = [0,1) \cup (1,3)$ Then $A\subseteq B$ but $Bd(A)= \{0,1,2\}$ and $Bd(B) = \{0,1,3\}$ therefore $Bd(A) \not \subseteq Bd(B)$ so this is a false conjecture. I am a little more uncomfortable with the limit points. I believe $A'= [0,1] \cup [2, \infty)$ and $B'= [0,1] \cup [3, \infty)$ and therefore again this would be a false conjecture. My definition of limit point is that every open set containing $x$ contains a point of $A$ different from $x$. My definition of boundary is: Let $(X,\mathfrak T)$ be a topological space and let $A \subseteq X$. A point $x \in X$ is in the boundary of $A $if every open set containing $x$ intersects both $A$ and $X−A$","['elementary-set-theory', 'general-topology']"
1278077,Linear Ordinary Differential Equation with Nonconstant Coefficients,"What would be a good method for solving these equations? $y''±kx^2y=0$ As I see, it could work with power series (At least with the minus), it wouldn't work with LaPlace. Is there a better methood to solve it?",['ordinary-differential-equations']
1278165,How to know what kinds of substitution can we do in math?,"I have seen in many contexts that somebody out of the blue decides to put $x=y^2$, or $x=t/2$. So how do I know what kind of sustitution I'm allowed to do? Is there any necessary conditions or we can just put for example $x=\sqrt {sin(2y)}$ if necessary?","['algebra-precalculus', 'soft-question']"
1278172,Evaluate $\int_0^{\infty}\frac{e^{-x}-e^{-2x}}{x}dx$ using a double integral,"I was given the following problem: Evaluate the following integrate using a double integral: $\int_0^{\infty}\frac{e^{-x}-e^{-2x}}{x}dx$. The professor told us off the bat the answer was $\ln(2)$. He wants us to show our work and prove this is true. My attempt is below. $I(x)$=$\int_0^{\infty}\frac{e^{-x}-e^{-2x}}{x}dx$ = $\int_0^{\infty}\frac{e^{-y}-e^{-2y}}{y}dy$ =$I(y)$. Thus I can say $=I(x)=\sqrt{I(x)I(y)}$ \begin{eqnarray}
\int_0^{\infty}\frac{e^{-x}-e^{-2x}}{x}dx &=&\sqrt{\int_0^{\infty}\frac{e^{-x}-e^{-2x}}{x}dx\int_0^{\infty}\frac{e^{-y}-e^{-2y}}{y}dy}\\
& = & \sqrt{\int_0^{\infty}\int_0^{\infty}\frac{(e^{-x}-e^{-2x})(e^{-y}-e^{-2y})}{xy}dxdy}
\end{eqnarray} This is where things get a little nasty. I can decided to make a change of variables. Letting $x=r\cos{\theta}$, $y=r\sin{\theta}$, thus $dA=dxdy=rdrd\theta$ by the Jacobian. Thus: \begin{eqnarray}
\int_0^{\infty}\frac{e^{-x}-e^{-2x}}{x}dx & = & \sqrt{\int_0^{2\pi}\int_0^{\infty}\frac{(e^{-r\cos{\theta}}-e^{-2r\cos{\theta}})(e^{-r\sin{\theta}}-e^{-2r\sin{\theta}})}{r^2\cos{\theta}\sin{\theta}}rdrd\theta}\\
& = & \sqrt{\int_0^{2\pi}\int_0^{\infty}\frac{(e^{-r(\cos{\theta}+\sin{\theta})}-e^{-r(2\cos{\theta}+\sin{\theta})}-e^{-r(\cos{\theta}+2\sin{\theta})}-e^{-2r(\cos{\theta}+\sin{\theta})}}{r\cos{\theta}\sin{\theta}}drd\theta}
\end{eqnarray} This is where I am stuck. From here I did a lot of trial and error trying to solve for the problem. From changing the order of integration, integration by parts, and subsitution. Is there something I am missing? Maybe a trig identity that will help simplify the expression. Thank You for your time and I greatly appreciate any feedback you give me.","['calculus', 'multivariable-calculus', 'trigonometry']"
1278203,"Proof that $\gcd(2^m-1,2^n+1)=1$ for odd $m$ using group theory","Below is a perfectly fine proof using basic tools of number theory: Showing $\gcd(2^m-1,2^n+1)=1$ Could we prove this more quickly using group theory? I would be very interested in seeing an abstract algebra-flavored proof.","['gcd-and-lcm', 'abstract-algebra', 'group-theory', 'elementary-number-theory', 'divisibility']"
1278240,Suggest a follow up book to Axler's Linear Algebra Done Right?,"So I know that a similar question has probably been asked about alternatives or compliments to this book, but I think my situation is different enough to warrant slightly different advice. So I've just completed a course that used this text and I've read it pretty thoroughly for the most part, but I didn't learn everything as well as I wanted (maybe that's normal), probably because some days I was slightly less motivated than others and so my knowledge is better in some areas than others. I want to close the gaps obviously, but I'm not sure I want to just re-read the text, not for a few weeks anyway. Could anybody suggest another book that treats linear algebra in a similar theoretical fashion (less emphasis on matrices), or should I just wait a week or two after the semester is over to re-charge and just re-read sections from this text? Also, I've had two semesters of real analysis, and am planning to self study functional analysis over the summer, will this afford me a chance to plug a few of the holes? As in, do a lot of the more fundamental results in linear algebra also pop up in a functional analysis text? That way I could possibly kill two birds with one stone?","['book-recommendation', 'reference-request', 'linear-algebra', 'soft-question']"
1278251,Sum of open/closed/compact sets in $\mathbb{R}^n$ open/closed/compact,"I know that the following exercise you can find on internet maybe with solution too, but I want to know, if my ""solutions"" are correct. Let $X,Y\subset \mathbb{R}^n$, $X+Y=\{x+y;x\in X, y\in Y\}$. Prove it or find a counterexample. 1) If X, Y open, then X+Y is open 2) If X, Y closed, then X+Y is closed 3) If X, Y compact, then X+Y is compact My ideas: 1) is true. Could you have a look if my solution is correct? My try: We know that for all $x\in X \exists \epsilon >0: B_{\epsilon}(x)=\{b\in X; \|b-x\|<\epsilon\}\subset X$, and for all $y\in Y \exists \epsilon' >0: B_{\epsilon'}(x)=\{b'\in X; \|b'-x\|<\epsilon'\}\subset Y$, because $X$ and $Y$ are open. Now: $\|z-(x+y)\|=\|z-x-y\|=\|z'-z'+z-x-y\|=\|z'-x+z-z'-y\|\le\|z'-x\|+\|z-z'-y\|<\epsilon+\epsilon'$. Define $\eta =\epsilon +\epsilon'$. We have: for $x+y\in X+Y \exists \eta >0, \eta =\epsilon +\epsilon': B_{\eta}(x+y)=\{z\in X+Y; \|z-(x+y)\|<\eta\}\subset X+Y$. I'm not sure, if this is correct. If my ""solution"" is false, could you help to correct? 2) First I said that this is true, but after googeling I found out that you can find a counterexample. Could you help me to find the mistake of my ""solution""? My try:
For every sequence $(x_n)\subseteq X$ such that $x_n\to x_0$, $x_0\in \mathbb{R}^n$, it is $x_0\in X$, because X is closed. For every sequence $(y_n)\subseteq Y$, such that $y_n\to y_0$, $y_0\in \mathbb{R}^n$, it is $y_0\in Y$, because Y is closed. Let $(z_n)\subseteq X+Y$ be a sequence, $z_n=x_n+y_n$ for every $n\in\mathbb{N}$ and let $z_n\to z_0 \in \mathbb{R}^n$. But it is $z_n=x_n+y_n\to x_0+y_0$ and by the uniqueness of limits $z_0=x_0+y_0\in X+Y$, because X and Y are closed. But my try has to be wrong I think, because you find counterexamples for 2).
And I don't find the mistake :(, could you help me? 3) Is it correct? I would say yes. Maybe I can prove it with a continuous function and $X+Y$ as it's compact image. Regards","['real-analysis', 'general-topology']"
1278256,Some questions about reduction of elliptic curves,"Let $E \rightarrow S$ be an elliptic curve (i.e, a smooth proper curve of genus 1). If $S = \text{Spec (K)}$ where $K$ is a local field, the usual way of doing a reduction at a prime $\mathfrak{p} = (\pi)$ is by reducing the defining equation of the elliptic curve modulo $\pi$ or, equivalently, by finding the Néron model of $E$, namely $\tilde{E} \rightarrow \text{Spec} (\mathcal{O}_K)$ and define $\tilde{E}_{\kappa(\mathfrak{p})} \rightarrow \text{Spec} (\kappa(\mathfrak{p}))$ as the reduction in the prime $\mathfrak{p}$. In the case of $K$ a global field, the same process applies when completing in the prime $\mathfrak{p}$ and reducing to the case of a local field. And, now comes the questions: 1) It's natural to do another process. Suppose $K$ is a global field. If $\tilde{E} \rightarrow \text{Spec} (\mathcal{O}_K)$ is the Néron model, then I could simply define $\tilde{E}_{\kappa(\mathfrak{p})} \rightarrow \text{Spec} (\kappa(\mathfrak{p}))$ as the reduction, where the pullback is given by the inclusion of a point at $\mathfrak{p}$. Or I could define the reduction by using the Néron model over $\mathcal{O}_{K, \mathfrak{p}}$ and defining the reduction as the fiber over $\mathfrak{p}$. Are these constructions equivalent? 2) It's known that if the reduction is bad, then it's multiplicative or additive. In these cases, respectively, $E_{nonsing} \cong \mathbb{G}_m$ and $E_{nonsing} \cong \mathbb{G}_a$. Is it possible to prove such isomorphisms in a more scheme-theoretical way? In Silverman's book, for instance, the proof uses the defining equation of $E$. 3)Is there a more scheme-theoretical way of defining what's a split multiplicative reduction? 4)If $S$ is an arbitrary scheme and viewing $E \rightarrow S$ as a deformation of elliptic curves, is it possible to define a reduction of this family at some prime under certain suitable conditions? For instance, if the residue field is always the same ($\kappa (s)$ is always the same for each $s \in S$), then it's possible to find the Néron model of each fiber $E_s \rightarrow \text{Spec} (\kappa (s))$ and reduce at a given prime $\mathfrak{p}$ of $\mathcal{O}_{\kappa (s)}$, however I can't see any reasonable way to glue everything (such that the morphism to the base is at least flat). Thanks in advance.","['elliptic-curves', 'algebraic-geometry', 'arithmetic-geometry']"
1278266,Permuting the terms of a sequence does not affect its convergence,"Let $x_n$ be a sequence such that $x_n \rightarrow 0$.  Let $\sigma\colon\mathbb N \rightarrow \mathbb N$ be a bijection. Define a new sequence $y_n:= x_ {\sigma (n)} $. Show that $ y_n \rightarrow 0 $. ATTEMPT Since $x_n$ converges to 0 implies after a certain $n>n_{0}$ all its terms will lie between $(0-\epsilon,0+\epsilon$). As $\sigma$ is a bijection so it is increasing function. If I take set of subscripts of original sequence, I take all $n$ after $n>n_0$ such that set $\{ n_1 ,n_2,n_3,n_4,\ldots\}$ where all $n_{i} ,i=1,2,3,\ldots$ are bigger than $n_0$. So applying $\sigma$ function which is an increasing function I get new increasing sequence of subscripts. Now I need to claim that $x_i = \sigma (n_i)$ in order to make furthure progress. But how? Thanks","['sequences-and-series', 'real-analysis']"
1278311,$\lim_{n\rightarrow\infty}\frac{1}{n}\sum_{k=1}^{n}\frac{k}{k^{2}+1}$,"Could please give me a hint. $$\lim_{n\rightarrow\infty}\frac{1}{n}\sum_{k=1}^{n}\frac{k}{k^{2}+1}$$ It looks like an integral, but I failed to figure out the function.","['calculus', 'limits']"
1278328,Why are diffeomorphism-invariant PDE not elliptic?,"In reading geometric analysis papers, I frequently encounter a statement of the form, ""The PDE in question is diffeomorphism-invariant, and therefore cannot be elliptic."" My vague understanding is that this might have to do with the space of solutions being infinite-dimensional, or maybe it has to do with elliptic regularity failing.  Either way, I would like more precise clarification.","['analysis', 'riemannian-geometry', 'partial-differential-equations']"
1278356,"The assignment $R\mapsto\operatorname{Iso}_{R\text{-alg}}(A\otimes_k R,M_n(R))$ is a scheme?","Let $A$ be a central simple algebra over some field $k$, with degree $n$. There is a functor $F$ defined by the assignment, for a commutative ring $R$,
$$
F(R)=\operatorname{Iso}_{R\text{-alg}}(A\otimes_k R,M_n(R)).
$$ I'm writing $\operatorname{Iso}_{R\text{-alg}}(A\otimes_k R,M_n(R))$ to be the set of algebra isomorphisms $A\otimes_k R\to M_n(R)$. Is there a nice way to see that this is in fact a scheme over $k$?","['algebraic-geometry', 'schemes']"
1278399,Deforming line bundles on abelian varieties,"Let $X$ ba an abelian variety over $\mathbb C$. I would like to understand how line bundles on $X$ deform. The obstructions to deform line bundles  lie in $$\textrm{Ext}^2(L,L)=H^2(X,\mathscr O_X).$$ Is this the trivial vector space? If so, this would in particular imply the smoothness of the Picard scheme. I know this is very classical but I cannot find a reference. Note that what I ask is equivalent to asking about the surjectivity of the map $$\textrm{Pic }X\overset{c_1}{\longrightarrow}H^2(X,\mathbb Z).$$ Also, I would be curious to know if the answer changes in positive characteristic... Thank you!","['abelian-varieties', 'algebraic-geometry']"
1278400,"For any strictly increasing convergent sequence $x_n$, the sequence $f(x_n)$ is convergent","Let $f(x)$ be defined on R and be strictly increasing. Claim: for any strictly increasing convergent sequence $x_n$, the
  sequence $f(x_n)$ is convergent. I believe it's false. Think about any strictly increasing right-continuous function with a jump discontinuity. Clearly, as $x_n$ goes to the point of discontinuity, $f(x_n)$ fails to converge because at that point the left-sided limit isn't equal to the value of the function. The problem is that the suggested answer is that the claim is true. Am I right or no?","['sequences-and-series', 'real-analysis', 'functions']"
1278419,"Show that the number of reduced residues $a \bmod m$ such that $a^{m-1} \equiv 1 \pmod m$ is exactly $\prod_{p \mid m} \gcd(p-1,m-1).$","Show that the number of reduced residues $a \bmod m$ such that $a^{m-1} \equiv 1 \mod m$ is exactly $$\displaystyle \prod_{p \mid m} \gcd(p-1,m-1).$$ Suppose $f(x) = x^{m−1}−1$ and let $m = p^\alpha_1 \cdots p^\alpha_n$ denote the prime factorization of $m.$ If $p$ is prime, $p \mid m$ and $\alpha \geqslant 1,$ then $f(x)$ has $(m − 1, p − 1)$ roots modulo $p^{\alpha}.$ Thus $f(x)$ has $\displaystyle \prod (m − 1, p − 1)$ roots mod $m.$ Suppose $p \geqslant 3$ or $p = 2$ and $\alpha = 1$ or $2.$ By the generalized Euler criterion, $x^m−1 ≡ 1 \mod p^{\alpha}$ has $k = (m − 1, \phi(p^{\alpha})) = (m-1,p^{\alpha-1}(p-1))$ roots since $1^{\phi(p^{\alpha}/k)} \equiv 1 \mod p^{\alpha}.$ But $k =
(m-1,p^{\alpha-1}(p-1)) =(m-1,p-1)$ since $p \mid m$ and hence $p \nmid m−1.$ We are left with the case that $p = 2$ and $\alpha \geqslant 3.$ Since $p = 2 \mid m$ we have that $m − 1$ is odd. Thus $x^{m−1} ≡ a \mod 2^{\alpha}$ has exactly $1$ solution. But in
this case $1 = (m − 1, p − 1) = (m − 1, 2 − 1)$ as well. $ \Box$ Above is a elementary number theory proof. Question: How can this be proved using tools from abstract algebra (potentially group/ring theory)?","['ring-theory', 'group-theory', 'elementary-number-theory']"
1278425,A continuously differentiable bijection implies its inverse is Lipschitz continuous,"Let $f:\mathbb{R}\rightarrow \mathbb{R}$ be a continuously differentiable bijection. Does this imply that $f^{-1}$ is Lipschitz continuous? (of course, not globally, take for instance $f(x)=x^3$) If not, what if $f\in C^2$ in addition? I tried stupid things like... Fix an interval $[a,b]$ and pick $x,y\in [a,b]$. Then
$$|x-y|= |f(f^{-1}(x)) - f(f^{-1}(y))|\leq \|f'\|_{\infty} |f^{-1}(x)-f^{-1}(y)|$$
where $\|f'\|_{\infty} := \sup_{x\in [a,b]} |f'(x)|$. But I don't see how to conclude from this. Thanks!","['calculus', 'continuity', 'real-analysis', 'lipschitz-functions', 'analysis']"
1278433,"Given $Re\{f'(z)\}$, to find $Im\{f(z)\}$","An analytic function $f(z)$ is such that $\Re\{f'(z)\} =2y$ and $f(1+i)=2$ . Then the imaginary part of $f(z)$ is $-2xy$ $x^2-y^2$ $2xy$ $y^2-x^2$ Here, by using Milne Thomson's method I get $f'(z)=\int{-2i}$ $dz$ $=-2iz+c$ , $c$ is the ingrating constant. Now again integrating I got $f(z) =-iz^2+cz+d$ , $d$ is another integrating constant. But by only one condition I can not find out the value of two constants $c$ and $d$ . But if I omit $c$ , then using the given condition I get $\Im(f(z))$ as $y^2-x^2$ . I'm really confused and cannot understand what to do actually. Should I omit $c$ in the first integration? Is there any other method for finding the solution? Update:(21st May-2015) Using Cauchy-Riemann equations we get $f'(z)=2y-2ix$ . Then , $$f(z)=\int (2y-x)(\,dx+i\,dy)+C$$ $$=\int 2y\,dx+2i\int y\,dy-2i\int x\,dx+2\int x\,dy+C$$ $$=2xy+iy^2-ix^2+2xy+C$$ $$=4xy+i(y^2-x^2)+C.$$ So, if we neglect the constant or take it as a real constant then we get the imaginary part is $y^2-x^2$ . But I have a confusion about the integration. Is the integration correct ? If wrong then please tell me why it is incorrect ? There is no difficulty about the answer of  Daniel Fischer. See my update only.","['complex-analysis', 'functions']"
1278447,Estimation of the Hermite Polynomials using Plancherel-Rotach asymptotics,"Suppose $H_n(x)$ is a Hermite Polynomial such that
$$\int_{\mathbb{R}} H_n(x) H_m(x) e^{-x^2} dx = \delta_{m,n}.$$
I want to show for $ \phi_n(x) = H_n(x)e^{-\frac{X^2}{2}}$
$$ \left( \phi_n(x)\phi_{n-1}(y) - \phi_{n-1}(x) \phi_n(y) \right)^2 \leq \frac{C}{n},$$
for all $x,y$ and $n$, some constant $C$ (doesn't depend on $x,y,n$).
I have tried to use Plancherel-Rotach estimates, but I haven't succeeded. I wonder if you have ever seen somewhere a similar result before.","['probability-theory', 'real-analysis', 'orthogonal-polynomials']"
1278465,Maximum number of Sylow subgroups,"I've been studying Sylow-$p$ subgroups, and I've come across this problem. Let $G$ be a finite group. Show that the number of Sylow subgroups of $G$ is at most $\frac{2}{3}|G|$ . ($|G|$ is the number of elements of $G$). I am having trouble figuring this one out, I was wondering if anyone could help?","['abstract-algebra', 'sylow-theory', 'group-theory', 'finite-groups']"
1278482,Is this a normal form for $4$-forms on manifolds?,"Starting from a $2$-form $\omega$ which is nondegenerate and closed on a $2n$-dimensional manifold, it is always possible to find local coordinates $x_1,y_1,\ldots,x_n,y_n$ so that the form $\omega$ can be written locally as 
$$\sum_{k:1}^n a_Idx_k\wedge dy_k.$$ It is well-known that we can also say more on the functions $a_I$ (Darboux theorem). Take $\psi$, a $4$-form nondegenerate and closed on a $4n$-dimensional manifold. It is not true, in general, that locally $\psi$  can be written as
$$\sum_{k:1}^n a_Idx_{4k-3}\wedge dx_{4k-2}\wedge dx_{4k-1}\wedge dx_{4k}$$
where $a_I$ are in $C^{\infty}(M)$ when n>1.
Someone knows if there are some conditions on the manifold that assure that this can be done?",['differential-geometry']
