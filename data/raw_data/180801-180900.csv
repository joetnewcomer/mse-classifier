question_id,title,body,tags
3292556,Summation methods ordered by strength,"A summation method is a partial function from scalar sequences to scalars, i.e. an element of the set $\mathbb{C}^\mathbb{N} \rightharpoonup \mathbb{C}$ . A summation method $\Sigma_1$ is weaker than a summation method $\Sigma_2$ iff $\Sigma_1 \subseteq \Sigma_2$ , i.e. $\text{dom } \Sigma_1 \subseteq \text{dom } \Sigma_2$ and $\forall a \in \text{dom } \Sigma_1 : \Sigma_1(a) = \Sigma_2(a)$ . A summation method $\Sigma_1$ is consistent with a summation method $\Sigma_2$ iff $\forall a \in \text{dom } \Sigma_1 \cap \text{dom } \Sigma_2 : \Sigma_1(a) = \Sigma_2(a)$ . Cauchy summation is defined as the limit of partial sums, where such a limit exists: \begin{align}
    (\text{Cauchy}) \sum a
    &= \lim_{m \rightarrow \infty} \sum_{n=0}^m a_n
\end{align} A summation method is regular iff it is stronger than Cauchy summation. A summation method is linear iff $\Sigma(sa) = s\Sigma(a)$ and $\Sigma(a+b) = \Sigma(a)+\Sigma(b)$ for every scalar $s$ , sequence $a$ , and sequence $b$ . A summation method is stable iff $\Sigma(a)=a(0)+\Sigma(\sigma(a))$ , where $\sigma(a)(n)=a(n+1)$ is the shift operator. Is there a comprehensive list of summation methods (partially) ordered by strength? Are the following methods correctly ordered by strength? \begin{align}
    (\text{Cesàro},\alpha) \sum a
    &= \lim_{m \rightarrow \infty} \sum_{n=0}^m \frac{\binom{m}{n}}{\binom{m+\alpha}{n}} a_n
    \\
    (\text{Lambert}) \sum a
    &= \lim_{\varepsilon \rightarrow 0^+} \lim_{m \rightarrow \infty} \sum_{n=0}^m a_n \frac{\varepsilon(n+1) \mathrm{e}^{-\varepsilon(n+1)}}{1-\mathrm{e}^{-\varepsilon(n+1)}} \\
    (\text{Abelian means},\lambda) \sum a
    &= \lim_{\varepsilon \rightarrow 0^+} \lim_{m \rightarrow \infty} \sum_{n=0}^m a_n \exp(-\varepsilon \lambda_n)
    \\
    (\text{Borel},\alpha) \sum a
    &= \int_0^\infty \mathrm{e}^{-t} \lim_{m \rightarrow \infty} \sum_{n=0}^m \frac{a_n t^{n\alpha}}{(n\alpha)!} \,\mathrm{d}t
\end{align} Note that Abel and Lindelöf summation are Abelian means summation for $\lambda_n = n$ and $\lambda_n = n \log n$ , respectively. Do the following methods fall somewhere in the linear order above? \begin{align}
    (\text{Le Roy}) \sum a
    &= \lim_{z \rightarrow 1^-} \lim_{m \rightarrow \infty} \sum_{n=0}^m \frac{(zn)!}{n!} a_n
    \\
    (\text{Mittag-Leffler}) \sum a
    &= \lim_{\varepsilon \rightarrow 0} \lim_{m \rightarrow \infty} \sum_{n=0}^m \frac{a_n}{(\varepsilon n)!}
\end{align}","['summation-method', 'divergent-series', 'order-theory', 'sequences-and-series']"
3292558,Maximum of det(AX) as a function of Tr(AX),"Let $A$ = $\begin{pmatrix}
3&0&1\\
-1&2&-1\\
-2&-2&1
\end{pmatrix}$ and $X$ square matrix of order 3 diagonalizable and meets $AX=XA$ . When $Tr(AX) = d$ , I need to find the maximum of $det(AX)$ as a function of $d$ . All eigenvalues of $X$ are positive. What I have so far : I know that $Tr(AX) = \sum_k{\lambda_k}$ and $Det(AX) = \prod_k{\lambda_k}$ with $\lambda_k$ eigenvalues of $AX$ . So to maximize $Det(AX)$ I can maximize $Ln(Det(AX)) = \sum_k{Ln(\lambda_k)}$ . Therefore I have $\dfrac{\partial Ln(Det(AX))}{\partial \lambda_k} = \dfrac{1}{\lambda_k}$ . But I don't know how to continue.","['matrices', 'diagonalization', 'determinant']"
3292569,Is it possible to solve this second order autonomous differential equation?,"$$x''(t) = \frac{1}{x^2(t)}$$ I'm interested in this differential equation because it mimics the motion of an object subject to gravity. The solution of this differential equation will be an algebraic expression of the position  of such an object, which would be useful.",['ordinary-differential-equations']
3292575,How to analyse the smallest eigenvalue of this linear ODE?,"I am trying to solve the eigensystem of a 1st-order linear ODE system in the region $(-\infty,\infty)$ and with Dirichlet boundary condition at the infinities \begin{align}
-\mathrm{i} u'(x) +f^*(x) v(x) &= \lambda u(x) \\
f(x)u(x) + \mathrm{i} v'(x) &= \lambda v(x)
\end{align} where $f(x)$ is a complex-valued function mainly varying around $x=0$ where its norm decreases from $1$ to $1-\delta$ and goes back and its phase varies from $0$ to $\phi$ and $\delta\leq1,\phi\leq2\pi$ . $f^*(x)$ is its complex conjugate. For example, we can have two forms of $f(x)$ (using tanh or Cauchy distribution) of the similar profile $$
f(x)= \left(1-\delta\frac{\tanh(x/a+1)-\tanh(x/a-1)}{2\tanh{1}} \right) \exp{ \left[\mathrm{i}\phi\frac{\tanh(x/a)}{2} \right]}\\
f(x)= \left(1-\delta\frac{a^2}{x^2+a^2} \right) \exp{\left[\mathrm{i}\phi\frac{\tanh(x/a)}{2} \right]}
$$ where $a$ controls the width of the region in which $f(x)$ varies quickly. I tried reducing it to a 2nd-order ODE. But it messes up the eigenstructure $$v''-\frac{f'}{f}v'+(\lambda^2-|f|^2-\mathrm{i}\frac{f'}{f}\lambda)v=0.$$ I have no idea if any of the two cases can be solved analytically. If possible, it would be the best. It is known that the system will have a few (at least one) discrete real eigenvalues in $(-1,1)$ if $\delta,\phi$ are not too small and the eigenfunction is more or less localized around $x=0$ . Outside $(-1,1)$ , there will be a continuous spectrum. I am interested in the eigenvalue $\lambda_0$ closest to $0$ only. If one cannot solve the system, is it possible to (roughly) understand how $\lambda_0(a,\delta,\phi)$ behaves to some extent? Perhaps some variation trend or even more. E.g., $\lambda_0$ monotonically increases with $\delta$ or something like this.","['ordinary-differential-equations', 'eigenvalues-eigenvectors', 'sturm-liouville', 'eigenfunctions', 'boundary-value-problem']"
3292625,"Is there a characterization of groups with the property $\forall N\unlhd G,\:\exists H\leq G\text{ s.t. }H\cong G/N$?","A common mistake for beginning group theory students is the belief that a quotient of a group $G$ is necessarily isomorphic to a subgroup of $G$ .  Is there a characterization of the groups in which this property holds? If this question is too broad, I might ask if such a characterization exists for $p$ -groups. History : I originally posed the opposite question, regarding groups for which $\exists N\unlhd G\,:\, \not\exists H \unlhd G\, \text{  s.t. } H \cong G/N$ , and crossposted this to MO .  I received an answer there to the (now omitted) peripheral question about probability, which shows that most finite groups probably have this property.  After this, I changed the question to its current state, as this smaller collection of groups is more likely to be characterizable.","['finite-groups', 'group-cohomology', 'combinatorics', 'p-groups', 'group-theory']"
3292680,Merging two functions,So I have two fuctions like this :- $f(x) = (x/5)^2$ and $g(x) = \sqrt{(x/5)}$ and a third fuction as a combination of both $ h(x) =  \Biggl[ { }^{ x\; \lt \; 5 : \; f(x) }_{ x \;\ge \; 5: \; g(x)}\Biggr] $ When I put $x =5$ in the first function I get $f(5) = 1$ and in the second one I get $g(5) = 1\;$ . That means h(x) is countinous at $x =5$ is there any way I can converge $h(x)$ into a single function??,['functions']
3292683,Is $100$ the only square number of the form $a^b+b^a$?,"Conjecture: $100$ is the only square number of the form $a^b+b^a$ for integers $b>a>1$ . In other words, $(a,b)=(2,6)$ is the only solution. Can we prove/disprove this? Observations: The solution mentioned should not come as a surprise, since $2^6+6^2=8^2+6^2=10^2$ is a (non-primitive) Pythagorean triple. It is possible to show that $2^b+b^2$ has no other solutions. See Remark 1. In the general case where $a$ is a power of $2$ ; that is, $a=2^d$ for some positive integer $d$ , a similar approach can be followed. See Remark 2. We can eliminate some values of $b$ when $a=5^r,6^r$ , since no matter the value of $r$ , we have $a\equiv5,6\pmod{10}$ respectively. PARI/GP code: If the conjecture is true it should only ever print 2 6 . sqfun(a,b)={for(i=2,a,for(j=2,b,if(issquare(i^j+j^i)==1,print(i,"" "",j))));} Remark 1: Suppose that there is a positive integer $b$ that admits $2^b+b^2=t^2$ for some integer $t$ . Then we can write the equation as $$2^b=(t+b)(t-b)\implies\begin{cases}t+b=2^c\\t-b=2^{b-c}\end{cases}$$ for some positive integer $c>\dfrac b2$ . Subtracting the two equations yields $$2b=2^c-2^{b-c}\implies b=2^{b-c-1}(2^{2c-b}-1).$$ If $b$ is odd, it cannot have a factor of $2$ , forcing $b-c-1=0\implies t=b+2$ and substituting gives $2^b+b^2=(b+2)^2$ , or $2^b=4(b+1)$ . No solutions exist. If $b$ is even, then $b=2k$ for some positive integer $k$ , so we must have $$\begin{cases}2^k=s(m^2-n^2)\\2k=2mns\end{cases}$$ for some integers $m,n,s$ , so that $2^{mns}=s(m^2-n^2)$ . Without loss of generality, let $m>n>0$ and $s>0$ . [Servaes: If $mns\ge4$ then $2^{mns}\geq(mns)^2\geq sm^2> s(m^2-n^2)$ , so the only solutions with even $b$ are $b=4,6$ , and the first case does not yield a square.] Remark 2: If $b$ is odd, it boils down to the equation $$2^{db}=4\left(b^{2^{d-1}}+1\right)\implies 2^{db-2}-1=b^{2^{d-1}}.$$ [Haran: For $db-2>1$ , the LHS is congruent to $3\pmod4$ , and since the RHS is a square for $d>1$ , we reach a contradiction unless \begin{cases}d=1\implies a=2\quad\text{case covered above}\\db-2=1\implies1=b^{2^{d-1}}\implies 2^{d-1}=0\end{cases} which is impossible.] If $b$ is even, then $b=2k$ for some positive integer $k$ , and the Pythagorean triplet forces $$\begin{cases}2^{dk}=s(m^2-n^2)\\(2k)^{2^{d-1}}=2mns.\end{cases}$$ [Servaes: From the first equation, all three factors on the RHS are powers of two, so $$\begin{cases}m+n=2^u\\m-n=2^v\end{cases}\implies\begin{cases}m=2^{v-1}(2^{u-v}+1)\\n=2^{v-1}(2^{u-v}-1)\end{cases}$$ with $u>v>0$ . Since $m$ and $n$ are coprime, we have $v=1$ . Plugging this into the first equation yields $$2^{dk}=s(m-n)(m+n)=2^{u+1}s\implies s=2^{dk-u-1}.$$ Substituting this into the second equation yields $$(2k)^{2^{d-1}}=2mns=2(2^{u-1}+1)(2^{u-1}-1)s=(2^{2u-2}-1)2^{dk-u}$$ which is impossible; if we let $k=2^w\ell$ with $\ell$ odd then this implies $\ell^{2^{d-1}}=2^{2u-2}-1$ which by Catalan's conjecture/Mihailescu's theorem is impossible if $d>1$ . Note that $u>v$ hence $u\geq2$ .]","['conjectures', 'modular-arithmetic', 'number-theory', 'pythagorean-triples', 'square-numbers']"
3292690,"Relationship between $S(G)$, $\text{Aut}(G)$","Let $G$ be a nontrivial group, denote $\text{Aut}(G)$ the group of all its automorphisms of $G$ and denote $S(G)$ the symmetric group on $G$ , e.g. the set of all bijections $f:G\rightarrow G$ . I would be interested, whether $\text{Aut}(G)$ and $S(G)$ can ever be isomorphic as a groups. For a finite case, we can make the observation, that any permutation $f\in S(G)$ not fixing the identity cannot be automorphism, so in the finite case $S(G)$ and $\text{Aut}(G)$ aren't even equinumerous. Could someone provide a rigorous argument for the infinite case? It seems like it is in fact impossible to have these two isomorphic as a groups, but can they atleast have the same cardinality? We know that if $|G|=\kappa$ then $|S(G)|=2^\kappa$ . E: Adding some more ideas, someone could use: Denote $S_{fix}(G)$ the set of permutations of $G$ that fix the identity element $e\in G$ . Certainly we get $$
\text{Aut}(G)\preceq S_{fix}(G)\preceq S(G)
$$ If we can show that $S_{fix}(G)$ and $S(G)$ aren't equinumerous, then we are done proving that cardinalities cannot ever be equal. So, the cardinality problem is solved, now can we show that $\text{Aut}(G)$ and $S(G)$ cannot be isomorphic in the infinite case (or construct a counterexample?).","['permutations', 'group-theory', 'automorphism-group']"
3292699,"Prove that $\iint_S \vec{r}\cdot \vec{n}\,\mathrm{d}S=3 V(A)$","Let $S$ be a closed regular surface and $\vec{n}$ a vector field of unit normal vectors to the surface. Prove that the flux of the vector field $\vec{F}=\vec{r}$ is equal to $3\, V(A),$ where $V(A)$ is the volume of the interior $A$ of $S$ . I am looking for a proof that $\displaystyle \iint_S \vec{r}\cdot \vec{n}\,\mathrm{d}S= 3 V(A)$ , without use of Gauss divergence theorem. So far I can say that $$\iint_S \vec{r}\cdot \vec{n}\,\mathrm{d}S=\iint_D (\vec{r},\vec{r}_u,\vec{r}_v)\,\mathrm{d}u\,\mathrm{d}v,$$ where $(\vec{r},\vec{r}_u,\vec{r}_v)$ stands for the triple product of $\vec{r},\,\vec{r}_u,\,\vec{r}_v$ . Any ideas are welcomed. Thanks in advance for the help.","['multivariable-calculus', 'multiple-integral', 'surface-integrals']"
3292715,"$\{\sqrt[3]{x}| x\in \mathbb{Q}\}$ and $\{x\in \mathbb{Q}|\sqrt[3]{x} \}$, what is the difference? [closed]",Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 4 years ago . Improve this question Consider two following sets: $$A = \{\sqrt[3]{x}\mid x\in \mathbb{Q}\}$$ $$B = \{x\in \mathbb{Q}\mid \sqrt[3]{x} \}$$ What is the difference between the two sets?,['elementary-set-theory']
3292782,How do I define this subset using mathematical notation?,"Assume $P = \{2, 3, 5, 7, 11, 13, 17, 19, 23,....\}$ or in another words, P is the set consisting of all prime numbers. Now, suppose we want to form the set $S$ , which is subset of $P$ ,and  whose elements are the first 100 prime numbers. How do I define subset S using mathematical notation? My two attempts were: $S = \{x \in P \mid x ≤ m\}$ (where m is the 100th prime number) This method will only work when we know the exact value of m. $S = \{x_{i} \in P \mid  1 ≤ i ≤ 100\}$ (I believe this method is also incorrect, as sets do not support indexing) So what will be the correct way of defining subset $S$ ?",['elementary-set-theory']
3292893,Finding the solution to $xy'' +2y' +xy=0$ around $x_{0}=0$using the method of Frobenius.,"We know that the solution of this ODE is like: $$ y=\sum_{n=0}^{\infty}C_nx^{n+r}$$ Them derivative $y$ and $y'$ . $$y'=\sum_{n=0}^{\infty}(n+r)C_nx^{n+r-1}$$ $$y''=\sum_{n=0}^{\infty}(n+r-1)(n+r)C_nx^{n+r-2}$$ Replace $y$ , $y'$ and $y''$ in the ODE. $$\sum_{n=0}^{\infty}(n+r-1)(n+r)C_nx^{n+r-1}+\sum_{n=0}^{\infty}2(n+r)C_nx^{n+r-1} +\sum_{n=0}^{\infty}C_nx^{n+r+1}=0 $$ Now in the first and second summations if $k=n-1$ and in the third summation if $k=n+1$ . We have: $$\sum_{k=-1}^{\infty}(k+r)(k+r+1)C_{k+1}x^{k+r}+\sum_{n=-1}^{\infty}2(k+r+1)C_{k+1}x^{k+r} +\sum_{n=1}^{\infty}C_{k-1}x^{k+r}=0 $$ Now I separed the $k=-1$ and $k=0$ in the first and second summantions. $$r(r-1)C_0x^{r-1}+(r+1)(r)C_1x^{r} + 2rC_0x^{r-1} +2(r+1)C_1x^r + \sum_{k=1}^{\infty}[(k+r)(k+r+1)C_{k+1}x^{k+r}+2(k+r+1)C_{k+1}x^{k+r}+C_{k-1}x^{k+r}]=0$$ After that I equalized the right side with the left and I have this 2 equation to find $r$ : $$(r^2 +r)C_0=0$$ and $$(r^2+3r+2)C_{1}=0$$ If you solve the quadratic equations you have: $$r_1=0$$ $$r_{2,3}=-1$$ $$r_4=-2$$ And that's all that I did please help me.","['frobenius-method', 'ordinary-differential-equations']"
3292918,Covering a set with $N$ balls of common minimal(!) radius (Existence of such a covering),"Let $X$ be a Banach space, and denote by $B_r (x)$ the closed ball of radius $r > 0$ around $x \in X$ . Furthermore, let $A \subset X$ be compact and $N \in \Bbb{N}$ .
I am interested in ""optimally"" covering $A$ by $N$ balls, i.e,. with as small radius as possible.
More precisely, define $$
  r_0
  := \inf \Big\{
            r > 0
            \colon
            \exists \, x_1,\dots,x_N \in X \text{ such that } A \subset \bigcup_{i=1}^N B_r (x_i)
          \Big\},
$$ and assume that $r_0 > 0$ . I would like to know whether there necessarily exist $x_1,\dots,x_N \in X$ such that $A \subset \bigcup_{i=1}^N B_{r_0} (x_i)$ .
  In other words, I would like to know if the infimum above is actually a minimum. Note I am taking the $x_i$ from the ""surrounding"" space $X$ , not from the compact set $A$ . I can prove the claim in case that $X$ is reflexive (even only assuming that $A$ is bounded),
but I am not sure whether it is true for more general Banach spaces.
I will give my proof for the reflexive case below, in case one can either generalize it,
or use it to get an idea for a counterexample. Proof for the reflexive case: Choose a sequence $r_n \to r_0$ such that for each $n$ there are $x_1^n,\dots,x_N^n \subset X$ satisfying $A \subset \bigcup_{i=1}^N B_{r_n}(x_i^n)$ .
If $B_{r_n} (x_i^n) \cap A = \emptyset$ for some $i,n$ , replace $x_i^n$ by zero.
Note that this retains the property $A \subset \bigcup_{i=1}^N B_{r_n}(x_i^n)$ . Since $A$ and the sequence $(r_n)_{n}$ are bounded, there is $R > 0$ such that $\| x \| \leq R$ and $r_n \leq R$ for all $x \in A$ and $n \in \Bbb{N}$ :
There are now two cases for each $i,n$ :
1) There is some $x \in A \cap B_{r_n} (x_i^n)$ ,
   and hence $\| x_i^n \| \leq \| x_i^n - x \| + \| x \| \leq r_n + R \leq 2R$ .
2) There is no $x \in A \cap B_{r_n} (x_i^n)$ , and hence $x_i^n$ , whence $\| x_i^n \| \leq 2R$ . Therefore, each of the sequences $(x_i^n)_{n \in \Bbb{N}} \subset X$ is bounded.
Since $X$ is assumed to be reflexive, we can choose a common subsequence
(which I will ignore in the notation below) such that $x_i^n \to x_i$ weakly for all $i = 1,\dots,N$ . Now, let $x \in A$ be arbitrary.
For each $n \in \Bbb{N}$ , there is $i_n \in \{1,\dots,N\}$ satisfying $\| x - x_i^n \| \leq r_n$ .
Next, there is $\ell \in \{1,\dots,N\}$ such that $i_n = \ell$ for infinitely many $n \in \Bbb{N}$ ,
say for $n = n_m$ with $n_m \to \infty$ .
Since $x - x_i^{n_m} \to x - x_i$ weakly and since the norm is lower semicontinuous with respect
to weak convergence, we see that $\| x - x_\ell \| \leq \liminf_{m \to \infty} \| x - x_i^{n_m} \| \leq \liminf_{m \to \infty} r_{n_m} = r_0$ .
Since this holds for any $x \in A$ , we get $A \subset \bigcup_{\ell=1}^N B_{r_0} (x_\ell)$ ,
as desired.","['banach-spaces', 'reflexive-space', 'geometry', 'functional-analysis', 'optimization']"
3292951,Limit Of A Sequence Involving Factorial Functions,"Find the limit of the sequence $$\frac{c^n}{n!^{\frac{1}{k}}}$$ , $(k>0, c>0)$ Now when $0<c<1$ we get $$0<\frac{c^n}{n!^{\frac{1}{k}}}< \frac{1}{n!^{\frac{1}{k}}}$$ So by Sandwich Theorem we get the limit of the sequenc equal to $0$ But when $c>1$ i do not understand how to move?",['limits']
3293001,Representation of Tangent function on unit circle,I have found a interesting website in Google. It represents tangent function of a particular angle as the length of a tangent from a point that is subtending the angle.I thought it is really an amazing result. But I can't digest it because I don't know proof.I had tried many times but failed repeatedly.Help me proving this fact,['trigonometry']
3293038,"Conjecture: ""For every prime $k$ there will be at least one prime of the form $n! \pm k$"" true?","Using PARI/GP, I searched for primes of the form $n!\pm k$ where $k \ne 2$ is prime and $n\in \Bbb{N}$ . With the help of user Peter, we covered a range of $k \le 10^7$ and couldn't find a prime $k$ for which there is no prime of either form $n!+k$ or $n!-k$ . Observations: $(1)$ When $n \ge k$ , $n! \pm k$ cannot be prime as $k$ will be a factor of $n! \pm k$ . This means that there are a finite number of primes of the form $n! \pm k$ for each $k$ . $(2)$ As $k$ increases, the number of primes of the form $n!\pm k$ also seems to increase. The reason for this is that as $k$ increases, the number of $n$ for which $n!\pm k$ may be prime also increases as all $n \lt k$ may give prime $n!\pm k$ . For those who want to carry forward the search here is the PARI/GP code: for(k=1, 10^4,b=0; for(n=1, prime(k), if(ispseudoprime(n!+prime(k))==1, b=b+1)); print([prime(k), b])) The first column of output will give the $k$ and the second column will the number of times $n!+k$ is prime for that given $k$ . Here are the first few lines of output: [2, 1]
[3, 1]
[5, 3]
[7, 4]
[11, 5]
[13, 3]
[17, 6]
[19, 7] For rest of the output computed till now click here . Question: Is there any prime $k\ne 2$ for which there are no primes of the form $n!\pm k$ ? Extra: I decided to test some other factorial-like functions and they gave surprisingly similar results. For any prime $k$ , there is at least one prime of the form: $(1)$ $p_n$ # $\pm k$ , where $p_n$ # is the primorial function and $k\gt 5$ . This was verified for the range of $k\le 10^7$ . $(2)$ $n!!\pm k$ , where $n!!$ is the double factorial and $k\gt 2$ . This was verified for the range $k\le 10^5$ . $(3)$ $2n!!\pm k$ where $n$ can only odd and $k\gt 5$ . This was verified for the range $k\le 10^5$ . I find it strange that a function that grows relatively slow like $2^n+2131$ doesn't have a single prime even for $n\le 10^4$ , but a fast-growing, factorial-like function like $n!+prime(k)$ has primes for every single $k$ even after being restricted by $n \lt k$ .","['number-theory', 'conjectures', 'elementary-number-theory', 'prime-numbers']"
3293047,Compactness and dimensionality.,"Compactness is indeed a central theme in analysis and general topology. Since the first courses in these subjects, we are exposed to criteria for compactness, such as the Heine-Borel Theorem for subspaces of $\mathbb{R}^n$ . Then we grow up to discover, in our first course of functional analysis, that things do not work so desirably in the case of infinite dimensional normed spaces, as through Riesz Lemma one shows that the unit ball is not compact in an infinite dimensional vector space . Much in the same line of thought, studying topological vector spaces, hence vector spaces endowed with a weaker notion of distance, we have another theorem by Riesz stating that a topological vector space is finite dimensional if and only if it is locally compact . To recover compactness in infinite dimensional spaces we introduce weak topologies and weak compactness , defined through the topological dual of a space. Finally in the general context of topological spaces one can proove finite product of compacta compact without the axiom of choice , while the famous Tychonoff theorem relative to the infinite case is actually equivalent to it (or better to a weaker version). Moreover, when one increases the dimension of a space, most naturally does it through product we have $\mathbb{R};\ \mathbb{R}^n=\mathbb{R}^{n-1}\times\mathbb{R}...$ I have highlighted words much in a brainstorming fashion, to show the relations I know between compactness and dimensionality, intended in a broad sense. Compactness do recalls, in its definition, a notion of dimensionality, in the sense that if a space is compact, we are always able to extract a finite object, a cover, from an arbitrary one. What I would like to know is: Is there more to this intuition? Can we formalize it? Can we build a notion of dimensionality directly from compactness, in a way which is somehow consistent with the usual one, in the case of vector spaces? Is there a more general relation between compactness and dimensionality, with compactness being a 'signature' for a notion of finite dimensionality? Thanks in advance","['topological-vector-spaces', 'functional-analysis', 'general-topology', 'soft-question', 'compactness']"
3293076,How to find the definite integral of cube of a function whose definite integral is known?,"I'm given that the definite integration of some function is equal to $0$ . Now I've to find maximum value of definite integration of cube of same function between same bounds. How to do it? Please explain. I'm writing it in mathematical form. $$\int^1 _0 f(x)=0:-1\le f(x)\le1$$ Find the maximum value of $$\int^1_0 [f(x)]^3$$ Seriously I have no clue to do the question. I tried to draw the graph(experimental) where I kept areas in 1st, 4th quadrants equal so that the integration is zero. Now I'm trying but draw the graph of cubic of same graph. And maximize the area in the first quadrant. I'm thinking about to do it using some graphical calculator and have some visualization of the problem but obviously I have no clue how to do that even. Thanks for solving the question or giving it time.","['integration', 'calculus', 'functions', 'definite-integrals']"
3293078,Is Lax-Miligram theorem a generalization of Riesz representation?,"Let $H$ a hilbert space with inner product $\left<.,.\right>$ . We denote $\|\cdot \|$ the norm induced by the inner product. Lax-miligram tels us that there is a one-to-one correspondance between Continuous and elliptic bilinear form $a:H\times H\to \mathbb R$ and continuous linear functional $L:H\to \mathbb R$ . I.e. that if $a$ is continuous (i.e. $a(u,v)\leq K\|u\|\|v\|$ ), elliptic (i.e. $a(u,u)\geq C\|u\|^2$ ) and if $L$ is a $L:H\to \mathbb R$ is continuous an linear, then there is a unique $u\in H$ s.t. for all $v\in H$ , $$a(u,v)=L(v).$$ Is this a sort of generalization of Riezs representation theorem ? Because it looks very similar, but a bit more general.",['functional-analysis']
3293097,Why do mean value theorems have open interval for differentiablity while closed for continuity? [duplicate],"This question already has answers here : Why does the Mean Value Theorem require a closed interval for continuity and an open interval for differentiability? (2 answers) Closed 4 years ago . For mean value theorems like Lagrange's and Rolle's, we have the following conditions: For applying mean value theorem to any function $f(x)$ for the domain $[a,b]$ , it should be (1) continuous in $[a,b]$ (2) differentiable in $(a,b)$ So why is it that for the criteria of differentiablity, we have the open interval ?? Is it possible for a function differentiable in $(a,b)$ and continuous in $[a,b]$ to be non- differentiable at the end points? Also why is the first statement needed ?? Doesn't the second statement of differentiablity also mean that the function is continuous ??
I'm not very experienced in calculus and still in high-school,  so it might be something too obvious I'm missing , please help :)","['calculus', 'derivatives']"
3293101,Residue at infinity without singularity,"I'm sorry if this question is a duplicate but I really have not found anything online that says this and I need a confirmation. My problem is the following: for a function on the complex plane to have a residue at a point there must be a singularity. This because the residue is defined to be the coefficient $a_{-1}$ of the Laurent series and therefore if the Laurent series has no negative terms there is no residue (or the residue is zero). However the situation on the Riemann sphere is different, that is to say it seems to me that the point at infinity might have a residue even without being a singularity. Take for example $f(z) = \frac{1}{z}$ . A simple calculation (using the definition) shows that the residue at infinity is -1. However, this function has a 0 at infinity and not a singularity. This can be seen both by taking the limit and by using the fact that a function $f$ has a pole at infinity iff $f(\frac{1}{z})$ has a pole at 0 and this is not the case. Moreover, the function has to have a nonzero residue at infinity because the sum of residues of a meromorphic function on the Rieman sphere must be zero. This is counterintuitive to me but I'm quite convinced this is how it is. Can someone confirm this to me (that the point at infinity is radically different from other points)? Moreover, if this is the case, is there any profound reason why the point at infinity behaves so differently?","['complex-analysis', 'residue-calculus']"
3293112,"Relationship between GCD, LCM and the Riemann Zeta function","Let $\zeta(s)$ be the Riemann zeta function. I observed that as for large $n$ , as $s$ increased, $$
\frac{1}{n}\sum_{k = 1}^n\sum_{i = 1}^{k} \bigg(\frac{\gcd(k,i)}{\text{lcm}(k,i)}\bigg)^s \approx \zeta(s+1) 
$$ or equivalently $$
\frac{1}{n}\sum_{k = 1}^n\sum_{i = 1}^{k} \bigg(\frac{\gcd(k,i)^2}{ki}\bigg)^s \approx \zeta(s+1) 
$$ A few values of $s$ , LHS and the RHS are given below $$(3,1.221,1.202)$$ $$(4,1.084,1.0823)$$ $$(5,1.0372,1.0369)$$ $$(6,1.01737,1.01734)$$ $$(7,1.00835,1.00834)$$ $$(9,1.00494,1.00494)$$ $$(19,1.0000009539,1.0000009539)$$ Question : Is the LHS asymptotic to $\zeta(s+1)$ ? Update : I have posted this in MO since it was open in MSE.","['summation', 'number-theory', 'elementary-number-theory', 'analytic-number-theory', 'prime-numbers']"
3293130,Presentations of discrete subgroups of $\textrm{PGL}_2(\mathbb{R})$,"It is well known that geometrically finite Fuchsian groups, or finitely generated discrete subgroups of $\textrm{PSL}_2(\mathbb{R})$ can be classified up to isomorphism by their signature $[g,s;m_1,\dots,m_r]$ which define a presentation $\Gamma = \left\langle a_1,b_1,\dots,a_g,b_g,c_1\dots,c_s,d_1,\dots,d_r\ |\ d_1^{m_1}=\dots=d_r^{m_r}=\prod_{i=1}^g[a_i,b_i]\prod_{j=1}^{r}d_j\prod_{k=1}^sc_k=1 \right\rangle.$ Does there exist a similar presentation for discrete subgroups of $\textrm{PGL}_2(\mathbb{R})$ ?","['geometric-group-theory', 'group-theory', 'lattices-in-lie-groups', 'low-dimensional-topology']"
3293237,Interpretation Reflection principle,"The reflection principle says that for the Markov process $(B_t,\mathcal{F}_t,P_x)$ associated with Brownian Motion it is satisfied that $P_0(\text{max}_{s\leq t} B_s \geq a) =2P_0(B_t\geq a)$ What is the interpretation behind it? 
Why is it called ""Reflection Principle""? Is there something that gets reflected?","['reflection', 'markov-process', 'geometric-interpretation', 'brownian-motion', 'probability-theory']"
3293273,Shortest path to paint a sphere with a large square or circular brush,"Survey telescopes in space need to ""paint"" the celestial sphere with their apertures in order to cover it without wasting too much time. Screen shots below from two videos give some idea. These are certainly not optimal in a mathematical sense though they are probably optimal in terms of spacecraft management and scientific return. My question is about the mathematics behind painting a sphere by moving a finite size ""brush"" over the surface with the shortest stroke length. I think that if $\theta(t)$ and $\phi(t)$ describe the stroke for $0 \le t \le 1$ then the path length to be minimized can be expressed as: $$\int_0^1 dt \sqrt{ \left(\frac{d \theta}{dt} \right)^2 +  \left(\sin \theta \frac{d \phi}{dt} \right)^2}$$ but that should be checked. For example, if the brush is $\pi/10$ radians wide, you can perform 10 great circles around lines of latitude, stepping by $\pi/10$ in longitude each time. The total path length is then $20 \pi$ for a circular or square brush of width $\pi/10$ . But there is certainly a more complex spiral-like pattern starting at one pole and ending at the opposite pole that would involve substantially less overpainting. Has this problem been solved, or even addressed? Does this problem have a better name than ""Shortest path to paint a sphere with a large square or circular brush""? example videos are pretty interesting, especially TESS' orbital maneuvering after 05:20 TESS, from video Spektr-RG/eROSITA  from video","['spheres', 'geometry', 'solid-geometry', 'calculus', 'optimization']"
3293274,Prove $ \int_0^1 \frac{\ln^a(1-x)\ln(1+x)}{x}dx=(-1)^a a! \sum_{n=1}^\infty\frac{H_n^{(a+1)}}{n2^n}$,"Nice little generalization: $$\int_0^1 \frac{\ln^a(1-x)\ln(1+x)}{x}dx=(-1)^a a! \sum_{n=1}^\infty\frac{H_n^{(a+1)}}{n2^n},\quad a=0,1,2,...$$ The point of this post is to save us some calculations in our solutions and here is my proof: \begin{align}
I&=\int_0^1 \frac{\ln^a(1-x)\ln(1+x)}{x}\ dx\overset{x\ \mapsto\ 1-x}{=}\int_0^1 \frac{\ln^ax\ln(2-x)}{1-x}\ dx\\
&=\ln2\int_0^1 \frac{\ln^ax}{1-x}\ dx+\int_0^1 \frac{\ln^ax\ln(1-x/2)}{1-x}\ dx\\
&=\ln2((-1)^aa!\zeta(a+1))-\sum_{n=1}^\infty\frac1{n2^n}\int_0^1\frac{x^n\ln^ax}{1-x}\ dx\\
&=\ln2((-1)^aa!\zeta(a+1))-\sum_{n=1}^\infty\frac{(-1)^aa!\left(\zeta(a+1)-H_n^{(a+1)}\right)}{n2^n}\\
&=\ln2((-1)^aa!\zeta(a+1))-\ln2((-1)^aa!\zeta(a+1))+(-1)^aa!\sum_{n=1}^\infty\frac{H_n^{(a+1)}}{n2^n}\\
&=(-1)^aa!\sum_{n=1}^\infty\frac{H_n^{(a+1)}}{n2^n}
\end{align} I came up with such generalization while I was working on some nice harmonic series. Other approaches are appreciated. UPDATE : Here is another nice rule $$\int_0^1\frac{\ln^ax\ln(1+x)}{1-x}dx=(-1)^aa!\left(\ln2\zeta(a+1)+\sum_{n=1}^\infty\frac{(-1)^nH_n^{(a+1)}}{n}\right)$$ and we can prove it following the same approach above: \begin{align}
\int_0^1\frac{\ln^ax\ln(1+x)}{1-x}dx&=-\sum_{n=1}^\infty\frac{(-1)^n}{n}\int_0^1\frac{x^a\ln^nx}{1-x}dx\\
&=-\sum_{n=1}^\infty\frac{(-1)^n}{n}\left[(-1)^aa!\left(\zeta(a+1)-H_n^{(4)}\right)\right]\\
&=-(-1)^aa!\left(\zeta(a+1)\sum_{n=1}^\infty\frac{(-1)^n}{n}-\sum_{n=1}^\infty\frac{(-1)^nH_n^{(a+1)}}{n}\right)\\
&=-(-1)^aa!\left(-\ln2\zeta(a+1)-\sum_{n=1}^\infty\frac{(-1)^nH_n^{(a+1)}}{n}\right)\\
&=(-1)^aa!\left(\ln2\zeta(a+1)+\sum_{n=1}^\infty\frac{(-1)^nH_n^{(a+1)}}{n}\right)
\end{align} Or $$\int_0^1\frac{\ln^ax\ln\left(\frac{1+x}{2}\right)}{1-x}=(-1)^aa!\sum_{n=1}^\infty\frac{(-1)^nH_n^{(a+1)}}{n}$$","['integration', 'harmonic-numbers', 'calculus', 'sequences-and-series']"
3293298,Which applications parallel transport have?,"I am looking for some applications of parallel transport. I have seen that, for example, one can find connection by using parallel transport. Which other application the parallel transport might have that make it interesting to study or in other words Why we do parallel transport of a vector along a curve?","['riemannian-geometry', 'differential-geometry']"
3293320,Solution to $\frac{d^n y}{dx^n} = y$ for integer $n$,"In short, my question is about the solution of $\frac{d^n y}{dx^n} = y$ for positive integer $n$ , where $y$ is real. For example, if $n = 2$ , the solution is $y = c_1e^x+c_2e^{-x}$ . The work that I and my old friend, WolframAlpha, made on this is such: Assume that a solution is proportional to $e^{\lambda x}$ , with $\lambda$ a constant. Substituting that into the original equation finds $$\frac{d^n}{dx^n} (e^{\lambda x}) - e^{\lambda x} = 0 \to \lambda^n e^{\lambda x}- e^{\lambda x} = 0$$ This can be factored as $$(\lambda^n -1)e^{\lambda x} = 0$$ Since $e^{\lambda x}$ cannot equal $0$ , $\lambda^n -1 = 0$ . Solving this for $\lambda$ is equivalent to finding the group of the $n$ th roots of unity, so $$\lambda_k = e^{2k\pi i/n}, k \in \{1, 2, ..., n\}$$ The overall solution is then $$y = \sum_{k=1}^{n} c_k e^{\lambda_k x}$$ It seems like we are done. However, this can in fact be written somewhat differently (I'm cautious about calling it simplified), as the sums of $e^{px}\cos(qx)$ and $e^{px}\sin(qx)$ . For example, if $n = 3$ , $$y = c_1 e^x+c_2 e^{-x/2} \cos\left( \frac{x\sqrt{3}}{2}\right) + c_3 e^{-x/2} \sin\left( \frac{x\sqrt{3}}{2}\right)$$ How can I get from the first representation of $y$ to the second one for higher $n$ ? For anyone interested, the Mathematica code for finding $y$ is DSolve[D[y[x], {x, 5}] == y[x], y[x], x]","['roots-of-unity', 'ordinary-differential-equations']"
3293328,Computing $\int_0^1\frac{\ln^3(1-x)\ln(1+x)}{x}dx$ or $\sum_{n=1}^\infty\frac{H_n^{(4)}}{n2^n}$,"Challenging Integral: \begin{align}
I=\int_0^1\frac{\ln^3(1-x)\ln(1+x)}{x}dx&=6\operatorname{Li}_5\left(\frac12\right)+6\ln2\operatorname{Li}_4\left(\frac12\right)-\frac{81}{16}\zeta(5)-\frac{21}{8}\zeta(2)\zeta(3)\\&\quad+\frac{21}8\ln^22\zeta(3)-\ln^32\zeta(2)+\frac15\ln^52
\end{align} I came across this integral while i was trying to calculate $\displaystyle\sum_{n=1}^\infty\frac{H_n^{(4)}}{n2^n}$ , proposed by Cornel on his FB page here , but he has not revealed his solution yet. The integral is related to the sum through the identity ( see here ): $$\int_0^1 \frac{\ln^a(1-x)\ln(1+x)}{x}dx=(-1)^a a! \sum_{n=1}^\infty\frac{H_n^{(a+1)}}{n2^n}$$ With $a=3$ , We get $\quad\displaystyle I=-6\sum_{n=1}^\infty\frac{H_n^{(4)}}{n2^n}\quad$ . The way I computed this integral is really long as it's based on values of tough alternating Euler sums which themselves long to calculate. I hope we can find other approaches that save us such tedious calculations. Any way, here is my approach: Using the identity from this solution : $\displaystyle\int_0^1 x^{n-1}\ln^3(1-x)\ dx=-\frac{H_n^3+3H_nH_n^{(2)}+2H_n^{(3)}}{n}$ Multiplying both sides by $\frac{(-1)^{n-1}}{n}$ then summing both sides from $n=1$ to $n=\infty$ , gives: \begin{align}
I&=\int_0^1\frac{\ln^3(1-x)}{x}\sum_{n=1}^\infty-\frac{(-x)^{n}}{n}dx=\int_0^1\frac{\ln^3(1-x)\ln(1+x)}{x}dx\\
&=\sum_{n=1}^\infty\frac{(-1)^nH_n^3}{n^2}+3\sum_{n=1}^\infty\frac{(-1)^nH_nH_n^{(2)}}{n^2}+2\sum_{n=1}^\infty\frac{(-1)^nH_n^{(3)}}{n^2}
\end{align} We have: \begin{align}
\sum_{n=1}^\infty\frac{(-1)^nH_n^3}{n^2}&=-6\operatorname{Li}_5\left(\frac12\right)-6\ln2\operatorname{Li}_4\left(\frac12\right)+\ln^32\zeta(2)-\frac{21}{8}\ln^22\zeta(3)\\&\quad+\frac{27}{16}\zeta(2)\zeta(3)+\frac94\zeta(5)-\frac15\ln^52
\end{align} \begin{align}
\sum_{n=1}^\infty\frac{(-1)^nH_nH_n^{(2)}}{n^2}&=4\operatorname{Li}_5\left(\frac12\right)+4\ln2\operatorname{Li}_4\left(\frac12\right)-\frac23\ln^32\zeta(2)+\frac74\ln^22\zeta(3)\\&\quad-\frac{15}{16}\zeta(2)\zeta(3)-\frac{23}8\zeta(5)+\frac2{15}\ln^52
\end{align} $$\sum_{n=1}^\infty\frac{(-1)^nH_n^{(3)}}{n^2}=\frac{21}{32}\zeta(5)-\frac34\zeta(2)\zeta(3)$$ The proof of the first and second sum can be found here and the third sum can be found here . By substituting these three sums,we get the closed form of $I$ . Thanks.","['integration', 'harmonic-numbers', 'polylogarithm', 'closed-form', 'sequences-and-series']"
3293345,Question about hodge star operation and basis orientation,"I was reading the book ""Differential forms and applications"" by M. Do Carmo. In his proof of the divergence theorem as a  corollary of Stokes theorem. He claims(without proof) the following Given $\omega$ a 1-form in $\mathbb{R}^3$ , and $\{e_1,e_2,N\}$ is a positive oriented basis with $N$ normal to $e_1$ and $e_2$ . Then $\star\omega(e_1,e_2)=\omega(N)$ Now, I can check this by straight-forward computation, but this quite unsatisfying, as it doesn't shed any light on why this is true. So, this is my question: What is the relation between the image of a k-form $\omega$ in a space $W$ and the image of $\star\omega$ in $W^{\bot}$ ? Furthermore, is it true that: Given a $\{
e_1,\cdots,e_n
\}$ an oriented basis(that is $\nu(e_1,\ldots ,e_n)=\mbox{det}(e_i)>0$ ) and a k-form $\omega$ . Is it true that, $\omega(e_1,\ldots,e_k)=\star
\omega(e_{k+1},\ldots,e_n)$ ? I've tried some cases and it seems to be true, however my calculations seem difficult to generalise to the general case. Any idea on whether this is true, an if it is, how to prove it?","['differential-forms', 'differential-geometry']"
3293355,"Purely Inseparable Morphism of Schemes (Ex. from Liu's ""AG & AC"")","My questions refer to Exercise 5.3.9 from  Liu's ""Algebraic Geometry"" (page 208): I have two questions: How to show in (a) that $K(Y) \to K(X)$ pure inseparable implies $f$ purely inseparable My considerations: As @Laurent Moret-Bailly stated in his comment below it is neccessary to assume that $X$ dominates $Y$ (otherwise the extension $K(X)/K(Y)$ don't make any sense since in such case this map in genereal would not exist). By definition $f: X \to Y$ is called purely inseparable if $f$ injective and if for every $x ∈ X$ , the extension of residue fields $k(f(x)) → k(x)$ is a purely inseparable extension. We obtain following diagram $$
\require{AMScd}
\begin{CD}
O_{Y,f(x)}  @>{}>> O_{X,x} \\
@VVV  @VVV  \\
K(Y)=O_{Y, \eta_Y} @>{}>> K(X)=O_{X, \eta_X}
\end{CD}
$$ By finiteness & purely separateness we have $K(X) = K(Y)[a^{1/n}]$ for appropriate $a \in K(Y)$ . The question is how this strucure can be ""transfered""  to $O_{Y,f(x)}/m_{f(x)}=k(f(x)) \to k(x)= O_{X,x}/m_x$ ? Honestly, I have no idea.","['algebraic-geometry', 'schemes']"
3293359,How do we know $\sin$ and $\cos$ are the only solutions to $y'' = -y$?,"According to Wikipedia, one way of defining the sine and cosine functions is as the solutions to the differential equation $y'' = -y$ . How do we know that sin and cos (and linear combinations of them, to include $y=e^{ix}$ ) are the only solutions to this equation? It seems like a clever combination of inverse polynomials or exponentials could do the same.","['trigonometry', 'ordinary-differential-equations']"
3293415,"Given $a,b,c$ positive numbers, is there a function $h$ such that $h(ax+b) = c \cdot h(x)$ for all $x>0$?","Given $a,b,c$ positive numbers, is there a function $h$ (no trivial) such that $$h(ax+b) = c\, h(x)$$ for all $x>0$ ?. I know that taking $h(x)= c^{\frac{x}{b}}$ makes $h(x+b) = c \, h(x)$ , and that taking $h(x)= c^{\frac{\ln(x)}{\ln(a)}}$ makes $h(ax)=c\,h(x)$ but i don't see how to combine both conditions. Any help will be appreciated","['functional-equations', 'real-analysis']"
3293423,Flaw in a proof of $\det AB=\det A\det B$?,"Since the elementary row operations, namely row exchanging, multiplying a scalar to a row, and subtracting a row from another row, doesn't affect to the result of the determinant, we only consider the upper triangular matrices. And for an upper triangular matrix $A$ , $\det A$ is just a product of its diagonal entries. And if we multiply two upper triangular matrices, $A,B$ , we have $$AB=\left[\begin{array}{}
a_{11}&\dots&\dots&\dots\\
0&a_{22}&\dots&\dots\\
0&0&\ddots& \vdots&\\
0&0&\dots&a_{nn}
\end{array}\right]\left[\begin{array}{}
b_{11}&\dots&\dots&\dots\\
0&b_{22}&\dots&\dots\\
0&0&\ddots& \vdots&\\
0&0&\dots&b_{nn}
\end{array}\right]\\
=\left[\begin{array}{}
a_{11}b_{11}&\dots&\dots&\dots\\
0&a_{22}b_{22}&\dots&\dots\\
0&0&\ddots& \vdots&\\
0&0&\dots&a_{nn}b_{nn}
\end{array}\right].$$ So $\det AB=\det A \det B.$ I feel this should prove the equality. Any flaw in this reasoning? EDIT: In fact, multiplying scalar to a row does affect to the result. May approaching this direction a dead end?","['matrices', 'determinant', 'proof-verification', 'linear-algebra']"
3293424,Does order matter when subtracting systems of linear equations?,"Let's say I have a simple system like so: \begin{cases}
    2x - y = 1\\
    x - y = 2\\
\end{cases} Why does it not matter what equation is being subtracted from the other when it comes to getting solutions. The answers are the same, irrespective of which equation is being subtracted from the other. Why does this work? My confusion stems from the fact that a-b is not the same as b-a.",['algebra-precalculus']
3293451,Problems with proof of $\omega_1=\bigcup\{X_\xi|\xi\in\omega_1\}$,"I have the proof of following lemma, which I do not really understand: Let $(X,<)$ be a well orderd uncountable set.
Let $\omega_1=\{\xi\in X|X_\xi\,\,\text{countable}\}$ and $X_\xi=\{\alpha\in X|\alpha <\xi\}$ Lemma: $\omega_1=\bigcup\{X_\xi|\xi\in\omega_1\}$ My main issue seems to be, that the elements of $\omega_1$ are elements of $X$ such that $X_\xi$ are countable, while the elemens of $\bigcup\{X_\xi|\xi\in\omega_1\}$ are countable sets. And I do not understand why we can 'compare' these sets in the first place. It somehow seems self-referential. Following proof is given: Is $\alpha <\xi\in\omega_1$ , we have $X_\alpha\subseteq X_\xi$ . So $X_\alpha$ is countable and it is $\alpha\in\omega_1$ . So we have $X_\alpha\subseteq\omega_1$ . Which proofs $\omega_1\supseteq\bigcup\{X_\xi|\xi\in\omega_1\}$ . And I do not understand this conclusion. 
I do not understand why both sets have compareable (the same) elements... For the other part: Is $\xi\in\omega_1$ then is $X_\xi$ countable. Then is $\xi^+\in\omega$ since $X_{\xi^+}=X_\xi\cup\{\xi\}$ is countable and $\xi\in X_{\xi^+}$ . Hence $\subseteq$ . I understand every detail of both proofs, but I do not understand why it shows what we desire... Can you give an explanation?
Thanks in advance.","['elementary-set-theory', 'proof-explanation', 'order-theory', 'ordinals']"
3293452,Surface Area of $n$-Dimensional Sphere with Multiple Hyperplanar Cuts,"Let $S^{n-1}\subset\mathbb{R}^n$ be the unit sphere, and $v_1, \cdots, v_m\in S^{n-1}$ be $n$ -dimensional unit vectors. Each of these vectors defines an $n-1$ dimensional hyperplane, which cuts $S^{n-1}$ in exactly half. This hyperplane is oriented by the vector $v_i$ , meaning it designates a set of exactly half of the points on the sphere; call this set $A_{v_i}$ . Now, let $$A=\bigcup_{1\leq i\leq m}A_{v_i}$$ What is the surface area of $A$ ? Or, equivalently, what portion of the total surface area of $S^{n-1}$ is contained in $A$ ? More importantly, how does one compute this directly from $v_1, \cdots, v_m$ ? Here are a few remarks that may be helpful. First, note that $A$ can be thought of as $A=\{v\in S^{n-1}\text{ | }\exists i\text{ with } v\cdot v_i\geq 0\}$ , since the half- $\mathbb{R}^n$ space which each vector $v_i$ defines is precisely equivalent to the set of all vectors which project non-negatively onto $v_i$ . Additionally, this question may be easier to answer with low values for $m$ ; straightforwardly, when $m=2$ , one can just look at the angle between the vectors to determine the answer, though I do not see how to extend this... I think that an even answer which treats cases for values of $m\leq 5$ , for example, would be interesting. Edit : It seems this question may be quite a bit harder than anticipated, as can be see here . However, as mentioned above, I still think that an explicit answer for the first few values of $m$ would be interesting. Let $|A|$ denote the measure of $A$ . When $m=2$ , the answer is simply $|A|=\frac{\pi-\cos^{-1}(v_1\cdot v_2)}{2\pi}$ . When $m=3$ , the problem comes down to computing the area of the resulting spherical triangle , though I am not sure about the details... I will accept an answer which treats such cases (with $m$ up to 4 or 5, or higher if you can!).","['spheres', 'geometry', 'multivariable-calculus', 'vector-analysis', 'differential-geometry']"
3293490,Unclear ideas in the proof of the Archimedean Principle,"Here is how the principle is laid out in the text: Given real numbers $a$ and $b$ , with $a \gt 0$ , there is an integer $n \in \mathbb{N}$ such that $b \lt na$ First off what is important about finding an $n$ that satisfies $b \lt na$ It talks about the strategy behind the proof and goes on to say that any non-empty subset of integers that is bounded above has ""a largest integer"". If $k_0$ is the largest integer that satisfies $k_0a \leq b$ , then $n=(k_0+1)$ must satisfy $na \gt b$ . In order to justify this application of the Completeness axiom, we have two details. 1) Is the set $E:= \{k \space \in \mathbb{N} \space : \space ka \leq b\}$ bounded above and 2) Is $E$ non-empty? This answer depends on whether $b \lt a$ or not. What I don't understand is why is $k_0$ introduced? and why does it matter if $k_0a \leq b$ ? Where did the idea of $k_0a \leq b$ come from and why is it important? Why does $E$ being non-empty depend on whether $b \lt a$ or not? How does it follow that n = $k_0 + 1$ must satisfy $b \lt na$ ? Then the proof is laid out: If $b \lt a$ set $n=1$ . If. If $a \leq b$ , consider the set $E:= \{k \space \in \mathbb{N} \space : \space ka \leq b\}$ . $E$ is nonempty since $1 \in E$ . Let $k \in E$ . Since $a \gt 0$ it follows from the first multiplicative property that $k \leq \frac{b}{a}$ . This proves $E$ is bounded by $\frac{b}{a}$ . Thus by the completeness axiom $E$ has a finite supremum $s$ that belongs to $E$ . set $n= s+1$ . Then $n \in \mathbb{N}$ , n cannot belong to $E$ thus $ na \gt b$ . Whats the significance of if $b \lt a$ then set $n=1$ ? I thought we were dealing with the set $E$ . How is $E$ considered non-empty when $1 \in E$ , by that I mean where was the $1$ pulled from? Just the fact that we are dealing with the set $\mathbb{N}$ ? I'm confused. What justifies setting $n = k_0 + 1$ ?",['real-analysis']
3293517,Solve a function based on an inequality,"Problem: Suppose that $f(x)\in C^\infty (R),~~$ and $~~ \forall n\in N,~~x\in R,~~$ we have $$|f^{(n)}(x)|\leq e^x$$ Prove that $f(x)=f(0)e^x$ . My thought is that prove the derivative of $g=fe^{-x}$ is zero. However, I can only prove $|g^{(n)}(x)|\leq 2^n$ by mathematical induction and given conditions.","['complex-analysis', 'sequences-and-series', 'analysis', 'real-analysis']"
3293547,Decoding Every Top 100 Voting Ever,"I need expert help on the math behind the following voting mechanism, any comment towards solutions are greatly appreciated! -- A country is holding a poll to determine the top 100 restaurants out of its 100 thousand domestic restaurants. Assuming each restaurant is unique, no chains or franchises, all of them share equal and fair chance of exposure to all customers nationwide. In the end there were 1 million valid voters, with each voter named 5 restaurants. Say each voter entered 5 non-repeat and valid entries. Is there a way to estimate: 1. the minimum votes a restaurant needs to be in top 100; 2. how many votes does #1 get? -- I'm not a math expert so my educated guess is each restaurant has a probability of 0.1% chance to be voted but that's as far as I could go, I have absolutely 0 idea how to proceed next… Look forward to your help, thanks! -- [UPDATE 07/17/2019] Thank you guys for all the insightful inputs! I’m confident that we’re on the right track to finding out the best answer and we’re close. If we are to put our solutions to test in a real world scenario however, I think it’s highly unlikely that a mere 2 digit votes will render a lucky restaurant Top 100. I assume we can all agree on this? So now the question is: how can we apply common sense to the equation? How do we identify the distribution model in real world? The Gaussian distribution seems to be an adequate one to describe the world we live in, where heavenly restaurants and unholy ones are extremely rare, and passable/half-decent ones constitute the majority. Let's add more conditions to define the scenario: Each restaurant has a Twitter account The voting result is positively correlated with Twitter follower counts The #1 restaurant has 10,000,000 followers whereas #100 has 100K Does this make more sense?","['applications', 'statistics', 'probability']"
3293573,Different definitions of Borel sigma-algebra,"Let $X$ be a locally compact Hausdorff space.
Denote by $\mathcal{B}(X)$ the Borel $\sigma$ -algebra (generated by all open sets in $X$ ) and by $\mathcal{B}_c(X) \subseteq \mathcal{B}(X)$ the collection of all relatively compact Borel sets. Then $\mathcal{B}_c(X)$ forms a $\delta$ -ring. For a ring $\mathcal{R}$ on some set $S$ denote by $\mathcal{R}^{loc} := \{ E \subseteq S \mid E \cap A \in \mathcal{R} \textrm{ for all } A \in \mathcal{R} \}$ the collection of all sets $E \subseteq S$ that are locally in $\mathcal{R}$ . If $\mathcal{R}$ is a $\delta$ -ring then $\mathcal{R}^{loc}$ is a $\sigma$ -algebra that contains $\mathcal{R}$ . Back to the space $X$ . The $\sigma$ -algebra $\mathcal{B}_c(X)^{loc}$ contains all open sets of $X$ and therefore $\mathcal{B}(X) \subseteq \mathcal{B}_c(X)^{loc}$ [Dinculeanu, ""Vector Measures"", p. 291]. $\mathcal{B}_c^{loc}(X)$ is also sometimes referred to in the older literature as the $\sigma$ -algebra of Borel sets. (It is useful in the context of vector measures, because the total variation measure of a vector measure can be defined on all of $\mathcal{B}_c(X)^{loc}$ .) I am searching for an example of a locally compact Hausdorff space $X$ such that $\mathcal{B}(X) \subsetneq \mathcal{B}_c(X)^{loc}$ , i.e. these two definitions of a Borel $\sigma$ -algebra are different. Equivalently, is there a locally compact Hausdorff space $X$ and a non-Borel measurable $E \not\in \mathcal{B}(X)$ but such that $E \cap K \in \mathcal{B}_c(X)$ (i.e. is Borel-measurable) for all compact $K \subseteq X$ ? Edit: Just an idea: Consider the open ordinal space $X = [0, \omega_1)$ where $\omega_1$ is the first uncountable ordinal. Then $X$ is locally compact but not $\sigma$ -compact. The sets $[0, \alpha]$ , $0 \leq \alpha < \omega_1$ are compact sets and any compact set $K \subseteq [0, \omega_1)$ is contained in some $[0, \alpha]$ . If $E \in 2^{[0, \omega_1)} \setminus \mathcal{B}[0, \omega_1)$ is a non-Borel measurable set then $E \cap [0, \alpha]$ is a Borel measurable subset of $[0, \alpha]$ for all $\alpha < \omega_1$ since $\alpha$ is a countable ordinal and $\mathcal{B}[0, \alpha] = 2^{[0, \alpha]}$ . Hence $E \cap [0, \alpha]$ is a Borel measurable subset of $[0, \omega_1)$ .
So the question is: Is $\mathcal{B}[0, \omega_1)$ strictly smaller than the power set $2^{[0, \omega_1)}$ ?",['measure-theory']
3293578,Logarithmic integral $\int_0^{1}\frac{\ln x\ln (1-x^{2})}{1+x^{2}}\mathrm dx$,Evaluate the integral in a closed-form : $$I=\int_0^{1}\frac{\ln x\ln (1-x^{2})}{1+x^{2}}\mathrm dx$$ My attempt : After put $x=\tan y$ we obtain: $$I=\int_0^{\frac{π}{4}}\ln (\tan x)\ln (1-\tan^{2} x)dx$$ $$1-\tan^{2} x=(1+\tan x)(1-\tan x)$$ $$\ln (1+\tan x)=\ln(\sin x+\cos x)-\ln(\cos x)=\ln (\cos (\frac{π}{4}-x))-\ln (\cos x)$$ Also: $$\ln (1-\tan x)=\ln(\cos x-\sin x)-\ln(\cos x)=\ln (\cos (\frac{π}{4}+x))-\ln (\cos x)$$ So: $$\ln (\tan x)\ln (1-\tan^{2} x)$$ $$=(\ln (\sin x)-\ln(\cos x)(\ln(\cos (\frac{π}{4}-x))-\ln (\cos x))(\ln(\cos (\frac{π}{4}+x))-\ln(\cos x))$$ Now I have many integrals. How can I evaluate them? Let me know if anyone has other ideas.,"['integration', 'definite-integrals', 'harmonic-numbers', 'closed-form', 'sequences-and-series']"
3293587,Showing $f(x) = \frac{x^2}{\sin(x)}$ is analytic near $0$,"Problem Show the function $$
f(x) = \frac{x^2}{\sin(x)}
$$ is an analytic about $x=0$ . Try We have $$
f(x) = \frac{x^2}{x - x^3/3! + x^5/5! - \cdots }
$$ Letting $f(x) = \sum_{n=0}^\infty a_n x^n $ , we have $$
a_0 = 0, a_1 = 1, a_2 = 0, a_3 = 1/6, a_4 = 0, a_5 = 7/360, \cdots
$$ thus $f(x) = x - x^3/6 + \cdots$ . Now we have to decide if $\sum_{n=0}^\infty a_n x^n$ is convergent near zero. But I cannot see the rules of $a_0, a_1, a_2, \cdots$ , so how should I proceed? It is known that Assume $f: = \sum_{n=0}^\infty b_n x^n$ and $g:= \sum_{n=0}^\infty c_n x^n$ be convergent near zero with radius of convergence $\rho>0$ . If $g(0) \neq 0$ , we have $$
\frac{f}{g} = \sum_{n=0}^\infty d_n
$$ for some radius of convergence $\le \rho$ . So relating this fact to my problem, $$
f(x) = \frac{x}{1 - x^2/3! + x^4/5! - \cdots }
$$ may be convergent with radius of convergence $\le \infty$ , which is the radius of $x^2$ (poylnomial) and $\sin(x)$",['sequences-and-series']
3293602,evaluate the summation : $\sum_{n=0}^{\infty}\frac{(-1)^{n}}{(n+1)(n+2x+3)}$,"Find $$S=\displaystyle\sum_{n=0}^{\infty}\frac{(-1)^{n}}{(n+1)(n+2x+3)}$$ for $x≥0$ . At first, I use a partial fraction $$S=\displaystyle\sum_{n=0}^{\infty}\left(\frac{(-1)^{n}}{2(x+1)(n+1)}-\frac{(-1)^{n}}{2(x+1)(n+2x+3)}\right)
=\frac{1}{2(x+1)}(I-J),$$ where $$I=\sum_{n=0}^{\infty}\frac{(-1)^{n}}{n+1}
=\ln 2$$ and $$J=\sum_{n=0}^{\infty}\frac{(-1)^{n}}{n+3+2x}$$ I think to use: $$\ln (1+y)=\sum_{n=0}^{\infty}\frac{(-1)^{n}y^{n+1}}{n+1}$$ Is my work correct? How to complete this work ?","['calculus', 'closed-form', 'summation']"
3293604,countable family of open sets,"Is there a countable family of open subsets of ${\bf R}$ or $[0,1]$ such that each rational belongs to only finitely many of the open sets and each irrational belongs to infinitely many of the sets?",['general-topology']
3293615,"Minimize the probability of winning a game with infinite independent $U(0, 1)$ random variables","Note: this question has been rephrased so that the problem isn't affected by boundary issues, as suggested by mathworker21's comment . See below for the original question. Let $k \in [0, 1]$ be a real number. The game starts with a random choice of a sequence $X_1, X_2, \dotsc$ of real numbers in $[0, 1]$ , which are not revealed to you. At any point in the game, you can either stop or show the next number of the sequence. The goal is to stop exactly before the sum of the shown numbers exceeds $k$ . For instance, at the beginning you can do either of the following: Stop without showing any number. If $X_1 \le k$ , you lose. If $X_1 > k$ , you win. Show $X_1$ . If $X_1 > k$ , you lose. If $X_1 \le k$ , the game goes on, and you can do either of the following: Stop . If $X_1 + X_2 \le k$ , you lose. If $X_1 + X_2 > k$ , you win. Show $X_2$ . If $X_1 + X_2 > k$ , you lose. If $X_1 + X_2 \le k$ , the game goes on. For a given $k \in [0, 1]$ , any strategy will have a certain probability $p$ of winning on any given sequence. For example, if $k = 0$ , the best strategy has probability $p = 1$ of winning, because you win by stopping right away. The question is: Which $k$ minimizes the probability $p$ of winning? In the original statement of the problem, there were only a finite number $n$ of random numbers. For example, for $n = 2$ , by showing $X_2$ you would have immediately won if $X_1 + X_2 \le k$ , and lost otherwise. In that case, the probability of winning appears to be minimum if $k = \frac {\sqrt {10}} 2 - 1$ , which I found by case analysis. For $n \ge 3$ , it seems unlikely that there is a simple expression of $k$ in terms of $n$ .","['algorithmic-game-theory', 'probability-theory']"
3293621,Interpretation of lemma: $f\in L^{1}_{loc}(\Omega)\ st\ \int f\phi=0\: \forall\phi\in\mathcal{D}(\Omega)\ \Rightarrow f=0\ in\ L^{1}_{loc}(\Omega)$,"As in the title, consider the following lemma in the theory of distributions: $$
f\in L^{1}_{loc}(\Omega)\;\;\text{ s.t. }\int f\phi=0\quad \forall\phi\in\mathcal{D}(\Omega)\ \implies f=0\;\text{ in }\; L^{1}_{loc}(\Omega)
$$ where $\mathcal{D}(\Omega)$ is the space of compactly supported $C^{\infty}$ functions, also known as test functions. The proof I know is based on mollifiers and convolution: the result follows by the uniform convergence of the regularized $f_\epsilon=f\ast\rho_\epsilon$ to $f$ , as $\epsilon\rightarrow 0$ where $\rho_\epsilon$ are a family of mollifiers. Now, we can see the same result written as $\langle f,\phi\rangle=0\; \forall\phi\in\mathcal{D}(\Omega)\ \Rightarrow\ f=0\ in\ L^1_{loc}(\Omega)$ where we view $f$ as an element of the dual $\mathcal{D}'(\Omega)$ . This may be interpreted as $f\in\mathcal{D}(\Omega)^{\perp}\subset\mathcal{D}'(\Omega)\ \Rightarrow f=0$ . If we where in a (seprable) Hilbert space, where the inner product allows us to 'internalize' the notion of dual (through Riesz theorem) and as a consequence that of orthogonal (as the most natural one) this consition is known to be necessary and sufficient for the set we are treating to be a orthogonal basis. I wonder if: we can have an analogous in this case (maybe through the notion of
density of $\mathcal{D}(\Omega)$ in $L^1$ ?) where the setting is that of general Topological Vector Spaces It is in general possible to define and charachterize a subspace $M\subset E$ such that $f\in E\ st\ \langle f,\phi\rangle =0\ \forall\phi\in M\ \Rightarrow f=0\ \in E'$ If yes, can we in some sense think of M as a ''basis''? More in general are there relevant generalization of the concept in arbitary TVS?","['convolution', 'topological-vector-spaces', 'functional-analysis', 'distribution-theory']"
3293664,Is the sum of binomial coefficients over square free integers normally distributed?,"I observed experimentally that the sum of binomial coefficients over square free integers approximately fits a normal distribution. Can this be proved or disproved theoretically? Let $\mu(r)$ be the Mobius function. Define $$
A_n = 
\mu(1){n\choose 1} + \mu(2){n\choose 2} + \mu(3){n\choose 3} + \cdots + \mu(n){n\choose n}
$$ $$
B_n = 
\mu(1)^2{n\choose 1} + \mu(2)^2{n\choose 2} + \mu(3)^2{n\choose 3} + \cdots + \mu(n)^2{n\choose n} 
$$ Note that $B_n$ is nothing but the sum of the Binomial coefficients over square free integers. Claim 1 : The sequence of numbers $\dfrac{A_n}{2^n}$ is normally distributed with a mean $0$ . Claim 2 : The sequence of numbers $\dfrac{\zeta(2)B_n}{2^n}$ is normally distributed with a mean $1$ . I do not have a closed form for the standard deviation in terms of well known constants and functions. As a illustration, given below is the histogram for $\frac{\zeta(2)s_n}{2^n}$ . The blue dots are the actual distribution while the red line represents a perfect normal distribution with the parameters $a,b$ and $c$ given below. Note that a similar sum over squares (instead of square free integers) appears to be arc-sine distributed instead of normal. So normality does not appear to be trivial. Update : Normality tests done for $n \le 10^5$ and the observation is that as increases, the distribution fits a normal distribution better","['statistics', 'summation', 'number-theory', 'normal-distribution', 'binomial-coefficients']"
3293687,Realizing an isomorphism of (faithful) semidirect products,"Suppose that we have two finite groups $A$ and $B$ , and suppose that $A$ is abelian. Let $G_{\phi} = A \rtimes_{\phi} B$ be the semidirect product given by $\phi: B \to \operatorname{Aut}(A)$ , and let $G_{\psi} = A \rtimes_{\psi} B$ be another semidirect product given by $\psi: B \to \operatorname{Aut}(A)$ . Suppose that both $\psi$ and $\phi$ are injective maps. I want to show that if $G_\phi \simeq G_\psi$ then $\phi(B)$ and $\psi(B)$ are in the same conjugacy class in $\operatorname{Aut}(A)$ , or to find a counterexample. I suspect this is not true in general, but I am struggling to find a counterexample.","['group-theory', 'finite-groups']"
3293708,What is the ratio of Carmichael pseduo-primes to true primes for $1$ to $n$? Or is it known?,"Let $\pi(n)$ be the prime counting function. And let $\varphi(n)$ be the count of Carmichael pseudo-primes for $1$ to $n$ . Is the ratio, $$\frac{\varphi(n)}{\pi(n)}$$ is known, as $n \to \infty$ ? I am asking this because of i want to know how much safe is the Fermat Primality Test (the one which only uses Fermat's Little Theorem). I recently wrote a Python script (initially for RSA) and produced more than 10, random 1024 bit primes with the help of this test. After i used the powerful mathematical software PARI/GP to check if they are really primes or pseudo-primes. In conclusion none of them were pseudo-primes. So, if know this rate, i will know the probability that this test will encounter a pseudo-prime and fail.","['number-theory', 'elementary-number-theory', 'pseudoprimes']"
3293725,Does component-wise convergence in distribution imply the random vector converges in distribution?,"Suppose $X_1, X_2, \cdots$ be a sequence of random variables such that $X_n \xrightarrow{d} X$ . Similarly, $Y_1, Y_2, \cdots$ be a sequence of random variables such that $Y_n \xrightarrow{d} Y$ . Is it true that $\left(X_n, Y_n\right) \xrightarrow{d} \left(X,Y\right)$ ? Also, is the converse true?","['stochastic-processes', 'convergence-divergence', 'probability-theory', 'weak-convergence']"
3293728,Can I get a sequence of bounded functions converging pointwise to $f(x)=1/x$ for $x$ non zero and $0$ for $x$ zero?,How do I construct an explicit sequence of bounded functions converging pointwise to $f(x)=1/x$ for non zero $x$ and $f(0)=0$ . It would be better if someone may find a continuous and even better if someone gives a differentiable sequence of functions on $\Bbb R$ converging to $f$ pointwise.,"['functions', 'sequences-and-series', 'metric-spaces', 'real-analysis']"
3293772,Has $n^{n+1}+(n+1)^{n+2}$ other obvious factors than that I found?,"Has the number $$f(n):=n^{n+1}+(n+1)^{n+2}$$ ""obvious"" factors (algebraic, aurifeuillan or similar kinds) apart from those , I mention below ? I only managed to find out forced factors for odd numbers $\ n\ $ : If $\ n\ $ is of the form $\ 6k+1\ $ , then $\ f(n)\ $ is divisible by $\ 3\ $ . If $\ n\ $ is of the form $\ 6k+3\ $ , then $\ f(n)\ $ is divisible by $\ n^2+n+1\ $ and finally, if $\ n+2\ $ is prime, then $\ f(n)\ $ is divisble by $\ n+2\ $ . For even $n$ , I did not find forced factors. The smallest not completely factored number of this form is $f(62)$ . It has the composite cofactor $$29645851324749161395794060252012567916992450650017954$$ $$8416412620499302880901240095492001218810908429181608669479$$ with $111$ digits.","['number-theory', 'prime-factorization', 'elementary-number-theory']"
3293811,Algebra and Combinatorics books for Mathematical Olympiads,"Could you kindly point out to me, some good contest-preparation book's to develop theory and problem solving skills in Algebra? It would be good if the book is less of theory and more of problems. I have ""Principles and techniques in Combinatorics"", but I would like some more difficult books, explaining theory well(this books theory is meh...). The same for Algebra(polynomials, functional Equations, inequalities, etc.) Thanks for your help!!!","['contest-math', 'book-recommendation', 'reference-request', 'combinatorics', 'algebra-precalculus']"
3293828,Peter-Weyl Theorem on the Sphere,"The Peter-Weyl theorem says that the matrix coefficients of the unitary irreps of a compact topological group $G$ form an orthonormal basis for $L^2(G)$ . Similarly, spherical harmonics provide an orthonormal basis for $L^2(S^2)$ , however the spherical harmonics are a basis for the irreps of $SO(3)$ , not $S^2$ , which has no Lie group structure ( Lie Group Structure on the 2-Sphere: does the following argument hold? ). I understand that the two spaces are intimately related since $SO(3)$ acts transitively on $S^2$ , but precisely how does spherical harmonic decomposition relate to the Peter-Weyl theorem considering the space under question is not a topological group?","['harmonic-analysis', 'group-theory', 'fourier-analysis', 'spherical-harmonics']"
3293834,Degree of a polynomial over an algebraic curve (in particular Edwards curve),"I've been very confused about how to define the degree of a rational function over an algebraic curve. For an Elliptic curve in Weierstrass form $E : Y^2=X^3 - AX -B$ over an algebraically closed field $K$ , char $K \neq 2,3$ , the set of polynomials on $E$ is given by $$ K[E] := K[X,Y]/\langle Y^2-X^3-AX-B \rangle $$ The set of rational functions is given by $$ K(E):= K[E]^2 / \sim $$ Then, the degree of a polynomial $f \in K[E]$ , where $ f(x,y)=v(x)+yw(x)$ is its canonical form is given by $$ \deg(f) := \max \{ 2 \deg_x(v),3+2\deg_x(w) \}   $$ Here, $\deg_x(v)$ is the classical degree of a polynomial $v \in K[X].$ Let $C:X^2 + Y^2 = 1+dX^2Y^2$ be an Edwards curve over $K$ , how do we define the degree of a polynomial $f \in K[C]$ ? In particular, for any algebraic curve. How will the result vary when the base field is not algebraically closed (for example, $\mathbb{F}_q$ )? From what I've read so far, it looks like it has something to do with the pole divisors of the rational function (x) and (y) in those curves, but this connection is not clear.","['number-theory', 'algebraic-geometry', 'arithmetic-geometry']"
3293840,Does knowing a graph has a Hamiltonian Cycle make it easier to find the cycle?,"Given a simple and connected graph $G=(V, E)$ . I know it's NP-Complete to determine if $G$ has a Hamiltonian Cycle (HC). But if we know $G$ indeed contains an HC, can we find the cycle in poly-time?","['graph-theory', 'combinatorics', 'hamiltonian-path']"
3293854,High precision evaluation of the series $\sum_{n=3}^\infty (-1)^n (1-n^{1/n})$,"This series converges conditionally, but it's quite slow. I would like to find its value with high accuracy: $$S=\sum_{n=3}^\infty (-1)^n (1-n^{1/n})$$ Wolfram Alpha gives $S \approx 0.226354\ldots$ . Since the terms decrease monotonely in absolute value, we can apply an approximate estimation: $$S_N= \sum_{n=3}^{N-1} (-1)^n (1-n^{1/n})+ \frac{1}{2} (-1)^N (1-N^{1/N})$$ $$S_{100}=0.22644\ldots$$ $$S_{101}=0.22626\ldots$$ $$\frac{S_{100}+S_{101}}{2} =0.22635473854439942\ldots$$ Another way could be to transform the series, for example: $$n^{1/n}=\exp \frac{\log n}{n}=\sum_{k=0}^\infty \frac{\log^k n}{n^k k!}$$ Which gives us (assuming we are allowed to change the order of summation): $$S=\sum_{k=1}^\infty \frac{1}{k!} \sum_{n=3}^\infty (-1)^{n+1} \frac{\log^k n}{n^k}=\sum_{k=1}^\infty \frac{S_k}{k!}$$ The inner series $S_k>0$ can be expressed in terms of repeated derivatives of the zeta function, which don't have a closed form for $k \geq 2$ , but the series can still be evaluated numerically with high accuracy. Note $$S_1=\frac{\log 2}{2} (1+\log 2-2\gamma)$$ For $k \geq 2$ we can easily write: $$S_k=\sum_{q=1}^\infty \frac{\log^k (2q+1)}{(2q+1)^k}-\sum_{q=2}^\infty \frac{\log^k (2q)}{(2q)^k}$$ Both the series converge absolutely and can be easily approximated by Euler-Maclaurin summation with all the integrals and derivatives expressed in closed form (obviously for large $k$ it becomes unwieldy). Evaluating the series up to $S_6$ we obtain: $$S > 0.2263538 \ldots$$ Still not that good. Finally, we could use Euler-Maclaurin, but I'm not sure how to apply it in this case, especially how to deal with the integral.","['euler-maclaurin', 'approximation', 'sequences-and-series']"
3293933,"Showing that the $\sigma$-algebra of countable and cocountable sets on $\mathbb{R}$ is uncountably generated, and also a subset of the Borel algebra","I have shown that the $\sigma$ -algebra generated by the set of all countable and cocountable sets in $\mathbb{R}$ , i.e. $\sigma \left( \{A\subset \mathbb{R} : A \text{ or } A^\complement \text{ is countable } \}\right)$ is equal to the $\sigma$ -algebra generated by the set of singletons in $\mathbb{R}$ , which must be uncountably generated. Is this equivalence sufficient to show, that $\sigma \left( \{A\subset \mathbb{R} : A \text{ or } A^\complement \text{ is countable } \}\right)$ is also uncountable? I am having trouble seeing whether or not an uncountably generated $\sigma$ -algebra can be equivalent to a countably generated $\sigma$ -algebra in some cases. Also, how can this $\textit{uncountably}$ generated $\sigma$ -algebra be a subset of the Borel algebra on $\mathbb{R}$ , which is $\textit{countably}$ generated?",['measure-theory']
3293965,"Study continuity of $f(x) = |x|$ for $x\in\Bbb R \setminus \Bbb Q$, $f(x) = \frac{qx}{q+1}$ for $x\in\Bbb Q$.","Study continuity of the following function: $$
f(x) = \begin{cases}
|x|,\ \text{if $x$ is irrational}\\
\frac{qx}{q+1},\ \text{if}\ x = {p\over q}, q\in\Bbb N, p\in\Bbb Z, p\perp q
\end{cases}
$$ I've been recently studying some similar functions. The usual trick was to consider different sequences $x_n$ and then study the behavior of $f(x)$ as $x_n$ approaches some point $x_0$ . I wasn't able to apply the same trick for this function but here some intuition though, which I want to formalize somehow. If we take any sequence $\{x_n\}_{n\in\Bbb N}$ of irrational numbers such that: $$
\lim_{n\to\infty}x_n = x_0
$$ Then: $$
\forall x_n \in\Bbb R\setminus \Bbb Q:f(x_n) = |x_n|
$$ In such case: $$
\lim_{n\to\infty} f(x_n) = |x_0|
$$ So it looks like the function is continuous at every irrational point. For the rational ones, I was trying to use a similar approach. Let $\{y_n\}$ be a sequence of rational numbers such that for $y_n \in\Bbb Q$ and $y_0\in\Bbb R\setminus\Bbb Q$ : $$
\lim_{n\to\infty}y_n = y_0
$$ But: $$
\lim_{n\to\infty}f(y_n) \ne f(y_0) = |y_0|
$$ Now every neighborhood of a given point in $\Bbb R$ contains infinitely many rationals and irrationals. So we might approximate $y_0$ with points from $y_n$ closer and closer to $y_0$ so if we introduce a $\{q_n\}$ denoting consequent denominators from $p\over q$ then it is going to grow and eventually: $$
\lim_{n\to\infty}{q_n\over q_n + 1} = 1
$$ So looks like every rational point is a point of removable discontinuity at least for $x \ge 0$ . My problem is with putting down a rigorous proof behind that intuition. Could you please help me with that?","['continuity', 'calculus', 'real-analysis']"
3294005,Homotopy equivalence of S1 and R2-0 [duplicate],"This question already has an answer here : Is the punctured plane homotopy equivalent to the circle? (1 answer) Closed 4 years ago . I want to show that $X=S^1=\{x^2+y^2=1|x,y\in \mathbb{R}\}$ and $Y=\mathbb{R}^2-\{0\}$ are homotopy equivalent. For this I have to find a function $f:X\rightarrow Y$ and a function $g:Y\rightarrow X$ such that $f\circ g$ is homotopic to the $id_Y$ and $g\circ f$ is homotopic to the $id_X$ . The construction of $g$ is easy: $g(x,y)=\frac{1}{\sqrt{x^2+y^2}}\begin{pmatrix}x\\y\end{pmatrix}$ . But how do I construct $f$ ? There is a certain ambiguity 'how much I stretch the unit circle'? Many thanks in advance","['general-topology', 'homotopy-theory']"
3294008,Integrating factor mistakes when solving 1 order ODE,"I have an ODE: $$\frac{dy}{dx} + 3x^{2}y = x^{2}$$ . I got the following integrating factor: $$e^{x^3}$$ Then I multiplied both sides, but didn't come up with the right answer. It should be: $$y = c~e^{-x^3} + \frac{1}{3}. $$ When I come up with the following: $$y = \left(\frac{1}{3}e^{x^3} + c\right) e^{x^3}$$ What am I doing wrong?","['integrating-factor', 'ordinary-differential-equations']"
3294065,Can we cancel out $1$ after replacing $e^x$ in $e^x-1$ by its Taylor expansion when calculating a limit?,"So I am to prove the following formula $$\lim_{x \to 0} \frac{e^x -1}{x} =1$$ Now, I write, $$
\begin{split}
\lim_{x \to 0} \frac{e^x -1}{x} 
   &= \lim_{x \to 0} \frac{(1+x+x^2/2!+x^3/3!+...) -1}{x} \\
   &= \lim_{x \to 0} \frac{x+x^2/2!+x^3/3!+...}{x} \\
   &= \lim_{x \to 0}1+x/2 +x^2/6+...\\
   &= 1
\end{split}
$$ Is it permissible to cancel out the $1$ at the numerator  and the calculation after that? Here we are dealing with an infinite series expansion of $e^x$ ,so I am very much confused about this method. By the way,I am not here for any other rigorous proof; I just want to know if my method is correct or not and why it is so.
Thanks in advance!","['limits-without-lhopital', 'alternative-proof', 'calculus', 'limits', 'substitution']"
3294080,Rationality of $X \times \mathbb P^1$ does not imply Rationality of $X$,What is the example that $X$ is not rational but $X\times \mathbb P^1$ is? (this is called stable rational if I remember correctly) Thanks :),"['algebraic-geometry', 'birational-geometry']"
3294082,"Given $a$ and $b$ positive integers, prove that $\min(a^{1/b},b^{1/a}) \le 3^{1/3}$","The exercise is to prove that the minimum value between $a^{1/b}$ and $b^{1/a}$ is no greater than $3^{1/3}$ , where $a$ and $b$ are positive integers. As it was presented in an introductory calculus class, I tried using brute Mathematics, ploting graphs, but was unable to develop and was looking for some elegant ideas.","['number-theory', 'calculus']"
3294096,"Find formula for $f''(0)$ using $f(0), f(h), f(2h), f'(h)$","I want to find an approximation for $f''(0)$ using the values of: $f(0), f(h), f(2h), f'(h)$ Usually I would use unknown coefficients and work the formula $$Af(0) + Bf(h) +Cf(2h)+Df'(h)$$ using taylor's expansion constraints. The problem here, that in the expansion of $f'(h)$ , there is a difference in the multiplication by $h$ : $f'(h) = f'(0) + hf''(0) + ...$ unlike $f(h) = f(0) + hf'(0) + \frac{h^2}{2}f''(0) + ...$ Moreover, I don't know the value of $f'(0)$ Help would be appreciated","['numerical-calculus', 'numerical-methods', 'derivatives']"
3294107,Integrating $1/x$ on unit sphere (quaternions),"I have an issue with integrating over the unit sphere in $\mathbb{H}$ (quaternions).
The integral is : $$\oint_{\mathbb{S}^2} \frac{1}{q} dq$$ with $$q\in \mathbb{H}, q=ia+jb+kc, (a,b,c) \in \mathbb{R}^3$$ yet we do not use the real numbers to have a 3-dimensional space. So I used that property : if we have $$
\begin{align*}
  \gamma \colon & [a;b] \to \mathbb{C}\\
  &t \mapsto \gamma(t).
\end{align*}
$$ then $$\int_\gamma f(\zeta) d\zeta = \int_a^b f(\gamma(\xi)) \gamma'(\xi) d\xi$$ Note that I supposed that we can adapt this property to quaternions. So, after changing this in a ""normal"" integral, I got : $$\int_{-\pi / 2}^{\pi / 2} \int_{- \pi}^{\pi} \frac{i \cos^2(\theta) \cos(\phi)-j \cos^2(\theta)\sin(\phi)-k\cos(\theta)\sin(\theta)\cos^2(\phi)+k\cos(\theta)\sin(\theta)\sin^2(\phi) }{i\cos(\theta)\cos(\phi) + j\cos(\theta)\sin(\phi)+k\sin(\theta)} d\phi d\theta$$ with using the parametrization of unit sphere : $$\mathbb{S}^2(\theta,\phi) : \left\{
\begin{align*}
  x(t) &= \cos(\theta)\cos(\phi) \\
  y(t) &= \cos(\theta)\sin(\phi) \\
  z(t) &= \sin(\theta)
\end{align*}
\right\} $$ and so $$ \mathbb{S}^2(\theta,\phi)=
\begin{align*}
  &i \cos(\theta)\cos(\phi) \\
  + &j \cos(\theta)\sin(\phi) \\
  + &k \sin(\theta)
\end{align*}
$$ yet we do not use the real numbers. And the quaternion-adaptation for the property seen above : $$\int_{-\pi / 2}^{\pi / 2} \int_{- \pi}^{\pi} \frac{(d \mathbb{S}^2(\theta,\phi)/d\theta)(d \mathbb{S}^2(\theta,\phi)/d\phi)}{\mathbb{S}^2(\theta,\phi)} d\phi d\theta$$ And there's the issue : The result is divergent, however, we easily can see than $1/q$ has only one pole (or singularity) at $q=0$ yet $\mathbb{S}^2$ does not pass trought this point. I certainly make a mistake but I am not able to determine which even if I strongly think that the mistake is about the quaternion-adaptation of the seen property. Thanks you for helping.","['quaternions', 'analysis']"
3294122,What approach provides the largest known verification of the Riemann Hypothesis?,"The Riemann Hypothesis is true if and only if Robin's Inequality is true for all n>5040. It has also been shown by Akbary and Friggstad that the smallest counterexample greater than 5040, if it exists, must be a Superabundant Number . These two facts suggest that Robin's Inequality might provide a more elementary way to show the Riemann Hypothesis is true or help provide a counterexample in the form of a Superabundant Number which violates the inequality. Robin's Inequality is elegantly stated: $$f(n)=\frac{\sigma (n)}{e^{\gamma} n \log \log n}<1$$ Below is a plot of the LHS for the first 2000 Superabundant Numbers above 5040 from A004394 . Looking at this plot and knowing how close the values get to 1 make it seem plausible that RH could be false, but if true it appears to be an asymptotically an increasing function bounded above by 1. Examining the remaining terms provided, the function behavior looks similar and for the largest term listed $f(a[1000000])\approx0.9998655$ . No terms before the millionth cross the threshold of one and $a[1000000]\approx10^{103082}$ . Is this the highest known verification of RH? It is my understanding that ZetaGrid and others working with the zeta function directly have only verified zeros up to $10^{13}$ . Also, from my understanding of Briggs he appears to have only verified completely up to $10^{154}$ using SA numbers? In fact, based on this curve and the possible relationship shown here , I am willing to venture a conjecture .","['number-theory', 'riemann-hypothesis']"
3294127,Solving the following limit without L'Hospital's rule: $\lim_{x\to 0} \frac{\sin(x^2+2)-\sin(x+2)}{x} $,"I have been trying to solve the following limit $$\lim_{x\to 0} \frac{\sin(x^2+2)-\sin(x+2)}{x}.$$ I came across the right answer as shown by the steps below, but I would to check if the steps are correct or if someone has a more straightforward solution. So applying the sum formula for sine and doing simple algebra we have: $$\lim_{x\to 0} \frac{\cos{2} \,(\sin{x^2}-\sin{x})}{x} - \frac{\sin{2} (\cos{x^2}-\cos{x})}{x} .$$ The first limit is easy to evaluate and is equal to $-\cos{2}$ . However, the second limit is harder, as it follows: $$\lim_{x\to 0}\frac{\sin{2} (\cos{x^2}-\cos{x})}{x} .$$ I came across a solution by using the following sum-to-product identity: $$\cos{A}-\cos{B}=-2\sin{\Big(\frac{A+B}{2}\Big)} \sin{\Big(\frac{A-B}{2}\Big)}$$ Setting $A=x^2$ and $B=x$ , we have that $$\cos{x^2}-\cos{x}=-2\sin{\Big(\frac{x^2+x}{2}\Big)} \sin{\Big(\frac{x^2-x}{2}\Big)}$$ This is my only point of concern whether I applied the identity correctly. The rest of it flows more easily: $$\lim_{x\to 0}\frac{\sin{2} (\cos{x^2}-\cos{x})}{x} = \lim_{x\to 0} \frac{-2\sin{2}\,\sin{\Big(\frac{x^2+x}{2}\Big)} \sin{\Big(\frac{x^2-x}{2}\Big)}}{x}$$ $$= -2 \sin{2} \lim_{x\to 0} \frac{\sin{\Big(\frac{x^2+x}{2}\Big)}}{x} \lim_{x\to 0} \sin{\Big(\frac{x^2-x}{2}\Big)} $$ The first limit can be solved as it follows: $$\lim_{x\to 0} \frac{\sin{\Big(\frac{x^2+x}{2}\Big)}}{x} = \lim_{x\to 0} \frac{\sin{\Big(\frac{x^2+x}{2}\Big)} \Big(\frac{x^2+x}{2}\Big)}{x \Big(\frac{x^2+x}{2}\Big)} = 1 \cdot \lim_{x \to 0} \frac{x^2 + x}{2x} = \frac{1}{2} $$ The second limit is equal to zero $$\lim_{x\to 0} \sin{\Big(\frac{x^2-x}{2}}\Big)=0$$","['limits', 'calculus', 'limits-without-lhopital', 'trigonometry']"
3294159,Characterizing maximal subgroups of cyclic groups.,"Suppose $G = \langle x \rangle $ is a cyclic group of order $n\geq 1$ . Prove that a subgroup $H \leq G$ is maximal if and only if $H = \langle x^p \rangle$ for some prime $p$ dividing $n$ . Source question: Dummit and Foote, ""Abstract algebra"", ex 16(c) p.65. Can someone check my proof? Attempt: $\Rightarrow$ Let $H$ be a maximal subgroup of $H$ . Write $H = \langle x^s \rangle$ with $s\mid n$ . Suppose, to reach a contradiction, that $s$ is not prime. Then we can write $s = qm$ with $1 < q < s$ . Since $x^s = x^{qm} = (x^q)^m$ , it follows that $H \subseteq \langle x^q \rangle$ . By order considerations, we get strict inclusions $$\langle x^s \rangle \subset \langle x^q\rangle \subset G$$ and this contradicts the maximality of $H$ . Hence, $s$ must be prime. $\Leftarrow$ Suppose $H = \langle x^p \rangle \subseteq \langle x^s \rangle$ with $p\mid n$ . By Lagrange's theorem, we have $$\frac{n}{p} \mid \frac{n}{(n,s)} \implies (n,s)\mid p$$ and thus $|\langle x^s \rangle| \in \{n/p,n\}$ . We conclude that either $\langle x^s \rangle = H$ or $\langle x^s \rangle = G$ . Thus, $H$ is maximal.","['maximal-subgroup', 'group-theory', 'solution-verification', 'cyclic-groups']"
3294203,Is there a closed-form solution for $\sum_{n=1}^{\infty} \sum_{m=1}^{\infty} \frac{1}{nm(3n+m)}$?,"I am seeking a closed-form solution for this double sum: \begin{eqnarray*}
\sum_{n=1}^{\infty} \sum_{m=1}^{\infty} \frac{1}{nm(\color{blue}{3}n+m)}= ?.
\end{eqnarray*} I will turn it into $3$ tough integrals in a moment.  But first I will state some similar results: \begin{eqnarray*}
\sum_{n=1}^{\infty} \sum_{m=1}^{\infty} \frac{1}{nm(n+m)} &=& 2 \zeta(3) \\
\sum_{n=1}^{\infty} \sum_{m=1}^{\infty} \frac{1}{nm(\color{blue}{2}n+m)} &=& \frac{11}{8} \zeta(3) \\
\sum_{n=1}^{\infty} \sum_{m=1}^{\infty} \frac{1}{nm(\color{blue}{4}n+m)} &=& \frac{67}{32} \zeta(3) -\frac{G \pi}{2}. \\
\end{eqnarray*} where $G$ is the Catalan constant. The last result took some effort ... Now I know most of you folks prefer integrals to sums, so lets turn this into an integral. Using \begin{eqnarray*}
\frac{1}{n} &=& \int_0^1 x^{n-1} dx\\
\frac{1}{m} &=& \int_0^1 y^{m-1} dy\\
\frac{1}{3n+m} &=& \int_0^1 z^{3n+m-1} dz \\
\end{eqnarray*} and summing the geometric series, we have the following triple integral \begin{eqnarray*}
\int_0^1 \int_0^1 \int_0^1 \frac{z^3 dx dy dz}{(1-xz^3)(1-yz)}.
\end{eqnarray*} Now doing the $x$ and $y$ integrations we have \begin{eqnarray*}
I=\int_0^1  \frac{\ln(1-z) \ln(1-z^3)}{z} dz.
\end{eqnarray*} Factorize the argument of the second logarithm ... \begin{eqnarray*}
I= \underbrace{\int_0^1  \frac{\ln(1-z) \ln(1-z)}{z} dz}_{=2\zeta(3)} + \int_0^1  \frac{\ln(1-z) \ln(1+z+z^2)}{z} dz.
\end{eqnarray*} So if you prefer my question is ... find a closed form for: \begin{eqnarray*}
I_1 = - \int_0^1  \frac{\ln(1-z) \ln(1+z+z^2)}{z} dz.
\end{eqnarray*} Integrating by parts gives: \begin{eqnarray*}
I_1 = - \int_0^1  \frac{\ln(z) \ln(1+z+z^2)}{1-z} dz + \int_0^1  \frac{(1+2z)\ln(z) \ln(1-z)}{1+z+z^2} dz.
\end{eqnarray*} and let us call these integrals $I_2$ and $I_3$ respectively. All $3$ of these integrals are not easy for me to evaluate and any help with their resolution will be gratefully received.","['integration', 'summation', 'definite-integrals', 'closed-form']"
3294215,Should people who want to study arithmetic geometry study complex geometry?,"I want to study arithmetic geometry, and I have read some fundamental texts of  algebraic geometry, such as Hartshorne. Next I'm studying etale cohomology and abelian varieties.
On texts of these theories, the author sometimes takes some pages for complex geometry as a classical theory.
(For example, complex Lie groups as a classical theory of abelian varieties.) For understanding these example completely, I have to study complex geometry, and for complex geometry, I have to study many analysis. It takes a lots of time, but I don't know whether it is worthwhile to study complex geometry deeply, for people who want to learn arithmetic, such as me. And also I don't know whether it is safe to use complex geometry as a black box. So I wonder if I should study complex geometry, or study arithmetic using complex geometry as a black box.","['complex-geometry', 'arithmetic', 'algebraic-geometry', 'soft-question']"
3294240,Overlap of left cosets and right cosets,"Let $G$ be a group, and let $H$ be a subgroup of finite index $r$ . Let $\{\alpha_i\}$ and $\{\beta_i\}$ be complete sets of right and left coset representatives, respectively. Then, \begin{align*}
G= \bigsqcup_{i=1}^r H\alpha_i = \bigsqcup_{i=1}^r \beta_iH.
\end{align*} My question is this: Is it always true, possibly after reordering the cosets, that $H\alpha_i \cap \beta_iH \neq \emptyset$ for every $i\in \{1,\ldots,r\}$ ? Any hints on this? I can prove it when $G$ is finite, but my proof doesn't work when $G$ is infinite.","['group-theory', 'abstract-algebra']"
3294245,Higher derivatives of Zeta function for $s>1$?,"I'm searching for integral expressions for $\zeta^{(n)} (s)$ for $n \geq 1$ and general $s$ . I have found two useful papers 1 and 2 from which I was able to obtain the following two cases which seem to work great numerically: $$1) \qquad \Re (s)<0$$ Denote $$s_1=1-s$$ Then we have: $$(-1)^n \zeta^{(n)} (s)= \\ = \frac{1}{(2 \pi  i)^{s_1} } \int_0^{\infty } \frac{t^{s_1-1} \left((-1)^{s_1} \left(\log  t-\log (2 \pi )+\frac{\pi  i}{2}\right)^n+\left(\log t-\log (2 \pi )-\frac{\pi  i}{2}\right)^n\right)}{e^t-1} \, dt$$ It follows from a more general formula (2) in paper 1.* $$2) \qquad 0 < \Re (s)<1$$ Then we have: $$\zeta^{(n)} (s)= \\ = \frac{1}{2 \pi  i} \int_0^{\infty } \left(\frac{1}{2 (u+1)}+\log (u)-\psi (u+1)\right) \left(e^{i \pi  s} \left(\log \left(\frac{1}{u}\right)+i \pi \right)^n- \\ -e^{-i \pi  s} \left(\log \left(\frac{1}{u}\right)-i \pi \right)^n\right) \frac{du}{u^s} $$ Which directly follows from formula (1.7) in paper 2. My question is : can we find a similar explicit expression for $\zeta^{(n)} (s)$ with $\Re (s)>1$ ? $^*$ For anyone who doesn't have access to paper 1, here's the original formula, valid for all complex $s$ : $$(-1)^n \zeta^{(n)} (1-s) = \sum_{k=0}^n \binom{n}{k} \left(e^{s z} z^{n-k}+e^{s z^*} (z^*)^{n-k} \right) \left( \Gamma(s) \zeta(s) \right)^{(k)}$$ Where $z=-\log (2 \pi) - \frac{\pi i}{2}$ . A side question: what other ways exist to numerically evaluate these derivatives? How does Mathematica do it, in case you know?","['integration', 'riemann-zeta', 'derivatives', 'special-functions']"
3294267,Proof verifications for set equality,"Can I get a proof verification? Are there any flaws in this proof? The examples in the book are only for sets bounded either above or below. Prove $$\cup_{n\in \mathbb{N}}(0,\frac{n}{n+1})=(0,1)$$ Assume $x \in \cup_{n\in \mathbb{N}}(0,\frac{n}{n+1})$ . Thus $\exists n_x \in \mathbb{N}$ such that $x \in (0,\frac{n_x}{n_x+1})$ $\implies 0<x<\frac{n_x}{n_x+1}$ also since $0<1 \implies$ $n_x<n_x+1 \implies \frac{n_x}{n_x+1}<1$ We have $0<x<\frac{n_x}{n_x+1}<1$ Thus $x \in (0,1)$ So $$\cup_{n\in \mathbb{N}}(0,\frac{n}{n+1})\subseteq(0,1)$$ Assume $0<x<1$ Then since $0<1-x$ , $\frac{x}{1-x} \in \mathbb{R}$ By the Archimedean property $\exists n \in 
\mathbb{N}$ such that $n>\frac{x}{1-x}$ Thus $0<x< \frac{n}{n+1}$ So $x \in \cup_{n\in \mathbb{N}}(0,\frac{n}{n+1})$ And $$\cup_{n\in \mathbb{N}}(0,\frac{n}{n+1})\supseteq(0,1)$$","['elementary-set-theory', 'proof-verification']"
3294294,"Do non-symmetric ""strongly positive definite"" matrices have unique positive definite square roots?","It is well known that if $A$ is a symmetric positive definite matrix, then it has a unique square root which is positive definite. My question is whether this result extends to a strongly positive definite nonsymmetric matrix. More precisely, let $A$ be a real nonsymmetric $n\times n$ matrix, which satisfies the following strong positive definite condition: there exists $a>0$ such that for each $x\in\mathbb R^n$ , the estimate $$
\langle Ax, x\rangle\geq a|x|^2
$$ holds. Is it true then that there exists a unique (edit: strongly positive definite) matrix $B$ such that $B^2=A$ ? I would be very interested in knowing the answer to this result, and reference to a proof. Thanks!","['matrices', 'linear-algebra']"
3294304,Find triple summation rel in a closed form $S=\sum_{n=1}^{\infty}\sum_{m=1}^{n}\sum_{k=1}^{m}\frac{1}{(n+1)(k+1)(m+1)nmk}$,"Evaluate $\displaystyle S=\sum_{n=1}^{\infty}\sum_{m=1}^{n}\sum_{k=1}^{m}\frac{1}{(n+1)(k+1)(m+1)nmk}$ My attempt : Let $$A=\sum_{k=1}^{m}\frac{1}{k(k+1)} 
=\sum_{k=1}^{m}\left( \frac1{k}-\frac1{k+1} \right) = \frac{m}{m+1}$$ and a second sum : $$B=\sum_{m=1}^{n}\frac{1}{(m+1)^{2}}$$ from here how I can complete ??","['calculus', 'closed-form', 'summation']"
3294356,Every interval $I \subset \mathbb{R}$ is connected. [Proof clarification],"I struggled to understand a part of the following proof. Topological Proof that every Interval $I \subset \mathbb{R}$ is connected Definition: A topological space is connected if, and only if, it cannot be divided in two
  nonempty, open and disjoint subsets, or, similarly, if the empty set and the whole set are the 
  only subsets that are open and closed at the same time. Proof . Suppose $I = A \cup B$ and $A \cap B = \emptyset$ , $A$ and $B$ are both non-empty and open in the subspace-topology of $I \subset \mathbb{R}$ . Choose $a\in A$ and $b\in B$ and suppose $a < b$ . Let $s := \mathrm{inf}\{ x \in B ~|~ a < x \}$ . Then in every neighborhood of $s$ there are points of $B$ (because of the definition of the infimum), but also of $A$ , then if not $s = a$ , then $a < s$ and the open interval $(a,s)$ lies entirely in $A$ . And so $s$ cannot be an inner point of $A$ nor $B$ , but this is a contradiction to the property that both $A$ and $B$ be open and $s \in A \cup B$ . My Problems I am struggled with the bold parts. Probably because I'm more familiar with metric spaces than with topological spaces. I know that $\forall \epsilon>0, \exists y\in B:s+\epsilon>y$ and this implies that every open ball $\beta (s,\epsilon)$ contains a point of $B$ . Furthermore, if $a=s\in A$ clearly $\beta (s,\epsilon)$ contains a point of $A$ , otherwise, if $a<s$ then $(a,s)\subset A$ which also means that $\beta (s,\epsilon)$ contain a point of $A$ . If this argument is correct, then my problem turns out to be the translation of these ideas of open balls and distances to the topological framework. I have the intuition that he is trying to show that $s$ is a boundary point of $B$ in $I$ . As $A$ and $B$ separates $I$ , $B^c=A$ . So, $s$ can never be (an interior point) either in $A$ or in $B$ . I'm trying to furnish a proof in the context of a topological space. Can someone clarify my doubts? Thanks in advance!","['proof-explanation', 'general-topology', 'self-learning', 'real-analysis']"
3294358,Extension of the Lebesgue measurable sets,"My question is the following : is there a $\sigma$-algebra $\mathcal{T}$ (of subsets of $\mathbb{R^n}$) that contains strictly the $\sigma$-algebra $\mathcal{L}$ of 
Lebesgue measurable sets (in $\mathbb{R}^n$), and such that there is a measure on $\mathcal{T}$ that extends the usual Lebesgue measure on $\mathcal{L}$ ? I guess not, but I did not find a reference.","['measure-theory', 'real-analysis']"
3294398,Express $\sum_{j=1}^{n}\sum_{i=1}^{n} \frac{1}{i(i+j)}$ in terms of harmonic numbers,Express $$\sum_{j=1}^{n}\sum_{i=1}^{n} \frac{1}{i(i+j)}$$ in terms of the harmonic numbers $H_n$ . I guess that there could be several approaches for doing this.,"['harmonic-numbers', 'summation', 'sequences-and-series']"
3294446,$ \int_0^\frac{\pi}{2}\ln^n\left(\tan(x)\right)\:dx$,"I'm currently working on a definite integral and am hoping to find alternative methods to evaluate. Here I will to address the integral: \begin{equation}
I_n = \int_0^\frac{\pi}{2}\ln^n\left(\tan(x)\right)\:dx
\end{equation} Where $n \in \mathbb{N}$ . We first observe that when $n = 2k + 1$ ( $k\in \mathbb{Z}, k \geq 0$ ) that, \begin{equation}
I_{2k + 1} = \int_0^\frac{\pi}{2}\ln^{2k + 1}\left(\tan(x)\right)\:dx = 0
\end{equation} This can be easily shown by noticing that the integrand is odd over the region of integration about $x = \frac{\pi}{4}$ . Thus, we need only resolve the cases when $n = 2k$ , i.e. \begin{equation}
I_{2k} = \int_0^\frac{\pi}{2}\ln^{2k}\left(\tan(x)\right)\:dx 
\end{equation} Here I have isolated two methods. Method 1: Let $u = \tan(x)$ : \begin{equation}
I_{2k} = \int_0^\infty\ln^{2k}\left(u\right) \cdot \frac{1}{u^2 + 1}\:du = \int_0^\infty \frac{\ln^{2k}\left(u\right)}{u^2 + 1}\:du 
\end{equation} We note that: \begin{equation}
\ln^{2k}(u) = \frac{d^{2k}}{dy^{2k}}\big[u^y\big]_{y = 0}
\end{equation} By Leibniz's Integral Rule: \begin{align}
I_{2k} &= \int_0^\infty \frac{\frac{d^{2k}}{dy^{2k}}\big[u^y\big]_{y = 0}}{u^2 + 1}\:du = \frac{d^{2k}}{dy^{2k}} \left[ \int_0^\infty \frac{u^y}{u^2 + 1} \right]_{y = 0} \nonumber \\
&= \frac{d^{2k}}{dy^{2k}} \left[ \frac{1}{2}B\left(1 - \frac{y + 1}{2}, \frac{y + 1}{2} \right) \right]_{y = 0} =\frac{1}{2}\frac{d^{2k}}{dy^{2k}} \left[ \Gamma\left(1 - \frac{y + 1}{2}\right)\Gamma\left( \frac{y + 1}{2} \right) \right]_{y = 0} \nonumber \\
&=\frac{1}{2}\frac{d^{2k}}{dy^{2k}} \left[ \frac{\pi}{\sin\left(\pi\left(\frac{y + 1}{2}\right)\right)} \right]_{y = 0} = \frac{\pi}{2}\frac{d^{2k}}{dy^{2k}} \left[\operatorname{cosec}\left(\frac{\pi}{2}\left(y + 1\right)\right)  \right]_{y = 0}
\end{align} Method 2: We first observe that: \begin{align}
\ln^{2k}\left(\tan(x)\right) &= \big[\ln\left(\sin(x)\right) - \ln\left(\cos(x)\right) \big]^{2k} \nonumber \\
&= \sum_{j = 0}^{2k} { 2k \choose j}(-1)^j \ln^j\left(\cos(x)\right)\ln^{2k - j}\left(\sin(x)\right)
\end{align} By the linearity property of proper integrals we observe: \begin{align}
I_{2k} &= \int_0^\frac{\pi}{2} \left[ \sum_{j = 0}^{2k} { 2k \choose j}(-1)^j \ln^j\left(\cos(x)\right)\ln^{2k - j}\left(\sin(x)\right) \right]\:dx \nonumber \\
&= \sum_{j = 0}^{2k} { 2k \choose j}(-1)^j \int_0^\frac{\pi}{2} \ln^j\left(\cos(x)\right)\ln^{2k - j}\left(\sin(x)\right)\:dx \nonumber \\
& = \sum_{j = 0}^{2k} { 2k \choose j}(-1)^j F_{n,m}(0,0)
\end{align} Where \begin{equation}
F_{n,m}(a,b) =  \int_0^\frac{\pi}{2} \ln^n\left(\cos(x)\right)\ln^{m}\left(\sin(x)\right)\:dx
\end{equation} Utilising the same identity given before, this becomes: \begin{align}
F_{n,m}(a,b) &= \int_0^\frac{\pi}{2}  \frac{d^n}{da^n}\big[\sin^a(x) \big] \cdot \frac{d^m}{db^m}\big[\cos^b(x) \big]\big|\:dx \nonumber \\
&= \frac{\partial^{n + m}}{\partial a^n \partial b^m}\left[ \int_0^\frac{\pi}{2} \sin^a(x)\cos^b(x)\:dx\right] = \frac{\partial^{n + m}}{\partial a^n \partial b^m}\left[\frac{1}{2} B\left(\frac{a + 1}{2}, \frac{b + 1}{2} \right)\right] \nonumber \\
&= \frac{1}{2}\frac{\partial^{n + m}}{\partial a^n \partial b^m}\left[\frac{\Gamma\left(\frac{a + 1}{2}\right)\Gamma\left(\frac{b + 1}{2}\right)}{\Gamma\left(\frac{a + b}{2} + 1\right)}\right] 
\end{align} Thus, \begin{equation}
I_{2k} = \sum_{j = 0}^{2k} { 2k \choose j}(-1)^j \frac{1}{2}\frac{\partial^{2k }}{\partial a^j \partial b^{2k - j}}\left[\frac{\Gamma\left(\frac{a + 1}{2}\right)\Gamma\left(\frac{b + 1}{2}\right)}{\Gamma\left(\frac{a + b}{2} + 1\right)}\right]_{(a,b) = (0,0)}
\end{equation} So, I'm curious, are there any other Real Based Methods to evaluate this definite integral?","['integration', 'definite-integrals', 'recursion', 'gamma-function', 'beta-function']"
3294453,Intuition of Kolmogorov‘s 0-1 Law,Kolmogorov‘s 0-1 Law seems to say something very intuitive: Tail events of independent objects have probability $0$ or $1$ . At least it should be intuitive - but it is not to me. Why exactly are tail events supposed to have this behaviour? What‘s the intuitive argument?,"['independence', 'probability-theory', 'probability']"
3294486,The notion of basis in infinite dimensional (topological) vector spaces,"As in the title I would like to clear my mind about what is meant by a basis in infinite dimension, especially in the case where the vector space is endowed with a compatible topology. What I know is: Hamel basis : a collection of linearly idependent vectors whose finite linear combinations express all the elements of the space. This notion should be independent of whether we place a topology on the vector space or not. We can always prove the existence of such a basis through Zorn's Lemma Schauder basis : a collection of linearly independent vectors such that the closure of its span coincides with the whole space, in other terms we can express any vector of the space as an infinite sum. I also know this collection as a complete system. By its definition, it seems to me this concepts fits only in the case of Topological Vector Spaces. I do not know any existence results. Orthonormal basis , or Fourier basis : a particular case of Schauder basis in separable Hilbert spaces. I know a characterization, which states that TFAE: B is  a orthonormal basis, $B^\perp=0$ , Parseval identity holds, the series of Fourier coefficients of any vector is $<\infty$ (aka Fischer-Riesz theorem). What I would like to know is what are other concepts or generalization of the idea of basis in particular, if any, in the case of Topological Vector Spaces which are not normable, such as locally convex. Thanks in advance","['schauder-basis', 'topological-vector-spaces', 'linear-algebra', 'functional-analysis', 'hamel-basis']"
3294492,"Haar functions are basis in $L^2[0,1]$","Define the Haar functions as $e_0^0=1$ and for $n\ge 1$ , $k=1,\ldots,2^n$ $$
e_n^k(t)=\left\{ \begin{array}{ll}
         2^{\frac{n-1}{2}} & \mbox{if $x \in \big(\frac{K-1}{2^n},\frac{K}{2^n}\big)$};\\
        -2^{\frac{n-1}{2}} & \mbox{if $x \in \big(\frac{K}{2^n},\frac{K+1}{2^n}\big)$};\\
0 &\mbox{otherwise}
\end{array} \right.
$$ As part of showing that this is an orthonormal basis in $L^2[0,1]$ , I need to show first that if $\langle f,e^k\rangle=0$ for each $k$ and $n$ then $\langle f,\chi_{[0,x]}\rangle = 0$ for every dyadic $x$ . This would mean $f=0$ . I was looking at this answer but I do not understand the construction he uses. Thanks in advance for your help.","['hilbert-spaces', 'functional-analysis', 'real-analysis']"
3294505,"Upper bound on the number of edges given number of vertices, girth and maximum degree","For a simple and undirected graph $G$ , is there a known upper bound on the number of edges it has, given number of vertices $n$ , girth $g$ and maximum degree $\Delta$ ?","['graph-theory', 'combinatorics', 'discrete-mathematics']"
3294526,Commutation of limit and integration,"I'm a physics student and perhaps do not have an in depth exposure to analysis. In the following calculation $$
\tilde{\Phi}(\Omega)= \lim_{\omega \rightarrow0} \int_{-\infty}^{\infty} d\tau\:e^{-i\Omega\tau} \text{cos}\big(\omega g^{-1}e^{-g \tau}\big)
$$ it turns out that when I carry out the integral and evaluate $|\tilde{\Phi}(\Omega)|^2$ , then take the limit $\omega $ going to zero, I get a finite result (The finite result is well verified, it is from a paper with whose author I have gone through the calculation). However, if I take the limit $\omega$ going to zero first then $\tilde{\Phi}(\Omega)=\delta(\Omega)$ and $|\tilde{\Phi}(\Omega)|^2$ is the Dirac delta function squared. Pertaining to the corresponding interpretation in terms of physics, the finite result is what is the 'correct' computation. However, I wanted to know if this is the correct way mathematically too, what exactly is the subtelty that has gone into this, and are there similar examples of the same? For instance I know that when I just have two limits, the order can be important. For instance if $$
L = \lim_{ x,y \rightarrow{0}} \frac{f(x)}{g(y)}
$$ where both $f(x)$ and $g(y)$ approach zero when $x,y$ approach zero then suppose I took the $x$ limit first. Then that would lead to $L$ being zero. 
But the commutation of a limit and an integral is something that I can't quite wrap my head around.","['limits', 'analysis']"
3294530,Are there visual proofs for the sums of reciprocals of square and triangular numbers?,This is a visual proof for the sum of the reciprocals of powers of 2 - Are there a similar proofs for reciprocals of square and triangular numbers? I couldn't find any. I don't know if I used the right terms; maybe it's: infinite series sum. So correct this question if it's wrong.,['sequences-and-series']
3294535,Sum of reciprocals of products,"We are given a set of natural numbers 2, 3, 4, ..., n. 
  Consider all subsets, each of them consisting of the combinations $_{(n-1)}C_{2}$ , $_{(n-1)}C_{3}$ , $_{(n-1)}C_{4}$ etc. We take the products of the terms in each such subset and then its reciprocals. 
  Find the sum of all these reciprocals. I believe I must find a recursive formula but I have no idea how to proceed... I tried for n=4 and n=5 and found 5/12 and 86/120 respectively but I don't know how to continue. 
For example, for n=4: Let's consider the set {2,3,4}. Then we have the subsets {2,3}, (2,4), (3,4), (2,3,4) and their respective elements' products are 6, 8, 12 and 24. Then we take $\frac{1}{6}, \frac{1}{8}, \frac{1}{12}, \frac{1}{24}$ and add them. The result is $\frac{10}{24}$ . Also noticed that for each such fraction, the product of the numerator and the denominator equals n!.",['combinatorics']
3294548,How to represent a set of variables are different elements of a set mathematically?,"Lets say that we have set $A$ . The variables $m_{1}$ , $m_{2}$ , $\cdots$ $m_{N}$ are elements of the set $A$ but with exclusivity. The variables have to be different elements of the set. How can I represent it mathematically? Can I just write $m_1, m_2, \cdots m_N \in A$ ?",['elementary-set-theory']
3294565,Connection between Residue Theorem in complex analysis and algebraic geometry,"I am currently studying algebraic curves using the Fulton. In chapter 8 we have a proposition called ""Residue Theorem"" RESIDUE THEOREM. Let $C,E$ be as above ( $C$ is a projective plane curve, $E = \sum_{Q\in X} (m_{(f(Q)} - 1)\, Q$ , $X$ is a non singular model of $C$ ). Suppose $D$ and $D'$ are effective divisors on $X$ , with $D'\equiv D$ . Suppose $G$ is an adjoint of degree $m$ such that $\operatorname{div}(G) = D + E + A$ for some effective divisor $A$ . Then there is an adjoint $G'$ of degree $m$ such that $\operatorname{div}(G') = D' + E + A$ . I was wondering if this has anything to do with the Residue Theorem in complex analysis. Can anyone help me?","['complex-analysis', 'algebraic-geometry']"
3294574,Value of $\prod_{n>1} \frac{1}{1-\frac{1}{n^s}}$ or $-\sum_{n=2}^{\infty} \log(1-\frac{1}{n^s} )$,"I know \begin{align}
\prod_{p~is~ prime} \frac{1}{1-\frac{1}{p^2}} = \zeta(2) = \frac{\pi^2}{6}
\end{align} which has a convergent number. actually I can even generalized this to \begin{align}
\prod_{p ~is~ prime} \frac{1}{1-\frac{1}{p^s}} = \zeta(s)  
\end{align} For $s>1$ [consider $s\in \mathbb{R}$ ] we know zeta function converges, so this   has a convergent number. How about generalization to arbitrary integers? [i.e., I want to replace $p$ with arbitrary integer $n$ .] For example $s=2$ , we have \begin{align}
 \prod_{n>1} \frac{1}{1-\frac{1}{n^2}}
\end{align} taking log we need to show \begin{align}
- \sum_{n=2} \log\left(1-\frac{1}{n^2} \right) 
\end{align} is convergent or not. simply by telescope method I can see this value converges to $\log(2)$ , that means $ \prod_{n>1} \frac{1}{1-\frac{1}{n^2}} = 2$ . Now consider $s>1$ . \begin{align}
-\sum_{n>1} \log\left(1-\frac{1}{n^s}\right)
\end{align} This is convergent from comparison test. Simply take $a_n = -\log(1-\frac{1}{n^s})$ and $b_n = \frac{1}{n^s}$ , then \begin{align}
\lim_{n\rightarrow \infty} \frac{a_n}{b_n} = \lim_{x\rightarrow 0} \frac{-\log(1-x)}{x} = 1 >0
\end{align} and since $\sum_{n=1}^{\infty} b_n = \zeta(s)$ is convergent for $s>1$ , $\sum_{n=2}^{\infty} a_n$ also converges. What I want to obtain is the value of such convergent series, first i tried telescope method, but it seems difficult even for $s=3$ . Is there a way to compute exact value of those products? How and what is the values of those products?","['analysis', 'calculus', 'products', 'convergence-divergence', 'zeta-functions']"
3294575,Let $f:\mathbb{N} \rightarrow \mathbb{N}$ such that $f(1)=2011$ and $f(n)= \frac{1}{n^2 -1}(f(1)+f(2)+...+f(n-1))$ for $n \ge 2$. Calculate $f(2011)$ [duplicate],"This question already has answers here : Solving for $f(2004)$ in a given functional equation (4 answers) Closed 4 years ago . Being $f:\mathbb{N} \rightarrow \mathbb{N}$ such that $f(1)=2011$ and $f(n)=  \frac{1}{n^2 -1}(f(1)+f(2)+...+f(n-1))$ for $n \ge 2$ . Calculate $f(2011)$ When calculating $f(n)$ I need to consider the sum of the previous elements, from $2011$ to $f(n-1)$ . But when considering each of these, I need again the the sum of the previous $f(n)$ . I've never met a problem like this. It seems like a sequence  by recursion: are there any rules when approaching problems like this?","['recurrence-relations', 'sequences-and-series']"
3294610,Compute $\int_{\mathbb R}\frac{dx}{1+2x^2+x^4}$,"I want to compute Compute $$\int_\mathbb R\frac{1}{1+2x^2+x^4}dx$$ using the residue theorem and I've already applied the standard method of integrating along the upper half of the unit circle. But I have encountered a little problem when trying to show that one of the contour integral vanishes: So first I parameterize the upper arc via $$\gamma:=\begin{cases}[0,\pi]\to\mathbb C\\ t\mapsto Re^{it}\end{cases}$$ and I want to show that with $f(z):=\frac{1}{z^4+2z^2+1}$ we have $$\lim_{R\to\infty}\left|\int_\gamma f(z)dz\right|=0$$ because I can't use the standard estimation. The denominator has 3 summands so I'm unsure how to apply a certain inequality to it. How can I estimate $|z^4+2z^2+1|$ ? Essentially I just want to say that $|z^4+2z^2+1|\geq |z|^4-2|z|^2-1$ and maybe that's even true but as of now I don't see why.","['complex-analysis', 'residue-calculus']"
3294646,Gradient operator of the log multivariate Gaussian density,"I'm trying to analytically find the gradient the log a multivariate Gaussian density, which is given by $$
f(x_{1}, \dots, x_{p}) = f(\vec{x}) = \frac{1}{(2\pi)^{p/2}|\Sigma|^{1/2}} \exp \Bigg(-\frac{1}{2}(\vec{x} - \vec{\mu})^{T}\Sigma^{-1}(\vec{x} - \vec{\mu})\Bigg) \sim \mathcal{N}(\vec{\mu}, \Sigma)
$$ where $\vec{x}, \vec{\mu} \in \mathbb{R}^{p}$ , and $\Sigma \in \mathbb{R}^{p \times p}$ . I want to find the analytical expression for $\nabla f$ , where $\nabla$ is the gradient operator defined as $$
\nabla f(\vec{x}) = \Bigg[ \frac{\partial f(\vec{x})}{\partial x_{1}}, \dots, \frac{\partial f(\vec{x})}{\partial x_{p}} \Bigg]
$$ My vector calculus is very rusty and not sure how to take partial derivatives with respect to $x_{1}, \dots, x_{p}$ . Any help is much appreciated!","['statistics', 'vectors', 'normal-distribution', 'multivariable-calculus', 'linear-algebra']"
3294659,Coordinate basis of tangent space,"I am reading Carroll, Sean. An Introduction to General Relativity: Spacetime and Geometry . In the second chapter, he explains at length the concept of manifolds and tangent vector space at a point on the manifold, with a coordinate chart $x^\mu$ . The book explains how the basis of the tangent space is, $$\frac{\partial}{\partial x^\mu} \equiv\partial_\mu$$ This means that any directional derivative along any curve parametrized by $\lambda$ can be written as a linear combination of $\partial_\mu$ . So a vector can then be defined as, $$\text{X}=X^\mu \partial_\mu\equiv X^\mu \hat{e}_\mu$$ I get the abstract ideas, somewhat, which are being explained here. But I am having a hard time connecting these ideas to the usual ones taught about vectors in Euclidean geometry. For example, the definition of vectors as, $$\text{X}=X^\mu \partial_\mu$$ sort of looks like an operator, like its 'waiting' for something to act on for it to have a meaningful idea. I am not able to understand the link I am missing to make the connection from these abstract concepts to those in Euclidean geometry where vectors are simply written as $$\vec{V}=V_1 \hat{i}+V_2 \hat{j}+V_3\hat{k}$$ .","['manifolds', 'tangent-spaces', 'differential-geometry']"
3294697,How should one go about learning discrete mathematics? [closed],"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 4 years ago . Improve this question How should one go with learning the proofs? How should one learn to prove things themselves? What kind of thinking skills should one develop and how? How should one practice problems? How to remember the concepts one learnt  better? All in all, what should be the main strategy to do full justice to discrete mathematics and enjoy it.","['soft-question', 'discrete-mathematics', 'learning']"
3294700,Mnev's Universality Type Theorem,"In order to state properly Mnev's universality type theorems, one has to understand the definition of stable equivalence. I have some questions to the definition.
Here is the definition as in Oriented Matroids from Björner et.al. Let $V \subseteq \mathbb{R}^n$ and $W \subseteq \mathbb{R}^{n+d}$ be
semi-algebraic sets with $\pi(W) = V$ , where $\pi : \mathbb{R}^{n+d} \rightarrow \mathbb{R}^n$ is the canonical
projection that deletes the last $d$ coordinates. $V$ is a stable projection of $W$ if $W$ has the form $$W = \{(v,v') \in \mathbb{R}^{n+d} : v \in V,\ \phi_i(v) \cdot v' > 0; \
\psi_j(v) \cdot v' = 0 \textrm{ for } i \in X; j \in Y \} .$$ Here $X$ and $Y$ denote finite (possibly empty) index sets. 
For $i \in X$ and $j \in Y$ the functions $\phi_i$ and $\psi_j$ have to be polynomial functions $$ \phi_i= ( \phi_i^1 , . . . , \phi_i^d ) : \mathbb{R}^n \rightarrow (\mathbb{R}^d)^* \text{ with } \phi_i^k \in \mathbb{Z}[x_i, \ldots , x_n] \quad \mbox{and}$$ $$\psi_j = (\psi_j^1,\ldots,\psi_j^d) :\mathbb{R}^n \rightarrow (\mathbb{R}^d)^*
\text{ with } \psi_i^k \in \mathbb{Z}[x_i, \ldots , x_n],$$ that associate to every element of $\mathbb{R}^n$ a linear functional on $\mathbb{R}^d$ . Two semialgebraic
sets $V$ and $W$ are rationally equivalent if there exists a homeomorphism $f : V \rightarrow W$ such that both $f$ and $f^{-1}$ are given by rational functions.
Two semialgebraic sets $V$ and $W$ are stably equivalent if 
they are in the same
equivalence class with respect to the equivalence 
relation generated by stable projections and rational equivalence. Question 1: What is exactly meant by homeomorphism in this case? What is exactly meant by rational function in this case? Question 2: OK, to unwrap and really understand the concept, how
can I show that the following two sets are
stably-equivalent? $S = \{(x,y,z)\in \mathbb{R}^3 : x y = z\}$ $T = \{(x,y,z,a)\in \mathbb{R}^4 : x y = z ; a = (x+y)^2\}$ . Question 3: Intuitively the following two sets should be stably
equivalent: $S\subset \mathbb{R}^n$ and $S'= \{(x,1)\in \mathbb{R}^{n+1} : x\in S\}.$ I don't see how to show this. Question 4: Are the following two sets stably-equivalent? $S = \{x\in \mathbb{R} : x>0\}$ $T = \{(x,y)\in \mathbb{R}^2 : x y^2 - 1 = 0\}.$ thanks Till","['matroids', 'functions', 'polynomials', 'discrete-mathematics']"
3294729,Writing nonlinear ODE in matrix form,"I want to obtain the eigenvalues of the following nonlinear system ${\displaystyle {\dot {x}}_{1}(t)=x_{2}(t)}$ $  {\displaystyle{\dot {x}}_{2}(t)=-{\frac {g}{\ell }}\sin {x_{1}}(t)-{\frac {k}{m\ell }}{x_{2}}(t)}$ I have tried to convert to matrix form in order to find $A-I\lambda$ $A= [0, 1$ $-g/l\sin(x_1), -k/ml]$ But this doesn't seem right due to he sin term still being present, any advice?","['ordinary-differential-equations', 'eigenvalues-eigenvectors', 'matrices', 'linear-algebra', 'derivatives']"
3294765,Does convolution of Borel measures have the cancellation property?,"The convolution of two Borel measures $\mu$ and $\nu$ is given by $$(\mu * \nu)(E) = \int_{-\infty}^\infty \nu(E - x) \; \mu(d x).$$ I have been trying to figure out whether the following cancellation law holds for convolutions: $$\text{if } \nu \neq 0 \text{ and } \mu_1 * \nu = \mu_2 * \nu, \text{ then also } \mu_1 = \mu_2$$ Here I use $\mu = \nu$ to mean that $\mu(E) = \nu(E)$ for all Borel measurable $E$ . Intuitively, I feel that the cancellation property should hold, but I have seen examples of the cancellation property failing for very similar kinds of convolution, so I am unsure. Does the cancellation property above hold for convolution of measures? And if not, can we recover it by restricting for example to probability measures and/or continuous measures?","['measure-theory', 'convolution']"
3294803,Proof of a Binomial identity,"Computer experiments suggest that $$f_m(n,k)= \sum\limits_{j = 0}^n {{{( - 1)}^{n - j}}}\frac {2j + 1}{n + j + 1}\binom{2n}{n-j}\sum\limits_{l = 0}^{m - 1} \binom{mj+l+k}{2k}$$ satisfies $$f_m(k,k)=m^{2k+1}$$ and $$f_m(n,k)=0$$ for $n>k.$ Is there a simple proof of this fact?","['binomial-coefficients', 'combinatorics']"
