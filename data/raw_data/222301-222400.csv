question_id,title,body,tags
4560148,"In a compact metric space, is there an upper bound on the size of a collection of equidistant points?","Fix $\epsilon > 0.$ A finite subset $F\subset X$ of the compact metric space $X$ is called $\epsilon$ - equidistant if $d(x,y) = \epsilon$ for all distinct $x,y\in X.$ For all $\epsilon>0,$ does there exist $N,$ depending on both $\epsilon$ and $X,$ such that if $F\subset X$ is $\epsilon$ -equidistant, then the cardinality of $F$ is at most $N?$ The answer is yes for a compact metric group $G$ with identity 1. Let $\mu$ denote the normalized Haar measure of $G$ and $B$ the open ball around 1 with radius $\epsilon/2.$ An upper bound on the size of an $\epsilon$ -equidistant set is $1/\mu\big(B).$ But a proof or counterexample for an arbitrary compact metric space eludes me.","['general-topology', 'metric-spaces']"
4560159,Solution verification for a line integral,"Question: Sami walked from the point $(0,1,2)$ to $(3,2,4)$ in a straight line. Given that $A$ is the line segment from which she walked, determine the value of the following integral(Hint: Use parametric equations.): $$ \int_{A}^{} x^{2}dx + y^{2}dy + xzdz $$ Answer:(Sorry if this seems like more of a discussion than an answer, i'm still learning and it helps when I write down everything going on in my head.) First we parameterise the curve $A$ . First, find the direction vector for the line segment. In order to do this we subtract the two points that we originally have, thus: $(3,2,4)-(0,1,2) = \langle 3,1,2 \rangle$ . Now let us define the parametric function $r(t)$ , in order to parameterise the curve we must multiply by $t$ . Thus: $r(t) = \langle 0,1,2 \rangle + t\langle 3,1,2 \rangle $ , simplifying we eventually get $r(t) = \langle 3t,t + 1,2t + 2 \rangle$ . In order for us to get a definite integral we must find some sort of interval. To do this let us test the points $0,1$ . It follows that: $r(0) = \langle 0,1,2 \rangle$ and that, $r(1) = \langle 3,2,4 \rangle$ . Now we can finally get rid of this Line integral and replace it with a definite one with the interval $[0,1]$ , However first we must calculate a few derivatives. $$A: \begin{cases} x(t)=0+3t,\\y(t)=1+t,\\z(t)+2+2t\end{cases},\quad 0\leqslant t\leqslant 1.$$ Therefore, $x'(t)=3,y'(t)=1,z'(t)=2$ . Now that we have these values we can proceed to evaluate the definite integral: $$\begin{equation}\begin{aligned}
\int_{A}^{} x^{2}dx + y^{2}dy + xzdz &= \int_{0}^{1} x^{2}dx + y^{2}dy + xzdz \\
 &= \int_{0}^{1} (3t)^{2}(3) + (1 + t)^{2}(1) + (3t)(2t + 2)(2) dt \\
  &= \int_{0}^{1} 27t^{2} + t^{2} + 2t + 1 + 12t^{2} + 12t dt \\
  &= \int_{0}^{1} 40t^{2} + 1 + 14t dt
\end{aligned}\end{equation}$$ Now we can simply evaluate this using the power rule: $$ \int_{0}^{1} \frac{40t^{3}}{3} + t + 7t^{2} dt= \left[\frac{40(1)^{3}}{3} + (1)^{2} + 7(1)^{2}\right] - \left[\frac{40(0)^{3}}{3} + (0)^{2} + 7(0)^{2}\right]=\frac{64}{3}.$$","['multivariable-calculus', 'solution-verification', 'line-integrals']"
4560192,I need help interpreting Definition 1.10 in Rudin‚Äôs PMA.,"While I have a basic understanding of what this definition states, I've been running into trouble interpreting the results when I test it with certain sets other than the traditional examples used to show that the Rationals do not have this property. $\textbf{Definition 1.10:}$ ""An ordered set ùëÜ is said to have the least-upper-bound property if the following is true: $$\text{If }ùê∏\subsetùëÜ\text{, }E \text{ is not empty, and } ùê∏ \text{ is bounded above, then } \sup(ùê∏) \text{ exists in } ùëÜ.""$$ $\\$ I am interpreting this as a series of nested conditional statements: $$\Big[ \big( \left( E\subset S \right) \land \left( E \neq \varnothing \right) \land \left( E \text{  bounded above}\right) \big) \implies (\ \sup(E) \text{ exists in }S)\ \Big] \implies S \text{ has LUB property}$$ From here, we usually let $S=\mathbb{Q}$ and $E=\{q\in\mathbb{Q}:q^2<2 \}$ to show that $\mathbb{Q}$ does not have the LUB property. This makes sense to me because while the antecedent within brackets is true, the consequent is false. Thus the bracketed conditional is false, forcing the entire definition to be true. But what about if (for example) $S=\mathbb{Q}$ and $E=\{q\in\mathbb{Q}:q^2<-1\}$ ? In this case, $E=\varnothing$ , thus the antecedent within the brackets is false. This renders the entire conditional in brackets true. Then the whole definition can only be true if $\mathbb{Q}$ has the LUB property - which is clearly wrong. Can someone help me track down my misunderstanding?",['real-analysis']
4560268,"Prove that with some conditions,$\sum\limits_{i=1}^mA_iBA_i^T=B$ iff $A_iB=BA_i(1\leq i\leq m)$.","$A_i\in\mathbb{R}^{n\times n}(1\leq i\leq m)$ , $\sum\limits_{i=1}^mA_iA_i^T=I$ , $B\in\mathbb{R}^{n\times n}$ and $\text{tr}(B)=1$ , $B$ is positive. Prove that $\sum\limits_{i=1}^mA_iBA_i^T=B$ iff $A_iB=BA_i(1\leq i\leq m)$ . One direction is simple:if $A_iB=BA_i(1\leq i\leq m)$ ,then $\sum\limits_{i=1}^mA_iBA_i^T=\sum\limits_{i=1}^mBA_iA_i^T=B$ ,but what about the other direction? Update:Thank @mechanodroid for answer and I realize that the condition: $\sum\limits_{i=1}^mA_i^TA_i\preceq I$ should be added after reviewing the background of this problem.The form $\sum A_iBA_i^T$ is called the Kraus representation and the property $\sum\limits_{i=1}^mA_iBA_i^T=B$ is called ""unital"".And for Kraus representation there is a default rule $\sum\limits_{i=1}^mA_i^TA_i\preceq I$ (which is called trace-preserving) as mentioned by @mechanodroid, but I omitted that,my fault.","['matrices', 'linear-algebra']"
4560269,How to reduce the ODE to first order?,"How to reduce the following O.D.E. into first order? $$(vv_{xxx}-v_{x}v_{xx})g^2 + v^3 v_x = 0, \tag{1}$$ where $v=v(x)$ and $v_{x}$ is the derivative w.r.t $x$ , $g$ is a constant. After integration, equation (1) can be written as $$(vv_{xx}-v_{x}^2)g^2+\frac{v^4}{4} - c=0, \tag{2}$$ where $c$ is an integration constant. How to integrate further to get a first order O.D.E.?","['reduction-of-order-ode', 'ordinary-differential-equations']"
4560273,Simplifying $\frac{1-4\cos80^\circ}{\tan20^\circ}$,"I am working on simplifying the value $$\frac{1-4\cos80^\circ}{\tan20^\circ}$$ I am looking for it to be expressed in terms of tangent, because the value seems to be $\tan40^\circ$ . However, I can't find any obvious way to do so. How would  simplify it to express like such?","['algebra-precalculus', 'trigonometry']"
4560343,Can you function both sides of an equation?,"So i had this question on my exam recently:
Given that: $g(x)= x +\ln x -1$ , $x>0$ ,(obviously $g$ is $1:1$ ) $f(f(x))= f(x) + x + \ln x -1$ (1) , true for every $x>0$ prove that: $f$ is $1:1$ (which i easily proved with monotony , no problem here) $f^{-1}(1) = 1$ the equation $f(x) = x$ , $x>0$ is only true for $x=1$ so here's how i tackled the third one: $f(x) = x \Leftrightarrow f(f(x)) = f(x) \Leftrightarrow f(f(x)) - f(x) = 0 $ from (1): $ x + \ln x -1 = 0 \Leftrightarrow g(x) =0 \Leftrightarrow g(x) = g(1) \Leftrightarrow x=1$ since $g$ is $1:1$ so the equation is true for $x=1$ , and since $f$ is monotonous ( or $1:1$ ) $x=1$ is the only root of the equation My professor said that this solution is false because "" I cannot function both sides of an equation because the equation is not true for all $x\in Df$ "" . I really don't see how what my professor said is relevant at all and I'm honestly really confused. Any ideas? EDIT: I asked my professor again and it seems that his real problem was that, according to him, i cannot function an equation that might not have a solution to begin with. I disagree with that observation because even if the equation is not true for all x>0 , provided everything in my solution is equivalent to each other, the equation will just turn out to be impossible. I also showed my solution to two other professors at my school and they agreed with it.","['algebra-precalculus', 'functions']"
4560349,Does $S_b$ become eventually greater than $S_{b+1}$?,"For a base $b \geq 2$ , let $S_b$ be the sequence the $n$ ‚àíth term of which is found by concatenating $n$ copies of the number $n$ written in base $b$ , and then seeing the resulting string as a number in base $b$ . For example, given $b=2$ , we get the sequence $1$ , $1010_2$ , $111111_2$ , $100100100100_2$ etc, and for base ten we get $1$ , $22$ , $333$ , $4444$ , etc. For fixed $b$ , does the sequence $S_b$ become eventually greater than the sequence $S_{b+1}$ ? That is, does the $n$ -th term of $S_b$ is greater than that of $S_{b+1}$ for all $n$ greater than some constant?",['number-theory']
4560353,Please check my solution of distributing $4$ prizes among $6$ people,"There are $6$ people and $4$ identical prizes. Assuming that $0$ distribution of prizes is allowed, find the number of ways of distributing the $4$ identical prizes to the $6$ persons such that a person can get any number of prizes. My answer is coming $246$ or $$\binom{6}{1}+\binom{6}{2}\cdot3+\binom{6}{3}\cdot3+\binom{6}{4}$$ I first picked up a person and found the number of ways of distributing all prizes to him. Then I picked up any two persons and found the number of ways of distributing all prizes to them. I continued this till the $4$ th person as after that the prizes end. Is my method and my answer right $?$",['combinatorics']
4560364,Hausdorff topological spaces: Is the pointwise limit of a sequence of Borel measurable functions again Borel measurable?,"I'm trying to respond to @GEdgar's comment about extending this result to more general spaces. Let $(X, \mathcal X)$ be a measurable space and $(E, d)$ a metric space. Let $f, f_n:X \to E$ such that $\lim_n f_n = f$ pointwise. Theorem: If $f_n$ is Borel measurable for all $n$ , then so is $f$ . My questions: Could you have a check on my below attempt? Does this theorem hold in case $E$ is a Hausdorff topological space? Proof: Let $O$ be open in $E$ . It suffices to show that $f^{-1}(O) \in \mathcal X$ . Let $$
O_m := \{x \in O \mid d(x, \partial O) > 1/(m+1)\} \quad \forall m \in \mathbb N.
$$ Then $O_m \subset O$ and $O_m$ is open in $E$ . We have $$
\begin{align}
&f(x) \in O \\
\iff &\lim_n f_n (x) \in O \\
\iff & \exists m \in \mathbb N,  \lim_n f_n (x) \in O_m\\
\iff & \exists m \in \mathbb N, \exists N \in \mathbb N, \forall n \ge N: f_n (x) \in O_m.
\end{align}
$$ It follows that $$
f^{-1}(O) = \bigcup_{m \in \mathbb N} \bigcup_{N \in \mathbb N} \bigcap_{n \ge N} f_n^{-1} (O_m).
$$ Clearly, $f_n^{-1} (O_m) \in \mathcal X$ because $f_n$ is Borel measurable. This completes the proof.","['measurable-functions', 'general-topology', 'metric-spaces', 'measure-theory']"
4560366,A series of questions on the subspace generated in a Hilbert space.,"Let $H$ be a Hilbert space. Note. Where it is not subject to definition with the overline we indicate the closure of the set. Claim 1. Prove that the set $$\overline{\text{sp}}(A):=\bigcap\left\{M\;|\; M\;\text{is closed subspace such that}\; M\supseteq A\right\}$$ is a closed subspace of $H$ . proof. Clearly $0\in \overline{\text{sp}}(A)$ . Let $x,y\in \overline{\text{sp}}(A)$ and $\alpha.\beta\in \mathbb{R}$ , then $x$ and $y$ are in all closed subspaces $M$ that contain $A$ and therefore $\alpha x+\beta y\in \overline{\text{sp}}(A)$ . It remains to show that $\overline{\text{sp}}(A)$ is closed. Let $\{x_n\}\subseteq \overline{\text{sp}}(A)$ a sequence such that $x_n\to x$ . Since $\{x_n\}$ is, in particular, a sequence in every closed subspace $M$ that contains $A$ , results that $x$ is in every closed subspace $M$ that contain $A$ and so $x\in \overline{\text{sp}}(A)$ . Claim 2. Let $A\subseteq H$ be a set we denote with $\text{sp}(A)$ the subspace generated by $A$ : $$\text{sp}(A)=\left\{\sum_{k=1}^nc_kx_k\;|\; n\ge 1, c_k\in\mathbb{R}, x_k\in A\right\}.$$ I must prove that $$\overline{\text{sp}}(A)=\overline{\text{sp}(A)}$$ proof. Since $\overline{\text{sp}(A)}$ is a closed subspace that contains $A$ , from definition of $\overline{\text{sp}}(A)$ we deduce that $\overline{\text{sp}}(A)\subseteq\overline{\text{sp}(A)}$ . Let now $M$ a closed subspace such that $M\supseteq A$ , since $M$ is closed with respect sum and product result that $\text{sp}(A)\subseteq M$ , therefore $$\text{sp}(A)\subseteq M,\quad\text{for all closed subspace}; M\supseteq A,$$ from which it is deduced that $\text{sp}(A)\subseteq \overline{\text{sp}}(A)$ , so using the claim $1$ we have that $\overline{\text{sp}(A)}\subseteq \overline{\text{sp}}(A)$ . Claim 3. Let $L$ a subspace of $H$ , we prove that $$\overline{L}=\overline{\text{sp}}(L)$$ proof. Since $\overline{L}$ is a closed subspace that contains $L$ , from definition we have that $\overline{\text{sp}}(L)\subseteq \overline{L}$ . On the other hand, $L\subseteq \text{sp}(L)$ and therefore using the claim $2$ we have $\overline{L}\subseteq \overline{\text{sp}(L)}=\overline{\text{sp}}(L)$ . Question. Are the proposed proofs correct?","['hilbert-spaces', 'solution-verification', 'functional-analysis', 'real-analysis']"
4560371,"Show that the solution to $y^{''}+f(y)y^{'}+g(y) = 0$, where $f \in C(\mathbb{R})$ and $g\in C^{1}(\mathbb{R})$, is unique.","The problem is: Show that the local solution to $y^{''}+f(y)y^{'}+g(y) = 0$ , where $f \in C(\mathbb{R})$ and $g\in C^{1}(\mathbb{R})$ , is unique. Since my class currently has only covered the existence and uniqueness theorem of 1st order ODE, I think I should transform it into a system of 1st order ODE. Let $x_1 = y$ and $x_2 = y^{'}=x_1^{'}$ . Then the DE becomes $$
 x_1^{'}= x_2   \enspace \text{ and } x_2^{'} =   - f(x_1)x_2 -g(x_1).
$$ Define $F(x,y) =  (y, -f(x) y-g(x) \,)$ . The DE now can be written as $$
   \frac{d\psi}{dt}(t) =  F(\psi(t)), \, \text{where }\psi(t) = (x_1(t), x_2(t)), 
$$ which is a 1st order ODE. The function $F$ is continuous, hence given an initial condition, a local solution must exist. In order to show that it's unique, I think I should show that $F$ is Lipschitz. But it seems that $F$ needs not be Lipschitz. Setting $g \equiv 0$ , and consider any $f$ that's continuous but not Lipschitz. Then for any points whose second coordinates coincide, $(x_1,x_2),(y_1,x_2)$ , we have $$
||F(x_1,x_2) - F(y_1,x_2)|| = |x_2| \cdot | f(x_1)-f(y_1)|.
$$ Since $f$ is not Lipschitz, $F$ also can't be Lipschitz from the equation above. Where do I get wrong? Can anyone prove the uniqueness of the solution?","['calculus', 'analysis', 'ordinary-differential-equations']"
4560374,Conjugate stabilisers with group actions,"Let the group $G$ act on the set $X$ . Suppose $x,y\in X$ and that we have $y=g*x$ . Prove that $h\in stab_G(x)$ if and only if $ghg^{-1}\in stab_G(y)$ . Attempt: By definition $stab_G(x)=\{g\in G:g*x=x\}$ . So $ghg^{-1}\in stab_G(y)$ means that $(ghg^{-1})*y=y$ . Since this is a group action, we have $(gh)*g^{-1}y=y$ , that is, $(gh)*g^{-1}gx=y$ . Therefore $(gh)*x=y$ . I don't know how this verifies that $h\in stab_G(x)$ though, can anyone give any tips?","['group-actions', 'group-theory', 'abstract-algebra', 'solution-verification']"
4560390,"Infinite product of areas in a square, inscribed quarter-circle and line segments.","The diagram shows a square of area $An$ and an enclosed quarter-circle. Line segments are drawn from the bottom-left vertex to points that are equally spaced along the quarter-circle. The regions enclosed by the line segments and the quarter-circle have areas $a_1, a_2, a_3, ..., a_n$ . Find the value of $A$ such that $\lim\limits_{n\to\infty}\prod\limits_{k=1}^n a_k = 2$ . I have parced the problem to this: $$\lim\limits_{n\to\infty}\prod\limits_{k=1}^n Anf(k)(g(k)-g(k-1))=2$$ where $f(k)=\frac{3}{2}-\sin{\frac{k\pi}{2n}-\cos{\frac{k\pi}{2n}}}$ $g(k)=\arcsin{\left(\dfrac{\sin{\frac{k\pi}{2n}}-\cos{\frac{k\pi}{2n}}}{2\sqrt{f(k)}}\right)}$ Desmos suggests $A\approx 5.77987$ . I am looking for a closed form for $A$ . I have tried to take the log of the product and relate the resulting sum to an integral, but I do not know how to deal with the $g(k-1)$ . (This question was inspired by a related question , where the product of the lengths of the line segments approaches $2$ .) EDIT After some more exploration, it seems that $A$ also makes $\frac{1}{n}\prod\limits_{k=1}^{n}A\frac{\pi}{4}\left(\cos{\frac{k\pi}{2(n+1)}}+\sin{\frac{k\pi}{2(n+1)}}-1\right)$ converge to a positive number (approximately $0.8817$ ). EDIT2 Based on this question , it seems that $A=\frac{4}{\pi}e^{4G/\pi}\sqrt2$ where $G$ is Catalan's constant .","['area', 'circles', 'closed-form', 'infinite-product', 'limits']"
4560468,Find real intervals where a function is nearly constant,"A differentiable function $f$ is said to be nearly constant over $I \subset \mathbb{R}$ if $f$ does not vary much over $I$ . For example, one can ask for ùúñ>0 small enough such that $\displaystyle \int_{I} (f(x)-\lambda_I)^2 \, \mathrm{d}\mu(x) < \epsilon$ with $\lambda_I = \frac{1}{\mu(I)} \int_{I} f(x)\,d\mu(x)$ . Does anyone know if there is an article or page that discusses how to find these $I$ intervals for a given $\epsilon$ threshold?
More generally I am looking for a (numerical) analysis method that would allow me to know if sometimes a function $f$ is almost constant. Thanks in advance!","['integration', 'real-analysis', 'algorithms', 'numerical-methods', 'derivatives']"
4560471,Expected number of Same color run in standard 52 deck,"I encountered this question What is the expected number of runs of same color in a standard deck of cards? , and I understand the answer approach by @George. However, I'm unsure why my answer leads to a different answer. I cannot find my logic error, and I'm looking for some explanations or suggestions. My approach: There are $26$ Black cards, so we assume there are $26+1=27$ slots for the Red cards to be. For each slot i, the probability that at least one Red card is in it is $1- (26/27)^{26}$ . If the slot has at least one Red card, the number of same color runs increases by 2; this holds for all $2\leq i\leq 27.$ For the first slot, if there is at least one Red, the number of run is increased by $1$ , and $0$ otherwise. A illustration is below: ___ B ___ B ___ B...___ B___B___ Then I get the answer to be $(2\cdot 26+1)\cdot(1-(26/27)^{26})=33.133$ What caused the error?","['statistics', 'probability']"
4560478,Inverse of a cubic with some constraints,"I'm trying to find the inverse of a particular cubic equation over a certain range. I have a partial solution and I'm not sure what's missing to make it complete. I'd like to solve the following equation in terms of $u$ : $$
c=ku^3+(1-k)u
$$ Where: $$
-0.5 <= k <= 0.5 \\
0 <= u <= 1 \\
\therefore 0 <= c <= 1
$$ I know that for these value ranges, the function is strictly increasing and so has a 1:1 mapping between $c$ and $u$ . The reason I'm doing this is the above equation is involved in fisheye lens distortion correction and I'm trying to do a de-correction. I thought inverting the equation would be easy algebra and it turns out it's way too much for my 41-year-old brain to handle. Ultimately, I ended up throwing it at Wolfram Alpha , which produced (I've introduced $p$ to save typing): $$
p = \sqrt[3]{\sqrt{729 k^4 c^2 - 108 (k-1)^3 k^3} - 27 k^2 c} \\
u = - \frac{\sqrt[3]{2} (k-1)}{p} - \frac{p}{3 \sqrt[3]{2} k} 
$$ Now, despite being a small monster, it mostly works (eq 1 is the original, eq 3 is the inverse over the original $c$ and so should be identity, eq 4+ should be ignored) but only for $k > 0$ . In particular, when $k <= 0$ then the original function is no longer generally 1:1 over $u$ , and the inverse seems to be undefined over the areas with multiple solutions for $u$ . k=-0.5 k=0.5 Blue: original, purple: inverse. Note the undefined gap below around $c=u=2$ . Only 0 to 1 are of interest; zoomed out to show gap. Because the inverse is undefined over $c$ 's with multiple $u$ 's, I'm almost certain that I need a $\pm$ (or two) somewhere, but I can't figure it out. I did try randomly changing $+$ 's to $-$ 's but never arrived at a correct solution. I'm at least pretty sure that the undefinedness originates with a negative term in that square root ( e.g. when $s$ is negative here ). What do I need to do to that partial solution to complete it over the given range? Previous work (can be skipped): The very first thing I did was type the function into some random online algebra calculator and ask it to solve for $u$ . None of them could solve the equation (I forgot about Wolfram Alpha at this point). So I was going to do it by hand. At first I forgot that I was looking for ""inverse"" and started digging around for solutions to cubics. I discovered depressed cubics and set about finding an equation for the solutions (a doomed approach since I was really looking for the inverse). I found Cardano's method here and tested it out on Desmos (it's actually eq 6 in the link above, kind of a neat curve if you zoom out), where I finally realized this wasn't what I was looking for. So then I searched around for inverses of depressed cubics (I didn't really know how to handle the $k$ in front of the 3rd-degree term but figured I'd work it out eventually). I found a lot of algebra work but I wasn't able to understand how to apply it with non-constant terms ( $k$ ), or how to take advantage of the constraints that I had. Eventually I found this comment on a post here and tried just entering the equation into Wolfram Alpha and, to my pleasant surprise, it worked. I threw the equation back into Desmos to test it, which is where I noticed it wasn't defined over $0<=c<=1$ for $k<=0$ , so I messed around with $+$ 's and $-$ 's to no avail, got pretty burnt out, and that's the point I'm at now.","['cubics', 'algebra-precalculus', 'inverse-function', 'polynomials']"
4560531,"Is $\mathbb{P}(A):=\lim_{N\to\infty}\max_{n\geq N}\frac{1}{\pi(n)}\#\{\text{primes }p\leq n,\ p\in A\}$ a Probability Measure?","I'm taking a class in probability, and we had a question which was to prove or disprove that $$\mathbb{P}(A):=\lim_{N\to\infty}\max_{n\geq N}\frac{1}{\pi(n)}|\{\text{primes }p\leq n,\ p\in A\}|$$ is a probability measure. Here $\pi(n):=|\{\text{primes }p\leq n\}|$ is the prime counting function. I know $$\mathbb{P}(\mathbb{N})=\lim_{N\to\infty}\max_{n\geq N}\frac{1}{\pi(n)}|\{\text{primes }p\leq n\}|=1,$$ and clearly $\mathbb{P}(A)\in[0;1]$ for any $A\subseteq\mathbb{N}$ . But for additivity, I can only get to \begin{align}
\mathbb{P}(A\sqcup B)&=\lim_{N\to\infty}\max_{n\geq N}\frac{1}{\pi(n)}|\{\text{primes }p\leq n,\ p\in A\sqcup B\}|\\
&=\lim_{N\to\infty}\max_{n\geq N}\frac{1}{\pi(n)}(|\{\text{primes }p\leq n,\ p\in A\}|+|\{\text{primes }p\leq n,\ p\in B\}|)
\end{align} and in general the maximum of sums need not be equal to the sum of the maxima, so I'm beginning to suspect this is not satisfied. I'm not sure how to prove it though, so could someone help me either way?","['probability-distributions', 'probability-theory', 'probability']"
4560587,What's wrong with this supposedly very simple proof about elementary set theory?,"The following is a simple result in elementary Set Theory: Given $f:A\to B, \,\,X_1,X_2‚äÜA$ , then $f(X_1 \cap X_2) ‚äÜ f(X_1) \cap f(X_2)$ , and it's not necessarily the case that $f(X_1 \cap X_2) = f(X_1) \cap f(X_2)$ I'm aware of the proof of the first fact (and the disproof of the second fact). However, I don't know what's wrong with a proof I'll give to the following false statement: [False statement] Given $f:A\to B, \,\,X_1,X_2‚äÜA$ , then $f(X_1 \cap X_2) = f(X_1) \cap f(X_2)$ Before I give the incorrect proof, I'll first prove a possibly false lemma (possibly false because I really don't know its truth value, though I suspect it is true) (Possibly incorrect) Lemma: $\{x : (x ‚àà S) ‚àß (x ‚àà T)\} = \{x : x ‚àà S\} ‚à© \{x : x ‚àà T\}$ (Possibly incorrect) Proof of the lemma: Any set $S$ can be expressed as $\{x : x \in S \}$ , so it follows that: $(1) \,\,\, S = \{ x : x \in S \}$ $(2) \,\,\, T = \{ x : x \in T \}$ By $(1)$ and $(2)$ , it follows that: $S \cap T = \{ x : x \in S \} \cap \{ x : x \in T \}$ By definition of set intersection: $S‚à©T ‚âú \{x : (x ‚àà S) ‚àß (x ‚àà T)\}$ Therefore: $\{x : (x ‚àà S) ‚àß (x ‚àà T)\} = \{ x : x \in S \} \cap \{ x : x \in T \} ‚àé$ Now I present the definitely incorrect proof: [Incorrect Proof]: By definition of the image of a set under a function f: $f(X_1 ‚à© X_2) ‚âú \{f(x) : x ‚àà (X_1 ‚à© X_2)\}$ The statement "" $x ‚àà (X_1 ‚à© X_2)$ "" is equivalent to the statement "" $(x ‚àà X_1) ‚àß (x ‚àà X_2)$ "", so we can substitute: $f(X_1 ‚à© X_2) = \{f(x) : (x ‚àà X_1) ‚àß (x ‚àà X_2)\}$ By the lemma: $\{f(x) : (x ‚àà X_1) ‚àß (x ‚àà X_2)\} = \{f(x) : (x ‚àà X_1) \} \cap \{f(x) : (x ‚àà X_2)\}$ , so we can substitute: $f(X_1 ‚à© X_2) = \{f(x) : (x ‚àà X_1) \} \cap \{f(x) : (x ‚àà X_2)\}$ By definition of the image of a set under a function f: $f(X_1) ‚âú \{f(x) : x ‚àà X_1 \}$ , and $f(X_2) ‚âú \{f(x) : x ‚àà X_2 \}$ , so we can substitute: $f(X_1 ‚à© X_2) = f(X_1) \cap f(X_2) ‚àé$ What exactly is wrong with this proof? Until now, my exposure to formal proofs in Mathematics was only through The Book of Proof (Richard Hammack), so I definitely lack a lot of skills, though I plan to improve my knowledge of proofs by reading other books. I'd be glad to know where my thinking went astray here. Thank you very much!","['elementary-set-theory', 'solution-verification']"
4560617,Concentration of measure on sphere: Bounding the probability of a large angle,"Fix any $y$ on the sphere $S^{n-1}:=\{x\in\mathbb{R}^n : \|x\|_2=1\}$ .
Let $z$ be a random variable, uniformly distributed on $S^{n-1}$ .
Show that for any $\epsilon\in(0,1/\sqrt{2})$ . $$
\mathbb{P}[|y^Tz|> \epsilon]\leq \left(1-\epsilon^2\right)^{n/2}
$$ This is an exercise left to the reader in Martin Wainwright's High Dimensional Statistics , p. 69.
The author statest that it is a ""geometric calculation"". What I tried: The most promising approach I have is the observation that the term $\sqrt{1-\epsilon^2}$ is the length of the leg of a right-angled triangle with hypotenuse of length 1 and leg of length $\epsilon$ . Such a triangle indeed readily appears when one draws a two-dimensional sphere, and the region $\{x\in\mathbb{R}^n : |y^Tx|>\epsilon\}$ .
But I don't understand how to connect this to the probability in question, and consequentially how to get the exponent $n$ . Can anyone help?","['spheres', 'concentration-of-measure', 'geometry', 'trigonometry', 'probability']"
4560624,Prove that $(\sin x + \cos x)(6 - \sin x)<9$,"Is there any elementary way to prove that $(\sin x + \cos x)(6 - \sin x)<9$ ? I've noticed that $(\sin x + \cos x)$ has to be positive so $x \in\left(-\dfrac{\pi}{4}, \dfrac{3\pi}{4}\right)$ and then $(6 - \sin x)\in\left(6-\dfrac{\sqrt2}{2},6+ \dfrac{\sqrt2}{2}\right)$ but since $(\sin x + \cos x) \in\left(0, \sqrt2\right]$ the maximum possible value of $(\sin x + \cos x)(6 - \sin x)$ can be $(6+ \dfrac{\sqrt2}{2}) * \sqrt2 = 1+6\sqrt2$ which is greater than $9$ . My second attempt was to find the derivative, but I couldn't find its roots.","['algebra-precalculus', 'trigonometry', 'inequality']"
4560626,"Write the sum $\sum\limits_{a \in \mathbb{N}}\sum\limits_{b \in \mathbb{N}} \frac{(a,b)}{a^sb^t}$ in terms of the Riemann zeta function","I have the following exercise, and I need some help: Write the sum $$\sum\limits_{a \in \mathbb{N}}\sum\limits_{b \in \mathbb{N}} \frac{(a,b)}{a^sb^t}$$ in terms of the Riemann zeta function ( $(a,b)$ is the greatest common divisor).
I assume you have to somehow sort the sums for $d:=(a,b)$ , but I have no idea how, any help is appreciated. I tried to use the fact that $d=xa + yb$ and then $$ \frac{(a,b)}{a^sb^t} = \frac{x}{a^{s-1}b^t} + \frac{y}{a^sb^{t-1}}$$ but since I don't know if the original series is convergent or not, I can't use re-arrangements and so I got stuck.","['number-theory', 'gcd-and-lcm', 'dirichlet-series', 'sequences-and-series', 'riemann-zeta']"
4560671,"Disintegration theorem: how to prove that for $\nu$-a.e. $y \in Y$, we have $g\circ \pi=g(y)$ $\mu_y$-a.e.","Theorem 4 of this blog entry of Terrence Tao states that: Let $X$ be a compact metric space, $\mathcal X$ its Borel $\sigma$ -algebra, and $\mu$ a Borel probability measure on $X$ . Let $(Y, \mathcal Y)$ a measurable space, $\pi:X\to Y$ a measurable map, and $\nu := f_\sharp \mu$ . Then there is a collection $(\mu_y)_{y\in Y}$ of Borel probability measures on $X$ , such that for all bounded measurable maps $f:X\to \mathbb C$ and $g:Y\to \mathbb C$ , $$
\int_X f\cdot (g\circ \pi) \mathrm d\mu = \int_Y \left(\int_X f\mathrm d\mu_y\right)g(y)\mathrm d\nu(y) \quad (\star)
$$ for $\nu$ -a.e. $y \in Y$ , $$
g\circ \pi=g(y) \quad \mu_y\text{-a.e.} \quad (\star\star)
$$ At the end of the proof, the author proves $(\star\star)$ by applying $(\star)$ twice, i.e., Finally, we prove $(\star\star)$ . From two applications of $(\star)$ we have $$
\int_Y\left(\int_X f(g \circ \pi) \mathrm d \mu_y\right) h(y) \mathrm d \nu(y) = \int_Y\left(\int_X f g(y) \mathrm d \mu_y\right) h(y) \mathrm d \nu(y)
$$ for all bounded measurable $f: X \rightarrow \mathbb{C}$ and $h: Y \rightarrow \mathbb{C}$ . The claim follows (using the separability of the space of all $f$ ). My question: I could not follow his reasoning here. Could you elaborate on how he obtain $(\star\star)$ ? Thank you so much! Proof: We have the pullback map $$
\pi^\sharp:L^2(Y, \mathcal Y, \nu)\to L^2(X, \mathcal X, \mu), g \mapsto g \circ \pi.
$$ We take its adjoint $\pi_\sharp:L^2(X, \mathcal X, \mu)\to L^2(Y, \mathcal Y, \nu)$ , and have the duality $$
\int_X f(\pi^\sharp g) \mathrm d \mu = \int_Y\left(\pi_{\sharp} f\right) g \mathrm d \nu \quad \forall f \in L^2(X, \mathcal X, \mu), \forall g \in L^2(Y, \mathcal Y, \nu).
$$ From duality that, we have $\|\pi_\sharp f\|_{L^\infty(Y)}\le \|f\|_\infty$ for all $f\in C(X)$ . Since $C(X)$ is separable, we find a measurable representative $\tilde{\pi}_{\sharp} f$ of $\pi_{\sharp} f$ to every $f \in C(X)$ which varies linearly with $f$ , and is such that $|\tilde{\pi}_{\sharp} f(y)| \le \|f\|_{\infty}$ for all $y$ outside of a set $E$ of $\nu$ -measure zero and for all $f \in C(X)$ . We can then apply the Riesz representation theorem to obtain a Radon probability measure $\mu_y$ such that $$
\tilde{\pi}_{\sharp} f(y)=\int_X f \mathrm d \mu_y
$$ for all such $y$ . We set $\mu_y$ equal to some arbitrarily fixed Radon probability measure for $y \in E$ . We then observe that the required properties (including the measurability of $y \mapsto \int_X f \mathrm d \mu_y$ are already obeyed for $f \in C(X)$ . To generalise this to bounded measurable $f$ , observe that the class $\mathcal{C}$ of $f$ obeying the required properties is closed under dominated pointwise convergence, and so contains the indicator functions of open or compact sets (by Urysohn's lemma). Applying dominated pointwise convergence again and inner and outer regularity, we see that the indicator functions of any Borel set lies in $C$ . Thus all simple measurable functions lie in $\mathcal{C}$ , and on taking uniform limits we obtain the claim. Finally, we prove $(\star\star)$ . From two applications of $(\star)$ we have $$
\int_Y\left(\int_X f(g \circ \pi) \mathrm d \mu_y\right) h(y) \mathrm d \nu(y) = \int_Y\left(\int_X f g(y) \mathrm d \mu_y\right) h(y) \mathrm d \nu(y)
$$ for all bounded measurable $f: X \rightarrow \mathbb{C}$ and $h: Y \rightarrow \mathbb{C}$ . The claim follows (using the separability of the space of all $f$ ).","['proof-explanation', 'measure-theory', 'probability-theory', 'metric-spaces']"
4560681,Why is an area preserving diffeomorphism a symplectomorphism (in $R^2$),"Given this very simple sympletic vector space: $\left(\mathbb{R}^2, \mathrm{~d} x \wedge \mathrm{d} y\right)$ , how can we show that an area preserving diffeomorphism $f: \mathbb{R}^2 \rightarrow \mathbb{R}^2$ defines a symplectomorphism? I believe an area-preserving diffeomorphism is a diffeomorphism that preserves the Lebesgue measure (please correct me if this is not the case or if there is a better definition in the context of symplectic geometry), but given that is the case, how can we relate preserving Lebesgue measure to showing that $\mathrm{~d} x \wedge \mathrm{d} y(u,v)=\mathrm{~d} x \wedge \mathrm{d} y (f(u),f(v))$ which is the definition of symplectomorphism where f is our area-preserving diffeomorphism.","['symplectic-geometry', 'symplectic-linear-algebra', 'differential-geometry']"
4560702,Building $\textit{techniques}$ (as opposed to $\textit{concepts}$) for advanced complex analysis,"I'm struggling with the exercises in Stein and Shakarchi's Complex Analysis , and believe what I'm missing is advanced techniques (as opposed to concepts ) in real analysis. The difficulty I consistently have is not with the new material introduced regarding complex analysis, but with techniques assumed (not discussed or presented) of real analysis.  Examples: Replace $\frac{1}{z-a}$ with an infinite geometric series Replace $\sin \theta$ with $2\theta/\pi$ using Jordan's inequality Replace $1 - e^{iz}$ with the power series of $e$ which tends to $-iz$ as $z \to 0$ ( assumed on p.45 of text, explained on math.SE, though I can't find the link) and many other similar cases All these examples have in common: The proof or problem applies a non-trivial technique to go from one step to the next, usually to replace an intractable expression with a tractable one The technique is not discussed in the text The technique applies to real analysis (not complex) The technique is a technique* , as opposed to understanding a concept How, then, can I build my real analysis techniques so that I can follow Stein and Sharakachi? I know real analysis well enough to solve all the problems on a MIT OCW real analysis final (although sometimes with difficulty), but not well enough to solve the problems on a Rudin based course final .  This might suggest to learn real analysis again, using Rudin.  However, looking at the Rudin text and course, I don't see them teaching these advanced techniques but rather more advanced concepts , such as point-set topology and metric spaces beyond the line. What course should I use to learn the techniques needed to approach Stein and Shakarachi, then? Or should I simply work through Stein and Shakarachi, and use  it as a motivator to look up (and learn) new techniques? *By technique I mean a means of simplifying an expression that does not follow directly from the underlying definitions and theorems, but instead is a creative application from elsewhere (such as those discussed here .)  I distinguish technique from concept , which means understanding the objects, definitions, and theorems.  Both of them, of course, are crucial. I'm not the first person to raise this issue .  But the recommendation given there (to first learn complex variable calculus before learning the proofs) seems to miss the point, as the issue, as shown by those examples, is not with complex variables but with techniques from real analysis.","['complex-analysis', 'soft-question', 'real-analysis']"
4560728,How many smooth vector space structures does $\mathbb R^n$ have?,"The title is a bit misleading. I am really asking about how many ways are there to equip $\mathbb R^n$ with a smooth addition $+:\mathbb R^n \times \mathbb R^n \to \mathbb R^n$ so that the (possibly non-standard) addition-map together with the standard scalar multiplication $\mathbb R \times \mathbb R^n \to \mathbb R^n$ give the smooth manifold $\mathbb R^n$ (with its standard smooth structure) the structure of a smooth vector space? A smooth vector space is like an ordinary vector space, only that all involved maps must be smooth. Background: I was learning a little bit of synthetic differential geometry, and while doing that I seemed to have proven that there is only one such smooth addition map on $\mathbb R^n$ once scalar multiplication is fixed. This seemed a bit extreme, so I thought it is time for a reality check. Here is my argument: There is a well adapted model of SDG which sends the smooth manifold $\mathbb R$ to the line object $R$ of the model and which sends $\mathbb R^n$ to the product $R^n$ . We may also choose a model such that each manifold becomes a microlinear space in it. In particular $R^n$ is microlinear (which is one of the axioms of synthetic differential geometry anyway), and it satisfies the Kock-Lawvere axiom. Such an $R$ -vector space is called Euclidean by Lavendhomme. Lavendhomme shows in their book that a map out of any $R$ -vector space $V$ into an Euclidean vector space is already linear if it is homogeneous. Now assume $+'$ is any addition map on $\mathbb R^n$ such that we get a smooth vector space together with standard scalar multiplication. Then we use the embedding of manifolds into the well adapted model to get an addition map on $R^n$ such that the resulting structure is a vector space internal to the model. Let us denote this vector space by $V$ . Since everything except the addition map is fixed, we have that the identity $V \to R^n$ is homogeneous. Since $R^n$ with its standard addition is an euclidean vector space (in the terminology of Lavendhomme, Basic Concepts of Synthetic Differential Geometry), we see that the identity $V\to R^n$ must be linear. But then we see that the two addition maps must agree, and using that the embedding of manifolds into the model is faithful we see that the abitrary addition $+'$ is in fact the standard one. What do you think? Did I make a mistake? I often do stupid stuff when I calculate alone, so reality check please!","['synthetic-differential-geometry', 'smooth-manifolds', 'category-theory', 'differential-geometry']"
4560732,"Proving that if A ‚äÜ B, then ùí´A ‚äÜ ùí´B [duplicate]","This question already has an answer here : Prove Properties of Sets and Powersets [closed] (1 answer) Closed 1 year ago . In an attempt to prove that if $A ‚äÜ B$ , then $ùí´A ‚äÜ ùí´B$ ; I have conjured the following proof: We must show that whenever $X ‚àà ùí´A$ , then $X ‚àà ùí´B$ ; From $X ‚àà ùí´A$ it follows that $X ‚äÜ A$ . If we denote $z$ to be any element in $X$ , then from $X ‚äÜ A$ it follows that $z ‚àà A$ ; And from $A ‚äÜ B$ that $z ‚àà B$ . We have shown that any element of $X$ must be an element of $B$ , hence we say that $X 
‚äÜ B$ . And from this it follows that $X ‚àà ùí´B$ . Therefore we have shown that any element of $ùí´A$ is also an element of $ùí´B$ . The question of interest: is this proof valid? I ask because I am relatively new to forming set-theoretic proofs. Thank you in advance.",['elementary-set-theory']
4560798,Some terminology involving homogeneous ideals in polynomial rings,"I was thinking about a problem that (as I only realized today) can be translated into the language of projective ideals in polynomial rings $-$ i.e. the stuff that defines projective varieties . I am now hoping to make use of the vast body of already existing knowledge on projective algebraic geometry, but I find it hard to find what I need because I don't speak this language very well. So I have a number of questions about what things are called. I hope someone can point me to the right terminology? Suppose $I \subset k[x_0, \ldots, x_N]$ is an ideal, generated by a finite set of homogeneous polynomials, where moreover all these homogeneous generators are homogeneous of the same degree $n$ . Does this number $n$ have a name? Intuitively I would expect it to be the degree of $I$ , but the geometric object $V(I)$ , consisting of the set of points in $\mathbb{P}^N$ on which all elements of $f$ are zero, apparently also has a degree which is defined in term of intersections with hyperplanes. It does not seem obvious to me that the two notions of degree are the same or even related. If they are not, what is my number $n$ called then? Let $I$ and $n$ be as above. Let $H^n$ be the ( $\binom{N + n -1}{n}$ -dimensional) vectorspace of all homogeneous degree $n$ polynomials. (Actually, if there is a more standard notation for $H^n$ I would also like to know.) What is the number $\dim (H^n \cap I)$ called? It is a dimension, but obviously it is not the dimension of the corresponding geometric object $V(I)$ . The space $H^n \cap I$ is what generates $I$ , by assumption. Keeping in mind Wikipedia's view of $I$ as being 'generated by a finite set of homogeneous polynomials' (rather than a vectorspace of homogeneous polynomials), we note that a set $S$ of homogeneous polynomials is a set generating $I$ which is minimal w.r.t. inclusion among all sets with that property, if and only if $S$ is a basis of $H^n \cap I$ . So from that perspective $\dim H^n \cap I$ is perhaps just called the number of generators of $I$ ? But the term 'number of generators' feels a bit ambiguous. It sounds like it depends on some chosen set of generators, that need moreover not be minimal w.r.t. inclusion. Maybe it is some special value of the Hilbert polynomial? The common set of zeros $V(I)$ of $I$ is apparently only called a variety if $I$ is a prime ideal, which, if I recall correctly, happens if and only if $V(I)$ is Zariski-closed. However, when $I$ is not prime, $V(I)$ is still a geometric object $-$ a well defined subset of $\mathbb{P}^N$ . So what is this geometric object called if it is not (necessarily) a variety? A 'shape'? A 'blob'? A 'bunch of points that together exhibit a remarkably smooth and rigid structure, as if they really try to be a variety but then fail at the last moment'? Common sense tells me $V(I)$ must have a Zariski-closure $\overline{V(I)}$ and that associated to that thing there is some ideal, which I now will call $\overline{I}$ by analogy, consisting of all polynomials that vanish on $\overline{V(I)}$ . The question is of course what is $\overline{I}$ called, and what is the standard notation for it. But now that I type this am also wondering what is the relation between $I$ and $\overline{I}$ is. On one hand being zero on a bigger set is a more restrictive condition and I expect $\overline{I} \subset I$ . On the other hand, making the innocuous sounding assumption that polynomials are continuous, we would have that every element of $I$ vanishes on all of $\overline{V(I)}$ and hence $I \subset \overline{I}$ . Together this implies $I = \overline{I}$ . But this would break the relation I thought I remembered between $V(I)$ being closed or not and $I$ being prime or not. So somewhere I am making a mistake, but where? (I am pretty sure I knew the answer to this conundrum 20 years ago, but now I am at a loss. I hope someone can help me)","['notation', 'algebraic-geometry', 'terminology']"
4560827,Efficient way to verify if pair of numbers are medians of partition of sets,"Given a multi-set of multi-sets $\mathcal{S} = \{S_1, \ldots,S_i, \ldots, S_n \}, S_i \subset \mathbb{R}$ . Denote powerset of $\mathcal{S}$ as $\mathbb{P}(\mathcal{S})$ . My question is, given a pair $(x, y) \in \mathbb{R}^2$ , how can one efficiently verify $\exists P \in \mathbb{P}(\mathcal{S})$ such that, $\textbf{median}(\cup_{I \in P} I) = x$ and $\textbf{median}(\cup_{J \in \mathcal{S} \setminus P} J) = y$ ?","['elementary-set-theory', 'computational-complexity', 'median']"
4560829,How do I deal with the basis in the proof of Lemma 1.10 in Introduction to smooth manifolds by John Lee?,"This is Lemma 1.10 in Introduction to smooth manifolds by John Lee , 2nd edition. Lemma 1.10. Every topological manifold has a countable basis of precompact coordinate balls. Proof . Let $M$ be a topological $n$ -manifold. First we consider the special case in which $M$ can be covered by a single chart.
Suppose $\varphi: M \to \hat U \subseteq \mathbb{R}^n$ is a global
coordinate map, and let $\mathscr{B}$ be the collection of all open
balls $B_r(x)\subseteq  \mathbb{R}^n$ such that $r$ is rational, $x$ has rational coordinates, and $B_{r'}(x)\subseteq  \hat U$ for some $r' > r$ . Each such ball is precompact in $\hat U$ , and it is easy
to check that $\mathscr{B}$ is a countable basis for the topology of $\hat U$ . Because $\varphi$ is a homeomorphism, it follows that the collection of sets of the form $ \varphi^{-1}(B)$ for $ B \in \mathscr{B}$ is a countable basis for the topology of $M$ ;
consisting of precompact coordinate balls, with the restrictions of $\varphi$ as coordinate maps. My question is about checking  that the $ \varphi^{-1}(B)$ for $ B \in \mathscr{B}$ are a countable basis for the topology of $M$ First of all is it correct that to prove that a set is a basis of a topology it suffices to prove that the any element of the topology is a union of element of basis elements?
According to wikipedia the following is the definition. But I think I have read proofs were they just do as I described. Are they equivalent definitions? About the question I guess I can prove it like this:
Let $\mathscr{B}$ be a basis for the topology of $\hat U$ . Let $U \in \tau_M$ , then $ \varphi(U) \in \tau_{\hat U}$ , because $\varphi$ is a homeomorphism  and $\varphi(U)=\bigcup_{i \in I}B_i,  B_i \in \mathscr{B}  \implies U = \varphi^{-1}(\bigcup_{i \in I}B_i)=\bigcup_{i \in I}\varphi^{-1}(B_i) $ and since I have written any open set of $\tau_M$ as union of elements of $\{\varphi^{-1}(B):, B \in  \mathscr{B} \}$ , this last set is a basis for $\tau_M$ . Is this correct? Thank you!","['manifolds', 'general-topology', 'differential-geometry']"
4560838,How to think about a basic combinatorial question,"Let's say we have 20 individuals and need to assign them each one of 20 jobs. This is a pretty standard introductory level question in the combinatorics background presented in a probability theory course. One solution says: line up the individuals in a row, then for the first one, you have 20 choices of job, for the second you have 19, and so on. Meaning there are 20! potential ways to assign the jobs. What I find confusing about this example is the fact that you actually started with 20! ways to order the individuals in a row to begin with. One might be tempted to think that, due to the multiplication rule, there are actually $(20!)^2$ ways to assign the jobs. Further reflection reveals: yes, indeed, there are $(20!)^2$ person/job pairs where we care which appears first, second, third, etc in the row. But since we're not being asked to designate a first, second, third, etc. pair we need to correct for the over-counting. Each set of 20 person-job pairs can be ordered $20!$ ways, so we have the correct answer as: $(20!)^2 /  20! = 20!$ Is the above reasoning sound? When we approach a problem like this one by imagining lining up the people or objects to be labeled/chosen, are we ""automatically""/implicitly adjusting for the over-counting that I've somewhat painfully accounted for explicitly above?",['combinatorics']
4560849,Langrange Multiplier to Function $x^2-y^2-z^2$,"Im Trying To Find The min and max values of function $$f(x, y, z) = x^2-y^2-z^2$$ At constraint $g(x, y, z) = x^2+y^2+z^2-1$ . My Solution : I'm using gradient to find the partial derivatives of each variables so : $\nabla f'(x, y, z) = <2x, -2y, -2z>$ $\nabla g'(x, y, z) = <2x, 2y, 2z>$ Set up : $$\nabla (f) = \lambda \nabla(g)$$ $$ 2x = \lambda(2x)$$ $$-2y = \lambda(2y)$$ $$-2z = \lambda(2z)$$ At $x^2+y^2+z^2-1$ Solving for $\lambda$ : $$\lambda = \frac{2x}{2x} = 1$$ $$\lambda = -\frac{2y}{2y} = -1$$ $$\lambda = -\frac{2z}{2z} = -1$$ Im basically stuck at here because the lambdas are not giving any variable and only constant to sub into the constraint (which is confusing). Anyone can tell me what i did wrong here? Ps: i'm writing on a touch device.","['multivariable-calculus', 'calculus', 'lagrange-multiplier']"
4560854,Using the combinational proof template for discrete mathematics is this a valid polished proof?,"Let $k, m, n$ be positive integers such that $n\geq k\geq m\geq 0$ .  Then, ${n\choose k} {k\choose m} = {n\choose m} {{n-m}\choose {k-m}}.$ Here is my Polished Proof: Claim: Suppose $k$ , $m$ , and $n$ are positive integers such that $n\geq k\geq m\geq 0$ . Then, ${n\choose k} {k\choose m} = {n\choose m} {{n-m}\choose {k-m}}.$ Proof: To prove ${n\choose k} {k\choose m}$ $=$ $ {n\choose m} {{n-m}\choose {k-m}}$ let's imagine that we have a class of $n$ people and we will choose $k$ of them to form a committee, of those on the committee we will choose $m$ of them to be on the subcommittee. We will consider the question: How many $k$ -element subsets of people does the set $\{1,2,3...,n  \}$ have, and of $k$ people how many, $m$ -element subsets of people does $k$ have? Answer 1: Given $n$ people, we can form a committee of size $k$ in ${n\choose k}$ ways to get $k$ -element subsets. Once the committee is selected, we can form a subcommittee of size $m$ in ${k\choose m}$ ways to get $m$ -elements. Thus, we can form $k$ -element subsets of $n$ and $m$ -element subsets of $k$ by ${n\choose k} {k\choose m}$ . Answer 2: On the other hand, we can achieve the same total of ways by  forming a subcommittee of size $m$ in ${n\choose m}$ ways to get $m$ -element subsets. Once we have selected the subcommittee we can form a committee of the remaining size of $(k-m)$ in ${{n-m}\choose {k-m}}$ to get $(k-m)$ -element subsets. We choose $(k-m)$ people from $(n-m)$ people because we have already selected $m$ people for the subcommittee. Thus, we can form $m$ -element subsets of $n$ and $(k-m)$ -element subsets of $(n-m)$ by ${n\choose m} {{n-m}\choose {k-m}}$ . Since answers 1 and 2 are correct solutions to the same question, ${n\choose k} {k\choose m}$ $=$ $ {n\choose m} {{n-m}\choose {k-m}}$ .//","['binomial-coefficients', 'combinatorial-proofs', 'discrete-mathematics']"
4560855,Simplest function sufficient to categorize a square,"Background Let $p_i=(x_i,y_i)$ with $i\in \{1,2,3,4\}$ define four (possibly repeating) points in the plane. Let $f(a,b,c)$ be any function with the property that $$f(a,b,c)=f(a,c,b)=f(b,a,c)=f(b,c,a)=f(c,a,b)=f(c,b,a)$$ That is, the output of $f$ is independent on any permutations of the inputs. Finally, define $$S_1=f(d(p_1,p_2),d(p_1,p_3),d(p_1,p_4))$$ where $d(a,b)$ is the standard Euclidean distance (although this could really be any metric). In a similar manner, define $S_2,S_3,$ and $S_4$ . We say that a function $f$ categorizes a square if $$S_1=S_2=S_3=S_4\Leftrightarrow \text{The points }p_1,p_2,p_3,p_4\text{ define a square}$$ Obviously, the $\Leftarrow$ implication is self-evident (at least if one considers four identical points a square). This leaves the question of what functions $f$ imply that the points $p$ form a square? Question: What is the simplest such function $f$ which categorizes a square? In this question, 'simple' can be taken to mean: cleanest, neatest, easiest to compute, etc. Work so far: The obvious choice for $f$ is $$f(a,b,c)=a+b+c$$ By almost any definition, this is probably the simplest function which could possibly categorize a square (this is opposed to constant $f$ which definitely does not categorize the square). However, I could not prove that this function works although I can show it for the following function: $$f(a,b,c)=\left(\frac{\max\{a,b,c\}}{\sqrt{2}}-\min\{a,b,c\}\right)^2+\left(a+b+c-\max\{a,b,c\}-2\min\{a,b,c\}\right)^2+\min\{a,b,c\}$$ This function evaluates to $\min\{a,b,c\}$ if the two shorter distances are equal and the longest distance is equal to the shorter distances after being stretched by a factor of $\sqrt{2}$ . To prove this function categorizes a square, it is sufficient to prove cases depending on how many of the lengths amongst the four points equal the absolute minimum length (in a square, its four of the lengths). Since $\binom{4}{2}=6$ , one simply has to check the cases: $$\text{There is $1$ unique minimum distance among $6$ lengths}$$ $$\text{There are $2$ equal minimum distances among $6$ lengths}$$ $$\vdots$$ $$\text{There are $5$ equal minimum distances among $6$ lengths}$$ (the case where all the distance are equal is impossible). After going through the logic, one can show that in all cases but the case with $4$ equal minimum distances that $S_i\neq S_j$ for some $i,j\in\{1,2,3,4\}$ . Then in this case, you can show that this corresponds to a square.","['euclidean-geometry', 'soft-question', 'geometry', 'plane-geometry']"
4560873,High first singular value for random matrix,I have a 100 by 100 matrix of random entries. The SVD of the matrix shows that the first singular value is quite high and the rest are substantially lower. I know that this first singular value is the best rank one approximation of the matrix but why is it so much higher than the other values?,"['matrices', 'linear-algebra', 'svd']"
4560935,I wrote a probability question I can't solve,"$\newcommand{\nCk}[2]{{}^{#1}C_{#2}}$ I wrote this question to prep my students for their midterm, and I realized when I sat down to solve it that I can't figure out the right way to think about it. A costume shop has $7$ costumes available to rent, $4$ of each. You and $9$ friends go to the costume shop independently and each pick a costume. What is the probability you arrive at the party and there are exactly $5$ distinct costumes? (You are the only 10 guests) I know from simulation that the solution should be something like $0.232402$ , perhaps it is $\nCk{7}{5}\cdot 48\cdot\frac{\nCk{15}{5}}{\nCk{28}{10}}$ . I can justify the $\nCk{7}{5}$ and the $\nCk{15}{5}$ in the numerator, but not the $48$ . $\nCk{7}{5}$ because of the $7$ costumes $5$ are chosen. We need to ensure that $1$ of each are worn by $5$ guests, but the other $5$ are free to choose from the $15$ (hence $\nCk{15}{5}$ ). But I'm sure I'm thinking about this not quite right. I'd love any explanations. Thanks!","['combinations', 'probability']"
4560956,Minimal polynomial of $\cos\left(\frac{\pi}{13}\right)$,"Find the Minimal polynomial of $\cos\left(\frac{\pi}{13}\right)$ .
My try: Let $$13 \theta=\pi \implies 9\theta=\pi-4\theta$$ $$\implies \cos(9\theta)=-\cos(4\theta)$$ Now Let $x=\cos(\theta)$ $$\implies 4(4x^3-3x)^3-3(4x^3-3x)=-(2(2x^2-1)^2-1) $$ $$\implies 256 x^9-576 x^7+432 x^5+16x^4-120 x^3-16 x^2+9x+2=0$$ Now how to test that this is Minimal?","['trigonometry', 'polynomials', 'minimal-polynomials']"
4560985,Result analogous to the Central Limit Theorem if the third moment is also finite,"Motivation Let $\{X_n\}_{n \in \mathbb{N}}$ be a sequence of i.i.d. random variables that have finite first moment. Let $S_n =\sum_{i=1}^n X_i$ . We have the Law of Large Number $$
n^{-1}S_n \to \mathbb{E}[X_1] \quad \text{a.s.}
$$ We can view $n^{-1}S_n$ as converging (in some sense) to $\mathbb{E}[X_1]$ , which is a (degenerate) random variable that has the same first moment as $X_n$ . In the meantime, if we assume finite second moment, we also have the Central Limit Theorem, $$
n^{-\frac{1}{2}}S_n \overset{d}{\longrightarrow} N(\mathbb{E}[X_1],\text{Var}[X_1]).
$$ We can view $n^{-\frac{1}{2}}S_n$ as converging to a random variable that has the same first and second moments as $X_1$ . The takeaway is, for the above two cases, we can always find: 1) a notion of probability convergence; 2) a random variable that matches the corresponding moments of $X_1$ ; 3) a proper exponent $\alpha$ that is put in front of $S_n$ -- that make $$
n^{-\alpha}S_n \to Y
$$ hold. Question For the same i.i.d. sequence, if we further assume that its third moment is finite, can we get an analogous result? The form of the result is likely to be $$
n^{-\alpha}S_n \to Y,
$$ where $\alpha$ is some positive number, $Y$ is a random variable with the same first three moments as $X_1$ , and the concept of convergence is something that is well-defined. Moreover, for even higher orders, do we have a general result for this analogy?","['central-limit-theorem', 'real-analysis', 'law-of-large-numbers', 'probability-theory', 'probability']"
4561011,Find $C$ such that $\frac{1}{n}\prod_{k=1}^{n}C\left(\cos{\frac{k\pi}{2(n+1)}}+\sin{\frac{k\pi}{2(n+1)}}-1\right)$ converges to a positive number.,"I'm looking for the value of $C$ such that $L=\lim\limits_{n\to\infty}\frac{1}{n}\prod\limits_{k=1}^{n}C\left(\cos{\frac{k\pi}{2(n+1)}}+\sin{\frac{k\pi}{2(n+1)}}-1\right)$ equals a positive real number. Desmos suggests $C\approx 4.5395$ . I'm looking for a closed form. (I'm not so interested in the value of $L$ , but I wouldn't mind knowing that also; desmos suggests $L\approx 0.8817$ .) Context: This question is related to another question about an infinite product involving a quarter-circle inscribed in a square. ( $C$ in this question seems to equal $\frac{\pi}{4}A$ in the other question.) I think this question is interesting by itself, so I'm asking it here. My attempt: I have tried to take the log of the product and relate the resulting sum to an integral, but I do not know how to deal with the $\frac{1}{n}$ and also the $(n+1)$ . I have considered using complex numbers, but I do not know how that could be done.","['infinite-product', 'limits', 'closed-form']"
4561018,Why do so many primes such that $2^q\equiv4\pmod{q+2}$ end in $7$?,"Originally, I was investigating the divisibility of $p^q-q^p$ by $p+q$ for primes $p,q$ , but I quickly discovered that even $p=2$ is not easy at all. When $p=2$ , we have $2^q-q^2\equiv0\pmod{q+2}\iff2^q\equiv4\pmod{q+2}$ , or equivalently, $\operatorname{ord}_{q+2}(2)\mid(q-2)$ . We know that $q$ cannot be $3$ modulo $10$ , as otherwise it is necessary that $2^{10k+3}\equiv4\pmod5$ , but this is a contradiction. We also see that $q=5$ satisfies the congruence, but subsequent solutions up to $\approx10^{11}$ seem to display a pattern. \begin{array}{cccccc}\hline\small6462647&\small259195007&\small1654549877&\small22442226767&\small41344905167&\small53085400877&\small86123562527\\\small130647917&\small277628447&\small12746032157&\small\color{red}{22677320759}&\small46649950877&\small77652121367&\small\color{red}{105780380351}\\\small218206487&\small1043030837&\small19745250527&\small26427995687&\small46726848677&\small82396696727&\small149661517007\\\hline\end{array} Why are solutions with $7$ modulo $10$ so common?","['number-theory', 'modular-arithmetic', 'prime-numbers']"
4561091,Is every function eligible as a boundary condition?,"Consider the Laplace equation on unit square domain: $$
u_{xx} + u_{yy} = 0, 0 < x < 1, 0 < y < 1
$$ I wondered whether there is any boundary condition that wouldn't let this equation have a solution. Suppose the boundary condition is $u(t,0) = u(t,1) = u(0,t) = u(1,t) = f(t)$ for some real-valued function $f$ . I thought $f$ would need to be ""pathological"". The candidates I came up in mind were: Dirichlet's function: Though this candidate might let the equation seem unsolvable at first glance, my intuition tells that the solution would be $u = 0$ anyway, for Dirichlet's function is zero almost everywhere. Thomae's function: This suffers from the same argument as above. Not to mention that Thomae's function is Riemann-integrable. Cantor's staircase: This really would make the equation seem weird, but still, my intuition tells that the usual methods of solving PDE, such as separation of variables, superposition principle, and Fourier transform, would go through well anyway. Minkowski's question-mark: Again, this suffers from the same argument as above. Weierstrass' function: Would being nowhere differentiable make it? Hell if I know. Indicator function on Vitali set: Now I'm talking about non-measurability. Dang. Is there an example of such $f$ ? Or to loosen the requirements, is there any instance of Laplace equation whose boundary condition doesn't let a solution to be there?","['partial-differential-equations', 'examples-counterexamples', 'real-analysis']"
4561103,Characterizing Lie groups where every core-free subgroup is trivial,"A subgroup, $H\subset G$ , is called core-free if $H$ contains no non-trivial normal subgroups of $G$ . One can define $\text{Core}_G(H)$ to be the largest normal subgroup of $G$ contained in $H$ . The core-free subgroups, $H\subset G$ , are exactly those with $\text{Core}_G(H)=1$ . I am interested in characterizing all Lie groups, $G$ , such that all of its core-free subgroups are trivial. That is, I am looking for all groups $G$ where $\text{Core}_G(H)=1$ implies $H=1$ . Example 1: Every subgroup, $H\subset G$ , of an abelian group, $G$ , is also a normal subgroup, $H\lhd G$ . Normal subgroups have $\text{Core}_G(H)=H$ . Thus, when $G$ is abelian we have that $\text{Core}_G(H)=1$ is logically equivalent to $H=1$ . Example 2: The above proof actually holds for all Dedekind groups, $G$ . Example 3: A non-Dedekind example is discussed here . But is there a full characterization of these groups? I am particularly interested in the case where $G$ is a Lie group although a result about finite groups could also be interesting.","['group-theory', 'finite-groups', 'lie-groups']"
4561247,"Find $||\vec{w}||$ where $ ||\vec{u}|| = ||\vec{v}|| = 1$, $\vec{u} + \vec{v} + \vec{w} = 0$, and $\vec{u} \perp \vec{v}$","I was requested to find $||\vec{w}||$ where $i) \space \space ||\vec{u}|| = ||\vec{v}|| = 1$ , $ii) \space \space \vec{u} + \vec{v} + \vec{w} = 0$ , and $iii) \space \space \vec{u} \perp \vec{v}$ . I am very new to multivariate calculus and was wondering if my solution is correct. Here is what I attempted. $I$ . From $ii$ it follows that $\vec{u} + \vec{v} = -\vec{w}$ . It is clear from the definition of a norm that that $||\vec{w}|| = ||-\vec{w}||$ , since negative components are squared and hence always become positive. Therefore, $||w|| = ||\vec{u} + \vec{v}||$ . $II$ . $\vec{u} + \vec{v}$ can be thought of as the diagonal of the parallelogram with sides $\vec{u}$ and $\vec{v}$ . Because $\vec{u}$ and $\vec{v}$ have equal lengths $(i)$ and are orthogonal $(iii)$ , such paralellogram is a square. Therefore $\vec{u} + \vec{v}$ is the diagonal of a square with sides of length $1$ $(i)$ . $III$ . From $II$ it follows that, by application of Pythagoras theorem, $||\vec{u} + \vec{v}|| = \sqrt{||\vec{u}||^2 + ||\vec{v}||^2} = \sqrt{1^2 + 1^2} = \sqrt{2}$ . From $I$ we have $||\vec{u} + \vec{v}|| = ||w||$ . Therefore, $||||\vec{w}|| = \sqrt{2}$ . I am aware that this may be a simple problem. However, I am only starting to build a basic understanding of multivariate calculus, and since I self study I don't have teachers to tell me whether my solutions are right or wrong (specially in problems that involve demonstrations rather than mere calculations). I would highly appreciate $a)$ validation/correction of my proof, and $b)$ alternative proofs or ways to solve the problem. Thanks in advance!","['multivariable-calculus', 'linear-algebra', 'geometry']"
4561289,"Show that for any $n$, there are infinitely many cubes of the form $2^na - 9$.","Show that for any $n$ , there are infinitely many cubes of the form $2^na - 9$ . Progress: We use induction on $n.$ For $n=1$ it works. Say it works for $n-1$ . We will show for $n$ . Note that $2^na-9$ is $$2^{n-1}2a-9.$$ If we have infinite $a$ such that $a$ is even for $n-1$ , then we are done. Else, only finite amounts of $a$ are even. So after a large constant $N$ , we have $2^{n-1}a-9=x^3$ for only odd $a$ . So say $$2^{n-1}a_1-2^{n-1}a_2=u^3-w^3\implies 2^{n-1}|u^3-w^3$$ But I couldn't get anything further. I thought about taking $v_2$ , as in, if $2^na=x^3+9$ then we can take $x=y^2$ . So we have $$2^na=y^2+3^2.$$","['contest-math', 'number-theory', 'elementary-number-theory']"
4561299,Intrinsic curvature of transverse metric,"Suppose we have a hypersurface $f(x^\mu)=0$ (with $\mu=0,1,...,d-1$ ) in a manifold with metric tensor $g_{\mu\nu}$ . The transverse metric is defined as $$h_{\mu\nu}=g_{\mu\nu}-n_\mu n_\nu,$$ with $$n_\mu=\frac{\partial_\mu f}{\sqrt{|\partial_\nu f \partial^\nu f|}}.$$ It is used to define the extrinsic curvature of the hypersurface: $$K_{\mu\nu}=h^\alpha_{~~\mu} h^\beta_{~~\nu}\nabla_\alpha n_\beta$$ Does it have any sense computing the Riemann (intrinsic) curvature tensor for $h_{\mu\nu}$ ? What would it mean? Would it be related to the extrinsic curvature?","['tensors', 'general-relativity', 'curvature', 'differential-geometry']"
4561358,Quotient of generalised hypergeometric series ${}_3 F_2$,"I have a function, defined for $x>0$ as $$f(x) = (1+x)^3 \cdot \frac{{}_3F_2\left(\left\{1,\frac{1}{2}+\frac{1}{2x},\frac{1}{2x}\right\},\left\{1+\frac{1}{2x},\frac{3}{2}+\frac{1}{x}\right\},1\right)}{{}_3F_2\left(\left\{1,\frac{1}{2}+\frac{1}{2x},\frac{1}{2}+\frac{1}{2x}\right\},\left\{\frac{3}{2}+\frac{1}{2x},\frac{3}{2}+\frac{1}{x}\right\},1\right)}$$ and I was wondering if it is possible to say anything about the quotient of the hypergeometric series? In particular, I would like to say something about the monotonicity of $f$ . I believe that $f$ is strictly increasing but I don't know how to show it. I would really appreciate some help!","['monotone-functions', 'analysis', 'real-analysis', 'functions', 'hypergeometric-function']"
4561394,Do the connected sets determine the topology in the case of manifolds?,"Let $f:M\to S$ be a bijection between two spaces, at least one of which (without loss of generality, $M$ ) is known to be a manifold. Suppose $f$ preserves and reflects connected sets, meaning $X\subseteq M$ is connected iff $f(X)$ is connected. Must $f$ be a homeomorphism? It seems to me that the answer is yes, but I'm having trouble formalizing the argument. I think if we prove this for $M=\Bbb R^n$ then we can conclude it for all $n$ -manifolds. I believe I have a proof for $n=1$ , but I'm having trouble with $n=2$ .","['general-topology', 'connectedness']"
4561405,Translate an English sentence having exactly/only one condition in First Order Logic,"Our job is to translate the following sentence to first order logic: "" The public university in Melbourne was built on the land of the Torres Strait Islander peoples. "" We can only use one variable: u which represents all universities. We can only use the following two predicates: Public(u) , and TorresLand(u) and u represents a university. How do I go about translating this sentence? From what I understand, I can translate like this: $‚àÉu$ [Public( $u$ ) $‚àß$ TorresLand( $u$ )] But it look like that ""The public university"" implies only one public university is present at the given location. How do I translate the requirement of exactly/only one into First Order Logic? EDIT:
Based on one of the answers provided below, I am providing another predicate Melbourne(u) to preserve info about the location of the public university. Based on this new info, is my answer below correct: ‚àÉu [(Public(u) ‚àß Melbourne(u) ‚àß ‚àÄv(Public(v) ‚àß Melbourne(v) ‚Üí v = u) ‚àß TorresLand(u)]","['first-order-logic', 'predicate-logic', 'logic', 'discrete-mathematics']"
4561406,$L^2$ convergence in the product measure implies convergence when the quadratic variation is absolutely continuous.,"(This question is partially related to another one on this forum.) In Karatzas and Shreve, II edition, Chapter 3, we see in equation (2.2) the definition of the following measure on the product space $[0,\infty)\times\Omega$ $$
\mu_M(A) = \mathbb{E}\left[\int_0^{\infty}1_{A}(s,\omega)d\left<M\right>_s(\omega)\right] \quad (1)
$$ where $M$ is a continuous square integrable martingale and $A\in\mathcal{B}([0,\infty))\otimes\mathcal{F}$ is a measurable set of the product sigma algebra. So if $t\rightarrow\left<M\right>_t(\omega)$ is absolutely continuous (for almost all $\omega\in\Omega$ ) with respect to the Lebesgue measure $\lambda$ we have that the measure in $(1)$ becomes $$
\mu_M(A) = \mathbb{E}\left[\int_0^{\infty}1_{A}(s,\omega)f(s,\omega)ds\right] = \int_{\Omega}\left(\int_0^{\infty}1_{A}(s,\omega)f(s,\omega)ds\right)d\mathbb{P}\quad (2)
$$ with $f(s,\omega)\geq 0$ . Later, in Lemma 2.4, it is stated and proved that if $X$ is a bounded, measurable and adapted process then there exists a sequence $\xi^{(n)}$ of simple processes such that $$
\sup_{t>0}\lim_{n\rightarrow\infty}\mathbb{E}\left[\int_0^t(\xi^{(n)}_s-X_s)^2ds\right] = 0\quad (3)
$$ I understand that this is $L^2$ convergence in the product measure $\lambda\otimes\mathbb{P}$ defined on the product $\sigma$ algebra $$
\left(\lambda\otimes\mathbb{P}\right)(A\times B) = \lambda(A)\mathbb{P}[B]
$$ In fact the $(3)$ is equivalent to the integral with respect to $\lambda\otimes\mathbb{P}$ , i.e. $$
\int_{\left[0,\infty\right)\times\Omega}g(s,\omega)d\left(\lambda\otimes\mathbb{P}\right) = \int_{\Omega}\left(\int_{0}^{\infty}g(s,\omega)ds\right)d\mathbb{P}
$$ for a $\lambda\otimes\mathbb{P}$ -measurable+integrable function $g$ . Since $L^2$ convergence implies convergence in measure, we get that for all $\varepsilon>0$ it holds $$
\int_{\Omega}\left(\int_{0}^{\infty}1_{\{\left|\xi^{(n)}_s(\omega)-X_s(\omega)\right|>\varepsilon\}}ds\right)d\mathbb{P}\rightarrow 0.
$$ The problem is: can I conclude now that $$
\int_{\Omega}\left(\int_{0}^{\infty}1_{\{\left|\xi^{(n)}_s(\omega)-X_s(\omega)\right|>\varepsilon\}}f(s,\omega)ds\right)d\mathbb{P}\rightarrow 0.
$$ where $f$ is defined in $(2)$ ? Should $f$ be bounded, the implication would be obvious. But can I assume that $f$ is bounded? I think I am missing something important.","['measure-theory', 'lebesgue-measure', 'stochastic-processes', 'absolute-continuity', 'quadratic-variation']"
4561407,"Creation/computation of ""Two not touch"" puzzles","This is a mathematical and algorithmic question, so I hope it is not flagged for failing to be a pure mathematical question. The puzzle ""Two not touch"" (or Star Battle ) consists of a $10 \times 10$ grid array fully tiled with irregularly shaped contiguous regions, for instance: The task is to place (20) stars in the grid cells such that: There are exactly two stars in each row There are exactly two stars in each column There are exactly two stars in each contiguous tiled region No two stars ""touch,"" that is, are adjacent vertically, horizontally, or on diagonally adjacent squares My question isn't about how to solve such a puzzle.  It is instead how to algorithmically/mathematically create a valid puzzle that has a (single) unique solution, as such puzzles ensure. I have little doubt that the first step is to randomly assign two cells (for ""virtual stars""... where the solution stars must fall) in each row and each column in a blank (un-tiled) grid, obeying the ""not touch"" constraint.  This is quite a simple algorithm. Next comes drawing the tiled regions.  It is fairly straightforward to draw contiguous regions that bound just two of the virtual stars. Question :  How does one ensure that the tiled regions admit just a single unique puzzle solution?","['puzzle', 'combinatorics', 'constraint-programming']"
4561442,"Using complex analysis, show that $\int_0^\infty\frac{\arctan(x)}{1+x^2}\,dx=\frac{\pi^2}8$","The result is of course confirmed by substituting $x\mapsto\tan(x)$ : $$I = \int_0^\infty \frac{\arctan(x)}{1+x^2} \, dx = \int_0^{\frac\pi2} x \, dx = \frac{\pi^2}8$$ Or integrating by parts: $$I = \lim_{x\to\infty} \arctan^2(x) - I \implies 2I = \left(\frac\pi2\right)^2 \implies I = \frac{\pi^2}8$$ Or splitting the integral at $x=1$ and substituting $x\mapsto\frac1x$ on the integral over $[1,\infty)$ : $$I= \int_0^1 \frac{\arctan(x) + \arctan\left(\frac1x\right)}{1 + x^2} \, dx = \frac\pi2 \int_0^1 \frac{dx}{1+x^2} = \frac{\pi^2}8$$ Or differentiating under the integral sign: $$I(a) = \int_0^\infty \frac{\arctan(ax)}{1+x^2} \, dx \implies I'(a) = \int_0^\infty \frac x{(1+x^2)(1+a^2x^2)} \, dx = \frac{\ln(a)}{a^2-1} \\ I(0) = 0 \implies I(1) = \int_0^1 \frac{\ln(x)}{x^2-1} \, dx = \frac{\pi^2}8$$ Or getting the same integral of $\frac{\ln(x)}{x^2-1}$ by converting $\arctan(x)$ to an integral representation and computing the resulting double integral (per @Dr.WolfgangHintze's suggestion) using the same substitution as in the third method above: $$\begin{align*}
I &= \int_0^\infty \int_0^x \frac x{(1+x^2)(1+x^2y^2)} \, dy \, dx \\[1ex]
&= \int_0^\infty \int_y^\infty \frac x{(1+x^2)(1+x^2y^2)} \, dx \, dy \\[1ex]
&= \frac12 \int_0^\infty \frac{\ln\left(\frac{y^2+y^4}{1+y^4}\right)}{y^2-1} \, dy \\[1ex]
&= \int_0^\infty \frac{\ln(y)}{y^2-1} \, dy + \frac12 \int_0^\infty \frac{\ln(1 + y^2)}{y^2-1} \, dy - \frac12 \int_0^\infty \frac{\ln(1+y^4)}{y^2-1} \, dy \\[1ex]
&= (1 + 2 - 2) \int_0^1 \frac{\ln(y)}{y^2-1} \, dy = \frac{\pi^2}8
\end{align*}$$ I was wondering how, if at all possible, one might approach it with the residue theorem? I see that $z=\pm i$ are simple poles of $\frac1{1+z^2}$ , but they're also the branch points of $\arctan(z)$ , since $$\arctan(z) = -\frac i2 \log\left(\frac{i-z}{i+z}\right)$$ so I don't believe the theorem can be readily applied here. The integrand is odd so I don't think there's much to infer from symmetry. Maybe there's a way to massage the integrand to get closer to something with which we can use a contour integral.","['complex-analysis', 'residue-calculus', 'definite-integrals']"
4561475,Is the limit of approximate eigenvectors an eigenvector?,"Suppose $\mathcal{H}$ is a Hilbert space $H:\mathcal{H}\to\mathcal{H}$ is a self-adjoint operator. If $\lambda\in\sigma(H)$ , then we have a sequence of vectors $\{\phi_n\}\subset\mathcal{H}$ with unit norm, $\|\phi_n\|=1$ , such that $$\lim_{n\to\infty}\|(H-\lambda)\phi_n\| = 0\, .$$ If we suppose that $\phi_n$ converges to $\phi\in\mathcal{H}$ (i.e. $\phi_n\to\phi$ ) will $\phi$ be an eigenvector of $H$ ? This is true if $H$ is bounded as $$\begin{align}\|(H-\lambda)\phi \| &\leq \|(H-\lambda)(\phi-\phi_n)\| +\| (H-\lambda)\phi_n\|\\
&\leq \|H-\lambda\|\|\phi-\phi_n\| + \|(H-\lambda)\phi_n\|\to 0 
\end{align}\, ,$$ by the assumption that $H$ (and hence $H-\lambda$ ) is bounded and that $\phi_n$ is a sequence of approximate eigenvectors. If it is not true for unbounded $H$ , can someone provide an example? Are there extra criteria one can impose on unbounded $H$ to make the statement true?","['self-adjoint-operators', 'spectral-theory', 'functional-analysis', 'eigenvalues-eigenvectors']"
4561543,Restriction of Gaussian measure,"In these lecture notes, exercise 3.39 is posed:
Let $\tilde B, B$ be Banach spaces, and $\mu$ be a Gaussian measure on $B$ . If $\tilde B$ is continuously embedded into $B$ and $\mu(\tilde B)=1$ , then the ""restricted"" measure $\tilde \mu$ on $\tilde B$ defined by $$\tilde\mu(A)=\mu(A), \quad A\in\mathcal{B}(\tilde B)$$ is Gaussian. Questions: How can we show $\tilde\mu$ is Gaussian? Is the Cameron-Martin spaces and corresponding Cameron-Martin norms the same? Thoughts: One first has to show that the embedding $$j:B'\rightarrow \mathcal{R}_\mu,$$ where $B'$ is the dual space and $\mathcal{R}_\mu$ is the $L^2(B,\mu)$ -closure of $B'$ , extends to an embedding $$\tilde j: \tilde B'\rightarrow \mathcal{R}_\mu$$ Then, to me it looks like $\|f\|_{L^2(B,\mu)}=\|f\|_{L^2(\tilde B,\tilde\mu)}$ for $f\in L^2(B,\mu)$ . Does this mean that $\mathcal{R}_{\tilde \mu}$ , the $L^2(\tilde B,\tilde \mu)$ -closure of $\tilde B'$ equals $\mathcal{R}_\mu$ ? We know elements in $\mathcal{R}_\mu$ are $L^2(B,\mu)$ Gaussian random variables (by an $L^2$ -limit argument of approximating sequence in $\mathcal{R}_\mu \cap B'$ ). To me this means $\tilde l \in \tilde B'$ satisfy $\tilde l(X)$ is Gaussian for $X\sim \mu$ , so we are not there yet. I am a little confused.","['measure-theory', 'gaussian-measure', 'probability-theory']"
4561582,An exposition of Tao's proof of disintegration theorem,"I have recently come across Tao's proof disintegration theorem, i.e., Let $X$ be a compact metric space, $\mathcal X$ its Borel $\sigma$ -algebra, and $\mu$ a Borel probability measure on $X$ . Let $(Y, \mathcal Y)$ be a measurable space, $\pi:X\to Y$ a measurable map, and $\nu := f_\sharp \mu$ the push-forward of $\mu$ by through $f$ . Then there is a collection $(\mu_y)_{y\in Y}$ of Borel probability measures on $X$ with the following properties. For all bounded measurable map $f:X\to \mathbb C$ and $\nu$ -integrable map $g:Y\to \mathbb C$ , $$
\int_X f (g\circ \pi) \mathrm d\mu = \int_Y \left(\int_X f\mathrm d\mu_y\right)g(y)\mathrm d\nu(y). \quad (\star)
$$ For all bounded measurable map $g:Y\to \mathbb C$ , for $\nu$ -a.e. $y \in Y$ , $$
g\circ \pi=g(y) \quad \mu_y\text{-a.e.}. \quad (\star\star)
$$ It is difficult for me to fully understand it. Fortunately, with help from @AnneBauval ( here ) and @EricWofsey ( here ), it seems I got it. For the sake of completeness, I present my exposition below and post it as an answer. I'm very happy to receive your suggestion, especially if my mistakes are pointed out.","['measure-theory', 'solution-verification', 'probability-theory']"
4561598,What is the name for a rectangle with two curved opposite edges?,"Assuming there is a name for this, what is it? I have looked through the list names of shapes in Wikipedia, but those seem all to be either polygons (all straight-sided) or all curves, none that are a mix of lines and arcs. The closest I have found is "" stadium "", but that obviously has both ends convex, not to mention that the arcs are semicircles. The object in the photo is part of a set of card scrapers, which are used for finishing wood; sets commonly include also a rectangle and a ""goose neck"". Product listings usually call these ""curved"" which is not a great name.","['geometry', 'terminology']"
4561600,How many sets of non-adjacent edges in the 600-cell?,"(This is a simpler variant of my previous question, with one colour instead of two.) The 600-cell is a 4D regular polytope. It has $120$ vertices, $720$ edges, $1200$ triangular faces, and $600$ tetrahedral cells. Each vertex touches $12$ edges, in an icosahedral arrangement. Two edges are adjacent if they're part of one triangular face. The number of adjacent pairs of edges is $1200\times\binom{3}{2}=3600$ . Question 1: How many subsets (of that set of $720$ edges) have no adjacent pairs of edges? Question 2: How many of these are distinct, considering symmetries of the 600-cell? An obvious upper bound for these numbers is the total number of subsets, $2^{720}\approx5.515\times10^{216}$ . The rectified 600-cell is a 4D uniform polytope, whose vertices correspond to the edges of the 600-cell, with the same adjacency relations. It has $720$ vertices and $3600$ edges. Each vertex touches $10$ edges. So I may equivalently ask about sets of non-adjacent vertices in the rectified 600-cell: Question 1: How many vertex-induced subgraphs (of the rectified 600-cell's graph) have no edges? Question 2: How many of these are distinct, considering symmetries of the rectified 600-cell? An approximate answer would still be appreciated. Let $A_1$ and $A_2$ be the answers to the two questions (respectively). The order of the 600-cell's symmetry group is $600\times24=14400$ , where the $24$ is from tetrahedral symmetry. Thus, for each subset, there are between $1$ and $14400$ subsets in its orbit under the symmetry group. As $A_1$ counts the subsets and $A_2$ counts the orbits, we get $$A_2\leq A_1\leq14400A_2.$$ In fact, it seems very likely that a random subset would have no symmetry; all $14400$ subsets in its orbit would be unequal to each other. So I'm expecting $$A_1\approx14400A_2.$$ And I think $A_2$ would be more difficult to compute than $A_1$ . Indeed, ignoring the adjacency condition, we'd have $2^{720}$ for $A_1$ , but nothing so easy for $A_2$ .","['polytopes', 'graph-theory', 'big-numbers', 'combinatorics', 'symmetry']"
4561619,Asymptotics of rational functions intersecting with generalized arithmetic progressions,"Let $f(x)=\frac{A}{x+B}$ for $A,B\in \mathbb{R}$ . Let $\alpha_1,\alpha_2$ be linearly independent over $\mathbb{Q}$ . Is it true that $$|f(\mathbb{Q})\cap (\alpha_1\cdot[1,t]+\alpha_2\cdot [1,t])|\le Kt$$ for some universal constant $K$ (not depending on $A$ or $B$ )? I know this is true for $f(x)=a_nx^n+\dots+a_1x^1+a_0$ . By the Pigeonhole Principle, if we have $|f(\mathbb{Q})\cap (\alpha_1\cdot[1,t]+\alpha_2\cdot [1,t])|> nt$ , then $f(\mathbb{Q})\ni \alpha_1\cdot y+\alpha_2\cdot z$ for some fixed value $y$ and at least $n+1$ distinct values of $z$ . It follows that $|f(\mathbb{Q})\cap (\alpha_1 y+\alpha_2\cdot \mathbb{Q})|\ge n+1$ . Let $g(x)=f(x)-\alpha_1\cdot y$ . Then $|g(\mathbb{Q})\cap\alpha_2\cdot \mathbb{Q}|\ge n+1$ , so there are distinct $x_1,\dots,x_{n+1}\in \mathbb{Q}$ so that $g(x_i)\in \alpha_2\cdot \mathbb{Q}$ for all $1\le i\le n+1$ . Letting $V$ be the Vandermonde matrix $$V=\begin{pmatrix}
1&x_1&\cdots &x_1^{n}\\
1&x_2&\cdots &x_2^{n}\\
\vdots&\vdots&\ddots&\vdots\\
1&x_{n+1}&\cdots&x_{n+1}^n
\end{pmatrix}$$ We have $$V\begin{pmatrix}a_0-\alpha_1y\\ a_1 \\ \vdots \\ a_n \end{pmatrix}\in\alpha_2\cdot \mathbb{Q}^{n+1}$$ Since $V$ is a matrix in $\mathbb{Q}^{n+1\times n+1}$ and is invertible, it follows that $$\begin{pmatrix}a_0-\alpha_1y\\ a_1 \\ \vdots \\ a_n \end{pmatrix}\in\alpha_2\cdot V^{-1}\mathbb{Q}^{n+1}\subseteq\alpha_2\cdot\mathbb{Q}^{n+1}$$ Hence every coefficient of $g$ is in $\alpha_2\cdot\mathbb{Q}$ , so $g(\mathbb{Q})\subseteq \alpha_2\cdot\mathbb{Q}$ . So $g(\mathbb{Q})\subseteq \alpha_1\cdot y+\alpha_2\cdot\mathbb{Q}$ , so $|f(\mathbb{Q})\cap (\alpha_1\cdot[1,t]+\alpha_2\cdot [1,t])|\le 2n$ . I've tried adapting this idea to the case $f(x)=\frac{A}{x+B}$ for real $A,B$ , but I've had no luck so far. Any ideas?","['number-theory', 'combinatorics', 'rational-functions']"
4561639,"How to calculate distance on screen in pixels corresponding to a certain angle, knowing camera's FOV and screen resolution?","I am trying to re-create how a certain videogame handles weapon recoil. For example, there is a value of recoil_magnitude , which describes a vertical ""kick"" of the weapon, in degrees. I want to convert that value to a distance in pixels my crosshair has moved on the screen, knowing that angle, FOV (Field Of View, in degrees) of the camera, and the resolution of the screen (in pixels). The first idea i had was to not overthink it and try to calculate it directly - by dividing vertical screen resolution by recoil_magnitude and multiplying it by my FOV - but testing showed that this formula is (unsurprisingly) inaccurate. Any ideas how I would approach this?","['trigonometry', 'geometry']"
4561677,An exercise on the Einstein tensor from Petersen's Riemannian geometry,"This comes from Riemannian geometry , Peter Petersen, Exercise 3.4.16. Consider the $(0,2)$ -tensor $
T = \operatorname{Ric} + b \operatorname{scal} g + cg
$ where $b, c\in \mathbb R$ . Show that $\nabla^* T=0$ if $b=-\frac{1}{2}$ . The tensor $G = \operatorname{Ric} - \frac{1}{2} \operatorname{scal} g +cg$ is known as the  Einstein tensor, and $c$ as the cosmological constant. Show that if $c=0$ , then $G=0$ in dimension 2. When $n>2$ show that if $G=0$ , then the metric is an Einstein metric. When $n>2$ show that if $G=0$ and $c=0$ , then the metric is Ricci flat, i.e. $\operatorname{Ric} \equiv 0$ . For 2, I've done this so far and I just want to make sure it's right: In dimension 2, $$
\sec \left(e_1, e_2\right)=R_{1221}=\left\langle\operatorname{Ric}\left(e_1\right), e_1\right\rangle=\left\langle\operatorname{Ric}\left(e_2\right), e_2\right\rangle,
$$ where $e_1, e_2$ orthonormal at a given point $p$ of $M$ .
Thus $$
\begin{gathered}
G\left(e_1\right)=\operatorname{Ric}\left(e_1\right)-\frac{\text { scal }}{2} e_1=R_{1221} e_1-R_{1221} e_1=0, \\
G\left(e_2\right)=\cdots=0 .
\end{gathered}
$$ and for part 4,if $G=0$ , then Ric $=\frac{\text { scal }}{2} \cdot I$ , taking contractions imply that $$
\text {scal }=\frac{n}{2} \text { scal, }
$$ thus if $n \geq 3, s c a l=0$ , Ric $=\frac{s c a l}{2} \cdot g=0$ I'd appreciate it if you can lmk if I'm on the right track for 2, and 4 and help me with 1 and 3.","['solution-verification', 'riemannian-geometry', 'differential-geometry']"
4561683,Does mapping degree imply betti number inquality,"Given two compact orientable connected manifolds $M,N$ of dimension $n$ without boundary, and a continuous (or smooth) map $f:M\to N$ , the degree of $f$ is defined as the integer $$
f_*([M])=(\deg f)[N]\in H_n(N)\cong\mathbb{Z}
$$ where $[M]$ is the fundamental class of $M$ . Suppose $\deg f\neq0$ , is it possible to show that $\beta_M(q)\geq\beta_N(q)$ for any $1<q<n$ , where $\beta_M(q)=\mathrm{rank}~H_q(M;\mathbb{Z})$ is the $q$ -th betti number. I'm inspired by this question and this proof actually shows that $\beta_M(1)\geq\beta_N(1)$ (by the proof the degree is a finite number so the map on $H_1$ becomes an isomorphism after $\otimes_\mathbb{Z}\mathbb{Q}$ , and therefore it is a rational surjection). Therefore for surfaces the betti number inequality holds. However, I cannot prove or disprove it.","['differential-topology', 'algebraic-topology', 'differential-geometry']"
4561693,What is the probability of a polynomial with integer coefficients has rational roots? [closed],Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 1 year ago . Improve this question What is the probability of a polynomial with integer coefficients has rational roots? For some reason I feel like the probability of having rational roots assuming the coefficients are random integers would get smaller as the degree goes up. Degree 1: $ax+b=0$ always has 1 rational root Degree 2: $ax^2+bc+c=0$ has rational root(s) if $b^2-4ac$ is a perfect square ( side question: do we consider $0$ to be a perfect square since $0^2=0$ )? Degree 3: $ax^3+bx^2+cx+d=0$ I can't say much for this case but I know Cardano's formula has a lot of radicals (and nested radicals!) Anyone know any results/theorems in this direction?,"['number-theory', 'irrational-numbers', 'roots', 'soft-question', 'probability']"
4561700,Probability normally random variable X is between two values,"Find Œ¥ such that $P(2 ‚àíŒ¥ < X < 2 + Œ¥) = 0.95$ when $\mu = 2$ and $\sigma^2 = 4$ I believe the approach to this question is to normalize the bounds of
X. Doing so I get P(‚àíŒ¥/2 < Z < Œ¥/2). Since the middle 95% of the area
is covered, that means the lower bound is at the 2.5th percentile. I
am not sure how to translate that to a value of Œ¥ however. Is this the
right approach?","['statistics', 'probability-distributions', 'normal-distribution', 'probability']"
4561706,Prove that $y=-\tan^{-1}(x)$ is a decreasing function with out the help of calculus.,"Motivation:- I was disproving the statement"" If $f:\mathbb R\to \mathbb R$ a decreasing function. then, f is surjection. "" I could able to prove this by calculus. But the question is pre-calculus level. I am practicing my old books. Attempt:- Let $$x<y\implies y-x>0.$$ Consider $$-\tan^{-1}(x)-(-\tan^{-1}(y))=\tan^{-1}(y)-\tan^{-1}(x)=\tan^{-1}\left(\frac{y-x}{1+xy}\right)$$ The sign of $1+xy $ depends on the value of $x$ and $y$ . I don't know how to proceed from here now. Please give some hints.","['algebra-precalculus', 'trigonometry']"
4561712,"If a continuous monotone function $f:[0,1]^2\to[0,1]$ aggregates nicely, is it ""multiplication in disguise""?","Suppose we have a continuous function $f:[0,1]^2\to [0,1]$ such that: $f(a,b)=f(b,a)$ $b\ge c \implies f(a,b) \ge f(a,c)$ $f(a,f(b,c))= f(f(a,b),c)$ $f(0,0)=0, f(1,1)=1$ In other words, $f$ is monotone increasing and surjective onto $[0,1]$ , and the result of turning a multiset of real numbers into a single real number by repeatedly replacing $a,b$ with $f(a,b)$ is independent of the order in which this aggregation is performed. Obviously, $f(a,b)=ab$ works. In general, if $g:[0,1]\to[0,1]$ is a strictly montone function (either increasing or decreasing) whose image is the whole interval, then $f(a,b)=g^{-1}(g(a)\cdot g(b))$ also works. Equivalently, if $h:[0,1]\to\mathbb{R}_{\ge0}\cup\{\infty\}$ is a strictly monotone function whose image is the full set of nonnegative real numbers along with $\infty$ , then taking $f(a,b) = h^{-1}(h(a)+h(b))$ works (where we take $x+\infty=\infty$ for all $x$ ). This is just a transformation of the above example with $h(x)=-\log(g(x))$ . Are there any other examples? In other words, do all such nicely-aggregating functions necessarily behave like a relabeling of addition/multiplication under some bijective map? One corollary of this that might either be provable without showing the full result or (if false) suggestive of a potential counterexample would be that $f(0,1)$ must equal either $0$ or $1$ .","['functional-equations', 'real-analysis']"
4561722,Real eigenspaces of a matrix $A\in\mathcal{M}_{2\times 2}(\mathbb{R})$ are the union of straight lines trajectories and the fixed point $y\equiv 0$,"I'm trying to show that real eigenspaces of a matrix $A\in\mathcal{M}_{2\times 2}(\mathbb{R})$ are the union of straight lines trajectories and the fixed point $y\equiv 0$ . I'm studying this in the field of systems of linear differential equations. If we have the equation \begin{equation}
y'(t)=Ay(t)+g(t)
\end{equation} and consider \begin{equation}
y'(t)=Ay(t)
\end{equation} the solution to the homogeneous system involves scalar multiples of the eigenvectors of the matrix $A$ .
Moreover, the general solutions to this homogeneous system involves linearly independent eigenvectors (which can be generalized eigenvectors). Of course, here we have two straight lines in the phase plane corresponding to this solution, which isn't the same line since those eigenvectors are linearly independent. If we think about an eigenspace as $E(A,\lambda)=\{\alpha v_\lambda:\alpha\in\mathbb{R}\}$ since if $\lambda$ is an eigenvalue, then there exist $v_\lambda\neq\vec{0}$ such that $Av_\lambda=\lambda v_\lambda$ and if we multiply by $\alpha\in\mathbb{R}$ both sides, $\alpha (Av_\lambda)=A(\alpha v_\lambda)=\alpha\lambda v_\lambda\in E(A,\lambda)$ . Is is trivial that $y\equiv 0$ is in any eigenspace. However, i'm not sure if I'm done. Do I have to take any consideration with the non-homogeneous part of the system? I think I don't because eigenspaces of the matrix are not related to $g(t)$ , but I'm not completely sure I have to prove something else. Any hint with this pseudo-proof?","['systems-of-equations', 'vector-spaces', 'ordinary-differential-equations']"
4561778,Relevance of Complex Coordinate Geometry [closed],"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 1 year ago . This post was edited and submitted for review 1 year ago and failed to reopen the post: Original close reason(s) were not resolved Improve this question I have been studying complex numbers (but not Calculus with them). So I have understood Arithmetic with Complex Numbers: Add, Subtract, Multiply, Divide, Exponentiate Forms of Complex Numbers: Rectangular, Polar, Exponential Roots of Unity and their basic properties Complex Plane/Argand Diagram For example, I have learnt that the general equation of a circle is $$az\overline{z}+\overline{B}z+B\overline{z}+c=0$$ And the condition for three points to form an equilateral triangle in the complex plane is: $$z_1^2 + z_2^2 + z_3^2 = z_1z_2 + z_1z_3 + z_2z_3$$ I know that as I go forward, I will learn about lines , and ellipses , parallelograms and quadrilaterals in the complex plane, with their related equations, and properties. Such questions tend to get asked in entrance exams and contest math (both of which interest me). I know that complex numbers get used in: Electrical Engineering, and that they are useful in dealing with waves/oscillations Solving contest math problems (say tiling with dominoes, or in generating functions) However, I wanted to know, where else in math will I make use of complex coordinate geometry(circles, lines, ellipses, etc). That is, what are the applications of complex coordinate geometry?","['complex-analysis', 'soft-question', 'complex-numbers', 'contest-math']"
4561821,"When does $(X\times Y,\Vert\cdot\Vert)$ have the product topology?","Let $(X,\Vert\cdot\Vert_X)$ and $(Y,\Vert\cdot\Vert_Y)$ be normed vector spaces and let $\Vert\cdot\Vert$ be a norm on $X\times Y$ such that $\Vert(x,0)\Vert=\Vert x\Vert_X$ and $\Vert(0,y)\Vert=\Vert y\Vert_Y$ for all $x\in X$ and $y\in Y$ . Is the metric topology induced by this norm necessarily the product topology on $X\times Y$ ? It suffices to show that this norm and the norm $\Vert(x,y)\Vert_1:=\Vert x\Vert_X+\Vert y\Vert_y$ are equivalent since $\Vert\cdot\Vert_1$ induces the product topology, but I was only able to show $\Vert\cdot \Vert$ is continuous with respect to $\Vert\cdot\Vert_1$ , not conversely. This shows only that the metric topology is no finer than the product topology, not that they are equal. So, I suspect there may be a counterexample.","['product-space', 'normed-spaces', 'functional-analysis', 'analysis']"
4561886,"Find all analytic functions such that $z^{2} f^{\prime \prime}(z)+f^{\prime}(z)-6 f(z)=0, \quad z \in \mathbb{C}$","This is a question I got in a homework sheet for one of my modules (MSc Mathematics, complex analysis module). We've been doing Taylor Series and Laurent series in class, and I tried to find the Taylor series for $f(z)$ about 0, and then differentiated that to get $f'(z)$ and $f''(z)$ . Then I substituted these into the given equation, and for the first few terms I got: $$-6f(0) + (2-6z)f'(0) + (z^2+2z)f''(0) + ...$$ I hit a dead end after that. I don't know if what I've done is helpful, or if I'm completely on the wrong track. If anyone could advise me on whether this is going in the right direction or not, that would be very helpful. Thank you!","['complex-analysis', 'functions', 'taylor-expansion', 'complex-numbers']"
4561903,"Differentiation under the ingtegral sign for a $W^{1, \infty}$ function","I have the following question. If $u\in L^1([0, T]; W^{1, \infty}(\Omega))$ , then for every $t\in[0, T]$ can we conclude that the function $$
w^t:\Omega\longrightarrow\mathbb R,\qquad x\longmapsto\int_0^t u(s, x)ds
$$ belongs to $W^{1, \infty}(\Omega)$ and $\frac{\partial w^t}{\partial x}=\int_0^t \frac{\partial}{\partial x}u(s, x)ds$ ? I'm pretty sure that the answer is positive but I cannot find a book where to find it or some similar result which can confirm it. Could you help me? Thank you","['sobolev-spaces', 'derivatives', 'functional-analysis']"
4561916,Continuous function satisfying $ f\left(\dfrac{x+t}{2}\right) \le f(x) + f(t)$ inequality must be $0$,"Let $f$ a real function defined and continuous on $[0,1]$ such that $$f(0)=f(1)=0$$ $$ f\left(\dfrac{x+t}{2}\right) \le f(x) + f(t)$$ for all $x,t$ prove that $f$ is zero. My try was proving first that f is nonnegative (no problem) then using the fact that $f([0,1]) = [0,M]$ try to prove that $M$ must be zero. by contradiction if I assume that $M=f(\alpha)>0$ then continuity of $f$ must be positive on a whole neighbourhood of $\alpha$ . but then I was stuck, trying to draw from here a contradiction. Any advice would be greatly appreciated.","['functional-equations', 'functional-inequalities', 'real-analysis', 'continuity', 'calculus']"
4561921,Relation between speed and potential,"I'm studying newtonian dynamical systems and they can be described by the differential equation $$1)\space  m\ddot{x} = F(x)$$ supposing $F$ sufficiently regular we could define the potential $V$ as its primitive so $$2)\space F(x) = -{dV\over dx}$$ We can also define the energy of the system $E$ as $$3)\space E = \frac{1}{2}mv^2 + V(x)$$ as a results we have $$4) \space v = \sqrt{\frac{2}{m}(E-V)}$$ What confuses me is that $(1)$ could also be described by the pair of equations $$\dot{x} = v,\space \space \dot{v} = \frac{F(x)}{m}$$ for the sake of simplicity take $m=1$ and by the second equation above I think that $$v(x) = -\int_{x_0}^{x}F(\zeta)d\zeta = V(x_0)-V(x)$$ So how $4)$ and the last equation could be the same thing? I was thinking about that and the conclusion I came is that I could not write the last relation, can't I? Every clarification is welcome, because in this moment I have a lot of confusion in my head. Thanks!","['ordinary-differential-equations', 'dynamical-systems']"
4561924,"Help with proof that every point $x \in [0,1]$ is an accumulation point of given sequence","I was aksed to show that every point $x \in [0,1]$ is an accumulation point of the sequence $$
v_n= \sum_{k=0}^Kz_k10^{-k-1} \text{, where } n= \sum_{k=0}^Kz_k10^k.
$$ So for example $v_{123}=0.321$ or $v_{3210}=0.0123$ . I think I understand the question and got the idea but I don't quite know how to write down the proof. Here is my attempt - hopefully not a mess: Proof. Let $x \in (0,1)$ be arbitrary.The point $x$ can be written as $$
x=0.x_0x_1x_2x_3 \cdots \text {, where } 0 \leq x_i \leq 9, \forall i \in \mathbb N.
$$ Now define the subsequence $$
y_k =0.x_0x_1x_2x_3 \cdots x_k.
$$ Then we get $|y_k-x| \lt \varepsilon, \forall \varepsilon \gt 0$ if we choose $N= \lceil \frac{1}{n} \rceil$ and $lim_{k \to \infty} y_k=x$ . If now $x_i=z_i, \forall i \in \mathbb N$ , we get an $n_k$ with $$
n_k= \sum_{i=0}^Kz_i10=\cdots x_3x_2x_1x_0 \implies v_{n_k}= \sum_{i=0}^Kz_i10^{-i-1}=0.x_0x_1x_2x_3 \cdots.
$$ Then $$
lim_{k \to \infty}v_{n_k}=x
$$ and the point $x$ is an accumulation point of the sequence $v_n$ . For $x=0$ , define $$
v_{n_k} =0.000 \cdots 1.
$$ Then $|v_{n_k}-x|=|v_{n_k}-0| \leq 10^{-k+1} \lt \varepsilon$ with $N= \lceil \frac{1}{n} \rceil$ . For $x=1$ define $$
v_{n_k}=0.999 \cdots 9
$$ Then $|v_{n_k}-x|=|v_{n_k}-1| \leq 10^{-k+1} \lt \varepsilon$ with $N= \lceil \frac{1}{n} \rceil$ . That means every $x \in [0,1]$ is an accumulation point of the sequence $v_n$ . $$\tag*{$\blacksquare$}$$ I'm really struggling with this one for a long time now, so thank you very much in advance!","['proof-writing', 'analysis', 'solution-verification', 'sequences-and-series', 'limits']"
4561927,Question about infinity in real analysis,"My question is a bit general. When defining measure, we typically have to encounter a series $\sum_{n=1}^{\infty}\mu(E_i)$ , where $\mu$ can be a measure or outer measure, etc. However, this series can be divergent. So we extend $R$ to $\bar{R}=R \cup \{\infty,-\infty\}$ . $\bar{R}$ has some arithmetic operations, see https://en.wikipedia.org/wiki/Extended_real_number_line . But I do not find any statements about $\infty=\infty,\infty \geq \infty, \infty \leq \infty$ , however, this comparison is allowed in real analysis. For example, when proving Caratheodory set is a $\sigma$ ring, we need to show $\mu(F)=\mu(F\cap \cup_{i=1}^{\infty}(E_i))+\mu(F -\cup_{i=1}^{\infty}(E_i))$ . First we may prove $\mu(F)=\mu(F\cap \cup_{i=1}^{n}(E_i))+\mu(F -\cup_{i=1}^{n}(E_i))$ where $E_i$ is disjoint. Then $\mu(F)\geq\mu(F\cap \cup_{i=1}^{n}(E_i))+\mu(F -\cup_{i=1}^{\infty}(E_i))$ for any $n$ . Then $\mu(F)\geq \sum_{i=1}^{n}\mu(F\cap E_i)+\mu(F -\cup_{i=1}^{\infty}(E_i))$ . Things are trivial if $\mu(F)$ is finite. But if it is infinite, I think we allow $\infty \geq \infty$ . The remaining proof steps are unrelated to the question so I omit it here.","['measure-theory', 'infinity', 'real-analysis']"
4562032,Probability of getting at least one spade from drawing 2 cards in succession,"Two cards are drawn in succession without replacement from a deck of 52 playing cards. Find the probability that at least one of them is a spade. Here's my approach: We can get a spade in $13 \choose 1$ ways, and the from the rest of the cards $(52-1 = 51)$ , we can choose any card, so $52 \choose 1$ . Thus, our number of favorable outcome would be ${13 \choose 1} {51 \choose 2} = 13\times51 = 663$ , and the probability would then be $\frac{663}{1326}$ But, the book has a different answer, i.e.,it computes the number of cases where there is no spade and the number of ways for that is of course ${39 \choose 2} = 741$ , and our required probability is then $1-\frac{741}{1326} = \frac{15}{34}$ Why are the two approaches different? Where am I going wrong?","['combinatorics', 'probability']"
4562033,"Does convergence in $L^1$ of $\{f_n(\cdot,\ell)\}_{n \in \mathbb{N}}$ for each $\ell \in \mathbb{Q}$ implies convergence for $\ell \in \mathbb{R}$?","On a measure space $(X,\mathcal{A},\mu)$ ,
consider a sequence of functions $\{f_n:X \times \mathbb{R} \longrightarrow \mathbb{R}\}_{n \in \mathbb{N}}$ with $\ell \in \mathbb{R} \longmapsto f_n(x,\ell)\in \mathbb{R}$ is increasing and continuous for each $x \in X$ , $n \in \mathbb{N}$ , such that $$
    \lim_{n \to \infty}\int_X|f_n(x,\ell) - f_0(x,\ell)|\mu(dx) = 0,
   ~\mbox{for all}~
   \ell \in \mathbb{Q},
$$ then does it hold that $$
    \lim_{n \to \infty}\int_X|f_n(x,\ell) - f_0(x,\ell)|\mu(dx) = 0,
   ~\mbox{for all}~
   \ell \in \mathbb{R}.
$$ My attempt:
if $\mu$ is a finite measure, then for $\ell \in \mathbb{Q}$ , $f_n(\cdot,\ell)$ converges to $f_0(\cdot,\ell)$ in measure $\mu$ , then it is equivalent to that for any subsequence $\{n_k\}_{k \in \mathbb{N}}$ of $\{n\}_{n \in \mathbb{N}}$ , there exists a subsubsequence $\{n_{k_m}\}_{m \in \mathbb{N}}$ such that for $\ell \in \mathbb{Q}$ , $f_{n_{k_m}}(\cdot,\ell)$ converges to $f_0(\cdot,\ell)$ $\mu$ -a.e. Then we can easily deduce that for $\ell \in \mathbb{R}$ , $f_{n_{k_m}}(\cdot,\ell)$ converges to $f_0(\cdot,\ell)$ $\mu$ -a.e., which is equivalent to that for $\ell \in \mathbb{R}$ , $f_n(\cdot,\ell)$ converges to $f_0(\cdot,\ell)$ in measure $\mu$ .
Then it remains to prove that for all $\ell \in \mathbb{R}$ , $\{f_n(\cdot,\ell)\}_{n \in \mathbb{N}}$ is uniformly integrable. From another point of view, if we define a projection \begin{align}
    \pi: (L^1(\mu))^{\mathbb{R}} & \longrightarrow (L^1(\mu))^{\mathbb{Q}},
\\       (f(\cdot,\ell))_{\ell \in \mathbb{R}}  & \longmapsto  (f(\cdot,\ell))_{\ell \in \mathbb{Q}},
\end{align} and let $E \subset (L^1(\mu))^{\mathbb{R}}$ defined as $$
        E := \{(f(\cdot,\ell))_{\ell \in \mathbb{R}}: \ell \in \mathbb{R} \longmapsto f(x,\ell)\in \mathbb{R}~\mbox{is increasing and continuous for each}~ x \in X \},
$$ All product spaces are equipped with the product topology and then
I can show that $\pi|_{E}$ is a continuous injective function, the question falls into that is $\pi^{-1}|_{\pi(E)}$ continuous, i.e. is $\pi|_{E}$ a homeomorphism?","['calculus', 'convergence-divergence', 'probability', 'real-analysis']"
4562101,Doubts on the setting of PMA Rudin's proof of the 9.24 (Inverse Function Theorem),"PMA Rudin Theorem 9.24 (Inverse Function Theorem) Suppose $\textbf{f}$ is a $\mathscr{C '}$ -mapping of an open set $E \subset R^n$ into $ R^n. \textbf{f '(a)}$ is invertible for some $\textbf{a} \in E$ , and $\textbf{b = f (a)}$ . Then: (a) There exist open sets $U$ and $V$ in $R^n$ such that $\textbf{a} \in U, \textbf{b} \in V$ . $\textbf{f}$ is one-to-one on U, and $\textbf{f}(U)=V$ ; (b) If $\textbf{g}$ is the inverse of $\textbf{f}$ [which exists, by (a)], defined in $V$ by $\textbf{g(f(x))} = \textbf{x}$ , (for $\textbf{x} \in U)$ . Then $\textbf{g} \in \mathscr{C '}(V)$ For part b of his proof on the book, the first line states: ""Pick $\textbf{y} \in V, \; \textbf{y} + \textbf{k} \in V$ . Then there exist $\textbf{x} \in U, \; \textbf{x + h} \in U,$ so that $\textbf{y} = \textbf{f(x)}, \; \textbf{y + k = f(x + h)}.$ "" Question 1: Is it okay to assume that open sets $U$ and $V$ as vector spaces. Is this assumption arbitrary or common sense ?","['multivariable-calculus', 'general-topology', 'linear-transformations', 'real-analysis']"
4562107,Triangular inequality and metrics,"Prove that the metrics $\rho(A,B)$ defined by : $$
\rho(A,B) = 
\begin{cases}
\dfrac{\mathbb P(A \bigtriangleup B)}{\mathbb P(A \bigcup B)}  & \text{if} 
 \space \mathbb P(A \bigcup B) \neq 0 \\
0  & \text{if} \space \mathbb P(A \bigcup B) = 0 \\
\end{cases}
$$ satisfy the triangular inequality. What i was thinking was to use the fact that $ x \rightarrow \frac{a+x}{b+x}$ when a < b and $x \geq -a$ is increasing to swith from any C to subevent of $A \bigcup B$ and then normalizing the probability function, assume that $\mathbb P(A \bigcup B) = 1 $ but i don't know how to proceed.","['metric-spaces', 'measure-theory', 'probability-theory', 'inequality']"
4562141,"If a circle can be inscribed in two quadrilaterals, then circle can be inscribed also in the quadrilateral $ABCD$","Show that if a circle can be inscribed in quadrilateral $1$ ( $AESH$ ) and in quadrilateral $2$ ( $KCLS$ ), then circle can be inscribed also in the quadrilateral $ABCD$ . Here is a picture: The places where inscribed circle is tangent to quadrilateral $1$ are marked as red points (blue points for places where inscribed circle is tangent to quadrilateral $2$ ). As you see I've already took into account same lengths of some sides somming form the fact of inscribed circles (lengths: $a, b, c, d, e, f, g, h$ ). Then I think that I need to use the fact that both circles are also inscribed in bigger tiangles: circle that is inscribed in quadrilateral $1$ is also inscribed in triangles $AEG$ and $AFH$ circle that is inscribed in quadrilateral $2$ is also inscribed in triangles $SKG$ and $SFL$ From that I got $4$ equations: $n+g = m + h$ $m+h + e + c = o + p + d$ $l+g = k + f$ $k + f + e + c = b + i + j$ But I don't know what to do next. Ultimately I need to prove that: $AB + DC = AD + BC$ .",['geometry']
4562166,Should we write $\lim_\limits{x\to -\infty} \frac{3x^2-1}{x^3+4x+3}=0^-$ instead of just $0$?,"This may sounds silly but I have a doubt about a notation.
Say I have $$\lim_{x\to -\infty} \dfrac{3x^2-1}{x^3+4x+3}$$ The limit is obviously zero, for the polynomial at the denominator is of a higher degree than the one at the numerator. Yet I was thinking: should we (or could we, or must we...) be more precise and write the result as $0^-$ instead of just $0$ , or is that something wrong or nonsensical? It's like when $$\lim_{x\to 0} \dfrac{1}{x}$$ does not exist unless we specify if it's $x\to 0^+$ or $x\to 0^-$ , but reversed.","['notation', 'limits', 'calculus']"
4562201,Finding a simpler differential equation for this geometric problem,"This is the problem I am trying to solve: Find the curves which tangent segment between the coordinate axis is constant Let $k$ be the length of the segment, then we have to find the points of intersection of the tangent line to the curve with the $x$ and $y$ axis, $Q$ and $P$ respectively. Using the equation $Y-y=y‚Äô(Q-x)$ , we obtain: $$
Q = x - \frac{y}{y‚Äô}
$$ and $$
P = y‚Äô(\frac{y}{y‚Äô}-x)
$$ So the equation for the distance would be $$
k^2=(y‚Äô)^2(\frac{y}{y‚Äô}-x)^2+(x - \frac{y}{y‚Äô})^2 
$$ I changed it up a little bit and ended up with this $$
k^2=(y‚Äô)^2(\frac{y}{y‚Äô}-x)^2+\frac{1}{(y‚Äô)^2}(xy‚Äô - y)^2 
$$ I tried expanding the squares, but the equation is too hard for me to solve. I think the reasoning that got me there is right, so I thought there must be a simpler way to express the differential equation. The final equation kinda looks like the one of a circumference, so maybe there‚Äôs a way to parametrize it with that, but I couldn‚Äôt manage to do anything. I would really appreciate any hint to keep going, since I‚Äôve been stuck with this problem for a couple of days now.","['geometry', 'ordinary-differential-equations']"
4562250,"What is the most efficient way to ""encode"" a finite field into a structure that has only one binary operation?","I know that a finite field can be easily encoded into and decoded from a finite Paige loop, which can be defined as a Moufang loop that is simple and isn't a group. However, the finite Paige loop of a field of order $q$ has about $q^7$ elements. Is there any more efficient way to encode a field into a type of structure specified by axioms such that every structure of that type can be uniquely decoded?","['field-theory', 'finite-fields', 'abstract-algebra', 'binary-operations']"
4562314,What is the geometry in algebraic geometry?,"Coming from a physics background, my understanding of geometry (in a very generic sense) is that it involves taking a space and adding some extra structure to it. The extra structure takes some local data about the space as its input and outputs answers to local or global questions about the space + structure. We can use it to probe either the structure itself or the underlying space it lives on. For example, we can take a smooth manifold and add a Riemannian metric and a connection, and then we can ask about distances between points, curvature, geodesics, etc. In symplectic geometry, we take an even-dimensional manifold and add a symplectic form, and then we can ask about... well, honestly, I don't know. But I'm sure there is interesting stuff you can ask. Knowing very little about algebraic geometry, I am wondering what the ""geometry"" part is. I am assuming that the spaces in this case are algebraic varieties, but what is the extra structure that gets added? What sorts of questions can we answer with this extra structure that we couldn't answer without it? I have to guess that this is a little more complicated than just taking a manifold and adding a metric, otherwise I would expect to be able to find this explained in a relatively straightforward way somewhere. If it turns out the answer is ""it's hard to explain, and you just need to read an algebraic geometry text,"" then that's fine. In that case, it would be interesting to try to get a sense of why it's more complicated. (I have a guess, which is that varieties tend to be a lot less tame than manifolds, so you have to jump through more technical hoops to tack on extra stuff to them, but that's pure speculation.)","['algebraic-geometry', 'geometry', 'differential-geometry']"
4562353,Problem with partial derivative with multi-variable,"Here, $z=z(u,v)$ where $u=u(x,y)$ and $v=v(x,y)$ $$p=\frac{\partial z}{\partial x}=\frac{\partial z}{\partial u} \frac{\partial u}{\partial x}+\frac{\partial z}{\partial v} \frac{\partial v}{\partial x} \implies \frac{\partial}{\partial x}=\frac{\partial u}{\partial x} \frac{\partial}{\partial u}+\frac{\partial v}{\partial x} \frac{\partial}{\partial v}$$ $$q=\frac{\partial z}{\partial y}=\frac{\partial z}{\partial u} \frac{\partial u}{\partial y}+\frac{\partial z}{\partial v} \frac{\partial v}{\partial y}\implies \frac{\partial}{\partial y}=\frac{\partial u}{\partial y} \frac{\partial}{\partial u}+\frac{\partial v}{\partial y} \frac{\partial}{\partial v}$$ $$
\begin{align}
r&=\frac{\partial^2 z}{\partial x^2}\\\\
&=\frac{\partial}{\partial x}\left(\frac{\partial z}{\partial x}\right)\\\\
&=\left(\frac{\partial u}{\partial x} \frac{\partial}{\partial u}+\frac{\partial v}{\partial x} \frac{\partial}{\partial v}\right)\left(\frac{\partial u}{\partial x} \frac{\partial z}{\partial u}+\frac{\partial v}{\partial x} \frac{\partial z}{\partial v}\right)\\\\
&\stackrel{{}^3}{=}\frac{\partial u}{\partial x} \frac{\partial}{\partial u}\left(\frac{\partial u}{\partial x} \frac{\partial z}{\partial u}+\frac{\partial v}{\partial x} \frac{\partial z}{\partial v}\right)+\frac{\partial v}{\partial x} \frac{\partial}{\partial v}\left(\frac{\partial u}{\partial x} \frac{\partial z}{\partial u}+\frac{\partial v}{\partial x} \frac{\partial z}{\partial v}\right)\\\\
&\stackrel{{}^4}{=}\frac{\partial^2 z}{\partial u^2}\left(\frac{\partial u}{\partial x}\right)^2+2 \frac{\partial^2 z}{\partial u \partial v} \frac{\partial u}{\partial x} \frac{\partial v}{\partial x}+\frac{\partial^2 z}{\partial v^2}\left(\frac{\partial v}{\partial x}\right)^2+\frac{\partial z}{\partial u} \frac{\partial^2 u}{\partial x^2}+\frac{\partial z}{\partial v} \frac{\partial^2 v}{\partial x^2}
\end{align}
$$ I couldn't understand how line $(4)$ came from line $(3)$ , Like what should be $$\frac{\partial u}{\partial x} \frac{\partial}{\partial u}\left(\frac{\partial u}{\partial x} \frac{\partial z}{\partial u}+\frac{\partial v}{\partial x} \frac{\partial z}{\partial v}\right)=?$$ I guess $$\frac{\partial^2 z}{\partial u^2}\left(\frac{\partial u}{\partial x}\right)^2+ \frac{\partial^2 z}{\partial u \partial v} \frac{\partial u}{\partial x} \frac{\partial v}{\partial x}+\frac{\partial u}{\partial x}\frac{\partial z}{\partial u} \frac{\partial^2 u}{\partial x^2}+0$$ But that seems not correct. Any help will be appreciated.","['multivariable-calculus', 'chain-rule']"
4562375,Proving the existence of a left-inverse for every injective function,"Trying to prove the theorem that for every injective function there exists a left-inverse of that function, I have conjured up the following proof: Assume that $f$ indeed, is a function, chance, from $A$ to $B$ ; and that $f$ is injective. From this I am trying to prove the existence of a function, chance, $g$ from $B$ to $A$ such that $g\circ f(x) = x$ . The existence of this function could be shown with a constructive proof. We may construct our left-inverse $g$ by defining its mapping such that if $y$ is an element of $B$ , and $y$ belongs to $ranf$ , then $g(y) = f^{-1}(y)$ ; and else, if $y$ does not belong to $ranf$ then $g(y) = a$ where $a$ is some arbitrary value in $A$ . Therefore we have constructively defined the existence of this function $g$ for when $f$ is injective. Notice that that is all I needed for I have no intention in proving the converse (namely that the existence of the left-inverse proves that $f$ is injective). Now I have three concerns pertaining to this proof. The first of which is if this proof is even valid. I ask of this for I am still new to formulating proofs, hence I require affirmation from those more advanced. Second, in constructing this function $g$ , I have defined a part of it using $f^{-1}$ . How is this permissable since I have not proved the existence of $f^{-1}$ in the first place; and so how am I using it to define but another function? Thirdly, is this kind of proof considered as a ""constructive proof"" as I have been calling it so far? Since I assumed we're proving the existence of a mathematical object by providing a construction for it, I have been calling it so. And would you also care to explain why this type of proof is valid (in addition to my first question) since all we have done is provided a way to construct this function $g$ . Does the ability of being able to construct it properly prove its existence ? Thank you in advance","['elementary-set-theory', 'functions']"
4562388,"Is there a normed space $W$ such that $W=X\oplus Y$, with $X$ not closed and such that $W$ is homeomorphic to $X\times Y$?","If $W$ is a normed space, $X,Y$ are vector subspaces with the subspace topology, $X$ is not closed and $X\oplus Y=W$ in the algebraic sense, then the map $X\times Y\to W$ , $(x,y)\mapsto x+y$ is bijective and continuous, but not a homeomorphism. If $W$ is Banach, then the stronger conclusion holds that $X\times Y$ is not homeomorphic to $W$ , as a consequence of the fact that Banach spaces cannot be homeomorphic to non-Banach normed spaces (e.g. here ). I believe that it should be possible to find a normed space $W$ with a non-closed subspace $X$ and another subspace $Y$ such that $X\oplus Y=W$ and $X\times Y$ is homeomorphic to $W$ . However,  I cannot find such an example.","['normed-spaces', 'topological-vector-spaces', 'functional-analysis', 'examples-counterexamples']"
4562401,Can every manifold be embedded into a compact manifold of the same dimension,"Can every connected smooth boundary-less manifold be embedded into a compact smooth boundaryless manifold of the same dimension ? If not, can someone please provide me with  a counterexample ? Thank you","['differential-topology', 'examples-counterexamples', 'differential-geometry']"
4562404,Quasicompactness in terms of morphisms and $\operatorname{Spec} \mathbb{Z}$,"In The Rising Sea , Vakil states the following right before exercise 8.3.B (p. 231): Following Grothendieck‚Äôs philosophy of thinking that the important notions
are properties of morphisms, not of objects, we can restate the definition
of quasicompact (resp. quasiseparated) scheme as a scheme that is quasicompact
(resp. quasiseparated) over the final object $\operatorname{Spec}\mathbb{Z}$ in the category of schemes. It is clear to me that if $X\to \operatorname{Spec}\mathbb{Z}$ is quasicompact (resp. quasiseparated), then X is quasicompact (resp. quasiseparated), since $\operatorname{Spec}\mathbb{Z}$ is affine. It is also clear that if $X$ is quasiseparated, then the morphism is quasiseparated, since every open subscheme of a quasiseparated scheme is also quasiseparated. The problem is that I am not sure how to verify that if $X$ is quasicompact, then the morphism $X\to \operatorname{Spec}\mathbb{Z}$ is quasicompact. This is clear if $X$ is noetherian, but I can't see why it holds in general. Related question that may be useful to solve my problem: how does $\operatorname{Spec}\mathbb{Z}$ behave? Is it true that every open subscheme of this scheme is affine? Is every affine open subscheme of the form $\operatorname{Spec}\mathbb{Z}_f$ ?","['zariski-topology', 'algebraic-geometry', 'schemes']"
4562408,How to solve $y(x)^{y'(x)} = |x|^{|x|}$ for $y(x)$?,"To practice ordinary differential calculus, I set myself a few problems to solve.
One of those problems is ""Solve $y(x)^{y'(x)} = |x|^{|x|}$ for $y(x)$ !"" with $x \in \mathbb{R} \backslash \left\{ 0 \right\}$ and $y(x) \in \mathbb{C} \backslash \left\{ 0 \right\}$ . So I started: $$
\begin{align*}
y(x)^{y'(x)} &= |x|^{|x|} \quad\mid\quad \ln\left( ~~ \right)\\
\ln\left( y(x)^{y'(x)} \right) &= \ln\left( |x|^{|x|} \right)\\
y'(x) \cdot \ln\left( y(x) \right) &= |x| \cdot \ln\left( |x| \right) \quad\mid\quad \int ~\operatorname{d}x\\
\int y'(x) \cdot \ln\left( y(x) \right) ~\operatorname{d}x &= \int |x| \cdot \ln\left( |x| \right) ~\operatorname{d}x + c_{1}\\
-y(x) + \ln\left( y(x)^{y(x)} \right) &= \int |x| \cdot \ln\left( |x| \right) ~\operatorname{d}x + c_{1}\\
\end{align*}
$$ Since the equation reminds me of power towers, I tried to solve the equation with the lambert W-function: $$
\begin{align*}
-y(x) + \ln\left( y(x)^{y(x)} \right) &= \int |x| \cdot \ln\left( |x| \right) ~\operatorname{d}x + c_{1}\\
-y(x) + \ln\left( y(x) \right) \cdot y(x) &= \int |x| \cdot \ln\left( |x| \right) ~\operatorname{d}x + c_{1}\\
-y(x) + \ln\left( y(x) \right) \cdot e^{\ln(y(x))} &= \int |x| \cdot \ln\left( |x| \right) ~\operatorname{d}x + c_{1}\\
\end{align*}
$$ Now comes the problem: I don't know how to continue.
Is there a nice way to continue? Wolfram|Alpha tells me that there is solution to this formula via using the lambert W-function: $$y(x) = \frac{\int |x| \cdot \ln\left( |x| \right) ~\operatorname{d}x + c_{1}}{\operatorname{W}\left( \frac{\int |x| \cdot \ln\left( |x| \right) ~\operatorname{d}x + c_{1}}{e} \right)} \text{ or } y(x) = \frac{\int^{x}_{1} |\xi| \cdot \ln\left( |\xi| \right) ~\operatorname{d}\xi + c_{1}}{\operatorname{W}\left( \frac{\int^{x}_{1} |\xi| \cdot \ln\left( |\xi| \right) ~\operatorname{d}\xi + c_{1}}{e} \right)}$$ Just how?","['lambert-w', 'calculus', 'ordinary-differential-equations', 'real-analysis']"
4562409,"How do I find A in $y = Ax^2 + x + 7000$ (differential calculus, Leibniz's notation)","So the problem I'm trying to solve is prefaced with this: Earlier we mentioned that NASA claims that the Vomit Comet can make passengers experience weightlessness for about 25 seconds. Let‚Äôs check on that claim.
To simulate weightlessness (neutral buoyancy) the pilot must execute a parabolic flight path: $y = Ax^2 + Bx + C.$ In Problem #88 you should have found that B and C were 1 and 7000,
respectively, so the flight path is $y = Ax^2 + x + 7000$ with A yet to be determined. The pilot will climb at an angle of 45‚ó¶
to an altitude of about 7000 meters and then
follow this parabolic path to produce a vertical acceleration of d $d^2y/dt^2 = ‚àí9.8 m/s^2$ (matching the
acceleration due to gravity) and horizontal acceleration of d
2x
dt
2 = 0. This will provide neutral
buoyancy inside the plane. On the way back down the pilot pulls out of this dive when the
altitude returns to 7000 meters.
For training purposes this is repeated 40 times. And this is the problem itself: To determine A we need one more fact. At the beginning of the maneuver, the initial
airspeed is about 180 meters/second (approximately 400 mph). Use this to determine dx/dt
and in turn use this and the fact that $d^2y/dt^2$ = ‚àí9.8 to determine A. The solution is $A = -9.8 / 180^2$ . I think I am confused about some of the concepts involved in solving this problem, which are detailed here along with things I know: I'm not sure how to achieve the ""speed"" of things in calculus. I am used to velocity, which you find by taking the derivative of whatever you're working with, and acceleration is found with the second derivative. So, how is speed calculated? I understand that airspeed is the sum of windspeed and groundspeed. In order to visualize this, I drew a right triangle with  the airspeed being the diagonal (which in this case I believe is curved, so I guess it's technically not a right triangle, but for simplicity's sake this is what I used), the bottom being the groundspeed ( $dx/dt$ ) , and the side being the windspeed ( $dy/dt$ ). I am guessing in order to solve this I would need to utilize Pythagorean's theorem, $a^2+b^2=c^2$ , which in this problem is $180^2 = a^2 + b^2$ . What I don't understand about this is how is this relevant to finding A? From what I understand, A is supposed to represent how wide the parabola is. This is what I did to determine $dx/dt$ : $dy = 2Axdx + dx$ $dx = dy/2Ax+1$ $dx/dt = 1/(2Ax+1)$ I don't understand how I would use this and the fact that $d^2y/dt^2 = ‚àí9.8 m/s^2$ to solve for A.","['differential', 'physics', 'calculus', 'derivatives']"
4562451,"Given $8\sqrt{p} = q\sqrt{80}$, where $p$ is prime, is the solution unique?","I had this maths question: Given that $$8\sqrt{p} = q\sqrt{80}$$ where $p$ is prime, find the value of $p$ and the value of $q$ I did this by simplifying the RHS to $4q\sqrt{5}$ and comparing clearly gives $p=5$ and $q=2$ However, I also thought why not do this by getting unitary surds on either side, eg $$8\sqrt{p} = q\sqrt{80} \Rightarrow \sqrt{64p} = \sqrt{80q^2}$$ This tells me that $64p=80q^2$ or equivalently $4p = 5q^2$ . How would I be able to get $p$ and $q$ from this method? How do I know that the solution is unique? If so, is it fortuitous that we get a unique solution with these particular numbers or will it always be unique - I think I just need to see a proof to convince myself!",['algebra-precalculus']
4562454,The existence of a partial derivative at a point,"Let $f(x,y) = \frac{xy}{x^2+y^2}$ if $(x,y)\neq(0,0)$ and $f(x,y) = 0$ if $(x,y)=(0,0)$ . By definition, we have $f_x(0,0) = \lim_{h\rightarrow0} \frac{f(h,0)-f(0,0)}{h}=0$ .
But we also have that $f_x(x,y) = \frac{y(y^2-x^2)}{(x^2+y^2)^2}$ , and from this equation it seems that $f_x(x,y)$ is not defined at $(0,0)$ . Why is this the case? I can see that $f_x(x,y) = \frac{y(y^2-x^2)}{(x^2+y^2)^2}$ doesn't take into account that "" $f(x,y) = 0$ if $(x,y)=(0,0)$ "", whereas by the definition, $f_x(0,0)$ is defined $\iff$ $f(0,0)$ is defined. But I still am not sure to fully understand why we cannot use the equation of $f_x$ to determine whether $f_x$ is defined at $(0,0)$ or not.","['partial-derivative', 'multivariable-calculus']"
4562469,Principle of Contraction for Random Variables,"Let $\epsilon_1, \epsilon_2, \epsilon_3, ..., \epsilon_n, ...$ be a sequence of independent random variables where $P[\epsilon_i=-1]=P[\epsilon_i=1] = 1/2$ for all $i$ , i.e. the so-called Rademacher sequence. Let $u_1, u_2, u_3, ..., u_n, ...$ be a sequence of reals. Define a random series $S=\sum_{i=1}^\infty \epsilon_i u_i$ . Let $\lambda_i\in [0,1]$ , fixed, for all $i$ . Define another random series $S_\lambda=\sum_{i=1}^\infty \lambda_i \epsilon_i u_i$ . Principle of Contration : If $S$ converges almost surely, then $S_\lambda$ also converges almost surely. I tried to prove that $\{\sum_{i=1}^N \lambda_i \epsilon_i u_i\}_N$ is a Cauchy sequence almost surely but I failed in that $\epsilon_i u_i$ can be positive for some $i$ 's and negative for some other $i$ 's. To be more specific, for $N_2>N_1$ , $$\left|\sum_{i=1}^{N_1} \lambda_i \epsilon_i u_i - \sum_{i=1}^{N_2} \lambda_i \epsilon_i u_i\right|=\left|\sum_{i=N_1+1}^{N_2} \lambda_i \epsilon_i u_i\right|.$$ We want the RHS above goes to zero as $N_1, N_2 \to \infty$ . What we have from the almost sure convergence of $S$ is, $\left|\sum_{i=N_1+1}^{N_2} \epsilon_i u_i\right|$ goes to zero as $N_1, N_2 \to \infty$ , which I don't know how to use to derive the desired convergence above. Thanks for any help. Edit: The book mentions that, if $S$ converges almost surely, then $\mathbb P[|S|>x]$ goes to zero very rapidly as $x\to\infty$ . One can use this fact to prove the Principle of Contration . I didn't see how and so tried the Cauchy sequence argument above. By the way, I also didn't see why the probability $\mathbb P[|S|>x]$ decreases rapidly though I know it will decrease to zero as $x\to\infty$ .","['measure-theory', 'rademacher-distribution', 'convergence-divergence', 'probability', 'random-variables']"
4562489,"How to avoid ""impossible"" linears with trig integrals","Let's say I want to integrate $\int\sec^3xdx$ . Due to the way this expression is set up, you must use integration by parts, and not u-sub, etc. Applying integration by parts, I get $\sec{x}\tan{x}-\int{\sec{x}\tan^2{x}dx}$ . For the new integral here, using integration by parts again results in $\sec{x}\tan{x}-(\sec{x}\tan{x}-\int\sec^3{x}dx)$ . The $\sec{x}\tan{x}$ terms cancel out, resulting in just $\int\sec^3{x}dx$ . Uh-oh... isn't that where we started?? Wump wump. And to make matters even more confusing, consider $2\int\sec^3xdx$ , which we'll assign to the variable $a$ . Applying all of the above steps again, we somehow end up with $a = 2a$ ... hang on a minute, that doesn't seem about right. Of course, the real reason behind this seemingly ""impossible"" result is that an antiderivative isn't just one equation, it's a whole set. Hence the "" $+C$ "". And due to the properties of logarithms, it's not inconceivable that multiplying $a$ by a scalar multiple will indeed result in another member of $a$ , right? I'd like to make sure my logic is all true, and logarithms are indeed the reason why this is happening. I'd also like to know what to do to avert this issue should I ever come across it.","['integration', 'trigonometry', 'paradoxes', 'logarithms']"
4562494,"Are there any perfect squares of the form $\underbrace{88\cdots8}_{n\text{ times}}1$ (in decimal, at least two $8$'s)?","I saw this problem recently and it is deceptively hard.  The usual $\pmod{4}$ trick won't work, and indeed there will be perfect squares whose last $n$ digits will be $\underbrace{88\cdots8}_{n\text{  times}}1$ , for any $n$ . I can show that if $\underbrace{88\cdots8}_{n\text{  times}}1$ is a perfect square, $2n$ digits total, then the decimal representation of $\sqrt{8/9}$ must start with $n$ digits followed by almost that many zeroes (like $n-1$ or so).  This seems preposterous, but I can't figure out how to rule it out.  I've thought of using continued fractions, since there is a limit on how well $\sqrt{8/9}$ can be approximated with rationals, but I can't seem to get a tight enough inequality.  Maybe someone with more expertise in Diophantine approximation can answer this? Note: even if you can prove that there aren't infinitely many perfect squares of this form, even if you don't have a computable bound on how large they might be, I'd still be interested.","['diophantine-approximation', 'number-theory', 'diophantine-equations', 'square-numbers', 'decimal-expansion']"
4562640,Supersingular elliptic curve over $\mathbb F_p$,"I guess that the answer should be well known, but I fail to find a reference for it. For any prime $p$ , is there a supersingular elliptic curve actually defined over $\mathbb F_p$ ? In Katz and Mazur's book in the proof of Theorem 2.9.4, the authors show that any supersingular elliptic curve over $\overline{\mathbb F_p}$ can be defined over $\mathbb F_{p^2}$ if $p$ is odd, and over $\mathbb F_{16}$ if $p=2$ . But is there at least one of them which actually stems from $\mathbb F_p$ ? Edit: In Li and Oort's book ""Moduli of supersingular abelian varieties"", at the top of page 9, the authors write ""For every $p$ there exists a supersingular elliptic curve over $\mathbb F_p$ ."" Therefore it seems that the answer is affirmative, however they do not offer a justification as to why it is true.","['number-theory', 'algebraic-geometry', 'elliptic-curves', 'arithmetic-geometry']"
4562650,What is the difference between $y_{|x=1}=2$ and $y(1)=2$,What is the difference between $$y_{|x=1}=2$$ and $$y(1)=2$$ Let's say you have an equation $$xy^3+y^2-y+2=C$$ and the value of $C$ is asked when $y_{|x=1}=2$ . Can I just directly input the values?,"['notation', 'ordinary-differential-equations']"
4562667,equality between symmetric differences,"I'm trying to show this property of the symmetric difference.
I want to show in which case this equality holds: $$
\mathbb{P}(A\Delta C) = \mathbb{P}(A\Delta B)+\mathbb{P}(B\Delta C)
$$ What I know is that $$
\mathbb{P}(A\Delta C)\leq \mathbb{P}(A\Delta B)+\mathbb{P}(B\Delta C)
$$ always holds and the $\subseteq$ comes from the monotonicity. To show the equality i was thinking about using "" $[(A \bigtriangleup B) \bigcup (B \bigtriangleup C)] \setminus (A \bigtriangleup C) = (A \bigtriangleup B) \bigcap (B \bigtriangleup C)$ "" but I even have to show the latter and i don't know how to do it.","['elementary-set-theory', 'probability']"
4562736,Find the all positive integer solutions to: $x^3-x^2+x=3y^3$,Number theory problem: Find the all positive integer solutions to: $$x^3-x^2+x=3y^3$$ Here are my attempts: $$x(x^2-x+1)=3y^3$$ $$x(x+1)(x^2-x+1)=3y^3(x+1)$$ $$x(x^3+1)=3(x+1)y^3$$ $$x^4+x^2=3(x+1)y^3$$ I can not see how can I proceed.,"['elementary-set-theory', 'number-theory', 'polynomials']"
4562737,How many ways we distribute 10 distinct objects among 4 persons such that only one person gets exactly 4 objects?,How many ways we distribute 10 distinct objects among 4 persons such that only one person gets exactly 4 objects? The correct answer given is ${10 \choose 4} \cdot 3^6$ . Here they are choosing $4$ objects out of the $10$ and giving them to one person and the remaining $6$ objects have $3$ choices each. Shouldn't the answer be ${10\choose 4}{4 \choose 1} \cdot 3^6$ as for the group made of $4$ objects we have $4$ choices too. So choose $4$ from $10$ objects and choose $1$ from $4$ persons and then give that $4$ objects to that person. Why is this approach wrong?,"['combinations', 'combinatorics', 'discrete-mathematics']"
4562765,Solution of ODE strictly monotone increasing,"Let $f \in C^1(\mathbb R)$ and look at $y'(t) = f(y(t))$ , $y(0) = y_0$ such that $f(y_0) > 0$ . Show that every solution is strictly monotone increasing. My idea: It is clear, if $f>0$ on $\mathbb R$ . So assume that $y'$ is not strictly increasing. So there exists $a$ with $y'(a)=f(y(a))\leq 0$ . By intermediate value theorem there exists $\xi$ between $0$ and $a$ so that $y'(\xi)=f(y(\xi))=0$ . Now I don't know how to got on.",['ordinary-differential-equations']
