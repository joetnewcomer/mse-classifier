question_id,title,body,tags
308043,Least value of $a$ for which at least one solution exists?,"What is the least value of $a$ for which
$$\frac{4}{\sin(x)}+\frac{1}{1-\sin(x)}=a$$
has atleast one solution in the interval $(0,\frac{\pi}{2})$? I first calculate $f'(x)$ and put it equal to $0$ to find out the critical points.
This gives
$$\sin(x)=\frac{2}{3}$$
as $\cos(x)$ is not $0$ in $(0,\frac{\pi}{2})$. I calculate $f''(x)$ and at $\sin(x)=\frac{2}{3}$, I get a minima. Now to have at least one solution, putting $\sin(x)=\frac{2}{3}$ in the main equation, I get $f=9-a$, which should be greater than or equal to $0$. I then get the 'maximum' value of $a$ as $9$.
Where did I go wrong?
[Note the function is $f(x)=LHS-RHS$ of the main equation.]","['quadratics', 'derivatives']"
308067,Binomial random variable with number of trials being a Poisson random variable,Let $Y$ be the number of heads in a an $X$ toss sequence of flipping a coin with probability $p$ of heads. Show that $Y \sim \mathrm{Pois}(p \lambda)$ if $X \sim \mathrm{Pois}(\lambda)$.,['probability']
308090,"Show this equation has at least one root in $(0,1)$","Let $ax^2+bx+c=0$ be a quadratic equation, where $a,b,c\in\mathbb{R}$. If $2a+3b+6c=0$, then show that this equation will have atleast one root in $(0,1)$. I think it involves either Rolle's Theorem or Lagrange's Mean Value Theorem, but can't think further. Please help, and yes, thanks in advance!",['calculus']
308103,Silly question: Why is $\sqrt{(9x^2)} $ not $3x$?,"I had to find the derivative of $f(x) = \sqrt{(9x^2)}$. I applied chain rule with the following steps. Let $f(x)$ be $\sqrt{x}$ and $g(x)$ be $9x^2$ $$ \begin{align} &f'(g(x)) \times g'(x)  \\
 & = \frac{1}{2\sqrt{(9x^2)}} \times 18x \\
 & = \frac{18x}{2\sqrt{9x^2}} \\
 & = \frac{9x}{3\sqrt{x^2}}\\
 & = \frac{9x}{3\sqrt{x^2}} \\
 & = \frac{3x}{\sqrt{x^2}} \end{align}$$ I got the answer but I don't understand why the last bit doesn't simplify to $3$ because $\sqrt{x^2}$ is $x$ and if it does then why does the back of my textbook and W|A say that it is not? EDIT: Okay, so from what I understand, it should be actually $3|x|$. If for example, I had $\sqrt{4x^2}$, I will have $2|x|$, if my understanding is correct.","['calculus', 'derivatives']"
308113,Practical question about a fixpoint,"Let $c\in \Bbb R^n$ be some fixed vector and $A\in \Bbb R^{n\times n}$ be a fixed matrix with non-negative elements. Consider the map $f:\Bbb R^n\to\Bbb R^n$ given by
$$
  f^i(x^1,\dots,x^n) = 
  \begin{cases}
    1,&x^i\geq c^i \\
    0, &x^i<c^i.
  \end{cases}
$$
By abusing notation, why may think that $f$ is a vector-valued indicator function $f(x) = 1_{\{x\geq c\}}$. Consider further the following dynamics:
$$
  x_{k+1} = Af(x_{k}). \tag{1}
$$
Clearly, not matter where we start, it takes only finitely many iterations (at most $n$) to converge to a fixpoint of $Af(\cdot)$. I wonder, however, whether there is a handy formula for such a fixpoint given the initial value $x_0$. Please, feel free to retag. Updated: let me elaborate on what I know. Denote $F(x) = Af(x)$. Note that since $A$ has non-negative elements only, it holds that $x_{k+1}\leq x_{k}$ for $k\geq 1$ where the inequality shall be understood as an element-wise one. Since $f$ is a monotone function, $f(x_{k+1})\leq f(x_{k})$ as well, thus there are two cases. If $f(x_{k+1}) = f(x_k)$ then 
$$
   F(x_{k+1}) = Af(x_{k+1}) = Af(x_k) = x_{k+1}
 $$
and thus $x_{k+1}\in \mathsf{Fix}(F)$. It $f(x_{k+1})\neq f(x_k)$, then for some $1\leq i\leq n$ it holds that $f^i(x_k) =1$ but $f^i(x_{k+1}) = 0$. Since $f$ most $n$ components, the case 2. can happen at most $n$ times. In fact, I know that 
$$
  \mathsf{Fix}(F|x_0) = F^m(x_0)
$$
where $m$ is a number of non-zero components of $f(x_0)$. I wonder, though if there is a better formula.","['linear-algebra', 'real-analysis']"
308117,How to compute Nullspace on maple?,"I have the matrix 
$$A := \begin{bmatrix}6& 9& 15\\-5& -10& -21\\ 2& 5& 11\end{bmatrix}.$$ Can anyone please tell me how to both find the eigenspaces by hand and also by using the Nullspace command on maple? Thanks.","['maple', 'linear-algebra']"
308123,What do characteristic polynomials characterize?,"Let $R$ be an integral domain and $F$ a finitely generated free module over $R$. For a linear transformation $\alpha\in\operatorname{End}_R(F)$, the characteristic polynomial is \begin{equation}
p_\alpha(t)=\det(t-\alpha)\in R[t].
\end{equation} Similar transformations have same characteristic polynomial. However, these polynomials fail to characterize similarity, in the sense that non-similar transformations can have the same characteristic polynomial. So my question is: What can we say about two transformations $\alpha$ and $\beta$ that share the same polynomial? Obviously, $\alpha$ and $\beta$ have the same spectrum and same algebraic multiplicity for each eigenvalue. But unless $R$ is an algebraically closed field--in this case the polynomial is determined by the roots and their multiplicities--we should be able to say more about $\alpha$ and $\beta$. Also we should know more than traces and determinants since they are just two of the coefficients. Can someone give a hint?
Thanks!","['matrices', 'linear-algebra', 'characteristic-polynomial', 'abstract-algebra']"
308147,Understanding calculus formulas intuitively,"I am currently studying calculus in Russian and my course book is very rigorous.I used to think that I understand everything but I recently noticed that I only understand the logical steps in proofs of theorems and I actually don't understand all the formulas and theorems intuitively and can't see the motivation in proofs.Is there any way to improve intuitive understanding and really feel how mathematics works ,could you recommend any books?","['calculus', 'soft-question']"
308149,"What is the meaning of ""mean-field""?","In lots of Bayesian papers, people use variational approximation. In lots of them they call it  "" mean-field variational approximation"". Does anyone know what is the meaning of mean-field in this context?","['approximation', 'bayesian', 'probability']"
308158,Proving {$b_n$}$_{n=1}^\infty$ converges given {$a_n$}$_{n=1}^\infty$ and {$a_n b_n$}$_{n=1}^\infty$,"Suppose {$a_n$}$_{n=1}^\infty$ and  {$b_n$}$_{n=1}^\infty$ are sequences such that {$a_n$}$_{n=1}^\infty$ coverges to A$\neq$0 and {$a_n b_n$}$_{n=1}^\infty$ converges.  Prove that {$b_n$}$_{n=1}^\infty$ converges. What I have so far: $b_n = {a_n b_n \over a_n}$ $\to$ $C \over A$, $A\neq0$ |$b_n - {C \over A}$| = |${a_n b_n \over a_n} - {C \over A}$| = |${Aa_nb_n - Ca_n \over Aa_n}$| $ \leq $ |${1 \over Aa_n}||Aa_nb_n - Ca_n$|=|${1 \over Aa_n}||a_n(Ab_n - C)$| $\leq |{1 \over Aa_n}||a_n||(Ab_n - C)$|.  Note: since $a_n$ converges, there is M>0 such that |$a_n| \leq$M for all n $ \in\Bbb N$. Thus, |${1 \over Aa_n}||a_n||(Ab_n - C)$| = |${1 \over M}||M||(Ab_n - C)$|.  And this is where I get lost.  Any thoughts? Or am I completely wrong to begin with?","['proof-writing', 'real-analysis']"
308176,Notation of an iterated function on 2 sets,"Let $X$ and $C$ be two sets, I have defined an iterated function on them $f: X \times C \rightarrow X$. What interests me is the iterations of $f$ on an initial value $x \in X$, and a sequence $(c_n)_{n \in \mathbb{N}} \in C$, for instance $f(f(f(x, c_0), c_1),c_2)$. I am wondering if there is some conventional way to express these iterations, for example by adding superscript on $f$. What I need to write are: 1) iterations from $c_0$ to $c_{n_0}$ where $n_0 \in \mathbb{N}$ 
$$f(\ldots f(f(f(x, c_0), c_1), c_2) \ldots, c_{n_0})$$ 2) iterations from $c_k$ to $c_{k+m}$:
$$f(\ldots f(f(\ldots, c_k), c_{k+1}) \ldots, c_{k+m})$$ Could anyone help?","['notation', 'convention', 'functions']"
308178,"Path connectedness, metrizability and path lengths","I was wondering if there is some way to topologically construct a path connected space where it is possible to measure the lengths of the paths? Like, if a space is metrizable and path connected, can you measure the path lengths? If not, what else is needed?","['general-topology', 'connectedness', 'measure-theory']"
308215,An exercise in Liu regarding a sheaf of ideals (Chapter II 3.4),"I'm fairly certain there is both a typo and an omission in this exercise. It reads ""Let $X$ be a scheme and $f \in \mathcal{O}_X(X)$. Show that $U \mapsto f|_U \mathcal{O}_X(U)$ for every affine open subset $U$ defines a sheaf of ideals on $X$. We denote this sheaf of ideals by $f \mathcal{O}_X$..."" Surely ""affine"" above should be omitted, but my real question is are we missing any hypotheses on $f$? It is clear that $f \mathcal{O}_X$ defines a presheaf satisfying the uniqueness condition, i.e., if an global section restricts to zero everywhere on an open over, then the element is identically $0$, as $\mathcal{O}_X$ is a sheaf to begin with. However, in proving that is satisfies the criterion regarding the glueing of local sections, do we not need the hypothesis that $f|_U$ is not a zero-divisor for
  all $U$? This is the only condition in which I'm able to get at the result. Am I missing anything? EDIT: Please see Martin Brandenburg's answer. I was mistaken. (But it was not a regrettable mistake, as the point which I missed deserves an extra line or two of qualification.)","['sheaf-theory', 'algebraic-geometry', 'schemes']"
308230,Expectation of the min of two independent random variables?,"How do you compute the minimum of two independent random variables in the general case ? In the particular case there would be two uniform variables with a difference support, how should one proceed ? EDIT: specified that they were independent and that the uniform variables do not have obligatory the same support range.","['uniform-distribution', 'probability-distributions', 'probability', 'random-variables']"
308249,Convergence of probability measures in total variation and limits of integrals,"Suppose $\mu_n$ and $\mu$ are probability measures such that $\mu_n \to \mu$ in total variation. I'm curious to what extent we can say $$\int f \ \mathrm{d}\mu_n \to \int f \ \mathrm{d}\mu,$$ when $\mu_n \to \mu$ in total variation - recall that this means $$\lim_{n \to \infty} \sup_{A \in \mathcal F}|\mu_n (A) - \mu(A)| \to 0,$$ where $\mathcal F$ is the underlying $\sigma$-algebra and $f$ of course is a Borel function. I've looked around a bit (admittedly not too hard - I thumbed through the TOC and index of Billingsley's ""Convergence of Probability Measures"" and looked at the Wikipedia page) and it seems to me I ought to be able to say that this should happen under very mild requirements. Under weak convergence of probability measures, of course, $\int f \ \mathrm{d}\mu_n \to \int f \ \mathrm{d}\mu$ holds for all bounded, continuous functions, which competely characterizes this mode of convergence. Surely I can get away with more with total variation convergence - what I hope ""getting away with more"" entails is that I can widen the class of $f$ such that this happens. For example, since $\mu_n (A) \to \mu(A)$ for all $A$ rather than just those $A$ with boundary probability $0$ I would hope we could loosen the continuity assumption on $f$.","['probability-theory', 'measure-theory']"
308255,Is Euler's lemma of fluid mechanics a nonlinear version of Liouville's theorem of ODEs?,"Liouville's Theorem Consider the following linear system of ordinary differential equations:  $$\tag{1}
 \dot{\mathbf{x}}=A(t)\mathbf{x}(t).$$ Let $\mathbf{x}_1, \mathbf{x}_2,
 \ldots, \mathbf{x}_n$ be solutions of (1). Define the Wronskian
  determinant to be  $$W(t)=\det \begin{bmatrix} \mathbf{x}_1 &
 \mathbf{x}_2 & \ldots & \mathbf{x}_n\end{bmatrix}.$$ Then we have the
  following differential relation for $W(t)$: $$\tag{L}
 \dot{W}(t)=\verb+trace+\, A(t)\,\cdot\,W(t).$$ Compare with a lemma due to Euler which I encountered in a course of fluid mechanics I am attending. Here $\mathbf{x}$ refers to Eulerian coordinates and $\mathbf{y}$ refers to Lagrangian coordinates. Euler's Lemma Let $\mathbf{u}(\mathbf{x}, t)$ be the velocity field of a fluid flow $\mathbf{\Phi}(\mathbf{y}, t)$, meaning that:
  $$\begin{array}{cc} \displaystyle
\begin{cases} \dot{\mathbf{x}}(t)=\mathbf{u}(\mathbf{x}(t), t) \\ \mathbf{x}(0)=\mathbf{y}\end{cases}, & \mathbf{x}(t)=\mathbf{\Phi}(\mathbf{y}, t)\end{array}.$$
  Denote with $J$ the Jacobian of the deformation gradient, that is 
  $$J(\mathbf{y}, t)=\det D_{\mathbf{y}}\mathbf{\Phi}(\mathbf{y}, t).$$
  Then we have the following differential relation for $J$:
  $$\tag{E}\frac{dJ}{dt}(t)=(\verb+div+\,\mathbf{u})\,J.$$ Even if it is formulated with the language of fluid mechanics, this lemma is essentially a result in ordinary differential equations, just like Liouville's theorem. My question is if Euler's lemma can be viewed as a nonlinear version of Liouville's theorem and if either one of the two results can be derived from the other. Thank you for reading.","['fluid-dynamics', 'ordinary-differential-equations']"
308264,Prove that two normed linear spaces are equivalent as metric spaces if and only if the norms are equivalent?,"We have the two norms $\|\cdot\|_a$ and $\|\cdot\|_b$ on the vectorspace V. They're equivalent if there exists a $k>0$ and $K>0$ so that  $k\|\cdot\|_a\le\|\cdot\|_b\le$ K$\|\cdot\|_a$ for all $v\in V$. I've proved this is an equivalence relation on the set of norms. I now have to prove, that $d_{\|\cdot\|_a}$ is equivalent to $d_{\|\cdot\|_b}$ if and only if $\|\cdot\|_a$ is equivalent to $\|\cdot\|_b$. I've already proven the ""if""-statement, I just have to prove the ""only if""-statement now, and I don't really have any ideas how to do it. I would appreciate a little help very much.","['metric-spaces', 'differential-geometry']"
308280,Commutative algebra - integral extensions question [closed],"This question is unlikely to help any future visitors; it is only relevant to a small geographic area, a specific moment in time, or an extraordinarily narrow situation that is not generally applicable to the worldwide audience of the internet. For help making this question more broadly applicable, visit the help center . Closed 11 years ago . This is homework, but I am pretty stuck and I feel I am lacking intuition on this so I ask. The question is as follows : let $k$ be a field and $R = k[x_1, \dots, x_n]$ (this notation means a polynomial ring in $n$ variables with coefficients in $k$ but there are possibly relations between the variables, i.e. $R \cong k[X_1, \dots, X_n] / I$ where $I$ is an ideal of the ring $k[X_1, \dots, X_n]$ where the elements $X_i$ are algebraically independent indeterminates). Consider $G \le \mathrm{Aut}(R)$ a finite subgroup of automorphisms of the ring and let $R^G$ denote the fixed subring of $R$ by the action of $G$, i.e.
$$
R^G = \{ r \in R \, | \, \forall g \in G, \quad g \cdot r = r\}.
$$
Assume $k \subseteq R^G$. We were asked to show that the extension $R^G \to R$ is an integral extension and that $R$ is a finitely generated $R^G$-module (which is okay). Writing
$$
R = \langle r_1, \dots, r_m \rangle_{R^G},
$$
for each generator $r_i$ we know that there exists an integrality relation of the form
$$
r_i^{n_i} + s_{i1} r^{n_i - 1} + \dots + s_{in_i} = 0, \quad s_{ij} \in R^G.
$$
Fix such a relation for each generator. Define
$$
S = k[ s_{11},\dots,s_{1n_1},s_{21},\dots,s_{2n_2},\dots,s_{mn_m}] \subseteq R^G
$$
to be the $k$-subalgebra generated by the coefficients of these polynomials in $R^G[X]$. We are asked to show that $R$ and $R^G$ are finitely generated $S$-modules and that $R^G$ is a finitely generated $k$-algebra (i.e. is a polynomial ring over some elements in $R^G$). All I have managed to show is that if $R^G$ is a finitely generated $S$-module, then $R$ also is, because since $R$ is a finitely generated $R^G$-module, I can use the fact that 
$$
R = \sum_{i=1}^m R^G r_i = \sum_{i=1}^m \left( \sum_{j=1}^p S q_j \right) r_i = \sum_{i=1}^m \sum_{j=1}^p r_i q_j.
$$
I don't need a full proof, just a hint towards a solution would be appreciated ; right now I just have no idea where to start. Edit: I asked my teacher and he confirms that all he really wanted was to give steps to show that $R^G$ was an affine $k$-algebra, so we can use whatever generators we want (which wasn't explicit in the question). I'll be fine for the rest, but thank you all for noticing I was doing an impossible question (or uselessly too hard).","['commutative-algebra', 'algebraic-geometry']"
308281,Hausdorff space if and only if subspaces are closed,"Let $X$ be a space that is the union of the subspaces $S_1,\dots,S_n$, where each $S_i$ is homeomorphic to the unit circle, and suppose that there is some $p \in X$ such that $S_i \cap S_j = \{p\}$ whenever $i \neq j$. I am trying to show that $X$ is Hausdorff if and only if each $S_i$ is closed in $X$, and also to construct an example of such a space $X$ which is not Hausdorff. If we assume that $X$ is Hausdorff, then it's easy to show that each $S_i$ is closed in $X$, since the unit circle is compact and compact subspaces of Hausdorff spaces are closed. I'm having trouble with the converse, however. Let $x_1,x_2$ be distinct points of $X$, then $x_1 \in S_i, x_2 \in S_j$ for some $i,j$. Suppose that neither point is  $p$. Then $ X - (S_i - \{p\}) = S_1 \cup \dots \cup S_{i-1} \cup S_{i+1} \cup \dots S_n $ is closed, so $S_i - \{p\}$ is open. If $i \neq j$, then $S_i - \{p\}, S_j - \{p\}$ are disjoint neighbourhoods of $x_1,x_2$. Now if $i = j$, we have $x_1,x_2 \in S_i - \{p\}$, and I'm not seeing how we could find disjoint neighbourhoods of $x_1,x_2$, given that we don't know the topology of $S_i$. Do we have to assume that the unit circle, and hence each $S_i$, has the topology induced by the Euclidean metric? The last case is when one of the points, say $x_1$, is $p$. Then $x_1 \in S_1$, which is closed, and $x_2 \notin S_1$, so we can find a neighbourhood $U_2$ of $x_2$ which does not intersect $S_1$, and therefore does not contain $x_1$. How could we produce a neighbourhood $U_1$ of $x_1$ not intersecting $U_2$, though? Finally, any help on constructing a non-Hausdorff $X$ would be appreciated; I'm guessing what we proved means that we need the $S_i$'s to not all be closed in $X$, but I can't see how to use this fact to explicitly construct such an $X$.",['general-topology']
308317,"Cheese, mouse and a cat","I have a problem and I don't know how to solve it because I don't know where to start. 
If we have the following situation: Room 1-Room 2-Room 3-Room 4-Room 5 There is a little mouse in room 4 and he always forgets in which room he has been when going to the next room. In room 5 there is a big hungry cat waiting for him and in room 1 there is cheese. What is the chance he will get the cheese and not being eaten by the cat?
My error solution:
If I go like $\displaystyle \left(\frac{1}{2}\right)^{3} + \left(\frac{1}{2}\right)^{4} +$ (endless possibilities). I know that this is not the way I should calculate it. This is I think a geometric distribution because it is memoryless. On the other hand I can use binomial distribution to calculate it but there are endless possibilities.. I just need a push in the right direction. Thanks in advance.","['statistics', 'probability']"
308318,Is the map $S^{2n+1}\rightarrow \mathbb{C}P^n \rightarrow \mathbb{C}P^n/\mathbb{C}P^{n-1}\cong S^{2n}$ essential?,"This question is motivated solely by idle curiousity. There is a natural map $p:S^{2n+1}\rightarrow \mathbb{C}P^n$ mapping a point on $S^{2n+1}\subseteq \mathbb{C}^{n+1}$ to the unique complex line it spans in $\mathbb{C}^{n+1}$. It is well know that $p$ gives $S^{2n+1}$ the structure of an $S^1$ bundle over $\mathbb{C}P^n$.  From this, one gets a long exact sequence in homotopy groups.  Since $\pi_k(S^1)  = 0$ for $k > 1$, one sees from this that $p_\ast :\pi_{2n+1}(S^{2n+1})\rightarrow \pi_{2n+1}(\mathbb{C}P^n)$ is an isomorphism.  In particular, $p$ is homotopically nontrivial. Likewise, notice that by collapsing the $2n-2$ skeleton of $\mathbb{C}P^n$ to a point, one gets a map $q:\mathbb{C}P^n\rightarrow \mathbb{C}P^n/\mathbb{C}P^{n-1}\cong S^{2n}$, the latter homeomorphism coming from the usual cellular picture of $\mathbb{C}P^n$.  It is easy to see that this map induces an isomorphism on $H_{2n}$, so is also homotopically nontrivial. My question is about the composition $q\circ p : S^{2n+1}\rightarrow S^{2n}$. Is the composition $q\circ p:S^{2n+1}\rightarrow S^{2n}$ also homotopically nontrivial? Here are some data points: The composition of two homotopically nontrivial maps need not be homotopically nontrivial.  The simplest examples are probably the following:  If $X$ and $Y$ are both noncontractible, then any of the ""natural"" inclusions $i:X\rightarrow X\times Y$ is homotopically nontrivial, the projection $X\times Y\rightarrow Y$ is homotopically nontrivial, but the composition is homotopically trivial. In the case $n=1$, $q$ doesn't actually collapse anything - it's a homeomorphism.  Thus, in this case $q \circ p$ is homotopically nontrivial.  (In fact, it's known to generate $\pi_3(S^2)$). For higher $n$, $\pi_{2n+1}(S^{2n})\cong \mathbb{Z}/2$, so the square of $q\circ p$ in $\pi_{2n+1}(S^{2n})$ is homotopically trivial. If we use $\mathbb{R}P^n$ instead of $\mathbb{C}P^n$, we end up getting a map $S^n\rightarrow S^n$.  This map is homotopically nontrivial iff $n$ is odd, where it acts by multiplication by 2 on the top homology group. Thanks, and please feel free to retag as appropriate!","['algebraic-topology', 'differential-geometry']"
308320,Find $\alpha$ such that $y'=\sqrt{1+y^4}-|y|^\alpha$ has global solutions,"How do I find $\alpha$ such that $y'=\sqrt{1+y^4}-|y|^\alpha$ has global solutions? For example, imposing $y'=0$ for $\alpha=4$ we get that for solutions with starting point in $$[-(\frac{1+\sqrt{5}}{2})^{1/4}, +(\frac{1+\sqrt{5}}{2})^{1/4}]$$ have global solutions while the others, with a comparison, can be shown to have vertical asymptotes. In general, I can ""see"", but I'm not able to carry out all the calculations needed, that when $2\alpha>4$, the equation $y'=0$ has solutions, thus we can find an interval inside which the solutions are global, while outside they are not (how to prove?) When $\alpha=2$ all the solutions are global, this I can prove by showing that $y'\rightarrow 0 \;(y\rightarrow \infty)$. When $\alpha<2$ we have $y'\rightarrow \infty \;(y\rightarrow \infty)$ but I can't really conclude something here. My suggestion is that there are no global solutions (maybe all?).",['ordinary-differential-equations']
308321,"Algebraic and geometric multiplicity, eigenspace and Transition Matrix","I have a matrix $$ A=\begin{bmatrix}6 & 9 &15 \\ -5&-10 & -21 \\2&5&11\end{bmatrix} $$ The Characteristic Polynomial is $ x^3-7x^2+16x-12 $ From this i have worked out the Eigenvalues to be $2,2,3$ and the corresponding Eigenvectors to be $ \begin{bmatrix} 3\\-3\\1 \end{bmatrix} $ For the value 2, and $ \begin{bmatrix} 1\\-2\\1 \end{bmatrix} $ For the value 3 However im not too sure what is meant by the Alegrabic multiplicity,Eigenspace and the Geometric multiplicity?? The Question further on asks to compute the $ JordanForm $ which i got to be $$ \begin{bmatrix}3 & 0 &0 \\ 0&2 & 1 \\0&0&2\end{bmatrix} $$ But then asks me to find the Transition matrix P by assembling the generalized eigenvectors. i've computed the generalized eigenvectors to be $ \begin{bmatrix}-6 & -3 &1 \\ 0&1 & -2 \\1&0&1\end{bmatrix} $ but im not sure how to find the Transition Matrix P from this??",['matrices']
308324,Function composition and Bell polynomials,"Suppose that we have the Taylor expansions :
$$f(x)=\sum_{n=1}^{\infty}\frac{a_{n}}{n!}x^{n}$$
$$g(x)=\sum_{n=1}^{\infty}\frac{b_{n}}{n!}x^{n}$$
Then we have the standard result :
$$g(f(x))=\sum_{n=1}^{\infty}\left(\sum_{k=1}^{n}b_{k}B_{n,k}(a_{1},...,a_{n-k+1})\right)\frac{x^{n}}{n!}\ \ \ \ \ (1)$$
Where $B_{n,k}(\cdot)$ are the partial Bell polynomials . 
Now suppose we have the expansion :
$$h(x)=\sum_{n=1}^{\infty}B_{n}(a_{1},...,a_{n})\frac{x^{n}}{(n!)^{2}}\ \ \ \ \ (2)$$
Where $B_{n}(\cdot)$ are the complete Bell polynomials. We want to express $h(x)$ in closed form as a composite function. Thus, we use the relation above, and we set:
$$\sum_{k=1}^{n}b_{k}B_{n,k}(a_{1},...,a_{n-k+1})=\frac{B_{n}(a_{1},...,a_{n})}{n!}\ \ \ \ \ (3)$$
How can we solve for $b_{k}$ !? To be more specific, I'm interested in the relation between the two expansions:
$$\sum_{n=0}^{\infty}\frac{B_{n}\left(a_{1},a_{2},...,a_{n}\right)}{n!}x^{n}\ \ \ \ \ (4)$$
And:
$$\sum_{n=0}^{\infty}\frac{B_{n}\left(a_{1},2!a_{2},...,n!a_{n}\right)}{(n!)^{2}}x^{n}\ \ \ \ \ (5)$$
Using the reasoning above - function composition - or any other method for that matter.","['power-series', 'combinatorics']"
308329,"How to rewrite $\sin^4 \theta$ in terms of $\cos \theta, \cos 2\theta,\cos3\theta,\cos4\theta$?","I need help with writing $\sin^4 \theta$ in terms of $\cos \theta, \cos 2\theta,\cos3\theta, \cos4\theta$. My attempts so far has been unsuccessful and I constantly get developments that are way to cumbersome and not elegant at all. What is the best way to approach this problem? I know that the answer should be: $\sin^4 \theta =\frac{3}{8}-\frac{1}{2}\cos2\theta+\frac{1}{8}\cos4\theta$ Please explain how to do this. Thank you!",['algebra-precalculus']
308339,Rigid body motion on the Poincare disc model of the hyperbolic plane,"I'd like to implement an interactive simulation of an actor controlled by the user moving around in the Poincaré disc model of the hyperbolic plane. I need to know how to perform translation and rotation on the Poincaré disc. If i represent points as regular Euclidean points in the unit circle, I believe that hyperbolic translation and rotation would then be Möbius transformations if you think of the points as complex numbers. Is this correct? If not what is a better way of performing translation and rotation. Assuming Möbius transformations are the right approach, however, I am unable to find defined anywhere how specific translations and rotations correspond to specific Möbius transformations. Can someone clear this up for me? I'm looking for functions of complex variables that correspond to ""translate z in direction d on the hyperbolic plane represented as the unit circle"" and ""rotate z around c by $\theta$ on the hyperbolic plane represented as the unit circle""","['hyperbolic-geometry', 'geometry']"
308342,Existence of an injection from $\Bbb N$ without the axiom of choice,"If you have a set $A$, and it satisfies that for some $x\in A$, there is a bijection between $A$ and $A\setminus\{x\}$. Does that imply that there is an injection from $\Bbb N$ to $A$?
It is clearly true in ZFC, but I ask if it is true in ZF.","['elementary-set-theory', 'axiom-of-choice']"
308343,"Find $\sum\limits_{k\, \text{ odd}} \frac{2(k^2-1)}{k^4+k^2+1}$","How to find $$\sum_{k \text{ odd}} \frac{2(k^2-1)}{k^4+k^2+1}$$ Here we find $\displaystyle\sum_{k=1}^{\infty} \frac{2(k^2-1)}{k^4+k^2+1}=1$ and we know that $\displaystyle\sum_{k \,\text{odd}} + \sum_{k \,\text{even}}=1.$ Can we use this information to find sum? Or, maybe we can find it on other way? We can say that our sum is equal to $$\color{red}{2}\sum_{k=1}^{\infty}\frac{(2k-1)^2-1}{(2k-1)^4+(2k-1)^2+1}=\sum_{k=1}^{\infty} \left(\frac{1-4k}{4k^2-2k+1}+\frac{4k-3}{4k^2-6k+3}\right),$$ but I don't think we can see something from that. EDIT: Actually, Wolfram find that $$2\sum_{k=1}^{\infty}\frac{(2k-1)^2-1}{(2k-1)^4+(2k-1)^2+1}=\pi \text{sech}\left(\frac{\sqrt{3} \pi}{2}\right).$$ It's pretty nice closed form.","['sequences-and-series', 'calculus', 'real-analysis']"
308352,What kind of combinatorial problem is this?,"Is there a theory from which the following problem comes? Does this type of problem have a name? Find the largest possible number of $k$-element sets consisting of points from some finite set and have pairwise singleton or empty intersections. I hope that was clear. If not, here's an example for $k=3$: Let the set of points be $S=\{1,2,3,4,5,6\}$. The most 3-element sets (with pairwise singleton or empty intersections) that can be constructed from $S$ is 4, such as $\{456,236,124,135\}$. I made a table for $|S|=3,4,5,6,7,8,9$ and got $1,1,2,4,7,8,12$, respectively, hoping I could dig up some information from OEIS. I read a little on Steiner systems, and although it feels like I'm in the neighborhood, I'm not confident... Edit1: typos. Edit2: Johnson graphs and (for $k=3$) Steiner Triple Systems (STS) seem close to what I'm looking for. The condition of ""pairwise singleton or empty intersections"" is equivalent to ""every 2-subset of S occurs in at most one $k$-element set"". STS require that every 2-subset of S occurs in exactly one $3$-element set"". Edit3: Thank you to everyone who replied! All of your comments helped me push through a barrier I was facing for some time.","['graph-theory', 'combinatorics']"
308354,Improper Integral : $\int_{0}^{\infty } \frac{dx}{x\sin x}$?,$$\int\limits_{0}^{\infty}\frac{dx}{x\sin x}$$ How can I explain that this integral diverges?,"['calculus', 'integration']"
308377,Does the series $\;\sum\limits_{n=0}^{\infty}\left(\frac{\pi}{2} - \arctan(n)\right)$ converge or diverge? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question I tried everything that I know but I couldn't solve this series: $$\sum_{n=0}^{\infty} \left(\frac{\pi}{2} - \arctan(n)\right)$$ Does it diverge or converge?","['sequences-and-series', 'real-analysis']"
308386,"If $P(A \cup B \cup C) = 1$, $P(B) = 2P(A) $, $P(C) = 3P(A) $, $P(A \cap B) = P(A \cap C) = P(B \cap C) $, then $P(A) \le \frac14$","We have ($P$ is probability):
$P(A \cup B \cup C) = 1$ ; $P(B) = 2P(A) $ ; $P(C) = 3P(A) $ and $P(A \cap B) = P(A \cap C) = P(B \cap C) $. Prove that $P(A) \le \frac{1}{4} $.
Well, I tried with the fact that $ 1 = P(A \cup B \cup C) = 6P(A) - 3P(A \cap B) + P(A \cap B \cap C) $ but I got stuck... Could anyone help me, please?",['probability']
308387,Introductory measure theory textbook,I would like to teach myself measure theory and I am looking for a good introductory textbook at the advanced undergraduate or early graduate level. A reader-friendly text with plenty of examples would be ideal.,"['measure-theory', 'soft-question']"
308394,"Determine if $G$ is a group under the $\,\gcd\,$ operation","Let $G = [1,2,3,4,6,12].\;$ Let $\,a*b = \gcd(a,b), a,b \in G.\;$ Determine whether $G$ is a group. I have found that for any two elements in $G$, commutativity holds, but the inverses are not unique for some elements i.e. $\gcd(3,4) = \gcd(3,2) = 1$, and the identity is not unique, e.g., $\gcd(2,2) = 2$ but $\gcd(3,3) = 3$. So $G$ is clearly not a group, is my logic correct?","['finite-groups', 'group-theory', 'abstract-algebra']"
308397,Difference between a Hamilton and a gradient vector field,"I have been asked to consider a set of vector fields and determine whether these vectorfields are Hamilton or gradient and if possible to determine a Hamilton or potential function. I am a bit confused with the definitions of these concepts and can't find them clearly explained anywhere. For a system $x' = f(x,y)$ and $y' = g(x,y)$ I believe it is hamiltonian if $\partial_y f= -\partial_x g $, which is just some kind of exactness of the d.e.? But consider for example:
$$
x' = y \\ y' =-x,
$$
of course the solutions are cosines/sines but bare with me. A Hamiltonian $H = x^2 + y^2 = C$ satisfies $\partial H/\partial y = y $and $-\partial H/\partial x = -x $ but it also satisfies $x'' = -x = - \partial V /\partial x$ and $y'' = -y =- \partial V/\partial y$ for V the same function as the Hamilton above.
I should know this rather easy concept, but I am utterly confused.",['ordinary-differential-equations']
308418,Why U(1) and SO(2) are locally equivalent?,"In one of my particle physics textbooks, I came across the statement that U(1) and SO(2) are locally equivalent. I don’t really know what it means. I know a bit of group theory and that $U(1)$ is just the group of $1$ -D unitary transformations and $SO(2)$ the $2$ -D proper rotation group. Could anyone explain the statement in both a formal and intuitive way? Thanks!",['group-theory']
308422,Why do we accept Kuratowski's definition of ordered pairs?,"I've been struggling understanding Kuratowski's definition of ordered pairs.
I understand what it means but I don't see why I should accept it.
I've seen this question and this one , most importantly --- through reading the wiki page I've realised one thing. The only reason $(a,b)=\{\{a\},\{a,b\}\}$ is accepted is because it satisfies $(a,b)=(c,d) \iff (a=c) \land (b=d)$ Am I not misunderstanding this?
If I can come with my own exotic definition which satisfies the above iff statement, would it be accepted?","['elementary-set-theory', 'definition']"
308440,"Find and example of two elements $a,b$ in a finite group $G$ such that $|a| = |b| = 2, a \ne b$ and $|ab|$ is odd.","Find and example of two elements $a,b$ in a finite group $G$ such that $|a| = |b| = 2, a \ne b$ and $|ab|$ is odd. Any ideas as to how I would go about finding it? Thanks","['group-theory', 'abstract-algebra']"
308445,"Topological way to show , if $X$ finite than there is no bijection to $X\setminus{x}$ while $x\in X$","I got the Idea from this question: <> another thread I got the idea to define a finite set like this: We call a set $A$ finite if the topological space $(A,T)$ is hausdorff iff $T$ is the discrete topology. If my proof isn't wrong this one is equivalent to the normal defintion, that a set is finite if there is a bijection to $\{1,\dots,n\}$ for a $n\in \mathbb{N}$. I never listen to any Topology-lecture (i didn't take a topology course) so i don't know if there is a problem in it, and I don't think I am able to do the proof on my own so I ask for some help. My basic Idea was, that  any bijection between discrete finite topological spaces is a homoeomorphism. Now we make a simplicial complex out of the sets (taking the elements of A as 0-skeleton and between two 0-cells a 1-cell) and perhabs we can show, that the homotopie groups aren't equal. (since the 0th is just a set we have to take a higher one). So for example, we can show that the free groups of $n$ and $n-1$ generators aren't the same. Does anyone got an idea for this, or won't there be a way without cardinality at all.",['general-topology']
308448,Please help me understand this. $\frac{dx}{dt} = S x (a-x)$. What does it mean for some constant $S$? How to find $x$ for fastest/slowest growth?,"I am having some trouble understanding this problem. There is this function that calculates reaction rate of a substance for some constant positive $S$. $a$ = original amount of the first substance 
$x$ = some amount of substance First question, what does $\frac{dx}{dt} = S x (a-x)$ mean? Does this mean that the rate of change of $x$ in the equation $(S x (a-x))$ is affected by the change in time? So if there was no '$x$' in the equation, than change in time would not affect the equation right? *This is the first time I am encountering '$dt$' in my derivative assignments. When finding derivatives for simple equations, its mostly been of d/dx notation. When I graphed $S x (a-x)$, I substituted random numbers for $S$ and $a$. Does this tell me anything about the function for rate of increase and decrease? Should I have solved for $a$? I notice the function increases and then decreases as $x$ moves away from $0$. I also know that when the derivative crosses the $x$ axis, the original function (which I don't know) will start to decrease. What do I need to do to determine the fastest/slowest growth rate using the derivative? 
Thanks","['ordinary-differential-equations', 'calculus', 'derivatives']"
308473,discrete exponential calculating,"I am interested in discrete exponential calculating. I know that $a^b = c\mod k$ is calculated as below.  For example $3^4 = 13 \mod 17$ . $3^4 = 81$ ; $81 \mod 17 = 13$ . I am interested in big numbers. For example $12356423547^{72389478972138} \mod 1239859034832$ This calculation is more difficult . And I don't think it is possible to calculate this expression without any simplification. I have researched some ways to simplify this equalization. And I found that $a^b \mod k = a^{(b \mod \log(a,1)) \mod k}$ $\log(a,b)$ is discrete logarithm where $a$ is base. Of course this is simpler from $a^b$ but not enough simple. In very big calculations this way isn't useful. For example in $128$ bit public keys $a$ and $b$ will be $128$ bit integers (for example). I am interested in that. Is there any simplification formula to calculate big numbers exponential in real time? Thank you.","['exponentiation', 'logarithms', 'discrete-mathematics']"
308475,Finding a sequence of polynomials that converges uniformly to a holomorphic function on an open set,"The following is exercise 13.2 in Rudin's Real & Complex Analysis, which I'm self-studying. Let $\Omega = \{z: |z| < 1 \text{ and } |2z - 1| > 1\}$, and suppose $f \in H(\Omega)$. Must there exist a sequence of polynomials which converges to $f$ uniformly in $\Omega$? I have a solution, but I feel it's simple and the shape of $\Omega$ is suspicious so there might be a trick somewhere. Assume such a sequence exists. Let $0 < \epsilon < 1$, $f(z) = 1/z$ and $P$ be a polynomial that satisfies:
$$|f(z) - P(z)| < \epsilon \ \ \forall z \in \Omega$$
Therefore
$$|P(z)| < |f(z)| + \epsilon \ \ \forall z \in \Omega$$
But near the boundary of the unit disc, $|f(z)| < 2$, so $|P(z)| < 3$ near the boundary. By the continuity of $P$, we have $P(z) \le 3$ on the boundary. By the maximum modulus principle, $P(z) < 3$ on the unit disc. But $|f(z)|$ gets arbitrarily large near $0$. Therefore $P$ cannot approximate $f$ on $\Omega$. What gives me confidence in my argument is that it doesn't work on compact subsets of $\Omega$ (for which the existence of the polynomial sequence is guaranteed by Runge's theorem). Is my counter-example correct?","['uniform-convergence', 'complex-analysis']"
308479,"HK a subgroup, neither is included in the other's normalizer?","Can anyone think of an example of the following: $H$ and $K$ are proper subgroups of $G$.  $H$ is not contained in the normalizer of $K$. $K$ is not contained in the normalizer of $H$. Nevertheless, $HK$, the set of all $hk$ where $h \in H$, and $k \in K$, is somehow a group?",['group-theory']
308486,Why isn't a lemniscate a manifold?,"I would like a formal, but not very deep in the theory, answer to this question. Maybe I am even wrong at the understanding of what a lemniscate may be, so here is another question: Is the image of the function $f:[-2\pi,2\pi]\rightarrow \mathbb{R^2}$ given by: $f(t)=(1+\cos(t),\sin(t))I_{(0,2\pi]}(t)+ (-1+\cos(t),\sin(t))I_{(-2\pi , 0)}(t)$ a lemniscate? (where $I_{X}$ is the indicator function of the set $X$)","['general-topology', 'manifolds']"
308490,composition of certain covering maps,"This problem was posted before, but not the proof (because the asker knowed the answer), only a counterexample without the hypothesis of finite fibres.  I want to know how to prove this proposition: Let $q:X\to Y$ and $r:Y\to Z$ be covering maps. Let's suppose that for each $z\in Z$ , the set $ r^{-1}(z)$ is finite, then the composition $p = r\circ q$ is also a covering map.
Well I have to consider $z\in Z$ and show that there exist a neighborhood that is evenly covered by $p$, I know that there exist a neighborhood $U$ that is evenly covered by $r$, I think that this will be the desired neighborhood.
First of all $ r^{-1}(U) = \cup_{i=1}^{n}  V_i $ (it's easy to see that the unions is finite using the fact that the fibres are finite and this is a local homeomorphism between the $V_i$)
Then $ p^{-1}(U)=q^{-1} (r^{-1}(U) ) = q^{-1}(\cup_{i=1}^{n}  V_i)=\cup_{i=1}^{n}  q^{-1}(V_i) $
With $ q^{-1}(V_i) \cong V_i$ under $q$ and so $\cong$ U under $p$
I never used the fact that the preimage is finite, so my proof is obviously not correct, please help me with this","['general-topology', 'covering-spaces', 'algebraic-topology']"
308501,Even integer approximations to multiples of pi,"I admit that I'm probably out of my depth with this question, but I can't help but feel curious. I wanted to show that, in the sequence $\{\sin(n)\}$, there is never a largest term (the sequence never attains its limit superior). My reasoning was that, given $$ \left| \sin(x) - \sin(y) \right| \leq \left| x - y \right|,$$ if we can furnish an even $M$ with $M = N\pi \pm \epsilon$, then either $\frac{3}{2}M$ or $\frac{1}{2}M$ will nearly equal an odd multiple $K$ of $\frac{\pi}{2}$ such that $\sin(K\frac{\pi}{2}) = 1$.
By the inequality, the difference between $\sin(\frac{3}{2}M)$ and $1$ -- or $\sin(\frac{1}{2}M)$ and $1$, whichever -- would be at most $\frac{3}{2} \epsilon$. Thus, the problem reduces to showing that we can get an arbitrarily small $\epsilon$. (I recognize that the inequality above is pretty watered down: the mean value theorem shows that the inequality is as stark as $\cos(\xi) \leq 1$ for $\xi \in (x,y)$, which, if both points $x$ and $y$ are close to $(2k+ \frac{1}{2}) \pi$, is really much stronger than what I've got. This seems like a hard way to prove the claim, so if anybody has a better one, I'd also like to hear about that.) But my main question , which I came to because of the above, is about approximating multiples of $\pi$ by integers. If $\pi = \frac{p}{q} + \epsilon$, then $q\pi - q\epsilon = p$; thus, the size of $q$ becomes important to the accuracy, since the $\epsilon$ we were considering above is $q\epsilon$ in these terms. Spivak's Calculus has a little discussion about this when he proves $e$ is transcendental. He notes that the proof of $e$'s irrationality shows that $\sum_{k=1}^n \frac{n!}{k!} = n!e - R_n,$ with $|R_n| < \frac{3}{n+1}$. The sum on the left can be controlled for parity, since choosing $n$ odd leaves $(\cdots + n + 1)$ at the tail of this sum, and all other terms multiplied by $(n-1)$. So there must exist, given $\epsilon > 0$, an $N$ and an even $M$ such that $M = Ne \pm \epsilon$. (In other words, if $e$ were $\pi$, I'd be home already!) Spivak mentioned that this property - good approximations existing with small denominators - is somehow characteristic of transcendental numbers. ""The number $e$ is by no means unique in this respect: generally speaking, the better a number can be approximated by rational numbers, the worse it is."" So I wonder: Can we furnish an approximation $\frac{p}{q}$ to $\pi$ with $q\epsilon$ arbitrarily small? (For my purposes, can we do better and furnish one with an even $p$?) More generally (and I am out of my depth here, but would enjoy references), what can we prove about the ""goodness"" of rational approximations to transcendental numbers, in the sense of small denominators?","['approximation', 'analysis', 'number-theory']"
308504,Unusual function format and its partial derivatives.,"I came across a function of this format: $z = f(u,v)$ where $u = x^2y^2$ and $v = 5x + 1$ Because this function is not in the same format of the ones I've seen before (explicit or implicit), I don't know how to find (or even to do a single solving step!) its partial derivatives. Basically, I need to show that: $\frac{\partial^2z}{\partial x\partial y}
= 4xy\frac{\partial f}{\partial u}
+4x^3y^3\frac{\partial^2f}{\partial u^2}
+10x^2y\frac{\partial^2f}{\partial v \partial u}$ Anyone could tell me how I should approach this type of problem? Thanks!","['multivariable-calculus', 'coordinate-systems']"
308520,How to solve the DE $y' = -y + ty^{1/2}$?,"The DE is $y' = -y + ty^{\frac{1}{2}}$. $2 \le t \le 3$ $y(2) = 2$ I tried to see if it was in the linear form . I got: $$\frac{dy}{dt} + y = ty^{\frac{1}{2}}$$ The RHS was not a function of t . I also tried separation of variables, but I couldn't isolate the y from the term $ty^{\frac{1}{2}}$. Any hints?",['ordinary-differential-equations']
308539,Connection between connected and compact spaces?,"What kind of connection is there between connected and compact subspaces, if any? I am just curious. I know that the image of a compact space under a continuous function is compact and the same holds for connected spaces. But this is not what I am looking for. I would like to see a condition on a set or a topological space in order to see if we can infer that if a set is connected + some other condition then it is compact. (Something similar to any compact set in a Hausdorff space is closed. In this case the extra condition would be having a Hausdorff space). (Sorry for the initial confusion. I meant compact set, not connected, in my example.)
Thanks.",['general-topology']
308580,unbiased estimator of sample variance using two samples,"I have a couple questions, I'm hoping someone can help!
Let $X_1...X_n$ is a random i.i.d. sample from a $N(\mu,\sigma^2)$ distribution, and $Y_1...Y_m$ is a random i.i.d. sample from a $N(2\mu,\sigma^2)$ distribution, and further let the two samples be independent (and the quantities $\mu$ and $\sigma^2$ be unknown). 
I'm trying to do the following: construct an unbiased estimator of $\mu$ ($\hat{\mu}$) using both samples, calculate $Var(\hat{\mu})$, and then use both samples to obtain an unbiased estimator for $\sigma^2$. I think I understand the first two parts: we know $\large E(\frac{X_1+...+X_n}{n}) = \mu$, and $\large E(\frac{Y_1+...+Y_m}{m}) = 2\mu$, so I believe $\large \frac{X_1+...+X_n}{2n}+\frac{Y_1+...+Y_m}{4m}$ should provide an unbiased estimator for $\mu$, and from that it follows $\large Var(\hat{\mu})=\sigma^2(\frac{1}{4n}+\frac{1}{16m})$. What I'm not clear on is how to construct an unbiased estimator for the variance. I'm aware that $\large\frac{1}{n-1}\sum_{i=1}^n(X_i-\bar{X})^2$ provides an unbiased estimator for $\sigma^2$ (the proof is on wikipedia). From this, it seems like $\large\frac{1}{2}\cdot\frac{1}{n-1}\sum_{i=1}^n(X_i-\bar{X})^2$+$\large\frac{1}{2}\cdot\frac{1}{n-1}\sum_{i=1}^m(Y_i-\bar{Y})^2$ would yield $\frac{\sigma}{2}+\frac{\sigma}{2}=\sigma$, but something about it makes me nervous, and I feel like is approach may be inherently flawed? Any help/suggestions would be greatly appreciated!
Thanks","['statistics', 'sampling', 'probability']"
308591,Property true for some integers and false for others: $-a^n$ = $(-a)^n$,"I am currently working in my Discrete math class with elementary number theory and methods of proof. I have been given the problem  $-a^n = (-a)^n$. According to the professor and the book this property is true for some integers and false for others integers. For example: Let $a=1$. Then, $-1^n$ = $(-1)^n$. Wouldn't that be true? But How can I show an example where this property is false for other integers?","['elementary-number-theory', 'algebra-precalculus']"
308618,Solving equations involving the floor function,"I am trying to solve the following problem: For what real numbers x is: $\lfloor{2x}\rfloor = 3\lfloor{x}\rfloor$? I'm not sure how to deal with the floor functions, so I have no idea where to start. If someone could walk me through the process that would great!","['discrete-mathematics', 'ceiling-and-floor-functions']"
308644,Prove $A\cup (A\cap B) = A$,"What I've done so far is stated that $(A \cup A) \cap (A \cup B)$  by distribution $A\cap (A\cup B)$        by 1, definition of $\cup$ $A\cap A$              by 2, definition of $\cup$ $A$                   by 3, definition of $\cap$ I'm not sure if I need to state that $A\cup B = \{x\mid x\in A\lor x\in B\}$ somewhere in there. I'd really appreciate some help on this one. Thank you!",['elementary-set-theory']
308652,What does this notation mean? F|U,"If $F$ is a function and $U$ is a set, then what does $F|U$ mean? In http://ocw.mit.edu/courses/mathematics/18-101-analysis-ii-fall-2005/lecture-notes/lecture6.pdf , the Inverse Function Theorem, the notation is used Also, the file in stating the Lemma 2.14 states that $A \in U$, what does this mean? A set is an element of another set? What is $A$? EDIT : Could someone kindly explain to me what is going on in Lemma 2.16. How does $\delta$ come into play? I dont see the role in the lemma. I also don't see why this proves one-to-one","['notation', 'elementary-set-theory', 'functions']"
308677,Martingale that converges almost surely to $-\infty$.,"The question is as follows: Exercise 5.2.4. Give an example of a martingale $X_n$ with $X_n \to -\infty$ a.s. Hint: Let
  $X_n = \xi_1 + · · · + \xi_n$, where the $\xi_i$ are independent (but not identically distributed) with $E\xi_i = 0$. My guess is that we should not make $\xi_n$ having a distribution such that it has zero expectation but are more and more likely to be negative. For example, we can have
$\mathbb{P}(\xi_n = 1) = 1/n$ and $\mathbb{P}(\xi_n = \frac {-1} {n-1}) = \frac {n-1} n$. But I am not sure how to prove $\sum \xi_n \to -\infty$.","['probability-theory', 'martingales']"
308683,How do you prove that $\ln|f(z)|$ is harmonic?,Suppose that $f(z)$ is analytic and nonzero in a domain $D$.  Prove that $\ln|f(z)|$ is harmonic in $D$. I know the laplacian equation but I'm not sure how to use it.,"['harmonic-functions', 'complex-analysis']"
308693,Evaluate $\int_{0}^{\pi} \frac{d\theta}{(2+\cos\theta)^2}$,"How can one evaluate $\displaystyle\int_{0}^{\pi} \frac{d\theta}{(2+\cos\theta)^2}$? My attempt: $$\int_{0}^{\pi} \frac{d\theta}{(2+\cos\theta)^2} =  \frac{1}{2}\int_{0}^{2\pi} \frac{d\theta}{(2+\cos\theta)^2}$$ To find the singularity, I solve:
$ (2+\cos\theta)^2 = 0 $ and therefore, $\cos\theta =  -2$. Substituting: $\cos z = \frac{e^{iz} + e^{-iz}}{2} = \frac{z + \frac{1}{z}}{2}$,
I find that $z = -2 + \sqrt{3} $ is the singular point that lies in the unit circle $|z| = 1$. From this point, I have little idea how to go about solving this problem. I know I have to find the residue and then just sum them but to get the expression that would cancel out the pole is where I am currently stuck.","['complex-analysis', 'contour-integration']"
308713,let $A\in M_n\mathbb R$ .how prove these statements with following condition?,"Assume $A\in M_n(\mathbb{R})$, $A\neq 0$ such that:
\begin{align*}
A=(a_{ij}),\ 1\le i,j\le n,\\
a_{ik}a_{jk}=a_{kk}a_{ij},\ \forall\, i,j
\end{align*}
How to prove that: $\operatorname{trace}(A)\neq0$, $A$ is symmetric, $x^{n-1}(x-\operatorname{trace}(A))$ is the characteristics polynomial of $A$. Thanks in advance.","['matrices', 'linear-algebra', 'contest-math']"
308733,Prove an integral limit,"Let $F(x),G(x)\ge 0$ be decreasing functions on $[0,+\infty)$
and
$\displaystyle\lim_{x\to+\infty}x(F(x)+G(x))=0$ (1) Prove that: $\forall\varepsilon>0,\displaystyle\lim_{x\rightarrow+\infty}\displaystyle\int_{\varepsilon}^{+\infty}xF(xt)\cos{t}dt=0$ (2) And have $\displaystyle\lim_{n\to+\infty}\displaystyle\int_{0}^{+\infty}(F(t)-G(t))\cos{\dfrac{t}{n}}dt=0$
prove that: $$\displaystyle\lim_{x\to 0}\displaystyle\int_{0}^{\infty}(F(t)-G(t))\cos{(xt)}dt=0$$ the simple problem you can see. the simple problem  see: http://sms.math.ecnu.edu.cn/contest/university03/mathclass11_answer.pdf this problem from: http://wenku.baidu.com/view/0ac7ae777fd5360cba1adb69.html","['integration', 'limits']"
308804,Homeomorphism between real projective plane and disc,Let $D = \{\mathbf{x} \in \mathbb{R}^2 \ | \ \|\mathbf{x}\| \le 1\}$ and let $\mathbb{R}\mathbb{P}^2$ be the real projective plane Let $X = D/\sim$ where $\sim$ identifies antipodal points in the boundary of $D$. I am interested in finding explicitly a homeomorphism between X and the projective plane. Could anyone please help me with this one?,"['general-topology', 'algebraic-topology', 'differential-geometry']"
308807,Help with Euler Substitution,"Let $a < 0$. Find the following indefinite integral by using the third Euler substitution. $$\int \frac{dx}{(x^2 + a^2) \sqrt{x^2 - a^2}}$$ Where the third Euler substitution is defined by: Given an integral of the form $\int R(x, \sqrt{ax^2 + bx + c})dx,$ $a \neq 0$.
If the quadratic polynomial under the radical has 2 distinct real roots $\alpha_1$ and $\alpha_2$ i.e., $$ax^2 + bx + c = a(x-\alpha_1)(x - \alpha_2),$$ then set $$\sqrt{ax^2 + bx + c} = t(x - \alpha_{1 \text{ or } 2}).$$ Hint: $t^4 + 1 = (t^2 - \sqrt 2t + 1)(t^2 + \sqrt 2t + 1)$. I tried beginning by setting $$\sqrt{x^2 - a^2} = t(x-a)$$ and attempted to solve for $x$ in order to find some function to define $dx$ in terms of $dt$ but I'm having some trouble. I'm not quite sure how to apply the hint here. Thanks in advance.","['calculus', 'integration']"
308834,There isn't a sequence converging pointwise to this function.,"I'm trying to solve this question: Show that there isn't a sequence of continuous functions $f_n:[0,1]\to
 \mathbb R$ converges pointwise to the function $f:[0,1]\to \mathbb R$
  such that $f(x)=0$ for $x$ rational and $f(x)=1$, for $x$ irrational. Of course there isn't a sequence $f_n:[0,1]\to
 \mathbb R$ converges uniformly to the function $f:[0,1]\to \mathbb R$ because $f$ is discontinuous, but when the convergence is pointwise? I need help here Thanks in advance","['sequences-and-series', 'real-analysis']"
308836,to find the distance,i am trying to find the power graphs of cycles $C_n$ and then calculation of distances between vertices. for cycles $C_n$ we can find power graphs upto power greatest integer function of n/2. Square of $C_n$ yielding result that distance between any two vertices is same. my question is how to prove that distance between any two vertices is same on squaring cycles.,"['graph-theory', 'discrete-mathematics', 'combinatorics']"
308841,Pullbacks and transpose map,"Given maifolds $M,N$ and a smooth map $\phi:M \to N$, and a smooth function $f:N \to \mathbb{R}$, we have the pullback of $\phi$ by $f$ to be the function $\phi^* f = f \circ \phi : M \to \mathbb{R}$. Similarly, given a linear map $T:V \to W$, we get a transpose map $T^*: W^* \to V^*$ such that $T^*g = g \circ T$. I just noticed that these ideas are really similar. Is there something more ""going on""? It can't be a coincidence, since mathematicians have decided to use basically the same notation. My question is: is there a general way to encapsulate this concept? I imagine (perhaps incorrectly) that such an answer would involve category theory (I am aware of the so-called ""dual functor"" associated to vector spaces, which I understand is related to this topic) If possible, could someone point me to a reference without too much category theory? Thanks. p.s. any references would be good, so even if they do contain tons of category theory, that's OK.","['category-theory', 'linear-algebra', 'reference-request', 'differential-geometry']"
308849,"Integer sequences which quickly become unimaginably large, then shrink down to ""normal"" size again?","There are a number of integer sequences which are known to have a few ""ordinary"" size values, and then to suddenly grow at unbelievably fast rates. The TREE sequence is one of these sequences, which starts ""1, 3"" and then grows to an unimaginably large value which completely dwarfs even things like Graham's Number. Another example is given by the sequence of Ackermann numbers , which also has an extremely large third term, though not as large as that of TREE(3). I'm interested in a variant of the above concept: integer sequences which seem to start off normally, then have one or a few values which then become mind-bogglingly large, and then which end up going back to ""ordinary-sized"" values for the rest of the sequence. Does anyone know of things like this which arise ""naturally,"" perhaps in the context of graph theory or combinatorics or something similar? Obviously one can construct sequences that fit this pattern by splicing things together, but I'm mostly interested in the case where this behavior somehow occurs in some kind of natural integer sequence.","['graph-theory', 'sequences-and-series', 'recreational-mathematics', 'combinatorics']"
308897,Elliptic Regularity Theorem,"I want to collect some results on elliptic regularity. The problem I consider is
\begin{align}          
           Lu&=f,&in \quad U,\\
             u&=g,&on \quad  \partial U.\tag{1}
\end{align}
where $Lu:=a_{ij}(x)u_{x_ix_j}+b_i(x)u_{x_i}+c(x)u.$ is a strictly elliptic operator. I have known that the $C^{2,\alpha}$-regularity from Gilbarg&Trudinger's book and the $H^2$-regularity from Evans'book. Now I wonder that can the $C^2$-regularity is also available？Namely，can we take $\alpha=0$ in the $C^{2,\alpha}$-regularity. More precisely，I want to make clear that is the following theorem valid？ THEOREM ($C^2$-elliptic regularity ) Let $U$ is $C^2$ bounded domain, $g\in C^2(\bar U)$,$u\in C(\bar U)\cap C^2(U)$ is a classical solution of the Dirichlet problem $(1)$, where $a_{ij},b_i,c,f\in C(\bar U)$. Then $u\in C^2(\bar U)$. In addition, I also wonder the solvability of $(1)$ in function space $C^2(\bar U)$.Namely,is the following existence theorem valid？ THEOREM ($C^2$-existence) Let $U$ is $C^2$ bounded domain, $g\in C^2(\bar U)$, $c\leq 0$,$a_{ij},b_i,c,f\in C(\bar U)$. Then the Dirichlet problem $(1)$ has a unique solution $u\in C^2(\bar U)$. Any answer or reference is appreciated! :)","['sobolev-spaces', 'holder-spaces', 'functional-analysis', 'partial-differential-equations']"
308908,What's next for me?,"I'm in my last year of undergrad, and I would like to do original research for my senior thesis.  I am already published in finite group theory and am looking for a new topic to study. I have taken the graduate algebra sequence at my university, which was primarily galois theory and representation theory.  I didn't find Galois theory very interesting (I guess I don't understand the motivation.)  Representation theory was cool, but I must admit my intuitive grasp on modules and abstract linear algebra is not yet perfect.  I've also taken real and complex analysis, combinatorics, cryptography, number theory, and a lot of physics.  I pretty much unilaterally do not enjoy physics or analysis.  The others were pretty neat.  I performed well in all but the analysis classes. A few of the topics I've bookmarked which seem interesting, in no particular order: algebraic graph theory, knot theory, noncommutative ring theory, module theory, lie theory, tessellations/tilings, homology,  combinatorial game theory, fusion systems, algebraic combinatorics.  (I have no idea what background you need for any of these, or whether I would actually like them- they just sounded like possibilities.)  Do any of these seem suitable? Given my interests and background, what would be a good area of math for me to look into next? An ideal answer would suggest an area of math and include one or more small subtopics which could help inspire me to want to learn that area.  For example, ""Noncommutative ring theory is the perfect next step for you. You should explore commuting graphs."" To be clear I'm not looking for specific problems like ""prove that xxx is true.""  I am more looking for recommendations which fit my mathematical tastes, contain a few somewhat unstudied topics where I might find some ""low hanging apple"" research problems, and would be reasonably accessible for someone with my background. EDIT: To  those who think I shouldn't even be asking this question, please let me reiterate what I have said in the comments.  First, nobody at my school works in algebra, so I can't just ask a prof. Second, if you believe it would be better for me to study an advanced topic without trying to do original research, please let me reiterate that it is okay if I do not produce original results for the thesis.  I can just write an expository paper on what I've been reading.  Again, I have already done independent research, so I know from experience that it is a good motivator for me to have a topic to relate everything back to when I am exploring a new subject.  An open topic is just a ""carrot on a stick"" to motivate my study habits.  Finally, I am just looking for a bunch of suggestions- I don't have to do any of them if they aren't a good fit.  Thanks for reading.","['abstract-algebra', 'reference-request', 'soft-question', 'advice', 'combinatorics']"
308909,Using Taylor's Theorem to show that $\ln(1 + x^2) \leq x^2$,"Can we show that if $\operatorname{abs}(x) \lt 1$, then $$\ln(1+x^2) \leq x^2\;,$$
using Taylor's Theorem? I am thinking of expanding it about $x=0$ but I got something like 
$$f(x) = -x^2 + \frac{x^4}{2} - \dots$$ Is my approach correct? Could you give me some hints/guides here? Thanks.","['inequality', 'calculus', 'logarithms', 'analysis', 'taylor-expansion']"
308925,Bijective Proof: Number of Partitions of 2n into n parts,"The number of partitions of n is equal to the # of the partitions of 2n divided into n parts. I know that the number of partitions of any integer n into i parts equals the number of partitions of n with the largest part i, but do not know where to go from here, especially how to prove via bijection - any help is appreciated! (Supp. problem in my intro. combinatorics class)","['integer-partitions', 'combinatorics']"
308939,"Commutative ring and its group-algebra, and abelian-group-algebra as a commutative ring.","In course of discussing the algebraic structures, one of my seniors is led quite naturally to considering the $\color{red} {geometric}$ version of following: Question : Since we could consider the spectrum of an abelian-group-algebra $\color{blue}{as\ a\ commutative\ ring}$, it is natural to ask: what kind of informations of this abelian group could be obtained from the considerations of this spectrum? On the other hand, we can view the commutative ring $\color{blue} {as\ an\ abelian\ group}$, and thus form its group-algebra. We then ask a further question: what relations are there between the spectrum of the ring, and the spectrum of this group-algebra? Notice : As I have yet heard of nothing about the subject, any source or reference in this direction is the most appreciated. Thanks in advance. Also one of my seniors is greatly intrigued in the $\color{green}{geometric}$ point of view of this question, thus it would be quite wonderful if any insight or crucial observations are provided. Thanks again.","['commutative-algebra', 'algebraic-geometry', 'abelian-groups']"
308940,Splitting field of $ x^2 + 1$ over $\mathbb{Z_3}$,"I have the following exercise: Find splitting field for the polynomial $x^2 + 1$ over $\mathbb{Z_3}$. My solution: At first, we should try to solve the equation $x^2 + 1 = 0$,
thus $x^2 = 2$ and we need $\sqrt2$. 
Add this root to our new field and we have 
$\{0, 1, 2, \sqrt2, 2\sqrt2, 1+\sqrt2,
2 + \sqrt2, 1+2\sqrt2,
2 + 2\sqrt2 \}$ 
and that's our splitting field where roots of $x^2 + 1 = 0$ are $\sqrt2$ and $2\sqrt2$. Is it correct or not? And I think there is no exact algorithm how to build a splitting field. How to do it properly?","['galois-theory', 'finite-fields', 'abstract-algebra']"
308942,Applications of the Isomorphism theorems,"In my study of groups, rings, modules etc, I've seen the three isomorphism theorems stated and proved many times. I use the first one ( $G/\ker \phi \cong \operatorname{im} \phi$ ) very often, but I can't recall having ever used the other two. Can anyone give some examples where they are used in a crucial way in some proof? For clarity, let us say that the 2nd one is : $(M/L)/(N/L) \cong M/N$ under the appropriate conditions, and the 3rd one is $(M+N)/N \cong M/(M\cap N).$","['ring-theory', 'abstract-algebra', 'big-list', 'modules', 'group-theory']"
308952,Motivation for spectral graph theory.,"Why do we care about eigenvalues of graphs? Of course, any novel question in mathematics is interesting, but there is an entire discipline of mathematics devoted to studying these eigenvalues, so they must be important. I always assumed that spectral graph theory extends graph theory by providing tools to prove things we couldn't otherwise, somewhat like how representation theory extends finite group theory.  But most results I see in spectral graph theory seem to concern eigenvalues  not as means to an end, but as objects of interest in their own right. I also considered practical value as motivation, e.g. using a given set of eigenvalues to put bounds on essential properties of graphs, such as maximum vertex degree.  But I can't imagine a situation in which I would have access to a graph's eigenvalues before I would know much more elementary information like maximum vertex degree. ( EDIT: for example, dtldarek points out that $\lambda_2$ is related to diameter, but then why would we need $\lambda_2$ when we already have diameter?  Is this somehow conceptually beneficial?) So, what is the meaning of graph spectra intuitively?  And for what practical purposes are they used?  Why is finding the eigenvalues of a graph's adjacency/Laplacian matrices more than just a novel problem?","['motivation', 'graph-theory', 'linear-algebra', 'spectral-graph-theory', 'intuition']"
308984,Show $x^6 + 1.5x^5 + 3x - 4.5$ is irreducible in $\mathbb Q[x]$.,"Show $p(x) = x^6 + 1.5x^5 + 3x - 4.5$ is irreducible in $\mathbb Q[x]$. By Gauss' Lemma, a primitive polynomial in $\mathbb Z[x]$ is irreducible in $\mathbb Q[x]$ if and only if it is irreducible in $\mathbb Z[x]$. We can look at $2x^6 + 3x^5 + 6x - 9 \in \mathbb Z[x]$. Eisenstein's Criterion fails since $3^2 \mid (-9)$. I also tried replacing $x$ with $x-1$ and $x+1$ to see if I could use Eisenstein, but they didn't work. I tried reducing it mod $p$. You cant to it mod $2$ since the leading coefficient divides 2, so I tried mod 3, but it immediately factors there. I tried mod 5 and the linear terms don't have roots, but I still need to check quadratic and cubic factors. But that just seems extremely long and if it doesn't work mod 5 I'll have to keep trying mod $p$ until I reach some prime where $p(x)$ is irreducible. I don't know where to go from here. What is the correct way to approach this?","['irreducible-polynomials', 'field-theory', 'abstract-algebra', 'polynomials']"
308986,Question about members in sets,"Let $A_1,A_2,...,A_n$ be sets with $k$ members in $A_i$ for every $1\le i\le n$. Suppose that the $A_i$ satisfy: 1) $|A_i\cap A_j| = 1$ for all $i\ne j$, 2) $A_1\cap A_2\cdots\cap A_n =\emptyset$. What is the largest $n$ for every $k\in \mathbb{Z}^+$? Somebody told me that the largest $n$ is $(k-1)^2+k$ when $k=1,2,3,4$. How can one prove this?","['combinatorial-designs', 'elementary-set-theory', 'combinatorics']"
308991,"Does $1 + \frac{1}{x} + \sqrt{\frac{2x}{x + 1}},$ have a global minimum?","Does the following function have a global minimum: $$1 + \frac{1}{x} + \sqrt{\frac{2x}{x + 1}},$$ where $x \in \mathbb{N}$? I tried using WolframAlpha , but it appears to give an inconsistent result.","['inequality', 'a.m.-g.m.-inequality', 'calculus', 'computational-algebra']"
308998,What is the total variation measure of the integration of a kernel of signed measures?,"Assume given a probability space $(\Omega,\mathcal{F},P)$ and a measurable space $(E,\mathcal{E})$. Let $(\nu_\omega)_{\omega\in\Omega}$ be a family of signed measures on $(E,\mathcal{E})$. Assume that $\omega\mapsto\nu_\omega(A)$ and $\omega\mapsto|\nu_\omega|(A)$ are $\mathcal{F}$ measurable for all $A\in\mathcal{E}$, where $|\nu_\omega|$ denotes the total variation measure of $\nu_\omega$. Further assume that $\int_\Omega |\nu_\omega|(E)dP(\omega)$ is finite. The family $(\nu_\omega)$ is basically a signed measure analogue of the Markov kernels from probability theory used for regular conditional distributions. Under these assumptions, it is possible to define the integration of $(\nu_\omega)$ with respect to $P$ as the unique signed measure $\lambda$ on $\mathcal{F}\otimes\mathcal{E}$ such that $\lambda(F\times A) = \int_F \nu_\omega(A) dP(\omega)$ for $F\in\mathcal{F}$ and $A\in\mathcal{E}$. This can be done simply by Jordan-Hahn decomposing each $\nu_\omega$ and carrying out the ordinary kernel integration construction for the positive and negative parts separately. My question is the following: What is the total variation measure of $\lambda$? My own guess is the following. Let $\mu$ denote the integration of $(|\nu_\omega|)_{\omega\in\Omega}$ with respect to $P$, that is, the unique measure such that $\mu(F\times A)=\int_F |\nu_\omega|(A)dP(\omega)$ for $F\in\mathcal{F}$ and $A\in\mathcal{E}$. I would think that $|\lambda|=\mu$. It is quite clear that $|\lambda|\le \mu$. However, I don't find the converse inequality as obvious. An appealing line of argument would be to simply claim that with $\nu_\omega = \nu_\omega^+ - \nu_\omega^-$, the Jordan-Hahn decomposition of $\lambda$ is obtained by integrating the kernels $(\nu^+_\omega)$ and $(\nu^-_\omega)$. However, while this yields two nonnegative measures whose difference is $\lambda$, it is not obvious that the two measures are singular: Intuitively, these two measures would have mass on ""glued together"" strips of the $\mathcal{E}$-sets where each $\nu^+_\omega$ and $\nu^-_\omega$ are concentrated, but it is not obvious that such glued together sets are measurable.","['probability-theory', 'measure-theory', 'probability-distributions', 'analysis']"
309006,Does $\frac{3}{1\cdot 2} - \frac{5}{2\cdot 3} + \frac{7}{3\cdot 4} - ...$ Converges?,$$\frac{3}{1\cdot 2} - \frac{5}{2\cdot 3} + \frac{7}{3\cdot 4} - ...$$ Do you have an idea about this serie? If it converges what is the sum?,"['sequences-and-series', 'calculus']"
309033,Dual space of Bochner space,"Let $B$ be a refexive Banach space. I want to show that 
$$(L^2(0,T;B))^* = L^2(0,T;B^*)$$ and that 
the dual pairing is
$$\langle F,f \rangle_{L^2(0,T;B^*), L^2(0,T;B)} = \int_0^T \langle F(t), f(t) \rangle_{B^*,B}.$$
Can anyone help me with either part? Thanks.","['functional-analysis', 'banach-spaces']"
309034,"If $\mathcal{B}$ in $X$ converges to $x$, it accumulates at $x$ and if $X$ is Hausdorff, $x$ is a unique point of accumulation.","Essentially I need feedback, mostly on writing style and accuracy and tightness of arguments. Suppose $\mathcal{B}$ converges to $x$. For every open neighbourhood $U(x)$ of $x$ in $X$ there exists $B_j \in\mathcal{B}$ such that $B_j\subset U(x)$. Clearly, $B_j \cap U(x) \neq \emptyset$. We have to show that $B_i \cap U(x) \neq \emptyset$ for all $i \in I$ such that $i \neq j$. Since for all $i,j \in I$ there exists $k \in I$ such that $b \in B_k \subset B_i \cap B_j$, therefore $B_i \cap B_j \neq \emptyset$ for all $i,j \in I$. It follows that $B_i \cap U(x) \neq \emptyset$ for all $i \neq j \in I$. Thus, for every $U(x) \in \mathcal{T}$ and every $B_i \in \mathcal{B}$, $U(x) \cap B_i \neq \emptyset$.\ 
Suppose $(X, \mathcal{T})$ is a Hausdorff space. Consider a filterbase $\mathcal{B}$ in $X$ converging to $x\in X$.We show that, if $y \in X$ and $y\neq x$, then $\mathcal{B}$ cannot accumulate at $y$. Since, $x\neq y$ and $X$ is Hausdorff, there exist open neighbourhoods $U(x) \in \mathcal{T}$ and $V(y) \in \mathcal{T}$ of $x$ and $y$ respectively such that $U(x) \cap V(y) =\emptyset$.  Since $\mathcal{B}$ converges to $x$, there exists a filterbasis element $B_i\in \mathcal{B}$ for every open neighbourhood $U(x)$ of $x$ such that $B_i \subset U(x)$. It follows that there exists $B_i \in \mathcal{B}$ such that $B_i \cap V(y)= \emptyset$. Therefore, $\mathcal{B}$ cannot accumulate at $y$.","['general-topology', 'filters', 'convergence-divergence', 'uniform-spaces']"
309037,Generalization of the Factorial function,"Is there any standard generalization of the Factorial function where the ""skips"" per multiplication is a parameter? For example, one generalization could be: $a(a-b)(a-2b)(a-3b)...1$ I tried to generalize it myself and came up with a few interesting results. I defined $f(a, b)$ as $f(a, b) = a(a-\frac{1}{b})(a-\frac{2}{b})(a-\frac{3}{b})...$ where $b\neq0$ and $a,b$ are integers. Here are some of the results I've came up with: The factorial of $n$ would be $f(n,1)$. $(nk)!$ = $k^nf(n,k)$ because $(nk)!=nk(nk-1)(nk-2)(nk-3)... = k^nn(n-\frac{1}{k})(n-\frac{2}{k})(n-\frac{3}{k})$ $(nk)! = (kn)!$ => $k^nf(n,k)=n^kf(k,n)$ => $\frac{k^n}{n^k} = \frac{f(k,n)}{f(n, k)}$ From 1, 2 and 3: $f(nk, 1) = k^nf(n,k)=n^kf(k,n)$ $f(n, 0) = \infty$ because $f(n,0)=n(n-0)(n-0)(n-0)...=n^\infty=\infty$ If it's not standardized - would it actually be useful for anything?","['factorial', 'reference-request', 'combinatorics']"
309050,How many minutes in 1 day?,"There are 24*60 minutes in a day (ignoring the imperfections of the natural world, the Earth and Sun). So there are 24*60 valid 24 hour times (excluding seconds) on a digital clock. Each of these can be rotated 4 ways, by 0,1,2 or 3 places. For example : 12:34 23:41 34:12 41:23 In which case only 1 and 2 are valid 24 hour times. How many of these 4*24*60 rotations are also valid minutes? 
(What is the fastest way to find this out?) Also, what is the minimum generating set for all 24*60 valid 24 hours times. So can I find the minimal set of Lyndon words (the earliest 24 hour times) that generate all 24 hours times? How many of these minutes are there? So out of 24*60 minutes in a day, 1 day is actually just generated by x of these significant minutes. (This is not a homework question)",['combinatorics']
309061,$\omega(x)=\mathbb{R}^2$ is false.,"Let $ \phi $ be a flow on $ \mathbb{R}^2 $ coming from $ C^1$ class function.
I want to prove that there is no point $x \in \mathbb{R}^2 $ such that $\omega(x)=\mathbb{R}^2$ (where $\omega (x) := \{y \in \mathbb{R}^2 \ | \ \exists t_{n} \to \infty : \text{ }\phi(t_{n},x) \to y \}$). It is an implication from Poincare-Bendixson theorem? (I've studied only this version: $ \emptyset \neq \omega (x) $ - bounded $ \Rightarrow \omega (x)$ has an equilibrium point or is a closed orbit.) Thank you for help.","['dynamical-systems', 'ordinary-differential-equations']"
309069,Geodesic on a surface of revolution using Christoffel Symbols.,"I have the following problem: For a function $f:[a,b]\rightarrow \mathbb{R}_{>0}$ and for the open set $U=\{(u_1,u_2)\vert\: a<u_1<u_2, 0\leq u_2<2\pi\}$ consider the (local) surface of revolution $M$ obtained as the image of $\sigma:U\rightarrow U'\subset\mathbb{R}^3$ where
\begin{equation}
\sigma(u_1,u_2) = \left(f(u_1)cos(u_2),f(u_1)sin(u_2),u_1\right)
\end{equation}
For a constant $0\leq c<2\pi$, shot that  the meridian curve $\gamma(t)=\sigma(u_1(t),c)$ is a geodesic in $M$. The way I have tried to solve this as follows: Recall that $\gamma(t)=\sigma(\gamma_1(t),\gamma_2(t)) = \sigma(u_1(t),c)$ and consider the geodesic equations:
\begin{equation}
\frac{d^2\gamma_k}{dt^2} + \sum_{i,j=1,2}\Gamma_{ij}^k \frac{d\gamma_i}{dt}\frac{d\gamma_j}{dt} = \frac{d^2\gamma_k}{dt^2} + \Gamma_{1,1}^k\left(\frac{d\gamma_1}{dt}\right)^2 + 2\Gamma_{1,2}^k \frac{d\gamma_1}{dt}\frac{d\gamma_2}{dt} + \Gamma_{2,2}^k\left(\frac{d\gamma_2}{dt}\right)^2 = 0
\end{equation}
which should be satisfied for $k=1,2$ if $\gamma(t)$ is a geodesic ($\Gamma_{ij}^k$ are the Christoffel Symbols). Since $\frac{d\gamma_2}{dt} = 0$, the equations above reduce to
\begin{equation}
\frac{d^2\gamma_k}{dt^2} + \Gamma_{1,1}^k\left(\frac{d\gamma_1}{dt}\right)^2 = 0
\end{equation}
Computing $\Gamma_{1,1}^1$ we get:
\begin{equation}
\Gamma_{1,1}^1 =\frac{1}{2}\left(g^{-1}\right)^{1,1}\frac{\partial g_{1,1}}{\partial u_1}= \frac{\frac{\partial f(u_1)}{\partial u_1}\frac{\partial^2f(u_1)}{\partial u_1^2}}{\left(\frac{\partial f(u_1)}{\partial u_1}\right)^2 + 1}
\end{equation}
and $\Gamma_{1,1}^2 = 0$. The first fundamental form is:
\begin{equation}
(g_{ij}) = 	\begin{pmatrix} 
																	f'(u_1)^2+1	& 0 \\
																	0		 	& f(u_1)^2 
													\end{pmatrix}							= 	\begin{pmatrix} 
																												\frac{1}{f'(u_1)^2+1}	& 0 \\
																												0		 	& \frac{1}{f(u_1)^2} 
																								\end{pmatrix}^{-1}.
\end{equation} This does not seem to work out, and I was wondering why? What mistake have I made? Cheers!",['differential-geometry']
309080,"Cantor set + Cantor set =$[0,2]$","I am trying to prove that $C+C =[0,2]$ ,where $C$ is the Cantor set. My attempt: If $x\in C,$  then  $x= \sum_{n=1}^{\infty}\frac{a_n}{3^n}$ where $a_n=0,2$ so any element of $C+C  $ is of the form  $$\sum_{n=1}^{\infty}\frac{a_n}{3^n} +\sum_{n=1}^{\infty}\frac{b_n}{3^n}= \sum_{n=1}^{\infty}\frac{a_n+b_n}{3^n}=2\sum_{n=1}^{\infty}\frac{(a_n+b_n)/2}{3^n}=2\sum_{n=1}^{\infty}\frac{x_n}{3^n}$$ where $x_n=0,1,2, \ \forall n\geq 1$. Is this correct?","['general-topology', 'cantor-set', 'real-analysis', 'analysis']"
309097,"The smallest subgroup containing $ (1, 2) $ and $(1, 2, 3.,\ldots,n) $ is $ S_n$","I try  this by following way,
Let  $H $ be the subgroup  generated by $(1, 2), (1, 2, 3,\dots .,n) $. How do I show, $H$ contain  elements $ (1, r) $  for $ r = 1, 2,...n$. Does there exist any trick to show it?",['group-theory']
309105,Does it exist a function for which the derivative changes sign more than countably many times?,"Does there exist any function $f \in C^2[0,1]$; $f: [0,1] \mapsto [0,1]$, for which the derivative changes sign more than countably many times?","['calculus', 'real-analysis']"
309121,$w^4+(w')^2 = g(t)$,"I have a question about a first order non-linear differential equation. I have tried many method to solve this problem but not successful yet. 
Here is my question; $$w^4 + (w')^2 = g(t)$$ $$w' = \left[g(t)- w^4\right]^{0.5}$$ I have tried runge kutta 4th order and 4-5 adaptive step size and cash-carp methods up to now, I think they are very good methods to solve this IVP but still not give expected values for some places. Do you have another suggestions to solve this? 
Thanks in advance","['ordinary-differential-equations', 'numerical-methods']"
309124,Find all integers such that $\frac{n^3-3}{n^2-7}$ is an integer,"Find all integers such that $\frac{n^3-3}{n^2-7}$ is an integer.
I have no idea how to approach these types of proofs. But I tried a few things, did not get me anywhere. $n^3 -3 = an^2-7a$ then $n^3-an^2 = 3-7a$, and hence $n^2(n-a) = 3-7a$ And then I have no where to go... Any help is appreciated thanks.",['number-theory']
309125,Proof of the arc length parametrization is $1$,"Let $\gamma : [a,b] \to \mathbb R^n$ be a regular curve. Let $p:[a,b] \to [0, p(b)]$ be the map $p(t) = \int_{a}^t \|\gamma' (s) \|ds$. Then $p^{-1}: [0,p(b)] \to [a,b]$. I tried to show that $\|\gamma'(p^{-1}(s))\| = 1$ (for all $s\in[a,b]$). Can you check my work please? Proof is: By definitions, if $s=p(t)$ then $p'(t) = \|\gamma' (t) \|$ for all $t \in [a,b]$ and $\gamma'(p^{-1}(s)) = {d \over ds}\gamma(p^{-1}(s)) = {d p^{-1} (s) \over ds } {d \gamma(p^{-1}) \over d p^{-1}} = {1 \over p' (p^{-1} (s))} {d \gamma (p^{-1}) \over dp^{-1}}$ therefore 
$$\|\gamma'(p^{-1}(s))\| =  {1 \over \| p' (p^{-1} (s))\|} \left \| {d \gamma (p^{-1})  \over  dp^{-1} } \right \|= {1 \over  \| p' (p^{-1} (p(t)))\| } \|\gamma' (t)\|= {\|\gamma'(t)\| \over \|p'(t)\|}= {\|\gamma' (t)\| \over \|\|\gamma' (t)\|\|}1$$.","['multivariable-calculus', 'differential-geometry']"
309134,For what values of x $\sum_{n=1}^{\infty} \frac{(x-4)^{n^{2}}}{n!}$ converges?,"$$\sum_{n=1}^{\infty} \frac{(x-4)^{n^{2}}}{n!}$$
I've tried root test but I couldnt solve","['sequences-and-series', 'calculus']"
309139,Finding the ring of integers of $\mathbb Q[\alpha]$ with $\alpha^5=2\alpha+2$.,"I am stuck with problem 22, chapter 3 in Marcus' book Number Fields which says: Suppose $\alpha^5=2\alpha+2$. Prove that the ring of integers of $\mathbb Q[\alpha]$ is $\mathbb Z[\alpha]$. Prove the same thing also if $\alpha^5+2\alpha^4=2$. Try: Discriminant for both of them is not square free.","['integer-rings', 'algebraic-number-theory', 'abstract-algebra']"
309148,About normalization of scheme,"I have the following definition for normalization of scheme: Let $X$ a integral scheme and $L\supseteq K(X)$ an algebraic extension. So $\pi:X'\to X$ is a normalization of $X$ in $L$ if $X'$ is normal, $K(X')=L$, $\pi$ is integral and $\pi$ extend the canonical map $\mathrm{Spec}(L)\to X$. My first problem is to prove the uniqueness. My idea was to get it with a universal property: $\pi:X'\to X$ is the normalisation of $X$ in $L$ iff for all $Y$ normal with $K(Y)=L$, $Y\to X$ integral there a unique $Y\to X'$ so that the diagram we think is commutative. Is it that? I'm not sure because I can't verify it because of my second problem. If my approach via univeral property were false, how get the uniqueness? My second problem was the affine case. I suspect that if $X$ is affine with $X=\mathrm{Spec}(A)$ we have $X'=\mathrm{Spec}(A')$ with $A'$ the integral closure of $A$ in $L$. Whatever the definition (of normality in $L$) that I take I have to check the integrity of $f:X'\to X$ that is: for all $U\subseteq X$ open we have $f^{-1}(U)$ affine and $\mathcal{O}_{X'}(f^{-1}(U))$ integral over $\mathcal{O}_X(U)$. My problem is to check the first part: why for all $U\subseteq X$ open we have $f^{-1}(U)$ affine?","['algebraic-geometry', 'schemes']"
309149,Riesz representation theorem on dual space,"The Riesz representation theorem on Hilbert spaces is well known, It asserts we can represent a bounded linear function on a Hilbert space $H$ with an inner product on $H$ and vice-versa. My question: Given an inner product in $H^*$, say $(a,b)_{H^*}$, can I write it as $$(a,b)_{H^*} = \langle a, f \rangle_{H^*, H}$$ where $f \in H$? This is the RRT applied to the Hilbert space $H^*$ with its dual $H$. I think it works but I never saw it so I should get it clarified.","['hilbert-spaces', 'functional-analysis', 'riesz-representation-theorem']"
309166,Proving upper limit on number of moves?,"In a $(2n-1)\times(2n-1)$ square grid every small square is marked with Up or Right or Down or Left arrow. An example would be
$$\begin{array}{|c|c|c|}\hline\\\leftarrow & \rightarrow & \leftarrow\\ \hline \\ \uparrow & \downarrow & \uparrow \\ \hline \\ \leftarrow & \uparrow & \rightarrow  \\ \hline \end{array}$$
A bug starts from an arbitrary square. It moves by following the arrow of current square, after it leaves, the arrow in that square is turned by $\frac{\pi}{2}$ radian anticlockwise. The process continues until the bug escapes the square grid. Show that for any arrangement of arrows in $(2n-1)\times(2n-1)$ grid the bug will be out of the square in not more than $2^{3n-1}.(n-1)! -3$ moves. PS: If you have any ideas please edit the title to something more informative. Source: Problem Statement","['dynamical-systems', 'puzzle', 'recreational-mathematics', 'combinatorics']"
309175,Two gamblers' ruin,"I'm trying to work out the solution to a variant of the gambler's ruin. Here's my version: There are two very unlucky but friendly gamblers A and B who decide
to pool their money together to form a common budget with starting
amount $b$, a positive integer. They roll a weighted die to decide who
will play the next game. Therefore, gambler A will play a round with
probability $p_A$. Likewise gambler B plays with probability
$p_B=1-p_A$. Now, A and B are bad at gambling and either break even or
lose money whenever they play—say \$1. So their pool of money can
only decrease. However, they are not equally unlucky. Gambler A breaks even (does not lose or make money) $q_A$ of the time and loses otherwise. And gambler B breaks even
$q_B$ of the time and loses otherwise. When they've totally exhausted their funds, I want to know how much
money each gambler is individually responsible for losing. For example, say they started off with \$1000 and gambler A plays 1/3
of the time, and breaks even 1/3 of the times he plays. Gambler B
plays (therefore) 2/3 of the time and breaks even 1/2 of the time she
plays. (By simulation) gambler A is likely responsible for about \$400
lost and gambler B is responsible the remaining \$600. I'd appreciate any hints.","['random-walk', 'probability']"
309177,When is $(2^a-1)$ a power of 3,"I am looking to characterize the values of $a\in\mathbb{Z}$ for which $(2^a-1)$ is an integral power of 3. In particular, are there any besides $a=1,2$? Any positive/negative results would be much appreciated. Thanks!",['number-theory']
309183,Help with second integral in a Cauchy's integral formula problem.,I have been trying to do this problem for a while: Use Cauchy's integral formula to evaluate $$\int_{-\infty}^\infty \frac{t\operatorname{sin}(\pi t)}{t^2+4}dt.$$ I have factored it into $$\int_{-\infty}^\infty \frac{t\operatorname{sin}(\pi t)}{t^2+4}dt=\frac{1}{2i}\left(\int_{-\infty}^\infty \frac{te^{i\pi t}}{t^2+4}dt-\int_{-\infty}^\infty \frac{te^{-i\pi t}}{t^2+4}dt\right).$$ So for first integral I am supposed to split it up into $\oint f dz - \int_{\gamma}f dz$ where $f$ is the integrand above and $\Gamma$ is a circle of radius $R$ in the upper half plane (ie $\gamma(t)=Re^{i\theta}:0\leq\theta<\pi$).  But I can't seem to evaluate the second integral in this formula - the $\int_{\gamma}f dz$. I'm sure this is obvious but I could use some help.,['complex-analysis']
309185,Centralizers of Matrices,"let $A$ be a complex matrix. Denote by $J(A)$ the Jordan Canonical Form of $A$. Let $C[J(A)]$ be the centralizer of $J(A)$ in $M_n(\mathbb C)$. Can we construct a real matrix $B$, that is, $B$ has only real entries,  verifying the equality $C[J(A)]=C(B)$, in $M_n(\mathbb C)$?",['matrices']
309187,Motivation for the importance of topology,"Starting from tomorrow, I will be tutoring some undergraduate students following a course in general topology. I am looking for examples motivating the importance of topology in mathematics which can be explained without too much difficulty using concepts of other areas of mathematics (or physics) they have already treated (those areas would be mainly analysis, complex analysis, linear algebra, a little graph theory, some numerical methods for maths, and classical mechanics, electromagnetism, special relativity, some QM and a little statistical physics for physics). I have tried looking around, but I have found little that would motivate me to follow such a course. Do anybody have some nice example? Note: I will of course explain to them that without topology they'll be able to do very little advanced mathematics (e.g. functional analysis, differential geometry, ...) EDIT: Ok, I gave as examples Tychonoff's theorem, Brower's fixed point theorem and the Jordan curve theorem. I would like to keep this question alive, for personal interest. What are interesting (not too hard) applications of topology in other areas of mathematics?","['general-topology', 'education']"
