question_id,title,body,tags
3312092,How is $\sin 90° = 1$ possible?,"How can two angles of a triangle be equal to $90°$ ? If two angles were $90°$ , this would mean that the two sides would be parallel and the angle of the third side would be equal to 0 . Thus, there would be only two vertices and this wouldn't be a triangle at all, ultimately making $\sin 90° = 1$ impossible.","['trigonometry', 'functions', 'triangles', 'ratio']"
3312102,Is the derivative of the function bounded?,"If a function has an oblique or horizontal asymptote but doesn't have any vertical asymptote, then can we say that the derivative of the function is bounded? This question came in my mind while I was studying real analysis, geometrically I am able to see that it might happen but am not able to give any analytical proof.","['calculus', 'derivatives', 'real-analysis']"
3312117,Computing a canonical divisor,"I am trying to understand canonical divisors better by computing some examples. Let $R = k[u,v,w]/(v^2 - uw)$ , and set $X = \text{Spec}(R) \subseteq \mathbb{A}^3$ . Let $\tilde{X}$ be the blow-up of $X$ at the origin, which naturally sits inside of $Y$ , the blow-up of $\mathbb{A}^3$ at the origin, as a divisor. I want to compute the canonical divisor of $\tilde{X}$ . Because the blow-up map $\tilde{X} \to X$ is an isomorphism away from $0$ and $X$ is normal Gorenstein the canonical divisor is supported on the exceptional divisor $E$ of the blowup, i.e. $K_{\tilde{X}} = k E$ for some $k \in \mathbb{Z}$ . The question is then: what is $k$ ? My idea was: we know that $K_Y = 2 E'$ where $E'$ is the exeptional divisor on $Y$ (general fact about the canonical of a blow-up of a smooth variety along a smooth subvariety). As $\tilde{X}$ is a smooth divisor on $Y$ , by the adjunction formula we get $K_{\tilde X} = (2 E' + \tilde{X})|_{\tilde{X}}$ , but here I am stuck. Can anyone point me to how to proceed? Or maybe there is a better way of computing the canonical divisor on this surface? Do you know other examples that are easy to compute by hand? Thank you in advance.","['algebraic-geometry', 'commutative-algebra']"
3312152,Arbitrary union example,"In Enderton, Elements of Set Theory , an arbitrary union axiom is written in this way. Axiom. For any set $A$ , there exist a set $B$ whose elements are exactly the members of the members of $A$ . \begin{equation}
\forall x  \left[x \in B \iff \left(\exists b \in A\right)x \in b\right].
\end{equation} This set is called $\cup A$ . Hence, \begin{equation}
x \in \cup A \iff \left(\exists b \in A\right)x \in b.
\end{equation} I have two doubts : Now, suppose that $A=\{\{x\},\{x,y\}\}$ . Then, $\cup A$ is the set of 
members of members of $A$ . Members of $A$ are $\{x\}$ and $\{x,y\}$ . Hence, $\cup A=\{x,x,y\}=\{x,y\}$ . What about $\cup \cup A$ ? It should be the set of members of $x$ and $y$ . Thereby $\cup \cup A= x \cup y$ ? Is it okay? Suppose $A=\{x,\{x,y\}\}$ . Now I'm really in trouble. What is $\cup A$ ?",['elementary-set-theory']
3312162,"If $Y = 1 - X$ then is the cdf of $Y$, 1 for y ≥ 1?","$$F_{X}(x)=\begin{cases} 0, & x<0 \\ x, & 0 \le x < 1 \\ 1, & x ≥ 1. \end{cases}$$ The question is contained in a text book: This is how I have proceeded: $P(y≥1) = P[(1-x)≥1] = P(x\leq 0) = 0$ . I don't know how to get $1$ .",['probability']
3312171,Does $-\frac{1}{2}+\frac{1}{3}-\frac{1}{5}+\frac{1}{7}+\frac{1}{11}+\frac{1}{13}+\frac{1}{17}+\frac{1}{19}+\frac{1}{23}+\dots$ converge?,"Let $d(m)$ be the number of positive divisors of $m$ [including $1$ and $m$ ]. Let $p_k$ be the $k^\text{th}$ prime number. Consider the series $$\sum_{k=1}^{\infty }\frac{(-1)^{d(p_{k}-1)}}{p_{k}}=-\frac{1}{2}+\frac{1}{3}-\frac{1}{5}+\frac{1}{7}+\frac{1}{11}+\frac{1}{13}+\frac{1}{17}+\frac{1}{19}+\frac{1}{23}+\dots$$ Does the series converge? If yes, then what is its value of
  convergence? Any help/hint will be appreciated. THANKS!","['number-theory', 'divisor-counting-function', 'elementary-number-theory']"
3312208,"Interesting patterns in $f(k,n)=k\pi-\sum\limits_{x=1}^n\tan^{-1}\left(\frac1{\sqrt[k]x}\right)$","Motivation: If we draw a right-angled triangle $A_1$ with sides $1,1$ then the hypotenuse is of length $\sqrt2$ . If we draw a right-angled triangle $A_2$ with sides $\sqrt2,1$ attached to $A_1$ then the hypotenuse is of length $\sqrt3$ . If we draw a right-angled triangle $A_3$ with sides $\sqrt3,1$ attached to $A_2$ then the hypotenuse is of length $\sqrt4$ . If we keep on doing this, what is the largest value of $n$ such that none of the areas of $A_1,\cdots,A_n$ overlap? Consider the bivariate function $$f(k,n)=k\pi-\sum_{x=1}^n\tan^{-1}\left(\frac1{\sqrt[k]x}\right)$$ where $k,n$ are positive integers. For every $k$ , there is a largest value $n$ (call it $n^+$ ) such that $f(k,n)$ is minimised yet remaining non-negative. The results are tabulated below. \begin{align}\begin{array}{c|c|c}k&f(k,n^+)&n^+\\\hline
1& 0.0358 &16\\
2& 0.1545 &16\\
3& 0.1000 &20\\
4& 0.1239 &24\\
5& 0.1863 &28\\
6& 0.2670 &32\\
7& 0.3557 &36\\
8& 0.4475 &40\\
9& 0.5394 &44\\\\\\\\\\\\
\end{array}\quad\quad\quad\begin{array}{c|c|c}k&f(k,n^+)&n^+\\\hline
10& 0.0344 &49\\
11& 0.1097 &53\\
12& 0.1844 &57\\
13& 0.2580 &61\\
14& 0.3300 &65\\
15& 0.4004 &69\\
16& 0.4690 &73\\
17& 0.5357 &77\\
18& 0.6007 &81\\
19& 0.6640 &85\\\\\\\\\\
\end{array}\quad\quad\quad\begin{array}{c|c|c}k&f(k,n^+)&n^+\\\hline
20& 0.0516 &90\\
21& 0.1072 &94\\
22& 0.1616 &98\\
23& 0.2147 &102\\
24& 0.2666 &106\\
25& 0.3173 &110\\
26& 0.3669 &114\\
27& 0.4154 &118\\
28& 0.4628 &122\\
29& 0.5091 &126\\
30& 0.5544 &130\\
31& 0.5988 &134\\
32& 0.6423 &138\\
33& 0.6848 &142
\end{array}\end{align} We can see several interesting patterns. It seems that $n^+$ increases by $4$ for each increment of $k$ , but at certain values, it increases by $5$ . In each table, $f(k,n^+)$ seems to be monotonically increasing. As $k$ increases, the length of the table increases (from left to right) Each table (from left to right) represents a cycle . Therefore we have $$(n^+)_1=9,\quad (n^+)_2=10,\quad (n^+)_3=14$$ since the first cycle has length $9$ , the second cycle has length $10$ and the third cycle has length $14$ . Questions Why does $n^+$ increase by $4$ so regularly in each cycle? Is it true that $f(k,n^+)$ is monotonically increasing in each cycle? Is it true that as $\ell$ increases, $(n^+)_\ell$ increases? Answer to Motivation: If $A=\{A_1,\cdots,A_n\}$ then $|A|=16$ since $k=2$ .","['optimization', 'trigonometry', 'recreational-mathematics', 'sequences-and-series']"
3312288,Almost sure definition of Ito's lemma but integral terms are defined in $L^2$,"I am aware that this question is related to this but I thought it would be useful to clarify a few things. I am reading this book to get a quick overview of stochastic calculus. It introduces the Ito's lemma in an almost sure sense, However, the term $\int_0^T F'_x(t,W(t)) dW(t)$ is defined in the book as a limit of sums which converge in $L^2$ . In the proof of Ito's Lemma, the book always mentions that if the convergence is $L^2$ , there is a subsequence that converges almost surely. With this in mind, is it OK then to define stochastic integrals $\int_0^T f(t,W(t)) \,dW(t)$ in the almost sense? I find this confusing since this integral may not even be defined for an abritrary continuous function $f$ especially if $f$ and $W$ don't simultaneously satisfy certain variation conditions. OR, should I interpret it in this manner: Define the stochastic integral in $L^2$ and for those which converge in $L^2$ , we can also define the a.s. convergence using the subsequence argument? Hoping for clarification on the issue. Thanks!","['stochastic-calculus', 'stochastic-processes', 'brownian-motion', 'probability-theory', 'probability']"
3312292,When does the direct image functor respect direct sums of sheaves?,"Let $f: X \rightarrow Y$ be a morphism of schemes, where $Y = \text{spec}A$ is affine. Let $\mathcal{L}$ be an invertible sheaf on $X$ . Is it true that the direct image functor $f_{*}$ respects arbitrary direct sums in the sense that, $$
f_{*} \bigoplus_{d \geq 0} \mathcal{L}^{\otimes d} \simeq \bigoplus_{d \geq 0} f_{*} \mathcal{L}^{\otimes d} 
$$ Are there any conditions on $f$ that would make this true?","['coherent-sheaves', 'category-theory', 'algebraic-geometry', 'adjoint-functors', 'schemes']"
3312306,"given 20 diff jewelry, wear 5 per day. proof that after 267 days at least one pair of jewelry would be wear in 15 diff days.","Given 20 different jewels. 
which 5 of them can be wear per single day. proof that after 267 days, there would be at least one pair of jewelry that wears together (in other combination) in 15 different days. I need to prove this claim using the pigeonhole principle. 
I've tried to come with a solution by taking all the possible pairs fitting them into the 5 possible positions of the jewelry who can be wear per day. 
then, to prove that the 5th jewel will provide a combination which has been already used in the last 15 days. 
I having a hard time to provide a combinatorial solution and declaring what is the pigeonholes and what is the pigeon number.","['number-theory', 'pigeonhole-principle', 'combinatorics', 'discrete-mathematics']"
3312326,"$f$ has $n$-order derivative for any $n$ and for each $x$, $ \mid f^{(n)}(x) - f^{(n-1)}(x) \mid < \frac{1}{n^2} $ to show its limit.","$f$ is defined in $\mathbb{R}$ , has $n$ -order derivative for any $n$ ,
and for each $x$ , $$ \mid f^{(n)}(x) - f^{(n-1)}(x) \mid < \frac{1}{n^2} $$ show that $\lim_{n \to \infty} f^{(n)}(x) = c \exp(x)$ with constant $c$ . as $n \to \infty$ , the $f^{(n)}(x) - f^{(n-1)}(x)$ trends to $0$ , it is quite natural to say one of the limits of $f(x)$ is $ c \exp(x)$ intuitively, but I don't know how to exclude the rest and put it mathematically, can someone provide a clue.","['derivatives', 'real-analysis']"
3312332,Structure of simple group of order 168 just via Sylow theory (fix for Math Doctor Bob),"There are a lot of questions on here about the simple group of order 168, e.g., this , this , this , this , this , this , and this . There is also plenty of info on the internet about this group, e.g., this . I am about to ask something very specific that I think is different from these, but please let me know if I've missed something. A student of mine recently showed me this pair of videos ( part 1 , part 2 ) by Robert Donley (aka Math Doctor Bob ), which attempts to derive the number and structure of the Sylow subgroups of the simple group of 168, along with its class equation, using only Sylow theory, the classification of groups of order 8, and elementary counting arguments. I buy the arguments in the first video, but the second video seems to me to contain a significant gap in reasoning. My question is about how to patch the reasoning in the video using only the types of tools used in the video. (The closest thing I could find was these notes , which use the same types of tools and obtain the same results, but what I want is specifically to rescue Donley's argument itself.) Here are the details: Up til about 2m,15s into the second video, the argument has established that: There are 8 Sylow 7-subgroups, for a total of 48 elements of order 7. There are 28 Sylow 3-subgroups, for a total of 56 elements of order 3, and they are all conjugate. There are no elements of orders 6 or 14. At this point, Donley turns attention to the Sylow 2-subgroups, arguing first that they are nonabelian, and then using this to conclude that there are 21 of them and they are self-normalizing, and proceeding from there to use counting arguments to deduce that they are isomorphic to $D_4$ . His argument that they are nonabelian appears to me to have a big gap. Donley says, consider one Sylow 2-subgroup; call it $H_8$ . Look at its order 2 elements. If $H_8=C_2^3$ , there are 7 of them; let a Sylow 3-subgroup act by conjugation (this claim is what I have a problem with); since $3\nmid 7$ , there is a singleton orbit, so an order 2 element is centralized by an order 3 element, and there is an order 6 element, contradiction. If $H_8=C_4\times C_2$ , he lets a Sylow 7-subgroup act and concludes in the same way (since $7\nmid 3$ ) that there is a singleton orbit and thus an element of order 14. If $H_8=C_8$ , he lets either one act because there is only one element of order 2. My objection is that you can't let a Sylow 3-subgroup act on the order 2 elements in a specific Sylow 2-subgroup unless you have already established, or are at least explicitly provisionally assuming, that the Sylow 2 normalizer contains a Sylow 3. (And similarly for a Sylow 7 in place of a Sylow 3.) In fact, Donley concludes shortly thereafter that the Sylow 2's are self-normalizing, by reasoning that the nonabelian groups of order 8 each have a center of order 2, thus a factor of 3 or 7 dividing the order of the Sylow 2 normalizer would imply an order 2 element centralized by an order 3 or 7 element, and thus an element of order 6 or 14, so the Sylow 2 normalizer's order must only be divisible by 2. So he wants to conclude this is actually false; it certainly shouldn't be assumed implicitly. What I would like to ask your help with is reorganizing just this specific part of the argument, beginning from bulleted information above, to obtain the conclusion that the Sylow 2 is nonabelian. I see how to do it using more powerful tools (specifically, Burnside's transfer theorem ), but I would like to see how to do it using only Sylow theory, the classification of groups of order 8, and counting. If it requires to access information about the structure of $S_4$ , that's fine too. Really I'm thinking in terms of what my student knows. To begin with, I think it's better tactically to consider the number of Sylow 2's before asking about their structure, since this controls whether they are normalized by Sylow 3's etc. Therefore, I think the argument should begin: The number of Sylow 2's is, by Sylow theory, either 1, 3, 7 or 21. It can't be 1 because the group is simple, and similarly 3 can be ruled out because this would imply a nontrivial (and therefore injective, by simplicity) homomorphism to $S_3$ , which is impossible because $168>6$ . So there are 7 or 21 Sylow 2's. Suppose there are 7. Then the Sylow 2 normalizer is order 24, and it contains a Sylow 3, which therefore acts on the Sylow 2. Now Donley's exact reasoning can be used to rule out the cases that $H_8$ is isomorphic to $C_2^3$ , $C_8$ , $D_4$ , or $Q_8$ , and a minor adjustment can be used to rule out $C_4\times C_2$ . Specifically, $C_2^3$ has 7 elements of order 2, so (since $3\nmid 7$ ) the action on these has a fixed point, and Donley's exact reasoning then yields an element of order 6, a contradiction. Meanwhile, all four of $C_4\times C_2$ , $C_8$ , $D_4$ , and $Q_8$ have a characteristic subgroup of order 2, so this too is a fixed point, leading to the same contradiction. (For $C_4\times C_2$ , it's generated by the unique order 2 element that is a square. For the other three, it was identified by Donley, see above: the unique subgroup of order 2 in $C_8$ , and the centers of $D_4$ and $Q_8$ .) These contradictions now rule out the possibility that there are 7 Sylow 2's; there must be 21, and they must be self-normalizing. The real question I have is: From here, how do we conclude that the Sylow 2's are not abelian? Donley's line of argumentation is a nonstarter because we know that the Sylow 3's and Sylow 7's do not act on a Sylow 2. The high-tech answer is the Burnside transfer theorem. If $H_8$ is abelian and self-normalizing, then certainly it is central in its normalizer, and the Burnside transfer theorem then gives us a normal 2-complement, which is impossible since the group is simple. But how would you do it using only Sylow theory, the classification of groups of order 8, counting, and, if you need it, the structure of $S_4$ ? (And the bulleted facts above?)","['group-theory', 'abstract-algebra', 'finite-groups']"
3312334,What are the number of solutions of $|\sqrt{2\sin^4 x+18\cos^2 x}-\sqrt{2\cos^4 x+18\sin^2 x}|=1?$,"The number of $x\in [0,2\pi]$ for which $\bigg|\sqrt{2\sin^4 x+18\cos^2 x}-\sqrt{2\cos^4 x+18\sin^2 x}\bigg|=1$ is What I did try was: Let $$f(x)=\bigg|\sqrt{2\sin^4 x+18\cos^2 x}-\sqrt{2\cos^4 x+18\sin^2 x}\bigg|$$ then $$f\bigg(\frac{\pi}{2}+x\bigg)=\bigg|\sqrt{2\sin^4 x+18\cos^2 x}-\sqrt{2\cos^4 x+18\sin^2 x}\bigg|$$ So, $\displaystyle \frac{\pi}{2}$ is a time period of that function. How do I solve this? Pls, I need help.","['trigonometry', 'proof-writing', 'absolute-value', 'substitution']"
3312384,Pull back of twisted sheaf under a regular map associated to a base point free linear system,"Let $D$ be a divisor on a normal projective variety $X$ and $V$ be a subspace of the global section of $\mathscr O_X(D),$ L is a base point free linear system and $\phi_L:X\overset{(g_0:\cdots:g_n)}\longrightarrow \mathbb P^n$ the regular map associated to L. I have to show $\phi^*_L(\mathscr O_{\mathbb P^n}(m))\cong O_X(mD)$ for all $m\in\mathbb Z.$ PS. I thought about it and I have the following idea. Let $E=1.Z(x_0)$ be the divisor in $\mathbb P^n.$ Then $\mathscr O_{P^n}(E)|_{U_i}=(X_i/X_0)\mathscr O_{U_i}$ where $U_i=\{x_i\neq 0\}.$ Then I know there exists a divisor $\tilde E$ in $X$ such that $\mathscr O_{X}(\tilde E)|_{V_i}=(g_i/g_0)\mathscr O_{X}|{V_i}$ where $V_i=\phi_L^{-1}(U_i).$ I do not understand how to relate $O_{X}(\tilde E)$ with $O_{X}(D)$ Any kind of hint or suggestion will be extremely helpful.","['divisors-algebraic-geometry', 'algebraic-geometry', 'commutative-algebra', 'sheaf-theory']"
3312401,alternative definitions for limit of a sequence,"In several proofs I noticed that authors consider slightly different inequalities to prove that a sequence $(a_n)$ converges to a limit $l$ , for example: $$\forall \epsilon>0 \: \exists N \: \forall n \ge N \: |a_n - l | \le \epsilon$$ and $$\forall \epsilon>0 \: \exists N \: \forall n \ge N \: |a_n - l | < k\epsilon$$ where k is a constant. The aforementioned versions are different from the following traditional definition: $$\forall \epsilon>0 \: \exists N \: \forall n \ge N \: |a_n - l | < \epsilon$$ Why can we consider them as equivalent? Thanks a lot.",['limits']
3312453,Prove $ \left(\sum \limits_{k=1}^n (2k-1)\frac{k+1}{k}\right) \left( \sum \limits_{k=1}^n (2k-1)\frac{k}{k+1}\right) \le \frac{9}{8}n^4$,"Prove that for all $n \in \mathbb{N}$ the inequality $$ \left(\sum \limits_{k=1}^n (2k-1)\frac{k+1}{k}\right) \left( \sum \limits_{k=1}^n (2k-1)\frac{k}{k+1}\right) \le \frac{9}{8}n^4$$ holds. My work . I proved this inequality, but my proof is ugly (it is necessary to check by brute force whether the inequality holds for $n=1,2,3,...,15$ ). I hope that there is nice proof of this inequality. Michael Rozenberg wrote a very nice solution to a similar problem ( Prove the inequality $\sum \limits_{k=1}^n \frac{k+1}{k} \cdot \sum \limits_{k=1}^n \frac{k}{k+1} \le \frac{9}{8}n^2$ ). I think this inequality has a similar proof, but I can’t prove in a similar way. I will write as I proved the inequality. Let $S_n= \sum \limits_{k=1}^n \frac{1}{k} $ . Then $$ \sum \limits_{k=1}^n (2k-1)\frac{k+1}{k}=n^2+2n-S_n $$ and $$\sum \limits_{k=1}^n (2k-1)\frac{k}{k+1}=n^2-2n-3+\frac{3}{n+1}+3S_n$$ We need to prove that $$3S_n^2-S_n \left( 2n^2+8n+3-\frac{3}{n+1}\right)+\frac{n^4}{8}+7n^2+3n-3+\frac{3}{n+1} \ge 0$$ To prove this inequality, I found discriminant of the quadratic polynomial and used the fact that $S_n \le n$ . It was possible to prove that the inequality holds for all $n \ge 16$ .","['contest-math', 'multivariable-calculus', 'summation', 'inequality']"
3312545,Plane Circling an airport.,"A plane is going in circle around an airport the plane takes $3$ minutes to complete one round. The angle of elevation of the plane from point $p$ on the ground at time $t$ seconds is equal to that at time $(t+30)$ seconds. At time $(t+x)$ seconds the plane flies vertically above the point $p$ . What is $x$ equal to? I have tried using basic trig, but that doesn't helps, may be there is some use of circle chord or something.","['trigonometry', 'circles']"
3312555,Find the asymptote of the function $f(x) = \sqrt{\frac{x^3}{x - 3}} - x$,"We have a function $f(x) = \sqrt{\frac{x^3}{x - 3}} - x$ and when $x$ goes towards $-\infty$ , we have an asymptote $y = -2x - 3/2$ .
How we get this asymptote?",['analysis']
3312572,Questions about the existence of a function,"Question 1: Study the existence of $C^1$ function $f : \mathbb{R} \rightarrow \mathbb{R}$ satisfying $\forall x\in\mathbb{R},\mbox{ } f\circ f'(x)=x.$ Question 2: Study the existence of  differentiable function $f : \mathbb{R} \rightarrow \mathbb{R}$ satisfing $\forall x\in\mathbb{R},\mbox{ } f\circ f'(x)=x.$ Question 3: Study the existence of $C^1$ function $f : \mathbb{R} \rightarrow \mathbb{R}$ satisfying $\forall x\in\mathbb{R},\mbox{ } f'\circ f(x)=x.$ For question 1, such a function can not exist because :
f' must be injective and since f 'is continuous, f' must be strictly monotonous. For example, If we assume that f 'is strictly increasing  We can show that $\displaystyle \lim_{x\rightarrow -\infty}f'(x)=-\infty$ and $\displaystyle \lim_{x\rightarrow +\infty}f'(x)=+\infty$ which implies that f ' is surjective . with a simple argument it shows that f is injective ( if $f(x)=f(y)$ by surjection of $ f'$ , we have $f'(a)=x $ and $f'(b)=y$ for some real $ a,b $ , thus implie $a=f(f'(a)=f(x)=f(y)=f(f'(b)=b$ so $ x=y$ ). the continuity of f proves that f est strictly monotonous. For example, if we suppose f strictly inreasing, we must have $f'>0$ . this contradicts the surjectivity of $f '$ For Question 2 , I need help","['functional-equations', 'derivatives', 'analysis', 'real-analysis']"
3312586,Is an automorphism of a finite group inner when it preserves conjugacy of elements and subgroups?,"If $G$ is a finite group, and $\phi \in \operatorname{Aut}(G)$ is an automorphism of $G$ that sends each element $g \in G$ to a conjugate of itself, i.e. there exists an $h_g \in G$ depending on $g$ such that $\phi(g) = h_ggh_g^{-1}$ . sends each subgroup $H \le G$ to a conjugate of itself, i.e. there exists an $h_H\in G$ depending on $H$ such that $\phi(H) = h_HHh_H^{-1}$ . Of course if $\phi$ is inner —that is, there is an element $h_\phi$ depending only on $\phi$ such that $\phi(g) = h_\phi gh_\phi^{-1}$ for all $g \in G$ —then $\phi$ clearly satisfies 1. and 2. I was surprised to discover that there finite groups $G$ and non-inner automorphisms $\phi \in \operatorname{Aut}(G)$ for which at least one of 1. or 2. holds. Are there finite groups $G$ and automorphisms $\phi\in\operatorname{Aut}(G)$ for which both 1. and 2. hold, but $\phi$ is not inner? Edit: Here is an example of ""1. but not 2."" It comes from GroupProps , although the language there goes a little over my head, so any errors in recounting it are mine. Consider $\mathbb{Z}/8\mathbb{Z}$ and its automorphism group $(\mathbb{Z}/8\mathbb{Z})^\times$ . I will write elements of $\mathbb{Z}/8\mathbb{Z}\rtimes(\mathbb{Z}/8\mathbb{Z})^\times$ as $(g,h)$ , e.g. $(4,5)$ . The proposed automorphism $\phi$ has $(g,1) \mapsto (g,1)$ , $(g,7)\mapsto(g,7)$ , but $(g,3)\mapsto(g+4,3)$ and $(g,5) \mapsto(g+4,5)$ . It's not hard to check that $\phi$ is an automorphism, so I'll leave it to you. It also satisfies 1.: $(2,1)$ conjugates $(g,3)$ to $(g+4,3)$ , and $(1,1)$ conjugates $(g,5)$ to $(g+4,5)$ . I claim that it does not send the subgroup $(0,(\mathbb{Z}/8\mathbb{Z})^\times)$ to a conjugate. If it did, $(h,k)$ conjugates $(0,g)$ to $(h-g\cdot h,g)$ , so $h$ must be $0$ or $4$ , both of which are fixed under multiplication by $3$ or $5$ .","['group-theory', 'finite-groups']"
3312607,A closed form for the sum $\frac{a}{b}+\frac{a\cdot(a+1)}{b\cdot(b+1)}+\frac{a\cdot(a+1)\cdot(a+2)}{b\cdot(b+1)\cdot(b+2)}+\cdots$,"I watched this YouTube video that calculates the sum $$\frac{1}{3\cdot4}+\frac{1\cdot2}{3\cdot4\cdot5}+\frac{1\cdot2\cdot3}{3\cdot4\cdot5\cdot6}+\cdots=\frac16$$ then they ask, as a challenge to the viewer, what is the value of the sum $$\frac{17}{75\cdot76}+\frac{17\cdot18}{75\cdot76\cdot77}+\frac{17\cdot18\cdot19}{75\cdot76\cdot77\cdot78}+\cdots$$ This got me thinking about a way to generalise this type of sum, i.e. how can one calculate the value of the sum $$\frac{a}{b}+\frac{a\cdot(a+1)}{b\cdot(b+1)}+\frac{a\cdot(a+1)\cdot(a+2)}{b\cdot(b+1)\cdot(b+2)}+\cdots$$ where $a,b\in\mathbb{N}$ and $a\lt b$ . We can rewrite this sum as $$\begin{align}
\frac{(b-1)!}{(a-1)!}\sum_{n=0}^\infty\frac{(a+n)!}{(b+n)!}
&=\frac{(b-1)!}{(a-1)!\cdot(b-a)!}\sum_{n=0}^\infty\frac{(a+n)!\cdot(b-a)!}{(b+n)!}\\
&=\frac{(b-1)!}{(a-1)!\cdot(b-a)!}\sum_{n=0}^\infty\frac1{\binom{b+n}{b-a}}\\
&=\frac{(b-1)!}{(a-1)!\cdot(b-a)!}\left(\sum_{n=b-a}^\infty\frac1{\binom{n}{b-a}}-\sum_{n=b-a}^{b-1}\frac1{\binom{n}{b-a}}\right)\\
\end{align}$$ So this effectively simplifies down to the following problem: How can we evaluate the sum $$\sum_{n=k}^\infty \frac1{\binom{n}{k}}$$ for $k\in\mathbb{N}\setminus\{1\}$ in a closed form? Numerically it appears that the solution is $$\boxed{\sum_{n=k}^\infty \frac1{\binom{n}{k}}=\frac{k}{k-1}}$$ which would mean that a closed form for our sum is $$\boxed{\frac{a}{b}+\frac{a\cdot(a+1)}{b\cdot(b+1)}+\frac{a\cdot(a+1)\cdot(a+2)}{b\cdot(b+1)\cdot(b+2)}+\cdots=\frac{(b-1)!}{(a-1)!\cdot(b-a)!}\left(\frac{b-a}{b-a-1}-\sum_{n=b-a}^{b-1}\frac1{\binom{n}{b-a}}\right)}$$ testing this solution for our example gives $$\begin{align}
\frac{17}{75\cdot76}+\frac{17\cdot18}{75\cdot76\cdot77}+\frac{17\cdot18\cdot19}{75\cdot76\cdot77\cdot78}+\cdots
&=\frac1{75}\left(\frac{17}{76}+\frac{17\cdot18}{76\cdot77}+\frac{17\cdot18\cdot19}{76\cdot77\cdot78}+\cdots\right)\\
&=\frac1{75}\left(\frac{(76-1)!}{(17-1)!\cdot(76-17)!}\left(\frac{76-17}{76-17-1}-\sum_{n=76-17}^{76-1}\frac1{\binom{n}{76-17}}\right)\right)\\
&=114000634335804\left(\frac{59}{58}-\sum_{n=59}^{75}\frac1{\binom{n}{59}}\right)\\
&=114000634335804\left(\frac{59}{58}-\frac{1023230845711831}{1005887950021800}\right)\\
&=114000634335804\left(\frac1{29170750550632200}\right)\\
&=\frac{17}{4350}\\
\end{align}$$ which seems to agree with numerical evaluation, but how do I prove this result? Edit: There is actually a much better closed form for this result as follows $$\boxed{\frac{a}{b}+\frac{a\cdot(a+1)}{b\cdot(b+1)}+\frac{a\cdot(a+1)\cdot(a+2)}{b\cdot(b+1)\cdot(b+2)}+\cdots=\frac{a}{b-a-1}}$$ which is found in the supplied answers.","['fractions', 'binomial-coefficients', 'closed-form', 'sequences-and-series']"
3312626,prove that (f: ℕ-->ℕ is strictly increasing) ⇒ ∀(x ∈ ℕ)[ x <= f(x)],"My math prof used this result in a proof about sequences without justification. I tried to prove it myself (as an exercise), but my proof quickly got out of control. I ended up using set cardinality and the injectivity of strictly increasing functions. My (unfinished) proof also depends on the truth value of [|A| > |B|] ⇒ A ⊈ B, which I think will be even harder to prove (if it is not axiomatic). Is there a more obvious way to prove this result? I feel like there must be because my prof stated it without explaining. Thank you.","['elementary-set-theory', 'functions']"
3312636,How to prove finite abelian group is direct sum of cyclic groups by using matrices over Euclidean domain?,"Exercise from Algebra, Chapter $0$ by Aluffi: Prove using this proposition: I'm totally lost as to how to begin. How would we relate finite abelian groups to this theorem dealing with matrices over a Euclidean Domain? My only guess to start would be to let $R=\mathbb Z$ (since abelian groups are $\mathbb Z$ -modules). I know also that $M_{m,n}(\mathbb Z) \cong \mathrm{Hom}_{\mathbb Z-\mathrm{Mod}}(\mathbb Z^n, \mathbb Z^m)$ (which is itself a $\mathbb Z$ -module). Am I on the right track? Any ideas on how to go about this?","['modules', 'ring-theory', 'abstract-algebra', 'group-theory', 'abelian-groups']"
3312641,Evaluating a Trigonometric Integral without Substitutions,"I have been tasked with evaluating the integral $$I=\int\frac{\sin(2x)+\sin(4x)-\sin(6x)}{\cos(2x)+\cos(4x)+\cos(6x)+1}dx$$ After substituting first $u=2x$ and then $v=\cos(u)$ and a messy partial fraction decomposition, I get the answer $$\frac{4 \log(\cos(x)) - 2 \log(1 - 2 \cos(2 x)) + 3 \log(\cos(2 x))}{6} + C$$ But given how similar the numerator is to the derivative of the denominator, I suspect there is a much shorter way of going about this involving the identity $$I=\log(\cos(2x)+\cos(4x)+\cos(6x)+1) + \int\frac{3\sin(2x)+5\sin(4x)+5\sin(6x)}{\cos(2x)+\cos(4x)+\cos(6x)+1}dx$$ or something similar and some carefully chosen trigonometric identities. How do I proceed?","['integration', 'indefinite-integrals']"
3312660,"Can't understand an ACT practice problem: Triangle appears to be isosceles, why isn't the answer $7.3\sim $ here?","In the following picture, $XY = YZ$ , $\angle a = 40^\circ$ , and the length opposite is $5$ . The problem asks to compute $XY$ We immediately dropped the dotted perpendicular and get two right triangles. 
The length of the bottom is 2.5 in each right triangle, and therefore $a/2 = 20^\circ$ $\sin 20 = 2.5 / XY$ or, $XY = 2.5 / \sin 20 \approx 7.3$ Their answer uses $5 / a = XY / 70$ $5 / 40 = XY / 70$ $XY = 350/40 = 8.75$ I would have thought both these answers should be the same, where did we go wrong?","['trigonometry', 'geometry', 'fake-proofs']"
3312691,"Pivots, determinant and eigenvalues","In symmetric matrices, Product of pivots = determinant of that matrix Determinant of the matrix = Product of eigenvalues Therefore the product of eigenvalues = product of pivots. Do any or all of the above apply to matrices that are not symmetric?",['matrices']
3312731,Picture of Root System of $\mathfrak{sl}_{3}(\mathbb{C})$,"Let $\mathfrak{h} \subseteq \mathfrak{sl}_{3}(\mathbb{C})$ be the CSA consisting of the diagonal matrices and R the corresponding roots. Then R is a root system in $\mathfrak{h}^{\ast}$ .
I always see people referring to the picture root system $\mathfrak{sl}_{3}(\mathbb{C})$ as that root system. I don't understand why this makes sense, as $\mathfrak{h}^{\ast} \cong \mathbb{C}^{2} \ncong \mathbb{R}^{2}$ .","['semisimple-lie-algebras', 'abstract-algebra', 'lie-algebras', 'root-systems']"
3312760,Proving $\mathcal P(A)= \mathcal P(B) \iff A=B$ - choosing of a specific element of the set,"This question, in general, has been already asked here . My question is whether following approach can be applied too. For any $A$ and $\mathcal P(A)$ we know that $A \in \mathcal P(A)$ If we know that some given set is a power set, seems we are able to choose the ""main"" element from the power set. In other words we can define a function $f(\mathcal P(A))=A$ So if $f(\mathcal P(A))= f(\mathcal P(B))$ , then $A=B$ Is it a valid approach? Update I will try to explain my question better. Of course it's not a problem to fetch $A$ from $\mathcal P(A)$ by $\cup \mathcal P(A)$ . And it's not a problem to prove the statement in many other ways. But my question is intended to achieve a better understanding of functions . And the specific question about P(A)=P(B) - is no more just an example. So... Usually when we define some function we describe the algorithm of this function (or assume it's obvious). But what about defining function without known algorithm? Instead of telling the function ""Return me, please, a union of all elements of $\mathcal P$ "" I want to tell the function ""I know that $\mathcal P$ is a power set and it contains the 'main' element [the set that this $\mathcal P$ was created from]. So, please, dear function, go and fetch this element for me"". I don't see here any contradiction to logic or to common sense. But I wonder is there any contradiction to axioms of sets theory. Hope, my question is clear now. Update 2 I think I understood what is my mistake. I still haven't figured out if there is any meaning in my question in principle. But I realized that the example I gave is really bad. If we have some function that is not one to one it's clear that there is no way do define some sort of inverse function [e.g. if we have $f:\mathbb R\to \mathbb R, f(x)=x^2$ it's not legitimate to define function $g$ (upgraded $f^{-1}$ ) that will in some way reveal secrets - whether appropriate 4 was product of $f(2)$ or of $f(-2)$ ] In our question we know that $P(A)=P(B)$ but we don't know that it's kind of one to one (e.g. may be $A\ne B$ ), so it's impossible do define an inverse function that will fetch the 'main' element. Sorry for all the chatter.",['elementary-set-theory']
3312772,The limit $\lim_{r\to0}\frac1r\left(1-\binom{n}{r}^{-1}\right)$,I have deduced numerically (See also Wolfram ) that we have $$\lim_{r\to0}\frac1r\left(1-\frac1{\binom{n}{r}}\right)=H_n$$ where $H_n$ denotes the $n$ th Harmonic number and we define the binomial coefficient by $$\binom{n}{r}=\frac{\Gamma(n+1)}{\Gamma(r+1)\cdot\Gamma(n-r+1)}$$ Has anyone seen this result or similar elsewhere in mathematical literature? Is it possible to analytically prove this result? Would this result be any useful for calculating $H_n$ explicitly (especially for complex arguments)?,"['gamma-function', 'limits', 'binomial-coefficients', 'harmonic-numbers']"
3312776,Any higher mathematical relationship between these survival analysis entities?,"For part of some software documentation, I created this image of the relationships between survival analysis entities: survival, CDF, PDF, hazard and cumulative hazard (see image below). There is an obvious horizontal ""symmetry"" in the image. Is this a consequence of some higher mathematics? Or is this a consequence of mathematicians are humans and like things to look and feel alike? Or neither, and it's just by chance.",['statistics']
3312777,A version of PCA which chooses regressors based on covariance between responses and X,"The PCA I've seen is to achieve dimensionality reduction by choosing the desired number of principal components in direction which maximizes the total variance of our design matrix $X$ , or the direction which maximizes $X^TX$ . I'm thinking of a way to choose regressors that have the most significance by incorporating the response vector $y$ . So let $x_{(.),1},\dots x_{(.),p}$ be the columns of $X$ , and $\bar{x}_{(.),1},\dots \bar{x}_{(.),p}$ be their centered (mean $0$ ) versions. So I would want to do something like choose a first principal component $v_1$ such that $v_1$ is in the colspace of $X$ and maximizes $$v_1^T \frac{ \sum_{j=1}^p (y - \hat y)\bar x_{(.),j}^T }{\sum_{j=1}^p \| \bar x_{(.),j}\|} v_1~.$$ The reason that I would want something like this is so that I can find a linear transformation of the data such that the probability of my regressors $\beta_1 \dots \beta_p$ under the transformation is in order of significance. In other words, $\mathbb{P}(\beta_1 = 0) \leq \mathbb{P}(\beta_2 = 0) \leq \dots \leq \mathbb{P}(\beta_p) = 0$ . I don't know if something like this exists, or if this is a wrong angle to approach dimensionality reduction from.","['covariance', 'statistics', 'linear-algebra']"
3312820,"Given a knight on an infinite chess board that moves randomly, what's the expected number of distinct squares it reaches in 50 moves?","I was asked this in an interview and wasn't sure how to frame the answer. Basically as in the question you have a knight on an infinite chess board and it chooses one of its valid 8 moves uniformly at each move. After 50 moves, the question was to give (as tight as possible) a lower and upper bound on the expected number of distinct squares it reached. I got as far as realizing that the knight must live in a 200x200 square, and that it can only reach half of the squares (since it must end at the same colour as it started). However this doesn't really address the randomness aspect of the question.","['stochastic-processes', 'geometric-probability', 'probability-theory', 'probability']"
3312860,General ODE and rewriting solution,"When considering the general form (which is an initial value problem) $$\frac{{dy}}{{dt}} = ay - b
% MathType!MTEF!2!1!+-
% feaagKart1ev2aaatCvAUfeBSjuyZL2yd9gzLbvyNv2CaerbuLwBLn
% hiov2DGi1BTfMBaeXatLxBI9gBaerbd9wDYLwzYbItLDharqqtubsr
% 4rNCHbGeaGqiVu0Je9sqqrpepC0xbbL8F4rqqrFfpeea0xe9Lq-Jc9
% vqaqpepm0xbba9pwe9Q8fs0-yqaqpepae9pg0FirpepeKkFr0xfr-x
% fr-xb9adbaqaaeGaciGaaiaabeqaamaabaabaaGcbaWaaSaaaeaaca
% WGKbGaamyEaaqaaiaadsgacaWG0baaaiabg2da9iaadggacaWG5bGa
% eyOeI0IaamOyaaaa!3E8D!
$$ with initial condition y(0)=y0 (Where y0 is an arbitrary initial value) If $$\begin{array}{l}a \ne 0\\y \ne \frac{b}{a}\end{array}
% MathType!MTEF!2!1!+-
% feaagKart1ev2aaatCvAUfeBSjuyZL2yd9gzLbvyNv2CaerbuLwBLn
% hiov2DGi1BTfMBaeXatLxBI9gBaerbd9wDYLwzYbItLDharqqtubsr
% 4rNCHbGeaGqiVu0Je9sqqrpepC0xbbL8F4rqqrFfpeea0xe9Lq-Jc9
% vqaqpepm0xbba9pwe9Q8fs0-yqaqpepae9pg0FirpepeKkFr0xfr-x
% fr-xb9adbaqaaeGaciGaaiaabeqaamaabaabaaGceaqabeaacaWGHb
% GaeyiyIKRaaGimaaqaaiaadMhacqGHGjsUdaWcaaqaaiaadkgaaeaa
% caWGHbaaaaaaaa!3E06!
$$ The testbook I have rewrites the general form as: $$\frac{{\frac{{dy}}{{dt}}}}{{y - (\frac{b}{a})}} = a
% MathType!MTEF!2!1!+-
% feaagKart1ev2aaatCvAUfeBSjuyZL2yd9gzLbvyNv2CaerbuLwBLn
% hiov2DGi1BTfMBaeXatLxBI9gBaerbd9wDYLwzYbItLDharqqtubsr
% 4rNCHbGeaGqiVu0Je9sqqrpepC0xbbL8F4rqqrFfpeea0xe9Lq-Jc9
% vqaqpepm0xbba9pwe9Q8fs0-yqaqpepae9pg0FirpepeKkFr0xfr-x
% fr-xb9adbaqaaeGaciGaaiaabeqaamaabaabaaGcbaWaaSaaaeaada
% WcaaqaaiaadsgacaWG5baabaGaamizaiaadshaaaaabaGaamyEaiab
% gkHiTiaacIcadaWcaaqaaiaadkgaaeaacaWGHbaaaiaacMcaaaGaey
% ypa0Jaamyyaaaa!40EC!
$$ I don't understand why they would rewrite in this way. The only connection I can make in my mind that the derivative is related to the limit which 1/0 would be undefined or a condition associated with a limit. Any insight that some one can provide for this rewrite would really clear up a lot for me. This leads to a solution of the initial value problem of $$y = (\frac{b}{a}) + [y0 - (\frac{b}{a})]{e^{at}}
% MathType!MTEF!2!1!+-
% feaagKart1ev2aaatCvAUfeBSjuyZL2yd9gzLbvyNv2CaerbuLwBLn
% hiov2DGi1BTfMBaeXatLxBI9gBaerbd9wDYLwzYbItLDharqqtubsr
% 4rNCHbGeaGqiVu0Je9sqqrpepC0xbbL8F4rqqrFfpeea0xe9Lq-Jc9
% vqaqpepm0xbba9pwe9Q8fs0-yqaqpepae9pg0FirpepeKkFr0xfr-x
% fr-xb9adbaqaaeGaciGaaiaabeqaamaabaabaaGcbaGaamyEaiabg2
% da9iaacIcadaWcaaqaaiaadkgaaeaacaWGHbaaaiaacMcacqGHRaWk
% caGGBbGaamyEaiaaicdacqGHsislcaGGOaWaaSaaaeaacaWGIbaaba
% GaamyyaaaacaGGPaGaaiyxaiaadwgadaahaaWcbeqaaiaadggacaWG
% 0baaaaaa!46A3!
$$ Thanks in advance.","['multivariable-calculus', 'mathematical-modeling', 'ordinary-differential-equations']"
3312892,College algebra Books,"I am looking for college algebra books containing as many elementary algebra questions as possible. For example, simplify $$\frac{x}{1+x^2} - \frac{4}{(1+x^2)^2}, \quad \frac{4x}{1+2x+ x^3} - \frac{10x^2}{x^2+x^3},$$ or factorise $$x^4-2x^2+1, \quad 2x^2 + 4x+2, \quad etc.$$ It would be good if the book contains challenging  and non-routine questions. Problems for my attempts: Factorize the following polynomial on three factors (polynomials with degree is greater that 0) with integer coefficients. $$x^6+27$$ Let $a$ , $b$ and $c$ be positive numbers such that $abc=1$ . Prove that: $$\frac{1}{1+a+ab}+\frac{1}{1+b+bc}+\frac{1}{1+c+ca}=1.$$ Solve the following equation. $$\sqrt[3]{2-\sqrt[3]{2-x}}=x.$$","['fractions', 'algebra-precalculus', 'book-recommendation', 'reference-request']"
3312958,"Use Cauchy's theorem to prove $\int_0^\infty\sin(x^2)\,dx=\int_0^\infty\cos(x^2)\,dx=\frac{\sqrt{2\pi}}{4}$.","Use Cauchy's theorem to prove $$\displaystyle\int_0^\infty\sin(x^2)\,dx=\int_0^\infty\cos(x^2)\,dx=\frac{\sqrt{2\pi}}{4}~.$$ This is an exercise in Stein's Complex Analysis. He hints that integrate the funtion $e^{-z^2}$ over the path in the figure as follows: So I get \begin{equation}
\int_0^R e^{-x^2}\,dx+\int_{0}^{\frac{\pi}{4}}e^{-R^2\cos(2\theta)-iR^2\sin(2\theta)+i\theta}Ri\,d\theta-\int_{0}^{R}e^{-x^2}e^{i\frac{\pi}{4}}\,dx=0.
\end{equation} If the middle term of the above formula converges to $0$ as $R\to\infty$ , then we are done. I get $$
\bigg|\int_{0}^{\frac{\pi}{4}}e^{-R^2\cos(2\theta)-iR^2\sin(2\theta)+i\theta}Ri\,d\theta\bigg|\leq R\int_0^{\frac{\pi}{4}}e^{-R^2\cos(2\theta)}\,d\theta.
$$ And since $\cos\theta\geq1-\theta^2$ , we have $$
R\int_0^{\frac{\pi}{4}}e^{-R^2\cos(2\theta)}\,d\theta\leq Re^{-R^2}\int_0^{\frac{\pi}{4}}e^{2R^2\theta^2}\,d\theta.
$$ But I don't know how to prove this integral goes to $0$ as $R\to\infty$ .",['complex-analysis']
3312981,check whether a sigma-algebra is countably generated,"Consider the Cantor space $\{0,1\}^\mathbb{N}$ equipped with the Borel algebra $\mathcal{F}$ . Define an equivalence relation $x\sim x'$ if $x$ and $x'$ only differs on finitely many places, i.e.~ $|\{n: x_n\neq x_n'\}|<\infty$ . Let $\Pi$ be the associated partition on $\{0,1\}^\mathbb{N}$ . Let $\overline{\Pi}$ denotes the algebra generated by $\Pi$ closed under arbitrary unions. I would like to know whether the sigma-algebra $\overline{\Pi}\cap\mathcal{F}$ is countably generated. In general I am curious if there is any general procedure of checking whether a sigma-algebra is countably generated.","['measure-theory', 'probability-theory']"
3312995,"If $\lim \limits_{x \to 1} \frac{f(x)+2}{x-1} = 3$, compute: $\lim \limits_{x \to -1} \frac{(f(-x))^2-4}{x^2-1}$","Be $f(x)$ a polynomial in $\Bbb R$ such that:
If $$\lim \limits_{x \to 1} \frac{f(x)+2}{x-1} = 3$$ Compute: $$\lim \limits_{x \to -1} \frac{(f(-x))^2-4}{x^2-1}$$ I noticed that, if the first limit exists, then $f(x)+2 = (x-1)P(x)$ , where $P(x)$ is another polynomial. Then $$\lim \limits_{x \to 1} P(x) = 3$$ I tried to use that in the second limit, but i can't proceed further. Any hints?","['limits', 'calculus', 'limits-without-lhopital', 'polynomials']"
3313040,Evaluate $I = \iint_S x~dS$ over the part of $2z = x^2$ that lies in the first octant part of $x^2 + y^2 = 1$.,"Evaluate $I = \iint_S x~dS$ over the part of $2z = x^2$ that lies in the first octant part of $x^2 + y^2 = 1$ . In my attempt at solving this problem I begin by expressing $S$ a system of equations and inequalities and the paramterizing it. $$
S:
\begin{cases}
  2z = x^2 \Leftrightarrow z = x^2/2 \\
  x^2 + y^2 \leq 1 \\
  x,y,z \geq 0
\end{cases}
\quad
\Leftrightarrow
\quad
\mathbf{r}(r,\theta) = 
\begin{bmatrix}
  r\cos\theta \\
  r\sin\theta \\
  r^2 \cos^2(\theta)/2
\end{bmatrix},
~r \in [0,1], ~ t\in[0, \pi/2]
$$ I arrive at this paramterization by first paramterizing the closed disk $x^2 + y^2 \leq 1$ , and then substituting $x = r\cos\theta$ into $z=x^2/2$ to paramterize $z$ . After coming up with this parameterization I proceed to expressing the area element $dS$ in terms of $r$ and $\theta$ . $$dS = \Big\lvert \frac{d\mathbf{r}}{dr} \times \frac{d\mathbf{r}}{d\theta} \Big\rvert dr d\theta = \dots = \sqrt{\frac{r^2\cos^2(\theta)(r^2 \cos 2\theta - r^2 - 4)}{-2}} dr d\theta$$ My book does not paramterize $S$ and instead immediately finds a significantly easier expression for $dS$ , namely $$dS = \sqrt{1+x^2} dx dy.$$ How should one think to come up with this simpler expression for $dS$ and was my approach to solving the problem, not only ineffective, but wrong?","['multivariable-calculus', 'surface-integrals']"
3313048,Why do solutions to first order autonomous ODEs tend towards equllibria?,"Consider a first order autonomous ODE: $$\frac{dy}{dt}=f(y)$$ The solutions to this ODE cannot cross each other due to the Picard-Lindelöf theorem (lets say this ODE satisfies it). Also note that, because the sign of $f(y)$ can only change at the zeros and the function can't cross the zeros since they are (equilibrium) solutions, $f(y)$ is monotone. These two reasons put together mean that any solution to a 1st order autonomous ODE are bounded by the equilibrium solutions that surround them: p and q are equilibrium solutions, i.e. f(p)=f(q)=0. This is what my introductory textbook on differential equations and all the online resources I could find say about the subject. What I don't get is how they go further and say that the limit of these bound solutions approach the equilibria as $t\to\infty$ or $-\infty$ depending on if $f(y)$ is decreasing or increasing or, if there is no bounding equllibrium solution, $f(y)$ approaches $\pm\infty$ . I mean I believe them, and it certainly seems intuitive, yet I don't see how monotonicity and not being able to cross over guarantee this alone. Couldn't you have a solution with a horizontal asymptote slightly lower/higher than the next highest/lowest equilibria? Such a solution would still be monotone, and still be bounded by the equilibrium solutions, yet doesn't have to get close to them: So why must these solutions approach equilibrium points/explode to infinity if there are no available equilibrium points? Edit: looking at the slope field of my proposed solution, I see that the answer to my question probably has to do with the time invarience of these solutions as the slope field can't change over time to make my proposed solution possible without the asymptote also being an equilibrium solution. But how do I make this precise instead of a graphical intuition?",['ordinary-differential-equations']
3313103,"Prove that $[0,\infty)$ is not homeomorphic to $\mathbb{R}$ without connectedness","I want to prove that the metric space $([0,\infty), |\cdot|)$ is not homeomorphic to $(\mathbb{R},|\cdot|)$ (or $((0,\infty),|\cdot|)$ , whichever is easier) without using the notion of connectedness. I have only been given the definition of a homeomorphism in the question (a continuous bijection between topologies/metric spaces whose inverse is also continuous). I am also allowed to use the following definition of continuity: $f:X\to Y$ is continuous if and only if the preimage of every open set is open. I.e $U\subseteq Y$ is open if and only if $f^{-1}(U)=\{x\in X: f(x)\in U\}\subseteq X$ is open. Part 1 of the question asks us to prove that for homeomorphic spaces, the image of every open set is open. I am not sure if this is helpful. Can someone give some pointers or an outline of a solution?","['general-topology', 'functions', 'open-map', 'metric-spaces']"
3313115,Taking the derivative of $y = (\frac{x}{1-\sqrt{x}})^3$ using the chain rule,"While working through differential calculus questions for the chain rule, I stumbled upon: $$y = \left(\frac{x}{1-\sqrt{x}}\right)^3  $$ I initially attempted to apply the chain rule, but to apply it, I would need to differentiate the contents in the brackets, which, from what I know, I can only differentiate using the quotient rule. However, in my book, the quotient rule is taught later and thus I would assume that I can only use the mathematical tools taught thus far, i.e. the chain rule and the 'differentiating short-cut' (that's what my teacher calls it), i.e. if $f(x) = ax^n$ , $f'(x) = anx^{n-1}$ . I cannot figure out a way to solve this question by only using only the chain rule and differentiating short-cut; am I missing something or is the question simply in the wrong place in my book? I would also like to point out that when I looked at the worked solutions for this maths book, they had all answers for this exercise except for that question. The solutions displayed without working is: $$\frac{1-2\sqrt{x}}{4\sqrt{x-x\sqrt{x}}}$$ Even if I were to use the quotient rule and chain rule, I get a different answer (I even repeated my working twice in case I made a mistake, but I got the same answer both times): $$\frac{3x^2-\frac{3}{2}x^{\frac{5}{2}}}{(1-\sqrt{x})^4}$$ EDIT : I believe the product rule can also not be used to solve this question as it is, just like the quotient rule, taught later in the book. Bibliography: Mathematics Higher Level, IB, by Josip Harcet et. al.","['calculus', 'derivatives', 'chain-rule']"
3313122,Very Explicit Unit/Counit of the Inverse/Direct Image Adjunction,"I've based the title on this question here . There, for sheaves $\mathcal{F}$ and $\mathcal{G}$ on topological spaces $X$ and $Y$ respectively, given a continuous map $\varphi:X\to Y$ they construct the unit and counit of the adjunction between $\varphi_*$ and $\varphi^{-1}$ via the universal properties of the various structures involved. To try to get a feel for all the different constructions, I've been trying to write down the unit and counit explicitly by defining the actual maps themselves. This has been my attempt so far: First we want to define $\varepsilon:\varphi^{-1}\varphi_*\mathcal{F}\to\mathcal{F}$ . Let $U\subseteq X$ be open. For  a sheaf $\mathcal{H}$ on $Y$ , we define $\varphi^{-1}\mathcal{H}$ by sheafifying $\varphi_0^{-1}\mathcal{H}$ , the presheaf given by setting $\varphi_0^{-1}\mathcal{H}$ to be the direct limit of $\mathcal{H}(V)$ for open $V\subseteq Y$ with $\varphi(U)\subseteq V$ . Elements of $\varphi_0^{-1}\varphi_*\mathcal{F}(U)$ are of the form $(a,V)$ , where $V\subseteq Y$ is open, $U\subseteq\varphi^{-1}(V)$ , and $a\in\mathcal{F}(\varphi^{-1}(V))$ . Let $\mathcal{H}=\varphi^{-1}_0\varphi_*\mathcal{F}$ . Elements of $\varphi^{-1}\varphi_*\mathcal{F}(U)$ are then of the form $s:U\to\coprod_{u\in U}\mathcal{H}_u$ , such that for any $u\in U$ we have $s(u)\in\mathcal{H}_u$ and an open set $W_u\subseteq U$ with $u\in W_u$ and some $a_u\in\mathcal{H}(W_u)$ such that, for any $w\in W_u$ , the germ $(a_u)_w\in\mathcal{H}_w$ (this is just the definition of sheafification). Now, $(a_u)_w$ is represented by $(b_{u,w},W'_{u,w})$ for some $W'_{u,w}\subseteq W_u$ with $w\in W'_{u,w}$ and $b_{u,w}\in\mathcal{H}(W'_{u,w})$ . Then $b_{u,w}$ is of the form $(c_{u,w},V_{u,w})$ , where $V_{u,w}\subseteq Y$ is open, $W'_{u,w}\subseteq\varphi^{-1}(V_{u,w})$ , and $c_{u,w}\in\mathcal{F}(\varphi^{-1}(V_{u,w}))$ . Then define $\varepsilon_U:\varphi^{-1}\varphi_*\mathcal{F}(U)\to\mathcal{F}(U)$ by letting $\varepsilon_U(s)$ be given by gluing the $c_{u,u}|_{W'_{u,u}}$ together. We now want to define $\eta:\mathcal{G}\to\varphi_*\varphi^{-1}\mathcal{G}$ . Let $V\subseteq Y$ be open, and let $\mathcal{H}=\varphi_0^{-1}\mathcal{G}$ . Then elements of $\varphi_*\varphi^{-1}\mathcal{G}(V)$ are of the form $s:\varphi^{-1}(V)\to\coprod_{u\in\varphi^{-1}(V)}\mathcal{H}_{u}$ , such that for any $u\in\varphi^{-1}(V)$ we have $s(u)\in\mathcal{H}_u$ and an open set $W_u\subseteq V$ with $u\in\varphi^{-1}(W_u)$ and some $a_u\in\mathcal{H}(\varphi^{-1}(W_u))$ such that, for any $w\in\varphi^{-1}(W_u)$ , the germ $(a_u)_w\in\mathcal{H}_w$ . Now, $(a_u)_w$ is represented by $(b_{u,w},\varphi^{-1}(W'_{u,w}))$ for some $W'_{u,w}\subseteq W_u$ with $w\in\varphi^{-1}(W'_{u,w})$ and $b_{u,w}\in\mathcal{H}(\varphi^{-1}(W'_{u,w}))$ . Then $b_{u,w}$ is of the form $(c_{u,w},V_{u,w})$ , where $V_{u,w}\subseteq Y$ is open, $\varphi(\varphi^{-1}(W'_{u,w}))\subseteq V_{u,w}$ , and $c_{u,w}\in\mathcal{G}(V_{u,w})$ . Let $a\in\mathcal{G}(V). $ Then define $\eta_V:\mathcal{G}(V)\to\varphi_*\varphi^{-1}\mathcal{G}(V)$ by letting $\eta_V:a\mapsto(s:u\mapsto (a)_u)$ , or to be precise unraveling the definitions  (I think) and picking an explicit representative in the various equivalence classes $$s:u\mapsto ((a,V),\varphi^{-1}(V))$$ I feel like these definitions should be correct, since I don't think I could have made any other choices. However I'd like to be certain before I check they satisfy the naturality requirements etc. Then really I have two questions: Are these definitions correct? Do people often use these definitions directly? There are so many equivalence classes of equivalence classes it can be difficult to picture/remember what is going on, especially when looking at stalks of inverse images. I know there's a more down to earth description of sheafification for sheaves of functions, but it still seems unwieldy. Then do we just tend to use the universal properties from the adjunction in practice? Any help would be much appreciated.","['algebraic-geometry', 'category-theory', 'sheaf-theory']"
3313126,Existence of function satisfying $f(f'(x))=x$ almost everywhere,"My project is to Study the existence of a continuous function $f : \mathbb{R} \rightarrow \mathbb{R}$ differentiable almost everywhere satisfying $  f\circ f'(x)=x$ almost everywhere $x \in \mathbb{R}$ I began the study by supposing $f\in   C ^ 1(\mathbb{R}) $ , I have shown that f does not exist. After, I found some difficulties when we assume only f differentiable on $\mathbb{R}$ , I had an answer using Darboux's theorem Questions about the existence of a function . Now, I want to attack the initial problem. Previous arguments do not work! Do you have any suggestions for me?","['functional-equations', 'derivatives', 'functional-analysis', 'real-analysis']"
3313136,Prokhorov Metric and Weak Topology of Measure,"Let $X$ be separable metric space and $\mathscr{M}\left(X\right)$ be the space of all probability measures on $X$ and $d_{P}$ are Prohorov metric on $\mathscr{M}\left(X\right)$ . We denote $\mu_{n}\Rightarrow\mu$ if $\mu_{n}$ converges to $\mu$ weakly. It is well known that $\mu_{n}\Rightarrow\mu\Longleftrightarrow d_{P}\left(\mu_{n},\mu\right)\rightarrow 0$ However, in many books (like Billingsley (1999).Convergence of Probability Measures), they just conclude that the weak topology on $\mathscr{M}\left(X\right)$ can be induced by $d_{P}$ . If the weak topology on $\mathscr{M}\left(X\right)$ is metrizable, we can make sure that this statement is true since topology is determined by convergence in metric space. But we do not have the result that the weak topology on $\mathscr{M}\left(X\right)$ is metrizable. (I know this statement is true, but I don't know how to prove it.) So my question is how to prove that the weak topology on $\mathscr{M}\left(X\right)$ can be induced by $d_{P}$ ? Could anyone help me out? Thanks in advance.","['measure-theory', 'weak-convergence', 'functional-analysis', 'weak-topology', 'general-topology']"
3313146,Solve $ y=({\rm d}y/{\rm d}x)^2 $,"It is obvious that we can differentiate both sides of the equation with respect to $x$ and then discuss the result. But can we just make a square root of both sides and integrate? Sorry the original version is so naive. The following is more detailed. If we take square root $$\pm \sqrt y=\frac{{\rm d}y}{{\rm d}x}$$ then $$\frac{{\rm d}y}{\sqrt y}=\pm {\rm d}x$$ $$2\sqrt y=\pm x+c$$ The solutions are $$y=(\frac{\pm x+c}{2})^2$$ or $y=0$ If we differentiate both sides with respect to $x$ $$y'=2y'y''$$ $$y'(2y''-1)=0$$ If we choose $y'=0$ , then $y=c$ . And plug it in to the original equation, we get $c=0$ . If we choose $y''=\frac12$ , then $y=\frac14x^2+dx+f$ . Plugging in, we get $y=\frac14x^2+dx+d^2$ , which is enough. (How could the non-trivial solutions differ???-this is a solved question now.) Now, everything is great. From this example, I know that there are something a little bit different with the liner differential equation in a nonlinear one. Sometimes, one needs to plug in the solution with constants under some circumstances to determine some constant. Besides, the form of the solution of a nonlinear differential equation could be more complicated-it could be piecewise-combined. One could choose a set of solution satisfying the equation and match them at every boundary of each segment correspondingly. Thank @Allawonder and @Gae. S. for pointing them out.",['ordinary-differential-equations']
3313164,Solving $\tan^{-1}x > \cot^{-1}x$,"I am doing problems in Inverse Trigonometric Functions. I faced some issues while solving Inverse Trigonometric Inequalities. I have mentioned the question, the solution given in my book and the way in which I attempted the problem in the image below. As you could see, clearly the book answer does not match with mine. I tried my best to identify the mistake in my procedure, but I was unable to find any errors. Kindly tell where I have went wrong . I am sure I have gone wrong since I solved the question graphically and attained the result given in my book.","['trigonometry', 'inverse-function', 'inequality']"
3313176,Notation regarding random variables,"Let X be a random variable. Consider X ~ F. It can be read as X has distribution F. What is distribution referring here? Consider the following interpretations 1) If X is continuous, then F is a probability density function and if X is discrete then F is a probability mass function. 2) F is a cumulative distribution function. Which of the above is correct? If not, what is the distribution the notation referring to?","['notation', 'elementary-probability', 'random-variables']"
3313188,"$\iint_A F\cdot n\, dS$ region bounded by $x^2+y^2=1$ and $-1\le z\le 2$","This is the question: we need to find the outward flux and verify it using divergence theorem The main query is that i solved it normally first using $\iint F\cdot n\,dS$ and i got incorrect answer as $3\pi$ and when i solve it using divergence theorem i got the correct answer as $6\pi$ . Can yu please find my mistake? Here is my solution: Now one more thing : what is the condition to use green's theorem and stoke's theorem why are they not valid here as i am getting curl 0 so answer will be 0 according to stoke's theorem. The question is how to know when do we use stoke's green's or divergence theorem ?","['integration', 'divergence-operator', 'surface-integrals', 'multivariable-calculus', 'calculus']"
3313210,"If $f$ is continuous and $f'(x)\ge 0$, outside of a countable set, then $f$ is increasing","PROBLEM. Let $f:[a,b]\to\mathbb R$ be a continuous function, such that $f'(x)\ge 0$ , for all $x\in [a,b]\setminus A$ , where $A\subset [a,b]$ is a countable set. Show that $f$ is increasing. Attention. In this problem, we DO NOT assume that $f$ is differentiable in the whole $[a,b]$ . Notes. (1) If we assume that $f$ is differentiable in the whole interval, then we can easily show that $f'(x)\ge 0$ , everywhere. For otherwise, if $f'(x_0)=c<0$ , for some $x_0\in [a,b]$ , then by virtue of Darboux's Theorem , $(c,0)\subset f'([a,b])$ , and hence, $f'(x)<0$ , for uncountably many $x$ 's. (2) The conclusion of the problem does not hold if we replace the assumption $A$ is countable with $A$ is a set of measure zero . Take for example the Devil's staircase , with a negative sign in front. (3) If the hypothesis $f'(x)\ge 0$ , is replaced by $f'(x)=0$ , then the conclusion becomes f is constant .","['monotone-functions', 'real-analysis', 'continuity', 'calculus', 'derivatives']"
3313218,Show that $(\ln x)^n$ are linearly independent over polynomial.,"Question : If $f_n(x)(\ln x)^n + f_{n-1}(x)(\ln x)^{n-1} + ... +f_0(x) = 0$ where $ f_i (x) $ are polynomial with real coefficients , then show that all $f_i (x)$ are identically zero. I already know that if we replace $ \ln x $ as $ e^x$ , then this is true. Let $f_n(x)e^{nx}+ f_{n-1}(x)e^{(n-1)x} + ... +f_0(x) = 0$ .
By divide $e^{nx}$ , $$f_n(x)+ \frac{f_{n-1}(x)}{e^{x}}+ ... +\frac{f_0(x)}{e^{nx}}= 0$$ . Take limit infinity, $\lim f_n(x)=0$ and this mean $f_n(x)$ is identically zero. By induction, we're done. However, $(\ln x)$ is not accepted in this process because $\frac{P(x)}{\ln x}$ does not approach to zero as $ n \rightarrow \infty$ where $P(x)$ is polynomial. How to prove this?","['calculus', 'real-analysis']"
3313244,Mistake in calculating Green's function,"Solve the BVP $$y'' = f(x) = x, \qquad y(0) = 0, \qquad y'(1) = 0$$ with the usage of Green's function. First of all, the solution should be $$y = \frac{x^3}{6} - \frac{x}{2}.$$ According to this explanation, for calculating $G$ , we first need a fundamental system of the associated homogenous equation $y'' = 0$ . We take $u_1 = x$ and $u_2 = 1$ . According to the boundary values, we now choose $y_1 = x$ and $y_2 = 1$ , then we have $y_1(0) = 0$ and $y_2'(1) = 0$ . Furthermore, $W(y_1, y_2) = -1$ , so it follows $$G(x,s) = \begin{cases} -s \qquad &0 \leq s \leq x \\
-x \qquad &x \leq s \leq 1.
\end{cases}$$ Then I obtain for the solution $$y = \int_0^1 G(x,s) f(s) \ \mathrm{d}s = -\frac{1}{3},$$ which is obviously not the correct answer. Where is my mistake?","['ordinary-differential-equations', 'greens-function', 'real-analysis', 'calculus', 'boundary-value-problem']"
3313271,Equivalence between two versions of Open Mapping Theorem,"I have seen two versions of the open mapping theorem. I am trying to understand why they are equivalent. From wikipedia: If $X$ and $Y$ are Banach spaces and $A : X \rightarrow Y$ is a surjective continuous linear operator, then $A$ is an open map. From Royden (paraphrased): Let $X$ and $Y$ are Banach spaces and $T : X \rightarrow Y$ is a continuous linear operator. $T(X)$ is closed as a subspace of $Y$ iff $T$ is an open map. How are these equivalent? EDIT: I've included the releveant portion in Royden. Indeed, he discusses the image as having inherited the subspace topology from $Y$ -- I missed this before the discussion in the comments, thanks!","['general-topology', 'functional-analysis']"
3313313,Repeated Decimal Expansion Corresponding to a Fraction Problem,"How do I solve the following question. The repeated decimal expansion $1.23\overline 6$ corresponds to
  which fraction? a. $\frac{370}{300}$ b. $\frac{3710}{3001}$ c. $\frac{371}{301}$ d. $\frac{37100}{30001}$ e. $\frac{371}{300}$ Here is how I am trying to do but I get the wrong answer. $100α − α = 123.6 − 1.236 = 122.364$ Hence $99α = 122.364 \Rightarrow α = \frac{122.364}{99}$ Thank you.",['algebra-precalculus']
3313350,weak convergence in $L^2$ and convergence of integral involving test-functions,"Let $\Omega$ be a bounded set of $\mathbb{R}^n$ and $(f_n)_n\subset L^2(\Omega)$ such that $f_n\rightharpoonup f\in L^2(\Omega)$ weakly in $L^2(\Omega)$ . Then for any given test function $\phi\in C^\infty_c(\Omega)$ , do we have the following convergent property: $$
\int_\Omega  |f_n|\phi\,dx\to \int_\Omega |f|\phi \,dx,\quad \textrm{as $n\to \infty$.}
$$","['lebesgue-integral', 'functional-analysis', 'weak-convergence']"
3313356,"Is this an ""If and only if"" proof?","My task is to show that some particular class of sets $F$ is the class of sets of the form $A$ (I'm leaving out the details of the question). My question is as follows: To complete this task, must I show that if a set is of form $A$ then it belongs to the class $F$ , and that if a set belongs to the class $F$ then it has the form $A$ ? The reason I ask is that the writer of the textbook has solutions in the back, and seems to have intended only the former (if a set is in the class $F$ , it has the form $A$ ).","['elementary-set-theory', 'proof-writing']"
3313408,Disjunctive normal form and Conjunctive normal form from truth tables,"Hi hope you're having a good day. I'm working through some work about CNF and DNF and one of the questions was write the answer from a truth table in the CNF, then DNF from the table. So I wrote the CNF from the '1's in the final column, but it was wrong. CNF was supposed for the '0's and DNF for the '1's. I really do not understand the reasoning behind this I can't find much information on it either. I'm really stuck and I have an exam on this tomorrow. I don't unerstand why CNF uses the False values and DNF uses the truths, and what I(P) is. Below is the correct completed truth table and everything from answer sheet. Consider the formula (P∨ ¬R)→ ¬(¬Q∨R) (i) Build a conjunctive normal form for this formula from its truth table (ii) Transform this formula in a logical equivalent disjunctive normal form(DNF) using the rewrite rules. P | Q | R | (P v ¬R) | ¬(¬Q v R) |  (P v ¬R) → ¬(¬Q v R)
1 | 1 | 1 |    1     |     0     |           0
1 | 1 | 0 |    1     |     1     |           1      
1 | 0 | 1 |    1     |     0     |           0
1 | 0 | 0 |    1     |     0     |           0
0 | 1 | 1 |    0     |     1     |           0
0 | 1 | 0 |    1     |     1     |           1
0 | 0 | 1 |    0     |     1     |           0
0 | 0 | 0 |    1     |     0     |           0 A disjunction of three literals is created for each line (for each interpretation of propositional variables) with a false(i.e. 0) value of the formula.For each propositional variable P, the literal P is added to the disjunction if I(P) = 0, and ¬P is added to the disjunction if I(P) = 1. Such disjunction is false for the interpretation given by this line. The corresponding CNF is : (¬P ∨¬Q ∨¬R) ∧ (¬P ∨ Q ∨¬R) ∧ (¬P ∨ Q ∨ R) ∧ (P ∨ Q ∨ R) Here each disjunction has exactly 3 literals, one for each variables appearingin the formula. Such CNFs are called full CNFs . A conjunction of three literals is created for each line (for each interpreta-tion of propositional variables) with a true (i.e., 1) valueof the formula. Foreach propositional variable P, the literal ¬P is added to the conjunction ifI(P) = 0, andPis added to the conjunction is I(P) = 1. Such conjunctionis true for the interpretation given by this line.
  The corresponding DNF is : (P∧Q∧ ¬R)∨(¬P∧Q∧R)∨(¬P∧Q∧ ¬R)∨(¬P∧ ¬Q∧R) Here each conjunction has exactly 3 literals, one for each variables appearing in the formula. Such DNFs are called full DNFs .","['conjunctive-normal-form', 'discrete-mathematics', 'disjunctive-normal-form']"
3313456,Is there an extension of Donsker's invariance principle for not identically distributed random variables?,"As proved in Donsker-Prohorov's Invariance principle, for i.i.d random variables $\xi_1,\xi_2,\cdots$ , its partial sums $S_n(t)=\sum_{i=1}^{[nt]}\xi_i$ converge to Brownian motion $W(t)$ in distribution. What if the random variables $\xi_1,\xi_2,\cdots$ are independent but not identically distributed(i.e, same mean as 0 but different variance $v_i^2$ )? Did someone prove a similar result for not identically distributed cases? If not, how should I prove this by following the original proof? I would appreciate if someone can help!","['central-limit-theorem', 'functional-inequalities', 'stochastic-processes', 'functional-analysis', 'probability']"
3313461,"$V(I)$ consists of a finite set of points if and only $k[x_1,\ldots,x_n]/I$ has Krull dimension zero","I am trying to prove the following: Let $I\subset k[x_1, ..., x_n]$ be an ideal. Show that $V(I)$ consists of a finite set of points if and only if $k[x_1,..., x_n]/I$ , seen as k-space
vector, is an algebra of finite dimension. To do this, I would like to use the following result: $k[x_1,\ldots,x_n]/I$ has Krull dimension zero $\iff$ it is finite-dimensional as a $k$ -vector space. Here is where several questions arise: Question 1: why "" $V(I)$ consists of a finite set of points if and only $k[x_1,\ldots,x_n]/I$ has Krull dimension zero""? If the above is true, it is sufficient to prove then that: $k[x_1,\ldots,x_n]/I$ has Krull dimension zero $\iff$ it is finite-dimensional as a $k$ -vector space. Edit: In everything, k is an algebraically closed field.","['algebraic-geometry', 'ring-theory', 'abstract-algebra', 'dimension-theory-algebra', 'commutative-algebra']"
3313467,How can we compute the Fréchet derivative of $q\mapsto\int\frac{(pf)^2}q\:{\rm d}\lambda$?,"Let $(E,\mathcal E,\lambda)$ be a measure space $p:E\to[0,\infty)$ be $\mathcal E$ -measurable with $$\int p\:{\rm d}\lambda=1$$ $\mu:=p\lambda$ $f\in\mathcal L^1(\mu)$ Now let $$\Phi(q):=\int_{\left\{\:q\:>\:0\:\right\}}\frac{(pf)^2}q\:{\rm d}\lambda$$ for $q\in\mathcal L^1(\lambda)$ with $q\ge0$ . Are we able to rigorously prove that the Fréchet derivative of $\Phi$ exists and is equal to $-\frac{(pf)^2}{q^2}$ ? My first problem is a formal one: A mapping can only be Fréchet derivative on an open subset of a Banach space. We would clearly want to consider the Banach space $L^1(\lambda)$ , but how do we need to define the open suset $\Omega$ ? If this question is clarified, we should need to show $$\frac{\left|\Phi(q+h)-\Phi(q)+\frac{(pf)^2}{h^2}\right|}{\left\|h\right\|_{L^1(\lambda)}}\xrightarrow{h\to0}0\tag1$$ for all $q\in\Omega$ . How can we do this? (If at all.) Please take note of my related question: Minimize $q\mapsto\int\frac{(pf)^2}q\:{\rm d}\lambda$ subject to $\int q\:{\rm }\lambda=1$ using the method of Lagrange multipliers .","['measure-theory', 'frechet-derivative', 'lp-spaces', 'functional-analysis', 'probability-theory']"
3313495,Minimize $q\mapsto\int\frac{(pf)^2}q\:{\rm d}\lambda$ subject to $\int q\:{\rm }\lambda=1$ using the method of Lagrange multipliers,"Let $(E,\mathcal E,\lambda)$ be a measure space $p:E\to[0,\infty)$ be $\mathcal E$ -measurable with $$\int p\:{\rm d}\lambda=1$$ $\mu:=p\lambda$ $f\in\mathcal L^1(\mu)$ I want to minimize $$\Phi(q):=\int_{\left\{\:q\:>\:0\:\right\}}\frac{(pf)^2}q\:{\rm d}\lambda$$ over all $\mathcal E$ -measurable $q:E\to[0,\infty)$ subject to $$\int q\:{\rm d}\lambda=1.\tag1$$ I already know that the solution is proportional to $p|f|$ , but I want to verify this rigorously. I want to use he method of Lagrange multipliers . We should be able to rephrase the problem in the following way: We want to minimize a functional on a Banach space subject to the condition that the norm of the candidate is $1$ . We would clearly take the Banach space $\mathcal L^1(\mu)$ (note that $(1)$ is noting else than the norm of $q$ in this space). How do we need to proceed in detail? It's clear to me that it's sufficient to find a stationary point of the Lagrange function. It's then easy to show that the resulting candidate solution is a minimum (using the Cauchy-Schwarz inequality). Please take note of my related question: How can we compute the Fréchet derivative of $q\mapsto\int\frac{(pf)^2}q\:{\rm d}\lambda$? .","['measure-theory', 'lagrange-multiplier', 'lp-spaces', 'functional-analysis', 'optimization']"
3313520,How to show that this function is continuous?,"Let $\psi(x,y)$ be a continuous function in two real variables, and then define $$f(x) = \sup_{t \in [-x,x]} \psi(x,t)$$ It seems to me that the function $f$ should also be continuous for $x \geq 0$ , but I'm not sure how to prove it. Is this true and how would you prove it?","['continuity', 'analysis', 'real-analysis']"
3313634,What is the series $\sum_{n=1}^{\infty} \frac{e^{-n^2 x}}{n}$?,"Following Passare: How to compute $\sum 1/n^2$ by solving triangles I tried the following $$
\int_0^{\infty}\frac{e^{-nx}}{n^2} dx = \frac{1}{n^3}
$$ So we can write (with some help of Wolfram Alpha) $$
\sum_{n=1}^{\infty} \int_0^{\infty}\frac{e^{-nx}}{n^2} dx =  \int_0^{\infty} \sum_{n=1}^{\infty} \frac{e^{-nx}}{n^2} dx = \int_0^{\infty} Li_2(e^{-x}) dx = \zeta(3)
$$ where $Li_2$ is the https://en.wikipedia.org/wiki/Polylogarithm#Dilogarithm . But is also true that $$
\int_0^{\infty}\frac{e^{-n^2x}}{n} dx = \frac{1}{n^3}
$$ so that one can write $$
\sum_{n=1}^{\infty} \int_0^{\infty}\frac{e^{-n^2x}}{n} dx =  \int_0^{\infty} \sum_{n=1}^{\infty} \frac{e^{-n^2x}}{n} dx = \int_0^{\infty} ?? dx = \zeta(3)
$$ The problem here is the evaluation of the series $$
\sum_{n=1}^{\infty} \frac{e^{-n^2x}}{n} = ??
$$ which I (and also Wolfram Alpha) don't know how to evaluate. Is this series known in the literature and is there any way to evaluate it or express it somehow in terms of some special functions?","['riemann-zeta', 'polylogarithm', 'exponential-sum', 'sequences-and-series']"
3313638,Counterexample with finite index,"I'm on a three part question, and have got stuck on the last part. The full question is: Let $G$ be a group and $H$ a finite index subgroup of $G$ . (a) If $g \in G$ show that there is a smallest positive integer $k$ such that $g^{k} \in H.$ Show that $k$ divides every integer $m$ such that $g^{m} \in H$ . (b) If $H$ is normal in $G$ show that $k$ divides $[G:H]$ . (c) Produce a counterexample to the claim that for all subgroups $H$ we have $k$ dividing $[G:H]$ I'm working on part (c). From part (b), I can see that I need $H$ to not be a normal subgroup, but I'm having a hard time coming up with a counterexample. Any help would be appreciated.","['group-theory', 'abstract-algebra', 'examples-counterexamples']"
3313639,$s(t) = |\sum_{n=1}^{\infty} \int_{0}^{t} u_{n}(x) dx|^{2}$ is a polynomial,"Let $\{u_{n}\}_{n \in \mathbb{N}}$ be an orthonormal subset of $L^{2}[0,1]$ . Prove that the function $$s(t) =\left| \sum_{n=1}^{\infty} \int_{0}^{t} u_{n}(x) dx\right|^{2}$$ is a restriction of a polynomial by determinating such polynomial. Any help would be appreciated.","['hilbert-spaces', 'functional-analysis', 'analysis', 'real-analysis']"
3313701,"For a cordinate system $(U,x^1,\ldots , x^d)$ show that $[\partial / \partial x_i,\partial / \partial x_j]=0 $ on $U$.","I'm working through Warner's Foundations of Differentiable Geometry and stuck on this question. Let $(U,x^1,\ldots x^d)$ be a coordinate system on $M$ , show that $[\partial / \partial x_i,\partial /\partial x_j]=0 $ on $U$ . I'm confused on what this question is asking. Are we supposed to apply $[\partial / \partial x_i,\partial /\partial x_j]$ to an arbitrary function $f$ defined on $U$ and use that partial derivatives commute? Or since $\partial /\partial x_i$ is a basis for a vector field on $M$ should we interpret $[\partial / \partial x_i,\partial /\partial x_j]$ a vector field and show that is it is zero on $U$ . If $[\partial / \partial x_i,\partial /\partial x_j]$ is not a vector field could you explain what kind of object it is in your answer.","['smooth-manifolds', 'differential-geometry']"
3313716,"Subsets of $\{1,\cdots,n\}$ with max intersection $2$. [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question Consider a collection of $n$ different $8$ -element subsets of $\{1,\cdots,n\}$ . 
If for any $2$ subsets in our collection we have that the size of the intersection is no larger than $2$ we say that the collection is ""good"". Given $n$ , how many good collections are there?",['combinatorics']
3313725,How to get the days worked?,"I have this statement: It was calculated that $750$ meters of a ditch could be excavated in $10$ days. If $7$ workers made $350$ meters and later with $5$ assistants they
  finished the work in the fixed term, how many days did the assistants
  work? My attempt was: Workers | Meters | Days
   7       350m    x
   12      400m   10-x $1)$ More workers, less days: indirect proportion $2)$ More meters, more days: direct proportion From $1)$ $\frac{x}{10-x}= \frac{350}{400}$ , From $2)$ $7x=12(10-x) = \frac{x}{(10-x)} = \frac{12}{7}$ But, I cannot get $x$ from $1)$ or $2)$ independently, if not that, I must gather both information in a single equation. So my doubt is, What is the logic behind, to join the information from $1), 2)$ and get the result of $x$ ?",['algebra-precalculus']
3313765,what does the common difference of a sequence describe,"I am given the sequence 1, 7, 21, 43, 73, ... and can derive without any assumption about the nature of the sequence that the ultimate difference is 8 , I'm interested in understanding what this difference allows you to deduce about the original polynomial which generates this sequence; and whether it is possible to find this polynomial? I can see that 1, 7, 21, 43, 73, ... has a difference of 6, 14, 22, 30, ... which is generated by the arithmetic sequence 6 + 8(n-1) , but trying to rationalize how the difference of a sequence can then be non-constant ( 1, 7, 21, 43, 73 ) it doesn't really make sense. Can anyone shed some light on how to go about solving this intuitively?","['number-theory', 'sequences-and-series']"
3313768,Determining multiplicity of 1 as an eigenvalue for a certain matrix,"By Matlab, I know that the eigenvalues of the matrix $B^{-1}A$ are 2.457, 0.542, and 1 (multiplicity 3) where $A$ and $B$ are defined as: \begin{equation}
A=
\begin{pmatrix}
1 & 0 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 \\
0 & 0 & 2 & 1 & 1 \\
0 & 0 & 1 & 2 & 1 \\
0 & 0 & 1 & 1 & 2 \\
\end{pmatrix},
B=
\begin{pmatrix}
1 & 0 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 \\
0 & 0 & 1 & 0 & 0 \\
0 & 0 & 0 & 2 & 1 \\
0 & 0 & 0 & 1 & 2 \\
\end{pmatrix}
\end{equation} Similarly, the eigenvalues of the matrix $B^{-1}A$ are 4.56, 0.43, and 1 (multiplicity 4) where $A$ and $B$ are defined as: \begin{equation}
A=
\begin{pmatrix}
1 & 0 & 0 & 0 & 0 & 0\\
0 & 2 & 1 & 1 & 1 & 1 \\
0 & 1 & 2 & 1 & 1 & 1 \\
0 & 1 & 1 & 2 & 1 & 1\\
0 & 1 & 1 & 1 & 2 & 1\\
0 & 1 & 1 & 1 & 1 & 2\\
\end{pmatrix},
B=
\begin{pmatrix}
1 & 0 & 0 & 0 & 0 & 0\\
0 & 1 & 0 & 0 & 0 & 0\\
0 & 0 & 1 & 0 & 0 & 0\\
0 & 0 & 0 & 1 & 0 & 0\\
0 & 0 & 0 & 0 & 2 & 1\\
0 & 0 & 0 & 0 & 1 & 2\\
\end{pmatrix}
\end{equation} In general, given $n$ , the matrices are defined as follows: \begin{equation} 
A =
\begin{pmatrix}
I_{n-m_A} & 0 \\
0 & I_{m_A} + J_{m_A} \\
\end{pmatrix},
B =
\begin{pmatrix}
I_{n-m_B} & 0 \\
0 & I_{m_B} + J_{m_B} \\
\end{pmatrix},
\end{equation} where $m_A \ne m_B$ and they can be $1,...,n-1$ (so it can be that $m_A < m_B$ ). $J_m$ is a $m \times m$ matrix of ones. 
Is there any explanation to why the multiplicity of 1 as an eigenvalue is always $n-2$ where $n$ is the dimension of the matrices?","['matrices', 'eigenvalues-eigenvectors']"
3313811,"Why are these two definitions of a ""Subgroup Generated by $X$"" equivalent?","In previous readings, I have frequently seen the concept of the subgroup generated by set $X$ (otherwise denoted as $gp(X)$ ) explained as follows: "" $gp(X)$ is the subgroup that is generated from all possible finite compositions of the elements of $X$ and their inverses "" However, I came across a definition today that I have not previously seen. It reads as follows: "" let $gp(X)$ be defined as the intersection of all subgroups of $G$ containing $X$ "" Upon first glance, this seems fairly obvious...if a subgroup $H$ contains the elements that comprise the set $X$ , then by definition of ""subgroup"", $H$ clearly also contains the inverse elements of the elements belonging to set $X$ . Additionally, because $H$ is a subgroup, it clearly also contains the identity element. I see that a nice trick to ""pick out these elements"" is by imposing an intersection with another subgroup $J$ that also contains the set $X$ . In this way, subgroup $J$ and subgroup $H$ clearly both contain all elements of set $X$ , the inverses of the elements of set $X$ , and the identity. It seems like only two subgroups are necessary to pick out these elements...which inspires two questions: Why define this as ""intersection of all subgroups""? What happens if there is only one subgroup that contains $X$ ? It seems to me that the first defintion avoids these issues.","['group-theory', 'abstract-algebra']"
3313835,Notation for codomain,"Let $X, Y$ be sets, and $f : X \rightarrow Y$ a map. Is there a standard notation for the codomain of f? cod $f$ , maybe? 
I know that in category theory, specifically in Set there exists a function (of classes) from Mor( Set ) to Ob( Set ) that assigns the 'target' to each morphism, but that seems cubersome..","['notation', 'functions']"
3313861,Zero-dimensionality implies $\pi$- regularness,Let $R$ be a commutative ring with 1. An element $a$ in $R$ is said $\pi$ -regular if $a^n = a^nra^n$ for some $r \in R$ and a natural number $n$ . A ring $R$ is called $\pi$ -regular if  every element is $\pi$ -regular. Is any zero dimensional ring a $\pi$ -regular ring? Note: Zero dimensional= every prime ideal is maximal.,"['algebraic-geometry', 'abstract-algebra', 'commutative-algebra']"
3313865,Prove this matrix to be unitary,"This is a homework question so, hints are appreciated. But if someone is generous enough, to show the full calculation, I'd be quite grateful! Say a matrix B is anti-hermitian: $$\begin{bmatrix}
i & -1\\ 
1 & i
\end{bmatrix}$$ And I want to calculate the matrix exponential $e^{Bt}$ , where the exponential is a function of time. Now after I attempted my own calculation for $e^{Bt}$ , using Taylor series and Caley Hamilton theorem, I ended up with this: \begin{bmatrix}
\ \frac{e^{2it}+1}{2} & \frac{e^{2it}-1}{2i}\\ 
 \frac{1- e^{2it}}{2i} & \frac{e^{2it}+1}{2}
\end{bmatrix} But here's the problem, in theory if the exponent of a unitary operator is anti-hermitian, then the operator is unitary. But now that I have gotten the matrix representation of the matrix exponential, and I want to prove the above matrix to be unitary using the statement: $$U^{-1}=U^{\dagger}$$ I run into some problem. Can some just please check if my matrix exponential is correct or if I am missing something, that prevents me from proving $e^{Bt}$ as unitary using $U^{-1}=U^{\dagger}$ . 
Thanks a ton, in advance!","['unitary-matrices', 'matrix-exponential', 'matrices', 'linear-algebra', 'taylor-expansion']"
3313920,Who has the winning strategy for the game?,"My friend Mickey asked me to play the following game with him. The number $1$ is written on the whiteboard. Me and Mickey take turns to do the following, starting with me. If the number written on the board is $n$ , then replace it by $n+d\le2019$ where $d|n$ . The player who can not replace the number written on the whiteboard losses. But I always lose. Actually, does Mickey has a winning strategy? Any help is appreciated!","['game-theory', 'number-theory', 'combinatorial-number-theory']"
3314024,Differential on Lie group $SO(3)$,"Consider the decomposition of any rotation matrix $R\in SO(3)$ as $$ R=\exp(\theta_3 \hat{e}_3)\exp(\theta_1\hat e_1 + \theta_2 \hat e_2)$$ where the hat designates the hat operator ,
and the application $\phi$ that ""extracts"" the angles $(\theta_1,\theta_2,\theta_3)$ : \begin{align}
\phi: SO(3)&\longrightarrow \mathbb{R}^3 \\
 R &\longmapsto (\theta_1,\theta_2,\theta_3)
\end{align} Is it possible to derive a closed-form expression for $d\phi$ ? What I have done: I computed $d(\phi^{-1})$ : $$\phi^{-1}=\mathrm{comp}\circ \alpha$$ where $\mathrm{comp}$ is the product in $SO(3)$ and $$\alpha:(\theta_1,\theta_2,\theta_3)\longmapsto (\exp(\theta_3 \hat e_3),\exp(\theta_1\hat e_1 + \theta_2 \hat e_2))$$ I find, with $\Theta = (\theta_1,\theta_2,\theta_3)$ : \begin{align}d(\phi^{-1})(\Theta)(u)& = d(\mathrm{comp}(\alpha(\Theta))(d\alpha(\Theta)(u)) \\
& = \mathrm{Ad}\big(\mathrm{inv}\circ\exp(\theta_1\hat e_1 + \theta_2 \hat e_2)\big)(d\exp(\theta_3\hat e_3)(u)) + d\exp(\theta_1\hat e_1 + \theta_2 \hat e_2)(u)
\end{align} and then I thought of using the identity: $$d\phi(R)= \big( d(\phi^{-1})(\phi(R))\big)^{-1}$$ This provides a way of computing $d\phi(R)$ numerically. Any better idea?","['closed-form', 'lie-algebras', 'lie-groups', 'differential-geometry']"
3314044,"If $\phi : G \to G$ is a Lie group automorphism without fixed points, is $g^{-1}\phi(g)$ surjective?","If $G$ is a real connected Lie group and $\phi : G \to G$ is a Lie group automorphism without fixed points other than $e$ , does it follow that the map $\psi : g \mapsto g^{-1} \phi(g)$ surjective? Can we describe its inverse? Note that that $\psi$ is injective. ( Automorphism with no fixed points other than identity ) The example $G = \mathbb Z$ and $\phi(n) = -n$ shows that we need $G$ connected. Context: I was reading a computation in Iwaniec's Spectral Methods of Automorphic Forms , where the case of $G = N = \left\{\begin{pmatrix}1 & * \\ 0 & 1\end{pmatrix} \right\} \subset \mathrm{SL}_2(\mathbb R)$ and $\phi = \mathrm{Ad}_a$ with $a = \begin{pmatrix}y & 0 \\ 0 & y^{-1}\end{pmatrix}$ , $y > 1$ , occurs in a computation for the Selberg trace formula. The inverse of $\psi$ is easily computed as $\begin{pmatrix}1 & n \\ 0 & 1\end{pmatrix} \mapsto \begin{pmatrix}1 & n/(y^2 - 1) \\ 0 & 1\end{pmatrix}$ , but I want to understand this conceptually. Idea: in the example above we have, by Taylor expansion, $$
\psi^{-1}(n)
= \prod_{k = 1}^\infty \mathrm{Ad}_{a^{-k}}(n)
$$ Maybe in the general case, $\psi^{-1}(g) = \cdots \phi^{-3}(g) \phi^{-2}(g) \phi^{-1}(g)$ ? Provided the product converges?","['lie-groups', 'differential-geometry']"
3314083,How can I simplify $\sum_{i=1}^{n} \sin(x - y_i)$ to the form $Asin(x-y_0)$?,For example for $n=2$ the new phase $y_0$ is the average of $y_1$ and $y_2$ but this dowsn't seem to be true in general. And what about simplifying $\sum_{i=1}^{n} A_i sin(x - y_i)$ ? Analytically it's easy to see why we get one sine. But is there an elementary reasoning for this?,"['trigonometry', 'summation']"
3314100,Continuous extension of XOR,"The $\text{XOR}$ function is a function from $\{0,1\}^2$ to $\{0,1\}$ , defined as: $\text{XOR}(0,0)=\text{XOR}(1,1)=0$ $\text{XOR}(1,0)=\text{XOR}(0,1)=1$ I am interested in finding an extension of this function to $\mathbb{R}$ . To be more specific, I am looking for a function $f$ from $\mathbb{R}^2$ to $\mathbb{R}$ with the following properties (for all $x,y,z\in\mathbb{R}$ ): $f(x,y)=f(y,x)$ $f(x,0)=x$ $f(x,x)=0$ $f(x,f(y,z))=f(f(x,y),z)$ $f$ is continuous Does such a function exist? If yes, how do I construct it? If not, how do I prove so?","['functions', 'real-analysis']"
3314129,Inverse of a structured matrix of sines.,"Suppose I have a matrix $P$ defined by $$
P =\begin{pmatrix}
\sin(\frac{\pi}{n+1}) & \sin(\frac{2\pi}{n+1}) & \cdots & \sin(\frac{n\pi}{n+1}) \\
\sin(\frac{2\pi}{n+1}) & \sin(\frac{4\pi}{n+1}) & \cdots & \\
\vdots & & \ddots & \\
\sin(\frac{n\pi}{n+1}) & \cdots & & \sin(\frac{n^2\pi}{n+1})
\end{pmatrix} 
$$ and suppose I wish to find its inverse. I claim that $P^2 = \frac{n+1}{2} I_n$ and hence $P^{-1} = \frac{2}{n+1} P$ and indeed computing this in Matlab for a variety of $n$ it appears to be true, but I've been struggling to show this rigourously. I suspect I'm just very rusty with my trig manipulations but any help would be appreciated. So far, I have that $$ 
(P^2)_{kl} = \sum_{j=1}^n \sin(\frac{kj\pi}{n+1})\sin(\frac{lj\pi}{n+1})
$$ which looks somewhat similar to the stuff you get in fourier anyalysis where $\sin$ and $\cos$ form orthogonal polynomials, but I've been struggling to adapt it to this sum situation. From here I've been trying to use that $$ 
(P^2)_{kl} = \frac{1}{2}\sum_{j=1}^n \cos\left(\frac{(k-l)j}{n+1} \pi\right) - \cos\left(\frac{(k+l)j}{n+1} \pi\right)
$$ but I really haven't made much progress. Even the diagonal case where $k = l$ seems to not work out as immediately as I hoped, since I'm a bit lost on what to do with the second term. I suspect I am missing something obvious...","['trigonometric-series', 'orthogonal-polynomials', 'trigonometry']"
3314130,Doubt in a graph theory paper of Lovasz,"I am reading from the paper ""Product Dimension of Graphs"" by Lovasz, Nesetril and Pultr (available here ). I have a doubt in the proof of Lemma 4.2 which establishes that for a graphs $G$ with order $n\ge 5$ and $\Delta(G^c)=n-2$ the product dimension is at most $n-2$ . The authors start by letting $H=G^c$ . They let $a$ be the vertex of degree $\Delta (G^c)$ in $G^c$ . Now $a$ is not adjacent to all other vertices in $G^c$ for then $\Delta(G^c)$ would have been $n-1$ , which is against the hypothesis. So, there exists exactly one vertex $b$ such that $ab$ is not an edge in $G^c$ . Now I believe at this point there is a typographical error. The authors state: Denote by $H'$ resp. $H^*$ the subgraphs of $H$ spanned by $V(H)\setminus \{a,b\}$ . I believe this should be: Let $H'$ be the subgraph of $G^c$ induced by all the vertices except $a$ . Also let $H^*$ be the subgraph of $G^c$ induced by all the
  vertices except $a$ and $b$ . Next they consider three cases: Case A: $H^*$ has no edges. Case B: $H^*$ has edges and the largest degree vertex of $H^*$ has degree at most $n-3$ . Case C: $H^*$ has edges and the largest degree vertex of $H^*$ has degree equal to $n-2$ . In Case A, the authors state that ""obviously $\dim G\le n-2$ "". I do not understand this. Can someone explain?","['graph-theory', 'combinatorics']"
3314133,Etale iff Completions are Isomorphic,"I have a question aboutthe proof of proposition 4.3.26 from Liu's ""Algebraic Geometry and Arithmetic Curves"": Let $Y$ be a locally Noetherian scheme and $f:X \to Y$ a morphism of finite type. Fix a point $x$ and denote $y=f(x)$ . Assume that $O_{X,x}/m_x=k(x)=k(y)=O_{Y,y}/m_y$ coincide. The local ring morphism on stalks $f_x:O_{Y,y} \to O_{X,x}$ induces a morphism of completions $$\widehat{f}_x:\widehat{O}_{Y,y} \to \widehat{O}_{X,x}$$ where the completions are induced wrt to corresponding maximal ideals $m_x$ and $m_y$ . The proposition says that $f$ is etale in $x$ if and only if $\widehat{f}_x:\widehat{O}_{Y,y} \to \widehat{O}_{X,x}$ is an isomorphism. The "" $\Rightarrow$ "" I understand. Regarding the "" $\Leftarrow$ "" I don't understand the argument. Liu refers to Theorem 1.3.16 and Exercise 1.2.18. Recall etale means flat and unramified . Exercise 1.2.18 solves the flatness of $f_x$ : It says that if $B \to E$ is faithful flat then $A \to B$ is flat if and only if $A \to E$ is flat. Taking for $A \to B$ the morphism $f_x$ and for $E$ the completion we are done since completions of local rings are faithful flat. Recall unramified means that $k(y) \to k(x)$ is separable and $m_yO_{X,x}=m_x$ . QUESTION:
By assumption $k(y) = k(x)$ so the first one is ok but what about $m_yO_{X,x}=m_x$ ? My considerations:Since $\widehat{f}_x$ is an iso we deduce that $\widehat{m_x} = \widehat{m_y}\widehat{O}_{X,x}$ as completions $O_{Y,y}/m_y \cong \widehat{O}_{Y,y}/\widehat{m_y} \to  \widehat{O}_{X,x}/\widehat{m_x} \cong O_{X,x}/m_x$ are surjective. for every $k$ there exist a $d_k$ with $ g(m_y)^{d_k} \subset m_x ^k$ and vice versa (so same topology) But I don't see how to conclude that $m_yO_{X,x}=m_x$ .","['formal-completions', 'algebraic-geometry', 'schemes', 'commutative-algebra']"
3314213,Can the Cauchy product of divergent series with itself be convergent?,"For series $\sum a_n$ and $\sum b_n$ their Cauchy product is the series $\sum c_n$ where $$
c_n = a_0b_n+a_1b_{n-1}+\ldots+a_nb_0.
$$ Does there exist a sequence $\sum a_n$ such that: $\sum a_n$ is divergent? The Cauchy product of $ \sum a_n$ and $\sum a_n$ is convergent?","['divergent-series', 'sequences-and-series', 'real-analysis']"
3314255,How many negative eigenvalues can $AB + BA$ have when $A$ and $B$ are symmetric positive definite?,"Let $A, B \in \mathbb R^{n\times n}$ symmetric positive definite. Clearly, any eigenvector $v$ of either $A$ or $B$ is such that (taking for example a nonzero eigenvector of $A$ with eigenvalue $\lambda$ ) $$
v^T(AB + BA) v = 2 \lambda (v^TBv) > 0,
$$ so $AB + BA$ has at least one positive eigenvalue. From this answer , we conclude that, in dimension 2, $AB + BA$ has at most one negative eigenvalue. What is the situation when $n$ is general? Can we have more than $\lfloor n/2\rfloor$ negative eigenvalues? (the value $\lfloor n/2\rfloor$ can be obtained by taking block diagonal matrices with 2x2 blocks corresponding to the 2-dimensional example.)","['matrices', 'linear-algebra']"
3314258,Finding maximum value,"The question is : Let $a,$$b,$$c$ be positive real numbers such that $ \frac{a}{1+b} + \frac{b}{1+c} + \frac{c}{1+a} =1$ Then find the maximum value of $abc$ . I just blindly simplified the equation and  wrote $abc$ on LHS and other terms on RHS so I concluded if I could find the maximum value of RHS that would help but i am unable to do that also .please tell what would be the correct approach and method for the question .This question requires a subjective approach (not trial and error).","['inequality', 'systems-of-equations', 'maxima-minima', 'linear-algebra', 'algebra-precalculus']"
3314271,When does a quadratic form being equal to zero implies the underlying matrix is equal to zero?,"Let $X_1,\dots,X_n \in\mathbb{R}^m$ be vectors; and $M\in\mathbb{R}^{m\times m}$ is a symmetric matrix. My question is as follows. Is there any condition $\mathcal{C}$ on $X_1,\dots,X_n$ such that, under $\mathcal{C}$ , it holds: $$
X_i^T M X_i = 0 \iff M=0,
$$ and in the absence of $\mathcal{C}$ , $X_i^T MX_i = 0\iff M=0$ fails, that is, there is a matrix $M\neq 0$ such that $X_i^T M X_i= 0$ but $M\neq 0$ . For instance, if ${\rm span}(X_iX_i^T)$ is the set of all ( $m\times m$ ) symmetric matrices, then one can establish $X_i^T M X_i = 0\iff M=0$ .","['matrices', 'linear-algebra', 'quadratic-forms']"
3314311,Noisy communication: threshold detecting,"I would like to check if my solution to a standard problem in Bayesian statistics is correct. We study a simple noisy communication channel. Suppose that $\mathsf{X}$ is a binary signal that takes value $-1$ and $1$ with equal probability. The received signal is $\mathsf{Y} = \mathsf{X} + \mathsf{N}$ , where $\mathsf{N}$ is a standard normal, independent of $\mathsf{X}$ . The decoder receives the value of $\mathsf{Y}$ and decides whether $\mathsf{X}$ was $1$ or $-1$ using the following decoding rule: $\mathsf{X}$ was $1$ if and only if: $$\mathbb{P}(\mathsf{X} =1 | \mathsf{Y} = y) > 2 \cdot \mathbb{P}(\mathsf{X} =-1 | \mathsf{Y} = y) .$$ It turns out that the decoding rule can be expressed in the form: decide in favour of $1$ if and only if $\mathsf{Y} > t$ for some threshold $t$ . Find the threshold. My solution was to apply the mixed Bayes rule (e.g. $\mathbb{P}(\mathsf{X} =1 | \mathsf{Y}= y) =\frac{f_{\mathsf{Y}|x=1}(y) \cdot \mathbb{P}(\mathsf{X} =1)}{f_{\mathsf{Y}}(y)} $ )  to both sides and solve the inequality in the variable $y$ . After some computations, this led me to the threshold $$t=\frac{\ln(2)}{2}.$$ Does this solution make any sense?","['statistics', 'bayesian', 'probability']"
3314324,"Exemples of applications of ""groupoidification"" to linear algebra","I just read Baez's very nice blog notes about groupoidification, and around the beginning, he states : ""From all this, you should begin to vaguely see that starting from any sort of incidence geometry, we should be able to get a bunch of matrices. Facts about incidence geometry will give facts about linear algebra! 'Groupoidification' is an attempt to reverse-engineer this process. We will discover that lots of famous facts about linear algebra are secretly facts about incidence geometry!"" There are hints of how this could happen in said notes but (as far as I can see) no concrete example. What would be some nice (easy to begin with) examples of such a phenomenon ? I'm not looking for particularly hard or even new facts about linear algebra that a groupoidification could unravel (although if there are, I would be very glad to see them); but just some result(s) that appear more naturally, more clearly, or on which another point of view is given via this ""groupoidification"" method. So the perfect story would be:  ""I have this theorem of linear algebra, I know how to prove it but if I were to prove it the usual way there would be a whole lot of annoying mess and non-motivated computations; but there is a nice way to prove it by viewing the situation as some degroupoidification of a problem I know how to handle"". Something that would also be interesting (which is not so different) would be : ""Oh I have this fact about incidence geometry/spans of groupoids that's quite nice to prove; and if I translate it into linear algebraic terms I get something interesting, that I might have known but the proof of which is not very enlightening"". If there are a lot of details for your answer and you don't want to write them all down, it's not a problem, I'm fine with just ideas, as long as there's a concrete result in the end.","['groupoids', 'categorification', 'geometry', 'linear-algebra', 'soft-question']"
3314333,"How many possibilities exist to arrange ${1,....,n}$ so, that any number $k$ may only be placed, if $k-1$ or $k+1$ has already been placed?","I'm doing some exercises in preparation for my exam in combinatorics and found the following task: How many possibilities exist to arrange ${1,....,n}$ such that any number $k$ (apart from the first one to be placed) may only be placed, if $k-1$ or $k+1$ has already been placed? You can start with any number. I tried some examples and found the following number of possibilities: $1$ for $n=1$ , $2$ for $n=2$ , $4$ for $n=3$ , namely: $(1,2,3),(2,3,1),(2,1,3),(3,2,1)$ and $10$ arrangements for $n=4$ . Obviously, $n!$ would be the maximum and if I start with $1$ or $n$ , there is only one way to proceed with the arrangement. Any help is appreciated.","['combinatorics', 'discrete-mathematics']"
3314350,How impure can an impure subgroup be?,"A subgroup $H$ of an abelian group $G$ is called pure if $nH=nG\cap H$ for all $n$ . We always have $nH\subset nG\cap H$ , so if $H$ is impure then $nH$ is a proper subgroup of $nG\cap H$ for some $n$ . Is  there an abelian group $G$ , a subgroup $H$ , and an $n$ , such that $H\cap nG$ has finite index in $G$ , but $nH$ has infinite index?","['group-theory', 'abelian-groups']"
3314378,Solve the following equation: $\sin x \cos x = \frac{1}{2}$,"I am required to solve the following equation: $$\sin x \cos x = \frac{1}{2}$$ My attempt: Rewriting $\cos x$ $$\sin x \sqrt{1 - \sin^2 x} = \frac{1}{2}$$ Squaring both sides $$\bigl(\sin x \sqrt{1 - \sin^2 x}\bigr)^2 = \bigl(\frac{1}{2}\bigr)^2$$ $$\sin^2 x (1 - \sin^2 x) = \frac{1}{4}$$ Expanding left side and multiplying both sides by 4 $$\sin^2 x - \sin^4 x = \frac{1}{4}$$ $$4\sin^2 x - 4\sin^4 x = 1$$ $$4\sin^2 x - 4\sin^4 x -1 = 0$$ Reordering left side $$- 4\sin^4 x + 4\sin^2 x  -1 = 0$$ $$4\sin^4 x - 4\sin^2 x  + 1 = 0$$ Expression above can be factored as $$(2\sin^2 x - 1)(2\sin^2 x - 1) = 0$$ $$(2\sin^2 x - 1)^2 = 0$$ It follows that $$2\sin^2 x - 1 = 0 $$ $$\sin^2 x = \frac{1}{2} $$ $$\sin x = ± \frac{1}{\sqrt{2}} $$ So the resulting angles are: $45^{\circ},135^{\circ},225^{\circ},315^{\circ}$ Is my solution correct? The reason why I am asking is, the author of the book used different method, and the end result he got was: $$\sin2x = 1$$ So $2x = \sin^{-1}(1) = 90^{\circ},450$ , and thus $x = 45^{\circ},225^{\circ}$","['trigonometry', 'proof-verification']"
3314432,"Show $\int\frac{f(u+\varepsilon v)-f(u)}\varepsilon\:{\rm d}\mu\xrightarrow{\varepsilon\to0}\int f'(u)v\:{\rm d}\mu$ for a large class of $f,u,v$","Let $(\Omega,\mathcal A,\mu)$ be a measure space. I want to show that $$\int\frac{g(u+tv)-g(u)}t\:{\rm d}\mu\xrightarrow{t\to0}\int g'(u)v\:{\rm d}\mu\tag1$$ for a preferably large class of differentiable $g:\mathbb R\to\mathbb R$ and $\mathcal E$ -measurable $u,v:\Omega\to\mathbb R$ . Without any further assumption, we see that $$g(u(\omega)+tv(\omega))-f(u(\omega))=\int_0^tf'(u(\omega)+sv(\omega))v(\omega)\:{\rm d}s\tag2$$ for all $\omega\in\Omega$ and $t\in\mathbb R$ and $$\frac{f(u(\omega)+tv(\omega))-f(u(\omega))}t\xrightarrow{t\to0}f'(u(\omega))v(\omega)\tag3$$ for all $\omega\in\Omega$ . So, all we need to conclude is to find conditions under which the integrals in $(1)$ are well-defined and Lebesgue's dominated convergence theorem (or a theorem of that kind) is applicable. We may note that if $(t_n)_{n\in\mathbb N}\subseteq\mathbb R\setminus\{0\}$ with $t_n\xrightarrow{n\to\infty}0$ , then (by the mean value theorem) there is a $x_n(\omega)$ between $u(\omega)$ and $u(\omega)+t_nv(\omega)$ with $$\frac{g(u(\omega)+t_nv(\omega))-g(u(\omega))}{t_n}=g'(x_n(\omega))v(\omega)\tag4$$ for all $\omega\in\Omega$ and $n\in\mathbb N$ . So, some kind of linear growth condition on $g'$ (i.e. $|g'(x)|\le c(1+|x|)$ for all $x\in\mathbb R$ for some $c\ge0$ ) might be feasible.","['gateaux-derivative', 'measure-theory', 'lp-spaces', 'functional-analysis']"
3314436,"Showing $\langle a,p,q\mid p^{-1}ap=a^2, q^{-1}aq=a^2\rangle$ is non-hopfian (from first principles).","According to a search on Approach0, this question is new to MSE. Motivation for Study: I'm doing some light reading of some notes by Miller on combinatorial group theory. Hopfian groups have just been defined. Whilst I've seen the term used countless times before now, I have not yet once played with it. So here goes . . . The Details: The following is the definition I'm working with. Definition: A group $G$ is hopfian if whenever $G/N\cong G$ , we have that $N$ is the trivial group. Lemma: Any group $G$ is hopfian iff every epimorphism $\alpha: G\to G$ is an automorphism. The proof of this Lemma seems elementary to me, so, with a few qualms, I'll leave it out. The Question: Question: (G. Higman) Show that the group $H$ with presentation $$\langle a,p,q\mid p^{-1}ap=a^2, q^{-1}aq=a^2\rangle$$ is non-hopfian. For extra credit to those that answer (but no promised bounty): Complete the exercise from first principles , please; that is, without any fancy footwork, so as to make clear the concept of (not) being hopfian. My Attempt: My goal is to exhibit an epimorphism $\psi: G\to G$ that is not an automorphism. Define $\psi$ by $$\begin{align}
p &\mapsto p,\\
q &\mapsto q,\\
a &\mapsto a^2.
\end{align}$$ Would this work? I'm not sure of whether it's an epimorphism, let alone not an automorphism. I have $$\psi(p)\psi(q)=pq\stackrel{?}{=}\psi(pq)$$ (because $\psi$ is defined on the generators, right? So the same must be for the $qp$ case; the $\psi(a^2)=\psi(a)\psi(a)$ case is trivial). Moreover, I have, since $a^2p=pa$ by the first relation, that $$\psi(a)\psi(p)=a^2p=pa\stackrel{?}{=}\psi(ap);$$ the $\psi(aq)$ bit is similar. What I'm struggling with is $\psi(p)\psi(a)=pa^2$ and so on. Please help :) Disclaimer: I'm in hospital at the moment and so I'm on a break from my PhD. (I've been here a month now.) The above is just for fun and has little if anything at all, a priori , to do with my research.","['combinatorial-group-theory', 'group-presentation', 'group-theory', 'hopfian']"
3314452,Is there a closed form solution to the matrix differential equation $\dot X=AX+XA^T - K$?,"Is there a closed form solution the matrix differential equation $\dot X = AX + XA^T - K $ for example when $A = \begin{bmatrix} 0 & 1 \\ 0 & 0 \end{bmatrix}$ and $K = \begin{bmatrix} 0 & 0 \\ 0 & 1 \end{bmatrix}$ In general $A$ is square and $K$ is positive semi-definite. As far as I understand the equation: $\dot X = AX + XA^T$ has the closed form solution $X(t) = e^{At}Ce^{tA^T}$ Can this be extended to $\dot X = AX + XA^T - K $ ? These are similar questions, but do not answer the closed form solution question: On the solution of one matrix differential equation Solution of differential lyapunov equation","['matrices', 'matrix-equations', 'ordinary-differential-equations', 'dynamical-systems']"
3314459,Largest set of equidistant points in $\mathbb{R}^n$ under non-Euclidean norms,"I posed this question in a Facebook group for math problems: What is the size of the largest set $S \subset \mathbb{R}^n$ for which there exists some norm $||\cdot||: \mathbb{R}^n \to \mathbb{R}_{\geq 0}$ on $\mathbb{R}^n$ (as a vector space over $\mathbb{R}$ ) such that $||p - q||$ has the same value for all distinct $p, q \in S$ ? Under the Euclidean norm, the largest such sets are the $n+1$ vertices of a regular $n$ -dimensional simplex. Other norms allow larger sets; the best result I know is the $2^n$ vertices of the unit hypercube under the uniform norm $||(x_1, \ldots, x_n)||_\infty = \max_{1 \leq i \leq n} |x_i|.$ Benjamin Gunby, a math Ph.D. student at Harvard, has proved an upper bound of $3^n$ with the following argument (paraphrased): Let $||\cdot||$ be a norm. For $p \in \mathbb{R}^n$ and $r > 0$ , let $B(p, r) = \{ q \in \mathbb{R}^n: ||q - p|| < r\}$ be the open ball with center $p$ and radius $r$ . Let $V$ be the volume of a ball of radius $1$ ; the volume of a ball of radius $r$ is thus $r^n V$ . Let $p_1, \ldots, p_k$ be $k$ points in $\mathbb{R}^n$ such that the distance between any two distinct points is $2$ . By the triangle inequality, the balls $B(p_i, 1)$ are pairwise disjoint and contained in $B(p_1, 3)$ . Thus, $\operatorname{Vol} \left(\bigcup_{i=1}^k B(p_i, 1)\right) = kV \leq \operatorname{Vol} B(p_1, 3) = 3^n V$ , so $k \leq 3^n$ . Can either bound be improved upon? As a final note, $\mathbb{Q}^n$ admits arbitrarily large finite sets with all points equidistant, such as $\{1, \ldots, p-1\}^n$ under the $p$ -adic uniform norm $||(q_1, \ldots, q_n)|| = \max_{1 \leq i \leq n} ||q_i||_p$ , where $p$ is an arbitrary prime. (Volume is not a meaningful concept in $\mathbb{Q}^n$ under $p$ -adic norms, so the argument for the upper bound does not apply.)","['normed-spaces', 'geometry']"
3314462,"The field of fractions of $\mathbb{Z}[[X]]$ and $\mathbb{Q}[[X]]$, the power series rings, are different.","It is not hard to see that the field of fractions of $\mathbb{Z}[X]$ is the same as the field of fractions of $\mathbb{Q}[X]$ ; so I wonder if the same is true for the respective power series rings. My attempt: Let $p(x) \in \mathbb{Z}[[X]]$ such that its constant term is nonzero. In $\mathbb{Q}[[X]]$ , $p(x)$ is a unit; consequently, $p(x)/1$ is an element of the field of fraction of $\mathbb{Q}[[X]]$ . On the other hand, $p(x)$ is not a unit of the integral domain $\mathbb{Z}[[X]]$ . Then $p(x)/1$ is not an element of the field of fractions of $\mathbb{Z}[X]$ . Am I right? Thanks in advance!","['field-theory', 'ring-theory', 'abstract-algebra', 'formal-power-series']"
3314511,Simple combinatorics and probability theory related question,"5 apples are randomly distributed to 4 boxes. We need to find probability that there are 2 boxes with 2 apples, 1 box with 1 apple and 1 empty box. I'm getting the correct answer with $\frac{\frac{5!}{2!2!1!0!} * 4 * 3}{4^5} = 0.3515625$ (anyway, the answer is said to be 0.35, but I think it is a matter of rounding). But I don't understand why there are $4^5$ elementary events in total.
Firstly, I thought It should be $(\!\!\binom{4}{5}\!\!)$ - number of combinations with repetitions, but I couldn't get the proper answer. Isn't approach with $(\!\!\binom{4}{5}\!\!)$ elementary events more correct? Apples don't seem distinct to me - that's the reason. 
Or, may be, we can solve this problem with sample space in which apples are not distinct?","['elementary-probability', 'combinatorics']"
3314533,$L^p$ inequalities,"I just wonder if someone might give a hint. I've thought to apply Minkowski inequality, but I couldn't find out the way. Given $2 \leq p<\infty$ . Show that for any real-valued functions $f,g \in L^p(\mathbb{R})$ , the following holds: \begin{align*}
2 \left( \left\|\frac{f}{2} \right\|_{L^p}^p+  \left\|\frac{g}{2} \right\|_{L^p}^p\right)\leq  \left\|\frac{f-g}{2} \right\|_{L^p}^p+ \left\|\frac{f+g}{2} \right\|_{L^p}^p\leq \frac{1}{2}\left(\|f\|_{L^p}^p+\|g\|_{L^p}^p \right).
\end{align*} Proof: For the  right hand side I realized the following: \begin{align*}
  \left\|\frac{f-g}{2} \right\|_{L^p}^p+ \left\|\frac{f+g}{2} \right\|_{L^p}^p &\leq   \frac{1}{2^p}(\|f\|_{L^p}^p+\|g\|_{L^p}^p+\|f\|_{L^p}^p+\|g\|_{L^p}^p ) \quad \textrm{ by Minkowski inequality} \\
  &=\frac{1}{2^{p-1}}(\|f\|_{L^p}^p+\|g\|_{L^p}^p) \leq \frac{1}{2}(\|f\|_{L^p}^p+\|g\|_{L^p}^p).
\end{align*} For the left  hand side,  we can observe that $$
f=\frac{f+g}{2}+\frac{f-g}{2}  \quad \textrm{ and } \quad g=\frac{g+f}{2}-\frac{f-g}{2}. 
$$ Hence, \begin{align*}
 \left\|\frac{\frac{f+g}{2}+\frac{f-g}{2}}{2} \right\|_{L^p}^p+  \left\|\frac{\frac{f+g}{2}-\frac{f-g}{2}}{2} \right\|_{L^p}^p&\leq \frac{2}{2^p}\left( \left\|\frac{f-g}{2} \right\|_{L^p}^p+ \left\|\frac{f+g}{2} \right\|_{L^p}^p \right) \quad \textrm{by Minkowski inequality} \\ 
 & \leq \frac{1}{2}\left( \left\|\frac{f-g}{2} \right\|_{L^p}^p+ \left\|\frac{f+g}{2} \right\|_{L^p}^p\right)
\end{align*} which is equivalent to $$
2 \left( \left\|\frac{f}{2} \right\|_{L^p}^p+  \left\|\frac{g}{2} \right\|_{L^p}^p\right)\leq  \left\|\frac{f-g}{2} \right\|_{L^p}^p+ \left\|\frac{f+g}{2} \right\|_{L^p}^p.
$$","['measure-theory', 'lp-spaces', 'functional-analysis']"
3314591,Which mathematical subjects simplify another mathematical subject by removing exceptions?,"I have often heard it said that complex analysis is in some ways simpler than real analysis (because every differentiable function can be differentiated as many times as we want, and always has a power series expansion). Similarly, many theorems in projective geometry are simpler than their equivalents in euclidean geometry because one doesn't have to deal with the exceptional case of non-intersecting lines. Are there any other well-known pairs of mathematical topics that bear a similar relationship, where theorems are greatly simplified by the removal of an exceptional case?","['complex-analysis', 'projective-geometry']"
3314608,Square root of the square of the cosine: absolute value or not,"Given the following function we find its derivative: $$a) \frac{d}{dx}\left[\arcsin(\sin(x))\right] = \frac{1}{\sqrt{1 - \sin^2(x)}}\cos(x) = \frac{\cos(x)}{\sqrt{\cos^2(x)}} = \frac{\cos(x)}{|\cos(x)|}$$ It is important to notice that in the last step the square root of the square resulted in the absolute value, which makes sense if we check the graph of $\arcsin(\sin(x))$ . Now, the we try to find another integral: $$b) \int \frac{dx}{\sqrt{(x - a)(b - x)}}$$ Here we use the substitution $$ x - a = (b - a)\sin^2(u), dx = 2(b - a)\sin(u)\cos(u)du$$ I do not know why this particular substitution was chosen, except that it is hinted at by Apostol. So, with this substitution it is easy to find: $$\int \frac{dx}{\sqrt{(x - a)(b - x)}} = \frac{2(b - a)\sin(u)\cos(u)}{\sqrt{(b - a)\sin^2(u)(b - a)\cos^2(u)}}du = \frac{2(b - a)}{|b - a|}\int \frac{\sin(u)\cos(u)}{\sin(u)\cos(u)}du$$ which is then trivial. It is important that here $\sqrt{\sin^2(x)\cos^2(x)} = \sin(x)\cos(x)$ unlike in (a), and $\sin/\cos$ themselves are pulled out, not their absolute values! What is the difference in (a), and (b)? I do not understand why in (b) we are allowed to pull out non-absolute value $\sqrt{\cos^2(x)\sin^2(x)} = \sin(x)\cos(x)$ , while it should be like in (a).","['integration', 'calculus', 'trigonometry', 'absolute-value']"
3314629,Compute $\sum_{n=1}^\infty\frac{H_n^2H_n^{(2)}}{n^3}$,"How to prove $$\sum_{n=1}^\infty\frac{H_n^2H_n^{(2)}}{n^3}=\frac{19}{2}\zeta(3)\zeta(4)-2\zeta(2)\zeta(5)-7\zeta(7)\ ?$$ where $H_n^{(p)}=1+\frac1{2^p}+\cdots+\frac1{n^p}$ is the $n$ th generalized harmonic number of order $p$ . This series is very advanced and can be found evaluated in the book (Almost) Impossible Integrals, Sums and Series page 300 using only series manipulations, but luckily I was able to evaluate it using only integration, some harmonic identities and results of easy Euler sums. Can we prove the equality above in different methods besides series manipulation and the idea of my solution below? All approaches are highly appreciated. Solution is posted in the answer section. Thanks","['integration', 'harmonic-numbers', 'calculus', 'sequences-and-series', 'riemann-zeta']"
