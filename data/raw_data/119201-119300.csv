question_id,title,body,tags
1776324,How to find the domain of this function?,"f(x)= $\frac{(\sqrt{x}-\sqrt{x-1} )}{( \sqrt{x}+\sqrt{x-1} )}\;$ first off $\sqrt{x}$ is defined for: $$x > 0                   \tag{1}$$ and  $\sqrt{x-1}$ is defined for: $$x \ge 1                 \tag{2}$$ from $(1)$ and $(2)$, we get domain of $f(x)$ should be $\{x | x\ge 1\}$ We found the domains of elementary functions contained in $f(x)$ and intersected them to find the domain of $f(x)$. but putting $x = 0$, we get $$f(0)= -1$$ why this solution was not contained in the above mentioned solution? I always find the domains of composite functions by this way, How can I be sure that some points, like $(0,-1)$ in above problem, are still not included in the solution?","['algebra-precalculus', 'function-and-relation-composition', 'functions']"
1776369,$F(h)=\int_0^1{h\left\lvert f(x+h)-f(x) \right\rvert}dx$ has derivative at 0,"Let $f$ be a Riemann integrable function defined on $[-2,2]$. Define a function
  $F:(-1,1)\to \Bbb{R}$ by $$F(h)=\int_0^1{h\left\lvert f(x+h)-f(x) \right\rvert}dx$$
  Show that the derivative $F'(0)$ exists. I have tried to use the fundamental theorem of calculus after some change of variables, but it doesn't seem to work since there is no relation between $h$ and $x$. Then I tried to prove by definition: proving the following limit exists
$$\lim_{h\to 0}\frac{F(h)-F(0)}h=\lim_{h\to 0}\int_0^1{\left\lvert f(x+h)-f(x) \right\rvert}dx$$
I guess the limit is $0$. But I don't know how to prove it. Could you please give me some hints? Thank you. Edit: Well, after some trying, I think I can do it like this (a rough idea):
$$\left\lvert f(x+h)-f(x) \right\rvert\le \underset{P_h}{\sup f}-\underset{P_h}{\inf f}$$ where $P_h$ is a partition of $[-2,2]$ s.t. it has some relation to restrict the $\left\lvert f(x+h)-f(x) \right\rvert$ to be small enough. I think this is the right approach, how can I change it to a rigorous argument?","['derivatives', 'real-analysis', 'integration']"
1776412,Cannot Find Mistake In Lagrange Multipliers Problem,"I am working on a problem asking me to use the method of constrained extrema to find the global maximum and minimum for the following functions: $$f(x,y) = xy$$ constrained to  $$g(x,y) = 4x^2 + 2xy + y^2 - 4$$ So far I have done the calculations and solved the problem and have come up with an answer that does not make sense however I cannot see where I may have made a calculation error. The first thing I did was find the gradient of both f(x,y) and g(x,y) and equate them to get the following result: $$ y = 8x\lambda + 2y\lambda$$
$$ x = 2x\lambda + 2y\lambda$$ I multiplied the first equation by x and the second equation by y then divided both by lambda to get the following: $$ \frac{xy}{\lambda} = 8x^2 + 2xy$$
$$ \frac{xy}{\lambda} = 2xy + 2y^2$$ As the left hand side of both equations are equal I produced the following: $$ 8x^2 + 2xy = 2xy + 2y^2$$ I then simplified this and did the algebra to come up with a solution y = 2x which I then substituted back into g(x,y) and got the solution $$ x = \pm \frac{2}{\sqrt{12}}$$ And I believe this result is incorrect as when you plug these values into f(x,y) you get the same answer of one third for both values. This must be incorrect as one of these values should be a maximum and the other a minimum as asked in the question. Thank you, Michael","['multivariable-calculus', 'lagrange-multiplier']"
1776430,Solve the Following Differential Equation: $y'''+y''=y'+y$,"I am trying to solve the following differential equation: $y'''+y''=y'+y$ My attempt $y'''+y''=y'+y \Leftrightarrow y'''+y''-y'-y = 0 $ I'm trying to find y in the form: $y(x) = e^{\lambda x }$ $y'''=\lambda^{3}e^{\lambda x}$ $y''=\lambda^2e^{\lambda x}$ $y' = \lambda e^{\lambda x}$ $y=e^{\lambda x}$ Therefore, $y'''+y''-y'-y = 0  \Leftrightarrow (\lambda^3+\lambda^2-\lambda-1)e^{\lambda x}$ Hence, $y(x) = e^{\lambda x}$ is a solution of $y'''+y''-y'-y = 0 $ iff $\lambda$ is a root of the characteristic equation. The characteristic equation $x(\lambda)= \lambda^3+\lambda^2-\lambda-1 = (x-1)(x+1)^2= 0$ Therefore $\lambda_1 = 1; \lambda_2 = -1$ ; Hence $y(x) = c_1e^x+c_2e^{-x}$ How do I find $c_1$ and $c_2$ knowing that my initial conditions are $y(0)=y'(0)=0, y''(o) = 1$ edit According to the comments: $y(x) = c_1e^x+c_2e^{-x}+c_3xe^{-x}$ . Why do we add $c_3xe^{-x}$ and not simply $c_3e^{-x}$ ? Also,do we have to find those constants or can we leave $c_1$ $c_2$ and $c_3$ in the final answer?","['ordinary-differential-equations', 'analysis']"
1776484,Is the space of $\mathbb{R}\to\mathbb{R}$ more huge than the space of all discrete functions?,"Assume that we have some general discrete function ${0,1,2,....n}\to\mathbb{R}$. For each number I have a real value. Let's infinite increase number $n$ (which is integer value), to approximate $\mathbb{R}\to\mathbb{R}$ function. As I understand it is only approximation even in limit, isn't it? Even if  I cover all integer values in the limit is cool, but we still have that $\mathbb{N}\ne\mathbb{R}$ ( Cantor's Diagonal argument ) So the space of $\mathbb{R}\to\mathbb{R}$ is more huge then the space of all discrete functions? Isn't it? (p.s. my background: I'm not familiar with functional-analysis)","['functional-analysis', 'functions']"
1776507,Evaluating the rational integral $\int \frac{x^2+3}{x^6(x^2+1)}dx $,Evaluate $$\int \frac{x^2+3}{x^6(x^2+1)}dx .$$ I am unable to break into partial fractions so I don't think it is the way to go. Neither is $x=\tan \theta$ substitution. Please give some hints. Thanks.,"['partial-fractions', 'calculus', 'indefinite-integrals', 'integration', 'rational-functions']"
1776528,Background for reading Atiyah's first paper on the twisted cubic,"What should an undergraduate student need to know before being able to read Michael Atiyah's A Note on the Tangents of a Twisted Cubic ? Most of the words in the paper look foreign to me, but I'm very intrigued by the objects involved (Veronese surface, twisted cubic, rational normal cubic). Furthermore, the geometry involved looks very synthetic, the paper doesn't use any abstract algebra at all. The arguments look very much like the proofs in high school Euclidean geometry. Are there any books which teach this kind of geometry? Preferably, the books should require as few prerequisites as possible (undergraduate linear algebra should be fine, but if it doesn't, then all the better), and it should also contain nice pictures, but I suspect that older geometry books lack pretty pictures.","['projective-geometry', 'algebraic-geometry']"
1776586,Is every discrete martingale a time-changed simple random walk?,"While going through the book by Revuz and Yor titled 'Continuous Martingales and Brownian Motion', I came accross the notion of time change. In a nutshell, if X is a stochastic process and C is an (a.s.) increasing process that is non-negative, then under some mild regularity conditions on X, one can define the time-changed process $\hat{X}$ defined by 
$$
\hat{X}_t(\omega):=X_{C_t(\omega)}(\omega), \ \omega\in\Omega.
$$
The book does this in continuous time and one of the main results is the Dambis, Dubins-Schwarz theorem which says that any continuous local martingale vanishing at 0 is eual to a time-changed Brownian Motion. This got me thinking about whether there is an analogous result in discrete time. Specifically, is it true that every discrete martingale is a time-changed simple random walk?","['random-walk', 'probability-theory', 'martingales']"
1776602,Stuck : Using inverses to solve linear congruences?,"Question : What are the solutions of the linear congruence 3x ≡ 4 (mod 7)? Step 1 - We know that −2 is an inverse of 3 modulo 7. Step 2 - Multiplying both sides of the congruence by −2 shows that −2·3x ≡−2·4(mod7). Step 3 - Because −6 ≡ 1 (mod 7) - Equation 1 and −8 ≡ 6 (mod 7) - Equation 2 it follows that if x is a solution, then x ≡ −8 ≡ 6 (mod 7). In Step 3, 
I am unable to understand how Equation 1 and Equation 2 lead to the statement x ≡ −8 ≡ 6 (mod 7). Here are the conclusions I was able to derive from these facts, -6 mod 7 = 1 mod 7 -8 mod 7 = 6 mod 7 (-1) is the inverse of 6 modulo 7 It'd be great if you can help me figure out what other conclusion I'm missing.","['discrete-mathematics', 'elementary-number-theory']"
1776669,How to differentiate this fraction $\frac{2}{x^2+3^3}$?,$\frac{2}{(x^2+3)^3}$. I have ${dy}/{dx}$ x 2 x ${x^2+3^3}$ - 2 x ${dy}/{dx}$  x ${x^2+3^3}$ over $({x^2+3)^6}$ And then simplifying to $-12x^5 + 36x^2$  over $({x^2+3)^6}$ I'm not sure if this is right.,"['derivatives', 'calculus']"
1776676,What's wrong with my differentiation (help finding a derivative)?,"So the equation looks a bit complicated, but the derivation itself should be straightforward. But I'm evidently getting mixed up somewhere, because my answer is wrong.
$$ \frac{\partial ({-k_{b}T \ln(2\cosh(\frac{\epsilon}{k_{b}T}})))}{\partial T} $$
(where V is kept constant, hence the partial derivative) So according to the product rule:
$$ {-k_b T} \frac{\partial ({\ln(2\cosh(\frac{\epsilon}{k_{b}T}})))}{\partial T} + {-k_b} ({\ln(2\cosh(\frac{\epsilon}{k_{b}T}}))) $$ Then the chain rule:
$$\frac{\partial ({\ln(2\cosh(\frac{\epsilon}{k_{b}T}})))}{\partial T} 
= \frac{\partial {(2\cosh(\frac{\epsilon}{k_{b}T}}))}{\partial T} \frac {1} {(2\cosh(\frac{\epsilon}{k_{b}T}))}
= \frac{\partial {(\frac{\epsilon}{k_{b}T}})}{\partial T} 2\sinh(\frac{\epsilon}{k_b T}) \frac {1} {(2\cosh(\frac{\epsilon}{k_{b}T}))}
= \frac {\epsilon} {k_b} 2\sinh(\frac{\epsilon}{k_b T}) \frac {1} {(2\cosh(\frac{\epsilon}{k_{b}T}))}
= \frac {\epsilon} {k_b} \tanh(\frac{\epsilon}{k_b T})$$ So the final answer I'm getting is: 
$$ {-k_b T} \frac {\epsilon} {k_b} \tanh(\frac{\epsilon}{k_b T}) + {-k_b} ({\ln(2\cosh(\frac{\epsilon}{k_{b}T}})))
=  -{\epsilon}T \tanh(\frac{\epsilon}{k_b T})-{k_b} {\ln(2\cosh(\frac{\epsilon}{k_{b}T}})) $$ But apparently this is incorrect, and the correct answer is: 
$$ \frac {\epsilon}{T} \tanh(\frac{\epsilon}{k_b T})-{k_b} {\ln(2\cosh(\frac{\epsilon}{k_{b}T}})) $$ I'm probably making a stupid mistake somewhere, but I can't seem to spot it.","['derivatives', 'calculus']"
1776688,Why $\sin(x)+\sin(\pi x)$ is not periodic?,"Why $\sin(x)+\sin(\pi x)$ is not periodic? There is an answer here which tries to explain it, but I somehow do not get it. If we assume that $T>0$ is a period of $\sin(x)+\sin(\pi x)$, then $$\sin(x)+\sin(\pi x)=\sin(x+T)+\sin(\pi (x +T))$$ Apparently one needs to differentiate the equation above two times to get: $$\sin(x)+\pi^2 \sin(\pi x)=\sin(x+T)+ \pi^2 \sin(\pi (x +T))$$ and then what?","['real-analysis', 'trigonometry', 'periodic-functions']"
1776717,Can the unit interval map bijectively to a region?,"The Hilbert Curve shows that there exists a surjection from the unit interval to the unit square. I was wondering, does there exist a bijection from the unit interval to the unit square?","['cardinals', 'functions']"
1776722,Why does this exact sequence of sheaves imply the maps are $G$-equivariant?,"I'm confused about something in Tamme's Introduction to Étale Cohomology (page 27). Let $G$ be a group and let $G$-$\mathsf{Set}$ denote the category of left $G$-sets with $G$-equivariant maps as morphisms. Let $T_G$ denote the canonical topology on this category. Then a family $\left\{\phi_i: U_i \to U\right\}$ is a family of universal effective epimorphisms if and only if $U = \bigcup_i \phi_i (U_i)$. Tamme is showing that the category $G$-$\textsf{Set}$ is equivalent to the category of sheaves of sets on the site ($G$-$\textsf{Set}$, $T_G$). To a $G$-set $Z$ we associate the representable sheaf $h_Z = \text{Hom}_G (-, Z)$ and to a sheaf $F$ we associate the set $F(G)$ made into a left $G$-set by applying $F$ to the right-multiplication of $G$ on itself. It is easy to see that $$ Z\mapsto h_Z \mapsto h_Z (G) = \text{Hom}_G (G, Z)$$ gives a natural isomorphism in one direction of the equivalence. The thing I'm struggling with is the other direction: showing that $$ F \cong \text{Hom}_G (-, F(G))$$ naturally in $F$. To set things up specifically for my problem, let $U$ be a $G$-set and let $u\in U$. Define $\phi_u : G\to U$ by $\phi_u (g) = g\cdot u$. Then $\phi_u$ is a $G$-map and $\left\{\phi_u : G\to U\right\}_{u\in U}$ is a covering family in $T_G$. The sheaf property of $F$ gives us an equaliser diagram $$ F(U)\to\prod_{u\in U} F(G)\rightrightarrows \prod_{u, v \in U} F(G\times_U G)$$ Hence $F(U)$ can be identified with a subset of the set $\prod_{u\in U } F(G) \cong \left\{ \text{functions } U\to F(G)\right\}$. I'm struggling to interpret how the exactness condition implies that each of these functions $U\to F(G)$ is actually a $G$-map i.e. $F(U) \cong \text{Hom}_G (U, F(G))$ (as is quickly mentioned in the book). I know that this is just a matter of spelling out what the maps to the term on the right actually are, but I've let myself get extremely confused. I'd really appreciate if anyone can explain how it works in more detail than the book. Thanks! Edit : Zhen Lin's comment proves the equivalence with a far more general statement about sheaves on categories of sheaves; this example follows as a special case where the underlying site has one object. However I would still like to see an answer to this question because the thing that is actually confusing me is how one interprets the equaliser diagram to see that elements of $F(U)$ are naturally $G$-equivariant functions $U\to F(G)$. I am not sure if this is obvious and I am just looking at it in the wrong way or if it requires some work.","['sheaf-theory', 'algebraic-geometry', 'etale-cohomology', 'grothendieck-topologies', 'category-theory']"
1776723,"If $x^2+ax-3x-(a+2)=0\;,$ Then $ \min\left(\frac{a^2+1}{a^2+2}\right)$","If $x^2+ax-3x-(a+2)=0\;,$ Then $\displaystyle \min\left(\frac{a^2+1}{a^2+2}\right)$ $\bf{My\; Try::}$ Given $x^2+ax-3x-(a+2)=0\Leftrightarrow ax-a = -(x^2-3x-2)$ So we get $$a=\frac{x^2-3x-2}{1-x} = \frac{x^2-2x+1+1-x-4}{1-x} = \left[1-x-\frac{4}{1-x}+1\right]$$ Now $$f(a) = \frac{a^2+1}{a^2+2} = \frac{a^2+2-1}{a^2+2} = 1-\frac{1}{a^2+2}$$ So $$f(x) = 1-\frac{1}{\left[(1-x)-\frac{4}{1-x}+1\right]^2+2}$$ Now put $1-x=t\;,$ Then we get $$f(t) =1- \frac{1}{\left(t-\frac{4}{t}+1\right)^2+2}$$ Now How can I maximize $\displaystyle \frac{1}{\left[(1-x)-\frac{4}{1-x}+1\right]^2+2, }\;,$ Help Required, Thanks","['algebra-precalculus', 'optimization', 'calculus', 'derivatives']"
1776734,How to find integer solutions to $M^2=5N^2+2N+1$?,"My number theory is terrible so I don't know what ""class"" of problem this secretly is.  I'm looking for all positive integer solutions to the equation: $M^2=5N^2+2N+1$ That is, I want positive integer $M$ and $N$ to make the above true.  I've got the obvious solution ($N=0$, $M=1$) but I don't know how to go about getting more solutions.  It has been suggested to me that there should be infinitely many solutions, and I would like to find them all. I could transform it to look like Pell's equation by completing the square on the right, but it won't have integer coefficients (or you could multiply it through by the denominators, but then it wouldn't look like Pell's equation), so I don't think that helps much. I don't know enough number theory to guess at other things, but I'm happy to read something on this topic.","['number-theory', 'pell-type-equations', 'diophantine-equations']"
1776768,counterexample for $\overline{A \cap B} = \overline{A} \cap \overline{B}$,"Prove $(\overline{A \cap B}) \subseteq \overline{A} \cap \overline{B}$. But the same relation with a $=$ isn't always true. Can someone find an example where the $=$ doesn't hold, I can't seem to find one. Thanks in advance.","['general-topology', 'real-analysis', 'examples-counterexamples', 'elementary-set-theory']"
1776817,Taking curl of Euler equation,"Consider an inviscid incompressible ﬂow. Euler’s equation can be written as
$$\frac{\partial \textbf u}{\partial t}
+ \textbf ω × \textbf u = −\textbf∇\bigg( \frac pρ
+
\frac 12
\textbf u^2 + V \bigg)$$
where the vorticity $\textbf ω = \textbf ∇ × \textbf u$. By taking the curl of this equation and using the vector identity $\textbf ∇ × (\textbf a × \textbf b) = (\textbf b \cdot \textbf ∇)\textbf a − (\textbf a\cdot \textbf∇)\textbf b + \textbf a(\textbf∇ \cdot \textbf b) − \textbf b(\textbf∇ \cdot \textbf a)$ show that
$$\frac{D \textbf ω}{Dt}
= (\textbf ω \cdot \textbf ∇)\textbf u$$
This is the vorticity equation. I am very stuck on this. Does taking the curl mean we have to do this:$$\textbf ∇ \times \bigg( \frac{\partial \textbf u}{\partial t}
+ \textbf ω × \textbf u \bigg)= −\textbf ∇ \times \bigg( \textbf∇\bigg( \frac pρ
+
\frac 12
\textbf u^2 + V \bigg) \bigg)$$ and the LHS becomes $$\textbf ∇ \times  \frac{\partial \textbf u}{\partial t}+ \textbf ∇ \times (\textbf ω × \textbf u )$$ and then use the identity? I was not sure if we can just kind off expand the LHS like how I did. But even still, after using the identity, it gets me nowhere.","['multivariable-calculus', 'euler-lagrange-equation', 'fluid-dynamics', 'vector-spaces']"
1776826,Characterization of Compact Space via Continuous Function,"Let $(X,\mathfrak{T})$ be a topological space. We know that if $X$ is compact and $f:X\to \mathbb{R}$ be any continuous function then $f(X)$ is bounded since the continuous image of a compact set is compact and any compact subset of a metric space is bounded. My questions are (edited after David C. Ullrich's comment below), What is(are) the necessary and/or sufficient condition(s) on $(X,\mathfrak{T})$ so that if for any continuous $f:X\to \mathbb{R}$ we can conclude that $f(X)$ is bounded then it would imply that $X$ is compact? Let $(X,\mathfrak{T})$ be a topological space. If every continuous function $f:X\to Y$ is bounded for all metric space $(Y,d)$ then can we say that $X$ is compact? Let $(X,\mathfrak{T})$ be a topological space. If there exists a metric space $(Y,d)$ such that every continuous function $f:X\to Y$ is bounded  then can we say that $X$ is compact?","['continuity', 'general-topology', 'compactness']"
1776834,Showing that $\sigma=\prod_{n=1}^{\infty}(n!)^{\frac{1}{2^{n+1}}}$,"Somos's quadratic recurrence constant The Somos's Quadratic recurrence constant is defined by the sequence $g_n=ng_{n-1}$ with initial value of $ g_0= 1$ The value of $\sigma=1.661687...$ An infinite product from maths world $\sigma=\prod_{k=1}^{\infty}k^{\frac{1}{2^k}}$ We found another infinite product involving the factorial numbers by experiments on a sum calculator. $$\sigma=\prod_{n=1}^{\infty}(n!)^{\frac{1}{2^{n+1}}}$$
Where n! is valid for non-negative integers and defined by $n!=n(n-1)(n-2)\cdots2\cdot1$ Can somebody help us to prove this","['real-analysis', 'infinite-product', 'sequences-and-series', 'calculus']"
1776880,Tomita Theory: Involution,"Given a Hilbert space $\mathcal{H}$. Consider a von Neumann algebra:
$$M\subseteq\mathcal{B}(\mathcal{H}):\quad M=M''$$ Suppose a cyclic vector:
$$\Omega\in\mathcal{H}:\quad\overline{\mathcal{M}\Omega}=\mathcal{H}$$ Regard the involution:
$$S_0:\mathcal{M}\Omega\to\mathcal{H}:\quad S_0M\Omega:=M^*\Omega$$
This operator is closable! But I didn't succeed checking this? What if there's no cyclic vector?","['hilbert-spaces', 'operator-theory', 'functional-analysis', 'von-neumann-algebras', 'operator-algebras']"
1776902,Polynomial with integer coefficients ($f(x)=ax^3+bx^2+cx+d$) with odd $ad$ and even $bc$ implies not all rational roots [duplicate],"This question already has answers here : If $ad$ and $bc$ are odd and even, respectively, then prove that $ax^3+bx^2+cx+d$ has an irrational root. (2 answers) Closed last month . Today, I attempted this problem in the ISI admission test for B.Math UG2016 for which I want my solution to be verified (whether it is correct or not) Q: Given $f(x)=ax^3+bx^2+cx+d$ where $a,b,c,d\in\Bbb Z$ and $ad$ is odd and $bc$ is even. Prove that $f(x)$ cannot have all rational roots. My attempted solution: Let us assume that there are three rational roots of $f(x)$, namely $\dfrac{p_1}{q_1},\dfrac{p_2}{q_2}$ and $\dfrac{p_3}{q_3}$ where we have WLOG $q_1,q_2,q_3\gt 0$ and $\gcd(p_i,q_i)=1~\forall~1\leq i\leq 3$ Now, by Vieta's formulas, we have, $$\frac{p_1}{q_1}+\frac{p_2}{q_2}+\frac{p_3}{q_3}=-\frac ba\implies a(p_1q_2q_3+p_2q_3q_1+p_3q_1q_2)=-bq_1q_2q_3\tag1$$ $$\frac{p_1p_2}{q_1q_2}+\frac{p_2p_3}{q_2q_3}+\frac{p_2p_2}{q_1q_2}=\frac ca\implies a(p_1p_2q_3+p_2p_3q_1+p_3p_1q_2)=cq_1q_2q_3\tag2$$ Now, since $ad$ is odd, both $a,d$ must be odd and since $bc$ is even, either $b$ or $c$ is even. By the rational root theorem and since both $a,d$ are odd, we know that all the $p_i$'s and $q_i$'s are odd and hence any product involving the $p_i$'s and the $q_i$'s will be odd. If $b$ is even, we consider $(1)$ for which the LHS is odd $\times$ odd $=$ odd and the RHS is even $\times$ odd $=$ even which is a contradiction since LHS and RHS cannot have different parity. If $c$ is even, we consider $(2)$ and use a similar argument to show that the parity of the LHS and the RHS is different which is a contradiction. Hence, in both cases, we arrive at a contradiction and hence our assumption that $f(x)$ has all rational roots was wrong. Therefore, $f(x)$ cannot have all rational roots. Is my solution correct? Also, I think I forgot to show for both the cases of $b$ and $c$ being even like I did here (due to rush of the exam hour). I probably just showed for the case of $b$ being even. If such a solution is to be graded out of $10$ for correctness, how much might it be graded  if it just shows one of the cases?","['algebra-precalculus', 'polynomials', 'proof-verification']"
1776904,"What is the smallest number of people in a group, so that it is guaranteed that at least three of them will have their birthday in the same month?","How should I begin solving this? I know that for months, there are 12, and 3 people from a small group suppose to have birthdays in the same month. Do I just multiply $12\times 3 = 36$ people? Or do I use ""$\lceil x \rceil$""?","['pigeonhole-principle', 'discrete-mathematics']"
1776908,"If $x \geq C$, where $C > 0$ is a constant, then what is the least upper bound for $\dfrac{2x}{x + 1}$?","The title says it all. Since
$$f(x) = \dfrac{2x}{x + 1} = 2\left(1 - \dfrac{1}{x + 1}\right),$$
then because $x \geq C$ where $C > 0$, an upper bound is given by
$$\dfrac{2x}{x + 1} < 2.$$ Note that the lower bound is equivalent to
$$x \geq C \iff x + 1 \geq C + 1 \iff \dfrac{1}{x + 1} \leq \dfrac{1}{C + 1}$$ $$\iff 2\left(1 - \dfrac{1}{x + 1}\right) \geq 2\left(1 - \dfrac{1}{C + 1}\right),$$
so that if $2 - \varepsilon$ is an upper bound for $f(x)$ ($\varepsilon > 0$), then $\varepsilon$ satisfies the inequality
$$2 - \varepsilon \geq f(x) \geq 2\left(1 - \dfrac{1}{C + 1}\right) \implies 0 < \varepsilon < \dfrac{2}{C + 1}.$$ My question is essentially whether we can do better than this.","['inequality', 'functions']"
1776951,Theorem 3.55 in Baby Rudin: Every re-arrangement of an absolutely convergent series converges to the same sum in every normed space?,"Here's Theorem 3.55 in the book Principles of Mathematical Analysis by Walter Rudin, third edition. If $\sum a_n$ is a series of complex numbers which converges absolutely, then every rearrangement of $\sum a_n$ converges, and they all converge to the same sum. And, here's Rudin's proof. Let $\sum a_n^\prime$ be a rearrangement, with partial sums $s_n^\prime$. Given $\varepsilon > 0$, there exists an integer $N$ such that $m \geq n \geq N$ implies $$\mbox{ (26) } \ \ \ \ \sum_{i=n}^m \vert a_i \vert \leq  \varepsilon.$$ Now choose $p$ such that the integers $1, 2, \ldots, N$ are all contained in the set $k_1, k_2, \ldots, k_p$. [Here $\{k_n\}$ is a sequence of positive integers in which every positive integer appears as a term once and only once, and $a_n^\prime = a_{k_n}$ for each $n = 1, 2, 3, \ldots$; moreover, $s_n^\prime = a_1^\prime + \cdots + a_n^\prime$. This is the notation of  Definition 3.52 in Rudin. ] Then if $n > p$, the $a_1, \ldots, a_N$ will cancel in the difference $s_n - s_n^\prime$, so that $\vert s_n - s_n^\prime \vert \leq \varepsilon$ by (26). Hence $\{s_n^\prime \}$ converges to the same sum as $\{s_n \}$. Now here is my reading of Rudin's proof. As $\sum a_n$ converges absolutely, the series $\sum \vert a_n \vert$ converges, which means that the sequence $\{ \sum_{i =1}^n \vert a_i \vert \}_{n \in \mathbb{N}}$ is convergent and therefore Cauchy. Thus, given a real number $\varepsilon > 0$, we can find a natural number $N$ such that $$ \left\vert \sum_{i=1}^n \vert a_i \vert - \sum_{i=1}^m \vert a_i \vert \right\vert < \varepsilon \ \mbox{ for all } \ m, n \in \mathbb{N} \ \mbox{ such that } \ n \geq m >  N.$$ That is, $$ \sum_{i = m+1}^n \vert a_i \vert < \varepsilon \  \mbox{ for all } \ m, n \in \mathbb{N} \ \mbox{ such that } \ n \geq m >  N.$$ Now let $\{k_n \}$ be a sequence of natural numbers in which every natural number appears exactly once, and let $a_n^\prime = a_{k_n}$, and then let $s_n^\prime = \sum_{i=1}^n a_i^\prime$ for each $n = 1, 2, 3, \ldots$. We first need to show that the series $\sum a_n^\prime$ converges.   let $p$ be a natural number such that $$\{1, \ldots, N \} \subset \{ k_1, \ldots, k_p \}.$$ Then, for all $n \in \mathbb{N}$ such that $n > p$, we have 
  $$ \vert s_n^\prime - s_n \vert = \left\vert \sum_{i \in \{ k_1, \ldots, k_n \} \setminus \{1, \ldots, n \} } a_i  \right\vert \leq \sum_{i \in \{ k_1, \ldots, k_n \} \setminus \{1, \ldots, n \} } \vert a_i \vert \leq \sum_{i = N+1}^{\max ( \{ k_1, \ldots, k_n \} \setminus \{1, \ldots, N \} )} \vert a_i \vert < \varepsilon. $$ Now let's suppose that $$\lim_{n \to \infty} s_n = s.$$ Then for $n \in \mathbb{N}$ such that $n > p$, we have $$0 \leq \vert s_n^\prime - s \vert \leq \vert s_n^\prime - s_n \vert + \vert s_n - s \vert < \epsilon + \vert s_n - s \vert \to \epsilon + 0 \ \mbox{ as } \ n \to \infty.$$ So, $$ 0 \leq \lim_{n \to \infty} \vert s_n^\prime - s \vert \leq \epsilon,$$ provided that the limit exists (i.e. provided that the sequence $\{s_n^\prime \}$ converges). We now show that the sequence $\{s_n^\prime \}$ is Cauchy. For all $m, n \in \mathbb{N}$ such that $n \geq m > p$, we have $$ \vert s_n^\prime - s_m^\prime \vert \leq \sum_{i = m+1}^n \vert a_i^\prime \vert \leq  \sum_{i = N+1}^{\max( \{ k_{m+1}, \ldots, k_n \} )} \vert a_i \vert < \varepsilon,$$ showing that the sequence $\{s_n^\prime \}$ is indeed Cauchy. So for all $m, n \in \mathbb{N}$ such that $n \geq m > p$, we have $$ \left\vert \vert s_n^\prime - s \vert - \vert s_m^\prime - s \vert \right\vert \leq \left\vert (s_n^\prime - s) - (s_m^\prime - s) \right\vert = \vert s_n^\prime - s_m^\prime \vert < \varepsilon,$$ showing that the sequence $\{ \vert s_n^\prime - s \vert \}$ is Cauchy. Therefore $ \lim_{n \to \infty} \vert s_n^\prime - s \vert $ exists and we also  have $$0 \leq \lim_{n \to \infty} \vert s_n^\prime - s \vert \leq \varepsilon$$ for every $\varepsilon >0$, which shows that the last limit is $0$ and therefore $$ \lim_{n \to \infty} s_n^\prime = s.$$ Is this presentation correct? Have I understood Rudin's logic correctly? If there are any errors or issues in my presentation, please do point those out!! In proving this result, we have only used the axioms of a Banach space; so this result holds in any Banach space Am I right? Does this result hold in every normed space?","['real-analysis', 'sequences-and-series', 'absolute-convergence', 'convergence-divergence', 'analysis']"
1776985,"Defining the set $\{(t^3,t^4,t^5) : t \in \mathbb{C}\}\subset \mathbb{C}^3$ by two polynomial equations","What are two polynomials $f,g \in \mathbb{C}[x,y,z]$ such that $$\{(x,y,z): f(x,y,z)=g(x,y,z)=0\}\;=\;\{(t^3,t^4,t^5): t \in \mathbb{C}\}$$ holds as an equality of subset of $\mathbb{C}^2$? This answer , as I understand it, claims that there are indeed such polynomials. How can we find them? Surely both polynomials need to be on the ideal of this curve, and thus $f(x,y,z)=p_1(xz-y^2)+p_2(yz-x^3)+p_3(z^2-x^2y)$, for some polynomials $p_i$ in $x,y,z$, and similarly for $g$. Alas, we cannot simply equate coefficients of each monomial in the two equations, nor solve generally these equations so as to ensure their solutions will only be points on the curve. Is there a reasonable way to find $f, g$?","['algebraic-curves', 'polynomials', 'algebraic-geometry', 'commutative-algebra']"
1777048,Proving recurrence relation with induction: $T(n) = T(n-1) + n$,"I have to prove that the bound of the following relation is $\theta(n^2)$ by induction- $$T(n) = T(n-1) +  n$$ should i seprate my induction into two sections - 
to claim  that $T(n) = O(n^2)$ and $T(n) = \Omega(n^2)$ and prove each case, or should i expand the relation and then formulate my claims ? should my two equations be the same , but with diffrent sign  -->   $\leq$ and $\geq$ Thanks!","['complex-analysis', 'asymptotics', 'sequences-and-series', 'calculus']"
1777058,Using the martingale central limit theorem,"Suppose a box has $2n$ tickets half of which are labelled $+1$ and half $-1$. Labeling the draws without replacement by $X_1, ...$, define $S_m = X_1 + ... + X_m$. For any $t \in (0,1)$ $S_{\frac{[2nt]}{\sqrt n}} \rightarrow^D N(0, v_t^2)$ where $[\;]$ denotes the greatest integer function and some $v_t$ depending on $t$. I've been told that there is a martingale $Y_k := \frac{S_1}{2n-1} + ... + \frac{S_k}{2n-k}$, but I'm not seeing how to show this. Let $F_k := \sigma(X_1, ... X_k).$ Then $\Bbb E(Y_k\; |\; F_{k-1}) = \Bbb E(Y_{k-1}\; |\; F_{k-1}) + \Bbb E(\frac{S_k}{2n-k}|\; F_{k-1} ) = Y_{k-1} + \Bbb E(\frac{S_k}{2n-k}\;|\; F_{k-1} )$. I don't see how the last term vanishes, and even if it did it's not really clear to me how to use central limit theorem. Any hints or starting points would be much appreciated.","['probability-theory', 'martingales', 'central-limit-theorem']"
1777075,Inequality $\sum\limits_{cyc}\frac{a^3}{13a^2+5b^2}\geq\frac{a+b+c}{18}$,"Let $a$ , $b$ and $c$ be positive numbers. Prove that: $$\frac{a^3}{13a^2+5b^2}+\frac{b^3}{13b^2+5c^2}+\frac{c^3}{13c^2+5a^2}\geq\frac{a+b+c}{18}$$ This inequality is strengthening of the following Vasile Cirtoaje's one, which he  created in 2005. Let $a$ , $b$ and $c$ be positive numbers. Prove that: $$\frac{a^3}{2a^2+b^2}+\frac{b^3}{2b^2+c^2}+\frac{c^3}{2c^2+a^2}\geq\frac{a+b+c}{3}.$$ My proof of this inequality you can see here: https://artofproblemsolving.com/community/c6h22937p427220 But this way does not help for the starting inequality. A big problem we have around the point $(a,b,c)=(0.785, 1.25, 1.861)$ because the difference between the LHS and the RHS in this point is $0.0000158...$ . I tried also to use Cauchy-Schwarz, but without success. Also, I think the BW (see here https://math.stackexchange.com/tags/buffalo-way/info I tryed!) does not help.","['contest-math', 'real-analysis', 'inequality']"
1777079,Is $\sqrt{\left(\operatorname{Si}(x)-\frac\pi2\right)^2+\operatorname{Ci}(x)^2}$ completely monotone?,"Recall the definitions of the sine and cosine integrals :
$$\operatorname{Si}(x)=\int_0^x\frac{\sin t}t dt,\quad\operatorname{Ci}(x)=-\int_x^\infty\frac{\cos t}t dt.$$
Both functions are oscillating, with a countably infinite number of minima and maxima. Note that
$$\lim_{x\to\infty}\operatorname{Si}(x)=\frac\pi2,\quad\lim_{x\to\infty}\operatorname{Ci}(x)=0.$$
Consider the following function:
$$f(x)=\sqrt{\left(\operatorname{Si}(x)-\frac\pi2\right)^2+\operatorname{Ci}(x)^2}.$$ It appears that the function $f(x)$ and all its derivatives are monotonic  for $x>0$. Specifically, the function itself and all its derivatives of an even order are strictly decreasing, and all its derivative of an odd order are strictly increasing. Is it actually true? If so, then how can we prove it?","['derivatives', 'trigonometry', 'calculus', 'definite-integrals', 'special-functions']"
1777112,Why don't more celestial bodies exhibit higher-order rotations?,"It is well known that the Earth spins on its axis. It is also well known that the Earth's axis also precesses, i.e. spins around a secondary axis, much more slowly. Less well known is that we have seen asteroids that seem to tumble through space, with precession rates on roughly the same order of magnitude as rotation rates. My question is, why haven't we seen many instances of higher orders of rotation (where the secondary axis spins around a tertiary axis, the tertiary axis spins around a quaternary axis, etc.)? Can rotations of a high enough order always be expressed in terms of lower-order rotations at higher rates of rotation, or do higher-order rotations eventually decay into lower-order ones (as, for example, rotating around the $x$, $y$, $z$, and $x$ axes, all at the same rate*, produces an about-face, a seemingly impossible behavior)? (The latter seems to be stated by a comment on this question , but it doesn't go into much explanation.) *This generates the matrix $$\begin{pmatrix}
  \cos^2t & \sin t\cos t(\sin t-1) & \sin t(\sin t+\cos^2t) \\
  \sin t(\sin t+\cos^2 t) & \cos t(\sin^3t-\sin^2t+\cos^2t) & \sin t\cos^2t(\sin t-2) \\
  \sin t\cos t(\sin t-1) & \sin t(\sin^3t+2\cos^2t) & \cos t(\sin^3t-\sin^2t+\cos^2t) \\
 \end{pmatrix}$$
with the about-face occurring at $t=\pi/2$.","['matrices', 'physics', 'rotations', 'geometry']"
1777115,Compute the cumulative distribution function of the variable $R=\sqrt{X^2+Y^2}$,"I've returned to the study of statistics after a long while and I'm trying to solve some problems. One of those is the next: Suppose $X$ and $Y$ are random independent variables with normal distribution $N(0,1)$, which has distribution function $$f(x)=\frac{1}{\sqrt{2\pi}}\exp{\left(\frac{-x^2}{2}\right)}$$ Compute the cumulative distribution function of the variable
$$R=\sqrt{X^2+Y^2}$$ I'd appreciate some hints to solve these kind of problems. Thanks.","['statistics', 'probability-distributions']"
1777145,Evaluate $\int_0^{2\pi}\frac{\sin^2(x)}{a + b\cos(x)}\ dx$ using a suitable contour,"I need to find a good contour for $\int_0^{2\pi}\frac{\sin^2(x)}{a + b\cos(x)}\ dx$ but I don't know which one to choose. Both a semicircular, and rectangular contour look ugly for this. I've been looking at a semicircular contour of radius $2\pi$, but then I have the problem that I don't know whether the singularity is inside or outside the closed region. If it helps, the answer is $\frac{2\pi}{b^2}\left[a - \sqrt{a^2 - b^2}\right]$","['integration', 'definite-integrals', 'contour-integration']"
1777179,"Why are second order linear PDEs classified as either elliptic, hyperbolic or parabolic?","Is there a geometric interpretation of second order linear partial differential equations which explains why they are classified as either elliptic, hyperbolic or parabolic, or is this just a naming convention? That is, do they have any relation with actual ellipses, hyperbolas and parabolas?","['intuition', 'partial-differential-equations', 'terminology', 'geometry', 'ordinary-differential-equations']"
1777211,Explicit solution to a Rayleigh quotient equation,"For 5 months! I have been struggling to solve the following equations analytically without numeric method (i,e, Newton method): Main equation: $$
 \biggl(M^2-\cfrac{\mathbf{x^{\text{T}}}M^2\mathbf{x}}{\mathbf{x^{\text{T}}}\mathbf{x}}E\biggr)\mathbf{x}=\mathbf{1}
$$ Constraint equations: $$
\begin{cases}
 \mathbf{x^{\text{T}}1}=0 \\
\\
\mathbf{x^{\text{T}}x}=u 
\end{cases} $$ where $\{M,E\}\in\mathbf{R}^{n \times n}$ and $\{\mathbf{1},\mathbf{x}\}\in\mathbf{R}^n$ are defined, then $M$ is an arbitrary symmetric matrix, $E$
  is an identical matrix,
  $\mathbf{1}$ is all one vector, $\mathbf{x}$ is a
  variable vector and $u\in\mathbf{R}$ is a scalar.
  Furthermore, as a knowledge, the below equation form is called Rayleigh
  quotient $R(M^2,\mathbf{x})$: $$R(M^2,\mathbf{x}):=\cfrac{\mathbf{x^{\text{T}}}M^2\mathbf{x}}{\mathbf{x^{\text{T}}}\mathbf{x}}$$ Now, we attempt to estimate the $\mathbf{x}$. Does the analytic solution or method exist? My ability is shortage but, I guess that this problem has a beautiful solution. Also, main equation is a simultaneous cubic equation. Theoretically, this is solvable. Just, this is my theme question. Furthermore, same question is already asked on math overflow . Then answerers provided worthful information which may be solution to clue.","['matrices', 'linear-algebra', 'vectors', 'systems-of-equations']"
1777231,Show me how to evaluate $\int_0^1\int_0^1\frac{[-\ln(x)]^s}{1-xy}dxdy=\frac{\zeta(s+2)}{\Gamma(s+2)}$,"Double integrals $$\int_0^1\int_0^1\frac{[-\ln(x)]^s}{1-xy}dxdy=\frac{\zeta(s+2)}{\Gamma(s+2)} \tag1$$ $$\int_0^1\int_0^1\frac{[-\ln(xy)]^s}{1-xy}dxdy=\zeta(s+2)\Gamma(s+2) \tag2$$ Where $\sum_{n=0}^{\infty}\frac{1}{(n+1)^s}=\zeta(s)$, valid for $\Re(s)>1$ and $\Gamma(n+1)=n!$ valid for all non-negative integers and rational arguments. I came across these two double integrals during the time I was on Wolfram integrator, was trying to search for something. It didn't gave me the closed form, just the numerical values and the rest I had to find the closed form base on these values. I don't know how to prove these integrals, can somebody show me how to prove it, so I can learn from it, so next time I can independently do it myself. I hope these closed form are correct. P.s Please, try not to miss too many steps. Thank you!","['multivariable-calculus', 'zeta-functions', 'integration', 'definite-integrals']"
1777234,Conformal map from doubly slit plane to the open unit disk.,"As stated in the title, what is the starting point in finding a conformal map between doubly-slit domain to the open unit disk? I know how to deal with a single-slit domains, but have trouble trying to modify them to work on doubly slit domains. For instance, if $D = \Bbb{C}\setminus_{\{(-\infty, -1]\cup[1, \infty)\}}$, then $f(z) = \log(1-z^2)$ conformally maps $D$ onto $V$, where $V = \{z: |\Im(1-z^2)|<\pi\}$. But I find it hard to explicitly construct a conformal map from $V$ to the open unit disk so I can compose it with $f$ to obtain my desired map. 
So I am guessing there must be a different approach to this problem that I have not seen before. Any hint is appreciated.","['analyticity', 'complex-analysis', 'conformal-geometry']"
1777250,Is there an opposite of the Kronecker Delta?,"Instead of $\delta(n,n) = 1$ and $\delta (n,k) = 0$, is there something that returns $0$ when the arguments are the same, and $1$ when the arguments are different. Is there a special function that does this? Is there a name for it? Thanks!","['kronecker-symbol', 'functions']"
1777306,How to solve $\cos(\frac{\alpha }{2} )=\frac{a}{\sqrt{a^{2}+b^{2} } }$ for $\cos(\alpha)$ using half-angle formula.,"I have $\cos(\frac{\alpha }{2} )=\frac{a}{\sqrt{a^{2}+b^{2}  } }  $ How can I get $\cos(\alpha ) $ from this? I know this identitiy. $\cos(\frac{\alpha }{2} )=\sqrt{\frac{1+\cos(\alpha )  }{2} }  $ But just cant figure out, how to do it.","['trigonometry', 'calculus']"
1777312,Prove that the set of all infinite subsets of $\mathbb{N}$ is uncountable.,"For this problem, my proof was:
If we want to express out the set of all the finite subsets, $F$.
$F = \{\{n_{1}\},\{n_{1},n_{2}\},\{n_{1},n_{2},n_{3}\},\cdots\}$ with $n_{1} \in \mathbb{N}$, $n_{2} \in \mathbb{N} - \{n_{1}\}$, $n_{3} \in \mathbb{N} - \{n_{1},n_{2}\}$.
Notice that the first element of the $F$ above comes with the only one element $\in \mathbb{N}$, the second element of $F$ comes with only two elements $\in \mathbb{N} \cdots$.
There are countably infinite number of the first element of $F$, and countably infinite number of the second element of $F$(since countably infinite $\times$ countably infinite gives countably infinite). Then the cardinality of $F$ is the sum of finite number of countably infinite, which is countably infinite.
Therefore, we can conclude that set of all finite subsets of $\mathbb{N}$ is a countably finite set. However, I realized that the proof above although got the rough idea but is very informal and actually made use of P&C.
Now I think it is possible to do a proof with mapping: For example:
$\{n_{1},n_{2}\} \hookrightarrow (n_{1},n_{2}) \in \mathbb{N} \times \mathbb{N}$.
However, I found it difficult to phrase it in this approach. 
Hope some one can help me to improve my proof. Thank you!","['cardinals', 'elementary-set-theory']"
1777322,"Prove $1+a<b+c$ given $a>0,b>0,c>0$, $a<bc$ , $1+ a^{3} = b^{3} + c^{3} $.","Suppose: $a>0,b>0,c>0$, $a<bc$ , $1+ a^{3} = b^{3} + c^{3} $. Prove: $$ 1+a<b+c $$ This inequality at the University of Toronto plan.",['functions']
1777341,"Possible wrong gradient in my book, need confirmation","While reading this chapter about iterative algorithms, I came up with the following function and it's gradient. I just can't find the same gradient showed. I tried two different approaches and both disagree with the book. Now I'm starting to think they made some mistake and I just need to confirm whether this is the case or not. By the way, one of my computations is the following. $$\frac{\partial f}{\partial x_i}(x) = \lim_{t\to 0} \frac{f(x+te_i)-f(x)}{t} = \lim_{t\to 0} \frac{\frac{1}{2}(x+te_i)^TA(x+te_i) -b^T(x+te_i)- \frac{1}{2}x^TAx + b^Tx}{t} =$$ $$= \lim_{t\to0} \frac{\frac{1}{2}(x^TAx + te^T_iAx + tx^Te_i + t^2e_i^Te_i) -b^Tx - tb^Te_i -\frac{1}{2}x^TAx + b^Tx}{t} = $$ $$= \lim_{t\to0} \frac{e^T_iAx + x^Te_i + te^T_ie_i - 2b^Te_i}{2} = \frac{e^T_iAx + x^Te_i - 2b^Te_i}{2} = \frac{(Ax)_i + x_i-2b_i}{2},$$ where $(Ax)_i$ is the ith line of $Ax$. Therefore, $\nabla f(x) = \frac{Ax + x - 2b}{2}$ or $\frac{Ax+x}{2}-b$. Anyway, the resulty doesn't match. Also, if the book indeed made a mistake, what should be the function $f$ to get that gradient? Thanks.","['linear-algebra', 'analysis']"
1777344,How many non-differentiable functions exist?,The size of the set of functions that map $\mathbb{R}\to \mathbb{R}$ equals $(\#\mathbb{R})^{\#\mathbb{R}}$. How many non-differentiable functions are there in this set?,"['derivatives', 'real-analysis', 'functions', 'elementary-set-theory', 'cardinals']"
1777354,Normal vector field to this hypersurface,"Let $M^n$ be a hypersurface of the unit sphere $S^{n+1} \subset \mathbb{R}^{n+2}$ contained in the open upper hemisphere $S^{n+1}_+$, and let $N : M \to \mathbb{R}^{n+2}$ be a unit normal vector field to $M$ (with $\langle N(p), p \rangle = 0$ for all $p$). Consider the diffeomorphism $f : S^{n+1}_+ \to \mathbb{R}^{n+1}$ obtained by central projection, that is, $$f(x_1, \dots, x_{n+2}) = \left( \frac{x_1}{x_{n+2}}, \dots, \frac{x_{n+1}}{x_{n+2}} \right).$$ How do I get a normal vector field $\overline{N}$ to the hypersurface $\overline{M} = f(M)$? I know that we can proceed like this: take a parametrization $\varphi : U \to M$ and define $$\overline{N}(f(p)) = w_1 \times \cdots \times w_n,$$ where $w_i = \frac{\partial(f \circ \varphi)}{\partial x_i}(\varphi^{-1}(p)) = Df(p) \cdot \frac{\partial\varphi}{\partial x_i}(\varphi^{-1}(p))$. But the vector products are not explicit enough. Is there a nicer expression? Thanks for your thoughts.","['vector-fields', 'spherical-geometry', 'differential-geometry']"
1777364,What is an example of two sets which cannot be compared?,"In set theory, if we do not assume the Axiom of Choice, we cannot prove the Trichotomy Law between cardinals. That is, we cannot prove that for any two sets, there exists an injection from one to the other. But this raises the question: what is an example of a pair of sets between which there does not exist an injection?","['cardinals', 'elementary-set-theory', 'axiom-of-choice']"
1777400,Proving that classes aren't sets,"I've always had trouble proving that certain classes, (like the universe, $\mathcal W$, or the set of all sets, which I'll call $S$ henceforth). It recently occurred to me that the separation axiom (namely, given a set $A$ and a definite unary condition $P(x)$, $B=\{x \in A \mid P(x)\}$ is also a set) could possibly be used in a proof. For example, Assume (towards a contradiction) $S$ is a set, defined as $x \in S \Leftrightarrow \mathrm {Set}(x)$. Applying the unary definite condition $P(x) \Leftrightarrow x \notin x$ to the set yields $T=\{x\in S \mid P(x)\}$, which, by the separation axiom, is a set, but by Russell's paradox, isn't a set. Is that sufficient to prove that $S$ is not a set?",['elementary-set-theory']
1777427,Splitting Poisson process formal proof,"Let $\{X_t\}_{t\ge 0}$ be a Poisson Process with parameter $\lambda$. Suppose that each event is type 1 with probability $\alpha$ and type 2 with probability $1-\alpha$. Let $\{X^{(1)}_t\}_{t\ge 0}$ the number of type 1 events up until time $t$ and $\{X^{(2)}_t\}_{t\ge 0}$ the number of type 2 events up until time $t$ Prove that $\{X^{(1)}_t\}_{t\ge 0}$ and $\{X^{(2)}_t\}_{t\ge 0}$ are Poisson Processes with parameter $\lambda \alpha$ and $\lambda(1-\alpha)$ respectively Furrthermore prove that for each $t\ge 0$ the random variables $\{X^{(1)}_t\}_{t\ge 0}$ and $\{X^{(2)}_t\}_{t\ge 0}$ are independent My attempt: In order to prove that they are poisson process I will use the next definition: An stochastic process $\{Y_t\}_{t\ge 0}$ is a poisson process iff: a) $Y_0=0$ b) It has independent increments c) $Y_{t+s}-Y_{s}$~$Poisson(\lambda t)$ for any values $s\ge 0$ and $t>0$ a) For any $t\ge 0$ we have: $X_t=X^{(1)}_t+X^{(2)}_t$; we know that $\{X_t\}_{t\ge 0}$ is a poisson process hence $X_0=0$ $\Rightarrow X^{(1)}_0+X^{(2)}_0=0 \Rightarrow X^{(1)}_0=0$ and $X^{(2)}_0=0$ b)Let $n\in \mathbb N$ In this part I need to prove that for any $n$ arbitrary times $0<t_1\le t_2\le...\le t_n$ and states $x_1,...,x_n$
 $$P[X^{(1)}_{t_1}=x_1,X^{(1)}_{t_2}-X^{(1)}_{t_1}=x_2,...,X^{(1)}_{t_n}-X^{(1)}_{t_{n-1}}=x_n]=P[X^{(1)}_{t_1}=x_1]P[X^{(1)}_{t_2}-X^{(1)}_{t_1}=x_2]...P[X^{(1)}_{t_n}-X^{(1)}_{t_{n-1}}=x_n]$$ I don´t know how to Formally prove this part, and I don´t think this is trivial. Any help would be highly appreciated c) $$P[X^{(1)}_t=k]=\sum_{i=k}^\infty P[X^{(1)}_t=k|X_t=i]P[X_t=i]=\sum_{i=k}^\infty \binom{i}{k}\alpha^i(1-\alpha)^{i-k}{e^{-\lambda t}(\lambda t)^i \over i!}={e^{-\lambda \alpha t}(\lambda \alpha t)^k\over k!}$$ Know I need to compute $P[X^{(1)}_{t+s}-X^{(1)}_t=n]=\sum_{j=0}^\infty P[X^{(1)}_{t+s}-X^{(1)}_t=n|X^{(1)}_s=j]P[X^{(1)}_s=j]$ This part is also giving me trouble because I dont´know what to do from here I would really apreciate if you can help me with this problem. Also I hope that this won´t be marked as a duplicate because I haven´t seen a formal proof about the splitting poisson process.","['stochastic-processes', 'probability-distributions', 'poisson-process', 'probability', 'poisson-distribution']"
1777431,98% confidence interval,"For this question from a large amount of data I have calculated that the mean is 44.22, the sample size is 100 and the standard deviation is 22.0773. From this I am asked to , make the 98% confidence intervals for the
(1) true mean µ of the module mark
(2) true variance of the module mark And for each:
(a) Determine what quantity to look at, and which distribution table
to use, justifying your choice. 
(b) Determine the number of degrees of freedom, justifying your answer.
(c) Calculate the actual intervals. So far for 1, I have used the z table to  look for $99\%$ as I need $1\%$ to the right of $2.33$ and $1\%$ to the left of $-2.33$, so $98\%$ is between $\pm2.33$. Giving me $$
\bar x \pm 2.33\frac{\sigma}{\sqrt{n}}
$$ Which provides me with a 39.08 to 49.36 confidence interval, is this correct? And how would I determine degrees of freedom and go about answering part 2?",['statistics']
1777468,Dirichlet Problem in Stochastic PDE Section of Probability Textbook.,"I recently started learning about stochastic calculus and stochastic PDEs, and I don't know where to begin with some of the problems in my textbook.  Any help with the following or a push in the right direction would be appreciated.  This is in the section on stochastic PDEs, but it's not clear what techniques from the section are useful here. Let D be the open unit disk in $\mathbb{R}^2$ and $u^{\epsilon}\in C^2(D)\cap C(\overline{D})$ be the solution to the Dirichlet problem: $\epsilon \Delta u^\epsilon + \frac{\partial u^\epsilon}{\partial x_1}=0$, 
$u(x)=f(x)$ for $x\in\partial D$ where $f$ is a continuous function on $\partial D$. Find the limit $\lim_{\epsilon\to0^+}u^{\epsilon}(x_1,x_2)$ for $(x_1,x_2)\in D$.","['stochastic-analysis', 'probability-theory', 'partial-differential-equations']"
1777481,Signed sum over labeled connected graphs,"Let $\binom{n}{2}$ be the set of all subsets of $\{1,2,3, \ldots, n\}$ of size $2$ and let $C_n$ be the set of $E \subseteq C_n$ so that the graph $G$ with vertex set $\{1,2, 3, \ldots, n\}$ and edge set $E$ is connected.  Using generating function methods one can show that $$\sum_{E \in C_n} (-1)^{|E|} = (-1)^{n-1}(n-1)!.$$ For example, if $n=3$ then $$C_n = \{\{12,23\}, \{12, 13\}, \{13, 23\}, \{12, 13, 23\} \}$$ and then $$(-1)^2 + (-1)^2 + (-1)^2 + (-1)^3 = 2!.$$
Is there a more direct proof?  For example, a sign-reversing involution argument.","['combinatorics', 'graph-theory']"
1777484,Deriving the Normalization formula for Associated Legendre functions: Stage $4$ of $4$,"The question that follows is the final stage of the previous $3$ stages found here: Stage 1 , Stage 2 and Stage 3 which are needed as part of a derivation of the Associated Legendre Functions Normalization Formula: $$\color{blue}{\displaystyle\int_{x=-1}^{1}[{P_{L}}^m(x)]^2\,\mathrm{d}x=\left(\frac{2}{2L+1}\right)\frac{(L+m)!}{(L-m)!}}\tag{1}$$ where for each $m$, the functions $${P_L}^m(x)=\frac{1}{2^LL!}\left(1-x^2\right)^{m/2}\frac{\mathrm{d}^{L+m}}{\mathrm{d}x^{L+m}}\left(x^2-1\right)^L\tag{2}$$ are a set of Associated Legendre functions on $[−1, 1]$. The question in my textbook asks me to Derive $(1)$ as follows: Multiply together the two formulas for ${P_{L}}^m(x)$ given by
  $(2)$ and $${P_L}^{m}(x)=(-1)^m\frac{(L+m)!}{(L-m)!}\frac{1}{2^LL!}\left(1-x^2\right)^{-m/2}\frac{\mathrm{d}^{L-m}}{\mathrm{d}x^{L-m}}\left(x^2-1\right)^L\quad\longleftarrow\text{(Stage 3)}$$ Then integrate by parts repeatedly lowering the $L+m$ derivative and raising the $L−m$ derivative until both are $L$ derivatives. Then use the regular Normalization formula for Legendre Functions: $$\displaystyle\int_{x=-1}^{1}[{P_{L}}(x)]^2\,\mathrm{d}x=\frac{2}{2L+1}\tag{3}$$ where ${P_{L}}(x)$ represents a Legendre function and ${P_{L}}^m(x)$ represents an associated Legendre function. Start of attempt: Multiplying together $(2)$ and the Stage $3$ formula yields:
$$[{P_{L}}^m(x)]^2=\frac{(-1)^m}{(2^LL!)^2}\frac{(L+m)!}{(L-m)!}\frac{\mathrm{d}^{L-m}}{\mathrm{d}x^{L-m}}\left(x^2-1\right)^L\frac{\mathrm{d}^{L+m}}{\mathrm{d}x^{L+m}}\left(x^2-1\right)^L\tag{4}$$ Multiplying both sides of $(4)$ by $\mathrm{d}x$ and integrating gives:
$$\int[{P_{L}}^m(x)]^2\,\mathrm{d}x=\frac{(-1)^m}{(2^LL!)^2}\frac{(L+m)!}{(L-m)!}\color{red}{\int\frac{\mathrm{d}^{L-m}}{\mathrm{d}x^{L-m}}\left(x^2-1\right)^L\frac{\mathrm{d}^{L+m}}{\mathrm{d}x^{L+m}}\left(x^2-1\right)^L\,\mathrm{d}x}\tag{5}$$ Focusing now on the part marked $\color{red}{\mathrm{red}}$ and integrating by parts:
$$\int\frac{\mathrm{d}^{L-m}}{\mathrm{d}x^{L-m}}\left(x^2-1\right)^L\frac{\mathrm{d}^{L+m}}{\mathrm{d}x^{L+m}}\left(x^2-1\right)^L\,\mathrm{d}x$$
$$=\left.\frac{\mathrm{d}^{L-m}}{\mathrm{d}x^{L-m}}\left(x^2-1\right)^L\frac{\mathrm{d}^{L+m-1}}{\mathrm{d}x^{L+m-1}}\left(x^2-1\right)^L\right|_{-1}^1-\int\frac{\mathrm{d}^{L+m-1}}{\mathrm{d}x^{L+m-1}}\left(x^2-1\right)^L\,\frac{\mathrm{d}^{L-m+1}}{\mathrm{d}x^{L-m+1}}\left(x^2-1\right)^{L}\mathrm{d}x$$
$$=0-\int\frac{\mathrm{d}^{L+m-1}}{\mathrm{d}x^{L+m-1}}\left(x^2-1\right)^L\,\frac{\mathrm{d}^{L-m+1}}{\mathrm{d}x^{L-m+1}}\left(x^2-1\right)^{L}\mathrm{d}x$$ End of attempt. I don't know how to take this calculation any further as I have no idea how to evaluate
$$\color{#180}{\int\frac{\mathrm{d}^{L+m-1}}{\mathrm{d}x^{L+m-1}}\left(x^2-1\right)^L\,\frac{\mathrm{d}^{L-m+1}}{\mathrm{d}x^{L-m+1}}\left(x^2-1\right)^{L}\mathrm{d}x}$$ Could someone please help me reach equation $(1)$ and finally end this derivation of 
$$\color{blue}{\displaystyle\int_{x=-1}^{1}[{P_{L}}^m(x)]^2\,\mathrm{d}x=\left(\frac{2}{2L+1}\right)\frac{(L+m)!}{(L-m)!}}\tag{1}$$ EDIT: The Latex didn't render correctly in the description below the bounty; so I type it here instead: One user has already given a detailed answer to this question that uses mathematical induction. The problem is that I am finding it hard to understand this type of proof as it is beyond my current level of understanding. I am looking for an answer that doesn't use mathematical induction. Could someone please explain in simple English (where possible) why $\bbox[yellow]{\displaystyle-\int\dfrac{\mathrm{d}^{L+m-1}}{\mathrm{d}x^{L+m-1}}\left(x^2-1\right)^L\,\dfrac{\mathrm{d}^{L-m+1}}{\mathrm{d}x^{L-m+1}}\left(x^2-1\right)^{L}\mathrm{d}x}
$ $\bbox[yellow]{\displaystyle=(-1)^m\int_{-1}^1\frac{\mathrm{d}^L}{\mathrm{d}x^L}(x^2-1)^{L}\frac{\mathrm{d}^L}{\mathrm{d}x^L}(x^2-1)^L\mathrm{d}x}$ I desperately need to understand this as this forms the final part of a $4$ step proof. Thank you very much.","['integration-by-parts', 'legendre-polynomials', 'integration', 'special-functions', 'orthogonal-polynomials']"
1777485,Help Me Understand How this was Derived,"Here is the question:
""Newton’s Law of Cooling. Newton's Law of Cooling states that the rate of change of the temperature of an object is proportional to the difference between its own temperature and the temperature of its surroundings. The temperature of a warm object can be found by $T = A + (T_0 – A)e^{kt}\;$, where $A\;$ is the temperature of the surroundings, $T_0\;$ is the initial temperature of the object, $t\;$ is the time in minutes since the initial temperature was measured, and $k\;$ is a characteristic of the object.
At what rate is a cup of tea cooling 3 minutes after its initial temperature was taken, if it had an initial temperature of 92°C, is placed in a room at a temperature of 21°C, and has a $k\;$ value of 0.054?"" During the explanation of the answer to this question they show this deriving: From the four lines of math seen above, how did ""they"" get from the third line to the fourth line (last line)? I believe the chain rule is being applied here, please explain the process of this math. Thanks!","['derivatives', 'chain-rule', 'calculus']"
1777492,Need help proving this set identity,"I need some help with this question for Discrete Math... It says: Let $A$, $B$ and $C$ be sets. Establish the identity: $A\cap(B-C) = B\cap(A-C)$ Now I've worded what I have, but just let me know if I'm on the right track. Let $x$ be a member of $A\cap(B-C)$ such that $x \in A$ AND $x \in B$ but not $C$. So therefore $x \in A \cap B$ and not a member of $C$. Hence $x \in B \cap A$ and not $C$ to give $B\cap(A-C)$.","['proof-verification', 'elementary-set-theory', 'discrete-mathematics']"
1777505,Probability that out of 600 crabs 60 are still alive after 9 months.,"A crabs' life expectancy can be modeled exponentially, and a crab lives 3 months on average. I am absolutely not sure about this, because there is nothing concerning this in our book, so I guess it was meant to be solved in some obvious/easy fashion, here's what I tried: If it were only one crab, I could simply plug 9 into $\lambda e^{-\lambda x}$ , where $\lambda=1/3$ . $60$ is $10\%$ of $600$ , so maybe I need to look after what time 90% died, intuitively I would resort to $$1-e^{-x/3}=0.9$$ $$0.1=e^{-x/3}$$ and so on, which would give me $\approx 6.9$ months, and then do something about the remaining $2.1$ months. The last thing I was thinking of is to calculate the probability for 540 crabs dying at some point before the 9 month mark, and then taking the converse probability, but that I'd only know how to do with the help of a computer.",['probability']
1777526,If $p$ is an odd prime and $k$ an integer with $0<k<p-1$ then $1^k + 2^k + \ldots + (p-1)^k$ is divisible by $p$,"If $p$ is an odd prime and $k$ an integer with $0<k<p-1$ prove that $1^k + 2^k + \ldots + (p-1)^k$ is divisible by $p$. Given hint: use primitive root. This is a question on a practice final of mine. For $k$ being odd, it seems obvious (as the $\pm$ terms cancel out), but I cannot figure out how to do this for the general case.","['number-theory', 'primitive-roots']"
1777561,"There exists polynomial $(P_{n})_{n\in\mathbb{N}}$ such that $P_n(0)=1$, and $\lim_{n\rightarrow \infty}P_{n}(z)=0$..","Show that there exists a sequence of polynomial $(P_{n})_{n\in\mathbb{N}}$ such that $P_n(0)=1$ for each $n$, and $\lim_{n\rightarrow \infty}P_{n}(z)=0$  for all $z\in \mathbb{C}\setminus \left\{0\right\}$. Remark: There are proofs of this fact that use versions of the Runge's theorem, the problem is that those versions do not coincide with versions I was taught in my course. Runge's theorem on my course is: Runge's Theorem for compacts: Let $U\subseteq \mathbb{C}$ be an open set, $K\subseteq U$ compact set, $f:U\rightarrow \mathbb{C}$ holomorphic function. Let $\varepsilon >0 $  and let $A\subseteq \mathbb{C}\setminus K$ such that $A$ intersects any connected component of $\mathbb{C}\setminus K$. Then there is $g\in  \mathcal{R}_{A}$ such that $\left\|f-g\right\|_{K}<\varepsilon $. where 
$$\mathcal{R}_{A}:=\left\{f \: \mbox{rational function with each pole in } A\right\}$$ 
In my attempt I use the following lemma: Lemma $\bigstar$: Let $K\subseteq \mathbb{C}$ be a compact set. Let $r>0$ such that $A:=\left\{z\in \mathbb{C}\: : \: |z|>r\right\}\subseteq \mathbb{C}\setminus K$ and $f\in \mathcal{R}_{A}$. Then $f$ can be approximated uniformly on $K$ by polynomials. My attempt: For each $n\in \mathbb{N}$ consider $C_{n}:=\left\{z\in \mathbb{C}\: : \: \frac{1}{n}\leq \mbox{Re}(z) \leq n \: \mbox{ and }\: \frac{-1}{4n}\leq \mbox{Im}(z) \leq \frac{1}{4n}\right\}$. We define
$$K_{n}:=\left\{z\in\mathbb{C}\: : \: z\in \overline{B_{n}(0)  } \: \mbox{and} \: d(z,\mathbb{R}^{+})\geq \frac{1}{n}\right\}\cup \overline{B_{\frac{1}{4n}}(0)}\cup C_{n}.$$
Clearly $ K_ {n} $ is compact. Now, we consider the open set $V_{n}:=\left\{z\in \mathbb{C}\: : \: \frac{1}{n}\leq \mbox{Re}(z) \leq n \: \mbox{ and }\: \frac{-1}{3n}<\mbox{Im}(z) < \frac{1}{3n}\right\}\cup B_{\frac{1}{3n}}(\frac{1}{n})\cup B_{\frac{1}{3n}}(n)$. We define 
$$U_{n}:=\left\{z\in\mathbb{C}\: : \: z\in B_{n+\frac{1}{3n}}(0)   \: \mbox{and} \: d(z,\mathbb{R}^{+})> \frac{2}{3n}\right\}\cup B_{\frac{1}{3n}}(0)\cup V_{n}.$$
Note that  $U_{n}$ is  open and also $K_{n}\subseteq U_{n}$. 
All this is summarized in the following figure: Now, we consider $A_{n}:=\left\{z\in \mathbb{C} \: : \: |z|>n+\frac{1}{3n}\right\}$ and $f_{n}:U_{n}\rightarrow \mathbb{C}$ defined by:
$$f_{n}(z):=\left\{\begin{array}{rl}1 & \mbox{If }z\in B_{\frac{1}{3n}}(0) \\ 0 & \mbox{If }z\in U_{n}\setminus B_{\frac{1}{3n}}(0)   \end{array}\right.$$
Note that $f_{n}$ is holomorphic in $U_{n}$. Therefore, by Runge's Theorem for compacts there is $g_{n}\in \mathcal{R}_{A_{n}}$ such that $\left\|f_{n}-g_{n}\right\|_{K_{n}}<\frac{1}{2n}$. But, by Lemma $\bigstar$ for $r_{n}=n+\frac{1}{3n}$, $g_{n}$ can be approximated uniformly on $K_{n}$ by polynomials. So, there exist a polynomial $P_{n}$ such that $\left\|g_{n}-P_{n}\right\|_{K_{n}}<\frac{1}{2n}$. Therefore, $$\left\|f_{n}-P_{n}\right\|_{K_{n}}<\frac{1}{n} \: \mbox{ for all } n=1,2,\ldots,n.$$
Therefore,  $(P_{n})_{n\in\mathbb{N}}$ is a sequence of polynomial such that $P_n(0)=1$ for each $n$, and $\lim_{n\rightarrow \infty}P_{n}(z)=0$  for all $z\in \mathbb{C}\setminus \left\{0\right\}$. Questions: I want to know if there is any mistake in my test. In addition, I want to know if I am correctly applying the theorems statements. If my proof has mistakes I would like you to give me some hint to complete the proof correctly.","['complex-analysis', 'alternative-proof', 'proof-verification']"
1777589,"$f:\mathbb R^2 \to \mathbb R$ be a function , $|f(x)-f(y)|\ge 3\|x-y\| , \forall x,y \in \mathbb R^2$ ; is $f(\mathbb R^2)$ open in $\mathbb R$?","Let $f:\mathbb R^2 \to \mathbb R$ be a function such that $|f(x)-f(y)|\ge 3\|x-y\| , \forall x,y \in \mathbb R^2$ , then is it true that $f$ maps open sets of $\mathbb R^2$ to open sets of $\mathbb R$ ? I can show that $f$ maps open sets to open sets in $f(\mathbb R^2)$ , so to prove the claim we only need to show that $f(\mathbb R^2)$ is open in $\mathbb R$ . Please help . Thanks in advance","['multivariable-calculus', 'metric-spaces', 'analysis', 'open-map']"
1777635,"How can I Show that, $\arcsin\left(\frac{b}{c}\right)-\arcsin\left(\frac{a}{c}\right)=2\arcsin\left(\frac{b-a}{c\sqrt2}\right)$","Where $c^2=a^2+b^2$ is Pythagoras theorem. Sides a,b and c are of a right angle triangle. Show that, $$\arcsin\left(\frac{b}{c}\right)-\arcsin\left(\frac{a}{c}\right)=2\arcsin\left(\frac{b-a}{c\sqrt2}\right)$$ How do I go about proving this identity? Can anybody help? I know of the arctan.",['trigonometry']
1777650,Which matricies are a product of projections?,"I believe that if $A$ is an $n$ by $n$ matrix over $\mathbb{R}$, then $A$ can be written as a product of projections as long as $A$ is not invertible. However, I don't know how to prove this. By projection I mean a matrix $P$ which satisfies $P^2 = P$. I know how the show this if $n = 2$, however the method involves explicitly calculating such a representation. I think it would be extremely messy to generalize this and hope that someone finds a simpler solution.",['linear-algebra']
1777652,"Show that, $2\arctan\left(\frac{1}{3}\right)+2\arcsin\left(\frac{1}{5\sqrt2}\right)-\arctan\left(\frac{1}{7}\right)=\frac{\pi}{4}$","Show that, $$2\arctan\left(\frac{1}{3}\right)+2\arcsin\left(\frac{1}{5\sqrt2}\right)-\arctan\left(\frac{1}{7}\right)=\frac{\pi}{4}$$ There is a mixed of sin and tan, how  can I simplify this to $\frac{\pi}{4}$ We know the identity of $\arctan\left(\frac{1}{a}\right)+\arctan\left(\frac{1}{b}\right)=\arctan\left(\frac{a+b}{ab-1}\right)$",['trigonometry']
1777665,A question on the cartesian product of two power sets for notation,"I had a question with respect to the notation for the cartesian product of two power sets. For instance, suppose that $A = \{1\}, B = \{2\}$ and one were to determine the cartesian product of two sets for $\mathcal{P}(A) \times \mathcal{P}(B)$ and $\mathcal{P}(A \times B)$, then would it be written as: $\mathcal{P}(A) \times \mathcal{P}(B) = \{(\emptyset, \emptyset); (\emptyset,2); (1,\emptyset), (1,2)\}$ Or would one write it as the latter $\mathcal{P}(A) \times \mathcal{P}(B) = \{(\emptyset, \emptyset); (\emptyset,\{2\}); (\{1\},\emptyset), (\{1\},\{2\})\}$ ? I assume that it would be the latter case right ? Also, what exactly would the $\mathcal{P}(A\times B)$ be in terms of notation (I do know that $\mathcal{P}(A \times B) = \{ \emptyset, A \times B\}$ but am a bit unsure about how to list the elements). Advice would be appreciated, thank you",['elementary-set-theory']
1777765,Finding value of a definite integral,Question: Find the value of: $$\frac{100}{\ln2}\int_0^1\frac{1-x^{99}}{(1+x)(1+x^{100})}dx$$ I'm not sure where how to approach this question. A hint would be appreciated.,"['integration', 'definite-integrals']"
1777790,What do you call a function $f$ such that $f(f(x))=x$?,"What is the name of the property of a function that yields the original result when done twice in a row: $$f(f(x)) = x?$$ I'm pretty sure there is a word for these functions, but I haven't been able to find it.",['functions']
1777805,Will this function be odd?,"Question: If $f:R\to R$ is an invertible function such that $f(x)$ and $f^{-1}(x)$ are symmetric about the line $y = -x$, then: A) $f(x)$ is odd B) $f(x)$ and $f^{-1}(x)$ may not be symmetric about $y = x$ C) $f(x)$ may not be odd D) None of these Purely by intuition, I'd say that $f(x)$ will be an odd function. Is this right? If it is, how can I prove this?","['functions', 'inverse']"
1777807,"If $f\circ f\circ f=id$, then $f=id$ [duplicate]","This question already has answers here : If $f^3=\rm id$ then it is identity function [duplicate] (2 answers) 3rd iterate of a continuous function equals identity function (3 answers) Closed 8 years ago . Let $f$ a continuous function on all $\mathbb R$. How can I prove that if $f\circ f\circ f=id$, then $f=id$ ? I really have no idea.","['functional-equations', 'real-analysis', 'calculus', 'functions']"
1777856,"Solving the ""Spider and Fly problem"" using calculus","As part of my homework I've the following problem: Find the shortest path from corner $S$ to corner $F$ (the spider should walk on the surface). I have to use calculus to solve the problem (more specifically using the absolute min/max theorems). I'm struggling to come up with a ""primary function"" to derive and apply the absolute max/min theorems. My guess is that i have to find the shortest path from corner $S$ to the end of the common edge (between the planes) and add to that the shortest path from that edge the corner $F$, but i'm unable to construct appropriate function (should i use the distance formula?). Thanks.",['calculus']
1778005,"$\{0,1\}$-matrix and permutation matrices","A permutation matrix is a square matrix with exactly one $\textbf{1}$ in each row and column, and zeros in all other positions of the matrix. Let $M$ be an $n \times n$ $\{0,1\}$ -matrix with exactly $m$ ones in each row and column. Prove that $M$ can be written as the sum of $m$ permutation matrices. I saw my lecturer about this problem and the hint he gave me was to think about decompositions of bipartite graphs into perfect matchings. For the life of me I don't really understand what he means by that nor do I even know how to get started on the question. Any help would be greatly appreciated.","['graph-theory', 'permutation-matrices', 'matrices', 'combinatorics', 'bipartite-graphs']"
1778022,Algebraic variety determined by closed points,"I am in the process of understanding the importance of the closed points of algebraic varieties (taking the scheme point of view). I ask myself the following question: if varieties $X$ and $Y$ over a field $k$ have closed points in bijection, then are ALL points of $X$ in bijection with the points of $Y$?. Edit: I am only interested in projective varieties.",['algebraic-geometry']
1778041,Continuity of matrix product with respect to matrix norm?,"I'm trying to teach myself about ordinary differential equations with an old script and I'm struggling with this problem: Show that the matrix product is continuous with respect to
the matrix norm. That is, if $A_j → A$ and $B_j → B$ we have $A_j\cdot B_j → AB$. My problem is that I don't even understand what the limit of $A_j\cdot B_j$ has to do with the matrix norm. Any help would be greatly appreciated!","['matrices', 'normed-spaces', 'continuity']"
1778048,Counting the number of Latin squares,Counting the number of latin squares is a difficult problem. I understand that the common used formula is $n!(n-1)!$ (the number or reduced latin squares). As seen here and in many other pages you can google. But I was wondering if anyone can explain how this works? Is there a formula or method for calculating the number of reduced latin squares? Also how do the numbers $n!(n-1)!$ come about? It is because there are that many different combinations of numbers we can have in the first row and column?,"['combinatorics', 'latin-square']"
1778053,Limit of $n-1$ measure of the boundary of a sphere,"The measure of a sphere of radius $R$ centered in $0_{\mathbb{R}^n}$ in $\mathbb{R}^n$ is
\begin{array}{l l}\int_{B_0(R)}dx_1\ldots dx_n & =\int_0^R\rho^{n-1}d\rho \int_{-\frac{\pi}{2}}^{\frac{\pi}{2}}\cos^{n-1}{\varphi_1}d\varphi_1\ldots\int_{-\frac{\pi}{2}}^{\frac{\pi}{2}}\cos{\varphi_{n-1}}d\varphi_{n-1}\int_{0}^{2\pi} d\theta \\ & =\omega_n \int_0^R\rho^{n-1} d\rho 
\end{array}
where $\omega_n$ is the $n-1$ measure of the boundary of the sphere. We can calculate the integral of the function $e^{-||x||^2}$ over $\mathbb R^n$ as
$$\int_{\mathbb{R}^n}e^{-||x||^2}dx_1\ldots dx_n=\int_{\mathbb R^n}e^{-x_1^2-\ldots-x_1^n}dx_1\ldots dx_n=\int_{-\infty}^{+\infty}e^{-x_1^2}dx_1\cdot \ldots \cdot \int_{-\infty}^{+\infty}e^{-x_n^2}dx_n=\pi^{\frac{n}{2}} $$
This integral can also be calculated by observing that $e^{-||x||^2}$ is a radial function: in fact
$$\int_{\mathbb R^n}e^{-||x||^2}=\omega_n\int_{\mathbb R^{n}} e^{-\rho^2}\rho^{n-1}d\rho\stackrel{\rho^2=t}{=}\frac{\omega_n}{2}\int_{\mathbb R^n}e^{-t}t^{\frac{n}{2}-1}dt=\frac 12 \omega_n \Gamma\left (\frac{n}{2}\right )$$
This yields the equality
$$\omega_n=\frac{2\pi^{\frac{n}{2}}}{\Gamma\left (\frac{n}{2}\right )}=\frac{\pi^{\frac {n-1}{2}}2^{\frac{n+1}{2}}}{n!!}$$
Clearly, we have 
$$\lim_{n \to \infty}\omega_n=0$$
How can we interpret such result in a geometrical way? Is there any intuitive explanation of this fact?","['intuition', 'limits', 'spheres', 'integration', 'measure-theory']"
1778109,"Sequence of random variables, mean zero, convergence to -infinity","What would be an example of a sequence $(X_k)$ of independent random variables with zero mean such that
  $$\frac{1}{n} \sum_{i=1}^{n} X_{i} \xrightarrow[\mbox{almost surely}]{n \to \infty}-\infty\ ?$$ My thoughts: I guess this is supposed to be a counterexample to the strong law of large numbers. I know that the variance of my sequence needs to be unbounded, because otherwise that sequence would fulfill all conditions of the SLLN.
I have found both, sequences that fulfill independency and sequences that fulfill the second condition, but i could not imagine any sequence that fulfills both of them. One idea was to use the Cantor, but I haven't found anything useful.","['law-of-large-numbers', 'independence', 'probability-theory', 'sequences-and-series', 'random-variables']"
1778110,Show that the permutation $(1 \space 2 \space 3)$ can not be a cube of any element of $S_n.$,"Here is my try: If there exists $a \in S_n$ such that $a^3=(1 \space 2 \space  3)$, then $a^9=e$ where $e$ is identity in $S_n$. Then $o(a)=9$. I don't know how to proceed further. Can anyone provide me a hint? Thanks.","['finite-groups', 'abstract-algebra', 'permutations', 'group-theory', 'symmetric-groups']"
1778157,"Is the charateristic function $\chi _{\Omega }$ in the Sobolev space $W^{1,2}_{0}(\Omega)$?","Given $\Omega$ is a bounded, $C^1$ domain in $\mathbb{R}^n$. $\chi _{\Omega }(x)$ is the characteristic function of $\Omega$. I have done the followings: We can get $\chi _{\Omega }(x) \in L^2(\Omega)$ for all $n \in \mathbb{N}$ quite easily. The next thing is to show the existence of the weak derivative of $\chi_{\Omega}$. For $n=1$, $\Omega$ is an open interval. Let $\phi \in C_{c}^{\infty }(\Omega)$ be an arbitrary test function. We have $\int_{a}^{b}\chi _{(a,b) }\phi 'dx=\int_{a}^{b}\phi'dx =\phi(b)-\phi(a)=0$ So $\int_{a}^{b}\chi _{(a,b) }\phi 'dx=-\int_{a}^{b}0.\phi dx$, and the weak derivative of $\chi_{\Omega}$ is $0$. For $n\geq 2$, I get stuck and don't know if $\chi_{\Omega}$ has the weak derivative or not. Thank you very much for your help.","['functional-analysis', 'lebesgue-integral', 'sobolev-spaces']"
1778226,How quickly do spheres get huge as the dimension grows?,"Let $\varepsilon > 0$. Let $k_d(\varepsilon)$ be the minimum number of balls $B(x, \varepsilon) \subset \mathbb{R}^d$, $x \in \mathbb{S}^{d-1}$, w.r.t. the usual metric in $\mathbb{R}^d$, needed in order for the balls to cover $\mathbb{S}^{d-1}$. Is there a neat way to calculate $k_d(\varepsilon)$? I'm interested in the rate at which it increases as $d$ grows. For example, the ratios $k_{d+1}(\varepsilon) / k_d(\varepsilon)$, would suffice. So far, I have tried to look at regular polygons with vertexes on $\mathbb{S}^{d-1}$ and areas of spherical caps around $x$ in comparison to the area of $\mathbb{S}^{d-1}$, but things tend to get quite messy: For example with the spherical caps you end up looking at regularized incomplete Beta functions. If somebody has a slick way to approach this, I would appreciate it if they shared. Of course literary references to something related to this would be great as well. Thanks! EDIT: It turns out that people have been seriously working on optimal spherical coverings. However, they study something called ""covering density"" which I'm not instantly sure how to turn into a number of spheres.",['geometry']
1778285,$f(nx)\to 0$ as $n\to+\infty$,"Let $f:\mathbb R^+\to\mathbb R^+$ be a continuous function, and let $I$ be a subset of $\mathbb R^+$ such that the following property holds: For any $x\in I$, $f(nx)\to 0$ as $n\to+\infty$. Intuitively, if $I$ is 'big' enough, $f$ necessarily tends to $0$ at infinity, but it happens to not always be the case. I am investigating whether it can be said, for various $I$, if $f(x)\to 0$ as $x\to+\infty$. As a first example, consider $I=[0,1]$. Set $\varepsilon>0$, and consider the closed sets $F_n=\{x\in I\mid f(kx)<\varepsilon,\forall k\geq n\}$. Their union is $[0,1]$, and thus, thanks to the property of Baire, one of them has non-empty interior, i.e. $[a,b]\in F_n$ for a certain $n$. It follows that for all $k\geq n$ and $x\in[ka,kb]$, $f(x)<\varepsilon$. But since $b>a$, $\bigcup_{k=n}^\infty [ka,kb]$ contains a half-line, and $\limsup_{x\to\infty} f(x) \leq \varepsilon$. Since the reasoning holds for any $\varepsilon>0$, we conclude that $f$ does, indeed, tend to $0$ at infinity. The same proof actually works for all $I$ with non-empty interior. The result is false in higher dimensions when $I$ contains a neighbourhood of the origin, as a simple counter-example can be constructed using a parabola. What happens when $I\subset \mathbb R$ is smaller? Consider the following sets: $I$ is any measurable set with empty interior, but with Lebesgue measure >0. In that case, one of the aforementioned $F_n$ has positive Lebesgue measure. $I=(0,1)\cap C$, where $C$ is the Cantor set (or another uncountable set). Then, one of the $F_n$ has to be uncountable aswell, $I=\{1/k,k\in\mathbb N\}$ or $I=(0,1)\cap \mathbb Q$, both of these being equivalent. I provided an answer below for this one, and actually for any countable set; such a function $f$ does not necessarily converge to $0$. In any of these cases, can anything be said about the behaviour of $f$ at infinity? Bonus question: what is the minimum condition for $I$ (if there is one) so that $f$ has to converge to $0$? I thought about mimicking the proof of the first example when $I$ has empty interior but positive Lebesgue measure. If there exists an integer $n$ and a non-trivial interval $[a,b]$ such that $|F_n\cap [a,b]|=b-a$, then $f\leq\varepsilon$ on a set that is dense on a half-line, and thus, using continuity, tends to $0$. Sadly, such an interval may not exist, since the closure of $F_n$ could very well be of empty interior, like a generalized Cantor set.","['real-analysis', 'functions', 'limits']"
1778292,Polar decomposition-uniqueness,"Let $A$ be arbitrary $n \times n$ matrix (with complex entries). Then it can be expressed as $A=UP$ where $P=\sqrt{A^*A}$ and $U$ unitary. If $A$ is invertible then $U$ is uniquely determined. If $A$ is real then $P=\sqrt{A^TA}$ and $U$ is orthogonal. I'm interested in the following question: Is it always possible for a singular matrix $A$ to produce two different unitary matrices $U_1,U_2$ such that $A=U_1P=U_2P$ where $P$ as before?","['matrices', 'linear-algebra']"
1778310,"Banach Contraction mapping of $\Phi(f)(x)=\int_0^x \frac{1}{1+f(t)^2}dt$ , find a fixed point.","Let $(X,d)$ be metric space with $d(f,g)=\sup |f(x)-g(x)|$ where $X$ is the set of continuous function on $[0,1/2]$ . Show $\Phi:X\rightarrow X$ $$\Phi(f)(x)=\int_0^x \frac{1}{1+f(t)^2}dt$$ has a unique fixed point $f(0)=0$ . b) Show that it satisfies $\frac{df}{dx}=\frac{1}{1+f(x)^2}$ My attempt: I assumed $[0,1/2]$ is complete. I need to show that: $$d(\Phi(f)(x),\Phi(g)(x))=\sup \Big|\int_0^x \frac{1}{1+f(t)^2}dt-\int_0^x \frac{1}{1+g(t)^2}dt\Big|\leq\alpha d(f,g)$$ Now, $$\sup \Big|\int_0^x \frac{1}{1+f(t)^2}dt-\int_0^x \frac{1}{1+g(t)^2}dt\Big|=\sup \Big|\int_0^x \frac{1}{1+f(t)^2+g(t)^2}dt\Big|$$ Now ideally I need to somehow change this integral to include $d(f,g)=\sup|f(x)-g(x)|$ , but I don't know how. Then I would integrate, and get the integration constant to be $<1$ , which will be my contraction constant.","['banach-fixed-point', 'integration', 'ordinary-differential-equations', 'analysis']"
1778313,A version of Bezout's Theorem,"I have read the following version of Bezout's Theorem, but I don't get to understand how it implies the classical version. Let $F,G\in K[X_{0},X_{1},X_{2}]$ be non-constant homogeneous polynomials of respective degrees $d$ and $e$ with no common irreducible components. Then, there exists a ring $A$ such that 
  $$
\mathrm{Proj}\left(\frac{K[X_{0},X_{1},X_{2}]}{\langle F,G\rangle}\right)\simeq \mathrm{Spec}(A)
$$
  and $\dim_{Krull} (A)=0$. By Noether's Theorem $A$ is a finite dimensional $K$-vector space. Furthermore, $\dim_{K}(A)=d\cdot e$. Now, how could we prove that this imply $\#\mathrm{Spec}(A)=d\cdot e$ (or less, depending on how the multiplicity works in this version)? $\mathbf{Remark}.$ The reason why there exists a ring $A$ such that 
$$
\mathrm{Proj}\left(\frac{K[X_{0},X_{1},X_{2}]}{\langle F,G\rangle}\right)\simeq \mathrm{Spec}(A)
$$
and $\dim_{Krull} (A)=0$ is because $\mathrm{Proj}\left(\frac{K[X_{0},X_{1},X_{2}]}{\langle F,G\rangle}\right)$ has dimension $0$, and therefore it is affine.","['algebraic-curves', 'algebraic-geometry']"
1778337,Abelian Galois group of $f$ implies splitting is simple extensions by a root of $f$.,"Given an irreducible polynomial $f\in \mathbb{Q}[x]$ with Abelian Galois group, I would like to show that the splitting field $K$ over the rationals can be written as a simple extension $\mathbb{Q}(\alpha)$, where $\alpha$ is a root of $f$. I know that any finite extension can be written as a simple extension, but I fail to see how the commutativity of the Galois group allows this adjoined element to be a root of $f$. Can we use the fact that a normal subgroup of the Galois group has a fixed field that is Galois over $\mathbb{Q}$, and thus every intermediate field $\mathbb{Q}\subset E \subset K$ is Galois?","['abstract-algebra', 'galois-theory', 'field-theory']"
1778343,How can I find Limit of integral,How can I find: $$\lim_{x\to0}  \int_{0}^{x} e^{-t}\mathrm{d}t$$ I think to use fundamental method of calculus? $F(x)= \int_{0}^{x} e^{-t}\mathrm{d}t$ Then $F'(x)=-e^{-t}$ But I don't get any result! Then I think to integrate then take a limit $$ \int_{0}^{x} e^{-t}\mathrm{d}t= 1-e^{-x}$$ $$\lim_{x\to0} \int_{0}^{x} e^{-t}\mathrm{d}t=\lim_{x\to0} (1-e^{-x})=??$$ But also I don't know how can I find this limit.,"['real-analysis', 'integration', 'limits']"
1778344,Two complementary continued fractions that are algebraic numbers,"Define the two similar continued fractions, $$x=\cfrac{1}{km\color{blue}+\cfrac{(m-1)(m+1)} {3km\color{blue}+\cfrac{(2m-1)(2m+1)}{5km\color{blue}+\cfrac{(3m-1)(3m+1)}{7km\color{blue}+\ddots}}}}\tag1$$ $$y=\cfrac{1}{km\color{blue}-\cfrac{(m-1)(m+1)} {3km\color{blue}-\cfrac{(2m-1)(2m+1)}{5km\color{blue}-\cfrac{(3m-1)(3m+1)}{7km\color{blue}-\ddots}}}}\tag2$$ For integer $m>1$, it seems $(1)$ and $(2)$ are algebraic numbers . For $(1)$ and the special case $k=1$, then, $$x=\tan\Big(\frac{\pi}{4m}\Big)=\frac{1}{4m}\frac{\Gamma\Big(\frac{2m-1}{4m}\Big)\Gamma\Big(\frac{2m+1}{4m}\Big)}{\Gamma\Big(\frac{4m-1}{4m}\Big)\Gamma\Big(\frac{4m+1}{4m}\Big)}\tag3$$ and is adapted from Nicco's cfrac in this post . For $(2)$ and general $k\neq1$, $$y =\tanh\Big(\frac{1}{2m}\,\log (R)\Big)= \frac{R^{1/m}-1}{R^{1/m}+1};\;\;R=\frac{k+1}{k-1}\tag4$$ and solves , $$\frac{ (1+y)^{m}-(1-y)^{m}}{(1+y)^{m}+(1-y)^{m}}=\frac{1}{k}\tag5$$ hence $x,y$ are radicals . Questions: What is the formula for $x$ for general $k>1$? Does $y$ also have a formula in terms of gamma functions ?","['hyperbolic-functions', 'trigonometry', 'closed-form', 'continued-fractions', 'gamma-function']"
1778357,Show that $\tan x +\frac{1}{2}\tan \frac{x}{2}+\dots + \frac{1}{2^n}\tan \frac{x}{2^n} = \frac{1}{2^n}\tan \frac{x}{2^n}-2\cot(2x) $,"Show that $$\tan x +\frac{1}{2}\tan \frac{x}{2}+\dots + \frac{1}{2^n}\tan \frac{x}{2^n} = \frac{1}{2^n}\tan \frac{x}{2^n}-2\cot(2x), \quad (n=0,1,\ldots). $$
I tried to prove this using induction but with no result. I'm not sure how to begin to solve this.",['trigonometry']
1778373,Blow up of an ideal in $\Bbb C^2$,"As described in these notes, I am trying to compute the blow up of $\mathbb C^2=\text{ Maxspec }\mathbb C[x,y]$ along the subvariety corresponding to the ideal $\langle\ x^2,y\ \rangle$ but I am having trouble with the steps. Now the blow up is given by the closure of the image of the map $f$ defined as follows - $$f:\mathbb C^2\setminus\mathcal Z(x^2,y)\to \mathbb C^2\times \mathbb P^1\quad\text{is given by}\quad (a,b)\mapsto(a,b,[a^2:b])$$ Now if $[x_0:x_1]$ are the homogeneous coordinates of $\mathbb P^1$ then $\mathbb {C^2\times P^1}$ is covered by $\mathbb C^2\times U_0$ and $\mathbb C^2\times U_1$ where $U_i=\{\ [a_0:a_1]\ |\ a_i\neq0\ \}$ . Let $A_0=\overline{\text{ Im }f}\cap(\mathbb C^2\times U_0)$ and $A_1=\overline{\text{ Im }f}\cap(\mathbb C^2\times U_1)$ then the blow up is obtained by appropriately glueing $A_0$ and $A_1$ . However I am unable to explicitely write this ""appropriate glueing"" without a proper description of $A_0$ and $A_1$ . By that I mean I want to write the $A_i$ as the vanishing of some ideals in $\mathbb {C^2\times P^1}$ . This way I can look at glueing maps at the coordinate ring level. Could someone hepl me describe $A_0$ and $A_1$ ? Thank you.","['algebraic-geometry', 'blowup']"
1778382,Evaluating the integral $\int \frac{x^2+x}{(e^x+x+1)^2}dx$,"Evaluate $$\int \frac{x^2+x}{(e^x+x+1)^2}dx$$ I tried converting in the form of Quotient rule(seeing the square in the denominator), neither am I able to make the denominators' derivative in the numerator. Some hints would be great. Thanks.","['real-analysis', 'calculus', 'closed-form', 'indefinite-integrals', 'integration']"
1778389,Holomorphic function $f\left(\frac{1}{2n}\right)=f\left(\frac{1}{2n-1} \right)=\frac{1}{n}$,"Does there exists a holomorphic function $f:B_2(0)\to\mathbb C$ such that $$f\left(\frac{1}{2n}\right)=f\left(\frac{1}{2n-1}\right)=\frac{1}{n},\;\forall n\in\mathbb Z^+.$$ I do not have an idea?","['complex-analysis', 'functions']"
1778400,"Find the equation of the tangent to the parabola $y=x^2$, if the x-intercept of the tangent is 2","I'm trying to solve this problem: Find the equation of the tangent to the parabola $y=x^2$. If the x-intercept of the tangent is 2. All what I can think of is finding the slope which is $dy/dx = 2x$ so the tangent line equation would be $y-y_0 = 2x(x-x_0)$ I don't know exactly where to go from here, should I plug in intercept points? $y-0 = 2x(x-2)$","['derivatives', 'slope', 'tangent-line', 'calculus']"
1778441,Spectrum of Laplace operator with potential acting on $L^2(\mathbb R)$ is discrete,"Consider an operator $H=-\Delta +U(x)$ on $L^2(\mathbb R)$ for a function $U(x): \mathbb R \to \mathbb R$ that tends to $+\infty$ as $|x|$ grows. These kinds of operators appear all over non-relativistic quantum mechanics as Hamiltonians. A statement that I have read is that such an operator has a discrete spectrum, and it was presented as being a standard result. How can this be proven? (I'm sorry if this is a lazy question, it seems to be common knowledge so one would expect proofs to abound like sand at the beach, but I couldn't find them on this website.)","['functional-analysis', 'laplacian', 'spectral-theory', 'hilbert-spaces']"
1778473,How to compute $\int_0^1\frac{\ln(x)}{1+x^5}dx$?,"Let $\phi$ denote the golden ratio $\phi=\frac{1+\sqrt5}{2}$.
  How can I prove this sum?
  $$\sum_{n=0}^{\infty}(-1)^n\left[\frac{\phi}{(5n+1)^2}+\frac{\phi^{-1}}{(5n+2)^2}-\frac{\phi^{-1}}{(5n+3)^2}-\frac{\phi}{(5n+4)^2}\right]=\left(\frac{2\pi}{5}\right)^2$$ My try: Change  the sums into an integrals:
$\sum_{n=0}^{\infty}\frac{(-1)^n}{(5n+1)^2}=\int_0^1\frac{-\ln(x)}{1+x^5}dx$ Can somebody give a hint how on to integrate this integral. Try substitution by letting $u=\ln(x)$ is not working and integration by part is making it more complicated than before. What kind of substitution should I be using?","['integration', 'sequences-and-series']"
1778490,Reversing the $T(n) = \frac{n(n+1)}{2}$ formula,"Can someone reverse this formula? Sorry if it's too basic, I'm an old guy and my math is rusty :-D $s =\frac{n(n+1)}{2}$ If it ain't clear, by reverse I mean obtaining the value of n by providing s Thanks","['algebra-precalculus', 'summation']"
1778553,How many $5$ card poker hands contain at least $1$ red and $1$ black card?,How many $5$ card poker hands contain at least $1$ red and $1$ black card? I used inclusion-exclusion to calculate my answer. The number of total poker card hands are:$$52\choose 5$$I have $26$ red cards and $26$ black cards as my $A$ and $B$ set. I also need the total number of hands that have flushes as my $(A\cap B)$. So my formula is as follows:$$1red1black=U -A+B-(A\cap B)$$So:$$1red1black={52\choose 5}-26+26-\left(2\cdot \left({13\choose 5}{4\choose 1}-{10\choose 1}{4\choose 1}\right)\right)$$$$={52\choose 5}-2\cdot \left(4{13\choose 5}-40\right)$$Is this line of thinking correct?,"['combinations', 'binomial-coefficients', 'inclusion-exclusion', 'permutations', 'combinatorics']"
1778606,Curve with all normal planes having a common point,"Question: Consider a regular curve parametrized by arclength. If all of the normal planes have a common point then this curve lies on a sphere. I guess this has to do with the Frenet frame, but don't know how to proceed...","['frenet-frame', 'differential-geometry']"
1778627,Ellipsoid moment of inertia matrix,"Some background info: torque $\tau$ is defined as $$\tau = I*d\omega$$ Where $I$ is the moment of inertia matrix and $d\omega$ is an object's rotational acceleration. As I understand it, the inertia matrix acts just like mass in that it counteracts the torque (for example, if an object is spinning around the x axis, a big value of $I_{xx}$ means that the object needs more torque around the x axis in order to spin). However, angular momentum $M$ can be defined as $$M=I * \omega$$ Where $\omega$ is the rotational velocity. So it seems that torque is the time derivative of angular momentum. Using these facts, how would I find the moment of inertia matrix for an ellipsoid with uniform density of the form $$\frac{x^2}{a}+\frac{y^2}{b}+\frac{z^2}{c}≤9$$ with $a≠b≠c≠0$? Would I have to use spherical coordinates somehow? I'm not given any torque or angular velocity information. Any guidance is appreciated.","['multivariable-calculus', 'classical-mechanics', 'physics', 'elliptic-integrals']"
1778643,Orientability of the level set of a map between abstract oriented manifold,"Let M and N be oriented manifold and let $f:M\to N$ be a smooth map between them. Suppose $y \in N$ is a regular value for $f$, how can we show that $f^{-1}(y)$ is orientable? I've seen a solution for the case $N = \mathbb{R}$, but I fail in generalizing that proof.","['manifolds', 'smooth-manifolds', 'differential-geometry']"
1778664,Every subset of a finite set is finite (hopefully this would be the last time),"I am so sorry for posting about it more than one time but this is my 4th revision for this proof and I want some feedback.. Note : $[n]$ is $\{1,2,3,4,\ldots,n\}$, a finite set Prop: Every subset of a finite set is finite Proof: Let $A,B$ sets and suppose $B$ is a finite set. Also let $A \subseteq B$ If $A = \varnothing$, then it is finite If $B = \varnothing$, then also $A = \varnothing$, which is finite. So we suppose $A \neq \varnothing$ and $B \neq \varnothing$. Then there exstis a bijection $f: B \to [n]$ Since $A \subseteq B$, the inclusion mapping $I : A \to B$ defined on $f(a) = a$ for $a \in A$ exists. Note $I(a_1) = a_1$ and $I(a_2)=a_2$ and if we suppose $I(a_1)=I(a_2)$, then $a_1 = a_2$, and therefore $I$ is an injection. Then we can have $f \circ I: A \to [n]$, which is injective. We need to prove that there is a bijection between the set $A$ and subset of $[n]$ So, let $p(n)$ be the statement that ""If $A \subseteq [n]$, $A$ has a bijection with $[m]$ for some $m \in Z_{\ge0}$ such that $m \le n$"" Base case $(n=1)$ : If $A \subseteq [1]$, since we suppose $A \neq \varnothing$, $A$ has a bijection with $[1]$ Induction part : Now let $k \in N$ and suppose $p(k)$ holds. Now we want to prove that $p(k+1)$, that is, ""If $A \subseteq [k+1]$, $A$ has a bijection with $[m]$ for some $m \in Z_{\ge0}$ such that $m \le k+1$"" Then if $A $ has $k+1 $ elements, it is done. It has a bijection with $[k+1]$. If $A \subseteq [k]$, by the induction hypothesis, $A$ has a bijection with $[m]$ for $m \le k$. Hence every subset of finite set is finite.","['real-analysis', 'elementary-set-theory']"
1778665,Why is the wedge product of a 1-form and itself $0$? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Why is the wedge product of a 1-form and itself $0$?
Why doesn't this apply to 2-forms?","['calculus', 'exterior-algebra']"
1778688,Are probability measures weak-* closed?,"Non-duplicates This is in a different setting, and this only deals with compact spaces which is the easy case. Now for the question. Let $X$ be a locally compact Hausdorff space. $\mathcal{C}_0(X)$ is the set of continuous functions $f:X\to\mathbb{R}$ that go to zero at infinity, i.e. are less than any $\epsilon$ outside an appropriate compact set. One of the many Riesz representation theory gives an isometric isomorphism between $\mathcal{C}_0(X)$ and the space $M(X)$ of all complex regular Borel measures on $X$. So Banach-Alaoglu shows the ball of $M(X)$ is compact in the weak-* topology. Consider $P(X)\subseteq\{\mu:\|\mu\|\leq1\}$ the set of positive probability measures, i.e. $P(X)=\{\mu\in M(X):\mu\geq0,\mu(X)=1\}$. Is $P(X)$ weak-* compact? $P(X)$ is contained in the ball, so if it is weak-* closed, it is closed in a compact set, hence compact. If $X$ is compact, certainly $f\equiv1$ is in $\mathcal{C}_0$, so if $\mu_\alpha$ is a net of probabilities converging to $\mu$, $1=\mu_n(X)=\mu_n(f)\to\mu(f)=\mu(X)$, and since limits preserve inequalities for any $g\geq0$ $\mu(g)\geq0$, so $\mu\in P(X)$. The argument for positivity works in general. The hard part with noncompact spaces is $\mu(X)=1$. It is fairly easy to prove $\mu(X)\leq1$: one merely has to work with $\epsilon$s and $\delta$s in an appropriate way. But I couldn't find any way to conclude $\mu(X)\geq1$. Proceeding by contradiction with $\mu(X)=1-\delta$ doesn't lead me anywhere. I googled for 1-2 hours and found nothing: wherever the weak-* closure was mentioned, it was just assumed. So how do I prove this last bit? Is $\mu(X)\geq1$? Or are there cases where it isn't? And if so, counterexamples?","['functional-analysis', 'weak-convergence', 'measure-theory']"
1778710,Finding and b in an equation with a floor function,"\begin{align}
    a^2 + ba + c &= 0 & \text{{No real roots.}}\\
    \lfloor a^2 \rfloor + ba + c &= 0 & \text{{At least one real roots.}}
\end{align} Are there any values of b and c that will make the given number of roots correct? The first thing I thought about doing was finding the discriminant .In order for the first equation to have no real roots, we must have $b^2 – 4c < 0$. That means that $b^2 < 4c$. 
I know that the discriminant of the second one must be 0 but I am not sure how to express it because a floor function is involved. What should I do? 
Will this approach get me anywhere or are there any better methods?",['number-theory']
1778713,Formal Notation for Finding Inverses of Functions,"Generally in most introductory university courses, finding the inverses of functions, is done in what seems to be to be a very haphazard way. Given any scalar function $f : \mathbb{R^n} \to \mathbb{R}$, what most people would do is say (and I put this here in as general a form as I can) : $$y = f(x)$$
and then do a swap of variables
$$x = f^{-1}(y)$$ But the only reason this 'swap' is done is because the function $f$ is mapping a set $A$ (it's domain) to another set $B$ (it's codomain). This can be represented as $$f : A \to B$$ and the inverse is simply $$f^{-1} : B \to A$$ But the swap of the of the variables only implicitly shows this, transformation of the function $f$ to $f^{-1}$, it does not formally show the reversal of the mapping of the sets (the domain and codomain). I will give an example below to further illustrate my point : Example : Find $f^{-1}(x)\ \  \text{of} \ \  f(x)=e^x$ This is what most professors, typically would do to find the inverse : $$y = f(x)$$
$$\implies y = e^x$$
$$\implies x = e^y$$
$$\implies ln(x) = ln(e^y)$$
$$\implies y = ln(x)$$
$$\implies f^{-1}(x) = ln(x)$$ As you can see in the example above, there is virtually no structure to the way the inverse function $f^{-1}$ has been computed, and leaves a lot to be desired in terms of formalism. This way of computing inverse functions, is what is commonly used by almost everyone, but I don't find it rigorous. Sure it does find the inverse function, but the process of finding it is very informal and unsatisfactory. My question is, what is the most formal notation/process for finding the inverses of functions? Given the example above (or a more general example), how would you go about finding the inverse $f^{-1}$ in the most formal and mathematically rigorous way? Furthermore how would you go about finding the inverse of functions in higher mathematics, (e.g in Category Theory)?","['abstract-algebra', 'functions', 'algebra-precalculus', 'inverse', 'category-theory']"
1778736,Is a function of $\mathbb N$ known producing only prime numbers?,"It is well known that a polynomial $$f(n)=a_0+a_1n+a_2n^2+\cdots+a_kn^k$$ is composite for some number $n$. What about the function $f(n)=a^n+b$ ? Do positive integers $a$ and $b$ exists such that $a^n+b$ is prime for every natural number $n\ge 1$ ? I searched for long chains in order to find out whether there is an obvious upper bound. For example $4^n+4503$ is prime for $n=1,\ldots,14$.","['number-theory', 'prime-numbers', 'functions', 'divisibility']"
