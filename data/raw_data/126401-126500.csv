question_id,title,body,tags
1922100,Elevator Talk on Topology,"I am interested in what others do when trying to give an elevator talk on their research interests, particularly on trying to explain what topology is. I am particularly interested in giving an elevator talk to someone whose knowledge does not exceed the standard high school mathematics curriculum. Currently I do one of two things: I like to talk about Topological Data Analysis as a cool application of what topology does. I can talk about how topology can be used to recover the shape of molecules and how important that can be to chemistry and biology. This works but I would like to have an explanation of what topology is, not just what it can do. I make a feeble attempt at describing topology as the study of shape, perhaps mentioning the old coffee mug and donut equivalence. I am hoping someone has come up with a better alternative to 2.","['topological-data-analysis', 'general-topology', 'differential-geometry', 'soft-question']"
1922138,Evaluate $\lim_{x\to0}\frac{e-(1+x)^\frac1x}{x}$ [duplicate],"This question already has answers here : Limit as $x\to 0$ of $\frac{(1+x)^{1/x}-e}{x}$ (6 answers) Closed 4 years ago . Somebody asked this and I think it's quite interesting as I couldn't figure out how to evaluate this but the Wolfram Alpha says its limit is $\frac e2$.
$$\lim_{x\to0}\frac{e-(1+x)^\frac1x}{x}$$
Could someone help here?","['calculus', 'limits']"
1922230,How to show that the set of open balls with rational centres and rational radii form a countable base for $\mathbb{R}^n$?,"There are questions on Math.SE that seem relevant, but I will explain why they do not answer my question: 1) $\mathbb R^n$ has countable basis of open balls? (Yes) : this question doesn't prove that rational centre/radii balls form a base; it proves that $\mathbb{R}^n$ has such a base 2) Open ball with rational radii forms a basis. : makes a claim that I do not know how to show (it is not obvious to me): Now let $B$ be an open ball with centre $a$, and irrational radius $\rho$. Then $B$ is the union of all the open balls with centre $a$ and rational radius $r\lt \rho$. 3) How to cover an open subset of $\mathbb{R}^n$ with balls? : the answer to this question gets me the closest, I think, but I am still having trouble with it. Let me break it down my issues: HINT: Every open set in $\mathbb{R}^n$ is a union of open (or closed) balls whose centres have rational coordinates and whose radii are rational; how many such balls are there? Alright, assuming that I can show that, I still don't know how to show its countable. My guess is I have to play around and find a bijective function that connects each ball with an integer. Is this the right approach? In case the first statement isn’t obvious, suppose that $B$ is the ball of radius $r$ about a point $x\in\mathbb{R}^n$. If $x$ has all rational coordinates, there’s nothing to be done. How is there nothing to be done? Don't we still have to show that $r$ (the radius) is rational? Otherwise there is a point $y$ with all coordinates rational inside the ball of radius $r/2$ centred at $x$. Why is this an obvious statement? I don't know how to begin to show it. Could a hint be provided here? Let $d$ be the distance between $x$ and $y$, let $q$ be a rational number such that $d<q<r/2$, and let $B'$ be the ball of radius $q$ centred at $y$; then $x\in B'\subseteq B$. This part I am totally good with. Anyway, so if I can show that there a countable number of such balls, then by definition of second-countability, $\mathbb{R}^n$ is second countable.",['general-topology']
1922263,Conditions for an order-embedding wrt $\mathbb{R}$,"I am trying to understand a proposition which goes like this: Let $(X,\precsim)$ be a nonempty totally preordered set. Let $(\hat{X}, \precsim)$ be the set of all equivalence classes in $(X,\precsim)$, i.e. $X$'s quotient set endowed with the same order as $X$ (thus clearly a totally-ordered set). Then $\exists f: \hat{X} \rightarrow \mathbb{R}$, where $f$ is order-embedding, iff $\exists X^* \subset \hat{X}$ such that $X^*$ is at most countable and order-dense (close-packed) in $\hat{X}$. ($\mathbb{R}$ is ordered as usual). I just can't understand how to prove this nor get any intuition why this is so. (The fact that it starts with a proset and not a toset is irrelevant to my lack of understanding, I just wanted to state it in full.) Edit: Order-embedding, not order-isomorphic. Sorry for the confusion. (bis)","['order-theory', 'elementary-set-theory']"
1922275,Show that this polynomial in two variables has no integer solutions,Consider the equation $15x^2 - 7y^2 = 16$.  Show that it has no integer solutions. Any hints or comments are welcome.,"['diophantine-equations', 'polynomials', 'roots', 'number-theory', 'quadratics']"
1922276,Derivatives Theorems for functions from $\mathbb{R}$ to a Banach Space,"The following are true for functions $f$ from $\mathbb{R}$ to $\mathbb{R^n}$: Suppose f is continuous, $f'$ exists in $(x-\delta,x) \cup (x,x+\delta)$ and 
$\lim\limits_{u \to x}{f'(u)} = l$ then $f'(x)=l$ Suppose $f'$ is continuous on $[a,b]$ then $\forall{\epsilon >0}$ $\exists \delta>0$ s.t.
$\forall x,t \in [a,b] $, $|x-t|<\delta \implies 
|{\frac{f(t)-f(x)}{t-x} - f'(x)}| < \epsilon$ Are they true for functions from $\mathbb{R}$ to a Banach space as well? These are from Baby Rudin Ch 5 Q 8,9, but he doesn't dicuss any generalizations. I'm not very familiar with theorems on Banach spaces, so I apologize if this is standard.","['functional-analysis', 'real-analysis', 'banach-spaces', 'derivatives']"
1922395,Proof of quadratic inequality using AM-GM,Proof of quadratic inequality using AM-GM,"['algebra-precalculus', 'inequality', 'a.m.-g.m.-inequality']"
1922406,"Affine Scheme of the form $X=Spec(R)$ for $R$ commutative ring, as the analogue of an affine variety $X$ with coordinate ring $R$","In this amazing notes http://www.mathematik.uni-kl.de/~gathmann/class/alggeom-2002/main.pdf pg.75 the author exlpains roughly the idea behind the notion of an affine variety and how does affiliate with that of an affine scheme. Now, my question has to do mostly with the remark 5.1.3 down from the definition of affine schemes. He says that for a given $f \in R$ we can see the latter as a function on $X$ in a standard sense, that is, for every $\mathcal{P} \in X$ we define $f(\mathcal{P})$ to be the value of the composition $R \rightarrow R/\mathcal{P} \rightarrow \mathbb{k}(\mathcal{P})$. That's exactly what I don't get. What kind of function is that? The values for any distinct $\mathcal{P} \in X$ has a different target. Can you please write me down explicitly what does he mean by that? I don't understand if for every $\mathcal{P} \in X$ we get something like a function $f_{\mathcal{P}}: R \rightarrow \mathbb{k}(\mathcal{P})$, or not. P.S. Excuse me if the latter isn't correct I'm just trying to get you what my problem is!","['schemes', 'affine-schemes', 'algebraic-geometry']"
1922420,How to understand the proof of $\mathbb{E}[X+Y] = \mathbb{E}[X] + \mathbb{E}[Y]$ with continuous random variables?,"$\newcommand{\E}{\mathbb{E}}$I'm studying Expectation, according to the book, for two continuous random variables, we have $$\E(X+Y)=\E(X) + \E(Y)$$ The proof is as follows. $$\E[X+Y] = \int^∞_{-∞}\int^∞_{-∞}(x+y)f(x,y)dxdy$$
$$= \int^∞_{-∞}\int^∞_{-∞}xf(x,y)dydx + \int^∞_{-∞}\int^∞_{-∞}yf(x,y)dxdy\tag1$$
$$= \int^∞_{-∞}xf_X(x)dx + \int^∞_{-∞}yf_Y(y)dy\tag2$$
$$= \E[X] + \E[Y]$$ How can we get (2) from (1)? More specifically, why $\int^∞_{-∞}f(x,y)dy=f_X(x)$?","['probability-theory', 'expectation', 'probability-distributions']"
1922434,Prove the space of bounded sequences is Banach,"http://www.math.ucla.edu/~tao/resource/general/121.1.00s/exam1sol.pdf Here is a proof, but I cannot fully understand why it does not give a proof that $x$ is a bounded sequence (i.e. $x$ is in the space). It seems that the proof only shows that the Cauchy sequence in the space converges to $x$. But $x$ is not shown to be definitely in the space.","['real-analysis', 'cauchy-sequences', 'proof-verification', 'functional-analysis', 'proof-explanation']"
1922447,Infimum of the Ky Fan metric achieved,"We have a probability space: $ (\Omega, \mathcal{A}, P)$ and random Variables $X,Y$. We define the Ky Fan metric as 
$$ 
d(X,Y):= \min \{\epsilon\ge 0\mid P(|X-Y|>\epsilon) \le \epsilon\}
$$ My question: Why is the infimum of the Ky Fan metric achieved and so the definition well defined? $T:=\{\epsilon\ge 0| P(|X-Y|>\epsilon) \le \epsilon\}$ I define a monoton decreasing sequence $ \epsilon_k \rightarrow d(X,Y) (k \rightarrow \infty)$  with $\epsilon_k \in T$. $P(|X-Y|> \epsilon_k) \le \epsilon_k \le \epsilon_j$ for all $ j <k$. For all $ j<k$ we have : $ P(\{\omega: |X(\omega)-Y(\omega)| > \epsilon_j)\}) \le P(\{\omega:|X(\omega)-Y(\omega)| >\epsilon_k)\}\le\dots \le P(\{\omega: |X(\omega)-Y(\omega)| > d(X,Y))\})$","['real-analysis', 'probability-theory', 'supremum-and-infimum', 'measure-theory', 'convergence-divergence']"
1922493,$M_1 \oplus R \simeq M_2 \oplus R$ and $M_1 \not\simeq M_2$,"I have the following problem: We had to prove that if $R$ is a principal ideal domain we can ""subtract"" $R$ in direct sums of $R$-modules, i.e. $M_1 \oplus R \simeq M_2 \oplus R$ implies $M_1 \simeq M_2$. Moreover we had the theorem that if $R$ is commutative (and not necessarily a PID) the rank of free R-modules is well-defined and had an example that this is not true for non-commutative rings. In particular, we obtain a counter example for above if $R$ is not commutative. I now wonder if there is an example of a commutative ring $R$ and $R$-modules $M_1, M_2$ such that $M_1 \oplus R \simeq M_2 \oplus R$ but $M_1 \not\simeq M_2$. In particular I wonder if there are integral domains and principal ideal rings which don't fulfill this property.","['abstract-algebra', 'modules', 'integral-domain']"
1922516,Tangents and roots to simultaneous equations.,"Straight line tangents I've been solving questions about linear tangents to curves and I noticed that when you create a simultaneous equation with a linear tangent you get a repeated root if it is tangent to a quadratic (and this is the only solution) and a repeated root (and one other root) when it is tangent to a cubic. { EDIT 1: Thinking about this a little more, I've realised that you can also have triple repeated roots where the line crosses the curve but has the same gradient as the curve where it crosses.} I was wondering if the number of repeated roots for a straight-line tangent to a curve is always two, and I thought about quartic curves and I think the roots you can get are: -2 equal roots that are real (tangent) and two complex roots -4 real roots: 2 are equal (tangent) and 2 different real rots (where the line crosses the curve) -2 pairs of equal roots (when the line is tangent to the curve at two points) Please correct me if I am wrong, but I think that with a straight-line tangent it always just has a double root at the point where it is tangent, and it may or may not have other roots... But I have also only thought about this using sketches of cubic and quartic curves. I was wondering if there was another way to see why this would be the case? Also, what would happen if you get a triple root? What does this mean? EDIT 2: Please scrap all of what I said above! I'm leaving it in just to show my thought process and general question, but after some more investigation with curves, my question has changed a bit... See below! So I now see that whenever there is a repeated root to an even power, the line is tangent to the curve. When there is a repeated root with an odd power, the line and curve meet and have the same gradient at this point, but they cross.
So my questions now are: What is the significance of having a double root, as opposed to a quadruple root, when the line meets the curve (e.g. a curve defined by a quartic polynomial)? Does it have something to do with the second and third order derivatives too? What is the significance of complex roots to these equations? Specifically, what would be the difference between a tangent to a quartic where there is a single, real, repeated root to the power of four in the simultaneous equation as opposed to a single real root to the power of two, and a set of complex conjugate roots? My current idea of this is that with a single real root to the power of four, as you diverge away from the tangent point, the distance between the line and the curve keeps on growing, but each single complex conjugate root pair adds another dip of the curve towards line. If that is the case, then what is the significance of the real and imaginary components of the complex pair? I think the real component is the actual x value at which there is the closest PERPENDICULAR distance (I think! Please correct me on this one) between the line and the curve (i.e. the shortest distance following a normal to the tangent, as this is the actual closest distance) as opposed to the shortest vertical distance...) But then I am not sure what the significance of the imaginary part is. What difference does it make if, for instance, the conjugate pair is $-1/+-/2i$ as opposed to $-1/+-/7i$?? Tangents which are curves This I am not sure about at all. Does it follow the same principles that: Even power repeated root means tangent Odd power repeated root meant same gradient but crossing Extra real roots mean intersection Extra complex conjugate roots means shortening of distance between the two curves? Thinking about it now, when you solve the simultaneous equations and you set the two functions (i.e. y values) equal to each other, you literally create a distance function and you are trying to find where the distance is zero. Other than the fact that this means solutions to the equation show where the functions meet, whether tangent or intersection, i'm not sure what the significance of this is in my consideration. And it makes me a little more confused as to whether the shortest distance represented by a complex conjugate root pair is the vertical distance or the perpendicular distance. On the one hand, if it were the perpendicular distance, I am essentially imagining tilting the coordinate system so that the line (or lower power curve) is forming the x axis. The problem with it being the perpendicular distance though, is that this shortest distance follows a line which cuts the two curves (or line and curve) at different values of x. Which, then, is the solution that we find when solving the simultaneous equation? The vertical distance would solve this issue of the discrepancy of the x coordinate, and I suppose in that case the 'shortest actual distance' function would be more complicated... Unless, the 'base' line-i.e. x axis-- was formed by whichever function you subtract . E.g. if you have the curve f(x) and line g(x) and you form the distance function f(x)-g(x)=0, then maybe the distance line must be perpendicuular to the subtracted function, g(x), and not the first function, f(x), and the distance line must only be perpendicular to g(x) and the solution is the x value on f(x) that gives the shortest distance to any point on the line g(x)... I apologise for the length of this post and hope I have made myself sufficiently clear!
Thank you in advance for any help.","['roots', 'functions', 'systems-of-equations']"
1922536,Equations for the image of a 2-sphere by a differentiable map,"My professor gave us this exercise. Let $S^2=\{(x_1,x_2,x_3)\in\mathbb{R}^3|(x_1)^2+(x_2)^2+(x_3)^2=1\}$ be the unit sphere in $\mathbb{R}^3$, and let's consider the function $f\colon S^2\to\mathbb{R}^6$ defined by $$
f(x_1,x_2,x_3)=((x_1)^2,(x_2)^2,(x_3)^2,x_2x_3,x_1x_3,x_1x_2).
$$ Prove that $f$ is an immersion but is not injective. Besides, write the equations for $f(S^2)\subset\mathbb{R}^6$ and prove that  $f(S^2)$  is an embedded submanifold of $\mathbb{R}^6$. Solution For the first question, it is sufficient to write down the jacobian matrix $J$ of the function f and note that it is not possible for all the determinants of the $3\times3$ submatrices of $J$ to be zero simultaneously (provided that we are considering only the points of the 2-dim sphere), so the differential is everywhere injective on the sphere and we are done. Besides, $f$ is not injective because, for example, $f(x_1,x_2,x_3)=f(-x_1,-x_2,-x_3)$ ($(x_1,x_2,x_3)$ lies on the 2-dim sphere if and only if $(-x_1,-x_2,-x_3)$ does). But I am just stuck with the second question, I don't get what my professor means with ""write the equations for $f(S^2)$""... The only equation I see is satisfied by a point in $f(S^2)$ is $x_1+x_2+x_3=1$. I'm wondering, how many equations there should be for $f(S^2)$? And how can I find them? Only by means of algebric manipulations of the components of $f$, or is there some ""sistematic"" way to find them?","['manifolds', 'differential-geometry']"
1922567,Difference between the algebraic and topological dual of a topological vector space?,"What is the difference between the algebraic and the topological dual of a topological vector space, such as for example the Euclidean space $\mathbb{H}$? I am interested in intuitive as well as in detailled technical answers.","['functional-analysis', 'topological-vector-spaces', 'linear-algebra', 'vector-spaces']"
1922568,Which one is the correct way to compute the change of basis matrix?,"I was looking for a way to compute the change of basis matrix (given the old basis and the new basis), but I found two methods that lead to different results, and I can't understand which one is correct. Method 1: $$ 
B = \left\{
\begin{pmatrix}
1 \\ 2 
\end{pmatrix} , 
\begin{pmatrix}
3 \\ 4 
\end{pmatrix} 
\right\} ~ , ~
 D= \left\{
\begin{pmatrix}
1 \\ 4 
\end{pmatrix} , 
\begin{pmatrix}
2 \\ 3 
\end{pmatrix} \right\} 
$$ The vectors in $D$ are expressed as a linear combination of the ones in $B$, and then the coefficients are used to construct the change of basis matrix $S$, i.e.: $$
\begin{pmatrix}1 \\ 4 \end{pmatrix} = s_{11}\cdot \begin{pmatrix}1 \\ 2 \end{pmatrix} + s_{12} \cdot \begin{pmatrix}3 \\ 4 \end{pmatrix} \ \ \Rightarrow s_{11}=4 \ \ \text{and}  \ \ s_{12}=-1  \\
\begin{pmatrix}2 \\ 3 \end{pmatrix} = s_{21}\cdot \begin{pmatrix}1 \\ 2 \end{pmatrix} + s_{22} \cdot \begin{pmatrix}3 \\ 4 \end{pmatrix} \Rightarrow s_{21}=\frac{1}{2} \ \ \text{and}  \ \ s_{22}=\frac{1}{2}  \\
\Rightarrow S =\begin{pmatrix}4 & -1 \\ \frac{1}{2} & \frac{1}{2} \end{pmatrix}
$$ Method 2: $$\begin{pmatrix}s_{11} & s_{12} \\ s_{21} & s_{22} \end{pmatrix} \cdot \begin{pmatrix}1 & 3 \\ 2 & 4 \end{pmatrix} = \begin{pmatrix}1 & 2 \\ 4 & 3 \end{pmatrix} \\
\Rightarrow s_{11}=0 \ \ ;\ \ s_{12}= \frac{1}{2} \ \ ; \ \ s_{21}= -5 \ \ ; \ \ s_{22}=\frac{9}{2}\\
\Rightarrow S =\begin{pmatrix}0 & \frac{1}{2} \\ -5 & \frac{9}{2} \end{pmatrix}
$$","['matrices', 'change-of-basis', 'linear-algebra']"
1922581,Solve for $k\in\mathbb{Z}$ such that $f\left(\frac{2\pi}{1999}\right)=\frac{1}{2^k}$ where $f(x)=\prod_{n=1}^{999}\cos(nx)$.,"$f(x)$ is defined such that:
$$f(x)=\prod_{n=1}^{999}\cos(nx)$$ Given that solve for $k$ (which is integer): $$f\left(\frac{2\pi}{1999}\right)=\frac{1}{2^k}$$ I tried many different methods including euler's formula, trig identities and expressing each cosine in terms of $\cos x$ using De Moivre's theorem. Then I tried to multiply these polynomials of powers of cosine and I reached some interesting results. For example first term's power will be $\dfrac{(n+1)!}{(n-1)!2!}$ and its coefficient - $a$ - will be $\dfrac{n!}{(n-2)!2!}$ with term itself $a\cos^n(x)$. Then powers are in descending order, each power equal to previous one minus 2. I wasn't able to find a rule for coefficients except the first and last one, though they are always in the form of binomial coefficients or sum of them such that highest power chooses 2 or 3 or other number. After few terms it always became really cumbersome so I couldn't continue solving it that way with just pen and paper. All that didn't lead me even close to solving the equation though. I solved it numerically using Java app and answer was $k=999$ if I remember correctly. Is there any way to solve it algebraically?","['trigonometry', 'complex-numbers', 'functions']"
1922593,Convergence of $u_{n+1}= 2\left| u_n \right| -1$,"Find all $u_0$ such that the recursive sequence defined by $u_{n+1}= 2\left| u_n \right| -1$ converges. Let $f(x) = 2\left|x\right|-1$. If $(u_n)$ converges, it converges to a fixed point of $f$, that is to say $-\frac 13$ or $1$. Furthermore, if $(u_n)$ converges to $l\in\{-\frac 13, 1\}$ , the mean value theorem yields, for some large enough $n_0$,  $$\forall n\geq n_0, \displaystyle \left|\frac{u_{n+1}-l}{u_{n}-l} \right|=2$$ Since $\lim_{n\to \infty}(u_{n}-l)= 0$ it must be that $u_{n_1}=l\;\;$ for some $n_1\geq n_0$ which implies $u_n=l$ for all $n\geq n_1$. Note that $u_0<-1$ or $u_0>1$ both lead to divergence of $(u_n)$ Therefore, finding the $u_0$ for which the sequence converges amounts to studying the following set $$X:= \{x\in[-1,1], \exists p\in \mathbb N, f^{(p)}(x)\in\{-\frac 13, 1\}\}$$ Is it possible to determine what this set contains exactly ? Certainly $X\cap (\mathbb R \setminus \mathbb Q)=\emptyset$.","['recurrence-relations', 'real-analysis', 'dynamical-systems', 'sequences-and-series', 'discrete-mathematics']"
1922623,"Stars and bars to find ""how many $x$ digit numbers are there with sum of digits $y$""?","This question poses a seemingly very simple method to solve problems of the sort ""how many $x$ digit numbers are there with sum of digits $y$?"", but I don't understand it. Why are the ""bad"" solutions in correspondence to the solutions of $y_1 + 10 + x_2 + x_3 + x_4 + x_5 = 23$? What's the idea? For instance, what ""correct solution"" corresponds to taking $y_1=13$? How to solve this problem?",['combinatorics']
1922626,May conjecture AM-GM without positivity $a_{1}a_{2}a_{3}\cdots a_{2n} \le\left(\frac{a_{1}+a_{2}+\cdots+a_{2n}}{2n}\right)^{2n}$,"Let $a_{1},a_{2},\cdots,a_{2n-1},a_{2n}$be real numbers,I conjecture $$a_{1}a_{2}a_{3}\cdots a_{2n}=\prod_{i=1}^{2n}a_{i}=\le\left(\dfrac{a_{1}+a_{2}+\cdots+a_{2n}}{2n}\right)^{2n}\tag{1}$$
I have know if $a_{i}$ be postive real numbers,It's AM-GM inequality,but it seem for any real numbers,$(1)$ also hold?right? basis $n=2$ it is for any real $a_{1},a_{2}$,then have 
$$a_{1}a_{2}\le\left(\dfrac{a_{1}+a_{2}}{2}\right)^2\Longleftrightarrow 4a_{1}a_{2}\le (a_{1}+a_{2})^2\Longleftrightarrow (a_{1}-a_{2})^2\ge 0$$","['algebra-precalculus', 'means', 'inequality']"
1922648,Antiderivative of $e^{2\arctan{x}}$,"Is there any way to integrate this: $$\int e^{2\arctan x}\, dx$$ I tried to solve it using integration by parts but I could not end the integral because it got very difficult. Then I tried to solve it using Mathematica but it returned a really weird expression. The expression is part of solving this equation $$ y' + \frac{y}{1+x^2}=e^{\arctan x}\ $$ $$ V = e^{-\int f(x) dx} = e^{-\int \frac{dx}{1+x^2}} = e^{-\arctan x}$$
$$R = e^{\arctan x} $$ $$U = \int \frac{e^{\arctan x}}{ e^{-\arctan x}} dx$$ $$ U = \int e^{2\arctan x} dx $$","['calculus', 'indefinite-integrals', 'integration', 'special-functions', 'ordinary-differential-equations']"
1922666,Prove that $(x+3)^2$ is not one-to-one,"So the domain given is $f\colon\mathbb{R}\to\mathbb{R}^+\cup\{0\}$. Does this mean the set of all negative numbers and $0$ but no positive numbers? I am asking because if it does include positive and negative numbers I believe I can prove this by making $x_1= -8$ and $x_2=2$ giving different $x$ values but the same $y$ value. At least I think that is how this is done, any resources, pointers and information is much appreciated!",['functions']
1922674,Why do we have codomain?,"This really ties to the question I asked last night about $f:A\rightarrow B$, but I still don't understand some things. I'm only in AP Calculus BC, and we've never discussed this codomain set $B$. Why does it exist? If the range of $f$ is $\{f(a)\mid a\in A\}$, then why don't we use the range where $B$ is? The way I see it, one could simply say $\Bbb U=\Bbb{R}\cup \{ a+bi\mid a\in\Bbb R\wedge b\in\Bbb R\wedge i^2=-1\}$ and set $B=\Bbb U$ and never have to worry about it again, so how do you know what to set the codomain equal to?",['elementary-set-theory']
1922734,"How to find a trajectory $\sigma(t)$ to represent the ellipse $\{(x,y):4x^{2}+9y^{2}=36\}$?","Given the ellipse $\{(x,y):4x^{2}+9y^{2}=36\}$, find a trajectory $\sigma(t)$ which represent it. So far, I have this: The standard equation for an ellipse is: $\frac{x^{2}}{a^{2}}+\frac{y^{2}}{b^{2}}=1$ So, $4x^{2}+9y^{2}=36\}$ $=\left \langle \text{Arithmetic: Divide by}\ 36 \right \rangle$ $\frac{4x^{2}}{36}+\frac{9y^{2}}{36}=\frac{36}{36}$ $=\left \langle \text{Arithmetic} \right \rangle$ $\frac{x^{2}}{9}+\frac{y^{2}}{4}=1$ I don't know how to continue developing the solution, but I think the trajectory could be represented as $(a\cos(t),b\sin(t))$ Some ideas, suggestions to solve this?",['multivariable-calculus']
1922817,Evaluating $\int_{0}^{\infty}\frac{\mathrm{d}x}{x^{\alpha}(x + 1)}$,"I need some help to evaluate the following integral. $$\int_{0}^{\infty}{\mathrm{d}x \over x^{\alpha}\left(x + 1\right)}$$ where $\alpha \in \left(0,1\right)$ I've tried many ways (the best one seems to be developing by Taylor series) but actually I have no solution. Some ideas?
Thank you.","['real-analysis', 'integration', 'calculus']"
1922819,Stars and Bars with bounds [duplicate],"This question already has answers here : Counting bounded integer solutions to $\sum_ia_ix_i\leqq n$ (5 answers) Closed 7 years ago . This question is related to Error solving “stars and bars” type problem I have what I thought is a fairly simple problem: Count non-negative
  integer solutions to the equation $$x_1 + x_2 + x_3 + x_4 + x_5 = 23$$ such that $0 \leq x_1 \leq 9$. The difference here is on the constraint. It bounds all the $x_i$ under 10 : $\forall i\le5$ ,  $0 \leq x_i \leq 9$. $8+8+0+0+7=23$ is accepted but not $18+3+0+0+2=23$ or $11+0+0+0+12=23$ . In other words all the $x_i$ must be usual digits. Note that bad solutions may include one or two bad $x_i$. It is the main difficulty. What is the count of combinations ? Edit : this question includes a double bounds and a supplemental difficulty to find the right solution.",['combinatorics']
1922820,Resolution of singularities for stacks,"I was wondering whether there is a version of Hironaka's resolution of singularities theorem that applies to stacks. Specifically, I was wondering about the following situation: We define the quotient stack $S = \mathbb{A}^n/\mathbb{G}_{\operatorname{m}}$, where the multiplicative group acts on $\mathbb{A}^n$ by scaling. In other words, $S$ is just projective $(n-1)$-space, but with the image $\mathbf{O}$ of the origin left in. Now $S$ presumably has a bad singularity at $\mathbf{O}$. Does there exist a smooth stack $\widetilde{S}$ and a ""resolution of singularities"" morphism $f:\widetilde{S} \to S$? Note that I am being deliberately vague about the nature of $f$. In the context of schemes, I would for example have required $f$ to be birational, however I am not sure that this makes sense for stacks.","['algebraic-stacks', 'algebraic-geometry']"
1922832,Alternating series: $\sum\limits_{n= 1}^{\infty} (-1)^{n-1} \frac{\ln(n)}{n}$ convergence?,"Determine whether the series converges absolutely, conditionally or diverges? $$\sum\limits_{n= 1}^{\infty} (-1)^{n-1} \frac{\ln(n)}{n}$$ I know that $\sum|a_{n}|$ diverges by using the comparison test: $$\frac{\ln(n)}{n} > \frac{1}{n}$$ and the smaller, r.h.s being the divergent harmonic series. So, should my conclusion for the alternating series be divergent or convergent conditionally * ? * How to estimate whether the alternating series terms are cancelling?","['sequences-and-series', 'convergence-divergence']"
1922847,Narasimhan-Seshadri with Arbitrary Structure Group $G$?,"The way the Narasimhan-Seshadri Theorem is stated classically is that the semi-stable, degree-0 holomorphic vector bundles with structure group $G=U(n)$ on a Riemann surface $X$, are in one-to-one correspondence with representations of the fundamental group $\pi_{1}(X)$ in $G=U(n)$, modulo conjugation.  Moreover, the stable locus coincides precisely with the irreducible representations, and one can extend to arbitrary degree with mild adjustments.  This gives a nice three-way correspondence between (i) semi-stable holomorphic bundles with structure group $G=U(n)$, (ii) representations of $\pi_{1}(X)$ in $G=U(n)$, and (iii) flat connections on $U(n)$-bundles on $X$. My main question is: certainly the gauge theory and topology easily generalize to $G$ an arbitrary compact Lie Group, but does this level of generality hold in the holomorphic vector bundles?  In other words, can we write the same ""trinity"" above where we instead speak of semi-stable, degree-0 holomorphic vector bundles with structure group $G^{\mathbb{C}}$? I suppose I'm confused about something even more elementary.  Certainly the most general holomorphic vector bundles have structure group $\rm{GL}(n,\mathbb{C})$.  And I think you can still have semi-stable bundles with this structure group.  So why isn't the Narasimhan-Seshadri Theorem stated for $G=\rm{GL}(n, \mathbb{C})$? In addition, I've heard vaguely that for a certain choice of $G$, one can arrive at moduli spaces of Higgs bundles?  If this is indeed the case is there a popular reference which explains this correspondence?","['algebraic-geometry', 'representation-theory', 'vector-bundles', 'differential-geometry', 'lie-algebras']"
1922856,Evaluating the sum $\sum_{n=1}^{\infty}\frac{1}{n!(n+2)}$,"The sum again is
$$\sum_{n=1}^{\infty}\frac{1}{n!(n+2)}$$
It looks like it should be amenable to some modification to get towards the exponential power series or something close to it, But I really can't get anything to pop out. Wolfram alpha says it sums to 1/2 and my friend verified this by partial sums but I am curious if there is a slick way to evaluate this, maybe something like partial fractions that can deal with the factorial or a product rule type thing?","['sequences-and-series', 'calculus']"
1922862,Product of banded matrices,"How can one show that the product of two banded matrices is a banded matrix with upper and lower bandwidths equal to the sum of the upper and lower bandwidths (respectively) of the multiplicands ? 
Thank you","['matrices', 'numerical-methods', 'linear-algebra']"
1922904,"Examples of ""self-referential"" sequences","I recently found the so-called Van Eck's sequence , in which $a(n)$ is the answer to the question ""except for $a_{n-1}$ itself, how far back did we last see $a_{n-1}$?"" ($a_n=0$ if $ a_{n-1}$ never appeared before): $$0, 0, 1, 0, 2, 0, 2, 2, 1, 6, 0, 5, 0, 2, 6, 5, 4, 0, 5, 3, 0, 3, 2, 9, 0, 4, 9, 3, 6, 14, 0, 6, 3, 5,\dots$$ I'm intrigued by the idea that the sequence is created by considering a feature of the sequence itself - it is self-referential in a funny way, almost circularly defined. I'm having a hard time pinning down this characteristic precisely, so forgive me the vagueness of the question: What are some examples of other such ""self-referential"" sequences? I tried creating some myself, but they turned out to be not very interesting. For instance, ""$a_n$ is the number of sub-sequences in $(a)_1^{n-1}$ that are $a_{n-1}$ long"" is just $1,1,2,2,3,4,5,6,\dots$ Homemade sequences are also very welcome! Edit: I just found the look-and-say sequence , which is also rather neat: $$1, 11, 21, 1211, 111221, 312211, 13112221,\dots,$$
which is constructed by enumerating the number of certain numbers in a row found in the previous entry, i.e., the second entry is ""one $1 =11$"", the third is ""two $1$s $=21$"", etc.","['recurrence-relations', 'big-list', 'soft-question', 'sequences-and-series', 'online-resources']"
1922933,Find the remainder of $(2x^3-7x^2-19x+8)/(x^2-4x+5)$ without using division,"I have the following problem: Find the remainder of $f(x)=2x^3-7x^2-19x+8$ is divided by $x^2-4x-5.$ An classmate said to equate coefficients, but I do not know what they referred to. I have no idea how to proceed with this problem. Whether it's a hint or a full solution, any help would be appreciated.","['algebra-precalculus', 'polynomials']"
1922942,The Heine-Borel theorem,"The Heine-borel theorem states: A set  $B$$\subset$$\mathbb{R}^n$ is compact $\Longleftrightarrow$ $B$ is closed and bounded. In an exercise i need to prove that the  $''\Longleftarrow''$ statement is not valid in some metric or topological spaces.
My counterexample is this: Take the metric space $(\mathbb{N},d)$ where $d$ is the discrete metric. The open sets in this metric space are the sets of the form $B(x,\epsilon)$$ = 
\left\{\begin{matrix}
\{x\} & \epsilon < 1\\ 
X & \epsilon \geqslant  1
\end{matrix}\right.
$ Then $\mathbb{N}$ is bounded because $\mathbb{N}$$\subset$ $B(m,2)$ $\forall m\in \mathbb{N}$ and it also closed in the discrete metric space Now suppose that $\mathbb{N}$ is compact.
The collection  $C=\{B(m,1/2):m\in\mathbb{N}\}$ is an open cover of $\mathbb{N}$  so by our assumption there must be a finite subcover of  $\mathbb{N}$
say $M=$$\{B(m_1,1/2),,,,B(m_j,1/2)\}$ where $\mathbb{N}$$\subseteq$$\bigcup$$M$. But from this argument and the fact that the elements of $M$ are singletons( from the definition of the open ball in the discrete metric space) we deduce that $\mathbb{N}$ is a finite set which is a contradiction. Hence $\mathbb{N}$ is not compact. Is this counterxample valid or am i missing something?
If it valid i would appreciate a little help to construct another counterexample. Thank you in advance!","['general-topology', 'real-analysis', 'metric-spaces']"
1923016,"Deck of Cards Probability: Two lost cards, one drawn—what is its suit?",I'm having trouble with a probability problem and would love for an explanation. The problem is as follows: Two cards from an ordinary deck of 52 cards are missing. What is the probability that a random card drawn from the deck is a spade? For whatever reason I can't wrap my head around the change in probability from the random removal—best I've got is 52-choose-50.,['probability']
1923045,Are varieties locally contractible?,"Supposed that $X \subset K^n$ is the zero set of some polynomials, where $K = \mathbb{R}$ or $\mathbb{C}$. Is it the case that for every point $x \in X$ there is an $\epsilon > 0$ so that $B = B_{\epsilon}(x) \cap X$ is contractible around $x$? $(B_{\epsilon}$ is a ball of radius $\epsilon$ in the ambient Euclidean space.) Seems so but I don't know how to prove it. My guess would be to show that there is a neighborhood where all of the homotopy groups vanish, and this presumably follows from some finiteness about the topology of an algebraic variety. But I don't know how to show that $X$ is locally simply connected to begin with, though the intuition that there are no arbitrarily small holes seems reasonable for an algebraic variety. Just wondering. Follow up: Is there a reasonable sense in which local rings are contractible?","['algebraic-topology', 'algebraic-geometry']"
1923064,Generalizing an inequality involving a convex function,"If $V:[0,1] \rightarrow \mathbb{R}$ is a convex and nondecreasing function, then for all $(p,q,r,t,\lambda,\mu) \in [0,1]^{6}$ such that $p \geq q \geq r \geq t$ $\lambda p + (1-\lambda) t=\mu q + (1-\mu) r$ we have
\begin{equation*}
\lambda V(p) + (1-\lambda) V(t) \geq \mu V(q) + (1-\mu) V(r)
\end{equation*} I am trying to generalize this observation to the multidimensional case. Consider $n \geq 2$ and the simplex 
\begin{equation}
\Delta=\{(p_1,\cdots,p_n) \in \mathbb{R}^{n} \mid \forall i, p_i > 0 \text{ and } \sum_{i=1}^{n}{p_i}=1\}
\end{equation} Suppose that $\Delta$ is endowed with a (partial) order $\succeq$ such that \begin{equation*}
p \succeq q \Rightarrow p \succeq \alpha p + (1-\alpha) q \succeq q
\end{equation*}
for all $\alpha \in [0,1]$. Consider a continuous function $V:\Delta \rightarrow \mathbb{R}$ that is convex and nondecreasing with respect to $\succeq$, i.e. $V(p) \geq V(q)$ whenever $p \succeq q$. Finally, consider four vectors $p,q,r,t$ and two scalars $\lambda \in [0,1], \mu \in [0,1]$ such that: $p \succeq q \succeq r \succeq t$ $\lambda p + (1-\lambda) t = \mu q + (1-\mu)r$ I am trying to prove that these conditions are sufficient to guarantee that
\begin{equation*}
\lambda V(p) + (1-\lambda) V(t) \geq \mu V(q) + (1-\mu) V(r)
\end{equation*} It is easy when $q=\alpha p + (1-\alpha) t$ and $r=\beta p + (1-\beta) t$ for some $(\alpha,\beta) \in [0,1]^2$ since this case essentially boils down to the unidimensional problem. But I haven't made any progress otherwise. Any hint, help or reference would be greatly appreciated. Thank you!","['real-analysis', 'convex-analysis']"
1923072,Inequality of probablity.,"Let $(S,F,P)$ be probability space and $X :S \rightarrow \mathbb{R}$ be random variable with mean 0 and variance 1. Let $c \geq 0$. I want to show that $P(X \geq c) \leq \frac{1}{1+c^2}.$ I already know Chebychev inequality $P(X\geq) \leq 1/c^2$ when $c > 0$. If this inequality holds, $1/1+c^2$ will be better estimates. Could you help me?",['probability']
1923123,Variance Estimate in linear regression,"In a linear regression, $y=X\beta+\epsilon$, where $\epsilon\sim N(0, \sigma^2)$, $X\sim R^{N \times (p+1)}$. Assume the observations $y_i$ are uncorrelated and have constant variance $\sigma^2$, and that the $x_i$ are fixed. Then $\hat{\beta} = (X^T X)^{-1} X^T y$. One estimate the variance $\sigma^2$ by
$\hat{\sigma}^2 = \frac{1}{N-p-1}\sum_{i=1}^N (y_i-\hat{y}_i)^2$. How to prove $E(\hat{\sigma}^2) = \sigma^2$? and why
$\hat{\beta}\sim N(\beta, (X^T X)^{-1}\sigma^2)$ ? I know how to get the mean and variance of $\hat{\beta}$, but why it follows a normal distribution?","['machine-learning', 'statistics', 'linear-regression']"
1923136,How can we show binomial function is convex without calculus?,"Let $f(z)=\binom{z}{n},$ where $\binom{z}{n}=\frac{z(z-1)\cdots(z-n+1)}{n!}$ and imagine $n\ge 0$. We can show it is convex when $z\ge n$, for example, by calculating $f''(z)$. In fact, it is true for $z\ge n-1$ as dxiv's answer says. But $z\ge n$ is good enough for combinatorial taste. I wonder could we show it is convex by algebraic or combinatorial methods or any other approaches? We may assume $f$ is defined on reals. But proofs for integers are very appreciated too.",['combinatorics']
1923171,How many ways can a group of friends order food?,"If $10$ people have dinner together, how many
  different ways can three(people) order chicken, four order steak and
  three orders lobster? So for this question would this be a permutation with similar objects or a partition with different items. If so I know one uses the formula. $$\frac{n!}{n_{1}!n_{2}!n_{k}} = \frac{10!}{3!*4!*3!} =4200 \text{ ways }$$ Would this be the correct answer?","['permutations', 'statistics', 'probability']"
1923184,What is the geometric reason of why is the divergence of the curl of a vector field equal to zero?,"What is the geometric reason of why is the divergence of the curl of a vector field equal to zero? I know how to prove it but I can't quite get some intuition behind it. I have seen some arguments that treat the del operator as a vector function, but I think this is not so correct as in some cases this analogy fails. This is described in http://www.feynmanlectures.caltech.edu/II_02.html in sections 2-7 and 2-8 but gives poor explanations on why thinking about the del operator as a normal vector works in some cases while does not work in other cases.","['multivariable-calculus', 'differential-geometry', 'vectors', 'vector-analysis']"
1923189,"Finding how many solutions an equation $\sin\left(\frac{\pi}{x}\right) = 1$ has in the interval $x\in(0.001, 0.002)$","Given equation $\sin\left(\frac{\pi}{x}\right) = 1$, find how many roots it has in interval $x\in(0.001, 0.002)$. Because I've never done this kind of problems in my life, I'm in blind spot. How can I find the number?","['algebra-precalculus', 'trigonometry', 'calculus', 'functions']"
1923196,Find $\lim_{x\to\infty} x^{\sin(1/x)}$,How to find $\lim_{x\to\infty} x^{\sin(1/x)}$? I tried $$\lim_{x\to\infty} x^{\sin(1/x)}=\lim_{x\to\infty}e^{\sin(1/x)\ln(x)}$$ Then $$\lim_{x\to\infty}\sin\left(\frac{1}{x}\right)\ln(x)=\lim_{x\to\infty}\frac{\sin(1/x)}{\frac{1}{\ln(x)}}=\lim_{x\to\infty}\frac{\cos(1/x)}{x^2}x\ln^2(x)=\lim_{x\to\infty}\frac{1}{x}\cos\left(\frac{1}{x}\right)\ln^2(x)$$ Which doesn't look promising.,['limits']
1923215,Give a combinatorial proof: $ n(n+1)2^{n-2} = \sum_{k=1}^{n}k^2\binom{n}{k} $,"Find a combinatorial argument for the following binomial identity: $$n(n+1)2^{n-2} = \sum_{k=1}^{n}k^2\binom{n}{k} .$$ Algebraic proofs can be found at Can $n(n+1)2^{n-2} = \sum_{i=1}^{n} i^2 \binom{n}{i}$ be derived from the binomial theorem? , and a related identity at $\sum_{k=1}^m k(k-1){m\choose k} = m(m-1) 2^{m-2}$ .",['combinatorics']
1923217,Distinguishable versus indistinguishable counting (three variations on similar problem). Trying to grasp concepts.,"Can someone please help me understand the following three variations of a problem... Here are the three problems along with some of my reasoning/questions: 1) How many ways to put 20 different (distinct) chocolates into a red bag and a green bag so that each bag contains 10 chocolates? I'm thinking I can think of this as a set (call this set $A$) of 20 distinct integers and the different ways I can put these distinct elements into two distinct sets (call these sets $B$ and $C$). My answer to this is: ${20 \choose 10} \cdot {10 \choose 10}$. That is select 10 elements for my first set $B$ and 10 elements out of the remaining elements for my second set $C$. This one seems pretty straightforward. 2) How many ways to put 20 different (distinct) chocolates into two identical blue bags so that each bag contains 10 chocolates? Conceptually this is a bit trickier. I'm thinking this is analogous to a set (call this set $A$) of 20 distinct integers and the ways I can put these distinct elements into two identical sets (both called $B$). My answer to this is: $\frac{20\choose 10}{2!}$. That is, I'm thinking of this as the number of ways to create two sets of subsets, but since one set is identical to the other I'm dividing out the over-counted subsets. My question here though is how is this possibly less than the ways I can create 10 element subsets from a 20 element set? I'm dealing with two sets... although identical it doesn't make intuitive sense that this somehow reduces the number of combinations that would be obtained from a single set. 3) How many ways to put 20 identical chocolates into two identical blue bags so that each bag contains 10 chocolates? This one I'm not sure on.","['combinatorics', 'elementary-set-theory']"
1923287,All the lines on the Segre quadric,"Find all the lines on the quadric surface in $\mathbb P^3$ defined by the equation
   $$xw=yz$$ 
   (with the homogeneous coordinates $[x:y:z:w]$ of course). Now it is well known that by the Segre embedding there is an isomorphism $\mathbb P^1 \times \mathbb P^1$ with our quadric. Moreover the images $\{[u_0,v_0]\}\times \mathbb P^1$ and $\mathbb P^1 \times \{[s_0,t_0]\}$ give two rulings of lines of our quadric. I have heard however from my teacher these are all the lines on the quadric. Is there any way to show this that is not too theoretically involved?",['algebraic-geometry']
1923295,"If $A$ and $B$ are finite sets, show that $A \cup B$ is finite","If $A$ and $B$ are finite sets, show that $A \cup B$ is finite I already found the bijection to be 
$h: A \cup B \rightarrow \big\{1,\ldots , n+m \big\}$
$$h(x)= \begin{cases}
f(x),&\text{if }x\in \big\{1,\ldots,n\big\}\\
m+g(x),&\text{if }x\in \big\{n+1,\ldots ,n+m\big\}
\end{cases}$$ here $f$ is a bijection from $A \rightarrow \big\{1,\ldots ,n \big\}$
and g is a bijction from $B \rightarrow \big\{1, \ldots ,m \big\}$ What i'm really asking is how do i show $h(x)$ is onto and one-to-one. Can someone walk me through the steps. Piece wise functions confuse me","['elementary-set-theory', 'functions']"
1923297,Lines through a point on the quadric,Suppose that we have a quadric $Q$ in $\mathbb P^3$ defined by the equation $x^2+y^2=z^2+w^2$ and consider the point $p=[1:1:1:1]$ on  $Q$. Compute the equation of all the lines through $p$ contained in $Q$. Now there is a clear way to do this by consider first a linear change of coordinates such that we make our quadric equation become $xw=yz$ and use the Segre embedding of $\mathbb P^1\times\mathbb P^1$ to get the desired answer. I was wondering if there was a more direct strategy to find an answer.,"['projective-space', 'projective-geometry', 'algebraic-geometry']"
1923299,What is the $\frac{1}{2}$ representation of $U(1)$?,"This may be a silly question, and so I apologize in advance. But it stems from a reading of section 2 (page 5) of the physics paper,  "" Counting chiral primaries in N=1 d=4 superconformal field theories "". My question is: What does the representation of $U(1)$ labeled as $\frac{1}{2}$ indicate? My question is a group-theory question, and is as such a math question, but for those unfamiliar with the context, here is some background. The superconformal group for $\mathcal{N} = 1$ supersymmetry in  $d = 4$ spacetime dimensions is $SU(2,2|1)$. We focus our attention on a particular subgroup of $SU(2,2|1)$, called the maximal bosonic subgroup: $SU(2,2) \times U(1)_R$. The $U(1)_R$ is known as an R-symmetry group in physics. The generators of supersymmetry (the ''supercharges'') $Q$ and $Q^\dagger$ belong to representations $4_1$ and $\bar{4}_{-1}$ of $SU(2,2) \times U(1)_R$. The subscript denotes the $U(1)_R$ representation ($1$ is the fundamental, $-1$ is the anti-fundamental) and the $4$ and $\bar{4}$ are $SU(2,2)$ representations. So, so far we are labeling everything in terms of irreps of the maximal bosonic subgroup. The conformal group in $d = 4$ spacetime dimensions is $SO(4,2)$, which has a covering group $SU(2,2)$. We want to study a quantum field theory not in 4-dimensional Minkowski (""flat"") space but on the space $\mathbb{R} \times S^3$. So one is interested in the Killing spinors of this space, and the isometries. Based on (4) and (5), we restrict our attention to the subgroup $U(1) \times SO(4)$ of the conformal group, which is the isometry group of $\mathbb{R} \times S^3$. The idea then is to decompose the generators in terms of representations of the isometry group $SU(2)_l \times SU(2)_r \times U(1)$ and the R-symmetry $U(1)_R$. Here we've used the fact that $\mathbb{so(4)} = \mathbb{su}(2)_l \times \mathbb{su}(2)_r$. The claim is $$4_1 \longrightarrow (2,1)_{\frac{1}{2},1} \oplus (1,2)_{-\frac{1}{2},1}$$
$$\bar{4}_{-1} \longrightarrow (2,1)_{-\frac{1}{2},-1} \oplus (1,2)_{\frac{1}{2},-1}$$ There are now two $U(1)$ subscripts: the first is for the $U(1)$ which is part of the isometry group, and the second is for the $U(1)_R$ which is the R-symmetry group. Note that the $U(1)_R$ subscript is the same on each term on the right hand side and carries over from the left. The question posed above pertains to the first subscript in the above decomposition, i.e. the representation of the $U(1)$ which is part of the isometry group of the manifold. I know that an element in $U(1)$ is represented by $e^{i\theta}$ and moreover, $U(1)$ is isomorphic to $SO(2)$. The latter made me think of the irreducible spinor representation of $SO(2)$, but that too is a real 1-dimensional representation (2d Dirac spinor with 2 complex components, but the Majorana-Weyl condition brings it down to 1 real component). Also, if $U(1)$ is parametrized by $\left(\begin{array}{cc}\cos n\theta & \sin n\theta\\-\sin n\theta & \cos n\theta\end{array}\right)$, does $\frac{1}{2}$ simply mean that $n = 1/2$ in this representation, so that effectively, its a half rotation?","['mathematical-physics', 'superalgebra', 'group-theory', 'lie-algebras', 'lie-groups']"
1923303,Why is the determinant of the Jacobian the change of volume factor that comes from changing variables?,"I can understand this through various examples found in the internet but I can't quite intuitively understand why the determinant of the derivative(in its most general form)-the Jacobian-gives the change of volume factor that arises when we change variables in, say, an integral. I mean, why does the determinant of the matrix consisting of the derivatives of the original variables wrt the new variables give a number that corresponds to how much the infinitesimal volume has changed? How can we geometrically connect the derivatives that are the components of the Jacobian with the aforementioned change of volume?","['multivariable-calculus', 'differential-geometry', 'vector-analysis']"
1923328,Prove Ultraparallel Theorem in the half-plane model,"Given that $l_1$ and $l_2$ are hyperbolic lines and they are ultraparallel, prove that there exists a line perpendicular to both $l_1$ and $l_2$. My progress:
In the half-plane model, I can prove that the situation when $l_1$ is a Euclidean vertical line and $l_2$ is a Euclidean semi-circle. However, I cannot prove the statement when $l_1$ and $l_2$ are both Euclidean circles. I let the radius of the two circles containing $l_1$ and $l_2$ be $r_1$ and $r_2$. I let the radius of the circle containing the perpendicular line be $r$. I let the center of the circles containing $l_1$, $l_2$ and the perpendicular line to be $c_1$, $c_2$ and $c$.
Then I have the equation:
$$ (c-c_1)^2 = r_1^2+r^2$$
$$ (c-c_2)^2 = r_2^2+r^2$$
I want to show that $r>0$ but I couldn't.","['hyperbolic-geometry', 'noneuclidean-geometry', 'geometry']"
1923351,Adjunction integral for Gysin map?,"Let $f : X \to Y$ be a map between compact, orientable, smooth manifolds. Then the Gysin map is defined by requiring that $\int_X f_! \alpha \wedge \beta = \int_Y \alpha \wedge f^*(\beta)$, for forms of suitable dimension. This looks very much like an adjunction, if the integration was replaced by Hom. I guess this is not a coincidence (or maybe I am overly excited) but I don't know how to relate these things; is there a categorification of this formula that makes sense? I guess that somehow there would be morphisms between $k$ and $n-k$ forms, and the space of these morphisms can be naturally given a volume, which would be the volume normally associated to the integral of the wedge product. Less vaguely than that I don't know how to proceed.","['algebraic-topology', 'category-theory', 'differential-forms', 'algebraic-geometry']"
1923356,"Prove: For odd integers $a$ and $b$, the equation $x^2 + 2 a x + 2 b = 0$ has no integer or rational roots.","If $a$ and $b$ are odd integers, prove that the equation $$x^2 + 2ax + 2b = 0$$ has no integer or rational roots.","['quadratics', 'functions', 'elementary-number-theory']"
1923358,Finding the closure of some subsets of the ordered square,"I need to find the closure of these sets on the ordered square: $$A = \left\{\left\langle\frac1n,0\right\rangle
 \mid n\in \mathbb{Z}_+\right\}$$ $$B = \left\{\left\langle1-\frac1n,\frac12\right\rangle
\mid n\in \mathbb{Z}_+\right\}$$ $$C = \{\left\langle x,0\right\rangle
\mid 0<x<1\}$$ $$D = \left\{\left\langle x,\frac12\right\rangle
\mid 0<x<1\right\}$$ $$E =\left \{\left\langle\frac12,y\right\rangle
 \mid 0<y<1\right\}$$ I know that the closure is just the set itself united with its limit points. For $A$ , the set of limit points, I imagine, are $\{\langle 1,0\rangle\}$ , that is, the $x$ coordinate is $1$ and the $y$ is $0$ . But here is says the reverse. What am I getting wrong? Following the same reasoning, $B' = \{\langle 1,\frac{1}{2}\rangle\}$ $C' = \{\langle 0,0\rangle,\langle 0,1\rangle\}$ What am I doing wrong?",['general-topology']
1923437,A function in which addition and multiplication behave the same way,"Exponents have a well-known property: $$x^ax^b = x^{a+b}$$ but $$x^{a} + x^{b} \neq x^{a+b}$$ Similarly, $$\log(a) + \log(b) = \log(ab) $$ But $$\log(a)\log(b) \neq \log(ab)$$ So my question is this: Is there a function $f$ on $\mathbb{R}$ or some infinite subset of $\mathbb{R}$ with the following properties $$(1)\quad f(x)f(y) = f(x+y)$$
$$(2)\quad f(x)+f(y) = f(x+y)$$
ie
$$(3)\quad f(x)+f(y) = f(x)f(y)$$ It seems that $(2)$ requires the function to be linear...","['functions', 'functional-equations']"
1923455,Prove that the set $B_m$ is measurable,"Let $(X, \mathcal{A}, \mu)$ be a measure space and $\{A_n\}$ a family of measurable sets. For $m \in \mathbb{N}$ let $B_m$ be the set of points $x \in X$ that belong to at least $m$ of the sets $A_n$. Prove that $B_m$ is measurable and that $\mu (B_m) \leq \dfrac{1}{m} \sum_{n=1}^{\infty} \mu (A_n)$ I have been trying using the theorem that said that $\mu (\cup_{n=1}^\infty C_n)  \leq \sum_{n=1}^{\infty} \mu (C_n)$ for a family of measurable sets $\{C_n\}$ and I'm looking for the family that could help me, but I don't know how to use the factor $\dfrac{1}{m}$. I'm also trying to see the set $B_m$ as the intersection of other measurable sets that I know. I tried with induction over $m$ too.","['measure-theory', 'analysis']"
1923461,Does the forgetful functor from Stone spaces to sets preserve colimits?,"Write $\mathbf{Stone}$ for the category of compact, Hausdorff totally disconnected spaces, and write $U:\mathbf{Stone}\to\mathbf{Set}$ for the forgetful functor. I think it must be likely that $U$ does not preserve colimits, but I can not see why - I am confident that it preserves coproducts, but I don't know about coequalizers.","['category-theory', 'general-topology', 'limits-colimits']"
1923516,"Give an example of a subset $L'$ of a lattice $L$ , such that $L'$ is a lattice but not a sublattice of $L$. [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Find the   example of a subset $L'$ of a lattice $L$ , such that $L'$ is a lattice but not a sublattice of $L$.","['lattice-orders', 'discrete-mathematics']"
1923522,"Finding the dimension of $S = \{B \in M_n \,|\, AB = BA\}$, where $A$ is a diagonalizable matrix","I need some help proving the following: Let $A \in M_{n \times n}$ be a diagonalizable matrix with distinct eigenvalues $\lambda_1, \ldots , \lambda_k$ and corresponding multiplicities $d_1, \ldots, d_k$. Given that $S = \{B \in M_n \,|\, AB = BA\}$, prove that $\dim (S) = d_1^2 + \cdots + d_k^2$. Here's what I've done: Since $A$ is diagonalizable, we have that $D = P^{-1}AP$, where $D$ is a diagonal matrix. We may then write, $$P^{-1}AP = \begin{bmatrix}\Lambda_1 & & &  \\ & \Lambda_2 & & \\ & & \ddots & \\ & & & \Lambda_k\end{bmatrix} = D,$$ where $$\Lambda_i = \underbrace{\begin{bmatrix}\lambda_i & & & \\ & \lambda_i & & \\ & & \ddots & \\ & & & \lambda_i\end{bmatrix}}_{d_i \, \text {columns}}.$$ Obviously the size of each $\Lambda_i$ is $d_i \times d_i = d_i^2$, which I'm thinking we need to show that each block contributes this to the total dimension as we work along the diagonal, but I'm having a little trouble coming to this conclusion via the why and how . Clearly each column vector of $D$ and consequently each column vector of each $\Lambda_i$ is linearly independent, but I am unable to see what comes next to receive the squared part. Can someone provide a hint as to how I can make this conclusion?","['eigenvalues-eigenvectors', 'matrices', 'proof-writing', 'linear-algebra', 'vector-spaces']"
1923531,Linear operator as sum of linear functionals?,"Is it possible to get an analouge of the matrix represenation of a linear operator on finite dimensional space for general linear operators on Banach spaces. The matrix represenation look like a ""sum of functionals"" hence maybe some kind of integral operators with certain kernals? I think I did an exam question which looks like this but I cant rememeber the formulation or find the exam. Furthermore, given that I remember correctly what is the widest class of operators for which this is possible? Found possible duplicate ; Can all continuous linear operators on a function space be represented using integrals?","['functional-analysis', 'soft-question']"
1923557,Does Quasi-increasing and Quasi-decreasing imply continuity?,Suppose $f$ is a function $f$: $\mathbb{R} \to \mathbb{R}$. Then Do the following equations imply the continuity of $f$ at $s$? $ \lim_{x\uparrow s} \sup f(x) \leq f(s) \leq \lim_{x\downarrow s} \inf f(x)$ $ \lim_{x\uparrow s} \inf f(x) \geq f(s) \geq \lim_{x\downarrow s} \sup f(x)$,"['continuity', 'analysis', 'limits']"
1923565,Finding $\lim\limits_{n \to \infty} \frac{\ln(n+1)}{\ln(n)} \frac{\ln(n!)}{\ln((n+1)!)}$,"I am trying to find the limit as $n \to \infty$ of the function below: $$f(n) = \frac{\ln(n+1)}{\ln(n)} \frac{\ln(n!)}{\ln((n+1)!)}$$ The textbook only gives me an answer but I don't know how it got to it.
I got confused with the factorials within logs. Edit: I understand that this could be expanded to: $$f(n) = \frac{\ln(n+1)}{\ln(n)} \frac{\ln(n) + \ln(n-1) + ...}{\ln(n+1) + \ln(n) + \ln(n-1) + ...}$$ I'm confused which terms get reduced to zero as $n \to \infty$ or how to group them.","['logarithms', 'limits']"
1923620,Why is a homogeneous function called homogeneous?,"Why is a homogeneous function called homogeneous? When I ask this, I don't mean, ""Show me how to algebraically manipulate a function whose input has been multiplied by a constant to get the original function multiplied by the same constant."" I mean--why do we use the word ""homogeneous""? That word in particular must have been chosen for a reason; what is it meant to communicate in this context?","['terminology', 'ordinary-differential-equations', 'linear-algebra']"
1923624,Taylor's polynomial uniqueness proof - why are these limits inferable?,"So I'm viewing a short proof on the uniqueness of Taylor polynomials. Uniqueness of Taylor polynomial: Let $f:]a,b,[ \rightarrow \mathbb{R}$ $n$ times continuously
  differentiable and $x_0 \in ]a,b,[$. If $p$ is $n$th degree polynomial
  function for which $$f(x)-p(x)=o(|x-x_0|^n), \space \text{when} \space x \rightarrow
x_0$$  then $$p(x)=T_{n, x_0} f(x)$$ Proof starts like: $$\frac{p(x)-T_{n, x_0}f(x)}{(x-x_0)^n} = \frac{p(x)-f(x)}{(x-x_0)^n}+\frac{f(x)-T_{n, x_0}f(x)}{(x-x_0)^n}$$ then $$\frac{p(x)-f(x)}{(x-x_0)^n} \rightarrow 0 \space, when \space x-x_0 \rightarrow 0$$ $$\frac{f(x)-T_{n, x_0}f(x)}{(x-x_0)^n} \rightarrow 0 \space, when \space x-x_0 \rightarrow 0$$ Now my problem is, how can one actually say that the above approach $0$ if the denominator approaches $0$?","['taylor-expansion', 'asymptotics', 'calculus', 'limits']"
1923721,Tangent line intersections given the normal line equation for $(x-2)^2$,"Sorry but I'm a bit stuck at this problem with derivatives and the tangent line, I'll be stating the problem then the steps I've done to try and solve it. The problem is stated like this: Find all points on the graph of $y = (x-2)^2$ at which the tangent line is perpendicular to the line with equation $2x - y + 2 = 0$ So I have the equation for the normal line: $y = 2(x + 1)$, so I think the  equation for the tangent line is $y = -\frac{1}{2}(x + 1)$. Since I need to get points of intersections with $(x-2)^2$, I need to get an equation for the tangent line based on it so I solve for derivatives. $$f(x) = (x - 2)^2$$
$$f'(x) = \frac{d}{dx} (x-2)^2$$
$$f'(x) = 2(x - 2)$$ So now given these, I have another equation for the tangent line at a given point of tangency $t$: $$y - f(t) = f'(t)(x - t)$$
$$y - (t - 2)^2 = 2(t - 2)(x - t)$$
$$y = 2(t - 2)(x - t) + (t - 2)^2$$
$$y = (t - 2)[2(x - t) + (t - 2)]$$
$$y = (t - 2)(2x - 2t + t - 2)$$
$$y = (t - 2)(2x -t - 2)$$
$$y = (t - 2)2(x - \frac{t}{2} - 1)$$
$$y = 2(t - 2)(x - \frac{t + 2}{2})$$ Now going back to the equation for the normal line, I now have two equations for the tangent line: $$y = -\frac{1}{2}(x + 1)$$
$$y = 2(t - 2)(x - \frac{t + 2}{2})$$ Now this is where I'm stuck. The two equations seem to imply that $2(t - 2) = -\frac{1}{2}$ and $\frac{t + 2}{2} = -1$, however solving for $t$ on the first equation gives me $\frac{7}{4}$ which seem to match what's in the answer key, but the other equation gives me $t = -4$. Why is that? Was I wrong in any of my assumptions? I know I must be missing something huge but I can't pinpoint it right now. Any help would be greatly appreciated. Thanks.","['algebra-precalculus', 'calculus', 'derivatives']"
1923784,Why the separable equation $\frac{dy}{dt}=\frac{-t}{y}$ has no equilibrium solution?,"I am given a separable equation with initial value$$y^{'} = -\frac{t}{y} \qquad y(0)=1$$. This is an example from the book however I am not sure why this equation has no equilibrium solution. I do know that an equilibrium solution is a value of $y$ for which $\frac{dy}{dt}=0$ and this happens when $t=0$. From what I understood, the only time this equation has equilibrium solution is when $y=1$ but the equation suggests 2 values for $y$ which can't be possible for the given IVP. Is that why it has no equilibrium solution? Please help.",['ordinary-differential-equations']
1923798,"Zeta function of algebraic variety over $\mathbb{F}_q$, formula for product of Witt vectors.","Let $X$ be an algebraic variety over $\mathbb{F}_q$. We have the definition of the zeta function of $X$ as follows:$$Z(X, t) = \prod_{x \, = \,\text{Fr}_q\text{-orbit in }X(\overline{\mathbb{F}}_q)}(1 - t^{\deg x})^{-1},$$where we write $\deg x = \text{number of elements in }x$. Question. What is $Z(X_1 \times X_2, t)$ in terms of $Z(X_1, t)$ and $Z(X_2, t)$? The result supposedly be a formula for the product of Witt vectors...","['algebraic-geometry', 'algebraic-number-theory', 'number-theory', 'arithmetic-geometry', 'riemann-zeta']"
1923839,Is there a way to show that the addition of the first n terms of the Fibonacci sequence squared gives an answer divisible by a particular number?,Is there a way to show that the addition of the first n terms of the Fibonacci sequence squared gives an answer divisible by a particular number?,"['number-theory', 'fibonacci-numbers', 'modular-arithmetic']"
1923883,Show that $x^2 + 1$ is irreducible over $\Bbb Z_3$ and reducible over $\Bbb Z_5$,Show that $x^2 + 1$ is irreducible over $\Bbb Z_3$ and reducible over $\Bbb Z_5$. I can't figure any way to express $x^2 + 1$ as a product of two polynomials in either ring.  Each product I try either ends up with a number being off by $1$ or $2$. Anyone have any ideas?,['abstract-algebra']
1923914,References about distances between singular probability measures,"I would be interested in references on the topic of distances between probability measures that are singular with one another and not reduced to trivial ones. For example from here we know that total variation distance is not suitable for such a problem. In the end I am looking for a structure that would be fine enough to be able to address mutually singular Wiener measures in a non trivial way (for example it is well known that the Wiener measures associate with the two process driven by a BM are mutually singulars : $X^1_t =\sigma_1.W_t$ and $X^2_t =\sigma_2.W_t$, with $X^i_0=0, i=1,2$ as soon as $\sigma_1\not=\sigma_2$ so finding a meaningful distance between those measures is a matter of interest for me). 
Best regards Edit following the advice of Ilya here i what I could set up using the Wasserstein representation of Kantorovitch distance. So let's formalize the set up : 
Let $(X^1_t)_{t\geq 0},(X^2_t)_{t\geq 0}$ be two processes defined by as $X_0^i =1,X^i_t=e^{\mu.t + \sigma_i.W^i_t$}, i=1,2$ with respect to 2 Brownian motions $W^1_t$ and $W^2_t$. The relation between the 2 process $W^1_t, W^2_t$ is left unspecified and we do not impose that $(W^1_t, W^2_t)$ is a 2 dimensional BM at the moment. Let's note $\mathcal{L}_i$ the marginal law's of $(X^i_t)_{t\geq 0},i=1,2$, $X^i$ seen as a random variables in $C_1(\mathbb{R^+},\mathbb{R^+})$ the space of continuous function s.t. $f(0)=1$, and $\forall t\geq 0, f(t)\geq 0$, the measures being over sets of the Borel sigma-field resulting from topology of the sup norm over compacts of this functional space.
Now the space $\mathcal{J}$ of all the joint laws over state space $C_1(\mathbb{R^+},\mathbb{R^+})^2$ with marginals equals to $\mathcal{L}_1$ and $\mathcal{L}_2$ We define the distance between those 2 measure (which are btw mutually singulars) as : $$d_{KW}(\mathcal{L}_1,\mathcal{L}_2)=inf_{J\in \mathcal{J}}(\mathbb{E^J}[d(X^1,X^2)])$$ So now using Ilya's ideas and specifying the $d$ in the preceding infimum, as $d(x,y)=sup_{s\geq0}(|x(s)-y(s)|) $, using a particular $J_W\in \mathcal{J}$ which is the one where  $W^1_t= W^2_t$ I can rewrite using Burkholder, Davies, Gundy inequality (maybe that's too much) that : $d_{KW}(\mathcal{L}_1,\mathcal{L}_2)\leq \mathbb{E^{J_W}}[|X^1_s-X^2_s|^*])$ 
(here the star is for the sup) 
$\mathbb{E^{J_W}}[|X^1_s-X^2_s|^*])\leq C_1\mathbb{E^{J_W}}[<X^1_.-X^2_.>_\infty^{1/2}])=F^{J_W}$ I have not finished the calculations yet but even though, I bet that thanks to the negative drift it should be possible for $F^{J_W}$ to be bounded and that this bound tends to $0$ as $\sigma_1 - \sigma_2\to 0$ ( I think this was Ilya's original idea). 
Anyway this would not prove that $d_{KW}(\mathcal{L}_1,\mathcal{L}_2)$ is not trivially equal to 0 for a better choice of $J \in\mathcal{J}$ this is why I'm still a bit unsatisfied with this example. Any thoughts ?","['wiener-measure', 'reference-request', 'probability-theory', 'measure-theory']"
1923920,Find all $x$ so $\frac{1^2+2^2+\cdots+x^2}{x}$ is a perfect square...,"Find all $x$ so $\dfrac{1^2+2^2+\cdots+x^2}{x}$ is a perfect square... Clearly 1 is solution, but I have to show that there is an infinity... I see that this happens when the numbers $1,2,...,x$ have a whole quadratic root. Am I on the right road?","['means', 'square-numbers', 'sums-of-squares', 'number-theory', 'elementary-number-theory']"
1923924,Normal variables - adding and multiplying by constant [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question $X\sim N(a,b)$, while $c$ is constant. Is is true that then: $X+c\sim N(a+c,b)$  ? $cX\sim N(c\cdot a, b)$  ?",['probability']
1923962,Calculus - Finding limit (NOT L'Hopital's Rule): $\lim_{x \to 1^-}\frac{x^2+x+\sin({\pi\over 2}x)-3}{x-1}$,How do I find this limit? $$\displaystyle{\lim_{x \to 1^-}}\frac{x^2+x+\sin({\pi \over 2}x)-3}{x-1}$$ I am unable to factor the numerator to get rid of the denominator. Can someone please help? Thank you! Is there any other way to get the answer besides using L'Hopital's Rule?,"['limits-without-lhopital', 'closed-form', 'limits']"
1923999,"What is the origin of the term ""Crystal Ball Condition""?","Given $p>0$ and a family of random variables $\{X_{n}\}$,  the uniform integrability of $\{|X_{n}|^{p}\}$ follows from the existence of a $\delta>0$ such that 
$$
\sup_{n} E(|X_{n}|^{p+\delta})<\infty.
$$
This is called the ""Crystal Ball Condition"" (see for example Resnick, A Probability Path, Section 6.5.1).  What is the origin of the term?","['terminology', 'uniform-integrability', 'probability-theory', 'random-variables']"
1924013,Conditions for the existence of a density with respect to Lebesgue measure,"Let $X:\Omega \to \mathbb{R}$ be a random variable on a probability space $(\Omega,\mathcal{A},\mathbb{P})$ and denote by $$\chi(\xi) := \mathbb{E}e^{i \xi \cdot X}, \xi \in \mathbb{R}^d,$$ its characteristic function. I'm looking for sufficient and necessary conditions in terms of the characteristic function  that (the distribution of) $X$ has a density with respect to Lebesgue measure. For example, there are the following results: If $\int_{\mathbb{R}^d} |\chi(\xi)| \, d\xi < \infty$, then $X$ has a density with respect to Lebesgue measure. $X$ has an $L^2$-density with respect to Lebesgue measure if, and only if, $\int_{\mathbb{R}^d} |\chi(\xi)|^2 \, d\xi < \infty$. Are there any similar statements? I'm mainly interested in the existence of the density and not in additional properties of the density (such as $L^p$-integrability, differentiability,...). Thanks!","['density-function', 'reference-request', 'probability-theory', 'characteristic-functions', 'random-variables']"
1924026,Gluing topological spaces,"The following is called a gluing datum : A family of topological spaces $(U_i)$, For all $i,j$ an open subset $U_{ij}\subseteq U_i$ For all $i,j$ a map $\varphi_{ji}:U_{ij}\to U_{ji}$ such that $\varphi_{ii}=\operatorname{id}$ for aall $i$, $\varphi_{ji}(U_{ij}\cap U_{ik})\subseteq U_{ji}\cap U_{jk}$ for all $i,j,k$, $\varphi_{kj}\circ \varphi_{ji}=\varphi_{ki}$ on $U_{ij}\cap U_{ik}$ for all $i,j,k$. Then there is a space $X$ together with open continous functions $\psi_i:U_i\to X$, such that 1) $X$ is covered by the images of the $U_i$, 2) $\psi_j\circ\varphi_{ji}=\psi_i$ on $U_{ij}$  for all $i,j$, 3) $\psi_i(U_i)\cap\psi_j(U_j)=\psi_i(U_{ij})=\psi_j(U_{ij})$ for all $i,j$. Moreover, $X$ is universal with respect to 2). Question: What is happening here, categorically? Is this a special colimit? Does this have a name in category theory? Which parts are categorical nonsense and which are topology? Thank you.","['category-theory', 'general-topology']"
1924073,Finding $\lim_{x \to \infty} \left(\frac{a_{1}^{1/x}+a_{2}^{1/x}+\cdot\cdot\cdot{a_{n}}^{1/x}}{n}\right)^{nx}$,"For non zero positive reals $a_{1},a_{2}\cdot\cdot\cdot a_{n}$ how to find 
$$
\lim_{x \to \infty}
   \left(\frac{a_1^{1/x} +a_2^{1/x}+\ldots +a_n^{1/x}}{n}\right)^{nx}?
$$ It becomes indeterminant form $1^{\infty}.$ But difficult to solve by  L'Hospital's Rule. By using A.M.-G.M. inequality it comes that limit is $\geq a_{1}a_{2}\cdot\cdot\cdot a_{n}.$ I also tried by using Squeeze. Please help.Thanks.","['real-analysis', 'limits']"
1924097,Inradius in Right angled triangles.,Let $AD$ be an altitude in right angled $\triangle{ABC}$ with $\angle{A}=90^{o}$ and $D$ on $BC$. Suppose that the radii of incircles of triangles $ABD$ and $ACD$ are $33$ $(r_1)$ and $56$ $(r_2)$ respectively. Let $r$ be the radius of incircle of the $\triangle{ABC}$. Find the value of $3(r+7)$. (Figure is rough),"['circles', 'euclidean-geometry', 'triangles', 'geometry']"
1924147,"Borel measurability of ""closest point selection""","Let $(Y,d)$ be a metric space, and let $X \subset Y$. Does there exist a Borel measurable function $\gamma: Y \to X$ such that, for all $y \in Y$, $d(y,\gamma(y)) \leq 2 \inf\{d(y,x) : x \in X\}$? I would be interested in such a selection function with the assumption that $X$ is Borel, or even closed, but I would prefer an answer that works for arbitrary $X$.","['real-analysis', 'metric-spaces', 'measure-theory']"
1924154,Is a monoid a magma?,"According to this wikipedia page , a monoid is defined as an object that contains An associative binary operation An identity element There is no mention of the object necessarily containing a set. The same page includes the statement ""a monoid is a semigroup with an identity element"". It is my understanding that a semigroup is a magma with additional constraints, is this correct? The page also compares a monoid and a magma, stating a monoid simply has more constraints. But doesn't a monoid lack magma's constraint of having to contain a set? So does this mean a monoid does necessitate a set? Or have I misunderstood something? I might just be nitpicking the specific wording of a wikipedia page, but I don't want to assume it's an error before I understand it for sure. Thanks in advance!","['abstract-algebra', 'magma', 'semigroups', 'monoid']"
1924170,"Defining an ""additive"" group structure on $[0,1]$","Addition modulo $1$ defines a group structure on the halfopen unit interval $[0,1)$. Obviously, this construction does not work if one starts with $[0,1]$ instead of $[0,1)$. Is it possible to extend addition on $[0,1]$ to a group operation? More precisely: Does there exist a binary operation $\ast: [0,1]^2 \to [0,1]$ such
  that $a \ast b = a+b$ whenever $a+b \leq 1$ and such that
  $([0,1],\ast)$ is a group? Clearly, if this is the case then $0$ should be the neutral element. However, we did not make much progress beyond this. This question came up when trying to invent exercises for a group theory course. I do not know what the answer is.","['group-theory', 'binary-operations']"
1924261,"If A is a set of pairwise-disjoint sets, is the power set of A a set of pairwise-disjoint sets?","This question is just as in the title:
If A is a set of pairwise-disjoint sets, is the power set of A a set of pairwise-disjoint sets? Either prove this or provide a counterexample. This is the question, and would like to double check my work on this problem; I provided a counterexample, but just want to be sure (or find out if that is wrong!).",['elementary-set-theory']
1924288,Sigma algebra on the empty set,"Several textbooks don't include in the definition of a $\sigma$-algebra $\mathcal{F}$ on a set $\Omega$, that $\Omega$ must be non-empty. I wonder if that's a requirement. Because if $\Omega=\emptyset$, $\mathcal{F}$ can only be $\{\emptyset\}$. I know that $\{\emptyset, \Omega\}$ is the trivial $\sigma$-algebra on any non-empty $\Omega$, but if $\Omega$ itself is $\emptyset$, then the set containing the empty set itself would be a $\sigma$-algebra. Have never heard that (have you?), but it doesn't seem to contradict the definition. Solution: As Willie pointed out in 2), I was missing the point that $\{\emptyset\}=\{\emptyset,\emptyset\}=\{\emptyset,\Omega\}$ so the $\sigma$-algebra generated is the trivial one again.",['measure-theory']
1924291,Given $f(x)=x(x-1)(x-2)...(x-10)$ what is the derivative $f'(0)$?,"$$f: \Bbb R \to \Bbb R; x \mapsto f(x)=x(x-1)(x-2)\cdots(x-10)$$
  Evaluate $f'(0)$! I've tried to set the factors apart, but I only know that $(fg)'=f'g+fg'$.
I don't know how I should apply that rule for any $n$ amount of factors. I also thought of actually doing the multiplication, but I don't know what shortcut I should use, and multiplicating one after the other takes extremely long.","['derivatives', 'calculus']"
1924307,Did I solve $z^{n-1}=\overline{z}$ correctly?,"Please could someone tell me if my solution of $z^{n-1}=\overline{z}$
  is correct? My solution: We have $z^{n-1} =\overline{z}$ if and only if $z^{n-1}z =\overline{z}z$, so $z^n = |z|^2$ In polar coordinates, $$ r^n e^{i n \varphi}  = r^2$$ or, equivalently, $$ r^{n-2} e^{i n \varphi}  = 1$$ This equation implies that $r=1$. Hence we are taking $n$-th roots of $1$: $$e^{i n \varphi}  = 1$$ So the resulting set is a discrete and finite subset of the unit circle (consisting of the $n$-th roots of $1$).",['complex-analysis']
1924322,How does one create a partition of unity for a complex manifold?,"As far as I am aware, partitions of unity for smooth manifolds require the use of smooth functions with compact support (e.g. bump functions). However, for a complex manifold, the transition maps have to be not only smooth, but holomorphic. And by the Identity Theorem any holomorphic function with compact support is identically zero. Question: How does one surmount this obstacle when working with complex manifolds? Naively it seems to me that because of this the only possible complex manifold to define would be the open unit disk in $\mathbb{C}^n$ , i.e. a manifold with only one chart, since Wikipedia says that the atlas of a complex manifold consists of charts to the open unit disk in $\mathbb{C}^n$ .","['complex-geometry', 'differential-geometry']"
1924329,Understanding intuitively Why the rate of change of area of a circle with radius is the circumference of the circle,"I don't know whether this a rigorous mathematical question. But I was trying to figure out the intuition behind the answer . I have through out my high school used the fact that d/dr (πr^2)= 2πr . It is obvious from the formula. My question is how should I understand the answer intuitively or geometrically ? We all know that the rate of change of displacement with time is the instantaneous velocity. The answer seems obvious in the first reading of any basic calculus text. Derivatives of certain other functions also seem obvious (or atleast not as unobvious as the above circle one ) at the first go , or if they don't seem so obvious we can understand them after drawing a picture and analysing it geometrically. But how should I intuitively  understand the rate of change of area of circle with radius being equal to the circumference of the circle ? Why is it so ? I need to understand it geometrically too.
 How can the rate of change of area of circle with radius give the circumference of the circle ( intuitively ) ?","['derivatives', 'euclidean-geometry', 'analytic-geometry', 'geometry']"
1924343,Showing convergence in probability of sample variance to population variance,"Problem 6.7.2 of Resnick's A Probability Path says: Let $\{X_{n}\}$ be iid, with $EX_{n}=\mu$, $\mathrm{Var}(X_{n})=\sigma^2$.  Set $\overline{X}=\sum_{i=1}^{n} X_{i}/n$. Show:
$$
\frac{1}{n}\sum_{i=1}^{n}(X_{i}-\overline{X})^2\to \sigma^{2}
$$
where the $\to$ means convergence in probability.  There is no hypothesis on higher moments of $X_{n}$, so I believe that one cannot apply Chebyshev's theorem.  Furthermore this precedes any discussion of characteristic functions or the strong law of large numbers. How does one get this result without such tools? [This is probably the same question as this one : Convergence in probability of sample variance but the answers there apparently invoke the Strong Law which isn't proved until Chapter 7 of Resnick.]","['probability-limit-theorems', 'law-of-large-numbers', 'probability-theory', 'random-variables']"
1924366,Puzzle about throwing two darts at the first uncountable ordinal.,"This is something I read a while ago that I can't find the source of, but the source credited Axioms of symmetry: throwing darts at the real number line (Freiling 1986). Two people, each throws a dart at the set of the first uncountable ordinal. The first dart hits $n_1$, the second dart hits $n_2$. The one who hits the higher ordinal number wins. Since in the first uncountable ordinal, there are countably many ordinals less than $n_1$, but uncountably ordinals greater than $n_1$, the probability that the second player wins is 1. But if the two players don't interfere with each other, the order of throwing the dart ""shouldn't"" matter, so the probability that the second player wins ""should"" be $1/2$. What is the probability of the second player winning?","['paradoxes', 'elementary-set-theory', 'ordinals']"
1924375,How many ways can a word be formed from $8$ A's and $5$ B's if every A is next to another A and every B is next to another B?,"How many ways can a word be formed from $8$ A's and $5$ B's if every A is next to another A and every B is next to another B? Note: It doesn't have to be an actual legal word.  At least I think so. I can't do it with permutations or combinations, and I don't think listing these all out is a very good idea.  Thanks in advance for posting a solution!",['combinatorics']
1924402,Limits of functions that can't be attacked by Taylor series or L'hopital's rule,"Often on this site there is posed a question about a limit which is hard to resolve using l'Hopital.  (I don't mean probelms asking to find a limit without using 'Lhopital, I mean problems where using l'Hopital leads to roadblocks or subtleties.) I always attack those posed problems using Taylor series. For limit problems involving functions (as opposed to infinite sums or products) this pretty much always allows the limit to be found -- for the problems people pose here. I'm interested now in problems of the form ""find $\lim_{x\to a}f(x)$"" that resist solution by  l'Hopital's rule and also by Taylor series methods.  I have a fairly contrived example: $$\lim_{x\to 0}\frac{1-\cos\left(\frac{2}{x+e^{-1/x^2}} \right)}{\sin^2\left(\frac{1}{x}\right)}
$$
The combination of the topologist's sin curve in the denominator and the infinitely differentiable but non-analytic $e^{-1/x^2}$ as part of the numerator makes this poison to Taylor series methods, and differentiating the numerator or denominator only makes the behavior worse.  Yet the answer for this case is fairly obvious. My question is, can you find that limit (and prove the value you find is indeed the limit). And can anybody come up with a less contrived function whose limit resists Tayler series, yet can be found by a different technique?","['limits-without-lhopital', 'calculus', 'limits']"
1924472,"Working through Baby Rudin, what's the best approach? [duplicate]","This question already has answers here : What are some good math specific study habits? (7 answers) Closed 7 years ago . I'm currently working through Principles of Mathematical Analysis , and I'm thoroughly enjoying it, but I wanted to know from some of you who've read it before, what's the best approach to get the most out of Baby Rudin? I'm hoping to complete most, if not all of the exercises in it, that I'm sure of. No questions there. What I'm not so sure about is note taking, currently I'm taking truly copious amounts of notes, to the point where I've copy-pasted almost everything in the first chapter into my own book. It would be completely illogical to rewrite the whole book out just for the sake of it, and it would take me forever to complete the book that way. I know as I'm typing this, that this is a very subjective matter, and some people prefer to take copious amounts of notes, while others prefer to take none at all, but since this is my first true Definition-Theorem-Proof style book (if you can call it that), I want to find out what's the best way to tackle the book. For those of you who've read Baby Rudin, and more generally for all Definition-Theorem-Proof style books, how do you go about taking down notes? Do you copy-paste most of the stuff (i.e as I did)? Do you only take down notes on proofs and use the book as a reference for definitions and theorems? Do you take down all the definitions and theorems? Do you take down any of the exposition stuff (comments etc.)? Do you take as little notes as possible and only worry about doing the exercises? Do you try and reprove everything and not worry about notes as much? I know that each person studies in their own way, and this may be the softest of soft questions on Math.SE, but I'm highly interested to see how others have gone about working through Baby Rudin.","['real-analysis', 'reference-request', 'book-recommendation', 'soft-question', 'analysis']"
1924490,Why is Halloween the same as Christmas [closed],"Closed. This question is off-topic . It is not currently accepting answers. Closed 7 years ago . This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. This question is not about mathematics, within the scope defined in the help center . Improve this question Someone told me that Halloween was the same as Christmas and that it had something to do with math, is this a joke or does it actually have a mathematical basis?","['algebra-precalculus', 'puzzle']"
1924505,Algebra solve for $x$ in the equation $x^3 = x$,"I tried to solve for x in the equation $x^3=x$. I did $$x^3=x$$ $$x^2=1$$ $$x=\pm1$$ but it's wrong, can anyone help.",['algebra-precalculus']
1924529,How to find $\lim_{x \to \frac{\pi}{6}}\frac{\sin(x)-\frac{1}{2}}{x-\frac{\pi}{6}}$ without using L'Hospital's Rule?,"I have to find $$\lim_{x \to \frac{\pi}{6}}\frac{\sin(x)-\frac{1}{2}}{x-\frac{\pi}{6}}$$ We are not allowed to use L'Hospital's rule, any suggestions would be beneficial! I have tried multiplying by the conjugate (both the numerator and the denominator). I have tried using trig substitution.","['limits-without-lhopital', 'calculus', 'limits']"
1924650,How do I prove this identity involving the Mobius function and Euler's function?,"I've been trying to prove the following identity which has been used in a paper I'm currently reading: $\displaystyle\sum_{q\leq Q}\frac{\mu(q)^2}{\phi(q)}\leq \frac{k}{\phi(k)}\displaystyle\sum_{q\leq Q, (q,k)=1}\frac{\mu(q)^2}{\phi(q)}$. I tried to split the sum as $\displaystyle\sum_{q\leq Q}\frac{\mu(q)^2}{\phi(q)}=\displaystyle\sum_{r|k}\displaystyle\sum_{m\leq\frac{Q}{r},(m,\frac{k}{r}=1)}\frac{\mu(mr)^2}{\phi(mr)}$ but cannot proceed. Can anyone help? Here $\mu$ and $\phi$ are the Mobius function and Euler's totient function respectively.","['number-theory', 'analytic-number-theory']"
1924687,polynomial approximation in Hardy space $H^\infty$,"$H^\infty$ is the Hardy space of bounded analytic functions on the open unit disk $|z| < 1$ with the norm $$\|f\|  = \sup_{ |z| \,< \,1}|f(z)|$$
It has two important subspaces : $H^\infty_C$ the (closed) subspace of analytic functions that stay continuous on the closed unit disk $|z|\le 1$. $H^\infty_K $ the subspace of functions whose Taylor series stay convergent on $|z| = 1$ Question : Can you show that $H^\infty_C \subseteq H^\infty_K$, or find a counter-example $f \in H^\infty_C, f \not\in H^\infty_K$  ? Attempt : $f \in H^\infty_C, f \not\in H^\infty_K$ means its Fourier series diverges, so it can't be Holder continuous on the boundary, and the Dini's criterion should diverge. That's why I thought to $f(z) = \frac{z}{\log(1-z)}$, but it seems its Taylor coefficients are all of the same sign, so Abel's lemma guarantees it converges. Next try  : things like $\frac{1}{\log \log (1-z)}$ or $\frac{1}{\log \log \log \log (1-z)}$ (the branch $\log(1) = 2i\pi$) there is a proof of existence (but no example) of a $2\pi$-periodic continuous function whose Fourier series diverges at one point (but it doesn't have to be analytic, so it doesn't apply here) $f_N(z) = \sum_{n=0}^N \frac{f^{(n)}(0)}{n!} z^n$ is the truncated Taylor series. With $r \to 1^-$ , and $N \to \infty$ :
$$\begin{eqnarray}\|f(z)-f_N(rz)\| & \ =\ & \|(f(z)-f(rz))+(f(rz)-f_N(rz))\| \\
& \le &  \|f(z)-f(rz)\|+\|f(rz)-f_N(rz)\|
\end{eqnarray}
$$
$f \in H^\infty_C$ means it is uniformly continuous on $|z| \le 1$ so that $ \|f(z)-f(rz)\| = o(r)$, and $f(rz)$ is analytic on $1/r > 1$ hence it is approximated uniformly on $|z| \le 1$  by its truncated Taylor series $f_N(rz)$, so that $\|f(rz)-f_N(rz)\| = o_r(N)$ and
$$\|f(z)-f_N(rz)\| = o(r)+o_r(N)$$
showing that the polynomials are dense in $H^\infty_C$. But doing the same for $\|f(z) - f_N(z)\|$ is more complicated :
$$\begin{eqnarray}\|f(z)-f_N(z)\| & \ =\ & \|(f(z)-f_N(rz))+(f_N(rz)-f_N(z))\| \\
& \le &  \|f(z)-f_N(rz)\|+\|f_N(rz)-f_N(z)\| \\
& = & o(r)+o_r(N) + \mathcal{O}((r-1)N)
\end{eqnarray}
$$
Ideally, if $f \in H^\infty_K$ then we would have $\|f_N(rz)-f_N(z)\|< \alpha \|f(rz)-f(z)\| = o(r)$ so that $\|f(z)-f_N(z)\| = o(r) + o_r(N)$. Hence, for showing $f \in H^\infty_K$, one needs a good bound for $\|f_N(rz)-f_N(z)\|$, probably using that $$f_N(rz)-f_N(z) = \frac{1}{2i\pi} \int_{|s| = R} \frac{f(s)}{s} \left(\frac{1-(rz/s)^{N+1}}{1-rz/s}-\frac{1-(z/s)^{N+1}}{1-z/s}\right)ds$$","['functional-analysis', 'complex-analysis', 'fourier-series', 'polynomials']"
1924699,To prove that the algebraic multiplicity equals the dimension of the generalized eigenspace,"I am stuck at one step of the proof. Let $G_{T}(\lambda)$ be the dimension of the generalized eigenspace of an upper triangular matrix $T$ with eigenvalue $\lambda$, and let $\#_T(\lambda)$ be the number of times $\lambda$ appears on the diagonal. The author has already proved that
$$G_T(\lambda) \ge \#_T(\lambda)$$
and so the equality can be established by showing that
$$\#_T(\lambda) \ge G_T(\lambda)$$ The author uses MI on the dimensional $m$ of $T$, of which the base case $m=1$ is trivial. Then assume the inequality is true for all $1$ to $m-1$, and then consider an upper triangular matrix $T$ with dimension $m$. Suppose $\{v_1,v_2,\cdots,v_m\}$ is a basis for the vector space $V$ with diagonal entries $\lambda_1,\lambda_2,\cdots,\lambda_m$. Then $U=\langle\{v_1,v_2,\cdots,v_{m-1}\}\rangle$ is a subspace of $V$ that is invariant relative to $T$. Then the restriction $T_U:U\to U$ with basis $\{v_1,v_2,\cdots,v_{m-1}\}$ has an upper triangular representation with diagonal elements $\lambda_1,\lambda_2,\cdots,\lambda_{m-1}$, for which one can apply the induction assumption. Now, the author's induction step starts by this: Suppose that $\lambda$ is any eigenvalue of $T$. Then suppose that $v\in Ker((T-\lambda I_V)^m)$. As an element of $V$, we can write $v$ as a linear combination of the basis elements of $\{v_1,v_2,\cdots,v_m\}$, or more compactly, there is a
vector $u \in U$ and a scalar $\beta$ such that $v=u+\beta v_m$. Then, $$\beta(\lambda_m - \lambda)^m v_m =\beta(T-\lambda I_V)^m(v_m)$$ $$=-(T-\lambda I_V)^m (u) + (T-\lambda I_V)^m (u) + \beta(T-\lambda I_V)^m(v_m)$$
$$=-(T-\lambda I_V)^m (u) + (T-\lambda I_V)^m (u+\beta v_m)$$
$$=-(T-\lambda I_V)^m (u) + (T-\lambda I_V)^m (v)$$
$$=-(T-\lambda I_V)^m (u)$$
The final expression is an element of $U$ because $U$ is invariant relative to both $T$ and $I_V$. Hence
$$\beta(\lambda_m - \lambda)^m v_m=0$$
$$\cdots$$ I am stuck at the first step. The author says this step uses the theorem that if $\lambda$ is an eigenvalue of a matrix $A$, then for integer $s \ge 0$, $\lambda^s$ is an eigenvalue of $A^s$. But
$$(T-\lambda I_V)v_m \ne (\lambda_m-\lambda)v_m$$ Thanks in advance for any help! Regards!","['eigenvalues-eigenvectors', 'linear-algebra']"
1924733,Is there a tangential surface integral?,"In $\mathbb{R}^2$, we have two different types of line integrals, the tangential line integral
$$\int_C  \mathbf{F}\cdot d\mathbf r$$
and 
the normal line integral
$$\int_C  \mathbf{F}\cdot \mathbf n \,ds.$$ To give a motivation, these two different integrals are very helpful for understanding Divergence theorem and Stoke's theorem. Let $\mathbf {F} = P \mathbf i + Q\mathbf j$. The Divergence Theorem says
$$\iint_D \text{div}(\mathbf F)\,dx\,dy = \int_C  \mathbf{F}\cdot \mathbf n \,ds.$$
This gives 
$$\iint_D (P_x + Q_y) \,dx\,dy=\int_C \mathbf{F}\cdot (-dy, dx) = \int_C P\,dy - Q\,dx.$$
Stoke's theorem is 
$$\iint_D \text{curl}(\mathbf F)\cdot \mathbf k \,dx\,dy = \int_C  \mathbf{F}\cdot d\mathbf r$$
and this gives 
$$\iint_D (P_y - Q_x) \,dx\,dy=\int_C \mathbf{F}\cdot (dx, dy) = \int_C P\,dx + Q\,dy.$$ Green's theorem can be derived from either of the two above theorems. However, for all the surface integral, I have only seen the normal surface integral defined by 
$$\iint_D \mathbf F\cdot \mathbf n\, dS$$
is there a similar concept that is close to the tangential line integral $\int_C  \mathbf{F}\cdot d\mathbf r$?","['real-analysis', 'partial-differential-equations', 'surface-integrals', 'multivariable-calculus', 'vector-analysis']"
