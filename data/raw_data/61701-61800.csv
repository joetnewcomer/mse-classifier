question_id,title,body,tags
697094,What's the name of this chaotic system? (Cool pics included.),"I found this playing with a 2D-ODE-system plotter I'm writing. Surely, since it's so simple, it's been found and extensively studied by someone. What's it called? I'd like to look it up and learn a little about it. There's a weird pattern were some are simple spriograph-like graphs and the others are completely chaotic. In case anyone enjoys seeing these as much as I do, I'll add an album on imgur for your viewing pleasure. The titles are of the form ""$x_0$_$y_0$"". These are all rendered with VODE from Scipy with $t_0=0$ and $t_1=1000$. $$
\begin{eqnarray*}
x' &=& \cos(y)+\sin(t) \\
y' &=& \sin(x)+\cos(t)
\end{eqnarray*}
$$ Here's the album: https://i.sstatic.net/tAxrW.jpg If anyone's interested, I uploaded a video of (1,1) plotted from t=0 to 250 with the vector field: https://vimeo.com/88323596 .","['dynamical-systems', 'ordinary-differential-equations', 'chaos-theory']"
697096,Prove that any palindrome with an even number of digits is divisible by 11,"Confusing myself here, need some clarification.. First, we consider the palindrome $abccba$ . We can see this can be written as $$a(10^5 + 10^0) + b(10^4 + 10^1) + c(10^3 + 10^2) = a(10^5 + 1) + 10b(10^3 + 1) + 100c(10 + 1)$$ So essentially we see that all palindromes of even digits can be written in the form $x(10^{2k+1} + 1)$ , i.e. we must show that any number of the form $(10^{2k+1} + 1)$ is divisible by $11$ . Base case: $10^{2(0)+1} + 1 = 10 + 1 = 11$ , which is clearly divisible by $11$ . Induction hypothesis: Assume that $(10^{2k+1} + 1)$ is divisible by $11$ , we work to show that $(10^{2(k+1)+1} + 1)$ is divisible by $11$ . That is, $(10^{2k+3} + 1) = (10^2\cdot10^{2k+1} + 1) = \dots$ Where am I going wrong?","['induction', 'palindrome', 'number-theory']"
697104,"Joint pdf of $f(x,y)=e^{-(x+y)}$","I am asked to find the joint pdf of $\ f(x,y)=e^{-(x+y)} $
where $x,y$ are between $0$ and $\infty$ or $0$ otherwise. I can see its an exponential distribution, which means its continuous so I started a double integral like this: $\displaystyle\int_{0}^{\infty} \int_{0}^{\infty}e^{-x}e^{-y} dy dx$ I tried substituting in $u=e^{-x}$ and $du= -e^{-x} $ $v=e^{-y}$ and $\int v= \int   e^{-y}dy=-e^{-y} $ My result after substituting y for 0 and $\infty$ is $\int_{0}^{\infty} e^{-x}-e^{-x}dx$ = $-e^{-x}-e^{-x}$ and with limits applied I get $2$. 
I can see that the answer should be EXP(1) since the exponential pdf is $\lambda e^{-\lambda x} $ so for my example $\ e^{-(x+y)} $ it must be $1$. (EXP(1) is the answer in the back of the text book for the marginal pdfs).
Am I on the right track with my integration please or am I doing all of this wrong? Thanks.","['statistics', 'probability-distributions', 'statistical-inference']"
697120,Real numbers via equivalence classes of Cauchy sequences and the Completeness Axiom,"Hi so there's a question in my elementary real analysis course I'm a little bugged about. The question goes: Use the definition of the real numbers via equivalence classes of Cauchy sequences to prove the Completeness Axiom. I tried using proof by contradiction by first stating Completeness is false. Then every nonempty subset S of R that is bounded above has no least upper bound. I wanted to construct a Cauchy sequence of descending upperbounds and show that these upperbounds converge to real number which would be the least upperbound, resulting in a contradiction. Is this a valid method? If so, I'm a little stuck on the details of such a Cauchy sequence. Any help is much appreciated.",['real-analysis']
697151,"Show that if G is a simple graph with at least 4 vertices and 2n-3 edges, it must have two cycles of the same length.","For $n\ge4$ , let G be a simple n-vertex graph with at least $2n - 3$ edges. Prove that G has two cycles of equal length. (West's Introduction to Graph Theory Q 2.1.42) I am trying to prove the above claim. So far I have reasoned as follows: G must be connected because $2n-3\ge n-1$ for $n\ge4$ , and any simple n-vertex graph with at least $n-1$ edges must be connected. Let T be a spanning tree of G. T must have $n-1$ edges. Therefore T has at least $2n-3 - (n-1) = n-2$ fewer edges than G. That is, $|e(G) \setminus e(T)| \ge n-2$ . Each one of these 'extra' edges adds exactly cycle to G, so G has at least $n-1$ cycles, each with length 3 to n. Because there are at least n-2 cycles in G, it suffices to show that $n-2$ of these edges cannot all have distinct sizes. (I'm unsure about this line... is this a correct statement?) From here I've lost my way, but I think I am on the right track. For what it's worth, this question appears right after the section that introduces trees, spanning trees, and their properties etc. Thank you!","['graph-theory', 'discrete-mathematics', 'trees']"
697160,"Meaning of ""almost everywhere"" in measure theory.","I'm slightly confused about the term almost everywhere as it is used in Folland's real analysis. Given a measure space $(X, \mathcal{M}, \mu)$  Suppose $f \equiv g$, $\mu$-almost everywhere where $f, g : X \to \mathbb{R}$. Does this mean that $$\mu(\{x : f(x) \ne g(x) \}) = 0$$ Or that there exists a measurable set $E$ such that $\{x : f(x) \ne g(x) \} \subseteq E$ and $\mu(E) = 0$? This issue came up when my professor was proving the following theorem from Folland: To prove (a) $\implies$ $\mu$ is complete, he took a null set $N \in \mathcal{M}$ and said for any $E \subseteq N$, $1_E \equiv 0$ almost everywhere.  This part confused me, because how can we know if $E$ is measurable?","['measure-theory', 'real-analysis']"
697201,The functor $\mathrm{Haus}\to\mathrm{Set}$ sending a space to its set of open sets is not representable?,"I know the contravariant functor $\mathrm{Top}\to\mathrm{Set}$ sending a topological space to its set of open sets is representable, with representing object being the two point space with precisely one singleton being the only nontrivial open set. Why do things not work in the category of Hausdorff spaces? Towards a contradiction, I suppose the functor $F$ is representable, so $F(-)\cong\operatorname{Hom}_{\mathrm{Haus}}(-,A)$ for some representing space $A$. In particular, $F(A)\cong\operatorname{Hom}(A,A)$. Let $U\in F(A)$ be the universal element corresponding to $\mathrm{id}_A$. Then for any space $B$, and any $V\in F(B)$, there is a unique morphism $f\colon A\to B$ such that $F(f)(V)=U$, i.e., $f^{-1}(V)=U$. This unique morphism is $\eta_B^{-1}(\eta_A(U))$ where $\eta_X$ is the component morphism $F(X)\to\mathrm{Hom}(X,A)$. This claim certainly seems unlikely, so that $F$ is not representable. However, I'm having trouble coming up with a concrete example to show this cannot be.","['general-topology', 'category-theory']"
697204,Is any UFD also a PID?,"Is there any counterexample that will disprove that every unique factorization domain (UFD) is also a principal ideal domain (PID)? I mean, any PID is a UFD, does the converse hold? Thanks in advance!","['ring-theory', 'abstract-algebra', 'principal-ideal-domains', 'commutative-algebra', 'unique-factorization-domains']"
697241,limit of increasing sequence of measures is a measure,"Statement Let $(X,\Sigma,\mu)$ be a measurable space and let $(\mu_n)_{n\geq 1}$ be a sequence of measure in this space. Suppose that this is a monotone increasing sequence, in the sense that $\mu_n(E)\leq \mu_{n+1}(E)$ for all $E \in \Sigma$, and for all $n$. If we define, for every $E \in \Sigma$ $\space$  $\mu(E)=\lim_{n \to \infty} \mu_n(E)$, prove that $\mu$ is a measure. The attempt at a solution I am having problems trying to prove the countable additivity property, which is, if $\{E_i\}_{i \in \mathbb N}$ is a countable collection of pairwise disjoint sets in $\Sigma$, then 
$\mu(\bigcup_{i \in \mathbb N} E_i)=\sum_{i \in \mathbb N} \mu(E_i)$ In this particular case, the property is satisfied if and only if $\lim_{n \to \infty} \mu_n(\bigcup_{i \in \mathbb N} E_i)=\sum_{i \in \mathbb N}\lim_{n \to \infty}\mu_n(E_i)$ Each $\mu_n$ is a measure, so $\lim_{n \to \infty} \mu_n(\bigcup_{i \in \mathbb N} E_i)=\lim_{n \to \infty} \sum_{i \in \mathbb N} \mu_n(E_i)$. How could I go on from here? I know I must use the fact that $(\mu_n)_{n \in \mathbb N}$ is a monotone increasing sequence, I would appreciate any help.","['measure-theory', 'real-analysis']"
697245,parametrization of the hyperboloid of two sheets,"Find the parametrization for the hyperboloid of two sheets${(x,y,z) \in \mathbb{R}^3}; -x^2-y^2+z^2=1$. Ok so I saw two answers for this question: $x(u,v)=(\sinh u \cos v, \sinh u \sin v, \cosh u)$ and $x=(u,v)= (\cosh u \sinh v, \sinh v, \cosh u \cosh v)$. I'm pretty sure the first one is the correct one. But I'm confused on how to parametrize. So what I think is, $$x^2+y^2-z^2=-1$$ $$x^2+y^2=z^2-1$$ $$r^2=z^2-1$$ $$r=\sqrt{z^2-1}$$ So, $x=r\cos v$=$\sqrt{z^2-1}\cos v$, $y=r\sin v= \sqrt{z^2-1}\sin v$, and $z= \sqrt{z^2-1}$. Clearly I know this isn't right but I'm not sure how to go from here. I know we need to get the partial derivative and I guess somehow that gets us the missing part. Can someone help please.",['differential-geometry']
697282,Found an example for solving via quadratic formula in a book where I am wondering if this is correct,"As a refresher, I was skimming through a free Calculus online textbook ""MOOCULUS massive open online calculus"" ( https://mooculus.osu.edu/handouts ) and stumbled upon the following example solving a quadratic equation via the quadratic formula: Is the step where they get rid of the -10 in the denominator correct? I am wondering because sqrt(81)/10 is != sqrt(8.1) for example.","['quadratics', 'algebra-precalculus', 'functions']"
697305,Prove $ (A \cup B) \cap C$ = $(A \cap C) \cup (B \cap C) $,"Prove $ (A \cup B) \cap C$ =  $(A \cap C) \cup (B \cap C) $ Starting from the left side, $ (A \cup B) \cap C = $ By distributive law, ( distributing the $\cap C$), we have $ (A \cap C ) \cup (B \cap C) = $ Therefore, $ (A \cap C ) \cup (B \cap C) = (A \cap C) \cup (B \cap C)$ If I start from the right, I have =  $(A \cap C) \cup (B \cap C) $ By Distributive Law =  $(A \cup B ) \cap C$ Therefore,
$ (A \cup B) \cap C$ =  $(A \cup B ) \cap C$ Did I do this correctly or do I need to include the set union definition and the set intersection definitions? Assuming that I need to include the set union definition of $A \cup B$ for the left side 
$[x: x \in A \lor x \in B]$ so that means that x belongs in A or x belongs in B For the right side I would have set intersection $[x: x \in A \land x \in C]$ so x belongs in A and x belongs in C $[x: x \in B \land x \in C]$ so x belongs in B and x belongs in C so maybe it's like this? $[x: x \in A \land x \in C] \lor [x: x \in B \land x \in C]$ and then by distributive law I would have gotten $[x: x \in A \lor x \in B] \land C$ which becomes $(A \cup B) \cap C$ My question is how do I write a better proof than this jumbled mess?","['elementary-set-theory', 'proof-verification']"
697327,What is the generalization of Gauss's Theorem to a manifold?,"In a (pseudo-)Riemannian manifold with constant basis vectors, one certainly has that the integral of the divergence of a tensor field $T$ over a submanifold $\Omega$ is equal to the integral over the boundary $\partial\Omega$ of the inner product of $T$ with the outward-directed unit normal vector. To be more explicit, in component form in Minkowski space,
$$ \int\limits_\Omega \partial_\mu {{T^\alpha}_\beta}^\mu \ \mathrm{d}x^0 \wedge \mathrm{d}x^1 \wedge \mathrm{d}x^2 \wedge \mathrm{d}x^3 = \int\limits_{\partial\Omega} {{T^\alpha}_\beta}^\mu \varepsilon_{\mu|\alpha\beta\gamma|} \ \mathrm{d}x^\alpha \wedge \mathrm{d}x^\beta \wedge \mathrm{d}x^\gamma, $$
where I'm using the convention in Misner, Thorne, & Wheeler that $|\alpha\beta\gamma|$ runs over all indices such that $0 \leq \alpha < \beta < \gamma \leq 3$, and $\epsilon$ is the Levi-Civita symbol/tensor (there being no difference in the lowered-index form in Minkowski space). The problem is, the proof given in that book only makes sense in Cartesian coordinates. What if I have some arbitrary coordinates in a curved manifold? Is there an analogous equation relating
$$ \int\limits_\Omega \nabla_\mu {{T^\alpha}_\beta}^\mu \sqrt{|g|} \ \mathrm{d}^4x \leftrightarrow \int\limits_{\partial\Omega} {{T^\alpha}_\beta}^\mu n_\mu \sqrt{|\gamma|} \ \mathrm{d}^3x? $$
(Here $\nabla$ is the covariant derivative compatible with the metric, $g$ is the determinant of the metric, and $\gamma$ is the determinant of the induced metric on the surface.) Wald 1 shows in an appendix that
$$ \int\limits_\Omega \nabla_\mu v^\mu = \int\limits_{\partial\Omega} v^\mu n_\mu, $$
where I've followed his lead and suppressed the volume elements. This would seem to indicate that I can follow a naive ""partial to covariant"" prescription to make my first equation turn into my second. But does this work for arbitrary tensors? I worry because rank $(1,0)$ tensors can have fortuitous cancellations, such as how $\nabla_\mu v^\mu = \partial_\mu (\sqrt{|g|} v^\mu) / \sqrt{|g|}$ holds without extra connection terms. 1 Yes, another physics book. It occurs to me that I don't own any pure math differential geometry books.","['physics', 'differential-geometry']"
697337,Understanding the definition of the empirical measure,"I'm reading Kosorok's Introduction to Empirical Processes and Semiparametric Inference and I'm stuck on an important definition. We define the empirical measure to be $P_n=n^{-1}\sum_{i=1}^n\delta_{X_i}$, where $\delta_x$ is the measure that assigns mass 1 at $x$ and zero elsewhere. For a measurable function $f : X \rightarrow R$, we denote $P_nf=n^{-1}\sum_{i=1}^nf(X_i)$. First, let me take a crack at $P_n$: is it the same as $n^{-1}\delta_{U_{i}X_i}$ where I use $U_{i}X_i$ to denote the union of the points $X_i$ over $i$? Does $P_n$ inherently only work on functions? And then, does $P_nf$ follow directly from the definition of $P_n$? I'm confused by the wording ""we denote"". Is this a new definition?","['probability-theory', 'measure-theory']"
697339,Why and When is a determinant of a larger matrix equal to a determinant of a smaller matrix?,"The following is written in the solution of my textbook. $$|A|= \left| \begin{array} {cccc} 
1 & 2& -1& 4 \\
0& 5& -1& 6 \\
0& -3& 3& -6 \\
0& 2& 2& -1\\
\end{array}
\right| = \left| \begin{array} {ccc} 
5& -1& 6 \\
-3& 3& -6 \\
2& 2& -1\\
\end{array}
\right|$$ where $A=\left[ \begin{array} {cccc} 
1 & 2& -1& 4 \\
0& 5& -1& 6 \\
0& -3& 3& -6 \\
0& 2& 2& -1\\
\end{array}
\right]$ I can see that we are ignoring column 1 and row 1 of $A$ to compute the determinant. But I don't understand why this is a valid operation. Can someone please show me what are the properties of determinants/matrices that are being used to justify this?","['matrices', 'determinant']"
697345,Splitting of exact sequence of groups when middle group has split subgroup.,"I am trying to show that a short exact sequence of abelian groups splits. I have a short exact sequence, $$0\rightarrow \mathbb{Z} \rightarrow G \rightarrow \mathbb{Z}_2 \rightarrow 0$$ and I know that  $\mathbb Z \oplus \mathbb Z_2$ is a subgroup of $G$. Do I have a splitting by sending the generator of $\mathbb Z_2$ to the generator of $\mathbb Z_2$ in $G$?","['group-theory', 'abstract-algebra', 'abelian-groups']"
697388,Relations between monoids and modules?,"What is the relation between monoids and modules? Are they completely different algebraic structures, or is there a kind of inclusion relation like ""elements of a module are also elements of a monoid""?","['elementary-set-theory', 'monoidal-categories', 'category-theory', 'monoid', 'modules']"
697399,Prove or disprove $(A + B) \cap C = (A \cap C) +(B \cap C)$,"Prove or disprove $(A + B) \cap C = (A \cap C) +(B \cap C)$ I want to disprove this statement. $(A+B)$ is the symmetric difference and has the form of $(A \cup B) \backslash (A \cap B)$ I am starting on the left which is $(A + B) \cap C $ If I take the complement definition of $(A+B)$, I would have $[x: x \in A \cup B \land x \notin A \cap B]$ So I am left with $A \cup B$ now I'm going to use the distributive law $\cap C$ on $A \cup B$ The result would be $(A \cup C) \cap (B \cup C)$ $(A \cup C) \cap (B \cup C) \neq (A \cap C) +(B \cap C)$ because in the middle we have $\cap$ on the left and $+$ on the right... but that's wrong. What if I let $ C = \emptyset$ ? Then I would have $(A +B) \cap \emptyset = (A \cap \emptyset) +(B \cap \emptyset )$ I'm going to start at the right this time .. because I've seen some properties already and it's similar to what I did weeks before $= (A \cap \emptyset) +(B \cap \emptyset )$ Universal Bound Law $A \cap \emptyset = \emptyset$ $= (\emptyset) +(\emptyset )$ If I take the symmetric difference of $= (\emptyset) +(\emptyset )$ it's an empty set. hmmm now that I think about it...if I approach it this way it looks like I'm proving that they are indeed equal. $(A + B) \cap \emptyset$ [ distributive law] $(A \cap \emptyset ) + (B \cap \emptyset)$ [universe bound laws] $( \emptyset ) + ( \emptyset)$ [symmetric difference] that's an empty set... I want to disprove this statement... but how? edit: another attempt at this problem using set intersection definition Prove or disprove $(A + B) \cap C = (A \cap C) +(B \cap C)$ Suppose $x \in (A +B) \cap C$, then $[x \in (A +B)] \cap C$ and we have $(x \in A + x \in B) \cap C$ For $x \in A$, by set intersection definition, we have $x \in A \land C$ and $x \in B \land C$ [maybe for $x \in C$, by set intersection definition, we have $x \in A \land C$ and $x \in B \land C$ since C is being distributed, not A. ] By symmetric difference definition, we have $x \in A \land C + x \in B \land C$ Therefore, $(A \cap C) +(B \cap C)$ Is this correct?!","['elementary-set-theory', 'proof-verification']"
697402,How do I solve this infinite limit?,"I have this limit: $$ \lim_{x\to\infty}\frac{x^3+\cos x+e^{-2x}}{x^2\sqrt{x^2+1}} $$ I tried to solve it by this: $$ \lim_{x\to\infty}\frac{x^3+\cos x+e^{-2x}}{x^2\sqrt{x^2+1}} = \lim_{x\to\infty}\frac{\frac{x^3}{x^3}+\frac{\cos x}{x^3}+\frac{e^{-2x}}{x^3}}{\frac{x^2\sqrt{x^2+1}}{x^3}} = \frac{0+0+0}{\frac{\sqrt{\infty^2+1}}{\infty}}$$ I do not think that I got it right there... Wolfram also says that the answer is $1$, which this does not seems to be. How do I solve this?",['limits']
697414,Closed-form expression for a hypergeometric series,"What is the closed-form expression for $${}_2 F_1 \left(1+2\lceil n/2\rceil,-n;1/2;-z/4\right)$$ According to the book Concrete Mathematics (R.Graham, D.Knuth, O.Patashnik 2nd), the authors say the general sum of $\sum_k {\ n-k \choose k}z^k$ leads to  the closed form of the above series. I understand $\sum_k {\ n-k \choose k}z^k= \frac{1}{\sqrt{1+4z}}((\frac{1+\sqrt{1+4z}}{2})^{n+1}-(\frac{1-\sqrt{1+4z}}{2})^{n+1})$, but I can not see how this sum leads to the closed-form of the the hypergeometric series.","['special-functions', 'closed-form', 'sequences-and-series', 'hypergeometric-function']"
697425,"When is a local, reduced, (commutative) ring an integral domain?","Question I am wondering whether or not it is true that if $A$ is a reduced ring, then 
is it the case that the localization of $A$ at any of its prime ideals is an integral domain? Discussion Recall that $A$ is reduced if it contains no nonzero nilpotents, i.e. $Nil(A)=\{0\}$. I have already shown the following two facts: A ring $A$ being reduced is a local property, i.e. $A$ is reduced if and only if the localization of $A$ at any prime ideal is reduced. $A$ reduced does not imply $A$ is an integral domain (in general). The counter example I used to prove $2$ was $\mathbb{Z}/6\mathbb{Z}$. Unfortunately, in this case all the localizations at prime ideals are integral domains, and they seem to be in every example I can think of. More generally, one could ask the question (since localizations are local rings), when is a reduced local ring an integral domain? If anyone had a good idea for a counterexample to the original question (or a proof if it is true-although I doubt this since being an integral domain seems much stronger than being reduced), that would be much appreciated. This is one of 12 parts to a question which I had on my midterm a few weeks ago, and the only part I have not figured out of that question","['commutative-algebra', 'ring-theory', 'abstract-algebra']"
697433,A family has three children. What is the probability that at least one of them is a boy?,"According to me there are $4$ possible outcomes: $$GGG \ \ 
BBB \ \ 
BGG \ \
BBG $$ Out of these four outcomes, $3$ are favorable. So the probability should be $\frac{3}{4}$. But should you take into account the order of their birth? Because in that case it would be $\frac{7}{8}$!",['probability']
697456,Why the tempered distribution is zero?,"My question is derived from the proof of the equation $\Delta f=f$ which has no nonzero solution in $\mathscr{S}'(\mathbb{R}^n)$. The ideal to solve this equation is to use the Fourier transform. By using Fourier transform, we have $-4\pi^2\left | \xi  \right |^2\mathscr{F}f(\xi)=\mathscr{F}f(\xi)$. Hence, the Fourier transform of $f$ must be zero at our first glance. However, I don't know the deep reason in tempered distribution sense. This question can be generalized as follows: Suppose $f\in \mathscr{S}'(\mathbb{R}^n)$ and $g\in \mathscr{O}^n_M$,
where
$$\mathscr{O}^n_M:=\left \{h(x)\in C^\infty(\mathbb{R}^n): \forall \alpha, \exists C(\alpha)>0, N(\alpha)\in\mathbb{N}\cup\{0\}, s.t.\quad |D^\alpha h(x)|\leq C(\alpha)(1+|x|^2)^{N(\alpha)}\right \}
$$
is the multiplier of $\mathscr{S}'(\mathbb{R}^n)$. Then the product $``gf""$ is well defined by $<gf, \varphi>=<f, g\varphi>$, $\forall \varphi\in\mathscr{S}(\mathbb{R}^n)$. My question is: Fix a $g\in \mathscr{O}^n_M$ and $g\neq 0$, if every $\varphi\in\mathscr{S}(\mathbb{R}^n)$ we have $<gf, \varphi>=0$, then can we make a conclusion that $f=0$ in $\mathscr{S}'(\mathbb{R}^n)$ ?","['distribution-theory', 'functional-analysis', 'schwartz-space']"
697472,Fourier series for $e^x$,"I'm trying to teach myself partial differential equations from Strauss' book. I have run into a very bizarre problem - I cannot figure out what is the Fourier series of $e^x$! And not even Google has helped. The book's general formula is with . The book's answer for the $e^x$ fourier series is But I derived this by hand (and with Mathematica) independently: So what gives? Did Mathematica and I both fail to do a simple straightforward computation? Or did the book just pull something out of a hat? In addition, I cannot figure out how to transfer from a complex Fourier series to a real one. I assume one cannot just take the real part?","['fourier-series', 'ordinary-differential-equations', 'partial-differential-equations', 'mathematica', 'complex-analysis']"
697491,"if derivative vanishes in a path connected set, then $f$ is constant on that set?","Let $f: \mathbb{R}^d \to \mathbb{R}^m $ be a function sucht that $Df(a) = 0 $ for all $a \in U \subseteq \mathbb{R}^d$. Also, suppose $U$ is open and path-connected. Question: IS $f$ constant on $U$ ??","['calculus', 'real-analysis']"
697520,Properties of the indiscrete rational extension of $\mathbb{R}$,"Let $X = \mathbb R$ equipped with the topology generated by open intervals of the form $(a,b)$ and set of the form $(a,b)\cap \mathbb Q.$ Then $X$ is regular. $X$ is normal $X$ \ $\mathbb Q$ is dense in $ X$ $\mathbb Q$ is dense in $X$ My attempt is : for (3) $(a-\epsilon,a+\epsilon) \cap \mathbb Q$ is nbd of a $\in \mathbb Q$ intersect with $X$ \ $\mathbb Q$ is empty, so $X$ \ $\mathbb Q$ is not dense in $X$ for (4) i think $\mathbb Q$ is dense in $X$ Please give  me the counter example of (1) and (4). Thank you.","['general-topology', 'examples-counterexamples']"
697531,Are the fibers of a flat map homotopy equivalent?,"At the end of the Wikipedia article on Deformation Retract , there is the following sentence: Two spaces are homotopy equivalent if and only if they are both deformation retracts of a single larger space. I was wondering if this has some meaning in Algebraic Geometry. For instance, consider the situation of a flat surjective map of complex schemes $f:X\to S$, where $S$ is a smooth curve, e.g. the formal disk. Question 1 . Are the fibers of $f$ homotopy equivalent? Is every fiber $X_s$ a deformation retract of the total space $X$? I tried to show, first, that any fiber is a retract of the total space, but I am unsure about my solution, and in any case it is weaker than deformation retract. But it goes as follows: if $X_0$ is a particular fiber of $f$, we can define a retraction $r:X\to X_0$ as the identity on $X_0$, and by
$$r(x)=\{x\}^-\cap X_0,\,\textrm{for }x\in X\setminus X_0.\,\textrm{(this is the flat limit I guess)}$$ Question 2 . In the topological category, say we have a topological fiber bundle $X\to S$. Are the fibers homotopy equivalent? Thanks for any clue on this!","['general-topology', 'algebraic-geometry', 'algebraic-topology']"
697538,Exterior power of a space of maps $(\mathbb{K}^T)$,"We are given a set $T \neq \emptyset, \ \ p \ge 1, \ \ p_i : T \rightarrow \mathbb{K}$ Could you help me prove that if $ \phi: (\mathbb{K}^T)^p \ni (f_1, ..., f_p) \rightarrow \rho \in \mathbb{K}^{T^p}$ where $\rho: T^p \ni (x_1, ..., x_p) \rightarrow det [f_i(x_j)]_{i,j = 1, ... p} \in \mathbb{K}$ then $(\mathbb{K}^{T^p}, \phi)$ is the $p$-th exterior power of $\mathbb{K}^T$? I know that $\phi$ is $p$-linear and anti-symmetric, because $\det$ is $p$-linear and anti-symmetric, but I have problems finding the unique linear map which makes the proper diagram commute. Could you help me with that? Thank you.","['exterior-algebra', 'linear-algebra', 'analysis']"
697551,On track Prerequisite for Statistics and Probability,"I do not really have a solid mathematical background because of the range of courses i had back in high school/university that wasn't really scientific oriented. Presently i am doing an MSc in Computer Science which is going pretty well and almost completed but somehow, i have this nemesis course that deals with Poisson processes, Bernoulli, Markov chains and Branching process.The whole class(formulas) sounds Chinese to me although i am able to get the concepts. So i will like to ask : If you met this course today with no mathematical background, how will you approach it ? I have time to get back to the basics ! I just need to know a clear path before i start hitting the books. Thank you very much !","['statistics', 'markov-chains', 'probability-theory', 'probability-distributions', 'probability']"
697558,"$k$th difference of $1,2^k,3^k,...$","I read, in an exposition of Euler's proof of Fermat's theorem on sums of squares, that the $k$-th order finite forward difference of the function $f(x_i)=x_i^k$, relatively to the nodes $x_i=i$ where $i=1,2,3,...$, defined by the recurrence $\Delta^n f(x_i):=\Delta^{n-1} f(x_{i+1})-\Delta^{n-1} f(x_{i}),\quad \Delta^1 f(x_i)=\Delta f(x_i):=f(x_{i+1})-f(x_i),\quad n=1,2,...$ is always $k!$ for any natural number $i=1,2,3,...$. For $x_{i+1}=x_i +h$ Wikipedia gives the formula (easily proved by induction) $\Delta^{k}f(x_i)=\sum_{j=0}^k (-1)^j \binom{k}{j}f(x_i+(k-j)h)$, which, in our case where $x_i=i$, $h=1$ and $f(x)=x^k$, gives $\Delta^k f(i)=\sum_{j=0}^k (-1)^j\binom{k}{j} (i+k-j)^k$. But I am not able to use that to prove (I've tried by induction, in vain) that for all $i\in\mathbb{N}_{\geq 1}$, for $f(x)=x^k$, we have $\Delta^k f(i)=k!$. Neither am I able to prove it by recursion because it isn't a linear one... Has anybody any idea on how to prove it?
Thank you so much in advance!","['elementary-number-theory', 'discrete-mathematics']"
697590,Finding the coordinate vector relative to a given basis,"Given the basis $\beta = \{(1,-1,3),(-3,4,9),(2,-2,4)\}$ and $x = (8, -9, 6)$, I am to find the corresponding coordinate vector $[x]_\beta$. I claim that the coordinate vectors entries $x_1,x_2,x_3$ meet the following criterion: $$x_1(1,-1,3)+x_2(-3,4,9)+x_3(2,-2,4) = (8,-9,6)$$ This is equivalent to solving the augmented matrix \begin{bmatrix}
1 &-3 &2 & 8\\-1 & 4 & -2 & -9\\3 & 9 & 4 & 6
\end{bmatrix} which is row equivalent to \begin{bmatrix}
1 &-3 &2 & 8\\0 & 1 & 0 & -1\\0 & 0 & -1 & 0
\end{bmatrix} which gives $x_3 = 0$, $x_2 = -1$ and $x_1 = 3x_2 + 8 = 5$, thus the coordinate vector $(5, -1, 0)$ There is an error here, seeing as the text claims a different answer. What is the error? In particular, is it computational or simply an error in my understanding of the question? Edit: fix typo in equation",['linear-algebra']
697596,Proof of there's no homeomorphism between Euclidean spaces,"I read a wonderful proof about there's no homeomorphism between Euclidean spaces of 1 and 2 dimension. If there is, then Euclidean space of 1 and 2 dimension are homeomorphic and hence have the same topological properties. But when one remove one point from 1 dimensional Euclidean space, it becomes disconnected while it is not when remove from 2 dimensional space. So I'm wondering if I can generalize to any dimension $m,n$, assuming $m<n$. Then I remove an $m-1$ dimensional subspace from both spaces. And one is connected, the other is not. So the homeomorphism doesn't exist. Am I right? Edit: Thanks for all replies. I'm current unknown for algebraic topology. Could you please explain me for why the method I use is invalid?","['general-topology', 'algebraic-topology']"
697600,Natural uses for the co-product of sets?,"I had come across countless uses of the (Cartesian) product of sets long before I first ever met the concept of a ""co-product"" 1 of sets.  In fact, anyone who has learned basic analytic geometry in high-school is already acquainted with at least one good example of a Cartesian product of sets. Does the concept of a co-product of sets have a useful life prior (or at least independent of) its role as obligatory example of elementary category theory? I'm looking for examples accessible to ""non-mathematicians"" (by which I really mean non-math-majoring undergraduates) in which the concept of a co-product of sets proves natural and useful (in the same way that, say, the product of two coordinate axes provides a natural and useful way to think about points on a plane). Epilogue The answers I received were very thought-provoking; thank you all! While thinking about MJD's and Martin Brandenburg's answers in particular my understanding of co-products of sets, and of their products for that matter, changed radically.  Now I've come to regard the co-product as a more natural and ubiquitous construct than the product 2 .  This is a complete reversal of how I saw them when I first posted my question.  I'd like put out these thoughts here, for whatever utility they may have for others, and whatever constructive criticism I may get. Since what follows is a bit long, here's the punchline: In $\def\Set{\mathbf{Set}}\Set$ , co-products are partitioned domains ; products are parametrized codomains. OK, here it goes.  After mulling over your answers, my thought now is that the standard description of the co-product in the $\Set$ category as "" the disjoint union"" makes it appear a lot more exotic than it is in reality.  Basically, the co-product arises whenever a domain is partitioned into subdomains : the partitioned domain is the co-product of these subdomains.  (The inclusion of the subdomains into the domain are, of course, the co-product's canonical inclusions.) This situation arises all the time .  Anyone who has been exposed to highschool math is familiar with piecewise definitions of functions, such as, for example, the standard definition of the absolute value function $|\cdot|:\mathbb{R}\to\mathbb{R}_{\ge 0}$ , $$
\left|x\right| = \left\{
  \begin{array}{lr}
    x, & \mathrm{if}\; x \ge 0\\
    -x, & \mathrm{if}\; x < 0
  \end{array}
\right.
$$ Such piecewise definitions amount to expressing the domain of a $\Set$ morphism (i.e. the function being defined) as the co-product of the domains of the ""pieces"" that the definition ""stitches together.""  In the example above, these stitched-together pieces are the $\Set$ morphisms $f_0:\mathbb{R}_{\ge 0}\to\mathbb{R}_{\ge 0}$ and $f_1:\mathbb{R}_{< 0}\to\mathbb{R}_{\ge 0}$ defined by $$
\begin{array}{lr}
    f_0(x) = & x\\
    f_1(x) = & -x
\end{array}
$$ But such maneuvers are not limited to Mathematics.  Every procedure whose first stage is a ""channeling"" of the input into one of several mutually exclusive cases (e.g. ""whites"" and ""colors""), and associates a different sub-procedure with each case (e.g. ""wash in hot water"" and ""wash in lukewarm water""), to finally produce an output of ""a uniform kind"" (e.g., ""washed laundry""), is one that fits the description of the co-product in $\Set$ . I think that what makes it so easy to miss the ubiquity of the co-product in $\Set$ is that expressions such as $$X = \bigsqcup X_\alpha$$ tend to be interpreted as describing a synthetic operation, namely, one that starts with some arbitrary sets $X_\alpha$ , and combines them into "" their disjoint union"".  My point is that in practice such a maneuver is rare in comparison to the one that goes in the ""opposite direction"", namely, the analytic operation that starts with some set $X$ , and partitions it into subsets $X_\alpha$ . The unfortunate irony here is that it is precisely the needs of the in-practice-rare synthetic operation that necessitates introducing an exotic ""disjoint union"" operation (and even more exotic constructions of it, via ""tagged sets"" and the like), since arbitrary sets $\{X_\alpha\}$ cannot be assumed to be pairwise-disjoint. In contrast, the analytic operation, which is readily recognizable by anyone who has ever sorted out a bunch of items into separate classes, is one that does not require introducing any new set operation.  (At most, it requires to formally define a partition of a set $X$ as a cover of $X$ consisting of pairwise-disjoint subsets of $X$ .) In light of the above, I've come to realize that the term ""disjoint union"" could also be interpreted simply as shorthand for ""a union of disjoint (and covering) subsets"", instead of an exotic new set operation.  (There's precedent in Mathematics for transposing the adjective from the parts to the whole; for example an ""open cover"" is defined as a ""cover by open sets"".) Thinking of the co-product in $\Set$ as an manipulation on a domain also sharpened my appreciation of the product in $\Set$ as a manipulation on a codomain : whereas the co-product partitions a domain into subdomains, the product parametrizes a codomain by component sets.  With the co-product, several functions that have disjoint domains and the same codomain are stitched together.  With the product, several functions that have the same domain, and ""independent"" codomains are bound together into a single composite function. As MJD's answer alluded to, in programming the co-product manifests itself as ""switch"" statements, or, more generally, as sequences of if , else if ... else if , else expressions: function f(x):
    if test_1(x):
        return f_1(x)
    else if test_2(x):
        return f_2(x)
    ...
    else:
        return f_n(x)
    end
end Here, the domain $X$ of f is effectively partitioned into disjoint subsets $X_1, X_2, \dots, X_n$ , where $X_i$ consists of all those elements of $X$ for which test_i is true, and test_j is false for every $j < i$ .  The function f ""stitches together"" the functions f_1 , ..., f_n , having (effective) domains $X_1, \dots, X_n$ , respectively.  This function f is the ""unique morphism"" in $\Set$ , for the given f_1 , ..., f_n , that is guaranteed by the definition of the co-product. 3 In contrast, the product manifests itself in programming most commonly whenever real-world entities are modeled as composites of a finite number of parameters in such a way that (1) any two model objects are considered identical if and only if their parameter values parameters all match, (2) any combination of allowable values for the parameters represents a valid model object 4 .  The simplest example of this would be modeling space as a collection of three parameters, x , y , and z .  Then, for example: function pos(t):
    return (pos_x(t), pos_y(t), pos_z(t)) The function pos ""bundles together"", the functions pos_x , pos_y , and pos_z .  It is the ""unique morphism"" in $\Set$ , for the given pos_x , pos_y , and pos_z , that is guaranteed by the definition of the product. Note that the function f given earlier is a function from the co-product (IOW the co-product serves as the domain), whereas the function pos given here is a function to the product (IOW, the product serves as the codomain).  This is characteristic. In short, the take-home message is: co-products are partitioned domains , products are parametrized codomains. Or better yet (as explained in footnote 2), sums are partitioned domains , cosums are parametrized codomains . 1 In the case of co-product I deliberately avoid the common practice of omitting the hyphen, as in cotangent , cohomology , cokernel , etc.  In natural language, juxtaposition is not associative (that's why, e.g., the components of the word unionized are parsed out differently by a chemist and a labor activist), and the non-standard, but plausibly intelligible, parsing ""copro-duct"" (literally: ""excrement conduit"") gives the unhyphenated version of the word a ... let's say, suspicious aura . 2 In fact, I now think that it's a bit unfortunate that learners of category theory are usually told about the co-product, and often summarily, only after being taught the product.  At least in $\Set$ , it would be more natural to begin with the co-product (or rather, with partitions, expressed as ""sums"" of disjoint subsets), and then introduce the product, or rather, the cosum!  Then the slogan given elsewhere could be restated a bit more memorably as: sums are partitioned domains, cosums are parametrized codomains . 3 Pedantic caveat: in order to interpret f as the morphism guaranteed by the definition of the co-product, the f_i must be construed as the restrictions of the implemented functions to their effective domains $X_i$ .  In practice, the domains of the implemented functions f_i will often be proper supersets of their effective domains $X_i$ .  Still, considering only its role in the implementation of f , the domain of each f_i is indeed $X_i$ . 4 Note that these two conditions correspond, respectively, to the existence and uniqueness conditions on the morphism that is guaranteed by the definition of a product.  Dually, the conditions on the subsets of a partition, namely (1) that they be pairwise-disjoint, and (2) that they cover the original set, correspond, respectively, to the existence and uniqueness conditions on the morphism that is guaranteed by the definition of a co-product.","['examples-counterexamples', 'education', 'elementary-set-theory', 'category-theory', 'soft-question']"
697617,Limits of Integral $\lim\limits_{n\to\infty}\int\limits_a^b\sqrt[n]{f^n(x)+g^{n}(x)}dx.$,"Let $f, g:[a,b]\to[0,\infty)$ be continuous functions. Find the value of $$\lim\limits_{n\to\infty}\int\limits_a^b\sqrt[n]{f^n(x)+g^{n}(x)}dx.$$ One said that the results is $\int\limits_a^b h(x)dx$ where $h(x)=\max\{f(x), g(x)\}$. Please give me some hints.","['definite-integrals', 'calculus', 'integration', 'limits']"
697631,Find an unbiased estimator function (Poisson)?,"I think it is pretty easy to find an unbiased estimator for a regular distribution, whether it be Poisson or Gamma or something else.  For example, the unbiased estimator (Poisson from a random sample of size $n$) for $\lambda$ would be $\overline{Y}$. However, now suppose you have a function to find the number of failings of a computer system, and it is $C=2Y+Y^2$. We can easily see that $E(C)=E(2Y + Y^2) = 3\lambda + \lambda^2$.  But now if we want to find a function of $\overline{Y}$ that is an unbiased estimator of $E(C)$, how would you go about that? I would think that you need to find $\hat{\theta}$, such that $E(\hat{\theta})=3\lambda + \lambda^2$, but I am a little confused as to whether or not that is accurate. Any help on this problem would be greatly appreciated!  Thank you very much.","['statistics', 'probability', 'parameter-estimation']"
697643,Calculus on Manifolds - operational point of view,"I'm a student of Physics and I've been studying manifolds and calculus on such objects for a time. Usually when we deal with vector calculus there are books that bring one operational point of view. For example: the book Mathematical Methods for Physicists by George Arfken. This book brings interpretations of all the objects, like the vectors themselves, the integrals, the operations and so on and in the same time shows how one operates with them in practice. How to manipulate those objects and even carry down computations with them. Calculus on manifolds, on the other hand, is being a little more complicated. The reason is that all books I've found until now focus just on theorems and their proofs. There's nothing wrong with it, of course this is interesting as well, but what I really need is that operational view with interpretations and so on. For what I've seem until now, when doing calculus on manifolds one gets one incredible amount of work just to do some computations: work out charts, prove they are bijections and homeomorphism, prove they are $C^k$ related and so on. This also confuses me, because it seems much more complicated than vector calculus even to get started, while many people say it's not. So, where can I learn this operational point of view of calculus on manifolds? Meaning, learn to interpret objects like exterior derivatives, differential forms and their integrals, and in the same time learn how to in practice carry out operations with those objects? Thanks very much in advance.","['reference-request', 'differential-geometry']"
697644,Is there a $k$ for which $k\cdot n\ln n$ takes only prime values?,There exist some real $k$ such that $\forall $ integer $ n > 1$ the integer part of $ k *n\ln(n)$ is always prime?,"['prime-numbers', 'number-theory']"
697647,"Multivariable Integral, How to compute it?","Q How to evaluate a multivariate integral with a Gaussian weight function? $$
\mathcal{Z_{n}}
\equiv\int_{-\infty}^{\infty}
\exp\left(-a\sum_{j = 1}^{n}x_{j}^2\right)\,
{\rm f}\left(x_{1},x_{2},\ldots,x_{n}\right)\,
{\rm d}x_{1}\,{\rm d}x_{2}\ldots{\rm d}x_{n}
$$ Where $\displaystyle{%
{\rm f}(x_{1},x_{2},\ldots,x_{n}) =\prod_{j}
{1 \over \sqrt{1 + {\rm i}\,b\left(x_{j}^2-x_{j+1}^2\right)^2}}}$ . I need a hint to solve this integral and this is how I proceeded: $$
\mathcal{Z_{n}}=
\int_{-\infty}^{\infty}\prod_{j=1}^{n}{\rm d}x_{j}\,
\exp\left(%
-\,{a \over 2}\sum_{j = 1}^{n}x_{j}^{2} - {1 \over 2}
\log\left(1 + {\rm i}\,b\left[x_{j}^{2} - x_{j + 1}^{2}\right]^{2}\right)\right)
$$ Now the integral is of the form of the canonical partition function integrated over the configuration space. Hence the integral can be identified as an $n-$ particle partition of the canonical ensemble, which is given by $$
\mathcal{Z}_{n}= \int_{-\infty}^{\infty}\prod_{j = 1}^{n}{\rm d}x_{j}\, 
{\rm e}^{-\beta{\cal H}},
$$ Where $$\mathcal{H}=\Bigg(-\frac{a}{2}\sum_{j=1}^{n}x_{j}^2-\frac{1}{2}\log{\Big(1+i b(x_{j}^2-x_{j+1}^2)^{2}\Big)\Bigg)}.$$ Then I got stuck. How to proceed? Thanks.","['mathematical-physics', 'multivariable-calculus', 'quantum-field-theory', 'gaussian-integral']"
697660,Random walk with $\sum_{n=1}^{\infty} \frac{1}{n} \mathbb{P}\{ S_n > 0 \} < \infty$,"Consider a random walk started at $S_0=0$, denoted $S_n = \sum_{k=1}^{n}X_k$, where $X_1$, $X_2$...  are the i.i.d increments. If we have $\sum_{n=1}^{\infty} \frac{1}{n} \mathbb{P}\{ S_n > 0 \} < \infty$, then can we say $\underset{0 \leq k < \infty}{\inf} S_k < 0$ with probability 1? If we can, how do we show this? Can we say anything about the moments of $X_1$?","['stochastic-processes', 'random-walk', 'sequences-and-series', 'random', 'probability-theory']"
697675,multiplying a matrix by a row vector,Is multiplying a matrix by a row vector the same as multiplying it by a column vector? Or are there any differences between the two?,"['matrices', 'linear-algebra', 'vectors']"
697687,Galois cover an affine scheme,"Let $X = \operatorname{Spec}(A)$ be an affine scheme, with $A$ noetherian (and normal if this is useful). We suppose that $X$ is a finite Ã©tale covering of $Y = \operatorname{Spec}(B)$, Galois with group $G$. So the morphism $X \to Y$ comes from $B \cong A^G \hookrightarrow A$. I know that $A$ is a projective $B$-module, hence locally free. Is it the case that $A$ is always a free $B$-module?","['commutative-algebra', 'algebraic-geometry']"
697719,Variance of sums of independent random variables,I have the following formula - $Var(\overline{X}) = Var(\frac{1}{n}\sum_{i=1}^n X_i) = \frac{1}{n^2}\sum_{i=1}^n Var(X_i)$ I know that the variance of the sum of independent random variables is equal to the sum of the variances of the random variables but I don't see where the $\frac{1}{n^2}$ is coming from? Why isn't it $\frac{1}{n}$?,['probability']
697722,Subgroups of the Klein-4 Group,"Can anyone explain to me the subgroups of the Klein-4 group? I'm trying to view it this way: I want some groups that are not empty and $ab^{-1} \in H$, where $H$ denotes the subgroups I am looking for. So the Klein-4 group is as follows: $V_4 = \langle a,b : a^2 = b^2 = (ab)^2 = 1\rangle $. I'm a bit confused by the $\langle $ and $\rangle $ to denote a cyclic group but I sort of follow what's going on. I guess the group itself and the trivial subgroup are there...But can you explain to me how to find the rest? Possible answer: Trivial subgoups $ \{\ e \}\ $ has order one.
Order 2: $\{\ e,a \}\ , \{\ e,b \}\ , \{\ e,ab \}\ $
Order 4: The group itself. As the order of the subgroups must divide the order of the group, these must be all the subgroups.","['finite-groups', 'group-theory', 'abstract-algebra']"
697731,"How to solve this recurrence relation with Sigma notation (f(n, m) = f(n - 1, m) + f(n, m- 1) + c?","This recurrence relation was inferred from the function $f(n, m) = f(n - 1, m) + f(n, m-1) + c$. After expanding the latter, I ended up with the following: $$f(n,m)=\begin{cases}
0,&\text{if }n,m <0\\
1,&\text{if }n,m = 0\\
\sum_{i=0}^{k=n+m-1}\left(\left[f(n-i,m-[k-i])+c\right]\binom{k}{i}\right)-c,&\text{otherwise},
\end{cases}$$ Do you have any idea how to solve this recurrence relation?","['discrete-mathematics', 'recursive-algorithms', 'recursion', 'algorithms', 'binomial-coefficients']"
697738,Dimension of the vector space of homogeneous polynomials,"Let $k[X_0, X_1, \ldots, X_n]_d$, or briefly $k[X]_d$, be the $k$-vector space whose elements are the zero polynomial and homogeneous polynomials of degree $d\geq 1$. I found the following formula for the dimension
$$dim(k[X]_d)= \binom{n+d} {n}$$ but in my book there is no justification for this equality. Could someone explain me, possibly in an intuitive way, why that binomial coefficient is the dimension of that vector space?","['vector-spaces', 'linear-algebra', 'polynomials']"
697742,Trigonometry inside a trapezium,"I have the following image, and it's asked to find the values of $X$ and $Y$. I've managed to find it using the this idea: Divide the image in two right triangles and let's call the height of the trapezium $H$. The opposite cathetus of the left triangle has a length of $\frac{H}{\tan{60^{\circ}}}$ and the opposite cathetus of the right triangle is $\frac{H}{\tan{30^{\circ}}}$. The sum of this two catheti has to be equals to $12$, in this sum, we can assume that the height $H = 3\sqrt{3}$. Applying trigonometrical functions in both triangles, I managed to find that $X = 6, Y = 6\sqrt{3}$ But a friend of mine has found $X = 8, Y = \frac{16\sqrt{3}}{3}$, and he did it in a completely different manner from mine. Which one is right ?","['trigonometry', 'algebra-precalculus']"
697782,Prove the inclusion-exclusion formula for $P(A \cup B \cup C) $,"I need to prove the following equation. $P(A \cup B \cup C) = P(A) + P(B) + P(C) - P(A \cap B) - P(B \cap C) - P(A \cap C) + P(A \cap B \cap C)$ I started with this.. $P(A \cup B \cup C) = P(A \cup B) \cup C$ I think that I may go on with De Morgan laws ..
but I'm not sure which are the right steps.
Can you give me some hint? Of course I'm not asking for the solution, just a ""way to follow"".",['elementary-set-theory']
697806,Applying Khovanov homology to two different non-trivial diagrams of the unknot,"I'm attempting the calculate the Khovanov homology of the unknot using the figure eight diagram of the unknot with exactly one crossing going from top left to bottom right as shown below. I also include the convention I'll be using for the resolutions of the crossings. I calculate that the resulting chain complex given by this diagram is $$\cdots\to 0\to V\otimes V\stackrel{m}{\to} V\to0\to\cdots$$ where $V$ is the graded abelian group $\mathbb{Z}_{(1)}\oplus\mathbb{Z}_{(-1)}$ (I'll drop the gradings from here as I don't think they play any part in my eventual misunderstanding - I could be wrong) generated by $v_+$ and $v_-$ and $m$ is the map which acts on generators by
$$\begin{array}{rcl}m(v_-\otimes v_-)&=&0\\
m(v_+\otimes v_-)&=&v_-\\
m(v_-\otimes v_+)&=&v_-\\
m(v_+\otimes v_+)&=&v_+.\end{array}$$ Here we see that the kernal of $m$ is freely generated by $v_-\otimes v_-$ and $v_-\otimes v_+ - v_+\otimes v_-$ and so we get that $H^{Kh}_0\cong\mathbb{Z}\oplus\mathbb{Z}$, and $m$ is surjective so $H^{Kh}_1$ is trivial. Now consider the mirror image of the above diagram which is still isotopic to the unknot, and with the same choice of crossing resolutions. Because of our choice of resolutions, we now get the chain complex
$$\cdots\to 0\to V\stackrel{\Delta}{\to} V\otimes V\to0\to\cdots$$ where $\Delta$ is the map which acts on generators by
$$\begin{array}{rcl}\Delta(v_-)&=&v_-\otimes v_-\\
\Delta(v_+)&=&v_+\otimes v_- + v_-\otimes v_+.\end{array}$$ Here we see that the kernal of $\Delta$ is trivial so $H^{Kh}_0$ is trivial, but $\mbox{Im}\Delta\cong \mathbb{Z}\oplus\mathbb{Z}$ and so $H^{Kh}_1\cong\mathbb{Z}\oplus\mathbb{Z}$. It seems that I'm missing something here as either I've inadvertently shifted homological degrees somewhere where I should not have (or haven't where I should have), or I need to maybe dualise the chain complex for some reason when taking the mirror image of our knot. Which of my calculations above is incorrect (or both?) and am I not understanding some crucial step in the definition of the Khovanov homology of a knot which has lead to this mistake?","['general-topology', 'homology-cohomology', 'knot-theory']"
697815,Domain when dividing two functions,"Let's say we have two function $f(x) = \sqrt{x-3}$ and $g(x) = \sqrt{16-x^2}$, when finding the domain of $\frac{f}{g}$ do you find the domain of $\frac{\sqrt{3-x}}{\sqrt{16-x^2}}$ so that $x$ is an element of $(-4,3]$ or would you find the domain of $\sqrt{\frac{3-x}{16-x^2}}$ where $x$ is an element of $(-4,3] \cup (4, +\infty)$? Thanks, any help is appreciated.","['algebra-precalculus', 'functions']"
697823,"G is group of order pq, pq are primes","Problem. Let $G$ be a group of order $pq$ such that $p$ and $ q$ are prime integers. I am to show that every proper subgroup of $G$ is cyclic. My attempt. What I know: Any element $a$ divides $pq$ and $a^{pq} = e$. The order of subgroups $H$ divide $pq$ by Lagrange. If I could show that $G$ is cyclic, then all subgroups must be cyclic. If I can show that $G$ is a group of prime order, then I can show that it is cyclic. I'm not sure what more I can do here...I've tried looking at Fermat's Little Theorem but I can't seem to properly understand it and how it could affect my problem..","['cyclic-groups', 'group-theory', 'abstract-algebra']"
697834,Imagining the projective Space,"I am trying to get used to work in the projective space. Therefore I wanted to know which tactics there are to imagine the projective space. $$\mathbb{P^n}(k):= (k^{n+1}\backslash \{0\})/k^{*}$$ I like for example for the real projective space the idea of the sphere, but I am not sure if I got it right: $\mathbb{P}(\mathbb{R})^2$ is the set of lines in $\mathbb{R}^3$ going through the origin. So if we put a Shere in $\mathbb{R}^3$ then each point in $\mathbb{P}(\mathbb{R})^2$ is described by two antipodal points on the sphere. Then I saw that a parabola looks somehow like an ellipse on the sphere. (In the picture the red line. For the sake of lucidity I did not put the antipodal 'ellipse'.) So can I imagine that the poles are zero and infinity? I would be really happy if you could share your imgaination methods with me! All the best, Luca","['projective-space', 'algebraic-geometry', 'projective-geometry']"
697838,Degree of a function,"I found on wikipedia ( http://en.wikipedia.org/wiki/Degree_of_a_polynomial ) that a degree of a general function can be computed as
$$\deg f(x) = \lim_{x\to\infty}\frac{\log |f(x)|}{\log x}$$
or
$$\deg f(x) = \lim_{x\to\infty}\frac{x f^\prime(x)}{f(x)}$$
So e.g. in case  $f(x)=\log x$, $\deg f(x) = 0$. In case of polynomials, it is the classical polynomial degree, i.e., $\deg (x^3+1) = 3$. Unfortunately, any reference to some relevant literature is missing. 
Can you please point me at some literature where these kinds of degrees are analyzed? Thanks. In case like $f(x) = x+\log x$ the degree (by this definition) is $1$. But does it say also something about possible number of real roots? Similarly like when we have a ""pure"" polynomial (there is at most ""$\deg f(x)$"" roots)?","['reference-request', 'functions', 'polynomials']"
697843,Fourier Series for $|\cos(x)|$,"I'm having trouble figuring out the Fourier series of $|\cos(x)|$ from $-\pi$ to $\pi$. I understand its an even function, so all the $b_n$s are $0$ $$a_0 = \frac 2 \pi \int_0^\pi |\cos(x)|\,dx = 0$$ $$a_n = \frac 2 \pi \int _0^\pi  |\cos(x)| \cos(nx) \, dx = \frac 2 \pi \int_0^\pi \cos^2(x)\,dx.$$ since for all $j,k$ not equal the integral is zero. so only $a_1$ remains. is this correct? How would I evaluate $\sum_{n=1}^\infty (-1)^{n-1} /(4n^2 - 1)\  {}$?","['sequences-and-series', 'fourier-analysis', 'ordinary-differential-equations', 'calculus']"
697895,Is this a geodesic?,"Let $(M,g)$ be a riemannian manifold. Let $p$ in $M$ and $v,v_{0}$ two vectors in $\mathrm{T}_{p}M$. I am looking at the curve $$ \gamma \, : \, t \, \longmapsto \, \mathrm{Exp}_{p}(tv+v_{0}) $$ and I am wondering whether this curve is a geodesic. Here, $\mathrm{Exp}_{p}$ denotes the riemannian exponential map : $c \, : \, t \, \mapsto \, \mathrm{Exp}_{p}(tw)$ is the unique geodesic such that $c(0)=p$ and $c'(0)=w$. To prove that $\gamma$ is a geodesic, I should compute $\nabla_{\dot{\gamma}}\dot{\gamma}$ and see whether this quantity is zero or not. However, I'm having trouble computing $\nabla_{\dot{\gamma}}\dot{\gamma}$ and I would appreciate if someone could shed some light for me on this. It is clear that $\gamma(0) = \mathrm{Exp}_{p}(v_{0})$ and (if I'm not mistaken) $\gamma'(0) = \mathrm{D}_{v_{0}} \big( \mathrm{Exp}_{p} \big) \cdot v \in \mathrm{T}_{\gamma(0)}M$. So I was wondering whether $\gamma$ wouldn't be the geodesic from $\gamma(0)$ with initial speed $\gamma'(0)$.","['riemannian-geometry', 'manifolds', 'differential-geometry']"
697925,Orthonormal Sets in Hilbert Spaces,"let $H$ be a Hilbert space and let M be a dense linear subspace of H.
Can we find a complete orthonormal set $\{u_{\alpha}: \alpha \in A\}$ for H
in M? I think the answer is negative in general, but I cannot find a counterexample.
Thank you very much in advance for your help.",['functional-analysis']
697926,Riemann-Roch theorem for singular curves,"It might be a naive question, but I just realized I had not thought about this before. If $C$ is a smooth curve, for any line bundle $D$ we have the Riemann-Roch formula:
$$\chi(D)=\deg D+1-g(C).$$
Does this nicely extend also to singular curves as $\chi(D)=\deg D+1-p_a(C)$ ? (if yes, is it an easy consequence of the smooth case?)","['riemann-surfaces', 'algebraic-geometry']"
697945,"Two possible definitions of ""vector-valued distribution""","Let $X$ be a reflexive real Banach space, the complex case should be totally analogous. Define $$\tag{1}
\mathcal{D}^\star(0, T; X)=\left\{ u\colon \mathcal{D}(0, T)\to X\ \text{linear and continuous}\right\}
$$ where the topology on $\mathcal{D}(0, T)$ , the space of real-valued test functions, is the usual one from distribution theory. Now define $$
\tag{2}
\left[\mathcal{D}(0, T; X^\star)\right]^\star = \left\{u \colon \mathcal{D}(0, T; X^\star)\to \mathbb{R}\ \text{linear and continuous}\right\}, 
$$ where $\mathcal{D}(0, T; X^\star)$ denotes the space of the smooth $f\colon (0, T)\to X^\star$ such that the support $\operatorname*{Supp}(f)$ is compact. We equip this vector space with the obvious analogue of the topology of $\mathcal{D}(0, T)$ . Precisely, we consider the unique topology $^{[1]}$ such that, if $\phi_n, \phi\in \mathcal{D}(0, T; X^\star)$ then $\phi_n\to \phi$ is equivalent to $$
\begin{cases}
\operatorname*{Supp}\phi_n \subset [a, b]\subset (0, T),\ \text{for fixed }a,b;\\ 
\left\lVert \frac{d^k \phi_n}{dx^k}-\frac{d^k\phi}{dx^k} \right\rVert_{\infty} \to 0,\quad\forall k\in \mathbb{N}.
\end{cases}
$$ Both definitions give rise to something which might be reasonably called ""space of $X$ -valued distributions"". Question . Are these two spaces isomorphic? Example . Let $X=\mathbb{R}^n$ and consider a continuous function $\boldsymbol{u}\colon (0, T)\to \mathbb{R}^n$ . (The boldface font refers to vector valued functions). The two definitions above give rise to the following two representations of $\boldsymbol u$ as a vector valued distribution. Using definition (1) $$
\boldsymbol{u}\text{ acts on }\mathcal{D}(0, T)\text{ through the pairing }\langle \boldsymbol{u}, \phi\rangle = \int_0^T \boldsymbol{u}(t)\phi(t)\, dt,\text{ where }\phi\in \mathcal{D}(0, T).$$ Note that the test function $\phi$ is scalar-valued. On the other hand, using definition (2) $$
\boldsymbol{u}\text{ acts on }\mathcal{D}(0, T; \mathbb{R}^n)\text{ through the pairing }\langle \boldsymbol{u}, \boldsymbol{\psi}\rangle = \int_0^T \boldsymbol{u}(t)\cdot \boldsymbol \psi(t)\, dt,\text{ where }\boldsymbol\psi\in \mathcal{D}(0, T; \mathbb{R}^n).$$ Here the test function is vector-valued and the pairing uses the dot product of $\mathbb{R}^n$ . Note. From some lecture notes which I found online it seems that Laurent Schwartz himself chose definition (1). $^{[1]}$ Actually, I am cheating here. I know neither if such a topology exists nor if it is unique. I am just guessing that the usual construction which works for real valued test functions works here as well.","['distribution-theory', 'functional-analysis']"
697962,Understanding the definition of compactness.,"$(X, \mathscr T )$ be a topological space and $A \subset X$. $\{ U_i \mid i \in I \}$ is said to be an open cover of $A$ if $A \subset \cup_{i \in I} U_i$. $A$ is said to be compact if there exists finite $J \subset I$ such that $A \subset \cup_{i \in J} U_i$. $\{ U_i \mid i \in J \}$ is then called finite subcover of $A$. My doubt: Let set of open sets which cover $A \subset X$ be $\{U_1,U_2, U_3, \dots\}$. If we add $X$ in this collection of open sets, then also it would cover $A$ i.e. the new covering set be $\{X, U_1,U_2, U_3, \dots\}$. Now we need to take a finite subset of the above ""covering set"". Let that subset be $\{X, \phi \} $ i.e $\{X, \phi \} \subset \{X, U_1,U_2, U_3, \dots\}$. This subset would cover $A$ since $A \subset X$. So $A$ is compact. But we can virtually do this with any subset of $X$. I know this is wrong but where am I making a mistake?","['general-topology', 'self-learning', 'compactness']"
697970,Is a function still a function if it doesn't have any rule?,"From what I've read on the internet, I've concluded that function differs from relation in that function can only have one range per domain. So, if for example: F={(1,3),(2,4),(3,6),(4,12)} I don't think there's any rule in it ( f(x)=blabla ) cause I just randomly typed it out. As you can see, the F set has a perfect one-to-one correspondence. But since it doesn't have any rule, is it still considered a function?
Thanks!","['algebra-precalculus', 'functions']"
697996,Showing the quotient map is open,"If I have a topological space $X$ and a subgroup $G$ of $\operatorname{Homeo}(X)$ . Then defining an equivalence relation $x \sim y$ iff there is a $g\in G$ s.t. $g(x) = y$ . I'm trying to show that the quotient map $q: X \to X/R$ is open. I can just about see that, if $U$ is an open set in X, then $p^{-1}(p(U)) = \cup_{g \in G} g(U)$ - reason being that this will give all the elements that will map into the equivalence classes of $U$ under $q$ . Now I'm struggling to see why this means that $p^{-1}(p(U))$ is open. Just because we know that $U$ is open, how do we know that $g(U)$ is open. (Which would then give a union of open sets). Thanks",['general-topology']
697998,Domain with a minimal left ideal is a division ring.,"I need to show that a domain $R$ with a minimal left ideal is a division ring. Suppose that $I$ is a minimal left ideal, then take $a\in I\setminus \{0\}$ and consider the left ideal generated by $a$, that is, $Ra$. It is a subset of $I$ and by minimality of $I$ we get that
$$ Ra=I $$
and $I$ is principal. Take $r\in R$ to be nonzero, then $ra\in I$ and $ra\neq 0$ since $r\neq 0, a\neq0$. Take $r' \in R$ and suppose that 
$$
ra=r'a
$$
then $(r-r')a=0$ and hence $r-r'=0$, so that $r=r'$. I am not sure how to proceed from here.","['ring-theory', 'abstract-algebra']"
698048,How to prove this claim using Mathematical Induction?,"We have $n$ points on a surface and for each $3$ points, we are able to put them into a circle with radius of unit length. Prove that all of these points are on circle with radius of unit length. My attempt for this question was something like this:
Checking the $n^{\mathrm{th}}$ point with the two points that are on the border of the circle which covers the $n-1$ previous points.","['induction', 'discrete-mathematics']"
698062,"Need help with $\int_0^\infty\frac{\log(1+x)}{\left(1+x^2\right)\,\left(1+x^3\right)}dx$","I need you help with this integral:
$$\int_0^\infty\frac{\log(1+x)}{\left(1+x^2\right)\,\left(1+x^3\right)}dx.$$ Mathematica says it does not converge, which is apparently false.","['definite-integrals', 'residue-calculus', 'improper-integrals', 'calculus']"
698080,monotone convergence question,"I am trying to show that 
$$\lim_{n \rightarrow \infty} \int^{n^2}_{0}{e^{-x^2}n \sin\frac{x}{n}dx} = \frac{1}{2}.$$ I have tried by using the monotone convergence theorem, but if I take 
$f_n = e^{-x^2}n \sin\frac{x}{n}$ on $(0,n^2)$ and $0$ otherwise I can show neither of 1) $f_n \leq f_{n+1}$ a.e 2) $\sup_n \int f_n <\infty$ Is this the right approach or am I missing something?","['lebesgue-integral', 'integration', 'limits']"
698100,Proving the existence of a point with a certain property for a continuous function,"Let $f:[0,1]\to\mathbb{R}$ a continuous function and $\int_0^1xf(x)dx=0$. Show that there exists a point $c\in(0,1)$ so that $f(c)=(\int_c^1f(x)dx)^2$. As a potential solution, I tried assuming that no such point exists, then the function $g(x)=f(x)-(\int_x^1f(t)dt)^2$ would have constant sign for all $x\in(0,1)$. $g(x)>0$ can't be true for all $x\in(0,1)$ since then  $\int_0^1xf(x)dx>0$. But I can't figure out how to prove that $g(x)<0$ for all $x$ can't be true. Thanks","['continuity', 'calculus', 'integration', 'functions']"
698117,Prove that this particular sequence contains an infinite number of sixes,"Given the sequence $$2,7,1,4,7,4,2,8,\ldots$$ which begins with $2, 7$ and is constructed by multiplying successive pairs of its members and adjoining the results as the next one or two members of the sequence.
Prove that this sequence contains an infinite number of sixes. Any idea?","['recurrence-relations', 'sequences-and-series', 'problem-solving']"
698150,"Is $f(x)=\sup_{y\in K}g(x, y)$ a continuous function?","Let $K\subset \mathbb R^n$ be a compact subset and consider a continuous function $g:K\times K\longrightarrow \mathbb R$. Define $f:K\longrightarrow \mathbb R$ by, $$f(x)=\sup_{y\in K}g(x, y).$$ Is $f$ a continuous function?",['analysis']
698172,Maximum-Value Secretary Problem,"Background: The classic secretary problem has the simple solution of rejecting the first 1/e applicants and then selecting anyone who was better than the best in the rejected set.  However, in the real world secretaries are not of value 0 if they are not the best, and so choosing the 2nd best is normally far better than choosing the worst.  Also, if you stick to the classical approach, there's a 1/e chance that you will receive a random secretary from the set that excludes the best secretary. Real-World Example: Say that you've interviewed 98 out of 100 secretaries and have not found any better than secretary #32.  You then interview the 99th secretary and find that she is second only to #32. Analysis: Under the classical problem, you'd reject #99 as they have a value of 0 (not the best).  Thus, you'd take a random secretary in favor of the 98th or 99th best, depending on whether the last secretary is the best or not. However, the classical solution would not be the best decision in nearly all real-world cases, as you are taking a random applicant instead of one better than at least 97/99 others. Question: What is the proper stopping strategy to maximize the expected-value of the secretary you hire? You have n secretaries. Each secretary has a linear value assigned after each interview (a secretary ranked 4 is assumed to be twice as valuable as one ranked 2). The value-distribution of secretaries is unknown. You must accept or reject each secretary immediately following their interview with no recalls. You must maximize the expected value of the secretary you hire.","['probability', 'decision-theory']"
698176,Infinite product related to the Wallis product,"Some time ago I heard  this math question on the radio: The Wallis product $$\frac{2}{1}*\frac{2}{3}*\frac{4}{3}*\frac{4}{5}*\frac{6}{5}*\frac{6}{7}* \dotsb$$ is known to converge to $\pi/2$, but what does this infinite product converge to:
$$
\frac{\sqrt[2]{2}}{\sqrt[1]{1}}*\frac{\sqrt[2]{2}}{\sqrt[3]{3}}*\frac{\sqrt[4]{4}}{\sqrt[3]{3}}*\frac{\sqrt[4]{4}}{\sqrt[5]{5}}*\frac{\sqrt[6]{6}}{\sqrt[5]{5}}*\frac{\sqrt[6]{6}}{\sqrt[7]{7}} *\dotsb
$$ All I know about it is that it is aproximatly equal to $1.37676673907$ Wolfram Alpha doesn't give me much more How does one attack such a problem? I know how the value for the Wallis product was found, but none of these techniques seem to work on this seemingly related product. Tell me anything you find or know about it! Edit: Thanks to the link lucian gave me I found the closed form:
$$2^{2\gamma-\ln{(2)}}$$ I checked 50 digits and they are all correct, now how would you arrive at this or how would you prove this?","['calculus', 'infinite-product']"
698177,Expected value of rolling dice until getting a $3$,I am having trouble with this question with regards to random variables and calculating expected values: Suppose I keep tossing a fair six-sided dice until I roll a $3$. Let $X$ be the number of times I roll the dice. What is the value of $E[X]$? So for this problem I was thinking that the answer would just be $1$. Here is my thought behind it. For each turn there is a $1/6$ chance of hitting a three. If I keep rolling and rolling I will eventually hit a $3$. So the math works out to be $(1/6)*6$ which is equal to $1$. Does this logic make sense? I am a bit confused with how exactly I would go about picking the values for $P(X=x)$ and how to calculate expected value. Some insight would be very helpful.,"['probability', 'random-variables']"
698184,A boolean algebra is complete if its stone space is extremally disconnected,"I have the following proof, but I don't understand one of the steps: Theorem 4.4. A Boolean algebra is complete iff its Stone space is exlremally disconnected. Proof. Identify the given Boolean algebra $B$ with the clopen algebra of $\mathsf{S}B$. Suppose that $B$ is complete, and let $U$ be an open set in $\mathsf{S}B$. Let $\mathscr{A}$ be the family of all members of $B$ included in $U$; then, since $B$ is a base for $\mathsf{S}B$, we have $U = \bigcup \mathscr{A}$. Since $B$ is complete, $\mathscr{A}$ has a supremum $V$ in $B$ which must by definition be a clopen subset of $\mathsf{S}B$. We claim that $\overline{U} = V$. 
  Since $V$ is an upper bound for $\mathscr{A}$, certainly $U = \bigcup \mathscr{A} \subseteq V$, so that $\overline{U} \subseteq V$ since $V$ is closed. If $V - \overline{U} \neq \emptyset$, then $Vâ\overline{U}$ is a non-empty open set which must, since $\mathsf{S}B$ is a Boolean space, include a non-empty clopen set $W$. But then $V-W$ is a clopen set which includes $\bigcup \mathscr{A}$ and is properly included in $V$. This contradicts the choice of $V$ as the supremum of $\mathscr{A}$. Therefore $\overline{U}=V$ as claimed, so a fortiori $V$ is open. Conversely, suppose that $\mathsf{S}B$ is extremaily disconnected, and let $\mathscr{A}$ be a subfamily of $B$. Then $U = \bigcup\mathscr{A}$ is an open subset of $\mathsf{S}B$ (recall that we are identifying $B$ with $\mathsf{CS}B$!) and so, since $\mathsf{S}B$ is extremally disconnected, $\overline{U}$ is clopen and hence in $B$. We claim that $\overline{U} = \bigvee \mathscr{A}$ in $B$. Certainly $\overline{U}$ is an upper bound for $\mathscr{A}$ in $B$; on the other hand, if $V$ is a member of $B$ which includes each member of $\mathscr{A}$, then $U = \bigcup \mathscr{A} \subseteq V$ so that $\overline{U} \subseteq V$ since $F$ is clopen. Therefore $\overline{U} = \bigvee \mathscr{A}$ as claimed, and $B$ is complete. $\blacksquare$ I do not understand the argument that why $V - \overline{U}$ is open set. and why should it include $W$ clopen set.","['general-topology', 'filters', 'boolean-algebra', 'compactness']"
698193,Taking limit of a probability distribution,"I have a probability distribution of the form $$ p_{m+1}(s)= \frac {(bs)^m}{b(m!)} e^{-bs}$$ I want to show that under the limit $m \to \infty$, it will becomes a Gaussian. I applied Stirling's formula on the factorial but I can't massage the expression into the form I want. Can someone please help me out?","['central-limit-theorem', 'probability-distributions', 'limits']"
698207,Non-trivial zeros off critical line,"If non-trivial zeros lay off the critical line (as shown in the picture below), would they have to come in fours rather than conjugate pairs (as the diagram shows)? I am presuming they would, since $\sum_{\rho}^{}\text{Li}(x^{\rho})$ is conditionally convergent, and is taken to mean $\sum_{\rho}^{}|\text{Li}(x^{\rho})+\text{Li}(x^{1-\rho})|$ , and since $1-(\sigma+bi)$ and its pair only cancel imaginary terms when $\sigma=\frac{1}{2}$ , (if $s=\frac{1}{4}+bi$ , then $1-s=\frac{3}{4}-bi$ ), they would presumably have to come in fours, eg: $s_{1}=\frac{1}{4}+bi$ , $1-s_{1}=\frac{3}{4}-bi$ , $s_{2}=\frac{3}{4}+bi$ , $1-s_{2}=\frac{1}{4}-bi$ . My second question: is it possible for there to be zeros in the critical strip with exactly the same imaginary value? Update Just done a bit of playing around & it is easier to visualise how this might happen in a contour plot of $\xi(\sigma+bi)$ :","['riemann-hypothesis', 'riemann-zeta', 'number-theory']"
698246,"Whether a space is compact, if all functions are bounded","Let $X$ be a paracompact Hausdorff space. It is easy to see the following statement. If $X$ is compact, then every continuous function is bounded. Does the converse hold? If every function on $X$ is bounded, then is $X$ compact? The reason why I assume $X$ to be paracompact Hausdorff is the existence of ""enough"" number of functions. Namely, I wanted to make use of a partition of unity, but my attempt has not succeeded yet. So feel free to remove the assumptions, if you want.","['general-topology', 'compactness']"
698254,Proof of Vandermonde Matrix Inverse Formula,"I'm working through Exercise 40 from section 1.2.3 of Knuth's The Art of Computer Programming volume 1, but am finding myself unable to produce a rigorous proof, and the one here is suspect and not quite clear enough (for me, at least) in some of the steps; in particular, how to ""[identify] the $k$th order coefficient in [the] two polynomials."" The problem is this: given a Vandermonde matrix $[x_j^i]_n$, show that the inverse is given by $$
[b_{ij}]_n = \left[
\frac{
   \sum_{\substack{1 \leq k_1 < \dotsc < k_{n-j} \leq n\\k_1,\dotsc,k_{n-j} \neq i}} (-1)^{j-1} x_{k_1} \dotsc x_{k_{n-j}}
}{
   x_i \prod_{\substack{1 \leq k \leq n\\k \neq i}} (x_k - x_i)
}
\right]_n\text{.}
$$ The author gives a hint by stating that the sum in the above numerator is just the coefficient of $x^{j-1}$ in the polynomial $(x_1-x)\dotsc(x_n-x)/(x_i-x)$; and he gives an intermediate result showing the explicit multiplication of the matrix and its inverse as $$
   \sum_{1 \leq t \leq n}b_{it}x_j^t
   =
   \frac{
      x_j \prod_{\substack{1 \leq k \leq n\\k \neq i}} (x_k - x_j)
   }{
      x_i \prod_{\substack{1 \leq k \leq n\\k \neq i}} (x_k - x_i)
   }
   =
   \delta_{ij}\text{.}
$$ The only other hint as to the type of solution he was expecting is a reference to A. de Moivre's The Doctrine of Chances , 2nd edition, pp. 197-199, which deals with polynomial recurrence relations and difference products (available here ). At the least, I was just hoping someone could either verify the proof is correct at proofwiki and possibly fill in exactly how one identifies the $k$th order coefficient in the proof; or perhaps explain a proof strategy as to what steps to take where the intermediate result is obtained at some point before the final result. Thanks so much for any help.","['matrices', 'inverse', 'proof-verification']"
698271,"How can I prove that $(\mathbb Z,\leq_*)$ is isomorphic to $(\mathbb N,\leq )$","We define the binary relation $\leq_*$ between integers by the following rule: For $n,m\in\mathbb Z$, $n\leq_âm$ holds if and only if one of the following conditions is satisfied: $|n|<|m|$, or $|n|=|m|$ and $n<0\,$, or $n=m$. How can I prove that $(\mathbb Z,\leq_*)$is isomorphic to $(\mathbb N,\leq )$? My thoughts: I have to find a bijection $f : A_1 â A_2$. Then, I need to prove that $f$ is an isomorphism by showing that it is injective, surjective and that it preserves the order. However, I can't seem to find to find $f$. How can I do this?","['elementary-set-theory', 'order-theory']"
698324,Is there a regular not completely regular space which is not a corkscrew?,"While studying some examples of regular spaces which are not completely regular, I came across Steen's and Seebach's ""Counterexamples in Topology"". In this book, after searching for examples, I only found four examples of regular not completely regular spaces: Tychonoff Corkscrew, deleted Tychonoff Corkscrew, Hewitt's Condensed Corkscrew and Thomas' Corkscrew. All this examples are variations of the same example: the Tychonoff Corkscrew. So my question is the following one: is there a regular not completely regular space which is not a corkscrew? Or in other way, is it possible to define the property of being a corkscrew is some sense in order to have a result of the form that every regular space is completely regular except if it is a corkscrew? Alternatively, is it possible to construct a regular not completely regular space which is not a corkscrew in the sense of being radically different -in the sense that use totally different ideas and it is not homeomorphic to the cited ones- from the previous examples?","['general-topology', 'examples-counterexamples']"
698327,Classification of triply transitive finite groups,"A permutation group $G$ on a set $X$ is said to be $k$-transitive if it is both transitive on $X$ and either $k=1$ or the point stabilizer $G_x$ is $(k-1)$-transitive on $X\setminus\{x\}$. Is there a classification of 3-transitive finite groups? Examples: For every non-negative integer $n$, $S_n$ and $A_n$ are 3-transitive on $\{1,2,\dots,n\}$ If $n-1=p^f$ is a prime power, then all $G$ with $\operatorname{PGL}(2,p^f) \leq G \leq \operatorname{P\Gamma L}(2,p^f)$ are 3-transitive If $n-1=q^2$ is the square of a prime power, then also all $G$ with $M(q^2)\leq G \leq \operatorname{P\Gamma L}(2,p^f)$, where $\operatorname{PSL}(2,q^2) < M(q^2) < \operatorname{P\Gamma L}(2,q^2)$ Every sharply triply transitive group is either $\operatorname{PGL}(2,p^f)$ or $M(q^2)$, of order $((n-1)^2-1)((n-1)^2-(n-1))/(n-2) = n(n-1)(n-2)$. This is due to Zassenhaus; see HuppertâBlackburn (XI.1.4.b, XI.2.1, and XI.2.6). However, there are triply transitive groups that are not sharply triply transitive (such as $\operatorname{P\Gamma L}(2,p^f)$ for $f>1$). If $n$ is odd, then Wagner (1966) showed that any non-identity normal subgroup of a triply transitive group is also triply transitive. By taking a minimal normal subgroup (and then a minimal normal subgroup of that) we get a simple triply transitive group of the same degree, so if we are only interested in $n$, then we need only consult our knowledge of finite simple groups. I think $\operatorname{ASL}(n,2)$ is always triply transitive. Here are the triply transitive groups of degree $n < 2500$ that don't fall into the above categories: $M_{11}$ of degree 11 $M_{11}$ of degree 12, $M_{12}$ of degree 12 $A_7 \ltimes 2^4$ of degree 16 (?) $M_{22}, \operatorname{Aut}(M_{22})$ of degree 22 $M_{23}$ of degree 23 $M_{24}$ of degree 24 Note these are mostly Mathieu groups. Bibliography Wagner, A.
âNormal subgroups of triply-transitive permutation groups of odd degree.â
Math. Z. 94 (1966) 219â222
MR 199251 DOI: 10.1007/BF01111350 Siemons, Johannes.
âNormal subgroups of triply transitive permutation groups of degree divisible by 3.â
Math. Z. 174 (1980), no. 2, 95â103.
MR 592907 DOI: 10.1007/BF01293530","['permutations', 'finite-groups', 'group-theory']"
698346,"Compute $\int_C\sin y\,dx+(x\cos y-\sin y)\,dy$","Compute $\int_C\sin y\,dx+(x\cos y-\sin y)\,dy$ where $C$ is $\displaystyle \frac {x^2}{4}+\frac {y^2}{2}=1$ in the first quadrant counter clockwise. I set $x=2\cos \theta$ and $y=\sqrt{2}\sin\theta$ where $0\leq\theta\leq \frac {\pi}{2}$. But when I plug $x$ and $y$ back into the integral I am unable to solve it. Please drop some hints. Thanks. EDIT: $\displaystyle\int_{\Gamma}=\iint_D(\frac {\partial Q}{\partial x}-\frac {\partial P}{\partial y})\,dA=\int_0^2\int_0^{\sqrt{2}}2\cos y\,dy\,dx=\pi$ $\int_{c_1}+\int_{c_2}=\int_0^20+\int_0^\sqrt{2}-\sin t\,dt$, where $C_1:$ $x=t,\,dx=dt, y=0,dy=0\,dt, 0\leq t\leq 2$ $C_2: y=t, dy=\,dt, x=0, dx=0\,dt, 0\leq t\leq \sqrt{2}$ So $\displaystyle \int_c=\int_{\Gamma}-\int_{c_1}-\int_{c_2}=\pi-0-\frac {\pi}{4}+1=\frac {3\pi}{4}+1$","['multivariable-calculus', 'integration']"
698348,Determining the probability of unique values chosen from a larger set?,"I'm trying to solve what I think is a more generalized version of the ""birthday paradox"".  I run into problems like this all the time and I can never quite figure out how to tackle them. Suppose I have a set of $M$ possibilities all with an equal probability of being chosen: $\operatorname{P}(M_n) = 1/M$.  Now suppose I pick from the set of possibilities $N$ times.  I'd like to know the probability of there being $C$ unique values chosen.  I'd also like to know the probability of the tails. This strikes me as related to the Birthday paradox. To make the problem more concrete, I'm currently trying to figure out how unexpected an event is.  I have $156$ salts chosen where each salt is a $12\mathrm{-bit}$ number.  Only $147$ salts were unique.  That is, $9$ of them are duplicates.  So $M = 2^{12} = 4096$ and $N = 156$.  I'd like to calculate the probability that there were exactly $147$ unique salts chosen.  I'd also like to be able to compute the probably of at least $147$ and at most $147$. Is there a probability distribution for this?  Maybe something like the Poisson distribution?","['probability-distributions', 'discrete-mathematics', 'probability']"
698370,Find the limit of $ a_n =\left(1+\frac{1^2}{n^2}\right)^1\left(1+\frac{2^2}{n^2}\right)^2\cdots \left(1+\frac{n^2}{n^2}\right)^n$,"$$ a_n =\left(1+\frac{1^2}{n^2}\right)^1\left(1+\frac{2^2}{n^2}\right)^2\cdots \left( 1 + \frac{n^2}{n^2} \right)^n$$ $$\lim_{n\to\infty} a_n^{-1/n^2}$$ So I tried solving it by taking the logarithm. Let the limit be $L$. Hence, $$\lim_{n\to\infty}\log(L) = \lim_{n\to\infty} \left(-\frac{1}{n^2}\log\left(1+\frac{1}{n^2}\right)-\frac{2}{n^2}\log\left(1+\frac{2^2}{n^2}\right)-\cdots - \frac{n}{n^2}\log\left(1+\frac{n^2}{n^2}\right)\right).$$ This looks like it should be tractable using the definition of $$\int^1_0 f(x)\,dx =\lim_{n \to \infty} \frac{1}{n}\sum^n_{r=0}f\left(\frac{r}{n}\right)$$ with taking $f(x) = \log(1+x^2)$ but I am not being able to simplify it to the requisite form. I took this approach mainly because we were recently taught this in school, and it seems to work quite well. I would be interested in alternative solutions too of course. Thanks in advance.","['calculus', 'integration', 'limits']"
698387,What does it mean to be integral over something,I don't understand what it means to say $\mathbb Q[\sqrt d]$ to be integral over $\mathbb Z$?,['number-theory']
698391,Why is Simpson's rule exact for cubics?,I can't understand: Why is Simpson's rule exact for cubic polynomials?,"['approximation', 'calculus', 'integration']"
698403,Queuing model $M/M/\infty$,"I am considering a queuing model of the form $M/M/\infty$, you find properties of this queue here: http://en.wikipedia.org/wiki/M/M/%E2%88%9E_queue I am interested in the average busy period of this model, i.e the average time interval during which at least one server is busy. I am a little bit confused here how this should like with an infinite amount of servers.","['probability-theory', 'queueing-theory', 'probability']"
698446,Quadratic variation - Semimartingale,We know that any Semimartingale has Quadratic variation. I am interested to know if the converse is also true i.e. if a process has quadratic variation then it is semimartingale. Can some one prove/disprove it. Thank you very much.,"['stochastic-processes', 'stochastic-analysis', 'probability-theory', 'quadratic-variation', 'stochastic-calculus']"
698464,Precalc - Trig Identities,"I only need a hint as to where to go from here. My problem is this: $$ \dfrac{1+\tan(x)}{\sin(x)}-\sec(x) $$ Here's my work trying to solve the problem, up until I got stuck. Did I make a mistake somewhere or make it more complicated than it should have been? $$ \dfrac{(1+\tan(x))(\cos(x)}{\sin(x)\cos(x)}-\dfrac{\sin(x)}{\cos(x)\sin(x)}=\dfrac{(1+\tan(x))(\cos(x))-\sin(x)}{\cos(x)\sin(x)}=\dfrac{1+\tan(x)-\sin(x)}{{\sin(x)}}=\dfrac{1}{\sin(x)}+\dfrac{\dfrac{\sin(x)}{\cos(x)}}{\sin(x)}-\dfrac{\sin(x)}{\sin(x)}=\csc(x)+\sec(x)-1 $$",['trigonometry']
698477,Minimum of variance when sample is unbiased?,"Show that if an estimator $\hat\mu=a_1X_1 +a_2X_2 +\cdots+a_nX_n$, where $a_1, a_2,\ldots,a_n$ are constants, is unbiased, then its variance is minimum when  $a_1=a_2=\cdots=a_n=\frac{1}{n} \hat\mu=\bar X$. Ive tried subjecting it to $\sum a_i=1$, and I know that $\sum a_i^2$ is minimized by choosing $a_1=a_2=\cdots=a_n=1/n$), not sure what to do next. We are assuming all observations are iid.","['statistics', 'statistical-inference']"
698478,A problem with concyclic points on $\mathbb{R}^2$,"I am thinking about the following problem: If a collection $\{P_1,P_2,\ldots,P_n\}$ of $n$ points are given on the $\mathbb{R^2}$ plane, has the property that for every $3$ points $P_i,P_j,P_k$ in the collection there is a fourth point $P_l$ in the collection such that $P_l$ is con-cyclic with $P_i,P_j,P_k$, (i.e. $P_l$ lies on the circle passing through the points $P_i,P_j,P_k$), does it follow that all the points are necessarily con-cyclic ? I would really appreciate if someone finds a proof with basic Euclidean Geometry. I would call a class of Convex Geometric figure (upto Homothety) on $\mathbb{R}^2$, $k$-determined if exactly $k$ points are required to determine the figure uniquely. For example a circle is $3$-determined, one needs exactly $3$ points on the plane to determine a circle uniquely. An ellipse is $4$-determined. From here I would like to ask the following question : If a collection $S$ of $n$ points on $\mathbb{R}^2$, has the property that every sub-collection $T_i=\{P_{i_1},\ldots,P_{i_k}\}$ of $k$ points of $S$ has the property that there is a $k+1^{th}$ point, $P_i \in S\setminus T_i$ (distinct from the sub-collection $T_i$) that lies on the $k$-determined convex figure, determined by $T_i$, then  does it follow that all points of $S$ lie on the $k$-determined convex figure? Inspired from The Sylvester-Gallai Theorem","['geometry', 'euclidean-geometry']"
698486,Does there exist a system such that the additive identity is non-zero?,"I am trying to explain how although the additive identity is written as $0$, it is not the same as the number $0$.
For example for a $2\times 2$ matrix the additive identity is $\begin{pmatrix} 0 & 0 \\ 0 & 0 \end{pmatrix}$. However this is a bad example since it only involves $0$'s So what is a system such that the additve identity is non-zero (preferably not involving a $0$)? I would use mod p but this (seemingly) contradicts the rule for the uniqueness of the identity This arose because of a question, find a vector space such that $0=1$, however by ""$0,1$"" they meant the additive and multiplicative identities. So I was trying to explain that the additve identity is different from $0$ in certain systems.","['arithmetic', 'elementary-set-theory']"
698506,Curvature of saddle by definition,"I'm trying to compute the principle curvatures of the saddle $M$ defined by $z= y^2 -x^2$ at the point $p = (0,0,0)$, but I know my computations are wrong.  Maybe you can help to see where I went wrong. I have computed the tangent plane as $z = 0$.  So first take a vector $(0,1,0)= e_1$, corresponding to the $x=0$ part (so that $z = y^2$).  Now, define a map $\gamma(s) = (0,s,s^2)$.  Then, $\gamma : (-\epsilon,\epsilon) \rightarrow M$ and this satisfies $\gamma(0) = (0,0,0) = p$ and also $\gamma'(0) = (0,1,0) = e_1$. Now, the first curvature should be the eigenvalue of the Weingarten map $L$.  That is by definition $$L(e_1) = -\frac{d}{ds}n(\gamma(s))|_{s=0}$$  But $$n(\gamma(s)) = \frac{\gamma(s)}{|\gamma(s)|} = \frac{(0,s,s^2)}{\sqrt{s^2+s^4}}$$ When I take the derivative and evaluate at $s= 0$, I get $(0,0,1)$, which is not a multiple of $e_1$. I know by a different method that I should get $L(e_1) = 2e_1$.  Can you see where I went wrong?  Thanks.","['curvature', 'differential-geometry']"
698520,Euler-Lagrange Equation example,"I have been working on solving Euler-Lagrange Equation problems in differential equations, specifically in Calculus of Variations, but this one example has me stuck.  I am probably making mistakes in my integration. I am supposed to solve the Euler-Lagrange equation given that $f(t,x(t),x^{\prime}(t))=f(t,u,v)=\frac{\sqrt{1+v^2}}{u}$. I know that $f_u=-\frac{\sqrt{1+v^2}}{u^2}$ and $f_v=\frac{v\sqrt{1+v^2}}{u(1+v^2)}$.  Plugging this into the Euler-Lagrange Equation, $f_u-\frac{d}{dt}f_v$ gives
$$\frac{\sqrt{1+(x^{\prime})^2}}{x^2}-\left(\frac{x^{\prime}\sqrt{1+(x^{\prime})^2}}{x(1+(x^{\prime})^2)}\right)^{\prime}=0.$$ I cannot figure out from here how to solve it.  Have I made a mistake up to now?  Could someone help me out in actually solving this for x?","['ordinary-differential-equations', 'calculus-of-variations']"
698526,Find $\int \cos^4(x)dx$,"We have: $\int \cos^n x\ dx = \frac{1}{n} \cos^{n-1} x \sin x + \frac{n-1}{n}\int \cos^{n-2} x\ dx.$ Find $\int \cos^4x\ dx$ by using the formula twice What I have so far is: $\int \cos^4 x\ dx = \frac{1}{4} \cos^{3} x \sin x + \frac{3}{4}\int \cos^{2} x\
 dx$ Now we use the formula for $\int cos^{2} x\ dx$: $\int \cos^2 x\ dx = \frac{1}{2} \cos x \sin x + \frac{1}{2}\int \cos^{0} x\
 dx$ $\int \cos^2 x\ dx = \frac{1}{2} \cos x \sin x + \frac{1}{2}\int 1 \
 dx$ $\int \cos^2 x\ dx = \frac{1}{2} \cos x \sin x + \frac{1}{2}[ x ]$ $\int \cos^2 x\ dx = \frac{1}{2} \cos x \sin x + \frac{x}{2}$ Now plug this in to the  $\int \cos^4 x\ dx$ equation above $\int \cos^4 x\ dx = \frac{1}{4} \cos^{3} x \sin x + \frac{3}{4}[\frac{1}{2} \cos x \sin x + \frac{x}{2}]$ $\int \cos^4 x\ dx = \frac{1}{4} \cos^{3} x \sin x + \frac{3}{8}[\cos x \sin x + {x}]$ This is where I get stuck. I'm aware I could have used an identity for $\cos^2x$ but the question needs me to use the formula twice.","['trigonometry', 'calculus', 'integration', 'indefinite-integrals']"
698532,Edges and Vertices,"Three missionaries and three cannibals start on the left bank of a river. They have a rowboat with them that holds at most two people that can be used to transport people across the river (assume the rowboat can be rowed by either a missionary or a cannibal). Assuming that at no time the number of cannibals can outnumber the missionaries on either bank of the river how can all three missionaries and all three cannibals be transported safely across the river to the right bank. My answer would be to take a cannibal over first, then take a missionary, then another, and then you have 2 missionaries and 1 cannibal on the right, and 1 missionary and 1 cannibal still on the left with a cannibal crossing back but then that wouldn't work because now you will have a cannibal crossing back over to the left to pick up another person which will lead to 2 cannibals and 1 missionary.",['functions']
698533,Divergence of $ \sum_{n = 2}^{\infty} \frac{1}{n \ln n}$ through the comparison test?,"I have shown that it diverges through the integral test, but I am curious about how this would be shown using the comparison test. I can't use harmonic series because this is lesser than it. I had one idea: harmonic series can be compared to $1 + (\frac{1}{2}) + (\frac{1}{4} + \frac{1}{4}) + (\frac{1}{8} + \frac{1}{8} + \frac{1}{8}  + \frac{1}{8})$ to show that it diverges, maybe something similar can be done in this case? Edit: using Cauchy condesnation: $\sum_{n = 2}^{\infty} \frac{2^n}{2^n \log 2^n} \rightarrow \frac{1}{\log 2} \sum_{n = 2}^{\infty} \frac{1}{n}$, which is the harmonic series excluding $n = 1$, so the series diverges.","['convergence-divergence', 'sequences-and-series']"
698546,Does this condition on the sum of a function and its integral imply that the function goes to 0?,Consider a bounded real-valued function $S:\mathbf{R}\to\mathbf{R}$ so that $$\lim_{x\to\infty} \left( S(x) + \int_1^x \frac{S(t)}{t}dt\right)$$ exists and is finite. Can one say that $\lim_{x\to\infty} S(x)=0$?,"['integral-equations', 'limits']"
698552,Proving a particular function is a measure,"Statement Let $(X,\Sigma)$ be a measurable space. Let a function of sets $\mu:\Sigma \to \mathbb R_{\geq 0}$ that satisfies: $A, B \in \Sigma \space \wedge \space A \cap B = \emptyset \space \implies \mu(A \cup B)=\mu(A) + \mu(B)$ $A_n \in \Sigma \wedge A_n \searrow \emptyset \implies \lim_{n \to \infty} \mu(A_n)=0$ Prove that $\mu$ is a measure. The attempt at a solution. In order to prove that $\mu$ is a measure, I have to show it satisfies three properties: i. $\mu(\emptyset)=0$ ii. $\mu(E) \geq 0$ for all $E \in \Sigma$ iii. If $\{E_i\}_{i \in \mathbb N}$ is a sequence of pairwise disjoint sets, then $\mu(\bigcup_{i \in \mathbb N} E_i)=\sum_{i \in \mathbb N} \mu(E_i)$ I could prove i., since $\emptyset \in \Sigma$ and $\emptyset \cap \emptyset=\emptyset$, by hypothesis we have $\mu(\emptyset)=\mu(\emptyset \cup \emptyset)=\mu(\emptyset)+\mu(\emptyset) \implies \mu(\emptyset)=0$ I don't know how to show ii. and iii., I would appreciate any help/suggestion.","['measure-theory', 'real-analysis']"
698557,Elimination of Trigonometric Functions,"Is there a simple way to eliminate the trigonometric functions here? 
$$
\begin{array}{lcl}
A\cos(3\omega\tau)+B\sin(3\omega\tau)+C\cos(\omega\tau) &=& D\\
B\cos(3\omega\tau)+A\sin(3\omega\tau)+C\sin(\omega\tau) &=& 0
\end{array}
$$
I would ideally like to solve for $\tau$. Please help!","['calculus', 'complex-analysis']"
698563,Stable and unstable manifolds,"I would like to know how to finish this problem, and if what I have done so far is correct. Problem: Determine the stable and unstable manifolds for the rest point of the system $$\dot{x}=2x-(2+y)e^y, \dot{y}=-y.$$ Attempt and outline: The rest point of the system is $(1,0).$ Now, I changed the coordinates of the system to be centered at the origin, giving me the system $$\dot{x}=2(x+1)-(2+y)e^y, \dot{y}=-y.$$ I have found the solutions of the (shifted) system to be $$x=e^{{c_1}e^{-t}}+c_2e^{2t}-1, y=c_1e^{-t}$$ Then I computed $Df(x_0)$ and obtained the eigenvalues of the associated linear system as $\lambda_1 = 2, \lambda_2 = -1$. My question is: Now that I have the stable and unstable eigenspaces (manifolds) for the linear system, how can I find them explicitly for the nonlinear system? Thanks for any help.",['ordinary-differential-equations']
698575,Show the cylinder is a regular surface,"Show that the cylinder $(x,y,z) \in R^3; x^2+y^2=1 $is a regular surface and find parameterizations whose coordinate neighborhoods cover it. I'm going to be honest I saw this answer but I don't quite understand it. I am familiar with the propositions that I am given but not sure how its applied. Proposition 2: If $f: U \subset R^3 \rightarrow R $ is a differentiable function and $a \in f(U)$ is a regular value of $f$, then $f^{-1}(a)$ is a regular surface in $R^3$. Proof:Define this function $f(x,y,z)= x^2+y^2+z^2-1$. Then the cylinder is the set $f^{-1}(0)$. Computing all partial derivatives, this result is obtained. $\frac{\partial f}{\partial x}=2x, \frac{\partial f}{\partial y}=2y, \frac{\partial f}{\partial z}=2z.$ It is clear that all partial derivatives are zero if and only if x=y=z=0  or $(0,0,0)$. Further checking shows that $f(0,0,0) \neq 0$, which means that $(0,0,0)$ does not belong to $f^{-1}(0)$. Hence for all $u \in f^{-1}(0)$, not all of partial derivatives at $u$ are zero. By proposition 2, the cylinder hence is regular surface. Futhermore the cylinder can be parameterized as $g(u,v)=(cos u, sinu,v)$ where $u,v \in \mathbb{R}$ Okay so I'm not sure why we define the function as $f(x,y,z)= x^2+y^2+z^2-1$; is it because we are told it is in $R^3$ so we have to include $z$? I really want to understand all the steps to this. If someone can help I would really appreciate it.",['differential-geometry']
698592,Constructively generating a sigma algebra,"We have a collection $\mathcal{C}$ of sets (includes $\Omega)$ and would like to constructively generate the sigma algebra $\sigma(\mathcal{C})$. Would the following process work? Let $\mathcal{S}=\mathcal{C}$ 1.Take the complement of each set in $\mathcal{S}$ and add it to $\mathcal{S}$
2.Take all possible finite and countably infinite unions of sets in $\mathcal{S}$ and add them to $\mathcal{S}$.
3. goto step 1. I have seen it claimed that taking countable unions and intersections of open intervals can only give you a proper subset of the Borel sets. This would seem to imply that the above process would not work because any resulting set could only have arisen from countable unions and intersections.","['set-theory', 'measure-theory']"
