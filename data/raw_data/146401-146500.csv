question_id,title,body,tags
2398037,Calculate $\int_{-\pi}^\pi\bigg(\sum_{n=1}^\infty\frac{\sin(nx)}{2^n}\bigg)^2dx$,"Calculate:$$\int_{-\pi}^\pi\bigg(\sum_{n=1}^\infty\frac{\sin(nx)}{2^n}\bigg)^2dx$$ One can prove $\sum_{n=1}^\infty\frac{\sin(nx)}{2^n}$ converges uniformly by Dirichlet's test, integrate term-by-term, and since $\int_{-\pi}^\pi\frac{\sin(nx)}{2^n}dx=0,$ we get series of $0$'s and the final result would be $0.$ Thing is I'm not sure how to deal with the square. Any help appreciated.","['real-analysis', 'calculus', 'integration', 'sequences-and-series', 'analysis']"
2398078,Why isn't the Jordan Curve Theorem axiomatic?,"In topology, a Jordan curve is a non-self-intersecting continuous loop in the plane, and another name for a Jordan curve is a plane simple closed curve. The Jordan curve theorem asserts that every Jordan curve divides the plane into an ""interior"" region bounded by the curve and an ""exterior"" region containing all of the nearby and far away exterior points, so that every continuous path connecting a point of one region to a point of the other intersects with that loop somewhere. ( Wikipedia ) That a continuous closed non-self-intersecting loop would divide a normal euclidean plane into two regions which can be joined only by a path crossing the loop would have been axiomatic, or so I would have thought. It is inherent in the idea of a closed non-intersecting curve that it defines an inside and an outside. Are the difficulties in proving the theorem present in a simple euclidean plane, or only when it is applied to non-euclidean geometries or higher dimensions?","['general-topology', 'axioms', 'foundations']"
2398130,Does there exist a side-rational triangle of area $1$?,"A side-rational triangle stands for a triangle with each side rational. We know, by cosine theorem and computing the area of the triangle, we can get that each angle of the triangle is of rational $\sin$ and $\cos$. Then consider ant height of one side, we have 
$$S=h(h\cot \alpha+h\cot \beta)/2$$
Then it suffices to show that 
$$t-\frac{1}{t}+T-\frac{1}{T}\notin \mathbb{Q}^2\quad t,T\in \mathbb{Q}$$
But i am stuck on it.","['number-theory', 'triangles']"
2398152,Minimum difference between $2^n$ and $3^m$ vs. $N$ where $N=n+m$,"I'd like to know minimum difference $D$ as a function of $N$ where: $D=|2^n-3^m|$ $N=n+m$ Just experimentally, it looks like $\ln D$ is linear with $N$, approximately: $\ln{D}\approx0.425N$ For a given $N$, the minimum $D$ occurs at $n=\lfloor{N\over{1+{\log2\over{\log3}}}}\rfloor+1$ if $2^n-3^m$ is positive and $n=\lfloor{N\over{1+{\log2\over{\log3}}}}\rfloor$ if $2^n-3^m$ is negative. A detail: The red dots are where the minimum $2^n-3^m$ is negative, blue positive. So there's slight amount of ""noise"" around that line so maybe an exact expression is unlikely, but is there a more formal way to derive this?","['number-theory', 'collatz-conjecture']"
2398165,Choosing branch cuts for complex integration,"When calculating integrals like $$\int_0^\infty \frac{x^\alpha}{1 + x^2}dx$$ for $\alpha \in (-1,1 )$, it is convenient to take the branch cut of the integrand along the positive real axis and then use the keyhole contour. I was wondering is there a way to use the principal branch cut, which runs along the negative real axis, to calculate this kind of integrals? I'm assuming some trivial manipulation of the integrand for $x>0$ would do the trick, but I fail to see it.","['complex-analysis', 'integration', 'definite-integrals', 'complex-integration']"
2398173,Relations between Trace and Spectrum of an Operator,"As the trace of a matrix equals to the sum of all eigenvalues, do we have an analogous result that the trace of an operator (if it is well-defined) equals to an integral on the spectrum space?","['functional-analysis', 'reference-request', 'trace', 'operator-theory']"
2398177,Question about the physical intuition behind tensors,"I would like to check something with you. I am a beginner in differential geometry and in general relativity so I may say wrong things. This is what I understood from tensors. Tensors are object for which coordinates follows a specific transformation when a change of basis is done. If I define a tensor on a basis $A$, I automatically know its components on a basis $B$. The philosophy behind the object is to be able to define quantities that are ""absolute"" and don't depend on coordinates. For example $ds^2=dx^2+dy^2$ is also written in polar coordinates $ds^2=dr^2+r^2 d\theta^2$ but it represents physically the same distance : if I compute the scalar product between two vectors using either the first or the second basis, the result will be the same. So finally : can I say that tensors are mathematical object that are used to describe phenomenon that are absolute and don't depend on a given set of basis . For example if I take a n-contravariant and p-covariant tensor and I apply it on n vectors and p covectors the final result will not depend of any choice of basis. Also : why do we only define tensors as object that transforms as $m'^i_j=m^k_l \frac{\partial x^l}{\partial y^j}\frac{\partial y^i}{\partial x^k}$ and not more general transformations ? Is it because the tensors are constructed around the notion of vectors/covectors and we want that tensors applied on vector and covector give result independant of the coordinates. So all the tensors were constructed to ensure that applied on vector and covectors they give result indepent of coordinates. Indeed, we could imagine to create other objects that ensure basis-independant results with other object than vectors but it is just that we don't need them in practice (in general relativity we would'nt need them for example). My last question is juste to be sure that I understand well... or not.","['differential-geometry', 'general-relativity']"
2398188,Lebesgue integral of Gaussian process is Gaussian.,"Let $X:\Omega\times\mathcal{T}\rightarrow\mathbb{R}$ be a measurable stochastic process, Lebesgue integrable on $\mathcal{T}$ for a.e. $\omega\in\Omega$: $$\int_{\mathcal{T}} |X(\omega,t)|\,dt<\infty.$$ Suppose that $X$ is Gaussian, that is, for every $t_1,\ldots,t_m\in\mathcal{T}$ and $m\in\mathbb{N}$ the random vector $(X(t_1),\ldots,X(t_m))$ follows a multivariate normal law. I want to prove that the random variable defined by 
$$\omega\mapsto \int_{\mathcal{T}} X(\omega,t)\,dt $$ is normal. If the integral were interpreted as a Riemann integral, then we could express $\int_{\mathcal{T}} X(\omega,t)\,dt$ as a limit of Riemann sums, which are clearly normal (see the accepted answer here ). But I do not know how to prove that $\int_{\mathcal{T}} X(\omega,t)\,dt$ is normal when the integral is in the Lebesgue sense. We know that the Lebesgue integral is a limit of step functions, but those step functions may not be normal.","['stochastic-processes', 'probability-theory', 'probability', 'lebesgue-integral', 'stochastic-integrals']"
2398194,why is R-square NOT well-defined for a regression without a constant term,"We often have a constant term in a linear regression such as, $y=\beta_1 x+\beta_0$. The $R^2$ or the coefficient of determination, is defined as $R^2=1-\frac{SS_{res}}{SS_{tot}}$, where $SS_{res}$ and $SS_{tot}$ are residual sum of squares and total sum of squares. Let's say now we drop the constant term $\beta_0$, the above formula for calculating $R^2$ still works, or is it? If we try this in Matlab, we receive a Warning that says, R-square and the F statistic are not well-defined unless X has a column of ones. What does ""not well-defined"" mean here? It seems okay.","['regression', 'statistics', 'linear-regression', 'matlab']"
2398226,Relation of subsets of a quotient sets by the same relation,"I have a set $\mathbb{A}$ and an equivalence relation $\sim$ defined on that set. Now I take a subsets $A \subset \mathbb{A}$. Can I just say $A/\sim \subset \mathbb{A}/\sim$? As I understand it I can't, since there can be $\mathbb{A} := \{x,y\}$ with $x \sim y$ while $A := \{x\}$ ($x,y \in \mathbb{A}$, $x \in A$, $y \notin A$).
From this follows $\{\{x,y\}\} = \mathbb{A}/\sim$ but $\{\{x\}\} = A/\sim$ and we know $\{\{x\}\} \not\subset \{\{x,y\}\}$. This especially comes into play, when I want to do set operations on subsets of $\mathbb{A}$ and I want to have the intersection of two subsets in regard to the equivalence classes. Disclaimer: I hope the title actually describes what I'm asking. I'm happy about any hint for clarification.","['equivalence-relations', 'elementary-set-theory']"
2398268,"If $\ \sum_{k=1}^n m(E_k) > n-1,$ then prove that $\bigcap_{k=1}^n E_k$ has positive measure.","Question: Let $E_1,E_2,...,E_n$ be measurable subsets of $[0,1]$ with $$ \sum_{k=1}^n m(E_k)  > n-1.$$ Prove that $\bigcap_{k=1}^n E_k$ has positive measure. This is one of the questions in graduate analysis past year paper.
I think we need to assume that the intersection $\bigcap_{k=1}^n E_k$ is nonempty. Otherwise, the question is false. Anyway, let's assume that $\bigcap_{k=1}^n E_k \neq \emptyset.$ If $n=2,$ by inclusion-exclusion principle and assumption, $$m(E_1\cup E_2) + m(E_1 \cap E_2) = m(E_1) + m(E_2) > 2.$$ Since $E_1,E_2 \subseteq [0,1],$ by monotonicity of Lebesgue measure, $$m(E_1) \leq 1, m(E_2) \leq 1.$$ By finite subadditivity of Lebesgue measure, $$m(E_1 \cup E_2) \leq m(E_1) + m(E_2) \leq 2.$$ Hence, $$m(E_1 \cap E_2) > 2 - m(E_1 \cup E_2) \geq 0$$ Therefore, the intersection $\bigcap_{k=1}^n E_k$ has positive measure for $n=2.$ I try prove the general $n$ using induction, but it seems a bit long. Does there exist an efficient method to solve the question? EDIT: Actually I am looking for a direct proof instead of indirect proof or inductive proof. If a direct proof is not possible, then I will accept Marios's answer.","['real-analysis', 'lebesgue-measure', 'measure-theory']"
2398307,Group of order 2016,I've come across the following exercise: Let $G$ be a group of order 2016 in which every element of order 7 is conjugate. Prove that $G$ has a subgroup of index 2. Does anyone have any idea of how one much approach doing this using Sylow theory?,"['finite-groups', 'sylow-theory', 'group-theory']"
2398327,Mean value theorem for Riemann-integrable functions,"I'm reading Bressoud's A radical approach to Lebesgue theory of integration and there's a section that I don't get, please read below: Is there a mean value theorem for integrable functions ? I know there's one for integrals of continuous functions. If the continuity assumption is dropped, I don't know what to do...","['real-analysis', 'integration']"
2398331,Is there an elementary way to prove that the algebraic integers are a Bézout domain?,"Well, the title of my question says all, but let me give some context. Right now I'm writing some lecture notes on ring theory with a little of commutative algebra. I wrote a few results about integral extensions and that led me to define the algebraic integers $\overline{\Bbb Z}$ as the integral closure of the extension $\Bbb Z\subseteq \Bbb C$. Since I included a topic on factorization in integral domains where I defined what is a Bézout domain, it seems very natural to me to show that $\overline{\Bbb Z}$ is an example of a Bézout domain. However,  and here comes my problem, I haven't found an elementary proof of the above fact. The only reference that I have is a theorem in Kaplansky's book ""Commutative rings"". I checked the proof given in that book, but I can't understand it very well, moreover Kaplansky uses terminology from Algebraic Number Theory as ""class group"" and certainly I can't use any of that in my notes because they are aimed to cover a basic/intermediate course of ring theory. In summary, is there a ring-theoretic way to prove that the ring of algebraic integers is a Bézout domain? P.S. I'm aware of this post and the only answer uses Algebraic Number Theory, which as I said, I can't use.","['abstract-algebra', 'ring-theory', 'alternative-proof', 'commutative-algebra']"
2398360,How many ways are there to color $1\times1$ squares in a $4\times5$ rectangle?,How many ways are there to color $1\times1$ squares in a $4\times5$ rectangle with four colors in a way that every $2\times2$ square contains all four colors? The answer to this is very simple but needs to prove sth that I can't. The following statement: In every coloring we use two colors repeatedly in a column or row I mean like below here is the column case: Any hints?,['combinatorics']
2398407,Can polynomial be a solution to linear ordinary differential equation?,"Can polynomial
\begin{equation}
\pi_x(t) = \sum^m_{k=0}x_kt^k
\end{equation}
be a solution to  a linear ordinary differential equation:
\begin{equation}
\dot{x}(t) = A x(t)
\end{equation}
where $x \in \mathbb{R}^n$ and $A \in \mathbb{R}^{n \times n}$.","['polynomials', 'ordinary-differential-equations', 'linear-algebra']"
2398428,Distribution of the outer product of two Gaussian vectors,"Assume that $\mathbf{x} \sim \mathcal{N}(0,\mathbf{I}_n)$ and $\mathbf{y}\sim \mathcal{N}(0,\mathbf{I}_p)$ are two independent standard Gaussian vectors. What is the distribution of their outer product $$\mathbf{x}\mathbf{y}^T=(x_iy_j)_{i\leq n, j\leq p},$$
which is a $n\times p$ matrix? In the simple case where $p=n=1$, we end up we the normal-product distribution , but in higher dimensions, things appear to get trickier and I don't know much about matrix variate distributions.","['outer-product', 'normal-distribution', 'probability-distributions', 'probability', 'linear-algebra']"
2398436,Any neat proof that $0$ is the unique solution of the equation $4^x+9^x+25^x=6^x+10^x+15^x$?,"It is obvious that both $f(x)= 4^x+9^x+25^x$ and $g(x)=6^x+10^x+15^x$ are strictly monotonic increasing functions. It is also easy to check that $0$ is a solution of the equation. Also I chart the functions, and it looks that for any $x$ , $f(x)>g(x),$ which can be somehow proof by studying the derivative of the $h(x)=f(x)-g(x)$ and showing that $(0,0)$ is an absolute minimum point for $h(x).$ However $h(x)$ is a function with a messy derivative, and is not looking easy (for me) to find the zeroes of this derivative. Does anyone know an elegant proof (maybe an elementary one, without derivatives) for this problem?","['real-analysis', 'exponential-function']"
2398460,Derivations on the spaces of continuous functions form an infinite dimensional vector space(generalized tangent space),"This question basically asks why the notion of tangent space can't be well-generalized to topological manifolds without coming across the issue of dimension. Let $X$ be a smooth manifold of finite dimension and $C(X)$ denote the space of continuous functions on $X$. Let $p\in X$. A linear derivation $v$ w.r.t.$p$ is a linear functional on $C(X)$ satisfying $v(fg)=f(p)v(g)+g(p)v(f), \forall f,g\in C(X)$. My question is, is the space of linear derivations an infinite dimensional space? I will be happy enough to see a proof for $X=\mathbb R, p=0$(or other special cases that could lead to infinite dimension), but general results will be great. As we know, if $C(X)$ is replaced by $C^\infty(X)$, then this space is the ordinary tangent space, which is finite dimensional.","['functional-analysis', 'smooth-manifolds', 'differential-geometry']"
2398543,Cesaro continiuity leads linearity,"I need just a hint please. It seems that I have to prove that 
$f(x)=mx$
in which 
$m\in \mathbb{R}.$ But I couldn't handle it. Problem: We say that a sequence $x_{n}\; , n = 1, 2,\cdots ,$ Cesaro converges to $a,$ 
  if
  $$ \lim\limits_{n\to\infty}\frac{1}{n}\sum_{i=1}^{n}x_{i}=a. $$
  A function 
  $f$ 
  is Cesaro continuous at 
  $a$ 
  if 
  $x_{n}\to a$ (in Cesaro mean) 
  implies 
  $f(x_{n})\to a$ (in Cesaro mean). 
  Prove that, if
  $f : \mathbb{R}\to\mathbb{R}$ 
  is Cesaro continuous at 
  $0$ 
  and 
  $f(0) = 0,$ then $f$ is linear.","['cesaro-summable', 'real-analysis', 'analysis', 'limits']"
2398552,Are the elements of a set within a set also the elements of the latter?,"It is my understanding that an event is a subset of the set of all possible outcomes (sample space). If however the sample space consists of elements which are sets, can an event be defined as one the elements from these ""inner"" sets?
Ex. A coin is flipped twice, (S={(H,T),(T,H),(T,T),(H,H)} Is the event A=(H) valid for the sample space despite not being a subset of S?","['probability', 'elementary-set-theory']"
2398559,Finding the number of terms of binomial expansion $(1+x+x^2)^{20}$,"In the expansion of $(1+x+x^2)^{20}$ , find the number of terms in the binomial expansion. Let $(1+x)$ be one term and $x^2$ as the second terms $$\binom {20} {0} C x^{40}(1+x)^0+\binom {20} {1}Cx^{39}(1+x)^1+\dotsb+\binom {20} {20} x^0(1+x)^{20}$$ Number of terms $= 1+2+3+\dotsb +20 = 20\cdot \frac{21}{2}=210$ ? But the answer is 41. How? Can anyone explain it to me why I am wrong? And why answer should be 41 This is a gmat exam question.","['combinatorics', 'binomial-theorem', 'solution-verification']"
2398566,Approximate three or more numbers,"I know that using continued fraction I can approximate $$\frac{\ln 3}{\ln 2},$$ which means that i can find two integers such that $2^{k_2} \approx 3^{k_3}$, my question is can I approximate using continued fraction or any other method three integer $k_2 ,k_3,k_5$ such that $2^{k_2} \approx 3^{k_3} \approx 5^{k_5}$ ?","['number-theory', 'irrational-numbers', 'approximation']"
2398572,"if $f$ is Lebesgue integrable in $[0,1] \Rightarrow f$ is bounded in $[0,1]$?","I know this is almost trivial or evident, but I wanted to be sure if any Lebesgue integrable function on a compact set is bounded or not. I hope it is true because I'm using that fact for solving some of my problems. If it is not true, please provide a counterexample. Thanks.","['real-analysis', 'integration', 'lebesgue-integral', 'measure-theory']"
2398603,Quotient of Fractional Ideals,"I am just wondering if the following isomorphism always happens or under some special conditions this holds.
$$ I^{-1}/\mathcal{O}_{K}\cong \mathcal{O}_K/I, $$ where $K$ is a number field, $\mathcal{O}_K$ is ring of integers of $K$ and $I$ is an integral ideal. Note that those two cardinalities are the same and I believe if K is with class number one then the above isomorphism holds. Thank you for the help.","['number-theory', 'abstract-algebra', 'algebraic-number-theory', 'algebraic-geometry']"
2398614,Matrix Multiplication $\to$ Function Composition?,"One property of matrices that I found very interesting is the fact that if you have two functions of the same form
$$f_0(x)=\frac{ax+b}{cx+d}$$
$$f_1(x)=\frac{a'x+b'}{c'x+d'}$$
then the function $f_0\circ f_1$ is in the same form, and if you put the coefficients $a,b,c,d$ and $a',b',c',d'$ into two matrices like this:
$$\begin{pmatrix} a&b \\ c&d \end{pmatrix}$$
$$\begin{pmatrix} a'&b' \\ c'&d' \end{pmatrix}$$
Then the coefficients of $f_0\circ f_1$ are given by the matrix
$$\begin{pmatrix} a&b \\ c&d \end{pmatrix}\begin{pmatrix} a'&b' \\ c'&d' \end{pmatrix}$$
I use this property quite often when dealing with the composition of rational functions with linear numerators and denominators since it spares me the trouble of putting myself through some unnecessary algebra. Whilst thinking about this property, however, I was wondering if there is an analogous type of function that corresponds to a three-by-three matrix. I'm looking for some type of function so that if $g$ and $g_0$ are of this type such that the ambiguous non-$x$ variables of the type of function (suppose they are $a,b,c,d,e,f,g,h,i$ and $a',b',c',d',e',f',g',h',i'$) can be assigned to two three-by-three matrices
$$\begin{pmatrix} a&b&c \\ d&e&f \\ g&h&i \end{pmatrix}$$
$$\begin{pmatrix} a'&b'&c' \\ d'&e'&f' \\ g'&h'&i' \end{pmatrix}$$
and the matrix corresponding to $g\circ g_0$ is
$$\begin{pmatrix} a&b&c \\ d&e&f \\ g&h&i \end{pmatrix}\begin{pmatrix} a'&b'&c' \\ d'&e'&f' \\ g'&h'&i' \end{pmatrix}$$ Can anyone find a type of function like this? This would be very helpful to me in my studies of iterated functions.","['matrices', 'function-and-relation-composition', 'functions']"
2398634,Applications of Beta Distribution [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 6 years ago . Improve this question What properties of random variable leads to modeling it with Beta Distribution? Context: If you ask the same question about Bernouli distribution, the answer would be the distribution of a random variable that has only two outcomes and the probability of one outcome is fixed at $p$.
Now how can we answer a similar question about Beta distribution?","['statistics', 'probability']"
2398639,"Prove that for all sets A,B,C if B $\subseteq$ C then A $\cup$ B $\subseteq$ A $\cup$ C","I don't really know what to do with unions, can someone help me? I assume $B\subseteq C$, (I want to show that $A\cup B \subseteq A\cup C$)
suppose $A\cup B \subseteq A\cup C$ and let $x\in A\cup C$ so that $x\in A$ or $x\in C$... I don't really know what to do up to this point, can someone offer me guidance?",['discrete-mathematics']
2398647,"Limit $\lim_{(x,y)\to (0,0)}\frac{\sin(xy)}{xy}$","First of all, thanks for any help provided.  My question is how to properly solve this limit: $\lim_{(x,y)\to (0,0)}\frac{\sin(xy)}{xy}$ I should be 1 as it look, I tried it using polar coordinates and I obtained this limit: $\lim_{r \to 0} \frac{\sin(r^2\sin(\theta)\cos(\theta))}{r^2\sin(\theta)\cos(\theta)}$ where I am using $x=r\cos(\theta)$ and $y=r\sin(\theta)$.  From this limit how I conclude that is equal 1?  I guess $\theta$ don't approach any value while $x,y \to 0$ and that is because I didn't wrote it in the limit (is that correct?). Thank you",['multivariable-calculus']
2398665,preimage of a polynomial union of closed paths,"This is an exercise from Conway p.130 and I managed to solve (a) and (b). But I am stuck at (c). I have no idea how to show that the preimage of p is a union of finite number of closed paths... either about the behavior as c goes to infinity.
Could anyone help me with this problem?","['complex-analysis', 'polynomials']"
2398733,$p\equiv1\pmod 8$. Solve $x^4\equiv-1\pmod p$,"Here is a very elegant result proven using Wilson's theorem: Theorem. $p\equiv1\pmod4\iff x^2\equiv-1\pmod p$ is solvable. In particular, $$x\equiv\Big(\frac{p-1}{2}\Big)!$$is a solution. $-(*)$ Proof. '$\Rightarrow$': $\bigg(\Big(\frac{p-1}{2}\Big)!\bigg)^2\equiv 1*2*\dots*\frac{p-1}{2}*\frac{p-1}{2}*\dots*2*1\equiv(-1)^{(p-1)/2}*1*2*\dots*\frac{p-1}{2}*(-\frac{p-1}{2})*\dots*(-2)*(-1)\equiv(-1)^{(p-1)/2}*1*2*\dots*\frac{p-1}{2}*\frac{p+1}{2}*\dots*(p-2)*(p-1)\equiv (p-1)!\equiv-1\pmod p$ '$\Leftarrow$': If so, then $x$ is of order $4$ in $\Bbb Z^*_p$. By Lagrange's theorem, $4$ divides $p-1$ the order of $\Bbb Z^*_p$. Thus $p\equiv1\pmod 4$ Afterall, $\Big(\frac{p-1}{2}\Big)!$ and $\bigg(\Big(\frac{p-1}{2}\Big)!\bigg)^3$ are the elements of order $4$ in $\Bbb Z^*_p$ Out of curiosity, I want to investigate the semi-direct product $\Bbb Z_p\rtimes\Bbb Z_8$. Assume $p\equiv1\pmod 8$. $x^4\equiv-1\pmod p$ has the following solutions for different $p$: p = 17, x ≡ 2, 8, 9, 15
p = 41, x ≡ 3, 14, 27, 38
p = 73, x ≡ 10, 22, 51, 63
p = 89, x ≡ 12, 37, 52, 77
p = 97, x ≡ 33, 47, 50, 64
p = 113, x ≡ 18, 44, 69, 95
p = 137, x ≡ 10, 41, 96, 127
p = 193, x ≡ 9, 43, 150, 184
p = 233, x ≡ 12, 97, 136, 221
p = 241, x ≡ 8, 30, 211, 233
p = 257, x ≡ 4, 64, 193, 253
p = 281, x ≡ 60, 89, 192, 221
p = 313, x ≡ 5, 125, 188, 308
p = 337, x ≡ 85, 111, 226, 252
p = 353, x ≡ 70, 116, 237, 283 I have no clue how to express one of the solutions of $x^4\equiv-1\pmod p$ in terms of $p$. Note that if $a$ is one of them, then so is $a^3$, $a^5$ and $a^7\mod p$ because $\Bbb Z^*_p$ is cyclic. I've tried out something like $\frac{p-1}{4}!+1$, and even $\frac{p-1}{8}!$. Obviously, those were just plain guess. The result $(*)$ is elegant. I wonder if the result for $x^4\equiv-1\pmod p$ if $p\equiv1\pmod 8$ would be equally elegant. Can somebody derive the general solution to this just like in $(*)$? P.S. As I'd expect, this question would be favourited in just a few minutes. I am however surprised that it has NEVER been asked before.","['number-theory', 'modular-arithmetic', 'group-theory', 'quadratic-residues']"
2398734,Mapping of compact set into colimit of space,"I am reading proposition 2.5.4 of Peter May's 'More Concise Algebraic Topology' ( http://www.maths.ed.ac.uk/~aar/papers/mayponto.pdf ), a part of which says that Let $\mathcal{D}$ be a filtered category, and $X_*:\mathcal{D} \to \mathcal{U}$ be a diagram of closed inclusions inside the category $\mathcal{U}$ of compactly generated weak Hausdorff spaces. Let $X$ be the colimit of $X_*$ then for every map $f:K \to X$ of a compact space $K$ into $X$, the image of $K$ lies inside some $X_d$. May proves this by first constructing $d_n \in \mathcal{D}, k_n \in K, (n=0,1,...)$  such that there are arrows $d_{n-1} \to d_n$ and $f(k_n) \in X_{d_n} \setminus X_{d_{n-1}}$. Then he claims that the countable ordered set $\{ d_n \}$, considered as a subcategory of $\mathcal{D}$, is cofinal in $\mathcal{D}$, hence $X=\varinjlim X_{d_n}$. This is where I got confused. A countably infinite totally ordered subcategory in a filtered category may not necessarily be cofinal. For example, $\{ \{1 \}, \{1,2 \}, \{1,2,3 \},... \}$ in the directed system of finite subsets of $\mathbb{Z}$. So May's claim must have used some of the topological information, but which I cannot see how. A similar question has been asked in this post: Compact subset in colimit of spaces , but it is the case when $\mathcal{D}$ is the poset of natural numbers, where a countably infinite subset is indeed cofinal. The answer in that question also doesn't generalize to prove the proposition in May's book. Any help is appreciated!","['algebraic-topology', 'general-topology', 'limits-colimits']"
2398777,"Prove that $\frac{\tan x}{x}>\frac{x}{\sin x}, x\in(0,\pi/2)$","Prove that $$\frac{\tan x}{x}>\frac{x}{\sin x},\;\;\; x\in(0,\pi/2).$$ My work I formulated $$f(x)=\tan x \sin x - x^2$$ in hope that if $f'(x)>0$ i.e. monotonic then I can conclude for $x>0, f(x)>f(0)$ and hence, prove the statement. However, I got $$f'(x)=\sin x + \sec x \tan x -2x, $$ where I am unable to conclude if $f'(x)>0.$ I also found $$f''(x)=\cos x + 2\sec^3x-\sec x-2,$$ $$f'''(x)=-\sin x (1-6\sec^4x+\sec^2x).$$ But I am not able conclude the sign of any of the higher derivatives either. Am I doing something wrong? Or is there some other way?","['derivatives', 'real-analysis', 'inequality', 'trigonometry', 'calculus']"
2398797,"Show that $\lim_{n \to \infty} \int_{0}^{1}|f_n(x)| \, dx= 0$ if $\int_0^1|f_n(x)|^2\,dx < 100$","Let $\{f_n\}$ be a sequence of Lebesgue integrable functions such that (i) $\int_0^1|f_n(x)|^2 dx < 100$ (ii) $ f_n \to 0$ almost everywhere We must show that $$ \lim_{n\to\infty}\int_0^1 |f_n(x)| \, dx = 0$$ I have a solution using Egoroff and Schartz Inequality. Is that necessary? Any other ideas ? Also I prove it by myself without that. I will edit the post later.","['real-analysis', 'lebesgue-integral', 'measure-theory', 'limits']"
2398826,"Using the relation $2(1 – \cos x) < x^2$, $x \ne 0$, prove that $\sin (\tan x) \ge x$ , $x \in [0,\pi/4]$.","Using the relation $2(1 – \cos x) < x^2$, $x \ne 0$, prove that $\sin (\tan x) \ge x$ ,  $x \in [0,\pi/4]$. For this problem I tried to use the relation $\tan x > x > \sin x$ for $x \in (0,1)$. Based on this my first step is $(\sin x/2)^2 < (x/2)^2$ , after this step I am struck.","['trigonometry', 'proof-verification']"
2398883,Is there a binary operation over the nonnegative reals satisfying the metric and group axioms?,"Is there a binary operation over the nonnegative reals which satisfies the metric axioms and the group axioms ? I.e., find an $f : S \times S \to S$ such that $(f,S)$ follows the group and metric axioms ( $S$ is a set of nonnegative reals) or prove that there is no such function. I have tried $f: (a,b) \mapsto |a - b|$ , but it is not associative. Some of other that I have tried are $f: (a,b) \mapsto |a + b|$ $f: (a,b) \mapsto |a.b|$ $f: (a,b) \mapsto |a / b|$ EDIT : I am trying XOR operation and to me it appears a valid choice.","['abstract-algebra', 'real-numbers', 'metric-spaces', 'group-theory']"
2398903,find maxima on a cardinal (catmull rom) spline,"I am looking to find the maximum deviation from the straight line joining control points on a cardinal spline. This link gives a polynomial equation for the spline: $$q(t) = 0.5 \cdot(  	(2 \cdot P_1) + (-P_0 + P_2) \cdot t + (2\cdot P_0 - 5\cdot P_1 + 4\cdot P_2 - P_3)  \cdot t^2 + (-P_0 + 3\cdot P_1- 3 \cdot P_2 + P_3) \cdot t^3)$$ The only input I have is the 4 points in 3 dimensions. My idea was to compute the tangent by taking the first derivative of the above equation so that I get the slope at any point on the spline. Then I could compare it with the slope of the line joining the two points. But I am kind of confused how to do it in 3D. How do I compare the slopes in 3D? I can get a unit vector in the direction of the straight line joining the points, but how can I get a unit vector at the tangent. Is there a simpler way to do this?","['derivatives', 'geometry']"
2398914,A die is rolled and a coin is flipped. What is wrong with the following reasoning?,"A die is rolled and a coin is flipped. What is wrong with the following reasoning?: Let $A=\{1,3,6\}$ (event from die roll), let $B=\{H\}$ (event of heads)
then, $A\cap B=\emptyset$ (since they have no common elements)
and $\Pr(A\cap B)=\Pr(\emptyset)=0$. I realize that the probability of the intersection of two independent events is the product of their probabilities but I want to know what is 'wrong' with this reasoning.","['independence', 'probability', 'dice']"
2398938,Find number of common divisors of 463050 and 2425500,"I am new to combinatorics (second lesson in the course) and I was wondering how to solve the following problem in the most elegant way: Find the number of common divisors for 463050 and 2425500? My intuition tells me to divide both numbers by 10 which will lead me to 5 and 2 but I feel that there is some other way. Thanks to all the kind helpers. p.s I will appreciate straightforward answer, and will appreciate even more a guidance on how to solve this kind of problems in the future.","['combinatorics', 'elementary-number-theory']"
2399042,Minimal sphere around a polyhedron,"I am writing about (convex) polyhedra (in 3-dimensional Euclidean space) and am trying to determine some symmetry groups. It would be very good to be able to say that every polyhedron has a unique sphere with minimal radius containing it . If this were true, then the center of this sphere would be preserved by the symmetries of the polyhedron (because they preserve distances) and these symmetries would be easier to determine (since they would have a fixed point). Now, I have two related questions and I would appreciate also partial answers: (1) Does such a unique minimal sphere always exist? Is there an appropriate restriction on the type of polyhedra considered that guarantees its existence? (2) If such a sphere exists, it cannot, in general, touch all vertices of the polyhedron. So can the sphere be characterized in other ways? What kind of point is the center of this sphere?","['polyhedra', 'euclidean-geometry', 'polytopes', 'geometry']"
2399109,"How many function from $\{0,1\}^{n}$ to $\{0,1\}^{m}$ there is","I am new to combinatorics and struggling with the following quastion: How many different functions $$f:\left\{0,1\right\}^{n}\rightarrow \left\{0,1\right\}^{m}$$ can be found? if: $$m \geq n$$ How I imagine it: every $\left\{0,1\right\}^{n}$
is a series of $1$-th and $0$-th in the length of $n$,
so for every element we can choose to change it to ($0$ or $1$) or to leave it without changing it. So for every element we got $2$ options and we got $n$ elements so we got $2^{n}$ options correct ? Now, the moment we finish all the elements ($n$) for every new place we got $2$ options - $0$ or $1$ and we are left with $m-n$ places to fill so we got $2^{m-n}$ options, correct ? The final answer is : $$2^{m}\cdot2^{m-n}=2^{m}$$ Is this correct or I completely misunderstood some-thing?","['combinatorics', 'logic', 'functions']"
2399125,Continuous right derivative implies differentiability,"A book of mine says the following is true, and I am having some trouble proving it. (I've considered using the Lebesgue differentiation theorem and absolute continuity, as well as elementary analysis methods.) Let $f: [0, \infty) \rightarrow \mathbb{R}$ be continuous and have right derivatives at each point in the domain, with the right derivative function being continuous.  Then $f$ is differentiable.","['derivatives', 'real-analysis']"
2399143,"If trigonometric series is $0$ everywhere, then its coefficients are $0$","How to prove that if $\forall x \in \mathbb R, \sum_{n=-\infty}^\infty c_n e^{inx} = 0$, then $c_n=0$ for all $n$ ? I feel something could be done by integrating the series, but how to switch the sum and the integral then ? Nothing is assumed on the type of convergence or the regularity of $c_n$ (is it in $\ell^2$).","['real-analysis', 'fourier-series']"
2399154,Sum of the recursive series,"Let $\langle a_n \rangle$ be a recursive sequence given by $a_1>2$ and, $a_{n+1}=a_n^2-2$  for $n \in \mathbb N$ Show that $\sum_{n=1}^\infty \frac{1}{a_1a_2\cdots a_n} = \frac{a_1-\sqrt{a_1^2-4}}{2}$ I have reached this step: $\frac{1}{a_1a_2a_3\cdots a_n}=\frac{1}{2} (\frac{a_n}{a_1a_2\cdots a_n-1} -\frac{a_n-1}{a_1a_2\cdots a_n})$ But I am not able to obtain the final expression .Please help me to obtain it. Thanks for help in advance.","['real-analysis', 'sequences-and-series', 'analysis']"
2399193,An $F_{\sigma \delta}$-set as $\limsup_n F_n$ of closed sets.,"Let $\{C_{n,k}: n\ge 1, k\ge 1\}$ be a collection of closed sets in a metric space $X$. Is it true that there exists a sequence $(F_n)$ of closed sets such that
$$
C:=\bigcap_{k\ge 1}\bigcup_{n\ge 1}C_{n,k} = \{x \in X: x \in F_n \text{ for infinitely many }n\}?
$$ (I know that the answer is affirmative in the case that $C=A \setminus B$, where $A$ is a closed real interval and $B$ is a countable set, but the method does not extend to the whole class of $F_{\sigma \delta}$ sets.) I would add that, if the answer is affirmative in general, then it should be a known fact. However, I couldn't find it, e.g., in Kechris.","['descriptive-set-theory', 'general-topology', 'borel-sets']"
2399219,Proof of Jordan-Hölder for Modules carries over for Groups?,"The Book [Auslander, Reiten - Representation theory of Artin algebras] begins with the Jordan-Hölder theorem for modules of finite length over arbitrary rings. The proof is probably quite standard - here is the idea: Define the length of a module $M$ and the multiplicities of its composition factors as minimal length and minimal multiplicities over all (generalized) composition series. Then show that these functions are additive with respect to short exact sequences. The Jordan-Hölder theorem now follows easily by induction on the length of $M$: For $l(M) \leq 1$ the statement holds clearly. If $l(M) \geq 2$ there is a submodule $0 \lneq U \lneq M$. Any (generalized) composition series of $M$ splits into a (generalized) composition series of $U$ and of $M/U$. By induction hypothesis, those sequences satisfy the claim, i.e. they have length $l(U)$ and $l(M/U)$, respectively, and certain factor multiplicities defined by $U$ and $M/U$. By additivity of the length function and the multiplicity functions shown before, the claim also holds for the chosen composition series of $M$. I wonder whether this proof can be adopted verbatim to prove the Jordan-Hölder theorem for groups. At first sight, I see no reason why this cannot be done. However, I haven't seen this proof in any source concerning groups (usually, the Zassenhaus lemma is used instead).","['modules', 'abstract-algebra', 'noncommutative-algebra', 'ring-theory', 'group-theory']"
2399259,A closed form of $\sum_{n=1}^\infty\left[ H_n^2-\left(\ln n+\gamma+\frac1{2n} \right)^2\right]$,"The series of squares of harmonic numbers $$
\sum_{n=1}^\infty H_n^2 \tag1
$$ is divergent since $\displaystyle \lim_{n \to \infty} H_n^2 \ne 0$, actually from the classic result (6.3.18) ,
$$
H_n=\ln n+\gamma+\frac1{2n}+O\left(\frac1{n^2}\right),\qquad  \, n \to \infty,
$$ where $\gamma$ is the Euler-Mascheroni constant, one gets as $n \to \infty$, 
$$
H_n^2=\left(\ln n+\gamma+\frac1{2n} \right)^2+O\left(\frac{\ln n}{n^2}\right)\tag2
$$which tends to infinity. Then the following new series $$
\sum_{n=1}^\infty \color{grey}{\left[\color{#151515}{\: H_n^2-\left(\ln n+\gamma+\frac1{2n} \right)^2}\: \right]} \tag3
$$ may be seen as a sort of regularization of $(1)$. The series $(3)$ is absolutely convergent as one may directly deduce from the comparison test with a Bertrand series, using $(2)$. Question . What is a closed form of $(3)$? My intuition is that $(3)$ admits a closed form in terms of known constants (or here ).  I've used the advanced Inverse Symbolic Calculator ISC $2.0$ but it found nothing. My recent attempt, not yet fruitful, has been to convert $(3)$ into an integral representation, starting  with
$$
\begin{align}
-\int_0^1\!\left(\!\frac1{\ln x}+\frac1{1-x}-\frac12\!\right)\!x^{n-1}\:dx&=H_n-\ln n-\gamma-\frac1{2n},\quad n\ge1,
\end{align}
$$ and trying to employ similar techniques used here . Analogous considerations are here or here , one may also explore some variations of $(3)$, like
$$
\sum_{n=1}^\infty \color{grey}{\left[\color{#151515}{\: H_n^q-\left(\ln n+\gamma+\frac1{2n} \right)^q}\: \right]}, \,\sum_{n=1}^\infty (-1)^n \!\color{grey}{\left[\color{#151515}{\: H_n^q-\left(\ln n+\gamma+\frac1{2n} \right)^q}\: \right]}.
$$","['closed-form', 'integration', 'definite-integrals', 'harmonic-numbers', 'sequences-and-series']"
2399263,How do I write ${2}^{i}$ in polar form,I haven't been given any extra information so I'm not sure if this is already considered polar form. Here is how I went about it. ${2}^{i} = ({\frac{2}{e}}\cdot{e})^i = {({\frac{2}{e}})^i}\cdot{e^i}$ $\implies r = {({\frac{2}{e}})^i}$ and  $\phi = 1$ Giving the polar form  as ${({\frac{2}{e}})^i} \cdot (\cos{1} + i\sin{1})$ My intuition tells me this isn't right. I'd appreciate any pointers here thanks.,"['complex-analysis', 'complex-numbers']"
2399315,Language formed by adding symbols to start or end turn by turn,"A word is formed by starting with ""$0$"" and then adding ""$1$"" either to the start or to the end i.e we can form ""$10$"" or ""$01$"". In the next step we add a ""$0$"", again either to the start or to the end. This is continued, alternating the symbol we add. Denote by  $L_n$ the language containing all words of length $n$ that can be formed like this. We can define this recursively: $$L_0 = \{""""\}$$
$$L_n = \{c+w \space | \space w\in L_{n-1}\} \cup \{ w+c \space | \space w\in L_{n-1} \},$$
$$ \text{where } c=""0"" \text{ if } n \text{ is odd and }  c=""1"" \text{ if } n \text{ is even }$$
$$\text{and + means the concatenation of strings.}$$ We get: $L_0 = [""""]$ (the empty string) $L_1 = [""0""]$ $L_2 = [""10"", ""01""]$ $L_3 = [""010"", ""100"", ""001""]$ $L_4 = [""1010"", ""0101"", ""1100"", ""1001"", ""0011""]$ $L_5 = [""01010"", ""10100"", ""00101"", ""01100"", ""11000"", ""01001"", ""10010"", ""00011"", ""00110""]$ $L_6 = [""101010"", ""010101"", ""110100"", ""101001"", ""100101"", ""001011"", ""101100"", ""011001"", ""111000"", ""110001"", ""010011"", ""110010"", ""100011"", ""000111"", ""100110"", ""001101""]$ Denote $a_n = \# L_n$. These start out as 
$$[1, 1, 2, 3, 5, 9, 16, 29, 52, 94, 170, 308, 560, 1018, 1856, 3383, 6177, 11279, 20614, 37685, 68926, 126112, 230802, 422557, 773730, 1417222, \dots]$$ Questions: Is there a context free grammar for the language $L=\bigcup L_n$? Is there a formula for $a_n$, or what is their generating function? I noticed that $\frac{a_n}{a_{n-1}}$ seems to approach something like $1.832...$. Is this true and what is this constant? It's like the factor ""how many different words"" each word from $L_{n-1}$ produces to $L_n$ (each produces two, but some of these are same as others).","['combinatorics', 'formal-languages', 'sequences-and-series']"
2399321,Least Squares with Euclidean ($ {L}_{2} $) Norm Constraint,"Suppose I have set of samples $(x_i,y_i), 1 \leq i \leq n$. I am interested in solving the following optimization problem:
$$
\min \sum_{i=1}^n (y_i-a^\top x_i)^2, \quad \text{s.t } \|a\|_{2} = 1.
$$ If we assume that $\sum_i x_i x_i^\top$ is invertible, I am wondering if one can prove that the solution to the above optimization problem is 
$$
a^\ast=\frac{\left(\sum_i x_i x_i^\top \right)^{-1} (\sum_i x_i y_i)}{\|\left(\sum_i x_i x_i^\top \right)^{-1} (\sum_i x_i y_i)\|}
$$
Does the above solution still hold if we relax the constraint to be $\|a\|_{2} \leq 1$? Assuming that the above solution does not hold, in this inequality constrained case, does running a projected gradient descent guaranteed to find the true minimum since the problem is convex?","['nonlinear-optimization', 'least-squares', 'optimization', 'convex-optimization', 'linear-algebra']"
2399332,Pull-back of a differential : I get confused with the variables,"I edited again my message with the remarks done in the comments. I have a 2-form : $$\alpha=\alpha_{\mu \nu} dx^\mu \wedge dx^\nu$$ I want to compute the pull back $F^{*}(d \alpha)$ to show that : $F^{*}(d \alpha)=dF^{*}( \alpha)$ But I make a mistake somewhere because I can't prove the equality. $$ F : y \mapsto x $$ So when I write $x^\mu$ I have in fact a dependance $x^\mu(y^\nu)$. $$d \alpha=d \alpha_{\mu \nu} \wedge dx^\mu \wedge dx^\nu 
\\= \frac{\partial \alpha_{\mu \nu}}{\partial x^\epsilon} dx^\epsilon \wedge dx^\mu \wedge dx^\nu$$ $$F^{*}(d \alpha)=F^{*}(\frac{\partial \alpha_{\mu \nu}}{\partial x^\epsilon}) F^{*}(dx^\epsilon) \wedge F^{*}(dx^\mu)  \wedge F^{*}(dx^\nu)$$ I have : $$ F^{*}(dx^\mu) = \frac{\partial x^\mu}{\partial y^i} dy^i$$ and $$F^{*}(\frac{\partial \alpha_{\mu \nu}(x)}{\partial x^\epsilon})=\frac{\partial \alpha_{\mu \nu}(x(y))}{\partial x^\epsilon(y)}$$ And finally, I get : $$F^{*}(d \alpha)=\frac{\partial \alpha_{\mu \nu}(x(y))}{\partial x^\epsilon(y)} \frac{\partial x^\epsilon}{\partial y^i}\frac{\partial x^\mu}{\partial y^j}\frac{\partial x^\nu}{\partial y^k} dy^i \wedge dy^j \wedge dy^k$$ On the other hand, I have : $$F^{*}(\alpha)=F^{*}(\alpha_{\mu \nu}(x)) F^{*}(dx^\mu)  \wedge F^{*}(dx^\nu)\\
=\alpha_{\mu \nu}(x(y)) \frac{\partial x^\mu}{\partial y^i} \frac{\partial x^\nu}{\partial y^j} dy^i \wedge dy^j$$ But here there is a problem when I differentiate : $$dF^{*}(\alpha)=d(\alpha_{\mu \nu}(x(y)) \frac{\partial x^\mu}{\partial y^i} \frac{\partial x^\nu}{\partial y^j}) \wedge dy^i \wedge dy^j$$ Indeed I will have extra derivative term in $\frac{\partial^2 x^\mu}{\partial y^i \partial y^l} $ when I differentiate. And I don't have these terms in $F^{*}(d \alpha)$. So where is my mistake ?? [edit] According to the answer below, I see that my misunderstanding is in the fact that : $$dF^{*}(\alpha)=d(\alpha_{\mu \nu}(x(y))) \wedge (\frac{\partial x^\mu}{\partial y^i}) dy^i \wedge ( \frac{\partial x^\nu}{\partial y^j} ) dy^j$$ We don't differentiate the terms $\frac{\partial x^\nu}{\partial y^j}$. But I don't understand why as the definition of the exterior derivative is the following : With : $$\alpha=\alpha_\mu dx^{\mu}$$ We have by definition : $$ d\alpha=d\alpha_\mu \wedge dx^{\mu}$$ Thus in my example it should be : $$dF^{*}(\alpha)=d(\alpha_{\mu \nu}(x(y)) \frac{\partial x^\mu}{\partial y^i}  \frac{\partial x^\nu}{\partial y^j} ) \wedge  dy^i \wedge  dy^j$$ And not : $$dF^{*}(\alpha)=d(\alpha_{\mu \nu}(x(y)))  \frac{\partial x^\mu}{\partial y^i}  \frac{\partial x^\nu}{\partial y^j}  \wedge  dy^i \wedge  dy^j$$ ie the differential applies to all the terms including the chain derivative and not only on $\alpha_\mu$. Could someone clarify this for me (or at least give me an exact definition of the exterior derivative ?)",['differential-geometry']
2399333,The Radon Nikodym derivative is non-zero almost everywhere,"Let $\mu$ and $\nu$ be finite positive measures on a measure space and assume that $\nu$ is absolutely continuous with respect to $\mu$ . That is, for every measurable set $E$ , if $\mu(E) = 0$ , then $\nu(E) = 0$ . Via the Radon-Nikodym Theorem there must be a measurable function $h$ such that for all measurable sets $A$ we have $\nu(A) = \int_A h \text{ }d\mu$ . This function $h$ is called the Radon-Nikodym derivative of $\nu$ with respect to $\mu$ and is denoted by $\frac{d\nu}{d\mu}$ . Two questions: With respect to the measure $\nu$ , is $\frac{d\nu}{d\mu}$ almost everywhere non-zero? With respect to the measure $\mu$ , is $\frac{d\nu}{d\mu}$ almost everywhere non-zero?",['measure-theory']
2399350,"$r=\pm1$ are the only rationals with $\,r+1/r\in \Bbb Z$ (sum with its reciprocal is an integer)","Can sum of a rational number and its reciprocal be an integer? My brother asked me this question and I was unable to answer it. The only trivial solutions which I could think of are $1$ and $-1$. As to what I tried, I am afraid not much. I have never tried to solve such a question, and if someone could point me in the right direction, maybe I could complete it on my own. Please don't misunderstand my question. I am looking for a rational number $r$ where $r + \frac{1}{r}$ is an integer.","['algebra-precalculus', 'elementary-number-theory']"
2399358,locally finite closed coverings are fundamental,"First of all the definitions, since i'm not english and I don't know if it's clear what I'm talking about. Let's take a topological space $X$ A covering is locally finite if for every $x \in X$, there is a neighbourhood $I_x$ of $x$ that intersects only a finite amount of sets of the covering. The situation I am proposing is about a locally finite covering whose elements are closed sets. A covering is called fundamental if for every set $\Omega$ in $X$, we have that $\Omega$ is open iff $\Omega \cap A_i$ is open in $A_i$ for every $i\in I$, where $\{A_i \}_{i\in I}$ is the fundamental covering. I think this theorem is quite simple, because it was proven in a first course of topology. To be precise, it was first proven that every finite closed covering (that is a finite covering composed of closed sets) is fundamental, and then this result was used to prove this stronger version (every finite closed covering is locally finite). The question is: how can I use the fact that every finite closed covering is fundamental to prove that every locally finite closed covering is fundamental as well? The problem is that I don't get the proof, cause when he says like ""this is open"" and ""this is closed"" I can't understand where he is working, and how I can deduce that if a set is (for example) open in a subset, then it is open in the whole topological space. I know how to conclude that if the subspace is open itself, but I can't see how to apply that here",['general-topology']
2399368,Suppose $A \cap C \subseteq B \cap C$ and $A \cup C\subseteq B \cup C$. Prove that $A \subseteq B$,"This is Velleman's exercise 3.5.4: Suppose $A \cap C \subseteq B \cap C$ and $A \cup C\subseteq  B \cup C$. Prove that $A \subseteq B$ This is the proof given by the book (which I understand completely): Proof. Suppose x ∈ A. We now consider two cases: Case 1. $x \in C$. Then $x ∈ A \cap C$, so since $A \cap C\subseteq B \cap C, x \in B \cap C$,
and therefore $x \in B$. Case 2. $x \notin C$. Since $x \in A, x \in A \cup C$, so since $A \cup C\subseteq B \cup C$,
$x \in B \cup C$. But $x \notin C$, so we must have $x \in B$. Thus, $x \in B$, and since x was arbitrary, $A \subseteq B$. I was wondering if one could write a proof like this one in below: Proof. Let x be an arbitrary element of A. Then by $A \cup C \subseteq B \cup C$, we have either $x \in B$ or $x \in C$. Now we consider these two cases: Case 1. x is an element of B. Case 2. x is an element of C. Since in one of the cases $x \in B$ and since x was arbitrary, $A \subseteq B$.","['logic', 'elementary-set-theory', 'proof-verification']"
2399381,Solving an infinite product of consecutive square roots,"Given $a$ and $b$ calculate $ab$
$$a=\sqrt{7\sqrt{2\sqrt{7\sqrt{2\sqrt{...}}}}}$$
$$b=\sqrt{2\sqrt{7\sqrt{2\sqrt{7\sqrt{...}}}}}$$ I simplified the terms and further obtained that $ab$ is equal to:
$$ab=2^{\frac{1}{2}+\frac{1}{4}+\frac{1}{8}+\frac{1}{16}...}\cdot7^{\frac{1}{2}+\frac{1}{4}+\frac{1}{8}+\frac{1}{16}+...}$$ How can I get a finite value?",['sequences-and-series']
2399407,Show that the integral is divergent $\int_0^\infty\frac{\ dx}{1+x^2\sin^2x}$,"Show that the integral is divergent
   $$\int_0^\infty\frac{\ dx}{1+x^2\sin^2x}$$ It has no point of discontinuity in range of integration. Also, I have found $\int_0^\infty\frac{\ dx}{1+x^2\sin^2x}>\frac{\pi}{2}$, but that seems to be of no consequence. I don't how to move ahead with this.","['improper-integrals', 'integration', 'trigonometry', 'convergence-divergence']"
2399409,"Find the maximum value of $a^2b^3$ where $a,b$ are positive real numbers satisfying $a+b=10$ [duplicate]","This question already has answers here : Find the greatest value of $a^2\cdot b^3$ where $a+b=10$ (4 answers) Closed 6 years ago . Find the greatest value of $a^2b^3$ where $a,b$ are positive real numbers satisfying $a+b=10$.Determine the values of $a,b$ for which the greatest value is attained. It is my question.I continuously tried to use weighted A.M-G.M. inequality, but unfortunately I found no way.I don't think it can be done using Tchebycheff's inequality or Cauchy-Schwartz's theorem. Please give me any hint for doing that.I also failed to solve another similar problem (but reversed. ""Find $\min(3x+2y)$, where $x^2y^3$=48). If possible then please give me hint in that also. Thank you.","['radicals', 'inequality', 'a.m.-g.m.-inequality', 'algebra-precalculus', 'maxima-minima']"
2399412,Computing the twist of $y^2=x^3+x$ and usability of twists by GLV/GLS method,"I'm currently on KSS-16 curves, which are given by $\newcommand{\F}{\mathbb F}E(\F_p):\ y^2=x^3+x$ . In an actual paper for updating the key sizes, there is a twist of $E$ defined, given by $E'(\F_{p^2}):\ y^2=x^3+2^{1/4}x$ . [4] I would like to understand how they come to that twist, and how to define the homomorphism or isomorphism $E\to E'$ . My attempt is the following: I thought about using $\F_{p^{16}}\cong \F_{p^2}[x]/(x^8-2^{1/2})$ . Choosing $u\in \F_{p^{16}}$ such that $u^8=2^{1/2}$ leads to: $u=2^{1/16}$ . Now I don't know how to get further or what to aim. There is a small hole in my notes and I can't find anything to fit. Details [1] solves the primary question, where [2] throws up an extended question: Are twists usable for speeding up by the GLV/GLS Method? Required stuff We could consider the affine equation for an elliptic curve and use proposition X.5.4 from [3] or the projective way, given in [1] on page 138 ff. and use a dehomogenization. The problem I've met is, that Silverman only define twists of degree 2,3,4 and 6. But this time, this is a twist of degree eight. (Octic twist?) Let me repeat the given stuff first: Preliminaries Elliptic Curve $E(\F_p):\ y^2=x^3+x$ Prime $p\equiv \pm 3\bmod 8$ Twist $E'(\F_{p^2}):\ y^2=x^3+2^{1/4}x$ Embedding degree $k=16$ Discriminant $D=1$ $j$ -Invariant: $j_E=12^3$ Definition 1: Degree of a Twist Let $E(\F_p)$ be an elliptic curve. The degree of its twist $E'(\F_{p^{k/d}})$ is defined by the integer $d$ . Proposition 2: [3] Prop. X.5.4 Let $char(\F_p)>3$ and let $n=\begin{cases} 2 & if j_E\neq 0,12^3\\ 4 & j_E=12^3\\ 6 & j_E=0.\end{cases}$ Then the twists of E are canonically isomorphic over the algebraic closure of $\F_p$ . More precisely, in our situation of $E$ , we have the twist $E'_d$ corresponding to $m\in\F_p^*$ given by: (i) $E'_m:\ y^2=x^3+m^2Ax+m^3B$ if $n=2$ (ii) $E_m:\ y^2=x^3+mAx$ if $n=4$ and (iii) $E_m:\ y^2=x^3+mB$ if $n=6$ . Proposition: Projective version [1] Let $E:\ Y^2Z=X^3+AXZ^2+BZ^3$ with $A,B\in\F_p$ . For any $d\in\F_p^*$ all twists of $E$ corresponding to $d$ are given by: $E_d:\ dY^2Z=X^3+AXZ^2+BZ^3$ or by change of variables $dZ\leftrightarrow Z$ $E_d:\ Y^2=X^3 + \frac{A}{d^2}XZ^2 + \frac{B}{d^3}Z^3$ which becomes isomorphic to $E$ over any field, where $d$ is a square. Application We have $E:\ y^2=x^3+x$ , that means $A=1, B=0$ . Furthermore, the Twist, we want to reach is given by $E':\ y^2=x^3+2^{1/4}x$ . Therefore $m=2^{1/8}$ and $d=(1/2)^{1/8}$ . The missing degree eight twist is the only obstacle right now. But, if we consider $\F_{p^{16}}\cong \F_{p^2}[t]/(t^8-2)$ , we would get the equation $t^8=2$ , where $t\in\F_{p^{16}}$ and 2 should be not a square in $\F_{p^2}$ , but indeed $\sqrt{2}\in\F_{p^2}$ , since $2\in\F_p$ is a non-square if $p\equiv \pm 3 \bmod 8$ and we have $\F_{p^{16}} \cong \F_p[X]/(X^{16}-2)$ . Missing Answere Is this an octic twist as given in [4, Section 6.3]? How to compute it then? I thought about $t^8=\sqrt{2}$ which would lead to $t=2^{1/16}$ and, therefore, $E_t:\ Y^2=X^3 + 2^{1/8}XZ^2$ , what is not $2^{1/4}$ .
If this is a typo and, therefore, a quartic twist, it is solved then. References [1] http://www.jmilne.org/math/Books/ectext5.pdf p.138 [2] https://eprint.iacr.org/2008/194.pdf [3] https://link.springer.com/book/10.1007%2F978-0-387-09494-6 [4] https://eprint.iacr.org/2017/334","['number-theory', 'elliptic-curves', 'commutative-algebra']"
2399413,Let $a_n$ be a sequence of real numbers such that $\lim(a_n\sum_{k = 1}^n a_k^2) = 1$,Let $a_n$ be a sequence of real numbers such that $\lim(a_n\sum_{k = 1}^n a_k^2) = 1$ . Prove that $\lim((3n)^{\frac{1}{3}}a_n)=1$ I'm more concerned with how I can derive the prove of this question,"['real-analysis', 'calculus']"
2399418,Is conditional probability transitive?,"Is conditional probability ""transitive"" (or how else this is called - please, explicate) in the meaning that $P(a \mid c)=P(a \mid b)P(b \mid c)$ ? Intuitively this seems so, but could you comment/proove on how to understand this (or refute)?","['statistics', 'probability', 'proof-explanation']"
2399425,Jugs of Water Puzzle: Minimum Number of Operations,"PUZZLE. Given two water jugs with capacities $a, b \in \mathbb{N}$ , the goal is to measure exactly $c$ units of water only performing the following operations: fill one of the jugs to it's capacity limit, empty one of the jugs, fill water from one jug to the other until the first jug is empty or the second jug is full. This puzzle is well-known and the special case $a = 5, b = 3, c = 4$ was originally featured in the movie Die Hard 3:  With a Vengeance . It can be easily solved by brute-force in a few steps. We call a triplet $(a, b, c)$ an instance . A sequence of operations as described above is called a solution , if after performing all these operations in order one of the jugs contains exactly $c$ units water. If there is no solution requiring strictly fewer operations, a solution is called optimal . Naturally, there are two questions in this puzzles context: Existence : Given an instance $(a, b, c)$ , is it possible to measure exactly $c$ units of water using a sequence of the operations described above? [solved below] Optimality : Find an optimal solution. How? Both problems can be solved algorithmically by BFS. There are at $a + 1$ possible amounts the first jug can contain and $b + 1$ amounts for the second jug. Hence, we have $(a + 1)(b + 1) \in \mathcal{O}(ab)$ possible states. When considering large capacities and instances with only quite long solutions, space and time complexity issues arise. Thus, I search for a more efficient approach. It is clear that the amount of water in each jug is always an integer linear combination $s \cdot a + t \cdot b$ of the capacities $a$ and $b$ . It can also be shown that every such integer linear combination can be reached (up to the exception of exceeding capacity limits, let's assume $c \le \max(a, b)$ and $a \le b$ wlog). By Bezout's Lemma, if every linear combination is reachable, we are able to measure $c$ units of water iff $gcd(a, b) \mid c$ .
To do so, we use the following algorithm: fill the first jug transfer from first jug to second jug if one of the jugs contains exactly $c$ units water: terminate, solution found, else continue with step 4. if the second jug is full: empty it and transfer from second to first jug go to step 1 We execute this algorithm twice: In the first run, 'first jug' means the jug with capacity $a$ . In the second run, 'first jug' means the jug with capacity $b$ . After both runs, we take the solution requiring the minimum number of operations. EXAMPLE . Let's work through the instance $(5, 3, 4)$ from the movie. The algorithm yields: 1st run: $(0, 0) \rightarrow_1 (5, 0) \rightarrow_2 (2, 3) \rightarrow_4 (2, 0) \rightarrow_4 (0, 2) \rightarrow_1 (5, 2) \rightarrow_2 (4, 3)$ 2nd run: $(0, 0) \rightarrow_1 (0, 3) \rightarrow_2 (3, 0) \rightarrow_1 (3, 3) \rightarrow_2 (5, 1) \rightarrow_4 (0, 1) \rightarrow_4 (1, 0) \rightarrow_1 (1, 3) \rightarrow_2 (4, 0)$ Note that each pair $(p, q)$ means that the jug with capacity $a = 5$ contains $p$ units of water and jug with capacity $b = 3$ contains $q$ units. An arrow $\rightarrow_k$ denotes a transition (step $k$ ) as given by the algorithm. QUESTION. Is this algorithm always optimal and why? (Proof) Algorithmic approaches (I know, it may overlap with computer science) faster than BFS are also highly appreciated. May we use the Extended Euclidean algorithm in some way?","['algorithms', 'puzzle', 'combinatorics', 'modular-arithmetic', 'elementary-number-theory']"
2399464,Selecting the best statistical analysis,"I'm going to begin an experiment about drying leaves. I want to learn about how some special kind of leaves are going to dry themselves in 2 different situation. A group of them will stay in a high density, and the another group I will spread out in a bigger area (for example, 1 m2 for the first, and 3 m2 for the second). Of course, I will repeat this experiment several times. In the end, I will get: Individual weight of the leaves (selecting samples) in the beginning Individual weight along 4 days Individual weight in the end Nutritional composition in the start and in the end I am remembering my knowledge in stats and R, but I am still lost. My question is, which is the best comparison method to analyse this data? I want to know: How the humidity content change along the days To dry this kind of leaves, which drying area is better? Is it statistical significance between both method about losing water and nutrient content? Kind regards!
Alex.",['statistics']
2399478,An infinite sequence of independent events with constant probability is uncountable,"Let $(\Omega, M, P)$ be a probability measure space and assume there is an infinite sequence $A_1, A_2, \ldots$ of elements of $M$ which are all independent from each other and such that $P(A_i) = \frac{1}{2}$ for all $i \in \mathbb{N}$. How does one prove the claim that $\Omega$ is uncountable?","['probability-theory', 'measure-theory']"
2399480,Question on Euclidean norm of a non-square matrix,"Let $\;f:\mathbb R^n \rightarrow \mathbb R^m\;$ and consider the
  matrix $\; \nabla \cdot f=\begin{pmatrix}
                           \frac{\partial f_1}{\partial x_1} \dots \frac{\partial f_1}{\partial x_n} \\ \dots \\ \frac{\partial
 f_m}{\partial x_1} \dots \frac{\partial f_m}{\partial x_n}\\ 
                            \end{pmatrix}\;$. I want to compute this: $\;\frac{1}{2} {\vert \nabla f \vert }^2\;$
  where $\;\vert \cdot \vert\;$ is the Euclidean norm of the matrix. NOTE: $\;n\;$ is not necessary equal to $\;m\;$ Searching on google about ""Euclidean norm of a non-square matrix"", all the results I found, were about the Frobenius norm. So I thought it would be a good idea to compute the Frobenious norm of $\;\nabla f  \;$ . But then, I came across with this post What is the difference between the Frobenius norm and the 2-norm of a matrix? which confused me completely. I haven't had any experience in norms of matrices until I was assigned to compute the above one. This is why I apologize in advance if my questions below are quite trivial or silly. What is the Euclidean norm of the above matrix? How should I proceed in order to compute $\;\frac{1}{2} {\vert \nabla f \vert }^2\;$ ? Any help or hints would be valuable. Thanks in advance!","['matrices', 'normed-spaces', 'multivariable-calculus', 'linear-algebra']"
2399506,How do I make my Eggbot designs look right on an egg? (Or: how to transform projected plane so shapes look good on a spheroid?),"I think my question, in short, is the following: Imagine an spheroid, so with two diameters, and a plane ""wrapped"" around the spheroid using equirectangular projection. Let the two diameters be equal (so, a sphere), and then draw a circle on the spheroid. Look at the circle from above - it looks circular. If the two diameters are not equal, how do I need to transform the plane such that the circle looks correct again, as best as possible? Here is more detail on the situation, so you can tell if I'm actually asking the right question :-) I also may have misused maths (I'm British, so ""maths"") terminology - please tell me if so. I have an Eggbot . It prints (or rather, plots) flat designs on spherical objects, and also on eggs - i.e. ellipsoids. If you print a design with a circle in it on a spherical object, it looks like a circle. If you print it on an egg, it looks distorted. (Due to the design of the Eggbot, it assumes ellipsoid objects like eggs are spheroids rather than oblate spheroids, and we can do that for this question.) To compensate for this, it seems like the Eggbot community has a rule of thumb that you stretch designs horizontally by 150% when printing on eggs. But eggs vary, or at least the ones I have do - some are quite round, some are long and thin. So I'd like a more precise answer to the question: how much do I have to stretch my design to get it to look as right as possible on a particular egg? Eggbot designs are done in Inkscape, using 3200 px wide x 800 px high canvases, and are plotted at 1px per motor stepping in both directions. See the Eggbot coordinate system for existing documentation. The Eggbot takes designs and plots them using an equirectangular projection - that link has a good picture of what a circle looks like drawn on a sphere and on an egg, and the poor look of the sphere on the egg is the ""problem"" I want to solve a bit more rigorously. What I'm hoping for is a formula which takes two inputs - the two diameters of the egg - and outputs a percentage between 100% and 200% which is the y-axis scaling factor that I need to use to make the design look best on that particular egg. Please let me know if more info is necessary. I'm new here, so apologies for any lapses in etiquette, and thank you for your consideration :-) Update : Thanks for the initial feedback. Yes, the principal axes of the ellipsoid are the coordinate axes. The Eggbot spins the egg around its long axis, and then moves a pen up and down the length of the same axis, thereby giving access to most points on the egg. The circle I want to look good is a circle centred in the middle of the long axis, with a radius such that the whole circle is visible from one side. This link has a good picture of what I mean. I think we could start with ""looking like a circle"" meaning lying on a plane crossing the ellipsoid, yes.","['spheres', 'projection', 'differential-geometry', 'geometry']"
2399512,Measure of inverse image of a monotone function is continuous?,"I'm studying for my analysis qualifying exam, and came across this question: Let $f : [0,1] \rightarrow [0,1]$ be a function that is continuous and nondecreasing with $f(0) = 0$ and $f(1) = 1$ and define $\phi(t) = \lambda(\{x \in [0,1] : f(x) \le t\})$ where $\lambda$ is lebesgue measure. Is $\phi(t)$ necessarily continuous from the left? Is $\phi(t)$ necessarily continuous from the right? Do the answer to parts 1 or 2 change if $f$ is strictly increasing? So far I have that $\phi(t)$ is not necessarily continuous from the left because if $f(x)$ is the Cantor function then $\lim_{t \rightarrow \frac 12^-} \phi(t) = \lambda(\{x \in [0,1] : f(x) < \frac 12\}) = \lambda([0,\frac 13)) = \frac 13,$ but $\phi(\frac 12) = \lambda([0,\frac 23]) = \frac 23$. For proving that $\phi$ is continuous from the right, I have that $$
\lim_{t \rightarrow y^+} \phi(t) = \lim_{n \rightarrow \infty} \phi\left(y + \frac 1n\right) =\lim_{n \rightarrow \infty} \lambda\left(\left\{x \in [0,1] : f(x) \le y + \frac 1n\right\}\right) = \lambda\left(\bigcap_{n=1}^\infty\left\{x \in [0,1] : f(x) \le y + \frac 1n\right\}\right) = \lambda\left(\left\{x \in [0,1] : f(x) \le y\right\}\right) = \phi(y),
$$ where we can use $\lambda\left(\bigcap_{n=1}^\infty\left\{x \in [0,1] : f(x) \le y + \frac 1n\right\}\right) = \lambda\left(\left\{x \in [0,1] : f(x) \le y\right\}\right)$ because it is a monotone decreasing sequence of sets from the monotonicity of $f$.  I think there might be something missing something because I didn't use the continuity of $f$ anywhere. If $f$ is strictly increasing instead, I think that $\phi$ is continuous from the left as well but I'm not sure how to prove it.  I'm thinking it would be similar to the proof that it's continuous from the right, but then I don't know where you would apply that $f$ is strictly increasing or what prevents you from applying it when $f$ is just monotone non-decreasing.","['continuity', 'real-analysis', 'lebesgue-measure', 'measure-theory']"
2399518,When is interchange of quantifiers allowed? Ex: $\forall w \in \bigcup A_n$,"There is a myriad of question for the interchange of different quantifiers, mainly between $\exists$ and $\forall$. I'm interested in knowing when both can be interchanged. The motivation came from this: $\forall w \in \bigcup_n A_n \Leftrightarrow\forall_{n,w} w \in A_n$, when $w \in \bigcup_n A_n \Leftrightarrow\exists_{n} w \in A_n$. Any help would be appreciated.","['logic', 'elementary-set-theory']"
2399533,Prove that if $A \bigtriangleup B\subseteq A$ then $B \subseteq A.$,"This is Velleman's exercise 3.5.5 ( And NO! not a duplicate of Prove that if $A \mathop \triangle B \subseteq A$ then $B\subseteq A$ ! My question is different ): Prove that if $A \bigtriangleup B\subseteq A$ then $B \subseteq A.$ Since in the definition of a symmetric difference we have disjunction, shouldn't we prove this statement by cases? So here's my proof of it: Proof. Let $x$ be an arbitrary element of $B$ . Now suppose $x \not\in A$ . From $x \in B$ and $x \not\in A$ , we get $x \in (B\setminus A)$ . We now consider two cases. Case 1. $x \in (A\setminus B)$ . Then by $A \bigtriangleup B \subseteq A$ , we have $x \in A$ which is a contradiction. Case 2. $x \not\in (A\setminus B)$ . Since $x \in (B\setminus A)$ and $A \bigtriangleup B \subseteq A$ , $x \in A$ which is also a contradiction. Since by both cases we reached a contradiction then $x \in A$ and since $x$ was arbitrary, $B \subseteq A$ . In other words, in proof by cases (when we have disjunction in the given/hypotheses/premises) when we also use a contradiction, do we need to reach a contradiction for all the cases or just one will be enough? Thanks in advance.","['logic', 'elementary-set-theory', 'proof-verification']"
2399561,I need help with this conditional probability question,"This question was provided in tutorial session: Your friends Alice and Bob are both talented test-takers, but they can sometimes
get distracted by their philosophies. Alice is an optimist, and she always wants to believe a statement is true. When given a true/false statement that is true, Alice gets the correct answer with probability 80%, but for false statements, she gets the correct answer only 35% of the time. On the other hand, Bob is a skeptic, and he tends to doubt the truth of statements. If a statement is true, he will get the correct answer with probability 15%, but if a statement is false, he will get the correct answer 85% of the time. (a) Your teacher receives a bonus if all of her students achieve at least 50%, so she wants to design a true/false test on which both Alice and Bob will expect to receive at least this score. What percentage of statements on the test would you set to true in order to achieve this? (b) Your teacher is now being bribed to make Alice's score as high as possible. However, she does not want Bob to fail the class. What percentage of statements should be true in order to maximize Alice's expected score while keeping Bob's expected score no less than 43%? (c) You are now taking a true/false test with Alice and Bob. You cannot read the
language in which the test is written, but you can see both Alice's and Bob's answers for each question; Alice's answers are independent of Bob's. You also
know that each statement on the test is true with probability 50%. How should you fill out your answer sheet to achieve the highest possible expected score? What will your expected score be? (d) Now imagine that you need to create an answer key for the test. You can look at the answer sheets for as many optimists (people who answer true questions correctly with probability 75% and false questions correctly with probability 40%) and pessimists (people who answer true questions correctly with probability 40% and false questions correctly with probability 90%) as you like. The students mistakes are independent of each other. You know that each statement
on the test is true with probability 30%. How would you create an answer key that is at least 77% correct in expectation? My approach:: Let C be the event that answer is correct and S be the event that the statement is true. Then for Alice:  P(C|S) = 0.8 and P(C|S') = 0.35 and for Bob: P(C|S) = 0.15 and P(C|S') = 0.85 (a) We need to make P(C) >= 0.5 for both of them because both need to achieve at least 50%. Suppose P(S) = x, P(S') = 1-x then for Alice: P(C) = P(C|S)P(S) + P(C|S')P(S') = 0.8x + (1-x)*0.35 >=0.5 Solving we get x >= 0.33 Similarly for Bob we get x <= 0.43 So according to the question, % of questions set to true should be between 33-43% (b) Since Bob's score needs to be at least 43%, we have for Bob : P(C) >= 0.43 P(C) = P(C|S)P(S) + P(C|S')P(S') = 0.15x + (1-x)*0.85 >=0.43 x<=0.7 So 70% statements should be true. I am not sure about this. (c) I have no clue about this one. (d) For Optimists:  P(C|S) = 0.75 and P(C|S') = 0.4 and for pessimists: P(C|S) = 0.4 and P(C|S') = 0.9 P(S) = 0.3(given) Optimists are expected to answer P(C) = 0.3*0.75+0.7*0.4=0.505 i.e 50.5% times correctly and pessimists are expected to answer P(C) = 0.3*0.4+0.7*0.9=0.75 i.e 75% times correctly. How can I achieve now at least 77% correct answer key because copying pessimists' answer only gives 75%? Is my method correct? How to approach these kind of questions?","['bayes-theorem', 'probability-theory', 'probability', 'discrete-mathematics']"
2399562,What is the intuition behind the formula $\frac{1}{1+f(x)}$,"What is the intuition of $\frac{1}{1+f(x)}$ ?
I often see formulas of such style in statistics.
For example sigmoid function is of form $\frac{1}{1+e^{-x}}$. Why is $\frac{1}{1+f(x)}$ used frequently? What is its intuition?",['statistics']
2399582,derivative of multiplication of three matrices with a matrix,"In short, my problem is to compute $\frac{d(X^tAX)}{dX}$; where both $A$ and $X$ are matrices. I have to maximize a negative-log likelihood function $L$ $$L = \frac{1}{2}\ln(|\Sigma|)+\frac{1}{2}\varepsilon^t\Sigma^{-1}\varepsilon;$$ where $\Sigma$ is the covariance matrix, $\varepsilon$ is a column vector of residuals (in my case) and $t$ denotes the transponse. The probelm is that $\Sigma$ is a function of other matrices $$\Sigma = J^tCJ$$ where, both $J$ and $C$ are matrices. The matrix $J$ is again a function of a vector $\lambda$. I have to maximize the function $L$ w.r.t. vector $\lambda$. I tried chain rule to solve this problem as follows $$\frac{dL}{d\lambda}=0\implies\frac{dJ}{d\lambda}\frac{d\Sigma}{dJ}\frac{dL}{d\Sigma}=0.$$ In the above equation, $\frac{dJ}{d\lambda}$ and $\frac{d\Sigma}{dJ}$ becomes a tensor. So, I am no longer able to write these quantities on paper. Also, taking derivative of $L$ w.r.t. an individual element of $ \lambda$ does not solve the problem. There are few online resources which suggest using $vec$ operator to deal with tensors; but they heavily use Kronecker product etc. which I have not been able to understand very well, because most of the online material is very opaque. Can someone please point me to the solution? If someone can refer a good text dealing with a similar problem, that would be great.","['derivatives', 'matrix-calculus']"
2399591,Expectation of Maximum Frequency,I saw this question in a blog but do not know how to solve it. Question: There are K balls in a sack numbered 1 to K. Bob chooses a ball at random and notes down its number and then puts it back in sack. He does this process for N times. What is the expected value of the frequency of the most frequent element?,"['expectation', 'probability', 'puzzle', 'combinatorics', 'random-variables']"
2399594,An inverse question inspired by Cauchy–Schwarz inequality [duplicate],"This question already has answers here : If $(a_n)$ is such that $\sum_{n=1}^\infty a_nb_n$ converges for every $b\in\ell_2$, then $a\in\ell_2$ (2 answers) Closed 6 years ago . I have the following question, whose inverse question can be done by the well-known Cauchy–Schwarz inequality. But I do not know how to solve this question: Suppose that $\{a_n\}_{n=1}^\infty$ is a sequence of real numbers such that
\begin{equation}
\sum_{n=1}^\infty a_n b_n \quad \text{is a convergent series whenever}\quad\sum_{n=1}^\infty b_n^2<\infty.
\end{equation}
Show that $\sum_{n=1}^\infty a_n^2<\infty$.","['real-analysis', 'inequality', 'sequences-and-series']"
2399599,The eigenfunctions of $\Delta \colon H_0^1(\Omega)\cap H^2(\Omega) \to L^2(\Omega)$ form an orthonormal basis?,"Let $\Omega$ be a bounded open subset of $\mathbb{R}^n$ with smooth boundary. Consider the Dirichlet Laplace operator
$$\begin{cases}
D(A)=H^1_0(\Omega)\cap H^2(\Omega)\\
Au=\Delta u.
\end{cases}
$$
 I usually see in some references that the eigenfunctions of this operator are an orthonormal basis for the Hilbert space $L^2(\Omega)$. It is stated in Wikipedia that this result follows from the spectral theorem on compact self-adjoint operators, applied to the inverse of the Laplacian (which is compact, by the Poincaré inequality and Rellich–Kondrachov theorem). I have some questions about this: 1) first why the operator $A$ is invertible 2) why the inverse is a bounded operator. (my guess is that the boundedness maybe follows from the closed graph theorem, $A$ closed operator implies $A^{-1}$ is also closed? I am I right?) however I didn't prove that $A$ is a closed operator, I just have a feeling it is closed. 3) I don't see how the compactness of the operator $A^{-1}$ follows from the Poincaré inequality and Rellich–Kondrachov.","['eigenvalues-eigenvectors', 'partial-differential-equations', 'operator-theory', 'functional-analysis', 'laplacian']"
2399611,"Suppose $A$, $B$, and $C$ are sets. Prove that $A ∪ C ⊆ B ∪ C$ iff $A \setminus C ⊆ B \setminus C$.","This is Velleman's exercise 3.5.6: Suppose $A$, $B$, and $C$ are sets. Prove that $A ∪ C ⊆ B ∪ C$ iff $A \setminus C ⊆ B \setminus C$. And here's my proof of it: Proof. ($\rightarrow$) Suppose $A ∪ C ⊆ B ∪ C$. Let $x$ be arbitrary and $x ∈ A$ and $x ∉ C$. From $x ∈ A$ and $A ∪ C ⊆ B ∪ C$ we have $x ∈ B ∪ C$. Since $x ∉ C$, then $x ∈ B$. Since $x$ was arbitrary, $A \setminus C ⊆ B \setminus C$. ($\leftarrow$) Suppose $A \setminus C ⊆ B \setminus C$. Let x be arbitrary and $x ∈ A ∪ C$. Now suppose $x ∉ C$. From $x ∈ A$, $x ∉ C$ and $A \setminus C ⊆ B \setminus C$, we get $x ∈ B$. Ergo $x ∈ B \lor x ∈ C$. Since $x$ was arbitrary, $A ∪ C ⊆ B ∪ C$. Since $A ∪ C ⊆ B ∪ C$ $\Rightarrow$ $A \setminus C ⊆ B \setminus C$ and $A ∪ C ⊆ B ∪ C$ $\Leftarrow$ $A \setminus C ⊆ B \setminus C$, therefore $A ∪ C ⊆ B ∪ C$ $\iff$ $A \setminus C ⊆ B \setminus C$. Is my proof valid? Thanks in advance.","['logic', 'elementary-set-theory', 'proof-verification']"
2399613,How to derive the likelihood and loglikelihood of the poisson distribution [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question As the title suggests, I'm really struggling to derive the likelihood function of the poisson distribution (mostly down to the fact I'm having a hard time understanding the concept of likelihood at all). I've watched a couple videos and understand that the likelihood function is the big product of the PMF or PDF of the distribution but can't get much further than that. The question is as follows: ""Random variables $X_1, \dots, X_n$ are independent and identically distributed (IID) from a $Poisson(θ)$ distribution. Suppose a random sample $x = (x_1, \dots, x_n)$ has been observed. (a) Write down the likelihood function $L(θ)$ based on the observed sample."" If anyone could help show me the process for deriving the likelihood function I would really appreciate it. Thanks!","['statistics', 'poisson-distribution', 'log-likelihood', 'probability-distributions']"
2399624,Closure of a compact space always compact?,"Is the closure of a compact subspace of a topological space always compact? I want to say no, but i can't think of/find any counterexamples. I think its probably true with added conditions, like Hausdorff property? Because the closure is always closed and closed sets in a compact hausdorff space are compact. Any counterexamples for a non-Hausdorff space?","['general-topology', 'examples-counterexamples', 'compactness']"
2399642,"Let $f$ be an entire function, show that the following conditions imply that $f$ is constant.","Let $f$ be an entire function, show that the following conditions imply that $f$ is constant. (i) $f(\mathbb C)\cap\{x \in \mathbb{R} | x < 0 \}= \emptyset$ (ii) $f(\mathbb C)\cap\{x \in \mathbb{R} | 0 < x < 1 \}= \emptyset$ (iii) $f(\mathbb C)\cap\{z \in \mathbb{C} | |z - 1| < \frac{1}{4} \} = \emptyset$ I know how to prove the (iii) using Liouville's Theorem. I know that the $f(\mathbb C)$ is dense in $\mathbb{C}$ if $f$ is a nonconstant entire function. Then the intersection of the range of $f$ with any open set in $\mathbb{C}$ can not be empty. But for (i) and (ii) I don't know because those two are not open sets in $\mathbb{C}$ . Show I consider that sets as open sets in the relative topology?","['complex-analysis', 'analytic-functions', 'entire-functions', 'complex-numbers']"
2399648,proving relations between set of functions,"i'm having problem with this question. i'll explain what i've done after i ask it. let F be the set of all functions $N\to N$. K is a relation over F that is defined like this: for every $f,g \in F$ $(f,g) \in K$ iff for every $n\in N$  $f(n) \leq g(n)$ a)are there maximal elements for the relation K? is there a greatest element? prove. b)are there minimal elements for the relation K? is there a smallest element? c)(where i'm having most of the trouble) prove that for every $f \in F$ there's $g \in F$ that covers f, and prove that for every $f \in F$ there exist more than one such g. what i've done: a)let $h,j \in F$ and for every $x \in N$ $h(x) \leq j(x)$, so $(f,g) \in K$, thus there exists some h(x) that would greater than or equal to j(x), but that is not possible since j(x) must be greater or equal, so such number could not exist in N and thus there is no greatest value since for every $h(x) \leq j(x)$. from that we can also infer that the maximum value might be given j(x) b)same thing, but the opposite to show minimal and smallest element while concidering 0 is the smallest and the minimal is $h(x)$ iff for every $x \in N$ $h(x) \leq j(x)$, thus h(x) must be less or equal to j(x) with the limit of 0(the smallest element). c)let $x \in N$ and let $g_x \in F$ be defined like this: $g_x(k)=\begin{cases}
f(k),&\text{if }k\ne m\\
f(k)+1,&\text{if }k=m\;.
\end{cases}$ so $f \leq g_x(k)$ and $f \neq g_x$. now if we say that there exists a $h \in F$ so that $h \neq f$ , then if $k=m$ -> then $g(k)=f(k)+1$ because F is defined to be from N->N and there can't be $f(k)≤h(k)≤g_x(k)$ and if it's not equal, then by the information given in the question it's bigger and most cover. (i don't know how to prove that more of one  like that exists). i've done my best efforts, please help me if you can.","['elementary-set-theory', 'discrete-mathematics']"
2399678,Finite generation of a pre-image of a finitely generated subalgebra,"Let $k$ be a field, let $A$ and $B$ be commutative, finitely-generated, graded $k$ -algebras, and let $S$ be a finitely-generated, graded $k$ -subalgebra of $B$ . Question1: If $\varphi:A\to B$ is a graded $k$ -algebra map, must $\varphi^{-1}(S)$ be finitely generated? Question2: If so, can we say anything about the degrees of generators for $\varphi^{-1}(S)$ ? More specifically, if $A$ , $B$ , and $S$ are generated in degrees at most $d_A$ , $d_B$ , and $d_S$ , is there some constant $C=C(d_A,d_B,d_S)$ for which there must exist generators of $\varphi^{-1}(S)$ in degrees at most $C$ ? This paper shows that in characteristic $0$ , the intersection of two finitely-generated subalgebras need not be finitely generated, so that $\varphi(A)\cap S$ may not be finitely generated. Then, since $\varphi^{-1}(S)=\varphi^{-1}(\varphi(A)\cap S)$ , we have a counterexample to question $1$ . In Remark-Question 1.6, the author states that the results of the paper do not extend to positive characteristic. Does characteristic $p$ help? Or are there other properties of $A$ , $B$ , $S$ , and/or $\varphi$ for which my questions have affirmative answers? Sorry, for the vagueness here - I wish I could be more specific than ""other properties,"" but this seems like a hard question and I'm not quite sure what should be true of my setup to make it work. I'd be happy with partial answers and/or references. Thanks.","['reference-request', 'positive-characteristic', 'algebraic-geometry', 'commutative-algebra']"
2399708,"Let $ \tau(\omega) =\inf \{ t \in (0, \infty): B_t(\omega) = 10\}$. Does it follow $P( \tau = s) = 0?$","Consider the first time the Brownian motion reaches $10$, i.e.
$$\tau(\omega) =\inf \{ t \in (0, \infty): B_t(\omega) = 10\}$$
Clearly, $P(B_t = 10) =0, \forall t \in \mathbb{R}^+$since the Brownian motion is normally distributed. But does it follow that
$$P( \tau = s) =0, \forall s \in \mathbb{R}^+$$
and does considering the interval $[0, \infty)$ make a difference?","['stochastic-processes', 'probability-theory', 'brownian-motion']"
2399710,Study Tips and Techniques for Self-Oriented Students,"I am asking for what, if any, the preferred study skills of approaching classes are like in higher math education are like in general, and I am not asking necessarily for personal anecdotes for this question (though they are welcome if it's all you have to share). My question is what are the better studying methods for learning higher mathematics(i.e., subjects involving more proofs instead of calculations like Analysis, Topology, Axiomatic Set Theory, Abstract Algebra, etc.)? Let me explain what I mean by giving you an example. As an undergrad at first, courses like the Calculus sequence, Differential Equations could be approached by learning how to solve problems even if you weren't able to understand the proofs(which were usually skipped over in the textbook by the professor). But now, that I have taken Linear Algebra, and I am about to take Analysis I usually take a much different approach: $ $$\cdot$$ $ I start by rewriting all the definitions and theorems and proofs of a chapter and memorizing them. Then I will work through the examples, and ideally get to the exercises and finish off the chapter. And also spend time reflecting on the topics to get a more intuitive understanding of the concepts involved. I skip very little, anything if at all from the books I'm working with even if the topics are skipped in class. This approach is very effective, especially when I am studying a topic for my own interests, and I am really able to understand things at a level that my peers usually have trouble following. The drawback is that I move at a much slower pace than my peers and I end up struggling in a class towards the end of a semester because I am behind on the syllabus. I end up risking a low grade though all but once I have managed an A- or above. Also am able to work out Jech's Set Theory which others have told me is out of my league but I actually find it the right amount of challenging using this approach. The method followed by the math department at my school feels very superficial and not as the effective long-term. Usually, professors do not focus on the reasoning or intuition behind concepts. Tests are oriented so that we memorize by rote the proofs of the major theorems and regurgitate them on exams. Let me give more concrete questions: I asked a math professor once, and he said that real mathematics is usually done where you understand 2 or 3 pages a day of a text on your first reading of it. Is this true for graduate level work for the average student? Do students who follow my immersive way of studying tend to have an advantage over those who don't when we get to grad school? In terms of learning theory and doing exercises, how much importance is recommended to place on each? 4. Are there study techniques used in more advanced math courses (like engaging in discourse with peers, focusing more on memorization before attempting to do problem sets, taking notes in a particular way) that are more fruitful than others?","['self-learning', 'advice', 'soft-question', 'education', 'analysis']"
2399755,Which of the following sets has the greatest cardinality?(Math subject GRE exam 0568 Q.61 ),"How can I solve this question in only 2.5 minutes? It must be solved using deep insight and intuition, which I do not have. Could anyone help me, please? Thanks! Which of the following sets has the greatest cardinality? (A) $\mathbb{R}$ (B) The set of all functions from $\mathbb{Z}$ to $\mathbb{Z}$ (C) The set of all functions from $\mathbb{R}$ to $\{0, 1\}$ (D) The set of all finite subsets of $\mathbb{R}$ (E) The set of all polynomials with coefficients in $\mathbb{R}$","['cardinals', 'elementary-set-theory']"
2399770,"In how many ways can we permute the digits $2,3,4,5,2,3,4,5$ if identical digits must not be adjacent?","In how many ways can we permute the digits $2,3,4,5,2,3,4,5$ if identical digit must not be adjacent? I tried this by first taking total permutation  as $\dfrac{8!}{2^4}$ Now $n_1$ as $22$ or $33$ or $44$ or $55$ occurs differently $N_1 = \left(^7C_1\times \dfrac{7!}{8}\right)$ And $n_2 = \left(^4C_1 \times 4!\right)$ Using the inclusion-exclusion principle I got: $\dfrac{8!}{16}-\left(^7C_1\times\dfrac{7!}{8}\right)+\left(^4C_1\times4!\right)$ But answer was wrong Please help me solve the question This question is from combinatorics and helpful for RMO","['permutations', 'combinatorics', 'combinations']"
2399780,Group of order 21 and subgroup of order 7,"I have this problem and I don't know how to solve it, because in this part of the book I only have normality and the isomorphism theorems. Let $G$ a group and $|G|=21$ assume that $a \in G$ and $|a|=7.$ Prove that $A = 
 \langle a \rangle$, the subgroup generated by $a$, is normal in $G$. i.e $$A \lhd G$$ At this moment of the book I CAN'T use Sylow theorems so I dont know how to do this without it.
Thanks.","['abstract-algebra', 'normal-subgroups', 'group-theory']"
2399813,Is the following correct $dx = \lim_{ \Delta x\to 0} \Delta x\ $?,I hope your answer for this question will help me understand a lot of things. Thank you guys.,"['notation', 'calculus', 'limits']"
2399824,"If a bird fly to height of $h$ ,What's the area that it can see?","Suppose a bird fly to height $h$ from earth . The bird can see area under by it's eyes ,name as $S$ ,What's $max \{S\}$ ? Is it possible to solve  ? my first trial was to assume a cone by $height =h$ and $S=\pi R^2$ as area like the figure I attached with. Is $S$ a constant for special amount of $h$ ? can we calculate $max \{S\}$ or $S$ ?(or something is missed  ?) Thanks for any hint ,in advance.","['trigonometry', 'calculus', 'geometry']"
2399830,"How prove infinitely many postive integers triples $(x,y,z)$ such $(x+y+z)^2+2(x+y+z)=5(xy+yz+zx)$","show that there exsit infinitely many  postive integers triples $(x,y,z)$ such $$(x+y+z)^2+2(x+y+z)=5(xy+yz+zx)$$ May try it is clear $(x,y,z)=(1,1,1)$ is one  solution，and $$(x+y+z+1)^2=5(xy+yz+xz)+1$$","['number-theory', 'vieta-jumping', 'diophantine-equations', 'elementary-number-theory']"
2399840,Solving system of differential equations to evaluate $x(t)$,"I have to solve the following system of equations and find $x(t)$ $$\frac{dx}{dt} =a\cos(y)-b$$
$$x\frac{dy}{dt}=-a\sin(y)$$ Initial conditions: $t=0,x=x_o, y=\frac{\pi}{2}$ By dividing equations and integration, i obtained $x(y)$: $$x=x_o \csc(y) \left|\csc(y)-\cot(y)\right|^{\frac{b}{a}}$$ Now I cannot proceed to find $x(t)$.","['trigonometry', 'ordinary-differential-equations', 'trigonometric-integrals', 'calculus']"
2399859,Find the domain of $f(x) = \sqrt{\log_{x^2}(x)}$.,"I do understand that x should belong to $(0,1) \cup (1, \infty)$ but when I solved it I got three conditions: that $x$ belongs to $(1, \infty)$ , $(0, \infty)$ and $x\neq1$. So upon intersection of these intervals I am only left with $x$ belonging to $(1, \infty)$. So problem is that I am not getting $(0,1)$ as a solution. Here's how I solved it:
1/2 log x to base x>=0 .......(i) 
Therefore x>=1 
This implies that x belongs to [1, infinity) 
x cannot=1 .......(ii)
And
X >0
Therefore x belongs to (0, infinity)
Upon intersection of these 3intervals I get x belongs to (1, infinity) Where did I go wrong?","['algebra-precalculus', 'logarithms', 'functions']"
2399924,How does $t \rightarrow \infty$ then $t[1-F(t)+F(-t)] \rightarrow 0$ relate to the weak law of large numbers?,"Refering to the notes here http://www.stat.umn.edu/geyer/8112/notes/weaklaw.pdf In Theorem 1, I understand how (i) $\iff$ (iii). I also understand the second part of (ii) where  $\lim_{t \to\infty} \int ^t _{-t} x F \{dx \} = \mu $ However, I do not understand how the first part of (ii) is of any relevance here. Doesn't that equation hold true for all distribution functions, since as $t \rightarrow \infty$, $F(t) \rightarrow 1$ and $F(-t) \rightarrow 0$? Therefore, $1-F(t)+F(-t) \rightarrow 0$, and therefore $t(1-F(t)+F(-t)) \rightarrow 0$? How does this relate to the weak law of large numbers?","['law-of-large-numbers', 'probability-theory', 'probability', 'probability-distributions']"
2399937,What does it mean to work without a basis?,"When reading proofs or definitions on Wikipedia, I'm accustomed to seeing both a basis-dependent discussion and basis-free discussion. Take, for example, this page on the tensor product, which has a ""free vector space"" discussion alongside a matrix representation discussion. While I understand not all vector spaces have a canonical basis, it's not formally clear to me what it means for a proof or definition to be basis-dependent vs. basis-free, and why it's better to be basis-free in the first place. 1) If I'm writing a proof or defining an object, what rules or criteria must I follow to be properly basis free? And, once I know what a basis-dependent proof or definition looks like, what is the strategy from generalizing it to a basis-independent proof or definition? 2) If all vector spaces can be represented by a (not necessarily canonical) basis, can't we always represent operators and members of that that space with matrices and linearly independent sums? My larger question, is then, if we're really making no assumptions when write down matrices or element-wise operations, why is it bad or ungentlemanly to choose a basis without loss of generality?",['linear-algebra']
2399941,How to prove L'Hospital's rule using $\varepsilon$-$\delta$ method? [duplicate],"This question already has answers here : Understanding the Proof of L'Hopital's Rule (2 answers) Closed 4 years ago . For $\varepsilon$ - $\delta$ proofs, basically we need to find a $\delta$ such that $|F(x)-L|<\epsilon$ whenever, $0<|x-a|<\delta$ (for a small positive number $\epsilon$ ). To prove L'Hospital's rule (for when numerator and denominator function both tend to $0$ as $x\rightarrow a^{+}$ )  let us assume $F(x)=\frac{f(x)}{g(x)}$ . Where, $\lim_{x\rightarrow a^{+}}f(x)=0$ and $\lim_{x\rightarrow a^{+}}g(x)=0$ . I claim that $L=\lim_{x \rightarrow a^{+}}\frac{f'(x)}{g'(x)}$ . Now I need to prove this $L$ is indeed the limit. $$\left|\frac{f(x)}{g(x)}-\lim_{x \rightarrow a^{+}}\frac{f'(x)}{g'(x)}\right|<\epsilon.$$ But after this I cannot understand how to find $\delta$ as a function of $\epsilon$ , so that I can complete the proof. How should I proceed?","['epsilon-delta', 'real-analysis', 'limits']"
2399944,Use of Lagrange multipliers in pure math problems,"I realize that Lagrange multipliers are extremely useful for applied optimization problems. However, I know that the standard analytic proof of the spectral theorem relies on them. I've also seen a few other uses/mentions of them in some pure math textbooks. (For example, Wade's An Introduction to Analysis uses an exercise on Lagrange multipliers to later prove a result due to Bernstein on the convergence of Fourier series.) My question, then, is if Lagrange multipliers are generally a useful
  technique for extremal problems that arise in pure math. If so, are
  there some well-known proofs in this area that use them (other than
  those I mentioned)? I'm simply curious as to their use outside applied optimization, since the derivation of the existence of the so-called Lagrange multiplier is really just a corollary of a very geometric fact--namely that the gradient is perpendicular to the level sets. EDIT: To be a bit more specific, by ""useful"" I mean that it is in fact applicable to certain pure math problems with somewhat regular frequency.","['derivatives', 'real-analysis', 'multivariable-calculus', 'soft-question', 'lagrange-multiplier']"
2399959,solving $\cos z + \sin z = i$,"I found a solution but when testing it, it does not work....? $$\cos z + \sin z = i \\ \frac{e^{iz} + e^{-iz}}{2} + \frac{e^{iz} - e^{-iz}}{2i} = i \\ e^{2iz}(1+i) + 2e^{iz} + i - 1 = 0 \\ e^{iz} = \frac{-1 \pm \sqrt{2-i}}{1+i} \\ z = -i \mathrm{Log}\left(\frac{-1\pm\sqrt{2-i}}{1+i}\right) + k2\pi$$ Upon testing it in W|A with $k=0$, I don't get the required result $(=i)$. I'm not sure where I went wrong and I did this a few times already.",['complex-analysis']
2399975,"If $f\in L^1_{loc}$, does it mean that $f$ is continuous on $\mathbb{R}$?","Let $L^1_{\text{loc}}$ denote locally compact and $(Arf)$ denote the average of a function $f$.  I already have the proof for the following Theorem state as $\text{Theorem:  If} ~~f\in L^1_{loc}~~\text{then}~~ \lim_{r\to 0}(Ar f )(x) = f (x)$ for $m$ — a.e. $x\in \mathbb{R}^n$. Now, I want to construct a parallel proof for the following statement: $$\text{If}~ f(x)~\text{ is continuous on}~ \mathbb{R,}~\text{ prove that}~\lim_{r\to 0}(Arf)(x) = f(x)$$ for all $x$. My questions are; what modifications do I have to make in the above Theorem so as to write an independent proof to my statement?  What is the relationship between $\mathbb{R}$ and $L^1_{\text{loc}}$?","['real-analysis', 'lebesgue-integral', 'measure-theory', 'lebesgue-measure']"
2400011,The BEST book of measure theory for beginners,"I need a book which explains the concepts of measure, set functions, outer meaures, extension of meaures, measurable functions, outer measurable functions and Lebesgue measure kindly help me...","['real-analysis', 'reference-request', 'lebesgue-measure', 'book-recommendation', 'measure-theory']"
2400080,Derivative of matrix-valued function with respect to matrix input,"I have the expression $$\bf \phi  = \bf X W$$ where $\bf X$ is a $20 \times 10$ matrix, $\bf W$ is a $10 \times 5$ matrix. How can I calculate $\frac{d\phi}{d\bf W}$? What is the dimension of the result?","['matrices', 'matrix-calculus', 'derivatives']"
2400127,Definition of sub-bundle,In these notes (Example 2.19) it is said that a sub-bundle $E'$ of $E$ should be a bundle $E' \subset E$ such that $E/E'$ is also a vector bundle. I feel a bit confused as I can't imagine bundles $E' \subset E$ with $E/E'$ is not a vector bundle.,"['vector-bundles', 'algebraic-geometry']"
