question_id,title,body,tags
2133570,Why is the notation $\mu(dt)$ in integrals so widely used in Measure Theory?,"It seems to me rather ambiguous as it gives the impression of invariance by translation. Could it be an archaic notation that comes from the Lebesgue measure (for which of course, this notation makes sense)? It seems to me that $d\mu(t)$ is more precautious with general measures, because one can directly see that it depends on the point $t$ .","['notation', 'lebesgue-measure', 'terminology', 'lebesgue-integral', 'measure-theory']"
2133586,$A^{2016}-2A^{3016}+A=0$,"I'm learning linear algebra and need help with the following problem: Let $A = \begin{pmatrix}-2 & 4 & 3\\0 & 0 & 0\\-1 & 5 & 2\end{pmatrix} \in M_{3x3}(\mathbb{R})$. Show that $A^{2016}-2A^{3016}+A=0$. I guess this is a direct application of the Cayley-Hamilton theorem which states that every matrix satisfies its own characteristic equation. The characteristic polynomial of $A$ is  $p_{A}(\lambda) = \lambda - \lambda^{3}$ (I skipped the easy computation of the determinant to save me some time). Hence, by the Cayley-Hamilton theorem $$A - A^{3} = 0 \tag{*}$$ How should I make use of $(*)$ and continue from here to prove the identity? I thought I could write $(*)$ as $A = A^{3}$ and then appropriately multiply both sides of latter equality but I got stuck. I'm also interested to know if there are other methods to solve this problem. EDIT: As A.G. demonstrated, the identity is not true. It would be true for odd powers, e.g. $A^{2017}-2A^{3017}+A=0$. This is an unfortunate typo from my teacher's notes. I apologize to the users who gave answers prior to this edit.","['matrices', 'linear-algebra']"
2133595,Associativity of concatenation,"Prove that the following operator is associative for $b\in \Bbb N$ $$x||y = x\cdot b^{1+\lfloor\log_{b}{y}\rfloor}+y$$ One thing that you can notice is that it is the concatenation operator. However, you are not allowed to use this fact. In first order logic, we refuse to attach any meaning to any objects and try to prove things starting with axioms.","['number-theory', 'first-order-logic', 'formal-proofs']"
2133602,What is this presentation isomorphic to?,"I am trying to determine the group given by the presentation: $\langle\ a, b, c\ \vert\ a^2=b^5,\ b^2=c^3,\ c^2=a^7\ \rangle$. I've been trying to tackle this problem by starting with the first relation and, in essence, 'cycling' through the other two relations by substitution, in the hope that I produce some sort of simpler relation. So far, I've managed to deduce that $a=b^{50}$ and $c^2=b^{65}$. These together with the original relation $c^2=a^7$ mean we can say: $b^{285}=1$. From here, though, I am struggling to get any further. From what I've done so far, my intuition suggests to me that this is going to be some cyclic group, but I'm very unsure. Any help would be appreciated!","['abstract-algebra', 'group-theory', 'group-presentation']"
2133633,Are Differential Structure of a Complex Number and its Field Structure Independent?,"It is well known that $\mathbb{R}^2$ has a very famous field structure defiend by $(a,b)(c,d)=(ac-bd,ad+bc)$. And it also has a holomorphic structure, which makes $z\mapsto z$ differentiable but not $z\mapsto \bar{z}$. One of my friends asked me about the difference between $\mathbb{R}^2$ and $\mathbb{C}$, and I stated these two structures, but when I did it, I realized that I am not aware of the relation, or independence, of these two structures. So is one of these structures implies the other? So, to elaborate my question more, it would be like this: Suppose we have a holomorphic structure (of course with topology) on $\mathbb{R}^2$ which makes $(x,y)\mapsto(x,y)$ holomorphic but not $(x,y)\mapsto (x,-y)$. Now we want to find a field structure $\cdot:\mathbb{R}^2 \times \mathbb{R}^2 \to \mathbb{R}^2$ which is compatible with the holomorphic structure; $z \mapsto a\cdot z$ is complex-differentiable, and its derivative is a constant $a$. (edit) And of course the operation should be continuous with respect to the usual topology. Is it always isomophic to $\mathbb{C}$? Here I stated the holomorphic structure first, but I am also curious about the other way: defining the field structure first and finding the 'compatible' holomorphic structure. And I am also curious if there is any way to see that one of these structures are actually implying the other 'directly,' which is the fact that I am not really sure of. Thanks in advance! (edit) I stated that the operation should be continuous with respect to the usual topology. (edit) I changed ""differentiability"" condition into ""holomorphicity.""","['complex-analysis', 'differential-topology']"
2133637,Proof: Inequality in Mercer's theorem,"In the outline of the Mercer's theorem proof there is an inequality assumed without any explanation: $$\sum_{i=0}^{\infty} \lambda_i \vert e_i(t) e_i(s) \vert \le \sup_{x \in [a,b]} \vert K(x,x)\vert^2$$ Why does this need to hold?","['functional-analysis', 'spectral-theory', 'operator-theory']"
2133714,"Show that in Lyapunov equation $A^TQ+QA=-I$, the matrix $Q$ is positive definite.","Let $A$ be matrix whose eigenvalues all have negative real parts. Define $Q=\int^{\infty}_0 B(t)dt$ where $B(t)=e^{A^Tt}e^{At}$ . Prove that $Q$ is symmetric and positive definite. This question is related to the corresponding Lyapunov equation $A^TQ+QA=-I$ . By the above we know that $B(t)^T=B(t)$ and $\forall x \neq 0. x^TB(t)x>0$ . Therefore: \begin{align}
-I
&=\lim_{\tau \to \infty} B(\tau) -I\\
&=\lim_{\tau \to \infty} \int^{\tau}_0\frac{d B(t)}{dt} \\
&= \lim_{\tau \to \infty} \Big( A^T\int^{\tau}_0B(t)dt+\int^{\tau}_0B(t)dt\ A \Big)\\
&=A^TQ+QA\\
\end{align} However I am confused on how to use these facts to show that $Q$ is symmetric and positive definite.","['matrix-equations', 'dynamical-systems', 'matrices', 'linear-control', 'ordinary-differential-equations']"
2133726,Find the limit of the expression,"Find
  $$ \lim_{x\to\infty}\frac{\sqrt{1-\cos^3(1/x)}\cdot(3^{1/x}-5^{-1/x})}
{\log_2( 1+x^{-2} + x^{-3})}$$ Firstly I replace $x$ with $1/t$. Then $t$ tends to $0$. And then I fix numerator with formulas for limits considering $t \to 0$. 
But I don't know what to do with denominator. Any help?","['calculus', 'limits']"
2133755,"Calculate $P(A' \cap B)$ and $P(A' \cap B')$ given $P(A) = 1/2$, $P(B) = 1/2$ and $P(A \cup B)= 2/3$",We are given that $P(A) = P(B) = 1/2$ and $P(A \cup B)= 2/3$ . I found that events $A$ and $B$ are not mutually exclusive by showing that $P(A \cup B) \neq P(A) + P(B)$ (i.e. $2/3 \neq 1$ ) I also found that the two events are not independent by showing that $P(A \cap B) \neq P(A)P(B)$ (i.e. $1/3 \neq 1/4$ ) Because the events are not mutually exclusive or independent I am having trouble solving for $P(A'\cap B)$ and $P(A' \cap B')$ . I wanted to use the fact that $P(A'\cap B) = P(B) - P(A\cap B)$ but the events must be mutually exclusive to use this. Any suggestions?,"['statistics', 'probability']"
2133773,Two distinct solutions of $x'(t)=f(x(t))$ cannot intersect at any point.,"Let $f:\mathbb{R}^n \to \mathbb{R}^n $ be a continuously differentiable function. Prove that two distinct solutions of $x'(t)=f(x(t))$ (the ODE is autonomous) cannot intersect at any point, not even at different times. Notes: Clearly there is a relationship between this question and the theorems for the existence and uniqueness of ODEs. Theorem: Let A be an open subset of $\mathbb{R}^n$ and that $f \in C^1(A)$. Then $\forall x_0 \in A \ \exists \ \alpha>0$ such that the IVP $$x'(t)=f(x(t)), \ x(0)=x_0$$ has a unique solution $x(t)=x(t,x_0)$ on the interval $[-\alpha,\alpha]$. As $f \in C^1$ the theorem applies so the solutions to $x'(t)=f(x(t))$ are unique (they will not be in the same position at the same time). However I do not know how to show that the two solutions cannot intersect at later times.","['ordinary-differential-equations', 'dynamical-systems']"
2133783,"A summation involving $\arctan$, $\pi$ and Hyperbolic function","Prove that
$$\sum_{n\in\mathbb{Z}}\arctan\left(\frac{\sinh(1)}{\cosh(2n)}\right)=\frac{\pi}{2}$$ Writing  $$\dfrac{\sinh(1)}{\cosh(2n)}=\dfrac{e^{1}-e^{-1}}{e^{2n}+e^{-2n}}$$ I tried to use the identity
$$\arctan\left(\frac{a_1}{a_2}\right)+\arctan\left(\frac{b_1}{b_2}\right)=\arctan\left(\frac{a_1b_2+
a_2b_1}{a_2b_2-a_1b_1}\right)$$
with a suitable choice of $a_1,a_2,b_1,b_2$ but I haven't been able  to find a telescopic sum.","['hyperbolic-functions', 'telescopic-series', 'pi', 'summation', 'sequences-and-series']"
2133790,Showing matrices in $SU(2)$ are of form $\begin{pmatrix} a & -b^* \\ b & a^*\end{pmatrix}$,"Matrices $A$ in the special unitary group $SU(2)$ have determinant $\operatorname{det}(A) = 1$ and satisfy $AA^\dagger = I$. I want to show that $A$ is of the form $\begin{pmatrix} a & -b^* \\ b & a^*\end{pmatrix}$ with complex numbers $a,b$ such that $|a|^2+|b|^2 = 1$. To this end, we put $A:= \begin{pmatrix} r & s \\ t & u\end{pmatrix}$ and impose the two properties. This yields \begin{align}\operatorname{det}(A) &= ru-st \\ &= 1 \ ,\end{align}
and 
\begin{align}
AA^\dagger &= \begin{pmatrix} r & s \\ t & u\end{pmatrix}  \begin{pmatrix} r^* & t^* \\ s^* & u^* \end{pmatrix} \\&= \begin{pmatrix} |r|^2+|s|^2 & rt^* +su^* \\ tr^*+us^* & |t|^2 + |u|^2\end{pmatrix} \\
&= \begin{pmatrix} 1 & 0 \\ 0 & 1\end{pmatrix} \ .\\
\end{align}
The latter gives rise to 
\begin{align}
 |r|^2+|s|^2 &= 1 \\
&= |t|^2+|u|^2 \ ,
\end{align}
and 
\begin{align}
tr^*+us^* &= 0 \\
&= rt^*+su^* \ .
\end{align} At this point, I don't know how to proceed. Any hints would be appreciated. @Omnomnomnom's remark 
\begin{align}
A A^\dagger &= \begin{pmatrix} |r|^2+|s|^2 & rt^* +su^* \\ tr^*+us^* & |t|^2 + |u|^2\end{pmatrix} \\
&= \begin{pmatrix} |r|^2+|t|^2 & sr^* +ut^* \\ rs^*+tu^* & |s|^2 + |u|^2\end{pmatrix} = A^\dagger A \ ,
\end{align}
gives rise to $$
|t|^2 = |s|^2 \\
|r|^2 = |u|^2
$$ and 
$$
AA^\dagger :\begin{pmatrix}
rt^* +su^* = sr^* +ut^* \\
tr^*+us^* = rs^*+tu^*  
\end{pmatrix}: A^\dagger A $$ At this point, I'm looking in to find a relation between $t,s$ and $r,u$ respectively.",['group-theory']
2133812,Maximizing Score in Dice Rolling Game,"In a game I was playing, you roll two six-sided dice. If either of them rolls a one, your points for the turn become zero and your turn is ended. If you roll greater than one on both dice, the sum of the rolls add to your points and you can choose to roll again or choose to end your turn and add your points from the turn to your total score. I was wondering how many rolls per turn would give you the best possible score on average, so I programmed a simple simulation that tested rolling once, twice, three times, and four times in a turn. It turned out that the best score comes from rolling a pair three times, but I can't explain why. Can anyone explain this through a proof or some equations?","['recreational-mathematics', 'probability']"
2133856,Can indefinite double integrals be solved by change of variables technique?,"I have a simple double integral: $$\int\int(x+y)dxdy$$ Now, change the variables according to the following scheme:
 $$x=u+v$$
$$y=u-v$$ The jacobian is then:
$$|\frac{\partial (x,y)}{\partial (u,v)}|=1$$ Substitute u and v into the integral, solving the integral and substituting y and x back in their place equals: $$(\frac{x-y}{2})(\frac{x+y}{2})^2$$ Which is obviously not the same as the result from directly integrating: $yx(\frac{x+y}{2})$ So my question is, can this technique not be used for solving double integrals, and is there perhaps any way to make the technique work (unless I have made a mistake somewhere).","['substitution', 'multivariable-calculus', 'indefinite-integrals', 'jacobian', 'change-of-variable']"
2133879,Dirichlet problem and Brownian motion,"Consider the Dirichlet problem of the following form: Let $D$ be a bounded,
connected open set in $R^d$ and $\partial D$ its boundary. Given any continuous function
$f$ defined on the boundary $\partial D$, one needs to find a function $u$ which
is continuous on $\bar{D }$, equal to $f$ on $\partial D$, and harmonic in $D$. I was reading some lecture notes on Brownian motion and there was a proof that if $D$ satisfies the cone condition, then the Dirichlet problem has a solution of the form $$u(x)=E_x[f(B_{\tau_D})],$$
where $$\tau_D=\inf\{t>0: Β_t \not \in D\}.$$
I think that in the case $d=2$, if $D$ is a Jordan Domain, then the Dirichlet problem always has a solution, even if $D$ does not satisfy the cone condition. To see this, consider a conformal mapping $\phi$ from the unit disk $\Delta$ to $D$. From Caratheodory's theorem it extends continuously and injectively on $\bar{\Delta}$. Now $f\circ \phi$ is continuous on $\partial\Delta$ and thus has a harmonic extension $F$ on $D$. But then $F\circ \phi^{-1}$ solves the Dirichlet problem. My question is the following: is $E_x[f(B_{\tau_D})]$ a solution to the Dirichlet problem in this case?","['complex-analysis', 'brownian-motion', 'harmonic-functions', 'probability']"
2133889,Do any two coprime factors of $x^n-1$ over the $p$-adic integers $\mathbb{Z}_p$ which remain coprime over $\mathbb{F}_p$ generate comaximal ideals?,"Let $f,g$ be distinct irreducible factors of $x^n-1$ over $\mathbb{Z}_p[x]$ (polynomials over $p$-adic integers). Suppose $\overline{f},\overline{g}$ are coprime in $\mathbb{F}_p[x]$ - thus, the ideal generated by them $(\overline{f},\overline{g}) = 1$ in $\mathbb{F}_p[x]$. Must $(f,g) = 1$ in $\mathbb{Z}_p[x]$? Note that $f,g$ are certainly coprime, but $\mathbb{Z}_p[x]$, coprime doesn't mean comaximal (e.g. $p,x$ are coprime but not comaximal).","['finite-fields', 'p-adic-number-theory', 'abstract-algebra', 'number-theory', 'commutative-algebra']"
2133909,Prove that this iteration cuts a rational number in two irrationals $\sum_{n=0}^\infty \frac{1}{q_n^2-p_n q_n+1}+\lim_{n \to \infty} \frac{p_n}{q_n}$,"For any $1 \leq p<q$ we have: $$\frac{p}{q}=\frac{1}{q^2-p q+1}+\frac{(q-p)(pq-1)}{q(q^2-p q+1)}$$ Let's consider an iteration: $$p_{n+1}=(q_n-p_n)(p_nq_n-1)$$ $$q_{n+1}=q_n(q_n^2-p_n q_n+1)$$ Then we have: $$\frac{p_0}{q_0}=\sum_{n=0}^\infty \frac{1}{q_n^2-p_n q_n+1}+\lim_{n \to \infty} \frac{p_n}{q_n}$$ The above is trivially true, provided both limits exist separately. But it turns out numerically that both the sum and the limit are finite and (seemingly) irrational. Let's denote: $$A(p_0,q_0)=\sum_{n=0}^\infty \frac{1}{q_n^2-p_n q_n+1}$$ $$B(p_0,q_0)=\lim_{n \to \infty} \frac{p_n}{q_n}$$ $$A(p_0,q_0)+B(p_0,q_0)=\frac{p_0}{q_0}$$ We have (I will only write $A$ , since $B$ can be obtained by subtraction): $$A(1,2)=0.365624790175942982737859474249681505 \dots$$ $$A(1,3)=0.145650460727123812176794888179825955 \dots$$ $$A(2,3)=0.261766321023330525617942741920174815 \dots$$ $$A(3,4)=0.205525029400010131449324836277780238 \dots$$ Moreover, since we define 'numerators' and 'denominators' separately, we obtain different results for $A(mp_0,mq_0)$ : $$A(2,4)=0.1123721471627326977547524155555190359 \dots$$ $$A(3,6)=0.0527707965471706424044987365216530762 \dots$$ $$A(4,8)=0.0303300858480840619918350602972694890 \dots$$ $$A(4/3,8/3)=0.228842771329071793825717533784828873 \dots$$ I haven't been able to find a closed form for any of $A,B$ I tried. However, it seems likely they are irrational. If it's true and there is no known closed form, then we can produce an infinite number of pairs of irrationals $A,B$ which sum to a particular rational number nontrivially. My questions are: Can we prove that $A,B$ are irrational for rational $p_0,q_0$ ? Is there any closed form for $A,B$ in terms of $p_0,q_0$ ? Are the values of $A,B$ unique for every distinct pair of $p_0,q_0$ ? A sketch of a proof of existence for $B$ (note that we assume $p_0,q_0 \in \mathbb{N}$ and $1 \leq p_0 \leq q_0-1$ ): $$p_{n+1}=(q_n-p_n)(p_nq_n-1) \geq p_n^2+p_n-1$$ $$q_{n+1}=q_n+q_n^2(q_n-p_n) \geq q_n^2+q_n$$ We can see that $p_n,q_n$ are non-decreasing, and for $n>1$ they are increasing (because $q_n$ is strictly increasing and it 'helps' $p_n$ after the first step). For $n \to \infty$ we have $p_n \to \infty$ and $q_n \to \infty$ , thus: $$\frac{p_{n+1}}{q_{n+1}}=\frac{(q_n-p_n)(p_nq_n-1)}{q_n(q_n^2-p_n q_n+1)} \approx \frac{p_n}{q_n}$$ It is apparent the limit exists. The limit for $A$ exists because the sequence $q_n^2-p_n q_n+1$ grows much faster than $n^2$ and the sum obviously converges. Update A little something on a closed form. The system of recurrence relations can be rewritten as a single recurrence relation, using: $$p_n=q_n+\frac{1}{q_n}-\frac{q_{n+1}}{q_n^2}$$ Then we have a second order recurrence relation: $$q_{n+2}=q_{n+1}(q_{n+1}q_n+1)+\frac{q_{n+1}^3}{q_n^2} \left(\frac{q_{n+1}}{q_n}-1 \right)$$ $$q_0=q_0, \qquad q_1=q_0(q_0^2-q_0 p_0+1)$$ Or a more symmetric form: $$\frac{q_{n+2}}{q_{n+1}}=q_{n+1}q_n+1+\frac{q_{n+1}^2}{q_n^2} \left(\frac{q_{n+1}}{q_n}-1 \right)$$ If we find a closed form for it (which I'm not sure exists) we can take the limit and find the closed form for $B$ . We also have a more simple looking relation (but it still requires us to know $q_n$ ): $$\frac{p_n}{q_n}=1+\frac{1}{q_{n-1}^2}-\frac{q_{n-1}}{q_n}-\frac{q_n}{q_{n-1}^3}$$ And in fact, we can also write $A$ in terms of $q_n$ : $$A=\sum_{n=0}^\infty \frac{q_n}{q_{n+1}}$$ Update 2 Getting rid of some unnecessary parts, we can reformulate the problem: Set some $q_1>q_0>0$ . Then we can define a second order recurrence: $$q_{n+2}=q_{n+1}(q_{n+1}q_n+1)+\frac{q_{n+1}^3}{q_n^2} \left(\frac{q_{n+1}}{q_n}-1 \right)$$ With the following property: $$L(q_0,q_1)-S(q_0,q_1)=\lim_{n \to \infty} \frac{q_{n+1}}{q_n^3}- \sum_{n=0}^\infty \frac{q_n}{q_{n+1}}=\frac{q_1-q_0}{q_0^3}$$ Can we find a closed form for the recurrence? Or separately for the limit $L$ or the sum $S$ above? Note that for the limit $L$ to be finite we need to have as $ n \to \infty$ : $$q_n \asymp C \cdot a^{3^n}$$ For example we have: $$S(1,2)=0.645953147800624278311945190231458547= \\ = \frac{1}{2}+\frac{1}{7}+\frac{1}{323}+\frac{1}{33657247}+\frac{1}{38127274806076464952763}+\dots$$ No closed form for this number either, however look at the denominator sequence - all the numbers end with $3$ or $7$ . This pattern continues as far as I can see.","['recurrence-relations', 'sequences-and-series', 'irrational-numbers', 'elementary-number-theory']"
2133933,how many times in average do I have to roll a dice to get a 1? [duplicate],"This question already has answers here : On average, how many times must I roll a dice until I get a $6$? (6 answers) Closed 7 years ago . I've read that the answer to such a problem is the inverse probability. So here getting a one has probably 1/6, so the number of tries you would be expected to run in order to get a 1 is 6. I'm not sure I understand this.",['probability']
2133984,"If $f(s) = (1+s)^{(1+s)^{(1+s)/s}/s}$, show that $\lim_{s \to \infty} f(s)/s = 1$.","If $f(s) = (1+s)^{(1+s)^{(1+s)/s}/s}$, show that $\lim_{s \to \infty} f(s)/s = 1$. This function comes up
in the parameterization
of the solutions to
$x^y = y^x$.
See for example, here: Are there real solutions to $x^y = y^x = 3$ where $y \neq x$? If we write
$y = rx$,
we get
$x = r^{1/(r-1)}$
and
$y=r^{r/(r-1)}$. Then
$x^y
=(r^{1/(r-1)})^{r^{r/(r-1)}}
=r^{r^{r/(r-1)}/(r-1)}
$. Finally,
if we write
$r = 1+s$,
this is
$f(s) = (1+s)^{(1+s)^{1+1/s}/s}
$. Wolfy says that,
around $s=0$,
$$f(s)
=e^e +  \dfrac{e^{1 + e} s^2}{24} 
- \dfrac{e^{1 + e} s^3}{24} 
+ \dfrac{e^{1 + e} (219 + 5 e) s^4}{5760} + O(s^5)
$$
and,
around $s = \infty$,
$$f(s)
=s + (\log^2(1/s) - \log(1/s) + 1) 
+ \dfrac{\log^4(1/s) - 3 \log^3(1/s) + 5 \log^2(1/s) - 6 \log(1/s) + 2}{2 s} + O((1/s)^2),
$$
calling this a
generalized Puiseux series. My question is:
How to show that that expansion
at $s = \infty$ is correct.
I would be satisfied with
a proof that,
as the title says,
$\lim_{s \to \infty} \dfrac{f(s)}{s}
= 1
$. It might help
to note that $\dfrac{y}{x}
= r$
and
$\dfrac{r}{s}
= \dfrac{1+s}{s}
= 1+\dfrac1{s}
$.",['limits']
2134011,Conversion of upper triangle linear index from index on symmetrical array,"Say we have a symmetrical matrix of the following form: A = [[0,1,2],
     [1,0,2],
     [2,2,0]] If we take the upper triangle of A and flatten it we get: B = [0,1,2,0,2,0] Is there a known formula that could take an index for A in the form of (i,j) and convert it to a value k that corresponds to the location in B for that index. For example: A[0,1] = B[1] = 1 
A[1,0] = B[1] = 1
A[2,0] = B[2] = 2
A[2,1] = B[4] = 2 In addition what is the method for deriving this formula? Perhaps my brain just isn't working today, but I can't seem to remember how to go about doing this. I have found something similar here , but that is for the triangle with an offset of 1 and I would like to include the diagonal in my conversion.","['matrices', 'symmetric-matrices']"
2134031,Is this formula for $\frac{e^2-3}{e^2+1}$ known? How to prove it?,"I found an interesting infinite sequence recently in the form of a 'two storey continued fraction' with natural number entries: $$\frac{e^2-3}{e^2+1}=\cfrac{2-\cfrac{3-\cfrac{4-\cdots}{4+\cdots}}{3+\cfrac{4-\cdots}{4+\cdots}}}{2+\cfrac{3-\cfrac{4-\cdots}{4+\cdots}}{3+\cfrac{4-\cdots}{4+\cdots}}}$$ The numerical computation was done 'backwards', starting from some $x_n=1$ we compute: $$x_{n-1}=\frac{a_n-x_n}{a_n+x_n}$$ And so on, until we get to $x_0$. The sequence converges for $n \to \infty$ if $a_n>1$ (or so it seems). For constant $a_n$ we seem to have quadratic irrationals, for example: $$\frac{\sqrt{17}-3}{2}=\cfrac{2-\cfrac{2-\cfrac{2-\cdots}{2+\cdots}}{2+\cfrac{2-\cdots}{2+\cdots}}}{2+\cfrac{2-\cfrac{2-\cdots}{2+\cdots}}{2+\cfrac{2-\cdots}{2+\cdots}}}$$ For $a_n=2^n$ we seems to have: $$\frac{1}{2}=\cfrac{2-\cfrac{4-\cfrac{8-\cdots}{8+\cdots}}{4+\cfrac{8-\cdots}{8+\cdots}}}{2+\cfrac{4-\cfrac{8-\cdots}{8+\cdots}}{4+\cfrac{8-\cdots}{8+\cdots}}}$$ I found no other closed forms so far, and I don't know how to prove the formulas above. How can we prove them? What is known about such continued fractions? There is another curious thing. If we try to expand some number in this kind of fraction, we can do it the following way: $$x_0=x$$ $$a_0=\left[\frac{1}{x_0} \right]$$ $$x_1=\frac{1-a_0x_0}{1+a_0x_0}$$ $$a_1=\left[\frac{1}{x_1} \right]$$ However, this kind of expansion will not give us the above sequences. We will get faster growing entries. Moreover, the fraction will be finite for any rational number. For example, in the list notation: $$\frac{3}{29}=[9,28]$$ You can easily check this expansion for any rational number. As for the constant above we get: $$\frac{e^2-3}{e^2+1}=[1,3,31,74,315,750,14286,\dots]$$ Not the same as $[1,2,3,4,5,6,7,\dots]$ above! We have similar sequences growing exponentially for any irrational number I checked. $$e-2=[1,6,121,284,1260,3404,25678,\dots]$$ $$\pi-3=[7,224,471,2195,10493,46032,119223,\dots]$$ By the way, if we try CF convergents, we get almost the same expansion, but finite: $$\frac{355}{113}-3=[7,225]$$ $$\frac{4272943}{1360120}-3=[7,224,471,2195,18596,227459,\dots]$$ So, the convergents of this sequence are not the same as for the simple continued fraction, but similar. Comparing the expansion by the method above and the closed forms at the top of the post, we can see that, unlike for simple continued fractions, this expansion is not unique. Can we explain why? Here is the Mathematica code to compute the limit of the first fraction: Nm = 50;
Cf = Table[j, {j, 1, Nm}];
b0 = (Cf[[Nm]] - 1)/(Cf[[Nm]] + 1);
Do[b1 = N[(Cf[[Nm - j]] - b0)/(Cf[[Nm - j]] + b0), 7500];
 b0 = b1, {j, 1, Nm - 2}]
N[b0/Cf[[1]], 50] And here is the code to obtain the expansion in the usual way: x = (E^2 - 3)/(E^2 + 1);
x0 = x;
Nm = 27;
Cf = Table[1, {j, 1, Nm}];
Do[If[x0 != 0, a = Floor[1/x0];
  x1 = N[(1 - x0 a)/(x0 a + 1), 19500];
  Print[j, "" "", a, "" "", N[x1, 16]];
  Cf[[j]] = a;
  x0 = x1], {j, 1, Nm}]
b0 = (1 - 1/Cf[[Nm]])/(1 + 1/Cf[[Nm]]);
Do[b1 = N[(1 - b0/Cf[[Nm - j]])/(1 + b0/Cf[[Nm - j]]), 7500];
 b0 = b1, {j, 1, Nm - 2}]
N[x - b0/Cf[[1]], 20] Update I have derived the forward recurrence relations for numerator and denominator: $$p_{n+1}=(a_n-1)p_n+2a_{n-1}p_{n-1}$$ $$q_{n+1}=(a_n-1)q_n+2a_{n-1}q_{n-1}$$ They have the same form as for generalized continued fractions (a special case). Now I understand why the expansions are not unique.","['continued-fractions', 'exponential-function', 'sequences-and-series', 'irrational-numbers']"
2134041,Set of slopes of tangents and secants of a continuous function,"Given a continuous function $f$ let us define the following subsets of the set $R$ of real numbers. $T$ =set of slopes of all possible tangents to the graph of $f$. $S$ =set of slopes of all possible secants, i.e. the lines joining two points on the graph of $f$. The question is to examine whether the following statements are true or false. (i) If $f$ is differentiable, then $S$ is a subset of $T$. (ii) If $f$ is differentiable, then $T$ is a subset of $S$. (iii) If $T = S = R$, then $f$ must be differentiable everywhere. (iv) Suppose $0$ and $1$ are in $S$. Then every number between $0$ and $1$ must also be in $S$. I have no idea on how to even approach this problem.The official solution hints for the use of mean value theorem and I have no idea on how it should be applied here.Any idea shall be highly appreciated.Thanks.","['elementary-set-theory', 'real-analysis', 'calculus']"
2134043,Is there a name for the center of a line?,"Is there a name for the center point for a line? For example:
---------o--------- If the dashes represent a straight line and the O represents the center of that line, what would the name for that center point be?",['geometry']
2134056,Set of quadratic expressions $nx^2+m$ whose union is all integers?,"Is there a set of quadratic equations whose union is equal to the counting integers (1,2,3,4...) but all pairs of intersections are empty. An example of linear equations which satisfy this is simply: $$
\begin{align*}
S_1 &= \{1,3,5,7,\ldots,2n+1\}\\
S_2 &= \{2,4,6,8,\ldots,2n+0\}\\[0.2in]    
S_1 \cup S_2 &= \{1,2,3,4,5,6,7,8,9,\ldots\}\\
S_1 \cap S_2 &= \varnothing
\end{align*}$$ It is easy to construct these for linear functions, but is it impossible to do the same for functions of the form $f_{mn}(x)=nx^2+m$?","['number-theory', 'quadratic-forms', 'sequences-and-series']"
2134064,Calculating area of sphere with constraint on zenith,"Let $\mathbb S_R$ be the sphere of radius $R$ centered about the origin. Consider $$A_R= \left\{ (x,y,z)\in \mathbb S_R \mid x^2+y^2+(z-R)^2\leq 1 \right\}.$$ I want to calculate the area of this region of the sphere with radius $R$ about the origin. I already calculated the area of the region of $\mathbb S_R$ of vectors with zenith $\leq \alpha$ is given by $2\pi R^2(1-\cos \alpha)$. For $A_R$, here's my idea. I want to find the zenith $\alpha$ which satisfies $R\sin \alpha=\sin \alpha+R$, since this is the zenith of points of both $\mathbb S_R$ and the unit sphere translated up $R$ units at points which are of the same height. Then, I just want to integrate the zenith $0\leq \phi\leq \alpha$. Solving gives $\phi=\arcsin \frac R{R-1}$ and things get a little messy. On the other hand, another student posted a solution which makes sense. He just writes $\alpha$ should satisfy $2R^2-2R^2\cos\alpha=1$ and then obtains the area of $A_R$ is $\pi$, independently of the radius. Why is my method wrong? Picture","['surface-integrals', 'multivariable-calculus', 'integration', 'definite-integrals', 'spherical-coordinates']"
2134094,How to optimize $\max_{ \|a \| \le r } E[ \|a+Z\|^k]$ where $Z$ i.i.d. Gaussian,"Let $\| \cdot \|$ be a Euclidean distance. How to optimize 
\begin{align}
\max_{ \|a  \| \le r } E[ \|a+Z\|^k],
\end{align}
where $Z \in \mathbb{R}^n$ is i.i.d. Gaussian standard normal and $k>0$? Solution for the case of $n=1$. For $n=1$ I found that 
\begin{align}
E[|a+Z|^k]= \frac{2^{k/2} \Gamma \left(\frac{k+1}{2} \right)}{\sqrt{\pi}}F_{1,1} \left(-\frac{k}{2},\frac{1}{2}; -\frac{a^2}{2} \right),
\end{align}
where $F_{1,1}$ is the Kummer’s confluent hypergeometric function. 
Since, $f(x)=F_{1,1} \left(-\frac{k}{2},\frac{1}{2}; -\frac{x^2}{2} \right)$ is increasing $x$ it follows that \begin{align}
\max_{|a| \le r }E[|a+Z|^k]=  E[|r+Z|^k].
\end{align} My Question: How can we find the maximum for any dimension $n\ge 1$? My conjecture is that the optimal value of $a$ is such that  $\|a \|=r$. That is $a$ is  a point on a ball of radius $r$. Thanks.","['expectation', 'probability-theory', 'probability', 'optimization']"
2134095,Integrate $\int \frac{1}{(1-x)(1+x)}dx$,"Integrate $$\int \frac{1}{(1-x)(1+x)}dx$$ $$\int \frac{1}{1-x^2}dx$$ $$=\tanh^{-1}(x)+C$$ When I look on Desmos though, this is only part of the answer? The blue is the function that it is supposed to be, and the red is the derivative of the answer I got. As you can see it's right, but only the red is shaded, the other two blue regions are not. Why is this? How can I fix this? My answer is correct, right?","['trigonometry', 'calculus', 'indefinite-integrals', 'integration', 'definite-integrals']"
2134136,Probability of a maximum being greater than a number. Inequality,"Imagine we have a seqence of (positive) absolutely continuous random variables $X_n$ and we know $\sup_n X_n$ is a measurable random variable and $\sup_n X_n < \infty$, i.e. there is a maximum one. Is the following true? $$P\left( \sup_{n} X_n \geq a \right) = P\left( \bigcup_n \left\{ X_n \geq a\right\} \right).$$ If not, is then the following true?
$$P\left( \sup_{n} X_n \geq a \right) \leq P\left( \bigcup_n \left\{ X_n \geq a\right\} \right).$$ Thanks for the help! :)","['calculus', 'integration', 'probability', 'measure-theory', 'random-variables']"
2134163,Find the sum of the series $\sum_{k=1}^{\infty} \frac {1}{(k)(k+2)(k+4)}$.,"Problem: Find the sum of the series $\sum_{k=1}^{\infty} \frac {1}{(k)(k+2)(k+4)}$. Thoughts I first tried to write out the series to detect some kind of a pattern, I suspect I need a way of rewriting the expression $\frac {1}{(k)(k+2)(k+4)}$ , but not sure how to proceed. To help visualize it looks like: $\frac {1} {(1)(3)(5)} + \frac {1} {(2)(4)(6)} +  \frac {1} {(3)(5)(7)} + ...$","['sequences-and-series', 'analysis']"
2134224,Differential of a Map,"I have the following map that embeds the Torus $T^2$ into $\mathbb{R}^3$: $$f(\theta, \phi)=(cos\theta(R+rcos(\phi)),sin\theta(R+rcos(\phi)), rsin\phi)$$ noting that $0<r<R$. I want to compute the differential of $f$, $f_*$, that maps $T_P(T^2)$ to $T_{f(p)}(\mathbb{R}^3)$. This topic is extremely confusing to me.  I am not sure how to really approach the problem at all.  I believe that if $v\in T_p(T^2)$, then I choose a smooth curve $g:\mathbb{R}\to T^2$ s.t. $g(0)=p$ and $g'(0)=v$, then $df(p)v=\frac{d}{dt}f(g(t))$ at $t=0$. I don't really know what to do with all this.  I don't know where to go.  If someone has a good example or a good source to look at that would help explain this problem, or if someone could help me with this problem that would be greatly appreciated. Thank you in advance.",['differential-geometry']
2134247,"What is $\mathbb{Z}[x]/(x,x^2+1)$ isomorphic to?","Consider the quotient ring $\mathbb{Z}[x]/(x,x^2+1)$. Taking the quotient by $(x)$ first, we get a ring that is isomorphic to $\mathbb{Z}$ by setting the relation $x=0$. Applying the relation, $(x^2+1)$ becomes $(1)$, so the quotient ring is isomorphic to $\mathbb{Z}/(1)=\{0\}$. Taking the quotient by $(x^2+1)$ first, we get a ring that is isomorphic to $\mathbb{Z}[i]$ by setting the relation $x^2=1$ (or equivalently, $x=i$). Applying the relation, $(x)$ becomes $(i)$, so the quotient ring is isomorphic to $\mathbb{Z}[i]/(i)\approx\mathbb{Z}$. Which approach, if either, is correct?",['abstract-algebra']
2134265,Can endpoints be local minimum?,"My textbook defines local maximum as follows: A function $f$ has local maximum value at point $c$ within its
  domain $D$ if $f(x)\leq f(c)$ for all $x$ in its domain lying in some
  open interval containing $c$ . The question asks to find any local maximum or minimum values in the function $$g(x)=x^2-4x+4$$ in the domain $1\leq x<+\infty$ . The answer at the back has the point $(1,1)$ , which is the endpoint. According to the definition given in the textbook, I would think endpoints cannot be local minimum or maximum given that they cannot be in an open interval containing themselves. (ex: the open interval $(1,3)$ does not contain $1$ ). Where am I wrong?",['calculus']
2134267,Power of a random variable and related notion of moment,"I am trying to grasp the idea of a power of a random variable, defined as a function $\Omega \to E$. In understand how a function can self-compose with itself, but I am unable to relate this to the power of random variables. I haven't been able to verify online that the referred to power is indeed the functional power, and I'm uncertain to assume so, since, as far as I understand, a self-composing function $f:X \to Y$ would require that $Y ⊆ X$, which does not hold with a RV. I am self-teaching, and so getting by on bits and pieces, thus even though I make a sincere effort not to, there might be an important thing I'm missing for which I'd greatly appreciate any reference and perhaps explanation. A related question I have concerns the moments of a RV's distribution. How can we assume an expected value for the kth power of a random variable X $E[X^k]$, or better, how can we know the specific underlying distribution of the kth powers of X, for which its first moment (expected value) would be given with $E[X^k]$? Where does this multitude arise?","['stochastic-processes', 'statistics', 'random-variables']"
2134269,How to find the maximal volume of a rectangular box given a fixed surface area?,"I am asked to find the maximal volume of a rectangular box with a fixed surface area of $150$. I would like to solve this problem using gradients/Lagrange multipliers. I have done a bit of work so far but I'm not sure if I am on the right track or how to complete the problem. I know that this box should be a cube, but I would like to show this without assuming it is true. Here is what I have so far: $Volume=V(l,w,h)=lwh$ $Surface Area=S(l,w,h)=2(lw+hw+hl)$. $\triangledown V(l,w,h)= \lambda  \triangledown S(l,w,h)$ $\triangledown V(l,w,h)=(wh)\hat{i} + (lh)\hat{j} + (wl)\hat{k}$ $\triangledown S(l,w,h)=(2w+2h)\hat{i} + (2l+2h)\hat{j} + (2w+2l)\hat{k}$ So putting this all together gives me: $(wh)\hat{i} + (lh)\hat{j} + (wl)\hat{k} =\lambda [(2w+2h)\hat{i} + (2l+2h)\hat{j} + (2w+2l)\hat{k}]$ And at this point I am not sure how to conclude that $w=h=l$ . Additionally, I see that I can look at the system of equations: $wh=\lambda2(w+h)$ $lh=\lambda2(l+h)$ $wl=\lambda2(w+l)$ $2(lh+wh+lw)=150$ But I am unsure of how to solve these.","['multivariable-calculus', 'optimization', 'lagrange-multiplier']"
2134307,Second order nonlinear differential equation $y'' = C/y^{1/2}$,"$y'' = \frac{C}{\sqrt{y}}$ How can this differential equation be solved? I would love to add details about an attempt, but I have no idea where to even start.","['ordinary-differential-equations', 'nonlinear-system']"
2134316,Closed form for $\sum\limits_{n=1}^\infty\frac{W(n^2)}{n^2}$,"Apologies if this has been asked before. I am wondering if the following series has a closed form : $$\alpha=\sum_{n=1}^\infty\frac{W(n^2)}{n^2}\tag{1}$$ where $W(x)$ is the Lambert W function . I am interested in this series as an extension of the series : $$\sum_{n=1}^\infty\frac{\ln{n^2}}{n^2}=-2\zeta'(2)=\frac{\pi^2}{3}\ln{\left(\frac{A^{12}}{2\pi e^\gamma}\right)}\tag{2}$$ since $W(x)$ is the product logarithm. Obviously $(1)$ must converge by comparison with $(2)$ since $W(x)e^{W(x)}=x$ so $W(x)e^{W(x)}<\ln(x)e^{\ln{x}}$ so $W(x)<\ln{x}$ for $x\ge1$ by monotonicity of $W(x)$. However, I am not sure what it converges to. A value (obtained by a couple of toy formal methods) is $\alpha\overset{!}{=}\sqrt{2\pi}-\frac{1}{2}$, but I do not think this is an  equality (although it is hard to tell since the series converges so slowly). Using Wolfram Alpha to sum to $10000$ terms, the partial sum appears to be $2.0142453>2.0066283=\sqrt{2\pi}-\frac{1}{2}$, but I do not know $\alpha$'s exact numerical value. Thus my question is: Is there a closed form for $\alpha$? If not, is there an expression for the error in the $\sqrt{2\pi}-\frac{1}{2}$ approximation? My attempts : (Note: I have only put the following here to show where I got the value of $\sqrt{2\pi}-\frac{1}{2}$ from; I assume that the methods are not properly correct) . In the first place, using this toy resummation formula I had derived, the formula $\int_0^\infty\frac{W(x^2)}{x^2}dx=\sqrt{2\pi}$ (derivable from $\int_0^\infty\frac{W(x)}{x\sqrt{x}}dx=\sqrt{8\pi}$ ) and the Taylor series of $W(x)$ I formally calculated $\alpha=\sqrt{2\pi}-\frac{1}{2}$. However, the given resummation formula often gives the wrong answer. I also attempted to evaluate the integral using the Abel-Plana formula (although I do not think $\frac{W(z^2)}{z^2}$ satisfies the conditions to apply it). Formally using the fact that $\lim\limits_{s\rightarrow0}\frac{W(s^2)}{s^2}=1$, I got: $$\sum_{n=1}^\infty\frac{W(n^2)}{n^2}=\int_{0}^\infty\frac{W(x^2)}{x^2}\;dx-\frac{1}{2}+i\int_0^\infty\frac{\frac{W(-t^2)}{-t^2}-\frac{W(-t^2)}{-t^2}}{e^{2\pi t}-1}\;dt=\sqrt{2\pi}-\frac{1}{2}$$ I assume that the occurrences of this incorrect value are to do with my incorrect applications of these rules missing some remainder term, but I do not know a good way of rectifying this. So my question is: does anyone know a way of evaluating $(*)$ exactly?","['lambert-w', 'sequences-and-series', 'closed-form']"
2134349,Verify the following identity by a committee-selection model,"$${n \choose 0} + {n+1 \choose 1} + {n+2 \choose 2} +\cdots + {n + r \choose r} = {n+r+1 \choose r}$$ The ""committee selection model"" is a model used to view combinations as selecting a committee from a group of people. E.g., ${15 \choose 4}$ is the number of 4-person committees that can be formed from a group of 15 people. What I'm tasked with doing is a combinatorial proof using this model--showing that the left counts the same thing as the right using the committee model.","['combinations', 'combinatorics']"
2134356,Proving that if $A$ is an $m\times n$ matrix and has rank equal to $m$ then $A$ has a right inverse.,"By a ""right inverse"" I mean an $n\times m$ matrix $B$ such that $AB = I_m$, where $I_m$ is the $m\times m$ identity matrix. So, obviously $m \leq n$ for $A$ to be of rank $m$.
I already know that if $m=n$ then $A$ is an $m$ x $m$ matrix with rank $m$ so it must be invertible. Any hints on how to prove for when $m < n$? Am I going about it wrongfully in separating the problem into two different cases?","['matrices', 'matrix-rank', 'linear-algebra']"
2134358,Counting lattice points to get results on prime density?,"Given a positive integer $n$ , the number of non-negative integer solutions to the equation $x^2+y^2=n$ depends only on the prime factorization of $n$ . In particular, only divisors which are congruent to $1\pmod 4$ will increase the number of solutions. This is because these are the primes splitting in $\mathbb{Q}(i)/\mathbb{Q}$ and the norm map sends $x+iy$ to $x^2+y^2$ . So we can read all of this information off of the coefficients of the corresponding Dedekind zeta function. Gauss's circle problem instead asks for the number of lattice points inside a circle of radius $n$ centered at the origin, so this is just summing the first $n$ coefficients of the zeta function (and multiplying by 4 to allow negative numbers. Probably I should be more careful about 0, but we're at least very close). Of course we have a decent approximation for the answer to this problem, there should be about $\pi n^2$ lattice points in the circle. Side question 1) This implies that the average coefficient of the zeta function for $\mathbb{Q}(i)$ is $\pi/4$ . Do we expect the average coefficient of general zeta functions/L functions to have some nice interpretation? Side question 2) It seems like it should be somewhat annoying but not too hard to combine these two paragraphs to show that there are infinitely many primes $1\pmod 4$ and even to get a decent approximation of the number of such primes less than a given $N$ . I know the usual proof of Dirichlet's theorem and realize this isn't so different, but it seems like the lattice counting point of view should give a different approach. Main question) How much does the above generalize? Ie, for which polynomials $f(x_1,...,x_k)$ does counting lattice points inside $f(x_1,...,x_k)=n$ as $n$ varies give information about the densities of certain primes? Conversely, which sets of prime numbers are counted by some polynomial, and does this lead to more regular behavior of these primes than we might expect? I have a few guesses about this but nothing very solid. I'd guess that polynomials arising from norm maps of number fields would tell you about the splitting of primes in that number field, so abelian extensions of $\mathbb{Q}$ would tell you about primes in specific arithmetic progressions (or sums of arithmetic progressions). I've read the book Primes of the Form $x^2+ny^2$ , so I have some idea that if the class number is greater than 1 things will get hairy, but I still hope there are some results for such fields - maybe looking at multiple polynomials at once to cover different genera?","['number-theory', 'class-field-theory', 'zeta-functions', 'prime-numbers']"
2134431,Show that the line through $C$ and $D$ is perpendicular to the diameter of the circle,"As has been shown in the figure below: $AB$ is the diameter of $\odot O$, $CE$ and $CF$ are tangent lines to $\odot O$, and $D$ is the intersection point of $AE$ and $BF$. Show that the $CD$ is perpendicular to $AB$. This is easy to prove by analytical method. I am wondering whether there is any pure geometric method. updated figure","['circles', 'tangent-line', 'euclidean-geometry', 'geometry']"
2134448,Where is the absolute value when computing antiderivatives?,"Here is a typical second-semester single-variable calculus question: $$ \int \frac{1}{\sqrt{1-x^2}} \, dx $$ Students are probably taught to just memorize the result of this since the derivative of $\arcsin(x)$ is taught as a rule to memorize. However, if we were to actually try and find an antiderivative, we might let $$ x = \sin \theta \quad \implies \quad dx = \cos \theta \, d \theta $$ so the integral may be rewritten as $$ \int \frac{\cos \theta}{\sqrt{1 - \sin^2 \theta}} \, d \theta  = \int \frac{\cos \theta}{\sqrt{\cos^2 \theta}} \, d \theta $$ At this point, students then simplify the denominator to just $\cos \theta$, which boils the integral down to $$ \int 1 \, d \theta = \theta + C = \arcsin x + C $$ which is the correct antiderivative. However, by definition, $\sqrt{x^2} = |x|$, implying that the integral above should really be simplified to $$ \int \frac{\cos \theta}{|\cos \theta|} \, d \theta = \int \pm 1 \, d \theta $$ depending on the interval for $\theta$. At this point, it looks like the answer that we will eventually arrive at is different from what we know the correct answer to be. Why is the first way correct even though we're not simplifying correctly, while the second way is... weird... while simplifying correctly?","['absolute-value', 'calculus']"
2134510,Is this definition of a Group sufficient?,"I was browsing through the questions and read one about whether defining a group as $G$ a set with certain features instead of an ordered pair $\langle G, \circ \rangle$, was abuse of language. Someone mentioned that one could also define a group as an object of the Category of Groups.
My question is: is that all one needs to say? are the group axioms implied from the category? I haven't taken Category Theory so I apologize if the question is ""stupid"".","['category-theory', 'group-theory', 'definition']"
2134519,"If$f^{-1}(x)=kx-f(x)$, then what can we say about $f$?","If $f^{-1}(x)=kx-f(x)\forall x\in\mathbb{R}$ for a strictly increasing $f$ and $k$ a constant, then what can be said about $f$? I think the answer is of the form $f(x)=x+c$, for some $c\in\mathbb{R}$. Any hints. Thanks beforehand","['real-analysis', 'functions']"
2134546,Showing the following inclusion: $\delta (A\cap B)\cap (\bar A \cup (\overline{\delta B})) \subseteq \delta A$,"The question at hand is to prove the following inclusion: $\delta (A\cap B)\cap (\bar A \cup (\overline{\delta B})) \subseteq \delta A$ for   $A,B \subset \mathbb R^n$ NOTE: For my notation, $\bar X$ is the complement of $X$ and $\delta X$ is the boundary of $X$. I can draw a picture of this and make sense of it, but I have issues showing this is true mathematically. 
One of the theorems we know is that $\delta (A \cap B) \subseteq \delta A \cup \delta B$ if that helps. Attempt at a  solution: $$\delta (A\cap B)\cap (\bar A \cup (\overline{\delta B})) \subseteq \delta A$$ $$= (\delta (A \cap B) \, \cap \, \bar A) \ \cup \ ( \ \delta(A \cap B) \cap (\overline{\delta B}))$$ $$\subseteq (\delta (A \cap B) \, \cap \, \bar A) \ \cup \ ( \ (\delta A \cup \delta B) \cap (\overline{\delta B}))$$ $$= (\delta (A \cap B) \, \cap \, \bar A) \ \cup \ ( \ (\delta A \cap \overline{\delta B}) \cup (\delta B \cap \overline{\delta B}))$$ $$= (\delta (A \cap B) \, \cap \, \bar A) \ \cup \  (\delta A \cap \overline{\delta B}) $$ But at this point, I feel lost. Perhaps I didn't approach this the right way from the beginning, or I just don't know how to continue. Any help would be greatly appreciated.","['general-topology', 'elementary-set-theory']"
2134582,Is every element on a set also a set?,"I've been trying to understand in a more formal way what a set actually is, but I have some questions. According to the axiom of regularity for every non-empty set A there exists an element in the set that's disjoint from A. That would mean that such element is also a set, right? I read here: Axiom of Regularity , that in axiomatic set theory everything is a set, I understand that natural numbers are constructed from the empty set, integers are constructed from the naturals, rationals from the integers, and reals from the rationals. I can see how every element in such sets is also a set. But, for example, in the set of all the letters of the alphabet, or the sample space of an experiment when the possible results are not numbers, or the set of my classmates; it's not clear to me how their elements are also sets. So, are they really sets? Is every element in a set also a set? Thank you","['axioms', 'elementary-set-theory']"
2134600,Show that $f_{\alpha}(t)$ is a p.d.f.,"Let $\displaystyle \phi(t)=\frac{1}{\sqrt{2\pi}}e^{-t^2/2}$,$t\in \Bbb R$ be the standard normal density function and $\displaystyle \Phi(x)=\int_{-\infty}^x\phi(t)\,dt$ be the standard normal distribution function. Let $f_{\alpha}(t)=2\phi(t)\Phi(\alpha t)$,$t\in \Bbb R$
where $\alpha \in \Bbb R$. Show that $f_{\alpha}$ is a probability density function. we have $\Phi'(x)=\phi(x)$. We have to show that $\displaystyle\int_{-\infty}^{\infty}f_{\alpha}(t)\,dt=1$. I tried by integration by-parts but I got the value is $0$. Dose there any other process or where is my mistake.? Edit : $\displaystyle \int_{-\infty}^{\infty} f_{\alpha}(t)dt= 2\int_{-\infty}^{\infty}\phi(t)\Phi(\alpha t)\,dt=2\left[\Phi(\alpha t)\int_{-\infty}^{\infty}\phi(t)\,dt\right]_{-\infty}^{\infty}-2\int_{-\infty}^{\infty}\left[\alpha\Phi'(\alpha t).\int_{-\infty}^{\infty}\phi(t)\,dt\right]\,dt=2[\Phi(\infty)-\Phi(-\infty)]-2\int_{-\infty}^{\infty}\alpha\phi(\alpha t)\,dt=\cdots=0$","['probability-theory', 'probability', 'probability-distributions']"
2134622,To find minimum value of $2\csc(2x)+\sec(x)+\csc(x)$,"To find minimum value of $$2\csc(2x)+\sec(x)+\csc(x)$$ for $x \in (0,\frac{\pi}{2})$ i converted to sin and cos so that i may reduce it to form $a\cos(x)+b\sin(x)$. I reduced it to $$\frac{\sin(x)+\cos(x)+1}{\sin(x)\cos(x)}$$ How do i proceed from here? Thanks a ton!",['trigonometry']
2134630,Is every $F_{\sigma\delta}$-set a set of points of convergence of a sequence of continuous functions?,"It is well known that if $\langle f_n:n\in\mathbb{N}\rangle$ is a sequence of continuous functions, $f_n\colon\mathbb{R}\to\mathbb{R}$, then $\big\{x\in\mathbb{R}:\lim_{n\to\infty}f_n(x)\text{ exists}\big\}$ is an $F_{\sigma\delta}$-set ( see this post ). I am asking if the converse is true, i.e., whether for every $F_{\sigma\delta}$-set $E\subseteq\mathbb{R}$ there exists a sequence $\langle f_n:n\in\mathbb{N}\rangle$ of continuous functions, $f_n\colon\mathbb{R}\to\mathbb{R}$, such that $\big\{x\in\mathbb{R}:\lim_{n\to\infty}f_n(x)\text{ exists}\big\}=E$. My attempt : I would try to prove it in two steps. (1) Given an $F_{\sigma\delta}$-set $E$, find closed sets $E^k_n$, $n,k\in\mathbb{N}$, such that $E^k_n\supseteq E^l_n$ and $E^k_n\subseteq E^k_m$ for $k\le l$ and $n\le m$, and $E=\bigcap_k\bigcup_n E^k_n$. (2) Given $E^k_n$ as above, find continuous functions $f_n\colon\mathbb{R}\to\mathbb{R}$ such that for every $x$, $x\in E^k_N$ iff $\left|f_n(x)-f_m(x)\right|\le 2^{-k}$ for all $m\ge n\ge N$. (1) would be accomplished as follows. Let $E=\bigcap_k\bigcup_n F^k_n$, $F^k_n$ closed. Let $\langle G^0_n:n\in\mathbb{N}\rangle$ consists of all elements of $\langle F^0_n:n\in\mathbb{N}\rangle$, each repeating infinitely many times. Let $\langle G^1_n:n\in\mathbb{N}\rangle$ consists of all possible intersections $F^0_i\cap F^1_j$, $i,j\in\mathbb{N}$, each repeating infinitely many times and ordered so that $G^1_n\subseteq G^0_n$ for every $n$. Similarly, let $\langle G^k_n:n\in\mathbb{N}\rangle$ consists of all possible intersections $G^0_{i_0}\cap\cdots\cap G^k_{i_k}$, $i_0\dots,i_k\in\mathbb{N}$, each repeating infinitely many times and ordered so that $G^k_n\subseteq G^l_n$ for every $n$, whenever $l<k$. This way we obtain $\bigcup_n G^k_n=\bigcap_{l\le k}\bigcup_n F^l_n$. Finally, put $E^k_n=\bigcup_{m\le n}G^k_m$. Then $\bigcup_n E^k_n=\bigcup_n G^k_n$ and hence $\bigcap_k\bigcup_n E^k_n=\bigcap_k\bigcup_n G^k_n=\bigcap_k\bigcup_n F^k_n=E$. Is that correct? And can (2) be accomplished, too?","['general-topology', 'descriptive-set-theory', 'real-analysis', 'convergence-divergence']"
2134723,Modern focus of functional analysis and operator theory?,"I have read several histories of functional analysis and operator theory, and they all focus on the importance of Hilbert's spectral theory, Frechet's metric spaces, Lebesgue integration theory, and unification work by Riesz. This work was all done about 100 years ago so I'm wondering what major advances have happened since? From reading these histories you'd get the impression that nothing of major note has happened in these fields since around 1940. So what topics do modern specialists in functional analysis and operator theory perform research in? Is it the case that all the widely applicable results were discovered 100 years ago and nowadays its all finding results in niche areas? Are there any recommendations for papers written in the last 20 years which are considered to be of major importances? What about some recent (last 5 years) papers that are worth reading?","['functional-analysis', 'reference-request', 'operator-theory']"
2134752,Existence of solution with the smallest norm in hilbert space,"Let $A: H\rightarrow H$ be a contiunuous, linear map on the Hilbert space $H$, $y\in H\setminus \left\{ 0 \right\}$ and $\lambda \in \mathbb{K}$. Show, that if the equation $\lambda x - A x=y$ has at least one solution $x=x_0$, then it has solution with the smallest norm, and this solution is nonzero and unique. I'm guessing that the Riesz representation theorem could be helpful, but I can't see how it works.","['functional-analysis', 'normed-spaces', 'hilbert-spaces']"
2134762,Is there any example of a sequentially-closed convex cone which is not closed?,I am interested in showing that a sequentially-closed convex cone is closed in order to prove a representation theorem for a pre-ordered preference relation. Thank you in advance!,"['functional-analysis', 'weak-convergence', 'topological-vector-spaces']"
2134770,Prove linear combinations of logarithms of primes over $\mathbb{Q}$ is independent,"Suppose we have a set of primes $p_1,\dots,p_t$. Prove that  $\log p_1,\dots,\log p_t$ is linear independent over $\mathbb{Q}$. Now, this implies $ \sum_{j=1}^{t}x_j\log(p_j)=0 \iff x_1=\dots=x_t=0$. I think I have to use that fact that every $q\in\mathbb{Q}$ can be written as $\prod_{\mathcal{P}}$, where $n_p$ is a unique sequence ($n_2$,$n_3$,$\dots$) with domain $\mathbb{Z}$. Here, $\mathcal{P}$ denotes the set of all integers. Now how can I use this to prove the linear independency?","['algebra-precalculus', 'real-analysis', 'number-theory']"
2134787,"Find minimal value of $abc$ if the quadratic equation $ax^2-bx+c = 0$ has two roots in $(0,1)$ [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question If $$ ax^2-bx+c = 0 $$ has two distinct real roots in (0,1) where a, b, c are natural numbers then find the minimum value of product abc ?","['algebra-precalculus', 'quadratics']"
2134792,Justify geometrically: an element and its inverse are not conjugate,Consider the group $G$ of rotations of regular tetrahedron in $\mathbb{R}^3$. We know that this group is $A_4$. We also know that a rotation of order $3$ and its inverse are not conjugate: ratation of order $3$ corresponds to a 3-cycle $(123)$ and in $A_4$ we know by algebraic arguments that $(123)$ and $(132)$ are not conjugate. Q. Is there any geometric smart way to show that a rotation of order $3$ and its inverse are not conjugate in the group of rotational symmetries?,"['finite-groups', 'group-theory']"
2134796,Are closed ball convex in a translation surface?,"Let $(X,\omega)$ be a translation surface and $x$ any point (smooth or not) in it. Let $r\in \mathbb{R}^+$ be such that it is smaller than the diameter of $(X,\omega)$. Is the closed ball $B_r(x)$ always convex? My guess is no. I tried to figure it out using a simple translation surfaces: the regular octahedron with sides identified (it has one point of conical singularity of total angle $6\pi$). Then if I'm not wrong I can find a smooth point $x$ and an $r>0$ such that the closed ball $B_r(x)$ ""overlaps"" about the singular point giving non convexity. In the figure below I've drawn the situation I mean: the ball $B_r(x)$ is the dark part of the octahedron and I drew two segments not entirely contained in it. Are my guess and my construction right? Thank you","['convex-geometry', 'riemannian-geometry', 'differential-geometry', 'convex-hulls']"
2134801,Compute $E(\sin X)$ if $X$ is normally distributed,"If $X$ is normally distributed with mean $\mu$ and standard deviation $\sigma$ what is the expected value $E[\sin(x)]$?
I think this has something to do with the characteristic function...","['statistics', 'probability', 'normal-distribution']"
2134838,Is $\bigcup_{i \in \mathbb{N}} \mathbb{N}^i$ countable? [duplicate],"This question already has answers here : The set of all finite sequences of members of a countable set is also countable (4 answers) Closed 7 years ago . I was wondering if $\bigcup_{i \in \mathbb{N}} \mathbb{N}^i$ were countable or not, where $\mathbb{N}^{i}$ means the direct product of $i$ copies of $\mathbb{N}$. I may have read that this is countable, but I think I have never seen a proof of the countability (or uncountability). The fact is that I know a countable union of countable set is countable, and I know how to prove that by using the axion of countable choice. The problem is that $\prod_{1}^{\infty} \mathbb{N}$ is not countable, and I don't know how to get rid of the problem.",['elementary-set-theory']
2134875,Definition of regular map,"I am following Shaferevich's Basic Algebraic Geometry 1.Here quasiprojective variety means open subset of a projective closed set.  He defines regular maps between quasiprojecive varities (in section 4.2) as locally $f:U\rightarrow \mathbb A_i^m$ is regular. My question is how to define regular map $f:X\rightarrow Y$, where $X$ may be open subset of $\mathbb A^n$ or closed subset of $\mathbb A^n$ or quasiprojective and $Y$ may be open subset of $\mathbb A^n$ or closed subset of $\mathbb A^n$ or quasiprojective. If both $X$ and $Y$ are closed subset of some affine space then I know $f$ is given by polynomials. But what about the other cases. I know closed subset or open subset of of $\mathbb A^n$ can be regarded as quasiprojective in $\mathbb P^n$ (after identifying $\mathbb A^n$ with one of $\mathbb A_i^n$ in $\mathbb P^n$ and by identifying I mean set theoretically, at least Shaferevich says so[Discussion after Lemma $1.1$ in section $4.1$] ). So to check the map is regular do I need to identify both $X$ and $Y$ to the subsets of $\mathbb P^n$ and $\mathbb P^m$ respectively and then check the corresponding map is regular? Let me discuss one example: I need to show $\mathbb A^1-\{0\}$ is isomorphic to $Z(T_1T_2-1)$ in $\mathbb A^2$.
Lets identify $\mathbb A^1-\{0\}$ with $X=\{(1:x) :x\in k^* \}\subset\mathbb P^1$ and $Z(T_1T_2-1)$ with $Y=\{(1:x:y):x,y\in k,xy=1\}$ so that both $X$ and $Y$ are quasiprojective varieties. Then define 
$\begin{equation}
f:X\rightarrow Y\\
(1:x)\mapsto (1:x:\frac{1}{x})
\end{equation}$ $\begin{equation}
g:Y\rightarrow X\\
(1:x:y)\mapsto (1:x)
\end{equation}$ If coordinates of $\mathbb P^1$ are $S_0, S_1$ and that of $\mathbb P^2$ are $T_0, T_1, T_2$ then $f$ is given by $1, \frac{S_1}{S_0}, \frac{S_0}{S_1}$ and $g$ is given by $1, \frac{T_1}{T_0}$. Hence $f$ and $g$ are regular and also they are inverse of each other. Is this method correct or I am making some mistake or doing this in a complicated way? Please help me to understand. Thank you","['proof-writing', 'algebraic-geometry', 'commutative-algebra']"
2134877,quotients of algebraic groups,"I starded studying Git theory, and I am stuck with the follwoing problem. Let $\textbf{Sch}$ be the category os Schemes of a field (it can be algebraically closed if needed), and $\textbf{Sets}$ be the category of sets. Let $X \in \textbf{Sch}$ and Let G be a algebraic group (G is a group object in $\textbf{Sch}$)acting on $X$. For each $T \in \textbf{Sch}$ Consider the action of $Hom(T,G)$ on Hom(T,X) as follwoing, for each morphism $g : T \to G$ and each morphism $x:T \to X$, we have  $Hom(T,G) \times Hom(T,X) \to Hom(T,X)$, $(g,x) \to (g(t)x(t))$. We say that two morphisms $x,y : T \to X$ are in the same class if there exist one $g \in Hom(T,G)$ such that $x(t) = g(t)y(t)$ for all t. Define the functor and $\mathcal{F} : \textbf{Sch} \to \textbf{Sch} $ that sends each scheme T to the set of classes of equivalences of $Hom(T,X)$ defined as before. I saw in some notes that I am not able to find that is it possible to say that the space of orbits X/G represents the functor $\mathcal{F}$, if G is a reductive group, but I am not able to find  such notes, neither prove this fact, any references are welcome. Thank you As suggested, I posted this question on Mathoverflow. https://mathoverflow.net/questions/262268/naive-question-on-quotients-of-algebraic-groups-and-moduli-spaces","['moduli-space', 'algebraic-groups', 'invariant-theory', 'algebraic-geometry']"
2134903,"Is there any mathematical reason for this ""digit-repetition-show""?","The number $$\sqrt{308642}$$ has a crazy decimal representation : $$555.5555777777773333333511111102222222719999970133335210666544640008\cdots $$ Is there any mathematical reason for so many repetitions of the digits ? A long block containing only a single digit would be easier to understand. This could mean that there are extremely good rational approximations. But here we have many long one-digit-blocks , some consecutive, some interrupted by a few digits. I did not calculate the probability of such a ""digit-repitition-show"", but I think it is extremely small. Does anyone have an explanation ?","['number-theory', 'radicals', 'decimal-expansion']"
2134942,How to find $\lim_{x\rightarrow \infty }\left ( \frac{x-2}{x-3} \right)^{x}$?,How to find the limit : $$\lim_{x\rightarrow \infty }\left ( \frac{x-2}{x-3} \right )^{x}$$ What is the approach for $1^\infty$ ?,"['functions', 'limits']"
2134965,Prove that isomorphisms are symmetric,"Prove that isomorphisms are symmetric Now if $(G, *)$ and $(H, \circ)$ are two groups. A map $\gamma : G \to H$ such that $\gamma (x * y) = \gamma(x) \circ \gamma(y)$ for all $x, y \in G$ is a homomorphism , and a bijective homomorphism is an isomorphism , and we notationally put $G \cong H$ if a isomorphism exists between $G$ and $H$. I need to prove that $G \cong H \implies H \cong G$. Now we know that $\gamma : G \to H$ is an isomorphism, and it seems like $\gamma^{-1} : H \to G$ should be an isomorphism as well. Proving that $\gamma^{-1}$ is bijective is trivial, however proving that it is an homomorphism doesn't seem to be as easy, since $\gamma^{-1}(\gamma(x * y)) = \gamma^{-1}(\gamma(x) \circ \gamma(y)) \implies (x * y) = \gamma^{-1}(\gamma(x) \circ \gamma(y))$ and since we have no idea how $\circ$ affects $\gamma^{-1}$ we can't deduce anything further. (please correct me if I'm wrong) However I found a proof online, that I'm not so sure about In the proof above how do we know that $$s_1 \circ s_2 = \phi^{-1}(t_1) \circ \phi^{-1}(t_2) \ \ \ \ \ \ \ \ (1)$$ and how do we know that the $t_1$ and $t_2$ in $(1)$ above is the same as $t_1$ and $t_2$ in equality $(2)$ below? $$\phi^{-1}(t_1 * t_2) = s_1 \circ s_2 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (2)$$","['abstract-algebra', 'group-theory', 'elementary-set-theory', 'proof-verification']"
2135008,Normed space $V$ separable $\Leftrightarrow$ unit sphere $\{x\in V: |x|=1\}$ separable,"This is my very first post on mathstack even though I have visited here a lot. I think this community is great and ""teaches"" many things that are not discussed in class, so I must thank all you active advisors here. But to the question. This is my homework problem and I would like to have comments on my proof. Let $V$ be a normed space. Show that $V$ is separable $\Leftrightarrow$ unit sphere $S=\{x\in V: \lVert x\rVert=1\}$ is separable. Proof: ""$\Rightarrow$ "": Because $V$ is metric space, then $V$ is separable $\Leftrightarrow$ $V$ is 2nd countable. Therefore $S$ inherits 2nd countability and also being metric space is thus separable. ""$\Leftarrow$"": Assume that $S$ is separable. Then it contains countable dense subset $A\subset S$ s.t. $\bar{A}=S$. Now define set $$Q=\bigcup\limits_{q\in\mathbb{Q}}qA,$$ where $qA=\{qa:a\in A\}$. $Q$ is countable union of countable sets and thus countable. We then show that $\bar{Q}=V$. Let $x\in V$. We can assume that $x\neq 0$, because $0\in Q$. Now $$\frac{x}{\lVert x\rVert}\in S.$$ Because $\bar{\mathbb{Q}}=\mathbb{R}$, there exists sequence $q_n\in\mathbb{Q}$ s.t. $q_n\rightarrow \lVert x\rVert$. Also, because $\bar{A}=S$, there exists sequence $a_n\in A$ s.t. $a_n\rightarrow \frac{x}{\lVert x\rVert}$. Then $$q_n a_n\in q_n A\subset\bigcup\limits_{q\in\mathbb{Q}}qA=Q \quad \forall n $$ and $$q_n a_n\rightarrow \lVert x\rVert\cdot \frac{x}{\lVert x\rVert}=x. $$ Therefore $x\in\bar{Q}$ and we are done (?).","['functional-analysis', 'general-topology', 'metric-spaces', 'separable-spaces']"
2135032,Two independent geometric random variables - proof of sum,"If $X$ and $Y$ are independent geometric random variables, $X \sim G(p)$ and $Y \sim G(q)$ then if $Z = X+Y$ I need to show that: $$P[Z=z] = \frac{pq}{p-q}[(1-q)^{z-1}-(1-p)^{z-1}]$$ My attempt: \begin{align}
P[Z=z] &= \sum_{k=1}^z P[X=k]P[Y=z-k] && \text{(not sure of my summation limits here)}  \\
&= \sum_{k=1}^z p(1-p)^{k-1} \cdot q(1-q)^{z-k-1} \\
&= \frac{pq}{(1-p)}\cdot \frac{(1-q)^z}{(1-q)}\cdot\sum_{k=1}^z (\frac{1-p}{1-q})^k \\
&= \frac{pq}{(1-p)}\cdot \frac{(1-q)^z}{(1-q)} \cdot \frac{1-(\frac{1-p}{1-q})^k}{1-\frac{1-p}{1-q}} \\
&= \frac{pq}{(1-p)}\cdot \frac{(1-q)^z}{(p-q)} \left[1 -(\frac{1-p}{1-q})^k\right] \\
&= \frac{pq}{p-q}\left[\frac{(1-q)^z}{1-p} - \frac{(1-p)^z}{1-p}\right]
\end{align} The result is pretty close to the answer. The only discrepancy is the first expression in the parentheses, $\frac{(1-q)^z}{1-p}$ which should be $\frac{(1-q)^z}{1-q}$ . Could someone please have a look at my working and show me where I have gone wrong? Or perhaps a neater calculation? Thanks! PS I did check similar questions answered here, but couldn't find anything relevant to my problem. Is the sum of two independent geometric random variables with the same success probability a geometric random variable? How to compute the sum of random variables of geometric distribution","['statistics', 'probability']"
2135035,How to prove $\pi^3<3^\pi$ without using explicit value of $\pi$? [duplicate],This question already has answers here : How to prove $3^\pi>\pi^3$ using algebra or geometry? (5 answers) How to prove that $3^\pi > \pi^3$ [duplicate] (4 answers) Closed 7 years ago . How to prove  $\pi^3<3^\pi$ without using explicit value of $\pi$?  In the following link I proposed similar problem and got extremely amazing explanations which uses pure geometrical ideas : How to prove: $2^\frac{3}{2}<\pi$ without writing the explicit values of $\sqrt{2}$ and $\pi$ Here too I am thinking some similar kind of idea (not involving calculus) but not getting any. Can there also be something like that?,"['elementary-number-theory', 'geometry']"
2135038,Derivative of a vector divided by its norm w.r.t a parameter,"Let say that we have the vector $V(\theta)=[-2\theta \hspace{0.2cm} \theta^2 \hspace{0.2cm} \theta^3]^T$, and the elements of $V$ are differentiable functions of $\theta$ and The norm of the vector $V$ equal to $\|V(\theta)\| = \sqrt{(-2\theta)^2 + (\theta^2)^2 + (\theta^3)^2}$. Is there a direct expression of the derivative of the following formula w.r.t the parameter $\theta$: $$ \frac{\partial}{\partial \theta} \left (\frac{V(\theta)}{\|V(\theta)\|} \right)$$","['derivatives', 'normed-spaces', 'vectors', 'calculus']"
2135044,Prove that: $\cos^2 20° + \cos^2 40° +\cos^2 80° = \sin^2 20° + \sin^2 40° + \sin^2 80°$,"Prove that: $\cos^2 20° + \cos^2 40° +\cos^2 80° = \sin^2 20° + \sin^2 40° + \sin^2 80°$ My Attempt: $$L.H.S=\cos^2 20° + \cos^2 40° + \cos^2 80°$$
$$=\dfrac {1+\cos 40}{2}+\dfrac {1+\cos 80}{2} + \dfrac {1+\cos 160°}{2}$$
$$=\dfrac {3+\cos 40°+\cos 80°+\cos 160°}{2}$$ I.could not solve further from here..",['trigonometry']
2135114,"Understanding the ""first step analysis"" of absorbing Markov chains","Consider a time-homogeneous Markov chain $\{X_n\}_{n=0}^\infty$ with the state space state space $S=\{0,1,2\}$ and the following transition probability matrix:
\begin{pmatrix} 
	 1 & 0 & 0 \\ 
	 \alpha & \beta & \gamma \\ 
	 0 & 0 & 1
\end{pmatrix}
where $\alpha,\beta,\gamma>0$. Note that state 0 and 2 are absorbing. Let
$
T=\min\{n\geq 0\mid X_n=0\textrm{ or }X_n=2\}
$
be the time of absorption of the process. It is intuitively true that
$$
P(X_T=0\mid X_1=1)=P(X_T=0\mid X_0=1)\tag{*}
$$
which is the key point of the so called ""first step analysis"". See for instance Chapter 3 in Karlin and Pinsky's Introduction to Stochastic Modeling. But the book does not bother giving a proof of it. Here is my question : How can one prove (*) using the definition of conditional probability and the Markov property?","['stochastic-processes', 'probability-theory']"
2135155,Rudin's PMA Chapter 10,"I am having a hard time trying to learn Rudin's Principles of Mathematica Analysis chapter 10 on differential forms. Please suggest a book for reference on this chapter. I would most prefer a book where there is a lot of geometric intuition. Also I don't know Vector calculus. Let me know if I need to learn that before learning this chapter. In that case suggest a book for that as well. Please take note that this is for self study.
Thanks.","['self-learning', 'real-analysis', 'reference-request', 'differential-forms', 'differential-geometry']"
2135156,The power of matrix $A$,"Let $A = \begin{pmatrix}0 & a\\ b&c\\ \end{pmatrix}$ with $a, b, c \in \mathbb{R}$. My question is that: ``How can we compute $A^n$ for any $n\in \mathbb{N}$? In fact, one had that $A^2 - cA - abI_2 = 0$ or $A^2 = cA + abI_2$. Then I obtained
\begin{eqnarray}
A^2 &=& cA + abI_2\\
 A^3 &=& (c^2 +ab)A + abcI_2\\
.....&&....................\\
\end{eqnarray}","['matrix-equations', 'matrices', 'matrix-calculus', 'matrix-decomposition', 'matrix-rank']"
2135215,Equilateral polygon inscribed within an ellipse,"Do you know of any `nice description' (say, the position of its vertices in polar coordinates) of the equilateral $n$-agons inscribed in a given ellipse? What about if one of such vertices is supposed to be in the intersection of one of the (say major) axes, does this make any difference? Thanks!","['conic-sections', 'geometry']"
2135290,Discriminant of a cyclotomic field,"If $\zeta$ is a primitive $n$ -th root of unity, prove that: $$d(1, \zeta,...,\zeta^{\varphi(n)-1})=(-1)^{\varphi(n)/2}n^{\varphi(n)}\prod_{p\mid n} p^{-\frac{\varphi(n)}{p-1}}$$ Let $n=\prod_{i=1}^{m}p_i^{e_i}$ . After looking it up in some books, I was able to understand why this is true for $m=1$ . However, they all ignored the general case $m>1$ or simply stated that it could be done by induction on $m$ , but I really can't see how it could be done. The only interesting thing I could find out was that for $n,m$ with $\gcd(n, m)=1$ , we get, on the right hand side of the equation: $$(-1)^{\varphi(nm)/2}nm^{\varphi(nm)}\prod_{p\mid nm} p^{-\frac{\varphi(nm)}{p-1}}=$$ $$\left((-1)^{\varphi(n)/2}n^{\varphi(n)}\prod_{p\mid n} p^{-\frac{\varphi(n)}{p-1}}\right)^{\varphi(m)}\left((-1)^{\varphi(m)/2}n^{\varphi(m)}\prod_{p\mid m} p^{-\frac{\varphi(m)}{p-1}}\right)^{\varphi(n)}$$ That makes me think I'm getting somewhere, but I'm stuck with the problem of showing that $d(1, \zeta,...,\zeta^{\varphi(nm)-1})=[d(1, \zeta,...,\zeta^{\varphi(n)-1})]^{\varphi(m)}[d(1, \zeta,...,\zeta^{\varphi(m)-1})]^{\varphi(n)}$ , which doesn't seem trivial at all. Any ideas? Thanks!","['number-theory', 'abstract-algebra', 'algebraic-number-theory']"
2135310,How to calculate expected value of an absolute sum,"If I have two independent variables $x$ and $y$ with a uniform distribution between -1 and 1. How would I calculate the expected value of their absolute sum. e.g. $E(|x + y|)$ I wrote some code to brute force this here https://jsbin.com/xorixa/edit?js,console The result comes out to be $2/3$ but my question is how would I go about calculating this.","['statistics', 'probability']"
2135331,"What is the basic difference between differentiable, analytic and holomorphic function?","The function $f(z)$ is said to be analytic at $z_0$ if its derivative exists at each point $z$ in some neighborhood of $z_0$ , and the function is said to be differentiable if its derivative exist at each point in its domain.
So whats the difference?","['complex-analysis', 'calculus']"
2135332,How would one justify the answer to this question on derivatives?,"I couldn't understand the solution to the following problem: Suppose a balloon of volume V and radius r is being inflated, so that V and r are both functions of the time t. If dV/dt is constant, what can be said (without calculation)
about the behavior of dr/dt as r increases? The answers page says that the answer is: dr/dt decreases as r increases. I don't really understand why that answer is true. I thought that r should has an increasing rate just like the volume, since the volume is dependent on the radius. If anyone is interested, the question is from the book Calculus and Analytic Geometry by George Simmons, page 68, section 2.4, problem no. 17
The answer is in page 859. Thanks in advance.","['derivatives', 'calculus', 'geometry']"
2135342,How do I combine standard deviations from 2 groups?,"I am abstracting data from a research study. I do not know the individual values within each group. But I have 2 groups. One with a population of 149, a mean of 37.3 and an SD of 12.8. My other group has a population of 669, a mean of 38.4 and an SD of 13.4. How do I combine the standard deviations?","['statistics', 'standard-deviation']"
2135383,What is the smallest integer with 100 non trivial factors?,"Excluding 1 and itself as factors, what is the smallest integer with 100 different factor values? Example: 20 has 4 non trivial factors (2*10 and 4*5)","['number-theory', 'factoring', 'optimization']"
2135428,"The pdf of last interval of a Poisson process in $[0,T]$","Assume a Poisson point process with rate $\lambda$ in time $[0,T]$. Supoose $X$ is the random variable representing the time between the last arrival and $T$. What is the probability density function of $X$ as $T\to \infty$? The pdf is $\frac{d}{dx}P\left(X\leq x\right)$. We can break up $P\left(X\leq x\right)$ by the number of arrivals in time $[0,T]$: \begin{align}
P\left(X\leq x\right)&=\sum_{k=1}^{\infty}Poisson(k, \lambda T)P\left(X\leq x|k   \text{ arrivals}\right)\\
&=\sum_{k=1}^{\infty}Poisson(k, \lambda T)P\left(T-T_k\leq x|k   \text{ arrivals}\right)\\
&=\sum_{k=1}^{\infty}Poisson(k, \lambda T)P\left(T-T_k\leq x|T_k \leq T <T_{k+1}\right)
\end{align} where $T_k=\sum_{i=1}^{k}A_i$ is the time $k^{th}$ arrival, and $A_i$ is the $i^{th}$ inter-arrival time. Any idea how to continue? Or, a resource that already has the answer?","['stochastic-processes', 'probability-theory', 'probability-distributions', 'probability', 'stochastic-calculus']"
2135431,How to calculate the summation $(\sum_{p = k}^{n} \binom{n}{p}) / 2^n$ quickly?,"I was solving a question which technically reduces to the following Given $N$ items, it is equiprobable for each item to be good or bad, what is the probability that number of good items in the set are greater than or equal to $K$. This can be reduced to $\dfrac{x}{2^n}$ where $\displaystyle x = \sum_{p = k}^{n} \binom{n}{p}$. Is there a more simplified form which is easier to calculate for large values of $N, K$? Note: It may be safe to assume that we do not require extremely high precision while calculating(first 5-10 digits only). Thanks!","['combinatorics', 'summation', 'probability']"
2135438,Writing sins 3s in terms of sin s,"In the reduction below, I do not understand line 4 and 6.  What identities were applied to line 3 and 5 to reach those conclusions?  How were those identities introduced? 1 ) $\sin  3a $ 2 )  $= \sin(2a +s)$ 3 )  $= \sin2a ·\cos a + \cos 2a·\sin a$ 4 )  $=(2\sin a·\cos a)\cos a + (\cos^2a - \sin^2a)\sin a$ 5 )  $= 2\sin a·\cos²a + \cos²a·\sin a - \sin³a$ 6 ) $ = 2\sin a(1-\sin²a) + (1 - \sin²a)\sin a - \sin³a$ 7 ) $ = 2\sin a - 2\sin³a + \sin a - \sin³a - \sin³a$ 8 ) $= 3\sin a - 4\sin³a$ This is important rewriting all forms of $\sin$ $n·s$ in terms  of $\sin$ $s$. All help is greatly appreciated",['trigonometry']
2135470,A smooth function can not be transformed into another smooth function without changing the value of every open interval.,"Take any $C^\infty$ (smooth) function $f: R \to R$ . For any arbitrary function $t:R\to R$ , define $g :R\to R$ as $g(x)= (t\circ f)(x)$ Conjecture : For any such $g$ , if $g$ is smooth ( $g\in C^\infty$ ), the following must necessarily hold: $(i)$ : Either: $s(x) = x$ (identity function), or $(ii)$ : There exists no open ( $O_R$ ) interval $U$ on the domain of $f, g$ , for which holds: $f(U)=g(U)$ . i.e.: $$\forall U\in O_R:\exists x\in U:f(x)\neq g(x)$$ In plain English: A smooth function cannot be transformed into another smooth function, without changing the values in all its intervals: Only isolated points may remain unchanged. Here is an incomplete argument why it seems to me must be true: Assume we have a an arbitrary smooth function $f$ , and an arbitrary function $s$ , and $g=s\circ f$ . Assume that $s$ is not the identity function (contradicting condition $i$ ), and that for some interval $(a,b)$ , $f(x)=g(x)$ for all $x\in (a,b)$ , (contradicting condition $ii$ ). Take $b$ here to be the largest $b$ , such that this holds (which is possible by the Completeness Axiom on $R$ ). Now denote by $f_n, g_n$ the $n$ th derivative of $f, g$ respectively. Since by assumption, $f$ is smooth on $b$ , we know that $$(1): \underset{\delta \to 0^-}{\text{Lim}}\left(\frac{f_{n-1}(b+\delta)-f_{n-1}(b)}{\delta}\right)=:L_{f_n}^-=L_{f_n}^+:=\underset{\delta \to 0^+}{\text{Lim}}\left(\frac{f_{n-1}(b+\delta)-f_{n-1}(b)}{\delta}\right)$$ ( $L$ will denote the limit with respect to the point $b$ ). $(2):$ Since $f$ and $g$ are identical on $(a,b)$ , we also know that $L_{f_n}^-=L_{g_n}^-$ , for all $n\in \mathbb N$ . $(3):$ Now assume (in order to derive a contradiction) that $g$ is smooth on $b$ , so that $L_{g_n}^-=L_{g_n}^+$ for all $n \in \mathbb N$ . Then using $(1,2)$ it also holds that $L_{f_n}^+=L_{g_n}^+$ for all $n \in \mathbb N$ . However, since $b$ is the largest value such that $f(x)=g(x)$ on $(a,b)$ , that means that either $f(b)\neq g(b)$ (in which case $g$ is discontinuous and not smooth, completing the proof for that case), or for some $c>b$ , it is the case that $f(x)\neq g(x)$ for all $x\in (b,c)$ . Now here comes a bit of a leap: Given that $f(x)\neq g(x)$ for all $x\in (b,c)$ , we also know that there is an interval $(b,\beta _1)$ , where $\beta_1\leq c$ , in which for all $x$ : $f_1(x)\neq g_1(x)$ . Similarly, given interval $(b, \beta_i)$ in which for all $x: f_i(x)\neq g_i(x)$ , there is an interval $(b, \beta_{i+1})$ , where $\beta_{i+1}\leq \beta_i$ , in which for all $x: f_{i+1}(x)\neq g_{i+1}(x)$ Again a leap: Hence we know that for any $n\in \mathbb N$ , there is a $\beta \in \mathbb N$ , such that for all $x\in (b, \beta), f_{n}(x)\neq g_{n}(x)$ . Hence there exists an $n\in \mathbb N$ , such that $L_{g_n}^+ \neq L_{f_n}^+$ . This contradicts $(3)$ , therefore, $g$ is not smooth. Discussion: Is this conjecture correct? Is the first part of the proof correct? Is there a way to fill in the ""leaps"" at the end? Are there better ways to prove it (or if the conjecture is false, to restate it into a correct one)? ps. note , I have no formal maths training, and I came up with this conjecture myself based on intuition, so if this is a stupid conjecture or proof, understand that.","['derivatives', 'real-analysis', 'proof-verification']"
2135474,Half iteration of exponential function,"I'm working on the half iteration of the exponential function. No one has any idea what fractional iterations could mean but I think intuitively it should be a function $f(x)$ such that $f(f(x))=e^x$. Here's how I'm finding $f(x)$ when $x\approx 0$: If $x\approx 0$, then, we have,
$$e^x\approx 1+x+\frac{x^2}{2}$$.  ...(1) Now, if we assume the required function $f(x)$ to be of the form $ax^2+bx+c$, then $$f(f(x))= a^3x^4+2a^2bx^3+(2a^2c+ab^2+ab)x^2+(2abc+b^2)x+ac^2+bc+c$$ But, since $x\approx 0$ therefore, $$f(f(x))=e^x\approx ac^2+bc+c+(2abc+b^2)x+(2a^2c+ab^2+ab)x^2$$.        ....(2) Comparing coefficients of like powers of $x$ in equation (1) and (2), we get, $$ac^2+bc+c=1 \tag {3.1}$$
$$2abc+b^2=1 \tag {3.2}$$
$$2a^2c+ab^2+ab=\frac{1}{2} \tag {3.3}$$ The problem is solving these equations. I've tried substitution but they get reduced to a polynomial of very high degree which I don't know how to solve. Is there some way to solve these to get $a$, $b$, and $c$ and hence get the required half iteration function of $e^x$ as $ax^2+bx+c$? Please tell me how to solve these three equations.","['systems-of-equations', 'function-and-relation-composition', 'functions', 'tetration', 'exponentiation']"
2135480,Denoting all the cube roots of a real number,"This may be a very simple question to ask, but I am confused with these definitions and would like to clarify here. $\sqrt{81} = 9$. But $\sqrt{81} \ne -9$ because $\sqrt{}$ is used to represent the principal root. So, If I want to represent both the roots, I have to mention it as $\pm\sqrt{81} = \pm 9$. We know every real number ($\ne 0$) has three cube roots, one real and two complex. So, if we say $\root 3 \of {27}$, it means the principal cube root, which is $3$. If so, (a) How do we indicate that we are referring to all the three cube roots
  together (like $\pm \sqrt{81}$ for square roots) 
  because $\root 3 \of {}$ refers to only principal cube root? (b) Why are there no commonly accepted guidelines to decide the principal
  cube root because in some places, it is the real number while some
  books refer it to the one in positive imaginary axis. Please help me to clear my doubts.","['number-theory', 'complex-analysis', 'notation']"
2135482,Inverse of integer matrix with determinant $\pm 1$,"Suppose we have a matrix $A = (a_{ij}) \in \operatorname{GL}_n(\mathbb{R})$ with $a_{ij} \in \mathbb{Z}$.
I need to show that $A^{-1}$ has entries in $\mathbb{Z}$ if and only if $\det(A) = \pm 1$.","['matrices', 'determinant']"
2135487,The playoff function,"The setting Let's consider a single elimination tournament with $n=2^r$ teams. Usually the playoff tree is seeded in a way that the two top teams can meet no earlier than in the finals. Top 4 can't eliminate each other before semifinals etc. The playoff bracket that guarantees these properties is the one where the top team gets paired with the last team, second with second-to-last etc. To pair the second round matchups, rank the first round pairs according to the higher seed and use the same rule. In the end the playoff tree of 16 teams should look like this: 1
(p1)    wp1
16
        (p1.2)     wp1.2
9
(p8)    wp8
8
                   (p1.3)         wp1.3
5
(p5)    wp5
12
        (p4.2)     wp4.2
13
(p4)    wp4
4
                                 (p1.4)         wp1.4
3
(p3)    wp3
14
        (p3.2)     wp3.2
11
(p6)    wp6
6
                   (p2.3)         wp2.3
7
(p7)    wp7
10
        (p2.2)     wp2.2
15
(p2)    wp2
2 With p[p] I mark a pair, a wp[p] is the winner of the pair p[p] . A good playoff tree is the one where any subtree has the same properties as described necessary for the whole tree. For example, consider this subtree in the upper tree: 3
(p3)    wp3
14
        (p3.2)     wp3.2
11
(p6)    wp6
6 The two higher seeded teams (3 and 6) as on the very opposite sides of the bracket and can only meet at the latest stage. The strongest team here (3) is paired against the weakest of these (14). The question Let's number the slots in a round from top to the bottom. Given s(A) - the seeding of team A and n - the number of teams, what will be the function that would return i - the number of slot for this team in the bracket. What would be the inverse function (given slot number, return the teams seed - useful to find the opponent). Examples In a round of 16 ( n=16 ) we must place team with seed s=13 in the bracket. The slot number must be i=7 - that team must be the first in the 4th pair. For the inverse function, given that we placed s=13 in the 4th pair, we must find the opponent which will be the second team in that pair. So, given n=16 and the slot number i=8 we must get s=4 - seed of the 13s opponent. I am looking for a function that would be applicable for arbitrary n instead of hardcoding the seed-slot relations for limited number of n values. A note This is a problem that is usually solved programmatically either by hardcoding an ordering or by an iterative process. I am interested if it's replacable with a single mathematical function that you could plug in a number and get another one out for any n . The relation between seeds and slots is a uniquely (if you always start with 1st seed) defined bijection so obviously you could just say that the function exists and let's call it pOff(s) . As you could probably guess, I am interested if this function is expressable with another, previously defined functions (special functions, complex numbers etc. is ok if necessary).","['functions', 'discrete-mathematics']"
2135511,How to find this integral...,$$\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}e^{-\left(3x^2+2\sqrt2xy+3y^2\right)}dxdy$$ I have no idea how to integrate this function. If the middle $xy$ term would not have been present it would have been easy. But the $xy$ term is causing a problem.,"['calculus', 'multivariable-calculus', 'improper-integrals', 'integration', 'definite-integrals']"
2135514,"In how many ways can we roll a red die, a yellow die, and a black die, and get a sum of $9$?","I know I can use generating functions. Each of the die has a generating function $x+x^2+x^3+x^4+x^5+x^6$, and so I need to find the coefficient of $x^9$ in the generating function of their sum, $(x+x^2+x^3+x^4+x^5+x^6)^3$. I am not sure how to do this, however, short of expanding it all out. (I'm not just trying to get the answer but also the method behind it. Thanks a lot.)","['generating-functions', 'combinatorics']"
2135521,basis of sum of 2 vector spaces,"Let $V=\{(x,y,z)\epsilon \mathbb R^3: x-y=z\}$ and $W=\{(x,y,z)\epsilon \mathbb R^3: x+z=2y\}$ subspaces of $\mathbb R^3$. Show that $V+W= \mathbb R^3$. Also check if the sum is direct, $V \oplus W= \mathbb R^3$. At first i found the basis of $V$ and $W$ which are $V=<(1,1,0),(1,0,1)>$ and  $W=<(2,1,0),(-1,0,1)>$. By definition the sum is $V+W=<x_1,x_2,x_3,x_4>$ where $x_1,x_2$ is the vectors of $V$ and $x_3,x_4$ the vectors of $W$. Then, i put the vectors on a matrix and proceeded to gauss elimination and i got an equation between $x_1,x_2,x_3,x_4$ equals $0$ but i don't know how to proceed from this point. Any help will be appreciated.","['linear-algebra', 'vectors']"
2135522,Does there exist a factorization consisting of polynomials of $x^4+3x^2+6$,So as I understand it every polynomial with real coefficients should have a factorization consisting of polynomials of degree one(In case of real roots) and degree two(complex roots). But I have been unable to find such a factorization of the polynomial $x^4+3x^2+6$. Even using gp and Mathematicas Factor function I only get the original polynomial as an answer. So my question is. Does there exist a factorization?,"['radicals', 'polynomials', 'complex-numbers', 'factoring', 'algebra-precalculus']"
2135532,"Find the function $f$, given that $ f'(x) = f(x)(1-f(x))$ and that $f(0) = \frac12$","Find the function $f$, given that $$f'(x) = f(x)(1-f(x))$$ and that $f(0) = \frac12$ The answer is $$y = \frac{1}{1+e^{-x}}$$ What I tried doing is changing $f'(x)$ as \frac{dy}{dx} and all the $f(x)$ as $y$ to make it easier to read for myself. Manipulating the equation. I got $$\left(y + \frac1y\right)dy = 1dx$$ but when I integrate I'm not getting the correct answer, I'm pretty sure I'm doing this incorrectly. Any advice?","['derivatives', 'integration', 'calculus']"
2135536,Why does the gradient commute with taking expectation?,"Let $X, Y$ be two random variables, with $X$ taking values in $\Bbb R^n$ and $Y$ taking values in $\Bbb R$. Then we can look at the function $h: \Bbb R^n \to \Bbb R$ given by $$\beta \mapsto \Bbb E[(Y-X^T\beta)^2]$$ It is claimed that the gradient of $h$ is given by $$\nabla h = \Bbb E[2X(X^T\beta-Y)]$$ This seems like a special case of the identity $$\nabla \Bbb E[f]=\Bbb E [\nabla f]$$ Where the expectation is taken over the mutual distribution of some random variables. Formally, We want the following: Suppose $X_1,...,X_m$ are random variables returning values in some sets $A_i$ with some given mutual probability distribution. Then for every function $f: \Bbb R^n \times \prod A_i \to \Bbb R$, for every $\beta \in \Bbb R^n$ we can form the random variable $f(\beta, X_1,...,X_m)$ and take its expectation. Taking different values of $\beta$ gives rise to a function $\Bbb R^n \to \Bbb R$. We claim that its gradient is equal to the vector obtained by first fixing the values of $X_1,...,X_m$ and taking the gradient of the resulting function $\Bbb R^n \to \Bbb R$, and this gives a random variable returning values in $\Bbb R^n$, for which we can take the expectation.","['multivariable-calculus', 'probability-theory', 'expectation', 'vector-analysis']"
2135549,Implicit function theorem exercise with higher derivatives,"Consider the equation $e^{xz}+y-z=e$. Using the implicit function theorem shows $z$ is a smooth function of $x,y$ about $(1,1,1)$. I needed to calculate a directional derivative of $z$ at $(1,1)$ and managed that using the implicit function theorem to recover the gradient of $z$. Now I'm asked whether the partial derivatives of $z$ are symmetric about $(1,1)$ and furthermore, I need to calculate them. I think the partial derivatives are symmetric because the original function $e^{xz}+y-z=e$ is smooth, which means so is $z=z(x,y)$. I don't understand however how to find second order derivatives. The ""formula"" $$\frac{\partial z}{\partial x}=-\frac{\frac{\partial f}{\partial x}}{\frac{\partial f}{\partial z}}$$ (read with matrix inverse instead of quotient in matrix case) does not really make sense before it's evaluated at a point, since the RHS has additional variables. So how to find $\frac{\partial ^2z}{\partial x\partial y}(1,1)$?","['multivariable-calculus', 'implicit-differentiation', 'implicit-function-theorem', 'calculus']"
2135592,Martingales composed with stopping times,"Let $(\Omega, \mathcal{F}, (\mathcal{F}_t),P)$ be a filtered probability space and $M_{t}$ be a continuous-time martingale. Suppose $\tau: \Omega \to \mathbb{R}$ is a stopping time with respect to $\mathcal{F}_t$. One often sees the composed functions $M_\tau : \Omega \to \mathbb{R}$, given by $M_{\tau}(\omega) = M_{\tau(\omega)}(\omega)$ being treated as random variables, but why are they measurable? Thanks.","['probability', 'martingales']"
2135635,Limit of function which is product of $x^x $ primitives,"I'm trying to analytically derive the following limit: $$ \lim_{x\to \infty}\left(\frac{1}{8}\right)\left(e^{1-\frac{\sqrt{x}}{2}}\right)\left(\frac{x}{x-\frac{\sqrt{x}}{2}+1}\right)^{x-\frac{\sqrt{x}}{2}+1} $$
I've found it extremely difficult because, as you apply L'Hospital's rule, you need to differentiate $x$ times, thus getting an infinite chain of differentiations (each one invoking the product rule). WorlframAlpha says the limit is equal to $\frac{1}{8e^{1/8}}$ which seems to match perfectly the numerical estimates I've made with my computer up to $x=2\times10^4$, but it gives no explanation for how it derives this result. How can I analytically evaluate this limit? On it's face, it seems intractable. Yet there appears to be an analytical solution. The purpose of evaluating this limit is to calculate the following limit of a combinatorial probability:
$$\lim_{N\to\infty}\left(\frac{M^2(N!)}{2N^M(N-M+1)!}\right)$$
Where $M=\frac{N^{1/2}}{2}$. The original limit above can be found by applying Sterling's Approximation on the second limit. If anyone is aware of any alternative techniques for analytically evaluating this second limit, that would be just as helpful.","['combinatorics', 'probability', 'calculus', 'limits']"
2135675,Two interesting results in integration $\int_{0}^{a}f(a-x) \ \mathrm{d}x= \int_{0}^{a}f(x)\ \mathrm{d}x$ and differentiation of powers of functions,"I am investigating the following result in integration $\displaystyle\int_{0}^{a}f(a-x) \ \mathrm{d}x = \int_{0}^{a}f(x) \ \mathrm{d}x \ \ \ (*)$ This neat little result forms the basis for many questions in calculus exams, often then asking one to evaluate something like
$\displaystyle\int_{0}^{\frac{\pi}{2}}\frac{\sin^n x}{\sin^n x + \cos^n x} \ \mathrm{d}x$ where $n$ is a positive integer. The process of solving this integral isn't too challenging, and is almost immediate from $(*)$. My question is this: can anyone think of any more challenging integrals out there (possibly requiring some clever substitution, integration by parts etc.) that $(*)$ can help solve? UPDATE I also came across another identity involving differentiation: $\displaystyle \frac{\mathrm{d}}{\mathrm{d}x}(u(x))^{v(x)} = (u(x))^{v(x)}\left(\frac{\mathrm{d}v(x)}{\mathrm{d}x}\ln u(x) + \frac{v(x)}{u(x)}\frac{\mathrm{d}u(x)}{\mathrm{d}x}\right)$. This is another identity that can be used to solve integrals, but I am again unable to find any creative examples, so if anyone could suggest some I'd be happy to give them a go.","['integration', 'calculus']"
2135708,"When ""Set of complements"" is equal to ""Complement of set""?","Consider $A \subset \{0,1\}^n$ I want $A$ to have $2$ properties. $1.$ $A$ is increasing, i.e., If $x \in A$ and $x \subset y$ then $y \in A$ too. $2.$ $A^c$ is equal to set $B=\{x | x^c \in A\}$ Is there any characterization for such a set? I have to example for it. But I want to find an IFF condition for such sets... $e1)$ $A=\{x|$ first coordinate of $x$ is  $1\}$ $e2)$ Fix an odd number of coordinates. $A= \{x| x$  contains at least half  of coordinates equal to $1\}$
[For even number there is a similar example]","['combinatorics', 'lattice-orders', 'elementary-set-theory', 'discrete-mathematics']"
2135710,"Elliptic functions - proof non-constant function, finitely many zeros and poles.","I have questions on the attached lemma and proof. $f(z)$ is an elliptic function here, $\Omega$ is a period lattice. 
So the idea behind the proof is this is a contradiction because the function was assumed to be non-constant but by the theorem that if f is analytic in a region $R$ with zeros at a sequence of points $a_i$ that tend to $a_0$ $\in R$, then $f$ is identically zero in $R$. Questions - mainly I don't understand where the consruction of the sequence comes from which of the conditions out of the three: bounded, closed, infinitely many zeros, means that a convergent sequence of zeros can be constructed? I don't understand the reasoning behind the sequence, and does it make use of the fact of the periodicity of $f(z)$? I'm guessing this sequence would not be possible to construct if there were only finitely many zeros for the proof to work...? When it argues that by continuity $f(a_0)=0$, we have that $\Omega$ has inifnitely many zeros as our assumption, but we haven't said anything about poles? We haven't disallowed poles, and this means the region is not analytic so not continous and so the limit may not neccessary exist? Many thanks in advance","['periodic-functions', 'elliptic-functions', 'complex-analysis', 'proof-explanation', 'sequences-and-series']"
2135723,How to define a product space probability using a mixture of probabilities?,"Let $(\Omega, \mathcal{F})$ be a measurable space, and let $P, P_1, P_2,...$ be probability measures on this space with $P = \sum_{n=1}^\infty a_n P_n$, where $a_n > 0$ and $\sum_{n=1}^\infty a_n = 1$. I want to define a probability measure on the product space $\Omega \times \mathbb{N}$. If $\Omega$ is countable, I can easily verify that $Q$ defined by 
$$Q(\omega, n) = a_nP_n(\omega)$$
is a probability on $\Omega \times \mathbb{N}$. But now suppose $\Omega$ is not countable. As usual, we equip $\Omega \times \mathbb{N}$ with the sigma-algebra $\mathcal{F} \times \mathscr{P}(\mathbb{N})$ generated by the semi-algebra $\mathcal{S} = \{F \times N: F \in \mathcal{F}, N \in \mathscr{P}(\mathbb{N}) \}$ of measurable rectangles. I want to proceed as in the countable case and define $Q$ on $\mathcal{S}$ by 
$$Q(F \times N) = \sum_{n \in N}a_nP_n(F).$$
Now, in order to uniquely extend $Q$ to $\mathcal{F} \times \mathscr{P}(\mathbb{N})$, I just need to show that $Q$ is countably additive on $\mathcal{S}$ (or finitely additive and countably sub additive, but I was hoping I could just show countable additivity.) Let $F \times N \in \mathcal{S}$ be a countable disjoint union $\cup_{j \in J} F_j \times N_j$ of measurable rectangles. We need to show that 
$$Q(F \times N) = \sum_{j \in J}Q(F_j \times N_j).$$ I have convinced myself that we can reduce to the case where each $N_j$ is a singleton $\{ n_j\}$. But now I find myself stuck. I've tried playing around with the indices, but I can't seem to make progress. Question. Can you please give me a hint or a suggestion for how to proceed? My feeling is that this should be very easy and I'm missing something fairly obvious. Somehow I think we can assume without loss of generality that $\cup_{j \in J}F_j \times N_j$ is of the form $\cup_{n \in N}F \times \{n\}$. If that's so, countable additivity follows by two applications of the definition of $Q$:
$$Q(F \times N) = \sum_{n \in N}a_nP_n(F) = \sum_{n \in N}Q(F \times \{n\}).$$ Here's my idea for reducing the problem. First, as above, I think I can show that it's sufficient to assume that $N_j$ in $\cup_{j \in J}F_j \times N_j$ is a singleton $\{n_j\}$, with $n_j \in N$. Next, we can assume that each $n_j$ is unique. If not, and $n_j = n_k = n$, then we write $F_n = F_j \cup F_k$ where the union is disjoint. So we reduce to the case where $\cup_{j \in J}F_j \times N_j$ is of the form $\cup_{n \in N}F_n \times \{n\}$. Finally, since by assumption $F \times N \in \mathcal{S}$, we have $F \times N = \cup_{n \in N} F \times \{n\}$. So by the previous paragraph 
$$\cup_{n \in N}F \times \{n\} = \cup_{n \in N} F_n \times \{n\},$$
which implies that $F_n = F$ for all $n \in N$ and completes the reduction. Does this work?","['probability-theory', 'probability', 'measure-theory']"
2135755,Consistency proof of the M-estimator when our parameter space is no longer compact?,"Suppose that we have a parameter space $\Theta$ that is NOT compact. The M-estimator is defined to be $\widehat{\theta}_{n}$ which maximizes $M_{n}\left(\theta\right)=\sum_{i=1}^{n}m_{\theta}\left(X_{i}\right)$
and $\theta^{*}$ maximizes $M\left(\theta\right)=\mathbb{E}\left[m_{\theta}\left(X\right)\right]$,
for some functions $m_{\theta}$ and $X_{1},\ldots,X_{n}$ random
variables i.i.d. from a pdf $f$. The expectation $\mathbb{E}$
is with respect to $f$. Assume that there exists a compact
set $S\in \Theta$ such that $\theta^{*}\in X$ and \begin{equation}
\mathbb{E}\left[\sup_{\theta\in\mathcal{\Theta}\cap S^{c}}m_{\theta}\left(X\right)\right]<M\left(\theta^{*}\right).\label{eq:lessinexpect}
\end{equation}
How can we show that almost surely, $\widehat{\theta}_{n}$ is in the compact set $S$?","['probability-theory', 'estimation', 'probability', 'parameter-estimation']"
2135789,"$SL(2;\mathbb{R})$ $SO(2, 1;\mathbb{R})$ isomorphism","In all the texts about the $SL(2;\mathbb{R})$ group, people discuss the transformations of the upper half-plane. Is it legitimate, instead, to think of $SL(2;\mathbb{R})$ as simply of $SO(1,2; \mathbb{R})$? Then there must be a way to explicitly construct the isomorphism between them, right? If someone can provide such a construction, I would also appreciate explaining why, contrary to the $SU(2)$ vs. $SO(3;\mathbb{R})$ case, it is isomorphism but not $2\to1$ homomorphism.","['group-theory', 'group-isomorphism', 'lie-groups']"
