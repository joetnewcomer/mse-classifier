question_id,title,body,tags
1837919,Continued fraction $1 + \frac 2{3 + \frac 4 {5 + \cdots}} = \frac 1 {\sqrt{e} - 1}$?,"I saw this link (written in Japanese) and found an interesting problem: Calculate $1 + \frac 2{3 + \frac 4 {5 + \cdots}}$. The link provides the answer ($\frac 1 {\sqrt e - 1}$) and a hint that one uses Maclaurin series, but doesn't provide a detailed answer. Can someone explain this equality? If possible, can someone also calculate $1^2 + \frac {2^2}{3^2 + \frac {4^2} {5^2 + \cdots}}$ and $1^n + \frac {2^n}{3^n + \frac {4^n} {5^n + \cdots}}$? These two are also in the link, and answers of them are not provided and seem unsolved. Answer of Continued fraction for $\frac{1}{e-2}$ might help.","['number-theory', 'continued-fractions', 'elementary-number-theory']"
1837921,Numbers on a circle: how many arc sums can be positive?,"There are $n$ real numbers, $a_1,\dots,a_n$, arranged on a circle. Given a fixed integer $k<n$, let $S_i$ be the sum of the $k$ adjacent numbers starting at $a_i$ and counting clockwise, like this (illustrated for $k=3$): The sum of all $n$ numbers is $0$. What is the largest possible number of strictly-positive $S_i$? Here are some lower bounds: If $k\leq n/2$, then at least $n-k$ sums can be positive, e.g. when $a_1 = \cdots = a_{n-1} = 1$ and $a_n = -(n-1)$. There are $n-k$ sums that do not contain $a_n$, and they are positive. If $k\geq n/2$, then at least $k$ sums can be positive, e.g. when $a_1 = \cdots = a_{n-1} = -1$ and $a_n = +(n-1)$. There are $k$ sums that contain $a_n$, and they are positive. And here are some upper bounds: If $n$ is even and $k=n/2$, at most $n/2$ sums can be positive. This is because, if a certain sum $S_i$ is positive, then its complement sum $S_{i+k}$ must be negative (since $S_i+S_{i+k}=0$). If $k=n/3$, then at most $2n/3$ sums can be positive, since if $S_i$ and $S_{i+k}$ are positive, then $S_{i+2k}=-(S_i+S_{i+k})$ must be negative. Similarly, if $k=n/a$ for some integer $a$, then at most $(a-1)n/a$ sums can be positive. What is the general answer as a function of $k$?","['combinatorics', 'summation', 'elementary-number-theory']"
1837953,Distributional equality,"Let $(W_t)_{t\geq0}$ be a standard Brownian motion. I have to show that the following equality holds in distribution. Does someone has a good hint to show this?
$\sup_{t \geq 0}( |W_t| -t) = \sup_{t \geq 0} \left( W_t \cdot \frac{1}{1 + t} \right)^2$ Is there something particular to use to deal with the square on the RHS?
Any help is appreciated. Thanks More general result (point 1°) for p):","['stochastic-processes', 'probability-theory', 'brownian-motion', 'probability-distributions']"
1837979,What is $\mathop {\lim }\limits_{x \to 0} \frac{{\tan 2x + \tan 4x - \tan 6x}}{{{x^3}}}$? . [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question What is $\mathop {\lim }\limits_{x \to 0} \frac{{\tan 2x + \tan 4x - \tan 6x}}{{{x^3}}}$?",['calculus']
1837999,Minimal value of probability according to the difference of a Levy-process,"Can we conclude for a Levy-Process, that for all $\epsilon>0$ it holds that 
$\min_{s\in [0,t]} \mathbb P\left(\left|X_t-X_s\right|\leq \epsilon\right)>0$? Stochastic continuity doesn't seem to work, and the infinite divisibility property of $X_t$ may be useless since from the triangle inequality of $|\cdot|$ we get an estimate of the upper bound.","['stochastic-processes', 'probability-theory', 'probability', 'levy-processes', 'stochastic-calculus']"
1838002,Finitely generated projective modules over polynomial rings with integral coefficients,"There is famous Quillen-Suslin theorem which states that every finitely generated projective module over a ring of polynomials $k[x_1,...,x_n]$, where $k$ is a field, is free. I have never carefully read a proof of this theorem, which is for example in the Lang's Algebra . Probably it is based on Quillen's original ideas. - this is not true as it was pointed out in the answer below. Questions: Is every finitely generated projective modules over $\mathbb{Z}[x_1,...,x_n]$ free? If yes, then is the proof modification of the one given in Lang's Algebra ? And if yes, then how about polynomial rings over other Dedekind domains or number rings?","['modules', 'homological-algebra', 'algebraic-geometry', 'commutative-algebra']"
1838006,Why Differential Forms on Riemann surfaces?,"I am working with Rick Miranda's ""Algebraic Curves and Riemann Surfaces"". Right now I am in chapter four ""Integration on Riemann Surfaces"" and struggle with it a lot!:( It starts with the definition of holomorphic 1-forms which is as follows: Definition: A holomorphic 1-form on an open set $V\subset \mathbb C$ is an expression $\omega$ of the form $$\omega=f(z)\text{dz}$$ where $f$ is a holomorphic function on $V$. We say that $\omega$ is a holomorphic 1-form in the coordinate z. -- The main problem for me is now that i can't really work with this expression. What is $\omega=f(z)\text{dz}$? Why should we define something like this/ what is the benefit from that? We already have a notion for the integral of a function on submanifolds. Why we should not apply this here? Because of this open question I am not able to understand the definitions which come later for example the following two: Definition: A $C^{\infty}$ 1-form on an open set $V\subset \mathbb C$ is an expression $\omega$ of the form $$\omega=f(z,\overline{z})\text{dz}+g(z,\overline{z})\text{d}\overline{\text{z}}$$ where $f$ and $g$ are $C^{\infty}$ function on $V$. We say that $\omega$ is a $C^{\infty}$ 1-form in the coordinate $z$. I think my problems with this definition are the same as above. Definition: A $C^{\infty}$ 2-form on an open set $V\subset \mathbb C$ is an expression $\eta$ of the form $$\eta=f(z,\overline{z})\text{dz}\wedge\text{d}\overline{\text{z}}$$
where $f$ is a $C^{\infty}$ function on $V$. We say that $\eta$ is a $C^{\infty}$ 2-form in the coordinate $z$. My additional problem/question here is: What is $\wedge?$. At this point its the first time that the author introduces this symbol. I would be very very glad if someone can make this clear for me. I appreciate any kind of help.","['riemann-surfaces', 'abstract-algebra', 'complex-analysis', 'riemannian-geometry']"
1838013,"Showing that for $f \in K[x]$, we have $f(x) \mid f(x + f(x))$","Let $K$ be a field an $f \in K[x]$. I now want to show that $f(x) \mid f(x + f(x))$ (in $K[x]$). I know that I need to find a polynomial $g \in K[x]$ so that $f(x) g(x) = f(x + f(x))$. So I thought that if we start with $f(x) = a_n x^n + \dots + a_1 x + a_0$, then if we simply substitute $x$ by $x + f(x)$, we get $f(x + f(x)) = a_n (a_n x^n + \dots + a_1 x + a_0 + x)^n + \dots + a_1 (a_n x^n + \dots + a_1 x + a_0 + x) + a_0$ which doesn't look all that friendly to work with. I don't really know how to continue at this point, and if this approach does lead anywhere.","['abstract-algebra', 'polynomials', 'divisibility']"
1838034,Lipschitz continuity of $\sqrt{A}$,"Let $U \subset\mathbb{R}^n$ be an open set, $\mathbb{S}^n$ be the set of all $n\times n$ symmetric real matrices, $A:U\to \mathbb{S}^n$ be a uniformly Lipschitz continuous function. Suppose $\exists \lambda>0$ s.t. $\forall x\in U, \xi\in\mathbb{R}^n$ $\ ^t\xi A(x)\xi\geq\lambda|\xi|^2$. Then we can define $A^{1/2}:U\to \mathbb{S}^n$, which is the nonnegative sqrt of A at each point. Then is $A^{1/2}$ also uniformly Lipschitz continuous? If it holds, how to prove it?","['matrices', 'linear-algebra', 'calculus']"
1838035,Mean continuity of gradient,"Let $f:\mathbb R^n\longrightarrow R$ be a differentiable function, and suppose $\nabla f$ is bounded. Prove that $$\lim_{r\to 0}\frac{1}{\omega_n r^n}\int_{B_r(x)}[\nabla f(y)-\nabla f(x)] dy=\underline{0}.$$
  Show also that $$\lim_{r\to 0}\frac{1}{\omega_n r^n}\int_{B_r(x)}|\nabla f(y)-\nabla f(x)| dy=0$$ is not necessarily true. In one variable the first statement is straightforward. I tried the spherical-coordinates-change of variables, but id doesn't seem to work easy (recall that $f$ is not necessarily $C^1$). Like always, simple suggestions of useful tools are welcome too. Thank you in advance.","['multivariable-calculus', 'integration', 'derivatives']"
1838066,Irreducible elements for a commutative ring that is not an integral domain,"Why does the definition of an irreducible element require us to be in an integral domain? Why can we not define an irreducible element exactly the same in a commutative ring that is not an integral domain? We have that an element is irreducible if it cannot be written as a product of two non-unit elements. Unit elements are well defined and unique in a commutative ring that is not an integral domain, so I cannot see that being the problem. I've proven a proposition of my own design (probably well known and elementary, an definitely trivial). I used irreducible elements, but otherwise nothing that requires me to move from a commutative ring to an integral domain. Do irreducible elements really require me to be in an integral domain?","['abstract-algebra', 'integral-domain', 'commutative-algebra']"
1838105,Consequence of Riesz Representation Theorem from Rudin RCA,It's Riesz Representation Theorem from Rudin's book. In the following chapter I met the following example: It's obvious that $\sigma$-compact set has the  $\sigma$-finite measure. But how to prove strictly if $E\in \mathfrak{M}$ and $E$ has $\sigma$-finite measure then $E$ is inner regular? Rudin wrote that it's easy. But I tried and thought about this and no results. How to prove that for any $\alpha$ with $\alpha <\mu(E)$ exists compact set $K\subset E$ such that $\mu(K)>\alpha$? If we show this then problem will be solved.,"['general-topology', 'riesz-representation-theorem', 'real-analysis', 'measure-theory']"
1838109,What is the first square in the sequence $4729494n+1$?,"Today I found a strange phenomenon that I want to ask about. If  $$f(n)=4729494n+1,$$
is square, where $n$ is positive integers. Then I found $n=4729492$, because  $$f(4729492)=4729493^2$$
In fact, note $$(x-1)(x+1)+1=x^2$$ Now  I conjecture: $$n_{\min}=4729492?$$","['number-theory', 'square-numbers']"
1838116,The other $47$ roots of the minimal polynomial for $\cos 1 ^\circ$,"The minimal polynomial for $x=\cos 1 ^\circ=\cos \frac{\pi}{180}$ is: $$281474976710656 x^{48}-3377699720527872 x^{46}+18999560927969280 x^{44}- \\ -66568831992070144 x^{42}+162828875980603392 x^{40}-295364007592722432 x^{38}+ \\ +411985976135516160 x^{36}-452180272956309504 x^{34}+396366279591591936 x^{32}- \\ -280058255978266624 x^{30}+160303703377575936 x^{28}-74448984852135936 x^{26}+ \\ +28011510450094080 x^{24}-8500299631165440 x^{22}+2064791072931840 x^{20}- \\ -397107008634880 x^{18}+59570604933120 x^{16}-6832518856704 x^{14}+ \\ +583456329728 x^{12}-35782471680 x^{10}+1497954816 x^8- \\ -39625728 x^6+579456 x^4-3456 x^2+1$$ It obviously has $48$ roots, but since it's even we only need to consider $24$ positive roots. One is $x=\sin 1 ^\circ=\cos(\frac{\pi}{2}-\frac{\pi}{180})=\cos \frac{89\pi}{180}=\cos 89 ^\circ$. It seems that all the other roots are made using numbers of degrees $<90$, which share no common divisors with $180$: $$x=\cos \alpha ^\circ$$ $$\alpha=\{1,7,11,13,17,19,23,29,31,37,41,43,47,49,53,59,61,67,71,73,77,79,83,89 \}$$ What is the general algebrac reason for this? How does this rule work for other trigonometric functions of rational multiplies of $\pi$? If, in general, we find a polynomial for the following number: $$y=\text{trig} \frac{p}{q} \pi $$ Where $\text{trig}=\{ \sin, \cos, \tan  \}$, $p,q$ - integers, then what will the other solutions be?","['polynomials', 'abstract-algebra', 'roots', 'trigonometry']"
1838133,Does $\forall v ( T_1 v = 0 \lor T_2 v = 0 \lor \dots \lor T_n v =0 )$ imply $T_1 = 0 \lor T_2 = 0 \lor \dots \lor T_n = 0$?,"Let $V$ and $W$ be vector spaces and $T_1$, $T_2$, $\dots$, $T_n$ be linear transformations from $V$ to $W$, such that for every $v$ in $V$, either $T_1 v = 0$, $T_2 v = 0$, $\dots$ or $T_n v = 0$. Can we conclude that $T_1 = 0$, $T_2 = 0$, $\dots$ or $T_n = 0$? My attempt: I could prove the statement for $n = 2$ but I couldn't generalize it, and I also couldn't find any counterexample for greater $n$. For $n = 2$, suppose $T_1 \ne 0$ and $T_2 \ne 0$. Hence there are $u$ and $v$ in $V$ such that $T_1 u \ne 0$ and $T_2 v \ne 0$. By hypothesis, we must have $T_1 v = 0$ and $T_2 u = 0$ which yield $T_1 ( u + v ) \ne 0$ and $T_2 ( u + v ) \ne 0$, contradicting the hypothesis. I also noted that my argument for $n = 2$ can be reformulated if $V$ and $W$ were just groups and $T_1$ and $T_2$ were group homomorphisms. So I got interested in the more general problem about groups. (This is in fact another question about which I'm less concerned in this particular post.)","['abstract-algebra', 'group-homomorphism', 'linear-transformations', 'group-theory', 'linear-algebra']"
1838157,Closed form for $\prod\limits_{l=1}^\infty \cos\frac{x}{3^l}$,Is there any closed form for the infinite product $\prod_{l=1}^\infty \cos\dfrac{x}{3^l}$? I think it is convergent for any $x\in\mathbb{R}$. I think there might be one because there is a closed form for $\prod_{l=1}^\infty\cos\dfrac{x}{2^l}$ if I'm not wrong.,"['infinite-product', 'trigonometric-series', 'calculus', 'closed-form', 'sequences-and-series']"
1838161,Prove by induction $3+3 \cdot 5+ \cdots +3 \cdot 5^n = \frac{3(5^{n+1} -1)}{4}$,My question is: Prove by induction that $$3+3 \cdot 5+ 3 \cdot 5^2+ \cdots +3 \cdot 5^n = \frac{3(5^{n+1} -1)}{4}$$ whenever $n$ is a nonnegative integer. I'm stuck at the basis step. If I started with $1$. I get the right hand side is $18$ which is clearly not even close. It says prove shouldn't it be always true?,"['algebra-precalculus', 'induction', 'summation', 'geometric-progressions', 'discrete-mathematics']"
1838162,Quotient of two Gaussian densities,"The matrix cookbook contains formulas for the product of two multivariate Gaussians, but doesn't appear to contain formulas for the quotient of two Gaussians. $$
\frac{\mathcal{N}(\mathbf{m}_1, \Sigma_1)}{\mathcal{N}(\mathbf{m}_2, \Sigma_2)} = ~??
$$ Note that I'm not looking for the quotient of two random variables ( answered here ), I just care about the quotient of two PDFs. Context: I'm trying to derive factor analysis from Roweis and Ghahramani (1999) . They apply Bayes rule: $$
p(\mathbf{x} \mid \mathbf{y}) = \frac{p(\mathbf{y} \mid \mathbf{x}) p(\mathbf{x})}{p(\mathbf{y})} \\
=\frac{\mathcal{N}(C\mathbf{x}, R)\mathcal{N}(0, I)}{\mathcal{N}(0,CC^T + R)} \\
= \frac{\mathcal{N}((R^{-1} + I)^{-1} (R^{-1} C \mathbf{x}), (R^{-1} + I)^{-1})}{\mathcal{N}(0,CC^T + R)} \\
\vdots \\
??? \\
\vdots \\
= \mathcal{N}(\boldsymbol{\beta} \mathbf{y}, I - \boldsymbol{\beta} C), \quad \boldsymbol{\beta} = C^T (C C^T + R)^{-1}
$$ I used the matrix cookbook for the third equality. R is a covariance matrix without any special assumptions at this point in the paper.","['statistics', 'normal-distribution']"
1838186,"Silverman, arithmetic of EC, I1.9 no nonconstant morphisms $P^m \to P^n$ for m>n","This topic goes about problem 9 of the first chapter of Silverman, arithmetic of EC: If $m>n$, prove that there are no nonconstant morphisms $P^m \to P^n$. A solution can be found for example at Why is $\phi:\mathbb{P}^n\rightarrow \mathbb{P}^m$ constant if dim $\phi(\mathbb{P}^n)<n$? ,
but since it is in the beginning of the book, 
I think there should exist also an easier solution too, shouldn't it?
There was a hint given in the book: the dimension theorem.","['elliptic-curves', 'algebraic-geometry']"
1838189,Critical points of a cubic function,"There is a function $x^3 - 6x^2 + 9x + 1$. Its critical points are $1$ and $3$. I am very confused, if these points are maximum and minimum points respectively or are both inflection points. Can someone please help me with these ? These points can not be maximum and minimum points since function attains higher and lower values as compared to what the function attains at these $2$ points. Please correct me if I am wrong.","['derivatives', 'calculus']"
1838219,Write the expression(I don't know understand the question),"Write the expression (p^ ~q) ^ r, using only the operators v and ~. The question meant the ^ operator with v operator?",['discrete-mathematics']
1838227,Generic method to distribute n distinct objects among r people such that each person gets at least one object,"Is there any generic method to solve problems of the kind - ""How many ways to distribute n distinct objects among r person(s) such that each person gets at least 1 object?"". I am aware of 2 different methods to solve this depending on the inputs - n and r. If n and r are pretty close to each other, we can find out all
mutually exclusive distribution cases, then find the number of
different ways to form such distribution groups and finally the
number of ways to distribute such distinct groups among the people.
For example, if I had to find out the number of ways I can
distribute 12 distinct objects among 9 persons such that each person
gets at least 1,then I can form 3 distribution cases - A)One person
gets 4 objects, remaining 8 gets 1 each. B)One person gets 3,another
4 and remaining 7 gets 1 each object. C)Three people gets 3 objects
each, remaining 6 people gets 1 each.I can form the group (A) in
12!/(4!8!)ways, group (B) in 12!/(3!2!7!)ways and group (C) in
12!/(2!2!2!3!6!)ways. Each of these groups can be distributed to 9
persons in 9! ways, hence the answer would be summation of
(A+B+C)*9!. This method is quicker for problems where n and r are close to each other. If say r<5 and the difference between n and r is significant, then we can solve the problem by a variant of Inclusion-Exclusion principle. For example, if I had to distribute 9 objects between 3 people such that each person gets at least 1, then we can find the total number of ways to distribute these 9 objects without any restriction i.e. $3^9$, then subtract from it the total number of ways where at least one among the 3 people doesn't get a single object i.e. in $\binom 31(2^9-2)$ ways and finally subtract the number of cases where all the objects are given to a single person in $\binom 31$ ways. Hence the answer will be $3^9-\binom 31(2^9-2)-3$. This method seems quicker for problems where r is small. But I would like to know a generic method to approach this problem irrespective of the values of n and r, which yields quicker results. I also know if the objects are identical then we can construct a generating function G(x) and then find the co-efficient of $x^n$ which will give us all possible ways of distributing n identical objects. I would appreciate if anyone can guide to me to a generic solution for distinct objects.","['permutations', 'combinatorics', 'combinations']"
1838248,Finding the possible positions of chess knight mathematically relative to a given position,"From this website I found the following question: A chess board’s 8 rows are labelled 1 to 8, and its 8 columns a to h. Each square of the board is described by the ordered pair (column letter, row number). (a) A knight is positioned at (d, 3). Write down its possible positions after a single move of the knight. (b) If R = {1, 2, ..., 8} , C = {a, b, ..., h} , and P = {coordinates of all squares on the chess board} , use set notation to express P in terms of R and C (c) A rook is positioned at (g, 2). If T = {2} and G = {g}, express its possible positions after one move of the rook in terms of R, C, T and G. For (a) is there anyway mathematically to list all the possible positions of the knight? I could for example, use a chess board to determine all the possible positions of the knight. About (C) I completely don't get it. The answers are provided in the website , however, I'm interested in how to solve them.",['discrete-mathematics']
1838251,$m_*(E)=m^*(E)\iff E$ Lebesgue measurable,"Let $E\subset [a,b]$. Show that $E$ is Lebesgue measurable if and only if the Lebesgue outer measure of $E$ is equal to the Lebesgue inner measure of $E$. I have seen the proof for this above statement for the Caratheodory definition of Lebesgue measurable, but I was wondering if someone could help me prove it for a different (but equivalent) definition of Lebesgue measurable set. The definition my book is using: $E\subset \mathbb{R}$ is said to be Lebesgue measurable if $E$ can be squeezed between an open set $G$ and a closed set $F$ where we have that $m^*(G\setminus F)<\varepsilon$ I need some help to start the problem please. Thanks! Just for completeness I provide the definitions of inner and outer lebesgue measure below: Lebesgue outer measure: For a subset $E$ of $\mathbb{R}$, we have that $m^*(E)=\inf\{\sum_{n=1}^{\infty}\ell(I_n):E\subset \cup_{n=1}^{\infty}I_n\}$ where $\ell(\cdot)$ denotes the length Lebesgue inner measure: For a subset $E$ of a bounded interval $[a,b]$, we have that $m_*(E)=b-a-m^*([a,b]\setminus E)$","['real-analysis', 'lebesgue-measure', 'measure-theory']"
1838252,finding the series $\sum_{n=1}^\infty \frac{x^n}{n!} \frac{1}{n}$,"My goal is to solve this series 
$$S(x) = \sum_{n=1}^\infty \frac{x^n}{n!} \frac{1}{n}$$ I did took the derivative first w.r.t $x$ $$S'(x) = \sum_{n=1}^\infty \frac{x^{n-1}}{n!}$$ which I formulated to be 
$$ S'(x) = \frac{e^x}{x} - \frac{1}{x} $$ Hence, applying the antiderivative $$ \int \frac{e^x}{x} dx - \ln(x) $$
(I did not put $c$ intentionally) I have searched for this integral $ \int \frac{e^x}{x} \, dx $ and I found that there's a special function called the exponential integral 
$$\mathrm{Ei}(x) =  \int_{-\infty}^x \frac{e^t}{t} dt$$ I am questioning the feasibility to solve this summation in terms of the $Ei$. I am having a problem regarding the notion of bridging between definite integrals and symbolic antiderivatives ? EDITED: There's something just came up to my mind,
what if I apply this definite integral on $S'(x)$
$$ \int_1^{x} S'(t) dt = \int_{-\infty}^x \frac{e^t}{t} dt - \int_{-\infty}^1 \frac{e^t}{t} dt - \ln(x) + \ln(1) $$
then,
$$ S(x) - S(1) =\mathrm{Ei}(x) - \mathrm{Ei}(1) - \ln(x) $$ which requires finding $S(1) = \sum_{n=1}^{\infty} \frac{1}{n!\,n}$","['calculus', 'indefinite-integrals', 'integration', 'definite-integrals', 'special-functions']"
1838264,How to draw a lattice for the divisors of big numbers?,"An exercise ask to find atoms and join-irreducible elements for the set of divisors of 360. I know how to find them by drawing the lattice but it seems difficult in this case. Is there another way to find atoms?
If not, is there a easy way to draw such a lattice?","['divisibility', 'lattice-orders', 'elementary-number-theory', 'integer-lattices', 'discrete-mathematics']"
1838303,Evaluating sums of the form $\sum_{i_d=1}^{\infty}\ldots\sum_{i_2=1}^{\infty}\sum_{i_1=1}^{\infty}x^{i_1\cdot i_2\cdots i_d}$,"I am wondering if there is a way to evaluate or get a more useful expression for a sum of the following form:
$$\sum_{i_d=1}^{\infty}\ldots\sum_{i_2=1}^{\infty}\sum_{i_1=1}^{\infty}x^{i_1\cdot i_2\cdots i_d},$$ where $|x|<1.$  For example, if $d=2$, then the sum is an example of a Lambert series and the exponents that appear are essentially given by (up to some index shuffling) this OEIS entry .  In this case it is not difficult to obtain $$\sum_{j=1}^{\infty}\sum_{i=1}^{\infty}x^{ij}=\sum_{j=1}^{\infty}\frac{x^{j}}{1-x^{j}},$$ which I can then evaluate for any $|x|<1.$ This can be viewed as summing over a $d$-dimensional non-negative integer lattice, so I've looked at things like ""lattice sums"" (tried to post a link here but not enough reputation points to post more than 2 links) but can't seem to find anything helpful there. Even something for the case $d=3$ would be helpful.",['sequences-and-series']
1838365,Effective divisors exactly those with global sections,"Let $X$ be a finite-type scheme over a field $k$. To an effective divisor $D$, there is a global section of the invertible sheaf $\mathcal{O}_X(D)$ (corresponding to the canonical morphism $\mathcal{O}_X \to \mathcal{O}_X(D)$). I've read somewhere that the opposite is true: if $H^0(X,\mathcal{O}_X(D)) \not= 0$, then there is an effective divisor $E$ with $\mathcal{O}_X(D) = \mathcal{O}_X(E)$ (i.e. $D$ and $E$ are linearly equivalent). If this is true, why? And why wouldn't the following be a counterexample: let $X$ be an elliptic curve and $p,q,r \in X$ be distinct points, then $H^0(X,\mathcal{O}_X(p+q-r))$ is $1$-dimensional, but $p+q-r$ is not linearly equivalent to an effective divisor.",['algebraic-geometry']
1838386,What is the necessary condition for ODE to have unique solution?,"For the ODE:
\begin{align}
\dot{x}(t)&=f(x,t) \\
x(t_{0})&=x_{0}
\end{align}
If $\;\;f:\mathbb{R}^{n}\rightarrow{}\mathbb{R}^{n}$ is Lipschitz continuous on $\mathbb{R}^{n}$, then there exists a unique solution for the ODE.
The reverse is not always true, right? and what is the necessary condition for the uniqueness for the ODE? I have read a book about numerical computing for ODE. The author only assumed there exists a unique solution for the ODE. In proving some properties in the numerical scheme, the author used the Lipschitz continuous property of the ODE. I wonder it is not a correct proof.","['numerical-methods', 'ordinary-differential-equations']"
1838409,Counting Problem (Sums of a set from 1 to 100),"In how many ways can you select two distinct integers from the set {1,
  2, 3, . . . , 100} so that their sum is: (a) even? (b) odd? I'm studying for a discrete midterm this coming Monday and saw the following problem on a practice midterm my Professor posted. I know the amount has to be less than C(100,2), but it would be naive to think the answer to a and b is just half that...right? What's tricky about this problem is that I'm not confident about the relationship between odd and even numbers in generating sums. Here's what I can make out, at least intuitively: Even + Even = Even, or C(50, 2)
Odd + Odd = Even C(50,2)
Even + Odd = Either (no idea how to compute this) Am I approaching this problem the right way?",['discrete-mathematics']
1838415,Deriving the mean of the Gumbel Distribution,"I'm trying to determine an expected value of a random variable related to the Gumbel/Extreme Value Type 1 distribution.  I think the answer follows the same process as expected value of the Gumbel itself, but I can't figure out the derivation of the expected value of the Gumbel. I found here a derivation, but there's a step in the middle where magic happens.  Need to understand what's going on there to see if I can apply it to my other problem. Recall, the density of the Gumbel distribution is $f(x) = e^{-e^{-x}}e^x$.  The derivation at the link shows that $$
\int_{-\infty}^{\infty}x e^{-x} e^{-e^{-x}}dx = - \int_{0}^{\infty}{\ln y}e^{-y}dy\quad  [y=e^{-x}]\\
= -\frac{d}{d\alpha}\int_0^\infty y^\alpha e^{-y}dy\bigg|_{\alpha=0}\\
=-\frac{d}{d\alpha}\Gamma(\alpha+1)\bigg|_{\alpha=0}\\
=\Gamma'(1) = \gamma \approx 0.577...
$$ The jump from the first line to the second is the one I can't follow.  I've tried doing integration by parts on one or the other to demonstrate the equivalence, but I end up with a floating 1 or infinity. Thanks in advance!","['indefinite-integrals', 'statistics', 'definite-integrals', 'expectation']"
1838472,The trace functional and its scalar multiples [duplicate],"This question already has answers here : Show that trace is a unique linear functional (2 answers) Closed 8 years ago . I am trying to solve the following problem: Show that the trace functional on $n \times n$ matrices is unique in the following sense. If $W$ is the space of $n \times n$ matrices over the field $F$ and if $f$ is a linear functional on $W$ such that $f(AB)=f(BA)$ for each $A$ and $B$ in $W$, then $f$ is a scalar multiple of the trace function. I know that one way to prove this is to show that the null space of $f$ equals the null space of the trace function, but I found this solution rather complicated; any other suggestions?","['matrices', 'linear-algebra', 'linear-transformations']"
1838496,Distribution of the minimum,"I have the following problem, given a random variable $X$ with density
$$f(x)=2x\text{ for }x\in(0,1)$$
and a r.s.s. $X_1, X_2, X_3$. I have to calculate the probability that $X_{(1)}=\min\{X_1,X_2,X_3\}$ exceeds the median $M$. Previously I have computed the distribution of $X_{(1)}$, so I get this
$$P(X_{(1)}>M)=1-F_{X_{(1)}}(M)=(1-F(M))^3=\frac{1}{8}$$
since by definition $F(M)=\frac{1}{2}$. The thing that makes me doubt about my result is that I haven't used the density of $f$ at all, does that mean this is true for every random variable, or am I missing something?","['statistics', 'random-variables', 'probability-distributions']"
1838517,Solve the non-linear differential equation,"I have been trying to solve the following differential equation:
$$ \dot{y} = \frac{3x^2}{y-x^2+1}$$ Substituting $u=y-x^2+1$ we get $\dot{u}=\dot{y}-2x$ we get $\dot{u}=\frac{3x^2}{y}-2x$. But I can't get any further now, i have tried substituting $k=u-x^2$, but it doesn't help.",['ordinary-differential-equations']
1838549,Find the values of $x$ such that $2\tan^{-1}x+\sin^{-1}\left(\frac{2x}{1+x^2}\right)$ is independent of $x$.,"Find the values of $x$ such that 
  $$2\tan^{-1}x+\sin^{-1}\left(\frac{2x}{1+x^2}\right)$$ is independent of $x$. Checking for $x\in [-1,1]$
In the taken domain $\sin^{-1}\left(\frac{2x}{1+x^2}\right)$ comes out to be $2\tan^{-1}x$ hence the taken function comes out to be equal to $4\tan^{-1}x$ hence the function is clearly dependent on $x$. Now checking for $x\in (1,\infty)$
In the taken domain $2\tan^{-1}x$ comes out to be $\pi-\sin^{-1}\left(\frac{2x}{1+x^2}\right)$ and hence the net sum becomes independent of $x$. Now checking for $x\in (-\infty,-1)$
In the taken domain $2\tan^{-1}x$ comes out to be $-\pi-\sin^{-1}\left(\frac{2x}{1+x^2}\right)$  and hence the net sum becomes $-\pi$ therefore becomes, independent of $x$. But the answer has been mentioned as just $x\in [1,\infty)$ Can anybody tell me why the second set has not been included.",['trigonometry']
1838568,"X={1,2,3}. Give a list of topologies on X such that every topology on X is homeomorphic to exactly one on your list.","I'm teaching my self topology with the aid of a book. I'm trying to do the following problem: Let X={1,2,3}. Give a list of topologies on X such that every topology on
  X is homeomorphic to exactly one on your list. I'm not sure If I totally understand what is being asked, but I'm going to attempt to list every topology in groups that are homeomorphic to one another. I want to know if this is correct. (A) trivial topology. $\mathscr{T}=${X,$\varnothing$}; I can't think of anything else that is homeomorphic to this one. (B) ""singles"" (B1): $\mathscr{T}=${X,$\varnothing$,{1}}; (B2): $\mathscr{T}=${X,$\varnothing$,{2}}; (B3): $\mathscr{T}=${X,$\varnothing$,{3}}; (C) ""doubles"" (C1): $\mathscr{T}=${X,$\varnothing$,{1,2}}; (C2): $\mathscr{T}=${X,$\varnothing$,{2,3}}; (C3): $\mathscr{T}=${X,$\varnothing$,{3,1}}; (D) ""single-doubles"" (D1): $\mathscr{T}=${X,$\varnothing$,{1},{1,2}}; (D2): $\mathscr{T}=${X,$\varnothing$,{1},{1,3}}; (D3): $\mathscr{T}=${X,$\varnothing$,{2},{2,1}}; (D4): $\mathscr{T}=${X,$\varnothing$,{2},{2,3}}; (D5): $\mathscr{T}=${X,$\varnothing$,{3},{3,1}}; (D6): $\mathscr{T}=${X,$\varnothing$,{3},{3,2}}; (D') ""single-doubles (disjoint)"" (D'1): $\mathscr{T}=${X,$\varnothing$,{3},{1,2}}; (D'2): $\mathscr{T}=${X,$\varnothing$,{2},{1,3}}; (D'3): $\mathscr{T}=${X,$\varnothing$,{1},{2,3}}; (E) ""single-single-doubles"" (E1): $\mathscr{T}=${X,$\varnothing$,{1},{2},{1,2}}; (E2): $\mathscr{T}=${X,$\varnothing$,{1},{3},{1,3}}; (E3): $\mathscr{T}=${X,$\varnothing$,{2},{3},{2,3}}; (F) ""single-double-doubles"" (F1): $\mathscr{T}=${X,$\varnothing$,{1},{1,2},{1,3}}; (F2): $\mathscr{T}=${X,$\varnothing$,{2},{2,1},{3,2}}; (F3): $\mathscr{T}=${X,$\varnothing$,{3},{3,2},{3,1}}; (G) ""single-single-double-doubles"" (G1): $\mathscr{T}=${X,$\varnothing$,{1},{2},{1,2},{2,3}}; (G2): $\mathscr{T}=${X,$\varnothing$,{1},{2},{1,2},{3,1}}; (G3): $\mathscr{T}=${X,$\varnothing$,{1},{3},{1,2},{3,1}}; (G4): $\mathscr{T}=${X,$\varnothing$,{1},{3},{2,3},{3,1}}; (G5): $\mathscr{T}=${X,$\varnothing$,{2},{3},{2,3},{3,1}}; (G6): $\mathscr{T}=${X,$\varnothing$,{2},{3},{1,2},{2,3}}; (H) power set: $\mathscr{T}=${X,$\varnothing$,{1}, {2},{3},{1,2},{2,3},{3,1}};; I can't think of anything else that is homeomorphic to this one. IS this a complete list of all topologies on X?",['general-topology']
1838572,More convenient form of derivative of $\mathrm{sinc}(x)$,"$\mathrm{sinc}(x)$ is defined as $\frac{\sin(x)}{x}$ except continuous at $x=0$ (insert the removable singularity). The derivative of $\mathrm{sinc}(x)$ is usually given as the derivative of $\frac{\sin(x)}{x}$, namely $$\frac{\cos(x)}{x} - \frac{\sin(x)}{x^2},$$ but this has the same problem as $\frac{\sin(x)}{x}$. You have to re-insert the removable singularity at $x=0$. Is there a more convenient form of the derivative of $\mathrm{sinc}(x)$, say perhaps using $\mathrm{sinc}(x)$ itself, that doesn't have this issue? (don't say piecewise; if piecewise was convenient we wouldn't have $\mathrm{sinc}$ in the first place.)",['derivatives']
1838588,Any undirected graph on 9 vertices with minimum degree at least 5 contains a subgraph $K_4$?,"Let $G$ be simple undirected graph with degree of every vertices is at least 5. Prove or disprove that $G$ contains subgraph $K_4$. I came up with this question when I were trying to find Ramsey number $R(4,3)$. I think my conjecture is correct but I am unable to prove it. If anyone have any idea please share with me. Thank you in advance !","['graph-theory', 'algebraic-graph-theory', 'extremal-graph-theory', 'ramsey-theory', 'discrete-mathematics']"
1838598,Olympic Problem about Theory of numbers.,"Let $Y=\{1,2,\ldots, 2014\} \subset \mathbb{N}$. Find the maximal subset $A\subset Y$ such that,
  $$\forall x\in A,\quad x\not\mid\sum_{y\in A\setminus\{x\}} y.$$ Example, $A'=\{2,4,6,\ldots,2014\}\cup\{5\}$ this set holds the conditions, but ins't the maximal subset.","['number-theory', 'elementary-set-theory', 'elementary-number-theory']"
1838603,Why does $(128)!$ equal the product of these binomial coefficients $128! = \binom{128}{64}\binom{64}{32}^2 \dots \binom21^{64}$?,"I'm working through some combinatorics practice sets and found the following problem that I can't make heads or tails of. It asks to prove the following: $$128! = \binom{128}{64}\binom{64}{32}^2\binom{32}{16}^4\binom{16}8^8\binom 84^{16}\binom 42^{32}\binom{2}{1}^{64}$$ Weird, huh? The first thing I noticed is that the exponents mirror the $r$ variables. I would normally just re-express each statement in $\frac{n!}{(n-r)!r!}$ form, but the exponents throw me for a loop. Are there any intuitions about factorials or $_n C_r$ that I should be considering here?","['algebra-precalculus', 'combinatorics', 'factorial', 'binomial-coefficients']"
1838617,Dividing an equilateral triangle into N equal (possibly non-connected) parts,"It’s easy to divide an equilateral triangle into $n^2$ , $2n^2$ , $3n^2$ or $6n^2$ equal triangles. But can you divide an equilateral triangle into 5 congruent parts? Recently M. Patrakeev found an awesome way to do it — see the picture below (note that the parts are non-connected — but indeed are congruent, not merely having the same area). So an equilateral triangle can also be divided into $5n^2$ and $10n^2$ congruent parts. Question. Are there any other ways to divide an equilateral triangle into congruent parts? (For example, can it be divided into 7 congruent parts?) Or in the opposite direction: can you prove that an equilateral triangle can’t be divided into $N$ congruent parts for some $N$ ? (Naturally, I’ve tried to find something in the spirit of the example above for some time — but to no avail. Maybe someone can find an example using computer search?..) I’d prefer to use finite unions of polygons as ‘parts’ and different parts are allowed to have common boundary points. But if you have an example with more general ‘parts’ — that also would be interesting.","['dissection', 'geometry']"
1838628,Weak convergence implies convergence on continuous functions,"Let $X$ be a metric space, and let $\mu_n$ be a sequence of measures on $X$ converging weakly to a measure $\mu$, meaning for all bounded continuous functions $f$, we have $\int_{X}fd\mu_n \rightarrow \int_{X}fd\mu$ as $n \to \infty$. Now say that $f$ is not necessarily bounded, but it is continuous, and that $\sup_n \int_{X}fd\mu_n < \infty$ and $\int_X fd\mu < \infty$. Is it necessary that
$\int_X fd\mu_n \rightarrow \int_Xfd\mu$? What I tried:
Assume further that $f$ is non-negative and that we can get a sequence of functions $f_n$ with $f_n \leq f_{n+1}$ and converging pointwise to $f$, which are bounded continuous. Then using monotone convergence + weak convergence we get $$\int_X f d\mu = 
\lim_{m\to\infty}\int_X f_m d\mu = 
\lim_{m\to\infty}\lim_{n\to\infty}\int_X f_m d\mu_n$$ But I'm not sure how to proceed from here. When can one interchange these limits?","['weak-convergence', 'probability-theory']"
1838649,"Linear transformation $T$ such that for every extension $\overline{T}$, $\|\overline{T}\|>\|T\|$.","Let $E$ and $F$ be normed spaces such that $\dim F < \infty$, $G$ a subspace of $E$ and $T:G\rightarrow F$ a continuous linear map. I know that there exists a continuous linear extension $\overline{T}:E\rightarrow F$. Also, if $E$ is a Hilbert space, then $\overline{T}$ can be chosen in the way that $\|\overline{T}\|=\|T\|$. Problem: Find an example of $E$, $F$, $G$ and $T$ (like above) such that every continuous linear extension $\overline{T}$ has a greater norm, i.e. $\|\overline{T}\|>\|T\|$. Now, $F$ must be at least a 2-dimensional space, otherwise I could use Hahn-Banach to find an extension with equal norm.  My professor told me it could be done with $E$ of finite dimension. Of course, I tried to come up with an example of $E$ with a norm that doesn't satisfy the parallelogram law. For example, $E=\left(\mathbb{R}^3,\|\cdot\|_{\infty}\right)$ and $F=\left(\mathbb{R}^2,\|\cdot\|_1\right)$. But I couldn't prove that it works with any example I tried using those spaces. Can somebody help me to find an example and assure that it really has that property? EDIT: Apparently, it can't be done with $E$ of finite dimension nor with $F$ equipped with the $\sup$ norm, as @Hamza proved below.","['functional-analysis', 'normed-spaces', 'operator-theory']"
1838657,How can I rewrite recursive function as single formula?,"There is following recursive function $$
\begin{equation}
    a_n=
    \begin{cases}
      -1, & \text{if}\ n = 0 \\
      1, & \text{if}\ n = 1\\
      10a_{n-1}-21a_{n-2}, & \text{if}\ n \geq 2
    \end{cases}
\end{equation}
$$ I know this can be rewritten as 
$$
a_n=7^n-2\cdot3^n
$$ But how can I reach that statement? I found this problem on some particular website. My skills are not enough to solve such things. Someone told me I have to read about Generating function but it didn't help me. I would be thankful if someone explained it to me.","['generating-functions', 'recurrence-relations', 'sequences-and-series']"
1838669,Prove that Standard Deviation is always $\geq$ Mean Absolute Deviation,"Where $$s = \sqrt{ \frac{1}{n} \sum_{i=1}^{n} (x_i - \bar{x})^2}$$ and 
$$ M = \frac{1}{n} \sum_{i=1}^{n} |x_i - \bar{x}|$$ I came up with a sketchy proof for the case of $2$ values, but I would like a way to generalize (my ""proof"" unfortunately doesn't, as far as I can tell). Proof for $2$ values (I would appreciate feedback on this as well): $$\frac{1}{\sqrt{2}} \sqrt{(x_1 - \bar{x})^2 + (x_2 - \bar{x})^2} \geq \frac{1}{2} (|x_1- \bar{x}| + |x_2- \bar{x}|)$$ Now let $|x_1- \bar{x}| = a$ and $|x_2- \bar{x}| = b$ be the $2$ legs of a right triangle and $\sqrt{(x_1 - \bar{x})^2 + (x_2 - \bar{x})^2} = c$ its hypothenuse. And let $\theta$ be the angle between $c$ and either $a$ or $b$. Then $(\sin{\theta} + \cos{\theta}) = \frac{a}{c} + \frac{b}{c} = \frac{a+b}{c} = \frac{\frac{1}{2} (|x_1- \bar{x}| + |x_2- \bar{x}|)}{\frac{1}{\sqrt{2}} \sqrt{(x_1 - \bar{x})^2 + (x_2 - \bar{x})^2}}$ so that $$ \sqrt{2} \geq (\sin{\theta} + \cos{\theta})$$ And we know that $\max(\sin{\theta} + \cos{\theta}) = \sqrt{2}$. QED? I have no idea how to prove the general case, though .","['inequality', 'standard-deviation', 'statistics', 'proof-explanation', 'solution-verification']"
1838674,"Poincaré's inequality proof for $u \in W_0^{1,p}(\Omega)$.","I am trying to prove Poincare's inequality for $u \in W_0^{1,p}(\Omega)$, where $\Omega \subset \mathbb{R}^n$ is an open bounded set and $1 \leq p < \infty$. This is Poincare's inequality: $||u||_{L^p(\Omega)} \leq C ||\nabla u ||_{L^p(\Omega)}$. For $p < N$ the inequality follows applying Sobolev-Gagliardo-Nirenberg inequality. Indeed, $$||u||_{p^*} \leq C||\nabla u||_{p}, $$ and from the fact that $\Omega$ is bounded we have $||u||_p \leq \tilde{C} ||u||_{p^*} \leq C||\nabla u||_{p}$. How can I prove the inequality for $ N \leq p < \infty$ ?","['functional-analysis', 'lp-spaces', 'sobolev-spaces', 'partial-differential-equations']"
1838693,Dual result of Fatou lemma,"If $\{f_n\}\subset L^+$, $f\in L^+$ such that $\{f_n\}$ is dominated by $f$ where $\int f < \infty$ then $$\limsup\int f_n\leq \int \limsup f_n$$ Attempted proof - Consider the sequence $\{f - f_n\}\subset L^+$ then applying Fatou's lemma we have $$\int (\liminf(f-f_n))\leq \liminf \int (f - f_n)$$ We know that $$\int(\liminf (f - f_n)) = \int \lim_{k\rightarrow \infty} \inf_{n\geq k}(f - f_n)$$ Then from the Monotone Convergence theorem, $$\int \lim_{k\rightarrow \infty}\inf_{n\geq k}(f-f_n) = \lim_{k\rightarrow \infty}\int \inf_{n\geq k}(f - f_n)$$ Therefore we have, $$\lim_{k\rightarrow \infty}\int \inf_{n\geq k}(f - f_n) = \lim_{k\rightarrow \infty}\int \inf_{n\geq k} f - \lim_{k\rightarrow \infty}\int \inf_{n\geq k}f_n = \int  f - \lim_{k\rightarrow \infty}\int \sup_{n\geq k}f_n$$ I am not sure if I am on the right track or where to go from here. Just some hints should help me enough. Attempted proof #2 - Consider the sequence $\{f - f_n\}\subset L^+$ then applying Fatou's lemma we have 
\begin{align*}
&\int (\liminf(f-f_n))\leq \liminf \int (f - f_n)\\
\Leftrightarrow &\int\liminf f - \int \liminf f_n \leq \liminf\int f - \liminf\int f_n\\
\Leftrightarrow &\int f - \int \limsup f_n \leq \int f - \limsup\int f_n
\end{align*}
Rearranging and cancelling out $\int f$ (which is possible since $\int f <\infty$) then we have $$\limsup\int f_n\leq \int \limsup f_n$$","['real-analysis', 'measure-theory']"
1838697,Can I find a function of $y$ that satisfies the relation $\dfrac{df(y)}{dx} = y^2(3y'+1)$,"Suppose we have an unknown function $y=y(x)$  , is it possible to find a function $f(y)$ such that:
$$\dfrac{df}{dx}= y^2\left(3\dfrac{dy}{dx}+1 \right)$$? EDIT: of course if there is no $1$ in the RHS, the solution will be $f(y) = y^3$ I appreciate any help Thank you",['ordinary-differential-equations']
1838714,probability measures vs. probability distributions vs. measure of probability density,"I am learning probability theory right now and am confused about some basic concepts. I have a few questions and am wondering if you can also check if the following is correct: Suppose we have a probability space $(\Omega, \mathcal{F}, \mathbb{P}^1)$ . My understanding is that: $\mathbb{P}^1$ is called a probability measure but not a probability distribution . If we have some random variable $X$ that maps to $(\mathbb{R}, \mathcal{B})$ , then $X$ induces a probability distribution $\mathbb{P}^2$ on $(\mathbb{R}, \mathcal{B})$ , which is a measure on $(\mathbb{R}, \mathcal{B})$ such that $\mathbb{P}^2(A) = \mathbb{P}^1(X^{-1}(A)), A \in \mathcal{B}$ . Is it true that $\mathbb{P}^2$ is also a probability measure on $(\mathbb{R}, \mathcal{B})$ ? We can consider a probability density function $f$ of $X$ with respect to some dominating measure $\mathbb{M}$ on $(\Omega, \mathcal{F})$ . Then $\mathbb{F}(A)=\int_A f ~d\mathbb{M}, A \in \mathcal{F}$ is a measure on $(\Omega, \mathcal{F})$ . Is it always true that $\mathbb{F}$ is a probability measure on $(\Omega, \mathcal{F})$ ? Must the random variable $X$ be defined on a probability space? From the above point, people often take the dominating measure $\mathbb{M}$ to be the Lebesgue measure. But the Lebesgue measure is not a probability measure...","['probability-theory', 'lebesgue-measure']"
1838717,"Real Analysis, Folland Problem 2.2.14 Integration of Nonnegative functions","Problem 2.2.14 - If $f\in L^{+}$, let $\lambda(E) = \int_{E}f d\mu$ for $E\in M$. Then $\lambda$ is a measure on $M$, and for any $g\in L^{+}$, $\int g d\lambda = \int f g d\mu$.(First suppose that $g$ is simple) Attempted proof - 
Observe that $\lambda(\emptyset) = \int_{\emptyset}f d\mu = \int 1_{\emptyset} f d\mu = \int 0 f d\mu = 0$. Let $\{E_n\}_{n\in\mathbb{N}}\subset M$ and let $F = \bigcup_{n=1}^{\infty}E_n$. Then $$\lambda(F) = \int_{F}f d\mu = \int 1_{F}f d\mu = \int \left(\sum_{n=1}^{\infty}1_{E_n}f\right)d\mu = \sum_{n=1}^{\infty}\int 1_{E_n}f d\mu \ \ \text{by proposition 2.15}\\ = \sum_{n=1}^{\infty}\int_{E_n}f d\mu = \sum_{n=1}^{\infty}\lambda(E_n)$$ Therefore $\lambda$ is a measure. Now, let $g\in L^{+}$, where $g$ is a simple with standard representation $g = \sum_{n=1}^{N}a_n 1_{E_n}$, then $$\int g d\lambda = \sum_{n=1}^{N}a_n\lambda(E_n) = \sum_{n=1}^{N}a_n\int_{E_n}f d\mu = \sum_{n=1}^{N}a_n\int f 1_{E_n}d\mu$$ $$=\int \sum_{n=1}^{N}a_n f 1_{E_n}d\mu = \int f g d\mu$$
Otherwise, there exists an increasing sequence $\{g_n \}_{n\in\mathbb{N}}\in L^{+}$ that converges to $g$, so that $\{fg_n\}_{n\in\mathbb{N}}$ converges to $fg$ and hence $$\int g d\lambda = \lim_{n\rightarrow \infty}\int g_n d\lambda = \lim_{n\rightarrow \infty}\int f g_n d\mu = \int f g d\mu$$ I am pretty sure this is correct, I just don't understand how $$\int f \chi_{F}d\mu = \int (\sum_{1}^{\infty}\chi_{E_n}f)d\mu$$ Also I do not understand the last part starting with otherwise that I found online.","['real-analysis', 'measure-theory']"
1838724,"Boundary and Interior of set $\{-3,2,5\}$","I'm trying to see if I'm correctly understanding and applying the definition for interior and boundary points. Interior point: A point x in R is an interior point of S if there exists a neighborhood N of $x$ such that $N \subseteq S$. Boundary point: ... if every neighborhood of $x$ contains at least one point in $S$ and at least one point not in $S$, then $x$ is a boundary point. Given the set $\{-3,2,5\}$ I assume the only interior point is $2$ since this is not an interval and there is no neighborhood at $-3$ and $5$. Additionally, I don't think there is any boundary points or accumulation points, again because there is no neighborhood. Is this correct?","['real-analysis', 'elementary-set-theory']"
1838726,Does associativity imply closure?,"Does associativity of binary operation imply closure under this operation? Sometimes definitions of semigroup, group or vector space omit axiom of closure under corresponding operations and sometimes they don't. One of the arguments for omitting the axiom that I found is that associativity implies closure. As a possible proof, let + be binary operation on set A . Assume a , b and c are elements of A . Also (b + c) is in set but (a + b) is not in a set. Then a + (b + c) is well-defined (even though the result can be out of set). However, if we assume that + is associative, we will get: a + (b + c) = (a + b) + c But that is not true because second ""addition"" in right part is not defined for (a + b) that is out of set and c . So for associativity, (a + b) must be in set. Does this argument make sense? Is it true? UPDATE : In a possible proof the error is in the first assumption. If + is binary operation on A and a and b are in A then (a + b) must be in set by definition of binary operation ( A x A -> A ).","['abstract-algebra', 'semigroups', 'associativity', 'binary-operations']"
1838752,"Real Analysis, Folland problem 2.2.16 Integration of Nonnegative functions","If $f\in L^+$ and $\int f < \infty$, for every $\epsilon > 0$ there exists $E\in M$ such that $\mu(E) < \infty$ and $\int_E f > (\int f) - \epsilon$. Attempted proof - Let $f\in L^+$ and $\int f < \infty$. Let $\epsilon > 0$, by definition of $\int f$, there exists a simple function $\phi = \sum_{n}a_n \chi_{E_n}$ such that $0\leq \phi \leq f$ and $$\int f - \epsilon < \int \phi$$
Note, we have a finite family of disjoint measurable sets $\{E_n\}_{n}$. Let $E = \bigcup_{n}E_n$ then $E\in M$ and for each $n$ $\mu(E_n) < \infty$ this $\mu(E) < \infty$. Note also we have that $\int \phi \leq \int f < \infty$ thus $$\int f - \epsilon < \int_{E}\phi \leq \int_{E}f$$ I am not sure if this is correct any suggestions is greatly appreciated.","['real-analysis', 'measure-theory']"
1838770,Eigenvector corresponding to eigenvalue $ 1 $ of a stochastic matrix,"I am trying to justify fact $ 5 $ in this link which states that if $ A $ is a column stochastic matrix, then $ A $ has eigenvalue $ 1 $ and a unique eigenvector such that all entries are either negative or positive. I have successfully proved that $ A $ has an eigenvalue $ 1 $ but still stuck on the second part of the fact. It seems that this is the Perron Frobenius theorem, but the proof for this theorem requires materials that are beyond a first course in linear algebra that I haven't learned about, so is there any way to prove this fact without using the PF theorem?","['matrices', 'eigenvalues-eigenvectors', 'stochastic-matrices', 'linear-algebra']"
1838779,Transformation of random variables that preserves the distribution,"Suppose we have a random variable $X$ with distribution $F_X$.
Let $X_1$ and $X_2$ be two independent copies of $X$. My question: can we find a transformation $Z=g(X_1,X_2)$ such that the distribution of $Z$ is given by $F_X$? For example, if $X$ is a standard normal then such a transformation is given by $g(X_1,X_2)=0.25 X_1+0.25X_2$. Another example is we have $X={-1,1}$ equally likely. Then the transformation is  $g(X_1,X_2)=X_1X_2$. Note, a  trivial answer to this question is $g(X_1,X_2)=X_1$. 
However, I would like to find something more interesting. I started with the usual set up but didn't get anywhere
\begin{align}
F_Z(z)=\mathbb P [ g(X_1,X_2) \le z]
\end{align}","['probability-theory', 'probability', 'random-variables']"
1838793,Simplifying number of sets in a relationship,Got this monster set ((A∩B) ∪C ) ∪ (A∪(B∩C)) I'm trying to reduce the number of sets to be as small as possible using set identities Set Rules All I can think of is to apply distribution law ((C∪A) ∩ (C∪B) ∪ (A∪B) ∩ (A∪C)) Maybe I could play around with the middle terms (C∪B) ∪ (A∪B) but is that allowed?,['discrete-mathematics']
1838813,Enumerate elements of the following relations from the set A,"Literally the first homework question, and I seem to be struggling. There doesn't seem to be any examples in our book, so I'm hoping someone might help walk me through it. I'm guessing it's pretty simple too... I'm not looking for the answer, I'd just like some pointers on what I need to do, and how I should go about enumerating the elements. Enumerate the elements of the following relations from the set A of positive integers less than or equal to 10 to the set B of positive
  integers less than or equal to 30. An element a of A is related to the element b of B if b = 3 × a R=(1,3)(2,6)(3,9)(4,12)(5,15)(6,18)7,21)(8,24)(9,27)(10,30) An element a of A is related to the element b of B if b = 2 × a - 1 R=(1,1)(2,3)(3,5)(4,7)(5,9)(6,11)(7,13)(8,15)(9,17)(10,19) At first I thought I'd just have the two sets:
A = {1,2 3 ,4 5 ... 10 }
B = {1, 2, 3, 4, 5 ... 30 } so would I just take a (lets say 1) and b (1 again)
1 = 3 * 1 (obviously false)? and continue on for each element in both sets? 
3 = 3 * 1 (true) It just seems a little tedious to go through all combinations to test.",['discrete-mathematics']
1838848,"Derivative of the magnitude of a vector. Does it exist, or not?","I have a puzzling situation involving derivatives. I want to derivate:
$$
\frac{d}{dx}| \mathbf F(x)|
$$ This was actually something involving physics. Lets be 2-dimensional for simplicity. Let a particle be at position $\mathbf r = (x, y)$. The distance $s$ of the particle from point $(0, 0)$ is simply $s = |\mathbf r|$. I want to calculate how that distance changes over time.
$$
\frac{ds}{dt} = 
\frac{d}{dt}|\mathbf r| = 
\frac{d}{dt}\sqrt{x(t)^2 + y(t)^2} = 
\frac{1}{\sqrt{x(t)^2 + y(t)^2}}\left(x\frac{dx}{dt} + y\frac{dy}{dt}\right) = \frac{1}{|\mathbf r|}\left(x\frac{dx}{dt} + y\frac{dy}{dt}\right) 
$$ As you can see, $ds/dt$ is not defined when $|\mathbf r| = 0$. I can't see why. On physics point of view, the particle should always travel continuously in the plane (assuming the path it makes is continuous and fully differentiable). Why is the distance variation undefined? Assume for instance, I have a table, and $(x, y)$ is the position of my fingers. I can't see why it wouldn't exist. Hypothesis: Notice that, by description I told, the curve $(x, y)$ is continuous on all points, and smooth/differentiable on all points. Thus, $x(t), y(t), x'(t), y'(t)$ is well defined, for all points. If you want, consider them to be class $C^\infty$. My question : Does this derivative exist or not when $|\mathbf r| = 0$? What is the value/evaluation of such derivative in an arbitrary given period $t_0$ when $|\mathbf r| = 0$? Considering $x(t) = t^2$ and $y(t) = t^2$, we get $s$ proportional to $t^2$, and thus its derivative exists at $t=0$ with the derivative having a well defined value of zero.","['derivatives', 'real-analysis', 'calculus']"
1838860,Polynomial ring with arbitrarily many variables in ZF,"For a given field $k$ and a set $X$ we want to define the ring $k[X]$ of polynomials with $X$ as the set of variables. We do not assume $X$ to be finite. And we want to do this without employing axiom of choice. Informally, the elements of $k[X]$ will be finite sums of monomials of the form $cx_1^{k_1}\dots x_n^{k_n}$ , where each monomial is determined by a coefficient $c\in k$ , finitely many elements $x_1,\dots,x_n\in X$ and the exponents $k_1,\dots,k_n$ , which are positive integers. Addition and multiplication of polynomials from $k[X]$ will be defined in the natural way. However, we also should be able to describe this algebraic structure more formally. Especially if we are trying to use it in some proof in the axiomatic system ZF. In this case it is also important to check that we have not used AC anywhere in the proof. (Using Axiom of Choice can easily be overlooked, especially if somebody is used to work in ZFC rather than ZF, i.e., without the restriction that AC should be avoided.) To explain a bit better what I mean, this is similar to defining the polynomial ring $k[x]$ of polynomials in a single variable $x$ . Informally, we view polynomials as expressions of the form $a_nx^n+\dots+a_1x+a_0$ (with $a_i\in k$ ). And we will also write them in this way. But formally they are sequences of elements of $K$ with finite support. I will also provide below a suggestion how to construct $k[X]$ in ZF. I would be interested in any comments on my approach, but also if there are different ways to do this, I'd be glad to hear about them. This cropped up in a discussion with some colleagues of mine. Transfinite induction and direct limit One colleague suggested the following approach, which clearly uses AC (in the form of the well-ordering theorem ). But he said that this is the construction of $k[X]$ which seems the most natural to him. We take any well-ordering of the set $X=\{x_\beta; \beta<\alpha\}$ . By a transfinite induction we define rings $k_\beta$ for $\beta\le\alpha$ and also an embeddings $k_\beta \hookrightarrow k_{\beta'}$ for any $\beta<\beta'<\alpha$ . The ring $k_\beta$ is supposed to represent the polynomials using only variables $x_\gamma$ for $\gamma\le\beta$ . We put $k_0=k[x_0]$ . Similarly if $\beta$ is a successor ordinal we can define $k_\beta=k_{\beta-1}[x_\beta]$ . If $\beta$ is a limit ordinal, then we can take $k_\beta$ as a direct limit of $k_\gamma$ , $\gamma<\beta$ . Then the ring $k_\alpha$ is $k[X]$ which we wanted to construct. It is not immediately clear to me whether the proof can be simplified in the way that the direct limit can be replaced by union. However, I do not consider this to be an important difference, since using direct limit (especially in such a simple case, with linear order and embeddings) seem to me to be a rather standard approach for this type of constructions. And anybody with enough mathematical maturity to study a proofs of this level will probably not have a problem with the notion of direct limit. The fact that this is indeed a ring (or even integral domain) follows from the fact that these properties are preserved by this simple version of direct limits. (I.e., direct limit based on linearly ordered system of rings with embeddings between them. This does not differ substantially from the proof that union of chain of rings is a ring.) Functions with finite support I have suggested this approach, which is more closely modeled after the case of ring in a single variable. Unless I missed something, this can be done in ZF, i.e., without use of ZFC. Let us first try to definite the set $M$ of all monomials of the form $x_1^{k_1}\dots x_n^{k_n}$ . (I.e., the monomials with the coefficient $1$ .) Every such monomial is uniquely determined by a finite subset $F\subseteq X$ and a function $g: F\mapsto\mathbb N$ , where $\mathbb N=\{1,2,\dots\}$ . Or, if you will, $\mathbb N=\omega\setminus\{0\}$ . (Since we are talking about finite sets, it might be worth mentioning that there are several notions of finite set in ZF . We take the standard one, which is sometimes called Tarski-finite or Kuratowski-finite. This notion of finiteness is well behaved. For our purposes it is important to know that union of finite set of finite sets is again finite and the same is true for Cartesian product.) So we can get $M$ as a set of all pairs $(F,g)$ with the properties described above. Existence of such sets can be defined in ZF in a rather straightforward manner. (All properties of $F$ and $g$ can be described by a formula in a language of set theory. Clearly $F\in\mathcal P(X)$ . Or we can use the set $\mathcal P^{<\omega}(X)$ of finite subsets of $X$ instead. The function $g$ belongs to the set of all functions from such $F$ 's to $\mathbb N$ . For each $F$ we have the set $\mathbb N^F$ consisting of all functions $F\to\mathbb N$ . Then we can simply take the union $G=\bigcup\limits_{F\in\mathcal P(X)} \mathbb N^F$ , based on axiom of union. The we use axiom scheme of specification to get only those pairs from $\mathcal P(X)\times G$ which have the required properties.) Now we have the set $M$ . We want to model somehow the finite sums of elements from $M$ multiplied by a coefficents from $k$ . To this end we simply take the functions from $M$ to $k$ with finite support. So far we have only defined the underlying set $k[X]$ . We still need to define addition, multiplication, verify that this is integral domain. However, any polynomial $p\in k[X]$ only uses finitely many variables, since we have finitely many monomials and each of them only contains finitely many variables. If we are verifying closure under addition or multiplication, or some properties of integral domain such as associativity or distributivity, then any such condition only includes finitely many polynomials and thus we have only finitely many variables. So we can look at this condition as property of polynomials in $k[F]$ , where $F$ is some finite subsets. Assuming we already know that polynomial ring in finitely many variables over a field $k$ is an integral domain, this argument can be used to argue that $k[X]$ is an integral domain, too. The above discussion occurred in connection with the proof of Andreas Blass' result that existence of Hamel basis for vector space over arbitrary fields implies Axiom of Choice. This proof can be found for example in the references below. It is also briefly described in this answer . In this proof the polynomials from $k[X]$ are used. (Then the field $k(X)$ of all rational functions in variables from $X$ is created - in the other words, the quotient field of $k[X]$ . And the proof than uses existence of a Hamel basis of $k(X)$ considered as a vector space over a particular subfield of $k(X)$ .) Unless I missed something, the proofs given there do not discuss whether $k[X]$ can be constructed without AC. Which suggests that the authors considered this point to be simple enough to be filled in by a reader. So I assume that proof of this fact should not be too difficult. (Of course, if you know of another reference for a proof this results which also discusses this issue, I'd be glad to learn about it.) A. Blass: Existence of bases implies the axiom of choice. Contemporary  Mathematics, 31:31–33, 1984. Available on the author's website Theorem 5.4 in L. Halbeisen: Combinatorial Set Theory , Springer, 2012. The book is freely available on the author's website . Theorem 4.44 in H. Herrlich Axiom of choice , Springer, 2006, (Lecture Notes in Mathematics 1876). There are these related questions: Polynomial ring with uncountable indeterminates . Polynomial ring indexed by an arbitrary set. The answers given there can be considered somewhat similar to the approach I suggested above. However, it is not discussed there whether AC was used somewhere in this construction.","['polynomials', 'abstract-algebra', 'ring-theory', 'set-theory', 'axiom-of-choice']"
1838863,$\cos28 + \sin28= k^3\cos17=$?,"If $\cos28^\circ +\sin28^\circ = k^3$ then $\cos17^\circ = $?. Find in terms of $k$. MY ATTEMPT:
I tried finding $\cos28^\circ - \sin28^\circ$ in terms of $k$. Then I found out $\cos28^\circ$ with the help of the two equations. Finally I found out $\cos17^\circ$ from $\cos28^\circ$. However the answer is coming in terms of $\sqrt{k^6 - 2}$, which is way too complicated. The answer simply given here is $\frac{k^3}{\sqrt2}$. Please, help.",['trigonometry']
1838864,vacuous truth -> empty set is both included and not included in every set?,"I understand the concept of vacuous truth and its use in showing that the empty set is a subset of every set. Based on my understanding of vacuous truth (for example https://en.wikipedia.org/wiki/Vacuous_truth ) we have $\forall x \in \varnothing: P(x)$ or $\forall x(x \in \varnothing \implies P(x))$ Now $P(x)$ can be $x \in A$ so $\forall x (x \in \varnothing \implies x \in A)$. This establishes that $\varnothing \subset A$ (so the empty set is a subset of any set $A$). However, my understanding is that it doesn't really matter what $P(x)$ is---the vacuous truth holds regardless (I find this quite obvious from what the vacuous truth is and how it works; wikipedia illustrates that if there are no phones in a room then we can say either 1) all phones are on or 2) all phones are off or even 3) all phones are both on and off). Therefore $P(x)$ can instead be $x \notin A$ and we have $\forall x (x \in \varnothing \implies x \notin A)$. It seems to me this is just as vacuously true. But then this would mean that the empty set is not a subset of any set $A$ ($\varnothing \not \subset A$) (along with being a subset of any $A$). If this is so then: Why is only the $\varnothing \subset A$ part mentioned (I've never seen $\varnothing \not \subset A$ stated)? If both $\varnothing \subset A$ and $\varnothing \not \subset A$ are (vacuously) true then how can any coherent statement or proof be based on any of them? Further, if $\varnothing \subset A$ is true ""above"" $\varnothing \not \subset A$ then doesn't that require a proof beyond merely vacuous truth? Lastly, can we extrapolate this further and say that both $\forall x(x \in \varnothing \implies x = x)$ and $\forall x(x\in \varnothing \implies x \neq x)$ are vacuously true? This should be simple and clear so I'm wondering if I'm missing something. Thanks! (PS I did search for for this before posting and the closest I came to was Is this statement ""Every element in the empty set is greater than itself."" true or its negation is true? which is really a different case where $\neg \forall x \in \varnothing : P(x)$ is negated to become $\exists x : P(x)$. Our case here instead is: $\forall x \in \varnothing:P(x)$ becoming $\forall x \in \varnothing:\neg P(x)$.)","['logic', 'elementary-set-theory']"
1838884,Number of solutions to this nice equation $\varphi(n)+\tau(n^2)=n$,"How many natural numbers $n$ satisfy the equation$$\varphi(n)+\tau(n^2)=n$$where $\varphi$ is the Euler's totient function and $\tau$ is the divisor function i.e. number of divisors of an integer. I made this equation and I think it is not hard. I haven't solved this completely yet, so I want you to work on this along with me. I'd love to see your solutions!","['number-theory', 'divisor-counting-function', 'totient-function', 'elementary-number-theory']"
1838898,Theorem 2.17 from RCA Rudin,"$\bf 2.17\ $ Theorem $\ $ Suppose $X$ is a locally compact, $\sigma$-compact Hausdorff space. If $\frak M$ and $\mu$ are as described in the statement of Theorem $\it 2.14$, then $\frak M$ and $\mu$ have the following properties: $(a)\ \ $ If $E\in\frak M$ and $\epsilon>0$, there is a closed set $F$ and an open set $V$ such that $F\subset E\subset V$ and $\mu(V-F)<\epsilon$. $(b)\ \ $ $\mu$ is a regular Borel measure on $X$. $(c)\ \ $ If $E\in\frak M$, there are sets $A$ and $B$ such that $A$ is an $F_\sigma$, $B$ is a $G_b$, $A\subset E\subset B$, and $\mu(B-A)=0.$ $\rm P\scriptstyle{\rm ROOF}$ $\quad$ Every closed set $F\subset X$ is a $\sigma$-compact, because $F=\bigcup(F\cap K_n)$. Hence $(a)$ implies that every set $E\in\frak M$ is inner regular. This proves $(b)$. I understood the proof of points $(a)$ and $(c)$. But I can't understand the proof of $(b)$. It's obvious that every closed set is $\sigma$-compact. But how Rudin applies $(a)$ here? We have to show that if $\alpha>0$ then exists compact set $K\subset E$ such that $\mu(K)>\alpha$. Can anyone explain it to me please?","['general-topology', 'real-analysis', 'measure-theory']"
1838916,Solving $2x^4+x^3-11x^2+x+2 = 0$ [duplicate],"This question already has answers here : Quadratic substitution question: applying substitution $p=x+\frac1x$ to $2x^4+x^3-6x^2+x+2=0$ (4 answers) condition for a cubic polynomial to have a real root (3 answers) Closed 8 years ago . I am having no idea how I can solve this problem. I need help! Here's the problem $2x^4+x^3-11x^2+x+2 = 0$ I am learning Quadratic Expressions and this is what I need to solve, and I can't understand how :C","['algebra-precalculus', 'roots', 'polynomials', 'quadratics']"
1838931,"Conjecture about primes and the factorial: for all primes $p>5$, must there exist a prime $q<p$ such that $q\equiv m!\pmod p$ for some $2<m<p$?","Below $0\notin\mathbb N$. Further corrected conjecture: For all prime numbers $p>5$ there exist a prime number $q<p$ such that 
  $q\equiv m!\!\pmod p$, $2<m<p$. or Given a prime $p>5$ there exist a prime $q<p$ and $k,m\in\mathbb N$, $2<m<p$, such that $kp+q=m!$ I want help to prove the conjecture (which is tested for all $p<100,000,000$) or to find a counter-example. p=7  q=3  k=3   m=4
p=11 q=2  k=2   m=4
p=13 q=11 k=1   m=4
p=17 q=7  k=1   m=4
p=19 q=5  k=1   m=4
p=23 q=5  k=5   m=5
p=29 q=23 k=173 m=7
p=31 q=7  k=23  m=6
p=37 q=17 k=19  m=6
p=41 q=23 k=17  m=6
p=43 q=29 k=937 m=8
p=47 q=11 k=107 m=7
p=53 q=31 k=13  m=6
p=59 q=2  k=2   m=5
p=61 q=59 k=1   m=5
p=67 q=53 k=1   m=5 ... Up to the prime 1020361 For several reasons I have had major problems extracting my real observations. Also, the primes are not unique having this property, a lot of semiprimes, but not all, and occasionally some other numbers, also have it. It seems like less  than one third of all natural numbers have it and there is a secondary conjecture: For all primes $p$ there is a prime $q<p^2$ such that $q\equiv m!\pmod {p^2}$,  $2<m<p^2$. tested for all $p<100,000,000$. There are strong reasons to believe that the conjecture is true. Suppose 
$0\equiv m!\!\pmod n$, then $0\equiv r!\!\pmod n$ for all $r>m$. And suppose 
$n=sp^t$, where $p$ is the largest prime dividing $n$, $p\nmid s$ and $t>0$, then $0\equiv (pt)!\!\pmod n$. If $p$ is a large prime there are a lot of nonzero solutions to $x\equiv m!\!\pmod p$ and the probability for one of those solutions to be a prime increase with p.","['conjectures', 'number-theory', 'factorial', 'prime-numbers', 'modular-arithmetic']"
1838946,The number of positive integer solutions to the equation $x_1+2x_2+...+nx_n=n^2.$,"Let $n \ge 2, n \in \mathbb N$. $A_n$ denotes the number of positive integer solutions to the equation
  $$x_1+2x_2+...+nx_n=n^2.$$
  Prove inequality
  $$\frac{n^n(n-1)^{n-1}}{2^{n-1}\left(n!\right)^2}<A_n<\frac{n^{2n-1}}{\left(n!\right)^2}$$ I have no idea how to solve this problem.","['diophantine-equations', 'combinatorics', 'inequality']"
1838949,Pattern on last digits of numbers to a certain power,"There are 4 one-digit numbers which when squared have a last digit equal to the first number. They are 0,1,5 and 6. There are 2 two-digit numbers which when squared have their last two digits equal to the first number. They are 25 and 76. There are 2 three-digit numbers which when squared have their last three digits equal to the first number. They are 625 and 376. (i.e. 376^2 = 141376, ends with 376, 625^2 = 390625, ends with 625) This pattern can be continued for n-digit numbers which when squared have their last n-digits equal to the former number. This pattern can continue indefinitely. [The proof is left to the reader] i.e. Prove $5, 25, 625, 0625, 90625, 890625,...$ (we will count 0625 as part of the pattern even though it is not a four digit number as only 0 works and also because it continues the pattern.) and $6, 76, 376, 9376, 09376, 109376, 7109376, 87103976,...$ will continue indefinitely. However, that cannot just be my question since it's been asked before. (automorphic numbers) Therefore, what about other powers? ($n^3, n^4$) [ Edit : I forgot to mention and so on. So I actually wanted a general case $n^i$] Or even to the power of itself? ($n^n$)",['number-theory']
1838955,Subtracting expressions with radicals,"I want to subtract the expressions $20\sqrt{72a^3b^4c} - 14\sqrt{8a^3b^4c}$. I simplified this to $120ab^2\sqrt{2ac}-28ab^2\sqrt{2ac}$. My textbook says the answer is $92ab^2\sqrt{2ac}$. Why doesnt the $ab^2\sqrt{2ac}$ part change at all? I thought everything except the 92 would cancel out since it looks like it's cancelling out. This is my first time using stackexchange, please tell me if I can ask this question better. Thanks.","['algebra-precalculus', 'radicals']"
1838965,"If $\cos\alpha = \frac{2\cos\beta - 1}{2-\cos\beta}$ , $(0<\alpha , \beta< \pi)$, then $\tan\frac{\alpha}{2}\cot\frac{\beta}{2}$ is equal to?","If $\cos\alpha = \frac{2\cos\beta - 1}{2-\cos\beta}$ , $(0<\alpha , \beta< \pi)$, then $\tan\frac{\alpha}{2}\cot\frac{\beta}{2}$ is equal to? MY ATTEMPT: I tried simplifying the equation to get a relation between $\cos\alpha$ and $\cos\beta$. But $\tan$ and $\cot$ aren't coming. Please, help.",['trigonometry']
1838977,"Write $\,-4i\,$ in polar form","Write $\,-4i\,$ in polar form ${re}^{i\theta}$, with $r$, $\theta\in \mathbb R$, and $\,r\geq0,\;0\leq\theta<2\pi$. I let $\,z=-4i\,$ first, then get $\,r=\sqrt{0+{4^2}}=4$. However, $\,\tan\theta\,$ is undefined, can I just say $\theta$ is $\dfrac{\pi}{2}$? So $z$ in polar form will be  ${4e}^{i\pi/2}$. Thank you for your help!","['complex-analysis', 'complex-numbers']"
1838980,Solve $2^x+4^x=2$,"This is the equation, but the result is different from wolframalpha: $$2^x+4^x=2$$
$$2^x+2^{2x}=2^1$$
$$x+2x=1$$
$$x=\frac{1}{3}$$ WolframAlpha: $x=0$ Where is the error?","['algebra-precalculus', 'exponential-function', 'quadratics']"
1839028,How to prove that $\lim_{k\to+\infty}\frac{\sin(kx)}{\pi x}=\delta(x)$?,"It is well-known that: $$\lim_{k\to+\infty}\frac{\sin(kx)}{\pi x}=\delta(x).$$ This can also be written as $$ 2\pi\delta(x)=\int^{+\infty}_{-\infty}e^{ikx}\,\mathrm dk.$$ However, I don't know how to prove this without using Fourier Transform . I have already searched google and looked for some books, but I just get nothing. In short, I want to know the proof of this equation: $$\lim_{k\to+\infty}\int^{+\infty}_{-\infty}\frac{\sin(kx)}{\pi x}f(x)dx=f(0).$$","['dirac-delta', 'real-analysis', 'distribution-theory', 'calculus']"
1839035,Measurable function and the Mean Value Theorem,"Let $\,f:[a,b]\to \mathbb{R}\,$ be continuous on $[a,b]$ and derivable on $(a,b)$. By the mean value property, for all $\,x\in (a,b)\,$ there exists $\,\xi_x\in (a,x)\,$ such that $\,f(x)-f(a)=f'\left(\xi_x\right)(x-a)$. Let $\,h:(a,b)\to\mathbb{R}\,$ be defined as $\,h(x)=\xi_x$. Is the function $h$ measurable? Is $\,f'\!\circ h\,$ measurable? The motivation for this question is the following: in an exercise in class, I estimated $\,\int_{\mathbb{R}} \left\lvert F(x)-F(-x)\right\rvert dx\,$ for a certain ""good"" function $\,F$ using $\,\leq \int_{\mathbb{R}} \left\lvert F'\left(\xi_x\right)\right\rvert 2\left\lvert x\right\rvert dx,\,$ but the professor told me to be careful, as he wasn't sure of the measurability of $\,x\mapsto F'\left(\xi_x\right)$. Edit: Thank you for your answers. Assuming that $x\mapsto \xi_x$ is well-defined (taking $\xi_x$ as the smallest possible), is it measurable?","['real-analysis', 'measure-theory']"
1839057,Showing that $\int_{-n}^{n}{x+\tan{x}\over A +B(x+\tan{x})^{2n}}dx=0$,"Where n is an integer, $n\ge1$ and $(A,B)$ just constants $$I=\int_{-n}^{n}{x+\tan{x}\over A
+B(x+\tan{x})^{2n}}dx=0$$ It is obvious that $$\int_{-n}^{n}x+\tan{x}dx=0$$ Let make a substitution for I $$u=x+\tan{x}\rightarrow du=1+\sec^2{x}dx$$ $$\int_{-n}^{n}{u\over A+Bu^{2n}}{du\over 2+\tan^2{u}}=0$$ I can't find a standard integral of this. I am shrugged at this point on how to continued any further, required some help please Also note that $$\int_{-n}^{n}{u\over A+Bu^{2n}}du=0$$ And $$\int_{-n}^{n}{u\over A+Bu^{2n}}{du\over C+D\tan^{2k}{u}}=0$$ Where A , B , C and D are just constants $n,k\ge1$ are both integers","['proof-verification', 'calculus', 'functions', 'integration', 'definite-integrals']"
1839064,Evaluate $\int \frac {\sin(x)}{x^2 + 4x + 5}dx$,"Question: Evaluate
  $$ \int \frac{\sin(x)}{x^2 + 4x + 5} dx=\int \frac {\sin(x)}{(x + 2)^2 + 1}dx $$ By using the change of variable $y = x + 2$ we have that $dy = dx$ then $$I = \int \frac{\sin(y - 2)}{y^2 + 1} dy$$ $f = \sin(y - 2)$, $f' = \cos(y - 2)$ $g' = \frac {1} {y^2 + 1}$, $g = \arctan(y)$ $I = \sin(y - 2) \cdot \arctan(y) + \int \cos(y - 2)  \arctan(y) dy$ $I_1 = \int \cos(y - 2) \cdot \arctan(y) dy$ How can I solve?","['complex-analysis', 'integration', 'calculus']"
1839065,"Complete a proof that $F(x,y)$ is contracting.","Can anyone fill in the dots in this proof? Let $D := [0,\frac{1}{2}]^2$. Show there is exactly one $(x,y)=(x^*,y^*)\in D$ such that
  \begin{align*}
x &= \frac{x^3}{2} + y^4 + \frac{1}{4} \,, \\
y &= x^4 + \frac{y^3}{2}+\frac{1}{5} \,.
\end{align*} Obviously I need to use Banach's fixed point theorem, so I need to show $F$ (as defined below) is contracting. My try (the $q \in \mathbb R$, $q<1$, isn't filled in yet of course) Let $F(x,y) = \begin{pmatrix} \frac{x^3}{2} + y^4 + \frac{1}{4} \\ x^4 + \frac{y^3}{2}+\frac{1}{5}\end{pmatrix}$, $x=(x_1,x_2),y=(y_1,y_2)$. Then 
\begin{align*}
|F (x_1,x_2)-F(y_1,y_2)|^2 &= |F_1 (x_1,x_2)-F_1(y_1,y_2)|^2 - |F_2 (x_1,x_2)-F_2(y_1,y_2)|^2 \\
&= \left| \frac{x_1^3}{2} - \frac{y_1^3}{2} + x_2^4  - y_2^4 \right|^2 - \left|  \frac{x_2^3}{2} - \frac{y_2^3}{2} + x_1^4 - y_1^4 \right|^2 \\
&\ \ \vdots \\
&\le q^2 |x_1-y_1|^2 + q^2 |x_2 - y_2|^2 \\
&= q^2 |x-y|^2 \,.
\end{align*}
So now we have $F(x)-F(y)|\le q |x-y|$ and thus $F\colon D \to D$ contracting, $D \subset \mathbb R^2$ closed, so by Banach's fixed point theorem there exists exactly one $(x^*,y^*)\in D$ as described. $\qquad \qquad \qquad  \Box$","['multivariable-calculus', 'fixed-point-theorems', 'real-analysis', 'banach-fixed-point']"
1839100,"Is there a closed form for the integral $\int_0^1 x^n \log^m (1-x) \, {\rm d}x$?","Let $n \in \mathbb{N}$. We know that: $$\int_0^1 x^n \log(1-x) \, {\rm d}x = - \frac{\mathcal{H}_{n+1}}{n+1}$$ Now, let $m , n \in \mathbb{N}$. What can we say about the integral $$\int_0^1 x^n \log^m (1-x) \, {\rm d}x$$ For starters we know that $\displaystyle \log^m (1-x)=m! \sum_{k=m}^{\infty} (-1)^k \frac{s(k, m)}{k!} x^k$ where $s(k, m)$ are the Stirling numbers of first kind . Thus \begin{align*}
\int_{0}^{1} x^n \log^m (1-x) \, {\rm d}x &=m! \int_{0}^{1}x^n \sum_{k=m}^{\infty} (-1)^k \frac{s(k, m)}{k!} x^k  \\ 
 &= m! \sum_{k=m}^{\infty} (-1)^k \frac{s(k, m)}{m!} \int_{0}^{1}x^{n+m} \, {\rm d}x\\ 
 &= m! \sum_{k=m}^{\infty} (-1)^k \frac{s(k, m)}{m!} \frac{1}{m+n+1}
\end{align*} Can we simplify? I know that Striling numbers are related to the Harmonic number but I don't remember all identities.","['stirling-numbers', 'real-analysis', 'integration', 'sequences-and-series']"
1839114,Semi-finite trace on a von Neumann algebra: Equivalent definitions,"Let $(N,\tau)$ be a semi-finite von Neumann algebra. This means that $\tau$ is a normal, faithful and semi-finite trace. Normality means that $\tau(x) = \sup_i \tau(x_i)$ if $x \in N_+$ is the limit of an increasing net $x_i$ in $N_+$. With $\tau$ one associates the following sets: $$
N_\tau^+ := \{x \in N_+ : \tau(x) < \infty \}
$$
and 
$$
 \mathscr L_\tau^1(N) := \{ x \in N : \tau(\lvert x \rvert) < \infty \}.
$$
The latter set is in fact a $*$-ideal and equals the complex linear span of $N_\tau^+$. I read a few definitions of semi-finiteness and I wonder if these are all equivalent. Lets recall a few definitions: Every $0 \neq x \in N_+$ majorizes some $0 \neq y \in N_\tau^+$. (Takesaki: Theory of Operator Algebras I, p. 309) $\tau(x) = \sup \{ \tau(y) : y \leq x, \ y \in N_\tau^+ \}$ for $x \in N_+$. (Dixmier: von Neumann algebras p. 93) The $\sigma$-weak (=ultra weak) closure of $N_\tau^+$ equals $N_+$. (A. M. Bimkchentaev: On a Property of $L^p$ Spaces on Semifinite von Neumann Algebras) For all $x \in N_+$ there exists an increasing net $x_\alpha$ in $N_\tau^+$ with strong (SOT) limit $x$. (Edward Nelson: Notes on Non-commutative Integration) I hope that all these definitions are equivalent for a normal tracial weight $\tau$ on a von Neumann algebra. By tracial I mean that $\tau(x^*x) = \tau(xx^*)$ for all $x \in N$. I am also wondering if the normality may be dropped to see the equivalence. Maybe the following result is helpful (Haagerup): A weight on a von Neumann algebra is normal iff it is ultra weakly lower semi-continuous.","['operator-theory', 'functional-analysis', 'von-neumann-algebras', 'trace', 'operator-algebras']"
1839120,"How to maximize Std Dev given a range of possible values, a number of values, and a specific mean?","( I'm asking here and not stats.stackexchange because I'd like a mathematical proof of this ) In this question: Prove how to maximize Standard Deviation given a certain mean $\bar{x}$ and set of values ; as pointed out by @mathguy in his second paragraph, I assumed that the mean and values were not independent and that the mean was $\frac{a+b}{2}$ where $a$ and $b$ are the minimum and maximimum values of the range respectively. I'd like to understand how to maximize the SD of $n$ values in a range $[a,b]$ for an arbitrary mean $\bar{x}=y$. For example, how would you maximize the standard deviation for $5$ values in the range $[0,1]$ with a mean of $0.3$? Ideally I'd love to have a solution for this specific example (or another) and an understanding for the general solution. Should we use calc, and if so how? Can we use something else?","['statistics', 'standard-deviation', 'optimization']"
1839156,Is there a quick way to justify that this elementary probability is equal to $\frac23$?,"I just solved this problem with the conditional probability formula and after a while the answer was surprisingly $\frac23$. I believe there must be a tricky short way to calculate it. Can somebody help me? There are $n$ urns of which the $r$th contains $r-1$ red balls and $n-r$ magenta balls.  You pick an urn at random and remove two balls at random without replacement.  Find the probability that: the second ball is magenta, given that the first is magenta.","['combinatorics', 'probability', 'discrete-mathematics']"
1839178,How to prove that $\int_{0}^{1}\ln{(x/(1-x))}\ln{(1+x-x^2)}\frac{dx}{x}=-\frac{2}{5}\zeta{(3)}$,"$$\int_{0}^{1}\ln{\big(\frac{x}{1-x}\big)}\ln{(1+x-x^2)}\frac{dx}{x}=-\frac{2}{5}\zeta{(3)}$$ Put  $$\frac{x}{1-x}=y$$
 $$I=\int_{0}^{\infty}\ln{y}\ln{(1+3y+y^2)}\frac{dy}{y(y+1)}=\frac{8}{5}\zeta{(3)}$$
 Simple integral at first sight, however I cannot prove that. I would appreciate your help.","['integration', 'definite-integrals', 'calculus']"
1839192,"Universal property, localization of rings and modules, and initial element in a category","Sorry for the confusing title. I just started learning category theory and am very confused about the concept ""universal property"". I am not even sure whether my ""proof"" is a proof or is just a restating of the original problem. Here is a problem from Vakil's notes of Algebraic Geometry. Exercise 1.3.D. Verify that $A\rightarrow S^{-1}A$ satisfies the following universal property: $S^{-1}A$ is initial among $A$-algebras $B$ where every element of $S$ is sent to an invertible element in $B$. My attempt: I searched and found this question on MSE: https://math.stackexchange.com/questions/1816224/localization-and-the-universal-property?rq=1 . So I constructed my ""proof"" based on that: We consider a category $\mathscr{C}$ with objects as pairs of, e.g., $(S^{-1}A, A\xrightarrow{i_s} S^{-1}A), (B, A\xrightarrow{\pi_B} B), (C, A\xrightarrow{\pi_C} C)$. The objects are pairs whose first components are $A$-algebras, and second components are ring maps from $A$ to the corresponding $A$-algebras, in which elements from $S$ are sent to an invertible element. Notice that $S$ is in $A$. For any two objects $B, C$, the morphisms are ring maps between $B$ and $C$. We have the following diagram: We see that any map $\pi: A\rightarrow B$ where every element of $S$ is sent to an invertible element must factor uniquely through $i_s: A\rightarrow S^{-1}A$. My question: Could anyone verify my ""proof""? I am not sure how this universal property could be used. Edit: According to @Hoot's suggestion, I will define $\phi$ and prove that it is unique. Define $\phi: S^{-1}A\rightarrow B$ by $\phi(a/s)=\pi(a)\pi(s)^{-1}$, for $s\in S, a\in A$. We prove that $\phi$ is well-defined. Let $a_1/s_1=a_2/s_2$, i.e., $s(a_1s_2-a_2s_1)=0$ for some $s\in S$. This implies $\pi(a_1s_2-a_2s_1)=0$. We have $\phi(a_1/s_1)=\pi(a_1)\pi(s_1)^{-1}, \phi(a_2/s_2)=\pi(a_2)\pi(s_2)^{-1}$. Apparently they are equal. By some similar computations we can prove it is a ring homomorphism. It remains to show that $\phi$ is unique. Let $\psi: S^{-1}A\rightarrow B$ be another ring homomorphism, such that $\pi=\psi\circ i_s$. Then $\pi(a)=\psi(a)$ for all $a\in A$. Since it is homomorphism, $\psi(a/s)=\psi(a)\psi(s)^{-1}=\pi(a)\pi(s)^{-1}$. This shows that $\psi=\phi$. Another question: In the notes the author says every map $A\rightarrow B$ that sends elements in $S$ to an invertible element factors uniquely through $A\rightarrow S^{-1}A$. I'm still confused about this sentence. Shouldn't we say it factors uniquely through $S^{-1}A\rightarrow B$, since that is the unique universal map? Thank you for your help!","['algebraic-geometry', 'localization', 'ring-theory', 'universal-property', 'category-theory']"
1839209,Hints on showing Cauchy sequence converges,"Let $T>0$ and $L\geq0$. Let $C[0,T]$ be the space of all continuous real valued functions on $[0,T]$ with the metric $\rho$ defined by $$\rho(x,y)=\sup_{0\leq t\leq T}e^{-Lt}\left|x(t)-y(t)\right|$$ How can we verify that $\left(C[0,T],\rho\right)$ is a complete metric space? My working: Let $\{x_n(t)\}$ be an arbitrary Cauchy sequence in $C[0,T]$. We need to show that $\{x_n(t)\}$ converges to say $x(t)\in C[0,T]$. The definition of Cauchy sequence states that $\{x_n(t)\}$ is Cauchy if $\forall\epsilon>0,\exists N$ such that $m,n\geq N\implies\rho(x_m(t),x_n(t))<\epsilon$. But $\rho(x_m(t),x_n(t))=\sup_{0\leq t\leq T}e^{-Lt}\left|x_m(t)-x_n(t)\right|$. Since every Cauchy sequence is bounded, then $\forall t\in[0,T]$, $\rho\left(x_m(t),x_n(t)\right)<K$ for a constant $K$. Then I am stuck, I am not sure how to show $\{x_n(t)\}$ converges. Could anybody please give some hints? Thanks.","['cauchy-sequences', 'sequences-and-series', 'metric-spaces', 'convergence-divergence', 'analysis']"
1839230,What is a short exact sequence?,"I'll just quote my book here so you can see the definitions I have: Suppose that you are given a sequence of vector spaces $V_i$ and linear maps $\varphi_i: V_i\to V_{i+1}$ connecting them, as illustrated below: $$\cdots \longrightarrow V_{i-1} \stackrel{\varphi_{i-1}}{\longrightarrow} V_i \stackrel{\varphi_{i}}{\longrightarrow} V_{i+1} \stackrel{\varphi_{i+1}}{\longrightarrow} \cdots$$ The maps are said to be exact at V_i if $\operatorname{im} \varphi_{i-1} = \operatorname{ker}\varphi_i$.  The sequence is called an exact sequence if the maps are exact at $V_i$ for all $i$.  $\dots$ If $V_1, V_2$ and $V_3$ are three vector spaces, and if the sequence $$0 \stackrel{\varphi_0}{\longrightarrow} V_{1} \stackrel{\varphi_{1}}{\longrightarrow} V_2 \stackrel{\varphi_{2}}{\longrightarrow} V_{3} \stackrel{\varphi_{3}}{\longrightarrow} 0 \tag{1.7}$$ is exact, it is called a short exact sequence .  In this diagram ""$0$"" represents the zero-dimensional vector space. OK, here's what I'm not understanding.  If the image of any function in this sequence is the kernel of the next function, doesn't every step of this just map to $0$?  And even if it didn't, because we're starting with the $0$ vector space, everything has to map to $0$ because linear transformations always map $0$ to $0$.  So I'm not understanding this definition at all.  The first exercise right below these definitions is to show that equation $(1.7)$ implies that $\varphi_1$ is injective and $\varphi_2$ is surjective.  But all I'm seeing here is a chain of functions mapping zero to zero.  Can someone explain what I'm missing here?","['exact-sequence', 'linear-algebra']"
1839277,Study of differentiablity of function,"Study the differentiability of the function $f:\mathbb{R}^2\rightarrow \mathbb{R}$ $f(x,y)=\begin{cases} 
      \frac{x^3+y^3}{x^2+\left|y\right|} & (x,y)\ne(0,0) \\
      0 &(x,y)=(0,0) \\
   \end{cases}$ in point $(0,0)$. So what I did is I calculated the partial derivatives of the function in point $(0,0)$. I got:
$$\frac{∂f}{∂x}\left(0,0\right)=\lim_{t\rightarrow 0}\left(\frac{f\left(t,0\right)-f\left(0,0\right)}{t}\right)=\lim_{t\rightarrow 0}\left(\frac{t^3}{t^3}\right)=1$$and
$$\frac{∂f}{∂y}\left(0,0\right)=\lim_{t\rightarrow 0}\left(\frac{f\left(0,t\right)-f\left(0,0\right)}{t}\right)=\lim_{t\rightarrow 0}\left(\frac{t^3}{t\left|t\right|}\right)=0$$ So he partial derivatives do exist. Next I think I need to calculate:
$$l=\lim_{h\to O_m}\left(\frac{f\left(a+h\right)-f\left(a\right)-<h,\Delta f\left(a\right)>}{\left|\left|h\right|\right|}\right)$$ $$\:l=\lim_{\left(h_1,h_2\right)\rightarrow \left(0,0\right)}\:\left(\frac{f\left(h_1,h_2\right)-f\left(0,0\right)-h_1\cdot 1-h_2\cdot 0}{\sqrt{h_1^2+h_2^2}}\right)$$ $$\:l=\lim_{\left(h_1,h_2\right)\rightarrow \left(0,0\right)}\:\left(\frac{\frac{h_1^3+h_2^3}{h_1^2+\left|h_2\right|}-h_1}{\sqrt{h_1^2+h_2^2}}\right)$$ And this is the point at which I get stuck, since I don't really fully understand what I'm doing. Can anyone help me with this a bit?","['multivariable-calculus', 'derivatives', 'limits']"
1839342,Why are an even number of flips required to get back to the original list?,"Consider the list of numbers $[1, \cdots, n]$ for some positive integer $n$. Two distinct elements $i$ and $j$ of the list can be switched in a so-called flip . For example, let $f$ be a flip that switches $2$ and $4$. Then $f([1,2,3,4]) = [1,4,3,2]$. Now consider a sequence of $k$ flips $f_1, \cdots, f_k$ of the list $[1, \cdots, n]$ such that $f_1(f_2(\cdots f_k([1,\cdots,n])\cdots)) = [1,\cdots, n]$, i.e. performing all flips gives the original list. Then $k$ must be even. I would like to find a proof of this proposition that is elementary as possible. I already came up with a justification using permutation groups which goes as follows: Each flip $f_i$ corresponds to a transposition of the list $[1, \cdots, n]$. Since the composition $f_1f_2\cdots f_k$ results in the identity, it must be an even permutation. Thus any representation of $f_1f_2\cdots f_k$  as a product of transpositions must contain an even number of transpositions. In particular, since each $f_i$ is a transposition, it follows that $k$ must be even. This ""proof"" trivializes the problem statement as it is by using relatively high-powered facts about permutation groups. Is there a lower-level proof that avoids using theses results? (Ideally such a proof would avoid permutation groups altogether and be understandable to the layman.) Edit: to clarify (since this question hasn't been getting as much attention as I had hoped), any proof that avoids re-deriving these powerful results about permutations would suffice. Basically I would want a proof that does not prove much more than the question requires, i.e. doesn't have a part where it says ""in particular"".","['parity', 'alternative-proof', 'abstract-algebra', 'permutations', 'symmetric-groups']"
1839398,"$\binom{n}{k}$ is a ""binomial coefficient;"" $n \; P \; k$ is a ""__________.""","If I want to search for information concerning $\binom{n}{k}$, I can't Google that symbol directly, nor can I search for something like ""n C k"" and get anything relevant, but because the term ""binomial coefficient"" exists it's possible to search for, say, ""Catalan numbers in terms of binomial coefficients"" or whatever. Conversely, if I want to write something involving $\binom{n}{k}$ in a fundamental way and make it discoverable to others' searches, I should make sure to include the term ""binomial coefficient."" Is there a similar noun describing the function
$$n \; P \; k = \frac{n!}{(n-k)!}$$
Obviously one could use a rather verbose description, but that's not very useful for searchability -- imagine replacing the search described above with ""Catalan numbers in terms of the number of combinations of k elements out of an n element subset,"" for instance, to which this would be analogous. The best solution I can see at present is to use the term ""binomial coefficient"" and maybe rewrite the formula to include an extraneous $k!$ or something.","['terminology', 'combinatorics']"
1839424,Find an estimator by using the method of moment,"Let $X$ be a discrete random variable with density function: 
  $$p(x;\theta)=\left(\frac{\theta}{2}\right)^{\lvert x\rvert}(1-\theta)^{1-\lvert x\rvert}$$
  where $x\in\{-1,0,1\}$ and $\theta \in[0,1]$. I have to find an estimator of $\theta$ by using the method of moment. Now, the first and second moments are: $\mathbb{E}(X)=0$ and $\mathbb{E}(X^2)=\theta$ Based on this , when a simple random sample of size $n$ is drawn: $\hat \mu_1=\dfrac{1}{n}\sum_{i=1}^nx_i$ and $\hat \mu_2=\dfrac{1}{n}\sum_{i=1}^nx_i^2$ So, the estimator $\hat \theta$ is 
$$\hat \theta = \dfrac{1}{n}\sum_{i=1}^nx_i^2$$ Is that correct? :-) Edit I also have to prove that the estimator is unbiased and consistency. For first question:
$$\mathbb{E}(\hat \theta)=\frac{1}{n}\mathbb{E}(X_1^2)+\frac{1}{n}\mathbb{E}(X_2^2)+\ldots+\frac{1}{n}\mathbb{E}(X_n^2)=\frac{1}{n}(\theta+\theta+\ldots+\theta)=\theta$$ thus the estimator is unbiased. For consistency we need that $\lim_{n \to \infty}\mathbb{E}(\hat \theta)=\theta$ and $\lim_{n \to \infty}\mathbb{Var}(\hat \theta)=0$. Any help?","['statistics', 'parameter-estimation']"
1839427,"Let $H$ be hilbert and $T$ a BLO, such that $T:H\rightarrow H$. Prove that $\langle T(x),x \rangle = 0$ implies $T = 0$. [duplicate]","This question already has an answer here : Prove that if $\langle Tx,x\rangle =0$ for all $x \in X$, then $T = 0$ (1 answer) Closed 3 years ago . Let $H$ be hilbert and $T$ a BLO, such that $T:H\rightarrow H$. Prove that $\langle T(x),x \rangle = 0$ implies $T = 0$. Any hints to tackle this problem? i tried writing x as $x = u + v$ where $u \in Y$ and $v \in Y^T$ for some closed linear subspace of $H$, but i did not see somethins smart. Is it maybe smart to try using the contra positive?",['functional-analysis']
1839454,Finding the method of moments estimator for the Uniform Distribution,"Let $X_1, \ldots, X_n \sim \text{Uniform}(a,b)$ where $a$ and $b$ are unknown paramaters and $a < b$. (a) Find the method of moments estimators for $a$ and $b$. (b) Find the MLE $\hat{a}$ and $\hat{b}$. For part (b), consider that $$
f(x) = \begin{cases} 0 & \text{ if } x \notin [a,b] \\
                     1/(b-a) & \text{ if } x \in [a,b] \\
\end{cases} 
$$ Thus, the MLE estimate will be $(\min \{X_1, \ldots, X_n \}$, $\max \{X_1, \ldots, X_n \})$. But what about part (a)?","['statistics', 'probability']"
1839490,Integration by parts or substitution?,"$$\int_{}^{}x e^x \mathrm dx$$ One of my friends said substitution , but I can't seem to get it to work.
Otherwise I also tried integration by parts but I'm not getting the same answer as wolfram. The space in the question seems like it shouldn't take more than 2 lines though. Am I missing something? Thanks to all the answers below , I messed up in the original question it was actually $$\int_{}^{}x e^{x^2} \mathrm dx$$ With help from the below answers I did the following: Let $u = x^2$ , then $du=2x\mathrm dx$ So rewriting the integral $$\int_{}^{}{{x\cdot e^u} {1 \over 2x}} \mathrm dx$$ Simplifying yields: $${1 \over 2x}\int_{}^{}{e^u}\mathrm dx$$ Which in turn yields: $${\frac{e^u}{2}} + C$$ The rest is fairly obvious!","['integration', 'calculus']"
1839495,Find last three nonzero digits of $1^1 \cdot 2^2 \cdot 3^3 \cdot ... \cdot 25^{25}$,"Find the last three nonzero digits of $1^1 \cdot 2^2 \cdot  3^3 \cdot  ... \cdot  25^{25}$ . I had been sitting with this problem whole day now, what I had tried so far: Dividing the product by $10^{100}$ (since there are $5^{100}$ (taking fives from factors as well)). And playing with Chinese remainder theorem. $1^1 \cdot  2^2 \cdot  3^3   \dots   25^{25} \equiv 0 \pmod{8}$ But I don't see any way apart from brute forcing the modulus $125$ . I had also noticed that the product can be rewritten as: $$ \frac{25!}{0!}\cdot  \frac{25!}{1!} \cdot  \frac{25!}{2!} \cdot  \frac{25!}{3!} \cdot  \cdot  \cdot  \frac{25!}{24!}$$ But I can't seem to get any useful information from that.","['number-theory', 'chinese-remainder-theorem', 'perfect-powers', 'modular-arithmetic', 'elementary-number-theory']"
1839496,Expected number of tosses to get 3 consecutive Heads [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question I have a fair coin. What is the expected number of tosses to get three Heads in a row? I have looked at similar past questions such as Expected Number of Coin Tosses to Get Five Consecutive Heads but I find the proof there is at the intuitive, not at the rigorous level there: the use of the ""recursive"" element is not justified. The Expectation $\mathbb E[X]$ is a number, not a random variable, as it is treated there. Please make this clear.",['probability']
1839497,What is the difference between hyperreal numbers and dual numbers,Wikipedia has two different but unconnected pages for Hyperreal and Dual numbers . https://en.wikipedia.org/wiki/Hyperreal_number and https://en.wikipedia.org/wiki/Dual_number I cannot stop seeing them very related to each other. In one the product is not explicitly defined (it is said that it is the result of a series of cuts) in the other it is stressed that $\epsilon^2=0$ is the defining property. Both are related to derivatives when evaluated in functions (for example of polynomials or Taylor series) although in one the st symbol is used and in the other $\epsilon$ is used. Is there a simple relation between these two mathematical constructs? are both the same? is one just a specialization (for a certain operation) case of the other? Is one a field and the other just a ring for example? Is the difference the partial vs. total order?,"['nonstandard-analysis', 'real-analysis', 'definition']"
1839510,How to get the correct angle of the ellipse after approximation,"I need to get the correct angle of rotation of the ellipses. These ellipses are examples. I have a canonical coefficients of the equation of the five points. $$Ax ^ 2 + Bxy + Cy ^ 2 + Dx + Ey + F = 0$$ Ellipses: Points: Zero ellipse:   [16,46]  [44,19]  [50,35]  [31,61]  [17,54]
First ellipse:  [14,95]  [47,71]  [55,83]  [23,107] [16,103]
Second ellipse: [12,128] [36,117] [58,128] [35,146] [13,136]
Third ellipse:  [16,164] [29,157] [54,188] [40,195] [17,172]
Fourth ellipse: [22,236] [31,207] [50,240] [40,252] [26,244] Coefficients: Zero ellipse                 First ellipse                Second ellipse                Third ellipse                  Fourth ellipse
A: 0.00039679682899033947    A: 0.00007365946131786486    A: 0.000021675708916102692    A: 0.00004189611868790682      A: 0.00004418821462144713
B: 0.00021821614636627075    B: 0.00006770936206052314    B: -0.000002834437159146921   B: -0.00004283926773569747     B: -0.000012890924982902275
C: 0.00024184103978866782    C: 0.00009244517004290531    C: 0.000057745675577137415    C: 0.00003944519997403195      C: 0.000020104667194164587
D: -0.03490717401354479      D: -0.01110309000831378      D: -0.0011544916677563865     D: 0.0046141642800698515       D: -0.00016090203479326006
E: -0.026421911476591453     E: -0.01877226426820658      E: -0.015086084806642279      E: -0.012396706675782408       E: -0.008774013189179199
F: 1.0                       F: 1.0                       F: 1.0                        F: 1.0                         F: 1.0 I successfully find the coordinates of the center and the length of the axes. But I get the wrong rotation. I get the angle using the equation:
$$\theta = \frac{1}{2} \arctan \left( \frac{B}{A-C} \right) $$ Angles result: Zero ellipse:    0.4766612094205555
First ellipse:  -0.6500786401646479
Second ellipse:  0.03921024408607312
Third ellipse:  -0.7568233305427435
Fourth ellipse: -0.24572750447422026 Visualization of the result: How do I calculate the correct angle? And how to convert the value to degrees without errors? UPDATED: I wrote the algorithm here . The first set points angle is not correct. In the second set of points, the correct angle. You can put your own values and see the result. UPDATED: SOLVED! Based on the response of @Ng Chung Tak, I managed to get into the code and implement the right formula! Implementation of the code here . Formula: $$\theta = \tan^{-1}
 \left(
   \frac{C-A}{B}+\frac{\sqrt{(A-C)^{2}+B^{2}}}{B} \:
 \right) $$ Result: Thanks to all!","['discrete-mathematics', 'calculus', 'conic-sections', 'ordinary-differential-equations', 'quadratics']"
1839562,Does this inequality involving inverse tangent (arctan) hold?,"I am wondering if the following statement is true for $\theta\in\left(-\frac{\pi}{2},\frac{\pi}{2}\right)$ and $x,y\in\mathbb{R}$: $$\tan^{-1}\left(\frac{\sin(\theta)+x}{\cos(\theta)+y}\right)\leq\theta+x\cos(\theta)-y\sin(\theta)+c(x^2+y^2),$$ where $c\geq2$ is a constant (though an answer showing that constant $c$ exists without quantifying what it is would be good enough). I've plotted the difference between RHS and LHS for multiple values of $\theta$ and the inequality seems to hold.  However, I have no idea how to prove this, as my usual method of Taylor series expansion (around $(x,y)=(0,0)$ does not seem to work here (the series converges only for $|x|,|y|<1$).  Can anyone help? If the above inequality holds, I think that it would solve this question .","['inequality', 'trigonometry']"
1839585,"two metrics on X such that lim d1(xn,x)=0 <=> lim d2(xn,x)=0, does it imply the identity of the two induced topologies?","Two metrics $d_1, d_2$ on $X$
For all $x_n, x$ from $X$ it holds:
$$\lim d_1(x_n,x)=0 \iff \lim d_2(x_n,x)=0$$ Does it imply that the topology induced by $d_1$ is the same as the topology induced by $d_2$? For example:
I have two definition of metric for compact convergence.
$X=C(IR,E)$ all continuous functions from $IR$ to $E$, where $E$ is a metric space with metric $q$ $d_1(f,g)=\sum_{i=1}^\infty 2^{-i} * \sup \{q(f(x),g(x)) :x \in [0, i] \} $ $d_2(f,g)=\sum_{i=0}^\infty \min \{2^{-i}, sup(q(f(x),g(x)) : x\in [0, i]) \} $ $\lim d_1(f_n,f)=0 \iff$ For all compact subset $K$ of $X$: $f_n$ converge uniformly to $f$ on $K \iff
\lim d_2(f_n,f)=0$. Do these two metrics induce the same topology?","['general-topology', 'analysis']"
1839598,Find roots of polynomial in a finite field,"I need to build a field $L$ of 121 elements and find how many roots polynomial $g=x^9-1$ has in $L$. Then to find all these roots. So, $121=11^2$ this is power of prime. We can build finite field of 121 elements by finding normal irreducible polynomial of of power 2. We can see that $x^9-1 = (x-1)(x^2+x+1)(x^6+x^3+1)$, lets take $h=x^2+x+1$ as irreducible since it does not have natural roots in $Z_{11}$. We can build the field $L=\{k\alpha+b + h(\alpha), k,b \in Z_{11}\}$ Instantly we can see that 1 is the root of $g$ because of $(x-1)$. Am I right so far? How can I find other roots of $g$ or at least find their conunt?","['number-theory', 'finite-fields', 'irreducible-polynomials']"
1839605,"Is there a measure space $(X,\mathcal M, m)$ such that $\{m(E) \mid E \in \mathcal M\} = \Bbb Q_{\geq 0} \cup \{+\infty\}$?","I have in mind the following question: Is there a measure space $(X,\mathcal M, m)$ such that the range of $m$ satisfies $S:=\{m(E) \mid E \in \mathcal M\} = \Bbb Q_{\geq 0} \cup \{+\infty\}$? (I would also accept a space where $\Bbb Q_{\geq 0} \cup \{+\infty\}$ is replaced by $\Bbb Q_{\geq 0}\,$.) An idea would be to take $X=\Bbb N$ and define $m(\{n\}):=r_n$ the $n$-th positive rational number. But then $m(\{k(n) \in X \mid r_n=1/n^2, n\geq 0\})=\pi^2/6$ is not rational. So the measurable sets corresponding to $1/n^2$ shouldn't be disjoint.
To avoid this, we could demand that some fixed element $x_0$ belongs to every non-empty measurable set. But this is not possible since $\mathcal M$ is a $\sigma$-algebra, in particular it is closed under taking complements. Similarly, if $(x_n)$ is any sequence of positive rational numbers that converges to $\sqrt 2$, the measurable sets corresponding to $x_n$ shouldn't included one in another (to avoid a chain).
I could replace $\pi^2/6$ and $\sqrt 2$ by any positive real number (since $\Bbb Q$ is dense in the reals)! Therefore, my intuition is that such a measure space can't exist. Actually, I believe that the set $S$ defined above should be closed in $\Bbb R \cup \{+\infty\} \cong S^1$ (and even ""closed under taking series"" with elements in $S$). But I'm unsure if this is true, and how to prove it. Any comment would be appreciated!","['examples-counterexamples', 'measure-theory']"
1839608,Demystifying the tensor product,"It seems to me, through my mathematical immaturity, that the tensor product seems to beg for more well-definition. I am working in vector spaces (so we always have a free module) and here is what my professor has shown me thus far. We can define the tensor product of two maps (multi-linear) as follows. Let $S \in \mathcal{L}(V_1, \dots, V_n; \mathcal{L}(W;,Z))$ and $T \in \mathcal{L}(V_{n+1}, \dots , V_{n+m};W)$ , We define $S \otimes T \in \mathcal{L}(V_1, \dots , V_{n+m};Z)$ by setting $$S \otimes T(v_1, \dots ,v_{n+m})=S(v_1, \dots, v_n)[T(v_{n+1}, \dots , v_{n+m})]$$ Now, we do have $\mathcal{L}(V_1, \dots , V_{n+m};Z) \cong V^*_1 \otimes \dots \otimes V^*_{n+m} \otimes Z$ I believe. So it is, up to isomorphism, a tensor but not, itself, a tensor. Further, suppose that $V_1, \dots , V_n$ are vector spaces. We define the tensor product $$V_1 \otimes \dots \otimes V_n = \mathcal{L}(V^*_1, \dots V^*_n; \mathbb{F})$$ Since we regard $V$ and $V^{**}$ to be identified we have $$v_1 \otimes \dots \otimes v_n \in V_1 \otimes \dots \otimes V_n$$ defined $$(v_1 \otimes \dots \otimes v_n)(L_1, \dots L_n)=L_1(v_1)\dots L_n(v_n)$$ Finally, we have defined a tensor of type $m,n$ to be a multi-linear map from $\underbrace{V^* \times \dots \times V^*}_{m \text{ times}}\times \underbrace{V \times \dots \times V}_{n \text{ times}} \to \mathbb{F}$ . problem So it seems to me that tensor products do not always produce tensors? That a tensor product sometimes is and sometimes is not a map to the field? Which makes me wonder how we can consider the idea to be well-defined? I have to be told by some to think about it in terms of the universal property, i.e., it takes multi-linear maps to linear ones but that isn't as illuminating as some may think. How is one to think about this product and these objects? Thanks for your help!","['linear-algebra', 'soft-question', 'multilinear-algebra']"
