question_id,title,body,tags
3739291,Properties of the solutions of the ODE $y'' + p(x)y' + q(x)y = 0$,"Let $u(x)$ and $v(x)$ be solutions of $y'' + p(x)y' + q(x)y = 0$ , $p$ and $q$ continuous in $\mathbb{R}$ , such that $u(0) = 1$ , $u'(0) = 0$ , $v(0) = 0$ and $v'(0) = 1$ . Prove that, if $x_{1} < x_{2}$ are such that $u(x_1) = u(x_2) = 0$ and $u(x) \neq 0$ for all $x \in (x_1, x_2)$ , then there exists a point $c \in (x_1, x_2)$ such that $v(c) = 0$ . What's more, prove that such a point is unique. I don't really know how to start tackling this problem. I know that the Wronskian of $u$ and $v$ is greater than $0$ in the entire interval, and that $v(x_1) \neq 0$ and $v(x_2) \neq 0$ , but I couldn't go much farther than that... Does anyone have a tip to get me going in the right direction? Thanks in advance!","['wronskian', 'ordinary-differential-equations']"
3739319,$\ell_1$ is a schur space,"I want to prove that, in $l_1$ , if $x_n\to x$ weakly then $x_n\to x$ . i tried to use proprieties of $l_1$ . If $x_n\to x$ weakly, then for all $f\in {\ell^1}'$ , $f(x_n)\to f(x)$ . Considering $T\in {\ell^1}'$ : \begin{align}T&:\ell^1\to \mathbb{K} \\ x&\to T(x)=\sum_{n=1}^{\infty}x_n \end{align} , then if $x_n=\{\xi_{j}^{n}\}$ and $x={\xi_j}$ : Computing $|T(x_n)-T(x)|=|\sum_{j=1}^{\infty}\xi_j^n-\sum_{j=1}^{\infty}\xi_j|\geq |\|x_n\|_1-\|x\|_1|\to 0$ then $\|x_n\|_1\to \|x\|_1$ . For the other hand, trying \begin{align}G&:\ell^1\to \mathbb{K} \\ x&\to G(x)=x_n\end{align} , n fixed. I computed to $|G(x_n)-G(x)|$ to get some inequality to $\|x_n-x\|_1$ . Someone can help?","['measure-theory', 'functional-analysis', 'real-analysis']"
3739355,Likelihood ratio test question,"If $X_i$ , $i=1,\ldots,n$ , are observations from the normal distribution with known variance $\sigma_i^2$ , respectively, and $X_i$ 's are mutually independent, construct a test for testing that their means are all equal. My approach: $\lambda=\frac{L(\omega)}{L(\Omega)}$ where $\omega$ comes from the space where all means are equal and hence in likelihood means are replaced $\mu$ and $\sigma_i^2$ stay the same.
In, $L(\Omega)$ , all means are staying as they were as $\mu_i$ and variances $\sigma_i^2$ .
Do, we need to replace means and variances by their maximum likelihood somewhere.
I am confused about that.","['statistical-inference', 'statistics', 'normal-distribution', 'hypothesis-testing']"
3739365,Intuitive meaning of Diffeomorphism,"Let $U\subset\mathbb{R}^n$ , $V\subset\mathbb{R}^m$ and a bijection $f:U\to V$ is a diffeomorphism if $f$ and $f^{-1}$ are differentiable. I would like to know the intuitive meaning of two open sets being diffeomorphic. For example , if two spaces are homeomorphic , these spaces share the same topological properties. And we have a clear intuitive idea of two spaces being homeomorphs, like the classic relationship between a donut and a mug. Is there a similar intuitive idea for diffeomorphism? Edit: The proprieties that homeomorphism preserves is, for example, if one of them is compact, then the other is as well; if one of them is connected, then the other is as well; if one of them is Hausdorff, then the other is as well; their homotopy and homology groups will coincide. So, what are the properties preserved by diffeomorphism? I quoted homeomorphism, to indicate what I meant by an intuitive idea.","['multivariable-calculus', 'diffeomorphism', 'intuition', 'differential-geometry']"
3739394,Showing $−1 − r^2 \leq \cos^3\theta + r^2 \cos^5\theta \leq 1 + r^2$,"I was studying my textbook in advanced calculus when I encountered an inequality I can't seem to justify: Now $−1 \leq \cos\theta \leq 1$ , which implies that $$−1 − r^2 \leq \cos^3\theta + r^2 \cos^5\theta \leq 1 + r^2$$ I first cubed the inequality to get $$−1 \leq \cos^3\theta \leq 1 \tag{1}$$ Followed by adding $r^2 \cos^5 \theta$ : $$−1 + r^2 \cos^5\theta \leq \cos^3\theta + r^2 \cos^5\theta \leq 1 + r^2 \cos^5 \theta \tag{2}$$ This is where I am stuck.  I want to remove the $\cos^5\theta$ from either sides, as well as having the left hand side contain only negative terms. Or maybe I need to think of this inequality's justification differently? Thank you, trig never was my strong suit.","['trigonometry', 'inequality']"
3739448,"Describe the set $A = \{ 7a +3b: a,b \in \mathbb{Z}\}$","So in Hammack's ""Book of Proof"" there is the following example when he introduces the concept of set-builder notation in chapter 1.1. Describe the set $A = \{ 7a +3b: a,b \in \mathbb{Z}\}$ In which he then proceeds to state the following: If n is any integer, then $n = 7n +3(−2n)$ , so $n = 7a+3b$ where $a = n$ and $b = −2n$ . Therefore $n \in A$ . We’ve now shown that $A$ contains only integers, and also that every integer is an element of $A$ .
Consequently $A = \mathbb{Z}$ . My question is: are the values $a=n$ and $b=-2n$ arbitrary? If not, where did they come from?",['elementary-set-theory']
3739458,$p(x).y''+p'(x).y'+\frac{1}{p(x)}.y=0$,Is there a general solution I can give to the differential equation $\; p(x).y''+p'(x).y'+\frac{1}{p(x)}.y=0\;$ (the function $p(x)$ wasn't given) ?,['ordinary-differential-equations']
3739467,"In an isosceles triangle with base $AB$ and $\angle CAB=80^\circ$ taken $D$ on $CA$, $E$ on $CB$ such that ...","For the well-known problem In an isosceles triangle with base $AB$ and $\angle CAB=80^\circ$ taken $D$ on the segment $CA$ , $E$ on the segment $CB$ such that $\angle BAE=60^\circ$ , $\angle ABD=50^\circ$ , find $\angle EDB$ . The question is what is a canonical or otherwise simple without being too artificial way of solving it? Or what was the solution you heard/seen/found first? Btw, simple angle chasing does not help. The first way I can think of is considering difference of heights $DH_d$ and $EH_e$ of triangles $ABD$ and $ABE$ respectively along with $H_dH_e$ which together give the inclination angle of $DE$ relative to $AB$ and thus the desired angle. Needed for that lengths of $AD,\,BD,\,AE,\,BE$ can be expressed in terms of $AB$ and known angles by the sine rule. Almost like putting the thing into Cartesian coordinates. Another approach could be vectors, then taking $A$ or $B$ as the origin makes things more simple, than taking $CA,\,CB$ as basis vectors, IMHO. By ""too artificial"" I mean things like this: constructing a regular $18$ -gon with side $AB$ , proving lines $AE,\,BD,\,DE$ contain some diagonals and then finding the angle very easy by angle chasing. Update : The solutions are not as trivial as one would expect from the statement. It's called Langley's problem of adventitious angles first posed in The Mathematical Gazette in 1922. Check out An Intriguing Geometry Problem by Tom Rike . (from this answer ).","['euclidean-geometry', 'trigonometry', 'geometry']"
3739515,Is there a deeper reason for the classification of moduli in which a primitive root exists?,"The primitive root theorem classifies the set of moduli for which a primitive root exists as $$1,2,4,p^k,2p^k$$ where $p$ is an odd prime and $k$ is a positive integer. I have worked through a proof of this assertion which can be broken down as follows: It is clear that $1,2,4$ each have a primitive root. Higher powers of $2$ do not have a primitive root by induction. If the modulus has an odd prime factor and the modulus has a primitive root, then the modulus is either a power of that prime or twice a power of that prime. Every odd prime has a primitive root (using polynomials in modular arithmetic). Primitive roots modulo a prime can be ""lifted"" to moduli that are higher powers of the prime. Primitive roots in a modulus can be lifted to twice that modulus. This is all well and good, but this proof just works towards the expected result using standard elementary techniques without providing much insight. I was wondering: Is there a deep reason for why the classification of suitable moduli is so strange? It's a natural question to wonder when a reduced residue system has a multiplicative generator, yet the set we end up with carves out an unexpected subset of the positive integers. I don't entirely know what would qualify as a satisfactory answer, but some possibilities are: The set of integers $1,2,4,p^k,2p^k$ appears in other parts of mathematics. There is a more general theorem of which this is merely a shadow. There is a different proof that is less reminiscent of mechanical verification. EDIT: I came across a couple of quotes that sum up my feelings. What the standard proof is like, if I may exaggerate: Well, I have slightly mixed feelings about [the classification of finite simple groups]. First of all, it takes so many pages to prove; it seems to me the degree of understanding must be pretty limited if that is the only way it can be done. - Michael Atiyah, The Mathematical Intelligencer What I'm looking for: Not only is the above combinatorial proof much shorter than our previous proof, but it also makes the reason for the simple answer completely transparent. It is often the case, as occurred here, that the first proof to come to mind turns out to be laborious and inelegant, but that the final answer suggests a simpler combinatorial proof. - Richard Stanley, Enumerative Combinatorics I","['modular-arithmetic', 'number-theory', 'elementary-number-theory', 'primitive-roots', 'abstract-algebra']"
3739516,The condition and proof about the integral test for convergence,"The proof about the integral test: Suppose $f (x) $ is nonnegative monotone decreasing over $[1,\infty)$ , then the positive series $\sum_{n=1}^{\infty}f(n)$ is convergent if and only if $\lim_{A\rightarrow +\infty}f(x)dx$ exists. Proof:
Since $f(x)$ is monotone decreasing, we can get $f(n+1)<\int_{n}^{n+1}f(x)\Bbb{dx}< f(n)$ , sum them up and get $\sum_{k=1}^{n+1}f(x)-f(1)<\int_{1}^{n+1}f(x)\Bbb{dx}<\sum_{k=1}^{n}f(k)$ , when the series is convergent, the integral is bounded, since $f(x)$ is nonnegative, the integral is monotone increasing, the $\lim_{A\rightarrow +\infty}f(x)dx$ exists. When $\lim_{A\rightarrow +\infty}f(x)dx$ exists, the positive series is bounded, so it is convergent. When reading the integral test for positive series, I confused about the condition ""Monotone decreasing"": this condition is used to get $f(n+1)<\int_{n}^{n+1}f(x)\Bbb{dx}< f(n)$ and following that $\sum_{k=1}^{n+1}f(x)-f(1)<\int_{1}^{n+1}f(x)\Bbb{dx}<\sum_{k=1}^{n}f(k)$ , but I am confused because when the condition is monotone increasing we can just change the direction of the sign of the inequality like $f(n+1)>\int_{n}^{n+1}f(x)\Bbb{dx}> f(n)$ , so why the condition ""monotone decreasing"" is necessary? ""Continuous"": the condition says that $f (x) $ is continuous. But when proves it seems that the condition that be used is the integrable. Is the condition continuous not necessary? I think there is something wrong with my understanding. Could you find and point it? Thank you!","['integration', 'convergence-divergence', 'analysis']"
3739569,Drawing from a deck without replacement (Checking my answer),"From Carol Ash's The Probability Tutoring Book , Draw from a deck without replacement. Find the probability that a) the $10^{th}$ draw is a king and the $11^{th}$ draw is a non-king b) the first king occurs on the $10^{th}$ draw c) it takes $10$ draws to get $3$ kings My attempts: a) $$P(10^{th}\text{ is king and }11^{th}\text { is non king}) = P(1^{st}\text{ is king and }2^{nd}\text { is non king}) \\ = \frac{4}{52} \frac{48}{51}$$ b) To get the probability that the first king is on the $10^{th}$ we want $9$ non-kings first. Here is where my confusion begins. I first try a combinations approach: Of $48$ non-kings, pick 9 of them and then of $4$ kings pick $1$ of them. This results in: $$\frac{{48 \choose 9}{4 \choose 1}} {52 \choose 10}$$ Using a different approach: Draw 9 non-kings one at a time, and then draw a king $$\frac{(48)(47)(46)...(40)}{(52)(51)(51)...(44)} \frac{4}{43}$$ I feel as though these two should produce the same numerical answer, yet the first method produces an answer(0.424) that's a factor of 10 away from the latter method(.0424) c) $$P(10 \text{ draws to get } 3 \text{ Kings}) = P(10^{th} = \text{King}|2 \text{Kings before})P(2 \text{ Kings before}) = \frac{2}{43} \frac{{4 \choose 2}{48 \choose 7}}{52 \choose 10}$$","['discrete-mathematics', 'solution-verification', 'combinatorics', 'probability']"
3739570,Show that a sequence $a_n$ is a solution of the given recurrence relation,"Show that the sequence $a_n=3^{n+4}$ is a solution of the recurrence relation $a_n=4a_{n-1}-3a_{n-2}$ . I'm stuck on this question as I'm having trouble figuring it out when $a_n=3^{n+4}$ . After substituting $3^{n+3}$ for both n's in $4a_{n-1}$ and $3a_{n-2}$ , I have no idea where to go from there.","['recurrence-relations', 'discrete-mathematics']"
3739696,What is the most general context in which the limit laws hold?,"By limit laws I mean properties like $\lim (f+g) = \lim f + \lim g$ $\lim af = a \lim f$ $\lim fg = (\lim f) (\lim g)$ $\lim f/g = (\lim f)/(\lim g)$ if $\lim g \neq 0$ . What is most general setting for these to occur? For example, it seems true of $\mathbb{R}$ and $\mathbb{Q}$ , among others. Is it true in any metric space? Or other spaces? Also, what if we only require it true for sequences? Does that change anything? Or if we only require linearity (i.e. the first 2 properties) and not necessarily the product and quotient rules?","['limits', 'general-topology', 'functions', 'real-analysis']"
3739702,2 questions on Page 6 of Hoffman Kunze ( Linear Algebra),"While studying Linear Algebra from Hoffman Kunze I have following two questions : I.3. Matrices and Elementary Row Operations One cannot fail to notice that in forming linear combinations of linear equations there is no need to continue writing the ""unknowns' $x_{1}, \ldots, x_{n},$ since one actually computes only with the coefficients $A_{i j}$ and the scalars $y_{i} .$ We shall now abbreviate the system (1-1) by $$AX=Y$$ where $$A=\begin{bmatrix}A_{11}&\cdots&A_{1n}\\\vdots&&\vdots\\A_{m1}&\cdots&A_{mn}\end{bmatrix}\\X=\begin{bmatrix}x_1\\\vdots \\x_n\end{bmatrix}\text { and }Y=\begin{bmatrix}y_1\\\vdots\\y_m\end{bmatrix}$$ We call $A$ the matrix of coefficients of the system. Strictly speaking, the rectangular array displayed above is not a matrix, but is a representation of a matrix. An $m \times n$ matrix over the field $F$ is a function $A$ from the set of pairs of integers $(i, j), 1 \leq i \leq m, 1 \leq j \leq n,$ into the field $F$ . The entries of the matrix $A$ are the scalars $A(i, j)=A_{i j},$ and quite often it is most convenient to describe the matrix by displaying its entries in a rectangular array having $m$ rows and $n$ columns, as above. Thus $X$ (above) is, or defines, an $n \times 1$ matrix and $Y$ is an $m \times 1$ matrix. For the time being, $A X=Y$ is nothing more than a shorthand notation for our system of linear equations. Later, when we have defined a multiplication for matrices, it will mean that $Y$ is the product of $A$ and $X$ Questions-> (1) Why in 2nd paragraph author wrote that the rectangular array displayed above is not a matrix? (2) In 2nd line of 2nd paragraph author wrote the definition of matrix. How is a matrix a function from set of pair of integers into the field?
To me this definition given contradicts the definition given on Wikipedia and I can't understand it. Definition on Wikipedia: https://en.m.wikipedia.org/wiki/Matrix_(mathematics) Can kindly anyone explain why I am confused .","['matrices', 'linear-algebra']"
3739718,Positive integer $m≤n$ such that $m$ has the largest number of distinct prime factors among all positive integers $\le n$,"How do I interpret the following mathematically: Consider a positive integer $n$ such that $n=p_1^{\alpha_1}p_2^{\alpha_2}\cdots p_m^{\alpha_m}$ where $p_i$ are primes and $\alpha_i$ are positive integers. I want to consider the positive integer $m\le n$ such that $m$ has the largest number of distinct prime factors among all positive integers less than or equal to $n$ . I explain it with the following example: Consider $n=36$ . Here my $m$ will be $30$ since $30=2\times 3\times 5$ and it has the largest number of distinct prime factors among all positive integers which are less than or equal to $n=36$ . But I cant express my view mathematically.
How do I present my mathematical idea?
Can someone please help me to write the above fact in a more precise and concise manner which can be easily understood by mathematicians. Please help.","['elementary-number-theory', 'discrete-mathematics']"
3739763,How is this proposition false?,"I have a proposition: ((x v y) <=> (~x => ~y)) When I solve this, I end up getting True but the answer is False . Here's how I solved it: when we have a <=> b , we can write it as ~a.~b + a.b and a => b becomes ~a+b So the above equation becomes: => ~(x + y).~(~x => ~y) + (x + y).(~x => ~y) => ~(x+y).~(x+~y) + (x+y).(x+~y) Using De Morgan's law ( ~(a+b) = ~a.~b and ~(a.b) = ~a+~b ) => (~x.~y).(~x.y) + (x+y).(x+~y) => (~x.~x + ~x.y + ~y.~x + ~y.y) + (x.x + x.~y + y.x + y.~y) => (~x + ~x(y+~y) + 0) + (x + x(~y + y) + 0) => (~x + ~x) + (x + x) => ~x + x which is always True But, according to another solution, <=> is only True when both sides result in the same solution, So, if we go by this: => LHS = x+y and RHS is (x + ~y) , which can never be equal and hence, False . So what am I doing wrong? EDIT: PS: This is where I got the question from.",['discrete-mathematics']
3739772,Evaluating $2x^3-9x^2-10x+13$ for $x=3+\sqrt{5}$. Is there an efficient way to tell that this reduces to $1$?,"I was helping my sibling with a math problem from a past year paper for a competitive exam. It requires us to evaluate this cubic expression for a given value of $x$ which has an $a+b$ form where $b$ is a square root, as shown: I essentially plugged in $x=a+b$ in the expression and expanded each term and finally got the answer as $1$ . But this does not seem like the fastest way to do this, especially because there is only 1 minute given to solve each multiple choice question. Is there a better way to reduce the original expression that gives the answer as $1$ or suggests that the square root term is going to evaluate to $0$ ? Thanks!","['algebra-precalculus', 'radicals']"
3739776,Proving $\sum_{n=0}^\infty\frac{(-1)^n\Gamma(2n+a+1)}{\Gamma(2n+2)}=2^{-a/2}\Gamma(a)\sin(\frac{\pi}{4}a)$,"Mathematica gives $$\sum_{n=0}^\infty\frac{(-1)^n\Gamma(2n+a+1)}{\Gamma(2n+2)}=2^{-a/2}\Gamma(a)\sin(\frac{\pi}{4}a),\quad 0<a<1$$ All I did is reindexing then using the series property $\sum_{n=1}^\infty (-1)^n f(2n)=\Re \sum_{n=1}^\infty i^n f(n)$ ; $$\sum_{n=0}^\infty\frac{(-1)^n\Gamma(2n+a+1)}{\Gamma(2n+2)}=\sum_{n=1}^\infty\frac{(-1)^{n-1}\Gamma(2n+a-1)}{\Gamma(2n)}=-\Re\sum_{n=1}^\infty\frac{i^{n}\Gamma(n+a-1)}{\Gamma(n)}$$ and I dont know how to continue, any idea? Thanks","['gamma-function', 'closed-form', 'sequences-and-series']"
3739843,Does $\Phi_n(\alpha)=0$ in $\Bbb{F}_p$ for some $\alpha\in\mathbb{F}_p$ imply that $\mathrm{ord}_p(\alpha) = n$?,"Let $\Phi_n(x)$ denote the $n^\text{th}$ cyclotomic polynomial. Suppose it has a root $\alpha$ in the finite field $\Bbb{F}_p$ and $p \nmid n$ . Does it follow that $\mathrm{ord}_p(\alpha) = n$ ? In the case where we're working with $\Bbb{C}$ , then this is more or less a trivial result by definition of cyclotomic polynomials. However, it is no longer clear when working with finite fields. We clearly have $\mathrm{ord}_p(\alpha) \mid n$ , but must equality hold? Also, what if we generalise it to $\Bbb{F}_{p^n}$ ?","['number-theory', 'finite-fields', 'elementary-number-theory', 'cyclotomic-polynomials', 'prime-numbers']"
3739926,How to evaluate the Gauss sum using Mordell's Trick?,"I have been working on this problem: I have shown that the integral equals $G_n$ using the residue theorem. I have proved that the integral over the horizontal paths $B,D,F,H$ vanish. I have found the functional equation $f(z+n) - f(z) = g(z) := \exp(2 \pi i z^2 / n)(\exp(2 \pi i z) + 1)$ . This allows me to merge the integrals over $A$ and $C$ into one. And I can merge $E$ and $G$ into one. Let $P^-$ denote the path $P$ reversed. $$\begin{align}
& \int_A f(z) dz + \int_C f(z) dz\\
=& \int_{C^{-}} f(z+n) dz - \int_C^- f(z) dz\\
=& \int_{C^{-}} g(z) dz\\
=& \int_{-R}^{R} a g(a z) dz\\
=& \int_{-R}^{R} a \exp(-z^2)(\exp(2 \pi i a z) + 1) dz\\
=& \int_{-R}^{R} a \exp(-z^2)(\exp(- \sqrt{\pi} \sqrt{n} (1 - i) z) + 1) dz
\end{align}$$ and $$\begin{align}
& \int_E f(z) dz + \int_G f(z) dz\\
=& \int_{G^{-}} g(z) dz\\
=& \int_{-R}^{R} i g(i z) dz\\
=& \int_{-R}^{R} i \exp(- 2 \pi i z^2 / n)(\exp(- 2 \pi z) + 1) dz\\
\end{align}$$ Now I do not know what to do with these two resulting integrals, I think I should equate them and their values equal $G_n$ and I somehow want to form the boxed expression from them but I am very lost with this. I have evaluated the Gaussian integral as $\sqrt{\pi}$ but I don't know how to apply this here. Any advice would be appreciated!",['complex-analysis']
3739978,Determining the closed form of $\sum\limits_{r = 2}^n \binom{n}{r} \binom{r}{2}$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Here is a sum in combinatorics, $\sum\limits_{r = 2}^n \binom{n}{r} \binom{r}{2}$ where $n>2$ , does this have a closed form?","['summation', 'binomial-coefficients', 'combinatorics']"
3739980,When does the Picard group embeds inside the divisor class group?,"Let $(X, \mathcal O_X)$ be a Noetherian, separated, integral scheme that is locally regular in codimension $1$ (i.e. if $\dim \mathcal O_{X,x}=1$ then $\mathcal O_{X,x}$ is regular). Then, is it true that $Pic(X)$ embeds inside $Cl(X)$ (the Weil divisor class group) ? Is it at least true if we also assume $X$ is normal ? I know that if I assumed $X$ is locally factorial, then $Pic(X)\cong Cl(X)$ . But otherwise, I'm not sure.","['divisors-algebraic-geometry', 'algebraic-geometry', 'schemes', 'line-bundles']"
3739992,How do I integrate the Boltzmann equation for neutrinos?,"In Sterile Neutrinos as Dark Matter we are given the Boltzmann equation for neutrinos $$\left( \frac{\partial}{\partial t} - HE \frac{\partial}{\partial E}\right) f_s (E,t) = \left[ \frac{1}{2} \sin ^2 2\theta (E,t)  \Gamma (E,t) \right] f_a (E,t) \tag{2}$$ $f_s$ and $f_a$ are the distribution functions of sterile and active neutrinos. $f_a = \left( e^{E/T}+ 1\right)^{-1} \approx \left( e^{p/T}+1\right)^{-1}$ $\Gamma (E,t)$ is the rate of scattering production of $\nu_s$ through a particular channel and it's stated that, by changing the time variable from $t$ to $a$ ( the Robertson-Walker scale factor) and integrating $(2)$ over momenta we find that: $$\frac{dr}{d \ln(a)}= \frac{\gamma}{H}+ r \frac{d \ln(g*)}{d \ln(a)} \tag{4}$$ $\gamma = \displaystyle \frac{1}{n_a} \int \frac{d^3 p}{(2\pi)^3} \sin^2 2\theta (p,T) \Gamma (p,T) \frac{1}{e^{p/T}+1}$ $ \displaystyle n_i ≡ 2 \int \frac{d ^3p}{(2π) ^3}f_i$ is the number density of sterile (active) neutrinos with $i = s,a  $ $g^∗a^3T^3= constant$ $H = \displaystyle \frac{\dot{a}}{a}$ and $r= \displaystyle\frac{n_s}{n_a}$ How do I integrate $(2)$ to get $(4)$ ? I know that $g^*$ comes from the entropy conservation law but I don't understand why it is brought up in the article or how it helps with this integration and this isn't explained in the article. I think that in this case, I can consider $E\approx p$ as the mass is negligible (as done in the distribution function for the active neutrinos, above) and so I think I can rewrite $(2)$ as $$\left( \frac{\partial}{\partial t} - Hp \frac{\partial}{\partial p}\right) f_s (E,t) = \left[ \frac{1}{2} \sin ^2 2\theta (p,t)  \Gamma (p,t) \right] f_a (p,t) \tag{2}$$ Dodelson-Widrow production of sterile neutrino Dark Matter with non-trivial initial abundance does something similar, but with the equation written slightly differently. But I still do not understand how the integration is done.","['integration', 'physics', 'calculus']"
3740053,Showing triangulation of equilateral triangle is non-regular,"I am trying to show that this triangulation is non-regular (sometimes called non-convex I think). By regular I mean there exists a convex function from the triangulation to $\mathbb{R}$ such that the faces of the lower convex hull of the lifted points correspond to the triangles of the triangulation. Another definition I have seen is that the domains of linearity of the function coincide with the faces of the triangulation. I know that the way to do this would be to attempt to construct such a function and probably find inequalities going around the triangle, thus reaching a contradiction. However, I can't seem to figure out the way to do this. To start, I think it is possible to assume that the three inner vertices lie below the three outer vertices but I am not sure why. If this is the case then I can picture in my head how lifting up the outer vertices would cause one of the faces to not be linear but I'm struggling to see how to make this mathematical. Any help would be appreciated.","['convex-hulls', 'convex-geometry', 'triangulation', 'geometry', 'triangles']"
3740069,I don't understand this derivation,"I try to unterstand a derivation and need help. There are given two functions $$
s=-cos(j\pi/n),s\in[-1,1]
$$ and the nonlinear transformation $$
y(s)=C\tan[\frac{\pi(s+1)}{4}+\frac{s-1}{2}\arctan\frac{y^*}{C}]+y^*,y\in[0,\infty)
$$ $y*$ and $C$ are constant parameters. The derivation and its solution is $$
\frac{ds}{dy(s)}=4C/[\pi+2\arctan(y^*/C)]/[C^2+(y(s)-y^*)^2]
$$ but i don't understand how to reach this solution.",['derivatives']
3740087,Is this quotient always a solid torus?,"Consider the subgroup $G$ of the unit circle $\mathbb S^1 \subset \mathbb C$ generated by $\xi = \exp(2\pi/n)$ , where $n\geq 2$ . Also, consider the closed unit disc $\overline{\mathbb D^2}\subset \mathbb C$ centered at $0$ and the solid torus $\mathbb T := \overline{\mathbb D^2} \times \mathbb S^1$ . If we take the action $A:G \times \mathbb T \to \mathbb T$ by the formula $$
A(\xi,(z,\gamma)) := (\xi z, \xi^k\gamma),
$$ where $k$ is an integer and $0\leq k \leq n-1$ , then we have the quotient $\mathbb T/G$ . Is the quotient $\mathbb T/G$ homeomorphic to $\mathbb T$ ? I know the answer is affirmative in two cases: if $k=0$ , then the quotient is $\overline{\mathbb D^2}/G \times \mathbb S^1$ and $\overline{\mathbb D^2}/G$ is a cone, which is homeomorphic to a disc. if $k$ and $n$ are coprimes, then the action is free and the quotient is a manifold. Let $l$ be an integer such that $lk = 1 \mod n$ and $0\leq l\leq n-1$ . The map $f:\mathbb T/G \to \mathbb T$ given by $f([z,\gamma]) = (\gamma^{-l}z,\gamma^n)$ is a diffeomorphism. So we can restrict ourselves to the case when $k$ and $n$ are not coprime. The motivation for this question is that this problem appeared naturally while I was investigating some properties of Seifert manifolds.","['general-topology', 'fiber-bundles']"
3740118,Is there any easy way to calculate the value of this determinant?,"\begin{vmatrix}
0 & 3 & 1 & 2 & 10! & e^{-7}\\ 
1 & 2 & -1 & 2 & \sqrt{2} & 2 \\ 
-1 & -2 & 3 & -3 & 1 & -\frac{1}{5} \\ 
-2 & -1 & 3 & 2 & -2 & -9 \\
0 & 0 & 0 & 0 & 4 & 2 \\
0 & 0 & 0 & 0 & 1 & 1 \\
\end{vmatrix} I still can't see any easy way to compute the determinant above I would appreciate any kind of help. Thanks.","['matrices', 'determinant', 'linear-algebra']"
3740132,"Construct a triangle, given the altitude, median, and angle bisector for a vertex.","We are given that in a triangle, say $\triangle ABC$ , the altitude is dropped from A to the opposite side of the triangle. Also given is the median from A and it's the angle bisector . With help of the above conditions, construct $\triangle ABC$ . I tried solving this problem. I know that if it is an equilateral or isosceles triangle the question can be easily done. But there should definitely be a general proof for any triangle.","['triangles', 'geometry']"
3740138,Factoring $ab^3 - a^3 b + bc^3 - b^3 c + ca^3 - c^3 a$,"Factor $$ab^3 - a^3 b + bc^3 - b^3 c + ca^3 - c^3 a$$ I used the factor theorem to get factors $$f(a, b, c)=(a-b)(b-c)(a-c)\;g (a, b, c)$$ for some polynomial $g (a, b, c)$ . How can I continue using this method? (sorry for the previously messed up question I'm new to this website and didn't fully understand the guidelines).","['algebra-precalculus', 'polynomials']"
3740170,"Find the curvature of of the function at the point $(1,0,1)$","Find the curvature of the curve defined by: $$C:=\begin{cases} 
     \left(x+y\right)^{2}-z=yz \\
      \left(x-z\right)^{2}=y+z-1\\
   \end{cases}$$ At the point $(1,0,1)$ . All of the curves for which I found  them their curvature at the given point were some vector-valued functions,but this one is different and I don't know how to find the curvature.","['curves', 'curvature', 'differential-geometry']"
3740222,Suppose every element of $\mathcal F$ is a subset of every element of $\mathcal G$. Prove that $\bigcup \mathcal F\subseteq \bigcap\mathcal G$.,"Not a duplicate of Prove that if F and G are nonempty families of sets, then $\bigcup \mathcal F \subseteq \bigcap \mathcal G$ Validity of this proof: Prove that $\cup \mathcal{F} \subseteq \cap \mathcal{G}$ Proof that $\bigcup\mathscr F\subseteq\bigcap\mathscr G$, when every element of $\mathscr F$ a subset is of every element of $\mathscr G$ This is exercise $3.3.17$ from the book How to Prove it by Velleman $($$2^{nd}$ edition $)$ : Suppose $\mathcal F$ and $\mathcal G$ are nonempty families of sets, and every element of $\mathcal F$ is a subset of every element of $\mathcal G$ . Prove that $\bigcup \mathcal F\subseteq \bigcap\mathcal G$ . Here is my proof: Suppose $x$ is an arbitrary element of $\bigcup\mathcal F$ . This means that we can choose some $A_0$ such that $A_0\in \mathcal F$ and $x\in A_0$ . Let $B$ be an arbitrary element of $\mathcal G$ . Since $\forall A\in\mathcal F\forall B\in\mathcal G(A\subseteq B)$ , $A_0\subseteq B$ . From $A_0\subseteq B$ and $x\in A_0$ , $x\in B$ . Thus if $B\in \mathcal G$ then $x\in B$ . Since $B$ was arbitrary, $\forall B\Bigr(B\in\mathcal G\rightarrow x\in B\Bigr)$ and so $x\in\bigcap \mathcal G$ . Therefore if $x\in \bigcup\mathcal F$ then $x\in\bigcap\mathcal G$ . Since $x$ was arbitrary, $\forall x\Bigr(x\in \bigcup\mathcal F\rightarrow x\in\bigcap\mathcal G\Bigr)$ and so $\bigcup\mathcal F\subseteq\bigcap\mathcal G$ . $Q.E.D.$ Is my proof valid $?$ Thanks for your attention.","['elementary-set-theory', 'proof-writing', 'solution-verification']"
3740226,Maximize $\boxed{\mathbf{x}+\mathbf{y}}$ subject to the condition that $2 x^{2}+3 y^{2} \leq 1$,"Maximize $\mathbf{x}+\mathbf{y}$ subject to the condition that $2 x^{2}+3 y^{2} \leq 1$ My approach $\frac{x^{2}}{1 / 2}+\frac{y^{2}}{1 / 3} \leq 1$ Let $z=x+y$ $\mathrm{Now}, 4 \mathrm{x}+6 \mathrm{y} \frac{d y}{d x}=0 \Rightarrow \frac{d y}{d x}=-\frac{2 x}{3 y}$ $2 x^{2}+3 y^{2}=1$ What to do next? Any suggestion or Hint would be greatly appreciated!","['multivariable-calculus', 'calculus', 'solution-verification', 'optimization']"
3740237,Showing a system of equations has no integer solutions,"I am having trouble finding an elegant way of showing this system of equations has no integer solutions: $$32c+11d=9a+10b$$ $$2c+d=a$$ $$ad-bc=1$$ So far I've narrowed it down to showing $221c^2+100$ cannot be a perfect square, but I'm hoping there's a way that's less computational!","['systems-of-equations', 'modular-arithmetic', 'number-theory', 'diophantine-equations', 'quadratic-forms']"
3740263,How to find the laplace transform of the function $f(t)= \sqrt{t}\sin(t) $,I would like to ask on how to find the laplace transform of the function $f(t)=\sqrt{t}\sin(t)$ when i seached on wolframmath it seems that the answer used a gamma function and has a sine of arctan of something. I would like to know the steps in finding the laplace transform of this function. Thank you so much.,"['inverse-laplace', 'laplace-transform', 'ordinary-differential-equations']"
3740347,Integrating $\ln(x)\times\ln(1-x)$,Is there a way I can derive the value of the integral $ \int_0^1 \ln(x)\ln(1-x)dx$ using the fact that $\displaystyle\sum_{i=1}^\infty \frac{1}{n^2} = \frac{\pi^2}{6}$ ? (the actual value of the integral is $2-\frac{\pi^2}{6}$) Thanks in advance,"['integration', 'logarithms']"
3740357,Multiplying out a quadratic equation of differential factors acting on a function,"I am having trouble understanding a multiplying out of a quadratic equation with differential factors: from the following video : $$
(D + A(x))(D + B(x))y(x) = 0\\
(D^2 + AD + AB + B^{'} + BD)y = 0 \\ 
$$ What I don't get is his remark on the last multiplication two terms. It looks like he is using the multiplication rule for differentiation, but in the end, the multiplied out parenthesis is again acting on y, so for me it looks like a double use. I see that $B^{'} = DB$ but I still do not get why two terms are produced?",['ordinary-differential-equations']
3740379,Bound for $\sum_{k=0}^{n}(-1)^k{3n\choose k}{n\choose k}$.,"In the book Complex analysis by Bak J. & Newman J. , chapter 11, talks about Sums Involving Binomial coefficients and find a bound $\frac{16}{9}\sqrt{3}$ for $|(z-1)^2(z+1)|$ in the ""Example 3"" on the unit circle, my way was using lagrange multipliers in this form: We want find $\max{|(z-1)^2(z+1)|}$ ahnd have that $|z-1|^2+|z+1|^2=4$ . Let be $a=|z-1|$ and $b=|z+1|$ and then the exercise is: ""Maximize $f(a,b)=a^2b$ subject to $a^2+b^2=4$ "" then $\nabla f=\lambda\nabla g$ so $\begin{cases}2ab=\lambda(2a)\\a^2=\lambda(2b)\end{cases}$ , i.e., $ab=\lambda a$ if $a(b-\lambda)=0$ therefore i) $a=0$ or $b=\lambda$ , $b^2=4$ then $b=2$ then $|z+1|=2$ or $|z-1|=0$ then $z=1$ and $a^2b=0$ . ii) $b=\lambda$ , $a^2=2b^2$ then $4=a^2+b^2=3b^2$ then $b^2=4/3$ then $b=\frac{2\sqrt{3}}{3}$ then $a^2=\frac{8}{3}$ then $a=\frac{2\sqrt{2}}{\sqrt{3}}$ So $a^2b=\frac{8}{3}\frac{2\sqrt{3}}{3}=\frac{16}{9}\sqrt{3}$ . After i want to use this idea for exercise 17.b with $\sum_{k=0}^{n}(-1)^k{3n\choose k}{n\choose k}$ but, i don´t see what should be $a$ and $b$ . Edit: this exercise says that $|\sum_{k=0}^{n}(-1)^k{3n\choose k}{n\choose k}|\leq4^n$ .","['complex-analysis', 'optimization', 'summation', 'binomial-coefficients']"
3740391,Can we have a converse Skolem paradox?,"My information about models is not that great, so the question here is elementary in that field. Can we have a model of ZF or ZF-regularity, in which there are two sets $x,y$ and such that no bijection exists between them, i.e. externally speaking, but at the same time we have the statement of existence of a bijection between them is satisfied in it? I'm asking that because what is seen from outside of a model can conflict with what's satisfied in it! So for example a countable model of ZF does have a bijection between every set in it and the set $\omega$ of all finite von Neumann ordinals, and $\omega$ is a set in it also, but still the model does fulfill Cantor's theorem, and so it satisfy the statement that MOST sets are uncountable! While in fact (externally speaking) All of them are countable! This is the Skolem paradox. The explanation given is that the bijection is seen externally and it exists, but it is not in the model, i.e. its a subset of the model but not an element of the model. I'm asking if the converse can also happen? That's why I call it converse Skolem paradox. My own personal guess is that NO such a paradox can exist. But I'm not sure of the satisfaction conditions in Models, and my knowledge about those is indeed trivial. That's why I asked this rather trivial question.","['elementary-set-theory', 'model-theory', 'first-order-logic']"
3740394,A limits with substitution,"Evaluate $$\lim_{n\rightarrow \infty}\frac{\sqrt{1-x_0^2}}{x_1x_2...x_n}$$ where $x_{r+1}=\sqrt{\frac{1+x_r}{2}}; 0\leq r<n;\space r,n\in \mathbb{Z}$ My teacher says to substitute $x_0=\cos(\theta)$ but I don't understand why that is the case. Is the $\cos(\theta)$ substitution arbitrary or is there any underlying logic to it?",['limits']
3740395,Solution to Lagrange's Four Square Theorem with Fewest Terms,"Lagrange's four square theorem states that any natural number $n$ can be written as the sum of the square of 4 other integers. For most values of $n$ , there are multiple square combinations that work. For example, $16=4^2$ and also $16=2^2 + 2^2 + 2^2 + 2^2$ . Is there a name for the solution where first term is as large as possible, the second term is as large as possible (given the value of the first term), and so on? For 16, this would be the $4^2$ solution. I'd still want no more than 4 nonzero terms. Has this solution been discussed anywhere? I like this solution because it's unique. Also, would that solution be equivalent to the solution with the fewest nonzero terms? If no name for this solution exists, what name would you suggest? Names that occur to me are the minimum entropy solution, or the maximum bias solution.","['number-theory', 'sums-of-squares', 'terminology']"
3740435,Isomorphic elliptic curves have the same j-invariant,"Let $K$ be an algebraically closed field of characteristic different from $2$ or $3$ , and
let $E: y^2 = x^3 +Ax+B$ and $E′: y^2 = x^3 +A′x+B′$ be elliptic curves over $K$ . Assume that $E$ and $E′$ are isomorphic via an invertible linear map $M : \mathbb{P}^2 \rightarrow \mathbb{P}^2$ that maps the infinite point $\mathcal O$ of $E$ to the infinite point $\mathcal O$ of $E'$ . I want to show that that $j(E) = j(E′)$ . So what I have tho show is that $j(E) = 1728\cdot\frac{4A^3}{4A^3+27B^2} = 1728\cdot\frac{4A'^3}{4A'^3+27B'^2} = J(E')$ . My idea was to represent the linear map $M$ as follows: $M =\begin{bmatrix}a & b & c\\d&e&f\\ g&h&i\end{bmatrix}$ Since $M * \mathcal O = M[0:1:0] = [b:e:h] = [0:1:0] = \mathcal O$ it should follow than $ b = 0, e = 1$ and $h = 0$ . However, this doesn't seem to lead anywhere, since I don't learn anything useful about the coefficients $A'$ & $B'$ which are used to calculate $j(E')$ . Am I somewhat on the right track, or is this done completely different?","['matrices', 'algebraic-geometry', 'elliptic-curves']"
3740452,Proof of Stokes' theorem for differentiable manifolds,"In Evan's well-known PDE book, he states the following in an appendix, without proof: Let $U\subset\mathbb{R}^n$ be an open, bounded set with $\partial U$ being $C^1$ . Suppose $u\in C^1(\bar{U})$ , then $$\int_U \frac{\partial u}{\partial x_i} \, dx=\int_{\partial U} u\nu^i \, dS\;\;\;\;(i=1,\ldots,n),$$ where $\nu=(\nu^1,\ldots\nu^n)$ denotes the outward-pointing unit normal vector field to the region $U$ . This is the Green–Gauss Theorem, and it can be derived from the divergence theorem, which in turn is a special case of Stokes' theorem. I cannot find a reference which gives a (complete, rigorous) proof of Stokes' theorem in this generality (i.e. not requiring $C^\infty$ ). Where can I find such a proof? Note: a very similar question is asked here , but careful inspection show that the supposed answers do not actually resolve the problem. A proof is given for $n=3$ , $U$ convex, but there is some handwaviness in generalizing to the nonconvex case. All references given point to special cases of the theorem (e.g. Rudin) or to $C^\infty$ presentations. Note 2: If possible, I would prefer an analytic proof as I am not so familiar with differential forms. But any complete reference would be appreciated.","['integration', 'stokes-theorem', 'differential-geometry']"
3740479,Is $S_R$ finitely generated?,"Suppose $S_R$ -  is the set of all total recursive bijections on $\mathbb{N}$ . It is not hard to see that this set forms a group with respect to composition, and that $|S_R| = \aleph_0$ . Is $S_R$ finitely generated? The group $S_R$ contains the group $S_\infty$ (the group of finitely based bijections) as its subgroup, which is infinitely generated. However, there exists $S_\infty < H \leq S_R$ , such that $H$ is finitely generated. The $H$ can be described as $\langle (01), f \rangle$ , where $f$ is defined by formula: $$f(x) = \begin{cases} 0 & \quad x = 0 \\ 2 & \quad x = 1 \\ x + 2 & \quad x \geq 2 \text{ and is even} \\ x - 2 & \quad x \geq 2 \text{ and is odd} \end{cases}$$ Indeed, $\forall x = 2n+1$ $(0x)=(01)f^{n}$ and $\forall x = 2n$ $(0x)=(01)f^{-n}$ . Hovever, this does not give us the answer to the question as $H$ is most likely a proper subgroup of $S_R$ (though, i do not know for sure).","['finitely-generated', 'abstract-algebra', 'symmetric-groups', 'group-theory', 'computability']"
3740524,Galerkin method for nonlinear ode,"I'm trying to solve the following differential equation: $$\frac{d^2u}{dx^2}=\frac{du}{dx}u+u^2+x$$ $$x \in \Omega=[0,1]$$ $$BCS:u|_{x=0}=1;\frac{du}{dx}|_{x=1}=1$$ You can see that the right side contains $u^2$ . So when I paste it in the weighted residual form, I get nonlinear term.
For example, if I have approximation: $$ u=1+\sum_{i=1}^n\alpha_i x^i$$ There will be nonlinear integral in weighted residuals $$\int (1+\sum_{i=1}^n\alpha_i x^i)^2dx$$ That's why the system will be nonlinear. What am I missing? I tried to switch from $u$ to $u^2$ in equation because $u\frac{du}{dx}=\frac{1}{2}\frac{du^2}{dx}$ , but can't make it for $\frac{d^2u}{dx^2}$ Edit, according to the answer: I won't write BCS integrals, because they don't make real sense in the question. I'll write only the integral in the main domain. So I have $$\int_0^1w(\frac{d^2u}{dx^2}-\frac{du}{dx}u-u^2-x)dx=0$$ $w-$ weight function. Paste approximation of $u$ . Let's take $n = 2$ $$\int_0^1w(2\alpha_2-(\alpha_1 + 2\alpha_2 x)(1+\alpha_1 x +\alpha_2 x^2)-(1+\alpha_1 x +\alpha_2 x^2)^2-x)dx=0$$ Take in account Bubnov-Galerkin approximation of weight function: $$ w=\beta_1x+\beta_2x^2$$ $$\int_0^1\beta_1x(2\alpha_2-(\alpha_1 + 2\alpha_2 x)(1+\alpha_1 x +\alpha_2 x^2)-(1+\alpha_1 x +\alpha_2 x^2)^2-x)dx +\int_0^1\beta_2x^2(2\alpha_2-(\alpha_1 + 2\alpha_2 x)(1+\alpha_1 x +\alpha_2 x^2)-(1+\alpha_1 x +\alpha_2 x^2)^2-x)dx=0$$ From here since $\beta_i $ arbitrary we have system $$\begin{cases}
 \int_0^1x(2\alpha_2-(\alpha_1 + 2\alpha_2 x)(1+\alpha_1 x +\alpha_2 x^2)-(1+\alpha_1 x +\alpha_2 x^2)^2-x)dx =0\\
\int_0^1x^2(2\alpha_2-(\alpha_1 + 2\alpha_2 x)(1+\alpha_1 x +\alpha_2 x^2)-(1+\alpha_1 x +\alpha_2 x^2)^2-x)dx=0
\end{cases}
$$ Here we exactly have unknowns only $\alpha_i;i=1,2$ .But if we extend polynomial to $2n=4$ we will have new $\alpha_i;i=1..4$ with 2 equations only Edit 2: Actually I need two terms approximation, so I don't think that switching to 2n terms and then solving 2n equations is the key point. I suppose we should simplify ode, or choose another interpolation functions rather then $x^i$","['numerical-methods', 'finite-element-method', 'galerkin-methods', 'ordinary-differential-equations']"
3740539,"If $A^3 = I_n$, then $\operatorname{tr}(A)\in\Bbb Z$","Let $A\in M_{n\times n}(\Bbb R)$ s.t. $A^3 = I_n$ . Show that $\operatorname{tr}(A) \in \Bbb Z$ . I know that $P(A) = 0$ , where $ P(x) = x^3 - 1 = (x-1)(x^2+x+1)$ , that is, $1$ is an eigenvalue of $A$ . Also, trace is the sums of the eigevalues and in $\Bbb C$ have $1, \omega, \omega^2$ are the eigenvalues of $A$ . However I'm stuck in $\Bbb R$ . I guess, it's not true that the trace in $\Bbb R$ is equal to the trace in $\Bbb C$ . Can you help me?","['matrices', 'trace', 'linear-algebra']"
3740561,Good revision notes for complex variable and linear algebra,"Are there any short notes on complex analysis and linear algebra (around 100 pages) with some exercises so I can refresh my mind on these two subjects? Initially, I had my study notes but I lost it due to a flood. Now I am going to graduate school and I wish to do some revision before I go. I don't mind if the content is dense since I learnt them before.","['book-recommendation', 'complex-analysis', 'linear-algebra', 'linear-transformations', 'complex-integration']"
3740620,How to uniformly sample multiple numbers whose product is within some bound,"Suppose I have 3 positive integers: $n_1$ , $n_2$ , and $n_3$ . How do I uniformly sample $(n_1, n_2, n_3)$ so that $50 < n_1 n_2 n_3 < 100$ . I could sample each number independently with bounds between 1 and 100, then keep re-sampling if their product is out of bound. I need to do this with a computer program with more numbers and larger bounds, so I prefer a way that's efficient both in space and time. Are there other ways to sample than what I described above? EDIT (regarding the accepted answer): At the time of this edit, there were 3 approaches answered so far: complete enumeration (addresses the example in the question, simple, but space and time bound for very large problems) rejection sampling (simple, but time bound for very large problems) weighted draw (""efficient"" in space and time compared to other approaches, but complex) All answers work best in different situations. I accepted weighted drawing since it seemed to be most complete in a sense that it addressed the ""efficient both in space and time"" part for larger problems the best.","['statistics', 'probability', 'sampling']"
3740622,Proof of identity relating Prime-counting function and Stirling numbers of the second kind,"In his famous 1973 paper Gallagher showed that the distribution of prime numbers in short intervals tends to a Poisson distribution. To do it he uses in one step: $$\sum_{n \leq N}(\pi (n+h)-\pi(n))^{k}=\sum_{r=1}^{k} \sigma (k,r) \underset{distinct}{\sum_{1 \leq d_{1}< \dots <d_{r} \leq h}}  \pi(N; \left  \{ d_{1},d_{2},\dots,d_{r} \right \})$$ Where $\sigma (k,r)$ are the Stirling numbers of the second kind and $\pi(N; \left  \{ d_{1},d_{2},\dots,d_{r} \right \}$ counts the different integers $x\leq N$ such that $\{x,x+d_{1},\dots,x+d_{r}\}$ are simultaneously primes. I understand that he has used $\sum_{k=0}^n \sigma (n,k)(x)_{k}=x^{n}$ . Where $(x)_{k}$ is the falling factorial. Nevertheless,
I do not understand why the identity is true. Any advice?","['combinatorics', 'stirling-numbers', 'prime-numbers']"
3740669,Complex Analysis Prelim Question,"This is a complex analysis qualifying examination question. I'm an incoming grad student and we get the opportunity to have a freebie attempt on one qualifying exam. I have $\textit{some}$ experience in complex analysis from undergrad, and some of the advanced topics that were not covered have been tricky to learn on my own. So here goes. Let $\mathcal{F}$ be a family of analytic functions on $\mathbb{D}$ (the unit disk).  Suppose that for all $0<r<1$ , \begin{equation}M_r:=\sup_{f\in \mathcal{F}}\int_{\lvert z\rvert=r}\lvert f(z)\rvert \lvert dz\rvert<\infty.\end{equation} Prove that $\mathcal{F}$ is a normal family. From my understanding, this means that I must show that for any sequence $f_n$ in $\mathcal{F}$ , there exists an analytic function $f:\mathbb{D}\rightarrow \mathbb{C}$ and a subsequence $(n_k)$ such that $f_{n_k}\to f$ uniformly on any compact $K\subset \mathbb{D}$ . Here is my proof attempt. Let $f_n$ be a given sequence in $\mathcal{F}$ and $K$ be a compact subset of $\mathbb{D}$ . My goal is to use the Arzela-Ascoli Theorem on $\mathcal{F}$ to prove the existence of the required subsequence and limit function $f$ . We must show that $\mathcal{F}$ is uniformly bounded and equicontinuous. I will only show equicontinuity since uniform boundedness is the same technique. Let $f\in \mathcal{F}$ and $z_1,z_2\in K$ be given. Let also $\varepsilon>0$ be given. Since $K$ is compact, there exists an $r<1$ such that $K\subset \{\lvert z\rvert <r\}$ . Since both $K$ and $\{\lvert z\rvert =r\}$ are compact and disjoint, $d:=\text{dist}(K,\{\lvert z\rvert =r\})>0$ . Pick $\delta=\varepsilon\frac{2\pi d^2}{M_r}$ and suppose $\lvert z_1-z_2\rvert <\delta$ . Then, by Cauchy's Integral Formula, we have \begin{equation}
\begin{split}
\lvert f(z_1)-f(z_2)\rvert =& \frac{1}{2\pi}\lvert \int_{\lvert z\rvert =r} f(z)\left(\frac{1}{z-z_1}-\frac{1}{z-z_2}\right)dz\rvert\\
\leq & \frac{1}{2\pi}\int_{\lvert z\rvert =r}\lvert f(z)\frac{z_1-z_2}{(z-z_1)(z-z_2)}\rvert \lvert dz\rvert\\
\leq &\frac{\lvert z_1-z_2\rvert}{2\pi d^2}\int_{\lvert z\rvert =r}\lvert f(z)\rvert \lvert dz\rvert \\
\leq &\frac{M_r}{2\pi d^2}\lvert z_1-z_2\rvert \\
<& \varepsilon.
\end{split}
\end{equation} Then, since $\mathcal{F}$ is equicontinuous and uniformly bounded, by Arzela-Ascoli's theorem, we should be done. However, it only tells me that there is a continuous limit function $f:K\rightarrow \mathbb{C}$ and a subsequence $f_{n_k}\rightarrow f$ uniformly on $K$ . How can I show that this limit function can be extended to all of $\mathbb{D}$ , that it is independent of $K$ and that it is also analytic? I think I'm not seeing whats going on with this whole normal family buisness. Any help is appreciated.",['complex-analysis']
3740703,Showing $\lim_{n\to\infty}\int_{\mathbb{R}} f(x)f(x+n) dx=0$,"Problem Let $f(x)\in L^2(-\infty,\infty)$ . Prove that $$
\lim_{n\to\infty}\int_{-\infty}^\infty f(x)f(x+n) dx=0.
$$ My attempt Let $N\in\mathbb{N}$ and $f_N(x):=f(x)\chi_{[-N,N]}(x)$ . For any $n\in\mathbb{N}$ , consider $$
\begin{split}
\int_{-\infty}^\infty f(x)f_N(x+n)dx&=\int_{-\infty}^\infty f(x)f(x+n)\chi_{[-N,N]}(x+n)dx\\
&=\int_{-\infty}^\infty f(x)f(x+n)\chi_{[-N-n,N-n]}(x)dx\\
&=\int_{-N-n}^{N-n}f(x)f(x+n)dx
\end{split}
$$ This is where I get stuck. We know for a.e. $x\in\mathbb{R}$ that $\lim_{n\to\infty} f(x+n)=0$ . Thus, if I were allowed to interchange limit and integral, I would get the desired conclusion. I tried Dominated Convergence Theorem, but could not find a way to dominate the integrand by an integrable function not depending on $n$ . Maybe there is a different approach. Any hints? I'd like to be able to say the absolute value of the above integral is less than any $\varepsilon>0$ for $n$ large enough, and then since $N$ is arbitrary, the conclusion follows.","['lebesgue-integral', 'real-analysis']"
3740778,"Given cups that are $\frac12$, $\frac13$, $\frac14$, $\frac15$, $\frac18$, $\frac19$, $\frac1{10}$ full, can we pour to get a cup $\frac16$ full?","There are seven cups, $C_1$ , $C_2$ , $\ldots$ , $C_7$ and they have the same capacity $V$ . Initial: Water of $C_1$ occupies $\frac{1}{2}V$ Water of $C_2$ occupies $\frac{1}{3}V$ Water of $C_3$ occupies $\frac{1}{4}V$ Water of $C_4$ occupies $\frac{1}{5}V$ Water of $C_5$ occupies $\frac{1}{8}V$ Water of $C_6$ occupies $\frac{1}{9}V$ Water of $C_7$ occupies $\frac{1}{10}V$ Allow pouring all water from one cup to another if the water does not overflow or pour water from one cup to another until it is full. Can we, after a number of times pouring water, have cup that occupies $\frac{1}{6}V$ ? This is my attempt: We consider cup A and cup B have the amount of water, respectively, a and b where $0\le a,b\le 1$ . If you pour water from cup A to cup B, the following will happen: If $a+b<1$ . Then after pouring, cup A will be empty and cup B takes up $a+b$ cup. If $a+b<1$ . Then after pouring, cup A will takes up $a-b$ cup and cup B is full. I just think something here and I can't solve this problem ! Can you help me this stuck!",['discrete-mathematics']
3740833,Find all $x > 0$ s/t $\sqrt{x} + 1/\sqrt{x}$ and $x^{1/3} + 1/x^{1/3}$ are integers. Why doesn't this get all solutions?,"This is a math puzzle I've been working on, and I'm not sure why my approach isn't yielding all the solutions for $x$ . As in the title, the question is to find all positive reals $x$ where $\sqrt{x} + 1/\sqrt{x}$ and $x^{1/3} + 1/x^{1/3}$ are both integers. Here's my approach--I'm not sure where the error is. Where does the following approach go wrong? Suppose that $\sqrt{x} + 1/\sqrt{x} = m$ and $x^{1/3} + 1/x^{1/3} = n$ , where $m,n \in \mathbb{Z}$ . We let $m, n > 0$ since $\sqrt{x} + 1/\sqrt{x} > 0$ and $x^{1/3} + 1/x^{1/3} > 0$ for $x > 0$ . We equivalently have $x - m\sqrt{x} + 1 = 0$ and $x^{2/3} -nx^{1/3} + 1 = 0$ . Let $u = \sqrt{x}$ , so that we have $u^2 - mu + 1 = 0$ and $u^{4/3} - nu^{2/3} + 1 = 0$ . It suffices to find all $u$ satisfying both of these equations. Applying the quadratic formula, $u = \frac{m \pm \sqrt{m^2 - 4}}{2}$ and $u^{2/3} = \frac{n \pm \sqrt{n^2-4}}{2}$ . Squaring the first equation gets $u^2 = (\frac{m \pm \sqrt{m^2 - 4}}{2})^2$ .Cubing the second equation gets $u^2 = (\frac{n \pm \sqrt{n^2-4}}{2})^3$ . So there are 4 sign combinations setting these two expressions for $u^2$ equal. Since $m,n$ are integers, I look for integer solutions only, finding only $m = 2, n = 2$ as the viable solution in all 4 cases. I checked this part with WolframAlpha--the general idea was to isolate radicals to one side. If we have a nonzero sum of surds, it ends up being irrational while the other side is rational. That leaves integer solutions to the radicals $\sqrt{m^2-4},\sqrt{n^2-4}$ , the only positive solutions to which are $m = 2$ and $n = 2$ . This yields $u = 1$ as the only viable solution. However, the solution states that there are infinitely many such $x$ .","['algebra-precalculus', 'solution-verification', 'integers']"
3740876,Transformation to remove column in regression proof,"I'm trying to show that the $F$ statistic where the smaller model is just the removal of the $j$ th predictor is equivalent to the square of the $t$ statistic for question $3.1$ in Elements of Statistical Learning. $$F = \frac{RSS_0 - RSS_1}{RSS_0/(N-p-1)}$$ $$z_j = \frac{\hat{\beta_j}}{\hat{\sigma}\sqrt{v_{jj}}}$$ where $v_{jj} = (X^TX)^{-1}_{jj}$ , and $RSS_0$ is the residual sum of squares of the bigger model, and $RSS_1$ is the residual sum of squares of the model with predictor $j$ removed. This boils down to showing that $$RSS_0 - RSS_1 = \frac{\hat{\beta_j^2}}{v_{jj}}$$ I try and compute $RSS_0 - RSS_1$ (I will refer to $H = X(X^TX)^{-1}X^Ty$ ): \begin{align}
RSS_0 - RSS_1 &= ||y-\hat{y}_{full}||^2 - ||y-\hat{y}_{no \beta_j}||^2
\\&= ||(I-H_{full})y||^2 - ||(I-H_{no\beta_j})y||^2
\\&= y^T(I-H_{full})y - y^T(I-H_{no\beta_j})y = y^T(H_{no\beta_j} - H_{full})y
\end{align} It is over here where I am stuck - I don't know how to get an expression for $H_{no\beta_j}$ - If I knew some transformation $T: \mathbb{R}^{n\times p} \rightarrow \mathbb{R}^{n\times (p-1)}$ then maybe I could proceed, but other ideas are appreciated.","['linear-regression', 'statistics', 'linear-algebra', 'hypothesis-testing']"
3740896,A homogeneous linear system $\textbf{Ax}=\textbf{0}$,"Consider a homogeneous system $\textbf{Ax}=\textbf{0}$ whose coefficient matrix is $$\textbf{A}= \begin{pmatrix}
 x_{1}^{2}&  x_{1}y_{1}&  y_{1}^{2}&  x_{1}&  y_{1}&  1\\ 
 x_{2}^{2}&  x_{2}y_{2}&  y_{2}^{2}&  x_{2}&  y_{2}&  1 \\ 
 x_{3}^{2}&  x_{3}y_{3}&  y_{3}^{2}&  x_{3}&  y_{3}&  1 \\ 
 x_{4}^{2}&  x_{4}y_{4}&  y_{4}^{2}&  x_{4}&  y_{4}&  1\\ 
 x_{5}^{2}&  x_{5}y_{5}&  y_{5}^{2}&  x_{5}&  y_{5}&  1 
\end{pmatrix}\in Mat(\mathbf{R} ;5\times 6 ) .$$ $$ \textbf{x}= \begin{pmatrix}
A\\ 
B\\ 
C\\ 
D\\ 
E\\
F 
\end{pmatrix}\in\mathbf{R^6};\qquad\textbf{0}=\begin{pmatrix}
0\\ 
0\\ 
0\\ 
0\\ 
0
\end{pmatrix}.$$ Show that $rank(\textbf{A})=5;$ there is an $\mathbf{x} $ such that $\textbf{Ax}=\textbf{0}$ and $\det(\begin{pmatrix}
 2A&  B&  D \\ 
  B& 2C& E \\ 
 D&  E&  2F \
\end{pmatrix})\ne 0$ . $\Longleftrightarrow $ For any $ k_{1},k_{2},k_{3}\in \{1,2,3,4,5\} $ and $k_{1}<k_{2}<k_{3}$ , $ rank\begin{pmatrix}
 x_{k_{1}}&  y_{k_{1}}& 1\\ 
 x_{k_{2}}&  y_{k_{2}}& 1 \\ 
 x_{k_{3}}&  y_{k_{3}}& 1
 \end{pmatrix}=3.$ I want to apply only the knowledge of linear algebra to proof "" There is a unique conic through any five points in a real plane, and it is nondegenerate if and only if no three of the points are collinear .""","['matrices', 'systems-of-equations', 'algebraic-geometry', 'linear-algebra']"
3740914,Does this partial midpoint-convexity imply full convexity?,"Let $f:(-\infty,0] \to \mathbb [0,\infty)$ be a $C^1$ strictly decreasing function. Definiton: Given $c \in (-\infty,0]$ , we say that $f$ is midpoint-convex at the point $c$ if $$
f((x+y)/2) \le (f(x) + f(y))/2,
$$ whenever $(x+y)/2=c$ , $x,y \in (-\infty,0]$ . Question: Let $r<0$ be fixed, and suppose that for every $x \in [r,0]$ , $f$ is midpoint-convex at $x/2$ . Is $f|_{[r,0]}$ convex? I know that $f|_{[r/2,0]}$ is convex. Indeed, the assumption implies that $f|_{[r/2,0]}$ is midpoint-convex in the usual sense, i.e. $$
f((x+y)/2) \le (f(x) + f(y))/2,
$$ whenever $x,y \in [r/2,0]$ , and midpoint-convexity plus continuity implies full convexity. Clarification: The point is that on the one hand, we are given assumptions which are stronger than midpoint-convexity at $[r/2,0]$ (since we are given ""convexity-information"" on how values of $f$ on $[r/2,0]$ relate to its values on $[r,0]$ as well. On the other hand, we are assuming something weaker then midpoint-convexity on all $[r,0]$ .","['calculus', 'convex-analysis', 'examples-counterexamples', 'real-analysis']"
3740957,Stokes' Theorem general case,"With the following lemma : Lemma : Let $f_{+},f_{-} : U \longmapsto \mathbb{R}$ be $C^{1}$ maps with $f_{-} \leq 0 \leq f_{+}$ with $U \subset \mathbb{R}^{n}$ open and bounded with $C^{1}$ boundary. Let $\Omega : \lbrace (x,t) : x \in U \wedge f_{-}(x) < t < f_{+}(x) \rbrace$ and $u \in C^{1}(\overline{\Omega})$ . Let $y = (x,t)$ then we have $$\int_{\Omega} \partial_{t}u(y)dy = \int_{\Sigma_{+}\cup \Sigma_{-}}u(z) \cdot \langle e_{t},v_{ext}(z)\rangle d\sigma(z)$$ Where $\Sigma_{+} = graph(f_{+}),\Sigma_{-} = graph(f_{-})$ and $v_{ext}(z)$ is the normal tangent vector. I'd like to prove the general case, which means the following theorem : Theorem : Let $\Omega \subset \mathbb{R}^{m}$ open and bounded with $C^{1}$ boundary. Then given $u \in C^{1}({\overline{\Omega}})$ and said $v_{ext}(z)$ the normal tangent vector of the boundary in the point $z \in \partial \Omega$ in outgoing direction with respect to the ""inside"" of the manifold, we have $$\int_{\Omega}\partial_{i}u(y)dy = \int_{\partial \Omega}u(z)\cdot \langle e_{i},v_{ext}(z)\rangle d\sigma(z)$$ I do understand the proof of the lemma, what I don't understand is the general proof of the theorem which requires an easy Sard's theorem version to affirm that the image under the projection $p : \mathbb{R}^{n} \longmapsto \mathbb{R}^{n-1} \hspace{0.2cm} p(x_{1},\cdots,x_{n}) = (x_{1},\cdots,x_{n-1})$ of the point of the boundary, where the restriction of $p$ to the tangent space $T_{x}\partial \Omega$ is not invertible, has measure $0$ , in other words $p(\lbrace x \in \partial\Omega : \lvert p_{|_{T_{x}\partial\Omega}} \mbox{not invertible}\rbrace) \rvert = 0$ . Thanks to this observation we can proceed as if $\partial\Omega$ didn't contain ""critical"" points where $v_{ext} \perp e_{i}$ . Then called $U = p(\Omega)-p(\lbrace x \in \partial\Omega : \langle e_{i},v_{ext} \rangle = 0\rbrace)$ , open in $\mathbb{R}^{n-1}$ , and $V$ a connected component of $U$ , I should be able to prove that $\Omega \cap p^{-1}(V)$ is a finite union of open and disjoint sets which are of the form of the lemma already proven and conclude the theorem by additivity of the integral. Any solution and help on how to prove that $\Omega \cap p^{-1}(V)$ is a finite union of open and disjoint set which are of the form of the lemma already proven is well accepted. I know there are easier ways to prove the theorem for instance using partition of unity, a tool I'm not aware of. I would like to keep the proof as linear as possible, possibly using just general topology and the analysis required. As general as possible solutions using just general topology and the analysis concerning the second year of math university are well accepted too. Edit 1 : The definition of manifold I'm currently using is : Definition : A subset $M \subseteq \mathbb{R}^{n}$ is a differentiable manifold of class $C^{l}$ and dimension $k$ if $\forall \hspace{0.1cm} x \in M \hspace{0.1cm} \exists  \hspace{0.1cm} U \in \mathbb{R}^{k},V \in \mathbb{R}^{n}$ open subsets, with $x \in V$ and a diffeomorphism $\phi : U \longmapsto V \cap M$ of class $C^{l}$ . While the ""easy"" version of Sard's Theorem for manifolds is the following : Definition : Let $f : \Sigma \longmapsto \Gamma$ a function of class $C^{1}$ between manifolds of same dimension. A point $p \in \Sigma$ is said to be critical is $d_{p}f$ is not surjective. The immage of the critical point are said critical values . Theorem : Let $f : \Sigma \longmapsto \Gamma$ a function of class $C^{1}$ between manifolds. The critical values have null measure.","['divergence-theorem', 'manifolds-with-boundary', 'real-analysis', 'stokes-theorem', 'general-topology']"
3740976,Absolute moment existence,"I have given $$F_X(x) = \frac{1}{1+e^{-x}} ; \quad x \geq0$$ I have to calculate $k$ , s.t. $E[|X|^k]<\infty$ I did calculate the density by $f_X(x) = \frac{dF}{dx} =\frac{e^{-x}}{(1+e^{-x})^2} $ . Using this to calculate the absolute moments, I found it to be very cumbersome so I think that this might not be the best way to solve this. Does anyone have thoughts? Best","['integration', 'expected-value', 'probability-distributions', 'probability-theory']"
3741069,No-nonsense reference on classical Dieudonné theory,"There should be an (anti-)equivalence between finite commutative group schemes over perfect fields, and certain modules over the Dieudonné ring of that field. Despite being universally known, the proof is rarely given in the literature. I am looking for a reference that satisfies the following criteria. It's written in English. It's written in modern language (so no barely-readable typewriter stuff with archaic language). It's no-nonsense (so no crystalline cohomology, no prisms, no Breuil-Kisin modules, just a simple proof for a simple beginner). Does such a reference exist?","['number-theory', 'algebraic-geometry', 'schemes', 'reference-request']"
3741088,How to find first integral of a system,"I have the following system $x'=y, y'=-1-x+x^2+y^2$ . I know that $x^2+y^2-1=0$ is an invariant curve of the system but how do i find a first integral of the system?",['ordinary-differential-equations']
3741122,What is the actual difference between del and d in multivariate calculus?,"Recently I've tried to find the difference between partial differentiation and total differentiation.
I've heard the total derivative is defined on single value functions, while the partial derivative by contrast is defined on multivariate functions.
My problem is, that total differentiation is used on multivariate functions all the time. Every time I come up with a rigorous definition I arrive at a contradiction.
I will share what I have defined so far, and hopefully you can enlighten me. Let $$f: (x_1, ... , x_n) \rightarrow f(x_1, ..., x_n)$$ and it's partial derivative by the difference quotient $$\frac{\partial f}{\partial x_i} = \lim_{h \to 0} \frac{f(x_1,..,x_i+h,...x_n)- f(x_1,..., x_n)}{h}$$ the total derivative must by contrast account for interdependence between $x_k$ in the domain of f. $$\frac{df}{dx_i}\stackrel{?}{=} \sum_k{\frac{\partial f}{\partial x_k} \frac{\partial x_k}{\partial x_i}}$$ This seemed sensible to me, until I realized it simplified to $$n \frac{\partial f}{\partial x_i}$$ which definitely isn't right. Can someone tell me where I've made an error? Or provide better definition? This issue really annoys me, since all my research so far didn't answer this question at all. Edit:
Ok thank you for all the responses!
I'm just writing out the final formula for total derivatives for quick lookup now: $\frac{d}{d x_i}$ is defined recursively as $$\frac{df}{dx_i}\stackrel{!}{=} \sum_k{\frac{\partial f}{\partial x_k} \frac{d x_k}{d x_i}}$$ until $x_k$ has a domain without interdependence, in which case $\frac{\partial x_j}{\partial x_i}$ = $\frac{d x_j}{d x_i}$ and the entire expression can be calculated by limits.","['partial-derivative', 'multivariable-calculus', 'calculus', 'derivatives']"
3741130,Probabilistic Recurrence Relations,"In the paper ""The Complexity of Parallel Search"" (Karp, Upfal and Wigderson; Journal of Computer and System Sciences 36, 225 - 253, 1988) in the appendix, the authors present the iteration procedure m = n; t = 0;
while m > 0 do
     begin m = m - X(m); t = t+1 end
T=t; where $X(m)$ is a random variable over $\{0,\dots,m\}$ and $T$ is the random variable which represents the number of iterations executed in the above procedure, depending on $X(m)$ . They give the following theorem: Theorem Suppose $\operatorname{E}[X(m)]\geq g(m)$ where $g:\mathbb R^+\to\mathbb R^+$ is monotone nondecreasing. Then $\operatorname{E}[T]\leq\int_1^n\frac{1}{g(x)}dx$ and for every $a>0$ : $$\operatorname{Pr}\left[T>(a+1)\int_1^n\frac{1}{g(x)}dx\right]<e^{-a}$$ They give no proof but refer to a forthcoming publication. However, I was not able to find any proof of this. The second part of the theorem could be obtained, I think, from Corollary 4.3 of ""Probabilistic Recurrence Relations"" (Karp; Journal of the ACM, 41 (6), 1136 - 1150, 1994). However, I can not really wrap my head around why we have $$\operatorname{E}[T]\leq\int_1^n\frac{1}{g(x)}dx.$$","['expected-value', 'recurrence-relations', 'probability', 'random-variables']"
3741150,Groups where every continuous function is uniformly continuous,"Let $G$ be a topological group, and $(X, d)$ a metric space. The function $f : G \to X$ is left uniformly continuous if for all $\varepsilon > 0$ there exists an identity neighbourhood $U$ such that for all $g\in G, u \in U$ it holds $d(f(g), f(ug)) < \varepsilon$ . If $G$ is compact or discrete, every continuous function is uniformly continuous. Is there a larger class of groups for which this holds, maybe with some extra assumptions on $X$ or $f$ ? I am particularly interested in totally disconnected locally compact groups $G$ , ultrametric normed vector spaces $X$ and bounded functions $f$ .","['uniform-continuity', 'topological-vector-spaces', 'topological-groups', 'abstract-algebra', 'functional-analysis']"
3741168,Inequation in paper from Terence Tao on the Collatz Conjecture,"I try to understand Terence Tao's paper on the Collatz Conjecture [ 1909.03562 ], but got stuck on page 25. We have $n$ copies of a geometric random variable of mean $2$ , denoted by $a_i$ and $a_{[i,j]}$ is defined to be the sum over them from $a_i$ to $a_j$ . It is then claimed, that if $$|a_{[i,j]}-2(j-i)| \leq C_A(\sqrt{(j-i)(\log(n))}+\log(n))$$ holds for all $i,j$ , that then we have $$a_{[1,n]} \geq 2n-C_A(\sqrt{n(\log(n))}+\log(n)) > n \frac{\log 3}{\log 2}$$ with large $n$ . I see that I get at least $$a_{[1,n]} \geq 2(n-1)-C_A(\sqrt{n(\log(n))}+\log(n))$$ which had the same consequence, but is this a typo or can I get even the stronger statement? But the more important question is the following. He introduces a stopping time $k_{\text{stop}}$ with the property $$a_{[1,k_{\text{stop}}]} \leq n \frac{\log 3}{\log 2} - C_A^2 \log(n)<a_{[1, k_{\text{stop}}+1]}$$ It is then claimed, that $$k_{\text{stop}}= n \frac{\log(3)}{2 \log(2)}+O(C_A^2 \log(n))$$ I do not understand the last statement. In the ""worst"" case, all the $a_i$ are 1 and then this would not hold. Clearly, this example would violate the inequality in the beginning, but why is this the case in general? Furthermore, he claims, that the stopping time $l$ iff $$a_{[1,l]} \leq n \frac{\log 3}{\log 2}-C_A^3 \log n < a_{[1,l+1]}$$ Where does the $C_A^3$ instead of $C_A^2$ come from?","['analytic-number-theory', 'number-theory', 'collatz-conjecture']"
3741170,analysis/ode question,"Prove that there does not exist any twice continuously differentiable function $f:[0,1]\to \mathbb{R}$ with $f(0)=0$ and $f(1)=1$ such that $$
- e^{-f'} f'' + 2 f = 0.
$$ As an attempt, I drew a graph of what the solution should look like.  At zero, we know that $u(0)=u''(0)=0$ from the equation and at one, we know that $u(1)=1$ and $u''(1)= 2e^{u'(1)}>0$ .  Thus, we know that there must be a point $c$ such that $u'(c)=0$ and $u(c)>0$ .  But from the equation this implies that $u''(c) = 2 u(c)2e^{u'(c)}>0$ .  This seems to contradict the ability of the solution to match the boundary condition at $x=0$ , but I have trouble formalizing this.  Is there a simpler argument?","['ordinary-differential-equations', 'real-analysis']"
3741186,Covariance between functions of random variables,"Suppose $Y,X_1,X_2,...$ are random variables (not necessarily i.i.d.) with expectation $0$ and variance $1$ , and suppose that $$Cov(X_n,Y)<\frac{1}{n} $$ for every $n \in \mathbb{N}$ . Given a measurable function $f:\mathbb{R}\longrightarrow \mathbb{R}$ with $||f||_{\infty}\le 1$ , can we bound $$Cov(f(X_n),Y) $$ other then the trivial bounds $$|Cov(f(X_n),Y)|\le \sqrt{Var(f(X_n))\cdot Var(Y)}? $$","['measure-theory', 'probability-limit-theorems', 'conditional-probability', 'probability-theory', 'probability']"
3741190,Interesting/Useful tricks in linear algebra. [closed],"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 3 years ago . Improve this question This may be an opinion based-based question, since everyone understands things differently, but what are some interesting/useful tricks in linear algebra? For example, if we know that the determinant of a matrix is equal to 0
0
, then we that the matrix is not invertible, the rows and columns of the matrix are linearly dependent, and so on. Are there any others, that would be useful to have on a cheatsheet for a linear algebra exam?","['matrices', 'big-list', 'linear-algebra', 'vector-spaces']"
3741210,"For any positive integer $k$, there exists a prime $p$ such that ${x \choose k}\equiv -1\pmod{p}$ has an integer solution.","Here is a conjecture of mine. Prove that for any positive integer $k$ , there exists a prime $p$ such that $${x \choose k}\equiv -1\pmod{p}$$ has an integer solution. When $k$ is odd, we can take $x$ to be $p-1$ , the question can be easily solved because $${p-1 \choose k}\equiv (-1)^k\equiv -1\pmod{p}.$$ However, when $k$ is even, I cannot find any pattern. Here are results for $k=4$ and $k=6$ . $$x=30\implies {x \choose 4}\equiv -1\pmod{193},$$ $$x=34\implies {x \choose 6}\equiv -1\pmod{97}.$$ Edit: See Peter's comment. It is an obvious result. Still, I am very curious about if $p$ can be arbitrarily large. If we use Peter's hint, we need to prove that given $k$ , the prime factor of the sequence $$\left\{{x\choose k}+1\right\}_{x=1}^{\infty}$$ can be arbitrarily large. I feel like that the proof is similar to Primes dividing a polynomial .","['number-theory', 'binomial-coefficients', 'modular-arithmetic']"
3741252,What is the correct name for relation like things such as $\in$ and =,= and $\in$ look like relations and you can sometimes treat them like they are.  However the domain and codomain of both is the class of all sets. Is there a term for this type of thing?,['elementary-set-theory']
3741313,Proof for the general formula for $a^n+b^n$.,"Based on the following observations. That is $$a+b = (a+b)^1  \\  a^2+b^2 = (a+b)^2-2ab \\ a^3+b^3 = (a+b)^3-3ab(a+b) \\ a^4+b^4= (a+b)^4-4ab(a+b)^2+2(ab)^2\\ a^5+b^5 
= (a+b)^5 -5ab(a+b)^3+5(ab)^2(a+b)\\\vdots$$ I came to  make the following conjecture as  general formula. $$ a^n +b^n =\sum_{k=0}^{n-1}(-1)^k \frac{n\Gamma(n-k)}{\Gamma(k+1)\Gamma(n-2k+1)}(a+b)^{n-2k}(ab)^k $$ where $\Gamma(.) $ is gamma function. I tried up proving the result using binomial theorem $\displaystyle (a+b)^n=\sum_{r=0}^n a^{n-r}b^r$ for positive integers $a,b$ however, I didn't find  any elegance in the work.  So in the expect of some beautiful proofs,  I wish to share  general formula here. Thank you","['summation', 'binomial-coefficients', 'combinatorics']"
3741381,Showing that the Diophantine equation $m(m-1)(m-2)(m-3) = 24(n^2 + 9)$ has no solutions,"Consider the Diophantine equation $$m(m-1)(m-2)(m-3) = 24(n^2 + 9)\,.$$ Prove that there are no integer solutions. One way to show this has no integer solutions is by considering modulo $7$ (easy to verify with it). I am curious whether there is a slightly less $``$ random $``$ way to solve this problem such as using the fact that if $p\equiv 3 \pmod 4$ divides $x^2 + y^2$ , then $p$ must divide both $x$ and $y$ . This looks convenient since the left-hand side has a multiplier which is $\equiv 3 \pmod 4$ (and hence such a $p$ surely exists) and we will be done provided we can take $p\neq 3$ (since the only prime $p\equiv 3 \pmod 4$ which divides $y=3$ is $3$ itself). Any idea if this method could work? I am of course also open to see other ideas. Any help appreciated!","['modular-arithmetic', 'number-theory', 'elementary-number-theory', 'diophantine-equations', 'problem-solving']"
3741397,Vertices in a graph with the same number of closed walks,"A graph is called walk regular if the number of closed walks starting from vertex $u$ of length $k$ does not depend on $u$ . If $A$ is the adjacency matrix of the graph, this means that $A^k$ has equal diagonal values for every $k>0$ . I'm interested in a weaker condition, that there exists two vertices $u,v$ such that the number of closed walks of length $k$ is the same for $u$ and $v$ . Are there results or references about this? In other words, when does $[A^k]_{uu} = [A^k]_{vv}$ hold? For example, it would be nice to have necessary/sufficient conditions for this property to hold. If there is a graph automorphism that maps $u\to v$ then certainly $u$ and $v$ have the same number of closed walks, though the existence of such an automorphism is not necessary (an example is the Folkman graph which is walk-regular but not vertex-transitive). I'm aware that if the graph has $n$ vertices and $u,v$ have the same number of closed walks for $k=1,2,\ldots n-1$ , then by Hamilton-Cayley's theorem it is true also for all $k\geq n$ . I'm asking in the case of a simple undirected graph, but if there are generalizations for directed and/or weighted graphs they're highly welcome.","['matrices', 'adjacency-matrix', 'graph-theory', 'reference-request']"
3741419,Conditions for a intersection of connected sets to be connected.,"This is the original statement I want to prove: Conjecture: Let $A$ and $B$ be open connected sets in $\mathbb R^2$ with the usual metric such that $A \cap B \neq \emptyset$ . Then $ \partial A \cap \partial B = \emptyset \Longrightarrow$ $ A \cap B $ is connected. It is a simple statement, but I cannot find a proof neither a counter example. Any ideas are welcome! Update 0: Some comments about this being a general topological result made me realize that an example of space where this doesn't hold is important as motivation. Here is a simple example of such space: Consider the circle $S^1 = \mathbb R / \mathbb Z$ and the intervals $A = (\frac{2}{8}, \frac{7}{8})/ \sim$ and $B = (\frac{-3}{8}, \frac{3}{8})/ \sim$ ( $\sim$ is the equivalence relation defining the circle). Note that they satisfy the conditions but their intersection is not connected: $A \cap B =( (\frac{2}{8}, \frac{7}{8}) \cup (\frac{5}{8}, \frac{7}{8}))/ \sim$ . This is illustrated below. Update 1: I came with a weaker version of this statement that is sufficient for the application I need. Weak Conjecture: Let $A,B$ be open connected sets in $\mathbb R^2$ such that $A \cap B \neq \emptyset$ and each connected component of $\partial A$ and $\partial B$ is the image of a proper embedding from $\mathbb R$ to $\mathbb R^2$ . Then $ \partial A \cap \partial B = \emptyset \Longrightarrow$ $ A \cap B $ is connected. $\ \ \ $ Proof: $\quad$ First, we will refer to images of proper embeddings from $\mathbb R$ to $\mathbb R^2$ as lines. Note that lines splits the plane into two connected components. In the case that a line $\phi$ is a connected component of the boundary of some connected set $U$ , we can define $D(\phi)$ as the connected component of $\mathbb R^2 \setminus \phi$ which contains $U$ . The other c.c. is denoted $E(\phi)$ . If we denote $\Phi_U$ the collection of all c.c. of $\partial U$ , we can write $$ U = \bigcap_{\phi_i \in \Phi_U} D(\phi_i) \qquad \ \ \ \ \ U^c = \bigsqcup_{\phi_i \in \Phi_U} E(\phi_i)\;. $$ It is important to note that the union above is disjoint. Otherwise, we would get $i_1 \neq i_2$ such that $\phi_{i_1} \cap \phi_{i_2} \neq \emptyset$ , absurd since they are different c.c. components of $\partial U$ . $\quad$ Now we begin the proof. Let $C : = A \cap B$ and suppose $C$ has at least two nonempty connected components $C_1$ and $C_2$ . Note that $ C_2 \subset C_1^c = \bigsqcup_{\phi_{i} \in \Phi_{C_1}} E(\phi_i)$ , therefore $\exists ! \  i_n$ s.t. $C_2 \in E(\phi_{i_n})$ . Since $\partial A \cap \partial B = \emptyset $ , we can suppose without loss of generality that $\phi_{i_n} \subset \partial A$ . However, $C_1 \subset A$ and $C_2 \subset A$ are contained on different c.c. of $\mathbb R^2 \setminus \phi_{i_n}$ , which would imply that $A$ is not connected, absurd. $\qquad $ Q.E.D. The main question remains open for discussion. The understanding of the topology of $\partial U$ is all that we should need to conclude it.","['general-topology', 'metric-spaces', 'connectedness']"
3741458,Smoothest possible path interpolation given 2-D positions and directions?,"Assume I have a set of $n$ points $\{x_1,...,x_n \} \in \mathbb{R^2}$ and a set of corresponding directions (or angles) $\{d_1,...,d_n \}$ . It is my goal to find the smoothest, continuous path (edit: I define smoothness as the smallest overall curvature) which passes through all $n$ points while honoring all $n$ directions. The solution may be provided in increments, for example through splines between a pairs of successive points. I have illustrated what I mean below. Do you have any suggestions on how to tackle this issue?","['interpolation', 'geometry', 'differential-geometry']"
3741471,Reducing ordinary differential equation into clairaut's form,Given equation is $$x^{2}p^{2}+py\left ( 2x+y \right )+y^{2}=0$$ Where $p=\frac{\mathrm{d} y}{\mathrm{d} x}$ I know about clairaut's form and if we put $y=u$ and $xy=v$ then we will get clairaut's form. I want to learn how to guess that we need to put $y$ and $xy$ .,['ordinary-differential-equations']
3741476,Problem with Summation of series,"Question: What is the value of $$\frac{1}{3^2+1}+\frac{1}{4^2+2}+\frac{1}{5^2+3} ...$$ up to infinite terms? Answer: $\frac{13}{36}$ My Approach: I first find out the general term ( $T_n$ ) $${T_n}=\frac{1}{(n+2)^2+n}=\frac{1}{n^2+5n+4}=\frac{1}{(n+4)(n+1)}=\frac{1}{3}\left(\frac{1}{n+1}-\frac{1}{n+4}\right)$$ Using this, I get, $$T_1=\frac{1}{3}\left(\frac{1}{2}-\frac{1}{5}\right)$$ $$T_2=\frac{1}{3}\left(\frac{1}{3}-\frac{1}{6}\right)$$ $$T_3=\frac{1}{3}\left(\frac{1}{4}-\frac{1}{7}\right)$$ I notice right away that the series does not condense into a telescopic series. How do I proceed further?",['sequences-and-series']
3741514,"Composition of entire functions is identity, then functions are linear","A question from a previous qualifying exam at my university reads: ""Suppose that f and g are entire functions such that $f \circ g(x) = x$ when $x \in \mathbb{R}$ . Show that $f$ and $g$ are linear functions."" One can conclude that the composition of $f$ and $g$ is the identity on all of $\mathbb{C}$ , by the uniqueness principle. I know how to solve the problem if one assumes that $f$ is injective. However, there are examples of functions that have a right inverse but are not injective. However, entire functions have many properties, so is there a way of showing $f$ must be injective from the information above, or should I approach the problem differently?","['complex-analysis', 'entire-functions']"
3741530,Spivak's Calculus on Manifolds theorem 2-9 why is continuous differentiable needed,"In the third last line, it is said that because each $g_i$ is continuously differentiable at $a$ then the constructed function $g$ is also differentiable at $a$ . I do not see why ""continuously"" differentiable is need cuz I think a function is differentiable if and only if each of its components is differentiable (theorem 2-3(3)). It seems that I am missing something very obvious Edit: theorem 2-8 is","['multivariable-calculus', 'calculus']"
3741532,Convergence in probability implies mean squared convergence,"Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space. Let $(X_n)_{n \in \mathbb{N}}$ be a sequence of $\mathcal{F}$ measurable random variables. Let $X$ be another $\mathcal{F}$ measurable random variable. I have $X_n \rightarrow X $ in probability. Additionally, $\mathbb{P}(|X_n|<L) = 1 \hspace{3mm} \forall \hspace{2mm}n \in \mathbb{N}$ , where $L$ is a constant independent of $n$ . I have to show that $X_n \rightarrow X$ in mean squared sense, i.e. as $n \rightarrow \infty$ , $\mathbb{E}(X_n - X)^2 \rightarrow 0$ . How do I go about this? Thanks.","['convergence-divergence', 'probability-theory']"
3741536,implicit differentiation and taking limit on derivative,"I have this equation $x^3-xy^2+y^3=0$ and I want to know the value of the derivative at $(0,0)$ . Through implicit differentiation I find $y'=\frac{y^2-3x^2}{3y^2-2xy}$ . Now for $x=0,y=0$ this fraction becomes an indeterminate form. Upon graphical inspection I think if I were to draw a tangent at the Origin, it will have a slope very close to $-0.75$ , but what is an easy method to find out the actual value? Note, when you graph the original function it LOOKS like a line, but it ISN'T. Thank you for your input.","['multivariable-calculus', 'calculus']"
3741551,"Correct logical equivalent of ""Every real number except zero has multiplicative inverse.""","My Discrete Mathematics textbook translates the statement ""Every real number except zero has multiplicative inverse"" to $$\forall{x}{({(x\neq0)} \rightarrow{\exists{y}{(xy=1)}})}.\tag1$$ I noticed that the above translation is correct if and only if you interpret the original English statement as not specifying whether zero has multiplicative inverse. That is, all numbers have inverses except zero for which zero may or may not have an inverse. (This is evident from the truth table in which if $x$ was equal to zero then whether $x$ has an inverse or not the statement evaluates to true in both cases.) In the same vein, I can say that ""Every real number greater than 7 has a multiplicative inverse"" translates to $$\forall{x}{({(x>7)} \rightarrow{\exists{y}{(xy=1)}})};$$ this statement doesn't mean that only real numbers greater than $7$ have a multiplicative inverse. However, if you interpret the original English statement as ""Every real number except zero has multiplicative inverse while zero does not have a multiplicative inverse"", then this translates to $$\forall{x}{({(x\neq0)} \leftrightarrow{\exists{y}{(xy=1)}})}.\tag2$$ My professor translated the original sentence the same way the book did. So, I asked whether he assumed that zero has multiplicative inverse, and he answered with a yes because we know that zero does not have a multiplicative inverse. I then explained what I wrote above, but I couldn't get my point across, and he insisted that his translation was correct. Is what I wrote above correct, or is the first translation indeed the only correct one? Is ""Every real number except zero has multiplicative inverse"" ambiguous or is $(1)$ or $(2)$ its correct logical equivalent?","['predicate-logic', 'first-order-logic', 'logic', 'discrete-mathematics', 'logic-translation']"
3741552,Why do partitions correspond to irreps in $S_n$?,"As stated for example in these notes ( Link to pdf ), top of page 8, irreps of the symmetric group $S_n$ correspond to partitions of $n$ . This is justified with the following statement: Irreps of $S_n$ correspond to partitions of $n$ . We've seen that conjugacy classes of $S_n$ are defined by cycle type, and cycle types correspond to partitions. Therefore partitions correspond to conjugacy classes, which correspond to irreps. I understand the equivalence between partitions, cycle types, and conjugacy classes, but I do not fully get the connection with irreps: I can associate to a partition $\lambda\vdash n$ the conjugacy class of permutations of the form $$\pi=(a_1,...,a_{\lambda_1})(b_1,...,b_{\lambda_2})\cdots (c_1,...,c_{\lambda_k}).$$ The fact that conjugacy classes are defined by cycle types comes from the fact that $\sigma\pi\sigma^{-1}$ has the same cycle type structure as $\pi$ . However, in what sense do conjugacy classes correspond to irreps? I can understand this if we restrict to one-dimensional representations, as then $\rho(\pi)=\rho(\sigma\pi\sigma^{-1})$ for all $\sigma$ , but this is not the case for higher dimensional representations I think, being $S_n$ non-abelian.","['integer-partitions', 'representation-theory', 'finite-groups', 'symmetric-groups', 'group-theory']"
3741563,"Is $f(x)=\sum_{n=1}^{\infty}\frac{x}{1+n^2x^2}$, $x\in[0,1]$ continuous on $[0,1]$","Let $f(x)=\sum_{n=1}^{\infty}\frac{x}{1+n^2x^2}$ , $x\in[0,1]$ . Question: Show that $f$ is Lebesgue integrable and determine whether $f$ is continuous on $[0,1]$ . For the first part, I have no problem, I showed that it is Lebesgue integrable. But for the second part, I could not reach any result by using the definition. Also, I'm not sure if I should use the first part.  Can you give me a hint for this part?","['continuity', 'lebesgue-integral', 'real-analysis']"
3741623,Doubt in the framing of a question on Venn diagram,"In a group of $265$ people, $200$ like singing, $110$ like dancing and $55$ like painting. If $60$ people like both singing and dancing, $30$ like both singing and painting and $10$ like all the three activities, then the number of people who like only dancing and painting are? Now I know that this question has been asked before. But the problem I am facing is in the framing of the question. In all the solutions that I have seen, in all of them, we are considering that all these $265$ people like some activity. My question is why isn't it possible that out of $265$ people, some of them don't like any of the three activities?",['elementary-set-theory']
3741746,Generators of the ideal correspond to $d$-uple embedding,"I am trying to mimic the interesting proof from Hartshorne Problem 1.2.14 on Segre Embedding to give a generating set of the ideal correspond to the $d$ -uple embedding: We fix the notation $\Delta = \big\{ (\nu_0, \dots, \nu_n) \in {\mathbb{N}}^{n+1}_0 ~:~ \nu_0 + \dots + \nu_n = d \big\}$ . The polynomial map is $\theta : k[y_\nu : \nu \in \Delta] \rightarrow k[x_0, \dotsc, x_n]$ given by $$
\theta ( y_\nu ) := x^{\nu_0}_0 \cdots x^{\nu_n}_n
$$ and we know that ${\mathrm{ker}}~\theta$ is the ideal of the $d$ -uple embedding, i.e., $\rho_d({\mathbb{P}}^n) = Z({\mathrm{ker}}~\theta)$ (cf. Exercise I.2.12 Hartshorne). Now let $W \leq k[y_\nu : \nu \in \Delta]$ denote the ideal $$
W := \Big\langle y_{\tau_1} y_{\tau_2} - y_{\tau^{\prime}_1} y_{\tau^{\prime}_2} ~:~ \tau_1, \tau_2, \tau^{\prime}_1, \tau^{\prime}_2 \in \Delta, \tau_1 + \tau_2 = \tau^{\prime}_1 + \tau^{\prime}_2 \Big\rangle
$$ Clearly, $W \subseteq {\mathrm{ker}}~\theta$ . Using the lemma in the above link, we need to produce a $k$ -subspace $T \subseteq k[y_\nu : \nu \in \Delta]$ with the conditions $$
T + W = k[y_\nu : \nu \in \Delta], \hspace{.2in} \theta \lvert_{T} = {\mathrm{injective}}
$$ After a few thoughts it seems reasonable to think of the following subspace as a candidate for $T$ : First define the equivalence relation on $\Delta \times \Delta$ given by $(\tau_1, \tau_2) \sim (\tau^{\prime}_1, \tau^{\prime}_2)$ if $\tau_1 + \tau_2 = \tau^{\prime}_1 + \tau^{\prime}_2$ . Let $\Omega \subseteq \Delta \times \Delta$ be a subset with a unique representative from each class of $\sim$ . Now let $T$ be the $k$ -span of the monomials $y^{\alpha_1}_{\tau_1} \dotsc y^{\alpha_r}_{\tau_r}$ (with the distinct elements $\tau_1, \dotsc, \tau_r \in \Delta$ and $\alpha_1, \dotsc, \alpha_r \geq 1$ ) such that $(\tau_i, \tau_j) \in \Omega$ for each $i \neq j$ . Clearly, $\theta$ is injective if restricted to $T$ . I got lost in the step : Each monomial $M$ of $k[y_\nu : \nu \in \Delta]$ satisfy $M \equiv b$ mod $W$ for some $b \in T$ . Did I do anything wrong?","['algebraic-geometry', 'commutative-algebra']"
3741802,Solve the equation $\frac{1}{x^2+11x-8} + \frac{1}{x^2+2x-8} + \frac{1}{x^2-13x-8} = 0$,Problem Solve the equation $$\frac{1}{x^2+11x-8} + \frac{1}{x^2+2x-8} + \frac{1}{x^2-13x-8} = 0$$ What I've tried First I tried factoring the denominators but only the second one can be factored as $(x+4)(x-2)$ . Then I tried substituting $y = x^2 - 8$ but that didn't lead me anywhere. Where I'm stuck I don't know how to start this problem. Any hints? P.S. I would really appreciate it if you give me hints or at least hide the solution. Thanks for all your help in advance!,['algebra-precalculus']
3741843,How can i evaluate $\int _0^{\infty }\frac{\ln \left(x\right)\sin \left(x\right)}{x^2+1}\:dx\:$ using real methods,"I've been trying to evaluate this integral for a while now. My friend used complex analysis to evaluate this but he got a wrong result. I tried using real methods but I've been stuck. One can probably use differentiating under the integral sign in the following ways, $$I\left(a\right)=\int _0^{\infty }\frac{\ln \left(x\right)\sin \left(ax\right)}{x^2+1}\:dx$$ or $$I\left(a\right)=\int _0^{\infty \:}\frac{x^a\sin \left(x\right)}{x^2+1}\:dx$$ But that seems complicated, I have no idea how to proceed, please help me.","['integration', 'improper-integrals', 'definite-integrals']"
3741855,How to solve $\int \frac{dx}{\sqrt{1+x}-\sqrt{1-x}}$?,"How can I evaluate the following integral $$\int \frac{dx}{\sqrt{1+x}-\sqrt{1-x}}$$ This is taken from a definite integral where $x$ varies from $0$ to $1$ . My attempt: Multiplied by conjugate $$\int \frac{dx}{\sqrt{1+x}-\sqrt{1-x}}\\=\int \frac{(\sqrt{1+x}+\sqrt{1-x})dx}{(\sqrt{1+x}-\sqrt{1-x})(\sqrt{1+x}+\sqrt{1-x})}$$ $$=\int \frac{\sqrt{1+x}+\sqrt{1-x})dx}{1+x-1+x}$$ $$=\int \frac{\sqrt{1+x}+\sqrt{1-x})dx}{2x}$$ If I use $x=\sin^2\theta$ $$\int \frac{\left(\sqrt{1+\sin^2\theta}+\cos\theta\right)}{2\sin^2\theta}\sin2\theta\ d\theta\\
=\int \left(\sqrt{1+\sin^2\theta}+\cos\theta\right)\cot\theta d\theta$$ If I use $x=\tan^2\theta$ $$\int \frac{\left(\sec\theta-\sqrt{1-\tan^2\theta}\right)}{2\tan^2\theta}2\tan\theta\sec^2\theta d\theta\ d\theta\\
=\int \frac{\left(\sec\theta-\sqrt{1-\tan^2\theta}\right)}{\sin\theta\cos\theta} d\theta$$ Should I use substitution $x=\sin^2\theta$ or $x=\tan^2\theta$ ?. I can't decide which substitution will work further. Please help me solve this integration. Thanks","['integration', 'indefinite-integrals', 'calculus']"
3741857,$L^2$ norm of inverse differential operator,"This has come up in Lemma 1 of Mandache's 2001 paper on exponential instability for the inverse problem of the Schrodinger operator. Let $\Omega = B(0,1)$ in $\mathbb{R}^d$ . Suppose $r_0\in (0,1)$ and $q$ is a function in $L^{\infty}$ supported on $B(0,r_0)$ . Suppose also that $0$ is not a Dirichlet eigenvalue of $-\Delta+ q$ , so that the boundary value problem $(-\Delta + q)u = F$ in $\Omega$ , $u = f$ on $\partial\Omega$ has a unique solution $u\in H^1(\Omega)$ for any $F\in H^{-1}(\Omega)$ , $f\in H^{1/2}(\partial\Omega)$ . I have two questions: In the paper, the author uses the notation $(-\Delta + q)^{-1}$ , which I would assume the operator that takes some $F\in H^{1/2}(\partial \Omega)$ and maps it to the unique $u\in H^1$ such that $(-\Delta + f)u = F$ ; is this correct? He also uses the norm $||(-\Delta + q)^{-1}||_{L^2}$ ; how am I to interpret this?","['inverse-problems', 'lp-spaces', 'functional-analysis', 'partial-differential-equations']"
3741881,Generic linear projection with $\text{Codim}\ge 2$ is birational (geometric proof),"Let $X\subseteq \mathbb P^N$ be a smooth variety and $p$ a general point $\mathbb P^N\setminus X$ . Consider the map $$\pi:X\to \mathbb P^{N-1}$$ as the restriction of linear projection $\mathbb P^N\setminus \{p\}\to \mathbb P^{N-1}$ . Then $\pi$ is a finite morphism (proper and quasi-finite) onto its image. Let's assume $\dim X\le N-2$ , in other words, $\pi(X)$ is not the whole space, then is $\pi:X\to \pi(X)$ a birational map? Edited: As KReiser pointed it out, it is an exercise in Hartshorne (which I didn't realize), and the standard proof is to show $X$ and $\pi(X)$ have the same function field using the standard tool in commutative algebra. There are already complete solutions linked in KReiser's comment. However, as a complex geometer, I'm used to thinking this problem geometrically, for example, I can relax the condition to $X\subset \mathbb C^N$ an analytic subvariety and ask if a generic linear projection is bimeromorphic. In other words, to me this problem is equivalent to show that for a  generic point $q\in \pi(X)$ , the line through $\overline{pq}$ intersect $X$ at only one point . Is there a geometric proof of this fact?","['complex-geometry', 'algebraic-geometry']"
3741886,How do two conjugate elements of a group have the same order?,"I'm reading group action in textbook Algebra by Saunders MacLane and Garrett Birkhoff. I have a problem of understanding the last sentence: Since conjugation is an automorphism, any two conjugate elements have the same order. Assume $x,y \in G$ are conjugate, then they are equivalent. As such, $gxg^{-1} = y$ for some $g \in G$ . This means $gx = yg$ . From here, I could not get how $x,y$ have the same order. Could you please elaborate on this point?","['group-theory', 'abstract-algebra']"
3741921,"(RESOLVED) Given $z = f (x, y)$ and $x = r \cos \theta $, $ y = r \sin \theta$ prove the following","Question: Let $z = f (x, y)$ and $x = r \cos \theta $ , $ y = r \sin \theta$ Show that $$\frac{\partial^2z}{\partial x^2} + \frac{\partial^2z}{\partial y^2} = \frac{\partial^2z}{\partial r^2} + \frac{1}{r^2} \frac{\partial^2z}{\partial \theta^2} + \frac{1}{r} \frac{\partial z}{\partial r} $$ My attempt is to show that LS=RS, but I am stuck on how to eliminate the $\frac{1}{r} \frac{\partial z}{\partial r} $ term . See below $$LS: \frac{\partial^2z}{\partial x^2} + \frac{\partial^2z}{\partial y^2}$$ For the RS, first find its given partial derivatives/expressions First term: $$===>\frac{\partial^2z}{\partial r^2} = \frac{\partial^2z}{\partial x^2}cos^2\theta + \frac{\partial^2z}{\partial y^2}sin^2\theta + 2(\frac{\partial^2z}{\partial x\partial y}sin\theta cos\theta)$$ This is the part where I get stuck $$ \frac{1}{r^2} \frac{\partial^2z}{\partial \theta^2}=\frac{1}{r^2}[\frac{\partial}{\partial \theta}(-\frac{\partial z}{\partial x}rsin\theta+\frac{\partial z}{\partial y}rcos\theta)]$$ Now treat $(-\frac{\partial z}{\partial x}rsin\theta+\frac{\partial z}{\partial y}rcos\theta)$ as a function of $z$ hence $(-\frac{\partial z}{\partial x}rsin\theta+\frac{\partial z}{\partial y}rcos\theta)$ can be seen as $\frac{\partial z}{\partial \theta}$ $$= \frac{1}{r^2}[\frac{\partial}{\partial x}(-\frac{\partial z}{\partial x}rsin\theta+\frac{\partial z}{\partial y}rcos\theta)\frac{\partial x}{\partial \theta} + \frac{\partial}{\partial y}(-\frac{\partial z}{\partial x}rsin\theta+\frac{\partial z}{\partial y}rcos\theta)\frac{\partial y}{\partial \theta}]$$ We know $\frac{\partial x}{\partial \theta} = -rsin\theta$ and $\frac{\partial y}{\partial \theta}=rcos\theta$ , so substitute them in $$= \frac{1}{r^2}[\frac{\partial}{\partial x}(-\frac{\partial z}{\partial x}rsin\theta+\frac{\partial z}{\partial y}rcos\theta)(-rsin\theta) + \frac{\partial}{\partial y}(-\frac{\partial z}{\partial x}rsin\theta+\frac{\partial z}{\partial y}rcos\theta)(rcos\theta)]$$ $$= \frac{1}{r^2}[(\frac{\partial ^2z}{\partial x^2}r^2sin^2\theta-\frac{\partial ^2z}{\partial x\partial y}r^2cos\theta sin\theta) + (-\frac{\partial ^2z}{\partial x\partial y}r^2cos\theta sin\theta+\frac{\partial ^2z}{\partial y^2}r^2cos^2\theta)]$$ Second term: $$===>\frac{1}{r^2} \frac{\partial^2z}{\partial \theta^2} = \frac{\partial ^2z}{\partial x^2}sin^2\theta-2(\frac{\partial ^2z}{\partial x\partial y}cos\theta sin\theta) +\frac{\partial ^2z}{\partial y^2}cos^2\theta$$ Now for the last term on the right side, Third term: $$===>\frac{1}{r} \frac{\partial z}{\partial r}= \frac{1}{r}[\frac{\partial z}{\partial x}cos\theta + \frac{\partial z}{\partial y}sin\theta]$$ Combining all terms of the right side, we have the following $$\frac{\partial^2z}{\partial x^2}cos^2\theta + \frac{\partial^2z}{\partial y^2}sin^2\theta + \frac{\partial^2z}{\partial x^2}sin^2\theta + \frac{\partial^2z}{\partial y^2}cos^2\theta + \frac{1}{r}[\frac{\partial z}{\partial x}cos\theta + \frac{\partial z}{\partial y}sin\theta]$$ $$===>RS: \frac{\partial^2z}{\partial x^2} + \frac{\partial^2z}{\partial y^2} + \frac{1}{r}[\frac{\partial z}{\partial x}cos\theta + \frac{\partial z}{\partial y}sin\theta]$$ which, $$≠LS=\frac{\partial^2z}{\partial x^2} + \frac{\partial^2z}{\partial y^2}$$ My QUESTION: There is supposed to be an extra term for the second term of the right side that cancels the third term, but I can't see it. Anyways, what did I do wrong? I believe my error is evaluating the second term of the right side, but it seems correct to me.","['multivariable-calculus', 'calculus']"
3741982,Can any continuous function be re-parameterized into a differentiable function?,"$|x|$ is not differentiable at zero. However, if we compose it with another function that ""eases up"" very gently to zero, for example, $x=t^3$ , we can obtain a function $|t^3|$ which is differentiable everywhere. I imagine this as ""stretching out"" $|x|$ to make it smooth. It seems like any continuous function could be turned in to a differentiable function by composing it with another function, that momentarily comes down to a derivative of 0 everywhere the continuous function is not differentiable. As I have posed it, this question has a trivial solution: $f\circ 0$ is always differentiable (even if $f$ is not continuous!). So, an additional requirement should be imposed, to fit the intuition of ""stretching $f$ ."" The function being composed should be monotonically increasing and should cover the entire domain of $f$ . Given a continuous $f(x)$ , can such a $g(t)$ always be found so that $f(g(t))$ is differentiable everywhere?","['continuity', 'calculus']"
3742016,Fréchet manifold structure on space of sections,"I know that the space $\mathsf{C}^\infty(M;N)$ of smooth maps from a closed (smooth) manifold $M$ to a (smooth) manifold $N$ is a Fréchet manifold. I have been looking for a more general version of this statement along the following lines: Let $p: E \to B$ be a smooth fiber bundle, where $E$ and $B$ are manifolds with corners (with some additional assumptions on $p:E \to B$ ?) . Then $\Gamma^\infty(B;E) := \{ s: B \to E \mid s $ smooth, $ p \circ s = \mathsf{id}_B \}$ is a Fréchet manifold (with corners?) but I can't seem to find a precise statement or proof of something like this anywhere. I've tried looking in ""A Convenient Setting for Global Analysis,"" but that book seems to work in a very large amount of generality that is a bit beyond what I would need. The only generalizations I am looking for are: instead of functions $f: M \to N$ , we consider sections $s: B \to E$ of a fiber bundle $p: E \to B$ , the manifolds in question can have boundary (or maybe even corners). Then the original result for $\mathsf{C}^\infty(M;N)$ would then be recovered by taking $M$ and $N$ without corners and considering the trivial bundle $M \times N \to M$ . I would really appreciate it if anyone could suggest a reference where a result like this is stated/proven, or if someone could explain how I could formulate/prove this (namely, what are the charts on $\Gamma^\infty(B;E)$ , what assumptions would we need on $p: E \to B$ , and do we need a notion of ""Fréchet manifold with corners""?). Thanks very much!","['fiber-bundles', 'manifolds-with-boundary', 'manifolds', 'global-analysis', 'differential-geometry']"
3742056,Infinitely many common prime divisors,"By Zsigmondy's theorem, there are infinitely many prime divisors of $2^{2^n}-1$ . That is, the set $$A=\{p \text{ is a prime}: p\mid 2^{2^n}-1 \text{ for some }n\in\Bbb{N}\}$$ is infinite. Also, as shown here Primes dividing a polynomial , for any given $f(x)\in\Bbb{Z}[x]$ , $$B_{f}=\{p \text{ is a prime}: p\mid f(n) \text{ for some }n\in\Bbb{N}\}$$ is also infinite. Can we show that $A\cap B_{f}$ is also an infinite set? Update: For two different polynomials, the common prime divisor set is indeed infinite, I found this result here . ( $B_{f}\cap B_{g}$ is a infinite set for any $f,g$ ) However, I cannot find any result concerning expression like $2^{2^n}-1$ . Update2: Maybe it's easier to consider $$A'=\{p \text{ is a prime}: p\mid 2^{n}+1 \text{ for some }n\in\Bbb{N}\}$$ and $A'\cap B_{f}$ ?","['number-theory', 'prime-factorization', 'elementary-number-theory', 'prime-numbers']"
3742098,Product of operator with its adjoint is self-adjoint,"Suppose $A$ is a densely defined closed operator. Show that $A^*A$ (with domain $D(A^*A)=\{\psi\in D(A)|A\psi\in D(A^*)\}$ ) is self-adjoint. Let $\psi\in D(A^*A)$ and observe that $A^*A$ is nonnegative: $$(\psi,A^*A\psi)=(A\psi,A\psi)=\|A\psi\|\ge0.$$ Then $A^*A$ is symmetric and $$(A^*A\psi,\psi)=(\psi,A^*A\psi)=((A^*A)^*\psi,\psi)$$ for all $\psi\in D(A^*A)\cap D((A^*A)^*)$ , implying $(A^*A)^*=A^*A$ in this domain. We must show that $D(A^*A)=D((A^*A)^*)$ . Recall the definition of the domain of the adjoint: $$D(B^*)=\{\psi\in\mathcal{H}|\exists\tilde\psi\in\mathcal{H}:(\psi,B\phi)=(\tilde\psi,\phi),\forall\phi\in D(B)\}.$$ Then for a symmetric operator, say $B$ , we have $D(B)\subset D(B^*)$ since $$(\psi,B\phi)=(B\psi,\phi)$$ for all $\phi\in D(B)$ . This gives us the forward inclusion since $A^*A$ is symmetric. How can the reverse inclusion be achieved?","['operator-theory', 'functional-analysis', 'self-adjoint-operators']"
3742193,How to prove that these two functions do not intersect?,"I have this function $\;g(x)-x\;$ on the domain $\;0<x<\frac{1}{3}\;$ , where $g(x)=\frac{\left(9 x^2+1\right) \cosh ^{-1}\left(\frac{36 x^2+\left(1-9 x^2\right)^2 \cosh (2 \pi  x)}{\left(9 x^2+1\right)^2}\right) \sqrt{81 x^4+54 x^2+\left(1-9 x^2\right)^2 \cosh (2 \pi  x)+1}}{2 \sqrt{2} \pi  \cosh (\pi  x)}+\frac{18 \sqrt{2} x^2 \left(9 \pi  x^3+4 \tanh (\pi  x)\right)}{2 \sqrt{2} \pi }.$ I need to prove that $\;g(x)\;$ does not intersect $\;x\;$ over the mentioned domain. Calculating the first derivative does not work since it makes the problem more complicated. The plot of the functions is attached. Any hint or suggestion is welcome.","['functions', 'solution-verification']"
3742199,Geometric interpretation of $\dfrac{dg(t)}{dt}$,"In Riemannian geometry for some reasons we consider a variation of metric then we compute its time-depending derivative. I want to know why we do this? Is it similar to finding the critical points? If so what is the definition and intuition of critical points here? Update(29-03-2021) For example sometimes in the easiest case, we consider first-order deformation $$g_t=g+th,$$ for some symmetric tensor $h$ .
Is in this case $\dfrac{dg_t}{dt}|_{t=0}=h$ ? If so what is the point of considering $g_t$ , instead we can work with $h$ ? more generally if we consider $$g_t=g+th+t^2k+\cdots ,$$ then I think the result is same as above. i.e. $\dfrac{dg_t}{dt}|_{t=0}=h$ . Am I right? Also I forgot from calculus that why we evaluate it at $t=0$ after taking derivative?","['differential-topology', 'riemannian-geometry', 'differential-geometry']"
3742242,Calculate gradient in polar coordinates using exterior derivative,"I'm teaching myself some basics of differential form, and stumbled over the calculation of gradient in polar coordinates. The book I'm reading is Fortney's A Visual Introduction to Differential Forms and Calculus on Manifolds , which talks little about gradient in non-Cartesian coordinates, so I turned to wikipedia. According to the wikipedia of exterior derivative : $$\nabla f = (df)^\sharp = \frac{\partial f}{\partial x^i}\, (dx^i)^\sharp$$ This formula involves $\sharp$ . According to the wikipedia of musical isomorphism : $$\omega^\sharp := g^{ij} \omega_i \mathbf{e}_j = \omega^j \mathbf{e}_j$$ This formula involves inverse metric tensor $g^{ij}$ (inverse matrix to metric tensor $g_{ij}$ ). According to wikipedia of metric tensor , the metric tensor in polar coordinates is: $$g_{ij} = \begin{bmatrix}
    1 & 0 \\
    0 & r^2
  \end{bmatrix}$$ Combining all these, the gradient of $f(r,\theta)$ in polar coordinates seems to be $$
\nabla f(r, \theta) = \frac{\partial f}{\partial r}\mathbf{e}_r + \frac{1}{r^\color{red}{2}}\frac{\partial f}{\partial \theta}\mathbf{e}_\theta$$ which is different from the gradient in polar coordinates we usually refer to, if not wrong. What am I missing here? How can I calculate the usual gradient in polar coordinates using exterior derivative as the tool? Clarification Post shown by Si Kucing in the comment helps, but I think my question is a bit different. Specifically speaking, I'm also interested in the standard way to obtain the usual gradient, but it's not explained in detail in that post. It's not immediately clear to me why ""the norm of $\frac{∂}{∂θ}$ is $r$ "". Look forward to answer(s) elaborating on this part.","['exterior-derivative', 'differential-geometry', 'vector-analysis', 'differential-forms', 'exterior-algebra']"
3742299,Simple module over $ֿ\mathbb{Z}G$ has a $\mathbb{Z}N$ composition series when $N \triangleleft G$ is nilpotent and of finite-index,"Assume that $M$ is a simple $\mathbb{Z}G$ module with $G$ finitely-generated, virtually nilpotent group. Take $N\leq G$ to be a normal, finite index, nilpotent subgroup. The claim is that $M$ has a finite-length composition series as a $\mathbb{Z}N$ -module. How can I see this? One approach I've tried: I know that a module has a finite-length composition series if and only if the module is both Artinian and Noetherian. Now in fact I can prove (with some ""heavier"" theorems) that $M$ is Noetherian in this case (this follows because $N$ is also finitely generated, and nilpotent, hence polycyclic, in essence). But, this approach doesn't use the fact the $M$ is simple as a $\mathbb{Z}G$ -module and moreoever I can't prove the descending-chain-condition anyways.","['modules', 'finitely-generated', 'ring-theory', 'abstract-algebra', 'group-theory']"
3742308,It is true that this integral converges to $0$?,"Let $\Omega$ be an open bounded subset of $\mathbb{R}^n$ and let $ p\geq 1$ . Let $(u_n)_n$ be a bounded sequence of $W_0^{1, p}(\Omega)$ and let $\Omega_n\subset\Omega$ be a subset of $\Omega$ which depends only 0n $n$ and such that $$meas(\Omega_{n})\longrightarrow 0 \quad \mbox{ as } n\to +\infty.$$ Could I conclude that $$\int_{\Omega_{n}} \vert\nabla u_n\vert^{p} dx\longrightarrow 0 \quad \mbox{ as } n\to +\infty?$$ If not, what additional assumptions I need? Could anyone please help? Thank you in advance!","['sobolev-spaces', 'functional-analysis', 'real-analysis']"
