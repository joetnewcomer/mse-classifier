question_id,title,body,tags
702104,Equivalent definitions of Compact Sets?,"Usually, compact sets are defined by each open cover of the set having a finite subcover. My professor gave us a bizarre definition: A set X is said to be compact if each infinite subset has an accumulation point in X. I am struggling to understand why these two definitions are equivalent. I have to use the latter throughout the course, so I thought it would be nice to at least understand why it's a valid definition. Help would be appreciated :) All our sets exist in the plane.","['general-topology', 'compactness']"
702111,Integral $=\int_0^\infty x^{\alpha -1}Li_n (-\sigma x) Li_m(-\omega x^r)dx$.,"I am trying to calculate an integral that can be expressed in terms of infinite hypergeometric series by using transforms and Residue method, the integral is 
$$
I_{n,m}(\alpha,\sigma,\omega,r)=\int_0^\infty x^{\alpha -1}Li_n (-\sigma x) Li_m(-\omega x^r)dx
$$
where n,m are positive integers.  The complex parameters are $\alpha,\sigma,\omega$ and real $r\neq 0$ are defined so that the integral exists.  This is an integral containing polyLogs so we define the Polylogarithm function for $|z|\leq 1$ and $n\geq 2$ by a power series expression of the form
$$
Li_n(z)=\sum_{j=1}^\infty \frac{z^j}{j^n}, \ (|z| \leq 1).
$$
For $|z| > 1$ we obtain
$$
Li_n(z)=(-1)^{n+1}Li_n(z^{-1})-\frac{1}{n!}\ln^n(-z)-\sum_{j=0}^{n-2}\frac{1}{j!}(1+(-1)^{n-j})(1-2^{1-n+j})\zeta(n-j)\ln^j(-z)
$$
where the Riemann Zeta function is given by $\zeta(n-j)$ and the logarithm is defined on the principle sheet. I was thinking of also using an integral representation of the polyLogs which are given by
$$
Li_n(-z)=\frac{1}{2\pi i}\int_{\gamma -i\infty}^{\gamma+i\infty} \frac{\Gamma(s)\Gamma(-s)}{(-s)^{n-1}} z^{-s} ds, \ (-1<\gamma <0, |\arg z| < \pi, \ n=0,1,2,...)
$$
and inserting into this $I_{n,m}$...Any ideas on what do, I need a complete solution.  Thanks.","['special-functions', 'integration', 'definite-integrals', 'analysis', 'contour-integration']"
702121,M/M/3 queue - reducing wait time by adding servers,"Full question below: You are the manager of the customer support division in your company. Your
division uses 3 telephone lines operated by 3 separate customer service representatives. A
customer is put on hold if their call arrives while all 3 customer service representatives are
busy serving other customers. You observe that customer calls arrive at a Poisson rate of 5
per hour, and that the length of the customer calls is exponentially distributed. You also
observe that 75% of the time, a customer is not put on hold, while the remaining 25% of
the time, a customer can expected to be put on hold for an average of 12 minutes. You wish
to improve service in the division by making sure that 90% of the time, a customer is not
put on hold, while 10% of the time, a customer can expect to be put on hold for an average
of only 4 minutes. How many telephone lines will you add to your division to achieve your
goal? So I think the biggest problem here is that I don't know $\mu$.  I do know $\rho=\frac{\lambda}{c\mu}=\frac{5}{3\mu}$ for this problem.  I understand that ""time on hold"" refers to to time waiting in the queue.  With $W$ is time waiting in the queue, I know:
$$E[W]=\frac{\rho}{\lambda(1-\rho)}P(W>0)$$ With 3 operators, I used the fact that ""75% of the time, a customer is not put on hold, while the remaining 25% of
the time, a customer can expected to be put on hold for an average of 12 minutes"" to calculate:
$$E[W]=.75(0) + .25(12min)=3min$$
Then using $E[W]$ along with $P(W>0)=.25$, I solved the first equation to find $\mu=\frac{10}{3}$. Knowing $u$, I used ""90% of the time, a customer is not
put on hold, while 10% of the time, a customer can expect to be put on hold for an average
of only 4 minutes"" to find the new $E[W]=1min$ and $P(W>0)=.1$. To solve for $c$(number of servers) I again plugged these numbers into the original equation for $E[W]$ and found $c=3.3$. You can obviously only have an integer number of servers, so this would be $c=4$, and minus the original 3 would give the addition of just 1 server as the answer. Sorry for the long question, but am I doing this right?  I feel like I messed up along the way or made some wrong assumptions (mostly that $E[W] can be calculated from the information in the problem). Thanks for looking.","['queueing-theory', 'probability']"
702136,"Given $N$ coins, find a coin with minimal bias based on $N$ samples","General description: Given $N$ coins $Z_1,...,Z_N$ (Bernoulli RVs), where the $i$-th coin has probability $p_i$ for ""Head"", I'm trying to find  $\min\limits _{i\in[N]}p_{i}$. I'm interested in a ""probably accurate"" estimation:
Given $\epsilon,\delta \in (0,1)$, my guess $\hat{i}$ has to hold: $\mathbb{P}(p_{\hat{i}}\leq \min\limits _{i\in[N]}p_{i} + \epsilon)\geq 1-\delta$ The parameter I'm trying to minimize here is $m$, the number of samples needed of each coin in order to comply with the probabilistic condition defined with  $\epsilon$ and $ \delta$. My objective: I must give an algorithm (or general method) which will need at most $m=\left\lceil \frac{1}{\epsilon^{2}}\cdot\frac{N}{\delta}\right\rceil $ samples. My try: The straightforward method is as follows: Given samples $\left(\left(z_{1}^{i},...,z_{m}^{i}\right)\right)_{i=1}^{N}$, compute $\hat{p}_{i}=\frac{1}{m}\sum\limits _{j=1}^{m}z_{j}^{i}$ for all $i \in [N]$ return $\hat{i}$ s.t. $\hat{p}_{\hat{i}}=\min\limits _{i\in [N]}\hat{p}_{i}$ The tricky part is to prove the bound on $m$. This is supposed to be rather simple, using basic tools such as Chebyshev's inequality or the union bound, but I threw everything I could think of at it without success. One of my tries was: if for all $i\in [N]$ it holds that $|\hat{p_i}-p_i|<\epsilon$, then the $\hat{i}$ we'll return is indeed $\epsilon$-close to  $\min\limits _{i\in[N]}p_{i}$, but using Chebyshev's inequality to compute that I get a much smaller probability than $1-\delta$ . Help will be very appreciated.","['statistics', 'probability', 'machine-learning']"
702168,Proof of Wirtinger inequality,"Quoting from Ana Cannas da Silva's book on Symplectic Geometry:
""As an exercise in Fourier series, show the Wirtinger inequality: for $f\in C^1([a,b])$, with $f(a)=f(b)=0$ we have
$$
\int_a^b\Big|\frac{\mathrm{d}f}{\mathrm{d}t}\Big|^2\mathrm{d}t \ge\frac{\pi^2}{(b-a)^2} \int_a^b\left|\ f\right|^2\mathrm{d}t.""
$$
I already found a few questions about this topic in the site, but I couldn't actually grasp what's happening here. Also, I would very much like you to show me where I go wrong with my try, which is sketched below. I know that, for $f\in \mathcal{L}^2([0,2\pi])\supset C^1([0,2\pi])$, I can expand:
$$
f(t)=\sum_{n=-\infty}^{+\infty}c_n e^{int},\ \ \ c_n=\frac{1}{2\pi}\int_0^{2\pi}\mathrm{d}t\ e^{-int}f(t).
$$
Rescaling  $t \to \omega (t - a)$, where $\omega = 2\pi/(b-a)$, we can get a more general form for $f\in C([a,b])$:
$$
f(t)=\sum_{n=-\infty}^{+\infty}c_n e^{in\omega t},\ \ \ c_n=\frac{1}{b-a}\int_a^{b}\mathrm{d}t\ e^{-in\omega t}f(t).
$$
Now, having:
$$
\frac{\mathrm{d}}{\mathrm{d}t}f(t) = \sum_{n=-\infty}^{+\infty}\tilde{c}_ne^{i\omega nt},\ \ \tilde{c}_n=\frac{1}{b-a}\int_a^b\mathrm{d}t\ e^{-i\omega nt}\frac{\mathrm{d}}{\mathrm{d}t}f(t).
$$
Using the fact that $\,f(a)=f(b)=0$ we get:
$$
\tilde{c}_0 = \frac{1}{b-a}\int_a^b\mathrm{d}t \frac{\mathrm{d}}{\mathrm{d}t}
f(t) = \frac{f(b)-f(a)}{b-a} =0 \longrightarrow 
\frac{\mathrm{d}}{\mathrm{d}t}f(t) = 
\sum_{n\in\mathbb Z\setminus\{0\}}\tilde{c}_n e^{i\omega nt}
$$
Now deriving the series expansion of $f$ yields:
$$
\frac{\mathrm{d}}{\mathrm{d}t}f(t) = \frac{\mathrm{d}}{\mathrm{d}t} \sum_{n=-\infty}^{+\infty}c_n e^{in\omega t} = \sum_{n=-\infty}^{+\infty}(in\omega)c_n e^{in\omega t}=\sum_{n\in\mathbb Z\setminus\{0\}}(in\omega)c_n e^{in\omega t}
$$
Comparing the two expressions we establish: $\tilde{c}_n = i\omega n c_n$, for $n\not= 0$. Parseval's Equality reads here for $\mathrm{d}f/\mathrm{d}t$:
$$
\int_a^b\left|\frac{\mathrm{d}f}{\mathrm{d}t}\right|^2\mathrm{d}t=
\sum_{n\in\mathbb Z\setminus\{0\}}  |\tilde{c_n}|^2 = 
\omega^2\sum_{n\in\mathbb Z\setminus\{0\}} n^2 |c_n|^2 \ge
\omega^2\sum_{n\in\mathbb Z\setminus\{0\}}  |c_n|^2 = 
\omega^2 \left(\int_a^b\mathrm{d}t\left|f(t)\right|^2-|c_0|^2\right)
$$
where in the last passage we used Parseval's Equality for $f$: $\int_a^b|f|^2\mathrm{d}t=\sum_{n=-\infty}^{+\infty}|c_n|^2$. We are now left with finding a suitable way of estimating $|c_0|^2$:
$$
|c_0|^2 = \left|\frac{1}{b-a}\int_a^b\mathrm{d}t\ f(t)\right|^2,
$$ thus
$$
\int_a^b\left|\frac{\mathrm{d}f}{\mathrm{d}t}\right|^2\mathrm{d}t \ge \frac{4\pi^2}{(b-a)^2}\left(\int_a^b\left|f\right|^2\mathrm{d}t - \frac{1}{(b-a)^2}\left|\int_a^bf\mathrm{d}t\right|^2\right).
$$
Which is not exactly what I wanted. Please lend me a hand!","['fourier-series', 'inequality', 'calculus', 'integration', 'integral-inequality']"
702170,Transition time in a Lotka-Volterra system,"I am working with a set of real-valued ordinary differential equations based on the Lotka-Volterra competition equations : $$\begin{align}
\dot{a_1} & = a_1 \left( 1 - a_1 - 2 a_2 \right) \\
\dot{a_2} & = a_2 \left( 1 - a_2 - (1-1/\nu) a_1 \right)
\end{align}$$ where $a_{1,2} \in [0,1]$ and $\nu \ge 1$. I would like to obtain a closed form (or analytical) solution for the time, $\tau$, it takes for this system to transit between two regions in state space. Specifically, I would like to solve for $\tau$ given $a_1(0) = \delta$ and $a_2(\tau) = \delta$, where $1/2 \lt \delta \lt 1$. This is along the manifold between two fixed points: the unstable manifold of a saddle at $(a_1,a_2) = (1,0)$ and a stable equilibrium at $(a_1,a_2) = (0,1)$. There is a solution for $\nu = 1$ ($\tau = -2 \text{ln}(1/\delta-1)$), but I have been unable to find a solution for the more general case in terms of $\nu$ (or even for any particular value of $\nu \gt 1$, including the limiting case of $\nu \rightarrow \infty$). This paper seems to imply that the equations above are not fully integrable except when $\nu = 1$ (see Eq. 25'), i.e, when the second equation is not a function of $a_1$. However, I'm not actually interested in solving this system for all time over the full state space. Question: Are there any methods to solve or obtain a reliable approximation for $\tau = f(\nu, \delta)$ for this system just within my region of interest? Attempts: In addition to paper and pencil, I have used Matlab's dsolve and Mathematica's DSolve along with assumptions to try to solve the ODEs for the specified boundary conditions. I was unable solve the system using these, but might there be ways to transform or break up the system that would facilitate a solution? I have tried using low-order power series, e.g., this paper , about each of the equilibria to obtain functions of time that are then inverted to solve for $\tau$. This was far from accurate as only a few series terms can be used. I have tried schemes based on simulating the ODE and fitting the transit times to a function of $\nu$. This requires finding initial conditions that lie on the manifold. How can that be done reliably as a function of $\nu$ and $\delta$? And can fitting methods be adapted to more general forms of the equation above (i.e., reusing the same fitting coefficients and without fitting high dimensional surfaces)? I am more interested in non-fitting-based solutions, but if you can demonstrate something that works well, I would be happy to look at it. Update 1 – Mar. 17, 2014 : The nullclines of the system and the Jacobian determinant (related to curvature) can be used to obtain estimated initial and final conditions. Solving for the roots of $\det(J)=0$ as a function of $a_1$ and scaling appropriately, one obtains $$ a_2(t) = \tfrac{1}{2} \left( 2 - a_1(t) - \sqrt{a_1(t) \left( \tfrac{2}{\nu} \left( a_1(t)-1 \right) + 2 - a_1(t) \right)} \right)$$ For $a_1(0) = 1-\delta$, this expression appears to provide a good approximation for $a_2(0)$ on the stable manifold (attracting contour) in question. It is less reliable for obtaining an estimate for $a_1(\tau)$. Perhaps this is due to the Jacobian evaluated at $(a_1,a_2) = (0,1)$ being a defective matrix with only one eigenvector. Update 2 – Mar. 25, 2014 – (post bounty): The equation from @JJacquelin's answer immediately after the transformation to polar coordinates can be simplified and integrated definitely (I used Mathematica 9) with respect to the bounds at times $0$ and $\tau$: $$\begin{align}
\int_0^\tau{dt} & = \int_{\theta_0}^{\theta_{\tau}}{\frac{\sin^3\theta + \cos^3\theta + \left(2\cos\theta + \left(1-\tfrac{1}{\nu}\right)\sin\theta\right)\sin\theta\cos\theta}{\left(\tfrac{1}{\nu} \cos \theta + \sin \theta\right)\sin\theta\cos \theta}d\theta} + \int_{\rho_0}^{\rho_{\tau}}{\frac{1}{\rho}d\rho} \\
\tau & = \int_{\theta_0}^{\theta_{\tau}}{\frac{1-\tfrac{1}{\nu}+\left(2+\cot\theta\right)\cot\theta+\tan\theta}{1+\tfrac{1}{\nu}\cot\theta}d\theta} + \ln\left(\frac{\rho_{\tau}}{\rho_0}\right) \\
& = \frac{\nu^2}{1+\nu^2}\left(\ln\left(\frac{\cos(\theta_0)}{\cos(\theta_{\tau})}\right) +2\ln\left(\frac{\cos\theta_{\tau}+\nu\sin\theta_{\tau}}{cos\theta_0+\nu\sin\theta_0}\right)+\frac{1}{\nu^2}\ln\left(\frac{\cos\theta_{\tau}\left(1+\nu\tan\theta_{\tau}\right)^2}{\cos\theta_0\left(1+\nu\tan\theta_0\right)^2}\right)\right) + \nu\ln\left(\frac{\nu+\cot\theta_0}{\nu+\cot\theta_{\tau}}\right) + \ln\left(\frac{\rho_{\tau}}{\rho_0}\right)
\end{align}$$ Transforming back from polar to Cartesian coordinates further simplifies the expression: $$\tau = \ln\left(\frac{a_1(0)}{a_1(\tau)}\right) + 2\ln\left(\frac{a_1(\tau)+\nu a_2(\tau)}{a_1(0)+\nu a_2(0)}\right) + \nu\ln\left(\frac{a_2(\tau)\left(a_1(0)+\nu a_2(0)\right)}{a_2(0)\left(a_1(\tau)+\nu a_2(\tau)\right)}\right)$$ Here is some ""simple"" Matlab code that demonstrates this. Also in the code is an ODE-based method that uses ode45 's event detection . This accurately finds the time $\tau$ by integrating along the manifold in question and terminating when the solution satisfies a condition. It's simple and fast for this basic case. However, recall that this system is a simplified version of a more general one in which the time scaling of the vector field can vary and even be different in each of the two dimensions. This could lead to long integration times if the scaling cannot be factored. I'm hoping that the analytical solution given here can be generalized. The analytic solution-based part of my Matlab code underestimates $\tau$ (except for $\nu$ close to $1$ when it slightly overestimates it). The source of almost all of the error is due to the estimate of $a_1(\tau)$ ( af1 in the code). Something else I'm looking into.","['dynamical-systems', 'closed-form', 'ordinary-differential-equations', 'systems-of-equations']"
702185,Definition of the nth derivative? [First post],"If the definition of the derivative is 
$$
f^\prime(x) = \lim_{\Delta x \to 0} \dfrac{f(x+\Delta x) - f(x)}{\Delta x}
$$
Would it make sense that the nth derivative would be (I know that the 'n' in delta x to the nth power is useless) 
$$
f^{(n)}(x)=\lim_{\Delta x \to 0} \sum_{k=0}^{n}(-1)^k{n \choose k}\dfrac{f(x+\Delta x(n-k))}{\Delta x^n}
$$
I came to this conclusion using this method
$$
f^\prime(x) = \lim_{\Delta x \to 0} \dfrac{f(x+\Delta x) - f(x)}{\Delta x}
$$
(this is correct right?)
$$
f^{\prime\prime}(x) = \lim_{\Delta x \to 0} \dfrac{f^\prime(x+\Delta x) - f^\prime(x)}{\Delta x}=$$ $$\lim_{\Delta x \to 0}\dfrac{\dfrac{f((x+\Delta x)+\Delta x)-f(x+\Delta x)}{\Delta x}-\dfrac{f(x+\Delta x)-f(x)}{\Delta x}}{\Delta x}=$$ $$\lim_{\Delta x \to 0}\dfrac{f(x+2\Delta x)-2f(x+\Delta x)+f(x)}{\Delta x^2}
$$
After following this method a couple of times(I think I used it to the 5th derivative) I
noticed the pattern of
$$(a-b)^n$$
And that is how i arrived at 
$$
f^{(n)}(x)=\lim_{\Delta x \to 0} \sum_{k=0}^{n}(-1)^k{n \choose k}\dfrac{f(x+\Delta x(n-k))}{\Delta x^n}
$$
Have I made a fatal error somewhere or does this definition actually follow through? Thanks for your time I really appreciate it. P.S. Any input on using tags will be appreciated.","['definition', 'derivatives', 'limits']"
702186,Prove that the intersection of two subgroups is a subgroup.,"In more detail, if  $G$  is a group and $H_1$, $H_2$   are subgroups of G   then $H_1 \cap H_2$   is a subgroup of  G.
Next, give an example of a particular group $G$  (any one you like), and two different subgroups  $H_1$, $H_2$ of $G$  , compute the intersection $H_1 \cap H_2$  , and verify it is indeed a subgroup. Finally, give three examples showing that $H_1 \cup H_2$   need not be a subgroup of $G$ .","['group-theory', 'abstract-algebra']"
702191,"Is there a symbol for ""dependent""?","For random variables $A$ and $B$ , $A \perp B$ is sometimes used to denote ""A is independent of B"".  Is there a symbol that is commonly used to mean ""A is not independent of B""?","['notation', 'probability']"
702199,$\ell^{\infty}(\mathbb N)$ is not a separable space,"I have to prove that $\ell^{\infty}(\mathbb N)$ is not separable. My attempt Consider a SUBSET $V$ of $\ell^{\infty}(\mathbb N)$ consisting of bounded sequences that have only $0$, $1$ entries, e.g. $(0,1,1,0,0,0,0,1,0,0,\dots)$ Now assume that this SUBSET is uncountable. If we take a radius $r=1/4$ then balls with origins that are elements of $V$ would be disjoint and because any base of  $\ell^{\infty}(\mathbb N)$ must contain a subset of each element of the set of these balls, base of  $\ell^{\infty}(\mathbb N)$ can't be countable so it doesnt satisfy the second axiom fo countability and thus is not separable (since  $\ell^{\infty}(\mathbb N)$ is a metric space). Could someone check this? And I still need to prove that $V$ is uncountable...","['separable-spaces', 'general-topology', 'lp-spaces', 'metric-spaces', 'functional-analysis']"
702211,Degree of a polynomial,"If I have a polynomial, for example, $$ x^8 + x^2 + \dfrac{1}{x} $$ would this be considered to be of degree 8? I am working on a question involving the function $ \frac{1}{x} $ and I am wondering how this term affects the degree of the entire polynomial, if at all.","['algebra-precalculus', 'polynomials']"
702217,Geodesic equations and christoffel symbols,I want to learn explicitly proof of the proposition 9.2.3. Which books or lecture notes I can find? Please give me a suggestion. Thank you:),"['geometry', 'differential-geometry', 'self-learning', 'reference-request', 'proof-writing']"
702225,Proof of Castalnuovo's rationality criterion,"Let $S$ be a complex projective smooth surface.
If $D$ is a divisor on $S$, let's write $h^i(D)$ for $dim H^i(S,\mathcal{O}_S(D))$, where $\mathcal{O}_S(D)$ is the invertible sheaf associated to $D$. Let's denote with $K$ a canonical divisor, so $K$ is such that $\mathcal{O}_S(K)=\Omega^2_S$. I want to prove Castelnuovo's rationality criterion, so let $S$ be a surface such that $q(S)=P_2(S)=0$. I've already proved that with this assumption, there is on $S$ a smooth rational curve $C$ such that $C^2\geq 0$. From this using Riemann-Roch and the genus formula, i get $\chi(\mathcal{O}_S(C ))\geq 2$. Now i want to show that $h^0(C )\geq 2$. To do this it suffices to show that $h^2( C)=0$. My question is: is it correct to say that $h^2( C)=h^0(K-C)\leq h^0(K)$?","['birational-geometry', 'algebraic-geometry', 'surfaces']"
702254,Weierstrass Approximation Theorem for $\Bbb C$,"The Weierstrass approximation theorem states that any continuous function $ f : I \rightarrow \Bbb R $ on a closed, bounded, connected subset $ I \subseteq \Bbb R $ can be uniformly approximated by polynomials. Can any continuous function $ \phi : J \rightarrow \Bbb C $ on a closed, bounded, connected subset $ J \subseteq \Bbb C $ be uniformly approximated by polynomials? What I mean is, for which subsets $ J \subseteq \Bbb C $ can all functions be approximated uniformly by polynomials. This question is an example sheet question that I had (already supervised on $-$ non-examinable) but supervisor wasn't sure what the question meant exactly. There are some basic sets, such as closed, real intervals, that it clearly holds for, but others (such as closed unit ball) that it does not hold for. Is anyone able to shed any light on the answer. (Not just a few counter-examples, but some explanation as to why it does / does not hold on certain set (eg, because connected complement / similar).) Thanks very much!","['approximation', 'complex-analysis']"
702260,Is $\sqrt{1+x^2}$ matrix monotone?,"A function $f(x)$ is matrix monotone if $f(A)-f(B)$ is positive semidefinite whenever $A-B$ is positive semidefinite for positive semidefinite matrices $A, B$. Is $\sqrt{1+x^2}$ matrix monotone?","['matrices', 'linear-algebra']"
702318,A Parseval-like theorem for Mellin transforms,"A particular case of Parseval's theorem for Fourier transforms says that if $f$ is square integrable on $\mathbb{R}$, then $$ \int_{-\infty}^{\infty} |f(t)|^{2} \ dt = \int_{-\infty}^{\infty} |\hat{f} (\omega)|^{2} d \ \omega .$$ I recall coming across a similar theorem for Mellin transforms that states under certain conditions, $$ \int_{0}^{\infty} \frac{|f(x)|^{2}}{x} \ dx = \frac{1}{2 \pi}\int_{-\infty}^{\infty} |F(it)|^{2} \ d t$$ where $F(s)$ is the Mellin transform of $f(t)$. Using this theorem we can evaluate an integral like $ \displaystyle \int_{-\infty}^{\infty} \Gamma(a+it) \Gamma(a-it) \ dt$ fairly easily. But I can't find much information about this theorem on the internet. Is this somehow just a corollary of the other theorem?","['fourier-analysis', 'integration', 'integral-transforms']"
702340,What happens if I toss a coin with decreasing probability to get a head?,"Yesterday night, while I was trying to sleep, I found myself stuck with a simple statistics problem. Let's imagine we have a ""magical coin"", which is completely identical to a normal coin but for a thing: every time you toss the coin, the probability to get a head halves. So at t = 1 we have 50:50, then 25:75, then 12.5:87.5 and so on. At t = ∞ we are going to have 0:100. My question is: if I toss this magical coin infinite times, can I say I am sure I am going to get at least one head? On one hand, I thought, the law of large numbers states that if an event is repeated infinite times, every state that is possible is bound to happen. On the other side, however, at t = ∞ the probability to get a head is zero. Surely the solution of the problem is fairly easy, so what am I doing wrong?","['statistics', 'law-of-large-numbers', 'infinity', 'probability']"
702347,Constant Speed of Geodesics,"Let V be the set of smooth functions $ f : [0,1] \rightarrow \Bbb R $ such that $ \int_0^1 f(t) dt = k $. If $ F : V \rightarrow \Bbb R $ is given by $ F(f) = \int_0^1 f(t)^2 dt $, then show that the only critical point of F is the constant function $ f(t) = k$. Deduce that geodesics have constant speed. This looks like it should be pretty straight forward, but I can't manage it. I someone able to give me a (fairly sizeable!) hint, but not just a full solution. (If I still can't get it after a hint, then I may ask for a full solution!) (I can show that $ f(t) = k $ is a critical point, but not that it is the only critical point.) Thanks in advance! :)","['calculus-of-variations', 'differential-geometry', 'geodesic']"
702350,Can any function be parametrised? [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 10 years ago . Improve this question I'm going over surface integrals for my Calc 2 exam in May and the questions rely heavily on parametrization. Can it be proven that any function $\mathbb{R^n}\rightarrow \mathbb{R^m}$ (more specifically focusing on the case $m=1$) can be written as a parametrization and changed into a function $\mathbb{R}\rightarrow\mathbb{R}$? Also any tips or hints on trying to find the parametrization would really help, on the more difficult questions I sometimes struggle to find a suitable one. Thanks",['multivariable-calculus']
702384,Suppose $G$ is a group of order 4. Show either $G$ is cyclic or $x^2=e$.,"I've figured out that if I know $G$ is not cyclic, then it for any $a \in G, o(a) \neq 4$ (or the order of any element in group $G$ is not 4). I know ahead of time that the elements in the group ($\forall x \in G$) must have order $o(x)=k$ where $0 < k \leq 4$ where $k \in \mathbb{Z}$, so $k = 1, 2, 3, 4$. If $G$ not cyclic, then we know $k \neq 4$ so we have $k = 1, 2, 3$ left. I know how to show that $k \neq 3$ but I am not sure if I am supposed to do it for all possible $k$ because obviously if our order was higher (let's say $n$) then it would get messy. It ends up being in this case that $k = 2$ is good and $k = 1$ is trivial. I have looked up online and it says using Lagrange's Thm we know it has to be $k = 1, 2$ since $3 \nmid 4$, but I cannot use that theorem as we have not have learned it in class. How can I show that $k = 1$ or $2$ in another way? However working from using the result that if we have $x \in G$ and $H = \langle a \rangle$ and knowing that $\left\vert{H}\right\vert=1$ or $2$, then $x^2=1$ for either case. Then I am done right? What is another, cleaner, better way of trying to answer the question in the title? I apologize if my formatting is poor since I am new at LaTeX and extraordinarily bad at algebra it seems. Thank you in advance.","['cyclic-groups', 'group-theory', 'abstract-algebra']"
702390,Measure preserving transform and convergent random variables,"I have been trying to learn about Ergodic Theorem for a while and now I have a problem I can't solve. Assume $T$ is a measure preserving transform and $X_n\rightarrow X$ everywhere. Also, assume that $E(\sup_n |X_n|)<\infty$. Then I need to show $\lim_{n\rightarrow\infty}\frac{1}{n}\sum_{k=0}^{n-1}{X_k(T^k(\omega))}$ converges with probability 1. It's easy to show $X$ is integrable, so I was trying to use ergodic theorem (Birkhoff's theorem) to prove this but I couldn't get better results. Any suggestion is really appreciated.","['probability-theory', 'ergodic-theory']"
702391,Probability Question I can't get around.,"This is the question from my assignment, which I can't get around. Suppose that a water distribution system is composed of a number of independent 
pipes. At temperatures below 0 deg C, the pipes may burst; on such occasions the 
probability that one pipe will catastrophically burst is 0.05. Assume that the failure 
(catastrophic bursting) of two or more pipes at the same time is unlikely. If the 
distribution system must be shut down when 3 of the pipes have failed, determine the 
probability that the distribution system can withstand at least 5 below 0 deg C events 
before a shut down occurs. How do you do this question without knowing number of pipes ? I understand how it is possible if one knows the number of pipe. But how do you do it if number of pipes are not given ?","['statistics', 'probability-theory', 'probability-distributions', 'probability', 'combinatorics']"
702403,Prove that $a \equiv b \pmod{m_1m_2}\implies a \equiv b \pmod {m_1}$,"So, I have this problem: if $$a \equiv b \mod(m_1m_2)$$ then (show) $$a \equiv b \mod(m_1)$$. I have to do a proof, but I have no idea where to begin the proof. Can someone help? Proof (Edit): We know $a\equiv b \mod(m_1m_2)$, and $m_1$ and $m_2$ are positive integers and a and b are integers. We want to show $a≡b \mod(m_1)$ Consider a positive integer $n$, and integers $x$,$y$. By the definition of congruence, $x \equiv y \mod(n)$ means $n \mid x-y$.  Since $n$, $x$, and $y$ $\in \mathbb{Z}$, then by the definition of divides  $n \mid x-y$ becomes $\exists_c(nc=x-y)$ for some integer $c$. Applying this definition: Suppose $a \equiv b \mod(m_1m_2)$; this expression becomes $m_1m_2|a-b$ by the definition of congruence. Then, since $m_1, m_2, a, b \in \mathbb{Z}$ then: $\exists_c(m_1m_2c = a-b)$ for some integer $c$. Now, let $c$ be $m_2c$. Thus, $m_1(m_2c) = a-b$, and since $(m_2c)$ is an integer, this proves that $m_1 \mid a-b$ that is, $a \equiv b \mod(m_1)$ Q.E.D.","['congruences', 'discrete-mathematics', 'proof-writing']"
702414,What Is Exponentiation?,"Is there an intuitive definition of exponentiation? In elementary school, we learned that $$
a^b = a \cdot a \cdot a \cdot a \cdots (b\ \textrm{ times})
$$
where $b$ is an integer. Then later on this was expanded to include rational exponents, so that $$
a^{\frac{b}{c}} = \sqrt[c]{a^b}
$$ From there we could evaluate decimal exponents like $4^{3.24}$ by first converting to a fraction. However, even after learning Euler's Identity, I feel as though there is no discussion on what exponentiation really means . The definitions I found are either overly simplistic or unhelpfully complex. Once we stray from the land of rational powers into real powers in general, is there an intuitive definition or explanation of exponentiation? I am thinking along the lines of, for example, $2^\pi$ or $3^{\sqrt2}$ (or any other irrational power, really). What does this mean? Or, is there no real-world relationship? To draw a parallel to multiplication: If we consider the expression $e\cdot \sqrt5$, I could tell you that this represents the area of a rectangle with side lengths $e$ cm and $\sqrt5$ cm. Or maybe $e \cdot \pi$ is the cost of $\pi$ kg of material that costs $e$ dollars per kg.
Of course these quantities would not be exact, but the underlying intuition does not break down. The idea of repeated addition still holds, just that fractional parts of terms, rather than the entire number, are being added. So does such an intuition for exponentiation exist? Or is this one of the many things we must accept with proof but not understanding? This question stems from trying to understand complex exponents including Euler's identity and $2^i$, but I realized that we must first understand reals before moving on the complex numbers.","['exponentiation', 'algebra-precalculus', 'soft-question']"
702455,"Irreducibility of a polynomial in $F[x,y]$.","This is a rather easy question, but I'm not entirely confident in why I think this is true. Let $F$ be a field. Consider $F[x,y]$. I want to show that the ring $F[x,y]/(y^{2} - x)$ is an integral domain. My thought process is that because $F$ is a field, $F[x,y]$ is a unique factorization domain. I'm inclined to say that $y^{2} - x$ is irreducible in $F[x,y]$ (and therefore a prime ideal, so the quotient we are considering would indeed be an integral domain). But I'm not entirely confident in my judgment that $y^{2} - x$ is irreducible. Is it a stretch to say that this follows from Eisenstein's criterion?","['irreducible-polynomials', 'integral-domain', 'abstract-algebra']"
702538,How to compute this Riemann surface?,"This question is related to other more general question that I asked Computing Riemann surfaces of a given algebraic function . By the way, I've found an approaching in Markushevich's book that satisfies in some way the question in the link. However I still not being able to solve some problems. For instance, let $$ z = \frac{1}{2}(w + \frac{1}{w}) $$ and $$z = \frac{1}{2}(w + \frac{1}{w^2}) $$ How do I compute the associated Riemann surfaces? The general procedure is to find where the function $f(w)= z$ is injective around each branched point by picking some ""triangles"" with vertex in the respective branch point and, then, paste these ""triangles"" along the boundaries in the same way that the images are glued. For the first case, it seems that I need find a double cover since the first equation is non-injective for $w.w'=1 $, then $1$ and $-1$ would be the unique branch points, however I don't know how to find the ""triangles"" in the real axis (at first, I was thinking in picking the upper semi-plane and the lower one, however points in the real line when reflected stay in the real line). Now, for the second algebraic function, I have no idea about how to start. Thanks in advance.","['riemann-surfaces', 'algebraic-geometry', 'algebraic-curves']"
702559,convergence in mean square implies convergence of variance,"I need some hints for the following question: Suppose $X,X_1,X_2, \cdots \in L^2(\Omega)$ are random variables that converge in mean square. Show that $Var[X_n] \rightarrow Var[X]$. Convergence in mean square implies that as $n \rightarrow \infty$ we have that $\mathbb{E}[(X_n-X)^2] \rightarrow 0$. I tried to use the definition of variance $Var[X]=\mathbb{E}[X^2]-\mathbb{E}[X]^2$ and trying to prove that $|Var[X_n]-Var[X]|\leq \mathbb{E}[(X_n-X)^2]$ but I don't get any result.","['probability', 'expectation']"
702562,How many algebras are there of finite-sized $\Omega$?,"An algebra of $\Omega$ is a family that contains $\Omega,$ is closed under complement and finite union. If $\Omega=\{\}$, there can only be 1 algebra associated with $\Omega$: $2^{\Omega}.$ If $\Omega=\{1\}$, there can only be 1 algebra associated with $\Omega$: $2^\Omega$. If $\Omega=\{1,2\}$, there are 2 possible algebras: $2^\Omega, \{\Omega,\varnothing\}.$ If $\Omega=\{1,2,3\},$ there are 5 possible algebras: $2^\Omega,\{\Omega,\varnothing\},\{\Omega,\varnothing,\{1\},\{2,3\}\},\{\Omega,\varnothing,\{2\},\{1,3\}\},\{\Omega,\varnothing,\{3\},\{1,2\}\}.$ If $\Omega=\{1,2,3,4\},$ there are 15 possible algebras: $2^\Omega,
\{\{1,2,3,4\}, \{\}\},
\{\{1,2,3,4\}, \{\}, \{1\}, \{2,3,4\}\},
\{\{1,2,3,4\}, \{\}, \{2\}, \{1,3,4\}\},
\{\{1,2,3,4\}, \{\}, \{3\}, \{1,2,4\}\},
\{\{1,2,3,4\}, \{\}, \{4\}, \{1,2,3\}\},
\{\{1,2,3,4\}, \{\}, \{1,2\}, \{3,4\}\},
\{\{1,2,3,4\}, \{\}, \{1,3\}, \{2,4\}\},
\{\{1,2,3,4\}, \{\}, \{1,4\}, \{2,3\}\},
\{\{1,2,3,4\}, \{\}, \{1\}, \{2\}, \{1,2\}, \{3,4\}, \{2,3,4\}, \{1,3,4\}\},
\{\{1,2,3,4\}, \{\}, \{1\}, \{3\}, \{1,3\}, \{2,4\}, \{1,2,4\}, \{2,3,4\}\},
\{\{1,2,3,4\}, \{\}, \{1\}, \{4\}, \{1,4\}, \{2,3\}, \{1,2,3\}, \{2,3,4\}\},
\{\{1,2,3,4\}, \{\}, \{2\}, \{3\}, \{2,3\}, \{1,4\}, \{1,2,4\}, \{1,3,4\}\},
\{\{1,2,3,4\}, \{\}, \{2\}, \{4\}, \{2,4\}, \{1,3\}, \{1,2,3\}, \{1,3,4\}\},
\{\{1,2,3,4\}, \{\}, \{3\}, \{4\}, \{3,4\}, \{1,2\}, \{1,2,3\}, \{1,2,4\}\}.$ How many algebras of $\Omega$ are there if $\Omega$ is of size $n$? The first few terms look like 'Bell Numbers' (OEIS A000110). Is it the same?","['measure-theory', 'combinatorics']"
702599,is there a simple characterisation of when compact sets are closed?,In the Euclidean spaces compact sets are always closed. This is not true for general topological spaces. Can we characterise when it is possible? Is it true for metric spaces?,['general-topology']
702616,"In a Commutative Ring, is Addition Necessarily Commutative?","In A First Course in Abstract Algebra , Fraleigh writes on p. 172 that ""a ring in which multiplication is commutative is a commutative ring "". Of course, this raises the question: is addition necessarily commutative in a commutative ring? Is it commutative in any ring? Are there examples of rings in which addition is non-commutative? As far as I could tell, commutativity of the underlying additive operation is not one of the defining properties of a ring. Or is it? I don't think the book has been entirely clear on these issues --- I would be thankful if someone could shed some light on this.","['ring-theory', 'abstract-algebra']"
702618,Understanding the significance of row space and column space basis,"I've just learned about the row and column space basis and I'm confused about what the significance of each is. My professor basically hasn't said much and has danced around any direct questions on how these things relate. So what I know is this: The column space basis is solved by taking a spanning set of vectors and forming matrix A, doing RREF(A), looking at the non-zero columns (linearly independent columns) and then relating that back to the original matrix A. The corresponding columns in the original matrix A form the column basis for A. This makes sense because you can see that any column in that matrix can be formed from some linear combination of the basis. Now when it comes to row space I can mechanically do it. Transpose A, reduce it to echelon form (not RREF), transpose it again, and read off the columns. In this case, you do not go back to the original matrix. My questions are: why don't we go back to the original matrix? Why do we only reduce it to echelon form and then read off the rows? How does this basis relate to the rows of the original matrix A? Sorry if these are elementary question. I feel like I can mechanically (and begrudgingly) do it but I really want to understand and appreciate it. Thank you!","['vector-spaces', 'matrices', 'linear-algebra']"
702646,Multiple Fourier Integrals involving Heaviside Theta Function,"I want to evaluate the integral: $$I=\int_{-\infty}^{\infty}dx_1 \int_{-\infty}^{\infty}dx_2 \  \Theta(x_1-x_2) \ e^{i(ax_1+bx_2)}$$
where $\Theta(x)$ is the Heaviside function. What I was doing now was taking the relation for $\Theta$: $\Theta (x)=-\frac{1}{2\pi i}\int_{-\infty}^{\infty}d\tau \frac{1}{\tau + i\epsilon} e^{-ix\tau}$ and I got:
$$I= -\frac{1}{2\pi i}\int_{-\infty}^{\infty}dx_1 \int_{-\infty}^{\infty}dx_2\int_{-\infty}^{\infty}d\tau \ \frac{1}{\tau + i\epsilon}e^{-i(\tau-a)x_1}e^{-i(\tau+b)x_2}\\=2\pi i\int_{-\infty}^{\infty}d\tau\ \frac{1}{\tau + i\epsilon}\delta(\tau-a)\delta(\tau+b) =2\pi i\frac{\delta(a+b)}{a + i\epsilon}$$
I didn't know if the integral was convergent and I could simply interchange the integrals, so I tried it in a different form with $X=x_1+x_2$ and $x=x_1-x_2$ :
$$I=\frac{1}{2}\int_{-\infty}^{\infty}dX \int_{-\infty}^{\infty}dx \ \Theta(x) \ e^{ia\frac{x+X}{2}+ib\frac{X-x}{2}} \\ =\pi \int_{-\infty}^{\infty}dx \ \Theta(x) e^{-2\pi i\frac{b-a}{4\pi}}\delta(\frac{b+a}{2})$$
With the Fourier Transform of the Heaviside function $\int_{-\infty}^{\infty}dk\ \Theta(k)e^{-2\pi i kx}=\frac{1}{2}(\delta(x)-\frac{i}{\pi k}) $ I get
$$I=\pi \left(2\pi\delta(b-a)-\frac{4 i}{b-a}\right)\delta(a+b)=2\pi^2\delta(a)\delta(b)+2\pi i\frac{\delta(a+b)}{a}$$
I don't know yet where the $\delta(a)\delta(b)$ should come from in the first method. When I want to check that now and integrate $I$ over $a$ and $b$ I get from the first line:
$$\int_{-\infty}^{\infty}da \int_{-\infty}^{\infty}db \ I = \int_{-\infty}^{\infty}dx_1\int_{-\infty}^{\infty}dx_2 \Theta(x_1-x_2) \delta(x_1)\delta(x_2)  \\ = \Theta(0)=\frac{1}{2}$$ and from the second result:
$$\int_{-\infty}^{\infty}da \int_{-\infty}^{\infty}db \ I=4\pi^2-\int_{-\infty}^{\infty}db \frac{1}{b}=-\infty$$
Where did it go wrong? Is the integral correct? EDIT: corrected mistake in derivation because of comment.","['fourier-analysis', 'integration', 'integral-transforms']"
702681,Integral $\int_0^1\frac{\log(1-x)}{\sqrt{x-x^3}}dx$,"I have a trouble with this integral
$$I=\int_0^1\frac{\log(1-x)}{\sqrt{x-x^3}}dx.$$
Could you suggest how to evaluate it?","['improper-integrals', 'closed-form', 'calculus', 'integration', 'definite-integrals']"
702692,Prove that $H$ is a abelian subgroup of odd order,"Question is: Let $G$ be a group of  order 2n. Suppose half of the element of G are of order 2 and the other half form  a subgroup $H$ of order n . Prove that $H$ is of odd order  and is an abelian subgroup of $G$ What could i see is.. if we prove that order of every element of $H$ is odd , then order of $H$ is odd . Also i am unable to use the fact that half of the element of $G$ are of order 2. Please help me to clear this. Thank You.","['finite-groups', 'abstract-algebra']"
702695,"Functional Equation : If $(x-y)f(x+y) -(x+y)f(x-y) =4xy(x^2-y^2)$ for all x,y find f(x).","Problem : If $(x-y)f(x+y) -(x+y)f(x-y) =4xy(x^2-y^2)$ for all x,y find f(x). My approach : The given equation can be written as $$(x-y)f(x+y) -(x+y)f(x-y) =4xy(x-y)(x+y)$$ $$\Rightarrow \frac{(x-y)f(x+y)}{(x-y)(x+y)} -\frac{(x+y)f(x-y)}{(x-y)(x+y)} =4xy$$ $$\Rightarrow \frac{f(x+y)}{x+y} -\frac{f(x-y)}{x-y} =4xy$$ Now we know that $$(x+y)^2 -(x-y)^2 = 4xy$$ $\Rightarrow \frac{f(x+y)}{x+y} =(x+y)^2$....(i) & $\frac{f(x-y)}{x-y} =  (x-y)^2$...(ii) Now putting y =0  in (i) and (ii) we get : $\frac{f(x)}{x} =x^2$ $\Rightarrow f(x) =x^3$ But the answer is $f(x) =x^3 +kx$ ( where k is any constant ) please clarify this part thanks...","['algebra-precalculus', 'functions', 'functional-equations']"
702707,Find the integral $\int \frac{1}{x^2 \cdot \tan(x)} \ dx$,This problem seems pretty tricky. I need to find the integral of $$\int \dfrac{1}{x^2 \cdot \tan(x)} \ dx$$ Any help would be greatly appreciated!,"['trigonometry', 'calculus', 'integration', 'indefinite-integrals']"
702723,How to think of quotients of polynomial rings,"I'm studying for an algebra midterm and I'm really just having a hard time wrapping my head around quotients of polynomial rings, especially ones where the ideal being quotiented by is something non-principle (i.e an ideal of the form $(x^2 - 2, 3$) in an appropriate polynomial ring). For example this question Set of Ideals of a Polynomial Ring makes use of the fact that $$\mathbb{Z}[x]/(2,x^3 + 1) \cong \mathbb{Z}_2[x]/(x^3 + 1)$$ to arrive at a solution, but this isomorphism doesn't at all seem obvious to me (hopefully because I'm just not thinking about the quotient in the correct way). Another example, also a question from dummit and foote ($\S 9.1, 13$), is ''Prove that the rings $F[x,y]/(y^2 - x)$ and $F[x,y](y^2 - x^2)$ are not isomorphic for any field $F$ ''. Really I don't even see an obvious direction to proceed, but I think, on a more fundamental level, I really just have no intuitive notion as to what those fields even look like. So I was hoping for some helpful way(s) of thinking about these spaces. Any insight would be much appreciated.","['ring-theory', 'abstract-algebra']"
702744,Significance and applications of the Riesz Representation Theorem in locally compact Hausdorff spaces,"Can anyone tell me the signification of Theorem $2.14$ (The Riesz Representation Theorem in locally compact Hausdorff spaces), page $40, 41$ in Rudin - Real and Complex Analysis? And some applications of that theorem? Thanks in advance.","['measure-theory', 'riesz-representation-theorem', 'real-analysis', 'lebesgue-integral', 'lebesgue-measure']"
702777,Higher centers are characteristic.,"Let $G$ be a group. Define $\zeta^i=\zeta^i(G)$ inductively as follows: $\zeta^0=1$and $\zeta^{i+1}$ is the subgroup of $G$ for which $$\frac{\zeta^{i+1}(G)
}{\zeta^i(G)}=Z\left(\frac{G}{\zeta^i(G)}\right)$$ Thus $\zeta^{i+1}(G)=\{g\in G:\forall g'\in G,[g,g']\in \zeta^i(G)\}$ is the largest$^{1}$ subgroup of $G$ for which $[\zeta^{i+1}(G),G]\leqslant \zeta^i(G)$. My questions are two: $(1)$ Is is true the last inclusion is an equality for each $i=0,1,2,\ldots$? It is easily seen the last definition agrees for $i=0$, for $Z(G)$ is the largest subgroup of $G$ for which $[Z(G),G]\leqslant 1$, i.e. $[Z(G),G]=1$, but I am not sure if we have equality for $i=1,2,\ldots$. $(2)$ I want to show each $\zeta^{i}(G)$ is characteristic. $\zeta^{0}(G)=1$ is trivially characteristic. Now assume $\zeta^{i}(G)$ is, and observe that if $\eta$ is an automorphism of $G$, then $[\zeta^{i+1}(G),G]\leqslant \zeta^{i}(G)$ becomes $[\eta\zeta^{i+1}(G),G]\leqslant \zeta^{i}(G)$ for both $G$ and $\zeta^{i}(G)$ are characteristic, and $\eta[H,K]=[\eta H,\eta K]$. This means$^{1}$ $$\frac{\eta\zeta^{i+1}(G)}{\zeta^i(G)}\leqslant \frac{\zeta^{i+1}(G)
}{\zeta^i(G)}=Z\left(\frac{G}{\zeta^i(G)}\right)$$ so $\eta \zeta^{i+1}(G)\leqslant \zeta^{i+1}(G)$ and $\zeta^{i+1}(G)$ is characteristic. Is there a better proof? $1.$ Lemma If $K\lhd G$, $K\leqslant H\leqslant G$ , then $[H,G]\leqslant K\iff H/K\leqslant Z(G/K)$. Thus if $H$ is some group above $\zeta^i(G)$ for which $[H,G]\leqslant   \zeta^i(G)$ the lemma gives $H/  \zeta^i(G)\leqslant   \zeta^{i+1}(G)/\zeta^i(G)$, which implies $H\leqslant   \zeta^{i+1}(G)$.",['group-theory']
702789,Show that $Q_8$ can't be embedded in $M_{2 \times 2}(\mathbb{R})$ as a group.,"So, suppose that we're working in a field $F$. Consider the ring $M_{n \times n} (F)$ which is the set all $n \times n$ matrices with entries in $F$. Is it possible to determine whether a matrix polynomial equation has solutions? If yes, is it possible to find the solutions for low degree polynomials? My knowledge of mathematics is very limited as an undergraduate. I'm sure that there are many aspects of this question that are possibly beyond my knowledge at this level, but my interest in this question comes from this problem: Show that the group $Q_8 = \{ \pm 1, \pm i, \pm j,\pm k\}$ under multiplication defined on Quaternions can not be embedded in the group of invertible elements of $M_{2\times 2}(\mathbb{R})$ under matrix multiplication. So, because the cardinality of $M_{2 \times 2}(\mathbb{R})$ is infinite, I thought it might be very difficult to try group homomorphisms from $Q_8$ to $M_{2 \times 2}(\mathbb{R})$ and show that they can't have trivial kernel. Especially because if we replace $\mathbb{R}$ by $\mathbb{C}$ the problem becomes false. So, I thought that I should carefully study the number of solutions in each group and find some contradictions. For example, is it possible to show that the equation $A^4=I$ has less than $8$ solutions in $M_{2 \times 2}(\mathbb{R})$?","['abstract-algebra', 'quaternions', 'linear-algebra', 'finite-groups', 'group-theory']"
702804,Mean value over an infinite interval,"I just need a sanity check, been thinking about this all morning. If we use the Mean Value Theorem on a function over the infinite interval (suppose the function's domain is unbounded), i.e. $$M=\lim\limits_{T \to \infty} \dfrac{1}{2T}\int_{-T}^{T} \text{dt} f(t)$$ There is no way that M can be finite right? My intuition tells me it's either zero or infinite, but I wanted another opinion; oddly enough, I wasn't able to google it. Thanks!","['functions', 'improper-integrals', 'integration', 'real-analysis']"
702816,Lie algebra $\implies$ Lie group?,"Lie's third theorem says that every finite-dimensional Lie algebra g over the real numbers is associated to a Lie group G. So say I have an $r-$ parameter group of symmetries whose tangents at the identity form a Lie algebra, can we conclude that the group is a Lie group? As an example of why I am asking, consider the ODE $y''=y'$. It has a $2-$parameter group of symmetry transformations given by $y\to \epsilon y$, and $y\to y+t$. It's not clear to me that this forms a Lie group since the transformations don't commute and I can't see a smooth structure. However, its generators, given by $\partial_y,y\partial_y$ form a Lie algebra.","['ordinary-differential-equations', 'lie-algebras', 'manifolds', 'lie-groups', 'symmetry']"
702874,"What does ""percent of change"" mean?","Whenever a price is changed, you can find the percent of increase or the percent of decrease by using the following formula: $$\frac{\text{percent of change}}{100}=\frac{\text{change in price}}{\text{original price}}$$ To find the change in price, you calculate the difference between the original price and the new price. Is the ""percent of change"" the change in price represented as a percent of the original price? Does the proportion: ""percent of change"" is to $100$ as change in price is to original price make sense? Also, don't we lose the percent symbol if the original price is $100? Since then $$\text{percent of change}=\text{change in price}$$ So does ""percent of change"" now just become a portion of the original price? If I replace the word ""percent"" in the above formula with ""portions of 100"" the whole thing makes a lot more sense, because of the literal meaning of ""percent"" being ""for each 100"" in my opinion. Edit: the formula also makes no sense if the original ""price"" is zero.","['percentages', 'algebra-precalculus']"
702901,Number theory: Odd number and powers of 2,"Is is true that for any odd natural number $x > 2$, there exists a positive natural number $y$, such that $x^y = 2^n+1$ or $x^y=2^n-1$ where $n$ is a also natural $> 0$. This cannot be solved by simple group theory methods, since we demand that $x^y$ be exactly $2^n+1$ or $2^n-1$ and not only modulu $2^n$. Thanks.",['number-theory']
702936,Equation with an infinite number of solutions,"I have the following equation: $x^3+y^3=6xy$. I have two questions: 1. Does it have an infinite number of rational solutions? 
2. Which are the solutions over the integers?($ x=3 $ and $ y=3 $ is one)
Thank you!","['algebra-precalculus', 'diophantine-equations', 'rational-numbers']"
702949,Which of the two popular definitions of independent events is more primitive?,"I know there are two ways to say event $a$ and $b$ are independent: $P(a)P(b)=P(a\cap b)$ $P(a\mid b)=P(a)$ and I can derive one from the other with the Bayes Formula $P(a|b)=P(a\cap b)/P(b)$. My question is: Of the two equations above, which is the definition from which the other equation is proven?","['bayesian', 'probability']"
702977,Isomorphism of an extension field of a field of finite transcendence degree,"The following is the proposition (1.4) of Mumford's book Algebraic Geometry If $\mathbb C$ has infinite transcendence degree over $k$, then every variety has a $k$-generic point. In the proof Then $L$ is an extension field of $k$ of finite transcendence degree. But any such field is isomorphic to a subfield of $\mathbb C$. i.e. there exists a monomorphism $\phi : L \rightarrow {\mathbb C}$. Is any extension field of $k$ of finite transcendence degree isomorphic to a subfield of $\mathbb C$ ? If so, how do you prove it.","['algebraic-geometry', 'extension-field', 'field-theory']"
702979,Randomly generate an matrix $A$ s.t. $A^m = I$,"Fixed $n$, I want to randomly generate a $n \times n$ real matrix $A$ from the set: $\{A \in \mathcal{M}_{n \times n}(\mathbb{R}): \exists m \in \mathbb{N} \mbox{ s.t. } A^m = I\}$ I think I should first randomly generate a diagonal matrix $D$ such that $\det(D) = \pm 1$ and then randomly generate an invertible matrix $P$ and then compute $PDP^{-1}$. Is this method correct? Since $|\det(D)|=1$, I just generate a random $n$ unity ($+1$ or $-1$ for $\mathbb{R}$) to get the matrix $D$. But how can I randomly generate an invertible matrix $P$? To make the problem possible to solve, I should add a constraint like the matrix norm $\Vert P \Vert$ of P should satisfy: $0 < m \leq \Vert P \Vert \leq M$ for some constant $m,M$","['linear-algebra', 'algorithms']"
703009,Collar neighbourhoods for topological manifolds.,"The well-known collar neighbourhood theorem states: Let $M$ be a smooth manifold with compact boundary $\partial M$, then there exists a neighbourhood of $\partial M$, which is diffeomorphic to $\partial M\times [0,1)$. I am asking myself if the theorem holds in the topological category. Is it true at least for compact topological manifolds? My first idea would be to take a more closer look at the work of Kirby and Siebenmann on topological manifolds, but since I am absolutely not an expert in this field, I hoped to get an answer with a reference or a counterexample here.","['general-topology', 'manifolds', 'algebraic-topology']"
703011,Summation over Weierstrass $\wp$ functions,"I've been trying to prove the following closed expression for a summation over Weierstrass 
$\wp$-functions: \begin{equation}
\sum_{k=1}^{N-1} \wp_N(k) = \frac{2}{\omega}\left(\zeta\left(\frac{\omega}{2}\right)-N\zeta_N\left(\frac{\omega}{2}\right)\right),
\end{equation} where $\wp_N$ is the usual WeierstrassP function with periods $(N,\omega)$, $\zeta_N$ is the Weierstrass zeta-function with periods $(N,\omega)$ and $\zeta$ is the Weierstrass zeta-function with periods $(1,\omega)$. Also, $N \in \mathbb{N}$, $N\geq 2$ and $\omega = i\pi/\kappa $ for some $\kappa\in \mathbb{R_{>0}}$. My usual approach to such a problem is to find a quasi-periodic function $F$, i.e. satisfying
$$F(z+1) = \alpha F(z),\qquad F(z+\omega)=F(z),
$$ 
where $\alpha \in \mathbb{C}$ and $|\alpha| >0$. This $F$ should then have the left hand side of the expression above in its Laurent series. Secondly, I postulate a different function which has the exact same pole structure as $F$. Due to the Liouville theorem for elliptic functions, one can then conclude that they must be equal (quasi-periodicity dictates that their difference is not just a constant, but must be zero). Equating the Laurent-coefficients then should yield the equation given above. In this case, one could use an appropriate modification of the function $F(z) = \sum_{k=0}^{N-1} \wp_N(z+k)$, which has as its zeroth order Laurent coefficient precisely $\sum_{k=1}^{N-1} \wp_N(k)$. This $F$ is doubly-periodic with periods $(1,\omega)$ and therefore does not satisfy quasi-periodicity yet. Its Laurent expansion equals
$$ 
F(z) = \frac{1}{z^2} + \sum_{k=1}^{N-1} \wp_N(k)+ O(z)
$$
and has therefore the exact same pole structure as the $\wp(z)$ (with periods $(1,\omega)$). Does this approach work at all and if yes, which function $F$ should one use? If not, how could one prove the statement above? In the mean time, I have found a function $F$ which might do the trick. Using the argument above, I proved that 
$$
F(z)=\sum_{k=0}^{N-1} e^{ipk}\wp_N(z+k)
$$
equals 
$$
G(z) = -\frac{\sigma(z+r)}{\sigma(z-r)}e^{\frac{p}{\pi}\zeta(\omega/2)z}\left( \wp(z) -\wp(r) +\Delta(r)\left(\frac{\wp'(z)-\wp'(r)}{\wp(z)-\wp(r)} -\frac{\wp''(r)}{\wp'(r)}    \right)  \right)
$$
where $r=-ip/(4\kappa)$, $\Delta(r) = \zeta(r) +\frac{p}{2\pi}\zeta(\omega/2)$ and $\wp$ and $\zeta$ are defined on the lattice $(1,\omega)$. Here $\sigma$ is the usual Weierstrass $\sigma$ function and is also defined on the lattice $(1,\omega)$. $p$ is a non-zero complex number. The expansion of $G$ around the point $z=0$ equals, writing $\delta=\frac{p}{\pi}\zeta\left(\frac{\omega}{2}\right)$
\begin{eqnarray}\label{laurent0}
G(z) &=& \left( 1+2 \zeta(r)z+2\zeta^2(r) z^2 +O(z^3)\right)\left(1+\delta z +\frac{1}{2}(\delta z)^2\right) \nonumber \\
& &\times \left\{\frac{1}{z^2}-\wp(r) +\Delta\left( -\frac{2}{z} -\wp(r)z + \wp'(r) z^2 -\frac{\wp''(r)}{\wp'(r)}\right) \right\} \nonumber \\ &=& \frac{1}{z^2} + \frac{2\zeta(r) +\delta -2\Delta}{z} + \left(-\wp(r) -\Delta\frac{\wp''(r)}{\wp'(r)} +\left(\zeta(r) +\delta/2\right)\left(-4\Delta+2(\zeta(r) +\delta/2) \right) \right) +O(z). \nonumber \\
\end{eqnarray}
One sees that the term going as $\frac{1}{z}$ vanishes due to our definition of $\Delta(r)$.
By equating their respective Laurent series, I found
$$
\sum_{k=1}^{N-1} e^{ipk}\wp_N(k) = -\wp(r) -\Delta(r) \frac{\wp''(r)}{\wp'(r)}-2\Delta(r)^2.
$$
However, when I take the limit $p\rightarrow 0$ -- by expanding the right hand side in $p$ and taking the zeroth order term -- I find
$$
\sum_{k=1}^{N-1}\wp_N(k) = \frac{2}{\omega}\zeta\left(\frac{\omega}{2}\right),
$$
which is not exactly the answer I know to be true found on the top of this question. Also, numerical analysis of this expression shows conclusively that the equation above cannot be true, whereas the equation on the top of this page yields correct results every time.","['summation', 'elliptic-functions', 'complex-analysis']"
703048,How would one arrive at the formulas for divergence and curl?,"It has been some years since I've taken multivariable calculus now, but there's something I really never understood: how people would discover the expressions for divergence and curl. I mean, the books usually say the formulas and then show that with that it's possible to view divergence as a measure of how much a vector field diverges locally and curl the analog for rotation locally. Now, it's not clear that if you pick those expressions it will give this interpretation. Books usually say: ""we take those formulas because they work"" and well, I know that. What I want to know is: imagining we want to find two operators $\operatorname{div}$ and $\operatorname{curl}$ on vector fields such that $\operatorname{div}$ gives local divergence and $\operatorname{curl}$ gives local rotation, how could we deduce the definitions that would work? I'm questioning this because currently I'm studying differential forms on manifolds, and to appreciate the definition of exterior derivative I thought it would be good to go back and see where the definitions of divergence and curl come from. Based then on the exterior derivative, I've found out that if $v\in \mathfrak{X}(\mathbb{R}^3)$ is a vector field and we consider the usual cartesian coordinates in $\mathbb{R}^3$ then $$\nabla \times v = \sum_{i=1}^3 \nabla v^i \times \dfrac{\partial}{\partial x^i} \qquad \nabla\cdot v = \sum_{i=1}^3 \nabla v^i \cdot \dfrac{\partial}{\partial x^i}$$ I then started to try seeing if these formulas were any easier to find out, but I couldn't get anythin from it. Thanks very much in advance.","['vector-analysis', 'multivariable-calculus', 'intuition', 'soft-question']"
703060,"Inequality in triangle involving side lenghs, medians and area","A, B and C are the vertices of a triangle. Denote $m_a$, $m_b$ and $m_c$ the medians from A, B and C. Prove the inequality:
$$\sum_{cyc}{a^2bcm_a}\geq\sum_{cyc}{cS(a^2+b^2)}$$where a, b and c are the side lengths BC, CA and AB respectively and S is the area of the triangle.
This can be rewritten as $$\sum_{cyc}{am_a}\geq S(\sum_{cyc}{\frac{a^2+b^2}{ab}})$$
Any ideas? Thanks!","['geometry', 'inequality', 'contest-math', 'triangles', 'area']"
703066,Should this be viewed as a serious issue with the meadow-theoretic approach?,"Meadow theory (see here ) allows us to apply the results and concepts of universal algebra to the study of fields. Obviously, this is very, very nice. However, I have the following issue with the meadow-theoretic approach: since every meadow satisfies $0^{-1}=0,$ and since this makes reciprocation in both $\mathbb{R}$ and $\mathbb{C}$ discontinuous (at $0$), thus these number systems cannot be viewed as models of the theory of meadows in the category $\mathrm{Top}$ unless we endow them with a non-standard topology. Questions. Should this be viewed as a serious issue with the meadow-theoretic approach? Does anyone know of a good solution?","['category-theory', 'abstract-algebra', 'field-theory']"
703067,Difference between Vector Functions and Vector Field,I understand that a vector function is a function that has a domain $\mathbb{R}^n$ and range on $\mathbb{R}^m$ so it takes vectors and gives vectors right? So what is a vector field?And how can I visualize them?,"['multivariable-calculus', 'calculus', 'vector-fields', 'vector-analysis', 'advice']"
703071,Existence of a morphism of schemes from $X$ to $\mathbb P_A^n$?,"In exercise §II.III.VIII. of Algebraic geometry and arithmetic curves by Qing.Liu. one is asked the following: Let $X$ be a scheme over a ring $A.$ Let $f_0, \cdots,f_n\in\mathcal O_X(X)$ be such that the $f_{i,x}$ generate the unit ideal of $\mathcal O_{X,x}$ for every $x\in X.$ Show that $X=\cup_i X_{f_i}$ and that we have a morphism $f:X\rightarrow\mathbb P_A^n$ such that $f^{-1}(D_+(T_i))=X_{f_i}$ and that $f|_{X_{f_i}}$ is induced by the map $g:A[T_i^{-1}T_j]_j\rightarrow\mathcal O_X(X_{f_i})$ sending $T_i^{-1}T_j$ to $f_i^{-1}f_j.$ If $A=k$ is a field and $x\in X(k),$ determine $f(x)$ as well. That $X=\cup_i X_{f_i}$ is easy, and I think the morphism $f$ comes from the invertibility of  $f_i$ in $\mathcal O_X(X_{f_i}),$ from the fact that morphisms into an affine scheme are in bijection with ring-homomorphisms of the rings of global sections, from the composition of the above deduced map with the inclusion $D_+(T_i)\rightarrow\mathbb P_A^n,$ and finally from the compatibility of these maps. But how could I show the compatibility of these maps? I am now confused by those entangling relations between morphisms and between schemes, and cannot see how to verify this compatibility. Also, to determine $f(x),$ first identiy $\mathbb P_k^n(k)$ with $\mathbb P(k^{n+1}).$ Then, for $x\in X(k)\cap X_{f_i},$ we find $f(x)=(\alpha_0,\cdots,\alpha_n),$ where $\alpha_j$ is the image of $f_i^{-1}f_j$ in $k=k(x).$ Any hint or answer is welcomed. P.S. Please forgive my cumbersomeness in this area, and help me improve upon it, as I am quite unfamiliar with algebraic geometry. Sincere thanks in advance. :)","['algebraic-geometry', 'schemes', 'projective-schemes']"
703088,The smallest quadrangle inscribed in a rectangle,"I'm supposed to find a quadrangle of the smallest perimeter possible inscribed in a rectangle.
The inscribed quadrangle has each of its four vertices on another side of the rectangle. Let's call the rectangle ABCD and let the shorter side be $a$ and the larger $b$. Let's call the quadrangle $KLMN$. So for example $K$ lies on $AB$, $L$ on $BC$, $M$ on $CD$, $N$ on $AD$. I think that the sides of $KLMN$ would be the shortest of its diagonals intersected at the right angle, because then by the law of cosines, we have $KL^2 + LM^2= KM^2 + 2 KL \cdot LM \cdot \cos  \angle KLM$, and $\cos  \angle KLM \le 0$ if $\angle KLM \ge 90 ^{\circ}$ and $KM$ is the shortest if it is parallel = equal to the proper side of the rectangle. Could you tell me if I'm right or correct me if I'm wrong? Thank you.","['optimization', 'geometry']"
703116,Find the limit of $\lim_{x\to 0}\frac{\sqrt{x^2+a^2}-a}{\sqrt{x^2+b^2}-b}$,Can someone help me solve this limit? $$\lim_{x\to0}\frac{\sqrt{x^2+a^2}-a}{\sqrt{x^2+b^2}-b}$$ with $a>0$ and $b>0$.,"['radicals', 'calculus', 'limits']"
703129,Isogeny of an elliptic curve,"Let $E$ be an elliptic curve over $\mathbb{Q}$ and $p$ be a prime. Then what does it mean by ""$E$ has a $\mathbb{Q}$-isogeny of degree $p$""?","['algebraic-geometry', 'elliptic-curves', 'number-theory']"
703133,How to find multiplicative orders of all elements in field $\Bbb F$ (say $\Bbb F_{13}$)?,I am working on some finite fields and I was referring to some online class material. Is there any way to find the multiplicative orders of all elements in a field $\Bbb F$?,"['finite-groups', 'finite-fields', 'discrete-mathematics', 'cryptography']"
703137,Cubic diophantine equation,"How can be solved the equation $x^3+x-1=y^2$ in positive integers? I know this equation defines an elliptic curve, but this seems to be a non-elementary way to solve this question. Is there a more elementary solution? By the way I found three solutions: $(1,1), (2,3)$ and $(13,47)$. Is this related to the law group property of elliptic curves? Thanks for further answers.","['diophantine-equations', 'elliptic-curves', 'number-theory']"
703149,Can be solved without L'Hopital?,Can this limit be evaluated without l'hopital's rule? $$\lim_{h\to0}\frac{\sqrt[3]{8+h}-2}{h}$$,"['radicals', 'calculus', 'limits-without-lhopital', 'limits']"
703163,Geometry of $k$-forms and $k$-vectors,"In this question I was trying to see why $k$-forms are selected as the way to generalize vector calculus rather than $k$-vectors and a comment providing links to other questions made me end up with another doubt on the geometric interpretation of $k$-forms and $k$-vectors. Considering for a while $\Lambda^k(V)$ and $\Lambda^k(V^\ast)$ without regard to manifolds, I've convinced myself very well that an element of $\Lambda^k(V)$ represents simply pieces of $k$-dimensional planes. So for instance, if $v,w\in V$ then $v\wedge w\in \Lambda^2(V)$ would be simply the oriented paralelogram generated by $v$ and $w$ and it would carry it's area as information. My understanding of an element of $\Lambda^k(V^\ast)$ was that of an object which can do measures with objects from $\Lambda^k(V)$. So that if $\omega \in \Lambda^1(V)=V^\ast$, then putting $\hat{\omega}=\omega^{-1}(1)$ we see that $\hat{\omega}$ can represent $\omega$ in the sense that $\omega$ defines what means for a vector to cross $1$ unit along a direction without regard to metrics. Now, my doubt is that in that answers, people consider elements from $\Lambda^k(V^\ast)$ as pieces of $k$-planes also. So that $dx\wedge dy$ would be consider as the paralelogram  $e_1\wedge e_2$. This confuses me a lot, and I think the problem is that I'm really failing to get the interpretation of $k$-forms. Is this right to represent $dx\wedge dy$ by that paralelogram? If so, why is that? How to really get these ideas?","['geometry', 'multilinear-algebra', 'intuition']"
703185,"Proof: $a^2 - b^2 = (a-b)(a+b)$ holds $\forall a,b \in R$ iff R is commutative","We want to show that for some ring $R$, the equality $a^2 - b^2  = (a-b)(a+b)$ holds $\forall a,b \in R$ if and only if $R$ is commutative. Here's my proof --- I'm not sure if the first part stands up to examination. I'd be grateful if someone could take a look. Forward: $a^2 -b^2 = (a-b)(a+b) \forall a,b \in R$ implies $R$ is commutative Let $x = (a-b)$. Then \begin{align}
x(a+b) &= xa+xb\\
&= (a-b)a + (a-b)b\\
&= a^2 -ba + ab - b^2\end{align} Then we note that $a^2 - ba + ab - b^2 = a^2 - b^2$ iff $-ba + ab = 0$ if and only if $ab=ba$ iff $R$ is commutative. Backwards: $R$ is commutative implies $a^2 - b^2 = (a-b)(a+b) \forall a,b \in R$. Let $x = (a+b)$. Then $(a-b)x = ax - bx = a(a+b) - b(a+b) = a^2 + ab - ba - b^2$. $R$ is commutative, so $ab-ba = 0$, so $a^2 + ab - ba - b^2 = a^2 - b^2$.","['proof-verification', 'ring-theory', 'elementary-set-theory', 'abstract-algebra']"
703207,Find the exact value of the infinite sum $\sum_{n=1}^\infty \big\{\mathrm{e}-\big(1+\frac1n\big)^{n}\big\}$,"How can we find the exact value of the infinite sum 
$$
\displaystyle\sum_{n=1}^\infty \left\{\mathrm{e}-\Big(1+\frac1n\Big)^n\right\}?
$$ This problem appears in: T. Andreescu, T. Radulescu & V. Radulescu, Problems in Real Analysis: Advanced Calculus on the real line , p.114.","['sequences-and-series', 'convergence-divergence', 'calculus', 'real-analysis', 'limits']"
703212,"Is $dx\,dy$ really a multiplication of $dx$ and $dy$?","On the answers of the question Is $\frac{\textrm{d}y}{\textrm{d}x}$ not a ratio? it was told that $\frac{dy}{dx}$ cannot be seen as a quotient, even though it looks like a fraction. My question is: does $dxdy$ in the double integral represent a multiplication of differentials? The problem then can be generalized for a multiple integral.","['nonstandard-analysis', 'calculus', 'real-analysis', 'analysis']"
703219,Integral of a differential 1-form along a curve (clarification on the definition),"Let's denote with $(e_1,\dots,e_d)$ the usual basis of $\Bbb R^d$, and with $({e_1}^*,\dots,{e_d}^*)$ the dual basis of its dual space $\Bbb {(R^d)}^*$.
Let $U$ be an open subset of $\Bbb R^d$ and $\omega:U\to \Bbb {(R^d)}^*$ be a $C^\infty$ differential 1-form.
So, by definition, there exist $C^\infty$ functions $\omega_1,\dots,\omega_d:U\to\Bbb R$ such that $\omega=\sum_{j=1}^d\omega_j\,dx^{\,j}$, where each $x^{\,j}$ is the restriction to $U$ of ${e_j}^*$ (so $dx^{\,j}$, the differential of ${x^{\,j}}$, is the constant map $U\to ({\Bbb R^d})^*$, $u\mapsto {e_j}^*$). Let $\gamma:[a,b]\to U$ be a $C^\infty$ curve.  So, for all $t\in[a,b]$ it is defined $\gamma'(t)$ as an element of $\Bbb R^d$.  Being $\omega(\gamma(t))$ a functional, we can associate to it a vector of $\Bbb R^d$ (its representation with respect to the usual basis, which happens to be the vector $^t(\omega_1(\gamma(t)),\dots,\omega_d(\gamma(t)))\,\,$).
Now, it is licit to take the scalar product $\langle\omega(\gamma(t)),\gamma'(t)\rangle$.
So we define $$\int_\gamma\omega:=\int_a^b\langle\omega(\gamma(t)),\gamma'(t)\rangle\,dt=\int_a^b\biggl(\sum_{j=1}^d\omega_j(\gamma(t))(\gamma^{\,j})'(t)\biggr)dt.$$ and call it the INTEGRAL OF $\omega$ ALONG $\gamma$. The question is: what is this definition supposed to mean?  What does this integral represent?","['differential-geometry', 'definition']"
703246,I have trouble understanding the proof of the Wold decomposition theorem,"I'm trying to understand the proof of the Wold decomposition theorem in [1, p.187]. I find a few things about it very irritating. The theorem states: Theorem 5.7.1 (The Wold Decomposition). Let $X_t$ be a stationary process with $$\sigma^2 = E|X_{n+1}-P_{M_n}X_{n+1}|^2 >0,$$ where $$M_n=\overline{span} \lbrace X_t: -\infty<t\leq n \rbrace.$$ Then $X_t$ can be decomposed as $$X_t=\sum_{j=0}^\infty \psi_j Z_{t-j} + V_t$$ where (1) $\psi_0=1, \sum_{j=0}^\infty \psi^2< \infty$ (2) $E[Z_t]=0$, $var(Z_t)=\sigma^2$, $t \in \mathbb{Z}$ and $Z_t$ is uncorrelated (3) $Z_t \in M_t$,  $t \in \mathbb{Z}$ (4) $E(Z_tV_s)=0$,  $t,s \in \mathbb{Z}$ (5) $V_t$ is deterministic Here $P$ denotes the projection. The proof starts by setting $$Z_t:=X_t-P_{M_{t-1}}X_t,$$ $$\psi_t:=\langle X_t, Z_{t-j}\rangle/\sigma^2,$$ $$V_t:=X_t-\sum_{j=0}^\infty \psi_j Z_{t-j}.$$ We have to show that these sequences satisfy (1)-(5). Since $Z_t \in M_t$ and $Z_t \in M_{t-1}^\bot$ by definition, we have that $$Z_t \in M_{t-1}^\bot \subset M_{t-2}^\bot \subset...$$ which shows that $E(Z_sZ_t)=0$ for $s<t$. This establishes the last part of (2). Furthermore, an exercise in the book establishes that $var(Z_t)=\sigma^2$. What I am having trouble with is another part: My question: Why is $E[Z_t]=0$? And why does that not yield that $V=0$? My idea was to use the zero-mean-property of $X_t$. We know that $Z_t \in M_t$, i.e., in the smallest closed subspace that contains all $X_t$, $t<n$. Therefore, $Z_t$ is the limit of a subsequence $\lbrace X_{t_j} \rbrace$ of zero-mean and so $$E[Z_t]=E[\lim_{j \to \infty} X_{t_j}] = \int\lim_{j \to \infty} X_{t_j}dP = \lim_{j \to \infty} E[X_{t_j}]=0.$$ But why can I interchange the limit and the integral in the third inequality? And even worse: If $X_t$ as well as $Z_t$ indeed have zero-mean, why does that not result in $E[V_t]=0$ and therefore -by determinancy- $V_t=0$? Any help is much appreciated! [1] Brockwell, Peter J.: Time series: theory and methods. Second Edition. 2006, Springer.","['statistics', 'stochastic-processes', 'time-series']"
703308,Simplify a triple sum,"I need to find a closed form for this summation:
$$\sum_{j=1}^m\sum_{i=j}^m\sum_{k=j}^m\frac{{m\choose i}{{m}\choose{k}}}{j{m\choose j}}r^{k-j+i}$$
I posted this a long time ago, but today I found out there was an important typo in the formula, so I repost the correct one again here.
Any minor simplification or closed form for the special case of $r=1$ is also helpful. Any help is greatly appreciated!","['summation', 'algebra-precalculus', 'binomial-coefficients', 'combinatorics']"
703309,Functional equation $xf(y)+yf(x)=f(x+y)^2-f\left(x^2\right)-f\left(y^2\right)$,"Here is a nice problem: Let $f:\mathbb R\to\mathbb R$ be a function, $\mathbb R$ is the set of real numbers, satisfying the following properties: $f(1)$ is an integer and $$xf(y)+yf(x)=f(x+y)^2-f\left(x^2\right)-f\left(y^2\right)\text,$$ for all real numbers $ x , y $ . $f(x)=0$ is a solution, another is $ f(x)=x $ . These are all solutions?
Better asking: determine all functions that satisfy the above conditions. I would like to see a complete solution! Thank you!","['algebra-precalculus', 'functions', 'functional-equations']"
703325,"Prove that $(1-\frac{1}{2^2}\cdots 1-\frac{1}{9\,999^2})(1-\frac{1}{10\,000^2})=0.500\,05$ [duplicate]","This question already has answers here : Evaluating the infinite product $\prod\limits_{k=2}^\infty \left ( 1-\frac1{k^2}\right)$ (6 answers) Closed 10 years ago . Prove that $\displaystyle\left(1-\frac{1}{2^2}\right)\left(1-\frac{1}{3^2}\right)\cdots\left(1-\frac{1}{9\,999^2}\right)\left(1-\frac{1}{10\,000^2}\right)=0.500\,05$ Here are all my attempts to solve this problem: So the first thing I thought about is to transform the expression of the form $$\left(1-\frac{1}{n^2}\right)$$ To the expression: $$\left(\frac{n^2-1}{n^2}\right)$$ But in evaluating the product $$\prod_{k=2}^n    \frac{n^2-1}{n^2}$$ seems way complicated than what I'm capable of, I don't know how to evaluate products even if I know that notation. The other idea is to transform again $$\left(1-\frac{1}{n^2}\right)\to \left(1-\frac{1}{n}\right)\left(1+\frac{1}{n}\right)$$ But this isn't helpful in any way. My other attempts were to try to see what happens when I start evaluating this sum, and it turns out that a lot of things cancel out but again no result. I'll be happy if someone could guide me to solve this problem. (I feel that there is some kind of symmetry that I should remark, a symmetry that would allow me to cancel things out and to have my final)","['algebra-precalculus', 'products']"
703330,Why square the result of $x_1 - \bar{x}$ in the standard deviation? [duplicate],"This question already has answers here : Why is there not a simpler way to calculate the standard deviation? (4 answers) Closed 10 years ago . I don't understand the necessity of square the result of  $x_1 - \bar{x}$ in  $$\sqrt{\frac{\sum_{i=1}^{N} (x_i - \bar{x})^2}{N-1}}$$. In fact I don't understand even why is $N - 1$ on the denominator instead of just $N$. Someone could explain it or recommend a good text about it? All books about Errors Theory or even Statistics that I found are either too much abstract or too much simplist.
Thanks in advance.","['statistics', 'standard-deviation']"
703369,How to solve this differential equation system?,"The following system is given: $$
\dot{x} = y + z \\
\dot{y} = x + z \\
\dot{z} = x + y
$$ The first thing I did was to find out the eigenvalues. I found out, that -1 is a doubled and 2 a single eigenvalue, so $$
\lambda_{1,2} = -1,\ \ \lambda_3 = 2
$$ In the excercises ago, the ideas were to determine $ y=e^{\lambda x} \underline{u} $. so I tried to do the following: $$
\begin{pmatrix}
0-\lambda & 1 & 1 \\
1 & 0-\lambda & 1 \\
1 & 1 & 0-\lambda
\end{pmatrix}
$$ Is this step right? I tried to find a scheme as in the excercises ago and in the line $ \dot{x} = y +z$ I don't have an x but one y and one z. When inserting  $ \lambda_1 = -1 $ I have $$
A-\lambda E = \underline{0} \rightarrow
\begin{pmatrix}
1 & 1 & 1 \\
1 & 1 & 1 \\
1 & 1 & 1
\end{pmatrix} = \underline{0}
$$ which means that $ x_i + y_i + z_i = 0\ for\ i ={1,2,3} $. Here is the point on which I don't know how to go on. One solution is the trivial one, so $x=y=z=0$. Can I use this solution? I think that I have to use something like $$
y = C_1 *
\begin{pmatrix}
u_1*e^{\lambda_1 x} \\
u_2*e^{\lambda_1 x}\\
u_3*e^{\lambda_1 x}
\end{pmatrix} + C_2 \begin{pmatrix} ... \end{pmatrix} + C_3 \begin{pmatrix} ... \end{pmatrix}$$ in the case $ \lambda_1 = 1 $, but how to I get my u here exactly?","['systems-of-equations', 'ordinary-differential-equations', 'eigenvalues-eigenvectors']"
703376,The smallest 12 digit natural number for which the sum of its digits is 80.,"So everytime I heard the word smallest natural number of 5 digits for example I do this in my head: 100000...
^
| which means that there must be a one in there: So I type in 1000 and then add more digits to have $$1000\,9999\,9999$$ Now into my calculator I calculated that this is is not 80 rather just 73, so I'll have to add a 7 out there to have $$1007\,9999\,9999$$ But is my answer correct? If not why my method fails and what is the correct method?","['elementary-number-theory', 'algebra-precalculus']"
703381,Simplifying the expression $\sqrt{(1+\cos t)^2+(-\sin t)^2}$,"I wish to find the length of the parametric curve $$x = f(t) = t + \sin t, y = g(t) = \cos t, t \in [0, \pi]$$ The length $L$ is given by $$\int_0^\pi\sqrt{(f'(t))^2+(g'(t))^2}dt = \int_0^\pi\sqrt{(1+\cos t)^2 + (-\sin t)^2}dt$$ Now, what I am able to do with this expression is to simplify it to $$\sqrt{1+2\cos t + \cos^2 t + \sin^2 t}$$ The identity $\sin^2 t + \cos^2 t = 1$ is staring at me, but I do not see how $$\sqrt{2\cos t + 2} = \sqrt{2}\sqrt{\cos t + 1}$$ is going to help me evaluate the integral. Is there another way to simplify the expression so that I'll get an easily computable integral? This task is early in Calc 2, so no very tricky tricks should be needed. I assume I need some expression with [trigonometric identity]-squared so that I will get rid of the square-root, but I honestly don't see how.","['radicals', 'trigonometry', 'calculus']"
703399,Symmetric non-degenerate bilinear forms over $\mathbb{Z}$ and $\mathbb{Q}$,"Consider the four non-degenerate symmetric bilinear forms over $\mathbb{Q}$ given be the matrices
$\bigl(\begin{smallmatrix}
1&0\\ 0&1
\end{smallmatrix} \bigr)$,$\bigl(\begin{smallmatrix}
1&0\\ 0&-1
\end{smallmatrix} \bigr)$,$\bigl(\begin{smallmatrix}
-1&0\\ 0&1
\end{smallmatrix} \bigr)$ and $\bigl(\begin{smallmatrix}
-1&0\\ 0&-1
\end{smallmatrix} \bigr)$.
Considered over $\mathbb{Z}$ these matrices become unimodular symmetric bilinear forms. I want to classify all unimodular symmetric bilinear forms over $\mathbb{Z}$, which are, considered over $\mathbb{Q}$ equivalent to one of the given forms above. Can somebody help me?","['bilinear-form', 'abstract-algebra', 'matrices', 'linear-algebra', 'modules']"
703428,"Software to draw Geometry in 2D, 3D","I am looking for a software to sketch moving figures as this one .
Thanks. See also:","['geometry', 'math-software']"
703430,Geodesics on spheroid,"Describe the geodesics A Spheroid obtained by rotating the ellipse $\frac{x^2}{p^2}+\frac{z^2}{q^2}=1$ around the z-axis where $p, q\gt 0$ Please explain this question explicitly. Thank you:)","['geometry', 'self-learning', 'differential-geometry', 'geodesic']"
703431,"Assuming the axiom of choice, how to find explicit group structure of a given set","Let us assume the axiom of choice. This is equivalent to every nonempty set having group structure. My question is, given some nonempty set, can we define the binary operator in a constructive way just by knowing that it's possible or do we have to be very clever for every case? In particular, I'm interested in how could we can describe and define a group structure on $\mathbb{R} \setminus \mathbb{Q}$.","['elementary-set-theory', 'group-theory', 'axiom-of-choice']"
703464,Directional derivatives of $f \mapsto \max f$,"Consider the functional $\Psi \colon C^{0}([0,1]) \to \mathbb R$ defined by 
$$
\Psi(f):=\max_{x \in [0,1]} f(x)
$$ Find the directional derivative (if it exists) in the generic point $f$ in the generic direction $g$. I should find the limit
$$
\frac{\partial \Psi}{\partial g}(f):=\lim_{t \to 0} \frac{\max(f+tg)-\max f}{t}
$$
but I do not know how to estimate $\max(f+tg)$. Thanks.",['derivatives']
703498,Taylor Series of $\frac{1}{1-\cos x}$,"The problem is, as the title suggests, to find the Power Series Expansion of $\frac{1}{1- \cos x}$ around $x=c$. What I've tried: Direct Computation: Derivatives get very ugly quickly, and don't yield a nice formula that I can recognize as a ""series."" Tried finding the integral of $\frac{1}{1- \cos x}$, finding it's series and then differentiating it to get the new series. Tried reverse of the above, differentiating and finding it's series, then integrating (very messy). Then I tried some substitution ""tricks"", like using the series of $\frac{1}{1-x}$ and then plugging in the series expansion for $\cos x$, but that's a double sum that I struggled to produce anything useful from
:$\displaystyle \sum_{k=0}^\infty\left(\sum_{n=0}^\infty\frac{(-1)^nx^{2n}}{(2n)!}\right)^k$ I am literally at my witts end with this problem. I have spent perhaps a day or two trying to figure it out, because I feel that I am so close - but just barely missing something. I do not want the solution posted - now it's personal and I have to figure it out, but I would greatly appreciate a hint in the right direction, or to point out a mistake that I may be overlooking.","['power-series', 'calculus', 'taylor-expansion']"
703506,Why doesn't this calculation work?,"I want to find some closed form for $\gcd(x^3+1,3x^2 + 3x  + 1)$ but get $7$ which is not always true.","['polynomials', 'divisibility', 'number-theory']"
703510,The Four Transitive Subgroups of $A_7$.,"I know that $A_7$ contains 3 transitive subgroups: $A_7, PSL(2,7), F_{21}$ (Alternating group of 7 elements, $PSL(2,7)$, Frobenius group of order 21). In studying the Galois group structure of degree 7 polynomials, it seems that there is a 4th subgroup of $A_7$ that is transitive. I cannot seem to locate anything to indicate what this 4th group is. Is there indeed a 4th transitive subgroup of $A_7$ distinct from the 3 I have listed above?","['galois-theory', 'finite-groups', 'group-theory', 'abstract-algebra']"
703515,Wikipedia's proof of Schur Product Theorem,"The Schur Product Theorem  basically states that the Hadamard product of two semidefinite matrices is semidefinite. The proof from Wikipedia : ==== Proof of positivity ==== Let $M = \sum \mu_i m_i m_i^T$ and $N = \sum \nu_i n_i n_i^T$ .  Then $$
M \circ N = \sum_{ij} \mu_i \nu_j (m_i m_i^T) \circ (n_j n_j^T) = \sum_{ij} \mu_i \nu_j (m_i \circ n_j) (m_i \circ n_j)^T
$$ Each $(m_i \circ n_j) (m_i \circ n_j)^T$ is positive (but, except in the 1-dimensional case, not positive definite, since they are rank 1 matrices) and $\mu_i \nu_j > 0$ , thus the sum giving $M \circ N$ is also positive. Here, I am not sure how they got the form of $M$ and $N$ with the $\mu$ and $\nu$ in front. Could anyone be kind enough to give me an explanation of what is going on here? thank you!",['linear-algebra']
703517,"Finite Subgroups Of $GL(2,\mathbb{R})$","I have the following question: Is it true that every finite subgroup of odd order in $GL(2,\mathbb{R})$ is cyclic? Thanks!",['group-theory']
703519,Question concerning the mean-value property,"If $U$ is an open subset of $\mathbb C$, the mean square norm is defined as: $$||f||_{L^2 (U)} = {\left(\int_U |f(z)|^2 dxdy\right)}^{1/2}$$ And the norm supremum is defined as: $$||f||_{L^{\infty} (U)} = \sup_{z \in  U} |f(z)|$$ If $f$ is holomorphic in a neighborhood of $D_r(z_0)$, show that for any $0 < s < r,  \exists C > 0$, a constant, which depends on $s$ and $r$ such that: $$||f||_{L^{\infty} (D_s(z_0))}\le C||f||_{L^{2} (D_r(z_0))}$$ And prove that if $\{f_n\}$ is a Cauchy sequence of holomorphic functions in the mean square norm, then the sequence $\{f_n\}$ converges uniformly on every compact subset of $U$ to a holomorphic function.","['cauchy-sequences', 'complex-analysis']"
703549,Geodesics on torus,"Describe the geodesics on Torus $$\sigma (u,v)= ((a+b \cos u)\cos v, (a+b\cos u)\sin v, b\sin u)$$ First fundamental form for torus is $$b^2 du^2 +(a+b \cos u)^2dv^2$$ Consider unit-speed geodesic $$b^2 \dot u^2 +(a+b \cos u)^2\dot v^2=1$$ By Clairaut's theorem, $\rho \sin \phi =\Omega $ where $\Omega$ is constant, $\phi$ is angle the spiral filament makes to the meridian. $$\Rightarrow \gamma \text{ is a geodesic. Results are shown below:} $$ . But I do not understand how to choose $$  0< \Omega < a-b ~~ \text{or} ~~ \Omega = a-b $$ How to find range of $\rho$ here? I cannot understand the range shown from minimum radius $\Omega $ . Please explain clearly. Thank you :)","['self-learning', 'differential-geometry', 'geodesic']"
703572,How can I represent an N dimensional line?,How can I represent a  straight line (between two points) in a N-dimensional space?,['linear-algebra']
703579,Convergence of Random Variables in mean,"If $$E[|X_n-X|^r]\rightarrow0$$ prove that $$E|X_n^r|\rightarrow E|X^r| $$
for every $r\ge 1$ This is the very notation used. I believe it should be: 
$$E[|X_n|^r]\rightarrow E[|X|]^r $$ Attempt I think I can obtain $E[X_n]\rightarrow E[X]$ using Jensen Inequality but I don't think this helps. I have no further idea.","['convergence-divergence', 'probability', 'random-variables']"
703587,$\epsilon - \delta$ proof that $\lim_{x \to a} \sqrt x = \sqrt a$,"I am trying to prove, 
$\lim_{x \to a} \sqrt x = \sqrt a$ As per the definition of limit for every $\epsilon > 0$ there is some $\delta > 0$ such that 
 $ 0 < |x-a| < \delta$ implies $|f(x) - \sqrt a| < \epsilon$ $|\sqrt x - \sqrt a|  = \frac {|x -a|}{\sqrt x + \sqrt a} $ since 
$ 0 < |x-a| < \delta$ $\frac {|x -a|}{\sqrt x + \sqrt a} < \delta$ Can I stop my proof at this point since I found $\epsilon$ ( which is $\delta$ in this case)","['calculus', 'limits']"
703598,Sum of Random Distributions/ Unusual Results,"$$X \sim N(\mu_1,\sigma_1^2)$$
$$Y \sim N(\mu_2,\sigma_2^2)$$
then 
$$X+Y \sim N(0,\sigma_1^2+\sigma_2^2)$$ One way, I tested this to be true is in excel, I used the norm.inv(rand(),0,1) and created an array of 1000 rows/data points. X            Y
1   -0.57306826      0.516810296
2   -0.209113627     0.191298912
3   -1.399749083    -1.195672984
4   1.317783869     0.003841951
5   1.800761285     0.866364269
6   1.259689933     -0.985409706
7   -0.501198314    1.799725917
8   0.209555354     -0.258582777
9   -0.744123211    0.738373998
10  0.595194985     -0.653501771 Then I summed $X$ and $Y$ and then took the average of the two columns and I indeed got a mean of 0, ($\mu_{x+y}=0$)  and a standard deviation ($\sigma_{x+y}=2$). So I said, perfect!! But then an idea occurred to me. What if started from an initial standard normal value, and then summed another and added it to the former as such, in other words, reiteravily adding normal values. $X_t=X_{t-1}+X_{t-2}$
, where each $X \sim N(0,1)$ In excel format, 1   0
2   =NORM.INV(RAND(),0,1)+A1
3   =NORM.INV(RAND(),0,1)+A2
4   =NORM.INV(RAND(),0,1)+A3
5   =NORM.INV(RAND(),0,1)+A4
6   =NORM.INV(RAND(),0,1)+A5
7   =NORM.INV(RAND(),0,1)+A6
8   =NORM.INV(RAND(),0,1)+A7
9   =NORM.INV(RAND(),0,1)+A8
10  =NORM.INV(RAND(),0,1)+A9 Using this approach, when I averaged the entire column of 1000 data points, my mean wasn't zero and my variance also wasn't $1000$ as I had expected. What gives? The variance never equaled 1000 throughout all the simulations of random numbers.
Theoretically, my $E(\sum_1^nX_t)=0$ and the Variance $Var(\sum_1^nX_t)=n\cdot1$","['statistics', 'probability']"
703606,Probability question with bounds?,"If I am given that on Saturday there is 0.6 probability of raining and 0.7 probability of raining on Sunday, then there is a 0.88 chance that it will rain at least one of the days (this is using independence assumption). However, what if nothing about their probability structures were known? Ie. they could be negatively correlated. They could be correlated with $r=1$. What would be the bounds on the probability of it raining at least one day? Im thinking $0.7,0.88$?","['probability-theory', 'probability']"
703618,"""Opposite"" of idempotent operation?","What is the adjective given to a mathematical operation/expression on a variable whose new value can only be described in terms of that variable's existing value? Sequential operation? Example: i = i + 1 Counter-example: i = 3 + 1 I don't know if what I call a ""sequential operation"" is semantically opposite to ""idempotent"" operation/expression but it does seem like it (e.g. the counter-example shown doesn't change value depending on how often you execute it). Why I'm asking I'm trying to distinguish between functions in my computer program where you need to read the existing value into memory before you can compute the value from those that can be expressed as simple literals. I need to state in my design document that my program must support both cases, and I want to use the mathematically correct term for it. (note it doesn't need to be numerical, it could be string concatenation vs string overwriting).","['computer-science', 'computational-mathematics', 'discrete-mathematics', 'terminology']"
703622,Calculating a multivariate probability density - how to invert the function?,"This is an example from a lecture, however it was presented without proof, so I'm trying to find a way to calculate the PDF for the given condition: $X_1$ and $X_2$ are two independent random variables with an uniform distribution on $(0,1)$. For the random variables: $(Z_1, Z_2) := \sqrt{-2 \ln X_1} (\cos 2\pi X_2, \sin 2\pi X_2)$ calculate the PDF. My reasoning is as follows: Use the formula for $Z = Z(X)$: $\;\rho_Z(\mathbf{z}) = \rho_X[\mathbf{x}(\mathbf{z})] \cdot
\left| \frac{ \partial \mathbf{x} }{ \partial \mathbf{z} } \right|$ I can calculate the Jacobian:
$$\frac{\partial (Z_1, Z_2)}{\partial (X_1, X_2)} =
\begin{vmatrix}
-\frac{\cos (2 \pi X_2)}{\sqrt{2} X_1 \sqrt{-\ln{X_1}}} &
-\frac{\sin (2 \pi X_2)}{\sqrt{2} X_1 \sqrt{-\ln X_1 }} \\
-2 \sqrt{2} \pi \sqrt{-\ln X_1} \sin(2 \pi X_2) &
2 \sqrt{2} \pi \cos (2 \pi X_2) \sqrt{-\ln X_1}
\end{vmatrix}
$$ and then the inverse: $$\frac{\partial (X_1, X_2)}{\partial (Z_1, Z_2)} =
\begin{vmatrix}
-\sqrt{2} X_1 \cos (2 \pi X_2) \sqrt{- \ln X_1} &
-\frac{\sin (2 \pi X_2)}{2 \sqrt{2} \pi \sqrt{- \ln X_1}} \\
-\sqrt{2} X_1 \sqrt{-\ln{X_1} \sin (2 \pi X_2)} &
\frac{\cos (2 \pi X_2)}{2 \sqrt{2} \pi \sqrt{- \ln X_1}}
\end{vmatrix}
$$ Then multiply the inverse Jacobian by $\rho_{(X_1, X_2)}(x_1,x_2)$ to get:
$$
\begin{pmatrix}
X_1 \left(1 + \cos (4 \pi X_2) \right) \ln X_1 -
\frac{ \sin^2 (2 \pi x_2) }{2 \pi} &
\frac{ (1 + 4 \pi X_1 \ln X_1) \sin (4 \pi X_2) }{ 4 \pi}
\end{pmatrix}
$$ But how can I obtain the relation this inverse relation $(X_1(Z_1, Z_2), X_2(Z_1, Z_2))$?
Am I suppose to calculate this PDF by different means? All my calculation are from Mathematica. Thanks for any suggestions!","['multivariable-calculus', 'probability']"
703632,A plan to defeat a betting game where the odds of winning are 50/50. Help me understand why it's flawed. [duplicate],"This question already has answers here : Why did my friend lose all his money? (4 answers) Closed 9 years ago . My friend has this plan where he implies that it's impossible to lose, as long as the odds of winning are 50/50 on each bet. His idea is that basically you keep doubling your bet until you win and then start over again. So for example, you bet 1 dollar and you lose, your net profit is now -1 dollar. Now you double your bet to 2 dollars and you lose again so your net profit is -3 dollars. Now you double your bet to 4 dollars and you win. This means you gain 4 dollars and now your net profit is 1 dollar. So you've made a profit. Now you start again. The reasoning here being that it is highly unlikely for you to lose a 50/50 toss x number of times in a row. My counter-argument here is that basically if you go in with 50 dollars with the aim of doubling up to 100 dollars, you have the same odds of winning if you do one bet of 50 dollars or the technique outlined above. I cannot wrap my head around explaining this issue in a clear manner though, so maybe you wonderful folk at Mathematics can help! Oh and I've pointed out that he uses gamblers fallacy in very obscure way, as he insists you need to go back to betting 1 dollar once you've won. This appears to be an obscure case of gamblers fallacy to me as it implies there is some hidden force which are changing the odds on each individual coin toss.","['probability', 'gambling']"
703633,Locally complete intersection in a fiber,"Let Y be an affine noetherian scheme, $Z = V_+(F_1, \ldots, F_r)$ a closed subscheme of $\mathbb{P}^d_Y$ that is flat over Y. Let $y_0 \in Y$ be a point such that $Z_{y_0}$ is a complete intersection in $\mathbb{P}^d_{k(y_0)}$. Set $r = dim Z_{y_0}$. I am trying to show that this implies that there is an open neighborhood V of Y such that for all $y \in V$we have that $Z_y$ is a complete intersection in $\mathbb{P}^d_{k(y)}$ of dimension $r$ for every $ y \in V$. I am having no luck here, however.
I have tried the following: Look at the case $r=2$ and show it there. Here still no luck, and the methods I thought of was quite ugly. One was to try to consider $(F_2)/rad(F_1)$ as some sort of quasicoherent sheaf and show something regarding the support. It didn't work however. Trying to just invert coefficients in polynomials in $F_i$. However, I couldn't show that inverting certain coefficients (those coefficients of $F_i$ not vanishing on $y_0$) gave a local complete intersection. Any hints or solutions are welcome!",['algebraic-geometry']
703634,Describe the fibers of $\phi$ and that $\phi$ is a homomorphism.,"Define $\phi: \mathbb{R}^x \mapsto \{\pm1\}$ by letting $\phi(x)$ be $x$ divided by the absolute value of $x$. Describe the fibers of $\phi$ and that $\phi$ is a homomorphism. Need help getting a grasp of this topic. For reference, this is Dummit and Foote, 3ed., section 3.1, question 6. Description of the fiber The only two possible fibers from the set $\{\pm1\}$ are the fibers $X_{-1}$ and $X_1$. By definition, these are represented as follows $X_{1} = \phi^{-1} (1) = \{x \in \mathbb{R} | \phi(x) = 1\}$ $X_{-1} = \phi^{-1} (-1) = \{x \in \mathbb{R} | \phi(x) = -1\}$ However, since the mapping $\phi$ is defined as $\phi(x) = \frac{x}{|x|}$, we can re-write the above as $X_{1} = \phi^{-1} (1) = \{x \in \mathbb{R} | x>0\}$ $X_{-1} = \phi^{-1} (-1) = \{x \in \mathbb{R} | x<0\}$ Homomorphism ( of particular concern) Let $x,y \in \mathbb{R}^x$. Consider three cases. ( Do I need to do three cases? ) If $x>0$, $y<0$, then $xy<0$. $\phi(xy) = -1 = 1 \times -1 = \phi(x)\phi(y)$ If $x>0$, $y>0$, then $xy>0$. $\phi(xy) = 1 = 1 \times 1 = \phi(x)\phi(y)$ $x<0$, $y<0$, then $xy>0$. $\phi(xy) = 1 = -1 \times -1 = \phi(x)\phi(y)$ Thus, $\phi$ is a homomorphism.","['proof-verification', 'group-theory', 'abstract-algebra']"
703635,Use implicit differentiation to find derivative,"$$x\sin(4x+5y)=y\cos(x)$$
I am trying to use implicit differentiation to find dx/dy for this problem but the answer i keep getting is $$4x\cos(4x+5y)=-y\sin(x)$$ and I am stuck.","['implicit-differentiation', 'calculus', 'derivatives']"
703643,Partial fraction decomposition of $\frac{1}{x^{2n}+a^{2n}}$,"I came across a formula for the partial fraction decomposition of $ \displaystyle \frac{1}{x^{2n}+a^{2n}}$. It seems correct (at least for $n=1,2$, and $3$). But how is it derived? $$\frac{1}{x^{2n}+a^{2n}} = \frac{1}{na^{2n-1}} \sum_{k=0}^{n-1} \frac{a -x \cos (\frac{2k+1}{2n} \pi)}{\Big(x-a \cos (\frac{2k+1}{2n} \pi) \Big)^{2} +a^{2} \sin^{2} (\frac{2k+1}{2n} \pi) }$$ EDIT: The denominators of the partial fractions can be rewritten as $$x^{2}-2ax\cos \left(\frac{2k+1}{2n} \pi \right) +a^{2}$$ If you factor $ \displaystyle x^{2n}+a^{2n}$ over the complex numbers and then rearrange terms and multiply pairwise you get quadratic factors like that. So at least that makes sense.","['trigonometry', 'calculus', 'algebra-precalculus', 'partial-fractions']"
703653,variation of the binomial theorem,"Why does: $$ \sum_{k=0}^{n} k \binom nk p^k (1-p)^{n-k} = np $$ ?
Taking the derivative of: $$ \sum_{k=0}^{n}  \binom nk p^k (1-p)^{n-k} = (1 + [1-P])^n = 1 $$ does not seem useful, since you would get zero. And induction hasn't yet worked for me, since – during the inductive step – I am unable to prove that: $$ \sum_{k=0}^{n+1} k \binom {n+1}{k} p^k (1-p)^{n+1-k} = (n+1)p  $$ assuming that: $$ \sum_{k=0}^{n} k \binom {n}{k} p^k (1-p)^{n-k} = np  $$",['probability-theory']
703685,What are the pre- requisites required to learn Real Analysis? [closed],"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 6 months ago . The community reviewed whether to reopen this question 6 months ago and left it closed: Original close reason(s) were not resolved Improve this question I already have quite a solid foundation in Single and Multivariable calculus. But how do I know if I'm prepared to tackle real analysis? Before I get into Real Analysis, I want to know everything that I need to know first. Reading a book, but having to look up sources on the basics that I missed, is a complete waste of time. Please advise me on everything that I need to know before studying Real Analysis. Please outline what to expect from Real Analysis, and recommend textbook for beginners.",['real-analysis']
