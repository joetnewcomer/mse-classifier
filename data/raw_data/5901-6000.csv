question_id,title,body,tags
43891,How to calculate the middle of a line?,"My question is following. I have a line with a given $(X_1, Y_1)$ and $(X_2, Y_2)$ coordinates ( see figure below ). I need to calculate coordinates of the middle of this line $(X, Y)$. I tried to use classical method of finding distance between two coordinates, but it works only when the line is situated horizontally. Could anybody help me with a formula to find coordinates of the middle of a given line please? Thanks beforehand.","['geometry', 'coordinate-systems']"
43929,Why are projective morphisms closed?,"It is a well-known fact that if $X$ is a projective curve and $p \in X$ a smooth point, then any rational map $X \to Y$, $Y$ a projective variety, extends to a rational map $X \to Y$ regular at $p$. This is proposition I.6.8 in Hartshorne (in the case of $X$ an abstract non-singular curve), for example. However, the two proofs I have seen both assume that it suffices to consider the case $Y = \mathbb{P}^n$. As I understand it, this is because morphisms of projective varieties are proper, and in particular the image is closed. Where I can find a proof of this, in the case of varieties only? I found a proof here by Akhil Mathew, but I got lost when he started talking about base change.",['algebraic-geometry']
43930,Prerequisites/Books for A First Course in Linear Algebra,"What mathematical knowledge do I need to begin studying linear algebra? In particular, how much calculus do I need to know? Also, do you have a favorite linear algebra book you can recommend?","['big-list', 'linear-algebra', 'book-recommendation', 'reference-request']"
43934,How can I see alternative trigonometry solutions on a calculator?,"When doing inverse trigonometric equations on a calculator, only the lowest positive solution is shown. How can I see alternative solutions (specifically for a Casio FX85ES)? Current behaviour:
$$sin^{-1}{0.5} = 30$$ Desired behaviour:
$$sin^{-1}{0.5} =  30  
                , 150
                , 390
                , ...$$","['trigonometry', 'calculator']"
43944,fundamental theorem of ODE,"I have some questions regarding the following theorems: Theorem Let $A$ be an open subset of a Banach space $W$, let $I$ be an open interval in $\mathbb{R}$, and let $F$ be a continuous mapping from $I \times A$ to $W$ which is locally uniformly Lipschitz in its second variable. Then for any point $<t_0,\alpha_0>$ in $I \times A$, for some neighborhood $U$ of $\alpha_0$ and for any sufficiently small interval $J$ containing $t_0$, there is a unique function $f$ from $J$ to $U$ which is a solution of the differential equation passing through the point $<t_0, \alpha_0>$. the solution function is proved to be the fixed point of the mapping $K: f\rightarrow g$, where $f:J \rightarrow  A$ is any continuous mapping and $g:J \rightarrow W$ is defined by 
$$ g(t)=\alpha_0+\int^t_{t_0}F(s,f(s))ds$$ the proof starts by choosing a neighborhood $L \times U$ of $<t_0,\alpha_0>$ on which $F$ is bounded and Lipschitz in $\alpha$ uniformly over $t$. Question 1: why not choose $I \times A$ instead of the neighborhood $L \times U$. Is the purpose to make $F$ bounded? A lemma to the above theorem:
Let $g_1$ and $g_2$ be any two solutions of $d\alpha/dt=F(t,\alpha)$ through $<t_0,\alpha_0>$. Then $g_1(t)=g_2(t)$ for all t in the intersection $J=J_1 \cap J_2$ of their domains. Proof by contradiction. Otherwise there is a point $s$ in $J$ such that $g_1(s) \neq g_2(s)$. Suppose that $s>t_0$, and set $C=\{t:t>t_0 \mbox{and} g_1(t)\neq g_2(t)\}$ and x = glbC. The set $C$ is open, and therefore $x$ is not in $C$. That is $g_1(x)=g_2(x)$ Question 2: why is the set $C$ open? Call this common value $\alpha$ and apply the theorem to $<x, \alpha>$. With $r$ such that $B_r(\alpha) \subset C$ [ Edit (T.B.): This should be $B_r(\alpha) \subset A$], we choose $\delta$ small enough so that the differential equation has a unique solution $g$ from $(x-\delta,x+\delta)$ to $B_r(\alpha)$ Question 3: why $B_r(\alpha)$ has to be a subset of $C$? Why is this possible? The above lemma allows us to remove the restriction on the range of $f$ Question 4: Can you elaborate this? and why removing the restriction useful? Thanks Edit (T.B.): This is taken from Section 6 of Lynn H. Loomis, Shlomo Sternberg, Advanced Calculus , Jones and Bartlett Publishers, 1990.","['ordinary-differential-equations', 'analysis']"
43956,Understanding relation between Quotient Space and $S^1$,"There is this example at the Wikipedia article on Quotient spaces (QS): Consider the set $X = \mathbb{R}$ of all real numbers with the ordinary topology, and write $x \sim y$ if and only if $x−y$ is an integer. Then the quotient space $X/\sim$ is homeomorphic to the unit circle $S^1$ via the homeomorphism which sends the equivalence class of $x$ to $\exp(2πix)$. I understand relations, equivalence relation and equivalence class but quotient space is still too abstract for me. This seems like a simple enough example to begin with. I understand (sort of) the definition but I can't visualize. And by this example and others, there is a lot of visualizing going on here! torus, circles etc.","['general-topology', 'quotient-spaces']"
43958,Cyclic groups whose every non-identity member is a generator,"Let $G$ be a cyclic group. There's a theorem which states that if $|G|$ is a prime, then every non-identity member of $G$ is a generator. What about a cyclic group whose order is not prime: Is there such a group whose every non-identity member is a generator? Are there other necessary/sufficient conditions regarding groups whose every non-identity member is a generator? (Beyond primality of $|G|$.)","['finite-groups', 'group-theory', 'abstract-algebra']"
43972,Largest Part of a Random Weak Composition,"Suppose we have a weak composition of the integer n into k parts. (A weak compositions is essentially a partition in which order matters and 0 is allowed) My question is, what is the expected value of the largest part of the composition? The assumption is that all compositions have equal probability.","['probability', 'combinatorics']"
43974,Importance of Linear Algebra [closed],"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 7 years ago . Improve this question In one of his online lectures Benedict Gross comments that one can never have too much Linear Algebra.  Also, looking around it seems like I can find comments to the effect that Linear Algebra has more importance than other sub-disciplines of mathematics.  If true, why is Linear Algebra the most important sub-discipline of mathematics?  If Benedict Gross is correct, why can't one have enough Linear Algebra?","['linear-algebra', 'soft-question']"
43995,Unique Groups for Game Tournament,"I am trying to put together a Munchkin game tournament where I am assuming I will have 16 people coming to my tournament. As part of that, I want to have as many games as possible where people are not playing against the same player twice. (So, every combination is unique.) I can easily come up with these groups for three rounds of the tournament. Is it possible to do more? If so, can you point me in the right direction? Unfortunately, I think I am confusing my combinations and permutations and it's leaving me stumped.","['permutations', 'combinatorics']"
44004,"Why do books say ""of course"" it's never that simple, differential equations?","I'm reading about differential equations. It says that a first order ODE may be written: $$M(x,y)dx + N(x,y)dy = 0.$$ Then if there is some function $f(x,y)$ such that  $\frac{\partial f}{\partial x}= M$ and  $\frac{\partial f}{\partial y}= N$ you can write:
$$\frac{\partial f}{\partial x}dx+\frac{\partial f}{\partial y}dy=0.$$ Then it says "" Of course , the only way that such an equation holds is if $\frac{\partial f}{\partial x}= 0$ and  $\frac{\partial f}{\partial y}= 0$. And this entails that the function $f$ be identically constant. $f(x,y) =c$."" Here is the whole excerpt: I don't see why this is the case. First, I thought  $\frac{\partial f}{\partial x}$ and  $\frac{\partial f}{\partial y}$ were not zero but rather  $\frac{\partial f}{\partial x}=M$ and $\frac{\partial f}{\partial y}=N$. Also, if two things add to zero they both don't need to be zero, one can be negative the other positive? I'm confused, please help. The fact that it says ""of course"" is making me feel pretty dumb. This is from the section on ""The Method of Exact Equations"" Thanks.",['ordinary-differential-equations']
44009,Does finiteness of $\lim\limits_{x\to\infty}f(x)$ and $\lim\limits_{x\to\infty}f'(x)$ imply $\lim\limits_{x\to\infty}f'(x)=0$?,"Assume that $f:{\bf R}\to{\bf R}$ is differentiable on ${\bf R}$, and both of $\lim\limits_{x\to\infty}f(x)$ and $\lim\limits_{x\to\infty}f'(x)$ are finite. Geometrically, one may have
$$\lim_{x\to\infty}f'(x)=0$$ 
Here is my question : How can one actually prove it? By definition, it suffices to show that $$\lim_{x\to\infty}\lim_{h\to 0}\frac{f(x+h)-f(x)}{h}=0$$ i.e. $$\forall \epsilon>0~\exists M>0\quad \textrm{s.t.}\quad x>M\Rightarrow \left|\lim_{h\to 0}\frac{f(x+h)-f(x)}{h}\right|<\epsilon$$ For large enough $M$ and small enough $\epsilon$, one has 
$$|f(x+h)-f(x)|<\tilde{\epsilon}$$ But I have no idea how to go on.","['calculus', 'real-analysis']"
44014,RSA: is it easy to find the public key from the secret key?,"I know that it is not easy to find the secret key from the public key.
Is it relatively easy to find the public key from the secret key for scientists in the field? If the answer is yes, then is there any cryptography system such that only a particular person can encode and any one in public can decode?
For an example scenario, a king writes his order and encodes it using his (secret) public key. Then his soldiers decode the code using the (open) secret key to check if it was truly written by the king.","['cryptography', 'number-theory']"
44041,Irreducible polynomial modulo every prime?,"There exist irreducible polynomials in $\mathbb{Z}[x]$ (e.g. $x^4-10x^2+1$) which are reducible modulo every prime $p$. (A proof can be found in J.S. Milne's Fields and Galois Theory , page 13.) This kind of polynomial is so ""bad"". I want to know if there exists some non-trivial ""good"" polynomials. State precisely: Does there exist a polynomial $f(x)\in \mathbb{Z}[x]$ with degree $>1$ such that $f(x)$ is irreducible in $\mathbb{F}_p[x]$ for any prime number $p$?","['irreducible-polynomials', 'abstract-algebra', 'polynomials']"
44069,The ring of power series in z with a positive radius of convergence,"Let $A$ be the ring of power series in $z$ with a positive radius of convergence, where all coefficients are complex numbers. What is the name of $A$? Does it have a special name? I want to show that if $f(z)\in A$ has nonzero constant, then $f(z)$ is invertible in $A$. How can I prove this? I know that any formal power series is invertible if the constant is not zero. But how can I show that the radius of convergence of $1/f(z)$ is positive? How can I know this result from complex analysis? I studied complex analysis for a semester, but I don't remember whether I learned this or not. I thought I have heard some similar thing, but I can't find out it in the textbook(Silverman)","['commutative-algebra', 'complex-analysis']"
44071,Boundary of a Borel set,"Let $X$ be a topological space and $B$ is a Borel set of this space, i.e. $B\in\mathcal{B}(X)$ where $\mathcal{B}(X)$ is the smallest $\sigma$-algebra which contains all open subsets of $X$. Let $B\subset A$ where $A$ is compact. Is it true that $A' = (A\setminus B) \cup\partial B$ is a compact set? If it is not true in general, does it hold if $X$ is also metrizable (separable)? Finally, is a condition that $B$ is a Borel set is crucial?","['general-topology', 'measure-theory']"
44080,approximating geodesic distances on the sphere by euclidean distances of a transformed sphere,"Is there a way to find a function $F:\mathbb S^2 \rightarrow \mathbb R^3$ of class $C^1$, minimizing
$$\int_{\mathbb S^2\times\mathbb S^2}(d(F(x),F(y))−\delta(x,y))^2 dx dy$$
, where $d$ stands for the euclidean distance in $\mathbb R^3$ and $\delta$ the geodesic distance on the sphere $\mathbb S^2$? Or $d$ could stand for the squared euclidean distance, and $\delta$ the square geodesic distance, if this makes the problem simpler. The goal is thus to approximate geodesic distances by euclidean distances of transformed points. I tried to perform a Multi-Dimensional Scaling to get this least square solution for a finite set of point, but it seems that the solution was just the identity (or a uniform scaling)... is that right? Thanks!","['geometry', 'spherical-geometry', 'differential-geometry']"
44090,Please explain this definition of symmetry,"I am reading an article ""Differential Equations: Not just a bag of tricks"" in the mathematics magazine. The author has given elementary examples of symmetry ($y=x^2$ symmetric about $y$ axis, $y=x^3$ symmetric about origin, $y=\sin x$ symmetric in translation by $2\pi$) and then proceeds to define: These transformations are symmetries
  of $f$ because they map the graph of
  $f$ to itself. In general, for a
  function $f : \mathbb{R} \rightarrow \mathbb{R}$
  , a symmetry of $f$ is a
  continuous map from $\mathbb{R}^2$ to
  $\mathbb{R}^2$ that maps the graph of
  $f$ to itself and has a continuous
  inverse. I do not understand why the introduction of $\mathbb{R}^2$ was needed and why the inverse was mentioned. Moreover, what is the importance of stressing continuous. Thank you.","['transformational-geometry', 'algebra-precalculus', 'functions']"
44093,Trouble with absolute value in limit proof,"As usual, I'm having trouble, not with the calculus, but the algebra. I'm using Calculus, 9th ed. by Larson and Edwards, which is somewhat known for racing through examples with little explanation of the algebra for those of us who are rusty. I'm trying to prove $$\lim_{x \to 1}(x^2+1)=2$$ but I get stuck when I get to $|f(x)-L| = |(x^2+1)-2| = |x^2-1| = |x+1||x-1|$. The solution I found says ""We have, in the interval (0,2), |x+1|<3, so we choose $\delta=\frac{\epsilon}{3}$."" I'm not sure where the interval (0,2) comes from. Incidentally, can anyone recommend any good supplemental material to go along with this book?","['absolute-value', 'algebra-precalculus', 'limits']"
44098,Bézout-like identities for linear operators,"As usual, when I pose a question here the answer I receive generates more questions. Today I posed myself a problem originating from this answer by Joel Cohen. Let $V$ be a finite dimensional vector space over an arbitrary field. Let us agree to say that the linear operators $A, B$ verify a Bézout-like identity if there exist linear operators $X, Y$ such that 
  $$I=XA+YB,$$
  where $I$ denotes the identity mapping. Problem : Find necessary and sufficient conditions for $A$ and $B$ to verify a Bézout-like identity. I believe the answer lies somewhere around $\ker(A), \ker(B)$. For example, if $A$ and $B$ are associated to the block $n \times n$ matrices $$A \equiv \begin{bmatrix} \mathbf{0} & \mathbf{0} \\ \mathbf{0} & P_{k \times k} \end{bmatrix}, \quad B \equiv \begin{bmatrix} Q_{h \times h} & \mathbf{0} \\ \mathbf{0} & \mathbf{0} \end{bmatrix}$$ with nonsingular $P, Q$, then we can take $$X= \begin{bmatrix}  \mathbf{0} & \mathbf{0} \\ \mathbf{0} & P^{-1} \end{bmatrix}, \quad Y=\begin{bmatrix} Q^{-1} & \mathbf{0} \\ \mathbf{0} &  \mathbf{0} \end{bmatrix}$$ which yield a Bézout-like identity if and only if $k +h=n$. Moreover, if $k+h < n$, then we can be sure that no Bézout-like identity is possible. This could suggest that the sought condition is $$\ker(A) \oplus \ker(B)=V.$$","['matrices', 'linear-algebra', 'block-matrices']"
44099,Quotient of free module,Let $R$ be a commutative ring with $1$ and let $J$ be a proper ideal of $R$ such that $R/J \cong R^n$ as $R$-modules where $n$ is some natural number. Does this imply that $J$ is the trivial ideal? Basically I am trying to prove/disprove that if $J$ is a proper ideal of $R$ and $R/J$ is free then $J=0$ and above is my work.,"['modules', 'ideals', 'abstract-algebra']"
44113,What's the value of $\sum\limits_{k=1}^{\infty}\frac{k^2}{k!}$?,"For some series, it is easy to say whether it is convergent or not by the ""convergence test"", e.g., ratio test. However, it is nontrivial to calculate the value of the sum when the series converges. The question is motivated from the simple exercise to determining whether the series $\sum\limits_{k=1}^{\infty}\frac{k^2}{k!}$ is convergent. One may immediately get that it is convergent by the ratio test. So here is my question: What's the value of $$\sum_{k=1}^{\infty}\frac{k^2}{k!}?$$","['sequences-and-series', 'calculus', 'exponential-function', 'real-analysis', 'factorial']"
44122,Ramification of an integral closure of $\mathbb{C}\{z\}$,"Let $\mathbb{C}\{z\}$ be the ring of convergent series in one
variable over $\mathbb{C}$, $K$ the fraction field of
$\mathbb{C}\{z\}$, $E$ a Galois extension of $K$ and
$\mathcal{O}_{E}$ the integral closure of $\mathbb{C}\{z\}$ in $E$. We have naturally the diagram induce by the inclusion maps: $$\begin{array}{ccc}
\mathbb{C}\{z\} & \rightarrow & \mathcal{O}_{E} \\
\downarrow & & \downarrow \\
K & \rightarrow & E.
\end{array}$$ Now I'm requested to prove that the dual of the inclusion
$\mathbb{C}\{z\} \hookrightarrow \mathcal{O}_{E}$, namely the map of
topological spaces $Spec(\mathcal{O}_{E}) \rightarrow
Spec(\mathbb{C}\{z\})$, is ramified only over $0$. As a first step I calculated $Spec(\mathbb{C}\{z\})$, which should be
the set $\{(0),(z)\}$, where $(z)$ is the maximal ideal. In specific
this means that $\mathbb{C}\{z\}$ is a Discrete Valuation Ring and I
have to compute the ramification explicitly only over two points.
Moreover another consequence is that $\mathcal{O}_{E}$ is a Dedekind
domain. Unfortunately I have no idea on how to go further. I computed the
valuation induced by $\mathbb{C}\{z\}$ on $K$, but it doesn't seem
to bring anywhere. I thank you previously for your help.","['algebraic-geometry', 'algebraic-number-theory']"
44126,Primes of the form $n^2+1$ - hard?,"I met a student that is trying to prove for fun that there are infinitely many primes of the form $n^2+1$. I tried to tell him it's a hard problem, but I lack references. Is there a paper/book covering the problem? Is this problem really hard or I remember incorrectly?","['prime-numbers', 'reference-request', 'open-problem', 'number-theory']"
44139,"How many solutions are there to $F(n,m)=n^2+nm+m^2 = Q$?","Let $n,m$ be two positive integers, we consider:
$$F(n,m)=n^2+nm+m^2$$ Let $Q$ be one value reach by $F(n,m)$. How many different pairs $(n,m)$ verify $F(n,m)=Q$?","['polynomials', 'algebraic-number-theory', 'number-theory']"
44149,Help on a proof,"I'm studying a proof on this book http://www.math.ucsd.edu/~atparris/papers/book.pdf I can't copy here the proof I'm studying because it is a little bit long. I only need help on a little statement. I don't understand in the page 180 of the book why we can choose $\alpha,\alpha^\prime\in\{\alpha_1,\alpha_2,\alpha_3\}$ distinct such that $x_\alpha-x_{\alpha^\prime}\not\in\{x_\beta-x_{\beta^\prime},x_{\beta^\prime}-x_\beta\}$.","['logic', 'elementary-set-theory', 'proof-explanation']"
44152,Casimir element invariance,"I'm sorry to bother but i'm having some problems in proving that, given a simple Lie Algebra L of finite dimension $n$ (equipped with the Killing form) and its enveloping universal algebra U(L), then the element (Casimir):
c = $\sum x_iy_i$ where $(x_i)_i$ is a basis and $(y_i)_i$ is its dual basis (with respect to the Killing form) doesn't depend on the choice of a particular basis. The argument should be just related to linear algebra i guess. I tried to take another basis and the change-of-coordinates-matrix but i can't get to the solution. Can someone help me? Am I missing something? Thank you",['linear-algebra']
44154,Conjugacy classes of maximal tori in PGL2: only 2?,"If $K$ is a field, and $F$, $L$ are two distinct quadratic extensions of $K$, then must the subgroups of $\operatorname{PGL}(2, K)$ defined by $F$ and $L$ be conjugate? To define the subgroup, identify the field $F$ with a two-dimensional $K$-vector space.  The subgroup is the subgroup induced by the action of the nonzero elements of $F$ on this vector space. Different identifications yield conjugate subgroups. Everything makes good sense when the absolute Galois group of the field is locally cyclic, so that extension fields are extremely unique.  However, I'm not sure this makes much sense for a field like $\mathbf{Q}$.  What goes wrong with (at least one of) the following arguments: They should not be conjugate: Surely conjugacy would lift to an isomorphism of $K$-algebras between $F$ and $L$?  Surely it simply defines an isomorphism of the groups of units of $F$ and $L$?  However, I think not all quadratic fields over $\mathbf{Q}$ have the same group of units (the torsion parts differ at least in $\mathbf{Q}[i]$ and $\mathbf{Q}[ω]$). They should be conjugate: I believe conjugacy classes of maximal tori correspond in some way to elements of the Weyl group.  The Weyl group has two elements, and the identity element corresponds to the subgroup defined by $K$ acting on $K ⊕ 0$.",['group-theory']
44160,Continued proportion implies $(a^2+b^2+c^2)(b^2+c^2+d^2)=(ab+bc+cd)^2$,"I am trying to find a tricky way to proof these: If $a,b,c,d$ are in continued proportion, prove that $$(a^2+b^2+c^2)(b^2+c^2+d^2)=(ab+bc+cd)^2 ,$$ This result could be extended to $$(a^2+b^2+c^2+d^2)(b^2+c^2+d^2+e^2)=(ab+bc+cd+de)^2$$ when $a,b,c,d,e$ are in continued proportion. The standard way for solving them could be putting $\frac{a}{b}=\frac{c}{d}=k$ then followed by substitution and which is followed by tedious algebraic manipulations,but that is not what I am looking for could these be solved in a less easy way using some other algebraic method/tricks? Please explain.","['geometric-progressions', 'algebra-precalculus']"
44163,Are there infinitely many primes next to smooth numbers?,"A side discussion over on this question has left me curious: is there any $B$ for which it's known that there are infinitely many primes adjacent to $B$-smooth numbers (i.e., for which there are infinitely many primes of the form $n\pm 1$, where all the prime factors of $n$ are $\leq B$)?  Of course, the Lenstra-Pomerance-Wagstaff conjecture about the distribution of Mersenne primes (and specifically just the conjecture that there are infinitely many) implies this conjecture in the sharpest possible form (with $B=2$), but I'm wondering if results of this form have been proven for any value of $B$.","['prime-numbers', 'number-theory']"
44171,the pseudometric induced by a measure,"Let $(X, \Sigma, \mu)$ be a measure space. We can define a pseudometric $d$ on $\Sigma$ in the following way: $$d(A, B) = \mu(A\bigtriangleup{}B)$$ where $A\bigtriangleup{}B = (A\cup{}B)\setminus{}(A\cap{}B)$ is the symmetric difference. Does this metric have a name? What does the topology induced by $d$ on $\Sigma$ tell us about the measure?","['general-topology', 'measure-theory', 'metric-spaces']"
44179,Signs in the natural map $\Lambda^k V \otimes \Lambda^k V^* \to \Bbbk$,"Let $V$ be a finite-dimensional vector space over a field $\Bbbk$.  Let $V^*$ denote its dual.  I strongly suspect that there is a natural map
$$\Lambda^k V \otimes \Lambda^k V^* \to \Bbbk$$
that looks something like
$$v_1 \wedge \dotsb \wedge v_k \otimes \alpha_1 \wedge \dotsb \wedge \alpha_k \mapsto \sum_{\sigma} {\operatorname{sgn} \, \sigma}\prod_i \alpha_i(v_{\sigma(i)}).$$
What does the correct, natural formula look like?  In particular, what is the correct sign convention?","['exterior-algebra', 'linear-algebra', 'multilinear-algebra']"
44191,How to prove uniform continuity?,"I'm starting out university math and I'm struggling with understanding how to prove uniform continuity. I think I understand the concept of finding a $|x-x_0|<\delta$ for $|f(x)-f(x_0)|<\epsilon$ but all the examples I have found so far have been very vague in explaining how they relate to each other. I have figured out that the smallest $\delta$ has something to do with the steepest part of the $f()$ function in such way that if $\delta$ satisfies $\epsilon$ in the steepest climb or descent, it will satisfy it everywhere else too. But the problem I'm facing is that I don't always understand how I'm supposed to figure out the relation between these two variables. I am able to solve an example like $f(x) = 5x+8$ like so: $x \geq 0, x=x_0+\delta, |f(x)-f(x_0)| = |5(x_0+\delta)+8-5x_0-8| = 5|\delta|$ and thus $5|\delta|<\epsilon$ so the solution is $\delta < \frac{\epsilon}{5}$. This seems easy and reasonable. Here is an example that I can't crack: $f:[0,\infty[\rightarrow\mathbb{R}, f(x)=x^2$ So what I did first was define $x_0 \geq 0, x=x_0+\delta$ Then I wrote $|f(x)-f(x_0)|<\epsilon$ where $|f(x)-f(x_0)|$ is $|(x_0+\delta)^2 - x_0^2| = |x_0^2 + 2x_0\delta + \delta^2 - x_0^2| = |2x_0\delta + \delta^2|$ At this point many of the examples on the net are saying that I can break this in two parts, $|2x_0\delta| < \frac{\epsilon}{2}$ and $|\delta^2| < \frac{\epsilon}{2}$ and solve them separately. So I get $\delta < \sqrt{\frac{\epsilon}{2}}$ and $\delta < \frac{\epsilon}{4x_0}$ So what am I supposed to do with these two deltas I got? And why am I supposed to break it in parts? Shouldn't I get a single value for the $\delta$? I understand that because $x^2$ grows at an increasing speed, no $\delta$ can satisfy all $\epsilon$ (and thus it's not uniformly continuous). But I don't know how I'm supposed to get there. Also, if i confine the $f(x)=x^2$ to $f:[0,5]\rightarrow\mathbb{R}$, how can I then show that it's uniformly continuous? Many of the documents i've found by googling ""uniform continuity"" seem to take shortcuts and I get lost. If someone can explain this in a ""layman way"" clearly I would be very grateful!",['analysis']
44206,How many points in the xy-plane do the graphs of $y=x^{12}$ and $y=2^x$ intersect?,"The question in the title is equivalent to find the number of the zeros of the function $$f(x)=x^{12}-2^x$$ Geometrically, it is not hard to determine that there is one intersect in the second quadrant. And when $x>0$, $x^{12}=2^x$ is equivalent to $\log x=\frac{\log 2}{12}x$. There are two intersects since $\frac{\log 2}{12}<e$. Is there other quicker way to show
  this? Edit : This question is motivated from a GRE math subject test problem which is a multiple-choice one(A. None B. One C. Two D.Three E. Four). Usually, the ability for a student to solve such problem as quickly as possible may be valuable at least for this kind of test. In this particular case, geometric intuition may be misleading if one simply sketch the curve of two functions to find the possible intersect.",['calculus']
44213,Construction of representations,"Is there an example, where given a conjugacy class in a finite group, can we construct an irreducible representation from it?","['geometry', 'representation-theory', 'group-theory']"
44223,History Question - Branch Cut,My professor began discussing branch cuts in class today and mentioned that he did not know the origin of the term. Does anyone know the origin of the term and perhaps a source that talks about it?,"['math-history', 'complex-analysis']"
44225,What infinity is greater than the continuum? Show with an example,The diagonal argument establishes that the continuum is greater than countable infinity. What is an example of the next infinity (or any greater infinity) and how can it be shown that there is no 1:1 correspondence with the continuum?,"['cardinals', 'infinity', 'elementary-set-theory']"
44240,Looking for a good precalculus/algebra reference,"I'm working my way through Calculus, 9th ed. by Larson and Edwards in independent study. The problem is that many of the exercises and examples use a lot of algebra tricks that are glossed over and assumed knowledge on the part of the student. Now, when I took precalc in high school I was a total layabout and didn't really absorb many of the finer points as far as some specific topics go (nested absolute value inequalities, for instance) and I'm having a hard time working through many of the exercises. I have no trouble understanding the calculus aspect of the problems, but fail miserably on some of the harder algebraic aspects. I know I'm not the only one struggling with this, though -- an overarching criticism I've found of this book is that it assumes too much algebra knowledge of undergrad math students and doesn't fully explain any steps. What I'm really looking for is a precalc-level algebra reference with good examples that I can turn to for specific topics in algebra when I encounter a question I have trouble with. Can anyone recommend such a thing? Edit : I'd also like to point out that I have a kindle, so cheaper suggestions for good kindle books are welcome. That's assuming, of course, that kindle is a satisfactory medium for such a thing. I'm not sure.","['reference-request', 'self-learning', 'calculus', 'algebra-precalculus']"
44245,Shrinking Group Actions,"Suppose $H\subset G$ is a subgroup of a topological group $G$, and $Y\subset X$ is a subspace of a topological space $X$. Suppose we are given a continuous group action $\rho : G\times X\rightarrow X$ on $X$, and suppose that $Y$ is $H$ stable, that is $h.y \in Y$ for all $h\in H$ and $y\in Y$. You can form the quotient spaces $H\setminus Y$ and $G \setminus X$, and there is a natural, continuous, in general neither injective nor surjective map $\theta : H\setminus Y\rightarrow G\setminus X$. I am looking for conditions that assure this is a homeomorphism. You can show easily that $\theta$ is onto $\mathrm{iff}~Y$ intersects all orbits, and one to one $\mathrm{iff} ~ \forall y\in Y, H.y=G.y\cap Y$. So I'll suppose these two conditions. Under what general conditions on $Y,~X,~H,~G$ and $\rho$ (like $Y$ being a closed subspace (or even compact), $H$ being a closed subgroup (or possibly compact) and/or $\rho$ being a proper group action) is $\theta$ a homeomorphism? All spaces $X$ I have in mind are Hausdorff, but not necessarily locally compact. Also, the groups $G$ I consider are Lie groups, but I am interested in weaker conditions too. I have found an obvious set of conditions that ensure $\theta$ is a homeomorphism, by ensuring $G\setminus X$ to be Hausdorff, $H$ and $Y$ compact. Then $H\setminus Y$ is compact Hausdorff and $\theta$ must be closed. My goal with this is to try to find easy proofs for separation of quotients (my immediate goal) by working with smaller spaces and smaller (whenever possible compact) subgroups. For instance, if you take $\mathrm{Fr}(d,X)$ to be the space of all $d$ frames of a finite dimensional vector space $X$, I could show that the quotient space under the natural action of $\mathrm{GL}(d)$ is the same as the one obtained from the orthonormal frames with the action of the orthogonal group $\mathrm{O}(d)$. This is of course a very minor achievement, but I have found it helpful in order to show that the natural action of $\mathrm{GL}(X)$ on the grassmannian of $d$ planes of $X$ is continuous, and it's helped me 'believe' in some proofs involving grassmannians and Stiefel manifolds. Thank you for your time!","['general-topology', 'lie-groups', 'topological-groups', 'algebraic-topology']"
44261,Smith normal form help,"I want to find the structure of the abelian group:
$$G=\frac{\mathbb{Z}^{3}}{\langle (2,0,10),(0,4,8),(4,-4,12) \rangle}$$
The Smith normal form of the matrix associated to $G$ is:
$$P= \left( \begin{array}{ccc}
2 & 0 & 0 & 0\\
0 & 4 & 0 & 0\\
0 & 0 & 0 & 0\end{array} \right),$$
which is correct (verified it with software). Thus the decomposition of $G$ as a direct sum of cyclic groups is $\mathbb{Z}_{2} \oplus \mathbb{Z}_{4} \oplus \mathbb{Z}$ yes? why the answer is $\mathbb{Z}_{2} \oplus \mathbb{Z}_{4} \oplus \mathbb{Z} \oplus \mathbb{Z}$, i.e why the extra summand $\mathbb{Z}$?. I thought that we only look at the elements of the diagonal of $P$ which in this case there are only three: $2,4,0$. What am I doing incorrect? Can you please explain?",['abstract-algebra']
44266,Bulgarian Solitaire: Size of root loops,"I first learned of Bulgarian solitaire from one of Martin Gardner's books a while ago and have since investigated it somewhat. Google-searching has revealed that surprisingly little work has been done (publicly anyway) in this area. The way the game works is as follows: take any number of items (like coins or small stones) and partition them into any number of piles with any number of items in each pile. Then take one item from each pile and make a new pile with them. Repeat for as long as necessary. For example: $10$ items, starting with piles of $4, 4, 1, 1$ At first, there are four piles. Taking one item from each leaves us with $3, 3$. Adding back the four we took gives us $4, 3, 3$. Repeating this step results in... $4, 4, 1, 1$ $4, 3, 3$ $3, 3, 2, 2$ $4, 2, 2, 1, 1$ $5, 3, 1, 1$ $4, 4, 2$ $3, 3, 3, 1$ $4, 2, 2, 2$ $4, 3, 1, 1, 1$ $5, 3, 2$ $4, 3, 2, 1$ $\mathbf{4, 3, 2, 1}$ $\dots$ Those with a good eye will quickly see that $4, 3, 2, 1$ is a stable state in that going through a turn of the game doesn't change anything. What is more interesting is that EVERY initial configuration of $10$ items will end up at this stable state. Additionally, $6$ items will always end up in $3, 2, 1$; $15$ items will always end up in $5, 4, 3, 2, 1$; and so on. Triangular numbers of items are the only numbers for which this happens. This is because only a $n, n-1, n-2, \dots, 3, 2, 1 { }$ state is stable; subtracting one from each gets rid of the $1$-pile and adds a pile of $n$. Clearly, a triangular number of items results in a ""root loop"" of size 1. I'm going to go ahead and state an observation and a fact that follows from it. This observation is that all partitions of $n$ items will lead to exactly one other partition of $n$, by definition. This means that while loops can exist, there can never be a partition of $n$ that leads to two partitions of $n$. This has the effect of splitting a directed graph (an edge from $i$ to $j$ has weight 1 iff partition $i$ leads to partition $j$) into a number of subgraphs that exactly corresponds to the number of loops. This is not hard to prove, and I am not Fermat. :P What I found to be even more interesting was what happened when you used a non-triangular number of items. In these cases, you will go into a loop. For example... $7$ $6, 1$ $5, 2$ $4, 2, 1$ $3, 3, 1$ $3, 2, 2$ $3, 2, 1, 1$ $\mathbf{4, 2, 1}$ $\dots$ Thus, starting with $7$ items ends up in a root loop of size $4$. More experimenting reveals that given a non-triangular number $n$ of items, find the triangular number $T_k \geq n$ and $k$ is the size of at least one of the root loops in the directed graph of all partitions of $n$. Why is this so?","['card-games', 'number-theory']"
44274,What's the relation between cohomology and unramified Galois covering of curves,"The following statement in a paper puzzles me: ""We may view $H^1(X(N), \mathbb{Z}/\ell\mathbb{Z})$ as classifying unramified Galois coverings of $X(N)$ with structure group $\mathbb{Z}/\ell\mathbb{Z}$."" Here $X(N)$ is the usual modular curve of level $N$.  Anyway, the statements seems to indicates that it is a general result about (complete?) curves over $\mathbb{C}$. On one hand, the étale covers of a variety corresponds to finite continuous $\pi_1^{\mathrm{ét}}(X)$-sets. On the other hand, $H^1(X(N), \mathbb{Z}/\ell\mathbb{Z})\cong (\mathbb{Z}/\ell\mathbb{Z})^{2g}$ is identified with the $n$-torsions of the Picard variety through the Kummer sequence.  I am having trouble to tie these two sides of the picture together.  Could any explain or point to a nice reference? 
Thank you.",['algebraic-geometry']
44275,Abelian subgroups of p-groups,"In his paper ""Large Abelian subgroups of $p-$groups"", Alperin stated: Theorem 1: If $p$ is an odd prime and $k$ is a positive integer, then there exists a group of order $p^{3k+2}$ all of whose abelian subgroups have order at most $p^{k+2}$.... In the paragraph after this theorem, he stated ""Burnsides classic theorem: a group of order $p^n$ has (normal) abelian subgroup of order $p^m$ with $n\leq m(m-1)/2$."" As per this Burnsides result, we can say that ""A group of order $p^{3k+2}$ contains an abelian subgroup of order $p^{k+3}$, because the inequality in Burnsides classic theorem holds with $n=3k+2$ and $m=k+3$; so how it is possible to get counterexample as in Theorem 1? Also, as per Burnsides classic result we can say that ""A group of order $p^k$ ($k>4$) contains an abelian subgroup of index $p$; i.e order $p^{k-1}$"", since the inequality in Burnsides result holds for $n=k$ and $m=k-1$ ($k>4$). Question 1 Can one explain what is correct, what is wrong? Question 2 Does all maximal abelian normal subgroups of a (non-abelian) $p-$group have same order?","['group-theory', 'p-groups']"
44277,Rings and modules of finite order,"Fields of finite order are well classified, and classification of groups of finite order has taken some depth in research. Why classification of finite rings and modules is not well studied in research?","['ring-theory', 'finite-rings', 'abstract-algebra']"
44287,Cofinality of cardinals,"I have read some of the related questions (cofinality and its consequences, for example) about cofinality, but I still have no idea how to calculate the cofinality of an aleph. So, let's say I have a cardinal $\aleph_\alpha$, how should I go about calculating its cofinality? I read some of Jech's Set Theory, but I did not grasp anything that might be useful to do my calculations. I apologize in advance if I missed something out from the book; I'll appreciate references to where I find the answer in the book.","['cardinals', 'elementary-set-theory']"
44288,Simplifying $\nabla[ \phi( \parallel \mathbf{x} - \mathbf{\xi}_i \parallel ) ]$,"I'd appreciate help simplifying the relationship $$
\nabla\left[ \; \phi(\parallel \mathbf{x} - \mathbf{\xi}_i \parallel) \; \right]
$$ for $\mathbf{x}$ and $\mathbf{\xi}_i$ in $\mathcal{R}^n$ . This is how far I've come (I'm not even sure if I'm on the right track) Setting $\mathbf{u} = \parallel \mathbf{x} - \mathbf{\xi}_i \parallel$ , so that $$
\nabla[ \phi(\mathbf{u}) ] = \left( \frac{\partial \phi}{\partial u_1} , \cdots , \frac{\partial \phi}{\partial u_n} \right) 
$$ but $$
\frac{\partial \phi}{\partial u_j} = \frac{\partial \phi}{\partial u_j} \frac{\partial u_j}{\partial \mathbf{x}} + \frac{\partial \phi}{\partial u_j} \frac{\partial u_j}{\partial \mathbf{\xi}_i}
$$ for $j = 1 , \cdots , n$ Note: this question is related to a previous one Edit:
Your answers are correct, and I will tag them as such, but they aren't the answers I was hoping for. In my previous question, I required help proving a relationship between involving $\mathbf{x}$ and $\mathbf{\xi}$ , from page 14 of these lecture slides . What I am now trying to understand is why $\phi$ is differentiated with respect to $\xi$ in the first place i.e. $\frac{\partial \phi}{\partial \xi}$ . The problem I'm working on is in the area of Hermite interpolation. For example, on page 4 (column 1) of the paper Hermite variational implicit surface reconstruction it is shown that $$
\frac{\partial}{\partial f} \mathbf{n}_i^T \nabla f(\mathbf{\xi}_i) = \mathbf{n}_i^T \nabla k(\mathbf{x} , \mathbf{\xi}_i)
$$ In the past I assumed that the components of the gradient of $\nabla f(\mathbf{\xi}_i)$ and $\nabla k(\mathbf{x} , \mathbf{\xi}_i)$ were differentials of $f(\mathbf{\xi}_i)$ and $k(\mathbf{x} , \mathbf{\xi}_i)$ with respect to $x_i$ . However the lecture slides and the paper suggest that the terms of the gradient are differentials with respect to $\xi_i$ . What I really would like to know is why.",['multivariable-calculus']
44290,Is this formula for the $n^{th}$ prime number useful?,Is the below formula for the $n^{th}$ prime number in elementary functions useful somehow? $$p(n)=\sum _{a=2}^{2^n} \sin \left(\pi  2^{\left(n-\sum _{b=2}^a \frac{\sin ^2\left(\frac{\pi }{b}((b-1)!)^2\right)}{\sin ^2\left(\frac{\pi }{b}\right)}\right)^2-1}\right)\frac{a \sin ^2\left(\frac{\pi }{a} ((a-1)!)^2\right) }{\sin ^2\left(\frac{\pi }{a}\right)}.$$,"['prime-numbers', 'number-theory']"
44293,Complex Integral,"Can you help me solve the following problem? Let $f$ be a holomorphic function on $D_{r}(0), $ the disc of radius $r>1$ with center on the origin. Calculate the following integral: $$\int_{|z|=1} (2\pm(z + z^{-1}))\frac{f(z)}{z}\mathbb dz$$ Solution: Observe that $(2\pm(z + z^{-1}))\frac{f(z)}{z}= \frac{\left(  2z \pm z^{2} \pm 1 \right)f(z)}{z^{2}}$. Let $h(z)= \left(  2z \pm z^{2} \pm 1 \right)f(z)$. Then this function is holomorphic in $D_{r}(0)$ since $f$ is and it is multiplied by a polynomial. Then by the Cauchy's Integral Formula: $$\int_{|z|=1} (2\pm(z + z^{-1}))\frac{f(z)}{z}\mathbb dz =\int_{|z|=1} \frac{h(z)}{z^{2}} \mathbb dz = 2\pi i \frac{h'(0)}{1!}$$ But $h'(0) = 2f(0) \pm f'(0)$.",['complex-analysis']
44294,Can one show that $\sum_{n=1}^N\frac{1}{n} -\log N - \gamma \leqslant \frac{1}{2N}$ without using the Euler-Maclaurin formula?,"I would like to prove that
$$
\sum_{n=1}^N\frac{1}{n} -\log N - \gamma \leqslant \frac{1}{2N}
$$
without using the Euler-Maclaurin summation formula. The motivation for this is that I have come very close to doing so (see the answer provided below) but annoyingly have not actually proved the above. Some may ask why I don't just use the formula. I'm writing a set of analytic number theory notes for my own use and it seems an unwieldy result to introduce and prove, given that the above inequality is all I need, and given that I have gotten so close without using Euler-Maclaurin!","['inequality', 'sequences-and-series', 'harmonic-numbers']"
44301,Normal subgroups of the symmetric group $S_N$,"Is there a list of all normal subgroups for $S_N$? What is a criteria for a finite group to be a normal subgroup of $S_N$? Which of them are kernels of irreducible representation? From a partition of $N$, we can construct an irreducible representation, so how does the related subgroup look in terms of the partition?","['finite-groups', 'representation-theory', 'group-theory', 'symmetric-groups']"
44306,Cauchy's theorem: what about non-smooth homotopies?,"This morning I realized I have never understood a technical issue about Cauchy's theorem (homotopy form) of complex analysis. To illustrate, let me first give a definition. (In what follows $\Omega$ will always denote an open subset of the complex plane.) Definition Let $\gamma, \eta\colon [0, 1]_t \to \Omega$ be two piecewise smooth closed curves (or circuits ). We say that $\gamma, \eta$ are $\Omega$- homotopic if there exists a continuous mapping $H \colon [0, 1]_\lambda \times [0, 1]_t \to \Omega$ s.t. $H(0, t)=\gamma(t)$ and $H(1, t)=\eta(t), \quad \forall t \in [0, 1]$; $H(\lambda, 0)=H(\lambda, 1), \quad \forall \lambda \in [0, 1]$. Theorem (Cauchy) Let $f\colon \Omega \to \mathbb{C}$ be holomorphic. If $\gamma, \eta$ are $\Omega$-homotopic circuits, then $$\int_{\gamma} f(z)\, dz= \int_{\eta}f(z)\, dz.$$ Problem The function $H$ above is only continuous and need not be smooth. So for $0< \lambda < 1$, the closed curve $H(\lambda, \cdot)$ may be pretty much everything (a Peano curve, for example). Does this void the validity of theorem as it is stated above? How can integration be defined over such a pathological object? The proof of Cauchy's theorem that I have in mind goes as follows. To begin, one observes that for a sufficiently small value of $\lambda_1$, the circuits $\gamma=H(0, \cdot)$ and $H(\lambda_1, \cdot)$ are close toghether ; that is, they can be covered by a finite sequence of disks not leaving $\Omega$ like in the following figure: Since $f$ is locally exact, its integrals over every single disk depend only on the local primitive. Playing a bit with this, one arrives at $$\int_\gamma f(z)\, dz= \int_{H(\lambda_1, \cdot)} f(z)\, dz.$$ Then one repeats this process, yielding a $\lambda_2$ greater than $\lambda_1$ and such that $$\int_{H(\lambda_1,\cdot)} f(z)\, dz= \int_{H(\lambda_2, \cdot)} f(z)\, dz.$$ And so on. A compactness argument finally shows that this algorithm ends in a finite number of steps. Problem is : this proof assumes implicitly that $H(\lambda_1, \cdot), H(\lambda_2, \cdot) \ldots$ are piecewise smooth, to make sense of integrals $$\int_{H(\lambda_j, \cdot)}f(z)\, dz.$$ 
This, however, does not follow from the definition if $H$ is only assumed to be continuous. Therefore this proof works only for smooth $H$. Is this regularity condition necessary?",['complex-analysis']
44308,Ways to define the directional derivative,"I am reading a text where directional derivatives of functions $f:E\rightarrow F$, where $E,F$ are Banach spaces, at the point $x_0 \in E$ are defined as $d_v f(x_0)=\lim_{t\rightarrow 0+} \frac{f(x_0+tv)-f(x_0)}{t}$ for any $v\in E$. My question is: Why is the limit taken with respect to ""$t\rightarrow 0+$"" instead of just ""$t\rightarrow 0$"" ? What does it change if we have ""$t\rightarrow 0+$ instead of ""$t\rightarrow 0$"" ? Since in some textbooks, just the """"$t\rightarrow 0$"" version is used.",['analysis']
44310,Entire functions such that $f(z^{2})=f(z)^{2}$,"I'm having trouble solving this one. Could you help me? Characterize the entire functions such that $f(z^{2})=f(z)^{2}$ for all $z\in \mathbb{C}$. 
Hint: Divide in the cases $f(0)=1$ and $f(0)=0$. For the first case prove ( I've alredy done this ) and use that $f(z^{2^{n}})= f(z)^{2^{n}}$ for all $n$ natural to see that $f$ is constant. For the second case, if $f$ is not identically zero, then $f$ has a zero in $z=0$ of order $m\geq 1$.","['complex-analysis', 'functional-equations']"
44312,"If $X$ is uniformly distributed on $ [0,1]$, how is $X^2$ distributed?","I seem to be getting it equal to the $X$, which can't be right","['statistics', 'probability']"
44329,Function for concatenated semicircles,I am looking for a closed-form formula for something like this: Can anybody help - Thank you!,['functions']
44333,considering the minimum in random walk,"Grimmett and Stirzaker's ""Probability and Random Processes"" gives a nice discussion about random walk, for example, it considers $M_n=\max\{S_i,0\le i \le n\}$ where as usual $$S_i=\sum_{k=1}^i{X_k},$$ here $S_0=0$, $\mathbb{P}(X_k=1)=p$ and $\mathbb{P}(X_k=-1)=q=1-p$. One of the results about $M_n$ is $\mathbb{P}(M_n\ge r, S_n=b)$ or even $\mathbb{P}(M_n\ge r)$. I am just wondering how to relate to the minimum $m_n=\min\{S_i,0\le i \le n\}$ given this result? Is there any simple way to do this? I just found sometimes considering the minimum is most convenient for some problems.","['random-walk', 'probability']"
44335,"Motivated by Poisson distributions, prove that: If $n p_n \to \lambda$ then $ \left( 1 - p_n \right)^n \to e^{-\lambda}$","I have this ugly proof that some sequence converges to something and I really don't like it because it seems too hard for no reason... can anyone help me make this more simple? Here it is : We are given a sequence $p_n$ with $n p_n \to \lambda > 0$. We show that 
$$
\left( 1 - p_n \right)^n \to e^{-\lambda}.
$$
So my proof begins by noticing that
$$
(1-p_n)^n = \left( 1 + \frac{-np_n}n \right)^n 
$$
and that the family of functions $s_n(x) = \left(1+\frac xn \right)^n$ is equicontinuous at $x$ (I think I can pull some argument stating that the derivative of $s_n(x)$ is always bounded (because it also converges to $e^x$) when considering an interval of arbitrary but fixed length centered at $x$, so that in this interval, all functions $s_n$ can have the same Lipschitz constant, therefore giving equicontinuity, correct me if I'm wrong) so that if I note by $x_n$ the sequence $-n p_n$, $x = -\lambda$ and $s(x) = e^x$, I wish to show that 
$$
\forall \varepsilon > 0, \quad \exists N \quad s.t. \quad \forall n > N, \quad |s_n(x_n) - s(x)| < \varepsilon.
$$
so now,
$$
|s_n(x_n) - s(x)| \le |s_n(x_n) - s_n(x_m)| + |s_n(x_m) - s_n(x)| + |s_n(x) - s(x)|.
$$
Since $x_n$ is convergent, it is also Cauchy, so that for all $\delta > 0$, there exists an $N_1$ such that for all $n,m > N_1$, $|x_m - x_n| < \delta$ and $|x_m - x| < \delta$. Since the family $\{s_n\}$ is equicontinuous, for all $\varepsilon > 0$, there exists a $\delta > 0$ such that $|x - y| < \delta \Rightarrow |s_n(x) - s_n(y)| < \frac{\varepsilon}3$, so that the first two terms are taken care of by $N_1$ by taking $(x,y) = (x_n, x_m)$ and $(x,y) = (x_m, x)$ respectively. The last term is also bounded by $\varepsilon/3$ when $n > N_2$ because $s_n \to s$ pointwisely. Taking $N = \max \{ N_1, N_2 \}$ we're done. I feel like my proof is a little too harsh on this easy-looking problem... anyone has a better proof? What I mean by ""better"" is using less powerful or advanced tools, something simple. I can't seem to find anything better right now.",['real-analysis']
44341,Finding number of matrices whose square is the identity matrix,"how can we find the number of matrices with real entries of size $9 \times 9$ (up to similarity) such that $A^{2}=I$? I first thought about the following: Notice $A$ satisfies the polynomial $f(t)=t^{2}-1$ hence its minimal polynomial divides $(t-1)(t+1)$. So its characteristic polynomial is of the form $p(t)=(t-1)^r(t+1)^j$ where $r+j = 9$, right? Then I'm not sure what to do, I tried to consider the rational canonical form but in order to do this we need to know the minimal polynomial right? because in the rational canonical form the last term in the array is exactly the minimal polynomial, how to find it? Can you please help?","['matrices', 'linear-algebra', 'examples-counterexamples']"
44346,Linear Algebra: different determinant answers,"I'm having a problem verifying my answer to this question:
Solve for x: $$\left| \begin{array}{cc}
x+3 & 2 \\
1 & x+2 \end{array} \right| = 0$$ I get: $(x+3)(x+2)-2=0$ $(x+3)(x+2)=2$
thus: $x+3=2$ and    $x+2=2$ $x=-1$ and $x=0$ The book says that $x=-1$ and $x=-4$ is the correct answer. I tried doing it a different way by expanding and got totally different answers: $x^2+5x=-4$ $x(x+5)=-4$ $x=-4$ and $x=-9$ What is going on here?","['linear-algebra', 'determinant']"
44348,Rules applying to nested absolute values,I'm trying to use some algebra get $||x-5|-10|<\epsilon$ into a more manageable form (I'd like it in terms of $0<|x+5|<\delta$) but I'm not sure where to begin. I don't really know the rules regarding absolute values within absolute values and can't seem to find anything that would help me on the net. What are the rules pertaining to this sort of thing that I can use to get started messing around with this?,"['absolute-value', 'algebra-precalculus']"
44355,"Can ""being differentiable"" imply ""having continuous partial derivatives""?","Consider the following theorem: Let $E$ be a subset of ${\bf R}^n$, $f:E\to {\bf R}^m$ be a function, $F$ be a subset of $E$, and $x_0$ be an interior point of $F$. If all the partial derivatives $\frac{\partial f}{\partial x_j}$ exist on $F$ and are continuous at $x_0$, then $f$ is differentiable at $x_0$. And I consider the converse of the above theorem: Let $E$ be a subset of ${\bf R}^n$, $f:E\to {\bf R}^m$ be a function, $F$ be a subset of $E$, and $x_0$ be an interior point of $F$. If $f$ is differentiable at $x_0$, then all the partial derivatives $\frac{\partial f}{\partial x_j}$ exist on some neighbourhood of $x_0$ and are continuous at $x_0$. It is trivial to show that the converse is NOT true when $m=1$. It seems no hope that it will be true when $m\geq 2$. Here is my question : Is the converse
  true when $m\geq 2$? If is not true, how to construct the counterexample? Edit : The title is corrected. Edit : Since another question is not relevant to the first one here, I think, I put it into another post .","['multivariable-calculus', 'differential-geometry']"
44361,Question about direct sum of function space,"I am reading Applied linear algebra: the decoupling principle by Lorenzo Adlai Sadun (btw very recommendable!) On page 30 about direct sums on vector spaces it says: Let $V$ be the space of continuous functions on a domain $U \subset \mathbb R^3$. Then $V \oplus V \oplus V$ is the space of continuous $\mathbb R^3$-valued functions on $U$. What I don't understand is how this threefold direct sum of $V$ can lead to a statement about the codomain (""-valued"" functions). But I just guess that I don't get it altogether - please enlighten me. Thank you! EDIT I think what confuses me most is that we start with $\mathbb R^3$ and end up with it. It would come more natural if we started with $\mathbb R$ and after taking the direct sum three times would end in $\mathbb R^3$.","['vector-spaces', 'linear-algebra', 'functional-analysis']"
44368,Finding $A^n$ for a matrix,"I have a matrix $$
A =
\left[ {\begin{array}{cc}
 1 & c  \\
 0 & d  \\
 \end{array} } \right]
$$ with $c$ and $d$ constant. I need to find $A^n$ ($n$ positive) and then need to prove that formula using induction. I would like to check that the formula I derived is correct: $$
A^n =
\left[ {\begin{array}{cc}
 1 & c^{n-2}(dc + c)  \\
 0 & d^n  \\
 \end{array} } \right]
$$ If this is correct, how can I prove this? I suppose I can write $A^{n+1} = A^n A$, which would be $$
\left[ {\begin{array}{cc}
 1 & c^{n-2}(dc + c)  \\
 0 & d^n  \\
 \end{array} } \right]
\left[ {\begin{array}{cc}
 1 & c  \\
 0 & d  \\
 \end{array} } \right]

$$ But then what would I do? Thanks.","['matrices', 'induction']"
44373,Sense of the linearity of the derivative,"In what sense the derivative is linear?. In Bartle's book The elements of real analysis
takes as an observation the case f:R$\rightarrow$ R and says f is diferentiable at c iff the derivative f'(c) of f exists at c. In this case the derivative of f at c is linear function on 
R to R wich sends the real number u into the real number f'(c)u. Then I took f(x)=$x^3$ , f'(c)=3$c^2$ at c$\neq$0 how do I define the derivative to be linear?.
Obviously f'(a+b)$\neq$f'(a)+f'(b) for a, b $\neq$ 0 in general, so this isn't the sense,
then I took $\phi$(x)=f'(c)(x) and yes this is linear for any f on R to R with derivative at c, because f'(c) is
a number and $\phi$(x) is just a linear function in the sense $\phi$(x)=ax , where a is constant So my question is this last sense the one to take to understand that a derivative at a point is a linear function?
thanks beforehand.","['functions', 'real-analysis']"
44374,Intermediate ring between a field and an algebraic extension.,"This is an exercise in some textbooks. Let $E$ be an algebraic extension of $F$. Suppose $R$ is ring that contains $F$ and is contained in $E$. Prove that $R$ is a field. The trouble is really with the inverse of $r$, where $r\in R$. How to prove that $r^{-1}\in R$, in apparent lack of a characterization of $R$. It occurred to me to use the smallest field containing $R$ ($R$ is easily shown to be an integral domain), that's the field of quotients, and proving that it's $R$ itself, but I don't really know how to proceed. A not-too-weak, not-too-strong hint will be much appreciated. Beware $ $ Readers seeking only hints should  beware that there is now a complete answer.","['abstract-algebra', 'field-theory']"
44386,Find the point in a triangle minimizing the sum of distances to the vertices [duplicate],"This question already has answers here : How to prove the property of the Lemoine point of a triangle? (2 answers) Closed 7 years ago . Given a triangle in a plane with vertices A, B, C, find the point T that minimizes the sum of distances between A-T, B-T, and C-T. I can experimentally determine this point by sampling the space and finding the minimum via an attractive, interactive web page: http://phrogz.net/SVG/tweedlie-gradient.xhtml Drag any vertex to see the gradient of value sums change and the point T be updated. I find it interesting to note that moving any vertex towards or away from T does not affect T, until the point where the vertex touches T and causes it to move along with it. However, an experimental determination is neither efficient nor accurate, and prevents me from graphing other interesting properties such as the arcs of the vertices when a fixed sum is required. Please help me find the equation for T (preferably in terms of vectors, as the answer should be the same in 2D or 3D). Edit : Based on the answer, I've created an updated interactive using the calculated point and showing the construction: http://phrogz.net/SVG/fermat-point.xhtml","['optimization', 'geometry', 'triangles']"
44391,Foci of a general conic equation,"The general equation of a conic is $A x^2 + B x y + C y^2 + D x + E y + F = 0$.  At Wikipedia, there is an equation for the eccentricity, based on ABCDEF. Is there a similar equation for getting the foci or directrix for a general ellipse, parabola, hyperbola from ABCDEF?  Please assume that a non-degenerate form of the equation is given.","['geometry', 'conic-sections']"
44395,Rationalizing the denominator [duplicate],"This question already has answers here : Evaluating the limit of $\lim_{x \to 9} \frac {x-9} {\sqrt{x} - 3}$ (4 answers) Closed 8 years ago . So I feel stupid for asking this, but I can't figure this out. I haven't taken algebra for about 8 years, so doing this is kind of fuzzy. Just started Calc 1 and we're finding limits.
$$\lim_{x \to 9} \frac{x - 9}{\sqrt{x} - 3} .$$ I try to do some algebra to rationalize the denominator, but everything I do gets me to the limit equaling either $2$ or $3$. Which makes me think I don't understant rationalizing the denominator. What I get is:
$$\lim_{x \to 9} \frac{x\sqrt{x} - 9\sqrt{x}}{x - 3\sqrt{x}}$$ This is where I'm confusing myself. I don't know where to go to simplify from here. And I still can't do direct substitution because it will equal $\frac{0}{0}$.","['calculus', 'algebra-precalculus', 'limits']"
44396,Largest Triangle with Vertices in the Unit Cube,"How would one find a triangle, with vertices in or on the unit cube, such that the length of the smallest side is maximized? And what is that length? A lower bound for the length is $\sqrt{2}$, by looking at an equilateral triangle, and an upper bound is $\sqrt{3}$, since that's the diameter of the unit cube.","['geometry', 'triangles', '3d']"
44403,"Existence of a matrix, characteristic polynomial and minimal polynomial","Let $k$ be a field and let $p(x),q(x)$ be elements of $k[x]$. If $q(x)$ divides $p(x)$ and if every root of $p(x)$ is a root of $q(x)$ prove there exists a matrix $A$ having minimal polynomial equal $q(x)$ and characteristic polynomial equal $p(x)$. So I tried first an example. Take $p(x)=(x-3)^{2}(x-5)$ and $q(x)=(x-3)(x-5)$. Now set: $C= \left( \begin{array}{ccc}
3 & 0 & 0\\
0 & 3 & 0\\
0 & 0 & 5\end{array} \right)$ Then $C$ is a diagonal matrix and its characteristic polynomial is equal $p(x)$ while its minimal polynomial is $q(x)$. Now how to deal with the general case? I'm not sure the same argument would hold for any general $p(x)$, can you please help?",['linear-algebra']
44454,Isomorphism between complex numbers minus zero and unit circle,How do we show that $\mathbb{C}^{\times}$ and $S^{1}$ are isomorphic as groups?,['abstract-algebra']
44459,Proof for divisibility by $7$,"One very classic story about divisibility is something like this. A number is divisible by $2^n$ if the last $n$-digit of the number is divisible by $2^n$.
  A number is divisible by 3 (resp., by 9) if the sum of its digit is divisible by 3 (resp., by 9).
  A number $\overline{a_1a_2\ldots a_n}$ is divisible by 7 if $\overline{a_1a_2\ldots a_{n-1}} - 2\times a_n$ is divisible by 7 too. The first two statements are very well known and quite easy to prove. However I could not find the way on proving the third statement. PS: $\overline{a_1a_2\ldots a_n}$ means the digits of the number itself, not to be confused with multiplication of number.","['divisibility', 'number-theory']"
44478,Finding power series representation of $ \int_0^{\frac{\pi }{2}} \frac{1}{\sqrt {1 - k^2\sin^2{x}}}\;{dx}$,"I want to show that $\displaystyle \int_0^{\frac{\pi }{2}} \frac{1}{\sqrt {1 - k^2\sin^2{x}}}\;{dx} = \frac{\pi}{2}\sum_{n \ge 0}k^{2n}\left({\frac{{1 \cdot 3 \cdots \left( {2n - 1} \right)}}
{{2 \cdot 4 \cdots \cdot 2n}}} \right)$, where $ -1 < k < 1$. Here is what I did: $$\displaystyle \begin{aligned}\int_0^{\frac{\pi }{2}} \frac{1}{{\sqrt {1 - k^2\sin^2{x}}}}\;{dx} & = \int_{0}^{\pi/2}\sum_{n \ge 0} \frac{k^{2n}}{2^{2n}}\binom{2n}{n}\sin^{2n}{x}\;{dx} \\& = \sum_{n \ge 0}\int_{0}^{\pi/2} \frac{k^{2n}}{2^{2n}}\binom{2n}{n}\sin^{2n}{x}\;{dx}  \\& = \frac{\pi}{2} \sum_{n \ge 0} ~ k^{2n} \bigg(\frac{1}{2^{2n}}\binom{2n}{n}\prod_{1 \le r \le n}\frac{2r-1}{2r} \bigg) \\& = \frac{\pi}{2} \sum_{n \ge 0} ~ k^{2n} \bigg(\prod_{1 \le r \le n}\frac{2r-1}{2r} \cdot \prod_{1 \le r \le n}\frac{2r-1}{2r} \bigg) \\& = \frac{\pi}{2}\sum_{n \ge 0}k^{2n}\bigg(\prod_{1 \le r \le n}\frac{2r-1}{2r}\bigg)^2.\end{aligned}$$ However, there no power on the coefficients in the given series, so they obviously don't match, and I couldn't whatsoever discern a mistake in my calculations. Thanks in advance.","['power-series', 'sequences-and-series', 'integration']"
44494,Finite groups with periodic cohomology,"I'm trying to understand Chapter 12, Section 11 in Cartan + Eilenberg's Homological Algebra , which concerns finite groups with periodic cohomology. Unfortunately I am jumping right to this section in the book (I've been working in Serre's Local Fields , and I'm doing the exercise at the end of Chapter 8, Section 4, which refers to the above section in Cartan + Eilenberg), so I'm a little disconcerted with the notation change (and things like using $(\Pi:1)$ for the order of the group $\Pi$ - what is up with that?) I suppose I have two main questions. How do we know that, given a finite group $G$ with periodic cohomology, say with $${\widehat{H}}{}^n(G,A)\cong\!\!\!{\widehat{H}}{}^{n+q}(G,A)$$ for all $n\in\mathbb{Z}$ for some $q\in\mathbb{N}$, these isomorphisms must be given by cup-producting with a fixed element $g\in\widehat{H}{}^q(G,\mathbb{Z})$? This seems to be an implicit assumption in their investigation, and while I can very well believe that it's true (the cup-product satisfies some universal property, if I understand correctly), I don't see what's barring the isomorphisms from being ""accidental"". The fact that the period $q$ is necessarily even (unless $G$ is trivial in which case $q=1$) seems very mysterious to me. Of course, this is the key property for the exercise I'm doing (defining a generalization of the Herbrand quotient), so I would like to have a firm grasp of why it's true. I can more or less follow the reasoning in Cartan + Eilenberg for why this is true, but it's just a proof by contradiction by making a computation using the cup product, and using the fact that $\mathbb{Z}/2\mathbb{Z}$ has periodic cohomology with even period. Furthermore, I again am not seeing why cup-producting with an element of $\widehat{H}{}^q(G,\mathbb{Z})$ is necessarily involved. So, are there any more intuitive explanations of why group cohomology, if it is periodic, has even period? Are there any references other than Cartan + Eilenberg I can look at for this fact?","['homology-cohomology', 'group-cohomology', 'abstract-algebra']"
44511,Are the inverses of these matrices always tridiagonal?,"While putzing around with the linear algebra capabilities of my computing environment, I noticed that inverses of $n\times n$ matrices $\mathbf M$ associated with a sequence $a_i$, $i=1\dots n$ with $m_{ij}=a_{\max(i,j)}$, which take the form $$\mathbf M=\begin{pmatrix}a_1&a_2&\cdots&a_n\\a_2&a_2&\cdots&a_n\\\vdots&\vdots&\ddots&a_n\\a_n&a_n&a_n&a_n\end{pmatrix}$$ (i.e., constant along ""backwards L"" sections of the matrix) are tridiagonal. (I have no idea if there's a special name for these matrices, so if they've already been studied in the literature, I'd love to hear about references.) How can I prove that the inverses of these special matrices are indeed tridiagonal?","['matrices', 'tridiagonal-matrices', 'linear-algebra', 'inverse']"
44517,a question about $E(\sum_{n=1}^{+\infty}X_{k}$)=$\sum_{n=1}^{+\infty}EX_{k}$,"$X_{k}$ are random variables and they are not independent,
I wonder if $E(\sum_{n=1}^{+\infty}X_{k}$)=$\sum_{n=1}^{+\infty}EX_{k}$.
if the equation does not hold, what conditions are required in order to make it right.","['probability-theory', 'convergence-divergence']"
44518,Differential inequality,"1. I start with simple differential inequality: find $u\in C^1[0,1]$ such that $u(0) = 0$ and 
$$
u'(t)\leq -u(t)
$$
for all $t\in [0,1]$. Using Gronwall's lemma one can see that $u\leq 0$. On the other hand it seems to be the only solution, since this inequality keep $u$ non-decreasing for $u<0$ and non-increasing for $u>0$. Is it right that only $u=0$ satisfies this inequality? 2. With Gronwall's lemma one can see that any solution of 
$$
u'(t)\leq\beta(t)u(t)
$$
is bounded from above by the solution of
$$
u'(t) = \beta(t)u(t).
$$ So there are two main results: (i) there is a solution of $u'\leq \beta u$ which dominates any other solution. (ii) this solution is attained on the correspondent equation. Are there any similar results on PD inequalities of the type
$$
u_t(t,x)\leq L_x u(t,x)
$$
where $L_x$ is a differential operator in $x$ variable (of first or second order). The main question for me if (i) is valid for such inequalities.","['ordinary-differential-equations', 'partial-differential-equations']"
44522,(Theoretical) Multivariable Calculus Textbooks [duplicate],"This question already has answers here : References for multivariable calculus (13 answers) Closed 10 years ago . (Note that I have used bold text frequently simply to highlight the key points of my question for those who do not have the time to read through it thoroughly (it is not very long, however); I hope this is not considered offensive.) There are many textbooks on multivariable calculus. However, some textbooks on multivariable calculus do not focus very much on the theoretical foundations of the subject. For example, a textbook might state a result along the lines of ""the order of partial differentiation is immaterial"" without proof and ask the student to use this rule to solve problems. Similarly, theorems such as those due to Green and Stokes are often not proved in their full generality. Therefore, I ask the following question: What are some good theoretical
  multivariable calculus textbooks ? Since ""theoretical"" is somewhat ambiguous, let me state the following criteria which I would like a ""theoretical"" textbook on multivariable calculus to satisfy: The textbook should be rigorous and it should not state a theorem without proof if the theorem is proved in at least one other multivariable calculus textbook. (Of course, the textbook may omit certain theorems; however, this criterion at least ensures that major theorems in multivariable calculus are not stated without proof and used purely for the sake of computations. Also, this criterion permits the textbook to state an interesting theorem if it is beyond the scope of all multivariable calculus textbooks.) The textbook should be primarily based on developing the theoretical foundations of multivariable calculus; therefore, applications such as learning how to compute the partial derivative of a function, learning how to solve extremum problems, learning how to compute etc. should be kept to a minimum . In particular, the textbook can assume that the reader has already seen at least an informal treatment of the subject where these aspects are emphasized. The textbook should have a rigorous treatment of differentiability in $n$-dimensional Euclidean space (e.g., the inverse and implicit function theorems should be proven), Riemann integration in $n$-space , and differential forms (e.g., Stokes theorem should be proven). It would also be a bonus if the book treated the general concept of a manifold. Textbooks with minimal prerequisites are preferred ; however, please feel free to suggest books meeting the above criteria even if the prerequisites are quite demanding. Finally, it would also be preferable, but not essential, for the book to only treat multivariable calculus . Examples of books meeting the above criteria: ""Analysis on Manifolds"" by James Munkres, ""Principles of Mathematical Analysis"" by Walter Rudin, and ""Calculus on Manifolds"" by Michael Spivak. Although I have studied theoretical multivariable calculus already (four years ago), I could never find ""the perfect book"" (relative to myself, of course). Every book has its virtues; Rudin for its elegance, Munkres for its beautiful exposition, and Spivak for its ""quick and dirty"" approach. I am hoping that someone will be able to suggest a book that (relative to myself) is ""perfect"". Also, this question can be useful to other students who have not yet studied the subject and wish to learn it. Thank you very much for all answers! Please do feel free to suggest as many books as you can think of so we can form a big list. Also, please try to explain why a particular book is good or at least why you think it is good. I suppose it is fine to suggest a book that is already suggested provided you have a different view as to why the book is good.","['big-list', 'multivariable-calculus', 'book-recommendation', 'reference-request']"
44524,Transforming puzzle to graph theory?,"I am trying to solve the puzzle below and am thinking that there ought to be some way of formulating it as a problem about counting matchings, but I can not make it work. I would appreciate a hint or a different strategy. N premier league footballers, all with different birth dates, and a single female, Natasha, are to be seated at a round table. To avoid any footballers getting ignored, each footballer must either sit next to a younger footballer or to Natasha. In how many ways can the footballers and Natasha be seated?","['graph-theory', 'puzzle', 'discrete-mathematics', 'combinatorics']"
44546,Integral of $\sqrt{1+\tan^2x}$ [duplicate],"This question already has answers here : Closed 13 years ago . Possible Duplicate: Ways to evaluate $\int \sec \theta d \theta$ I'm having a bit of a problem with an integral. The original problem was the length of a curve given parametrically. I've managed to reduce that integral to: $$\int_0^{\pi/4}\sqrt{1+\tan^2x}\ \mathrm{d}x$$ I've tried some substitions for $\tan x$, but always got stuck on a worse form.","['trigonometry', 'calculus', 'integration']"
44548,Applications of systems of linear equations,"Sorry if this questions is overly simplistic. It's just something I haven't been able to figure out. I've been reading through quite a few linear algebra books and have gone through the various methods of solving linear systems of equations, in particular, $n$ systems in $n$ unknowns. While I understand the techniques used to solve these for the most part, I don't understand how these situations present themselves. I was wondering if anyone could provide a simple real-world example or two from data analysis, finance, economics, etc. in which the problem they were working on led to a system of $n$ equations in $n$ unknowns. I don't need the solution worked out. I just need to know the problem that resulted in the system.",['linear-algebra']
44559,"Formal proof for A subset of the real numbers, well ordered with the normal order of $\mathbb R$, is at most $\aleph_0$",I tried to write a formal proof for the theorem: $A$ subset of $\mathbb R$ well ordered by the normal order $\implies A$ is at most of cardinality $\aleph_0$. Any suggestions? Thanks.,"['elementary-set-theory', 'order-theory']"
44569,Weierstrass Form of Elliptic Curve,"One can put every cubic curve into Weierstrass form, how unique is this form?","['algebraic-geometry', 'elliptic-curves']"
44579,p chance of winning tennis point -> what f(p) chance of winning game?,"In Wii Tennis, I have fixed $\,\,p\,\,$ chance of winning a given point. What is my chance $f(p)$ of winning the entire game? If $p=0.5, f(p)=0.5$ by symmetry, but I believe $f(0.51) > 0.51 $ EDIT: to clarify, the rules of Wii Tennis are the same as regular tennis. EDIT: would a Markov Chain be useful here?",['probability']
44593,Diffraction and Computer Generated Holography Calculations,"I've tried this through Mathematica, and hit my own limit in math ability trying to do this, both to no avail. I'm assuming there is no way to do so, as a simple solution to this problem would be a breakthrough for Ray Tracing, but WHY is it so difficult to integrate a euclidean distance function. (and by extension, the surrounding trigonometric functions) $\int {\cos {\sqrt {x^2+y^2+z^2}}dx}$ I find myself REALLY wanting to accomplish this for the sake of a project I'm working on, and only being able to do this via Riemann sums makes for a VASTLY inferior calculation. The full equation is much uglier than this, but the stumbling block is this part. Here's the full equation I'm working with at the moment. (There is a corresponding sin equation as well, the combination of which is used to determine the phase offset) $\int_{\text{vs}}^{\text{ve}} \left(\int_{\text{us}}^{\text{ue}} \text{Cos}\left[\frac{\sqrt{(-\text{px}+\text{t4}+\text{t1} u+\text{t2} v)^2+(-\text{py}+\text{t8}+\text{t5} u+\text{t6} v)^2+(\text{t12}+\text{t9} u+\text{t10} v)^2}}{w}\right.] \, du\right) \, dv$ There are a lot of variables here because I'm a little too much computer background, and too little math background.  u,v are defined over the range us-ue,vs-ve, (hence the integral ranges) and t[1-16] are components of a 4x4 translation matrix that pushes the 2d surface u,v into 3d coordinates. p[x,y] is the location of the holographic plate ""pixel"" being computed. w is the wavelength of light under consideration. The idea is to push the same equation to multiple cores on the GPU, each with a different pixel co-ordinate. For the purposes of a single computation, all t,p and w variables are constants. us and ue cannot be taken for granted unfortulately as there is the possibility that us and ue are functions of v, however, vs and ve would be constants. The idea here is to create a holographic plate representation of a surface instead of a point. I don't want to do Riemann sums because it creates holes, and I have the distinct impression that it's terribly inefficient. Yes, this is what I originally posted to MathOverflow. I simplified the equation above using the Fourier Aproximation, and then further reduced it's complexity using Euler's Formula.  I can't speak to the efficiency of calculation of Euler's formula vs the integral of a Cos/Sin pair, but, it is technically more correct since I'm talking in electromagnetic waves anyway.  The resulting Complex Amplitude actually seems to give the correct answer, as I can demonstrate through pictures more easily than words. The speed of calculation slows down to a crawl the moment I try to do any rotations of the u,v coordinate surface, and I'm guessing that's because a whole bunch of terms zero out when it's parallel to the z=0 plane, and don't when it's not.  Making the z coordinate of the surface a function of u,v also has a similar computational hit, which is unfortunate, because that's one of the easier ways to make a continuous wavefront pattern from a z-buffer. In any event, here are the graphics I generated to test whether I was on the right track or not with my calculations, and they actually match the real wavefront pattern surprisingly well.  Take a gander if you're interested:","['trigonometry', 'integration', 'physics', 'euclidean-geometry']"
44594,Interesting applications of the cofinite topology?,"Background : I'm doing some expository writing on intuitionistic logic and I have been toying with the idea of demonstrating its applicability via models where the denotations  are taken from a Heyting algebra. A topology is nothing more than a complete Heyting algebra of sets, so we have a natural and rich source of Heyting algebras to build models of intuitionistic propositional logic with. The Sierpiński space, for example, is already sufficient to falsify double negation elimination and some other tautologies of classical logic. Dually, Kuratowski's result for the complement–closure problem can be viewed as a reflection of the fact that $\lnot \lnot \lnot p \dashv \vdash \lnot p$ is valid intuitionistically. In particular, this proves that $A^{\circ c \circ c \circ c \circ} = A^{\circ c \circ}$, since $B^{c \circ}$ is precisely the Heyting pseudocomplement of $B$ in the Heyting algebra of open sets. Question : Are there similar applications for the cofinite topology in particular? I was hoping to give an example of how intuitionistic logic could be used to reason about ""almost-everywhere"" truths, but I haven't been able to figure out anything non-trivial.","['general-topology', 'logic', 'examples-counterexamples', 'soft-question']"
44595,Machin's formula and cousins,"There exists a well-known formula by John Machin: 
$$\frac{\pi}{4} = 4 \arctan \left(\frac{1}{5}\right) - \arctan \left(\frac{1}{239}\right).$$ Actually, it belongs to the family of Machin-like formulas of the form
$$\frac{\pi}4 = \sum_k a_k \arctan {b_k}^{-1}\quad\text{for some integers}\quad(a_k,b_k)$$ For example:
$$\frac{\pi}{4} = \arctan \left(\frac{1}{2}\right) + \arctan \left(\frac{1}{3}\right) = 2 \arctan \left(\frac{1}{2}\right) - \arctan \left(\frac{1}{7}\right)$$ and so forth. These formulas are quite easy to prove, but is there any easy way to generate such $(a_n, b_n)$?","['pi', 'trigonometry', 'diophantine-equations']"
44608,Help with understanding and studying probability,"I'm a CS major and self studying sheldon ross's first course in probability book, before that I have taken a calculus based probability course, not a strong one, which ended with superficially covering content in ross's 6th and 7th chapter. We proved gamma(1/2) = pi, solved integrals for calculating moment generating functions of some common ditributions, joint pdfs, jacobian determinant etc. The problem is, although doing a calculus based probability course and being comfortable with linear algebra and calculus I spend a lot of time understanding example problems in this book. My intention was studying some real analysis and measure theory and continue with stochastic calculus and I was hoping that at least at the end of summer I would get my feet wet in stochastic calculus. With this speed it seems that I would only be able to complete the ross's book at the end of summer if I attempt fair amount of exercises for each chapter. As an example, I was reading sum of independent random variables and the author explains it by convolution and I lost lots of time (hours) just understanding the convolution integral and its applications to the problem but this is only a single example in the book and there are many examples of this kind. I love to learn math and doing this as an hobby, but I have started to think that I am a bit stupid for learning math. What do you suggest me for studying math books efficiently ? And for professional math major students, do you spend a lot of time on text or do you grasp it very quickly ? Can you give some strategies for learning faster ? As a note I'm a foreign student and do not have abundance of qualified instructors or tutors who would help me with points I do not understand.",['probability']
44613,Factoring Quantities Question,"I was doing an exercise and ran into a problem with their use of factoring. Here is the problem specific to where the issue occurs: $$
\frac{(x^2 + 1)^{1/2} - x^2 (x^2 + 1)^{-1/2}}{x^2 + 1} = \frac{(x^2 + 1)^{-1/2}\left( x^2 + 1 - x^2\right)}{x^2 + 1}
$$ If $(x^2+1)^{-1/2}$ was factored out on the top, shouldn't the amount after factoring be just be $1 - x^2$? I am not seeing where the extra $x^2$ is coming from. Can anyone spot the issue I am having?","['factoring', 'algebra-precalculus']"
44628,Is any $K3$ surface of degree $8$ in $\mathbb{P}^5$ the complete intersection of quadrics?,Here the base field is the complex numbers $\mathbb{C}$.,['algebraic-geometry']
44651,$k[x]$-module and cyclic module over a finite dimensional vector space,"Given a finite dimensional vector space $V$ over a field $k$ and a linear transformation $T: V \rightarrow V$ we can make $V$ a $k[x]$-module via the map: $$(a_{0}+a_{1}x+\cdots+a_{n}x^{n}) \cdot v \mapsto \sum a_{i}T^{i}(v).$$ On page 10 of this file I was reading the following result: ""$V$ is a cyclic $k[x]$-module iff the minimal polynomial and the characteristic polynomial coincide"" Can anyone please show me how to prove this? Or any reference? Thanks.","['vector-spaces', 'linear-algebra']"
44659,How can I calculate the standard deviation knowing an event probability and a number of trials?,"I'm writing a test for a probabilistic data structure that I've implemented. Since its probabilistic, its performance is different every time, and in particular, the performance varies much more widely (as a percentage) when the number of items is small. I want the test to fail if the performance is so bad that it's unlikely to have been that bad by chance. Basically, I want a significance test. In the test, I check the structure n times. Each check may fail with probability p. If the total number of failures is more than twice the standard deviation greater than the mean (n*p), I want to fail the test. Now, I know n and I can calculate p. How can I use n and p to get the standard deviation? I know it can be easily estimated by simulation, but there are about a hundred combinations of n and p, so I would prefer a way to just calculate it. Unfortunately, I haven't found an answer, or if I have it was too complex for this layman to notice.","['statistics', 'standard-deviation', 'probability']"
44667,Complex Analysis and Algebra,"There are two results in Complex Analysis that have a counterpart in Algebra: -If we consider the ring of holomorphic functions in an open set $\mathcal H(U)$ with the usual sum and product, every finitely generated ideal is principal. In fact it is generated by any holomorphic function that vanishes exactly where the ideal $I$ and with the same multiplicitiy. This is the same as in $\mathbb C[X]$ (although here all the ideals are finitely generated), where every ideal is characterized by the zeroes and the multiplicities. -In several complex variables, a function which is holomorphic in $U\setminus\{p\}$ is holomorphic in $U$. If we restricted to rational functions $\displaystyle \frac{p(z)}{q(z)}$, this would be a corrolary from the fact that $q(z)=0$ has codimension $1$. Hence it can't be a point. My question is if it is a coincidence that in these two cases, holomorphic functions act somewhat similar to polynomials, or if it is an instance of a more general phenomenon?","['big-picture', 'complex-analysis']"
44670,"How to understand ""maximal"" in the definition of differentiable structure","Consider the definition of differentiable structure ( Lectures on Differential Geometry , S.S. Chern): Suppose $M$ is an m-dimensional manifold. If a given set of coordinate charts ${\mathcal A} = \{(U,\phi_U),(V,\phi_V),(W,\phi_W),\cdots\}$ on $M$ satisfies the following conditions, then we call ${\mathcal A}$ a $C^r$-differentiable structure on $M$: $\{U,V,W,\cdots\}$ is an open covering of $M$; any two coordinate charts in ${\mathcal A}$ are $C^r$-compatible; ${\mathcal A}$ is maximal , i.e., if a coordinate chart $(\tilde{U},\phi_{\tilde{U}})$ is $C^r$-compatible with all coordinate charts in ${\mathcal A}$, then $(\tilde{U},\phi_{\tilde{U}})\in{\mathcal A}$. An example for this definition in that book, is as following:
For $M={\mathbb R}$, let $U=M$, and $\phi_U$ be the identity map. then $\{(U,\phi_U)\}$ is a coordinate covering of ${\mathbb R}$. This provides a smooth differentiable structure on ${\mathbb R}$, called the standard differentiable structure of ${\mathbb R}$. I don't understand how $\{(U,\phi_U)\}$ provides a smooth differentiable structure. Is it maximal? Consider for example $\{(U,\phi_U),(V,\phi_V)\}$ where $V=(0,1)$ and $\phi_V$ the identity map. This puzzles me.",['differential-geometry']
44678,help to prove an inequality,"Suppose $f\in C^2[a,b]$, $f(a)=f(b)=0$. Then for any $x\in [a, b]$:
$$\frac{f(x)}{(x-a)(b-x)}\le \frac{1}{b-a} \int_a^b{|f^{\prime\prime}(t)|dt}.$$ Any help is appreciated.","['inequality', 'calculus', 'analysis']"
44684,What is the smallest number of $45^\circ-60^\circ-75^\circ$ triangles that a square can be divided into?,"What is the smallest number of $45^\circ-60^\circ-75^\circ$ triangles that a square can be divided into? The image below is a flawed example, from http://www.mathpuzzle.com/flawed456075.gif Laczkovich gave a solution with many hundreds of triangles, but this was just an demonstration of existence, and not a minimal solution. ( Laczkovich, M. ""Tilings of Polygons with Similar Triangles."" Combinatorica 10, 281-306, 1990. ) I've offered a prize for this problem: In US dollars, (\$200-number of triangles). NEW:  The prize is won, with a 50 triangle solution by Lew Baxter.","['geometry', 'tiling', 'puzzle', 'recreational-mathematics', 'open-problem']"
44689,How to find a random axis or unit vector in 3D?,"I would like to generate a random axis or unit vector in 3D . In 2D it would be easy, I could just pick an angle between 0 and 2*Pi and use the unit vector pointing in that direction. But in 3D I don't know how can I pick a random point on a surface of a sphere . If I pick two angles the distribution won't be uniform on the surface of the sphere. There would be more points at the poles and less points at the equator. If I pick a random point in the (-1,-1,-1):(1,1,1) cube and normalise it, then there would be more chance that a point gets choosen along the diagonals than from the center of the sides. So thats not good either. But then what's the good solution?","['geometry', 'probability', 'random']"
44694,Understanding algebraic manipulation,"If $a+b+c \neq 0 $ where $a,b$ and $c$ are three non-zero distinct integers, then find the value of: $$\frac{ab+ca}{a^2+ab+ca} + \frac{ab+cb}{b^2+ab+bc} + \frac{ac+cb}{c^2+ac+bc}$$ What confusing me here, is the not so obvious hint which is given with the problem,which says that that form could be written as: $$3- \frac{a^2}{a^2+ab+ca} - \frac{b^2}{b^2+ab+bc} - \frac{c^2}{c^2+ac+bc}$$ But how is this possible?",['algebra-precalculus']
44696,Aren't asteroids contradicting Euler's rotation theorem?,"I am totally confused about Euler's rotation theorem. Normally I would think that an asteroid could rotate around two axes simultaneously. But Euler's rotation theorem states that: In geometry, Euler's rotation theorem
  states that, in three-dimensional
  space, any displacement of a rigid
  body such that a point on the rigid
  body remains fixed, is equivalent to a
  single rotation about a fixed axis
  that runs through the fixed point. It
  also means that the composition of two
  rotations is also a rotation. But asteroids do rotate around two axes. Look at the videos from this website: http://csep10.phys.utk.edu/astr161/lect/asteroids/features.html The Spin of Asteroid Toutatis By making a series of observations, it
  is possible to study the rotation of
  some asteroids. Most have simple
  rotations around a fixed axis, with
  periods typically between one hour and
  one day. For example, here is a movie
  (83 kB MPEG) made by the Hubble Space
  Telescope of the asteroid Vesta in
  rotation (Ref). However, the asteroid
  4179 Toutatis (which crosses Earth's
  orbit) has been found through radio
  telescope observations to have an
  irregular shape and a complex tumbling
  rotation---both thought to arise from
  a history of violent collisions. Here
  is a short animation (47 kB MPEG) of
  the spin of Toutatis; here is a longer
  animation (288 kB MPEG). Here are the movies: http://csep10.phys.utk.edu/astr161/lect/asteroids/toutspin.mpg and http://csep10.phys.utk.edu/astr161/lect/asteroids/toutspin2.mpg You can clearly see that those rotations are not possible around one axis. But then isn't it contradicting Euler's rotation theorem?","['geometry', 'rotations', 'physics', 'euclidean-geometry']"
44697,n-th derivative condition to become polynomial for real function,"I've seen a similar result in complex analysis, when an entire complex function satisfies $f(z)f^{(n)}(z)=0$ for all $z \in \mathbb{C}$ implies that $f(z)$ is polynomial. What if when $f: \mathbb{R} \rightarrow \mathbb{R}$ is a $n$ times differentiable function such that $f(x)f^{(n)}(x)=0$ for all $x\in\mathbb{R}$, does it follow that $f$ is polynomial? thanks. what i have tried so far: 
I tried induction: for $n=1$ we have $f(x)f'(x)=0$ which means $f(x)^2=c$ hence $f'(x)=0$ for all $x$. Supposing the statement is true for $n−1$, I want to prove that $f^{(n)}(x)f(x)=0$ will implies $f^{(n)}(x)f'(x)=0$ which implies $f^{(n)}(x)=0$ (by induction hypothesis) .. my idea is to define function $g$ such that i could get $f^{(n)}(x)f'(x)=0$.. i'm stuck here.. I have another try, by analysing $\bigcup A_j$, where $A_j$ is the open interval on which $f(x)$ is not zero (it can be proved it is indeed interval). 
I also have tried taylor theorem.",['analysis']
