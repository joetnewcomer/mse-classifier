question_id,title,body,tags
1677089,Calculating transformation of normal random variables.,"Let's say you have 4 i.i.d $N(0, 1)$ random variables $X_1 ,X_2, X_3, X_4$, how would you compute the pdf of $\frac{X_1}{\sqrt{X_1^2 + X_2^2 + X_3^2 + X_4^2}}$. I am also interested in the general approach for doing these kind of calculations and if there is a way to do it without running into really messy integrals.","['statistics', 'probability', 'normal-distribution', 'random-variables']"
1677090,evaluate $\int _0 ^\infty \frac{1-\cos(ax)}{x^2}dx$,"Im trying to evaluate for a given $a\in \mathbb R$$$\int _0 ^\infty \frac{1-\cos(ax)}{x^2}dx$$
I have noticed that since $1-\cos(ax)$ is analytic in $\mathbb C$, the integral $$\int _{C}  \frac{1-\cos(az)}{z^2}dz$$where $C$ is a simple closed contour around the point $z_0=0$, is by Cauchy's integral formula: $$(1-\cos(az_0))'=a\sin(az_0)=0$$which might hint that the solution lays within integration of half a circle in the positive (or negative) imaginary plane. I also think that since the function inside the integral is even, it is tempting to try and evaluate the real integral from $-\infty$ to $\infty$, and correspondingly evaluate the complex integral for bigger contours.","['complex-analysis', 'integration', 'contour-integration']"
1677100,"More than basis vectors in a space are dependent, less can't span the space proof","Let $V$ be a vector space, $ B = \{ \mathbf{b}_{1}, \ldots, \mathbf{b}_{n} \}$ a basis for $V$ (independent and spans $V$).
Prove that fewer vectors than $n$ can't span $V$, while more vectors are necessarily dependent. I am looking for a clearer proof than the one on this page: https://math.kennesaw.edu/~plaval/math3260/basis.pdf (middle of third page, Theorem 306), and/or an explanation as to why that system of equations helps prove linear dependence (says to consider said linear combination, but doesn't really explain anything). Thanks!","['linear-algebra', 'vector-spaces']"
1677116,biharmonic complex analysis,"Complex analysis texts typically discuss analytic functions whose real and imaginary components are harmonic and satisfy the Laplace equation, $\nabla^2 f = 0$. I am working with a complex function whose real and imaginary components satisfy the biharmonic equation instead, i.e. $\nabla^4 f= 0$. Thus far I have not been able to find very many resources and was wondering if anyone could point me towards any good books or papers covering this topic.","['complex-analysis', 'harmonic-functions', 'book-recommendation', 'reference-request']"
1677117,Evaluating $\lim_{x \to 0}{\frac{\sin(4x)}{\sin(3x)}}$ without L'Hospital,"I need to evaluate
$$\lim_{x \to 0}{\frac{\sin(4x)}{\sin(3x)}}$$
I solved this using L'Hospital's Theorem and I got 4/3 However, is there a way to do this without applying this theoerm?","['limits-without-lhopital', 'calculus', 'limits']"
1677124,Frechet derivative for bilinear map,"Let $\mathbb{X}, \mathbb{Y}$ and $\mathbb{Z}$ be normed spaces and let $f$ be a bounded bilinear map. Show that $f$ is Frechet differentiable at every $(x,y) \in \mathbb{X} \times \mathbb{Y}$ and find its Frechet derivative. (View f as a map $\mathbb{X} \times \mathbb{Y} \rightarrow \mathbb{Z}$). What I have tried: I think the derivative is the function itself but I'm not sure how to set it out formally. I know how to do it for single normed spaces but I am confused with the bilinear map stuff.","['derivatives', 'frechet-derivative']"
1677176,Integrate $\int_0^\infty \frac{\log x}{x^2+2x+4}\ dx$,"What is $$\int_0^\infty  \frac{\log x}{x^2+2x+4}\ dx$$ Here's a hint that came along with the problem, Substitute $x$ as $2t$ and write it as a sum of two integrals. Then try to simplify.","['integration', 'definite-integrals']"
1677181,"How do you ""linearize"" a differential operator to get its symbol?","Assuming I got some non-linear differential operator $D$, given by $(\partial_xu(x,t))^2-\partial_tu(x,t)=0$, what would its linearization (around a solution $\tilde u$) be? So far I thought of something like a FrÃ©chet derivative, i.e. $Du = D\tilde u + A(u-\tilde u)+o(u-\tilde u)$, where $D\tilde u$ would vanish because $\tilde u$ is a solution. However, I don't see how this $A$ could be written as a ""usual"" DE so I can determine its symbol. After some research, I guess this question could also be seen as a follow-up question to this comment .","['ordinary-differential-equations', 'partial-differential-equations']"
1677183,Taking the topological dual in terms of category theory,"Consider the categories $\mathbf{Vect}$ of vector spaces $X$ with linear maps and $\mathbf{TopVect}$ of topological vector spaces $(X, \tau)$ with continuous linear maps both over $\mathbb{R}$. Taking the algebraic dual is a contravariant functor $* : \mathbf{Vect} \to \mathbf{Vect}$ with $X \mapsto X^*$ and $(f : X \to Y) \mapsto (f^* : Y^* \to X^*)$ (the transpose of $f$) with $(f^*(y^*))(x) := y^*(f(x))$. Similarly, it is also clear that taking the topological dual leads to a contravariant functor $' : \mathbf{TopVect} \to \mathbf{Vect}$ with $X \mapsto X'$ and $(f : X \to Y) \mapsto (f' : Y' \to X')$ with $(f'(y'))(x) := y'(f(x))$. In order to see that this is indeed a functor it is enough to observe that $f'$ is just $f^*$ restricted to $Y' \subseteq Y^*$ and is well-defined, i.e. $f^*|_{Y'} \subseteq X'$ due to continuity of $f$. We can also consider the ""taking the weak* topological dual"" as the contravariant functor $'_\sigma : \mathbf{TopVect} \to \mathbf{TopVect}$ with $X \mapsto X'_\sigma$ and $(f : X \to Y) \mapsto (f' : Y' \to X')$ with $(f'(y'))(x) := y'(f(x))$. Clearly, $'_\sigma$ is well-defined, i.e. $X'_\sigma$ is an object in $\mathbf{TopVect}$ and $f'$ is a morphism in $\mathbf{TopVect}$ since $f'$ is continuous (and linear) by the choice of the weak-* topology on both $X'$ and $Y'$. Similarly, one can also consider more general functors equipping $X'$ with some vector space topology type $\tau_{\text{source}}$ and $Y'$ with a topology type $\tau_{\text{target}}$ such that all the $f'$ are continuous. Questions: Is it possible to decompose the $'_\sigma$-functor into $'_\sigma = E_\sigma \circ \, '$ where $E_\sigma$ is some kind of ""equip with the weak* topology"" functor? The problem is, that we loose information about the space $X$ when performing $'$, but we need $X$ in order to define $E_\sigma$. One plausible solution is to redefine $'$ to $\bar{'} := (', id) : \mathbf{TopVect} \to \mathbf{TopVect} \times \mathbf{Vect}$, $X \mapsto (X', X)$ and set $E_\sigma : im(\bar{'}) \to \mathbf{TopVect}$ that sends the pair $(X', X)$ to the topological vector space $(X', \sigma(X', X))$
where $im(\bar{'})$ is the particular subcategory of $\mathbf{TopVect} \times \mathbf{Vect}$ that we can reach by $\bar{'}$. This construction seems to be rather ugly and artificial. Maybe there is a better description for such a decomposition. All these ""take some top. dual functors"" seem to be special instances of the ""take the algebraic dual"" functor. Is there a better more abstract point of view for such a relation?","['functional-analysis', 'category-theory']"
1677192,"Prove that for any integers $a, b, c, d$ number $(a^2 + b^2)(c^2 + d^2)$ is a sum of two squares of integer. [duplicate]","This question already has answers here : The product of two numbers that can be written as the sum of two squares (2 answers) Closed 8 years ago . Prove that for any integers $a, b, c, d$ number $(a^2 + b^2)(c^2 + d^2)$ is a sum of two squares of integer. In fact I have no idea how to do this and I'll appreciate any tips or the  solution.",['algebra-precalculus']
1677225,The category of locally $P$ spaces,"Let $P$ be a class of topological spaces (for example, compact spaces). The class of locally $P$ spaces consists of those spaces in which every point has a neighborhood basis consisting of $P$ spaces. The class of weakly locally $P$ spaces consists of those spaces in which every point has a neighborhood in $P$. Question. What are some categorical properties of the category of locally $P$ spaces which are not shared by the category of weakly locally $P$ spaces, or vice versa? If necessary, assume that $P$ is closed under suitable  operations. This could shed some light on the question which of the two definitions of locally $P$ spaces is more ""natural"". (And you already might guess my preference.)","['category-theory', 'general-topology', 'soft-question', 'definition']"
1677226,Explaining the standard deviation formula,"I'm revisiting standard deviation for the first time years, and I can't for the life of me recall the difference between two formulas. In particular, I'm also looking for how we arrived at these forumulas. Firstly we have for the sample standard deviation $$ \sqrt{\dfrac{ \sum_{i=1}^{n}(X-\bar{X})^2}{n-1}}$$ Also we have the population standard deviation $$ \sqrt{\dfrac{ \sum_{i=1}^{n}(X-\mu)^2}{n}}$$ From what I understand, we sqaure the difference to remove negative values. After that I'm lost. Is the square root to go back to the difference but without the negatives? Also, why do we divide by $n-1$ on sample, and by $n$ on the population? Why is there a difference and can anyone give a real example?","['normal-distribution', 'standard-deviation', 'probability-distributions', 'robust-statistics', 'statistics']"
1677258,Proving (without using complex numbers) that a real polynomial has a quadratic factor,"The Fundamental Theorem of Algebra tells us that any polynomial with real coefficients can be written as a product of linear factors over $\mathbb{C}$. If we don't want to use $\mathbb{C}$, the best we can say is: If $p(x)$ is a polynomial with real coefficients, $\deg p > 2$, then
  there exists some quadratic polynomial $q(x)$ such that $q(x)$ is a
  factor of  $p(x)$.  (There are then two cases: either $q(x)$ is
  irreducible over $\mathbb{R}$, or it can be further factored as a
  product of linear factors.) This is easily proven as a corollary of the FTA:  If we work over $\mathbb{C}$, $p(x)$ can be written as a product of linear factors, and since a complex number $z$ is a root of $p(x)$ if and only if its conjugate $\bar{z}$ is, we can pair up linear factors so as to get a real quadratic. (In fact, the theorem above -- which seems at first glance like a weaker form of the FTA -- is equivalent to it, since every real quadratic can be factored over $\mathbb{C}$.) Is there a way to prove the above theorem without invoking complex numbers?  It seems to have a certain value on its own as a property of the reals.  For example, the fact that any even-degree real polynomial of $\deg 2n$ can be factored into $n$ (real) quadratics seems like something one should be able to prove without needing to change fields. A version of this question was asked at Factorize real polynomials to quadratic factors. Proof without fundamental theorem of algebra. , but the accepted (and only) answer there just concluded that such a proof would be equivalent to the FTA.  I already know that; I'm wondering how one could write such a proof without passing to the algebraic closure. Or, to put it another way:  The statement of the theorem would make sense (and would be true) even if complex numbers had never been invented (or discovered, if you are a Platonist).  So it seems like it ought to be provable without using complex numbers.  Is it?","['abstract-algebra', 'real-numbers', 'polynomials', 'alternative-proof']"
1677269,Certain symmetrized product of cosines - can it be transformed into more manageable form,"I am interested in the following expression:
$$
F_{k_1,\ldots,k_n}(t):=\sum_{\sigma\in S_n}\cos(\sigma(1)k_1t)\cos(\sigma(2)k_2t)\cdots\cos(\sigma(n)k_nt)
$$
where $k_1, \ldots, k_n$ are natural numbers (can be assumed all different) and $\sigma$ runs over the full permutation group on $\{1,...,n\}$. Does this resemble anything simpler? I want any kind of additional information. To ask something slightly more concrete: expanding this into powers of $t$, coefficients are obviously symmetric functions of $k_1,\ldots,k_n$; they look quite impenetrable. For example,
$$
F_{k_1,k_2,k_3,k_4}(t) = 24-90s_1t^2 + \left(\frac{177}2s_1^2+96s_2\right)t^4 - \left(\frac{163}4s_1^3 + \frac{233}2s_1s_2 + 21s_3 \right)t^6 + \text{(more and more horrible fractions)},
$$
where $s_1, s_2, \ldots$ are the elementary symmetric functions of the $k_i$'s, $s_1=k_1+k_2+k_3+k_4$, $s_2=k_1k_2+k_1k_3+...+k_3k_4$, etc. How to treat this? What would be ideal for me is a decomposition into a product of some nice terms (preferably into sums of sines or cosines, something like that).","['transformation', 'trigonometry', 'trigonometric-series', 'symmetric-functions', 'power-series']"
1677306,How to simplify this equation regarding pronic numbers for integer solutions,"A pronic number is a number that can be expressed as the product of two consecutive positive integers. For instance, $42 = 6 \cdot 7$ is a pronic number. I've become interested in solving for the sequence of all pronic numbers $x_{n}$ such that $2x_{n}$ is also a pronic number. This is essentially then solving the equation $\dfrac{m(m+1)}{n(n+1)} = \dfrac{1}{2}$ for positive integer solutions, I think. My first thought was to take a purely computational approach, and generate a list of all pronic numbers to some limit and them check as to whether each pronic number $\times 2$ was in my list, but this is far too costly and it seems to me there should me some mathematics to simplify my problem. I took a look at the generating function for pronic numbers, and found it to be $\dfrac{2x}{(1-x)^{3}}$. Is there some way I can exploit the power series fractional representation of my problem or something else in order to more concisely express integer solutions to my problem?","['generating-functions', 'computational-mathematics', 'sequences-and-series']"
1677308,Solving $\int {\frac{1}{(-x^{2}+6x-5)^{1/2}}}\;dx$ such that $(1\lt x\lt5)$ using trigonometric substitutions and pythagorean identities,"First post so I'll get right to the question; $$\int {\frac{1}{(-x^{2}+6x-5)^{1/2}}}\;dx,\qquad(1\lt x\lt5)$$ To begin with I completed the square which yields: $$-(x-3)^{2}+4$$ substituting this completed square into the integrand yields: $$\int {\frac{1}{(-(x-3)^{2}+4)^{1/2}}}\,\,dx$$ solving by substituting the trig substitution: let $$x = 3+2\tan u$$ hence: $$\frac{dx}{du} = 2\sec^{2}u$$ thus: $$dx = (2\sec^{2}u) du$$ Rearranging $$x = 3+2\tan u$$ yields $$u=\tan^{-1}(\frac{x-3}{2})$$ Now rewriting the integral using the value of x yields:
$$\int {\frac{1}{(-(3+2\tan u-3)^{2}+4)^{1/2}}}\,\,\,(2\sec^{2}u) du$$ which yields:$$\int {\frac{1}{(-(2\tan u)^{2}+4)^{1/2}}}\,\,(2\sec^{2}u) du$$ which is the same as saying: $$\int {\frac{1}{(-4\tan^{2}u+4)^{1/2}}}\,\,\,(2\sec^{2}u) du$$ which can be rearranged to give: $$\int {\frac{1}{(4-4\tan^{2}u)^{1/2}}}\,\,\,(2\sec^{2}u) du$$ Applying the constant multiple rule to the integral yields:
$$\frac 12\int {\frac{1}{(1-\tan^{2}u)^{1/2}}}\,\,\,(\sec^{2}u) du$$ Now we know that pythagorean identity: $$\tan^{2}u=\sec^{2}u-1$$ so substituting I end up with an indefinite integral that looks like this:
$$\frac 12\int {\frac{1}{(1-\sec^{2}u+1)^{1/2}}}\,\,\,(\sec^{2}u) du$$ which gives:
$$\frac 12\int {\frac{1}{(2-\sec^{2}u)^{1/2}}}\,\,\,(\sec^{2}u) du$$ However this is obviously wrong because I think it is unsolvable. So where did I veer from the right path?","['indefinite-integrals', 'integration', 'trigonometry', 'calculus']"
1677351,Example 19.6 in van der Vaart: show that the class of indicator functions is P-Glivenko-Cantelli and P-Donsker,"I have some doubts related to example 19.6 in van der Vaart ""Asymptotic Statistics"" which applies Theorem 19.4 (Glivenko-Cantelli) and Theorem 19.5 (Donsker) to the distribution function. Definitions: Consider a random variable $X:\Omega \rightarrow \mathcal{X}$ defined on the probability space $(\Omega, \mathcal{A}, \mathbb{P})$ with probability distribution $P$. All functions mentioned from now on will be random functions from $\mathcal{X}$ to $\mathbb{R}$. Consider two functions $l,u$. A bracket $[l,u]$ is the set of all functions $f$ with $l\leq f\leq u$. A $\epsilon$-bracket in $L_r(P)$ is a bracket with $\int_{\mathcal{X}}(u-x)^rdP<\epsilon^r$ with $0<\epsilon<\infty$ and $r>0$.  The $L_r(P)$ norm of a function $f$ is $(\int_{\mathcal{X}}|f|^rdP)^{\frac{1}{r}}$. Let $\mathcal{F}$ be a class of functions $f$. The bracketing number $N_{[\text{ }\text{ }]}(\epsilon, \mathcal{F}, L_r(P))$ is the minimum number of $\epsilon$-brackets in $L_r(P)$ to cover $\mathcal{F}$. The entropy is $\log(N_{[\text{ }\text{ }]}(\epsilon, \mathcal{F}, L_r(P)))$. The bracketing integral $J_{[\text{ }\text{ }]}(1, \mathcal{F}, L_2(P)):=\int_{0}^1 \sqrt{log(N_{[\text{ }\text{ }]}(\epsilon, \mathcal{F}, L_2(P)))d\epsilon}$. Setting: (1) $\{X_i\}_{i=1}^N$ i.i.d. defined on the probability space $(\Omega, \mathcal{A}, \mathbb{P})$; $X_i:\Omega \rightarrow \mathbb{R}$; $P$ is the probability distribution function of $X_i$; $F$ is the cdf of $X_i$ (2) Take the the class of functions $\mathcal{F}:=\{f_t \text{ s.t. } f_t=1(X_i\leq t) \text{ and } t \in \mathbb{R}\}$, where $1(\cdot)$ is the indicator function taking value $1$ if the condition inside is satisfied and $0$ otherwise. I want to show that (1)  $N_{[ \text{ }]}(\epsilon, \mathcal{F}, L_1(P))<\infty$ $\forall \epsilon>0$ (2) $J_{[ \text{ }]} (1, \mathcal{F}, L_2(P))<\infty$  $\leftrightarrow$ $\log N_{[ \text{ }]}(\epsilon, \mathcal{F}, L_1(P))=O(\frac{1}{\epsilon^2})$ Here a summary of the proof in the book with my questions: (a) I believe that (2) implies (1). Hence the proof is focused on showing (2) (b) Consider a finite partition of the extended real line in $-\infty=t_0<t_1<...<t_k=\infty$ such that $\lim_{t\rightarrow t_j^{-}} F(t)-F(t_{j-1})<\epsilon$ for $j=1,...,k$ [it can be shown that it exists]. Consider the brackets $[1(X_i \leq t_{j-1}), 1(X_i \leq t_j)]$ $j=1,...,k$ (c) These brackets have $L_1(F)$-size equal to $\epsilon$, i.e. $\int_{\mathbb{R}}1(x\leq  t_{j})- 1(x \leq t_{j-1})dF=F(t_j)-F(t_{j-1})<\epsilon$. Where does this come from ? The condition $\lim_{t\rightarrow t_j^{-}} F(t)-F(t_{j-1})<\epsilon$ does not imply $F(t_j)-F(t_{j-1})<\epsilon$ unless $t_{j}$ is a continuity point of $F$ (d) Choose $k<\frac{2}{\epsilon}$. How do I know that this is possible? (e) For any function $g(X_i)$ such that $0\leq g\leq 1$ (and hence in one of the brackets) $\int_{\mathbb{R}}g^2 dF\leq \int_{\mathbb{R}}gdF$ (f) Hence, the  $L_2(F)$-size of the brackets is bounded by $\sqrt{\epsilon}$. Why? (g) Hence, $N_{[ \text{ }]}(\sqrt{\epsilon}, \mathcal{F}, L_2(P))\leq \frac{2}{\epsilon}$. Why? (h) Hence, $N_{[ \text{ }]}(\epsilon, \mathcal{F}, L_2(P))\in O(\frac{1}{\epsilon^2})$. Just by taking the square of (f) (i) Hence $\log (N_{[ \text{ }]}(\epsilon, \mathcal{F}, L_2(P)))$ is of order smaller than the order of $\log(\frac{1}{\epsilon})$. Why not $O(\log(\frac{1}{\epsilon^2}))$ [just by taking the log of the square of (g)]? (l) This implies $\log (N_{[ \text{ }]}(\epsilon, \mathcal{F}, L_2(P)))\in  O(\frac{1}{\epsilon^2})$. Why? Is that because $O(\log(\frac{1}{\epsilon^2})) \in O(\frac{1}{\epsilon^2})$? This proof is obscure to me in several parts and any hint on the topic would be really appreciated.","['stochastic-processes', 'probability-theory', 'proof-verification', 'central-limit-theorem', 'proof-explanation']"
1677360,Probability that the roots of a quadratic equation are real,"Roots of the quadratic equation $x^2+5x+3=0$ are $4\sin^2\alpha+a$ and $4\cos^2\alpha+a$. Another quadratic equation is  $x^2+px+q=0$ where $p,q\in\mathbb{N}$ and $p,q\in[1,10]$. Find the probability that the roots of second  quadratic equation are real and that they are $4sin^4\alpha+b$ and $4\cos^4\alpha+b$. $$p^2-4q\ge 0$$ If $p=1$, then no possibilities. If $p=2$, then $q=1$. If $p=7,8,9,10$, then $q\in[1,10]$. But in this way there may be repetitions. I need to find the number quadratic equations first and then I can use the fact the difference in roots for both equations is same to reduce the total possibilities.","['algebra-precalculus', 'trigonometry', 'probability', 'quadratics']"
1677375,Derivative of a probability measure,"Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space and $f: (\Omega, \mathcal{F}) \to (\mathbb{R}, \mathcal{B}(\mathbb{R}))$ a measurable non-negative function s.t. $\int_\Omega f d\mathbb{P}=1$.
  Define for $A\in\mathcal{F} :$
  $$\tilde{\mathbb{P}}(A)=\int_A f d\mathbb{P}$$
  Show, using 'standard machinery', that for $g\in\mathcal{L_1(\Omega)}$ that:
  $$\int_\Omega g d\tilde{\mathbb{P}}=\int_\Omega gf d\mathbb{P}$$ This question seems trivial to me since it follows from working out the differential: $$d\tilde{\mathbb{P}}=fd\mathbb{P}$$ I however assume that is too easy, so I started reading something about the Radon-Nikodym-theorem. It seems like this answer is a direct consequence of that theorem, given that $\tilde{\mathbb{P}}$ is a probabilty measure. Am I correct?","['probability-theory', 'measure-theory']"
1677398,System of Linear Differential Equations,"I'm working on a mass-spring-dashpot system and I have a system of coupled differential equations I'm not sure how to solve. Below I've given a picture of the problem setup. There is a mass $m$ attached to two elements in parallel: a spring $k$ and a dashpot $d$. These are connected to another dashpot $c$. A force $F(t)$ is applied to the junction between $c$ and $k, d$. I've defined some distances such as $x(t)$ and $y(t)$. I'll write my first equation at the yellow point. There are four forces applied here (from $F(t), c, k, d$). Since there is no mass at the yellow dot, we can write: $$0 = F + k(x - y) + d(\dot{x} - \dot{y}) - c\dot{y}$$ I'll write my second equation at mass $m$. There are two forces applied here (from $k, d$). $$m\ddot{x} = -k(x - y) - d(\dot{x} - \dot{y})$$ I now have two equations for two unknowns, $x$ and $y$. What I would like is an equation independent of $y$: it may contain $x, F(t)$, any derivatives of $x$, and any constants. I'm not sure how to solve this system. Both of my equations contain derivatives of both variables, so I don't see a substitution I can make to simplify one to just having $x$. What I attempted to do (from a physics, not a math perspective) was to redraw the diagram using capacitors, inductors, and current sources - this way I could sum up the components using complex impedance. I didn't get very far with this method, though. Any ideas on what I can do? Both equations are linear, so I conjecture a nice solution should exist, but I can't seem to find it.",['ordinary-differential-equations']
1677400,Asymptotics for solutions of a version of Lienard's differential equation,"Consider the second order differential equation
$ x'' + f(x)x' + g(x) = 0 $ with 
$$
f(x) = -\lambda + x^2, \quad g(x) = (-1 + x^2)x \, .
$$
with $\lambda > 0$. Note: The original post had a misprint in this formula. $g$ should be a cubic, not a quadratic. This has the general form of Lienard's equation . Much is known about the asymptotic behavior (as $t \to \infty$) of solutions, if $g(x) = (1 + x^2)x$. Essentially, all non-constant solutions must either lie on a limit cycle (which is unique) or converge to this limit cycle. However, in the form given above, there are stationary points at $x = \pm 1$ that are stable if $\lambda < 1$, there is a Hopf bifurcation as $\lambda$ increases past $1$, and numerical evidence suggests that there are unstable limit cycles coexisting with stable large amplitude limit cycles for some $\lambda < 1$. An image of the stable limit cycle for $\lambda = .772$ is shown below. So the picture is more complicated. Is anything known about the global behavior of solutions for this type of problem?","['stability-in-odes', 'bifurcation', 'ordinary-differential-equations']"
1677402,Does $|f'(x)|<1$ imply $f$ has a fixed point?,"$f :\mathbb R \rightarrow \mathbb R$ is differentiable on $\mathbb R $ and $|f'(x)| \lt 1$, does $f$ have a fixed point? I think it does but I can't finish the proof. Let's define $g(x) = f(x) - x$, we want to prove that this function is equal to $0$ at some point. $g'(x) = f'(x) - 1 \in (-2,0)$, so $g$ is strictly decreasing. What now?",['real-analysis']
1677431,Is $e^e$ irrational?,"I was surprised to find out that the following question is open:
Is $e^e$ transcedental? According to Wikipedia , a positive answer to Schanuel's conjecture implies ""yes"" to the above question. My questions: 1) Can we at least prove that $e^e$ is irrational? Or is this also open? 2) Given that $e^e$ is irrational, does it follow that $e^e$ is transcedental? Added comment : For (2) I mean ""Does the knowledge that $e^e$ is irrational help with the proof that $e^e$ is transcedental?""",['number-theory']
1677440,"Tangents of two circles, a problem in Jules Verne book","Paris in the 20th century by Jules Verne presents the following problem (translation mine): Given two circles $O$ and $O'$: From point $A$ on $O$, two tangents are drawn for $O'$; a line is drawn between the points which they touch [on $O'$]; a tangent is drawn at point $A$ for the circle $O$; the question is what is the intersection point of this tangent and the line that was drawn between the two points of touch on $O'$. How would I solve this problem? I would also like to know if this is a famous problem (I assume it was in 1863, why else Verne would have included it?). Edit: Diagram plotted by Moti . In the diagram, point $C$ is the original problem's $A$.",['geometry']
1677447,Limits problem without L'Hopital,I am prompted to solve the following limit $$\lim_{x\mapsto 0} (\cos(x)^\frac{1}{x^2})$$ I try to approach this problem by doing $$\lim_{x\mapsto 0} (-1+(1+\cos(x))^\frac{\cos(x)}{\cos(x)x^2})$$ where the limit of ($1+\cos(x)^\frac{1}{\cos(x)}$) is $e$. So I would have to calcualte the limit of $\frac{\cos(x)}{x^2}$. Is this approach correct?,"['limits', 'logarithms', 'exponential-function', 'trigonometry', 'functions']"
1677449,Are there order statistics for a Gaussian variable raised to a power?,"Let $X$ be a random variable with a standard normal distribution. Let $Y = |X|^{2p}$. I am trying to find the distribution for $Y_{(n)}$, i.e., the largest value of $Y$ out of $n$ samples. I have derived the pdf to be:
$$f_{Y_{(n)}} = n \left(\frac{1}{p\sqrt{2\pi}} y^{\frac{1}{2p} - 1} \exp\left(-\frac{1}{2}y^{1/p} \right)\right) \left(\int_0^y \frac{1}{p\sqrt{2\pi}} t^{\frac{1}{2p} - 1} \exp\left(-\frac{1}{2}t^{1/p}\right) \, dt \right)^{n-1}$$ But Mathematica says $EY_{(n)}$ is infinite. Intuitively, I feel that it should be some finite value in terms of p and n. Any ideas?","['statistics', 'probability', 'order-statistics', 'normal-distribution']"
1677495,What are some functions that respect the following criteria? : $f(1/x) = f(x)$ and $\int_{0}^{+\infty} f(x) dx = 1$,I'm looking for some functions that respect these six criteria: $f$ is defined on $[0 ; +\infty[$ $f$ is differentiable everywhere in $[0 ; +\infty[$ $f(0) = 0$ $\lim\limits_{x \to +\infty} f(x) = 0$ $f(1/x) = f(x)$ $\int_{0}^{+\infty} f(x) dx = 1$,"['special-functions', 'distribution-theory', 'functions']"
1677497,Parallel curve to a sine wave,"I've been trying to find the formula for the offset/parallel to a sine wave.  Not just the parametric equation, but the y = f(x) form. Here's what I've done so far:
Read up on the parametric form and plugged in the x(t) and y(t) formulas. What I get is of course a parametric equation in terms of t. If $$ y =  \sin x $$ then the parameterization would be $$ x = t $$ $$ y = \sin  t $$ Plugging in the offset formula: $$ x_d(t)  = t + \frac{d\cdot\cos t}{\sqrt{1 + \cos^2 t}} $$ $$ y_d(t)  = \sin t  - \frac{d}{\sqrt {1 + \cos^2 t}} $$ Now, that's all accurate, but it doesn't put it into a function form.  According to my calculus book, the next step is to solve each of these for t and then set them equal to one another.  The problem is that they are kind of a mess, with those sinusoidal functions involved. My question is:  What's the y =  f(x) form for an offset curve of a sine wave? A little background:  I need this because I'm trying to find the intersection point when 3 offsets of three $\pi\over3$ -out-of-phase to each other sine waves intersect.  Basically where the green, blue and red intersect at the same time in the link below.  I can find it numerically, but I'd like it exactly because it's something of discovery to find out how the ancient people drew braids using just compass and straight edges. I can draw it no problem in C#:
The intersection point was found using trial and error and is approximately 0.63. There are two blue lines, two red lines and two green lines, because I used +0.63 offset and -0.63 offset from the sine wave. Thank you in advance for any help.","['derivatives', 'calculus']"
1677509,Solve $\int \sin ^m\left(x\right)\cos ^n\left(x\right)$,"$$\int \sin ^m\left(x\right)\cos ^n\left(x\right)$$ m,n are natural numbers and I'm asked to find the recurrent formula for this integral. Now I know there are three cases to look at namely:
$$ m>n$$
$$ m<n$$
$$ m=n$$ The last case I'm able to solve, but I'm not sure about the first two.
I'm using integration by parts so for example if we take the first case:
$$u=\sin ^m\left(x\right)\cos ^{n-1}\left(x\right)$$
$$dv\:=\:\int \cos \left(x\right)$$ Did I choose the wrong u and dv, because I am not able to solve it. At one point I get something like this: $\int \sin ^m\left(x\right)\cos ^{n-2}\left(x\right)$ in the expression and that's quite problematic.","['indefinite-integrals', 'trigonometry', 'calculus']"
1677519,Problem 19 chapter 9 from PMA Rudin,"Show that the system of equations $$\begin{cases}
3x + y - z+u^2=0 \\
x - y + 2z+u=0 \\
2x + 2y - 3z+2u=0
\end{cases}$$ can be solved for $x,y,u$ in terms of $z$; for $x,z,u$ in terms of $y$; for $y,z,u$ in terms of $x$; but not for $x,y,z$ in terms of $u$. Proof: Let $\mathbf{f}:\mathbb{R}^4\to \mathbb{R}^3$ defined by $$\mathbf{f}(x,y,z,u)=(3x + y - z+u^2, x - y + 2z+u, 2x + 2y - 3z+2u).$$ Also we see that $\mathbf{f}(0,0,0,0)=(0,0,0)$ and $\mathbf{f}'(0,0,0,0)=A$ where $[A]$ has the following form (relative to the standard basis) $$[A]=\begin{bmatrix}
3 & 1 & -1 & 0 \\
1 & -1 & 2 & 1 \\
2 & 2 & -3 & 2 
\end{bmatrix}$$
Our linear operator $A\in L(\mathbb{R}^4,\mathbb{R}^3)$ can be written as: $A(x,y,z,u)=A_1(x,y,u)+A_2(z)$ where $A_1(x,y,u)=A(x,y,0,u)$ and $A_2(z)=A(0,0,z,0)$. And $$[A_1]=\begin{bmatrix}
3 & 1  & 0 \\
1 & -1  & 1 \\
2 & 2 & 2 
\end{bmatrix}$$
Since $\det[A_1]=-12\neq 0$ then $A_1$ is invertible. Then by implicit function theorem exists open neighborhood $W\in \mathbb{R}$ and $U\in \mathbb{R}^4$ of $0$ and $(0,0,0,0)$ respectively. Also to every $z\in W$ exists a unique $(x(z),y(z), u(z))$ such that $$(x(z),y(z), u(z),z)\in U \quad\text{and}\quad \mathbf{f}(x(z),y(z), u(z),z)=0.$$ Hence the system of equations can be solved for $x,y,u$ in terms of $z$. Analogous reasoning can be applied for another cases. How to show rigorously that above system can not be solved for $x,y,z$ in terms of $u$? Can anyone give the full answer? I would be very grateful for help!","['multivariable-calculus', 'linear-algebra']"
1677536,Can a L-shaped figure be divided into 5 congruent shapes?,"Given a square, remove one quarter of it. Can the resulting L-shaped figure be divided into 5 congruent shapes? If not, how can we prove that fact? I tried using circles, triangles and smaller squares, but could not find a solution. Is there a known general solution for any number of divisions, not just 5?","['symmetry', 'congruences-geometry', 'geometry']"
1677547,Probability of record breaking temperature on Feb 29 vs other days,"Is there a higher likelihood of breaking a temperature record (as recorded since NOAA started doing so) on Feb 29th than any other given day, simply because there are fewer sample points to be compared against? The temperature points would still tend to follow the same bell curve, but would the slightly lower resolution (or fewer sample points) increase the odds of a temperature falling outside the limits of existing points?","['statistics', 'probability']"
1677558,Bayesian inference exercise,"I am learning online Bayesian Statistics and I have a test in a couple of days. I have no idea how to solve this exercise, any help will be appreciated. There might be something similar in the quiz... Statistical decision theory: a decision-theoretic approach to the estimation of an unknown parameter $\theta$ introduces the loss function $L(\theta, a)$ which, loosely speaking, gives the cost of deciding that the parameter has the value $a$, when it is in fact equal to $\theta$. The estimate $a$ can be chosen to minimize the posterior expected loss,
$$E(L(a|y))=  \int L(\theta,a)p(\theta|y)d\theta$$
This optimal choice of $a$ is called a Bayes estimate for the loss function $L$. Show that: (a) If $L(\theta, a) = (\theta â a)^2$ (squared error loss), then the posterior mean, $E(\theta|y)$, if it exists, is the unique Bayes estimate of $\theta$. (b) If $L(\theta, a) = |\theta â a|$, then any posterior median of $\theta$ is a Bayes estimate of $\theta$. (c) If $k_0$ and $k_1$ are non negative numbers, not both zero, and $L(\theta,a)= k_0(\thetaâa)$ if $\theta\geq a$,  $k_1(aâ\theta)$ if $\theta<a$, then any $k_0$ quantile of the posterior distribution $p(\theta|y)$ is a Bayes estimate of $\theta$.","['bayesian', 'statistics', 'statistical-inference']"
1677571,"Frobenius mophism, Exercise 7.3 R of Ravi Vakil's book on algebraic geometry","I am a geometry person and got stuck in Exercise 7.3.R which is about Frobenius morphism. Suppose $p$ is a prime and $r \in \mathbb{Z}^+$. Let $q=p^r$ and $k=\mathbb{F}_q$. Define $\phi :k[x_1,\dots,x_n] \rightarrow k[x_1,\dots,x_n]$ by $\phi(x_i)=x_i^p$ for each $i$, and let $F:\mathbb{A}_k^n \rightarrow \mathbb{A}_k^n$ be the map of schemes corresponding to $\phi$. (a) Show that $F^r$ is the identity on the level of sets, but is not the identity morphism. (b) Show that $F$ is a bijection, but is not an isomophism of schemes. (c) If $K=\bar{F}_p$, show that the morphism $F:\mathbb{A}_K^n \rightarrow \mathbb{A}_K^n$ of $K$-schemes corresponding to $x_i \rightarrow x_i^p$ is a bijection, but no power of $F$ is the identity on the level of sets! For (a) and (b), I only know the solution when $n=1$ since $k[x]$ is a PID which makes it very easy. But I got stuck when $n>1$.","['algebraic-geometry', 'commutative-algebra']"
1677579,Proof of every finite group is finitely presented.,"I'm reading the proof that every finite group is finitely presented from Dummit's Abstract Algebra, but there's a part that I don't understand. In the proof below, what are the elements $\tilde{g_i}$? I think they are the cosets $g_iN$, but how do we know that they generate $\tilde{G}$? And why does $|\tilde{G}|=|G|$ lead to $N=\ker \pi$? And finally, how do we get the sufficient condition (ii) in the final sentence? I really do not understand these parts and I'd greatly appreciate any explanations.","['finite-groups', 'abstract-algebra', 'group-theory', 'group-presentation']"
1677582,Infinite Earring and Product Space Homeomorphic,"Old qual question here: We define two topological spaces $X$ and $Y$ as subspaces of certain topological spaces. $X$ is defined as a subspace of $\mathbb{R}^2$ which is the union of the infinite number of circles:
$$X=\bigcup_{i=1}^\infty S^1_n\subset\mathbb{R}^2$$
where $S_n^1$ is a circle in $\mathbb{R}^2$ with radius $1/n$ and center at $(1/n,0)$. Now let $S^1$ denote a unit circle with a marked point $p_*$. $Y$ is defined as a subspace of the infinite product of circles $\prod_{i=1}^n S^1$ with product topology, consisting of points $(p_1,p_2,\dots)$ where $p_i=p_*$ for all $i$ except one. Is $X$ homeomorphic to $Y$? We are very stuck. We only have point set topology at this point in the course. Our thoughts include $\overline{X}=X$ wheras $\overline{Y}$ contains the point $(p_*,p_*,\dots)\not\in Y$, but we are not sure how to capture that idea with homeomorphism (since closure depends on an ambient space). We also know that $X$ is compact, not sure about $Y$.","['general-topology', 'infinite-product']"
1677604,How do people pick $\delta$ so fast in $\epsilon$-$\delta$ proofs,"For example, in a proof that shows $f(x) = \sqrt x$ is uniformly continuous on the positive real line, the proof goes like: Let $\epsilon > 0$ be given, and $\delta = \epsilon^2$.... Or to show that every Lipschitz continuous function is uniformly continuous Let $\epsilon > 0$ be given, and $\delta = \epsilon$.... Do these people have a magic ball that let them see what the $\delta$ value is going to work? I often find myself struggling coming up with the $\delta$ value after doing a bunch of inequalities on $|f(x) - f(y)|< \delta$ to make it less than $\epsilon$. How do people know what $\delta$ is going to be in the first line of their proof?","['real-analysis', 'calculus', 'epsilon-delta', 'proof-writing', 'proof-explanation']"
1677628,A nice way to do Euler's method on a calculator?,"As part of the calculator paper for IB (International Baccalaureate), we may be asked to do Euler's method, for say, 10 iterations. While it is feasible to do with a calculator (slightly easier if you have 2 calculators), it is quite a nuisance, and it is quite easy to make a mistake when I have to retype the numbers back into the calculator. The problem here is that calculators can only store 1 answer ( Ans ) at a time, and that any attempt to store your answer into a memory slot would delete your calculation line which you would have to type in again. On the other hand, you can easily use the calculator to execute recursive functions which only rely on 1 variable. For example, I can calculate the $n$th term of the following recursive sequence by repeatedly pressing the = button: $$T_{n+1}=T_n^3+\sqrt{T_n}-\frac{1}{T_n},\, T_0=5$$ In this example, I would first press 5 = and then type in ${Ans}^3+\sqrt{Ans}-\frac{1}{Ans}$ and press = $n$ times to get $T_n$. However, this is not possible with Euler's method which has recursive formulas: $$x_{n+1}=x_n+h$$
$$y_{n+1}=y_n+h\frac{dy_n}{dx_n}$$ where $h$ is the step (which can be pre-stored in a memory slot) and $\frac{dy_n}{dx_n}=f(x_n, y_n)$. We are allowed to use a graphical calculator (GDC) which has several functions. I have found a way to do this using the spreadsheet function which is quite fiddly, but at least avoids copying mistakes when retyping numbers into my calculator. I was wondering if there were yet easier methods to do this, so I shall ask for the following methods, if possible: Method A I would prefer it if a method with the following restrictions could be used to execute Euler's method: You have a calculator which is an ordinary scientific calculator which has the ability to store the previous answer (Ans). You have the ability to type in a whole function in terms of (Ans) as shown in the first example. Is it possible to type in a one-liner which would do Euler's method by repeatedly pressing = ? *Note: I am aware that this method is probably possible but may be quite complicated to type in/learn. Therefore I would prefer Method B if it is simpler, as I would be under the time pressure of an exam. Nevertheless, I would still be interested in a method A which can do Euler's method for me as I personally prefer my ordinary scientific calculator to my GDC. Method B In addition to the Ans tool given in Method A, you also have the ability to type in $m\times n$ matrices in your calculator. The calculator can take in matrices in its input, and can output matrices which will be stored to Ans. Matrix multiplication (and raising to a power) can be carried out along with transpose, determinant and inverse functions (where possible) on matrices. Note that I cannot ""get"" cell $(i,j)$ of a matrix - I have to use the matrix as a whole. However, I can still do something like the following: $$\pi\begin{bmatrix}\sqrt{\det\left({Ans}^{T} \times \begin{bmatrix}3 & 4\\12 & \det(Ans)\end{bmatrix}^{-1}\right)} & 4\\\det(Ans)^2 & -\det({Ans}^2)\end{bmatrix}^3$$ Similarly, is there a one-liner which would be able to do Euler's method? EDIT: Method C Unfortunately, it turns out that my calculator cannot accept matrices within matrices which is a real shame - my mistake that I thought it could. It can only manipulate matrix answers, and I can only type in constant matrices. Nevertheless, I'm sure there is a way to circumvent this problem with some matrix multiplication. So ny calculator can only do something like: $$\begin{bmatrix}1 & 2 \\ 8 & 2\end{bmatrix}^{-2}\times {Ans}^T \times {(Mat\, A)}^{-1}$$ (Where Mat A is previously stored in the memory. Note that Ans can still be a matrix) Note that my calculators can store values (and matrices in the case of method B) into their memory, but that would only be initial values for variables (like $h$, $x_0$ and $y_0$), as the one-liner must be deleted before I can type in the line which can store memory. In addition to these methods, if there is some function/tool I am completely missing on these calculators which I could use to simplify my task, I would be glad to hear it.","['eulers-method', 'calculator', 'ordinary-differential-equations']"
1677633,Can I order a finite collection of distinct finite sets in such a way $A_i\cup A_{i+1}\neq A_i$?,"If I have a finite collection of $n$ distinct finite sets $\{A_i\}_{i\in I}$, can I give it an order $A_1,A_2,A_3\dots,A_n$ in such a way that $A_i\cup A_{i+1}\neq A_i\ \forall i$? It seems to me clear, but I want to be sure of that.","['combinatorics', 'elementary-set-theory']"
1677708,How many monomorphisms are there $\mathbb{Q} \rightarrow \mathbb{C}$,"I was surprised as to how no sources online really took this particular monomorphism for an example while it seemed very common. My thoughts are that it is only the identity map that exists, so $1$. I am essentially mapping $p \in \mathbb{Q}$ to $a+bi \in \mathbb{C}$. But for it to be a monomorphism, I need $\phi(1)=1$(right?). Then I first have the map $\phi(p)=p+0i=p$ Now if I try to come up with a different monomorphism, namely a non-identity map, so if I have any $t \in \mathbb{Q}$, $t=\frac{p}{q}$ then $\phi'(t=\frac{p}{q})=\frac{\phi'(p)}{\phi'(q)}$. But even for this map, I must have the rule $\phi'(1)=1$. Then, $\phi'(p)=\phi'(1+...+1)=p\phi'(1)=p$ and in a similar manner we end up $\phi'$ mapping it to the same element in $\mathbb{C}$. So $\phi'$ also becomes the identity element no matter what. Am I right? If not, can someone tell me why and how to fix it please.","['abstract-algebra', 'monomorphisms', 'field-theory']"
1677748,Why do ratios of these Fibonacci-type sequences approach $\pi$?,"Define $A_n$ by $A_1=12$, $A_2=18$, and $A_n=A_{n-1}+A_{n-2}$ for $n\ge3$. Similarly define $B_n$ by $B_1=5$, $B_2=5$, and $B_n=B_{n-1}+B_{n-2}$ for $n\ge3$. Terms of $A_n$: $12, 18, 30, 48, 78,\dots$ Terms of $B_n$: $5, 5, 10, 15, 25,\dots$ I found that dividing element $A_n$ by $B_n$ where $n$ approaches $\infty$ appears to result in: $$\lim\limits_{n\to \infty}\left ( \frac{A_n}{B_n} \right ) = \pi$$ My question is, why does the ratio appear to converge towards $\pi$, and what is the significance of $5, 12, 18$ as to why this happens?","['fibonacci-numbers', 'sequences-and-series', 'pi']"
1677814,Does an essentially self-adjoint operator have the same kernel as its closure?,"Let $H$ be a Hilbert space and let $A : D(A) \subset H \to H$ be an essentially self-adjoint operator. Let $\overline A$ be the unique self-adjoint extension of $A$. Question: Is it true that $\ker(A) = \ker(\overline A)$? I don't really see any reason for this to be true, so I tried constructing a counterexample... but somehow this is not so easy to do! For instance, I tried starting with the negative Laplacian $\Delta = - \frac{d^2}{dx^2}$ on $L^2(S^1)$ with domain $\mathrm{dom}(\Delta) = C^\infty(S^1)$. This is an essentially self-adjoint operator and the closure $\overline \Delta$ is easily understood if we look to the frequency domain. On $\ell^2(\mathbb{Z})$, we find $\overline \Delta$ is conjugate to the diagonal operator $D$ on $\ell^2(\mathbb{Z})$ given by $D(a_n) = (n^2a_n)$ and with domain $\{ (a_n) \in \ell^2(\mathbb{Z}) : (na_n) \in \ell^2(\mathbb{Z})\}$. From this, we conclude that $\Delta$ and $\overline \Delta$ have the same one-dimensional kernel. 
$$\ker(\Delta) = \ker(\overline \Delta) = \{\text{constant functions}\} \subset L^2(S^1).$$
Next I tried to replace $\Delta$ by its restriction $\Delta_S$ to some smaller subspace $S \subset C^\infty(S^1)$ such that $S$ intersects trivially with the constant functions, but still manages to be a core for $\Delta$, i.e. has $\overline \Delta_S = \overline \Delta$. However, every subspace $S$ like this I try turns out to give a non essentially self-adjoint $\Delta_S$. For instance, taking $S = \{f \in C^\infty(S^1) : f(p) = 0\}$ for some point $p$ fails. So does taking $S$ to be the smooth functions vanishing on a whole neighbourhood of some point $p$. Any thoughts?","['functional-analysis', 'operator-theory', 'hilbert-spaces', 'unbounded-operators']"
1677824,On conformal metrics notation,"A simple question, just for clarifying: suppose we have two riemannian metrics $g$ and $\tilde{g}$ in a differentiable manifold $M$, and assume they are conformal say, with $\tilde{g} = \mu g$ for some positive valued differentiable function $\mu : M \to \mathbb{R}$. This means that $$\tilde{g}(p)(v, w) = \mu(p) g(p)(v, w), \quad \forall  p \in M, \forall v,w \in T_p M$$ right?","['conformal-geometry', 'notation', 'riemannian-geometry', 'differential-geometry']"
1677853,Differential in Huybrechts,"the differential $df|x:T_x\mathbb{R}^2\to T_{f(x)}\mathbb{R}^2$ of a differentiable map $f:\mathbb{R}^2\to \mathbb{R}^2$ is given by the usual jacobian matrix. However, if we complexify the tangent space, the differential is a complex linear map $df|x_\mathbb{C}:T_x\mathbb{R}^2\otimes \mathbb{C}\to T_{f(x)}\mathbb{R}^2\otimes \mathbb{C}$. The tangent space can be given the $\mathbb{C}$-basis $\{\frac{\partial}{\partial z}:=\frac{1}{2}(\frac{\partial}{\partial x}-i\frac{\partial}{\partial y}), \frac{\partial}{\partial \bar z}:=\frac{1}{2}(\frac{\partial}{\partial x}+i\frac{\partial}{\partial y})\}. $ This I understand. But the following is not clear to me: With respect to this basis the differential $df|x_\mathbb{C}$ is given by the matrix $$\small \begin{pmatrix} \frac{\partial f}{\partial z} & \frac{\partial f}{\partial \bar z} \\     \frac{\partial \bar f}{\partial z} & \frac{\partial \bar f}{\partial \bar z} \end{pmatrix}$$ I would very much appreciate your help explicitely calculating this matrix! I have spent several hours on it, but didn't get a good result. I found this statement in Huybrechts which I link here in case my explanation was not clear enough. Thanks a lot","['complex-geometry', 'complex-analysis', 'differential-geometry']"
1677894,What is the probability that three are males and two are female?,The human sex ratio at birth is commonly thought to be 107 boys to 100 girls. Suppose five infants are chosen at random. (A) What is the probability that three are males and two are female? (B) What is the probability that at least one of them is a male? My work: (A) $(5C2 * 5C3)$ / $207C5$ (B) $(5C1 * 202C)4$ / $207C5$ I'm not sure if these are correct.,"['statistics', 'probability', 'discrete-mathematics']"
1677907,What does the following set mean?,"How are the symbols $\cup$ and $\cap$ are used like that? Can someone please explain what the following does? $$
\bigcup \left\{\{1\}, \{1,2\}, \bigcap\{\{2,3\}, \{3,4\}\}\right\}
$$",['elementary-set-theory']
1677916,How to evaluate integral $\int_0^{\infty} e^{-x^2} \frac{\sin(a x)}{\sin(b x)} dx$?,"I came across the following integral: $$\int_0^{\infty} e^{-x^2} \frac{\sin(a x)}{\sin(b x)} dx$$ while trying to calculate the inverse Laplace transform $$ L_p^{-1} \left[ \frac{\sinh(\alpha\sqrt{p})}{\sinh(\beta\sqrt{p})}
\frac{e^{-\gamma\sqrt{p}}}{\sqrt{p}} \right], |\alpha|<\beta, \gamma>0$$ using the Bromwich integral approach. The contour I used is the following: the above mentioned integral arises while doing integration over the segments $L_1^+,L_2^+,\cdots$ and $L_1^-,L_2^-,\cdots$. I have searched for this integral in Prudnikov et. al., Integrals and Series, v.1, but found nothing. I have also tried to evaluate the integral using residue theorem, but could not quite decide which contour to use. Any help is greatly appreciated! P.S. The ILT can be calculated by noticing that
$$ 	F[p] = \frac{\sinh (\sqrt{p} \alpha)}{\sinh (\sqrt{p} \beta)} 
         \frac{e^{-\gamma\sqrt{p}}}{\sqrt{p}} 
				 = \sum_{n=0}^{\infty} 
				 \left(
					 \frac{e^{-(-\alpha+\beta+\gamma+2n\beta)\sqrt{p}}}{\sqrt{p}}
					 -\frac{e^{-(\alpha+\beta+\gamma+2n\beta)\sqrt{p}}}{\sqrt{p}}
				 \right)$$
using
$$L_p^{-1} \left[ \frac{e^{-\alpha\sqrt{p}}}{\sqrt{p}}  \right] = \frac{1}{\sqrt{\pi t}} e^{-\frac{\alpha^2}{4t}}$$
we get
$$\begin{align*}
	f(t)
	&= L_p^{-1}[F(p)]   \\
	&= \sum_{n=0}^{\infty} 
	   \left(
			 \frac{ e^{-(-\alpha+\beta+\gamma+2n\beta)^2/4t} }{\sqrt{\pi t}}
			 - \frac{ e^{-(-\alpha+\beta+\gamma+2n\beta)^2/4t} }{\sqrt{\pi t}}
		 \right). 
\end{align*}$$
Here I am more interested in calculating the above ILT using the Bromwich integral approach.","['laplace-transform', 'calculus', 'complex-analysis', 'definite-integrals', 'contour-integration']"
1677944,Invariance of function under isometry of Riemannian manifolds,"Suppose that $(M,g)$ and $(N,g')$ are Riemannian manifolds and that $f: M \to N$ is an isometry. Now take smooth vector fields $X, Y, Z$ on $M$. Is it true that $X\langle Y, Z\rangle_p = df_p(X)\langle(df_p(Y), df_p(Z)\rangle_{f(p)}$, where $p \in M$?","['isometry', 'riemannian-geometry', 'differential-geometry']"
1678024,Is there a geometrical interpretation of this equality $2\cdot 4\cdot 6\cdot\ldots\cdot(2n)=2^nn!$?,$$2\cdot 4\cdot 6\cdot\ldots\cdot(2n)=2^nn!$$ How it can be seen in a plane? I have found many proofs with by induction but I wish to understand it geometrically.,"['combinatorics', 'factorial', 'geometric-interpretation', 'geometry']"
1678030,Equivalence of matrix norms,"The equivalence of vector norms on finite dimensional spaces  immediately implies that all induced matrix norms are equivalent. However, for matrix norms (like Frobenius norm, Nuclear norm) that are not induced by a vector norm, one proves equivalence on a case by case basis. Hence my question is, can I say all matrix norms, induced or not, are equivalent ? If so how do I justify it in general ?","['matrices', 'normed-spaces', 'matrix-norms', 'linear-algebra']"
1678037,Show that $\Gamma(z)\Gamma(1-z) \sin \pi z$ is bounded in the complex plane,"Attempt I know that $\Gamma(z)=\int_0^\infty e^{-t}t^{z-1} \ dt$ so $$\lvert \Gamma(z) \rvert \leq \int_0^\infty e^{-t}|t^{z-1}| \ dt=\int_0^{\infty} \frac{e^{-t}}{t} t^{\Re(z)} dt .$$ After this, I'm not really sure what more I can do. Edit I am actually trying to show that $$\frac{\pi}{\sin \pi z} =\Gamma(z) \Gamma(1-z)$$ without resorting to contour integration. However I am beginning to think that showing that this function is bounded might be more work than just carrying out the integration. Sorry for the lack of background in the original question.","['complex-analysis', 'gamma-function', 'beta-function']"
1678058,Implicit function whose domain is $\mathbb R^2$,"Let $F(x, y, z)=z^3+3z+2x^4+y^2-x^2-2y$. I want to show that the equation $F(x, y, z)=0$ defines a $C^2$ function $z=f(x, y)$ whose domain is $\mathbb R^2$. By the implicit function theorem, it's easy to see that such an $f$ exists in a neighborhood of $(0, 0)$, however, I don't know how to show that we can extend this function to $\mathbb R^2$.",['multivariable-calculus']
1678104,"solve the following system of equations in real $x$, $y$","solve for real $x,y$ $$2^{x^2+y}+2^{x+y^2}=8 \tag{1}$$ $$\sqrt{x}+\sqrt{y}=2 \tag{2}$$ Trivially $x=y=1$ Now Equation $(1)$ can be written as $$2^{x^2+(\sqrt{y})^2}+2^{x+(\sqrt{y})^4}=8$$ so we get $$2^{x^2+(2-\sqrt{x})^2}+2^{x+(2-\sqrt{x})^4}=8$$ so $$2^{x^2+4+x-4\sqrt{x}}+2^{x^2+25x+16-32\sqrt{x}-8x\sqrt{x}}=8$$ But i have no clue to proceed..","['algebra-precalculus', 'systems-of-equations']"
1678105,Existence of polynomials in the Diagonal-nilpotent decomposition of a matrix,"Let $V$ be a finite dimensional vector space over $\mathbb{C}$ and $T: V \rightarrow V$ linear operator. Show that there exist polynomials, without constant terms, $g, h \in \mathbb{C}$ such that $g(T)=D_T$ and $h(T)=N_T$, where $D_T$ is a diagonalizable matrix and $N_T$ nilpotent matrix such that $T=D_T+N_T$ and $D_TN_T=N_TD_T$. I have proved that $D_T$ and $N_T$ actually exist by using Jordan Canonical form and now I want to show the existence of the polynomials described above. I want to use the following result to prove the claim: If $f_T=\prod_{i=1}^{r}(t-\lambda_i)^{e_i}$ in $F[t]$ and all the $\lambda_i$ are distinct, then there exists a polynomial $P \in F[t]$ such that $(t-\lambda_i)^{e_i}\mid (P-\lambda_i)$ for all $i$ and $t \mid P$ in $F[t]$. From this result I know that $f_T \mid \prod_{i=1}^{r}(P-\lambda_i)$ and $t^r \mid P^r$. But I don't know how to proceed, any ideas?",['linear-algebra']
1678120,Covariance of multinomial distribution,"Let $X = (X_1,\ldots, X_k)$ be multinomially distributed based upon $n$ trials with parameters $p_1,\ldots,p_k$ such that the sum of the parameters is equal to $1$. I am trying to find, for $i \neq j$, $\operatorname{Var}(X_i + X_j)$. Knowing this will be sufficient to find the $\operatorname{Cov}(X_i,X_j)$. Now $X_i \sim \text{Bin}(n, p_i)$. The natural thing to say would be that $X_i + X_j\sim \text{Bin}(n, p_i+p_j)$ (and this would, indeed, yield the right result), but I m not sure if this is indeed so. Suggestions for how to go about this are greatly appreciated! UPDATE :  @grand_chat very nicely answered the question about the distribution of $X_i + X_j$. How would we go about computing the variance of $X_i - X_j$? As @grand_chat correctly points out, this cannot be binomial because it is not guaranteed to be positive. How, then, should one go about computing the variance of this random variable? UPDATE 2 : The answer in this link answers the question in my UPDATE .","['statistics', 'covariance', 'random-variables', 'probability-distributions']"
1678131,An elliptic integral?,"I ran into an integral a little while ago that looks like an elliptic integral of the first kind, however I am having trouble seeing how it can be put into the standard form.  I've tried messing around with some trig identities but didn't get anywhere. Perhaps there is some other definition that I'm missing. Here it is. If it is solvable by contour integration I would be open to this as well. $$ \int_0^{\phi_0} \frac{d\phi}{\sqrt{1-a\sin{\phi}}}$$ EDIT If it makes it any easier, let $a=2$ and $\phi_0=\frac\pi6$.  By standard form I mean:
$$ \int_0^{\phi_0} \frac{d\phi}{\sqrt{1-k^2\sin^2{\phi}}}=F(\phi_o,k) $$ A Mathematica calculation reveals (using the constants I mentioned): $$\int_0^{\pi/6} \frac{d\phi}{\sqrt{1-2\sin{\phi}}}=i\left(2F(\pi/4,4)-K(1/4)\right)$$ Where $F$ is an incomplete elliptic integral of the first kind and $K$ is a complete elliptic integral of first kind.  Note that Mathematica uses a different convention where $k$ is replaced by the parameter $m=k^2$.  This answer leads me to believe that the integral should be split up somehow.","['special-functions', 'integration', 'elliptic-integrals']"
1678182,Planes through the origin are subspaces of $\Bbb{R}^3$,"I'm reading the book Elementary Linear Algebra by Anton and Rorres, and the following has me a bit confused: ""If $\mathbf{u}$ and $\mathbf{v}$ are vectors in a plane $W$ through the origin of $\Bbb{R}^3$, then it is evident geometrically that $\mathbf{u + v}$ and $k\mathbf{u}$ also lie in the same plane $W$ for any scalar $k$ (Figure 4.2.3). Thus $W$ is closed under addition and scalar multiplication. It says that it is evident that $k\mathbf{u}$ also lies in the same plane $W$, but I feel like if $k$ is sufficiently large enough, the vector $k\mathbf{u}$ would extend outside of the vector space $W$. Can someone explain this to me a little more clearly please?","['linear-algebra', 'vector-spaces']"
1678205,derivative of a function divided by the same function,I've been trying to understand and look for a proof that for example (1) $$\frac{\frac{d}{dx}f(x)}{f(x)}$$ is equal to (2) $$\frac{d}{dx}ln[f(x)]$$ Can someone help me understand why 1 & 2 are equal?,"['derivatives', 'calculus']"
1678218,A property about positive definite matrix,"For any two positive definite same-sized matrices $A$ and $B$, I guessed a property about them and I have verified it via numerical experiment in matlab. The property is stated below: Assume $A$ and $B$ are both $n\times n$ positive definite matrices, then we define a vector $\vec{V}$.
$$V(i)=A_{ii}B_{ii}$$
that is, the $i$th component of $\vec{V}$ is $A_{ii}B_{ii}$. The minimal component of $\vec{V}$ is:
$$V_{min}=min\{V_{i}:i=1,2,3...,n\}$$ Then we can find a bound for the eigenvalue of their product $AB$, denote the smallest eigenvalue of $AB$ $\lambda_{min}$. The claim is that:
$$V_{min}\geq\lambda_{min}$$ Can someone prove it?","['matrices', 'linear-algebra']"
1678221,Chern Weil theory-user friendly guide,"I would like to learn basics about Chern Weil theory but I don't know from which place I should start. I'm after rather basic differential geometry course and have some background in algebraic topology (ordinary homology and cohomology, characteristic classes: Chern, Pontraigin, Stiefel Whitney) but I would like to see geometrical interpretation of the theory of characteristic classes. I will be grateful for any sugestions","['algebraic-topology', 'reference-request', 'differential-geometry']"
1678226,How can we prove that every sequence of $30$ elements from a set of three repeats a subsequence of length 3?,"How can we prove that for every series over $30$ elements(included $30$), there must be a ""sub"" three element series then will repeat itself? (Series's numbers are only $\{1,2,3\}$) Example for a ""sub"" series that repeats itself $12121$ ( ""121"" repeats) , $1111$ ( ""111"" repeats). Example for a good series: $12311122$ Well, this was a question from the exam, unfortunately I wasn't able to answer it. I thought of many ways to solve this, but I'm sure there's fast efficient way to solve this that I don't see. I would love to know how you would approach this.","['combinatorics', 'pigeonhole-principle', 'discrete-mathematics']"
1678232,Find the dimensions of a triangle if its area to be maximum,"A right triangle is to be constructed using a piece of wire of length 2L.
Find its dimensions if its area to be maximum. I have no idea how to solve this, all i know is that i will use local maximum rules.","['calculus', 'geometry']"
1678266,Distributivity of ordinal arithmetic,"Let greek letters be ordinals. I want to prove $\alpha(\beta + \gamma) = \alpha\beta + \alpha\gamma$ by induction on $\gamma$ and I already know it holds true for $\gamma = \emptyset$ and $\gamma$ a successor ordinal. Let $\gamma$ be a limit ordinal. I found
$$
\alpha(\beta + \gamma) = \alpha \cdot \sup_{\epsilon < \gamma} (\beta + \epsilon) = \sup_{\epsilon < \gamma} (\alpha(\beta + \epsilon)) = \sup_{\epsilon < \gamma} (\alpha\beta + \alpha\epsilon) = \alpha\beta + \alpha\gamma,
$$
but I am suddenly doubting if the second equality is justified. Question: Is the second equality correct?","['elementary-set-theory', 'ordinals']"
1678289,Extension of harmonic function with bounded $L^{2}$ norm,"Let $h:D\setminus \{0\}\rightarrow \mathbb{R}$ be a harmonic function, where $D$ is the unit disc in $\mathbb{R}^{2}$, with bounded $L^{2}$ norm, i.e. $||h||_{L^{2}(D)}^{2}=\int_{D}|h|^{2}(x,y)dxdy < \infty$. Is it possible to extend $h$ harmonically to the whole disc $D$? Roman","['functional-analysis', 'complex-analysis', 'real-analysis', 'partial-differential-equations']"
1678329,Measurability of product measures $ \{\mu \in M: (\mu \times \mu)(A) \in B\} \in \mathscr{M}$,"Let $(X,\mathscr{F})$ be a measurable space, and let $M$ be the set all probability measures $\mu: \mathscr{F} \to [0,1]$. Let us denote with $\mathscr{M}$ the $\sigma$-algebra on $M$ generated by the mappings $\mu \to \mu(F)$, with $F \in \mathscr{F}$. Now fix a Borel set $B$ of $\mathbb{R}$ and $A \in \mathscr{F} \otimes \mathscr{F}$. How can we prove that
$$
\{\mu \in M: (\mu \times \mu)(A) \in B\} \in \mathscr{M}?
$$ [Here $(\mu\times \mu)$ stands for the product measure and $\mathscr{F}\otimes \mathscr{F}$ for the product $\sigma$-algebra] [Linked thread on MO: here]","['real-analysis', 'measure-theory']"
1678349,Formulize this sequence,"There is this function defined as; $$f(x) = 10^x + 10^{x-1} +  ...+10^0  $$ Which simply gives the 111.. kind of number, given the length x. What I need to do is a way to formulize this function, find the result value with an algebraic expression. Is this achievable ?","['recreational-mathematics', 'sequences-and-series', 'discrete-mathematics']"
1678363,Why does Wolframalpha think that this sum converges?,"Looking at the sum: $$\sum_{n=1}^\infty\tan\left(\frac\pi{2^n}\right)$$ I'd say that it does not converge, because for $n=1$ the tangent $\tan\left(\frac\pi 2\right)$ should be undefined. But Wolframlpha thinks that the sum converges somewhere around $1.63312Ã10^{16}$ . What am I missing?","['real-analysis', 'summation', 'convergence-divergence']"
1678369,Example of generated sigma-algebra,"I looked at the definition of a generated $\sigma$-algebra in wikipedia ( https://en.wikipedia.org/wiki/Sigma-algebra ) and would like to know if this is correct. Let $X=\{1,2,3,4\}$ and $F=\{\{1\},\{2\}\}$. Is it correct that $\sigma(F)=\{\emptyset,\{1,2,3,4\},\{1\},\{2,3,4\},\{2\},\{1,3,4\}\}$? Thanks. edit: The correct answer is $\sigma(F)=\{\emptyset,\{1,2,3,4\},\{1\},\{2,3,4\},\{2\},\{1,3,4\},\{1,2\},\{3,4\}\}$.",['measure-theory']
1678384,"Proving this $\gcd(2^n-1,3^n+2)=1$ for all postive integers $n$","I have found 
$$\gcd(2-1,3+2)=\gcd(1,5)=1$$
$$\gcd(2^2-1,3^2+2)=\gcd(3,11)=1$$
$$\gcd(2^3-1,3^3+2)=\gcd(7,29)=1$$
$$\gcd(2^4-1,3^4+2)=\gcd(15,83)=1$$
$$\gcd(2^5-1,3^5+2)=\gcd(31,245)=1$$
$$\cdots\cdots$$
I  conjecture $\gcd(2^n-1,3^n+2)=1$,I can't prove this?",['number-theory']
1678483,Integral representation of Bessel function $K_v(y) = \frac{1}{2} \int_{0}^{\infty} t^{v-1} \text{exp}(-\frac{1}{2}y(t+t^{-1}))\text{d}t$.,"How does one find the following representation of the bessel function $K_v(y)$:
$$K_v(y) = \frac{1}{2} \int_{0}^{\infty} t^{v-1} \exp \left(-\frac{1}{2}y\left(t+t^{-1}\right) \right)\,\mathrm{d}t.$$
I have seen many different integral presentations in different sources but couldn't find a proof for this one.","['special-functions', 'integration', 'bessel-functions']"
1678521,Using quadratic reciprocity to motivate higher reciprocity laws?,"I'm an undergraduate following Neukirch's Algebraic Number Theory; Please do not assume much more than chapters $1$ and $2$ of this book to answer. The topics covered are: algebraic number fields, behaviour of ideals, prime splitting, $p$-adic numbers, valuations in general, ... . So, to the question: There is this famous theorem of number theory, called Gauss' Quadratic Reciprocity, which gives us a criterion for deciding whether a equation $x^{2}\equiv p\pmod{q}$, for given primes $p,q$ has solutions. That's what Quadratic Reciprocity was for me: a computational tool (an interesting one). I'm about to begin Class Field Theory and I'm been told that I'll study generalizations of this Gauss' law, namely the so called Reciprocity Map (I think due to Artin). That been said, It would be nice to be able to look at the classic Quadratic Reciprocity from a new point a view that makes it very explicit what aspects of it we are generalizing. Or perhaps just a way of look at the classic result as more than a computational tool would be nice already. There is a part of Neukirch's book where he discusses the quadratic reciprocity (way before CFT), and he says that ""the law of decomposition in the cyclotomic field provides the proper explanation to Gauss' Reciprocity Law"". The proof itself, however, seems a bit technical and I'm not getting it. Can someone help me out? Thanks.","['number-theory', 'algebraic-number-theory', 'elementary-number-theory']"
1678539,Limit of sum of the series,"What would be the sum of following ? $$\lim_{n\to\infty} \left[\frac{1}{(n+1)^{2}} + \frac{1}{(n+2)^{2}} + \frac{1}{(n+3)^{2}} + \cdots + \frac{1}{(n+n)^{2}}\right]$$ I tried to turn it into integral : $\displaystyle\int \frac{1}{(1+\frac{r}{n})^{2}}\frac{1}{n^{2}} $ but 
I can't figure out how to deal with $\frac{1}{n^{2}}$",['algebra-precalculus']
1678541,If a class of functions $\mathcal{F}$ is a Glivenko-Cantelli class then it is also a Donsker class?,"Definitions: Consider a random variable $X:\Omega \rightarrow \mathcal{X}$ defined on the probability space $(\Omega, \mathcal{A}, \mathbb{P})$ with probability distribution $P$. All functions mentioned from now on will be random functions from $\mathcal{X}$ to $\mathbb{R}$. Consider two functions $l,u$. A bracket $[l,u]$ is the set of all functions $f$ with $l\leq f\leq u$. A $\epsilon$-bracket in $L_r(P)$ is a bracket with $\int_{\mathcal{X}}(u-x)^rdP<\epsilon^r$ with $0<\epsilon<\infty$ and $r>0$.  The $L_r(P)$ norm of a function $f$ is $(\int_{\mathcal{X}}|f|^rdP)^{\frac{1}{r}}$. Let $\mathcal{F}$ be a class of functions $f$. The bracketing number $N_{[\text{ }\text{ }]}(\epsilon, \mathcal{F}, L_r(P))$ is the minimum number of $\epsilon$-brackets in $L_r(P)$ to cover $\mathcal{F}$. The entropy is $\log(N_{[\text{ }\text{ }]}(\epsilon, \mathcal{F}, L_r(P)))$. Notice that $N_{[\text{ }\text{ }]}(\epsilon, \mathcal{F}, L_r(P))$ and $\log(N_{[\text{ }\text{ }]}(\epsilon, \mathcal{F}, L_r(P)))$ are decreasing in $\epsilon$. Questions: If $\log(N_{[\text{ }\text{ }]}(\epsilon, \mathcal{F}, L_r(P)))\in O(\frac{1}{\epsilon^2})$ then $N_{[\text{ }\text{ }]}(\epsilon, \mathcal{F}, L_r(P))<\infty$? I.e. if $\mathcal{F}$ is a Glivenko-Cantelli class then it is also a Donsker class? Why? (from p.270 van der Vaart ""Asymptotic Statistics"")","['stochastic-processes', 'law-of-large-numbers', 'probability-theory', 'statistics', 'central-limit-theorem']"
1678548,What's wrong with this transformation?,"I have the equation $\tan(x) = 2\sin(x)$ and I'd like to transform it in this way:
$$\tan(x) = 2\sin(x)
\Longleftrightarrow
\frac{\sin(x)}{\cos(x)} = 2\sin(x)
\Longleftrightarrow
\sin(x) = 2\sin(x)\cos(x)
\Longleftrightarrow
\sin(x) = \sin(2x)$$
But I'm getting a wrong result so I suppose that I can't do it in this way. Why? EDIT: This is my solution:
$$\tan(x) = 2\sin(x)
\Longleftrightarrow
\frac{\sin(x)}{\cos(x)} = 2\sin(x)
\Longleftrightarrow
\sin(x) = 2\sin(x)\cos(x)
\Longleftrightarrow
\sin(x) = \sin(2x)
\Longleftrightarrow
\sin(2x) - \sin(x) = 0
\Longleftrightarrow
2\cos(\frac{3x}{2})\sin(\frac{x}{2}) = 0
\Longleftrightarrow
\cos(\frac{3x}{2}) = 0 \vee \sin(\frac{x}{2}) = 0$$ Proper solution is $\cos(x) = \frac{1}{2} \vee \sin(x) = 0$","['algebra-precalculus', 'trigonometry']"
1678557,"Given any nine numbers, prove there exists a subset of five numbers such that its sum is divisible by $5$.","Given any nine numbers, prove there exists a subset of five numbers such that its sum is divisible by $5$. I tried to take the numbers in the format $5k+1$, $5l+2$, and so on.  However, I am stuck in choosing ANY five from them...also,the numbers included in the subset may or may not belong to same format.","['number-theory', 'combinatorics', 'combinations']"
1678582,When is a function of the largest eigenvalue continuous and/or differentiable?,"I want to understand why the following function, the largest eigenvalue of a symmetric linear operator, is continuous and GÃ¢teaux differentiable . \begin{equation*}
\lambda(V)=\sup_{f \in \ell^2(I):\ \rVert f \lVert_2} \langle (A+V)f, f \rangle, \qquad V \in \ell^2(I)
\end{equation*}
where $I$ is a finite index set (subset of $\mathbb Z^d$ in fact) $A: \ell^2(I) \rightarrow \ell^2(I)$ is a symmetric linear operator that is nonnegative outside its diagonal, so $-A$ is positive definite $V \in \ell^2(I)$ multiplies like the diagonal matrix $\mathrm{diag}(V_1, \dots, V_n)$. I encountered this statement in a probability theory proof where it simply states that this follows easily from the Perron-Frobenius theorem and basic linear algebra. So we should have (1) \begin{equation*}
\lim_{n\rightarrow\infty} \sup_{\lVert f \rVert_2=1} \langle(A+V_n)f,f\rangle
=\sup_{\lVert f \rVert_2=1} \langle(Af,f\rangle, \qquad \mathrm{\ where\ } V_n \rightarrow 0 \mathrm{\ pointwise}
\end{equation*} and the existence of (2)\begin{equation*}
\lim_{t \rightarrow 0}\frac{1}{t} \left( \lambda(V+hg)-\lambda(V) \right)
=\lim_{t \rightarrow 0}\frac{1}{t} \left( \sup_{\lVert f \rVert_2=1} \langle(A+V+hg)f,f\rangle - \sup_{\lVert f \rVert_2=1} \langle(A+V)f,f\rangle \right).
\end{equation*} In (1) the problem is that it's not obvious to me that we may swap the limit and the supremum and I don't see any good reason for this to be true. For (2) I'm simply puzzled. The Perron-Frobenius theorem says that the largest eigenvalue of $A+V$ is simple and that it has a positive eigenfunction. But I don't see how to conclude the existence of the GÃ¢teaux derivative from there. I guess there must be some theorem from linear algebra, but so far my research didn't give me an answer either. Some more context on how I encountered this problem The operator $A$ is the generator $\Delta$ of a symmetric random walk $(X_t)_{t\geq0}$ on $\mathbb{Z}^d$, restricted to a finite, connected subset: \begin{equation*}
\Delta_I f(x) = \sum_{y\in\mathbb{Z}^d:\ |x-y|=1} \omega_{xy} [f(y)-f(x)], \qquad x\in I,\ f: \mathbb{Z}^d \rightarrow \mathbb{R},\ \mathrm{supp}(f)\subset I
\end{equation*}
where $\omega_{xy}=\omega_{yx}\in(0,\infty)$ are symmetric weights. Then I need $\Lambda(V):=\lambda(V)-\lambda(0)$ to be GÃ¢teaux differentiable and continuous with respect to pointwise convergence in order to apply a large deviations principle with rate function $\Lambda$.","['real-analysis', 'hilbert-spaces', 'supremum-and-infimum', 'continuity', 'linear-algebra']"
1678583,Difference between real and complex calculus?,"From the book, Advanced Engineering Mathematics, by Kreyszig , there quotes, ""This differs completely from real calculus, Even if a real function is once differentiable we cannot conclude that it is twice differentiable nor that any of its higher derivatives exist."" What does this sentence mean? what could be particular example for this notion? Does that mean in real calculus there could be a function that is differentiable once ? Or, does the real function may not have higher order differentiable function? what could be that function?","['complex-analysis', 'real-analysis']"
1678608,Does the functional equation $p(x^2)=p(x)p(x+1)$ have a combinatorial interpretation?,"A recent question asked about polynomial solutions to the functional equation $p(x^2)=p(x)p(x+1)$. Subsequently, Robert Israel posted an answer showing that solutions are necessarily of the form $p(x)=x^m(x-1)^m$. What I had hoped to do myself was provide a solution by interpreting $p(x)$ as a generating function, with the functional equation leading to some kind of counting argument for the form of $p(x)$. Robert's answer complicates this, however, because $x^m(x-1)^m$ has coefficients of alternating signs. I then thought to route around this by replacing $x\to-x$ in the functional equation. But, while $p(-x)$ has positive coefficients, $p(-x+1)$ does not and so runs into the same issue. That's as far as my thinking lead me. My question is: Is there some way to understand $p(x)$ (or some transformation of it) so as to provide a useful combinatorial interpretation of the functional equation?","['polynomials', 'alternative-proof', 'combinatorial-proofs', 'generating-functions', 'combinatorics']"
1678615,Why is $A$ a compact operator?,"Let $X$ be a compact space and let $\mu$ be a positive Borel measure on X. Let $T\in \mathscr{B}(L^p(\mu),C(X))$ where $1\lt p \lt \infty$. Show that if $A:L^p(\mu)\rightarrow L^p(\mu)$ defined by $Af=Tf$, then $A$ is a compact operator. Here is an example: let $X=[0,1]$,$\mu$ is the lebesgue measure on $[0,1]$, p=2. $\forall f\in L^2(0,1)$, define $T(f)=\int_0^1{f(x)e^{-ixy}}dx,y\in[0,1]$. Then  $$A:L^2(0,1)\rightarrow L^2(0,1)$$ $$f(x)\rightarrow \int_0^1{f(x)e^{-ixy}}dx, y\in[0,1]$$ 
is a compact operator.(this is a integral operator) Any help would be appreciated!","['functional-analysis', 'compact-operators', 'operator-theory']"
1678621,A nilpotent element of an algebra which does not lie in the span of commutator elements.,"What is  an example of a  C $^{*}$ algebra such that the span of  nilpotent elements is not a sub vector space of the span of commutator elements? Obviously any such C $^{*}$ algebra would be  a  counter example to the question $2$ of the following  MO post: https://mathoverflow.net/questions/231328/the-saturation-of-murray-von-neumann-relation I know that every stable C $^{*}$ algebra or every properly infinite C $^{*}$ algebra can be generated by nilpotent elements. But it seems that such algebras do not admit ""nice"" trace. However for my purpose an algebraic trace (a linear tracial functional which vanishes on commutators, not necessarily positive or bounded) is sufficient.","['c-star-algebras', 'operator-theory', 'functional-analysis', 'noncommutative-geometry', 'operator-algebras']"
1678628,Lebesgue measure of Cantor type set,"I'm learning about Measure Theory and need some help with this problem: Let $0 < \alpha < 1$. We construct a set $C_\alpha$ (Cantor type) as follows: In the first step we remove from the interval $[0, 1]$ a ""middle"" open interval of length $(1 - \alpha)3^{-1}$. In the nth step we remove $2^{n-1}$ open intervals of length $(1 - \alpha)3^{-n}$. Find the Lebesgue measure of $C_\alpha$. My work and thoughts: If we remove the set $C_\alpha$ from the close interval $[0, 1]$ we are left with the union of pairwise disjoint intervals. In more traditionally formulaic notation, we can write: $$[0, 1] \setminus C_\alpha = E_1 \cup E_2 \cup E_3 \cup \ldots$$ Therefore, taking the Lebesgue measure on both side of the preivous equality we get: $$\mu \left([0, 1] \setminus C_\alpha \right) = \mu \left( \bigcup_{n=1}^{+\infty} E_n \right) = \sum_{n = 1}^{+\infty} \mu(E_n).$$ I need to find a way to express $\mu(E_n)$ and calculate the above series. If I can do so then the result is immediate since: $$\mu(C_\alpha) = \mu([0, 1]) - \mu([0, 1]\setminus C_\alpha)$$ where $\mu([0, 1]) = 1$.","['real-analysis', 'lebesgue-measure', 'measure-theory', 'cantor-set']"
1678636,steps to calculate the space surface area cut by a cylinder(see the picture),"The space surface(in yellow) $ x^2+y^2 = 2az\ $ is cut by a cylinder(in green) $x^2+y^2=3a^2 (a>0)$ How to calculate the cut out part area $A$? I think the part is between the two planes $z=0$ and $ z= \frac32a $, and I only have the knowledge of using a formula $ \iint\limits_D \sqrt{1 + z^2_x + z^2_y} $ to calculate the $A$, and I should use it because there is an exercise for using this formula. In this case, $ z=\frac1{2a}(x^2+y^2), D: x^2+y^2 \le 3a^2 $ , so
$$z_x = \frac1ax,\ z_y= \frac1ay$$ $$ A=\iint\limits_D \sqrt{1 + \frac{x^2}{a^2} + \frac{y^2}{a^2}} dxdy= \frac1a \iint\limits_D \sqrt{a^2+x^2+y^2} dxdy $$ using polar coordinates to do the remain steps:
$$\frac1a \int_0^{2\pi}\int_0^{\sqrt3a} \sqrt{a^2+r^2}r dr=\frac\pi a\frac23 ({a^2+r^2})^\frac32\bigg|_0^{\sqrt3a}=\frac{14} 3\pi a^2$$","['multivariable-calculus', 'surface-integrals', 'integration']"
1678681,Idempotent ideals in certain commutative rings,"Let $R$ be a commutative ring with zero Jacobson radical such that each maximal ideal of $R$ is idempotent. Does it guarantee that each ideal is idempotent? I know only that if each maximal ideal is generated by an idempotent element then $R$ turns out to be semisimple Artinian. I think this fact is associated with my question, at least if one could show that any maximal ideal is generated by an idempotent element. Thanks for any suggestion!","['abstract-algebra', 'ring-theory', 'idempotents', 'commutative-algebra']"
1678715,Reciprocal of cos(x),Given the following development: Focusing on the first part: $\cos(x)\sin(x)$ Dividing by $\sin(x)$ gives $\cos(x)$ Shouldn't the reciprocal be $1/\cos(x)$ as opposed to $\cos(x)$?,"['algebra-precalculus', 'trigonometry']"
1678751,Constant LCM of $n$ consecutive numbers,"Let $f:\Bbb N\setminus\{0,1\}\to\Bbb N$ be a function defined by
  $$f(n)=\operatorname{lcm}[1,2,\ldots,n]$$
  Prove that for all $n\ge2$ there exis $n$ consecutive numbers for which $f$ is constant. Find the greatest number of elements of a set of consecutive integers on which $f$ is strictly increasing and determine all sets for which this maximum is realized. I tried with $n!$ but the idea didn't work. Any help will be truly appreciated.","['number-theory', 'elementary-number-theory']"
1678763,Resolution of the $E_8$ singularity with a weighted blowup,"I am reading Miles Reid's notes on weighted projective spaces, and I'm a little confused about a particular paragraph (notes here , page 8): A famous case is the $E_8$ singularity $X: (x^2+y^3+z^5=0)$, which is
  naturally weighted homogeneous with weights 15,10,6. The
  $\mathbb{G}_m$ quotient morphism $X \to \mathbb{P}^1$ defined by the
  ratio $x^2:y^3:z^5$ has stabiliser of order 2, 3, and 5. The weighted
  blowup $Y \to X$ (the graph of the quotient morphism $X \to
\mathbb{P}^1$) is a surface having cyclic quotient singularities of
  order 2,3,5 at the 3 points, giving rise to the Dynkin diagram of
  $E_8$. I'd like to see this very explicitly. I agree that $\mathbb{P}(15,10,6) \cong \mathbb{P}^2$, and I can see that the equation $x^2 + y^3 + z^5$ becomes $u+v+w$ in $\mathbb{P}^2$, with coordinates $(u,v,w)$, so I agree that $X \to \mathbb{P}^1$. However, I am having trouble writing the equations for the graph and observing the singularities Reid describes. Here is what I can do:
The map $\mathbb{A}^3 \setminus \{0\} \to \mathbb{P}(15,10,6)$ is given by $(x,y,z) \mapsto [x:y:z]$, and the isomorphism $\mathbb{P}(15,10,6) \to \mathbb{P}^2$ is $[x:y:z] \mapsto [x^2:y^3:z^5]$. The graph of this map is
$$
\Gamma = \{(x,y,z) \times [u:v:w] \,|\, uy^3=vx^2, uz^5=wx^2,wy^3=vz^5\}
$$
Restricting to $w=-u-v$ I get the equations $(uy^3=vx^2, uz^5=(-u-v)x^2,(-u-v)y^3=vz^5)$. Taking partial derivatives, this appears to be singular everywhere. What have I done wrong?","['projective-space', 'algebraic-geometry', 'blowup']"
1678780,Hartshorne or Vakil's notes,"I believe Hartshorne and Vakil's notes are two most popular text currently, so my question is about how to choose the text. I have worked through the first $4$ chapters of Vakil's notes and now I am thinking whether should I continue or try to study Hartshorne. Vakil's notes are very well-organized. Especially, the exercises appear just in the right time, and there are more explanation of the exercises, so that I know what I am doing. But the problem is most arguments are given in the form of exercises, which means I am always stuck. The typical situation is after $2$ hours work, maybe I am still in the same page. But the book has almost $800$ pages! Hartshorne has some proof, the exercises also have some explanation. So maybe I should try to work Hartshorne? Another question is about exercises. How long should I spend for an exercise that stick me. Should I look up a solution after maybe struggling for half hour? There are solutions for Hartshorne, so maybe study Hartshorne is more convenient since it is easier to look up solution? Also, what is the right pace to learn the stuff? I mean should I worry if every day I spend $3$ hours to learn the stuff but I only finish $1$ page? (I know maybe I should spend more time, but unfortunately I am teaching myself algebraic geometry and I have other classes currently) I appreciate any advice, thanks!","['reference-request', 'book-recommendation', 'soft-question', 'algebraic-geometry']"
1678829,Prove that $| S |\leq5$,"For any $a,b \in S$ there exists $c \in S$ such that $a,b,c$ form an arithmetic progression in some order. Prove that $| S |\leq5$. I am struggling to find examples where it works. I found a very simple example of $\{1,2,3\}$. I tried solving the contrapositive but that seemed to complicate things even further. How should one start when going about solving this?","['number-theory', 'arithmetic-progressions', 'arithmetic']"
1678858,Universal property of topology of uniform convergence,"What kind of universal property does the strong dual topology on $X'$ have, for $X$ being a locally convex space. Is it possible to define $X'$ as the projective limit of the normed spaces $\mathcal{L}(B,\mathbb{C})$ where $B\in \mathfrak{B}_X$ an element of the directed set of bounded subsets of X? What kind of universal property does the uniform norm have? EDIT: What I actually want to know is, in which sense the (bounded) uniform convergence topologies are categorical EDIT: It is known that there is an adjoint pair of functors $(F,G)$ between the symmetric monoidal categories of locally convex spaces and convex bornological spaces. The latter is closed, i.e. for $X,Y \in \mathsf{cbs}$ there is an internal hom object $[X,Y] \in \mathsf{cbs}$, which is just the set of bounded maps together with the bornology of equibounded sets of linear maps. For $A,B \in \mathsf{lcs}$ we obtain a topological space $G(F(A),F(B))$ and since the adjoint pair is the identity on set level, we have $G(F(A),F(B))=B(A,B)$. Moreover, we know that $\mathcal{L}(A,B) \subseteq B(A,B)$. Thus, we can endow $\mathcal{L}(A,B)$ with the initial topology with respect to this inclusion. My guess is, that this coincides with the bounded uniform convergence topology.","['functional-analysis', 'locally-convex-spaces', 'topological-vector-spaces', 'universal-property']"
1678871,Two ways of inducing a metric/topology on a manifold.,"Consider $\Bbb R^3$ equipped with the usual euclidean metric and topology. And consider the subset $S^2 := \{ x\in\Bbb R^3\,|\,d(x,0)=1\}\subset\Bbb R^3$ . Suppose we wanted to make $S^2$ in to a metric space on its own, it seems to me that there are two distinct ways of doing so. The first way would be to define a metric $\,\overline d:\, S^2\times S^2 \rightarrow \Bbb R\,,\;  \overline d(x,y):=d(x,y)\;$ (it is easy to show that this forms a metric on $S^2$). The problem I have with this definition is that it does not really resemble the distance we intuitivly think of when thinking of the sphere (for example the distance between north-and south-pole is 2 instead of $\pi$). The other obvious way would be to define the metric $\widehat d $ by considering all paths on the sphere between to points and defining the distance as the infimum of the lenghts of those paths. This also defines a metric on $S^2$ and seems to be the more intuitive way of doing so (distance between north-and south-pole is $\pi$) . Since the two metrics are not equal, my question is: Do $\overline d$ and $\widehat d$ induce the same topology on $S^2$ ? And if so, is this generally true for manifolds that are embedded in $\Bbb R^n$ ?","['manifolds', 'general-topology', 'metric-spaces']"
1678883,Conditional distribution of random variable X given itself,"I'm stuck with something that might seem trivial but gives me headache.
What is the distribution of $X|X$, i.e. the conditional distribution of $X$ given $X$? I'm pretty confident that: $$\mathbb P(X\le t|X\le s)=\frac{\mathbb P(X\le t  \cap X\le s)}{\mathbb P(X\le s)}=\frac{\mathbb P(X\le t)}{\mathbb P(X\le s)}$$
if $t\le s$ and
$$\mathbb P(X\le t|X\le s)=1$$ otherwise, $t>s$.
However from this point onwards, I am confused.
My intuitive answer would be that the conditional distribution $X|X$ is either the distribution of $X$ or $1$ (but a distribution equal to $1$ doesn't make any sense). P.S. I believe this is related to the question what is the joint distribution of X with itself, $f_{XX}(x,x)$, by
$$f_{XX}(x,x)=f_{X|X}(x|x)\cdot f_{X}(x)$$
but I can't find $f_{XX}(x,x)$ either.","['probability', 'random-variables', 'probability-distributions']"
1678885,Condensation of an expression,"There is an expression: $(h+2p)^2(x+2y)^2 - 3p^2(x+2y)^2-3y^2(h+2p)^2+9p^2y^2$ Is there a way to simplify this to the form $l^2 + 4lk + k^2$? I tried to substitute $l = (h+2p)(x+2y)$ and $k= 3py$ and this takes care of the expressions at the two ends, but the expressions in the middle are stumping me. Alternatively, one may try expressing it in the form $(l+2k)^2 - 3lk$, but I am unable to do this as well. However, I suspect that there is some relationship as $-3lk$ bears resemblance to $- 3p^2(x+2y)^2-3y^2(h+2p)^2$ if you factor out the $-3$. Is it possible to use Fibonnacci Identity in this endeavor? EDIT: The original expression is $(h^2 + 4ph + p^2)(x^2 + 4xy + y^2)$ 
I converted this to $$((h+2p)^2-3p^2)((x+2y)^2-3y^2)$$ EDIT: I tried an alternative approach. I multiplied out this expression:
$$(h^2 + 4ph + p^2)(x^2 + 4xy + y^2)$$ and got the following:
$$h^2x^2 + p^2x^2 + h^2y^2 + p^2y^2 + 4hpx^2 + 4xyh^2 + 4xyp^2 +4hpy^2 + 16hpxy$$ (I'm leaving out some steps) This can be factored into :
$$(hx + py)^2+4(px+hy)(hx+py)+(px+hy)^2 +12hpxy$$ This would have been perfect except for the pesky $12hpxy$.",['algebra-precalculus']
1678940,"What does ""closed under ..."" mean?","What exactly is meant by ""closed under fill in the blank ""? Thanks.","['terminology', 'elementary-set-theory']"
1678954,Bijective continuous map between $\mathbb{R}$ and $\mathbb{R}^2$,"I am currently attending a course on point-set topology and fundamental group. Today we proved in class that $\mathbb{R}$ and $\mathbb{R}^2$ are not homeomorphic with their normal Hausdorff topologies. I also learned from this question that there is in fact no continuous bijection between $\mathbb{R}$ and $\mathbb{R}^2$. I am wondering, what happens when we consider other topologies on $\mathbb{R}$ and $\mathbb{R}^2$? For example, in our course, we discussed cofinite and cocountable topologies, which I denote by $\tau_f$ and $\tau_c$ respectively. I am wondering, are there continuous bijections between $(\mathbb{R}, \tau_c)$ and $(\mathbb{R}^2, \tau_f)$? What about between $(\mathbb{R}^2, \tau_c)$ and $(\mathbb{R}, \tau_f)$?","['continuity', 'reference-request', 'general-topology', 'elementary-set-theory']"
1678971,Variance of max - min of 2 exponential random variables,"Suppose we have 2 random variables, $S\sim Exp(\lambda)$ and $T\sim Exp(\mu)$. Let $U=\min(S,T)$ and $V=\max(S,T)$. What is the variance of $W=V-U$? I calculated: $Var(U) = \frac{1}{(\lambda+\mu)^2}$ $Var(V) = \frac{1}{\lambda^2} + \frac{1}{\mu^2} + \frac{1}{(\lambda+\mu)^2}$ But I don't know how to proceed further.","['covariance', 'statistics', 'probability', 'random-variables']"
1678972,Proof of the relation $\int^1_0 \frac{\log^n x}{1-x}dx=(-1)^n~ n!~ \zeta(n+1)$,"I had the thought that by introducing some parameters into simple integrals and taking derivatives we can get exact values for infinitely many 'complicated' integrals. $$\int_0^1 x^a dx = \frac{1}{a+1}$$ $$\int_0^1 x^a \log x dx = -\frac{1}{(a+1)^2}$$ $$\int_0^1 x^a \log^n x dx = \frac{(-1)^n~ n!}{(a+1)^{n+1}}$$ Since $|x|<1$ the following sum has a closed form: $$\sum_{a=0}^{ \infty } x^a=\frac{1}{1-x}$$ And by definition: $$\sum_{a=0}^{ \infty } \frac{1}{(a+1)^{n+1}}=\zeta(n+1)$$ So we have: $$\int^1_0 \frac{\log^n x}{1-x}dx=(-1)^n~ n!~ \zeta(n+1)$$ Is this proof correct? Can we use this method to find more complicated integrals (assuming the derivatives exist of course)? For example, if we use two more parameters in the original integral: $$\int_0^1 (b+cx)^a dx = \frac{(b+c)^{a+1}-b^{a+1}}{c(a+1)}$$ We can get much more complicated expressions.","['integration', 'definite-integrals', 'calculus', 'proof-verification']"
1678979,Concrete Mathematics - Understanding the generalization in chapter 1 (Josephus),"A couple of months ago, I asked this question, and received a solid answer which provided a thorough level of detail and analysis on the logic behind the initial proof for $A(n) = f(n)$. To clarify, his goal is to show that this recurrence: $$f(1) = \alpha;$$
$$f(2n) = 2f(n) + \beta;$$
$$f(2n + 1) = 2f(n) + \gamma;$$ is equivalent to the following closed form: $$f(n) = A(n)\alpha + B(n)\beta + C(n)\gamma;$$ Deducing that, $$A(n) = 2^m;$$
$$B(n) = 2^m - l - 1;$$
$$C(n) = l$$ However, this requires a proof to be certain. In order to do this, he first proves that $A(n) = 2^m$ through the following recurrence: $$A(1) = 1;$$ 
$$A(2n) = 2A(n) + \beta$$
$$A(2n + 1) = 2A(n) + \gamma$$ for $(\alpha, \beta, \gamma) = (1, 0, 0)$ Then, using $(\alpha, \beta, \gamma) = (1, 0, 1)$ he provides: $$1 = \alpha;$$
$$2n = 2 \times 1 + \beta$$
$$2n + 1 = 2 \times 1 + \gamma$$ Which satisfies $f(n) = n$. For $f(n) = 1$, he provides: $$1 = \alpha;$$
$$1 = 2\times1 + \beta$$
$$1 = 2\times1 + \gamma$$ Which gives us $(\alpha, \beta, \gamma) = (1, -1, -1)$ What I'm trying to figure out is the big picture behind all of this. My understanding is that this technique of generalization for $f$ can be used as a framework for solving different kinds of problems using the fact that we can essentially represent any value $n$ as $2^m + l$, and then derive a recurrence of the given form, using arbitrary constants $(\alpha, \beta, \gamma)$ for some arbitrary purpose. What I don't understand is... how exactly is it that these proofs actually  show this is true? I understand, given the question I provided and its corresponding answer, that they're designed to fill gaps in areas where representing $f(n)$ through some form of these constants requires that $f(n)$ be defined for all n, and that this is a means of providing such proof. How is it that these statements show this fact when they require that $(\alpha, \beta, \gamma)$ be defined to specific values for each case?","['algebra-precalculus', 'discrete-mathematics']"
1678992,"Integrating $\int \frac{\sin x-\cos x}{(\sin x+\cos x)\sqrt{(\sin x \cos x + \sin^2x\cos^2x)}}\,dx$","I came across a question today... Integrate $\int \dfrac{\sin x-\cos x}{(\sin x+\cos x)\sqrt{(\sin x \cos x + \sin^2x\cos^2x)}}\,dx$ How to do it? I tried 1. to take $\sin x \cos x =t$ but no result 2. to convert the thing in the square root into $\sin x +\cos x$ so that I could take $\sin x + \cos x = t$ but then something I got is $\int\frac{-2}{t|t+1|\sqrt{t-1}}\,dt$. Now I don't know how to get past through it.","['indefinite-integrals', 'integration', 'calculus']"
1679028,Is a holomorphic function on $\mathbb{C}$ that's $L^2$ integrable necessarily bounded?,"I'm working on a homework problem and if I can prove this claim then I am finished.  Intuitively the answer should be yes, but I can't think about how I would attempt to rigorously prove this.  I have an entire function $f:\mathbb{C}\rightarrow\mathbb{C}$ and I know that $|f|^2$ is integrable over $\mathbb{C}$.  I want to say this implies that $f$ is bounded and hence the $0$ function by Liouville's theorem. The idea is that if $f$ isn't bounded, then its modulus has to approach infinity as $|z|\rightarrow\infty$ for some particular direction.  But this ""direction"" should be on a set that doesn't have measure $0$ and hence the integral of $|f|^2$ wouldn't be finite, which would contradict my claim.",['complex-analysis']
1679031,"Evalute $\lim\limits_{n\to\infty}\int _{0}^{1}\frac{nf(x)}{1+n^2x^2}\,dx$","Suppose $f\colon [0, 1] \to \mathbb{R}$ is a continuous function, Find the following limit:
$$\lim\limits_{n\to\infty}\int _{0}^{1}\frac{nf(x)}{1+n^2x^2}\,dx$$
I know the  answer is equal   $\frac{\pi}{2}f(0) $, but I don't prove that. Any ideas or insight would be greatly appreciated.","['real-analysis', 'limits', 'calculus', 'integration', 'definite-integrals']"
