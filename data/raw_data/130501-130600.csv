question_id,title,body,tags
2029083,Importance (applications) of functionals,Yes functional analysis is the study of functionals (up to some extend). Why we are so curious to study functionals? Some applications please for the motivations to me.,['functional-analysis']
2029089,Why is a locally closed subscheme defined in this way?,"I have started studying the theory of schemes using the book Algebraic Geometry I by Görtz and Wedhorn. 
There, they give the following definition of a locally closed subscheme: Let $X$ be a scheme. A (locally closed) subscheme of $X$ is a scheme $(Y,\mathcal{O}_Y)$ such that $Y\subseteq X$ is a locally closed subset and such that $Y$ is a closed  subscheme of the open subscheme $U\subseteq X$, where $U$ is the largest open subset of $X$ which contains $Y$ and in which $Y$ is closed (i.e., $U$ is the complement of $\overline{Y}\setminus Y$). We then have a natural morphism of schemes $Y\to X$. My question is the following: why do they take explicitly the largest possible $U$? This seems unnatural to me. Does it make a difference if one takes any open subset $V$ such that $Y$ is a closed subscheme of $V$? Is it not the same, after composing with the inclusion $V\to U$? I think that this probably has some meaning, so there must be some subtle point which I am missing. I have looked it up in other books and, for example, in EGA I the definition is essentially the same. In contrast, the book by Bosch defines a locally closed subscheme as a closed subscheme of an open subscheme ( any , not necessarily the largest possible).","['schemes', 'algebraic-geometry', 'definition']"
2029163,$\frac{1}{n}$ as a difference of Egyptian fractions with all denominators $<n$,"Is there a good characterization of the set $S$ of positive integers $n$ such that $\frac{1}{n}$ can be represented as a difference of Egyptian fractions with all denominators $< n$?
For example, $44 \in S$ because
$$ \dfrac{1}{44} = \left( \frac{1}{33} + \frac{1}{12}\right) - \frac{1}{11} $$ If I'm not mistaken, the first few members of $S$ are
$$ 6, 12, 15, 18, 20, 21, 24, 28, 30, 33, 35, 36, 40, 42, 44, 45 $$
This does not appear to be in the OEIS yet; I intend to submit it soon.
[ EDIT: It is now in OEIS as A278638 .] Here are some things I know so far: If $n \in S$, then $mn \in S$ for any positive integer $m$. $mn \in S$ for integers $m,n$ with  $n < m < 2 n$, because $$\dfrac{1}{mn} = \dfrac{1}{n(m-n)} - \dfrac{1}{m(m-n)}$$ $S$ contains no prime or prime power. There are no members of the form $2p^k$ where $p$ is a prime $> 3$. There are no members of the form $3p^k$ where $p$ is a prime $> 11$.","['number-theory', 'egyptian-fractions', 'elementary-number-theory']"
2029189,Need some examples of self-similar algebraic objects with special properties,"My knowledge in formal logic being too bad, let me define some concepts informally: Let $A$ be some object of type $T$ (like, a set, a topological space, a group, a lie algebra, or everything you could think about). We say that $A$ is self-similar if there exists a strict subobject $B$ of $A$ of the same type $T$ (like, a subset, a subspace with subspace topology, a subgroup, a sub lie algebra, ...) that is $T$-isomorphic to $A$. That is, $A$ embeds into itself strictly. Examples: any infinite set, $(\mathbb{Z},+,0)$ seen as a group, $]0,1[$ seen as a topological space, $\ldots$ Call ss-subobject of $A$ any strict subobject $B$ of $A$ isomorphic to $A$. Now, we say that a self-similar object $A$ is maternal if there exists a maximal (for inclusion) ss-subobject $B$ (by this, I mean that $B$ is maximal in the poset of self-similar subobject of $A$, I don't care if $B$ isn't maximal in the lattice of non necessarily self-similar subobjects). Examples: any infinite set, $(\mathbb{Z},+,0)$, $\mathbb{Q}$ seen as a topological space or a totally order set. Non examples: $]0,1[$, the cantor set, $\ldots$ Finally, we say that a self-similar object $A$ is densely self-similar if for any ss-subobjects $B$ and $C$ of $A$ with $B < C$ (inclusion), there exists a ss-subobject $D$ with $B < D < C$. Example: $]0,1[$ as a topological space. It is clear that if $A$ is densely self-similar, then $A$ is not maternal (by contradiction). Generally, does anyone have an example of non maternal $A$ that is non densely self-similar ? More specifically, can we find an algebraic (i.e., non topological) example of non maternal structure $A$ ? Same for densely self-similar ?","['abstract-algebra', 'general-topology']"
2029238,Russell's paradox: a set cannot contain its own powerset,"I've been trying to challenge myself but with no luck. Maybe one of you will have a better idea.
How can it be proven that there can't be a set which contains its own powerset, using only russell's paradox?
I've managed to prove it with other principles or axioms, such as that a set can not belong to itself, or that a powerset cannot belong to itself.",['discrete-mathematics']
2029257,Examples of pairewise independent but not independent continuous random variables,"By considering the set $\{1,2,3,4\}$, one can easily come up with an example (attributed to S. Bernstein) of pairwise independent but not independent random variables. Counld anybody give an example with continuous random variables ?","['independence', 'probability-theory', 'examples-counterexamples', 'random-variables']"
2029261,Could convergence in measure imply converge almost everywhere for the entire sequence and not just sub-sequence here?,"This doesn't seem to have been asked on this site before. I've been self-studying measure theory and came across this problem. Given a sequence of measurable functions $\{f_n\}_{n \in \mathbb{N}}$ such that for all $\epsilon \gt 0$ $$\sum_{n=1}^\infty \mu (\{x: |f_n (x)| \gt \epsilon \})  \lt \infty $$ Prove that $f_n \to 0$ a.e. I've given the problem a try and clearly the sum being finite implies the summand converges to 0 which satisfies the definition of convergence in measure. Also, I know that there exists a subsequence $f_{n_j}$ converging a.e to 0. In fact, were this a finite measure space, I could prove the problem statement. However, in this more general setting, I'm unable to prove the statement. Any help would be appreciated. This is my first time posting here so I hope I've met all conventions.","['real-analysis', 'lebesgue-measure', 'lebesgue-integral', 'measure-theory', 'analysis']"
2029276,Transivity proof : $y^2$ divides by $2x$,"Given a relation $R=\{(x,y) : y^2 \hbox{ divides } 2x\}$
For $x,y$ natural numbers.
How to go about proving transitivity of the set? 
I have tried many ways.
Or maybe I am mistaken and this is not true?","['discrete-mathematics', 'proof-verification', 'elementary-number-theory']"
2029293,Importance of the uniform boundedness principle,"I've heard that the uniform boundedness principle from functional analysis is a quite important result. The theorem is the following: Let $X$ be a Banach space and $Y$ a normed vector space. Let $F$ be a collection of continuous linear operators $T:X\to Y$ and suppose that $\sup_{T\in F}\|T(x)\|< \infty$ for all $x\in X$ , then $$\sup_{T\in F}\|T\|=\sup_{T\in F, \|x\|=1}\|T(x)\|<\infty.$$ Now, what is the importance of this result? I really can't grasp why this principle is so important as I've seem people say. My question here is: why is this principle so important, and what are the main important consequences of it?","['functional-analysis', 'banach-spaces', 'metric-spaces']"
2029294,Skyscrapper sheaf and generalization of points,"Let $A$ be a commutative ring with unity and $X=\operatorname{Spec}(A)$ together with its structure sheaf $\mathcal{O}_X$. Let $\operatorname{Sky}(\mathcal{O}_{X,x})$ be the skyscrapper sheaf and suppose that $\operatorname{Sky}(\mathcal{O}_{X,x})$ is a quasicoherent sheaf of $\mathcal{O}_X$-modules. I want to show that $x$ does no admit a non trivial generalizations. Suppose that there is some $y \neq x$ such that $y \in \overline{\{ x \}}$. Then the stalk  $\operatorname{Sky}(\mathcal{O}_{X,x})_{y} \cong \mathcal{O}_{X,x}$ by definition of skyscrapper sheaf. Since this sheaf is quasicoherent and $X$ is affine it must be isomorphic to the sheaf associated to the $A$-module $\mathcal{O}_{X,x}$. Let $x=\mathfrak{p}$, and $y=\mathfrak{m}$ (we may assume $y$ to be a maximal ideal) then it is clear that,
$$ A_{\mathfrak{p}} \cong A_{\mathfrak{p}} \otimes_{A} A_{\mathfrak{m}}\cong \mathcal{O}_{X,x} \otimes_{A} A_{\mathfrak{m}},$$ Which respect to which ring is this isomorphism of modules is taken $A_{\mathfrak{p}}$? Is this already a contradiction? Was my reasoning wrong at some point?","['ring-theory', 'sheaf-theory', 'algebraic-geometry']"
2029326,Rock drawing possibility [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question In the latest episode of Survivor there were 6 people and they had to draw rocks from a bag. In the bag were 6 rocks, 5 white rocks and 1 black rock. 
First person drew a rock and kept it in his hand.
Then the second person drew a rock.
Last person took the only rock that left. Then they all showed what they got at the same time. Was the possibility to draw a black rock for each person 1/6 or what was it?",['statistics']
2029336,Does every fraction $ > 1$ occur as $\sigma(n)/n$ for some $n$?,"Here $\sigma$ is the sum of divisor function, so $\sigma(2)/2 = 3/2, \sigma(6)/6 = 2$, $\sigma(24)/24 = 5/2$, $\sigma(11)/11 = 12/11$ etc. I found it hard to find information on these fractions by googling, not in the least because typing $\sigma$ into google will give you tons of links about $\Sigma$. I imagine there is either an elementary argument why the answer is 'no' or it is a well known open problem, but I couldn't find evidence for either option, so all help is welcome.",['number-theory']
2029340,Conics meeting 8 general lines,"I am trying to show that the number of plane conics in $\mathbb{P}^3$ meeting $8$ general lines is $92$, using what I know about intersection theory. I started considering the tautological bundle $S$ of $G=G(2,3)$, and I took $P=P(\operatorname{Sym}^2S^{\vee})$. $P$ is a projective bundle of rank $5$ over $G$ whose fiber over the plane $H$ consists of the conics lying on $H$. I also computed the Chow group of $P$, i.e. $$\mathbb{Z}[h,t]/(h^4,t^6+4ht^5+10h^2t^4+20h^3t^3)$$ What I cannot do is to find the cycle of the conics meeting a given line $L$ (I cannot even prove that it is a closed subscheme!). After that, I just need to elevate it to the eighth power and I should get $92$. Could anyone help?","['intersection-theory', 'projective-geometry', 'algebraic-geometry']"
2029355,How to compute this difficult looking integral,"I am having a really difficult time trying to solve $$\int_{0}^{\infty} \frac{dx}{x^3+x+1}$$ So I know I should definitely be wanting to use residue calculus. Moreover it was asked in the context of residue thereom, so if possible that would be my only intrest It doesn't seem similar to any of the other examples I have because I do not know a simple closed form for the poles, moreover, I dont have any sort of idea of what contour I would need to choose. I think possibly it can be done using the complex logarithm?  I know the answer is approximately $0.921763$ So any ideas/solutions on how to actually come to that final answer? Thanks","['complex-analysis', 'integration', 'residue-calculus']"
2029376,Do $AB$ and $BA$ have the same eigenvalues? [duplicate],This question already has answers here : Do matrices $ AB $ and $ BA $ have the same minimal and characteristic polynomials? (13 answers) Closed 7 years ago . Suppose $A$ and $B$ are $n\times n$ matrices and they are both invertible. Can we say that $AB$ and $BA$ have the same eigenvalues?,"['matrices', 'eigenvalues-eigenvectors', 'linear-algebra']"
2029378,On the asymptotic behaviour of the Cauchy product of harmonic numbers $\sum_{k=1}^n H_k H_{n-k+1}$,"In this post we take in our hands two simple tools. The first is the generating function of the harmonic numbers, you can see it in this Wikipedia, section 3, that holds for $|z|<1$. The second is the Cauchy product formula $$ \left( \sum_{n=1}^\infty a_n \right)  \left( \sum_{n=1}^\infty b_n \right) =  \sum_{n=1}^\infty a_k b_{n-k+1},$$ where the convergence is assumed, there are theorems that tell you when is convergent. In our case our factors are convergents because are the same, and this is well defined: we consider the square of the generating function and after we take the integral $\int_0^{1/2}$ to get if there are no mistakes $$\sum_{n=1}^\infty\frac{1}{(n+2)2^{n+2}}\sum_{k=1}^{n}H_k H_{n-k+1}=\int_0^{1/2}\left(\sum_{n=1}^\infty H_n z^n\right)^2 dz=\int_0^{1/2}\left(\frac{\log(1-z)}{1-z}\right)^2 dz.$$ Notice that is required use the Cauchy product and swap the sign of the series and integral. The integral in RHS is computed in a closed form as $2(\log 2-1)^2$. I don't know if is well known from the literature this sequence $$\sum_{k=1}^n H_k H_{n-k+1}.$$ The sequence starts as $1,3, \frac{71}{12}, \frac{29}{3}, \frac{638}{45}, \frac{349}{18}, \frac{14139}{560}, \frac{79913}{2520}\ldots$ And I would like to know what's about its asymptotic behaviour. One know that the plot of this arithmetic function is smooth (with a well defined slope ), see how Wolfram Alpha can show us the plot of partial sums if you type the code sum HarmonicNumber[k]HarmonicNumber[1000-k+1], from k=1 to 1000 in its online calculator. Question. What's about the asymptotic behaviour of $$\sum_{k=1}^{n}H_k H_{n-k+1}$$
  as $n\to\infty$? I am saying a big oh, or small oh statement or your answer as an asymptotic equivalence. You can provide me hints to get it with summation (I don't know if it is easy), or have you another idea? Thanks in advance. Thus feel free to add hints, references if you need it, or a more detailed answer.","['real-analysis', 'cauchy-product', 'summation', 'harmonic-numbers', 'sequences-and-series']"
2029395,Inflection points with natural logs.,"Where are the inflection points, if any exist, for $f(x)=10\frac{\ln(\ln(x))}{\ln(x)}$?
I don't think any exist. But could use a little help. My guess would be that with the second derivative, if $x = e^{-2}$ you get 0, but this is not in the domain of the function. Is this correct, or completely off? Any help would be appreciated.","['derivatives', 'calculus']"
2029429,The basic of functional derivative,"I've just started to learn mathematical physics, and I read Stone and Goldbart's Mathematics for Physics . But right at the beginning when they introduce the functional derivative, I couldn't understand their explanation: 1.2.1. The functional derivative: We restrict ourselves to expressions of the form $$J[y] = \int_{x_1}^{x_2} f[ \, x, y, y',y'',...y^{(n)} ] \, dx $$ Consider a functional $J=\int f dx$ in which f depends only on $x, y$ and $y'$ . Make a change $y(x) \rightarrow y(x) + \epsilon \eta (x)$ , where $\epsilon$ is a (small) $x$ -independent constant. The resultant change in J is: $$\begin{align} J[y+\epsilon \eta]-J[y] &=\int_{x_1}^{x_2}\{f(x,y+\epsilon \eta,y'+\epsilon \eta')-f(x,y,y')\}dx \\ &= \int_{x_1}^{x_2} \{\epsilon \eta\frac{\partial f}{\partial y}+\epsilon\frac{d\eta}{dx}\frac{\partial f}{\partial y'}+O(\epsilon^2)\}\\ &= ......(\text{this part I understand})\end{align} $$ I can't really wrap my head around this. What is that $\eta(x)$ that suddenly showed up? How did they manage from the first line to the second line in the above expression? And why is there a big-O at the end? (If you don't have the book you can actually find on page 16 right here , the next part is just an integration by part). I'm honestly clueless. It'd be awesome if someone can explain this to me please?",['derivatives']
2029438,Mathematics of hedging bets,"I bet £20 at odds of 3.0.  I have the chance to hedge this bet by laying an amount £$L$ at odds of 3.2, but will have to pay 5% commission on the winnings.  How should I choose $L$ to maximise my minimum payoff? Original post below: Could someone please help me out with the equations behind this calulator? I need to work out the equation for the lay stake which gives an answer of £19.05 in the example. I hope this question makes it a bit clearer. Any help is greatly appreciated. Here is an example","['algebra-precalculus', 'gambling']"
2029450,Prove that $\sqrt{3}\cos(x) + \sin(x) = 2\cos\left(x- \frac{\pi}{6}\right)$,I'm stuck on a trigonometry question. The formulae I have been given don't seem to help so I had to come here. The question is: Prove that $\sqrt{3}\cos(x) + \sin(x) = 2\cos\left(x- \frac{\pi}{6}\right)$ If these formulae can be used I would be glad if you could show me how: $\cos(2x) = 2\cos^2(x) - 1$ $\cos(2x) = 1 - 2\sin^2(x)$ $\cos^2(x) = \frac 12(1 + \cos(2x))$ $\sin^2(x) = \frac 12(1 - \cos(2x))$,"['algebra-precalculus', 'trigonometry']"
2029455,Is there a closed form of the sum $\sum _{n=1}^x\lfloor n \sqrt{2}\rfloor$,"I need to find the n-th partial sum of:
$$\sum _{n=1}^x\lfloor n \sqrt{2}\rfloor$$ Or this sum of a Beatty sequence . I tried to expand as the following: $$=\frac{\sqrt{2} x \left(x+1\right)}{2}-\frac{x}{2}+\frac{1}{\pi }\sum _{n=1}^x\sum _{k=0}^{\infty}\frac{\sin \left(2 \pi \sqrt{2} k\ n\right)}{k}$$ $$=\frac{\sqrt{2} x \left(x+1\right)}{2}-\frac{x}{2}+\frac{1}{\pi }\sum _{n=1}^x \arctan (\tan( \frac{\pi - 2 \pi \sqrt{2} n}{2}))$$ For $ n ∈ \{0,\frac{1}{\sqrt{2}}\}$ $$=\frac{\sqrt{2} x \left(x+1\right)}{2}-\frac{x}{2}+\frac{1}{\pi }\sum _{n=1}^x  \frac{\pi - 2 \pi \sqrt{2} n}{2}$$ But I still have the last term that oscillates around some value and I cant figure out how to find the result without doing the sum up to x. if there is no closed form, is it possible to find it for special values of x? Any hint is appreciated.","['sequences-and-series', 'arithmetic-progressions', 'arithmetic', 'modular-arithmetic', 'ceiling-and-floor-functions']"
2029485,"Conversion from Cartesian to spherical coordinates, calculation of volume by triple integration","Compute volume of the function $(x^{2}+y^{2})^{2}+z^{4}=y$ Attempted solution: $y$ is the sum of a square and a fourth power, clearly $y$ is positive. since the object consists of positive y, the object will occupy 2 quadrants in its proj. on xy plane and it will occupy 2 quadrants on zy plane. the object will have azimuth and co-latitude and distance: $0\le\phi\le\pi,\\ 0\le \theta\le\pi\\ \rho\ge0 $ Now to convert directly to spherical coordinates is my problem, as I understand it, it is easier to convert from Cartesian to cylindrical, and then from cylindrical to spherical. the conversion from Cartesian to cylindrical is as follows: $$x=rcos\theta,\\y=rsin\theta,\\z=z$$
Thus the function $(x^2+y^2)^2+z^4=y$ becomes $$(r^2cos^2\theta+r^2sin^2\theta)^2+z^4=rsin\theta$$
$$(r^2)^2*(1)+z^4=rsin\theta\\r^4+z^4=rsin\theta$$ Now To convert from cylindrical to spherical we may use:
$$r=\rho sin\phi,\\\theta=\theta,\\z=\rho cos\phi$$ We get 
$$\rho^4 sin^4\phi+\rho^4cos^4\phi=\rho sin\theta sin\theta\\\rho^3(sin^4\phi+cos^4\phi)=sin^2\theta\\\rho=\sqrt[3]{\frac{sin^2\theta}{sin^4\phi+cos^4\phi}}$$ the largest value of $sin^nu$ and $cos^nu$ is 1, thus the largest value of $\rho$ is $\sqrt[3]{\frac{1}{2}}$ Thus the limits of integration are $$0\le \phi \le\pi,\\0\le\theta\le\pi.\\0\le\rho\le\sqrt[3]{\frac{1}{2}}$$ What knowledge I would like mathstack's to share; Is this an okay method to convert to spherical coordinates? Am I missing an easier way to convert directly from Cartesian to spherical coordinates? How do I set up the integral, since I want to integrate with respect to Rho, Theta and Phi? please DO NOT solve the triple integral, that would be missing the point. Thanks! refer to this plot: My attempt at integrating: volume of the blob is: $$\int\int\int_A\:dV\\=\int_0^{\sqrt[3]{1/2}}\int_0^\pi\int_0^\pi\:\rho^2 \:sin\phi\: d\theta\: d\phi\: d\rho$$ Check back I will attempt to evaluate $$=\int_0^{\sqrt[3]{1/2}}\int_0^\pi\:\rho^2 \:[-cos\phi]^{\pi}_{0}\: d\phi\: d\rho$$ $$=\int_0^{\sqrt[3]{1/2}}\int_0^\pi\:\rho^2 \:[-cos\pi+cos(0)]\: d\phi\: d\rho$$ $$=\int_0^{\sqrt[3]{1/2}}\int_0^\pi\:2*\rho^2\: d\phi\: d\rho$$ $$=2*\int_0^{\sqrt[3]{1/2}}\int_0^\pi\:\rho^2\: d\phi\: d\rho=2*\int_0^{\sqrt[3]{1/2}}\:[\phi*\rho^2]^\pi_0\: d\rho=2\pi*\int_0^{\sqrt[3]{1/2}}\:\rho^2\:d\rho$$ $$=2\pi*[\phi^3/3]^{\sqrt[3]{1/2}}_0\\=2\pi*\frac{1/2}{3}=\pi/3$$ Thus the volume bound by the surface is $\pi/3$ If anyone would care to check my evaluation that would be greatly appreciated!","['multivariable-calculus', 'integration', 'volume']"
2029494,A basic theorem on Morse Theory: diffeomorphism between two manifolds with boundary induced by a map on a manifold,"I'm trying to understand the following theorem from ""Morse Theory"" by John Milnor: Theorem 3.1 Let f be a smooth real valued function on a manifold M. Let $a<b$ and suppose that the set $f^{-1}[a,b]$ is compact, and contains no crtitical points of f. Then $M^{a}$ is diffeomorphic to $M^{b}$, where $M^{a}=f^{-1}(-\infty,a]$ ed $M^{b}=f^{-1}(-\infty,b]$ Now I'll write the proof I found in the book: Choose a Riemannian metric M; and let $<X,Y>$ denote the inner product of two tangent vectors, as determined by this metric. The gradient of f is the vector field $grad f$ on M which is characterized by the identity $<X,grad f>=X(f)$ for any vector field X. This vector field f vanishes precisely at the critical points of f.
Let $\rho:M\rightarrow R$ be a smooth function which is equal to $\frac{1}{<grad f, grad f>}$ throughout the compact set $f^{-1}[a,b]$; and which vanisches outside of a compact neighborhood of this set. Then the vector field X, defined by
$X(q)$=$\rho (q) grad f(q)$ generates a 1-parameter group of diffeomorphisms of M, that is to say a $C^{\infty}$ map $\phi:R\times M\rightarrow M$ such that - for each t$\in R$ the map $\phi_{t}:M\rightarrow M$ defined by $\phi_{t}(q)=\phi(t,q)$ is a diffeomorphism of M onto itself - for all $t,s \in R$ we have $\phi_{t+s}=\phi_{t}\circ \phi_{s}$ For fixed $q\in M$ consider the function $t\rightarrow f(\phi_{t}(q))$. If $\phi_{t}(q)$ lies in the set $f^{-1}[a,b]$, then $\frac{df(\phi_{t}(q))}{dt}=<\frac{d(\phi_{t}(q))}{dt}(f),grad f>=<X,grad f>= 1$ Thus the correspondence $t\rightarrow f(\phi_{t}(q)$ is linear with derivative 1 as long as $f(\phi_{t}(q))$ lies between a and b. Now consider the diffeomorphism $\phi_{b-a}:M\rightarrow M$. Clearly this carries $M^{a}$ diffeomorphically onto $M^{b}$. Now let's come to the question: It is not clear to me why the last sentence is true. I thought to show that the image of $M^{a}$ through the restriction of $\phi_{b-a}$ to $M^{a}$  is 
contained in $M^{b}$. In order to do that I proved that $f^{-1}(a)$ is sent to $f^{-1}(b)$ through $\phi_{b-a}$ by using the fact we proved"" ...Thus the correspondence $t\rightarrow f(\phi_{t}(q)$ is linear with derivative 1 as long as $f(\phi_{t}(q))$ lies between a and b. "". After that I got stuck. Can someone give me some hints/suggestions to conclude the proof? Thanks in advance.","['morse-theory', 'general-topology', 'differential-topology', 'geometry']"
2029513,Geometry behind least squares under constraints,"I'm trying to solve the following minimisation problem by Lagrange multipliers. My questions is: How to interpret the solutions geometrically? Given a dataset $x_1, \dots, x_n \in \mathbb R^d$, a parameter vector $\theta \in \mathbb R^d$ and some $b \in \mathbb R^d$, I want to minimise
$$J(\theta) = \sum_{k=1}^n \lVert \theta - x_k \rVert^2$$ with respect to $\theta$ under the constraints $\theta^T b = 0$, $\lVert \theta - c \rVert^2 = 1$. For 1., I put $\mathcal L(\theta,\lambda) = J(\theta) - \lambda \theta^T b$, $\lambda \in \mathbb R$, and set $$\frac{\partial}{\partial \theta}\mathcal L(\theta,\lambda)
=\sum_{k=1}^n \frac{\partial}{\partial \theta} \lVert \theta - x_k \rVert^2
- \frac{\partial}{\partial \theta} \lambda \theta^T b
=\sum_{k=1}^n 2(\theta-x_k) - \lambda b = 0.$$ I'm somewhat shaky about the vector calculus, but I hope it's correct? Anyway, this is equivalent to $n \theta - n \bar x = \frac{1}{2} \lambda b$  and gives $\theta_0 = \frac{1}{2n} \lambda b + \frac{1}{n} \bar x $ where $\bar x$ is the sample mean. $\theta_0$ satisfies $\nabla J(\theta) = \lambda \nabla \theta^T b$. By the constraint ${\theta_0}^T b = 0$ we get
$\lambda = -2 {\bar x}^T \frac{b}{\lVert b \rVert}$. Finally, this yields
$$\theta_0 = \frac{1}{n} \bar x \left(1-\frac{b}{\lVert b \rVert}\right).$$ For 2. I get $$\frac{\partial}{\partial \theta}\mathcal L(\theta,\lambda)
=\sum_{k=1}^n \frac{\partial}{\partial \theta} \lVert \theta - x_k \rVert^2
- \frac{\partial}{\partial \theta} \lVert \theta - c \rVert^2 - 1
=\sum_{k=1}^n 2(\theta-x_k) - 2 \lambda (\theta - c)b.$$ Setting this equal to zero gives
$$\theta_0 = \frac{1}{n-\lambda}\left(n \bar x + \lambda c\right).$$ It looks rather messy to feed this into the constraint to compute $\lambda$. Is there some trick I'm missing? Anyway, my problem is that the exercise suggested a geometric meaning behind all of this and I have no clue. Could someone explain to me what's going on?","['multivariable-calculus', 'statistics', 'optimization', 'least-squares']"
2029518,"Please verify my proof: If $a$ and $b$ are irrational, then $a^b$ is irrational.","I would like to prove or disprove the following statement: If $a$ and $b$ are both irrational, then $a^b$ must be irrational. I disproved the statement by giving a counter-example . It follows: Let $a = \sqrt{10}$ and $b = \log(4)$. In this case, both $a$,$b$ $∉$ $\mathbb {Q}$.
  So $a^b = (\sqrt{10})$$^{(\log(4))}=2\in\mathbb {Q}$. Therefore, the statement is false. Am I answering this in a right way? Please help!","['irrational-numbers', 'proof-verification', 'number-theory', 'rational-numbers', 'discrete-mathematics']"
2029538,If $f(x)=x-\int^{\frac{\pi}{2}}_0f(x)\sin(x)dx$ find the explicit function for $f(x)$ in its simplest form,"A function $f(x)$, where $x$ is a real number , is defined implicitly by the following formula:
  $$f(x)=x-\int^{\frac{\pi}{2}}_0f(x)\sin(x)dx$$
  Find the explicit function for $f(x)$ in its simplest form. This question appeared in the recent New Zealand Qualifications Authority 2016 Scholarship Calculus examination. What I have done Let $f(x)=y$ $$f(x)=x-\int^{\frac{\pi}{2}}_0f(x)\sin(x)dx \Rightarrow y=x-\int^{\frac{\pi}{2}}_0y\sin(x)dx$$ $$ y=x-\int^{\frac{\pi}{2}}_0y\sin(x)dx  \Leftrightarrow \int^{\frac{\pi}{2}}_0y\sin(x)dx=x-y$$ Consider the integral $$ \int^{\frac{\pi}{2}}_0y\sin(x)dx$$ Let $u=y\Rightarrow du=dy$ and $dv= \sin(x) \Rightarrow v=-\cos(x)$ $$ \int^{\frac{\pi}{2}}_0y\sin(x)dx = \left[y\sin(x) \right]^{\frac{\pi}{2}}_0+\int^{\frac{\pi}{2}}_0\cos(x) dydx$$ How can I continue?","['integration', 'functions']"
2029541,When y is a function of itself,"When playing around with equations, I've twice found myself in the dilemma where my dependent variable is dependent on itself. In the first instance of this occurring, I spent hours trying things but I concluded algebra could no longer help, so I used Microsoft excel to recursively apply the function for discrete values (small changes in $x$) and referred to the previous cell's value of the dependent variable. I was able to attain a solution this way. However, now that I've come across this problem again in a different context, I would like to understand a bit more about it and if it's possible to solve with math alone. Let me recount to you the dilemma I've had today: Consider $\displaystyle v = \frac{Gmt}{r^2}$ where $v$ is the velocity of a small particle affected by the gravitation of a larger object, $G$ is the gravitational constant, $m$ is the mass of the larger object applying gravitation, $r$ is the distance between the two objects and $t$ is time. The problem is $r$, which is both a function of time and velocity. But velocity is a function of $r$. Can you see my dilemma? $$r = r_0-vt$$ where $r_0$ is the initial distance between the to objects (assume we know this value) The aim here is to plot velocity as a function of time, but I can't even get a concrete function for velocity. Is there any mathematical techniques that can be applied to get velocity solely in terms of $t$? I've been staring at it for ages but I can't figure it out for the life of me. Am I going about this the wrong way, is it even possible to what am asking? If it's not possible, perhaps someone can explain to me exactly what's going on and just help me understand. Thank you, it's much appreciated. (p.s I've not yet been to university so my mathematical background isn't strong. Perhaps the solution is obvious and for that I apologize, but please help if you can)","['algebra-precalculus', 'physics', 'functions']"
2029547,In what way is the calculation of $\lim_{x \to \infty} \frac{4x^2}{x-2}$ wrong?,"Is something wrong with the calculation below? $$ \begin{align}
\lim_{x \to \infty} \frac{4x^2}{x-2} &= \lim_{x \to \infty} \frac{4x}{1-2/x} \\
& = \frac{(\lim_{x \to \infty} 4x)}{(\lim_{x \to \infty} 1-2/x)} \\
& = \frac{(\lim_{x \to \infty} 4x)}{1} \\
& = \lim_{x \to \infty} 4x \\
& = \infty.
\end{align} $$ I ask because if there isn't then the following would seem correct, $$ \begin{align}
\lim_{x \to \infty} \frac{4x^2}{x-2} - 4x &= \left( \lim_{x \to \infty} \frac{4x^2}{x-2} \right) - \left( \lim_{x \to \infty} 4x \right) \\
& = \left( \lim_{x \to \infty} 4x \right) - \left( \lim_{x \to \infty} 4x \right) \\
& = \lim_{x \to \infty} 4x - 4x \\
& = \lim_{x \to \infty} 0 \\
& = 0.
\end{align} $$ But it is not, since $$ \begin{align}
\lim_{x \to \infty} \frac{4x^2}{x-2} - 4x &= \lim_{x \to \infty} \frac{4x^2 - 4x(x-2)}{x-2} \\
&= \lim_{x \to \infty} \frac{8x}{x-2} \\
&= \lim_{x \to \infty} \frac{8}{1-2/x} \\
&= 8. \\
\end{align} $$ In what way is this wrong? Where is the mistake?","['real-analysis', 'indeterminate-forms', 'calculus', 'limits']"
2029575,What are the odds of winning this bingo game?,"I'll explain the game real quick, it's called Pick 8. You get a sheet of paper, containing 3 rows of 8 boxes. You fill out each row with numbers 1-75, in any order, with no duplicates. The bingo caller then starts calling bingo numbers. If you get a row filled during the first 20 numbers called, you win the jackpot, which is usually around \$7000. The first person to win after 20 balls are called wins \$500. I'm interested in the jackpot. Mainly, how many sheets would I need to buy and fill out with an 8-number combination to ensure ~70% probability of winning in the first 20 numbers called? Each sheets costs \$3, so it's \$1 a row. I started by calculating how many 8-number combinations there are in a pool of 75 (where order doesn't matter). Apparently that's called a binomial coefficient, and it comes out to ~16.8 billion combinations. But I don't where to take it from there - how do I take into account the fact that I get 20 chances to get an 8-number combination correct? If I can figure out that, then I can multiply those odds by 3, and then multiply it even further to cover 70% of the possible combos, to see how many sheets I'd need to buy.",['probability']
2029587,Cauchy integral with singularity on contour,"I have been trying to calculate $$ 
I = \oint_C {\rm d}z\; \frac{e^z}{z^2(z-i)} = \oint_C {\rm d}z\; f(z)
$$ with $C = \{z : |z|^2 = 1\}$ (the unit circle). The function $f$ has a simple pole on $C$ , so I changed the contour a bit to avoid this singularity, the figure below shows a sketch I did this inspired by this other question. Now I split my new integration contour into two: $C_1 = \{z: z = e^{i\theta},\; \pi/2 + \epsilon <\theta<5\pi/2 + \epsilon \}$ This is the result I get $$ 
 I_1 = \lim_{\epsilon \to 0} \int_{C_1}{\rm d}z\;f(z) = i\pi e^i \tag{1}
 $$ $C_2 = \{z: z = i + \epsilon e^{i\theta},\; -\pi <\theta<0 \}$ $$ 
 I_2 = \lim_{\epsilon \to 0} \int_{C_2}{\rm d}z\;f(z) = 2\pi(i - 1) -2\pi i e^i \tag{2}
 $$ Now, because I avoided the singularity at $z=i$ , the only pole that contributes to the residues should be $z=0$ $$
{\rm Res}(f,0) = 1 + i \tag{3}
$$ The problem that I have is that $$
I = I_1 + I_2 = 2\pi(i-1) -\pi i e^i
$$ while, by using Cauchy's theorem, I expect $$
I = 2\pi i (i + 1)
$$ Any hints?","['complex-analysis', 'contour-integration', 'cauchy-principal-value']"
2029603,Deriving the inverse of a 2x2 matrix,I am looking for a derivation for the inverse of a 2x2 matrix. I am also wondering why the determinant is involved in the expression. I am familiar with high school maths and linear algebra. If there is an intuitive reason for expression i would also be interested in that.,"['matrices', 'linear-algebra', 'inverse']"
2029624,Given a basis of $T_pM (e_i)$. Extend this base to a local orthonormal frame $(E_i)$ with $\nabla E_i (p) = 0 $,"I have been working this problem almost 3 days, I would appreciate any help or idea: Let (M,h) be a Riemannian manifold. For every $ p \in M $ and $ (e_1 , ... , e_n)$ basis of $T_pM$. There exists an orthonormal frame in an neighborhood of p $(E_1, ... , E_n)$ , with $E_i (p) = e_i$ and $\nabla E_i (p) = 0 $ Hint: Fix an orthonormal frame $(\overline E_i)$ near p with $\overline E_i (p) = e_i$ and define $E_i = \alpha_i^j\overline E_i $ with $(\alpha_i^j(x))_{ij} \in SO(n)$ and $\alpha_i^j(p)= \delta_i^j$. What I have got: The construction of an orthonormal frame $(\overline E_i)$ near p with $\overline E_i (p) = e_i$. Follows from Gram-Schmidt process with no problem. Defining $E_i= \sum_j \alpha_i^j\overline E_i$ the frame is still orthonormal, that follows from a direct calculation and the fact that  $(\alpha_i^j(x))_{ij} \in SO(n)$ and $\overline E_i (p) = e_i$ because $\alpha_i^j(p)= \delta_i^j$. Since $h(E_i,E_j)= \delta_i^j$ then: $h(\nabla_X E_i, E_j) + h(E_i,\nabla_X E_j) = 0 $. So all I have to see is that: $h(\nabla_X E_i, E_j) = h(E_i,\nabla_X E_j) $ Writing the above equation with the koszul formula and doing the calculations, Using the antisymmetry of Lie bracket and the fact that the inner product is commutative: $h(\nabla_X E_i, E_j) - h(E_i,\nabla_X E_j) = -h([E_i,E_j],X) $ So all at have to see is that in p: $[E_i,E_j](p) = 0$ That the Lie bracket its 0 at p for the basis constructed in this way! I have been trying to justify this from lie bracket proprieties with no luck","['riemannian-geometry', 'differential-geometry']"
2029642,"A certain car model costs 21,000 euro now, and it devaluates 5% every year. How much will it cost in 6 years?","A certain car brand estimates that a certain model, that now costs
  21000 euro, will devaluate 5% per year. How much will this car cost in 6 years? I did: $$21000 \cdot (1+.05)^6 \approx 28142$$ Now I remove the initial value from this one to get the compound devaluation $$28142-21000 = 7142$$ Then I subtract this value from the initial value $$21000-7142 = 13858$$ But my book says the solution is 15,437 euro. What did I do wrong?","['algebra-precalculus', 'percentages', 'word-problem', 'arithmetic']"
2029655,Compute the equivalence classes,"Define an equivalence relation on $\mathbb{R}^2$ by $\textbf{x}\sim\textbf{y}$ iff $\exists A\in GL_2(\mathbb{R})$ such that $A\mathbf{x}=\mathbf{y}$. Compute the equivalence classes of this equivalence relation. My attempt: Let $\mathbf{x}=\begin{bmatrix}
    0 \\
    0 
\end{bmatrix}$. $A\mathbf{x}=\begin{bmatrix}
    0 \\
    0 
\end{bmatrix}$ $\forall A\in GL_2(\mathbb{R})$ So, it seems that the zero vector resides alone in its equivalence class. My hunch is that all the other (nonzero) vectors reside in the other equivalence class, making a total of 2 equivalence classes. But I don't know how to prove this as there doesn't seem to be any obvious way to solve for the matrix $A$ in the equation $A\mathbf{x}=\mathbf{y}$. Can someone please tell me how to proceed?",['linear-algebra']
2029672,$\frac{{\sin \theta \cos \theta}}{1!}+\frac{{\sin 2\theta \cos ^2\theta}}{2!}+\frac{{\sin 3\theta \cos ^3\theta}}{3!}+...\infty$,"I have tried replacing $\ x$ with $\cos x$ in the maclaurin series of $\ e^x$, but stuck with the $\sin$ terms. Is there any other method to solve this question.","['taylor-expansion', 'sequences-and-series', 'complex-numbers']"
2029675,"Soft question: How to pronounce ""Clairaut""","I'm preparing for a presentation tomorrow and I will refer to clairaut's theorem in multivariable calculus (mixed partials are equal) Can French speakers chime in as to how to correctly pronounce clairaut (for an english speaker). Is it pronounced ""clear-roo"" or.. Thanks!","['multivariable-calculus', 'soft-question', 'terminology']"
2029690,"Is the largest diagonal diagonal entry of a symmetric, positive semidefinite matrix a lower bound on the largest eigenvalue?","Well, the question is as simple as that: Given a symmetric and positive semidefinite matrix. Is it true that the largest diagonal entry is always smaller or equal to the largest eigenvalue? I was just getting a little frustrated while proving this for a specific kind of matrix (that happens to be symmetric and positve definite). So I'm wondering whether I can just skip the algebra and show that this is true in general. But a quick web search didn't reveal any promising references. Can someone clear up for me whether this is true or not?","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra']"
2029701,What is the Lie algebra of the Euclidean group?,"I am trying to find the Lie algebra for $E(n) = \left\{\begin{bmatrix}1 & 0^t \\
\mathbf{x} & A
\end{bmatrix}: A \in SO(n), \mathbf{x} \in \mathbb{E}^n \right\}$. In particular, I would like to show that $\mathfrak{e}(n) = \left\{\begin{bmatrix}0 & 0^t \\ \mathbf{b} & B \end{bmatrix}:B \in \mathfrak{so}(n),\mathbf{b} \in  \mathbb{E}^n \right\}$ using only the definition that a Lie algebra is the tangent space at the identity of the Lie group. I've managed to show that $\mathfrak{so}(n)$ is the set of skew-symmetric matrices but I'm not sure how to proceed from there. Thank you in advance.","['differential-geometry', 'lie-algebras', 'lie-groups']"
2029707,Entropy of the multivariate Gaussian,"Show that the entropy of the multivariate Gaussian $N(x|\mu,\Sigma)$ is given by
  \begin{align}
H[x] = \frac12\ln|\Sigma| + \frac{D}{2}(1 + \ln(2\pi))
\end{align}
  where $D$ is the dimensionality of $x$. My solution. Entropy for normal distribution: \begin{align}
H[x] = -\int_{-\infty}^{+\infty}N(x|\mu,\Sigma)\ln(N(x|\mu,\Sigma)) dx = &&\text{by definition of entropy}\\
= -E[\ln(N(x|\mu,\Sigma))] =\\
= -E[\ln((2\pi)^{-\frac{D}{2}} |\Sigma|^{-\frac12} e^{-\frac12(x - \mu)^T\Sigma^{-1}(x - \mu)})] = &&\text{definition of multivariable gaussian}\\
= \frac{D}{2}\ln(2\pi) + \frac12\ln |\Sigma| + \frac12E[(x - \mu)^T\Sigma^{-1}(x - \mu)] &&\text{the log of a product is the sum of the logs}.
\end{align} Consider the third term: \begin{align}
\frac12E[(x - \mu)^T\Sigma^{-1}(x - \mu)] = \\
= \frac12E[x^T\Sigma^{-1}x - x^T\Sigma^{-1}\mu - \mu^T\Sigma^{-1}x + \mu^T\Sigma^{-1}\mu] = \\
= \frac12E[x^T\Sigma^{-1}x] - \frac12E[2\mu^T\Sigma^{-1}x] + \frac12E[\mu^T\Sigma^{-1}\mu] = \\
= \frac12E[x^T\Sigma^{-1}x] - \mu^T\Sigma^{-1}E[x] + \frac12\mu^T\Sigma^{-1}\mu = \\
= \frac12E[x^T\Sigma^{-1}x] - \mu^T\Sigma^{-1}\mu + \frac12\mu^T\Sigma^{-1}\mu = &&\text{Since $E[x] = \mu$}\\
= \frac12E[x^T\Sigma^{-1}x] - \frac12\mu^T\Sigma^{-1}\mu
\end{align} How can I simplify the term: $E[x^T\Sigma^{-1}x]$ ?","['multivariable-calculus', 'entropy', 'gaussian-integral']"
2029753,"Prove that $(C([0,1]),\lVert \cdot \rVert_\infty)$ is infinite dimensional","Let $C([0,1])$ equipped with $\lVert \cdot \rVert_\infty$ be set of all functions continuous on $[0,1]$. Prove that $C([0,1])$ is not finite dimensional. There is a theorem which states that a normed vector space is finite dimensional if and only if its closed unit ball $\{v\in V: \lVert v \rVert =1   \}$ is compact. In our case, $S=\{f\in C([0,1]): \lVert f \rVert_\infty =1   \}$. We know that a subset of a vector space is compact if and only if it is closed and bounded. Clearly, $S$ is bounded. So all is needed to be proved here is that $S$ cannot be closed to establish that $(C([0,1]),\lVert \cdot \rVert_\infty)$ is not finite dimensional. One of the approaches that I've tried is this: If $f_0$ is a limit point of $S$ then $\exists \{f_n\}\subset S$ such that $\{f_n\}$ converges to $f$. In this case, one would have to prove that somehow $\lVert f_0 \rVert_\infty \ne 1$. This can be done by providing a counterexample that $\exists f_n\subset S$ converging to $f_0$ where $\lVert f_0 \rVert_\infty \ne 1$. I came up with the sequence of functions $f_n=e^{-nx}$, which supposedly converges to the zero function. The only problem is: what if $x=0$? Then $f_n$ converges to $1$. I would appreciate some advice.","['real-analysis', 'sequences-and-series', 'functions', 'proof-verification']"
2029853,Is the weak topology sequential on some infinite-dimensional Banach space?,"Recall that a topological space is sequential,
iff every sequentially closed set is already closed. Is there an infinite-dimensional Banach space on which the weak topology is sequential? I already know that the weak topology is not first countable, but (AFAIK) this does not imply that the weak topology is sequential. On Hilbert spaces, the answer is negative: if $\{e_n\}_{n \in \mathbb{N}}$ is a ONS, then the set $\{\sqrt{n}\,e_n\mid n\in\mathbb{N}\}$ is sequentially weakly closed, but not weakly closed ($0$ belongs to the weak closure). Edit: On $\ell^1$, the weak topology is also not sequential. This can be seen by using the Schur property of $\ell^1$.","['functional-analysis', 'general-topology', 'banach-spaces', 'weak-convergence']"
2029863,Central limit theorem and convergence in probability from Durrett,"I saw following exercise from Durrett's probability theory book and I managed to solve the 1st part, but couldn't get the 2nd part. Let $X_1, X_2, \dots$ be i.i.d samples with mean $0$, and finite non-zero variance. Denote $S_n = X_1 + X_2+\dots + X_n$. Use central limit theorem and Kolmogorov $0-1$ law to show $\limsup S_n/\sqrt{n} = \infty$ a.s. Use contradiction to show $S_n/\sqrt{n}$ does not converge in probability. ( Hint : consider $n=m!$) For 1st part : (Please point out errors if you see any) W.L.O.G, we may assume $Var(X_1)=1$. Then by C.L.T, we have $S_n/\sqrt{n} \sim Z=N(0,1)$. Then the event $$\left\{\limsup S_n/\sqrt{n} = \infty\right\} =  \left\{\bigcap _{m=1}^{\infty} \bigcup_{n=m}^{\infty} S_n/\sqrt{n} = \infty\right\}$$ is in the tail $\sigma$-algebra formed by $X_1,X_2,\dots$. By $0-1$ law, we have $P(\limsup S_n/\sqrt{n} = \infty)$ is either $0$ or $1$. Now, the event $\{\limsup S_n/\sqrt{n} = \infty\}$ is equivalent to: for any $N$, we have $\{\limsup S_n/\sqrt{n} > N\}$. Then
\begin{align}
P\left(\limsup S_n/\sqrt{n} > N\right)&=\lim_{m\rightarrow \infty} P\left(\bigcup_{n=m}^\infty S_n/\sqrt{n} > N\right) \\[0.2cm]
& \ge \lim_{m\to \infty} P\left( S_m/\sqrt{m} > N\right) \\[0.3cm]
& = 1-\Phi(N) >0
\end{align} For 2nd part : Suppose it converges, then it must converge to normal $Z$. Then I am not sure how to proceed. I think it may somehow connect with part $1$. The hint also reminds me of Stirling's approximation, not sure. Thanks.","['weak-convergence', 'probability-theory', 'central-limit-theorem']"
2029886,Evaluate $\int_0^1 \frac{\log(1+x)}{x}$,"Evaluate the integral : $$\int_0^1 \frac{\log(1+x)}{x}dx$$
It is an improper integral & I tried it by substituting $\log(1+x)=z$ . But it does not open any way to evaluate it.","['real-analysis', 'improper-integrals', 'integration', 'definite-integrals', 'analysis']"
2029892,Approximations of functionals,The distance between a point and a set in a metric space or in a normed space is used in approximation of functionals (i read it in functional analysis book) can any body explain this please as i am unaware of approximation of functions,['functional-analysis']
2029905,How do I show that an entire function which is real for all $z\in \mathbb C$ with $Im(z)=0$ or $\pi$ is $2\pi i$ periodic?,"I have an entire function $f$ which takes real values on all complex numbers with imaginary parts $0$ or $\pi$. I'm trying to show that $f$ is periodic with period $2\pi$. I tried using the Cauchy-Riemann equations, but to no avail. How should I approach this problem?","['complex-analysis', 'entire-functions']"
2029911,Is the pythagoras theorem true for an infinite set of vectors?,"Let $H$ be a Hilbert space. Consider a collection of orthogonal vectors $\{x_n\}_{n=1}^{k}$. We know that $$\left\|\sum_{n=1}^{k}x_n\right\|^2=\sum_{n=1}^{k}\|x_n\|^2$$ Now consider an infinite collection of orthogonal vectors $\{y_n\}_{n=1}^{\infty}.$ Is it true that 
$$\left\|\sum_{n=1}^{\infty}y_n\right\|^2=\sum_{n=1}^{\infty}\|y_n\|^2$$","['functional-analysis', 'hilbert-spaces']"
2029914,Conditions for an entire doubly periodic function to be constant,"I was going through the proof of the fact that an entire doubly periodic function is constant (using Liouville's theorem). My question is, do I have to assume the periods are independent over $\mathbb R$? For example, if I have an entire function $f$ with $f(z+\lambda_1)=f(z+\lambda_2)=f(z)$ for all $z\in\mathbb C$ with the $\lambda_1,\lambda_2$ being independent over, say $\mathbb Q$, but not necessarily over $\mathbb R$, does it still follow that $f$ is constant? I felt the proof I'm reading uses somewhere the fact that the period parallelogram is generated by two complex numbers forming a $\mathbb R$ basis of $\mathbb C$. What happens if I take them to be only independent over $\mathbb Q$? They may no longer form a basis for $\mathbb C$ but it seems that even then if $f$ is entire with $f(z+\lambda_1)=f(z+\lambda_2)=f(z)$ for $\lambda_1,\lambda_2$ independent over $\mathbb Q$, it has to be constant. Why is that true?","['complex-analysis', 'entire-functions', 'elliptic-functions']"
2029922,Find $\lim \limits_{n \to \infty}\left( 1 + \sqrt{2} + \sqrt[3]{3} + \dots \sqrt[n]{n} \right) \ln{2n+1 \over n}$,"I am looking for $$\lim \limits_{n \to \infty}\left( 1 + \sqrt{2} + \sqrt[3]{3} + \dots \sqrt[n]{n} \right) \ln{2n+1 \over n}$$
We notice $\ln{2n+1 \over n} = \ln\left({1 + {n+1 \over n}}\right)$. We also know that ${x \over 1 + x} \le \ln(1+x)$. From this, we get $${n+1 \over 2n+1} \le \ln\left({1 + {n+1 \over n}}\right)$$ Then we notice $n \le 1 + \sqrt{2} + \sqrt[3]{3} + \dots \sqrt[n]{n}$, so
$$n{n+1 \over 2n+1} \le \left( 1 + \sqrt{2} + \sqrt[3]{3} + \dots \sqrt[n]{n} \right) \ln{2n+1 \over n}$$
$n{n+1 \over 2n+1} \to + \infty$, so
$$\lim \limits_{n \to \infty}\left( 1 + \sqrt{2} + \sqrt[3]{3} + \dots \sqrt[n]{n} \right) \ln{2n+1 \over n} = + \infty$$
Is this reasoning correct?","['real-analysis', 'limits']"
2029987,"Prove the bijections between the following $(p,q,r)$-shuffles","I am reading the book ""From Calculus to Cohomology: De Rham cohomology and characteristic classes"" Let $p, q, r$ be nonnegative integers. It says, (for those who own the book, on pg 10) without justification that there are bijections
$$S\left(p,q+r\right)\times S\left(\bar{p},q,r\right) \overset{\cong}{\longrightarrow} S\left(p,q,r\right),\ \left(\sigma,\tau\right)\mapsto \sigma \circ \tau$$
and
$$S\left(p+q,r\right)\times S\left(p,q,\bar{r}\right) \overset{\cong}{\longrightarrow} S\left(p,q,r\right),\ \left(\sigma,\tau\right)\mapsto \sigma \circ \tau .$$ Here, the following notations are being used: For any $n$, we let $S\left(n\right)$ denote the group of all permutations of $\left\{1,2,\ldots,n\right\}$. For any $n$ and $m$, we let $S\left(n,m\right)$ denote the set of all permutations $\sigma\in S\left(n+m\right)$ with
$$
\sigma\left(1\right) < \sigma\left(2\right) < \cdots < \sigma\left(n\right) \qquad \text{and}
$$
$$\sigma\left(n+1\right) < \sigma\left(n+2\right) < \cdots < \sigma\left(n+m\right) .
$$ We let $S\left(p,q,r\right)$ be the set of all permutations $\sigma \in S\left(p+q+r\right)$ with $$\sigma\left(1\right)<\sigma\left(2\right)<\cdots<\sigma\left(p\right) ,$$ $$\sigma\left(p+1\right)<\sigma\left(p+2\right)<\cdots<\sigma\left(p+q\right),$$ $$\sigma\left(p+q+1\right)<\sigma\left(p+q+2\right)<\cdots<\sigma\left(p+q+r\right) .$$ We let $S\left(\bar{p},q,r\right)$ be the set of all $\sigma \in S\left(p,q,r\right)$ such that $\sigma$ is the identity on $\left\{1,2,...,p\right\}$. We let $S\left(p,q,\bar{r}\right)$ be the set of all $\sigma \in S\left(p,q,r\right)$ such that $\sigma$ is the identity on $\left\{p+q+1,p+q+2,...,p+q+r\right\}$. I cant seem to get this, I am really stuck, I tried doing an example and breaking it down into transpositions but it shed no light on the situation. Would rather a hint than an answer, although any help is greatly appreciated.","['permutations', 'combinatorics', 'algebraic-combinatorics']"
2030006,Question on exponential decay,I'm looking to show that a continuous function that satisfies $f(x+L)=(1/2)f(x)$ for any $x \in \mathbb{R}$ and a constant $L \in \mathbb{R}$ has to be an exponential. I thought about turning it into an ODE but didn't see how. Any help is appreaciated.,"['algebra-precalculus', 'calculus', 'functions']"
2030017,Proof $\int_{-\infty}^\infty\frac{dx}{\left(e^x+e^{-x}+e^{ix\sqrt{3}}\right)^2}=\frac{1}{3}$,"I'm interested in possible generalizations of the integral
$$
\int_{-\infty}^\infty\frac{dx}{\left(\cosh x+\frac{1}{2}e^{ix\sqrt{3}}\right)^2}=\frac{4}{3},\tag{1}
$$
or equivalently
$$
\int_0^\infty\frac{dt}{(1+t+t^{\,\alpha})^2}=\frac23, \quad \alpha=\frac{1+i\sqrt3}{2}, \tag{1a}
$$
$$
\int_0^\infty\frac{e^{x\sqrt{3}}\cos\left(\frac\pi6-x\right)}{\left(2\cos x+e^{x\sqrt{3}}\right)^2}dx=\frac16.\tag{1b}
$$
Alternative ways to prove integral $(1)$ are also welcomed because they might show how to obtain generalizations. Integrals with similar looking integrands has been considered before, however no context was given explaining where did they arize and no closed form solution was given: integrate $\int \frac{1}{e^{x}+e^{ax}+e^{a^{2}x}} \, dx$ Integrating a Complex Exponential Function I know only one proof of $(1)$ which is as follows. By contour integration applied to the function $$\frac{1}{z\prod_{k=1}^\infty\left(1+\frac{z^3}{k^3}\right)}$$ one can show that 
$$
\sum_{n=1}^\infty\frac{(-1)^n}{n!}\left|\Gamma(1-\varepsilon n)\right|^2=-\frac13\tag{*}
$$
where $\varepsilon=e^{2\pi i/3}$.
Then using the integral 3.985.1 from Gradsteyn and Ryzhik $$ \int_0^\infty \frac{\cos{ax} \space dx}{ch^\gamma \beta x} = \frac{2^{\gamma - 2}}{\beta\Gamma(\gamma)} \Gamma\left( \frac{\gamma}{2} + \frac{ai}{2\beta} \right) \Gamma\left( \frac{\gamma}{2} - \frac{ai}{2\beta} \right) $$ one can write this series as an integral
$$
\sum_{n=1}^\infty\frac{(-1)^n}{n!}\left|\Gamma(1-\varepsilon n)\right|^2=-1+\frac{1}{2}\int_{-\infty}^\infty\frac{dx}{\left(\cosh x+\frac{1}{2}e^{ix\sqrt{3}}\right)^2}.\qquad \qquad \Box
$$ This approach also allows to prove that
$$
\int_\limits{-\infty}^{\infty}\frac{\text{sech}x~e^{\frac{i\sqrt{3}}{2}x}dx}{\sqrt{e^x+e^{-x}+e^{i\sqrt{3}x}}}=\frac{\pi}{3},\tag{2}
$$
$$
\int_\limits{-\infty}^{\infty}\frac{e^{i \sqrt{3} x} \cosh x}{\left(e^x+e^{-x}+e^{i \sqrt{3} x}\right)^2}dx=\frac{1}{12}.\tag{3}
$$
It is interesting that $(3)$ is obtained from the same series evaluation (*) as $(1)$. Note also the equivalent forms
$$
\int_0^\infty\frac{t^{\alpha-1}dt}{(1+t+t^{\,\alpha})^2}=\frac{1}{3\alpha}, \quad \alpha=\frac{1+i\sqrt3}{2}\tag{3a}
$$
$$
\int_0^\infty\frac{t^{\alpha}dt}{(1+t+t^{\,\alpha})^2}=\frac{\alpha}{3}\tag{3b}
$$ However, I couldn't apply this technique to find any other integrals of similar kind calculable in closed form that have simple form as $(1),(2),(3)$. It is not also clear whether there is a direct computation without summation of any series. Given the simplicity of the closed forms above this might be possible. Note that it one can write $(1)$ and $(2)$ in terms of real integrands completely avoiding complex numbers, but the current form is more compact. Q1: Are there any other ways to prove $(1),(2),(3)$? Q2: What are possible generalizations of these integrals?","['alternative-proof', 'closed-form', 'integration', 'definite-integrals', 'contour-integration']"
2030039,Kernel of permutation representation,"Let $G$ be a finite group that acts on a finite set $X$. Let $K$ be a field and consider the associated permutation representation $G\to GL_{|X|}(K)$. Does the dimension of the kernel of the corresponding algebra homorphism $KG\to Mat_{|X|}(K)$ depend on $K$? In other words is this number something that can be deduced soley from the action of $G$ on $X$? I know that it does not depend on $K$ when you consider the natural action of $S_n$ on $\{1,\dots,n\}$. This is not too difficult to see as the image is the set of matrices whose rows and columns all sum to the same constant. This always has dimension $1+(n-1)^2$ and so the kernel must have dimension $n!-(n-1)^2-1$. However, I've no idea how to tackle this problem in general.","['permutations', 'representation-theory', 'group-theory']"
2030040,Minimal number of generators of an ideal,"Suppose $Y$ is an affine variety in $\mathbb{A}^n$ of $\dim r$. Then height of the prime ideal $\mathcal{I}(Y)$ is $n-r$. We have a result: ""Let $A$ be a Noetherian ring, $x_1,\dots ,x_r\in A$. Then every minimal prime ideal $\mathfrak{p}$ belonging to $(x_1,\dots ,x_r)$ has height $\leq r$."" (Atiyah-Macdonald, Corollary $11.16$, page $121$). Now suppose $\mathcal{I}(Y)$ is generated by $m$ elements. Then, using the result, $n-r\leq m$. So $\mathcal{I}(Y)$ is minimally generated by $n-r$ elements. $\underline{\text{My question}}$: Is it always possible to find $n-r$ elements which will generate $\mathcal{I}(Y)$ or there are some examples for which it is not possible to find that minimal number of elements ? Also, in particular, if $Y$ is a linear variety then as @Georges pointed out we can always find $n-r$ elements which will generate the ideal $\mathcal{I}(Y)$. I need an explanation for this last part. Thank you.","['algebraic-geometry', 'commutative-algebra']"
2030069,"How to prove that $\sin(x)≤\frac{4}{\pi^2}x(\pi-x) $ for all $x\in[0,\pi]$?","How to prove the inequality
$$
\sin(x)≤\frac{4}{\pi^2}x(\pi-x)
$$
for all $x\in[0,\pi]$? As both functions are symmetric to $\frac{\pi}{2}$ it suffices to prove it for $x\in\left[0,\frac{\pi}{2}\right]$. Furthermore one can see that $\frac{4}{\pi^2}(\pi-x)$ is the tangent to $\frac{\sin(x)}{x}$ in the point $\left(\frac{\pi}{2},\frac{2}{\pi}\right)$ so it would be enough to prove that $\frac{d^2}{dx^2}\left[\frac{\sin(x)}{x}\right]≤0$ in $\left[0,\frac{\pi}{2}\right]$. Is this the right way or are there more elegant approaches?","['inequality', 'trigonometry', 'calculus']"
2030072,"If $\int_{R^2} f(x,y)dxdy$ exists, must $\int_R f(a,y)dy$ exist?","Let $f$ be a smooth real function on $R^2$ such that 
  $$\int_{R^2} f dxdy$$ exists. Let $a\in R$. Must $\int_R f(a,y) dy$ exist? I believe this is true, but I don't know how to prove it.",['multivariable-calculus']
2030091,How to prove $3a=2b+c$ if $u_{n}\big|v_{n}$,"The sequence $\{u_{n}\}$, $\{v_{n}\}$ is defined by $$u_{0} =u_{1} =1,u_{n}=2u_{n-1}-3u_{n-2}(n\geq2)$$   $$v_{0} =a, v_{1} =b , v_{2}=c,v_{n}=v_{n-1}-3v_{n-2}+27v_{n-3} (n\geq3)$$ .There exists the positive integer $N$ such that when $n> N$ ,have $u_{n}\big|v_{n}$ . Prove that  $$3a=2b+c$$ I have do following 
$$u_n=\dfrac{\left (1+i\sqrt{2}\right )^n+\left (1-i\sqrt{2}\right )^n}{2}$$ $$v_n=\alpha\cdot 3^n+\beta \cdot \left (-1-2i\sqrt{2} \right )^n+\gamma \cdot \left  (-1+2i\sqrt{2} \right )^n$$ I think basics method does not works here. Any ideas ?","['number-theory', 'sequences-and-series']"
2030128,"Drawing squares on the sides of a right triangle,joining the vertices and so on...","As shown at the figure: ABC is a right triangle.Firstly, we erect squares on its sides.Then we join the consequtive vertices of the squares and we get 3 more triangles.We continue and we erect 3 squares on the sides of these 3 triangles,we join the vertices and we get trapezoids and so on and so forth(next step we erect squares on the sides of the trapezoids)
I have managed to show that the sum of the areas of the three initial triangles is 3 times the area of the right triangle.Then the sum of the trapezoids is 5 times the area of the right triangle...So my question is: is there a pattern behind this procedure?Possibly if we go on we will always be getting multiples of the area of the right triangle.","['triangles', 'geometry']"
2030154,Every bounded sequence is Cauchy?,"I know that every Cauchy sequence is bounded, but is the reverse true?","['cauchy-sequences', 'sequences-and-series']"
2030202,$S \not= \varnothing \implies \varnothing \subset S$?,"If $S$ is a nonempty set, is the following statement correct: $\varnothing \subset S$? It's confusing me becuase $\varnothing$ does not contain any elements so I'm struggling with the logic behind this statement.",['elementary-set-theory']
2030264,Mapping matrix to its adjugate is continuous,"I need help in proving that the function $f(A) =\operatorname{adj} (A)$ is continuous. I'm not sure at all how to work with continuity and matrices..
Thanks.","['matrices', 'matrix-calculus', 'functions', 'determinant', 'continuity']"
2030320,$\mathbb{R}$ is complete $\rightarrow$ $\mathbb{C}$ is complete,"In a book I am reading about functional analysis and metric spaces. The author goes through a long proof to show that $\mathbb{C}$ is complete, but at the end of the proof the author states that a simpler proof is to use the completenss of $\mathbb{R}$ to prove the completeness of $\mathbb{C}$, I have tried to look for this proof but couldn't find any. Is there a way to proof this?","['functional-analysis', 'complex-analysis', 'metric-spaces']"
2030366,"Number of distinct sequences of length 10, containing at least 5 consecutive As or at least 5 consecutive Bs","Im stuck on this question, asking for the number of distinct sequences of length 10, which contain at least 5 consecutive As or 5 consecutive Bs (for example ABABBBBBBA should be counted, as should ABBBBAAAAA). I know there's 1024 possible strings, but I'm unsure how to do the calculation without explicitly writing code to sum all the posibilites. How do I go about approaching this question without writing down every possibility?","['combinatorics', 'discrete-mathematics']"
2030390,Hypercube in infinite dimension,"I would like the following problem . You’ve got a 10 x 10 x 10 cube made up of 1 x 1 x 1 smaller cubes. The outside of the larger cube is completely painted red. On how many of the smaller cubes is there any red paint? Normally the answer would be : $10^{3}-8^{3}$ If we generalize to dimension n, we would have : $10^{n}-8^{n}$ Now consider a that you have a ball inside the hypercube of n dimension. What is the probability that it would inside of the painted smaller cubes ? the answer would be $\frac{10^{n}-8^{n}}{10^{n}}$ If n tend to infinity, the probability is 1. How is that possible ? Can we go from a discrete probability on a finite cardinal to an infinite set like that ? is it mathematically accurate? How would you explain the result?","['probability-theory', 'probability', 'probability-distributions']"
2030406,"Distributing n elements randomnly in r bins, and counting how many bins end up wih 1 element","TL,DR I will distribute n elements (indistinguishable) in r bins at random (equal chance of each bin) and try to calculate the expected value of X1=""number of bins with exactly 1 element in it"" as a function of n (r is known). Getting the probability distribution for X1 is interesting but not vital. Context I'm trying to find the best strategy for a board game I play with my friends. In it, you can draw n cards (you decide how many beforehand) and pay an amount for each card you want to draw. There are r different types of card, all with equal chances of appearing. After this, getting only one card of a type is penalized, while getting a group of 2 or more of the same kind is rewarded. Obviously, drawing dozens of cards assures you will not get many ""singletons"", but the cost becomes prohibitive. Knowing how many singletons vs groups i can expect if i draw n cards can help me optimize my plays (yes, I'm THAT guy that can't stop optimizing irrelevant things). The model Each card type is a ""bin"", and each card drawn is an element. There are r bins. N elements are distributed in the bins. Each element has to go into one and only one bin (once you show the card, you know what type it is). Each bin has the same chances of being selected. There is no limit on how many elements a bin can hold. Elements are indistinguishable, because the only thing that matter is how many of each type you get, regardless of the order. What I want to do I'm trying to plot (expected number of bins with 1 element), (expected number of bins with 2 or more elements) vs (number of elements distributed), with a 10% and 90% percentile lines if possible. The graph tools i know all require a explicit formula (a function of n) for the plot lines and allow no code. I know how to make a simulation of the card draw, but I prefer to use it as a validation for the analytical formula.
I'm very familiar with excel/google sheets and the rest of my related analisys are on that format. I can learn another tool if necesary, but the distribution has to be expressed as a function of n and r. What I've tried Reading the wikipedia article about probablility distributions, i find that this one https://en.wikipedia.org/wiki/Multinomial_distribution describes exactly the experiment I'm doing, but the information it provides is not the one I look for. This is already beyond the statistics I've learned in college and I'm stuck. I also tried modelling the problem as a system of differential equations of n variables X0, X1...Xn where Xi=""number of bins with exactly i elements in it"". When distributing an element, the probability that it falls in a bin with i elements is proportional to Xi, and the effect is that Xi decreases in 1 and X(i+1) increases in 1. It looks similar to this: dX0/dn=-k·X0 dX1/dn= + k·X0 - k · X1 dX2/dn= + k·X1 - k · X2 ... dXn/dn= + k · X(n-1) What failed in my approaches About the multinomial, I have to provide the specific combinations of number of elements in each bin to get the chances of the combination, but I want to ""group"" all the combinations that have say, 3 bins with 1 element, and combine the chances of all those combinations. This becomes unwieldly when n increases. About the differenctial equations,  I'm turning a discrete variable (number of elements) into continuous. It has undesirable effects, for example distributing only 1 element, and finding that there are 0,000001 bins with 20 elements already. Also, I only know the values at n=0 (all the bins are empty, so X0=r, and 0 for the rest) so I struggle giving a value to k. My questions • Is any probability distribution that models my problem and provides the information I look for better than the multinomial? • If not, is it possible to combine explicitly all the combinations of / into ? • What other data point (apart from n=0) can be used to estimate k in the case of the differential equations. Observations • n is at least 1 but has no upper bound • The cost of drawing a card is constant so it doesn't matter • The amount of physical cards is the game is high enough that drawing a card without replacing it doesn't change the probabilities of getting each card type in any meaningful way, so chances of getting each type remain constant. • First post here!  I really wanted to make a structured question, but maybe I was too verbose, sorry about that. Will try to correct it in later post once I get the hang of this.","['combinatorics', 'statistics', 'probability-distributions', 'discrete-mathematics']"
2030499,Sufficient and complete statistic: hypergeometrical distribution,"How can one show that for a r.v. $X$ that is hypergeometrically distributed, i.e. $X\sim H_{N, A, n} (N, n \text{ fixed})$, $X$ is sufficient and complete for the part $\theta = \frac{A}{N}$. So the definition of sufficient is that the conditional distribution $X\mid T=t$ is independent of $\theta$. One can show that sufficency is equivalent to $$f_{\theta}(x) = g(T(x), \theta) h(x).$$ Do I have to use this criterion or is it possible to show it directly? How could I start here? I guess like that: \begin{align}
P(X=x) & = \frac{ \binom A x \binom{N-A}{n-x}}{\binom{N}{n}} =\frac{A! (N-A)! (N-n)!}{(A-x)!(N-A-n+x)!N!} \cdot \frac{n!}{x!(n-x)!} \\[10pt]
& = \frac{A! (N-A)! (N-n)!}{(A-x)! (N-A-n+x)!N!} \binom n x
\end{align} which is probably almost the factorization required? The definition of completness is that if $E_{\theta} h(T) = 0 \text{ } \forall \theta \in \Theta$, then $h(t)=0$ a.s. Do I have to find one specific function to prove this?","['probability-theory', 'probability', 'statistics', 'probability-distributions']"
2030547,Show $\lim_\limits{x\to\infty} x(1-\frac{\ln (x -1)}{\ln x})=0$,"The following expression came up in a proof I was reading, where it is said ""It is easily shown: $$\lim_{x\to\infty} x(1-\frac{\ln (x-1)}{\ln x})=0.""$$ Unfortunately I'm not having an easy time showing it. I guess it should come down to showing that the ratio $\frac{\ln (x-1)}{\ln x}$ converges to 1 superlinearly, which seems intuitive but I don't know how to prove it formally. Any tips? Edit: original question had an implicit typo - I had $\ln x - 1$ rather than the intended $\ln(x-1)$.","['calculus', 'limits']"
2030560,Does there exist a non-PIR in which every countably generated prime ideal is principal?,"Is there a commutative ring $R$ such that all the countably generated primes are principal, but $R$ is not a principal ideal ring? I know that if all the prime ideals are principal, then all the ideals are principal (see here ; this answer doesn't need $R$ to ba a domain at all). On the other hand, any commutative ring such that countably generated ideals are principal, is a PIR (see here ). Notice that since the ring $R$ of algebraic integers is a non-Noetherian Bezout domain, all the finitely-generated (prime) ideals are principal, but $R$ is not a PIR. I tried some examples of non-PIR rings without too many prime ideals. The extreme case is only one prime ideal, for instance Artin and local, but the unique prime ideal wasn't principal in the examples I found. As pointed out by Alex Youcis in the comment below, this can't work since any Artin ring is noetherian. I wanted to search for local zero-dimensional rings, but I didn't know how. Thank you for your help!","['abstract-algebra', 'maximal-and-prime-ideals', 'ideals', 'commutative-algebra']"
2030563,Prove that at least one of the expressions does not exceed $\sqrt[3]{3}$,"Let $m,n > 1$ be positive integers. Prove that at least one of the numbers $$\sqrt[n]{m} \ , \ \sqrt[m]{n}$$ does not exceed $\sqrt[3]{3}$. I thought about doing a proof by contradiction. That is, assume this is not the case and so both exceed $\sqrt[3]{3}$. Then, $\sqrt[n]{m} > \sqrt[3]{3}$ and $\sqrt[m]{n} > \sqrt[3]{3}$. How do we continue?",['number-theory']
2030615,Is there such a thing as implicit integration?,"A problem I'm working on asks me at a certain point to integrate the following: $$x=2\left(\sin\left(y\right)\right)^2.$$ I've never integrated anything in this form. I can't isolate for $y$ either. Is there some sort of implicit integration technique I should be aware of, to get the indefinite integral of this? Thanks to the below comments, I was able to isolate y and get $$\sin^{-1}\left(\sqrt{\left(\frac{x}{2}\right)}\right)=y$$ ....which still looks insanely messy to integrate. I imagine I can use a u-substitution or something similar to solve this?","['integration', 'calculus']"
2030618,A deck of cards is dealt out. What is the probability that the first ace occurs on the 14th card?,"A deck of cards is dealt out. What is the probability that the first ace occurs on the 14th card? Solution 1. $$ 4\cdot\frac{48\cdot...\cdot36}{52\cdot...\cdot39}= 4\cdot\frac{48!/35!}{52!/38!}=4\cdot\frac{48!\cdot38!}{52!\cdot35!}\approx0.03116 $$ Solution 2. $$\frac{\binom 41 \binom {48}{13} 13!}{\binom {52}{14}14!}\approx0.03116$$ In both solutions only 14 draws are considered. If one continues to draw cards, until all 52 cards have been drawn, would the probability that the first ace is drawn on the 14th turn be the same. If so, why?","['binomial-coefficients', 'probability', 'combinatorics', 'factorial', 'discrete-mathematics']"
2030625,sequence multiplication limit,Need help with the following question :,"['sequences-and-series', 'limits']"
2030643,Prove or disprove equality of two sums,"By playing with maxima I found that the sums 
$$\sum_{n=1}^\infty \frac{1}{2^n n^2}$$
and 
$$\sum_{n=1}^\infty (-1)^{n+1}\frac{H_n}{n}$$
are numerically equal, where $H_n=\sum\limits_{k=1}^n\frac1k$. I'm not sure if it's just a coincidence or we can prove the equality. Any clarification is welcome.","['real-analysis', 'sequences-and-series']"
2030671,Proving the Lie-Product formula,"Let $A,B\in gl(n)$. Then prove
$$e^{A+B} = \lim_{k\to\infty} \left (e^{\frac{A}{k}}e^{\frac{B}{k}}\right )^k$$ I found this theorem in this notes http://www4.ncsu.edu/~aalexan3/articles/liegroups.pdf but there is no proof. I am new to exponential of matrices and can't prove this by my own.","['matrices', 'matrix-exponential', 'functional-analysis', 'linear-algebra']"
2030730,Fixed and current axes of rotation,"I was astonished by ingenuity of many users who demonstrated  reasons for why rotational matrices are not commutative. However in 3d rotations I'm more puzzled by some other theorem ... How intuitively to show that composition of rotations about fixed axes of global frame is equal to composition of the same rotations about their current X,Y,Z axes but made in reverse order . In the previous question the most interesting to me was example with permutations... Maybe someone also knows such nice examples..","['matrices', 'rotations', 'linear-algebra']"
2030779,"What does ""vanish identically"" mean?","This is from Stein's Complex Analysis: Suppose that $f$ is holomorphic in a connected open set $\Omega$, has a zero at a point $z_0 \in \Omega$, and does not vanish identicallly in $\Omega$. Then, there exists a neighborhood $U\in\Omega$ of $z_0$, a non-vanishing holomorphic function $g$ on $U$, and a unique positive integer $n$ such that
  $$f(z) = (z - z_0)^n g(z) \text{ for all } z\in U$$ I thought that $f$ vanishes identically in $\Omega$ means that $f(z) = 0$ for all $z\in \Omega$? But then in the proof, he wrote Since $\Omega$ is connected and $f$ is not identically zero, we conclude that $f$ is not identically zero in a neighborhood of $z_0$. Why? Why cannot $f$ be identically zero in a neighborhood of $z_0$? It does not contradict the fact that $f$ is not identically zero in $\Omega$.",['complex-analysis']
2030794,"How to get the second point in a line segment knowing its first point, distance and perpendicular line segment?","I need to get the second point in a line segment knowing its first point, distance and perpendicular line segment. The line segments need to intersect , thus the direction of the incomplete line segment could differ based on the location of its first point. The problem I have now is that I don't know how to obtain the direction of the incomplete line segment. This is what is known: a1 = (30, 30) a2 = (10, 30) b1 = (30, 35) d = 30 (distance of line segment b) I tried the following: Get perpendicular slope a. m = (b2.x - b1.x) / (b2.y - b1.y); Get horizontal direction. hd = ?  // either 1 or -1 Get a2. a2.x = a1.x + d * cos(atan(m)) * hd;
a2.y = a1.y + d * sin(atan(m)); I am missing the step to get the horizontal direction of the slope of b , I was unable to recognize the pattern. Or perhaps there is a better and shorter algorithm to figure out point b2 ?","['algorithms', 'trigonometry', 'linear-algebra']"
2030821,"Injective, surjective or bijective?: $f: \mathbb{R}^{2} \rightarrow \mathbb{R}^{2}, (x,y) \mapsto (x+y,x+y^{2})$","Is the following mapping injective, surjectiv or bijective? Say why and if necessary, calculate the inverses. $f: \mathbb{R}^{2} \rightarrow \mathbb{R}^{2}, (x,y) \mapsto (x+y,x+y^{2})$ I have looked for some tasks I don't understand in old exams that have been written years ago and this is one I couldn't solve at all. Can you tell me an easy way of doing it? Anyway I give it a try, somehow..: Say we have $x=2$ and $y=2$ then insert it into $f:$ $$(2,2)=(2+2,2+2^{2})$$ $$(2,2)=(4,6)$$ Now let's take $x=1$ and $y=-7$: $$(1,-7) =(1-7,1+(-7)^{2})$$ $$(1,-7)=(-6,50)$$ Something is injective if for every $(x+y,x+y^{2})$ we get at most one $(x,y)$ value (?) Something is surjective if  for every $(x+y,x+y^{2})$ we get at least one $(x,y)$ value (?) So I would say this is only surjective.",['functions']
2030871,Tensor product and localisation of integers,"I have this doubt about tensor products. Let us fix $p$ a prime. Set $\mathbb{Z}[\frac{1}{p}]$ the localisation of $\mathbb Z$ in $p$ and $\mathbb{Z}_{(p)}$ the localisation at the prime ideal $(p)$. Now my question is the following: Is the canonical morphism of $\mathbb Z$-algebras:
  $$\mathbb{Z}[\frac{1}{p}] \otimes_{\mathbb Z} \mathbb{Z}_{(p)}\rightarrow \mathbb Q$$
  induced by the multiplication $\mathbb{Z}[\frac{1}{p}] \times\mathbb{Z}_{(p)}\rightarrow \mathbb Q,\ (x,y) \mapsto xy$,
  an isomorphism? My guess is yes for every rationnal $\frac{a}{b}$ can be factored in the form
$\prod_i p_i^{\alpha_i}$ with $\alpha_i\in\mathbb Z$, thus we can put every fraction $\frac{a}{b}$ under the form $\frac{m}{p^\alpha n}$ with $p \nmid n$ and $(m,n)=1$. I then construct the map:
$$\frac{m}{p^\alpha n} \mapsto \frac{1}{p^\alpha}\otimes \frac{m}{n}$$
to be its inverse. Is this a valid proof? Are ther any more elegant proofs?","['localization', 'abstract-algebra', 'proof-verification', 'tensor-products']"
2030996,Determining the inverse of the following function,"The function $f \colon \mathbb R - {2} \to \mathbb R \setminus \{5\}$ defined by $ f(x) =\frac{ (5x+1)} {x-2} $ is bijective. Determine its inverse function. I have no idea how to do this problem. The way I go about such problems is usually, find the inverse $(f^{-1} (x))$ and plugging it into $f(x) $ to show that it equals $x$,  therefore it is bijective. I am not really sure on how to find the inverse in this one because I cannot use partial fractions in this. Even a starting point would be helpful!","['function-and-relation-composition', 'elementary-set-theory']"
2031011,"Prove that $\sin(2A)+\sin(2B)+\sin(2C)=4\sin(A)\sin(B)\sin(C)$ when $A,B,C$ are angles of a triangle","Prove that $\sin(2A)+\sin(2B)+\sin(2C)=4\sin(A)\sin(B)\sin(C)$ when $A,B,C$ are angles of a triangle This question came up in a miscellaneous problem set I have been working on to refresh my memory on several topics I did earlier this year. I have tried changing $4\sin(A)\sin(B)\sin(C)$ to  $$4\sin(B+C)\sin(A+C)\sin(A+B)$$ by making substitutions by reorganizing $A+B+C=\pi$. I then did the same thing to the other side to get $$-2(\sin(B+C)\cos(B+C)+\sin(A+C)\cos(A+C)+\sin(A+B)\cos(A+B))$$ and then tried using the compound angle formula to see if i got an equality. However the whole thing became one huge mess and I didn't seem to get any closer to the solution. I am pretty sure there is some simpler way of proving the equality, but I can't seem to figure it out. Maybe there is a geometric interpretation or maybe it can be done using just algebra and trig. Any hint's would be appreciated (I would prefer an algebraic approach, but it would be nice to see some geometric proofs as well)",['trigonometry']
2031020,"If $(1), (log_yx), (log_zy), (-15log_xz)$ are in Arithmetic Progression...","If $(1), (log_yx), (log_zy), (-15log_xz)$ are in AP then... (A)$z^3=x$ (B)$x=y^{-1}$ (C)$z^{-3}=y$ (D)$x=y^{-1}=z^3$ (Multiple answers may be correct) I tried many approaches, one of them being: $1+log_zy=2log_yx$ $log_zz+log_zy=log_yx^2$ $log_z(yz)=log_yx^2$ But the fact that the bases are different is causing the main problem as I don't know how to proceed further. It would be great if anybody could give me a hint for solving such questions.","['arithmetic-progressions', 'sequences-and-series']"
2031032,Finding height and area of non-right triangle - Heron's Formula?,"I would like to calculate the area for a triangle such that $a^2+b^2-c^2=1$ (an almost Pythagorean triple). I know that the triangle is non-right, so I would like to use $\text{Area}=\frac{1}{2}ab\sin C$... but I do not know how to represent $\sin C$ since I don't have any actual values. I know about Heron's formula where $S=\frac{a+b+c}{2}$ and $\text{Area}=\sqrt{s(s-a)(s-b)(s-c)}$, but I feel like that gets too lengthy with our side lengths? Edit to add: For $Area = \frac{1}{4}\sqrt{4a^2b^2-1}$ as shown by  @zipirovich, can this area ever be an integer if $a,b,c$ are positive integers and $a,b >1$? Or, is this impossible?",['trigonometry']
2031056,Probability of having $n$ dice equal to or greater than $x$ when $m$ dice are rolled,"I am trying to figure out how to do the math for something like this. The scenario: $n = 4$ $x = 7$ (using d10s, where 0 = 10) $m = 8$ In words, if I roll 8d10 (eight 10-sided dice) what is the probability of having four dice greater than or equal to 7 (where 0 is the greateest [10]) I have seen a lot of sites which will do the calculation where $n = 1$, but I want to make $n$ a variable. I know the probability of a 'successful' role is 4/10. I know that I could write out all the possible combinations and count the ones that meet the criteria, but I'm sure this can be done with math. How would you calculate this?","['probability', 'dice']"
2031059,Prove that $a^n-b^n = (a-b)(a^{n-1} + a^{n-2}b + \cdots + b^{n-1})$.,"Exercise Prove that $a^n-b^n = (a-b)(a^{n-1} + a^{n-2}b + \cdots + b^{n-1})$. I've posted my solution below. In case someone has a more clever solution, feel free to post it! (TBH, I was surprised that there was no question on Math.SE regarding this equation!)","['algebra-precalculus', 'polynomials', 'alternative-proof']"
2031065,Evaluating the sum $\sum_{k=1}^{n}{\frac{\mu(k)}{\phi(k)}} $,"It is easy to show that $$ \sum_{d|n}{\frac{\mu(d)}{\phi(d)}} = \prod_{p|n}{\frac{p-2}{p-1}} $$ (1) using the techniques described in this post: Is there a ""nice"" formula for $\sum_{d|n}\mu(d)\phi(d)$? . However, I have come across the scenario where instead of summing across the divisors of $n$, the sum is across all whole numbers less than $n$ $$ \sum_{k=1}^{n}{\frac{\mu(k)}{\phi(k)}} $$ (2) The first thought I had approaching this was to consider the divisors of the primorial $n\#$ because of the integers $1,2...n$, only the divisors of a primorial have nonzero Mobius values. However, the sum is taken only up to $n$, leaving out a large number of divisors. These divisors have a much smaller effect on the sum due to their size, but it is not negligible. How should I go about evaluating this sum? (WolframAlpha doesn't have a nice simplification, just values)","['totient-function', 'number-theory', 'mobius-function', 'summation', 'prime-numbers']"
2031068,"Why continuous function can be considered as ""topological homomorphism""?","In Munkres's book on topology, the notion of homeomorphism is stated to be analogous to the notion of isomorphism in context of modern algebra. I was wondering what will be the analogous concept of homomorphism in context of topology. One of my professors said that it is the continuous functions but I don't understand (although he tried) the reason behind this assertion. For example in case of group homomorphism we see that a group homomorphism $\varphi:(G,\circ)\to (H,\bullet)$ is a map such that $\varphi(x\circ y)=\varphi(x)\bullet\varphi(y)$ for all $x,y\in G$. If we try to define the notion of, say, ""topological homomorphism"", in an analogous manner we could define it in the following, A topological homorphism $\tau:(X,\mathscr{T}_X)\to (Y,\mathscr{T}_Y)$ is a map such that it preserves the ""topological structures"". But since here I don't know the precise notion of topological structures, I can't relate the notion of topological homomorphism as stated above to the notion of continuous functions. To me it seems that the notion of injective open map could serve as a notion of ""topological homomorphism"". Because actually the problem (at least for me) is that while we are discussing groups we can say that the homomorphism is ""structure preserving"" in the sense that it is ""binary operation preserving"". But here in case of topological spaces what can play the role of ""binary operation""? If we say that the topological homomorphism should preserve the arbitrary union and finite intersection of open sets then the most natural way to think about it is probably the notion of an injective open map . Can anyone explain this to me?","['big-picture', 'general-topology']"
2031113,find the maximum $\frac{\frac{x^2_{1}}{x_{2}}+\frac{x^2_{2}}{x_{3}}+\cdots+\frac{x^2_{n-1}}{x_{n}}+\frac{x^2_{n}}{x_{1}}}{x_{1}+x_{2}+\cdots+x_{n}}$,"give the postive intger $n\ge 2$,and postive real numbers $a<b$ if the real numbers such $x_{1},x_{2},\cdots,x_{n}\in[a,b]$ find the maximum of the value
$$\dfrac{\frac{x^2_{1}}{x_{2}}+\frac{x^2_{2}}{x_{3}}+\cdots+\frac{x^2_{n-1}}{x_{n}}+\frac{x^2_{n}}{x_{1}}}{x_{1}+x_{2}+\cdots+x_{n}}$$ it seem the  polya-szego inequality http://journalofinequalitiesandapplications.springeropen.com/articles/10.1186/1029-242X-2013-591","['inequality', 'convexity-inequality', 'optimization', 'multivariable-calculus', 'convex-optimization']"
2031177,Goldbach Conjecture and the Busy Beaver function?,"Background: Math undergrad, but complete layman in computer science I recently asked this question on CS stackexchange. I hope I am interpreting the answers correctly: Suppose we make a program to check that every even number greater than $2$ is the sum of two primes and run. All we have to do is run it for a certain, finite ammount of time; if a counterexample is found in that time, the conjecture is false. If no counterexample is found in that time, then the program will never halt so therefore the conjecture is true. Therefore there is an upper bound for the first possible counterexample. My question is, how is this upper bound encoded mathematically in the Goldbach conjecture? Does this mean that any math problem can be answered by brute force in a finite ammount of time? I am still in shock; all my life I've been told that if you have a statement about infinitely many numbers, you will never be able to conclude that it is true by just plugging in more and more numbers; but apparently this is possible. To me it's unbelivable that the upper bound for the smallest counterexample depends on our ability to encode the problem in a program. EDIT: Reformulation suggested by user1952009 in the comments: ""What happens if someone had (for every nn) an upper bound for B(n)B(n). He can solve the halting problem and every number theory conjecture, so what ?""","['computer-science', 'turing-machines', 'goldbachs-conjecture', 'number-theory', 'elementary-number-theory']"
2031187,Can an analytic function on the open unit disk blow up near the boundary? [duplicate],"This question already has an answer here : There is not an holomorphic function on a bounded domain such that $\lim_{z \to w} f(z)= \infty$ for every $w \in Fr(\Omega)$ (1 answer) Closed 7 years ago . Can we have a map $f$, holomorphic on the open unit disk, such that $|f(z)|\rightarrow \infty$ as $|z|\rightarrow 1$? I think not, (at least I can't think of any such map), but I'd like to be able to prove this.",['complex-analysis']
2031211,Concrete Applications of Lattices to Algebra,"The importance of lattices to algebra (or any field of mathematics really) should be fairly obvious. Specifically, we always have a complete lattice of subobjects (and a lattice of strong subobjects etc.) and a complete lattice of congruences. However, even though I like to claim this all the time I don't actually good way to illustrate the usefulness of this theory. What are some concrete application of lattices to algebra? This could be anything ranging from an alternate (better) proof of a classical theorem, to help in computing the subgroups of a finite group (if this is ever a thing, I'm only speculating here) or anything else, that you can hopefully motivate for a ""classical"" algebraist.","['applications', 'abstract-algebra', 'examples-counterexamples', 'lattice-orders']"
2031223,Properties of the space of random variables for different types of convergence,"Suppose we have a probability space $(\Omega,\mathcal{A},\mathbb{P})$, a sequence of random variable $(X_n)_n$ and some extra random variable $X$ on $(\Omega,\mathcal{A},\mathbb{P})$. There are a lot of different types of convergence which are defined now, for example we have: Weak convergence ($X_n\overset{w}{\rightarrow} X$) Convergence in probability ($X_n\overset{p}{\rightarrow} X$) Almost sure convergence ($X_n\overset{a.s.}{\rightarrow} X$) Convergence in $L^p$ ($X_n\overset{L_p}{\rightarrow} X$) Sure convergence ($X_n\overset{s}{\rightarrow} X$) Convergence in mean ($X_n\overset{m}{\rightarrow} X$) and for all of these we can look at the space of random variables with this type of convergence $(\mathcal{R}(\Omega,\mathcal{A},\mathbb{P}),\overset{*}{\rightarrow})$ where we sometimes make restrictions like in $L_p$ convergence we only take variables with a finite $p$'th moment. These spaces have certain properties like completeness, compactness, metrizability,$\dots$ My question is if there is some comprehensive list of all of these spaces and which properties they do/do not have? I have seen some properties (like completeness of the $L^p$ space) but a list would be really nice in my opinion. For clarification : I am not looking for properties like ""If $X_n$ converges a.s. to $X$ and $Y_n$ converges a.s. to $Y$ then $X_nY_n$ converges a.s. to $XY$, I'm looking for the classical topological/metric properties of the spaces of random variables.","['weak-convergence', 'probability-theory', 'convergence-divergence', 'random-variables']"
2031235,"Proof: If a function is in the Schwartz Space, then this function is uniformly continuous","I don't have this really clear, I want to justify if $f\in\mathcal{S}(\mathbb{R})$ then $f$ is uniformly continuous. So far, I know how can I bound $|x|$ for $f$ is in the Schwartz space, but I can't proceed with the uniformly continuous proof because I don't know how to bound $|y-x|$ to find a $\delta$ which depends on an $\varepsilon>0$ such as $|f(y)-f(x)|<\varepsilon$. Thank you so much","['schwartz-space', 'fourier-analysis', 'continuity', 'uniform-continuity', 'analysis']"
2031236,What fraction of the fund should one bet?,"Say we have a gambler who makes money through sports betting. My aim is to develop a model to help our gambler maximise his winnings and minimize losses. In my model, rather than betting a fixed amount of money, the gambler bets a certain fraction $0 < r < 1$ of his current betting fund. He continues betting that fraction as his betting fund increases or decreases until he cashes out after a certain number of sessions $n$. The gambler's initial fund shall be $F_0$. His fund after $i$ sessions shall be $F_i$. His probability of making a correct prediction shall be $0 < p < 1$. If our gambler had a $p$ of $0$ or $1$, then the entire model would be useless. The average odds with which our gambler deals with is $a > 1$. The gambler's minimum desired profit upon cash out is $T$. $$T \le F_n - F_0 \tag{1}$$ If we expressed everything as a multiple of $F_0$, $(1)$ can be rewritten as: $$T \le F_n - 1 \tag{1.1}$$ It follows that the following are known: $T$, $a$, $F_0$, $p$. Should our gambler lose a particular session say $i+1$, $$F_{i+1} = (1-r)F_i \tag{2.1}$$ Should he win that particular session $$F_{i+1} = F_i(1-r + ra) \tag{2.2}$$ Given that the gambler plays $n$ sessioms before cashing out. His expected number of wins = $p*n$        $(3.1)$ His expected number of losses = $(1-p)*n$         $(3.2)$ Now there are many different ways to distribute the gambler's losses and wins{$n \Bbb P pn$} and while calculating all scenarios and finding average $F_n$ may be ideal, it is computationally very expensive. So I decided to  model the problem assuming the losses take place in the worst way possible( back to back at the very beginning of the match). The gambler's revenue after $n$ matches is given by the formula: $F_n = (1-r)^{(1-p)n}\{(1-r)+ra\}^{pn}$             $(4)$ Now we know that our gambler wants to make a minimum profit of $T$ so we transform $(4)$ into an inequality using $(1.1)$ We get: $(1-r)^{(1-p)n}\{(1-r)+ra\}^{pn}$ $ \ge T + 1$         $(4.1)$ Taking the Natural logarithm of both sides, I get: $ln(1-r)*(1-p)(n) + ln(1-r + ra)*pn \ge ln(T+1)$           $(4.2)$ $n\{ln(1-r)(1-p) + ln(r(a-1)+1)(p) \} \ge ln(T+1)$    $(4.3)$ Giving the constraints on the variables and constants, I want to determine the minimum value of $n$ and maximum value of $r$ that satisfies $(4.1) / (4.3)$ (whichever is easier to solve) for any given $T$, $a$, $p$. MAJOR EDIT Thanks to @Rodrigo de Azevedo, I discovered Kelly's Criterion. I was sold on it, and decided to implement it into my gambling method. For the purposes of my method Kelly's criterion is given by: $r_i = p - $ ${1 - p}\over{a_i - 1}$  $(5)$ Where: $r_i$ is the ratio at session $i$ $a_i$ is the odds at session $i$ Now $r: 0 \lt r \lt 1$  $(5.1)$ Applying $(5.1)$ to $(5)$ we get: ${p(a - 1) - (1 -p)}\over{a - 1}$ $ \gt \frac{0}{1}$ Cross multiply. $p(a-1) - (1 - p) \gt 0(a-1)$ $pa - p - 1 + p \gt 0$ $pa - 1 > 0$ $pa > 1$ $p > 1/a$  $(5.2)$ Now that that's out of the way, we still have the problem of determining minimum $n$ such that we make a profit $ \ge T$. In order to do this, we'll assume a ""mean"" value for $a$ then find the minimum value for $n$ that satisfies $(4.1)$ Due to the fact, that you do not know the odds for the matches in advance, your mean odds at $i$ say $a_{\mu i}$ may not be the mean odds at $n$ $a_{\mu n}$. In order to protect against this(and because I'm not a very big risk taker), I'll assume a value for $a_{\mu}$, that is less than $a_{\mu}$ called $a_{det}$. $a_{det} = a_{\mu} - k\sigma$ Where $a_{\mu}$ is the Geometric Mean as opposed to the arithmetic mean of the odds and $\sigma$ is associated S.D Using Chebyshev's Inequality, at least $k^{2} - 1 \over k^2$ of the distribution of the odds lie above $a_{det}$. Picking a $k$ of $2.5$ $2.5^{2}-1\over 2.5^{2}$ $0.84$ So our $a_{det}$ is lower than at least $84$% of the distribution of the odds. This is safe enough for me. $a_{det} = a_{\mu} - 2.5\sigma$ Using $a_{det}$, we'll calculate the minimum $n$ that satisfies $(4.1)$ Subbing $5$ and $a_{det}$ into $(4.1)$ we get: $\left(1-\left(p - \frac{1-p}{a_{det}-1}  \right) \right)^{n - np} \cdot \left(\left(p - \frac{1-p}{a_{det}-1}  \right)\cdot(a_{det} - 1)\right)^{np}$  $ \ge T + 1$   $(6.0)$ This can be simplified further to:
$\left({a_{det}-1-(pa_{det}-1)}\over{a_{det}-1}\right)^{n(1-p)}\cdot\left(pa_{det}-1+1\right)^{np}$ $\left({a_{det}-pa_{det}}\over{a_{det}-1}\right)^{n(1-p)}\cdot\left(pa_{det}\right)^{np}$ $\left(\left(\frac{a_{det}*(1-p)}{a_{det}-1}\right)^{n(1-p)}\cdot\left(pa_{det}\right)^{np}\right)$ $(6.1)$ P.S due to my particularly low $a_{det}$ we'll likely make much more profit than $T$, but that's loads better than choosing a higher $a_{det}$ and making less.","['operations-research', 'probability', 'mathematical-modeling', 'gambling']"
2031269,Can the sum of the first $n$ squares be a cube?,"In other words, if you have a pile of cannonballs in a square pyramid, can you rearrange them as a cube instead, or do you have to shell someone first? Or, instead, does $$n(n+1)(2n+1)=6x^3$$ have any nontrivial integer solutions? The analogous problem where you want to put the cannonballs in a square instead of a cube is know to have only one nontrivial solution: $$\sum_{n=1}^{24}n^2=70^2$$ It can be seen that $n,n+1,2n+1$ are pairwise coprime by using Euclid's algorithm. Consider the six cases of the rest $n \pmod 6$: $n=6y$ $y(6y+1)(12y+1)=x^3$ Since the product of 3 coprime integers is a cube each is a cube too. Let 
$y=a^3$, $6y+1=b^3$, $12y+1=c^3$. A solution is the equivalent to a solution to the system $$b^3-6a^3 = c^3 - 12 a^3 = 1$$ $n=6y+1$ Applying the same argument and substitution: $$2b^3-a^3=3c^3-2a^3=1$$ $n=6y+2$ $$c^3-4a^3=6b^3-c^3=1$$ $n=6y+3$ $$c^3-6a^3=4b^3-c^3=1$$ $n=6y+4$ $$b^3-2a^3=2b^3-3c^3=1$$ $n=6y+5$ $$c^3-2a^3=12b^3-c^3=1$$ So if it is proven that none of these systems of ""cubic Pell equations"" has a nontrivial solution, the theorem is proven. I have a suspicion a quick proof would require an algebraic number theory atom bomb.","['number-theory', 'diophantine-equations', 'algebraic-number-theory', 'elementary-number-theory']"
2031281,Deciphering delay in codes,"Can you please help me in understanding how to determine the delay while deciphering codes using appropriate examples ? I am trying to follow the definition given in the book Codes and Automata by Jean Berstel, Dominique Perrin and Christophe Reutenauer, but I don't seem to follow it. A subset $X$ of $A^{+}$ is said to have a finite deciphering delay if there exists an integer $d\geq0$ such that the following condition holds : For $x,x'\in X$ ,$y\in X^{d}$, $y'\in X^{*}$,  $xy$ is a prefix of $x'y'$ implies $x=x'$. A few examples that I came across in various books are as follows:
            The set {${ab,abb,baab}$} has a delay one. 
            The set $ba^*$ has delay one.
            The set {$aa,ba,b$} is a finite code with infinite delay.
The set {$a,a^{k}b$} has delay k. I am unable to relate the definition to the examples given. It will be of great help if someone can explain this to me. Thanks.","['automata', 'discrete-mathematics']"
2031334,Please verify my proof of: There is no integer $\geq2$ sum of squares of whose digits equal the integer itself.,"While going to sleep, I just started thinking about numbers, their squares, cubes and after thinking for about $20$ minutes I got that: There is no integer (having any numbers of digits) except $0$ and $1$, sum of squares of whose digits is equal to number itself. Isn't it interesting ?? Now I came out blanket and started writing everything on paper (Or started finding a proof of what I have got). MY WORK Suppose there exist an integer $a_0a_1a_2.......a_{n-1}$  having n digits. Firstly, we can easily exclude negative integers from the race as the number will be negative and sum of squares will be positive (we can never equate negative and positive). Now comes the turn of non negative integers. As we have assume that there exist an integer which satisfy our condition so, it should yield us: $$10^{n-1}a_0+10^{n-2}a_1+.........10a_{n-2}+a_{n-1}={a_0}^2+{a_1}^2+.......{a_{n-2}}^2+{a_{n-1}}^2$$
Which on further solving becomes,
$$a_0(10^{n-1}-a_0)+a_1(10^{n-2}-a_1)+.........+a_{n-2}(10-a_{n-2})+a_{n-1}(1-a_{n-1})=0$$
$$a_0(10^{n-1}-a_0)+a_1(10^{n-2}-a_1)+.........+a_{n-2}(10-a_{n-2})=a_{n-1}(a_{n-1}-1)$$ Now, the hardest part for me comes: The terms of left are all positive and they increase as we keep on going towards left. We can only compare the terms $$a_{n-1}(a_{n-1}-1)$$ and $$a_{n-2}(10-a_{n-2})$$ because the shortest of other terms is too far from comparison. Now if we make some comparison, we will have $$a_{n-1}(a_{n-1}-1)=a_{n-2}(10-a_{n-2})$$ Now let's form a table for the function on RHS: $$\begin{array}{c|c}
a_{n-2}&            a_{n-2}(10-a_{n-2})\\\hline
0&                         0\\
1&                         9\\
2&                         16\\
3&                         21\\
4&                         24\\                         
5&                         25\\
6&                         24\\
7&                         21\\
8&                         16\\
9&                         9
\end{array}$$ Again, we form a table and this time for the function on LHS: $$\begin{array}{c|c}
a_{n-1}&                       a_{n-1}(a_{n-1}-1)\\\hline
0&                                  0\\
1&                                  0\\
2&                                  2\\
3&                                  6\\
4&                                 12\\
5&                                 20\\
6&                                 30\\
7&                                 42\\
8&                                 56\\
9&                                 72
\end{array}$$
Now we have all possible values of  $a_{n-1}(a_{n-1}-1)$ and  $a_{n-2}(10-a_{n-2})$ and A quick look at tables yield that the only common value $a_{n-1}(a_{n-1}-1)$ and  $a_{n-2}(10-a_{n-2})$ have is $0$. So the condition is followed when ($a_{n-1}$ ,$a_{n-2}$ )=($0,0$) and ($1,0$). Or $1$ and $0$ are the only numbers which follow the condition.{ There is no integer (having any numbers of digits) except $0$ and $1$, sum of squares of whose digits is equal to number itself is proved }. I hope you guys will understand that such questions are hard to write (specially for someone like me who is a beginer at Mathjax). So, if you have any problem in understanding, leave comment. I shall be thankful if someone can verify my proof or can give a new one (with completely different approach). You can suggest modification in my work or give suggestion that where it can be improved.Thanks","['alternative-proof', 'proof-verification', 'number-theory', 'proof-writing', 'elementary-number-theory']"
2031365,Generalization of Law of Large Numbers and Central Limit Theorem using Polynomial Scaling,"Let $\{ X_i \}_{i=1}^n$ be sequence of i.i.d. mean zero ($\mathbb{E} X_i = 0$) random variables with bounded second moment ($\mathbb{E} X_i^2 < \infty$) . Now what would be the limiting behavior of $$S^a_n := \frac{\sum_{i=1}^n X_i}{n^a},$$ as $n \to \infty$ where $a \in [0,1]$ or even $\mathbb{R}$. When $a = 1$, we have the Strong Law of Large Numbers which say that $S^1_n$ almost surely converges to $0$. When $a = 1/2$, we have the Central Limit Theorem which say that $S^{1/2}_n$ converges to a normal distribution ($\mathcal{N} (0, \mathbb{E}X_i^2 )$) in distribution. But what happens for other choices of $a$ and how can one prove it converges or diverges in those scenarios? This is Terence Tao's comment on it (which I didn't fully understand) - https://terrytao.wordpress.com/2008/06/18/the-strong-law-of-large-numbers/ Assuming the random variables have bounded second moment, the limit will be almost surely zero for a > 1/2, converge (in a distributional sense) to a normal distribution for a=1/2, and diverge to infinity almost surely for a < 1/2, all thanks to the (strong) law of large numbers. For heavy-tailed random variables with infinite second moment, the situation is going to be more complicated, but can be worked out for any specific distribution by a variety of tools (e.g. Fourier analysis)""","['probability-limit-theorems', 'law-of-large-numbers', 'probability-theory', 'central-limit-theorem']"
2031368,Sigma additivity of events implies events being disjoint,"Let $(\Omega, \mathcal{A}, \mathbb{P})$ be a probability space and $(A_n)_n$ a sequence in $\mathcal{A}$. If $\mathbb{P}(\bigcup_n A_n) = \sum\limits_{n} \mathbb{P}(A_n)$, then $\mathbb{P}(A_i \cap A_j) = 0$ for all $i,j \in \mathbb{N}, i \not= j$. I have to prove that the $\sigma-$additivity of the probability measure implies that the events are pairwise disjoint. It is clear that I could construct a disjoint sequence $B_n := A_n \setminus \bigcup_{k = 1}^{n-1} A_k$ that would satisfy the condition but that doesn't really help with this excercise.","['probability-theory', 'probability', 'measure-theory']"
2031372,Other integrals for the tribonacci constant?,"The post, Is there an integral for the golden ratio? gives numerous beautiful integrals for $\phi$. Some were just specializations of trigonometric evaluations such as,
$$F(k)=\int_0^\infty \frac{x^{\pi/k-1}}{1+x^{2\pi}}dx =\frac{1}{2}\csc\Big(\frac{\pi}{2k}\Big)=\phi,\quad\text{at}\;k=5$$
However, integrals for phi's cousin the tribonacci constant $T$ seem to be harder to find. Phi appears in the pentagon, dodecahedron, etc, but $T$ also has a geometric context, the snub cube, $\hskip2.8in$ One integral I know for $T$ is,
$$\beta\times \Bigl(\frac{T+1}{T}\Bigr)^2=\int_0^1 \frac{1}{\sqrt{(1-t^2)(1-k^2t^2)}}dt = 1.570983\dots$$
where,
$$\beta=\frac{\Gamma\bigl(\tfrac{1}{11}\bigr)\, \Gamma\bigl(\tfrac{3}{11}\bigr)\, \Gamma\bigl(\tfrac{4}{11}\bigr)\, \Gamma\bigl(\tfrac{5}{11}\bigr)\, \Gamma\bigl(\tfrac{9}{11}\bigr)}{11^{1/4}(4\pi)^2}$$
$$k = \frac{1}{2}\sqrt{2-\sqrt{\frac{2T+15}{2T+1}}}$$
though it is a bit unsatisfying as $T$ appears in the integrand. Q: Are there other nice integrals for the tribonacci constant $T$?","['constants', 'definite-integrals', 'sequences-and-series', 'calculus']"
2031389,Extended Upper Half plane and Modular Curves,"Perhaps an introductory question, but, recently a came across the notion of Modular Curve and I read about its compactification. Now, every Modular Curve is by definition a quotient of the form $\mathbb{H}/ \Gamma$, for $\mathbb{H}$ the upper-half plane and $\Gamma$ a suitable (congruence) subgroup of $SL_{2}(\mathbb{Z}$). Since this becomes a Hausdorff space thourgh the quotient topology given by the natural projection $\pi: \mathbb{H} \rightarrow \mathbb{H} / \Gamma$, we can ask about its compactification. We can define that compactification to be the quotient of the topological space $\mathbb{H}^{*}= \mathbb{H} \cup \mathbb{P}^{1} (\mathbb{Q})$ called the extended upper half plane, by $\Gamma$, with the ""natural"" action of the latter on $\mathbb{P}^{1} (\mathbb{Q})$ (induced by the action on each coordinate of  points of $\mathbb{Q}^{2}$ via Möbius Transformation). Now, my question is, why do we choose $\mathbb{Q}$ and not another field instead, such as $\mathbb{R}$ for instance?","['riemann-surfaces', 'moduli-space', 'algebraic-geometry', 'number-theory', 'modular-forms']"
