question_id,title,body,tags
617374,Constructing equivalent matrices with rows and columns exchanged,"I am trying to construct all inequivalent $8\times 8$ matrices (or $n\times n$ if you wish) with elements 0 or 1. The operation that gives equivalent matrices is the simultaneous exchange of the i and j row AND the i and j column. eg. for $1\leftrightarrow2$
\begin{equation}
\left( \begin{array}{ccc}
0 & 0 & 0 \\
0 & 1 & 1 \\
1 & 0 & 0 \end{array} \right) \sim
\left( \begin{array}{ccc}
1 & 0 & 1 \\
0 & 0 & 0 \\
0 & 1 & 0 \end{array} \right)
\end{equation} Eventually, I will also need to count how many equivalent matrices there are within each class but I think Polya's counting theorem can do that. For now I just need an algoritmic way of constructing one matrix in each inequivalence class. Any ideas?","['discrete-mathematics', 'algorithms']"
617384,Two series involving the Gamma function,"The last piece I am left with in my proof is to compute the following two series: $$\sum_{i=1}^{n-1}\dfrac{\Gamma(i-d)\Gamma(n-i+d)}{\Gamma(i+1)\Gamma(n-i)(n-i-d)}, \sum_{i=1}^{n-1} \dfrac{\Gamma(n-d-i)\Gamma(i+d)}{(i-d)\Gamma(i+1)\Gamma(n-i)},$$ here $n\geq 2$, $d\in(-0.5, 0.5)$. According to Maple that would be $$
\begin{align}
& \sum_{i=1}^{n-1}\dfrac{\Gamma(i-d)\Gamma(n-i+d)}{\Gamma(i+1)\Gamma(n-i)(n-i-d)}= \\ 
&=\dfrac{\Gamma(-d)}{2}\left[\dfrac{d\Gamma(-d)\Gamma(d)\Gamma(n-2d)\Gamma(n)-2\Gamma(n+d)\Gamma(n-d)\Gamma(-2d)}{(n-d)\Gamma(n)\Gamma(n-d)\Gamma(-2d)}\right] \\
&= \dfrac{d\Gamma(-d)^2\Gamma(d)\Gamma(n-2d)}{2\Gamma(n-d+1)\Gamma(-2d)}-\dfrac{\Gamma(-d)\Gamma(n+d)}{(n-d)\Gamma(n)}
\end{align}
$$
and
$$
\begin{align}
&\sum_{i=1}^{n-1} \dfrac{\Gamma(n-d-i)\Gamma(i+d)}{(i-d)\Gamma(i+1)\Gamma(n-i)}= \\ &=\dfrac{\Gamma(d)}{2}\dfrac{d\Gamma(-d)^2\Gamma(n-2d)\Gamma(n)+2\Gamma(n-d)^2\Gamma(-2d)}{d\Gamma(-2d)\Gamma(n-d)\Gamma(n)} \\
&= \dfrac{\Gamma(d)\Gamma(-d)^2\Gamma(n-2d)}{2\Gamma(-2d)\Gamma(n-d)} + \dfrac{\Gamma(n-d)\Gamma(d)}{d\Gamma(n)}.
\end{align}
$$ I have already simplified these series as much as possible and could not find any more elementary properties of the $\Gamma$ function that would make these expressions more convenient. Therefore, I thought I should use one of the definitions of the $\Gamma$ function. Also I believe it should be something that involves integrals or sums (rather than products) in order to change the order of summation and apply $\sum_{i=1}^{n-1}$ first. However, writing the first series as 
$$
\sum_{i=1}^{n-1}\dfrac{\int_0^\infty e^{-u}u^{i-d-1}du\int_0^\infty e^{-v}v^{n-i+d-1}dv}{(n-i-d)\int_0^\infty e^{-z}z^idz\int_0^\infty e^{-w}w^{n-i-1}dw\int_0^\infty e^{-r}r^{n-i-d-1}dr} = 
$$
$$
\sum_{i=1}^{n-1}\dfrac{\int^\infty_0 \int^\infty_0 e^{-u-v}u^{i-d-1}v^{n-i+d-1}dudv}{(n-i-d) \int^\infty_0 \int^\infty_0 \int^\infty_0 e^{-z-w-r}z^{i}w^{n-i-1}r^{n-i-d-1}dzdwdr}
$$ does not help at all because of denominator. I also tried to rewrite it (both the series and the desired result) using the Beta function:
$$
\begin{align}
\sum_{i=1}^{n-1}\dfrac{\Gamma(i-d)\Gamma(n-i+d)}{\Gamma(i+1)\Gamma(n-i)(n-i-d)} &= \sum_{i=1}^{n-1}\dfrac{B(d+1,i-d)B(n-i+d,1-d)B(n-i-d,1) (i-n)}{\Gamma(1+d)\Gamma(-d)d}\\ 
&= \dfrac{B(-d,-d)B(n-2d,d)B(n-i-d,1)  + 2B(-d,n+d)}{2(n-d)}
\end{align}
$$
and to use a couple of definitions:
$$
    B(x,y) = 2\int_0^{\pi/2}(\sin\theta)^{2x-1}(\cos\theta)^{2y-1}\,d\theta, \qquad \mathrm{Re}(x)>0,\ \mathrm{Re}(y)>0,
$$
$$
    B(x,y) = \int_0^\infty\dfrac{t^{x-1}}{(1+t)^{x+y}}\,dt, \qquad \mathrm{Re}(x)>0,\ \mathrm{Re}(y)>0.
$$
However, even though they allowed me to use geometric progression, resulting expressions were too cumbersome (or should I try harder?). Even if this is a correct way, I cannot see how to go from a triple integral (geometric progression, cumbersome expression) to a triple + single integral, i.e. 
$$
\dfrac{B(-d,-d)B(n-2d,d)B(n-i-d,1)  + 2B(-d,n+d)}{2(n-d)}
$$
(here I ignore requirements $\mathrm{Re}(x)>0$, $\mathrm{Re}(y)>0$, which can be easily satisfied). In case all this is not terribly difficult I would like only a hint first. This does not really help, but since there seems to be some particular way to evaluate this kind of series I tried to take some simpler one first and just got annoyed by such an elegant answer (the one I got from Maple, of course): $$\sum_{i=1}^{n-1}\dfrac{\Gamma(i-d)\Gamma(n-i+d)i}{\Gamma(i+1)\Gamma(n-i)}=\Gamma(1-d)\Gamma(1+d)(n-1)=\dfrac{d(1-n)\pi}{\sin(\pi(1+d))}$$ (comparing with the very first series above $\frac{1}{n-d-i}$ here is just replaced with $i$). Edit:
the desired results also can be rewritten to $$
\begin{align}
& \sum_{i=1}^{n-1}\dfrac{\Gamma(i-d)\Gamma(n-i+d)}{\Gamma(i+1)\Gamma(n-i)(n-i-d)} \\ 
&= \dfrac{\Gamma(-d)\Gamma(n+d)}{(n-d)\Gamma(n)} \left(\dfrac{d\Gamma(2d)\Gamma(n)\Gamma(d-n+1)}{\Gamma(n+d)\Gamma(2d-n+1)} - 1\right), \\
&\sum_{i=1}^{n-1} \dfrac{\Gamma(n-d-i)\Gamma(i+d)}{(i-d)\Gamma(i+1)\Gamma(n-i)} \\ 
&=-\dfrac{\Gamma(d)\Gamma(n-d)}{d\Gamma(n)} \left(\ \dfrac{\Gamma(n)\Gamma(n-2d)\Gamma(1-d)^2}{\Gamma(1-2d)\Gamma(n-d)^2} -1\right).
\end{align}
$$","['special-functions', 'gamma-function', 'summation', 'sequences-and-series']"
617398,Coefficients of a polynomial also are the roots of the polynomial?,"How many real solutions $(r_1, r_2, \cdots, r_n)$ are there such that $(r_1, r_2, \cdots, r_n)$ are the roots of the polynomials $x^{n} + r_1 x^{n-1} + r_2 x^{n-2} + \cdots + r_n$ For $n = 2, 3, 4$ I found $2, 4, 5$ real solutions, and $2, 6$, and according to WA and assuming a double root, $24$ complex solutions. Is it possible to generalize this for real/complex solutions? In particular, a proof (or dispute of the fact) that the number of complex solutions follows the factorials, and if possible also find a pattern for the number of real solutions. I would prefer not an answer that is just a computation to show a pattern up to some $n$. Edited because of bounty.","['algebra-precalculus', 'roots', 'polynomials']"
617407,Evaluate the limit $\lim\limits_{n \to \infty} \frac{1}{1+n^2} +\frac{2}{2+n^2}+ \ldots +\frac{n}{n+n^2}$,Evaluate the limit $$\lim_{n \to \infty} \dfrac{1}{1+n^2} +\dfrac{2}{2+n^2}+ \ldots+\dfrac{n}{n+n^2}$$ My approach : If I divide numerator and denominator by $n^2$ I get : $$\lim_{ n \to \infty} \dfrac{\frac{1}{n^2}}{\frac{1}{n^2} +1} +\dfrac{\frac{2}{n^2}}{\frac{2}{n^2} +1} + \ldots+ \dfrac{\frac{1}{n}}{\frac{1}{n} + 1}=0$$ but the answer is $\dfrac{1}{2}$ please suggest how to solve this.. thanks.,"['summation', 'calculus', 'limits']"
617418,Show that $p$ is prime if the following limit property holds,Let $n$ be a positive integer. Show that $n$ is prime if and only if $$\lim_{r\to \infty}\lim_{s\to\infty} \lim_{t\to\infty} \sum_{k=0}^s\left(1-\left(\cos\left(\frac{(k!)^r\pi}{n}\right)\right)^2t\right)=n$$,"['elementary-number-theory', 'limits']"
617421,"Trouble solving $\int\sqrt{1-x^2} \, dx$","I am trying to learn how to solve integrals and I've got the hang out of a lot of examples, but I haven't got the slightest idea how to solve this example, this is how far I've got: $$
\int\sqrt{1 - x^2} \, dx = x\sqrt{1-x^2} - 2\int\frac{x^2}{\sqrt{1-x^2}} \, dx
$$ Can you please help me solve it, and also some tips concerning the integration are welcome. Thank you","['calculus', 'integration', 'indefinite-integrals']"
617428,Prove $1^{2007}+2^{2007}+\cdots+n^{2007}$ is not divisible by $n+2$,"Prove that for any odd natural number $n$, the number $1^{2007}+2^{2007}+\cdots+n^{2007}$ is not divisible by $n+2$.","['elementary-number-theory', 'discrete-mathematics']"
617448,Generating function for lattice points in a sphere,"This is a note in Sedgewick's Analytic Combinatorics : The number of lattice points with integer coordinates that belong to the closed ball of radius n in d-dimensional Euclidean space is $\displaystyle[z^{n^2}]\frac{1}{1-z}\Theta(z)^d$ where $\displaystyle\Theta(z) = 1 + 2\sum_{k=1}^{\infty} z^{k^2}$. I've tried to figure out why this is true to no avail - perhaps $\Theta$ counts the number of ways to place points on a 1-dimensional ball of radius $k^2$, and raising it to the $d$ counts the cross product of all possibilities? I still don't know where the $\frac{1}{1-z}$ comes into play. Hints or explanations would be very much appreciated!","['geometry-of-numbers', 'generating-functions', 'combinatorial-geometry', 'combinatorics']"
617455,The sum of Gaussian functions,"Suppose there is a normal distribution and the Gaussian function is $F(x)=\exp(-c\|x-b\|^2)$ where $c$ is a constant and $x,b\in \mathbb{R}^N$, b means the mean value. $F(x)=\exp(-c\|x-b\|^2)=F(x)=\exp(-c(x^Tx-2x^Tb+b^Tb))=\exp(-c(x^Tx))\times\exp(2cx^Tb)\times\exp(-c(b^Tb))$ 1) $F(x_1)+F(x_2)+F(x_3)=\exp(-c(b^Tb)) \times(  \exp(-c(x_1^Tx_1))\times\exp(2cx_1^Tb)+\exp(-c(x_2^Tx_2))\times\exp(2cx_2^Tb)+\exp(-c(x_3^Tx_3))\times\exp(2cx_3^Tb)   )$ Is there any way I can write as $F(x_1)+F(x_2)+F(x_3)=G(b)\times H(x_1,x_2,x_3)$. 2) How about $\sum\limits_{x\in \Omega}F(x)$?",['statistics']
617459,A generalization of Cayley-Bacharach Theorem,"This is exercise 19.4.B on Ravi Vakil's notes. Let $C$ be a regular plane curve of degree $e>2$, and $D_1,D_2$ be two plane curves of same degree $d$ not containing $C$. By Bezout's theorem $D_i$ and $C$ meet at $de$ points. Suppose both $D_i$ meet $C$ at the same $de-1$ points. Show that the remaining point is the same as well. In other words, let $E$ be a divisor on $C$ of degree $de-1$ such that $D_i\cap C=E+p_i$ for some closed points $p_1,p_2$ of degree 1. Show $p_1=p_2$. I think I'm supposed to use 19.4.2 which says if $C$ is not isomorphic to $\mathbb{P}^1$, then $\mathscr{O}_C(p_1)\cong\mathscr{O}_C(p_2)$ iff $p_1=p_2$. We know $C$ is not $\mathbb{P}^1$ in this case since $e>2$. It would be great to show $\mathscr{O}_C(E+p_1)\cong\mathscr{O}_C(E+p_2)$ but I don't know how?",['algebraic-geometry']
617461,Preservation of separatedness of a scheme of finite type over a field by shrinking the base field,"This is a generalization of this question .
Let $k$ be a field.
Let $k'$ be an extension field of $k$.
Let $X$ be a $k$-scheme of finite type.
Suppose $X\times_k k'$ is separated over $k'$.
Is $X$ separated over $k$?
If yes, how do you prove it?",['algebraic-geometry']
617464,Trigonometry equation $\sin(x)+\cos(x)-\tan(x)=0.4$,There's some way to find $x$ here ? $$\sin(x)+\cos(x)-\tan(x)=0.4$$,['trigonometry']
617497,Finding all homomorphisms between two groups - couple of questions,"Consider $\mathbb{Z}_{15}$, and $\mathbb{Z}_{18}$. Let's say I want to find all homomorphisms $f:\mathbb{Z}_{15}\rightarrow \mathbb{Z}_{18}$. I'm not interested in the answer in particular, mostly I'm concerned about understanding the properties of homomorphism, so I can answer these kind of questions myself. So, first of all, I know that homomorphism of cyclic group is completely determined by it's generator. But, will any mapping do? For example, the easiest one to find is $f(1)=0$, where $Imf=\left\{0\right\}$, and $Ker=G$ 
(correct me if I'm wrong, this kind of $f$ can be defined between any two groups). Now, what things do I need to consider, when trying to find another one (if it exist)? Can I decide that $f(1)=1$? (It is not onto, but that shouldn't bother me) And what about $f(1)=2$? and so on... My second question is: what about non-cyclic groups? Consider $D_{10}$ and $\mathbb{Z}_{18}$, for example. Do I need to go and define $f$ for each and every $g\in D_{10}$? (it doesn't have a generator) A link to a useful (and simple) summary regarding homomorphisms properties will also be great. Thank you in advance.","['finite-groups', 'abstract-algebra']"
617500,Direct proof that nilpotent matrix has zero trace,"Does anyone know a proof from the first principles that a nilpotent matrix has zero trace. No eigenvalues, no characteristic polynomials, just definition and basic facts about bases and matrices.","['trace', 'matrices', 'nilpotence', 'linear-algebra']"
617505,"If $f'$ is differentiable at $a$ then $f'$ is continuous at $(a-\delta,a+\delta)$","Is there a counterexample? Proposition: Let $f:\mathbb{R} \longrightarrow \mathbb{R}$ be a differentiable function  such that $f':\mathbb{R} \longrightarrow \mathbb{R}$ is differentiable at $a\in\mathbb{R}$ (possibly differentiable at a single point). Then $f':\mathbb{R} \longrightarrow \mathbb{R}$ is continuous at an interval $(a-\delta,a+\delta)$ for some $\delta>0$. Any hints would be appreciated.",['real-analysis']
617521,How close is the analogy between regular systems of parameters and smooth coordinate charts?,"Let $X$ be a smooth variety with dimension $ n$ and $ p \in X $ a closed point. By definition, $ \mathscr{O}_p$ is a regular local ring, so we can choose a regular system of parameters $ u_1, \dots, u_n$ to generate the maximal ideal in $ \mathscr{O}_p$. There is a very strong analogy between smooth coordinate charts and a regular system of parameters: The stalk $ \Omega_{\mathscr{O}_p / k} $ of the cotangent bundle is a free $ \mathscr{O}_p$-module with basis $ du_1, \dots, du_n$. The completion $ \widehat{\mathscr{O}_p}$ is the power series ring $ k[[u_1, \dots, u_n]]$. If $ Y \subseteq X $ is a smooth sub-variety with codimension $ d $ passing through $ p $, then there is a regular system of parameters $ t_1, \dots, t_n $ such that in some Zariski open neighborhood around $ p $ we have $Y = V(t_1, \dots, t_d)$. This is an algebraic analogue of the rank theorem from differential geometry Question: Does this analogy go ""all the way"" in the Zariski topology? More precisely, is there some Zariski open neighborhood $ p \in U \subseteq X $ on which the morphism $ U \to k[X_1, \dots, X_n]$ defined by $ p \mapsto (u_1(p), \dots, u_n(p))$ is an open immersion? The second bullet point above says that the analogy goes ""all the way"" in the analytic topology. EDIT: OK, for an elliptic curve the morphism $ U \to k[X_1, \dots, X_n]$ cannot be an open immersion. Can anything be said about this morphism?",['algebraic-geometry']
617529,Richardson's theorem for constants,"It's known that there is no algorithm for deciding for any elementary function is it identically zero or not ( http://en.wikipedia.org/wiki/Richardson%27s_theorem ). But if I consider only constants - is there some algorithm for deciding for any constant expression composed from elementary functions (e. g. $\ln (\sin 1 - \tan (\pi^2))$), is it equal to zero or not?","['algebra-precalculus', 'algorithms']"
617532,Infinite product expression [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 10 years ago . Improve this question Define $f(z)=\cos z$ I want to write infinite product expression for $f(z)$ Please show how to write it explicitly. I need to get the result $$\cos z=\prod _{k=0}^{\infty} \left(1-\frac{4z^2}{\pi^2(2k+1)^2}\right)$$",['complex-analysis']
617557,Relation of Hodge Theorem to Eigenfunction Basis of Laplacian,"The classical Hodge theorem I know of relates the de Rham cohomology groups isomorphically to the space of harmonic forms and shows that $Id=\pi+\Delta G$ , where $\pi$ is the harmonic projection of $k$ -forms and $G$ is the Green's Operator for the Laplacian $\Delta=d\delta +\delta d$ . ( http://en.wikipedia.org/wiki/Hodge_theory ) It isn't clear to me how this relates to the following ""Hodge theorem"" from The Laplacian on a Riemannian Manifold by Steven Rosenberg : Let $(M,g)$ be a compact, connected oriented Riemannian manifold. Then there exist an orthonormal basis of eigenfunctions (eigenforms) for $L^2(M,g)$ (or $L^2\Lambda^k(M,g)$ ) of the Laplacian. $0$ is an eigenvalue with multiplicity 1, and all other eigenvalues are strictly positive, accumulate at infinity, and have finite multiplicities. In particular, I don't see the connection to the orthonormal basis of eigenfunctions part: how does this follow from the classical version?","['spectral-theory', 'functional-analysis', 'differential-geometry', 'hodge-theory']"
617572,does $a^2-51b^2=\mp 6$ have a solution for integers?,"does $a^2-51b^2=\mp 6$ have a solution for integers? I have tried for many modulos, but could not get much out of them.","['elementary-number-theory', 'combinatorics']"
617576,Counting Valid Strings in Will Shortz 3D-Word Hunt,"So I was reading the NY Times Magazine (only the puzzle section of course) and I came across a puzzle I had never seen before. Titled the ""3D-Word Hunt"", the goal is to find as many five letter words as possible in a $2 \times 3 \times 3$ array of letters. You are allowed to repeat letters, but you cannot stall and repeat. Below is an example puzzle. $\hskip2in$ To clarify the rules, an acceptable word would be ""DETER"" and an $un$ acceptable word would be ""ADDER"". In the aforementioned puzzle in the NY Times I found 32 English words. But then I thought of another (arguably harder) question: How many acceptable five letter strings are there? (So, disregard the requirement that the string be an actual English word) I have always struggled with tricky counting problems, so I come to you looking for an elegant solution. I feel like there should be some dynamic program to solve this question (first find all five letter words that do not travel more than $n$ -steps from the first letter with $n \in \{1, 2, 3, 4, 5\}$ ), but my results have been inconclusive. Happy holidays!","['recreational-mathematics', 'combinatorics']"
617578,The shape of Pringles potato chip [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. This question is not about mathematics, within the scope defined in the help center . Closed 5 years ago . Improve this question Why the shape of Pringles potato chip is hyperbolic paraboloid? I found several articles that say the shape is hyperbolic paraboloid, but cannot find out why it is so. Does anyone have reasonable (and/or mathematical) answers?","['hyperbolic-geometry', 'geometry']"
617594,Need help simplifiying a rational expression,"There's a math question on an online test which asks the following Multiply the following expression, and simplify:
$\frac{x^2-16y^2}{x} * \frac{x^2+4xy}{x-4y}$ But no matter how I try I keep getting the answer incorrect with a message telling me to simplify my answer.  I can't seem to figure out how to simplify it enough to get it right. $\frac{x^2-16y^2}{x} * \frac{x^2+4xy}{x-4y}$
 equals, $\frac{x^4 + 4x^3y - 16x^2y^2 - 64xy^3}{x^2-4xy}$. I then factored x out of the numerator and denominator to get $\frac{x(x^3 + 4x^2y - 16xy^2 - 64y^3)}{x(x-4y)}$ and cancelled out the factored x's to get $\frac{x^3 + 4x^2y - 16xy^2 - 64y^3}{x-4y}$.  I don't know what to do from here though. I've managed to get enough marks to be able to pass it but since it's a readiness test I want to understand all of the material going in.","['rational-functions', 'algebra-precalculus']"
617601,Spectrum of shift-operator,"Hoi, consider the Hilbertspace $l^2$ and the Left and Right-shift operator \begin{align*}
L(x_1,x_2,\cdots) &= (x_2,x_3,\cdots)\\
R(x_1,x_2,\cdots) &= (0,x_1,x_2,\cdots )
\end{align*} I know that $L^*=R$ so these operators are Hilbert-space adjoints. The spectrum consists of 3 disjoint parts $\sigma(T) = \sigma_p(T)\cup \sigma_c(T)\cup \sigma_r(T)$. Assuming you are familiar with these notions: $\sigma_p(T)$ is point-spectrum, $\sigma_c(T)$ is continuous spectrum and $\sigma_r(T)$ the residual spectrum. I want to show that $$\sigma_p(L) = \sigma_r(R) = \{\lambda :|\lambda|<1\} $$
$$\sigma_c(L)=\sigma_c(R) = \{\lambda : |\lambda|=1\} $$
$$\sigma_r(L)=\sigma_p(R) =\emptyset. $$ I stumbled upon a few problems. I can see that $\rho(L),\rho(R)<1$ so that $\{\lambda: |\lambda|>1\}$ is contained in the resolvent-sets of both $L$, and $R$. I can calculate the point-spectrum for $L$, and $R$. So for $L$ i can calculate $\sigma_p(L)=\{\lambda : |\lambda|<1\} $ and since $\sigma(L)$ is closed, and $\{\lambda: |\lambda|>1\}$ is contained in the resolvent-set of $L$ we find that $\sigma(L) = \{\lambda: |\lambda| \leq 1\}$. Thus $$\sigma_c(L)\cup \sigma_r(L)= \{\lambda: |\lambda | =1\}. $$ Apparantly I can use the fact that $L$, and $R$ are eachothers adjoints, and reading the internet I found that $\sigma(T) = \sigma(T^*)$, or something like $\lambda \in \sigma(T) $implies $\overline{\lambda}\in \sigma(T^*)$ which is something i can't prove. I hoped to be able to use this fact by some Theorem in Rudin. (this excercise is also from Rudin CH. 12 excercise 18.c) Apparantly the fact that $\lambda \in \sigma_r(L)$ implies that $\overline{\lambda}\in \sigma_p(L^*) = \sigma_p(R) = \emptyset$, so that we can conclude that $\sigma_r(L)=\emptyset$. I dont understand this at all. Can someone explain this a little bit? How to go on from here? 
Thanks in advance.","['operator-theory', 'spectral-theory', 'functional-analysis']"
617622,Counter example for absolutely continuous measure,"I need a example for the following statement:
""Given a pair of finite measures $(\mu,\nu)$ on a given measurable space $(\Omega, \mathbb{A})$ is said to have property $P$ if for every $\epsilon >0$ there exists a $\delta >0$ such that for all $A \in \mathbb{A}$,  $\mu(A)<\delta  \rightarrow \nu(A)<\epsilon$. 
Show that in the case that $\nu$ is not a finite measure, $\nu$ is absolutely continuous with respect to $\mu$ does not imply that $(\mu,\nu)$ has property P. Thanks!","['measure-theory', 'examples-counterexamples', 'real-analysis']"
617636,Product of vector spaces,"Let $V$ be a vector space over a fixed field $k$. Under what circumstances do we have $V\times V\cong V$? I think this should be true if $\mathrm{dim} \ V=\infty$, isn't it?","['vector-spaces', 'linear-algebra', 'abstract-algebra']"
617639,irreducibility of $x^{5}-2$ over $\mathbb{F}_{11}$.,"I am tasked to show that $x^{5}-2$ is irreducible over $\mathbb{F}_{11}$ the finite field of 11 elements. I've deduced that it has no linear factors by Fermat's little theorem. But showing it has no quadratic factors is proving harder. My approach so far is assume it did. Factor the polynomial and remulitply and compare coefficients to obtain a contradiction. I'm having trouble doing that since there are so many cases. I was given then hint ""How many elements are in a quadratic extension of $\mathbb{F}_{11}$""? The answer is 121 but I don't know how that helps me. Any hints on dealing with the hint would be very nice. Thanks.","['finite-fields', 'irreducible-polynomials', 'abstract-algebra']"
617649,"The ""smallest"" and ""Largest"" finitely generated infinite group.","The smallest finite group that can be generated by $n$ elements and cannot be generated by any less than $n$ elements is a product of $n$ cyclic groups of order $2$. (a) Is there a largest finitely generated infinite group that can be generated by $n$ elements but not by more than $n$ elements? 
Largest in the sense that if you remove or change any relation between the generators you end up with a group that can be generated by more than $n$ elements. ADDED : (a) is not really a question since any infinite group $G$ can be infinitely generated $<G>$.  I'm stupid. (b) Is there a smallest finitely generated infinite group generated by $n$ elements yet cannot be generated by less than $n$ elements? Smallest in the sense that any extra relation imposed on the group's generators will result in a finite group (or an infinite group generated by less than $n$ elements).",['group-theory']
617652,Trying to understand a change of function in a ODE,"I'm trying to understand the following change. Given this equation: $2 z'' (1 + z^2) + (z')^3 = 0$ and writing $w = z'$, $z'' = w \dfrac{dw}{dz}$ reduces to: $$-\dfrac{dw}{w^2} = \dfrac{dz}{2 (1 +z^2)}$$ I don't understand that change of function. Is it $w(t)$ or $w(z)$? If it is $w(t)$ why the second ODE relates $w$ to $z$ instead of $w$ to $t$? If it is $w(z)$ how can it be $w(z) = z'(t)?$ Could you explain the function change in detail? This is from http://www.liv.ac.uk/~pjgiblin/papers/giblin-warder.pdf page 8 (close to the end)","['ordinary-differential-equations', 'functions']"
617669,How to find the infinitesimal generator of this semigroup?,"Definition 1: Let $X$ be a Banach space. A semigroup is a family $\{T(t)\}_{t\geq 0}$ of continuous linear operators $T(t):X\to X$ such that $(i)\;\;T(0)=I$, where $I$ is the identity operator; $(ii)\;\;T(s)\circ T(t)=T(t+s)$ for all $t,s\geq 0$. Definition 2: the infinitesimal generator of a semigroup $\{T(t)\}_{t\geq 0}$ is the operator $A:D(A)\to X$ where: $$D(A)=\left\{x\in X;\;\lim_{h\to 0^+}\frac{T(h)x-x}{h}\text{ exists in } X \right\}$$ and $$A(x)=\lim_{h\to 0^+}\frac{T(h)x-x}{h}$$ for all $x\in D(A)$. Definition 3: the translation of the function $f:\mathbb{R}\to\mathbb{R}$ is the function $f_t:\mathbb{R}\to\mathbb{R}$given by $f_t(x)=f(x+t)$ for all $x\in\mathbb{R}$. Take $X=L^2(\mathbb{R})$ in definition 1 and consider the semigroup $T:=\{T(t)\}_{t\geq 0}$ where $T(t)f=f_t$ for all $f\in L^2(\mathbb{R})$. My problem is to find the infinitesimal generator of $T$. First of all I need to find $D(A)$, that is, I need to find  all $f\in L^2(\mathbb{R})$ such that $$\lim_{h\to 0^+}\frac{f_h-f}{h}=\lim_{h\to 0^+}\frac{T(h)f-f}{h}=g\tag{1}$$ for some $g\in L^2(\mathbb{R})$. Could someone explain me how can we conclude? Any help is appreciated. Thanks.","['functional-analysis', 'partial-differential-equations', 'analysis', 'semigroup-of-operators', 'banach-spaces']"
617673,Finding a basis to a vector space,"Let $ W = \left \{\mathbf{x} = \begin{pmatrix} x_1 \\x_2 \\x_3 \end{pmatrix} : x_1 + x_2 + x_3 = 0  \right\}$ and find a basis for $W$ I don't really know how to do it by guess work so I tried this method: Solve $x_1 + x_2 + x_3 = 0$ to row echelon form (which it already is in) and so we get the solution $ \begin{pmatrix} x_1 \\x_2 \\x_3 \end{pmatrix} = \begin{pmatrix} -x_2 -x_3 \\x_2 \\x_3 \end{pmatrix}$ then use a simple method to find the matrix, let $x_2 = 1$ and $x_3 = 0$ which gives us $\begin{pmatrix} -1 \\1 \\0 \end{pmatrix}$ and let $x_3 = 1$ and $x_2 = 0$ giving $\begin{pmatrix} -1 \\ 0 \\1 \end{pmatrix}$ so the basis is $\left \{\begin{pmatrix} -1 \\1 \\0 \end{pmatrix}, \begin{pmatrix} -1 \\ 0 \\1 \end{pmatrix} \right\}$ Is this a valid method as I really don't like guess work (which my teacher said for us to do). I have tested and it is a basis for the vector space $W$ thanks",['linear-algebra']
617695,Probability that $ax^2+bx+c$ has no real roots after rolling 3 dice.,"Suppose that I roll $3$ dice and write down the outcome as the coefficients $a,b,c$ in the polynomial $ax^2+bx+c$ respectively. What is the probability that this polynomial has no real roots? So, I have to count the number of triples $(a,b,c)$ such that $b^2 < 4ac$, where $a,b,c \in \{1,2,3,4,5,6\}$. I'm not sure how I can do that. Please give me a hint first. This problem is from a high school probability course, so I think it must have a very basic solution.","['quadratics', 'dice', 'probability']"
617699,Can We Represent Every Real Number Using Only Finite Memory?,"This question arises from a comment I recently read in another question. My question is whether we can represent every real number using only finite memory. I will clarify what I mean by represent using only finite memory by use of examples: $5$ can be represented in finite memory simply by itself as a one-character string. Similarly for $1.234583$, which can also be represented by a string of finite length. $\pi$ can also be adequately represented in finite memory: it is the ratio of any circle's circumference to its diameter. $e$ we can represent as $\displaystyle\lim_{n \rightarrow \infty} \left(1+\frac1n\right)^n$ $0.818181\ldots$ can be represented as $0.\overline{81}$ or $\frac{9}{11}$. $0.010011000111\ldots$ can be represented as the sum of some sequence $a_n$ as $n\rightarrow \infty$. For all the examples above, an adequate representation of the given real is possible using only finite memory, because we can describe/define exactly the given real using a string of finite length. So do any reals that cannot be described/represented in finite memory exist? For which their only closed-form expression requires a string of infinite length? (Infinitely many digits?) Relevant Reading Material Includes: Is it possible to represent every huge number in abbreviated form? Every Number is Describable?","['formal-languages', 'real-analysis', 'number-theory']"
617711,Examples that the morphism $X\times_k k' \rightarrow X$ is not closed,"Let $k$ be a field.
Let $k'$ be an extension field of $k$.
Let $X$ be a $k$-scheme of finite type.
If $k'$ is algebraic over $k$, the morphism $X\times_k k' \rightarrow X$ is integral.
Hence it is closed.
Suppose $k'$ is not algebraic over $k$.
I would like to know examples, if any, that the morphism $X\times_k k' \rightarrow X$ is not closed.",['algebraic-geometry']
617717,Deducing that polynomials span,"Let us say that we are dealing with a countable family of polynomials with real coefficients in $n$ indeterminates that commute.  Are there any known/common nice systematic ways to tell if their span is the whole space of polynomials when they have a nice generating function?  What about the closure of the span in the supremum norm restricted to our polynomial space defined on a full-dimensional set such as $[0, 1]^n$? (I am not restricting only to methods that use the generating function.  But that is just one possibility.)","['analysis', 'linear-algebra', 'abstract-algebra', 'combinatorics']"
617735,Multiple regression degrees of freedom $f$-test.,"I'm finding conflicting information from college textbooks on calculating the degrees of freedom for a a global $F$-test on a multiple regression. To be absolutely clear, assume there are 50 observations and 3 independent variables. Can you please tell me the df for the numerator and denominator?  I have found 2 sets of numbers in college texts. One indicating the numerator is equal to $P$, in this case 3, and alternatively $P-1$.  For the denominator I am finding $n-p$,which in this case would be 47, and alternatively, $n-p-1$.  Perhaps I am misunderstanding the material and there are circumstances when one vs. the other formula applies. I've not done any regression analysis in more than 25 years and now find I'm stuck on a Christmas vacation project I wanted to do with my son. So any help that would explain, in a gentle way, (I can't get through the quadratic explanation, or something that will bury me in calculus) how to determine the df would be appreciated. Concrete examples would be very beneficial. Also, if there is a good practical walk through of multiple regression/Anova that will show some examples and explain concepts (but please do not recommend Regression for Dummies) I'd appreciate a referral to that as well.  Thanks for your help.",['statistics']
617793,How to prove that $n^{-2}[x+g(x)+g\circ g(x)+\cdots +g^{\circ n}(x)]$ converges when $n\to\infty$ [duplicate],"This question already has an answer here : Show that $\lim\limits_{n\to\infty}\frac{a_1+a_2+\dots+a_n}{n^2}$ exists and is independent of the choice of $a$ (1 answer) Closed 10 years ago . Let $f:\mathbb R\to\mathbb R$ be a periodic function with period $1$. We assume that $f$ is Lipschitz continuous, and in particular, we assume that there exists an $L\in (0,1)$, such
that
$$
|f(x)-f(y)| \le L|x-y|, \quad \text{for all $x,y\in\mathbb R$.}
$$
Let also $g(x)=x+f(x).$
Show that the limit
$$\lim_{n\to +\infty}\frac1{n^2}[x+g(x)+g(g(x))+\cdots +g^{\circ n}(x)]$$
exists and is independent of $x$, where, for every $n\ge1$, $g^{\circ n}$ is $g$ composed with itself $n$ times, thus $g^{\circ 1}=g$ and, for every $n\ge1$, $g^{\circ n+1}=g\circ g^{\circ n}$. My attempt: Since
$$f(x+1)=f(x),\forall x\in R$$
then
$$g(g(x))=g(x+f(x))=x+f(x)+f(x+f(x))$$
$$g(g(g(x)))=g(x+f(x)+f(x+f(x)))=x+f(x)+f(x+f(x))+f(x+f(x)+f(x+f(x)))$$
$$\cdots\cdots $$
and  I have
$$|g(x)-g(y)|=|x-y+f(x)-f(y)|\le |x-y|+|f(x)-f(y)|<(L+1)|x-y|$$
where $L+1>1$. So $g$ is also Lipschitz continuous, and that's all I can do. Thank you for you help.","['limits', 'calculus', 'analysis']"
617795,Finding the variance of a statistic.,"$X_1,\cdots,X_n$ are independent random variables from $N(\mu,\sigma^2)$ distribution. Define
$$T=\frac{1}{2(n-1)}\sum_{i=1}^{n-1}(X_{i+1}-X_i)^2$$
I have shown that it is an unbiased estimator of the variance. I need to compare its variance to that of the sample variance. Now how do I find $Var(T)$? Finding $E(T^2)$ simply by squaring the above expression and then tking expectation is becoming very clumsy!","['statistics', 'estimation']"
617797,Exactness of the Tensor Functor,"This might turn out to be a very stupid question, so I apologize in advance, but it is confusing me a little bit. I know in general that if $$M'\rightarrow M\rightarrow M''\rightarrow 0$$ is an exact sequence of $A-$modules, then $$M'\otimes_AN\rightarrow M\otimes_AN \rightarrow M''\otimes_AN \rightarrow 0$$ is an exact sequence for any $A-$module $N$. If instead we are given an exact sequence of the form: 
$$M'''\rightarrow M'\rightarrow M\rightarrow M''\rightarrow 0$$ where $M'''$ is not the zero module (because I know that tensoring with a module doesn't necessarily take injective maps to injective maps), then I guess my question is why isn't the following an exact sequence as well?
$$M'''\otimes_A N\rightarrow M'\otimes_AN\rightarrow M\otimes_AN \rightarrow M''\otimes_AN \rightarrow 0$$ What is going morally wrong here? I guess i'm wondering where exactly is the proof of the first case failing to show that the second sequence is exact at $M'\otimes_AN$? I would appreciate very much if anyone could clarify my confusion. I am probably just being stupid about this :/","['homological-algebra', 'abstract-algebra', 'tensor-products']"
617808,Lebesgue measure/Measurable sets,"Question : Let $f,g$ be measurable real valued functions on $\mathbb{R}$ such that  : $$\int_{-\infty}^{\infty} (f(x)^2+g(x)^2)dx=2\int_{-\infty}^{\infty} f(x)g(x)dx$$ Let $E=\{x\in \mathbb{R} : f(x)\neq g(x)\}$ . Which of the followng statements are necessarily true? $E$ is empty set $E$ is measurable $E$ has lebesgue measure $0$ For almost all $x\in \mathbb{R}$ we have $f(x)=0$ and $g(x)=0$ Explanation: What all I could see is that second bullet and third bullet are probably correct. Because : $$\int_{-\infty}^{\infty} (f(x)^2+g(x)^2)dx=2\int_{-\infty}^{\infty} f(x)g(x)dx$$ i.e., $$\int_{-\infty}^{\infty} (f(x)^2+g(x)^2)dx-2\int_{-\infty}^{\infty} f(x)g(x)dx=0$$ i.e., $$\int_{-\infty}^{\infty}(f(x)-g(x))^2dx=0$$ Though I have negative limits my function $(f(x)-g(x))^2$ is positive So, I would see that $E=\{x\in \mathbb{R} : f(x)\neq g(x)\}$ is measurable and has measure $0$ Please tell me if what I have done is sufficient/clear.","['lebesgue-integral', 'measure-theory', 'real-analysis', 'analysis']"
617827,On the nature of a first derivative,"This is a very, very basic question. Never been very involved in math but I've been learning calculus in my free time, so here goes. I have observed some various things that happen with derivatives, but I don't know what it's telling me. I see that if I find the slope at two x-values with a derivative, then the difference in their slopes is the same as if I plugged the difference between the two x-values into the derivative. But what does the slope itself tell me? If my x value is 8, and f'(x) is 2x, then what does my slope of 16 at that point tell me? The slope at 7.99998 is going to be .00004 away from 16, but what do those two slopes actually tell me? I guess I'm having a hard time understanding the usefulness of the value given when you plug in x-values in a slope, what does the quantity (the slope) actually mean? Thanks for taking time to read this. I understand this board has lots of really juicy questions and this is hardly worth your time but I really appreciate the help!","['education', 'calculus', 'derivatives']"
617863,"Prove, in this figure, that $EFGH$ is a parallelogram","In the following figure, $ABCD$ is a parallelogram, and $O$ is any point. Parallelograms $OAEB, OBFC, OCGD, ODHA$ are completed. Prove that $EFGH$ is a parallelogram. We can obtain a fairly trivial proof using affine geometry. As $OAEB, OBFC, OCGD, ODHA$ are parallelograms, $$\vec{A} + \vec{B} = \vec{O} + \vec{E} \implies \vec{A}  + \vec{B} - \vec{O} = \vec{E} \tag1$$ $$\vec{C} + \vec{B} - \vec{O} = \vec{F}\tag2$$ $$\vec{D} + \vec{C} - \vec{O} = \vec{G} \tag3$$ $$\vec{D} + \vec{A} - \vec{O} = \vec{H}\tag4$$ Adding $(1)$ to $(3)$ and $(2)$ to $(4)$ , we get, $$\vec{E} + \vec{G} = \vec{A} + \vec{B} + \vec{C} + \vec{D} - 2\vec{O} \tag5$$ $$\vec{F} + \vec{H} =  \vec{A} + \vec{B} + \vec{C} + \vec{D} - 2\vec{O} \tag6$$ Clearly, $(5)$ and $(6)$ are equal, therefore, $$\vec{E} + \vec{G} = \vec{F} + \vec{H}$$ Therefore, $EFGH$ is a parallelogram. Can somebody give an elementary proof using Euclidean geometry? Also, I noticed that in my proof, nowhere did I use the fact that $ABCD$ is a parallelogram, but constructing an example, it was quickly clear that the result stated does not generalize to all quadrilaterals. How come? Is my proof incorrect?","['affine-geometry', 'geometry']"
617907,Dealing with Generating Functions accurately,"I'm currently working through Iven Niven's ""Mathematics of Choice."" In the chapter on Generating Functions, the exercises include problems like: How many solutions in non-negative integers does the equation $2x+3y+7z+9r=20$ have? This of course ends up being the same as finding the coefficient of $x^{20}$ in $(1+x^2+x^4+x^6+\cdots+x^{20})(1+x^3+x^6+\cdots+x^{18})(1+x^7+x^{14})(1+x^9+x^{18})$. Maybe I'm just being a big weenie, but dealing with polynomials this large ends up being really tedious and error-prone. I've realized that you can save the most involved multiplication for last, since that requires the least detail, and I'm of course not bothering to keep track of any powers greater than the one I'm interested in. Any tips for keeping these giant polynomials manageable?","['generating-functions', 'combinatorics']"
617915,A finite unital and commutative ring with exactly one maximal ideal has $p^{n}$ elements.,"Suppose $R$ is a finite unital and commutative ring that has exactly one maximal ideal. Prove that $\left | R \right |=p^{n}$ where $p$ is a prime number. If $R$ will be non-commutative, do we have the desired result? Suppose $I$ is a maximal ideal of $R$, so $R/I$ is a field, because $R$ is finite, thus $| R/I|=p^{m}$, where $p$ is prime. Now I don't know what I should do next, so please help me.","['noncommutative-algebra', 'commutative-algebra', 'ring-theory', 'abstract-algebra']"
617936,"""Why"" is $[\mathbb{C}:\mathbb{R}] < \infty$?","Obviously this question is a little open-ended. A lot of complex analysis seems to work primarily because we can view $\mathbb{C}$ as a finite-dimensional $\mathbb{R}$-algebra, and apply analytic and geometric ideas which work only (or at least best) in finite-dimensional real space. When we consider most other fields that we come across in practice (for instance, $\mathbb{F}_q$,$\mathbb{Q}_p$, or $\mathbb{Q}$) generally their algebraic closures are infinite-dimensional extensions. Is there any intuitive reason why the way we construct $\mathbb{R}$ would suggest that we were producing a field whose algebraic closure was a finite-dimensional extension?  Does such a construction generalize to other fields in any way?","['abstract-algebra', 'soft-question', 'real-analysis', 'intuition', 'complex-analysis']"
617942,$\ell^p$ is not isometric to $\ell^q$,The problem is this: if $1\le p<q<\infty$ then $\ell^p$ and $\ell^q$ are not isometric (as Banach spaces). This is an exercise but I'd like to see an elegant proof.,"['lp-spaces', 'functional-analysis', 'real-analysis', 'banach-spaces']"
617963,"Determining the number of surfaces and boundaries *from* the number of vertices, edges and faces.","Question: Suppose that the number of vertices, the number of edges and the number of faces are given for a set of polyhedra (consisting of triangles only). Can the number of polyhedra and number of boundaries be determined from these parameters only? Is there an answer that enables cheap computation or one that shows that such an approach does not exist? Background: In the field of Mechanical engineering, Computer Aided Engineering (CAE) sometimes requires a 3D mesh of connected triangular elements to represent the geometry of e.g. machine components. However, these meshes may not always be 'watertight' or accidentally contain more that one component where a single component is expected, etcetera. The question is if there exists a computationally cheap function to analyze this, similar to the Euler–Poincaré characteristic. Approaches that I here consider computationally expensive are e.g. topology traversal using e.g. advancing front techniques.","['algebraic-topology', 'combinatorics']"
617971,"If $G$ is an infinite group, then the group ring $R(G)$ is not semisimple.","Let $R$ be a ring and $G$ an infinite group. Prove that $R(G)$ (group ring) is not semisimple. My idea was to suppose it is semisimple, then $R(G)$ is left artinian and $J(R(G))=0$. I was trying to make a ascending chain of ideals that won't stop, then it is not left noetherian, by Hopkins theorem it is not left artinian, a contradiction.
I also tried to make a descending chain that won't stop, so it is not left artinian, but I wasn't successful. So please help me.","['ring-theory', 'group-theory', 'abstract-algebra', 'group-rings']"
617974,Need Sine form of Cotangent equation,$$(b^2 - c^2)\cot A + (c^2 - a^2)\cot B + (a^2 -b^2)\cot C=0$$ I want this equation to be in the Sine form. Please help me with steps. Thanks a lot,['trigonometry']
618001,Convex Sets in Functional Analysis?,"Why did Bourbaki choose to study convex sets, convex functions and locally convex sets as part of the theory of topological vector spaces, and what is so important about these concepts? I'd like to really feel the intuitive reason why they devoted an entire chapter to these things, to appreciate the necessity for studying them here and not somewhere else , why they are naturally related to semi-norms and weak topologies, and why lead to something so important as the Hahn-Banach theorem. (Contents of the chapter viewable on amazon if necessary) Edit - to be clear: I'm not interested in ex post facto justifications for studying convexity. You could make the same arguments about e.g. point set topology, missing the fundamental simplicity in the fact that topology is just about 'near-ness', ignoring how every single concept/theorem has a deep intuitive interpretation as such. I'm interested in the most core fundamental conception of convexity as it lies within the edifice of mathematics as a whole, in the sense that one would be able to derive the contents of the chapter themselves when viewed from the right perspective. Thanks!","['topological-vector-spaces', 'convex-analysis', 'functional-analysis']"
618004,finite group whose only automorphism is identity map,"Question is to prove that  : A finite group whose only automorphism is identity map must have order at most $2$. What i have tried is  : As any automorphism is trivial, so would be inner automorphism i.e., each map for fixed $g\in G $ with $\eta : G\rightarrow G$ taking $h$ to $ghg^{-1}$ is trivial. Thus, $ghg^{-1}=g$ i.e., $gh=hg$ for all $g\in G$ and $h\in G$ which would say that $G$ is abelian. So, I would have that $G$ is finite abelian group. Now, As $G$ is abelian, the map $g\rightarrow g^{-1}$ is an automorphism. But only automorphism is identity map, so we would have  : $g=g^{-1}$ i.e., $g^2=e$ for all $g\in G$ So, I would have that $G$ is group with each element of order $2$. Combining with previous result I would have : $G$ is a finite abelian group in which each element is of order $2$ I am not able to conclude anything more than this.... A kind of cheating would give something very close : As group is finite abelian which has each element with order $2$, It should be : $\mathbb{Z}_2\times \mathbb{Z}_2$ Or $\mathbb{Z}_2\times \mathbb{Z}_2\times \mathbb{Z}_2$ Or $\mathbb{Z}_2\times \mathbb{Z}_2\times \mathbb{Z}_2\times \mathbb{Z}_2$ Or something very similar to this. For first group $\mathbb{Z}_2\times \mathbb{Z}_2$  automorphism group is general linear group of order $2$ with entries from $\mathbb{Z}_2$ which is not trivial. So, this should not be the required group. This would hold for similar cases So, I feel that i am on right path but i need some help to make it more clear. Thank you :)","['finite-groups', 'group-theory', 'abstract-algebra']"
618031,Del operator ($\nabla$) in spherical co-ordinate system,"I am teaching myself about vector fields and came across the following question: Is the following force field $\vec{F}$ conservative, where $\vec{F}(r,\theta,\varphi)$ is defined by: $$F_{r}=2ar\sin(\theta)\sin(\varphi),\:
 F_{\theta}=ar\cos(\theta)\sin(\varphi),\: F_{\varphi}=ar\cos(\varphi)$$ A simple test to determine whether a force field is conservative is to see if the following is true: $$\nabla\times \vec{F}=\vec{0}$$ Where by abuse of notation we have: $$\nabla=\frac{\partial \hat{\boldsymbol{\imath}}}{\partial x}+\frac{\partial \hat{\boldsymbol{\jmath}}}{\partial y}+\frac{\partial \hat{\boldsymbol{k}}}{\partial z}$$ However, as we are using a curvilinear co-ordinate basis I'm not sure how $\nabla$ should be defined? Further to JohnD's answer , I have tried to derive his expression for $\nabla$, however, I have not managed to come to the right answer. Taking partial derivatives of $r$ with respect to $x,y$ and $z$ we get: \begin{align}\frac{\partial r}{\partial x}&=\frac{x}{\sqrt{x^{2}+y^{2}+z^{2}}}=\sin(\theta)\cos(\varphi) \\
\frac{\partial r}{\partial y}&= \frac{y}{\sqrt{x^{2}+y^{2}+z^{2}}}=\sin(\theta)\sin(\varphi) \\ \frac{\partial r}{\partial z} &= \frac{z}{\sqrt{x^{2}+y^{2}+z^{2}}}=\cos(\theta)\end{align} Our partial derivatives of $\theta$ with respect to our cartesian co-ordinates are: \begin{align}\frac{\partial \theta}{\partial x}&= \frac{z\frac{\partial r}{\partial x}}{\sqrt{r^{2}-z^{2}}}=\frac{r\cos(\theta)\sin(\theta)\cos(\varphi)}{r\sqrt{1-\cos^{2}(\theta)}}=\cos(\theta)\cos(\varphi) \\
\frac{\partial \theta}{\partial y}&=\frac{z\frac{\partial r}{\partial y}}{\sqrt{r^{2}-z^{2}}}=\frac{r\cos(\theta)\sin(\theta)\sin(\varphi)}{r\sqrt{1-\cos^{2}(\theta)}}=\cos(\theta)\sin(\varphi) \\
\frac{\partial \theta}{\partial z} &= \frac{z\frac{\partial r}{\partial z}-r}{r\sqrt{r^{2}-z^{2}}} = \frac{r\cos^{2}(\theta)-r}{r\sqrt{r^{2}-r^{2}\cos^{2}(\theta)}}=-\frac{\sin(\theta)}{r}\end{align} And finally partial derivatives of $\varphi$: \begin{align}\frac{\partial \varphi}{\partial x}&=-\frac{y}{x^{2}(1+\frac{y^{2}}{x^{2}})}=-\frac{r\sin(\theta)\sin(\varphi)}{r^{2}\sin^{2}(\theta)\cos^{2}(\theta)(1+\tan^{2}(\varphi))}=-\frac{\sin(\varphi)}{r} \\
\frac{\partial \varphi}{\partial y}&=\frac{1}{x(1+\frac{y^2}{x^{2}})}=\frac{1}{r\sin(\theta)\cos(\varphi)(1+\tan^{2}(\varphi))}=\frac{\cos(\varphi)}{r\sin(\theta)} \\
\frac{\partial \varphi}{\partial z}&=0\end{align} We therefore get: \begin{align}\frac{\partial}{\partial x}&\mapsto \sin(\theta)\cos(\varphi)\frac{\partial}{\partial r}+\cos(\theta)\cos(\varphi)\frac{\partial}{\partial \theta} - \frac{\sin(\varphi)}{r}\frac{\partial}{\partial \varphi} \\
\frac{\partial}{\partial y} &\mapsto \sin(\theta)\sin(\varphi)\frac{\partial}{\partial r} + \cos(\theta)\sin(\varphi)\frac{\partial}{\partial \theta} + \frac{\cos(\varphi)}{r\sin(\theta)}\frac{\partial}{\partial \varphi} \\
\frac{\partial}{\partial z} &\mapsto \cos(\theta)\frac{\partial}{\partial r} - \frac{\sin(\theta)}{r}\frac{\partial}{\partial \theta}\end{align} However summing coefficients of $\frac{\partial}{\partial r}$, $\frac{\partial}{\partial \theta}$ and $\frac{\partial}{\partial \varphi}$ doesn't give what is expected, so what have I done wrong?","['multivariable-calculus', 'vector-analysis']"
618036,"Calculation of $\lambda$, If $x^2+2(a+b+c)\cdot x+3\lambda \cdot (ab+bc+ca) = 0$ has real roots","Let $a,b,c$ be the sides of a $\triangle$ where $a\neq b\neq c$ and $\lambda\in \mathbb{R}$. If the roots of the equation $$x^2+2(a+b+c)\cdot x+3\lambda \cdot (ab+bc+ca) = 0$$ are real , Then which one is Right. $\bf{Options}::$ $\displaystyle (a)\;\; \lambda <\frac{4}{3}\;\;\;\;\;\; (b)\; \lambda >\frac{4}{3}\;\;\;\;\;\; (c)\; \lambda \in \left(\frac{1}{3},\frac{5}{3}\right)\;\;\;\;\;\; (d)\;\; \lambda \in \left(\frac{4}{3},\frac{5}{3}\right)$ $\bf{My\; Try}::$ If given equation has real roots , Then its $\bf{Discriminant}\geq 0$ So $$\displaystyle 4(a+b+c)^2-12\lambda\cdot (ab+bc+ca)\geq 0$$ $$\displaystyle (a+b+c)^2-3\lambda\cdot (ab+bc+ca)\geq 0$$ $$\displaystyle 3\lambda\leq \frac{(a+b+c)^2}{(ab+bc+ca)} = \frac{a^2+b^2+c^2}{(ab+bc+ca)}+2$$ Now I did not understand how can i solve after that Help Required Thanks",['algebra-precalculus']
618040,Finding value of the function $f(x)f(y) = f(x) + f(y) + f(xy) - 2$?,"So here is the question If $f(x)$ is a polynomial satisfying $$f(x)f(y) = f(x) + f(y) + f(xy) - 2$$ for all real $x$ and $y$  and $f(3) = 10$, then $f(4)$ is equal to ? here what i have tried Putting $x=y=1$ in the given solution,$$(f(1)^2) = 3f(1) - 2$$ on solving it we get $$f(1) = 2$$
  or$$f(1)= 1$$ so putting $y=1$in the eqation $$f(x)f(y) = f(x) + f(y) + f(xy) - 2$$we get $$f(x) = 1$$ but it not true as $$f(3) = 10$$ so $f(1) = 2$ i am stuck here i don't know what to do next please help me Akash Thanks",['functions']
618068,Can I use the quadratic formula when there is no constant term?,"I was wondering if it's erroneous to use the quadratic formula on a quadratic equation where there is no constant term. What I figured I'd try was to just assome the constant term is +0. I was doing a trigonometric equation, which looks like this: $2\cos^2 x - 3\sqrt 3 \cos x = 0$ I did like this: $\cos x = y$ $2y^2 - 3\sqrt 3y = 0$ $$y = \dfrac{3\sqrt 3 \pm \sqrt{27 - 4(2)(0)} }4$$ and ended up down the line with y equaling  0 (when confined to a domain between -1 and 1). When I try doing the equation on my calculator with x equaling 90 or 270 (as it has to be for cos x to equal 0), it does end up being 0. So I did arrive at the right answer doing it this way, but for all I know that might just be a lucky coincidence. So I'm wondering if it's right to use the quadratic formula in this case, or if I just lucked out on having it work?","['trigonometry', 'algebra-precalculus', 'quadratics']"
618074,Function : Find the range of $f(x) = \sin^{-1}x +\tan^{-1}x +\cos^{-1}x$,"Problem : Find the range of $f(x) = \sin^{-1}x +\tan^{-1}x +\cos^{-1}x$ Solution : Since, $\sin^{-1}x + \cos^{-1}x = \frac{\pi}{2}$ Since range of $\tan^{-1}x$  is $ (\frac{-\pi}{2}, \frac{\pi}{2})$ $\therefore, \frac{-\pi}{2} \leq \tan^{-1}x \leq \frac{\pi}{2}$ = $ \frac{-\pi}{2} + \frac{\pi}{2} \leq \tan^{-1}x + \frac{\pi}{2} \leq \frac{\pi}{2} + \frac{\pi}{2}$. = $0 \leq \tan^{-1}x+ \frac{\pi}{2} \leq \pi $ Is it correct.. please suggest thanks....","['algebra-precalculus', 'functions']"
618080,Uniform continuity - Please check my work,"Iv'e got some questions involving uniform continuity of functions and its properties.
I would like that someone will check my work and maybe help with correcting flaws. Let $A \subset R$ and let $f,g: \ A \rightarrow \mathbb{R} $ be uniformly continuous in A. Prove or disprove: f+g is uniformly continuous in A : By definitions: $\forall \epsilon'>0 \ \exists \delta_1>0: \ |x-y|<\delta_1 \Rightarrow |f(x)-f(y)|<\epsilon'$ $\forall \epsilon'>0 \ \exists \delta_2>0: \ |x-y|<\delta_2 \Rightarrow |g(x)-g(y)|<\epsilon'$ Now, let $h(x)=f(x)+g(x)$ and $\delta=min(\delta_1,\delta_2)$. By the triangle inequality we may write the following:
$|[f(x)-f(y)]+[g(x)-g(y)]| \leq |f(x)-f(y)|+|g(x)-g(y)|<\epsilon'+\epsilon'=2\epsilon'$. Let $\epsilon'=\frac{\epsilon}{2}$ we get eventually:
$\forall \epsilon>0 \ \exists \delta>0: \ |x-y|<\delta \Rightarrow |h(x)-h(y)|<2\epsilon'=\epsilon$. $f\cdot{g}$ is uniformly continuous in A - This is false as we may take $f(x)=x, \ g(x)=x$. f,g are bounded. $f\cdot{g}$ is uniformly continuous in A - I have seen proofs here and here . Given $A=\mathbb{R}$. $f \circ g$ is uniformly continuous in $\mathbb{R}$ - I have no clue - no matter what I tried to do, I get to dead end. Please help, thanks!","['calculus', 'continuity', 'functions']"
618101,Essential Supremum with the continuous function?,"I have a problem when I read about the Essential Supremum of a measurable function. 
Let $f: E\longrightarrow \mathbb{R}$ is a measurable function respect $E$ is Lebesuge measurable set and the Lebesgue measure. Let
$$ \operatorname{ess sup} f = \inf\{z: f\leq z\;\text{almost everywhere}\}$$
We always have $\operatorname{ess sup} f \leq \sup f$, but when $f$ is continuous, why $\operatorname{ess sup} f = \sup f$? I assume that $\operatorname{ess sup} f < \sup f = \alpha < \infty$, then exist $z$ such that $f\leq z$ almost everywhere and $z < \sup f = \alpha$, then the set $A = \{x\in E: f(x) > z\}$ is a null set, so the set $B = \{x\in E: \alpha > f(x) > z\}$ is also a null set, but $B = f^{-1}\big((z,\alpha)\big)$ is an open set in $E$. But since a set $B$ is open in $E$ if and only if exist an open set $V \subset \mathbb{R}$ such that 
$$ B = V\cap E$$
Now, I can't find any contradiction?, for exmaple, if $E = \mathbb{R}$ then I have a contradiction since $B$ is open and not empty which can't be a null set. But if $E$ is a null set of $\mathbb{R}$, why is contradiction?",['real-analysis']
618111,Smallest non-commutative ring with unity,Find the smallest non-commutative ring with unity. (By smallest it means it has the least cardinal.) I tried rings of size 4 and I found no such ring.,"['noncommutative-algebra', 'ring-theory', 'abstract-algebra']"
618136,"Show that $T_\lambda : C^0([0,1], \mathbb{R}) \to C^0[(0,1), \mathbb{R})$ is contractive.","Let the aplication $T_\lambda : C^0([0,1], \mathbb{R}) \to C^0[(0,1), \mathbb{R})$ defined by $$ T_\lambda \phi(x) = \lambda \int_0^1 \frac{x^2 + y^2}{1 + |\phi(y)|} \, dy $$ Show that $T_\lambda$ is contractive for  $|\lambda| < 3/4$ My attemp: I have only been able to show that $T_\lambda$ is contractive for $|\lambda | < 1/2$ $$ d ( T_\lambda(\phi), T_\lambda(\psi)) = || T_\lambda(\phi) - T_\lambda(\psi)||_\infty = \textrm{sup}_{x \in[0,1]} \{| \lambda \int_0^1\frac{x^2 + y^2}{1 + |\phi(y)|}dy - \lambda \int_0^1\frac{x^2 + y^2}{1 + |\psi(y)|}dy|\} $$ $$ =  | \lambda \,\, | \textrm{sup}_{x \in [0,1]} \{ |\int_0^1\frac{(x^2 + y^2)(|\psi(y)| - |\phi(y)|)}{(1 + |\phi(y)|)(1 + |\psi(y)|)} dy |\} $$ Now let $f_x(y) =\frac{(x^2 + y^2)(|\psi(y)| - |\phi(y)|)}{(1 + |\phi(y)|)(1 + |\psi(y)|)} $ and let $y_0 \in [0,1]$ such that $f_x(y_0) = \textrm{max}_{y \in [0,1]} {f(y)}$ Then: $$ | \lambda \,\, | \textrm{sup}_{x \in [0,1]} \{ |\int_0^1\frac{(x^2 + y^2)(|\psi(y)| - |\phi(y)|)}{(1 + |\phi(y)|)(1 + |\psi(y)|)} dy |\} \leq$$
$$ \leq | \lambda \,\, | \textrm{sup}_{x \in [0,1]} \{ |\frac{(x^2 + y_0^2)(|\psi(y_0)| - |\phi(y_0)|)}{(1 + |\phi(y_0)|)(1 + |\psi(y_0)|)}  \leq 2|\lambda| |\psi(y_0) - \phi(y_0)| \leq 2 |\lambda| d(\phi, \psi) $$ Then is inmediate that $T_\lambda$ is ocntractive for $ |\lambda| < 1/2 $ Is there any errors in my attemp? How can I improve it to get $|\lambda| < 3/4$?","['functional-analysis', 'functions']"
618137,"Cubic equation $ax^3+3bx^2+3cx+d = 0$ has $2$ equal roots. How can I find their value in terms of $a,b,c$?","If the equation $ax^3+3bx^2+3cx+d = 0$ has $2$ equal roots, then equal root must be equal to $\displaystyle \frac{bc-ad}{2(ac-b)^2}.$ My Try:: Let $x=\alpha,\alpha,\beta$ be the roots of given equation. Then using Vieta's formula $$ \alpha+\alpha+\beta = -\frac{3b}{a}\Rightarrow 2\alpha +\beta = -\frac{3b}{a}$$ $$ \alpha \cdot \alpha +\alpha \cdot \beta +\alpha \cdot \beta = \frac{3c}{a}\Rightarrow \alpha^2+2\alpha \cdot \beta = \frac{3c}{a}$$ $$\alpha \cdot \alpha \cdot \beta = -\frac{d}{a}\Rightarrow \alpha^2 \cdot \beta = -\frac{d}{a}.$$ Now I did not understand how can I find the value of $\alpha$ in terms of $a,b$ and $c$. Help is required. Thanks","['cubics', 'algebra-precalculus']"
618150,Continuity of double centralizers in Banach algebras,"I had some problems with a certain exercise, came up with a solution, but I'm not sure it is correct. Exercise (""MURPHY, C*-Algebras and Operator Theory"", Chapter 2, exercise 1) Let $A$ be a Banach algebra such that for all $a\in A$, the implication
  $$Aa=0\text{ or }aA=0\Rightarrow a=0\qquad (1)$$
  holds. Let $L,R$ be linear mappings from  $A$ to itself such that for all $a,b\in A$,
  $$L(ab)=L(a)b,\quad R(ab)=aR(b),\qquad (2)$$
  $$\text{and } R(a)b=aL(b).\qquad (3)$$
  Show that $L$ and $R$ are necessarily continuous. A double centralizer in a Banach algebra is defined to be a pair $(L,R)$ of bounded linear maps from $A$ to itself satisfying conditions (2) and (3). This exercise shows that if the Banach algebra satisfies condition (1) (for example, if it is a C*-algebra), then boundedness is consequence of (2) and (3). I spent quite some time trying to solve this. Then, Solution: By the Closed Graph Theorem, to show that $L$ is continuous, it suffices to show that for every sequence $\left\{x_n\right\}\subseteq A$ such that $x_n\rightarrow 0$ and such that $\left\{L(x_n)\right\}$ also converges, then $\lim L(x_n)=0$. Let $x_n\rightarrow 0$ and $L(x_n)\rightarrow y$ in $A$. Then for every $n\in\mathbb{N}$ and for every $b\in A$,
$$bL(x_n)=R(b)x_n,\quad\text{ by (3)}.$$
Taking $n\rightarrow\infty$, we have, for every $b\in A$,
$$by=R(b)0=0,$$
that is, $Ay=0$. By (1), this implies that $y=0$. Continuity of $R$  is proved similarly. Q.E.D. Now, the problem is that I didn't use condition (2), and that seems too strong. Is there any problem with my reasoning? Thank you. EDIT (see Martin's answer): I just found out that (1) and (3) imply (2). This explains why (2) was not used above. Let's show this: Suppose $A$ is an algebra (not necessarily normed) satisfying (1) and let $L,R$ be linear maps from $A$ to $A$ satisfying (3). Let $a,b\in A$. Then for every $c\in A$,
$$c(L(ab)-L(a)b)=cL(ab)-cL(a)b\overset{(3)}{=}R(c)(ab)-(R(c)a)b=R(c)ab-R(c)ab=0.$$
Then $A(L(ab)-L(a)b)=0$, hence, by (1), $L(ab)=L(a)b$, for every $a,b\in A$. Similarly, $R(ab)=aR(b)$ for every $a,b\in A$. Therefore, (2) holds.","['banach-algebras', 'c-star-algebras', 'continuity', 'analysis', 'functional-analysis']"
618162,"Set theory, show a set is countable, homework. check my answer","I solved this question but there is something strange going on and I am unsure of myself. Would like someone to review it. We are given a total order (or linear order) $<^{*}$on group $A$ such that for all $a \in A$: $|\{x\in A | x<^{*}a\}|<\aleph_0$ We are asked to show that $A\leq \aleph_0$ My solution if $<^{*}$ is a total order then there is an $a' \in A$ such that for all $x\in A$: $x<^{*}a'$. so if we take $a=a': \{x\in A | x<^{*}a\}=A$  so we can infer that $A < \aleph_0$... Here's what bothers me. We were asked to prove that $A \leq \aleph_0$ not $A < \aleph_0$. I know that what i proved shows both, but they aren't usually that lenient. if they wrote $\leq$ then that means there is a possiblity that $|A| = \aleph_0$, and according to my proof there isnt. Have I done something wrong? I think that $A$ is a finite group. Else, $|\{x\in A | x<^{*}a\}|<\aleph_0$ won't be true for all $a$.","['infinity', 'elementary-set-theory', 'proof-verification']"
618169,Limits and derivatives - two questions,"I was asked to find two limits. Let $f$ be differentiable function at $x=1$ and $f(1)>0$. $$\lim_{n \rightarrow \infty}\left(\frac{f\left(1+\frac{1}{n}\right )}{f(1)} \right)^{\frac{1}{n}}$$ Let $\frac{1}{n}=h$ so the limit becomes $$\lim_{h \rightarrow 0}\left(\frac{f\left(1+h \right)}{f(1)} \right)^h=\lim_{h \rightarrow 0} \left(\frac{f(1+h)-f(1)}{f(1)}+1 \right)^h$$ How may I continue? Same for $\lim_{x \rightarrow 1} \left(\frac{f(x)}{f(1)} \right)^{\frac{1}{\log(x)}}$. I defined $h=\log(x)$ and tried to continue with no luck. Please help, thank you!","['calculus', 'derivatives', 'limits']"
618184,"Vectors, Basis, Dual Vectors, Dual Basis and Tensors","I'm trying to understand tensors and I know they have something to do with the basis and the dual basis of a vector space and a dual space. First I will give a concrete example to make clear what I want to understand. Let 
$$v_1=\left(\begin{array}{cc}
2 \\
3 \\
\end{array}\right)$$ $$v_2= \left(\begin{array}{cc}
1 \\
2 \\
\end{array}\right) $$ be a basis for some vectorspace V(over the reals) and let v be in V. $$v=\left(\begin{array}{cc}
4 \\
2 \\
\end{array}\right) $$ Then calculate: $$\left(\begin{array}{cc}
4 \\
2 \\
\end{array}\right) = v_1\left(\begin{array}{cc}
2 \\
3 \\
\end{array}\right)+ v_2\left(\begin{array}{cc}
1 \\
2 \\
\end{array}\right) $$ In matrix-form:
$$\left(\begin{array}{cc}
4 \\
2 \\
\end{array}\right)= \left(\begin{array}{cc}2&1\\3&2\end{array}\right)\left(\begin{array}{cc}
v_1 \\
v_2 \\
\end{array}\right) $$ With solution: $$\left(\begin{array}{cc}
v_1 \\
v_2 \\
\end{array}\right)= \left(\begin{array}{cc}
6 \\
-8 \\
\end{array}\right)$$ So I have two transformations: 1.
$$\left(\begin{array}{cc}
4 \\
2 \\
\end{array}\right)= \left(\begin{array}{cc}2&1\\3&2\end{array}\right)\left(\begin{array}{cc}
6 \\
-8 \\
\end{array}\right)$$ 2.With the inverse matrix !
$$\left(\begin{array}{cc}2&-1\\-3&2\end{array}\right)\left(\begin{array}{cc}
4 \\
2 \\
\end{array}\right)= \left(\begin{array}{cc}
6 \\
-8 \\
\end{array}\right)$$ Now I know that the dual basis is just the rows of the inverse matrix: $$ B^* = (2, -1), (-3, 2)$$ which gives the Kronecker delta when multiplied in matrix form with it's ""not inverse"" matrix. For simplicity let's write: $$S = \left(\begin{array}{cc}2&1\\3&2\end{array}\right)$$
$$S^{-1} = \left(\begin{array}{cc}2&-1\\-3&2\end{array}\right) = T $$ So we can write it as this: 1.
$$\left(\begin{array}{cc}
4 \\
2 \\
\end{array}\right)= S\left(\begin{array}{cc}
6 \\
-8 \\
\end{array}\right)$$ 2.
$$T\left(\begin{array}{cc}
4 \\
2 \\
\end{array}\right)= \left(\begin{array}{cc}
6 \\
-8 \\
\end{array}\right)$$ Now I'm almost there to get a tensor I think. But I'm confused with all the bases and transformations. What role does the dual basis play in this? And how can I construct a tensor out of these bases? Just glue all the bases together, then dual bases indices up and normal bases indices down ? I think what would help me is when someone could show me how to do this procedure above, but with covectors(other name for dual vectors) instead of vectors. For example, let's have a dual basis and some covector and then find the coefficients with the inverse of the dual basis and so on. And I would appreciate a concrete example similar to mine above.Thanks for response ! Happy Holidays","['vector-spaces', 'differential-geometry', 'linear-algebra', 'tensors', 'functional-analysis']"
618185,continuous and bounded function without maximum or minimum,"Give an example that contradicts this sentence : $f:(0,1]\to\Bbb R$ is a continuous and bounded function in $(0,1]$ then : $f$ has maximum or minimum. I have understood that $\sin(1/x)$ could be a right contradiction but I can't understand why this works ? Could anyone here explain me ? 
Thanks :)",['functions']
618188,Distribution function of the sum of poisson and uniform random variable.,"Merry Christmas to everybody. I am working on the following problem. Let $X$ and $Y$ be independent Poisson($\lambda$), respectively Uniform$(0,1)$ random variables. Find the distribution function of the random variable $Z := X+Y$. I have the solution here but I don't understand it completely. \begin{align*}
F_Z(a) &= \mathbb P(X+Y \le a) = \sum_{i = 0}^{\lfloor a\rfloor-1} \mathbb P(X = i) + \mathbb P(X = \lfloor a\rfloor, Y \le a-\lfloor a\rfloor) \\
&= \sum_{i = 0}^{\lfloor a\rfloor-1} \mathbb P(X = i) + \mathbb P(X = \lfloor a\rfloor) \cdot \mathbb P(Y \le a-\lfloor a\rfloor)
= \sum_{i = 0}^{\lfloor a\rfloor-1} \frac{\lambda^i}{i!} e^{-\lambda} + \frac{\lambda^{\lfloor a\rfloor}}{\lfloor a\rfloor!} e^{-\lambda} \cdot (a-\lfloor a\rfloor).
\end{align*} What I don't understand is: \begin{align*}
\mathbb P(X+Y \le a) = \sum_{i = 0}^{\lfloor a\rfloor-1} \mathbb P(X = i) + \mathbb P(X = \lfloor a\rfloor, Y \le a-\lfloor a\rfloor)
\end{align*} $\lfloor \cdot \rfloor$ denotes the floor function.","['uniform-distribution', 'random-variables', 'probability-theory', 'probability-distributions', 'probability']"
618192,How to solve $\sin x +\cos x = 1$?,"No matter how I do it, I always end up with $x = 0, 90, 270$ and $360$. All of those except $270$ is right, but I can't quite figure out how to get the $270$ degrees out of the answer. I've tried using trig identities, I've tried squaring both sides, but I always end up with $$2\sin x\cos x$$ which then leads me to $x = 0, 90, 270, 360$. But $$\sin (270) + \cos (270) = -1$$ so I'm doing something wrong.","['trigonometry', 'algebra-precalculus']"
618225,Reconciling the two statements,"I had just recently picked up Functional Analysis so my problem may sound trivial. But I appreciate any help. I am having trouble to reconcile the two statements (said to be true in my notes): let $B \subset$ X*, dual space of X and define $B^o$ and $B^z$ to be the set of its annihilators and pre-annihilators respectively. 1) $(B^z)^o$ is the weak* closure of $R:=$  convex hull of $B$. 2) The norm closure of spanB is  a strict subset of $(B^z)^o$. I feel one of the two is wrong because 1) seems to contradict 2). Here's my reasoning. $R$ is a subset of spanB, hence norm closure of $R$ is contained in the norm closure of spanB. But the weak* topology is contained in the weak topology of X* i.e. the smallest topology to have X** to be continuous. So weak* closure of R is weak closed implying it's also normed closed, as R is convex. So the norm closure of $R$ is in norm closure of spanB, which conflicts with 2) if 1) is true. Thank you for any clarifications.",['analysis']
618256,Double Euler sum $ \sum_{k\geq 1} \frac{H_k^{(2)} H_k}{k^3} $,I proved the following result $$\displaystyle \sum_{k\geq 1}  \frac{H_k^{(2)} H_k}{k^3} =- \frac{97}{12} \zeta(6)+\frac{7}{4}\zeta(4)\zeta(2) + \frac{5}{2}\zeta(3)^2+\frac{2}{3}\zeta(2)^3$$ After consideration of powers of polylogarithms. You can refer to the following thread . My question is : are there any papers in the literature which dealt with that result? Are my evaluations worth publishing ?,"['sequences-and-series', 'harmonic-numbers', 'real-analysis', 'polylogarithm', 'complex-analysis']"
618288,"Does $ST=TS$ with $S,T$ diagonalizable matrices imply that they share eigenspaces?","I know it's been answered before (at least to the case with $n$ different eigenvalues) but I didn't find a proof for the general case, and I would like some help with this question. We are given linear transforms $S,T: V\to V$ where $V$ is some vector space. We are given that $S$ and $T$ commute, $ST=TS$, and that they are diagonalizable: $T=PD_1P^{-1}$ and $S=KD_2K^{-1}$, where $D_1, D_2$ are diagonal and $K,P$ are invertible. We are asked to show that $S$ and $T$ have a common eigenspace. My solution Maybe I understood the question wrong, but what I tried to do is show that if $v$ is an eigenvector of $S$ then it is also an eigenvector of $T$. let $Sv=\lambda v$. $STv=TSv=T\lambda v=\lambda Tv$ which implies that $Tv$ is an eigenvector of $S$ with eigenvalue $\lambda$. Why does that mean that $v$ is an eigenvalue of $T$? Another possible way to solve this question is write: $PD_1P^{-1}KD_2K^{-1} = KD_2K^{-1}PD_1P^{-1}$ and get that $P=K$ but I don't know how to do that either.","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors', 'diagonalization']"
618317,So close yet so far Finding $\int \frac {\sec x \tan x}{3x+5} dx$,"Cruising the old questions I came across juantheron asking for $\int \frac {\sec x\tan x}{3x+5}\,dx$ He tried using $(3x+5)^{-1}$ for $U$ and $\sec x \tan x$ for $dv$while integrating by parts.  below is his work. How can I calculate
$$
\int {\sec\left(x\right)\tan\left(x\right)  \over 3x + 5}\,{\rm d}x
$$ My Try:: $\displaystyle \int \frac{1}{3x+5}\left(\sec x\tan x \right)\,\mathrm dx$ Now Using Integration by Parts:: We get $$= \frac{1}{3x+5}\sec x +\int  \frac{3}{(3x+5)^2}\sec x\,\mathrm  dx$$ Here he hit his road block. I tried the opposite tactic Taking the other approach by parts. let $$U= \sec x \tan x$$ then$$ du= \tan^2 x \sec x +\sec^3 x$$ and $$dv=(3x+5)^{-1}$$ then $$v=\frac 1 3 \ln(3x+5)$$ Thus $$\int \frac {\sec x \tan x}{3x+5}\,dx= \frac {\ln(3x+5)\sec x \tan x}{3} - \int \frac {\ln(3x+5) [\tan^2 x \sec x +\sec^3 x]}{3} \,dx$$ As you can see I got no further than he did. So how many times do you have to complete integration by parts to get the integral of the original $\frac {\sec x \tan x}{3x+5} \, dx$ or is there a better way?","['calculus', 'integration', 'indefinite-integrals', 'recreational-mathematics']"
618340,Sub-dimensional linear subspaces of $\mathbb{R}^{n}$ have measure zero.,"I would appreciate it if someone could refer me to a proof (or simply give one here) for the statement in the title. That is: If $k<n$, then every $k-$dimensional subspace of $\mathbb{R}^{n}$ has $n-$dimensional Lebesgue measure zero. I've seen some proofs that use Sard's lemma but I'm not really familiar with that subject and I've never seen a proof of said lemma so I'd appreciate a proof that doesn't use it if possible. Thanks in advance!","['vector-spaces', 'measure-theory', 'real-analysis', 'lebesgue-measure', 'geometric-measure-theory']"
618375,Morphism into a Dedekind scheme,"I am trying to solve the following exercise without using Zariski's main theorem.
Let X be an integral scheme of dimension 1 and $f:X \rightarrow Y$ a birational, separated morphism of finite type where Y is a Dedekind scheme. Show that f is an open immersion. It seems as if X was proper over Y, the case would be easier but apart from that, I can not aee what to do. Any hints / solutions are welcome!",['algebraic-geometry']
618391,If $A$ and $B$ are two disjoint non empty subsets of $\mathbb{R}^2$ such that $A\cup B$ is open....,"Question is  : If $A$ and $B$ are two disjoint non empty subsets of $\mathbb{R}^2$ such that $A\cup B$ is open in $\mathbb{R}^2$ . Then which of the following is true? If $A$ is open and $A\cup B$ is connected then $B$ must be closed in $\mathbb{R}^2$. If $A$ is closed then $B$ must be open in $\mathbb{R}^2$. If both $A$ and $B$ are connected, then $A\cup B$ must be disconnected. If  $A\cup B$ is disconnected then both $A$ and $B$ are open. I am sure that first and second bullet are correct but do not know how to make it more clear. For first bullet, Suppose $B$ is open then there is no chance of $A\cup B$ being connected though $A$ and $B$ are connected. (As $A$ and $B$ are disjoint) But $B$ being Not open does not imply $B$ being closed. So, I would not say this is a proof but i would see this can be made to a proof.(I guess it can) For second bullet, Suppose $B$ is also closed then $A\cup B$ is closed but we have given that $A\cup B$ is open. But $B$ being Not closed does not imply $B$ being open. So, I would not say this is a proof but i would see this can be made to a proof.(I guess it can) For third bullet, I can surely say that this is false. Suppose $A\cup B$ is connected then $A$ and $B$ should have a common point But $A$ and $B$ are disconnected.Thus third option is false. For fourth bullet, I think it is true.In general, $A\cup B$ being disconnected does not imply  both $A$ and $B$ are open. but we have a condition $A\cup B$ is open. I feel this would force both $A$ and $B $ to be open. I could not make this more clear. I would be thankful if someone can help me to clear this. Thank you :)",['general-topology']
618399,What is a Kählerian variety?,"I know what a Kähler manifold is, and I (roughly) know what a variety is. However, I don't know what a Kählerian variety is. Is it just a variety which is also a Kähler manifold, or is it a separate concept? Is there any distinction between affine and projective varieties in the definition of a Kählerian variety?","['algebraic-geometry', 'soft-question', 'kahler-manifolds']"
618410,"For a continuous function $f :\mathbb{R}\rightarrow \mathbb{R}$ satisfying $\int_{\mathbb{R}}|f(x)|dx<\infty$, which of the following is true?","Problem: For a continuous function $f :\mathbb{R}\rightarrow \mathbb{R}$ satisfying $$\int_{\mathbb{R}}|f(x)|dx<\infty$$ and for some $\alpha >0$ let $d_f(\alpha)$ be the Lebesgue measure of the set $$\{x\in \mathbb{R} : |f(x)|>\alpha\}$$ Then, for all $\alpha \geq 0$ which of the following is true? $\alpha d_f(\alpha)\leq \int_{\mathbb{R}}|f(x)|dx$ $\alpha^2 d_f(\alpha)\leq \int_{\mathbb{R}}|f(x)|dx$ $d_f(\alpha)\leq \alpha \int_{\mathbb{R}}|f(x)|dx$ $d_f(\alpha)\leq \alpha^2 \int_{\mathbb{R}}|f(x)|dx$ My solution: As $\alpha<|f(x)|$ on $\{x\in \mathbb{R} : |f(x)|>\alpha\}$ we have $$\int_{\{x: \alpha<|f(x)|\}}\alpha<\int_{\{x: \alpha<|f(x)|\}}|f(x)|<\int_{\mathbb{R}}|f(x)|dx$$ i.e., $$\alpha.d_f(\alpha)<\int_{\mathbb{R}}|f(x)|dx$$ So, I can see that first option is true. I belive all the other three options are not necessarily true but i could not come up with an example. Please help me to see if my argument for first bullet is sufficient/clear and help me to see other in detail. Thank you.","['measure-theory', 'real-analysis', 'analysis', 'lebesgue-integral', 'lebesgue-measure']"
618411,Embedding of elliptic curves into $\mathbb{P}^2$ by arbitrary line bundle of degree $3$,"Let $E$ be a complex elliptic curve, with distinguished point $x_0 \in E$. Any divisor of degree three is equivalent to the divisor $D=x+2x_0$. If $x=x_0$, it is well known that $L(D)$ has an explicit basis that is usually used as the standard embedding to projective plane 
$$L(D) \cong span(1, \wp, \wp'),$$ where $\wp$ is the Weierstrass function. What functions can I choose as a basis for an arbitrary $D$ of degree $3$? Of course, the Weierstrass function and constants still belong to $L(D)$, but what is the third function?","['algebraic-geometry', 'elliptic-functions', 'elliptic-curves']"
618425,Probability of number of random answers being correct.,"My teacher gave us a true-false test with 100 ""questions.""  Only there were no questions.  He had an answer key and was trying to prove that if we answered true and false questions randomly, the class average would be around 50%.  I got 7 right out of 100, so, of course, 93 wrong out of 100.  He said that he had never had a score that far from the mean. What is the probability of getting only 7 true-false questions out of 100 correct?",['probability']
618429,How prove this equation $A^2+B^2=C^2+D^2$,"define: plane $W:Ax+By+Cz+D=0$ and the 
 hyperboloid of one sheet $U:x^2+y^2-z^2=1$
if $$W\bigcap U=l_{1},W\bigcap U=l_{2}$$ where $l_{1},l_{2}$ be two  straight lines show that :$$A^2+B^2=C^2+D^2$$ My try: since
  $$\begin{cases}
Ax+By+Cz+D=0\\
x^2+y^2-z^2=1
\end{cases}$$
  then
  $$(Ax+By+D)^2=C^2(x^2+y^2-1)$$
  then
  $$(A^2-C^2)x^2+(B^2-C^2)y^2+2ABxy+2BDy+2ADx+D^2+C^2=0$$ Follow is user44197 idea
$$(A^2-C^2)x^2+(2ABy+2AD)x+(B^2-C^2)y^2+D^2+C^2=0$$
$$\Delta (y)=(2ABy+2AD)^2-4(A^2-C^2)[(B^2-C^2)y^2+D^2+C^2]$$
$$\Delta=4A^2B^2y^2+8A^2BDy+4A^2D^2-4(A^2B^2-A^2C^2-B^2C^2+C^4)y^2-4(A^2D^2+A^2C^2-C^2D^2-C^4)$$
so
$$\Delta(y)=4[C^2(A^2+B^2-C^2)y^2+2A^2BDy+C^2(C^2+D^2-A^2)]$$
then I can't.Thank you very much!",['geometry']
618438,Lipschitz-continuous $f(x)=x^2\cdot \sin\left(\frac{1}{x}\right)$,"How to prove that $f$ is globally
Lipschitz-continuous $$ f:\mathbb{R}\longrightarrow \mathbb{R}$$ $$ f(x) = \left\{ 
  \begin{array}{c l}
    x^2\cdot \sin\left(\frac{1}{x}\right) & ,\quad x\neq0\\
    0 & ,\quad x=0
  \end{array} \right.$$ Any hints would be appreciated.","['lipschitz-functions', 'holder-spaces', 'real-analysis']"
618443,Pre-College Maths Textbooks [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Questions about choosing a course, academic program, career path, etc. are off-topic. Such questions should be directed to those employed by the institution in question, or other qualified individuals who know your specific circumstances. Closed 7 years ago . Improve this question I am a high school student searching for some mathematics books covering material all the way up to, but not including, college level mathematics. I have already read Gelfand's books and Lang's Basic Mathematics, and enjoyed them thoroughly. Yet I do not feel I have thoroughly mastered all facets of high school maths, and would like to do so before moving on. Are there any other books that it could be beneficial for me to study at this stage?","['geometry', 'trigonometry', 'algebra-precalculus', 'reference-request']"
618471,Cauchy integral formula problem,"Let $C$ be the unit circle centered at the origin and $a \in \mathbb{R}$. $$\int_0^{2\pi}\frac{dt}{1 + a^2 - 2a\cos(t)} = \int_C \frac{i\;dz}{(z-a)(az-1)}$$ Use Cauchy's integral formula to deduce if $0 \leq a < 1$ then, $$\int_0^{2\pi}\frac{dt}{1 + a^2 - 2a\cos(t)} = \frac{2\pi}{1 - a^2}$$ I was unsure how to go about the first part. I could just try to compute both integrals and show they are equal but that doesn't seem to be what is wanted. Is there is a trick that I am missing? As for the second part, I keep getting $0$. I use the first part, and see there are singularities at $z = a$ and $z = 1/a$. If $a < 1$ then the singularities lie within $C$ and Cauchy's integral formula can be used. I think I can split the integral into two, where I take $1 / (z - a)$ to be my function and evaluate the integral around a circle centered at $1/a$, and vice versa take $1/(az - 1)$ to be my function and evaluate the integral around a circle centered at $a$. Many thanks.","['integration', 'complex-analysis']"
618478,How many permutations of the letters in the word MISSISSIPPI are palindromes?,"How many of permutation of letters in  the word "" $\bf{MISSISSIPPI}$ "" are palindromes? $\text{My Try}:$ Palindrome is a word which read as  same forwards and backwards. Here word "" $\bf{MISSISSIPPI}$ "" contain $\bf{4I\;,4S\;,2P}$ and $\bf{1M}$ . So total $11$ letters. So must be in the form of $-----M-----$ , so we put $\bf{2I\;,2S\;,1P}$ on left of $M$ , which can be done as $\displaystyle =\frac{5!}{2!\times 2!\times 1} = 30$ . But I did not understand how can we not permute $\bf{2I\;,2S\;,1P}$ on right of $M$ ?","['palindrome', 'combinatorics']"
618480,What is the definition of a measurable set?,"I have seen multiple definitions for what a measurable set is (all of which come together to form a sigma algebra). I was wondering if they are all equivalent and if not what situation would one be used over another? Definition 1 Let $(X, \Sigma)$ be a measurable space, then any set $S \in \Sigma$ is a measurable set. Measurable Space: The pair $(X, \Sigma)$ where $X$ is a set and $\Sigma$ is a $\sigma$ -algebra on $X$ Definition 2 Given a space $X$ let there exist an outer measure $\mu : 2^{X} \to [0, \infty]$ (where $2^{X} = \mathcal{P} \left( X \right) = $ all the subsets of $X$ ) then a set $S$ is measurable iff for every $A \in 2^{X}$ $$
\mu(A) = \mu(A \cap S) + \mu(A \cap S^{c}) = \mu(A \cap S) + \mu(A \setminus S)
$$ Definition 3 (I'm drawing this one from memory from baby rudin, and it's defined on $\mathbb{R}$ ) Begin by defining a (outer $_1$ ) measure $\mu$ . Next put $\mathcal{M}_f$ to be the set of countable unions of intervals. Then a set $S$ is measurable iff $$
\exists \{ S_n \}_{n=0}^{\infty} \, s.t. \mu(S_n) \to \mu(S) \text{ as } n \to \infty
$$ Now I know that the sets described in definition 2 form a sigma algebra on $X$ , and likewise I know the sets $S$ in definition 3 form a sigma algebra on $\mathbb{R}$ , but definition 1 seems to imply that any possible sigma algebra can be used. In definition 3 I cannot remember if he defines this using the outer measure (I believe he does). The only conclusion I have been able to draw from this is definition 2 and 3 must be equivalent, but we call these sets $\boldsymbol\mu$ -measurable (a specific measure is defined). However in definition 1 we call any set like that just measurable, and that given any sigma algebra $\Sigma \, \exists \mu$ an outer measure s.t. the sigma algebra formed by definition 2 with this outer measure is $\Sigma$ . Is this correctly put?","['measurable-sets', 'measure-theory', 'analysis']"
618491,Distribute n identical objects into r distinct groups,"Is there a separate formula for calculating distribution of n identical objects into r distinct groups? I read this particular concept in a book but did not understand it. Any help would be thoroughly appreciated. Also, what exactly do u mean by distinct groups? Does that mean that the groups differ on the basis of no of objects they contain? Or, if u think of groups as boxes, does it mean the boxes itself are different regardless of no of objects in them? EDIT : How would the answer differ if instead of distinct groups/boxes, we have identical groups/boxes?",['combinatorics']
618496,"$A \subset \mathbb{R} $ is measurable, prove that $-A=\{x : -x \in A\}$ is measurable.","$A \subset \mathbb{R} $ is measurable, prove that $-A=\{x : -x \in A\}$ is measurable. It is more than obvious that $-A$ is measurable, but I am sure that I am not supposed to say :""$-A$ is just $A$ displaced on the real line"". My Question is : if I show that for each $\epsilon > 0$ there exists an open set $O$ containing $-A$ such that $m(O \setminus -A) < \epsilon$, does this imply that $-A$ is measurable ?","['measure-theory', 'real-analysis', 'analysis', 'lebesgue-integral', 'lebesgue-measure']"
618509,Differentials Definition,"Please define differentials rigorously such that they give a consistency to their use in the following links. I have read Is $\frac{\textrm{d}y}{\textrm{d}x}$ not a ratio? What is the practical difference between a differential and a derivative? Differential of a function at Wikipedia. If $\frac{dy}{dt}dt$ doesn't cancel, then what do you call it? Leibniz's notation at Wikipedia. Exact differential equation at Wikipedia. Moment of inertia at Wikipedia. Center of mass at Wikipedia, etc.","['differential', 'ordinary-differential-equations', 'calculus']"
618539,Prove that $M$ is a free module if and only if $M$ is a projective module over $PID$.,Let $R$ be a principal ideal domain and $M$ a finitely generated $R$ module. Prove that $M$ is a free $R$-module if and only if $M$ is a projective $R$-module. I am quite confused and totally not clear about projective modules defined by the universal lift property in commutative diagram.,"['ring-theory', 'projective-module', 'abstract-algebra', 'principal-ideal-domains', 'modules']"
618550,Showing convergence of a series,"Let $a_0,a_1\in\mathbb{R}$,$a_n=a_{n-1}-\cfrac{2}{n}a_{n-2}$ for $n\ge2$. How to show $\sum_0^\infty|a_n|<\infty$","['sequences-and-series', 'calculus', 'real-analysis', 'limits']"
618573,"Does the union of all these neighborhood cover $[0,1]$","Consider the rationals in $[0,1]$. Around each I take a neighborhood (possibly of different radii). Is the union of all these neighborhood sure to cover $[0,1]$? What if I had used irrationals instead of rationals?","['general-topology', 'compactness', 'analysis']"
618583,Does this type of functions exist [duplicate],This question already has answers here : No continuous function switches $\mathbb{Q}$ and the irrationals (4 answers) Closed 10 years ago . Does there exist a cont function $f$ : $\mathbb{R}$ $\rightarrow$$\mathbb{R}$  which takes irrational values at rational points and rational values at irrational points?,"['connectedness', 'analysis']"
618604,"Solvable and nilpotent groups, normal series and intuition","I'm reading Hungerford's algebra and I'm on Nilpotent and solvable groups chapter. Hungerford starts with: Consider the following conditions on a finite group G: i)   G is the direct product of its Sylow subgroups ii)  If m divides |G|, then G has a subgroup of order m iii) If |G| = mn with (m,n) = 1, then G has a subgroup of order m This chapter comes after Sylow theorems, where we have seen that if $|G| = p_1^{\alpha_1}p_2^{\alpha_2} \dotsm p_n^{\alpha_n}$ there is a subgroup of order $p_i^k$ for $k \in \{0, 1, ..., \alpha_i\}$, but we can't guarantee more (take for an example $A_4$, it has subgroups of order 3 and 4, but there is no subgroup of order 6).
So the question What kind of groups have nice subgroup structure? isn't that unexpected. What was unexpected? We shall first define nilpotent and solvable groups in terms of certain 
     ''normal series''of subgroups. In case of finite groups, nilpotent groups are   characterized by condition i) and solvable ones by condition iii). Hungerford first gives definition of nilpotent groups in terms of ascending central series and definition of solvable groups in terms of commutator subgroups and then proves equivalences with i) and iii). Conceptual jump between i), ii), iii) and definitions involving normal series is a little too big for me. I can't really see how someone could start thinking about i), ii), iii) and come out with normal series.
I don't have a nice way to think about them and I would really be thankful if someone has a nice conceptual view about them, or several eye-opening exercises.","['solvable-groups', 'sylow-theory', 'group-theory', 'soft-question', 'intuition']"
618616,When are generalized Severi-Brauer varieties trivial?,"Let $F$ be a field and $A$ be an $F$-central simple algebra of degree $n$. Let $0< k< n$ and let $SB_k(A)$ denote the generalized Severi-Brauer variety: if $E/F$ is a field extension, $SB_k(A)(E)$ consists of the right ideals of dimension $kn$ of $A_E=A\otimes_F E$. If $A$ is split, i.e. $A\simeq M_n(F)$, then $SB_k(A)=Gr(k,n)$, the Grassmannian. Is the converse true? If not, can you provide a counterexample? The result is true if $k=1$, since $SB_k(A)$ has a rational point over $F$ iff the index of $A$ divides $k$, and Grassmannians have rational points over $F$. I've crossposted the question to MO: https://mathoverflow.net/questions/153150/when-are-generalized-severi-brauer-varieties-grassmannians","['algebraic-geometry', 'algebras', 'abstract-algebra']"
618654,"Prove that in a quadrilateral, the lines joining the midpoints of the opposite sides and the midpoints of the diagonals are concurrent","Prove that in a quadrilateral, the lines joining the midpoints of the opposite sides and the midpoints of the diagonals are concurrent. We construct an arbitrary quadrilateral $ABCD$ with $E, F, G$ as the midpoints of $AB, BC, CD$. Let $H, I$ be the midpoints of $AC, BD$. Let $EG, HI$ intersect at $J$. Let the line joining $F, J$ meet $AD$ at $K$. We will prove that $K$ is the midpoint of $DA$. Joining $KG, GF, FE, EK$, it quickly becomes clear that the above is only true if $KGFE$ is a parallelogram, which in turn, is only true if $EJ = JG, KJ = JF$. Proving the first equality is easy. In $\Delta ABC, EH || BC, 2\cdot EH = BC$. Likewise, in $\Delta DBC, IG || BC, 2\cdot IG = BC$. Therefore, $IG||EH, IG=EH$. Therefore, $EHGI$ is a parallelogram and $EJ = JG$. Even after numerous efforts I wasn't able to prove the second equality. I noticed that this was because I was not utilizing the fact that $F$ is the midpoint of $BC$ and that $FK$ is the straight line. So, to utilize those facts, I considered $\Delta HKJ, \Delta JFI$. Proving these are congruent will prove our conjecture. Now, we can use the fact that $FK$ is a straight line by saying, that $\angle HJK = \angle IJF$. Also, since $EHGI$ is a parallelogram, $HJ = JI$. Now we need only one more equivalence to prove congruency. I wasn't able to find this. A way to utilize the fact that $F$ is the midpoint of $BC$ is by noticing that $EHCF, IGFC, AHFE, FIDG$ are all parallelograms. I have, however, no idea how to use these in the proof. I think I'm forgetting something. Because in each approach I take, there is always a single piece that is missing. If anybody could point out what this 'piece' is, I would be grateful. I would appreciate solutions that are related to the approaches described above.",['geometry']
618657,Unique factorization of ideals?,"Is it case that even if the domain is not UFD for its elements, the domain is UFD for ideals. I mean can we uniquely factorize the ideals, whatsoever? Is that possible, and why? For example, in $\mathbb{Z}[\sqrt{-14}]$, can we factorize: $\langle 30\rangle = \langle 2 \rangle \langle 3 \rangle \langle 5 \rangle$? Thanks.","['algebraic-number-theory', 'abstract-algebra']"
618661,Solutions for $\frac{3}{x+1}\le\frac{2}{2x+5}$,Im in search of the solutions for: $$\frac{3}{x+1}\le\frac{2}{2x+5}$$ So first i tried to combine the two sites: $$\frac{6x + 15 - 2x + 2}{2x^2 +7x + 5}\le{0}$$ $$\frac{4x + 17}{2x^2 +7x +5}\le{0}$$ My problem is that now i have two solutions for the denominator and i dont know how to continue: $2x^2+7x+5 = -1 \text{ and } -2.5$ The solution should be: $(-2.5;-1) \cup (-\infty;-3.25)$,"['inequality', 'algebra-precalculus']"
618674,"How prove $E|X|^p<\infty$ and $E|Y|^p<\infty$, if $E|X+Y|^p<\infty$","Let two random variables $X$ and $Y$ be independent of each other, for some $p>0$ , we have $$E|X+Y|^p<\infty$$ Show that $$E|X|^p<\infty,\quad E|Y|^p<\infty$$ My try: I know Minkowski inequality $$E|X+Y|^p \leq E|X|^p + E|Y|^p, \tag{$0<p<1$}$$ But this inequality here is not useful, so how prove it? Thank you very much!","['probability-theory', 'inequality', 'expected-value']"
618714,Does uniform integrability plus convergence in measure imply convergence in $L^1$?,"Does uniform integrability plus convergence in measure imply convergence in $L^1$? I know this holds on a probability space. Does it hold on a general measure space? I have tried googling. It returned very few results on UI on measure spaces, and none of them mentioned a result like the one in the title. This comes from a discussion about another question. The proof i have seen for a probability space breaks for a general measure space. By UI, i mean
$\sup_{f}\int_{|f|>h} |f|d\mu $ goes to $0$ as $h$ goes to infinity.","['lebesgue-integral', 'measure-theory', 'convergence-divergence', 'uniform-integrability']"
618739,Limit n tends to infinity,"How can i solve this:
$$
\lim_{n\to\infty} \cos(1)\cos(0.5)\cos(0.25)\ldots \cos(1/2^n)
$$ I tried using comlex numbers and logarithms but did'nt work out.Can anyone help please.","['trigonometry', 'complex-numbers', 'calculus', 'limits']"
