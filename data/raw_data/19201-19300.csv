question_id,title,body,tags
159713,Solve $y' = x + y$,I am suppose to use the substitution of $u = x + y$ $y' = x + y$ $u(x) = x + y(x)$ I actually forget the trick to this and it doesn't really make much sense to me. I know that I need to get everything in a variable with x I think but I am not sure how to manipulate the problem according to mathematical rules that will make sense. Also I know that at some point I will get an integral or something and that I have no idea how to do that with multiple variables.,"['ordinary-differential-equations', 'calculus', 'integration']"
159722,Find the vertical and horizontal asymptotes of the function.,"I am asked to find the vertical and horizontal asymptotes of the equation: $$f(x)=(a^{-1}+x^{-1})^{-1}$$ I simplify this to $$f(x)=\frac{1}{a^{-1}+x^{-1}}$$
$$f(x)=a^1+x^1$$$$f(x)=a+x$$Which is some constant, graphed as horizontal line - that will not have a vertical or horizontal asymptote. Is my algebra terribly off?",['algebra-precalculus']
159745,$\mathrm{Aut}(\mathbb P)$ is isomorphic to $\mathrm{ Aut} (k(t) )$,"$\def\Aut{\mathrm{Aut}}$I want to prove that the automorphism group of $\mathbb P^1$ it's isomorphic with the Moebius transformation with coefficients over the obvious field. I proved that the automorphism of $k(t)$ are of this form, If I prove that:
 $$\Aut(\mathbb P)\text{ is isomorphic to }\Aut (k(t) )$$
I'll be done. How can I do it, only using basic facts?","['projective-space', 'algebraic-geometry']"
159746,"A complex map with ""bounded"" derivative is injective","The exercise I try to solve states: ""Let $\,f\,$ be analytic in $\,D:=\{z\in\mathbb{C}\;|\;|z|<1\}\,$ , and such that $$|f'(z)-1|<\frac{1}{2}\,\,\,\forall\,z\in D$$ Prove that $\,f\,$ is $\,1-1\,$ in $\,D\,$. My thoughts: The condition $$|f'(z)-1|<\frac{1}{2}\,\,\,\forall\,z\in D$$ means the range of the analytic function $\,f'\,$ misses lots of points on the complex plane, so applying Picard's Theorem (or some extension of Liouville's) we get that $\,f'(z)=w=\,$ constant, from which it follows that $\,f\,$ is linear on $\,D\,$ and thus $\,1-1\,$ there. Doubts: $\,\,(i)\,\,$ This exercise is meant to be from an introductory first course in complex functions, so Picard's theorem seems overkill here...yet I can't see how to avoid it. $\,\,(ii)\,\,$ Even assuming we must use Picard's Theorem, the versions of it I know always talk of ""entire functions"", yet our function $\,f\,$ above is analytic only in the open unit disk. Is this a problem? Perhaps it is and thus something else must be used...? Any help will be much appreciated.",['complex-analysis']
159752,Proof about $z\cot z=1-2\sum_{k\ge1}z^2/(k^2\pi^2-z^2)$,"In Concrete Mathematics , it is said that
$$z\cot z=1-2\sum_{k\ge1}\frac{z^2}{k^2\pi^2-z^2}\tag1$$
and proved in EXERCISE 6.73
$$z\cot z=\frac z{2^n}\cot\frac z{2^n}-\frac z{2^n}\tan\frac z{2^n}+\sum_{k=1}^{2^{n-1}-1}\frac z{2^n}\left(\cot\frac{z+k\pi}{2^n}+\cot\frac{z-k\pi}{2^n}\right)$$
The trigonmetric identity is not hard, but I cannot understand the rest: It can be shown that term-by-term passage to the limit is justified, hence equation (1) is valid. How can we conclude that? Thanks for help!","['trigonometry', 'sequences-and-series', 'real-analysis']"
159759,"Given a cubic function, and its quadratic derivative- can I recover the cubic from quadratic?","Background: I'm trying to learn how to work with cubic and quadratic bezier splines for various drawing libraries, and working through how to approximate a cubic spline with a quadratic spline. It's occured to me that it should be possible to approximate any continuous parametric function with an arbitrary series of interconnected quadratic splines, as long as you have a suitable fitness function for each section. It has further occured to me that the derivative of any cubic spline is expressible as a quadratic spline. So now I am curious. if I have an abitrary function f(t);
its derivative f'(t);
and I can approximate f'(t) with a series of quadratic splines...
can I have some way of assuming those quadratics as derivatives of cubics, and directly compute a series of cubics that then approximates f(t) from the quadratics? is there something wrong with my reasoning here? (edited for brevity) (clarification)
I mentioned I was working through how to approximate a cubic spline with a quadratic spline. Let us assume for the purposes of this question that I have already solved this problem, and I have a procedure P which takes any arbitrary function f(t) (which could be a cubic spline, or anything else) with the constraint that we will only approximate over intervals where f'(t) is continuous. The question therefore is not how do I approximate a cubic with a quadric but, given that I have procedure P, if I apply procedure P to f'(t) to compute a series of quadratic splines, can I use that information to recover a cubic spline approximation of f(t). From the answers, if I am understanding corrrectly,  I think that I can so long as I can still use f(t) to recover this ""integral constant"". This is an acceptable solution since what I want is something like a procedure P2 which can take a f(t) and give me a sequence of cubic splines which approximate it. edit: further, it seems that if we have f(t) and its f'(t) and its f''(t) we could even do a straight forward linear approximation of f''(t) and recover a cubic spline approximation of f(t) by solving for the integral constants in f'(t) and f(t).
neat.","['quadratics', 'spline', 'derivatives', 'numerical-methods']"
159769,How to calculate a linear transformation given its effect on some vectors,"Im not sure if my question is worded very well, but I'm having trouble understanding how to tackle this problem. Let $T\colon\mathbb{R}^3\to\mathbb{R}^2$ be the linear transformation such that $T(1,-1,2)=(-3,1)$ and $T(3,-1,1) = (-1,2)$. Find $T(9,-1,10)$. Thanks",['linear-algebra']
159775,$f$ closed iff $y\in N$ and open $V\supset f^{-1}\left(\{y\}\right)$ exists $U$ open such that $V\supset f^{-1}(U)\supset f^{-1}(\left\{y\right\})$,Prove that $f\colon M\to N$ (topological spaces) is closed if and only if for all $y\in N$ and all open sets $V\supset f^{-1}\left(\{y\}\right)$ in $M$ there exists an open set $U$ in $N$ containing $y$ such that $V\supset f^{-1}(U)\supset f^{-1}(\left\{y\right\})$. I can't prove this in any way. I tried for 3 days.,['general-topology']
159787,Topology needed for differential geometry,"I am a physics undergrad, and need to study differential geometry ASAP to supplement my studies on solitons and instantons. How much topology do I need to know? I know some basic concepts reading from the internet on topological spaces, connectedness, compactness, metrics and quotient hausdorff spaces. Do I need to go deeper? Also, could you suggest me some chapters from topology textbooks to brush up this knowledge? Could you please also suggest a good differential geometry books that covers the topics in differential geometry that are needed in physics in sufficient detail (without too much emphasis on mathematical rigour)? I have heard of the following textbook authors: Nakhara, Fecko, Spivak. Would you recommend these?","['general-topology', 'soft-question', 'reference-request', 'differential-geometry']"
159801,"Characterizing all ring homomorphisms $C[0,1]\to\mathbb{R}$.","This is something I've been trying to work out this evening. Let $R$ be the ring of continuous real-valued functions on $[0,1]$ with pointwise addition and multiplication. For $t\in [0,1]$, the map $\phi_t\colon f\to f(t)$ is a ring homomorphism of $R$ to $\mathbb{R}$. I'm trying to show that every ring homomorphism of $R\to\mathbb{R}$ has this form. Suppose otherwise, that there is some $\phi\neq\phi_t$, and thus there is some $f_t\in R$ such that $\phi(f_t)\neq \phi_t(f_t)=f_t(t)$. Define $g_t=f_t-\phi(f_t)1\in R$. Here $\phi(f_t)1$ is the constant function sending $[0,1]$ to $\phi(f_t)$. Then $g_t(t)\neq 0$. My first small question is why does $\phi(g_t)=0$? It seems only that $\phi(g_t)=\phi(f_t)-\phi(\phi(f_t)1)$. I would like to conclude that there are only finitely many $t_i$ such that $g(x)=\sum g_{t_i}^2(x)\neq 0$ for all $x$. Then $g^{-1}=1/g(x)\in R$, but $\phi(g)=0$, contradicting the fact that homomorphisms map units to units. How can we be sure there are only finitely many $g_{t_i}$ such that the sum of their squares is never $0$? Thanks.","['ring-theory', 'abstract-algebra']"
159810,When are two norms equivalent on a Banach space?,"I'm working on an exercise from functional analysis. Let $E$ be a vector space and $\|\cdot\|_1$ and $\|\cdot\|_2$ be two complete norms on $E$. Now suppose that $E$ satisfies the following property: $\bullet$ if $(x_n)$ is a sequence in $E$ and $x,y\in E$ such that $\|x_n-x\|_1\to 0$ and $\|x_n-y\|_2\to 0$, then $x=y$. Now we want to show that the norms $\|\cdot\|_1$ and $\|\cdot\|_2$ are equivalent. My idea is as follows:
If for any $n>0$, there is an element $x_n\in E$ such that $\|x_n\|_1>n\|x_n\|_2$. Then consider $(\frac{x_n}{\|x_n\|_1})_{n\geq 1}$. Clearly, $(\frac{x_n}{\|x_n\|_1})_{n\geq 1}$ converges to $0$. However, I cann't get a contradicition from this. Maybe my idea is wrong. In fact, I even don't konw how to show that a Cauchy sequence in norm $\|\cdot\|_1$ is also a Cauchy sequence in norm $\|\cdot\|_2$. Anyone can give me some hints or a counter example? Thank you very much.",['functional-analysis']
159820,Question about a proof in Evans,"On page 57. in Partial Differential Equation by Lawrence C. Evans, he prove the maximum principle for the Cauchy problem of the heat equation, i.e. (I quote) Suppose $u\in C^2_1(\mathbb{R}^n\times (0,T])\cap C(\mathbb{R}^n\times [0,T])$ solves $u_t-\Delta u= 0$ in $\mathbb{R}^n\times (0,T)$ and $u=g$ on $\mathbb{R}^n\times \{t=0\}$. Moreover, u satisfies the growth estimate $$u(x,t)\le Ae^{a|x|^2}$$ for $x\in\mathbb{R}^n,0\le t\le T$ for constants $A,a>0$. Then $$\sup_{\mathbb{R}^n\times [0,T]}u = \sup_{\mathbb{R}^n}g$$ In the proof they define $v(x,t):=u(x,t)-\frac{\mu}{(T+\epsilon -t)^\frac{n}{2}}\exp{\frac{|x-y|^2}{4(T+\epsilon -t)}}$
The proof consists of several steps. First they show for $4aT<1$ that $\max_{\overline{U_T}} v= \max_{\Gamma_T}v$, where $U_T:=B^0(y,r)\times (0,T]$ for fixed $r>0$. If $x\in \mathbb{R}^n$ then $v(x,0)\le g(x)$ Now in equation $(29)$ they say: for $r$ selected sufficiently large, we have $v(x,t)\le A\exp{a(|y|+r)^2}-\mu (4(a+\gamma))^{\frac{n}{2}}\exp{(a+\gamma)r^2}\le \sup_{\mathbb{R}^n}g$. Why is this all less or equal the supremum of $g$, for large $r$? And why can we conclude with all these facts, that $v(y,t)\le \sup_{\mathbb{R}^n} g$ for all $y\in \mathbb{R}^n$ and $0\le t\le T$?","['partial-differential-equations', 'real-analysis']"
159836,$\int_{0}^{\infty} \frac{e^{-x} \sin(x)}{x} dx$ Evaluate Integral,"Compute the following integral: $$\int_{0}^{\infty} \frac{e^{-x} \sin(x)}{x} dx$$ Any hint, suggestion is welcome.","['improper-integrals', 'calculus', 'integration', 'limits']"
159848,"Differentiability of $(x,y)\mapsto|x|\cdot y$","Check the differentiability of the function $f:\mathbb{R}^2\rightarrow \mathbb{R}$ of two variables given by the formula $$f(x)=|x_1|\cdot x_2$$ I still have problems with this. I started by trying to count partial derivatives: $\displaystyle\frac{\partial f}{\partial x_1}(x)=\lim_{h\to 0}\frac{f(x_1+h,x_2)-f(x_1,x_2)}{h}=\lim_{h\to 0}\frac{|x_1+h|x_2-|x_1|x_2}{h}$, so I think the problems can be at the points: $(0,x_2)$, where $x_2\neq 0$, because then we have that this limit is equal to $\displaystyle\lim_{h\to 0}\frac{|h|x_2}{h}$ which doesn't exist (left and right limits are not equal). $\displaystyle\frac{\partial f}{\partial x_2}(x)=\lim_{h\to 0}\frac{f(x_1,x_2+h)-f(x_1,x_2)}{h}=\lim_{h \to 0}\frac{|x_1|(x_2+h)-|x_1|x_2}{h}=|x_1|$, so I think we haven't any problems here, this partial derivative always exists. But what exactly can we deduce from these speculations about partial derivatives? I've also tried to proudly find the differential of this function. I was taught that the function is differentiable at the point $x$ iff there exists (if there exists, there is only one) a linear mapping $L$ such that  $(*)\displaystyle\lim_{h\to 0}\frac{f(x+h)-f(x)-L(h)}{\|h\|}=0$. Then we say that $Df(x)=L$ is a differential of function $f$ at the point $x$. For example consider function $g:\mathbb{R}^2\rightarrow \mathbb{R}, \ g(x)=x_1\cdot x_2$. We can find differential of this function by looking at the increment of this function: $g(x+h)-g(x)=(x_1+h_1)(x_2+h_2)-x_1x_2=x_1h_2+x_2h_1+h_1h_2$ . Then the candidate for $Df(x)$ is linear part of this increment: $L(h)=x_1h_2+x_2h_1$. When we check $(*)$ it appears that indeed it is a desired differential. But in my example: $f(x+h)-f(x)=|x_1+h_1|(x_2+h_2)-|x_1|x_2$ I'm confused, it seems hard. Do I have to consider a few cases depending on a sign of $x_1,  \ x_2$ ? Can anybody make it clear for me? It is really important to me to finally understand this topic.","['derivatives', 'real-analysis']"
159860,Does this multivariate function have only one maximum?,"Let $X_1$ and $X_2$ be random variables (not of the same distribution and not independent). Both have a zero probability of being below $-1$. Their joint density is $\rho(x_1,x_2)$. Also, they both have finite expectations. Now, define the region $A = \{ (t_1,t_2)\in\mathbb{R}^2 \mid 0\le t_1,t_2<1  \text{ and }t_1+t_2<1  \}$, and define the function $f:A\to\mathbb{R}$ with $$f(t_1,t_2) = \int_{-1}^\infty\int_{-1}^\infty \log(1+t_1x_1+t_2x_2)\rho(x_1,x_2)\,dx_1dx_2.$$ Can we say something interesting about $f$? For example, does $f$ have at most only one local maximum?","['multivariable-calculus', 'calculus', 'probability']"
159862,Euler's product formula for $\sin(\pi z)$ and the gamma function,"I want to derive Euler's infinite product formula $$\displaystyle \sin(\pi z) = \pi z \prod_{k=1}^\infty \left( 1 - \frac{z^2}{k^2} \right)$$ by using Euler's reflection equation $\Gamma(z)\Gamma(1-z) \sin(\pi z) = \pi$ and the definition of $\Gamma(z)$ as an infinite product, namely $$\displaystyle \Gamma(z) := \frac{1}{z} \prod_{k=1}^\infty \frac{(1+\frac{1}{k})^z}{1+\frac{z}{k}}.$$ To be precise, I obtain that $$\sin(\pi z) = \pi z(1-z) \left( \prod_{k=1}^\infty \frac{1+\frac{z}{k}}{(1+\frac{1}{k})^z} \right) \left( \prod_{k=1}^\infty \frac{1+\frac{1-z}{k}}{(1+\frac{1}{k})^{1-z}} \right)$$ hence I wish to prove $$(1-z) \left( \prod_{k=1}^\infty \frac{1+\frac{z}{k}}{(1+\frac{1}{k})^z} \right) \left( \prod_{k=1}^\infty \frac{1+\frac{1-z}{k}}{(1+\frac{1}{k})^{1-z}} \right) = \prod_{k=1}^\infty \left( 1 - \frac{z^2}{k^2} \right).$$ I multiplied things out and got it to the form $$(1-z) \prod_{k=1}^\infty \frac{1 + \frac{1}{k} + \frac{z(1-z)}{k^2}}{1 + \frac{1}{k}} = (1-z) \prod_{k=1}^\infty \left( 1 + \frac{\frac{z(1-z)}{k}}{1+\frac{1}{k}}\right)$$ however the $(1-z)$ factor out front is giving me some trouble; I'm not sure how to proceed.","['gamma-function', 'special-functions', 'complex-analysis']"
159863,Automorphisms of the field of complex numbers,"Using AC one may prove that there are $2^{\mathfrak{c}}$ field automorphisms of the field $\mathbb{C}$. Certainly, only the identity map is $\mathbb{C}$-linear ($\mathbb{C}$-homogenous) among them but are all these automorphisms $\mathbb{R}$-linear?","['ring-theory', 'abstract-algebra', 'field-theory']"
159875,Regarding Legendre transform from tangent bundle to cotangent bundle,"( I'm a complete beginner at differential geometry ) I'm studying about constrained systems, in which we ""map a Lagrangian system from a tangent to a cotangent bundle. Hamiltonian dynamics then appears as image dynamics via the Legendre map which is degenerate. A study of image of (hamiltonian) dynamics is possible if the Legendre map has constant rank."" More specifically from what I've (barely) understood, we have a configuration space $(q_1, ..., q_n, v_1, ..., v_n)$ or $(q, v)$ in short, where $v_i = dq_i/dt$, the config space being regarded as tangent bundle. Now we perform a legendre transform of lagrangian $L$. We obtain a map from the TB to the cotangent bundle $(q, p)$, where $p_i = ∂L/∂v_i$. Now the rank of the Hessian matrix $∂L/(∂v_i∂v_j)$ is supposed to determine some property of the image of the map in the cotangent bundle, which I can't understand (intuitively I think it determines the image as a subset of the cot bundle, but that's a vague idea). For me to better understand this, could someone please point out Broadly which area in differential geometry deals with this (is it symplectic geometry?) Which theorem(s)/result(s) precisely deals with whatever I've stated above (nature of Legendre transform and relation of rank of that Hessian matrix to the image in cotangent bundle) Which book on differential geometry would be recommended that also treats the same area that I've asked about in 1., and also would be good as a first reading I'm anyway going to study differential geometry, but only from the view of using it in higher-level Physics. So it would be highly helpful if it could further be mentioned which part/sections of the recommended book(s) I would have to read (ones that have applications in Physics) Thanks in advance","['differential-topology', 'symplectic-geometry', 'differential-geometry']"
159876,What is the length of a maximal deranged sequence of permutations,"We were playing a home-made scribblish and were trying to figure out how to exchange papers.  During each round, you'll trade k times and each time you need to give your current paper to someone who has never had it, and you need to receive a paper that you've never had. There are n papers.    For example, if everyone passes their paper to the left, then you can trade $n-1$ times, and on the $n$th trade everyone gets their papers back.  Clearly $k < n$ no matter how you trade. It is suboptimal for one player to always trade with the same player, so we want to use different permutations each time.  When writing a webpage to choose permutations randomly, I ran into a theoretical problem: if we don't know k , can we still generate a good sequence of shuffles? As long as any good sequence of shuffles can be extended to a maximal sequence, we are ok. For n ≤ 6 this is true.  Is it true in general? For n a positive integer, call a sequence of permutations $g_i \in S_n$ deranged if $\prod_{i=a}^b g_i$ has no fixed points on $\{1,\dots,n\}$ for any $1 \leq a\leq b \leq k$, where $k$ is the length of the sequence. Must every maximal deranged sequence have $k=n-1$? A deranged sequence of length 1 is just called a derangement . We partial order deranged sequences by $a \leq b$ if $a$ is an initial segment of $b$, so that $(1,2,3,4,5) \leq (1,2,3,4,5), (1,2,3,4,5) \leq (1,2,3,4,5), (1,2,3,4,5), (1,3,5,2,4)$.  Hence a deranged sequence $g_1, \dots, g_k\in S_n$ is maximal iff for every $g_{k+1} \in S_n$, the sequence $g_1, \dots, g_k, g_{k+1}$ is not deranged. Examples: In order to make the problem more symmetrical, it can be helpful to append $g_{k+1} = (g_1 \cdots g_k)^{-1}$ to the sequence.  This corresponds to a final step of ""handing everyone back their original paper."" Then every consecutive $k-1$ subsequence of every cyclic permutation has the property that it is deranged.  Thus these deranged ""cycles"" of length $k+1$ are acted on both by $S_n$ (relabeling the people) and by $C_{k+1}$ (cyclic permutations).  This can help reduce the number of truly distinct examples. For two players, obviously you just pass it to each other and it is over. (1,2) [ add (1,2) to complete the cycle ] For three players, you can either pass clockwise twice or counterclockwise twice. (1,2,3), (1,2,3) [ add (1,2,3) to complete the cycle ] (1,3,2), (1,3,2) [ this is the previous one with players 2 and 3 swapped ] For four players, there are 24 deranged sequences, but after completing them to deranged cycles, there are only 3 distinct orbits under $S_n$ and $C_{k+1}$. Notice that $k+1=n$ in each case: (1,2)(3,4), (1,3)(2,4), (1,2)(3,4), (1,3)(2,4) -- trade within, across, within, across (1,2)(3,4), (1,3,2,4), (1,2)(3,4), (1,4,2,3) -- across, left, across, right (1,2,3,4), (1,2,3,4), (1,2,3,4), (1,2,3,4) -- four lefts For five players there are 1344 deranged sequences, and once completed they fall into 4 orbits. In each case $n=k+1$. (1,2)(3,4,5), (1,3)(2,4,5), (1,2,3,4,5), (1,2,4,5,3), (1,4,5,2,3) (1,2)(3,4,5), (1,3)(2,4,5), (1,4,3,5,2), (1,3,5,4,2), (1,3,4,2,5) (1,2,3,4,5), (1,2,3,4,5), (1,2,3,4,5), (1,2,3,4,5), (1,2,3,4,5) -- five left (1,2,3,4,5), (1,2,3,4,5), (1,3,5,2,4), (1,5,4,3,2), (1,3,5,2,4) -- left, left, double-left, right, double-left For six players, the number of possibilities seems to explode (1128960 deranged sequences, 362 orbits of deranged cycles), but in each case $n=k+1$. The sequence OEIS:A000479 may be relevant.","['permutations', 'group-theory', 'latin-square']"
159882,Derivative of a function defined by the divided difference of another function.,"Given a function $f$ of class $C$ $^{n+2}$ in an interval $[a,b]$ and $x_{0}=a<x_1<x_2 ... <x_n = b$ a subdivision of $[a,b]$ into $n+1$ points. Given another function $g$ defined in the same interval $[a,b]$ by the divided difference such that $g(x) = f[x_0, x_1, ... , x_n, x]$. Prove that $g'(x)=f[x_0, x_1, ... , x_n, x, x]$.","['interpolation', 'calculus', 'derivatives', 'numerical-methods']"
159887,"Prove that $fg\in L^r(\Omega)$ if $f\in L^p(\Omega),g\in L^q(\Omega)$, and $\frac1 p+\frac1 q=\frac1 r$","Can anyone give me a hint for proving the following: Let $\Omega$ be a measure space. Assume $f \in L^p(\Omega)$ and $g \in L^q(\Omega)$ with $1 \leq p, q \leq \infty$ and $\frac1p + \frac1q \leq 1$. Prove that $fg \in L^r(\Omega)$ with $\frac1r = \frac1p + \frac1q$. Note: One should be able to use (the standard) Hölder inequality. Notice that if you have $\frac1p + \frac1q = 1$ you recover the former result.","['measure-theory', 'analysis']"
159925,Operator norm is not induced by a scalar product,"Definition of the problem Let $\mathcal{H}$ be a Hilbert space, $\dim\mathcal{H}\geq2$. Prove
that the operator norm on $L\left(\mathcal{H}\right)$ is not induced
by a scalar product. We are hinted to prove that the orthogonal projection onto $span\left\{ \varphi\right\} $
for $\varphi\in\mathcal{H},\quad\left\Vert \varphi\right\Vert =1$,
is given by $P_{\varphi}x=\left\langle x,\varphi\right\rangle \varphi,\quad x\in\mathcal{H}$.
We have now to consider $P_{\varphi}$ and $P_{\psi}$, where $\varphi\perp\psi$
and $\left\Vert \varphi\right\Vert =\left\Vert \psi\right\Vert =1$. My effort I did prove the above citted statement. My idea I should use the parallelogram equality to show that the equality
does not hold: 
$$
\left\Vert P_{\varphi}+P_{\psi}\right\Vert ^{2}+\left\Vert P_{\varphi}-P_{\psi}\right\Vert ^{2}=2\cdot\left\Vert P_{\varphi}\right\Vert ^{2}+2\cdot\left\Vert P_{\psi}\right\Vert ^{2}.
$$ Further efforts I did try to compute the first operator norm, and I get the following
by using Pythagoreus Theorem and Cauchy-Schwarz, and since $\varphi\perp\psi$: 
$$
\begin{eqnarray*}
\left\Vert P_{\varphi}+P_{\psi}\right\Vert ^{2}+\left\Vert P_{\varphi}-P_{\psi}\right\Vert ^{2} & = & \sup_{\left\Vert x\right\Vert =1}\left(\left\Vert P_{\varphi}x\right\Vert ^{2}+\left\Vert P_{\psi}x\right\Vert ^{2}+\left\Vert P_{\varphi}x\right\Vert ^{2}+\left\Vert -P_{\psi}x\right\Vert ^{2}\right)\\
 & = & 2\sup_{\left\Vert x\right\Vert =1}\left(\left\Vert P_{\varphi}x\right\Vert ^{2}+\left\Vert P_{\psi}x\right\Vert ^{2}\right)\\
 & = & 2\sup_{\left\Vert x\right\Vert =1}\left(\left\Vert \left\langle x,\varphi\right\rangle \varphi\right\Vert ^{2}+\left\Vert \left\langle x,\psi\right\rangle \psi\right\Vert ^{2}\right)\\
 & \leq & 2\sup_{\left\Vert x\right\Vert =1}\left(\left|\left\langle x,\varphi\right\rangle \right|^{2}\left\Vert \varphi\right\Vert ^{2}+\left|\left\langle x,\psi\right\rangle \right|^{2}\left\Vert \psi\right\Vert ^{2}\right)\\
 & = & 2\sup_{\left\Vert x\right\Vert =1}\left(\left|\left\langle x,\varphi\right\rangle \right|^{2}+\left|\left\langle x,\psi\right\rangle \right|^{2}\right)\\
 & \leq & 2\sup_{\left\Vert x\right\Vert =1}\left(\left\Vert x\right\Vert ^{2}\left\Vert \varphi\right\Vert ^{2}+\left\Vert x\right\Vert ^{2}\left\Vert \psi\right\Vert ^{2}\right)\\
 & = & 2\sup_{\left\Vert x\right\Vert =1}\left(\left\Vert x\right\Vert ^{2}+\left\Vert x\right\Vert ^{2}\right)\\
 & = & 2\cdot\left(1+1\right)\\
 & = & 4.
\end{eqnarray*}
$$ On the other side, by almost the same computations, we have: 
\begin{eqnarray*}
2\cdot\left\Vert P_{\varphi}\right\Vert ^{2}+2\cdot\left\Vert P_{\psi}\right\Vert ^{2} & = & \sup_{\left\Vert x\right\Vert =1}\left(2\left\Vert P_{\varphi}x\right\Vert ^{2}+2\left\Vert P_{\psi}x\right\Vert ^{2}\right)\\
 & = & ...\\
 & \leq & 4.
\end{eqnarray*} And I guess that would with difficulties prove my statement.. My Question How would you go to solve the problem? Could you give me a few steps
so I could go any further? Do you see any mistakes in what I did so
far? Thank you for your help, Franck.","['linear-algebra', 'hilbert-spaces', 'functional-analysis']"
159929,Calculation of atan2,"I am familiar with the basics of atan2. The doubt I have in the computation of atan2 came across from an image processing sofware. This is a portion of the code segment when x>y. x and y are absolute values. const_1 = 57.2836266; const_2 = -18.6674461; const_3 = 8.91400051; const_4 = -2.53972459; c = sqrt(y/x); c2 = c*c; angleInTheta = (((const_4*c2 + const_3)*c2 + const_2)*c2 + const_1)*c; What confuses me is the formula of angleInTheta. The results are perfectly correct when applied. I would like to know get a brief explanation of this formula. Thanks,","['trigonometry', 'numerical-methods']"
159940,comparing distribution of two data sets,"I need to compare the distribution (unknown) of a set of data to the distribution of another one (unknown). In particular, I want to check for equality of the two distributions. What are some statistical tests for this?","['statistics', 'probability-distributions']"
159942,Why do mathematicians care so much about zeta functions?,Why is it that so many people care so much about zeta functions? Why do people write books and books specifically about the theory of Riemann Zeta functions? What is its purpose? Is it just to develop small areas of pure mathematics?,"['zeta-functions', 'soft-question', 'number-theory']"
159951,Main differences between analytic number theory and algebraic number theory,"What are some of the big differences between analytic number theory and algebraic number theory? Well, maybe I saw too much of the similarities between those two subjects, while I don't see too much of analysis in analytic number theory.","['analytic-number-theory', 'algebraic-number-theory', 'big-picture', 'number-theory']"
159953,Affine change of coordinates,"Let $P,U$ be points in $K^2$ ($K$ is a field). Let $L(1)$, $L(2)$ be two lines through $P$, and $L(3)$, $L(4)$ be two distinct lines through $U$. How to show that there is an affine change of coordinates $T$ of $K^2$ such that $T(P)=U$, $T(L(1))=L(3)$, and $T(L(2))=L(4)$?","['algebraic-geometry', 'algebraic-curves']"
159970,Chain rule and inverse in matrix calculus,"I am having trouble understanding the derivation of some seemingly simple matrix derivatives and am wondering if there is an intuitive (perhaps geometric) explanation.  I am reasonably well-versed in multivariate calculus and linear algebra, but am not comfortable with tensor math. The function I am interested in is $f(t)=\mathbf{B}^T(\mathbf{X}+t\mathbf{Y})^{-1}\mathbf{A}$, where $t$ is a scalar, and $\mathbf{A},\mathbf{B},\mathbf{X},\mathbf{Y}$ are matrices with conformant dimensions. On the page 24 of the pdf of the appendix on matrix calculus in the book by Jon Dattorro (page 600 of the book), I find the formula for the first derivative of $f(t)$: $$\frac{df}{dt}=-\mathbf{B}^T(\mathbf{X}+t\mathbf{Y})^{-1}\mathbf{Y}(\mathbf{X}+t\mathbf{Y})^{-1}\mathbf{A}$$ This sort of makes sense to me from my knowledge of calculus of functions of single variable: if you have $g(t)=a(x+ty)^{-1}b=ab(x+ty)^{-1}$, then $\frac{dg}{dt}=-ab(x+ty)^{-2}y=-a(x+ty)^{-1}y(x+ty)^{-1}b$ (from the chain rule and the power rule). That is, there is a clear similarity in the form. What I don't understand is why the matrix equation for $\frac{df}{dt}$ looks the way it does.  Is it due to non-commutativity of matrix multiplication?  But how does that come in to this problem exactly?  I've found the chain rule for matrix-valued function in the same pdf on page 8 (eq 1749) but I am not sure how to apply it here. Maybe I don't understand something about the calculus of the single-variable functions. I guess I am asking if there is a way to derive the equation for $\frac{df}{dt}$ ""from first principles"" without using tensors.","['matrices', 'linear-algebra', 'calculus']"
159987,Words that agree on the count of all subwords of length $\leq k$,"I'm working with a two letter alphabet $\{0,1\}$, and I'm talking about generalized sub-word i.e. letters don't need to be adjacent, $|01010|_{00} = 3$ For example, the two words $u=1001$ and $v=0110$ agree on all subwords of length $\leq$ 2 (1, 0, 10, 01, 11 and 00), and are both of length 4, which happens to be the shortest length where this property will be true with $k=2$. I've found the minimal lengths $\{2,4,7,12,16,22\}$ for $k=\{1,2,3,4,5,6\}$ respectively, through bruteforcing. What I'm basically looking for is, for two words $|u|=|v|=n$, what bound you need on $k$ such that if $u$ and $v$ agree on all subwords of length $\leq k$, then $u=v$. I'm aiming for a $\mathcal{O}(\log n)$ bound, so I've tried looking for an inductive proof on k where the length of the word becomes a multiple after each iteration. Also, as a side proof, so far experimentally, I've found that if two words agree on all subwords of length $k$, they also agree on all of length $\leq k$, but can't quite find a proof or counter-proof for this.","['group-theory', 'combinatorics']"
159992,How to find a canonical member of an equivalence class of matrices under row and column swaps?,"Call two matrices ""swap-equivalent"" if one matrix can be transformed into the other via some sequence of row swaps and column swaps. I'd like a computationally efficient algorithm that can transform a matrix into a canonical swap-equivalent matrix (so that all members of an equivalence class give the same result). I've been first sorting the rows and then sorting the columns, using the following comparison function: A list (row or column) $a$ is considered greater than a list $b$ if when sorted, $a$ comes before $b$ lexicographically, with ties broken by the lexicographic order of (unsorted) $a$ and $b$. For example: $\begin{matrix} 1 & 0 & 3 \\ 0 & 4 & 2 \\ 2 & 0 & 4 \end{matrix}$ becomes $\begin{matrix} 2 & 0 & 4 \\ 0 & 4 & 2 \\ 1 & 0 & 3 \end{matrix}$ after sorting the rows, and then $\begin{matrix} 4 & 0 & 2 \\ 2 & 4 & 0 \\ 3 & 0 & 1 \end{matrix}$ after sorting the columns. This is efficient enough, but I haven't been able to figure out if it's right. EDIT: Turns out this doesn't work. $\begin{matrix} 2 & 1 & 0 \\ 1 & 0 & 2 \end{matrix}$ gets transformed to $\begin{matrix} 2 & 0 & 1 \\ 1 & 2 & 0 \end{matrix}$ but $\begin{matrix} 2 & 1 & 0 \\ 0 & 2 & 1 \end{matrix}$ gets transformed to $\begin{matrix} 1 & 2 & 0 \\ 2 & 0 & 1 \end{matrix}$ even though they're equivalent. Sorting the rows again fixes it though.  Is that enough?  Maybe iterate until a stable state is reached?","['matrices', 'permutations', 'algorithms']"
159994,"Proving that $A_n$ is the only proper nontrivial normal subgroup of $S_n$, $n\geq 5$","There is a famous Theorem telling that: For $n≥5$ , $A_n$ is the only proper nontrivial normal subgroup of $S_n$ . For the proof, we firstly start with assuming a subgroup of $S_n$ which $1≠N⊲S_n$ . We proceed until at the last part of proof's body, we assume $N∩A_n=\{1\}$ . This assumption should be meet a contradiction with normality of $N$ in $S_n$ . There; we get $N=\{1,\pi $ } in which $\pi$ is an odd permutation of order $2$ . Now for meeting desire inconsistency, I have two approaches: (a) Since every normal subgroup, having two elements, lies in the center of $G$ so, our $N⊆ Z(S_n)=\{1\}$ for $n≥5$ and then $N=\{1\}$ . (b) Clearly, $1≠N$ acting on set $\Omega=\{1,2,...,n\}$ is intransitive wherein $|\Omega|≥5$ and according to the following Proposition $S_n$ would be imprimitive. Proposition 7.1: If the transitive group $G$ contains an intransitive normal subgroup different from $1$ , then $G$ is imprimitive (Finite Permutation Groups by H.Wielandt). May I ask if the second approach is valid? I am fond of knowing new approach if exists. Thanks.","['permutations', 'group-theory']"
159995,Orthogonal Trajectory of $x^2 + 2y^2 = k^2$,$x^2 + 2y^2 = k^2$ I first take the derivative like the instructions say. $2x + 4y \frac{dy}{dx} = 0$ I am not entirely sure why a dy and dx appears but it does in the instructions so I go with it. Now I need to solve for $y'$ $ + 4y \frac{dy}{dx} = -2x$ $  \frac{dy}{dx} = \frac{-x}{2y}$ $  \frac{dy}{dx} = \frac{-x}{2y}$ So now I need to find the inverse negative $  \frac{dy}{dx} = \frac{2y}{x}$ And that should be my slope at each line. And now I need to solve that. $  \frac{1}{2}ydy = xdx$ Take the integratal and I get $\frac{1}{4}y^2 = \frac{1}{2}x^2 + C$ $y^2 = 2x^2 + C$ $y = \sqrt{2x^2 + C}$ This is wrong and I do not know why.,"['calculus', 'integration']"
160010,Proving that a particular kind of multiple integral yields a real number.,"I encountered the following problem on a practice exam: Suppose $a_1,...,a_n>0$ are such that $$\sum_{k=1}^n\frac{1}{a_k}<1.$$ Then $$\int_1^\infty\cdots\int_1^\infty\frac{1}{x_1^{a_1}+\cdots+x_n^{a_n}}\,dx_1\cdots dx_n<\infty.$$ Now, this is not tricky for $n=1$, as $\frac{1}{a_1}<1$ iff $a_1>1$ in this circumstance, and so convergence is guaranteed by the convergence of $\sum_{k=1}^\infty k^{-a_1},$ but I'm not sure how to proceed for other $n$. I have a few thoughts: (1) Actually calculate the antiderivative at each stage, and apply methods of improper integrals where necessary. This seems like it would be more hectic than it's worth. (2) Find an upper bounding integrand that is more friendly, and show that that integral evaluates to a real number. This one seems like it could be doable, if I can find such a bounding integrand. My attempts so far have either failed to evaluate to a real number or failed to be a bounding integrand. (3) Generalize the integral test and the result that $\sum_{k=1}^\infty k^{-p}$ is a real number for $p>1$ in some fashion. This seems like it could be my best bet, but I worry that if I don't phrase them carefully, I may be trying to prove results that are incompatible or not both true. My question is this : Does anyone have any recommendations for how I might proceed (whether it's a hint for one of the approaches I listed above or the seed of an entirely different approach)? Thanks for any help you can give me!","['calculus', 'integration']"
160013,High school mathematical research,"I am a grade 12 student. I am interested in number theory and I am looking for topics to research on. Can you suggest some topics in number theory and in general that would make for a good research project? I have self-studied certain topics in Abstract Algebra and Number Theory. I'm fascinated by primes (like most people are). Preferably, suggest some unexplored problems so that new results can be obtained. Thanks.","['big-list', 'soft-question', 'number-theory']"
160014,Approximation of $\log(x)$ as a linear combination of $\log(2)$ and $\log(3)$,"I wonder if it's possible to approximate $\log(n)$, n integer, by using a linear combination of $\log(2)$ and $\log(3)$. More formally, given integer $n$ and and real $\epsilon>0$, is it always possible to find integer $x,a,b$ where: $$\left|n^x-2^a 3^b\right|<\epsilon$$ For example, I can approximate $11$ by $$2^{-33} 3^{23}=10.959708460955880582332611083984375 \approx 10.96.$$","['logarithms', 'number-theory']"
160022,"Integration of $\int_0^\infty\frac{1-\cos x}{x^2(x^2+1)}\,dx$ by means of complex analysis","Dear all: this time I have the integral $$\int_0^\infty\frac{1-\cos x}{x^2(x^2+1)}\,dx$$and we must try to solve it using complex integration, residues, Cauchy's Theorem and the whole lot. (BTW, does anyone have any idea whether this integral can be solved without complex functions?) $\underline{\text{What I did}}$: Letting $\,\gamma\,$ be the integration path containing the segments $$\begin{align}(i)&\,\,\text{the real interval} \,[-R\,,\,-\epsilon]\\(ii)&\,\,\text{the ""little"" half circle} \,\{z\;|\;z=\epsilon e^{i\theta}\,,\,\theta\in [0,\pi]\}\\(iii)&\,\,\text{ the real interval}\,[\epsilon\,,\,R]\\(iv)&\,\,\text{ and the ""big"" half circle}\,\{z\;|\;z=R e^{i\theta}\,,\,\theta\in [0,\pi]\}\end{align}$$ we take the integral $$I:=\oint_\gamma\frac{1-e^{iz}}{z^2(z^2+1)}\,dz$$
As the only pole of this function within $\,\gamma\,$ is the simple one $\,z=i\,$ (for $\,\epsilon<1<R\,$, say), and $$\,\operatorname{Res}_{z=i}\left(\frac{1-e^{iz}}{z^2(z^2+1)}\right)=\lim_{z\to i}\frac{1-e^{iz}}{z^2(z+i)}=\frac{e^{-1}-1}{2i}$$We get from the Cauchy's residue theorem $$\displaystyle{I=2\pi i\,\frac{e^{-1}-1}{2i}=\pi\left(\frac{1}{e}-1\right)}$$ We now pass to evaluate the above integral on each segment of $\,\gamma\,$ described above:$$\text{on}\,(iv)\,\text{it is easy:}\,\left|\frac{1-e^{iz}}{z^2(z^2+1)}\right|\leq\frac{1+e^{-R\cos\theta}}{R^4}\xrightarrow[R\to\infty]{} 0$$ On $\,(i)\,,\,(iii)\,$ together and letting $\,R\to \infty\,$ we get $\,\displaystyle{\int_{-\infty}^\infty\frac{1-\cos x}{x^2(x^2+1)}\,dx}\,$ , which isn't a problem as the integrand function is even. So here comes the problem : on $\,(ii)\,$ we have:$$z=\epsilon e^{i\theta}\Longrightarrow dz=\epsilon ie^{i\theta}d\theta\,,\,0\leq\theta\leq \pi\,\,\text{but going from left to right, so}$$$$\oint_{z=\epsilon e^{i\theta}}\frac{1-e^{iz}}{z^2(z^2+1)}\,dz=\int_\pi^0\frac{1-e^{i\epsilon e^{i\theta}}}{\epsilon^2e^{2i\theta}\left(\epsilon^2e^{2i\theta}+1\right)}\,\epsilon ie^{i\theta}\,d\theta$$ Now, the only thing I could came up with to evaluate the above integral when $\,\epsilon\to 0\,$ is to get the limit into the integral, getting $$\lim_{\epsilon\to 0}\frac{1-e^{i\epsilon e^{i\theta}}}{\epsilon e^{i\theta}\left(\epsilon^2 e^{2i\theta}+1\right)}=-i\Longrightarrow \int_\pi^0\frac{1-e^{i\epsilon e^{i\theta}}}{\epsilon^2e^{2i\theta}\left(\epsilon^2e^{2i\theta}+1\right)}\,\epsilon ie^{i\theta}\,d\theta\xrightarrow [\epsilon\to 0]{} -\pi$$applying L'Hospital, so the final result is$$\pi\left(\frac{1}{e}-1\right)=I\xrightarrow [R\to\infty\,,\,\epsilon\to 0]{} \int_{-\infty}^\infty\frac{1-\cos x}{x^2(x^2+1)}\,dx-\pi$$from which we get the value of $\,\displaystyle{\frac{\pi}{2e}}\,$ for our integral, which is correct (at least according to Wolframalpha), yet... How can I justify the introduction of the limit into the integral?? The only way that seems to me possible (if at all) is to substitute $$\epsilon\to\frac{1}{\delta}$$ to get an indefinite integral with upper limit equal to $\,\infty\,$ inj $\,(ii)\,$ above and then use the dominated convergence theorem (or perhaps the monotone one). My question is two fold: Is the substitution just described what can put me out of my misery in this case? , and: Is it possible to justify the passage of the limit into the integral without making the substitution and, thus, without resourcing to an indefinite integral with infinite upper limit? Thank you to anyone investing he/his time just to read this question, and of course any ideas, corrections will be deeply appreciated.","['complex-integration', 'integration', 'complex-analysis']"
160023,approximation hypergeometric distribution with binomial,"Let $X$ be $\rm{Hypergeometric}(2n,\ell,n)$ and $E(X)=\frac{1}{2} \ell=:\mu$. 
Is it possible and how to approximate the $q$-th central moment $E(X-\mu)^q$ of the hypergeometric distribution by the moments of binomial distribution? Thank you.","['statistics', 'approximation', 'probability-distributions', 'probability']"
160031,Group as product of subsets,"There's a fairly simple result that states that for a finite group $G$ and two subsets $A, B$ with $$|A| + |B| > |G|,$$ any $g \in G$ has a representation $g = a*b$ with $a \in A$, $b \in B$. To prove this, just consider that the sets $A$ and $gB^{-1} = \{gb^{-1} : b \in B\}$ can't be disjoint. This immediately implies that every number modulo a prime $p$ is the sum of two squares: let $G = \mathbb{Z}/p\mathbb{Z}$ and $A = B = \{x^2 : x \in \mathbb{Z}/p\mathbb{Z}\}$. My question: can this result be extended meaningfully to products of three or more subsets?  I'm interested in representations mod $p$ as sums of cubes and higher powers. The most obvious (to me) generalization for a finite group $G$ and three subsets $A, B, C$ with $$|A| + |B| + |C| > |G|,$$ any $g \in G$ has a representation $g = a*b*c$ with $a \in A$, $b \in B$, $c \in C$. is clearly false: just take $G = \mathbb{Z}/2\mathbb{Z}$ and $A = B = C = 0$.","['finite-groups', 'combinatorics']"
160033,Criterion for a limit of invertible operators on a Banach space to be invertible,"Let $A_n$ linear operators in a Banach space $B$ that have inverses. $||A_n-A|| \to 0$ for some operator $A$. I need to prove that $A$ has an inverse operator iff the sequence $\{||A_n^{-1}||\}$ is bounded. I am almost sure it should be solved with the Uniform boundedness principle, but I can't figure it out, neither statements.","['banach-algebras', 'functional-analysis', 'banach-spaces']"
160056,What is a good book to study linear algebra? [duplicate],"This question already has answers here : Prerequisites/Books for A First Course in Linear Algebra (6 answers) Closed last year . I'm looking for a book to learn Algebra. The programme is the following. The units marked with a $\star$ are the ones I'm most interested in (in the sense I know nothing about) and those with a $\circ$ are those which I'm mildly comfortable with. The ones that aren't marked shouldn't be of importance. Any important topic inside a unite will be boldfaced. U1: Vector Algebra. Points in the $n$-dimensional space. Vectors. Scalar product. Norm. Lines and planes. Vectorial product. $\circ$ U2: Vector Spaces. Definition. Subspaces. Linear independence. Linear combination. Generating systems. Basis. Dimesion. Sum and intersection of subspaces. Direct sum. Spaces with inner products. $\circ$ U3: Matrices and determinants. Matrix Spaces. Sum and product of matrices. Linear ecuations. Gauss-Jordan elimination. Range. Roché Frobenius Theorem. Determinants. Properties. Determinant of a product. Determinants and inverses. $\star$ U4: Linear transformations. Definition. Nucleus and image. Monomorphisms, epimorphisms and isomorphisms. Composition of linear transformations. Inverse linear tranforms. U5: Complex numbers and polynomials. Complex numbers. Operations. Binomial and trigonometric form. De Möivre's Theorem. 
Solving equations. Polynomials. Degree. Operations. Roots. Remainder theorem. Factorial decomposition. FTA. Lagrange interpolation. $\star$ U6: Linear transformations and matrices. Matrix of a linear transformation. Matrix of the composition. Matrix of the inverse. Base changes. $\star$ U7: Eigen values and eigen vectors Eigen values and eigen vectors. Characteristc polynomial. Aplications. Invariant subspaces. Diagonalization. To let you know, I own a copy of Apostol's Calculus $\mathrm I $ which has some of those topics, precisely: Linear Spaces Linear Transformations and Matrices. I also have a copy of Apostol's second book of Calc $\mathrm II$which continues with Determinants Eigenvalues and eigenvectors Eigenvalues of operators in Euclidean spaces. I was reccommended Linear Algebra by Armando Rojo and have Linear Algebra by Carlos Ivorra , which seems quite a good text. What do you reccomend?","['linear-algebra', 'book-recommendation', 'reference-request']"
160082,Solving $\frac{dP}{dt} = k(M - P)$,"I am suppose to solve for P(t), to find an epxression for P(t) and I am suppose to find the limit. I can't find anything. $$\frac{dP}{dt} = k(M  - P)$$ $$\frac{dP}{M - P} = k \, dt$$ $$\int \frac{dP}{M - P} = \int k \, dt$$
$$ \ln \frac{1}{M - P} = xk + c$$
$$ \frac{1}{M - P} = e^{xk} + e^c$$
$$ \frac{1}{e^{xk} + e^c} = M - P$$
$$ -\frac{1}{e^{xk} + e^c} +M=  P$$ This is wrong but I am not sure why.","['ordinary-differential-equations', 'calculus', 'integration']"
160095,The collection of all compact perfect subsets is $G_\delta$ in the hyperspace of all compact subsets,"Let $X$ be metrizable (not necessarily Polish), and consider the hyperspace of all compact subsets of $X$, $K(X)$, endowed with the Vietoris topology (subbasic opens: $\{K\in K(X):K\subset U\}$ and $\{K\in K(X):K\cap U\neq\emptyset\}$ for $U\subset X$ open), or equivalently, the Hausdorff metric. We want to show that $K_p(X)=\{K\in K(X):K \text{ is perfect}\}$ is $G_\delta$ in $K(X)$. (This is another question from Kechris, Classical Descriptive Set Theory , Exercise 4.31.) A possible approach: $K_p(X) = \bigcap_{n=1}^\infty \{K\in K(X): \forall x\in K, (B(x,1/n)\setminus\{x\})\cap K\neq\emptyset\}$. What can we say about the complexity of $\{K\in K(X): \forall x\in K, (B(x,1/n)\setminus\{x\})\cap K\neq\emptyset\}$? Note that for fixed $x$, the set $\{K\in K(X): (B(x,1/n)\setminus\{x\})\cap K\neq\emptyset\}$ is open in $K(X)$. Also, the set $\{(x,K)\in X\times K(X):x\in K\}$ is closed in $X\times K(X)$, but I don't think this helps since the projection of a $G_\delta$ set need not be $G_\delta$. Any ideas?","['general-topology', 'descriptive-set-theory']"
160132,Complex Analysis Book [duplicate],"This question already has answers here : What is a good complex analysis textbook, barring Ahlfors's? (28 answers) Closed 8 years ago . I want a really good book on Complex Analysis, for a good understanding of theory. There are many complex variable books that are only a list of identities and integrals and I hate it. For example, I found Munkres to be a very good book for learning topology, and ""Curso de Análise vol I"" by Elon Lages Lima is the best Real Analysis book (and the best math book) that I have read with many examples, good theory and challenging exercises. An intuitive and introductory approach is not very important if the book has good explanations and has correct proofs. Added: If it is possible, tell me your experience with your recommended books and if you got a really good understanding of complex analysis with a deep reading.","['book-recommendation', 'reference-request', 'complex-analysis']"
160149,Trignometric shifting in ODE. Wolframalpha gives different answer?,"The ODE looks very identical ( kinda of) The ODE I have is $$y'' - y' + y = 0$$
$$y(0) = 5$$
$$y(1) = y(-1)$$ The solution (nontrivial) I got is $$y = 5e^{t/2}[\cos(\sqrt{3}x/2) + \left ( \frac{1-e}{1+e} \right )\cot(\sqrt{3}/2)\sin(\sqrt{3}x/2)]$$ Wolframalpha http://www.wolframalpha.com/input/?i=y%27%27+-+y%27+%2B+y+%3D+0+%2Cy%280%29+%3D+5+%2Cy%281%29+%3D+y%28-1%29 Could someone explain to me how do I get from my solution to do that weird shifting with the x - 1 part inside the sine functions? Wolframalpha doesn't show the ""simplification"" Thanks","['trigonometry', 'ordinary-differential-equations']"
160157,Integration of $\int\frac{1}{x^{4}+1}\mathrm dx$,"I don't know how to integrate $\displaystyle \int\frac{1}{x^{4}+1}\mathrm dx$ . Do I have to use trigonometric substitution? Many duplicate posts link to this one as the target. (Those posts were merged into this one, which is the source of the many answers.)","['calculus', 'integration', 'indefinite-integrals']"
160165,Computing rank using $3$-Descent,"For an elliptic curve $E$ over $\Bbb{Q}$, we know from the proof of the Mordell-Weil theorem that the weak Mordell-Weil group of $E$ is $E(\Bbb{Q})/2E(\Bbb{Q})$. It is well known that
$$
0 \rightarrow E(\Bbb{Q})/2E(\Bbb{Q}) \rightarrow S^{(2)}(E/\Bbb{Q}) \rightarrow Ш(E/\Bbb{Q})[2] \rightarrow 0
$$
is an exact sequence which gives us a procedure to compute the generators for $E(\Bbb{Q})/2E(\Bbb{Q})$. (Relatively) recently I found out that there is another way to compute the rank of $E$ using $3$-descent. I was wondering, since the natural structure of the weak Mordell-Weil group is $E(\Bbb{Q})/2E(\Bbb{Q})$, what is the motivation behind using $3$-descent? Also does $3$-descent similarly produce the generators of $E(\Bbb{Q})/2E(\Bbb{Q})$ or does it simply tell us the structure of $E(\Bbb{Q})$ via the Mordell-Weil theorem by giving us only the rank of $E$? Finally does it help us get around the issue of $Ш(E/\Bbb{Q})$ containing an element that is infinitely $2$-divisible?","['elliptic-curves', 'number-theory']"
160168,Prove a group generated by two involutions is dihedral,"Prove a finite group generated by two involutions is dihedral Is my following argument correct? Let $G=\langle x,y\rangle$ be a group generated by involutions $x,y$. Let $n=\mathrm{ord}(xy)$ to get a presentation $G=\langle x,y\mid x^2=y^2=(xy)^n=1\rangle $ so G is dihedral of order $2n$ ? Further note: I realise now my argument is not sufficient as it remains to show $G$ has no other relations. I just found an idea from a reference which claims ""... So $G$ must have a presentation of the form $G=\langle x,y\mid x^2=y^2=(xy)^m=1\rangle $, then one has to show $m=n$ ..."" in which I do not understand why $G$ has exactly a presentation of such form (the presentation inovlves $m$)? That reference also showed $|\langle x,y\rangle |=2n$ which directly led to the conclusion: $m=n$",['group-theory']
160219,Evaluate the series: $ \sum_{k=1}^{\infty}\frac{1}{k(k+1)^2k!}$,Evaluate the series: $$ \sum_{k=1}^{\infty}\frac{1}{k(k+1)^2k!}$$,"['sequences-and-series', 'calculus', 'real-analysis']"
160231,Reference request in number theory for an analyst.,"I am a confirmed mathochist. My background is in analysis, and fairly traditional analysis at that; mainly harmonic functions, subharmonic functions and boundary behaviour of functions, but I have for many years had an interest in number theory (who hasn't?) without ever having the time to indulge this interest very much. Having recently retired from teaching, I now do have the time, and would like to look more deeply into a branch of number theory in which my previous experience might still be useful, and in particular, I would be interested to find out more about the interplay between elliptic curves, complex multiplication, modular groups etc. I am pretty confident in my background with respect to complex analysis, and I have a working knowledge of the basics of p-adic numbers, but my algebra background is much, much weaker: just what I can remember from courses many years ago in groups, rings, fields and Galois Theory, and absolutely no knowledge of the machinery of homolgy/cohomology, and very little of algebraic geometry (I once read the first 2-3 chapters of Fulton before getting bored and going back to analysis!) Alas, I now no longer have easy access to a good academic library, so I would need to puchase any text(s) needed, unless any good ones happen to be available online. My request would then be this: What text(s) would you recommend for someone who wants to find out more about elliptic curves, complex multiplication and modular groups, bearing in mind that I am very unlikely to want to do any original research, and it is all ""just for fun""? Many thanks for your time!","['elliptic-curves', 'reference-request', 'number-theory']"
160247,Constant Radon-Nikodym derivative,"Let $(\Omega, F, \mu)$ be a complete measure space, $\mu(\Omega)=1$ and $\mu$ takes values 0 or 1.Let $\nu$ positive measura, $\sigma$-finite and absolutely continuous with respect to
 $\mu$. Show that then $f=\frac{d\nu}{d\mu}$ is constant a.e. equal to $\nu(\Omega)$ that is a finite number. Hint:prove that there exists a value $\alpha\in \mathbb{R}$ such that $\mu(f^{-1}(\alpha))=1$.","['measure-theory', 'integration']"
160248,Evaluating $\lim\limits_{n\to\infty} e^{-n} \sum\limits_{k=0}^{n} \frac{n^k}{k!}$,"I'm supposed to calculate: $$\lim_{n\to\infty} e^{-n} \sum_{k=0}^{n} \frac{n^k}{k!}$$ By using WolframAlpha, I might guess that the limit is $\frac{1}{2}$ , which is a pretty interesting and nice result. I wonder in which ways we may approach it.","['sequences-and-series', 'calculus', 'real-analysis', 'limits']"
160272,"Subset of $\mathbb{I}\cap [0,1]$ (irrationals in [0,1]) that is closed in $\mathbb{R}$ and has measure $\epsilon \in (0,1)$","Measure theory guarantees that every Lebesgue finite measurable set $E$ has a closed subset $F$ such that $m(E \backslash F)<\epsilon$  for small $\epsilon$. But today I saw in some text that for all small $\epsilon >0$ there exist a subset of $\mathbb{I}\cap [0,1]$ (irrationals in [0,1]) that is closed in $\mathbb{R}$ and has Lebesgue measure less than $\epsilon$? Note the set is required to be closed in $\mathbb{R}$, not in $\mathbb{I}\cap [0,1]$. Can someone give me an example / a proof that such thing does not exist?","['measure-theory', 'real-analysis']"
160273,Coordinate ring of general linear group,"Let $n$ be a positive integer and let $k$ be an algebraically closed field. What is the coordinate ring of $GL(n,k)$ (the set of all $n \times n$ matrices with entries in $k$)?  Here we identify this set as a subset of $k^{n^{2}}$. Would it suffice to say that the coordinate ring is the localization of $k[x_{11},x_{12},..,x_{nn}]$ at the determinant function? Is there a way to ""simplify"" this?",['algebraic-geometry']
160282,Derivative of a composition,"Let $f$ and $g$ two differentiable functions on $]a, b[$. Then $f \circ g$ is differentiable on the same interval and we have the expression : $$(f \circ g)' = g' \cdot f' \circ g$$ How do you prove this ?",['derivatives']
160287,Evaluating Integral with Residue Theorem,"The integral in question is $$\int_{_C} \frac{z}{z^2+1}\,dz,$$ where $C$ is the path $|z-1| = 3.$ The two pole of $f(x)$ where $f(x)=\frac{z}{z^2+1}$ is $-j$ and $j$ $${\rm Res}_{z=z_0}f(x)=\lim_{z\rightarrow\infty}(z-z_0)f(z)$$ For the first pole: $${\rm Res}_{z=j}f(z)= \lim_{z\rightarrow\\j}(z-j)\frac{z}{z^2+1} \\ = \lim_{z\rightarrow\\j}\frac{(z-j)z}{(z+j)(z-j)}\\
=\lim_{z\rightarrow\\j}\frac{z}{(z+j)} =\frac{j}{(j+j)}$$ ${\rm Res}_{z=j}f(z)= \frac{1}{2}$. For the second pole: $${\rm Res}_{z=-j}f(z)= \lim_{z\rightarrow\\-j}(z+j)\frac{z}{z^2+1} \\ = \lim_{z\rightarrow\\-j}\frac{(z+j)z}{(z+j)(z-j)}\\ = \lim_{z\rightarrow\\-j}\frac{z}{(z-j)}\\ = \frac{j}{(-j-j)}$$ ${\rm Res}_{z=-j}f(z)= \frac{-1}{2}$. Sum: $${\rm Res}_{z=j}f(z)+ {\rm Res}_{z=-j}f(z)= \frac{1}{2}-\frac{1}{2} = 0$$ Now I have always been under the impression that when integrating inside a path, the only time when the result is 0 is when there are no pole in or on the path. Am I mistaken? or have I made an error in the calculation? Or should I not be trying to use the Residue Theorem all together? Any help would be much appreciated.","['residue-calculus', 'calculus', 'integration', 'complex-analysis']"
160298,manifold structure on on a finite dimensional real vector space,"I am reading Warner's Differentiable Manifolds I do not get one example which is Let $V$ be a finite dimensional real vector space. Then $V$ has a natural manifold structure. If $\{e_i\}$ is a basis then the elements of the dual basis $\{r_i\}$ are the coordinate functions of a global coordinate system on $V$ . I don't understand how ""the elements of the dual basis $\{r_i\}$ are the coordinate functions of a global coordinate system on $V$ ."" Could any one explain me about that? Then how such a global coordinate system uniquely determines a differentiable structure on $V$ ? And why this structure is indipendent of choice of basis? First of all for a manifold structure I need each point must have an open neighborhood $U$ homeomorphic to some open subset of $\mathbb{R}^n$ . Here am I getting such notions?",['differential-geometry']
160300,Do dual Banach spaces admitting $c_0$ as a quotient contain complemented copies of $\ell_1$?,The following question is bothering me. Suppose that we have Banach space $X$ such that $X^*$ has a quotient isomorphic to $c_0$. Must $X^*$ contain a complemented copy of $\ell_1$?,"['functional-analysis', 'banach-spaces']"
160306,Weak and pointwise convergence in a $L^2$ space,"Let $I$ be a measured space (typically an interval of $\Bbb R$ with the Lebesgue measure), and let $(f_n)_n$ a sequence of function of $L^2(I)$. Assume that the sequence $(f_n)$ converge pointwise and weakly. How to prove that the pointwise limit and the weak limit are the same ?","['hilbert-spaces', 'integration']"
160328,What is the usefulness of matrices?,"I have matrices for my syllabus but I don't know where they find their use. I even asked my teacher but she also has no answer. Can anyone please tell me where they are used?
And please also give me an example of how they are used?",['matrices']
160337,independence of random variables for finite subfamilies,"Let $X$ be a random variable and $\{Y_j\}, j\in J$ a family of random variables. $J$ should be an index set, perhaps uncountable. My question is, if $X$ is independent to every finite subfamily of $\{Y_j\}$, i.e. for every $ I \subset J$ and $|I|\in \mathbb{N}$ the family $\{Y_j;j\in I\}$ and $X$ are independent. Could we conclude that $X$ is independent to the whole family $\{Y_j; j\in J\}$? cheers math","['probability-theory', 'measure-theory']"
160338,Expression of the Hyperbolic Distance in the Poincaré Upper Half Plane,"While looking for an expression of the hyperbolic distance in the Upper Half Plane $\mathbb{H}=\{z=x +iy \in \mathbb{C}| y>0\},$ I came across two different expressions. Both of them in Wikipedia. In the page Poincaré Half Plane Model it is explicitly stated that the distance of $z,w \in \mathbb{H}$ is: $$d_{hyp}(z,w)= {\rm arcosh}(1+ \frac{|z-w|^2}{2{\rm Im}(z){\rm Im}(w)}).$$ While in the page Poincaré Metric it is stated that the metric on the Upper Half Plane is: $$\rho(z,w)=2{\rm artanh}(\frac{|z-w|}{|z-\bar w|}).$$ At the beginning I thought it would have been an easy exercise to prove the equivalence of the two expressions. But first I failed in doing that, and then I found, using Mathematica, a counterexample (i.e. $z=2i$ and $w=i$ ). Question : If they are not equal, which of the two expressions is the right one? Then, how is the metric related to the induced distance? The question is probably silly, but I'm often confused about the relationships between ""metric"" objects.","['differential-geometry', 'hyperbolic-geometry', 'trigonometry', 'riemannian-geometry', 'geodesic']"
160346,Can different uniformizations of Riemann surfaces be related somehow,"Let $X$ be a hyperbolic compact connected Riemann surface. Let $U\subset X$ be an open subset. Assume that $U\neq X$. We can uniformize $X$ by $\mathbf{H}$ directly to obtain it as a quotient of $\mathbf{H}$ by some cofinite Fuchsian group $\Gamma$ without cusps nor elliptic elements. But we can also uniformize $U$ in the same way and then obtain $X$ by adding the set $X-U$ of cusps. Can these uniformizations be related in some sense? Even abstractly speaking? Have such ""different"" uniformizations been studied in some sense? It's a bit of a vague question, I admit. I'm just wondering what exactly can be done in this context.","['hyperbolic-geometry', 'riemann-surfaces', 'algebraic-geometry', 'soft-question']"
160349,Frenet reference frame (TNB) in generic riemannian space,"We know that given a curve $r(t)$ in an euclidean space and $s(t)$ the arc length on the curve we can build a $TNB$ reference frame, using the Frenet formulas:
$$T=\frac{dr(t)}{ds}$$
$$N=\frac{\frac{dT}{ds}}{||\frac{dT}{ds}\|}$$
$$B=T\times N$$
My question is:
given a generic $3\times 3$ metric tensor $g_{\mu \nu}$ defining an element:
$$ds^2=g_{\mu \nu}dx^{\mu}dx^{\nu}$$ is it still possible to define a $TNB$ reference frame as in the euclidean geometry?","['geometry', 'differential-geometry']"
160379,A concrete example of the monotone class theorem,"I have a lot of trouble in applying the functional monotone class theorem. Therefore I'm solving some exercises to get some experience. Maybe someone could help me with the following. Suppose I have shown that the following equality is true: $$E[g f(W_{t+h}-W_t)]=E[g]E[f(W_{t+h}-W_t)]$$ for a bounded and measurable function $g$ and for a bounded and continuous function $f$ on $\mathbb{R}$ . Now I should use the functional monotone convergence theorem to extend this to all f, which are bounded and measurable on $\mathbb{R}$ . According to PlanetMath (Theorem 2), how would you choose $\mathcal{K}$ and $\mathcal{H}$ in this situation. Since I have trouble to apply the theorem, it would be appreciated if someone could help me to see a example of its use. math","['monotone-class-theorem', 'measure-theory']"
160380,What is the expected area of a polygon whose vertices lie on a circle?,I came across a nice problem that I would like to share. Problem : What is expected value of the area of an $n$-gon whose vertices lie on a circle of radius $r$? The vertices are uniformly distributed.,"['probability', 'euclidean-geometry']"
160389,infinite series involving harmonic numbers and zeta,"I ran across a fun looking series and am wondering how to tackle it. $$\sum_{n=1}^{\infty}\frac{H_{n}}{n^{3}}=\frac{{\pi}^{4}}{72}.$$ One idea I had was to use the digamma and the fact that $$\sum_{k=1}^{n}\frac{1}{k}=\int_{0}^{1}\frac{1-t^{n}}{1-t}dt=\psi(n+1)+\gamma.$$ Along with the identity $\psi(n+1)=\psi(n)+\frac{1}{n}$,  I managed to get it into the form $$\sum_{n=1}^{\infty}\frac{H_{n}}{n^{3}}=\gamma\zeta(3)+\zeta(4)+\sum_{n=1}^{\infty}\frac{\psi(n)}{n^{3}}.$$ This would mean that $$\sum_{n=1}^{\infty}\frac{\psi(n)}{n^{3}}=\frac{{\pi}^{4}}{360}-\gamma\zeta(3).$$  Which, according to Maple, it does.  But, how to show it?.  If possible. I also started with $\frac{-\ln(1-x)}{x(1-x)}=\sum_{n=1}^{\infty}H_{n}x^{n-1}$. Then divided by x and differentiated several times.  This lead to some interesting, but albeit, tough integrals involving the dilog: $$-\int\frac{\ln(1-x)}{x(1-x)}dx=Li_{2}(x)+\frac{\ln^{2}(1-x)}{2}=\sum_{n=1}^{\infty}\frac{H_{n}x^{n}}{n}.$$ Doing this again and again lead to some integrals that appeared to be going in the right direction. $$\int_{0}^{1}\frac{Li_{3}(x)}{x}dx=\frac{{\pi}^{4}}{90}$$ $$-\int_{0}^{1}\frac{\ln^{2}(1-x)\ln(x)}{2x}dx=\frac{{\pi}^{4}}{360}$$ $$-\int_{0}^{1}\frac{\ln(1-x)Li_{2}(1-x)}{x}dx=\frac{{\pi}^{4}}{72}$$ But, what would be a good approach for this one? I would like to find out how to evaluate $$\sum_{n=1}^{\infty}\frac{\psi(n)}{n^{3}}=\frac{{\pi}^{4}}{360}-\gamma\zeta(3)$$
 if possible, but any methods would be appreciated and nice. Thanks a bunch.",['sequences-and-series']
160393,Cutting cake into 5 equal pieces,"If a cake is cut into $5$ equal pieces, each piece would be $80$ grams
  heavier than when the cake is cut into $7$ equal pieces. How heavy is
  the cake? How would I solve this problem? Do I have to try to find an algebraic expression for this? $5x = 7y + 400$?",['algebra-precalculus']
160411,short exact sequences and direct product,"Let
$$0\longrightarrow L^{(i)}\longrightarrow M^{(i)}\longrightarrow N^{(i)}\longrightarrow 0$$
be a short exact sequence of abelian groups for every index $i$. Clearly if I take finite direct products, then
$$0\longrightarrow \prod_iL^{(i)}\longrightarrow\prod_i M^{(i)}\longrightarrow \prod_iN^{(i)}\longrightarrow 0$$
is a short exact sequence. But what about infinite direct product? Is the exactness preserved?","['homological-algebra', 'abstract-algebra']"
160429,How to arrive at Stokes's theorem from Green's theorem?,"I would like to verify the identity
$$ \oint \vec F  \cdot (\hat i dx  + \hat j dy) + \oint \vec F \cdot (\hat i dx  + \hat j dy) + \oint \vec F  \cdot (\hat i dx  + \hat j dy)  = \oint \vec F \cdot (\hat i dx + \hat j dy + \hat k dz) $$
If it is incorrect then what would be the correct identity.
Green's theorem is special case of Stokes's theorem. How do we arrive at Stokes's theorem using Green's theorem?","['multivariable-calculus', 'integration']"
160431,Sum of $n \sigma(n)$,"What is known about the asymptotic behavior of
$$
-\frac{\pi^2}{18}x^3+\sum_{n\le x}n\sigma(n) ?
$$ It seems to be $O(x^{2+\varepsilon})$ but I cannot prove this.","['multiplicative-function', 'arithmetic-functions', 'number-theory']"
160450,What's the latest on Laver tables?,"A couple of years ago, I was astonished and delighted to learn about Laver tables , a sequence (indexed on $n$) of Cayley-like tables for a binary operation $\star$ on numbers $i,j\leq 2^n$ that satisfies $p\star 1\stackrel{\text{def}}{=}p+1\bmod 2^n$ and $p\star (q\star r)\stackrel{\text{def}}{=}(p\star q)\star(p\star r)$.  As the Wikipedia page notes, these have connections with elementary embeddings of cardinals (and apparently some connections with representations of braid groups as well, though I know less about that). In particular, it's known that the top 'row' of the table - the list of entries $1\star q$ - is periodic for each $n$, with period $2^k$ for some $k\lt n$.  It's relatively straightforward to show that this period sequence is nondecreasing (larger tables project onto smaller ones).  All the tables that have been calculated have period 16 or less, and it's known that the smallest $n$ (if any) with a period larger than 16 is titanic. On the other hand, the Wikipedia page notes that the sequence of periods is 'known' to be unbounded - but only under the assumption of one of the strongest large-cardinal hypotheses known! It's this last result that I'm hoping for an update on; is anything 'new' known about the unboundedness of the period sequence?  Has it been shown to hold unconditionally?  If not, is there any revised upper or lower bound on the hypothesis needed for unboundedness?  I've seen Dehornoy's result that the unboundedness can't be proven in PRA, but has it been proven independent of PA itself (or even ZFC, e.g. needing some large-cardinal hypothesis) yet?","['large-cardinals', 'abstract-algebra']"
160485,Are test/bump functions always bounded?,"A bump function is a infinitely often differentiable function with compact support. I guess that such functions are always bounded, especially because the set where they are not zero is compact and because they are continuous they should attain a maximum value on that set. or am I wrong? I am wondering because nowhere in the literature I am using there it is said that such functions are bounded, and I guess this is an important property and think it should be mentioned if it holds. So maybe it's not the case?","['distribution-theory', 'functional-analysis', 'real-analysis']"
160495,Determining values where a function is not differentiable,"Given $$g(x) = 
\begin{cases}
-1-2x & \text{if }x< -1,\\
x^2 & \text{if }-1\leq x\leq1,\\
x & \text{if }x>1,
\end{cases}
$$ determine at which values $g(x)$ is differentiable. The approach I have taken with this question is to determine the values at which it is not differentiable, which will tell me all other values will be. I know that the function will not be differentiable where the limit at a given value does not exist. If I differentiate this function I get: $$
g'(x) = 
\begin{cases}
-2 & \text{if }x< -1,\\
2x & \text{if }-1\leq x\leq1,\\
0 & \text{if }x>1.
\end{cases}
$$ I am a little bit lost as to how to proceed with this question - if I can show that the left hand and right hand limits disagree, then I can determine where the function is not differentiable, and therefore where it is differentiable. Am I heading in the right direction here?","['calculus', 'derivatives']"
160496,Restriction maps for structure sheaf of Spec A,"For the space $X = \operatorname{Spec} A$, we define the structure sheaf $\mathcal{O}_X$ as follows.  For an open subset $U \subseteq X$, we let $\mathcal{O}_X(U)$ be the projective limit of the family $\{ A_f : f \in A, D(f) \subseteq U \}$ indexed with the partial order $f \le g \iff D(f) \subseteq D(g)$.  (Here $A_f$ denotes the localization of $A$ at $f$.)  I am having trouble understanding how to define the restriction maps $\rho^U_V : \mathcal{O}_X(U) \to \mathcal{O}_X(V)$, for $V \subseteq U$.  I understand it should be induced from $\rho^{D(g)}_{D(f)} : A_g \to A_f$ somehow ($D(f) \subseteq D(g)$), but I can’t quite figure out what it should be. ($D(f)$ are the principal open sets.)","['algebraic-geometry', 'schemes']"
160563,"Sanity check, is $\{(-9,-3),(2,-1),(7,7),(-1,-1)\}$ a function?","EDIT#2: Yes, I'm crazy! This IS a function. Thanks for beating the correct logic into me everyone! I'm using a website provided by my algebra textbook that has questions and answers. It has the following question: Determine whether the following relation represents a function:
$$\{(-9,-3),(2,-1),(7,7),(-1,-1)\}$$ I answered NO, it is not a function but the website says it is. Am I wrong? If so, what am I missing? EDIT: I was given the following definition in class: Function: A function is a rule which assigns to each X, called the domain, a unique y, called the range. My instructor also said that if you plot the points you can tell if it is not a function if it fails the vertical line test. Here is the graph of the above points, and for example it would fail the vertical line test if I drew one on x = 1, right? Thanks!
Jason","['relations', 'functions']"
160578,Understanding the definition of a compact set,"I just need a bit of help clarifying the definition of a compact set. Let's start with the textbook definition: A set $S$ is called compact if, whenever it is covered by a collection of open sets $\{G\}$, $S$ is also covered by a finite sub-collection $\{H\}$ of $\{G\}$. Question: Does $\{H\}$ need to be a proper subset of $\{G\}$? If, for instance, $\{G\}$ is already a finite collection, does that mean $S$ is automatically covered by a finite sub-collection of $\{G\}$? Also, is there any need for the open sets in $\{H\}$ to be bounded sets?","['general-topology', 'compactness', 'real-analysis']"
160599,Expressing $\widehat{MN}=\{x : x \mid mn\}$ as a product of $\widehat M$ and $\widehat N$.,"Let $m,n$ be any two positive integers. Note $\widehat X$ the set of positive divisors of $x$. $$\widehat X = \{ d : d \mid x\}$$ (do not confuse it with $\hat a = \{x : x \equiv a \mod m\}$) Assume $(m,n)=1$. How could one prove that $$\widehat {MN}=\{d:d\mid mn\}$$ is the product $\widehat M \cdot \widehat N$ in the sense that all divisors of $mn$ appear in the product $$\left(\sum d_i+\sum d_i d_j+\cdots+ d_1 d_2 \cdots d_r \right) \left(\sum e_i+\sum e_i e_j+\cdots+ e_1 e_2 \cdots e_r \right)$$ (clearly $e_1 e_2 \cdots e_r=m$ and $ d_1 d_2 \cdots d_r=n$) where $d_i$ are the divors of $n$ and $e_i$ those of $m$? This is essential in the proof that if $f$ is multiplicative, then $$F(n)=\sum_{d \mid n}f(d)$$ also is.","['elementary-number-theory', 'elementary-set-theory']"
160633,Prove that $\tan^{-1}\left(\frac{x+1}{1-x}\right)=\frac{\pi}{4}+\tan^{-1}(x)$,The question is: Prove that $\tan^{-1}\left(\frac{x+1}{1-x}\right)=\frac{\pi}{4}+\tan^{-1}(x)$. It's from A-level further mathematics.,['trigonometry']
160651,$M_m$ is naturally isomorphic to $(F_m/F_m^2)^{*}$,"Let us denote $M_m$ be the set of tangent vectors to a manifold $M$ at point $m$ and is called tangent space  to $M$ at point $m$ we denote $\bar{F_m}$ be the set of all germs at point $m$ and $F_m$ be the set of germs vanishes at $m$ In warner book there is a lemma:
$M_m$ is naturally isomorphic to $(F_m/F_m^2)^{*}$:
In proof he says if $v\in M_m$, then $v$ is a linear function  on $F_m$ vanishing on $F_m^2$ because of the derivation property ,but I do not get why is that so?Could any one explain me a explicitly why?
derivation property says $v(f.g)=f(m)v(g)+g(m)v(f)$, but I do not connect this with the above line of my confusion. Thank you.",['differential-geometry']
160667,About the uniqueness of rank-1 decomposition of a positive-definite Hermitian matrix,"Suppose T is positive-definite Hermitian matrix and I know that it can be expressed by eigen-decomposition as the following sum of rank-1 matrices:$ \textbf{T}= \sum    \lambda _{k}   \textbf{u}_{k}  \textbf{u}_{k}^{H} $where $\textbf{u}_{k} $ are orthogonal to each other. But my question is: is this rank-1 decomposition unique? For example, can T be also written in other forms, say:$\textbf{T}= \sum    \gamma _{k}   \textbf{v}_{k}  \textbf{v}_{k}^{H} $, only in this case $\textbf{v}_{k} $ do not necessarily need to be orthogonal vectors. If so, is there any relationship between $\textbf{u}_{k} $ and $\textbf{v}_{k} $? Thanks.",['linear-algebra']
160686,Every finite subgroup of $\mathbb{Q}/\mathbb{Z}$ is cyclic,"Show that every finite subgroup of the quotient group $\mathbb{Q}/\mathbb{Z}$ (under addition) is cyclic. Note: there is a related problem which I just proved: ""Let $G$ be a finite abelian group, then $G$ is non-cyclic iff $G$ has a subgroup isomorphic to $C_p \times C_p$ for some prime $p$."" Since $\mathbb{Q} /\mathbb{Z}$ is abelian, so based on the related problem it suffices to show it has no elementary abelian subgroup group. I tried to start prove by contradiction: Let $\mathbb{Z} <A<\mathbb{Q}$ such that $A$/$\mathbb{Z} \simeq C_p \oplus C_p$ for some prime p, but I can't proceed further.",['group-theory']
160689,Power series and singularity,"Consider the power series $\sum a_n z^n$.Given that $a_n$ converges to $0$, prove that 
  $f(z)$ cannot have pole on the unit circle, where $f(z)$ is the function represented by the power series in the question. EDIT I have thought an answer for it. Since $a_n$ converges to $0$, we can write $\lvert a_n \rvert <1$ for all $n >N_0$. From here, we can say radius of convergence of the power series is bigger than or equal to $1$. If the radius of convergence is bigger than $1$, the series converges on the unit circle. If it is equal to $1$, then points on the unit circle cannot be an isolated singularity. But I am not sure of my answer.",['complex-analysis']
160692,Calculate: $\sum_{k=0}^{n-2} 2^{k} \tan \left(\frac{\pi}{2^{n-k}}\right)$,Calculate the following sum for integers $n\ge2$: $$\sum_{k=0}^{n-2} 2^{k} \tan \left(\frac{\pi}{2^{n-k}}\right)$$ I'm trying to obtain a closed form if that is possible.,"['trigonometry', 'sequences-and-series', 'trigonometric-series']"
160723,Radius either integer or $\sqrt{2}\cdot$integer,"Given a circle about origin with exactly $100$ integral points(points with both coordinates as integers),prove that its radius is either an integer or $\sqrt{2}$ times an integer. What my solution is:
Since circle is about origin, hence, integral points would be symmetric about the $x$-axis  and $y$-axis as well as line $x=y$ and line $x+y=0$ ,i.e. if $(x,y)$ is an integral point, so are $(x,-y),(-x,-y),(-x,y),(y,x),(y,-x),(-y,x)$ and $(-y,-x)$.Therefore, we need to consider only a single octant.
Since there are a total of $100$ integral points, two cases are possible: 1) radius of the circle is integer. 2) radius of the circle is not an integer. case 1:
If radius is an integer, then $4$ points on the $x$-axis and $y$-axis of the circle would be integral points and hence each octant must have $12$ points(as $100-4=96$ is a multiple of $8$).
therefore, this case is consistent. case2:
If radius is not an integer, then $100$ integral points can't be divided into $8$ parts(octants),and points on $x$-axis and $y$-axis of circle are not integral points, therefore points on line $x=y$ and $x+y=0$ must be integral points so as to divide $100-4=96$ points in $8$ parts.
But since point on line $x=y$ and circle is of the form $(r\cdot\cos(45^\circ),r\cdot\sin(45^\circ))$,therefore, $r/\sqrt{2}$ is an integer and hence $r=\sqrt{2}\cdot$integer.
other points of circle on these lines are consistent with it. So, i proved that either radius is an integer and if not then it has to be $\sqrt{2}\cdot$integer. Is there any flaw in my arguments??
I couldn't find the proof to check whether mine is correct.
Thanks in advance!!","['geometry', 'geometry-of-numbers']"
160725,Expectation value of a product of an Ito integral and a function of a Brownian motion,"this problem has come up in my research and is confusing me immensely, any light you can shed would be deeply appreciated. Let $B(t)$ denote a standard Brownian motion (Wiener process), such that the difference $B(t)-B(s)$ has a normal distribution with zero mean and variance $t-s$. I am seeking an expression for $$E\left[ \cos(B(t))\int\limits_0^t \sin(B(s))\,\textrm{d}B(s) \right],$$ where the integral is a stochastic It$\hat{\textrm{o}}$ integral.  My first thought was that the expectation of the integral alone is zero, and that the two terms are statistically independent, hence the whole thing gives zero.  However, I can't prove this. To give you a little background: this expression arises as one of several terms in a calculation of the second moment of the integral $$\int\limits_{0}^{t}\cos(B(s))\,\textrm{d}s,$$ after applying It$\hat{\textrm{o}}$'s lemma and squaring.  I can simulate this numerically, so I should know when I get the right final expression! Thanks.","['stochastic-processes', 'stochastic-integrals', 'stochastic-calculus', 'brownian-motion', 'probability']"
160730,Check my solution - Modelling of a spring with Differential Equation,"I am doing some work with differential equations. I have solved the following problem but am uncertain if I'm doing it correctly. Could someone look over it for me and check if I'm doing something wrong or not? Thanks in advance! The problem is as follows: $\hskip 1in$ My Solution: $$\frac{\partial u(x,t)}{\partial t} = \sum_{n=1}^{\infty} \sin(n \pi x)\big(a_n 100\pi \cos(100\pi t)-b_n 100\pi \sin(100 \pi t)\big)$$ From initial condition $\displaystyle\frac{\partial u(x,0)}{\partial t} = 0$: $$\frac{\partial u(x,0)}{\partial t} = \sum_{n=1}^{\infty} \sin(n \pi x)[a_n  100\pi] = 0
\\ \implies  a_n = 0$$ Therefore: $$u(x,t) = \sum_{n=1}^{\infty} \sin(n \pi x)\big(b_n\cos(100\pi t)\big).$$ Since $$b_m = \frac{2}{L} \int_{0}^{L}  u(x,0) \sin\left( \frac{m\pi x}{L}\right)dx, \quad\text{and}\quad  u(x,0) = 4\sin(3\pi x)),$$ it follows that $$b_m = \frac{2}{1} \int_{0}^{1}  4\sin(3\pi x) \sin\left( \frac{m\pi x}{1}\right)dx.$$ Due to property of sine function where $$\int_{0}^{L} \ \sin\left( \frac{n\pi x}{L}\right) \sin\left( \frac{m\pi x}{L}\right)dx= \begin{cases}L/2 & \text{if } n=m \\ 0 & \text{if } n\ne m, \end{cases}$$ when $m = 3$, $b_m = 2\cdot 4\cdot\frac{1}{2} = 4$ and $b_m=0$ otherwise. Finally, then: $$ u(x,t)= 4 \sin(3\pi x)\cos(100 \pi t).$$ If anyone could have a look over this it would be much appreciated. Thanks!","['fourier-series', 'ordinary-differential-equations', 'mathematical-modeling', 'physics']"
160737,Compute: $\sum_{k=1}^{\infty}\sum_{n=1}^{\infty} \frac{1}{k^2n+2nk+n^2k}$,"I try to solve the following sum: $$\sum_{k=1}^{\infty}\sum_{n=1}^{\infty} \frac{1}{k^2n+2nk+n^2k}$$ I'm very curious about the possible approaching ways that lead us to solve it. I'm not experienced with these sums, and any hint, suggestion is very welcome. Thanks.","['sequences-and-series', 'real-analysis', 'limits']"
160738,"How to define a bijection between $(0,1)$ and $(0,1]$?","How to define a bijection between $(0,1)$ and $(0,1]$?
  Or any other open and closed intervals? If the intervals are both open like $(-1,2)\text{ and }(-5,4)$ I do a cheap trick (don't know if that's how you're supposed to do it):
I make a function $f : (-1, 2)\rightarrow (-5, 4)$ of the form $f(x)=mx+b$ by
\begin{align*}
-5 = f(-1) &= m(-1)+b \\
4 = f(2) &= m(2) + b
\end{align*}
Solving for $m$ and $b$ I find $m=3\text{ and }b=-2$ so then $f(x)=3x-2.$ Then I show that $f$ is a bijection by showing that it is injective and surjective.","['elementary-set-theory', 'functions']"
160764,"""Theorem of Witt"" for modules","For modules $M_1 \oplus N \cong M_2 \oplus N$, why is $M_1 \cong M_2$, if $Hom(M_1,N)=\{0\}=Hom(M_2,N)$? It seams similar to Witt's cancellation theorem for quadratic forms. Regards, Khanna","['modules', 'abstract-algebra']"
160771,How did Ramanujan get this result?,"We know Ramanujan got this result
$$\sqrt{1+2\sqrt{1+3\sqrt{1+\cdots }}}=3$$
and he used the formula
$$x+n+a=\sqrt{ax+{{(n+a)}^{2}}+x\sqrt{a(x+n)+{{(n+a)}^{2}}+(x+n)\sqrt{\cdots }}}$$
where $x=2,n=1,a=0$ ,we get the first result, but I don't know how to prove it, can you help me?",['calculus']
160779,Galois Group over Finite Field,"I am having a bit of difficulty trying to answer the following question: What is the Galois group of $X^8-1$ over $\mathbb{F}_{11}$? So far I have factored $X^8-1$ as $$X^8-1=(X+10)(X+1)(X^2+1)(X^4+1).$$ I know $X^2+1$ is irreducible over $\mathbb{F}_{11}$ since $10$ is not a square modulo $11$. Also, $X^4+1$ is irreducible over $\mathbb{F}_{11}$. The roots of $X^2+1$ and $X^4+1$ over $\mathbb{Q}$ are $\pm i$ and $\pm \frac{\sqrt{2}}{2} \pm \frac{\sqrt{2}}{2} i$, respectively. We also see that $\sqrt{2} \not \in \mathbb{F}_{11}$ since no element squared is equal to $2$. I would then think that $\mathbb{F}_{11}(i, \sqrt{2})$ is a splitting field for $x^8-1$ over $\mathbb{F}_{11}$, which is clearly Galois. If all this were true, I would then venture that the Galois group is $V_4$. I have the feeling, however, that I have made many mistakes in my reasoning. How should one approach a problem like this?","['galois-theory', 'finite-fields', 'abstract-algebra']"
160781,Dedekind complete ⇒ Sequentially complete,"Let F be an ordered field with least upper bound property. 1.Let $\alpha: \mathbb{N} \to F$ be a Cauchy sequence.
Since F is an ordered field, $x$ is bounded both above and below. 2.By assumption and dual of it, $A$={$\alpha(n)$|$n\in \mathbb{N}$} has a inf $a_0$ and sup $b_0$. 3.F is Archimedean 4.If subsequence of a Cauchy sequence is convergent to $a\in F$ then the Cauchy sequence is convergent to $a\in F$ These are all i know.. How do I prove all Cauchy sequences are convergent in $F$? Please consider my level. I want quite a direct proof not mentioning any topology & Cauchy net. *Comment button is not available to me now, (I don't know why), so i write this here.
I just proved it with facts that (i)every cauchy sequence is convergent in the set of Cauchy reals and (ii)there exists a bijective homomorphism between two dedekind complete fields and (iii)the set of Cauchy reals is dedekind complete.
Let $x:i→x(i):\mathbb{N}→F$ be a cauchy sequence in dedekind complete field $F$. Then use the bijective homomorphism $f$ to show that $x':i→f(x(i))$ is a cauchy sequence in the set of Cauchy reals. By the fact (i), $x'$ is convergent. Since inverse of $f$ is also homomorphism, use this to show that $x$ is convergent.","['field-theory', 'analysis']"
160784,What is the importance of determinants in linear algebra?,"In some literature on linear algebra determinants play a critical role and are emphasized in the earlier chapters (see books by Anton & Rorres, and Lay). However in other literature it is totally ignored until the latter chapters (see Gilbert Strang).
How much importance should we give the topic of determinants? I tend to use it to find linear independence of vectors and might extend this to finding the inverse but I think Gauss Jordan and LU might be easier for inverse. Does it have any other uses in Linear Algebra.
Are there areas where determinants are used and have a real impact? Are there any real life applications of determinants?
Is there a really good motivating example or explanation which will hook students into this topic? 
In linear algebra, where should determinants be placed? Like I said in my comment - in some literature it is at the beginning whilst in others it is bolted on at the end. I like the idea of checking if vectors are independent by using determinants so think they should be placed before independence of vectors. What do you think? If you teach a linear algebra course where do you place this topic.","['matrices', 'linear-algebra', 'education']"
160800,Monte Carlo algorithm that determines if a permutation of the integers 1 through $n$ has already been sorted.,"This question is from ""Discrete Mathematics and Its Applications"", from Kenneth Rosen, 6th Edition. Devise a Monte Carlo algorithm that determines whether
  a permutation of the integers 1 through $n$ has already been
  sorted (that is, it is in increasing order), or instead, is a random
  permutation. A step of the algorithm should answer
  “true” if it determines the list is not sorted and “unknown”
  otherwise. After $k$ steps, the algorithm decides that the integers
  are sorted if the answer is “unknown” in each step.
  Show that as the number of steps increases, the probability
  that the algorithm produces an incorrect answer is
  extremely small. [ Hint : For each step, test whether certain
  elements are in the correct order. Make sure these
  tests are independent.] Here is my attempt at a solution: Algorithm (informal description) : Given a permutation of the integers 1 through $n$, in each step of the algorithm, one element is randomly chosen from the permutation, with a total of $k$ steps. In each step, if the value of the chosen element is $i$, the algorithm checks if the element is in the correct position, that is, if it is in the $i^{th}$ position of the permutation (with $1\leq i\leq n$). If it is in the correct position, the result is ""unknown""; otherwise, the result is ""true"". For example, in the permutation $162453$, the number $4$ is in the $4^{th}$ position, therefore it is in the correct position in the permutation. If all steps give the result ""unknown"" , the algorithm determines that the permutation is sorted; otherwise, it determines that the integers are not sorted. I posted the details as an answer, but I'm not sure whether it is correct and completely consistent. Thank you in advance.","['monte-carlo', 'discrete-mathematics', 'probability', 'algorithms']"
160806,Condition for commuting matrices,"Let $A,B$ be $n \times n$ matrices over the complex numbers. If $B=p(A)$ where $p(x) \in \mathbb{C}[x]$ then certainly $A,B$ commute. Under which conditions the converse is  true? Thanks :-)","['matrices', 'linear-algebra']"
160811,Second Bianchi identity,"This is q. 7 of ch. 4 from Do Carmo's book on Riemannian Geometry . Prove that:
$$ \nabla R(X,Y,Z,W,T) + \nabla R(X,Y,W,T,Z) + \nabla R(X,Y,T,Z,W)=0.$$ Let $\{e_i\}$ a geodesic frame  on $p$ , it is enough to prove that the identity for : $$ \nabla R(e_i,e_j,e_k,e_l,e_h) + \nabla R(e_i,e_j,e_l,e_h,e_k) + \nabla R(e_i,e_j,e_h,e_k,e_l)=0.$$ The author says that the left side expression is : $$ R(e_l,e_h,\nabla_{e_k} e_i,e_j) + R(e_h,e_k,\nabla_{e_l} e_i,e_j) +  R(e_k,e_l,\nabla_{e_h} e_i,e_j).$$ I'd like to know why this is indeed the case.(you can check that: $$\nabla R(e_i,e_j,e_k,e_l,e_h)=\langle \nabla_{e_h} \nabla_{e_l} \nabla_{e_k}e_i - \nabla_{e_h} \nabla_{e_k} \nabla_{e_l}e_i +\nabla_{e_h} \nabla_{[e_k,e_l]}e_i , e_j \rangle).$$","['riemannian-geometry', 'differential-geometry']"
160821,what is the use of derivatives,"Can any one explain me what is the use of derivatives in real life. When and where we use derivative, i know it can be used to find rate of change but why?. My logic was in  real life most of the things we do are not linear functions and derivatives helps to make a real life functions into linear. eg converting parabola into a linear function $x^{2}\rightarrow 2x$ but then i find this; derivation of $\sin{x}\rightarrow \cos{x}$ why we cant use $\sin{x}$ itself to solve the equation. whats the purpose of using its derivative $\cos{x}$.
Please forgive me if i have asked a stupid questions, i want to improve my fundamentals in calculus.","['calculus', 'derivatives']"
160824,System of equations of 3rd degree,"I need help with the following system of equations: $
 2y^3 +2x^2+3x+3=0 $ $
 2z^3 + 2y^2 + 3y + 3= 0 $ $2x^3 + 2z^2 + 3z + 3 = 0$",['algebra-precalculus']
160825,"Lower bound for $\|A-B\|$ when $\operatorname{rank}(A)\neq \operatorname{rank}(B)$, both $A$ and $B$ are idempotent","Let's first focus on $k$-by-$k$ matrices. We know that rank is a continuous function for idempotent matrices, so when we have, say, $\operatorname{rank}(A)>\operatorname{rank}(B)+1$, the two matrices cannot be close in norm topology. But I wonder whether there is an explicit lower bound of the distance between two idempotent matrices in terms of their difference in their ranks. Thanks!","['operator-algebras', 'linear-algebra', 'operator-theory']"
160847,Polynomials irreducible over $\mathbb{Q}$ but reducible over $\mathbb{F}_p$ for every prime $p$,"Let $f(x) \in \mathbb{Z}[x]$. If we reduce the coefficents of $f(x)$ modulo $p$, where $p$ is prime, we get a polynomial $f^*(x) \in \mathbb{F}_p[x]$. Then if $f^*(x)$ is irreducible and has the same degree as $f(x)$, the polynomial $f(x)$ is irreducible. This is one way to show that a polynomial in $\mathbb{Z}[x]$ is irreducible, but it does not always work. There are polynomials which are irreducible in $\mathbb{Z}[x]$ yet factor in $\mathbb{F}_p[x]$ for every prime $p$. The only examples I know are $x^4 + 1$ and $x^4 - 10x^2 + 1$. I'd like to see more examples, in particular an infinite family of polynomials like this would be interesting. How does one go about finding them? Has anyone ever attempted classifying all polynomials in $\mathbb{Z}[x]$ with this property?","['finite-fields', 'abstract-algebra', 'polynomials', 'galois-theory', 'field-theory']"
