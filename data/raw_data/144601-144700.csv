question_id,title,body,tags
2357445,Let $G$ be an abelian group of odd order. Prove that the map $\varphi : G\rightarrow G$ defined by $\varphi (x)=x^2$ is an automorphism,"A problem from Artin's Algebra (not the problem I am asking): Let $G$ be an abelian group of odd order. Prove that the map $\varphi : G\rightarrow G$ defined by $\varphi (x)=x^2$ is an automorphism. I have solved this problem, also we can see here . Then comes Generalization of the problem: Let $G$ be an abelian group of finite order. Prove that the map $\varphi : G\rightarrow G$ defined by $\varphi (x)=x^k$ is an automorphism, where $k$ does not have any prime factor same of order of $G$ . Is it ok?","['abstract-algebra', 'group-theory']"
2357518,Contour integrate $\int_{-\infty}^{\infty} \frac{dt}{t}$,"A paper (admittedly a physics paper) I read has $$\int_{-\infty}^{\infty} \frac{dt}{t}  = \pm i \pi$$ ""where a semicircular path of infinitesimal radius $\epsilon$ passes either counterclockwise or clockwise around $t=0$, yielding $+i\pi$ or $-i\pi$."" Any symbolic computing software says the integral does not converge. Can someone explain this?","['complex-analysis', 'real-analysis', 'contour-integration', 'calculus']"
2357570,On the definition of Euclidean domain,"Typically, a Euclidean domain is defined to be an integral domain which admits a function defined on all nonzero elements whose values on the set of all non-negative integers. Some author requires additional condition which says that for every nonzero elements $a$, $b$ the value of the function at $ab$ is no less than that at $a$. One may use those properties to prove that every ED is a PID, and by the theorem which says that PID is UFD one gets that every ED is a UFD. Sometimes, it is required to prove ED is UFD without the concept of PID. However, hard part appears to be that every elements in ED can be written as a finite product of irreducibles. For me, it is unavoidable to pass through PID argument. However, as most ED function satisfies, if we have that the value of the function at a nonzero element is strictly larger than that at a proper divisor (non-unit, not associated), then typical least value argument provides that in the domain every elements can be factored into irreducibles. My question is that is there any ED which does not admit any ED function with the above stronger property.","['abstract-algebra', 'ring-theory', 'euclidean-domain', 'unique-factorization-domains']"
2357589,Limit as x tends to infinity of a product of two functions where one is an integral and the other tends to 0,"Any hints on how to best approach this problem? $$\lim_{x\to+\infty} \dfrac{1}{x} \int_{1}^{x} \dfrac{t^3}{1+t^3} dt$$ The first point of confusion for me is that $\dfrac{1}{x} \rightarrow 0$ as $ x \rightarrow +\infty$, so by evaluating the limit for $\dfrac{1}{x}$ and the integral separately and multiplying their limits afterwards should result in $0$, but I highly suspect that this is too simple of a solution that it must be wrong. Secondly, my hunch is that to evaluate the limit of the integral I could find a function with a smaller area than $\dfrac{t^3}{1+t^3}$ on the listed interval and show that the limit tends to $\infty$ and this would be sufficient to show that $\dfrac{t^3}{1+t^3}$ must also tend to $\infty$ since it has a larger area. Is this the right approach and any hints as to how I could find a function with smaller area that I can show tends to $\infty$?","['integration', 'calculus']"
2357611,"Is identity the only function $f$ on real line satisfying $ f(x +f(y) + yf(x)) = y +f(x) + xf(y) ,\forall x,y \in \mathbb R$? [duplicate]","This question already has answers here : Find the function equation $f(x+f(y)+yf(x))=y+f(x)+xf(y)$ (2 answers) Closed 5 years ago . Let $f:\mathbb R \to \mathbb R$ be a function such that $ f(x +f(y) + yf(x)) = y +f(x) + xf(y) ,\forall x,y \in \mathbb R$ , then is it true that $f(x)=x,\forall x \in \mathbb R$ ? If not true in general , then what if we also assume $f$ is bijective , or say continuous ? Over $\mathbb C$ , $f(z)=\bar z$ is a bijective continuous , non-identity solution . Over $\mathbb R$ I can show that under the further assumption $\{f(x)/x : x\ne 0\}$ is countable, we must have $f$ is identity . With only the given functional equation , I can show that if $f(x_0)=0$ for some $x_0 $
 then $x_0=0$ , and then $f(f(x))=x,\forall x \in \mathbb R$ i.e. $f$ is bijective . But I can't figure out anything else Please help . Thanks in advance","['real-analysis', 'functional-equations']"
2357619,A question in the book of Hamilton's Ricci flow,"I am reading the book ""Hamilton's Ricci flow"" by Chow, Lu and Ni. However, I am struggling to understand one step in P.172-173, which I think it is just a question in calculus and has nothing to do with the Ricci flow. Here is my question: It was deduced that (see (4.60) in P.172)
$$\tag{1}\frac{d}{dt}(A-C)
=(-2(A^2+AC+C^2)+B^2+AB+BC)(A-C).$$
Similarly, we have the equation for $\frac{d}{dt}(A-B)$ and $\frac{d}{dt}(B-C)$. 
Then it was claimed that if $A(0)\geq B(0)\geq C(0)$, then we have $A(t)\geq B(t)\geq C(t).$ This is the place I get lost. I just wonder how one can derive this from the evolution equation $(1)$, becasuse it seems to me that the coefficient of $A-C$ on the RHS of $(1)$, that is
$-2(A^2+AC+C^2)+B^2+AB+BC$, is not always positive.","['inequality', 'ordinary-differential-equations', 'differential-geometry', 'calculus']"
2357627,Is this number friends relationship transitive?,"I am calling two real numbers $a,b$ friends, if there exists a non-constant integer polynomial $p(x)$, such that $p(a)-p(b)=0$. The relation is obviously symmetric and reflexive. Is the relationship also transitive? ( i.e. Can we state for all numbers $a,b,c \in \mathbb R$ that if there is a polynomial $p_1(x) \in \mathbb Z[x]$ and $deg(p_1)>0$ such that $p_1(a)-p_1(b)=0$, and a polynomial $p_2(x) \in \mathbb Z[x]$ and $deg(p_2)>0$ such that $p_2(b)-p_2(c)=0$, does there also exist polynomial $p_3(x) \in \mathbb Z[x]$ and $deg(p_3)>0$ such that $p_3(a)-p_3(c)=0$ )","['polynomials', 'algebraic-geometry']"
2357673,Definition of Tail-index of a probability distribution,What is a valid definition of Tail-index of a probability distribution? I understand that it is something to do with the rate of convergence of the density function $f(x)$ $($to $0)$ as $x \to \infty$. I tried searching google and I do find a lot of articles/papers on the topic but nowhere I can find a specific definition of the term. Any help would be much appreciated! Thanks.,"['distribution-tails', 'probability-theory', 'probability-distributions', 'statistics', 'probability']"
2357760,An expression involving the roots of a quadratic polynomial,"I have the equation $$ 9x^2 - 11x + 1 = 0 $$ whose two roots are $ \alpha $ and $ \beta $ . I need to evaluate $$ \frac 1 {(9\alpha-11)^2} + \frac{11\beta - 1} 9$$ What I've tried Expanded the denominator and add them, but nothing simplifies and I get even a complex expression. I found that $ \alpha + \beta = \frac{11}{9} 
\implies \alpha = \frac{11}{9} - \beta $ How to evaluate the value of the expression in an easier way?","['algebra-precalculus', 'polynomials', 'quadratics']"
2357793,on sums of squares being squares,"A sum of 2 squares can be a square, eg. $3^2+4^2=5^2$. A sum of 3 squares can be a square, eg. $3^2+4^2+12^2=13^2$, but is it possible to find an example where sum of any two of them would also be a square? What about 4 squares such that sum of any two, any three and all four are squares? Are there arbitrarily long sequences of squares such that any sum among them is a square?","['number-theory', 'square-numbers', 'elementary-number-theory']"
2357811,Embedding $L^p \subset L^q$ compact? And relation to abstract Wiener spaces,"I am currently reading Hui Hsiung Kuo's book ""Gaussian Measures in Banach Spaces"" and there is an exercise (Exercise 21, p. 86) in which you are asked to show that for $1 \leq p < 2$, $(i, L^{2}[0,1], L^{p}[0,1])$ is not an abstract Wiener space (I have provided a definition of abstract Wiener space below). Here, $i$ denotes the inclusion map $i \colon L^{2}[0,1] \hookrightarrow L^{p}[0,1]$. One of the consequences of the definition of an abstract Wiener space is that the embedding map $i$ has to be compact, i.e. $L^{2}[0,1] \hookrightarrow \hookrightarrow L^{p}[0,1]$. As I am trying to show that it isn't an AWS, one of my first thoughts was to try to prove the embedding is not compact. But I could not produce a proof nor find one so far. So my question is twofold: Is the embedding $L^{2}[0,1] \hookrightarrow L^{p}[0,1]$ ($1 \leq p < 2$), or maybe more generally $L^{q}(S, \mathcal{S}, m) \hookrightarrow L^{p}(S, \mathcal{S}, m)$ ($1 \leq p < q$) a compact operator? Let us say that $(S, \mathcal{S}, m)$ is a finite measure space so the embedding makes sense. If not, how do I prove that the triple $(i, L^{2}[0,1], L^{p}[0,1])$ is not an abstract Wiener space? Best Regards, Andre Appendix (Definition of abstract Wiener space): Kuo defines an abstract Wiener space starting from a (real) separable Hilbert space $(H, | \cdot |)$. Take another norm (if it exists) $\| \cdot \|$ on $H$ that is ""measurable"" in $H$, by which Kuo means (Definition 4.4, p. 59): $\forall \varepsilon > 0 ~ \exists P_{\varepsilon} \in FP$ such that
$$
\mu \{ \| P x \| > \varepsilon \} < \varepsilon \quad \forall P \in FP, ~P \perp P_{\varepsilon},
$$ 
where $FP$ denotes the set of all finite-dimensional orthogonal projections on $H$. $\mu$ denotes the ""standard"" Gauss measure in $H$ (which is not $\sigma$-additive), defined on cylinder sets
$$
E_{P,F} = \{ x \in H ~|~Px \in F \}, \quad P \in FP, F \in B(P(H))
$$
(where the range $P(H)$ is finite-dimensional with dimension $\dim P(H) = n$ since $P$ is a finite-dimensional projection) via
$$
\mu(E_{P,F}) := \left( \frac{1}{\sqrt{2 \pi}} \right)^{n} \int_{F} e^{-\frac{|x|^2}{2}} dx.
$$ Then we define the Banach space $B$ as the completion of $H$ w.r.t. this norm $\| \cdot \|$. Obviously, $H$ is embedded into $B$ and we call the embedding map $i$. The triple $(i, H, B)$ is then called an abstract Wiener space . One of the consequences of this definition (Lemma 4.6, p.70 in the book) is that the embedding $i$ must be compact.","['banach-spaces', 'wiener-measure', 'probability-theory', 'lp-spaces', 'measure-theory']"
2357817,Grobner Basis and Surfaces,"Grobner basis are really good at describing polynomial systems of equations with 0-dimensional zero sets. In a sense, Grobner basis yields a better/simplified description of such systems because the Grobner polynomials (in appropriate monomial order) let one explicitly compute the zeros. However, suppose the ideal $I\subseteq k[x_1,\ldots,x_n]$ has a positive dimensional zero set, such as a curve or surface. What can Grobner basis tell you about these zero sets? I'm particularly interested in the curves and surfaces case (as I am intersecting the flat 3-torus with various varieties).","['real-algebraic-geometry', 'algebraic-geometry', 'computational-geometry', 'algebraic-curves', 'surfaces']"
2357845,Rudin proof: $\mathbb{Q}$ is countable,"I'm reading Rudin and he states that the set of fractions is countable because the set $(a,b)$ with $a \in \mathbb{Z}, b \in \mathbb{Z_0}$ is countable and we can write any fraction as $a/b$ Of course, there are missing a lot of details (I think). So can someone verify my reasoning? Define $$f: \mathbb{Z} \times \mathbb{Z}_0 \to \mathbb{Q}: (a,b) \mapsto \frac{a}{b}$$ Clearly, $f$ is surjective. Let's prove a little lemma first: Lemma : $f: A \to B$ surjective $\Rightarrow \exists T \subset A: f: T \to B$ is bijective Proof : For every $b \in B$, $f^{-1}(b) := \{a \in A|f(a) = b\} \neq \emptyset$, since $f$ is surjective. Therefore, the set $f^{-1}(b)$ contains at least one element. For every $b \in B$, remove elements (if necessary) $a \in A$ such that $f^{-1}(b)$ becomes a singleton. Call the set of removed elements $R$. Then clearly $R \subset A$ and it follows that $f: A - R := T \subset A \to B$ is a bijection, since for any $b \in B$, there is only one element in the domain that gets mapped to $b \quad \triangle$ Applying the lemma to $f$ above, we find that there is a set $T \subset \mathbb{Z} \times \mathbb{Z_0}$ such that $|T| = |\mathbb{Q}|$ Since $\mathbb{Q}$ is infinite, $T$ is infinite. Also, $\mathbb{Z} \times \mathbb{Z_0}$ is countable, because it is the product of two countable sets and Rudin already proved that every infinite subset of a countable set is countable, so it must follow that $T$, and therefore $\mathbb{Q}$, is countable. Does this seem correct?","['elementary-set-theory', 'cardinals', 'functions', 'proof-verification']"
2357846,What is the expected total number of topological sorts in a Directed a cyclic graph with $n$ vertices?,"I know that a DAG with $n$ vertices can have $O(n!)$ topological sorts. However, I am interested in knowing the expected number of topological sorts in a randomly generated DAG?","['graph-theory', 'directed-graphs', 'random-graphs', 'probability', 'order-theory']"
2357899,The cartesian product of a finite amount of countable sets is countable.,"I want to prove that the cartesian product of a finite amount of countable sets is countable. I can use that the union of countable sets is countable. My attempt: Let $A_1,A_2, \dots, A_n$ be countable sets. We prove the statement by induction on $n$ For $n = 1$, the statement clearly holds, as $A_1$ is countable. Now, suppose that $B := A_1 \times A_2 \times \dots A_{n-1}$ is countable. We have: $$B \times A_n = \{(b,a)|b \in B, a \in A_n\}$$
$$= \bigcup_{a \in A_n} \{(b,a)|b \in B\}$$ and $\{(b,a)|b \in B\}$ is countable for a fixed $a \in A_n$, since the function $f_a: B \to B \times \{a\}: b \to (b,a)$ is a bijection, and $B$ is countable by induction hypothesis. Because the union of countable sets remains countable, we have proven that $(A_1 \times \dots A_{n-1}) \times A_n$ is countable, and because $f: (A_1 \times \dots A_{n-1}) \times B \to A_1 \times \dots A_{n-1} \times A_n: ((a_1, \dots, a_{n-1}),a_n) \mapsto (a_1, \dots, a_{n-1},a_n)$
is a bijection, the result follows. Questions: Is this proof correct/rigorous? Are there other proofs that are
  easier? Someone pointed out that we can prove this theorem using the
  'zigzag'-argument. Can someone provide this proof? I think this
  zigzag-method is too graphical, and therefore not rigorous, so if
  someone can clarify why this method is completely rigorous, I would be
  more than glad to award him the bonus.","['cardinals', 'elementary-set-theory', 'proof-verification']"
2357908,On group monomorphisms,"I read that in the category of groups every monomorphism is an equalizer. The proof I read uses the amalgamation property for groups, but I couldn't understand it. Is there an easier way to prove mono=equalizers in Grp category, or can someone explain me how to use amalgamation to prove that in simple words?","['category-theory', 'group-theory']"
2357953,Relationship between two hypergeometric functions,"Let $F(a, b, c, x)$ be the hypergeometric function. Suppose I can express $F(a, b, c, x)$ in finite terms, say in terms of $\Gamma$ functions, for various $x$ . Is there a way I can then deduce the value of $F(-a, b, c, x)$ ? For example, it is known that $$F\bigg(\frac{1}{2}, \frac{1}{2}, 1, \frac{1}{2}\bigg) = \frac{\Gamma(1/4)^2}{2\pi^{3/2}}.$$ Is there a way to use this result to deduce the value of $F(-1/2, 1/2, 1, 1/2)$ ? Likewise, it is known that $$F\left(\frac{1}{12}, \frac{5}{12}, 1, \Big(\frac{4}{85}\Big)^3\right) = \frac{\Gamma(1/7) \Gamma(2/7) \Gamma(4/7)}{8\pi^2} \frac{255^{1/4}}{7^{1/4}}.$$ Is there a way to use this result to deduce the value of $F(-1/12, 5/12, 1, {64/614125})$ ?","['elliptic-functions', 'sequences-and-series', 'hypergeometric-function', 'modular-forms', 'power-series']"
2357954,$(xyz)_b$ is divisible by $n$ if and only if $z+3y-4x$ is divisible by $n$,"Determine all natural numbers $n > 1$ with the following property: there exists a base $b \geq 5$ such that any three digit-number $(xyz)_b$ is divisible by $n$ if and only if $z+3y-4x$ is divisible by $n$. Suppose that $b$ is such a base for some $n$. Then $xb^2+yb+z \equiv z+3y-4x \pmod{n}$, so that $x(b^2+4)+y(b-3) \equiv 0 \pmod{n}$. How can we continue?",['number-theory']
2357966,Restriction map of sheaf of regular functions on open sets of irreducible variety is always injective?,"Let $X$ be an irreducible variety. Then any open set $U\subset X$ is dense. Thus $U$ is irreducible as topological space. Consider $O_X(U)$ sheaf of regular functions on $U$. If $U'\subset U$ is open in $U$, is $O_X(U)\to O_X(U')$ injective? I think it is the case, if $f\in O_X(U)$ is sent to $0\in O_X(U')$, then $f|_{U'}=0$. So $U'\subset V(f)$ and $U=(U-U')\cup V(f)$. Clearly $V(f)=U$ by $U$ irreducible. Thus $f|_U=0$. This is related to Extending regular function on normal variety from a subvariety of codimension 2 . In this post, @MooS Answer says we know $\cap_{ht(p)=1}A_p=A$ implies restriction map injectivity. However this theorem requires normal variety. An irreducible variety is always normal?","['abstract-algebra', 'general-topology', 'sheaf-theory', 'algebraic-geometry']"
2357986,Problem when reconstructing rotation from Euler angles,"I have a rotation matrix R: R=[[-0.22247682, -0.32863132, -0.91788099],
   [-0.01426572, -0.94027818,  0.34010798],
   [-0.9748336 ,  0.08876037,  0.20450194]] and I want to decompose this into three rotations, $R_Z(\alpha)R_X(\beta)R_Z(\gamma)$, where I consider clockwise rotations. The rotation matrix in terms of these Euler angles is then given by $R=$
\begin{bmatrix}
\cos\alpha\;\cos\gamma\;-\;\sin\alpha\;\cos\beta\;\sin\gamma & -\sin\gamma\;\cos\alpha\;-\;\sin\alpha\;\cos\beta\;\cos\gamma\; & \sin\alpha\;\sin\beta \\
\sin\alpha\;\cos\gamma\;+\;\sin\gamma\;\cos\alpha\;\cos\beta\; & -\sin\alpha\;\sin\gamma\;+\;\cos\alpha\;\cos\beta\;\cos\gamma & -\cos\alpha\;\sin\beta\\
\sin\beta\;\sin\gamma & \sin\beta\;\cos\gamma & \cos\beta\\
\end{bmatrix} Then, I calculate $\beta=\arccos(R_{33})=1.36$, $\alpha=\arctan(-R_{13}/R_{23})=1.22$, and $\gamma=\arctan(R_{31}/R_{32})=-1.48$. As a double check, I reconstruct the matrix R from these Euler angles, and find the following: R'=[[ 0.22247682,  0.32863132, -0.91788099],
    [ 0.01426572,  0.94027818,  0.34010798],
    [ 0.9748336 , -0.08876037,  0.20450194]]) I double checked everything, but I cannot find what the problem is. What could I be missing? Edit: It turns out the transpose problem was because my python code had some indexation problem. The sign issues still persist, however. I updated the matrix R' above.","['matrices', 'trigonometry', 'rotations']"
2357993,"Given $f^{\prime} = g , \, g^{\prime} = f$, Prove $f = \sinh, \, g = \cosh$","I'm having some trouble proving these rigorously Given $f, g\,\colon \mathbb{R} \to \mathbb{R}\,$ differentiable with $$f^{\prime} = g \quad \text{and}\quad g^{\prime} = f$$ First, if $f(0) = g(0) = 0$, Prove that $f = g = 0$ Second, if $f(0) = 0$, $\,g(0) = 1$, Prove that $f = \sinh$, $\,g = \cosh$ Any suggestions?","['derivatives', 'real-analysis', 'trigonometry']"
2358005,"Average number of ways to express number as a sum of $n$ squares goes to zero, why?","So I recently stumbled upon this beautiful problem: Show that the number $r_2(n)$ of representations of $n$ as a sum of two squares (of not neccesarily positive integers) has $\pi$ as its arithmetic mean, that is
  $$ \lim_{n\rightarrow \infty }\frac{1}{n}\sum_{i=0}^n r_2(i) = \pi$$ Now the proof remarks that every point of the unit two dimensional integer lattice $(x, y)$ is the solution to the equation $x^2+y^2=n$ for some $n$, and then if we look at all the lattice point satisfyting $x^2+y^2 \leq n$ we can bound this quantity by the area of a circle (with radius about $\sqrt{n}$), and thus gain the result. (This is a rough idea of the proof, it is by no means precise) Now we can extend this to the function $r_k(n)$ that counts the number of ways to express $n$ as the sum of $k$ squares. Now we simply take the $k$ dimensional lattice and bound it by $k$-spheres, and gain the average as the $k$-volume of the unit $k$-sphere. This quantity is given by:
$$\frac{\pi^{\frac{k}{2}}}{\Gamma(1+\frac{k}{2})}$$
where $\Gamma(n)$ is the gamma function. Now what is interesting about this is that the average tends to zero as the dimension grows to infinity. On the other hand, it is well known that any natural number can be expressed as the sum of four squares. Now since our definition of $r_k(n)$ counts all the ways to gain $n$, including those that allow $0^2$ as one of the summands (I assume this is true since in our lattice-counting proof we include all latice points, including those that have one or more coordinates zero), then it would be the case that solutions obtained for smaller dimension be valid in higher dimension as well (simply by setting on of the coordinates to zero). So we would expect that every number can be expressed in atleast one way for all $k\geq4$, meaning $r_k(n)\geq1$ for all $n$. However, this would mean that the average should be atleast one for all higher dimensions, but this contradicts that the volume goes to zero. Why is this? Is there some intuitive explanation? I have a sense that the infinite nature of the average is probably in some way misleading and my usual intuition that can be applied to finite averages. 
I have tried thinking of the limit also as an asymptotic bound of $\sum r_k(n)$ in terms of $c\cdot n$, but that doesnt help either.
There is also a possibility that there is some flaw in my proof (well, idea of proof as it is presented here). Maybe it is not the volume that I should be looking at?","['real-analysis', 'asymptotics', 'average', 'number-theory', 'geometry']"
2358016,$E[X\mid F_n] \to X$ almost surely,"I was reading on Convergence in distribution of conditional expectations Let $X$ be integrable on $(\Omega, \mathcal{F}, P)$ and assume $\mathcal{F}_n \uparrow \mathcal{F}$. Then, 
$$E(X \mid \mathcal{F}_n) \to X \ \ \text{a.s.}$$ And I was wondering if this is claim is true? Is it a well known fact? Has the theorem a name?",['probability-theory']
2358024,Integral $\int_{0}^{\infty}x^{-x}dx$,I'm trying to find a closed form for this integral:$$\int_{0}^{\infty}x^{-x}dx$$ Here's the integrand graph: Clearly it is convergent. My attempt is to obtain a closed form for the area under the curve. Is this possible?,"['improper-integrals', 'integration', 'definite-integrals', 'calculus']"
2358037,Kelly Criterion for simultaneous independent bets,"I'm trying to obtain a more generic version of the Kelly criterion for when we have simultaneous independent events to bet on, I'm going to focus on the case where we just have 2 different events. In the case where we have just one event the objective is to maximize the function: $$f(x) := p\log(1+bx-x) + (1-p)\log(1-x)$$ $b$ are the odds received and $x$ the fraction of our total wealth that we bet. In the case where we have two events to bet on, I suppose that the function to maximize would be of the form: $$p_1p_2\log(1+x_1b_1+x_2b_2 - x_1-x_2) + p_1(1-p_2)\log(1+x_1b_1- x_1-x_2)+(1-p_1)p_2\log(1+x_2b_2 - x_1-x_2)+(1-p_1)(1-p_2)\log(1- x_1-x_2)$$ As it is differentiable, the problem is equivalent to find the solution of the system of equations: $$p_1p_2\frac{b_1-1}{1+x_1b_1+x_2b_2 - x_1-x_2} + p_1(1-p_2)\frac{b_1-1}{1+x_1b_1- x_1-x_2}=(1-p_1)p_2\frac{1}{1+x_2b_2 - x_1-x_2}+(1-p_1)(1-p_2)\frac{1}{1- x_1-x_2}$$ $$p_1p_2\frac{b_2-1}{1+x_1b_1+x_2b_2 - x_1-x_2} + (1-p_1)p_2\frac{b_2-1}{1+x_2b_2 - x_1-x_2}=p_1(1-p_2)\frac{1}{1+x_1b_1- x_1-x_2}+(1-p_1)(1-p_2)\frac{1}{1- x_1-x_2}$$ However, this seems completely intractable to solve explicitly. I'm asking for your help to do it. Maybe there is some trick to solve it, or I'm not attacking it in the right way. Thank you in advance.","['expectation', 'probability', 'optimization', 'gambling']"
2358042,What Exactly is a Finite-Dimensional C$^{*}$-Algebra?,"I am aware that if $A$ is a finite-dimensional C$^{*}$-algebra, then $A$ is isomorphic to $$
M_{n_{1}}(\mathbb{C})\oplus\cdots\oplus M_{n_{k}}(\mathbb{C})
$$ for some positive integers $k$ and $n_{1},\ldots,n_{r}$. But what exactly is the precise definition of finite-dimensional here? Does it simply mean that there are finitely many $a_{1},\ldots,a_{m}$ with $A\cong C^{*}(a_{1},\ldots,a_{m})$? Silly question, I know, but thank you.","['functional-analysis', 'c-star-algebras', 'operator-algebras']"
2358043,Counterexample to Schmidt Decomposition for 3 systems,"Problem 2.77 in Nielsen and Chuang's book asks for an example of a pure state $|\psi\rangle$ in a three part composite space $A\otimes B\otimes C$ such that $|\psi\rangle$ has no Schmidt decomposition. So suppose I start with $|\psi\rangle = \sum_{i,j,k}c_{ijk}|i_A\rangle|j_B\rangle|k_C\rangle$ for orthonormal bases $|i_A\rangle, |j_B\rangle, |k_C\rangle$. The proof for 2 spaces involves taking the singular value decomposition of the coefficient matrix. So in the 3 space case, I could take the SVD of each matrix $C_k$ (defined as $(C_k)_{ij}=c_{ijk}$), but they might not all have the same SVD, and I think that causes the problem. Using that, my best guess for a counterexample would be a state like 
$$|\psi\rangle = (|00\rangle + |01\rangle +|10\rangle+|11\rangle)|0\rangle + (|00\rangle+|01\rangle - |10\rangle - |11\rangle)|1\rangle$$
(appropriately normalized), since the parts of the vector corresponding to the first two spaces can't be singular value decomposed with the same unitaries (I think). But I have no idea how to prove this: How do I know there isn't some crazy basis for the space $C$ that would still produce a Schmidt decomposition?","['matrices', 'tensor-products', 'linear-algebra', 'quantum-computation']"
2358046,Is there a scheme structure on the real line (with the cofinite topology)?,"One of the first conundrums one encounters when learning about schemes is that the affine real line $\mathbb{A}_\mathbb{R}^1 = \mathrm{Spec} \mathbb{R}[x]$ as a lot more points than the $x$-axis ""real line"" we know and love from, say, Euclidean geometry. These extra points aren't just generic points: there is a closed point in $\mathbb{A}_\mathbb{R}^1$ corresponding to every polynomial $f(x) \in \mathbb{R}[x]$, irreducible over $\mathbb{R}$ (we can thus think of $\mathbb{A}_\mathbb{R}^1$ as a quotient of the complex ""line"" $\mathbb{C}$ by the action of the conjugation automorphism $\sigma: \mathbb{C} \to \mathbb{C}: z \mapsto \overline{z}$). In many other fields, the topological space $\mathbb{R}$ (with the usual topology) is given status as a bona fide object, without extra points. My question is thus the following: Is there a scheme $X$, the set $X_\mathrm{cl}$ of closed points of which, with the topology induced from the Zariski topology, is homeomorphic to $\mathbb{R}$ with the cofinite topology? My intuition says ""no"", for what would the structure sheaf on such a scheme be (could it possibly be an $\mathbb{R}$-scheme?), but I have been unable to come up with a disproof.","['general-topology', 'algebraic-geometry']"
2358050,What constitutes the classification of functions into **elementary** and **non-elementary**?,"Stemming from a comment thread in another question I got curious about why exponential and trig functions are considered elementary but there are so very many other non-algebraic functions which are not.
Are there any particular motivations or is it something that becomes obvious when one has studied enough analysis? Is it the exponential functions relation to being eigenfunction to differentiation that is central to this choice or something else?","['elementary-functions', 'math-history', 'calculus', 'analysis']"
2358060,Finding Value of Pascal's Triangle Given Single Index,"I know that you can find the value of any number in Pascal's Triangle using the row and column with binomial coefficients, but cannot find a method to find the value given an index. For instance, a Pascal's Triangle with 5 rows looks like:
\begin{gather}
1\\
1 \quad 1\\
1 \quad 2 \quad 1\\
1 \quad 3 \quad 3 \quad 1\\
1 \quad 4 \quad 6 \quad 4 \quad 1
\end{gather} If you were to index this triangle, it would look like this:
\begin{gather}
00\\
01 \quad 02\\
03 \quad 04 \quad 05\\
06 \quad 07 \quad 08 \quad 09\\
10 \quad 11 \quad 12 \quad 13 \quad 14
\end{gather} Without using previous values or referencing the row and column, can you find the value at any given index?","['combinatorics', 'binomial-coefficients']"
2358069,Who was the first person that discovered that the icosahedron and the dodecahedron have 43380 unique nets?,"I'm trying to find out who was the first person that discovered that the icosahedron and the dodecahedron have 43380 unique (nonisomorphic) nets. Also, how was this number first discovered? By brute force enumeration or some clever argument was used? This article here lists two references, but I was unable to find them and, so, I'm unsure if they were the first to enumerate the unique nets and how the nets were counted. Bouzette, S., Vandamme, F.: The regular Dodecahedron and Icosahedron unfold
in 43380 ways (unpublished manuscript) Hippenmeyer, C.: Die Anzahl der inkongruenten ebenen Netze eines regulären
Ikosaeders. Elem. Math. 34, 61–63 (1979) Thanks, Humberto.","['combinatorics', 'math-history', 'geometry']"
2358082,Generate integer matrices with integer eigenvalues,"I want to generate $500$ random integer matrices with integer eigenvalues. Thanks to this post , I know how to generate a random matrix with whole eigenvalues: Generate a diagonal matrix $D$ with the desired (integer)
eigenvalues. Generate an invertible matrix $A$ of the same size as $D$. Record the matrix $A^{-1} D A$. However, the problem is that this generates a lot of float matrices, and I'd actually like to have both integer matrices and integer eigenvalues. The float values are introduced by A.inverse() . According to this post , inverse matrices have whole integer values only when the determinant of the original matrix is 1 or -1 (and therefore an orthogonal matrix). I tried using the C++ library AlgLib, which has a rmatrixrndorthogonal function that uses G.W. Stewart's 1980 algorithm to generate a random uniformly distributed (Haar) orthogonal matrix. I also tried using R 's pracma library, which has a randortho function that also generates orthogonal matrices. However, both functions generate matrices with float values. Is there a way for me to generate orthogonal, integer matrices?","['eigenvalues-eigenvectors', 'random-matrices', 'matrices', 'orthogonal-matrices', 'linear-algebra']"
2358091,Imaginary $\delta$ in proof of continuity,"Define $f: \mathbb R^2 \to \mathbb R$ as
  $$f(x_1,x_2)=x_1+x_2$$
  Prove that $f$ is continuous where the distance function on $\mathbb R^2$ is
  $$d'(x,a)=\sqrt{(x_1-a_1)^2+(x_2-a_2)^2}$$ I went about proving this using the $\delta$ - $\epsilon$ definition of continuity. I chose $\delta=\sqrt{\epsilon-1}$. Then, given that
$$d'(x,a)\lt \delta$$
I need to derive
$$|f(x_1,x_2)-f(a_1,a_2)|\lt \epsilon$$
My derivation went like this:
$$d'(x,a)\lt \delta$$
$$\sqrt{(x_1-a_1)^2+(x_2-a_2)^2}\lt \sqrt{\epsilon-1}$$
$$(x_1-a_1)^2+(x_2-a_2)^2\lt \epsilon-1$$
Then, by a variation of the triangle inequality,
$$(x_1-a_1+x_2-a_2)^2\lt \epsilon-1$$
$$(x_1-a_1+x_2-a_2)^2+1\lt \epsilon$$
Then, using the fact that $n^2+1 \gt |x|$, 
$$|x_1+x_2-a_1-a_2|\lt \epsilon$$
$$|f(x_1,x_2)-f(a_1,a_2)|\lt \epsilon$$
And so the continuity of the function is proven. My question is this: since I let
$$\delta=\sqrt{\epsilon-1}$$
it must be that when $\epsilon \lt 1$, $\delta$ is imaginary. Is this a problem, or is the proof still valid? Do you see any other flaws in it? Thanks!","['real-analysis', 'proof-verification', 'continuity', 'epsilon-delta', 'general-topology']"
2358119,Quotient rule/Quotient rule,"\begin{align}
& f(x)^2 \frac d {dx}\, \frac{g(x)}{f(x)} = f(x)g'(x) - f'(x)g(x). \tag 0 \\[10pt]
& g(x)^2 \frac d {dx}\, \frac{f(x)}{g(x)} = g(x)f'(x) - g'(x)f(x). \tag 0 \\[10pt]
\text{Therefore } & f(x)^2 \frac d {dx}\, \frac{g(x)}{f(x)} + g(x)^2 \frac d {dx}\, \frac{f(x)}{g(x)} = 0. \tag 1
\end{align}
If one had never heard of the quotient rule, one could of course prove $(1)$ by an argument paralleling the sort used to prove the quotient rule, or by first proving the quotient rule and deducing $(1)$ as a corollary (the latter option being of course what I did). But: Is there some natural interpretation of the right side of $(0)$, perhaps not relating it to the left side? (Maybe this part is the main point of this question.) Is there a quick intuitive argument for $(1)$ -- thus a simpler argument than any that proves the quotient rule or does something paralleling that proof? Similarly for the left side of $(0)$? Perhaps we should note that $(0)$ is weaker than the quotient rule in that it does not imply differentiability of the quotient, but rather it assumes it.","['derivatives', 'calculus']"
2358135,Examples of diagonal line segments in $\mathbb{R}^2$ that contain no rational points?,"I know we can have a vertical line , something like $(\pi, y)$ for $y$ in some interval, or a horizontal line, something like $(x, \pi)$ for $x$ in some interval, that contains no points $(q_1, q_2)$ s.t. $q_1, q_2 \in \mathbb{Q}$. I believe that it is possible to have a (continuous, straight) diagonal line segment that has no rational points (mostly because I am unable to prove otherwise!). Are there any examples of a line like this?","['real-numbers', 'irrational-numbers', 'rational-numbers', 'geometry', 'general-topology']"
2358216,There is an analytic set in $\mathscr N$ that is not Borel.,"Let $\mathbb N^{\mathbb N}=\mathscr N,$ and $A$ a subset of the Polish space, $X.\ A$ is said to be analytic if it is the continuous image of a function from a Polish space. A standard result is that a subset $A$ of $X$ is analytic if and only if there is a closed subset of $\mathscr N ×X$ whose projection on $X$ is $A.$ We also have that if $X$ is Polish, then the closed sets in $X$ may be indexed by $\mathscr N,$ which is to say there is a closed subset $A$ of $\mathscr N\times X $ such that the closed sets in $X$ are precisely the sections $A_{\bf n}=\left \{ x\in X:(\textbf{n},x)\in A \right \}$ The exercise is to show that there exists an analytic set that is not Borel, and the hint is to consider the projection $\mathscr N\times \mathscr N\times X\to \mathscr N\times X;\ (\textbf{m},\textbf{n},x)\to (\textbf{m},x)$, to show that the analytic sets in $X$ may also be indexed by $\mathscr N$. Here is my attempt, with the questions in italics: To start, note that there is a closed subset $S$, of $\mathscr N\times \mathscr N\times X$ such that $\left \{ S_{\textbf{n}} \right \}_{\textbf{n}}$ constitutes the closed sets of $\mathscr N\times X.$ Furthermore, the map $\pi:(\textbf{m},\textbf{n},x)\mapsto (\textbf{m},x)$ is continuous so its image is analytic because $\mathscr N\times \mathscr N\times X$ is Polish. Let $A$ be the image of this map and consider the sections $A_{\bf m}.$ We can define the projection $\pi_1:S_{\textbf{m}}\to A_{\bf m}$ by $(\textbf{n},x)\mapsto x$ so that each $A_{\textbf{m}}$ is the projection from $\mathscr N\times X$ of the closed set $S_{\textbf{m}}$ and therefore is analytic. On the other hand, if $A'$ is analytic, then it is the projection of some closed set in $\mathscr N\times X$, which in turn,  must be one of the $S_{\bf m}.$ This proves the claim in the hint. Is  the  foregoing rigorous enough? If not, can you suggest how to make it so? From here, it's a standard argument but I ran into a snag: There is an analytic subset $S$ of $\mathscr N\times \mathscr N$ such that the analytic sets in $\mathscr N$ are precisely the sections $S_{\textbf{n}}.$ Now define $D=\left \{ \textbf {n}:(\textbf {n},\textbf {n})\in S \right \}.$ Now I want to claim that $D$ is analytic because it is the projection on $\mathscr N$ of the closed set  $S\cap \left \{ (\textbf n,\textbf m):m=n \right \}.$ But I can't show this set is closed. edit: the set is not necessarily closed but it is analytic, being the intersection of two analytic sets. So the proof proceeds. If $D$ is Borel, then so is $\mathscr N\setminus D$, which, by a routine argument, is seen to be analytic. So there must be an $\textbf i$ for which $S_{\textbf i}=\mathscr N\setminus D.$ Now, if $\textbf i\in D$ then $\textbf i\in S_{\textbf i},$ which is a contradiction. Symmetry shows that if we assume that $\textbf i\in \mathscr N\setminus D,$ we reach impossible conclusion that $\textbf i\in D.$ And this finishes the proof.","['real-analysis', 'descriptive-set-theory', 'proof-writing', 'measure-theory', 'general-topology']"
2358241,Compute the distance from a point in $\textbf{R}^3$ to Boy's surface,"We're given a parametric surface $S\subset\textbf{R}^3$, and an arbitrary $\boldsymbol x\in\textbf{R}^3$ where $\boldsymbol x := (x_1,x_2,x_3)$. We'd like to compute the distance from $\boldsymbol x$ to $S$. Note. By distance I mean smallest (Euclidean) distance . Example. Let $S\subset\textbf{R}^3$ be the image of the map $$
\begin{align}
[0;2\pi] \times [0;\pi] & \longrightarrow \textbf{R}^3 \\
(\theta, \varphi) & \longmapsto (s_1, s_2, s_3) \\
(\theta, \varphi) & \longmapsto (\cos(\theta)\sin(\varphi),\ \sin(\theta)\sin(\varphi),\ \cos(\varphi))
\end{align}
$$ (ie. $S$ is the unit sphere centered at $\boldsymbol 0\in\textbf{R}^3$). Then the (smallest Euclidean) distance $d$ from $\boldsymbol x \in \textbf{R}^3$ to $S\subset\textbf{R}^3$, is (I think) $$ d = |\boldsymbol x - \boldsymbol 0| - 1 = |\boldsymbol x| - 1,$$ where $|\boldsymbol a|$ is the norm of $\boldsymbol a$. The case of interest is the distance from $\boldsymbol x\in\textbf{R}^3$ to the Kusner-Bryant parametrization of Boy's surface (an immersion of $\textbf{R}P^2$ inside $\textbf{R}^3$), which is a function of a complex parameter $w\in\textbf{C}$ in the complex unit disk $\textbf{D}$ (ie. $|w| \leq 1$). Now $S\subset\textbf{R}^3$ is the image of the map $$
\begin{align}
\textbf{D}\subset\textbf{C} & \longrightarrow \textbf{R}^3 \\
w & \longmapsto (s_1, s_2, s_3) \\
w & \longmapsto (gg_1, gg_2, gg_3)
\end{align}
$$ where $$
\begin{align}
g1 & := -{3 \over 2} \text{Im}\left[{w(1-w^4) \over g_4}\right] \\
g2 & := -{3 \over 2} \text{Re}\left[{w(1+w^4) \over g_4}\right] \\
g3 & := \text{Im}\left[{1 + w^6 \over g_4}\right] - {1 \over 2} \\
g4 & := w^3(w^3 + \sqrt5) - 1\\
g & := {1 \over g_1^2 + g_2^2 + g_3^2}
\end{align}
$$ What is an expression for the distance from $\boldsymbol x$ to $S$? (An application of this is to render the surface )","['optimization', 'calculus', 'multivariable-calculus', 'differential-geometry', 'linear-algebra']"
2358331,Can anybody solve the following using binomial theorem?,"If $x,y \in\mathbb{R}$ such that $x^2 + y^2 - 6x + 8y + 24 = 0$ then what is the greatest value of $$\frac{16\cos^2(\sqrt{x^2+y^2})}{5} - \frac{24\sin(\sqrt{x^2+y^2})}{5}?$$","['algebra-precalculus', 'binomial-theorem']"
2358352,How to rescale the length of a price series?,"The question is about an equation coming from a scientific paper which i find it hard to reproduce. But the problem is as follows: A range of window lengths varying from twenty days to sixty days are considered. Let l denote the window length, L denote the price series length and i denote an index in price series. For each window length between i and i + l days, where index i ranges from the beginning of price series to L - l - 1 (inclusive range). The price list observed between days [i, i + l] is scaled to a new price list with 20 elements. The price series length scaling is performed using the following equation. Rescaling is analogous to resizing the price series length to 20 days. Price for day j in actual price series becomes the price on day dj in rescaled price series where dj is given by the following equation. Price for days between dj and dj+1 are interpolated. Given the following price list , how would this formula be applied in for example Excel? I tried to reproduce the result but i get some really weird numbers, so i wonder if someone can help apply this formula for the given price table list +-----+--------+
| Day | Price  |
+-----+--------+
|   1 |   86.5 |
|   2 |  84.76 |
|   3 |   78.7 |
|   4 |  71.21 |
|   5 |  79.84 |
|   6 |  72.83 |
|   7 |  73.01 |
|   8 |  67.42 |
|   9 |  75.79 |
|  10 |  73.52 |
|  11 |  77.61 |
|  12 |  71.43 |
|  13 |  66.81 |
|  14 |  66.54 |
|  15 |  69.44 |
|  16 |  63.33 |
|  17 |  64.73 |
|  18 |  61.14 |
|  19 |  67.52 |
|  20 |  71.12 |
|  21 |  63.93 |
|  22 |  66.59 |
|  23 |  63.78 |
|  24 |  66.65 |
|  25 |  63.34 |
|  26 |  71.13 |
|  27 |  74.63 |
|  28 |  67.08 |
|  29 |  60.44 |
|  30 |  60.87 |
|  31 |  66.35 |
|  32 |  67.53 |
|  33 |  69.62 |
|  34 |  73.98 |
|  35 |  79.52 |
|  36 |  86.74 |
|  37 |   87.9 |
|  38 |  82.19 |
|  39 |  84.98 |
|  40 |  80.11 |
|  41 |  80.69 |
|  42 |  81.28 |
|  43 |  85.92 |
|  44 |  95.83 |
|  45 |  98.66 |
|  46 |  96.84 |
|  47 |  100.3 |
|  48 | 101.91 |
|  49 | 108.97 |
|  50 | 116.54 |
|  51 | 119.52 |
|  52 | 124.37 |
|  53 | 130.74 |
|  54 | 136.83 |
|  55 | 140.88 |
|  56 | 140.68 |
|  57 | 142.73 |
|  58 | 135.58 |
|  59 | 144.65 |
|  60 |  150.3 |
+-----+--------+ The result should be 40 windows with rescaled prices to 20 elements each. The equation is a linear interpolator that rescales the series over interval L elements to one over 20 elements. So basically taking all the prices after the 20th element in the price series and rescale that new list to a 20 elements list. 
Here is the same table with the windows it should rescale. I created a simple excel file here with the following table: +-----------+--------------------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
|           | windows length (l) |  21   |  22   |  23   |  24   |  25   |  26   |  27   |  28   |  29   |  30   |  31   |  32   |  33   |  34   |  35   |  36   |  37   |  38   |  39   |  40   |  41   |  42   |  43   |  44   |  45   |  46   |  47   |   48   |   49   |   50   |   51   |   52   |   53   |   54   |   55   |   56   |   57   |   58   |   59   |   60   |
+-----------+--------------------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
| Index (i) | Price              |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |        |        |        |        |        |        |        |        |        |        |        |        |        |
| 1         | 86.5               |  86.5 |  86.5 |  86.5 |  86.5 |  86.5 |  86.5 |  86.5 |  86.5 |  86.5 |  86.5 |  86.5 |  86.5 |  86.5 |  86.5 |  86.5 |  86.5 |  86.5 |  86.5 |  86.5 |  86.5 |  86.5 |  86.5 |  86.5 |  86.5 |  86.5 |  86.5 |  86.5 |   86.5 |   86.5 |   86.5 |   86.5 |   86.5 |   86.5 |   86.5 |   86.5 |   86.5 |   86.5 |   86.5 |   86.5 |   86.5 |
| 2         | 84.76              | 84.76 | 84.76 | 84.76 | 84.76 | 84.76 | 84.76 | 84.76 | 84.76 | 84.76 | 84.76 | 84.76 | 84.76 | 84.76 | 84.76 | 84.76 | 84.76 | 84.76 | 84.76 | 84.76 | 84.76 | 84.76 | 84.76 | 84.76 | 84.76 | 84.76 | 84.76 | 84.76 |  84.76 |  84.76 |  84.76 |  84.76 |  84.76 |  84.76 |  84.76 |  84.76 |  84.76 |  84.76 |  84.76 |  84.76 |  84.76 |
| 3         | 78.7               |  78.7 |  78.7 |  78.7 |  78.7 |  78.7 |  78.7 |  78.7 |  78.7 |  78.7 |  78.7 |  78.7 |  78.7 |  78.7 |  78.7 |  78.7 |  78.7 |  78.7 |  78.7 |  78.7 |  78.7 |  78.7 |  78.7 |  78.7 |  78.7 |  78.7 |  78.7 |  78.7 |   78.7 |   78.7 |   78.7 |   78.7 |   78.7 |   78.7 |   78.7 |   78.7 |   78.7 |   78.7 |   78.7 |   78.7 |   78.7 |
| 4         | 71.21              | 71.21 | 71.21 | 71.21 | 71.21 | 71.21 | 71.21 | 71.21 | 71.21 | 71.21 | 71.21 | 71.21 | 71.21 | 71.21 | 71.21 | 71.21 | 71.21 | 71.21 | 71.21 | 71.21 | 71.21 | 71.21 | 71.21 | 71.21 | 71.21 | 71.21 | 71.21 | 71.21 |  71.21 |  71.21 |  71.21 |  71.21 |  71.21 |  71.21 |  71.21 |  71.21 |  71.21 |  71.21 |  71.21 |  71.21 |  71.21 |
| 5         | 79.84              | 79.84 | 79.84 | 79.84 | 79.84 | 79.84 | 79.84 | 79.84 | 79.84 | 79.84 | 79.84 | 79.84 | 79.84 | 79.84 | 79.84 | 79.84 | 79.84 | 79.84 | 79.84 | 79.84 | 79.84 | 79.84 | 79.84 | 79.84 | 79.84 | 79.84 | 79.84 | 79.84 |  79.84 |  79.84 |  79.84 |  79.84 |  79.84 |  79.84 |  79.84 |  79.84 |  79.84 |  79.84 |  79.84 |  79.84 |  79.84 |
| 6         | 72.83              | 72.83 | 72.83 | 72.83 | 72.83 | 72.83 | 72.83 | 72.83 | 72.83 | 72.83 | 72.83 | 72.83 | 72.83 | 72.83 | 72.83 | 72.83 | 72.83 | 72.83 | 72.83 | 72.83 | 72.83 | 72.83 | 72.83 | 72.83 | 72.83 | 72.83 | 72.83 | 72.83 |  72.83 |  72.83 |  72.83 |  72.83 |  72.83 |  72.83 |  72.83 |  72.83 |  72.83 |  72.83 |  72.83 |  72.83 |  72.83 |
| 7         | 73.01              | 73.01 | 73.01 | 73.01 | 73.01 | 73.01 | 73.01 | 73.01 | 73.01 | 73.01 | 73.01 | 73.01 | 73.01 | 73.01 | 73.01 | 73.01 | 73.01 | 73.01 | 73.01 | 73.01 | 73.01 | 73.01 | 73.01 | 73.01 | 73.01 | 73.01 | 73.01 | 73.01 |  73.01 |  73.01 |  73.01 |  73.01 |  73.01 |  73.01 |  73.01 |  73.01 |  73.01 |  73.01 |  73.01 |  73.01 |  73.01 |
| 8         | 67.42              | 67.42 | 67.42 | 67.42 | 67.42 | 67.42 | 67.42 | 67.42 | 67.42 | 67.42 | 67.42 | 67.42 | 67.42 | 67.42 | 67.42 | 67.42 | 67.42 | 67.42 | 67.42 | 67.42 | 67.42 | 67.42 | 67.42 | 67.42 | 67.42 | 67.42 | 67.42 | 67.42 |  67.42 |  67.42 |  67.42 |  67.42 |  67.42 |  67.42 |  67.42 |  67.42 |  67.42 |  67.42 |  67.42 |  67.42 |  67.42 |
| 9         | 75.79              | 75.79 | 75.79 | 75.79 | 75.79 | 75.79 | 75.79 | 75.79 | 75.79 | 75.79 | 75.79 | 75.79 | 75.79 | 75.79 | 75.79 | 75.79 | 75.79 | 75.79 | 75.79 | 75.79 | 75.79 | 75.79 | 75.79 | 75.79 | 75.79 | 75.79 | 75.79 | 75.79 |  75.79 |  75.79 |  75.79 |  75.79 |  75.79 |  75.79 |  75.79 |  75.79 |  75.79 |  75.79 |  75.79 |  75.79 |  75.79 |
| 10        | 73.52              | 73.52 | 73.52 | 73.52 | 73.52 | 73.52 | 73.52 | 73.52 | 73.52 | 73.52 | 73.52 | 73.52 | 73.52 | 73.52 | 73.52 | 73.52 | 73.52 | 73.52 | 73.52 | 73.52 | 73.52 | 73.52 | 73.52 | 73.52 | 73.52 | 73.52 | 73.52 | 73.52 |  73.52 |  73.52 |  73.52 |  73.52 |  73.52 |  73.52 |  73.52 |  73.52 |  73.52 |  73.52 |  73.52 |  73.52 |  73.52 |
| 11        | 77.61              | 77.61 | 77.61 | 77.61 | 77.61 | 77.61 | 77.61 | 77.61 | 77.61 | 77.61 | 77.61 | 77.61 | 77.61 | 77.61 | 77.61 | 77.61 | 77.61 | 77.61 | 77.61 | 77.61 | 77.61 | 77.61 | 77.61 | 77.61 | 77.61 | 77.61 | 77.61 | 77.61 |  77.61 |  77.61 |  77.61 |  77.61 |  77.61 |  77.61 |  77.61 |  77.61 |  77.61 |  77.61 |  77.61 |  77.61 |  77.61 |
| 12        | 71.43              | 71.43 | 71.43 | 71.43 | 71.43 | 71.43 | 71.43 | 71.43 | 71.43 | 71.43 | 71.43 | 71.43 | 71.43 | 71.43 | 71.43 | 71.43 | 71.43 | 71.43 | 71.43 | 71.43 | 71.43 | 71.43 | 71.43 | 71.43 | 71.43 | 71.43 | 71.43 | 71.43 |  71.43 |  71.43 |  71.43 |  71.43 |  71.43 |  71.43 |  71.43 |  71.43 |  71.43 |  71.43 |  71.43 |  71.43 |  71.43 |
| 13        | 66.81              | 66.81 | 66.81 | 66.81 | 66.81 | 66.81 | 66.81 | 66.81 | 66.81 | 66.81 | 66.81 | 66.81 | 66.81 | 66.81 | 66.81 | 66.81 | 66.81 | 66.81 | 66.81 | 66.81 | 66.81 | 66.81 | 66.81 | 66.81 | 66.81 | 66.81 | 66.81 | 66.81 |  66.81 |  66.81 |  66.81 |  66.81 |  66.81 |  66.81 |  66.81 |  66.81 |  66.81 |  66.81 |  66.81 |  66.81 |  66.81 |
| 14        | 66.54              | 66.54 | 66.54 | 66.54 | 66.54 | 66.54 | 66.54 | 66.54 | 66.54 | 66.54 | 66.54 | 66.54 | 66.54 | 66.54 | 66.54 | 66.54 | 66.54 | 66.54 | 66.54 | 66.54 | 66.54 | 66.54 | 66.54 | 66.54 | 66.54 | 66.54 | 66.54 | 66.54 |  66.54 |  66.54 |  66.54 |  66.54 |  66.54 |  66.54 |  66.54 |  66.54 |  66.54 |  66.54 |  66.54 |  66.54 |  66.54 |
| 15        | 69.44              | 69.44 | 69.44 | 69.44 | 69.44 | 69.44 | 69.44 | 69.44 | 69.44 | 69.44 | 69.44 | 69.44 | 69.44 | 69.44 | 69.44 | 69.44 | 69.44 | 69.44 | 69.44 | 69.44 | 69.44 | 69.44 | 69.44 | 69.44 | 69.44 | 69.44 | 69.44 | 69.44 |  69.44 |  69.44 |  69.44 |  69.44 |  69.44 |  69.44 |  69.44 |  69.44 |  69.44 |  69.44 |  69.44 |  69.44 |  69.44 |
| 16        | 63.33              | 63.33 | 63.33 | 63.33 | 63.33 | 63.33 | 63.33 | 63.33 | 63.33 | 63.33 | 63.33 | 63.33 | 63.33 | 63.33 | 63.33 | 63.33 | 63.33 | 63.33 | 63.33 | 63.33 | 63.33 | 63.33 | 63.33 | 63.33 | 63.33 | 63.33 | 63.33 | 63.33 |  63.33 |  63.33 |  63.33 |  63.33 |  63.33 |  63.33 |  63.33 |  63.33 |  63.33 |  63.33 |  63.33 |  63.33 |  63.33 |
| 17        | 64.73              | 64.73 | 64.73 | 64.73 | 64.73 | 64.73 | 64.73 | 64.73 | 64.73 | 64.73 | 64.73 | 64.73 | 64.73 | 64.73 | 64.73 | 64.73 | 64.73 | 64.73 | 64.73 | 64.73 | 64.73 | 64.73 | 64.73 | 64.73 | 64.73 | 64.73 | 64.73 | 64.73 |  64.73 |  64.73 |  64.73 |  64.73 |  64.73 |  64.73 |  64.73 |  64.73 |  64.73 |  64.73 |  64.73 |  64.73 |  64.73 |
| 18        | 61.14              | 61.14 | 61.14 | 61.14 | 61.14 | 61.14 | 61.14 | 61.14 | 61.14 | 61.14 | 61.14 | 61.14 | 61.14 | 61.14 | 61.14 | 61.14 | 61.14 | 61.14 | 61.14 | 61.14 | 61.14 | 61.14 | 61.14 | 61.14 | 61.14 | 61.14 | 61.14 | 61.14 |  61.14 |  61.14 |  61.14 |  61.14 |  61.14 |  61.14 |  61.14 |  61.14 |  61.14 |  61.14 |  61.14 |  61.14 |  61.14 |
| 19        | 67.52              | 67.52 | 67.52 | 67.52 | 67.52 | 67.52 | 67.52 | 67.52 | 67.52 | 67.52 | 67.52 | 67.52 | 67.52 | 67.52 | 67.52 | 67.52 | 67.52 | 67.52 | 67.52 | 67.52 | 67.52 | 67.52 | 67.52 | 67.52 | 67.52 | 67.52 | 67.52 | 67.52 |  67.52 |  67.52 |  67.52 |  67.52 |  67.52 |  67.52 |  67.52 |  67.52 |  67.52 |  67.52 |  67.52 |  67.52 |  67.52 |
| 20        | 71.12              | 71.12 | 71.12 | 71.12 | 71.12 | 71.12 | 71.12 | 71.12 | 71.12 | 71.12 | 71.12 | 71.12 | 71.12 | 71.12 | 71.12 | 71.12 | 71.12 | 71.12 | 71.12 | 71.12 | 71.12 | 71.12 | 71.12 | 71.12 | 71.12 | 71.12 | 71.12 | 71.12 |  71.12 |  71.12 |  71.12 |  71.12 |  71.12 |  71.12 |  71.12 |  71.12 |  71.12 |  71.12 |  71.12 |  71.12 |  71.12 |
| 21        | 63.93              | 63.93 | 63.93 | 63.93 | 63.93 | 63.93 | 63.93 | 63.93 | 63.93 | 63.93 | 63.93 | 63.93 | 63.93 | 63.93 | 63.93 | 63.93 | 63.93 | 63.93 | 63.93 | 63.93 | 63.93 | 63.93 | 63.93 | 63.93 | 63.93 | 63.93 | 63.93 | 63.93 |  63.93 |  63.93 |  63.93 |  63.93 |  63.93 |  63.93 |  63.93 |  63.93 |  63.93 |  63.93 |  63.93 |  63.93 |  63.93 |
| 22        | 66.59              |       | 66.59 | 66.59 | 66.59 | 66.59 | 66.59 | 66.59 | 66.59 | 66.59 | 66.59 | 66.59 | 66.59 | 66.59 | 66.59 | 66.59 | 66.59 | 66.59 | 66.59 | 66.59 | 66.59 | 66.59 | 66.59 | 66.59 | 66.59 | 66.59 | 66.59 | 66.59 |  66.59 |  66.59 |  66.59 |  66.59 |  66.59 |  66.59 |  66.59 |  66.59 |  66.59 |  66.59 |  66.59 |  66.59 |  66.59 |
| 23        | 63.78              |       |       | 63.78 | 63.78 | 63.78 | 63.78 | 63.78 | 63.78 | 63.78 | 63.78 | 63.78 | 63.78 | 63.78 | 63.78 | 63.78 | 63.78 | 63.78 | 63.78 | 63.78 | 63.78 | 63.78 | 63.78 | 63.78 | 63.78 | 63.78 | 63.78 | 63.78 |  63.78 |  63.78 |  63.78 |  63.78 |  63.78 |  63.78 |  63.78 |  63.78 |  63.78 |  63.78 |  63.78 |  63.78 |  63.78 |
| 24        | 66.65              |       |       |       | 66.65 | 66.65 | 66.65 | 66.65 | 66.65 | 66.65 | 66.65 | 66.65 | 66.65 | 66.65 | 66.65 | 66.65 | 66.65 | 66.65 | 66.65 | 66.65 | 66.65 | 66.65 | 66.65 | 66.65 | 66.65 | 66.65 | 66.65 | 66.65 |  66.65 |  66.65 |  66.65 |  66.65 |  66.65 |  66.65 |  66.65 |  66.65 |  66.65 |  66.65 |  66.65 |  66.65 |  66.65 |
| 25        | 63.34              |       |       |       |       | 63.34 | 63.34 | 63.34 | 63.34 | 63.34 | 63.34 | 63.34 | 63.34 | 63.34 | 63.34 | 63.34 | 63.34 | 63.34 | 63.34 | 63.34 | 63.34 | 63.34 | 63.34 | 63.34 | 63.34 | 63.34 | 63.34 | 63.34 |  63.34 |  63.34 |  63.34 |  63.34 |  63.34 |  63.34 |  63.34 |  63.34 |  63.34 |  63.34 |  63.34 |  63.34 |  63.34 |
| 26        | 71.13              |       |       |       |       |       | 71.13 | 71.13 | 71.13 | 71.13 | 71.13 | 71.13 | 71.13 | 71.13 | 71.13 | 71.13 | 71.13 | 71.13 | 71.13 | 71.13 | 71.13 | 71.13 | 71.13 | 71.13 | 71.13 | 71.13 | 71.13 | 71.13 |  71.13 |  71.13 |  71.13 |  71.13 |  71.13 |  71.13 |  71.13 |  71.13 |  71.13 |  71.13 |  71.13 |  71.13 |  71.13 |
| 27        | 74.63              |       |       |       |       |       |       | 74.63 | 74.63 | 74.63 | 74.63 | 74.63 | 74.63 | 74.63 | 74.63 | 74.63 | 74.63 | 74.63 | 74.63 | 74.63 | 74.63 | 74.63 | 74.63 | 74.63 | 74.63 | 74.63 | 74.63 | 74.63 |  74.63 |  74.63 |  74.63 |  74.63 |  74.63 |  74.63 |  74.63 |  74.63 |  74.63 |  74.63 |  74.63 |  74.63 |  74.63 |
| 28        | 67.08              |       |       |       |       |       |       |       | 67.08 | 67.08 | 67.08 | 67.08 | 67.08 | 67.08 | 67.08 | 67.08 | 67.08 | 67.08 | 67.08 | 67.08 | 67.08 | 67.08 | 67.08 | 67.08 | 67.08 | 67.08 | 67.08 | 67.08 |  67.08 |  67.08 |  67.08 |  67.08 |  67.08 |  67.08 |  67.08 |  67.08 |  67.08 |  67.08 |  67.08 |  67.08 |  67.08 |
| 29        | 60.44              |       |       |       |       |       |       |       |       | 60.44 | 60.44 | 60.44 | 60.44 | 60.44 | 60.44 | 60.44 | 60.44 | 60.44 | 60.44 | 60.44 | 60.44 | 60.44 | 60.44 | 60.44 | 60.44 | 60.44 | 60.44 | 60.44 |  60.44 |  60.44 |  60.44 |  60.44 |  60.44 |  60.44 |  60.44 |  60.44 |  60.44 |  60.44 |  60.44 |  60.44 |  60.44 |
| 30        | 60.87              |       |       |       |       |       |       |       |       |       | 60.87 | 60.87 | 60.87 | 60.87 | 60.87 | 60.87 | 60.87 | 60.87 | 60.87 | 60.87 | 60.87 | 60.87 | 60.87 | 60.87 | 60.87 | 60.87 | 60.87 | 60.87 |  60.87 |  60.87 |  60.87 |  60.87 |  60.87 |  60.87 |  60.87 |  60.87 |  60.87 |  60.87 |  60.87 |  60.87 |  60.87 |
| 31        | 66.35              |       |       |       |       |       |       |       |       |       |       | 66.35 | 66.35 | 66.35 | 66.35 | 66.35 | 66.35 | 66.35 | 66.35 | 66.35 | 66.35 | 66.35 | 66.35 | 66.35 | 66.35 | 66.35 | 66.35 | 66.35 |  66.35 |  66.35 |  66.35 |  66.35 |  66.35 |  66.35 |  66.35 |  66.35 |  66.35 |  66.35 |  66.35 |  66.35 |  66.35 |
| 32        | 67.53              |       |       |       |       |       |       |       |       |       |       |       | 67.53 | 67.53 | 67.53 | 67.53 | 67.53 | 67.53 | 67.53 | 67.53 | 67.53 | 67.53 | 67.53 | 67.53 | 67.53 | 67.53 | 67.53 | 67.53 |  67.53 |  67.53 |  67.53 |  67.53 |  67.53 |  67.53 |  67.53 |  67.53 |  67.53 |  67.53 |  67.53 |  67.53 |  67.53 |
| 33        | 69.62              |       |       |       |       |       |       |       |       |       |       |       |       | 69.62 | 69.62 | 69.62 | 69.62 | 69.62 | 69.62 | 69.62 | 69.62 | 69.62 | 69.62 | 69.62 | 69.62 | 69.62 | 69.62 | 69.62 |  69.62 |  69.62 |  69.62 |  69.62 |  69.62 |  69.62 |  69.62 |  69.62 |  69.62 |  69.62 |  69.62 |  69.62 |  69.62 |
| 34        | 73.98              |       |       |       |       |       |       |       |       |       |       |       |       |       | 73.98 | 73.98 | 73.98 | 73.98 | 73.98 | 73.98 | 73.98 | 73.98 | 73.98 | 73.98 | 73.98 | 73.98 | 73.98 | 73.98 |  73.98 |  73.98 |  73.98 |  73.98 |  73.98 |  73.98 |  73.98 |  73.98 |  73.98 |  73.98 |  73.98 |  73.98 |  73.98 |
| 35        | 79.52              |       |       |       |       |       |       |       |       |       |       |       |       |       |       | 79.52 | 79.52 | 79.52 | 79.52 | 79.52 | 79.52 | 79.52 | 79.52 | 79.52 | 79.52 | 79.52 | 79.52 | 79.52 |  79.52 |  79.52 |  79.52 |  79.52 |  79.52 |  79.52 |  79.52 |  79.52 |  79.52 |  79.52 |  79.52 |  79.52 |  79.52 |
| 36        | 86.74              |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       | 86.74 | 86.74 | 86.74 | 86.74 | 86.74 | 86.74 | 86.74 | 86.74 | 86.74 | 86.74 | 86.74 | 86.74 |  86.74 |  86.74 |  86.74 |  86.74 |  86.74 |  86.74 |  86.74 |  86.74 |  86.74 |  86.74 |  86.74 |  86.74 |  86.74 |
| 37        | 87.9               |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |  87.9 |  87.9 |  87.9 |  87.9 |  87.9 |  87.9 |  87.9 |  87.9 |  87.9 |  87.9 |  87.9 |   87.9 |   87.9 |   87.9 |   87.9 |   87.9 |   87.9 |   87.9 |   87.9 |   87.9 |   87.9 |   87.9 |   87.9 |   87.9 |
| 38        | 82.19              |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       | 82.19 | 82.19 | 82.19 | 82.19 | 82.19 | 82.19 | 82.19 | 82.19 | 82.19 | 82.19 |  82.19 |  82.19 |  82.19 |  82.19 |  82.19 |  82.19 |  82.19 |  82.19 |  82.19 |  82.19 |  82.19 |  82.19 |  82.19 |
| 39        | 84.98              |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       | 84.98 | 84.98 | 84.98 | 84.98 | 84.98 | 84.98 | 84.98 | 84.98 | 84.98 |  84.98 |  84.98 |  84.98 |  84.98 |  84.98 |  84.98 |  84.98 |  84.98 |  84.98 |  84.98 |  84.98 |  84.98 |  84.98 |
| 40        | 80.11              |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       | 80.11 | 80.11 | 80.11 | 80.11 | 80.11 | 80.11 | 80.11 | 80.11 |  80.11 |  80.11 |  80.11 |  80.11 |  80.11 |  80.11 |  80.11 |  80.11 |  80.11 |  80.11 |  80.11 |  80.11 |  80.11 |
| 41        | 80.69              |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       | 80.69 | 80.69 | 80.69 | 80.69 | 80.69 | 80.69 | 80.69 |  80.69 |  80.69 |  80.69 |  80.69 |  80.69 |  80.69 |  80.69 |  80.69 |  80.69 |  80.69 |  80.69 |  80.69 |  80.69 |
| 42        | 81.28              |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       | 81.28 | 81.28 | 81.28 | 81.28 | 81.28 | 81.28 |  81.28 |  81.28 |  81.28 |  81.28 |  81.28 |  81.28 |  81.28 |  81.28 |  81.28 |  81.28 |  81.28 |  81.28 |  81.28 |
| 43        | 85.92              |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       | 85.92 | 85.92 | 85.92 | 85.92 | 85.92 |  85.92 |  85.92 |  85.92 |  85.92 |  85.92 |  85.92 |  85.92 |  85.92 |  85.92 |  85.92 |  85.92 |  85.92 |  85.92 |
| 44        | 95.83              |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       | 95.83 | 95.83 | 95.83 | 95.83 |  95.83 |  95.83 |  95.83 |  95.83 |  95.83 |  95.83 |  95.83 |  95.83 |  95.83 |  95.83 |  95.83 |  95.83 |  95.83 |
| 45        | 98.66              |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       | 98.66 | 98.66 | 98.66 |  98.66 |  98.66 |  98.66 |  98.66 |  98.66 |  98.66 |  98.66 |  98.66 |  98.66 |  98.66 |  98.66 |  98.66 |  98.66 |
| 46        | 96.84              |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       | 96.84 | 96.84 |  96.84 |  96.84 |  96.84 |  96.84 |  96.84 |  96.84 |  96.84 |  96.84 |  96.84 |  96.84 |  96.84 |  96.84 |  96.84 |
| 47        | 100.3              |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       | 100.3 |  100.3 |  100.3 |  100.3 |  100.3 |  100.3 |  100.3 |  100.3 |  100.3 |  100.3 |  100.3 |  100.3 |  100.3 |  100.3 |
| 48        | 101.91             |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       | 101.91 | 101.91 | 101.91 | 101.91 | 101.91 | 101.91 | 101.91 | 101.91 | 101.91 | 101.91 | 101.91 | 101.91 | 101.91 |
| 49        | 108.97             |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |        | 108.97 | 108.97 | 108.97 | 108.97 | 108.97 | 108.97 | 108.97 | 108.97 | 108.97 | 108.97 | 108.97 | 108.97 |
| 50        | 116.54             |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |        |        | 116.54 | 116.54 | 116.54 | 116.54 | 116.54 | 116.54 | 116.54 | 116.54 | 116.54 | 116.54 | 116.54 |
| 51        | 119.52             |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |        |        |        | 119.52 | 119.52 | 119.52 | 119.52 | 119.52 | 119.52 | 119.52 | 119.52 | 119.52 | 119.52 |
| 52        | 124.37             |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |        |        |        |        | 124.37 | 124.37 | 124.37 | 124.37 | 124.37 | 124.37 | 124.37 | 124.37 | 124.37 |
| 53        | 130.74             |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |        |        |        |        |        | 130.74 | 130.74 | 130.74 | 130.74 | 130.74 | 130.74 | 130.74 | 130.74 |
| 54        | 136.83             |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |        |        |        |        |        |        | 136.83 | 136.83 | 136.83 | 136.83 | 136.83 | 136.83 | 136.83 |
| 55        | 140.88             |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |        |        |        |        |        |        |        | 140.88 | 140.88 | 140.88 | 140.88 | 140.88 | 140.88 |
| 56        | 140.68             |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |        |        |        |        |        |        |        |        | 140.68 | 140.68 | 140.68 | 140.68 | 140.68 |
| 57        | 142.73             |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |        |        |        |        |        |        |        |        |        | 142.73 | 142.73 | 142.73 | 142.73 |
| 58        | 135.58             |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |        |        |        |        |        |        |        |        |        |        | 135.58 | 135.58 | 135.58 |
| 59        | 144.65             |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |        |        |        |        |        |        |        |        |        |        |        | 144.65 | 144.65 |
| 60        | 150.3              |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |        |        |        |        |        |        |        |        |        |        |        |        |  150.3 |
+-----------+--------------------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+","['interpolation', 'sequences-and-series', 'calculus', 'analysis']"
2358357,Do you use logarithm and trigonometric rules by heart?,"That is technically no primary mathematical question, but I am really interested in that: I am able to prove that , e.g. $\cos(A + B) = \cos A\cos B - \sin A \sin B$ or that $\log(A)+ \log(B) = \log(AB)$. I also understand why this is. But at the end of the day I simply have to memorise these rules. It's not like that I look at a calculation including trig-functions or logarithms and ""have a natural feeling"" for the calculation like dividing, multiplying, factorizing and so on, where I kinda ""see"" the result and the steps. So here's my question: I am always a little bit confused if I simply do not have enough routine in using these operations or if it is just the usual case, that one does not simply ""see, or have a natural feeling"" for these calculations ? Because whenever I see a professor or any tutorials dealing with them it seems like they get these results like they're ""obviously to see"" . Both examples are randomly chosen, there are plenty of others related especially to these topics.","['logarithms', 'trigonometry', 'calculus', 'soft-question', 'education']"
2358373,Is the Aztec Diamond chaotic?,"Firstly, let me explain the context. An Aztec Diamond is a shape which looks like: (A rigorous definition can be found at Mathworld .) The Aztec Diamond Theorem states that such a shape of order $n$ can be tiled in $2^{\frac{n(n+1)}{2}}$ ways using $2 \times 1$ dominoes. The Arctic Circle Theorem states that as $n$ becomes large, a random domino tiling of this Aztec diamond tends to have the following properties: The tiles outside a certain circle will be arranged homogeneously in a “brick-wall” pattern (these are the homogeneously coloured areas in the example below). They are denoted as frozen. For each corner, these patterns are distinct in orientation and phase. This can be visualised as follows: Suppose the diamond’s squares are marked black and white in a chessboard pattern. Then assign a different colour (red, green, blue, yellow) to each domino tile, depending on whether the top, left, right, or bottom half rests on a black square. A homogeneous brick-wall tiling would then correspond to a homogeneous colours as all tiles within have the same orientation and phase. A typical tiling would then look like this: My question is about whether such a configuration can be described as chaotic. I regard chaos as both deterministic and having the property that when an initial parameter is slightly altered (in our case, the orientation/position of a domino), after a while the system will differ completely. So, if one alters a tile, for example on the border of the Arctic Circle for a large $n$, does that then impact the whole of the rest of the diagram? Once the corners are tiled, does that determine the rest of the diagram?","['tiling', 'combinatorics', 'chaos-theory', 'asymptotics']"
2358399,Show that $X$ is simply connected iff any two paths in $X$ with the same initial and terminal points are path-homotopic,"Let $X$ be a path connected space. Show that $X$ is simply connected iff any two paths in $X$ with the same initial and terminal points are path-homotopic Recall $X$ simply connected means $\pi_1(X, p) = \{[c_p]\}$, and $X$ is path-connected. My Proof : Suppose $X$ is simply connected, and let $f, g$ be two paths in $X$ with initial point $p$, and terminal point $q$, then $f \cdot \bar{g} \sim c_p$, let $G$ denote this homotopy, i.e $G: f \cdot \bar{g} \sim c_p$ Define $H(s, t) = G(s, t) \cdot g$, which can be easily verified is a path homotopy between $f$ and $g$ Conversely suppose any two paths in $X$ with the same initial and terminal points, are path-homotopic. Let $h$ be any loop at a point $p \in X$, pick a point $q = h(a)$ for some $a \in [0, 1]$, then $f =h|_{[0, a]}$, and $g =\overline{h|_{[a, 1]}}$ are two paths  with the same initial and terminal points, hence $f$ is path homotopic to $g$ and therefore $f \cdot  \bar{g}$ is homotopic to $c_p$, and $f \cdot \bar{g} = h$, therefore $h \sim c_p$, and $\pi_1(X)$ is trivial. $\square$ Is this proof satisfactory and rigorous enough? Any comments on my proof writing skills are also greatly appreciated.","['algebraic-topology', 'general-topology', 'proof-verification']"
2358416,combinatorics design,"Six scientists are working on a secret project. They wish to lock up the documents in a cabinet so that the cabinet can be opened when and only when three or more of the scientists are present. What is the smallest number of locks needed? What is the smallest number of keys each scientist must carry? I am thinking of solving this problem is this way:
Suppose there are n locks and label the keys with 1,2,...,n. Let $X=\{1,2,...,n\}$. We have to construct six non-empty subsets of $X$, say, $A_1,A_2,...,A_6$ such that $A_i \cup A_j \cup A_k = X$ for distinct $i,j,k$;and $A_i \cup A_j \ne X$ for $i \ne j$. From here I don't know how to proceed.
Any help will be much appreciated! Best regards,Michael.","['combinatorial-designs', 'combinatorics']"
2358468,Does this simple 2D dynamical system have a conserved quantity?,"Consider the following two-dimensional dynamical system, $$\dot{x} = y -y^3$$
$$\dot{y}= -x-y^2$$ where as usual the dot represents a time derivative. (This system is found on page 165 of Strogatz book 'Nonlinear Dynamics and Chaos'.) I am trying to find a conserved quantity for this system , apparently it does exist and there is a simple way to find it. Strogatz shows that the system is reversible with a nonlinear center at the origin. The phase portrait looks like: Does this system have a conserved quantity? Something like $x^2+y^2 = \text{constant}$, for example (this does not work though...). If so how would I go about finding it? I have tried playing around with the system but have not been able to find one, however the phase portrait leads me to believe that something should be conserved.","['nonlinear-system', 'dynamical-systems', 'calculus']"
2358477,Prove that three $2\times2$ matrices that commute are linearly dependent,"Statement: Suppose that $A$ , $B$ and $C$ are complex $2\times2$ matrices, any two of which commute under matrix multiplication.  Show that $A$ , $B$ and $C$ are linearly dependent. I think one method is to show the existence of $a,b,c\in\mathbb C$ , such that $aA+bB+cC=0$ while $a$ , $b$ , $c$ are not all zero.  I'm not sure how to proceed with this. I observed that if we add an assumption that $A$ , $B$ and $C$ are diagonalizable, then they are simultaneously diagonalizable since they all commute.  I think this implies that there exists a common $P$ such that $A=PD_1P^{-1}$ , $B=PD_2P^{-1}$ , $C=PD_3P^{-1}$ , where the $D_i$ are diagonal matrices.  Any three $2\times2$ diagonal matrices must be linearly dependent because they each have two non-zero entries only.  As a consequence, $A$ , $B$ and $C$ are linearly dependent. Unfortunately, not all matrices are diagonalizable.  I also tried to use Jordan canonical forms, but all I can see is that three $2\times2$ upper-triangular matrices may not be linearly dependent and that this line of reasoning might lead to a dead end. Therefore, how to prove the original statement?",['linear-algebra']
2358484,Integer matrices with determinant equal to $1$,"Integer matrices with determinant equal to $1$ are quite useful in many situations. Take, for example, this question . For the $2 \times 2$ case it's easy to find many such matrices, e.g., $$\begin{bmatrix}
2 & 3 \\
3 & 5 \\
\end{bmatrix}$$ $$\begin{bmatrix}
4 & 3 \\
5 & 4 \\
\end{bmatrix}$$ But how to construct the procedure for generation integer matrix with
arbitrarily chosen dimension $n \times n$? Is it a method which is as general as it is possible? I'm also interested in the answer how many degrees of freedom has an
integer matrix with determinant equal 1 (or other perhaps number) ?
Without determinant constraint $n \times n$ matrix has of course $n^2$ degrees of freedom.. how many is lost when we constrain it with determinant?","['matrices', 'linear-algebra', 'determinant']"
2358594,The exponential of a straight line is a straight line if and only if the line is horizontal,"Suppose that $f(z) = e^{z}$. Show that the image of a straight line $\ell$ in $\mathbb{C}$ under $f$ is a straight line if and only if $\ell$ is horizontal. My attempt: Suppose $\ell$ is horizontal. Then for the complex number $z=x+iy$, $y=d$ for fixed $d \in \mathbb{R}$. Hence, $$e^z = e^x e^{id} = e^{x}\cos d + i \sin d$$ which, geometrically, is a complex number with fixed argument $d$ radians, with a variable length $e^{x}$ for $x \in \mathbb{R}$. Hence, as $x$ varies, then $e^{z}$ traces out a straight line. Now suppose that the image of $z$ under $f$ is a straight line. Then $$e^{z} = e^x \cos y + e^x i \sin y.$$ If the image of $z$ under $f$ is a straight line, then the argument of $e^z$ for any $z$ is fixed. This implies $y$ is fixed. However, I'm quite confused now. Even though I fix $y=d$ in the first implication, $z=x+id$ still doesn't look horizontal to me in the Argand diagram... ( scratch this , I realise it actually does haha) I'm not sure if I proved the last implication correctly, it seems kind of dodgy. I say that $y$ is fixed, but do I have to say anything about $x$?","['complex-analysis', 'functions', 'proof-verification']"
2358605,"Does this ""apparently simple"" linear system have a solution?","Does there exist $x \in (0,1)^\mathbb{N}$ such that for any decreasing $v \in (0,1)^\mathbb{N}$ that converges to $0$ (meaning, $v_{n+1} < v_n$ and $v_n \rightarrow 0$), there is $a \in (0,1)^\mathbb{N}$ with:
  $$
\begin{array}{lll}
\sum a_n & =& v_0\\
\sum a_n x_n& = &v_1\\
\sum a_n x^2_n & = &v_2\\
\mbox{etc?}&&
\end{array}
$$ [NB: I asked a related question before, which I then rewrote as the above. But I was recommended to post it anew to avoid invalidating old answers.] Note that my question is equivalent to this: think of an infinite Vandermonde matrix with coefficients $x \in (0,1)^\mathbb{N}$ $$
V(x) = \left(
\begin{array}{llllll}
1      & 1    & 1      & \cdots & 1     & \cdots\\
x_1    & x_2  & x_3    & \cdots & x_n   & \cdots\\
x^2_1  & x^2_2& x^2_3  & \cdots & x^2_n & \cdots\\
\vdots &\vdots&\vdots  & \ddots &\vdots & \vdots\\
x_1^m & x^m_2 &x^m_3 & \cdots & x^m_n  & \cdots\\
\vdots &\vdots&\vdots  & \ddots &\vdots & \vdots 
\end{array}
\right)
$$
(where superscrits represent exponents and not just row position) and ask whether there is $x \in (0,1)^\mathbb{N}$ such that for any decreasing and convergent (to $0$) $v \in (0, 1)^\mathbb{N}$, there is $a \in (0, 1)^\mathbb{N}$ satisfying $V(x) \cdot a= v$. I've found the following relevant paper: http://www.sciencedirect.com/science/article/pii/S0019357712000419 but it requires that $x\,$ satisfy $\sum_n \frac{1}{|x_n|} < \infty$, which cannot be true in the above (because $1 / |x_n| > 1$ for all $n$). The paper makes this assumption because it assumes nothing about $v$, so there's hope. As always, thank you all for your help.","['functional-analysis', 'real-analysis', 'linear-algebra']"
2358618,"Prove existence of $\lim_{(x,y) \rightarrow (0,2)} \frac{x (y-2)^3}{3x - 5(y-2)^4}$","I've been trying to prove the existence of this limit... trying with a bunch of different curves I'm always getting $0$ (I don't know if I'm using the suggestion correctly) but when I try to make an epsilon-delta proof I get stucked because I don't know how to properly bound the denominator. $$\lim_{(x,y) \rightarrow (0,2)} \frac{x (y-2)^3}{3x - 5(y-2)^4}$$ (Consider curves close to $3x-5(y-2)^4=0$ ) My question is: if indeed this limit does exist -and it's $0$ - how can I prove it? As I wrote above I don't know how to work around the denominator. I need something smaller than $|3x-5(y-2)^4|$ ... Or maybe the limit does not exist, and then my question would be what curve can you think of to prove it. Thank you for your time!","['limits', 'multivariable-calculus', 'epsilon-delta', 'proof-writing', 'analysis']"
2358675,Gradient of the distance of point and set,"Let $A⊂\mathbb{R}^{n}$ be a closed subset and $d:\mathbb{R}^n \to \mathbb{R}$ 
 defined by $d(x)=\inf\{||x-y|| | y\in A\}$ ($x \in \mathbb{R}^n$) where $||v||$ is the Euclid norm of $v \in \mathbb{R}^n$.If $d$ is totally differentiable at $x_{0}\notin A$,prove that $||(\mathrm{grad} \ d)(x_{0})|| = 1$. If $A$ is the one point,It is obvious.However I have no idea in the case $A$ is merely closed subset. It comes down to the one point case ?","['derivatives', 'metric-spaces', 'calculus']"
2358680,Convergent sequence with odd terms decreasing and even terms increasing,"Let $\left(a_n\right)$ is convergent sequence. $a_0=0, a_1=1,a_2,a_3,...$ Odd terms decrease and even terms increase and for all $n\ge1$ 
  $$2\le \frac{a_n-a_{n-1}}{a_n-a_{n+1}}\le3.$$
  Find the boundaries in which there can be a limit of this sequence. My work so far: I proved that $$\frac{11}{24}\le\lim_{n\to\infty}a_n\le\frac{23}{24}$$
But I can not say that this is the final answer. I need an examples of sequences such that: 1) $$\lim_{n\rightarrow\infty}a_n=\frac{11}{24}$$ 2) $$\lim_{n\rightarrow\infty}a_n=\frac{23}{24}$$
or 3) (If my answer can be improved) I need numbers $m$ and $M$, where $$\frac{11}{24}<m\le\lim_{n\rightarrow\infty}a_n\le M<\frac{23}{24}$$","['real-analysis', 'sequences-and-series', 'calculus', 'limits']"
2358682,Relating an integral over the n-ball with the surface area of the (n-1)-sphere,"I'm asking for help in order to prove the following formula:
$$\int_{|\mathbf{x}|<1}x_1^2 d\mathbf{x}= \frac{\omega_{n}}{n\left(n+2\right)} $$
Where $\mathbf{x}=(x_1,\dots,x_n)\in \mathbb{R}^n $, and $\omega_n$ is the area of the $(n-1)$-sphere. \ 
I already proved the formula in the cases $n=2$ and $n=3$, using respectively polar coordinates and Fubini's theorem. However I don't have knowledge of any theorem that could help me in the general case aside from Fubini's theorem, which allows me to proceed in the following way:
$$\int_{|\mathbf{x}|<1}x_1^2 d\mathbf{x}= \int_{-1}^{1}\left(\int_{D_{\bar{x}_1}}x_1^2\mathrm{d}x_2\dots\mathrm{d}x_n\right)\mathrm{d}x_1= \int_{-1}^{1}x_1^2 \mathcal{L}^{n-1}(D_{\bar{x}_1})\mathrm{d}x_1 $$
Where $D_{\bar{x}_1}= \left\{|\mathbf{x}|<1\right\}\cap \left\{x_1=\bar{x}_1\right\}$, which is an $(n-1)$-ball of radius $\sqrt{1-x_1^2}$, and $\mathcal{L}^{n-1}$ denotes the Lebesgue measure on $\mathbb{R}^{n-1}$.
However, this doesn't help as I'm supposed to relate the integral to the measure of the $(n-1)$-sphere, not the $(n-1)$-ball. Even then I could only go as far as saying $$\mathcal{L}^{n-1}(D_{\bar{x}_1})= \left(1-x_1^2\right)^{\frac{n-1}{2}}\mathcal{L}^{n-1}(D) $$
Where $D$ is the unit ball in $\mathbb{R}^{n-1}$, but I still can't compute the following integral when $n$ is even:
$$\int_{-1}^{1}x^2(1-x^2)^{\frac{n-1}{2}}\mathrm{d}x $$
I guess that I need some form of Stokes's theorem, but I only studied the classical results in $\mathbb{R}^3$, and the generalized version that I've found is expressed through differential forms. Is it possible to solve this in a more elementary way? Edit: the number of dimensions was incorrect in some instances","['multivariable-calculus', 'real-analysis', 'integration']"
2358736,Applications of Combinatorial Discrepancy Theory,"TL;DR: What are some fancy applications of combinatorial discrepancy theory? Combinatorial Discrepancy Consider a set of white balls $\Omega$ and a family $\mathcal{A}$ of subsets of Omega. The task is to find a two-coloring of $\Omega$, such that in every set $A \in \mathcal{A}$ the difference between the number of ""red"" and ""blue"" balls is as low as possible. Mathematically, this problem can be described as minimizing the discrepancy of a set system: Let $\Omega$ be a finite set and let $\mathcal{A}$ be a family of subsets of $\Omega$.
The combinatorial discrepancy of $\mathcal{A}$ is defined as
\begin{equation}
\operatorname{disc}(\mathcal{A})=\min_{\chi: \Omega \mapsto \{-1,1\}} \max_{A \in \mathcal{A}} |\sum_{a \in A}\chi(a)|.
\end{equation}
It has been shown, that for $|\Omega|=|\mathcal{A}|=n$, $\operatorname{disc}(A) \leq 6\sqrt{n}$ (see Six Standard Deviations Suffice ). Finding colorings $\chi$ that minimize the discrepancy is also a topic of current research (see Constructive Algorithms for Discrepancy Minimization ). I have read that combinatorial discrepancy was used in computer science , but not how and where exactly it is used. Where is combinatorial discrepancy used in CS? What other fields is combinatorial discrepancy used in (apart from coloring balls)?","['combinatorics', 'probability-theory', 'computer-science', 'discrete-mathematics']"
2358738,An integral involving error functions and a Gaussian,"Let $d\ge 1$ be an integer and let $\vec{A}:=\left\{ A_i \right\}_{i=1}^d$ be real numbers. We consider a following integral:
\begin{equation}
{\mathfrak I}^{(d)}(\vec{A}):=\int\limits_0^\infty e^{-u^2}\left[ \prod_{i=1}^d \operatorname{erf}(A_i u) \right] du
\end{equation}
By expanding the error functions in Taylor series and then integrating term by term we found the answer for $d=1$ and $d=2$. We have:
\begin{eqnarray}
\sqrt{\pi} {\mathfrak I}^{(d)}(\vec{A}) =
\begin{cases}
 \arctan(A_1) & \text{if $d=1$}\\[4pt]
 \arctan\left(\frac{A_1 A_2}{\sqrt{1+A_1^2+A_2^2}}\right) & \text{if $d=2$}
\end{cases}
\end{eqnarray}
Now the question is how do we derive the result for arbitrary values of $d$?",['integration']
2358761,Is a positive semidefinite matrix always non-negative?,"I'm trying to get some intuition behind the meaning of a positive semidefinite matrix, which I learned a long time ago in undergrad but clearly didn't internalize properly. As I understand, a symmetric matrix $M \in \textbf{R}^{n~\times~n}$ is positive semidefinite iff $z^TMz \ge 0$, $\forall z \in \textbf{R}^n$.
Note that I'd like to use this particular definition, not a more general one that involves complex numbers. As such, $z^TMz \in \textbf{R}$. This definition makes sense to me, and this question clarified it further, but then I was reading Boyd's textbook and became confused by an unrelated definition explained in $\S$3.1.4, which implies that the Hessian matrix $\textbf{H}$ of function $f$ is positive semidefinite if $\textbf{H} \succcurlyeq 0$, where the $""\succcurlyeq""$ symbol refers to a componentwise inequality between matrices. Thus, can a positive semidefinite matrix contain negative entries? EDIT: This question turned out to be silly, but if you have this question and am as rusty with linear algebra as I am, this post might be useful.","['convex-optimization', 'linear-algebra']"
2358765,Integral of $e^{x^3+x^2-1}(3x^4+2x^3+2x)$,"I understand that this looks exactly like a ""Do my Homework"" kinda question but trust me, I've spent hours(I won't go into detail as it's off topic). Note: I'm a High School student, our teacher gave this question as a challenge. I'm struggling with $$\int e^{x^3+x^2-1}(3x^4+2x^3+2x)\ dx$$ My Progress: I tried finding integral by parts, and found that$$\int e^{x^3+x^2-1}\ dx$$ was the only trouble maker(for now).
So, I tried finding it's integral then gave up and tried using a calculator to see what I missed.
The website said: That it's antiderivative is not elementary . I didn't even know what that means. New Approach: Now, I went on to trying to plot the graph of $$ e^{x^3+x^2-1}$$  to see if I could related it to $$\int_{-a}^x e^{x^3+x^2-1}\ dx$$ and say whether $$\int e^{x^3+x^2-1}\ dx$$ exists or not. I was hoping for some discontinuity in the graph of the definite integral but I didn't seem to find any. Note: I drew the graph of the definite integral through observation and intuition, I don't think there was any other method. So is there anyway of helping me?","['indefinite-integrals', 'problem-solving', 'integration']"
2358782,Derivative of inner product via adjoint operator vs. complex derivatives,"Dear math enthusiasts, I need to take the derivative of an inner product involving an operator on one side and I'd like to do this via the adjoint operator. However, it seems I'm doing something wrong since things don't quite match for the complex-valued case (for real numbers it works). I'm assuming some mismatch between the (Wirtinger?) calculus I'm applying for the complex derivative and the inner products / operators but I'm not sure where exactly things go wrong. Here is the setting: I have an operator $T: \mathbb{C}^n \mapsto {\mathcal S_n}$, where $\mathcal S_n$ denotes the set of Hermitian symmetric complex $n \times n$ matrices. I am looking at the inner product $\langle A, T(x) \rangle$ and I need its derivative with respect to $x$. The inner products I'm using are $\langle x,y\rangle = x^{\rm H} y$ on $\mathbb{C}^n$ and $\langle X,Y\rangle = {\rm Trace}(X^{\rm H} Y)$ on $\mathcal S_n$, where $(\cdot)^{\rm H}$ denotes conjugate transpose. I was thinking to use the adjoint operator $T^*: {\mathcal S_n} \mapsto \mathbb{C}^n$ defined via $\langle A, T(x) \rangle = \langle T^*(A), x \rangle$ for all $A \in \mathcal S_n$, $x \in \mathbb{C}^n$. Then I was hoping to use some magic like this: $$\frac{{\rm d} \langle A, T(x) \rangle}{{\rm d} x}
= \frac{{\rm d} \langle T^*(A), x \rangle}{{\rm d} x}
= T^*(A).
$$ Is this rule correct? Does it work in the complex domain? I was thinking it should work on any Hilbert space but I'm not sure. Anyways, I'm having trouble applying this. Here is a concrete simple example. The most simple form of it is the operator $T(x) = \begin{bmatrix} x_1 & x_2 \\ \bar{x}_2 & x_1 \end{bmatrix}$ [*] , where $\bar{x}$ denotes complex conjugation. Since $A \in \mathcal S_n$, let's say $A = \begin{bmatrix} a_1 & a_2 \\ \bar{a}_2 & a_1 \end{bmatrix}$, where $a_1$ is real.
I'm computing the adjoint via $$[T^*(A)]_i = \langle T^*(A),e_i\rangle = \langle A,T(e_i) \rangle = 
\begin{bmatrix} 
\langle A, \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} \rangle \\ 
\langle A, \begin{bmatrix} 0 & 1 \\ 1 & 0 \end{bmatrix} \rangle 
\end{bmatrix}
= \begin{bmatrix} 2 a_1 \\ a_2 + \bar{a}_2\end{bmatrix}.$$ So far so good. At the same time, my inner product gives me $$ \langle A,T(x) \rangle = a_1 x_1 + \bar{a}_2 x_2 + a_2 \bar{x}_2 + a_1 x_1.$$ I would have said its derivative should be $$\frac{{\rm d} \langle A, T(x) \rangle}{{\rm d} x}
= \begin{bmatrix}
2a_1 \\
\bar{a}_2 
\end{bmatrix},$$ using $\frac{\partial \bar{x}_2}{x_2} = 0$. I'm assuming this is where I'm wrong. On the other hand, I would only get a result agreeing with $T^*(A)$ if this derivative would be equal to one, which I find hard to believe (unless $x$ is real). I'm not an expert in complex analysis but I was told that for functions $f: \mathbb{C}^n \mapsto \mathbb{R}$ we have $\frac{{\rm d}f}{{\rm d}x} = \overline{\frac{{\rm d}f}{{\rm d}\bar{x}}}$, since $f = \bar{f}$. This means that if we look for extrema it does not matter which of the derivatives we equate to zero. It works nicely in the above example if we treat $x_2$ and $\bar{x}_2$ independently (I belive this is called Wirtinger calculus or something?). At the same time this seems to break something with the inner products and/or adjoint operators. Could someone help me shed light on where is the incompatibility and what is the best way of treating these types of problems? What is the correct answer to the derivative? What makes me really sceptical about using $T^*(A)$ is that it always returns something real-valued (for symmetric $A$ on which it is defined) though the derivatives should be complex-valued. P.S.: [*] There is another minor issue here that I think has not directly to do with the problem but I welcome comments on: For this operator to map to $\mathcal S_n$ we actually need to make sure $x_1$ is real. So I have two options: (a) define it as $T(x) = \begin{bmatrix} {\rm Real}(x_1) & x_2 \\ \bar{x}_2 & {\rm Real}(x_1) \end{bmatrix}$ where ${\rm Real}(x_1) = \frac 12(x_1 + \bar{x}_1)$. Interestingly, this does not seem to change the adjoint operator, since $T(e_i)$ is unchanged. However, my inner product becomes $\langle 2 a_1 \frac 12 (x_1+\bar{x}_1) + a_2x_2 + \bar{a}_2 \bar{x}_2 \rangle$, which does seem to change the derivative again to $\begin{bmatrix} a_1 \\ a_2 \end{bmatrix}$. So even with this correction, the result is incompatible to the one we get via $T^*(A)$. (b) Alternatively, I could define the operator to map from $\mathbb{R} \times \mathbb{C}^{n-1}$ to $\mathcal S_n$. I'm not sure if this causes complications for the inner products though.","['functional-analysis', 'complex-analysis', 'linear-algebra', 'adjoint-operators']"
2358822,Simple Directed Graph?,"In graph theory, would a graph with edges $(u, v)$ and $(v, u)$ connecting vertices $v$ and $u$ be considered a directed simple graph?  For example: would this graph be considered a simple directed graph? Thanks for your help.","['graph-theory', 'discrete-mathematics']"
2358840,"Is this a composition of scalar fields? Meaning of $(\phi(x,y,z,t),x,y,z)$?","In the following I'm interested in the mathematics, not the physical representation. The diffusion equation is 
$$
\frac{\partial \phi(\mathbf{r},t)}{\partial t}=\nabla \cdot [D(\phi,\mathbf{r})\nabla\phi(\mathbf{r},t)]
$$ Here $\phi$ and $D$ are multivariable functions. 
I think the explicit form of $D(\phi,\mathbf{r})$ is
$$
D(\phi,\mathbf{r})=D(\phi(\mathbf{r},t),\mathbf{r})=D(\phi(x,y,z,t),x,y,z)
$$
But what does $D(\phi(x,y,z,t),x,y,z)$ mean, is it a function composition? $\phi(\mathbf{r},t)$ is $\mathbb R^4 \rightarrow \mathbb R$, but what is $D$?","['multivariable-calculus', 'real-analysis', 'functions', 'partial-differential-equations']"
2358847,Can we denote a function without specifying its input variable(s)?,"I am in the process of writing my M.Sc. thesis. Coming from an ecology background, I have limited knowledge of mathematical notation. For the purpose of my project I define a differential equation system that I use as a base model upon which I build over the course of the paper, progressively adding complexity. For simplicity, let us say the base model would be: $\frac{d_y}{d_t}=fy+\alpha$ In the simpler instance of the model, the function $f$ can be defined as a constant, e.g. $f=\beta$. However, in more complex instances it is implemented as a function, e.g., $f(y)=\beta y$, but the rest of the model structure remains identical. I do not want to re-expose the whole model every time complexity is built-in, but I want to make it clear that complexity will be built into $f$. Can $f$ be exposed as a function from the get-go? If so, what notation can I use that does not require to specify the input variables? What I mean is if the base model is defined as $\frac{d_y}{d_t}=f(y)y+\alpha$ it induces confusion as to the structure of the simpler instances of the model, when $f=\beta$. I have tried presenting $f$, in the textual description of the equations system, as a function that represents, for instance, the growth rate, and that in the simplest instance of the model it is a constant, but readers have not picked it up and still wonder whether it is a function and, if so, why I do not use the $f()$ in the presentation of the base model. Would anyone have suggestions as to improve the clarity of the model presentation with respect to the introduction of $f$?","['ordinary-differential-equations', 'notation', 'functions']"
2358882,Domination problem with sets,"Let $M$ be a non-empty and finite set, $S_1,...,S_k$ subsets
  of $M$ , satisfying: (1) $|S_i|\leq 3,i=1,2,...,k$ (2) Any element of $M$ is an element of at least $4$ sets among $S_1,....,S_k$ . Show that one can select $[\frac{3k}{7}] $ sets from $S_1,...,S_k$ such that their union is $M$ . Partial solution: I can find a family of ${13\over 25}k$ such sets that no element in $M$ is in more then 3 set from that family. Thus we have a family of the size ${13\over 25}k$ instead of ${4\over 7}k$ . Say $|M| =n$ . Let' s take any set independently with a probability $p$ . Let's mark with $X$ a number of a chosen sets and with $Y$ a number of elements that are ''bad''
i.e. elements which are in at least 4 sets among a chosen sets. Note that $4n\leq 3k$ . Then we have $$E(X-Y)=E(X)-E(Y) \geq  kp-np^4 \geq kp (1-3p^3/4)$$ Since a function $x \mapsto  x(1-3x^3/4)$ achives a maximum at $x=\sqrt[3]{1/3}$ we have $E(X-Y)\geq {\sqrt[3]{9}\over 4}k> {13\over 25}k$ . So with the method of alteration we find constant ${\sqrt[3]{9}\over 4}$ which is about $0,051$ worse then ${4\over 7}$ . The question is cross-posted to mathoverflow For a full solution with probabilistic method I'm offering $\color{red}{500}$ points of bounty at any time.","['discrete-optimization', 'algorithms', 'extremal-combinatorics', 'combinatorics', 'probabilistic-method']"
2358888,What is the Basis of an Ordered Square?,"The dictionary order topology on $\Bbb R\times \Bbb R$ is generated by a basis having elements $(a\times b,c\times d)$ for $a<c$ or $a=c$ and $b<d$. Let $I=[0,1]$ and consider $I\times I$. The restriction of dictionary order topology on $I\times I$ defines a topology on $I\times I.$ I'm trying to figure out what would be its basis. The following is what I have; For $a,b,c,d\in I$ Its basis will contain elements of the form $(a\times b,c\times d)$ for $a<c$ or $a=c$ and $b<d$ The basis contains elements  $[0\times0,a\times b)$ with $0<a$ or $0=a$ and $0<b$ Also $(a\times b,1\times1]$ with $a<1$ or $a=1$ and $b<1$ belongs to the basis. Is that correct? Suggestions Please!",['general-topology']
2358892,What is the maximum number of distinct positive integer's square that sums up to $2002$?,"What is the maximum number of distinct positive integer's square that sums up to $2002$ ? My tries: $$\frac{n(n+1)(2n+1)}{6} = 2002$$
 $$\implies n\approx 17 $$ but am clueless as to how to proceed any further.","['number-theory', 'quadratics', 'sums-of-squares', 'elementary-number-theory']"
2358933,Orthogonal polynomials of the second kind,"Let $L:  \mathbb{R}[x] \rightarrow \mathbb{R}$ be a positive definite linear functional and let that $\{s_n\}$ be a positive semi-definite sequence such that $$L(x^n)= s_n, n\ge 0$$ and $$<p,q> = L(pq).$$ Given a positive definite sequence, we use the Gram-Schimdt orthogonalization method to construct a sequence of orthogonal polynomials $\{p_n\}$ whose leading coefficient is positive due to the  positivity nature of the sequence given. It turns out that this sequence of orthogonal polynomials  $\{p_n\}$ satsifies a three term recurrence relation given below
\begin{equation}
xp_n(x) =b_np_{n+1}(x)+a_np_n(x)+b_{n-1}p_{n-1}(x) , \quad n\ge 0
\end{equation} We can see the sequence $p_n(x)$ as a solution to the three term recurrence relations stated above. Akhiezer http://www.maths.ed.ac.uk/~aar/papers/akhiezer.pdf as my reference introduced another solution to this three term recurrence relation by defining another solution by \begin{equation} q_n(x)= \displaystyle L\left(\frac{p_n(x)-p_n(y)}{x-y}\right)
\end{equation} where the  quotient $\frac{p_n(x)-p_n(y)}{x-y}$  is a polynomial in $x$ and $y$ and $q_n(x)$ is a polynomial in variable $x$ and its degree is $n-1$ for any $x,y \in \mathbb{R}$ so that we have $ \displaystyle xq_n(x) =b_nq_{n+1}(x)+a_nq_n(x)+b_{n-1}q_{n-1}(x), n\ge 1$ with $q_0(x)=0$ and $q_1(x)= \frac{1}{b_0}$ Question: Akhiezer claimed that this sequence of polynomials $\{q_n\}$ is orthogonal. I dont understand how this is true. Can anyone please show me what this true? PS: Recall that $$<p,q> = L(pq)$$ defines an inner product","['real-analysis', 'functional-analysis', 'moment-problem', 'operator-algebras', 'linear-algebra']"
2358965,Integral of Multivariable Gaussian across a Circular Domain.,"Basically, trying to compute the probability, a.k.a volume under the bi-variate gaussian distribution: $$ f(x,y) = \frac{1}{2 \pi \sigma^2} \cdot \exp(\frac{-x^2 - y^2}{2 \sigma^2}) $$ over axis-aligned circles in the xy-plane. So, the circles all are of the form: $(x - c_x)^2 + y^2 = R^2$ So the centers always lie on the x-axis somewhere, and the gaussian always has mean $(x, y) = (0, 0)$ I've been using a numerical integration library which computes the following integral (setup in cartesian notation):
$$ 2 \cdot \int_{x = c_x-R}^{c_x + R}\int_{y=0}^{\sqrt{R^2 - (x - c_x)^2}} f(x, y) \, dy\, dx $$ But I also know that computing this is very easy when the circle is centered at the origin (i.e. when $c_x = 0$). Since the integral can just be written in polar coordinates and turns into:
$$ \frac{1}{2 \pi \sigma^2} \int_{\theta = 0}^{2\pi}\int_{r=0}^R re^{-r^2 / 2\sigma^2} \, dr\, d\theta = \frac{1 - e^{-R^2 / 2\sigma^2}}{2 \pi \sigma^2}$$ Buut, once I introduce the $c_x$ term and the circle is not centered at the origin, the polar integral gets a weird term added on, making things really scary lol. I don't know how I would go about finding a closed form, if one even exists? Here is what the polar integral becomes when $c_x \neq 0$: $$ \frac{1}{2 \pi \sigma^2} \int_{\theta = 0}^{2\pi}\int_{r=0}^R r e^{-r^2 / 2\sigma^2}e^{2r\cdot c_x \cdot\cos\theta / 2\sigma^2} \, dr\, d\theta$$ Anybody have a clue if/how I can find a closed form for the last integral? or perhaps that first integral, but I'd imagine it's harder from the cartesian perspective? Any help appreciated, Cheers :-)","['gaussian-integral', 'calculus', 'probability-distributions', 'multivariable-calculus', 'integration']"
2358989,Limits of Measurable Functions,"Let $(X, \mathcal{M})$ be a measurable space and let $f_1, f_2, ... : X \longrightarrow [-\infty, \infty]$ be measurable functions. Then $\{x \in X: \lim\limits_{n \to \infty} f_n(x) \text{ exists in } [-\infty, \infty]\} \in \mathcal{M}$. My professor gave this as an extra problem during the spring term, and in reviewing my notes I realized I never finished this one. I know that if for all $x \in X$, $f_n(x) \to f(x)$, then $f(x)$ is measurable, but I'm having difficulty dealing with this situation, where the $f_n(x)$ might not converge for all $x$. My professor suggested that we start by showing that $\{x \in X: f_n(x) \to 12\} \in \mathcal{M}$, which I've done: We know that $\limsup\limits_{n \to \infty} f_n(x)$ and $\liminf\limits_{n \to \infty} f_n(x)$ are measurable functions, and that for all $x$, $f_n(x) \to 12$ if and only if $\limsup\limits_{n \to \infty} f_n(x) = \liminf\limits_{n \to \infty} f_n(x)=12$. Thus $$\{x \in X: f_n(x) \to 12\} = \{x \in X: \limsup\limits_{n \to \infty} f_n(x)= 12\} \cap \{x \in X: \liminf\limits_{n \to \infty} f_n(x)= 12\}$$ is in $\mathcal{M}$ since it is the intersection of two sets in $\mathcal{M}$. I'm not sure how to adapt this to the situation at hand, though.",['measure-theory']
2359032,Theorem 6.19 in Baby Rudin: Do we need the continuity of $\varphi$?,"Here is Theorem 6.19 (change of variable) in the book Principles of Mathematical Analysis by Walter Rudin, 3rd edition: Suppose $\varphi$ is a strictly increasing continuous function that maps an interval $[ A, B]$ onto $[ a, b]$. Suppose $\alpha$ is monotonically increasing on $[ a, b]$ and $f \in \mathscr{R}(\alpha)$ on $[a, b]$. Define $\beta$ and $g$ on $[ A, B]$ by 
  $$ \beta(y) = \alpha \left( \varphi(y) \right), \qquad g(y) = f \left( \varphi(y) \right). \tag{36} $$
  Then $g \in \mathscr{R}(\beta)$ and 
  $$ \int_A^B g \ \mathrm{d} \beta =  \int_a^b f \ \mathrm{d} \alpha. \tag{37} $$ And, here is Rudin's proof: To each partition $P = \{ \ x_0, \ldots, x_n \ \}$ of $[a, b]$ corresponds a partition $Q = \{ \ y_0, \ldots, y_n \ \}$ of $[ A, B]$, so that $x_i = \varphi \left( y_i \right)$. All partitions of $[A, B]$ are obtained in this way. Since the values taken by $f$ on $\left[ x_{i-1}, x_i \right]$ are exactly the same as those taken by $g$ on $\left[ y_{i-1}, y_i \right]$, we see that 
  $$ \tag{38} U(Q, g, \beta) = U(P, f, \alpha), \qquad L(Q, g, \beta) = L(P, f, \alpha). $$ 
  Since $f \in \mathscr{R}(\alpha)$, $P$ can be chosen so that both $U(P, f, \alpha)$ and $L(P, f, \alpha)$ are close to $\int f \ \mathrm{d} \alpha$. Hence (38), combined with Theorem 6.6, shows that $g \in \mathscr{R}(\beta)$ and that (37) holds. This completes the proof. Let us note the following special case: Take $\alpha(x) = x$. Then $\beta = \varphi$. Assume $\varphi^\prime \in \mathscr{R}$ on $[ A, B]$. If Theorem 6.17 is applied to the left side of (37), we obtain 
  $$ \tag{39} \int_a^b f(x) \ \mathrm{d} x = \int_A^B f \left( \varphi(y) \right) \varphi^\prime(y) \ \mathrm{d} y. $$ Now here is Theorem 6.6 in Baby Rudin, 3rd edition: $f \in \mathscr{R}(\alpha)$ on $[a, b]$ if and only if for every $\varepsilon > 0$ there exists a partition $P$ such that 
  $$ \tag{13} U(P, f, \alpha) - L(P, f, \alpha) < \varepsilon. $$ And, here is Theorem 6.17: Assume $\alpha$ increases monotonically and $\alpha^\prime \in \mathscr{R}$ on $[a, b]$. Let $f$ be a bounded real function on $[a, b]$. Then $f \in \mathscr{R}(\alpha)$ if and only if $f \alpha^\prime \in \mathscr{R}$. In that case 
  $$ \tag{27} \int_a^b f \ \mathrm{d} \alpha = \int_a^b \ f(x) \alpha^\prime(x) \ \mathrm{d} x. $$ Now my question is, is the continuity of $\varphi$ essential in Theorem 6.19 (or its special case)? As far as I can see it, it suffices to just assume that $\varphi$ is a strictly increasing mapping of $[ A, b]$ onto $[a, b]$. And, can we not state Theorem 6.19 as an if-and-only-if-statement, rather than as just an if-statement as it is in its present form? In short, can we not restate Theorem 6.19 as follows? Suppose $\varphi$ is a strictly increasing (not necessarily continuous) function that maps an interval $[ A, B]$ onto $[ a, b]$. Suppose $\alpha$ is monotonically increasing on $[a, b]$, and $f \in \mathscr{R}(\alpha)$ on $[a, b]$. Define $\beta$ and $g$ on $[A, B]$ by 
  $$ \beta(y) = \alpha \left( \varphi(y) \right), \qquad g(y) = f \left( \varphi(y) \right). $$ Then $f \in \mathscr{R}(\alpha)$ on $[a, b]$ if and only if $g \in \mathscr{R}(\beta)$ on $[ A, B ]$, and in that case 
  $$ \int_A^B g \ \mathrm{d} \beta = \int_a^b f \ \mathrm{d} \alpha. $$","['real-analysis', 'riemann-integration', 'integration', 'definite-integrals', 'analysis']"
2359035,Induction: Every triangulation of an n-sided polygon has n − 2 triangles,"I am having trouble understanding a certain proof. Claim: Every triangulation of an $n$-sided polygon has $n-2$ triangles. Base Case ($n=3$): Trivial. We let $P$ be a polygon with $n$ edges. A diagonal is drawn between two vertices of $P$, splitting $P$ up into two smaller polygons $a$ and $b$. Polygon $a$ has $k+1$ edges ($k$ edges of $P$ plus the diagonal), where $k$ is between $2$ and $n-2$. Then, polygon $b$ has $n-k+1$ edges ($n-k$ edges of $P$ plus the diagonal). If we apply the induction hypothesis to polygon $a$, then polygon $a$ can be broken up into $k-1$ triangles. Likewise, by applying the induction hypothesis to polygon $b$, polygon $b$ can be broken up into $n-k-1$ triangles. Putting polygons $a$ and $b$ together, we get $n-2$ triangles. $(k-1)+(n-k-1) = n-2$ triangles. I think my confusion arises when considering that we didn't use the induction hypothesis for $n+1$ sides. Instead, we used the induction hypothesis separately on two sub polygons of $P$. Here's the proof I'm referencing: https://www.cise.ufl.edu/~ungor/courses/fall08/polytri.pdf","['induction', 'triangulation', 'geometry']"
2359052,"A function on [0,1] that satisfies the following conditions","I am struggling to come up with a function $F(x)$ with $x \in [0,1]$ that satisfy the following conditions (some sort of variants of Inada conditions) continuously differentiable strictly increasing convex $F(0) = 0$ the first order derivative approaches $0$ when $x \rightarrow 0$ the first order derivative approaches $+\infty$ when $x \rightarrow 1$ Any thought will be appreciated. Thanks for your help in advance! Addition: Also, would it be possible to parameterize this function, say with a parameter $a$, so that $\partial F(x)/\partial x$ is monotonic in $a$? Edits: As correctly pointed out, indeed, what I meant is $F(x)$ continuous on $[0,1]$ and $F'(x)$ continous on $(0,1)$. Thank you all for the wonderful help!","['calculus', 'analysis']"
2359070,Intuitive geometric explanation: existence of eigenvalue in odd dimension real vector space.,"I'm looking for an intuitive geometric explanation for the fact that given an odd dimensional real vector space $W$ and an endomorphism $T:W \rightarrow W$, there exists a real eigenvalue of $T$. I'm not looking for an algebraic explanation which involves the degree of characteristic polynomial.","['eigenvalues-eigenvectors', 'linear-algebra', 'linear-transformations', 'geometry']"
2359104,Why is the space of finite Borel-measure dual to the space of finite continuous function.,"Riesz-Representation-Theorem states that every positive linear functional $F$ for any finite continuous $f$ on a local compact space S one can find a unique borel measure, such that $$F(f)=\int f d\mu$$. Question: In the dual space there are not only positive linear functional. The dual space includes all linear functional. So according to the version of Riesz-representation theorem that I stated above, the set of finite borel-measure is only a subset of the dual space. What is the sufficient condition, that every element in the dual space can be written in the form of Riesz-Representation? Will the continuity of the functional help if we introduce the weak topology on the space? What about if I take a separable metrizable space S instead of local compact space S? Can we still apply the theorem?","['functional-analysis', 'riesz-representation-theorem']"
2359136,Show that there exists a measure $\mu$ such that $\int_Y fd\nu=\int_Xf \circ F d\mu$ for all continuous $f$ on $Y$,"Suppose that $X,Y$ are compact spaces, $F: X \to Y$ is a continuous map from $X$ to $Y$. Let $\nu$ be a finite measure on Borel sets of $Y$. Show that there exists a measure $\mu$ on Borel sets of $X$ such that $\int_Y fd\nu=\int_Xf \circ F d\mu$  for all continuous $f$ on $Y$. I understand that I can use the surjectivity of $F$ to induce a map from $\phi$ from $C(Y)$ to $C(X)$ defined by $g \to g \circ F$ and then Hahn Banach Theorem as done here: prove the existence of a measure $\mu$ But I don't want to do this way. For any compact $E$, define $\mu(E)=\nu(F(E))$ (Note that $F(E)$ is compact as $F$ is continuous). Then For any $E \in \mathcal{B}_X$, define $$\mu(E)=\sup_K\{\nu(F(K)): K \subset E \text{ is compact}\}$$
I want to show that $\mu$ is a measure. Suppose that it is a measure. Then we want to show if the equality holds or not. For any $E \in \mathcal{B}_Y, \mu(F^{-1}(E))=\sup_K\{\nu(F(K)):K \subset F^{-1}(E)\text{ is compact}\}=\nu(F(F^{-1}(E))=\nu(E)$ ,where the second equality holds since $\nu$ is a Regular measure and the third as $F$ is onto. Thus $$\nu(E)=\int_Y \chi_E d\nu=\int_X \chi_E \circ F d\mu=\int\chi_{F^{-1}(E)} d\mu=\mu(F^{-1}(E))$$ Thus, the equality holds for all simple functions. Now for any continuous $f$ on $Y$, $f$ is bounded and by writing $f$ as $f^{+}-f^{-}$, we can assume $f$ to be positive. Then there exists a sequence of simple functions $\{\phi_n\}$ such that $\{\phi_n\}$ increases (uniformly) to $f$. Then $$\int_Yfd\nu=\lim_n\int_Y\phi_nd\nu=\lim_n\int_X\phi_n \circ F d\mu=\int_Xf \circ F d\mu$$ The only thing which remains to be shown is that $\mu$ as defined is a measure which I am unable to show. How can I show that, if the way $\mu$ is defined makes sense? Thanks for the help!!","['functional-analysis', 'real-analysis', 'measure-theory']"
2359187,Solving a differential equation: two different forms of the same answer,"I get given some information and have to find an equation for y in terms of X. I get the answer which is cool, but in the exam mark scheme they give a different answer which turns out to be in fact the same answer. I wouldn't care so much if it wasn't for the obvious advantage the other form has over my form. The next question asks what happens to Y as X tends to infinity. I just need somebody to explain what's going on. (I know it has something to do with the way I compute the constant c in Ln form.) The question: $dy/dx=y(4-y)$.  And when $X = 0$, $Y=1$. 
So I integrate $\frac{1}{y(4-y)}$ and get the form $\frac{1}{4}\ln(\frac{y}{4-y})+c$. But to make things easier I put c into log form as ""LnA"" Then I solve for c  and get $\ln{A}$ as $\frac{1}{4}\ln{3}$. Then I rearrange and get $Y=\frac{4e^{4x}}{e^{4x}+3}$ as a final answer. But the mark scheme answer gives $\frac{4}{3e^{-4x}+1}$. The problem here is that it is very easy to see with the second form that Y will tend to 4 if X tends to infinity. So the second form reveals more. But it looks so different. Am I missing something?",['ordinary-differential-equations']
2359194,dimension of fiber product of k-schemes of finite type,"I'm reading Görtz and Wedhorn Algebraic Geometry I, I have a question about the proof of I don't understand why the final map is still injective.
I would be grateful for any help.",['algebraic-geometry']
2359203,"Show that $\int_0^\pi g^2\,dx \leq \int_0^\pi(g')^2\,dx +(\int_0^\pi g\,dx)^2$","Show that $\int_0^\pi g^2\,dx \leq \int_0^\pi (g')^2\,dx +(\int_0^\pi g\,dx)^2$, where $g \in H^1 (0,\pi)$ and $H$ means Sobolev space here. I want to apply Poincare inequality for ball here since I noticed that $\int_0^\pi[g^2 - \frac 1 \pi(\int_0^\pi g\,dx)^2]\,dx \leq \int_0^\pi (g')^2\,dx$,which looks like the Poincare inequality in  a ball, but still not quite. Any hints would be appreciated.","['real-analysis', 'inequality', 'partial-differential-equations', 'integral-inequality', 'analysis']"
2359222,Where may I find information regarding quantitative aspects of diffeomorphism?,"If anyone bothered to check on my question history, they would see that I have already been asking several questions related to this theme. Unfortunately I haven't had much success on the specifics, so I might as well as ask this super general question as a last resort. But fundamentally, I just want to know that if $f \in C^\infty(R^n)$ and all of its derivatives vanish in some sense rapidly enough as $|x| \to \infty$, and $\phi: U \to R^n$ is a diffeomorphism, $U$ an open bounded connected subset of $R^n$, then can we assert that $f\circ \phi: U \to R^n$ has bounded derivatives of all orders? The issue is of course that since $U$ is a bounded set, $D\phi$ must diverge, and in fact every derivative diverges hence they must do so rapidly (?). $D(f\circ \phi) = (Df)\circ \phi D\phi$, so it comes down to comparing the rate of vanishing of $D^n f$ and the rate of divergence of $D^m \phi$. This question will probably defy any sort of generalization, but can we at least assert that if $f$ and $D^n f$ vanish say $O(e^{-|x|^2})$ as $|x| \to \infty$, then given $U$, we may find $\phi$ such that $f \circ \phi$ has bounded derivatives of all orders?","['multivariable-calculus', 'differential-geometry', 'differential-topology']"
2359243,"If $\tan(\alpha)+\cot(\alpha)=p,$ denote $\tan^3(\alpha)+\cot^3(\alpha)$ in terms of $p$","I wrote the second expression according to the identity:
\begin{align}
& \tan^3(\alpha) + \cot^3(\alpha) \\[10pt]
= {} & \bigl(\tan(\alpha) + \cot(\alpha)\bigr) \bigl( \tan^2(\alpha) - \tan(\alpha) \cot(\alpha) + \cot^2(\alpha)\bigr) \\[10pt]
= {} & p\bigl(\tan^2(\alpha) + \cot^2(\alpha) - 1\bigr).
\end{align} 
Then tried to use the  identity $a^2+b^2=(a-b)^2+2ab$ but that was to no vail. How to solve it?",['trigonometry']
2359253,Defining an inner product by means of a multilinear functional,"Let $V$ be a complex vector space and an anti-linear involution $J:V \rightarrow V$ (this means that $J^2 = I$  and if $\lambda \in \mathbb{C}$ and $x, y \in V$ we have $J(\lambda x + y) = \overline{\lambda} J(x)+J(y)$). Fix $N$ a natural number and consider a multilinear functional $\omega:V^{2N}\rightarrow \mathbb{C}$ such that: $\omega(x_1,...,x_{2N}) = \omega(x_2, ..., x_{2N},x_1)$, for every $x_1,x_2,...,x_{2N} \in V$ The matrix $A$ whose matrix elements $A_{ij}$ defined by 
$A_{ij} = \omega(Jx_{i1},..., Jx_{iN}, x_{j1},..., x_{jN})$ is positive semi-definite for every $x_{kl} \in V$, $k=1,..., n$ and $l=1,...,N$, where $n$ can be any natural number. I saw this on a paper that I'm currently reading and the author claims that the condition 2 implies that the following:
$$\langle x, y \rangle = \omega(x_1,..., x_N, Jy_N,... Jy_1)$$ defines an inner product in $V^N$. I'm not sure about this because this is not linear in the first coordinate. Did I get this wrong?","['linear-algebra', 'inner-products']"
2359261,"determine for which values of $x$ the function $f(x)=\begin{cases} \frac{x^2-4}{x-2}+10, &\text{if }x < 2\\ 2x^3-x, &\text{if } x ≥ 2\\ \end{cases}$","is continuous... $$f(x)=\begin{cases}
\frac{x^2-4}{x-2}+10, &\text{if }x < 2\\
2x^3-x, &\text{if } x ≥ 2\\
\end{cases}$$ These kind of problems are very unclear to me, I only know these kind of functions have several graphs, in this example There are 2, But I can't figure out what these intervals means and even worse I don't even know where to start from.","['calculus', 'limits']"
2359301,Constructing the incenter of a triangle in only six steps,"Lately I have become hooked on the game Euclidea. One of the problems gives a triangle and asks you to construct the incenter, or as it is put, ""the intersection of angle bisectors."" It is stated that it should only take six steps. Steps are in the mode of the straightedge and collapsible compass constructions at the beginning of Baby Hartshorne: use of the ruler to construct a line or line segment and use of the compass to construct a circle are counted. Extending lines or constructing points at previously constructed intersections are not. The obvious solution has sadly been my best effort: bisect two of the triangle's angles (3 circles and 1 line each) and mark the intersection of the two lines. Any help is appreciated.","['euclidean-geometry', 'geometric-construction', 'geometry']"
2359335,Find the number of distributions of seven distinct balls into three distinct boxes if at least two balls must go into each box.,"My Answer: I chose to place three balls into one box and two balls in the other two boxes. This can be done three times:
$$\binom73\binom42\binom22=\binom{7}{3,2,2}\\ \binom72\binom53\binom22=\binom{7}{2,3,2} \\ \binom72\binom52\binom33=\binom{7}{2,2,3}$$
I'm not sure if this is correct, but we have not covered Stirling numbers yet, so I cannot use that as my explanation. Please help and thank you!","['permutations', 'combinatorics', 'combinations', 'discrete-mathematics']"
2359363,Polar Coordinates tranformation for Linear Homogeneous Differential Equations (1st order),"While studying a book of Differential Equations I found this problem so interesting. Suppose 
\begin{equation} 
M(x,y)dx+N(x,y)dy=0          \tag 1
\end{equation} is  a homogeneous ODE. Show that the transformation $x=r \cos (\theta) $ and $y= r \sin (\theta) $ reduces the equation to a separable  equation in the variables $r$ and $\theta$ Is from the book Diff. Eq's, Shepley L.  Ross. So starting from the hypothesis that the equation is homogenous then $(1)$ is equivalent to \begin{equation} 
\frac{dy}{dx}=g\left(\frac{y}{x}\right)          \tag 2
\end{equation} So the thing is thatI don't know how to relate $x$ and $y$ , or more precisely how to find the relation $\dfrac{dr}{d\theta}$ (or maybe the other way around) The first thing that came to  mind was $r^2=x^2+y^2$ but how do I differentiate it ? I mean, I don´t see clearly how to use the chain rule I have seen this $2rr'=2xx'+2yy'$. Although, still not clear how did they do it. Later, a silly approach (I think so) was to take the differentials of either $x$ and $y$ with respect to $r$ and $\theta$, respectively. Therefore: $$x=r \cos (\theta) \Rightarrow dx=\cos (\theta) dr  $$ and 
$$y= r \sin (\theta) \Rightarrow dy= r \cos (\theta) d\theta .$$ 
Later $$\frac{dy}{dx}=\frac{r \cos (\theta) d\theta} { \cos (\theta) dr} = \frac{r d\theta} {dr}$$ So after substituting in $(2)$ \begin{equation} 
\frac{r d\theta} {dr}=g\left(\frac{\sin \theta }{ \cos \theta }\right)  
\end{equation} which reduces it to a separable equation \begin{equation} 
\frac{dr } {r }=\frac{d\theta} { g(\tan \theta )}   
\end{equation} But.... come on!
At least I tried... Later the book  has also as an exercise to prove that the same equations is invariant under the tranformations $x=k\alpha$ and $y=k\beta$ with $k$ constant. But I think that the previous one seems more approachable. Could someone help me with this kind of problems? Thanks. :)","['polar-coordinates', 'ordinary-differential-equations', 'linear-transformations', 'calculus']"
2359382,Express the differential equation as power series,"My attempt: $y=\sum^{\infty}_{n=0}a_n x^n \rightarrow y'=\sum^{\infty}_{n=0}na_n x^{n-1}\rightarrow y''=\sum^{\infty}_{n=0}n(n-1)a_n x^{n-2}\\
(2+x^2)y""+x^2y'+3y=(2+x^2)\sum^{\infty}_{n=0}n(n-1)a_n x^{n-2}+x^2\sum^{\infty}_{n=0}na_n x^{n-1}+3\sum^{\infty}_{n=0}a_n x^n\\
2\sum^{\infty}_{n=0}n(n-1)a_n x^{n-2}+\sum^{\infty}_{n=0}n(n-1)a_n x^{n}+\sum^{\infty}_{n=0}na_n x^{n+1}+3\sum^{\infty}_{n=0}a_n x^{n}$ from here can any help me",['ordinary-differential-equations']
2359408,Determining if function is surjective,"Question: Let $\\f: \ \mathbb{R} \to \mathbb{R} \times \mathbb{R}$ via $ f(x) = (x+2, x-3)$. Is $f$ injective? Is $f$ surjective? I was able to prove that $f$ is injective. However, I am not quite sure if $f$ is surjective. If it is surjective could someone please tell me how to prove that. If not, could someone provide a counter example. Thanks","['elementary-set-theory', 'functions']"
2359436,What is the difference between an homogeneous and an isotropic space,"I try to get my head around the different kinds of homogi-enities (global similarities of a space ) and these are two of the global similarities I stumble upon and I don't really know the difference. Feel free to add other global similarities to your answer if you like I would like to know about all Related: How to say that the ""geometry is the same"" at every point of a metric space?","['terminology', 'homogeneous-spaces', 'isometry', 'geometry']"
2359454,"Why is $\langle a,b\mid 2a=2b\rangle\cong\mathbb{Z}\oplus\mathbb{Z}_2$","May I ask, why is $$\langle a,b\mid 2a=2b\rangle\cong\mathbb{Z}\oplus\mathbb{Z}_2?$$ I am quite new with group generators. In this case, the coefficients are in $\mathbb{Z}$, and we are in the abelian case. Thanks for any tips. Update: I figured out an idea: Let $a=(1,1), b=(1,0)$ which are elements in $\mathbb{Z}\oplus\mathbb{Z}_2$. Then $a,b$ generate $\mathbb{Z}\oplus\mathbb{Z}_2$, and satisfy only the relation $2a=2b=(2,0)$. Is this the correct way to view it?","['abstract-algebra', 'group-theory']"
2359455,Iranian TST problem on maximum subset with some property in a poset,"Let $M$ be the largest subset of $\{1,\dots,n\}$ such that for each $x\in M$ , $x$ divides at most one other element in $M$ . Prove that $$ |M|\leq \left\lceil \frac{3n}4\right\rceil. $$ My attempt: Let $M_1 = \{x\in M;\;\exists !y\in M:\; x|y \} $ and $M_0 = M\setminus M_1$ .
Obviously both $M_0$ and $M_1$ are an antichains in $M$ and they make a partition of $M$ . And this is all I can find. I was thinking about Dilworth theorem but... Also, I was thinking, what if I add a new element $k\in M^C$ to $M$ . Then $M\cup \{k\}$ is no more ''good'' set...","['combinatorics', 'contest-math', 'order-theory']"
2359457,Is Pythagoras' theorem about distances or areas?,"In $\mathbb{R}^2$ with the 1-norm or $\infty$-norm, Pythagoras' theorem is false for lengths of sides of a ""right-angled'' triangle, but it is true for areas of shapes on the sides. For example, given a triangle with coordinates $(0,0)$, $(4,0)$, $(0,3)$, the sides have length 3,4,7, or 3,4,4 (depending on the norm); but the areas of squares on the sides are still 9,16,25 because Lebesgue measure is independent of the norm. Is there a relation between measures and norms that are ""compatible'' to them? In this case, Lebesgue measure seems to fit more naturally with Euclidean distance because the area of a rectangle, for example, is proportional to the product of the lengths of its sides, but I don't know if there is a simple formula in terms of the 1-lengths of its sides. If there is a theory on this it doesn't get mentioned in textbooks.",['geometry']
2359458,How to show $\exp(ix)=\cos x+i\sin x$ using $\exp(z)=\sum_{n=0}^{\infty}\frac{z^n}{n!}$,"I have the following problem: How to show $\exp(ix)=\cos x+i\sin x$ using $\exp(z)=\sum_{n=0}^{\infty}\frac{z^n}{n!}$ My attempt : 
\begin{align*}
\exp(ix)=\sum_{n=0}^{\infty}\frac{(ix)^n}{n!}
\end{align*}
Now split the sum in 4 sums because $i^n$ has period 4, more precisely $i^{4n}=1$, $i^{4n+1}=i$, $i^{4n+2}=-1$ and $i^{4n+3}=-i$ for $n\geq 0$.
\begin{align*}
\sum_{n=0}^{\infty}\frac{(ix)^n}{n!}&=\sum_{n=0}^{\infty}\frac{(ix)^{4n}}{(4n)!}+\sum_{n=0}^{\infty}\frac{(ix)^{4n+1}}{(4n+1)!}+\sum_{n=0}^{\infty}\frac{(ix)^{4n+2}}{(4n+2)!}+\sum_{n=0}^{\infty}\frac{(ix)^{4n+3}}{(4n+3)!}\\
&=\sum_{n=0}^{\infty}\left(\frac{x^{4n}}{(4n)!}-\frac{x^{4n+2}}{(4n+2)!}\right)+i\sum_{n=0}^{\infty}\left(\frac{x^{4n+1}}{(4n+1)!}-\frac{x^{4n+3}}{(4n+3)!}\right)
\end{align*}
Then $4n$ and $4n+2$ are nonnegative and even numbers and $4n+1$ and $4n+3$ are odd. How can I use this to convert the two last expressions into
\begin{align*}
\cos x&=\sum_{m=0}^{\infty}(-1)^m \frac{x^{2m}}{(2m)!}\\
\sin x&=\sum_{m=0}^{\infty}(-1)^m \frac{x^{2m+1}}{(2m+1)!}
\end{align*}
I don't want to see proofs like
\begin{align*}
\exp(ix)&=1+ix+\frac{(ix)^2}{2!}+\frac{(ix)^3}{3!}+\frac{(ix)^4}{4!}+\frac{(ix)^5}{5!}\ldots\\
&=\Big(1-\frac{x^2}{2!}+\frac{x^4}{4!}\mp\ldots\Big)+i\Big(x-\frac{x^3}{3!}+\frac{x^5}{5!}\mp\ldots\Big)\\
&=\cos x+i\sin x
\end{align*}","['real-analysis', 'complex-numbers', 'exponential-function', 'calculus', 'sequences-and-series']"
2359474,"The possible degrees of $\mathbb{Q}(a,b)$ in terms of the degrees of $a$ and $b$","Let $n,m \geq 1$ be natural numbers. Is there a characterization of those natural numbers $d$ for which there are algebraic numbers $a,b$ of degrees $n,m$ such that $\mathbb{Q}(a,b)$ has degree $d$ over $\mathbb{Q}$? Two necessary conditions are $\mathrm{lcm}(n,m) \mid d$ and $d \leq nm$. (In particular, if $n,m$ are coprime, only $ d=nm$ is possible.) Are they sufficient? Or do we actually have $d \mid nm$? I have chosen $\mathbb{Q}$ just to fix ideas, maybe the same analysis works for any field (of characteristic zero). So an answer treating this more general case is appreciated as well.","['abstract-algebra', 'extension-field', 'field-theory']"
2359529,"$X=\mathrm{Spec}\ k[x,y,z]/(xy-z^2)\Longrightarrow \mathrm{Pic}(X)=0$","An exercise of Hartshorne shows that, given $A= k[x,y,z]/(xy-z^2)$, $\mathrm{Cl}(A)=\mathbb Z/2\mathbb Z$. I must prove that $\mathrm{Pic}(\mathrm{Spec}\ A)=0$, thus giving a counter-example to $\mathrm{Pic}=\mathrm{Cl}$. My attempt was to consider some UFD $B$, e.g. $k[x,y,z]$ itself, send it to $A$, and obtain a map from $Pic(\rm Spec\ B)$ to $Pic(\rm Spec\ A)$, and then hope that this is surjective. This would conclude since $B$ UFD implies $Pic(\rm Spec\ B)=0$. Can this work? Any hints are welcome.","['schemes', 'algebraic-geometry', 'commutative-algebra']"
2359568,A circle tangent to an ellipse,"A friend of mine showed me the following problem: Let $\cal E$ be an ellipse whose semi major axis has length $a$ and semi minor axis has length $b$. Let $\ell_1, \ell_2$ be two parallel lines tangent to $\cal E$. Let $\cal C$ be the circle tangent to $\ell_1$, $\ell_2$, and $\cal E$. Prove that the distance between the centers of $\cal C$ and $\cal E$ is equal to $a+b$. So far I managed to prove that if we draw the tangent line $k_1$ through $\cal E \cap \cal C$ and the tangent $k_2$ to $\cal E$ parallel to $k_1$ then the circle tangent to $k_1, k_2, \ell_1$ is tangent to $\cal E$ as well. I'm stuck. I'd like to see some proofs, preferably non-analytic ones.","['sangaku', 'conic-sections', 'euclidean-geometry', 'geometry']"
2359621,"What does $\lim\limits_{(x,y)\rightarrow0}$ mean and how to show $ \lim\limits_{(x,y)\rightarrow0}\frac{x^3}{x^2+y^2}=0$?","Consider $f:\mathbb{R}^2 \rightarrow \mathbb{R}$ where $$f(x,y):=\begin{cases}
      \frac{x^3}{x^2+y^2} & \textit{ if }  (x,y)\neq (0,0) \\
      0 & \textit{ if }  (x,y)= (0,0)
    \end{cases} $$ If one wants to show the continuity of $f$, I mainly want to show that $$ \lim\limits_{(x,y)\rightarrow0}\frac{x^3}{x^2+y^2}=0$$ But what does $\lim\limits_{(x,y)\rightarrow0}$ mean? Is it equal to $\lim\limits_{(x,y)\rightarrow0}=\lim\limits_{||(x,y)||\rightarrow0}$ or does it mean $\lim\limits_{x\rightarrow0}\lim\limits_{y\rightarrow0}$? If so, how does one show that the above function tends to zero?","['multivariable-calculus', 'real-analysis']"
2359627,"Geometric Interpretation of the ""Half Derivative""","I've been doing a little bit of research into fractional calculus involving fractional derivatives, and I was wondering what the geometric interpretations of such derivatives would be. As we know, the first derivative can represent slope or rate of change, and the second derivative can be used to investigate convexity or concavity. What about fractional derivatives, like the half-derivative? Is there any geometric interpretation or practical application for such a derivative? Furthermore, finding such a derivative seems to be quite elusive. It is often tempting to find a ""multiple derivative formula"" such as
$$\frac{d^n}{dx^n} \ln (x)=\frac{(-1)^{n-1}(n-1)!}{x^n}$$
and then evaluate it at fractional values, but this does not work. Because such a formula can be proven only by induction, evaluating it at fractional values is not justified. Is there any way to find a fractional derivative without a formula proven by induction, or does a fractional derivative just have to be defined separately? TLDR: What is the geometric interpretation of a fractional derivative? What are some applications? How do I find a fractional derivative?","['derivatives', 'fractional-calculus']"
2359646,Properties that are not preserved under homeomorphism,"Homeomorphism establishes a very strong relationship between topological spaces. We know that many important properties such as compactness and connectedness are preserved under homeomorphism, and fundamental groups of such spaces are isomorphic. I wish to gain some more intuition on the possible limits of homeomorphism, so I was wondering if you have any examples of properties that are not preserved under homeomorphism? Searching SE I found one such example here , which discusses completeness. I think that Vadim's answer was particularly good, since it shows that while the choice of metric is independent of the existence of homeomorphism, the fact that a space $X$ is homeomorphic to a complete metric space means it is metrizable by some complete metric. So are there any more properties like the above? Or ones that entirely break under homeomorphism?",['general-topology']
2359664,"Solving the integral $\int_{-\infty}^{\infty}e^x e^{-e^x} e^{-x^2}\,dx$","I am struggling to solve the integral $$\int_{-\infty}^{\infty}e^x e^{-e^x} e^{-x^2}\,dx.$$ Is there a way to find an exact solution in terms of standard mathematical functions (including non-elementary functions such as the error function and the gamma function )? What I have tried: Through substitution ($u = e^x$) I have found that the value is equal to $$\int_{0}^{\infty}e^{-u} e^{-(ln\ u)^2}\,du$$ I have tried further substitutions but none have helped me arrive at a value. I know from WolframAlpha that the value is around $0.529$.","['integration', 'calculus']"
2359720,Interesting Proofs about Metric Spaces?,"I'm currently working through the book Introduction to Topology by Bert Mendelson, and I've finished all of the exercises provided at the end of the section that I have just completed, but I would like some more to try. I've just finished learning about metric spaces, continuity, and open balls about points in metric spaces. Just for a bit of context, some of the proofs that I have done include: If $(X,d)$ is a metric space and $a\in X$, for each $\delta \gt 0$, the open ball $B(a; \delta)$ is a neighborhood of each of its points. Let $f:(X,d)\to (Y,d')$, $a\in X$, and let $\beta_{f(a)}$ be a basis for the neighborhood system at $f(a)$. Prove that $f$ is continuous at $a$ iff $f^{-1}(N)$ is a neighborhood of $a$ for each $N \in \beta_{f(a)}$. If $a$ and $b$ are distinct points of a metric space $X$, prove that there exist neighborhoods $N_a$ and $N_b$ of $a$ and $b$ respectively such that $N_a \cap N_b=\varnothing$. If $(X,d)$ is a metric space containing $a$ and $b$, and $\delta+\eta \lt d(a,b)$, then $B(a;\delta)\cap B(b;\eta)=\varnothing$. Can anybody give me any other (perhaps slightly more challenging) proofs to do about these topics? I would like to practice some more with them, but I'm not very good about forming true conjectures to prove. Thanks!","['general-topology', 'real-analysis', 'metric-spaces', 'soft-question']"
2359753,"Hoffman Kunze, Lemma concerning triangulable operators","I am currently studying Linear Algebra by myself and recently I have stumbled across an important Lemma in Hoffman Kunze's book: Lemma . 
  Let $V$ be a finite-dimensional vector space over the field $F$. Let $T$ be linear operator on $V$ such that the minimal polynomial for $T$ is a product of linear factors $$p = (x-c_{1})^{r_{1}}...(x-c_{k})^{r_{k}}, c_{i} \in F.$$ Let $W$ be a proper subspace of $V$ which is invariant under $T$. there  exists a vector $\alpha$ in $V$ such that a) $\alpha\notin W$; b) $(T-cI)\alpha\in W$, for some characteristic value $c$ of the operator $T$. I must admit that I'm a little confused at this point. If I understand correctly, by using this Lemma we can produce a sequence $\{0\} = W_{0} \subset W_{1} \subset \ldots \subset W_{n} = V$ of invariant subspaces for $T$ s.t. $\dim{W_{i}}=i$, which would give me a basis in which the matrix of the operator $T$ is triangular. But this is not clear to me. Can someone explain to me the exact meaning of the condition $(b)$? Why this $\alpha$, together with the old basis, spans an invariant subspace? How does it all relates to the invariant hyperplanes - are those exactly what $W_{i}$'s are? The book says that $(a)$ and $(b)$ state that the $T$-conductor of $\alpha$ into $W$ (i.e. the unique monic generator of the ideal $S(\alpha ; W)$) is a linear polynomial - that is also a little confusing to me and I would appreciate some explanation of this statement. Thanks in advance for any help.","['linear-algebra', 'invariant-subspace']"
2359759,Prove that the following complex-valued function is odd.,"I'm working on the following problem from the Texas A&M Fall 2013 graduate level qualifying exam: Define $\Omega:=\mathbb{C}\setminus [-i,i]$, that is, the complex
  plane with a slit along the imaginary axis from $-i$ to $i$. Suppose
  that $f\in H(\Omega)$ is such that $(f(z))^2=z^2+1$ for every $z\in \Omega$. Prove that $f$ is odd, namely, $f(z)=-f(-z)$ for all $z\in\Omega$. I started by defining $g:\Omega\to\mathbb C$ by $g(z)=f(z)+f(-z)$; clearly, it suffices to show that $g\equiv 0$ on $\Omega$. By a simple computation, one can see that $[g(z)]^2=2f(z)g(z)$. I then tried to prove the claim by contradiction - supposing that there is some $c\in \Omega$ such that $g(z)\neq 0$, but things started to get messy, and I figured I was on the wrong track. Edit: changed brackets to parentheses.","['complex-analysis', 'holomorphic-functions']"
2359773,Graph theory in disguise?,"There are $2n-1$ two-element subsets of set $\{1,2,...,n\}$ . Prove that one can choose $n$ out of these such that their union contains no more than $\frac{2}{3}n+1$ elements. I was trying this one too and with no success. Then I read the official solution (page 10, problem 5) and it is a kind of not natural to me. Can someone try to walk another way?","['graph-theory', 'optimization', 'extremal-combinatorics', 'combinatorics', 'contest-math']"
